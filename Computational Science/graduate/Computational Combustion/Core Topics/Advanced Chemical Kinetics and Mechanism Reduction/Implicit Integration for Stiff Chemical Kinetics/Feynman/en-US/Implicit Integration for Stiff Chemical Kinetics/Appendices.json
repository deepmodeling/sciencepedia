{
    "hands_on_practices": [
        {
            "introduction": "The choice of an integrator for stiff chemical kinetics is dictated by its stability properties, not just its order of accuracy. This exercise grounds this principle by having you analyze two classic implicit methods using the Dahlquist test equation, $\\dot{y} = \\lambda y$, which serves as the fundamental model for linear stability analysis. By deriving and comparing the stability regions of the Trapezoidal rule and the second-order Backward Differentiation Formula (BDF2), you will gain a firsthand understanding of L-stability and its crucial role in damping the non-physical, rapidly decaying modes characteristic of stiff systems .",
            "id": "4031709",
            "problem": "A homogeneous, constant-pressure reactor with stiff chemistry is advanced in time using implicit integrators. Linearization of the species source terms about a quasi-steady state yields the scalar Dahlquist test equation $\\,\\dot{y} = \\lambda y\\,$ for each eigenmode of the Jacobian, where $\\,\\lambda \\in \\mathbb{C}\\,$ and stiff recombination manifests as eigenvalues with large negative real parts. Let $\\,h > 0\\,$ denote a constant time step and define the nondimensional variable $\\,z = h \\lambda\\,$.\n\nTwo standard implicit methods are considered:\n- The trapezoidal rule (also known as the Crankâ€“Nicolson method).\n- The two-step Backward Differentiation Formula (BDF) of order two, hereafter Backward Differentiation Formula (BDF2).\n\nStarting from the definitions of these methods and the Dahlquist test equation, perform the following:\n1. For each method, derive the discrete propagation relation for $\\,y_{n+1}\\,$ in terms of previous values and $\\,z\\,$, and from it determine the linear absolute stability region in the $\\,z$-plane. For the trapezoidal rule, this is characterized by the modulus of a single amplification factor. For Backward Differentiation Formula (BDF2), this is characterized by the root condition for the characteristic polynomial of the two-step recurrence.\n2. Define the spectral radius $\\,\\rho(z)\\,$ of the one-step propagation operator as follows: for the trapezoidal rule, $\\,\\rho(z)\\,$ is the modulus of its single amplification factor; for Backward Differentiation Formula (BDF2), $\\,\\rho(z)\\,$ is the maximum modulus of the two characteristic roots. Then consider eigenvalues $\\,\\lambda\\,$ with $\\,\\Re(\\lambda) \\ll 0\\,$ and evaluate the asymptotic damping of stiff modes by computing the limits\n$$\n\\lim_{r \\to \\infty} \\rho_{\\mathrm{TR}}(-r)\n\\quad \\text{and} \\quad\n\\lim_{r \\to \\infty} \\rho_{\\mathrm{BDF2}}(-r),\n$$\nwhere $\\,r \\in \\mathbb{R}\\,$ and $\\,r > 0\\,$, and the subscript denotes the method.\n\nReport your final result as the ordered pair consisting of these two limits in the form $\\,\\big(\\lim_{r \\to \\infty} \\rho_{\\mathrm{TR}}(-r),\\,\\lim_{r \\to \\infty} \\rho_{\\mathrm{BDF2}}(-r)\\big)\\,$. Provide exact values (no rounding). The final answer must be dimensionless.",
            "solution": "The problem statement has been validated and is deemed a valid, well-posed problem in the field of numerical analysis for ordinary differential equations. It is scientifically grounded, self-contained, and objective.\n\nThe objective is to analyze two implicit numerical integration methods, the trapezoidal rule (TR) and the two-step Backward Differentiation Formula (BDF2), as applied to the Dahlquist test equation $\\dot{y} = \\lambda y$. We will first derive the stability properties for each method and then evaluate their asymptotic damping behavior for stiff modes, which are characterized by eigenvalues $\\lambda$ with large negative real parts. This is modeled by taking the limit of the spectral radius as $z = h\\lambda \\to -\\infty$ along the real axis.\n\n**Part 1: Trapezoidal Rule (TR)**\n\nThe trapezoidal rule (also known as the Crank-Nicolson method) applied to the ordinary differential equation (ODE) $\\dot{y} = f(y)$ is given by:\n$$y_{n+1} = y_n + \\frac{h}{2} \\left[ f(y_n) + f(y_{n+1}) \\right]$$\nFor the Dahlquist test equation, $f(y) = \\lambda y$. Substituting this into the TR formula gives:\n$$y_{n+1} = y_n + \\frac{h}{2} (\\lambda y_n + \\lambda y_{n+1})$$\nWe now solve for $y_{n+1}$ to find the propagation relation.\n$$y_{n+1} \\left( 1 - \\frac{h\\lambda}{2} \\right) = y_n \\left( 1 + \\frac{h\\lambda}{2} \\right)$$\nUsing the definition $z = h\\lambda$, we have:\n$$y_{n+1} \\left( 1 - \\frac{z}{2} \\right) = y_n \\left( 1 + \\frac{z}{2} \\right)$$\n$$y_{n+1} = \\left( \\frac{1 + \\frac{z}{2}}{1 - \\frac{z}{2}} \\right) y_n$$\nThis is a one-step recurrence relation of the form $y_{n+1} = G_{\\mathrm{TR}}(z) y_n$, where the amplification factor is:\n$$G_{\\mathrm{TR}}(z) = \\frac{1 + \\frac{z}{2}}{1 - \\frac{z}{2}}$$\nThe region of absolute stability is the set of all $z \\in \\mathbb{C}$ for which $|G_{\\mathrm{TR}}(z)| \\le 1$. Let $z = x + iy$ where $x, y \\in \\mathbb{R}$.\n$$ \\left| \\frac{1 + \\frac{x+iy}{2}}{1 - \\frac{x+iy}{2}} \\right| \\le 1 \\implies \\left| \\frac{ (2+x) + iy }{ (2-x) - iy } \\right| \\le 1 $$\n$$| (2+x) + iy | \\le | (2-x) - iy |$$\nSquaring both sides gives:\n$$(2+x)^2 + y^2 \\le (2-x)^2 + (-y)^2$$\n$$4 + 4x + x^2 + y^2 \\le 4 - 4x + x^2 + y^2$$\n$$8x \\le 0 \\implies x \\le 0$$\nThe stability region is the entire left half of the complex plane, $\\Re(z) \\le 0$. A method with this property is called A-stable.\n\nThe spectral radius for this one-step method is simply the modulus of the amplification factor:\n$$\\rho_{\\mathrm{TR}}(z) = |G_{\\mathrm{TR}}(z)| = \\left| \\frac{1 + \\frac{z}{2}}{1 - \\frac{z}{2}} \\right|$$\nWe are asked to compute the limit for stiff modes along the negative real axis. This corresponds to $z = -r$ for $r \\in \\mathbb{R}$ with $r > 0$ and $r \\to \\infty$.\n$$\\lim_{r \\to \\infty} \\rho_{\\mathrm{TR}}(-r) = \\lim_{r \\to \\infty} \\left| \\frac{1 + \\frac{-r}{2}}{1 - \\frac{-r}{2}} \\right| = \\lim_{r \\to \\infty} \\left| \\frac{1 - \\frac{r}{2}}{1 + \\frac{r}{2}} \\right| = \\lim_{r \\to \\infty} \\left| \\frac{2 - r}{2 + r} \\right|$$\nDividing the numerator and denominator by $r$:\n$$\\lim_{r \\to \\infty} \\left| \\frac{\\frac{2}{r} - 1}{\\frac{2}{r} + 1} \\right| = \\left| \\frac{0 - 1}{0 + 1} \\right| = |-1| = 1$$\nThus, the asymptotic damping limit for the trapezoidal rule is $1$.\n\n**Part 2: Two-Step Backward Differentiation Formula (BDF2)**\n\nThe BDF2 method applied to the ODE $\\dot{y} = f(y)$ is given by:\n$$\\frac{3}{2} y_{n+1} - 2y_n + \\frac{1}{2} y_{n-1} = h f(y_{n+1})$$\nFor the Dahlquist test equation, $f(y_{n+1}) = \\lambda y_{n+1}$. Substituting this gives:\n$$\\frac{3}{2} y_{n+1} - 2y_n + \\frac{1}{2} y_{n-1} = h \\lambda y_{n+1}$$\nCollecting terms and substituting $z = h\\lambda$:\n$$\\left( \\frac{3}{2} - z \\right) y_{n+1} - 2y_n + \\frac{1}{2} y_{n-1} = 0$$\nThis is a linear homogeneous recurrence relation. To analyze its stability, we seek solutions of the form $y_n = \\xi^n$. Substituting this ansatz yields the characteristic polynomial for $\\xi$:\n$$\\left( \\frac{3}{2} - z \\right) \\xi^2 - 2\\xi + \\frac{1}{2} = 0$$\nMultiplying by $2$ to clear the fractions gives a more convenient form:\n$$(3 - 2z) \\xi^2 - 4\\xi + 1 = 0$$\nThe stability of the method depends on the roots of this polynomial. The method is absolutely stable if all roots $\\xi_k$ satisfy $|\\xi_k| \\le 1$ (the root condition). The spectral radius $\\rho_{\\mathrm{BDF2}}(z)$ is the maximum modulus of these roots, $\\rho_{\\mathrm{BDF2}}(z) = \\max_k |\\xi_k|$.\n\nWe evaluate the limit for stiff modes by setting $z = -r$ with $r > 0$ and $r \\to \\infty$. The characteristic polynomial becomes:\n$$(3 - 2(-r)) \\xi^2 - 4\\xi + 1 = 0 \\implies (3 + 2r) \\xi^2 - 4\\xi + 1 = 0$$\nThe roots $\\xi_{1,2}$ are given by the quadratic formula:\n$$\\xi = \\frac{-(-4) \\pm \\sqrt{(-4)^2 - 4(3+2r)(1)}}{2(3+2r)} = \\frac{4 \\pm \\sqrt{16 - 12 - 8r}}{2(3+2r)} = \\frac{4 \\pm \\sqrt{4 - 8r}}{6 + 4r}$$\nFor $r > \\frac{1}{2}$, the discriminant is negative, so the roots are a complex conjugate pair. Let the roots be $\\xi$ and $\\bar{\\xi}$. The product of the roots is given by Vieta's formulas:\n$$\\xi \\bar{\\xi} = \\frac{1}{3 + 2r}$$\nThe modulus squared of a complex number is the product of the number and its conjugate, i.e., $|\\xi|^2 = \\xi \\bar{\\xi}$. Since the two roots are complex conjugates, they have the same modulus. Therefore, the spectral radius is the modulus of either root:\n$$\\rho_{\\mathrm{BDF2}}(-r) = |\\xi| = \\sqrt{\\xi \\bar{\\xi}} = \\sqrt{\\frac{1}{3 + 2r}} = \\frac{1}{\\sqrt{3 + 2r}}$$\nNow we can compute the required limit:\n$$\\lim_{r \\to \\infty} \\rho_{\\mathrm{BDF2}}(-r) = \\lim_{r \\to \\infty} \\frac{1}{\\sqrt{3 + 2r}}$$\nAs $r \\to \\infty$, the denominator $\\sqrt{3+2r} \\to \\infty$. Therefore, the limit is $0$.\n\n**Conclusion**\n\nThe calculated limits are:\n$$\\lim_{r \\to \\infty} \\rho_{\\mathrm{TR}}(-r) = 1$$\n$$\\lim_{r \\to \\infty} \\rho_{\\mathrm{BDF2}}(-r) = 0$$\nThe ordered pair of these limits is $(1, 0)$. A value of $\\rho$ close to $0$ indicates strong damping of stiff components, which is desirable. A value of $1$ indicates no damping. Thus, BDF2 is superior to the trapezoidal rule for handling stiff problems, a property known as L-stability.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "At the heart of any implicit solver for stiff kinetics lies the Newton-Raphson method, which leans heavily on the system's Jacobian matrix to find a solution. This hands-on exercise transitions from theory to practice, tasking you with the derivation and implementation of the analytic Jacobian for a representative hydrogen-oxygen chemical mechanism. Comparing your analytic Jacobian to a numerical finite-difference approximation will provide crucial insights into computational accuracy and the sparse structure of the matrix, illustrating why analytic Jacobians are indispensable for building efficient and robust chemistry solvers .",
            "id": "4031752",
            "problem": "Consider a chemically reacting system representative of hydrogen oxidation, formulated for implicit time integration of stiff chemical kinetics. The governing source term for species in an Ordinary Differential Equation (ODE) system follows the law of mass action for elementary reactions. Let the vector of molar concentrations be $\\mathbf{C} \\in \\mathbb{R}^N$ with components $C_i$ in $\\mathrm{mol}\\,\\mathrm{m}^{-3}$ for species $i$. The reaction rate of progress for an irreversible elementary reaction $n$ with Arrhenius parameters $(A_n,n_n,E_{a,n})$ at temperature $T$ is given by\n$$\nk_n(T) = A_n T^{n_n} \\exp\\left(-\\frac{E_{a,n}}{R T}\\right),\n$$\nwhere $R$ is the universal gas constant in $\\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$. For a reaction whose reactant stoichiometric exponents are $\\nu_{j,n}^{\\mathrm{react}}$, the forward rate of progress is\n$$\nr_n(\\mathbf{C},T) = k_n(T) \\prod_{j=1}^N C_j^{\\nu_{j,n}^{\\mathrm{react}}}.\n$$\nFor third-body reactions, the effective third-body concentration is taken as the total molar concentration $M = \\sum_{j=1}^N C_j$ with all third-body efficiencies equal to unity, so that a termolecular reaction $a + b + M \\rightarrow \\cdots$ has rate\n$$\nr_n(\\mathbf{C},T) = k_n(T) \\, C_a \\, C_b \\, M.\n$$\nThe species rate of production is\n$$\n\\omega_i(\\mathbf{C},T) = \\sum_{n=1}^{N_r} s_{i,n} \\, r_n(\\mathbf{C},T),\n$$\nwhere $s_{i,n}$ are the net stoichiometric coefficients (positive for products, negative for reactants) for species $i$ in reaction $n$, and $N_r$ is the number of reactions. The analytic Jacobian of the source term is the matrix\n$$\nJ_{i j}(\\mathbf{C},T) = \\frac{\\partial \\omega_i(\\mathbf{C},T)}{\\partial C_j}.\n$$\nYou will implement the analytic Jacobian for a reduced hydrogen/oxygen ($\\mathrm{H}_2/\\mathrm{O}_2$) mechanism at a fixed temperature $T$ and pressure $p$, and compare its accuracy and sparsity pattern to a finite-difference approximation.\n\nMechanism definition. Consider $N=8$ species ordered as $\\left[\\mathrm{H}_2,\\ \\mathrm{O}_2,\\ \\mathrm{H},\\ \\mathrm{O},\\ \\mathrm{OH},\\ \\mathrm{HO}_2,\\ \\mathrm{H}_2\\mathrm{O}_2,\\ \\mathrm{H}_2\\mathrm{O}\\right]$. Use $N_r=6$ irreversible elementary reactions:\n1. $\\mathrm{H} + \\mathrm{O}_2 \\rightarrow \\mathrm{O} + \\mathrm{OH}$ with $(A_1,n_1,E_{a,1}) = \\left(2.65\\times10^{10},\\ -0.5,\\ 7.5\\times10^{4}\\right)$ in units $\\left(\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n2. $\\mathrm{O} + \\mathrm{H}_2 \\rightarrow \\mathrm{H} + \\mathrm{OH}$ with $(A_2,n_2,E_{a,2}) = \\left(1.80\\times10^{10},\\ 0.0,\\ 2.6\\times10^{4}\\right)$ in $\\left(\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n3. $\\mathrm{OH} + \\mathrm{H}_2 \\rightarrow \\mathrm{H} + \\mathrm{H}_2\\mathrm{O}$ with $(A_3,n_3,E_{a,3}) = \\left(2.10\\times10^{7},\\ 1.0,\\ 1.6\\times10^{4}\\right)$ in $\\left(\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n4. $\\mathrm{H} + \\mathrm{O}_2 + M \\rightarrow \\mathrm{HO}_2 + M$ with $(A_4,n_4,E_{a,4}) = \\left(1.475\\times10^{18},\\ -1.0,\\ 0.0\\right)$ in $\\left(\\mathrm{m}^6\\,\\mathrm{mol}^{-2}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n5. $\\mathrm{HO}_2 + \\mathrm{H} \\rightarrow 2\\,\\mathrm{OH}$ with $(A_5,n_5,E_{a,5}) = \\left(1.80\\times10^{10},\\ 0.0,\\ 0.0\\right)$ in $\\left(\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n6. $2\\,\\mathrm{HO}_2 \\rightarrow \\mathrm{H}_2\\mathrm{O}_2 + \\mathrm{O}_2$ with $(A_6,n_6,E_{a,6}) = \\left(1.00\\times10^{9},\\ 0.0,\\ 0.0\\right)$ in $\\left(\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1},\\ \\text{dimensionless},\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\right)$.\n\nFor each reaction, adopt the net stoichiometric coefficients $s_{i,n}$ consistent with the written equations, and for reaction $4$ treat $M$ as the total concentration $M=\\sum_{j=1}^8 C_j$ with no net stoichiometric change on any species due to $M$ itself.\n\nThermodynamic state. Take a uniform constant temperature $T = 1200\\ \\mathrm{K}$ and pressure $p = 1\\ \\mathrm{atm}$, with $1\\ \\mathrm{atm} = 101325\\ \\mathrm{Pa}$. The total molar concentration is $C_{\\mathrm{tot}} = p/(R T)$, where $R = 8.314462618\\ \\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$. Let the initial molar concentrations be determined from specified mole fractions $x_i$ via $C_i = x_i\\, C_{\\mathrm{tot}}$. Use $\\mathrm{mol}\\,\\mathrm{m}^{-3}$ for concentrations, and seconds for time-related rates.\n\nTask. Implement a program that:\n- Computes the analytic Jacobian $J(\\mathbf{C},T)$ by differentiating the species source terms $\\boldsymbol{\\omega}(\\mathbf{C},T)$ with respect to $\\mathbf{C}$.\n- Computes a finite-difference approximation $J^{\\mathrm{FD}}(\\mathbf{C},T)$ using per-variable central differences with a perturbation $h_j$ chosen adaptively as $h_j = \\sqrt{\\epsilon}\\,\\max(1,|C_j|)$, where $\\epsilon$ is machine precision for double-precision floating point. If $C_j - h_j < 0$, use a forward difference $J^{\\mathrm{FD}}_{:,j} \\approx \\left(\\boldsymbol{\\omega}(\\mathbf{C}+h_j \\mathbf{e}_j) - \\boldsymbol{\\omega}(\\mathbf{C})\\right)/h_j$; otherwise use central differences $J^{\\mathrm{FD}}_{:,j} \\approx \\left(\\boldsymbol{\\omega}(\\mathbf{C}+h_j \\mathbf{e}_j) - \\boldsymbol{\\omega}(\\mathbf{C}-h_j \\mathbf{e}_j)\\right)/(2 h_j)$, with $\\mathbf{e}_j$ the unit vector in coordinate $j$.\n- Compares the analytic and finite-difference Jacobians using the relative Frobenius norm error\n$$\nE = \\frac{\\left\\|J - J^{\\mathrm{FD}}\\right\\|_F}{\\left\\|J^{\\mathrm{FD}}\\right\\|_F},\n$$\nwith the convention that if $\\left\\|J^{\\mathrm{FD}}\\right\\|_F = 0$ and $\\left\\|J - J^{\\mathrm{FD}}\\right\\|_F = 0$, then $E=0$; if $\\left\\|J^{\\mathrm{FD}}\\right\\|_F = 0$ and $\\left\\|J - J^{\\mathrm{FD}}\\right\\|_F > 0$, then $E=+\\infty$.\n- Determines whether the sparsity pattern matches by thresholding both Jacobians at a small positive tolerance $\\tau$ and checking if $\\mathbb{I}\\{|J_{i j}| > \\tau\\} = \\mathbb{I}\\{|J^{\\mathrm{FD}}_{i j}| > \\tau\\}$ for all entries, where $\\mathbb{I}\\{\\cdot\\}$ denotes the indicator function. Use $\\tau = 10^{-20}$.\n\nTest suite. Evaluate three compositions at $T=1200\\ \\mathrm{K}$ and $p=1\\ \\mathrm{atm}$:\n- Case $1$ (stoichiometric with radical seeds): $x_{\\mathrm{H}_2} = 2/3 - 2\\times10^{-12}$, $x_{\\mathrm{O}_2} = 1/3 - 0\\times10^{-12}$, $x_{\\mathrm{H}} = 1\\times10^{-12}$, $x_{\\mathrm{OH}} = 1\\times10^{-12}$, all other $x_i = 0$. This keeps $\\sum_i x_i = 1$ by subtracting the radical fractions from $x_{\\mathrm{H}_2}$.\n- Case $2$ (lean, oxygen-rich with radical seed): $x_{\\mathrm{H}_2} = 0.2$, $x_{\\mathrm{O}_2} = 0.8 - 1\\times10^{-12}$, $x_{\\mathrm{H}} = 1\\times10^{-12}$, all other $x_i = 0$.\n- Case $3$ (radical-free stoichiometric): $x_{\\mathrm{H}_2} = 2/3$, $x_{\\mathrm{O}_2} = 1/3$, all other $x_i = 0$.\n\nOutput specification. For each case, compute the relative error $E$ (as a floating-point number) and the sparsity pattern match (as a boolean). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $\\left[E_1,\\ \\mathrm{match}_1,\\ E_2,\\ \\mathrm{match}_2,\\ E_3,\\ \\mathrm{match}_3\\right]$.",
            "solution": "The problem requires the implementation and comparison of an analytic Jacobian matrix and a finite-difference approximation for the source terms of a stiff chemical kinetics system. The system represents a reduced hydrogen-oxygen combustion mechanism. The problem is scientifically grounded, well-posed, and objective. The solution proceeds by first defining the chemical system, then deriving the expression for the analytic Jacobian, and finally implementing the numerical calculation and comparison for the specified test cases.\n\n**System Definition**\nThe system consists of $N=8$ species and $N_r=6$ irreversible reactions. The species are indexed from $0$ to $7$: $0:\\mathrm{H}_2$, $1:\\mathrm{O}_2$, $2:\\mathrm{H}$, $3:\\mathrm{O}$, $4:\\mathrm{OH}$, $5:\\mathrm{HO}_2$, $6:\\mathrm{H}_2\\mathrm{O}_2$, $7:\\mathrm{H}_2\\mathrm{O}$. The rates of progress, $r_n$, for $n=1,\\dots,6$ are given by the law of mass action:\n$r_1 = k_1(T) C_{\\mathrm{H}} C_{\\mathrm{O}_2}$\n$r_2 = k_2(T) C_{\\mathrm{O}} C_{\\mathrm{H}_2}$\n$r_3 = k_3(T) C_{\\mathrm{OH}} C_{\\mathrm{H}_2}$\n$r_4 = k_4(T) C_{\\mathrm{H}} C_{\\mathrm{O}_2} M$, where $M = \\sum_{l=0}^{7} C_l$\n$r_5 = k_5(T) C_{\\mathrm{HO}_2} C_{\\mathrm{H}}$\n$r_6 = k_6(T) C_{\\mathrm{HO}_2}^2$\nThe vector of species production rates, $\\boldsymbol{\\omega}$, is calculated as the matrix-vector product $\\boldsymbol{\\omega} = \\mathbf{s} \\cdot \\mathbf{r}$, where $\\mathbf{s}$ is the $N \\times N_r$ net stoichiometric coefficient matrix.\n\n**Analytic Jacobian Derivation**\nThe analytic Jacobian is the matrix of partial derivatives $J_{ij} = \\frac{\\partial \\omega_i}{\\partial C_j}$. Using the chain rule:\n$$\nJ_{i j} = \\frac{\\partial}{\\partial C_j} \\left( \\sum_{n=1}^{N_r} s_{i,n} r_n(\\mathbf{C}, T) \\right) = \\sum_{n=1}^{N_r} s_{i,n} \\frac{\\partial r_n}{\\partial C_j}\n$$\nThis relation indicates that the $j$-th column of the Jacobian, $\\mathbf{J}_{:,j}$, can be computed by first finding the vector of derivatives of each reaction rate with respect to $C_j$, $(\\partial \\mathbf{r}/\\partial C_j)$, and then multiplying by the stoichiometric matrix: $\\mathbf{J}_{:,j} = \\mathbf{s} \\cdot (\\partial \\mathbf{r}/\\partial C_j)$. The derivatives $\\partial r_n / \\partial C_j$ are derived for each reaction type (bimolecular, bimolecular self-reaction, and termolecular).\n\n**Implementation Code**\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the chemical kinetics Jacobian problem for the specified H2/O2 mechanism.\n    \"\"\"\n    #\n    # --- 1. System Constants and Definitions ---\n    #\n    R = 8.314462618  # J/mol-K\n    T = 1200.0  # K\n    P_ATM = 101325.0  # Pa/atm\n    P = 1.0 * P_ATM  # Pa\n    C_TOT = P / (R * T)  # Total molar concentration in mol/m^3\n\n    SPECIES = ['H2', 'O2', 'H', 'O', 'OH', 'HO2', 'H2O2', 'H2O']\n    N_SPECIES = len(SPECIES)\n    species_map = {name: i for i, name in enumerate(SPECIES)}\n\n    # Net stoichiometric coefficients s[i, n] for species i in reaction n\n    # Rows: H2, O2, H, O, OH, HO2, H2O2, H2O\n    # Cols: R1, R2, R3, R4, R5, R6\n    s_matrix = np.array([\n        [ 0, -1, -1,  0,  0,  0],  # H2\n        [-1,  0,  0, -1,  0,  1],  # O2\n        [-1,  1,  1, -1, -1,  0],  # H\n        [ 1, -1,  0,  0,  0,  0],  # O\n        [ 1,  1, -1,  0,  2,  0],  # OH\n        [ 0,  0,  0,  1, -1, -2],  # HO2\n        [ 0,  0,  0,  0,  0,  1],  # H2O2\n        [ 0,  0,  1,  0,  0,  0],  # H2O\n    ], dtype=float)\n\n    # Arrhenius parameters (A, n, Ea) for each reaction\n    # Units: A in [m^3/mol/s] or [m^6/mol^2/s], n is dimensionless, Ea in [J/mol]\n    arrhenius_params = np.array([\n        # R1: H + O2 -> O + OH\n        [2.65e10, -0.5, 7.5e4],\n        # R2: O + H2 -> H + OH\n        [1.80e10, 0.0, 2.6e4],\n        # R3: OH + H2 -> H + H2O\n        [2.10e7, 1.0, 1.6e4],\n        # R4: H + O2 + M -> HO2 + M\n        [1.475e18, -1.0, 0.0],\n        # R5: HO2 + H -> 2 OH\n        [1.80e10, 0.0, 0.0],\n        # R6: 2 HO2 -> H2O2 + O2\n        [1.00e9, 0.0, 0.0],\n    ])\n\n    k_f = arrhenius_params[:, 0] * (T ** arrhenius_params[:, 1]) * np.exp(-arrhenius_params[:, 2] / (R * T))\n\n    #\n    # --- 2. Core Calculation Functions ---\n    #\n    def get_omega(C):\n        \"\"\"Computes the species source terms omega for a given concentration vector C.\"\"\"\n        r = np.zeros(6)\n        \n        # Unpack concentrations for readability\n        C_H2, C_O2, C_H, C_O, C_OH, C_HO2, C_H2O2, C_H2O = C\n        \n        # Rates of progress for the 6 reactions\n        r[0] = k_f[0] * C_H * C_O2\n        r[1] = k_f[1] * C_O * C_H2\n        r[2] = k_f[2] * C_OH * C_H2\n        M = np.sum(C) # Third-body concentration\n        r[3] = k_f[3] * C_H * C_O2 * M\n        r[4] = k_f[4] * C_HO2 * C_H\n        r[5] = k_f[5] * C_HO2**2\n        \n        return s_matrix @ r\n\n    def get_analytic_jacobian(C):\n        \"\"\"Computes the analytic Jacobian matrix.\"\"\"\n        J = np.zeros((N_SPECIES, N_SPECIES))\n        \n        # Unpack concentrations\n        C_H2, C_O2, C_H, C_O, C_OH, C_HO2, C_H2O2, C_H2O = C\n        idx_H2, idx_O2, idx_H, idx_O, idx_OH, idx_HO2, idx_H2O2, idx_H2O = range(8)\n        \n        M = np.sum(C)\n        \n        # Loop over columns j of the Jacobian (derivative w.r.t. C_j)\n        for j in range(N_SPECIES):\n            dr_dCj = np.zeros(6) # Vector of d(r_n)/d(C_j) for n=1..6\n            \n            # R1: H + O2 -> O + OH\n            if j == idx_H: dr_dCj[0] = k_f[0] * C_O2\n            elif j == idx_O2: dr_dCj[0] = k_f[0] * C_H\n            \n            # R2: O + H2 -> H + OH\n            if j == idx_O: dr_dCj[1] = k_f[1] * C_H2\n            elif j == idx_H2: dr_dCj[1] = k_f[1] * C_O\n                \n            # R3: OH + H2 -> H + H2O\n            if j == idx_OH: dr_dCj[2] = k_f[2] * C_H2\n            elif j == idx_H2: dr_dCj[2] = k_f[2] * C_OH\n            \n            # R4: H + O2 + M -> HO2 + M\n            dr_dCj[3] = k_f[3] * C_H * C_O2 # dM/dCj = 1 term\n            if j == idx_H: dr_dCj[3] += k_f[3] * C_O2 * M\n            elif j == idx_O2: dr_dCj[3] += k_f[3] * C_H * M\n\n            # R5: HO2 + H -> 2 OH\n            if j == idx_HO2: dr_dCj[4] = k_f[4] * C_H\n            elif j == idx_H: dr_dCj[4] = k_f[4] * C_HO2\n            \n            # R6: 2 HO2 -> H2O2 + O2\n            if j == idx_HO2: dr_dCj[5] = 2.0 * k_f[5] * C_HO2\n            \n            J[:, j] = s_matrix @ dr_dCj\n            \n        return J\n\n    def get_fd_jacobian(C):\n        \"\"\"Computes the Jacobian matrix using finite differences.\"\"\"\n        J_fd = np.zeros((N_SPECIES, N_SPECIES))\n        eps = np.finfo(float).eps\n        omega_0 = get_omega(C)\n\n        for j in range(N_SPECIES):\n            h = np.sqrt(eps) * max(1.0, abs(C[j]))\n            \n            if C[j] - h < 0: # Use forward difference\n                C_plus = C.copy()\n                C_plus[j] += h\n                omega_plus = get_omega(C_plus)\n                J_fd[:, j] = (omega_plus - omega_0) / h\n            else: # Use central difference\n                C_plus = C.copy()\n                C_plus[j] += h\n                C_minus = C.copy()\n                C_minus[j] -= h\n                \n                omega_plus = get_omega(C_plus)\n                omega_minus = get_omega(C_minus)\n                J_fd[:, j] = (omega_plus - omega_minus) / (2.0 * h)\n        return J_fd\n\n    #\n    # --- 3. Test Cases ---\n    #\n    test_cases = [\n        # Case 1: Stoichiometric with radical seeds\n        {\n            'H2': 2./3. - 2e-12, 'O2': 1./3., 'H': 1e-12, 'OH': 1e-12\n        },\n        # Case 2: Lean with radical seed\n        {\n            'H2': 0.2, 'O2': 0.8 - 1e-12, 'H': 1e-12\n        },\n        # Case 3: Radical-free stoichiometric\n        {\n            'H2': 2./3., 'O2': 1./3.\n        },\n    ]\n\n    results = []\n    for case_mole_fracs in test_cases:\n        x = np.zeros(N_SPECIES)\n        for name, val in case_mole_fracs.items():\n            x[species_map[name]] = val\n        C = x * C_TOT\n        \n        # Compute Jacobians\n        J_analytic = get_analytic_jacobian(C)\n        J_fd = get_fd_jacobian(C)\n        \n        # Compare Jacobians\n        norm_J_fd = np.linalg.norm(J_fd, 'fro')\n        norm_diff = np.linalg.norm(J_analytic - J_fd, 'fro')\n        \n        if norm_J_fd == 0.0:\n            error = 0.0 if norm_diff == 0.0 else np.inf\n        else:\n            error = norm_diff / norm_J_fd\n            \n        # Compare sparsity patterns\n        tau = 1e-20\n        sparsity_J = np.abs(J_analytic) > tau\n        sparsity_J_fd = np.abs(J_fd) > tau\n        sparsity_match = np.all(sparsity_J == sparsity_J_fd)\n        \n        results.extend([error, \"True\" if sparsity_match else \"False\"])\n\n    #\n    # --- 4. Final Output ---\n    #\n    return f\"[{','.join(map(str, results))}]\"\n\nprint(solve())\n```",
            "answer": "[1.2723707886401666e-08,True,3.029813083015494e-09,True,0.0,True]"
        },
        {
            "introduction": "An efficient implicit solver must not only be stable but also computationally fast, which raises a critical question: how often should the expensive Jacobian matrix be re-evaluated and factorized? This practice delves into the performance trade-offs among different Newton-Raphson variants, from the robust Full Newton to the cheaper Modified Newton and Chord methods. By implementing and comparing these strategies on a system with rapid temperature changes, you will quantify the balance between the cost of linear algebra and the speed of nonlinear convergence, a central challenge in designing high-performance kinetic solvers .",
            "id": "4031740",
            "problem": "Consider a homogeneous, constant-pressure, spatially uniform reacting mixture described by mass-action kinetics with Arrhenius temperature dependence. Let $y_A$, $y_B$, and $y_C$ denote molar concentrations in $\\mathrm{mol}\\,\\mathrm{m}^{-3}$. The reaction mechanism is a bimolecular conversion $A + B \\rightarrow C$ and a unimolecular conversion $B \\rightarrow C$. The ordinary differential equations (ODEs) for species are, using the Ideal Gas constant $R$ in $\\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$,\n$$\n\\frac{dy_A}{dt} = -k_1(T)\\,y_A\\,y_B,\\quad\n\\frac{dy_B}{dt} = -k_1(T)\\,y_A\\,y_B - k_2(T)\\,y_B,\\quad\n\\frac{dy_C}{dt} = k_1(T)\\,y_A\\,y_B + k_2(T)\\,y_B,\n$$\nwhere the Arrhenius rate coefficients are $k_1(T) = A_1\\,\\exp\\!\\left(-\\frac{E_1}{R\\,T}\\right)$ with units $\\mathrm{m}^3\\,\\mathrm{mol}^{-1}\\,\\mathrm{s}^{-1}$ and $k_2(T) = A_2\\,\\exp\\!\\left(-\\frac{E_2}{R\\,T}\\right)$ with units $\\mathrm{s}^{-1}$. Assume an externally imposed step change in temperature from $T_n$ to $T_{n+1}$ over a single implicit time step of size $h$ (in $\\mathrm{s}$). This external change models rapid thermal transients (e.g., due to compression or heat release) while focusing the comparison on the nonlinear algebraic solve.\n\nWe consider the backward Euler discretization for one time step,\n$$\n\\boldsymbol{F}(\\boldsymbol{y}) \\equiv \\boldsymbol{y} - \\boldsymbol{y}_n - h\\,\\boldsymbol{\\omega}(\\boldsymbol{y},T_{n+1}) = \\boldsymbol{0},\n$$\nwhere $\\boldsymbol{y} = [y_A, y_B, y_C]^T$ and $\\boldsymbol{\\omega}(\\boldsymbol{y},T)$ is the reaction source term vector implied by the ODEs above.\n\nThe nonlinear system is to be solved using three Newton-Raphson variants:\n- Full Newton: recompute the Jacobian $\\boldsymbol{J}(\\boldsymbol{y}) = \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{y}}$ at every nonlinear iteration at $T_{n+1}$; factorize it each time.\n- Modified Newton (lagged Jacobian): compute and factorize $\\boldsymbol{J}$ only once per time step at the initial iterate (use $T_{n+1}$) and reuse its factorization for all subsequent iterations of that step.\n- Chord method (frozen Jacobian across time steps): reuse the Jacobian factorization from the previous time step (evaluate at $\\boldsymbol{y}_n$ and $T_n$) for all iterations of the current step; do not refactor during the current step.\n\nYour tasks:\n1. Starting from the mass-action ODEs and the backward Euler discretization, derive the residual $\\boldsymbol{F}(\\boldsymbol{y})$ and the Jacobian structure needed for Newton updates. Justify why the system is stiff and why $\\boldsymbol{J}$ changes rapidly when $T$ changes.\n2. Implement a robust Newton solver for each variant (Full Newton, Modified Newton, and Chord), with backtracking line search and positivity preservation for concentrations. Use a convergence tolerance on the two-norm of the residual $\\|\\boldsymbol{F}(\\boldsymbol{y})\\|_2 \\le \\varepsilon$ with $\\varepsilon = 10^{-10}$ and a maximum of $50$ iterations per step. Treat any method that does not satisfy the tolerance within the iteration cap as a failure, and report $-1$ iterations for that method.\n3. Quantify, for a single implicit time step, the trade-off between fewer matrix factorizations and slower convergence by reporting, for each method, the total number of nonlinear iterations used and the number of $\\mathrm{LU}$ factorizations performed during the step. A factorization is counted each time a new Jacobian is factorized; reusing a previously factorized Jacobian does not add to the count.\n\nUnits to use:\n- Concentrations in $\\mathrm{mol}\\,\\mathrm{m}^{-3}$,\n- Time in $\\mathrm{s}$,\n- Temperature in $\\mathrm{K}$,\n- Activation energies in $\\mathrm{J}\\,\\mathrm{mol}^{-1}$.\n\nConstants and parameters:\n- Gas constant $R = 8.314\\,\\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$,\n- Reaction pre-exponential factors and activation energies $(A_1, E_1)$, $(A_2, E_2)$ are provided per test.\n\nInitial state:\n- $\\boldsymbol{y}_n = [y_{A,n}, y_{B,n}, y_{C,n}]^T$ is provided per test.\n\nTest suite:\nEach test case is a tuple $(A_1, E_1, A_2, E_2, T_n, \\Delta T, h, y_{A,n}, y_{B,n}, y_{C,n})$ where $T_{n+1} = T_n + \\Delta T$. Use the following three cases to explore different regimes of temperature change and time step size:\n- Case 1 (small temperature change, mild stiffness): $(1.0\\times 10^6, 8.0\\times 10^4, 1.0\\times 10^3, 1.1\\times 10^5, 1100, 10, 1.0\\times 10^{-4}, 2.0, 1.0, 0.0)$.\n- Case 2 (moderate temperature change, increased stiffness): $(1.0\\times 10^6, 8.0\\times 10^4, 1.0\\times 10^3, 1.1\\times 10^5, 1100, 150, 3.0\\times 10^{-4}, 2.0, 1.0, 0.0)$.\n- Case 3 (rapid temperature change, strong stiffness): $(1.0\\times 10^6, 8.0\\times 10^4, 1.0\\times 10^3, 1.1\\times 10^5, 1100, 500, 1.0\\times 10^{-3}, 2.0, 1.0, 0.0)$.\n\nFinal output specification:\n- For each test case, your program must output a list with six entries: $[i_{\\mathrm{full}}, i_{\\mathrm{mod}}, i_{\\mathrm{chord}}, f_{\\mathrm{full}}, f_{\\mathrm{mod}}, f_{\\mathrm{chord}}]$, where $i_{\\cdot}$ is the number of nonlinear iterations used by the method and $f_{\\cdot}$ is the number of $\\mathrm{LU}$ factorizations during the step as defined above. If a method fails to converge within the cap, report $i_{\\cdot} = -1$ and count factorizations according to its policy during the attempted iterations.\n- Your program should produce a single line of output containing the results for all three test cases as a comma-separated list enclosed in square brackets, where each element is itself the six-entry list for a test case, for example, $[[\\dots],[\\dots],[\\dots]]$.",
            "solution": "This problem compares different Newton-Raphson method variants for solving the nonlinear algebraic equations arising from an implicit time integration of a stiff ODE system. The problem is scientifically sound, well-posed, and objective.\n\n### Part 1: Derivations and Justification\n\nLet the state vector be $\\boldsymbol{y} = [y_A, y_B, y_C]^T$. The vector of reaction source terms, $\\boldsymbol{\\omega}(\\boldsymbol{y}, T)$, is:\n$$\n\\boldsymbol{\\omega}(\\boldsymbol{y}, T) = \\begin{pmatrix} \\omega_A \\\\ \\omega_B \\\\ \\omega_C \\end{pmatrix} = \\begin{pmatrix} -k_1(T)\\,y_A\\,y_B \\\\ -k_1(T)\\,y_A\\,y_B - k_2(T)\\,y_B \\\\ k_1(T)\\,y_A\\,y_B + k_2(T)\\,y_B \\end{pmatrix}\n$$\nThe backward Euler method discretizes the ODE system $\\frac{d\\boldsymbol{y}}{dt} = \\boldsymbol{\\omega}(\\boldsymbol{y}, T)$ as $\\frac{\\boldsymbol{y}_{n+1} - \\boldsymbol{y}_n}{h} = \\boldsymbol{\\omega}(\\boldsymbol{y}_{n+1}, T_{n+1})$. To solve for the unknown state $\\boldsymbol{y}_{n+1}$, we define a nonlinear residual function $\\boldsymbol{F}(\\boldsymbol{y})$ where $\\boldsymbol{y}$ stands for $\\boldsymbol{y}_{n+1}$:\n$$\n\\boldsymbol{F}(\\boldsymbol{y}) \\equiv \\boldsymbol{y} - \\boldsymbol{y}_n - h\\,\\boldsymbol{\\omega}(\\boldsymbol{y}, T_{n+1}) = \\boldsymbol{0}\n$$\nThe Newton-Raphson method for solving $\\boldsymbol{F}(\\boldsymbol{y}) = \\boldsymbol{0}$ requires the Jacobian matrix of the residual $\\boldsymbol{F}$ with respect to $\\boldsymbol{y}$, defined as $\\boldsymbol{J}(\\boldsymbol{y}) = \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{y}} = \\boldsymbol{I} - h \\frac{\\partial \\boldsymbol{\\omega}}{\\partial \\boldsymbol{y}}$, where $\\boldsymbol{I}$ is the identity matrix. The Jacobian of the source term, $\\boldsymbol{J}_{\\omega} = \\frac{\\partial \\boldsymbol{\\omega}}{\\partial \\boldsymbol{y}}$, evaluated at some state $(\\boldsymbol{y}, T)$, is:\n$$\n\\boldsymbol{J}_{\\omega}(\\boldsymbol{y}, T) =\n\\begin{pmatrix}\n-k_1(T)\\,y_B & -k_1(T)\\,y_A & 0 \\\\\n-k_1(T)\\,y_B & -k_1(T)\\,y_A - k_2(T) & 0 \\\\\nk_1(T)\\,y_B & k_1(T)\\,y_A + k_2(T) & 0\n\\end{pmatrix}\n$$\nThe Jacobian of the residual function, $\\boldsymbol{J}(\\boldsymbol{y})$, is therefore:\n$$\n\\boldsymbol{J}(\\boldsymbol{y}) =\n\\begin{pmatrix}\n1 + h\\,k_1(T_{n+1})\\,y_B & h\\,k_1(T_{n+1})\\,y_A & 0 \\\\\nh\\,k_1(T_{n+1})\\,y_B & 1 + h\\,k_1(T_{n+1})\\,y_A + h\\,k_2(T_{n+1}) & 0 \\\\\n-h\\,k_1(T_{n+1})\\,y_B & -(h\\,k_1(T_{n+1})\\,y_A + h\\,k_2(T_{n+1})) & 1\n\\end{pmatrix}\n$$\nThe system is stiff because the timescales, related to the eigenvalues of $\\boldsymbol{J}_{\\omega}$, can be widely separated, especially if $k_1(T)$ and $k_2(T)$ have very different magnitudes. The Jacobian $\\boldsymbol{J}$ is highly sensitive to temperature because the rate constants $k_1$ and $k_2$ depend exponentially on temperature via the Arrhenius law, especially for large activation energies. A large temperature change from $T_n$ to $T_{n+1}$ will cause a large change in the Jacobian, making a frozen Jacobian from the previous time step (Chord method) a poor approximation and thus hindering convergence.\n\n### Part 2 & 3: Implementation and Quantification\n\nThe following Python code implements the three Newton variants (Full, Modified, and Chord) with a robust backtracking line search. It then runs the three specified test cases and reports the number of iterations and LU factorizations for each method as required.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import lu_factor, lu_solve\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for comparing Newton-Raphson variants.\n    \"\"\"\n    # Universal constant\n    R = 8.314  # J mol^-1 K^-1\n\n    # Test cases: (A1, E1, A2, E2, Tn, dT, h, yA_n, yB_n, yC_n)\n    test_cases = [\n        # Case 1: Small dT, mild stiffness\n        (1.0e6, 8.0e4, 1.0e3, 1.1e5, 1100.0, 10.0, 1.0e-4, 2.0, 1.0, 0.0),\n        # Case 2: Moderate dT, increased stiffness\n        (1.0e6, 8.0e4, 1.0e3, 1.1e5, 1100.0, 150.0, 3.0e-4, 2.0, 1.0, 0.0),\n        # Case 3: Rapid dT, strong stiffness\n        (1.0e6, 8.0e4, 1.0e3, 1.1e5, 1100.0, 500.0, 1.0e-3, 2.0, 1.0, 0.0),\n    ]\n\n    all_results = []\n    for i, case in enumerate(test_cases):\n        case_results = []\n        \n        # Run for Full Newton, Modified Newton, Chord\n        methods = ['full', 'modified', 'chord']\n        iter_results = []\n        fact_results = []\n\n        for method in methods:\n            iters, facts = newton_solver(method, case, R)\n            iter_results.append(iters)\n            fact_results.append(facts)\n        \n        case_results.extend(iter_results)\n        case_results.extend(fact_results)\n        all_results.append(case_results)\n\n    # Format output as specified\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef calculate_rates(T, kin_params, R):\n    \"\"\"Calculates Arrhenius rate coefficients k1 and k2.\"\"\"\n    A1, E1, A2, E2 = kin_params\n    k1 = A1 * np.exp(-E1 / (R * T))\n    k2 = A2 * np.exp(-E2 / (R * T))\n    return k1, k2\n\ndef calculate_residual(y, y_n, h, k1_np1, k2_np1):\n    \"\"\"Calculates the residual vector F(y) for the backward Euler step.\"\"\"\n    yA, yB, _ = y\n    \n    omega_A = -k1_np1 * yA * yB\n    omega_B = -k1_np1 * yA * yB - k2_np1 * yB\n    omega_C = -omega_A - k2_np1 * yB\n    \n    F = np.zeros(3)\n    F[0] = y[0] - y_n[0] - h * omega_A\n    F[1] = y[1] - y_n[1] - h * omega_B\n    F[2] = y[2] - y_n[2] - h * omega_C\n    return F\n\ndef calculate_jacobian(y, h, k1, k2):\n    \"\"\"Calculates the Jacobian matrix J = dF/dy.\"\"\"\n    yA, yB, _ = y\n    \n    J = np.zeros((3, 3))\n    \n    J[0, 0] = 1.0 + h * k1 * yB\n    J[0, 1] = h * k1 * yA\n    \n    J[1, 0] = h * k1 * yB\n    J[1, 1] = 1.0 + h * k1 * yA + h * k2\n    \n    J[2, 0] = -h * k1 * yB\n    J[2, 1] = -(h * k1 * yA + h * k2)\n    J[2, 2] = 1.0\n    \n    return J\n\ndef newton_solver(method, case_params, R):\n    \"\"\"\n    Solves the nonlinear system for one time step using a specified Newton variant.\n    \"\"\"\n    A1, E1, A2, E2, T_n, dT, h, yA_n, yB_n, yC_n = case_params\n    kin_params = (A1, E1, A2, E2)\n    \n    y_n = np.array([yA_n, yB_n, yC_n])\n    T_np1 = T_n + dT\n    \n    max_iter = 50\n    tol = 1.0e-10\n    min_alpha = 1.0e-8\n\n    factorizations = 0\n    y_k = y_n.copy()\n    \n    k1_np1, k2_np1 = calculate_rates(T_np1, kin_params, R)\n    \n    lu_piv = None\n    \n    if method == 'chord':\n        k1_n, k2_n = calculate_rates(T_n, kin_params, R)\n        J = calculate_jacobian(y_n, h, k1_n, k2_n)\n        lu_piv = lu_factor(J)\n        factorizations = 0\n    elif method == 'modified':\n        J = calculate_jacobian(y_k, h, k1_np1, k2_np1)\n        lu_piv = lu_factor(J)\n        factorizations = 1\n    \n    for i in range(1, max_iter + 1):\n        F_k = calculate_residual(y_k, y_n, h, k1_np1, k2_np1)\n        norm_F_k = np.linalg.norm(F_k)\n        \n        if norm_F_k = tol:\n            return i - 1, factorizations\n        \n        if method == 'full':\n            J = calculate_jacobian(y_k, h, k1_np1, k2_np1)\n            lu_piv = lu_factor(J)\n            factorizations += 1\n        \n        try:\n            delta_y = lu_solve(lu_piv, -F_k, check_finite=False)\n        except np.linalg.LinAlgError:\n            return -1, factorizations\n\n        alpha = 1.0\n        while True:\n            y_trial = y_k + alpha * delta_y\n            if np.all(y_trial >= 0):\n                break\n            alpha /= 2.0\n            if alpha  min_alpha: return -1, factorizations\n        \n        while True:\n            F_trial = calculate_residual(y_trial, y_n, h, k1_np1, k2_np1)\n            if np.linalg.norm(F_trial)  norm_F_k:\n                break\n            alpha /= 2.0\n            if alpha  min_alpha: break\n            y_trial = y_k + alpha * delta_y\n\n        y_k = y_trial\n    \n    return -1, factorizations\n\nif __name__ == '__main__':\n    solve()\n```",
            "answer": "[[4,5,15,4,1,0],[5,9,-1,5,1,0],[6,-1,-1,6,1,0]]"
        }
    ]
}