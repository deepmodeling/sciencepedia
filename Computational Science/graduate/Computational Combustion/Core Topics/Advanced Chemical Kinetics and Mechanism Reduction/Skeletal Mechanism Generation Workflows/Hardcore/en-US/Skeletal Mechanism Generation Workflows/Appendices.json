{
    "hands_on_practices": [
        {
            "introduction": "The Quasi-Steady-State Assumption (QSSA) is a foundational technique in chemical kinetics reduction, allowing us to simplify complex mechanisms by eliminating the differential equations for highly reactive, short-lived species. This hands-on practice  guides you through the entire process, from identifying a candidate radical based on timescale analysis to deriving the reduced model and quantifying the error in a key combustion metric, the ignition delay time. By completing this exercise, you will gain a practical understanding of how QSSA is justified, implemented, and validated.",
            "id": "4063463",
            "problem": "You are given an elementary chain-branching combustion mechanism for a spatially homogeneous, constant-pressure, adiabatic reactor. The species set is $\\{A,B,R,P\\}$, where $A$ is a fuel, $B$ is an oxidizer, $R$ is a radical, and $P$ is a stable product. The mechanism consists of the following elementary reactions under the law of mass action:\n- $A + B \\xrightarrow{k_1(T)} R$ (initiation),\n- $R + B \\xrightarrow{k_2(T)} 2R$ (branching),\n- $R + R \\xrightarrow{k_3(T)} P$ (termination),\n- $A + R \\xrightarrow{k_4(T)} P + R$ (propagation).\n\nHere $T$ is the temperature of the mixture, and $k_i(T)$ are temperature-dependent rate constants given by Arrhenius-type expressions $k_i(T) = A_i \\exp\\left(-\\dfrac{E_i}{R_u T}\\right)$ for $i \\in \\{1,2,4\\}$, and $k_3(T) = A_3$ with negligible activation energy. The universal gas constant is $R_u = 8.314 \\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$. Concentrations are denoted by $[A] = a$, $[B] = b$, $[R] = r$, and $[P] = p$ with units $\\text{mol}\\,\\text{m}^{-3}$. Reaction heats per mole are $Q_1,Q_2,Q_3,Q_4$ for the respective reactions, with units $\\text{J}\\,\\text{mol}^{-1}$. The thermal parameters are density $\\rho$ in $\\text{kg}\\,\\text{m}^{-3}$ and constant specific heat at constant pressure $C_p$ in $\\text{J}\\,\\text{kg}^{-1}\\,\\text{K}^{-1}$.\n\nStarting from the fundamental laws of chemical kinetics (mass action) and energy conservation under adiabatic, constant-pressure conditions, you must:\n1. Identify candidate radicals for Quasi-Steady-State (QSS) based on a local timescale separation criterion at the initial state. For a species $i$ with concentration $c_i$, define the characteristic timescale $\\tau_i = \\dfrac{c_i}{|dc_i/dt|}$ computed from the full ordinary differential equation system at the initial time. Declare $R$ a QSS radical if the ratio $\\tau_R/\\tau_A$ is less than a given threshold parameter $\\theta$.\n2. Derive the reduced ordinary differential equation (ODE) system under the QSS assumption for $R$ by eliminating $dr/dt$ and replacing $r$ with an algebraic function $r_{\\mathrm{QSS}}(a,b,T)$ that enforces $dr/dt \\approx 0$.\n3. Compute the ignition delay time $\\tau_{\\mathrm{ign}}$ defined as the first time at which the temperature $T(t)$ crosses the threshold $T_{\\mathrm{ign}} = T_0 + \\Delta T$, where $T_0$ is the initial temperature and $\\Delta T$ is a specified temperature rise. If no crossing occurs before a specified final time $t_{\\mathrm{end}}$, set $\\tau_{\\mathrm{ign}} = t_{\\mathrm{end}}$.\n4. Estimate the absolute error in ignition delay between the full and reduced models, i.e., compute $|\\tau_{\\mathrm{ign}}^{\\mathrm{full}} - \\tau_{\\mathrm{ign}}^{\\mathrm{red}}|$, expressed in seconds.\n\nAll variables and constants must adhere to the following units: $a,b,r,p$ in $\\text{mol}\\,\\text{m}^{-3}$, $T$ in $\\text{K}$, time in $\\text{s}$, $k_1,k_2,k_4$ in $\\text{m}^3\\,\\text{mol}^{-1}\\,\\text{s}^{-1}$, $k_3$ in $\\text{m}^3\\,\\text{mol}^{-1}\\,\\text{s}^{-1}$, $Q_i$ in $\\text{J}\\,\\text{mol}^{-1}$, $\\rho$ in $\\text{kg}\\,\\text{m}^{-3}$, $C_p$ in $\\text{J}\\,\\text{kg}^{-1}\\,\\text{K}^{-1}$. Answer ignition delay errors in seconds.\n\nYou must implement a complete program that:\n- Integrates the full ODE system for $(a,b,r,T)$ under mass action kinetics and the energy equation,\n- Uses the QSS criterion to decide whether to reduce the system by eliminating $r$ via $dr/dt \\approx 0$; if QSS is not selected for $R$, the reduced system is identical to the full system,\n- Computes ignition delays for both models and returns the absolute errors.\n\nUse the following fixed parameter values for kinetics and thermodynamics:\n- $A_1 = 5\\times 10^7$, $E_1 = 7.0\\times 10^4 \\,\\text{J}\\,\\text{mol}^{-1}$,\n- $A_2 = 2\\times 10^8$, $E_2 = 6.0\\times 10^4 \\,\\text{J}\\,\\text{mol}^{-1}$,\n- $A_3 = 1\\times 10^4$,\n- $A_4 = 1\\times 10^7$, $E_4 = 5.0\\times 10^4 \\,\\text{J}\\,\\text{mol}^{-1}$,\n- $Q_1 = 0$, $Q_2 = 1.0\\times 10^5 \\,\\text{J}\\,\\text{mol}^{-1}$, $Q_3 = 0$, $Q_4 = 2.0\\times 10^4 \\,\\text{J}\\,\\text{mol}^{-1}$,\n- $\\rho = 1.0 \\,\\text{kg}\\,\\text{m}^{-3}$, $C_p = 1000 \\,\\text{J}\\,\\text{kg}^{-1}\\,\\text{K}^{-1}$,\n- $R_u = 8.314 \\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$.\n\nYour program must apply the following test suite of initial conditions and control parameters $(a_0,b_0,r_0,T_0,\\Delta T,\\theta,t_{\\mathrm{end}})$:\n- Case 1 (baseline chain-branching ignition): $(1.0, 2.0, 1.0\\times 10^{-9}, 1000.0, 50.0, 0.2, 0.01)$,\n- Case 2 (borderline QSS with elevated initial radical): $(1.0, 0.8, 5.0\\times 10^{-2}, 1000.0, 50.0, 0.05, 0.02)$,\n- Case 3 (low-temperature, slow kinetics): $(0.5, 0.5, 1.0\\times 10^{-9}, 800.0, 50.0, 0.2, 0.05)$.\n\nYour program should produce a single line of output containing the absolute ignition delay errors for the three cases as a comma-separated list enclosed in square brackets (e.g., \"[$e_1,e_2,e_3$]\"), where each $e_i$ is a floating-point number in seconds. The numerical output must have units of seconds and must be computable deterministically from the specified inputs without any external data.",
            "solution": "The problem requires the analysis of a simplified chain-branching combustion mechanism and a comparison between a full kinetic model and a reduced model derived under the Quasi-Steady-State Assumption (QSSA). The analysis involves deriving the governing ordinary differential equations (ODEs), applying a timescale-based criterion to justify the QSSA, deriving the reduced model, and numerically calculating the ignition delay time for both models to quantify the error introduced by the reduction.\n\n### 1. Full Kinetic Model\n\nThe reaction mechanism involves four species, Fuel ($A$), Oxidizer ($B$), Radical ($R$), and Product ($P$), governed by four elementary reactions:\n1.  $A + B \\xrightarrow{k_1(T)} R$\n2.  $R + B \\xrightarrow{k_2(T)} 2R$\n3.  $R + R \\xrightarrow{k_3(T)} P$\n4.  $A + R \\xrightarrow{k_4(T)} P + R$\n\nThe rate constants $k_i(T)$ are given by the Arrhenius-type expressions $k_i(T) = A_i \\exp(-E_i / (R_u T))$ for $i \\in \\{1, 2, 4\\}$ and $k_3(T) = A_3$. The net rates of progress for these reactions, denoted by $\\omega_i$, are given by the law of mass action, with concentrations $[A]=a, [B]=b, [R]=r$:\n$$ \\omega_1 = k_1(T) a b $$\n$$ \\omega_2 = k_2(T) r b $$\n$$ \\omega_3 = k_3(T) r^2 $$\n$$ \\omega_4 = k_4(T) a r $$\n\nThe temporal evolution of the species concentrations in a spatially homogeneous system is described by the following set of ODEs:\n$$ \\frac{da}{dt} = -\\omega_1 - \\omega_4 = -k_1(T)ab - k_4(T)ar $$\n$$ \\frac{db}{dt} = -\\omega_1 - \\omega_2 = -k_1(T)ab - k_2(T)rb $$\n$$ \\frac{dr}{dt} = +\\omega_1 + \\omega_2 - 2\\omega_3 = k_1(T)ab + k_2(T)rb - 2k_3(T)r^2 $$\nNote that reaction $4$ is a propagation step where one radical $R$ is consumed and one is produced, resulting in no net change in the concentration of $R$.\n\nFor a constant-pressure, adiabatic reactor, the energy conservation equation is:\n$$ \\rho C_p \\frac{dT}{dt} = \\sum_{i=1}^{4} Q_i \\omega_i $$\nGiven that $Q_1 = 0$ and $Q_3 = 0$, this simplifies to:\n$$ \\frac{dT}{dt} = \\frac{1}{\\rho C_p} (Q_2 \\omega_2 + Q_4 \\omega_4) = \\frac{r}{\\rho C_p} \\left( Q_2 k_2(T) b + Q_4 k_4(T) a \\right) $$\n\nThese four coupled, non-linear ODEs for the state vector $\\mathbf{y}(t) = [a(t), b(t), r(t), T(t)]^T$ constitute the full kinetic model.\n\n### 2. Quasi-Steady-State (QSS) Analysis\n\nThe QSSA is applicable to highly reactive intermediate species (radicals) whose characteristic reaction timescales are much shorter than those of the major species. We assess this condition at the initial state ($t=0$). The characteristic timescale for a species $i$ with concentration $c_i$ is defined as $\\tau_i = \\dfrac{c_i}{|dc_i/dt|}$.\n\nAt $t=0$, with initial conditions $(a_0, b_0, r_0, T_0)$, we compute the initial rates:\n$$ \\left(\\frac{da}{dt}\\right)_0 = -k_1(T_0)a_0b_0 - k_4(T_0)a_0r_0 $$\n$$ \\left(\\frac{dr}{dt}\\right)_0 = k_1(T_0)a_0b_0 + k_2(T_0)b_0r_0 - 2k_3(T_0)r_0^2 $$\n\nThe initial timescales for the fuel $A$ and radical $R$ are:\n$$ \\tau_A = \\frac{a_0}{\\left|\\left(\\frac{da}{dt}\\right)_0\\right|} = \\frac{a_0}{k_1(T_0)a_0b_0 + k_4(T_0)a_0r_0} = \\frac{1}{k_1(T_0)b_0 + k_4(T_0)r_0} $$\n$$ \\tau_R = \\frac{r_0}{\\left|\\left(\\frac{dr}{dt}\\right)_0\\right|} = \\frac{r_0}{\\left| k_1(T_0)a_0b_0 + k_2(T_0)b_0r_0 - 2k_3(T_0)r_0^2 \\right|} $$\n\nThe QSS assumption is deemed valid for the radical $R$ if the ratio of its timescale to that of the fuel $A$ is smaller than a prescribed threshold $\\theta$:\n$$ \\frac{\\tau_R}{\\tau_A}  \\theta $$\n\n### 3. Reduced Kinetic Model (QSS Model)\n\nIf the QSS criterion is met, we can simplify the system by assuming the net production rate of the radical $R$ is approximately zero, i.e., $dr/dt \\approx 0$. This converts the differential equation for $r$ into an algebraic equation:\n$$ k_1(T)ab + k_2(T)rb - 2k_3(T)r^2 = 0 $$\nRearranging gives a quadratic equation for the QSS concentration of the radical, $r_{\\mathrm{QSS}}$:\n$$ 2k_3(T)r^2 - k_2(T)br - k_1(T)ab = 0 $$\nSolving for $r$ using the quadratic formula and selecting the physically meaningful positive root yields:\n$$ r_{\\mathrm{QSS}}(a,b,T) = \\frac{k_2(T)b + \\sqrt{\\left(k_2(T)b\\right)^2 + 8k_1(T)k_3(T)ab}}{4k_3(T)} $$\n\nThe full ODE system is then reduced to a system of three ODEs for the state vector $\\mathbf{y}_{\\mathrm{red}}(t) = [a(t), b(t), T(t)]^T$. The concentration of $R$ is no longer a state variable but is diagnosed at each time step using the algebraic expression for $r_{\\mathrm{QSS}}$:\n$$ \\frac{da}{dt} = -k_1(T)ab - k_4(T)a \\cdot r_{\\mathrm{QSS}}(a,b,T) $$\n$$ \\frac{db}{dt} = -k_1(T)ab - k_2(T)b \\cdot r_{\\mathrm{QSS}}(a,b,T) $$\n$$ \\frac{dT}{dt} = \\frac{r_{\\mathrm{QSS}}(a,b,T)}{\\rho C_p} \\left( Q_2 k_2(T) b + Q_4 k_4(T) a \\right) $$\nThis reduced system is integrated with initial conditions $(a_0, b_0, T_0)$.\n\n### 4. Numerical Solution and Ignition Delay Calculation\n\nThe ignition delay time, $\\tau_{\\mathrm{ign}}$, is defined as the first time $t$ at which the temperature reaches a threshold $T_{\\mathrm{ign}} = T_0 + \\Delta T$. We solve the initial value problems for both the full and reduced systems using a numerical ODE solver, specifically `scipy.integrate.solve_ivp`. This function's event detection capability is used to accurately determine the moment of threshold crossing. An event is defined by the condition $T(t) - T_{\\mathrm{ign}} = 0$. If the event does not occur before the specified end time $t_{\\mathrm{end}}$, $\\tau_{\\mathrm{ign}}$ is set to $t_{\\mathrm{end}}$.\n\nFor each test case, we compute $\\tau_{\\mathrm{ign}}^{\\mathrm{full}}$ by integrating the full system. Then, we perform the QSS check. If the criterion is met, we compute $\\tau_{\\mathrm{ign}}^{\\mathrm{red}}$ by integrating the reduced system. If the criterion is not met, the reduced model is considered identical to the full model, so we set $\\tau_{\\mathrm{ign}}^{\\mathrm{red}} = \\tau_{\\mathrm{ign}}^{\\mathrm{full}}$, leading to a modeling error of zero. Finally, the absolute error is calculated as $|\\tau_{\\mathrm{ign}}^{\\mathrm{full}} - \\tau_{\\mathrm{ign}}^{\\mathrm{red}}|$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the combustion problem for a series of test cases, calculating the\n    error in ignition delay time between full and QSS-reduced models.\n    \"\"\"\n\n    # Fixed physical and chemical parameters\n    params = {\n        'A1': 5e7, 'E1': 7.0e4, 'Q1': 0.0,\n        'A2': 2e8, 'E2': 6.0e4, 'Q2': 1.0e5,\n        'A3': 1e4, 'E3': 0.0, 'Q3': 0.0,\n        'A4': 1e7, 'E4': 5.0e4, 'Q4': 2.0e4,\n        'rho': 1.0, 'Cp': 1000.0, 'Ru': 8.314\n    }\n\n    # Test cases: (a0, b0, r0, T0, delta_T, theta, t_end)\n    test_cases = [\n        # Case 1: baseline chain-branching ignition\n        (1.0, 2.0, 1.0e-9, 1000.0, 50.0, 0.2, 0.01),\n        # Case 2: borderline QSS with elevated initial radical\n        (1.0, 0.8, 5.0e-2, 1000.0, 50.0, 0.05, 0.02),\n        # Case 3: low-temperature, slow kinetics\n        (0.5, 0.5, 1.0e-9, 800.0, 50.0, 0.2, 0.05),\n    ]\n\n    simulator = CombustionSimulator(params)\n    results = []\n    for case in test_cases:\n        error = simulator.run_case(case)\n        results.append(error)\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\n\nclass CombustionSimulator:\n    \"\"\"\n    A class to encapsulate the combustion model, parameters, and solution logic.\n    \"\"\"\n    def __init__(self, params):\n        self.p = params\n        self.eps = np.finfo(float).eps\n\n    def _calculate_k(self, T):\n        \"\"\"Calculates Arrhenius rate constants at a given temperature T.\"\"\"\n        k1 = self.p['A1'] * np.exp(-self.p['E1'] / (self.p['Ru'] * T))\n        k2 = self.p['A2'] * np.exp(-self.p['E2'] / (self.p['Ru'] * T))\n        k3 = self.p['A3']  # E3 = 0\n        k4 = self.p['A4'] * np.exp(-self.p['E4'] / (self.p['Ru'] * T))\n        return k1, k2, k3, k4\n\n    def _rhs_full(self, t, y):\n        \"\"\"Right-hand side function for the full ODE system.\"\"\"\n        a, b, r, T = y\n        k1, k2, k3, k4 = self._calculate_k(T)\n\n        # To prevent negative concentrations from numerical errors\n        a = max(0, a)\n        b = max(0, b)\n        r = max(0, r)\n\n        # Reaction rates\n        omega1 = k1 * a * b\n        omega2 = k2 * r * b\n        omega3 = k3 * r * r\n        omega4 = k4 * a * r\n\n        # Species ODEs\n        dadt = -omega1 - omega4\n        dbdt = -omega1 - omega2\n        drdt = omega1 + omega2 - 2 * omega3\n\n        # Energy ODE\n        dTdt = (self.p['Q2'] * omega2 + self.p['Q4'] * omega4) / (self.p['rho'] * self.p['Cp'])\n\n        return [dadt, dbdt, drdt, dTdt]\n\n    def _rhs_reduced(self, t, y):\n        \"\"\"Right-hand side function for the QSS-reduced ODE system.\"\"\"\n        a, b, T = y\n        k1, k2, k3, k4 = self._calculate_k(T)\n        \n        # To prevent negative concentrations from numerical errors\n        a = max(0, a)\n        b = max(0, b)\n\n        # QSS radical concentration r_qss\n        # 2*k3*r^2 - k2*b*r - k1*a*b = 0\n        term_sqrt = np.sqrt((k2 * b)**2 + 8 * k1 * k3 * a * b)\n        r_qss = (k2 * b + term_sqrt) / (4 * k3 + self.eps)\n        \n        # Species ODEs with r_qss\n        dadt = -k1 * a * b - k4 * a * r_qss\n        dbdt = -k1 * a * b - k2 * b * r_qss\n\n        # Energy ODE with r_qss\n        dTdt = (r_qss / (self.p['rho'] * self.p['Cp'])) * (self.p['Q2'] * k2 * b + self.p['Q4'] * k4 * a)\n\n        return [dadt, dbdt, dTdt]\n\n    def _check_qss(self, a0, b0, r0, T0, theta):\n        \"\"\"Checks if the QSS assumption is valid based on the timescale criterion.\"\"\"\n        k1_0, k2_0, k3_0, k4_0 = self._calculate_k(T0)\n\n        # Initial rate of change for A\n        dadt_0 = -k1_0 * a0 * b0 - k4_0 * a0 * r0\n        tau_A_denom = abs(dadt_0)\n        \n        # Initial rate of change for R\n        drdt_0 = k1_0 * a0 * b0 + k2_0 * b0 * r0 - 2 * k3_0 * r0**2\n        tau_R_denom = abs(drdt_0)\n\n        # Handle cases where concentration or rate is zero\n        if tau_A_denom  self.eps: return False # Major species not changing, no timescale separation\n        if r0  self.eps or tau_R_denom  self.eps:\n            tau_R = 0.0 # Zero concentration or zero time derivative means infinite/zero timescale. Zero timescale is QSS.\n        else:\n            tau_R = r0 / tau_R_denom\n\n        tau_A = a0 / tau_A_denom\n        \n        if tau_A  self.eps: return False\n        \n        return (tau_R / tau_A)  theta\n\n    def _solve_for_ignition(self, rhs_func, y0, t_span, T_ign):\n        \"\"\"Integrates an ODE system and finds ignition time.\"\"\"\n        \n        num_vars = len(y0)\n        temp_idx = num_vars - 1\n\n        def ignition_event(t, y):\n            return y[temp_idx] - T_ign\n        ignition_event.terminal = True\n        ignition_event.direction = 1\n\n        sol = solve_ivp(\n            fun=rhs_func,\n            t_span=t_span,\n            y0=y0,\n            method='Radau',\n            events=ignition_event,\n            dense_output=True\n        )\n\n        if sol.t_events[0].size  0:\n            return sol.t_events[0][0]\n        else:\n            return t_span[1]\n\n    def run_case(self, case_params):\n        \"\"\"Runs a single test case and returns the ignition delay error.\"\"\"\n        a0, b0, r0, T0, delta_T, theta, t_end = case_params\n        T_ign = T0 + delta_T\n        t_span = (0, t_end)\n\n        # 1. Solve full model\n        y0_full = [a0, b0, r0, T0]\n        tau_full = self._solve_for_ignition(self._rhs_full, y0_full, t_span, T_ign)\n        \n        # 2. Check QSS validity\n        is_qss_valid = self._check_qss(a0, b0, r0, T0, theta)\n\n        if is_qss_valid:\n            # 3. Solve reduced model\n            y0_red = [a0, b0, T0]\n            tau_red = self._solve_for_ignition(self._rhs_reduced, y0_red, t_span, T_ign)\n        else:\n            # Per problem spec, if QSS is not applied, reduced model is identical\n            # to full model, so the error is zero.\n            tau_red = tau_full\n        \n        # 4. Calculate absolute error\n        error = abs(tau_full - tau_red)\n        return error\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Skeletal mechanism generation frequently involves lumping multiple species, such as isomers, into a single pseudo-species to reduce the model's size. A critical step in this process is to assign accurate thermochemical properties to this new lumped entity. This exercise  provides hands-on experience with a core computational task: generating a set of NASA polynomial coefficients that represent the averaged properties of an isomer group. You will implement a least-squares fitting procedure from first principles, a skill essential for managing thermochemical data in any combustion modeling workflow.",
            "id": "4063502",
            "problem": "You are tasked with implementing a computational procedure used in skeletal mechanism generation workflows in computational combustion to represent a lumped pseudo-species that aggregates a set of isomers. The lumped pseudo-species must be assigned a single set of National Aeronautics and Space Administration (NASA) seven-coefficient polynomial parameters over a specified temperature range, such that the polynomial simultaneously fits the iso-aggregate enthalpy and isobaric heat capacity data in the least squares sense. The procedure must be derived from first principles and implemented as a complete, runnable program. The final answer must be code.\n\nBackground and foundational base: In thermochemistry for ideal gases, the molar enthalpy $h(T)$ and the isobaric molar heat capacity $c_p(T)$ are related by the integral definition $h(T) = \\int_{T_0}^{T} c_p(\\tau) \\, d\\tau + h(T_0)$ for any reference temperature $T_0$, and the definition $c_p(T) = \\left(\\frac{\\partial h}{\\partial T}\\right)_p$. For the NASA seven-coefficient polynomial form on a single temperature interval, the following well-tested representation is used:\n- The nondimensional heat capacity ratio is $c_p(T)/R = a_1 + a_2 T + a_3 T^2 + a_4 T^3 + a_5 T^4$, where $R$ is the universal gas constant.\n- The nondimensional enthalpy is $h(T)/(R T) = a_1 + a_2 \\frac{T}{2} + a_3 \\frac{T^2}{3} + a_4 \\frac{T^3}{4} + a_5 \\frac{T^4}{5} + a_6 \\frac{1}{T}$, where $a_6$ is an integration constant adjusting the reference level of enthalpy.\n- The seventh coefficient $a_7$ pertains to entropy and is not used in this task.\n\nIn a lumped isomer group representing a pseudo-species in a skeletal mechanism, the mixture properties are constructed by mole-fraction-weighted averaging of the individual isomer properties. For a set of $n$ isomers with normalized weights $w_i$ such that $\\sum_{i=1}^{n} w_i = 1$, the lumped properties are $c_p^{\\mathrm{lump}}(T) = \\sum_{i=1}^{n} w_i \\, c_{p,i}(T)$ and $h^{\\mathrm{lump}}(T) = \\sum_{i=1}^{n} w_i \\, h_i(T)$.\n\nYour objective is to compute the six NASA polynomial coefficients $\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ that best fit the lumped properties over a specified temperature range in the least squares sense, simultaneously for $c_p(T)$ and $h(T)$, by solving a linear system for the coefficients constructed from the basis functions implied by the NASA form. You must construct the design matrix by stacking the equations for $c_p(T)/R$ and $h(T)/(R T)$ evaluated at a collection of temperatures in the given range, yielding a linear least squares problem. You must not use shortcut formulas for the target coefficients; you must derive and implement the least squares setup from the fundamental base given.\n\nUnits and numerical conventions:\n- Use $R = 8.31446261815324\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- All input enthalpies $h(T)$ must be treated in $\\mathrm{J\\,mol^{-1}}$ and all input heat capacities $c_p(T)$ in $\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- Construct the least squares problem using the nondimensional forms $c_p(T)/R$ and $h(T)/(R T)$.\n- Angles are not involved.\n\nTest suite and parameters: Implement the program to evaluate $c_{p,i}(T)$ and $h_i(T)$ for each isomer from known “true” NASA coefficients over a single interval, then form the lumped properties, and fit the six coefficients $\\{a_1,\\dots,a_6\\}$ by least squares. For each test case below, sample the temperature uniformly over the closed interval with the specified number of points, and use the provided isomer data.\n\nDefine the evaluation of each isomer’s properties from its given coefficients $\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ as:\n- $c_{p,i}(T)/R = a_1 + a_2 T + a_3 T^2 + a_4 T^3 + a_5 T^4$,\n- $h_i(T)/(R T) = a_1 + a_2 \\frac{T}{2} + a_3 \\frac{T^2}{3} + a_4 \\frac{T^3}{4} + a_5 \\frac{T^4}{5} + a_6 \\frac{1}{T}$.\n\nThe test suite comprises four cases:\n\n- Case A (general multi-isomer lump):\n  - Isomer $1$ coefficients: $\\{3.500000, 1.200\\times 10^{-3}, -3.000\\times 10^{-7}, 4.000\\times 10^{-11}, -2.000\\times 10^{-15}, -1.000000\\}$.\n  - Isomer $2$ coefficients: $\\{3.750000, 0.800\\times 10^{-3}, -2.500\\times 10^{-7}, 3.500\\times 10^{-11}, -1.800\\times 10^{-15}, -0.800000\\}$.\n  - Weights: $\\{0.6, 0.4\\}$.\n  - Temperature range: $[300\\,\\mathrm{K}, 1500\\,\\mathrm{K}]$ sampled at $41$ points.\n\n- Case B (single-isomer boundary):\n  - Isomer $1$ coefficients: $\\{3.500000, 1.200\\times 10^{-3}, -3.000\\times 10^{-7}, 4.000\\times 10^{-11}, -2.000\\times 10^{-15}, -1.000000\\}$.\n  - Weights: $\\{1.0\\}$.\n  - Temperature range: $[300\\,\\mathrm{K}, 1500\\,\\mathrm{K}]$ sampled at $41$ points.\n\n- Case C (three-isomer lump, extended range):\n  - Isomer $1$ coefficients: $\\{3.500000, 1.200\\times 10^{-3}, -3.000\\times 10^{-7}, 4.000\\times 10^{-11}, -2.000\\times 10^{-15}, -1.000000\\}$.\n  - Isomer $2$ coefficients: $\\{3.750000, 0.800\\times 10^{-3}, -2.500\\times 10^{-7}, 3.500\\times 10^{-11}, -1.800\\times 10^{-15}, -0.800000\\}$.\n  - Isomer $3$ coefficients: $\\{3.250000, 1.500\\times 10^{-3}, -3.200\\times 10^{-7}, 4.500\\times 10^{-11}, -2.200\\times 10^{-15}, -1.200000\\}$.\n  - Weights: $\\{0.5, 0.25, 0.25\\}$.\n  - Temperature range: $[500\\,\\mathrm{K}, 2000\\,\\mathrm{K}]$ sampled at $51$ points.\n\n- Case D (identical-isomer consistency check):\n  - Isomer $1$ coefficients: $\\{3.750000, 0.800\\times 10^{-3}, -2.500\\times 10^{-7}, 3.500\\times 10^{-11}, -1.800\\times 10^{-15}, -0.800000\\}$.\n  - Isomer $2$ coefficients: $\\{3.750000, 0.800\\times 10^{-3}, -2.500\\times 10^{-7}, 3.500\\times 10^{-11}, -1.800\\times 10^{-15}, -0.800000\\}$.\n  - Weights: $\\{0.5, 0.5\\}$.\n  - Temperature range: $[300\\,\\mathrm{K}, 800\\,\\mathrm{K}]$ sampled at $21$ points.\n\nAlgorithmic specification:\n- For each case, compute $c_{p,i}(T)$ and $h_i(T)$ from the given coefficients for each isomer at all sampled temperatures using the NASA forms above and $R$ as specified.\n- Form the lumped properties $c_p^{\\mathrm{lump}}(T)$ and $h^{\\mathrm{lump}}(T)$ using the provided weights.\n- Construct and solve the linear least squares system for $\\{a_1,\\dots,a_6\\}$ by stacking the $c_p(T)/R$ rows and the $h(T)/(R T)$ rows across all sampled temperatures, with equal weighting in the error norm for both properties.\n\nRequired final output:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list of fitted coefficients $\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ for the corresponding test case, in the order Case A, Case B, Case C, Case D. For example, the output format must be exactly like $[[a_1,a_2,a_3,a_4,a_5,a_6],[a_1,a_2,a_3,a_4,a_5,a_6],[a_1,a_2,a_3,a_4,a_5,a_6],[a_1,a_2,a_3,a_4,a_5,a_6]]$ with numerical values in place of symbols.",
            "solution": "The objective is to determine a set of six National Aeronautics and Space Administration (NASA) polynomial coefficients $\\{A_1, A_2, A_3, A_4, A_5, A_6\\}$ that describe the thermochemical properties of a lumped pseudo-species. This pseudo-species is an aggregation of multiple isomers, and its properties are mole-fraction-weighted averages of the constituent isomer properties. The coefficients must provide a best fit in the least squares sense to the lumped molar isobaric heat capacity $c_p^{\\mathrm{lump}}(T)$ and molar enthalpy $h^{\\mathrm{lump}}(T)$ data, generated over a discrete set of $N$ temperatures $T_j$.\n\nFirst, we define the functional forms for the nondimensional heat capacity and enthalpy that we seek for the lumped species, parameterized by the unknown coefficients $\\mathbf{x} = [A_1, A_2, A_3, A_4, A_5, A_6]^T$:\n$$ \\frac{c_p^{\\mathrm{fit}}(T)}{R} = A_1 + A_2 T + A_3 T^2 + A_4 T^3 + A_5 T^4 $$\n$$ \\frac{h^{\\mathrm{fit}}(T)}{RT} = A_1 + A_2 \\frac{T}{2} + A_3 \\frac{T^2}{3} + A_4 \\frac{T^3}{4} + A_5 \\frac{T^4}{5} + A_6 \\frac{1}{T} $$\nwhere $R$ is the universal gas constant.\n\nNext, we define the \"true\" or target properties of the lumped species. For a set of $n$ isomers, each with a given weight $w_i$ (where $\\sum_{i=1}^n w_i = 1$) and its own set of NASA coefficients $\\{a_{1,i}, a_{2,i}, \\dots, a_{6,i}\\}$, the thermochemical properties for each isomer $i$ are given by:\n$$ \\frac{c_{p,i}(T)}{R} = a_{1,i} + a_{2,i} T + a_{3,i} T^2 + a_{4,i} T^3 + a_{5,i} T^4 = \\sum_{k=1}^{5} a_{k,i} T^{k-1} $$\n$$ \\frac{h_i(T)}{RT} = a_{1,i} + a_{2,i} \\frac{T}{2} + a_{3,i} \\frac{T^2}{3} + a_{4,i} \\frac{T^3}{4} + a_{5,i} \\frac{T^4}{5} + a_{6,i} \\frac{1}{T} = \\sum_{k=1}^{5} a_{k,i} \\frac{T^{k-1}}{k} + a_{6,i} \\frac{1}{T} $$\nThe lumped properties are the weighted averages:\n$$ \\frac{c_p^{\\mathrm{lump}}(T)}{R} = \\sum_{i=1}^n w_i \\frac{c_{p,i}(T)}{R} $$\n$$ \\frac{h^{\\mathrm{lump}}(T)}{RT} = \\sum_{i=1}^n w_i \\frac{h_i(T)}{RT} $$\nThese lumped quantities, evaluated at a discrete set of $N$ temperatures $\\{T_1, T_2, \\dots, T_N\\}$, serve as the target data for our least squares fit.\n\nThe problem is to find the coefficient vector $\\mathbf{x}$ that minimizes the sum of squared residuals, $S$, where the residuals are the differences between the fitted functional forms and the target lumped data, summed over all $N$ temperature points for both heat capacity and enthalpy.\n$$ S = \\sum_{j=1}^{N} \\left[ \\left( \\frac{c_p^{\\mathrm{lump}}(T_j)}{R} - \\frac{c_p^{\\mathrm{fit}}(T_j)}{R} \\right)^2 + \\left( \\frac{h^{\\mathrm{lump}}(T_j)}{RT_j} - \\frac{h^{\\mathrm{fit}}(T_j)}{RT_j} \\right)^2 \\right] $$\nThis is a linear least squares problem. We can express it in the matrix form $\\mathbf{A} \\mathbf{x} \\approx \\mathbf{b}$, where we seek the vector $\\mathbf{x}$ that minimizes the Euclidean norm of the residual vector, $||\\mathbf{A} \\mathbf{x} - \\mathbf{b}||_2$.\n\nThe observation vector $\\mathbf{b}$ contains the target thermochemical data. It is a column vector of size $2N \\times 1$, constructed by stacking the $N$ values for nondimensional heat capacity followed by the $N$ values for nondimensional enthalpy:\n$$ \\mathbf{b} = \\begin{pmatrix} c_p^{\\mathrm{lump}}(T_1)/R \\\\ \\vdots \\\\ c_p^{\\mathrm{lump}}(T_N)/R \\\\ h^{\\mathrm{lump}}(T_1)/(RT_1) \\\\ \\vdots \\\\ h^{\\mathrm{lump}}(T_N)/(RT_N) \\end{pmatrix} $$\nThe design matrix $\\mathbf{A}$ contains the basis functions of our fitting polynomials evaluated at each temperature point. It is a $2N \\times 6$ matrix. The top $N$ rows correspond to the heat capacity equations, and the bottom $N$ rows correspond to the enthalpy equations. For a given temperature $T_j$, the row for $c_p/R$ is $[1, T_j, T_j^2, T_j^3, T_j^4, 0]$, and the row for $h/(RT)$ is $[1, T_j/2, T_j^2/3, T_j^3/4, T_j^4/5, 1/T_j]$. The full matrix is:\n$$ \\mathbf{A} =\n\\begin{pmatrix}\n1  T_1  T_1^2  T_1^3  T_1^4  0 \\\\\n\\vdots  \\vdots  \\vdots  \\vdots  \\vdots  \\vdots \\\\\n1  T_N  T_N^2  T_N^3  T_N^4  0 \\\\\n\\hline\n1  T_1/2  T_1^2/3  T_1^3/4  T_1^4/5  1/T_1 \\\\\n\\vdots  \\vdots  \\vdots  \\vdots  \\vdots  \\vdots \\\\\n1  T_N/2  T_N^2/3  T_N^3/4  T_N^4/5  1/T_N\n\\end{pmatrix} $$\nThe least squares solution $\\mathbf{x}$ is the vector that solves the normal equations $\\mathbf{A}^T \\mathbf{A} \\mathbf{x} = \\mathbf{A}^T \\mathbf{b}$. This system can be solved robustly using numerical linear algebra libraries, for instance, via QR decomposition or Singular Value Decomposition (SVD), which are standardly implemented in functions like `numpy.linalg.lstsq`.\n\nThe algorithm proceeds as follows for each test case:\n1. Generate an array of $N$ equally spaced temperatures $T_j$ over the specified range $[T_{\\text{min}}, T_{\\text{max}}]$.\n2. For each isomer $i$, calculate the vectors of $c_{p,i}(T_j)/R$ and $h_i(T_j)/(RT_j)$ values over all $T_j$.\n3. Compute the target lumped property vectors, $c_p^{\\mathrm{lump}}(T_j)/R$ and $h^{\\mathrm{lump}}(T_j)/(RT_j)$, by taking the weighted sum of the isomer properties.\n4. Construct the $2N \\times 1$ observation vector $\\mathbf{b}$ by vertically stacking the lumped $c_p/R$ vector and the lumped $h/(RT)$ vector.\n5. Construct the $2N \\times 6$ design matrix $\\mathbf{A}$ based on the powers of temperature, as derived above.\n6. Solve the linear system $\\mathbf{A} \\mathbf{x} \\approx \\mathbf{b}$ for the unknown coefficient vector $\\mathbf{x} = [A_1, \\dots, A_6]^T$ using a standard least squares solver.\n7. The resulting vector $\\mathbf{x}$ contains the desired six NASA coefficients for the lumped pseudo-species.\nThis procedure is applied to each of the four test cases provided.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes NASA polynomial coefficients for a lumped pseudo-species by\n    simultaneously fitting enthalpy and heat capacity data via linear least squares.\n    \"\"\"\n    # Universal gas constant in J mol^-1 K^-1\n    R = 8.31446261815324\n\n    # Test suite definition\n    test_cases = {\n        \"Case A\": {\n            \"isomers\": [\n                {\"coeffs\": [3.500000, 1.200e-3, -3.000e-7, 4.000e-11, -2.000e-15, -1.000000]},\n                {\"coeffs\": [3.750000, 0.800e-3, -2.500e-7, 3.500e-11, -1.800e-15, -0.800000]}\n            ],\n            \"weights\": [0.6, 0.4],\n            \"temp_range\": (300.0, 1500.0),\n            \"num_points\": 41\n        },\n        \"Case B\": {\n            \"isomers\": [\n                {\"coeffs\": [3.500000, 1.200e-3, -3.000e-7, 4.000e-11, -2.000e-15, -1.000000]}\n            ],\n            \"weights\": [1.0],\n            \"temp_range\": (300.0, 1500.0),\n            \"num_points\": 41\n        },\n        \"Case C\": {\n            \"isomers\": [\n                {\"coeffs\": [3.500000, 1.200e-3, -3.000e-7, 4.000e-11, -2.000e-15, -1.000000]},\n                {\"coeffs\": [3.750000, 0.800e-3, -2.500e-7, 3.500e-11, -1.800e-15, -0.800000]},\n                {\"coeffs\": [3.250000, 1.500e-3, -3.200e-7, 4.500e-11, -2.200e-15, -1.200000]}\n            ],\n            \"weights\": [0.5, 0.25, 0.25],\n            \"temp_range\": (500.0, 2000.0),\n            \"num_points\": 51\n        },\n        \"Case D\": {\n            \"isomers\": [\n                {\"coeffs\": [3.750000, 0.800e-3, -2.500e-7, 3.500e-11, -1.800e-15, -0.800000]},\n                {\"coeffs\": [3.750000, 0.800e-3, -2.500e-7, 3.500e-11, -1.800e-15, -0.800000]}\n            ],\n            \"weights\": [0.5, 0.5],\n            \"temp_range\": (300.0, 800.0),\n            \"num_points\": 21\n        }\n    }\n\n    all_results = []\n    \n    # The order of cases for the output must be A, B, C, D\n    case_order = [\"Case A\", \"Case B\", \"Case C\", \"Case D\"]\n\n    for case_name in case_order:\n        case = test_cases[case_name]\n        isomers = case[\"isomers\"]\n        weights = case[\"weights\"]\n        t_min, t_max = case[\"temp_range\"]\n        n_points = case[\"num_points\"]\n\n        # 1. Generate temperature points\n        T = np.linspace(t_min, t_max, n_points)\n\n        # 2. Calculate \"true\" lumped properties (to form the 'b' vector)\n        cp_lump_over_R = np.zeros(n_points)\n        h_lump_over_RT = np.zeros(n_points)\n\n        for i, isomer in enumerate(isomers):\n            coeffs = np.array(isomer[\"coeffs\"])\n            w = weights[i]\n            \n            # Powers of T: T^0, T^1, T^2, T^3, T^4\n            T_powers = np.vander(T, N=5, increasing=True)\n            \n            # c_p,i / R = sum_{k=1..5} a_k * T^(k-1)\n            cp_i_over_R = T_powers @ coeffs[:5]\n            \n            # h_i / RT = sum_{k=1..5} a_k * T^(k-1)/k + a_6/T\n            h_i_over_RT = (T_powers / np.arange(1, 6)) @ coeffs[:5] + coeffs[5] / T\n\n            cp_lump_over_R += w * cp_i_over_R\n            h_lump_over_RT += w * h_i_over_RT\n\n        # 3. Construct observation vector b\n        b = np.concatenate([cp_lump_over_R, h_lump_over_RT])\n\n        # 4. Construct design matrix A\n        A = np.zeros((2 * n_points, 6))\n        \n        # Basis functions for T\n        T_powers = np.vander(T, N=5, increasing=True) # T^0, T^1, ..., T^4\n\n        # Top part for c_p/R\n        A[:n_points, :5] = T_powers\n        # a6 coefficient is 0 for c_p\n        A[:n_points, 5] = 0\n\n        # Bottom part for h/RT\n        A[n_points:, :5] = T_powers / np.arange(1, 6)\n        A[n_points:, 5] = 1.0 / T\n\n        # 5. Solve the linear least squares system Ax = b\n        # rcond=None to use the machine-precision default\n        lumped_coeffs, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n        \n        all_results.append(lumped_coeffs.tolist())\n\n    # Format the output as a string to match the required format exactly\n    # e.g., [[c1,c2,...],[c1,c2,...]] without spaces after commas inside inner lists\n    \n    # Custom string formatting to avoid spaces introduced by default str(list)\n    formatted_results = []\n    for res in all_results:\n        # Format numbers to a reasonable precision for clean output\n        formatted_coeffs = [f\"{c:.15g}\" for c in res]\n        formatted_results.append(f\"[{','.join(formatted_coeffs)}]\")\n    \n    final_output_str = f\"[{','.join(formatted_results)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Creating a skeletal mechanism is not just about removing species and reactions; it often involves a final optimization step to ensure the reduced model accurately reproduces key combustion phenomena. This advanced practice  delves into this refinement stage by tasking you with re-calibrating reaction rate parameters to better match target data. You will set up and solve a constrained quadratic program, a state-of-the-art technique that balances fitting accuracy with physical plausibility, and in doing so, explore the fundamental trade-off between model bias and variance.",
            "id": "4063478",
            "problem": "You are tasked with formalizing and solving a small convex Quadratic Program (QP) that arises in computational combustion skeletal mechanism generation workflows after mechanism pruning. In such workflows, reaction rate constants in the pruned mechanism are often reweighted to best fit training observables while respecting tolerances and avoiding overfitting. You will set up a linearized surrogate mapping between logarithmic reaction-rate multipliers and observable deviations, then solve a weighted, regularized least-squares QP under bound constraints, and assess a bias-variance trade-off using a degrees-of-freedom proxy.\n\nThe fundamental base is as follows. In a skeletal mechanism, consider $m$ retained elementary reactions with baseline rate constants $\\{k_j\\}_{j=1}^m$. Let the multiplicative reweighting factors be $x \\in \\mathbb{R}^m$, applied as $k_j \\mapsto x_j k_j$. For small multiplicative deviations near $x_j = 1$, a first-order linearization of observable deviations is valid under the logarithmic sensitivity framework. Denote the vector of $p$ training observable deviations relative to the pruned-baseline predictions as $y \\in \\mathbb{R}^p$ (each component is the target deviation to be matched), and the sensitivity matrix $A \\in \\mathbb{R}^{p \\times m}$ with entries $A_{ij} = \\partial o_i / \\partial \\ln k_j$ evaluated at the baseline. The linearized prediction is then $A x$, with $x$ interpreted as small multiplicative factors around $1$ in logarithmic coordinates, so the residual is $A x - y$.\n\nEach observable has an associated tolerance $\\sigma_i  0$, collected in $\\sigma \\in \\mathbb{R}^p$, and the diagonal weighting matrix is $W = \\mathrm{diag}(1/\\sigma_1, \\ldots, 1/\\sigma_p)$. To penalize deviations of $x$ from the baseline $1$, introduce a ridge regularization parameter $\\alpha  0$. The QP objective is\n$$\nJ(x) = \\frac{1}{2} \\| W (A x - y) \\|_2^2 + \\frac{\\alpha}{2} \\| x - \\mathbf{1} \\|_2^2,\n$$\nwhere $\\mathbf{1} \\in \\mathbb{R}^m$ denotes the all-ones vector. Decision variables are bounded componentwise by lower and upper bounds to reflect physically plausible reweighting, $l \\le x \\le u$.\n\nYou must implement a solver that:\n- Minimizes $J(x)$ subject to $l \\le x \\le u$.\n- Returns the optimized $x^\\star$ and computes the following metrics:\n  - The weighted mean squared error (WMSE) of the fit,\n  $$\n  \\mathrm{WMSE}(x^\\star) = \\frac{1}{p} \\left\\| W (A x^\\star - y) \\right\\|_2^2,\n  $$\n  which is dimensionless due to the tolerance weighting.\n  - The bias magnitude induced by regularization and bounds,\n  $$\n  \\mathrm{Bias}(x^\\star) = \\| x^\\star - \\mathbf{1} \\|_2^2,\n  $$\n  which is dimensionless.\n  - A variance proxy using the degrees-of-freedom of the corresponding unconstrained weighted ridge regression linear operator. Define $W^2 = \\mathrm{diag}(1/\\sigma_1^2, \\ldots, 1/\\sigma_p^2)$ and $G = A^\\top W^2 A + \\alpha I_m$, where $I_m$ is the $m \\times m$ identity. The hat matrix mapping $y$ to fitted observables under the unconstrained ridge is\n  $$\n  H = A G^{-1} A^\\top W^2,\n  $$\n  and the degrees-of-freedom proxy is\n  $$\n  \\mathrm{df} = \\mathrm{trace}(H),\n  $$\n  which is dimensionless. This proxy increases with model flexibility and serves as a variance indicator.\n\nYou must implement the QP solve using a general-purpose numerical optimizer. The linear algebra for the unconstrained ridge quantities must be explicitly computed. The training observables and tolerances are provided numerically in the test suite below.\n\nYour program must produce a single line of output containing the results for all test cases as a comma-separated list of lists, where each inner list corresponds to one test case and contains three decimal numbers $[\\mathrm{WMSE}, \\mathrm{Bias}, \\mathrm{df}]$ in that order. For example, output in the format $[[a,b,c],[d,e,f],[g,h,i]]$. No units are required in the output because all metrics defined above are dimensionless.\n\nTest suite:\n- Case $1$ (happy path, well-conditioned):\n  - $p = 6$, $m = 4$,\n  - $A = \\begin{bmatrix}\n  0.40  -0.20  0.10  0.00 \\\\\n  0.10  0.30  -0.25  0.05 \\\\\n  0.00  0.15  0.20  -0.10 \\\\\n  0.25  -0.05  0.00  0.30 \\\\\n  -0.10  0.05  0.35  0.10 \\\\\n  0.05  0.00  -0.15  0.20\n  \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 0.06  -0.08  0.12  0.03  0.07  -0.05 \\end{bmatrix}^\\top$,\n  - $\\sigma = \\begin{bmatrix} 0.05  0.05  0.08  0.04  0.06  0.05 \\end{bmatrix}^\\top$,\n  - $\\alpha = 0.20$,\n  - bounds $l = 0.70$, $u = 1.50$ applied to each component of $x$.\n- Case $2$ (boundary-hitting, stronger data influence):\n  - $p = 5$, $m = 3$,\n  - $A = \\begin{bmatrix}\n  0.60  -0.10  0.20 \\\\\n  -0.40  0.30  0.10 \\\\\n  0.20  0.40  -0.30 \\\\\n  0.10  -0.20  0.50 \\\\\n  -0.30  0.20  0.00\n  \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 0.50  -0.40  0.30  0.20  -0.10 \\end{bmatrix}^\\top$,\n  - $\\sigma = \\begin{bmatrix} 0.10  0.10  0.10  0.10  0.10 \\end{bmatrix}^\\top$,\n  - $\\alpha = 0.05$,\n  - bounds $l = 0.50$, $u = 1.20$ applied to each component of $x$.\n- Case $3$ (underdetermined, low regularization, variance-dominated):\n  - $p = 3$, $m = 5$,\n  - $A = \\begin{bmatrix}\n  0.30  -0.20  0.10  0.00  0.05 \\\\\n  -0.10  0.40  0.00  0.20  -0.05 \\\\\n  0.20  0.00  0.30  -0.10  0.00\n  \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 0.15  -0.05  0.10 \\end{bmatrix}^\\top$,\n  - $\\sigma = \\begin{bmatrix} 0.05  0.07  0.06 \\end{bmatrix}^\\top$,\n  - $\\alpha = 0.01$,\n  - bounds $l = 0.60$, $u = 2.00$ applied to each component of $x$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case contributing an inner list $[\\mathrm{WMSE}, \\mathrm{Bias}, \\mathrm{df}]$, in the order of the test suite. For example, your output must look like $[[r_1,s_1,t_1],[r_2,s_2,t_2],[r_3,s_3,t_3]]$ where each symbol represents a decimal number.",
            "solution": "The task is to find the vector of reweighting factors $x^\\star$ that minimizes the objective function $J(x)$ subject to box constraints, and then to compute several key performance metrics. This represents a typical parameter optimization problem in model calibration.\n\n### Formulation as a Quadratic Program (QP)\n\nThe objective function $J(x)$ is a weighted, regularized sum of squares:\n$$\nJ(x) = \\frac{1}{2} \\| W (A x - y) \\|_2^2 + \\frac{\\alpha}{2} \\| x - \\mathbf{1} \\|_2^2\n$$\nThis function is quadratic in $x$. Expanding the terms shows it can be written in the standard QP form $\\frac{1}{2}x^\\top Q x + c^\\top x + \\text{constant}$. The Hessian matrix of $J(x)$ is $Q = A^\\top W^\\top W A + \\alpha I_m$. Since $W^\\top W$ is positive definite (as all $\\sigma_i > 0$) and $\\alpha > 0$, the Hessian $Q$ is positive definite, meaning $J(x)$ is a strictly convex function. Minimizing a strictly convex function over a convex set (the box constraints $l \\le x \\le u$) guarantees a unique solution.\n\nTo solve this problem efficiently using gradient-based numerical optimizers, we derive the analytical gradient of $J(x)$:\n$$\n\\nabla J(x) = \\frac{\\partial}{\\partial x} \\left[ \\frac{1}{2} (Ax-y)^\\top W^2 (Ax-y) + \\frac{\\alpha}{2} (x-\\mathbf{1})^\\top (x-\\mathbf{1}) \\right]\n$$\n$$\n\\nabla J(x) = A^\\top W^2 (Ax - y) + \\alpha (x - \\mathbf{1})\n$$\nwhere $W^2 = W^\\top W = \\mathrm{diag}(1/\\sigma_1^2, \\ldots, 1/\\sigma_p^2)$.\n\n### Optimization and Metrics Calculation\n\nThe problem is a box-constrained quadratic program, which can be solved using standard numerical optimization libraries, such as SciPy's `minimize` function with the `L-BFGS-B` method. The optimization is initialized with a feasible starting point, typically the baseline vector $x_0 = \\mathbf{1}$.\n\nOnce the optimal vector $x^\\star$ is found, the three required metrics are computed:\n\n1.  **Weighted Mean Squared Error (WMSE)**: This quantifies the goodness of fit, measuring the average squared residual weighted by the observable tolerances.\n    $$\n    \\mathrm{WMSE}(x^\\star) = \\frac{1}{p} \\left\\| W (A x^\\star - y) \\right\\|_2^2\n    $$\n\n2.  **Bias Magnitude**: This measures the magnitude of the correction applied to the rate constants, representing the deviation from the baseline model. It is influenced by the regularization term.\n    $$\n    \\mathrm{Bias}(x^\\star) = \\| x^\\star - \\mathbf{1} \\|_2^2\n    $$\n\n3.  **Degrees-of-Freedom Proxy (df)**: This metric proxies the model's complexity or variance. It is the trace of the \"hat matrix\" $H$ from the corresponding unconstrained ridge regression problem. The calculation involves:\n    - The Gram-like matrix: $G = A^\\top W^2 A + \\alpha I_m$.\n    - The hat matrix: $H = A G^{-1} A^\\top W^2$.\n    - The degrees of freedom: $\\mathrm{df} = \\mathrm{trace}(H)$.\n\nThis procedure provides not only the optimized parameters but also a quantitative assessment of the trade-off between fitting the data (low WMSE) and maintaining a simple, physically plausible model (low Bias and df).",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the quadratic programming problem for each test case and computes the required metrics.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path, well-conditioned)\n        {\n            \"p\": 6, \"m\": 4,\n            \"A\": np.array([\n                [0.40, -0.20, 0.10, 0.00],\n                [0.10, 0.30, -0.25, 0.05],\n                [0.00, 0.15, 0.20, -0.10],\n                [0.25, -0.05, 0.00, 0.30],\n                [-0.10, 0.05, 0.35, 0.10],\n                [0.05, 0.00, -0.15, 0.20]\n            ]),\n            \"y\": np.array([0.06, -0.08, 0.12, 0.03, 0.07, -0.05]),\n            \"sigma\": np.array([0.05, 0.05, 0.08, 0.04, 0.06, 0.05]),\n            \"alpha\": 0.20,\n            \"l\": 0.70, \"u\": 1.50\n        },\n        # Case 2 (boundary-hitting, stronger data influence)\n        {\n            \"p\": 5, \"m\": 3,\n            \"A\": np.array([\n                [0.60, -0.10, 0.20],\n                [-0.40, 0.30, 0.10],\n                [0.20, 0.40, -0.30],\n                [0.10, -0.20, 0.50],\n                [-0.30, 0.20, 0.00]\n            ]),\n            \"y\": np.array([0.50, -0.40, 0.30, 0.20, -0.10]),\n            \"sigma\": np.array([0.10, 0.10, 0.10, 0.10, 0.10]),\n            \"alpha\": 0.05,\n            \"l\": 0.50, \"u\": 1.20\n        },\n        # Case 3 (underdetermined, low regularization, variance-dominated)\n        {\n            \"p\": 3, \"m\": 5,\n            \"A\": np.array([\n                [0.30, -0.20, 0.10, 0.00, 0.05],\n                [-0.10, 0.40, 0.00, 0.20, -0.05],\n                [0.20, 0.00, 0.30, -0.10, 0.00]\n            ]),\n            \"y\": np.array([0.15, -0.05, 0.10]),\n            \"sigma\": np.array([0.05, 0.07, 0.06]),\n            \"alpha\": 0.01,\n            \"l\": 0.60, \"u\": 2.00\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        p = case[\"p\"]\n        m = case[\"m\"]\n        A = case[\"A\"]\n        y = case[\"y\"]\n        sigma = case[\"sigma\"]\n        alpha = case[\"alpha\"]\n        l_bound = case[\"l\"]\n        u_bound = case[\"u\"]\n        \n        # Define weighting matrix W and W^2\n        W = np.diag(1.0 / sigma)\n        W2 = np.diag(1.0 / (sigma**2))\n\n        # Objective function J(x)\n        def objective(x, A, y, W, alpha):\n            residual = A @ x - y\n            weighted_residual = W @ residual\n            fit_term = 0.5 * np.dot(weighted_residual, weighted_residual)\n            reg_term = 0.5 * alpha * np.dot(x - 1, x - 1)\n            return fit_term + reg_term\n\n        # Gradient of J(x)\n        def jacobian(x, A, y, W, alpha):\n            W2_local = W @ W\n            grad_fit = A.T @ W2_local @ (A @ x - y)\n            grad_reg = alpha * (x - 1)\n            return grad_fit + grad_reg\n            \n        # Initial guess and bounds\n        x0 = np.ones(m)\n        bounds = [(l_bound, u_bound)] * m\n        \n        # Perform optimization\n        opt_result = minimize(\n            fun=objective,\n            x0=x0,\n            args=(A, y, W, alpha),\n            method='L-BFGS-B',\n            jac=jacobian,\n            bounds=bounds\n        )\n        x_star = opt_result.x\n\n        # Calculate metrics\n        # 1. WMSE\n        wmse_residual = W @ (A @ x_star - y)\n        wmse = (1.0 / p) * np.dot(wmse_residual, wmse_residual)\n\n        # 2. Bias\n        bias = np.dot(x_star - 1.0, x_star - 1.0)\n\n        # 3. Degrees of Freedom (df)\n        Id_m = np.identity(m)\n        G = A.T @ W2 @ A + alpha * Id_m\n        G_inv = np.linalg.inv(G)\n        H = A @ G_inv @ A.T @ W2\n        df = np.trace(H)\n\n        results.append([wmse, bias, df])\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join([f\"[{r[0]:.6f},{r[1]:.6f},{r[2]:.6f}]\" for r in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}