{
    "hands_on_practices": [
        {
            "introduction": "The Interaction by Exchange with the Mean (IEM) model is a foundational closure for the micro-mixing process in transported PDF methods. This exercise provides a clear, analytical window into its core mechanism by examining an idealized case of homogeneous mixing. By tracking the evolution of a simple bimodal Probability Density Function (PDF), you can directly observe how the model deterministically drives all scalar realizations towards the ensemble mean, providing crucial intuition for the role of the mixing timescale $ \\tau_m $ in controlling the rate of scalar variance decay. ",
            "id": "4068250",
            "problem": "Consider homogeneous turbulent mixing of a conserved mixture fraction $Z$ in a statistically stationary, spatially uniform reactor with no sources, sinks, or mean-flow gradients. The Probability Density Function (PDF) of $Z$ at initial time $t=0$ is bimodal and consists of a convex combination of two Dirac delta distributions,\n$$\nP(Z,0) \\;=\\; w_1\\,\\delta\\!\\left(Z - z_1\\right) \\;+\\; w_2\\,\\delta\\!\\left(Z - z_2\\right),\n$$\nwhere $w_10$, $w_20$, $w_1+w_2=1$, and $z_1 \\neq z_2$. Mixing is modeled using the Interaction by Exchange with the Mean (IEM) model, whose micro-mixing law for any realization $Z(t)$ is\n$$\n\\frac{dZ}{dt} \\;=\\; -\\,\\frac{1}{\\tau_m}\\,\\bigl(Z(t) - \\widetilde{Z}(t)\\bigr),\n$$\nwhere $\\tau_m0$ is a constant micro-mixing timescale, and $\\widetilde{Z}(t)$ is the ensemble mean of $Z$ at time $t$. Assume the mean $\\widetilde{Z}(t)$ is determined self-consistently from the evolving PDF, and the system is closed and homogeneous so that conservation laws apply.\n\nStarting from the fundamental conservation of the mean for a conserved scalar under homogeneous IEM mixing and the deterministic Liouville transport of PDFs under the drift $\\dot{Z} = -(Z - \\widetilde{Z})/\\tau_m$, derive the time evolution of the PDF, $P(Z,t)$, for $t0$ and show explicitly how the two delta peaks move in time. Then, define the bimodality index\n$$\nB(t) \\;=\\; \\frac{|z_2(t) - z_1(t)|}{|z_2(0) - z_1(0)|},\n$$\nwhere $z_1(t)$ and $z_2(t)$ denote the instantaneous peak locations at time $t$, and compute $B(t)$ in closed form.\n\nProvide your final answer as a single closed-form symbolic expression for $B(t)$. No rounding is required. The bimodality index $B(t)$ is dimensionless; do not include units in your final answer.",
            "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- Initial Probability Density Function (PDF) of mixture fraction $Z$: $P(Z,0) = w_1\\,\\delta(Z - z_1) + w_2\\,\\delta(Z - z_2)$.\n- Conditions on weights: $w_1  0$, $w_2  0$, $w_1+w_2=1$.\n- Initial peak locations: $z_1 \\neq z_2$.\n- Mixing Model: Interaction by Exchange with the Mean (IEM).\n- IEM Law: $\\frac{dZ}{dt} = -\\frac{1}{\\tau_m}(Z(t) - \\widetilde{Z}(t))$.\n- Micro-mixing timescale: $\\tau_m0$ is a constant.\n- Ensemble Mean: $\\widetilde{Z}(t) = \\int_{-\\infty}^{\\infty} \\xi P(\\xi, t) d\\xi$.\n- System properties: Homogeneous, statistically stationary, closed, no sources or sinks, $Z$ is a conserved scalar.\n- Bimodality Index Definition: $B(t) = \\frac{|z_2(t) - z_1(t)|}{|z_2(0) - z_1(0)|}$, where $z_1(t)$ and $z_2(t)$ are the peak locations at time $t$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, describing a standard model (IEM) for scalar mixing in turbulence, which is a core topic in computational combustion. It is well-posed, providing a clear initial value problem for the evolution of a PDF. The language is objective and uses standard terminology. The statement that $Z$ is a conserved scalar in a closed, homogeneous system implies that its mean value $\\widetilde{Z}(t)$ must be constant. This can be verified by taking the time derivative of the definition of the mean and using the Liouville transport equation for the PDF, $\\frac{\\partial P}{\\partial t} + \\frac{\\partial}{\\partial Z}(\\dot{Z}P)=0$, where $\\dot{Z}$ is the IEM mixing law. This leads to $\\frac{d\\widetilde{Z}}{dt} = \\int \\dot{Z}P\\,dZ = \\int -\\frac{1}{\\tau_m}(Z - \\widetilde{Z})P\\,dZ = -\\frac{1}{\\tau_m}(\\widetilde{Z} - \\widetilde{Z}) = 0$. Thus, $\\widetilde{Z}(t)$ is indeed constant. The problem is self-consistent and contains all necessary information.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\nThe problem requires the derivation of the time evolution of the PDF, $P(Z,t)$, and the bimodality index, $B(t)$.\n\nFirst, we establish the value of the constant ensemble mean, $\\widetilde{Z}$. Since $\\widetilde{Z}(t)$ is constant for all $t \\ge 0$, we can compute it at $t=0$ using the given initial PDF, $P(Z,0)$.\n$$\n\\widetilde{Z} = \\widetilde{Z}(0) = \\int_{-\\infty}^{\\infty} Z \\, P(Z,0) \\, dZ\n$$\nSubstituting the expression for $P(Z,0)$:\n$$\n\\widetilde{Z} = \\int_{-\\infty}^{\\infty} Z \\, \\left[ w_1\\,\\delta(Z - z_1) + w_2\\,\\delta(Z - z_2) \\right] \\, dZ\n$$\nUsing the sifting property of the Dirac delta distribution, $\\int f(x)\\delta(x-a)dx = f(a)$, we get:\n$$\n\\widetilde{Z} = w_1 z_1 + w_2 z_2\n$$\nThis is the constant mean value of the mixture fraction for all time $t \\ge 0$.\n\nNext, we analyze the evolution of any single realization, $Z(t)$, governed by the IEM model. The IEM law is a first-order linear ordinary differential equation (ODE):\n$$\n\\frac{dZ}{dt} = -\\frac{1}{\\tau_m}\\left(Z(t) - \\widetilde{Z}\\right)\n$$\nThis equation can be solved by separation of variables or by identifying it as a standard linear ODE form. Let $Y(t) = Z(t) - \\widetilde{Z}$. Then $\\frac{dY}{dt} = \\frac{dZ}{dt}$. The ODE becomes:\n$$\n\\frac{dY}{dt} = -\\frac{1}{\\tau_m}Y(t)\n$$\nThe solution to this homogeneous ODE is $Y(t) = Y(0)\\,\\exp(-t/\\tau_m)$. Substituting back for $Z(t)$:\n$$\nZ(t) - \\widetilde{Z} = \\left(Z(0) - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nThis can be rearranged to give the trajectory of any point $Z(0)$ in the scalar space:\n$$\nZ(t) = \\widetilde{Z} + \\left(Z(0) - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nThis equation describes a deterministic mapping from the scalar value at $t=0$ to the scalar value at time $t$.\n\nThe evolution of the PDF, $P(Z,t)$, under this deterministic mapping is found by transporting the initial PDF along these trajectories. The initial PDF is composed of two Dirac delta distributions located at $Z=z_1$ and $Z=z_2$. Each delta function will move according to the trajectory equation derived above.\n\nLet $z_1(t)$ be the position of the peak that was initially at $z_1 \\equiv z_1(0)$. Using the trajectory equation with $Z(0)=z_1$:\n$$\nz_1(t) = \\widetilde{Z} + \\left(z_1 - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nSimilarly, for the peak initially at $z_2 \\equiv z_2(0)$, its position $z_2(t)$ is given by:\n$$\nz_2(t) = \\widetilde{Z} + \\left(z_2 - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nSince the weights $w_1$ and $w_2$ represent conserved probabilities (or mass fractions of the delta distributions), they remain constant. Therefore, the PDF at any time $t0$ is given by the sum of the two transported delta distributions:\n$$\nP(Z,t) = w_1\\,\\delta(Z - z_1(t)) + w_2\\,\\delta(Z - z_2(t))\n$$\nThis explicitly shows how the two delta peaks move in time, relaxing exponentially towards the mean $\\widetilde{Z}$.\n\nNow, we compute the bimodality index, $B(t)$, defined as:\n$$\nB(t) = \\frac{|z_2(t) - z_1(t)|}{|z_2(0) - z_1(0)|}\n$$\nThe denominator is simply $|z_2 - z_1|$. For the numerator, we compute the difference $z_2(t) - z_1(t)$:\n$$\nz_2(t) - z_1(t) = \\left[ \\widetilde{Z} + \\left(z_2 - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right) \\right] - \\left[ \\widetilde{Z} + \\left(z_1 - \\widetilde{Z}\\right) \\exp\\left(-\\frac{t}{\\tau_m}\\right) \\right]\n$$\n$$\nz_2(t) - z_1(t) = \\left[ (z_2 - \\widetilde{Z}) - (z_1 - \\widetilde{Z}) \\right] \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\n$$\nz_2(t) - z_1(t) = (z_2 - z_1) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nTaking the absolute value of this difference:\n$$\n|z_2(t) - z_1(t)| = \\left|(z_2 - z_1) \\exp\\left(-\\frac{t}{\\tau_m}\\right)\\right|\n$$\nSince $t \\ge 0$ and $\\tau_m  0$, the exponential term $\\exp(-t/\\tau_m)$ is always non-negative. Thus:\n$$\n|z_2(t) - z_1(t)| = |z_2 - z_1| \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nFinally, we substitute this result into the definition of $B(t)$:\n$$\nB(t) = \\frac{|z_2 - z_1| \\exp\\left(-\\frac{t}{\\tau_m}\\right)}{|z_2 - z_1|}\n$$\nGiven that $z_1 \\neq z_2$, the term $|z_2 - z_1|$ is non-zero and can be cancelled from the numerator and denominator. This yields the closed-form expression for the bimodality index:\n$$\nB(t) = \\exp\\left(-\\frac{t}{\\tau_m}\\right)\n$$\nThis result shows that the distance between the two modes of the PDF decays exponentially with a characteristic time equal to the micro-mixing timescale $\\tau_m$, which is the expected physical behavior of the IEM model.",
            "answer": "$$\\boxed{\\exp\\left(-\\frac{t}{\\tau_m}\\right)}$$"
        },
        {
            "introduction": "While mixing models describe the physics, their implementation in particle-based solvers relies on statistical representation, which introduces sampling error. This practice bridges the gap between statistical theory and computational practice by applying the Central Limit Theorem to a fundamental question: how many particles are needed to estimate a mean quantity to a desired precision? Answering this question is a critical step in assessing the reliability of simulation results and managing computational cost. ",
            "id": "4068300",
            "problem": "In a transported Probability Density Function (PDF) particle-based Monte Carlo solver for turbulent reacting flow, consider a single computational cell in which the mean of a scalar observable $Q$ (for example, a thermochemical quantity such as temperature or a species mass fraction) is estimated from $N$ statistically independent particle samples. Assume that the particle samples are independent and identically distributed with a finite variance $\\sigma^{2}$ that is known a priori from prior runs or theoretical considerations. You wish to construct a two-sided confidence interval at confidence level $1-\\alpha$ for the mean value $\\mu$ of $Q$, based on the Monte Carlo sample mean, and you require that the total width of this interval be no greater than a prescribed tolerance $\\Delta$.\n\nStarting from the definition of the sample mean and the statement of the Central Limit Theorem (CLT), derive the expression for the minimum number of particles $N$ required so that, under the Gaussian approximation implied by the CLT and for a two-sided confidence level $1-\\alpha$, the confidence interval for the mean has total width $\\Delta$. Express your result in terms of $\\Delta$, $\\sigma^{2}$, and the two-sided standard normal quantile $z_{1-\\alpha/2}$.\n\nThen evaluate this requirement numerically for a case representative of a nonpremixed turbulent flame simulation in which the scalar variance is $\\sigma^{2} = 9.0 \\times 10^{4}$, the desired confidence level is $1-\\alpha = 0.99$, and the prescribed total interval width is $\\Delta = 20$. Use the two-sided Gaussian quantile value $z_{0.995} = 2.576$ (four significant figures) for your calculation, and report the minimal integer $N$ that guarantees the interval width requirement under the Gaussian approximation.",
            "solution": "Let the $N$ particle samples of the scalar observable $Q$ be represented by the independent and identically distributed (i.i.d.) random variables $Q_1, Q_2, \\dots, Q_N$. Each sample is drawn from a distribution with a finite mean $\\mu$ and a finite variance $\\sigma^2$. The sample mean, $\\bar{Q}_N$, is the estimator for the population mean $\\mu$ and is defined as:\n$$ \\bar{Q}_N = \\frac{1}{N} \\sum_{i=1}^{N} Q_i $$\nThe expected value of the sample mean is $E[\\bar{Q}_N] = \\mu$, making it an unbiased estimator. The variance of the sample mean is given by $\\text{Var}(\\bar{Q}_N)$, which, for i.i.d. samples, simplifies to:\n$$ \\text{Var}(\\bar{Q}_N) = \\text{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} Q_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\text{Var}(Q_i) = \\frac{N\\sigma^2}{N^2} = \\frac{\\sigma^2}{N} $$\nThe standard deviation of the sample mean, known as the standard error, is therefore $\\sigma_{\\bar{Q}_N} = \\frac{\\sigma}{\\sqrt{N}}$.\n\nAccording to the Central Limit Theorem (CLT), for a sufficiently large number of samples $N$, the probability distribution of the sample mean $\\bar{Q}_N$ approaches a normal (Gaussian) distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$. We can express this as $\\bar{Q}_N \\approx \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{N}\\right)$.\n\nTo construct a confidence interval, we define a standardized variable $Z$ which, under the CLT, follows the standard normal distribution $\\mathcal{N}(0, 1)$:\n$$ Z = \\frac{\\bar{Q}_N - \\mu}{\\sigma / \\sqrt{N}} $$\nFor a two-sided confidence interval with a confidence level of $1-\\alpha$, we seek a range for $\\mu$ such that the following probability statement holds:\n$$ P(-z_{1-\\alpha/2} \\le Z \\le z_{1-\\alpha/2}) = 1-\\alpha $$\nwhere $z_{1-\\alpha/2}$ is the upper-tail critical value of the standard normal distribution corresponding to a cumulative probability of $1-\\frac{\\alpha}{2}$.\n\nSubstituting the expression for $Z$ into the inequality:\n$$ P\\left(-z_{1-\\alpha/2} \\le \\frac{\\bar{Q}_N - \\mu}{\\sigma/\\sqrt{N}} \\le z_{1-\\alpha/2}\\right) = 1-\\alpha $$\nWe can rearrange this inequality to isolate the unknown mean $\\mu$:\n$$ -z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le \\bar{Q}_N - \\mu \\le z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} $$\n$$ -\\bar{Q}_N - z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le -\\mu \\le -\\bar{Q}_N + z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} $$\nMultiplying by $-1$ and reversing the inequalities yields:\n$$ \\bar{Q}_N - z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le \\mu \\le \\bar{Q}_N + z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} $$\nThis defines the confidence interval for $\\mu$. The total width of this interval, $W$, is the difference between the upper and lower bounds:\n$$ W = \\left(\\bar{Q}_N + z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}}\\right) - \\left(\\bar{Q}_N - z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}}\\right) = 2 z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} $$\nThe problem requires that this width be no greater than a prescribed tolerance $\\Delta$. Thus, we set up the following inequality:\n$$ 2 z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le \\Delta $$\nTo find the minimum number of particles $N$, we solve for $N$:\n$$ \\frac{2 z_{1-\\alpha/2} \\sigma}{\\Delta} \\le \\sqrt{N} $$\nSquaring both sides (which are positive) preserves the inequality:\n$$ \\left(\\frac{2 z_{1-\\alpha/2} \\sigma}{\\Delta}\\right)^2 \\le N $$\nThis can be rewritten in terms of the variance $\\sigma^2$ as requested:\n$$ N \\ge \\frac{4 z_{1-\\alpha/2}^2 \\sigma^2}{\\Delta^2} $$\nThis is the derived expression for the minimum number of particles $N$ required.\n\nNext, we evaluate this expression numerically with the given values:\n- Variance $\\sigma^2 = 9.0 \\times 10^4$\n- Confidence level $1-\\alpha = 0.99$, which implies $\\alpha = 0.01$ and $\\frac{\\alpha}{2} = 0.005$.\n- Standard normal quantile $z_{1-\\alpha/2} = z_{1-0.005} = z_{0.995} = 2.576$.\n- Total interval width tolerance $\\Delta = 20$.\n\nSubstituting these values into the inequality for $N$:\n$$ N \\ge \\frac{4 \\times (2.576)^2 \\times (9.0 \\times 10^4)}{(20)^2} $$\n$$ N \\ge \\frac{4 \\times (2.576)^2 \\times 90000}{400} $$\n$$ N \\ge (2.576)^2 \\times \\frac{90000}{100} $$\n$$ N \\ge (6.635776) \\times (900) $$\n$$ N \\ge 5972.1984 $$\nSince the number of particles $N$ must be an integer, we must choose the smallest integer that satisfies this condition. Therefore, the minimal number of particles required is:\n$$ N_{\\text{min}} = \\lceil 5972.1984 \\rceil = 5973 $$",
            "answer": "$$\\boxed{5973}$$"
        },
        {
            "introduction": "A model's predictive power hinges on the quality of its parameters. The IEM mixing model, for instance, is governed by a mixing timescale, $ \\tau_m $, which is not a universal constant and must be related to the local turbulent flow conditions. This practice simulates a key task in model development: calibrating the parameter $ \\tau_m $ by comparing the model's prediction for variance decay against \"ground truth\" data from a Direct Numerical Simulation (DNS). This exercise demonstrates how fundamental models are connected to and validated against high-fidelity data, making them useful for practical engineering simulations. ",
            "id": "4068262",
            "problem": "You are asked to validate micromixing closures used in stochastic solvers for probability density function (PDF) transport in computational combustion by calibrating the micromixing time scale and comparing predicted scalar variance decay to direct numerical simulation (DNS) data in homogeneous turbulence. Consider a passive scalar field with homogeneous and isotropic turbulent flow, no mean shear, and no external sources, so that the mean scalar remains constant and only the variance decays due to micromixing. For both a particle-based Monte Carlo solver using the Interaction by Exchange with the Mean (IEM) micromixing closure and an Eulerian Stochastic Fields (ESF) solver with linear relaxation, the instantaneous scalar in each particle or field obeys a linear relaxation to the mean.\n\nStarting from the fundamental passive scalar transport equation in incompressible flow and the definition of variance for a scalar field, derive a variance decay equation consistent with these micromixing closures. Then, given DNS data for variance decay in homogeneous turbulence, infer calibrated values of the micromixing time scale $ \\tau_m $ or equivalent model parameters that best match the decay.\n\nAssume the following fundamental base:\n- The instantaneous passive scalar $ Z(\\mathbf{x},t) $ has mean $ \\langle Z \\rangle $ and variance $ \\sigma^2(t) = \\langle (Z - \\langle Z \\rangle)^2 \\rangle $.\n- Homogeneous turbulence with no mean scalar production or external sources implies $ d\\langle Z \\rangle/dt = 0 $.\n- Particle-based Monte Carlo with the Interaction by Exchange with the Mean (IEM) micromixing closure is represented by a linear relaxation of the form $ dZ_p/dt = -(Z_p - \\langle Z \\rangle)/\\tau_m $, where $ Z_p $ is the scalar carried by a particle.\n- Eulerian Stochastic Fields (ESF) with linear relaxation is represented by $ d\\phi_n/dt = -(\\phi_n - \\langle \\phi \\rangle)/\\tau_m $ for each stochastic field $ \\phi_n $, with ensemble mean $ \\langle \\phi \\rangle $.\n\nYour program must:\n1. Derive the variance decay equation implied by these closures in homogeneous turbulence and use it to construct a calibrating relation between the slope of $ \\ln \\sigma^2(t) $ and the micromixing time scale $ \\tau_m $.\n2. Implement two calibration strategies:\n   - Particle Monte Carlo (IEM-based) calibration by estimating the slope of $ \\ln \\sigma^2(t) $ versus $ t $ using least squares and inferring $ \\tau_m $ from the slope.\n   - Eulerian Stochastic Fields (ESF-based) calibration by minimizing the sum of squared errors between DNS variance $ \\sigma^2_{\\mathrm{DNS}}(t) $ and the predicted $ \\sigma^2_{\\mathrm{model}}(t;\\tau_m) $ using nonlinear least squares.\n\nThe DNS test suite provides time-series data for three scientifically plausible cases of homogeneous turbulence. Time is in seconds and variance is dimensionless. Use the provided data exactly:\n\n- Case $ 1 $ (happy path, fast mixing): times $ [0.0, 0.05, 0.1, 0.2, 0.4, 0.8] $; DNS variances $ [1.0, 0.6753200460, 0.4463289641, 0.2038965180, 0.0397622040, 0.0017658580] $.\n- Case $ 2 $ (slow mixing, long-time decay): times $ [0.0, 1.0, 2.0, 5.0, 10.0] $; DNS variances $ [1.0, 0.6603200460, 0.4643289640, 0.1303352830, 0.0203156390] $.\n- Case $ 3 $ (small initial variance, moderate mixing): times $ [0.0, 0.1, 0.2, 0.5, 1.0] $; DNS variances $ [0.01, 0.00675320046, 0.00447328964, 0.00136335283, 0.00018315639] $.\n\nYour program must:\n- For each case, compute two calibrated micromixing time scales in seconds: $ \\tau_m^{\\mathrm{MC}} $ from the IEM-based slope fit, and $ \\tau_m^{\\mathrm{ESF}} $ from nonlinear least squares minimization using the ESF variance prediction model $ \\sigma^2_{\\mathrm{model}}(t;\\tau_m) = \\sigma^2(0) \\exp(-2 t / \\tau_m) $.\n- Express each calibrated $ \\tau_m $ in seconds, rounded to six decimal places.\n- Produce a single line of output containing the six calibrated values in the order $ [\\tau_m^{\\mathrm{MC},1}, \\tau_m^{\\mathrm{ESF},1}, \\tau_m^{\\mathrm{MC},2}, \\tau_m^{\\mathrm{ESF},2}, \\tau_m^{\\mathrm{MC},3}, \\tau_m^{\\mathrm{ESF},3}] $.\n\nScientific realism constraints:\n- Ensure that variance values are strictly positive when taking logarithms.\n- Avoid using any external data; use the provided test suite only.\n- Use seconds as the unit for time and $ \\tau_m $; variance is dimensionless.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $ [result1,result2,result3] $), with each result rounded to six decimal places and expressed in seconds.",
            "solution": "The problem statement has been validated and is determined to be self-contained, scientifically grounded, and well-posed. The task is to derive a variance decay model from micromixing closures and use it to calibrate the micromixing time scale $ \\tau_m $ against provided Direct Numerical Simulation (DNS) data.\n\n### Step 1: Derivation of the Variance Decay Equation\n\nWe begin with the definition of the variance of a scalar field $ Z(\\mathbf{x},t) $, denoted as $ \\sigma^2(t) $:\n$$ \\sigma^2(t) = \\langle (Z - \\langle Z \\rangle)^2 \\rangle $$\nwhere $ \\langle \\cdot \\rangle $ represents the ensemble averaging operator.\n\nTo find the rate of change of the variance, we differentiate this definition with respect to time $ t $:\n$$ \\frac{d\\sigma^2}{dt} = \\frac{d}{dt} \\langle (Z - \\langle Z \\rangle)^2 \\rangle $$\n\nFor statistically homogeneous flows, the time derivative and averaging operators commute. Applying the chain rule for differentiation, we get:\n$$ \\frac{d\\sigma^2}{dt} = \\left\\langle 2 (Z - \\langle Z \\rangle) \\frac{d}{dt} (Z - \\langle Z \\rangle) \\right\\rangle $$\n\nExpanding the derivative term inside the average gives:\n$$ \\frac{d}{dt} (Z - \\langle Z \\rangle) = \\frac{dZ}{dt} - \\frac{d\\langle Z \\rangle}{dt} $$\n\nThe problem states that for the case of a passive scalar in homogeneous turbulence with no mean production or sources, the mean scalar is constant. Therefore, $ d\\langle Z \\rangle/dt = 0 $. This simplifies the above expression to:\n$$ \\frac{d}{dt} (Z - \\langle Z \\rangle) = \\frac{dZ}{dt} $$\n\nSubstituting this back into the equation for the rate of change of variance:\n$$ \\frac{d\\sigma^2}{dt} = \\left\\langle 2 (Z - \\langle Z \\rangle) \\frac{dZ}{dt} \\right\\rangle $$\n\nNow, we introduce the micromixing model. Both the Interaction by Exchange with the Mean (IEM) closure for particle Monte Carlo methods and the linear relaxation model for Eulerian Stochastic Fields (ESF) are represented by the same form. For any individual realization (a particle's scalar value $ Z_p $ or a stochastic field value $ \\phi_n $, which we generically denote as $ Z $), the evolution is a linear relaxation towards the mean:\n$$ \\frac{dZ}{dt} = -\\frac{Z - \\langle Z \\rangle}{\\tau_m} $$\nwhere $ \\tau_m $ is the characteristic micromixing time scale.\n\nSubstituting this model into our equation for $ d\\sigma^2/dt $:\n$$ \\frac{d\\sigma^2}{dt} = \\left\\langle 2 (Z - \\langle Z \\rangle) \\left( -\\frac{Z - \\langle Z \\rangle}{\\tau_m} \\right) \\right\\rangle $$\n\nWe can pull the constant $ -2/\\tau_m $ outside the averaging operator:\n$$ \\frac{d\\sigma^2}{dt} = -\\frac{2}{\\tau_m} \\langle (Z - \\langle Z \\rangle)^2 \\rangle $$\n\nRecognizing that $ \\langle (Z - \\langle Z \\rangle)^2 \\rangle $ is the definition of the variance $ \\sigma^2 $, we arrive at the final ordinary differential equation (ODE) for variance decay:\n$$ \\frac{d\\sigma^2}{dt} = -\\frac{2}{\\tau_m} \\sigma^2(t) $$\n\n### Step 2: Solution of the ODE and Calibration Relations\n\nThe derived ODE is a first-order linear homogeneous differential equation. It can be solved by separation of variables with the initial condition $ \\sigma^2(t=0) = \\sigma^2(0) $:\n$$ \\int_{\\sigma^2(0)}^{\\sigma^2(t)} \\frac{d\\tilde{\\sigma}^2}{\\tilde{\\sigma}^2} = \\int_0^t -\\frac{2}{\\tau_m} d\\tilde{t} $$\n$$ \\ln(\\sigma^2(t)) - \\ln(\\sigma^2(0)) = -\\frac{2}{\\tau_m} t $$\n\nThis yields two useful forms for our calibration strategies. First, the explicit solution for $ \\sigma^2(t) $:\n$$ \\sigma^2(t) = \\sigma^2(0) \\exp\\left(-\\frac{2t}{\\tau_m}\\right) $$\nThis model is directly used in the non-linear least squares calibration for the ESF-based method.\n\nSecond, the linear relationship in logarithmic space:\n$$ \\ln(\\sigma^2(t)) = \\left(-\\frac{2}{\\tau_m}\\right)t + \\ln(\\sigma^2(0)) $$\nThis equation has the form $ y = mx + c $, where $ y = \\ln(\\sigma^2(t)) $, $ x = t $, the intercept is $ c = \\ln(\\sigma^2(0)) $, and the slope is $ m = -2/\\tau_m $.\n\n### Step 3: Implementation of Calibration Strategies\n\n#### Strategy 1: Particle Monte Carlo (IEM-based) Calibration\nThis method uses the linear relationship derived above. We perform a linear least squares regression on the data pairs $ (t_i, \\ln(\\sigma^2_{\\mathrm{DNS},i})) $ to find the best-fit slope $ m $. Once the slope is determined, the micromixing time scale $ \\tau_m^{\\mathrm{MC}} $ is calculated by rearranging the slope definition:\n$$ m = -\\frac{2}{\\tau_m^{\\mathrm{MC}}} \\implies \\tau_m^{\\mathrm{MC}} = -\\frac{2}{m} $$\nThis calculation will be performed using `numpy.polyfit` to find the slope $ m $.\n\n#### Strategy 2: Eulerian Stochastic Fields (ESF-based) Calibration\nThis approach directly uses the non-linear exponential decay model. The goal is to find the value of $ \\tau_m^{\\mathrm{ESF}} $ that minimizes the sum of squared errors (SSE) between the DNS data and the model predictions:\n$$ \\text{SSE}(\\tau_m) = \\sum_{i} \\left( \\sigma^2_{\\mathrm{DNS}}(t_i) - \\sigma^2_{\\mathrm{model}}(t_i; \\tau_m) \\right)^2 $$\nwhere $ \\sigma^2_{\\mathrm{model}}(t; \\tau_m) = \\sigma^2(0) \\exp(-2t/\\tau_m) $, and $ \\sigma^2(0) $ is a known value (the first point in the DNS data for each case). This non-linear minimization problem will be solved using `scipy.optimize.least_squares`. The residuals function for the optimizer is:\n$$ r_i(\\tau_m) = \\sigma^2_{\\mathrm{DNS}}(t_i) - \\sigma^2(0) \\exp(-2t_i/\\tau_m) $$\nA good initial guess for the iterative solver is the value obtained from the linear fit, $ \\tau_m^{\\mathrm{MC}} $.\n\nThe following program will implement these two strategies for each of the three provided DNS test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef solve():\n    \"\"\"\n    Validates micromixing closures by calibrating the micromixing time scale\n    tau_m against DNS data for scalar variance decay in homogeneous turbulence.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"times\": np.array([0.0, 0.05, 0.1, 0.2, 0.4, 0.8]),\n            \"variances\": np.array([1.0, 0.6753200460, 0.4463289641, 0.2038965180, 0.0397622040, 0.0017658580])\n        },\n        {\n            \"times\": np.array([0.0, 1.0, 2.0, 5.0, 10.0]),\n            \"variances\": np.array([1.0, 0.6603200460, 0.4643289640, 0.1303352830, 0.0203156390])\n        },\n        {\n            \"times\": np.array([0.0, 0.1, 0.2, 0.5, 1.0]),\n            \"variances\": np.array([0.01, 0.00675320046, 0.00447328964, 0.00136335283, 0.00018315639])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        times = case[\"times\"]\n        variances = case[\"variances\"]\n\n        # --- Strategy 1: Particle Monte Carlo (IEM-based) Calibration ---\n        # This method performs a linear least squares fit on the transformed data:\n        # ln(sigma^2(t)) = - (2/tau_m) * t + ln(sigma^2(0))\n        # The slope 'm' of this line is -2/tau_m.\n        \n        # Take the natural logarithm of the variance data.\n        # The problem states variances are strictly positive, so no check is needed.\n        log_variances = np.log(variances)\n        \n        # Use polyfit to find the slope (m) and intercept (c) of the best-fit line.\n        # We only need the slope.\n        slope, _ = np.polyfit(times, log_variances, 1)\n        \n        # Calculate tau_m_MC from the slope.\n        # tau_m = -2 / slope\n        tau_m_mc = -2.0 / slope\n        results.append(tau_m_mc)\n\n        # --- Strategy 2: Eulerian Stochastic Fields (ESF-based) Calibration ---\n        # This method minimizes the sum of squared errors between the DNS data\n        # and the model sigma^2(t) = sigma^2(0) * exp(-2*t/tau_m) using\n        # non-linear least squares.\n        \n        sigma_sq_0 = variances[0]\n\n        # Define the residual function for the non-linear optimizer.\n        # It calculates the difference between DNS data and the model prediction.\n        def residuals(tau_m_array, t, sigma_sq_dns):\n            tau_m = tau_m_array[0]\n            # Handle potential non-positive tau_m during optimization iterations.\n            if tau_m = 0:\n                return np.full_like(sigma_sq_dns, 1e10) # Return a large error\n            \n            model_prediction = sigma_sq_0 * np.exp(-2.0 * t / tau_m)\n            return sigma_sq_dns - model_prediction\n\n        # Use the result from the linear fit as a good initial guess.\n        initial_guess = [tau_m_mc]\n\n        # Perform the non-linear least squares optimization.\n        # bounds=(0, np.inf) ensures the physical constraint tau_m  0\n        opt_result = least_squares(residuals, initial_guess, args=(times, variances), bounds=(0, np.inf))\n        \n        # The optimized value of tau_m is the solution.\n        tau_m_esf = opt_result.x[0]\n        results.append(tau_m_esf)\n\n    # Final print statement in the exact required format.\n    # Each result is formatted to six decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}