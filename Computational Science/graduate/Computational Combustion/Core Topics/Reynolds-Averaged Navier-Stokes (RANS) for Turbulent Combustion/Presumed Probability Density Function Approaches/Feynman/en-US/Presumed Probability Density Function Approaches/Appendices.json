{
    "hands_on_practices": [
        {
            "introduction": "Before applying any presumed PDF model, it is crucial to understand the fundamental constraints imposed by physics. A conserved scalar like the mixture fraction $Z$ is physically bounded, typically $0 \\le Z \\le 1$, which imposes a strict mathematical constraint on its mean $\\mu_Z$ and variance $\\sigma_Z^2$. This exercise guides you to derive this \"realizability constraint\" from first principles and grasp its profound physical implications for turbulent combustion modeling .",
            "id": "4053719",
            "problem": "Consider a filtered conserved scalar known as the mixture fraction $Z$ in computational combustion, defined so that $Z \\in [0,1]$ with $Z=0$ representing pure oxidizer and $Z=1$ representing pure fuel. In presumed probability density function approaches, $Z$ within a numerical cell is treated as a random variable with mean $\\mu_{Z}=\\mathbb{E}[Z]$ and variance $\\sigma_{Z}^{2}=\\mathbb{V}[Z]$, and the subgrid-scale distribution of $Z$ is often approximated by a Beta probability density function. Starting from the foundational property that $Z$ is a bounded random variable on $[0,1]$, derive the realizability constraint that limits $\\sigma_{Z}^{2}$ as a function of $\\mu_{Z}$. Use this constraint to characterize the admissible range of $\\sigma_{Z}^{2}$ for a given $\\mu_{Z} \\in (0,1)$, and then show how this constraint manifests in the positivity of the Beta shape parameters when the Beta distribution is parameterized to match the given $\\mu_{Z}$ and $\\sigma_{Z}^{2}$.\n\nFinally, discuss the physical implications in computational combustion modeling if a numerical scheme in a cell produces a variance that violates this realizability constraint. Your discussion should explain what violation implies about the underlying subgrid-scale scalar field and the consequences for closures that rely on the presumed probability density function. Conclude by reporting the closed-form expression for the maximum admissible variance as a function of $\\mu_{Z}$. Express the final reported maximum variance as a dimensionless analytic expression. No rounding is required.",
            "solution": "The problem asks for the derivation of the realizability constraint for the variance of the mixture fraction, its connection to the Beta probability density function (PDF), and the physical implications of its violation in computational combustion.\n\nFirst, we derive the realizability constraint for the variance $\\sigma_{Z}^{2}$ of the conserved scalar $Z$, given its mean $\\mu_{Z}$. The problem states that the mixture fraction $Z$ is a random variable bounded on the interval $[0, 1]$.\n\nBy definition, the variance is given by:\n$$\n\\sigma_{Z}^{2} = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2\n$$\nwhere $\\mathbb{E}[\\cdot]$ denotes the expectation operator. The mean is $\\mu_{Z} = \\mathbb{E}[Z]$. The expression for the variance can thus be written as:\n$$\n\\sigma_{Z}^{2} = \\mathbb{E}[Z^2] - \\mu_{Z}^{2}\n$$\nThe crucial physical constraint is that $Z$ is bounded:\n$$\n0 \\le Z \\le 1\n$$\nThis implies that $Z^2$ is also bounded by the same values, since for any $z \\in [0, 1]$, $z^2 \\le z$. Thus, we can write the inequality for the random variable $Z$:\n$$\nZ^2 \\le Z\n$$\nTaking the expectation of both sides of this inequality, and using the linearity of the expectation operator, we obtain:\n$$\n\\mathbb{E}[Z^2] \\le \\mathbb{E}[Z]\n$$\nSubstituting $\\mathbb{E}[Z] = \\mu_{Z}$, we have:\n$$\n\\mathbb{E}[Z^2] \\le \\mu_{Z}\n$$\nNow, we can substitute this upper bound for $\\mathbb{E}[Z^2]$ back into the equation for the variance:\n$$\n\\sigma_{Z}^{2} = \\mathbb{E}[Z^2] - \\mu_{Z}^{2} \\le \\mu_{Z} - \\mu_{Z}^{2}\n$$\nThis gives us the upper bound for the variance:\n$$\n\\sigma_{Z}^{2} \\le \\mu_{Z}(1-\\mu_{Z})\n$$\nBy definition, variance must be non-negative, so $\\sigma_{Z}^{2} \\ge 0$. Combining these, the realizability constraint defines the admissible range for the variance of a scalar bounded in $[0, 1]$:\n$$\n0 \\le \\sigma_{Z}^{2} \\le \\mu_{Z}(1-\\mu_{Z})\n$$\nThis is the fundamental realizability constraint derived from the boundedness of the mixture fraction $Z$.\n\nNext, we analyze how this constraint manifests when the subgrid-scale distribution of $Z$ is modeled by a Beta PDF. The Beta distribution for a random variable $X$ on $[0,1]$ is defined by two positive shape parameters, $\\alpha > 0$ and $\\beta > 0$. Its PDF is given by:\n$$\np(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n$$\nwhere $B(\\alpha, \\beta)$ is the Beta function. The mean $\\mu_X$ and variance $\\sigma_X^2$ of a Beta-distributed random variable are:\n$$\n\\mu_X = \\frac{\\alpha}{\\alpha + \\beta}\n$$\n$$\n\\sigma_X^2 = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n$$\nIn the context of presumed PDF modeling, we are given the mean $\\mu_{Z}$ and variance $\\sigma_{Z}^{2}$ from the solution of their transport equations, and we need to find the corresponding Beta parameters $\\alpha$ and $\\beta$. Let us re-parameterize in terms of $\\mu_{Z}$ and a combined parameter $S = \\alpha + \\beta$:\n$$\n\\mu_{Z} = \\frac{\\alpha}{S} \\implies \\alpha = S \\mu_{Z}\n$$\n$$\n1 - \\mu_{Z} = 1 - \\frac{\\alpha}{S} = \\frac{S-\\alpha}{S} = \\frac{\\beta}{S} \\implies \\beta = S(1-\\mu_{Z})\n$$\nThe variance can be expressed as:\n$$\n\\sigma_{Z}^{2} = \\frac{(S \\mu_{Z})(S(1-\\mu_{Z}))}{S^2(S+1)} = \\frac{\\mu_{Z}(1-\\mu_{Z})}{S+1}\n$$\nWe can solve this for $S$:\n$$\nS+1 = \\frac{\\mu_{Z}(1-\\mu_{Z})}{\\sigma_{Z}^{2}} \\implies S = \\frac{\\mu_{Z}(1-\\mu_{Z})}{\\sigma_{Z}^{2}} - 1\n$$\nFor the Beta distribution to be well-defined, its shape parameters must be positive: $\\alpha > 0$ and $\\beta > 0$. Substituting the expressions for $\\alpha$ and $\\beta$ in terms of $S$ and $\\mu_{Z}$:\n$$\n\\alpha = S \\mu_{Z} > 0\n$$\n$$\n\\beta = S (1-\\mu_{Z}) > 0\n$$\nGiven that $\\mu_{Z} \\in (0, 1)$, both $\\mu_{Z}$ and $(1-\\mu_{Z})$ are positive. Therefore, the conditions $\\alpha > 0$ and $\\beta > 0$ are both satisfied if and only if $S > 0$.\nThe condition $S > 0$ translates to:\n$$\n\\frac{\\mu_{Z}(1-\\mu_{Z})}{\\sigma_{Z}^{2}} - 1 > 0\n$$\n$$\n\\frac{\\mu_{Z}(1-\\mu_{Z})}{\\sigma_{Z}^{2}} > 1\n$$\nSince variance $\\sigma_{Z}^{2}$ is non-negative (and for a non-trivial distribution, strictly positive), we can multiply both sides by $\\sigma_{Z}^{2}$ without changing the inequality's direction:\n$$\n\\mu_{Z}(1-\\mu_{Z}) > \\sigma_{Z}^{2}\n$$\nThis demonstrates that the requirement for the existence of a valid Beta PDF with positive shape parameters is that the variance must be strictly less than the maximum possible variance. The boundary case $\\sigma_{Z}^{2} = \\mu_{Z}(1-\\mu_{Z})$ corresponds to $S \\to 0$, which implies infinite values for the PDF at $0$ and $1$, representing a bimodal distribution consisting of two delta functions at $Z=0$ and $Z=1$. This limiting case is a Bernoulli distribution, which is the distribution of maximum variance for a given mean on $[0,1]$.\n\nFinally, we discuss the physical implications of violating this constraint. If a numerical scheme used to solve the transport equations for $\\mu_{Z}$ and $\\sigma_{Z}^{2}$ produces a pair of values in a computational cell such that $\\sigma_{Z}^{2} > \\mu_{Z}(1-\\mu_{Z})$, this state is termed \"unrealizable\". This is a numerical artifact, not a physical possibility. The violation implies that no random variable bounded on $[0,1]$ can possess such a mean and variance. The underlying subgrid-scale scalar field represented by this pair of moments must mathematically have parts of its distribution outside the interval $[0,1]$, meaning $Z  0$ or $Z > 1$. This is physically impossible, as the mixture fraction represents a mass fraction.\n\nThe consequences for closures that rely on a presumed PDF are severe. If one attempts to calculate the Beta shape parameters $\\alpha$ and $\\beta$ using an unrealizable pair $(\\mu_{Z}, \\sigma_{Z}^{2})$, the term $S = \\alpha+\\beta$ will be negative. This would lead to negative values for $\\alpha$ and/or $\\beta$ (depending on the sign of $S$ and the value of $\\mu_Z$), which do not define a valid probability distribution. Any subsequent calculation that uses this presumed PDF, such as computing mean reaction rates, temperature, or density by integrating over the PDF, would yield nonsensical, unphysical results, or potentially cause numerical failures (e.g., floating-point exceptions). Therefore, numerical methods for turbulent combustion must incorporate mechanisms, often called \"realizability limiters,\" to ensure that the transported moments always satisfy the realizability constraints.\n\nThe closed-form expression for the maximum admissible variance as a function of the mean mixture fraction $\\mu_Z$ is the upper bound of the derived realizability constraint.\n\nThe maximum admissible variance is:\n$$\n\\sigma_{Z, \\text{max}}^{2} = \\mu_{Z}(1-\\mu_{Z})\n$$\nThis expression is inherently dimensionless as both $\\mu_Z$ and $\\sigma_Z^2$ are derived from the dimensionless scalar $Z$.",
            "answer": "$$\\boxed{\\mu_{Z}(1-\\mu_{Z})}$$"
        },
        {
            "introduction": "With the realizability constraint established , the next practical step is to connect the moments of the mixture fraction, which are transported in a RANS or LES simulation, to the parameters of the presumed PDF. This practice focuses on deriving the explicit formulas to calculate the Beta PDF shape parameters $\\alpha$ and $\\beta$ from a given mean $\\mu$ and variance $\\sigma^2$ . This procedure is the core mechanism for constructing the PDF in each computational cell, and it directly depends on the variance being admissible.",
            "id": "4053753",
            "problem": "In turbulent nonpremixed combustion modeling, the mixture fraction $Z \\in [0,1]$ is often treated with a presumed probability density function (PDF) closure. A common choice is the Beta distribution on $[0,1]$ with positive shape parameters $\\alpha$ and $\\beta$. Consider a single computational cell from a Reynolds-Averaged Navier–Stokes (RANS) simulation, where the cell-averaged mean and variance of the mixture fraction are reported as $\\mu$ and $\\sigma^{2}$, respectively. Starting from the definition of the Beta probability density function on $[0,1]$,\n$$\np_{Z}(z;\\alpha,\\beta)=\\frac{z^{\\alpha-1}(1-z)^{\\beta-1}}{B(\\alpha,\\beta)}, \\quad 0 \\le z \\le 1, \\quad \\alpha0,\\ \\beta0,\n$$\ntogether with the standard definitions of the mean and variance of a continuous random variable,\n$$\n\\mu=\\mathbb{E}[Z]=\\int_{0}^{1} z\\,p_{Z}(z;\\alpha,\\beta)\\,dz, \\quad \\sigma^{2}=\\operatorname{Var}(Z)=\\int_{0}^{1} (z-\\mu)^{2}\\,p_{Z}(z;\\alpha,\\beta)\\,dz,\n$$\nderive closed-form expressions for $\\alpha(\\mu,\\sigma^{2})$ and $\\beta(\\mu,\\sigma^{2})$. From your expressions, obtain a necessary and sufficient admissibility condition on $\\sigma^{2}$, expressed solely in terms of $\\mu$, that guarantees $\\alpha0$ and $\\beta0$.\n\nThen, for the specific RANS-reported values $\\mu=0.35$ and $\\sigma^{2}=0.040$, compute the corresponding shape parameters $\\alpha$ and $\\beta$. Define the admissibility indicator\n$$\nI=\\begin{cases}\n1,  \\text{if the variance is admissible under the Beta presumed PDF for the given }\\mu,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nReport the final result as the row vector $\\big[\\alpha\\ \\ \\beta\\ \\ I\\big]$. Round $\\alpha$ and $\\beta$ to four significant figures. The mixture fraction is dimensionless; express your final result as dimensionless numbers.",
            "solution": "The problem requires the derivation of expressions for the shape parameters, $\\alpha$ and $\\beta$, of a Beta probability density function (PDF) in terms of its mean, $\\mu$, and variance, $\\sigma^2$. Subsequently, an admissibility condition on $\\sigma^2$ must be found, and finally, numerical values for $\\alpha$, $\\beta$, and an admissibility indicator $I$ are to be computed for given $\\mu$ and $\\sigma^2$.\n\nThe Beta PDF for a random variable $Z$ on the interval $[0, 1]$ is given as:\n$$\np_{Z}(z;\\alpha,\\beta)=\\frac{z^{\\alpha-1}(1-z)^{\\beta-1}}{B(\\alpha,\\beta)}, \\quad 0 \\le z \\le 1, \\quad \\alpha0,\\ \\beta0\n$$\nwhere $B(\\alpha,\\beta)$ is the Beta function, $B(\\alpha,\\beta) = \\int_{0}^{1} t^{\\alpha-1}(1-t)^{\\beta-1} dt$. The Beta function is related to the Gamma function $\\Gamma(x)$ by $B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$. A key property of the Gamma function is $\\Gamma(x+1) = x\\Gamma(x)$.\n\nFirst, we derive the expression for the mean $\\mu = \\mathbb{E}[Z]$ using its definition:\n$$\n\\mu = \\mathbb{E}[Z] = \\int_{0}^{1} z\\, p_{Z}(z;\\alpha,\\beta)\\,dz = \\frac{1}{B(\\alpha,\\beta)}\\int_{0}^{1} z \\cdot z^{\\alpha-1}(1-z)^{\\beta-1}\\,dz = \\frac{1}{B(\\alpha,\\beta)}\\int_{0}^{1} z^{\\alpha}(1-z)^{\\beta-1}\\,dz\n$$\nThe integral in the numerator is the definition of $B(\\alpha+1, \\beta)$. Therefore,\n$$\n\\mu = \\frac{B(\\alpha+1, \\beta)}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+1)\\Gamma(\\beta)}{\\Gamma(\\alpha+1+\\beta)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\n$$\nUsing the Gamma function property, $\\Gamma(\\alpha+1) = \\alpha\\Gamma(\\alpha)$ and $\\Gamma(\\alpha+\\beta+1) = (\\alpha+\\beta)\\Gamma(\\alpha+\\beta)$, we simplify the expression:\n$$\n\\mu = \\frac{\\alpha\\Gamma(\\alpha)\\Gamma(\\beta)}{(\\alpha+\\beta)\\Gamma(\\alpha+\\beta)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} = \\frac{\\alpha}{\\alpha+\\beta}\n$$\n\nNext, we derive the variance $\\sigma^2 = \\operatorname{Var}(Z) = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2$. We first compute the second moment $\\mathbb{E}[Z^2]$:\n$$\n\\mathbb{E}[Z^2] = \\int_{0}^{1} z^2 p_{Z}(z;\\alpha,\\beta)\\,dz = \\frac{1}{B(\\alpha,\\beta)}\\int_{0}^{1} z^2 \\cdot z^{\\alpha-1}(1-z)^{\\beta-1}\\,dz = \\frac{B(\\alpha+2, \\beta)}{B(\\alpha, \\beta)}\n$$\nUsing the Gamma function representation:\n$$\n\\mathbb{E}[Z^2] = \\frac{\\Gamma(\\alpha+2)\\Gamma(\\beta)}{\\Gamma(\\alpha+2+\\beta)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} = \\frac{(\\alpha+1)\\alpha\\Gamma(\\alpha)\\Gamma(\\beta)}{(\\alpha+\\beta+1)(\\alpha+\\beta)\\Gamma(\\alpha+\\beta)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} = \\frac{\\alpha(\\alpha+1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)}\n$$\nNow, we compute the variance:\n$$\n\\sigma^2 = \\mathbb{E}[Z^2] - \\mu^2 = \\frac{\\alpha(\\alpha+1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)} - \\left(\\frac{\\alpha}{\\alpha+\\beta}\\right)^2 = \\frac{\\alpha(\\alpha+1)(\\alpha+\\beta) - \\alpha^2(\\alpha+\\beta+1)}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n$$\nSimplifying the numerator:\n$$\n\\alpha[(\\alpha+1)(\\alpha+\\beta) - \\alpha(\\alpha+\\beta+1)] = \\alpha[\\alpha^2 + \\alpha\\beta + \\alpha + \\beta - \\alpha^2 - \\alpha\\beta - \\alpha] = \\alpha\\beta\n$$\nThus, the expression for the variance is:\n$$\n\\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n$$\nTo find the expressions for $\\alpha(\\mu, \\sigma^2)$ and $\\beta(\\mu, \\sigma^2)$, we invert these moment relations. Let's introduce an intermediate variable for the sum of the parameters, $S = \\alpha + \\beta$.\nFrom the expression for the mean, $\\mu = \\frac{\\alpha}{\\alpha+\\beta} = \\frac{\\alpha}{S}$, which gives $\\alpha = \\mu S$.\nSimilarly, $1-\\mu = 1 - \\frac{\\alpha}{\\alpha+\\beta} = \\frac{\\beta}{\\alpha+\\beta} = \\frac{\\beta}{S}$, which gives $\\beta = (1-\\mu)S$.\nWe can rewrite the variance expression in terms of $\\mu$ and $S$:\n$$\n\\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)} = \\left(\\frac{\\alpha}{\\alpha+\\beta}\\right)\\left(\\frac{\\beta}{\\alpha+\\beta}\\right)\\frac{1}{(\\alpha+\\beta)+1} = \\mu(1-\\mu)\\frac{1}{S+1}\n$$\nSolving for $S$:\n$$\nS+1 = \\frac{\\mu(1-\\mu)}{\\sigma^2} \\implies S = \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1\n$$\nBy substituting this expression for $S$ back into the relations for $\\alpha$ and $\\beta$, we obtain the desired closed-form expressions:\n$$\n\\alpha(\\mu, \\sigma^2) = \\mu \\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 \\right)\n$$\n$$\n\\beta(\\mu, \\sigma^2) = (1-\\mu) \\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 \\right)\n$$\nThe admissibility condition requires that the shape parameters be strictly positive: $\\alpha > 0$ and $\\beta > 0$. For a physically realistic mixture fraction, the mean must be in the range $\\mu \\in [0, 1]$. We consider the non-degenerate case where $\\mu \\in (0, 1)$, for which both $\\mu$ and $1-\\mu$ are positive. In this case, the conditions $\\alpha>0$ and $\\beta>0$ are met if and only if the common factor is positive:\n$$\n\\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 > 0\n$$\n$$\n\\frac{\\mu(1-\\mu)}{\\sigma^2} > 1\n$$\nFor a non-degenerate distribution, $\\sigma^2 > 0$. Thus, we can multiply by $\\sigma^2$ without changing the inequality:\n$$\n\\sigma^2  \\mu(1-\\mu)\n$$\nThis is the necessary and sufficient admissibility condition on $\\sigma^2$ for a given $\\mu \\in (0,1)$. The variance must lie in the range $0  \\sigma^2  \\mu(1-\\mu)$.\n\nNow, we apply these results to the given RANS-reported values: $\\mu=0.35$ and $\\sigma^{2}=0.040$.\nFirst, we check the admissibility condition. We calculate the maximum allowable variance for this mean:\n$$ \\mu(1-\\mu) = 0.35 \\times (1 - 0.35) = 0.35 \\times 0.65 = 0.2275 $$\nWe are given $\\sigma^2 = 0.040$. Comparing the given variance to the maximum allowed variance:\n$$ 0.040  0.2275 $$\nSince the condition is satisfied, the given variance is admissible for the Beta presumed PDF. The admissibility indicator is therefore $I=1$.\n\nNext, we compute the corresponding shape parameters $\\alpha$ and $\\beta$. We first evaluate the sum $S$:\n$$ S = \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1 = \\frac{0.2275}{0.040} - 1 = 5.6875 - 1 = 4.6875 $$\nNow we calculate $\\alpha$ and $\\beta$:\n$$ \\alpha = \\mu S = 0.35 \\times 4.6875 = 1.640625 $$\n$$ \\beta = (1-\\mu) S = (1 - 0.35) \\times 4.6875 = 0.65 \\times 4.6875 = 3.046875 $$\nRounding these values to four significant figures as requested:\n$$ \\alpha \\approx 1.641 $$\n$$ \\beta \\approx 3.047 $$\nThe final result is the row vector $[\\alpha\\ \\ \\beta\\ \\ I]$ containing the computed values.\nThe vector is $[1.641\\ \\ 3.047\\ \\ 1]$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 1.641  3.047  1 \\end{pmatrix}} $$"
        },
        {
            "introduction": "The ultimate purpose of the presumed PDF is to compute the filtered value of nonlinear quantities, such as species mass fractions, by integrating them against the PDF. This computational practice challenges you to implement the most efficient numerical method for this task, Gauss-Jacobi quadrature, to evaluate the defining integral for a filtered species mass fraction $\\tilde{Y_i}$ . Mastering this technique is essential for translating the abstract PDF model into concrete, accurate results within a CFD simulation.",
            "id": "4053718",
            "problem": "You are given a tabulated species mass fraction profile $Y_i(Z)$ as a function of the mixture fraction $Z \\in [0,1]$. Under the assumption of constant density so that Reynolds and density-weighted (Favre) filtering coincide, the filtered species mass fraction $\\tilde{Y_i}$ for a presumed mixture fraction Probability Density Function (PDF) is defined as the expectation\n$$\n\\tilde{Y_i} \\;=\\; \\int_{0}^{1} Y_i(Z)\\, P(Z;\\alpha,\\beta)\\, \\mathrm{d}Z,\n$$\nwhere $P(Z;\\alpha,\\beta)$ is the Beta PDF with shape parameters $\\alpha0$ and $\\beta0$, given by\n$$\nP(Z;\\alpha,\\beta) \\;=\\; \\frac{Z^{\\alpha-1}(1-Z)^{\\beta-1}}{B(\\alpha,\\beta)},\n$$\nand $B(\\alpha,\\beta)$ denotes the Beta function.\n\nStarting from the integral definition of $\\tilde{Y_i}$ and the standard form of Gauss–Jacobi quadrature on the interval $[-1,1]$ with weight $(1-x)^{a}(1+x)^{b}$, derive an algorithm to evaluate $\\tilde{Y_i}$ when $Y_i(Z)$ is available only as a tabulated function over $Z \\in [0,1]$. Your algorithm must:\n- Select an appropriate change of variables to map the Beta-weighted integral on $[0,1]$ to a Gauss–Jacobi quadrature on $[-1,1]$.\n- Use an interpolation scheme to evaluate the tabulated $Y_i(Z)$ at the quadrature nodes mapped into $Z$-space.\n- Produce a numerical estimate of $\\tilde{Y_i}$ for given $(\\alpha,\\beta)$ and a specified number of quadrature nodes $N \\in \\mathbb{N}$.\n\nTo assess and discuss the numerical accuracy of Gauss–Jacobi quadrature in this context, compute the absolute error of the Gauss–Jacobi estimate relative to a high-accuracy reference integral for a set of test cases. For each test case, the tabulated $Y_i(Z)$ must be created by sampling a known analytic profile $g(Z)$ on a uniform grid over $[0,1]$, and the reference value must be computed by adaptively integrating the analytic integrand $g(Z)\\,P(Z;\\alpha,\\beta)$ over $[0,1]$ with stringent tolerances. The interpolation and quadrature design should be chosen to avoid spurious oscillations and to maintain stability near the endpoints $Z=0$ and $Z=1$, especially for $\\alpha1$ or $\\beta1$ where the Beta PDF is singular but integrable.\n\nImplement a complete program that:\n- Constructs the tabulated $Y_i(Z)$ from the analytic $g(Z)$ for each test case using a uniform grid of at least $M=1001$ points on $[0,1]$.\n- Computes $\\tilde{Y_i}$ using Gauss–Jacobi quadrature with $N$ nodes for the Beta weight implied by $(\\alpha,\\beta)$.\n- Computes a high-accuracy reference value of $\\tilde{Y_i}$ by directly integrating $g(Z)\\,P(Z;\\alpha,\\beta)$ on $[0,1]$ with absolute and relative tolerances both set to $10^{-13}$.\n- Returns the absolute errors $|\\tilde{Y_i}^{\\text{GJ}}-\\tilde{Y_i}^{\\text{ref}}|$ as floating-point numbers for each test case.\n\nTest suite:\n- Case $1$: $\\alpha=2.5$, $\\beta=3.5$, $g(Z)=Z^{3}$, $N=2$.\n- Case $2$: $\\alpha=4.0$, $\\beta=1.5$, $g(Z)=Z^{5}$, $N=3$.\n- Case $3$: $\\alpha=0.6$, $\\beta=0.7$, $g(Z)=\\exp(2Z)$, $N=12$.\n- Case $4$: $\\alpha=0.2$, $\\beta=5.0$, $g(Z)=\\sin(\\pi Z)$, $N=24$.\n- Case $5$: $\\alpha=10.0$, $\\beta=10.0$, $g(Z)=\\cos(3Z)$, $N=8$.\n\nAll quantities are dimensionless. Angles in $g(Z)$, when present, use radians. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_k$ is the absolute error for test case $k$ expressed as a floating-point number. No other output should be produced.",
            "solution": "We begin from the definition of the filtered species mass fraction under a presumed Probability Density Function (PDF) for the mixture fraction $Z \\in [0,1]$, assuming constant density so that Reynolds and Favre filtering coincide:\n$$\n\\tilde{Y_i} \\;=\\; \\mathbb{E}\\left[ Y_i(Z) \\right] \\;=\\; \\int_0^1 Y_i(Z)\\, P(Z;\\alpha,\\beta)\\,\\mathrm{d}Z,\n$$\nwith the Beta PDF\n$$\nP(Z;\\alpha,\\beta) \\;=\\; \\frac{Z^{\\alpha-1}(1-Z)^{\\beta-1}}{B(\\alpha,\\beta)},\n$$\nwhere $B(\\alpha,\\beta)=\\dfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$.\n\nTo apply Gauss–Jacobi quadrature, recall that it approximates integrals of the form\n$$\n\\int_{-1}^{1} (1-x)^{a}(1+x)^{b} f(x)\\,\\mathrm{d}x \\;\\approx\\; \\sum_{k=1}^{N} w_k f(x_k),\n$$\nwhere $\\{x_k\\}$ and $\\{w_k\\}$ are the $N$-point Jacobi nodes and weights for exponents $a-1$ and $b-1$. We wish to evaluate\n$$\nI \\;=\\; \\int_{0}^{1} Y_i(Z)\\, Z^{\\alpha-1}(1-Z)^{\\beta-1}\\, \\mathrm{d}Z,\n$$\nand then obtain the Beta-weighted expectation by normalizing with the Beta function:\n$$\n\\tilde{Y_i} \\;=\\; \\frac{I}{B(\\alpha,\\beta)}.\n$$\nWe map $Z$ to $x$ via the affine transformation $Z=\\dfrac{x+1}{2}$ with $x\\in[-1,1]$. Then $\\mathrm{d}Z = \\dfrac{1}{2}\\mathrm{d}x$, $1-Z = \\dfrac{1-x}{2}$, and $Z = \\dfrac{1+x}{2}$. Substituting, we obtain\n\\begin{align*}\nI \\;=\\; \\int_{-1}^{1} Y_i\\!\\left(\\frac{x+1}{2}\\right)\\,\\left(\\frac{1+x}{2}\\right)^{\\alpha-1}\\!\\left(\\frac{1-x}{2}\\right)^{\\beta-1}\\,\\frac{1}{2}\\,\\mathrm{d}x \\\\\n=\\; 2^{-(\\alpha+\\beta-1)} \\int_{-1}^{1} (1-x)^{\\beta-1} (1+x)^{\\alpha-1}\\, Y_i\\!\\left(\\frac{x+1}{2}\\right)\\,\\mathrm{d}x.\n\\end{align*}\nThis is precisely in the Jacobi form with exponents\n$$\na \\;=\\; \\beta-1, \\qquad b \\;=\\; \\alpha-1,\n$$\nand integrand function\n$$\nf(x) \\;=\\; Y_i\\!\\left(\\frac{x+1}{2}\\right).\n$$\nTherefore, the $N$-point Gauss–Jacobi quadrature approximation is\n$$\nI \\;\\approx\\; 2^{-(\\alpha+\\beta-1)} \\sum_{k=1}^{N} w_k\\, Y_i\\!\\left(\\frac{x_k+1}{2}\\right),\n$$\nand the desired Beta-weighted expectation is\n$$\n\\tilde{Y_i}^{\\text{GJ}} \\;=\\; \\frac{2^{-(\\alpha+\\beta-1)}}{B(\\alpha,\\beta)} \\sum_{k=1}^{N} w_k\\, Y_i\\!\\left(\\frac{x_k+1}{2}\\right).\n$$\n\nBecause $Y_i(Z)$ is available only as a tabulated function on $Z\\in[0,1]$, we must evaluate $Y_i$ at the mapped quadrature nodes $Z_k = \\dfrac{x_k+1}{2}$. To avoid oscillations and to reproduce smooth behavior, we adopt a cubic spline interpolant. A natural or not-a-knot cubic spline is continuous with continuous first and second derivatives, is stable for smooth data, and exactly reproduces any cubic polynomial, which is advantageous for accuracy when testing polynomial profiles.\n\nFor reference values, we compute\n$$\n\\tilde{Y_i}^{\\text{ref}} \\;=\\; \\int_{0}^{1} g(Z)\\, \\frac{Z^{\\alpha-1}(1-Z)^{\\beta-1}}{B(\\alpha,\\beta)}\\, \\mathrm{d}Z,\n$$\nwhere $g(Z)$ is the analytic profile that generated the tabulation, via adaptive quadrature with absolute and relative tolerances set to $10^{-13}$. This separates the quadrature error from the interpolation error as much as possible, since the reference uses the exact analytic function.\n\nAlgorithmic steps:\n1. For each test case, define the analytic $g(Z)$ and parameters $(\\alpha,\\beta)$.\n2. Build a uniform grid $\\{Z_j\\}_{j=0}^{M-1}$ on $[0,1]$ with $M=1001$ and tabulate $Y_j=g(Z_j)$.\n3. Construct a cubic spline interpolant $S(Z)$ from the tabulation.\n4. Obtain $N$-point Jacobi nodes and weights $\\{x_k,w_k\\}$ for exponents $a=\\beta-1$ and $b=\\alpha-1$.\n5. Map $x_k \\mapsto Z_k=(x_k+1)/2$ and compute $S(Z_k)$.\n6. Form the Gauss–Jacobi estimate\n   $$\n   \\tilde{Y_i}^{\\text{GJ}} \\;=\\; \\frac{2^{-(\\alpha+\\beta-1)}}{B(\\alpha,\\beta)} \\sum_{k=1}^{N} w_k\\, S(Z_k).\n   $$\n7. Compute the reference value $\\tilde{Y_i}^{\\text{ref}}$ by adaptively integrating $g(Z) P(Z;\\alpha,\\beta)$ on $[0,1]$ with tight tolerances.\n8. Report the absolute error $|\\tilde{Y_i}^{\\text{GJ}}-\\tilde{Y_i}^{\\text{ref}}|$.\n\nAccuracy discussion:\n- For integrands of the form $Z^{m}$, Gauss–Jacobi quadrature with $N$ nodes is exact for $m \\le 2N-1$ if the integrand is evaluated exactly at quadrature nodes. Using a cubic spline interpolant preserves exactness for cubic profiles and yields high accuracy for higher-degree polynomials with sufficiently fine tabulation.\n- When $\\alpha1$ or $\\beta1$, the Beta PDF has integrable endpoint singularities. Gauss–Jacobi nodes cluster near the endpoints for such exponents, enhancing accuracy because the quadrature is optimized for the $(1-x)^{a}(1+x)^{b}$ weight. The mapping $Z=(x+1)/2$ retains this clustering near $Z=0$ and $Z=1$.\n- The dominant error sources are interpolation error (if the tabulation is coarse or the function is rapidly varying) and quadrature truncation error (finite $N$). Increasing $M$ reduces interpolation error, and increasing $N$ reduces quadrature error. The reference integral, computed with tight tolerances, serves as a proxy for the exact expectation.\n\nThe program implements the above procedure for the specified test suite and outputs the absolute errors as a single comma-separated list in brackets, suitable for automated verification. All quantities are dimensionless, and any angles in $g(Z)$ are in radians.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, beta as beta_fn\nfrom scipy.integrate import quad\nfrom scipy.interpolate import CubicSpline\n\ndef gauss_jacobi_expectation_from_tabulation(z_grid, y_grid, alpha, beta, n_nodes):\n    \"\"\"\n    Compute E[Y(Z)] under Beta(alpha,beta) using Gauss-Jacobi quadrature,\n    where Y is given as tabulated values (z_grid, y_grid) on [0,1].\n    \"\"\"\n    # Jacobi parameters for weight (1-x)^(a) (1+x)^(b)\n    a_j = beta - 1.0\n    b_j = alpha - 1.0\n    # Obtain nodes and weights on [-1,1] for Jacobi(a_j, b_j)\n    x, w = roots_jacobi(n_nodes, a_j, b_j)\n    # Map nodes to Z in [0,1]\n    z_nodes = 0.5 * (x + 1.0)\n    # Interpolate Y at z_nodes using a cubic spline\n    spline = CubicSpline(z_grid, y_grid, bc_type='not-a-knot')\n    y_nodes = spline(z_nodes)\n    # Unnormalized weighted integral over [0,1]\n    scale = 2.0 ** (-(alpha + beta - 1.0))\n    I = scale * np.dot(w, y_nodes)\n    # Normalize by Beta function to get expectation\n    return I / beta_fn(alpha, beta)\n\ndef reference_expectation_analytic(func, alpha, beta):\n    \"\"\"\n    High-accuracy reference: integrate func(z) * BetaPDF(z; alpha,beta) over [0,1].\n    \"\"\"\n    B = beta_fn(alpha, beta)\n    def integrand(z):\n        return func(z) * (z**(alpha - 1.0)) * ((1.0 - z)**(beta - 1.0)) / B\n    # Handle potential endpoint singularities robustly\n    val, _ = quad(integrand, 0.0, 1.0, epsabs=1e-13, epsrel=1e-13, limit=100, points=[0.0, 1.0])\n    return val\n\ndef build_tabulation(func, M=1001):\n    \"\"\"\n    Build a uniform tabulation of func on [0,1] with M points.\n    \"\"\"\n    z = np.linspace(0.0, 1.0, M, dtype=float)\n    y = func(z)\n    return z, y\n\ndef solve():\n    # Define analytic profiles for test cases\n    def g1(z): return z**3\n    def g2(z): return z**5\n    def g3(z): return np.exp(2.0 * z)\n    def g4(z): return np.sin(np.pi * z)\n    def g5(z): return np.cos(3.0 * z)\n\n    test_cases = [\n        # (alpha, beta, function g(z), N nodes)\n        (2.5, 3.5, g1, 2),\n        (4.0, 1.5, g2, 3),\n        (0.6, 0.7, g3, 12),\n        (0.2, 5.0, g4, 24),\n        (10.0, 10.0, g5, 8),\n    ]\n\n    results = []\n    # Build a sufficiently fine tabulation to reduce interpolation error\n    M = 1001\n    for alpha, beta, g, n in test_cases:\n        z_grid, y_grid = build_tabulation(g, M=M)\n        gj_est = gauss_jacobi_expectation_from_tabulation(z_grid, y_grid, alpha, beta, n)\n        ref = reference_expectation_analytic(g, alpha, beta)\n        err = abs(gj_est - ref)\n        results.append(err)\n\n    # Format output as a single line with comma-separated floats (scientific notation), no spaces.\n    print(\"[\" + \",\".join(f\"{r:.12e}\" for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}