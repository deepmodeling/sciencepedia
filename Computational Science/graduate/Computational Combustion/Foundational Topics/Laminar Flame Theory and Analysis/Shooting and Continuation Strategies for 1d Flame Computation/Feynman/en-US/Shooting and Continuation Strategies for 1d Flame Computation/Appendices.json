{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex codes, it is crucial to understand the mathematical structure of the flame problem. This exercise treats the one-dimensional flame as a trajectory in phase space and asks you to determine the conditions for its existence using principles from dynamical systems theory. By performing a dimension-counting analysis , you will discover why a parameter like the flame speed $s$ cannot be pre-specified but must be solved for as part of the problem, a foundational concept in computing freely propagating waves.",
            "id": "4062376",
            "problem": "Consider a one-dimensional, steady, planar, freely propagating premixed flame in a frame moving with an unknown speed $s$ relative to the laboratory frame. The governing equations are the steady species and energy conservation laws with molecular diffusion and a one-step reaction, written in the moving frame. After nondimensionalization and introducing first-order variables for gradients, the steady boundary value problem reduces to an autonomous first-order ordinary differential equation (ODE) system of the form\n$$\n\\frac{d\\mathbf{u}}{dx}=\\mathbf{f}(\\mathbf{u};s), \\quad \\mathbf{u}\\in\\mathbb{R}^{n},\n$$\nwith $n=4$ arising from two second-order scalar balance equations (species and energy). Far-field boundary conditions are the unburned state $\\mathbf{u}^{-}$ as $x\\to -\\infty$ and the burned state $\\mathbf{u}^{+}$ as $x\\to +\\infty$. Assume $\\mathbf{u}^{-}$ and $\\mathbf{u}^{+}$ are hyperbolic equilibria of the ODE for fixed $s$ and that the linearizations about these equilibria have spectra\n$$\n\\sigma\\big(D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{-};s)\\big)=\\{\\,0.38,\\;1.27,\\;-0.19,\\;-2.41\\,\\},\n$$\n$$\n\\sigma\\big(D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{+};s)\\big)=\\{\\,-0.81,\\;-0.22,\\;0.36,\\;0.59\\,\\}.\n$$\nTreat $x$ as the independent variable in the dynamical-systems sense. You aim to compute the flame by a shooting method that launches along the unstable manifold of the unburned equilibrium and targets the stable manifold of the burned equilibrium. In a continuation framework, you may vary a set of $p$ scalar continuation parameters (including, but not limited to, the wave speed $s$). Because the problem is translation invariant in $x$, you impose a single scalar phase condition to fix the spatial shift during shooting.\n\nStarting from conservation-law structure and dynamical-systems definitions of stable and unstable manifolds, derive the dimension-counting condition that determines the minimal number of scalar continuation parameters $p$ required so that a transverse heteroclinic connection from $\\mathbf{u}^{-}$ to $\\mathbf{u}^{+}$ can be found by shooting while using one scalar phase condition to remove translational invariance. Then, using the provided spectra, evaluate the minimal $p$ for this $n=4$ flame model. Give your final answer as a single integer with no units.",
            "solution": "The problem requires the derivation of a dimension-counting condition to determine the minimal number of continuation parameters, $p$, needed to compute a one-dimensional, steady flame structure using a shooting method. This structure corresponds to a heteroclinic orbit connecting an unburned equilibrium state $\\mathbf{u}^{-}$ to a burned equilibrium state $\\mathbf{u}^{+}$ in an $n$-dimensional state space.\n\nLet the governing autonomous ordinary differential equation (ODE) system be\n$$\n\\frac{d\\mathbf{u}}{dx} = \\mathbf{f}(\\mathbf{u}; \\mathbf{q}),\n$$\nwhere $\\mathbf{u} \\in \\mathbb{R}^n$ is the state vector and $\\mathbf{q} \\in \\mathbb{R}^p$ is a vector of $p$ scalar continuation parameters. A solution representing the flame profile is a trajectory that connects the two equilibria: $\\lim_{x\\to-\\infty} \\mathbf{u}(x) = \\mathbf{u}^{-}$ and $\\lim_{x\\to+\\infty} \\mathbf{u}(x) = \\mathbf{u}^{+}$. In the language of dynamical systems, this trajectory is a heteroclinic orbit.\n\nSuch an orbit must lie in the intersection of the unstable manifold of the starting equilibrium, $W^u(\\mathbf{u}^{-})$, and the stable manifold of the ending equilibrium, $W^s(\\mathbf{u}^{+})$. The dimensions of these invariant manifolds are determined by the spectra of the linearized system at the equilibria. Let $J^{-} = D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{-}; \\mathbf{q})$ and $J^{+} = D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{+}; \\mathbf{q})$ be the Jacobian matrices at the unburned and burned states, respectively. The dimension of the unstable manifold of an equilibrium is the number of eigenvalues of its Jacobian with a positive real part. The dimension of the stable manifold is the number of eigenvalues with a negative real part. The problem states that the equilibria are hyperbolic, which means there are no eigenvalues with zero real part.\n\nLet $d_u^{-} = \\dim(W^u(\\mathbf{u}^{-}))$ be the number of eigenvalues of $J^{-}$ with $\\Re(\\lambda) > 0$.\nLet $d_s^{+} = \\dim(W^s(\\mathbf{u}^{+}))$ be the number of eigenvalues of $J^{+}$ with $\\Re(\\lambda) < 0$.\n\nThe heteroclinic orbit, being a solution to an autonomous ODE, is not a single point but a one-dimensional curve due to the system's translational invariance in the independent variable $x$. If $\\mathbf{u}(x)$ is a solution, then so is $\\mathbf{u}(x+c)$ for any constant shift $c$. Therefore, a robustly found heteroclinic connection should correspond to a one-dimensional intersection of $W^u(\\mathbf{u}^{-})$ and $W^s(\\mathbf{u}^{+})$.\n\nAccording to transversality theory, the dimension of the intersection of two manifolds $M_1$ and $M_2$ in an ambient space $A$ is given by $\\dim(M_1 \\cap M_2) = \\dim(M_1) + \\dim(M_2) - \\dim(A)$, provided the intersection is transverse. For our problem, the manifolds are $W^u(\\mathbf{u}^{-})$ and $W^s(\\mathbf{u}^{+})$, and the ambient space is the state space $\\mathbb{R}^n$. For a fixed set of parameters $\\mathbf{q}$, the condition for a one-dimensional transverse intersection is:\n$$\n1 = d_u^{-} + d_s^{+} - n.\n$$\nRearranging gives the condition for the existence of a structurally stable heteroclinic orbit without the need for adjustable parameters:\n$$\nd_u^{-} + d_s^{+} = n+1.\n$$\nIf this equality does not hold, the manifolds generally do not intersect in the desired one-dimensional manner. The codimension of this desired intersection, which represents the number of constraints that are not satisfied, is given by $C = (n+1) - (d_u^{-} + d_s^{+})$. To satisfy these constraints and force the manifolds to intersect appropriately, we must introduce a number of free parameters equal to this codimension. Therefore, the minimal number of continuation parameters $p$ required is:\n$$\np = n+1 - (d_u^{-} + d_s^{+}).\n$$\nThis assumes $p \\ge 0$. If the sum of dimensions is already large enough, no parameters are needed, so more formally $p = \\max(0, n+1 - (d_u^{-} + d_s^{+}))$.\n\nThis same result can be derived from the perspective of a numerical shooting method. In shooting, we aim to solve a system of algebraic equations where the number of variables equals the number of equations.\nThe variables are:\n1.  The parameters used to specify an initial condition on the $d_u^{-}$-dimensional unstable manifold $W^u(\\mathbf{u}^{-})$. This gives $d_u^{-}$ variables.\n2.  The $p$ continuation parameters $\\mathbf{q}$.\nTotal variables = $d_u^{-} + p$.\n\nThe equations are:\n1.  The conditions required for the computed trajectory to land on the $d_s^{+}$-dimensional stable manifold $W^s(\\mathbf{u}^{+})$. This manifold can be defined by $n - d_s^{+}$ equations in $\\mathbb{R}^n$.\n2.  A single scalar phase condition to remove the translational degree of freedom and select a unique solution from the one-parameter family of shifted solutions. This gives $1$ equation.\nTotal equations = $(n - d_s^{+}) + 1$.\n\nEquating the number of variables and equations for a well-posed root-finding problem:\n$$\nd_u^{-} + p = n - d_s^{+} + 1.\n$$\nSolving for $p$, we obtain the same dimension-counting condition:\n$$\np = n+1 - d_u^{-} - d_s^{+}.\n$$\nNow, we apply this condition to the specific problem. The given parameters are:\nThe dimension of the state space is $n=4$.\n\nThe spectrum of the Jacobian at the unburned state $\\mathbf{u}^{-}$ is given as $\\sigma\\big(D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{-};s)\\big)=\\{\\,0.38,\\;1.27,\\;-0.19,\\;-2.41\\,\\}$.\nThe eigenvalues with positive real parts are $0.38$ and $1.27$. Thus, the dimension of the unstable manifold at $\\mathbf{u}^{-}$ is $d_u^{-} = 2$.\n\nThe spectrum of the Jacobian at the burned state $\\mathbf{u}^{+}$ is given as $\\sigma\\big(D_{\\mathbf{u}}\\mathbf{f}(\\mathbf{u}^{+};s)\\big)=\\{\\,-0.81,\\;-0.22,\\;0.36,\\;0.59\\,\\}$.\nThe eigenvalues with negative real parts are $-0.81$ and $-0.22$. Thus, the dimension of the stable manifold at $\\mathbf{u}^{+}$ is $d_s^{+} = 2$.\n\nWe have all the necessary values:\n$n = 4$\n$d_u^{-} = 2$\n$d_s^{+} = 2$\n\nSubstituting these values into the derived formula for the minimal number of continuation parameters $p$:\n$$\np = n+1 - (d_u^{-} + d_s^{+})\n$$\n$$\np = 4+1 - (2 + 2)\n$$\n$$\np = 5 - 4\n$$\n$$\np = 1\n$$\nThe minimal number of continuation parameters required is $1$. This is consistent with the physical nature of freely propagating flames, where the flame speed $s$ is typically an unknown eigenvalue of the problem that must be determined along with the solution profile, thus serving as the single required continuation parameter.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Building upon the theoretical foundation, this practice moves to a hands-on coding exercise focused on a key application of continuation: detecting bifurcations. You will work with a canonical equation that models flame ignition and extinction, implementing a shooting method to find the critical parameter values where new solutions emerge. This exercise  provides a concrete look at how numerical continuation techniques are used to map out the rich behavior and stability limits of combustion systems.",
            "id": "4062369",
            "problem": "Consider a canonical one-dimensional steady reaction–diffusion model for a premixed flame in a thermally diffusive regime, posed on a dimensionless spatial interval $x \\in [0,1]$. In the near-onset regime and after appropriate nondimensionalization, amplitude reductions of the conservation of energy and species yield a normal-form boundary value problem for the scalar field $u(x)$ that captures the ignition–extinction balance:\n$$\n\\frac{d^2 u}{dx^2} + \\mu\\,u - u^3 = 0,\\quad x \\in (0,1),\n$$\nwith Dirichlet boundary conditions\n$$\nu(0) = 0,\\quad u(1) = 0.\n$$\nHere $u(x)$ is a dimensionless temperature or progress variable amplitude, and $\\mu$ is a dimensionless control parameter that summarizes the competition between reaction and diffusive transport. This reduced equation is a well-tested model in combustion theory near criticality and is mathematically consistent with steady one-dimensional reaction–diffusion systems under small-amplitude expansions.\n\nA standard shooting strategy reformulates the boundary value problem as an initial value problem with an unknown initial slope. Introducing $v(x) = du/dx$, the system can be written as\n$$\n\\frac{du}{dx} = v,\\qquad \\frac{dv}{dx} = -\\mu\\,u + u^3,\n$$\nwith initial conditions $u(0) = 0$ and $v(0) = s$, where $s$ is an unknown scalar chosen to satisfy the terminal boundary condition $u(1) = 0$. Define the shooting residual\n$$\nR(s;\\mu) = u(1; s, \\mu),\n$$\nthe value of $u$ at $x = 1$ resulting from integrating the initial value problem from $x=0$ to $x=1$ with initial slope $s$ and parameter $\\mu$.\n\nThe trivial branch $u(x)\\equiv 0$ satisfies the boundary conditions for all $\\mu$, and corresponds to $s=0$. Bifurcations that generate nontrivial branches can be detected by loss of invertibility of the shooting map at $s=0$, which is equivalent to the vanishing of the shooting Jacobian\n$$\n\\frac{\\partial R}{\\partial s}(0;\\mu) = \\lim_{s\\to 0} \\frac{R(s;\\mu)}{s}.\n$$\nBy linearizing the system at $u=0$ (which suppresses the cubic term), the derivative $\\partial R/\\partial s$ reduces to the boundary evaluation of the solution of the linear ordinary differential equation $\\tfrac{d^2 u}{dx^2} + \\mu u = 0$ with initial conditions $u(0)=0$, $u'(0)=1$. This yields the explicit formula\n$$\n\\frac{\\partial R}{\\partial s}(0;\\mu) = \\frac{\\sin(\\sqrt{\\mu})}{\\sqrt{\\mu}}.\n$$\nBranch points occur at parameter values where $\\frac{\\partial R}{\\partial s}(0;\\mu) = 0$, i.e., at\n$$\n\\mu_n = n^2 \\pi^2,\\quad n \\in \\mathbb{N}.\n$$\n\nYour task is to implement a program that, using shooting-based bifurcation detection and parameter continuation by bracketing, performs the following computations:\n\n1. For a given single parameter value $\\,\\mu\\,$, compute and return the absolute value of the shooting Jacobian magnitude\n$$\nD(\\mu) = \\left|\\frac{\\partial R}{\\partial s}(0;\\mu)\\right| = \\left|\\frac{\\sin(\\sqrt{\\mu})}{\\sqrt{\\mu}}\\right|.\n$$\n\n2. For a given parameter interval $[\\mu_a,\\mu_b]$ with $\\mu_a < \\mu_b$, use a continuation-by-bracketing strategy to locate a branch point $\\mu^\\star \\in [\\mu_a,\\mu_b]$ by finding a root of the scalar function $\\tfrac{\\partial R}{\\partial s}(0;\\mu)$, i.e.,\n$$\n\\frac{\\partial R}{\\partial s}(0;\\mu^\\star) = 0,\n$$\nand return the value $\\mu^\\star$ as a floating-point number.\n\nYou must implement the root-finding step using a robust bracketed solver applied to the function $\\tfrac{\\partial R}{\\partial s}(0;\\mu)$, and the detection of bifurcation is equivalent to detecting a sign change of this function across the interval followed by refinement to a root. This embodies a simple but effective parameter continuation strategy.\n\nUse the following test suite of parameter values:\n\n- Test case 1 (single value): $\\mu = 8.0$.\n- Test case 2 (interval): $[\\mu_a,\\mu_b] = [9.0, 10.5]$.\n- Test case 3 (single value): $\\mu = 12.0$.\n- Test case 4 (interval): $[\\mu_a,\\mu_b] = [38.0, 40.0]$.\n\nAll quantities are dimensionless, so no physical units apply. Angles are not used, so no angle unit is required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, where the outputs are floats:\n$$\n[\\;D(8.0),\\ \\mu^\\star \\text{ from } [9.0,10.5],\\ D(12.0),\\ \\mu^{\\star} \\text{ from } [38.0,40.0]\\;].\n$$\nNo rounding rules are imposed; output the native floating-point representations produced by your computations.",
            "solution": "The problem statement has been validated and is determined to be sound. It is scientifically grounded in the theory of bifurcation and dynamical systems applied to a canonical combustion model, is well-posed with all necessary information provided, and is free of contradictions or ambiguities. The tasks are specified with mathematical precision.\n\nThe problem requires the implementation of two distinct computational tasks related to the bifurcation analysis of a one-dimensional reaction-diffusion equation. The analysis is based on the shooting Jacobian at the trivial solution branch, given by the function:\n$$\n\\frac{\\partial R}{\\partial s}(0;\\mu) = \\frac{\\sin(\\sqrt{\\mu})}{\\sqrt{\\mu}}\n$$\nwhere $\\mu$ is the control parameter.\n\nThe first task is to compute the absolute magnitude of this Jacobian, denoted by $D(\\mu)$, for specific values of $\\mu$. The formula is:\n$$\nD(\\mu) = \\left|\\frac{\\sin(\\sqrt{\\mu})}{\\sqrt{\\mu}}\\right|\n$$\nThis is a direct function evaluation. This calculation will be performed for the test cases where a single parameter value is provided.\n- For test case $1$, we evaluate $D(\\mu)$ at $\\mu = 8.0$:\n$$\nD(8.0) = \\left|\\frac{\\sin(\\sqrt{8.0})}{\\sqrt{8.0}}\\right|\n$$\n- For test case $3$, we evaluate $D(\\mu)$ at $\\mu = 12.0$:\n$$\nD(12.0) = \\left|\\frac{\\sin(\\sqrt{12.0})}{\\sqrt{12.0}}\\right|\n$$\n\nThe second task is to locate a branch point $\\mu^\\star$ within a given parameter interval $[\\mu_a, \\mu_b]$ using a continuation-by-bracketing strategy. A branch point from the trivial solution occurs when the Jacobian vanishes, which allows for the existence of nontrivial solutions bifurcating from the trivial one. This corresponds to finding a root of the Jacobian function:\n$$\n\\frac{\\partial R}{\\partial s}(0;\\mu^\\star) = \\frac{\\sin(\\sqrt{\\mu^\\star})}{\\sqrt{\\mu^\\star}} = 0\n$$\nFor $\\mu > 0$, the roots of this function are determined by the zeros of the numerator, $\\sin(\\sqrt{\\mu^\\star}) = 0$. This condition is satisfied when $\\sqrt{\\mu^\\star} = n\\pi$ for any non-zero integer $n \\in \\mathbb{N}$, leading to the well-known bifurcation points at $\\mu^\\star_n = n^2\\pi^2$.\n\nThe problem specifies using a robust bracketed solver. This implies applying a numerical root-finding algorithm, such as Brent's method, to the function $f(\\mu) = \\frac{\\sin(\\sqrt{\\mu})}{\\sqrt{\\mu}}$ over the given interval $[\\mu_a, \\mu_b]$. This method is appropriate as it is guaranteed to converge to a root if the function values at the interval endpoints, $f(\\mu_a)$ and $f(\\mu_b)$, have opposite signs.\n- For test case $2$, the interval is $[\\mu_a, \\mu_b] = [9.0, 10.5]$. We seek the first bifurcation point, $\\mu^\\star_1 = (1\\cdot\\pi)^2 = \\pi^2 \\approx 9.8696$. We verify that the interval brackets this root:\n  - At $\\mu_a = 9.0$, the function argument is $\\sqrt{9.0} = 3.0$. The value is $f(9.0) = \\sin(3.0)/3.0 > 0$.\n  - At $\\mu_b = 10.5$, the argument is $\\sqrt{10.5} \\approx 3.24$. Since $\\pi \\approx 3.14159$, this argument is in the interval $(\\pi, 2\\pi)$, where the sine function is negative. Thus, $f(10.5) = \\sin(\\sqrt{10.5})/\\sqrt{10.5} < 0$.\n  Since $f(\\mu_a) \\cdot f(\\mu_b) < 0$, a root exists in the interval. A numerical solver will find $\\mu^\\star \\approx 9.8696044$.\n\n- For test case $4$, the interval is $[\\mu_a, \\mu_b] = [38.0, 40.0]$. We seek the second bifurcation point, $\\mu^\\star_2 = (2\\cdot\\pi)^2 = 4\\pi^2 \\approx 39.4784$. We verify the bracket:\n  - At $\\mu_a = 38.0$, the argument is $\\sqrt{38.0} \\approx 6.164$. Since $2\\pi \\approx 6.283$, this argument is in the interval $(\\pi, 2\\pi)$, where the sine function is negative. Thus, $f(38.0) < 0$.\n  - At $\\mu_b = 40.0$, the argument is $\\sqrt(40.0) \\approx 6.325$, which is slightly greater than $2\\pi$. This argument is in $(2\\pi, 3\\pi)$, where the sine function is positive. Thus, $f(40.0) > 0$.\n  Since $f(\\mu_a) \\cdot f(\\mu_b) < 0$, a root exists and will be located numerically at $\\mu^\\star \\approx 39.4784176$.\n\nThe implementation will consist of a Python script utilizing the `numpy` library for the required mathematical functions and `scipy.optimize.brentq` as the robust bracketed solver for the root-finding tasks. The script will process each test case in order and format the results into a single comma-separated list as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating Jacobian magnitudes and finding bifurcation points\n    for the given test cases.\n    \"\"\"\n\n    # Define the shooting Jacobian function dR/ds(0, mu).\n    # This function is the one whose roots are the bifurcation points.\n    def shooting_jacobian(mu: float) -> float:\n        \"\"\"\n        Calculates the shooting Jacobian at the trivial branch for a given parameter mu.\n        The formula is sin(sqrt(mu)) / sqrt(mu).\n        \"\"\"\n        # The problem scope implies mu > 0. The test cases all satisfy this.\n        # For mu=0, the limit is 1. We handle mu > 0 as per the problem.\n        if mu <= 0:\n            # This case is not hit by the provided test suite.\n            # Returning NaN or raising an error are valid options for mu < 0.\n            # The limit as mu -> 0+ is 1.0.\n            return 1.0 if mu == 0.0 else np.nan\n        \n        sqrt_mu = np.sqrt(mu)\n        return np.sin(sqrt_mu) / sqrt_mu\n\n    # Define the tasks based on the problem description.\n    # Task 1: Compute D(mu) = |shooting_jacobian(mu)|\n    def calculate_D(mu: float) -> float:\n        \"\"\"\n        Calculates the absolute magnitude of the shooting Jacobian.\n        \"\"\"\n        return np.abs(shooting_jacobian(mu))\n\n    # Task 2: Find the root mu* in a given interval [mu_a, mu_b].\n    # This is done by finding the root of the shooting_jacobian function.\n    # scipy.optimize.brentq is a robust bracketed root-finding algorithm.\n    def find_bifurcation_point(mu_a: float, mu_b: float) -> float:\n        \"\"\"\n        Finds a root of the shooting_jacobian function within the interval [mu_a, mu_b].\n        \"\"\"\n        root = brentq(shooting_jacobian, mu_a, mu_b)\n        return root\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'single', 'value': 8.0},\n        {'type': 'interval', 'bounds': [9.0, 10.5]},\n        {'type': 'single', 'value': 12.0},\n        {'type': 'interval', 'bounds': [38.0, 40.0]},\n    ]\n    \n    results = []\n    \n    # Process each test case.\n    for case in test_cases:\n        if case['type'] == 'single':\n            # This is Task 1: compute D(mu).\n            mu = case['value']\n            result = calculate_D(mu)\n            results.append(result)\n        elif case['type'] == 'interval':\n            # This is Task 2: find mu*.\n            mu_a, mu_b = case['bounds']\n            result = find_bifurcation_point(mu_a, mu_b)\n            results.append(result)\n\n    # Final print statement in the exact required format.\n    # The format is a comma-separated list of native float representations in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "For realistic flame structures, especially those with high activation energy, the governing equations become numerically \"stiff,\" posing a significant challenge for solvers. This capstone exercise requires you to implement and compare two powerful nonlinear solvers for a discretized 1D flame model: the fast but fragile direct Newton method and the more robust Pseudo-Transient Continuation (PTC) method. By analyzing their performance across different levels of stiffness , you will gain practical experience in diagnosing and overcoming the convergence issues that are central to modern computational combustion.",
            "id": "3966595",
            "problem": "Consider the one-dimensional, steady, non-dimensional reaction–diffusion model for a laminar premixed free flame with unity Lewis number, posed on the spatial interval $z \\in [0,1]$. The unknowns are the non-dimensional temperature $\\theta(z)$ and the non-dimensional fuel mass fraction $y(z)$. The governing equations are, for $z \\in (0,1)$,\n$$\n0 = \\frac{d^2 \\theta}{dz^2} + \\mathrm{Da}\\, y\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta}\\right),\n$$\n$$\n0 = \\mathrm{Le}\\, \\frac{d^2 y}{dz^2} - \\mathrm{Da}\\, y\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta}\\right),\n$$\nwith Dirichlet boundary conditions\n$$\n\\theta(0)=0,\\quad \\theta(1)=\\Theta_{\\mathrm{ad}},\\quad y(0)=1,\\quad y(1)=0.\n$$\nHere, $\\mathrm{Da}$ is the Damköhler number (the ratio of reaction to diffusion time scales), $\\beta$ is the non-dimensional activation energy parameter, $\\gamma$ is the heat-release coupling coefficient, $\\mathrm{Le}$ is the Lewis number (the ratio of thermal to mass diffusivity), and $\\Theta_{\\mathrm{ad}}$ is the non-dimensional adiabatic temperature rise. These parameters control stiffness: large $\\beta$ and large $\\mathrm{Da}$ generate an exponentially sharp reaction zone.\n\nYour task is to discretize these equations using second-order central differences on $N$ equally spaced grid points, with $N=50$. Let the grid be defined by $z_i = i\\,\\Delta z$ for $i=0,1,\\dots,N-1$, where $\\Delta z = 1/(N-1)$. Denote the discrete unknowns by $\\theta_i \\approx \\theta(z_i)$ and $y_i \\approx y(z_i)$. Construct the nonlinear residual vector $\\mathbf{F}(\\mathbf{U})=\\mathbf{0}$ for the $2N$-vector of unknowns $\\mathbf{U} = [\\theta_0,\\theta_1,\\dots,\\theta_{N-1},y_0,y_1,\\dots,y_{N-1}]^\\top$, as follows:\n\n- For interior nodes $i=1,2,\\dots,N-2$,\n$$\nF_{\\theta,i} = \\frac{\\theta_{i-1} - 2\\theta_i + \\theta_{i+1}}{\\Delta z^2} + \\mathrm{Da}\\, y_i\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right),\n$$\n$$\nF_{y,i} = \\mathrm{Le}\\, \\frac{y_{i-1} - 2 y_i + y_{i+1}}{\\Delta z^2} - \\mathrm{Da}\\, y_i\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right).\n$$\n\n- For boundary nodes,\n$$\nF_{\\theta,0} = \\theta_0 - 0,\\quad F_{\\theta,N-1} = \\theta_{N-1} - \\Theta_{\\mathrm{ad}},\n$$\n$$\nF_{y,0} = y_0 - 1,\\quad F_{y,N-1} = y_{N-1} - 0.\n$$\n\nDefine the residual norm as the Euclidean norm of the full $2N$-vector $\\mathbf{F}(\\mathbf{U})$, that is,\n$$\n\\|\\mathbf{F}(\\mathbf{U})\\|_2 = \\left( \\sum_{j=1}^{2N} F_j^2 \\right)^{1/2}.\n$$\n\nYou must implement and compare two nonlinear solvers:\n\n1. Direct Newton method (also called Newton–Raphson method): Starting from an initial guess, at each iteration $k$ form the Jacobian matrix $\\mathbf{J}(\\mathbf{U}^{(k)}) = \\partial \\mathbf{F}/\\partial \\mathbf{U}$ and solve the linear system\n$$\n\\mathbf{J}(\\mathbf{U}^{(k)})\\, \\delta^{(k)} = -\\mathbf{F}(\\mathbf{U}^{(k)}),\n$$\nthen update\n$$\n\\mathbf{U}^{(k+1)} = \\mathbf{U}^{(k)} + \\delta^{(k)}.\n$$\nTerminate when $\\|\\mathbf{F}(\\mathbf{U}^{(k+1)})\\|_2 \\le 10^{-8}$ or when the iteration count reaches a maximum of $50$.\n\n2. Pseudo-Transient Continuation (PTC): Introduce a pseudo-time and march toward steady state using backward Euler linearization with adaptive pseudo-time step. At iteration $k$, for a current pseudo-time step $\\Delta t^{(k)}$, solve\n$$\n\\left( \\frac{1}{\\Delta t^{(k)}} \\mathbf{I} + \\mathbf{J}(\\mathbf{U}^{(k)}) \\right)\\, \\delta^{(k)} = -\\mathbf{F}(\\mathbf{U}^{(k)}),\n$$\nand update\n$$\n\\mathbf{U}^{(k+1)} = \\mathbf{U}^{(k)} + \\delta^{(k)}.\n$$\nUse the following pseudo-time step control:\n- Initialize $\\Delta t^{(0)} = 10^{-4}$, with lower and upper bounds $10^{-6}$ and $10^{2}$.\n- After computing $\\mathbf{U}^{(k+1)}$, let $r^{(k)} = \\|\\mathbf{F}(\\mathbf{U}^{(k+1)})\\|_2 / \\|\\mathbf{F}(\\mathbf{U}^{(k)})\\|_2$. If $r^{(k)} < 0.7$, increase the step via $\\Delta t^{(k+1)} = \\min( 2\\, \\Delta t^{(k)}, 10^{2} )$; otherwise, decrease the step via $\\Delta t^{(k+1)} = \\max( 0.5\\, \\Delta t^{(k)}, 10^{-6} )$.\nTerminate when $\\|\\mathbf{F}(\\mathbf{U}^{(k+1)})\\|_2 \\le 10^{-8}$ or when the iteration count reaches a maximum of $200$.\n\nIn both methods, use the same initial guess:\n$$\n\\theta_i^{(0)} = \\Theta_{\\mathrm{ad}}\\, z_i,\\qquad y_i^{(0)} = 1 - z_i.\n$$\n\nDerive and implement the analytic Jacobian entries for efficiency. For each interior node $i$, the reaction term $R_i = \\mathrm{Da}\\, y_i\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right)$ has partial derivatives\n$$\n\\frac{\\partial R_i}{\\partial \\theta_i} = \\mathrm{Da}\\, y_i\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right)\\, \\frac{\\beta \\gamma}{(1+\\gamma \\theta_i)^2},\\qquad \\frac{\\partial R_i}{\\partial y_i} = \\mathrm{Da}\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right).\n$$\n\nTest Suite: Run your program on the following parameter sets, all with $\\Theta_{\\mathrm{ad}}=1$ and $\\mathrm{Le}=1$:\n- Case A (moderate stiffness): $\\mathrm{Da}=10$, $\\beta=5$, $\\gamma=4$.\n- Case B (stiff): $\\mathrm{Da}=50$, $\\beta=12$, $\\gamma=4$.\n- Case C (very stiff): $\\mathrm{Da}=100$, $\\beta=20$, $\\gamma=4$.\n\nFor each case, report four quantities for the direct Newton method and the pseudo-transient continuation method, respectively: the final residual norm and the number of iterations upon termination. If a method fails due to a linear solve error or does not reach the tolerance within the maximum iterations, report the residual norm achieved at termination and the iteration count used.\n\nFinal Output Format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[\\; r^{\\mathrm{N}}_{\\mathrm{A}},\\; i^{\\mathrm{N}}_{\\mathrm{A}},\\; r^{\\mathrm{P}}_{\\mathrm{A}},\\; i^{\\mathrm{P}}_{\\mathrm{A}},\\; r^{\\mathrm{N}}_{\\mathrm{B}},\\; i^{\\mathrm{N}}_{\\mathrm{B}},\\; r^{\\mathrm{P}}_{\\mathrm{B}},\\; i^{\\mathrm{P}}_{\\mathrm{B}},\\; r^{\\mathrm{N}}_{\\mathrm{C}},\\; i^{\\mathrm{N}}_{\\mathrm{C}},\\; r^{\\mathrm{P}}_{\\mathrm{C}},\\; i^{\\mathrm{P}}_{\\mathrm{C}} \\;],\n$$\nwhere $r$ denotes the final residual norm (a float) and $i$ denotes the iteration count (an integer). No physical units are involved since the formulation is non-dimensional. Angles are not present. Percentages are not used.",
            "solution": "The problem requires the numerical solution of a system of coupled, nonlinear boundary value problems that model a one-dimensional laminar premixed flame. The continuous governing equations are discretized using a second-order central finite difference scheme on a uniform grid, resulting in a large system of nonlinear algebraic equations of the form $\\mathbf{F}(\\mathbf{U}) = \\mathbf{0}$.\n\nThe vector of unknowns $\\mathbf{U}$ is constructed by concatenating the discrete temperature values $\\theta_i$ and the discrete fuel mass fraction values $y_i$ for all grid points $i=0, 1, \\dots, N-1$. Specifically, $\\mathbf{U} = [\\theta_0, \\dots, \\theta_{N-1}, y_0, \\dots, y_{N-1}]^\\top$, resulting in a vector of size $2N$. The residual vector $\\mathbf{F}(\\mathbf{U})$ is structured similarly, with its first $N$ components corresponding to the discrete equations for temperature, and the next $N$ components corresponding to the discrete equations for the fuel mass fraction. For the interior grid points $i=1, \\dots, N-2$, the residual equations are given by the discretized governing equations. For the boundary points $i=0$ and $i=N-1$, the residuals represent the enforcement of the Dirichlet boundary conditions.\n\nTwo iterative numerical methods are to be implemented to find the root $\\mathbf{U}$ that satisfies $\\mathbf{F}(\\mathbf{U}) = \\mathbf{0}$.\n\nFirst, the direct Newton method (Newton-Raphson) is a root-finding algorithm that begins with an initial guess $\\mathbf{U}^{(0)}$ and iteratively refines it. At each iteration $k$, the nonlinear function $\\mathbf{F}(\\mathbf{U})$ is approximated by its first-order Taylor expansion around the current iterate $\\mathbf{U}^{(k)}$:\n$$ \\mathbf{F}(\\mathbf{U}) \\approx \\mathbf{F}(\\mathbf{U}^{(k)}) + \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{U}}\\bigg|_{\\mathbf{U}^{(k)}} (\\mathbf{U} - \\mathbf{U}^{(k)}) $$\nBy setting $\\mathbf{F}(\\mathbf{U}) = \\mathbf{0}$ to find the next iterate $\\mathbf{U}^{(k+1)}$ and defining the Jacobian matrix as $\\mathbf{J}(\\mathbf{U}^{(k)}) = \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{U}}\\big|_{\\mathbf{U}^{(k)}}$, we obtain a linear system for the update step $\\delta^{(k)} = \\mathbf{U}^{(k+1)} - \\mathbf{U}^{(k)}$:\n$$ \\mathbf{J}(\\mathbf{U}^{(k)})\\, \\delta^{(k)} = -\\mathbf{F}(\\mathbf{U}^{(k)}) $$\nAfter solving for $\\delta^{(k)}$, the solution is updated via $\\mathbf{U}^{(k+1)} = \\mathbf{U}^{(k)} + \\delta^{(k)}$. This method exhibits quadratic convergence when the guess is sufficiently close to the root, but it can diverge if the initial guess is poor, especially for stiff systems where the basin of attraction is small.\n\nSecond, the Pseudo-Transient Continuation (PTC) method is a globalization technique designed to improve the robustness of the Newton method. It recasts the steady-state problem $\\mathbf{F}(\\mathbf{U})=\\mathbf{0}$ as the long-time solution of a pseudo-transient problem $\\frac{d\\mathbf{U}}{dt} = -\\mathbf{F}(\\mathbf{U})$. Applying the implicit (backward) Euler discretization in pseudo-time with a step size $\\Delta t$ gives:\n$$ \\frac{\\mathbf{U}^{(k+1)} - \\mathbf{U}^{(k)}}{\\Delta t^{(k)}} = -\\mathbf{F}(\\mathbf{U}^{(k+1)}) $$\nLinearizing the term $\\mathbf{F}(\\mathbf{U}^{(k+1)})$ around the current iterate $\\mathbf{U}^{(k)}$ as $\\mathbf{F}(\\mathbf{U}^{(k+1)}) \\approx \\mathbf{F}(\\mathbf{U}^{(k)}) + \\mathbf{J}(\\mathbf{U}^{(k)})(\\mathbf{U}^{(k+1)} - \\mathbf{U}^{(k)})$ and rearranging yields the linear system for the update $\\delta^{(k)}$:\n$$ \\left( \\frac{1}{\\Delta t^{(k)}} \\mathbf{I} + \\mathbf{J}(\\mathbf{U}^{(k)}) \\right)\\, \\delta^{(k)} = -\\mathbf{F}(\\mathbf{U}^{(k)}) $$\nwhere $\\mathbf{I}$ is the identity matrix. The term $\\frac{1}{\\Delta t^{(k)}}\\mathbf{I}$ adds to the diagonal of the Jacobian, improving the diagonal dominance and hence the conditioning of the linear system, especially for small $\\Delta t^{(k)}$. This makes the method more robust against poor initial guesses. The adaptive time-stepping strategy allows the method to take small, cautious steps when convergence is slow (by decreasing $\\Delta t^{(k)}$) and larger, more aggressive Newton-like steps when convergence is fast (by increasing $\\Delta t^{(k)}$).\n\nFor both methods, the analytical Jacobian matrix $\\mathbf{J}$ must be constructed. The Jacobian has a $2 \\times 2$ block structure corresponding to the derivatives of the $\\theta$ and $y$ residuals with respect to the $\\theta$ and $y$ variables. The entries are derived by differentiating the residual equations $F_{\\theta,i}$ and $F_{y,i}$ with respect to the variables $\\theta_j$ and $y_j$. For interior nodes, this results in a banded structure from the finite difference stencil, plus off-diagonal terms from the nonlinear reaction coupling. The derivatives of the reaction term $R_i = \\mathrm{Da}\\, y_i\\, \\exp(-\\frac{\\beta}{1+\\gamma \\theta_i})$ are given as:\n$$ \\frac{\\partial R_i}{\\partial \\theta_i} = R_i \\frac{\\beta \\gamma}{(1+\\gamma \\theta_i)^2}, \\qquad \\frac{\\partial R_i}{\\partial y_i} = \\frac{R_i}{y_i} = \\mathrm{Da}\\, \\exp\\!\\left(-\\frac{\\beta}{1+\\gamma \\theta_i}\\right) $$\nFor the boundary nodes, the residual equations are linear, leading to constant $1$ entries on the diagonal of the Jacobian.\n\nThe overall implementation proceeds by defining functions to compute the residual vector $\\mathbf{F}(\\mathbf{U})$ and the Jacobian matrix $\\mathbf{J}(\\mathbf{U})$ for any given state $\\mathbf{U}$. Then, two separate solver functions implement the iterative loops for the Newton and PTC methods, respectively, including their specific termination criteria and logic. The initial guess is constructed from the given linear profiles. The program iterates through the three specified test cases, runs both solvers for each, and collects the final residual norm and iteration count for reporting. This comparison highlights the trade-offs between the rapid convergence of the Newton method and the superior robustness of the PTC method, particularly as the problem stiffness increases with parameters $\\mathrm{Da}$ and $\\beta$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a 1D premixed flame problem using Newton and PTC methods.\n    \"\"\"\n    # --- Problem Constants ---\n    N = 50\n    DZ = 1.0 / (N - 1)\n    DZ2 = DZ * DZ\n    Z = np.linspace(0, 1, N)\n    TOL = 1e-8\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A (moderate stiffness)\n        {'Da': 10, 'beta': 5, 'gamma': 4, 'Le': 1, 'The_ad': 1},\n        # Case B (stiff)\n        {'Da': 50, 'beta': 12, 'gamma': 4, 'Le': 1, 'The_ad': 1},\n        # Case C (very stiff)\n        {'Da': 100, 'beta': 20, 'gamma': 4, 'Le': 1, 'The_ad': 1},\n    ]\n\n    # --- Helper Functions for Residual and Jacobian ---\n    \n    def compute_residual(U, params):\n        Da, beta, gamma, Le, The_ad = params['Da'], params['beta'], params['gamma'], params['Le'], params['The_ad']\n        theta = U[:N]\n        y = U[N:]\n        F = np.zeros(2 * N)\n\n        # Interior nodes\n        for i in range(1, N - 1):\n            # The reaction term argument can become large positive if (1+gamma*theta) is small or negative,\n            # leading to overflow in np.exp. Clamp the argument to a reasonable max value.\n            arg = -beta / (1.0 + gamma * theta[i]) if (1.0 + gamma * theta[i]) != 0 else np.inf\n            exp_term = np.exp(min(arg, 700)) if y[i] > 0 else 0\n            R = Da * y[i] * exp_term\n            \n            F[i] = (theta[i-1] - 2*theta[i] + theta[i+1]) / DZ2 + R\n            F[N + i] = Le * (y[i-1] - 2*y[i] + y[i+1]) / DZ2 - R\n            \n        # Boundary conditions\n        F[0] = theta[0] - 0.0\n        F[N-1] = theta[N-1] - The_ad\n        F[N] = y[0] - 1.0\n        F[2*N-1] = y[N-1] - 0.0\n        \n        return F\n\n    def compute_jacobian(U, params):\n        Da, beta, gamma, Le = params['Da'], params['beta'], params['gamma'], params['Le']\n        theta = U[:N]\n        y = U[N:]\n        J = np.zeros((2 * N, 2 * N))\n\n        # Interior nodes\n        for i in range(1, N - 1):\n            denom = 1.0 + gamma * theta[i]\n            if denom <= 0 or y[i] < 0:\n                dRd_theta, dRd_y = 0.0, 0.0\n            else:\n                arg = -beta / denom\n                exp_term = np.exp(min(arg, 700))\n                dRd_theta = Da * y[i] * exp_term * (beta * gamma) / (denom * denom)\n                dRd_y = Da * exp_term\n\n            # Block dF_theta / d_theta\n            J[i, i-1] = 1.0 / DZ2\n            J[i, i] = -2.0 / DZ2 + dRd_theta\n            J[i, i+1] = 1.0 / DZ2\n            \n            # Block dF_theta / d_y\n            J[i, N + i] = dRd_y\n            \n            # Block dF_y / d_theta\n            J[N + i, i] = -dRd_theta\n            \n            # Block dF_y / d_y\n            J[N + i, N + i - 1] = Le / DZ2\n            J[N + i, N + i]     = -2.0 * Le / DZ2 - dRd_y\n            J[N + i, N + i + 1] = Le / DZ2\n\n        # Boundary conditions\n        J[0, 0] = 1.0\n        J[N-1, N-1] = 1.0\n        J[N, N] = 1.0\n        J[2*N-1, 2*N-1] = 1.0\n        \n        return J\n\n    # --- Solver Implementations ---\n    \n    def solve_newton(U_init, params):\n        max_iter = 50\n        U = U_init.copy()\n        \n        for k in range(max_iter):\n            F = compute_residual(U, params)\n            norm_F = np.linalg.norm(F)\n            \n            if norm_F <= TOL:\n                return norm_F, k\n            \n            J = compute_jacobian(U, params)\n            \n            try:\n                delta = np.linalg.solve(J, -F)\n            except np.linalg.LinAlgError:\n                return norm_F, k\n            \n            U += delta\n            \n        final_norm = np.linalg.norm(compute_residual(U, params))\n        return final_norm, max_iter\n\n    def solve_ptc(U_init, params):\n        max_iter = 200\n        U = U_init.copy()\n        \n        dt = 1e-4\n        dt_min, dt_max = 1e-6, 1e2\n        \n        F_current = compute_residual(U, params)\n        norm_F_current = np.linalg.norm(F_current)\n\n        for k in range(max_iter):\n            if norm_F_current <= TOL:\n                return norm_F_current, k\n            \n            J = compute_jacobian(U, params)\n            A = np.identity(2 * N) * (1.0 / dt) + J\n            \n            try:\n                delta = np.linalg.solve(A, -F_current)\n            except np.linalg.LinAlgError:\n                return norm_F_current, k\n            \n            U += delta\n            \n            F_next = compute_residual(U, params)\n            norm_F_next = np.linalg.norm(F_next)\n            \n            ratio = norm_F_next / norm_F_current if norm_F_current > 1e-12 else 0.0\n            \n            if ratio < 0.7:\n                dt = min(2.0 * dt, dt_max)\n            else:\n                dt = max(0.5 * dt, dt_min)\n            \n            F_current = F_next\n            norm_F_current = norm_F_next\n\n        return norm_F_current, max_iter\n\n    # --- Main Execution Logic ---\n    results = []\n    for case in test_cases:\n        theta0 = case['The_ad'] * Z\n        y0 = 1.0 - Z\n        U0 = np.concatenate([theta0, y0])\n        \n        res_N, iter_N = solve_newton(U0, case)\n        results.extend([res_N, iter_N])\n        \n        res_P, iter_P = solve_ptc(U0, case)\n        results.extend([res_P, iter_P])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}