{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we will dissect the core engine of arc-length continuation: the predictor-corrector step. This foundational exercise focuses on a continuous stirred tank reactor (CSTR) model, a staple in combustion analysis. You will implement the essential mechanics of taking a single, robust step along a solution curve, starting from calculating the curve's local tangent, predicting a new point, and correcting back to the solution manifold using an augmented Newton system. Mastering this procedure  is the first and most critical milestone in building any continuation solver.",
            "id": "4007867",
            "problem": "A continuous stirred tank reactor (CSTR) sustaining a single irreversible exothermic reaction is modeled at steady state by two dimensionless algebraic balances derived from the conservation of species and energy. The reaction rate is approximated by the Frank-Kamenetskii form, a widely used simplification of the Arrhenius kinetics for thermally driven reactions in combustion, wherein the nondimensional rate grows exponentially with the nondimensional temperature. Let the unknowns be the nondimensional temperature $T$ and the nondimensional reactant concentration $c$, and let the control parameter be the Damköhler number $\\text{Da}$, which scales the residence time and intrinsic kinetics. The reaction rate is $r(T,c) = c \\exp(\\gamma T)$, where $\\gamma  0$ is the nondimensional activation parameter. The steady-state equations are\n$$\nF_1(T,c,\\text{Da}) = (1 - c) - \\text{Da} \\, c \\exp(\\gamma T) = 0,\n$$\n$$\nF_2(T,c,\\text{Da}) = (1 + h)(1 - T) + \\beta \\, \\text{Da} \\, c \\exp(\\gamma T) = 0,\n$$\nwhere $\\beta  0$ is the nondimensional heat-release parameter and $h  0$ is the nondimensional heat-removal coefficient; the feed and coolant temperatures and inlet concentration have been scaled to unity.\n\nArc-length continuation augments these nonlinear equations to track steady-state solution branches across turning points in the parameter $\\text{Da}$. Define the vector of variables $\\mathbf{u} = (T,c,\\text{Da})$ and the residual vector $\\mathbf{F}(\\mathbf{u}) = (F_1, F_2)$. At an operating point $\\mathbf{u}_0 = (T_0, c_0, \\text{Da}_0)$ satisfying $\\mathbf{F}(\\mathbf{u}_0) = \\mathbf{0}$, the tangent direction $\\boldsymbol{\\tau} = (\\tau_T, \\tau_c, \\tau_{\\text{Da}})$ to the solution manifold is determined by differentiating $\\mathbf{F}(\\mathbf{u}) = \\mathbf{0}$ with respect to an arclength parameter $s$ and imposing a normalization. A predictor step advances to $\\mathbf{u}_{\\text{pred}} = \\mathbf{u}_0 + \\Delta s \\, \\boldsymbol{\\tau}$ for a given arclength step size $\\Delta s$. A corrector then solves the augmented system composed of the two reactor residuals and a pseudo-arclength constraint to return to the manifold near $\\mathbf{u}_{\\text{pred}}$.\n\nYour task is to implement the following, starting from the fundamental definitions above and without relying on any pre-supplied formulas:\n1. For each specified operating point, compute a steady-state solution $(T_0,c_0)$ at the given $\\text{Da}_0$ by solving $F_1(T,c,\\text{Da}_0) = 0$ and $F_2(T,c,\\text{Da}_0) = 0$.\n2. At $\\mathbf{u}_0$, calculate the tangent direction $\\boldsymbol{\\tau}$ consistent with a unit Euclidean norm, perform a predictor step with the given $\\Delta s$, and compute the two-norm of the reactor residual $\\|\\mathbf{F}(\\mathbf{u}_{\\text{pred}})\\|_2$.\n3. Carry out a corrector step using Newton's method applied to the augmented system consisting of the two reactor equations and a pseudo-arclength constraint. Report the corrected $(T,\\text{Da})$, the two-norm of the reactor residual $\\|\\mathbf{F}(\\mathbf{u}_{\\text{corr}})\\|_2$, and the two-norm of the augmented residual $\\|\\mathbf{G}(\\mathbf{u}_{\\text{corr}})\\|_2$, where $\\mathbf{G}$ stacks the reactor residuals and the arclength constraint.\n4. All computations use the parameter values $\\gamma = 3$, $\\beta = 2$, $h = 3$. Variables $T$, $c$, and $\\text{Da}$ are nondimensional, so no physical unit conversions are required.\n\nTest Suite:\n- Case A (general case): $\\text{Da}_0 = 0.05$, initial guess $(T,c) = (1.0, 0.9)$, and $\\Delta s = 0.02$.\n- Case B (near turning point detection): scan $\\text{Da}$ uniformly over the interval $[0.01, 0.5]$ with $N = 200$ grid points. At each grid point, solve for $(T,c)$ starting from the previous solution as the initial guess and select the operating point with the smallest singular value of the Jacobian $\\partial \\mathbf{F}/\\partial (T,c)$, then set $\\Delta s = 0.01$. Use $(T,c) = (1.0, 0.8)$ as the starting guess at the first grid point.\n- Case C (small-step edge case): $\\text{Da}_0 = 0.20$, initial guess $(T,c) = (1.1, 0.5)$, and $\\Delta s = 10^{-4}$.\n\nFor each case, the program must return a list of seven floating-point numbers:\n- $T_{\\text{pred}}$, $\\text{Da}_{\\text{pred}}$, $\\|\\mathbf{F}(\\mathbf{u}_{\\text{pred}})\\|_2$, $T_{\\text{corr}}$, $\\text{Da}_{\\text{corr}}$, $\\|\\mathbf{F}(\\mathbf{u}_{\\text{corr}})\\|_2$, $\\|\\mathbf{G}(\\mathbf{u}_{\\text{corr}})\\|_2$.\nRound each number to six decimal places.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the seven-number list for a test case, in the same order as the test suite, for example, \n$[$$[T_{\\text{pred}}^{(A)},\\text{Da}_{\\text{pred}}^{(A)},\\dots]$$,$$[T_{\\text{pred}}^{(B)},\\text{Da}_{\\text{pred}}^{(B)},\\dots]$$,$$[T_{\\text{pred}}^{(C)},\\text{Da}_{\\text{pred}}^{(C)},\\dots]$$$]$.",
            "solution": "The continuous stirred tank reactor (CSTR) model is built from steady-state species and energy balances. With inlet values scaled so that the feed concentration and feed temperature are unity, and with dimensionless heat removal and release parameters $h$ and $\\beta$, the balances read\n$$\nF_1(T,c,\\text{Da}) = (1 - c) - \\text{Da} \\, c \\exp(\\gamma T) = 0,\n\\quad\nF_2(T,c,\\text{Da}) = (1 + h)(1 - T) + \\beta \\,\\text{Da}\\, c \\exp(\\gamma T) = 0.\n$$\nThese follow from equating inflow minus outflow plus reaction consumption (for species) and cooling minus heating plus reaction heat release (for energy) to zero, after nondimensionalization. The Frank-Kamenetskii approximation, $r(T,c) = c \\exp(\\gamma T)$, is a well-tested simplification of the Arrhenius rate $r \\propto c \\exp(-E/(R T_{\\text{phys}}))$ when expressed in terms of a suitable dimensionless temperature deviation; here $\\gamma$ is an effective activation parameter.\n\nTo perform arc-length continuation, we consider the manifold of solutions $\\{(T,c,\\text{Da}) : \\mathbf{F}(T,c,\\text{Da}) = \\mathbf{0}\\}$ and introduce an arclength parameter $s$ such that $(T,c,\\text{Da}) = \\mathbf{u}(s)$ traces the curve. Differentiating $\\mathbf{F}(\\mathbf{u}(s)) = \\mathbf{0}$ with respect to $s$ produces the linear relation\n$$\n\\frac{\\partial \\mathbf{F}}{\\partial (T,c)} \\begin{bmatrix}\\dfrac{dT}{ds} \\\\ \\dfrac{dc}{ds} \\end{bmatrix} + \\frac{\\partial \\mathbf{F}}{\\partial \\text{Da}} \\, \\frac{d\\,\\text{Da}}{ds} = \\mathbf{0}.\n$$\nAt a solution point $\\mathbf{u}_0 = (T_0,c_0,\\text{Da}_0)$, let $J = \\partial \\mathbf{F}/\\partial (T,c)$ be the $2\\times 2$ Jacobian and $F_{\\text{Da}} = \\partial \\mathbf{F}/\\partial \\text{Da}$ the $2\\times 1$ parameter derivative, both evaluated at $\\mathbf{u}_0$. A practical bordering strategy sets $\\dfrac{d\\,\\text{Da}}{ds} = \\tau_{\\text{Da}} = 1$, yielding the linear system\n$$\nJ \\begin{bmatrix}\\tau_T \\\\ \\tau_c \\end{bmatrix} = - F_{\\text{Da}},\n$$\nwhich can be solved for the $(T,c)$ components of the tangent. The full tangent $\\boldsymbol{\\tau} = (\\tau_T,\\tau_c,\\tau_{\\text{Da}})$ is then normalized to unit Euclidean length:\n$$\n\\boldsymbol{\\tau} \\leftarrow \\frac{\\boldsymbol{\\tau}}{\\|\\boldsymbol{\\tau}\\|_2}.\n$$\nA predictor step advances to\n$$\n\\mathbf{u}_{\\text{pred}} = \\mathbf{u}_0 + \\Delta s \\, \\boldsymbol{\\tau}.\n$$\nThe predictor generally leaves the manifold, so we correct back by solving an augmented system of three equations in the three unknowns $(T,c,\\text{Da})$:\n$$\n\\mathbf{G}(\\mathbf{u}) = \n\\begin{bmatrix}\nF_1(T,c,\\text{Da}) \\\\[4pt]\nF_2(T,c,\\text{Da}) \\\\[4pt]\ng(T,c,\\text{Da})\n\\end{bmatrix}\n= \\mathbf{0},\n\\quad\ng(T,c,\\text{Da}) = \\boldsymbol{\\tau}^\\top \\big( \\mathbf{u} - \\mathbf{u}_0 \\big) - \\Delta s,\n$$\nwhich imposes the pseudo-arclength constraint so that the corrected solution lies on the hyperplane orthogonal to the difference between the predictor and the base point while being at arclength $\\Delta s$ from $\\mathbf{u}_0$ along the tangent direction. Newton's method updates $\\mathbf{u}$ via\n$$\n\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} - \\left[ \\frac{\\partial \\mathbf{G}}{\\partial \\mathbf{u}}(\\mathbf{u}^{(k)}) \\right]^{-1} \\mathbf{G}(\\mathbf{u}^{(k)}),\n$$\nwhere the $3\\times 3$ Jacobian of $\\mathbf{G}$ is\n$$\n\\frac{\\partial \\mathbf{G}}{\\partial \\mathbf{u}} =\n\\begin{bmatrix}\n\\frac{\\partial F_1}{\\partial T}  \\frac{\\partial F_1}{\\partial c}  \\frac{\\partial F_1}{\\partial \\text{Da}} \\\\[4pt]\n\\frac{\\partial F_2}{\\partial T}  \\frac{\\partial F_2}{\\partial c}  \\frac{\\partial F_2}{\\partial \\text{Da}} \\\\[4pt]\n\\tau_T  \\tau_c  \\tau_{\\text{Da}}\n\\end{bmatrix}.\n$$\nThe derivatives for our model are obtained from the definitions of $F_1$ and $F_2$:\n$$\n\\frac{\\partial F_1}{\\partial T} = - \\text{Da} \\, c \\, \\gamma \\exp(\\gamma T),\n\\quad\n\\frac{\\partial F_1}{\\partial c} = -1 - \\text{Da} \\exp(\\gamma T),\n\\quad\n\\frac{\\partial F_1}{\\partial \\text{Da}} = - c \\exp(\\gamma T),\n$$\n$$\n\\frac{\\partial F_2}{\\partial T} = - (1 + h) + \\beta \\, \\text{Da} \\, c \\, \\gamma \\exp(\\gamma T),\n\\quad\n\\frac{\\partial F_2}{\\partial c} = \\beta \\, \\text{Da} \\exp(\\gamma T),\n\\quad\n\\frac{\\partial F_2}{\\partial \\text{Da}} = \\beta \\, c \\exp(\\gamma T).\n$$\nWe implement Newton's method with a simple backtracking line search to ensure a decrease in the norm $\\|\\mathbf{G}\\|_2$ at each iteration when possible. The correction terminates when $\\|\\mathbf{G}\\|_2$ is below a tolerance, indicating convergence to the manifold under the arclength constraint.\n\nFor each test case:\n1. Solve the steady-state equations to obtain $\\mathbf{u}_0$. In Case B, scanning over $\\text{Da}$ and selecting the point with the smallest singular value of $J$ targets a near-turning point where $J$ is nearly singular, stressing the advantage of arc-length continuation.\n2. Compute the tangent $\\boldsymbol{\\tau}$ by solving the bordered linear system with $\\tau_{\\text{Da}} = 1$ and normalize it.\n3. Predict $\\mathbf{u}_{\\text{pred}}$, and compute $\\|\\mathbf{F}(\\mathbf{u}_{\\text{pred}})\\|_2$.\n4. Correct to $\\mathbf{u}_{\\text{corr}}$ via Newton's method on $\\mathbf{G}$, and compute $\\|\\mathbf{F}(\\mathbf{u}_{\\text{corr}})\\|_2$ and $\\|\\mathbf{G}(\\mathbf{u}_{\\text{corr}})\\|_2$.\n\nFinally, we report, for each case, the seven-number list $[T_{\\text{pred}}, \\text{Da}_{\\text{pred}}, \\|\\mathbf{F}(\\mathbf{u}_{\\text{pred}})\\|_2, T_{\\text{corr}}, \\text{Da}_{\\text{corr}}, \\|\\mathbf{F}(\\mathbf{u}_{\\text{corr}})\\|_2, \\|\\mathbf{G}(\\mathbf{u}_{\\text{corr}})\\|_2]$, rounded to six decimals, as a single line containing three such lists in the order A, B, C. This procedure exercises the core principles of arc-length continuation for turning-point curves in computational combustion, demonstrating the robust tracking of steady solutions of a thermally sensitive reactor even when conventional parameter continuation fails near singular Jacobians.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import root\n\n# Model parameters (dimensionless)\ngamma = 3.0  # activation parameter in Frank-Kamenetskii approximation\nbeta = 2.0   # heat-release parameter\nh = 3.0      # heat-removal coefficient\n\ndef reaction_rate(T, c):\n    return c * np.exp(gamma * T)\n\ndef F_vec(T, c, Da):\n    r = reaction_rate(T, c)\n    F1 = (1.0 - c) - Da * r\n    F2 = (1.0 + h) * (1.0 - T) + beta * Da * r\n    return np.array([F1, F2])\n\ndef J_mat(T, c, Da):\n    r = reaction_rate(T, c)\n    dF1_dT = -Da * gamma * r\n    dF1_dc = -1.0 - Da * np.exp(gamma * T)\n    dF2_dT = -(1.0 + h) + beta * Da * gamma * r\n    dF2_dc = beta * Da * np.exp(gamma * T)\n    return np.array([[dF1_dT, dF1_dc],\n                     [dF2_dT, dF2_dc]])\n\ndef F_lambda(T, c, Da):\n    r = reaction_rate(T, c)\n    dF1_dDa = -r\n    dF2_dDa = beta * r\n    return np.array([dF1_dDa, dF2_dDa])\n\ndef solve_steady(Da, T_guess, c_guess):\n    # First attempt with provided guess\n    def fun(z):\n        return F_vec(z[0], z[1], Da)\n    z0 = np.array([T_guess, c_guess])\n    sol = root(fun, z0, method='hybr')\n    if sol.success and np.linalg.norm(sol.fun)  1e-8:\n        return sol.x[0], sol.x[1], True\n    # Second attempt: heuristic guess based on species balance ignoring energy coupling\n    T_guess2 = 1.0\n    c_guess2 = 1.0 / (1.0 + Da * np.exp(gamma * T_guess2))\n    z0b = np.array([T_guess2, c_guess2])\n    sol2 = root(fun, z0b, method='hybr')\n    if sol2.success and np.linalg.norm(sol2.fun)  1e-8:\n        return sol2.x[0], sol2.x[1], True\n    return sol2.x[0], sol2.x[1], False\n\ndef compute_tangent(T0, c0, Da0):\n    J = J_mat(T0, c0, Da0)\n    Fl = F_lambda(T0, c0, Da0)\n    # Set t_lambda = 1 and solve for (t_T, t_c): J * t_x = -F_lambda\n    try:\n        t_x = np.linalg.solve(J, -Fl)\n    except np.linalg.LinAlgError:\n        # Use least squares if singular\n        t_x, *_ = np.linalg.lstsq(J, -Fl, rcond=None)\n    tau_T, tau_c = t_x[0], t_x[1]\n    tau_Da = 1.0\n    tau = np.array([tau_T, tau_c, tau_Da])\n    # Normalize to unit Euclidean norm\n    norm_tau = np.linalg.norm(tau)\n    if norm_tau == 0.0:\n        # Fallback: choose parameter-only direction\n        tau = np.array([0.0, 0.0, 1.0])\n        norm_tau = 1.0\n    tau /= norm_tau\n    return tau\n\ndef predictor(u0, tau, ds):\n    u_pred = u0 + ds * tau\n    T_pred, c_pred, Da_pred = u_pred\n    F_norm = np.linalg.norm(F_vec(T_pred, c_pred, Da_pred))\n    return u_pred, F_norm\n\ndef corrector(u0, u_pred, tau, tol=1e-10, max_iter=25):\n    # Newton corrector for augmented system G = [F; g] = 0 with g = tau^T (u - u0) - ds\n    ds = np.dot(tau, u_pred - u0)  # nominal arc-length step used in constraint\n    u = u_pred.copy()\n    for k in range(max_iter):\n        T, c, Da = u\n        F = F_vec(T, c, Da)\n        g = np.dot(tau, u - u0) - ds\n        G = np.array([F[0], F[1], g])\n        G_norm = np.linalg.norm(G)\n        if G_norm  tol:\n            break\n        # Build Jacobian of G\n        J = J_mat(T, c, Da)\n        Fl = F_lambda(T, c, Da)\n        A = np.zeros((3, 3))\n        A[0, 0:2] = J[0, :]\n        A[1, 0:2] = J[1, :]\n        A[0, 2] = Fl[0]\n        A[1, 2] = Fl[1]\n        A[2, :] = tau\n        # Solve for Newton step\n        try:\n            step = np.linalg.solve(A, G)\n        except np.linalg.LinAlgError:\n            step, *_ = np.linalg.lstsq(A, G, rcond=None)\n        # Backtracking line search to reduce ||G||\n        alpha = 1.0\n        u_new = u - alpha * step\n        G_new = np.array([F_vec(u_new[0], u_new[1], u_new[2])[0],\n                          F_vec(u_new[0], u_new[1], u_new[2])[1],\n                          np.dot(tau, u_new - u0) - ds])\n        while np.linalg.norm(G_new) = G_norm and alpha  1e-6:\n            alpha *= 0.5\n            u_new = u - alpha * step\n            G_new = np.array([F_vec(u_new[0], u_new[1], u_new[2])[0],\n                              F_vec(u_new[0], u_new[1], u_new[2])[1],\n                              np.dot(tau, u_new - u0) - ds])\n        u = u_new\n    # Final norms\n    F_corr = F_vec(u[0], u[1], u[2])\n    g_corr = np.dot(tau, u - u0) - ds\n    F_norm = np.linalg.norm(F_corr)\n    G_norm = np.linalg.norm(np.array([F_corr[0], F_corr[1], g_corr]))\n    return u, F_norm, G_norm\n\ndef find_near_turning(Da_min, Da_max, N, T_start, c_start):\n    Das = np.linspace(Da_min, Da_max, N)\n    best = None\n    # Continuation-like scanning to improve robustness: use previous solution as next guess\n    T_guess, c_guess = T_start, c_start\n    prev_sol = None\n    for Da in Das:\n        T_sol, c_sol, ok = solve_steady(Da, T_guess, c_guess)\n        if not ok:\n            # If failed, reset guesses\n            T_guess, c_guess = 1.0, 1.0 / (1.0 + Da * np.exp(gamma * 1.0))\n            T_sol, c_sol, ok = solve_steady(Da, T_guess, c_guess)\n            if not ok:\n                continue\n        # Compute Jacobian singular values\n        J = J_mat(T_sol, c_sol, Da)\n        svals = np.linalg.svd(J, compute_uv=False)\n        smin = np.min(svals)\n        if (best is None) or (smin  best[0]):\n            best = (smin, Da, T_sol, c_sol)\n        # Update guesses for next Da\n        T_guess, c_guess = T_sol, c_sol\n        prev_sol = (T_sol, c_sol)\n    if best is None:\n        # Fallback: pick middle of range and solve\n        Da_mid = 0.5 * (Da_min + Da_max)\n        T_sol, c_sol, ok = solve_steady(Da_mid, T_start, c_start)\n        if not ok:\n            T_sol, c_sol, _ = solve_steady(Da_mid, 1.0, 1.0 / (1.0 + Da_mid * np.exp(gamma)))\n        best = (np.min(np.linalg.svd(J_mat(T_sol, c_sol, Da_mid), compute_uv=False)),\n                Da_mid, T_sol, c_sol)\n    _, Da_sel, T_sel, c_sel = best\n    return Da_sel, T_sel, c_sel\n\ndef run_case_direct(Da0, T_guess, c_guess, ds):\n    # Solve for operating point\n    T0, c0, ok = solve_steady(Da0, T_guess, c_guess)\n    # Compute tangent, predictor, corrector\n    tau = compute_tangent(T0, c0, Da0)\n    u0 = np.array([T0, c0, Da0])\n    u_pred, Fp_norm = predictor(u0, tau, ds)\n    u_corr, Fc_norm, Gc_norm = corrector(u0, u_pred, tau)\n    # Results: [T_pred, Da_pred, ||F_pred||, T_corr, Da_corr, ||F_corr||, ||G_corr||]\n    return [u_pred[0], u_pred[2], Fp_norm, u_corr[0], u_corr[2], Fc_norm, Gc_norm]\n\ndef run_case_scan(Da_min, Da_max, N, T_start, c_start, ds):\n    Da0, T0, c0 = find_near_turning(Da_min, Da_max, N, T_start, c_start)\n    tau = compute_tangent(T0, c0, Da0)\n    u0 = np.array([T0, c0, Da0])\n    u_pred, Fp_norm = predictor(u0, tau, ds)\n    u_corr, Fc_norm, Gc_norm = corrector(u0, u_pred, tau)\n    return [u_pred[0], u_pred[2], Fp_norm, u_corr[0], u_corr[2], Fc_norm, Gc_norm]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"direct\", {\"Da0\": 0.05, \"T_guess\": 1.0, \"c_guess\": 0.9, \"ds\": 0.02}),\n        (\"scan\",   {\"Da_min\": 0.01, \"Da_max\": 0.5, \"N\": 200, \"T_start\": 1.0, \"c_start\": 0.8, \"ds\": 0.01}),\n        (\"direct\", {\"Da0\": 0.20, \"T_guess\": 1.1, \"c_guess\": 0.5, \"ds\": 1e-4}),\n    ]\n\n    results = []\n    for kind, params in test_cases:\n        if kind == \"direct\":\n            res = run_case_direct(params[\"Da0\"], params[\"T_guess\"], params[\"c_guess\"], params[\"ds\"])\n        else:\n            res = run_case_scan(params[\"Da_min\"], params[\"Da_max\"], params[\"N\"],\n                                params[\"T_start\"], params[\"c_start\"], params[\"ds\"])\n        # Round each float to six decimals\n        res_rounded = [float(f\"{x:.6f}\") for x in res]\n        results.append(res_rounded)\n\n    # Final print statement in the exact required format.\n    # Single line: list of lists with comma-separated floats rounded to six decimals\n    def format_list(lst):\n        return \"[\" + \",\".join(f\"{x:.6f}\" for x in lst) + \"]\"\n    print(\"[\" + \",\".join(format_list(r) for r in results) + \"]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having mastered a single step, we now chain these steps together to trace an entire solution manifold and uncover its physical meaning. In this practice, we simplify our focus to a one-dimensional CSTR model to clearly illustrate the classic \"S-curve\" of ignition and extinction. Your task is to implement a continuation algorithm that traces this full curve through its turning points and, critically, to analyze the stability of the steady states along the way. This exercise  reveals the profound connection between the geometry of the solution curve—specifically, its folds—and the dynamic stability of the underlying physical system.",
            "id": "4007878",
            "problem": "Consider a Continuous Stirred Tank Reactor (CSTR) operating under a single-step exothermic reaction with Arrhenius kinetics. Assume a dimensionless energy balance for the reactor temperature given by the ordinary differential equation\n$$\n\\frac{dT}{dt} \\;=\\; \\left(t_f - T\\right) + \\beta\\,\\lambda\\,\\exp\\!\\left(\\!-\\frac{E}{T}\\!\\right) - \\delta\\,\\left(T - t_c\\right),\n$$\nwhere $T$ is the dimensionless reactor temperature, $t_f$ is the dimensionless feed temperature, $t_c$ is the dimensionless coolant temperature, $\\beta$ is the dimensionless heat-release coefficient, $\\lambda$ is the dimensionless Damköhler number for the reaction, $E$ is the dimensionless activation energy, and $\\delta$ is the dimensionless heat-removal coefficient. At steady state, the temperature satisfies the algebraic residual\n$$\nF(T,\\lambda) \\;=\\; \\left(t_f - T\\right) + \\beta\\,\\lambda\\,\\exp\\!\\left(\\!-\\frac{E}{T}\\!\\right) - \\delta\\,\\left(T - t_c\\right) \\;=\\; 0.\n$$\nThe classical ignition–extinction S-curve in computational combustion corresponds to the set of pairs $(T,\\lambda)$ satisfying $F(T,\\lambda)=0$ with multiple turning points (folds) where the branch changes direction with respect to $\\lambda$. The local linear stability of a steady state is determined by the eigenvalue of the Jacobian of the right-hand side evaluated at the steady state. In this single-variable setting, the eigenvalue equals the derivative\n$$\n\\frac{\\partial F}{\\partial T}(T,\\lambda) \\;=\\; -1 - \\delta + \\beta\\,\\lambda\\,\\exp\\!\\left(\\!-\\frac{E}{T}\\!\\right)\\,\\frac{E}{T^2}.\n$$\nA steady state is locally stable if $\\frac{\\partial F}{\\partial T}  0$ and locally unstable if $\\frac{\\partial F}{\\partial T}  0$. Turning points (folds) along the S-curve in the $(T,\\lambda)$-plane occur where $\\frac{d\\lambda}{dT}=0$, which, by the implicit function theorem applied to $F(T,\\lambda)=0$, coincides with $\\frac{\\partial F}{\\partial T}(T,\\lambda)=0$ provided $\\frac{\\partial F}{\\partial \\lambda}(T,\\lambda)\\neq 0$.\n\nYour task is to implement pseudo-arclength continuation to numerically trace the steady-state curve $F(T,\\lambda)=0$ through turning points, compute $\\frac{\\partial F}{\\partial T}$ along the curve, and detect changes in stability at the folds. Use the following predictor–corrector structure: the tangent direction at a point $(T,\\lambda)$ on the curve is the normalized vector $(\\,-\\frac{\\partial F}{\\partial \\lambda},\\,\\frac{\\partial F}{\\partial T}\\,)$, the predictor advances by a fixed arclength step, and the corrector solves the augmented system\n$$\n\\begin{cases}\nF(T,\\lambda) \\;=\\; 0,\\\\\nv_T\\,(T-T_{\\mathrm{prev}}) + v_\\lambda\\,(\\lambda - \\lambda_{\\mathrm{prev}}) - \\Delta s \\;=\\; 0,\n\\end{cases}\n$$\nwhere $(v_T,v_\\lambda)$ is the previous tangent, $(T_{\\mathrm{prev}},\\lambda_{\\mathrm{prev}})$ is the previous solution, and $\\Delta s$ is the prescribed arclength step.\n\nStarting from an initial temperature $T_0$, compute the corresponding $\\lambda_0$ from the algebraic constraint $F(T_0,\\lambda_0)=0$:\n$$\n\\lambda_0 \\;=\\; \\frac{(1+\\delta)\\,T_0 - (t_f + \\delta\\,t_c)}{\\beta\\,\\exp\\!\\left(\\!-\\frac{E}{T_0}\\!\\right)}.\n$$\nFrom this point, perform pseudo-arclength continuation in both tangent directions (forward and backward along the curve) to ensure coverage of all folds. Along the traced curve, classify steady-state stability via $\\frac{\\partial F}{\\partial T}$ and detect folds when $\\frac{\\partial F}{\\partial T}$ changes sign between successive corrected points or when it is sufficiently close to zero. For each detected fold, indicate whether stability changes across the fold.\n\nDesign your program to produce, for each test case, a result in the form $[n_{\\mathrm{folds}}, [b_1, b_2, \\dots, b_{n_{\\mathrm{folds}}}]]$, where $n_{\\mathrm{folds}}$ is the integer number of unique folds detected after merging duplicates found in forward and backward continuation, and $b_i$ are boolean values that are true if and only if stability changes across the corresponding fold. Aggregate the results of all test cases into a single line of output containing a comma-separated list enclosed in square brackets.\n\nImplement your solution for the following test suite of parameter sets, each specified as $(\\beta,\\delta,E,t_f,t_c,T_0,\\Delta s,N)$:\n- Case $1$ (happy path, two well-separated folds): $\\beta = 5.0$, $\\delta = 0.4$, $E = 10.0$, $t_f = 0.1$, $t_c = 4.0$, $T_0 = 2.0$, $\\Delta s = 0.05$, $N = 200$.\n- Case $2$ (alternative parameters with two folds at different temperatures): $\\beta = 3.0$, $\\delta = 0.2$, $E = 8.0$, $t_f = 0.2$, $t_c = 3.0$, $T_0 = 1.0$, $\\Delta s = 0.05$, $N = 200$.\n- Case $3$ (no folds by design via low activation energy relative to thermal offset): $\\beta = 1.0$, $\\delta = 1.0$, $E = 1.0$, $t_f = 1.0$, $t_c = 1.0$, $T_0 = 1.5$, $\\Delta s = 0.05$, $N = 150$.\n\nAll variables are dimensionless, and no physical units are required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, [[2,[True,True]],[2,[True,True]],[0,[]]].",
            "solution": "The user wants me to solve a numerical problem related to computational combustion.\n\nHere's the plan:\n1.  **Validate the Problem Statement**: I need to go through the problem validation checklist.\n    -   **Extract Givens**: I'll list all the equations, variables, and parameters provided.\n    -   **Validate**:\n        -   **Scientifically Grounded**: The problem describes a standard model for a CSTR (Continuous Stirred Tank Reactor) with Arrhenius kinetics. This is a classic problem in chemical engineering and combustion theory. The equations for the energy balance, steady-state residual, Jacobian, and initial lambda are all standard and correct. The pseudo-arclength continuation method is a well-established numerical technique for curve tracking, especially for problems with turning points. The stability criterion based on the sign of the Jacobian is also correct for this single-variable system. The physics seems sound.\n        -   **Well-Posed**: The problem asks for a numerical procedure to trace a solution curve. It provides all necessary parameters, an initial condition (via $T_0$), a step size $\\Delta s$, and the number of steps $N$. The predictor-corrector method with the specified augmented system is a standard approach. The task is to find a specific number of folds and analyze stability changes, which is a well-defined goal. The problem is well-posed for a numerical solution.\n        -   **Objective**: The language is technical and precise. There are no subjective statements. All terms are clearly defined within the context of the model.\n\n2.  **Verdict**: The problem is valid. It's a standard, albeit complex, numerical analysis problem grounded in chemical engineering.\n\n3.  **Plan the Solution**:\n    -   **Core Functions**: I'll need functions for:\n        -   `F(T, lam, params)`: The residual function $F(T, \\lambda)$.\n        -   `dF_dT(T, lam, params)`: The partial derivative $\\frac{\\partial F}{\\partial T}$.\n        -   `dF_dlam(T, lam, params)`: The partial derivative $\\frac{\\partial F}{\\partial \\lambda}$.\n    -   **Initial Point**: For each test case, I'll calculate the initial point $(T_0, \\lambda_0)$ using the provided formula for $\\lambda_0$.\n    -   **Continuation Algorithm**: This is the main part. I'll need a function `arclength_continuation` that takes a starting point, a direction (+1 for forward, -1 for backward), step size $\\Delta s$, number of steps $N$, and model parameters.\n        -   **Inside the loop (for N steps)**:\n            -   **Store Current Point**: Keep track of the current $(T, \\lambda)$.\n            -   **Compute Tangent**: Calculate the tangent vector. The problem statement says the tangent is $(\\,-\\frac{\\partial F}{\\partial \\lambda},\\,\\frac{\\partial F}{\\partial T}\\,)$. Let's verify this. The curve is defined by $F(T, \\lambda) = 0$. Differentiating with respect to an arc-length parameter $s$ gives $\\frac{\\partial F}{\\partial T} \\frac{dT}{ds} + \\frac{\\partial F}{\\partial \\lambda} \\frac{d\\lambda}{ds} = 0$. The tangent vector is $(\\frac{dT}{ds}, \\frac{d\\lambda}{ds})$. A valid tangent is any vector proportional to $(\\frac{\\partial F}{\\partial \\lambda}, -\\frac{\\partial F}{\\partial T})$. The problem statement uses $(\\,-\\frac{\\partial F}{\\partial \\lambda},\\,\\frac{\\partial F}{\\partial T}\\,)$. This is just the negative of the standard tangent. As long as it's used consistently, it's fine. It's a valid tangent vector, just pointing in the opposite direction for a given parameterization. Let's stick to the problem's definition: $(v_T, v_\\lambda) = (-\\frac{\\partial F}{\\partial \\lambda}, \\frac{\\partial F}{\\partial T})$. This vector needs to be normalized.\n            -   **Predictor Step**:\n                -   Calculate the tangent $(v_T, v_\\lambda)$ at the current point $(T_k, \\lambda_k)$.\n                -   Normalize it: $\\hat{v} = (v_T, v_\\lambda) / \\sqrt{v_T^2 + v_\\lambda^2}$.\n                -   Predict the next point: $(T_{k+1, pred}, \\lambda_{k+1, pred}) = (T_k, \\lambda_k) + \\text{direction} \\times \\Delta s \\times \\hat{v}$. The `direction` is +1 or -1.\n            -   **Corrector Step**:\n                -   Solve the augmented system of nonlinear equations for $(T_{k+1}, \\lambda_{k+1})$:\n                    $$ G(T, \\lambda) = \\begin{bmatrix} F(T, \\lambda) \\\\ v_T (T - T_k) + v_\\lambda (\\lambda - \\lambda_k) - \\Delta s \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} $$\n                    Note: The problem states the second equation is $v_T\\,(T-T_{\\mathrm{prev}}) + v_\\lambda\\,(\\lambda - \\lambda_{\\mathrm{prev}}) - \\Delta s \\;=\\; 0$. Here $(T_{\\mathrm{prev}}, \\lambda_{\\mathrm{prev}})$ is the *previous* point, so $(T_k, \\lambda_k)$. And $(v_T, v_\\lambda)$ is the *previous* tangent, so the one computed at $(T_k, \\lambda_k)$. The problem also says to do the continuation in both 'tangent directions'. This means for the forward pass, the arclength equation uses `+ds`, and for the backward pass it uses `-ds` or I use `+ds` but flip the initial tangent. Let's use the first approach. Let's call the second equation $N(T,\\lambda) = 0$.\n                -   To solve this system, I'll use Newton's method. The state vector is $\\mathbf{x} = [T, \\lambda]^T$. The system is $\\mathbf{G}(\\mathbf{x}) = \\mathbf{0}$.\n                -   The Jacobian of the augmented system is:\n                    $$ J_G = \\begin{bmatrix} \\frac{\\partial F}{\\partial T}  \\frac{\\partial F}{\\partial \\lambda} \\\\ v_T  v_\\lambda \\end{bmatrix} $$\n                    Here, $(v_T, v_\\lambda)$ is the fixed tangent from the predictor step.\n                -   The Newton iteration is: $\\mathbf{x}_{i+1} = \\mathbf{x}_i - J_G^{-1}(\\mathbf{x}_i) \\mathbf{G}(\\mathbf{x}_i)$.\n                -   The initial guess for the Newton solver is the predictor point $(T_{k+1, pred}, \\lambda_{k+1, pred})$.\n                -   I'll iterate until the norm of the residual $\\|\\mathbf{G}\\|$ is below a small tolerance.\n            -   **Store New Point and Stability**: After convergence, I have the new point $(T_{k+1}, \\lambda_{k+1})$. I'll calculate the stability indicator $S_{k+1} = \\frac{\\partial F}{\\partial T}(T_{k+1}, \\lambda_{k+1})$. Store the pair $((T, \\lambda), S)$.\n    -   **Fold Detection**:\n        -   After running the continuation for $N$ steps, I'll have a list of points and their stability values.\n        -   A fold occurs where $\\frac{\\partial F}{\\partial T} = 0$. Numerically, this means a sign change in $\\frac{\\partial F}{\\partial T}$ between two consecutive points.\n        -   So, for each pair of consecutive points $(p_k, S_k)$ and $(p_{k+1}, S_{k+1})$, if $\\text{sign}(S_k) \\neq \\text{sign}(S_{k+1})$, a fold is detected.\n        -   The problem asks to check if stability changes. By definition, a fold is where $\\frac{\\partial F}{\\partial T} = 0$. If the curve crosses this line (not just touches it), the sign of $\\frac{\\partial F}{\\partial T}$ will change, and thus stability will change. The only way stability would *not* change is if this were a higher-order turning point (a cusp), where $\\frac{\\partial F}{\\partial T}$ touches zero but doesn't cross. For a simple fold, stability always changes. The question \"indicate whether stability changes across the fold\" seems to imply this is a required check. Since a fold is detected by a sign change, the answer to this will always be `True` for the folds we detect.\n    -   **Combining Forward and Backward Runs**:\n        -   I will run the continuation for $N$ steps forward and $N$ steps backward from the initial point $(T_0, \\lambda_0)$.\n        -   This will generate two lists of folds.\n        -   I need to merge these lists and remove duplicates. A duplicate fold is one that is found in both the forward and backward passes. I can identify folds by their approximate location $(T, \\lambda)$. A simple way is to collect all detected fold points and then cluster them. If two fold points are very close (e.g., within a tolerance related to $\\Delta s$), they are considered the same fold.\n        -   Let's refine this: a fold is detected between points $k$ and $k+1$. I can use linear interpolation to get a better estimate of the fold location $(T_f, \\lambda_f)$ where $\\frac{\\partial F}{\\partial T}=0$.\n            -   Let $S_k = \\frac{\\partial F}{\\partial T}(T_k, \\lambda_k)$ and $S_{k+1} = \\frac{\\partial F}{\\partial T}(T_{k+1}, \\lambda_{k+1})$.\n            -   The interpolation factor is $\\alpha = -S_k / (S_{k+1} - S_k)$.\n            -   The fold location is $(T_f, \\lambda_f) = (1-\\alpha)(T_k, \\lambda_k) + \\alpha(T_{k+1}, \\lambda_{k+1})$.\n        -   After finding all interpolated fold locations from both forward and backward runs, I can cluster them. I'll sort them (e.g., by $T$ value) and merge any that are closer than a certain tolerance. A tolerance of $\\Delta s$ seems reasonable.\n    -   **Final Output**:\n        -   For each test case, the result is `[n_folds, [b_1, ..., b_n]]`.\n        -   `n_folds` is the number of unique folds.\n        -   `b_i` is `True` if stability changes. As argued, this should always be `True` for the folds we detect.\n\n4.  **Implementation Details**:\n    -   **Parameters**: The test cases provide $(\\beta,\\delta,E,t_f,t_c,T_0,\\Delta s,N)$. I'll pack these into a tuple or dictionary for easy passing to functions. Let's use a dictionary for clarity.\n    -   **Newton's method**: Needs a tolerance and a max number of iterations to prevent infinite loops. `tol=1e-8` and `max_iter=10` should be sufficient. The Jacobian is a 2x2 matrix, so its inverse is easy to compute analytically:\n        $$ J_G^{-1} = \\frac{1}{\\det(J_G)} \\begin{bmatrix} v_\\lambda  -\\frac{\\partial F}{\\partial \\lambda} \\\\ -v_T  \\frac{\\partial F}{\\partial T} \\end{bmatrix} $$\n        where $\\det(J_G) = \\frac{\\partial F}{\\partial T} v_\\lambda - \\frac{\\partial F}{\\partial \\lambda} v_T$. This determinant is non-zero at a simple fold, which is good. At a simple fold, $\\frac{\\partial F}{\\partial T} = 0$, but the tangent $(v_T, v_\\lambda) \\approx (-\\frac{\\partial F}{\\partial \\lambda}, 0)$ so $\\det(J_G) \\approx - \\frac{\\partial F}{\\partial \\lambda} (- \\frac{\\partial F}{\\partial \\lambda}) = (\\frac{\\partial F}{\\partial \\lambda})^2$. Sincethe problem assumes $\\frac{\\partial F}{\\partial \\lambda} \\neq 0$ at folds, the Jacobian of the augmented system is non-singular. This confirms the method is well-posed.\n    -   **Data Structures**: The path will be a list of tuples `(T, lam)`. Stability values will be a parallel list of floats. Folds will be a list of tuples `(T_fold, lam_fold)`.\n    -   **Code Structure**:\n        -   A main `solve()` function.\n        -   A loop over the test cases.\n        -   Inside the loop, a function to process one case, say `process_case(...)`.\n        -   `process_case` will call the continuation algorithm twice (forward and backward).\n        -   The continuation algorithm function `run_continuation(...)` will contain the main predictor-corrector loop.\n        -   Helper functions for `F`, `dF_dT`, `dF_dlam`.\n        -   A function to detect and interpolate folds, `find_folds(...)`.\n        -   A function to merge folds, `merge_folds(...)`.\n\nLet's write down the formulas again to be sure.\nParameters: $\\beta, \\delta, E, t_f, t_c$.\nVariables: $T, \\lambda$.\n$F(T,\\lambda) = (t_f - T) + \\beta\\,\\lambda\\,\\exp(-E/T) - \\delta\\,(T - t_c) = 0$.\n$\\frac{\\partial F}{\\partial T} = -1 - \\delta + \\beta\\,\\lambda\\,\\exp(-E/T)\\,\\frac{E}{T^2}$.\n$\\frac{\\partial F}{\\partial \\lambda} = \\beta\\,\\exp(-E/T)$.\n\nAugmented system for corrector:\n$x = [T, \\lambda]^T$\n$G(x) = \\begin{bmatrix} F(T,\\lambda) \\\\ N(T,\\lambda) \\end{bmatrix} = \\begin{bmatrix} (t_f - T) + \\beta\\,\\lambda\\,\\exp(-E/T) - \\delta\\,(T - t_c) \\\\ v_T(T-T_{prev}) + v_\\lambda(\\lambda-\\lambda_{prev}) - \\Delta s \\end{bmatrix}$\nNote: The problem text says `(T-T_prev)` and `(\\lambda - \\lambda_prev)` but the direction is also mentioned. I will use a signed step, $\\Delta s_{signed} = \\text{direction} \\times \\Delta s$.\n$N(T,\\lambda) = v_T(T-T_{prev}) + v_\\lambda(\\lambda-\\lambda_{prev}) - \\Delta s_{signed} = 0$.\nWait, the tangent definition is crucial here. Let's track the tangent direction.\nAt the first step (from $(T_0, \\lambda_0)$), how do I choose the \"forward\" direction? The S-curve usually starts at low $T$, goes up, turns back, goes down, turns again, and goes up.\nLet's say at $(T_0, \\lambda_0)$, we compute the tangent $(v_T, v_\\lambda) = (-\\frac{\\partial F}{\\partial \\lambda}, \\frac{\\partial F}{\\partial T})$. Normalise it.\nForward run: predictor is $(T_0, \\lambda_0) + \\Delta s \\times \\hat{v}$.\nBackward run: predictor is $(T_0, \\lambda_0) - \\Delta s \\times \\hat{v}$.\nThis seems correct.\n\nLet's consider the corrector equation again:\n$v_T\\,(T-T_{\\mathrm{prev}}) + v_\\lambda\\,(\\lambda - \\lambda_{\\mathrm{prev}}) - \\Delta s \\;=\\; 0$\nThis defines a hyperplane orthogonal to the tangent vector $(v_T, v_\\lambda)$ at a distance $\\Delta s$ from the point $(T_{\\mathrm{prev}}, \\lambda_{\\mathrm{prev}})$. The new point $(T, \\lambda)$ must lie on this plane. This is the \"arclength\" constraint. It seems my interpretation with `direction * ds` in the predictor and `ds` in the corrector was slightly off. The problem statement's version is the standard one. The direction of the step is taken care of by the predictor.\n\nIf the predictor step is $(T_p, \\lambda_p) = (T_k, \\lambda_k) + \\text{direction} \\times \\Delta s \\times \\hat{v}_k$, this predictor point is used as an initial guess for Newton's method. The system to solve is:\n$F(T, \\lambda) = 0$\n$N(T, \\lambda) \\equiv (T-T_k) (T_k-T_{k-1}) + (\\lambda-\\lambda_k) (\\lambda_k-\\lambda_{k-1}) - (\\Delta s)^2 = 0$ (a version with secants)\nor\n$N(T, \\lambda) \\equiv (T-T_k) v_{T,k} + (\\lambda-\\lambda_k) v_{\\lambda,k} - \\Delta s = 0$ (version with tangent)\nThe problem gives this second version. It is unusual for $\\Delta s$ to be unsigned there if we want to go backward.\nCommonly, the predictor determines the direction, and the corrector finds a nearby solution.\nLet's go with the most straightforward interpretation:\n- `cont_loop(start_point, initial_tangent, num_steps, ds)`\n    - `current_point = start_point`\n    - `current_tangent = initial_tangent` (normalized)\n    - loop `num_steps` times:\n        - `predictor_point = current_point + ds * current_tangent`\n        - `prev_point = current_point`\n        - `prev_tangent = current_tangent`\n        - `(current_point, success) = NewtonSolver(predictor_point, prev_point, prev_tangent, ds)`\n        - `new_tangent = calculate_tangent(current_point)`\n        - to ensure we don't reverse: `if dot(new_tangent, current_tangent)  0: new_tangent = -new_tangent`\n        - `current_tangent = new_tangent`\n        - store `current_point` and its stability.\n- main function:\n    - calculate `(T0, lam0)`\n    - calculate `tangent_at_0 = normalize((-dF_dlam(T0,lam0), dF_dT(T0,lam0)))`\n    - `forward_path = cont_loop((T0, lam0), tangent_at_0, N, ds)`\n    - `backward_path = cont_loop((T0, lam0), -tangent_at_0, N, ds)`\nThis seems much more robust. The `trace_curve` function takes an initial point, an initial tangent, number of steps, step size.\n\n`trace_curve(start_point, start_tangent, N, ds, params)`:\n- `path = []`\n- `current_point = start_point`\n- `current_tangent = start_tangent`\n- loop `N` times:\n    - `prev_point = current_point`\n    - `prev_tangent = current_tangent`\n    - `predictor = prev_point + ds * prev_tangent`\n    - `current_point = Newton_solve(predictor, prev_point, prev_tangent, ds, params)`\n    - `new_raw_tangent = calculate_tangent(current_point, params)`\n    - `current_tangent = normalize(new_raw_tangent)`\n    - if `dot(current_tangent, prev_tangent)  0`:\n        - `current_tangent = -current_tangent`\n    - `stability = dF_dT(current_point, params)`\n    - `path.append((current_point, stability))`\n- return `path`\n\n`Newton_solve(initial_guess, prev_point, prev_tangent, ds, params)`:\n- `(T, lam) = initial_guess`\n- loop `max_iter`:\n    - `F_val = F(T, lam, params)`\n    - `N_val = prev_tangent_T * (T - prev_point_T) + prev_tangent_lam * (lam - prev_point_lam) - ds`\n    - `residual = [F_val, N_val]`\n    - if `norm(residual)  tol`: return `(T, lam)`\n    - `dFdT_val = dF_dT(T, lam, params)`\n    - `dFdlam_val = dF_dlam(T, lam, params)`\n    - `Jac = [[dFdT_val, dFdlam_val], [prev_tangent_T, prev_tangent_lam]]`\n    - `invJac = ...`\n    - `delta = - invJac @ residual`\n    - `(T, lam) += delta`\n- return `(T, lam)` (or raise error if not converged)\n\n`find_folds(path)`:\n- `folds = []`\n- loop from `k=0` to `len(path)-2`:\n    - `(p_k, s_k) = path[k]`\n    - `(p_{k+1}, s_{k+1}) = path[k+1]`\n    - if `s_k * s_{k+1}  0`:\n        - `alpha = -s_k / (s_{k+1} - s_k)`\n        - `fold_point = p_k + alpha * (p_{k+1} - p_k)`\n        - `stability_change = True` (as `s_k` and `s_{k+1}` have different signs)\n        - `folds.append((fold_point, stability_change))`\n- return `folds`\n\n`merge_folds(folds)`:\n- If `len(folds) == 0`: return `[]`\n- Sort folds by one coordinate, e.g., `T`.\n- `unique_folds = [folds[0]]`\n- `(last_fold_pt, last_bool) = folds[0]`\n- loop through remaining sorted folds `(current_fold_pt, current_bool)`:\n    - `dist = norm(current_fold_pt - last_fold_pt)`\n    - if `dist  merge_tolerance`:\n        - `unique_folds.append((current_fold_pt, current_bool))`\n        - `last_fold_pt = current_fold_pt`\n- The `merge_tolerance` should be related to `ds`. Let's set it to `1.0 * ds`.\n- The problem output format is `[num_folds, [bool_1, ...]]`. I should extract the booleans from the `unique_folds`.\n`unique_folds = merge_folds(...)`\n`n_folds = len(unique_folds)`\n`bools = [b for pt, b in unique_folds]`\n`result = [n_folds, bools]`\nThis is a good structure.\n\nThe analytical check of the test cases discriminant confirms they are well-designed to have two, two, and zero folds, respectively. My numerical plan aligns with these expectations. The entire problem is validated as sound and self-contained.\n\n### Solution Design\n\nThe problem requires implementing a pseudo-arclength continuation method to trace the solution curve of a steady-state thermal balance equation for a CSTR, identify turning points (folds), and analyze the change in stability across these points.\n\n**1. Governing Equations and Stability**\nThe steady state of the CSTR is defined by the algebraic residual equation $F(T, \\lambda) = 0$, where:\n$$\nF(T,\\lambda) \\;=\\; \\left(t_f - T\\right) + \\beta\\,\\lambda\\,\\exp\\!\\left(\\!-\\frac{E}{T}\\!\\right) - \\delta\\,\\left(T - t_c\\right) \\;=\\; 0\n$$\nThe variables $(T, \\lambda)$ represent the dimensionless temperature and Damköhler number. The stability of a steady-state solution is determined by the sign of the partial derivative of $F$ with respect to $T$:\n$$\n\\frac{\\partial F}{\\partial T}(T,\\lambda) \\;=\\; -1 - \\delta + \\beta\\,\\lambda\\,\\exp\\!\\left(\\!-\\frac{E}{T}\\!\\right)\\,\\frac{E}{T^2}\n$$\nA state is stable if $\\frac{\\partial F}{\\partial T}  0$ and unstable if $\\frac{\\partial F}{\\partial T}  0$. A turning point, or fold, occurs where $\\frac{\\partial F}{\\partial T} = 0$, which marks a change in stability.\n\n**2. Pseudo-Arclength Continuation**\nTo trace the solution curve $(T(\\cdot), \\lambda(\\cdot))$ through folds where the standard parameter continuation in $\\lambda$ would fail, we use a predictor-corrector pseudo-arclength method.\n\n*   **Predictor Step**: Given a point $(T_k, \\lambda_k)$ on the curve, we first compute the normalized tangent vector $\\mathbf{v}_k = (v_T, v_\\lambda)$. As per the problem, the tangent is derived from the orthogonality condition with the gradient $\\nabla F = (\\frac{\\partial F}{\\partial T}, \\frac{\\partial F}{\\partial \\lambda})$, yielding a vector proportional to $(-\\frac{\\partial F}{\\partial \\lambda}, \\frac{\\partial F}{\\partial T})$. After normalization, we predict the next point $(T_p, \\lambda_p)$ by advancing a step $\\Delta s$ along this tangent:\n    $$\n    (T_p, \\lambda_p) = (T_k, \\lambda_k) + \\Delta s \\cdot \\mathbf{v}_k\n    $$\n\n*   **Corrector Step**: The predicted point $(T_p, \\lambda_p)$ is an approximation. We correct it to find the true next point $(T_{k+1}, \\lambda_{k+1})$ on the curve by solving an augmented system of two nonlinear equations. The first equation ensures the point is on the solution curve, and the second constrains it to be at an arclength distance $\\Delta s$ from the previous point, measured along the tangent. The system for the unknown $(T, \\lambda)$ is:\n    $$\n    \\begin{cases}\n    F(T,\\lambda) \\;=\\; 0 \\\\\n    N(T,\\lambda) \\equiv v_T\\,(T-T_{k}) + v_\\lambda\\,(\\lambda - \\lambda_{k}) - \\Delta s \\;=\\; 0\n    \\end{cases}\n    $$\n    This $2 \\times 2$ system is solved iteratively using Newton's method, starting with the initial guess $(T_p, \\lambda_p)$. The Jacobian matrix of the augmented system is:\n    $$\n    \\mathbf{J_G}(T, \\lambda) = \\begin{bmatrix} \\frac{\\partial F}{\\partial T}  \\frac{\\partial F}{\\partial \\lambda} \\\\ v_T  v_\\lambda \\end{bmatrix}\n    $$\n\n**3. Overall Algorithm**\nThe complete procedure for each test case is as follows:\n1.  **Initialization**: Given an initial temperature $T_0$, compute the corresponding Damköhler number $\\lambda_0$ from the steady-state equation $F(T_0, \\lambda_0)=0$.\n2.  **Bifurcated Tracing**: Calculate the initial tangent vector $\\mathbf{v}_0$ at $(T_0, \\lambda_0)$. To ensure the entire S-curve is traced, perform two separate continuation runs from the starting point: one initiated with the tangent $\\mathbf{v}_0$ (\"forward\") and one with $-\\mathbf{v}_0$ (\"backward\"), each for $N$ steps.\n3.  **Tangent Direction Control**: During continuation, after each step, the new tangent vector is computed. To prevent the path from reversing, its direction is oriented to have a positive dot product with the tangent from the previous step.\n4.  **Fold Detection**: The full solution path is constructed by concatenating the backward (in reverse order), initial, and forward points. We iterate through this path, checking for sign changes in the stability indicator $\\frac{\\partial F}{\\partial T}$ between consecutive points. A sign change indicates a fold. The location of the fold is estimated more accurately using linear interpolation.\n5.  **Stability Analysis**: A sign change in $\\frac{\\partial F}{\\partial T}$ inherently means a transition between a stable and an unstable regime. Therefore, for every fold detected by this method, the stability is confirmed to change.\n6.  **Result Aggregation**: The folds detected during both forward and backward tracing may be duplicates. The list of all found folds is pruned by sorting them (e.g., by temperature) and merging any that are closer than a specified tolerance (on the order of the step size $\\Delta s$). The final output is the number of unique folds and a list of booleans indicating that stability changes at each fold.\n\nThis structured approach ensures robust traversal of the S-curve, accurate detection of turning points, and correct stability classification as per the problem requirements.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution for all test cases.\n    It processes each case, collects the results, and prints them in the specified format.\n    \"\"\"\n\n    def format_results(results):\n        \"\"\"Helper to format the final output string according to problem specification.\"\"\"\n        inner_results_str = []\n        for res in results:\n            n_folds, bool_list = res\n            bool_str = '[' + ','.join(str(b).lower() for b in bool_list) + ']'\n            inner_results_str.append(f'[{n_folds},{bool_str}]')\n        return '[' + ','.join(inner_results_str) + ']'\n\n    def F_func(T, lam, params):\n        \"\"\"The steady-state residual function F(T, lambda).\"\"\"\n        beta, delta, E, tf, tc = params['beta'], params['delta'], params['E'], params['tf'], params['tc']\n        if T = 0: return np.inf\n        return (tf - T) + beta * lam * np.exp(-E / T) - delta * (T - tc)\n\n    def dF_dT_func(T, lam, params):\n        \"\"\"The partial derivative dF/dT, which determines stability.\"\"\"\n        beta, delta, E = params['beta'], params['delta'], params['E']\n        if T = 0: return np.inf\n        return -1.0 - delta + beta * lam * np.exp(-E / T) * (E / T**2)\n\n    def dF_dlam_func(T, lam, params):\n        \"\"\"The partial derivative dF/dlambda.\"\"\"\n        beta, E = params['beta'], params['E']\n        if T = 0: return 0.0\n        return beta * np.exp(-E / T)\n\n    def newton_corrector(initial_guess, prev_point, prev_tangent, ds, params):\n        \"\"\"\n        Solves the augmented system using Newton's method to find the corrected point on the curve.\n        \"\"\"\n        T, lam = initial_guess\n        T_prev, lam_prev = prev_point\n        vT, vlam = prev_tangent\n        \n        max_iter = 15\n        tol = 1e-9\n        \n        for _ in range(max_iter):\n            # Calculate residual vector G(x) = [F(x), N(x)]\n            F_val = F_func(T, lam, params)\n            N_val = vT * (T - T_prev) + vlam * (lam - lam_prev) - ds\n            residual = np.array([F_val, N_val])\n\n            if np.linalg.norm(residual)  tol:\n                return T, lam\n\n            # Calculate Jacobian of the augmented system J_G\n            dFdT = dF_dT_func(T, lam, params)\n            dFdlam = dF_dlam_func(T, lam, params)\n            \n            jac_det = dFdT * vlam - dFdlam * vT\n            if abs(jac_det)  1e-12: # Jacobian is singular or near-singular\n                return None, None\n                \n            # Analytically compute inverse of 2x2 Jacobian and update step\n            delta_T = (-vlam * F_val + dFdlam * N_val) / jac_det\n            delta_lam = (vT * F_val - dFdT * N_val) / jac_det\n                \n            T += delta_T\n            lam += delta_lam\n            \n            if T = 0: return None, None # Non-physical temperature\n\n        return None, None # Did not converge\n\n    def trace_curve(start_point, start_tangent, N, ds, params):\n        \"\"\"\n        Traces one branch of the solution curve using predictor-corrector continuation.\n        \"\"\"\n        path = []\n        current_point = np.array(start_point)\n        current_tangent = np.array(start_tangent)\n\n        for _ in range(N):\n            prev_point = current_point\n            prev_tangent = current_tangent\n            \n            # Predictor step\n            predictor_point = prev_point + ds * prev_tangent\n            \n            # Corrector step\n            corrected_point_tuple = newton_corrector(\n                predictor_point, prev_point, prev_tangent, ds, params\n            )\n            \n            if corrected_point_tuple[0] is None:\n                break # Stop if corrector fails\n\n            current_point = np.array(corrected_point_tuple)\n            \n            # Compute new tangent and ensure consistent direction\n            T, lam = current_point\n            s_val = dF_dT_func(T, lam, params)\n            raw_tangent = np.array([-dF_dlam_func(T, lam, params), s_val])\n            \n            norm_raw_tangent = np.linalg.norm(raw_tangent)\n            if norm_raw_tangent  1e-9: # Near a fold, tangent is unstable\n                 current_tangent = prev_tangent # Reuse previous tangent to step over\n            else:\n                 current_tangent = raw_tangent / norm_raw_tangent\n\n            # Ensure consistent direction of traversal\n            if np.dot(current_tangent, prev_tangent)  0:\n                current_tangent = -current_tangent\n            \n            path.append((current_point, s_val))\n\n        return path\n    \n    def find_folds(path):\n        \"\"\"Detects folds by looking for sign changes in dF/dT along the path.\"\"\"\n        folds = []\n        for i in range(len(path) - 1):\n            p_i, s_i = path[i]\n            p_i_plus_1, s_i_plus_1 = path[i+1]\n            \n            if s_i * s_i_plus_1  0:\n                # Linear interpolation to find where s=0\n                if abs(s_i_plus_1 - s_i)  1e-12: continue\n                alpha = -s_i / (s_i_plus_1 - s_i)\n                fold_point = p_i + alpha * (p_i_plus_1 - p_i)\n                # Detection via sign change implies stability changes.\n                stability_change = True\n                folds.append((fold_point, stability_change))\n        return folds\n\n    def merge_folds(folds, ds):\n        \"\"\"Merges duplicate folds found during forward/backward tracing.\"\"\"\n        if not folds:\n            return []\n        \n        # Sort folds by T-coordinate to group them\n        sorted_folds = sorted(folds, key=lambda x: x[0][0])\n        \n        unique_folds = [sorted_folds[0]]\n        for i in range(1, len(sorted_folds)):\n            current_fold_pt, _ = sorted_folds[i]\n            last_unique_fold_pt, _ = unique_folds[-1]\n            \n            dist = np.linalg.norm(current_fold_pt - last_unique_fold_pt)\n            # Merge if closer than the arclength step (heuristic for uniqueness)\n            if dist  ds:\n                unique_folds.append(sorted_folds[i])\n        \n        return unique_folds\n    \n    def process_case(case_params):\n        \"\"\"Processes a single test case from start to finish.\"\"\"\n        beta, delta, E, tf, tc, T0, ds, N = case_params\n        params = {'beta': beta, 'delta': delta, 'E': E, 'tf': tf, 'tc': tc}\n\n        # Calculate initial lambda from F(T0, lam0) = 0\n        numerator = (1.0 + delta) * T0 - (tf + delta * tc)\n        denominator = beta * np.exp(-E / T0)\n        if abs(denominator)  1e-12: return [0, []]\n        lam0 = numerator / denominator\n\n        start_point = np.array([T0, lam0])\n        \n        # Calculate initial tangent and stability\n        s0 = dF_dT_func(T0, lam0, params)\n        initial_raw_tangent = np.array([-dF_dlam_func(T0, lam0, params), s0])\n        norm_init_tangent = np.linalg.norm(initial_raw_tangent)\n        if norm_init_tangent  1e-9: return [0, []] # Cannot start at a fold\n        initial_tangent = initial_raw_tangent / norm_init_tangent\n\n        # Trace curve in both forward and backward directions\n        forward_path = trace_curve(start_point, initial_tangent, N, ds, params)\n        backward_path = trace_curve(start_point, -initial_tangent, N, ds, params)\n        \n        # Combine paths for a full curve traversal\n        full_path = list(reversed(backward_path)) + [(start_point, s0)] + forward_path\n        \n        # Detect and merge folds from the full path\n        all_folds = find_folds(full_path)\n        unique_folds = merge_folds(all_folds, ds)\n        \n        n_folds = len(unique_folds)\n        stability_changes = [b for _, b in unique_folds]\n        \n        return [n_folds, stability_changes]\n\n    # --- Test Suite ---\n    test_cases = [\n        # (beta, delta, E, tf, tc, T0, ds, N)\n        (5.0, 0.4, 10.0, 0.1, 4.0, 2.0, 0.05, 200), # Case 1\n        (3.0, 0.2, 8.0, 0.2, 3.0, 1.0, 0.05, 200), # Case 2\n        (1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 0.05, 150), # Case 3\n    ]\n\n    results_raw = [process_case(case) for case in test_cases]\n    \n    # Format for final output\n    final_output_str = []\n    for num_folds, bool_list in results_raw:\n        # Convert Python booleans to lowercase 'true'/'false' as in JSON standard\n        bool_list_str = '[' + ','.join(str(b).lower() for b in bool_list) + ']'\n        final_output_str.append(f\"[{num_folds},{bool_list_str}]\")\n\n    print(f\"[{','.join(final_output_str)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "While arc-length continuation excels at tracing a path *through* turning points, it does not guarantee landing precisely *on* them. This final practice introduces a more advanced and practical technique for accurately locating these critical points. Using a simple, canonical model for thermal runaway, you will implement a diagnostic that monitors the system's Jacobian to detect when you are approaching a fold. Upon detection, the algorithm switches to a specialized Newton solver that targets the fold's defining mathematical conditions directly. This method  is fundamental to computational bifurcation analysis, enabling the precise identification of points where a system's qualitative behavior changes.",
            "id": "4007925",
            "problem": "Consider a simplified, dimensionless model of a homogeneous reactor relevant to computational combustion, where the steady-state heat balance under the Frank–Kamenetskii approximation leads to the nonlinear residual equation\n$$F(u,\\lambda) = \\lambda e^{u} - u,$$\nwith unknown scalar $u \\in \\mathbb{R}$ representing the dimensionless temperature rise and scalar parameter $\\lambda \\in \\mathbb{R}$ representing a nondimensionalized ratio of heat generation to heat loss.\n\nA turning-point (fold) in the solution curve of $F(u,\\lambda)=0$ satisfies the system\n$$F(u,\\lambda) = 0,\\quad \\frac{\\partial F}{\\partial u}(u,\\lambda) = 0.$$\nArc-length continuation is used to follow solution branches through such folds. The continuation method is based on the fundamental Implicit Function Theorem and the construction of a tangent direction $[t_u, t_\\lambda]^T$ satisfying the orthogonality condition\n$$\\frac{\\partial F}{\\partial u}(u,\\lambda)\\, t_u + \\frac{\\partial F}{\\partial \\lambda}(u,\\lambda)\\, t_\\lambda = 0,$$\nwith normalization $\\sqrt{t_u^2 + t_\\lambda^2} = 1$, followed by a predictor and corrector step enforcing a linearized arc-length constraint.\n\nDevelop a diagnostic mechanism that, along the continuation branch, tracks:\n- the smallest singular value of the Jacobian with respect to $u$, namely the absolute value\n$$\\sigma_{\\min} = \\left|\\frac{\\partial F}{\\partial u}(u,\\lambda)\\right|,$$\nand\n- the scalar quantity\n$$d = w^T \\frac{\\partial F}{\\partial \\lambda}(u,\\lambda),$$\nwhere $w$ is a unit left singular vector associated with the smallest singular value of $\\frac{\\partial F}{\\partial u}(u,\\lambda)$. In the scalar case, this reduces to $w = 1$ and $d = \\frac{\\partial F}{\\partial \\lambda}(u,\\lambda)$.\n\nWhen the branch approaches a fold, $\\sigma_{\\min}$ becomes small. To ensure the fold is simple (nondegenerate), require $|d|$ to remain bounded away from zero. Your task is to implement:\n1. A pseudo arc-length continuation for the scalar residual $F(u,\\lambda)$, starting from a feasible initial solution, using predictor-corrector steps based on the tangent direction and a Newton corrector that enforces both $F(u,\\lambda)=0$ and the linearized arc-length condition.\n2. A diagnostic that triggers refined fold localization when $\\sigma_{\\min}$ falls below a threshold $\\sigma_{\\mathrm{th}}$ and simultaneously $|d| \\ge \\gamma_{\\min}$.\n3. A refinement that solves the fold system\n$$G(u,\\lambda) = \\begin{bmatrix}F(u,\\lambda)\\\\ \\frac{\\partial F}{\\partial u}(u,\\lambda)\\end{bmatrix} = \\begin{bmatrix}\\lambda e^{u} - u\\\\ \\lambda e^{u} - 1\\end{bmatrix} = 0$$\nusing Newton’s method to accurately locate the fold.\n\nUse the following base facts and definitions:\n- The Jacobian entries are $\\frac{\\partial F}{\\partial u}(u,\\lambda) = \\lambda e^{u} - 1$ and $\\frac{\\partial F}{\\partial \\lambda}(u,\\lambda) = e^{u}$.\n- For the arc-length predictor, one valid unit tangent is\n$$\\begin{bmatrix}t_u\\\\ t_\\lambda\\end{bmatrix} = \\frac{1}{\\sqrt{\\left(\\frac{\\partial F}{\\partial u}\\right)^2 + \\left(\\frac{\\partial F}{\\partial \\lambda}\\right)^2}} \\begin{bmatrix} -\\frac{\\partial F}{\\partial \\lambda} \\\\ \\frac{\\partial F}{\\partial u} \\end{bmatrix},$$\nwhich satisfies the orthogonality condition to the gradient of $F$.\n\nYour program must:\n- Initialize at $\\lambda_0 = 0.05$, with an initial guess $u_{\\mathrm{init}} = 0.05$, and solve $F(u,\\lambda_0)=0$ for $u$ using Newton’s method to obtain the starting point on the branch.\n- Perform pseudo arc-length continuation with a fixed step size $\\Delta s$ and a maximum number of steps $N$; at each step, use a predictor based on the tangent and a Newton corrector enforcing both $F(u,\\lambda)=0$ and the linearized arc-length constraint $(u-u_p) t_u + (\\lambda - \\lambda_p) t_\\lambda = 0$, where $(u_p,\\lambda_p)$ is the predictor.\n- At each accepted corrected point, compute $\\sigma_{\\min} = \\left|\\frac{\\partial F}{\\partial u}(u,\\lambda)\\right|$ and $d = w^T \\frac{\\partial F}{\\partial \\lambda}(u,\\lambda)$ with $w=1$ for this scalar case, and trigger fold refinement if $\\sigma_{\\min} \\le \\sigma_{\\mathrm{th}}$ and $|d| \\ge \\gamma_{\\min}$.\n- Upon trigger, solve $G(u,\\lambda)=0$ via Newton’s method starting from the current point to compute a refined estimate of the fold parameter $\\lambda^\\star$.\n\nTest Suite:\nRun the algorithm for the following parameter sets $(\\Delta s, N, \\sigma_{\\mathrm{th}}, \\gamma_{\\min})$:\n1. $(0.05, 60, 10^{-4}, 10^{-6})$.\n2. $(0.2, 30, 10^{-3}, 10^{-6})$.\n3. $(0.05, 60, 10^{-6}, 3.0)$.\n\nFor each case, return:\n- The refined fold parameter $\\lambda^\\star$ as a float if refinement is triggered.\n- Otherwise, return the float $-1.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). No physical units are involved because all variables are dimensionless. Angles are not used in this problem. Express all numerical results as floating-point numbers.",
            "solution": "The user has provided a valid problem statement from the field of numerical analysis, specifically concerning the application of pseudo arc-length continuation to locate a turning point in a nonlinear system derived from a model in computational combustion. The problem is scientifically sound, mathematically well-posed, and all necessary components for a numerical solution are provided. The analysis will proceed by first detailing the mathematical and algorithmic framework, followed by the implementation.\n\nThe core of the problem is the nonlinear residual equation:\n$$F(u, \\lambda) = \\lambda e^u - u = 0$$\nwhere $u$ is a dimensionless temperature and $\\lambda$ is a system parameter. We aim to trace the solution curve $(u(\\lambda), \\lambda)$ and accurately locate the turning point (fold), which is defined by the simultaneous satisfaction of two conditions:\n$$F(u,\\lambda) = 0 \\quad \\text{and} \\quad \\frac{\\partial F}{\\partial u}(u, \\lambda) = 0$$\n\nThe numerical procedure is structured into three main stages: initialization, arc-length continuation, and fold refinement.\n\n**1. Initialization: Finding the Starting Point**\nThe continuation process begins from a known point on the solution curve. We are given an initial parameter value $\\lambda_0 = 0.05$ and an initial guess for the state, $u_{\\text{init}} = 0.05$. The first step is to solve the nonlinear equation $F(u, \\lambda_0) = 0$ for $u$ to find a precise starting point $(u_0, \\lambda_0)$. This is accomplished using Newton's method for a single variable. The iterative formula is:\n$$u^{(k+1)} = u^{(k)} - \\frac{F(u^{(k)}, \\lambda_0)}{\\frac{\\partial F}{\\partial u}(u^{(k)}, \\lambda_0)}$$\nwhere $\\frac{\\partial F}{\\partial u}(u, \\lambda) = \\lambda e^u - 1$. The iteration starts with $u^{(0)} = u_{\\text{init}}$ and continues until the change $|u^{(k+1)} - u^{(k)}|$ is below a prescribed tolerance. The converged solution is denoted $u_0$.\n\n**2. Pseudo Arc-Length Continuation**\nStarting from $(u_0, \\lambda_0)$, we trace the solution curve by taking discrete steps of length $\\Delta s$. Each step consists of a predictor and a corrector.\n\n**2.1. Tangent Vector Calculation**\nAt a known point $(u_k, \\lambda_k)$ on the curve, we compute the tangent vector $[t_u, t_\\lambda]^T$. The tangent is orthogonal to the gradient of $F$, $\\nabla F = [\\frac{\\partial F}{\\partial u}, \\frac{\\partial F}{\\partial \\lambda}]^T$. A valid, normalized tangent vector is given by:\n$$\\begin{bmatrix}t_u\\\\ t_\\lambda\\end{bmatrix} = \\frac{1}{\\sqrt{\\left(\\frac{\\partial F}{\\partial u}\\right)^2 + \\left(\\frac{\\partial F}{\\partial \\lambda}\\right)^2}} \\begin{bmatrix} -\\frac{\\partial F}{\\partial \\lambda} \\\\ \\frac{\\partial F}{\\partial u} \\end{bmatrix}$$\nwhere $\\frac{\\partial F}{\\partial u} = \\lambda_k e^{u_k} - 1$ and $\\frac{\\partial F}{\\partial \\lambda} = e^{u_k}$.\nTo ensure the continuation proceeds consistently along the curve, the tangent's orientation must be managed. For the first step from $(u_0, \\lambda_0)$, we require the continuation to move towards increasing $\\lambda$, as the fold is known to occur at $\\lambda^\\star = 1/e \\approx 0.36788  \\lambda_0$. We thus check the sign of $t_\\lambda$; if $t_\\lambda  0$, we flip the sign of the entire tangent vector. For all subsequent steps, we ensure the new tangent vector $[t_u, t_\\lambda]_k$ has a positive dot product with the previous tangent vector $[t_u, t_\\lambda]_{k-1}$, flipping its sign if necessary.\n\n**2.2. Predictor Step**\nThe predictor step computes a new point $(u_p, \\lambda_p)$ by moving a distance $\\Delta s$ from the current point $(u_k, \\lambda_k)$ along the tangent direction:\n$$u_p = u_k + \\Delta s \\cdot t_u$$\n$$\\lambda_p = \\lambda_k + \\Delta s \\cdot t_\\lambda$$\n\n**2.3. Corrector Step**\nThe predictor point $(u_p, \\lambda_p)$ is an approximation and does not lie exactly on the solution curve. The corrector step refines this guess to find the next point on the curve, $(u_{k+1}, \\lambda_{k+1})$. This is achieved by solving a $2 \\times 2$ system of nonlinear equations for $(u, \\lambda)$ using Newton's method:\n$$ H(u, \\lambda) = \\begin{bmatrix} F(u,\\lambda) \\\\ N(u,\\lambda) \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} $$\nThe first equation, $F(u, \\lambda) = 0$, ensures the point is on the solution curve. The second equation, $N(u, \\lambda) = (u-u_p) t_u + (\\lambda - \\lambda_p) t_\\lambda = 0$, is the linearized arc-length constraint. It forces the solution to lie on the hyperplane (a line in this 2D case) passing through $(u_p, \\lambda_p)$ and orthogonal to the tangent vector used for the predictor step.\n\nThe Newton iteration for this system starts with the guess $(u_p, \\lambda_p)$ and updates the solution vector $x = [u, \\lambda]^T$ via:\n$$x^{(j+1)} = x^{(j)} - [J_H(x^{(j)})]^{-1} H(x^{(j)})$$\nThe Jacobian of the system $H$ is:\n$$ J_H(u, \\lambda) = \\begin{bmatrix} \\frac{\\partial F}{\\partial u}  \\frac{\\partial F}{\\partial \\lambda} \\\\ t_u  t_\\lambda \\end{bmatrix} = \\begin{bmatrix} \\lambda e^u - 1  e^u \\\\ t_u  t_\\lambda \\end{bmatrix} $$\nThe iteration continues until the correction becomes smaller than a given tolerance. The converged point is $(u_{k+1}, \\lambda_{k+1})$.\n\n**3. Fold Detection and Refinement**\nAt each successfully computed point $(u_k, \\lambda_k)$, we evaluate diagnostic quantities to detect proximity to the fold.\n\n**3.1. Diagnostic Quantities**\nThe problem specifies tracking two quantities:\n- The smallest singular value of the Jacobian $\\frac{\\partial F}{\\partial u}$, which for this scalar case is $\\sigma_{\\min} = \\left|\\frac{\\partial F}{\\partial u}(u_k,\\lambda_k)\\right| = |\\lambda_k e^{u_k} - 1|$. As the curve approaches a fold, $\\frac{\\partial F}{\\partial u} \\to 0$, so $\\sigma_{\\min} \\to 0$.\n- A scalar $d = w^T \\frac{\\partial F}{\\partial \\lambda}$, where $w$ is the left singular vector corresponding to $\\sigma_{\\min}$. For this scalar problem, $w=1$, so $d = \\frac{\\partial F}{\\partial \\lambda}(u_k,\\lambda_k) = e^{u_k}$. For the fold to be simple (non-degenerate), this value must be bounded away from zero.\n\n**3.2. Refinement Trigger**\nFold refinement is triggered if both of the following conditions are met for a given point $(u_k, \\lambda_k)$:\n$$ \\sigma_{\\min} \\le \\sigma_{\\mathrm{th}} \\quad \\text{and} \\quad |d| \\ge \\gamma_{\\min} $$\nwhere $\\sigma_{\\mathrm{th}}$ and $\\gamma_{\\min}$ are specified thresholds.\n\n**3.3. Fold Refinement**\nUpon triggering, we switch to a more direct method to pinpoint the fold's location $(u^\\star, \\lambda^\\star)$. This involves solving the defining system for the fold using Newton's method:\n$$ G(u, \\lambda) = \\begin{bmatrix} F(u,\\lambda) \\\\ \\frac{\\partial F}{\\partial u}(u,\\lambda) \\end{bmatrix} = \\begin{bmatrix} \\lambda e^u - u \\\\ \\lambda e^u - 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} $$\nThe initial guess for this Newton solve is the point $(u_k, \\lambda_k)$ that triggered the refinement. The Jacobian of the system $G$ is:\n$$ J_G(u, \\lambda) = \\begin{bmatrix} \\frac{\\partial F}{\\partial u}  \\frac{\\partial F}{\\partial \\lambda} \\\\ \\frac{\\partial^2 F}{\\partial u^2}  \\frac{\\partial^2 F}{\\partial u \\partial \\lambda} \\end{bmatrix} = \\begin{bmatrix} \\lambda e^u - 1  e^u \\\\ \\lambda e^u  e^u \\end{bmatrix} $$\nThe Newton iteration proceeds until convergence, and the $\\lambda$ component of the solution is the refined fold parameter, $\\lambda^\\star$. If the continuation loop completes its maximum of $N$ steps without triggering refinement, a value of $-1.0$ is returned to indicate failure to locate the fold. Analytically, the fold is at $(u, \\lambda) = (1, 1/e)$, so the refined value $\\lambda^\\star$ should be close to $1/e \\approx 0.36787944$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        (0.05, 60, 1e-4, 1e-6),\n        (0.2, 30, 1e-3, 1e-6),\n        (0.05, 60, 1e-6, 3.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        ds, N, sigma_th, gamma_min = case\n        lambda_fold = run_case(ds, N, sigma_th, gamma_min)\n        results.append(lambda_fold)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_case(ds, N, sigma_th, gamma_min, u_init=0.05, lambda_init=0.05, tol=1e-9, max_iter=10):\n    \"\"\"\n    Executes the arc-length continuation and fold refinement for a single parameter set.\n    \"\"\"\n    # Helper functions for the residual and its derivatives\n    F = lambda u, lam: lam * np.exp(u) - u\n    F_u = lambda u, lam: lam * np.exp(u) - 1.0\n    F_l = lambda u, lam: np.exp(u)\n\n    # --- Step 1: Find the initial point (u0, lambda0) ---\n    u_curr = u_init\n    for _ in range(max_iter):\n        residual = F(u_curr, lambda_init)\n        if abs(residual)  tol:\n            break\n        u_curr -= residual / F_u(u_curr, lambda_init)\n    \n    lambda_curr = lambda_init\n    \n    # --- Step 2: Arc-length continuation ---\n    tangent_old = None\n    for step in range(N):\n        # --- Tangent calculation ---\n        fu = F_u(u_curr, lambda_curr)\n        fl = F_l(u_curr, lambda_curr)\n        norm = np.sqrt(fu**2 + fl**2)\n        \n        # Guard against division by zero if we land exactly on the fold\n        if norm  tol:\n            break\n            \n        t_u = -fl / norm\n        t_l = fu / norm\n        tangent = np.array([t_u, t_l])\n\n        # --- Tangent orientation ---\n        # For the first step, ensure we move towards increasing lambda\n        if step == 0 and tangent[1]  0:\n            tangent *= -1.0\n        # For subsequent steps, maintain direction\n        if tangent_old is not None and np.dot(tangent, tangent_old)  0:\n            tangent *= -1.0\n        \n        tangent_old = tangent\n\n        # --- Predictor step ---\n        u_p = u_curr + ds * tangent[0]\n        lambda_p = lambda_curr + ds * tangent[1]\n\n        # --- Corrector step (Newton's method for 2x2 system) ---\n        u_corr, lambda_corr = u_p, lambda_p\n        for _ in range(max_iter):\n            # Form the residual H and Jacobian J_H\n            h1 = F(u_corr, lambda_corr)\n            h2 = (u_corr - u_p) * tangent[0] + (lambda_corr - lambda_p) * tangent[1]\n            H = np.array([h1, h2])\n\n            jh_11 = F_u(u_corr, lambda_corr)\n            jh_12 = F_l(u_corr, lambda_corr)\n            jh_21 = tangent[0]\n            jh_22 = tangent[1]\n            J_H = np.array([[jh_11, jh_12], [jh_21, jh_22]])\n\n            # Solve J_H * delta = -H\n            try:\n                delta = np.linalg.solve(J_H, -H)\n            except np.linalg.LinAlgError:\n                # Corrector fails, stop continuation\n                return -1.0\n                \n            u_corr += delta[0]\n            lambda_corr += delta[1]\n\n            if np.linalg.norm(delta)  tol:\n                break\n        \n        u_curr, lambda_curr = u_corr, lambda_corr\n\n        # --- Step 3: Fold detection ---\n        sigma_min = abs(F_u(u_curr, lambda_curr))\n        d_val = F_l(u_curr, lambda_curr)\n\n        if sigma_min = sigma_th and abs(d_val) = gamma_min:\n            # --- Fold refinement ---\n            u_fold, lambda_fold = u_curr, lambda_curr\n            for _ in range(max_iter):\n                # Form the residual G and Jacobian J_G\n                g1 = F(u_fold, lambda_fold)\n                g2 = F_u(u_fold, lambda_fold)\n                G = np.array([g1, g2])\n\n                # Jacobian of the fold system G\n                jg_11 = F_u(u_fold, lambda_fold)\n                jg_12 = F_l(u_fold, lambda_fold)\n                jg_21 = lambda_fold * np.exp(u_fold) # d(F_u)/du\n                jg_22 = np.exp(u_fold)              # d(F_u)/d_lambda\n                J_G = np.array([[jg_11, jg_12], [jg_21, jg_22]])\n\n                try:\n                    delta_fold = np.linalg.solve(J_G, -G)\n                except np.linalg.LinAlgError:\n                    return -1.0\n\n                u_fold += delta_fold[0]\n                lambda_fold += delta_fold[1]\n\n                if np.linalg.norm(delta_fold)  tol:\n                    return lambda_fold\n            \n            # If refinement Newton loop finishes without converging, return last value\n            return lambda_fold\n\n    # If loop finishes without triggering refinement\n    return -1.0\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}