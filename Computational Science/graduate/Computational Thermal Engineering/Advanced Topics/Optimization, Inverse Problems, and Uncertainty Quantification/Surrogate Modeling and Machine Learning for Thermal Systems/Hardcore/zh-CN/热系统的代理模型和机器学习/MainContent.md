## 引言
在现代工程与科学研究中，对复杂热系统的精确预测是推动技术创新与科学发现的基石。高保真度[数值模拟](@entry_id:146043)，如有限元法或计算流体力学，为此提供了强大的工具，但其惊人的计算成本往往成为[设计优化](@entry_id:748326)、不确定性量化或实时控制等大规模计算任务的瓶颈。这便引出了一个核心问题：我们如何在保证足够精度的前提下，大幅降低仿真的计算开销？代理建模与机器学习为此提供了革命性的解决方案，它们通过从数据中学习物理系统的输入-输出关系，构建出计算成本极低的“数字孪生”。本文旨在为读者提供一个关于热系统代理建模的系统性框架。在接下来的章节中，我们将首先深入“原理与机制”，揭示这些模型背后的数学基础和物理约束；然后，我们将通过“应用与跨学科连接”探索它们在工程与科学前沿的广阔应用；最后，通过一系列“动手实践”，将理论知识转化为解决实际问题的能力。

## 原理与机制

本章深入探讨了驱动热系统代理模型开发与应用的核心科学原理和关键机制。继引言之后，我们将从高级[计算模型](@entry_id:637456)面临的挑战出发，阐述代理模型的必要性，并系统地介绍其理论基础、关键模型类别以及确保其物理保真度的先进技术。本章旨在为读者构建一个坚实的理论框架，使其能够理解、设计并严格评估用于复杂热学问题的代理模型。

### 代理建模的动机：计算成本的挑战

在计算热工领域，高保真度[数值模拟](@entry_id:146043)，如[有限元法 (FEM)](@entry_id:176633) 或[有限体积法 (FVM)](@entry_id:749403)，是理解和预测复杂热现象的基石。然而，这些模拟的计算成本可能高得惊人，尤其是在处理多维度、多物理场耦合或需要进行大量查询（如在[设计优化](@entry_id:748326)、不确定性量化或[逆问题](@entry_id:143129)分析中）的场景时。代理模型的首要动机正是为了克服这一“[维度灾难](@entry_id:143920)”和计算瓶颈。

为了具体说明这一点，我们来估算一个典型[高保真度模拟](@entry_id:750285)的计算成本。考虑一个边长为 $L=0.1\,\text{m}$ 的三维立方体部件，其内部进行[瞬态热传导](@entry_id:170260)，[热扩散率](@entry_id:144337)为 $\alpha = 1.2 \times 10^{-5}\,\text{m}^{2}\text{/s}$。我们使用一个均匀的笛卡尔网格进行离散化，每个方向有 $n=512$ 个未知数节点。采用显式前向时间步进格式求解，其稳定性要求时间步长 $\Delta t$ 满足约束 $\Delta t \le \Delta x^2 / (2d\alpha)$，其中 $d$ 是空间维度（此处为3），因此 $\Delta t \le \Delta x^2 / (6\alpha)$，其中空间步长 $\Delta x = L/n$。我们的目标是模拟到特征[扩散时间尺度](@entry_id:264558) $t_{\text{end}} = L^2/\alpha$。

首先，我们确定求解的总自由度 (Degrees of Freedom, DOF)，即网格点的总数：
$$
N_{\text{dof}} = n^3 = 512^3 \approx 1.34 \times 10^8
$$

其次，我们计算所需的总时间步数。根据稳定性约束，我们选择时间步长为极限值：
$$
\Delta t = \frac{\Delta x^2}{6\alpha} = \frac{(L/n)^2}{6\alpha} = \frac{L^2}{6\alpha n^2}
$$
因此，达到 $t_{\text{end}}$ 所需的时间步数 $N_{\text{steps}}$ 为：
$$
N_{\text{steps}} = \frac{t_{\text{end}}}{\Delta t} = \frac{L^2/\alpha}{L^2/(6\alpha n^2)} = 6n^2 = 6 \times 512^2 \approx 1.57 \times 10^6
$$
值得注意的是，模拟到特征扩散时间所需的步数与网格分辨率的平方成正比，而与物理参数 $L$ 和 $\alpha$ 无关。

假设每次迭代中，更新每个网格点的温度需要 $c_{\text{op}} = 13$ 次浮点运算 (FLOPs)。那么，整个模拟的总计算量 $C_{\text{total}}$ 为：
$$
C_{\text{total}} = N_{\text{dof}} \times N_{\text{steps}} \times c_{\text{op}} = n^3 \times 6n^2 \times c_{\text{op}} = 6 c_{\text{op}} n^5
$$
总计算成本随着网格分辨率 $n$ 的五次方急剧增长。代入数值：
$$
C_{\text{total}} = 6 \times 13 \times 512^5 \approx 2.74 \times 10^{15} \text{ FLOPs}
$$
如果在一个持续性能为 $p = 8 \times 10^9$ FLOPs/s 的单 CPU 核心上运行此模拟，所需的总时间 $T_{\text{run}}$ 约为：
$$
T_{\text{run}} = \frac{C_{\text{total}}}{p} \approx \frac{2.74 \times 10^{15}}{8 \times 10^9} \approx 342,500 \text{ s} \approx 95.1 \text{ 小时}
$$
这个估算显示，即使是这样一个看似简单的问题，一次高分辨率的模拟也需要将近四天的计算时间。在需要数千次此类模拟的工程任务中，总成本将是无法承受的。代理模型通过学习并提供一个计算成本极低的近似映射，为解决这一挑战提供了可行的途径。

### 代理模型的基础：物理与统计

在构建代理模型之前，我们必须首先清晰地界定其旨在近似的物理系统。一个典型的例子是不可压缩流体中的[能量输运](@entry_id:183081)，这在[共轭传热](@entry_id:149857)等应用中至关重要。其控制方程源于[热力学第一定律](@entry_id:146485)，并结合了特定的本构关系。

对于一个不可压缩的[牛顿流体](@entry_id:263796)，其[能量守恒方程](@entry_id:748978)（或称热方程）可以写作：
$$
\underbrace{\rho c_p \frac{\partial T}{\partial t}}_{\text{瞬态储能}} + \underbrace{\rho c_p (\mathbf{u} \cdot \nabla T)}_{\text{对流输运}} = \underbrace{\nabla \cdot (k \nabla T)}_{\text{传导/扩散}} + \underbrace{q}_{\text{体积热源}}
$$
这个方程精确地描述了温度场 $T$ 的时空演化，其各项的物理意义如下：
- **瞬态储能项**：$\rho c_p \frac{\partial T}{\partial t}$，表示单位体积内热能随时间的变化率，其中 $\rho$ 是流体密度，$c_p$ 是定压比热容。
- **[对流输运](@entry_id:149512)项**：$\rho c_p (\mathbf{u} \cdot \nabla T)$，描述了由流体宏观运动（速度场为 $\mathbf{u}$）引起的热能输运。
- **传导/扩散项**：$\nabla \cdot (k \nabla T)$，描述了由分子微观运动（[热传导](@entry_id:143509)）引起的能量传递。它源于[傅里叶定律](@entry_id:136311) $\mathbf{q}'' = -k \nabla T$，其中 $k$ 是[热导](@entry_id:189019)率。
- **[体积热源](@entry_id:1133894)项**：$q$，代表单位体积内由于化学反应、焦耳热等产生的内热源。

推导此方程需要一系列明确的假设：流体是不可压缩的（[速度场散度](@entry_id:178755)为零，$\nabla \cdot \mathbf{u} = 0$），密度 $\rho$ 和比热容 $c_p$ 为常数，[热传导](@entry_id:143509)遵循[傅里叶定律](@entry_id:136311)，且忽略了粘性耗散等次要效应。代理模型的任务，本质上就是学习由这一（或其他）[偏微分](@entry_id:194612)方程及其边界条件所定义的、从系统输入（如边界条件、材料属性、热源 $q$）到系统输出（如特定点的温度）之间的复杂、[非线性映射](@entry_id:272931)关系。

#### 代理模型与降阶模型的区别

在[模型简化](@entry_id:171175)的领域中，区分**数据驱动的代理模型（Surrogate Model）**和**基于物理的[降阶模型](@entry_id:754172)（Reduced-Order Model, ROM）**至关重要。

- **代理模型**通常旨在直接近似系统的**输入-输出映射**。假设一个热系统将一组输入参数 $\theta$（如材料属性）和控制 $u$（如边界热流）映射到一组输出 $y$（如传感器温度），即 $y = f(\theta, u)$。代理模型 $\hat{f}$ 就是对这个映射 $f$ 的近似，$\hat{y} = \hat{f}(\theta, u)$。它通常通过从高保真模拟或实验中获得的数据对 $\{( \theta_i, u_i, y_i) \}$ 进行训练来构建，而无需了解系统内部的完整状态演化。因此，这类模型通常是**非侵入式 (non-intrusive)** 的，因为它们可以将高保真求解器当作一个“黑箱”来使用。

- **降阶模型**则旨在近似系统的高维**动力学算子**本身。它始于一个高维度的[常微分方程组](@entry_id:907499)（通常来自有限元等方法的[半离散化](@entry_id:163562)），例如 $\boldsymbol{M}\dot{\boldsymbol{x}} = -\boldsymbol{K}\boldsymbol{x} + \boldsymbol{B}u$。ROM通过投影方法（如伽辽金投影）将此系统投影到一个低维子空间中，得到一个维度远小于原始系统的动力学方程 $\boldsymbol{M}_r\dot{\boldsymbol{z}} = -\boldsymbol{K}_r\boldsymbol{z} + \boldsymbol{B}_r u$。这种方法通过近似[状态向量](@entry_id:154607) $\boldsymbol{x}(t)$ 而非直接近似输出 $y(t)$，保留了更多的物理结构。然而，构建降阶算子（如 $\boldsymbol{M}_r, \boldsymbol{K}_r$）通常需要访问并操作高保真模型的系统矩阵（$\boldsymbol{M}, \boldsymbol{K}$），因此是**侵入式 (intrusive)** 的。

这两种方法的关键区别在于：
1.  **目标不同**：代理模型近似输入-输出关系；ROM近似内部状态动力学。
2.  **实现方式不同**：代理模型是非侵入式的，仅需数据；ROM是侵入式的，需要访问原始模型代码。
3.  **灵活性不同**：如果需要预测一个新的输出量（例如，改变传感器位置），为特定输出训练的代理模型通常需要完全重新训练。而ROM由于近似了整个内部状态，可以简单地通过应用新的输出算子来计算新输出，无需重新训练动力学模型。

#### 代理模型误差：[偏差-方差分解](@entry_id:163867)

任何通过数据训练得到的代理模型 $\hat{f}$ 都不可避免地存在误差。理解误差的来源对于评估和[提升模型](@entry_id:909156)保真度至关重要。对于一个由物理定律决定的确定性真实映射 $f(x)$，代理模型在固定输入点 $x$ 的期望[均方误差](@entry_id:175403) (Mean Squared Error, MSE) 可以通过**[偏差-方差分解](@entry_id:163867) (Bias-Variance Decomposition)** 来剖析。

期望 MSE 的计算是针对所有可能的训练数据集 $\mathcal{D}$ 进行的，其分解形式为：
$$
\mathbb{E}_{\mathcal{D}}\big[(\hat{f}(x)-f(x))^2\big] = \underbrace{\Big(\mathbb{E}_{\mathcal{D}}\big[\hat{f}(x)\big]-f(x)\Big)^2}_{\text{偏差}^2} + \underbrace{\operatorname{Var}_{\mathcal{D}}\big[\hat{f}(x)\big]}_{\text{方差}}
$$
这个分解揭示了误差的两个根本来源：
- **偏差 (Bias)**：$\mathbb{E}_{\mathcal{D}}[\hat{f}(x)] - f(x)$，度量了模型在所有可能训练集上的**平均预测**与**真实物理值**之间的系统性差距。高偏差通常意味着模型过于简单，无法捕捉物理过程的复杂性（[欠拟合](@entry_id:634904)）。
- **方差 (Variance)**：$\operatorname{Var}_{\mathcal{D}}[\hat{f}(x)]$，度量了模型预测对于不同训练数据集的**敏感度或不稳定性**。高方差通常意味着模型过于复杂，过度拟合了训练数据中的随机噪声或特性，导致其泛化能力差。

**[偏差-方差权衡](@entry_id:138822)**是代理建模中的核心挑战：
- **[模型复杂度](@entry_id:145563)**：增加模型复杂度（例如，增加神经网络的层数或神经元数量）通常会降低偏差，因为它能学习更复杂的函数，但也可能增加方差，更容易过拟合。
- **训练数据量**：增加训练数据量通常会降低方差，因为模型可以从更多样本中学习到更稳定的统计规律。
- **物理约束**：在模型中加入物理约束（如能量守恒）可以作为一种正则化手段，通过限制模型的[假设空间](@entry_id:635539)来降低方差。然而，如果施加的物理约束本身是近似或不完全正确的，也可能引入新的偏差。

#### 代理模型不确定性：偶然与认知

在许多实际应用中，我们不仅关心模型的预测值，还关心预测的**不确定性**。概率性代理模型（如高斯过程）能够提供这种不确定性的量化。不确定性可以分为两大类：**[偶然不确定性](@entry_id:634772) (Aleatoric Uncertainty)** 和 **认知不确定性 (Epistemic Uncertainty)**。

- **[偶然不确定性](@entry_id:634772)**是系统固有的、不可约减的随机性。在[热系统建模](@entry_id:266158)中，最常见的来源是**传感器[测量噪声](@entry_id:275238)**。即使我们拥有完美的物理模型，由于测量过程的内在随机波动，[重复测量](@entry_id:896842)同一状态也会得到不同的结果。这种不确定性可以通过统计方法来表征（例如，估计噪声的方差），但无法通过收集更多同[类数](@entry_id:156164)据来消除。

- **认知不确定性**源于我们知识的缺乏，原则上是可约减的。其主要来源包括：
    1.  **[模型参数不确定性](@entry_id:752081)**：由于训练数据有限，我们无法精确确定模型的最佳参数（例如，神经网络的权重）。这种不确定性反映在参数的[后验分布](@entry_id:145605)上，可以通过收集更多数据来缩小分布，从而降低不确定性。
    2.  **[模型形式不确定性](@entry_id:1128038)**：我们选择的代理模型函数族（例如，某种特定结构的神经网络或特定[核函数](@entry_id:145324)的高斯过程）可能不足以表达真实的物理关系。这种“模型不匹配”也是一种认知不确定性，可以通过选择更灵活的模型（如更宽或更深的网络）或引入更准确的物理先验知识来减小。

区分这两种不确定性至关重要。[偶然不确定性](@entry_id:634772)为模型的预测精度设定了一个基本下限，而认知不确定性则指出了模型可以通过更多数据或更好的设计来改进的方向。例如，一个[高斯过程回归](@entry_id:276025)模型的总预测方差可以分解为代表认知不确定性的函数方差和代表[偶然不确定性](@entry_id:634772)的噪声方差之和。

### 关键代理模型及其机制

#### [前馈神经网络](@entry_id:635871)

**[前馈神经网络](@entry_id:635871) (Feedforward Neural Networks, FNNs)** 是最常用的代理模型之一。一个具有 $L$ 层的 FNN 通过一系列嵌套的[线性变换](@entry_id:149133)和[非线性](@entry_id:637147)**激活函数 (activation function)** $\phi$ 来构建从输入到输出的映射。 其计算过程如下：
$$
\boldsymbol{a}_0 = \boldsymbol{x} \quad (\text{输入层})
$$
$$
\boldsymbol{a}_\ell = \phi(\boldsymbol{W}_\ell \boldsymbol{a}_{\ell-1} + \boldsymbol{b}_\ell) \quad \text{for } \ell = 1, \dots, L-1 \quad (\text{隐藏层})
$$
$$
f_{\boldsymbol{\theta}}(\boldsymbol{x}) = \boldsymbol{w}_L^\top \boldsymbol{a}_{L-1} + b_L \quad (\text{输出层})
$$
其中，$\boldsymbol{W}_\ell, \boldsymbol{b}_\ell, \boldsymbol{w}_L, b_L$ 是网络的可训练参数 $\boldsymbol{\theta}$。

FNN 能够近似复杂函数的关键在于**[非线性激活函数](@entry_id:635291)** $\phi$。如果[激活函数](@entry_id:141784)是线性的，那么整个[多层网络](@entry_id:261728)将退化为一个简单的线性模型，无法表达复杂物理过程中的[非线性](@entry_id:637147)关系。然而，当使用[非线性激活函数](@entry_id:635291)（如 ReLU, [tanh](@entry_id:636446), sigmoid）时，根据**[通用近似定理](@entry_id:146978) (Universal Approximation Theorem)**，一个足够大的 FNN 能够以任意精度近似任何定义在[紧集上的连续函数](@entry_id:146442)。

在热科学问题中，[非线性](@entry_id:637147)无处不在。例如，考虑包含辐射换热的边界条件：
$$
-k \nabla T \cdot \boldsymbol{n} = h(T-T_\infty) + \varepsilon\sigma_{\text{SB}}(T^4 - T_{\text{sur}}^4)
$$
温度与辐射热流之间的 $T^4$ 关系是高度[非线性](@entry_id:637147)的。一个不带[非线性激活函数](@entry_id:635291)的线性模型无法捕捉这种关系，而一个标准的 FNN 则可以通过其层次化的[非线性](@entry_id:637147)结构，从数据中学习并逼近这种复杂的物理响应。

#### [高斯过程回归](@entry_id:276025)

**[高斯过程](@entry_id:182192) (Gaussian Process, GP)** 是一种强大的概率性（非参数）代理模型，它直接在[函数空间](@entry_id:143478)上定义分布。一个 GP 由一个**[均值函数](@entry_id:264860)** $m(x)$ 和一个**核函数（或协方差函数）** $k(x, x')$ 完全确定。它假定在任意一组输入点上的函数值服从一个[联合高斯](@entry_id:636452)分布。

当给定一组带噪声的训练数据 $\{(x_i, y_i)\}_{i=1}^n$ 后，GP 回归可以为新输入点 $x_\star$ 提供一个高斯分布的预测，其均值和方差有解析表达式。这个预测不仅给出了最可能的函数值（均值），还量化了预测的不确定性（方差）。

[核函数](@entry_id:145324)的选择对 GP 的性能至关重要，因为它编码了关于待建[模函数](@entry_id:155728)性质（如光滑度、周期性等）的先验知识。一个关键的区别在于**平稳核 (stationary kernel)** 和**非平稳核 (non-stationary kernel)**：
- **平稳核**：其值仅依赖于输入点之间的相对距离或位移，即 $k(x, x') = k(x-x')$。这意味着函数的统计特性（如[相关长度](@entry_id:143364)和方差）在整个输入空间中是恒定的。这对于模拟**均匀材料**中的物理过程是一个合理的假设。
- **非平稳核**：其值依赖于输入点的绝对位置，而不仅仅是它们的相对位置。这打破了[平移不变性](@entry_id:195885)，允许函数的统计特性随空间变化。这对于模拟**非均匀材料**（如复合材料）至关重要。在这些材料中，[热导](@entry_id:189019)率等物理属性随空间变化，导致温度场的平滑度等特征也随之改变。例如，通过使用具有空间变化长度尺度 $\ell(x)$ 的[核函数](@entry_id:145324)（如 Gibbs 核），GP 能够适应材料属性的局部变化。

### 确保物理保真度：物理知情机器学习

标准的“黑箱”机器学习模型在训练数据充足的区域可能表现良好，但在外推或数据稀疏区域，其预测可能严重偏离物理现实。**物理知情机器学习 (Physics-Informed Machine Learning, PIML)** 的目标就是将物理定律作为先验知识嵌入到模型中，以提高其泛化能力和物理保真度。

#### 物理知情神经网络 ([PINNs](@entry_id:145229))

**物理知情神经网络 (Physics-Informed Neural Networks, PINNs)** 是 PIML 的一个典型范例。PINN 的核心思想是将其[损失函数](@entry_id:634569)设计为多个部分的加权和，不仅包括与观测数据的**[数据失配](@entry_id:748209)项**，还包括一个在时空域内选取的**[配置点](@entry_id:169000) (collocation points)** 上计算的**[偏微分](@entry_id:194612)方程 (PDE) 残差项**。

对于前述的[热方程](@entry_id:144435) $\frac{\partial u}{\partial t} - \alpha \frac{\partial^2 u}{\partial x^2} = 0$，其 PDE 残差定义为 $f_\theta(x,t) := \frac{\partial u_\theta}{\partial t} - \alpha \frac{\partial^2 u_\theta}{\partial x^2}$，其中 $u_\theta$ 是一个以 $(x,t)$ 为输入的神经网络。PINN 的总[损失函数](@entry_id:634569)通常形如：
$$
\mathcal{L}(\theta) = \lambda_{\text{data}} \mathcal{L}_{\text{data}} + \lambda_{\text{PDE}} \mathcal{L}_{\text{PDE}} + \lambda_{\text{BC}} \mathcal{L}_{\text{BC}} + \lambda_{\text{IC}} \mathcal{L}_{\text{IC}}
$$
通过最小化这个复合损失，网络被驱动去同时拟合观测数据并遵守控制物理定律。

初始条件 (IC) 和边界条件 (BC) 的施加方式有两种主要途径：
- **软约束 (Soft Enforcement)**：将 IC/BC 的残差作为惩罚项加入总损失函数。例如，对于[狄利克雷边界条件](@entry_id:173524) $u(0,t)=T_L(t)$，可以加入损失项 $\sum_i (u_\theta(0, t_i) - T_L(t_i))^2$。这种方法实现简单灵活，但不能保证条件被精确满足。
- **硬约束 (Hard Enforcement)**：通过特殊设计网络结构来确保 IC/BC 被精确满足。例如，对于初始条件 $u(x,0)=u_0(x)$，可以将网络输出[参数化](@entry_id:265163)为 $u_\theta(x,t) = u_0(x) + t \cdot N_\theta(x,t)$，其中 $N_\theta$ 是一个神经网络。这种形式自动保证了在 $t=0$ 时，$u_\theta(x,0)=u_0(x)$。硬约束无需对应的损失项，但可能需要更精巧的架构设计。

#### 遵守[热力学](@entry_id:172368)与数学原理

除了 PDE 残差，代理模型还应遵守更基本的物理原理和数学性质，以确保其预测的有效性。
1.  **[热力学](@entry_id:172368)第二定律**：在[热传导](@entry_id:143509)中，局部[熵产](@entry_id:141771)率密度 $\sigma = -\frac{\mathbf{q} \cdot \nabla T}{T^2}$ 必须非负。如果采用[傅里叶定律](@entry_id:136311) $\mathbf{q} = -k\nabla T$，则 $\sigma = \frac{k \|\nabla T\|^2}{T^2}$。为了保证 $\sigma \ge 0$，[热导](@entry_id:189019)率 $k$ 必须非负。因此，任何旨在预测[热导](@entry_id:189019)率的代理模型 $k_\theta$ 都必须被约束为输出非负值。一个预测 $k  0$ 的模型不仅是物理上荒谬的（意味着热量从冷处自发流向热处），也会导致控制方程在数学上变得不适定 (ill-posed)。

2.  **数学适定性（[最大值原理](@entry_id:138611)）**：对于[稳态热传导](@entry_id:1132353)方程 $-\nabla \cdot (k \nabla T) = q$，其解的数学性质（如有界性）依赖于算子的椭圆性。经典的**[最大值原理](@entry_id:138611)**保证了在没有内部热源的情况下，温度的最大值和最小值必然出现在区域的边界上。这一原理成立的条件是热导率 $k$ 一致有界，即存在常数 $k_{\min}, k_{\max}$ 使得 $0  k_{\min} \le k(\boldsymbol{x}) \le k_{\max}  \infty$。因此，一个物理上可靠的代理模型 $k_\theta$ 应该被约束在这样一个有界的正值范围内，以保证其所描述的系统是数学上适定的。

3.  **[耦合输运](@entry_id:144035)（昂萨格关系）**：在涉及多种[输运过程](@entry_id:177992)（如热与质量同时传递）的更复杂系统中，[热力学通量](@entry_id:170306) $\boldsymbol{J}$ 与[热力学力](@entry_id:161907) $\boldsymbol{X}$ 之间通常存在线性关系 $\boldsymbol{J} = \boldsymbol{L}\boldsymbol{X}$。[熵产](@entry_id:141771)率为 $\sigma = \boldsymbol{J}^\top \boldsymbol{X} = \boldsymbol{X}^\top \boldsymbol{L} \boldsymbol{X}$。为了保证 $\sigma \ge 0$ 对所有可能的力 $\boldsymbol{X}$ 成立，现象学矩阵 $\boldsymbol{L}$ 必须是**[对称正定](@entry_id:145886) (Symmetric Positive Definite, SPD)** 的。因此，一个旨在学习耦合本构关系的代理模型 $\boldsymbol{L}_\theta$ 必须被约束为输出 SPD 矩阵。

#### 保持定性物理行为：[单调性](@entry_id:143760)

除了遵守定量的物理定律外，代理模型还应保持正确的**定性行为**。一个重要的例子是**[单调性](@entry_id:143760)**。 考虑一个[稳态热传导](@entry_id:1132353)问题，其控制方程为 $-\nabla \cdot (k \nabla T) = q$。根据[最大值原理](@entry_id:138611)的一个推论（[比较原理](@entry_id:165563)），可以严格证明，在边界条件固定的情况下，增加内部热源 $q$ 必然会导致整个温度场 $T$ 的非降（通常是增加）。即，若 $q_2(\boldsymbol{x}) \ge q_1(\boldsymbol{x})$，则对应的解 $T_2(\boldsymbol{x}) \ge T_1(\boldsymbol{x})$。

这是一个基本的物理直觉，但一个标准的代理模型（如无约束的神经网络）即使在完全单调的训练数据上进行训练，也**不能保证**其预测是单调的。由于权重可正可负，网络在插值时可能会产生不符合物理的“摆动”。为解决此问题，可以设计**单调神经网络**，例如，通过将所有网络权重约束为非负，并使用非递减的[激活函数](@entry_id:141784)。

此外，一个值得警惕的陷阱是训练数据本身的质量。如果用于生成训练数据的高保真求解器存在[数值不稳定性](@entry_id:137058)（例如，其离散[刚度矩阵](@entry_id:178659)不是一个**M-矩阵**），它可能产生违反单调性原理的数值伪影。在这种情况下，代理模型会忠实地学习这些非物理行为，导致其预测错误，即使模型本身结构合理。这凸显了生成高质量、物理一致的训练数据对于代理建模的重要性。