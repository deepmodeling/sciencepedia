{
    "hands_on_practices": [
        {
            "introduction": "在深入复杂的推导之前，理解伴随法为何如此强大至关重要。本练习通过一个思想实验，让您从高层次上定量比较不同方法在计算梯度时的成本。通过该练习 ，您将清晰地看到伴随法在设计参数众多时的独特优势和可扩展性，从而领会其在现代大规模优化问题中的核心价值。",
            "id": "3935153",
            "problem": "一个有界域中的稳态非线性热传导问题被离散化，得到代数残差方程 $\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$，其中 $\\mathbf{u} \\in \\mathbb{R}^{N_u}$ 是节点温度向量，$\\mathbf{p} \\in \\mathbb{R}^{N_p}$ 是设计参数向量，该向量线性参数化了空间变化的导热系数场。我们关注的量是一个单一的标量泛函 $J(\\mathbf{u})$，例如通过部分边界的总法向热通量。假设使用以下计算模型：\n- 名义参数 $\\mathbf{p}_0$ 及其收敛状态 $\\mathbf{u}_0$ 已经获得，并且相应的雅可比矩阵（状态切线）$\\mathbf{J}_0 \\equiv \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$ 已经组装好并且可以重复使用。\n- 对于一个不同的参数向量 $\\mathbf{p}$，使用牛顿法重新求解非线性状态需要 $S$ 次迭代，每次牛顿迭代需要进行一次大型稀疏线性求解，其系数矩阵为 $\\mathbf{J}(\\mathbf{u},\\mathbf{p})$。\n- 与大型稀疏线性求解相比，构造右端项、函数求值和向量运算的成本可以忽略不计。\n- 目标是计算在 $\\mathbf{p}_0$ 处的完整梯度 $\\nabla_{\\mathbf{p}} J(\\mathbf{u}(\\mathbf{p}))$。\n\n考虑三种方法：\n1. 对每个分量 $p_i$ 应用中心有限差分，每个参数需要两次扰动状态的重新求解。\n2. 通过在 $(\\mathbf{u}_0,\\mathbf{p}_0)$ 附近对残差进行线性化，并对每个参数求解一个线性灵敏度系统来获得直接灵敏度。\n3. 通过求解与标量目标 $J(\\mathbf{u})$ 相关联的单个伴随系统来获得的伴随法。\n\n在这些假设和成本模型下，推导每种方法计算关于所有 $N_p$ 个参数的完整梯度所需的总大型稀疏线性求解次数。将最终结果表示为行矩阵 $\\bigl[N_{\\mathrm{FD}} \\;\\; N_{\\mathrm{dir}} \\;\\; N_{\\mathrm{adj}}\\bigr]$，用 $N_p$ 和 $S$ 表示。不需要进行数值代入，也不需要单位。请提供未经四舍五入的最终表达式。",
            "solution": "首先验证问题，以确保其具有科学依据、良定性、客观性和完整性。\n\n### 步骤1：提取已知条件\n- 离散化的非线性残差方程：$\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$。\n- 节点温度的状态向量：$\\mathbf{u} \\in \\mathbb{R}^{N_u}$。\n- 设计参数向量：$\\mathbf{p} \\in \\mathbb{R}^{N_p}$。\n- 关注的标量：$J(\\mathbf{u})$。\n- 名义点：$(\\mathbf{u}_0, \\mathbf{p}_0)$，在该点 $\\mathbf{R}(\\mathbf{u}_0, \\mathbf{p}_0) = \\mathbf{0}$。\n- 名义点处的状态切线（雅可比矩阵）：$\\mathbf{J}_0 \\equiv \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$，其已经组装好且可重复使用。\n- 非线性状态重新求解的成本：$S$ 次迭代，每次迭代需要一次大型稀疏线性求解。这些求解的系数矩阵是依赖于状态的雅可比矩阵 $\\mathbf{J}(\\mathbf{u},\\mathbf{p})$。\n- 成本模型简化：与大型稀疏线性求解的成本相比，构造右端项、函数求值和向量运算的成本可以忽略不计。\n- 目标：计算在 $\\mathbf{p}_0$ 处的完整梯度 $\\nabla_{\\mathbf{p}} J(\\mathbf{u}(\\mathbf{p}))$。\n- 方法1（有限差分）：“每个参数两次扰动状态重新求解”。\n- 方法2（直接灵敏度）：“每个参数求解一个线性灵敏度系统”。\n- 方法3（伴随法）：“求解一个单一的伴随系统”。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题是计算科学与工程领域一个标准的、定义明确的练习，特别是在由偏微分方程控制的系统的灵敏度分析领域。\n- **科学依据：** 问题陈述基于数值分析（牛顿法）、有限元法（离散化残差）和灵敏度分析（直接法和伴随法）的既定原则。这是设计优化和不确定性量化中的一个典型问题。\n- **良定性：** 问题提供了一个明确的目标和一套完整的假设与定义，用于计算三种不同标准算法的计算成本。基于这些假设，存在唯一答案。\n- **客观性：** 语言正式、精确，没有任何主观性或模糊性。\n- **缺陷：** 该问题没有表现出任何缺陷。这是一个教科书式的例子，完整、一致、与指定主题相关且科学合理。\n\n### 步骤3：结论与行动\n问题有效。详细解答如下。\n\n目标是确定对于三种提出的方法中的每一种，计算具有 $N_p$ 个分量的完整梯度 $\\nabla_{\\mathbf{p}} J$ 所需的大型稀疏线性求解的总次数。成本单位为一次大型稀疏线性求解。\n\n### 方法1：中心有限差分 (FD)\n$J$ 关于第 $i$ 个参数 $p_i$ 的梯度可以使用中心有限差分公式来近似：\n$$ \\frac{dJ}{dp_i} \\approx \\frac{J(\\mathbf{u}(\\mathbf{p}_0 + \\epsilon \\mathbf{e}_i)) - J(\\mathbf{u}(\\mathbf{p}_0 - \\epsilon \\mathbf{e}_i))}{2\\epsilon} $$\n其中 $\\mathbf{e}_i$ 是第 $i$ 个标准基向量，$\\epsilon$ 是一个小的扰动量。\n为了计算这个表达式，我们需要计算两个扰动参数点处的状态向量：$\\mathbf{p}_+ = \\mathbf{p}_0 + \\epsilon \\mathbf{e}_i$ 时的 $\\mathbf{u}(\\mathbf{p}_+)$ 和 $\\mathbf{p}_- = \\mathbf{p}_0 - \\epsilon \\mathbf{e}_i$ 时的 $\\mathbf{u}(\\mathbf{p}_-)$。这涉及到两次求解非线性系统 $\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$。问题陈述中称其需要“每个参数两次扰动状态重新求解”。\n\n根据成本模型，使用牛顿法进行一次非线性重新求解的成本为 $S$ 次大型稀疏线性求解。因此，计算梯度的一个分量 $\\frac{dJ}{dp_i}$ 的成本为 $2 \\times S = 2S$ 次线性求解。\n\n要计算完整梯度 $\\nabla_{\\mathbf{p}} J$，必须对 $N_p$ 个参数中的每一个重复此过程。总成本为：\n$$ N_{\\mathrm{FD}} = N_p \\times (2S) = 2SN_p $$\n\n### 方法2：直接灵敏度\n泛函 $J$ 关于参数 $p_i$ 的全导数由链式法则给出：\n$$ \\frac{dJ}{dp_i} = \\frac{\\partial J}{\\partial \\mathbf{u}} \\frac{d\\mathbf{u}}{dp_i} $$\n其中导数在名义点 $(\\mathbf{u}_0, \\mathbf{p}_0)$ 处求值。向量 $\\frac{d\\mathbf{u}}{dp_i}$ 是状态关于参数 $p_i$ 的灵敏度。\n为了找到这个灵敏度向量，我们将控制残差方程 $\\mathbf{R}(\\mathbf{u}(\\mathbf{p}), \\mathbf{p}) = \\mathbf{0}$ 对 $p_i$ 求导，并在名义点处求值：\n$$ \\frac{d\\mathbf{R}}{dp_i} \\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} = \\frac{\\partial \\mathbf{R}}{\\partial \\mathbf{u}}\\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} \\frac{d\\mathbf{u}}{dp_i}\\bigg|_{\\mathbf{p}_0} + \\frac{\\partial \\mathbf{R}}{\\partial p_i}\\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} = \\mathbf{0} $$\n使用记号 $\\mathbf{J}_0 = \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$，我们可以将其重排为关于灵敏度向量 $\\frac{d\\mathbf{u}}{dp_i}$ 的线性系统：\n$$ \\mathbf{J}_0 \\frac{d\\mathbf{u}}{dp_i} = - \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n问题陈述该方法涉及“每个参数求解一个线性灵敏度系统”。这对应于求解上述方程。这需要为每个参数 $p_i$ 进行一次大型稀疏线性求解。由于有 $N_p$ 个参数，我们必须求解 $N_p$ 个这样的线性系统，每个系统对应一个灵敏度向量 $\\frac{d\\mathbf{u}}{dp_i}$，$i=1, \\dots, N_p$。所有系统的系数矩阵 $\\mathbf{J}_0$ 都是相同的。\n\n完整梯度的总成本是需要求解的系统数量：\n$$ N_{\\mathrm{dir}} = N_p \\times 1 = N_p $$\n\n### 方法3：伴随法\n当参数数量 $N_p$ 很大时，伴随法被设计用来高效地计算标量泛函的梯度。我们从与直接法中相同的梯度分量表达式开始：\n$$ \\frac{dJ}{dp_i} = \\frac{\\partial J}{\\partial \\mathbf{u}} \\frac{d\\mathbf{u}}{dp_i} $$\n从直接法中我们知道 $\\frac{d\\mathbf{u}}{dp_i} = - \\mathbf{J}_0^{-1} \\frac{\\partial \\mathbf{R}}{\\partial p_i}$。代入可得：\n$$ \\frac{dJ}{dp_i} = \\left( -\\frac{\\partial J}{\\partial \\mathbf{u}} \\mathbf{J}_0^{-1} \\right) \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n伴随法引入一个单一的伴随向量 $\\boldsymbol{\\lambda} \\in \\mathbb{R}^{N_u}$，它被定义为以下线性系统的解，该系统称为伴随系统：\n$$ \\mathbf{J}_0^T \\boldsymbol{\\lambda} = - \\left( \\frac{\\partial J}{\\partial \\mathbf{u}} \\right)^T $$\n求解伴随向量 $\\boldsymbol{\\lambda}$ 需要一次大型稀疏线性求解，正如问题中所述：“求解一个单一的伴随系统”。\n对伴随方程取转置，我们得到 $\\boldsymbol{\\lambda}^T \\mathbf{J}_0 = - \\frac{\\partial J}{\\partial \\mathbf{u}}$。右乘 $\\mathbf{J}_0^{-1}$ 得到 $\\boldsymbol{\\lambda}^T = - \\frac{\\partial J}{\\partial \\mathbf{u}} \\mathbf{J}_0^{-1}$。这正是梯度表达式中括号内的项。\n\n将 $\\boldsymbol{\\lambda}^T$ 代入 $\\frac{dJ}{dp_i}$ 的表达式中可得：\n$$ \\frac{dJ}{dp_i} = \\boldsymbol{\\lambda}^T \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n一旦计算出单个伴随向量 $\\boldsymbol{\\lambda}$，就可以通过计算 $\\boldsymbol{\\lambda}$ 与每个 $p_i$ 对应的向量 $\\frac{\\partial \\mathbf{R}}{\\partial p_i}$ 的内积来找到梯度的所有 $N_p$ 个分量。根据成本模型，向量运算（如内积）和构造向量（如 $\\frac{\\partial \\mathbf{R}}{\\partial p_i}$）的成本可以忽略不计。\n因此，伴随法的总成本完全由求解 $\\boldsymbol{\\lambda}$ 的成本决定。\n\n总成本为：\n$$ N_{\\mathrm{adj}} = 1 $$\n\n### 总结\n计算完整梯度的三种方法所需的大型稀疏线性求解总次数分别为：\n- 有限差分法：$N_{\\mathrm{FD}} = 2SN_p$\n- 直接灵敏度法：$N_{\\mathrm{dir}} = N_p$\n- 伴随法：$N_{\\mathrm{adj}} = 1$\n\n最终结果，以所要求的行矩阵形式表示为 $\\begin{pmatrix} 2SN_p  N_p  1 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 S N_p  N_p  1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "掌握了伴随法的计算优势之后，我们转向其具体推导过程。这个练习  将引导您从抽象的成本分析走向具体的数学推导，通过解析求解一个一维热传导问题，您将对基于拉格朗日乘子法的伴随系统构建过程有更深刻的理解，并掌握如何确定伴随方程及其相应的边界条件。",
            "id": "3935200",
            "problem": "考虑一根均匀、各向同性的一维杆中的稳态热传导，其占据空间域 $\\Omega = (0,L)$，具有恒定的热导率 $k>0$ 和均匀的体积生热率 $s_0>0$。令 $u(x)$ 表示温度场。从能量守恒和傅里叶热传导定律出发，建立 $u(x)$ 的控制偏微分方程(PDE)和边界条件，即齐次狄利克雷边界条件 $u(0)=0$ 和 $u(L)=0$。将目标泛函定义为 $u$ 的非线性泛函，\n$$\nJ(u) \\;=\\; \\int_{0}^{L} \\phi(u(x))\\,dx, \\qquad \\text{with} \\quad \\phi(u) \\;=\\; \\tfrac{1}{2}u^2.\n$$\n将热导率 $k$ 视为唯一关心的标量参数。使用基于伴随的灵敏度方法：\n\n1) 通过构建一个强制施加 PDE 约束的拉格朗日量，并要求其相对于 $u$ 的变分保持驻定，来推导伴随边值问题。确定伴随强迫项 $\\partial \\phi/\\partial u$ 以及与在给定的 $u$ 的狄利克雷约束下消除边界变分相一致的伴随边界条件。\n\n2) 显式求解正问题以得到 $u(x)$。\n\n3) 显式求解线性化伴随问题以得到伴随场 $\\lambda(x)$。\n\n4) 利用你的正问题和伴随问题的解，推导目标泛函相对于热导率的梯度 $dJ/dk$，并将其简化为只包含 $s_0$、$L$ 和 $k$ 的单个闭式解析表达式。\n\n将你最终的 $dJ/dk$ 答案表示为只包含 $s_0$、$L$ 和 $k$ 的单个闭式表达式。最终表达式中不要包含单位。",
            "solution": "分析从根据要求、从第一性原理建立温度场 $u(x)$ 的控制方程开始。\n\n对于稳态一维传热，应用于无穷小控制体积 $dx$ 的能量守恒原理指出，传出该体积的净热传导率必须等于其内部的生热率。这给出了 $\\frac{dq}{dx} = s_0$，其中 $q(x)$ 是热通量，$s_0$ 是均匀的体积生热率。\n傅里叶热传导定律将热通量与温度梯度联系起来：$q = -k \\frac{du}{dx}$，其中 $k$ 是热导率。\n将傅里叶定律代入能量守恒方程，得到：\n$$\n\\frac{d}{dx}\\left(-k \\frac{du}{dx}\\right) = s_0\n$$\n由于热导率 $k$ 是常数，这简化为正问题的控制常微分方程(ODE)：\n$$\n-k \\frac{d^2u}{dx^2} = s_0\n$$\n该问题定义在域 $x \\in (0, L)$ 上，具有齐次狄利克雷边界条件 $u(0)=0$ 和 $u(L)=0$。我们定义状态残差 $R(u, k) = k \\frac{d^2u}{dx^2} + s_0 = 0$。\n\n任务是求解目标泛函 $J(u) = \\int_{0}^{L} \\frac{1}{2}u^2(x)\\,dx$ 相对于参数 $k$ 的梯度。我们使用伴随法进行求解。\n\n1) 伴随边值问题的推导\n\n我们通过将目标泛函 $J$ 与由拉格朗日乘子场 $\\lambda(x)$（也称为伴随场）强制施加的控制 PDE 相增广，来构建拉格朗日泛函 $\\mathcal{L}$：\n$$\n\\mathcal{L}(u, k, \\lambda) = J(u) + \\int_{0}^{L} \\lambda(x) R(u, k)\\,dx = \\int_{0}^{L} \\frac{1}{2}u^2\\,dx + \\int_{0}^{L} \\lambda(x) \\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx\n$$\n伴随问题是通过要求拉格朗日量相对于状态场 $u$ 的任意容许变分保持驻定来推导的。一个容许变分 $\\delta u$ 必须满足 $u$ 的狄利克雷边界条件的齐次形式，即 $\\delta u(0)=0$ 和 $\\delta u(L)=0$。驻定性条件为 $\\delta_u \\mathcal{L} = 0$：\n$$\n\\delta_u \\mathcal{L} = \\frac{\\delta \\mathcal{L}}{\\delta u}[\\delta u] = \\int_{0}^{L} u\\,\\delta u\\,dx + \\int_{0}^{L} \\lambda \\left(k \\frac{d^2(\\delta u)}{dx^2}\\right) dx = 0\n$$\n我们对第二项应用两次分部积分法：\n$$\n\\int_{0}^{L} k\\lambda \\frac{d^2(\\delta u)}{dx^2}\\,dx = \\left[k\\lambda \\frac{d(\\delta u)}{dx}\\right]_0^L - \\int_{0}^{L} k\\frac{d\\lambda}{dx}\\frac{d(\\delta u)}{dx}\\,dx\n$$\n$$\n= \\left[k\\lambda \\frac{d(\\delta u)}{dx}\\right]_0^L - \\left[k\\frac{d\\lambda}{dx}\\delta u\\right]_0^L + \\int_{0}^{L} k\\frac{d^2\\lambda}{dx^2}\\delta u\\,dx\n$$\n将此代回驻定性条件得到：\n$$\n\\int_{0}^{L} \\left(u + k\\frac{d^2\\lambda}{dx^2}\\right)\\delta u\\,dx + \\left[k\\lambda \\frac{d(\\delta u)}{dx} - k\\frac{d\\lambda}{dx}\\delta u\\right]_0^L = 0\n$$\n由于 $\\delta u(0)=0$ 和 $\\delta u(L)=0$，项 $k\\frac{d\\lambda}{dx}\\delta u$ 在边界处为零。为了对任意变分 $\\delta u$ 消除剩余的边界项 $k\\lambda \\frac{d(\\delta u)}{dx}$，我们必须对伴随场 $\\lambda$ 施加边界条件。确保边界项为零的最简单选择是对 $\\lambda$ 施加齐次狄利克雷边界条件：$\\lambda(0)=0$ 和 $\\lambda(L)=0$。这些是与正问题约束相一致的伴随边界条件。\n\n消除了边界项后，驻定性条件简化为：\n$$\n\\int_{0}^{L} \\left(u + k\\frac{d^2\\lambda}{dx^2}\\right)\\delta u\\,dx = 0\n$$\n为了使该积分对任何容许变分 $\\delta u$ 都为零，被积函数必须恒等于零。这就得到了伴随控制 PDE：\n$$\nk\\frac{d^2\\lambda}{dx^2} + u(x) = 0 \\quad \\text{or} \\quad k\\frac{d^2\\lambda}{dx^2} = -u(x)\n$$\n问题要求确定伴随强迫项 $\\partial \\phi/\\partial u$。在我们的问题中，$\\phi(u) = \\frac{1}{2}u^2$，因此它对 $u$ 的导数是 $\\frac{\\partial \\phi}{\\partial u} = u(x)$。伴随方程可以写成 $k\\frac{d^2\\lambda}{dx^2} = -\\frac{\\partial \\phi}{\\partial u}$。因此，项 $\\frac{\\partial \\phi}{\\partial u}=u(x)$ 作为伴随问题的源项。\n\n完整的伴随边值问题是：\n-   PDE: $k\\frac{d^2\\lambda}{dx^2} = -u(x)$，对于 $x \\in (0,L)$。\n-   边界条件: $\\lambda(0)=0$, $\\lambda(L)=0$。\n\n2) 正问题的求解\n\n我们求解正问题：$k \\frac{d^2u}{dx^2} = -s_0$，其中 $u(0)=0$ 且 $u(L)=0$。\n对 $x$ 积分一次：\n$$\nk \\frac{du}{dx} = -s_0 x + C_1\n$$\n第二次积分：\n$$\nk u(x) = -\\frac{s_0}{2}x^2 + C_1 x + C_2\n$$\n应用边界条件求常数 $C_1$ 和 $C_2$：\n-   在 $x=0$ 处：$k u(0) = 0 \\implies 0 = 0 + 0 + C_2 \\implies C_2=0$。\n-   在 $x=L$ 处：$k u(L) = 0 \\implies 0 = -\\frac{s_0}{2}L^2 + C_1 L \\implies C_1 = \\frac{s_0 L}{2}$。\n代入常数，温度场为：\n$$\nk u(x) = -\\frac{s_0}{2}x^2 + \\frac{s_0 L}{2}x \\implies u(x) = \\frac{s_0}{2k}(Lx - x^2)\n$$\n\n3) 伴随问题的求解\n\n我们求解伴随问题：$k\\frac{d^2\\lambda}{dx^2} = -u(x)$，其中 $\\lambda(0)=0$ 且 $\\lambda(L)=0$。\n代入 $u(x)$ 的表达式：\n$$\nk\\frac{d^2\\lambda}{dx^2} = -\\frac{s_0}{2k}(Lx - x^2) \\implies \\frac{d^2\\lambda}{dx^2} = -\\frac{s_0}{2k^2}(Lx - x^2)\n$$\n对 $x$ 积分一次：\n$$\n\\frac{d\\lambda}{dx} = -\\frac{s_0}{2k^2}\\left(\\frac{L}{2}x^2 - \\frac{1}{3}x^3\\right) + D_1\n$$\n第二次积分：\n$$\n\\lambda(x) = -\\frac{s_0}{2k^2}\\left(\\frac{L}{6}x^3 - \\frac{1}{12}x^4\\right) + D_1 x + D_2\n$$\n应用边界条件求 $D_1$ 和 $D_2$：\n-   在 $x=0$ 处：$\\lambda(0)=0 \\implies 0 = 0 + 0 + D_2 \\implies D_2=0$。\n-   在 $x=L$ 处：$\\lambda(L)=0 \\implies 0 = -\\frac{s_0}{2k^2}\\left(\\frac{L^4}{6} - \\frac{L^4}{12}\\right) + D_1 L$。\n$$\n0 = -\\frac{s_0}{2k^2}\\left(\\frac{L^4}{12}\\right) + D_1 L \\implies D_1 L = \\frac{s_0 L^4}{24k^2} \\implies D_1 = \\frac{s_0 L^3}{24k^2}\n$$\n代入常数，伴随场为：\n$$\n\\lambda(x) = -\\frac{s_0}{2k^2}\\left(\\frac{Lx^3}{6} - \\frac{x^4}{12}\\right) + \\frac{s_0 L^3}{24k^2}x = \\frac{s_0}{24k^2}(x^4 - 2Lx^3 + L^3x)\n$$\n\n4) 梯度 $dJ/dk$ 的推导\n\n伴随法的核心优势在于，目标泛函对某个参数的全导数可以计算为拉格朗日量对该参数的偏导数，此时状态变量和伴随变量保持不变。这是因为根据伴随方程的定义($\\frac{\\partial \\mathcal{L}}{\\partial u}=0$)，涉及状态变量灵敏度的另一项 $\\frac{\\partial \\mathcal{L}}{\\partial u}\\frac{du}{dk}$ 为零。\n$$\n\\frac{dJ}{dk} = \\frac{d\\mathcal{L}}{dk} = \\frac{\\partial \\mathcal{L}}{\\partial k} = \\frac{\\partial}{\\partial k} \\int_{0}^{L} \\lambda(x) \\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx\n$$\n在积分号下对 $k$ 求导：\n$$\n\\frac{dJ}{dk} = \\int_{0}^{L} \\lambda(x) \\frac{\\partial}{\\partial k}\\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx = \\int_{0}^{L} \\lambda(x) \\frac{d^2u}{dx^2} dx\n$$\n从正问题中，我们知道 $\\frac{d^2u}{dx^2} = -\\frac{s_0}{k}$。将此代入梯度的表达式中：\n$$\n\\frac{dJ}{dk} = \\int_{0}^{L} \\lambda(x) \\left(-\\frac{s_0}{k}\\right) dx = -\\frac{s_0}{k} \\int_{0}^{L} \\lambda(x) dx\n$$\n现在我们计算伴随解 $\\lambda(x)$ 的积分：\n$$\n\\int_{0}^{L} \\lambda(x) dx = \\int_{0}^{L} \\frac{s_0}{24k^2}(x^4 - 2Lx^3 + L^3x) dx\n$$\n$$\n= \\frac{s_0}{24k^2} \\left[ \\frac{x^5}{5} - \\frac{2L x^4}{4} + \\frac{L^3 x^2}{2} \\right]_0^L = \\frac{s_0}{24k^2} \\left( \\frac{L^5}{5} - \\frac{L^5}{2} + \\frac{L^5}{2} \\right) = \\frac{s_0}{24k^2} \\frac{L^5}{5} = \\frac{s_0 L^5}{120 k^2}\n$$\n最后，我们将此结果代回梯度的表达式中：\n$$\n\\frac{dJ}{dk} = -\\frac{s_0}{k} \\left( \\frac{s_0 L^5}{120 k^2} \\right) = -\\frac{s_0^2 L^5}{120 k^3}\n$$\n这就是目标泛函 $J$ 对热导率 $k$ 的灵敏度的最终闭式解析表达式。",
            "answer": "$$\n\\boxed{-\\frac{s_0^2 L^5}{120 k^3}}\n$$"
        },
        {
            "introduction": "理论的最终目的是指导实践。本练习  的目标是将伴随法的理论转化为可靠的计算工具，您将为有限体积模型实现离散伴随法。更重要的是，本练习引入了泰勒测试（Taylor test），这是一种验证梯度计算准确性的黄金标准，它能确保您编写的代码不仅能够运行，而且结果可信、精确。",
            "id": "3935211",
            "problem": "考虑在一根长度为 $L$ 的杆上的一维稳态热传导，其导热系数在空间上变化，并通过一个向量 $p \\in \\mathbb{R}^{M}$ 在单元面上进行参数化。其中，对于一个具有 $N$ 个节点和间距 $\\Delta x = L/(N-1)$ 的均匀网格，有 $M = N - 1$。其控制偏微分方程 (PDE) 为 $- \\dfrac{d}{dx}\\left(k(x;p)\\,\\dfrac{du}{dx}\\right) = q(x)$，边界条件为狄利克雷边界条件 $u(0) = T_0$ 和 $u(L) = T_1$。其中 $u(x)$ 是温度，单位为 $\\mathrm{K}$；$k(x;p)$ 是导热系数，单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-1}\\cdot\\mathrm{K}^{-1}$；$q(x)$ 是体积热源，单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-3}$。\n\n在均匀网格上使用有限体积法进行离散化，用 $p$ 的分量表示面上的 $k$，以获得内部未知温度 $u \\in \\mathbb{R}^{n}$ 的线性代数系统，其中 $n = N - 2$：\n$$\nA(p)\\,u = b(p),\n$$\n其中 $A(p) \\in \\mathbb{R}^{n \\times n}$ 和 $b(p) \\in \\mathbb{R}^{n}$ 是根据面导热系数和狄利克雷边界值构建的。定义一个二次目标泛函\n$$\nJ(u) = \\frac{1}{2}\\sum_{i=1}^{n}\\omega_i\\left(u_i - u^{\\mathrm{ref}}_i\\right)^2,\n$$\n其中 $\\omega_i > 0$ 是权重，$u^{\\mathrm{ref}} \\in \\mathbb{R}^{n}$ 是一个参考内部温度剖面。\n\n任务：从傅里叶热传导定律和能量守恒定律出发，推导离散伴随方程以及目标泛函 $J$ 相对于参数向量 $p$ 的梯度的伴随表达式。然后实现一个程序，该程序能够：\n- 求解正问题 $A(p)\\,u=b(p)$ 以获得 $u$。\n- 求解伴随系统以获得伴随变量 $\\lambda \\in \\mathbb{R}^{n}$。\n- 使用伴随法计算梯度 $\\nabla_p J(p)$。\n- 通过比较基于伴随的方向导数与基于有限差分的方向导数，执行泰勒检验以验证梯度精度。对于给定的方向 $h \\in \\mathbb{R}^{M}$ 和一系列步长 $\\{\\varepsilon_k\\}$，计算：\n  - 一阶误差 $E_1(\\varepsilon_k) = \\left|J(p + \\varepsilon_k h) - J(p)\\right|$。\n  - 二阶校正误差 $E_2(\\varepsilon_k) = \\left|J(p + \\varepsilon_k h) - J(p) - \\varepsilon_k\\,\\nabla_p J(p)^\\top h\\right|$。\n通过拟合 $\\log E_1$ 与 $\\log \\varepsilon$ 以及 $\\log E_2$ 与 $\\log \\varepsilon$ 并分别提取斜率 $s_1$ 和 $s_2$ 来估计收敛阶。如果在规定的容差范围内，$s_1$ 约等于 $1$ 且 $s_2$ 约等于 $2$，则认为泰勒检验通过。\n\n输入必须遵守物理单位：$L$ 的单位为 $\\mathrm{m}$， $p$ 的导热系数分量的单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-1}\\cdot\\mathrm{K}^{-1}$，$q$ 的单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-3}$，温度 $T_0$、$T_1$、$u$ 和 $u^{\\mathrm{ref}}$ 的单位为 $\\mathrm{K}$。程序的输出是无量纲的布尔值，指示每种情况下泰勒检验是否通过。\n\n测试套件：\n- 情况 1（一般可变性）：$L = 1$，$N = 21$，$q(x) \\equiv q_0 = 1000$，$T_0 = 300$，$T_1 = 310$，$\\omega_i \\equiv 1$，$u^{\\mathrm{ref}}_i = 305$ (对所有 $i$)，基础 $p_j = 10\\left(1 + 0.2\\sin\\left(\\pi\\frac{j+0.5}{N-1}\\right)\\right)$ (对 $j=0,\\dots,N-2$)，方向 $h$ 为确定性随机单位向量。\n- 情况 2（边界影响，小系统）：$L = 0.1$，$N = 5$，$q(x) \\equiv 0$，$T_0 = 400$，$T_1 = 300$，$\\omega_i \\equiv 1$，$u^{\\mathrm{ref}}_i = 350$ (对所有 $i$)，基础 $p_j = 20$ (对所有面)，方向 $h$ 仅在边界两面 $j=0$ 和 $j=N-2$ 上有支撑，分量分别为 $1$ 和 $-1$，并归一化为单位范数。\n- 情况 3（具有随机权重和参考值的大系统）：$L = 2$，$N = 31$，$q(x) \\equiv q_0 = 500$，$T_0 = 290$，$T_1 = 315$，$\\omega_i$ 为 $[0.5,1.5]$ 区间内的确定性随机正分量，$u^{\\mathrm{ref}}$ 为 $[300,305]$ 区间内的确定性随机分量，基础 $p_j = 15\\left(1 + 0.1\\cos\\left(2\\pi\\frac{j+0.5}{N-1}\\right)\\right)$，方向 $h$ 为确定性随机单位向量。\n\n使用步长 $\\varepsilon_k \\in \\{10^{-1}, 5\\times10^{-2}, 2.5\\times10^{-2}, 1.25\\times10^{-2}, 6.25\\times10^{-3}\\}$。如果拟合的斜率满足 $|s_1 - 1| \\leq 0.15$ 和 $|s_2 - 2| \\leq 0.15$，则认为该情况的泰勒检验通过。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1,result_2,result_3]$），其中每个 $result_i$ 是一个布尔值，指示相应测试用例的泰勒检验是否通过。",
            "solution": "经分析，问题陈述有效。它在科学上基于热传导原理，在数学上是适定的、客观的，并为获得唯一解和进行验证提供了完整且一致的信息集。因此，我们可以进行推导和实现。\n\n核心任务是推导一个目标泛函相对于导热系数参数的梯度的伴随表达式，并使用泰勒检验验证其正确性。推导过程主要分为三个阶段：离散化控制偏微分方程、构建伴随问题以及推导梯度表达式。\n\n**1. 有限体积离散化（正问题）**\n\n一维稳态热传导的控制方程由能量守恒原理给出：\n$$\n- \\frac{d}{dx}\\left(k(x;p)\\,\\frac{du}{dx}\\right) = q(x)\n$$\n其中 $u(x)$ 是温度，$k(x;p)$ 是由向量 $p \\in \\mathbb{R}^{M}$ 参数化的导热系数，$q(x)$ 是体积热源。区域是一根长度为 $L$ 的杆，具有狄利克雷边界条件 $u(0) = T_0$ 和 $u(L) = T_1$。\n\n我们使用一个包含 $N$ 个节点 $x_i = i \\Delta x$（$i=0, 1, \\dots, N-1$）的均匀网格来离散化该区域，网格间距为 $\\Delta x = L/(N-1)$。温度未知的内部节点为 $i=1, \\dots, n$，其中 $n = N-2$。这些节点上的温度被组合成一个向量 $u \\in \\mathbb{R}^{n}$。导热系数定义在 $M=N-1$ 个节点间的面上，参数 $p_j$ 表示节点 $j$ 和节点 $j+1$ 之间的面上的导热系数，其中 $j=0, \\dots, M-1$。\n\n应用有限体积法，我们在每个内部节点 $i$ 的中心处对控制方程进行控制体积 (CV) 积分。节点 $i$ 的控制体积从面 $i-\\frac{1}{2}$ 延伸到面 $i+\\frac{1}{2}$。\n$$\n\\int_{x_{i-1/2}}^{x_{i+1/2}} - \\frac{d}{dx}\\left(k\\,\\frac{du}{dx}\\right) dx = \\int_{x_{i-1/2}}^{x_{i+1/2}} q(x) dx\n$$\n根据微积分基本定理，左侧的积分变成了控制体积各面上的热通量 $F = -k \\frac{du}{dx}$ 之差：\n$$\n\\left(-k\\,\\frac{du}{dx}\\right)\\bigg|_{x_{i+1/2}} - \\left(-k\\,\\frac{du}{dx}\\right)\\bigg|_{x_{i-1/2}} = \\bar{q}_i \\Delta x\n$$\n其中 $\\bar{q}_i$ 是控制体积内的平均热源。使用中心差分格式和面导热系数 $p_j$ 来近似通量，我们有：\n- 面 $i-\\frac{1}{2}$ 处的通量（节点 $i-1$ 和 $i$ 之间，导热系数为 $p_{i-1}$）：$F_{i-1/2} \\approx -p_{i-1} \\frac{u_i - u_{i-1}}{\\Delta x}$。\n- 面 $i+\\frac{1}{2}$ 处的通量（节点 $i$ 和 $i+1$ 之间，导热系数为 $p_i$）：$F_{i+1/2} \\approx -p_i \\frac{u_{i+1} - u_i}{\\Delta x}$。\n\n将这些代入内部节点 $i \\in \\{2, \\dots, n-1\\}$ 的平衡方程中，得到：\n$$\n-p_i \\frac{u_{i+1} - u_i}{\\Delta x} - \\left(-p_{i-1} \\frac{u_i - u_{i-1}}{\\Delta x}\\right) = q_i \\Delta x\n$$\n对未知温度 $u_i$ 进行整理，得到第 $i$ 行的线性方程：\n$$\n\\frac{1}{\\Delta x^2} \\left[ -p_{i-1} u_{i-1} + (p_{i-1} + p_i) u_i - p_i u_{i+1} \\right] = q_i\n$$\n对于邻近边界的节点，我们引入已知的温度 $u_0=T_0$ 和 $u_n+1=u_{N-1}=T_1$：\n- 对于节点 $i=1$：$-p_1 \\frac{u_2 - u_1}{\\Delta x} + p_0 \\frac{u_1 - T_0}{\\Delta x} = q_1 \\Delta x \\implies \\frac{1}{\\Delta x^2} \\left[ (p_0+p_1)u_1 - p_1 u_2 \\right] = q_1 + \\frac{p_0 T_0}{\\Delta x^2}$。\n- 对于节点 $i=n=N-2$：$-p_{n} \\frac{T_1 - u_n}{\\Delta x} + p_{n-1} \\frac{u_n - u_{n-1}}{\\Delta x} = q_n \\Delta x \\implies \\frac{1}{\\Delta x^2} \\left[ -p_{n-1}u_{n-1} + (p_{n-1}+p_n)u_n \\right] = q_n + \\frac{p_n T_1}{\\Delta x^2}$。\n\n这组 $n$ 个线性方程构成了系统 $A(p)u = b(p)$，其中 $A(p) \\in \\mathbb{R}^{n \\times n}$ 是一个对称三对角矩阵，$b(p) \\in \\mathbb{R}^{n}$ 是源向量。\n\n**2. 伴随方程的构建**\n\n目标泛函 $J$ 通过状态变量 $u$ 隐式地依赖于参数 $p$：$J(p) = J(u(p))$。它关于参数 $p_j$ 的梯度使用链式法则求得：\n$$\n\\frac{dJ}{dp_j} = \\frac{\\partial J}{\\partial u}^T \\frac{\\partial u}{\\partial p_j}\n$$\n灵敏度项 $\\frac{\\partial u}{\\partial p_j}$ 是通过对状态方程 $R(u, p) = A(p)u - b(p) = 0$ 关于 $p_j$ 微分来隐式定义的：\n$$\n\\frac{d R}{d p_j} = \\frac{\\partial R}{\\partial u}\\frac{\\partial u}{\\partial p_j} + \\frac{\\partial R}{\\partial p_j} = 0 \\implies A(p)\\frac{\\partial u}{\\partial p_j} = -\\frac{\\partial R}{\\partial p_j}\n$$\n解出 $\\frac{\\partial u}{\\partial p_j}$ 得到 $\\frac{\\partial u}{\\partial p_j} = -A(p)^{-1} \\frac{\\partial R}{\\partial p_j}$。将其代入梯度表达式：\n$$\n\\frac{dJ}{dp_j} = - \\left(\\frac{\\partial J}{\\partial u}\\right)^T A(p)^{-1} \\frac{\\partial R}{\\partial p_j} = - \\left( (A(p)^{-1})^T \\frac{\\partial J}{\\partial u} \\right)^T \\frac{\\partial R}{\\partial p_j}\n$$\n为避免计算成本高昂的矩阵求逆 $A(p)^{-1}$，我们定义一个伴随变量 $\\lambda \\in \\mathbb{R}^n$ 作为**伴随方程**的解：\n$$\nA(p)^T \\lambda = -\\frac{\\partial J}{\\partial u}\n$$\n由于矩阵 $A(p)$ 是对称的（$A(p)^T = A(p)$），伴随方程变为 $A(p)\\lambda = -\\nabla_u J$。目标泛函 $J(u) = \\frac{1}{2}\\sum_{i=1}^{n}\\omega_i(u_i - u^{\\mathrm{ref}}_i)^2$ 关于 $u$ 的梯度是一个向量，其分量为 $(\\nabla_u J)_i = \\omega_i(u_i - u^{\\mathrm{ref}}_i)$。\n\n根据 $\\lambda$ 的定义，梯度表达式简化为：\n$$\n\\frac{dJ}{dp_j} = \\lambda^T \\frac{\\partial R}{\\partial p_j}\n$$\n\n**3. 梯度表达式**\n\n最后一步是计算残差向量的偏导数 $\\frac{\\partial R}{\\partial p_j}$。内部节点 $i$ 的残差为 $R_i(u, p) = \\sum_{k=1}^n A_{ik}(p)u_k - b_i(p)$。我们分析它对每个参数 $p_j$（其中 $j \\in \\{0, \\dots, M-1\\}$）的依赖性。\n\n残差向量由物理平衡方程定义：\n$R_1 = \\frac{1}{\\Delta x^2} \\left[ (p_0+p_1)u_1 - p_1 u_2 - p_0 T_0 \\right] - q_1$\n$R_i = \\frac{1}{\\Delta x^2} \\left[ -p_{i-1}u_{i-1} + (p_{i-1}+p_i)u_i - p_i u_{i+1} \\right] - q_i$, 对于 $i \\in \\{2, \\dots, n-1\\}$\n$R_n = \\frac{1}{\\Delta x^2} \\left[ -p_{n-1}u_{n-1} + (p_{n-1}+p_n)u_n - p_n T_1 \\right] - q_n$\n\n我们计算残差向量分量 $R_i$ 关于参数 $p_j$ 的偏导数：\n\n- 对于 $j=0$（第一个面）：$p_0$ 仅出现在 $R_1$ 中。\n  $\\frac{\\partial R_1}{\\partial p_0} = \\frac{1}{\\Delta x^2}(u_1 - T_0)$。所有其他的 $\\frac{\\partial R_i}{\\partial p_0}$ 均为 $0$。\n  所以，$\\frac{dJ}{dp_0} = \\lambda^T \\frac{\\partial R}{\\partial p_0} = \\lambda_1 \\frac{u_1 - T_0}{\\Delta x^2}$。\n\n- 对于 $j \\in \\{1, \\dots, n-1\\}$（内部面）：$p_j$ 出现在 $R_j$ 和 $R_{j+1}$ 中。\n  $\\frac{\\partial R_j}{\\partial p_j} = \\frac{1}{\\Delta x^2}(u_j - u_{j+1})$\n  $\\frac{\\partial R_{j+1}}{\\partial p_j} = \\frac{1}{\\Delta x^2}(-u_j + u_{j+1})$\n  所以，$\\frac{dJ}{dp_j} = \\lambda_j \\frac{\\partial R_j}{\\partial p_j} + \\lambda_{j+1} \\frac{\\partial R_{j+1}}{\\partial p_j} = \\frac{(\\lambda_j - \\lambda_{j+1})(u_j - u_{j+1})}{\\Delta x^2}$。\n\n- 对于 $j=n=N-2$（最后一个面）：$p_n$ 仅出现在 $R_n$ 中。\n  $\\frac{\\partial R_n}{\\partial p_n} = \\frac{1}{\\Delta x^2}(u_n - T_1)$。所有其他的 $\\frac{\\partial R_i}{\\partial p_n}$ 均为 $0$。\n  所以，$\\frac{dJ}{dp_n} = \\lambda_n \\frac{u_n - T_1}{\\Delta x^2}$。\n\n总结来说，梯度 $\\nabla_p J$ 的分量是：\n$$\n\\frac{dJ}{dp_j} =\n\\begin{cases}\n \\lambda_1 \\frac{u_1 - T_0}{\\Delta x^2}   \\text{若 } j=0 \\\\\n \\frac{(\\lambda_j - \\lambda_{j+1})(u_j - u_{j+1})}{\\Delta x^2}   \\text{若 } 1 \\le j \\le n-1 \\\\\n \\lambda_n \\frac{u_n - T_1}{\\Delta x^2}   \\text{若 } j=n=N-2\n\\end{cases}\n$$\n这些公式使用基于1的索引来表示向量 $u$ 和 $\\lambda$。\n\n计算梯度的步骤如下：\n1.  求解正问题 $A(p)u = b(p)$ 以找到温度剖面 $u$。\n2.  使用 $u$ 计算伴随系统的右端项 $-\\nabla_u J$。\n3.  求解伴随问题 $A(p)\\lambda = -\\nabla_u J$ 以找到伴随变量 $\\lambda$。\n4.  结合 $u$ 和 $\\lambda$，使用推导出的公式计算 $\\nabla_p J$。\n\n泰勒检验通过比较基于伴随的方向导数 $\\nabla_p J(p)^T h$ 与有限差分近似来验证此梯度。对于一个光滑函数 $J(p)$，泰勒定理指出 $J(p+\\varepsilon h) = J(p) + \\varepsilon \\nabla_p J(p)^T h + O(\\varepsilon^2)$。误差 $E_1 = |J(p+\\varepsilon h) - J(p)|$ 和 $E_2 = |J(p+\\varepsilon h) - J(p) - \\varepsilon \\nabla_p J(p)^T h|$ 预计分别以 $O(\\varepsilon^1)$ 和 $O(\\varepsilon^2)$ 的阶数收敛。绘制 $\\log(E)$ 与 $\\log(\\varepsilon)$ 的关系图应得到斜率分别近似为 $1$ 和 $2$ 的直线。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for adjoint-based gradient verification.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general variability)\n        {\n            \"L\": 1.0, \"N\": 21, \"q0\": 1000.0, \"T0\": 300.0, \"T1\": 310.0,\n            \"omega_mode\": \"const\", \"u_ref_mode\": \"const\",\n            \"p_mode\": \"sin\", \"h_mode\": \"random\", \"seed\": 0\n        },\n        # Case 2 (boundary-influenced, small system)\n        {\n            \"L\": 0.1, \"N\": 5, \"q0\": 0.0, \"T0\": 400.0, \"T1\": 300.0,\n            \"omega_mode\": \"const\", \"u_ref_mode\": \"const\",\n            \"p_mode\": \"const\", \"h_mode\": \"boundary\", \"seed\": 1\n        },\n        # Case 3 (larger system with random weights and reference)\n        {\n            \"L\": 2.0, \"N\": 31, \"q0\": 500.0, \"T0\": 290.0, \"T1\": 315.0,\n            \"omega_mode\": \"random\", \"u_ref_mode\": \"random\",\n            \"p_mode\": \"cos\", \"h_mode\": \"random\", \"seed\": 2\n        }\n    ]\n\n    epsilons = np.array([1e-1, 5e-2, 2.5e-2, 1.25e-2, 6.25e-3])\n    slope_tolerance = 0.15\n    results = []\n\n    for case in test_cases:\n        test_passed = run_taylor_test(case, epsilons, slope_tolerance)\n        results.append(test_passed)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef assemble_system(p, L, N, q0, T0, T1):\n    \"\"\"\n    Assembles the finite-volume system matrix A and RHS vector b.\n    \"\"\"\n    n = N - 2  # Number of interior nodes\n    dx = L / (N - 1)\n    \n    A = np.zeros((n, n))\n    \n    # Python uses 0-based indexing for u_int[0...n-1]\n    # Parameter p has M=N-1 components, p[0...N-2]\n    \n    # Diagonal entries\n    for i in range(n):\n      A[i, i] = p[i] + p[i+1]\n      \n    # Off-diagonal entries\n    for i in range(n-1):\n      A[i, i+1] = -p[i+1]\n      A[i+1, i] = -p[i+1]\n\n    # The system is A_scaled u = b_scaled where A_scaled = A/dx^2.\n    A_scaled = A / (dx**2)\n    \n    b_scaled = np.full(n, q0)\n    # Incorporate boundary conditions into RHS vector b\n    b_scaled[0] += p[0] * T0 / (dx**2)\n    b_scaled[n-1] += p[N-2] * T1 / (dx**2)\n\n    return A_scaled, b_scaled\n\ndef compute_J(u, omega, u_ref):\n    \"\"\"\n    Computes the objective functional J.\n    \"\"\"\n    return 0.5 * np.sum(omega * (u - u_ref)**2)\n\ndef compute_gradient(u, lamb, p, L, N, T0, T1):\n    \"\"\"\n    Computes the gradient of J w.r.t. p using the adjoint method.\n    \"\"\"\n    n = N - 2\n    M = N - 1\n    dx = L / (N - 1)\n    grad = np.zeros(M)\n    \n    # Python arrays u, lamb are 0-indexed (0 to n-1)\n    # p is 0-indexed (0 to M-1)\n    \n    # j = 0 (corresponds to p[0])\n    grad[0] = lamb[0] * (u[0] - T0) / dx**2\n    \n    # j = 1 to n-1 (corresponds to p[1] to p[n-1])\n    # Note: n=N-2, M=N-1, so loop goes to M-2\n    for j in range(1, n):\n        grad[j] = (lamb[j-1] - lamb[j]) * (u[j-1] - u[j]) / dx**2\n        \n    # j = n = N-2 (corresponds to p[n] = p[N-2])\n    grad[n] = lamb[n-1] * (u[n-1] - T1) / dx**2\n        \n    return grad\n\ndef run_taylor_test(params, epsilons, tolerance):\n    \"\"\"\n    Performs a single Taylor test for a given configuration.\n    \"\"\"\n    L, N, q0, T0, T1 = params[\"L\"], params[\"N\"], params[\"q0\"], params[\"T0\"], params[\"T1\"]\n    n = N - 2\n    M = N - 1\n    \n    rng = np.random.default_rng(params[\"seed\"])\n    \n    # Setup omega (weights)\n    if params[\"omega_mode\"] == \"const\":\n        omega = np.ones(n)\n    else: # \"random\"\n        omega = rng.uniform(0.5, 1.5, size=n)\n        \n    # Setup u_ref (reference temperature)\n    if params[\"u_ref_mode\"] == \"const\":\n        u_ref_val = 305.0 if L == 1.0 else 350.0\n        u_ref = np.full(n, u_ref_val)\n    else: # \"random\"\n        u_ref = rng.uniform(300.0, 305.0, size=n)\n\n    # Setup p (base parameters)\n    j = np.arange(M)\n    if params[\"p_mode\"] == \"sin\":\n        p = 10.0 * (1.0 + 0.2 * np.sin(np.pi * (j + 0.5) / M))\n    elif params[\"p_mode\"] == \"cos\":\n        p = 15.0 * (1.0 + 0.1 * np.cos(2.0 * np.pi * (j + 0.5) / M))\n    else: # \"const\"\n        p = np.full(M, 20.0)\n        \n    # Setup h (perturbation direction)\n    if params[\"h_mode\"] == \"random\":\n        h = rng.standard_normal(M)\n    else: # \"boundary\"\n        h = np.zeros(M)\n        h[0] = 1.0\n        h[M - 1] = -1.0\n    h /= np.linalg.norm(h)\n    \n    # 1. Forward solve\n    A_base, b_base = assemble_system(p, L, N, q0, T0, T1)\n    u_base = scipy.linalg.solve(A_base, b_base, assume_a='sym')\n    J_base = compute_J(u_base, omega, u_ref)\n    \n    # 2. Adjoint solve\n    adj_rhs = -omega * (u_base - u_ref)\n    lamb = scipy.linalg.solve(A_base, adj_rhs, assume_a='sym')\n\n    # 3. Gradient computation\n    grad_J = compute_gradient(u_base, lamb, p, L, N, T0, T1)\n    \n    # Directional derivative\n    grad_h = np.dot(grad_J, h)\n    \n    E1_vals = []\n    E2_vals = []\n    \n    for eps in epsilons:\n        p_eps = p + eps * h\n        \n        # Solve perturbed forward problem and compute J\n        A_eps, b_eps = assemble_system(p_eps, L, N, q0, T0, T1)\n        u_eps = scipy.linalg.solve(A_eps, b_eps, assume_a='sym')\n        J_eps = compute_J(u_eps, omega, u_ref)\n        \n        # Calculate errors\n        E1 = abs(J_eps - J_base)\n        E2 = abs(J_eps - J_base - eps * grad_h)\n        \n        E1_vals.append(E1)\n        E2_vals.append(E2)\n\n    # 4. Convergence order estimation\n    log_eps = np.log(epsilons)\n    log_E1 = np.log(np.array(E1_vals))\n    log_E2 = np.log(np.array(E2_vals))\n    \n    # Use np.polyfit for linear regression (slope is the first element)\n    s1 = np.polyfit(log_eps, log_E1, 1)[0]\n    s2 = np.polyfit(log_eps, log_E2, 1)[0]\n    \n    # 5. Verdict\n    test_passed = abs(s1 - 1.0) = tolerance and abs(s2 - 2.0) = tolerance\n    return test_passed\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}