{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的推导之前，理解伴随方法为何如此强大至关重要。本练习通过对一个典型的非线性热传导问题，量化比较了有限差分、直接法和伴随法在计算梯度时的计算成本。通过这个思想实验 ，您将清晰地看到伴随法在处理大量设计参数时的卓越可扩展性，从而确立其在设计优化中的核心地位。",
            "id": "3935153",
            "problem": "一个有界域中的稳态非线性热传导问题被离散化，得到代数残差方程 $\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$，其中 $\\mathbf{u} \\in \\mathbb{R}^{N_u}$ 是节点温度向量，$\\mathbf{p} \\in \\mathbb{R}^{N_p}$ 是设计参数向量，该向量对空间变化的导热系数场进行线性参数化。目标量是单个标量泛函 $J(\\mathbf{u})$，例如通过部分边界的总法向热通量。假设存在以下计算模型：\n- 已获得名义参数 $\\mathbf{p}_0$ 及其收敛状态 $\\mathbf{u}_0$，并且相应的雅可比矩阵（状态切线）$\\mathbf{J}_0 \\equiv \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$ 已组装且可重用。\n- 使用牛顿法对不同的参数向量 $\\mathbf{p}$ 重新求解非线性状态需要 $S$ 次迭代，每次牛顿迭代需要一次大型稀疏线性求解，其系数矩阵为 $\\mathbf{J}(\\mathbf{u},\\mathbf{p})$。\n- 相对于大型稀疏线性求解，构建右端项、函数求值和向量运算的成本可忽略不计。\n- 目标是在 $\\mathbf{p}_0$ 处计算完整梯度 $\\nabla_{\\mathbf{p}} J(\\mathbf{u}(\\mathbf{p}))$。\n\n考虑三种方法：\n1. 对每个分量 $p_i$ 应用中心有限差分，每个参数使用两次扰动状态重解。\n2. 通过围绕 $(\\mathbf{u}_0,\\mathbf{p}_0)$ 对残差进行线性化来获得直接灵敏度，并为每个参数求解一个线性灵敏度系统。\n3. 通过求解与标量目标 $J(\\mathbf{u})$ 相关联的单个伴随系统来获得伴随方法。",
            "solution": "首先验证问题，确保其具有科学依据、适定、客观且完整。\n\n### 第1步：提取已知条件\n- 离散化非线性残差方程：$\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$。\n- 节点温度的状态向量：$\\mathbf{u} \\in \\mathbb{R}^{N_u}$。\n- 设计参数向量：$\\mathbf{p} \\in \\mathbb{R}^{N_p}$。\n- 标量目标量：$J(\\mathbf{u})$。\n- 名义点：$(\\mathbf{u}_0, \\mathbf{p}_0)$，其中 $\\mathbf{R}(\\mathbf{u}_0, \\mathbf{p}_0) = \\mathbf{0}$。\n- 名义点处的状态切线（雅可比矩阵）：$\\mathbf{J}_0 \\equiv \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$，已组装且可重用。\n- 非线性状态重解的成本：$S$ 次迭代，每次迭代需要一次大型稀疏线性求解。这些求解的系数矩阵是依赖于状态的雅可比矩阵 $\\mathbf{J}(\\mathbf{u},\\mathbf{p})$。\n- 成本模型简化：与大型稀疏线性求解的成本相比，构建右端项、函数求值和向量运算的成本可以忽略不计。\n- 目标：在 $\\mathbf{p}_0$ 处计算完整梯度 $\\nabla_{\\mathbf{p}} J(\\mathbf{u}(\\mathbf{p}))$。\n- 方法1（有限差分）：“每个参数两次扰动状态重解”。\n- 方法2（直接灵敏度）：“为每个参数求解一个线性灵敏度系统”。\n- 方法3（伴随方法）：“求解一个单一的伴随系统”。\n\n### 第2步：使用提取的已知条件进行验证\n该问题是计算科学与工程领域的一个标准的、定义明确的练习，特别是在由偏微分方程控制的系统的灵敏度分析领域。\n- **有科学依据：** 问题陈述基于数值分析（牛顿法）、有限元法（离散化残差）和灵敏度分析（直接法和伴随法）的既定原则。它是设计优化和不确定性量化中的一个典型问题。\n- **适定性：** 问题提供了明确的目标和一套完整的假设与定义，用以计算三种不同标准算法的计算成本。基于这些假设存在唯一答案。\n- **客观性：** 语言形式化、精确，没有任何主观性或歧义。\n- **缺陷：** 问题没有表现出任何缺陷。这是一个教科书式的例子，它完整、一致、与指定主题相关，并且在科学上是可靠的。\n\n### 第3步：结论与行动\n问题有效。详细解答如下。\n\n目标是确定对于三种提出的方法中的每一种，计算具有 $N_p$ 个分量的完整梯度 $\\nabla_{\\mathbf{p}} J$ 所需的大型稀疏线性求解的总次数。成本单位为一次大型稀疏线性求解。\n\n### 方法1：中心有限差分 (FD)\n$J$ 关于第 $i$ 个参数 $p_i$ 的梯度可以用中心有限差分公式近似：\n$$ \\frac{dJ}{dp_i} \\approx \\frac{J(\\mathbf{u}(\\mathbf{p}_0 + \\epsilon \\mathbf{e}_i)) - J(\\mathbf{u}(\\mathbf{p}_0 - \\epsilon \\mathbf{e}_i))}{2\\epsilon} $$\n其中 $\\mathbf{e}_i$ 是第 $i$ 个标准基向量，$\\epsilon$ 是一个小扰动。\n为了计算这个表达式，我们需要在两个扰动参数点计算状态向量：$\\mathbf{p}_+ = \\mathbf{p}_0 + \\epsilon \\mathbf{e}_i$ 对应的 $\\mathbf{u}(\\mathbf{p}_+)$ 和 $\\mathbf{p}_- = \\mathbf{p}_0 - \\epsilon \\mathbf{e}_i$ 对应的 $\\mathbf{u}(\\mathbf{p}_-)$。这涉及两次求解非线性系统 $\\mathbf{R}(\\mathbf{u}, \\mathbf{p}) = \\mathbf{0}$。问题陈述这需要“每个参数两次扰动状态重解”。\n\n根据成本模型，使用牛顿法进行一次非线性重解的成本是 $S$ 次大型稀疏线性求解。因此，计算梯度的一个分量 $\\frac{dJ}{dp_i}$ 的成本是 $2 \\times S = 2S$ 次线性求解。\n\n要计算完整梯度 $\\nabla_{\\mathbf{p}} J$，必须对 $N_p$ 个参数中的每一个重复此过程。总成本为：\n$$ N_{\\mathrm{FD}} = N_p \\times (2S) = 2SN_p $$\n\n### 方法2：直接灵敏度\n泛函 $J$ 相对于参数 $p_i$ 的全导数由链式法则给出：\n$$ \\frac{dJ}{dp_i} = \\frac{\\partial J}{\\partial \\mathbf{u}} \\frac{d\\mathbf{u}}{dp_i} $$\n其中导数在名义点 $(\\mathbf{u}_0, \\mathbf{p}_0)$ 处计算。向量 $\\frac{d\\mathbf{u}}{dp_i}$ 是状态相对于参数 $p_i$ 的灵敏度。\n为了找到这个灵敏度向量，我们将控制残差方程 $\\mathbf{R}(\\mathbf{u}(\\mathbf{p}), \\mathbf{p}) = \\mathbf{0}$ 对 $p_i$ 求导，并在名义点处计算：\n$$ \\frac{d\\mathbf{R}}{dp_i} \\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} = \\frac{\\partial \\mathbf{R}}{\\partial \\mathbf{u}}\\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} \\frac{d\\mathbf{u}}{dp_i}\\bigg|_{\\mathbf{p}_0} + \\frac{\\partial \\mathbf{R}}{\\partial p_i}\\bigg|_{(\\mathbf{u}_0,\\mathbf{p}_0)} = \\mathbf{0} $$\n使用记号 $\\mathbf{J}_0 = \\partial \\mathbf{R}/\\partial \\mathbf{u} \\big|_{(\\mathbf{u}_0,\\mathbf{p}_0)}$，我们可以将其重排为关于灵敏度向量 $\\frac{d\\mathbf{u}}{dp_i}$ 的线性系统：\n$$ \\mathbf{J}_0 \\frac{d\\mathbf{u}}{dp_i} = - \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n问题指出，该方法涉及“为每个参数求解一个线性灵敏度系统”。这对应于求解上述方程。对于每个参数 $p_i$，这需要一次大型稀疏线性求解。由于有 $N_p$ 个参数，我们必须求解 $N_p$ 个这样的线性系统，每个系统对应一个灵敏度向量 $\\frac{d\\mathbf{u}}{dp_i}$，其中 $i=1, \\dots, N_p$。所有系统的系数矩阵 $\\mathbf{J}_0$ 都是相同的。\n\n计算完整梯度的总成本是需要求解的系统数量：\n$$ N_{\\mathrm{dir}} = N_p \\times 1 = N_p $$\n\n### 方法3：伴随方法\n当参数数量 $N_p$ 很大时，伴随方法被设计用来高效计算标量泛函的梯度。我们从与直接方法中相同的梯度分量表达式开始：\n$$ \\frac{dJ}{dp_i} = \\frac{\\partial J}{\\partial \\mathbf{u}} \\frac{d\\mathbf{u}}{dp_i} $$\n从直接方法中，我们知道 $\\frac{d\\mathbf{u}}{dp_i} = - \\mathbf{J}_0^{-1} \\frac{\\partial \\mathbf{R}}{\\partial p_i}$。代入可得：\n$$ \\frac{dJ}{dp_i} = \\left( -\\frac{\\partial J}{\\partial \\mathbf{u}} \\mathbf{J}_0^{-1} \\right) \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n伴随方法引入一个单一的伴随向量 $\\boldsymbol{\\lambda} \\in \\mathbb{R}^{N_u}$，它被定义为以下称为伴随系统的线性系统的解：\n$$ \\mathbf{J}_0^T \\boldsymbol{\\lambda} = - \\left( \\frac{\\partial J}{\\partial \\mathbf{u}} \\right)^T $$\n求解伴随向量 $\\boldsymbol{\\lambda}$ 需要一次大型稀疏线性求解，正如问题中所述：“求解一个单一的伴随系统”。\n通过对伴随方程进行转置，我们得到 $\\boldsymbol{\\lambda}^T \\mathbf{J}_0 = - \\frac{\\partial J}{\\partial \\mathbf{u}}$。右乘 $\\mathbf{J}_0^{-1}$ 得到 $\\boldsymbol{\\lambda}^T = - \\frac{\\partial J}{\\partial \\mathbf{u}} \\mathbf{J}_0^{-1}$。这正是梯度表达式中括号内的项。\n\n将 $\\boldsymbol{\\lambda}^T$ 代入 $\\frac{dJ}{dp_i}$ 的表达式可得：\n$$ \\frac{dJ}{dp_i} = \\boldsymbol{\\lambda}^T \\frac{\\partial \\mathbf{R}}{\\partial p_i} $$\n一旦计算出单一的伴随向量 $\\boldsymbol{\\lambda}$，就可以通过计算 $\\boldsymbol{\\lambda}$ 与每个 $p_i$ 对应的向量 $\\frac{\\partial \\mathbf{R}}{\\partial p_i}$ 的内积来找到梯度的所有 $N_p$ 个分量。根据成本模型，向量运算（如内积）和构建向量（如 $\\frac{\\partial \\mathbf{R}}{\\partial p_i}$）的成本可以忽略不计。\n因此，伴随方法的总成本完全由求解 $\\boldsymbol{\\lambda}$ 的成本决定。\n\n总成本为：\n$$ N_{\\mathrm{adj}} = 1 $$\n\n### 总结\n三种方法计算完整梯度所需的大型稀疏线性求解总次数为：\n- 有限差分：$N_{\\mathrm{FD}} = 2SN_p$\n- 直接灵敏度：$N_{\\mathrm{dir}} = N_p$\n- 伴随方法：$N_{\\mathrm{adj}} = 1$\n\n最终结果，以所要求的行矩阵形式表示为 $\\begin{pmatrix} 2SN_p & N_p & 1 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 S N_p & N_p & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "理解了伴随法的计算优势后，我们现在转向其理论核心。本练习将引导您从第一性原理出发，针对一个简单的一维热传导问题，通过拉格朗日方法完整推导连续伴随方程。通过解析求解这个伴随问题 ，您将深刻理解伴随方程的结构，及其与正问题和目标函数之间的内在联系。",
            "id": "3935200",
            "problem": "考虑一根均匀、各向同性的一维杆中的稳态热传导，其占据的空间域为 $\\Omega = (0,L)$，具有恒定的热导率 $k>0$ 和均匀的体积生热率 $s_0>0$。令 $u(x)$ 表示温度场。从能量守恒和傅里叶热传导定律出发，建立 $u(x)$ 的控制偏微分方程（PDE）和边界条件，即齐次狄利克雷边界条件 $u(0)=0$ 和 $u(L)=0$。将目标泛函定义为 $u$ 的非线性泛函，\n$$\nJ(u) \\;=\\; \\int_{0}^{L} \\phi(u(x))\\,dx, \\qquad \\text{with} \\quad \\phi(u) \\;=\\; \\tfrac{1}{2}u^2.\n$$\n将热导率 $k$ 视为唯一关心的标量参数。使用基于伴随的灵敏度方法：\n\n1) 通过构建一个强制执行 PDE 约束的拉格朗日量，并要求其关于 $u$ 的变分是驻定的，来推导伴随边值问题。识别出伴随强迫项 $\\partial \\phi/\\partial u$ 以及在施加于 $u$ 的狄利克雷约束下与消除边界变分相一致的伴随边界条件。\n\n2) 显式求解正问题得到 $u(x)$。\n\n3) 显式求解线性化伴随问题得到伴随场 $\\lambda(x)$。\n\n4) 利用你的正问题解和伴随问题解，推导目标泛函关于热导率的梯度 $dJ/dk$，并将其简化为关于 $s_0$、$L$ 和 $k$ 的单个闭式解析表达式。\n\n将你关于 $dJ/dk$ 的最终答案表示为关于 $s_0$、$L$ 和 $k$ 的单个闭式表达式。最终表达式中不要包含单位。",
            "solution": "分析从第一性原理出发，按要求建立温度场 $u(x)$ 的控制方程。\n\n对于稳态一维热传递，应用于无穷小控制体 $dx$ 的能量守恒原理指出，传出该体积的净热传导速率必须等于其内部的生热速率。这给出了 $\\frac{dq}{dx} = s_0$，其中 $q(x)$ 是热通量，$s_0$ 是均匀的体积生热率。\n傅里叶热传导定律将热通量与温度梯度联系起来：$q = -k \\frac{du}{dx}$，其中 $k$ 是热导率。\n将傅里叶定律代入能量守恒方程得到：\n$$\n\\frac{d}{dx}\\left(-k \\frac{du}{dx}\\right) = s_0\n$$\n由于热导率 $k$ 是常数，这简化为正问题的控制常微分方程（ODE）：\n$$\n-k \\frac{d^2u}{dx^2} = s_0\n$$\n该问题定义在域 $x \\in (0, L)$上，具有齐次狄利克雷边界条件 $u(0)=0$ 和 $u(L)=0$。我们定义状态残差 $R(u, k) = k \\frac{d^2u}{dx^2} + s_0 = 0$。\n\n任务是求目标泛函 $J(u) = \\int_{0}^{L} \\frac{1}{2}u^2(x)\\,dx$ 关于参数 $k$ 的梯度。我们使用伴随方法进行求解。\n\n1) 伴随边值问题的推导\n\n我们通过使用拉格朗日乘子场 $\\lambda(x)$（也称为伴随场）来强制执行控制PDE，从而增广目标泛函 $J$，构建一个拉格朗日泛函 $\\mathcal{L}$：\n$$\n\\mathcal{L}(u, k, \\lambda) = J(u) + \\int_{0}^{L} \\lambda(x) R(u, k)\\,dx = \\int_{0}^{L} \\frac{1}{2}u^2\\,dx + \\int_{0}^{L} \\lambda(x) \\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx\n$$\n伴随问题是通过要求拉格朗日量对于状态场 $u$ 的任意、容许变分是驻定的来推导的。一个容许变分 $\\delta u$ 必须满足 $u$ 的齐次狄利克雷边界条件，即 $\\delta u(0)=0$ 和 $\\delta u(L)=0$。驻定条件为 $\\delta_u \\mathcal{L} = 0$：\n$$\n\\delta_u \\mathcal{L} = \\frac{\\delta \\mathcal{L}}{\\delta u}[\\delta u] = \\int_{0}^{L} u\\,\\delta u\\,dx + \\int_{0}^{L} \\lambda \\left(k \\frac{d^2(\\delta u)}{dx^2}\\right) dx = 0\n$$\n我们对第二项进行两次分部积分：\n$$\n\\int_{0}^{L} k\\lambda \\frac{d^2(\\delta u)}{dx^2}\\,dx = \\left[k\\lambda \\frac{d(\\delta u)}{dx}\\right]_0^L - \\int_{0}^{L} k\\frac{d\\lambda}{dx}\\frac{d(\\delta u)}{dx}\\,dx\n$$\n$$\n= \\left[k\\lambda \\frac{d(\\delta u)}{dx}\\right]_0^L - \\left[k\\frac{d\\lambda}{dx}\\delta u\\right]_0^L + \\int_{0}^{L} k\\frac{d^2\\lambda}{dx^2}\\delta u\\,dx\n$$\n将此代回驻定条件，得到：\n$$\n\\int_{0}^{L} \\left(u + k\\frac{d^2\\lambda}{dx^2}\\right)\\delta u\\,dx + \\left[k\\lambda \\frac{d(\\delta u)}{dx} - k\\frac{d\\lambda}{dx}\\delta u\\right]_0^L = 0\n$$\n由于 $\\delta u(0)=0$ 和 $\\delta u(L)=0$，项 $k\\frac{d\\lambda}{dx}\\delta u$ 在边界处为零。为了对任意变分 $\\delta u$ 消除剩余的边界项 $k\\lambda \\frac{d(\\delta u)}{dx}$，我们必须对伴随场 $\\lambda$ 施加边界条件。确保边界项为零的最简单选择是对 $\\lambda$ 施加齐次狄利克雷边界条件：$\\lambda(0)=0$ 和 $\\lambda(L)=0$。这些是与正问题约束相一致的伴随边界条件。\n\n在消除了边界项之后，驻定条件简化为：\n$$\n\\int_{0}^{L} \\left(u + k\\frac{d^2\\lambda}{dx^2}\\right)\\delta u\\,dx = 0\n$$\n为了使该积分对任何容许变分 $\\delta u$ 都为零，被积函数必须恒等于零。这就得到了伴随控制PDE：\n$$\nk\\frac{d^2\\lambda}{dx^2} + u(x) = 0 \\quad \\text{或} \\quad k\\frac{d^2\\lambda}{dx^2} = -u(x)\n$$\n问题要求识别伴随强迫项 $\\partial \\phi/\\partial u$。在我们的问题中，$\\phi(u) = \\frac{1}{2}u^2$，所以它关于 $u$ 的导数是 $\\frac{\\partial \\phi}{\\partial u} = u(x)$。伴随方程可以写成 $k\\frac{d^2\\lambda}{dx^2} = -\\frac{\\partial \\phi}{\\partial u}$。因此，项 $\\frac{\\partial \\phi}{\\partial u}=u(x)$ 作为伴随问题的源项。\n\n完整的伴随边值问题是：\n-   PDE: $k\\frac{d^2\\lambda}{dx^2} = -u(x)$ 对于 $x \\in (0,L)$。\n-   边界条件: $\\lambda(0)=0$, $\\lambda(L)=0$。\n\n2) 正问题的求解\n\n我们求解正问题：$k \\frac{d^2u}{dx^2} = -s_0$，其中 $u(0)=0$ 和 $u(L)=0$。\n对 $x$ 积分一次：\n$$\nk \\frac{du}{dx} = -s_0 x + C_1\n$$\n积分第二次：\n$$\nk u(x) = -\\frac{s_0}{2}x^2 + C_1 x + C_2\n$$\n应用边界条件求常数 $C_1$ 和 $C_2$：\n-   在 $x=0$ 处: $k u(0) = 0 \\implies 0 = 0 + 0 + C_2 \\implies C_2=0$。\n-   在 $x=L$ 处: $k u(L) = 0 \\implies 0 = -\\frac{s_0}{2}L^2 + C_1 L \\implies C_1 = \\frac{s_0 L}{2}$。\n代入常数，温度场为：\n$$\nk u(x) = -\\frac{s_0}{2}x^2 + \\frac{s_0 L}{2}x \\implies u(x) = \\frac{s_0}{2k}(Lx - x^2)\n$$\n\n3) 伴随问题的求解\n\n我们求解伴随问题：$k\\frac{d^2\\lambda}{dx^2} = -u(x)$，其中 $\\lambda(0)=0$ 和 $\\lambda(L)=0$。\n代入 $u(x)$ 的表达式：\n$$\nk\\frac{d^2\\lambda}{dx^2} = -\\frac{s_0}{2k}(Lx - x^2) \\implies \\frac{d^2\\lambda}{dx^2} = -\\frac{s_0}{2k^2}(Lx - x^2)\n$$\n对 $x$ 积分一次：\n$$\n\\frac{d\\lambda}{dx} = -\\frac{s_0}{2k^2}\\left(\\frac{L}{2}x^2 - \\frac{1}{3}x^3\\right) + D_1\n$$\n积分第二次：\n$$\n\\lambda(x) = -\\frac{s_0}{2k^2}\\left(\\frac{L}{6}x^3 - \\frac{1}{12}x^4\\right) + D_1 x + D_2\n$$\n应用边界条件求 $D_1$ 和 $D_2$：\n-   在 $x=0$ 处: $\\lambda(0)=0 \\implies 0 = 0 + 0 + D_2 \\implies D_2=0$。\n-   在 $x=L$ 处: $\\lambda(L)=0 \\implies 0 = -\\frac{s_0}{2k^2}\\left(\\frac{L^4}{6} - \\frac{L^4}{12}\\right) + D_1 L$。\n$$\n0 = -\\frac{s_0}{2k^2}\\left(\\frac{L^4}{12}\\right) + D_1 L \\implies D_1 L = \\frac{s_0 L^4}{24k^2} \\implies D_1 = \\frac{s_0 L^3}{24k^2}\n$$\n代入常数，伴随场为：\n$$\n\\lambda(x) = -\\frac{s_0}{2k^2}\\left(\\frac{Lx^3}{6} - \\frac{x^4}{12}\\right) + \\frac{s_0 L^3}{24k^2}x = \\frac{s_0}{24k^2}(x^4 - 2Lx^3 + L^3x)\n$$\n\n4) 梯度 $dJ/dk$ 的推导\n\n伴随方法的核心优势在于，目标泛函关于某个参数的全导数可以计算为拉格朗日量的偏导数，同时保持状态变量和伴随变量固定。这是因为涉及状态变量灵敏度的另一项 $\\frac{\\partial \\mathcal{L}}{\\partial u}\\frac{du}{dk}$，根据伴随方程的定义（$\\frac{\\partial \\mathcal{L}}{\\partial u}=0$）而为零。\n$$\n\\frac{dJ}{dk} = \\frac{d\\mathcal{L}}{dk} = \\frac{\\partial \\mathcal{L}}{\\partial k} = \\frac{\\partial}{\\partial k} \\int_{0}^{L} \\lambda(x) \\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx\n$$\n在积分号下对 $k$ 求导：\n$$\n\\frac{dJ}{dk} = \\int_{0}^{L} \\lambda(x) \\frac{\\partial}{\\partial k}\\left(k \\frac{d^2u}{dx^2} + s_0\\right) dx = \\int_{0}^{L} \\lambda(x) \\frac{d^2u}{dx^2} dx\n$$\n从正问题中，我们知道 $\\frac{d^2u}{dx^2} = -\\frac{s_0}{k}$。将此代入梯度的表达式中：\n$$\n\\frac{dJ}{dk} = \\int_{0}^{L} \\lambda(x) \\left(-\\frac{s_0}{k}\\right) dx = -\\frac{s_0}{k} \\int_{0}^{L} \\lambda(x) dx\n$$\n现在我们计算伴随解 $\\lambda(x)$ 的积分：\n$$\n\\int_{0}^{L} \\lambda(x) dx = \\int_{0}^{L} \\frac{s_0}{24k^2}(x^4 - 2Lx^3 + L^3x) dx\n$$\n$$\n= \\frac{s_0}{24k^2} \\left[ \\frac{x^5}{5} - \\frac{2L x^4}{4} + \\frac{L^3 x^2}{2} \\right]_0^L = \\frac{s_0}{24k^2} \\left( \\frac{L^5}{5} - \\frac{L^5}{2} + \\frac{L^5}{2} \\right) = \\frac{s_0}{24k^2} \\frac{L^5}{5} = \\frac{s_0 L^5}{120 k^2}\n$$\n最后，我们将此结果代回梯度的表达式中：\n$$\n\\frac{dJ}{dk} = -\\frac{s_0}{k} \\left( \\frac{s_0 L^5}{120 k^2} \\right) = -\\frac{s_0^2 L^5}{120 k^3}\n$$\n这就是目标泛函 $J$ 关于热导率 $k$ 的灵敏度的最终闭式解析表达式。",
            "answer": "$$\n\\boxed{-\\frac{s_0^2 L^5}{120 k^3}}\n$$"
        },
        {
            "introduction": "本章的最终实践旨在连接连续理论与计算实践。本练习将指导您为有限体积法建立的离散模型实施离散伴随方法，并计算目标函数相对于模型参数的梯度。此实践的核心是泰勒测试 ，这是一种验证所算梯度正确性的基本技术，也是计算科学与工程领域不可或缺的一项技能。",
            "id": "3935211",
            "problem": "考虑一根长度为 $L$ 的杆上的一维稳态热传导问题。其空间变化的导热系数在单元面上由一个向量 $p \\in \\mathbb{R}^{M}$ 参数化，其中对于一个具有 $N$ 个节点且间距为 $\\Delta x = L/(N-1)$ 的均匀网格，有 $M = N - 1$。控制偏微分方程 (PDE) 为 $- \\dfrac{d}{dx}\\left(k(x;p)\\,\\dfrac{du}{dx}\\right) = q(x)$，边界条件为狄利克雷边界条件 $u(0) = T_0$ 和 $u(L) = T_1$，其中 $u(x)$ 是温度（单位：$\\mathrm{K}$），$k(x;p)$ 是热导率（单位：$\\mathrm{W}\\cdot\\mathrm{m}^{-1}\\cdot\\mathrm{K}^{-1}$），$q(x)$ 是体积热源（单位：$\\mathrm{W}\\cdot\\mathrm{m}^{-3}$）。\n\n在均匀网格上使用有限体积法进行离散化，用 $p$ 的分量表示面上的 $k$，从而得到一个关于内部未知温度 $u \\in \\mathbb{R}^{n}$（其中 $n = N - 2$）的线性代数系统：\n$$\nA(p)\\,u = b(p),\n$$\n其中 $A(p) \\in \\mathbb{R}^{n \\times n}$ 和 $b(p) \\in \\mathbb{R}^{n}$ 是根据面上的热导率和狄利克雷边界值构建的。定义一个二次目标泛函\n$$\nJ(u) = \\frac{1}{2}\\sum_{i=1}^{n}\\omega_i\\left(u_i - u^{\\mathrm{ref}}_i\\right)^2,\n$$\n其中 $\\omega_i > 0$ 是权重，$u^{\\mathrm{ref}} \\in \\mathbb{R}^{n}$ 是一个参考的内部温度分布。\n\n任务：从傅里叶热传导定律和能量守恒定律出发，推导离散伴随方程以及目标泛函 $J$ 关于参数向量 $p$ 的梯度的伴随方法表达式。然后实现一个程序，该程序能够：\n- 求解正问题 $A(p)\\,u=b(p)$ 以得到 $u$。\n- 求解伴随系统以获得伴随变量 $\\lambda \\in \\mathbb{R}^{n}$。\n- 使用伴随方法计算梯度 $\\nabla_p J(p)$。\n- 通过比较基于伴随方法计算的方向导数与有限差分方法计算的方向导数，执行泰勒检验以验证梯度精度。对于给定的方向 $h \\in \\mathbb{R}^{M}$ 和一系列步长 $\\{\\varepsilon_k\\}$，计算：\n  - 一阶误差 $E_1(\\varepsilon_k) = \\left|J(p + \\varepsilon_k h) - J(p)\\right|$。\n  - 二阶校正误差 $E_2(\\varepsilon_k) = \\left|J(p + \\varepsilon_k h) - J(p) - \\varepsilon_k\\,\\nabla_p J(p)^\\top h\\right|$。\n通过拟合 $\\log E_1$ 与 $\\log \\varepsilon$ 以及 $\\log E_2$ 与 $\\log \\varepsilon$ 的关系，分别提取斜率 $s_1$ 和 $s_2$，来估计收敛阶。如果在规定的容差范围内，$s_1$ 约等于 $1$ 且 $s_2$ 约等于 $2$，则认为泰勒检验通过。\n\n输入必须遵守物理单位：$L$ 的单位为 $\\mathrm{m}$，$p$ 的热导率分量的单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-1}\\cdot\\mathrm{K}^{-1}$，$q$ 的单位为 $\\mathrm{W}\\cdot\\mathrm{m}^{-3}$，温度 $T_0$、$T_1$、$u$ 和 $u^{\\mathrm{ref}}$ 的单位为 $\\mathrm{K}$。程序的输出是无量纲的布尔值，表示每个测试用例的泰勒检验是否通过。\n\n测试套件：\n- 情况1（一般可变性）：$L = 1$，$N = 21$，$q(x) \\equiv q_0 = 1000$，$T_0 = 300$，$T_1 = 310$，$\\omega_i \\equiv 1$，对所有 $i$，$u^{\\mathrm{ref}}_i = 305$，基础 $p_j = 10\\left(1 + 0.2\\sin\\left(\\pi\\frac{j+0.5}{N-1}\\right)\\right)$（$j=0,\\dots,N-2$），方向 $h$ 为一个确定性的随机单位向量。\n- 情况2（受边界影响的小系统）：$L = 0.1$，$N = 5$，$q(x) \\equiv 0$，$T_0 = 400$，$T_1 = 300$，$\\omega_i \\equiv 1$，对所有 $i$，$u^{\\mathrm{ref}}_i = 350$，所有面上的基础 $p_j = 20$，方向 $h$ 仅在边界的面 $j=0$ 和 $j=N-2$ 上有支撑，其分量分别为 $1$ 和 $-1$，并归一化为单位范数。\n- 情况3（具有随机权重和参考值的较大系统）：$L = 2$，$N = 31$，$q(x) \\equiv q_0 = 500$，$T_0 = 290$，$T_1 = 315$，$\\omega_i$ 为 $[0.5,1.5]$ 内的确定性随机正值，$u^{\\mathrm{ref}}$ 为 $[300,305]$ 内的确定性随机值，基础 $p_j = 15\\left(1 + 0.1\\cos\\left(2\\pi\\frac{j+0.5}{N-1}\\right)\\right)$，方向 $h$ 为一个确定性的随机单位向量。\n\n使用步长 $\\varepsilon_k \\in \\{10^{-1}, 5\\times10^{-2}, 2.5\\times10^{-2}, 1.25\\times10^{-2}, 6.25\\times10^{-3}\\}$。如果拟合的斜率满足 $|s_1 - 1| \\leq 0.15$ 和 $|s_2 - 2| \\leq 0.15$，则认为该情况的泰勒检验通过。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[result_1,result_2,result_3]$），其中每个 $result_i$ 是一个布尔值，表示相应测试用例的泰勒检验是否通过。",
            "solution": "问题陈述被认定为有效。它在科学上基于热传递原理，在数学上是适定的、客观的，并为获得唯一解和进行验证提供了完整且一致的信息集。因此，我们可以继续进行推导和实现。\n\n核心任务是推导目标泛函相对于热导率参数的梯度的伴随方法表达式，并使用泰勒检验验证其正确性。推导过程分为三个主要阶段：离散化控制偏微分方程、建立伴随问题以及推导梯度表达式。\n\n**1. 有限体积离散化（正问题）**\n\n一维稳态热传导的控制方程由能量守恒原理给出：\n$$\n- \\frac{d}{dx}\\left(k(x;p)\\,\\frac{du}{dx}\\right) = q(x)\n$$\n其中 $u(x)$ 是温度，$k(x;p)$ 是由向量 $p \\in \\mathbb{R}^{M}$ 参数化的热导率，$q(x)$ 是体积热源。区域是一根长度为 $L$ 的杆，具有狄利克雷边界条件 $u(0) = T_0$ 和 $u(L) = T_1$。\n\n我们使用一个包含 $N$ 个节点 $x_i = i \\Delta x$（$i=0, 1, \\dots, N-1$）的均匀网格对区域进行离散化，网格间距为 $\\Delta x = L/(N-1)$。温度未知的内部节点为 $i=1, \\dots, n$，其中 $n = N-2$。这些节点上的温度被组合成一个向量 $u \\in \\mathbb{R}^{n}$。热导率定义在节点之间的 $M=N-1$ 个面上，参数 $p_j$ 表示节点 $j$ 和节点 $j+1$ 之间面上的热导率（$j=0, \\dots, M-1$）。\n\n应用有限体积法，我们将控制方程在以每个内部节点 $i$ 为中心的控制体积（CV）上进行积分。节点 $i$ 的控制体积从面 $i-\\frac{1}{2}$ 延伸到面 $i+\\frac{1}{2}$。\n$$\n\\int_{x_{i-1/2}}^{x_{i+1/2}} - \\frac{d}{dx}\\left(k\\,\\frac{du}{dx}\\right) dx = \\int_{x_{i-1/2}}^{x_{i+1/2}} q(x) dx\n$$\n根据微积分基本定理，左侧的积分变为控制体积边界面上的热通量 $F = -k \\frac{du}{dx}$ 的差值：\n$$\n\\left(-k\\,\\frac{du}{dx}\\right)\\bigg|_{x_{i+1/2}} - \\left(-k\\,\\frac{du}{dx}\\right)\\bigg|_{x_{i-1/2}} = \\bar{q}_i \\Delta x\n$$\n其中 $\\bar{q}_i$ 是控制体积内的平均热源。使用中心差分格式和面热导率 $p_j$ 来近似通量，我们有：\n- 面 $i-\\frac{1}{2}$ 处的通量（节点 $i-1$ 和 $i$ 之间，热导率为 $p_{i-1}$）：$F_{i-1/2} \\approx -p_{i-1} \\frac{u_i - u_{i-1}}{\\Delta x}$。\n- 面 $i+\\frac{1}{2}$ 处的通量（节点 $i$ 和 $i+1$ 之间，热导率为 $p_i$）：$F_{i+1/2} \\approx -p_i \\frac{u_{i+1} - u_i}{\\Delta x}$。\n\n将这些代入内部节点 $i \\in \\{2, \\dots, n-1\\}$ 的平衡方程中，得到：\n$$\n-p_i \\frac{u_{i+1} - u_i}{\\Delta x} - \\left(-p_{i-1} \\frac{u_i - u_{i-1}}{\\Delta x}\\right) = q_i \\Delta x\n$$\n针对未知温度 $u_i$ 进行整理，得到第 $i$ 行的线性方程：\n$$\n\\frac{1}{\\Delta x^2} \\left[ -p_{i-1} u_{i-1} + (p_{i-1} + p_i) u_i - p_i u_{i+1} \\right] = q_i\n$$\n对于邻近边界的节点，我们引入已知的温度 $u_0=T_0$ 和 $u_n+1=u_{N-1}=T_1$：\n- 对于节点 $i=1$：$-p_1 \\frac{u_2 - u_1}{\\Delta x} + p_0 \\frac{u_1 - T_0}{\\Delta x} = q_1 \\Delta x \\implies \\frac{1}{\\Delta x^2} \\left[ (p_0+p_1)u_1 - p_1 u_2 \\right] = q_1 + \\frac{p_0 T_0}{\\Delta x^2}$。\n- 对于节点 $i=n=N-2$：$-p_{n} \\frac{T_1 - u_n}{\\Delta x} + p_{n-1} \\frac{u_n - u_{n-1}}{\\Delta x} = q_n \\Delta x \\implies \\frac{1}{\\Delta x^2} \\left[ -p_{n-1}u_{n-1} + (p_{n-1}+p_n)u_n \\right] = q_n + \\frac{p_n T_1}{\\Delta x^2}$。\n\n这组 $n$ 个线性方程构成了系统 $A(p)u = b(p)$，其中 $A(p) \\in \\mathbb{R}^{n \\times n}$ 是一个对称三对角矩阵，$b(p) \\in \\mathbb{R}^{n}$ 是源向量。\n\n**2. 伴随方程的构建**\n\n目标泛函 $J$ 通过状态变量 $u$ 隐式地依赖于参数 $p$：$J(p) = J(u(p))$。它关于参数 $p_j$ 的梯度通过链式法则求得：\n$$\n\\frac{dJ}{dp_j} = \\frac{\\partial J}{\\partial u}^T \\frac{\\partial u}{\\partial p_j}\n$$\n灵敏度项 $\\frac{\\partial u}{\\partial p_j}$ 是通过将状态方程 $R(u, p) = A(p)u - b(p) = 0$ 对 $p_j$ 求导来隐式定义的：\n$$\n\\frac{d R}{d p_j} = \\frac{\\partial R}{\\partial u}\\frac{\\partial u}{\\partial p_j} + \\frac{\\partial R}{\\partial p_j} = 0 \\implies A(p)\\frac{\\partial u}{\\partial p_j} = -\\frac{\\partial R}{\\partial p_j}\n$$\n求解 $\\frac{\\partial u}{\\partial p_j}$ 得到 $\\frac{\\partial u}{\\partial p_j} = -A(p)^{-1} \\frac{\\partial R}{\\partial p_j}$。将此代入梯度表达式：\n$$\n\\frac{dJ}{dp_j} = - \\left(\\frac{\\partial J}{\\partial u}\\right)^T A(p)^{-1} \\frac{\\partial R}{\\partial p_j} = - \\left( (A(p)^{-1})^T \\frac{\\partial J}{\\partial u} \\right)^T \\frac{\\partial R}{\\partial p_j}\n$$\n为了避免计算成本高昂的矩阵求逆 $A(p)^{-1}$，我们定义一个伴随变量 $\\lambda \\in \\mathbb{R}^n$，作为**伴随方程**的解：\n$$\nA(p)^T \\lambda = -\\frac{\\partial J}{\\partial u}\n$$\n由于矩阵 $A(p)$ 是对称的（$A(p)^T = A(p)$），伴随方程变为 $A(p)\\lambda = -\\nabla_u J$。目标泛函 $J(u) = \\frac{1}{2}\\sum_{i=1}^{n}\\omega_i(u_i - u^{\\mathrm{ref}}_i)^2$ 关于 $u$ 的梯度是一个向量，其分量为 $(\\nabla_u J)_i = \\omega_i(u_i - u^{\\mathrm{ref}}_i)$。\n\n根据 $\\lambda$ 的定义，梯度表达式简化为：\n$$\n\\frac{dJ}{dp_j} = \\lambda^T \\frac{\\partial R}{\\partial p_j}\n$$\n\n**3. 梯度表达式**\n\n最后一步是计算残差向量的偏导数 $\\frac{\\partial R}{\\partial p_j}$。对于内部节点 $i$，其残差为 $R_i(u, p) = \\sum_{k=1}^n A_{ik}(p)u_k - b_i(p)$。我们分析它对每个参数 $p_j$（$j \\in \\{0, \\dots, M-1\\}$）的依赖关系。\n\n残差向量由物理平衡方程定义：\n$R_1 = \\frac{1}{\\Delta x^2} \\left[ (p_0+p_1)u_1 - p_1 u_2 - p_0 T_0 \\right] - q_1$\n$R_i = \\frac{1}{\\Delta x^2} \\left[ -p_{i-1}u_{i-1} + (p_{i-1}+p_i)u_i - p_i u_{i+1} \\right] - q_i$, for $i \\in \\{2, \\dots, n-1\\}$\n$R_n = \\frac{1}{\\Delta x^2} \\left[ -p_{n-1}u_{n-1} + (p_{n-1}+p_n)u_n - p_n T_1 \\right] - q_n$\n\n我们计算残差向量分量 $R_i$ 关于参数 $p_j$ 的偏导数：\n\n- 对于 $j=0$（第一个面）：$p_0$ 仅出现在 $R_1$ 中。\n  $\\frac{\\partial R_1}{\\partial p_0} = \\frac{1}{\\Delta x^2}(u_1 - T_0)$。所有其他 $\\frac{\\partial R_i}{\\partial p_0}$ 均为 $0$。\n  因此，$\\frac{dJ}{dp_0} = \\lambda^T \\frac{\\partial R}{\\partial p_0} = \\lambda_1 \\frac{u_1 - T_0}{\\Delta x^2}$。\n\n- 对于 $j \\in \\{1, \\dots, n-1\\}$（内部面）：$p_j$ 出现在 $R_j$ 和 $R_{j+1}$ 中。\n  $\\frac{\\partial R_j}{\\partial p_j} = \\frac{1}{\\Delta x^2}(u_j - u_{j+1})$\n  $\\frac{\\partial R_{j+1}}{\\partial p_j} = \\frac{1}{\\Delta x^2}(-u_j + u_{j+1})$\n  因此，$\\frac{dJ}{dp_j} = \\lambda_j \\frac{\\partial R_j}{\\partial p_j} + \\lambda_{j+1} \\frac{\\partial R_{j+1}}{\\partial p_j} = \\frac{(\\lambda_j - \\lambda_{j+1})(u_j - u_{j+1})}{\\Delta x^2}$。\n\n- 对于 $j=n=N-2$（最后一个面）：$p_n$ 仅出现在 $R_n$ 中。\n  $\\frac{\\partial R_n}{\\partial p_n} = \\frac{1}{\\Delta x^2}(u_n - T_1)$。所有其他 $\\frac{\\partial R_i}{\\partial p_n}$ 均为 $0$。\n  因此，$\\frac{dJ}{dp_n} = \\lambda_n \\frac{u_n - T_1}{\\Delta x^2}$。\n\n总之，梯度 $\\nabla_p J$ 的分量为：\n$$\n\\frac{dJ}{dp_j} =\n\\begin{cases}\n \\lambda_1 \\frac{u_1 - T_0}{\\Delta x^2} & \\text{if } j=0 \\\\\n \\frac{(\\lambda_j - \\lambda_{j+1})(u_j - u_{j+1})}{\\Delta x^2} & \\text{if } 1 \\le j \\le n-1 \\\\\n \\lambda_n \\frac{u_n - T_1}{\\Delta x^2} & \\text{if } j=n=N-2\n\\end{cases}\n$$\n这些公式对向量 $u$ 和 $\\lambda$ 使用了基于 1 的索引。\n\n计算梯度的步骤如下：\n1.  求解正问题 $A(p)u = b(p)$ 以找到温度分布 $u$。\n2.  使用 $u$ 计算伴随系统的右侧项 $-\\nabla_u J$。\n3.  求解伴随问题 $A(p)\\lambda = -\\nabla_u J$ 以找到伴随变量 $\\lambda$。\n4.  使用推导出的公式结合 $u$ 和 $\\lambda$ 来计算 $\\nabla_p J$。\n\n泰勒检验通过将基于伴随方法计算的方向导数 $\\nabla_p J(p)^T h$ 与有限差分近似值进行比较来验证此梯度。对于光滑函数 $J(p)$，泰勒定理表明 $J(p+\\varepsilon h) = J(p) + \\varepsilon \\nabla_p J(p)^T h + O(\\varepsilon^2)$。误差 $E_1 = |J(p+\\varepsilon h) - J(p)|$ 和 $E_2 = |J(p+\\varepsilon h) - J(p) - \\varepsilon \\nabla_p J(p)^T h|$ 预计将分别以 $O(\\varepsilon^1)$ 和 $O(\\varepsilon^2)$ 的阶数收敛。绘制 $\\log(E)$ 与 $\\log(\\varepsilon)$ 的关系图应得到斜率分别约为 1 和 2 的直线。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for adjoint-based gradient verification.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general variability)\n        {\n            \"L\": 1.0, \"N\": 21, \"q0\": 1000.0, \"T0\": 300.0, \"T1\": 310.0,\n            \"omega_mode\": \"const\", \"u_ref_mode\": \"const\",\n            \"p_mode\": \"sin\", \"h_mode\": \"random\", \"seed\": 0\n        },\n        # Case 2 (boundary-influenced, small system)\n        {\n            \"L\": 0.1, \"N\": 5, \"q0\": 0.0, \"T0\": 400.0, \"T1\": 300.0,\n            \"omega_mode\": \"const\", \"u_ref_mode\": \"const\",\n            \"p_mode\": \"const\", \"h_mode\": \"boundary\", \"seed\": 1\n        },\n        # Case 3 (larger system with random weights and reference)\n        {\n            \"L\": 2.0, \"N\": 31, \"q0\": 500.0, \"T0\": 290.0, \"T1\": 315.0,\n            \"omega_mode\": \"random\", \"u_ref_mode\": \"random\",\n            \"p_mode\": \"cos\", \"h_mode\": \"random\", \"seed\": 2\n        }\n    ]\n\n    epsilons = np.array([1e-1, 5e-2, 2.5e-2, 1.25e-2, 6.25e-3])\n    slope_tolerance = 0.15\n    results = []\n\n    for case in test_cases:\n        test_passed = run_taylor_test(case, epsilons, slope_tolerance)\n        results.append(test_passed)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef assemble_system(p, L, N, q0, T0, T1):\n    \"\"\"\n    Assembles the finite-volume system matrix A and RHS vector b.\n    \"\"\"\n    n = N - 2  # Number of interior nodes\n    dx = L / (N - 1)\n    \n    A = np.zeros((n, n))\n    \n    # Python uses 0-based indexing for u_int[0...n-1]\n    # Parameter p has M=N-1 components, p[0...N-2]\n    \n    # Diagonal entries\n    for i in range(n):\n      A[i, i] = p[i] + p[i+1]\n      \n    # Off-diagonal entries\n    for i in range(n-1):\n      A[i, i+1] = -p[i+1]\n      A[i+1, i] = -p[i+1]\n\n    # We derived the system as A_unscaled u = b_unscaled * dx^2\n    # So we scale A by 1/dx^2.\n    A_scaled = A / (dx**2)\n\n    # RHS vector b\n    b_scaled = np.full(n, q0)\n    # Incorporate boundary conditions into RHS vector b\n    b_scaled[0] += p[0] * T0 / (dx**2)\n    b_scaled[n-1] += p[N-2] * T1 / (dx**2)\n\n    return A_scaled, b_scaled\n\ndef compute_J(u, omega, u_ref):\n    \"\"\"\n    Computes the objective functional J.\n    \"\"\"\n    return 0.5 * np.sum(omega * (u - u_ref)**2)\n\ndef compute_gradient(u, lamb, p, L, N, T0, T1):\n    \"\"\"\n    Computes the gradient of J w.r.t. p using the adjoint method.\n    \"\"\"\n    n = N - 2\n    M = N - 1\n    dx = L / (N - 1)\n    grad = np.zeros(M)\n    \n    # Python arrays u, lamb are 0-indexed (0 to n-1) -> correspond to math indices 1..n\n    # p is 0-indexed (0 to M-1) -> correspond to math indices 0..n\n    \n    # j = 0 (corresponds to p[0])\n    grad[0] = lamb[0] * (u[0] - T0) / dx**2\n    \n    # j = 1 to n-1 (corresponds to p[1] to p[n-1])\n    # This corresponds to math indices j=1..n-1\n    for j in range(1, n):\n        # u[j-1] -> u_j, u[j] -> u_{j+1}\n        # lamb[j-1] -> lambda_j, lamb[j] -> lambda_{j+1}\n        grad[j] = (lamb[j-1] - lamb[j]) * (u[j-1] - u[j]) / dx**2\n        \n    # j = n (corresponds to p[n] = p[N-2])\n    grad[n] = lamb[n-1] * (u[n-1] - T1) / dx**2\n        \n    return grad\n\ndef run_taylor_test(params, epsilons, tolerance):\n    \"\"\"\n    Performs a single Taylor test for a given configuration.\n    \"\"\"\n    L, N, q0, T0, T1 = params[\"L\"], params[\"N\"], params[\"q0\"], params[\"T0\"], params[\"T1\"]\n    n = N - 2\n    M = N - 1\n    \n    rng = np.random.default_rng(params[\"seed\"])\n    \n    # Setup omega (weights)\n    if params[\"omega_mode\"] == \"const\":\n        omega = np.ones(n)\n    else: # \"random\"\n        omega = rng.uniform(0.5, 1.5, size=n)\n        \n    # Setup u_ref (reference temperature)\n    if params[\"u_ref_mode\"] == \"const\":\n        u_ref_val = 305.0 if '305' in params.get('p_mode', '') or params['L']==1.0 else 350.0 # Heuristic for cases\n        if params[\"L\"] == 1.0: u_ref_val = 305.0\n        elif params[\"L\"] == 0.1: u_ref_val = 350.0\n        u_ref = np.full(n, u_ref_val)\n    else: # \"random\"\n        u_ref = rng.uniform(300.0, 305.0, size=n)\n\n    # Setup p (base parameters)\n    j = np.arange(M)\n    if params[\"p_mode\"] == \"sin\":\n        p = 10.0 * (1.0 + 0.2 * np.sin(np.pi * (j + 0.5) / M))\n    elif params[\"p_mode\"] == \"cos\":\n        p = 15.0 * (1.0 + 0.1 * np.cos(2.0 * np.pi * (j + 0.5) / M))\n    else: # \"const\"\n        p = np.full(M, 20.0)\n        \n    # Setup h (perturbation direction)\n    if params[\"h_mode\"] == \"random\":\n        h = rng.standard_normal(M)\n    else: # \"boundary\"\n        h = np.zeros(M)\n        h[0] = 1.0\n        h[M - 1] = -1.0\n    h /= np.linalg.norm(h)\n    \n    # 1. Forward solve\n    A_base, b_base = assemble_system(p, L, N, q0, T0, T1)\n    u_base = scipy.linalg.solve(A_base, b_base, assume_a='sym')\n    J_base = compute_J(u_base, omega, u_ref)\n    \n    # 2. Adjoint solve\n    adj_rhs = -omega * (u_base - u_ref)\n    lamb = scipy.linalg.solve(A_base, adj_rhs, assume_a='sym')\n\n    # 3. Gradient computation\n    grad_J = compute_gradient(u_base, lamb, p, L, N, T0, T1)\n    \n    # Directional derivative\n    grad_h = np.dot(grad_J, h)\n    \n    E1_vals = []\n    E2_vals = []\n    \n    for eps in epsilons:\n        p_eps = p + eps * h\n        \n        # Solve perturbed forward problem and compute J\n        A_eps, b_eps = assemble_system(p_eps, L, N, q0, T0, T1)\n        u_eps = scipy.linalg.solve(A_eps, b_eps, assume_a='sym')\n        J_eps = compute_J(u_eps, omega, u_ref)\n        \n        # Calculate errors\n        E1 = abs(J_eps - J_base)\n        E2 = abs(J_eps - J_base - eps * grad_h)\n        \n        E1_vals.append(E1)\n        E2_vals.append(E2)\n\n    # 4. Convergence order estimation\n    log_eps = np.log(epsilons)\n    log_E1 = np.log(np.array(E1_vals))\n    log_E2 = np.log(np.array(E2_vals))\n    \n    # Use np.polyfit for linear regression (slope is the first element)\n    s1 = np.polyfit(log_eps, log_E1, 1)[0]\n    s2 = np.polyfit(log_eps, log_E2, 1)[0]\n    \n    # 5. Verdict\n    test_passed = abs(s1 - 1.0) = tolerance and abs(s2 - 2.0) = tolerance\n    return test_passed\n\nif __name__ == '__main__':\n    # A simple call to the main logic function.\n    # The output format is handled inside solve().\n    # This block allows the script to be runnable.\n    solve()\n```"
        }
    ]
}