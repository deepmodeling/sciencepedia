{
    "hands_on_practices": [
        {
            "introduction": "To truly master the Generalized Minimal Residual method (GMRES), one must look beyond its procedural steps and understand its core mathematical foundation. At its heart, GMRES constructs a residual vector $r_k = p_k(A)r_0$, where $p_k$ is a polynomial of degree $k$ that minimizes the residual norm while satisfying $p_k(0) = 1$. This exercise provides a carefully constructed scenario that isolates this principle, demonstrating how unrestarted GMRES can find the perfect polynomial to solve a problem in just a few steps, while a poorly chosen restart parameter can lead to complete stagnation . By working through this problem, you will gain a deep, intuitive grasp of how the method's convergence is tied to its ability to find optimal polynomials that suppress components of the residual corresponding to the operator's eigenvalues.",
            "id": "3957964",
            "problem": "Consider a one-dimensional steady advection–diffusion boundary value problem on a unit interval with Dirichlet boundary conditions, discretized by a second-order central finite difference scheme for diffusion and first-order upwind for advection. The resulting linear system $A x = b$ is nonsymmetric. Suppose a left preconditioner $M$ is chosen that exactly inverts the diffusive part but leaves the convective skew-symmetric part unaltered, and that, over an invariant two-dimensional subspace of the preconditioned operator $M^{-1} A$, the spectrum is tightly clustered at two real values, specifically at $\\lambda_{+} = 1$ and $\\lambda_{-} = -1$. Assume that, restricted to this two-dimensional invariant subspace, the eigenvectors $v_{+}$ and $v_{-}$ corresponding to $\\lambda_{+}$ and $\\lambda_{-}$ are orthonormal, and that the initial residual $r_{0}$ lies entirely in this subspace with equal projection onto these eigenvectors, that is $r_{0} = c \\, v_{+} + c \\, v_{-}$ for some nonzero scalar $c \\in \\mathbb{R}$. You apply the Generalized Minimal Residual method (GMRES) without restart to the preconditioned system $M^{-1} A x = M^{-1} b$, and also the restarted GMRES method with restart parameter $m = 1$ (denoted GMRES($1$)).\n\nStarting from the foundational definition that, after $k$ steps, GMRES produces a residual of the form $r_{k} = p_{k}(M^{-1} A) r_{0}$ where $p_{k}$ is a real polynomial of degree $k$ satisfying $p_{k}(0) = 1$, derive, from first principles, the exact residual-norm reduction factors for the following two cases:\n- Unrestarted GMRES after $2$ iterations.\n- GMRES($1$) after one restart cycle.\n\nExpress each reduction factor as the ratio $\\|r\\|_{2} / \\|r_{0}\\|_{2}$, where $\\|\\cdot\\|_{2}$ is the Euclidean norm, and provide the pair of results as a single $1 \\times 2$ row matrix. No rounding is required. The final quantities are dimensionless; report them without units.",
            "solution": "The problem requires the derivation of residual-norm reduction factors for two variants of the Generalized Minimal Residual (GMRES) method applied to a specific preconditioned linear system. We will address each case by starting from the foundational principles of GMRES.\n\nLet the preconditioned operator be denoted by $B = M^{-1}A$. The preconditioned system is $B x = M^{-1} b$. We start the iteration with an initial guess $x_0$ and the corresponding initial residual $r_0 = M^{-1}b - Bx_0$. After $k$ iterations, the unrestarted GMRES method finds an approximate solution $x_k$ in the affine Krylov subspace $x_0 + \\mathcal{K}_k(B, r_0)$, where $\\mathcal{K}_k(B, r_0) = \\text{span}\\{r_0, Br_0, \\dots, B^{k-1}r_0\\}$, such that the Euclidean norm of the corresponding residual $r_k = M^{-1}b - Bx_k$ is minimized.\n\nThe residual $r_k$ can be expressed in terms of the initial residual $r_0$ and a polynomial $p_k$. Since $x_k - x_0 \\in \\mathcal{K}_k(B, r_0)$, we can write $x_k = x_0 + q_{k-1}(B)r_0$ for some polynomial $q_{k-1}$ of degree at most $k-1$. The residual is then\n$$r_k = M^{-1}b - B(x_0 + q_{k-1}(B)r_0) = (M^{-1}b - Bx_0) - Bq_{k-1}(B)r_0 = r_0 - Bq_{k-1}(B)r_0$$\nDefining the residual polynomial $p_k(z) = 1 - z q_{k-1}(z)$, we see that $p_k$ is a polynomial of degree at most $k$ that satisfies the constraint $p_k(0) = 1$. The residual can be written as $r_k = p_k(B)r_0$. GMRES finds the polynomial $p_k$ that minimizes $\\|r_k\\|_2 = \\|p_k(B)r_0\\|_2$ over all real polynomials of degree at most $k$ with $p_k(0)=1$.\n\nFrom the problem statement, we are given a two-dimensional invariant subspace of $B$ spanned by two orthonormal eigenvectors, $v_+$ and $v_-$, corresponding to real eigenvalues $\\lambda_+ = 1$ and $\\lambda_- = -1$, respectively. The initial residual $r_0$ lies entirely in this subspace:\n$$r_0 = c \\, v_{+} + c \\, v_{-}$$\nfor some nonzero real scalar $c$. Since $r_0$ is in this invariant subspace, all subsequent residuals $r_k$ and Krylov vectors $B^j r_0$ will also lie within this subspace.\n\nLet's apply the operator $p_k(B)$ to $r_0$. Since $v_+$ and $v_-$ are eigenvectors of $B$:\n$$r_k = p_k(B)r_0 = p_k(B)(c v_{+} + c v_{-}) = c \\, p_k(B)v_{+} + c \\, p_k(B)v_{-} = c \\, p_k(\\lambda_{+})v_{+} + c \\, p_k(\\lambda_{-})v_{-}$$\nSubstituting the given eigenvalues:\n$$r_k = c \\, p_k(1)v_{+} + c \\, p_k(-1)v_{-}$$\nThe squared Euclidean norm of $r_k$ is found using the orthonormality of $v_+$ and $v_-$ (i.e., $\\langle v_+, v_+ \\rangle = 1$, $\\langle v_-, v_- \\rangle = 1$, and $\\langle v_+, v_- \\rangle = 0$):\n$$\\|r_k\\|_2^2 = \\langle c \\, p_k(1)v_{+} + c \\, p_k(-1)v_{-}, c \\, p_k(1)v_{+} + c \\, p_k(-1)v_{-} \\rangle$$\n$$\\|r_k\\|_2^2 = c^2 |p_k(1)|^2 \\langle v_+, v_+ \\rangle + c^2 |p_k(-1)|^2 \\langle v_-, v_- \\rangle + 2c^2 p_k(1)p_k(-1) \\langle v_+, v_- \\rangle$$\n$$\\|r_k\\|_2^2 = c^2 (p_k(1)^2 + p_k(-1)^2)$$\nThe squared norm of the initial residual $r_0$ is:\n$$\\|r_0\\|_2^2 = \\langle c v_{+} + c v_{-}, c v_{+} + c v_{-} \\rangle = c^2 \\langle v_+, v_+ \\rangle + c^2 \\langle v_-, v_- \\rangle + 2c^2 \\langle v_+, v_- \\rangle = c^2(1) + c^2(1) + 0 = 2c^2$$\nThe residual-norm reduction factor after $k$ steps is $\\frac{\\|r_k\\|_2}{\\|r_0\\|_2}$. Its square is:\n$$\\left( \\frac{\\|r_k\\|_2}{\\|r_0\\|_2} \\right)^2 = \\frac{c^2 (p_k(1)^2 + p_k(-1)^2)}{2c^2} = \\frac{p_k(1)^2 + p_k(-1)^2}{2}$$\nGMRES finds the polynomial $p_k$ that minimizes this expression.\n\n**Case 1: Unrestarted GMRES after 2 iterations ($k=2$)**\nWe are looking for a polynomial $p_2(z)$ of degree at most $2$ with $p_2(0)=1$ that minimizes $\\frac{p_2(1)^2 + p_2(-1)^2}{2}$. To minimize this sum of squares, we should ideally choose $p_2(z)$ such that $p_2(1)=0$ and $p_2(-1)=0$.\nLet's construct such a polynomial. The roots are $1$ and $-1$. The form of the polynomial must be $p_2(z) = \\gamma (z-1)(z+1)$ for some constant $\\gamma$. We use the constraint $p_2(0)=1$ to determine $\\gamma$:\n$$p_2(0) = \\gamma (0-1)(0+1) = -\\gamma = 1 \\implies \\gamma = -1$$\nSo, the optimal polynomial is $p_2(z) = -(z^2-1) = 1-z^2$. This is a polynomial of degree $2$ satisfying $p_2(0)=1$, so it is a valid candidate for GMRES(2).\nWith this polynomial, we have $p_2(1) = 0$ and $p_2(-1) = 0$. The minimum value of the squared reduction factor is:\n$$\\left( \\frac{\\|r_2\\|_2}{\\|r_0\\|_2} \\right)^2 = \\frac{0^2 + 0^2}{2} = 0$$\nThus, the reduction factor is $0$. This indicates that GMRES converges to the exact solution in two iterations for this specific problem setup.\n\n**Case 2: GMRES(1) after one restart cycle**\nGMRES(1) involves running a single GMRES step ($k=1$) and then restarting. The reduction factor \"after one restart cycle\" refers to the reduction achieved in this single step. We need to find the optimal polynomial $p_1(z)$ of degree at most $1$ with $p_1(0)=1$ that minimizes the reduction factor.\nA polynomial of degree at most $1$ with $p_1(0)=1$ has the general form $p_1(z) = 1 - \\alpha z$ for some real coefficient $\\alpha$.\nWe need to find the value of $\\alpha$ that minimizes the quantity $\\frac{p_1(1)^2 + p_1(-1)^2}{2}$.\n$$p_1(1) = 1 - \\alpha$$\n$$p_1(-1) = 1 - \\alpha(-1) = 1 + \\alpha$$\nThe expression to minimize is a function of $\\alpha$:\n$$f(\\alpha) = \\frac{(1-\\alpha)^2 + (1+\\alpha)^2}{2} = \\frac{(1 - 2\\alpha + \\alpha^2) + (1 + 2\\alpha + \\alpha^2)}{2} = \\frac{2 + 2\\alpha^2}{2} = 1 + \\alpha^2$$\nTo minimize $f(\\alpha)$, we find the critical points by taking the derivative with respect to $\\alpha$ and setting it to zero:\n$$f'(\\alpha) = 2\\alpha = 0 \\implies \\alpha = 0$$\nThis choice of $\\alpha=0$ minimizes $f(\\alpha)$. The minimal value is $f(0) = 1+0^2=1$.\nThe minimum squared reduction factor is $1$. The reduction factor is therefore $\\sqrt{1} = 1$.\nThis means that after one step of GMRES, the residual norm is not reduced at all; $\\|r_1\\|_2 = \\|r_0\\|_2$. The method stagnates. This occurs because the optimal polynomial is $p_1(z)=1$, which corresponds to making no update ($x_1=x_0$ and $r_1=r_0$).\n\nCombining the results, the reduction factor for unrestarted GMRES after $2$ iterations is $0$, and for GMRES(1) after one cycle is $1$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While the core GMRES algorithm is elegant, its practical performance on challenging problems from computational engineering almost always depends on effective preconditioning. However, the choice of how to apply a preconditioner—on the left or on the right—is a subtle but critical decision. This exercise uses a simple, concrete advection-diffusion model to illustrate the profound difference between these two strategies . You will find that while left preconditioning minimizes the norm of the preconditioned residual, right preconditioning preserves the original residual norm, which may better align with the physical 'energy' of the system. This hands-on calculation will clarify these abstract concepts and highlight the importance of choosing a preconditioning strategy that is consistent with the goals of the physical simulation.",
            "id": "3958007",
            "problem": "Consider a steady one-dimensional advection–diffusion model for temperature governed by Fourier’s law of heat conduction and linear advection. A second-order finite-volume or finite-difference discretization on two internal control volumes yields a symmetric positive definite (SPD) conduction stiffness matrix $K$ and an upper-triangular convection matrix $C$, so that the total operator is $A = K + C$. Take\n$$\nK = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix}, \\quad C = \\begin{pmatrix}0 & 3 \\\\ 0 & 0\\end{pmatrix}, \\quad A = \\begin{pmatrix}2 & 2 \\\\ -1 & 2\\end{pmatrix},\n$$\nwith a prescribed source term vector\n$$\nb = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}.\n$$\nDefine the physical energy norm induced by conduction as $\\|v\\|_{E} = \\sqrt{v^{\\top} K v}$, consistent with the discrete form of the energy functional for conduction $E(x) = \\frac{1}{2} x^{\\top} K x - b^{\\top} x$. Consider Generalized Minimal Residual (GMRES) with one iteration from the zero initial guess for the nonsymmetric linear system $A x = b$, using two different preconditionings:\n- Left preconditioning with $M_{L} = \\operatorname{diag}(A)$, so the solved system is $M_{L}^{-1} A x = M_{L}^{-1} b$, and GMRES minimizes $\\|M_{L}^{-1} r\\|_{2}$, where $r = b - A x$.\n- Right preconditioning with $M_{R} = K$, so the solved system is $A M_{R}^{-1} y = b$ with $x = M_{R}^{-1} y$, and GMRES minimizes $\\|r\\|_{2}$.\n\nLet $x_{L}$ and $x_{R}$ be the one-iteration GMRES approximations obtained under left and right preconditioning, respectively, and let $r_{L} = b - A x_{L}$ and $r_{R} = b - A x_{R}$ be the corresponding residuals. Let the energy-gradient directions be $g_{E,L} = b - K x_{L}$ and $g_{E,R} = b - K x_{R}$. To quantify “correlation with the physical energy norm,” use the cosine in the $K$-inner product,\n$$\n\\cos_{K}(u,v) = \\frac{u^{\\top} K v}{\\sqrt{u^{\\top} K u} \\, \\sqrt{v^{\\top} K v}}.\n$$\nCompute the ratio\n$$\n\\rho = \\frac{\\cos_{K}(r_{R}, g_{E,R})}{\\cos_{K}(r_{L}, g_{E,L})}.\n$$\nExpress your final answer as a simplified exact analytical expression. No rounding is required.",
            "solution": "The governing physical basis is Fourier’s law of heat conduction and linear advection. In the discrete setting, the symmetric positive definite (SPD) conduction matrix $K$ represents the bilinear form associated with the energy norm $\\|v\\|_{E} = \\sqrt{v^{\\top} K v}$, while the advection contribution $C$ introduces nonsymmetry so that $A = K + C$.\n\nWe analyze one iteration of Generalized Minimal Residual (GMRES) from $x_{0} = 0$ under left and right preconditioning.\n\nRight preconditioning with $M_{R} = K$: We solve $A M_{R}^{-1} y = b$ and set $x = M_{R}^{-1} y$. In one GMRES iteration, $y$ lies in $\\operatorname{span}\\{b\\}$, so $y = \\alpha b$, yielding $x = \\alpha K^{-1} b$. The residual is\n$$\nr_{R} = b - A x = b - \\alpha A K^{-1} b.\n$$\nThe GMRES step selects $\\alpha$ to minimize $\\|r_{R}\\|_{2}$, which gives\n$$\n\\alpha_{R} = \\frac{b^{\\top} (A K^{-1} b)}{\\|A K^{-1} b\\|_{2}^{2}}.\n$$\nCompute $K^{-1}$ and the needed quantities. Since\n$$\nK = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix}, \\quad \\det(K) = 3, \\quad K^{-1} = \\frac{1}{3} \\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix},\n$$\nwe have\n$$\nK^{-1} b = \\frac{1}{3} \\begin{pmatrix}1 \\\\ 2\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{3} \\\\ \\frac{2}{3}\\end{pmatrix},\n\\quad\nA K^{-1} b = \\begin{pmatrix}2 & 2 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}\\frac{1}{3} \\\\ \\frac{2}{3}\\end{pmatrix}\n= \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}.\n$$\nThus\n$$\n\\alpha_{R} = \\frac{b^{\\top} (A K^{-1} b)}{\\|A K^{-1} b\\|_{2}^{2}} = \\frac{\\begin{pmatrix}0 & 1\\end{pmatrix} \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}}{2^{2} + 1^{2}} = \\frac{1}{5}.\n$$\nTherefore\n$$\nx_{R} = \\alpha_{R} K^{-1} b = \\frac{1}{5} \\cdot \\frac{1}{3} \\begin{pmatrix}1 \\\\ 2\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{15} \\\\ \\frac{2}{15}\\end{pmatrix}.\n$$\nCompute the residual and the energy-gradient direction:\n$$\nA x_{R} = \\begin{pmatrix}2 & 2 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}\\frac{1}{15} \\\\ \\frac{2}{15}\\end{pmatrix}\n= \\begin{pmatrix}\\frac{2}{15} + \\frac{4}{15} \\\\ -\\frac{1}{15} + \\frac{4}{15}\\end{pmatrix}\n= \\begin{pmatrix}\\frac{2}{5} \\\\ \\frac{1}{5}\\end{pmatrix},\n$$\n$$\nr_{R} = b - A x_{R} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}\\frac{2}{5} \\\\ \\frac{1}{5}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{2}{5} \\\\ \\frac{4}{5}\\end{pmatrix},\n$$\n$$\nK x_{R} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}\\frac{1}{15} \\\\ \\frac{2}{15}\\end{pmatrix}\n= \\begin{pmatrix}\\frac{2}{15} - \\frac{2}{15} \\\\ -\\frac{1}{15} + \\frac{4}{15}\\end{pmatrix}\n= \\begin{pmatrix}0 \\\\ \\frac{1}{5}\\end{pmatrix},\n$$\n$$\ng_{E,R} = b - K x_{R} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}0 \\\\ \\frac{1}{5}\\end{pmatrix}\n= \\begin{pmatrix}0 \\\\ \\frac{4}{5}\\end{pmatrix}.\n$$\nThe $K$-inner product cosine is\n$$\n\\cos_{K}(r_{R}, g_{E,R}) = \\frac{r_{R}^{\\top} K g_{E,R}}{\\sqrt{r_{R}^{\\top} K r_{R}} \\, \\sqrt{g_{E,R}^{\\top} K g_{E,R}}}.\n$$\nCompute the needed terms:\n$$\nK g_{E,R} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}0 \\\\ \\frac{4}{5}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{4}{5} \\\\ \\frac{8}{5}\\end{pmatrix},\n$$\n$$\nr_{R}^{\\top} K g_{E,R} = \\begin{pmatrix}-\\frac{2}{5} & \\frac{4}{5}\\end{pmatrix} \\begin{pmatrix}-\\frac{4}{5} \\\\ \\frac{8}{5}\\end{pmatrix}\n= \\frac{8}{25} + \\frac{32}{25} = \\frac{40}{25} = \\frac{8}{5},\n$$\n$$\nK r_{R} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}-\\frac{2}{5} \\\\ \\frac{4}{5}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{8}{5} \\\\ 2\\end{pmatrix},\n\\quad\nr_{R}^{\\top} K r_{R} = \\begin{pmatrix}-\\frac{2}{5} & \\frac{4}{5}\\end{pmatrix} \\begin{pmatrix}-\\frac{8}{5} \\\\ 2\\end{pmatrix}\n= \\frac{16}{25} + \\frac{8}{5} = \\frac{56}{25},\n$$\n$$\ng_{E,R}^{\\top} K g_{E,R} = \\begin{pmatrix}0 & \\frac{4}{5}\\end{pmatrix} \\begin{pmatrix}-\\frac{4}{5} \\\\ \\frac{8}{5}\\end{pmatrix}\n= \\frac{32}{25}.\n$$\nThus\n$$\n\\cos_{K}(r_{R}, g_{E,R}) = \\frac{\\frac{8}{5}}{\\sqrt{\\frac{56}{25}} \\, \\sqrt{\\frac{32}{25}}}\n= \\frac{\\frac{8}{5}}{\\frac{\\sqrt{56}}{5} \\cdot \\frac{\\sqrt{32}}{5}}\n= \\frac{40}{\\sqrt{56}\\sqrt{32}}\n= \\frac{40}{\\sqrt{1792}}\n= \\frac{40}{16 \\sqrt{7}}\n= \\frac{5}{2 \\sqrt{7}}.\n$$\n\nLeft preconditioning with $M_{L} = \\operatorname{diag}(A) = \\begin{pmatrix}2 & 0 \\\\ 0 & 2\\end{pmatrix}$: We solve $M_{L}^{-1} A x = M_{L}^{-1} b$ by GMRES. In one iteration, $x$ lies in $\\operatorname{span}\\{M_{L}^{-1} b\\}$, so $x = \\alpha M_{L}^{-1} b$. The GMRES step selects $\\alpha$ to minimize $\\|M_{L}^{-1} r\\|_{2} = \\|M_{L}^{-1}(b - A x)\\|_{2}$, equivalently to minimize $\\|c - \\alpha q\\|_{2}$ where\n$$\nc = M_{L}^{-1} b, \\quad q = M_{L}^{-1} A M_{L}^{-1} b.\n$$\nCompute $M_{L}^{-1} = \\frac{1}{2} I$ and hence\n$$\nc = \\frac{1}{2} \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ \\frac{1}{2}\\end{pmatrix}, \\quad\nq = \\frac{1}{2} A \\left(\\frac{1}{2} b\\right) = \\frac{1}{4} A b = \\frac{1}{4} \\begin{pmatrix}2 \\\\ 2\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}.\n$$\nTherefore,\n$$\n\\alpha_{L} = \\frac{c^{\\top} q}{\\|q\\|_{2}^{2}} = \\frac{\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)}{\\left(\\frac{1}{2}\\right)^{2} + \\left(\\frac{1}{2}\\right)^{2}} = \\frac{\\frac{1}{4}}{\\frac{1}{2}} = \\frac{1}{2}.\n$$\nThen\n$$\nx_{L} = \\alpha_{L} c = \\frac{1}{2} \\begin{pmatrix}0 \\\\ \\frac{1}{2}\\end{pmatrix} = \\begin{pmatrix}0 \\\\ \\frac{1}{4}\\end{pmatrix},\n$$\nand\n$$\nA x_{L} = \\begin{pmatrix}2 & 2 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}0 \\\\ \\frac{1}{4}\\end{pmatrix}\n= \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}, \\quad\nr_{L} = b - A x_{L} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}.\n$$\nThe energy-gradient direction is\n$$\nK x_{L} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}0 \\\\ \\frac{1}{4}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{1}{4} \\\\ \\frac{1}{2}\\end{pmatrix}, \\quad\ng_{E,L} = b - K x_{L} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}-\\frac{1}{4} \\\\ \\frac{1}{2}\\end{pmatrix}\n= \\begin{pmatrix}\\frac{1}{4} \\\\ \\frac{1}{2}\\end{pmatrix}.\n$$\nCompute the $K$-cosine:\n$$\nK g_{E,L} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}\\frac{1}{4} \\\\ \\frac{1}{2}\\end{pmatrix}\n= \\begin{pmatrix}0 \\\\ \\frac{3}{4}\\end{pmatrix},\n$$\n$$\nr_{L}^{\\top} K g_{E,L} = \\begin{pmatrix}-\\frac{1}{2} & \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}0 \\\\ \\frac{3}{4}\\end{pmatrix} = \\frac{3}{8},\n$$\n$$\nK r_{L} = \\begin{pmatrix}2 & -1 \\\\ -1 & 2\\end{pmatrix} \\begin{pmatrix}-\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}\n= \\begin{pmatrix}-\\frac{3}{2} \\\\ \\frac{3}{2}\\end{pmatrix}, \\quad\nr_{L}^{\\top} K r_{L} = \\begin{pmatrix}-\\frac{1}{2} & \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}-\\frac{3}{2} \\\\ \\frac{3}{2}\\end{pmatrix} = \\frac{3}{2},\n$$\n$$\ng_{E,L}^{\\top} K g_{E,L} = \\begin{pmatrix}\\frac{1}{4} & \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}0 \\\\ \\frac{3}{4}\\end{pmatrix} = \\frac{3}{8}.\n$$\nTherefore,\n$$\n\\cos_{K}(r_{L}, g_{E,L}) = \\frac{\\frac{3}{8}}{\\sqrt{\\frac{3}{2}} \\, \\sqrt{\\frac{3}{8}}}\n= \\frac{\\frac{3}{8}}{\\sqrt{\\frac{9}{16}}}\n= \\frac{\\frac{3}{8}}{\\frac{3}{4}}\n= \\frac{1}{2}.\n$$\n\nThe requested ratio is\n$$\n\\rho = \\frac{\\cos_{K}(r_{R}, g_{E,R})}{\\cos_{K}(r_{L}, g_{E,L})}\n= \\frac{\\frac{5}{2 \\sqrt{7}}}{\\frac{1}{2}}\n= \\frac{5}{\\sqrt{7}}.\n$$\n\nFor completeness, we confirm “faster minimization of the preconditioned norm” for left preconditioning in this single-iteration comparison by computing the preconditioned residual norms with $M_{L}^{-1}$:\n$$\n\\|M_{L}^{-1} r_{L}\\|_{2} = \\left\\|\\frac{1}{2} \\begin{pmatrix}-\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}\\right\\|_{2}\n= \\left\\|\\begin{pmatrix}-\\frac{1}{4} \\\\ \\frac{1}{4}\\end{pmatrix}\\right\\|_{2}\n= \\sqrt{\\frac{1}{16} + \\frac{1}{16}}\n= \\sqrt{\\frac{1}{8}}\n= \\frac{1}{2 \\sqrt{2}},\n$$\n$$\n\\|M_{L}^{-1} r_{R}\\|_{2} = \\left\\|\\frac{1}{2} \\begin{pmatrix}-\\frac{2}{5} \\\\ \\frac{4}{5}\\end{pmatrix}\\right\\|_{2}\n= \\left\\|\\begin{pmatrix}-\\frac{1}{5} \\\\ \\frac{2}{5}\\end{pmatrix}\\right\\|_{2}\n= \\sqrt{\\frac{1}{25} + \\frac{4}{25}}\n= \\sqrt{\\frac{1}{5}}\n= \\frac{1}{\\sqrt{5}},\n$$\nand indeed $\\frac{1}{2 \\sqrt{2}} < \\frac{1}{\\sqrt{5}}$, so the left-preconditioned residual in the preconditioned norm is smaller after one iteration, while the correlation with the physical energy norm is poorer since $\\cos_{K}(r_{L}, g_{E,L}) = \\frac{1}{2} < \\cos_{K}(r_{R}, g_{E,R}) = \\frac{5}{2 \\sqrt{7}}$. The ratio $\\rho$ quantifies this difference.",
            "answer": "$$\\boxed{\\frac{5}{\\sqrt{7}}}$$"
        },
        {
            "introduction": "In engineering practice, the ultimate goal of a simulation is not to obtain a small residual norm, but to compute a specific quantity of interest (QoI)—such as stress, lift, or heat flux—to a desired accuracy. A standard relative residual tolerance may be overly stringent or dangerously loose depending on the specific QoI. This exercise introduces the powerful concept of goal-oriented error estimation using the adjoint method, which provides a direct link between the solver's residual and the error in the final engineering answer . By deriving this relationship and applying it to determine a suitable stopping tolerance, you will learn how to move beyond generic convergence criteria and implement intelligent, efficient stopping conditions that guarantee the required accuracy for the quantities that truly matter.",
            "id": "3957987",
            "problem": "A two-dimensional steady convection–diffusion heat transfer problem in a channel with a heated wall is discretized by a conservative finite-volume method using first-order upwind for the advective fluxes and central differencing for the diffusive fluxes. The resulting linear system is nonsymmetric and can be written as $A u = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is nonsymmetric, $u \\in \\mathbb{R}^{n}$ is the vector of nodal temperatures, and $b \\in \\mathbb{R}^{n}$ is the load vector from sources and boundary conditions. The integrated wall heat flux over the heated wall $\\Gamma_{h}$ is the quantity of interest, modeled at the discrete level as the linear functional $J(u) = g^{\\mathsf{T}} u$ for a known vector $g \\in \\mathbb{R}^{n}$ constructed from face conductances and wall normals.\n\nSuppose the Generalized Minimal Residual (GMRES) method is applied without left or right preconditioning to compute an approximate solution $\\tilde{u}$ with true residual $r = b - A \\tilde{u}$. Let the error in the quantity of interest be $\\Delta J = J(u) - J(\\tilde{u})$. You are asked to relate the relative residual $\\|r\\|_{2}/\\|b\\|_{2}$ to the expected absolute error $|\\Delta J|$ in the integrated heat flux using only fundamental definitions from linear algebra (error, residual, dual problem) and norm inequalities, and then determine a stopping tolerance that guarantees an engineering-accurate result.\n\nAssume the following data are available from problem setup and auxiliary adjoint analysis on the same mesh:\n- The discrete adjoint $z \\in \\mathbb{R}^{n}$ solves $A^{\\mathsf{T}} z = g$, and its Euclidean norm is bounded as $\\|z\\|_{2} \\leq 40$.\n- The Euclidean norm of the right-hand side is measured to be $\\|b\\|_{2} = 3.0 \\times 10^{4}$.\n- A previously validated computation indicates a nominal integrated heat flux $J_{\\mathrm{ref}} = 8.0 \\times 10^{4}$ in watt. The engineering requirement is that the computed integrated heat flux be accurate to within a fractional tolerance of $0.005$ of $J_{\\mathrm{ref}}$ in absolute value.\n\nUsing only the above information and fundamental linear algebra, derive an inequality that upper bounds $|\\Delta J|$ in terms of $\\|r\\|_{2}$ and $\\|z\\|_{2}$, then express this bound in terms of the relative residual $\\tau = \\|r\\|_{2}/\\|b\\|_{2}$. Determine the largest admissible value of $\\tau$ that guarantees the engineering requirement on the absolute error in integrated heat flux. Round your final answer for $\\tau$ to three significant figures. The final answer must be reported as a dimensionless number with no units.",
            "solution": "The problem requires us to derive an inequality relating the absolute error in a quantity of interest, $|\\Delta J|$, to the relative residual, $\\tau = \\|r\\|_{2}/\\|b\\|_{2}$, for a linear system solved with an iterative method. Subsequently, we must determine the largest value of $\\tau$ that guarantees a specified engineering accuracy for $J$.\n\nFirst, we formalize the problem setup. The exact solution $u \\in \\mathbb{R}^{n}$ to the discrete system satisfies the linear equation:\n$$A u = b$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ is a nonsymmetric matrix, and $b \\in \\mathbb{R}^{n}$ is the right-hand side vector.\n\nThe quantity of interest is a linear functional of the solution, given by:\n$$J(u) = g^{\\mathsf{T}} u$$\nfor a specified vector $g \\in \\mathbb{R}^{n}$.\n\nAn approximate solution, denoted by $\\tilde{u} \\in \\mathbb{R}^{n}$, is computed. The error in this solution is the vector $e = u - \\tilde{u}$. The corresponding residual is $r = b - A \\tilde{u}$. We can relate the error $e$ to the residual $r$ by observing that:\n$$A e = A (u - \\tilde{u}) = A u - A \\tilde{u} = b - A \\tilde{u} = r$$\nThus, the error vector $e$ satisfies the linear system $A e = r$.\n\nThe error in the quantity of interest, $\\Delta J$, is the difference between the exact value and the approximate value:\n$$\\Delta J = J(u) - J(\\tilde{u}) = g^{\\mathsf{T}} u - g^{\\mathsf{T}} \\tilde{u} = g^{\\mathsf{T}} (u - \\tilde{u}) = g^{\\mathsf{T}} e$$\n\nTo proceed, we introduce the discrete adjoint problem, which is defined with respect to the matrix $A$ and the vector $g$ that defines the quantity of interest. The adjoint solution, $z \\in \\mathbb{R}^{n}$, solves:\n$$A^{\\mathsf{T}} z = g$$\nThis allows us to express $g$ as $g = A^{\\mathsf{T}} z$. Substituting this into the expression for $\\Delta J$:\n$$\\Delta J = (A^{\\mathsf{T}} z)^{\\mathsf{T}} e = z^{\\mathsf{T}} A e$$\nSince we have already established that $A e = r$, we can substitute this to obtain an exact expression for the error in the quantity of interest:\n$$\\Delta J = z^{\\mathsf{T}} r$$\nThis fundamental result states that the error in the linear functional output is exactly equal to the inner product of the adjoint solution and the primal residual.\n\nTo obtain an upper bound for the magnitude of this error, $|\\Delta J|$, we apply the Cauchy-Schwarz inequality to the inner product $z^{\\mathsf{T}} r$:\n$$|\\Delta J| = |z^{\\mathsf{T}} r| \\leq \\|z\\|_{2} \\|r\\|_{2}$$\nThis inequality provides an upper bound on the absolute error in the quantity of interest in terms of the Euclidean norms of the adjoint solution $z$ and the residual $r$.\n\nThe problem specifies the use of the relative residual, $\\tau = \\|r\\|_{2}/\\|b\\|_{2}$, as the stopping criterion. We can express the norm of the residual as $\\|r\\|_{2} = \\tau \\|b\\|_{2}$. Substituting this into our error bound gives:\n$$|\\Delta J| \\leq \\|z\\|_{2} (\\tau \\|b\\|_{2}) = \\tau \\|z\\|_{2} \\|b\\|_{2}$$\nThis is the desired inequality that relates the absolute error $|\\Delta J|$ to the relative residual $\\tau$.\n\nNext, we must determine the largest admissible value of $\\tau$ that guarantees the specified engineering accuracy. The reference integrated heat flux is $J_{\\mathrm{ref}} = 8.0 \\times 10^{4}$. The required fractional tolerance is $0.005$. The maximum permissible absolute error, which we denote by $|\\Delta J|_{\\mathrm{max}}$, is therefore:\n$$|\\Delta J|_{\\mathrm{max}} = 0.005 \\times J_{\\mathrm{ref}} = 0.005 \\times (8.0 \\times 10^{4}) = 400$$\n\nTo guarantee that the computed error $|\\Delta J|$ does not exceed this value, we must ensure that its upper bound is less than or equal to $|\\Delta J|_{\\mathrm{max}}$:\n$$\\tau \\|z\\|_{2} \\|b\\|_{2} \\leq |\\Delta J|_{\\mathrm{max}}$$\nWe are asked to find the largest value of $\\tau$ for which this guarantee holds. Rearranging the inequality, we get:\n$$\\tau \\leq \\frac{|\\Delta J|_{\\mathrm{max}}}{\\|z\\|_{2} \\|b\\|_{2}}$$\nTo ensure this inequality is satisfied for any possible realization of $z$ that is consistent with the given information, we must use the most conservative (largest) value for $\\|z\\|_{2}$. The problem provides the bound $\\|z\\|_{2} \\leq 40$. Therefore, we use $\\|z\\|_{2} = 40$ in our calculation.\n\nThe given values are:\n- $|\\Delta J|_{\\mathrm{max}} = 400$\n- $\\|z\\|_{2} \\leq 40$\n- $\\|b\\|_{2} = 3.0 \\times 10^{4}$\n\nSubstituting these values into the inequality to find the maximum allowed $\\tau$:\n$$\\tau \\leq \\frac{400}{40 \\times (3.0 \\times 10^{4})}$$\n$$\\tau \\leq \\frac{10}{3.0 \\times 10^{4}} = \\frac{10}{3} \\times 10^{-4}$$\nThe largest admissible value for $\\tau$ is thus $\\frac{10}{3} \\times 10^{-4}$. Evaluating this numerically:\n$$\\tau_{\\mathrm{max}} = \\frac{10}{3} \\times 10^{-4} \\approx 3.333... \\times 10^{-4}$$\nThe problem asks for the answer to be rounded to three significant figures.\n$$\\tau_{\\mathrm{max}} \\approx 3.33 \\times 10^{-4}$$\nThis is the largest value of the relative residual tolerance $\\tau$ that guarantees the absolute error in the integrated heat flux is within the required engineering specification.",
            "answer": "$$\\boxed{3.33 \\times 10^{-4}}$$"
        }
    ]
}