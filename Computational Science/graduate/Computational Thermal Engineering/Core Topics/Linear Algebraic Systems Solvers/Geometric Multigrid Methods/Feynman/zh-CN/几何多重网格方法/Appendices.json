{
    "hands_on_practices": [
        {
            "introduction": "理论学习之后，最好的消化方式莫过于亲自动手计算。本练习将引导您在一维泊松问题上手动执行一个完整的 V 循环。通过手动追踪误差和残差向量在平滑、限制、粗网格校正、插值和后平滑等各个步骤中的变化，您将具体地感受到多重网格方法是如何协同不同尺度的计算来高效消除误差的。",
            "id": "3235102",
            "problem": "考虑一维泊松方程 $-u''(x) = f(x)$，定义在区间 $(0,1)$ 上，并带有齐次狄利克雷边界条件 $u(0) = u(1) = 0$。使用标准的二阶中心有限差分法，在具有 $N=15$ 个内点的最细网格上进行离散化，因此网格间距为 $h = \\frac{1}{N+1} = \\frac{1}{16}$。设最细网格上的离散算子为 $A_h = \\frac{1}{h^2} T$，其中 $T \\in \\mathbb{R}^{15 \\times 15}$ 是主对角线上为 $2$，第一亚对角线和第一超对角线上为 $-1$ 的三对角矩阵。\n\n执行一个两网格 V-循环，包含以下分量：\n- 前光滑：一次加权雅可比迭代，权重为 $\\omega = \\frac{2}{3}$。\n- 限制：从15点网格到7点粗网格的全加权限制 $R$（即 $(R r)_j = \\frac{1}{4}\\big(r_{2j-1} + 2 r_{2j} + r_{2j+1}\\big)$，其中 $j=1,\\dots,7$）。\n- 粗网格算子：伽辽金选择 $A_{2h} = R A_h P$，其中 $P$ 是从7点网格到15点网格的线性插值（值在偶数索引的细网格点处注入，并在奇数索引的细网格点处线性插值）。\n- 粗网格求解：精确求解粗网格系统。\n- 延拓：如上所述的线性插值 $P$。\n- 后光滑：一次加权雅可比迭代，权重为 $\\omega = \\frac{2}{3}$。\n\n假设右端项为零，$f \\equiv 0$，因此精确解为 $u \\equiv 0$。取最细网格上的初始猜测为中间内点处的克罗内克 delta 函数：$u^{(0)}_i = \\delta_{i,8}$，其中 $i=1,\\dots,15$。等价地，初始误差为 $e^{(0)} = u^{(0)}$。\n\n在最细网格上，用手算显式计算 V-循环每个阶段的以下量：\n- 前光滑后的误差 $e^{(1)}$ 和相应的细网格残差 $r^{(1)} = -A_h e^{(1)}$。\n- 限制后的粗网格残差 $r_{2h} = R r^{(1)}$ 和求解 $A_{2h} d_{2h} = r_{2h}$ 得到的精确粗网格校正量 $d_{2h}$。\n- 细网格校正量 $P d_{2h}$ 和后光滑前的校正误差 $e^{(1,\\mathrm{cc})} = e^{(1)} + P d_{2h}$。\n- 最后一次加权雅可比迭代后的后光滑误差 $e^{(V)}$。\n\n在报告残差时，为避免混乱，你可以忽略公因子 $\\frac{1}{h^2}$，并报告未缩放的量 $-T e$ 来代替 $-A_h e$。最后，设 $\\|\\cdot\\|_2$ 表示 $\\mathbb{R}^{15}$ 上的欧几里得范数。比值 $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$ 的精确值是多少？将你的最终答案表示为一个简化的精确表达式。不需要四舍五入。",
            "solution": "本题要求详细、分步地计算一维泊松方程的一个两网格 V-循环。我们将系统地计算循环的每个阶段误差向量的状态。\n\n**第0步：初始状态**\n\n问题在具有 $N=15$ 个内点的细网格上进行离散化。网格间距为 $h = \\frac{1}{16}$。设 $e^{(0)}$ 为 $\\mathbb{R}^{15}$ 中的初始误差向量。精确解为 $u \\equiv 0$，因此误差等于初始猜测。\n初始猜测给定为 $u^{(0)}_i = \\delta_{i,8}$，其中 $\\delta_{i,j}$ 是克罗内克 delta 函数。因此，初始误差向量 $e^{(0)}$ 是一个标准基向量：\n$$e^{(0)} = (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)^T \\equiv e_8$$\n初始误差的欧几里得范数为 $\\|e^{(0)}\\|_2 = \\sqrt{1^2} = 1$。\n\n**第1步：前光滑和细网格残差**\n\n对初始误差 $e^{(0)}$ 应用一次权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比前光滑。误差变换由迭代矩阵 $S = I - \\omega D_h^{-1} A_h$ 给出。\n细网格算子为 $A_h = \\frac{1}{h^2} T$，其中 $T = \\text{tridiag}(-1, 2, -1)$ 是 $15 \\times 15$ 的离散拉普拉斯算子。$A_h$ 的对角部分为 $D_h = \\frac{2}{h^2}I$。\n因此，光滑矩阵为：\n$$S = I - \\frac{2}{3} \\left(\\frac{h^2}{2}I\\right) \\left(\\frac{1}{h^2}T\\right) = I - \\frac{1}{3}T$$\n前光滑后的误差 $e^{(1)}$ 为：\n$$e^{(1)} = S e^{(0)} = \\left(I - \\frac{1}{3}T\\right) e_8 = e_8 - \\frac{1}{3} (T e_8)$$\n向量 $T e_8$ 对应于 $T$ 的第8列，即 $(0, \\dots, -1, 2, -1, \\dots, 0)^T$，其非零项在索引 $i=7, 8, 9$ 处。\n$$T e_8 = -e_7 + 2e_8 - e_9$$\n因此，\n$$e^{(1)} = e_8 - \\frac{1}{3}(-e_7 + 2e_8 - e_9) = \\frac{1}{3}e_7 + \\left(1-\\frac{2}{3}\\right)e_8 + \\frac{1}{3}e_9 = \\frac{1}{3}(e_7 + e_8 + e_9)$$\n所以，前光滑后的误差为 $e^{(1)} = (0, 0, 0, 0, 0, 0, \\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0, 0)^T$。\n\n接下来，我们计算细网格残差 $r^{(1)} = -A_h e^{(1)}$。根据题目要求，我们将计算未缩放的残差 $\\tilde{r}^{(1)} = -T e^{(1)}$。\n$$\\tilde{r}^{(1)} = -T \\left(\\frac{1}{3}(e_7 + e_8 + e_9)\\right) = -\\frac{1}{3}(T e_7 + T e_8 + T e_9)$$\n使用 $T e_i = -e_{i-1} + 2e_i - e_{i+1}$（其中 $e_0=e_{16}=0$）：\n\\begin{align*} T e_7 = -e_6 + 2e_7 - e_8 \\\\ T e_8 = -e_7 + 2e_8 - e_9 \\\\ T e_9 = -e_8 + 2e_9 - e_{10} \\end{align*}\n将这些相加得到：\n$$T(e_7+e_8+e_9) = -e_6 + (-1+2)e_7 + (-1+2-1)e_8 + (-1+2)e_9 - e_{10} = -e_6 + e_7 + e_9 - e_{10}$$\n因此，未缩放的残差为：\n$$\\tilde{r}^{(1)} = -\\frac{1}{3}(-e_6 + e_7 + e_9 - e_{10}) = \\frac{1}{3}(e_6 - e_7 - e_9 + e_{10})$$\n具体地，$\\tilde{r}^{(1)} = (0, 0, 0, 0, 0, \\frac{1}{3}, -\\frac{1}{3}, 0, -\\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0)^T$。题目将此量称为 $r^{(1)}$。\n\n**第2步：限制和粗网格求解**\n\n使用全加权限制算子 $R$ 将未缩放的细网格残差 $\\tilde{r}^{(1)}$ 限制到粗网格（7个内点）上：\n$$(r_{2h})_j = (R \\tilde{r}^{(1)})_j = \\frac{1}{4}\\left(\\tilde{r}^{(1)}_{2j-1} + 2\\tilde{r}^{(1)}_{2j} + \\tilde{r}^{(1)}_{2j+1}\\right) \\quad \\text{for } j=1, \\dots, 7$$\n$\\tilde{r}^{(1)}$ 的非零分量在索引 $6, 7, 9, 10$ 处。\n\\begin{align*} (r_{2h})_1 = (R\\tilde{r}^{(1)})_1 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_2 = (R\\tilde{r}^{(1)})_2 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_3 = (R\\tilde{r}^{(1)})_3 = \\frac{1}{4}(\\tilde{r}^{(1)}_5 + 2\\tilde{r}^{(1)}_6 + \\tilde{r}^{(1)}_7) = \\frac{1}{4}\\left(0 + 2\\left(\\frac{1}{3}\\right) - \\frac{1}{3}\\right) = \\frac{1}{12} \\\\ (r_{2h})_4 = (R\\tilde{r}^{(1)})_4 = \\frac{1}{4}(\\tilde{r}^{(1)}_7 + 2\\tilde{r}^{(1)}_8 + \\tilde{r}^{(1)}_9) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2(0) - \\frac{1}{3}\\right) = -\\frac{2}{12} = -\\frac{1}{6} \\\\ (r_{2h})_5 = (R\\tilde{r}^{(1)})_5 = \\frac{1}{4}(\\tilde{r}^{(1)}_9 + 2\\tilde{r}^{(1)}_{10} + \\tilde{r}^{(1)}_{11}) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2\\left(\\frac{1}{3}\\right) + 0\\right) = \\frac{1}{12} \\\\ (r_{2h})_6 = (R\\tilde{r}^{(1)})_6 = 0 \\\\ (r_{2h})_7 = (R\\tilde{r}^{(1)})_7 = 0 \\end{align*}\n限制后的粗网格残差为 $r_{2h} = (0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0)^T$。\n\n需要精确求解的粗网格方程是 $A_{2h} d_{2h} = R r^{(1)}$，其中 $r^{(1)} = -A_h e^{(1)}$。\n$A_{2h} = R A_h P = R \\left(\\frac{1}{h^2} T\\right) P = \\frac{1}{h^2} RTP$。\n$R r^{(1)} = R \\left(-\\frac{1}{h^2} T e^{(1)}\\right) = \\frac{1}{h^2} R \\tilde{r}^{(1)} = \\frac{1}{h^2} r_{2h}$。\n粗网格方程为 $(\\frac{1}{h^2} RTP) d_{2h} = \\frac{1}{h^2} r_{2h}$，可简化为 $(RTP) d_{2h} = r_{2h}$。\n已知矩阵 $RTP$ 为 $\\frac{1}{4}T_{2h}$，其中 $T_{2h}$ 是 $7 \\times 7$ 的三对角矩阵 $\\text{tridiag}(-1, 2, -1)$。\n所以，我们求解 $\\frac{1}{4} T_{2h} d_{2h} = r_{2h}$，或者 $T_{2h} d_{2h} = 4 r_{2h}$。\n$$T_{2h} d_{2h} = 4 \\left(0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0\\right)^T = \\left(0, 0, \\frac{1}{3}, -\\frac{2}{3}, \\frac{1}{3}, 0, 0\\right)^T$$\n设 $b_c$ 为右端项。我们注意到 $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$，其中 $e_j$ 是 $\\mathbb{R}^7$ 中的基向量。\n我们要求解 $T_{2h} d_{2h} = b_c$。我们尝试设 $d_{2h} = c \\cdot e_4$，其中 $c$ 为某个常数。\n$$T_{2h} (c \\cdot e_4) = c(-e_3 + 2e_4 - e_5) = -c(e_3 - 2e_4 + e_5)$$\n与 $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$ 比较，我们看到 $-c = \\frac{1}{3}$，所以 $c = -\\frac{1}{3}$。\n精确的粗网格校正量为 $d_{2h} = -\\frac{1}{3}e_4 = (0, 0, 0, -\\frac{1}{3}, 0, 0, 0)^T$。\n\n**第3步：延拓和校正**\n\n使用线性插值 $P$ 将粗网格校正量 $d_{2h}$ 延拓回细网格：\n$$d_h = P d_{2h} = P \\left(-\\frac{1}{3}e_4\\right) = -\\frac{1}{3} (P e_4)$$\n向量 $P e_4$ 是延拓矩阵的第4列。它对应于从一个在索引 $j=4$ 处为 $1$、其他地方为 $0$ 的粗网格向量进行插值。\n该值被注入到对应的细网格点 $i=2j = 8$ 处：$(P e_4)_8 = 1$。\n奇数索引的细网格点上的值是插值得到的：\n$(P e_4)_7 = \\frac{1}{2}((d_{2h})_3 + (d_{2h})_4) = \\frac{1}{2}(0+1) = \\frac{1}{2}$。\n$(P e_4)_9 = \\frac{1}{2}((d_{2h})_4 + (d_{2h})_5) = \\frac{1}{2}(1+0) = \\frac{1}{2}$。\n所以，$P e_4 = \\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9$。\n细网格校正量为：\n$$d_h = -\\frac{1}{3}\\left(\\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9\\right) = -\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9$$\n具体地，$d_h = (0,0,0,0,0,0, -\\frac{1}{6}, -\\frac{1}{3}, -\\frac{1}{6}, 0,0,0,0,0,0)^T$。这个量就是 $P d_{2h}$。\n\n后光滑前的校正误差为 $e^{(1,\\mathrm{cc})} = e^{(1)} + d_h$。\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}e_7 + \\frac{1}{3}e_8 + \\frac{1}{3}e_9\\right) + \\left(-\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9\\right)$$\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_7 + \\left(\\frac{1}{3}-\\frac{1}{3}\\right)e_8 + \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_9 = \\frac{1}{6}e_7 + \\frac{1}{6}e_9$$\n校正后的误差为 $e^{(1,\\mathrm{cc})} = (0,0,0,0,0,0, \\frac{1}{6}, 0, \\frac{1}{6}, 0,0,0,0,0,0)^T$。\n\n**第4步：后光滑和最终误差**\n\n对 $e^{(1,\\mathrm{cc})}$ 应用一次后光滑步骤（加权雅可比，$\\omega=2/3$）。一个 V-循环后的最终误差 $e^{(V)}$ 为：\n$$e^{(V)} = S e^{(1,\\mathrm{cc})} = \\left(I - \\frac{1}{3}T\\right) e^{(1,\\mathrm{cc})} = e^{(1,\\mathrm{cc})} - \\frac{1}{3}T e^{(1,\\mathrm{cc})}$$\n$$e^{(1,\\mathrm{cc})} = \\frac{1}{6}(e_7+e_9)$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6} T(e_7+e_9) = \\frac{1}{6}((-e_6+2e_7-e_8) + (-e_8+2e_9-e_{10}))$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\n现在，我们计算 $e^{(V)}$：\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{3}\\left(\\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})\\right)$$\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{18}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\n收集每个基向量的项：\n\\begin{align*} e_6:  \\quad \\frac{1}{18} \\\\ e_7:  \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{3}{18} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_8:  \\quad \\frac{2}{18} = \\frac{1}{9} \\\\ e_9:  \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_{10}: \\quad \\frac{1}{18} \\end{align*}\n一个 V-循环后的最终误差为：\n$$e^{(V)} = \\frac{1}{18}e_6 + \\frac{1}{18}e_7 + \\frac{2}{18}e_8 + \\frac{1}{18}e_9 + \\frac{1}{18}e_{10} = \\frac{1}{18}(e_6 + e_7 + 2e_8 + e_9 + e_{10})$$\n\n**第5步：误差范数比**\n\n最后，我们计算比值 $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$。\n我们知道 $\\|e^{(0)}\\|_2 = 1$。\n最终误差的范数平方为：\n$$\\|e^{(V)}\\|_2^2 = \\left(\\frac{1}{18}\\right)^2 (1^2 + 1^2 + 2^2 + 1^2 + 1^2) = \\frac{1}{18^2}(1+1+4+1+1) = \\frac{8}{18^2}$$\n范数为：\n$$\\|e^{(V)}\\|_2 = \\sqrt{\\frac{8}{18^2}} = \\frac{\\sqrt{8}}{18} = \\frac{2\\sqrt{2}}{18} = \\frac{\\sqrt{2}}{9}$$\n最终误差范数与初始误差范数的比值为：\n$$\\frac{\\|e^{(V)}\\|_2}{\\|e^{(0)}\\|_2} = \\frac{\\sqrt{2}/9}{1} = \\frac{\\sqrt{2}}{9}$$\n这个值表示对于这个特定的初始误差，经过一个 V-循环后的误差缩减因子。",
            "answer": "$$\\boxed{\\frac{\\sqrt{2}}{9}}$$"
        },
        {
            "introduction": "在了解了 V 循环的机械流程后，一个自然的问题是：我们如何评估和选择最有效的组件，尤其是平滑器？本练习引入了局部傅里叶分析 (Local Fourier Analysis, LFA)，这是一种强大的理论工具，用于量化平滑器对不同频率误差分量的阻尼效果。通过比较对称高斯-赛德尔 (Symmetric Gauss-Seidel, SGS) 和红黑高斯-赛德尔 (Red-Black Gauss-Seidel, RBGS) 平滑器对棋盘模式（一种典型的高频误差）的抑制能力，您将深刻理解为什么某些平滑策略在多重网格中表现更优。",
            "id": "3235044",
            "problem": "考虑在无限方形网格上的离散二维泊松方程，网格间距为 $h$，其标准五点格式为\n$$\n(A u)_{i,j} \\equiv \\frac{1}{h^{2}}\\left(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\\right) = f_{i,j}.\n$$\n假设网格是无限的（等效于在任意大域上的周期性边界条件），以便应用局部傅里叶分析（LFA）。关注应用于 $A u = f$ 的迭代平滑器的齐次误差传播。\n\n你需要比较几何多重网格方法中使用的两种平滑器对棋盘格傅里叶模式的阻尼效果：\n\n1. 对称高斯-赛德尔（SGS）：一次前向字典序高斯-赛德尔扫描，紧接着一次后向字典序高斯-赛德尔扫描。\n2. 红黑高斯-赛德尔（RBGS）：使用当前迭代中的黑点邻居更新所有红点（$i+j$ 为偶数），然后使用新更新的红点邻居更新所有黑点（$i+j$ 为奇数）。\n\n从核心定义出发，使用局部傅里叶分析（LFA）：\n- 网格上的一个傅里叶模式为 $\\,\\varphi_{\\boldsymbol{\\theta}}(i,j) = \\exp\\!\\left(\\mathrm{i}(\\theta_{x} i + \\theta_{y} j)\\right)\\,$，其中 $\\boldsymbol{\\theta} = (\\theta_{x},\\theta_{y}) \\in [-\\pi,\\pi)^{2}$。\n- 棋盘格模式是高频模式 $\\boldsymbol{\\theta} = (\\pi,\\pi)$，即 $\\varphi_{(\\pi,\\pi)}(i,j) = (-1)^{i+j}$。\n- 平滑器的误差传播算子 $E$ 将误差 $e$ 映射到新误差 $\\tilde{e} = E e$。\n\n从第一性原理出发，推导每种平滑器作用下，棋盘格傅里叶分量所乘的单次扫描振幅因子：\n- 对于SGS，将一次扫描解释为一次前向和一次后向字典序高斯-赛德尔扫描的复合，并计算棋盘格模式得到的标量振幅因子。\n- 对于RBGS，考虑到双色分裂在红黑分解中将棋盘格模式与零频率模式耦合。将“棋盘格模式的阻尼”定义为当平滑后误差在傅里叶基中表示时，乘以 $\\varphi_{(\\pi,\\pi)}$ 的系数的模。计算一次完整的红黑扫描（红点更新后进行黑点更新）的该系数。\n\n将最终答案表示为一个单行矩阵，其中包含两个阻尼因子，顺序为“SGS, RBGS”。无需四舍五入。无物理单位。答案必须是单个解析表达式或适当的精确数字。",
            "solution": "用户要求我验证问题陈述，如果有效，则通过推导应用于二维离散泊松方程的对称高斯-赛德尔（SGS）和红黑高斯-赛德尔（RBGS）平滑器对棋盘格傅里叶模式的阻尼因子来解决它。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- **方程：** 无限方形网格上的离散二维泊松方程，间距为 $h$：\n$$(A u)_{i,j} \\equiv \\frac{1}{h^{2}}\\left(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\\right) = f_{i,j}.$$\n- **假设：** 无限网格或在任意大域上的周期性边界条件，允许进行局部傅里叶分析（LFA）。\n- **任务：** 分析齐次误差传播，其中误差 $e$ 通过误差传播算子 $E$ 映射为新误差 $\\tilde{e} = E e$。\n- **平滑器：**\n  1. 对称高斯-赛德尔（SGS）：一次前向字典序扫描，后跟一次后向字典序扫描。\n  2. 红黑高斯-赛德尔（RBGS）：更新红点（$i+j$ 为偶数），然后更新黑点（$i+j$ 为奇数）。\n- **分析工具：** 局部傅里叶分析（LFA）。\n- **傅里叶模式：** $\\varphi_{\\boldsymbol{\\theta}}(i,j) = \\exp(\\mathrm{i}(\\theta_{x} i + \\theta_{y} j))$，其中 $\\boldsymbol{\\theta} = (\\theta_{x},\\theta_{y}) \\in [-\\pi,\\pi)^{2}$。\n- **棋盘格模式：** 对应于 $\\boldsymbol{\\theta} = (\\pi, \\pi)$ 的模式，即 $\\varphi_{(\\pi,\\pi)}(i,j) = (-1)^{i+j}$。\n- **目标：** 推导每种平滑器对棋盘格模式的振幅因子。对于SGS，这是两次扫描复合产生的标量因子。对于RBGS，这是平滑后误差中棋盘格模式系数的模，同时考虑模式耦合。\n- **最终答案格式：** 包含两个阻尼因子 [SGS, RBGS] 的单行矩阵。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题是数值分析领域的一个标准基础课题，特别是在多重网格方法理论中。二维泊松方程、高斯-赛德尔迭代和局部傅里叶分析都是公认的核心概念。该问题在科学上和数学上都是合理的。\n- **适定性：** 问题定义明确。它指定了方程、方法、分析技术以及要计算的量。在LFA中使用无限网格是一种标准的简化假设，使得问题易于处理且适定。处理RBGS情况的说明清晰，能得出唯一的结果。\n- **客观性：** 问题以精确、客观、技术性的语言陈述，没有任何主观性或歧义。\n\n**步骤3：结论与行动**\n问题有效。这是一个适定的、有科学依据的数值分析问题。我将继续解答。\n\n### 解答\n\n平滑器性能的分析基于其对误差 $e$ 的影响。对于线性系统 $Au=f$，迭代法可写为 $Mu^{k+1} = Nu^k + f$，其中 $A=M-N$。误差 $e^k = u - u^k$（其中 $u$ 是精确解）根据 $e^{k+1} = E e^k$ 传播，其中 $E = M^{-1}N = I - M^{-1}A$ 是误差传播算子。在LFA中，我们分析 $E$ 对单个傅里叶模式 $e^k = \\varphi_{\\boldsymbol{\\theta}}$ 的作用。在无限网格上，线性移不变算子将一个傅里叶模式映射为其自身的倍数：$E \\varphi_{\\boldsymbol{\\theta}} = \\lambda(\\boldsymbol{\\theta}) \\varphi_{\\boldsymbol{\\theta}}$。复标量 $\\lambda(\\boldsymbol{\\theta})$ 是放大因子。模式 $\\boldsymbol{\\theta}$ 的平滑因子或阻尼因子是 $|\\lambda(\\boldsymbol{\\theta})|$。我们感兴趣的是棋盘格模式，$\\boldsymbol{\\theta} = (\\pi, \\pi)$。\n\n离散泊松算子的齐次误差方程是\n$$4e_{i,j} - e_{i+1,j} - e_{i-1,j} - e_{i,j+1} - e_{i,j-1} = 0.$$\n来自算子 $A$ 的比例因子 $1/h^2$ 出现在误差传播方程 $M e^{k+1} = N e^k$ 的两侧，因此被消去，对放大因子没有影响。\n\n**1. 对称高斯-赛德尔（SGS）**\nSGS由一次前向字典序扫描和一次后向字典序扫描组成。我们推导每次扫描的放大因子并将它们相乘。\n\n**前向字典序扫描：** 更新按 $i$ 和 $j$ 的递增顺序进行。误差传播方程为：\n$$4e_{i,j}^{\\text{new}} - e_{i-1,j}^{\\text{new}} - e_{i,j-1}^{\\text{new}} - e_{i+1,j}^{\\text{old}} - e_{i,j+1}^{\\text{old}} = 0.$$\n$$4e_{i,j}^{\\text{new}} - e_{i-1,j}^{\\text{new}} - e_{i,j-1}^{\\text{new}} = e_{i+1,j}^{\\text{old}} + e_{i,j+1}^{\\text{old}}.$$\n设 $e^{\\text{old}} = \\varphi_{\\boldsymbol{\\theta}}(i,j) = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$ 且 $e^{\\text{new}} = \\lambda_{\\text{fwd}}(\\boldsymbol{\\theta}) \\varphi_{\\boldsymbol{\\theta}}(i,j)$。代入方程得到：\n$$\\lambda_{\\text{fwd}}(\\boldsymbol{\\theta})\\left(4 - \\exp(-\\mathrm{i}\\theta_x) - \\exp(-\\mathrm{i}\\theta_y)\\right)\\varphi_{\\boldsymbol{\\theta}}(i,j) = \\left(\\exp(\\mathrm{i}\\theta_x) + \\exp(\\mathrm{i}\\theta_y)\\right)\\varphi_{\\boldsymbol{\\theta}}(i,j).$$\n前向扫描的放大因子为：\n$$\\lambda_{\\text{fwd}}(\\boldsymbol{\\theta}) = \\frac{\\exp(\\mathrm{i}\\theta_x) + \\exp(\\mathrm{i}\\theta_y)}{4 - \\exp(-\\mathrm{i}\\theta_x) - \\exp(-\\mathrm{i}\\theta_y)}.$$\n对于棋盘格模式 $\\boldsymbol{\\theta} = (\\pi, \\pi)$，我们有 $\\exp(\\mathrm{i}\\pi) = -1$ 和 $\\exp(-\\mathrm{i}\\pi) = -1$：\n$$\\lambda_{\\text{fwd}}(\\pi, \\pi) = \\frac{-1 + (-1)}{4 - (-1) - (-1)} = \\frac{-2}{6} = -\\frac{1}{3}.$$\n\n**后向字典序扫描：** 更新按 $i$ 和 $j$ 的递减顺序进行。误差传播方程为：\n$$4e_{i,j}^{\\text{new}} - e_{i+1,j}^{\\text{new}} - e_{i,j+1}^{\\text{new}} = e_{i-1,j}^{\\text{old}} + e_{i,j-1}^{\\text{old}}.$$\n代入 $e^{\\text{old}} = \\varphi_{\\boldsymbol{\\theta}}$ 和 $e^{\\text{new}} = \\lambda_{\\text{bwd}}(\\boldsymbol{\\theta}) \\varphi_{\\boldsymbol{\\theta}}$：\n$$\\lambda_{\\text{bwd}}(\\boldsymbol{\\theta})\\left(4 - \\exp(\\mathrm{i}\\theta_x) - \\exp(\\mathrm{i}\\theta_y)\\right)\\varphi_{\\boldsymbol{\\theta}}(i,j) = \\left(\\exp(-\\mathrm{i}\\theta_x) + \\exp(-\\mathrm{i}\\theta_y)\\right)\\varphi_{\\boldsymbol{\\theta}}(i,j).$$\n后向扫描的放大因子为：\n$$\\lambda_{\\text{bwd}}(\\boldsymbol{\\theta}) = \\frac{\\exp(-\\mathrm{i}\\theta_x) + \\exp(-\\mathrm{i}\\theta_y)}{4 - \\exp(\\mathrm{i}\\theta_x) - \\exp(\\mathrm{i}\\theta_y)}.$$\n对于棋盘格模式 $\\boldsymbol{\\theta} = (\\pi, \\pi)$：\n$$\\lambda_{\\text{bwd}}(\\pi, \\pi) = \\frac{-1 + (-1)}{4 - (-1) - (-1)} = \\frac{-2}{6} = -\\frac{1}{3}.$$\n\n**SGS放大因子：** 一次SGS扫描的总放大因子是前向和后向因子的乘积：\n$$\\lambda_{\\text{SGS}}(\\pi, \\pi) = \\lambda_{\\text{fwd}}(\\pi, \\pi) \\cdot \\lambda_{\\text{bwd}}(\\pi, \\pi) = \\left(-\\frac{1}{3}\\right)\\left(-\\frac{1}{3}\\right) = \\frac{1}{9}.$$\n阻尼因子是该值的模：$|\\lambda_{\\text{SGS}}(\\pi, \\pi)| = \\frac{1}{9}$。\n\n**2. 红黑高斯-赛德尔（RBGS）**\n在RBGS中，网格点被划分为两组：红点（$i+j$ 为偶数）和黑点（$i+j$ 为奇数）。平滑过程分两个半扫描进行：首先，使用相邻黑点的值同时更新所有红点；其次，使用新计算的红点值更新所有黑点。\n\n我们分析一次完整的RBGS扫描对一个纯粹是棋盘格模式的初始误差 $e^{\\text{old}}(i,j) = \\varphi_{(\\pi,\\pi)}(i,j) = (-1)^{i+j}$ 的影响。\n对于此模式：\n- 在红点上（$i+j$ 为偶数），$e^{\\text{old}}(i,j) = 1$。\n- 在黑点上（$i+j$ 为奇数），$e^{\\text{old}}(i,j) = -1$。\n\n**第一个半扫描（红点更新）：** 设 $e^{\\text{int}}$ 为此阶段后的误差。对于任意红点 $(i,j)$，误差传播方程为：\n$$4e^{\\text{int}}_{i,j} = e^{\\text{old}}_{i+1,j} + e^{\\text{old}}_{i-1,j} + e^{\\text{old}}_{i,j+1} + e^{\\text{old}}_{i,j-1}.$$\n红点的邻居都是黑点。因此，所有四个邻居处的 $e^{\\text{old}}$ 值均为 $-1$。\n$$4e^{\\text{int}}_{i,j} = (-1) + (-1) + (-1) + (-1) = -4.$$\n因此，对于所有红点，$e^{\\text{int}}_{i,j} = -1$。\n在此半扫描中黑点不被更新，所以对于任意黑点 $(i,j)$，$e^{\\text{int}}_{i,j} = e^{\\text{old}}_{i,j} = -1$。\n红点更新后，网格上所有点 $(i,j)$ 的误差为 $e^{\\text{int}}(i,j) = -1$。用傅里叶模式表示，初始的棋盘格模式 $\\varphi_{(\\pi,\\pi)}$ 已被转换为 $-\\varphi_{(0,0)}$，即零频率模式的负值。\n\n**第二个半扫描（黑点更新）：** 设 $e^{\\text{new}}$ 为最终误差。此次扫描的输入是所有 $(i,j)$ 处的 $e^{\\text{int}}(i,j) = -1$。对于任意黑点 $(i,j)$，更新为：\n$$4e^{\\text{new}}_{i,j} = e^{\\text{int}}_{i+1,j} + e^{\\text{int}}_{i-1,j} + e^{\\text{int}}_{i,j+1} + e^{\\text{int}}_{i,j-1}.$$\n黑点的邻居都是红点。所有四个邻居处的 $e^{\\text{int}}$ 值均为 $-1$。\n$$4e^{\\text{new}}_{i,j} = (-1) + (-1) + (-1) + (-1) = -4.$$\n因此，对于所有黑点，$e^{\\text{new}}_{i,j} = -1$。\n在此半扫描中红点不被更新，所以对于任意红点 $(i,j)$，$e^{\\text{new}}_{i,j} = e^{\\text{int}}_{i,j} = -1$。\n一次完整的RBGS扫描后的最终误差是所有点 $(i,j)$ 处的 $e^{\\text{new}}(i,j) = -1$。\n\n**RBGS阻尼因子：** 最终误差状态是 $e^{\\text{new}} = -\\varphi_{(0,0)}$。我们在包含原始模式 $\\varphi_{(\\pi,\\pi)}$ 和它被转换成的模式 $\\varphi_{(0,0)}$ 的傅里叶基中表示它：\n$$e^{\\text{new}} = (-1) \\cdot \\varphi_{(0,0)} + (0) \\cdot \\varphi_{(\\pi,\\pi)}.$$\n乘以棋盘格模式 $\\varphi_{(\\pi,\\pi)}$ 的系数是 $0$。问题将阻尼因子定义为该系数的模。因此，RBGS下棋盘格模式的阻尼因子是 $|0| = 0$。这表明RBGS在单次扫描中完全消除了棋盘格误差分量，将其能量转移到了零频率模式。\n\n**结果总结：**\n- 使用SGS时，棋盘格模式的阻尼因子为 $\\frac{1}{9}$。\n- 使用RBGS时，棋盘格模式的阻尼因子为 $0$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{9} & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "现实世界中的工程问题往往比简单的泊松方程更复杂，例如当材料属性导致各向异性时。本练习将挑战您解决一个各向异性扩散问题 $\\epsilon u_{xx} + u_{yy} = f$，在这种 $\\epsilon \\ll 1$ 的情况下，标准的多重网格方法可能会失效。通过实现一种仅在强耦合方向进行粗化的半粗化策略，并结合使用线松弛平滑器，您将学习到如何根据问题的物理特性定制多重网格组件，这是将多重网格方法应用于复杂工程计算的关键一步。",
            "id": "3235031",
            "problem": "实现一个完整、可运行的程序，为各向异性二维偏微分方程 (PDE)\n$$\n\\epsilon\\, u_{xx} + u_{yy} = f \\quad \\text{on} \\quad \\Omega = [0,1]\\times[0,1],\n$$\n构建一个仅在 $y$ 方向进行半粗化的几何多重网格 (MG) 求解器，该方程在 $\\partial \\Omega$ 上具有齐次狄利克雷边界条件 $u=0$，其中 $\\epsilon \\ll 1$。程序必须遵守以下规范。\n\n基本基础与离散化：\n- 使用均匀的张量积网格，在 $x$ 方向有 $N_x$ 个点，在 $y$ 方向有 $N_y$ 个点，包括位于 $x=0$、$x=1$、$y=0$ 和 $y=1$ 的边界。令 $h_x = 1/(N_x-1)$ 和 $h_y = 1/(N_y-1)$。\n- 使用标准的二阶中心差分来离散化该偏微分方程。将 $A$ 表示为完整网格上的离散算子（边界值固定为 $0$，未知数位于内部）。\n- 在所有边界网格点上使用齐次狄利克雷边界条件 $u=0$。\n\n$y$ 方向半粗化的几何多重网格：\n- 仅在 $y$ 方向执行半粗化，保持 $x$ 方向的网格在所有层级上不变。如果一个细网格层有 $N_y$ 个点，下一个更粗的网格层必须有 $N_y^{(c)} = (N_y+1)/2$ 个点（假设 $N_y-1$ 可被 $2$ 整除，因此 $N_y^{(c)}$ 是一个整数）。\n- 仅在 $y$ 方向使用全加权限制（在 $x$ 方向为复制）。对于内部索引，这对应于沿 $y$ 方向以权重 $1/4$、$1/2$、$1/4$ 对细网格残差进行平均，并在边界注入零。\n- 仅在 $y$ 方向使用线性插值（延长）（在 $x$ 方向为复制）。粗网格值被注入到细网格的偶数索引 $y$ 位置；细网格的奇数索引 $y$ 位置通过对相邻粗网格值进行线性插值获得。\n- 在每个网格层级上，使用该层级对应的 $h_x$ 和 $h_y$ 值，采用相同的二阶模板重新离散化算子 $A$。\n\n光滑子：\n- 使用 $y$ 方向的线松弛光滑子。也就是说，对于每个固定的内部 $x$ 索引，通过隐式处理 $y$ 方向耦合、显式处理 $x$ 方向耦合，精确求解所得到的三对角系统。将其实现为跨 $x$ 线的块高斯-赛德尔方法，包含前向和后向扫描。\n\n最粗层求解：\n- 在 $y$ 方向的最粗层上，使用迭代方法近似求解 $A u = f$。你必须使用算子 $A$ 的应用和内部未知数的标准内积来实现共轭梯度 (CG) 方法。当相对残差范数低于 $10^{-12}$ 或达到最大迭代次数 $200$ 次时停止。不允许使用指定之外的任何外部库。\n\n人工构造的右端项：\n- 使用人工构造解 $u_{\\text{true}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$，使得\n$$\nf(x,y) = -\\pi^2\\left(\\epsilon + 1\\right)\\sin(\\pi x)\\sin(\\pi y).\n$$\n在所有内部网格点上计算 $f$ 的值；将 $f$ 的边界值设为 $0$。这确保了精确解满足在 $\\partial \\Omega$ 上的边界条件 $u=0$。\n\n算法任务：\n- 从零初始猜测开始，执行指定数量的 V 循环，每个层级进行 $\\nu_1$ 次前平滑和 $\\nu_2$ 次后平滑的线松弛扫描，其中每次线松弛扫描包含一次 $x$ 方向的前向和后向过程。使用 $\\nu_1=\\nu_2=1$。\n- 对于每个测试的参数集，报告最终残差 2-范数与初始残差 2-范数之比，其中残差为 $r = f - A u$。2-范数是内部网格点上的未加权欧几里得范数。\n\n测试套件：\n- 你的程序必须运行以下四个测试用例，并以十进制浮点数形式生成四个相应的残差缩减因子。\n    1. $N_x=65$, $N_y=65$, $\\epsilon=10^{-3}$, $V$-循环次数 $=6$。\n    2. $N_x=65$, $N_y=33$, $\\epsilon=10^{-6}$, $V$-循环次数 $=8$。\n    3. $N_x=33$, $N_y=65$, $\\epsilon=1$, $V$-循环次数 $=4$。\n    4. $N_x=65$, $N_y=9$, $\\epsilon=10^{-4}$, $V$-循环次数 $=5$。\n- 在每个层级上，当 $N_y \\le 5$ 时定义为最粗层，此时切换到 CG 粗网格求解。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含四个结果，格式为方括号内以逗号分隔的列表（例如 $[r_1,r_2,r_3,r_4]$），其中每个 $r_k$ 是对应测试用例计算出的残差缩减因子。\n- 没有物理单位，所有角度（如果有）均以弧度为单位。所有数值答案必须是十进制浮点数。\n\n你的实现必须是自包含的，并且能在指定环境下直接运行。不允许用户输入。目标是从基本原理出发，展示在 $y$ 方向进行半粗化并结合 $y$ 方向线松弛如何在 $\\epsilon \\ll 1$ 时解决各向异性问题，同时对一般的 $\\epsilon$ 保持鲁棒性。",
            "solution": "用户提供的问题是偏微分方程数值方法领域一个有效、适定且具有指导意义的练习。它要求实现一个针对各向异性扩散方程定制的几何多重网格 (MG) 求解器。所指定的组件——半粗化、线松弛和共轭梯度粗网格求解器——都是标准技术，它们的组合为设计用于解决挑战性问题的高效求解器提供了见解。我们将从基本原理出发来开发解决方案。\n\n该问题围绕具有齐次狄利克雷边界条件的二维各向异性泊松方程的数值求解展开：\n$$\n\\epsilon\\, u_{xx} + u_{yy} = f(x,y) \\quad \\text{on} \\quad \\Omega = [0,1]\\times[0,1]\n$$\n$$\nu(x,y) = 0 \\quad \\text{on} \\quad \\partial \\Omega\n$$\n参数 $\\epsilon$ 控制各向异性。当 $\\epsilon \\ll 1$ 时，$x$ 方向的扩散明显弱于 $y$ 方向。\n\n该解决方案通过实现一个完整的几何多重网格 V 循环来构建。核心组件详述如下。\n\n**1. 离散化与网格层次结构**\n\n我们使用一个在 $x$ 和 $y$ 方向上分别有 $N_x$ 和 $N_y$ 个点的均匀张量积网格来离散化域 $\\Omega$。网格间距为 $h_x = 1/(N_x-1)$ 和 $h_y = 1/(N_y-1)$。对内部网格点 $(x_i, y_j)$ 处的偏导数使用二阶中心差分，我们得到离散方程：\n$$\n\\epsilon \\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h_x^2} + \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h_y^2} = f_{i,j}\n$$\n这可以写成一个线性系统 $A u = f$，其中 $A$ 是离散算子。该方程表明，当 $\\epsilon \\ll 1$ 时，网格点之间在 $y$ 方向的耦合更强，因为系数 $1/h_y^2$ 远大于 $\\epsilon/h_x^2$（假设 $h_x \\approx h_y$）。\n\n多重网格方法在一系列层次化的网格上运行。该问题指定了在 $y$ 方向进行半粗化。从一个维度为 $(N_x, N_y^{(l)})$ 的细网格（层级 $l$）开始，下一个更粗的网格（层级 $l+1$）的维度为 $(N_x, N_y^{(l+1)})$，其中 $N_y^{(l+1)} = (N_y^{(l)}+1)/2$。$x$ 方向的网格点数在所有层级上保持不变。重复此过程，直到 $y$ 方向的网格变得足够小（这里是 $N_y \\le 5$），这就定义了最粗层。在每个层级上，使用相应的网格间距 $h_y$ 重新离散化算子 $A$。\n\n**2. 光滑子：线松弛**\n\n像 Gauss-Seidel 这样的标准逐点光滑子对于各向异性问题是低效的，因为它们无法在强耦合方向上快速传播信息。对于我们这个沿 $y$ 线耦合很强的问题，我们使用 $y$ 线松弛光滑子。对于每个固定的 $x$ 索引 $i$，我们将所有未知数 $u_{i,j}$（其中 $j=1, \\dots, N_y-2$）视为一个单独的块。该块的离散方程构成一个三对角系统：\n$$\n\\frac{1}{h_y^2} u_{i,j-1} - 2\\left(\\frac{\\epsilon}{h_x^2} + \\frac{1}{h_y^2}\\right) u_{i,j} + \\frac{1}{h_y^2} u_{i,j+1} = f_{i,j} - \\frac{\\epsilon}{h_x^2} \\left(u_{i-1,j} + u_{i+1,j}\\right)\n$$\n这个关于未知向量 $(u_{i,1}, \\dots, u_{i,N_y-2})^T$ 的三对角系统可以使用 Thomas 算法精确求解。一次完整的平滑扫描包括一次前向过程（$i$ 从 $1$ 迭代到 $N_x-2$）和一次后向过程（$i$ 从 $N_x-2$ 迭代到 $1$），这构成了一个对称块 Gauss-Seidel 方法。这种光滑子能有效衰减沿 $y$ 方向的高频误差分量。\n\n**3. 网格间传递算子：限制与延长**\n\n多重网格的有效性依赖于在细网格和粗网格之间传递信息。\n**限制算子 ($R$)** 将细网格的残差 $r^f$ 传递到粗网格的右端项 $r^c$。由于仅在 $y$ 方向进行粗化，我们在 $y$ 方向使用全加权，在 $x$ 方向使用恒等（复制）操作。对于一个内部粗网格点 $(i, J)$，残差计算如下：\n$$\nr^c_{i,J} = \\frac{1}{4} r^f_{i, 2J-1} + \\frac{1}{2} r^f_{i, 2J} + \\frac{1}{4} r^f_{i, 2J+1}\n$$\n**延长算子 ($P$)** 将粗网格的校正量 $e^c$ 插值到细网格。这也仅在 $y$ 方向进行。对于一个细网格点 $(i, j)$：\n- 如果 $j$ 是偶数（即 $j=2J$），则直接注入值：$e^f_{i, 2J} = e^c_{i, J}$。\n- 如果 $j$ 是奇数（即 $j=2J-1$），则通过线性插值得到值：$e^f_{i, 2J-1} = \\frac{1}{2}(e^c_{i, J-1} + e^c_{i, J})$。\n齐次狄利克雷条件意味着校正量在边界上为零，这在边界附近进行插值时会用到。\n\n在 $y$ 方向进行粗化的选择与 $y$ 线光滑子是协同作用的。光滑子使误差在 $y$ 方向变得平滑，因此其在更粗的 $y$ 网格上的表示是准确的。可能残留在 $x$ 方向的高频误差分量不受粗化影响，可以在所有网格层级上进行处理。\n\n**4. 最粗网格求解器**\n\n在最粗的网格上，必须求解系统 $A_c u_c = f_c$。由于该网格很小，直接求解是可行的，但问题指定了使用迭代求解器。我们实现共轭梯度 (CG) 方法。CG 是求解对称正定系统的有效方法，而 $A_c$ 正是这样的系统。从初始猜测 $u_0 = 0$ 开始，该算法迭代地改进解。当相对残差范数 $\\|f_c - A_c u_k\\|_2 / \\|f_c\\|_2$ 低于容差 $10^{-12}$ 或达到最大迭代次数 $200$ 次时，迭代停止。\n\n**5. V 循环算法**\n\n这些组件由 V 循环算法协调。对于给定的层级 $l$ 和问题 $A_l u_l = f_l$：\n1.  **前平滑**：对 $u_l$ 的当前近似解应用线松弛光滑子 $\\nu_1$ 次。\n2.  **计算残差**：计算残差 $r_l = f_l - A_l u_l$。\n3.  **限制**：将残差传递到下一个更粗的网格：$r_{l+1} = R r_l$。\n4.  **粗网格校正**：在粗网格上求解残差方程 $A_{l+1}e_{l+1} = r_{l+1}$。如果层级 $l+1$ 是最粗层，则使用 CG 求解器。否则，以初始猜测 $e_{l+1}=0$ 对此问题递归调用 V 循环。\n5.  **延长**：将计算出的校正量 $e_{l+1}$ 插值回细网格：$e_l = P e_{l+1}$。\n6.  **校正**：更新解：$u_l \\leftarrow u_l + e_l$。\n7.  **后平滑**：对校正后的近似解应用光滑子 $\\nu_2$ 次。\n\n此循环从最细网格上的初始猜测 $u=0$ 开始，重复指定的次数。最终结果是最终残差范数与初始残差范数之比，该比值量化了求解器实现的误差总体缩减程度。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass SemiCoarseningMGSolver:\n    \"\"\"\n    Geometric Multigrid Solver with y-direction semi-coarsening and line relaxation.\n    \"\"\"\n    def __init__(self, Nx, Ny, epsilon, num_v_cycles, nu1=1, nu2=1):\n        self.Nx = Nx\n        self.Ny = Ny\n        self.epsilon = epsilon\n        self.num_v_cycles = num_v_cycles\n        self.nu1 = nu1\n        self.nu2 = nu2\n        self.grids = self._setup_grids(Nx, Ny, epsilon)\n\n    def _setup_grids(self, Nx, Ny, epsilon):\n        grids = []\n        current_Ny = Ny\n        while current_Ny > 5:\n            grids.append({\n                'Nx': Nx,\n                'Ny': current_Ny,\n                'hx': 1.0 / (Nx - 1),\n                'hy': 1.0 / (current_Ny - 1),\n                'epsilon': epsilon\n            })\n            current_Ny = (current_Ny + 1) // 2\n        \n        grids.append({\n            'Nx': Nx,\n            'Ny': current_Ny,\n            'hx': 1.0 / (Nx - 1),\n            'hy': 1.0 / (current_Ny - 1),\n            'epsilon': epsilon\n        })\n        return grids\n\n    def _apply_A(self, u, level):\n        grid = self.grids[level]\n        Nx, Ny = grid['Nx'], grid['Ny']\n        hx, hy = grid['hx'], grid['hy']\n        eps = grid['epsilon']\n        \n        Au = np.zeros((Ny, Nx))\n        \n        eps_h_x2 = eps / (hx * hx)\n        inv_h_y2 = 1.0 / (hy * hy)\n        \n        center_coeff = -2.0 * (eps_h_x2 + inv_h_y2)\n        \n        # Sliced operation for performance\n        u_int = u[1:-1, 1:-1]\n        u_left = u[1:-1, :-2]\n        u_right = u[1:-1, 2:]\n        u_up = u[:-2, 1:-1]\n        u_down = u[2:, 1:-1]\n\n        Au_int = (eps_h_x2 * (u_left + u_right) +\n                  inv_h_y2 * (u_up + u_down) +\n                  center_coeff * u_int)\n        \n        Au[1:-1, 1:-1] = Au_int\n        return Au\n\n    def _restrict(self, r_fine, level):\n        fine_grid = self.grids[level]\n        coarse_grid = self.grids[level + 1]\n        Nx, Ny_c = coarse_grid['Nx'], coarse_grid['Ny']\n        \n        r_coarse = np.zeros((Ny_c, Nx))\n\n        # Vectorized restriction\n        r_coarse[1:-1, 1:-1] = (0.25 * r_fine[1:-2:2, 1:-1] + \n                                0.5 * r_fine[2:-1:2, 1:-1] + \n                                0.25 * r_fine[3::2, 1:-1])\n        return r_coarse\n\n    def _prolong(self, e_coarse, level):\n        coarse_grid = self.grids[level + 1]\n        fine_grid = self.grids[level]\n        Nx, Ny_f = fine_grid['Nx'], fine_grid['Ny']\n        \n        e_fine = np.zeros((Ny_f, Nx))\n        \n        # Vectorized prolongation\n        # Injection to even rows\n        e_fine[2:-1:2, 1:-1] = e_coarse[1:-1, 1:-1]\n        # Interpolation to odd rows\n        e_fine[1:-1:2, 1:-1] = 0.5 * (e_coarse[:-1, 1:-1] + e_coarse[1:, 1:-1])\n\n        return e_fine\n    \n    def _solve_tridiag(self, a, b, c, d):\n        n = len(d)\n        c_p = np.zeros(n)\n        d_p = np.zeros(n)\n        \n        c_p[0] = c[0] / b[0]\n        d_p[0] = d[0] / b[0]\n        \n        for i in range(1, n):\n            m = b[i] - a[i] * c_p[i-1]\n            c_p[i] = c[i] / m\n            d_p[i] = (d[i] - a[i] * d_p[i-1]) / m\n            \n        x = np.zeros(n)\n        x[-1] = d_p[-1]\n        \n        for i in range(n - 2, -1, -1):\n            x[i] = d_p[i] - c_p[i] * x[i+1]\n            \n        return x\n\n    def _line_relax_sweep(self, u, f, level):\n        grid = self.grids[level]\n        Nx, Ny = grid['Nx'], grid['Ny']\n        hx, hy = grid['hx'], grid['hy']\n        eps = grid['epsilon']\n        \n        u_new = u.copy()\n        \n        # Tridiagonal system setup (constant for all lines)\n        m = Ny - 2\n        diag_val = -2.0 * (eps / (hx * hx) + 1.0 / (hy * hy))\n        off_diag_val = 1.0 / (hy * hy)\n        \n        b = np.full(m, diag_val)\n        a = np.full(m, off_diag_val)\n        c = np.full(m, off_diag_val)\n\n        # Forward sweep\n        for i in range(1, Nx - 1):\n            rhs = f[1:-1, i] - (eps / (hx * hx)) * (u_new[1:-1, i - 1] + u[1:-1, i + 1])\n            u_new[1:-1, i] = self._solve_tridiag(a, b, c, rhs)\n        \n        u = u_new.copy()\n\n        # Backward sweep\n        for i in range(Nx - 2, 0, -1):\n            rhs = f[1:-1, i] - (eps / (hx * hx)) * (u[1:-1, i - 1] + u_new[1:-1, i + 1])\n            u_new[1:-1, i] = self._solve_tridiag(a, b, c, rhs)\n            \n        return u_new\n    \n    def _smoother(self, u, f, level, nu):\n        for _ in range(nu):\n            u = self._line_relax_sweep(u, f, level)\n        return u\n\n    def _dot(self, v1, v2):\n        return np.sum(v1[1:-1, 1:-1] * v2[1:-1, 1:-1])\n\n    def _cg_solve(self, f, level):\n        grid = self.grids[level]\n        u = np.zeros((grid['Ny'], grid['Nx']))\n        r = f.copy()\n        p = r.copy()\n        rs_old = self._dot(r, r)\n        norm_f = np.sqrt(self._dot(f,f))\n        \n        if norm_f == 0.0:\n            return u\n\n        for _ in range(200):\n            Ap = self._apply_A(p, level)\n            alpha = rs_old / self._dot(p, Ap)\n            u += alpha * p\n            r -= alpha * Ap\n            rs_new = self._dot(r, r)\n            if np.sqrt(rs_new) / norm_f  1e-12:\n                break\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n        return u\n\n    def _v_cycle(self, u, f, level):\n        if level == len(self.grids) - 1:\n            return self._cg_solve(f, level)\n        \n        u = self._smoother(u, f, level, self.nu1)\n        \n        r = f - self._apply_A(u, level)\n        \n        r_coarse = self._restrict(r, level)\n        \n        e_coarse_guess = np.zeros((self.grids[level+1]['Ny'], self.grids[level+1]['Nx']))\n        e_coarse = self._v_cycle(e_coarse_guess, r_coarse, level + 1)\n        \n        e_fine = self._prolong(e_coarse, level)\n        \n        u += e_fine\n        \n        u = self._smoother(u, f, level, self.nu2)\n        \n        return u\n\n    def solve(self):\n        # Setup manufactured solution\n        Nx, Ny, eps = self.Nx, self.Ny, self.epsilon\n        x = np.linspace(0, 1, Nx)\n        y = np.linspace(0, 1, Ny)\n        xx, yy = np.meshgrid(x, y)\n        \n        u_true = np.sin(np.pi * xx) * np.sin(np.pi * yy)\n        f = -np.pi**2 * (eps + 1) * u_true\n        \n        u = np.zeros((Ny, Nx))\n        \n        initial_residual_norm = np.sqrt(self._dot(f, f))\n        \n        if initial_residual_norm == 0:\n            return 0.0\n\n        for _ in range(self.num_v_cycles):\n            u = self._v_cycle(u, f, 0)\n            \n        final_residual = f - self._apply_A(u, 0)\n        final_residual_norm = np.sqrt(self._dot(final_residual, final_residual))\n        \n        return final_residual_norm / initial_residual_norm\n\n\ndef solve():\n    test_cases = [\n        (65, 65, 1e-3, 6),\n        (65, 33, 1e-6, 8),\n        (33, 65, 1.0, 4),\n        (65, 9, 1e-4, 5)\n    ]\n    \n    results = []\n    for Nx, Ny, epsilon, num_cycles in test_cases:\n        solver = SemiCoarseningMGSolver(Nx=Nx, Ny=Ny, epsilon=epsilon, num_v_cycles=num_cycles)\n        ratio = solver.solve()\n        results.append(ratio)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}