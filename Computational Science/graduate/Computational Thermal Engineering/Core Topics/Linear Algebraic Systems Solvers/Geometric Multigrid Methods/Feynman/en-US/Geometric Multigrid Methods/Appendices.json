{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the mechanics of the multigrid method, it's invaluable to perform a cycle by hand. This exercise  guides you through a single V-cycle for a simple one-dimensional problem, allowing you to manually trace the error and residual as they are smoothed, restricted, corrected, and prolongated. This hands-on calculation demystifies the abstract concepts and builds a concrete foundation for understanding why multigrid is so effective.",
            "id": "3235102",
            "problem": "Consider the one-dimensional Poisson equation $-u''(x) = f(x)$ on the interval $(0,1)$ with homogeneous Dirichlet boundary conditions $u(0) = u(1) = 0$. Discretize using the standard second-order centered finite difference method on a finest grid with $N=15$ interior points, so that the grid spacing is $h = \\frac{1}{N+1} = \\frac{1}{16}$. Let the discrete operator on the finest grid be $A_h = \\frac{1}{h^2} T$, where $T \\in \\mathbb{R}^{15 \\times 15}$ is the tridiagonal matrix with $2$ on the diagonal and $-1$ on the first sub- and super-diagonals.\n\nPerform one two-grid V-cycle with the following components:\n- Pre-smoothing: one sweep of weighted Jacobi with weight $\\omega = \\frac{2}{3}$.\n- Restriction: full-weighting restriction $R$ from the $15$-point grid to the $7$-point coarse grid (i.e., $(R r)_j = \\frac{1}{4}\\big(r_{2j-1} + 2 r_{2j} + r_{2j+1}\\big)$ for $j=1,\\dots,7$).\n- Coarse-grid operator: Galerkin choice $A_{2h} = R A_h P$, where $P$ is linear interpolation from the $7$-point grid to the $15$-point grid (values injected at even-indexed fine points and linearly interpolated at odd-indexed fine points).\n- Coarse solve: exact solution of the coarse-grid system.\n- Prolongation: linear interpolation $P$ as above.\n- Post-smoothing: one sweep of weighted Jacobi with weight $\\omega = \\frac{2}{3}$.\n\nAssume the right-hand side is zero, $f \\equiv 0$, so the exact solution is $u \\equiv 0$. Take the initial guess on the finest grid to be the Kronecker delta at the middle interior point: $u^{(0)}_i = \\delta_{i,8}$ for $i=1,\\dots,15$. Equivalently, the initial error is $e^{(0)} = u^{(0)}$.\n\nCompute explicitly, by hand, the following at each stage of the V-cycle on the finest grid:\n- The pre-smoothed error $e^{(1)}$ and the corresponding fine-grid residual $r^{(1)} = -A_h e^{(1)}$.\n- The restricted coarse residual $r_{2h} = R r^{(1)}$ and the exact coarse correction $d_{2h}$ solving $A_{2h} d_{2h} = r_{2h}$.\n- The fine-grid correction $P d_{2h}$ and the corrected error before post-smoothing $e^{(1,\\mathrm{cc})} = e^{(1)} + P d_{2h}$.\n- The post-smoothed error $e^{(V)}$ after one final weighted Jacobi sweep.\n\nWhen reporting residuals you may, to avoid clutter, ignore the common factor $\\frac{1}{h^2}$ and report the unscaled quantity $-T e$ in place of $-A_h e$. Finally, let $\\|\\cdot\\|_2$ denote the Euclidean norm on $\\mathbb{R}^{15}$. What is the exact value of the ratio $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$? Express your final answer as a simplified exact expression. No rounding is required.",
            "solution": "The problem requires a detailed, step-by-step computation of one two-grid V-cycle for the 1D Poisson equation. We will systematically compute the state of the error vector at each stage of the cycle.\n\n**Step 0: Initial State**\n\nThe problem is discretized on a fine grid with $N=15$ interior points. The grid spacing is $h = \\frac{1}{16}$. Let $e^{(0)}$ be the initial error vector in $\\mathbb{R}^{15}$. The exact solution is $u \\equiv 0$, so the error is equal to the initial guess.\nThe initial guess is given as $u^{(0)}_i = \\delta_{i,8}$, where $\\delta_{i,j}$ is the Kronecker delta. Thus, the initial error vector $e^{(0)}$ is a standard basis vector:\n$$e^{(0)} = (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)^T \\equiv e_8$$\nThe Euclidean norm of the initial error is $\\|e^{(0)}\\|_2 = \\sqrt{1^2} = 1$.\n\n**Step 1: Pre-smoothing and Fine-Grid Residual**\n\nOne pre-smoothing step using weighted Jacobi with weight $\\omega = \\frac{2}{3}$ is applied to the initial error $e^{(0)}$. The error transformation is given by the iteration matrix $S = I - \\omega D_h^{-1} A_h$.\nThe fine-grid operator is $A_h = \\frac{1}{h^2} T$, where $T = \\text{tridiag}(-1, 2, -1)$ is the $15 \\times 15$ discrete Laplacian. The diagonal of $A_h$ is $D_h = \\frac{2}{h^2}I$.\nThe smoother matrix is therefore:\n$$S = I - \\frac{2}{3} \\left(\\frac{h^2}{2}I\\right) \\left(\\frac{1}{h^2}T\\right) = I - \\frac{1}{3}T$$\nThe pre-smoothed error, $e^{(1)}$, is:\n$$e^{(1)} = S e^{(0)} = \\left(I - \\frac{1}{3}T\\right) e_8 = e_8 - \\frac{1}{3} (T e_8)$$\nThe vector $T e_8$ corresponds to the 8th column of $T$, which is $(0, \\dots, -1, 2, -1, \\dots, 0)^T$ with non-zero entries at indices $i=7, 8, 9$.\n$$T e_8 = -e_7 + 2e_8 - e_9$$\nThus,\n$$e^{(1)} = e_8 - \\frac{1}{3}(-e_7 + 2e_8 - e_9) = \\frac{1}{3}e_7 + \\left(1-\\frac{2}{3}\\right)e_8 + \\frac{1}{3}e_9 = \\frac{1}{3}(e_7 + e_8 + e_9)$$\nSo, the pre-smoothed error is $e^{(1)} = (0, 0, 0, 0, 0, 0, \\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0, 0)^T$.\n\nNext, we compute the fine-grid residual $r^{(1)} = -A_h e^{(1)}$. As permitted by the problem statement, we will compute the unscaled residual $\\tilde{r}^{(1)} = -T e^{(1)}$.\n$$\\tilde{r}^{(1)} = -T \\left(\\frac{1}{3}(e_7 + e_8 + e_9)\\right) = -\\frac{1}{3}(T e_7 + T e_8 + T e_9)$$\nUsing $T e_i = -e_{i-1} + 2e_i - e_{i+1}$ (with $e_0=e_{16}=0$):\n\\begin{align*} T e_7 &= -e_6 + 2e_7 - e_8 \\\\ T e_8 &= -e_7 + 2e_8 - e_9 \\\\ T e_9 &= -e_8 + 2e_9 - e_{10} \\end{align*}\nSumming these gives:\n$$T(e_7+e_8+e_9) = -e_6 + (-1+2)e_7 + (-1+2-1)e_8 + (-1+2)e_9 - e_{10} = -e_6 + e_7 + e_9 - e_{10}$$\nTherefore, the unscaled residual is:\n$$\\tilde{r}^{(1)} = -\\frac{1}{3}(-e_6 + e_7 + e_9 - e_{10}) = \\frac{1}{3}(e_6 - e_7 - e_9 + e_{10})$$\nExplicitly, $\\tilde{r}^{(1)} = (0, 0, 0, 0, 0, \\frac{1}{3}, -\\frac{1}{3}, 0, -\\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0)^T$. The problem calls this $r^{(1)}$.\n\n**Step 2: Restriction and Coarse-Grid Solve**\n\nThe unscaled fine-grid residual $\\tilde{r}^{(1)}$ is restricted to the coarse grid (7 interior points) using the full-weighting operator $R$:\n$$(r_{2h})_j = (R \\tilde{r}^{(1)})_j = \\frac{1}{4}\\left(\\tilde{r}^{(1)}_{2j-1} + 2\\tilde{r}^{(1)}_{2j} + \\tilde{r}^{(1)}_{2j+1}\\right) \\quad \\text{for } j=1, \\dots, 7$$\nThe non-zero components of $\\tilde{r}^{(1)}$ are at indices $6, 7, 9, 10$.\n\\begin{align*} (r_{2h})_1 &= (R\\tilde{r}^{(1)})_1 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_2 &= (R\\tilde{r}^{(1)})_2 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_3 &= (R\\tilde{r}^{(1)})_3 = \\frac{1}{4}(\\tilde{r}^{(1)}_5 + 2\\tilde{r}^{(1)}_6 + \\tilde{r}^{(1)}_7) = \\frac{1}{4}\\left(0 + 2\\left(\\frac{1}{3}\\right) - \\frac{1}{3}\\right) = \\frac{1}{12} \\\\ (r_{2h})_4 &= (R\\tilde{r}^{(1)})_4 = \\frac{1}{4}(\\tilde{r}^{(1)}_7 + 2\\tilde{r}^{(1)}_8 + \\tilde{r}^{(1)}_9) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2(0) - \\frac{1}{3}\\right) = -\\frac{2}{12} = -\\frac{1}{6} \\\\ (r_{2h})_5 &= (R\\tilde{r}^{(1)})_5 = \\frac{1}{4}(\\tilde{r}^{(1)}_9 + 2\\tilde{r}^{(1)}_{10} + \\tilde{r}^{(1)}_{11}) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2\\left(\\frac{1}{3}\\right) + 0\\right) = \\frac{1}{12} \\\\ (r_{2h})_6 &= (R\\tilde{r}^{(1)})_6 = 0 \\\\ (r_{2h})_7 &= (R\\tilde{r}^{(1)})_7 = 0 \\end{align*}\nThe restricted coarse residual is $r_{2h} = (0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0)^T$.\n\nThe coarse-grid equation to be solved exactly is $A_{2h} d_{2h} = R r^{(1)}$, where $r^{(1)} = -A_h e^{(1)}$.\n$A_{2h} = R A_h P = R \\left(\\frac{1}{h^2} T\\right) P = \\frac{1}{h^2} RTP$.\n$R r^{(1)} = R \\left(-\\frac{1}{h^2} T e^{(1)}\\right) = \\frac{1}{h^2} R \\tilde{r}^{(1)} = \\frac{1}{h^2} r_{2h}$.\nThe coarse-grid equation is $(\\frac{1}{h^2} RTP) d_{2h} = \\frac{1}{h^2} r_{2h}$, which simplifies to $(RTP) d_{2h} = r_{2h}$.\nThe matrix $RTP$ is known to be $\\frac{1}{4}T_{2h}$, where $T_{2h}$ is the $7 \\times 7$ tridiagonal matrix $\\text{tridiag}(-1, 2, -1)$.\nSo, we solve $\\frac{1}{4} T_{2h} d_{2h} = r_{2h}$, or $T_{2h} d_{2h} = 4 r_{2h}$.\n$$T_{2h} d_{2h} = 4 \\left(0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0\\right)^T = \\left(0, 0, \\frac{1}{3}, -\\frac{2}{3}, \\frac{1}{3}, 0, 0\\right)^T$$\nLet $b_c$ be the right-hand side. We note that $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$ where $e_j$ are basis vectors in $\\mathbb{R}^7$.\nWe are solving $T_{2h} d_{2h} = b_c$. Let's test the ansatz $d_{2h} = c \\cdot e_4$ for some constant $c$.\n$$T_{2h} (c \\cdot e_4) = c(-e_3 + 2e_4 - e_5) = -c(e_3 - 2e_4 + e_5)$$\nComparing this to $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$, we see that $-c = \\frac{1}{3}$, so $c = -\\frac{1}{3}$.\nThe exact coarse-grid correction is $d_{2h} = -\\frac{1}{3}e_4 = (0, 0, 0, -\\frac{1}{3}, 0, 0, 0)^T$.\n\n**Step 3: Prolongation and Correction**\n\nThe coarse-grid correction $d_{2h}$ is prolongated back to the fine grid using linear interpolation $P$:\n$$d_h = P d_{2h} = P \\left(-\\frac{1}{3}e_4\\right) = -\\frac{1}{3} (P e_4)$$\nThe vector $P e_4$ is the 4th column of the prolongation matrix. It corresponds to interpolating from a coarse-grid vector that is $1$ at index $j=4$ and $0$ otherwise.\nThe value is injected at the corresponding fine-grid point $i=2j = 8$: $(P e_4)_8 = 1$.\nThe values at odd-indexed fine-grid points are interpolated:\n$(P e_4)_7 = \\frac{1}{2}((d_{2h})_3 + (d_{2h})_4) = \\frac{1}{2}(0+1) = \\frac{1}{2}$.\n$(P e_4)_9 = \\frac{1}{2}((d_{2h})_4 + (d_{2h})_5) = \\frac{1}{2}(1+0) = \\frac{1}{2}$.\nSo, $P e_4 = \\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9$.\nThe fine-grid correction is:\n$$d_h = -\\frac{1}{3}\\left(\\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9\\right) = -\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9$$\nExplicitly, $d_h = (0,0,0,0,0,0, -\\frac{1}{6}, -\\frac{1}{3}, -\\frac{1}{6}, 0,0,0,0,0,0)^T$. This quantity is $P d_{2h}$.\n\nThe corrected error before post-smoothing is $e^{(1,\\mathrm{cc})} = e^{(1)} + d_h$.\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}e_7 + \\frac{1}{3}e_8 + \\frac{1}{3}e_9\\right) + \\left(-\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9\\right)$$\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_7 + \\left(\\frac{1}{3}-\\frac{1}{3}\\right)e_8 + \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_9 = \\frac{1}{6}e_7 + \\frac{1}{6}e_9$$\nThe corrected error is $e^{(1,\\mathrm{cc})} = (0,0,0,0,0,0, \\frac{1}{6}, 0, \\frac{1}{6}, 0,0,0,0,0,0)^T$.\n\n**Step 4: Post-smoothing and Final Error**\n\nOne post-smoothing step (weighted Jacobi, $\\omega=2/3$) is applied to $e^{(1,\\mathrm{cc})}$. The final error after one V-cycle, $e^{(V)}$, is:\n$$e^{(V)} = S e^{(1,\\mathrm{cc})} = \\left(I - \\frac{1}{3}T\\right) e^{(1,\\mathrm{cc})} = e^{(1,\\mathrm{cc})} - \\frac{1}{3}T e^{(1,\\mathrm{cc})}$$\n$$e^{(1,\\mathrm{cc})} = \\frac{1}{6}(e_7+e_9)$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6} T(e_7+e_9) = \\frac{1}{6}((-e_6+2e_7-e_8) + (-e_8+2e_9-e_{10}))$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\nNow, we compute $e^{(V)}$:\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{3}\\left(\\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})\\right)$$\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{18}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\nCollecting terms for each basis vector:\n\\begin{align*} e_6: & \\quad \\frac{1}{18} \\\\ e_7: & \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{3}{18} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_8: & \\quad \\frac{2}{18} = \\frac{1}{9} \\\\ e_9: & \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_{10}:& \\quad \\frac{1}{18} \\end{align*}\nThe final error after one V-cycle is:\n$$e^{(V)} = \\frac{1}{18}e_6 + \\frac{1}{18}e_7 + \\frac{2}{18}e_8 + \\frac{1}{18}e_9 + \\frac{1}{18}e_{10} = \\frac{1}{18}(e_6 + e_7 + 2e_8 + e_9 + e_{10})$$\n\n**Step 5: Error Norm Ratio**\n\nFinally, we compute the ratio $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$.\nWe know $\\|e^{(0)}\\|_2 = 1$.\nThe squared norm of the final error is:\n$$\\|e^{(V)}\\|_2^2 = \\left(\\frac{1}{18}\\right)^2 (1^2 + 1^2 + 2^2 + 1^2 + 1^2) = \\frac{1}{18^2}(1+1+4+1+1) = \\frac{8}{18^2}$$\nThe norm is:\n$$\\|e^{(V)}\\|_2 = \\sqrt{\\frac{8}{18^2}} = \\frac{\\sqrt{8}}{18} = \\frac{2\\sqrt{2}}{18} = \\frac{\\sqrt{2}}{9}$$\nThe ratio of the final error norm to the initial error norm is:\n$$\\frac{\\|e^{(V)}\\|_2}{\\|e^{(0)}\\|_2} = \\frac{\\sqrt{2}/9}{1} = \\frac{\\sqrt{2}}{9}$$\nThis value represents the error reduction factor for this specific initial error after one V-cycle.",
            "answer": "$$\\boxed{\\frac{\\sqrt{2}}{9}}$$"
        },
        {
            "introduction": "A key to the efficiency of multigrid lies in the design of its smoother, which must effectively damp high-frequency error components. This practice  introduces Local Fourier Analysis (LFA), the standard theoretical tool for analyzing multigrid operators. By deriving the optimal relaxation parameter for a weighted Jacobi smoother, you will see how we can quantitatively design components to ensure rapid convergence.",
            "id": "3957406",
            "problem": "Consider steady-state heat conduction in a homogeneous, isotropic two-dimensional plate with constant thermal conductivity, governed by the partial differential equation $-\\nabla^{2} T = f$ on a square domain with Dirichlet boundary conditions. Discretize the Laplacian using the standard five-point second-order finite difference stencil on a uniform Cartesian grid with spacing $h$, obtaining a linear system $A T = b$ where $A$ is symmetric positive definite. In the context of Geometric Multigrid (GMG) with standard coarsening by a factor of two in each spatial direction and bilinear interpolation, use the Weighted Jacobi (WJ) method as a smoother with relaxation parameter $\\omega \\in (0,1)$.\n\nStarting from first principles for stationary iterative methods and the structure of the discrete operator, derive the error-propagation (iteration) matrix of the Weighted Jacobi method applied to this system. Then, perform a Local Fourier Analysis (LFA) by considering the infinite-grid model with periodic boundary conditions to obtain the symbol of the iteration matrix acting on Fourier modes. Define the high-frequency set as those Fourier modes that cannot be represented on the next coarser grid,\n$$\n\\mathcal{H} = \\left\\{ (\\theta_{x}, \\theta_{y}) \\in [-\\pi,\\pi]^{2} : |\\theta_{x}| \\in \\left[\\frac{\\pi}{2}, \\pi\\right] \\text{ and } |\\theta_{y}| \\in \\left[\\frac{\\pi}{2}, \\pi\\right] \\right\\},\n$$\nand let the smoothing factor be the supremum, over $(\\theta_{x}, \\theta_{y}) \\in \\mathcal{H}$, of the magnitude of the corresponding Fourier symbol of the error-propagation matrix. Determine the value of $\\omega$ that minimizes this smoothing factor for the constant-coefficient Laplacian in two dimensions. Express your final answer for $\\omega$ as a reduced fraction with no units.",
            "solution": "The problem asks for the optimal relaxation parameter $\\omega$ for a Weighted Jacobi (WJ) smoother used in a Geometric Multigrid (GMG) context for the 2D Poisson equation. The optimization is based on minimizing the smoothing factor, which is determined through Local Fourier Analysis (LFA).\n\nStep 1: Discretization and Weighted Jacobi Method\nThe governing equation is the steady-state heat equation, which is Poisson's equation:\n$$-\\nabla^{2} T = f$$\nDiscretizing the Laplacian operator $-\\nabla^2$ on a uniform Cartesian grid with spacing $h$ using the standard five-point finite difference stencil at a grid point $(i, j)$ gives the discrete operator $A$:\n$$ (A T)_{i,j} = \\frac{1}{h^2} (4 T_{i,j} - T_{i+1,j} - T_{i-1,j} - T_{i,j+1} - T_{i,j-1}) = f_{i,j} $$\nThis leads to a large, sparse, symmetric positive definite linear system $A T = b$.\n\nThe Weighted Jacobi (WJ) method is a stationary iterative method for solving $A T = b$. We decompose the matrix $A$ as $A = D - L - U$, where $D$ is the diagonal part of $A$, and $-L$ and $-U$ are the strictly lower and upper triangular parts, respectively. For the given five-point stencil, the diagonal matrix $D$ is a scalar multiple of the identity matrix: $D = \\frac{4}{h^2} I$.\n\nThe WJ iteration is given by:\n$$ T^{(k+1)} = T^{(k)} + \\omega D^{-1} (b - A T^{(k)}) $$\nwhere $k$ is the iteration index and $\\omega \\in (0,1)$ is the relaxation parameter. Let the error at iteration $k$ be $e^{(k)} = T - T^{(k)}$, where $T$ is the exact solution to $A T = b$. Subtracting the iteration equation from $T = T + \\omega D^{-1}(b-AT)$ gives the error propagation equation:\n$$ T - T^{(k+1)} = T - T^{(k)} - \\omega D^{-1} A (T - T^{(k)}) $$\n$$ e^{(k+1)} = e^{(k)} - \\omega D^{-1} A e^{(k)} = (I - \\omega D^{-1} A) e^{(k)} $$\nThe error propagation matrix (or iteration matrix) for the WJ method is therefore:\n$$ S_{WJ} = I - \\omega D^{-1} A $$\nSubstituting $D^{-1} = \\frac{h^2}{4} I$, we get:\n$$ S_{WJ} = I - \\omega \\frac{h^2}{4} A $$\n\nStep 2: Local Fourier Analysis (LFA)\nLFA analyzes the action of an operator on Fourier modes, which are the eigenfunctions of linear, constant-coefficient operators on an infinite grid. A 2D Fourier mode at grid location $\\mathbf{x}_{j,k} = (jh, kh)$ is given by $v(\\mathbf{x}_{j,k}) = \\exp(i(j\\theta_x + k\\theta_y))$, where $\\boldsymbol{\\theta} = (\\theta_x, \\theta_y)$ is the grid frequency vector with components in $[-\\pi, \\pi]$.\n\nFirst, we find the symbol $\\hat{A}(\\boldsymbol{\\theta})$ of the discrete operator $A$, which is its eigenvalue corresponding to the mode $\\boldsymbol{\\theta}$. Applying $A$ to the Fourier mode:\n$$ (A v)_{j,k} = \\frac{1}{h^2} [4v_{j,k} - v_{j+1,k} - v_{j-1,k} - v_{j,k+1} - v_{j,k-1}] $$\n$$ = \\frac{v_{j,k}}{h^2} [4 - e^{i\\theta_x} - e^{-i\\theta_x} - e^{i\\theta_y} - e^{-i\\theta_y}] $$\n$$ = \\frac{v_{j,k}}{h^2} [4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y)] $$\nUsing the half-angle identity $1 - \\cos(\\alpha) = 2\\sin^2(\\alpha/2)$:\n$$ (A v)_{j,k} = \\frac{v_{j,k}}{h^2} [4\\sin^2(\\theta_x/2) + 4\\sin^2(\\theta_y/2)] $$\nThus, the symbol of $A$ is:\n$$ \\hat{A}(\\theta_x, \\theta_y) = \\frac{4}{h^2} (\\sin^2(\\theta_x/2) + \\sin^2(\\theta_y/2)) $$\nThe symbol of the WJ error propagation matrix $S_{WJ}$ can be found from the symbols of its constituent operators:\n$$ \\hat{S}_{WJ}(\\theta_x, \\theta_y) = 1 - \\omega \\frac{h^2}{4} \\hat{A}(\\theta_x, \\theta_y) $$\n$$ \\hat{S}_{WJ}(\\theta_x, \\theta_y) = 1 - \\omega \\frac{h^2}{4} \\left[ \\frac{4}{h^2} (\\sin^2(\\theta_x/2) + \\sin^2(\\theta_y/2)) \\right] $$\n$$ \\hat{S}_{WJ}(\\theta_x, \\theta_y) = 1 - \\omega (\\sin^2(\\theta_x/2) + \\sin^2(\\theta_y/2)) $$\n\nStep 3: Minimizing the Smoothing Factor\nThe purpose of a smoother in multigrid is to damp high-frequency error components. The smoothing factor $\\mu$ measures the effectiveness of this damping. It is defined as the largest magnitude of the symbol $\\hat{S}_{WJ}$ over the set of high frequencies $\\mathcal{H}$.\n$$ \\mu(\\omega) = \\sup_{(\\theta_x, \\theta_y) \\in \\mathcal{H}} |\\hat{S}_{WJ}(\\theta_x, \\theta_y)| $$\nThe problem defines the high-frequency set as:\n$$ \\mathcal{H} = \\left\\{ (\\theta_{x}, \\theta_{y}) \\in [-\\pi,\\pi]^{2} : |\\theta_{x}| \\in \\left[\\frac{\\pi}{2}, \\pi\\right] \\text{ and } |\\theta_{y}| \\in \\left[\\frac{\\pi}{2}, \\pi\\right] \\right\\} $$\nLet $S_x = \\sin^2(\\theta_x/2)$ and $S_y = \\sin^2(\\theta_y/2)$. The symbol can be written as $\\hat{S}_{WJ} = 1 - \\omega(S_x + S_y)$.\nWe need to find the range of values for $S_x$ and $S_y$ when $(\\theta_x, \\theta_y) \\in \\mathcal{H}$.\nIf $|\\theta_x| \\in [\\frac{\\pi}{2}, \\pi]$, then $|\\theta_x/2| \\in [\\frac{\\pi}{4}, \\frac{\\pi}{2}]$. Since $\\sin(u)$ is non-negative and increasing for $u \\in [0, \\pi/2]$, $\\sin(|\\theta_x/2|)$ ranges from $\\sin(\\pi/4) = \\frac{\\sqrt{2}}{2}$ to $\\sin(\\pi/2) = 1$.\nTherefore, $S_x = \\sin^2(\\theta_x/2)$ ranges from $(\\frac{\\sqrt{2}}{2})^2 = \\frac{1}{2}$ to $1^2 = 1$.\nSimilarly, $S_y$ also ranges from $\\frac{1}{2}$ to $1$.\n\nLet $\\lambda(\\theta_x, \\theta_y) = S_x + S_y$. The range of $\\lambda$ for $(\\theta_x, \\theta_y) \\in \\mathcal{H}$ is from the minimum possible sum to the maximum possible sum:\n$$ \\lambda_{min} = \\frac{1}{2} + \\frac{1}{2} = 1 $$\n$$ \\lambda_{max} = 1 + 1 = 2 $$\nSo, for $(\\theta_x, \\theta_y) \\in \\mathcal{H}$, $\\lambda \\in [1, 2]$.\n\nThe smoothing factor is then:\n$$ \\mu(\\omega) = \\sup_{\\lambda \\in [1, 2]} |1 - \\omega\\lambda| $$\nThe function $g(\\lambda) = 1 - \\omega\\lambda$ is linear in $\\lambda$. For $\\omega > 0$, it is a decreasing function. The supremum of its absolute value over an interval $[a, b]$ is attained at one of the endpoints: $\\max(|g(a)|, |g(b)|)$.\nHere, $a=1$ and $b=2$, so:\n$$ \\mu(\\omega) = \\max(|1 - \\omega \\cdot 1|, |1 - \\omega \\cdot 2|) = \\max(|1-\\omega|, |1-2\\omega|) $$\nWe want to find the value of $\\omega \\in (0,1)$ that minimizes $\\mu(\\omega)$. The minimum of the maximum of two functions typically occurs where they are equal. Since we are in the range $\\omega \\in (0,1)$, the term $1-\\omega$ is always positive, so $|1-\\omega| = 1-\\omega$.\nWe set the magnitudes equal:\n$$ |1-\\omega| = |1-2\\omega| \\implies 1-\\omega = |1-2\\omega| $$\nWe consider two cases for the term $1-2\\omega$:\n1. If $1-2\\omega \\ge 0$ (i.e., $\\omega \\le 1/2$), the equation becomes $1-\\omega = 1-2\\omega$, which gives $\\omega=0$. This is a boundary of our interval and not an optimal point.\n2. If $1-2\\omega < 0$ (i.e., $\\omega > 1/2$), the equation becomes $1-\\omega = -(1-2\\omega) = 2\\omega-1$.\n\nSolving for $\\omega$:\n$$ 2 = 3\\omega $$\n$$ \\omega = \\frac{2}{3} $$\nThis value satisfies the condition $\\omega > 1/2$.\nLet's analyze the behavior of $\\mu(\\omega)$. For $\\omega < 2/3$, we have $1-\\omega > 2\\omega-1$, so $\\mu(\\omega)$ is a decreasing function. For $\\omega > 2/3$, we have $2\\omega-1 > 1-\\omega$, so $\\mu(\\omega)$ is an increasing function. Therefore, the minimum is achieved exactly at $\\omega = 2/3$.\nAt this optimal value, the smoothing factor is $\\mu(2/3) = 1 - 2/3 = 1/3$.\nThe optimal relaxation parameter that minimizes the smoothing factor is $\\omega = 2/3$.\nThe final answer is requested as a reduced fraction.",
            "answer": "$$\\boxed{\\frac{2}{3}}$$"
        },
        {
            "introduction": "Standard multigrid methods can falter for problems with strong anisotropy, a common characteristic in many thermal engineering applications involving composite materials or boundary layers. This advanced practice  challenges you to build a robust solver by modifying the core multigrid components. By implementing a semi-coarsening strategy paired with a powerful line-relaxation smoother, you will learn how to tailor the algorithm to the underlying physics of the problem, a crucial skill for practical computational work.",
            "id": "3235031",
            "problem": "Implement a complete, runnable program that constructs a geometric multigrid (MG) solver with semi-coarsening only in the $y$-direction for the anisotropic two-dimensional partial differential equation (PDE)\n$$\n\\epsilon\\, u_{xx} + u_{yy} = f \\quad \\text{on} \\quad \\Omega = [0,1]\\times[0,1],\n$$\nwith homogeneous Dirichlet boundary conditions $u=0$ on $\\partial \\Omega$, where $\\epsilon \\ll 1$. The program must adhere to the following specifications.\n\nFundamental base and discretization:\n- Use a uniform tensor-product grid with $N_x$ points in the $x$-direction and $N_y$ points in the $y$-direction, including boundaries at $x=0$, $x=1$, $y=0$, and $y=1$. Let $h_x = 1/(N_x-1)$ and $h_y = 1/(N_y-1)$.\n- Discretize the PDE using standard second-order central differences. Denote $A$ as the resulting discrete operator on the full grid (with boundary values fixed to $0$ and unknowns on the interior).\n- Use homogeneous Dirichlet boundary conditions $u=0$ at all boundary grid points.\n\nGeometric multigrid with semi-coarsening in $y$:\n- Perform semi-coarsening exclusively in the $y$-direction, keeping the $x$-grid unchanged across levels. If a fine level has $N_y$ points, the next coarser level must have $N_y^{(c)} = (N_y+1)/2$ points (assume that $N_y-1$ is divisible by $2$ so that $N_y^{(c)}$ is an integer).\n- Use full-weighting restriction in the $y$-direction only (copying in the $x$-direction). For interior indices, this corresponds to averaging fine-grid residuals along $y$ with weights $1/4$, $1/2$, $1/4$, and injecting zeros at boundaries.\n- Use linear interpolation (prolongation) in the $y$-direction only (copying in the $x$-direction). Coarse values are injected into fine even-indexed $y$-locations; fine odd-indexed $y$-locations are obtained by linear interpolation of neighboring coarse values.\n- Rediscretize the operator $A$ on each grid level using the same second-order stencil with the appropriate $h_x$ and $h_y$ for that level.\n\nSmoother:\n- Use a line relaxation smoother in the $y$-direction. That is, for each fixed interior $x$-index, solve exactly the tridiagonal system arising from treating the $y$-coupling implicitly and the $x$-coupling explicitly. Implement this as a block Gauss–Seidel method across the $x$-lines with forward and backward sweeps.\n\nCoarsest-level solve:\n- Use an iterative method to approximately solve $A u = f$ at the coarsest level in $y$. You must implement the Conjugate Gradient (CG) method using operator application $A$ and standard inner products on the interior unknowns. Stop when the relative residual norm is below $10^{-12}$ or a maximum of $200$ iterations is reached. No external libraries beyond those specified are allowed.\n\nManufactured right-hand side:\n- Use the manufactured solution $u_{\\text{true}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$ so that\n$$\nf(x,y) = -\\pi^2\\left(\\epsilon + 1\\right)\\sin(\\pi x)\\sin(\\pi y).\n$$\nEvaluate $f$ at all interior grid points; set boundary values of $f$ to $0$. This ensures that the exact solution satisfies the boundary conditions $u=0$ on $\\partial \\Omega$.\n\nAlgorithmic task:\n- Starting from the zero initial guess, perform a prescribed number of $V$-cycles with $\\nu_1$ pre-smoothing and $\\nu_2$ post-smoothing line-relaxation sweeps per level, where each line-relaxation sweep consists of a forward and a backward pass in $x$. Use $\\nu_1=\\nu_2=1$.\n- At each tested parameter set, report the ratio of the final residual $2$-norm to the initial residual $2$-norm, where the residual is $r = f - A u$. The $2$-norm is the unweighted Euclidean norm over interior grid points.\n\nTest suite:\n- Your program must run the following four test cases and produce the four corresponding residual reduction factors as decimal floats.\n    1. $N_x=65$, $N_y=65$, $\\epsilon=10^{-3}$, number of $V$-cycles $=6$.\n    2. $N_x=65$, $N_y=33$, $\\epsilon=10^{-6}$, number of $V$-cycles $=8$.\n    3. $N_x=33$, $N_y=65$, $\\epsilon=1$, number of $V$-cycles $=4$.\n    4. $N_x=65$, $N_y=9$, $\\epsilon=10^{-4}$, number of $V$-cycles $=5$.\n- On each level, define the coarsest level to be when $N_y \\le 5$, at which point switch to the CG coarse solve.\n\nFinal output format:\n- Your program should produce a single line of output containing the four results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where each $r_k$ is the computed residual reduction factor for the corresponding test case.\n- There are no physical units, and all angles, if any, are in radians. All numerical answers must be decimal floats.\n\nYour implementation must be self-contained and runnable as-is under the specified environment. No user input is allowed. The goal is to demonstrate, from first principles, how semi-coarsening in the $y$-direction with line relaxation in the $y$-direction addresses anisotropy when $\\epsilon \\ll 1$ while maintaining robustness for general $\\epsilon$.",
            "solution": "The user-provided problem is a valid, well-posed, and an instructive exercise in the field of numerical methods for partial differential equations. It requires the implementation of a geometric multigrid (MG) solver tailored to an anisotropic diffusion equation. The specified components—semi-coarsening, line relaxation, and a Conjugate Gradient coarse-grid solver—are standard techniques, and their combination provides insight into designing efficient solvers for challenging problems. We will proceed to develop the solution from first principles.\n\nThe problem centers on the numerical solution of the two-dimensional anisotropic Poisson equation with homogeneous Dirichlet boundary conditions:\n$$\n\\epsilon\\, u_{xx} + u_{yy} = f(x,y) \\quad \\text{on} \\quad \\Omega = [0,1]\\times[0,1]\n$$\n$$\nu(x,y) = 0 \\quad \\text{on} \\quad \\partial \\Omega\n$$\nThe parameter $\\epsilon$ controls the anisotropy. When $\\epsilon \\ll 1$, the diffusion is significantly weaker in the $x$-direction than in the $y$-direction.\n\nThe solution is constructed by implementing a complete geometric multigrid V-cycle. The core components are detailed below.\n\n**1. Discretization and Grid Hierarchy**\n\nWe discretize the domain $\\Omega$ using a uniform tensor-product grid with $N_x$ and $N_y$ points in the $x$ and $y$ directions, respectively. The grid spacings are $h_x = 1/(N_x-1)$ and $h_y = 1/(N_y-1)$. Using second-order central differences for the partial derivatives at an interior grid point $(x_i, y_j)$, we obtain the discrete equation:\n$$\n\\epsilon \\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h_x^2} + \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h_y^2} = f_{i,j}\n$$\nThis can be written as a linear system $A u = f$, where $A$ is the discrete operator. The equation reveals that the coupling between grid points is stronger in the $y$-direction when $\\epsilon \\ll 1$, as the coefficient $1/h_y^2$ is much larger than $\\epsilon/h_x^2$ (assuming $h_x \\approx h_y$).\n\nThe multigrid method operates on a hierarchy of grids. The problem specifies semi-coarsening in the $y$-direction. Starting from a fine grid (level $l$) with dimensions $(N_x, N_y^{(l)})$, the next coarser grid (level $l+1$) has dimensions $(N_x, N_y^{(l+1)})$ where $N_y^{(l+1)} = (N_y^{(l)}+1)/2$. The number of grid points in the $x$-direction remains constant across all levels. This process is repeated until the grid in the $y$-direction becomes sufficiently small (here, $N_y \\le 5$), which defines the coarsest level. The operator $A$ is re-discretized on each level using the corresponding grid spacing $h_y$.\n\n**2. Smoother: Line Relaxation**\n\nStandard point-wise smoothers like Gauss-Seidel are inefficient for anisotropic problems because they fail to propagate information rapidly in the direction of strong coupling. For our problem where coupling is strong along $y$-lines, we use a $y$-line relaxation smoother. For each fixed $x$-index $i$, we treat all unknowns $u_{i,j}$ for $j=1, \\dots, N_y-2$ as a single block. The discrete equations for this block form a tridiagonal system:\n$$\n\\frac{1}{h_y^2} u_{i,j-1} - 2\\left(\\frac{\\epsilon}{h_x^2} + \\frac{1}{h_y^2}\\right) u_{i,j} + \\frac{1}{h_y^2} u_{i,j+1} = f_{i,j} - \\frac{\\epsilon}{h_x^2} \\left(u_{i-1,j} + u_{i+1,j}\\right)\n$$\nThis tridiagonal system for the unknown vector $(u_{i,1}, \\dots, u_{i,N_y-2})^T$ is solved exactly using the Thomas algorithm. A full smoothing sweep consists of a forward pass (iterating $i$ from $1$ to $N_x-2$) followed by a backward pass (iterating $i$ from $N_x-2$ to $1$), which constitutes a symmetric block Gauss-Seidel method. This smoother effectively damps high-frequency error components along the $y$-direction.\n\n**3. Inter-Grid Transfer Operators: Restriction and Prolongation**\n\nThe effectiveness of multigrid relies on transferring information between fine and coarse grids.\nThe **restriction operator ($R$)** transfers the fine-grid residual $r^f$ to the coarse-grid right-hand side $r^c$. Since coarsening is only in $y$, we use full-weighting in $y$ and identity (copying) in $x$. For an interior coarse-grid point $(i, J)$, the residual is computed as:\n$$\nr^c_{i,J} = \\frac{1}{4} r^f_{i, 2J-1} + \\frac{1}{2} r^f_{i, 2J} + \\frac{1}{4} r^f_{i, 2J+1}\n$$\nThe **prolongation operator ($P$)** interpolates the coarse-grid correction $e^c$ to the fine grid. This is also done only in the $y$-direction. For a fine-grid point $(i, j)$:\n- If $j$ is even (i.e., $j=2J$), the value is injected: $e^f_{i, 2J} = e^c_{i, J}$.\n- If $j$ is odd (i.e., $j=2J-1$), the value is found by linear interpolation: $e^f_{i, 2J-1} = \\frac{1}{2}(e^c_{i, J-1} + e^c_{i, J})$.\nHomogeneous Dirichlet conditions imply that the correction is zero on the boundaries, which is used when interpolating near a boundary.\n\nThe choice of coarsening in the $y$-direction is synergistic with the $y$-line smoother. The smoother makes the error smooth in the $y$-direction, so its representation on a coarser $y$-grid is accurate. The high-frequency error components that may remain in the $x$-direction are not affected by coarsening and can be addressed on all grid levels.\n\n**4. Coarsest-Grid Solver**\n\nOn the coarsest grid, the system $A_c u_c = f_c$ must be solved. Since this grid is small, a direct solve would be feasible, but the problem specifies an iterative solver. We implement the Conjugate Gradient (CG) method. CG is an efficient a method for symmetric positive-definite systems, which $A_c$ is. Starting with an initial guess $u_0 = 0$, the algorithm iteratively refines the solution. The iterations stop when the relative residual norm $\\|f_c - A_c u_k\\|_2 / \\|f_c\\|_2$ falls below a tolerance of $10^{-12}$ or a maximum of $200$ iterations is reached.\n\n**5. The V-Cycle Algorithm**\n\nThe components are orchestrated by the V-cycle algorithm. For a given level $l$ and a problem $A_l u_l = f_l$:\n1.  **Pre-smoothing**: Apply the line-relaxation smoother $\\nu_1$ times to the current approximation of $u_l$.\n2.  **Residual Calculation**: Compute the residual $r_l = f_l - A_l u_l$.\n3.  **Restriction**: Transfer the residual to the next coarser grid: $r_{l+1} = R r_l$.\n4.  **Coarse-Grid Correction**: Solve the residual equation $A_{l+1}e_{l+1} = r_{l+1}$ on the coarse grid. If level $l+1$ is the coarsest, use the CG solver. Otherwise, recursively call the V-cycle on this problem with an initial guess of $e_{l+1}=0$.\n5.  **Prolongation**: Interpolate the computed correction $e_{l+1}$ back to the fine grid: $e_l = P e_{l+1}$.\n6.  **Correction**: Update the solution: $u_l \\leftarrow u_l + e_l$.\n7.  **Post-smoothing**: Apply the smoother $\\nu_2$ times to the corrected approximation.\n\nThis cycle is repeated a specified number of times, starting from an initial guess of $u=0$ on the finest grid. The final result is the ratio of the final residual norm to the initial residual norm, which quantifies the overall reduction in error achieved by the solver.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass SemiCoarseningMGSolver:\n    \"\"\"\n    Geometric Multigrid Solver with y-direction semi-coarsening and line relaxation.\n    \"\"\"\n    def __init__(self, Nx, Ny, epsilon, num_v_cycles, nu1=1, nu2=1):\n        self.Nx = Nx\n        self.Ny = Ny\n        self.epsilon = epsilon\n        self.num_v_cycles = num_v_cycles\n        self.nu1 = nu1\n        self.nu2 = nu2\n        self.grids = self._setup_grids(Nx, Ny, epsilon)\n\n    def _setup_grids(self, Nx, Ny, epsilon):\n        grids = []\n        current_Ny = Ny\n        while current_Ny > 5:\n            grids.append({\n                'Nx': Nx,\n                'Ny': current_Ny,\n                'hx': 1.0 / (Nx - 1),\n                'hy': 1.0 / (current_Ny - 1),\n                'epsilon': epsilon\n            })\n            current_Ny = (current_Ny + 1) // 2\n        \n        grids.append({\n            'Nx': Nx,\n            'Ny': current_Ny,\n            'hx': 1.0 / (Nx - 1),\n            'hy': 1.0 / (current_Ny - 1),\n            'epsilon': epsilon\n        })\n        return grids\n\n    def _apply_A(self, u, level):\n        grid = self.grids[level]\n        Nx, Ny = grid['Nx'], grid['Ny']\n        hx, hy = grid['hx'], grid['hy']\n        eps = grid['epsilon']\n        \n        Au = np.zeros((Ny, Nx))\n        \n        eps_h_x2 = eps / (hx * hx)\n        inv_h_y2 = 1.0 / (hy * hy)\n        \n        center_coeff = -2.0 * (eps_h_x2 + inv_h_y2)\n        \n        # Sliced operation for performance\n        u_int = u[1:-1, 1:-1]\n        u_left = u[1:-1, :-2]\n        u_right = u[1:-1, 2:]\n        u_up = u[:-2, 1:-1]\n        u_down = u[2:, 1:-1]\n\n        Au_int = (eps_h_x2 * (u_left + u_right) +\n                  inv_h_y2 * (u_up + u_down) +\n                  center_coeff * u_int)\n        \n        Au[1:-1, 1:-1] = Au_int\n        return Au\n\n    def _restrict(self, r_fine, level):\n        fine_grid = self.grids[level]\n        coarse_grid = self.grids[level + 1]\n        Nx, Ny_c = coarse_grid['Nx'], coarse_grid['Ny']\n        \n        r_coarse = np.zeros((Ny_c, Nx))\n\n        # Vectorized restriction\n        r_coarse[1:-1, 1:-1] = (0.25 * r_fine[1:-2:2, 1:-1] + \n                                0.5 * r_fine[2:-1:2, 1:-1] + \n                                0.25 * r_fine[3::2, 1:-1])\n        return r_coarse\n\n    def _prolong(self, e_coarse, level):\n        coarse_grid = self.grids[level + 1]\n        fine_grid = self.grids[level]\n        Nx, Ny_f = fine_grid['Nx'], fine_grid['Ny']\n        \n        e_fine = np.zeros((Ny_f, Nx))\n        \n        # Vectorized prolongation\n        # Injection to even rows\n        e_fine[2:-1:2, 1:-1] = e_coarse[1:-1, 1:-1]\n        # Interpolation to odd rows\n        e_fine[1:-1:2, 1:-1] = 0.5 * (e_coarse[:-1, 1:-1] + e_coarse[1:, 1:-1])\n\n        return e_fine\n    \n    def _solve_tridiag(self, a, b, c, d):\n        n = len(d)\n        c_p = np.zeros(n)\n        d_p = np.zeros(n)\n        \n        c_p[0] = c[0] / b[0]\n        d_p[0] = d[0] / b[0]\n        \n        for i in range(1, n):\n            m = b[i] - a[i] * c_p[i-1]\n            c_p[i] = c[i] / m\n            d_p[i] = (d[i] - a[i] * d_p[i-1]) / m\n            \n        x = np.zeros(n)\n        x[-1] = d_p[-1]\n        \n        for i in range(n - 2, -1, -1):\n            x[i] = d_p[i] - c_p[i] * x[i+1]\n            \n        return x\n\n    def _line_relax_sweep(self, u, f, level):\n        grid = self.grids[level]\n        Nx, Ny = grid['Nx'], grid['Ny']\n        hx, hy = grid['hx'], grid['hy']\n        eps = grid['epsilon']\n        \n        u_new = u.copy()\n        \n        # Tridiagonal system setup (constant for all lines)\n        m = Ny - 2\n        diag_val = -2.0 * (eps / (hx * hx) + 1.0 / (hy * hy))\n        off_diag_val = 1.0 / (hy * hy)\n        \n        b = np.full(m, diag_val)\n        a = np.full(m, off_diag_val)\n        c = np.full(m, off_diag_val)\n\n        # Forward sweep\n        for i in range(1, Nx - 1):\n            rhs = f[1:-1, i] - (eps / (hx * hx)) * (u_new[1:-1, i - 1] + u[1:-1, i + 1])\n            u_new[1:-1, i] = self._solve_tridiag(a, b, c, rhs)\n        \n        u = u_new.copy()\n\n        # Backward sweep\n        for i in range(Nx - 2, 0, -1):\n            rhs = f[1:-1, i] - (eps / (hx * hx)) * (u[1:-1, i - 1] + u_new[1:-1, i + 1])\n            u_new[1:-1, i] = self._solve_tridiag(a, b, c, rhs)\n            \n        return u_new\n    \n    def _smoother(self, u, f, level, nu):\n        for _ in range(nu):\n            u = self._line_relax_sweep(u, f, level)\n        return u\n\n    def _dot(self, v1, v2):\n        return np.sum(v1[1:-1, 1:-1] * v2[1:-1, 1:-1])\n\n    def _cg_solve(self, f, level):\n        grid = self.grids[level]\n        u = np.zeros((grid['Ny'], grid['Nx']))\n        r = f.copy()\n        p = r.copy()\n        rs_old = self._dot(r, r)\n        norm_f = np.sqrt(self._dot(f,f))\n        \n        if norm_f == 0.0:\n            return u\n\n        for _ in range(200):\n            Ap = self._apply_A(p, level)\n            alpha = rs_old / self._dot(p, Ap)\n            u += alpha * p\n            r -= alpha * Ap\n            rs_new = self._dot(r, r)\n            if np.sqrt(rs_new) / norm_f < 1e-12:\n                break\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n        return u\n\n    def _v_cycle(self, u, f, level):\n        if level == len(self.grids) - 1:\n            return self._cg_solve(f, level)\n        \n        u = self._smoother(u, f, level, self.nu1)\n        \n        r = f - self._apply_A(u, level)\n        \n        r_coarse = self._restrict(r, level)\n        \n        e_coarse_guess = np.zeros((self.grids[level+1]['Ny'], self.grids[level+1]['Nx']))\n        e_coarse = self._v_cycle(e_coarse_guess, r_coarse, level + 1)\n        \n        e_fine = self._prolong(e_coarse, level)\n        \n        u += e_fine\n        \n        u = self._smoother(u, f, level, self.nu2)\n        \n        return u\n\n    def solve(self):\n        # Setup manufactured solution\n        Nx, Ny, eps = self.Nx, self.Ny, self.epsilon\n        x = np.linspace(0, 1, Nx)\n        y = np.linspace(0, 1, Ny)\n        xx, yy = np.meshgrid(x, y)\n        \n        u_true = np.sin(np.pi * xx) * np.sin(np.pi * yy)\n        f = -np.pi**2 * (eps + 1) * u_true\n        \n        u = np.zeros((Ny, Nx))\n        \n        initial_residual_norm = np.sqrt(self._dot(f, f))\n        \n        if initial_residual_norm == 0:\n            return 0.0\n\n        for _ in range(self.num_v_cycles):\n            u = self._v_cycle(u, f, 0)\n            \n        final_residual = f - self._apply_A(u, 0)\n        final_residual_norm = np.sqrt(self._dot(final_residual, final_residual))\n        \n        return final_residual_norm / initial_residual_norm\n\n\ndef solve():\n    test_cases = [\n        (65, 65, 1e-3, 6),\n        (65, 33, 1e-6, 8),\n        (33, 65, 1.0, 4),\n        (65, 9, 1e-4, 5)\n    ]\n    \n    results = []\n    for Nx, Ny, epsilon, num_cycles in test_cases:\n        solver = SemiCoarseningMGSolver(Nx=Nx, Ny=Ny, epsilon=epsilon, num_v_cycles=num_cycles)\n        ratio = solver.solve()\n        results.append(ratio)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}