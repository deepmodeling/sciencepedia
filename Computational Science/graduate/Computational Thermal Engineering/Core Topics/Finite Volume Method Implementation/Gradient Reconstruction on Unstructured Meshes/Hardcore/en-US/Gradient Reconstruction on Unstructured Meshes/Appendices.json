{
    "hands_on_practices": [
        {
            "introduction": "The Green-Gauss method provides a gradient reconstruction rooted directly in the Gauss divergence theorem. This exercise provides fundamental, hands-on practice in applying its discrete form to a finite volume cell. By comparing results from two different approximations for the face temperature, you will gain direct insight into how these choices, combined with mesh skewness, introduce errors and affect the overall accuracy of the gradient calculation .",
            "id": "3958307",
            "problem": "Consider a two-dimensional control volume (cell) $P$ used in the Finite Volume Method (FVM) within Computational Fluid Dynamics (CFD) for computational thermal engineering. The volume of cell $P$ is $V_{P} = 1.0$ and its boundary $\\partial V_{P}$ consists of four planar faces $f \\in \\{E,N,W,S\\}$ (east, north, west, south). The outward-oriented face area vectors are given by $\\boldsymbol{S}_{E} = (1.0,\\,0.0)$, $\\boldsymbol{S}_{N} = (0.0,\\,1.2)$, $\\boldsymbol{S}_{W} = (-1.0,\\,0.0)$, and $\\boldsymbol{S}_{S} = (0.0,\\,-1.2)$. The cell centroid is at $\\boldsymbol{x}_{P} = (0.0,\\,0.0)$, and the face centroids are $\\boldsymbol{x}_{f,E} = (0.6,\\,0.3)$, $\\boldsymbol{x}_{f,N} = (-0.1,\\,0.7)$, $\\boldsymbol{x}_{f,W} = (-0.5,\\,-0.2)$, and $\\boldsymbol{x}_{f,S} = (0.1,\\,-0.6)$. Neighboring cell centroids adjacent to faces $E$, $N$, $W$, and $S$ are $\\boldsymbol{x}_{N,E} = (1.0,\\,0.1)$, $\\boldsymbol{x}_{N,N} = (0.2,\\,1.1)$, $\\boldsymbol{x}_{N,W} = (-1.1,\\,-0.1)$, and $\\boldsymbol{x}_{N,S} = (0.0,\\,-1.0)$, respectively.\n\nThe temperature field is smooth and given analytically by\n$$\nT(x,y) \\;=\\; 300 \\;+\\; 5x \\;-\\; 3y \\;+\\; 2x^{2} \\;-\\; xy \\;+\\; y^{2}.\n$$\n\nStarting from the divergence theorem and fundamental definitions, derive the discrete Green–Gauss gradient reconstruction for cell $P$,\n$$\n\\nabla T_{P} \\;\\approx\\; \\frac{1}{V_{P}} \\sum_{f \\in \\partial V_{P}} T_{f}\\,\\boldsymbol{S}_{f},\n$$\nincluding a clear statement of how face temperatures $T_{f}$ are approximated. Then:\n\n1. Using equal-weight center-to-center interpolation, define $T_{f}^{\\text{lin}} = \\frac{1}{2}\\left(T_{P} + T_{N,f}\\right)$, where $T_{P} = T(\\boldsymbol{x}_{P})$ and $T_{N,f} = T(\\boldsymbol{x}_{N,f})$, and compute the Green–Gauss approximation $\\nabla T_{P}^{\\text{lin}}$.\n\n2. Using exact face-centroid evaluation, define $T_{f}^{\\text{exact}} = T(\\boldsymbol{x}_{f})$, and compute the Green–Gauss approximation $\\nabla T_{P}^{\\text{exact}}$.\n\n3. Using a Taylor-series perspective, discuss qualitatively the effect of skew faces (where $\\boldsymbol{x}_{f}$ is not collinear with the line connecting $\\boldsymbol{x}_{P}$ and $\\boldsymbol{x}_{N,f}$) on the error of $\\nabla T_{P}^{\\text{lin}}$ relative to $\\nabla T_{P}^{\\text{exact}}$ and the true gradient.\n\nReport the two gradient vectors in the order $\\nabla T_{P}^{\\text{lin}}$ followed by $\\nabla T_{P}^{\\text{exact}}$ as a single row matrix. Round each component to four significant figures. Express each gradient component in $\\mathrm{K/m}$.",
            "solution": "The problem requires the calculation of the temperature gradient in a control volume using two different approximations for the face temperature within the Green-Gauss reconstruction framework, followed by a discussion of the results.\n\nFirst, we derive the discrete Green-Gauss formula for the gradient. The derivation starts from the gradient theorem, a consequence of the Gauss divergence theorem. For a scalar field $T$ and a constant vector $\\boldsymbol{c}$, the divergence theorem applied to the vector field $T\\boldsymbol{c}$ gives:\n$$ \\int_{V} \\nabla \\cdot (T\\boldsymbol{c}) \\, dV = \\oint_{\\partial V} (T\\boldsymbol{c}) \\cdot d\\boldsymbol{S} $$\nUsing the product rule $\\nabla \\cdot (\\phi \\boldsymbol{A}) = \\phi (\\nabla \\cdot \\boldsymbol{A}) + \\boldsymbol{A} \\cdot (\\nabla \\phi)$, and noting that $\\nabla \\cdot \\boldsymbol{c} = 0$ for a constant vector $\\boldsymbol{c}$, we get $\\nabla \\cdot (T\\boldsymbol{c}) = \\boldsymbol{c} \\cdot \\nabla T$. Substituting this into the divergence theorem yields:\n$$ \\int_{V} \\boldsymbol{c} \\cdot \\nabla T \\, dV = \\oint_{\\partial V} T (\\boldsymbol{c} \\cdot d\\boldsymbol{S}) $$\nSince $\\boldsymbol{c}$ is a constant arbitrary vector, it can be factored out of the integrals:\n$$ \\boldsymbol{c} \\cdot \\int_{V} \\nabla T \\, dV = \\boldsymbol{c} \\cdot \\oint_{\\partial V} T \\, d\\boldsymbol{S} $$\nThis equality holds for any $\\boldsymbol{c}$, which implies the vectors themselves must be equal:\n$$ \\int_{V} \\nabla T \\, dV = \\oint_{\\partial V} T \\, d\\boldsymbol{S} $$\nTo apply this to a finite volume cell $P$, we introduce approximations. The gradient $\\nabla T$ is assumed to be constant over the cell volume $V_P$ and equal to its value at the centroid, $\\nabla T_P$. The volume integral is then approximated as:\n$$ \\int_{V_P} \\nabla T \\, dV \\approx \\nabla T_P \\int_{V_P} dV = V_P \\nabla T_P $$\nThe surface integral over the boundary $\\partial V_P$ is discretized into a sum over the individual faces $f$. On each face, the temperature is assumed to be constant and equal to a representative face value $T_f$. The surface integral is approximated as:\n$$ \\oint_{\\partial V_P} T \\, d\\boldsymbol{S} = \\sum_{f \\in \\partial V_P} \\int_{S_f} T \\, d\\boldsymbol{S} \\approx \\sum_{f \\in \\partial V_P} T_f \\int_{S_f} d\\boldsymbol{S} = \\sum_{f \\in \\partial V_P} T_f \\boldsymbol{S}_f $$\nwhere $\\boldsymbol{S}_f$ is the outward-oriented area vector of face $f$.\nEquating the approximated volume and surface integrals gives $V_P \\nabla T_P \\approx \\sum_{f} T_f \\boldsymbol{S}_f$, which leads to the requested formula:\n$$ \\nabla T_P \\approx \\frac{1}{V_P} \\sum_{f \\in \\partial V_P} T_f \\boldsymbol{S}_f $$\nThe accuracy of this reconstruction depends on the approximation used for the face temperature $T_f$.\n\nThe given temperature field is $T(x,y) = 300 + 5x - 3y + 2x^2 - xy + y^2$.\nThe cell centroid is $\\boldsymbol{x}_P = (0.0, 0.0)$, so the temperature at the centroid is $T_P = T(0.0, 0.0) = 300$.\nThe cell volume is given as $V_P = 1.0$.\n\n### 1. Gradient using linear interpolation, $\\nabla T_P^{\\text{lin}}$\n\nThis method approximates the face temperature by linear interpolation between the centroids of the two cells sharing the face: $T_f^{\\text{lin}} = \\frac{1}{2}(T_P + T_{N,f})$. We first calculate the temperatures at the neighboring cell centroids.\n$T_{N,E} = T(1.0, 0.1) = 300 + 5(1.0) - 3(0.1) + 2(1.0)^2 - (1.0)(0.1) + (0.1)^2 = 306.61$\n$T_{N,N} = T(0.2, 1.1) = 300 + 5(0.2) - 3(1.1) + 2(0.2)^2 - (0.2)(1.1) + (1.1)^2 = 298.77$\n$T_{N,W} = T(-1.1, -0.1) = 300 + 5(-1.1) - 3(-0.1) + 2(-1.1)^2 - (-1.1)(-0.1) + (-0.1)^2 = 297.12$\n$T_{N,S} = T(0.0, -1.0) = 300 + 5(0.0) - 3(-1.0) + 2(0.0)^2 - (0.0)(-1.0) + (-1.0)^2 = 304.0$\n\nWith $T_P = 300$, the face temperatures are:\n$T_{f,E}^{\\text{lin}} = \\frac{1}{2}(300 + 306.61) = 303.305$\n$T_{f,N}^{\\text{lin}} = \\frac{1}{2}(300 + 298.77) = 299.385$\n$T_{f,W}^{\\text{lin}} = \\frac{1}{2}(300 + 297.12) = 298.56$\n$T_{f,S}^{\\text{lin}} = \\frac{1}{2}(300 + 304.0) = 302.0$\n\nNow, we compute the sum $\\sum_f T_f^{\\text{lin}} \\boldsymbol{S}_f$:\n$\\sum T_f^{\\text{lin}} \\boldsymbol{S}_f = T_{f,E}^{\\text{lin}}\\boldsymbol{S}_E + T_{f,N}^{\\text{lin}}\\boldsymbol{S}_N + T_{f,W}^{\\text{lin}}\\boldsymbol{S}_W + T_{f,S}^{\\text{lin}}\\boldsymbol{S}_S$\n$= 303.305(1.0, 0.0) + 299.385(0.0, 1.2) + 298.56(-1.0, 0.0) + 302.0(0.0, -1.2)$\n$= (303.305 - 298.56, 1.2 \\times 299.385 - 1.2 \\times 302.0)$\n$= (4.745, 359.262 - 362.4)$\n$= (4.745, -3.138)$\n\nThe gradient is $\\nabla T_P^{\\text{lin}} = \\frac{1}{V_P} (4.745, -3.138) = \\frac{1}{1.0} (4.745, -3.138) = (4.745, -3.138)$.\n\n### 2. Gradient using exact face-centroid evaluation, $\\nabla T_P^{\\text{exact}}$\n\nThis method uses the exact temperature at the face centroid, $T_f^{\\text{exact}} = T(\\boldsymbol{x}_f)$.\n$T_{f,E}^{\\text{exact}} = T(0.6, 0.3) = 300 + 5(0.6) - 3(0.3) + 2(0.6)^2 - (0.6)(0.3) + (0.3)^2 = 302.73$\n$T_{f,N}^{\\text{exact}} = T(-0.1, 0.7) = 300 + 5(-0.1) - 3(0.7) + 2(-0.1)^2 - (-0.1)(0.7) + (0.7)^2 = 297.98$\n$T_{f,W}^{\\text{exact}} = T(-0.5, -0.2) = 300 + 5(-0.5) - 3(-0.2) + 2(-0.5)^2 - (-0.5)(-0.2) + (-0.2)^2 = 298.54$\n$T_{f,S}^{\\text{exact}} = T(0.1, -0.6) = 300 + 5(0.1) - 3(-0.6) + 2(0.1)^2 - (0.1)(-0.6) + (-0.6)^2 = 302.74$\n\nNow, we compute the sum $\\sum_f T_f^{\\text{exact}} \\boldsymbol{S}_f$:\n$\\sum T_f^{\\text{exact}} \\boldsymbol{S}_f = T_{f,E}^{\\text{exact}}\\boldsymbol{S}_E + T_{f,N}^{\\text{exact}}\\boldsymbol{S}_N + T_{f,W}^{\\text{exact}}\\boldsymbol{S}_W + T_{f,S}^{\\text{exact}}\\boldsymbol{S}_S$\n$= 302.73(1.0, 0.0) + 297.98(0.0, 1.2) + 298.54(-1.0, 0.0) + 302.74(0.0, -1.2)$\n$= (302.73 - 298.54, 1.2 \\times 297.98 - 1.2 \\times 302.74)$\n$= (4.19, 357.576 - 363.288)$\n$= (4.19, -5.712)$\n\nThe gradient is $\\nabla T_P^{\\text{exact}} = \\frac{1}{V_P} (4.19, -5.712) = \\frac{1}{1.0} (4.19, -5.712) = (4.19, -5.712)$.\n\n### 3. Qualitative Discussion\n\nTo assess the accuracy of these approximations, we first compute the true gradient at the cell centroid $\\boldsymbol{x}_P=(0.0, 0.0)$.\nThe gradient of the temperature field is $\\nabla T = (\\frac{\\partial T}{\\partial x}, \\frac{\\partial T}{\\partial y}) = (5 + 4x - y, -3 - x + 2y)$.\nAt $\\boldsymbol{x}_P = (0.0, 0.0)$, the true gradient is $\\nabla T(\\boldsymbol{x}_P) = (5, -3)$.\n\nComparing the results:\nTrue gradient: $\\nabla T_{\\text{true}} = (5, -3)$\nLinear interpolation: $\\nabla T_P^{\\text{lin}} = (4.745, -3.138)$\nExact face value: $\\nabla T_P^{\\text{exact}} = (4.19, -5.712)$\n\nThe effect of skew faces on the error of $\\nabla T_P^{\\text{lin}}$ versus $\\nabla T_P^{\\text{exact}}$ can be understood by analyzing the sources of error in each method. A face is considered skew when the line segment connecting the adjacent cell centroids $\\boldsymbol{x}_P$ and $\\boldsymbol{x}_{N,f}$ is not aligned with the face normal vector, or when the intersection of this line with the face does not coincide with the face centroid $\\boldsymbol{x}_f$. Both conditions are present in this problem.\n\nThe `lin` method uses an interpolated temperature $T_f^{\\text{lin}} = \\frac{1}{2}(T_P + T_{N,f})$. For a non-linear field like the one given, this is a second-order approximation of the temperature not at the face centroid $\\boldsymbol{x}_f$, but at the midpoint of the cell centers, $\\boldsymbol{x}_{m,f} = \\frac{1}{2}(\\boldsymbol{x}_P + \\boldsymbol{x}_{N,f})$. Applying this value at the face centroid location in the Green-Gauss sum introduces a \"skewness error.\" This error is approximately $(\\boldsymbol{x}_{m,f} - \\boldsymbol{x}_f) \\cdot \\nabla T$, which is a first-order error term that contaminates the gradient calculation, reducing the scheme's formal accuracy.\n\nThe `exact` method, by using $T_f^{\\text{exact}} = T(\\boldsymbol{x}_f)$, seems superior as it evaluates the temperature at the correct location required by the surface integral approximation, thus avoiding the explicit skewness error committed by the `lin` method. However, the Green-Gauss formula itself is an approximation whose accuracy is sensitive to the cell's geometry. For a perfectly orthogonal cell (e.g., a rectangle aligned with the axes), the formula would be exact for a linear temperature field. For the given distorted cell, the formula introduces a significant geometric error. This is why $\\nabla T_P^{\\text{exact}}$ deviates substantially from the true gradient $\\nabla T_{\\text{true}}$. The geometric imperfections essentially cause the formula to wrongly \"map\" the true gradient to an inaccurate numerical one.\n\nIn this specific case, the `lin` method gives a result that is fortuitously closer to the true gradient. This is because the errors inherent in the `lin` method (interpolation error from the non-linear field and the skewness error) happen to partially cancel the large geometric error of the Green-Gauss formula for this particular distorted cell. This outcome is coincidental and not general. Typically, on high-quality meshes (low skewness), the `exact` method would be more accurate. On highly skewed meshes, the `lin` method without explicit skewness correction is known to be inaccurate and can introduce unphysical numerical diffusion. The poor performance of the `exact` method here highlights a fundamental limitation of the basic Green-Gauss scheme on low-quality meshes.\n\nRounding the components of the computed gradients to four significant figures:\n$\\nabla T_P^{\\text{lin}} = (4.745, -3.138)$\n$\\nabla T_P^{\\text{exact}} = (4.190, -5.712)$\n\nThe two gradient vectors are reported as a single row matrix: $(\\nabla T_{P,x}^{\\text{lin}}, \\nabla T_{P,y}^{\\text{lin}}, \\nabla T_{P,x}^{\\text{exact}}, \\nabla T_{P,y}^{\\text{exact}})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4.745 & -3.138 & 4.190 & -5.712\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The weighted least-squares (WLS) method offers a powerful alternative, framing gradient reconstruction as a local data-fitting problem based on Taylor series expansions. However, its stability is highly dependent on the geometric quality of the neighbor stencil. This practice explores the critical failure mode of near-collinear stencils, which leads to ill-conditioned systems, and challenges you to evaluate remedies based on the crucial principles of numerical stability and the preservation of linear exactness .",
            "id": "3958296",
            "problem": "In a 2D cell-centered Finite Volume Method (FVM) for steady heat conduction, diffusive fluxes through cell faces are computed using Fourier’s law, $\\mathbf{q}=-k\\nabla T$, which requires a stable and accurate reconstruction of the temperature gradient $\\nabla T$ at each cell centroid. Consider reconstructing $\\nabla T$ in a cell $P$ from its neighboring cell centers $\\{\\mathbf{x}_i\\}$ using a Least Squares (LS) formulation based on the first-order Taylor expansion about the centroid $\\mathbf{x}_P$,\n$$\nT(\\mathbf{x}_i)=T(\\mathbf{x}_P)+\\nabla T\\cdot(\\mathbf{x}_i-\\mathbf{x}_P)+\\mathcal{O}(\\|\\mathbf{x}_i-\\mathbf{x}_P\\|^2).\n$$\nDefine $\\Delta\\mathbf{x}_i=\\mathbf{x}_i-\\mathbf{x}_P$ and minimize\n$$\nJ(\\mathbf{g})=\\sum_i w_i\\left[T(\\mathbf{x}_i)-T(\\mathbf{x}_P)-\\mathbf{g}\\cdot\\Delta\\mathbf{x}_i\\right]^2,\n$$\nwith weights $w_i>0$, where $\\mathbf{g}$ is the reconstructed gradient at $\\mathbf{x}_P$. The normal equations are\n$$\n\\left(\\sum_i w_i\\,\\Delta\\mathbf{x}_i\\Delta\\mathbf{x}_i^{\\top}\\right)\\mathbf{g}=\\sum_i w_i\\,\\Delta\\mathbf{x}_i\\left[T(\\mathbf{x}_i)-T(\\mathbf{x}_P)\\right].\n$$\nSuppose that the neighbor offsets are nearly collinear, i.e., there exists an orthonormal basis $\\{\\mathbf{e},\\mathbf{n}\\}$ with\n$$\n\\Delta\\mathbf{x}_i=d_i\\,\\mathbf{e}+\\epsilon_i\\,\\mathbf{n},\\quad \\text{where }\\sum_i w_i\\,\\epsilon_i^2\\ll \\sum_i w_i\\,d_i^2.\n$$\nThen the normal matrix\n$$\n\\mathbf{A}=\\sum_i w_i\\,\\Delta\\mathbf{x}_i\\Delta\\mathbf{x}_i^{\\top}\n$$\nhas one large eigenvalue associated with $\\mathbf{e}$ and one very small eigenvalue associated with $\\mathbf{n}$, yielding a large condition number and an unstable estimate of the $\\mathbf{n}$-component of $\\mathbf{g}$.\n\nFrom the fundamental definition of the gradient via the Taylor expansion and the Divergence Theorem,\n$$\n\\int_V \\nabla T\\,\\mathrm{d}V=\\int_{\\partial V}T\\,\\mathbf{n}\\,\\mathrm{d}S,\n$$\nany remedy must either add independent directional information or regularize the poorly observable component while maintaining consistency for linear fields so that non-degenerate stencils retain linear exactness.\n\nWhich of the following remedies are sound, principle-based ways to retain stable gradient components in such degenerate 2D stencils, while preserving linear exactness in non-degenerate settings?\n\nA. Increase the weights $w_i$ of neighbors most aligned with the nearly collinear direction to reduce the variance of the estimator in that direction.\n\nB. Augment the LS system with one or more face-normal equations derived from the Divergence Theorem (Green–Gauss), e.g., introduce the soft constraint $\\mathbf{g}\\approx \\frac{1}{|V_P|}\\sum_{f\\in\\partial V_P}T_f\\,\\mathbf{n}_f\\,A_f$, with a constraint weight that vanishes as the local mesh size $h\\to 0$, thereby adding independent directional information without altering the exactness for linear $T$ when the stencil is non-degenerate.\n\nC. Apply isotropic Tikhonov regularization with a fixed parameter $\\lambda>0$ to the LS normal equations, i.e., solve $\\left(\\mathbf{A}+\\lambda\\mathbf{I}\\right)\\mathbf{g}=\\mathbf{b}$, which always stabilizes the solution and preserves linear exactness for non-degenerate stencils.\n\nD. Enlarge the stencil to include additional non-collinear neighbors (e.g., second-ring cell centers or boundary face points) so that $\\sum_i w_i\\,\\epsilon_i^2$ is comparable to $\\sum_i w_i\\,d_i^2$, restoring full rank and improving the condition number of $\\mathbf{A}$.\n\nE. Rotate the coordinate system so that $\\mathbf{e}$ aligns with the $x$-axis and set the orthogonal gradient component $g_n$ to zero whenever the condition number of $\\mathbf{A}$ exceeds a threshold, thereby avoiding amplification of noise in the ill-observed direction.\n\nSelect all that apply. Ensure your choices are justified by first principles and the stated criteria regarding stability and preservation of linear exactness in non-degenerate stencils.",
            "solution": "The problem requires identifying valid remedies for an ill-conditioned Weighted Least Squares (WLS) gradient reconstruction system that arises from a nearly collinear stencil of neighbor points. A remedy is considered valid if it provides numerical stability while preserving \"linear exactness\" for non-degenerate stencils. A scheme is linearly exact if it perfectly reconstructs the constant gradient of any linear temperature field. The standard WLS method is linearly exact for non-degenerate stencils, as shown by substituting $T(\\mathbf{x}_i) - T_P = \\mathbf{c} \\cdot \\Delta\\mathbf{x}_i$ into the normal equations, which yields $\\mathbf{A}\\mathbf{g} = \\mathbf{A}\\mathbf{c}$, so $\\mathbf{g}=\\mathbf{c}$ if $\\mathbf{A}$ is invertible.\n\nLet's evaluate each option against the criteria of stability and linear exactness.\n\n**A. Increase the weights $w_i$ of neighbors most aligned with the nearly collinear direction.**\nThis is incorrect. The ill-conditioning arises from a lack of information in the direction orthogonal to the near-collinear line of points. Increasing the weights of points that lie on or near this line will only reinforce the dominance of that direction in the system matrix $\\mathbf{A}$, further increasing the disparity between its eigenvalues and worsening the condition number. This approach is counter-productive to stability.\n\n**B. Augment the LS system with a Green–Gauss (GG) constraint.**\nThis is a correct and widely used hybrid approach. The GG gradient estimate is derived from the Divergence Theorem and uses face-normal vectors, which typically provide directional information independent of the cell-to-cell vectors used in the LS formulation. This augmentation adds stability by regularizing the ill-conditioned directions. For a linear temperature field, both the WLS formulation and the GG formulation (with face-centroid temperatures) are independently exact. Therefore, combining them in a single minimization problem (e.g., as a soft constraint) preserves the property that the exact gradient is the solution. This method satisfies both criteria.\n\n**C. Apply isotropic Tikhonov regularization.**\nThis is incorrect. Tikhonov regularization solves $(\\mathbf{A}+\\lambda\\mathbf{I})\\mathbf{g}=\\mathbf{b}$. While adding the term $\\lambda\\mathbf{I}$ (with $\\lambda > 0$) guarantees that the system matrix is invertible and thus provides stability, it violates linear exactness. For a linear field, the right-hand side is $\\mathbf{b} = \\mathbf{A}\\mathbf{c}$. The regularized solution is $\\mathbf{g} = (\\mathbf{A}+\\lambda\\mathbf{I})^{-1}\\mathbf{A}\\mathbf{c}$. In general, $\\mathbf{g} \\neq \\mathbf{c}$, because $(\\mathbf{A}+\\lambda\\mathbf{I})^{-1}\\mathbf{A} \\neq \\mathbf{I}$. This introduces a bias in the solution, sacrificing accuracy for stability.\n\n**D. Enlarge the stencil to include additional non-collinear neighbors.**\nThis is a correct and fundamental solution. The ill-conditioning is a direct result of a geometrically deficient stencil. By adding more neighbors (e.g., second-ring neighbors) that are not collinear with the original set, the geometric matrix $\\mathbf{A}$ becomes well-conditioned and robustly invertible. This directly addresses the stability problem at its source. Since the method remains a pure least-squares formulation, its inherent property of linear exactness is preserved as long as the resulting stencil is non-degenerate.\n\n**E. Set the orthogonal gradient component $g_n$ to zero.**\nThis is incorrect. While this approach does provide stability by preventing the amplification of noise in the poorly-resolved direction, it fails the linear exactness criterion. If the true gradient of a linear field has a non-zero component in the direction $\\mathbf{n}$ (i.e., $\\mathbf{c} \\cdot \\mathbf{n} \\neq 0$), this method would erroneously reconstruct it as zero. This introduces a systematic error and does not preserve linear exactness for arbitrary linear fields.\n\nTherefore, the only sound, principle-based remedies that satisfy both stability and linear exactness are augmenting the system with independent Green-Gauss information and enlarging the stencil to correct its geometric deficiency.",
            "answer": "$$\\boxed{BD}$$"
        },
        {
            "introduction": "In practical computational engineering, no single reconstruction method is optimal for all mesh configurations and flow conditions. This capstone exercise moves from theory to practice by tasking you with designing a dynamic, hybrid algorithm that leverages the strengths of both the Green-Gauss and least-squares methods. You will develop and implement explicit criteria to intelligently switch between schemes, building a robust gradient reconstruction tool suitable for the complex meshes encountered in real-world simulations .",
            "id": "3958323",
            "problem": "You are tasked with designing and implementing a dynamic gradient reconstruction algorithm for two-dimensional unstructured meshes within the Finite Volume Method (FVM) framework. The algorithm must switch between two reconstruction methods based on local geometric and numerical quality: Green–Gauss (GG) and Weighted Least Squares (WLS). The objective is to reconstruct the gradient of a scalar field (interpreted as temperature) at a given cell centroid with robustness near boundaries and in highly skewed regions. The reconstructed gradients must be evaluated against an analytic reference solution, and the algorithm’s method selection must be justified by explicit, quantifiable criteria.\n\nStart from the following fundamental base:\n- The Gauss Divergence Theorem states that for a sufficiently smooth scalar field $\\,\\phi(\\boldsymbol{x})\\,$, the cell-averaged gradient over a polygonal cell of area $\\,A\\,$ satisfies\n$$\n\\int_{\\Omega} \\nabla \\phi \\, \\mathrm{d}\\Omega = \\int_{\\partial \\Omega} \\phi \\, \\boldsymbol{n} \\, \\mathrm{d}S,\n$$\nwhere $\\,\\boldsymbol{n}\\,$ denotes the outward-facing unit normal and $\\,\\partial \\Omega\\,$ is the cell boundary.\n- A Weighted Least Squares (WLS) fit of a linear field $\\,\\phi(\\boldsymbol{x})\\approx \\phi_P + \\boldsymbol{g}\\cdot(\\boldsymbol{x}-\\boldsymbol{x}_P)\\,$ around a cell centroid $\\,\\boldsymbol{x}_P\\,$ can be obtained by minimizing\n$$\nJ(\\boldsymbol{g}) = \\sum_j w_j \\left[ \\phi_j - \\phi_P - \\boldsymbol{g}\\cdot(\\boldsymbol{x}_j-\\boldsymbol{x}_P) \\right]^2,\n$$\nwith positive weights $\\,w_j>0\\,$, leading to the normal equations\n$$\n\\left( \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A} \\right)\\boldsymbol{g} = \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{b},\n$$\nwhere $\\,\\boldsymbol{A}\\,$ has rows $\\,(\\boldsymbol{x}_j-\\boldsymbol{x}_P)^\\top\\,$, $\\,\\boldsymbol{b}\\,$ has entries $\\,\\phi_j - \\phi_P\\,$, and $\\,\\boldsymbol{W}\\,$ is diagonal with entries $\\,w_j\\,$.\n\nDesign a robust selector for the method choice based on:\n1. Boundary proximity: If any face is a boundary face (Dirichlet condition), prefer WLS because Green–Gauss may suffer from biased face values at boundaries.\n2. Non-orthogonality: Define non-orthogonality at a face as the angle (in degrees) between the face normal $\\,\\boldsymbol{n}_f\\,$ and the centroid-to-centroid vector $\\,\\boldsymbol{d}_f\\,$ for internal faces, or the centroid-to-face-centroid vector for boundary faces. The angle is\n$$\n\\theta_f = \\arccos\\left( \\frac{|\\boldsymbol{d}_f\\cdot \\boldsymbol{n}_f|}{\\|\\boldsymbol{d}_f\\|} \\right)\\times \\frac{180}{\\pi}.\n$$\nLet $\\,\\theta_{\\max}\\,$ be the maximum over faces. If $\\,\\theta_{\\max} > \\Theta^\\star\\,$, prefer WLS. Use $\\,\\Theta^\\star = 60\\,$ degrees.\n3. Numerical conditioning: If WLS is preferred, compute the condition number $\\,\\kappa\\,$ of $\\,\\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A}\\,$ and its rank. If $\\,\\kappa>\\kappa_{\\max}\\,$ or rank $<2$, then revert to GG. Use $\\,\\kappa_{\\max}=10^6\\,$.\n\nImplement the following:\n- Green–Gauss Gradient: For a polygonal cell with area $\\,A\\,$ and edges (faces) of length $\\,L_f\\,$, outward unit normals $\\,\\boldsymbol{n}_f\\,$, and midpoints $\\,\\boldsymbol{x}_f\\,$, approximate the gradient as\n$$\n\\nabla \\phi_P \\approx \\frac{1}{A} \\sum_{f} \\phi_f \\, \\boldsymbol{n}_f \\, L_f,\n$$\nwith $\\,\\phi_f\\,$ equal to the arithmetic average of the two adjacent cell values for internal faces, and the Dirichlet boundary value at $\\,\\boldsymbol{x}_f\\,$ for boundary faces.\n- Weighted Least Squares Gradient: Solve the normal equations for $\\,\\boldsymbol{g}\\,$ using only internal neighbor centroids $\\,\\boldsymbol{x}_j\\,$ with weights $\\,w_j = 1/\\|\\boldsymbol{x}_j-\\boldsymbol{x}_P\\|\\,$. If the system is rank-deficient or ill-conditioned by the above criterion, revert to GG.\n\nAnalytic temperature field and units:\n- Let the analytic temperature field be\n$$\nT(x,y) = 300 + 10x + 5y + 0.5\\,x\\,y,\n$$\nwith $\\,T\\,$ in Kelvin (K) and $\\,x,y\\,$ in meters (m). The exact gradient is\n$$\n\\nabla T(x,y) = \\left(10 + 0.5y,\\; 5 + 0.5x \\right) \\quad \\text{in K/m}.\n$$\nAll computed gradient errors must be reported in Kelvin per meter (K/m). Angles must be treated in degrees.\n\nTest suite:\nFor each test case, a single target cell is defined by its vertices (in counter-clockwise order) and per-face neighbor metadata (whether boundary and, if internal, the neighbor centroid). The program must evaluate the selected method and the absolute gradient error magnitude (Euclidean norm) at the cell centroid. The algorithm must dynamically select the reconstruction method per the criteria above.\n\n- Test Case $1$ (interior well-shaped square, no boundaries):\n    - Vertices: $(1,1)$, $(2,1)$, $(2,2)$, $(1,2)$.\n    - Per-face neighbors (faces $0$ to $3$ in vertex order): internal neighbors at centroids $(1.5,0.5)$, $(2.5,1.5)$, $(1.5,2.5)$, $(0.5,1.5)$.\n- Test Case $2$ (boundary corner square):\n    - Vertices: $(0,0)$, $(1,0)$, $(1,1)$, $(0,1)$.\n    - Per-face neighbors: boundary at face $0$, internal at face $1$ with centroid $(1.5,0.5)$, internal at face $2$ with centroid $(0.5,1.5)$, boundary at face $3$.\n- Test Case $3$ (highly skewed quadrilateral, internal neighbors only):\n    - Vertices: $(2.0,1.0)$, $(3.0,1.1)$, $(2.8,2.2)$, $(2.0,2.0)$.\n    - Per-face neighbors: internal centroids $(3.3,0.4)$, $(3.6,1.8)$, $(1.9,2.8)$, $(1.4,1.4)$.\n- Test Case $4$ (boundary cell with insufficient internal neighbors for WLS):\n    - Vertices: $(3,0)$, $(4,0)$, $(4,1)$, $(3,1)$.\n    - Per-face neighbors: boundary at faces $0$, $1$, $2$, internal at face $3$ with centroid $(2.5,0.5)$.\n\nSelection thresholds:\n- Non-orthogonality threshold: $\\,\\Theta^\\star = 60\\,$ degrees.\n- Maximum acceptable condition number: $\\,\\kappa_{\\max} = 10^6\\,$.\n\nOutput specification:\n- For each test case, output a list with two entries: the selected method code and the absolute gradient error magnitude. Use method code $\\,0\\,$ for Green–Gauss (GG) and $\\,1\\,$ for Weighted Least Squares (WLS).\n- The final program output must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets. Each result must be a two-element list with no spaces, in the form $\\,\\left[\\text{method\\_code},\\text{error}\\right]\\,$. For example:\n$$\n[ [0,0.001234],[1,0.000567],\\ldots\\,]\n$$\n- All gradient errors must be expressed in $\\,\\text{K/m}\\,$ as floats. The output must contain numerical values only (no unit strings), with each error rounded to six decimal places.\n\nAngle unit requirement:\n- All angles used for non-orthogonality assessment must be treated in degrees.\n\nYour program must implement this dynamic selection algorithm, compute the reconstructed gradients for the specified test suite, compare them to the exact analytic gradients, and produce the required output line.",
            "solution": "The solution implements a dynamic gradient reconstruction algorithm that intelligently switches between the Green-Gauss (GG) and Weighted Least Squares (WLS) methods. For each cell in the test suite, the algorithm performs the following steps:\n\n**1. Geometric Pre-processing:**\nFirst, the fundamental geometric properties of the target cell are computed from its vertices. This includes the cell's area (using the shoelace formula), its centroid (using the formula for a simple polygon), and for each face, its length, midpoint, and outward-pointing unit normal vector.\n\n**2. Dynamic Method Selection:**\nA hierarchical decision logic determines the most suitable reconstruction method (GG or WLS) for the current cell.\n\n*   **Default Method:** The Green-Gauss (GG) method is the default choice.\n*   **WLS Preference Criteria:** The algorithm prefers WLS under two conditions:\n    1.  **Boundary Proximity:** If the cell has any face on the domain boundary, WLS is preferred.\n    2.  **High Non-Orthogonality:** For interior cells, the non-orthogonality angle is computed for each face. This angle is the measure between the face normal and the vector connecting the cell centroid to its neighbor's centroid. If the maximum angle across all faces exceeds the threshold $\\Theta^\\star = 60^\\circ$, the cell is considered highly distorted, and WLS is preferred to mitigate potential inaccuracies in the GG method.\n*   **WLS Validity Check (Fallback to GG):** If WLS is preferred, a numerical stability check is performed before its use. WLS is only considered valid if:\n    1.  The number of internal neighbors is at least 2 (the minimum required for a 2D gradient).\n    2.  The system matrix for the least-squares problem is full rank (rank = 2).\n    3.  The condition number of the system matrix is below the threshold $\\kappa_{\\max} = 10^6$.\n    If any of these checks fail, the WLS method is deemed unreliable, and the algorithm reverts to the more robust GG method.\n\n**3. Gradient Calculation:**\nThe gradient is computed using the selected method.\n\n*   **Green-Gauss (GG):** The gradient is calculated by summing contributions from each face, using the formula $\\nabla \\phi_P \\approx \\frac{1}{A} \\sum_{f} \\phi_f \\boldsymbol{n}_f L_f$. The face value $\\phi_f$ is the arithmetic average of the adjacent cell-centroid values for an internal face, or the exact analytic value at the face midpoint for a boundary face.\n*   **Weighted Least Squares (WLS):** The gradient is found by solving the $2 \\times 2$ normal equations. The system is constructed using only the internal neighbors of the cell. The weights are chosen as the inverse of the distance to each neighbor, $w_j = 1/\\|\\boldsymbol{x}_j-\\boldsymbol{x}_P\\|$.\n\n**4. Error Evaluation:**\nFinally, the computed gradient is compared against the exact analytical gradient evaluated at the cell's centroid. The error is reported as the Euclidean norm of the difference between the reconstructed and exact gradient vectors.\n\nThis entire process is applied to each of the four test cases provided, and the final output reports the selected method code (0 for GG, 1 for WLS) and the computed error for each case.",
            "answer": "```python\nimport numpy as np\n\n# --- Problem Constants and Analytic Functions ---\n\nTHETA_STAR = 60.0  # degrees\nKAPPA_MAX = 1e6\n\ndef analytic_T(x, y):\n    \"\"\"Analytic temperature field T(x,y) in Kelvin.\"\"\"\n    return 300.0 + 10.0 * x + 5.0 * y + 0.5 * x * y\n\ndef analytic_grad_T(x, y):\n    \"\"\"Exact gradient of the temperature field in K/m.\"\"\"\n    return np.array([10.0 + 0.5 * y, 5.0 + 0.5 * x])\n\n# --- Geometric Utility Functions ---\n\ndef get_polygon_properties(vertices):\n    \"\"\"\n    Calculates the area and centroid of a simple polygon.\n    Assumes vertices are given in counter-clockwise order.\n    \"\"\"\n    verts_shifted = np.roll(vertices, -1, axis=0)\n    cross_prod_terms = vertices[:, 0] * verts_shifted[:, 1] - verts_shifted[:, 0] * vertices[:, 1]\n    \n    area = 0.5 * np.sum(cross_prod_terms)\n    \n    cx_terms = (vertices[:, 0] + verts_shifted[:, 0]) * cross_prod_terms\n    cy_terms = (vertices[:, 1] + verts_shifted[:, 1]) * cross_prod_terms\n    \n    centroid_x = (1.0 / (6.0 * area)) * np.sum(cx_terms)\n    centroid_y = (1.0 / (6.0 * area)) * np.sum(cy_terms)\n    \n    return area, np.array([centroid_x, centroid_y])\n\ndef get_face_properties(vertices):\n    \"\"\"\n    Calculates properties for each face of the polygon.\n    Returns a list of dictionaries, one for each face.\n    \"\"\"\n    num_verts = len(vertices)\n    faces = []\n    for i in range(num_verts):\n        p1 = vertices[i]\n        p2 = vertices[(i + 1) % num_verts]\n        \n        face_vec = p2 - p1\n        length = np.linalg.norm(face_vec)\n        midpoint = 0.5 * (p1 + p2)\n        \n        # Outward normal for CCW vertices\n        normal = np.array([face_vec[1], -face_vec[0]]) / length\n        faces.append({'length': length, 'midpoint': midpoint, 'normal': normal})\n    return faces\n\n# --- Gradient Reconstruction Methods ---\n\ndef calculate_gg_gradient(cell_centroid, cell_area, faces, neighbor_data):\n    \"\"\"Computes the gradient using the Green-Gauss method.\"\"\"\n    grad_sum = np.zeros(2)\n    phi_P = analytic_T(cell_centroid[0], cell_centroid[1])\n    \n    for i, face in enumerate(faces):\n        neighbor = neighbor_data[i]\n        if neighbor['type'] == 'internal':\n            phi_N = analytic_T(neighbor['centroid'][0], neighbor['centroid'][1])\n            phi_f = 0.5 * (phi_P + phi_N)\n        else: # boundary\n            phi_f = analytic_T(face['midpoint'][0], face['midpoint'][1])\n        \n        grad_sum += phi_f * face['normal'] * face['length']\n        \n    return grad_sum / cell_area\n\ndef solve():\n    \"\"\"Main solver function to process all test cases.\"\"\"\n    \n    # Test cases defined as (vertices, neighbor_metadata)\n    test_cases = [\n        # Case 1: Interior well-shaped square\n        (\n            np.array([[1, 1], [2, 1], [2, 2], [1, 2]], dtype=float),\n            [\n                {'type': 'internal', 'centroid': np.array([1.5, 0.5])},\n                {'type': 'internal', 'centroid': np.array([2.5, 1.5])},\n                {'type': 'internal', 'centroid': np.array([1.5, 2.5])},\n                {'type': 'internal', 'centroid': np.array([0.5, 1.5])},\n            ]\n        ),\n        # Case 2: Boundary corner square\n        (\n            np.array([[0, 0], [1, 0], [1, 1], [0, 1]], dtype=float),\n            [\n                {'type': 'boundary', 'centroid': None},\n                {'type': 'internal', 'centroid': np.array([1.5, 0.5])},\n                {'type': 'internal', 'centroid': np.array([0.5, 1.5])},\n                {'type': 'boundary', 'centroid': None},\n            ]\n        ),\n        # Case 3: Highly skewed quadrilateral, internal\n        (\n            np.array([[2.0, 1.0], [3.0, 1.1], [2.8, 2.2], [2.0, 2.0]], dtype=float),\n            [\n                {'type': 'internal', 'centroid': np.array([3.3, 0.4])},\n                {'type': 'internal', 'centroid': np.array([3.6, 1.8])},\n                {'type': 'internal', 'centroid': np.array([1.9, 2.8])},\n                {'type': 'internal', 'centroid': np.array([1.4, 1.4])},\n            ]\n        ),\n        # Case 4: Boundary cell with insufficient neighbors for WLS\n        (\n            np.array([[3, 0], [4, 0], [4, 1], [3, 1]], dtype=float),\n            [\n                {'type': 'boundary', 'centroid': None},\n                {'type': 'boundary', 'centroid': None},\n                {'type': 'boundary', 'centroid': None},\n                {'type': 'internal', 'centroid': np.array([2.5, 0.5])},\n            ]\n        )\n    ]\n    \n    results = []\n\n    for vertices, neighbor_data in test_cases:\n        # --- 1. Geometric Pre-processing ---\n        area, centroid = get_polygon_properties(vertices)\n        faces = get_face_properties(vertices)\n        phi_P = analytic_T(centroid[0], centroid[1])\n\n        # --- 2. Dynamic Method Selection ---\n        has_boundary = any(n['type'] == 'boundary' for n in neighbor_data)\n        prefer_wls = has_boundary\n        \n        if not prefer_wls:\n            max_theta = 0.0\n            for i, face in enumerate(faces):\n                neighbor = neighbor_data[i]\n                if neighbor['type'] == 'internal':\n                    d_f = neighbor['centroid'] - centroid\n                else: # Boundary\n                    d_f = face['midpoint'] - centroid\n                \n                cos_theta = np.abs(np.dot(d_f, face['normal'])) / np.linalg.norm(d_f)\n                # Clip to avoid domain errors with arccos\n                cos_theta = np.clip(cos_theta, 0.0, 1.0)\n                theta_deg = np.degrees(np.arccos(cos_theta))\n                if theta_deg > max_theta:\n                    max_theta = theta_deg\n            \n            if max_theta > THETA_STAR:\n                prefer_wls = True\n        \n        # --- 3. Gradient Calculation ---\n        grad = None\n        method_code = 0  # Default to GG (0)\n\n        if prefer_wls:\n            internal_neighbors = [n['centroid'] for n in neighbor_data if n['type'] == 'internal']\n            \n            if len(internal_neighbors)  2:\n                # Revert to GG, not enough neighbors for WLS\n                pass\n            else:\n                # Attempt WLS\n                num_neighbors = len(internal_neighbors)\n                A = np.zeros((num_neighbors, 2))\n                b = np.zeros(num_neighbors)\n                w = np.zeros(num_neighbors)\n\n                for i, neighbor_centroid in enumerate(internal_neighbors):\n                    delta_x = neighbor_centroid - centroid\n                    A[i, :] = delta_x\n                    dist = np.linalg.norm(delta_x)\n                    w[i] = 1.0 / dist\n                    phi_N = analytic_T(neighbor_centroid[0], neighbor_centroid[1])\n                    b[i] = phi_N - phi_P\n                \n                W = np.diag(w)\n                M = A.T @ W @ A\n                \n                rank = np.linalg.matrix_rank(M)\n                if rank  2:\n                    # Revert to GG, rank deficient\n                    pass\n                else:\n                    cond = np.linalg.cond(M)\n                    if cond > KAPPA_MAX:\n                        # Revert to GG, ill-conditioned\n                        pass\n                    else:\n                        # WLS is valid\n                        rhs = A.T @ W @ b\n                        grad = np.linalg.solve(M, rhs)\n                        method_code = 1\n        \n        # Fallback to GG if WLS was not selected or failed\n        if grad is None:\n            grad = calculate_gg_gradient(centroid, area, faces, neighbor_data)\n            method_code = 0\n            \n        # --- 4. Error Evaluation ---\n        exact_grad = analytic_grad_T(centroid[0], centroid[1])\n        error = np.linalg.norm(grad - exact_grad)\n        \n        results.append(f\"[{method_code},{error:.6f}]\")\n\n    print(f\"[{','.join(results)}]\")\n```"
        }
    ]
}