{
    "hands_on_practices": [
        {
            "introduction": "Before diving into the complex machinery of hierarchical matrices, it is essential to appreciate the problem they are designed to solve. This first practice provides a crucial quantitative perspective on the immense computational and memory burdens associated with dense matrices in large-scale boundary element methods. By contrasting the quadratic complexity of a dense approach with the quasi-linear complexity of an H-matrix representation, you will gain a concrete understanding of why these advanced techniques are not just beneficial, but indispensable for tackling realistic problems in computational acoustics .",
            "id": "4115706",
            "problem": "A boundary integral discretization of the three-dimensional time-harmonic acoustic Helmholtz equation yields a dense linear system with $N=10^{5}$ boundary unknowns. The resulting system matrix is complex-valued, and a single matrix entry is stored in double-precision complex format, occupying $16$ bytes. Consider two assembly-and-storage strategies:\n\n1. Dense assembly and storage:\n   - The matrix is fully assembled by evaluating the Green’s function kernel for all source–target pairs. Use as the fundamental base that a pairwise interaction model yields $\\mathcal{O}(N^{2})$ kernel evaluations.\n   - Storage consists of all $N^{2}$ matrix entries.\n\n2. Hierarchical matrices with Adaptive Cross Approximation (ACA):\n   - The domain is hierarchically partitioned into a balanced binary cluster tree of depth $L=\\lceil \\log_{2} N \\rceil$.\n   - Far-field admissible blocks are compressed using low-rank factorizations of rank $r=30$ via Adaptive Cross Approximation (ACA). In a rank-$r$ factorization of an $m \\times n$ block, $U \\in \\mathbb{C}^{m \\times r}$ and $V \\in \\mathbb{C}^{n \\times r}$ are stored, incurring $r(m+n)$ complex numbers.\n   - Use the well-tested property of balanced binary space partitioning with an admissibility condition that the sum, over all far-field blocks at a fixed level $\\ell$, of $(m+n)$ is bounded by $2N$. Consequently, summing across all $L$ levels, the total count of complex numbers required to store all far-field low-rank factors is bounded by $2 r N \\log_{2} N$. Assume near-field contributions are negligible compared to this term at $N=10^{5}$ and $r=30$.\n   - Assume the ACA assembly cost is proportional to the number of stored low-rank degrees of freedom, so the total number of kernel evaluations for far-field blocks is also proportional to $2 r N \\log_{2} N$. Use this proportionality with unit constant to obtain a concrete count.\n\nTasks:\n- Starting from these bases and assumptions, derive explicit formulas for:\n  - The dense storage in bytes and the dense assembly cost in kernel evaluations.\n  - The hierarchical storage in bytes and the hierarchical assembly cost in kernel evaluations.\n- Then, define the compression factor\n  $$S \\equiv \\frac{\\text{dense storage (bytes)}}{\\text{hierarchical storage (bytes)}}.$$\n  Evaluate $S$ for $N=10^{5}$ and $r=30$.\n- For interpretability, you may also express intermediate memory budgets in gigabytes using decimal units, where $1\\,\\mathrm{GB} = 10^{9}$ bytes. However, your final reported value must be the compression factor $S$ as a pure number.\n\nRound your final answer for $S$ to four significant figures. Do not include any units with your final reported number.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the established principles of boundary element methods and hierarchical matrix approximations, specifically Adaptive Cross Approximation (ACA), used in computational acoustics. The problem is well-posed, providing all necessary data, explicit assumptions, and clear definitions, ensuring a unique and meaningful solution can be derived. The parameters and context are realistic for a large-scale scientific computing problem.\n\nWe proceed with the derivation and solution.\n\nThe number of boundary unknowns is $N=10^{5}$. A single matrix entry is stored as a double-precision complex number, occupying $16$ bytes.\n\nFirst, we analyze the dense assembly and storage strategy.\nThe system matrix is of size $N \\times N$.\nThe total number of entries is $N^2$.\nThe storage required for the dense matrix, denoted $D_{\\text{storage}}$, is the total number of entries multiplied by the storage per entry:\n$$D_{\\text{storage}} = N^2 \\times 16 \\text{ bytes}$$\nThe assembly cost, defined as the number of kernel evaluations, is based on the pairwise interaction model, resulting in a cost, denoted $D_{\\text{cost}}$, of:\n$$D_{\\text{cost}} = N^2 \\text{ kernel evaluations}$$\n\nNext, we analyze the hierarchical matrix strategy with Adaptive Cross Approximation (ACA).\nThe rank of the low-rank approximations is given as $r=30$.\nThe problem states that the total count of complex numbers required to store all far-field low-rank factors is bounded by $2 r N \\log_{2} N$, and contributions from the near-field are assumed to be negligible.\nTherefore, the storage for the hierarchical matrix, denoted $H_{\\text{storage}}$, is given by this count multiplied by the storage per complex number:\n$$H_{\\text{storage}} = (2 r N \\log_{2} N) \\times 16 \\text{ bytes}$$\nThe assembly cost for the far-field blocks, denoted $H_{\\text{cost}}$, is assumed to be proportional to the storage with a unit constant, and near-field costs are again neglected.\n$$H_{\\text{cost}} = 2 r N \\log_{2} N \\text{ kernel evaluations}$$\n\nNow, we evaluate these quantities and the compression factor $S$ for the given parameters $N=10^5$ and $r=30$.\n\nFor the dense strategy:\n$D_{\\text{storage}} = (10^5)^2 \\times 16 = 10^{10} \\times 16 = 1.6 \\times 10^{11}$ bytes. Using the conversion $1\\,\\mathrm{GB} = 10^9$ bytes, this is equivalent to $160\\,\\mathrm{GB}$.\n$D_{\\text{cost}} = (10^5)^2 = 10^{10}$ kernel evaluations.\n\nFor the hierarchical strategy, we first compute the value of $\\log_{2} N$:\n$$\n\\log_{2} N = \\log_{2}(10^5) = 5 \\log_{2}(10)\n$$\nUsing the change of base formula, $\\log_{2}(10) = \\frac{\\ln(10)}{\\ln(2)}$.\nNumerically, $\\log_{2}(10^5) \\approx 5 \\times \\frac{2.302585}{0.693147} \\approx 16.60964$.\nNow we can compute the storage and cost:\n$H_{\\text{storage}} = (2 \\times 30 \\times 10^5 \\times \\log_{2}(10^5)) \\times 16 \\approx (60 \\times 10^5 \\times 16.60964) \\times 16 \\approx 9.965784 \\times 10^7 \\times 16 \\approx 1.5945 \\times 10^9$ bytes. This is approximately $1.595\\,\\mathrm{GB}$.\n$H_{\\text{cost}} = 2 \\times 30 \\times 10^5 \\times \\log_{2}(10^5) \\approx 60 \\times 10^5 \\times 16.60964 \\approx 9.966 \\times 10^7$ kernel evaluations.\n\nThe compression factor $S$ is defined as the ratio of the dense storage to the hierarchical storage:\n$$S \\equiv \\frac{D_{\\text{storage}}}{H_{\\text{storage}}}$$\nSubstituting the derived formulas:\n$$S = \\frac{N^2 \\times 16}{(2 r N \\log_{2} N) \\times 16} = \\frac{N^2}{2 r N \\log_{2} N} = \\frac{N}{2 r \\log_{2} N}$$\nThis formula highlights that the compression factor improves linearly with the problem size $N$ and degrades inversely with the rank $r$ and the logarithm of $N$.\n\nWe now evaluate $S$ for the given values:\n$$S = \\frac{10^5}{2 \\times 30 \\times \\log_{2}(10^5)} = \\frac{10^5}{60 \\times \\log_{2}(10^5)}$$\nUsing the previously calculated value for $\\log_{2}(10^5)$:\n$$S \\approx \\frac{100000}{60 \\times 16.60964} \\approx \\frac{100000}{996.5784} \\approx 100.3433$$\nRounding the result to four significant figures gives $100.3$.\nThis means that the hierarchical matrix approach reduces the storage requirement by a factor of approximately $100.3$ compared to the dense matrix approach for this problem size.",
            "answer": "$$\\boxed{100.3}$$"
        },
        {
            "introduction": "Having established the compelling efficiency gains of hierarchical matrices, we now turn to the fundamental mechanism that enables them: geometric partitioning. The ability to compress a matrix relies on distinguishing between \"near-field\" interactions, which must be computed exactly, and \"far-field\" interactions, which can be approximated. This exercise guides you through the implementation of the geometric admissibility criterion, the core decision-making process that classifies matrix blocks and builds the hierarchical structure, thereby laying the practical foundation for the entire method .",
            "id": "4115730",
            "problem": "You are given a computational acoustics context where dense boundary integral equation matrices arising from the time-harmonic acoustic Helmholtz problem are compressed using Adaptive Cross Approximation (ACA) within the framework of hierarchical matrices. The physical model is governed by the Helmholtz equation, and the boundary integral formulation leads to matrices populated by the free-space Green's function. The hierarchical matrix structure requires a geometric admissibility classification of blocks into near-field (not compressed) and far-field (eligible for low-rank representation). Your task is to implement a geometric far-field admissibility test parameterized by a user-chosen separation parameter and to compute the fraction of admissible blocks on a sphere discretized with a given number of panels.\n\nStarting from the following fundamental base:\n- The time-harmonic acoustic field is governed by the Helmholtz equation $ \\nabla^2 p(\\boldsymbol{x}) + k^2 p(\\boldsymbol{x}) = 0 $ with wavenumber $ k $.\n- The free-space Green's function $ G(\\boldsymbol{x},\\boldsymbol{y}) $ for the Helmholtz equation is a smooth function of $ \\boldsymbol{x} $ and $ \\boldsymbol{y} $ when the source and target clusters are sufficiently separated in space relative to their sizes, and this smoothness underlies low-rank approximations in far-field interactions.\n- Hierarchical matrices partition the index set into clusters represented by geometric bounding boxes. Blocks between cluster pairs are classified as far-field or near-field using a geometric criterion that is consistent with the principle that two clusters are far-field if their size is small in comparison to their separation.\n\nImplement the following:\n1. Discretize the unit sphere of radius $ R = 1 $ using $ N $ panels, represented by $ N $ quasi-uniform points $ \\{\\boldsymbol{x}_i\\}_{i=1}^N $ on the sphere surface. Use a well-tested deterministic method that yields near-uniform coverage over the sphere (for example, a Fibonacci lattice) to define the panel locations $ \\boldsymbol{x}_i \\in \\mathbb{R}^3 $ satisfying $ \\|\\boldsymbol{x}_i\\|_2 = R $. No physical units are required in the final result because the output is a dimensionless fraction.\n2. Build a binary spatial cluster tree on the set of points by recursively splitting clusters along the longest axis of their axis-aligned bounding box until each leaf cluster contains at most $ m $ panels, where $ m $ is a fixed integer with $ m \\geq 2 $. Each cluster is associated with its axis-aligned bounding box in $ \\mathbb{R}^3 $ defined by the minimum and maximum corner vectors $ \\boldsymbol{b}^{\\min} \\in \\mathbb{R}^3 $ and $ \\boldsymbol{b}^{\\max} \\in \\mathbb{R}^3 $. The cluster size is quantified using a consistent geometric measure derived from the bounding box, and the separation between two clusters is quantified using the Euclidean distance between their axis-aligned bounding boxes.\n3. Construct a block-cluster tree over the same cluster tree for both rows and columns (the same set, since the boundary is the same for sources and targets). Starting from the pair consisting of the root cluster with itself, recursively generate blocks as follows: if a pair of clusters satisfies a geometric condition that formalizes the principle of size being small relative to separation, then declare this block as far-field and do not subdivide further; otherwise, if both clusters are leaves, declare this block as near-field; if not admissible and at least one cluster is not a leaf, subdivide the side with the larger geometric size (if both non-leaf) or the non-leaf side and recurse on child pairs until one of the previous conditions is met. The recursive process must partition the full interaction matrix indices into a disjoint set of blocks.\n4. Using a chosen separation parameter $ \\eta > 0 $, implement a mathematically sound far-field admissibility test consistent with the above principle. Use the axis-aligned bounding box of each cluster to define its geometric size and the Euclidean minimal distance between two axis-aligned bounding boxes to define separation. The test must be parameterized by $ \\eta $ so that increasing $ \\eta $ makes the classification more permissive.\n5. Compute the fraction of admissible blocks for the block-cluster tree, defined as the number of far-field blocks divided by the total number of blocks in the partition.\n\nYour program must:\n- Use $ R = 1 $ and a fixed leaf size $ m = 16 $ panels per leaf cluster.\n- For each test case, build the cluster tree and block-cluster tree and compute the fraction of admissible blocks as a real number in $ [0,1] $ rounded to six decimal places.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n\nTest suite:\n- Case 1: $ N = 64 $, $ \\eta = 0.5 $.\n- Case 2: $ N = 64 $, $ \\eta = 1.0 $.\n- Case 3: $ N = 64 $, $ \\eta = 2.0 $.\n- Case 4: $ N = 8 $, $ \\eta = 0.5 $.\n- Case 5: $ N = 256 $, $ \\eta = 0.5 $.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., [r_1,r_2,r_3,r_4,r_5]), where each $ r_i $ is the fraction of admissible blocks for the corresponding test case, rounded to six decimal places.",
            "solution": "The problem is valid. It is a well-defined computational task grounded in the established principles of hierarchical matrices used for accelerating boundary element methods. The parameters and objectives are clear, consistent, and scientifically sound.\n\nThe objective is to compute the fraction of admissible (far-field) blocks in a hierarchical matrix partition for a boundary discretized by points on a sphere. This fraction is a key performance indicator for hierarchical matrix algorithms, as it represents the proportion of matrix blocks that can be compressed, thereby reducing computational complexity. The process involves several standard steps from computational science: geometric discretization, hierarchical data structuring, and recursive partitioning based on a geometric admissibility criterion.\n\nThe solution is constructed through the following sequence of steps:\n1.  Generation of quasi-uniformly distributed points on a sphere to represent the discretized boundary.\n2.  Construction of a spatial cluster tree to hierarchically group these points.\n3.  Definition and implementation of a geometric admissibility criterion to classify pairs of clusters as near-field or far-field.\n4.  Construction of a block-cluster tree that partitions the matrix into near-field and far-field blocks, and computation of the resulting fraction of admissible blocks.\n\n**Step 1: Sphere Discretization**\n\nThe first step is to generate a set of $N$ points, $\\{\\boldsymbol{x}_i\\}_{i=1}^N$, that represent panel locations on the surface of a unit sphere of radius $R=1$. For the results to be deterministic and representative, the points must be distributed in a quasi-uniform manner. A Fibonacci lattice provides an effective method for this. The coordinates for the $i$-th point, where $i \\in \\{0, 1, \\dots, N-1\\}$, are generated using spherical coordinates $(\\rho, \\theta, \\phi)$ where $\\rho$ is the radial distance, $\\theta$ is the azimuthal angle, and $\\phi$ is the polar angle. For a unit sphere, $\\rho=1$. The angles are given by:\n$$ \\phi_i = \\arccos\\left(1 - \\frac{2(i+0.5)}{N}\\right) $$\n$$ \\theta_i = \\frac{2\\pi i}{\\Phi} $$\nwhere $\\Phi = \\frac{1+\\sqrt{5}}{2}$ is the golden ratio. The Cartesian coordinates $\\boldsymbol{x}_i = (x_i, y_i, z_i)$ are then obtained via the standard transformation:\n$$ x_i = R \\sin(\\phi_i) \\cos(\\theta_i) $$\n$$ y_i = R \\sin(\\phi_i) \\sin(\\theta_i) $$\n$$ z_i = R \\cos(\\phi_i) $$\nGiven $R=1$, the points lie on the unit sphere, satisfying $\\|\\boldsymbol{x}_i\\|_2 = 1$. These $N$ points form the index set for our problem.\n\n**Step 2: Cluster Tree Construction**\n\nA cluster tree is a hierarchical data structure that spatially organizes the set of points. It is built recursively. Each node in the tree, called a cluster $\\tau$, represents a subset of the point indices $I_\\tau \\subseteq \\{0, 1, \\dots, N-1\\}$ and is associated with an axis-aligned bounding box (AABB), $\\mathcal{B}_\\tau$, that encloses all points $\\{\\boldsymbol{x}_i\\}_{i \\in I_\\tau}$.\n\nThe tree construction proceeds as follows:\n-   The root cluster contains all $N$ point indices.\n-   A recursive function is applied to the root cluster. For a given cluster $\\tau$:\n    1.  If the number of points in the cluster, $|I_\\tau|$, is less than or equal to the leaf size parameter $m$ (given as $m=16$), the cluster is declared a leaf, and the recursion terminates for this branch.\n    2.  Otherwise, the cluster is split into two child clusters. The split is performed along the longest dimension of the cluster's AABB, $\\mathcal{B}_\\tau$. The points are partitioned into two sets based on the median of their coordinates along this dimension. This ensures a balanced spatial partitioning.\n    3.  Two new child clusters are created from these two sets of points, and the recursive function is called on each child.\n\nThis process results in a binary tree where each leaf cluster contains at most $m$ points.\n\n**Step 3: Geometric Admissibility Criterion**\n\nThe core of the hierarchical matrix method is the admissibility criterion, which determines whether the interaction between two clusters $\\tau$ and $\\sigma$ can be approximated. This is based on the principle that the Green's function is smooth for well-separated domains. A standard geometric condition formalizes this by comparing the clusters' sizes to their separation.\n\nFor two clusters, $\\tau$ and $\\sigma$, we define:\n-   **Bounding Box $\\mathcal{B}$**: The AABB for a cluster $\\tau$ is defined by its minimum and maximum corner vectors, $\\boldsymbol{b}_\\tau^{\\min}$ and $\\boldsymbol{b}_\\tau^{\\max}$.\n-   **Diameter $\\text{diam}(\\mathcal{B}_\\tau)$**: The size of a cluster is quantified by the diameter of its AABB, calculated as the Euclidean norm of the box's diagonal: $\\text{diam}(\\mathcal{B}_\\tau) = \\|\\boldsymbol{b}_\\tau^{\\max} - \\boldsymbol{b}_\\tau^{\\min}\\|_2$.\n-   **Distance $\\text{dist}(\\mathcal{B}_\\tau, \\mathcal{B}_\\sigma)$**: The separation between two clusters is the minimum Euclidean distance between their AABBs. This is computed as $\\text{dist}(\\mathcal{B}_\\tau, \\mathcal{B}_\\sigma) = \\left( \\sum_{j=1}^3 \\max(0, b_{\\tau,j}^{\\min} - b_{\\sigma,j}^{\\max}, b_{\\sigma,j}^{\\min} - b_{\\tau,j}^{\\max})^2 \\right)^{1/2}$.\n\nA block corresponding to the cluster pair $(\\tau, \\sigma)$ is declared **admissible** (far-field) if the following condition holds for a given separation parameter $\\eta > 0$:\n$$ \\max(\\text{diam}(\\mathcal{B}_\\tau), \\text{diam}(\\mathcal{B}_\\sigma)) \\le \\eta \\cdot \\text{dist}(\\mathcal{B}_\\tau, \\mathcal{B}_\\sigma) $$\nIf the bounding boxes touch or overlap, $\\text{dist}(\\mathcal{B}_\\tau, \\mathcal{B}_\\sigma) = 0$, and the condition is not satisfied (unless the clusters are single points, with zero diameter). Increasing $\\eta$ relaxes this condition, allowing larger clusters to be considered \"far-field\" at the same distance, thus making the admissibility more permissive.\n\n**Step 4: Block-Cluster Tree and Fraction Calculation**\n\nThe block-cluster tree represents a partition of the full matrix product space $I \\times I$ into disjoint blocks $(\\tau, \\sigma)$. We do not need to explicitly store this tree; we can traverse it recursively to count the number of admissible (far-field) and inadmissible (near-field) leaf blocks.\n\nThe counting is performed with a recursive algorithm, implemented iteratively using a stack to avoid deep recursion issues:\n1.  Initialize a stack with the initial block, `(root, root)`, where `root` is the root of the cluster tree. Initialize counters $N_{\\text{far}} = 0$ and $N_{\\text{near}} = 0$.\n2.  While the stack is not empty, pop a block $(\\tau, \\sigma)$.\n3.  Check if the block is admissible using the criterion from Step 3.\n    -   If yes, increment $N_{\\text{far}}$ and do not subdivide this block further.\n    -   If no, proceed to the next step.\n4.  Check if both $\\tau$ and $\\sigma$ are leaf clusters.\n    -   If yes, this block is an incompressible near-field block. Increment $N_{\\text{near}}$.\n    -   If no, at least one cluster is not a leaf, and the block must be subdivided.\n5.  To subdivide, select the cluster with the larger diameter for splitting. If one cluster is a leaf, the other (non-leaf) one must be split.\n    -   If $\\tau$ is chosen for splitting, push its child-pairs $(\\tau_1, \\sigma)$ and $(\\tau_2, \\sigma)$ onto the stack.\n    -   If $\\sigma$ is chosen for splitting, push $(\\tau, \\sigma_1)$ and $(\\tau, \\sigma_2)$ onto the stack.\n6.  Repeat until the stack is empty.\n\nFinally, the fraction of admissible blocks is computed as:\n$$ \\mathcal{F} = \\frac{N_{\\text{far}}}{N_{\\text{far}} + N_{\\text{near}}} $$\nThis value is calculated for each test case specified in the problem statement, with results rounded to six decimal places. The special case where $N=8$ and $m=16$ results in a cluster tree with only a single root node (which is also a leaf). The block `(root, root)` is inadmissible and cannot be subdivided, resulting in $N_{\\text{near}}=1$ and $N_{\\text{far}}=0$, yielding a fraction of $0.0$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the fraction of admissible blocks in a hierarchical matrix partition\n    for a sphere discretization.\n    \"\"\"\n\n    class Cluster:\n        \"\"\"Represents a cluster of points and its bounding box.\"\"\"\n        def __init__(self, indices, all_points):\n            self.indices = np.array(indices, dtype=int)\n            if self.indices.size > 0:\n                self.points = all_points[self.indices]\n                self.bbox_min = np.min(self.points, axis=0)\n                self.bbox_max = np.max(self.points, axis=0)\n                self.diameter = np.linalg.norm(self.bbox_max - self.bbox_min)\n            else:\n                self.points = np.empty((0, 3))\n                # Define a non-interfering default for empty clusters\n                self.bbox_min = np.full(3, np.inf)\n                self.bbox_max = np.full(3, -np.inf)\n                self.diameter = 0.0\n            self.children = None\n\n    def generate_sphere_points(N, R):\n        \"\"\"Generates N quasi-uniform points on a sphere of radius R using a Fibonacci lattice.\"\"\"\n        if N == 0:\n            return np.empty((0, 3))\n        \n        indices = np.arange(0, N, dtype=float) + 0.5\n        \n        phi = np.arccos(1 - 2 * indices / N)\n        golden_ratio = (1 + 5**0.5) / 2\n        theta = 2 * np.pi * indices / golden_ratio\n        \n        x = R * np.cos(theta) * np.sin(phi)\n        y = R * np.sin(theta) * np.sin(phi)\n        z = R * np.cos(phi)\n        \n        return np.stack([x, y, z], axis=1)\n\n    def build_cluster_tree(cluster, m, all_points):\n        \"\"\"Recursively builds a spatial cluster tree.\"\"\"\n        if len(cluster.indices) = m:\n            return  # This cluster is a leaf\n\n        # Find the longest dimension of the bounding box to split along\n        dims = cluster.bbox_max - cluster.bbox_min\n        split_dim = np.argmax(dims)\n        \n        # Partition points based on the median coordinate\n        coords = cluster.points[:, split_dim]\n        median = np.median(coords)\n        \n        left_indices = cluster.indices[coords  median]\n        right_indices = cluster.indices[coords >= median]\n\n        # Handle degenerate cases where one child would be empty\n        if len(left_indices) == 0 or len(right_indices) == 0:\n            mid_idx = len(cluster.indices) // 2\n            left_indices = cluster.indices[:mid_idx]\n            right_indices = cluster.indices[mid_idx:]\n\n        cluster.children = [\n            Cluster(left_indices, all_points),\n            Cluster(right_indices, all_points)\n        ]\n        \n        for child in cluster.children:\n            build_cluster_tree(child, m, all_points)\n\n    def is_admissible(c_tau, c_sigma, eta):\n        \"\"\"Checks if the block (c_tau, c_sigma) is admissible.\"\"\"\n        dist_sq = 0.0\n        for i in range(3):\n            d = max(0.0, c_tau.bbox_min[i] - c_sigma.bbox_max[i], c_sigma.bbox_min[i] - c_tau.bbox_max[i])\n            dist_sq += d * d\n        \n        if dist_sq == 0:\n            return False  # Bounding boxes overlap or touch\n        \n        dist = np.sqrt(dist_sq)\n        max_diam = max(c_tau.diameter, c_sigma.diameter)\n        \n        return max_diam = eta * dist\n\n    def count_blocks(root, eta):\n        \"\"\"Counts far-field and near-field blocks in the block-cluster tree.\"\"\"\n        far_count = 0\n        near_count = 0\n        \n        if root is None:\n            return 0, 0\n        \n        stack = [(root, root)]\n        \n        while stack:\n            c_tau, c_sigma = stack.pop()\n            \n            if is_admissible(c_tau, c_sigma, eta):\n                far_count += 1\n                continue\n            \n            # If not admissible, check if we must stop subdividing\n            if c_tau.children is None and c_sigma.children is None:\n                near_count += 1\n                continue\n                \n            # If we can subdivide, determine which cluster to split\n            split_tau = (c_tau.children is not None) and \\\n                        ((c_sigma.children is None) or (c_tau.diameter >= c_sigma.diameter))\n\n            if split_tau:\n                for child_tau in c_tau.children:\n                    stack.append((child_tau, c_sigma))\n            else:  # split_sigma\n                for child_sigma in c_sigma.children:\n                    stack.append((c_tau, child_sigma))\n\n        return far_count, near_count\n\n    R = 1.0\n    m = 16\n    \n    test_cases = [\n        (64, 0.5),\n        (64, 1.0),\n        (64, 2.0),\n        (8, 0.5),\n        (256, 0.5),\n    ]\n\n    results = []\n    for N, eta in test_cases:\n        points = generate_sphere_points(N, R)\n        \n        if N > 0:\n            root = Cluster(range(N), points)\n            build_cluster_tree(root, m, points)\n            far_blocks, near_blocks = count_blocks(root, eta)\n            total_blocks = far_blocks + near_blocks\n        \n            if total_blocks > 0:\n                fraction = far_blocks / total_blocks\n            else:\n                fraction = 0.0\n        else:\n            fraction = 0.0\n\n        results.append(round(fraction, 6))\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a block is deemed admissible, the next critical question is how efficiently it can be compressed. The rank required for an accurate approximation is not a fixed number but is deeply tied to the physical properties of the interaction kernel and the geometry of the underlying domains. This final practice explores this subtlety by comparing the rank needed for flat versus curved surfaces . By investigating how surface curvature influences the separability of the Green's function, you will develop a deeper intuition for the \"adaptive\" nature of Adaptive Cross Approximation (ACA) and the factors that govern its performance.",
            "id": "4115747",
            "problem": "Consider the time-harmonic acoustic field governed by the Helmholtz equation in three-dimensional free space and its associated free-space Green's function. For source point $\\mathbf{x}$ and field point $\\mathbf{y}$, the outgoing Green's function is given by\n$$\nG_k(\\mathbf{x}, \\mathbf{y}) = \\frac{e^{i k \\|\\mathbf{x}-\\mathbf{y}\\|}}{4\\pi \\|\\mathbf{x}-\\mathbf{y}\\|},\n$$\nwhere $k$ is the wavenumber in $\\text{m}^{-1}$, $i$ is the imaginary unit, and $\\|\\cdot\\|$ denotes the Euclidean norm in meters. In boundary integral formulations of computational acoustics, discrete panels of boundary points induce interaction submatrices whose entries are given by $G_k(\\mathbf{x}_p,\\mathbf{y}_q)$ for panel points $\\{\\mathbf{x}_p\\}$ and $\\{\\mathbf{y}_q\\}$.\n\nAdaptive Cross Approximation (ACA), defined here as the iterative construction of a low-rank separable sum $A \\approx \\sum_{r=1}^{R} \\mathbf{u}_r \\mathbf{v}_r^{\\top}$ by selecting pivot elements from the current residual matrix and updating the residual by subtracting the outer product $\\mathbf{u}_r \\mathbf{v}_r^{\\top}$ until the residual norm is sufficiently small, is a central tool in building Hierarchical Matrices (H-matrices). The ACA termination criterion is based on the relative Frobenius norm of the residual:\n$$\n\\frac{\\|A - \\sum_{r=1}^{R} \\mathbf{u}_r \\mathbf{v}_r^{\\top}\\|_F}{\\|A\\|_F} \\le \\varepsilon,\n$$\nwhere $\\varepsilon$ is a prescribed tolerance.\n\nIn this problem, you will construct and compare the ACA rank required to approximate interaction blocks for two geometries at equal values of $k$ and panel size $L$:\n\n- Geometry $1$ (flat plate): two parallel, square panels of side length $L$ lying in planes $z=0$ and $z=d$, respectively, with their centers aligned on the $z$-axis. Each panel is discretized by a uniform grid of $n\\times n$ points over the square domain $\\{(x,y) : x,y \\in [-L/2, L/2]\\}$.\n\n- Geometry $2$ (curved sphere): two small curved patches on a sphere of radius $R$ with geodesic side length approximately $L$. The first patch is centered at the north pole with unit normal $\\mathbf{c}_1 = (0,0,1)$. The second patch is centered at a point obtained by rotating $\\mathbf{c}_1$ by an angle $\\gamma$ about the $y$-axis, where $\\gamma$ is chosen so that the chord distance between the two patch centers equals $d$, i.e.,\n$$\n\\gamma = 2\\arcsin\\left(\\frac{d}{2R}\\right).\n$$\nFor each patch, define two orthonormal tangent directions $\\mathbf{t}_1$ and $\\mathbf{t}_2$ at the patch center, and parametrize patch points by small tangent offsets of size $u$ and $v$ along these directions. The patch points are constructed by normalization onto the sphere:\n$$\n\\mathbf{x}(u,v) = R \\cdot \\frac{\\mathbf{c} + \\frac{u}{R}\\mathbf{t}_1 + \\frac{v}{R}\\mathbf{t}_2}{\\left\\|\\mathbf{c} + \\frac{u}{R}\\mathbf{t}_1 + \\frac{v}{R}\\mathbf{t}_2\\right\\|},\n$$\nwith $u,v \\in [-L/2, L/2]$ and angles measured in radians. Each patch is discretized by a uniform grid of $n\\times n$ points over the square parameter domain for $(u,v)$.\n\nFor each geometry, assemble the interaction matrix $A \\in \\mathbb{C}^{N\\times N}$, where $N = n^2$, with entries\n$$\nA_{pq} = G_k(\\mathbf{x}_p, \\mathbf{y}_q),\n$$\nand compute the minimal ACA rank required to achieve the tolerance $\\varepsilon$ in the relative Frobenius norm sense. Use the fully pivoted ACA strategy in which, at each iteration, the pivot $(i,j)$ is chosen as the index of the maximal absolute value entry in the current residual, and the update uses $\\mathbf{u} = \\mathbf{R}[:,j]/\\mathbf{R}[i,j]$ and $\\mathbf{v} = \\mathbf{R}[i,:]$.\n\nYour tasks:\n- Implement the geometry discretizations exactly as described above, with all lengths in meters and angles in radians.\n- Assemble the Helmholtz interaction matrices using the Green's function $G_k$ as given above.\n- Implement the ACA algorithm and compute the minimal rank $R$ such that the relative Frobenius norm of the residual is at most $\\varepsilon$.\n- Compare the ACA ranks between the flat plate and curved sphere geometries at equal $k$ and $L$ for the test suite below.\n\nScientific foundations you may use:\n- The Helmholtz equation and its free-space Green's function $G_k$.\n- The concept of separable approximations of smooth kernels on well-separated domains.\n- The definition of the Frobenius norm and basic properties of low-rank matrix approximations.\n\nTest suite:\n- Case $1$ (happy path, near-flat sphere): $k=10\\,\\text{m}^{-1}$, $L=0.3\\,\\text{m}$, $d=1.0\\,\\text{m}$, $R=1000.0\\,\\text{m}$, $n=16$, $\\varepsilon=10^{-3}$.\n- Case $2$ (moderate curvature, moderate frequency): $k=10\\,\\text{m}^{-1}$, $L=0.3\\,\\text{m}$, $d=1.0\\,\\text{m}$, $R=5.0\\,\\text{m}$, $n=16$, $\\varepsilon=10^{-3}$.\n- Case $3$ (moderate curvature, higher frequency): $k=40\\,\\text{m}^{-1}$, $L=0.3\\,\\text{m}$, $d=1.0\\,\\text{m}$, $R=5.0\\,\\text{m}$, $n=16$, $\\varepsilon=10^{-3}$.\n- Case $4$ (strong curvature, high frequency, boundary admissible): $k=80\\,\\text{m}^{-1}$, $L=0.3\\,\\text{m}$, $d=1.0\\,\\text{m}$, $R=2.0\\,\\text{m}$, $n=16$, $\\varepsilon=10^{-3}$.\n\nAll physical quantities must be interpreted in meters and $\\text{m}^{-1}$, and angles in radians. The ACA rank is dimensionless and must be reported as integers.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists, with each inner list containing two integers $[R_{\\text{flat}}, R_{\\text{sphere}}]$ for the corresponding test case, enclosed in square brackets. For example, the output should look like\n[[R_flat,1,R_sphere,1],[R_flat,2,R_sphere,2],...].",
            "solution": "The objective of this problem is to compute and compare the rank of a low-rank approximation obtained via Adaptive Cross Approximation (ACA) for two distinct geometric configurations of interacting point sets. The interaction is governed by the free-space Green's function for the time-harmonic Helmholtz equation.\n\nThe governing integral kernel is the three-dimensional free-space Helmholtz Green's function, which describes the field at a point $\\mathbf{y}$ due to a point source at $\\mathbf{x}$. It is given by:\n$$\nG_k(\\mathbf{x}, \\mathbf{y}) = \\frac{e^{i k \\|\\mathbf{x}-\\mathbf{y}\\|}}{4\\pi \\|\\mathbf{x}-\\mathbf{y}\\|}\n$$\nwhere $k$ is the wavenumber, $i = \\sqrt{-1}$, and $\\|\\cdot\\|$ is the Euclidean norm. The problem involves two sets of points, a source set $\\{\\mathbf{x}_p\\}_{p=1}^{N}$ and a field set $\\{\\mathbf{y}_q\\}_{q=1}^{N}$, where $N=n^2$. These sets form an interaction matrix $A \\in \\mathbb{C}^{N \\times N}$ with entries $A_{pq} = G_k(\\mathbf{x}_p, \\mathbf{y}_q)$.\n\nThe geometries for the point sets are defined as follows:\n\n1.  **Geometry 1 (Flat Plates):** Two parallel, square panels are considered. The source panel's points $\\{\\mathbf{x}_p\\}$ lie in the $z=0$ plane, and the field panel's points $\\{\\mathbf{y}_q\\}$ lie in the $z=d$ plane. Both panels are of side length $L$ and are centered on the $z$-axis. The points are generated from a uniform $n \\times n$ grid on the domain $[-L/2, L/2] \\times [-L/2, L/2]$. Let the grid coordinates be $(u_i, v_j)$, where $u_i = -L/2 + i \\frac{L}{n-1}$ and $v_j = -L/2 + j \\frac{L}{n-1}$ for $i,j \\in \\{0, 1, \\dots, n-1\\}$. The point sets are then:\n    $$\n    \\{\\mathbf{x}_p\\} = \\{(u_i, v_j, 0) \\mid i,j \\in \\{0, \\dots, n-1\\}\\}\n    $$\n    $$\n    \\{\\mathbf{y}_q\\} = \\{(u_i, v_j, d) \\mid i,j \\in \\{0, \\dots, n-1\\}\\}\n    $$\n\n2.  **Geometry 2 (Curved Sphere Patches):** Two curved patches on a sphere of radius $R$ are considered. The center of the source patch is at the north pole, corresponding to a unit normal vector $\\mathbf{c}_1 = (0,0,1)$. The center of the field patch is defined by a normal vector $\\mathbf{c}_2$ obtained by rotating $\\mathbf{c}_1$ by an angle $\\gamma$ about the $y$-axis. The angle $\\gamma$ is chosen such that the chord distance between the patch centers is $d$, giving $\\gamma = 2\\arcsin(d/(2R))$.\n    The point sets are generated by projecting a planar $n \\times n$ grid of parameters $(u,v) \\in [-L/2, L/2] \\times [-L/2, L/2]$ onto the sphere. For a patch centered at $\\mathbf{c}$ with orthogonal tangent vectors $\\mathbf{t}_1$ and $\\mathbf{t}_2$, a point is given by:\n    $$\n    \\mathbf{p}(u,v) = R \\cdot \\frac{\\mathbf{c} + \\frac{u}{R}\\mathbf{t}_1 + \\frac{v}{R}\\mathbf{t}_2}{\\left\\|\\mathbf{c} + \\frac{u}{R}\\mathbf{t}_1 + \\frac{v}{R}\\mathbf{t}_2\\right\\|}\n    $$\n    -   For the source patch centered at $\\mathbf{c}_1=(0,0,1)$, a canonical choice for tangent vectors is $\\mathbf{t}_{1,1}=(1,0,0)$ and $\\mathbf{t}_{1,2}=(0,1,0)$.\n    -   The rotation matrix about the $y$-axis by an angle $\\gamma$ is $$M_y(\\gamma) = \\begin{pmatrix} \\cos\\gamma  0  \\sin\\gamma \\\\ 0  1  0 \\\\ -\\sin\\gamma  0  \\cos\\gamma \\end{pmatrix}.$$ The center and tangent vectors for the field patch are obtained by rotating those of the source patch:\n        $$\n        \\mathbf{c}_2 = M_y(\\gamma)\\mathbf{c}_1 = (\\sin\\gamma, 0, \\cos\\gamma)\n        $$\n        $$\n        \\mathbf{t}_{2,1} = M_y(\\gamma)\\mathbf{t}_{1,1} = (\\cos\\gamma, 0, -\\sin\\gamma)\n        $$\n        $$\n        \\mathbf{t}_{2,2} = M_y(\\gamma)\\mathbf{t}_{1,2} = (0,1,0)\n        $$\n    The point sets $\\{\\mathbf{x}_p\\}$ and $\\{\\mathbf{y}_q\\}$ are generated using the parameter grid $(u_i, v_j)$ with their respective centers and tangent vectors.\n\nThe Adaptive Cross Approximation (ACA) algorithm is employed to find a low-rank approximation $\\tilde{A}_R = \\sum_{r=1}^{R} \\mathbf{u}_r \\mathbf{v}_r^{\\top}$ of the matrix $A$. The algorithm proceeds iteratively as follows:\n1.  Initialize the residual matrix $\\mathbf{R}^{(0)} = A$, the rank $r=0$. Compute the Frobenius norm of the original matrix, $\\|A\\|_F$.\n2.  At each iteration $r=1, 2, \\dots$:\n    a. Find the pivot element $(i_r, j_r)$ corresponding to the entry of maximum absolute value in the current residual $\\mathbf{R}^{(r-1)}$. Let this value be $\\delta_r = \\mathbf{R}^{(r-1)}[i_r, j_r]$.\n    b. If $|\\delta_r|$ is numerically zero, the algorithm terminates.\n    c. Define the update vectors as specified:\n       $$\n       \\mathbf{u}_r = \\mathbf{R}^{(r-1)}[:, j_r] / \\delta_r\n       $$\n       $$\n       \\mathbf{v}_r = \\mathbf{R}^{(r-1)}[i_r, :]\n       $$\n    d. Update the residual matrix by subtracting the rank-1 outer product:\n       $$\n       \\mathbf{R}^{(r)} = \\mathbf{R}^{(r-1)} - \\mathbf{u}_r \\mathbf{v}_r^{\\top}\n       $$\n3.  The iteration stops when the minimal rank $R$ is found such that the relative Frobenius norm of the residual falls below a tolerance $\\varepsilon$:\n    $$\n    \\frac{\\|\\mathbf{R}^{(R)}\\|_F}{\\|A\\|_F} = \\frac{\\|A - \\sum_{r=1}^{R} \\mathbf{u}_r \\mathbf{v}_r^{\\top}\\|_F}{\\|A\\|_F} \\leq \\varepsilon\n    $$\nThe algorithm will be executed for each geometry and each set of parameters in the test suite to determine the required ACA rank $R$.",
            "answer": "```python\nimport numpy as np\n\ndef generate_flat_panels(L, d, n):\n    \"\"\"\n    Generates point coordinates for two parallel flat square panels.\n    \"\"\"\n    N = n * n\n    grid_1d = np.linspace(-L / 2, L / 2, n)\n    xx, yy = np.meshgrid(grid_1d, grid_1d)\n    x_coords = xx.flatten()\n    y_coords = yy.flatten()\n    \n    panel1_pts = np.zeros((N, 3))\n    panel1_pts[:, 0] = x_coords\n    panel1_pts[:, 1] = y_coords\n    \n    panel2_pts = np.zeros((N, 3))\n    panel2_pts[:, 0] = x_coords\n    panel2_pts[:, 1] = y_coords\n    panel2_pts[:, 2] = d\n    \n    return panel1_pts, panel2_pts\n\ndef generate_spherical_patches(L, d, R_sphere, n):\n    \"\"\"\n    Generates point coordinates for two curved patches on a sphere.\n    \"\"\"\n    if d > 2 * R_sphere:\n        raise ValueError(\"Distance d cannot be greater than the sphere diameter 2R.\")\n    \n    N = n * n\n    gamma = 2.0 * np.arcsin(d / (2.0 * R_sphere))\n    \n    grid_1d = np.linspace(-L / 2, L / 2, n)\n    u_grid, v_grid = np.meshgrid(grid_1d, grid_1d)\n    u_coords = u_grid.flatten()\n    v_coords = v_grid.flatten()\n    \n    # Patch 1 (source) - centered at north pole\n    c1 = np.array([0.0, 0.0, 1.0])\n    t11 = np.array([1.0, 0.0, 0.0])\n    t12 = np.array([0.0, 1.0, 0.0])\n    \n    panel1_pts = np.zeros((N, 3))\n    for i in range(N):\n        vec = c1 + (u_coords[i] / R_sphere) * t11 + (v_coords[i] / R_sphere) * t12\n        panel1_pts[i, :] = R_sphere * vec / np.linalg.norm(vec)\n        \n    # Patch 2 (field) - rotated from patch 1\n    cos_g, sin_g = np.cos(gamma), np.sin(gamma)\n    rot_mat_y = np.array([[cos_g, 0, sin_g], [0, 1, 0], [-sin_g, 0, cos_g]])\n    \n    c2 = rot_mat_y @ c1\n    t21 = rot_mat_y @ t11\n    t22 = rot_mat_y @ t12\n    \n    panel2_pts = np.zeros((N, 3))\n    for i in range(N):\n        vec = c2 + (u_coords[i] / R_sphere) * t21 + (v_coords[i] / R_sphere) * t22\n        panel2_pts[i, :] = R_sphere * vec / np.linalg.norm(vec)\n\n    return panel1_pts, panel2_pts\n\ndef assemble_matrix(panel1, panel2, k):\n    \"\"\"\n    Assembles the Helmholtz Green's function interaction matrix.\n    \"\"\"\n    N = panel1.shape[0]\n    A = np.zeros((N, N), dtype=np.complex128)\n    \n    for p in range(N):\n        for q in range(N):\n            dist = np.linalg.norm(panel1[p, :] - panel2[q, :])\n            if dist > 1e-12: # Avoid singularity if points coincide\n                A[p, q] = np.exp(1j * k * dist) / (4.0 * np.pi * dist)\n    return A\n\ndef compute_aca_rank(A, epsilon):\n    \"\"\"\n    Computes the minimal ACA rank for a given tolerance.\n    \"\"\"\n    N = A.shape[0]\n    norm_A_F = np.linalg.norm(A, 'fro')\n    \n    if norm_A_F == 0:\n        return 0\n        \n    R_matrix = A.copy()\n    \n    max_rank = N \n    for rank in range(1, max_rank + 1):\n        pivot_idx_flat = np.argmax(np.abs(R_matrix))\n        i, j = np.unravel_index(pivot_idx_flat, R_matrix.shape)\n        \n        pivot_val = R_matrix[i, j]\n        \n        if np.abs(pivot_val)  1e-16: # Numerically zero matrix\n            return rank - 1\n\n        u = R_matrix[:, j] / pivot_val\n        v = R_matrix[i, :]\n        \n        R_matrix -= np.outer(u, v)\n        \n        norm_R_F = np.linalg.norm(R_matrix, 'fro')\n\n        if norm_R_F / norm_A_F = epsilon:\n            return rank\n            \n    return max_rank\n\ndef solve():\n    test_cases = [\n        # k, L, d, R, n, epsilon\n        (10.0, 0.3, 1.0, 1000.0, 16, 1e-3),\n        (10.0, 0.3, 1.0, 5.0, 16, 1e-3),\n        (40.0, 0.3, 1.0, 5.0, 16, 1e-3),\n        (80.0, 0.3, 1.0, 2.0, 16, 1e-3),\n    ]\n\n    all_results = []\n    for k, L, d, R, n, eps in test_cases:\n        # Geometry 1: Flat plates\n        p1_flat, p2_flat = generate_flat_panels(L, d, n)\n        A_flat = assemble_matrix(p1_flat, p2_flat, k)\n        rank_flat = compute_aca_rank(A_flat, eps)\n\n        # Geometry 2: Spherical patches\n        p1_sphere, p2_sphere = generate_spherical_patches(L, d, R, n)\n        A_sphere = assemble_matrix(p1_sphere, p2_sphere, k)\n        rank_sphere = compute_aca_rank(A_sphere, eps)\n\n        all_results.append([rank_flat, rank_sphere])\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}