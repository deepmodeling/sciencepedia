{
    "hands_on_practices": [
        {
            "introduction": "The construction of finite difference schemes is rooted in the rigorous application of Taylor series expansions. This exercise provides foundational practice in the method of undetermined coefficients, challenging you to derive the specific weights for a fourth-order accurate forward-difference scheme. Mastering this technique is essential for developing custom stencils, particularly for implementing high-order boundary conditions where centered stencils are not applicable.",
            "id": "2401286",
            "problem": "Consider a sufficiently smooth function $f$ defined on an interval containing the nodes $x_i, x_{i+1}, x_{i+2}, x_{i+3}, x_{i+4}$ of a uniform grid with spacing $h>0$, where $x_{j} = x_{0} + j h$. Assume that $f$ has at least $5$ continuous derivatives on $[x_i, x_{i+4}]$. Using only the values $f(x_i)$, $f(x_{i+1})$, $f(x_{i+2})$, $f(x_{i+3})$, and $f(x_{i+4})$, construct a forward-difference approximation to the first derivative $f'(x_i)$ that is accurate through order $h^{4}$ (that is, has truncation error of order $\\mathcal{O}(h^{4})$). \n\nDetermine the unique coefficients $a_0, a_1, a_2, a_3, a_4 \\in \\mathbb{R}$ such that\n$$\nf'(x_i) \\approx \\frac{1}{h}\\sum_{k=0}^{4} a_k\\, f(x_{i+k})\n$$\nachieves fourth-order accuracy, and provide the resulting closed-form approximation as a single analytic expression.\n\nAnswer specification:\n- Provide your final result as a single closed-form analytic expression for the approximation to $f'(x_i)$ in terms of $f(x_{i+k})$ and $h$.\n- No rounding is required.",
            "solution": "The given problem is a standard and well-posed exercise in the field of numerical analysis, specifically the derivation of finite difference formulas. It is scientifically sound, logically consistent, and all required information is provided. Therefore, it is valid, and I will proceed with its solution.\n\nThe objective is to find coefficients $a_0, a_1, a_2, a_3, a_4$ for the approximation\n$$\nf'(x_i) \\approx \\frac{1}{h}\\sum_{k=0}^{4} a_k f(x_{i+k})\n$$\nsuch that the truncation error is of order $\\mathcal{O}(h^4)$. This is a direct application of the method of undetermined coefficients using Taylor series expansions.\n\nThe function $f$ is assumed to be sufficiently smooth, allowing us to expand each term $f(x_{i+k})$ in a Taylor series around the point $x_i$. The expansion is given by:\n$$\nf(x_{i+k}) = f(x_i + kh) = \\sum_{j=0}^{\\infty} \\frac{(kh)^j}{j!} f^{(j)}(x_i)\n$$\nwhere $f^{(j)}(x_i)$ denotes the $j$-th derivative of $f$ evaluated at $x_i$.\n\nSubstituting this expansion into the finite difference formula, we obtain:\n$$\n\\frac{1}{h}\\sum_{k=0}^{4} a_k f(x_{i+k}) = \\frac{1}{h}\\sum_{k=0}^{4} a_k \\left( \\sum_{j=0}^{\\infty} \\frac{(kh)^j}{j!} f^{(j)}(x_i) \\right)\n$$\nBy interchanging the order of summation, which is permissible here, we get:\n$$\n\\frac{1}{h}\\sum_{j=0}^{\\infty} \\frac{h^j f^{(j)}(x_i)}{j!} \\left( \\sum_{k=0}^{4} k^j a_k \\right)\n$$\nWe want this expression to approximate $f'(x_i)$ with a truncation error of $\\mathcal{O}(h^4)$. This means that when we expand the expression in powers of $h$, the coefficient of $f'(x_i)$ must be $1$, and the coefficients of $f(x_i)$, $f''(x_i)$, $f'''(x_i)$, and $f^{(4)}(x_i)$ must be $0$.\n\nLet's examine the terms for $j=0, 1, 2, 3, 4$:\n\\begin{itemize}\n    \\item For $j=0$: The term is $\\frac{1}{h} \\frac{h^0 f^{(0)}(x_i)}{0!} \\left( \\sum_{k=0}^{4} a_k \\right) = \\frac{f(x_i)}{h} \\sum_{k=0}^{4} a_k$. To eliminate this term, we must have:\n    $$ \\sum_{k=0}^{4} a_k = 0 $$\n    \\item For $j=1$: The term is $\\frac{1}{h} \\frac{h^1 f^{(1)}(x_i)}{1!} \\left( \\sum_{k=0}^{4} k a_k \\right) = f'(x_i) \\sum_{k=0}^{4} k a_k$. For this to equal $f'(x_i)$, we require:\n    $$ \\sum_{k=0}^{4} k a_k = 1 $$\n    \\item For $j=2$: The term is $\\frac{1}{h} \\frac{h^2 f^{(2)}(x_i)}{2!} \\left( \\sum_{k=0}^{4} k^2 a_k \\right) = \\frac{h f''(x_i)}{2} \\sum_{k=0}^{4} k^2 a_k$. To eliminate the $\\mathcal{O}(h)$ error term, we must have:\n    $$ \\sum_{k=0}^{4} k^2 a_k = 0 $$\n    \\item For $j=3$: The term is $\\frac{1}{h} \\frac{h^3 f^{(3)}(x_i)}{3!} \\left( \\sum_{k=0}^{4} k^3 a_k \\right) = \\frac{h^2 f'''(x_i)}{6} \\sum_{k=0}^{4} k^3 a_k$. To eliminate the $\\mathcal{O}(h^2)$ error term:\n    $$ \\sum_{k=0}^{4} k^3 a_k = 0 $$\n    \\item For $j=4$: The term is $\\frac{1}{h} \\frac{h^4 f^{(4)}(x_i)}{4!} \\left( \\sum_{k=0}^{4} k^4 a_k \\right) = \\frac{h^3 f^{(4)}(x_i)}{24} \\sum_{k=0}^{4} k^4 a_k$. To eliminate the $\\mathcal{O}(h^3)$ error term:\n    $$ \\sum_{k=0}^{4} k^4 a_k = 0 $$\n\\end{itemize}\nThe leading term of the truncation error will then be the term for $j=5$, which is of order $\\mathcal{O}(h^4)$, as required by the problem statement.\n\nThese five conditions yield a system of five linear equations for the five unknown coefficients $a_0, a_1, a_2, a_3, a_4$:\n\\begin{align*}\n    a_0 + a_1 + a_2 + a_3 + a_4 &= 0 \\\\\n    0 \\cdot a_0 + 1 \\cdot a_1 + 2 \\cdot a_2 + 3 \\cdot a_3 + 4 \\cdot a_4 &= 1 \\\\\n    0^2 a_0 + 1^2 a_1 + 2^2 a_2 + 3^2 a_3 + 4^2 a_4 &= 0 \\\\\n    0^3 a_0 + 1^3 a_1 + 2^3 a_2 + 3^3 a_3 + 4^3 a_4 &= 0 \\\\\n    0^4 a_0 + 1^4 a_1 + 2^4 a_2 + 3^4 a_3 + 4^4 a_4 &= 0\n\\end{align*}\nThis system can be written in matrix form as:\n$$\n\\begin{pmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 1 & 4 & 9 & 16 \\\\\n0 & 1 & 8 & 27 & 64 \\\\\n0 & 1 & 16 & 81 & 256\n\\end{pmatrix}\n\\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe sub-system for $a_1, a_2, a_3, a_4$ involves a Vandermonde-type matrix. Solving this $4 \\times 4$ system and then using the first equation to find $a_0$ is a straightforward, albeit tedious, procedure. The unique solution to this system is:\n$$ a_0 = -\\frac{25}{12}, \\quad a_1 = 4, \\quad a_2 = -3, \\quad a_3 = \\frac{4}{3}, \\quad a_4 = -\\frac{1}{4} $$\nTo facilitate a cleaner final expression, we can write these coefficients with a common denominator of $12$:\n$$ a_0 = -\\frac{25}{12}, \\quad a_1 = \\frac{48}{12}, \\quad a_2 = -\\frac{36}{12}, \\quad a_3 = \\frac{16}{12}, \\quad a_4 = -\\frac{3}{12} $$\nSubstituting these coefficients into the approximation formula:\n$$\nf'(x_i) \\approx \\frac{1}{h} \\left( -\\frac{25}{12}f(x_i) + \\frac{48}{12}f(x_{i+1}) - \\frac{36}{12}f(x_{i+2}) + \\frac{16}{12}f(x_{i+3}) - \\frac{3}{12}f(x_{i+4}) \\right)\n$$\nFactoring out the common denominator of $12$ gives the final closed-form expression for the fourth-order accurate forward-difference approximation to the first derivative:\n$$\nf'(x_i) \\approx \\frac{1}{12h} \\left( -25f(x_i) + 48f(x_{i+1}) - 36f(x_{i+2}) + 16f(x_{i+3}) - 3f(x_{i+4}) \\right)\n$$\nThis completes the derivation.",
            "answer": "$$\\boxed{\\frac{1}{12h} \\left( -25f(x_i) + 48f(x_{i+1}) - 36f(x_{i+2}) + 16f(x_{i+3}) - 3f(x_{i+4}) \\right)}$$"
        },
        {
            "introduction": "The celebrated accuracy of high-order schemes relies on the assumption of function smoothness, a condition often violated in physical problems involving shocks, material interfaces, or sharp corners. This hands-on investigation demonstrates the practical consequences of this limitation by applying a fourth-order central difference scheme to a function with a simple kink. Through this exercise, you will numerically observe the degradation of accuracy, a phenomenon known as order reduction, and learn to critically assess when and where high-order methods are appropriate.",
            "id": "3227834",
            "problem": "You are to investigate the behavior of a high-order finite difference approximation for the first derivative when applied to a function with a non-differentiable point. The foundational starting point is the Taylor series expansion of a sufficiently smooth function around a point. Begin from the definition that, for a function $f$ that is at least five times continuously differentiable near a point $x$, the values $f(x \\pm h)$ and $f(x \\pm 2h)$ admit Taylor series expansions about $x$. Using these expansions, derive a central finite difference approximation that uses the values at $x - 2h$, $x - h$, $x + h$, and $x + 2h$ to approximate $f'(x)$ with a truncation error that is proportional to $h^4$ for functions that are sufficiently smooth.\n\nOnce you have derived the high-order scheme, implement it and test its performance on the function $f(x) = |x - 0.5|$ over the interval $[0,1]$ using a uniform grid with $n$ points, so that the grid spacing is $h = \\frac{1}{n - 1}$ and the grid points are $x_i = i h$ for $i = 0, 1, \\dots, n - 1$. The exact derivative of $f$ is given by $f'(x) = -1$ for $x < 0.5$ and $f'(x) = +1$ for $x > 0.5$, and it is undefined at $x = 0.5$. To ensure scientific realism, treat the point $x = 0.5$ as excluded from any error metric because $f'(0.5)$ is undefined.\n\nDefine the derivative approximation only at interior points $x_i$ for $i = 2, 3, \\dots, n - 3$ so that the four-point central stencil fits within the interval. Classify each interior stencil as either \"smooth-region\" or \"corner-crossing\" as follows:\n- A stencil centered at $x_i$ is \"smooth-region\" if both $x_{i-2}$ and $x_{i+2}$ lie strictly on the same side of $0.5$, that is, either $x_{i+2} \\le 0.5$ or $x_{i-2} \\ge 0.5$.\n- A stencil centered at $x_i$ is \"corner-crossing\" if it straddles the corner, that is, $x_{i-2} < 0.5 < x_{i+2}$.\n\nFor each value of $n$ in the provided test suite, compute the following three error metrics, expressed as real numbers (floating point):\n- $E_{\\text{all}}$: the maximum absolute error over all interior points $x_i$, excluding any point for which $x_i = 0.5$.\n- $E_{\\text{smooth}}$: the maximum absolute error restricted to interior points with \"smooth-region\" stencils.\n- $E_{\\text{cross}}$: the maximum absolute error restricted to interior points with \"corner-crossing\" stencils. If no stencil is corner-crossing for a given $n$, define $E_{\\text{cross}} = 0$.\n\nUse the following test suite of grid sizes:\n- $n = 11$ (coarse grid with $0.5$ as a grid point),\n- $n = 12$ (coarse grid without $0.5$ as a grid point),\n- $n = 101$ (fine grid with $0.5$ as a grid point),\n- $n = 102$ (fine grid without $0.5$ as a grid point).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case produces a list $[E_{\\text{all}}, E_{\\text{smooth}}, E_{\\text{cross}}]$, and the overall output is a list of these lists, in the same order as the test suite. For example, the required output format is $[[E_{\\text{all}}^{(11)}, E_{\\text{smooth}}^{(11)}, E_{\\text{cross}}^{(11)}],[E_{\\text{all}}^{(12)}, E_{\\text{smooth}}^{(12)}, E_{\\text{cross}}^{(12)}],[E_{\\text{all}}^{(101)}, E_{\\text{smooth}}^{(101)}, E_{\\text{cross}}^{(101)}],[E_{\\text{all}}^{(102)}, E_{\\text{smooth}}^{(102)}, E_{\\text{cross}}^{(102)}]]$.\n\nAll answers are pure numbers without physical units, and no angle units are involved.",
            "solution": "The user-provided problem has been validated and is determined to be a valid, well-posed problem in numerical analysis. It is scientifically grounded, self-contained, and objective. All necessary information for both the theoretical derivation and the computational implementation is provided.\n\n### Derivation of the Fourth-Order Central Difference Formula\n\nThe objective is to derive a finite difference approximation for the first derivative, $f'(x)$, using the five points $x-2h$, $x-h$, $x$, $x+h$, and $x+2h$. The desired approximation should be of the form:\n$$\nf'(x) \\approx A f(x-2h) + B f(x-h) + C f(x) + D f(x+h) + E f(x+2h)\n$$\nTo achieve a high order of accuracy, we utilize Taylor series expansions for a sufficiently smooth function $f(x)$ around the point $x$. The expansions for $f(x \\pm h)$ and $f(x \\pm 2h)$ are:\n$$\nf(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + \\frac{h^4}{24}f^{(4)}(x) + \\frac{h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + \\frac{h^4}{24}f^{(4)}(x) - \\frac{h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x+2h) = f(x) + 2hf'(x) + \\frac{4h^2}{2}f''(x) + \\frac{8h^3}{6}f'''(x) + \\frac{16h^4}{24}f^{(4)}(x) + \\frac{32h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-2h) = f(x) - 2hf'(x) + \\frac{4h^2}{2}f''(x) - \\frac{8h^3}{6}f'''(x) + \\frac{16h^4}{24}f^{(4)}(x) - \\frac{32h^5}{120}f^{(5)}(x) + O(h^6)\n$$\nWe seek an approximation for $f'(x)$, which is an odd function with respect to the displacement $h$. Thus, we construct a linear combination that isolates odd-derivative terms. Due to the central nature of the stencil, we expect the formula to be antisymmetric, meaning $C=0$, $B = -D$, and $A = -E$. The approximation uses only the points $x \\pm h$ and $x \\pm 2h$, not $x$ itself. The general form for such a central difference is:\n$$\nf'(x) \\approx \\frac{c_1(f(x+h) - f(x-h)) + c_2(f(x+2h) - f(x-2h))}{h}\n$$\nLet's compute the differences from the Taylor series:\n$$\nf(x+h) - f(x-h) = 2hf'(x) + \\frac{2h^3}{6}f'''(x) + \\frac{2h^5}{120}f^{(5)}(x) + O(h^7)\n$$\n$$\nf(x+2h) - f(x-2h) = 4hf'(x) + \\frac{16h^3}{6}f'''(x) + \\frac{64h^5}{120}f^{(5)}(x) + O(h^7)\n$$\nLet's name these differences divided by $2h$:\n$$\nD_1 = \\frac{f(x+h) - f(x-h)}{2h} = f'(x) + \\frac{h^2}{6}f'''(x) + \\frac{h^4}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nD_2 = \\frac{f(x+2h) - f(x-2h)}{4h} = f'(x) + \\frac{4h^2}{6}f'''(x) + \\frac{16h^4}{120}f^{(5)}(x) + O(h^6)\n$$\n$D_1$ is the second-order central difference, and $D_2$ is also a second-order central difference but with step size $2h$. To cancel the leading error term, which is proportional to $h^2 f'''(x)$, we can form a linear combination of $D_1$ and $D_2$. We seek coefficients $\\alpha$ and $\\beta$ such that $\\alpha D_1 + \\beta D_2$ has the $h^2$ term eliminated, with $\\alpha + \\beta = 1$ to preserve the $f'(x)$ term.\n$$\n\\alpha \\left(\\frac{h^2}{6}\\right) + \\beta \\left(\\frac{4h^2}{6}\\right) = 0 \\implies \\alpha + 4\\beta = 0\n$$\nWe solve the system:\n$$\n\\begin{cases} \\alpha + \\beta = 1 \\\\ \\alpha + 4\\beta = 0 \\end{cases}\n$$\nSubtracting the first equation from the second gives $3\\beta = -1$, so $\\beta = -1/3$. Then $\\alpha = 1 - \\beta = 1 - (-1/3) = 4/3$.\nThe improved approximation is:\n$$\nf'(x) \\approx \\frac{4}{3}D_1 - \\frac{1}{3}D_2\n$$\nSubstituting the expressions for $D_1$ and $D_2$:\n$$\nf'(x) \\approx \\frac{4}{3} \\frac{f(x+h) - f(x-h)}{2h} - \\frac{1}{3} \\frac{f(x+2h) - f(x-2h)}{4h}\n$$\nTo simplify, let's find a common denominator, which is $12h$:\n$$\nf'(x) \\approx \\frac{8(f(x+h) - f(x-h)) - (f(x+2h) - f(x-2h))}{12h}\n$$\nRearranging the terms gives the final formula:\n$$\nf'(x) \\approx \\frac{-f(x+2h) + 8f(x+h) - 8f(x-h) + f(x-2h)}{12h}\n$$\nThe truncation error can be found by applying the coefficients $\\alpha = 4/3$ and $\\beta = -1/3$ to the $h^4$ terms of $D_1$ and $D_2$:\n$$\n\\text{Error Term} = \\left(\\frac{4}{3}\\right) \\frac{h^4}{120}f^{(5)}(x) - \\left(\\frac{1}{3}\\right) \\frac{16h^4}{120}f^{(5)}(x) = \\frac{h^4}{120} \\left(\\frac{4}{3} - \\frac{16}{3}\\right) f^{(5)}(x) = \\frac{h^4}{120} \\left(\\frac{-12}{3}\\right) f^{(5)}(x) = \\frac{-4h^4}{120}f^{(5)}(x) = -\\frac{h^4}{30}f^{(5)}(x)\n$$\nThe sign is opposite to the error of the approximation, so the truncation error is $f'(x) - f'_{\\text{approx}} = \\frac{h^4}{30}f^{(5)}(x) + O(h^6)$. The order of accuracy is $O(h^4)$, as required.\n\n### Implementation and Analysis\n\nThe derived formula is implemented to compute the derivative of $f(x) = |x - 0.5|$ on $[0,1]$. For each grid size $n$ from the test suite, the following steps are performed:\n1. A uniform grid is constructed with $n$ points, where $h = 1/(n-1)$ and $x_i = ih$ for $i=0, \\dots, n-1$.\n2. The function $f(x_i)$ and its exact derivative $f'(x_i) = \\text{sign}(x_i - 0.5)$ are computed for all grid points. Note that at $x_i = 0.5$, the exact derivative is undefined.\n3. The approximation is calculated at all interior points $x_i$ for $i \\in [2, n-3]$ using the derived formula.\n4. For each such point $x_i$, if $x_i \\neq 0.5$, the absolute error between the approximate and exact derivative is calculated.\n5. The stencil centered at $x_i$ is classified as \"smooth-region\" (if $x_{i+2} \\le 0.5$ or $x_{i-2} \\ge 0.5$) or \"corner-crossing\" (if $x_{i-2} < 0.5 < x_{i+2}$).\n6. Three sets of errors are collected: errors from all valid stencils, errors from smooth-region stencils, and errors from corner-crossing stencils.\n7. The maximum absolute error is computed for each set ($E_{\\text{all}}$, $E_{\\text{smooth}}$, $E_{\\text{cross}}$). If a set is empty, its maximum error is defined as $0$.\n\nThis procedure is repeated for each $n$ in the test suite $\\{11, 12, 101, 102\\}$. The function $f(x)$ is piecewise linear, so its fifth derivative is zero in any region that does not contain the corner at $x=0.5$. Consequently, for \"smooth-region\" stencils, the $O(h^4)$ error term vanishes, and the approximation is expected to be exact up to floating-point precision. For \"corner-crossing\" stencils, the smoothness assumption is violated, leading to a large $O(1)$ error that does not decrease as $h \\to 0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and tests a high-order finite difference scheme on a function with a corner.\n    \"\"\"\n    # The problem specifies a test suite of grid sizes n.\n    test_cases = [11, 12, 101, 102]\n    \n    all_results = []\n\n    for n in test_cases:\n        # 1. Set up grid, function, and exact derivative\n        h = 1.0 / (n - 1)\n        x = np.linspace(0.0, 1.0, n)\n        \n        # Function f(x) = |x - 0.5|\n        f_x = np.abs(x - 0.5)\n        \n        # Exact derivative f'(x) = sign(x - 0.5)\n        # f'(x) = -1 for x < 0.5, +1 for x > 0.5, undefined at x = 0.5\n        f_prime_exact = np.sign(x - 0.5)\n        \n        # Lists to store errors for different stencil types\n        errors_all = []\n        errors_smooth = []\n        errors_cross = []\n        \n        # 2. Loop over interior points where the 5-point stencil is valid\n        # The stencil at i uses points from i-2 to i+2.\n        # It's centered at x_i and defined for i from 2 to n-3.\n        # Python's range(start, stop) goes up to stop-1.\n        for i in range(2, n-2):\n            # Check edge case if i+2 is out of bounds due to loop definition\n            if i + 2 >= n:\n                continue\n\n            # The point where the derivative is being approximated\n            x_i = x[i]\n            \n            # Exclude the point x = 0.5 from any error metric, as f'(0.5) is undefined.\n            if np.isclose(x_i, 0.5):\n                continue\n                \n            # 3. Apply the fourth-order central difference formula\n            # f'(x) â‰ˆ (-f(x+2h) + 8f(x+h) - 8f(x-h) + f(x-2h)) / (12h)\n            f_prime_approx = (\n                -f_x[i+2] + 8 * f_x[i+1] - 8 * f_x[i-1] + f_x[i-2]\n            ) / (12.0 * h)\n            \n            # 4. Calculate error\n            error = np.abs(f_prime_approx - f_prime_exact[i])\n            errors_all.append(error)\n            \n            # 5. Classify the stencil and categorize the error\n            x_stencil_min = x[i-2]\n            x_stencil_max = x[i+2]\n            \n            # Smooth-region stencil: entirely on one side of 0.5 (inclusive)\n            if x_stencil_max = 0.5 or x_stencil_min >= 0.5:\n                errors_smooth.append(error)\n            # Corner-crossing stencil: straddles 0.5\n            elif x_stencil_min  0.5 and x_stencil_max > 0.5:\n                errors_cross.append(error)\n            # The classification is exhaustive for this problem's setup.\n\n        # 6. Compute the required error metrics (maximums)\n        # If a list is empty, the max error is 0.\n        E_all = max(errors_all) if errors_all else 0.0\n        E_smooth = max(errors_smooth) if errors_smooth else 0.0\n        E_cross = max(errors_cross) if errors_cross else 0.0\n        \n        all_results.append([E_all, E_smooth, E_cross])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists of floats.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "When solving time-dependent partial differential equations using the method of lines, the spatial discretization operator governs the stability of the entire simulation. This problem bridges the gap between spatial operators and temporal integration by asking you to analyze the stability of the forward Euler method applied to the diffusion equation. By examining the eigenvalues of the fourth-order discretization matrix, you will determine the maximum stable time step, gaining crucial insight into the stringent stability constraints that high-order discretizations can impose.",
            "id": "2401265",
            "problem": "Consider the one-dimensional linear diffusion equation with periodic boundary conditions in $1$ spatial dimension on the domain $[0,L)$, given by the spatially discretized system\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbf{u}(t) = A\\,\\mathbf{u}(t),\n$$\nwhere $A = \\kappa D^{(2)}$ and $D^{(2)}\\in\\mathbb{R}^{N\\times N}$ is the matrix representation of a fourth-order accurate, centered, periodic finite difference approximation to the second derivative operator $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$ on a uniform grid of $N$ points with grid spacing $h=L/N$. The grid points are at $x_j = jh$ for $j=0,1,\\dots,N-1$, and periodic boundary conditions identify $x_0$ with $x_N$. The explicit forward Euler time discretization is defined by\n$$\n\\mathbf{u}^{n+1} = \\mathbf{u}^{n} + \\Delta t \\, A\\, \\mathbf{u}^{n}.\n$$\nDefine the largest stable time step $\\Delta t_{\\max}$ as the supremum of all $\\Delta t  0$ such that for every eigenvalue $\\lambda$ of $A$, the amplification factor satisfies $\\left|1+\\Delta t\\,\\lambda\\right|\\le 1$.\n\nYour task is to:\n- Construct $D^{(2)}$ as the fourth-order accurate, centered, periodic finite difference matrix approximating $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$ on the uniform periodic grid described above.\n- Compute all eigenvalues of $A=\\kappa D^{(2)}$.\n- Determine $\\Delta t_{\\max}$ for the explicit forward Euler method using the eigenvalues of $A$ and the above definition.\n\nTest suite and required outputs:\nUse the following parameter sets $(L,N,\\kappa)$, each defining one independent test case:\n- Test case $1$: $(L,N,\\kappa)=\\left(1,\\,64,\\,1\\right)$.\n- Test case $2$: $(L,N,\\kappa)=\\left(2,\\,32,\\,\\frac{1}{2}\\right)$.\n- Test case $3$: $(L,N,\\kappa)=\\left(1,\\,5,\\,1\\right)$.\n- Test case $4$: $(L,N,\\kappa)=\\left(\\pi,\\,100,\\,2\\right)$, where $\\pi$ is the circle constant.\n\nFor each test case, compute $\\Delta t_{\\max}$ and express it as a decimal rounded to exactly $10$ decimal places with no units.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four test cases, in the same order as listed above, as a comma-separated list enclosed in square brackets, for example, $\\left[\\Delta t_{\\max}^{(1)},\\Delta t_{\\max}^{(2)},\\Delta t_{\\max}^{(3)},\\Delta t_{\\max}^{(4)}\\right]$, with each entry rounded to exactly $10$ decimal places and printed in standard decimal notation.",
            "solution": "The problem statement is subjected to validation.\n\nGivens are extracted verbatim:\n- The system of ordinary differential equations is $\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbf{u}(t) = A\\,\\mathbf{u}(t)$.\n- The matrix $A$ is defined as $A = \\kappa D^{(2)}$.\n- $D^{(2)}$ is the matrix representation of a fourth-order accurate, centered, periodic finite difference approximation to $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$.\n- The domain is $[0,L)$ with periodic boundary conditions.\n- The grid is uniform with $N$ points $x_j = jh$ for $j=0,1,\\dots,N-1$.\n- The grid spacing is $h=L/N$.\n- The time discretization is the explicit forward Euler method: $\\mathbf{u}^{n+1} = \\mathbf{u}^{n} + \\Delta t \\, A\\, \\mathbf{u}^{n}$.\n- The largest stable time step is defined as $\\Delta t_{\\max} = \\sup\\{\\Delta t  0 \\mid |1+\\Delta t\\,\\lambda|\\le 1 \\text{ for all eigenvalues } \\lambda \\text{ of } A\\}$.\n- Test cases $(L,N,\\kappa)$:\n  - Case 1: $(1,\\,64,\\,1)$\n  - Case 2: $(2,\\,32,\\,1/2)$\n  - Case 3: $(1,\\,5,\\,1)$\n  - Case 4: $(\\pi,\\,100,\\,2)$\n\nThe problem is validated against the specified criteria.\n- **Scientifically Grounded**: The problem is founded on the core principles of numerical analysis and computational physics, specifically the numerical solution of partial differential equations using finite difference methods and the stability analysis of time integration schemes. All concepts are standard and well-established.\n- **Well-Posed**: The problem is well-defined. It requests a specific, calculable quantity, $\\Delta t_{\\max}$, based on a complete set of parameters and definitions. A unique solution exists for each test case.\n- **Objective**: The problem is stated in precise, mathematical language, free from any subjectivity or ambiguity.\n\nThe verdict is that the problem is **valid**. A solution will be provided.\n\nThe solution is developed in four stages:\n1.  Construction of the fourth-order finite difference operator matrix $D^{(2)}$.\n2.  Determination of the eigenvalues of the system matrix $A = \\kappa D^{(2)}$.\n3.  Stability analysis of the forward Euler method to derive an expression for $\\Delta t_{\\max}$.\n4.  Application of the derived formula to the specified test cases.\n\nA fourth-order accurate, centered finite difference approximation for the second derivative $\\frac{\\mathrm{d}^2 u}{\\mathrm{d} x^2}$ at a grid point $x_j$ is given by the five-point stencil:\n$$\n\\frac{\\mathrm{d}^2 u}{\\mathrm{d} x^2}\\bigg|_{x_j} \\approx \\frac{1}{h^2} \\left( -\\frac{1}{12}u_{j-2} + \\frac{4}{3}u_{j-1} - \\frac{5}{2}u_j + \\frac{4}{3}u_{j+1} - \\frac{1}{12}u_{j+2} \\right)\n$$\nwhere $u_j = u(x_j)$ and $h$ is the uniform grid spacing. For a periodic domain of $N$ points, the indices are interpreted modulo $N$. This structure gives rise to a circulant matrix $D^{(2)} \\in \\mathbb{R}^{N\\times N}$. A circulant matrix is defined by its first row. The first row of the matrix $h^2 D^{(2)}$ is $(c_0, c_1, c_2, 0, \\dots, 0, c_{N-2}, c_{N-1})$, where the coefficients are $c_0 = -5/2$, $c_1 = 4/3$, $c_{N-1} = 4/3$, $c_2 = -1/12$, and $c_{N-2} = -1/12$.\n\nThe eigenvalues of an $N \\times N$ circulant matrix are given by its symbol. Let $\\theta_k = 2\\pi k/N$ for $k=0, 1, \\dots, N-1$. The eigenvalues of $h^2 D^{(2)}$, denoted $\\mu_k$, are:\n$$\n\\mu_k = c_0 + c_1(e^{i\\theta_k} + e^{-i\\theta_k}) + c_2(e^{i2\\theta_k} + e^{-i2\\theta_k}) = c_0 + 2c_1\\cos(\\theta_k) + 2c_2\\cos(2\\theta_k)\n$$\nSubstituting the coefficients $c_0 = -5/2$, $c_1 = 4/3$, $c_2 = -1/12$ and using the identity $\\cos(2\\theta) = 2\\cos^2(\\theta) - 1$:\n$$\n\\mu_k = -\\frac{5}{2} + \\frac{8}{3}\\cos(\\theta_k) - \\frac{1}{6}\\cos(2\\theta_k) = -\\frac{5}{2} + \\frac{8}{3}\\cos(\\theta_k) - \\frac{1}{6}(2\\cos^2(\\theta_k) - 1) = -\\frac{1}{3}\\cos^2(\\theta_k) + \\frac{8}{3}\\cos(\\theta_k) - \\frac{7}{3}\n$$\nThe eigenvalues of $D^{(2)}$ are $\\lambda_{D^{(2)},k} = \\mu_k / h^2$, and the eigenvalues of $A = \\kappa D^{(2)}$ are $\\lambda_k = \\kappa \\mu_k / h^2$. All $\\lambda_k$ are real and non-positive, as required for a diffusion operator.\n\nThe stability of the forward Euler scheme requires $|1 + \\Delta t \\lambda_k| \\le 1$ for all eigenvalues $\\lambda_k$. Since $\\lambda_k \\in \\mathbb{R}$ and $\\lambda_k \\le 0$, this condition is equivalent to $-1 \\le 1 + \\Delta t \\lambda_k \\le 1$. The right inequality is always satisfied for $\\Delta t > 0$. The left inequality gives $\\Delta t \\lambda_k \\ge -2$, which implies $\\Delta t \\le -2/\\lambda_k$ (the inequality flips as $\\lambda_k  0$). To satisfy this for all $k$, we must have:\n$$\n\\Delta t \\le \\min_{k, \\lambda_k \\ne 0} \\left( \\frac{-2}{\\lambda_k} \\right) = \\frac{-2}{\\max_{k, \\lambda_k \\ne 0} |\\lambda_k|} = \\frac{-2}{\\lambda_{\\min}}\n$$\nwhere $\\lambda_{\\min}$ is the most negative (minimum) eigenvalue of $A$. Thus, $\\Delta t_{\\max} = -2 / \\lambda_{\\min}$.\n\nThe minimum eigenvalue $\\lambda_{\\min}$ corresponds to the minimum value of $\\mu_k$. Let $c = \\cos(\\theta_k)$. The function $f(c) = -\\frac{1}{3}c^2 + \\frac{8}{3}c - \\frac{7}{3}$ has its vertex at $c = -(\\frac{8}{3}) / (2(-\\frac{1}{3})) = 4$, which is outside the range $c \\in [-1, 1]$. On the interval $[-1, 1]$, $f(c)$ is monotonically increasing. Therefore, the minimum value of $\\mu_k$ occurs when $\\cos(\\theta_k)$ is minimal. The range of $k$ is $0, 1, \\dots, N-1$. The minimum value of $\\cos(2\\pi k/N)$ occurs at $k_{\\text{ext}} = \\lfloor N/2 \\rfloor$.\nThe most negative eigenvalue of $h^2 D^{(2)}$ is thus:\n$$\n\\mu_{\\min} = \\mu_{k_{\\text{ext}}} = \\frac{1}{3}\\left( -\\cos^2(\\theta_{\\text{ext}}) + 8\\cos(\\theta_{\\text{ext}}) - 7 \\right), \\quad \\text{where} \\quad \\theta_{\\text{ext}} = \\frac{2\\pi \\lfloor N/2 \\rfloor}{N}\n$$\nThe minimum eigenvalue of $A$ is $\\lambda_{\\min} = \\kappa \\mu_{\\min} / h^2$. The maximum stable timestep is:\n$$\n\\Delta t_{\\max} = \\frac{-2}{\\lambda_{\\min}} = \\frac{-2h^2}{\\kappa \\mu_{\\min}} = \\frac{-2h^2}{\\kappa \\cdot \\frac{1}{3}\\left( -\\cos^2(\\theta_{\\text{ext}}) + 8\\cos(\\theta_{\\text{ext}}) - 7 \\right)}\n$$\nA special case occurs for even $N$. Here, $k_{\\text{ext}} = N/2$, so $\\theta_{\\text{ext}} = \\pi$ and $\\cos(\\theta_{\\text{ext}}) = -1$. The term in the parentheses becomes $-\\cos^2(\\pi) + 8\\cos(\\pi) - 7 = -(-1)^2 + 8(-1) - 7 = -1 - 8 - 7 = -16$.\nSo, for even $N$, $\\mu_{\\min} = -16/3$.\nThe formula simplifies to:\n$$\n\\Delta t_{\\max} = \\frac{-2h^2}{\\kappa(-16/3)} = \\frac{6h^2}{16\\kappa} = \\frac{3h^2}{8\\kappa} = \\frac{3(L/N)^2}{8\\kappa} = \\frac{3L^2}{8\\kappa N^2}\n$$\n\nThe calculations for each test case are as follows:\n\n- **Test case 1**: $(L,N,\\kappa)=(1,64,1)$. $N=64$ is even.\n  $\\Delta t_{\\max} = \\frac{3(1)^2}{8(1)(64)^2} = \\frac{3}{32768} = 0.000091552734375$.\n  Rounded to $10$ decimal places: $0.0000915527$.\n\n- **Test case 2**: $(L,N,\\kappa)=(2,32,1/2)$. $N=32$ is even.\n  $\\Delta t_{\\max} = \\frac{3(2)^2}{8(1/2)(32)^2} = \\frac{12}{4(1024)} = \\frac{3}{1024} = 0.0029296875$.\n  Rounded to $10$ decimal places: $0.0029296875$.\n\n- **Test case 3**: $(L,N,\\kappa)=(1,5,1)$. $N=5$ is odd.\n  $h = 1/5$. $k_{\\text{ext}} = \\lfloor 5/2 \\rfloor = 2$.\n  $\\theta_{\\text{ext}} = 2\\pi(2)/5 = 4\\pi/5$.\n  Let $c = \\cos(4\\pi/5)$. $\\mu_{\\min} = \\frac{1}{3}(-c^2 + 8c - 7)$.\n  $\\Delta t_{\\max} = \\frac{-2(1/5)^2}{(1) \\cdot \\mu_{\\min}} = \\frac{-2/25}{\\mu_{\\min}} = \\frac{-6}{25(-c^2 + 8c - 7)}$.\n  Numerically, $c \\approx -0.8090169944$, $\\mu_{\\min} \\approx -4.708881224$.\n  $\\Delta t_{\\max} \\approx \\frac{-0.08}{-4.708881224} \\approx 0.016989437820$.\n  Rounded to $10$ decimal places: $0.0169894378$.\n\n- **Test case 4**: $(L,N,\\kappa)=(\\pi,100,2)$. $N=100$ is even.\n  $\\Delta t_{\\max} = \\frac{3(\\pi)^2}{8(2)(100)^2} = \\frac{3\\pi^2}{160000}$.\n  Using $\\pi \\approx 3.141592653589793$, $\\Delta t_{\\max} \\approx \\frac{3(9.8696044011)}{160000} \\approx 0.000185055146$.\n  Rounded to $10$ decimal places: $0.0001850551$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the largest stable time step for the forward Euler method\n    applied to the 1D diffusion equation with a fourth-order finite difference\n    spatial discretization on a periodic domain.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 64, 1.0),\n        (2.0, 32, 0.5),\n        (1.0, 5, 1.0),\n        (np.pi, 100, 2.0)\n    ]\n\n    results = []\n    for case in test_cases:\n        L, N, kappa = case\n        h = L / N\n\n        # The stability limit depends on whether N is even or odd.\n        if N % 2 == 0:\n            # For even N, the Nyquist mode k=N/2 exists, and cos(2*pi*k/N) = -1.\n            # This leads to a simplified formula for dt_max.\n            # dt_max = (3 * h**2) / (8 * kappa)\n            dt_max = (3 * L**2) / (8 * kappa * N**2)\n        else:\n            # For odd N, the most negative eigenvalue corresponds to k = floor(N/2).\n            # We must use the general formula.\n            k_ext = np.floor(N / 2)\n            theta_ext = 2 * np.pi * k_ext / N\n            cos_theta = np.cos(theta_ext)\n            \n            # The minimum eigenvalue of the scaled (h^2 * D^(2)) operator.\n            # This is derived from the symbol of the FD scheme.\n            mu_min = (1/3) * (-cos_theta**2 + 8 * cos_theta - 7)\n            \n            # The minimum eigenvalue of the system matrix A = kappa * D^(2).\n            lambda_min = kappa * mu_min / h**2\n            \n            # The stability limit is dt_max = -2 / lambda_min.\n            dt_max = -2.0 / lambda_min\n\n        results.append(f\"{dt_max:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}