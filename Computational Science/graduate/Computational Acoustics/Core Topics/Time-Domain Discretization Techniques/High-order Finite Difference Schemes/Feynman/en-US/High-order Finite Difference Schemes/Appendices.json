{
    "hands_on_practices": [
        {
            "introduction": "Manually deriving coefficients for high-order schemes via Taylor series expansions becomes impractical as the order increases. This practice reframes the task as a systematic linear algebra problem, allowing you to create a powerful function that can generate centered finite difference coefficients for any arbitrary order . By solving a Vandermonde matrix system, you will develop a fundamental tool for building flexible and accurate simulation codes.",
            "id": "2401266",
            "problem": "You are given a uniform grid with spacing $h \\in \\mathbb{R}^{+}$ and a set of grid points indexed by integers $k \\in \\mathbb{Z}$. For a fixed integer $p \\in \\mathbb{N}$ with $p \\geq 1$, consider a centered stencil of width $2p+1$ consisting of points with offsets $k \\in \\{-p,-p+1,\\dots,-1,0,1,\\dots,p-1,p\\}$ about a point $x_{0} \\in \\mathbb{R}$. The goal is to approximate the first derivative $f^{\\prime}(x_{0})$ of a sufficiently smooth function $f:\\mathbb{R}\\to\\mathbb{R}$ using a linear combination of function values $f(x_{0} + k h)$.\n\nDefine a real vector of coefficients $\\{w_{k}\\}_{k=-p}^{p}$ such that the centered finite difference approximation\n$$\nD_{h}^{(p)}f(x_{0}) \\equiv \\frac{1}{h}\\sum_{k=-p}^{p} w_{k}\\, f(x_{0}+k h)\n$$\nhas a truncation error of order $\\mathcal{O}(h^{2p})$ as $h \\to 0^{+}$. Among all possible stencils on the given $2p+1$ symmetric points, assume the minimal centered stencil and require that the coefficients are uniquely determined by the exactness conditions\n$$\n\\sum_{k=-p}^{p} w_{k}\\, k^{r} = \\delta_{r,1} \\quad \\text{for all integers } r \\in \\{0,1,2,\\dots,2p\\},\n$$\nwhere $\\delta_{r,1}$ is the Kronecker delta equal to $1$ if $r=1$ and $0$ otherwise. These conditions enforce that, when $D_{h}^{(p)}$ is applied to any polynomial of degree at most $2p$, it exactly reproduces the first derivative at $x_{0}$ after accounting for the factor $1/h$.\n\nTask: Write a complete, runnable program that defines a function which, for a given integer input $p \\geq 1$, returns the list of coefficients $[w_{-p}, w_{-p+1}, \\dots, w_{-1}, w_{0}, w_{1}, \\dots, w_{p-1}, w_{p}]$ satisfying the above system. Your program must generate and output the coefficients for the following test suite of parameters:\n- $p \\in \\{1,2,3,4,5\\}$.\n\nAll numerical values in the output must be expressed as decimal floats rounded to exactly $16$ digits after the decimal point. There are no physical units involved in this problem.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list of the coefficient lists, with no embedded spaces. Concretely, if the results for the test cases are the lists $L_{1}, L_{2}, \\dots, L_{n}$, then the output must be a single line in the form\n$$\n[ L_{1},L_{2},\\dots,L_{n} ]\n$$\nwhere each $L_{j}$ is written as a bracketed comma-separated list of decimal floats rounded to exactly $16$ digits after the decimal point, with no spaces anywhere. For example, an output with two lists might look like\n$$\n[[a_{1},a_{2},a_{3}],[b_{1},b_{2},b_{3},b_{4},b_{5}]].\n$$",
            "solution": "The problem statement has been subjected to a rigorous validation process.\n\n**Step 1: Extracted Givens**\n- Grid: Uniform with spacing $h \\in \\mathbb{R}^{+}$.\n- Stencil: Centered of width $2p+1$ for $p \\in \\mathbb{N}, p \\geq 1$, with points indexed by $k \\in \\{-p, -p+1, \\dots, p\\}$.\n- Approximation: $D_{h}^{(p)}f(x_{0}) \\equiv \\frac{1}{h}\\sum_{k=-p}^{p} w_{k}\\, f(x_{0}+k h)$ for the first derivative $f^{\\prime}(x_{0})$.\n- Accuracy: Truncation error of order $\\mathcal{O}(h^{2p})$.\n- Coefficients: A real vector $\\{w_{k}\\}_{k=-p}^{p}$ is sought.\n- Conditions: The coefficients are determined by the system of linear equations:\n$$\n\\sum_{k=-p}^{p} w_{k}\\, k^{r} = \\delta_{r,1} \\quad \\text{for all integers } r \\in \\{0, 1, 2, \\dots, 2p\\}.\n$$\n- Task: Compute the coefficients $w_k$ for $p \\in \\{1, 2, 3, 4, 5\\}$.\n\n**Step 2: Validation of Givens**\nThe problem is well-defined within the field of numerical analysis, specifically concerning the Method of Undetermined Coefficients for deriving finite difference formulas. The conditions provided arise directly from matching coefficients in the Taylor series expansion of the finite difference operator, requiring that it exactly reproduces the first derivative for all polynomials up to degree $2p$.\n\nThe problem is to solve a system of $2p+1$ linear equations for $2p+1$ unknown coefficients $\\{w_{k}\\}_{k=-p}^{p}$. This system can be written in matrix form, $A \\mathbf{w} = \\mathbf{b}$.\nLet the vector of unknowns be $\\mathbf{w} = [w_{-p}, w_{-p+1}, \\dots, w_{p}]^T$.\nThe right-hand side vector is $\\mathbf{b} = [0, 1, 0, \\dots, 0]^T$, where the single non-zero element corresponds to the condition for $r=1$.\nThe system matrix $A$ is a $(2p+1) \\times (2p+1)$ matrix whose elements are given by $A_{i,j} = (j-p)^i$, for row index $i \\in \\{0, 1, \\dots, 2p\\}$ and column index $j \\in \\{0, 1, \\dots, 2p\\}$. Note that the column index $j$ corresponds to the stencil point $k=j-p$. The term $k^r$ must be evaluated carefully for $k=0$; specifically, $0^0$ is defined as $1$ in this context, consistent with its role in polynomial bases, while $0^r = 0$ for $r>0$.\nThe resulting matrix $A$ is a Vandermonde matrix for the distinct nodes $\\{-p, -p+1, \\dots, p\\}$. A Vandermonde matrix constructed with distinct nodes is always non-singular. Therefore, its inverse $A^{-1}$ exists and is unique. The system $A \\mathbf{w} = \\mathbf{b}$ thus has a unique solution $\\mathbf{w} = A^{-1}\\mathbf{b}$.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information. It is deemed **valid**. We proceed to the solution.\n\nThe solution requires solving the aforementioned linear system for each value of $p$ specified.\n\nLet $N = 2p+1$. We must solve for the vector $\\mathbf{w} = [w_{-p}, \\dots, w_p]^T$ of size $N$. The system of equations is:\n$$\n\\begin{pmatrix}\n(-p)^0 & (-p+1)^0 & \\cdots & p^0 \\\\\n(-p)^1 & (-p+1)^1 & \\cdots & p^1 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n(-p)^{2p} & (-p+1)^{2p} & \\cdots & p^{2p}\n\\end{pmatrix}\n\\begin{pmatrix}\nw_{-p} \\\\\nw_{-p+1} \\\\\n\\vdots \\\\\nw_p\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{pmatrix}\n$$\nThis linear system can be solved efficiently using standard numerical linear algebra libraries. For each specified integer $p$, the algorithm is as follows:\n1.  Set the dimension of the system, $N = 2p+1$.\n2.  Define the set of stencil nodes, $K = \\{k \\in \\mathbb{Z} \\mid -p \\le k \\le p \\}$.\n3.  Construct the $N \\times N$ Vandermonde matrix $A$, where its elements are $A_{r, k+p} = k^r$ for $r \\in \\{0, \\dots, 2p\\}$ and $k \\in K$. The convention $0^0=1$ must be respected.\n4.  Construct the $N$-dimensional right-hand side vector $\\mathbf{b}$, with $b_r = \\delta_{r,1}$ for $r \\in \\{0, \\dots, 2p\\}$.\n5.  Solve the linear system $A \\mathbf{w} = \\mathbf{b}$ for the coefficient vector $\\mathbf{w}$.\n6.  The components of the resulting vector $\\mathbf{w}$ are the required coefficients $[w_{-p}, w_{-p+1}, \\dots, w_p]$.\n\nThis procedure is deterministic and will yield the unique set of coefficients for any given $p \\geq 1$. The provided program implements this exact logic. For example, for $p=1$, the system is:\n$$\n\\begin{pmatrix}\n1 & 1 & 1 \\\\\n-1 & 0 & 1 \\\\\n1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nw_{-1} \\\\\nw_{0} \\\\\nw_{1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix}\n$$\nThe determinant of this matrix is $2$, indicating it is invertible. The solution is correctly found to be $\\mathbf{w} = [-0.5, 0, 0.5]^T$, the coefficients for the standard second-order central difference formula. The same principle applies to higher values of $p$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the coefficients for centered finite difference approximations\n    of the first derivative for a given set of stencil widths.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [1, 2, 3, 4, 5]\n\n    results = []\n    for p in test_cases:\n        # The parameter 'p' defines a stencil of width 2p+1.\n        # The number of coefficients and equations is N = 2p+1.\n        N = 2 * p + 1\n        \n        # The stencil points k range from -p to p.\n        k_values = np.arange(-p, p + 1, dtype=float)\n        \n        # The powers r range from 0 to 2p.\n        r_values = np.arange(N, dtype=float).reshape(-1, 1)\n\n        # Construct the Vandermonde-like matrix A.\n        # A[r, j] = k_values[j]**r.\n        # numpy.power correctly handles 0**0 = 1.\n        A = np.power(k_values, r_values)\n        \n        # Construct the right-hand side vector b, where b_r = delta_{r,1}.\n        b = np.zeros(N)\n        b[1] = 1.0\n        \n        # Solve the linear system A*w = b for the coefficients w.\n        w = np.linalg.solve(A, b)\n        \n        results.append(w.tolist())\n\n    # Format the output as specified in the problem statement.\n    list_of_strings = []\n    for res_list in results:\n        # Format each coefficient to exactly 16 decimal places.\n        formatted_list = [f\"{x:.16f}\" for x in res_list]\n        list_of_strings.append(f\"[{','.join(formatted_list)}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(list_of_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A high-order spatial discretization is only one component of a stable and accurate simulation of time-dependent problems like wave propagation or diffusion. This practice connects the properties of your spatial operator to the stability of the entire simulation by analyzing the eigenvalues of the finite difference matrix . By determining the maximum stable time step for the diffusion equation, you will gain crucial insight into the interplay between spatial grid resolution, scheme order, and the constraints on explicit time integration.",
            "id": "2401265",
            "problem": "Consider the one-dimensional linear diffusion equation with periodic boundary conditions in $1$ spatial dimension on the domain $[0,L)$, given by the spatially discretized system\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbf{u}(t) = A\\,\\mathbf{u}(t),\n$$\nwhere $A = \\kappa D^{(2)}$ and $D^{(2)}\\in\\mathbb{R}^{N\\times N}$ is the matrix representation of a fourth-order accurate, centered, periodic finite difference approximation to the second derivative operator $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$ on a uniform grid of $N$ points with grid spacing $h=L/N$. The grid points are at $x_j = jh$ for $j=0,1,\\dots,N-1$, and periodic boundary conditions identify $x_0$ with $x_N$. The explicit forward Euler time discretization is defined by\n$$\n\\mathbf{u}^{n+1} = \\mathbf{u}^{n} + \\Delta t \\, A\\, \\mathbf{u}^{n}.\n$$\nDefine the largest stable time step $\\Delta t_{\\max}$ as the supremum of all $\\Delta t > 0$ such that for every eigenvalue $\\lambda$ of $A$, the amplification factor satisfies $\\left|1+\\Delta t\\,\\lambda\\right|\\le 1$.\n\nYour task is to:\n- Construct $D^{(2)}$ as the fourth-order accurate, centered, periodic finite difference matrix approximating $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$ on the uniform periodic grid described above.\n- Compute all eigenvalues of $A=\\kappa D^{(2)}$.\n- Determine $\\Delta t_{\\max}$ for the explicit forward Euler method using the eigenvalues of $A$ and the above definition.\n\nTest suite and required outputs:\nUse the following parameter sets $(L,N,\\kappa)$, each defining one independent test case:\n- Test case $1$: $(L,N,\\kappa)=\\left(1,\\,64,\\,1\\right)$.\n- Test case $2$: $(L,N,\\kappa)=\\left(2,\\,32,\\,\\frac{1}{2}\\right)$.\n- Test case $3$: $(L,N,\\kappa)=\\left(1,\\,5,\\,1\\right)$.\n- Test case $4$: $(L,N,\\kappa)=\\left(\\pi,\\,100,\\,2\\right)$, where $\\pi$ is the circle constant.\n\nFor each test case, compute $\\Delta t_{\\max}$ and express it as a decimal rounded to exactly $10$ decimal places with no units.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four test cases, in the same order as listed above, as a comma-separated list enclosed in square brackets, for example, $\\left[\\Delta t_{\\max}^{(1)},\\Delta t_{\\max}^{(2)},\\Delta t_{\\max}^{(3)},\\Delta t_{\\max}^{(4)}\\right]$, with each entry rounded to exactly $10$ decimal places and printed in standard decimal notation.",
            "solution": "The problem statement is subjected to validation.\n\nGivens are extracted verbatim:\n- The system of ordinary differential equations is $\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbf{u}(t) = A\\,\\mathbf{u}(t)$.\n- The matrix $A$ is defined as $A = \\kappa D^{(2)}$.\n- $D^{(2)}$ is the matrix representation of a fourth-order accurate, centered, periodic finite difference approximation to $\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$.\n- The domain is $[0,L)$ with periodic boundary conditions.\n- The grid is uniform with $N$ points $x_j = jh$ for $j=0,1,\\dots,N-1$.\n- The grid spacing is $h=L/N$.\n- The time discretization is the explicit forward Euler method: $\\mathbf{u}^{n+1} = \\mathbf{u}^{n} + \\Delta t \\, A\\, \\mathbf{u}^{n}$.\n- The largest stable time step is defined as $\\Delta t_{\\max} = \\sup\\{\\Delta t > 0 \\mid |1+\\Delta t\\,\\lambda|\\le 1 \\text{ for all eigenvalues } \\lambda \\text{ of } A\\}$.\n- Test cases $(L,N,\\kappa)$:\n  - Case 1: $(1,\\,64,\\,1)$\n  - Case 2: $(2,\\,32,\\,1/2)$\n  - Case 3: $(1,\\,5,\\,1)$\n  - Case 4: $(\\pi,\\,100,\\,2)$\n\nThe problem is validated against the specified criteria.\n- **Scientifically Grounded**: The problem is founded on the core principles of numerical analysis and computational physics, specifically the numerical solution of partial differential equations using finite difference methods and the stability analysis of time integration schemes. All concepts are standard and well-established.\n- **Well-Posed**: The problem is well-defined. It requests a specific, calculable quantity, $\\Delta t_{\\max}$, based on a complete set of parameters and definitions. A unique solution exists for each test case.\n- **Objective**: The problem is stated in precise, mathematical language, free from any subjectivity or ambiguity.\n\nThe verdict is that the problem is **valid**. A solution will be provided.\n\nThe solution is developed in four stages:\n1.  Construction of the fourth-order finite difference operator matrix $D^{(2)}$.\n2.  Determination of the eigenvalues of the system matrix $A = \\kappa D^{(2)}$.\n3.  Stability analysis of the forward Euler method to derive an expression for $\\Delta t_{\\max}$.\n4.  Application of the derived formula to the specified test cases.\n\nA fourth-order accurate, centered finite difference approximation for the second derivative $\\frac{\\mathrm{d}^2 u}{\\mathrm{d} x^2}$ at a grid point $x_j$ is given by the five-point stencil:\n$$\n\\frac{\\mathrm{d}^2 u}{\\mathrm{d} x^2}\\bigg|_{x_j} \\approx \\frac{1}{h^2} \\left( -\\frac{1}{12}u_{j-2} + \\frac{4}{3}u_{j-1} - \\frac{5}{2}u_j + \\frac{4}{3}u_{j+1} - \\frac{1}{12}u_{j+2} \\right)\n$$\nwhere $u_j = u(x_j)$ and $h$ is the uniform grid spacing. For a periodic domain of $N$ points, the indices are interpreted modulo $N$. This structure gives rise to a circulant matrix $D^{(2)} \\in \\mathbb{R}^{N\\times N}$. A circulant matrix is defined by its first row. The first row of the matrix $h^2 D^{(2)}$ is $(c_0, c_1, c_2, 0, \\dots, 0, c_2, c_1)$, where the coefficients are $c_0 = -5/2$, $c_1 = 4/3$, and $c_2 = -1/12$.\n\nThe eigenvalues $\\mu_k$ of the matrix $h^2 D^{(2)}$ can be found analytically. For a circulant matrix defined by its first row $(r_0, r_1, \\dots, r_{N-1})$, the eigenvalues for $k=0, \\dots, N-1$ are given by the formula $\\mu_k = \\sum_{j=0}^{N-1} r_j e^{i 2\\pi kj/N}$. In our case, the non-zero elements of the first row are $r_0=c_0, r_1=c_1, r_2=c_2, r_{N-2}=c_2$, and $r_{N-1}=c_1$. Letting $\\theta_k = 2\\pi k/N$, the eigenvalue is:\n$$\n\\mu_k = c_0 + c_1 e^{i\\theta_k} + c_2 e^{i2\\theta_k} + c_2 e^{i(N-2)\\theta_k} + c_1 e^{i(N-1)\\theta_k}\n$$\nUsing the identity $e^{i(N-j)\\theta_k} = e^{-ij\\theta_k}$, the expression simplifies:\n$$\n\\mu_k = c_0 + c_1(e^{i\\theta_k} + e^{-i\\theta_k}) + c_2(e^{i2\\theta_k} + e^{-i2\\theta_k}) = c_0 + 2c_1\\cos(\\theta_k) + 2c_2\\cos(2\\theta_k)\n$$\nSubstituting the coefficients $c_0 = -5/2$, $c_1 = 4/3$, $c_2 = -1/12$ and using the identity $\\cos(2\\theta) = 2\\cos^2(\\theta) - 1$:\n$$\n\\mu_k = -\\frac{5}{2} + \\frac{8}{3}\\cos(\\theta_k) - \\frac{1}{6}\\cos(2\\theta_k) = -\\frac{5}{2} + \\frac{8}{3}\\cos(\\theta_k) - \\frac{1}{6}(2\\cos^2(\\theta_k) - 1) = -\\frac{1}{3}\\cos^2(\\theta_k) + \\frac{8}{3}\\cos(\\theta_k) - \\frac{7}{3}\n$$\nThe eigenvalues of $D^{(2)}$ are $\\lambda_{D^{(2)},k} = \\mu_k / h^2$, and the eigenvalues of $A = \\kappa D^{(2)}$ are $\\lambda_k = \\kappa \\mu_k / h^2$. All $\\lambda_k$ are real and non-positive, as required for a diffusion operator.\n\nThe stability of the forward Euler scheme requires $|1 + \\Delta t \\lambda_k| \\le 1$ for all eigenvalues $\\lambda_k$. Since $\\lambda_k \\in \\mathbb{R}$ and $\\lambda_k \\le 0$, this condition is equivalent to $-1 \\le 1 + \\Delta t \\lambda_k \\le 1$. The right inequality is always satisfied for $\\Delta t > 0$. The left inequality gives $\\Delta t \\lambda_k \\ge -2$, which implies $\\Delta t \\le -2/\\lambda_k$ (the inequality flips as $\\lambda_k < 0$). To satisfy this for all $k$, we must have:\n$$\n\\Delta t \\le \\min_{k, \\lambda_k \\ne 0} \\left( \\frac{-2}{\\lambda_k} \\right) = \\frac{-2}{\\max_{k, \\lambda_k \\ne 0} |\\lambda_k|} = \\frac{-2}{\\lambda_{\\min}}\n$$\nwhere $\\lambda_{\\min}$ is the most negative (minimum) eigenvalue of $A$. Thus, $\\Delta t_{\\max} = -2 / \\lambda_{\\min}$.\n\nThe minimum eigenvalue $\\lambda_{\\min}$ corresponds to the minimum value of $\\mu_k$. Let $c = \\cos(\\theta_k)$. The function $f(c) = -\\frac{1}{3}c^2 + \\frac{8}{3}c - \\frac{7}{3}$ has its vertex at $c = -(\\frac{8}{3}) / (2(-\\frac{1}{3})) = 4$, which is outside the range $c \\in [-1, 1]$. On the interval $[-1, 1]$, $f(c)$ is monotonically increasing. Therefore, the minimum value of $\\mu_k$ occurs when $\\cos(\\theta_k)$ is minimal. The range of $k$ is $0, 1, \\dots, N-1$. The minimum value of $\\cos(2\\pi k/N)$ occurs at $k_{\\text{ext}} = \\lfloor N/2 \\rfloor$.\nThe most negative eigenvalue of $h^2 D^{(2)}$ is thus:\n$$\n\\mu_{\\min} = \\mu_{k_{\\text{ext}}} = \\frac{1}{3}\\left( -\\cos^2(\\theta_{\\text{ext}}) + 8\\cos(\\theta_{\\text{ext}}) - 7 \\right), \\quad \\text{where} \\quad \\theta_{\\text{ext}} = \\frac{2\\pi \\lfloor N/2 \\rfloor}{N}\n$$\nThe minimum eigenvalue of $A$ is $\\lambda_{\\min} = \\kappa \\mu_{\\min} / h^2$. The maximum stable timestep is:\n$$\n\\Delta t_{\\max} = \\frac{-2}{\\lambda_{\\min}} = \\frac{-2h^2}{\\kappa \\mu_{\\min}} = \\frac{-6h^2}{\\kappa \\left( -\\cos^2(\\theta_{\\text{ext}}) + 8\\cos(\\theta_{\\text{ext}}) - 7 \\right)}\n$$\nA special case occurs for even $N$. Here, $k_{\\text{ext}} = N/2$, so $\\theta_{\\text{ext}} = \\pi$ and $\\cos(\\theta_{\\text{ext}}) = -1$. The term in the parentheses becomes $-(-1)^2 + 8(-1) - 7 = -1 - 8 - 7 = -16$.\nFor even $N$, the formula simplifies to:\n$$\n\\Delta t_{\\max} = \\frac{-6h^2}{\\kappa(-16)} = \\frac{3h^2}{8\\kappa} = \\frac{3(L/N)^2}{8\\kappa} = \\frac{3L^2}{8\\kappa N^2}\n$$\n\nThe calculations for each test case are as follows:\n\n- **Test case 1**: $(L,N,\\kappa)=(1,64,1)$. $N=64$ is even.\n  $\\Delta t_{\\max} = \\frac{3(1)^2}{8(1)(64)^2} = \\frac{3}{32768} = 0.000091552734375$.\n  Rounded to $10$ decimal places: $0.0000915527$.\n\n- **Test case 2**: $(L,N,\\kappa)=(2,32,1/2)$. $N=32$ is even.\n  $\\Delta t_{\\max} = \\frac{3(2)^2}{8(1/2)(32)^2} = \\frac{12}{4(1024)} = \\frac{3}{1024} = 0.0029296875$.\n  Rounded to $10$ decimal places: $0.0029296875$.\n\n- **Test case 3**: $(L,N,\\kappa)=(1,5,1)$. $N=5$ is odd.\n  $h = 1/5$. $k_{\\text{ext}} = \\lfloor 5/2 \\rfloor = 2$.\n  $\\theta_{\\text{ext}} = 2\\pi(2)/5 = 4\\pi/5$.\n  Let $c = \\cos(4\\pi/5)$. $\\mu_{\\min} = \\frac{1}{3}(-c^2 + 8c - 7)$.\n  $\\Delta t_{\\max} = \\frac{-2(1/5)^2}{(1) \\cdot \\mu_{\\min}} = \\frac{-2/25}{\\mu_{\\min}} = \\frac{-6}{25(-c^2 + 8c - 7)}$.\n  Numerically, $c \\approx -0.8090169944$, $\\mu_{\\min} \\approx -4.708881224$.\n  $\\Delta t_{\\max} \\approx \\frac{-0.08}{-4.708881224} \\approx 0.016989437820$.\n  Rounded to $10$ decimal places: $0.0169894378$.\n\n- **Test case 4**: $(L,N,\\kappa)=(\\pi,100,2)$. $N=100$ is even.\n  $\\Delta t_{\\max} = \\frac{3(\\pi)^2}{8(2)(100)^2} = \\frac{3\\pi^2}{160000}$.\n  Using $\\pi \\approx 3.141592653589793$, $\\Delta t_{\\max} \\approx \\frac{3(9.8696044011)}{160000} \\approx 0.000185055146$.\n  Rounded to $10$ decimal places: $0.0001850551$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the largest stable time step for the forward Euler method\n    applied to the 1D diffusion equation with a fourth-order finite difference\n    spatial discretization on a periodic domain.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 64, 1.0),\n        (2.0, 32, 0.5),\n        (1.0, 5, 1.0),\n        (np.pi, 100, 2.0)\n    ]\n\n    results = []\n    for case in test_cases:\n        L, N, kappa = case\n        h = L / N\n\n        # The stability limit depends on whether N is even or odd.\n        if N % 2 == 0:\n            # For even N, the Nyquist mode k=N/2 exists, and cos(2*pi*k/N) = -1.\n            # This leads to a simplified formula for dt_max.\n            # dt_max = (3 * h**2) / (8 * kappa)\n            dt_max = (3 * L**2) / (8 * kappa * N**2)\n        else:\n            # For odd N, the most negative eigenvalue corresponds to k = floor(N/2).\n            # We must use the general formula.\n            k_ext = np.floor(N / 2)\n            theta_ext = 2 * np.pi * k_ext / N\n            cos_theta = np.cos(theta_ext)\n            \n            # The minimum eigenvalue of the scaled (h^2 * D^(2)) operator.\n            # This is derived from the symbol of the FD scheme.\n            mu_min = (1/3) * (-cos_theta**2 + 8 * cos_theta - 7)\n            \n            # The minimum eigenvalue of the system matrix A = kappa * D^(2).\n            lambda_min = kappa * mu_min / h**2\n            \n            # The stability limit is dt_max = -2 / lambda_min.\n            dt_max = -2.0 / lambda_min\n\n        results.append(f\"{dt_max:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The remarkable accuracy of high-order schemes is fundamentally linked to the assumption that the function being differentiated is sufficiently smooth. This practice challenges that assumption by applying a fourth-order scheme to a function with a sharp corner, a common scenario in problems involving shocks or material interfaces . You will numerically investigate the phenomenon of \"order reduction,\" where the scheme's accuracy degrades from the theoretical high order to a much lower order, providing a critical lesson on the practical limitations of these methods.",
            "id": "3227834",
            "problem": "You are to investigate the behavior of a high-order finite difference approximation for the first derivative when applied to a function with a non-differentiable point. The foundational starting point is the Taylor series expansion of a sufficiently smooth function around a point. Begin from the definition that, for a function $f$ that is at least five times continuously differentiable near a point $x$, the values $f(x \\pm h)$ and $f(x \\pm 2h)$ admit Taylor series expansions about $x$. Using these expansions, derive a central finite difference approximation that uses the values at $x - 2h$, $x - h$, $x + h$, and $x + 2h$ to approximate $f'(x)$ with a truncation error that is proportional to $h^4$ for functions that are sufficiently smooth.\n\nOnce you have derived the high-order scheme, implement it and test its performance on the function $f(x) = |x - 0.5|$ over the interval $[0,1]$ using a uniform grid with $n$ points, so that the grid spacing is $h = \\frac{1}{n - 1}$ and the grid points are $x_i = i h$ for $i = 0, 1, \\dots, n - 1$. The exact derivative of $f$ is given by $f'(x) = -1$ for $x < 0.5$ and $f'(x) = +1$ for $x > 0.5$, and it is undefined at $x = 0.5$. To ensure scientific realism, treat the point $x = 0.5$ as excluded from any error metric because $f'(0.5)$ is undefined.\n\nDefine the derivative approximation only at interior points $x_i$ for $i = 2, 3, \\dots, n - 3$ so that the four-point central stencil fits within the interval. Classify each interior stencil as either \"smooth-region\" or \"corner-crossing\" as follows:\n- A stencil centered at $x_i$ is \"smooth-region\" if both $x_{i-2}$ and $x_{i+2}$ lie strictly on the same side of $0.5$, that is, either $x_{i+2} \\le 0.5$ or $x_{i-2} \\ge 0.5$.\n- A stencil centered at $x_i$ is \"corner-crossing\" if it straddles the corner, that is, $x_{i-2} < 0.5 < x_{i+2}$.\n\nFor each value of $n$ in the provided test suite, compute the following three error metrics, expressed as real numbers (floating point):\n- $E_{\\text{all}}$: the maximum absolute error over all interior points $x_i$, excluding any point for which $x_i = 0.5$.\n- $E_{\\text{smooth}}$: the maximum absolute error restricted to interior points with \"smooth-region\" stencils.\n- $E_{\\text{cross}}$: the maximum absolute error restricted to interior points with \"corner-crossing\" stencils. If no stencil is corner-crossing for a given $n$, define $E_{\\text{cross}} = 0$.\n\nUse the following test suite of grid sizes:\n- $n = 11$ (coarse grid with $0.5$ as a grid point),\n- $n = 12$ (coarse grid without $0.5$ as a grid point),\n- $n = 101$ (fine grid with $0.5$ as a grid point),\n- $n = 102$ (fine grid without $0.5$ as a grid point).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case produces a list $[E_{\\text{all}}, E_{\\text{smooth}}, E_{\\text{cross}}]$, and the overall output is a list of these lists, in the same order as the test suite. For example, the required output format is $[[E_{\\text{all}}^{(11)}, E_{\\text{smooth}}^{(11)}, E_{\\text{cross}}^{(11)}],[E_{\\text{all}}^{(12)}, E_{\\text{smooth}}^{(12)}, E_{\\text{cross}}^{(12)}],[E_{\\text{all}}^{(101)}, E_{\\text{smooth}}^{(101)}, E_{\\text{cross}}^{(101)}],[E_{\\text{all}}^{(102)}, E_{\\text{smooth}}^{(102)}, E_{\\text{cross}}^{(102)}]]$.\n\nAll answers are pure numbers without physical units, and no angle units are involved.",
            "solution": "The user-provided problem has been validated and is determined to be a valid, well-posed problem in numerical analysis. It is scientifically grounded, self-contained, and objective. All necessary information for both the theoretical derivation and the computational implementation is provided.\n\n### Derivation of the Fourth-Order Central Difference Formula\n\nThe objective is to derive a finite difference approximation for the first derivative, $f'(x)$, using the five points $x-2h$, $x-h$, $x$, $x+h$, and $x+2h$. The desired approximation should be of the form:\n$$\nf'(x) \\approx A f(x-2h) + B f(x-h) + C f(x) + D f(x+h) + E f(x+2h)\n$$\nTo achieve a high order of accuracy, we utilize Taylor series expansions for a sufficiently smooth function $f(x)$ around the point $x$. The expansions for $f(x \\pm h)$ and $f(x \\pm 2h)$ are:\n$$\nf(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + \\frac{h^4}{24}f^{(4)}(x) + \\frac{h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + \\frac{h^4}{24}f^{(4)}(x) - \\frac{h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x+2h) = f(x) + 2hf'(x) + \\frac{4h^2}{2}f''(x) + \\frac{8h^3}{6}f'''(x) + \\frac{16h^4}{24}f^{(4)}(x) + \\frac{32h^5}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-2h) = f(x) - 2hf'(x) + \\frac{4h^2}{2}f''(x) - \\frac{8h^3}{6}f'''(x) + \\frac{16h^4}{24}f^{(4)}(x) - \\frac{32h^5}{120}f^{(5)}(x) + O(h^6)\n$$\nWe seek an approximation for $f'(x)$, which is an odd function with respect to the displacement $h$. Thus, we construct a linear combination that isolates odd-derivative terms. Due to the central nature of the stencil, we expect the formula to be antisymmetric, meaning $C=0$, $B = -D$, and $A = -E$. The approximation uses only the points $x \\pm h$ and $x \\pm 2h$, not $x$ itself. The general form for such a central difference is:\n$$\nf'(x) \\approx \\frac{c_1(f(x+h) - f(x-h)) + c_2(f(x+2h) - f(x-2h))}{h}\n$$\nLet's compute the differences from the Taylor series:\n$$\nf(x+h) - f(x-h) = 2hf'(x) + \\frac{2h^3}{6}f'''(x) + \\frac{2h^5}{120}f^{(5)}(x) + O(h^7)\n$$\n$$\nf(x+2h) - f(x-2h) = 4hf'(x) + \\frac{16h^3}{6}f'''(x) + \\frac{64h^5}{120}f^{(5)}(x) + O(h^7)\n$$\nLet's name these differences divided by $2h$:\n$$\nD_1 = \\frac{f(x+h) - f(x-h)}{2h} = f'(x) + \\frac{h^2}{6}f'''(x) + \\frac{h^4}{120}f^{(5)}(x) + O(h^6)\n$$\n$$\nD_2 = \\frac{f(x+2h) - f(x-2h)}{4h} = f'(x) + \\frac{4h^2}{6}f'''(x) + \\frac{16h^4}{120}f^{(5)}(x) + O(h^6)\n$$\n$D_1$ is the second-order central difference, and $D_2$ is also a second-order central difference but with step size $2h$. To cancel the leading error term, which is proportional to $h^2 f'''(x)$, we can form a linear combination of $D_1$ and $D_2$. We seek coefficients $\\alpha$ and $\\beta$ such that $\\alpha D_1 + \\beta D_2$ has the $h^2$ term eliminated, with $\\alpha + \\beta = 1$ to preserve the $f'(x)$ term.\n$$\n\\alpha \\left(\\frac{h^2}{6}\\right) + \\beta \\left(\\frac{4h^2}{6}\\right) = 0 \\implies \\alpha + 4\\beta = 0\n$$\nWe solve the system:\n$$\n\\begin{cases} \\alpha + \\beta = 1 \\\\ \\alpha + 4\\beta = 0 \\end{cases}\n$$\nSubtracting the first equation from the second gives $3\\beta = -1$, so $\\beta = -1/3$. Then $\\alpha = 1 - \\beta = 1 - (-1/3) = 4/3$.\nThe improved approximation is:\n$$\nf'(x) \\approx \\frac{4}{3}D_1 - \\frac{1}{3}D_2\n$$\nSubstituting the expressions for $D_1$ and $D_2$:\n$$\nf'(x) \\approx \\frac{4}{3} \\frac{f(x+h) - f(x-h)}{2h} - \\frac{1}{3} \\frac{f(x+2h) - f(x-2h)}{4h}\n$$\nTo simplify, let's find a common denominator, which is $12h$:\n$$\nf'(x) \\approx \\frac{8(f(x+h) - f(x-h)) - (f(x+2h) - f(x-2h))}{12h}\n$$\nRearranging the terms gives the final formula:\n$$\nf'(x) \\approx \\frac{-f(x+2h) + 8f(x+h) - 8f(x-h) + f(x-2h)}{12h}\n$$\nThe truncation error can be found by applying the coefficients $\\alpha = 4/3$ and $\\beta = -1/3$ to the $h^4$ terms of $D_1$ and $D_2$:\n$$\n\\text{Error Term} = \\left(\\frac{4}{3}\\right) \\frac{h^4}{120}f^{(5)}(x) - \\left(\\frac{1}{3}\\right) \\frac{16h^4}{120}f^{(5)}(x) = \\frac{h^4}{120} \\left(\\frac{4}{3} - \\frac{16}{3}\\right) f^{(5)}(x) = \\frac{h^4}{120} \\left(\\frac{-12}{3}\\right) f^{(5)}(x) = \\frac{-4h^4}{120}f^{(5)}(x) = -\\frac{h^4}{30}f^{(5)}(x)\n$$\nThe sign is opposite to the error of the approximation, so the truncation error is $f'(x) - f'_{\\text{approx}} = \\frac{h^4}{30}f^{(5)}(x) + O(h^6)$. The order of accuracy is $O(h^4)$, as required.\n\n### Implementation and Analysis\n\nThe derived formula is implemented to compute the derivative of $f(x) = |x - 0.5|$ on $[0,1]$. For each grid size $n$ from the test suite, the following steps are performed:\n1. A uniform grid is constructed with $n$ points, where $h = 1/(n-1)$ and $x_i = ih$ for $i=0, \\dots, n-1$.\n2. The function $f(x_i)$ and its exact derivative $f'(x_i) = \\text{sign}(x_i - 0.5)$ are computed for all grid points. Note that at $x_i = 0.5$, the exact derivative is undefined.\n3. The approximation is calculated at all interior points $x_i$ for $i \\in [2, n-3]$ using the derived formula.\n4. For each such point $x_i$, if $x_i \\neq 0.5$, the absolute error between the approximate and exact derivative is calculated.\n5. The stencil centered at $x_i$ is classified as \"smooth-region\" (if $x_{i+2} \\le 0.5$ or $x_{i-2} \\ge 0.5$) or \"corner-crossing\" (if $x_{i-2} < 0.5 < x_{i+2}$).\n6. Three sets of errors are collected: errors from all valid stencils, errors from smooth-region stencils, and errors from corner-crossing stencils.\n7. The maximum absolute error is computed for each set ($E_{\\text{all}}$, $E_{\\text{smooth}}$, $E_{\\text{cross}}$). If a set is empty, its maximum error is defined as $0$.\n\nThis procedure is repeated for each $n$ in the test suite $\\{11, 12, 101, 102\\}$. The function $f(x)$ is piecewise linear, so its fifth derivative is zero in any region that does not contain the corner at $x=0.5$. Consequently, for \"smooth-region\" stencils, the $O(h^4)$ error term vanishes, and the approximation is expected to be exact up to floating-point precision. For \"corner-crossing\" stencils, the smoothness assumption is violated, leading to a large $O(1)$ error that does not decrease as $h \\to 0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and tests a high-order finite difference scheme on a function with a corner.\n    \"\"\"\n    # The problem specifies a test suite of grid sizes n.\n    test_cases = [11, 12, 101, 102]\n    \n    all_results = []\n\n    for n in test_cases:\n        # 1. Set up grid, function, and exact derivative\n        h = 1.0 / (n - 1)\n        x = np.linspace(0.0, 1.0, n)\n        \n        # Function f(x) = |x - 0.5|\n        f_x = np.abs(x - 0.5)\n        \n        # Exact derivative f'(x) = sign(x - 0.5)\n        # f'(x) = -1 for x < 0.5, +1 for x > 0.5, undefined at x = 0.5\n        f_prime_exact = np.sign(x - 0.5)\n        \n        # Lists to store errors for different stencil types\n        errors_all = []\n        errors_smooth = []\n        errors_cross = []\n        \n        # 2. Loop over interior points where the 5-point stencil is valid\n        # The stencil at i uses points from i-2 to i+2.\n        # It's centered at x_i and defined for i from 2 to n-3.\n        # Python's range(start, stop) goes up to stop-1.\n        for i in range(2, n-2):\n            # Check edge case if i+2 is out of bounds due to loop definition\n            if i + 2 >= n:\n                continue\n\n            # The point where the derivative is being approximated\n            x_i = x[i]\n            \n            # Exclude the point x = 0.5 from any error metric, as f'(0.5) is undefined.\n            if np.isclose(x_i, 0.5):\n                continue\n                \n            # 3. Apply the fourth-order central difference formula\n            # f'(x) â‰ˆ (-f(x+2h) + 8f(x+h) - 8f(x-h) + f(x-2h)) / (12h)\n            f_prime_approx = (\n                -f_x[i+2] + 8 * f_x[i+1] - 8 * f_x[i-1] + f_x[i-2]\n            ) / (12.0 * h)\n            \n            # 4. Calculate error\n            error = np.abs(f_prime_approx - f_prime_exact[i])\n            errors_all.append(error)\n            \n            # 5. Classify the stencil and categorize the error\n            x_stencil_min = x[i-2]\n            x_stencil_max = x[i+2]\n            \n            # Smooth-region stencil: entirely on one side of 0.5 (inclusive)\n            if x_stencil_max <= 0.5 or x_stencil_min >= 0.5:\n                errors_smooth.append(error)\n            # Corner-crossing stencil: straddles 0.5\n            elif x_stencil_min < 0.5 and x_stencil_max > 0.5:\n                errors_cross.append(error)\n            # The classification is exhaustive for this problem's setup.\n\n        # 6. Compute the required error metrics (maximums)\n        # If a list is empty, the max error is 0.\n        E_all = max(errors_all) if errors_all else 0.0\n        E_smooth = max(errors_smooth) if errors_smooth else 0.0\n        E_cross = max(errors_cross) if errors_cross else 0.0\n        \n        all_results.append([E_all, E_smooth, E_cross])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists of floats.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        }
    ]
}