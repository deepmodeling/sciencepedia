{
    "hands_on_practices": [
        {
            "introduction": "This first practice focuses on the fundamental mechanics of computing polynomial chaos coefficients. You will explore how to determine the coefficients for a simple nonlinear model by applying the principle of orthogonal projection. This exercise contrasts the analytical, exact solution with a numerical approximation using Gauss-Hermite quadrature, providing a tangible understanding of approximation error which is central to all computational UQ methods. ",
            "id": "4150845",
            "problem": "In a one-dimensional harmonic acoustic cavity, suppose the uncertain wall admittance is modeled as a log-normal parameter and its effect on the steady-state, dimensionless pressure amplitude at a sensor can be abstracted by the nonlinear map $u(\\xi)=\\exp(\\xi)$, where $\\xi$ is a standard normal random variable with probability density function $\\varphi(\\xi)=\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{\\xi^{2}}{2}\\right)$. Consider the generalized Polynomial Chaos (gPC) expansion of $u(\\xi)$ in the orthonormal Hermite basis up to degree $3$, i.e.,\n$$\nu(\\xi) \\approx \\sum_{n=0}^{3} a_{n} \\,\\psi_{n}(\\xi),\n$$\nwhere $\\{\\psi_{n}(\\xi)\\}_{n=0}^{\\infty}$ are the probabilists’ Hermite polynomials normalized to be orthonormal with respect to the standard normal measure, with the explicit forms\n$$\n\\psi_{0}(\\xi)=1,\\quad \\psi_{1}(\\xi)=\\xi,\\quad \\psi_{2}(\\xi)=\\frac{\\xi^{2}-1}{\\sqrt{2}},\\quad \\psi_{3}(\\xi)=\\frac{\\xi^{3}-3\\xi}{\\sqrt{6}}.\n$$\nThe gPC coefficients are defined by the orthogonal projection $a_{n}=\\mathbb{E}[\\,u(\\xi)\\,\\psi_{n}(\\xi)\\,]$, where $\\mathbb{E}[\\cdot]$ denotes expectation with respect to $\\varphi(\\xi)$.\n\nYour tasks are:\n- Derive the exact coefficients $a_{n}$ for $n=0,1,2,3$ from first principles.\n- Approximate the same coefficients using the two-point Gauss–Hermite quadrature tailored to the weight $\\exp(-x^{2})$ and appropriately scaled to the standard normal measure. Use the nodes $x_{1}=-\\frac{1}{\\sqrt{2}}$, $x_{2}=\\frac{1}{\\sqrt{2}}$ and weights $w_{1}=w_{2}=\\frac{\\sqrt{\\pi}}{2}$ for the weight $\\exp(-x^{2})$. Apply the scaling $\\xi=\\sqrt{2}\\,x$ so that, for any integrable function $f$, the expectation is approximated by\n$$\n\\mathbb{E}[\\,f(\\xi)\\,] \\approx \\frac{1}{\\sqrt{\\pi}}\\sum_{i=1}^{2} w_{i}\\, f\\!\\big(\\sqrt{2}\\,x_{i}\\big)=\\frac{1}{2}\\Big(f(-1)+f(1)\\Big).\n$$\n- Quantify the quadrature error by computing the Euclidean norm of the coefficient error vector across degrees $0,1,2,3$, namely\n$$\n\\left\\| \\mathbf{e}\\right\\|_{2}=\\sqrt{\\sum_{n=0}^{3}\\left(a_{n}^{\\mathrm{GH}}-a_{n}^{\\mathrm{exact}}\\right)^{2}},\n$$\nwhere $a_{n}^{\\mathrm{GH}}$ is the Gauss–Hermite approximation and $a_{n}^{\\mathrm{exact}}$ is the exact coefficient.\n\nExpress the final error $\\left\\|\\mathbf{e}\\right\\|_{2}$ as a single closed-form analytic expression in terms of $e$. No rounding is required. The final answer must be a single expression and dimensionless.",
            "solution": "The user wants to solve a problem in uncertainty quantification.\n\n### Step 1: Extract Givens\n-   **Model:** A nonlinear map $u(\\xi)=\\exp(\\xi)$ describes the quantity of interest.\n-   **Random Input:** $\\xi$ is a standard normal random variable, $\\xi \\sim N(0,1)$, with probability density function (PDF) $\\varphi(\\xi)=\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\xi^{2}}{2}\\right)$.\n-   **Approximation:** A generalized Polynomial Chaos (gPC) expansion up to degree $3$ is used: $u(\\xi) \\approx \\sum_{n=0}^{3} a_{n} \\,\\psi_{n}(\\xi)$.\n-   **Basis Polynomials:** The basis is the set of orthonormal probabilists' Hermite polynomials:\n    -   $\\psi_{0}(\\xi)=1$\n    -   $\\psi_{1}(\\xi)=\\xi$\n    -   $\\psi_{2}(\\xi)=\\frac{\\xi^{2}-1}{\\sqrt{2}}$\n    -   $\\psi_{3}(\\xi)=\\frac{\\xi^{3}-3\\xi}{\\sqrt{6}}$\n-   **Coefficient Definition:** The exact gPC coefficients are given by the orthogonal projection $a_{n}=\\mathbb{E}[\\,u(\\xi)\\,\\psi_{n}(\\xi)\\,]$, where $\\mathbb{E}[\\cdot]$ is the expectation with respect to the standard normal measure.\n-   **Quadrature Rule:** A two-point Gauss-Hermite quadrature is used for approximation. For a function $f(\\xi)$, the expectation is approximated as $\\mathbb{E}[\\,f(\\xi)\\,] \\approx \\frac{1}{2}\\big(f(-1)+f(1)\\big)$.\n-   **Tasks:**\n    1.  Derive the exact coefficients $a_{n}^{\\mathrm{exact}}$ for $n=0,1,2,3$.\n    2.  Approximate the coefficients $a_{n}^{\\mathrm{GH}}$ for $n=0,1,2,3$ using the given quadrature.\n    3.  Compute the Euclidean norm of the coefficient error vector, $\\left\\| \\mathbf{e}\\right\\|_{2}=\\sqrt{\\sum_{n=0}^{3}\\left(a_{n}^{\\mathrm{GH}}-a_{n}^{\\mathrm{exact}}\\right)^{2}}$.\n-   **Final Answer Format:** A single closed-form analytic expression in terms of $e$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is a standard exercise in computational methods for uncertainty quantification, specifically using gPC. All definitions, including the polynomials and the quadrature rule, are standard and correctly stated. The problem is self-contained, and the tasks are clearly defined, leading to a unique solution. No flaws are detected.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation\n\n#### Task 1: Exact Coefficients $a_{n}^{\\mathrm{exact}}$\nThe exact coefficients are defined by the integral $a_{n}^{\\mathrm{exact}} = \\mathbb{E}[u(\\xi)\\psi_{n}(\\xi)] = \\int_{-\\infty}^{\\infty} \\exp(\\xi) \\psi_n(\\xi) \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\xi^2}{2}\\right) d\\xi$.\n\nA known result for the gPC expansion of the function $u(\\xi) = \\exp(c\\xi)$ with a standard normal input $\\xi$ and orthonormal probabilists' Hermite polynomials is that the coefficients are given by:\n$$a_n = \\exp\\left(\\frac{c^2}{2}\\right) \\frac{c^n}{\\sqrt{n!}}$$\nIn this problem, $u(\\xi)=\\exp(\\xi)$, so $c=1$. The exact coefficients are:\n$$a_{n}^{\\mathrm{exact}} = \\exp\\left(\\frac{1}{2}\\right) \\frac{1}{\\sqrt{n!}} = \\frac{\\sqrt{e}}{\\sqrt{n!}}$$\nFor $n=0,1,2,3$, we have:\n-   $a_{0}^{\\mathrm{exact}} = \\frac{\\sqrt{e}}{\\sqrt{0!}} = \\sqrt{e}$\n-   $a_{1}^{\\mathrm{exact}} = \\frac{\\sqrt{e}}{\\sqrt{1!}} = \\sqrt{e}$\n-   $a_{2}^{\\mathrm{exact}} = \\frac{\\sqrt{e}}{\\sqrt{2!}} = \\frac{\\sqrt{e}}{\\sqrt{2}}$\n-   $a_{3}^{\\mathrm{exact}} = \\frac{\\sqrt{e}}{\\sqrt{3!}} = \\frac{\\sqrt{e}}{\\sqrt{6}}$\n\n#### Task 2: Approximate Coefficients $a_{n}^{\\mathrm{GH}}$\nThe coefficients are approximated using the given two-point Gauss-Hermite quadrature rule. The integrand for each coefficient is $f_n(\\xi) = u(\\xi)\\psi_n(\\xi) = \\exp(\\xi)\\psi_n(\\xi)$. The quadrature formula is:\n$$a_{n}^{\\mathrm{GH}} = \\mathbb{E}[f_n(\\xi)]_{\\mathrm{GH}} = \\frac{1}{2}\\Big(f_n(-1) + f_n(1)\\Big) = \\frac{1}{2}\\Big(\\exp(-1)\\psi_n(-1) + \\exp(1)\\psi_n(1)\\Big)$$\nWe evaluate this for $n=0,1,2,3$:\n-   For $n=0$: $\\psi_0(-1)=1$, $\\psi_0(1)=1$.\n    $a_{0}^{\\mathrm{GH}} = \\frac{1}{2}(\\exp(-1) \\cdot 1 + e \\cdot 1) = \\frac{e+e^{-1}}{2} = \\cosh(1)$.\n-   For $n=1$: $\\psi_1(-1)=-1$, $\\psi_1(1)=1$.\n    $a_{1}^{\\mathrm{GH}} = \\frac{1}{2}(\\exp(-1) \\cdot (-1) + e \\cdot 1) = \\frac{e-e^{-1}}{2} = \\sinh(1)$.\n-   For $n=2$: $\\psi_2(-1)=\\frac{(-1)^2-1}{\\sqrt{2}}=0$, $\\psi_2(1)=\\frac{1^2-1}{\\sqrt{2}}=0$.\n    $a_{2}^{\\mathrm{GH}} = \\frac{1}{2}(\\exp(-1) \\cdot 0 + e \\cdot 0) = 0$.\n-   For $n=3$: $\\psi_3(-1)=\\frac{(-1)^3-3(-1)}{\\sqrt{6}}=\\frac{2}{\\sqrt{6}}$, $\\psi_3(1)=\\frac{1^3-3(1)}{\\sqrt{6}}=\\frac{-2}{\\sqrt{6}}$.\n    $a_{3}^{\\mathrm{GH}} = \\frac{1}{2}\\left(\\exp(-1) \\cdot \\frac{2}{\\sqrt{6}} + e \\cdot \\frac{-2}{\\sqrt{6}}\\right) = \\frac{1}{\\sqrt{6}}(e^{-1}-e) = -\\frac{e-e^{-1}}{\\sqrt{6}} = -\\frac{2\\sinh(1)}{\\sqrt{6}}$.\n\n#### Task 3: Quadrature Error Norm\nThe error vector is $\\mathbf{e}$, with components $e_n = a_{n}^{\\mathrm{GH}} - a_{n}^{\\mathrm{exact}}$.\n-   $e_0 = \\cosh(1) - \\sqrt{e}$\n-   $e_1 = \\sinh(1) - \\sqrt{e}$\n-   $e_2 = 0 - \\frac{\\sqrt{e}}{\\sqrt{2}} = -\\frac{\\sqrt{e}}{\\sqrt{2}}$\n-   $e_3 = -\\frac{2\\sinh(1)}{\\sqrt{6}} - \\frac{\\sqrt{e}}{\\sqrt{6}} = -\\frac{1}{\\sqrt{6}}(2\\sinh(1)+\\sqrt{e})$\n\nThe squared Euclidean norm of the error is $\\|\\mathbf{e}\\|_2^2 = \\sum_{n=0}^{3} e_n^2$.\n$\\|\\mathbf{e}\\|_2^2 = (\\cosh(1)-\\sqrt{e})^2 + (\\sinh(1)-\\sqrt{e})^2 + \\left(-\\frac{\\sqrt{e}}{\\sqrt{2}}\\right)^2 + \\left(-\\frac{1}{\\sqrt{6}}(2\\sinh(1)+\\sqrt{e})\\right)^2$\n\nLet's expand each term:\n1.  $(\\cosh(1)-\\sqrt{e})^2 = \\cosh^2(1) - 2\\sqrt{e}\\cosh(1) + e$\n2.  $(\\sinh(1)-\\sqrt{e})^2 = \\sinh^2(1) - 2\\sqrt{e}\\sinh(1) + e$\n3.  $\\left(-\\frac{\\sqrt{e}}{\\sqrt{2}}\\right)^2 = \\frac{e}{2}$\n4.  $\\frac{1}{6}(2\\sinh(1)+\\sqrt{e})^2 = \\frac{1}{6}(4\\sinh^2(1) + 4\\sqrt{e}\\sinh(1) + e) = \\frac{2}{3}\\sinh^2(1) + \\frac{2}{3}\\sqrt{e}\\sinh(1) + \\frac{e}{6}$\n\nSumming these terms:\n$\\|\\mathbf{e}\\|_2^2 = \\left(\\cosh^2(1)+\\sinh^2(1)+\\frac{2}{3}\\sinh^2(1)\\right) + \\left(e+e+\\frac{e}{2}+\\frac{e}{6}\\right) + \\left(-2\\sqrt{e}\\cosh(1)-2\\sqrt{e}\\sinh(1)+\\frac{2}{3}\\sqrt{e}\\sinh(1)\\right)$\n\nGrouping the terms:\n-   Polynomial part: Using $\\cosh^2(x) = 1+\\sinh^2(x)$, we get $1+\\sinh^2(1)+\\sinh^2(1)+\\frac{2}{3}\\sinh^2(1) = 1+\\frac{8}{3}\\sinh^2(1)$.\n-   Constant in $e$: $2e+\\frac{e}{2}+\\frac{e}{6} = \\frac{12e+3e+e}{6} = \\frac{16e}{6} = \\frac{8e}{3}$.\n-   $\\sqrt{e}$ part: $-2\\sqrt{e}\\cosh(1) - \\frac{4}{3}\\sqrt{e}\\sinh(1)$.\n\nSo, $\\|\\mathbf{e}\\|_2^2 = 1+\\frac{8}{3}\\sinh^2(1) + \\frac{8e}{3} - 2\\sqrt{e}\\cosh(1) - \\frac{4}{3}\\sqrt{e}\\sinh(1)$.\n\nNow, we substitute the exponential forms: $\\sinh(x) = \\frac{e^x-e^{-x}}{2}$ and $\\cosh(x) = \\frac{e^x+e^{-x}}{2}$.\n-   $\\sinh^2(1) = \\left(\\frac{e-e^{-1}}{2}\\right)^2 = \\frac{e^2-2+e^{-2}}{4}$\n-   $\\sqrt{e}\\cosh(1) = e^{1/2}\\frac{e+e^{-1}}{2} = \\frac{e^{3/2}+e^{-1/2}}{2}$\n-   $\\sqrt{e}\\sinh(1) = e^{1/2}\\frac{e-e^{-1}}{2} = \\frac{e^{3/2}-e^{-1/2}}{2}$\n\nSubstituting these into the expression for $\\|\\mathbf{e}\\|_2^2$:\n$\\|\\mathbf{e}\\|_2^2 = 1+\\frac{8}{3}\\left(\\frac{e^2-2+e^{-2}}{4}\\right) + \\frac{8e}{3} - 2\\left(\\frac{e^{3/2}+e^{-1/2}}{2}\\right) - \\frac{4}{3}\\left(\\frac{e^{3/2}-e^{-1/2}}{2}\\right)$\n$= 1+\\frac{2}{3}(e^2-2+e^{-2}) + \\frac{8e}{3} - (e^{3/2}+e^{-1/2}) - \\frac{2}{3}(e^{3/2}-e^{-1/2})$\n\nDistribute and collect terms by powers of $e$:\n$= 1+\\frac{2}{3}e^2-\\frac{4}{3}+\\frac{2}{3}e^{-2} + \\frac{8e}{3} - e^{3/2}-e^{-1/2} - \\frac{2}{3}e^{3/2}+\\frac{2}{3}e^{-1/2}$\n$= \\left(1-\\frac{4}{3}\\right) + \\frac{2}{3}e^2 + \\frac{8e}{3} + \\left(-1-\\frac{2}{3}\\right)e^{3/2} + \\left(-1+\\frac{2}{3}\\right)e^{-1/2} + \\frac{2}{3}e^{-2}$\n$= -\\frac{1}{3} + \\frac{2}{3}e^2 + \\frac{8e}{3} - \\frac{5}{3}e^{3/2} - \\frac{1}{3}e^{-1/2} + \\frac{2}{3}e^{-2}$\n\nThis can be factored as:\n$\\|\\mathbf{e}\\|_2^2 = \\frac{1}{3} (2e^2 + 8e - 1 + 2e^{-2} - 5e^{3/2} - e^{-1/2})$\n\nThe quadrature error is the square root of this expression.\n$\\|\\mathbf{e}\\|_2 = \\sqrt{\\frac{1}{3} (2e^2 + 8e - 1 + 2e^{-2} - 5e^{3/2} - e^{-1/2})}$",
            "answer": "$$\n\\boxed{\\sqrt{\\frac{1}{3}\\left(2e^2 + 8e - 5e^{\\frac{3}{2}} - e^{-\\frac{1}{2}} + 2e^{-2} - 1\\right)}}\n$$"
        },
        {
            "introduction": "Real-world systems often have multiple sources of uncertainty with different statistical characters. This exercise tackles this challenge by asking you to construct a basis for a two-dimensional problem with mixed uncertainties—one Gaussian and one uniform. By selecting the appropriate polynomial families according to the Wiener-Askey scheme and applying the tensor-product construction, you will build the essential multi-dimensional framework upon which a full gPC analysis rests. ",
            "id": "4150847",
            "problem": "Consider a one-dimensional linear acoustic wave in a homogeneous medium where the sound speed is modeled as a random variable depending on two independent inputs, one Gaussian and one uniformly distributed. A Polynomial Chaos Expansion (PCE) is to be constructed for a scalar response quantity of interest in this computational acoustics setting. The PCE requires a set of orthonormal polynomial basis functions with respect to the probability measures of the random inputs. Specifically, let the two independent inputs be distributed as follows: $\\,\\xi_1 \\sim \\mathcal{N}(0,1)\\,$ and $\\,\\xi_2 \\sim \\mathcal{U}[-1,1]\\,$. \n\nStarting from the definition of orthonormality with respect to a probability measure and the independence of inputs, select appropriate univariate orthogonal polynomial families for $\\,\\xi_1\\,$ and $\\,\\xi_2\\,$ and determine their normalization to produce orthonormal bases. Then, use the tensor-product construction under the product measure for independent inputs to build a mixed Hermite–Legendre basis for the PCE of total polynomial degree less than or equal to $\\,2\\,$. \n\nProvide the final set of basis functions as explicit polynomials in $\\,\\xi_1\\,$ and $\\,\\xi_2\\,$ that are orthonormal under the joint probability density. Your final answer must be a single composite mathematical object listing all basis functions. No rounding is required.",
            "solution": "The problem requires the construction of an orthonormal polynomial basis for a two-dimensional random input space, up to a total polynomial degree of $2$. The random vector is $\\boldsymbol{\\xi} = (\\xi_1, \\xi_2)$, where the components are independent random variables with specified probability distributions: $\\xi_1$ follows a standard normal distribution, $\\xi_1 \\sim \\mathcal{N}(0,1)$, and $\\xi_2$ follows a standard uniform distribution, $\\xi_2 \\sim \\mathcal{U}[-1,1]$.\n\nThe Polynomial Chaos Expansion (PCE) represents a random quantity as a series expansion in terms of orthogonal polynomials of the underlying random inputs. The choice of polynomial family is dictated by the probability distribution of the random input to ensure orthogonality, a principle encapsulated by the Wiener-Askey scheme. Since the inputs $\\xi_1$ and $\\xi_2$ are independent, the joint probability density function (PDF) is the product of the individual PDFs: $f(\\xi_1, \\xi_2) = f_1(\\xi_1) f_2(\\xi_2)$. Consequently, the multivariate orthonormal basis can be constructed as a tensor product of the univariate orthonormal bases.\n\nLet $\\{\\Psi_k^{(i)}(\\xi_i)\\}$ be the set of orthonormal polynomials for the $i$-th random variable $\\xi_i$. Orthonormality is defined with respect to the probability measure of the variable, which means:\n$$\n\\mathbb{E}[\\Psi_j^{(i)}(\\xi_i) \\Psi_k^{(i)}(\\xi_i)] = \\int \\Psi_j^{(i)}(x) \\Psi_k^{(i)}(x) f_i(x) dx = \\delta_{jk}\n$$\nwhere $\\delta_{jk}$ is the Kronecker delta.\n\nFirst, we determine the appropriate orthonormal basis for each random variable.\n\nFor the first input, $\\xi_1 \\sim \\mathcal{N}(0,1)$, the PDF is $f_1(\\xi_1) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\xi_1^2/2)$. The corresponding family of orthogonal polynomials is the probabilists' Hermite polynomials, denoted $H_k(\\xi_1)$. Their orthogonality property with respect to the standard normal measure is:\n$$\n\\mathbb{E}[H_j(\\xi_1) H_k(\\xi_1)] = \\int_{-\\infty}^{\\infty} H_j(\\xi_1) H_k(\\xi_1) \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\xi_1^2}{2}\\right) d\\xi_1 = k! \\delta_{jk}\n$$\nTo obtain an orthonormal basis $\\Psi_k^{(1)}(\\xi_1)$, we must normalize the Hermite polynomials by dividing by the square root of their squared norm, $\\sqrt{k!}$.\n$$\n\\Psi_k^{(1)}(\\xi_1) = \\frac{H_k(\\xi_1)}{\\sqrt{k!}}\n$$\nThe first three Hermite polynomials are:\n$H_0(\\xi_1) = 1$\n$H_1(\\xi_1) = \\xi_1$\n$H_2(\\xi_1) = \\xi_1^2 - 1$\nThus, the first three orthonormal univariate basis functions for $\\xi_1$ are:\n$\\Psi_0^{(1)}(\\xi_1) = \\frac{1}{\\sqrt{0!}} H_0(\\xi_1) = 1$\n$\\Psi_1^{(1)}(\\xi_1) = \\frac{1}{\\sqrt{1!}} H_1(\\xi_1) = \\xi_1$\n$\\Psi_2^{(1)}(\\xi_1) = \\frac{1}{\\sqrt{2!}} H_2(\\xi_1) = \\frac{1}{\\sqrt{2}}(\\xi_1^2 - 1)$\n\nFor the second input, $\\xi_2 \\sim \\mathcal{U}[-1,1]$, the PDF is $f_2(\\xi_2) = 1/2$ for $\\xi_2 \\in [-1,1]$ and $0$ otherwise. The corresponding family of orthogonal polynomials is the Legendre polynomials, $P_k(\\xi_2)$. Their standard orthogonality relation is with respect to a uniform weight function on $[-1,1]$:\n$$\n\\int_{-1}^{1} P_j(\\xi_2) P_k(\\xi_2) d\\xi_2 = \\frac{2}{2k+1} \\delta_{jk}\n$$\nTo achieve orthonormality with respect to the probability measure $f_2(\\xi_2)d\\xi_2$, we define a normalized basis $\\Psi_k^{(2)}(\\xi_2) = c_k P_k(\\xi_2)$ and solve for the normalization constant $c_k$:\n$$\n\\mathbb{E}[\\Psi_j^{(2)}(\\xi_2) \\Psi_k^{(2)}(\\xi_2)] = \\int_{-1}^{1} (c_j P_j(\\xi_2)) (c_k P_k(\\xi_2)) \\frac{1}{2} d\\xi_2 = \\frac{c_k^2}{2} \\int_{-1}^{1} P_k(\\xi_2)^2 d\\xi_2 = \\frac{c_k^2}{2} \\left(\\frac{2}{2k+1}\\right) = \\frac{c_k^2}{2k+1}\n$$\nFor this to equal $\\delta_{jk}$, we must have $c_k^2/(2k+1) = 1$, which gives $c_k = \\sqrt{2k+1}$.\nTherefore, the orthonormal basis functions are:\n$$\n\\Psi_k^{(2)}(\\xi_2) = \\sqrt{2k+1} P_k(\\xi_2)\n$$\nThe first three Legendre polynomials are:\n$P_0(\\xi_2) = 1$\n$P_1(\\xi_2) = \\xi_2$\n$P_2(\\xi_2) = \\frac{1}{2}(3\\xi_2^2 - 1)$\nThus, the first three orthonormal univariate basis functions for $\\xi_2$ are:\n$\\Psi_0^{(2)}(\\xi_2) = \\sqrt{1} P_0(\\xi_2) = 1$\n$\\Psi_1^{(2)}(\\xi_2) = \\sqrt{3} P_1(\\xi_2) = \\sqrt{3}\\xi_2$\n$\\Psi_2^{(2)}(\\xi_2) = \\sqrt{5} P_2(\\xi_2) = \\frac{\\sqrt{5}}{2}(3\\xi_2^2 - 1)$\n\nNext, we construct the bivariate basis functions $\\Phi_{\\boldsymbol{\\alpha}}(\\xi_1, \\xi_2)$ using the tensor-product approach. A basis function is identified by a multi-index $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2)$, where $\\alpha_1$ and $\\alpha_2$ are the polynomial degrees in $\\xi_1$ and $\\xi_2$, respectively.\n$$\n\\Phi_{\\boldsymbol{\\alpha}}(\\xi_1, \\xi_2) = \\Psi_{\\alpha_1}^{(1)}(\\xi_1) \\Psi_{\\alpha_2}^{(2)}(\\xi_2)\n$$\nThe problem specifies a total degree truncation, where the basis includes all polynomials such that the total degree $|\\boldsymbol{\\alpha}| = \\alpha_1 + \\alpha_2$ is less than or equal to $2$. We list all valid multi-indices $(\\alpha_1, \\alpha_2)$ where $\\alpha_1, \\alpha_2 \\ge 0$:\n\nTotal Degree $0$: $\\alpha_1 + \\alpha_2 = 0$\n\\begin{itemize}\n    \\item $\\boldsymbol{\\alpha} = (0,0)$: $\\Phi_{(0,0)} = \\Psi_0^{(1)}(\\xi_1) \\Psi_0^{(2)}(\\xi_2) = 1 \\cdot 1 = 1$\n\\end{itemize}\n\nTotal Degree $1$: $\\alpha_1 + \\alpha_2 = 1$\n\\begin{itemize}\n    \\item $\\boldsymbol{\\alpha} = (1,0)$: $\\Phi_{(1,0)} = \\Psi_1^{(1)}(\\xi_1) \\Psi_0^{(2)}(\\xi_2) = \\xi_1 \\cdot 1 = \\xi_1$\n    \\item $\\boldsymbol{\\alpha} = (0,1)$: $\\Phi_{(0,1)} = \\Psi_0^{(1)}(\\xi_1) \\Psi_1^{(2)}(\\xi_2) = 1 \\cdot (\\sqrt{3}\\xi_2) = \\sqrt{3}\\xi_2$\n\\end{itemize}\n\nTotal Degree $2$: $\\alpha_1 + \\alpha_2 = 2$\n\\begin{itemize}\n    \\item $\\boldsymbol{\\alpha} = (2,0)$: $\\Phi_{(2,0)} = \\Psi_2^{(1)}(\\xi_1) \\Psi_0^{(2)}(\\xi_2) = \\frac{1}{\\sqrt{2}}(\\xi_1^2 - 1) \\cdot 1 = \\frac{1}{\\sqrt{2}}(\\xi_1^2 - 1)$\n    \\item $\\boldsymbol{\\alpha} = (1,1)$: $\\Phi_{(1,1)} = \\Psi_1^{(1)}(\\xi_1) \\Psi_1^{(2)}(\\xi_2) = \\xi_1 \\cdot (\\sqrt{3}\\xi_2) = \\sqrt{3}\\xi_1\\xi_2$\n    \\item $\\boldsymbol{\\alpha} = (0,2)$: $\\Phi_{(0,2)} = \\Psi_0^{(1)}(\\xi_1) \\Psi_2^{(2)}(\\xi_2) = 1 \\cdot \\frac{\\sqrt{5}}{2}(3\\xi_2^2 - 1) = \\frac{\\sqrt{5}}{2}(3\\xi_2^2 - 1)$\n\\end{itemize}\n\nThe complete set of $6$ orthonormal basis functions for a total degree up to $2$ is:\n$1$, \\quad $\\xi_1$, \\quad $\\sqrt{3}\\xi_2$, \\quad $\\frac{1}{\\sqrt{2}}(\\xi_1^2 - 1)$, \\quad $\\sqrt{3}\\xi_1\\xi_2$, \\quad $\\frac{\\sqrt{5}}{2}(3\\xi_2^2 - 1)$\nThese functions are orthonormal with respect to the joint PDF $f(\\xi_1, \\xi_2) = \\frac{1}{2\\sqrt{2\\pi}} \\exp(-\\xi_1^2/2)$ on the domain $(-\\infty, \\infty) \\times [-1,1]$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & \\xi_1 & \\sqrt{3}\\xi_2 & \\frac{1}{\\sqrt{2}}(\\xi_1^2 - 1) & \\sqrt{3}\\xi_1\\xi_2 & \\frac{\\sqrt{5}}{2}(3\\xi_2^2 - 1) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A key goal of uncertainty quantification is to understand which input parameters most significantly impact the output. This final practice demonstrates how a gPC expansion provides a powerful and direct route to this insight via Global Sensitivity Analysis (GSA). Using a pre-computed set of chaos coefficients from an acoustics problem, you will calculate the first-order Sobol' indices to decompose the output variance and quantitatively rank the influence of each uncertain input. ",
            "id": "4150803",
            "problem": "Consider a narrowband, one-dimensional duct acoustics problem governed by the linearized frequency-domain wave equation, where the scalar output of interest is a real-valued acoustic amplitude $y$ at a fixed interior point. Two independent input parameters drive the uncertainty in $y$: a nondimensionalized speed-of-sound ratio $\\theta_{c}$ and a nondimensionalized boundary admittance $\\theta_{b}$. After an isoprobabilistic transform, these are modeled as independent standard normal random variables $\\xi_{1}$ and $\\xi_{2}$, respectively. A third-degree generalized Polynomial Chaos (gPC) representation based on a tensorized orthonormal Hermite basis $\\{\\psi_{\\alpha}(\\xi_{1},\\xi_{2})\\}$ with respect to the joint standard normal measure is obtained for $y$:\n$$\ny(\\xi_{1},\\xi_{2}) \\approx c_{00}\\,\\psi_{00} + c_{10}\\,\\psi_{10} + c_{01}\\,\\psi_{01} + c_{20}\\,\\psi_{20} + c_{02}\\,\\psi_{02} + c_{11}\\,\\psi_{11} + c_{30}\\,\\psi_{30} + c_{03}\\,\\psi_{03} + c_{21}\\,\\psi_{21} + c_{12}\\,\\psi_{12},\n$$\nwith nonzero coefficients\n$$\nc_{00}=1.2,\\quad c_{10}=0.8,\\quad c_{01}=0.3,\\quad c_{20}=0.2,\\quad c_{02}=0.1,\\quad c_{11}=-0.4,\\quad c_{30}=0.05,\\quad c_{03}=-0.02,\\quad c_{21}=0.06,\\quad c_{12}=-0.03.\n$$\nHere $\\psi_{\\alpha}$ denotes the orthonormal tensor-product basis function indexed by the multi-index $\\alpha=(\\alpha_{1},\\alpha_{2})$, where $\\alpha_{1}$ and $\\alpha_{2}$ are the polynomial degrees in $\\xi_{1}$ and $\\xi_{2}$, respectively; thus, for example, $\\psi_{30}(\\xi_{1},\\xi_{2})$ depends only on $\\xi_{1}$ and has total degree $3$.\n\nUsing only the orthogonality of the basis and the definition of variance decomposition under independence, compute the first-order Sobol indices $S_{\\xi_{1}}$ and $S_{\\xi_{2}}$ that quantify the contributions of $\\xi_{1}$ and $\\xi_{2}$, respectively, to the variance of $y$. Then, on the basis of these values, identify which input is the dominant contributor to the variance of $y$. Round each Sobol index to four significant figures. Express your final answer as the ordered pair $(S_{\\xi_{1}}, S_{\\xi_{2}})$.",
            "solution": "The problem asks for the first-order Sobol indices $S_{\\xi_1}$ and $S_{\\xi_2}$ for an output $y$ given by a gPC expansion with respect to two independent standard normal variables, $\\xi_1$ and $\\xi_2$.\n\nThe gPC expansion is given by:\n$$ y(\\xi_{1}, \\xi_{2}) \\approx \\sum_{\\alpha} c_{\\alpha} \\psi_{\\alpha}(\\xi_{1}, \\xi_{2}) $$\nwhere the basis functions $\\{\\psi_{\\alpha}\\}$ are orthonormal. Due to this orthonormality, the total variance of the output $y$, denoted $V(y)$, can be calculated directly from the coefficients as the sum of squares of all coefficients corresponding to non-constant basis functions:\n$$ V(y) = \\sum_{\\alpha \\neq (0,0)} c_{\\alpha}^2 $$\nThe coefficient $c_{00}$ corresponds to the mean of $y$ and is excluded from the variance calculation. Using the provided non-zero coefficients:\n\\begin{align*}\nV(y) &= c_{10}^2 + c_{01}^2 + c_{20}^2 + c_{02}^2 + c_{11}^2 + c_{30}^2 + c_{03}^2 + c_{21}^2 + c_{12}^2 \\\\\n&= (0.8)^2 + (0.3)^2 + (0.2)^2 + (0.1)^2 + (-0.4)^2 + (0.05)^2 + (-0.02)^2 + (0.06)^2 + (-0.03)^2 \\\\\n&= 0.64 + 0.09 + 0.04 + 0.01 + 0.16 + 0.0025 + 0.0004 + 0.0036 + 0.0009 \\\\\n&= 0.9474\n\\end{align*}\n\nThe first-order Sobol index $S_{\\xi_i}$ is the fraction of the total variance due to the main effect of the variable $\\xi_i$. It is calculated as $S_{\\xi_i} = V_{\\xi_i} / V(y)$, where the partial variance $V_{\\xi_i}$ is the sum of squares of coefficients for basis functions that depend *only* on $\\xi_i$.\n\nFor $\\xi_1$, the partial variance $V_{\\xi_1}$ includes contributions from terms with multi-indices $(\\alpha_1, 0)$ for $\\alpha_1 > 0$. The relevant coefficients are $c_{10}, c_{20}, c_{30}$:\n$$\nV_{\\xi_1} = c_{10}^2 + c_{20}^2 + c_{30}^2 = (0.8)^2 + (0.2)^2 + (0.05)^2 = 0.64 + 0.04 + 0.0025 = 0.6825\n$$\nThe Sobol index for $\\xi_1$ is:\n$$\nS_{\\xi_1} = \\frac{V_{\\xi_1}}{V(y)} = \\frac{0.6825}{0.9474} \\approx 0.7203926...\n$$\nRounding to four significant figures gives $S_{\\xi_1} = 0.7204$.\n\nFor $\\xi_2$, the partial variance $V_{\\xi_2}$ includes contributions from terms with multi-indices $(0, \\alpha_2)$ for $\\alpha_2 > 0$. The relevant coefficients are $c_{01}, c_{02}, c_{03}$:\n$$\nV_{\\xi_2} = c_{01}^2 + c_{02}^2 + c_{03}^2 = (0.3)^2 + (0.1)^2 + (-0.02)^2 = 0.09 + 0.01 + 0.0004 = 0.1004\n$$\nThe Sobol index for $\\xi_2$ is:\n$$\nS_{\\xi_2} = \\frac{V_{\\xi_2}}{V(y)} = \\frac{0.1004}{0.9474} \\approx 0.1059742...\n$$\nRounding to four significant figures gives $S_{\\xi_2} = 0.1060$.\n\nComparing the indices ($S_{\\xi_1} \\approx 0.7204$ vs. $S_{\\xi_2} \\approx 0.1060$), it is evident that $\\xi_1$ (representing the speed-of-sound ratio) is the dominant contributor to the variance of the output $y$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.7204 & 0.1060 \\end{pmatrix}}\n$$"
        }
    ]
}