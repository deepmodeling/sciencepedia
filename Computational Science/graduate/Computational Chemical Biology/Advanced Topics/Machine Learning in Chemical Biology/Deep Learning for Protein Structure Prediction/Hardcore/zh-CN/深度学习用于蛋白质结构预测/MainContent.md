## 引言
蛋白质的三维结构决定其生物学功能，破解从[氨基酸序列](@entry_id:163755)到其复杂空间构象的“折叠密码”是过去半个世纪以来生物学领域最核心的挑战之一。尽管实验方法取得了巨大进步，但确定[蛋白质结构](@entry_id:140548)仍然是一个成本高昂且耗时的过程，这严重限制了我们对生命机制的理解和新药的开发。近年来，深度学习技术的突破，尤其是以[AlphaFold2](@entry_id:168230)为代表的模型，以前所未有的准确性解决了这一长期存在的难题，引发了[结构生物学](@entry_id:151045)的一场革命。这场革命不仅在于预测结果的精确度，更在于其背后深刻的计算原理和广阔的应用前景。

本文旨在系统性地剖析驱动这场革命的深度学习技术。我们将分三个章节展开：

*   在“**原理与机制**”中，我们将深入探讨模型的核心，从蛋白质几何的计算表示、进化信息的编码，到S[E(3)[等变神经网](@entry_id:748761)络](@entry_id:137437)的架构设计和专门的损失函数。
*   接着，在“**应用与跨学科连接**”中，我们将展示这些理论如何转化为解决实际科学问题的工具，涵盖单体与复合物的[结构预测](@entry_id:1132571)、[计算蛋白质设计](@entry_id:202615)以及在[药物发现](@entry_id:261243)和[病毒学](@entry_id:175915)中的应用。
*   最后，在“**动手实践**”部分，我们将通过具体的编程练习，让您亲手实现关键的评估指标和[损失函数](@entry_id:634569)，加深对核心概念的理解。

通过本次学习，您将不仅理解深度学习模型“做什么”，更能洞悉其“如何做”以及“为何能做”，从而掌握这项改变游戏规则的技术。

## 原理与机制

本章将深入探讨驱动现代[蛋白质结构预测](@entry_id:144312)深度学习模型的核心科学原理与计算机制。我们将从蛋白质结构的表示方法出发，解析进化信息如何被编码和利用，剖析尖端神经网络的架构设计哲学，并最终阐述如何通过特定的[损失函数](@entry_id:634569)和评估指标来训练和衡量这些模型。

### 蛋白质几何的计算表示

在计算机中描述一个三维大分子是一项根本性的挑战。选择合适的表示方法，不仅影响计算效率，更决定了模型能否有效学习和强制执行[物理化学](@entry_id:145220)定律。

#### 笛卡尔坐标与内部坐标

表示蛋白质结构最直接的方法是使用**[笛卡尔坐标](@entry_id:167698) (Cartesian coordinates)**。在该体系中，每个原子 $i$ 的位置由一个三维向量 $\mathbf{x}_i \in \mathbb{R}^3$ 指定，该向量相对于一个[全局坐标系](@entry_id:171029)原点。这种表示法虽然直观，但存在几个显著的缺点。首先，对于一个包含 $N$ 个原子的蛋白质，需要 $3N$ 个坐标来描述，这是一个高维空间，使得从头生成有效结构变得非常困难。其次，笛卡尔坐标本身并未内嵌任何关于分子几何的先验知识；原子间的[键长](@entry_id:144592)和键角可以任意取值，这使得大多数随机选择的坐标点都对应于物理上不现实的构象。

从对称性的角度看，[笛卡尔坐标](@entry_id:167698)是**[协变](@entry_id:634097) (equivariant)** 的，而非**不变 (invariant)** 的。当整个蛋白质结构经历一个[刚体运动](@entry_id:144691)（即一次[旋转和平移](@entry_id:175994)，属于[特殊欧几里得群](@entry_id:139383) $\mathrm{SE}(3)$）时，其所有原子的坐标都会相应地改变。具体而言，若一个[刚体变换](@entry_id:150396)由[旋转矩阵](@entry_id:140302) $R \in \mathrm{SO}(3)$ 和平移向量 $t \in \mathbb{R}^3$ 定义，则每个原子的坐标从 $\mathbf{x}_i$ 变为 $\mathbf{x}_i' = R\mathbf{x}_i + t$。这一[协变](@entry_id:634097)性质是物理定律的基础，任何处理三维坐标的深度学习模型都必须尊重它。

另一种更符合化学直觉的表示法是**内部坐标 (internal coordinates)**。该方法基于分子的共价连接图，通过一系列**键长 (bond lengths)**、$l$、**键角 (bond angles)**、$\theta$ 和**二面角 (dihedral angles)**、$\phi$ 来定义结构 。

-   **[键长](@entry_id:144592)** $l$：两个[共价键](@entry_id:146178)合原子间的距离。
-   **键角** $\theta$：由三个连续键合的原子构成的角度。
-   **二面角** $\phi$：定义为由原子 $(i, j, k)$ 构成的平面与由原子 $(j, k, l)$ 构成的平面之间的夹角。它描述了围绕[共价键](@entry_id:146178) $j-k$ 的扭转。

内部坐标的最大优势在于它们可以自然地编码化学约束。由于量子化的[电子轨道](@entry_id:157718)，蛋白质中的[共价键](@entry_id:146178)长和键角在很大程度上是恒定的 。因此，我们可以将它们视为固定参数，从而将描述[蛋白质构象](@entry_id:182465)的主要自由度简化为数量少得多的[二面角](@entry_id:185221)。这极大地缩小了需要探索的构象空间，并自动保证了局部几何的物理真实性。与[笛卡尔坐标](@entry_id:167698)不同，内部坐标（[键长](@entry_id:144592)、键角和[二面角](@entry_id:185221)）的值在整个分子进行[刚体运动](@entry_id:144691)时保持不变，因此它们是**$\mathrm{SE}(3)$-不变的 ([SE(3)](@entry_id:1131325)-invariant)**。值得注意的是，二面角是一个[伪标量](@entry_id:196696)，其符号会在镜像反射（属于 $\mathrm{O}(3) \setminus \mathrm{SO}(3)$ 的操作）下翻转，这一特性使其能够编码分子的手性。

#### 扭转角与运动学模型

在蛋白质中，最关键的变量是[主链](@entry_id:183224)和侧链的扭转角（即二面角）。

-   **[主链](@entry_id:183224)扭转角**：
    -   $\phi$ (phi): 围绕 $N_i-C_{\alpha,i}$ 键的旋转，由原子 $C_{i-1}-N_i-C_{\alpha,i}-C_i$ 定义。
    -   $\psi$ (psi): 围绕 $C_{\alpha,i}-C_i$ 键的旋转，由原子 $N_i-C_{\alpha,i}-C_i-N_{i+1}$ 定义。
    -   $\omega$ (omega): 围绕[肽键](@entry_id:144731) $C_i-N_{i+1}$ 的旋转，由原子 $C_{\alpha,i}-C_i-N_{i+1}-C_{\alpha,i+1}$ 定义。由于[肽键](@entry_id:144731)的[共振效应](@entry_id:155120)使其具有部分双键性质，该键的旋转受到严格限制，导致肽单元（$C_{\alpha,i}, C_i, O_i, N_{i+1}, H_{i+1}, C_{\alpha,i+1}$）基本处于一个平面上。因此，$\omega$ 角通常接近 $180^\circ$ (反式, trans) 或（在[脯氨酸](@entry_id:166601)旁）偶尔为 $0^\circ$ (顺式, cis)。

-   **侧链扭转角**：
    -   $\chi$ (chi): 描述侧[链构象](@entry_id:199194)的一系列角度，如 $\chi_1$ 通常定义了围绕 $C_{\alpha,i}-C_{\beta,i}$ 键的旋转。

从内部坐标（主要是扭转角，并假设[键长](@entry_id:144592)和键角固定）到[笛卡尔坐标](@entry_id:167698)的转换，可以通过一个**运动学模型 (kinematic model)** 实现。这个过程可以看作是一系列[刚体变换](@entry_id:150396)的连乘积。从蛋白质的N端开始，每个原子的笛卡尔坐标都可以通过前一个原子的坐标，加上由[键长](@entry_id:144592)、键角和扭转角决定的局部[旋转和平移](@entry_id:175994)来确定 。这个前向构建过程中的每一步都是一个 $\mathrm{SE}(3)$ 变换，并且整个过程是可[微分](@entry_id:158422)的。对于一个围绕轴 $\hat{\mathbf{u}}$（过点 $\mathbf{x}_0$）的扭转角 $\tau$，其对下游任一原子位置 $\mathbf{x}$ 的影响（即[雅可比矩阵](@entry_id:178326)）可以通过简单的叉乘计算得出：$\frac{\partial \mathbf{x}}{\partial \tau} = \hat{\mathbf{u}} \times (\mathbf{x} - \mathbf{x}_0)$。这为在[深度学习模型](@entry_id:635298)中通过[反向传播](@entry_id:199535)优化扭转角提供了数学基础。

#### 硬约束与软偏好

为了生成物理上完全现实的蛋白质模型，区分**硬性[立体化学约束](@entry_id:202820) (stereochemical constraints)** 和**软性能量偏好 (soft energy preferences)** 至关重要 。

-   **硬约束**：这些是几乎从不被违反的规则，源于非常高的能量势垒（远大于热能 $k_B T$）。在建模时，它们通常被视为等式或严格的[不等式约束](@entry_id:176084)。它们包括：
    1.  **固定的[共价键](@entry_id:146178)长和键角**：如前所述，这些参数的波动极小。
    2.  **[肽键](@entry_id:144731)的[平面性](@entry_id:274781)**：$\omega$ 角被严格限制在 $0^\circ$ 或 $180^\circ$ 附近。
    3.  **手性**：除甘氨酸外，所有[标准氨基酸](@entry_id:166527)的 $\alpha$-碳 ($C_\alpha$) 均为 L-构型。要翻转手性需要打破[共价键](@entry_id:146178)，这是一个化学反应，而非[构象变化](@entry_id:185671)。

-   **软偏好**：这些是能量上更有利的构象，但体系在[热涨落](@entry_id:143642)的影响下仍可能采样到其他构象。它们的能量差异通常在 $k_B T$ 的量级。在建模时，它们通常被编码为能量函数或损失项，引导模型趋向于这些偏好，但不强制执行。它们包括：
    1.  **Ramachandran 图分布**：主链的 $(\phi, \psi)$ 角由于[空间位阻](@entry_id:156748)，倾向于落在特定的“允许”区域内。
    2.  **[侧链旋转异构体](@entry_id:190441) (rotamers)**：[侧链](@entry_id:182203)的 $\chi$ 角倾向于采取特定的离散值，以最小化与[主链](@entry_id:183224)和其他侧链的碰撞。
    3.  **[氢键网络](@entry_id:750458)** 和其他[非共价相互作用](@entry_id:178248)。

在深度学习模型中，硬约束可以通过使用内部坐标表示或在结构生成后进行几何修正来强制执行，而软偏好则通过训练数据中学习到的统计模式和在[损失函数](@entry_id:634569)中加入能量项来体现。

### 进化的力量：[多序列比对](@entry_id:176306)

如果说几何约束定义了蛋白质“可能”是什么样子，那么进化信息则揭示了它“应该”是什么样子。单个[氨基酸序列](@entry_id:163755)包含的结构信息有限，而蕴含在进化历史中的共变模式是解开[蛋白质折叠](@entry_id:136349)之谜的关键。

#### [多序列比对](@entry_id:176306)与有效序列数

用于[结构预测](@entry_id:1132571)的主要进化信息来源是**[多序列比对](@entry_id:176306) (Multiple Sequence Alignment, MSA)**。一个 MSA 是一个 $N \times L$ 的矩阵，其中 $N$ 是同源序列的数量（**比对深度**），$L$ 是蛋白质的长度。矩阵的每一行是一个同源蛋白质的序列，它们经过排列，使得在进化上对应的残基位于同一列。

然而，原始的 MSA 序列不是[独立同分布](@entry_id:169067)的。由于共同的进化祖先，某些序列分支（clade）可能被过度采样，导致 MSA 中存在大量高度相似的冗余序列。为了量化和校正这种冗余，我们计算**有效序列数 ($N_{\text{eff}}$)** 。一种常见的方法是：

1.  设定一个[序列一致性](@entry_id:172968)阈值 $\tau$（例如 $\tau=0.80$）。
2.  对于 MSA 中的每个序列 $S_i$，计算其“邻居”数量 $n_i(\tau)$，即与 $S_i$ 的[序列一致性](@entry_id:172968)大于或等于 $\tau$ 的序列总数（包括 $S_i$ 自身）。
3.  为每个序列 $S_i$ 分配一个权重 $w_i = 1 / n_i(\tau)$。位于密集聚类中的序列将获得较低的权重。
4.  有效序列数 $N_{\text{eff}}$ 是所有权重的总和：$N_{\text{eff}} = \sum_{i=1}^{N} w_i$。

$N_{\text{eff}}$ 比原始深度 $N$ 更能反映 MSA 中包含的独立进化信息的真实数量。一个“好”的 MSA 不仅需要深度大，更需要多样性高（即 $N_{\text{eff}}$ 接近 $N$）。

#### 共进化假说：接触的指纹

MSA 的核心价值在于**共进化 (coevolution)** 假说 。该假说指出：在[蛋白质三维结构](@entry_id:193120)中物理接触的两个残基，为了维持结构的稳定性和功能，它们在进化过程中会协同突变。这种现象被称为**[上位性](@entry_id:136574) (epistasis)**。例如，如果一个残基发生了一次有害的突变（如一个大的疏水残基变成小的亲水残基），与其接触的另一个残基可能会发生一次**[补偿性突变](@entry_id:154377) (compensatory mutation)**（如也从疏水变为亲水），以恢复相互作用的稳定性。

随着时间的推移，这种成对的[补偿性突变](@entry_id:154377)会在 MSA 的对应列中留下统计指纹。即使这两个残基在序列上相距很远，它们的氨基酸组成也会显示出相关性。因此，通过检测 MSA 列与列之间的[统计依赖性](@entry_id:267552)，我们可以推断出哪些残基对在空间上是邻近的。

然而，从 MSA 中准确地提取共进化信号并非易事。一个主要的混淆因素是**[系统发育](@entry_id:137790) (phylogeny)**。由于共同的祖先，不接触的残基对也可能因为继承了相同的突变而显示出相关性。这种由[系统发育](@entry_id:137790)引起的伪信号会淹没真实的结构接触信号。简单地增加 MSA 的深度，特别是如果新增的序列来自一个已经过度采样的分支，反而会加剧[系统发育](@entry_id:137790)的偏差 。因此，序列重加权（如计算 $N_{eff}$ 时所做的）是一种重要的[启发式方法](@entry_id:637904)，用于减轻这种偏差。更强大的方法，如**[直接耦合分析](@entry_id:175442) (Direct Coupling Analysis, DCA)**，通过拟合全局统计模型（如逆 Potts 模型）来区分直接耦合（通常对应接触）和间接传递的相关性。而现代深度神经网络，通过学习 MSA 的复杂[条件概率分布](@entry_id:163069)，能够以更高精度地[解耦](@entry_id:160890)这些混合信号。

### 现代预测器的架构蓝图

基于上述原理，现代[蛋白质结构预测](@entry_id:144312)模型，如 [AlphaFold2](@entry_id:168230)，采用了一种复杂而优雅的架构，将进化信息和几何约束无缝地整合在一起。其核心可以概括为一个三阶段的流程 。

#### 双轨[并行处理](@entry_id:753134)：序列与配对表示

模型的核心是一个被称为**Evoformer**的强大模块，它并行地处理和更新两种不同粒度的信息表示 ：

1.  **MSA/序列表示 ($s_i$)**: 这是一个 $N \times L \times d_s$ 的张量（$d_s$ 是特征维度），编码了每个残基在所有同源序列上下文中的信息。它起初是经过处理的 MSA，然后在网络层中不断被提炼。

2.  **配对表示 ($p_{ij}$)**: 这是一个 $L \times L \times d_p$ 的张量，编码了每对残基 $(i, j)$ 之间的关系信息。它的初始特征可以包括残基在序列上的相对位置，以及从 MSA 中提取的初步共进化[耦合强度](@entry_id:275517)。

这两种表示之间存在着密切的信息交流。Evoformer 模块通过交替执行以下操作来迭代地提炼信息：

-   **MSA 表示的更新**: 通过基于**注意力 (attention)** 的机制完成。首先，模型在 MSA 的行（序列）之间应用注意力，这允许它比较和聚合来自不同同源物的信息。由于同源序列的顺序是任意的，此操作必须是**排列[协变](@entry_id:634097)的 (permutation-equivariant)**。接着，模型在 MSA 的列（残基位置）之间应用注意力，从而在[蛋白质序列](@entry_id:184994)的不同位置间传递信息。至关重要的是，在计算列注意力时，注意力权重会受到当前配对表示 $p_{ij}$ 的偏置影响。这意味着，如果模型已经相信残基 $i$ 和 $j$ 是相互作用的（来自 $p_{ij}$ 的信息），它将促进这两个位置之间的信息流动 。

-   **配对表示的更新**: 这是该架构最具创新性的部分之一，通过所谓的**三角乘法更新 (triangular multiplicative updates)** 实现。这个操作旨在使配对表示在几何上自洽。其思想来源于几何学中的**[三角不等式](@entry_id:143750)**：如果残基 $i$ 和 $k$ 接近，并且 $k$ 和 $j$ 也接近，那么 $i$ 和 $j$ 不可能相距太远。三角更新通过聚合所有中间残基 $k$ 的信息来更新 $p_{ij}$ 的表示，形式为 $p_{ij} \leftarrow \phi(p_{ij}, p_{ik}, p_{kj})$。通过这种方式，模型可以在整个蛋白质的“关系图”上传播和强化几何约束，使其学习到的配对表示更符合一个真实的三维欧几里得空间嵌入 。

经过多轮 Evoformer 模块的迭代处理后，模型生成了高度精炼的序列表示和配对表示，它们分别编码了每个残基的局部环境和每对残基间的空间关系。

### 几何的语言：[SE(3)](@entry_id:1131325) 协方差

当模型从抽象的特征转向生成具体的三维[坐标时](@entry_id:263720)，它必须遵循三维空间的[基本对称性](@entry_id:161256)。物理定律不应依赖于我们如何选择坐标系的原点和方向。这一物理原理在数学上通过**[特殊欧几里得群](@entry_id:139383) $\mathrm{SE}(3)$ (Special Euclidean group $\mathrm{SE}(3)$)** 来形式化。

#### [不变性](@entry_id:140168)与协方差

在深度学习的背景下，一个函数或模型 $f$ 对于一个群 $G$（如 $\mathrm{SE}(3)$）的对称性有两种主要形式 ：

-   **[不变性](@entry_id:140168) (Invariance)**: 如果对输入应用群变换 $g \in G$，输出保持不变，即 $f(g \cdot x) = f(x)$。例如，一个蛋白质的总能量是一个标量，它不随蛋白质在空间中的平移或旋转而改变，因此能量预测函数必须是 $\mathrm{SE}(3)$-不变的。

-   **协方差 (Equivariance)**: 如果对输入应用群变换 $g$，输出也以一种一致的方式进行变换，即 $f(g \cdot x) = g \cdot f(x)$（这里输出的变换方式与输入相同，但也可以不同）。这对于任何输入和输出都是坐标或向量的函数至关重要。例如，一个旨在优化蛋白质结构的函数 $f$，如果输入结构被[旋转和平移](@entry_id:175994)了，那么输出的优化结构也应该相应地被[旋转和平移](@entry_id:175994)。形式上，对于坐标预测模型 $f$，协方差要求 $f(RX+t) = Rf(X)+t$。

如果一个模型同时输出坐标 $\hat{X}$ 和能量 $E$，那么它必须对这两个输出表现出不同的对称性：坐标部分是[协变](@entry_id:634097)的，而能量部分是不变的。即 $f((R,t)\cdot X) = ((R,t)\cdot \hat{X}, E)$ 。

将 $\mathrm{SE}(3)$-协方差直接构建到神经网络的层结构中，是一种强大的**归纳偏置 (inductive bias)**。它强制网络学习那些本身就尊重物理对称性的操作，使得模型不必从数据中“发现”[旋转和平移](@entry_id:175994)的概念，从而极大地提高了数据效率和泛化能力。这类网络，如 [AlphaFold2](@entry_id:168230) 的结构模块，通过在更新过程中同时处理 $\mathrm{SE}(3)$-不变的特征（如距离）和 $\mathrm{SE}(3)$-协变的特征（如向量），来实现这一目标。

### 学习正确的形状：损失函数

拥有一个协变架构后，接下来的问题是如何训练它。[损失函数](@entry_id:634569)也必须与模型的对称性相匹配。一个直接计算预测坐标和真实坐标之间[均方根偏差](@entry_id:1131102)（RMSD）的[损失函数](@entry_id:634569)是不理想的，因为它需要一个全局的[刚体](@entry_id:1131033)对齐步骤，而这个对齐步骤本身可能存在歧义，并且在数学上不易处理。

为了解决这个问题，[AlphaFold2](@entry_id:168230) 引入了一种新颖的、$\mathrm{SE}(3)$-不变的损失函数，称为**框架对齐点误差 (Frame Aligned Point Error, FAPE)** 。

FAPE 的核心思想是在每个残基的局部参考系（或称框架）中进行误差计算，从而避免了全局对齐。一个局部参考系 $T_i = (R_i, t_i)$ 是一个定义在残基 $i$（通常基于其[主链](@entry_id:183224) N, C$\alpha$, C 原子）上的 $\mathrm{SE}(3)$ 变换。

FAPE 损失的计算过程如下：

1.  对于预测结构和目标结构，我们都有了一套每残基的局部框架，分别为 $\{T_i^{\mathrm{pred}}\}$ 和 $\{T_i^{\mathrm{tgt}}\}$。
2.  要计算任意原子 $j$ 的误差，我们首先将其预测坐标和目标坐标都转换到同一个参考系下——例如，残基 $i$ 的目标参考系 $T_i^{\mathrm{tgt}}$。
3.  要做到这一点，我们首先计算从预测框架 $T_i^{\mathrm{pred}}$ 到目标框架 $T_i^{\mathrm{tgt}}$ 的相对变换：$D_i = (T_i^{\mathrm{tgt}})^{-1} \circ T_i^{\mathrm{pred}}$。
4.  然后，我们将原子 $j$ 在其自身局部框架中的预测坐标 $u_{ij}^{\mathrm{pred}}$ 通过 $D_i$ 进行变换，得到 $D_i(u_{ij}^{\mathrm{pred}})$。这个新坐标表示了原子 $j$ 的预测位置，但是是在 $T_i^{\mathrm{tgt}}$ 的坐标系中描述的。
5.  最后，我们计算这个变换后的预测点与原子 $j$ 的目标点 $u_{ij}^{\mathrm{tgt}}$（它本身就在 $T_i^{\mathrm{tgt}}$ 坐标系中）之间的欧几里得距离。这个距离就是 FAPE 的一个分量：$e_{ij} = \| D_i(u_{ij}^{\mathrm{pred}}) - u_{ij}^{\mathrm{tgt}} \|_2$。
6.  最终的 FAPE 损失是对所有原子对 $(i, j)$ 的这些误差项进行平均（并通常会使用一个截断值来降低异常大误差的影响）。

FAPE 的关键优势在于其**$\mathrm{SE}(3)$-[不变性](@entry_id:140168)**。如果我们将一个任意的全局[刚体变换](@entry_id:150396) $g \in \mathrm{SE}(3)$ 同时应用于预测结构和目标结构，那么每个局部框架都会从 $T_i$ 变为 $g \circ T_i$。然而，当我们计算新的相对变换 $D_i'$ 时，全局变换 $g$ 会被抵消掉：
$$ D_i' = (g \circ T_i^{\mathrm{tgt}})^{-1} \circ (g \circ T_i^{\mathrm{pred}}) = ((T_i^{\mathrm{tgt}})^{-1} \circ g^{-1}) \circ (g \circ T_i^{\mathrm{pred}}) = (T_i^{\mathrm{tgt}})^{-1} \circ T_i^{\mathrm{pred}} = D_i $$
因为相对变换 $D_i$ 是不变的，并且局部坐标 $u_{ij}$ 的定义也不受全局变换影响，所以每个误差项 $e_{ij}$ 的值都保持不变。这种固有的不变性使得 FAPE 成为训练 $\mathrm{SE}(3)$-协变模型的理想损失函数。

### 衡量成功：结构准确性指标

当模型生成一个预测结构后，我们需要客观地评估其准确性。没有任何单一的指标是完美的，因此通常会组合使用多个指标，每个指标从不同角度揭示模型的质量 。

-   **[均方根偏差](@entry_id:1131102) (Root-Mean-Square Deviation, RMSD)**: 这是最传统、最直观的指标。它计算在最佳[刚体](@entry_id:1131033)叠合上，预测结构和目标结构之间对应原子坐标的均方根距离。RMSD 对所有原子的偏差一视同仁，并且由于其平方项的特性，它对大的偏差（离群点）极其敏感。例如，对于一个由两个[结构域](@entry_id:1132550)组成的蛋白质，如果一个结构域预测得完美，但另一个[结构域](@entry_id:1132550)的相对取[向错](@entry_id:161223)了（如 $\mathcal{P}_1$ 的情况），RMSD 会给出一个非常差的（高）值，因为它被少数几个大位移的原子所主导。因此，RMSD 最适合用于比较结构非常相似的单[结构域](@entry_id:1132550)蛋白。

-   **[模板建模得分](@entry_id:1133211) (Template Modeling score, [TM-score](@entry_id:1133211))**: [TM-score](@entry_id:1133211) 是为克服 RMSD 的缺点而设计的。它是一个介于 0 和 1 之间的分数，旨在评估整体拓扑结构的相似性。其计算公式巧妙地对大的距离偏差进行了降权。距离小的原子对贡献接近 1 的分数，而距离大的原子对（如在错误取向的结构域中）贡献接近 0 的分数，而不是一个巨大的惩罚项。这使得 [TM-score](@entry_id:1133211) 对于多结构域蛋白质的相对运动不那么敏感。在上述 $\mathcal{P}_1$ 的例子中，[TM-score](@entry_id:1133211) 会给出一个中等的分数（例如约 0.5-0.6），公正地反映出大约一半的结构是正确的。因此，[TM-score](@entry_id:1133211) 是评估整体折叠准确性的一个更鲁棒的指标。

-   **预测的局部距离差异检验 (predicted Local Distance Difference Test, pLDDT)**: 与 RMSD 和 [TM-score](@entry_id:1133211) 不同，pLDDT 不是一个比较两种结构的外部指标，而是由模型本身为每个残基生成的**内部置信度分数**，范围从 0 到 100。它预测了该残基局部环境的准确性，具体来说，是预测了在一个小的半径范围内（如 15 Å），原子间距离与真实结构相比的保持程度。pLDDT 是一个**局部**指标，它对全局排列是“盲目”的。在 $\mathcal{P}_1$ 的例子中，尽管全局排列错误，但由于每个[结构域](@entry_id:1132550)内部的局部几何都非常准确，pLDDT 会为几乎所有残基给出非常高的分数（例如 >90）。相反，如果一个模型（如 $\mathcal{P}_2$）整体折叠正确但局部细节充满噪音，pLDDT 则会普遍给出较低的分数。因此，pLDDT 极为了解模型对结构局部区域的“自信”程度。

综上所述，一个全面的结构评估应该结合这些指标：使用 pLDDT 来判断模型对局部细节的置信度，使用 [TM-score](@entry_id:1133211) 来评估整体拓扑的正确性，而 RMSD 则可用于对高质量、高相似度的结构进行精细的比较。