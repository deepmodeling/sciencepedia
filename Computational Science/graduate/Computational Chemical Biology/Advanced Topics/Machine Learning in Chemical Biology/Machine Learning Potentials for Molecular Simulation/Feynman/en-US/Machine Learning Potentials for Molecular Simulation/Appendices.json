{
    "hands_on_practices": [
        {
            "introduction": "At the heart of modern machine learning potentials lies the principle of decomposing the total system energy into contributions from individual atoms. This design ensures that the potential is both extensive (scales with system size) and invariant to the permutation of identical atoms, two fundamental requirements for any physical energy model. This exercise provides a concrete walkthrough of this process, taking you inside a simplified neural network to calculate atomic energy contributions and verify these essential symmetries firsthand .",
            "id": "3851774",
            "problem": "In atomistic machine-learned interatomic potentials used in computational chemical biology, the predicted Born–Oppenheimer potential energy is designed to be a scalar that is invariant to permutations of atom indices and extensive with respect to the number of atoms by decomposing the total energy into a sum of atom-wise contributions. Consider a toy three-atom system whose per-atom environment is encoded by a fixed descriptor vector $\\mathbf{x}_{i} \\in \\mathbb{R}^{3}$ that summarizes local geometry in a rotationally and translationally invariant manner, and an atom-wise neural network that maps $\\mathbf{x}_{i}$ to a scalar atomic energy contribution $\\varepsilon_{i}$ using a two-layer architecture with a Rectified Linear Unit (ReLU) activation. The total predicted energy is $E = \\sum_{i=1}^{3} \\varepsilon_{i}$. The network computes, for each atom $i$, the hidden pre-activation $\\mathbf{a}_{i} = \\mathbf{W}_{1}\\mathbf{x}_{i} + \\mathbf{b}_{1}$, the hidden activation $\\mathbf{h}_{i} = \\max(\\mathbf{0}, \\mathbf{a}_{i})$ applied elementwise, and the atomic energy $\\varepsilon_{i} = \\mathbf{w}_{2}^{\\top}\\mathbf{h}_{i} + b_{2}$, where $\\mathbf{W}_{1} \\in \\mathbb{R}^{2 \\times 3}$, $\\mathbf{b}_{1} \\in \\mathbb{R}^{2}$, $\\mathbf{w}_{2} \\in \\mathbb{R}^{2}$, and $b_{2} \\in \\mathbb{R}$ are fixed weights. Use the following parameters and descriptors:\n$$\n\\mathbf{W}_{1} = \\begin{pmatrix}\n0.5 & -0.2 & 0.1 \\\\\n-0.3 & 0.4 & 0.2\n\\end{pmatrix},\\quad\n\\mathbf{b}_{1} = \\begin{pmatrix}\n0.05 \\\\\n-0.10\n\\end{pmatrix},\\quad\n\\mathbf{w}_{2} = \\begin{pmatrix}\n0.8 \\\\\n-0.5\n\\end{pmatrix},\\quad\nb_{2} = 0.02,\n$$\nand\n$$\n\\mathbf{x}_{1} = \\begin{pmatrix} 1.2 \\\\ 0.7 \\\\ -0.3 \\end{pmatrix},\\quad\n\\mathbf{x}_{2} = \\begin{pmatrix} 0.5 \\\\ -0.1 \\\\ 0.6 \\end{pmatrix},\\quad\n\\mathbf{x}_{3} = \\begin{pmatrix} 1.0 \\\\ 0.0 \\\\ 0.2 \\end{pmatrix}.\n$$\nStarting from the physical requirement that potential energy is a scalar invariant to permutations of atom indices and that energy is additive over subsystems in the absence of interactions, and using only the definitions above for the network mapping and the ReLU nonlinearity, compute the predicted total energy $E$ in electronvolts for the given ordering $\\left( \\mathbf{x}_{1}, \\mathbf{x}_{2}, \\mathbf{x}_{3} \\right)$ and verify invariance with respect to a permutation of atom indices by explicitly considering the permuted ordering $\\left( \\mathbf{x}_{3}, \\mathbf{x}_{1}, \\mathbf{x}_{2} \\right)$. Round your final reported total energy to four significant figures and express the final energy in $\\mathrm{eV}$. The final reported answer must be a single numerical value.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information to compute the total potential energy of a three-atom system using a specified neural network potential model. All parameters and input data are clearly defined and dimensionally consistent. Therefore, the problem is valid and a solution can be derived.\n\nThe total potential energy, $E$, is defined as the sum of individual atomic energy contributions, $\\varepsilon_{i}$:\n$$E = \\sum_{i=1}^{3} \\varepsilon_{i}$$\nEach atomic energy $\\varepsilon_{i}$ is calculated by passing the atom's descriptor vector $\\mathbf{x}_{i}$ through a two-layer neural network. The network's computation proceeds as follows:\n$1$. The hidden pre-activation vector $\\mathbf{a}_{i} \\in \\mathbb{R}^{2}$ is computed:\n$$\\mathbf{a}_{i} = \\mathbf{W}_{1}\\mathbf{x}_{i} + \\mathbf{b}_{1}$$\n$2$. The hidden activation vector $\\mathbf{h}_{i} \\in \\mathbb{R}^{2}$ is computed by applying the element-wise Rectified Linear Unit (ReLU) function, $\\max(\\mathbf{0}, \\cdot)$:\n$$\\mathbf{h}_{i} = \\max(\\mathbf{0}, \\mathbf{a}_{i})$$\n$3$. The scalar atomic energy contribution $\\varepsilon_{i} \\in \\mathbb{R}$ is computed:\n$$\\varepsilon_{i} = \\mathbf{w}_{2}^{\\top}\\mathbf{h}_{i} + b_{2}$$\nThe given parameters are:\n$$\n\\mathbf{W}_{1} = \\begin{pmatrix}\n0.5 & -0.2 & 0.1 \\\\\n-0.3 & 0.4 & 0.2\n\\end{pmatrix},\\quad\n\\mathbf{b}_{1} = \\begin{pmatrix}\n0.05 \\\\\n-0.10\n\\end{pmatrix},\\quad\n\\mathbf{w}_{2} = \\begin{pmatrix}\n0.8 \\\\\n-0.5\n\\end{pmatrix},\\quad\nb_{2} = 0.02\n$$\nThe input descriptor vectors are:\n$$\n\\mathbf{x}_{1} = \\begin{pmatrix} 1.2 \\\\ 0.7 \\\\ -0.3 \\end{pmatrix},\\quad\n\\mathbf{x}_{2} = \\begin{pmatrix} 0.5 \\\\ -0.1 \\\\ 0.6 \\end{pmatrix},\\quad\n\\mathbf{x}_{3} = \\begin{pmatrix} 1.0 \\\\ 0.0 \\\\ 0.2 \\end{pmatrix}\n$$\nWe will now compute the atomic energy $\\varepsilon_{i}$ for each atom $i \\in \\{1, 2, 3\\}$.\n\n**Calculation for Atom 1:**\nFirst, we compute the pre-activation vector $\\mathbf{a}_{1}$:\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} 0.5 & -0.2 & 0.1 \\\\ -0.3 & 0.4 & 0.2 \\end{pmatrix} \\begin{pmatrix} 1.2 \\\\ 0.7 \\\\ -0.3 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} (0.5)(1.2) + (-0.2)(0.7) + (0.1)(-0.3) \\\\ (-0.3)(1.2) + (0.4)(0.7) + (0.2)(-0.3) \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} 0.6 - 0.14 - 0.03 \\\\ -0.36 + 0.28 - 0.06 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.43 \\\\ -0.14 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.48 \\\\ -0.24 \\end{pmatrix}\n$$\nNext, we apply the ReLU activation to get $\\mathbf{h}_{1}$:\n$$ \\mathbf{h}_{1} = \\max(\\mathbf{0}, \\mathbf{a}_{1}) = \\begin{pmatrix} \\max(0, 0.48) \\\\ \\max(0, -0.24) \\end{pmatrix} = \\begin{pmatrix} 0.48 \\\\ 0 \\end{pmatrix} $$\nFinally, we compute the atomic energy $\\varepsilon_{1}$:\n$$\n\\varepsilon_{1} = \\mathbf{w}_{2}^{\\top}\\mathbf{h}_{1} + b_{2} = \\begin{pmatrix} 0.8 & -0.5 \\end{pmatrix} \\begin{pmatrix} 0.48 \\\\ 0 \\end{pmatrix} + 0.02\n$$\n$$\n\\varepsilon_{1} = (0.8)(0.48) + (-0.5)(0) + 0.02 = 0.384 + 0 + 0.02 = 0.404\n$$\n\n**Calculation for Atom 2:**\nWe follow the same procedure for $\\mathbf{x}_{2}$. First, the pre-activation vector $\\mathbf{a}_{2}$:\n$$\n\\mathbf{a}_{2} = \\begin{pmatrix} 0.5 & -0.2 & 0.1 \\\\ -0.3 & 0.4 & 0.2 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ -0.1 \\\\ 0.6 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{2} = \\begin{pmatrix} (0.5)(0.5) + (-0.2)(-0.1) + (0.1)(0.6) \\\\ (-0.3)(0.5) + (0.4)(-0.1) + (0.2)(0.6) \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{2} = \\begin{pmatrix} 0.25 + 0.02 + 0.06 \\\\ -0.15 - 0.04 + 0.12 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.33 \\\\ -0.07 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.38 \\\\ -0.17 \\end{pmatrix}\n$$\nNext, the ReLU activation to get $\\mathbf{h}_{2}$:\n$$ \\mathbf{h}_{2} = \\max(\\mathbf{0}, \\mathbf{a}_{2}) = \\begin{pmatrix} \\max(0, 0.38) \\\\ \\max(0, -0.17) \\end{pmatrix} = \\begin{pmatrix} 0.38 \\\\ 0 \\end{pmatrix} $$\nFinally, the atomic energy $\\varepsilon_{2}$:\n$$\n\\varepsilon_{2} = \\mathbf{w}_{2}^{\\top}\\mathbf{h}_{2} + b_{2} = \\begin{pmatrix} 0.8 & -0.5 \\end{pmatrix} \\begin{pmatrix} 0.38 \\\\ 0 \\end{pmatrix} + 0.02\n$$\n$$\n\\varepsilon_{2} = (0.8)(0.38) + (-0.5)(0) + 0.02 = 0.304 + 0 + 0.02 = 0.324\n$$\n\n**Calculation for Atom 3:**\nWe repeat the procedure for $\\mathbf{x}_{3}$. First, the pre-activation vector $\\mathbf{a}_{3}$:\n$$\n\\mathbf{a}_{3} = \\begin{pmatrix} 0.5 & -0.2 & 0.1 \\\\ -0.3 & 0.4 & 0.2 \\end{pmatrix} \\begin{pmatrix} 1.0 \\\\ 0.0 \\\\ 0.2 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{3} = \\begin{pmatrix} (0.5)(1.0) + (-0.2)(0.0) + (0.1)(0.2) \\\\ (-0.3)(1.0) + (0.4)(0.0) + (0.2)(0.2) \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix}\n$$\n$$\n\\mathbf{a}_{3} = \\begin{pmatrix} 0.5 + 0 + 0.02 \\\\ -0.3 + 0 + 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.52 \\\\ -0.26 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.10 \\end{pmatrix} = \\begin{pmatrix} 0.57 \\\\ -0.36 \\end{pmatrix}\n$$\nNext, the ReLU activation to get $\\mathbf{h}_{3}$:\n$$ \\mathbf{h}_{3} = \\max(\\mathbf{0}, \\mathbf{a}_{3}) = \\begin{pmatrix} \\max(0, 0.57) \\\\ \\max(0, -0.36) \\end{pmatrix} = \\begin{pmatrix} 0.57 \\\\ 0 \\end{pmatrix} $$\nFinally, the atomic energy $\\varepsilon_{3}$:\n$$\n\\varepsilon_{3} = \\mathbf{w}_{2}^{\\top}\\mathbf{h}_{3} + b_{2} = \\begin{pmatrix} 0.8 & -0.5 \\end{pmatrix} \\begin{pmatrix} 0.57 \\\\ 0 \\end{pmatrix} + 0.02\n$$\n$$\n\\varepsilon_{3} = (0.8)(0.57) + (-0.5)(0) + 0.02 = 0.456 + 0 + 0.02 = 0.476\n$$\n\n**Total Energy Calculation:**\nThe total energy for the ordering $(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\mathbf{x}_{3})$ is the sum of the atomic energies:\n$$ E = \\varepsilon_{1} + \\varepsilon_{2} + \\varepsilon_{3} = 0.404 + 0.324 + 0.476 = 1.204 $$\n\n**Verification of Permutation Invariance:**\nThe problem asks to verify the invariance of the total energy with respect to a permutation of atom indices, specifically by considering the ordering $(\\mathbf{x}_{3}, \\mathbf{x}_{1}, \\mathbf{x}_{2})$.\nThe total energy for this permuted ordering, let's call it $E'$, would be calculated as:\n$$ E' = \\varepsilon(\\mathbf{x}_{3}) + \\varepsilon(\\mathbf{x}_{1}) + \\varepsilon(\\mathbf{x}_{2}) $$\nwhere $\\varepsilon(\\mathbf{x}_{i})$ is the energy contribution from the atom with descriptor $\\mathbf{x}_{i}$. Since the neural network function $\\varepsilon(\\cdot)$ is applied independently to each atom's descriptor, the values of $\\varepsilon_{1}$, $\\varepsilon_{2}$, and $\\varepsilon_{3}$ are the same regardless of their position in the list. The total energy is a sum over these contributions. Due to the commutative property of addition:\n$$ E' = \\varepsilon_{3} + \\varepsilon_{1} + \\varepsilon_{2} = \\varepsilon_{1} + \\varepsilon_{2} + \\varepsilon_{3} = E $$\nUsing the values we already computed:\n$$ E' = 0.476 + 0.404 + 0.324 = 1.204 $$\nThis explicitly demonstrates that $E' = E$, verifying that the total energy is invariant to permutations of the atom indices. This property is a direct consequence of the energy being defined as a sum of atomic contributions, where each contribution depends only on the local environment of that atom (encoded in $\\mathbf{x}_{i}$) and not on the arbitrary labeling or ordering of the atoms in the system. The requirement that the descriptors $\\mathbf{x}_i$ themselves are invariant to rotation and translation ensures overall geometric invariance, while the summation ensures permutational invariance.\n\nThe final total energy is $1.204\\,\\mathrm{eV}$. The problem requests the answer rounded to four significant figures. The calculated value $1.204$ already has four significant figures.",
            "answer": "$$\n\\boxed{1.204}\n$$"
        },
        {
            "introduction": "While predicting energies is crucial, molecular dynamics simulations are driven by forces, which are the negative gradient of the potential energy, $\\mathbf{F} = -\\nabla U$. A critical physical constraint is that these forces must be *conservative*, meaning the work done along any closed path is zero. This property is mathematically equivalent to the force field being \"irrotational,\" or having zero curl ($\\nabla \\times \\mathbf{F} = \\mathbf{0}$). This exercise challenges you to apply this fundamental test to a hypothetical force field from an ML model, allowing you to mathematically diagnose non-physical components that would violate energy conservation in a simulation .",
            "id": "3851711",
            "problem": "A Machine Learning (ML) model is trained to predict coarse-grained forces on a two-dimensional slow manifold of a biomolecular conformational landscape, with coordinates $x$ and $y$ taken to be dimensionless reaction coordinates. In a local patch of this manifold, the model outputs the following force field $\\mathbf{F}(x,y)$:\n$$\n\\mathbf{F}(x,y) \\;=\\; \\big(F_x(x,y),\\,F_y(x,y)\\big) \\;=\\; \\big(-k\\,x \\,-\\,\\lambda\\,y\\,+\\,\\alpha\\,x\\,y^{2},\\;\\; -k\\,y \\,-\\,\\lambda\\,x\\,+\\,\\beta\\,x^{2}\\,y\\big),\n$$\nwhere $k$, $\\lambda$, $\\alpha$, and $\\beta$ are constants. In conservative dynamics driven by a smooth scalar potential $U(x,y)$, the force satisfies $\\mathbf{F}(x,y)=-\\nabla U(x,y)$ on a simply connected domain.\n\nUsing only fundamental definitions, compute the out-of-plane component of the curl $\\nabla\\times\\mathbf{F}$ for this $2$-dimensional field as an analytic function of $x$, $y$, $k$, $\\lambda$, $\\alpha$, and $\\beta$. Then, based on first principles, interpret how nonzero values of this quantity provide evidence of inconsistency with the existence of a single-valued scalar potential on the domain of $(x,y)$, assuming required smoothness. Your final reported quantity must be the analytic expression for the out-of-plane component of $\\nabla\\times\\mathbf{F}$; no numerical rounding is required and no physical units are needed.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- A two-dimensional force field $\\mathbf{F}(x,y) = \\big(F_x(x,y),\\,F_y(x,y)\\big)$ is defined on a manifold with dimensionless coordinates $x$ and $y$.\n- The components of the force field are given by:\n  $$F_x(x,y) = -k\\,x \\,-\\,\\lambda\\,y\\,+\\,\\alpha\\,x\\,y^{2}$$\n  $$F_y(x,y) = -k\\,y \\,-\\,\\lambda\\,x\\,+\\,\\beta\\,x^{2}\\,y$$\n- $k$, $\\lambda$, $\\alpha$, and $\\beta$ are specified as constants.\n- The condition for a conservative force field is stated as $\\mathbf{F}(x,y)=-\\nabla U(x,y)$, where $U(x,y)$ is a smooth scalar potential on a simply connected domain.\n- The task is to compute the out-of-plane component of the curl, $\\nabla\\times\\mathbf{F}$, and interpret its significance regarding the existence of the potential $U(x,y)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific or Factual Unsoundness**: The problem is scientifically sound. It addresses the fundamental condition for a force field to be conservative, which is a cornerstone of classical mechanics and vector calculus. The connection between a non-zero curl and a non-conservative field is a standard result (related to Helmholtz's theorem and Stokes' theorem). The context, involving a machine learning model for molecular forces, represents a legitimate and current area of research where ensuring learned forces are conservative is a critical challenge.\n- **Non-Formalizable or Irrelevant**: The problem is entirely formalizable within the framework of vector calculus and is directly relevant to the topic of developing physically consistent machine learning potentials.\n- **Incomplete or Contradictory Setup**: The problem is self-contained. The functional form of the force field is explicitly provided, which is all that is necessary to compute its curl. There are no contradictions.\n- **Unrealistic or Infeasible**: The functions describing the force components are polynomials, which are well-behaved and physically plausible as local approximations of a more complex force field. The calculation is straightforward.\n- **Ill-Posed or Poorly Structured**: The problem is well-posed. The calculation of the curl of a given vector field is a standard operation that yields a unique result. The interpretation is based on established mathematical theorems.\n- **Pseudo-Profound, Trivial, or Tautological**: The problem is neither trivial nor pseudo-profound. It tests for a core conceptual understanding of the mathematical conditions for physical realism in learned force fields.\n- **Outside Scientific Verifiability**: The claims are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution\nThe problem requires the calculation of the out-of-plane component of the curl of a two-dimensional vector field and an interpretation of the result in the context of conservative dynamics.\n\nLet the given two-dimensional force field be $\\mathbf{F}(x,y) = F_x(x,y)\\,\\mathbf{\\hat{i}} + F_y(x,y)\\,\\mathbf{\\hat{j}}$. To compute its curl, we can treat it as a three-dimensional field $\\mathbf{F}(x,y,z) = F_x(x,y)\\,\\mathbf{\\hat{i}} + F_y(x,y)\\,\\mathbf{\\hat{j}} + 0\\,\\mathbf{\\hat{k}}$, where the components are independent of the $z$ coordinate.\n\nThe curl of $\\mathbf{F}$ is defined by the determinant of the following matrix:\n$$\n\\nabla \\times \\mathbf{F} = \n\\begin{vmatrix}\n\\mathbf{\\hat{i}} & \\mathbf{\\hat{j}} & \\mathbf{\\hat{k}} \\\\\n\\frac{\\partial}{\\partial x} & \\frac{\\partial}{\\partial y} & \\frac{\\partial}{\\partial z} \\\\\nF_x(x,y) & F_y(x,y) & 0\n\\end{vmatrix}\n$$\nExpanding the determinant, we get:\n$$\n\\nabla \\times \\mathbf{F} = \\left(\\frac{\\partial (0)}{\\partial y} - \\frac{\\partial F_y}{\\partial z}\\right)\\mathbf{\\hat{i}} - \\left(\\frac{\\partial (0)}{\\partial x} - \\frac{\\partial F_x}{\\partial z}\\right)\\mathbf{\\hat{j}} + \\left(\\frac{\\partial F_y}{\\partial x} - \\frac{\\partial F_x}{\\partial y}\\right)\\mathbf{\\hat{k}}\n$$\nSince $F_x$ and $F_y$ are functions of only $x$ and $y$, their partial derivatives with respect to $z$ are zero. Consequently, the $\\mathbf{\\hat{i}}$ and $\\mathbf{\\hat{j}}$ components of the curl are both zero. The only non-trivial component is the out-of-plane, or $\\mathbf{\\hat{k}}$, component:\n$$ (\\nabla \\times \\mathbf{F})_z = \\frac{\\partial F_y}{\\partial x} - \\frac{\\partial F_x}{\\partial y} $$\n\nWe are given the components of the force field:\n$$ F_x(x,y) = -k\\,x \\,-\\,\\lambda\\,y\\,+\\,\\alpha\\,x\\,y^{2} $$\n$$ F_y(x,y) = -k\\,y \\,-\\,\\lambda\\,x\\,+\\,\\beta\\,x^{2}\\,y $$\n\nFirst, we compute the partial derivative of $F_y$ with respect to $x$:\n$$\n\\frac{\\partial F_y}{\\partial x} = \\frac{\\partial}{\\partial x} \\left(-k\\,y \\,-\\,\\lambda\\,x\\,+\\,\\beta\\,x^{2}\\,y\\right) = 0 - \\lambda + 2\\,\\beta\\,x\\,y = -\\lambda + 2\\,\\beta\\,x\\,y\n$$\nNext, we compute the partial derivative of $F_x$ with respect to $y$:\n$$\n\\frac{\\partial F_x}{\\partial y} = \\frac{\\partial}{\\partial y} \\left(-k\\,x \\,-\\,\\lambda\\,y\\,+\\,\\alpha\\,x\\,y^{2}\\right) = 0 - \\lambda + 2\\,\\alpha\\,x\\,y = -\\lambda + 2\\,\\alpha\\,x\\,y\n$$\n\nNow, we substitute these expressions into the formula for the out-of-plane component of the curl:\n$$\n(\\nabla \\times \\mathbf{F})_z = \\left(-\\lambda + 2\\,\\beta\\,x\\,y\\right) - \\left(-\\lambda + 2\\,\\alpha\\,x\\,y\\right)\n$$\n$$\n(\\nabla \\times \\mathbf{F})_z = -\\lambda + 2\\,\\beta\\,x\\,y + \\lambda - 2\\,\\alpha\\,x\\,y\n$$\n$$\n(\\nabla \\times \\mathbf{F})_z = 2\\,\\beta\\,x\\,y - 2\\,\\alpha\\,x\\,y = 2\\,x\\,y\\,(\\beta - \\alpha)\n$$\nThis is the analytic expression for the out-of-plane component of the curl.\n\nFor the interpretation, we consider the condition for a force field to be conservative. A force field $\\mathbf{F}$ is conservative if it can be expressed as the negative gradient of a scalar potential, $U$. That is, $\\mathbf{F} = -\\nabla U$. On a simply connected domain, this condition is equivalent to the force field being irrotational, i.e., its curl is zero: $\\nabla \\times \\mathbf{F} = \\mathbf{0}$.\n\nThis can be proven from first principles using the equality of mixed partial derivatives (Clairaut's theorem). If a smooth, single-valued potential $U(x,y)$ exists, then its second-order mixed partial derivatives must be equal:\n$$ \\frac{\\partial^2 U}{\\partial y \\partial x} = \\frac{\\partial^2 U}{\\partial x \\partial y} $$\nFrom the potential-force relationship, we have $F_x = -\\frac{\\partial U}{\\partial x}$ and $F_y = -\\frac{\\partial U}{\\partial y}$. Taking further derivatives:\n$$ \\frac{\\partial F_x}{\\partial y} = \\frac{\\partial}{\\partial y} \\left(-\\frac{\\partial U}{\\partial x}\\right) = -\\frac{\\partial^2 U}{\\partial y \\partial x} $$\n$$ \\frac{\\partial F_y}{\\partial x} = \\frac{\\partial}{\\partial x} \\left(-\\frac{\\partial U}{\\partial y}\\right) = -\\frac{\\partial^2 U}{\\partial x \\partial y} $$\nThe equality of mixed partials thus implies $\\frac{\\partial F_x}{\\partial y} = \\frac{\\partial F_y}{\\partial x}$, which can be rearranged to $\\frac{\\partial F_y}{\\partial x} - \\frac{\\partial F_x}{\\partial y} = 0$. This is precisely the condition that the out-of-plane component of the curl is zero.\n\nTherefore, a non-zero value for $(\\nabla \\times \\mathbf{F})_z$ provides direct evidence of inconsistency with the existence of a single-valued scalar potential $U(x,y)$. If $(\\nabla \\times \\mathbf{F})_z = 2\\,x\\,y\\,(\\beta - \\alpha) \\neq 0$, it means the machine learning model has produced a non-conservative, or rotational, force field. Such a field is physically unrealistic for describing equilibrium dynamics, as the work done by the force on a particle traversing a closed path would not be zero, violating the principle of energy conservation. The inconsistency arises if $\\beta \\neq \\alpha$, in which case the curl is non-zero everywhere except on the axes $x=0$ or $y=0$.",
            "answer": "$$\n\\boxed{2\\,x\\,y\\,(\\beta - \\alpha)}\n$$"
        },
        {
            "introduction": "The ultimate test of a machine learning potential is its performance in a live molecular dynamics simulation. A key metric for stability and physical realism is long-term energy conservation. However, when energy drift is observed, it can stem from two distinct sources: intrinsic errors in the ML force model (i.e., non-conservative forces) or numerical inaccuracies from the discrete time steps of the integrator. This advanced practice guides you through the process of running a simulation and, more importantly, implementing a diagnostic procedure to disentangle these two sources of error, a crucial skill for validating and troubleshooting simulations that use learned force fields .",
            "id": "3851761",
            "problem": "You are given a one-dimensional Molecular Dynamics (MD) system suitable for computational chemical biology in which the true conservative potential is $U_{\\mathrm{true}}(x) = \\tfrac{1}{2} k x^{2}$ and the true force is $F_{\\mathrm{true}}(x) = -k x$. The mass is $m$ and the position and velocity are $x(t)$ and $v(t)$, respectively. The total energy of the true system is $E_{\\mathrm{true}}(t) = \\tfrac{1}{2} m v(t)^{2} + U_{\\mathrm{true}}(x(t))$. A machine learning (ML) force predictor introduces a non-conservative velocity-dependent residual, yielding $F_{\\mathrm{ML}}(x, v) = -k x - \\beta v$, which models a common coarse-grained effect where the learned forces include dissipative contributions not derivable from a potential.\n\nYour task is to write a complete, runnable program that:\n- Simulates trajectories using a second-order leapfrog scheme derived from Newton’s second law $m \\,\\ddot{x}(t) = F(x(t), v(t))$ and standard kinematics $v(t) = \\tfrac{dx}{dt}$, with the following discrete-time update for time step $\\Delta t$:\n  - Compute $a_{n} = \\tfrac{1}{m} F(x_{n}, v_{n})$.\n  - Compute $v_{n+\\tfrac{1}{2}} = v_{n} + \\tfrac{1}{2} a_{n} \\Delta t$.\n  - Compute $x_{n+1} = x_{n} + v_{n+\\tfrac{1}{2}} \\Delta t$.\n  - Compute $a_{n+1} = \\tfrac{1}{m} F(x_{n+1}, v_{n+\\tfrac{1}{2}})$.\n  - Compute $v_{n+1} = v_{n+\\tfrac{1}{2}} + \\tfrac{1}{2} a_{n+1} \\Delta t$.\n- Computes $E_{\\mathrm{true}}(t)$ at each discrete time $t_{n} = n \\,\\Delta t$ using the trajectory states $(x_{n}, v_{n})$ and the true potential $U_{\\mathrm{true}}(x)$.\n- Estimates the energy drift rate as the least-squares slope of $E_{\\mathrm{true}}(t)$ as a function of $t$ over the trajectory, namely $\\hat{\\gamma} = \\dfrac{\\sum_{n} (t_{n} - \\bar{t})(E_{\\mathrm{true}}(t_{n}) - \\bar{E})}{\\sum_{n} (t_{n} - \\bar{t})^{2}}$ where $\\bar{t}$ and $\\bar{E}$ denote sample means.\n\nYou must separate the observed energy drift rate under ML forces into two contributions using short pilot runs:\n- Integrator discretization error contribution: perform a short pilot run using $F_{\\mathrm{true}}(x)$ at the production step size $\\Delta t$ and estimate $\\hat{\\gamma}_{\\mathrm{int}}$ from the slope of $E_{\\mathrm{true}}(t)$ versus $t$.\n- Model prediction error contribution: perform two short pilot runs at a much smaller step size $\\delta t$ (where discretization error is negligible compared to model error), one using $F_{\\mathrm{ML}}(x, v)$ and one using $F_{\\mathrm{true}}(x)$, and estimate $\\hat{\\gamma}_{\\mathrm{model}}$ as the difference of the two slopes at $\\delta t$: $\\hat{\\gamma}_{\\mathrm{model}} \\approx \\hat{\\gamma}_{\\mathrm{ML}, \\,\\delta t} - \\hat{\\gamma}_{\\mathrm{true}, \\,\\delta t}$.\n\nThen, for a longer production run under ML forces and production time step $\\Delta t$, compute the total observed energy drift rate $\\hat{\\gamma}_{\\mathrm{tot}}$. Report the residual cross-term $\\hat{\\gamma}_{\\mathrm{res}} = \\hat{\\gamma}_{\\mathrm{tot}} - (\\hat{\\gamma}_{\\mathrm{int}} + \\hat{\\gamma}_{\\mathrm{model}})$, which quantifies non-additive interaction between model error and discretization.\n\nUse the following fixed system parameters across all test cases:\n- Mass $m = 1$ (in mass units).\n- Spring constant $k = 1$ (in energy per length squared units).\n- Initial condition $x(0) = 1$ and $v(0) = 0$ (in length and length per time units).\n- Production trajectory length $N_{\\mathrm{prod}} = 5000$ steps.\n- Pilot trajectory length $N_{\\mathrm{pilot}} = 2000$ steps.\n- Small pilot time step $\\delta t = 0.001$ (in time units).\n\nPhysical units: express all drift rates in energy per time units (E-unit per t-unit). Angles are not used. Percentages are not used.\n\nTest suite of parameter values $(\\Delta t, \\beta)$:\n- Case $1$: $(\\Delta t, \\beta) = (0.01, 0.01)$.\n- Case $2$: $(\\Delta t, \\beta) = (0.05, 0.10)$.\n- Case $3$: $(\\Delta t, \\beta) = (0.20, 0.00)$.\n- Case $4$: $(\\Delta t, \\beta) = (0.05, 0.50)$.\n\nYour program should produce a single line of output containing a comma-separated list of per-case results, each result itself being a list of four floating-point numbers $[\\hat{\\gamma}_{\\mathrm{tot}}, \\hat{\\gamma}_{\\mathrm{int}}, \\hat{\\gamma}_{\\mathrm{model}}, \\hat{\\gamma}_{\\mathrm{res}}]$, all in energy per time units. The final output format must be exactly one line like $[[\\hat{\\gamma}_{\\mathrm{tot},1},\\hat{\\gamma}_{\\mathrm{int},1},\\hat{\\gamma}_{\\mathrm{model},1},\\hat{\\gamma}_{\\mathrm{res},1}],[\\hat{\\gamma}_{\\mathrm{tot},2},\\hat{\\gamma}_{\\mathrm{int},2},\\hat{\\gamma}_{\\mathrm{model},2},\\hat{\\gamma}_{\\mathrm{res},2}],\\dots]$ without any spaces.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in classical mechanics and numerical analysis, well-posed with all necessary parameters and equations defined, and objective in its formulation. The task is to analyze energy drift in a one-dimensional molecular dynamics simulation where a machine learning potential introduces a non-conservative, velocity-dependent force. The analysis requires decomposing the total energy drift into contributions from the numerical integrator and the force model error.\n\nThe physical system is a particle of mass $m$ in a harmonic potential. The true conservative potential energy is given by $U_{\\mathrm{true}}(x) = \\tfrac{1}{2} k x^{2}$, where $k$ is the spring constant and $x$ is the position. The corresponding true conservative force is $F_{\\mathrm{true}}(x) = -\\nabla U_{\\mathrm{true}}(x) = -k x$. The total energy of this true system, $E_{\\mathrm{true}}(t) = \\tfrac{1}{2} m v(t)^{2} + U_{\\mathrm{true}}(x(t))$, is conserved if the dynamics are governed solely by $F_{\\mathrm{true}}(x)$.\n\nThe problem introduces a force from a machine learning model, $F_{\\mathrm{ML}}(x, v) = -k x - \\beta v$. This force includes the true conservative force $-k x$ and a dissipative, non-conservative term $-\\beta v$ that depends on velocity $v$. Such terms are common when coarse-graining microscopic degrees of freedom, which a machine learning model might implicitly learn. Propagating the system with this force, i.e., setting $m \\ddot{x} = F_{\\mathrm{ML}}(x, v)$, will lead to a change in the true energy $E_{\\mathrm{true}}$. The analytical rate of change of $E_{\\mathrm{true}}$ under the influence of $F_{\\mathrm{ML}}$ is:\n$$\n\\frac{dE_{\\mathrm{true}}}{dt} = \\frac{d}{dt} \\left( \\frac{1}{2} m v^2 + \\frac{1}{2} k x^2 \\right) = m v \\dot{v} + k x \\dot{x} = v(m \\ddot{x} + kx)\n$$\nSubstituting $m \\ddot{x} = F_{\\mathrm{ML}}(x, v) = -k x - \\beta v$, we get:\n$$\n\\frac{dE_{\\mathrm{true}}}{dt} = v ((-k x - \\beta v) + kx) = -\\beta v^2\n$$\nThis demonstrates that the ML model introduces a systematic energy drift, with the rate proportional to the dissipation parameter $\\beta$ and the square of the velocity.\n\nThe trajectory $(x(t), v(t))$ is generated using a specific second-order leapfrog integration scheme defined by a sequence of updates over a time step $\\Delta t$, from time $t_n$ to $t_{n+1}$:\n1.  Compute the acceleration at the beginning of the step: $a_{n} = \\tfrac{1}{m} F(x_{n}, v_{n})$.\n2.  Update the velocity to a half-step: $v_{n+\\tfrac{1}{2}} = v_{n} + \\tfrac{1}{2} a_{n} \\Delta t$.\n3.  Update the position over the full step using the half-step velocity: $x_{n+1} = x_{n} + v_{n+\\tfrac{1}{2}} \\Delta t$.\n4.  Compute the acceleration at the end of the step, using the new position but the half-step velocity: $a_{n+1} = \\tfrac{1}{m} F(x_{n+1}, v_{n+\\tfrac{1}{2}})$. This prescription is crucial as it keeps the scheme explicit even for velocity-dependent forces.\n5.  Complete the velocity update to the full step: $v_{n+1} = v_{n+\\tfrac{1}{2}} + \\tfrac{1}{2} a_{n+1} \\Delta t$.\n\nThe energy drift rate, $\\hat{\\gamma}$, is estimated by performing a linear least-squares fit to the time series of the true energy, $E_{\\mathrm{true}}(t_n)$. The slope of this fit is given by:\n$$\n\\hat{\\gamma} = \\frac{\\sum_{n=0}^{N} (t_n - \\bar{t})(E_{\\mathrm{true}}(t_n) - \\bar{E})}{\\sum_{n=0}^{N} (t_n - \\bar{t})^2}\n$$\nwhere $\\bar{t}$ and $\\bar{E}$ are the sample means of time and energy over the $N$-step trajectory.\n\nThe core of the task is to decompose the total observed energy drift, $\\hat{\\gamma}_{\\mathrm{tot}}$, into three distinct components:\n1.  **Integrator Discretization Error ($\\hat{\\gamma}_{\\mathrm{int}}$)**: This component arises from the approximation inherent in using a finite time step $\\Delta t$. It is isolated by simulating the system with the perfect conservative force, $F_{\\mathrm{true}}(x)$, using the production time step $\\Delta t$ for $N_{\\mathrm{pilot}}$ steps. Any observed drift in this simulation is due to the integrator's error.\n2.  **Model Prediction Error ($\\hat{\\gamma}_{\\mathrm{model}}$)**: This component is the systematic drift introduced by the non-conservative part of the ML force. To isolate it from integrator error, two pilot simulations of length $N_{\\mathrm{pilot}}$ are run with a very small time step $\\delta t$, where discretization errors are negligible. One run uses $F_{\\mathrm{true}}(x)$ to get a baseline drift $\\hat{\\gamma}_{\\mathrm{true}, \\,\\delta t}$, and the other uses $F_{\\mathrm{ML}}(x, v)$ to get $\\hat{\\gamma}_{\\mathrm{ML}, \\,\\delta t}$. The model's contribution is the difference: $\\hat{\\gamma}_{\\mathrm{model}} \\approx \\hat{\\gamma}_{\\mathrm{ML}, \\,\\delta t} - \\hat{\\gamma}_{\\mathrm{true}, \\,\\delta t}$.\n3.  **Residual Cross-Term ($\\hat{\\gamma}_{\\mathrm{res}}$)**: In a full production simulation of $N_{\\mathrm{prod}}$ steps using $F_{\\mathrm{ML}}(x, v)$ and the time step $\\Delta t$, the total observed drift is $\\hat{\\gamma}_{\\mathrm{tot}}$. If the effects of integrator and model error were perfectly additive, we would have $\\hat{\\gamma}_{\\mathrm{tot}} = \\hat{\\gamma}_{\\mathrm{int}} + \\hat{\\gamma}_{\\mathrm{model}}$. The residual term, $\\hat{\\gamma}_{\\mathrm{res}} = \\hat{\\gamma}_{\\mathrm{tot}} - (\\hat{\\gamma}_{\\mathrm{int}} + \\hat{\\gamma}_{\\mathrm{model}})$, quantifies the non-additive coupling between the model error and the numerical integration error.\n\nThe program will implement a simulation function that executes the specified five-step integration scheme. This function will be called four times for each test case $(\\Delta t, \\beta)$ to generate the trajectories needed to calculate $\\hat{\\gamma}_{\\mathrm{int}}$, $\\hat{\\gamma}_{\\mathrm{model}}$, and $\\hat{\\gamma}_{\\mathrm{tot}}$. The drift rates will be calculated using linear regression on the energy-time data from each trajectory. Finally, the residual $\\hat{\\gamma}_{\\mathrm{res}}$ will be computed and the four values will be reported for each test case. All calculations use the fixed parameters: $m=1$, $k=1$, $x(0)=1$, $v(0)=0$, $N_{\\mathrm{prod}}=5000$, $N_{\\mathrm{pilot}}=2000$, and $\\delta t = 0.001$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It calculates and decomposes the energy drift rate in a 1D MD simulation.\n    \"\"\"\n\n    # --- Fixed System Parameters ---\n    m = 1.0  # Mass\n    k = 1.0  # Spring constant\n    x0 = 1.0 # Initial position\n    v0 = 0.0 # Initial velocity\n    N_prod = 5000  # Number of steps for production runs\n    N_pilot = 2000 # Number of steps for pilot runs\n    delta_t_small = 0.001  # Small time step for model error estimation\n\n    # --- Test Cases ---\n    test_cases = [\n        (0.01, 0.01),\n        (0.05, 0.10),\n        (0.20, 0.00),\n        (0.05, 0.50),\n    ]\n\n    # --- Force and Energy Functions ---\n    def F_true(x, v):\n        \"\"\"True conservative force.\"\"\"\n        return -k * x\n\n    def F_ml(x, v, beta):\n        \"\"\"Machine learning force with a dissipative term.\"\"\"\n        return -k * x - beta * v\n\n    def E_true(x, v):\n        \"\"\"True conservative energy.\"\"\"\n        return 0.5 * m * v**2 + 0.5 * k * x**2\n\n    def run_simulation(force_func, dt, n_steps):\n        \"\"\"\n        Runs a simulation using the specified leapfrog-like integrator.\n        \n        Args:\n            force_func (callable): A function F(x, v) that returns the force.\n            dt (float): The time step.\n            n_steps (int): The number of integration steps.\n\n        Returns:\n            tuple: Arrays for times, positions, and velocities.\n        \"\"\"\n        ts = np.zeros(n_steps + 1)\n        xs = np.zeros(n_steps + 1)\n        vs = np.zeros(n_steps + 1)\n\n        xs[0], vs[0] = x0, v0\n        x_n, v_n = x0, v0\n\n        for n in range(n_steps):\n            # Compute a_n\n            a_n = force_func(x_n, v_n) / m\n            # Compute v_{n+1/2}\n            v_half = v_n + 0.5 * a_n * dt\n            # Compute x_{n+1}\n            x_np1 = x_n + v_half * dt\n            # Compute a_{n+1}\n            a_np1 = force_func(x_np1, v_half) / m\n            # Compute v_{n+1}\n            v_np1 = v_half + 0.5 * a_np1 * dt\n            \n            ts[n+1] = (n + 1) * dt\n            xs[n+1] = x_np1\n            vs[n+1] = v_np1\n            \n            x_n, v_n = x_np1, v_np1\n        \n        return ts, xs, vs\n\n    def calculate_drift_rate(times, energies):\n        \"\"\"\n        Calculates the energy drift rate using linear regression (slope).\n        \"\"\"\n        # np.polyfit(x, y, 1)[0] returns the slope of the least-squares fit.\n        return np.polyfit(times, energies, 1)[0]\n\n    all_results = []\n    for dt, beta in test_cases:\n        # 1. Calculate integrator drift contribution (gamma_int)\n        # Pilot run with true force and production time step\n        ts_int, xs_int, vs_int = run_simulation(\n            force_func=lambda x, v: F_true(x, v),\n            dt=dt, \n            n_steps=N_pilot\n        )\n        energies_int = E_true(xs_int, vs_int)\n        gamma_int = calculate_drift_rate(ts_int, energies_int)\n\n        # 2. Calculate model error contribution (gamma_model)\n        # Pilot run with true force and small time step\n        ts_model_true, xs_model_true, vs_model_true = run_simulation(\n            force_func=lambda x, v: F_true(x, v),\n            dt=delta_t_small,\n            n_steps=N_pilot\n        )\n        energies_model_true = E_true(xs_model_true, vs_model_true)\n        gamma_true_dt_small = calculate_drift_rate(ts_model_true, energies_model_true)\n\n        # Pilot run with ML force and small time step\n        ts_model_ml, xs_model_ml, vs_model_ml = run_simulation(\n            force_func=lambda x, v: F_ml(x, v, beta),\n            dt=delta_t_small,\n            n_steps=N_pilot\n        )\n        energies_model_ml = E_true(xs_model_ml, vs_model_ml)\n        gamma_ml_dt_small = calculate_drift_rate(ts_model_ml, energies_model_ml)\n        \n        gamma_model = gamma_ml_dt_small - gamma_true_dt_small\n\n        # 3. Calculate total observed drift (gamma_tot)\n        # Production run with ML force and production time step\n        ts_tot, xs_tot, vs_tot = run_simulation(\n            force_func=lambda x, v: F_ml(x, v, beta),\n            dt=dt,\n            n_steps=N_prod\n        )\n        energies_tot = E_true(xs_tot, vs_tot)\n        gamma_tot = calculate_drift_rate(ts_tot, energies_tot)\n\n        # 4. Calculate residual cross-term (gamma_res)\n        gamma_res = gamma_tot - (gamma_int + gamma_model)\n\n        all_results.append([gamma_tot, gamma_int, gamma_model, gamma_res])\n\n    # Format the final output string exactly as specified.\n    result_strings = []\n    for result_list in all_results:\n        # Using map(str, ...) is robust and avoids trailing zeros/spaces.\n        formatted_list = \",\".join(map(str, result_list))\n        result_strings.append(f\"[{formatted_list}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}