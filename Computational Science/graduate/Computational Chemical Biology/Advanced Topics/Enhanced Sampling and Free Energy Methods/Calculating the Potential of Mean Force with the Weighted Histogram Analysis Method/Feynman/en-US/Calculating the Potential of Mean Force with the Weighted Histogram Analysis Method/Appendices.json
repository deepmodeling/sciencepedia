{
    "hands_on_practices": [
        {
            "introduction": "A successful umbrella sampling study depends critically on ensuring sufficient overlap between the distributions sampled in adjacent windows. Too little overlap breaks the statistical connection required by WHAM, while too much can be computationally inefficient. This practice connects statistical mechanics theory to practical experimental design, guiding you to derive the relationship between the harmonic spring constant $k_i$ and the width of the sampled distribution, and then use it to select a stiffness that achieves a desired overlap .",
            "id": "3838304",
            "problem": "In umbrella sampling for reconstructing a one-dimensional potential of mean force by the Weighted Histogram Analysis Method (WHAM), each window applies a harmonic bias potential to a reaction coordinate $z$. Consider one such window $i$ with bias potential $U_i(z)$ centered at $z_i$, with stiffness $k_i$, defined by $U_i(z) = \\frac{1}{2} k_i (z - z_i)^{2}$. Assume canonical equilibrium at temperature $T$, and that the biased coordinate $z$ is sampled according to the Boltzmann distribution. Starting from the canonical ensemble definition and the fact that the Boltzmann weight is proportional to $\\exp(-\\beta U_i(z))$ with $\\beta = 1/(k_B T)$, derive the normalized form of the biased probability density $p_i(z)$, and thereby obtain the relation between the stiffness $k_i$ and the width $\\sigma_i$ (the standard deviation) of the sampled distribution around $z_i$. Do not assume any specific result about harmonic oscillators other than the Boltzmann form.\n\nTo ensure accurate WHAM reconstruction across adjacent umbrella windows, suppose we adopt the following operational overlap criterion: for two adjacent windows $i$ and $i+1$ with center separation $\\Delta = |z_{i+1} - z_i|$, require that the ratio of the probability density at the neighbor’s center to the probability density at its own center in window $i$ equals a target value $r \\in (0,1)$, namely $r = p_i(z_{i+1})/p_i(z_i)$. Using your derived biased distribution, obtain an explicit expression for $k_i$ in terms of $r$, $\\Delta$, $T$, and $k_B$.\n\nFinally, for a biomolecular system at $T = 300\\,\\mathrm{K}$ with adjacent umbrella centers spaced by $\\Delta = 0.10\\,\\mathrm{nm}$, and a target overlap ratio $r = 0.30$, compute the numerical value of $k_i$. Express your final stiffness in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$. Use the molar gas constant $R = 8.314462618 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$ in place of $k_B$ to keep energy units per mole. Round your answer to four significant figures.",
            "solution": "The problem is divided into three parts: first, the derivation of the normalized biased probability distribution $p_i(z)$ and the relationship between the harmonic stiffness $k_i$ and the distribution width $\\sigma_i$; second, the derivation of an expression for $k_i$ based on a specified overlap criterion; and third, a numerical calculation of $k_i$.\n\n**Part 1: Biased Probability Distribution and Stiffness-Width Relation**\n\nIn an umbrella sampling window $i$, the system is subject to a total potential energy that includes the intrinsic potential of mean force (PMF), $W(z)$, and the applied bias potential, $U_i(z)$. According to the principles of the canonical ensemble, the probability density of finding the system at a reaction coordinate value $z$ is proportional to the Boltzmann factor of the total energy: $p_i(z) \\propto \\exp(-\\beta [W(z) + U_i(z)])$, where $\\beta = 1/(k_B T)$ is the inverse temperature.\n\nFor a sufficiently stiff harmonic bias, the sampling is localized to a narrow region around the bias center $z_i$. In this region, it is a standard and reasonable approximation to assume that the intrinsic PMF $W(z)$ is nearly constant, i.e., $W(z) \\approx W(z_i)$. This constant energy offset can be absorbed into the normalization constant. The probability density is then determined primarily by the bias potential, $U_i(z)$:\n$$p_i(z) \\propto \\exp(-\\beta U_i(z))$$\nGiven the harmonic form of the bias potential, $U_i(z) = \\frac{1}{2} k_i (z - z_i)^2$, the unnormalized probability density is:\n$$\\tilde{p}_i(z) = C_0 \\exp\\left(-\\frac{\\beta k_i}{2} (z - z_i)^2\\right)$$\nwhere $C_0$ is an arbitrary constant. To obtain the normalized probability density $p_i(z)$, we must enforce the condition $\\int_{-\\infty}^{\\infty} p_i(z) dz = 1$. Let the normalized form be $p_i(z) = C \\exp\\left(-\\frac{\\beta k_i}{2} (z - z_i)^2\\right)$. The normalization constant $C$ is then given by the inverse of the integral:\n$$C^{-1} = \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\beta k_i}{2} (z - z_i)^2\\right) dz$$\nThis is a standard Gaussian integral. Using the general formula $\\int_{-\\infty}^{\\infty} \\exp(-ax^2) dx = \\sqrt{\\pi/a}$, with $x = z - z_i$ and $a = \\beta k_i / 2$, we find:\n$$C^{-1} = \\sqrt{\\frac{\\pi}{\\beta k_i / 2}} = \\sqrt{\\frac{2\\pi}{\\beta k_i}}$$\nThus, the normalization constant is $C = \\sqrt{\\frac{\\beta k_i}{2\\pi}}$. The normalized biased probability density is:\n$$p_i(z) = \\sqrt{\\frac{\\beta k_i}{2\\pi}} \\exp\\left(-\\frac{\\beta k_i}{2} (z - z_i)^2\\right)$$\nThis is a normal (Gaussian) distribution with mean $\\mu = z_i$. The standard form of a normal distribution is $f(x; \\mu, \\sigma^2) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$. By comparing the exponent of our derived $p_i(z)$ with the standard form, we have:\n$$\\frac{(z-z_i)^2}{2\\sigma_i^2} = \\frac{\\beta k_i (z - z_i)^2}{2}$$\nThis implies that the variance $\\sigma_i^2$ is related to the stiffness $k_i$ by $\\frac{1}{\\sigma_i^2} = \\beta k_i$. Rearranging gives the relationship between the stiffness and the distribution width (standard deviation) $\\sigma_i$:\n$$\\sigma_i^2 = \\frac{1}{\\beta k_i} = \\frac{k_B T}{k_i}$$\nThis can be written as $k_i = \\frac{k_B T}{\\sigma_i^2}$.\n\n**Part 2: Expression for Stiffness from Overlap Criterion**\n\nWe are given the overlap criterion for two adjacent windows, $i$ and $i+1$, as $r = p_i(z_{i+1})/p_i(z_i)$. Using our derived expression for $p_i(z)$:\nThe probability density at the center of window $i$, $z=z_i$, is the maximum value of the distribution:\n$$p_i(z_i) = \\sqrt{\\frac{\\beta k_i}{2\\pi}} \\exp(0) = \\sqrt{\\frac{\\beta k_i}{2\\pi}}$$\nThe probability density at the center of the adjacent window, $z=z_{i+1}$, is:\n$$p_i(z_{i+1}) = \\sqrt{\\frac{\\beta k_i}{2\\pi}} \\exp\\left(-\\frac{\\beta k_i}{2} (z_{i+1} - z_i)^2\\right)$$\nThe ratio is therefore:\n$$r = \\frac{p_i(z_{i+1})}{p_i(z_i)} = \\frac{\\sqrt{\\frac{\\beta k_i}{2\\pi}} \\exp\\left(-\\frac{\\beta k_i}{2} (z_{i+1} - z_i)^2\\right)}{\\sqrt{\\frac{\\beta k_i}{2\\pi}}} = \\exp\\left(-\\frac{\\beta k_i}{2} (z_{i+1} - z_i)^2\\right)$$\nGiven the center separation $\\Delta = |z_{i+1} - z_i|$, we have $\\Delta^2 = (z_{i+1} - z_i)^2$. The equation becomes:\n$$r = \\exp\\left(-\\frac{\\beta k_i \\Delta^2}{2}\\right)$$\nTo find an expression for $k_i$, we take the natural logarithm of both sides:\n$$\\ln(r) = -\\frac{\\beta k_i \\Delta^2}{2}$$\nSolving for $k_i$:\n$$k_i = -\\frac{2 \\ln(r)}{\\beta \\Delta^2}$$\nSubstituting $\\beta = 1/(k_B T)$, we obtain the final explicit expression for $k_i$:\n$$k_i = -\\frac{2 k_B T \\ln(r)}{\\Delta^2}$$\nSince $r \\in (0,1)$, $\\ln(r)$ is negative, which ensures that the stiffness $k_i$ is a positive quantity.\n\n**Part 3: Numerical Calculation**\n\nWe are asked to compute the numerical value for $k_i$ using the given parameters: $T = 300\\,\\mathrm{K}$, $\\Delta = 0.10\\,\\mathrm{nm}$, and $r = 0.30$. The problem specifies using the molar gas constant $R = 8.314462618 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$ in place of the Boltzmann constant $k_B$. This substitution correctly adapts the energy units from per-molecule to per-mole, yielding a stiffness in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$.\nThe formula becomes:\n$$k_i = -\\frac{2 R T \\ln(r)}{\\Delta^2}$$\nSubstituting the values:\n$$k_i = -\\frac{2 \\times (8.314462618 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}) \\times (300\\,\\mathrm{K}) \\times \\ln(0.30)}{(0.10\\,\\mathrm{nm})^2}$$\nFirst, we compute the product $RT$:\n$$RT = (8.314462618 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}) \\times (300\\,\\mathrm{K}) \\approx 2.4943\\,\\mathrm{kJ\\,mol^{-1}}$$\nNext, the natural logarithm of $r$:\n$$\\ln(0.30) \\approx -1.2040$$\nNow, we calculate $k_i$:\n$$k_i = -\\frac{2 \\times (2.4943387854\\,\\mathrm{kJ\\,mol^{-1}}) \\times (-1.2039728043)}{0.0100\\,\\mathrm{nm}^2}$$\n$$k_i = \\frac{6.00626301\\,\\mathrm{kJ\\,mol^{-1}}}{0.0100\\,\\mathrm{nm}^2} \\approx 600.6263\\,\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$$\nRounding the result to four significant figures as requested gives:\n$$k_i \\approx 600.6\\,\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$$",
            "answer": "$$\\boxed{600.6}$$"
        },
        {
            "introduction": "This practice simulates the entire computational workflow for calculating a ligand-receptor binding free energy, one of the most common applications of PMF calculations. You will implement the core WHAM algorithm from its foundational self-consistent equations to process synthetic biased histograms. This exercise also guides you through the crucial steps of handling the Jacobian for a radial coordinate and applying the standard-state correction to convert the final PMF into a physically meaningful binding free energy .",
            "id": "3838259",
            "problem": "You are asked to design a computational protocol to estimate a ligand–receptor binding potential of mean force (PMF) along a scalar radial separation coordinate using umbrella sampling combined with the Weighted Histogram Analysis Method (WHAM). The ligand–receptor separation is a scalar coordinate $r$ measured in nanometers. The radial measure in three-dimensional space introduces a Jacobian factor $4\\pi r^2$ that must be explicitly accounted for in the PMF. The ultimate goal is to compute the standard-state binding free energy.\n\nStart from the following fundamental bases:\n\n- The canonical ensemble Boltzmann distribution for a coordinate $x$ with energy $U(x)$ states that the probability density is proportional to $\\exp(-\\beta U(x))$, where $\\beta = 1/(k_\\mathrm{B} T)$, $k_\\mathrm{B}$ is the Boltzmann constant, and $T$ is the temperature.\n- The probability density for a three-dimensional radial coordinate $r$ (with no angular bias) has a measure factor $4\\pi r^2$, so the probability density with respect to the scalar $r$ is proportional to $4\\pi r^2 \\exp(-\\beta G(r))$ when $G(r)$ is the PMF excluding the geometric entropic term.\n- Umbrella sampling applies a harmonic bias in window $i$: $U_i^\\mathrm{bias}(r) = \\tfrac{1}{2} k_i (r - r_i)^2$ with force constant $k_i$ and center $r_i$.\n- The Weighted Histogram Analysis Method (WHAM) combines biased histograms from multiple windows into a single unbiased distribution by enforcing self-consistency between the global distribution and window normalizations.\n\nYour program must:\n\n1. Construct synthetic umbrella sampling histograms for each window by sampling from a known underlying PMF $G_\\mathrm{true}(r)$ (to make the problem self-contained and testable). The synthetic PMF to be used for data generation in all test cases is a Morse-type function\n   $$G_\\mathrm{true}(r) = D\\left(\\exp\\big(-2 a (r - r_0)\\big) - 2 \\exp\\big(-a (r - r_0)\\big)\\right),$$\n   where $D$ is the depth parameter in $\\mathrm{kJ/mol}$, $a$ is the range parameter in $\\mathrm{nm}^{-1}$, and $r_0$ is the minimum location in $\\mathrm{nm}$. The temperature must be $T = 300$ $\\mathrm{K}$, and the Boltzmann constant must be $k_\\mathrm{B} = 0.008314462618$ $\\mathrm{kJ/(mol\\cdot K)}$, so that $\\beta$ is in units of $(\\mathrm{kJ/mol})^{-1}$. The grid for $r$ must be uniform, with $r_\\mathrm{min} = 0.05$ $\\mathrm{nm}$, $r_\\mathrm{max} = 1.50$ $\\mathrm{nm}$, and bin width $\\Delta r = 0.01$ $\\mathrm{nm}$.\n\n2. For each window $i$ and each bin centered at $r_j$, construct the expected biased histogram counts using the biased radial probability density proportional to $4\\pi r_j^2 \\exp\\big(-\\beta\\big(G_\\mathrm{true}(r_j) + U_i^\\mathrm{bias}(r_j)\\big)\\big)$, normalized over the grid so that the total counts in window $i$ equal the specified per-window sample size $N_i$.\n\n3. Implement the Weighted Histogram Analysis Method (WHAM) to iteratively recover the global unbiased probability density $\\hat{p}(r)$ over the grid from the set of window histograms and their harmonic biases. Do not use any shortcut formulas. Derive the update rules from the principles above:\n   - The unbiased distribution must be consistent with the sum of window histograms weighted by the inverse of the bias-induced reweighting factors and window normalizations.\n   - The per-window normalization constants must be updated so that the global distribution reweights back to each window’s biased ensemble normalization.\n\n   Iterate until convergence of the window free energies to a tight tolerance such that the maximum change in all window normalizations between iterations is less than $10^{-10}$ in energy units.\n\n4. Convert the unbiased scalar probability density $\\hat{p}(r)$ into the PMF $G(r)$ that excludes the Jacobian by incorporating the $4\\pi r^2$ factor explicitly. The PMF must be shifted so that it approaches zero in the bulk region, defined here as the high-$r$ tail. Use a bulk range of $r \\in [1.30, 1.50]$ $\\mathrm{nm}$ and enforce that the mean of $G(r)$ over this range is zero.\n\n5. Compute the standard-state binding free energy $\\Delta G_\\mathrm{bind}^\\circ$ by integrating the association constant over a bound region $[0, r_c]$:\n   - Compute the radial association constant $K = \\int_0^{r_c} \\exp\\big(-\\beta G(r)\\big)\\,4\\pi r^2\\,dr$ in $\\mathrm{nm}^3$.\n   - Convert to a dimensionless standard-state equilibrium constant using the standard-state volume $V^\\circ = 1.66053906660$ $\\mathrm{nm}^3$ at $1$ $\\mathrm{M}$: $K^\\circ = K / V^\\circ$.\n   - Report the binding free energy $\\Delta G_\\mathrm{bind}^\\circ = -\\beta^{-1} \\ln K^\\circ$ in $\\mathrm{kJ/mol}$.\n\nYour program must implement the above steps and produce results for the following test suite. For each case, use the specified window set, underlying PMF parameters, per-window counts, and bound-region cutoff $r_c$. Umbrella windows have centers $r_i$ uniformly spaced as specified and identical force constants $k_i$ within each case:\n\n- Test Case $1$ (general case):\n  - Window centers: $r_i \\in \\{0.20, 0.30, 0.40, \\dots, 1.20\\}$ $\\mathrm{nm}$ with step $0.10$ $\\mathrm{nm}$.\n  - Force constant: $k_i = 1200$ $\\mathrm{kJ/(mol\\cdot nm^2)}$.\n  - Per-window counts: $N_i = 50000$.\n  - Underlying PMF parameters: $D = 10$ $\\mathrm{kJ/mol}$, $a = 15$ $\\mathrm{nm}^{-1}$, $r_0 = 0.30$ $\\mathrm{nm}$.\n  - Bound-region cutoff: $r_c = 0.45$ $\\mathrm{nm}$.\n\n- Test Case $2$ (weak binding edge case):\n  - Window centers: $r_i \\in \\{0.20, 0.30, 0.40, \\dots, 1.20\\}$ $\\mathrm{nm}$ with step $0.10$ $\\mathrm{nm}$.\n  - Force constant: $k_i = 900$ $\\mathrm{kJ/(mol\\cdot nm^2)}$.\n  - Per-window counts: $N_i = 30000$.\n  - Underlying PMF parameters: $D = 4$ $\\mathrm{kJ/mol}$, $a = 12$ $\\mathrm{nm}^{-1}$, $r_0 = 0.32$ $\\mathrm{nm}$.\n  - Bound-region cutoff: $r_c = 0.45$ $\\mathrm{nm}$.\n\n- Test Case $3$ (strong binding, broader coverage):\n  - Window centers: $r_i \\in \\{0.15, 0.25, 0.35, \\dots, 1.35\\}$ $\\mathrm{nm}$ with step $0.10$ $\\mathrm{nm}$.\n  - Force constant: $k_i = 1500$ $\\mathrm{kJ/(mol\\cdot nm^2)}$.\n  - Per-window counts: $N_i = 60000$.\n  - Underlying PMF parameters: $D = 20$ $\\mathrm{kJ/mol}$, $a = 22$ $\\mathrm{nm}^{-1}$, $r_0 = 0.28$ $\\mathrm{nm}$.\n  - Bound-region cutoff: $r_c = 0.40$ $\\mathrm{nm}$.\n\nAngle units are not applicable here. Express all energies in $\\mathrm{kJ/mol}$ and all lengths in $\\mathrm{nm}$. Your program must produce a single line of output containing the three binding free energies for the test suite as a comma-separated list enclosed in square brackets, with each value rounded to three decimal places (e.g., $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3\\right]$).",
            "solution": "The objective is to compute the potential of mean force (PMF) from synthetic umbrella sampling data using the Weighted Histogram Analysis Method (WHAM), and subsequently calculate the standard-state binding free energy. This process involves several steps: generating synthetic biased histograms, applying the WHAM algorithm to recover the unbiased probability distribution, converting this distribution into a PMF, and finally integrating the PMF to obtain the binding free energy.\n\nFirst, we establish the theoretical framework. The PMF, denoted as $G(r)$, along a one-dimensional reaction coordinate $r$ is related to the equilibrium probability density $P(r)$ by the Boltzmann relation. For a radial coordinate in three-dimensional space, the volume element is $4\\pi r^2 dr$, which introduces a Jacobian factor into the probability density. The probability $P(r)dr$ of finding the system with a separation between $r$ and $r+dr$ is given by:\n$$P(r) \\propto 4\\pi r^2 \\exp(-\\beta G(r))$$\nwhere $\\beta = 1/(k_\\mathrm{B} T)$, $k_\\mathrm{B}$ is the Boltzmann constant, and $T$ is the absolute temperature. The PMF $G(r)$ as defined here represents the free energy profile excluding the geometric entropic contribution that is captured by the $4\\pi r^2$ term.\n\nUmbrella sampling enhances sampling of high-energy regions by adding a biasing potential, typically harmonic, in each simulation window $i$. The bias potential is given by $U_i^\\mathrm{bias}(r) = \\frac{1}{2} k_i (r - r_i)^2$, where $k_i$ is the force constant and $r_i$ is the center of the potential for window $i$. In a biased simulation, the observed probability density, $P_i^\\mathrm{bias}(r)$, is modulated by this potential:\n$$P_i^\\mathrm{bias}(r) \\propto 4\\pi r^2 \\exp(-\\beta [G(r) + U_i^\\mathrm{bias}(r)])$$\n\nThe Weighted Histogram Analysis Method (WHAM) is a robust statistical technique for combining data from multiple biased simulations (windows) to compute the unbiased probability distribution along the reaction coordinate. It determines the optimal combination by solving a set of self-consistent equations. Let $N_{ij}$ be the number of samples observed in coordinate bin $j$ from window $i$, and $N_i = \\sum_j N_{ij}$ be the total number of samples in window $i$. The WHAM equations relate the unbiased probability $P_j$ of being in bin $j$ to the window-specific free energy offsets $f_i$:\n$$\n\\begin{cases}\nP_j = \\left( \\sum_{k=1}^{M} N_{kj} \\right) \\left/ \\left( \\sum_{k=1}^{M} N_k \\exp(\\beta f_k) \\exp(-\\beta U_{kj}) \\right) \\right. \\\\\n\\exp(-\\beta f_i) = \\sum_{j=1}^{N_\\mathrm{bins}} P_j \\exp(-\\beta U_{ij})\n\\end{cases}\n$$\nHere, $M$ is the number of windows, $N_\\mathrm{bins}$ is the number of coordinate bins, and $U_{ij} = U_i^\\mathrm{bias}(r_j)$ is the bias potential of window $i$ evaluated at the center of bin $j$. The probabilities $P_j$ are defined up to a global normalization constant, and are typically normalized such that $\\sum_j P_j = 1$. The free energies $f_i$ are defined only relative to each other, so one is typically set to zero (e.g., $f_1=0$) for a unique solution. These equations are solved iteratively until the values of $f_i$ converge.\n\nThe algorithmic procedure is as follows:\n1.  **System Setup and Data Generation**:\n    - Define physical constants $\\beta = 1/(k_\\mathrm{B}T)$ and a discrete grid of $r$ values, $r_j$, from $r_\\mathrm{min}$ to $r_\\mathrm{max}$ with bin width $\\Delta r$.\n    - For each test case, the true underlying PMF, $G_\\mathrm{true}(r)$, is defined by a Morse potential: $G_\\mathrm{true}(r) = D(e^{-2a(r-r_0)} - 2e^{-a(r-r_0)})$.\n    - For each window $i$, a synthetic histogram $N_{ij}$ is generated. The expected number of counts in bin $j$ is proportional to the biased probability density: $N_{ij} \\propto N_i \\cdot 4\\pi r_j^2 \\exp(-\\beta[G_\\mathrm{true}(r_j) + U_i^\\mathrm{bias}(r_j)])$. The counts are normalized such that $\\sum_j N_{ij} = N_i$.\n\n2.  **WHAM Iteration**:\n    - Initialize the window free energies, e.g., $f_i = 0$ for all $i$.\n    - Iterate until the maximum change in any $f_i$ is below a tolerance ($10^{-10}$):\n      a. Calculate the unbiased probabilities $P_j$ for all bins using the current $f_i$ values. This requires computing the denominator term for each bin $j$, $D_j = \\sum_{k=1}^M N_k \\exp(\\beta f_k - \\beta U_{kj})$, and the total counts per bin, $C_j = \\sum_{k=1}^M N_{kj}$. The unnormalized probability is then $\\tilde{P}_j = C_j / D_j$. Finally, normalize so that $\\sum_j P_j = 1$.\n      b. Calculate a new set of free energies, $f_i^\\mathrm{new}$, using the updated probabilities $P_j$: $f_i^\\mathrm{new} = -\\beta^{-1} \\ln\\left(\\sum_j P_j \\exp(-\\beta U_{ij})\\right)$.\n      c. To prevent numerical drift, shift the new free energies, e.g., by subtracting the value of the first one: $f_i^\\mathrm{new} \\leftarrow f_i^\\mathrm{new} - f_i^\\mathrm{new}[0]$.\n      d. Update $f_i \\leftarrow f_i^\\mathrm{new}$ and check for convergence.\n\n3.  **PMF Reconstruction**:\n    - Once the converged unbiased probabilities $P_j$ are obtained, the PMF $G(r_j)$ is calculated. From $P_j \\propto 4\\pi r_j^2 \\exp(-\\beta G(r_j))$, we can write $G(r_j) = -\\beta^{-1} \\ln(P_j/r_j^2) + \\text{constant}$. For bins with $P_j=0$, $G(r_j)$ is infinite.\n    - The PMF is shifted by an additive constant such that its average value over a bulk region (defined as $r \\in [1.30, 1.50]$ nm) is zero. This sets the reference state to be the unbound state.\n\n4.  **Binding Free Energy Calculation**:\n    - The standard-state binding free energy $\\Delta G_\\mathrm{bind}^\\circ$ is determined from the association constant $K$. The radial association constant is integrated over a defined bound volume:\n      $$K = \\int_0^{r_c} 4\\pi r^2 \\exp(-\\beta G(r)) dr$$\n      This integral is numerically approximated by a sum over the grid bins up to the cutoff $r_c$: $K \\approx \\sum_{j: r_j \\le r_c} 4\\pi r_j^2 \\exp(-\\beta G(r_j)) \\Delta r$.\n    - The standard-state equilibrium constant $K^\\circ$ is obtained by dividing by the standard-state volume, $V^\\circ = 1.66053906660$ $\\mathrm{nm}^3$ (equivalent to a $1$ M standard concentration): $K^\\circ = K/V^\\circ$.\n    - Finally, the binding free energy is computed as:\n      $$\\Delta G_\\mathrm{bind}^\\circ = -k_\\mathrm{B} T \\ln(K^\\circ) = -\\beta^{-1} \\ln(K^\\circ)$$\n\nThis entire protocol is implemented for each of the three test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the standard-state binding free energy for three test cases using WHAM.\n    \"\"\"\n\n    # --- Global Parameters and Constants ---\n    T = 300.0  # Temperature in K\n    K_B = 0.008314462618  # Boltzmann constant in kJ/(mol*K)\n    BETA = 1.0 / (K_B * T)  # In (kJ/mol)^-1\n    V_STANDARD = 1.66053906660  # Standard state volume in nm^3 (for 1 M)\n\n    # --- Grid setup ---\n    R_MIN = 0.05  # nm\n    R_MAX = 1.50  # nm\n    DR = 0.01  # nm\n    r_grid = np.arange(R_MIN, R_MAX + DR / 2.0, DR)\n    num_bins = len(r_grid)\n\n    # --- Bulk region definition for PMF shifting ---\n    BULK_MIN = 1.30\n    BULK_MAX = 1.50\n\n    # --- WHAM convergence criterion ---\n    WHAM_TOLERANCE = 1e-10\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"window_centers\": np.arange(0.20, 1.20 + 0.05, 0.10),\n            \"k\": 1200.0,\n            \"N_i\": 50000,\n            \"D\": 10.0,\n            \"a\": 15.0,\n            \"r0\": 0.30,\n            \"rc\": 0.45,\n        },\n        # Test Case 2\n        {\n            \"window_centers\": np.arange(0.20, 1.20 + 0.05, 0.10),\n            \"k\": 900.0,\n            \"N_i\": 30000,\n            \"D\": 4.0,\n            \"a\": 12.0,\n            \"r0\": 0.32,\n            \"rc\": 0.45,\n        },\n        # Test Case 3\n        {\n            \"window_centers\": np.arange(0.15, 1.35 + 0.05, 0.10),\n            \"k\": 1500.0,\n            \"N_i\": 60000,\n            \"D\": 20.0,\n            \"a\": 22.0,\n            \"r0\": 0.28,\n            \"rc\": 0.40,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        window_centers = case[\"window_centers\"]\n        k = case[\"k\"]\n        N_i_val = case[\"N_i\"]\n        D = case[\"D\"]\n        a = case[\"a\"]\n        r0 = case[\"r0\"]\n        rc = case[\"rc\"]\n\n        num_windows = len(window_centers)\n        \n        # --- 1. Construct Synthetic Histograms ---\n        \n        # True PMF (Morse potential)\n        g_true = D * (np.exp(-2 * a * (r_grid - r0)) - 2 * np.exp(-a * (r_grid - r0)))\n        \n        histograms = np.zeros((num_windows, num_bins))\n        biases_matrix = np.zeros((num_windows, num_bins))\n        N_i_array = np.full(num_windows, N_i_val, dtype=float)\n\n        for i in range(num_windows):\n            r_center = window_centers[i]\n            # Harmonic bias potential for window i\n            u_bias = 0.5 * k * (r_grid - r_center)**2\n            biases_matrix[i, :] = u_bias\n            \n            # Biased energy\n            biased_energy = g_true + u_bias\n            \n            # Biased probability distribution including Jacobian\n            # Prop to 4*pi*r^2 * exp(-beta * E_biased)\n            unnorm_prob = (4 * np.pi * r_grid**2) * np.exp(-BETA * biased_energy)\n            \n            # Normalize probability for this window\n            norm_factor = np.sum(unnorm_prob)\n            if norm_factor == 0:\n                # This case shouldn't happen with the given parameters\n                # but good practice to handle.\n                norm_prob = np.zeros_like(unnorm_prob)\n            else:\n                norm_prob = unnorm_prob / norm_factor\n\n            # Generate histogram counts\n            histograms[i, :] = N_i_val * norm_prob\n            \n        # --- 3. Implement WHAM ---\n        f_i = np.zeros(num_windows)  # Initialize window free energies\n        \n        # Pre-compute terms that don't change in the loop\n        total_counts_per_bin = np.sum(histograms, axis=0) # Numerator of P_j\n        exp_minus_beta_U = np.exp(-BETA * biases_matrix) # exp(-beta*U_ij)\n        \n        for iteration in range(10000): # Max iterations to prevent infinite loop\n            f_old = f_i.copy()\n            \n            # Denominator of P_j\n            exp_beta_f = np.exp(BETA * f_i)\n            weighted_N = N_i_array * exp_beta_f\n            \n            # Sum over windows k for each bin j\n            den_P = weighted_N @ exp_minus_beta_U\n            \n            with np.errstate(divide='ignore', invalid='ignore'):\n                P_unnormalized = total_counts_per_bin / den_P\n            \n            P_unnormalized[np.isnan(P_unnormalized)] = 0.0\n\n            # Normalize probabilities\n            P = P_unnormalized / np.sum(P_unnormalized)\n            \n            # Update free energies f_i\n            with np.errstate(divide='ignore'):\n              log_arg = P @ exp_minus_beta_U.T\n            \n            f_new = -1.0 / BETA * np.log(log_arg)\n            f_new[np.isinf(f_new)] = f_i[np.isinf(f_new)] # Keep old if log_arg is 0\n\n            # Shift to prevent drift\n            f_new -= f_new[0]\n            f_i = f_new\n\n            # Check for convergence\n            max_change = np.max(np.abs(f_i - f_old))\n            if max_change  WHAM_TOLERANCE:\n                break\n        \n        # --- 4. Convert Probability to PMF and Shift ---\n        with np.errstate(divide='ignore'):\n             # G = -k_B*T * (ln(P) - ln(4*pi*r^2*dr))\n             # The constant term ln(4*pi*dr) will be absorbed into the shifting constant\n             G = -1.0 / BETA * (np.log(P) - 2.0 * np.log(r_grid))\n\n        G[np.isneginf(G)] = np.inf # Bins with P=0 have infinite free energy\n        \n        # Shift PMF so bulk region (high r) is zero\n        bulk_mask = (r_grid >= BULK_MIN)  (r_grid = BULK_MAX)\n        G_bulk = G[bulk_mask]\n        \n        finite_G_bulk = G_bulk[np.isfinite(G_bulk)]\n        if len(finite_G_bulk) > 0:\n            shift = np.mean(finite_G_bulk)\n            G -= shift\n        \n        # --- 5. Compute Standard-State Binding Free Energy ---\n        bound_mask = r_grid = rc\n        \n        # Integrand for association constant K\n        integrand = np.exp(-BETA * G) * (4 * np.pi * r_grid**2)\n        \n        # Numerical integration (sum over bins)\n        K = np.sum(integrand[bound_mask]) * DR\n\n        # Standard-state equilibrium constant and free energy\n        if K > 0 and V_STANDARD > 0:\n            K_standard = K / V_STANDARD\n            delta_G_bind = -1.0 / BETA * np.log(K_standard)\n        else:\n            delta_G_bind = np.inf # Should not happen\n\n        results.append(round(delta_G_bind, 3))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After calculating a potential of mean force, a critical question remains: is the result self-consistent and reliable? This practice introduces a powerful validation technique where the final, unbiased PMF is used to \"predict\" the original biased distributions observed in each umbrella window. By quantitatively comparing these predictions to the original data using information-theoretic measures, you can rigorously assess the quality and convergence of your WHAM analysis .",
            "id": "3838250",
            "problem": "You are given a discretized reaction coordinate with $M$ bins and a set of harmonic bias potentials representing umbrella sampling windows. A Weighted Histogram Analysis Method (WHAM)-derived potential of mean force (PMF) defines an unbiased probability distribution along the reaction coordinate. Your task is to validate the WHAM-derived PMF by reconstructing the predicted biased distributions under each window using equilibrium statistical mechanics and quantitatively comparing them to observed histograms with divergence measures.\n\nStart from the following context-appropriate fundamental base in equilibrium statistical mechanics: the canonical ensemble assigns to each microstate of energy $E$ a probability proportional to $\\exp(-\\beta E)$, where $\\beta = 1/(k_{\\mathrm{B}} T)$ with $k_{\\mathrm{B}}$ the Boltzmann constant and $T$ the absolute temperature. The potential of mean force along a reaction coordinate $z$, denoted $F(z)$, is defined by integrating out orthogonal degrees of freedom and satisfies $P(z)\\propto \\exp(-\\beta F(z))$, where $P(z)$ is the unbiased probability density. When an additional bias potential $U_i(z)$ is applied in window $i$, equilibrium reweighting modifies the distribution along $z$. Using these principles, reconstruct the predicted biased distributions for each window from the given unbiased $P(z)$ and the window bias $U_i(z)$. Do not assume any shortcut formulas beyond what follows from the canonical ensemble and the definition of the potential of mean force.\n\nYou must implement a program that:\n- Discretizes the reaction coordinate $z$ into $M$ bins with centers spanning from $z_{\\min}$ to $z_{\\max}$.\n- Constructs a WHAM-derived unbiased distribution $P(z)$ as a normalized mixture of two Gaussian components along $z$.\n- For each umbrella window $i$, with harmonic bias potential parameters, reconstructs the predicted biased distribution along $z$ by equilibrium reweighting from $P(z)$ under $U_i(z)$.\n- Normalizes all distributions to sum to $1$ over bins.\n- Compares the predicted distributions to the observed histograms converted to normalized probability mass functions using the Kullback–Leibler divergence (KLD) and Jensen–Shannon divergence (JSD).\n- Uses a small regularization parameter $\\epsilon$ to ensure numerical stability in the presence of zero probabilities.\n\nPrecise specifications:\n1. Discretization and units:\n   - Number of bins $M$: $101$.\n   - Bin centers $z$: uniformly spaced from $z_{\\min} = 0$ to $z_{\\max} = 1$, in nanometers (nm).\n   - Temperature $T$: $300$ Kelvin (K).\n   - Boltzmann constant $k_{\\mathrm{B}}$: $0.008314462618$ kilojoules per mole per Kelvin (kJ mol$^{-1}$ K$^{-1}$), so that $\\beta = 1/(k_{\\mathrm{B}} T)$ has units of mol kJ$^{-1}$.\n   - All energies must be handled in kilojoules per mole (kJ mol$^{-1}$).\n2. Unbiased distribution $P(z)$:\n   - Define $P(z)$ as a mixture of two Gaussian components:\n     - Component $1$: weight $w_1 = 0.6$, mean $\\mu_1 = 0.3$ nm, standard deviation $\\sigma = 0.06$ nm.\n     - Component $2$: weight $w_2 = 0.4$, mean $\\mu_2 = 0.7$ nm, same $\\sigma$ as above.\n   - The unnormalized form is $P_{\\text{raw}}(z) = w_1 \\exp\\!\\left(-\\frac{(z-\\mu_1)^2}{2\\sigma^2}\\right) + w_2 \\exp\\!\\left(-\\frac{(z-\\mu_2)^2}{2\\sigma^2}\\right)$, and the normalized unbiased distribution is $P(z) = P_{\\text{raw}}(z) / \\sum_{j=1}^M P_{\\text{raw}}(z_j)$ so that $\\sum_j P(z_j) = 1$.\n3. Umbrella windows and observed histograms:\n   - The harmonic bias potential in window $i$ is $U_i(z) = \\frac{1}{2} k_i (z - z_{0,i})^2$, with $k_i$ in kJ mol$^{-1}$ nm$^{-2}$ and $z_{0,i}$ in nm.\n   - Four windows define the test suite:\n     - Window $A$: $z_{0,A} = 0.30$ nm, $k_A = 200.0$ kJ mol$^{-1}$ nm$^{-2}$, observed total counts $N_A = 10000$. The observed histogram is constructed from the exact reweighted equilibrium distribution for this window, converted to counts by allocating $N_A$ counts across bins.\n     - Window $B$: $z_{0,B} = 0.70$ nm, $k_B = 200.0$ kJ mol$^{-1}$ nm$^{-2}$, observed total counts $N_B = 8000$. The observed histogram is constructed from the reweighted equilibrium distribution multiplied by a deterministic skew factor $s(z) = \\exp(\\lambda (z - 0.6))$ with $\\lambda = 3.0$, then normalized and converted to counts.\n     - Window $C$: $z_{0,C} = 0.50$ nm, $k_C = 400.0$ kJ mol$^{-1}$ nm$^{-2}$, observed total counts $N_C = 3000$. The observed histogram is constructed by truncating the reweighted equilibrium distribution to the interval $[0.40, 0.60]$ nm (zero outside), then normalized and converted to counts.\n     - Window $D$: $z_{0,D} = 0.20$ nm, $k_D = 800.0$ kJ mol$^{-1}$ nm$^{-2}$, observed total counts $N_D = 2000$. The observed histogram is constructed by adding a uniform baseline $b = 0.001$ to the reweighted equilibrium distribution across all bins, then normalized and converted to counts.\n   - For count conversion in each window, allocate integer counts across bins from the normalized observed distribution by distributing $N_i$ counts using the fractional weights so that the final integer sum equals $N_i$.\n4. Regularization for numerical stability:\n   - Use $\\epsilon = 10^{-12}$ as a lower bound on probabilities. Before computing divergences, clip both predicted and observed distributions to be at least $\\epsilon$ in every bin and renormalize to sum to $1$.\n5. Divergence measures:\n   - Kullback–Leibler divergence (natural logarithm):\n     - Forward divergence from observed to predicted: $D_{\\mathrm{KL}}(Q\\Vert P) = \\sum_{j=1}^{M} Q_j \\ln\\!\\left(\\frac{Q_j}{P_j}\\right)$.\n     - Reverse divergence: $D_{\\mathrm{KL}}(P\\Vert Q) = \\sum_{j=1}^{M} P_j \\ln\\!\\left(\\frac{P_j}{Q_j}\\right)$.\n   - Jensen–Shannon divergence (natural logarithm):\n     - $D_{\\mathrm{JS}}(P,Q) = \\frac{1}{2} D_{\\mathrm{KL}}(P\\Vert M) + \\frac{1}{2} D_{\\mathrm{KL}}(Q\\Vert M)$, where $M = \\frac{1}{2}(P+Q)$ elementwise.\n6. Required final output format:\n   - Your program should produce a single line of output containing a comma-separated list enclosed in square brackets with $12$ floating-point values in this exact order:\n     - $[D_{\\mathrm{KL}}(Q_A\\Vert P_A), D_{\\mathrm{KL}}(Q_B\\Vert P_B), D_{\\mathrm{KL}}(Q_C\\Vert P_C), D_{\\mathrm{KL}}(Q_D\\Vert P_D), D_{\\mathrm{KL}}(P_A\\Vert Q_A), D_{\\mathrm{KL}}(P_B\\Vert Q_B), D_{\\mathrm{KL}}(P_C\\Vert Q_C), D_{\\mathrm{KL}}(P_D\\Vert Q_D), D_{\\mathrm{JS}}(P_A,Q_A), D_{\\mathrm{JS}}(P_B,Q_B), D_{\\mathrm{JS}}(P_C,Q_C), D_{\\mathrm{JS}}(P_D,Q_D)]$.\n   - All values are dimensionless floats.\n\nTest Suite Summary (to be hard-coded in your program):\n- $M = 101$, $z \\in [0,1]$ nm, $T = 300$ K, $k_{\\mathrm{B}} = 0.008314462618$ kJ mol$^{-1}$ K$^{-1}$, $\\sigma = 0.06$ nm, $w_1 = 0.6$, $\\mu_1 = 0.3$ nm, $w_2 = 0.4$, $\\mu_2 = 0.7$ nm, $\\epsilon = 10^{-12}$.\n- Window $A$: $(z_0, k, N) = (0.30 \\text{ nm}, 200.0 \\text{ kJ mol}^{-1} \\text{ nm}^{-2}, 10000)$.\n- Window $B$: $(z_0, k, N, \\lambda) = (0.70 \\text{ nm}, 200.0 \\text{ kJ mol}^{-1} \\text{ nm}^{-2}, 8000, 3.0)$.\n- Window $C$: $(z_0, k, N, \\text{interval}) = (0.50 \\text{ nm}, 400.0 \\text{ kJ mol}^{-1} \\text{ nm}^{-2}, 3000, [0.40, 0.60] \\text{ nm})$.\n- Window $D$: $(z_0, k, N, b) = (0.20 \\text{ nm}, 800.0 \\text{ kJ mol}^{-1} \\text{ nm}^{-2}, 2000, 0.001)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots,r_{12}]$).",
            "solution": "The problem requires the validation of a potential of mean force (PMF), represented by its corresponding unbiased probability distribution, against a series of \"observed\" histograms taken from different biased (umbrella) sampling windows. The validation is performed by quantitatively comparing predicted biased distributions with the observed ones using information-theoretic divergence measures. The approach is grounded in the principles of equilibrium statistical mechanics.\n\nThe fundamental connection between the potential of mean force $F(z)$ along a reaction coordinate $z$ and the equilibrium probability distribution $P(z)$ is given by the Boltzmann relation:\n$$\nP(z) \\propto \\exp(-\\beta F(z))\n$$\nwhere $\\beta = 1/(k_{\\mathrm{B}} T)$ is the inverse thermal energy, with $k_{\\mathrm{B}}$ being the Boltzmann constant and $T$ the absolute temperature. This relation implies that the PMF can be determined from the probability distribution up to an additive constant, as $F(z) = -\\frac{1}{\\beta} \\ln P(z) + C$.\n\nWhen an external bias potential, $U_i(z)$, is applied in an umbrella sampling window $i$, the total effective potential along the coordinate $z$ becomes $F(z) + U_i(z)$. The resulting biased equilibrium probability distribution in that window, denoted $P_i(z)$, is given by:\n$$\nP_i(z) \\propto \\exp(-\\beta (F(z) + U_i(z))) = \\exp(-\\beta F(z)) \\exp(-\\beta U_i(z))\n$$\nSubstituting the expression for the unbiased distribution $P(z)$, we arrive at the core reweighting equation, which allows us to predict the biased distribution from the unbiased one:\n$$\nP_i(z) \\propto P(z) \\exp(-\\beta U_i(z))\n$$\nWe will use this principle to generate the *predicted* biased distribution for each window. The problem defines synthetic *observed* distributions, which are derived from these predicted distributions with specific modifications to simulate experimental or sampling artifacts. The discrepancy between the predicted and observed distributions is then quantified.\n\nThe implementation follows these steps:\n\n1.  **System and Parameter Initialization**: We begin by defining the physical and numerical parameters of the system. The reaction coordinate $z$ is discretized into $M=101$ bins, spanning uniformly from $z_{\\min}=0$ nm to $z_{\\max}=1$ nm. The temperature is $T=300$ K and the Boltzmann constant is $k_{\\mathrm{B}} = 0.008314462618$ kJ mol$^{-1}$ K$^{-1}$. The inverse thermal energy $\\beta$ is calculated from these values. A small regularization constant $\\epsilon = 10^{-12}$ is defined for numerical stability.\n\n2.  **Unbiased Distribution Construction**: The unbiased probability distribution $P(z)$ is constructed as a normalized mixture of two Gaussian components. The unnormalized distribution $P_{\\text{raw}}(z)$ over the discrete bin centers $z_j$ is given by:\n    $$\n    P_{\\text{raw}}(z_j) = w_1 \\exp\\left(-\\frac{(z_j-\\mu_1)^2}{2\\sigma^2}\\right) + w_2 \\exp\\left(-\\frac{(z_j-\\mu_2)^2}{2\\sigma^2}\\right)\n    $$\n    with weights $w_1=0.6$, $w_2=0.4$, means $\\mu_1=0.3$ nm, $\\mu_2=0.7$ nm, and standard deviation $\\sigma=0.06$ nm. This raw distribution is then normalized to sum to unity over all bins, yielding the unbiased probability mass function $P(z_j)$:\n    $$\n    P(z_j) = \\frac{P_{\\text{raw}}(z_j)}{\\sum_{k=1}^M P_{\\text{raw}}(z_k)}\n    $$\n\n3.  **Prediction of Biased Distributions**: For each of the four umbrella windows ($A, B, C, D$), we first calculate the harmonic bias potential $U_i(z_j) = \\frac{1}{2} k_i (z_j - z_{0,i})^2$ using the provided spring constants $k_i$ and centers $z_{0,i}$. Using the reweighting formula, the unnormalized predicted biased distribution $P_i^{\\text{pred, raw}}(z_j)$ for window $i$ is calculated:\n    $$\n    P_i^{\\text{pred, raw}}(z_j) = P(z_j) \\exp(-\\beta U_i(z_j))\n    $$\n    This is then normalized to yield the predicted probability mass function for window $i$, which we denote $P_i(z_j)$.\n\n4.  **Generation of Observed Histograms**: The problem specifies rules for generating synthetic \"observed\" histograms, which we denote as $Q_i(z_j)$. This process simulates the finite sampling and potential systematic errors inherent in real data acquisition. For each window $i$:\n    a. A 'true' underlying probability distribution for the observed data is created by modifying the predicted distribution $P_i(z_j)$ according to the window's specific rule (e.g., applying a skew factor, truncating, or adding a baseline). This distribution is normalized.\n    b. Integer counts are generated from this modified probability distribution for a given total number of samples $N_i$. This is done using a deterministic rounding procedure that allocates the $N_i$ counts proportionally to the probabilities in each bin, ensuring the total count is exactly $N_i$.\n    c. The final observed probability mass function $Q_i(z_j)$ is obtained by normalizing these counts by the total number of samples $N_i$.\n\n5.  **Regularization and Divergence Computation**: To avoid numerical errors such as logarithms of zero when computing divergences, both the predicted ($P_i$) and observed ($Q_i$) distributions for each window are regularized. A small value $\\epsilon=10^{-12}$ is added to each bin, or more precisely, each bin's probability is clipped to have a minimum value of $\\epsilon$. The distributions are then re-normalized to sum to $1$.\n\n    Finally, we compute the divergence between the regularized distributions $P_i$ and $Q_i$ for each window. The required measures are:\n    -   **Kullback-Leibler Divergence (KLD)**:\n        $$\n        D_{\\mathrm{KL}}(Q \\Vert P) = \\sum_{j=1}^{M} Q_j \\ln\\left(\\frac{Q_j}{P_j}\\right) \\quad \\text{and} \\quad D_{\\mathrm{KL}}(P \\Vert Q) = \\sum_{j=1}^{M} P_j \\ln\\left(\\frac{P_j}{Q_j}\\right)\n        $$\n    -   **Jensen-Shannon Divergence (JSD)**:\n        $$\n        D_{\\mathrm{JS}}(P, Q) = \\frac{1}{2} D_{\\mathrm{KL}}(P \\Vert M_{\\text{mix}}) + \\frac{1}{2} D_{\\mathrm{KL}}(Q \\Vert M_{\\text{mix}}), \\quad \\text{where} \\quad M_{\\text{mix}} = \\frac{1}{2}(P+Q)\n        $$\n    These calculations are performed for each of the four windows, yielding a total of $12$ divergence values. The results are then formatted into a single list as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates divergence measures between predicted and observed distributions\n    in the context of umbrella sampling validation.\n    \"\"\"\n\n    # 1. System and Parameter Initialization\n    M = 101\n    z_min, z_max = 0.0, 1.0\n    T = 300.0  # Kelvin\n    k_B = 0.008314462618  # kJ mol^-1 K^-1\n    epsilon = 1e-12\n    beta = 1.0 / (k_B * T)  # mol kJ^-1\n    z = np.linspace(z_min, z_max, M)  # nm\n\n    # 2. Unbiased Distribution Construction\n    w1, mu1 = 0.6, 0.3\n    w2, mu2 = 0.4, 0.7\n    sigma = 0.06\n    p_raw_z = w1 * np.exp(-(z - mu1)**2 / (2 * sigma**2)) + \\\n              w2 * np.exp(-(z - mu2)**2 / (2 * sigma**2))\n    p_unbiased = p_raw_z / np.sum(p_raw_z)\n\n    # Test suite parameters\n    test_cases = [\n        {'id': 'A', 'z0': 0.30, 'k': 200.0, 'N': 10000},\n        {'id': 'B', 'z0': 0.70, 'k': 200.0, 'N': 8000, 'lambda': 3.0},\n        {'id': 'C', 'z0': 0.50, 'k': 400.0, 'N': 3000, 'interval': (0.40, 0.60)},\n        {'id': 'D', 'z0': 0.20, 'k': 800.0, 'N': 2000, 'b': 0.001}\n    ]\n\n    def prob_to_counts(probs, total_counts):\n        \"\"\"Converts a probability distribution to integer counts deterministically.\"\"\"\n        if not np.isclose(np.sum(probs), 1.0):\n             probs = probs / np.sum(probs)\n        \n        counts_float = total_counts * probs\n        counts_int = np.floor(counts_float).astype(int)\n        \n        remainder = total_counts - np.sum(counts_int)\n        \n        if remainder > 0:\n            fractional_parts = counts_float - counts_int\n            # Distribute remaining counts to bins with the largest fractional parts\n            indices_to_increment = np.argsort(fractional_parts)[-remainder:]\n            counts_int[indices_to_increment] += 1\n            \n        return counts_int\n\n    def kld(p, q):\n        \"\"\"Calculates Kullback-Leibler divergence D_KL(P || Q).\"\"\"\n        # Note: regularization outside this function handles p=0 or q=0 cases.\n        return np.sum(p * np.log(p / q))\n\n    def jsd(p, q):\n        \"\"\"Calculates Jensen-Shannon divergence D_JS(P, Q).\"\"\"\n        m = 0.5 * (p + q)\n        return 0.5 * kld(p, m) + 0.5 * kld(q, m)\n\n    all_results = {'kld_q_p': [], 'kld_p_q': [], 'jsd': []}\n\n    for case in test_cases:\n        # 3. Prediction of Biased Distributions (P_i)\n        z0, k = case['z0'], case['k']\n        U_bias = 0.5 * k * (z - z0)**2\n        p_pred_raw = p_unbiased * np.exp(-beta * U_bias)\n        p_pred = p_pred_raw / np.sum(p_pred_raw)\n\n        # 4. Generation of Observed Histograms (Q_i)\n        N = case['N']\n        q_prob_unnormalized = None\n        \n        if case['id'] == 'A':\n            q_prob_unnormalized = p_pred\n        elif case['id'] == 'B':\n            skew_factor = np.exp(case['lambda'] * (z - 0.6))\n            q_prob_unnormalized = p_pred * skew_factor\n        elif case['id'] == 'C':\n            q_prob_unnormalized = np.zeros_like(p_pred)\n            interval = case['interval']\n            mask = (z >= interval[0])  (z = interval[1])\n            q_prob_unnormalized[mask] = p_pred[mask]\n        elif case['id'] == 'D':\n            q_prob_unnormalized = p_pred + case['b']\n\n        # Normalize to get the 'true' observed probability\n        q_prob = q_prob_unnormalized / np.sum(q_prob_unnormalized)\n\n        # Convert to counts and back to PMF\n        counts_obs = prob_to_counts(q_prob, N)\n        q_obs = counts_obs / N\n\n        # 5. Regularization and Divergence Computation\n        p_reg = np.maximum(p_pred, epsilon)\n        p_reg /= np.sum(p_reg)\n        \n        q_reg = np.maximum(q_obs, epsilon)\n        q_reg /= np.sum(q_reg)\n        \n        d_kl_q_p = kld(q_reg, p_reg)\n        d_kl_p_q = kld(p_reg, q_reg)\n        d_js = jsd(p_reg, q_reg)\n        \n        all_results['kld_q_p'].append(d_kl_q_p)\n        all_results['kld_p_q'].append(d_kl_p_q)\n        all_results['jsd'].append(d_js)\n\n    final_output_list = all_results['kld_q_p'] + all_results['kld_p_q'] + all_results['jsd']\n    print(f\"[{','.join(map(str, final_output_list))}]\")\n\nsolve()\n```"
        }
    ]
}