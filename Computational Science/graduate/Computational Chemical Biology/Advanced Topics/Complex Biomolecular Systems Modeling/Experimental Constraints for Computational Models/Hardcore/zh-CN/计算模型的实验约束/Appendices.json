{
    "hands_on_practices": [
        {
            "introduction": "在将实验数据用于约束计算模型之前，至关重要的是要验证数据本身是否自洽并遵循基本的物理定律。本练习 () 演示了如何利用热力学循环和赫斯定律（Hess's Law），来评估不同来源的结合自由能测量值之间的一致性。通过这种方法，我们不仅可以检验数据的可靠性，还能在存在冗余测量的情况下，推断出缺失的热力学参数。",
            "id": "3845656",
            "problem": "一种蛋白质 $P$ 在标准态 ($1\\,\\mathrm{M}$) 条件下，于 $T=298.15\\,\\mathrm{K}$ 时，依次结合两种配体 $L_{1}$ 和 $L_{2}$，形成复合物 $PL_{1}$、$PL_{2}$ 和 $PL_{1}L_{2}$。通过等温滴定量热法 (ITC) 和表面等离子体共振 (SPR) 测得的标准结合吉布斯自由能及其估计的标准不确定度（一个标准差）已给出，另外一个三组分量热实验提供了从 $P+L_{1}+L_{2}$ 直接形成 $PL_{1}L_{2}$ 的总标准自由能。测量结果如下：\n- $P + L_{1} \\rightarrow PL_{1}$：$\\Delta G_{A\\to B} = -35.4\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AB} = 0.7\\,\\mathrm{kJ\\, mol^{-1}}$ (ITC)。\n- $PL_{1} + L_{2} \\rightarrow PL_{1}L_{2}$：$\\Delta G_{B\\to D} = -18.6\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{BD} = 0.9\\,\\mathrm{kJ\\, mol^{-1}}$ (ITC)。\n- $P + L_{2} \\rightarrow PL_{2}$：$\\Delta G_{A\\to C} = -14.2\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AC} = 0.5\\,\\mathrm{kJ\\, mol^{-1}}$ (SPR)。\n- $P + L_{1} + L_{2} \\rightarrow PL_{1}L_{2}$：$\\Delta G_{A\\to D} = -53.0\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AD} = 1.4\\,\\mathrm{kJ\\, mol^{-1}}$ (三组分量热法)。\n\n假设吉布斯自由能是状态函数，且赫斯定律 (Hess’s law) 适用于由这些状态形成的任何热力学循环。将报告的不确定度视为独立且呈高斯分布，并使用逆方差加权对结合网络的计算模型施加实验约束。\n\n首先，使用状态函数的性质来评估直接测量值 $\\Delta G_{A\\to D}$ 是否与两步路径 $A\\to B\\to D$ 在统计上一致。然后，使用赫斯定律闭合 $A\\to C\\to D$ 路径，在一个强制 $A\\to B\\to D$ 与 $A\\to D$ 匹配的加权最小二乘调整下，推断出与所有测量值最为一致的缺失标准吉布斯自由能 $\\Delta G_{C\\to D}$。以 $\\mathrm{kJ\\, mol^{-1}}$ 为单位表示最终推断的 $\\Delta G_{C\\to D}$，并将您的答案四舍五入到四位有效数字。",
            "solution": "该问题要求分析蛋白质-配体结合的热力学网络，并使用一组冗余、不确定的实验测量值来推断一个缺失的热力学量。分析将按要求分两部分进行：首先，评估所提供数据的统计一致性；其次，使用加权最小二乘调整法，计算未知的吉布斯自由能变 $\\Delta G_{C\\to D}$ 的最一致值。\n\n该结合方案描述了一个连接四个状态的热力学循环：\n- 状态 A：$P + L_{1} + L_{2}$\n- 状态 B：$PL_{1} + L_{2}$\n- 状态 C：$PL_{2} + L_{1}$\n- 状态 D：$PL_{1}L_{2}$\n\n提供的标准吉布斯自由能变($\\Delta G^\\circ$)及其标准不确定度($\\sigma$)如下：\n- $\\Delta G_{A\\to B} = -35.4\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AB} = 0.7\\,\\mathrm{kJ\\, mol^{-1}}$\n- $\\Delta G_{B\\to D} = -18.6\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{BD} = 0.9\\,\\mathrm{kJ\\, mol^{-1}}$\n- $\\Delta G_{A\\to C} = -14.2\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AC} = 0.5\\,\\mathrm{kJ\\, mol^{-1}}$\n- $\\Delta G_{A\\to D} = -53.0\\,\\mathrm{kJ\\, mol^{-1}}$，不确定度 $\\sigma_{AD} = 1.4\\,\\mathrm{kJ\\, mol^{-1}}$\n\n控制该系统的基本原理是赫斯定律，该定律指出，由于吉布斯自由能是状态函数，两个状态之间的总自由能变化与所取路径无关。这意味着对于任何闭合循环，自由能的净变化必须为零。对于方形循环 $A \\to B \\to D \\to C \\to A$，这意味着真实（无误差）值必须满足 $\\Delta G_{A\\to B} + \\Delta G_{B\\to D} + \\Delta G_{D\\to C} + \\Delta G_{C\\to A} = 0$。由于 $\\Delta G_{D\\to C} = -\\Delta G_{C\\to D}$ 和 $\\Delta G_{C\\to A} = -\\Delta G_{A\\to C}$，这等价于路径无关条件：\n$$ \\Delta G_{A\\to B} + \\Delta G_{B\\to D} = \\Delta G_{A\\to C} + \\Delta G_{C\\to D} $$\n该方程还意味着从状态 A 到状态 D 的总自由能变 $\\Delta G_{A\\to D}$ 必须与路径无关：\n$$ \\Delta G_{A\\to D} = \\Delta G_{A\\to B} + \\Delta G_{B\\to D} $$\n$$ \\Delta G_{A\\to D} = \\Delta G_{A\\to C} + \\Delta G_{C\\to D} $$\n我们的实验数据提供了多种独立的路径来确定同一个量，这种情况被称为超定。\n\n首先，我们评估 $\\Delta G_{A\\to D}$ 的直接测量值与从两步路径 $A \\to B \\to D$ 导出的值之间的统计一致性。\n间接路径的自由能变是各步骤之和：\n$$ \\Delta G_{A\\to B\\to D} = \\Delta G_{A\\to B} + \\Delta G_{B\\to D} = -35.4\\,\\mathrm{kJ\\, mol^{-1}} + (-18.6\\,\\mathrm{kJ\\, mol^{-1}}) = -54.0\\,\\mathrm{kJ\\, mol^{-1}} $$\n由于测量是独立的，不确定度以平方和的形式相加（即方差相加）。间接路径的方差为：\n$$ \\sigma_{A\\to B\\to D}^2 = \\sigma_{AB}^2 + \\sigma_{BD}^2 = (0.7\\,\\mathrm{kJ\\, mol^{-1}})^2 + (0.9\\,\\mathrm{kJ\\, mol^{-1}})^2 = 0.49\\,\\mathrm{kJ^2\\, mol^{-2}} + 0.81\\,\\mathrm{kJ^2\\, mol^{-2}} = 1.30\\,\\mathrm{kJ^2\\, mol^{-2}} $$\n我们将此结果 $\\Delta G_{A\\to B\\to D} = -54.0\\,\\mathrm{kJ\\, mol^{-1}}$ 与直接测量值 $\\Delta G_{A\\to D} = -53.0\\,\\mathrm{kJ\\, mol^{-1}}$ 进行比较。差值 $\\delta$ 为：\n$$ \\delta = \\Delta G_{A\\to B\\to D} - \\Delta G_{A\\to D} = -54.0\\,\\mathrm{kJ\\, mol^{-1}} - (-53.0\\,\\mathrm{kJ\\, mol^{-1}}) = -1.0\\,\\mathrm{kJ\\, mol^{-1}} $$\n这个差值的方差是这两个量的方差之和，因为它们来自独立的实验组：\n$$ \\sigma_{\\delta}^2 = \\sigma_{A\\to B\\to D}^2 + \\sigma_{AD}^2 = 1.30\\,\\mathrm{kJ^2\\, mol^{-2}} + (1.4\\,\\mathrm{kJ\\, mol^{-1}})^2 = 1.30\\,\\mathrm{kJ^2\\, mol^{-2}} + 1.96\\,\\mathrm{kJ^2\\, mol^{-2}} = 3.26\\,\\mathrm{kJ^2\\, mol^{-2}} $$\n差值的标准差为 $\\sigma_{\\delta} = \\sqrt{3.26}\\,\\mathrm{kJ\\, mol^{-1}} \\approx 1.806\\,\\mathrm{kJ\\, mol^{-1}}$。\n为了评估统计一致性，我们计算 z-score，它以其标准差为单位来衡量差异：\n$$ z = \\frac{|\\delta|}{\\sigma_{\\delta}} = \\frac{|-1.0\\,\\mathrm{kJ\\, mol^{-1}}|}{1.806\\,\\mathrm{kJ\\, mol^{-1}}} \\approx 0.55 $$\n由于 $z \\ll 2$，$\\Delta G_{A\\to D}$ 的直接和间接测量值之间的差异在统计上不显著。这些测量值在其报告的不确定度范围内相互一致。\n\n接下来，我们推断与所有测量值最一致的 $\\Delta G_{C\\to D}$ 值。这需要结合冗余信息以获得 $\\Delta G_{A\\to D}$ 的单一最佳估计值，我们将其表示为 $\\Delta G_{A\\to D}^*$。这就是“强制 $A\\to B\\to D$ 与 $A\\to D$ 匹配的加权最小二乘调整”。对于独立的高斯不确定度，最优组合是逆方差加权平均，也就是最大似然估计量。\n\n我们对 $\\Delta G_{A\\to D}$ 有两个独立的估计：\n1. 来自路径 $A \\to B \\to D$：$x_1 = \\Delta G_{A\\to B\\to D} = -54.0\\,\\mathrm{kJ\\, mol^{-1}}$，方差 $v_1 = \\sigma_{A\\to B\\to D}^2 = 1.30\\,\\mathrm{kJ^2\\, mol^{-2}}$。\n2. 来自直接测量：$x_2 = \\Delta G_{A\\to D} = -53.0\\,\\mathrm{kJ\\, mol^{-1}}$，方差 $v_2 = \\sigma_{AD}^2 = 1.96\\,\\mathrm{kJ^2\\, mol^{-2}}$。\n\n逆方差加权平均由下式给出：\n$$ \\Delta G_{A\\to D}^* = \\frac{\\frac{x_1}{v_1} + \\frac{x_2}{v_2}}{\\frac{1}{v_1} + \\frac{1}{v_2}} $$\n代入数值：\n$$ \\Delta G_{A\\to D}^* = \\frac{\\frac{-54.0}{1.30} + \\frac{-53.0}{1.96}}{\\frac{1}{1.30} + \\frac{1}{1.96}} = \\frac{-41.53846 - 27.04082}{0.76923 + 0.51020}\\,\\mathrm{kJ\\, mol^{-1}} = \\frac{-68.57928}{1.27943}\\,\\mathrm{kJ\\, mol^{-1}} \\approx -53.6014\\,\\mathrm{kJ\\, mol^{-1}} $$\n这个经过协调的值 $\\Delta G_{A\\to D}^*$ 代表了在给定所有相关测量值的情况下，整个 $A \\to D$ 过程最可能的真实自由能变。\n\n最后，我们使用这个协调值和赫斯定律对另一条路径 $A \\to C \\to D$ 进行计算，以推断 $\\Delta G_{C\\to D}$ 的值。其支配的热力学关系是：\n$$ \\Delta G_{A\\to D}^* = \\Delta G_{A\\to C} + \\Delta G_{C\\to D} $$\n我们求解 $\\Delta G_{C\\to D}$，使用我们对 $\\Delta G_{A\\to D}^*$ 的最佳估计以及 $\\Delta G_{A\\to C}$ 的实验测量值，因为这是该循环分支唯一可用的信息。\n$$ \\Delta G_{C\\to D, \\text{inf}} = \\Delta G_{A\\to D}^* - \\Delta G_{A\\to C} $$\n$$ \\Delta G_{C\\to D, \\text{inf}} = -53.6014\\,\\mathrm{kJ\\, mol^{-1}} - (-14.2\\,\\mathrm{kJ\\, mol^{-1}}) = -39.4014\\,\\mathrm{kJ\\, mol^{-1}} $$\n问题要求答案四舍五入到四位有效数字。\n$$ \\Delta G_{C\\to D, \\text{inf}} \\approx -39.40\\,\\mathrm{kJ\\, mol^{-1}} $$\n该值是反应 $PL_{2} + L_{1} \\to PL_{1}L_{2}$ 的吉布斯自由能变，它在有效热力学循环的假设下与整套提供的实验数据最一致。",
            "answer": "$$ \\boxed{-39.40} $$"
        },
        {
            "introduction": "当模型构建完成并根据实验数据确定其参数后，下一个关键步骤是客观地评估模型在多大程度上真实地描述了数据。卡方（$\\chi^2$）检验是实现此目的的标准统计工具，它通过比较模型预测值与实验观测值之间的偏差和测量不确定性来量化拟合优度。本练习 () 提供了一个通过编程实现$\\chi^2$拟合优度检验的动手实践，以评估模型预测与实验观测之间的一致性。",
            "id": "3845717",
            "problem": "给定一个固定的计算化学生物学模型，该模型可预测可测量的量。您会收到多个该模型的独立实验约束数据集。每个数据集包含观测值、模型预测值和估计的测量不确定度。假设每个测量误差都是独立的，并服从正态分布，且部分数据集已使用其数据调整了模型参数的子集。在这些假设下，标准化残差服从标准正态分布，其平方和服从卡方分布。您的任务是实现一个完整的程序，该程序计算每个数据集的残差、卡方检验统计量和拟合优度判定，并将这些结果聚合，得出跨数据集的全局拟合优度。\n\n使用以下基本原理：\n- 在独立测量误差被建模为具有已知标准差的正态分布的情况下，如果模型预测了潜在的均值，那么标准化残差 $$r_i = \\frac{y_i - m_i}{\\sigma_i}$$ 近似为来自标准正态分布的独立抽样。\n- 根据中心极限定理（CLT）和正态分布的性质，和 $$X^2 = \\sum_{i=1}^{n} r_i^2$$ 服从卡方分布，其自由度（DoF）为 $$\\nu = n - k,$$，其中 $$n$$ 是数据集中独立测量的数量，$$k$$ 是使用该数据集有效拟合的模型参数数量。\n- 对于一个卡方随机变量 $$X^2 \\sim \\chi^2_{\\nu}$$，其尾部概率（拟合优度p值）等于 $$p = 1 - F_{\\chi^2_{\\nu}}(X^2),$$，其中 $$F_{\\chi^2_{\\nu}}$$ 表示卡方分布的累积分布函数（CDF）。\n\n程序要求：\n- 对于每个数据集，计算残差向量 $$\\mathbf{r} = \\left[\\frac{y_1 - m_1}{\\sigma_1}, \\ldots, \\frac{y_n - m_n}{\\sigma_n}\\right],$$ 卡方统计量 $$X^2 = \\sum_{i=1}^{n} r_i^2,$$ 自由度 $$\\nu = n - k,$$ p值 $$p = 1 - F_{\\chi^2_{\\nu}}(X^2),$$ 以及在显著性水平 $$\\alpha$$ 下的检验判定，定义为 $$\\text{pass} = (p \\ge \\alpha).$$\n- 独立地对所有数据集进行聚合，通过对卡方统计量和自由度求和来计算全局拟合优度：$$X^2_{\\text{global}} = \\sum_{d} X^2_d,$$ $$\\nu_{\\text{global}} = \\sum_{d} \\nu_d,$$ 以及 $$p_{\\text{global}} = 1 - F_{\\chi^2_{\\nu_{\\text{global}}}}(X^2_{\\text{global}}),$$，并判定 $$\\text{pass}_{\\text{global}} = (p_{\\text{global}} \\ge \\alpha).$$\n- 将所有浮点输出（残差、卡方统计量和p值）四舍五入到小数点后六位。\n\n嵌入在程序中的输入规范：\n- 没有外部输入。您的程序必须在内部定义以下测试用例集，每个用例包含多个数据集。测量单位是一致的，输出（残差、卡方统计量和p值）是无量纲的。数组按 $[y_1, \\ldots, y_n]$、$[m_1, \\ldots, m_n]$ 和 $[\\sigma_1, \\ldots, \\sigma_n]$ 的顺序给出，其中 $k$ 表示从自由度中减去的拟合参数数量。\n\n测试集：\n- 用例1（普遍一致性，同质不确定度，中等残差）：\n  - 显著性水平：$$\\alpha = 0.05.$$\n  - 数据集 A:\n    - 观测值：$$\\mathbf{y}_A = [1.0, 0.8, 1.2, 0.9, 1.1].$$\n    - 预测值：$$\\mathbf{m}_A = [1.0, 0.75, 1.15, 0.95, 1.05].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_A = [0.1, 0.1, 0.1, 0.1, 0.1].$$\n    - 拟合参数个数：$$k_A = 1.$$\n  - 数据集 B:\n    - 观测值：$$\\mathbf{y}_B = [2.0, 1.8, 2.1, 1.9].$$\n    - 预测值：$$\\mathbf{m}_B = [2.05, 1.85, 2.05, 1.95].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_B = [0.1, 0.1, 0.1, 0.1].$$\n    - 拟合参数个数：$$k_B = 1.$$\n- 用例2（异方差不确定度和混合残差大小）：\n  - 显著性水平：$$\\alpha = 0.05.$$\n  - 数据集 C:\n    - 观测值：$$\\mathbf{y}_C = [5.0, 5.3, 4.8, 5.2].$$\n    - 预测值：$$\\mathbf{m}_C = [5.1, 5.2, 5.0, 5.1].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_C = [0.2, 0.3, 0.2, 0.4].$$\n    - 拟合参数个数：$$k_C = 2.$$\n  - 数据集 D:\n    - 观测值：$$\\mathbf{y}_D = [3.0, 3.2, 2.9].$$\n    - 预测值：$$\\mathbf{m}_D = [3.1, 3.0, 3.0].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_D = [0.2, 0.2, 0.1].$$\n    - 拟合参数个数：$$k_D = 1.$$\n- 用例3（强不一致性，小不确定度导致大残差）：\n  - 显著性水平：$$\\alpha = 0.05.$$\n  - 数据集 E:\n    - 观测值：$$\\mathbf{y}_E = [0.9, 1.1, 0.95, 1.05, 1.0].$$\n    - 预测值：$$\\mathbf{m}_E = [1.2, 1.2, 1.2, 1.2, 1.2].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_E = [0.05, 0.05, 0.05, 0.05, 0.05].$$\n    - 拟合参数个数：$$k_E = 0.$$\n  - 数据集 F:\n    - 观测值：$$\\mathbf{y}_F = [10.0, 9.5, 10.5, 9.8].$$\n    - 预测值：$$\\mathbf{m}_F = [10.0, 10.0, 10.0, 10.0].$$\n    - 不确定度：$$\\boldsymbol{\\sigma}_F = [0.2, 0.2, 0.2, 0.2].$$\n    - 拟合参数个数：$$k_F = 0.$$\n\n输出规范：\n- 对于每个用例，输出一个列表，其中包含每个数据集的一个条目和一个最终的全局条目。每个数据集条目必须是一个列表 $$[\\mathbf{r}, X^2, p, \\text{pass}]$$，其中 $$\\mathbf{r}$$ 是四舍五入到六位小数的残差向量，$$X^2$$ 是四舍五入到六位小数的卡方统计量，$$p$$ 是四舍五入到六位小数的p值，$$\\text{pass}$$ 是一个布尔值。最终的全局条目必须是一个列表 $$[X^2_{\\text{global}}, p_{\\text{global}}, \\text{pass}_{\\text{global}}]$$，其中的浮点值同样进行四舍五入。\n- 您的程序应生成单行输出，其中包含所有用例的结果，形式为用方括号括起来的逗号分隔列表，且不含任何空格。也就是说，顶层输出的形式为 $$[\\text{case}_1,\\text{case}_2,\\text{case}_3]$$，其中每个 $$\\text{case}_i$$ 本身都是一个按上述规定构建的列表。",
            "solution": "出发点是一个具有固定参数化的计算化学生物学系统的实验约束概率模型。令 $$y_i$$ 表示观测到的测量值，$$m_i$$ 表示相同实验条件下模型预测的均值，$$\\sigma_i$$ 表示已知的或估计的测量误差标准差。我们假设误差是独立的、服从正态分布的，因此 $$y_i = m_i + \\varepsilon_i$$，其中 $$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$$，且不同测量和数据集之间的误差是独立的。当测量方案独立且重复实验的变异性被很好地表征时，这一假设是合理的，这在计算化学生物学中整合正交分析法时是一种常见情况。\n\n在此模型下，每个标准化残差 $$r_i = \\frac{y_i - m_i}{\\sigma_i}$$ 服从标准正态分布 $$\\mathcal{N}(0,1)$$，并且由于独立性，向量 $$\\mathbf{r}$$ 由独立的标准正态分布条目组成。一个核心的统计学事实是，独立标准正态变量的平方和服从卡方分布。具体来说，统计量\n$$\nX^2 = \\sum_{i=1}^{n} r_i^2\n$$\n服从自由度为 $$\\nu = n - k$$ 的卡方分布，其中 $$n$$ 是数据集中的测量次数，$$k$$ 是用于调整该数据集预测的有效拟合模型参数的数量。减去 $$k$$ 是为了解释因参数估计而导致的自由度损失，这是拟合优度检验中的一个标准修正。\n\n为评估拟合优度，我们计算p值，即卡方分布的上尾概率：\n$$\np = \\mathbb{P}\\left(\\chi^2_{\\nu} \\ge X^2\\right) = 1 - F_{\\chi^2_{\\nu}}(X^2),\n$$\n其中 $$F_{\\chi^2_{\\nu}}$$ 是自由度为 $$\\nu$$ 的卡方分布的累积分布函数（CDF）。给定一个显著性水平 $$\\alpha$$，检验判定为\n$$\n\\text{pass} =\n\\begin{cases}\n\\text{True},  \\text{如果 } p \\ge \\alpha, \\\\\n\\text{False},  \\text{如果 } p  \\alpha.\n\\end{cases}\n$$\n\n当组合实验上独立的数据集时，全局拟合优度统计量是个体卡方统计量之和，全局自由度是个体自由度之和：\n$$\nX^2_{\\text{global}} = \\sum_{d} X^2_d, \\quad \\nu_{\\text{global}} = \\sum_{d} \\nu_d.\n$$\n根据由独立标准正态变量平方和导出的卡方变量的可加性，在模型假设下，$$X^2_{\\text{global}} \\sim \\chi^2_{\\nu_{\\text{global}}}$$。因此，\n$$\np_{\\text{global}} = 1 - F_{\\chi^2_{\\nu_{\\text{global}}}}(X^2_{\\text{global}})\n$$\n判定规则相同，即 $$\\text{pass}_{\\text{global}} = (p_{\\text{global}} \\ge \\alpha)$$。\n\n算法设计：\n1. 对于每个数据集，读取 $$\\mathbf{y}, \\mathbf{m}, \\boldsymbol{\\sigma}, k$$ 和 $$\\alpha$$。计算残差向量为 $$\\mathbf{r} = (\\mathbf{y} - \\mathbf{m}) \\oslash \\boldsymbol{\\sigma}$$，其中 $$\\oslash$$ 表示逐元素除法。\n2. 计算 $$X^2 = \\sum r_i^2$$ 和 $$\\nu = n - k$$。检查 $$\\nu > 0$$ 以确保卡方拟合优度检验的有效性。\n3. 使用可靠的卡方生存函数数值程序计算p值 $$p = 1 - F_{\\chi^2_{\\nu}}(X^2)$$，该函数直接计算上尾概率以保持数值稳定性。\n4. 将 $$p$$ 与 $$\\alpha$$ 比较，并相应地设置 $$\\text{pass}$$。\n5. 通过对 $$X^2$$ 和 $$\\nu$$ 求和来聚合各数据集，得到 $$X^2_{\\text{global}}$$ 和 $$\\nu_{\\text{global}}$$，然后计算 $$p_{\\text{global}}$$ 和 $$\\text{pass}_{\\text{global}}$$。\n6. 按照要求将所有浮点输出四舍五入到六位小数，并根据规范构建输出结构。\n\n在测试集上的应用：\n- 用例1使用同质不确定度 $$\\boldsymbol{\\sigma}_A = [0.1, 0.1, 0.1, 0.1, 0.1]$$ 和 $$\\boldsymbol{\\sigma}_B = [0.1, 0.1, 0.1, 0.1]$$，残差中等，拟合参数为 $$k_A = 1$$, $$k_B = 1$$。计算出的 $$X^2$$ 值相对于它们各自的 $$\\nu$$ 较小，从而产生大的p值，并通过了 $$\\alpha = 0.05$$ 的检验。\n- 用例2展示了异方差不确定度和混合残差，其中 $$k_C = 2$$, $$k_D = 1$$。每个数据集的 $$X^2$$ 值为中等，聚合的全局 $$X^2_{\\text{global}}$$ 和 $$\\nu_{\\text{global}}$$ 产生一个不小的p值，通过了 $$\\alpha = 0.05$$ 的检验。\n- 用例3具有小的不确定度和大的差异，导致两个数据集的 $$X^2$$ 都很大，全局p值非常小；检验在 $$\\alpha = 0.05$$ 水平下失败。\n\n该程序实现了这些步骤，并打印包含所有用例结果列表的单行输出。每个数据集条目的形式为 $$[\\mathbf{r}, X^2, p, \\text{pass}]$$，每个全局条目的形式为 $$[X^2_{\\text{global}}, p_{\\text{global}}, \\text{pass}_{\\text{global}}]$$，所有数值都四舍五入到六位小数。顶层列表按顺序包含三个用例，格式为用逗号和括号分隔且不含空格，以便于自动解析和验证。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef compute_dataset_metrics(y, m, s, k, alpha):\n    \"\"\"\n    Compute residuals, chi-square statistic, p-value, and pass/fail for one dataset.\n    y, m, s are numpy arrays of equal length; k is integer; alpha is float.\n    \"\"\"\n    # Standardized residuals\n    residuals = (y - m) / s\n    # Chi-square statistic\n    chi_sq = float(np.sum(residuals ** 2))\n    # Degrees of freedom\n    nu = int(len(y) - k)\n    if nu = 0:\n        raise ValueError(\"Degrees of freedom must be positive (n - k > 0).\")\n    # p-value (upper-tail probability)\n    p_value = float(chi2.sf(chi_sq, df=nu))\n    # Decision\n    passed = bool(p_value >= alpha)\n    return residuals, chi_sq, p_value, passed, nu\n\ndef round_float(x, ndigits=6):\n    return float(np.round(x, ndigits))\n\ndef round_list(lst, ndigits=6):\n    return [round_float(float(v), ndigits) for v in lst]\n\ndef format_element_no_space(el):\n    \"\"\"\n    Recursively format nested lists and primitive types into a string\n    without spaces, rounding floats to six decimals.\n    \"\"\"\n    if isinstance(el, list):\n        return \"[\" + \",\".join(format_element_no_space(x) for x in el) + \"]\"\n    elif isinstance(el, (float, np.floating)):\n        return f\"{float(el):.6f}\"\n    elif isinstance(el, (int, np.integer)):\n        return str(int(el))\n    elif isinstance(el, bool):\n        return \"True\" if el else \"False\"\n    else:\n        # Attempt to handle numpy arrays by converting to list\n        if isinstance(el, np.ndarray):\n            return format_element_no_space(el.tolist())\n        # Fallback: convert to string (should not occur in this problem)\n        return str(el)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"alpha\": 0.05,\n            \"datasets\": [\n                {\n                    \"y\": np.array([1.0, 0.8, 1.2, 0.9, 1.1]),\n                    \"m\": np.array([1.0, 0.75, 1.15, 0.95, 1.05]),\n                    \"s\": np.array([0.1, 0.1, 0.1, 0.1, 0.1]),\n                    \"k\": 1,\n                },\n                {\n                    \"y\": np.array([2.0, 1.8, 2.1, 1.9]),\n                    \"m\": np.array([2.05, 1.85, 2.05, 1.95]),\n                    \"s\": np.array([0.1, 0.1, 0.1, 0.1]),\n                    \"k\": 1,\n                },\n            ],\n        },\n        # Case 2\n        {\n            \"alpha\": 0.05,\n            \"datasets\": [\n                {\n                    \"y\": np.array([5.0, 5.3, 4.8, 5.2]),\n                    \"m\": np.array([5.1, 5.2, 5.0, 5.1]),\n                    \"s\": np.array([0.2, 0.3, 0.2, 0.4]),\n                    \"k\": 2,\n                },\n                {\n                    \"y\": np.array([3.0, 3.2, 2.9]),\n                    \"m\": np.array([3.1, 3.0, 3.0]),\n                    \"s\": np.array([0.2, 0.2, 0.1]),\n                    \"k\": 1,\n                },\n            ],\n        },\n        # Case 3\n        {\n            \"alpha\": 0.05,\n            \"datasets\": [\n                {\n                    \"y\": np.array([0.9, 1.1, 0.95, 1.05, 1.0]),\n                    \"m\": np.array([1.2, 1.2, 1.2, 1.2, 1.2]),\n                    \"s\": np.array([0.05, 0.05, 0.05, 0.05, 0.05]),\n                    \"k\": 0,\n                },\n                {\n                    \"y\": np.array([10.0, 9.5, 10.5, 9.8]),\n                    \"m\": np.array([10.0, 10.0, 10.0, 10.0]),\n                    \"s\": np.array([0.2, 0.2, 0.2, 0.2]),\n                    \"k\": 0,\n                },\n            ],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha = case[\"alpha\"]\n        case_results = []\n        chi_sq_global = 0.0\n        nu_global = 0\n        for ds in case[\"datasets\"]:\n            y = ds[\"y\"]\n            m = ds[\"m\"]\n            s = ds[\"s\"]\n            k = ds[\"k\"]\n            residuals, chi_sq, p_value, passed, nu = compute_dataset_metrics(y, m, s, k, alpha)\n            chi_sq_global += chi_sq\n            nu_global += nu\n            # Round values\n            residuals_rounded = round_list(residuals.tolist(), ndigits=6)\n            chi_sq_rounded = round_float(chi_sq, ndigits=6)\n            p_value_rounded = round_float(p_value, ndigits=6)\n            case_results.append([residuals_rounded, chi_sq_rounded, p_value_rounded, passed])\n        # Global aggregation\n        p_global = float(chi2.sf(chi_sq_global, df=nu_global))\n        pass_global = bool(p_global >= alpha)\n        chi_sq_global_rounded = round_float(chi_sq_global, ndigits=6)\n        p_global_rounded = round_float(p_global, ndigits=6)\n        case_results.append([chi_sq_global_rounded, p_global_rounded, pass_global])\n        results.append(case_results)\n\n    # Final print statement in the exact required format: no spaces anywhere.\n    print(format_element_no_space(results))\n\nsolve()\n```"
        },
        {
            "introduction": "计算模型的作用远不止于解释现有数据，它们还可以主动地指导未来的研究方向。通过灵敏度分析，我们可以识别出哪些潜在的实验能够最有效地优化我们的模型参数，从而实现信息收益最大化。本练习 () 将引导你完成一个量化不同实验方案“效用”的过程，以便优先选择那些能最有效降低关键参数不确定性的实验。",
            "id": "3845672",
            "problem": "您正在为一个平衡受体-配体结合实验进行建模，该实验在计算化学生物学中常用于从实验数据中推断生物物理参数。该计算模型通过假设一个Hill型占有模型，来预测在给定游离配体浓度 $L$（单位为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$）下的信号 $y$（单位为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$）。预测信号由确定性映射 $f(\\boldsymbol{\\theta}; L)$ 给出，定义为 $y = \\alpha \\cdot \\phi(L; K_d, n)$，其中 $\\boldsymbol{\\theta} = (K_d, n, \\alpha)$，$K_d$ 是解离常数（单位为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$），$n$ 是Hill系数（无量纲），$\\alpha$ 是一个比例常数（单位为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$）。分数占有率 $\\phi$ 为\n$$\n\\phi(L; K_d, n) = \\frac{\\left(\\dfrac{L}{K_d}\\right)^n}{1 + \\left(\\dfrac{L}{K_d}\\right)^n}.\n$$\n每个实验约束对应于在指定 $L$ 下的单次测量，产生一个带噪声的观测值 $y_i = f(\\boldsymbol{\\theta}; L_i) + \\varepsilon_i$，其中 $\\varepsilon_i$ 是零均值加性噪声，独立同分布，并被建模为具有已知标准差 $\\sigma_i$（单位为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$）的高斯噪声。您已获得关于 $\\boldsymbol{\\theta}$ 的先验高斯不确定性，由一个对称正定协方差矩阵 $\\boldsymbol{\\Sigma}_0$ 指定。\n\n从灵敏度和贝叶斯线性化高斯推断的定义出发，对每个候选约束执行以下操作：\n- 计算灵敏度系数，即模型预测相对于参数在标称 $\\boldsymbol{\\theta}$ 处的梯度，\n$$\n\\mathbf{S}_i = \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}; L_i) \\in \\mathbb{R}^3,\n$$\n这与可微模型下参数估计中灵敏度的定义一致。\n- 将单次测量约束视为对先验的增量信息更新，在线性化高斯近似下评估 $\\boldsymbol{\\theta}$ 的期望后验协方差，并提取由集合 $\\mathcal{C}$ 索引的指定关键参数子集的期望后验方差。\n- 将一个约束的效用定义为关键参数方差总和的期望分数减少量，除以给定的实验成本 $c_i$（无量纲），\n$$\nU_i = \\frac{\\left(\\sum_{j \\in \\mathcal{C}} \\operatorname{Var}_\\text{prior}[\\theta_j] - \\sum_{j \\in \\mathcal{C}} \\operatorname{Var}_\\text{post}^{(i)}[\\theta_j]\\right)}{\\sum_{j \\in \\mathcal{C}} \\operatorname{Var}_\\text{prior}[\\theta_j]} \\cdot \\frac{1}{c_i}.\n$$\n- 按 $U_i$ 的降序对约束进行优先级排序（排名）。若出现平局，则按约束索引的升序排序。\n\n您的推导和算法应仅基于基本原理：\n- 使用灵敏度的定义，即模型输出相对于参数的偏导数。\n- 在 $\\boldsymbol{\\theta}$ 处进行线性化，对高斯先验和高斯似然使用贝叶斯推断，其中添加单个线性约束会对参数精度矩阵产生一个秩一更新，反映了来自 $\\mathbf{S}_i$ 和 $\\sigma_i$ 的费雪信息贡献。\n\n您的程序必须使用有限差分来数值逼近 $\\mathbf{S}_i$ 和用于后验协方差的线性高斯更新，从而实现上述过程。所有输入均在下文的固定测试用例中提供。不需要任何用户输入。使用以下测试套件。所有浓度和信号必须以 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$ 为单位处理；不涉及角度；输出是无单位的索引。\n\n测试用例1：\n- 标称参数 $\\boldsymbol{\\theta} = (K_d, n, \\alpha) = \\left(50\\times 10^{-9}, 2.0, 100\\times 10^{-9}\\right)$。\n- 先验协方差\n$$\n\\boldsymbol{\\Sigma}_0 = \\begin{bmatrix}\n2.25\\times 10^{-16}   0   3.0\\times 10^{-17}\\\\\n0   9.0\\times 10^{-2}   0\\\\\n3.0\\times 10^{-17}   0   4.0\\times 10^{-16}\n\\end{bmatrix}.\n$$\n- 约束 $(L_i, \\sigma_i, c_i)$:\n  - 索引 $0$: $\\left(10\\times 10^{-9}, 5\\times 10^{-9}, 1.0\\right)$\n  - 索引 $1$: $\\left(50\\times 10^{-9}, 5\\times 10^{-9}, 1.2\\right)$\n  - 索引 $2$: $\\left(200\\times 10^{-9}, 5\\times 10^{-9}, 1.0\\right)$\n  - 索引 $3$: $\\left(1000\\times 10^{-9}, 10\\times 10^{-9}, 2.0\\right)$\n- 关键索引集 $\\mathcal{C} = \\{0, 1\\}$。\n\n测试用例2：\n- 标称参数 $\\boldsymbol{\\theta} = \\left(100\\times 10^{-9}, 1.5, 50\\times 10^{-9}\\right)$。\n- 先验协方差\n$$\n\\boldsymbol{\\Sigma}_0 = \\operatorname{diag}\\left(1.6\\times 10^{-15}, 2.5\\times 10^{-1}, 1.0\\times 10^{-16}\\right).\n$$\n- 约束：\n  - 索引 $0$: $\\left(100\\times 10^{-9}, 50\\times 10^{-9}, 1.0\\right)$\n  - 索引 $1$: $\\left(10\\times 10^{-9}, 50\\times 10^{-9}, 1.0\\right)$\n  - 索引 $2$: $\\left(1000\\times 10^{-9}, 50\\times 10^{-9}, 1.0\\right)$\n- 关键索引集 $\\mathcal{C} = \\{0\\}$。\n\n测试用例3：\n- 标称参数 $\\boldsymbol{\\theta} = \\left(30\\times 10^{-9}, 3.0, 150\\times 10^{-9}\\right)$。\n- 先验协方差\n$$\n\\boldsymbol{\\Sigma}_0 = \\operatorname{diag}\\left(1.0\\times 10^{-16}, 3.6\\times 10^{-1}, 9.0\\times 10^{-16}\\right).\n$$\n- 约束：\n  - 索引 $0$: $\\left(5\\times 10^{-9}, 4\\times 10^{-9}, 1.0\\right)$\n  - 索引 $1$: $\\left(30\\times 10^{-9}, 4\\times 10^{-9}, 1.0\\right)$\n  - 索引 $2$: $\\left(300\\times 10^{-9}, 4\\times 10^{-9}, 1.0\\right)$\n- 关键索引集 $\\mathcal{C} = \\{1\\}$。\n\n测试用例4：\n- 标称参数 $\\boldsymbol{\\theta} = \\left(60\\times 10^{-9}, 1.0, 200\\times 10^{-9}\\right)$。\n- 先验协方差\n$$\n\\boldsymbol{\\Sigma}_0 = \\operatorname{diag}\\left(2.5\\times 10^{-17}, 1.0\\times 10^{-2}, 1.0\\times 10^{-14}\\right).\n$$\n- 约束：\n  - 索引 $0$: $\\left(1\\times 10^{-9}, 10\\times 10^{-9}, 0.5\\right)$\n  - 索引 $1$: $\\left(60\\times 10^{-9}, 10\\times 10^{-9}, 2.0\\right)$\n  - 索引 $2$: $\\left(1000\\times 10^{-9}, 10\\times 10^{-9}, 1.0\\right)$\n- 关键索引集 $\\mathcal{C} = \\{2\\}$。\n\n实现要求：\n- 使用围绕标称 $\\boldsymbol{\\theta}$ 的对称有限差分来近似 $\\mathbf{S}_i$。使用的扰动幅度应相对于参数尺度较小但能保持数值稳定性。\n- 对于每个单一约束，在线性化和高斯假设下计算期望后验协方差，然后为给定的 $\\mathcal{C}$ 计算 $U_i$。\n- 对于每个测试用例，生成按 $U_i$ 降序排列的约束索引列表（平局时按索引升序）。\n\n最终输出规范：\n- 您的程序应生成一行输出，其中包含一个逗号分隔的列表，用方括号括起来，每个条目是相应测试用例的已排序约束索引列表，例如 $\\left[\\left[\\cdots\\right],\\left[\\cdots\\right],\\left[\\cdots\\right]\\right]$。",
            "solution": "该问题的目标是为受体-配体结合实验的一组候选实验测量（称为约束）确定优先级。优先级排序基于最大化实验信息增益的原则，该原则通过一个效用函数进行量化。效用函数衡量模型参数一个关键子集不确定性的期望减少量，并根据实验成本进行归一化。该分析在贝叶斯推断的框架内进行，使用了物理模型的线性化近似。\n\n方法论推导过程如下，基于对统计推断和灵敏度分析基本原理的严格应用。\n\n系统由一个确定性模型 $f(\\boldsymbol{\\theta}; L)$ 描述，该模型预测一个可观测信号 $y$ 作为游离配体浓度 $L$ 和一个生物物理参数向量 $\\boldsymbol{\\theta} = (K_d, n, \\alpha)$ 的函数。这些参数分别代表解离常数、Hill系数和比例常数。该模型由以下公式给出：\n$$\ny = f(\\boldsymbol{\\theta}; L) = \\alpha \\cdot \\phi(L; K_d, n)\n$$\n其中 $\\phi$ 是Hill型分数占有率函数：\n$$\n\\phi(L; K_d, n) = \\frac{\\left(\\dfrac{L}{K_d}\\right)^n}{1 + \\left(\\dfrac{L}{K_d}\\right)^n}\n$$\n所有浓度（$y$、$L$、$K_d$、$\\alpha$）的单位均为 $\\mathrm{mol}\\cdot\\mathrm{L}^{-1}$，Hill系数 $n$ 是无量纲的。\n\n该问题被置于贝叶斯框架中。我们关于参数 $\\boldsymbol{\\theta}$ 的先验知识被编码在一个多元高斯概率分布中，其均值为 $\\boldsymbol{\\theta}_0$（标称参数值），协方差矩阵为 $\\boldsymbol{\\Sigma}_0$。我们将其记为 $\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\theta}_0, \\boldsymbol{\\Sigma}_0)$。每个实验约束 $i$ 包含在已知配体浓度 $L_i$ 下的单次测量 $y_i$。该测量是带噪声的，由模型 $y_i = f(\\boldsymbol{\\theta}; L_i) + \\varepsilon_i$ 描述，其中噪声 $\\varepsilon_i$ 被假定为一个独立的、零均值的高斯随机变量，其方差 $\\sigma_i^2$ 已知，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$。因此，给定参数 $\\boldsymbol{\\theta}$，观测到 $y_i$ 的似然为 $p(y_i|\\boldsymbol{\\theta}) \\sim \\mathcal{N}(f(\\boldsymbol{\\theta}; L_i), \\sigma_i^2)$。\n\n为了更新我们对 $\\boldsymbol{\\theta}$ 的信念，理想情况下我们会计算后验分布 $p(\\boldsymbol{\\theta}|y_i) \\propto p(y_i|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})$。然而，由于 $f(\\boldsymbol{\\theta}; L_i)$ 是 $\\boldsymbol{\\theta}$ 的非线性函数，后验分布不是高斯分布，并且难以解析计算。该问题指定使用线性化高斯近似。我们使用一阶泰勒展开将模型 $f(\\boldsymbol{\\theta}; L_i)$ 在标称参数向量 $\\boldsymbol{\\theta}_0$ 周围线性化：\n$$\nf(\\boldsymbol{\\theta}; L_i) \\approx f(\\boldsymbol{\\theta}_0; L_i) + \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}_0; L_i)^T (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_0)\n$$\n梯度向量 $\\mathbf{S}_i = \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}_0; L_i)$ 是一个 $3 \\times 1$ 的灵敏度系数列向量，它量化了模型输出随每个参数的无穷小变化而变化的程度。观测模型在 $\\boldsymbol{\\theta}$ 上近似变为线性：\n$$\ny_i - f(\\boldsymbol{\\theta}_0; L_i) \\approx \\mathbf{S}_i^T (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_0) + \\varepsilon_i\n$$\n在此近似下，$\\boldsymbol{\\theta}$ 的高斯先验和 $y_i$ 的高斯似然导致 $\\boldsymbol{\\theta}$ 的高斯后验。协方差矩阵的更新规则由精度矩阵（协方差矩阵的逆）的更新规则导出。后验精度矩阵 $\\mathbf{P}_\\text{post}^{(i)}$ 是先验精度矩阵 $\\mathbf{P}_0 = \\boldsymbol{\\Sigma}_0^{-1}$ 与从测量中获得的精度之和，后者等效于测量的费雪信息。对于单个线性化高斯测量，此信息是一个秩一矩阵：\n$$\n\\mathbf{P}_\\text{post}^{(i)} = \\mathbf{P}_0 + \\frac{1}{\\sigma_i^2} \\mathbf{S}_i \\mathbf{S}_i^T = \\boldsymbol{\\Sigma}_0^{-1} + \\frac{1}{\\sigma_i^2} \\mathbf{S}_i \\mathbf{S}_i^T\n$$\n期望后验协方差矩阵 $\\boldsymbol{\\Sigma}_\\text{post}^{(i)}$ 是后验精度矩阵的逆：$\\boldsymbol{\\Sigma}_\\text{post}^{(i)} = (\\mathbf{P}_\\text{post}^{(i)})^{-1}$。通过应用Sherman-Morrison恒等式可以避免直接求逆，从而得到数值上更稳定的卡尔曼滤波协方差更新形式：\n$$\n\\boldsymbol{\\Sigma}_\\text{post}^{(i)} = \\boldsymbol{\\Sigma}_0 - \\boldsymbol{\\Sigma}_0 \\mathbf{S}_i \\left( \\sigma_i^2 + \\mathbf{S}_i^T \\boldsymbol{\\Sigma}_0 \\mathbf{S}_i \\right)^{-1} \\mathbf{S}_i^T \\boldsymbol{\\Sigma}_0\n$$\n该公式计算了在整合了第 $i$ 次测量的信息后的后验协方差。项 $(\\sigma_i^2 + \\mathbf{S}_i^T \\boldsymbol{\\Sigma}_0 \\mathbf{S}_i)$ 是一个标量，使得计算非常高效。\n\n灵敏度向量 $\\mathbf{S}_i = \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}_0; L_i)$ 使用对称有限差分法进行数值近似。对于每个参数 $\\theta_j$（其中 $j \\in \\{0, 1, 2\\}$ 分别对应于 $K_d, n, \\alpha$），偏导数为：\n$$\nS_{i,j} = \\frac{\\partial f}{\\partial \\theta_j} \\bigg|_{\\boldsymbol{\\theta}_0, L_i} \\approx \\frac{f(\\boldsymbol{\\theta}_0 + h_j \\mathbf{e}_j; L_i) - f(\\boldsymbol{\\theta}_0 - h_j \\mathbf{e}_j; L_i)}{2h_j}\n$$\n其中 $\\mathbf{e}_j$ 是第 $j$ 个参数的标准基向量，$h_j$ 是一个小步长扰动，选择为标称参数值的一个小分数，例如 $h_j = \\epsilon_h |\\theta_{0,j}|$，以确保数值稳定性。\n\n每个约束 $i$ 的效用 $U_i$ 定义为由成本归一化的、由集合 $\\mathcal{C}$ 索引的关键参数集方差总和的期望分数减少量。参数 $\\theta_j$ 的方差是协方差矩阵的第 $j$ 个对角元素。效用计算如下：\n$$\nU_i = \\frac{\\Delta V_i}{V_\\text{prior}} \\cdot \\frac{1}{c_i}\n$$\n其中 $V_\\text{prior} = \\sum_{j \\in \\mathcal{C}} (\\boldsymbol{\\Sigma}_0)_{jj}$ 是关键参数的先验方差总和，而 $\\Delta V_i = V_\\text{prior} - V_\\text{post}^{(i)}$ 是该总和的减少量，其中 $V_\\text{post}^{(i)} = \\sum_{j \\in \\mathcal{C}} (\\boldsymbol{\\Sigma}_\\text{post}^{(i)})_{jj}$。\n\n对约束进行排序的算法流程如下：\n1. 对于每个测试用例，获取标称参数 $\\boldsymbol{\\theta}_0$、先验协方差 $\\boldsymbol{\\Sigma}_0$、关键索引集 $\\mathcal{C}$ 以及约束列表 $(L_i, \\sigma_i, c_i)$。\n2. 计算关键参数的先验方差总和，$V_\\text{prior} = \\sum_{j \\in \\mathcal{C}} (\\boldsymbol{\\Sigma}_0)_{jj}$。\n3. 对于每个约束 $i$：\n    a. 使用对称有限差分在 $(\\boldsymbol{\\theta}_0, L_i)$ 处计算灵敏度向量 $\\mathbf{S}_i$。\n    b. 使用卡尔曼更新公式计算期望后验协方差矩阵 $\\boldsymbol{\\Sigma}_\\text{post}^{(i)}$。\n    c. 计算关键参数的后验方差总和，$V_\\textpost^{(i)} = \\sum_{j \\in \\mathcal{C}} (\\boldsymbol{\\Sigma}_\\text{post}^{(i)})_{jj}$。\n    d. 计算效用 $U_i = \\frac{V_\\text{prior} - V_\\text{post}^{(i)}}{V_\\text{prior} \\cdot c_i}$。\n4. 存储所有约束的 $(U_i, i)$ 对。\n5. 按效用 $U_i$ 的降序对这些对进行排序。如果两个效用相等，则按其对应的索引 $i$ 的升序进行排序以打破平局。\n6. 提取已排序的索引，形成该测试用例的最终排名列表。\n7. 对所有测试用例重复此过程，并格式化最终输出。\n此过程提供了一个有原则的、定量的实验排名，以指导计算化学生物学中的数据采集。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the experiment prioritization problem for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"theta\": np.array([50e-9, 2.0, 100e-9]),\n            \"Sigma0\": np.array([\n                [2.25e-16, 0.0, 3.0e-17],\n                [0.0, 9.0e-2, 0.0],\n                [3.0e-17, 0.0, 4.0e-16]\n            ]),\n            \"constraints\": [\n                (10e-9, 5e-9, 1.0),\n                (50e-9, 5e-9, 1.2),\n                (200e-9, 5e-9, 1.0),\n                (1000e-9, 10e-9, 2.0)\n            ],\n            \"critical_indices\": {0, 1}\n        },\n        {\n            \"theta\": np.array([100e-9, 1.5, 50e-9]),\n            \"Sigma0\": np.diag([1.6e-15, 2.5e-1, 1.0e-16]),\n            \"constraints\": [\n                (100e-9, 50e-9, 1.0),\n                (10e-9, 50e-9, 1.0),\n                (1000e-9, 50e-9, 1.0)\n            ],\n            \"critical_indices\": {0}\n        },\n        {\n            \"theta\": np.array([30e-9, 3.0, 150e-9]),\n            \"Sigma0\": np.diag([1.0e-16, 3.6e-1, 9.0e-16]),\n            \"constraints\": [\n                (5e-9, 4e-9, 1.0),\n                (30e-9, 4e-9, 1.0),\n                (300e-9, 4e-9, 1.0)\n            ],\n            \"critical_indices\": {1}\n        },\n        {\n            \"theta\": np.array([60e-9, 1.0, 200e-9]),\n            \"Sigma0\": np.diag([2.5e-17, 1.0e-2, 1.0e-14]),\n            \"constraints\": [\n                (1e-9, 10e-9, 0.5),\n                (60e-9, 10e-9, 2.0),\n                (1000e-9, 10e-9, 1.0)\n            ],\n            \"critical_indices\": {2}\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        theta0 = case[\"theta\"]\n        Sigma0 = case[\"Sigma0\"]\n        constraints = case[\"constraints\"]\n        critical_indices = case[\"critical_indices\"]\n\n        utilities = []\n\n        # Prior variance of critical parameters\n        var_prior_sum = 0.0\n        for j in critical_indices:\n            var_prior_sum += Sigma0[j, j]\n        \n        # Guard against zero prior variance, which implies no uncertainty to reduce.\n        if var_prior_sum == 0.0:\n            # If there's no prior variance, no experiment can reduce it. All utilities are 0.\n            # Rank by index as per tie-breaking rule.\n            ranked_indices = sorted(range(len(constraints)))\n            all_results.append(ranked_indices)\n            continue\n\n        for i, (L, sigma, c) in enumerate(constraints):\n            # 1. Compute sensitivity vector S_i using symmetric finite differences\n            S_i = compute_sensitivity(theta0, L)\n\n            # 2. Compute posterior covariance Sigma_post\n            # Using the numerically stable Kalman update form:\n            # Sigma_post = Sigma0 - K * S_i_T * Sigma0, where K = Sigma0 * S_i * (sigma^2 + S_i_T * Sigma0 * S_i)^-1\n            # Which simplifies to: Sigma_post = Sigma0 - (Sigma0 @ S_i) @ (S_i_T @ Sigma0) / (sigma^2 + S_i_T @ Sigma0 @ S_i)\n            # where S_i is a column vector\n            S_i_col = S_i.reshape(-1, 1)\n            S_i_T = S_i.reshape(1, -1)\n            \n            kalman_gain_numerator = Sigma0 @ S_i_col\n            kalman_gain_denominator = sigma**2 + S_i_T @ Sigma0 @ S_i_col\n            \n            # kalman_gain_denominator is a 1x1 matrix, extract the scalar\n            if kalman_gain_denominator[0, 0] == 0:\n                Sigma_post = Sigma0\n            else:\n                kalman_gain = kalman_gain_numerator / kalman_gain_denominator[0, 0]\n                Sigma_post = Sigma0 - kalman_gain @ S_i_T @ Sigma0\n\n            # 3. Compute posterior variance sum\n            var_post_sum = 0.0\n            for j in critical_indices:\n                var_post_sum += Sigma_post[j, j]\n\n            # 4. Compute utility U_i\n            # Avoid division by zero for cost\n            if c == 0:\n                utility = -np.inf # Effectively prioritizes this last\n            else:\n                fractional_reduction = (var_prior_sum - var_post_sum) / var_prior_sum\n                utility = fractional_reduction / c\n            \n            utilities.append({'utility': utility, 'index': i})\n\n        # 5. Rank constraints\n        # Sort by utility (descending) and then index (ascending) for ties\n        utilities.sort(key=lambda x: (-x['utility'], x['index']))\n        ranked_indices = [item['index'] for item in utilities]\n        all_results.append(ranked_indices)\n        \n    print(str(all_results).replace(' ', ''))\n\n\ndef model(theta, L):\n    \"\"\"\n    Computes the predicted signal y based on the Hill-type occupancy model.\n    theta = (K_d, n, alpha)\n    \"\"\"\n    Kd, n, alpha = theta\n    if Kd = 0 or L  0: # Physical constraints\n        return 0.0\n\n    # To prevent overflow for large n and L/Kd > 1\n    # phi = (L/Kd)^n / (1 + (L/Kd)^n) = 1 / (1 + (Kd/L)^n)\n    ratio = L / Kd\n    if ratio > 1.0:\n        inv_ratio = Kd / L\n        # n can be float, use np.power\n        phi = 1.0 / (1.0 + np.power(inv_ratio, n))\n    else:\n        # n can be float, use np.power\n        term = np.power(ratio, n)\n        phi = term / (1.0 + term)\n    \n    return alpha * phi\n\n\ndef compute_sensitivity(theta, L, rel_step=1e-8):\n    \"\"\"\n    Computes the sensitivity vector S = grad_theta f(theta, L) using \n    symmetric finite differences.\n    \"\"\"\n    S = np.zeros_like(theta)\n    for j in range(len(theta)):\n        theta_j = theta[j]\n        # Choose a step size that is robust to theta_j being zero.\n        h = rel_step * (np.abs(theta_j) + 1e-9)\n        \n        theta_plus = np.copy(theta)\n        theta_plus[j] += h\n        \n        theta_minus = np.copy(theta)\n        theta_minus[j] -= h\n        \n        f_plus = model(theta_plus, L)\n        f_minus = model(theta_minus, L)\n        \n        S[j] = (f_plus - f_minus) / (2.0 * h)\n    return S\n\nsolve()\n\n```"
        }
    ]
}