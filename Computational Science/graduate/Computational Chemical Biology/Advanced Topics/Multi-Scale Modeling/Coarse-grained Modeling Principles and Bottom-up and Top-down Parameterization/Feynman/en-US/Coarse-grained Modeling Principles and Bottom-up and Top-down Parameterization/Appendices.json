{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of bottom-up coarse-graining is deriving effective potentials that reproduce structural properties from a reference high-resolution simulation. The Iterative Boltzmann Inversion (IBI) method provides a robust and intuitive way to achieve this. This exercise guides you through the implementation of the IBI algorithm from first principles to parameterize a torsional potential, a critical interaction in models of polymers and proteins, by matching a target dihedral angle distribution . You will grapple with practical considerations like numerical discretization, smoothing, and ensuring periodic boundary conditions are correctly handled.",
            "id": "3839139",
            "problem": "You are parameterizing a coarse-grained torsional potential for a residue-level protein model using a bottom-up strategy grounded in equilibrium statistical mechanics. Assume a single dihedral angle $\\phi \\in [-\\pi,\\pi)$ is governed by a one-dimensional torsional potential $U(\\phi)$ that yields the equilibrium marginal distribution $p(\\phi)$ under the canonical ensemble. The canonical probability density for a coordinate $\\phi$ at temperature $T$ satisfies $p(\\phi) \\propto \\exp\\!\\left(-U(\\phi)/(k_{\\mathrm{B}} T)\\right)$, where $k_{\\mathrm{B}}$ is the Boltzmann constant. In reduced units, set $k_{\\mathrm{B}} T = 1$. Your goal is to apply Iterative Boltzmann Inversion (IBI) to derive a discretized torsional potential $U(\\phi)$ that matches a target atomistic dihedral distribution $p_{\\mathrm{target}}(\\phi)$, while making scientifically sound choices for binning and smoothing.\n\nDerive the IBI update rule starting from the canonical ensemble and implement it in a program that iteratively updates $U(\\phi)$ on a uniform angular grid. The implementation must adhere to the following principles and constraints:\n- Discretize the angle $\\phi$ in radians over the interval $[-\\pi,\\pi)$ into $N_b$ uniform bins of width $\\Delta \\phi = 2\\pi/N_b$, with bin centers placed at midpoints. Use angles in radians for all computations.\n- Use the reduced-unit convention $k_{\\mathrm{B}} T = 1$, so energies are expressed in units of $k_{\\mathrm{B}} T$.\n- The target dihedral distribution $p_{\\mathrm{target}}(\\phi)$ is provided analytically as a mixture of von Mises components. A single von Mises component has density $f(\\phi;\\mu,\\kappa) = \\exp\\!\\left(\\kappa \\cos(\\phi-\\mu)\\right) / \\left(2\\pi I_0(\\kappa)\\right)$, where $I_0$ is the modified Bessel function of the first kind of order zero, $\\mu$ is the mean angle (in radians), and $\\kappa$ is the concentration parameter. A mixture with $M$ components has $p_{\\mathrm{target}}(\\phi) \\propto \\sum_{m=1}^M w_m f(\\phi;\\mu_m,\\kappa_m)$ with weights $w_m > 0$ that sum to $1$. Construct $p_{\\mathrm{target}}(\\phi)$ on the discrete grid by evaluating the mixture at bin centers, adding a small pseudocount $\\varepsilon$ to each bin value, and normalizing so that $\\sum_i p_{\\mathrm{target}}(\\phi_i) = 1$.\n- Initialize the torsional potential to $U_0(\\phi_i) = 0$ at all bin centers $\\{\\phi_i\\}$.\n- At each iteration $n$, compute the model distribution $p_n(\\phi_i)$ implied by the current potential via $p_n(\\phi_i) \\propto \\exp\\!\\left(-U_n(\\phi_i)\\right)$ followed by normalization to $\\sum_i p_n(\\phi_i) = 1$.\n- Derive and apply an IBI update to obtain $U_{n+1}(\\phi_i)$ from $U_n(\\phi_i)$ and the ratio between $p_n(\\phi_i)$ and $p_{\\mathrm{target}}(\\phi_i)$, then apply a smoothing operator to $U_{n+1}(\\phi_i)$ that respects the periodicity of $\\phi$ (i.e., wrap-around at $\\pm \\pi$). Use an isotropic Gaussian kernel with standard deviation $\\sigma$ measured in \"bins\" (so the kernel width scales with bin count). After smoothing, fix the potential gauge by subtracting the mean so that $\\frac{1}{N_b}\\sum_i U_{n+1}(\\phi_i) = 0$.\n- Repeat updates for $N_{\\mathrm{iter}}$ iterations.\n\nDesign the binning and smoothing choices to achieve scientific realism: ensure periodic boundary conditions for smoothing, justify the pseudocount $\\varepsilon$ to avoid $\\log(0)$, and explain how the bin width $\\Delta \\phi$ controls resolution. Use radians for angles and express energies in $k_{\\mathrm{B}} T$ units. Report a quantitative mismatch metric between the final model distribution and the target distribution. Use the integrated absolute difference\n$$\nE = \\sum_{i=1}^{N_b} \\left| p_{\\mathrm{final}}(\\phi_i) - p_{\\mathrm{target}}(\\phi_i) \\right| \\Delta \\phi\n$$\nas a dimensionless scalar error.\n\nImplement the program and evaluate it on the following test suite, which explores a general case, a coarse-binning case, and a wrap-around edge case. In all cases, angles are in radians, energies are in $k_{\\mathrm{B}} T$ units, and the Gaussian smoothing standard deviation $\\sigma$ is specified in bins.\n\nTest case $1$ (happy path):\n- $N_b = 72$, $\\sigma = 0.0$, $\\varepsilon = 10^{-6}$, $N_{\\mathrm{iter}} = 3$.\n- Target mixture: $M = 1$ component with $(w_1,\\mu_1,\\kappa_1) = (1.0, 0.0, 5.0)$.\n\nTest case $2$ (coarse bins and smoothing):\n- $N_b = 12$, $\\sigma = 1.5$, $\\varepsilon = 10^{-6}$, $N_{\\mathrm{iter}} = 5$.\n- Target mixture: $M = 2$ components with $(w_1,\\mu_1,\\kappa_1) = (0.6, \\pi/3, 8.0)$ and $(w_2,\\mu_2,\\kappa_2) = (0.4, -\\pi/3, 4.0)$.\n\nTest case $3$ (edge case near periodic boundary):\n- $N_b = 36$, $\\sigma = 0.5$, $\\varepsilon = 10^{-8}$, $N_{\\mathrm{iter}} = 10$.\n- Target mixture: $M = 2$ components with $(w_1,\\mu_1,\\kappa_1) = (0.5, \\pi - 0.01, 20.0)$ and $(w_2,\\mu_2,\\kappa_2) = (0.5, -\\pi + 0.01, 20.0)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the three $E$ values, in the order of the test cases $(1,2,3)$, each rounded to $6$ decimal places, for example, `[result_1,result_2,result_3]`.",
            "solution": "We begin from the canonical ensemble for a one-dimensional torsional coordinate $\\phi$ with potential $U(\\phi)$ at temperature $T$. The equilibrium marginal probability density is\n$$\np(\\phi) = \\frac{1}{Z} \\exp\\!\\left(-\\frac{U(\\phi)}{k_{\\mathrm{B}} T}\\right),\n$$\nwhere $Z = \\int_{-\\pi}^{\\pi} \\exp\\!\\left(-U(\\phi)/(k_{\\mathrm{B}} T)\\right)\\, d\\phi$ is the partition function. In reduced units with $k_{\\mathrm{B}} T = 1$, this simplifies to $p(\\phi) \\propto \\exp\\!\\left(-U(\\phi)\\right)$.\n\nIn a bottom-up parameterization by Iterative Boltzmann Inversion (IBI), we seek a torsional potential $U(\\phi)$ that reproduces a target atomistic distribution $p_{\\mathrm{target}}(\\phi)$. Let $U_n(\\phi)$ be the potential at iteration $n$, and $p_n(\\phi)$ the corresponding model distribution implied by $U_n(\\phi)$ via the canonical ensemble. By construction,\n$$\np_n(\\phi) = \\frac{\\exp\\!\\left(-U_n(\\phi)\\right)}{\\int_{-\\pi}^{\\pi} \\exp\\!\\left(-U_n(\\phi')\\right) d\\phi'}.\n$$\nThe IBI update can be derived from the desire to correct $U_n(\\phi)$ such that $p_{n+1}(\\phi)$ approaches $p_{\\mathrm{target}}(\\phi)$. Consider an additive correction $\\Delta U_n(\\phi)$ so that $U_{n+1}(\\phi) = U_n(\\phi) + \\Delta U_n(\\phi)$. If we enforce $p_{n+1}(\\phi) = p_{\\mathrm{target}}(\\phi)$ exactly, then\n$$\np_{\\mathrm{target}}(\\phi) \\propto \\exp\\!\\left(-U_{n+1}(\\phi)\\right) = \\exp\\!\\left(-U_n(\\phi) - \\Delta U_n(\\phi)\\right) = \\exp\\!\\left(-U_n(\\phi)\\right)\\exp\\!\\left(-\\Delta U_n(\\phi)\\right).\n$$\nTaking logarithms and using proportionality (i.e., ignoring normalization constants), we get\n$$\n\\ln p_{\\mathrm{target}}(\\phi) = \\ln p_n(\\phi) - \\Delta U_n(\\phi) + \\text{constant}.\n$$\nChoosing the gauge (i.e., additive constant) so that the correction has zero mean, the natural update is\n$$\n\\Delta U_n(\\phi) = \\ln \\frac{p_n(\\phi)}{p_{\\mathrm{target}}(\\phi)}.\n$$\nRestoring $k_{\\mathrm{B}} T$ yields $\\Delta U_n(\\phi) = k_{\\mathrm{B}} T \\ln\\!\\left(p_n(\\phi)/p_{\\mathrm{target}}(\\phi)\\right)$, and in reduced units $k_{\\mathrm{B}} T = 1$, this becomes\n$$\nU_{n+1}(\\phi) = U_n(\\phi) + \\ln \\frac{p_n(\\phi)}{p_{\\mathrm{target}}(\\phi)}.\n$$\nThis update equates $p_{n+1}(\\phi)$ to $p_{\\mathrm{target}}(\\phi)$ if applied without smoothing and with exact distributions. In practice, to achieve stability and enforce physical smoothness, we discretize $\\phi$, apply regularization to $p_{\\mathrm{target}}$, and smooth $U_{n+1}$.\n\nDiscretization and binning: We select $N_b$ uniform bins over $[-\\pi,\\pi)$ with bin width $\\Delta \\phi = 2\\pi/N_b$ and centers at $\\phi_i = -\\pi + (i+1/2)\\Delta \\phi$ for $i = 0,\\dots,N_b-1$. The discrete $p_{\\mathrm{target}}(\\phi_i)$ is obtained from a mixture of von Mises components,\n$$\np_{\\mathrm{target}}(\\phi) \\propto \\sum_{m=1}^M w_m \\frac{\\exp\\!\\left(\\kappa_m \\cos(\\phi - \\mu_m)\\right)}{2\\pi I_0(\\kappa_m)}.\n$$\nTo prevent numerical issues such as $\\log(0)$, we add a pseudocount $\\varepsilon > 0$ to each bin and renormalize so that $\\sum_i p_{\\mathrm{target}}(\\phi_i) = 1$.\n\nModel distribution: Given a discrete potential $U_n(\\phi_i)$, we compute\n$$\np_n(\\phi_i) = \\frac{\\exp\\!\\left(-U_n(\\phi_i)\\right)}{\\sum_{j=1}^{N_b} \\exp\\!\\left(-U_n(\\phi_j)\\right)}.\n$$\n\nIBI update and smoothing: The discrete update is\n$$\nU_{n+1}(\\phi_i) = U_n(\\phi_i) + \\ln \\frac{p_n(\\phi_i)}{p_{\\mathrm{target}}(\\phi_i)}.\n$$\nWe then smooth $U_{n+1}(\\phi_i)$ with a Gaussian kernel of standard deviation $\\sigma$ measured in bins, using periodic boundary conditions (wrap-around) to respect the angular periodicity. Smoothing the potential, rather than the probability, enforces a physically reasonable regularization on the energy landscape. Since the potential is defined up to an additive constant, we fix its gauge by subtracting the mean value so that $\\frac{1}{N_b}\\sum_i U_{n+1}(\\phi_i) = 0$.\n\nError metric: After $N_{\\mathrm{iter}}$ iterations, we form $p_{\\mathrm{final}}(\\phi_i)$ from $U_{N_{\\mathrm{iter}}}(\\phi_i)$ and compute the integrated absolute difference\n$$\nE = \\sum_{i=1}^{N_b} \\left| p_{\\mathrm{final}}(\\phi_i) - p_{\\mathrm{target}}(\\phi_i) \\right| \\Delta \\phi,\n$$\nwhich is dimensionless and quantifies the mismatch.\n\nBinning and smoothing choices: The bin count $N_b$ sets the resolution $\\Delta \\phi$. Larger $N_b$ yields finer resolution at the cost of potentially noisier estimates if sampling were involved; here it enables better capture of sharp features in $p_{\\mathrm{target}}$. The pseudocount $\\varepsilon$ avoids undefined logarithms and overly large updates in bins with tiny probabilities. The smoothing parameter $\\sigma$ (in bins) controls regularity: $\\sigma = 0$ leaves $U$ unchanged, while larger $\\sigma$ produces smoother torsional profiles. Because $\\phi$ is periodic, smoothing must be performed with wrap-around boundary conditions to avoid artifacts near $\\pm \\pi$.\n\nAlgorithmic steps mapped to the program:\n1. Construct the grid of $N_b$ bin centers over $[-\\pi,\\pi)$.\n2. Build $p_{\\mathrm{target}}(\\phi_i)$ from the von Mises mixture, add $\\varepsilon$, and normalize.\n3. Set $U_0(\\phi_i) = 0$.\n4. For $n = 0,\\dots,N_{\\mathrm{iter}}-1$:\n   a. Compute $p_n(\\phi_i)$ from $U_n(\\phi_i)$.\n   b. Form the update $\\Delta U_n(\\phi_i) = \\ln\\!\\left(p_n(\\phi_i)/p_{\\mathrm{target}}(\\phi_i)\\right)$.\n   c. Set $U_{n+1}(\\phi_i) = U_n(\\phi_i) + \\Delta U_n(\\phi_i)$.\n   d. Smooth $U_{n+1}(\\phi_i)$ with a Gaussian kernel of standard deviation $\\sigma$ using wrap-around boundary conditions, then subtract its mean to fix the gauge.\n5. Compute $p_{\\mathrm{final}}(\\phi_i)$ and $E$.\n\nTest suite design:\n- Test case $1$ uses $N_b = 72$ and $\\sigma = 0.0$ to show that, in the absence of smoothing, the IBI update achieves an almost exact match to a unimodal $p_{\\mathrm{target}}$.\n- Test case $2$ uses coarse bins $N_b = 12$ and $\\sigma = 1.5$ to demonstrate that smoothing and coarse resolution produce a controlled mismatch for a bimodal target.\n- Test case $3$ places sharp peaks near the periodic boundary with $N_b = 36$ and $\\sigma = 0.5$, showing correct wrap-around handling and the role of pseudocount $\\varepsilon = 10^{-8}$.\n\nThe program outputs a single line with the three $E$ values, in the order of the test cases, rounded to $6$ decimal places, formatted as `[result_1,result_2,result_3]`.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import i0\nfrom scipy.ndimage import gaussian_filter1d\n\ndef von_mises_mixture(phi, components):\n    \"\"\"\n    Compute a mixture of von Mises densities at angles phi.\n    components: list of tuples (weight, mu, kappa)\n    Returns unnormalized mixture values evaluated at phi.\n    \"\"\"\n    # Each component: w * exp(kappa * cos(phi - mu)) / (2*pi*I0(kappa))\n    vals = np.zeros_like(phi, dtype=np.float64)\n    for w, mu, kappa in components:\n        vals += w * np.exp(kappa * np.cos(phi - mu)) / (2.0 * np.pi * i0(kappa))\n    return vals\n\ndef ibi_torsion(phi_centers, p_target, sigma_bins, n_iter):\n    \"\"\"\n    Perform Iterative Boltzmann Inversion on a discretized torsion.\n    phi_centers: array of bin centers in radians\n    p_target: normalized target distribution over bins (sum to 1)\n    sigma_bins: Gaussian smoothing standard deviation in bins\n    n_iter: number of IBI iterations\n    Returns final potential U (mean-zero) and final distribution p_final.\n    \"\"\"\n    nb = len(phi_centers)\n    # Initialize potential U0 = 0\n    U = np.zeros(nb, dtype=np.float64)\n    # Iterate IBI updates\n    for _ in range(n_iter):\n        # Model distribution from current potential\n        exp_neg_U = np.exp(-U)\n        p_model = exp_neg_U / np.sum(exp_neg_U)\n        # Update rule in reduced units (k_B T = 1): U_{n+1} = U_n + ln(p_model / p_target)\n        # Avoid division issues: p_target is strictly positive due to pseudocount\n        delta_U = np.log(p_model / p_target)\n        U = U + delta_U\n        # Smooth potential with Gaussian kernel, respecting periodicity\n        if sigma_bins > 0.0:\n            U = gaussian_filter1d(U, sigma=sigma_bins, mode='wrap')\n        # Fix gauge: subtract mean\n        U = U - np.mean(U)\n    # Final distribution from final potential\n    exp_neg_U = np.exp(-U)\n    p_final = exp_neg_U / np.sum(exp_neg_U)\n    return U, p_final\n\ndef build_target_distribution(phi_centers, components, epsilon):\n    \"\"\"\n    Build normalized discrete target distribution from von Mises mixture,\n    add pseudocount epsilon to each bin, and renormalize.\n    \"\"\"\n    p_raw = von_mises_mixture(phi_centers, components)\n    # Add pseudocount to all bins to avoid zeros\n    p_raw = p_raw + epsilon\n    # Normalize to sum 1\n    p_target = p_raw / np.sum(p_raw)\n    return p_target\n\ndef integrated_abs_difference(p_final, p_target, dphi):\n    \"\"\"\n    Compute E = sum |p_final - p_target| * dphi\n    \"\"\"\n    return float(np.sum(np.abs(p_final - p_target)) * dphi)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Angles in radians over [-pi, pi)\n    test_cases = [\n        # Test case 1: N_b=72, sigma=0.0, epsilon=1e-6, N_iter=3, unimodal von Mises\n        {\n            \"Nb\": 72,\n            \"sigma\": 0.0,\n            \"epsilon\": 1e-6,\n            \"n_iter\": 3,\n            \"components\": [(1.0, 0.0, 5.0)]\n        },\n        # Test case 2: N_b=12, sigma=1.5, epsilon=1e-6, N_iter=5, bimodal mixture\n        {\n            \"Nb\": 12,\n            \"sigma\": 1.5,\n            \"epsilon\": 1e-6,\n            \"n_iter\": 5,\n            \"components\": [(0.6, np.pi/3.0, 8.0), (0.4, -np.pi/3.0, 4.0)]\n        },\n        # Test case 3: N_b=36, sigma=0.5, epsilon=1e-8, N_iter=10, sharp peaks near boundaries\n        {\n            \"Nb\": 36,\n            \"sigma\": 0.5,\n            \"epsilon\": 1e-8,\n            \"n_iter\": 10,\n            \"components\": [(0.5, np.pi - 0.01, 20.0), (0.5, -np.pi + 0.01, 20.0)]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        Nb = case[\"Nb\"]\n        sigma = case[\"sigma\"]\n        epsilon = case[\"epsilon\"]\n        n_iter = case[\"n_iter\"]\n        components = case[\"components\"]\n\n        # Discretize phi in [-pi, pi)\n        dphi = 2.0 * np.pi / Nb\n        phi_centers = -np.pi + (np.arange(Nb) + 0.5) * dphi\n\n        # Build target distribution with pseudocount\n        p_target = build_target_distribution(phi_centers, components, epsilon)\n\n        # Run IBI with periodic Gaussian smoothing\n        U_final, p_final = ibi_torsion(phi_centers, p_target, sigma_bins=sigma, n_iter=n_iter)\n\n        # Compute integrated absolute difference E\n        E = integrated_abs_difference(p_final, p_target, dphi)\n\n        # Round to 6 decimals for final output format\n        results.append(f\"{E:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While bottom-up methods are designed to reproduce local structure, they do not automatically guarantee consistency with macroscopic thermodynamic properties like pressure. This discrepancy is a common challenge that must be addressed to create a physically realistic model. This practice demonstrates how to diagnose and correct for pressure deviations by applying the virial theorem . You will derive and implement a pressure correction potential, a vital refinement step that reconciles the microscopic interactions of a model with its target thermodynamic state.",
            "id": "3839161",
            "problem": "You are tasked with implementing a computational procedure to quantify and correct pressure deviations in a coarse-grained fluid model parameterized using Iterative Boltzmann Inversion (IBI). The system is assumed to be an isotropic fluid with pairwise-additive interactions truncated at a finite cutoff. All quantities are expressed in reduced, dimensionless units where the Boltzmann constant is $k_{\\mathrm{B}} = 1$, the reduced temperature $T$ is expressed in the same reduced units, and pressure is measured in the reduced unit of energy per unit volume. You must use the virial route to compute the pressure for a given radial distribution function and pair potential derivative, and then design a pressure correction term based on the virial identity to enforce a specified target pressure.\n\nFundamental base to use:\n- The virial expression for the pressure of an isotropic, homogeneous fluid with pairwise additive potential $u(r)$ at number density $\\rho$ and reduced temperature $T$ is\n$$\nP(\\rho, T) = \\rho\\,T - \\frac{2\\pi \\rho^{2}}{3}\\int_{0}^{r_c} r^{3}\\,u'(r)\\,g(r)\\,dr,\n$$\nwhere $g(r)$ is the radial distribution function, $u'(r)$ is the derivative of the pair potential with respect to $r$, and $r_c$ is the cutoff radius.\n- An additive correction to the potential, $\\Delta u(r)$, changes the pressure by\n$$\n\\Delta P = -\\frac{2\\pi \\rho^{2}}{3}\\int_{0}^{r_c} r^{3}\\,\\Delta u'(r)\\,g(r)\\,dr.\n$$\n\nYour design objective:\n- Define a linear-in-$r$ pressure correction term\n$$\n\\Delta u(r) = a\\left(1 - \\frac{r}{r_c}\\right)\\,H(r_c - r),\n$$\nwhere $H(\\cdot)$ is the Heaviside step function and $a$ is an amplitude to be determined such that the corrected model pressure matches a given target pressure $P^\\star$. Using the fundamental base above and the definition of $\\Delta u(r)$, derive and implement an explicit formula for $a$ in terms of the pressure deviation $\\Delta P = P^\\star - P(\\rho,T)$ and a radial integral over $g(r)$.\n\nNumerical setup:\n- Use the Lennard–Jones pair potential in reduced form with $\\epsilon = 1$ and $\\sigma = 1$:\n$$\nu_{\\mathrm{LJ}}(r) = 4\\left[\\left(\\frac{1}{r}\\right)^{12} - \\left(\\frac{1}{r}\\right)^{6}\\right],\\quad\nu'_{\\mathrm{LJ}}(r) = 4\\left[-12\\,r^{-13} + 6\\,r^{-7}\\right].\n$$\n- To avoid force discontinuities at the cutoff, use the force-shifted derivative inside the cutoff,\n$$\nu'_{\\mathrm{FS}}(r) = u'_{\\mathrm{LJ}}(r) - u'_{\\mathrm{LJ}}(r_c), \\quad \\text{for } r \\le r_c,\n$$\nand $u'_{\\mathrm{FS}}(r) = 0$ for $r > r_c$.\n- Approximate all integrals by the trapezoidal rule over a uniform radial grid $r_i = r_{\\min} + i\\,\\Delta r$ with $i = 0,\\dots,N$, where $r_{\\min} = 0.9$ and $\\Delta r = 0.001$. The upper bound is $r_c$ for each test case. Construct the grid so that $r_0 = r_{\\min}$ and $r_N = r_c$ exactly.\n\nRequired computations for each test case:\n1. Compute the model pressure $P(\\rho,T)$ using the virial expression with $u'_{\\mathrm{FS}}(r)$ and the specified $g(r)$.\n2. Compute the pressure deviation $\\Delta P = P^\\star - P(\\rho,T)$.\n3. Using virial considerations and the definition of $\\Delta u(r)$, determine the amplitude $a$ of the pressure correction that would enforce $P^\\star$ when evaluated with the same $g(r)$.\n4. Report the triple of floats $[P(\\rho,T), a, P_{\\mathrm{corrected}}]$, where $P_{\\mathrm{corrected}} = P(\\rho,T) + \\Delta P$ using your derived $\\Delta P$; this should match $P^\\star$ up to numerical quadrature error.\n\nAngle units are not involved. No percentages are involved. All outputs are unitless reduced quantities. Your program must round each float to $6$ decimal places.\n\nTest suite:\n- Use the following three test cases, each with the specified parameters. In all cases, use $r_{\\min} = 0.9$ and $\\Delta r = 0.001$.\n- Test case $1$ (happy path, structured correlations):\n  - $\\rho = 0.8$, $T = 1.0$, $r_c = 2.5$, $P^\\star = 0.8$.\n  - Define $g(r)$ as $g(r) = s(r)\\,h(r)$ with\n    $$\n    s(r) = \\frac{1}{1 + \\exp\\left[-k\\,(r - r_s)\\right]},\\quad k = 20,\\ r_s = 1.0,\n    $$\n    $$\n    h(r) = 1 + A\\,\\exp\\!\\left(-\\frac{(r - r_m)^2}{w^2}\\right)\\cos\\!\\left(\\omega\\,(r - r_m)\\right),\n    $$\n    with $A = 0.25$, $r_m = 1.2$, $w = 0.4$, and $\\omega = 8$.\n- Test case $2$ (low-density limit, same structure proxy):\n  - $\\rho = 0.05$, $T = 1.0$, $r_c = 2.5$, $P^\\star = 0.05$.\n  - Use the same $g(r)$ as in test case $1$.\n- Test case $3$ (shorter cutoff, near-ideal structure):\n  - $\\rho = 0.8$, $T = 1.0$, $r_c = 1.5$, $P^\\star = 1.2$.\n  - Define $g(r) = 1$ for all $r \\in [r_{\\min}, r_c]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, each inner list containing the three floats $[P(\\rho,T), a, P_{\\mathrm{corrected}}]$ rounded to $6$ decimal places, in the order of the test suite. For example, the output format must be exactly like\n`[[P_1,a_1,P_c,1],[P_2,a_2,P_c,2],[P_3,a_3,P_c,3]]`.",
            "solution": "The problem statement has been critically validated and is deemed to be scientifically grounded, well-posed, objective, and self-consistent. It presents a standard computational task in the field of coarse-grained molecular modeling, based on fundamental principles of statistical mechanics. All provided data, definitions, and conditions are sufficient and coherent for deriving a unique and meaningful solution.\n\nThe primary objective is to derive and implement a formula for the amplitude $a$ of a linear pressure-correction potential, $\\Delta u(r)$, such that the pressure of a coarse-grained fluid model matches a target pressure $P^\\star$. The derivation proceeds from the virial expression for pressure.\n\nThe total pressure $P$ of a homogeneous, isotropic fluid with pairwise interactions is given by the virial theorem:\n$$\nP(\\rho, T) = \\rho\\,T - \\frac{2\\pi \\rho^{2}}{3}\\int_{0}^{r_c} r^{3}\\,u'(r)\\,g(r)\\,dr\n$$\nHere, $\\rho$ is the number density, $T$ is the reduced temperature, $u'(r)$ is the derivative of the pair potential, $g(r)$ is the radial distribution function, and $r_c$ is the cutoff radius. All quantities are in reduced units.\n\nA small, additive correction to the potential, $\\Delta u(r)$, induces a corresponding change in pressure, $\\Delta P$:\n$$\n\\Delta P = -\\frac{2\\pi \\rho^{2}}{3}\\int_{0}^{r_c} r^{3}\\,\\Delta u'(r)\\,g(r)\\,dr\n$$\nWe require this pressure change to correct the initial model pressure, $P_{\\text{model}} = P(\\rho, T)$, to a target pressure, $P^\\star$. Thus, we set the desired pressure change to be $\\Delta P_{\\text{target}} = P^\\star - P_{\\text{model}}$.\n\nThe problem specifies a linear correction potential of the form:\n$$\n\\Delta u(r) = a\\left(1 - \\frac{r}{r_c}\\right)\\,H(r_c - r)\n$$\nwhere $H(\\cdot)$ is the Heaviside step function, ensuring the correction is zero for $r > r_c$. For $r \\le r_c$, the derivative of this correction potential with respect to $r$ is a constant:\n$$\n\\Delta u'(r) = \\frac{d}{dr}\\left[a\\left(1 - \\frac{r}{r_c}\\right)\\right] = -\\frac{a}{r_c}\n$$\nSubstituting this derivative into the expression for $\\Delta P$:\n$$\n\\Delta P = -\\frac{2\\pi \\rho^{2}}{3}\\int_{0}^{r_c} r^{3}\\,\\left(-\\frac{a}{r_c}\\right)\\,g(r)\\,dr\n$$\nSince $a$ and $r_c$ are constants, they can be factored out of the integral:\n$$\n\\Delta P = \\frac{2\\pi a \\rho^{2}}{3r_c}\\int_{0}^{r_c} r^{3}\\,g(r)\\,dr\n$$\nTo achieve the target pressure, we set $\\Delta P = \\Delta P_{\\text{target}} = P^\\star - P_{\\text{model}}$ and solve for the amplitude $a$:\n$$\nP^\\star - P_{\\text{model}} = \\frac{2\\pi a \\rho^{2}}{3r_c}\\int_{0}^{r_c} r^{3}\\,g(r)\\,dr\n$$\n$$\na = \\frac{P^\\star - P_{\\text{model}}}{\\frac{2\\pi \\rho^{2}}{3r_c}\\int_{0}^{r_c} r^{3}\\,g(r)\\,dr}\n$$\nRearranging gives the final explicit formula for $a$:\n$$\na = \\frac{3r_c (P^\\star - P_{\\text{model}})}{2\\pi\\rho^{2} \\int_{0}^{r_c} r^{3}\\,g(r)\\,dr}\n$$\nThe computational procedure is as follows:\n1.  For each test case, a uniform radial grid $r_i$ is constructed from $r_{\\min} = 0.9$ to the specified $r_c$ with spacing $\\Delta r = 0.001$. The integrals are numerically evaluated over this grid using the trapezoidal rule, which is a valid approximation as $g(r)$ is effectively zero for $r < r_{\\min}$.\n2.  The force-shifted Lennard-Jones derivative, $u'_{\\mathrm{FS}}(r) = u'_{\\mathrm{LJ}}(r) - u'_{\\mathrm{LJ}}(r_c)$, and the given radial distribution function $g(r)$ are evaluated on the grid.\n3.  The initial model pressure, $P_{\\text{model}} \\equiv P(\\rho, T)$, is computed by numerically evaluating the virial integral $\\int_{r_{\\min}}^{r_c} r^{3}\\,u'_{\\mathrm{FS}}(r)\\,g(r)\\,dr$ and substituting it into the pressure equation.\n4.  The denominator of the expression for $a$ is computed by numerically evaluating the integral $\\int_{r_{\\min}}^{r_c} r^{3}\\,g(r)\\,dr$.\n5.  With $P_{\\text{model}}$ and the required integral known, the amplitude $a$ is calculated using the derived formula.\n6.  The corrected pressure, $P_{\\mathrm{corrected}}$, is calculated as $P_{\\text{model}} + \\Delta P$. By construction, $\\Delta P = P^\\star - P_{\\text{model}}$, so $P_{\\mathrm{corrected}}$ must equal $P^\\star$, up to numerical precision. This serves as a consistency check.\n7.  The final results for each test case, $[P(\\rho,T), a, P_{\\mathrm{corrected}}]$, are collected and formatted.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def u_lj_prime(r):\n        \"\"\"\n        Computes the derivative of the reduced Lennard-Jones potential.\n        sigma = 1, epsilon = 1.\n        \"\"\"\n        r_inv = 1.0 / r\n        r_inv7 = r_inv**7\n        r_inv13 = r_inv**13\n        return 4.0 * (-12.0 * r_inv13 + 6.0 * r_inv7)\n\n    def get_g_case1_and_2(r):\n        \"\"\"\n        Computes the radial distribution function g(r) for test cases 1 and 2.\n        \"\"\"\n        k = 20.0\n        r_s = 1.0\n        s_r = 1.0 / (1.0 + np.exp(-k * (r - r_s)))\n\n        A = 0.25\n        r_m = 1.2\n        w = 0.4\n        omega = 8.0\n        h_r = 1.0 + A * np.exp(-((r - r_m) / w)**2) * np.cos(omega * (r - r_m))\n        return s_r * h_r\n\n    def get_g_case3(r):\n        \"\"\"\n        Computes the radial distribution function g(r) for test case 3.\n        \"\"\"\n        return np.ones_like(r)\n\n    def solve_case(params):\n        \"\"\"\n        Solves one case for P, a, and P_corrected.\n        \"\"\"\n        rho, T, r_c, P_star, g_func = params\n        r_min = 0.9\n        dr = 0.001\n\n        # 1. Construct the numerical grid\n        num_points = int(round((r_c - r_min) / dr)) + 1\n        r = np.linspace(r_min, r_c, num_points)\n\n        # 2. Evaluate functions on the grid\n        g_r = g_func(r)\n        u_lj_prime_rc = u_lj_prime(r_c)\n        u_fs_prime_r = u_lj_prime(r) - u_lj_prime_rc\n\n        # 3. Compute initial model pressure P\n        integrand_P = r**3 * u_fs_prime_r * g_r\n        I_P = np.trapz(integrand_P, r)\n        virial_term = (2.0 * np.pi * rho**2 / 3.0) * I_P\n        P_model = rho * T - virial_term\n\n        # 4. Compute the integral for the correction amplitude 'a'\n        integrand_a = r**3 * g_r\n        I_a = np.trapz(integrand_a, r)\n        \n        # 5. Compute 'a'\n        pressure_deviation = P_star - P_model\n        denominator_a = (2.0 * np.pi * rho**2 / (3.0 * r_c)) * I_a\n        \n        # Avoid division by zero, though not expected in this problem\n        if abs(denominator_a) < 1e-15:\n            a = np.nan\n        else:\n            a = pressure_deviation / denominator_a\n\n        # 6. Compute the corrected pressure as a consistency check\n        # By construction, P_corrected = P_model + pressure_deviation = P_star\n        delta_P_calculated = a * denominator_a\n        P_corrected = P_model + delta_P_calculated\n\n        return [P_model, a, P_corrected]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.8, 1.0, 2.5, 0.8, get_g_case1_and_2),   # Case 1\n        (0.05, 1.0, 2.5, 0.05, get_g_case1_and_2), # Case 2\n        (0.8, 1.0, 1.5, 1.2, get_g_case3),          # Case 3\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = solve_case(case)\n        all_results.append(result)\n\n    # Format the results into the required string format.\n    formatted_results = []\n    for res_list in all_results:\n        # Each res_list is [P, a, P_corrected]\n        formatted_list_str = [f\"{val:.6f}\" for val in res_list]\n        formatted_results.append(f\"[{','.join(formatted_list_str)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a coarse-grained model is parameterized, how can we be sure it is a valid representation of the underlying system? Discrepancies between the model and target data can arise either because the model's form is fundamentally incorrect (misspecification) or simply because its parameters are not yet precisely determined (parameter uncertainty). This exercise introduces the powerful framework of Bayesian posterior predictive checks to distinguish between these two scenarios . By comparing the target data distribution to a credible band of model-predicted distributions, you will develop a quantitative basis for either accepting the model or identifying its fundamental flaws.",
            "id": "3839165",
            "problem": "You are tasked with implementing a posterior predictive check for a coarse-grained observable in computational chemical biology, explicitly addressing bottom-up and top-down parameterization principles. Consider a coarse-grained bead model where the scalar inter-bead distance $r$ (in nanometers) is treated as an observable derived from an underlying effective potential. In the top-down parameterization view, you posit a parametric family for the distribution of $r$ and infer its parameters from target data (experimental or all-atom reference). In the bottom-up view, you compare distributions implied by the coarse-grained model to those from atomistic data and assess whether discrepancies are due to parameter uncertainty or model misspecification.\n\nBase your reasoning on the following foundational principles:\n\n- The Boltzmann distribution states that the equilibrium probability density of configurations is proportional to $\\exp\\left(-\\beta U\\right)$, where $\\beta = \\left(k_{\\mathrm{B}} T\\right)^{-1}$ and $U$ is the potential energy. Mapping to coarse-grained observables induces marginal distributions that depend on parameterized effective potentials.\n- Bayesian inference combines prior beliefs and likelihood via Bayes' rule: $p\\!\\left(\\theta\\mid \\mathcal{D}\\right) \\propto p\\!\\left(\\mathcal{D}\\mid \\theta\\right)p\\!\\left(\\theta\\right)$, where $\\theta$ denotes model parameters and $\\mathcal{D}$ the observed data.\n- The posterior predictive distribution is defined as $p\\!\\left(x_{\\mathrm{new}}\\mid \\mathcal{D}\\right) = \\int p\\!\\left(x_{\\mathrm{new}}\\mid \\theta\\right) p\\!\\left(\\theta\\mid \\mathcal{D}\\right)\\, d\\theta$.\n\nAssume for this problem that the scalar distance $r$ follows a lognormal model under the top-down parameterization: $y = \\ln r$ is Gaussian with unknown mean $\\mu$ and unknown variance $\\sigma^{2}$. Adopt a Normal-Inverse-Gamma prior for $(\\mu,\\sigma^{2})$ appropriate for this Gaussian model of $y$. The target distribution will be compared to this parametric family via a Posterior Predictive Check (PPC), defined here as computing the pointwise $0.95$ credible band for the model-implied density of $r$ and assessing the coverage of the target empirical density relative to this band.\n\nYou must derive, implement, and use the following in your program:\n\n1. A Bayesian update for the Gaussian model of $y=\\ln r$ with a Normal-Inverse-Gamma prior to obtain $p\\!\\left(\\mu,\\sigma^{2}\\mid \\mathcal{D}\\right)$.\n2. A posterior predictive calculation for the density of $r$ via the transformation from $y$ to $r$, constructing a pointwise $0.95$ credible band for the density $f(r)$ over a suitably chosen grid of $r$ values (in nanometers).\n3. An empirical density estimate of the target data for $r$ using a Gaussian kernel density estimate on $y$ followed by the appropriate change-of-variables transformation to $r$. The empirical density must be expressed in units of $\\mathrm{nm}^{-1}$.\n4. A decision rule that outputs a boolean per test case indicating whether discrepancies indicate model misspecification (output $\\mathrm{True}$) or parameter uncertainty (output $\\mathrm{False}$). Use two quantitative diagnostics:\n   - The coverage fraction $\\phi$, defined as the fraction of grid points where the empirical density lies within the pointwise $0.95$ credible band.\n   - An out-of-band area metric $A$, defined as the integral over $r$ of the magnitude by which the empirical density exceeds the credible band (above the upper limit or below the lower limit), approximated numerically.\n   Your program must decide $\\mathrm{True}$ for misspecification only when $\\phi$ is strictly less than a chosen threshold and $A$ is strictly greater than a chosen threshold. Otherwise, return $\\mathrm{False}$ for parameter uncertainty.\n\nAll distances must be treated in nanometers, and densities in $\\mathrm{nm}^{-1}$. The final output does not carry units because it is boolean.\n\nTest Suite Specification:\n\nImplement your program to evaluate the following three test cases that emulate different bottom-up and top-down scenarios. In each case, generate synthetic target data $\\mathcal{D}$ for $r$ accordingly:\n\n- Case $1$ (well-specified top-down model): $r$ is lognormal with $y=\\ln r$ drawn from a Gaussian with $\\mu=0.0$ and $\\sigma=0.4$, and sample size $n=500$.\n- Case $2$ (misspecified model; bottom-up discrepancy): $r$ is from a two-component mixture of lognormals with equal weights $0.5$, where component $1$ has $y=\\ln r$ Gaussian with $\\mu_{1}=-0.2$, $\\sigma_{1}=0.3$, and component $2$ has $y=\\ln r$ Gaussian with $\\mu_{2}=0.5$, $\\sigma_{2}=0.25$, and sample size $n=500$.\n- Case $3$ (small-sample parameter uncertainty): $r$ is lognormal with $y=\\ln r$ Gaussian with $\\mu=0.2$ and $\\sigma=0.5$, and sample size $n=25$.\n\nUse a single, fixed prior across cases that is reasonably weakly informative for $(\\mu,\\sigma^{2})$ given the expected magnitudes of $y$: choose a Normal-Inverse-Gamma prior with hyperparameters $m_{0}=0.0$, $\\kappa_{0}=1.0$, $\\alpha_{0}=2.0$, $\\beta_{0}=1.0$.\n\nImplementation Constraints and Output Format:\n\n- You must use a Monte Carlo approximation to construct the $0.95$ credible band for $f(r)$ by sampling from the posterior of $(\\mu,\\sigma^{2})$ and evaluating the lognormal density at a grid of $r$ values. Use a reproducible random seed, and choose a grid that spans the $0.01$ to $0.99$ empirical quantiles of $r$ with at least $200$ points.\n- The kernel density estimate for the empirical density must be computed on $y=\\ln r$ using a Gaussian kernel with bandwidth chosen by Silverman’s rule of thumb, $h = 1.06\\, s\\, n^{-1/5}$, where $s$ is the sample standard deviation of $y$ and $n$ is the sample size. Transform it to $r$ via the change-of-variables formula.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for the three test cases in the order listed, where each element is a boolean indicating misspecification (`True`) or parameter uncertainty (`False`). For example, an output could look like `[False, True, False]`.",
            "solution": "The problem requires the implementation of a Bayesian posterior predictive check to distinguish between parameter uncertainty and model misspecification in the context of coarse-grained (CG) modeling. We are given a parametric model for an observable, the inter-bead distance $r$, and tasked with evaluating its validity against synthetic target data representing different physical scenarios. This process emulates the critical step in computational chemical biology of validating a simplified CG potential against either experimental data (a top-down approach) or high-fidelity all-atom simulations (a bottom-up approach).\n\nThe core of the analysis rests on Bayesian inference. We model the logarithm of the distance, $y = \\ln r$, as a normally distributed random variable, $y \\sim \\mathcal{N}(\\mu, \\sigma^2)$, with unknown mean $\\mu$ and variance $\\sigma^2$. The corresponding distribution for $r$ is the lognormal distribution. The parameters $(\\mu, \\sigma^2)$ are inferred from a dataset $\\mathcal{D} = \\{r_1, \\dots, r_n\\}$, or equivalently, $\\mathcal{D}_y = \\{y_1, \\dots, y_n\\}$ where $y_i = \\ln r_i$.\n\nWe employ a conjugate prior for $(\\mu, \\sigma^2)$, the Normal-Inverse-Gamma (NIG) distribution, denoted as $(\\mu, \\sigma^2) \\sim \\text{NIG}(m_0, \\kappa_0, \\alpha_0, \\beta_0)$. Its probability density function is given by:\n$$\np(\\mu, \\sigma^2 | m_0, \\kappa_0, \\alpha_0, \\beta_0) = \\frac{\\sqrt{\\kappa_0}}{\\sqrt{2\\pi\\sigma^2}} \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} (\\sigma^2)^{-(\\alpha_0+1)} \\exp\\left(-\\frac{1}{2\\sigma^2}[2\\beta_0 + \\kappa_0(\\mu - m_0)^2]\\right)\n$$\nThe problem specifies the prior hyperparameters as $m_0=0.0$, $\\kappa_0=1.0$, $\\alpha_0=2.0$, and $\\beta_0=1.0$.\n\nGiven the data $\\mathcal{D}_y$, the likelihood function is that of a Gaussian distribution:\n$$\np(\\mathcal{D}_y | \\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right) \\propto (\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\mu)^2\\right)\n$$\nDue to the conjugacy of the NIG prior with the Gaussian likelihood, the posterior distribution $p(\\mu, \\sigma^2 | \\mathcal{D}_y)$ is also a Normal-Inverse-Gamma distribution, $\\text{NIG}(m_n, \\kappa_n, \\alpha_n, \\beta_n)$, with updated hyperparameters. Let $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ be the sample mean and $S = \\sum_{i=1}^n (y_i - \\bar{y})^2$ be the sum of squared deviations. The posterior hyperparameters are:\n$$\n\\kappa_n = \\kappa_0 + n \\\\\nm_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n} \\\\\n\\alpha_n = \\alpha_0 + \\frac{n}{2} \\\\\n\\beta_n = \\beta_0 + \\frac{1}{2}S + \\frac{\\kappa_0 n}{2(\\kappa_0+n)}(\\bar{y} - m_0)^2\n$$\n\nWith the posterior distribution determined, we perform a posterior predictive check. The posterior predictive distribution for a new observation $r_{\\text{new}}$ is $p(r_{\\text{new}} | \\mathcal{D}) = \\int p(r_{\\text{new}}|\\theta) p(\\theta|\\mathcal{D}) d\\theta$, where $\\theta = (\\mu, \\sigma^2)$. We approximate this by drawing a large number of samples, $\\{\\theta^{(j)}\\}_{j=1}^M$, from the posterior $p(\\theta|\\mathcal{D})$. For each sample $\\theta^{(j)} = (\\mu^{(j)}, \\sigma^{2(j)})$, we can evaluate the density of $r$. The density function of a lognormal variable $r$, given parameters $\\mu$ and $\\sigma^2$ for $y=\\ln r$, is obtained via the change-of-variables formula:\n$$\nf(r | \\mu, \\sigma^2) = p_Y(\\ln r | \\mu, \\sigma^2) \\left| \\frac{d(\\ln r)}{dr} \\right| = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(\\ln r - \\mu)^2}{2\\sigma^2}\\right) \\cdot \\frac{1}{r}\n$$\nBy evaluating this density for each posterior sample $\\theta^{(j)}$ on a grid of $r$ values, we obtain a distribution of density values at each grid point. The pointwise $0.95$ credible band is formed by taking the $0.025$ and $0.975$ quantiles of these density values at each point on the $r$-grid.\n\nTo compare our model against the target data, we must estimate the empirical probability density of the data, $\\hat{f}(r)$. This is done by first computing a Gaussian kernel density estimate (KDE) on the log-transformed data $y_i = \\ln r_i$:\n$$\n\\hat{f}_Y(y) = \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{y - y_i}{h}\\right)\n$$\nwhere $K(u) = (2\\pi)^{-1/2} e^{-u^2/2}$ is the Gaussian kernel. The bandwidth $h$ is set by Silverman's rule of thumb: $h = 1.06 \\cdot s_y \\cdot n^{-1/5}$, where $s_y$ is the sample standard deviation of the $y_i$ values. The density in the original $r$ space is then found by the same change-of-variables transformation:\n$$\n\\hat{f}_R(r) = \\hat{f}_Y(\\ln r) \\cdot \\frac{1}{r}\n$$\n\nFinally, we define a decision rule based on two diagnostics to determine if discrepancies between the empirical density $\\hat{f}_R(r)$ and the model's credible band suggest model misspecification.\n1.  **Coverage Fraction ($\\phi$)**: The fraction of grid points where the empirical density lies within the pointwise $0.95$ credible band.\n    $$\n    \\phi = \\frac{1}{N_{\\text{grid}}} \\sum_{i=1}^{N_{\\text{grid}}} \\mathbb{I}[f_{\\text{lower}}(r_i) \\leq \\hat{f}_R(r_i) \\leq f_{\\text{upper}}(r_i)]\n    $$\n2.  **Out-of-Band Area ($A$)**: The integrated magnitude of the deviation where the empirical density lies outside the band. This is computed numerically.\n    $$\n    A = \\int \\left( \\max[0, \\hat{f}_R(r) - f_{\\text{upper}}(r)] + \\max[0, f_{\\text{lower}}(r) - \\hat{f}_R(r)] \\right) dr\n    $$\nModel misspecification is concluded if the model provides poor coverage and the magnitude of the deviation is significant. We formalize this with the rule: model misspecification is declared ($\\mathrm{True}$) if $\\phi < \\phi_{\\text{threshold}}$ AND $A > A_{\\text{threshold}}$. Following standard practice, we choose a coverage threshold of $\\phi_{\\text{threshold}} = 0.95$, reflecting the $95\\%$ credible band. We select an area threshold of $A_{\\text{threshold}} = 0.05$, representing a non-trivial integrated deviation. If the conditions are not met, the discrepancy is attributed to parameter uncertainty ($\\mathrm{False}$).\n\nThis procedure is applied to three test cases: a well-specified model with ample data, a misspecified model (bimodal data fitted with a unimodal model), and a well-specified model with sparse data. The outcomes are expected to correctly identify the misspecified case while showing that parameter uncertainty (manifested as a wide credible band) can accommodate apparent deviations in the small-sample case.",
            "answer": "```python\nimport numpy as np\nimport scipy.stats\n\ndef solve():\n    \"\"\"\n    Main function to run the posterior predictive check on three test cases.\n    \"\"\"\n    # Set a random seed for reproducibility of data generation and sampling.\n    np.random.seed(42)\n\n    # Define fixed prior hyperparameters for the Normal-Inverse-Gamma distribution.\n    # m0, k0, a0, b0\n    prior_hyperparams = (0.0, 1.0, 2.0, 1.0)\n    \n    # Define thresholds for the decision rule.\n    # phi_threshold, A_threshold\n    thresholds = (0.95, 0.05)\n    \n    # --- Test Case Specifications ---\n    # Case 1: Well-specified model, n=500\n    r_data_1 = np.random.lognormal(mean=0.0, sigma=0.4, size=500)\n    \n    # Case 2: Misspecified model (mixture), n=500\n    n_mix = 250\n    y1_mix = np.random.normal(loc=-0.2, scale=0.3, size=n_mix)\n    y2_mix = np.random.normal(loc=0.5, scale=0.25, size=n_mix)\n    r_data_2 = np.exp(np.concatenate([y1_mix, y2_mix]))\n    \n    # Case 3: Small-sample parameter uncertainty, n=25\n    r_data_3 = np.random.lognormal(mean=0.2, sigma=0.5, size=25)\n    \n    test_cases = [r_data_1, r_data_2, r_data_3]\n    results = []\n\n    for r_data in test_cases:\n        is_misspecified = evaluate_case(r_data, prior_hyperparams, thresholds)\n        results.append(is_misspecified)\n\n    # Format and print the final output as a single-line string.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef evaluate_case(r_data, prior_hyperparams, thresholds):\n    \"\"\"\n    Performs the full Bayesian analysis for a single data case.\n    \"\"\"\n    m0, k0, a0, b0 = prior_hyperparams\n    phi_thresh, A_thresh = thresholds\n    \n    # Transform data to log-space\n    y_data = np.log(r_data)\n    n = len(y_data)\n    y_mean = np.mean(y_data)\n    \n    # Calculate posterior hyperparameters for the NIG distribution\n    kn = k0 + n\n    mn = (k0 * m0 + n * y_mean) / kn\n    an = a0 + n / 2\n    sum_sq_diff = np.sum((y_data - y_mean)**2)\n    bn = b0 + 0.5 * sum_sq_diff + (k0 * n * (y_mean - m0)**2) / (2 * (k0 + n))\n    \n    # Monte Carlo sampling from the posterior distribution\n    num_samples = 5000\n    # Sample sigma^2 from Inverse-Gamma(an, bn)\n    # Using 1/Gamma(an, 1/bn) to sample from Inverse-Gamma\n    sigma2_samples = 1.0 / np.random.gamma(shape=an, scale=1.0/bn, size=num_samples)\n    # Sample mu from Normal(mn, sigma^2/kn)\n    mu_samples = np.random.normal(loc=mn, scale=np.sqrt(sigma2_samples / kn))\n    \n    # Define grid for density evaluation\n    r_grid = np.linspace(np.quantile(r_data, 0.01), np.quantile(r_data, 0.99), 200)\n    y_grid = np.log(r_grid)\n\n    # Calculate posterior predictive densities on the grid\n    # This creates a (num_grid_points, num_samples) array\n    sigma_samples = np.sqrt(sigma2_samples)\n    pdf_y_samples = scipy.stats.norm.pdf(y_grid[:, np.newaxis], loc=mu_samples, scale=sigma_samples)\n    pdf_r_samples = pdf_y_samples / r_grid[:, np.newaxis]\n    \n    # Compute the 0.95 credible band\n    lower_band = np.quantile(pdf_r_samples, 0.025, axis=1)\n    upper_band = np.quantile(pdf_r_samples, 0.975, axis=1)\n\n    # Compute empirical density using Gaussian KDE on y_data\n    s_y = np.std(y_data, ddof=1)\n    h = 1.06 * s_y * n**(-1/5)\n    \n    # KDE calculation for y, broadcasted over the grid\n    y_kde_vals = np.sum(scipy.stats.norm.pdf((y_grid[:, np.newaxis] - y_data) / h), axis=1) / (n * h)\n    \n    # Transform KDE to r-space\n    r_kde_vals = y_kde_vals / r_grid\n    \n    # --- Decision Metrics ---\n    # 1. Coverage fraction (phi)\n    within_band = (r_kde_vals >= lower_band) & (r_kde_vals <= upper_band)\n    phi = np.mean(within_band)\n    \n    # 2. Out-of-band area (A)\n    diff_upper = np.maximum(0, r_kde_vals - upper_band)\n    diff_lower = np.maximum(0, lower_band - r_kde_vals)\n    total_diff = diff_upper + diff_lower\n    A = np.trapz(total_diff, r_grid)\n\n    # Decision rule\n    is_misspecified = (phi < phi_thresh) and (A > A_thresh)\n    \n    return is_misspecified\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}