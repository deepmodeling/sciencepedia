{
    "hands_on_practices": [
        {
            "introduction": "A primary check in any molecular dynamics simulation is confirming that the system's temperature matches the thermostat's target value. However, this check can be deceptively simple and often leads to a false sense of security about the quality of sampling. This exercise  delves into the statistical mechanics of the canonical ensemble to reveal why agreement of the kinetic temperature is a necessary but insufficient condition for ergodic sampling, particularly for systems with separable Hamiltonians.",
            "id": "2453013",
            "problem": "A classical Molecular Dynamics (MD) simulation of a cluster with $N=50$ particles is run under a thermostat set to a target temperature $T=300\\,\\mathrm{K}$. The Hamiltonian is separable into kinetic and potential terms, $H(\\mathbf{p},\\mathbf{q})=K(\\mathbf{p})+U(\\mathbf{q})$, and the equations of motion are integrated with a time step small enough to ensure numerical stability. Over a trajectory of length $10\\,\\mathrm{ns}$, the system remains confined to a single metastable basin separated by large free-energy barriers from other basins. The running time-average of the kinetic-temperature observable, defined via the instantaneous kinetic energy and the number of active degrees of freedom, matches the target temperature $T$ to within $1\\%$.\n\nStarting from first principles of the canonical ensemble, the definition of ergodicity as the equality of time and ensemble averages in the long-time limit, and the separability of kinetic and potential energy in classical mechanics, reason about how the time-averaged kinetic temperature can match the target even when the simulation is non-ergodic (i.e., trapped in a basin), and why agreement of the kinetic temperature with $T$ is a misleading diagnostic of proper sampling.\n\nWhich statements correctly explain both how this is possible and why relying on kinetic temperature alone can misdiagnose sampling quality? Select all that apply.\n\nA. In the canonical ensemble with separable Hamiltonian $H(\\mathbf{p},\\mathbf{q})=K(\\mathbf{p})+U(\\mathbf{q})$, the joint distribution factorizes, so a thermostat can enforce the correct Maxwell–Boltzmann momentum marginal and thereby $\\langle K\\rangle$ consistent with $T$, even if the coordinate distribution is restricted to one basin; thus the time-averaged kinetic temperature can match $T$ while configurational sampling is biased.\n\nB. Matching the target temperature guarantees that all ensemble averages are correct, because time averages equal ensemble averages regardless of ergodicity.\n\nC. The kinetic temperature depends primarily on fast velocity fluctuations and is largely insensitive to rare barrier-crossing events in slow collective coordinates; therefore it can appear correct while slow modes remain unsampled, making it an unreliable indicator of configurational sampling.\n\nD. Non-ergodicity necessarily causes the kinetic temperature to drift away from the setpoint over long times, so observing a match between the time-averaged kinetic temperature and $T$ implies ergodicity.\n\nE. Accounting for constraints reduces the number of degrees of freedom, and once this count is correct the temperature will always match $T$, which also implies that the coordinate distribution is correct.",
            "solution": "The problem statement will first be validated for scientific soundness and completeness.\n\n### Step 1: Extract Givens\n\n-   Simulation type: Classical Molecular Dynamics (MD)\n-   Number of particles: $N=50$\n-   Thermostat target temperature: $T=300\\,\\mathrm{K}$\n-   Hamiltonian: Separable, $H(\\mathbf{p},\\mathbf{q})=K(\\mathbf{p})+U(\\mathbf{q})$\n-   Integration time step: Sufficiently small for numerical stability.\n-   Trajectory length: $10\\,\\mathrm{ns}$\n-   System dynamics: The system is confined to a single metastable basin, separated by large free-energy barriers from other basins.\n-   Observation: The running time-average of the kinetic-temperature observable matches the target temperature $T$ to within $1\\%$.\n-   Definition of kinetic temperature: Derived from the instantaneous kinetic energy and the number of active degrees of freedom.\n-   Task: Explain how the time-averaged kinetic temperature can match the target $T$ despite the simulation being non-ergodic, and why this agreement is a misleading diagnostic of proper sampling.\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientific Groundedness**: The problem describes a canonical scenario in computational statistical mechanics. A separable Hamiltonian is the standard form in classical mechanics. The concept of a system being trapped in a metastable basin is a central challenge in MD, known as the sampling problem. Thermostats, the canonical ensemble, and the distinction between kinetic and configurational sampling are all fundamental and well-established principles. The problem is scientifically sound.\n-   **Well-Posedness**: The question is unambiguous. It asks for a mechanistic explanation for a common observation in MD simulations and requires evaluation of provided statements against this explanation. The setup is self-contained and allows for a definitive answer based on the principles of statistical mechanics.\n-   **Objectivity**: The problem is stated in precise, objective, and technical language. There are no subjective or opinion-based elements.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. It is scientifically grounded, well-posed, and objective. A rigorous solution can be derived from first principles.\n\n### Derivation from First Principles\n\nIn the canonical (NVT) ensemble, the equilibrium probability distribution of states in phase space $(\\mathbf{q}, \\mathbf{p})$ is given by the Boltzmann distribution:\n$$\n\\rho(\\mathbf{q}, \\mathbf{p}) = \\frac{1}{Z} e^{-\\beta H(\\mathbf{q}, \\mathbf{p})}\n$$\nwhere $\\beta = (k_B T)^{-1}$, $k_B$ is the Boltzmann constant, $T$ is the thermodynamic temperature, and $Z$ is the canonical partition function.\n\nThe problem states that the Hamiltonian is separable: $H(\\mathbf{p},\\mathbf{q}) = K(\\mathbf{p}) + U(\\mathbf{q})$. This has a profound consequence. The probability distribution factorizes into independent distributions for momenta $\\mathbf{p}$ and coordinates $\\mathbf{q}$:\n$$\n\\rho(\\mathbf{q}, \\mathbf{p}) = \\frac{1}{Z_p Z_q} e^{-\\beta K(\\mathbf{p})} e^{-\\beta U(\\mathbf{q})} = \\rho_p(\\mathbf{p}) \\rho_q(\\mathbf{q})\n$$\nwhere $\\rho_p(\\mathbf{p}) = Z_p^{-1} \\exp(-\\beta K(\\mathbf{p}))$ is the marginal probability distribution for momenta, and $\\rho_q(\\mathbf{q}) = Z_q^{-1} \\exp(-\\beta U(\\mathbf{q}))$ is the marginal probability distribution for coordinates. The key insight is that momenta and coordinates are statistically independent in the canonical ensemble for a separable Hamiltonian.\n\nA thermostat coupled to an MD simulation primarily acts to modify the equations of motion for the momenta $\\mathbf{p}$ to ensure that their distribution samples $\\rho_p(\\mathbf{p})$ correctly. This is the Maxwell-Boltzmann distribution. The ensemble average of the kinetic energy $K(\\mathbf{p})$ is then determined solely by this momentum distribution:\n$$\n\\langle K \\rangle_{\\text{ens}} = \\int K(\\mathbf{p}) \\rho_p(\\mathbf{p}) d\\mathbf{p}\n$$\nAccording to the equipartition theorem, which applies here, each quadratic term in the kinetic energy contributes $\\frac{1}{2} k_B T$ to this average. If there are $N_{\\text{dof}}$ kinetic degrees of freedom, then:\n$$\n\\langle K \\rangle_{\\text{ens}} = \\frac{N_{\\text{dof}}}{2} k_B T\n$$\nThe instantaneous kinetic temperature is defined as $T_{\\text{kin}}(t) = \\frac{2 K(\\mathbf{p}(t))}{N_{\\text{dof}} k_B}$. A working thermostat ensures that the time-average of this quantity, $\\langle T_{\\text{kin}} \\rangle_{\\text{time}}$, converges to the target temperature $T$. This equilibration happens on a very fast timescale, characteristic of molecular vibrations and collisions (femtoseconds to picoseconds).\n\nNow consider the configurational part. The ergodic hypothesis states that for a sufficiently long trajectory, the time average of an observable is equal to its ensemble average. In this problem, the simulation is explicitly stated to be non-ergodic over the $10\\,\\mathrm{ns}$ timescale because it is trapped in a single metastable basin. This means the trajectory only explores a subset of the configuration space $\\mathbf{q}$. Consequently, a time-average of any configurational observable $A(\\mathbf{q})$ will only reflect an average over that single basin, not the full Boltzmann-weighted average over all accessible configurations.\n$$\n\\langle A(\\mathbf{q}) \\rangle_{\\text{time}} \\approx \\langle A(\\mathbf{q}) \\rangle_{\\text{basin}} \\neq \\langle A(\\mathbf{q}) \\rangle_{\\text{ens}}\n$$\nBecause the dynamics of $\\mathbf{p}$ and $\\mathbf{q}$ are statistically decoupled in the ensemble, and because thermostats act efficiently on the fast momentum degrees of freedom, it is entirely possible for $\\langle K \\rangle_{\\text{time}} \\approx \\langle K \\rangle_{\\text{ens}}$ (and thus $\\langle T_{\\text{kin}} \\rangle_{\\text{time}} \\approx T$) while simultaneously $\\langle U \\rangle_{\\text{time}} \\neq \\langle U \\rangle_{\\text{ens}}$ and sampling of configuration space is severely biased.\n\nTherefore, agreement of the kinetic temperature with the target value $T$ is a check on the performance of the thermostat and the equilibration of kinetic degrees of freedom, but it provides no information about the sampling of the configurational landscape. Relying on it as a sole indicator of overall simulation quality or \"equilibration\" is a common but serious error, as the slow degrees of freedom responsible for conformational changes and chemical processes may be completely unsampled.\n\n### Option-by-Option Analysis\n\n**A. In the canonical ensemble with separable Hamiltonian $H(\\mathbf{p},\\mathbf{q})=K(\\mathbf{p})+U(\\mathbf{q})$, the joint distribution factorizes, so a thermostat can enforce the correct Maxwell–Boltzmann momentum marginal and thereby $\\langle K\\rangle$ consistent with $T$, even if the coordinate distribution is restricted to one basin; thus the time-averaged kinetic temperature can match $T$ while configurational sampling is biased.**\nThis statement is a precise summary of the statistical mechanics principles derived above. It correctly identifies the separability of the Hamiltonian and the resulting factorization of the probability distribution as the fundamental reason. It correctly explains that the thermostat acts on the momentum distribution independently of the (potentially poor) configurational sampling. This explains both *how* the phenomenon is possible and *why* kinetic temperature is a misleading diagnostic.\n**Verdict: Correct**\n\n**B. Matching the target temperature guarantees that all ensemble averages are correct, because time averages equal ensemble averages regardless of ergodicity.**\nThis statement is fundamentally false. The equivalence of time and ensemble averages is the definition of ergodicity. For a non-ergodic system, this equality does not hold. The problem explicitly describes a non-ergodic sampling situation. Therefore, this statement is in direct contradiction with the principles of statistical mechanics.\n**Verdict: Incorrect**\n\n**C. The kinetic temperature depends primarily on fast velocity fluctuations and is largely insensitive to rare barrier-crossing events in slow collective coordinates; therefore it can appear correct while slow modes remain unsampled, making it an unreliable indicator of configurational sampling.**\nThis statement provides a kinetic and timescale-based explanation which is complementary to the statistical mechanical argument in A. Momenta $\\mathbf{p}$ (and thus velocities) fluctuate on a very fast timescale ($\\sim 10^{-15} - 10^{-12}\\,\\mathrm{s}$). A thermostat can equilibrate these fluctuations quickly. Barrier-crossing events involve slow, collective motions of coordinates $\\mathbf{q}$ that occur on much longer timescales ($\\sim 10^{-9}\\,\\mathrm{s}$ or longer). A $10\\,\\mathrm{ns}$ simulation is long enough to average over the fast kinetic fluctuations, yielding a correct $\\langle T_{\\text{kin}} \\rangle_{\\text{time}}$, but may be far too short to observe the rare configurational events. This correctly identifies the timescale separation as the reason for the misleading diagnostic.\n**Verdict: Correct**\n\n**D. Non-ergodicity necessarily causes the kinetic temperature to drift away from the setpoint over long times, so observing a match between the time-averaged kinetic temperature and $T$ implies ergodicity.**\nThis statement is incorrect. As explained, non-ergodicity in configuration space does not prevent a thermostat from maintaining the kinetic temperature at the target value. The proper function of a thermostat is precisely to prevent such drifts. Therefore, observing a match between kinetic temperature and the target $T$ absolutely does not imply ergodicity in the full phase space. This statement posits the exact opposite of the correct physical picture.\n**Verdict: Incorrect**\n\n**E. Accounting for constraints reduces the number of degrees of freedom, and once this count is correct the temperature will always match $T$, which also implies that the coordinate distribution is correct.**\nThis statement is flawed. While it is true that one must use the correct number of degrees of freedom, $N_{\\text{dof}}$, to calculate $T_{\\text{kin}}$ from $K$, this is merely a matter of correct calculation. It does not guarantee that the temperature will match $T$; the thermostat does that. The final conclusion, that this implies the coordinate distribution is correct, is a non-sequitur and is fundamentally wrong for the reasons detailed in the analysis of options A and C.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "Real chemical systems, such as those involving catalysis or protein folding, are characterized by complex energy landscapes with multiple stable states separated by high barriers. Standard simulations can easily become trapped, leading to non-ergodic sampling and incorrect results. This practice  challenges you to act as a computational detective, using a realistic dataset from a catalytic reaction to diagnose the signatures of broken ergodicity and to identify appropriate enhanced sampling strategies to restore proper ensemble averaging.",
            "id": "3900145",
            "problem": "A catalytic surface reaction is simulated on a metal-oxide slab using both Molecular Dynamics (MD) and Markov Chain Monte Carlo (MCMC) under thermodynamic conditions intended to realize either the microcanonical ensemble with fixed number of particles ($N$), volume ($V$), and energy ($E$), or the canonical ensemble with fixed $N$, $V$, and temperature ($T$). The potential energy landscape has two metastable basins corresponding to reactant-like and product-like adsorption states. Canonical sampling at $T = 600\\ \\mathrm{K}$ yields the following observations: an energy histogram $p(E)$ accumulated over $10^7$ accepted MCMC moves exhibits two well-separated peaks centered near $E_1 \\approx -1.20\\ \\mathrm{eV}$ and $E_2 \\approx -1.05\\ \\mathrm{eV}$, with negligible counts for energies between the peaks. Two independent canonical runs, one initialized in basin $1$ and the other in basin $2$, show rare inter-basin transitions (fewer than $3$ transitions in $10^7$ moves) and strong run-to-run differences in the time-averaged reaction coordinate $q$. The integrated autocorrelation time (IAT) of $q$, computed from the time series in either run, is approximately $\\tau_{\\mathrm{int}} \\approx 10^5$ moves, whereas a typical local vibrational decorrelation time is $\\tau_{\\mathrm{vib}} \\sim 10$ moves. Microcanonical MD at total energy $E \\approx -1.15\\ \\mathrm{eV}$ exhibits no basin-to-basin transitions over $10^6$ time steps, and the distribution of $q$ depends on the initial basin.\n\nAssuming physically reasonable barrier heights (e.g., a free energy barrier $\\Delta F \\sim 20\\,k_{\\mathrm{B}}T$ separating the two basins) and that the MCMC proposal mechanism satisfies detailed balance with respect to the target canonical distribution, which of the following statements are valid diagnostics of broken ergodicity and scientifically sound remedies for recovering correct ensemble averages of catalytic observables under canonical or microcanonical conditions?\n\nA. The mere observation of a bimodal canonical energy histogram $p(E)$, with consistent peak weights across long time windows and across multiple independent runs that each exhibit frequent inter-basin transitions, is sufficient evidence of broken ergodicity.\n\nB. A strong dependence of the canonical energy histogram $p(E)$ on the initial basin, together with an IAT $\\tau_{\\mathrm{int}}$ for the reaction coordinate $q$ that is many orders of magnitude larger than the local decorrelation time $\\tau_{\\mathrm{vib}}$, is a valid diagnostic of broken ergodicity.\n\nC. In microcanonical simulations, the energy distribution is sharply concentrated by construction, so long autocorrelation times cannot be used to diagnose broken ergodicity and do not threaten the validity of microcanonical time averages.\n\nD. If time averages from canonical runs started in different basins disagree and the sampled $p(E)$ deviates from the expected canonical form due to trapping, this indicates broken ergodicity; enhanced sampling methods that promote basin connectivity, such as Parallel Tempering (PT, also known as Replica Exchange) or Umbrella Sampling along an appropriate reaction coordinate, are appropriate remedies.\n\nE. Simply increasing the total number of samples by a factor of $10$ without changing the sampling mechanism will always resolve broken ergodicity, because the law of large numbers guarantees convergence of time averages to ensemble averages regardless of autocorrelation and trapping.",
            "solution": "The user wants me to validate the problem statement and, if valid, provide a detailed solution.\n\n### Step 1: Extract Givens\n\n*   **System:** Catalytic surface reaction on a metal-oxide slab.\n*   **Methods:** Molecular Dynamics (MD) and Markov Chain Monte Carlo (MCMC).\n*   **Ensembles:** Microcanonical (fixed $N, V, E$) and Canonical (fixed $N, V, T$).\n*   **Potential Energy Landscape:** Two metastable basins (reactant-like and product-like).\n*   **Canonical Simulation ($NVT$) Data:**\n    *   Temperature: $T = 600\\ \\mathrm{K}$.\n    *   Energy histogram $p(E)$ from $10^7$ MCMC moves is bimodal.\n    *   Histogram peak centers: $E_1 \\approx -1.20\\ \\mathrm{eV}$ and $E_2 \\approx -1.05\\ \\mathrm{eV}$.\n    *   Histogram shows negligible counts for energies between the peaks.\n    *   Inter-basin transitions are rare: fewer than $3$ transitions in $10^7$ moves.\n    *   Time-averaged reaction coordinate, $\\langle q \\rangle$, shows strong run-to-run differences depending on the initial basin.\n    *   Integrated autocorrelation time of $q$: $\\tau_{\\text{int}} \\approx 10^5$ moves.\n    *   Local vibrational decorrelation time: $\\tau_{\\text{vib}} \\sim 10$ moves.\n*   **Microcanonical Simulation ($NVE$) Data:**\n    *   Total energy: $E \\approx -1.15\\ \\mathrm{eV}$.\n    *   No basin-to-basin transitions observed over $10^6$ time steps.\n    *   The distribution of the reaction coordinate $q$ depends on the initial basin.\n*   **Assumptions:**\n    *   Physically reasonable free energy barrier, $\\Delta F \\sim 20\\,k_{\\mathrm{B}}T$.\n    *   The MCMC proposal mechanism satisfies detailed balance with respect to the target canonical distribution.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scientifically sound and well-posed.\n*   **Scientifically Grounded:** The problem describes a classic and realistic challenge in computational statistical mechanics: sampling a system with multiple metastable states separated by high energy barriers. This phenomenon, often termed \"rare events,\" is central to the simulation of chemical reactions, phase transitions, and protein folding. All concepts used—microcanonical and canonical ensembles, ergodicity, autocorrelation time, Molecular Dynamics, Monte Carlo, and enhanced sampling—are fundamental to the field. The provided numerical values are consistent: a free energy barrier of $\\Delta F \\sim 20\\,k_{\\mathrm{B}}T$ implies a transition probability proportional to $e^{-\\Delta F / (k_{\\mathrm{B}}T)} \\approx e^{-20}$, which is extremely small and explains the observation of fewer than $3$ transitions in $10^7$ steps. The large discrepancy between the collective variable's autocorrelation time ($\\tau_{\\text{int}} \\approx 10^5$ moves) and the local vibrational time ($\\tau_{\\text{vib}} \\sim 10$ moves) is a textbook signature of such a system.\n*   **Well-Posed and Complete:** The problem provides sufficient, consistent information to evaluate the statements. The data from both canonical and microcanonical simulations paints a coherent picture of a system exhibiting broken ergodicity on the timescale of the simulations. The question is clearly formulated, asking to identify valid diagnostics and remedies from a list of options.\n*   **Objective:** The problem is phrased in precise, technical language, free from subjective or ambiguous terms.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. Proceeding to solution derivation and option analysis.\n\n### Solution and Option Analysis\n\nThe core issue described is \"practical\" broken ergodicity. The ergodic hypothesis posits that the time average of an observable for a single, long trajectory will equal the ensemble average over all possible microstates. A system is practically non-ergodic if the simulation time is insufficient for the trajectory to explore all relevant, accessible regions of phase space. This typically occurs when high energy or free energy barriers separate metastable state basins. The system becomes \"trapped\" in one basin for a duration longer than the simulation run.\n\nThe problem provides multiple, consistent indicators of this phenomenon:\n1.  **Dependence on Initial Conditions:** Both the canonical and microcanonical simulations show that properties (like the average reaction coordinate $\\langle q \\rangle$) depend on the starting basin. This directly violates the condition for ergodicity.\n2.  **Long Autocorrelation Time:** The integrated autocorrelation time of the reaction coordinate, $\\tau_{\\text{int}} \\approx 10^5$ moves, is a quantitative measure of how long it takes for the system to \"forget\" its state concerning the inter-basin motion. Since this time is a significant fraction of the total simulation length ($10^7$ moves), the generated samples are highly correlated, and the system is not exploring the phase space efficiently.\n3.  **Rare Transitions:** Observing fewer than $3$ transitions in $10^7$ moves confirms that the timescale for barrier crossing is far greater than the simulation length. An effective sampling of the equilibrium between the two basins would require many dozens, if not hundreds, of back-and-forth transitions.\n\nWith this understanding, we evaluate each option.\n\n**A. The mere observation of a bimodal canonical energy histogram $p(E)$, with consistent peak weights across long time windows and across multiple independent runs that each exhibit frequent inter-basin transitions, is sufficient evidence of broken ergodicity.**\n\nThis statement is factually incorrect. A bimodal energy histogram $p(E)$ is the expected equilibrium feature for a system with two populated metastable states in the canonical ensemble. The presence of two peaks simply reflects the two energy basins $E_1$ and $E_2$. The critical part of the statement, \"...consistent peak weights... and frequent inter-basin transitions,\" is the very *definition* of a well-converged, ergodic simulation. Frequent transitions indicate that the barrier is being crossed effectively, and consistent weights indicate that the relative populations (and thus the relative free energies) of the basins have been accurately determined. These are hallmarks of successful sampling, not broken ergodicity.\n\n**Verdict: Incorrect.**\n\n**B. A strong dependence of the canonical energy histogram $p(E)$ on the initial basin, together with an IAT $\\tau_{\\mathrm{int}}$ for the reaction coordinate $q$ that is many orders of magnitude larger than the local decorrelation time $\\tau_{\\mathrm{vib}}$, is a valid diagnostic of broken ergodicity.**\n\nThis statement correctly identifies two key diagnostics of broken ergodicity.\n1.  *Strong dependence of $p(E)$ on the initial basin:* If a simulation is trapped, a run started in basin $1$ will produce a histogram peaked only at $E_1$, while a run started in basin $2$ will produce a histogram peaked at $E_2$. The resulting histogram depends on history, meaning the time average is not converging to the true ensemble average (which should be bimodal, including both peaks with their correct thermodynamic weights). This is precisely what is described in the problem setup for the observable $q$.\n2.  *Large IAT:* The integrated autocorrelation time ($\\tau_{\\text{int}}$) of a coordinate like $q$ that describes the slow, inter-basin motion being much larger than local vibrational times ($\\tau_{\\text{vib}}$) is a classic signature of a rare-event problem. Here, $\\tau_{\\text{int}} \\approx 10^5$ while $\\tau_{\\text{vib}} \\sim 10$, a difference of $4$ orders of magnitude. This timescale separation indicates that while the system rapidly explores the local basin, it fails to sample the global configuration space on a practical timescale. This is a direct, quantitative indicator of broken ergodicity for a finite simulation length.\n\n**Verdict: Correct.**\n\n**C. In microcanonical simulations, the energy distribution is sharply concentrated by construction, so long autocorrelation times cannot be used to diagnose broken ergodicity and do not threaten the validity of microcanonical time averages.**\n\nThis statement is fundamentally incorrect. In a microcanonical ($NVE$) simulation, the total energy $E$ is conserved, so its distribution is indeed a delta function, $\\delta(E' - E)$. However, ergodicity in this ensemble concerns the exploration of the constant-energy hypersurface in phase space. If this surface is disconnected or has regions connected by very narrow bottlenecks (e.g., a potential energy saddle point higher than the total energy $E$), the system trajectory can be confined to a subset of the accessible states. The problem explicitly states that for $E \\approx -1.15\\ \\mathrm{eV}$, the system shows no transitions and the distribution of $q$ depends on the initial basin. This is a direct observation of broken ergodicity in the microcanonical ensemble. A long autocorrelation time of an order parameter like $q$ is precisely the quantitative diagnostic for this trapping. If the system is trapped, time averages will reflect only one basin, not the correct microcanonical average over all accessible states on the energy shell. Such trapping absolutely threatens the validity of the computed averages.\n\n**Verdict: Incorrect.**\n\n**D. If time averages from canonical runs started in different basins disagree and the sampled $p(E)$ deviates from the expected canonical form due to trapping, this indicates broken ergodicity; enhanced sampling methods that promote basin connectivity, such as Parallel Tempering (PT, also known as Replica Exchange) or Umbrella Sampling along an appropriate reaction coordinate, are appropriate remedies.**\n\nThis statement correctly identifies both a valid diagnostic and a set of appropriate remedies.\n1.  *Diagnostic:* The first part, \"If time averages from canonical runs started in different basins disagree... this indicates broken ergodicity,\" is a textbook definition of the practical problem. If the result depends on the initial state, the system has not reached equilibrium and has not sampled the ensemble ergodically. The observation that the sampled $p(E)$ would be unimodal (for a trapped run) instead of the true bimodal distribution is a direct consequence.\n2.  *Remedy:* The second part proposes valid solutions. Parallel Tempering (Replica Exchange) and Umbrella Sampling are standard, powerful enhanced sampling techniques designed specifically to overcome high energy barriers. PT uses high-temperature replicas to cross barriers easily, propagating this information to the target low-temperature replica. Umbrella Sampling modifies the potential energy along a reaction coordinate ($q$) to flatten the free energy profile, promoting transitions that can be later corrected for to recover the unbiased ensemble properties. Both are scientifically sound methods to restore effective ergodicity in simulations.\n\n**Verdict: Correct.**\n\n**E. Simply increasing the total number of samples by a factor of $10$ without changing the sampling mechanism will always resolve broken ergodicity, because the law of large numbers guarantees convergence of time averages to ensemble averages regardless of autocorrelation and trapping.**\n\nThis statement is dangerously naive and incorrect. While the ergodic theorem guarantees convergence in the limit of infinite time, it says nothing about the rate of convergence. In systems with high barriers, the convergence can be logarithmically slow. The effective number of independent samples is approximately $N_{\\text{eff}} \\approx N_{\\text{samples}} / (2\\tau_{\\text{int}})$. Given $N_{\\text{samples}} = 10^7$ and $\\tau_{\\text{int}} \\approx 10^5$, we have $N_{\\text{eff}} \\approx 10^7 / (2 \\times 10^5) = 50$. This is a woefully small number of effective samples. Increasing the run length by a factor of $10$ to $10^8$ moves would yield $N_{\\text{eff}} \\approx 500$, which is still likely insufficient for accurate statistics. More importantly, the simulation has observed fewer than $3$ transitions in $10^7$ moves. The characteristic time for a single transition is on the order of $\\tau_{\\text{trans}} \\approx (10^7/3) \\approx 3 \\times 10^6$ moves. To sample the equilibrium between basins robustly, the total simulation time must be many multiples of $\\tau_{\\text{trans}}$. A $10 \\times$ longer run ($10^8$ moves) might capture $\\sim 30$ transitions, which is an improvement but may not be enough for convergence and certainly does not \"always resolve\" the problem. The law of large numbers does not magically eliminate physical trapping on finite, practical timescales.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{BD}$$"
        },
        {
            "introduction": "Beyond diagnosing sampling issues, a key goal of molecular simulation is to compute thermodynamic properties like free energy profiles, which govern reaction rates and binding affinities. The 'Blue Moon' ensemble method provides a powerful way to do this by calculating the free energy derivative as an average constraint force. This problem  guides you through both the theoretical derivation of this relationship and its practical application, translating averaged simulation data into a quantitative free energy difference.",
            "id": "3862883",
            "problem": "In a canonical isothermal simulation at temperature $T$, consider an $N$-particle biomolecular system with Cartesian coordinates collected in $q \\in \\mathbb{R}^{3N}$ and momenta $p \\in \\mathbb{R}^{3N}$. The Hamiltonian is $H(q,p) = K(p) + U(q)$ with kinetic energy $K(p)$ quadratic in $p$ via a diagonal mass matrix $M = m I$ with a common particle mass $m$. Define a scalar collective variable (reaction coordinate) $\\xi(q)$ by a linear map $\\xi(q) = c^{\\top} q$, where $c \\in \\mathbb{R}^{3N}$ is a fixed, nonzero vector. You run holonomically constrained molecular dynamics at fixed $\\xi(q) = \\xi^{\\star}$ using the Lagrange multiplier $\\lambda$ through the equations of motion\n$$M \\ddot{q} = -\\nabla U(q) + \\lambda \\nabla \\xi(q)$$\ntogether with a thermostat that ensures sampling of the canonical constrained distribution on the manifold $\\{q : \\xi(q) = \\xi^{\\star}\\}$, and you assume ergodicity on this manifold so that time averages equal ensemble averages.\n\nStarting from fundamental definitions of the canonical ensemble, constrained partition functions using Dirac delta functions, and the definition of the potential of mean force $A(\\xi)$ via the marginal $P(\\xi)$, do the following:\n\n1. Derive an expression for $\\frac{dA}{d\\xi}(\\xi^{\\star})$ in terms of an ensemble average computed over the constrained manifold at $\\xi(q) = \\xi^{\\star}$, and identify any geometric or mass-metric Jacobian terms that enter for a general reaction coordinate. Explain under what conditions these geometric terms vanish.\n\n2. Specialize your result to the present case $\\xi(q) = c^{\\top} q$ with $M = m I$ and show that the derivative simplifies to an average of the instantaneous generalized force conjugate to $\\xi$, which for the given equations of motion coincides with the Lagrange multiplier $\\lambda$.\n\nYou then perform a series of independent constrained runs at five equally spaced values of $\\xi$ with spacing $h = 0.25$ nm over the interval $[\\xi_{\\min}, \\xi_{\\max}] = [0.50, 1.50]$ nm, and obtain converged estimates of the constrained-ensemble mean Lagrange multiplier $\\langle \\lambda \\rangle_{\\xi}$ at each grid point (assume statistical uncertainty is negligible for the purpose of this calculation):\n\n- At $\\xi = 0.50$ nm: $\\langle \\lambda \\rangle_{\\xi} = 21.25$ kJ mol$^{-1}$ nm$^{-1}$.\n- At $\\xi = 0.75$ nm: $\\langle \\lambda \\rangle_{\\xi} = 17.8125$ kJ mol$^{-1}$ nm$^{-1}$.\n- At $\\xi = 1.00$ nm: $\\langle \\lambda \\rangle_{\\xi} = 15.00$ kJ mol$^{-1}$ nm$^{-1}$.\n- At $\\xi = 1.25$ nm: $\\langle \\lambda \\rangle_{\\xi} = 12.8125$ kJ mol$^{-1}$ nm$^{-1}$.\n- At $\\xi = 1.50$ nm: $\\langle \\lambda \\rangle_{\\xi} = 11.25$ kJ mol$^{-1}$ nm$^{-1}$.\n\nUsing your result from parts $1$–$2$, compute the free energy difference $\\Delta A = A(\\xi_{\\max}) - A(\\xi_{\\min})$ by numerically integrating $\\frac{dA}{d\\xi}$ over $\\xi \\in [0.50, 1.50]$ nm with the composite Simpson rule applied to the five points above. Express your final $\\Delta A$ in kJ mol$^{-1}$ and round your answer to four significant figures.",
            "solution": "This problem requires a multi-part solution, beginning with a theoretical derivation from statistical mechanics, followed by a specialization to a specific case, and concluding with a numerical calculation.\n\n### Part 1: General Derivation of the PMF Derivative\n\nThe potential of mean force (PMF), $A(\\xi)$, is defined from the marginal probability distribution $P(\\xi')$ of the collective variable $\\xi(q)$ as $P(\\xi') \\propto \\exp(-\\beta A(\\xi'))$, where $\\beta = (k_B T)^{-1}$. The marginal probability is obtained by integrating the full canonical probability distribution over all degrees of freedom, subject to the constraint $\\xi(q) = \\xi'$. Focusing on the configurational degrees of freedom $q$, the PMF is given by:\n$$A(\\xi') = -k_B T \\ln Z_q(\\xi') + C$$\nwhere $C$ is a constant and $Z_q(\\xi')$ is the constrained configurational partition function:\n$$Z_q(\\xi') = \\int \\exp(-\\beta U(q)) \\delta(\\xi(q) - \\xi') dq$$\nHere, $U(q)$ is the potential energy, and $\\delta(\\cdot)$ is the Dirac delta function, which enforces the constraint.\n\nTo find the derivative of the PMF, $\\frac{dA}{d\\xi}$, we differentiate the expression for $A(\\xi')$ with respect to $\\xi'$:\n$$\\frac{dA}{d\\xi'}(\\xi') = -k_B T \\frac{1}{Z_q(\\xi')} \\frac{dZ_q(\\xi')}{d\\xi'}$$\nThe derivative of the partition function is:\n$$\\frac{dZ_q(\\xi')}{d\\xi'} = \\int \\exp(-\\beta U(q)) \\frac{\\partial}{\\partial\\xi'} \\delta(\\xi(q) - \\xi') dq$$\nUsing the property of the delta function $\\frac{\\partial}{\\partial y}\\delta(x-y) = -\\frac{\\partial}{\\partial x}\\delta(x-y)$, we can write:\n$$\\frac{dZ_q(\\xi')}{d\\xi'} = \\int \\exp(-\\beta U(q)) \\left( -\\frac{\\partial}{\\partial\\xi(q)} \\delta(\\xi(q) - \\xi') \\right) dq$$\nThis form is not directly useful for evaluation. A more rigorous approach involves using the generalized chain rule and integration by parts in the space of distributions. A key identity, often derived using mass-weighted coordinates, connects the derivative with respect to the collective variable value to an average over the constrained hyperplane. In mass-weighted coordinates $q' = M^{1/2}q$, where the metric is Euclidean, the derivative of the PMF can be shown to be:\n$$\\frac{dA}{d\\xi'}(\\xi') = \\left\\langle \\frac{\\nabla' \\xi \\cdot (-\\nabla' U)}{|\\nabla' \\xi|^2} \\right\\rangle_{\\xi'} + k_B T \\left\\langle \\nabla' \\cdot \\left(\\frac{\\nabla' \\xi}{|\\nabla' \\xi|^2}\\right) \\right\\rangle_{\\xi'}$$\nwhere $\\nabla'$ is the gradient with respect to $q'$, and $\\langle \\cdot \\rangle_{\\xi'}$ denotes a canonical average on the constrained manifold $\\{q : \\xi(q) = \\xi'\\}$.\n\nTransforming back to the original Cartesian coordinates $q$ (where $\\nabla' = M^{-1/2} \\nabla_q$), the general expression becomes:\n$$\\frac{dA}{d\\xi}(\\xi^{\\star}) = \\left\\langle \\frac{\\nabla\\xi \\cdot M^{-1} (-\\nabla U)}{\\nabla\\xi^\\top M^{-1} \\nabla\\xi} \\right\\rangle_{\\xi^{\\star}} - k_B T \\left\\langle \\nabla \\cdot \\left( \\frac{M^{-1}\\nabla\\xi}{\\nabla\\xi^\\top M^{-1} \\nabla\\xi} \\right) \\right\\rangle_{\\xi^{\\star}}$$\nThis is the required expression. The first term represents the projection of the physical force $F = -\\nabla U$ onto the reaction coordinate direction, weighted by the mass-metric $M^{-1}$. The second term, involving the divergence, is a geometric or metric correction term. It arises from the curvature of the level sets of $\\xi(q)$ within the configuration space endowed with the kinetic energy metric defined by $M^{-1}$.\n\nThis geometric correction term vanishes under certain conditions. Let the vector field in the divergence be $v(q) = \\frac{M^{-1}\\nabla\\xi}{\\nabla\\xi^\\top M^{-1} \\nabla\\xi}$. The term is zero if the ensemble average of its divergence, $\\langle \\nabla \\cdot v(q) \\rangle_{\\xi^{\\star}}$, is zero. A sufficient condition for this to happen is if $\\nabla \\cdot v(q) = 0$ for all $q$. This is true if the vector field $v(q)$ is constant. This occurs if both the mass matrix $M$ and the gradient of the collective variable $\\nabla\\xi$ are constant. A constant $\\nabla\\xi$ means that $\\xi(q)$ is a linear function of the Cartesian coordinates $q$.\n\n### Part 2: Specialization for a Linear Collective Variable\n\nWe are given a linear collective variable $\\xi(q) = c^\\top q$ and a simple mass matrix $M = mI$.\nFor $\\xi(q) = c^\\top q$, the gradient is a constant vector: $\\nabla\\xi = c$.\nThe mass matrix $M = mI$ is constant, and its inverse is $M^{-1} = \\frac{1}{m}I$.\n\nAs established in Part 1, since $\\nabla\\xi$ and $M$ are constant, the geometric correction term vanishes. The expression for the PMF derivative simplifies to only the first term:\n$$\\frac{dA}{d\\xi}(\\xi^{\\star}) = \\left\\langle \\frac{\\nabla\\xi \\cdot M^{-1} (-\\nabla U)}{\\nabla\\xi^\\top M^{-1} \\nabla\\xi} \\right\\rangle_{\\xi^{\\star}}$$\nSubstituting $\\nabla\\xi = c$ and $M^{-1} = \\frac{1}{m}I$:\n$$\\frac{dA}{d\\xi}(\\xi^{\\star}) = \\left\\langle \\frac{c^\\top (\\frac{1}{m}I) (-\\nabla U)}{c^\\top (\\frac{1}{m}I) c} \\right\\rangle_{\\xi^{\\star}} = \\left\\langle \\frac{-\\frac{1}{m} c^\\top \\nabla U}{\\frac{1}{m} c^\\top c} \\right\\rangle_{\\xi^{\\star}} = \\left\\langle \\frac{-c^\\top \\nabla U}{c^\\top c} \\right\\rangle_{\\xi^{\\star}}$$\nNow, we relate this to the Lagrange multiplier $\\lambda$ from the equations of motion for holonomically constrained dynamics:\n$$M \\ddot{q} = -\\nabla U(q) + \\lambda \\nabla \\xi(q)$$\nSubstituting $M=mI$ and $\\nabla\\xi=c$:\n$$m \\ddot{q} = -\\nabla U + \\lambda c$$\nTo maintain the constraint $\\xi(q) = c^\\top q = \\xi^{\\star}$, its second time derivative must be zero: $\\ddot{\\xi} = \\frac{d^2}{dt^2}(c^\\top q) = c^\\top \\ddot{q} = 0$.\nWe take the dot product of the equation of motion with $c$:\n$$c^\\top (m \\ddot{q}) = c^\\top (-\\nabla U) + c^\\top(\\lambda c)$$\n$$m (c^\\top \\ddot{q}) = -c^\\top \\nabla U + \\lambda (c^\\top c)$$\nSince $c^\\top \\ddot{q}=0$, we get:\n$$0 = -c^\\top \\nabla U + \\lambda (c^\\top c)$$\nSolving for the instantaneous value of the Lagrange multiplier $\\lambda$:\n$$\\lambda = \\frac{c^\\top \\nabla U}{c^\\top c}$$\nComparing this with our expression for the PMF derivative, we find:\n$$\\frac{dA}{d\\xi}(\\xi^{\\star}) = \\left\\langle \\frac{c^\\top \\nabla U}{c^\\top c} \\right\\rangle_{\\xi^{\\star}} = \\langle \\lambda \\rangle_{\\xi^{\\star}}$$\nThis shows that for this specific case, the derivative of the potential of mean force is equal to the ensemble average of the Lagrange multiplier used to enforce the constraint.\n\n### Part 3: Numerical Integration of the Free Energy Difference\n\nThe free energy difference between $\\xi_{\\min}$ and $\\xi_{\\max}$ is obtained by integrating the PMF derivative:\n$$\\Delta A = A(\\xi_{\\max}) - A(\\xi_{\\min}) = \\int_{\\xi_{\\min}}^{\\xi_{\\max}} \\frac{dA}{d\\xi} d\\xi$$\nUsing the result from Part 2, this becomes:\n$$\\Delta A = \\int_{\\xi_{\\min}}^{\\xi_{\\max}} \\langle \\lambda \\rangle_{\\xi} d\\xi$$\nWe are given numerical values for $\\langle \\lambda \\rangle_{\\xi}$ at $5$ equally spaced points and asked to perform a numerical integration using the composite Simpson's rule. The formula for the composite Simpson's rule for $n$ intervals (where $n$ is even) is:\n$$\\int_{x_0}^{x_n} f(x) dx \\approx \\frac{h}{3} \\left[ f(x_0) + 4f(x_1) + 2f(x_2) + \\dots + 4f(x_{n-1}) + f(x_n) \\right]$$\nThe provided data are:\n- Integration interval: $[\\xi_{\\min}, \\xi_{\\max}] = [0.50, 1.50]$ nm.\n- Step size: $h = 0.25$ nm.\n- Number of points: $5$, corresponding to $n=4$ intervals.\n- Function values $f_i = \\langle \\lambda \\rangle_{\\xi_i}$ in units of kJ mol$^{-1}$ nm$^{-1}$:\n - $f_0 = f(0.50) = 21.25$\n - $f_1 = f(0.75) = 17.8125$\n - $f_2 = f(1.00) = 15.00$\n - $f_3 = f(1.25) = 12.8125$\n - $f_4 = f(1.50) = 11.25$\n\nApplying the composite Simpson's rule:\n$$\\Delta A \\approx \\frac{h}{3} [f_0 + 4f_1 + 2f_2 + 4f_3 + f_4]$$\n$$\\Delta A \\approx \\frac{0.25}{3} [21.25 + 4(17.8125) + 2(15.00) + 4(12.8125) + 11.25]$$\nCalculating the terms inside the bracket:\n$$4 \\times 17.8125 = 71.25$$\n$$2 \\times 15.00 = 30.00$$\n$$4 \\times 12.8125 = 51.25$$\nSumming the terms:\n$$21.25 + 71.25 + 30.00 + 51.25 + 11.25 = 185.00$$\nNow, we compute the final value for $\\Delta A$:\n$$\\Delta A \\approx \\frac{0.25}{3} \\times 185.00 = \\frac{185.00}{12} \\approx 15.41666...$$\nThe unit of the result is $(\\text{nm}) \\times (\\text{kJ mol}^{-1} \\text{nm}^{-1}) = \\text{kJ mol}^{-1}$.\nRounding the result to four significant figures as requested:\n$$\\Delta A \\approx 15.42 \\text{ kJ mol}^{-1}$$",
            "answer": "$$\\boxed{15.42}$$"
        }
    ]
}