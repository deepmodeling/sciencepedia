{
    "hands_on_practices": [
        {
            "introduction": "本练习将我们对分子描述符的研究置于一个具体可感的物理性质之上。通过计算可旋转键数（Rotatable Bond Count, RBC），一个简单而强大的一维描述符，我们直接量化了分子的构象灵活性。这项实践至关重要，因为它将分子的结构图与构象熵等基本热力学概念联系起来，从而更深入地理解其在生物系统中的行为。",
            "id": "3854314",
            "problem": "带有醚侧链的芳香族酰胺是在定量构效关系 (QSAR) 中用于理解一维分子描述符的广泛使用的测试案例。考虑分子 4-(2-甲氧基乙氧基)-N-乙基苯甲酰胺，它可以用简化分子线性输入规范 (SMILES) 字符串 \"COCCOc1ccc(C(=O)NCC)cc1\" 表示。其核心是一个带有两个对位取代基的苯环：一个酰胺基和一个 2-甲氧基乙氧基。酰胺取代基是一个带有 N-乙基侧链的苯甲酰胺，即一个芳香族酰基 $-\\mathrm{C(=O)}-$ 连接到 $-\\mathrm{NH}-\\mathrm{CH_{2}}-\\mathrm{CH_{3}}$ 上。醚取代基是 $-\\mathrm{O}-\\mathrm{CH_{2}}-\\mathrm{CH_{2}}-\\mathrm{O}-\\mathrm{CH_{3}}$，通过氧原子连接到环上。\n\n使用以下基于化学图论和共振限制的标准可旋转键规则，计算可旋转键计数 (RBC)，然后从统计力学的角度简要解释这个一维描述符如何与构象灵活性和熵相关联：\n- 可旋转键是任意两个非氢原子之间的单键。\n- 排除环内的任何键。\n- 排除因酰胺官能团中强 $\\pi$-共振而导致旋转受限的任何单键，特指 $-\\mathrm{C(=O)}-\\mathrm{NH}-$ 中的酰胺 $\\mathrm{C}-\\mathrm{N}$ 键。\n- 与氢原子相连的键不予考虑。\n- 诸如 $\\mathrm{Ar}-\\mathrm{C(=O)}$ 和 $\\mathrm{Ar}-\\mathrm{O}$ 之类的单键应根据上述规则处理（它们是单键、环外键、连接非氢原子的键，并且本身不是酰胺 $\\mathrm{C}-\\mathrm{N}$ 键）。\n\n您的答案必须是等于该分子 RBC 的单个整数。无需四舍五入，也无需报告单位。在您的解释中，请使用玻尔兹曼框架将 RBC 与构象熵联系起来，不要使用任何经验性简化公式；重点关注可旋转单键的数量与在温度 $T$ 下可及的扭转微观态数量之间的概念性联系。",
            "solution": "首先验证问题的科学性和逻辑完整性。\n\n**步骤 1：提取已知信息**\n- **分子名称**：4-(2-甲氧基乙氧基)-N-乙基苯甲酰胺\n- **SMILES 字符串**：`COCCOc1ccc(C(=O)NCC)cc1`\n- **结构**：一个带有两个对位取代基的苯环：一个酰胺基 (`-C(=O)NHCH2CH3`) 和一个 2-甲氧基乙氧基 (`-OCH2CH2OCH3`)。\n- **任务**：计算可旋转键计数 (RBC) 并从统计力学角度解释其与构象熵的关系。\n- **可旋转键计数 (RBC) 规则**：\n    1. 可旋转键是任意两个非氢原子之间的单键。\n    2. 排除环内的任何键。\n    3. 排除因酰胺官能团中强 $\\pi$-共振而导致旋转受限的任何单键，特指 $-\\mathrm{C(=O)}-\\mathrm{NH}-$ 中的酰胺 $\\mathrm{C}-\\mathrm{N}$ 键。\n    4. 与氢原子相连的键不予考虑。\n    5. 诸如 $\\mathrm{Ar}-\\mathrm{C(=O)}$ 和 $\\mathrm{Ar}-\\mathrm{O}$ 之类的单键如果满足其他标准，则是可旋转的。\n\n**步骤 2：使用提取的已知信息进行验证**\n该问题具有科学依据，提法明确且客观。该分子在化学上是有效的，其结构与提供的名称和 SMILES 字符串一致。计算可旋转键计数的规则在计算化学和 QSAR 领域是明确且标准的。任务的第二部分要求基于统计力学的基本原理（玻尔兹曼熵公式）进行概念性解释，这是物理化学中的一个标准且可验证的主题。该问题不包含科学缺陷、歧义或矛盾。\n\n**步骤 3：结论与行动**\n该问题被判定为**有效**。将提供解答。\n\n**第 1 部分：计算可旋转键计数 (RBC)**\n\n为了计算 RBC，我们将系统地分析分子 4-(2-甲氧基乙氧基)-N-乙基苯甲酰胺（其结构为 `CH3-O-CH2-CH2-O-C6H4-C(=O)-NH-CH2-CH3`）中非氢原子之间的单键。我们对每个键应用给定的规则。\n\n该分子可以分解为其组成部分：2-甲氧基乙氧基侧链、苯环和 N-乙基苯甲酰胺侧链。\n\n1.  **连接到苯环上的 2-甲氧基乙氧基侧链 (`CH3-O-CH2-CH2-O-`)：**\n    - `CH3-O` 键：这是一个连接两个非氢原子的单键，不在环内。它是可旋转的。（计数 = $1$）\n    - `O-CH2` 键：这是一个连接两个非氢原子的单键，不在环内。它是可旋转的。（计数 = $2$）\n    - `CH2-CH2` 键：这是一个连接两个非氢原子的单键，不在环内。它是可旋转的。（计数 = $3$）\n    - `CH2-O` 键：这是一个连接两个非氢原子的单键，不在环内。它是可旋转的。（计数 = $4$）\n    - `O-芳香环C` 键（连接到环的醚键）：这是一个连接两个非氢原子的单键，不在环内，且不是酰胺 `C-N` 键。它是可旋转的。（计数 = $5$）\n\n2.  **苯环本身：**\n    - 苯环内的所有 `C-C` 键都是环系统的一部分，根据规则被明确排除。（不增加计数）\n\n3.  **连接到苯环上的 N-乙基苯甲酰胺侧链 (`-C(=O)-NH-CH2-CH3`)：**\n    - `芳香环C-C(=O)` 键（羰基与环的连接键）：这是一个连接两个非氢原子的单键，不在环内，且不是酰胺 `C-N` 键。它是可旋转的。（计数 = $6$）\n    - `C(=O)-N` 键（酰胺键）：由于 π-共振（`O=C-N \\leftrightarrow ^{-}O-C=N^{+}`），该单键具有显著的双键性质。这限制了旋转，因此根据规则被明确排除。（不增加计数）\n    - `N-CH2` 键：这是一个连接两个非氢原子的单键，不在环内，且不是受限的酰胺 `C-N` 键。它是可旋转的。（计数 = $7$）\n    - `CH2-CH3` 键：这是一个连接两个非氢原子的单键，不在环内。它是可旋转的。（计数 = $8$）\n\n将这些计数相加，得到总的可旋转键计数 (RBC)。\n总 RBC = $1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 = 8$。\n\n**第 2 部分：RBC 与构象熵之间的关系**\n\n可旋转键计数 (RBC) 与构象熵之间的关系植根于统计力学的原理，特别是玻尔兹曼熵公式。\n\n根据统计力学，一个系统的熵 $S$ 通过玻尔兹曼方程与热力学可及的微观态数量 $W$ 相关：\n$$S = k_B \\ln(W)$$\n其中 $k_B$ 是玻尔兹曼常数。一个微观态代表了系统的一个特定组态（在此案例中，是分子的一个特定构象）。\n\n构象熵 $S_{conf}$ 是总熵中源于分子结构柔性的那部分，即分子通过围绕单键旋转而采取不同空间排列的能力。RBC 是对此类内旋转自由度数量的直接度量。\n\n对于单个可旋转键，分子可以存在于几种低能扭转状态或“旋转异构体”中（例如，像反式、邻位+ 和 邻位- 这样的交叉构象）。我们将第 $i$ 个可旋转键的不同、可及的旋转异构体状态数表示为 $n_i$。这些状态的可及性取决于在给定绝对温度 $T$ 下，可用于克服旋转能垒的热能 $k_B T$。\n\n如果我们做一个简化假设，即围绕不同单键的旋转是相互独立的，那么整个分子的可及构象微观态总数 $W_{conf}$ 是每个单独可旋转键的可用状态数的乘积：\n$$W_{conf} = \\prod_{i=1}^{RBC} n_i$$\n为了说明这种概念性联系，可以进一步近似，认为每个可旋转键贡献大致相同数量的可及状态，记为 $n$。在这种情况下，总构象数随 RBC 呈指数增长：\n$$W_{conf} \\approx n^{RBC}$$\n例如，一个常见的近似是 $n=3$，代表反式和两个邻位构象。\n\n将 $W_{conf}$ 的这个表达式代入玻尔兹曼方程，得到构象熵：\n$$S_{conf} = k_B \\ln(W_{conf}) \\approx k_B \\ln(n^{RBC})$$\n$$S_{conf} \\approx (RBC) \\cdot k_B \\ln(n)$$\n这个最终表达式显示了构象熵 $S_{conf}$ 与可旋转键计数 (RBC) 之间存在直接的、近似线性的关系。更高的 RBC 意味着更多的内旋转轴，从而导致可能构象的数量（$W_{conf}$）呈指数级增长。这种更大的构象“无序度”或灵活性被量化为更高的构象熵。因此，RBC 是一个简单而强大的分子描述符，它与分子的构象灵活性及其对系统熵的贡献相关。",
            "answer": "$$\\boxed{8}$$"
        },
        {
            "introduction": "从单个描述符转向更全面的表示方法，我们现在将探索分子指纹，它将分子结构编码为高维位向量。本练习聚焦于一个核心应用：量化分子间的相似性，这是虚拟筛选和化合物库设计的基石。通过推导和比较 Tanimoto 和 Dice 两种相似性系数，您将学习到不同的数学定义如何导致不同的相似性评估结果，这在实际的化学信息学工作流程中是一个至关重要的考量。",
            "id": "3854355",
            "problem": "考虑用于定量构效关系 (QSAR) 模型的两个小分子，每个分子都被编码为 $1024$ 位的扩展连接性指纹 (ECFP)。设分子 A 中值为 $1$ 的比特位集合表示为 $A \\subset \\{1,\\dots,1024\\}$，分子 B 的表示为 $B \\subset \\{1,\\dots,1024\\}$。根据经验，观察到以下基数：$|A|=a=100$，$|B|=b=120$ 和 $|A \\cap B|=c=80$。在化学信息学中，二元指纹之间的基于集合的相似性度量是根据集合论的第一性原理定义的。Tanimoto 相似性（也称为 Jaccard 指数）定义为交集基数与并集基数之比，而 Dice 相似性（也称为 Sørensen–Dice 系数）定义为交集基数的两倍除以各个集合基数之和。\n\n从集合论恒等式 $|A \\cup B|=|A|+|B|-|A \\cap B|$ 出发，推导出 Tanimoto 相似性和 Dice 相似性关于 $a$、$b$ 和 $c$ 的表达式，用给定值计算它们，然后计算差值 $D - T$。将 $D - T$ 的最终答案以单个简化的解析表达式的精确形式表示。此外，在你的推导中解释为什么这两个度量不同，以及在 QSAR 的二元指纹背景下，这种差异是如何从它们的定义中产生的。",
            "solution": "我们从用于定量构效关系 (QSAR) 建模中二元分子指紋的相似性度量的基础集合论定义开始。每个分子的指紋是一个二元向量，值为 $1$ 的比特位对应于分子中存在的特征。集合 $A$ 和 $B$ 分别代表分子 A 和分子 B 中已设置比特（值为1的比特）的索引。交集 $A \\cap B$ 代表共享的特征，而并集 $A \\cup B$ 代表至少存在于一个分子中的特征。\n\nTanimoto 相似性，即 Jaccard 指数，根据第一性原理定义为共享特征数与唯一特征总数之比。用集合论的术语来说，即\n$$\nT \\equiv \\frac{|A \\cap B|}{|A \\cup B|}.\n$$\n使用恒等式\n$$\n|A \\cup B| = |A| + |B| - |A \\cap B|,\n$$\n我们可以用基数 $a$、$b$ 和 $c$ 来表示 $T$ 为\n$$\nT = \\frac{c}{a + b - c}.\n$$\n\nDice 相似性，也称为 Sørensen–Dice 系数，通过相对于两个集合的总大小来缩放交集，从而强调交集。其集合论定义为\n$$\nD \\equiv \\frac{2|A \\cap B|}{|A| + |B|},\n$$\n用 $a$、$b$ 和 $c$ 表示则为\n$$\nD = \\frac{2c}{a + b}.\n$$\n\n现在我们代入给定值 $a=100$，$b=120$ 和 $c=80$。\n\n对于 Tanimoto 相似性，\n$$\nT = \\frac{c}{a + b - c} = \\frac{80}{100 + 120 - 80} = \\frac{80}{140} = \\frac{4}{7}.\n$$\n\n对于 Dice 相似性，\n$$\nD = \\frac{2c}{a + b} = \\frac{160}{220} = \\frac{16}{22} = \\frac{8}{11}.\n$$\n\n所要求的最终量是差值 $D - T$。以精确形式计算此差值：\n$$\nD - T = \\frac{8}{11} - \\frac{4}{7}.\n$$\n使用通分来简化：\n$$\n\\frac{8}{11} - \\frac{4}{7} = \\frac{8 \\cdot 7}{77} - \\frac{4 \\cdot 11}{77} = \\frac{56 - 44}{77} = \\frac{12}{77}.\n$$\n因此，差值的精确简化表达式为\n$$\nD - T = \\frac{12}{77}.\n$$\n\n从定义推导出的差异解释：Tanimoto 相似性 $T$ 通过并集 $|A \\cup B|$ 来归一化交集 $|A \\cap B|$，这将不匹配的特征作为 $a + b - c$ 包含在分母中，从而对其进行惩罚。Dice 相似性 $D$ 通过和 $a + b$ 来归一化交集，并将交集加倍，从而有效地给予共享特征相对于总特征更大的权重。因为当 $c>0$ 时，$|A \\cup B| = a + b - c$ 严格小于 $a + b$，Dice 的分母更大，而其分子是 $2c$，这使得对于非平凡的重叠，$D$ 通常大于 $T$。在本例中，差值 $D - T = \\frac{12}{77}$ 的产生是因为 Dice 通过因子 $2$ 对交集给予了额外的强调，并且其分母中没有减去 $c$。在采用二元指纹的 QSAR 筛选中，这意味着 Dice 对共享比特更敏感，可能会将具有显著重叠的分子对的排名排在 Tanimoto 之前，这可能会影响命中富集度和阈值选择，具体取决于在奖励重叠和惩罚不匹配之间所期望的平衡。",
            "answer": "$$\\boxed{\\frac{12}{77}}$$"
        },
        {
            "introduction": "在真实的 QSAR 研究中，我们经常面对包含大量化合物和数十甚至数百个描述符的数据集，从而形成一个高维数据空间。这最后一个实践介绍了主成分分析（Principal Component Analysis, PCA），这是一种应对这种复杂性的基本方法，它通过降维来揭示潜在的数据模式。从第一性原理出发实现 PCA，将使您深刻理解如何将复杂的描述符数据转换为可解释的可视化和模型，这是任何计算化学生物学家都必须具备的关键技能。",
            "id": "3854316",
            "problem": "给定用于定量构效关系（QSAR）研究的小型、标准化的分子描述符矩阵，这些矩阵代表了不同的化合物集合。您需要完全从第一性原理出发执行主成分分析（PCA），具体步骤包括：计算标准化描述符的样本协方差矩阵的特征分解，将样本投影到前两个主成分上，并解释成分载荷。\n\n使用的基本定义和事实：\n- 标准化描述符排列在一个矩阵 $Z \\in \\mathbb{R}^{n \\times p}$ 中，其各列（描述符）在样本间的均值为零。样本协方差矩阵定义为 $$C = \\frac{1}{n-1} Z^\\top Z.$$\n- 主成分分析（PCA）旨在寻找一组标准正交方向（主轴）$v_1, v_2, \\dots, v_p \\in \\mathbb{R}^p$，这些方向在单位长度约束下能够最大化投影数据的方差。对于第一个主成分方向 $v_1$，这等价于在约束 $\\|v\\|_2 = 1$ 下最大化瑞利商 $v^\\top C v$，其解表明 $v_1$ 是 $C$ 对应于最大特征值 $\\lambda_1$ 的特征向量。后续的主成分 $v_2, \\dots$ 在正交性约束下可类似求得。\n- 给定特征分解 $$C = V \\Lambda V^\\top,$$ 其中 $V$ 是标准正交矩阵，$\\Lambda = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_p)$ 的对角元素已排序，满足 $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_p \\ge 0$，样本在前两个主成分上的投影（得分）为 $$T_{(2)} = Z \\, V_{(2)},$$ 其中 $V_{(2)}$ 包含前两个特征向量作为其列。前两个成分的成分载荷定义为 $$L_{(2)} = V_{(2)} \\, \\mathrm{diag}\\!\\big(\\sqrt{\\lambda_1}, \\sqrt{\\lambda_2}\\big).$$\n- 主成分 $j$ 的方差解释率 $r_j$ 为 $$r_j = \\frac{\\lambda_j}{\\sum_{k=1}^{p} \\lambda_k}.$$\n\n您的程序必须：\n1. 对于每个给定的测试用例，计算样本协方差 $C$ 及其特征值和特征向量，将特征值按降序排序并相应地排列特征向量，从而得到前两个特征值 $[\\lambda_1, \\lambda_2]$、前两个特征向量 $V_{(2)}$、得分 $T_{(2)}$ 和载荷 $L_{(2)}$。\n2. 解释载荷：对于前两个主成分中的每一个，识别出具有最大绝对载荷的描述符的索引（使用从0开始的索引）。即，对于成分 $j \\in \\{1,2\\}$，返回 $$\\arg\\max_{i \\in \\{0,\\dots,p-1\\}} |L_{(2)}[i,j-1]|.$$\n3. 计算方差解释率 $[r_1, r_2]$。\n4. 对于每个测试用例，返回一个包含以下内容的嵌套列表：\n   - 前两个特征值 $[\\lambda_1, \\lambda_2]$，\n   - 方差解释率 $[r_1, r_2]$，\n   - 对前两个成分具有最大绝对载荷的描述符的索引 $[\\mathrm{idx}_1, \\mathrm{idx}_2]$，\n   - 第一个样本的二维投影（得分）$[t_{1,1}, t_{1,2}]$，其中 $t_{1,j}$ 是第一个样本在成分 $j$ 上的得分。\n\n所有浮点数输出必须四舍五入到 $6$ 位小数。所有描述符索引必须是通过 $0$ 基索引的整数。最终输出必须是单行文本，将所有测试用例的结果汇总到一个列表中，不含任何空格，例如 $$\\big[\\text{case}_1,\\text{case}_2,\\text{case}_3\\big],$$ 其中每个 $\\text{case}_k$ 是上述嵌套列表。\n\n测试套件（每个 $Z^{(k)}$ 已按描述符标准化为零均值）：\n- 用例 $1$： $$Z^{(1)} = \\begin{bmatrix}\n-1.2  -1.0  \\phantom{-}0.8  \\phantom{-}0.5 \\\\\n\\phantom{-}0.4  \\phantom{-}0.3  -0.6  -0.2 \\\\\n\\phantom{-}0.8  \\phantom{-}0.9  -0.7  \\phantom{-}0.1 \\\\\n-0.5  -0.7  \\phantom{-}0.9  -0.4 \\\\\n\\phantom{-}0.3  \\phantom{-}0.4  -0.2  \\phantom{-}0.0 \\\\\n\\phantom{-}0.2  \\phantom{-}0.1  -0.2  \\phantom{-}0.0 \\\\\n\\end{bmatrix}.$$\n- 用例 $2$（边界条件，前两个描述符之间存在完全共线性）： $$Z^{(2)} = \\begin{bmatrix}\n-1.5  -3.0  \\phantom{-}0.6 \\\\\n-0.5  -1.0  -0.2 \\\\\n\\phantom{-}0.5  \\phantom{-}1.0  -0.1 \\\\\n\\phantom{-}1.0  \\phantom{-}2.0  -0.2 \\\\\n\\phantom{-}0.5  \\phantom{-}1.0  -0.1 \\\\\n\\end{bmatrix}.$$\n- 用例 $3$（边缘情况，存在一个零方差描述符）： $$Z^{(3)} = \\begin{bmatrix}\n\\phantom{-}0.5  -0.3  \\phantom{-}0.0  \\phantom{-}0.7 \\\\\n-0.5  \\phantom{-}0.3  \\phantom{-}0.0  -0.7 \\\\\n\\phantom{-}0.4  -0.2  \\phantom{-}0.0  \\phantom{-}0.6 \\\\\n-0.4  \\phantom{-}0.2  \\phantom{-}0.0  -0.6 \\\\\n\\end{bmatrix}.$$\n\n您的程序应生成单行输出，其中包含三个用例的结果列表，每个用例表示为一个嵌套列表 $[\\,[\\lambda_1,\\lambda_2],[r_1,r_2],[\\mathrm{idx}_1,\\mathrm{idx}_2],[t_{1,1},t_{1,2}]\\,]$，所有浮点数四舍五入到 $6$ 位小数，且整行中没有任何空格。计算不涉及角度，因此不需要角度单位，并且方差解释率必须以小数形式表示。",
            "solution": "问题陈述已经过分析，并被确定为有效。它在科学上基于线性代数和多元统计学的原理，特别是主成分分析（PCA），并将其应用于计算化学生物学（QSAR）中的一个相关问题。该问题是适定的（well-posed），提供了计算唯一且可验证解所需的所有必要数据和定义。测试用例包括标准、共线性和零方差情景，这些都适合用于评估一个稳健的实现。\n\n任务是从第一性原理出发，对给定的标准化分子描述符矩阵（$Z$）执行PCA。这包括计算样本协方差矩阵（$C$），对其进行特征分解以找到主成分，然后计算得分、载荷和方差解释率等派生量。\n\nPCA的核心在于找到一组新的正交轴（即主成分），这些轴与数据中方差最大的方向对齐。对于一个包含 $n$ 个样本和 $p$ 个描述符的数据矩阵 $Z \\in \\mathbb{R}^{n \\times p}$，其中每个描述符（列）都已中心化以具有零均值，样本协方差矩阵由以下公式给出：\n$$C = \\frac{1}{n-1} Z^\\top Z$$\n主成分是此协方差矩阵 $C$ 的特征向量。设 $C$ 的特征分解为 $C = V \\Lambda V^\\top$，其中 $V$ 是一个标准正交矩阵，其列 $v_j$ 是特征向量，$\\Lambda$ 是一个由相应特征值 $\\lambda_j$ 构成的对角矩阵。特征值按降序排序，$\\lambda_1 \\geq \\lambda_2 \\geq \\dots \\geq \\lambda_p \\geq 0$，因此第一个特征向量 $v_1$ 对应于数据中方差最大的方向。\n\n每个主成分 $j$ 捕获的方差量由其特征值 $\\lambda_j$ 给出。方差解释率 $r_j$ 通过将此值除以数据中的总方差（即所有特征值的总和，等于 $C$ 的迹）来进行归一化：\n$$r_j = \\frac{\\lambda_j}{\\sum_{k=1}^{p} \\lambda_k}$$\n\n原始数据可以投影到由主成分定义的新坐标系上。得到的坐标称为得分。前两个主成分的得分是通过将数据矩阵 $Z$ 投影到前两个特征向量 $V_{(2)} = [v_1, v_2]$ 上来计算的：\n$$T_{(2)} = Z V_{(2)}$$\n\n成分载荷用于衡量原始描述符和主成分之间的相关性，前两个成分的载荷通过以下公式计算：\n$$L_{(2)} = V_{(2)} \\mathrm{diag}(\\sqrt{\\lambda_1}, \\sqrt{\\lambda_2})$$\n载荷值的大小表示相应原始描述符在定义该主成分时的重要性。因此，对于前两个主成分中的每一个，我们识别出具有最大绝对载荷的描述符，以解释哪个原始变量对其贡献最大。\n\n为每个测试用例实现的总体算法如下：\n1.  给定具有 $n$ 个样本和 $p$ 个描述符的标准化描述符矩阵 $Z$。\n2.  计算 $p \\times p$ 的样本协方差矩阵 $C = \\frac{1}{n-1}Z^\\top Z$。\n3.  计算 $C$ 的特征值和特征向量。适用于对称矩阵的数值例程，例如 `numpy.linalg.eigh`，是合适的，因为它能保证得到实数特征值和标准正交的特征向量。\n4.  将特征值按降序排序，并相应地排列特征向量。设排序后的特征值为 $[\\lambda_1, \\lambda_2, \\dots, \\lambda_p]$，对应的特征向量矩阵为 $V=[v_1, v_2, \\dots, v_p]$。\n5.  提取前两个特征值 $[\\lambda_1, \\lambda_2]$ 和前两个特征向量，构成矩阵 $V_{(2)} = [v_1, v_2]$。\n6.  使用总方差 $\\sum_{k=1}^{p} \\lambda_k$ 计算方差解释率 $[r_1, r_2]$。\n7.  计算成分载荷 $L_{(2)} = V_{(2)} \\mathrm{diag}(\\sqrt{\\lambda_1}, \\sqrt{\\lambda_2})$。\n8.  对于这两个成分中的每一个，找到具有最大绝对载荷的描述符的基于 $0$ 的索引：$[\\arg\\max_i |L_{(2)}[i,0]|, \\arg\\max_i |L_{(2)}[i,1]|]$。\n9.  通过计算矩阵乘积 $T_{(2)} = Z V_{(2)}$ 的第一行，来计算第一个样本（$Z$ 的第一行）在前两个主成分上的得分。\n10. 将这些结果——$[\\lambda_1, \\lambda_2]$、$[r_1, r_2]$、两个索引以及第一个样本的两个得分——汇总到一个嵌套列表中。所有浮点值都四舍五入到 $6$ 位小数。\n\n此过程将应用于所有提供的测试用例。完全共线性（用例2）和零方差描述符（用例3）的特殊情况将由特征分解正确处理，其会产生零特征值，反映协方差矩阵的秩亏损。最终输出是一个单行字符串，表示所有测试用例结果的列表，不含多余字符或空格。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        np.array([\n            [-1.2, -1.0, 0.8, 0.5],\n            [0.4, 0.3, -0.6, -0.2],\n            [0.8, 0.9, -0.7, 0.1],\n            [-0.5, -0.7, 0.9, -0.4],\n            [0.3, 0.4, -0.2, 0.0],\n            [0.2, 0.1, -0.2, 0.0]\n        ]),\n        np.array([\n            [-1.5, -3.0, 0.6],\n            [-0.5, -1.0, -0.2],\n            [0.5, 1.0, -0.1],\n            [1.0, 2.0, -0.2],\n            [0.5, 1.0, -0.1]\n        ]),\n        np.array([\n            [0.5, -0.3, 0.0, 0.7],\n            [-0.5, 0.3, 0.0, -0.7],\n            [0.4, -0.2, 0.0, 0.6],\n            [-0.4, 0.2, 0.0, -0.6]\n        ])\n    ]\n\n    results = []\n    for Z in test_cases:\n        case_result = perform_pca(Z)\n        results.append(case_result)\n    \n    # Format the final output string to remove all spaces as per the requirement.\n    # str(list) creates a string representation like '[item1, item2, ...]'\n    # replace(' ', '') removes the spaces after commas and inside lists.\n    final_output_string = str(results).replace(' ', '')\n    print(final_output_string)\n\ndef perform_pca(Z):\n    \"\"\"\n    Performs PCA on a given standardized data matrix Z.\n\n    Args:\n        Z (np.ndarray): The n x p standardized descriptor matrix.\n\n    Returns:\n        list: A nested list containing PCA results for the first two components.\n              [[lambda1, lambda2], [r1, r2], [idx1, idx2], [t11, t12]]\n    \"\"\"\n    n, p = Z.shape\n    \n    # 1. Compute the sample covariance matrix C\n    # The definition is C = 1/(n-1) * Z^T * Z\n    C = (Z.T @ Z) / (n - 1)\n\n    # 2. Perform eigendecomposition of C\n    # np.linalg.eigh is for Hermitian (symmetric) matrices and returns eigenvalues\n    # in ascending order.\n    eigenvalues, eigenvectors = np.linalg.eigh(C)\n\n    # 3. Sort eigenvalues and eigenvectors in descending order\n    sort_indices = np.argsort(eigenvalues)[::-1]\n    sorted_eigenvalues = eigenvalues[sort_indices]\n    sorted_eigenvectors = eigenvectors[:, sort_indices]\n\n    # 4. Extract first two eigenvalues and eigenvectors\n    lambda12 = sorted_eigenvalues[0:2]\n    V2 = sorted_eigenvectors[:, 0:2]\n\n    # 5. Compute explained variance ratios\n    total_variance = np.sum(sorted_eigenvalues)\n    # Handle division by zero for cases where total variance is zero\n    if total_variance > 0:\n        ratios = lambda12 / total_variance\n    else:\n        ratios = np.zeros(2)\n\n    # 6. Compute scores for the first sample\n    # T2 = Z @ V2\n    # first_sample_scores = T2[0, :]\n    first_sample_scores = Z[0, :] @ V2\n\n    # 7. Compute loadings and find indices of max absolute loading\n    # L2 = V2 @ diag(sqrt(lambda12))\n    # We must handle potentially negative eigenvalues from numerical errors, although\n    # covariance matrices are positive semidefinite. Taking abs() before sqrt is safe.\n    sqrt_lambda12 = np.sqrt(np.abs(lambda12))\n    L2 = V2 @ np.diag(sqrt_lambda12)\n    \n    max_loadings_indices = [int(np.argmax(np.abs(L2[:, 0]))), int(np.argmax(np.abs(L2[:, 1])))]\n\n    # 8. Assemble results and round floats to 6 decimal places\n    result = [\n        [round(val, 6) for val in lambda12],\n        [round(val, 6) for val in ratios],\n        max_loadings_indices,\n        [round(val, 6) for val in first_sample_scores]\n    ]\n\n    return result\n\nsolve()\n```"
        }
    ]
}