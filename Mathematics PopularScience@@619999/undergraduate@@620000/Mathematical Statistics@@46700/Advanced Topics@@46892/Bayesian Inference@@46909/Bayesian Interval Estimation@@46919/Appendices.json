{"hands_on_practices": [{"introduction": "Our first practice exercise provides a clear and intuitive entry point into Bayesian reasoning by exploring a parameter with a finite set of possible values. Here, we investigate the unknown number of faces on a special die, a classic problem that illuminates the core mechanics of Bayesian updates. By calculating the posterior probability for each potential value and constructing a \"credible set,\" you will gain a hands-on understanding of how prior knowledge is formally combined with observed data. [@problem_id:1899362]", "problem": "A board game enthusiast acquires a collection of custom-made dice. One of these dice is known to have a number of faces $N$ from the set $\\mathcal{S} = \\{4, 6, 8, 10, 12, 20\\}$. The faces of the die are labeled with integers from $1$ to $N$. Lacking any specific information about the die's origin, the enthusiast assumes a discrete uniform prior distribution for $N$ over the set $\\mathcal{S}$.\n\nTo investigate the value of $N$, the die is rolled $k=5$ times, and the outcomes are recorded. The maximum value observed among these five rolls is found to be $M=8$.\n\nBased on this observation, determine the smallest set of possible values for $N$ whose total posterior probability is at least 0.90. Choose your answer from the options below.\n\nA. $\\{8\\}$\n\nB. $\\{8, 10\\}$\n\nC. $\\{8, 10, 12\\}$\n\nD. $\\{10, 12, 20\\}$\n\nE. $\\{4, 6, 8, 10, 12, 20\\}$", "solution": "The problem asks for the smallest 90% credible set for the unknown number of faces, $N$, of a die.\n\n**1. Define the components of the Bayesian model:**\n\n*   **Parameter Space:** The possible values for the number of faces $N$ are given by the set $\\mathcal{S} = \\{4, 6, 8, 10, 12, 20\\}$.\n*   **Prior Distribution:** The prior belief is that each value of $N$ in $\\mathcal{S}$ is equally likely. Since there are 6 possible values, the prior probability for each is:\n    $$P(N=n) = \\pi(n) = \\frac{1}{6} \\quad \\text{for } n \\in \\mathcal{S}$$\n*   **Data:** The experiment consists of $k=5$ rolls, and the observed data is that the maximum roll is $M=8$.\n*   **Likelihood Function:** The likelihood, $L(n | M=8)$, is the probability of observing the data ($M=8$) given a specific value of the parameter ($N=n$). Let $X_1, \\dots, X_5$ be the outcomes of the 5 rolls. The rolls are independent and uniformly distributed on $\\{1, \\dots, n\\}$.\n    The probability that a single roll $X_i$ is less than or equal to $m$ is $P(X_i \\leq m | N=n) = m/n$.\n    The probability that the maximum of 5 rolls is less than or equal to $m$ is the probability that all 5 rolls are less than or equal to $m$:\n    $$P(M \\leq m | N=n) = P(X_1 \\leq m, \\dots, X_5 \\leq m | N=n) = \\prod_{i=1}^{5} P(X_i \\leq m | N=n) = \\left(\\frac{m}{n}\\right)^5$$\n    The probability that the maximum roll is exactly $m$ is given by:\n    $$P(M=m | N=n) = P(M \\leq m | N=n) - P(M \\leq m-1 | N=n)$$\n    Substituting $m=8$ and $k=5$, our likelihood function is:\n    $$L(n | M=8) = P(M=8 | N=n) = \\left(\\frac{8}{n}\\right)^5 - \\left(\\frac{7}{n}\\right)^5 = \\frac{8^5 - 7^5}{n^5}$$\n    This likelihood is only defined for $n \\geq 8$. If $n < 8$, it is impossible to roll an 8, so the likelihood is 0.\n\n**2. Calculate the Posterior Distribution:**\n\nThe posterior probability $P(N=n | M=8)$ is proportional to the product of the likelihood and the prior, according to Bayes' theorem:\n$$P(N=n | M=8) \\propto P(M=8 | N=n) \\times P(N=n)$$\nSince the prior $P(N=n) = 1/6$ is constant for all $n \\in \\mathcal{S}$, the posterior is directly proportional to the likelihood:\n$$P(N=n | M=8) \\propto L(n | M=8)$$\n\nWe calculate the likelihood for each possible value of $N$:\n\n*   For $N=4$ and $N=6$: It is impossible to observe a maximum of 8, so $L(4 | M=8) = 0$ and $L(6 | M=8) = 0$. The posterior probabilities for these values are also 0.\n*   For $N \\in \\{8, 10, 12, 20\\}$, the likelihood is non-zero. Let's calculate the term $8^5 - 7^5 = 32768 - 16807 = 15961$.\n    The likelihoods are proportional to $1/n^5$:\n    *   $L(8 | M=8) = \\frac{15961}{8^5} = \\frac{15961}{32768} \\approx 0.48709$\n    *   $L(10 | M=8) = \\frac{15961}{10^5} = \\frac{15961}{100000} = 0.15961$\n    *   $L(12 | M=8) = \\frac{15961}{12^5} = \\frac{15961}{248832} \\approx 0.06414$\n    *   $L(20 | M=8) = \\frac{15961}{20^5} = \\frac{15961}{3200000} \\approx 0.00499$\n\n**3. Normalize the Posterior:**\n\nTo find the actual posterior probabilities, we must normalize so that they sum to 1. Let $K$ be the sum of the unnormalized posterior values (which are proportional to the likelihoods).\n$$K = L(8) + L(10) + L(12) + L(20) \\approx 0.48709 + 0.15961 + 0.06414 + 0.00499 \\approx 0.71583$$\nNow we compute the normalized posterior probabilities:\n*   $P(N=8 | M=8) = \\frac{L(8)}{K} \\approx \\frac{0.48709}{0.71583} \\approx 0.6804$\n*   $P(N=10 | M=8) = \\frac{L(10)}{K} \\approx \\frac{0.15961}{0.71583} \\approx 0.2230$\n*   $P(N=12 | M=8) = \\frac{L(12)}{K} \\approx \\frac{0.06414}{0.71583} \\approx 0.0896$\n*   $P(N=20 | M=8) = \\frac{L(20)}{K} \\approx \\frac{0.00499}{0.71583} \\approx 0.0070$\n\nThe sum of these probabilities is approximately $0.6804 + 0.2230 + 0.0896 + 0.0070 = 1.0000$.\n\n**4. Construct the Credible Set:**\n\nTo find the smallest 90% credible set, we rank the values of $N$ by their posterior probability (from highest to lowest) and add them to our set until the cumulative probability is at least 0.90.\n\nThe order of posterior probabilities is: $P(N=8) > P(N=10) > P(N=12) > P(N=20)$.\n\n1.  Start with the most probable value: The set is $\\{8\\}$. The cumulative probability is $\\approx 0.6804$. This is less than 0.90.\n2.  Add the next most probable value: The set is now $\\{8, 10\\}$. The cumulative probability is $\\approx 0.6804 + 0.2230 = 0.9034$.\n\nSince $0.9034 \\geq 0.90$, the set $\\{8, 10\\}$ is a 90% credible set. Because we added values in decreasing order of posterior probability, this is the smallest such set. Any other set of two values would have a lower total probability. For example, the set $\\{8, 12\\}$ has a probability of $0.6804 + 0.0896 = 0.7700$. Therefore, the smallest 90% credible set for $N$ is $\\{8, 10\\}$. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1899362"}, {"introduction": "Having explored a discrete parameter, we now turn to a common scenario involving a continuous parameter: estimating an unknown probability of success. This exercise models the number of attempts needed to pass an exam, a situation well-described by the geometric distribution. You will apply the concept of conjugate priors, where a Beta prior distribution for the probability $p$ combines neatly with the likelihood to yield a Beta posterior, and then determine a 95% credible interval from this posterior. [@problem_id:1899372]", "problem": "A study is conducted to estimate the difficulty of a professional certification exam. The number of attempts, $K$, that a candidate needs to achieve their first pass is modeled by a geometric distribution. The probability mass function for a single candidate taking $k$ attempts is $P(K=k|p) = (1-p)^{k-1}p$, where $p$ is the unknown probability of passing on any given attempt.\n\nIn the study, data is collected from $n=10$ independent candidates. The total number of attempts across all 10 candidates to achieve their respective first pass was found to be 25. Let this total be $S = \\sum_{i=1}^{10} k_i = 25$.\n\nFor a Bayesian analysis of the parameter $p$, a non-informative prior distribution is assumed, specifically a uniform distribution on the interval $[0,1]$.\n\nYour task is to determine the 95% equal-tailed credible interval for the success probability $p$. Report the lower and upper bounds of this interval. Round your answers for the lower and upper bounds to four significant figures.\n\nTo assist in your final calculation, you are provided with several quantile values for a Beta distribution with integer parameters $\\alpha'$ and $\\beta'$. The quantiles are denoted as $Q(\\text{probability}; \\alpha', \\beta')$, where $Q(\\gamma; \\alpha', \\beta')$ is the value $x$ such that the cumulative probability $P(\\text{Beta}(\\alpha', \\beta') \\le x) = \\gamma$. You must first determine the correct parameters for the posterior distribution from your derivation and then use the corresponding values from the list below.\n\n*   $Q(0.025; 10, 15) = 0.2223$, $Q(0.975; 10, 15) = 0.5976$\n*   $Q(0.025; 10, 16) = 0.2144$, $Q(0.975; 10, 16) = 0.5760$\n*   $Q(0.025; 11, 15) = 0.2568$, $Q(0.975; 11, 15) = 0.6136$\n*   $Q(0.025; 11, 16) = 0.2486$, $Q(0.975; 11, 16) = 0.5745$", "solution": "We model each candidate’s number of attempts $K_{i}$ as geometric with parameter $p$ and support $\\{1,2,\\ldots\\}$, so the likelihood for a single observation is\n$$\nP(K_{i}=k_{i}\\mid p)=(1-p)^{k_{i}-1}p.\n$$\nFor $n$ independent candidates with observations $k_{1},\\ldots,k_{n}$, the joint likelihood is\n$$\nL(p\\mid k_{1},\\ldots,k_{n})=\\prod_{i=1}^{n}(1-p)^{k_{i}-1}p\n=p^{n}(1-p)^{\\sum_{i=1}^{n}(k_{i}-1)}\n=p^{n}(1-p)^{S-n},\n$$\nwhere $S=\\sum_{i=1}^{n}k_{i}$ is the total number of attempts.\n\nWith a uniform prior on $[0,1]$, which is $\\mathrm{Beta}(1,1)$, the posterior is proportional to\n$$\np^{n}(1-p)^{S-n}\\cdot p^{1-1}(1-p)^{1-1}=p^{n}(1-p)^{S-n}.\n$$\nRecognizing the Beta kernel, the posterior distribution is\n$$\np\\mid \\text{data}\\sim \\mathrm{Beta}(n+1,\\,S-n+1).\n$$\nWith $n=10$ and $S=25$, this gives\n$$\np\\mid \\text{data}\\sim \\mathrm{Beta}(11,16).\n$$\nA $0.95$ equal-tailed credible interval is given by the $0.025$ and $0.975$ quantiles of $\\mathrm{Beta}(11,16)$. From the provided table,\n$$\nQ(0.025;11,16)=0.2486,\\qquad Q(0.975;11,16)=0.5745.\n$$\nRounding to four significant figures yields the same values. Therefore, the $0.95$ equal-tailed credible interval for $p$ is $\\left[0.2486,\\,0.5745\\right]$.", "answer": "$$\\boxed{\\begin{pmatrix}0.2486 & 0.5745\\end{pmatrix}}$$", "id": "1899372"}, {"introduction": "This final exercise tackles a more advanced, yet powerful, technique used in modern statistical modeling: inference via reparameterization. In many complex analyses, like modeling extreme weather events with the Generalized Extreme Value (GEV) distribution, it is mathematically more convenient to work with a transformed parameter, in this case $\\theta = 1/\\xi$. Your task is to start with a known posterior distribution for the transformed parameter and derive the corresponding credible interval for the original shape parameter $\\xi$, which requires a careful understanding of how non-linear transformations affect intervals. [@problem_id:1899368]", "problem": "An environmental scientist is studying extreme weather events by analyzing a dataset of annual maximum daily rainfall values. These values are assumed to be independent realizations from a Generalized Extreme Value (GEV) distribution. The GEV distribution is characterized by three parameters: location $\\mu$, scale $\\sigma > 0$, and shape $\\xi$. The sign of the shape parameter $\\xi$ is critical: $\\xi > 0$ implies a heavy-tailed (Fréchet-type) distribution, $\\xi < 0$ implies a bounded upper tail (Weibull-type), and $\\xi = 0$ corresponds to a light-tailed (Gumbel-type) distribution.\n\nFor computational convenience and to improve posterior normality, a Bayesian analysis is performed on the transformed parameter $\\theta = 1/\\xi$. From prior hydrological studies in the region, the location and scale parameters are considered known. The analysis yields a posterior probability density function for $\\theta$ that is well-approximated by a Normal distribution with mean $\\theta_0$ and variance $s^2$. You are given that the values of $\\theta_0$ and $s$ are such that the posterior probability of $\\theta$ being non-positive, $P(\\theta \\leq 0 | \\text{data})$, is negligible, ensuring that the tail behavior is decisively of the Fréchet type.\n\nLet $z_{\\beta}$ denote the upper $\\beta$ quantile of the standard normal distribution (i.e., $P(Z > z_{\\beta}) = \\beta$ for a standard normal variable $Z$). Derive a symbolic expression for the lower and upper bounds of the $100(1-\\alpha)\\%$ equal-tailed credible interval for the original shape parameter, $\\xi$. Present the lower and upper bounds as a pair.", "solution": "We are given a posterior for the transformed parameter $\\theta=1/\\xi$ that is well approximated by a Normal distribution with mean $\\theta_{0}$ and variance $s^{2}$, and it satisfies $P(\\theta \\le 0 \\mid \\text{data})$ negligible. This allows us to treat the posterior support as effectively on $\\theta>0$. Let $Z$ denote a standard normal variable and let $z_{\\beta}$ be defined by $P(Z>z_{\\beta})=\\beta$. By symmetry of the standard normal distribution, $P(Z \\le z_{\\beta})=1-\\beta$, so the lower-tail quantile at level $1-\\beta$ is $z_{\\beta}$, and $Q_{Z}(\\alpha/2)=-z_{\\alpha/2}$, $Q_{Z}(1-\\alpha/2)=z_{\\alpha/2}$.\n\nStep 1: Equal-tailed credible interval for $\\theta$. For a Normal posterior $\\theta \\sim \\mathcal{N}(\\theta_{0},s^{2})$, the equal-tailed level $1-\\alpha$ credible interval is\n$$\n\\left[\\,Q_{\\theta}\\!\\left(\\frac{\\alpha}{2}\\right),\\,Q_{\\theta}\\!\\left(1-\\frac{\\alpha}{2}\\right)\\right]\n=\n\\left[\\,\\theta_{0}+s\\,Q_{Z}\\!\\left(\\frac{\\alpha}{2}\\right),\\,\\theta_{0}+s\\,Q_{Z}\\!\\left(1-\\frac{\\alpha}{2}\\right)\\right]\n=\n\\left[\\,\\theta_{0}-z_{\\alpha/2}s,\\,\\theta_{0}+z_{\\alpha/2}s\\right].\n$$\n\nStep 2: Map the interval to $\\xi=1/\\theta$. On the domain $\\theta>0$, the transformation $g(\\theta)=1/\\theta$ is strictly decreasing, since $\\frac{d}{d\\theta}(1/\\theta)=-\\theta^{-2}<0$. For a strictly decreasing transformation, the image of an equal-tailed interval swaps its endpoints:\n$$\n\\left[\\,\\theta_{L},\\,\\theta_{U}\\,\\right]\\;\\mapsto\\;\\left[\\,\\frac{1}{\\theta_{U}},\\,\\frac{1}{\\theta_{L}}\\,\\right].\n$$\nApplying this to $\\theta_{L}=\\theta_{0}-z_{\\alpha/2}s$ and $\\theta_{U}=\\theta_{0}+z_{\\alpha/2}s$ yields the equal-tailed credible interval for $\\xi$:\n$$\n\\left[\\;\\frac{1}{\\theta_{0}+z_{\\alpha/2}s}\\,,\\,\\frac{1}{\\theta_{0}-z_{\\alpha/2}s}\\;\\right],\n$$\nwhich is well-defined under the stated condition that the posterior mass below zero is negligible, ensuring $\\theta_{0}-z_{\\alpha/2}s>0$ for practically relevant $\\alpha$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{\\theta_{0}+z_{\\alpha/2}s} & \\frac{1}{\\theta_{0}-z_{\\alpha/2}s}\\end{pmatrix}}$$", "id": "1899368"}]}