{
    "hands_on_practices": [
        {
            "introduction": "To quantitatively predict the impact of aging on circuit performance, we must begin with a mathematical model that describes the degradation of a single transistor over time. The power-law model is a widely accepted empirical framework for capturing the time evolution of threshold voltage shift, $\\Delta V_{th}$, due to mechanisms like Bias Temperature Instability (BTI). This first exercise provides a direct application of this fundamental model, allowing you to calculate the expected degradation under a constant stress condition, a foundational scenario in reliability analysis. ",
            "id": "4255907",
            "problem": "In reliability-aware Electronic Design Automation (EDA) for integrated circuits, lifetime timing sign-off incorporates device degradation due to Negative Bias Temperature Instability (NBTI) in p-channel metal-oxide-semiconductor (PMOS) transistors. Consider a long-channel PMOS under constant negative stress at gate voltage $V_{G}=-V_{DD}$, at fixed temperature and supply, where recovery is negligible during stress. Under such constant-stress conditions, numerous experiments support a sublinear-in-time growth of interface trap density consistent with diffusion-limited reaction kinetics and dispersive transport. The threshold voltage shift is proportional to the generated interface trap density through the oxide capacitance per unit area. Thus, with the proportionality constant folding in the field and temperature dependence at the stated stress point, the time evolution of the threshold voltage shift may be written as a sublinear power-law in time characterized by an amplitude and an exponent extracted from measurement.\n\nAssume the field- and temperature-calibrated amplitude at this stress point is $A=10\\,\\text{mV}\\,\\text{s}^{-n}$ and the time exponent is $n=0.2$. The transistor is held at constant stress for $t=10^{6}\\,\\text{s}$. Using the physically motivated power-law kinetics for NBTI-induced interface trap build-up and the proportionality of threshold shift to interface trap density, determine the threshold voltage shift $\\Delta V_{th}$ after time $t$.\n\nExpress the final result in volts and round your answer to four significant figures.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. It describes a standard scenario in semiconductor reliability physics, specifically the modeling of Negative Bias Temperature Instability (NBTI). The power-law model for threshold voltage degradation is a widely accepted empirical framework used in the industry for lifetime prediction. All necessary parameters are provided, their values are physically realistic, and their units are dimensionally consistent. Therefore, the problem is valid, and a solution can be determined.\n\nThe problem states that the time evolution of the threshold voltage shift, $\\Delta V_{th}$, follows a sublinear power-law in time, $t$. This relationship is expressed by the equation:\n$$\n\\Delta V_{th}(t) = A \\cdot t^n\n$$\nwhere $A$ is the field- and temperature-dependent amplitude, and $n$ is the time exponent.\n\nThe given parameters are:\n- Amplitude: $A = 10\\,\\text{mV}\\,\\text{s}^{-n}$\n- Time exponent: $n = 0.2$\n- Stress duration: $t = 10^{6}\\,\\text{s}$\n\nWe are asked to calculate the threshold voltage shift $\\Delta V_{th}$ after the specified stress duration. We substitute the given values into the power-law equation.\n\nFirst, let's substitute the numerical value for the exponent $n$:\n$$\nA = 10\\,\\text{mV}\\,\\text{s}^{-0.2}\n$$\nThe equation for $\\Delta V_{th}$ becomes:\n$$\n\\Delta V_{th} = (10\\,\\text{mV}\\,\\text{s}^{-0.2}) \\cdot (t)^{0.2}\n$$\n\nNow, we substitute the value for the time $t = 10^{6}\\,\\text{s}$:\n$$\n\\Delta V_{th} = (10\\,\\text{mV}\\,\\text{s}^{-0.2}) \\cdot (10^{6}\\,\\text{s})^{0.2}\n$$\n\nWe can separate the numerical values and the units. By the rules of exponents, $(x \\cdot y)^a = x^a \\cdot y^a$.\n$$\n\\Delta V_{th} = 10 \\cdot (10^{6})^{0.2} \\,\\,\\, \\text{mV} \\cdot \\text{s}^{-0.2} \\cdot \\text{s}^{0.2}\n$$\nThe units of time cancel out, as expected: $\\text{s}^{-0.2} \\cdot \\text{s}^{0.2} = \\text{s}^{0} = 1$. The resulting unit for $\\Delta V_{th}$ is millivolts ($\\text{mV}$).\n\nNow, we evaluate the numerical part. Using the exponent rule $(x^a)^b = x^{a \\cdot b}$:\n$$\n(10^{6})^{0.2} = 10^{6 \\times 0.2} = 10^{1.2}\n$$\n\nSubstituting this back into the expression for $\\Delta V_{th}$:\n$$\n\\Delta V_{th} = 10 \\cdot 10^{1.2} \\,\\text{mV}\n$$\nUsing the exponent rule $x^a \\cdot x^b = x^{a+b}$:\n$$\n\\Delta V_{th} = 10^{1} \\cdot 10^{1.2} \\,\\text{mV} = 10^{1 + 1.2} \\,\\text{mV} = 10^{2.2} \\,\\text{mV}\n$$\n\nTo obtain the numerical value, we calculate $10^{2.2}$:\n$$\n10^{2.2} = 10^{2} \\cdot 10^{0.2} = 100 \\cdot 10^{1/5} = 100 \\cdot \\sqrt[5]{10}\n$$\nThe value of $\\sqrt[5]{10}$ is approximately $1.58489319$.\n$$\n\\Delta V_{th} \\approx 100 \\cdot 1.58489319 \\,\\text{mV} \\approx 158.489319 \\,\\text{mV}\n$$\n\nThe problem requires the final answer to be expressed in volts ($\\text{V}$) and rounded to four significant figures. First, we convert from millivolts to volts:\n$$\n158.489319 \\,\\text{mV} = 0.158489319 \\,\\text{V}\n$$\nNow, we round this value to four significant figures. The first four significant figures are $1$, $5$, $8$, and $4$. The fifth significant digit is $8$, which is greater than or equal to $5$, so we round up the fourth significant digit.\n$$\n\\Delta V_{th} \\approx 0.1585 \\,\\text{V}\n$$",
            "answer": "$$\n\\boxed{0.1585}\n$$"
        },
        {
            "introduction": "In a functioning integrated circuit, transistors are not subjected to constant stress but are instead switched on and off according to the logic operations being performed. To extend our device-level aging model to the circuit level, we must determine the fraction of time each transistor spends in a stress-inducing state—a quantity known as the stress duty cycle. This practice demonstrates how to connect circuit-level activity, represented by input signal probabilities, to the BTI stress experienced by individual transistors in a standard CMOS NAND gate, a critical step in any aging-aware simulation flow. ",
            "id": "4255944",
            "problem": "Consider a static complementary metal-oxide-semiconductor (CMOS) two-input NAND gate whose pull-up network consists of two parallel p-channel metal-oxide-semiconductor field-effect transistors (PMOS) and whose pull-down network consists of two series n-channel metal-oxide-semiconductor field-effect transistors (NMOS). Let the inputs be binary random variables $A$ and $B$ that take values in $\\{0,1\\}$ under a stationary process with known marginal signal probabilities $P(A=1)$ and $P(B=1)$ and rail-to-rail supply $V_{\\mathrm{DD}}$. In aging-aware Electronic Design Automation (EDA), Bias Temperature Instability (BTI) is assessed through a stress duty cycle defined as the long-run time fraction during which the bias responsible for defect generation is present. For Negative Bias Temperature Instability (NBTI) in PMOS, the stress condition is that the gate-to-source voltage satisfies $V_{gs} < 0$ with magnitude on the order of $V_{\\mathrm{DD}}$, which in static CMOS logic with ideal rails occurs precisely when the PMOS gate is at logic low and its source is tied to $V_{\\mathrm{DD}}$. For Positive Bias Temperature Instability (PBTI) in NMOS, the stress condition is $V_{gs} > 0$, typically occurring when the NMOS gate is at logic high with its source near ground.\n\nUsing first principles of static CMOS gate operation and the probabilistic definition of a duty cycle, formulate how the vector-dependent input states $(A,B)$ induce BTI stress indicators for each individual transistor in the NAND gate. Then, focusing solely on the PMOS devices, derive closed-form expressions for the NBTI stress duty cycles of the PMOS connected to input $A$ and the PMOS connected to input $B$ in terms of the marginal probabilities $P(A=1)$ and $P(B=1)$ only, without assuming any particular correlation structure between $A$ and $B$ beyond stationarity.\n\nYour final answer must be a single analytical expression giving the pair of PMOS duty cycles as a two-entry row vector. No numerical evaluation is required, and no rounding is needed. Express the final pair using $P(A=1)$ and $P(B=1)$.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Gate Type:** Static complementary metal-oxide-semiconductor (CMOS) two-input NAND gate.\n- **Pull-Up Network (PUN):** Two parallel p-channel metal-oxide-semiconductor (PMOS) transistors.\n- **Pull-Down Network (PDN):** Two series n-channel metal-oxide-semiconductor (NMOS) transistors.\n- **Inputs:** Binary random variables $A$ and $B$ taking values in $\\{0, 1\\}$.\n- **Input Process:** Stationary process.\n- **Input Probabilities:** Known marginal signal probabilities $P(A=1)$ and $P(B=1)$.\n- **Supply Voltage:** Rail-to-rail supply $V_{\\mathrm{DD}}$.\n- **Aging Mechanism:** Bias Temperature Instability (BTI).\n- **Stress Duty Cycle:** The long-run time fraction during which the bias responsible for defect generation is present.\n- **Negative Bias Temperature Instability (NBTI) Stress Condition (for PMOS):** Gate-to-source voltage $V_{gs} < 0$, which occurs when the PMOS gate is at logic low and its source is tied to $V_{\\mathrm{DD}}$.\n- **Positive Bias Temperature Instability (PBTI) Stress Condition (for NMOS):** Gate-to-source voltage $V_{gs} > 0$, typically occurring when the NMOS gate is high with its source near ground.\n- **Objective 1:** Formulate how vector-dependent input states $(A,B)$ induce BTI stress indicators for each transistor.\n- **Objective 2:** Derive closed-form expressions for the NBTI stress duty cycles of the two PMOS transistors in terms of $P(A=1)$ and $P(B=1)$ only.\n- **Constraint:** Do not assume any particular correlation structure between $A$ and $B$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the specified validation criteria.\n- **Scientifically Grounded:** The problem is grounded in the established principles of digital integrated circuit design and reliability physics. The description of a static CMOS NAND gate, the definitions of NBTI and PBTI, and their corresponding stress conditions ($V_{gs}$ bias) are all factually correct and standard in the field of Electronic Design Automation (EDA). The use of signal probabilities to compute stress duty cycles is a conventional method in aging-aware analysis.\n- **Well-Posed:** The problem is well-posed. It provides a clear definition of the system (a 2-input NAND gate), the random inputs, the physical phenomenon (BTI), and the quantity to be derived (stress duty cycle). The duty cycle is defined as a long-run time fraction, which for a stationary process is equivalent to the state probability. The problem requires deriving this probability from the given marginal input probabilities. The constraint of not assuming a correlation structure is crucial; the problem is structured such that the solution for the PMOS transistors does not require knowledge of any joint probabilities, thus avoiding underspecification. A unique, stable, and meaningful solution exists.\n- **Objective:** The language is formal, precise, and free of any subjectivity or bias.\n\nThe problem does not exhibit any of the flaws listed (Scientific Unsoundness, Non-Formalizable, Incomplete/Contradictory, Unrealistic, Ill-Posed, Trivial, or Unverifiable). It is a standard, fundamental problem in the analysis of circuit aging.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A complete solution will be provided.\n\n### Solution Derivation\nThe problem asks for two tasks: first, to formulate the stress conditions for all four transistors in the 2-input NAND gate, and second, to derive the specific stress duty cycles for the two PMOS transistors.\n\nLet the two PMOS transistors in the pull-up network be $P_A$ and $P_B$, with their gates connected to inputs $A$ and $B$ respectively. Both have their sources connected to the supply voltage, $V_{\\mathrm{DD}}$. Let the two NMOS transistors in the pull-down network be $N_A$ and $N_B$, connected in series. Let $N_A$'s gate be connected to input $A$ and its source to ground ($GND$, potential $0$). Let $N_B$'s gate be connected to input $B$, its drain to the gate output, and its source to the drain of $N_A$. Inputs $A$ and $B$ are logic signals, where logic `0` corresponds to a voltage of $0$ and logic `1` corresponds to a voltage of $V_{\\mathrm{DD}}$.\n\n**Part 1: Formulation of Stress Indicators**\n\nThe BTI stress duty cycle is defined as the long-run fraction of time a transistor is under a stress bias. For a stationary process, this time average is equal to the probability of the device being in the stress-inducing state.\n\n**NBTI in PMOS Transistors ($P_A$ and $P_B$):**\nThe stress condition for NBTI is $V_{gs} < 0$.\n- For transistor $P_A$: Its source is at $V_s = V_{\\mathrm{DD}}$. Its gate is connected to input $A$, so $V_g = V_A$. The stress condition is $V_{gs, P_A} = V_A - V_{\\mathrm{DD}} < 0$. This inequality holds true when $V_A = 0$, which corresponds to the logic state $A=0$. Therefore, the stress indicator for $P_A$ is the event $\\{A=0\\}$.\n- For transistor $P_B$: Similarly, its source is at $V_s = V_{\\mathrm{DD}}$ and its gate is at $V_g = V_B$. The stress condition $V_{gs, P_B} = V_B - V_{\\mathrm{DD}} < 0$ is met when $V_B = 0$, which corresponds to the logic state $B=0$. The stress indicator for $P_B$ is the event $\\{B=0\\}$.\n\n**PBTI in NMOS Transistors ($N_A$ and $N_B$):**\nThe stress condition for PBTI is $V_{gs} > 0$.\n- For transistor $N_A$: Its source is connected to ground, so $V_{s, N_A} = 0$. Its gate is connected to input $A$, so $V_g = V_A$. The stress condition is $V_{gs, N_A} = V_A - 0 > 0$. This is met when $V_A = V_{\\mathrm{DD}}$, which corresponds to the logic state $A=1$. The stress indicator for $N_A$ is the event $\\{A=1\\}$.\n- For transistor $N_B$: Its gate is connected to input $B$, so $V_g = V_B$. Its source is connected to the drain of $N_A$. The source voltage, $V_{s, N_B}$, is not always at ground.\n    - If $A=0$, transistor $N_A$ is OFF, and the source of $N_B$ is floating (high impedance).\n    - If $A=1$, transistor $N_A$ is ON, creating a conductive path to ground. Thus, $V_{s, N_B} \\approx 0$.\nSignificant PBTI stress requires the source to be near ground while the gate is high. Therefore, stress on $N_B$ occurs only when its gate is high ($B=1$) AND its source is grounded (which requires $A=1$). The stress indicator for $N_B$ is the compound event $\\{A=1 \\text{ and } B=1\\}$.\n\n**Part 2: Derivation of PMOS NBTI Duty Cycles**\n\nThe task reduces to finding the probabilities of the stress events for the PMOS transistors, using only the given marginal probabilities $P(A=1)$ and $P(B=1)$.\n\nLet $D_{P_A}$ be the NBTI stress duty cycle for transistor $P_A$. This is the probability of its stress event $\\{A=0\\}$.\n$$ D_{P_A} = P(A=0) $$\nSince $A$ is a binary random variable, it must be either $0$ or $1$. By the law of total probability:\n$$ P(A=0) + P(A=1) = 1 $$\nTherefore, the duty cycle for $P_A$ can be expressed in terms of the given probability $P(A=1)$:\n$$ D_{P_A} = 1 - P(A=1) $$\nLet $D_{P_B}$ be the NBTI stress duty cycle for transistor $P_B$. This is the probability of its stress event $\\{B=0\\}$.\n$$ D_{P_B} = P(B=0) $$\nSimilarly, for the binary random variable $B$:\n$$ P(B=0) + P(B=1) = 1 $$\nSo, the duty cycle for $P_B$ can be expressed in terms of the given probability $P(B=1)$:\n$$ D_{P_B} = 1 - P(B=1) $$\nThese expressions for $D_{P_A}$ and $D_{P_B}$ depend only on the marginal probabilities of the inputs, $P(A=1)$ and $P(B=1)$, as required by the problem statement. No information about the correlation or joint probability of $A$ and $B$ is needed.\n\nThe final answer is the pair of duty cycles $(D_{P_A}, D_{P_B})$ presented as a row vector.\nThe duty cycle of the PMOS connected to input $A$ is $1 - P(A=1)$.\nThe duty cycle of the PMOS connected to input $B$ is $1 - P(B=1)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 - P(A=1) & 1 - P(B=1)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The power-law and Arrhenius models are powerful tools, but their predictive accuracy hinges on the values of their parameters, such as the amplitude $A$ and exponent $n$, which are specific to a given technology and operating condition. This final practice addresses the crucial question of how these parameters are determined in the real world: by fitting the model to experimental data. You will perform the essential work of a reliability engineer, using nonlinear least squares to extract model parameters from simulated measurement data and, critically, to quantify the confidence in your estimates, completing the loop from empirical observation to predictive modeling. ",
            "id": "4255916",
            "problem": "Consider a Metal–Oxide–Semiconductor Field-Effect Transistor (MOSFET) experiencing aging-induced threshold voltage shift due to mechanisms such as Negative Bias Temperature Instability (NBTI) and Hot Carrier Injection (HCI), within the context of Electronic Design Automation (EDA) for integrated circuits. A widely used phenomenological model for the threshold voltage drift is the power law, where the measured drift is modeled as $\\Delta V_{th}(t) = A\\, t^{n}$ for $t > 0$, with $A > 0$ and $n > 0$. Assume the measurement process is corrupted by additive, independent and identically distributed Gaussian noise $\\epsilon_i$ with zero mean and unknown variance, so that the observed data satisfy $y_i = A\\, t_i^{n} + \\epsilon_i$ for each sample $i$.\n\nTask:\n- Derive and implement a nonlinear least squares estimator for the parameters $A$ and $n$ by minimizing the sum of squared residuals $\\sum_{i=1}^{N} \\left(y_i - A\\, t_i^{n}\\right)^2$.\n- From first principles, construct approximate two-sided confidence intervals for $A$ and $n$ at a confidence level of $95\\%$ using the Jacobian of the model at the estimated parameters and the estimated residual variance under the Gaussian noise assumption.\n- Use time $t$ in seconds and $\\Delta V_{th}$ in volts. Express the outputs for $A$ in volts and for $n$ as a unitless exponent. All reported numerical outputs must be rounded to six decimal places.\n\nFundamental base to use:\n- The least squares principle under Gaussian noise, which yields maximum likelihood estimators by minimizing the sum of squared residuals.\n- First-order (linearized) uncertainty propagation for nonlinear models via the Jacobian, yielding the parameter covariance approximation $\\mathrm{Cov}(\\hat{\\theta}) \\approx s^2 \\left(J^\\top J\\right)^{-1}$, where $s^2$ is the unbiased residual variance estimate and $J$ is the Jacobian of the model with respect to parameters evaluated at the estimator.\n- Confidence intervals based on the Student's $t$ distribution using the estimated standard errors and degrees of freedom $N - p$ for $p = 2$ parameters.\n\nMathematical definitions required:\n- Let $\\theta = [A, n]^\\top$ and $f(t; \\theta) = A t^{n}$.\n- The Jacobian matrix $J \\in \\mathbb{R}^{N \\times 2}$ of $f$ with respect to $\\theta$ has entries $J_{i,1} = \\frac{\\partial f}{\\partial A}(t_i;\\theta) = t_i^{n}$ and $J_{i,2} = \\frac{\\partial f}{\\partial n}(t_i;\\theta) = A\\, t_i^{n} \\ln t_i$.\n- The unbiased residual variance estimate is $s^2 = \\frac{1}{N - p} \\sum_{i=1}^{N} \\left(y_i - f(t_i; \\hat{\\theta})\\right)^2$.\n- The approximate covariance of parameters is $\\Sigma \\approx s^2 \\left(J^\\top J\\right)^{-1}$ evaluated at $\\hat{\\theta}$.\n- The $95\\%$ two-sided confidence interval for parameter $\\theta_k$ is $\\left[\\hat{\\theta}_k - t_{0.975, \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k), \\hat{\\theta}_k + t_{0.975, \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k)\\right]$, where $\\nu = N - p$ and $\\mathrm{SE}(\\hat{\\theta}_k) = \\sqrt{\\Sigma_{k,k}}$.\n\nTest suite:\nFor each case below, treat $t$ as time in seconds and $y$ as measured $\\Delta V_{th}$ in volts. Fit $A$ and $n$ and compute the $95\\%$ confidence intervals as specified.\n\n- Case 1 (typical aging over decades of time):\n  - $t = [100, 500, 1000, 5000, 10000, 50000, 100000]$\n  - $y = [0.010190, 0.013850, 0.015640, 0.020635, 0.023716, 0.031522, 0.035813]$\n\n- Case 2 (short-time regime with low drift and negligible noise):\n  - $t = [1, 2, 5, 10, 20, 50, 100]$\n  - $y = [0.002000, 0.002378, 0.002990, 0.003556, 0.004228, 0.005318, 0.006325]$\n\n- Case 3 (sparse measurements, wide time span):\n  - $t = [1000, 100000, 1000000]$\n  - $y = [0.010467, 0.022285, 0.031870]$\n\nFinal output format:\n- Your program should produce a single line of output containing a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a comma-separated list of six floats: $\\left[\\hat{A}, \\hat{n}, A_{\\text{lower}}, A_{\\text{upper}}, n_{\\text{lower}}, n_{\\text{upper}}\\right]$, each rounded to six decimal places. For example: \"[[A1,n1,Al1,Au1,nl1,nu1],[A2,n2,Al2,Au2,nl2,nu2],[A3,n3,Al3,Au3,nl3,nu3]]\".",
            "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, and complete. It describes a standard and relevant task in the field of integrated circuit reliability analysis: parameter extraction and uncertainty quantification for an empirical aging model. All provided data, definitions, and constraints are consistent and sufficient for deriving a unique and meaningful solution.\n\nThe objective is to estimate the parameters $\\theta = [A, n]^\\top$ of the nonlinear power-law model for threshold voltage drift, $f(t; \\theta) = A t^n$, and to construct confidence intervals for these estimates. The estimation is based on a set of $N$ measurements $(t_i, y_i)$, where $y_i = f(t_i; \\theta) + \\epsilon_i$, and $\\epsilon_i$ are assumed to be independent and identically distributed (i.i.d.) random variables from a Gaussian distribution with zero mean, $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$.\n\n**Parameter Estimation via Nonlinear Least Squares (NLLS)**\n\nUnder the assumption of i.i.d. Gaussian noise, the Maximum Likelihood Estimation (MLE) of the parameters $\\theta$ is equivalent to minimizing the Sum of Squared Residuals (SSR). The objective function, $S(\\theta)$, is therefore:\n$$ S(\\theta) = \\sum_{i=1}^{N} \\left(y_i - f(t_i; \\theta)\\right)^2 = \\sum_{i=1}^{N} \\left(y_i - A t_i^n\\right)^2 $$\nSince the model $f(t; \\theta)$ is nonlinear with respect to the parameter $n$, this minimization problem does not have a closed-form analytical solution and must be solved numerically using an iterative algorithm.\n\nA common method is the Gauss-Newton algorithm or its more robust variant, Levenberg-Marquardt. These algorithms start with an initial guess $\\theta^{(0)} = [A^{(0)}, n^{(0)}]^\\top$ and iteratively refine the estimate. A robust strategy for obtaining an initial guess is to linearize the model by taking the natural logarithm:\n$$ \\ln(y_i) \\approx \\ln(A) + n \\ln(t_i) $$\nThis transformed equation is linear in its parameters $n$ and $c = \\ln(A)$. We can apply standard Ordinary Least Squares (OLS) to the data pairs $(\\ln(t_i), \\ln(y_i))$ to obtain initial estimates $n^{(0)}$ and $c^{(0)} = \\ln(A^{(0)})$, from which $A^{(0)} = \\exp(c^{(0)})$.\n\nThe iterative update at step $k$ for the parameter vector $\\theta^{(k)}$ is given by solving the linear system for the update step $\\Delta\\theta$:\n$$ \\left(J_k^\\top J_k\\right) \\Delta\\theta = J_k^\\top r_k $$\nwhere $r_k$ is the vector of residuals $r_{k,i} = y_i - f(t_i; \\theta^{(k)})$, and $J_k$ is the Jacobian matrix of the model function with respect to the parameters, evaluated at $\\theta^{(k)}$. The entries of the Jacobian are given by:\n$$ J_{i,1} = \\frac{\\partial f}{\\partial A}(t_i; \\theta) = t_i^n $$\n$$ J_{i,2} = \\frac{\\partial f}{\\partial n}(t_i; \\theta) = A t_i^n \\ln(t_i) $$\nThe parameters are then updated as $\\theta^{(k+1)} = \\theta^{(k)} + \\Delta\\theta$. The process is repeated until convergence, yielding the final NLLS estimate $\\hat{\\theta} = [\\hat{A}, \\hat{n}]^\\top$.\n\n**Confidence Interval Construction**\n\nThe uncertainty in the estimated parameters $\\hat{\\theta}$ can be approximated by linearizing the model around the estimate. This leads to the approximate parameter covariance matrix $\\Sigma$:\n$$ \\Sigma \\approx s^2 \\left(J^\\top J\\right)^{-1} $$\nwhere $J$ is the Jacobian matrix evaluated at the final estimate $\\hat{\\theta}$, and $s^2$ is the unbiased estimator of the residual variance $\\sigma^2$. It is calculated from the final sum of squared residuals:\n$$ s^2 = \\frac{1}{N-p} \\sum_{i=1}^{N} \\left(y_i - f(t_i; \\hat{\\theta})\\right)^2 $$\nHere, $p=2$ is the number of estimated parameters, and $\\nu = N-p$ are the degrees of freedom.\n\nThe diagonal elements of the covariance matrix $\\Sigma$ provide the estimated variances of the parameters, $\\mathrm{Var}(\\hat{A}) \\approx \\Sigma_{1,1}$ and $\\mathrm{Var}(\\hat{n}) \\approx \\Sigma_{2,2}$. The standard error (SE) for each parameter is the square root of its variance:\n$$ \\mathrm{SE}(\\hat{\\theta}_k) = \\sqrt{\\Sigma_{k,k}} $$\nA two-sided $(1-\\alpha)$ confidence interval for a parameter $\\hat{\\theta}_k$ is constructed using the Student's t-distribution, which is appropriate when the variance is estimated from the data:\n$$ \\left[ \\hat{\\theta}_k - t_{1-\\alpha/2, \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k), \\quad \\hat{\\theta}_k + t_{1-\\alpha/2, \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k) \\right] $$\nFor the required $95\\%$ confidence level, $\\alpha=0.05$, and we use the critical value $t_{0.975, \\nu}$.\n\n**Computational Procedure**\n\nThe solution is implemented by applying these principles to each test case.\n1.  For each $(t, y)$ dataset, initial parameter estimates are found via linear regression on the log-transformed data.\n2.  These initial estimates are provided to a numerical optimization routine (`scipy.optimize.least_squares`) which minimizes the sum of squared residuals of the original nonlinear model to find the final estimates $\\hat{A}$ and $\\hat{n}$. Constraints $A>0$ and $n>0$ are enforced.\n3.  The Jacobian matrix $J$ is computed at the final estimates.\n4.  The unbiased residual variance $s^2$ is calculated using the degrees of freedom $\\nu=N-2$.\n5.  The parameter covariance matrix $\\Sigma = s^2(J^\\top J)^{-1}$ is computed.\n6.  Standard errors for $\\hat{A}$ and $\\hat{n}$ are extracted from the diagonal of $\\Sigma$.\n7.  The critical value $t_{0.975, \\nu}$ is obtained from `scipy.stats.t.ppf`.\n8.  The $95\\%$ confidence intervals for $A$ and $n$ are calculated.\n9.  All six resulting values ($\\hat{A}$, $\\hat{n}$, and their lower/upper confidence bounds) are rounded to six decimal places as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\nfrom scipy.stats import t as t_dist\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"t\": np.array([100, 500, 1000, 5000, 10000, 50000, 100000]),\n            \"y\": np.array([0.010190, 0.013850, 0.015640, 0.020635, 0.023716, 0.031522, 0.035813])\n        },\n        {\n            \"t\": np.array([1, 2, 5, 10, 20, 50, 100]),\n            \"y\": np.array([0.002000, 0.002378, 0.002990, 0.003556, 0.004228, 0.005318, 0.006325])\n        },\n        {\n            \"t\": np.array([1000, 100000, 1000000]),\n            \"y\": np.array([0.010467, 0.022285, 0.031870])\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        t_data, y_data = case[\"t\"], case[\"y\"]\n        \n        # --- Nonlinear Least Squares Estimation ---\n        \n        # 1. Obtain initial guess by linearizing the model: log(y) = log(A) + n*log(t)\n        # This is a linear regression of log(y) on log(t)\n        try:\n            log_t = np.log(t_data)\n            log_y = np.log(y_data)\n            # np.polyfit returns [slope, intercept]\n            n_initial, log_A_initial = np.polyfit(log_t, log_y, 1)\n            A_initial = np.exp(log_A_initial)\n            initial_guess = [A_initial, n_initial]\n        except (ValueError, TypeError):\n            # Fallback for edge cases\n            initial_guess = [0.01, 0.2]\n\n        # 2. Define the residual function for the NLLS solver\n        def residuals(params, t, y):\n            A, n = params\n            return y - A * t**n\n        \n        # 3. Perform NLLS using scipy.optimize.least_squares\n        # Using Levenberg-Marquardt algorithm (default)\n        # Enforce constraints A > 0, n > 0\n        lsq_result = least_squares(\n            residuals, \n            initial_guess, \n            args=(t_data, y_data), \n            bounds=([0, 0], [np.inf, np.inf])\n        )\n        A_hat, n_hat = lsq_result.x\n        \n        # --- Confidence Interval Calculation ---\n        \n        # 1. Calculate final residuals and unbiased residual variance s^2\n        N = len(t_data) # number of data points\n        p = 2          # number of parameters\n        nu = N - p     # degrees of freedom\n        \n        final_residuals = residuals([A_hat, n_hat], t_data, y_data)\n        s_squared = np.sum(final_residuals**2) / nu if nu > 0 else np.nan\n        \n        # 2. Calculate the Jacobian matrix at the estimated parameters\n        J = np.zeros((N, p))\n        J[:, 0] = t_data**n_hat                                # d(f)/dA\n        J[:, 1] = A_hat * (t_data**n_hat) * np.log(t_data)      # d(f)/dn\n\n        # 3. Approximate parameter covariance matrix: Sigma = s^2 * (J^T * J)^-1\n        try:\n            if nu = 0 or np.isnan(s_squared):\n                 raise ValueError(\"Cannot compute CI with non-positive degrees of freedom.\")\n            # pinv is more robust than inv for potentially ill-conditioned matrices\n            cov_matrix = s_squared * np.linalg.pinv(J.T @ J)\n            \n            # 4. Extract standard errors\n            se_A = np.sqrt(cov_matrix[0, 0])\n            se_n = np.sqrt(cov_matrix[1, 1])\n            \n            # 5. Find the critical value from the Student's t-distribution for 95% CI\n            t_crit = t_dist.ppf(0.975, df=nu)\n            \n            # 6. Construct the confidence intervals\n            A_lower = A_hat - t_crit * se_A\n            A_upper = A_hat + t_crit * se_A\n            n_lower = n_hat - t_crit * se_n\n            n_upper = n_hat + t_crit * se_n\n\n        except (np.linalg.LinAlgError, ValueError):\n             # Handle cases where covariance cannot be computed (e.g., singular matrix)\n            A_lower, A_upper, n_lower, n_upper = [np.nan] * 4\n\n        # Assemble the results for this case, rounded to 6 decimal places\n        case_results = [\n            round(A_hat, 6),\n            round(n_hat, 6),\n            round(A_lower, 6),\n            round(A_upper, 6),\n            round(n_lower, 6),\n            round(n_upper, 6)\n        ]\n        all_results.append(case_results)\n        \n    # Format the final output string as specified: [[...],[...],[...]]\n    output_str = str(all_results).replace(\" \", \"\").replace(\"nan\", \"float('nan')\")\n    print(f\"[[{all_results[0][0]},{all_results[0][1]},{all_results[0][2]},{all_results[0][3]},{all_results[0][4]},{all_results[0][5]}],[{all_results[1][0]},{all_results[1][1]},{all_results[1][2]},{all_results[1][3]},{all_results[1][4]},{all_results[1][5]}],[{all_results[2][0]},{all_results[2][1]},{all_results[2][2]},{all_results[2][3]},{all_results[2][4]},{all_results[2][5]}]]\")\n\nsolve()\n```"
        }
    ]
}