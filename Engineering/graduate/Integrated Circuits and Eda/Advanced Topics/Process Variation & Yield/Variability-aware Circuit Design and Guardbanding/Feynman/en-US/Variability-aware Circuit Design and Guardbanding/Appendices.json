{
    "hands_on_practices": [
        {
            "introduction": "The fundamental purpose of guardbanding is to create a buffer against uncertainty, ensuring circuit performance meets specifications despite random variations. This exercise provides a foundational look at how the amount of statistical information we possess about a critical path's delay dramatically impacts the required guardband. By comparing bounds derived from the distribution-agnostic Chebyshev and Cantelli inequalities with the result from a full Gaussian model, you will gain a quantitative understanding of the trade-off between model generality and design pessimism. ",
            "id": "4307717",
            "problem": "A single critical path delay in a synchronous integrated circuit is modeled as a real-valued random variable $D$ due to Process, Voltage, and Temperature (PVT) variability. The design adopts guardbanding: the clock period is set to $T_{\\text{clk}} = \\mu + g$, where $\\mu$ is the mean of $D$ and $g$ is the guardband. The target failure probability (timing violation) per path is specified as $\\alpha$, so the yield requirement is $P(D \\leq \\mu + g) \\geq 1 - \\alpha$. Only the mean and variance of $D$ are known: $\\mathbb{E}[D] = \\mu$ and $\\operatorname{Var}(D) = \\sigma^{2}$. \n\nStarting from the definition of yield and the foundational tail-probability bounding principles given by Chebyshev’s inequality and Cantelli’s inequality (one-sided Chebyshev), derive from first principles the minimum guardband $g$ that guarantees the yield requirement when only $\\mu$ and $\\sigma^{2}$ are known. Then, under the additional assumption that $D$ is Gaussian with distribution $D \\sim \\mathcal{N}(\\mu, \\sigma^{2})$, derive the minimum Gaussian-based guardband that achieves the same yield requirement. \n\nEvaluate these three guardbands numerically for a path with $\\,\\mu = 1.0\\,\\text{ns}\\,$, $\\,\\sigma = 0.05\\,\\text{ns}\\,$, and $\\,\\alpha = 0.01\\,$. Express the three guardbands in nanoseconds in a single row matrix in the order: Chebyshev-based guardband, Cantelli-based guardband, Gaussian-based guardband. Round your numerical answers to four significant figures. The final answer must be a single row matrix and must contain only numbers (no units), while the problem statement specifies that the unit is nanoseconds (ns).",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of statistical circuit analysis and probability theory, well-posed with a clear objective and sufficient data, and free from ambiguity or contradiction. It poses a standard, formalizable problem in variability-aware integrated circuit design. We may therefore proceed with the solution.\n\nThe problem requires the derivation of the minimum guardband $g$ under three different sets of assumptions to satisfy a yield requirement. The yield requirement is given by $P(D \\leq \\mu + g) \\geq 1 - \\alpha$, where $D$ is the random variable representing the path delay, $\\mu$ is its mean, and $\\alpha$ is the target failure probability. This is equivalent to constraining the probability of a timing failure, $P(D > \\mu + g)$, to be no more than $\\alpha$:\n$$P(D > \\mu + g) \\leq \\alpha$$\n\nLet $\\mathbb{E}[D] = \\mu$ and $\\operatorname{Var}(D) = \\sigma^{2}$. The guardband $g$ is added to the mean delay, so the clock period is $T_{\\text{clk}} = \\mu + g$. We will derive the expression for $g$ and then evaluate it for the given parameters.\n\n**1. Guardband Derivation using Chebyshev’s Inequality**\n\nChebyshev's inequality provides a bound on the probability that a random variable deviates from its mean. For any random variable $X$ with finite mean $\\mu_X$ and finite non-zero variance $\\sigma_X^2$, and for any real number $k > 0$, the inequality states:\n$$P(|X - \\mu_X| \\geq k) \\leq \\frac{\\sigma_X^2}{k^2}$$\nWe apply this to the delay $D$, where $X=D$, $\\mu_X=\\mu$, and $\\sigma_X^2=\\sigma^2$. We are interested in the event $D > \\mu + g$, which is equivalent to $D - \\mu > g$. This one-sided event is a subset of the two-sided event $|D - \\mu| > g$. Therefore, the probability of our event of interest is bounded by the probability of the two-sided event:\n$$P(D > \\mu + g) \\leq P(|D - \\mu| > g)$$\nFor a continuous random variable, the use of $>$ versus $\\geq$ does not change the probability. Let's set $k=g$ in Chebyshev's inequality ($g$ must be positive, which is physically required for a guardband).\n$$P(|D - \\mu| \\geq g) \\leq \\frac{\\sigma^2}{g^2}$$\nTo satisfy the yield requirement $P(D > \\mu + g) \\leq \\alpha$, it is sufficient to enforce the condition that the upper bound provided by Chebyshev's inequality is equal to $\\alpha$. This guarantees that the failure probability will be no more than $\\alpha$.\n$$\\frac{\\sigma^2}{g^2} = \\alpha$$\nSolving for the minimum guardband $g$ that this inequality can guarantee, we get:\n$$g^2 = \\frac{\\sigma^2}{\\alpha} \\implies g = \\frac{\\sigma}{\\sqrt{\\alpha}}$$\nThis is the Chebyshev-based guardband, which we denote as $g_{\\text{Cheby}}$.\n$$g_{\\text{Cheby}} = \\frac{\\sigma}{\\sqrt{\\alpha}}$$\n\n**2. Guardband Derivation using Cantelli’s Inequality (One-Sided Chebyshev)**\n\nCantelli's inequality provides a tighter, one-sided bound. For a random variable $X$ with mean $\\mu_X$ and variance $\\sigma_X^2$, and for any $\\lambda > 0$, it states:\n$$P(X - \\mu_X \\geq \\lambda) \\leq \\frac{\\sigma_X^2}{\\sigma_X^2 + \\lambda^2}$$\nWe are interested in bounding $P(D > \\mu + g)$, which is $P(D - \\mu > g)$. Again assuming $D$ is continuous, this is the same as $P(D - \\mu \\geq g)$. We apply Cantelli's inequality with $X=D$ and $\\lambda=g$.\n$$P(D - \\mu \\geq g) \\leq \\frac{\\sigma^2}{\\sigma^2 + g^2}$$\nTo guarantee the yield requirement, we set this bound to be equal to $\\alpha$:\n$$\\frac{\\sigma^2}{\\sigma^2 + g^2} = \\alpha$$\nNow, we solve for the minimum guardband $g$ guaranteed by this inequality, which we denote $g_{\\text{Cantelli}}$:\n$$\\sigma^2 = \\alpha (\\sigma^2 + g^2)$$\n$$\\sigma^2 = \\alpha\\sigma^2 + \\alpha g^2$$\n$$\\sigma^2(1 - \\alpha) = \\alpha g^2$$\n$$g^2 = \\frac{\\sigma^2(1 - \\alpha)}{\\alpha}$$\n$$g_{\\text{Cantelli}} = \\sigma \\sqrt{\\frac{1 - \\alpha}{\\alpha}}$$\nAs $1-\\alpha < 1$, this guardband is strictly smaller (tighter) than the one derived from the two-sided Chebyshev inequality, which is expected.\n\n**3. Guardband Derivation assuming a Gaussian Distribution**\n\nUnder the assumption that the delay $D$ follows a Gaussian (Normal) distribution, $D \\sim \\mathcal{N}(\\mu, \\sigma^2)$, we can calculate the failure probability exactly. The requirement is to find the minimum $g$ such that:\n$$P(D > \\mu + g) = \\alpha$$\nTo evaluate this probability, we standardize the random variable $D$. Let $Z = \\frac{D-\\mu}{\\sigma}$. The variable $Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$. The inequality $D > \\mu + g$ is transformed as follows:\n$$\\frac{D - \\mu}{\\sigma} > \\frac{(\\mu + g) - \\mu}{\\sigma}$$\n$$Z > \\frac{g}{\\sigma}$$\nThe probability requirement becomes:\n$$P\\left(Z > \\frac{g}{\\sigma}\\right) = \\alpha$$\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, i.e., $\\Phi(z) = P(Z \\leq z)$. The tail probability is $P(Z > z) = 1 - \\Phi(z)$. Thus, we have:\n$$1 - \\Phi\\left(\\frac{g}{\\sigma}\\right) = \\alpha \\implies \\Phi\\left(\\frac{g}{\\sigma}\\right) = 1 - \\alpha$$\nTo find the argument of $\\Phi$, we use the inverse CDF, or the quantile function, $\\Phi^{-1}$:\n$$\\frac{g}{\\sigma} = \\Phi^{-1}(1 - \\alpha)$$\nSolving for the Gaussian-based guardband, $g_{\\text{Gauss}}$:\n$$g_{\\text{Gauss}} = \\sigma \\, \\Phi^{-1}(1 - \\alpha)$$\nThe term $\\Phi^{-1}(1 - \\alpha)$ represents the $(1-\\alpha)$-quantile of the standard normal distribution.\n\n**Numerical Evaluation**\n\nWe are given the following parameter values:\n$\\mu = 1.0\\,\\text{ns}$\n$\\sigma = 0.05\\,\\text{ns}$\n$\\alpha = 0.01$\n\nWe now calculate the three guardbands and round the results to four significant figures.\n\n1.  **Chebyshev-based guardband:**\n    $g_{\\text{Cheby}} = \\frac{0.05}{\\sqrt{0.01}} = \\frac{0.05}{0.1} = 0.5\\,\\text{ns}$.\n    To four significant figures, this is $0.5000\\,\\text{ns}$.\n\n2.  **Cantelli-based guardband:**\n    $g_{\\text{Cantelli}} = 0.05 \\sqrt{\\frac{1 - 0.01}{0.01}} = 0.05 \\sqrt{\\frac{0.99}{0.01}} = 0.05 \\sqrt{99}$.\n    Using a calculator, $\\sqrt{99} \\approx 9.949874$.\n    $g_{\\text{Cantelli}} \\approx 0.05 \\times 9.949874 \\approx 0.4974937\\,\\text{ns}$.\n    Rounding to four significant figures gives $0.4975\\,\\text{ns}$.\n\n3.  **Gaussian-based guardband:**\n    $g_{\\text{Gauss}} = 0.05 \\times \\Phi^{-1}(1 - 0.01) = 0.05 \\times \\Phi^{-1}(0.99)$.\n    The value $\\Phi^{-1}(0.99)$ is the z-score that corresponds to a cumulative probability of $0.99$. From standard statistical tables or a calculator, $\\Phi^{-1}(0.99) \\approx 2.326348$.\n    $g_{\\text{Gauss}} \\approx 0.05 \\times 2.326348 \\approx 0.1163174\\,\\text{ns}$.\n    Rounding to four significant figures gives $0.1163\\,\\text{ns}$.\n\nThe three guardbands, in the specified order (Chebyshev, Cantelli, Gaussian), are $0.5000\\,\\text{ns}$, $0.4975\\,\\text{ns}$, and $0.1163\\,\\text{ns}$. The non-parametric bounds are significantly more pessimistic (larger guardband) than the bound derived assuming a specific distribution, which is a well-known result. The Gaussian assumption leverages more information about the underlying process, resulting in a much more optimistic and efficient guardband.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5000 & 0.4975 & 0.1163\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In modern ICs, circuit delay variation is not a monolithic effect but rather the result of multiple, interacting physical parameter fluctuations. This practice delves into a core technique of Statistical Static Timing Analysis (SSTA) for handling these complex, correlated variations. You will use Principal Component Analysis (PCA) to diagonalize the covariance matrix of process parameters, transforming them into a set of uncorrelated variables that simplify the analysis and calculation of the final timing guardband. ",
            "id": "4307705",
            "problem": "An Electronic Design Automation (EDA) flow for Statistical Static Timing Analysis (SSTA) models process-induced variability of a critical path delay by linearizing the delay with respect to a small set of global process parameters. Let the zero-mean parameter variation vector be $x \\in \\mathbb{R}^{3}$ corresponding to threshold voltage, effective length, and oxide thickness, and assume $x$ is jointly Gaussian with covariance matrix\n$$\n\\Sigma \\;=\\;\n\\begin{pmatrix}\n0.04 & 0.018 & -0.012 \\\\\n0.018 & 0.09 & -0.015 \\\\\n-0.012 & -0.015 & 0.025\n\\end{pmatrix}.\n$$\nThe path delay is modeled to first order as\n$$\nt \\;=\\; t_{\\text{nom}} \\;+\\; g^{\\top} x,\n$$\nwith sensitivity vector\n$$\ng \\;=\\; \\begin{pmatrix} 10 \\\\ 5 \\\\ 7 \\end{pmatrix},\n$$\nwhere $t_{\\text{nom}}$ is the nominal delay and the entries of $g$ are in picoseconds per unit of normalized parameter variation. Principal Component Analysis (PCA) creates orthogonal directions of variation that are uncorrelated by diagonalizing the covariance. From a fundamental base of covariance properties and linear transforms of Gaussian random variables, do the following:\n\n1. Starting from the definition of covariance and orthogonal diagonalization of a symmetric positive semidefinite matrix, derive the transformation that maps $x$ to a new variable $z$ whose components are uncorrelated and have unit variance. Express the transform in terms of the eigenvector matrix and eigenvalue matrix of $\\Sigma$ without numerical substitution.\n\n2. Using the transformed variable $z$, express $t$ as $t = t_{\\text{nom}} + c^{\\top} z$ and identify $c$ in terms of the eigen-decomposition objects of $\\Sigma$ and the sensitivity vector $g$.\n\n3. Using the properties of Gaussian random variables, compute the variance of $t$ in closed form from the given $g$ and $\\Sigma$, and then determine the minimal one-sided guardband $\\Delta t$ such that\n$$\n\\mathbb{P}\\!\\left( t \\leq t_{\\text{nom}} + \\Delta t \\right) \\;=\\; 0.99865.\n$$\nExpress the final guardband $\\Delta t$ in picoseconds. Round your answer to four significant figures.\n\nYour final answer must be a single real number.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the principles of statistical circuit analysis, well-posed with a clear objective and sufficient data, and free from any factual or logical inconsistencies. We may therefore proceed with a full solution.\n\nThe problem is divided into three parts. We will address them sequentially.\n\n**Part 1: Derivation of the Decorrelating and Normalizing Transformation**\n\nWe are given a zero-mean Gaussian random vector $x \\in \\mathbb{R}^{3}$ with a covariance matrix $\\Sigma = E[xx^{\\top}]$. We seek a linear transformation $x \\to z$ such that the components of $z$ are uncorrelated and have unit variance. This means the covariance matrix of $z$ must be the identity matrix, i.e., $\\text{Cov}(z) = I$.\n\nLet the transformation be $z = A x$ for some matrix $A$. The covariance of $z$ is given by:\n$$\n\\text{Cov}(z) = E[zz^{\\top}] = E[(Ax)(Ax)^{\\top}] = E[A x x^{\\top} A^{\\top}] = A E[x x^{\\top}] A^{\\top} = A \\Sigma A^{\\top}\n$$\nSo we must find a matrix $A$ such that $A \\Sigma A^{\\top} = I$.\n\nThe covariance matrix $\\Sigma$ is real and symmetric. By the spectral theorem, it can be orthogonally diagonalized as:\n$$\n\\Sigma = V \\Lambda V^{\\top}\n$$\nwhere $V$ is an orthogonal matrix whose columns are the eigenvectors of $\\Sigma$ (satisfying $V^{\\top}V = VV^{\\top} = I$), and $\\Lambda$ is a diagonal matrix whose diagonal entries $\\lambda_i$ are the corresponding eigenvalues of $\\Sigma$. Since $\\Sigma$ is a covariance matrix, it is positive semidefinite, and thus its eigenvalues are non-negative, $\\lambda_i \\geq 0$. We already verified in the validation step that $\\Sigma$ is positive definite, so all $\\lambda_i > 0$.\n\nLet's substitute the eigendecomposition into our target equation:\n$$\nA (V \\Lambda V^{\\top}) A^{\\top} = I\n$$\nThis suggests choosing $A$ in a way that simplifies this expression. A two-step process is intuitive: first decorrelate, then normalize.\n\nStep (i): Decorrelation (Principal Component Analysis). Let's define an intermediate variable $y = V^{\\top}x$. This transformation projects the data $x$ onto the basis of eigenvectors of $\\Sigma$. The covariance of $y$ is:\n$$\n\\text{Cov}(y) = V^{\\top} \\Sigma V = V^{\\top} (V \\Lambda V^{\\top}) V = (V^{\\top}V) \\Lambda (V^{\\top}V) = I \\Lambda I = \\Lambda\n$$\nSince $\\Lambda$ is a diagonal matrix, the components of $y$ are uncorrelated. The variance of the $i$-th component, $y_i$, is $\\text{Var}(y_i) = \\lambda_i$.\n\nStep (ii): Normalization (Whitening). To make the variances equal to one, we must scale each component $y_i$ by $1/\\sqrt{\\lambda_i}$. Let $\\Lambda^{-1/2}$ be the diagonal matrix with entries $1/\\sqrt{\\lambda_i}$. We define $z = \\Lambda^{-1/2} y$. The covariance of $z$ is:\n$$\n\\text{Cov}(z) = \\Lambda^{-1/2} \\text{Cov}(y) (\\Lambda^{-1/2})^{\\top} = \\Lambda^{-1/2} \\Lambda \\Lambda^{-1/2} = I\n$$\nThis is the desired result. Combining the two steps, the complete transformation is:\n$$\nz = \\Lambda^{-1/2} y = \\Lambda^{-1/2} (V^{\\top} x) = (\\Lambda^{-1/2} V^{\\top}) x\n$$\nThus, the required transformation matrix is $A = \\Lambda^{-1/2} V^{\\top}$. The transformation that maps $x$ to $z$ is $z = \\Lambda^{-1/2} V^{\\top} x$.\n\n**Part 2: Expressing Delay in Terms of the Transformed Variable**\n\nThe path delay is given by $t = t_{\\text{nom}} + g^{\\top} x$. We need to express this in the form $t = t_{\\text{nom}} + c^{\\top} z$. To do this, we first express $x$ in terms of $z$ by inverting the transformation from Part 1.\nStarting from $z = \\Lambda^{-1/2} V^{\\top} x$:\n$$\n\\Lambda^{1/2} z = V^{\\top} x\n$$\nMultiplying by $V$ on the left and using $VV^{\\top}=I$:\n$$\nV \\Lambda^{1/2} z = V V^{\\top} x = I x = x\n$$\nSo, $x = V \\Lambda^{1/2} z$.\n\nNow, we substitute this expression for $x$ into the delay equation:\n$$\nt = t_{\\text{nom}} + g^{\\top} (V \\Lambda^{1/2} z)\n$$\nBy the associative property of matrix multiplication, this can be written as:\n$$\nt = t_{\\text{nom}} + (g^{\\top} V \\Lambda^{1/2}) z\n$$\nThis is in the form $t = t_{\\text{nom}} + c^{\\top} z$, where the row vector $c^{\\top}$ is given by $c^{\\top} = g^{\\top} V \\Lambda^{1/2}$. The corresponding column vector $c$ is the transpose of this expression:\n$$\nc = (g^{\\top} V \\Lambda^{1/2})^{\\top} = (\\Lambda^{1/2})^{\\top} V^{\\top} (g^{\\top})^{\\top} = \\Lambda^{1/2} V^{\\top} g\n$$\nsince $\\Lambda^{1/2}$ is diagonal and thus symmetric. The vector $c$ is therefore $c = \\Lambda^{1/2} V^{\\top} g$.\n\n**Part 3: Calculation of Guardband**\n\nFirst, we must compute the variance of the delay, $\\sigma_t^2 = \\text{Var}(t)$. The delay is $t = t_{\\text{nom}} + g^{\\top} x$. Since $t_{\\text{nom}}$ is a deterministic constant, it does not contribute to the variance.\n$$\n\\sigma_t^2 = \\text{Var}(t) = \\text{Var}(t_{\\text{nom}} + g^{\\top} x) = \\text{Var}(g^{\\top} x)\n$$\nFor a random vector $x$ with covariance matrix $\\Sigma$ and a constant vector $g$, the variance of the scalar random variable $g^{\\top}x$ is given by the quadratic form:\n$$\n\\sigma_t^2 = g^{\\top} \\Sigma g\n$$\nUsing the provided numerical values for $g$ and $\\Sigma$:\n$$\ng = \\begin{pmatrix} 10 \\\\ 5 \\\\ 7 \\end{pmatrix}, \\quad \\Sigma = \\begin{pmatrix} 0.04 & 0.018 & -0.012 \\\\ 0.018 & 0.09 & -0.015 \\\\ -0.012 & -0.015 & 0.025 \\end{pmatrix}\n$$\nWe compute the product $\\Sigma g$:\n$$\n\\Sigma g = \\begin{pmatrix} 0.04(10) + 0.018(5) - 0.012(7) \\\\ 0.018(10) + 0.09(5) - 0.015(7) \\\\ -0.012(10) - 0.015(5) + 0.025(7) \\end{pmatrix} = \\begin{pmatrix} 0.4 + 0.09 - 0.084 \\\\ 0.18 + 0.45 - 0.105 \\\\ -0.12 - 0.075 + 0.175 \\end{pmatrix} = \\begin{pmatrix} 0.406 \\\\ 0.525 \\\\ -0.02 \\end{pmatrix}\n$$\nNext, we compute the dot product $g^{\\top}(\\Sigma g)$:\n$$\n\\sigma_t^2 = g^{\\top} (\\Sigma g) = \\begin{pmatrix} 10 & 5 & 7 \\end{pmatrix} \\begin{pmatrix} 0.406 \\\\ 0.525 \\\\ -0.02 \\end{pmatrix} = 10(0.406) + 5(0.525) + 7(-0.02)\n$$\n$$\n\\sigma_t^2 = 4.06 + 2.625 - 0.14 = 6.545\n$$\nThe variance of the delay is $\\sigma_t^2 = 6.545$ ps$^2$. The standard deviation is $\\sigma_t = \\sqrt{6.545}$ ps.\n\nThe delay $t$ is a linear transformation of a jointly Gaussian random vector $x$. Therefore, $t$ is itself a Gaussian random variable. Its mean is $E[t] = E[t_{\\text{nom}} + g^{\\top}x] = t_{\\text{nom}} + g^{\\top}E[x] = t_{\\text{nom}}$, since $x$ is zero-mean. So, $t \\sim \\mathcal{N}(t_{\\text{nom}}, \\sigma_t^2)$.\n\nWe need to find the guardband $\\Delta t$ such that $\\mathbb{P}( t \\leq t_{\\text{nom}} + \\Delta t ) = 0.99865$. We standardize the random variable $t$ by defining $Z = (t - E[t]) / \\sigma_t = (t - t_{\\text{nom}}) / \\sigma_t$. $Z$ follows a standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$.\nThe condition becomes:\n$$\n\\mathbb{P}\\left( \\frac{t - t_{\\text{nom}}}{\\sigma_t} \\leq \\frac{(t_{\\text{nom}} + \\Delta t) - t_{\\text{nom}}}{\\sigma_t} \\right) = \\mathbb{P}\\left( Z \\leq \\frac{\\Delta t}{\\sigma_t} \\right) = 0.99865\n$$\nLet $k = \\Delta t / \\sigma_t$. We need to find the value $k$ such that $\\Phi(k) = 0.99865$, where $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution. This is a well-known value corresponding to three standard deviations from the mean. Specifically, $\\Phi(3) \\approx 0.99865$.\nTherefore, we set $k = 3$.\n$$\n\\frac{\\Delta t}{\\sigma_t} = 3 \\implies \\Delta t = 3\\sigma_t\n$$\nSubstituting the value of $\\sigma_t$:\n$$\n\\Delta t = 3 \\sqrt{6.545} \\approx 3 \\times 2.5583197... \\approx 7.674959...\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\n\\Delta t \\approx 7.675 \\text{ ps}\n$$",
            "answer": "$$\\boxed{7.675}$$"
        },
        {
            "introduction": "While assuming a specific distribution like Gaussian is convenient, what if the true distribution is unknown? This practice introduces you to the powerful framework of distributionally robust optimization (DRO), a state-of-the-art method for guardbanding against uncertainty. By defining an \"ambiguity set\" of all possible distributions with a given mean and covariance, you will derive a worst-case delay and the corresponding slack, ensuring your design is secure against not just one assumed distribution, but an entire family of them. ",
            "id": "4307679",
            "problem": "In variability-aware circuit design within Electronic Design Automation (EDA), consider a critical path whose random delay is modeled as an affine function of a vector of local stage-wise variations. Let the path delay be given by\n$$D(\\mathbf{x}) = d_{\\mathrm{nom}} + \\mathbf{a}^{\\top}\\mathbf{x},$$\nwhere $d_{\\mathrm{nom}}$ is the nominal delay, $\\mathbf{a} \\in \\mathbb{R}^{n}$ is a known sensitivity vector, and $\\mathbf{x} \\in \\mathbb{R}^{n}$ is a random vector of zero-order additive variations at $n$ stages. You are given an ambiguity set of all probability distributions for $\\mathbf{x}$ whose mean and covariance are fixed at $\\boldsymbol{\\mu} \\in \\mathbb{R}^{n}$ and $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{n \\times n}$, respectively. To design a guardband, you wish to ensure that, uniformly over all distributions in this ambiguity set, the probability that $\\mathbf{x}$ lies inside an uncertainty region is at least $1 - \\varepsilon$, with $\\varepsilon \\in (0,1)$ specified.\n\nStarting from first principles of probability inequalities and convex optimization, construct a distributionally robust formulation that secures the path delay against all distributions with the given mean $\\boldsymbol{\\mu}$ and covariance $\\boldsymbol{\\Sigma}$ by using an elliptical uncertainty set. Then, by solving the associated worst-case maximization, derive the closed-form expression for the worst-case slack,\n$$S_{\\mathrm{wc}} = T_{\\mathrm{clk}} - \\max_{\\mathbf{x} \\text{ in the uncertainty set}} D(\\mathbf{x}),$$\nas a function of $T_{\\mathrm{clk}}$, $d_{\\mathrm{nom}}$, $\\mathbf{a}$, $\\boldsymbol{\\mu}$, $\\boldsymbol{\\Sigma}$, and $\\varepsilon$.\n\nFinally, evaluate $S_{\\mathrm{wc}}$ numerically for the following data:\n- Dimension $n = 5$.\n- Clock period $T_{\\mathrm{clk}} = 170$ ps.\n- Nominal delay $d_{\\mathrm{nom}} = 120$ ps.\n- Sensitivity vector $\\mathbf{a} = \\begin{pmatrix} 1.2 \\\\ 0.8 \\\\ 1.1 \\\\ 0.9 \\\\ 1.0 \\end{pmatrix}$.\n- Mean vector $\\boldsymbol{\\mu} = \\begin{pmatrix} 2.0 \\\\ -1.0 \\\\ 0.0 \\\\ 1.0 \\\\ 0.5 \\end{pmatrix}$ ps.\n- Covariance matrix $\\boldsymbol{\\Sigma} = \\operatorname{diag}\\!\\big(4.0,\\, 9.0,\\, 1.0,\\, 4.0,\\, 2.0\\big)$ ps$^{2}$.\n- Risk level $\\varepsilon = 0.05$.\n\nExpress the final numerical value of the worst-case slack in picoseconds (ps) and round your answer to four significant figures. The final answer must be a single real number.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and provides a complete, consistent set of data and objectives within the domain of variability-aware circuit design. We shall proceed with a full derivation.\n\nThe problem asks for the worst-case slack, $S_{\\mathrm{wc}}$, defined as $S_{\\mathrm{wc}} = T_{\\mathrm{clk}} - D_{\\mathrm{wc}}$, where $D_{\\mathrm{wc}}$ is the worst-case path delay. The worst-case delay is the maximum possible delay given a random variation vector $\\mathbf{x}$ confined to an uncertainty set $\\mathcal{E}$. The core of the problem lies in constructing this uncertainty set $\\mathcal{E}$ in a distributionally robust manner.\n\n**Step 1: Constructing the Elliptical Uncertainty Set**\n\nWe are given an ambiguity set of probability distributions for the variation vector $\\mathbf{x} \\in \\mathbb{R}^{n}$, characterized by a known mean $\\mathbb{E}[\\mathbf{x}] = \\boldsymbol{\\mu}$ and a known covariance matrix $\\mathbb{E}[(\\mathbf{x}-\\boldsymbol{\\mu})(\\mathbf{x}-\\boldsymbol{\\mu})^{\\top}] = \\boldsymbol{\\Sigma}$. We need to define an uncertainty region $\\mathcal{E}$ for $\\mathbf{x}$ such that the probability of $\\mathbf{x}$ falling within this region is at least $1 - \\varepsilon$, regardless of the specific distribution of $\\mathbf{x}$ (as long as it has mean $\\boldsymbol{\\mu}$ and covariance $\\boldsymbol{\\Sigma}$).\n$$ \\inf_{P \\in \\mathcal{P}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})} \\mathbb{P}(\\mathbf{x} \\in \\mathcal{E}) \\ge 1 - \\varepsilon $$\nwhere $\\mathcal{P}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ is the set of all distributions with the given mean and covariance. This is equivalent to ensuring that the worst-case probability of $\\mathbf{x}$ being outside $\\mathcal{E}$ is no more than $\\varepsilon$:\n$$ \\sup_{P \\in \\mathcal{P}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})} \\mathbb{P}(\\mathbf{x} \\notin \\mathcal{E}) \\le \\varepsilon $$\nThe problem specifies using an elliptical uncertainty set. The natural choice for such a set, based on the mean and covariance, is an ellipsoid defined by the Mahalanobis distance:\n$$ \\mathcal{E}(\\Omega) = \\{ \\mathbf{x} \\in \\mathbb{R}^n \\mid (\\mathbf{x} - \\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}) \\le \\Omega^2 \\} $$\nHere, $\\Omega$ is a parameter that controls the size of the ellipsoid, which we must determine from the risk level $\\varepsilon$. To do this from first principles, we employ a generalized multivariate Chebyshev inequality, which can be derived from Markov's inequality.\n\nLet $Y$ be the non-negative random variable representing the squared Mahalanobis distance: $Y = (\\mathbf{x} - \\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})$. Its expected value is:\n$$ \\mathbb{E}[Y] = \\mathbb{E}\\left[\\text{tr}\\left((\\mathbf{x} - \\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right)\\right] = \\mathbb{E}\\left[\\text{tr}\\left(\\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^{\\top}\\right)\\right] $$\nUsing the linearity of expectation and the trace operator:\n$$ \\mathbb{E}[Y] = \\text{tr}\\left(\\boldsymbol{\\Sigma}^{-1} \\mathbb{E}\\left[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^{\\top}\\right]\\right) = \\text{tr}(\\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\Sigma}) = \\text{tr}(\\mathbf{I}_{n}) = n $$\nwhere $\\mathbf{I}_{n}$ is the $n \\times n$ identity matrix.\nNow, we apply Markov's inequality to the non-negative random variable $Y$: for any $k > 0$, $\\mathbb{P}(Y \\ge k) \\le \\frac{\\mathbb{E}[Y]}{k}$.\nThe event $\\mathbf{x} \\notin \\mathcal{E}(\\Omega)$ is equivalent to $Y > \\Omega^2$. Applying Markov's inequality with $k = \\Omega^2$:\n$$ \\mathbb{P}(\\mathbf{x} \\notin \\mathcal{E}(\\Omega)) = \\mathbb{P}(Y > \\Omega^2) \\le \\frac{n}{\\Omega^2} $$\nThis bound holds for any distribution of $\\mathbf{x}$ with the given mean and covariance. To satisfy the requirement that this probability is at most $\\varepsilon$, we set the bound equal to $\\varepsilon$:\n$$ \\frac{n}{\\Omega^2} = \\varepsilon \\implies \\Omega^2 = \\frac{n}{\\varepsilon} \\implies \\Omega = \\sqrt{\\frac{n}{\\varepsilon}} $$\nThus, the distributionally robust uncertainty set is:\n$$ \\mathcal{E} = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n \\mid (\\mathbf{x} - \\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}) \\le \\frac{n}{\\varepsilon} \\right\\} $$\n\n**Step 2: Deriving the Worst-Case Delay and Slack**\n\nThe worst-case delay, $D_{\\mathrm{wc}}$, is the maximum of the delay function $D(\\mathbf{x})$ over the uncertainty set $\\mathcal{E}$:\n$$ D_{\\mathrm{wc}} = \\max_{\\mathbf{x} \\in \\mathcal{E}} D(\\mathbf{x}) = \\max_{\\mathbf{x} \\in \\mathcal{E}} (d_{\\mathrm{nom}} + \\mathbf{a}^{\\top}\\mathbf{x}) $$\n$$ D_{\\mathrm{wc}} = d_{\\mathrm{nom}} + \\max_{(\\mathbf{x} - \\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}) \\le \\Omega^2} \\mathbf{a}^{\\top}\\mathbf{x} $$\nLet $\\mathbf{p} = \\mathbf{x} - \\boldsymbol{\\mu}$, so $\\mathbf{x} = \\boldsymbol{\\mu} + \\mathbf{p}$. The constraint becomes $\\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} \\le \\Omega^2$. The maximization term becomes:\n$$ \\max_{\\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} \\le \\Omega^2} \\mathbf{a}^{\\top}(\\boldsymbol{\\mu} + \\mathbf{p}) = \\mathbf{a}^{\\top}\\boldsymbol{\\mu} + \\max_{\\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} \\le \\Omega^2} \\mathbf{a}^{\\top}\\mathbf{p} $$\nTo solve the maximization of $\\mathbf{a}^{\\top}\\mathbf{p}$, we use the Cauchy-Schwarz inequality. Let's define an inner product $\\langle \\mathbf{u}, \\mathbf{v} \\rangle_{\\boldsymbol{\\Sigma}^{-1}} = \\mathbf{u}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{v}$. Let $\\mathbf{p}$ be a vector in this space. Then the constraint is $\\|\\mathbf{p}\\|_{\\boldsymbol{\\Sigma}^{-1}}^2 \\le \\Omega^2$. We can write $\\mathbf{a}^{\\top}\\mathbf{p}$ as an inner product: $\\mathbf{a}^{\\top}\\mathbf{p} = (\\boldsymbol{\\Sigma}\\mathbf{a})^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} = \\langle \\boldsymbol{\\Sigma}\\mathbf{a}, \\mathbf{p} \\rangle_{\\boldsymbol{\\Sigma}^{-1}}$.\nBy the Cauchy-Schwarz inequality:\n$$ |\\langle \\boldsymbol{\\Sigma}\\mathbf{a}, \\mathbf{p} \\rangle_{\\boldsymbol{\\Sigma}^{-1}}| \\le \\|\\boldsymbol{\\Sigma}\\mathbf{a}\\|_{\\boldsymbol{\\Sigma}^{-1}} \\|\\mathbf{p}\\|_{\\boldsymbol{\\Sigma}^{-1}} $$\n$$ (\\mathbf{a}^{\\top}\\mathbf{p})^2 \\le \\left( (\\boldsymbol{\\Sigma}\\mathbf{a})^{\\top} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\Sigma}\\mathbf{a}) \\right) \\left( \\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} \\right) = (\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}) (\\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p}) $$\nUsing the constraint $\\mathbf{p}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{p} \\le \\Omega^2$:\n$$ (\\mathbf{a}^{\\top}\\mathbf{p})^2 \\le (\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}) \\Omega^2 $$\nTaking the square root, the maximum value of $\\mathbf{a}^{\\top}\\mathbf{p}$ is $\\Omega \\sqrt{\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}}$.\nSubstituting this back into the expression for $D_{\\mathrm{wc}}$:\n$$ D_{\\mathrm{wc}} = d_{\\mathrm{nom}} + \\mathbf{a}^{\\top}\\boldsymbol{\\mu} + \\Omega \\sqrt{\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}} $$\nNow, substituting $\\Omega = \\sqrt{n/\\varepsilon}$:\n$$ D_{\\mathrm{wc}} = d_{\\mathrm{nom}} + \\mathbf{a}^{\\top}\\boldsymbol{\\mu} + \\sqrt{\\frac{n}{\\varepsilon}} \\sqrt{\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}} $$\nThe worst-case slack is therefore:\n$$ S_{\\mathrm{wc}} = T_{\\mathrm{clk}} - D_{\\mathrm{wc}} = T_{\\mathrm{clk}} - d_{\\mathrm{nom}} - \\mathbf{a}^{\\top}\\boldsymbol{\\mu} - \\sqrt{\\frac{n}{\\varepsilon}\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}} $$\n\n**Step 3: Numerical Evaluation**\n\nWe are given the following numerical data:\n$n = 5$, $T_{\\mathrm{clk}} = 170$ ps, $d_{\\mathrm{nom}} = 120$ ps, $\\varepsilon = 0.05$.\n$\\mathbf{a} = \\begin{pmatrix} 1.2 \\\\ 0.8 \\\\ 1.1 \\\\ 0.9 \\\\ 1.0 \\end{pmatrix}$, $\\boldsymbol{\\mu} = \\begin{pmatrix} 2.0 \\\\ -1.0 \\\\ 0.0 \\\\ 1.0 \\\\ 0.5 \\end{pmatrix}$ ps, $\\boldsymbol{\\Sigma} = \\operatorname{diag}\\!\\big(4.0,\\, 9.0,\\, 1.0,\\, 4.0,\\, 2.0\\big)$ ps$^{2}$.\n\nFirst, calculate the mean path delay variation, $\\mathbf{a}^{\\top}\\boldsymbol{\\mu}$:\n$$ \\mathbf{a}^{\\top}\\boldsymbol{\\mu} = (1.2)(2.0) + (0.8)(-1.0) + (1.1)(0.0) + (0.9)(1.0) + (1.0)(0.5) $$\n$$ \\mathbf{a}^{\\top}\\boldsymbol{\\mu} = 2.4 - 0.8 + 0.0 + 0.9 + 0.5 = 3.0 \\text{ ps} $$\n\nNext, calculate the quadratic form $\\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a}$. Since $\\boldsymbol{\\Sigma}$ is diagonal, this simplifies to $\\sum_{i=1}^{n} a_i^2 \\Sigma_{ii}$:\n$$ \\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a} = (1.2)^2(4.0) + (0.8)^2(9.0) + (1.1)^2(1.0) + (0.9)^2(4.0) + (1.0)^2(2.0) $$\n$$ \\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a} = (1.44)(4.0) + (0.64)(9.0) + (1.21)(1.0) + (0.81)(4.0) + (1.0)(2.0) $$\n$$ \\mathbf{a}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{a} = 5.76 + 5.76 + 1.21 + 3.24 + 2.0 = 17.97 \\text{ ps}^2 $$\n\nNext, calculate the scaling factor $\\sqrt{n/\\varepsilon}$:\n$$ \\sqrt{\\frac{n}{\\varepsilon}} = \\sqrt{\\frac{5}{0.05}} = \\sqrt{100} = 10 $$\n\nNow, substitute these values into the expression for $S_{\\mathrm{wc}}$:\n$$ S_{\\mathrm{wc}} = 170 - 120 - 3.0 - \\sqrt{100 \\times 17.97} $$\n$$ S_{\\mathrm{wc}} = 47 - 10\\sqrt{17.97} $$\n$$ S_{\\mathrm{wc}} \\approx 47 - 10 \\times 4.2391037 = 47 - 42.391037 = 4.608963 \\text{ ps} $$\n\nRounding the result to four significant figures gives $4.609$ ps.",
            "answer": "$$\n\\boxed{4.609}\n$$"
        }
    ]
}