## 引言
随着人工智能的飞速发展，传统基于[冯·诺依曼架构](@entry_id:756577)的计算系统正面临着日益严峻的[能效](@entry_id:272127)危机。数据在处理器和内存之间的频繁搬运，即所谓的“冯·诺依曼瓶颈”，已成为制约性能和功耗的关键因素。为了突破这一限制，研究人员从自然界最高效的计算设备——生物大脑——中汲取灵感，开辟了神经形态计算这一革命性的研究领域。这种脑[启发式](@entry_id:261307)计算范式通过模仿神经系统的结构和信息处理方式，有望以极低的功耗实现复杂的认知任务。

本文旨在系统性地梳理神经形态计算架构的核心知识体系，弥合从底层物理原理到顶层应用实践之间的鸿沟。读者将通过本文学习到神经形态系统是如何被设计、构建和应用的。文章将分为三个核心章节：

- **原理与机制**：我们将深入剖析神经形态计算的基石，从存算一体和[事件驱动计算](@entry_id:1124695)的根本优势出发，详细阐述神经元与突触的数学模型、电路实现、学习规则（如STDP）以及系统级的[异步通信](@entry_id:173592)协议（AER）。

- **应用与跨学科连接**：本章将理论与实践相结合，展示神经形态架构如何在机器学习、[机器人学](@entry_id:150623)和仿生感知等前沿领域中发挥作用，并探讨其与[计算神经科学](@entry_id:274500)、材料科学等学科的深刻联系。

- **动手实践**：通过一系列精心设计的问题，读者将有机会亲手应用所学知识，解决从单个[神经元建模](@entry_id:1128659)到系统级能耗分析的实际问题，从而巩固和深化理解。

现在，让我们一同启程，首先探索构建这些未来计算系统所需遵循的基本原理与核心机制。

## 原理与机制

在介绍性章节之后，我们现在深入探讨神经形态计算架构的核心科学原理和工程机制。本章的目标是系统性地阐述这些系统的基本构件、它们如何交互、如何学习以及它们在物理实现中所面临的实际挑战。我们将从架构范式的根本动机开始，逐步构建起一个完整的神经形态系统的概念蓝图，从单个晶体管的行为一直到大规模网络的通信协议。

### 架构基础：能量效率与[事件驱动计算](@entry_id:1124695)

传统计算系统建立在冯·诺依曼架构之上，其核心特征是计算单元和存储单元的物理分离。这种分离导致了所谓的“冯·诺依曼瓶颈”：数据必须在处理器和内存之间通过总线反复传输。在处理以数据为中心的工作负载（如现代人工智能）时，数据移动所消耗的能量和时间甚至超过了实际计算本身。这促使我们去探索一种根本不同的计算范式。

神经形态计算的核心优势在于它直接解决了数据移动的能耗问题。这得益于两大基本原则：**存算一体（memory-compute co-location）**和**[事件驱动计算](@entry_id:1124695)（event-driven computation）**。存算一体意味着信息（例如，突触权重）被存储在执行计算的位置或其附近，从而最大程度地减少了数据传输距离和能耗。[事件驱动计算](@entry_id:1124695)则意味着只有在信息“事件”（即神经脉冲或“尖峰”）发生时，系统才会进行计算和通信。在网络活动稀疏的情况下——这在大脑和许多仿生应用中是常态——大部分电路可以保持在低功耗的空闲状态。

我们可以通过一个量化模型来阐明这种[能效](@entry_id:272127)优势。考虑一个包含 $N_{\mathrm{syn}} = 10^6$ 个突触的网络。在传统的冯·诺依曼架构中，一个典型的操作可能是密集更新，即在一个时间步内，所有 $N_{\mathrm{syn}}$ 个突触权重都需要从[主存](@entry_id:751652)中读取。而在一个事件驱动的神经形态架构中，假设只有一小部分突触是活跃的，例如，活动比例为 $p = 10^{-2}$。

我们使用[互补金属氧化物半导体](@entry_id:178661)（CMOS）电路中动态开关能耗的基本关系式 $E = \frac{1}{2} C V^2$ 来进行分析，其中 $C$ 是[开关电容](@entry_id:197049)，$V$ 是电源电压。

对于冯·诺依曼架构，总能耗 $E_{\mathrm{vN}}$ 包括数据移动能耗 $E_{\mathrm{vN,move}}$ 和全局时钟网络能耗 $E_{\mathrm{clk}}$。
-   **数据移动能耗**：每次从内存读取一个 $B$ 位的权重字，都会对总线电容进行充放电。如果总线每比特的线路电容为 $C_{\mathrm{line}}$，平均开关活动因子为 $\alpha$（即比特翻转的概率），则每次读取的能耗约为 $E_{\mathrm{fetch}} = \frac{1}{2} (\alpha B C_{\mathrm{line}}) V^2$。在一个时间步内，总的数据移动能耗为 $E_{\mathrm{vN,move}} = N_{\mathrm{syn}} \times E_{\mathrm{fetch}}$。
-   **时钟能耗**：全局[时钟网络](@entry_id:1122493)具有相当大的电容 $C_{\mathrm{clknet}}$，并且在处理每个突触时都需要翻转。因此，总时钟能耗为 $E_{\mathrm{clk}} = N_{\mathrm{syn}} \times (\frac{1}{2} C_{\mathrm{clknet}} V^2)$。

对于神经形态架构，能耗 $E_{\mathrm{nm}}$ 主要由处理活跃事件的局部数据移动所贡献。
-   **事件驱动能耗**：只有活跃的突触（数量为 $N_{\mathrm{active}} = p \times N_{\mathrm{syn}}$）会触发局部的读操作和通信。由于存算一体，每次事件的有效电容 $C_{\mathrm{local}}$ 非常小。总能耗为 $E_{\mathrm{nm,move}} = N_{\mathrm{active}} \times (\frac{1}{2} C_{\mathrm{local}} V^2)$。

通过一个具体的假设场景，我们可以看到显著的差异 。假设 $V = 1\,\mathrm{V}$，$B = 32$ 位，$\alpha = 0.5$，$C_{\mathrm{line}} = 0.2\,\mathrm{pF}$，$C_{\mathrm{clknet}} = 10\,\mathrm{pF}$，而 $C_{\mathrm{local}} = 2\,\mathrm{fF}$。计算得出，[冯·诺依曼架构](@entry_id:756577)的总能耗约为 $E_{\mathrm{vN}} \approx 6.6 \times 10^{-6}\,\mathrm{J}$，而神经形态架构的能耗仅为 $E_{\mathrm{nm}} \approx 10^{-11}\,\mathrm{J}$。两者的能耗比率 $R = E_{\mathrm{nm}} / E_{\mathrm{vN}}$ 约为 $1.5 \times 10^{-6}$，这意味着对于这种稀疏工作负载，神经形态架构在数据移动和时钟方面的能效提升了超过五个数量级。这个巨大的差异正是驱动神经形态架构发展的根本动力。

### 基本计算单元：神经元与突触

神经形态系统的计算由神经元和突触这两个基本构件完成。神经元是处理单元，负责整合输入并生成输出脉冲；突触是连接单元，负责传递信号并存储权重。

#### 神经元模型：从生物物理到计算抽象

神经元模型描述了其膜电位如何随输入电流变化并最终产生脉冲。模型的复杂性与其生物物理保真度直接相关。

一个在[计算效率](@entry_id:270255)和[生物学合理性](@entry_id:916293)之间取得极佳平衡的典范是**泄漏积分发放（Leaky Integrate-and-Fire, LIF）模型**。我们可以从基本的电路原理推导出LIF模型。将神经元[细胞膜](@entry_id:146704)建模为一个电容器 $C$ 和一个电阻（其电导为 $g_L$）的[并联电路](@entry_id:269189)。电容器 $C$ [存储电荷](@entry_id:1132461)，表现为膜电位 $V$；泄漏电导 $g_L$ 代表[离子通道](@entry_id:170762)的被动泄漏，它总是试图将膜电位拉向泄漏[反转电位](@entry_id:177450) $E_L$。根据基尔霍夫电流定律（KCL），流入节点的外部刺激电流 $I(t)$ 必须等于流出节点的电流之和，即电容电流 $i_C = C \frac{dV}{dt}$ 和泄漏电流 $i_L = g_L(V - E_L)$。

由此，我们得到LIF模型的动力学方程 ：
$$
C \frac{dV}{dt} = -g_L(V - E_L) + I(t)
$$
这个方程描述了神经元在未发放脉冲时的**亚阈值动力学（subthreshold dynamics）**。为了构成一个完整的模型，我们还需要定义脉冲发放和重置的规则：
1.  **[发放阈值](@entry_id:198849)**：当膜电位 $V(t)$ 上升并达到一个预设的阈值 $V_{\mathrm{th}}$ 时，神经元发放一个脉冲。
2.  **电位重置**：发放脉冲后，膜电位被立即重置到一个较低的值 $V_{\mathrm{reset}}$。
3.  **[绝对不应期](@entry_id:151661)**：在发放脉冲后的一个短暂时间窗口 $\tau_{\mathrm{ref}}$ 内，神经元无法再次发放脉冲，无论输入电流多强。这通常通过将膜电位钳位在 $V_{\mathrm{reset}}$ 来实现。

LIF模型是一个一维系统（其状态仅由 $V$ 描述），它抓住了[神经元计算](@entry_id:174774)的核心特征——输入整合和[脉冲生成](@entry_id:1132149)。与之相对的是更为复杂的**Hodgkin–Huxley（HH）模型**，它是一个四维系统，包含了描述钠离子和[钾离子通道](@entry_id:174108)激活和失活的变量 $(V, m, h, n)$。HH模型能够精确复现动作电位的形状和动力学，具有极高的生物物理保真度，但其计算成本也远高于[LIF模型](@entry_id:1127214)。在设计大规模神经形态系统时，LIF模型及其变体因其计算效率而成为首选。

#### 神经元电路：亚阈值物理学的妙用

要在硅芯片上高效地实现LIF这类神经元模型，工程师们利用了MOSFET晶体管在**亚阈值（subthreshold）**或称**弱反型（weak inversion）**区域工作的独特物理特性。当栅源电压 $V_{GS}$ 低于阈值电压 $V_{th}$ 时，晶体管中的[载流子输运](@entry_id:196072)由扩散主导，其漏极电流 $I_D$ 与 $V_{GS}$ 呈指数关系 ：
$$
I_D \propto \exp\left(\frac{V_{GS}}{n U_T}\right)
$$
其中，$U_T = kT/q$ 是[热电压](@entry_id:267086)（$k$ 是玻尔兹曼常数，$T$ 是绝对温度，$q$ 是基本电荷），$n \ge 1$ 是亚阈值斜率因子。

这种指数关系对于神经形态设计至关重要，因为它直接模拟了许多生物[离子通道](@entry_id:170762)的[电压门控](@entry_id:176688)行为，例如在[脉冲起始](@entry_id:1132152)区电压的指数敏感性。利用亚阈值晶体管作为跨导器（将输入电压转换为输出电流），可以构建出能耗极低的神经元电路。

一个关键的品质因数是**[跨导效率](@entry_id:269674)（transconductance efficiency）**，定义为 $g_m / I_D$，其中 $g_m = \partial I_D / \partial V_{GS}$ 是跨导。在亚阈值区，可以推导出：
$$
\frac{g_m}{I_D} = \frac{1}{n U_T}
$$
这个比值仅依赖于物理常数和温度，而与[偏置电流](@entry_id:260952) $I_D$ 无关。这意味着在极低的电流下，晶体管仍能保持非常高的电压-电流转换增益，这使其成为实现低功耗[模拟神经形态电路](@entry_id:1120993)的理想选择。例如，一个由亚阈值晶体管构成的差分对电路，其输入-输出特性自然地呈现为[双曲正切](@entry_id:636446)（$\tanh$）函数形式，这种[非线性](@entry_id:637147)计算在神经网络中也十分常见。

#### 突触阵列：基于物理定律的矩阵运算

在神经形态系统中，大量的突触连接构成了计算的核心。一个高效的实现方式是使用**电阻式[交叉阵列](@entry_id:202161)（resistive crossbar）**。这种阵列由 $M$ 行（wordlines）和 $N$ 列（bitlines）交叉构成，在每个交叉点上放置一个可编程的电阻或[忆阻器](@entry_id:204379)（memristor）作为突触，其电导为 $G_{nm}$。

当在第 $m$ 行施加输入电压 $V_m$ 时，根据欧姆定律，流经交叉点 $(n,m)$ 处突触器件的电流为 $I_{nm} = G_{nm} (V_m - V_{BL,n})$，其中 $V_{BL,n}$ 是第 $n$ 列的电位。根据基尔霍夫电流定律，汇集在第 $n$ 列上的总电流 $I_n$ 是所有从行流入该列的电流之和 ：
$$
I_n = \sum_{m=1}^{M} I_{nm} = \sum_{m=1}^{M} G_{nm} (V_m - V_{BL,n})
$$
要实现一个理想的向量-[矩阵乘法](@entry_id:156035) $I_{out} = G V_{in}$（其中 $I_n = \sum_{m=1}^{M} G_{nm} V_m$），必须确保上式中的第二项 $V_{BL,n} \sum G_{nm}$ 为零。这可以通过将每一列连接到一个**转阻放大器（Transimpedance Amplifier, TIA）**的输入端来实现。理想的TIA在其输入端维持一个**虚拟地（virtual ground）**，即强制 $V_{BL,n} \approx 0$。

在这种配置下，交叉阵列利用物理定律（[欧姆定律](@entry_id:276027)和[基尔霍夫电流定律](@entry_id:270632)）并行地、模拟地执行了大规模的向量-[矩阵乘法](@entry_id:156035)。这是一个极其强大的存算一体实例，因为权重（电导 $G_{nm}$）就存储在计算发生的位置。然而，这种理想行为依赖于若干假设：器件是线性欧姆电阻，行线和列线的寄生电阻可忽略不计，并且操作频率足够低以避免[寄生电容](@entry_id:270891)的影响。

### 学习与可塑性：自适应的连接权重

生物神经系统的标志性特征是其学习能力，这主要通过突触权重的动态调整来实现，即**[突触可塑性](@entry_id:137631)（synaptic plasticity）**。

#### 基于时间的学习：[脉冲时间依赖可塑性](@entry_id:907386)（STDP）

**脉冲时间依赖可塑性（Spike-Timing-Dependent Plasticity, STDP）**是一个核心的生物学学习规则。它指出，突触权重的变化取决于突触前脉冲和突触后脉冲的精确时间差。经典的STDP规则是：
-   如果突触前神经元在突触后神经元之前发放脉冲（$\Delta t = t_{\mathrm{post}} - t_{\mathrm{pre}} > 0$），突触权重会增强（**[长时程增强](@entry_id:139004)，LTP**）。
-   如果顺序相反（$\Delta t  0$），突触权重会减弱（**[长时程抑制](@entry_id:154883)，LTD**）。

权重的变化量通常是时间差 $\Delta t$ 的指数函数：
$$
\Delta w = \begin{cases} A_+ \exp(-\Delta t / \tau_+)  \text{如果 } \Delta t > 0 \\ -A_- \exp(\Delta t / \tau_-)  \text{如果 } \Delta t  0 \end{cases}
$$
其中 $A_+, A_-$ 控制学习幅度，$\tau_+, \tau_-$ 是时间常数。在“all-to-all”配对规则中，每一次突触前脉冲都与所有历史的突触后脉冲配对，反之亦然。直接实现在线计算需要存储所有脉冲的历史时间，这不具备可扩展性。

一个优雅的在线实现方法是为每个突触引入两个内部[状态变量](@entry_id:138790)，称为**[资格迹](@entry_id:1124370)（eligibility traces）** 。一个迹 $x_{\mathrm{pre}}(t)$ 由突触前脉冲触发，并以时间常数 $\tau_+$ 指数衰减；另一个迹 $x_{\mathrm{post}}(t)$ 由突触后脉冲触发，并以时间常数 $\tau_-$ 指数衰减。
-   当一个突触后脉冲在时刻 $t_{\mathrm{post}}$ 到达时，权重增加量正比于当时突触前迹的值 $x_{\mathrm{pre}}(t_{\mathrm{post}})$。
-   当一个突触前脉冲在时刻 $t_{\mathrm{pre}}$ 到达时，权重减少量正比于当时突触后迹的值 $x_{\mathrm{post}}(t_{\mathrm{pre}})$。

这种方法将复杂的历史依赖计算转化为了简单的本地状态更新，是神经[形态学](@entry_id:273085)习算法设计的典范。与此相对，**基于速率的赫布学习（rate-based Hebbian learning）**，其权重变化仅依赖于突触前后神经元的平均发放率。实现这种规则只需要在每个神经元层面维持一个[状态变量](@entry_id:138790)（即其发放率的低通滤波估计值），而不需要在每个突触层面维持额外的状态。这揭示了不同学习规则在硬件实现上对状态存储需求的重要差异。

#### 可塑性突触的物理载体：忆阻器

**[忆阻器](@entry_id:204379)（Memristors）**是一种新兴的电子器件，被认为是实现高密度、低功耗可塑性突触的理想选择。忆阻器是一个两端器件，其电导 $G$ 并非固定值，而是由一个或多个内部[状态变量](@entry_id:138790) $x(t)$ 决定。其电导可以通过施加电压或电流脉冲来调节，从而[模拟突触](@entry_id:1120995)权重的增强和抑制。

[忆阻器](@entry_id:204379)的行为由两个耦合方程描述：一个描述[电流-电压关系](@entry_id:163680)的方程 $i(t) = G(x(t))v(t)$，以及一个描述内部状态演化的方程 $\frac{dx}{dt} = F(x, v, i)$。在电路设计和仿真中，需要精确的**紧凑模型（compact models）**来描述其动力学。两个广泛使用的模型是 ：
1.  **线性离子漂移模型（Linear Ion Drift Model）**：该模型最初用于描述HP实验室的二氧化钛[忆阻器](@entry_id:204379)。它假设状态变化率与流过器件的电流成正比。一个关键特征是，任何非零的电压都会导致状态的微小改变，即没有一个明确的开关阈值。
2.  **电压阈值自适应忆阻器模型（VTEAM Model）**：为了克服线性漂移模型的局限性，VTEAM模型引入了明确的电压阈值 $V_{\mathrm{on}}$ 和 $V_{\mathrm{off}}$。只有当施加的电压 $|v(t)|$ 超过这些阈值时，器件的状态才会发生改变。在阈值之内存在一个“死区”，这使得在进行读操作时（使用低电压）不会意外地改写权重，这在实际应用中至关重要。

### 系统级集成：信息流与通信

当我们将数以百万计的神经元和突触集成在一起时，如何有效地传递信息并确保系统协调工作成为核心挑战。

#### [神经编码](@entry_id:263658)：脉冲中的信息

神经元通过[脉冲序列](@entry_id:1132157)来编码和传递信息。理解这些**[神经编码](@entry_id:263658)（neural codes）**方案是理解神经形态系统信息处理能力的关键 。
-   **速率编码（Rate Coding）**：信息被编码在神经元于特定时间窗口内的平均发放率（即脉冲数量）中。这是最简单、最稳健的编码方式。
-   **[时间编码](@entry_id:1132912)（Temporal Coding）**：信息的载体是脉冲的精确发放时间。例如，**[延迟编码](@entry_id:1127087)（latency coding）**将信息编码在刺激发生后第一个脉冲的延迟时间上。[时间编码](@entry_id:1132912)通常具有更高的信息容量和更快的传输速度。
-   **群体编码（Population Coding）**：信息被编码在一组神经元的联合活动模式中。通过组合多个神经元的响应，系统可以实现对信息的精确和稳健的表示。

理论分析（例如使用[费雪信息](@entry_id:144784)论）表明，这些编码方案的效率和信息容量依赖于神经元的动力学特性（如[不应期](@entry_id:152190)）和刺激的特性。例如，对于由具有不应期的泊松过程生成的脉冲，当观测时间窗口足够长（至少长于一个平均脉冲间隔）时，单个神经元的速率编码所携带的关于刺激强度的信息量，至少与[延迟编码](@entry_id:1127087)相当。而[群体编码](@entry_id:909814)通过在多个独立神经元上求平均，可以线性地增加总信息量，从而提高编码的保真度。

#### [异步通信](@entry_id:173592)：地址事件表示（AER）

在没有全局时钟的事件驱动系统中，需要一种机制来异步地通信脉冲事件。**地址事件表示（Address-Event Representation, AER）**是为此设计的标准通信协议。其核心思想是，当一个神经元发放脉冲时，它不会发送脉冲本身，而是将其唯一的**地址**（例如，它在神经元阵列中的行和列索引）广播到一个共享的总线上。

一个典型的AER互连系统包括 ：
-   一个共享的并行[数据总线](@entry_id:167432)，用于传输地址。
-   两条控制线，**请求（Request, REQ）**和**应答（Acknowledge, ACK）**，用于协调数据传输。
-   一个**仲裁器（Arbiter）**，用于处理多个神经元同时发放脉冲（即“事件碰撞”）的情况，确保在任何时刻只有一个地址被放到总线上。

控制线通常采用**开漏（open-drain）**驱动和[上拉电阻](@entry_id:178010)，形成“线或”逻辑。这允许多个发送方共享同一条REQ线。通信过程遵循一个**四相捆绑数据[握手协议](@entry_id:174594)（four-phase bundled-data handshake）** ：
1.  **发送方**：获得仲裁器授权后，将地址数据放到总线上。然后，它通过拉低REQ线来断言请求。
2.  **接收方**：检测到REQ线变低，它便锁存总线上的地址数据。然后，它拉低ACK线以示确认。
3.  **发送方**：检测到ACK线变低，它便释放REQ线（[上拉电阻](@entry_id:178010)将其拉高）。
4.  **接收方**：检测到REQ线变高，它也释放ACK线，完成一次握手周期。

这种协议通过局部的因果关系（请求-应答）实现了分布式同步，完全无需全局时钟。它的正确工作依赖于**捆绑约束（bundling constraint）**，即必须确保数据信号在[控制信号](@entry_id:747841)（REQ）到达接收方之前已经稳定，这通常通过在[控制路径](@entry_id:747840)上匹配或增加延迟来实现。

### 实践中的挑战：模拟硬件的非理想性

构建神经形态系统的终极挑战在于，真实的模拟硬件并非理想的数学模型。设计稳健的系统必须考虑并补偿这些**非理想性（non-idealities）**。一个全面的电子设计自动化（EDA）验证流程必须包含对这些效应的精确统计建模 。

主要的非理想性及其物理和统计特征包括：
-   **[器件失配](@entry_id:1123618)（Device Mismatch）**：由于制造过程中的微观随机性，阵列中相同设计的晶体管或[忆阻器](@entry_id:204379)会表现出参数差异。这种失配通常被建模为高斯分布，其方差与器件面积成反比（**[Pelgrom定律](@entry_id:1129488)**），并且在芯片上表现出空间相关性。
-   **时间噪声（Temporal Noise）**：[模拟电路](@entry_id:274672)中的电流和电压会随时间随机波动。这包括具有平坦功率谱的**白噪声**（如热噪声）和在低频占主导地位的**闪烁噪声（$1/f$噪声）**。后者被认为是由大量独立的电荷俘获/释放过程（[随机电报噪声](@entry_id:269610)）叠加而成。
-   **缓慢漂移（Slow Drift）**：[模拟存储器](@entry_id:1120991)件（如[浮栅晶体管](@entry_id:171866)或[忆阻器](@entry_id:204379)）中存储的模拟状态（权重）会随时间缓慢变化。这种漂移通常表现为均值随时间的对数（$\propto \log t$）演化，并伴随着显著的随机波动。
-   **静态[非线性](@entry_id:637147)（Static Nonlinearity）**：电路的传递函数很少是完美线性的。在工作点附近的弱[非线性](@entry_id:637147)可以通过[泰勒级数](@entry_id:147154)（例如，三阶多项式）来近似；而包括饱和在内的大信号[非线性](@entry_id:637147)则需要更复杂的模型，如[样条](@entry_id:143749)函数或[分段线性模型](@entry_id:261074)。
-   **随机开关（Stochastic Switching）**：忆阻器的电阻状态切换是一个固有的[随机过程](@entry_id:268487)，源于细丝形成/断裂的原子级动力学。这通常通过**危险率（hazard rate）**模型来描述，即在给定电压和温度下，单位时间内发生切换的瞬时概率。在恒定应力下，这会导致开关时间的[指数分布](@entry_id:273894)；而由于器件间的差异，开关时间总体上常呈现为[对数正态分布](@entry_id:261888)。

总之，神经形态架构的设计是一个跨越物理学、电路设计、[计算机体系结构](@entry_id:747647)和算法理论的多学科挑战。本章阐述的核心原理和机制为理解和设计这些下一代计算系统提供了坚实的基础。成功的神经形态工程师必须不仅掌握抽象的[计算模型](@entry_id:637456)，还要深刻理解其物理实现及其固有的复杂性和非理想性。