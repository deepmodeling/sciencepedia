{
    "hands_on_practices": [
        {
            "introduction": "A critical first step in applying machine learning to electronic design is converting physical layout information into a numerical format that a model can process. This exercise demonstrates this process by focusing on the Half-Perimeter Wirelength (HPWL), a fundamental metric for estimating the wirelength of a net. You will calculate HPWL from a given placement and then apply z-score normalization, a standard feature scaling technique that is essential for the stable training of many ML models .",
            "id": "4281028",
            "problem": "Consider the construction of input features for Machine Learning (ML) in Electronic Design Automation (EDA) from a legal cell placement. A set of five instances with orientation $N$ (no rotation or mirroring) is placed as follows: instance $U_1$ at $(10,10)\\,\\mathrm{\\mu m}$, instance $U_2$ at $(16,13)\\,\\mathrm{\\mu m}$, instance $U_3$ at $(22,9)\\,\\mathrm{\\mu m}$, instance $U_4$ at $(15,18)\\,\\mathrm{\\mu m}$, and instance $U_5$ at $(20,13)\\,\\mathrm{\\mu m}$. Each instance has pins with local offsets relative to the instance origin: on $U_1$, pin $A$ has offset $(1,0)\\,\\mathrm{\\mu m}$ and pin $B$ has offset $(0,2)\\,\\mathrm{\\mu m}$; on $U_2$, pin $A$ has offset $(-1,1)\\,\\mathrm{\\mu m}$ and pin $B$ has offset $(2,-1)\\,\\mathrm{\\mu m}$; on $U_3$, pin $A$ has offset $(0,-2)\\,\\mathrm{\\mu m}$ and pin $C$ has offset $(3,1)\\,\\mathrm{\\mu m}$; on $U_4$, pin $C$ has offset $(-2,2)\\,\\mathrm{\\mu m}$ and pin $D$ has offset $(1,-3)\\,\\mathrm{\\mu m}$; on $U_5$, pin $A$ has offset $(0,0)\\,\\mathrm{\\mu m}$. Because the orientation is $N$, absolute pin coordinates are obtained by vector addition of the instance coordinate and the pin’s local offset.\n\nThe net list is:\n- Net $e_1$: pins $U_1/A$, $U_2/B$, $U_3/A$.\n- Net $e_2$: pins $U_1/B$, $U_4/C$.\n- Net $e_3$: pins $U_2/A$, $U_3/C$, $U_4/D$, $U_5/A$.\n- Net $e_4$: pins $U_1/A$, $U_2/A$, $U_5/A$.\n\nUse the standard definition of Half-Perimeter Wirelength (HPWL): for a net $e$ with pin coordinates $\\{(x_i,y_i)\\}_{i \\in e}$, the HPWL feature $w_e$ is the sum of the horizontal and vertical spans of the minimal axis-aligned bounding rectangle containing all its pins, that is, $w_e$ equals the horizontal span $\\max_{i \\in e} x_i - \\min_{i \\in e} x_i$ plus the vertical span $\\max_{i \\in e} y_i - \\min_{i \\in e} y_i$. Compute the HPWL features $w_{e_1}$, $w_{e_2}$, $w_{e_3}$, and $w_{e_4}$ from the given placement and net list. Then, form the $z$-score normalized HPWL features across the set $\\{w_{e_1},w_{e_2},w_{e_3},w_{e_4}\\}$ using the sample mean and the unbiased sample standard deviation (that is, divide by the square root of the sample variance with denominator $n-1$ for $n=4$). Provide the normalized HPWL of net $e_3$ as a single closed-form exact algebraic expression. The normalized HPWL is unitless. Do not round your answer.",
            "solution": "The solution is obtained by following these steps:\n$1$. Determine the absolute coordinates of all pins by adding the local pin offsets to their respective instance coordinates.\n$2$. Compute the HPWL feature for each of the four nets, denoted as $w_{e_1}$, $w_{e_2}$, $w_{e_3}$, and $w_{e_4}$.\n$3$. Calculate the sample mean, $\\bar{w}$, and the unbiased sample standard deviation, $s$, of the resulting set of HPWL values $\\{w_{e_1}, w_{e_2}, w_{e_3}, w_{e_4}\\}$.\n$4$. Compute the z-score for $w_{e_3}$ using the formula $z_{e_3} = (w_{e_3} - \\bar{w}) / s$.\n\nStep 1: Absolute Pin Coordinates\nAll coordinates are in units of $\\mathrm{\\mu m}$. The absolute coordinate of a pin is given by the vector sum of the instance coordinate and the pin's local offset.\n\nFor net $e_1$ (pins $U_1/A, U_2/B, U_3/A$):\n- Pin $U_1/A$: $(10,10) + (1,0) = (11,10)$\n- Pin $U_2/B$: $(16,13) + (2,-1) = (18,12)$\n- Pin $U_3/A$: $(22,9) + (0,-2) = (22,7)$\n\nFor net $e_2$ (pins $U_1/B, U_4/C$):\n- Pin $U_1/B$: $(10,10) + (0,2) = (10,12)$\n- Pin $U_4/C$: $(15,18) + (-2,2) = (13,20)$\n\nFor net $e_3$ (pins $U_2/A, U_3/C, U_4/D, U_5/A$):\n- Pin $U_2/A$: $(16,13) + (-1,1) = (15,14)$\n- Pin $U_3/C$: $(22,9) + (3,1) = (25,10)$\n- Pin $U_4/D$: $(15,18) + (1,-3) = (16,15)$\n- Pin $U_5/A$: $(20,13) + (0,0) = (20,13)$\n\nFor net $e_4$ (pins $U_1/A, U_2/A, U_5/A$):\n- Pin $U_1/A$: $(11,10)$\n- Pin $U_2/A$: $(15,14)$\n- Pin $U_5/A$: $(20,13)$\n\nStep 2: HPWL Calculation per Net\nThe HPWL, $w_e$, is defined as $(\\max_{i \\in e} x_i - \\min_{i \\in e} x_i) + (\\max_{i \\in e} y_i - \\min_{i \\in e} y_i)$.\n\nFor net $e_1$, with pin coordinates $\\{(11,10), (18,12), (22,7)\\}$:\n- Horizontal span: $\\max(11, 18, 22) - \\min(11, 18, 22) = 22 - 11 = 11$\n- Vertical span: $\\max(10, 12, 7) - \\min(10, 12, 7) = 12 - 7 = 5$\n- $w_{e_1} = 11 + 5 = 16$\n\nFor net $e_2$, with pin coordinates $\\{(10,12), (13,20)\\}$:\n- Horizontal span: $\\max(10, 13) - \\min(10, 13) = 13 - 10 = 3$\n- Vertical span: $\\max(12, 20) - \\min(12, 20) = 20 - 12 = 8$\n- $w_{e_2} = 3 + 8 = 11$\n\nFor net $e_3$, with pin coordinates $\\{(15,14), (25,10), (16,15), (20,13)\\}$:\n- Horizontal span: $\\max(15, 25, 16, 20) - \\min(15, 25, 16, 20) = 25 - 15 = 10$\n- Vertical span: $\\max(14, 10, 15, 13) - \\min(14, 10, 15, 13) = 15 - 10 = 5$\n- $w_{e_3} = 10 + 5 = 15$\n\nFor net $e_4$, with pin coordinates $\\{(11,10), (15,14), (20,13)\\}$:\n- Horizontal span: $\\max(11, 15, 20) - \\min(11, 15, 20) = 20 - 11 = 9$\n- Vertical span: $\\max(10, 14, 13) - \\min(10, 14, 13) = 14 - 10 = 4$\n- $w_{e_4} = 9 + 4 = 13$\n\nThe set of HPWL features is $W = \\{16, 11, 15, 13\\}$.\n\nStep 3: Statistical Calculation\nWe have a sample of $n=4$ HPWL values.\nThe sample mean, $\\bar{w}$, is:\n$$ \\bar{w} = \\frac{1}{4} (16 + 11 + 15 + 13) = \\frac{55}{4} $$\nThe unbiased sample variance, $s^2$, is calculated with a denominator of $n-1 = 3$:\n$$ s^2 = \\frac{1}{3} \\sum_{w \\in W} (w - \\bar{w})^2 $$\n$$ s^2 = \\frac{1}{3} \\left[ \\left(16 - \\frac{55}{4}\\right)^2 + \\left(11 - \\frac{55}{4}\\right)^2 + \\left(15 - \\frac{55}{4}\\right)^2 + \\left(13 - \\frac{55}{4}\\right)^2 \\right] $$\n$$ s^2 = \\frac{1}{3} \\left[ \\left(\\frac{9}{4}\\right)^2 + \\left(-\\frac{11}{4}\\right)^2 + \\left(\\frac{5}{4}\\right)^2 + \\left(-\\frac{3}{4}\\right)^2 \\right] $$\n$$ s^2 = \\frac{1}{3} \\left[ \\frac{81}{16} + \\frac{121}{16} + \\frac{25}{16} + \\frac{9}{16} \\right] = \\frac{1}{3} \\left( \\frac{236}{16} \\right) = \\frac{1}{3} \\left( \\frac{59}{4} \\right) = \\frac{59}{12} $$\nThe unbiased sample standard deviation, $s$, is the square root of the variance:\n$$ s = \\sqrt{\\frac{59}{12}} $$\n\nStep 4: Z-score Normalization for $w_{e_3}$\nThe z-score for $w_{e_3}=15$ is:\n$$ z_{e_3} = \\frac{w_{e_3} - \\bar{w}}{s} = \\frac{15 - \\frac{55}{4}}{\\sqrt{\\frac{59}{12}}} = \\frac{\\frac{60-55}{4}}{\\sqrt{\\frac{59}{12}}} = \\frac{\\frac{5}{4}}{\\frac{\\sqrt{59}}{\\sqrt{12}}} $$\nSimplifying the expression:\n$$ z_{e_3} = \\frac{5}{4} \\frac{\\sqrt{12}}{\\sqrt{59}} = \\frac{5}{4} \\frac{\\sqrt{4 \\cdot 3}}{\\sqrt{59}} = \\frac{5}{4} \\frac{2\\sqrt{3}}{\\sqrt{59}} = \\frac{5\\sqrt{3}}{2\\sqrt{59}} $$\nTo provide a closed-form expression with a rational denominator, we multiply the numerator and denominator by $\\sqrt{59}$:\n$$ z_{e_3} = \\frac{5\\sqrt{3}}{2\\sqrt{59}} \\cdot \\frac{\\sqrt{59}}{\\sqrt{59}} = \\frac{5\\sqrt{3 \\cdot 59}}{2 \\cdot 59} = \\frac{5\\sqrt{177}}{118} $$\nThis is the final, exact, unitless value.",
            "answer": "$$\\boxed{\\frac{5\\sqrt{177}}{118}}$$"
        },
        {
            "introduction": "Machine learning models can significantly accelerate the design cycle by providing rapid estimations for computationally expensive tasks like Static Timing Analysis (STA). In this problem, you will step into the role of an EDA engineer evaluating a simple linear model trained to predict timing slack. By calculating the model's predictions and comparing them against golden STA results using the Mean Absolute Error ($MAE$), you will gain hands-on experience with a core task in ML-driven EDA: quantifying model performance to determine its real-world viability .",
            "id": "4281022",
            "problem": "A research group in Electronic Design Automation (EDA) is training a machine learning model to predict path timing slack to reduce the frequency of full Static Timing Analysis (STA). For a given design, the trained predictor is a linear model that maps an engineered feature vector to a predicted slack. The model takes a feature vector $\\mathbf{x} \\in \\mathbb{R}^{5}$, a learned weight vector $\\mathbf{w} \\in \\mathbb{R}^{5}$, and a learned bias $b \\in \\mathbb{R}$, and produces a predicted slack. The five features are engineered, dimensionless indices derived from path characteristics and are on consistent internal scales across training and inference; examples include a drive-strength index, a fanout-load index, an inverse-slew index, an interconnect-length index, and a high-threshold-cell fraction index. The goal is to evaluate the model on three unseen paths by comparing its predictions to reference STA slacks.\n\nYou are given the learned parameters $\\mathbf{w}$ and $b$:\n- $\\mathbf{w} = [\\,0.12,\\,-0.08,\\,0.50,\\,-0.02,\\,-0.40\\,]$,\n- $b = 0.05$.\n\nYou are also given three path feature vectors and their corresponding STA slacks (reference values), all slacks measured in nanoseconds:\n- Path $1$: $\\mathbf{x}^{(1)} = [\\,10,\\,5,\\,0.3,\\,20,\\,0.1\\,]$, STA slack $s^{\\mathrm{STA}}_{1} = 0.60$.\n- Path $2$: $\\mathbf{x}^{(2)} = [\\,8,\\,7,\\,0.5,\\,15,\\,0.2\\,]$, STA slack $s^{\\mathrm{STA}}_{2} = 0.28$.\n- Path $3$: $\\mathbf{x}^{(3)} = [\\,12,\\,3,\\,0.2,\\,25,\\,0.05\\,]$, STA slack $s^{\\mathrm{STA}}_{3} = 0.70$.\n\nCompute the predicted slack for each path using the linear model and then compute the mean absolute error between the three predictions and the three STA slacks. Express the final mean absolute error in nanoseconds. Round your final answer to four significant figures.",
            "solution": "The predicted slack, $s^{\\mathrm{pred}}$, is calculated using the linear model:\n$$ s^{\\mathrm{pred}} = \\mathbf{w}^T \\mathbf{x} + b = \\sum_{j=1}^{5} w_j x_j + b $$\nThe given parameters are the weight vector $\\mathbf{w} = [\\,0.12,\\, -0.08,\\, 0.50,\\, -0.02,\\, -0.40\\,]^T$ and the bias $b = 0.05$.\n\nWe compute the predicted slack for each of the three paths.\n\nFor Path $1$, with $\\mathbf{x}^{(1)} = [\\,10,\\, 5,\\, 0.3,\\, 20,\\, 0.1\\,]^T$:\n$$ s^{\\mathrm{pred}}_{1} = \\mathbf{w}^T \\mathbf{x}^{(1)} + b $$\n$$ s^{\\mathrm{pred}}_{1} = (0.12)(10) + (-0.08)(5) + (0.50)(0.3) + (-0.02)(20) + (-0.40)(0.1) + 0.05 $$\n$$ s^{\\mathrm{pred}}_{1} = 1.20 - 0.40 + 0.15 - 0.40 - 0.04 + 0.05 $$\n$$ s^{\\mathrm{pred}}_{1} = 1.40 - 0.84 = 0.56 $$\n\nFor Path $2$, with $\\mathbf{x}^{(2)} = [\\,8,\\, 7,\\, 0.5,\\, 15,\\, 0.2\\,]^T$:\n$$ s^{\\mathrm{pred}}_{2} = \\mathbf{w}^T \\mathbf{x}^{(2)} + b $$\n$$ s^{\\mathrm{pred}}_{2} = (0.12)(8) + (-0.08)(7) + (0.50)(0.5) + (-0.02)(15) + (-0.40)(0.2) + 0.05 $$\n$$ s^{\\mathrm{pred}}_{2} = 0.96 - 0.56 + 0.25 - 0.30 - 0.08 + 0.05 $$\n$$ s^{\\mathrm{pred}}_{2} = 1.26 - 0.94 = 0.32 $$\n\nFor Path $3$, with $\\mathbf{x}^{(3)} = [\\,12,\\, 3,\\, 0.2,\\, 25,\\, 0.05\\,]^T$:\n$$ s^{\\mathrm{pred}}_{3} = \\mathbf{w}^T \\mathbf{x}^{(3)} + b $$\n$$ s^{\\mathrm{pred}}_{3} = (0.12)(12) + (-0.08)(3) + (0.50)(0.2) + (-0.02)(25) + (-0.40)(0.05) + 0.05 $$\n$$ s^{\\mathrm{pred}}_{3} = 1.44 - 0.24 + 0.10 - 0.50 - 0.02 + 0.05 $$\n$$ s^{\\mathrm{pred}}_{3} = 1.59 - 0.76 = 0.83 $$\n\nNext, we compute the Mean Absolute Error (MAE) between the predicted slacks ($s^{\\mathrm{pred}}_{i}$) and the reference STA slacks ($s^{\\mathrm{STA}}_{i}$). The formula for MAE over $N=3$ samples is:\n$$ \\text{MAE} = \\frac{1}{N} \\sum_{i=1}^{N} |s^{\\mathrm{pred}}_{i} - s^{\\mathrm{STA}}_{i}| $$\nThe reference STA slacks are given as $s^{\\mathrm{STA}}_{1} = 0.60$, $s^{\\mathrm{STA}}_{2} = 0.28$, and $s^{\\mathrm{STA}}_{3} = 0.70$.\n\nFirst, we calculate the absolute error for each path:\n- Path $1$ error: $|s^{\\mathrm{pred}}_{1} - s^{\\mathrm{STA}}_{1}| = |0.56 - 0.60| = |-0.04| = 0.04$.\n- Path $2$ error: $|s^{\\mathrm{pred}}_{2} - s^{\\mathrm{STA}}_{2}| = |0.32 - 0.28| = |0.04| = 0.04$.\n- Path $3$ error: $|s^{\\mathrm{pred}}_{3} - s^{\\mathrm{STA}}_{3}| = |0.83 - 0.70| = |0.13| = 0.13$.\n\nNow, we compute the MAE:\n$$ \\text{MAE} = \\frac{1}{3} (0.04 + 0.04 + 0.13) $$\n$$ \\text{MAE} = \\frac{1}{3} (0.21) $$\n$$ \\text{MAE} = 0.07 $$\n\nThe problem requires the final answer to be rounded to four significant figures. The calculated value is $0.07$. To express this with four significant figures, we add trailing zeros, resulting in $0.07000$. All slacks and errors are in units of nanoseconds.",
            "answer": "$$\\boxed{0.07000}$$"
        },
        {
            "introduction": "Many critical EDA tasks, such as predicting Design Rule Checking (DRC) violations, are classification problems characterized by severe class imbalance. In such scenarios, simple accuracy is a misleading metric of performance. This practice challenges you to use more robust metrics—precision, recall, and the $F_1$ score—to evaluate a violation classifier and, importantly, to contextualize its performance by comparing it to a random baseline, a crucial step for assessing true predictive power .",
            "id": "4280966",
            "problem": "An Electronic Design Automation (EDA) team is evaluating a learned binary classifier that predicts whether a given lithography layout patch contains a Design Rule Checking (DRC) violation. The test set contains $N=50000$ patches. The ground-truth number of violation patches is $P=350$. When the classifier is run at a fixed threshold tuned on a separate validation set, the number of predicted violation patches on the test set is $PP=1200$, among which $TP=280$ are truly violations, while the remainder are nonviolations.\n\nUsing only standard definitions of classification metrics grounded in counts of true positives, false positives, true negatives, and false negatives, compute the precision, recall, and $F_{1}$ score of the classifier on this test set.\n\nTo quantitatively assess the impact of the class imbalance inherent in this task, consider a reference classifier that independently assigns the violation label to each patch with a probability equal to the classifier’s positive prediction rate on this test set. Using first principles, determine the expected $F_{1}$ score of this reference classifier in the large-sample limit, and then compute the ratio of the classifier’s $F_{1}$ score to this reference $F_{1}$.\n\nRound all numerical results to four significant figures. Report your final numerical answers as a single row matrix in the order: precision, recall, $F_{1}$, ratio.",
            "solution": "The solution is divided into three parts: first, the computation of the primary classification metrics for the given classifier; second, the analysis of the reference random classifier; and third, the computation of the final ratio.\n\n### Part 1: Performance Metrics of the Given Classifier\n\nWe are given the following counts:\n- Total samples: $N = 50000$\n- True Positives (correctly identified violations): $TP = 280$\n- Ground-truth Positives (total actual violations): $P = 350$\n- Predicted Positives (total predicted violations): $PP = 1200$\n\nFrom these, we can derive the counts for False Positives ($FP$) and False Negatives ($FN$).\n\nA False Positive is a sample incorrectly classified as positive. The total number of predicted positives is $PP = TP + FP$.\n$$FP = PP - TP = 1200 - 280 = 920$$\n\nA False Negative is a sample incorrectly classified as negative. The total number of actual positives is $P = TP + FN$.\n$$FN = P - TP = 350 - 280 = 70$$\n\nWith these fundamental quantities, we can compute the standard metrics.\n\n**Precision ($\\mathcal{P}$)** is the fraction of predicted positives that are actually positive.\n$$\\mathcal{P} = \\frac{TP}{TP + FP} = \\frac{280}{280 + 920} = \\frac{280}{1200} = \\frac{7}{30}$$\nAs a decimal rounded to four significant figures, $\\mathcal{P} \\approx 0.2333$.\n\n**Recall ($\\mathcal{R}$)**, also known as sensitivity or true positive rate, is the fraction of actual positives that are correctly identified.\n$$\\mathcal{R} = \\frac{TP}{TP + FN} = \\frac{280}{280 + 70} = \\frac{280}{350} = \\frac{4}{5}$$\nAs a decimal, $\\mathcal{R} = 0.8$. To four significant figures, this is $0.8000$.\n\nThe **$F_1$ score** is the harmonic mean of precision and recall.\n$$F_1 = 2 \\cdot \\frac{\\mathcal{P} \\cdot \\mathcal{R}}{\\mathcal{P} + \\mathcal{R}}$$\nSubstituting the exact fractional values for $\\mathcal{P}$ and $\\mathcal{R}$:\n$$F_1 = 2 \\cdot \\frac{\\left(\\frac{7}{30}\\right) \\cdot \\left(\\frac{4}{5}\\right)}{\\left(\\frac{7}{30}\\right) + \\left(\\frac{4}{5}\\right)} = 2 \\cdot \\frac{\\frac{28}{150}}{\\frac{7}{30} + \\frac{24}{30}} = 2 \\cdot \\frac{\\frac{28}{150}}{\\frac{31}{30}} = 2 \\cdot \\frac{28}{150} \\cdot \\frac{30}{31} = 2 \\cdot \\frac{28}{5 \\cdot 30} \\cdot \\frac{30}{31} = \\frac{56}{155}$$\nAs a decimal rounded to four significant figures, $F_1 \\approx 0.3613$.\n\n### Part 2: Expected Performance of the Reference Classifier\n\nThe reference classifier is defined to label each patch as a violation with a probability, $p_{pred}$, equal to the given classifier's positive prediction rate.\n$$p_{pred} = \\frac{PP}{N} = \\frac{1200}{50000} = \\frac{12}{500} = \\frac{3}{125} = 0.024$$\n\nThe base rate, or true prevalence, of violations in the dataset is $p_{true}$.\n$$p_{true} = \\frac{P}{N} = \\frac{350}{50000} = \\frac{35}{5000} = \\frac{7}{1000} = 0.007$$\n\nFor this reference classifier, since predictions are made independently of the true label, we can calculate the expected values for precision and recall in the large-sample limit. For a random classifier of this type, the expected precision is equal to the base rate of the positive class, and the expected recall is equal to the prediction rate.\n\nThe expected precision, $E[\\mathcal{P}_{ref}]$, is the expected number of true positives divided by the expected number of predicted positives.\n$$E[\\mathcal{P}_{ref}] = \\frac{E[TP_{ref}]}{E[TP_{ref}] + E[FP_{ref}]} = \\frac{N \\cdot p_{true} \\cdot p_{pred}}{N \\cdot p_{true} \\cdot p_{pred} + N \\cdot (1-p_{true}) \\cdot p_{pred}} = \\frac{p_{true} \\cdot p_{pred}}{p_{pred} \\cdot (p_{true} + 1 - p_{true})} = p_{true}$$\nSo, $E[\\mathcal{P}_{ref}] = 0.007$.\n\nThe expected recall, $E[\\mathcal{R}_{ref}]$, is the expected number of true positives divided by the expected number of actual positives.\n$$E[\\mathcal{R}_{ref}] = \\frac{E[TP_{ref}]}{E[TP_{ref}] + E[FN_{ref}]} = \\frac{N \\cdot p_{true} \\cdot p_{pred}}{N \\cdot p_{true} \\cdot p_{pred} + N \\cdot p_{true} \\cdot (1-p_{pred})} = \\frac{p_{true} \\cdot p_{pred}}{p_{true} \\cdot (p_{pred} + 1 - p_{pred})} = p_{pred}$$\nSo, $E[\\mathcal{R}_{ref}] = 0.024$.\n\nThe expected $F_1$ score for this reference classifier, $F_{1,ref}$, is the harmonic mean of its expected precision and recall.\n$$F_{1,ref} = 2 \\cdot \\frac{E[\\mathcal{P}_{ref}] \\cdot E[\\mathcal{R}_{ref}]}{E[\\mathcal{P}_{ref}] + E[\\mathcal{R}_{ref}]} = 2 \\cdot \\frac{p_{true} \\cdot p_{pred}}{p_{true} + p_{pred}}$$\nSubstituting the numerical values:\n$$F_{1,ref} = 2 \\cdot \\frac{(0.007) \\cdot (0.024)}{0.007 + 0.024} = 2 \\cdot \\frac{0.000168}{0.031} = \\frac{0.000336}{0.031}$$\nAs a decimal rounded to four significant figures, $F_{1,ref} \\approx 0.01084$.\n\n### Part 3: Ratio of $F_1$ Scores\n\nThe final step is to compute the ratio of the classifier's $F_1$ score to the expected $F_1$ score of the reference classifier.\n$$\\text{Ratio} = \\frac{F_1}{F_{1,ref}}$$\nUsing the exact fractions provides the most accurate result.\n$$F_1 = \\frac{56}{155}$$\n$$F_{1,ref} = 2 \\cdot \\frac{\\frac{7}{1000} \\cdot \\frac{3}{125}}{\\frac{7}{1000} + \\frac{3}{125}} = 2 \\cdot \\frac{\\frac{21}{125000}}{\\frac{7}{1000} + \\frac{24}{1000}} = 2 \\cdot \\frac{\\frac{21}{125000}}{\\frac{31}{1000}} = 2 \\cdot \\frac{21}{125000} \\cdot \\frac{1000}{31} = \\frac{42}{125 \\cdot 31} = \\frac{42}{3875}$$\n$$\\text{Ratio} = \\frac{\\frac{56}{155}}{\\frac{42}{3875}} = \\frac{56}{155} \\cdot \\frac{3875}{42} = \\frac{56}{42} \\cdot \\frac{3875}{155} = \\frac{4}{3} \\cdot \\frac{3875}{155}$$\nSince $155 = 5 \\cdot 31$ and $3875 = 125 \\cdot 31$, the ratio simplifies:\n$$\\text{Ratio} = \\frac{4}{3} \\cdot \\frac{125 \\cdot 31}{5 \\cdot 31} = \\frac{4}{3} \\cdot \\frac{125}{5} = \\frac{4}{3} \\cdot 25 = \\frac{100}{3}$$\nAs a decimal rounded to four significant figures, the ratio is $33.33$.\n\nFinal answers, rounded to four significant figures, are:\n- Precision: $0.2333$\n- Recall: $0.8000$\n- $F_1$ Score: $0.3613$\n- Ratio: $33.33$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2333 & 0.8000 & 0.3613 & 33.33 \\end{pmatrix}}\n$$"
        }
    ]
}