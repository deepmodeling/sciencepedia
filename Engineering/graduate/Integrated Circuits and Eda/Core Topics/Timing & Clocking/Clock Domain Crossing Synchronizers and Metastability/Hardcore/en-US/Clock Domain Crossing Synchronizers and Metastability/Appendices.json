{
    "hands_on_practices": [
        {
            "introduction": "The reliability of a clock domain crossing synchronizer is quantified by its Mean Time Between Failures (MTBF). This first exercise provides a foundational analysis of the most common synchronizer structure: the two-flop synchronizer. By reasoning from basic timing parameters like clock period, setup times, and clock-to-Q delays, you will derive the classic exponential relationship between the available resolution time and the MTBF . Mastering this derivation is essential for developing an intuition for why synchronizers work and how their reliability is fundamentally limited by the physics of metastability.",
            "id": "4259927",
            "problem": "A two-stage flip-flop synchronizer is used to transfer an asynchronous binary signal into a destination clock domain in an integrated circuit designed under the methods of Electronic Design Automation (EDA). The synchronizer consists of two positive-edge-triggered D flip-flops in series, both clocked by the destination clock. The first stage ($\\text{FF1}$) samples the asynchronous input, and the second stage ($\\text{FF2}$) samples the output of $\\text{FF1}$ one destination clock cycle later. Let the destination clock period be $T_{clk}$. Let the clock arrival times at $\\text{FF1}$ and $\\text{FF2}$ differ by a clock skew $skew$, defined as the time by which the clock at $\\text{FF2}$ is advanced with respect to the clock at $\\text{FF1}$; a positive $skew$ reduces the time available between the two sampling events. The first-stage clock-to-$Q$ delay is $t_{cq1}$, and the second-stage setup time requirement is $t_{setup2}$. \n\nUnder the standard metastability model for bistable circuits, once a sampling event drives the first-stage latch into a metastable state, the probability that the metastable state persists longer than a time $t$ decays approximately exponentially with characteristic time constant $\\tau>0$, and a device- and process-dependent parameter $T_{0}>0$ captures the effective width of the vulnerable timing aperture and the gain factors of the latch. Assume the asynchronous input transitions at an average rate equal to the destination clock frequency and that sampling occurs every destination clock, i.e., both the input transition rate and the sampling rate equal $1/T_{clk}$.\n\nStarting only from these definitions and assumptions, and the behavior of exponential decay of metastability resolution with time constant $\\tau$, perform the following:\n\n1. Derive the available metastability resolution time $T_{res}$ between the sampling edge at $\\text{FF1}$ and the next sampling edge at $\\text{FF2}$, expressed in terms of $T_{clk}$, $t_{cq1}$, $t_{setup2}$, and $skew$. Clearly justify each term in your expression based on timing requirements and causality.\n\n2. Using the exponential resolution model and the stated event and sampling rates, derive a closed-form analytic expression for the Mean Time Between Failures (MTBF) of this two-flop synchronizer in seconds as a function of $T_{clk}$, $t_{cq1}$, $t_{setup2}$, $skew$, $\\tau$, and $T_{0}$. Express your final MTBF as a single closed-form expression in seconds. Do not evaluate numerically; no rounding is required.",
            "solution": "The goal is to derive the available resolution time for metastability and then, using a well-supported stochastic model of metastability resolution, derive the failure rate and the Mean Time Between Failures (MTBF).\n\nWe begin with the timing structure of a two-stage synchronizer in the destination clock domain. The two flip-flops are clocked by the destination clock. Let the clock period be $T_{clk}$, and let the clock arrival time at the second flip-flop $\\text{FF2}$ be advanced by $skew$ relative to the arrival time at the first flip-flop $\\text{FF1}$. A positive $skew$ thus reduces the time between the sampling edges of $\\text{FF1}$ and $\\text{FF2}$ from $T_{clk}$ to $T_{clk}-skew$.\n\nThe first flip-flop $\\text{FF1}$ samples the asynchronous input at a rising edge. If that sampling violates aperture timing (arriving sufficiently close to the sampling instant), $\\text{FF1}$ can enter a metastable state and only resolve after some random resolution time. The earliest time at which the output of $\\text{FF1}$ ($Q_1$) can become valid and start propagating toward $\\text{FF2}$ is the clock edge time at $\\text{FF1}$ plus the clock-to-$Q$ delay $t_{cq1}$, plus the random additional time the state takes to move sufficiently close to a stable rail. The input of $\\text{FF2}$ must be stable for $t_{setup2}$ before the sampling edge at $\\text{FF2}$ to ensure correct capture. Therefore, the available time for the metastable state at $\\text{FF1}$ to resolve must fit before the instant $(\\text{FF2 clock edge}) - t_{setup2}$.\n\nLet the pertinent edges be synchronized as follows: A sampling event occurs at $\\text{FF1}$ at time $t=0$. The next sampling edge at $\\text{FF2}$ occurs at time $t=T_{clk}-skew$ (because of the assumed positive $skew$ advancing $\\text{FF2}$). For correct capture, $Q_1$ must have stabilized and reached $\\text{FF2}$ input at least $t_{setup2}$ before this $\\text{FF2}$ edge. Also, $Q_1$ does not begin to change until after the deterministic delay $t_{cq1}$ from the $\\text{FF1}$ edge. These timing requirements yield the available resolution time from the $\\text{FF1}$ sampling instant to the latest allowed arrival at $\\text{FF2}$ input as\n$$\nT_{res} \\;=\\; (\\text{time from }\\text{FF1}\\text{ edge to }\\text{FF2}\\text{ edge}) \\;-\\; t_{cq1} \\;-\\; t_{setup2} \\;=\\; T_{clk} - skew - t_{cq1} - t_{setup2}.\n$$\nThis expression subtracts the deterministic time budgets $t_{cq1}$ and $t_{setup2}$ and the effective reduction in edge spacing $skew$ from the nominal one-period separation $T_{clk}$, leaving the interval available for the metastable state in $\\text{FF1}$ to resolve such that $\\text{FF2}$ samples a valid level.\n\nNext we turn to the metastability resolution statistics. For a bistable element driven into metastability by a violating input arriving near a sampling edge, the distribution of the time it takes to resolve sufficiently close to a stable rail obeys an exponential tail beyond a small offset. A widely used form models the probability that the resolution time exceeds $t$ as proportional to $\\exp(-t/\\tau)$, where $\\tau$ is the latch’s time constant. The constant of proportionality is not a pure probability but emerges in failure rate calculations as a factor with units of time, customarily denoted $T_{0}$, which incorporates the effective width of the vulnerable aperture and gain-related parameters. When combining this decay with independent input transition events and independent sampling events, the failure rate per unit time is modeled as the product of (i) the rate of opportunities for a violating arrival relative to a sampling edge and (ii) the probability that the resulting metastability persists longer than the available resolution time:\n$$\n\\lambda \\;=\\; f_{\\text{clk}} \\, f_{\\text{data}} \\, T_{0} \\, \\exp\\!\\left(-\\frac{T_{res}}{\\tau}\\right),\n$$\nwhere $f_{\\text{clk}}$ is the destination sampling rate and $f_{\\text{data}}$ is the average input transition rate into the synchronizer. Under the stated assumption, both rates equal the destination clock frequency: $f_{\\text{clk}}=f_{\\text{data}}=\\frac{1}{T_{clk}}$. Substituting these and our derived $T_{res}$ gives\n$$\n\\lambda \\;=\\; \\left(\\frac{1}{T_{clk}}\\right)\\left(\\frac{1}{T_{clk}}\\right) T_{0} \\, \\exp\\!\\left(-\\frac{T_{clk}-t_{cq1}-t_{setup2}-skew}{\\tau}\\right)\n\\;=\\; \\frac{T_{0}}{T_{clk}^{2}} \\, \\exp\\!\\left(-\\frac{T_{clk}-t_{cq1}-t_{setup2}-skew}{\\tau}\\right).\n$$\nThe Mean Time Between Failures (MTBF) is the reciprocal of the failure rate,\n$$\n\\text{MTBF} \\;=\\; \\frac{1}{\\lambda} \\;=\\; \\frac{T_{clk}^{2}}{T_{0}} \\, \\exp\\!\\left(\\frac{T_{clk}-t_{cq1}-t_{setup2}-skew}{\\tau}\\right),\n$$\nwhich is in seconds because $T_{clk}^{2}/T_{0}$ has dimensions of time and the exponential is dimensionless.\n\nIn summary, the derived available resolution time is\n$$\nT_{res} \\;=\\; T_{clk} - t_{cq1} - t_{setup2} - skew,\n$$\nand, under the stated rates and metastability model, the MTBF in seconds is\n$$\n\\text{MTBF} \\;=\\; \\frac{T_{clk}^{2}}{T_{0}} \\, \\exp\\!\\left(\\frac{T_{clk}-t_{cq1}-t_{setup2}-skew}{\\tau}\\right).\n$$",
            "answer": "$$\\boxed{\\frac{T_{clk}^{2}}{T_{0}} \\exp\\!\\left(\\frac{T_{clk}-t_{cq1}-t_{setup2}-skew}{\\tau}\\right)}$$"
        },
        {
            "introduction": "While the previous practice established how to analyze synchronizer reliability, practical design involves making trade-offs to meet system requirements. This exercise addresses the classic dilemma between reliability and performance: adding more synchronizer stages exponentially improves the MTBF but linearly increases signal latency. You will tackle a realistic optimization problem, determining the minimum number of stages required to satisfy a strict MTBF target without violating a maximum latency constraint . This practice demonstrates how to apply the metastability model to make quantitative decisions that balance competing design goals.",
            "id": "4259950",
            "problem": "A digital system-on-chip must safely transfer a single-bit control signal from an asynchronous source domain into a destination domain using a cascade of identical edge-triggered flip-flops as a synchronizer. The destination domain samples at frequency $f_{\\text{clk}}$ with period $T_{\\text{clk}}$. Each additional flip-flop stage adds one destination clock cycle of end-to-end latency. The source bit toggles independently with average frequency $f_{\\text{data}}$, creating potential asynchronous sampling hazards.\n\nMetastability in a flip-flop is modeled by an exponentially decaying resolution process: the probability that the metastable state has not resolved by time $t$ decays proportionally to $\\exp(-t/\\tau)$, where $\\tau$ is the metastability time constant of the device. There exists a technology-dependent effective time offset $T_{0}$ that captures the width of the vulnerable aperture and related internal parameters, such that failures occur when the metastability persists longer than the available resolution time $T_{\\text{res}}$ beyond $T_{0}$. A failure can occur on any sampling attempt, and sampling attempts occur at a rate proportional to the product $f_{\\text{clk}} f_{\\text{data}}$ under independence assumptions. The aggregate Mean Time Between Failures (MTBF) increases exponentially with the available resolution time $T_{\\text{res}}$ and decreases linearly with the attempt rate.\n\nThe available resolution time scales with the number of synchronizer stages $N$ as $T_{\\text{res}} = N T_{\\text{clk}} - T_{\\text{guard}}$, where $T_{\\text{guard}}$ is a fixed timing guard that lumps setup-time requirements and interstage clock-to-$Q$ and skew effects into a single conservative margin. Assume $T_{\\text{guard}}$ is independent of $N$.\n\nGiven the system and device parameters\n- destination clock frequency $f_{\\text{clk}} = 1.0 \\times 10^{9} \\, \\text{s}^{-1}$ (so $T_{\\text{clk}} = 1.0 \\times 10^{-9} \\, \\text{s}$),\n- source toggle frequency $f_{\\text{data}} = 2.0 \\times 10^{8} \\, \\text{s}^{-1}$,\n- metastability time constant $\\tau = 30 \\times 10^{-12} \\, \\text{s}$,\n- effective offset $T_{0} = 20 \\times 10^{-12} \\, \\text{s}$,\n- timing guard $T_{\\text{guard}} = 150 \\times 10^{-12} \\, \\text{s}$,\n- target Mean Time Between Failures $\\mathrm{MTBF}_{\\text{target}} = 10 \\, \\text{years}$ (use $1 \\, \\text{year} = 3.1536 \\times 10^{7} \\, \\text{s}$),\n- maximum allowable end-to-end latency $L_{\\max} = 2$ destination clock cycles,\n\nderive from first principles an analytical expression for the MTBF as a function of $T_{\\text{res}}$, and use it to determine the smallest integer number of synchronizer stages $N$ that simultaneously satisfies $\\mathrm{MTBF} \\ge \\mathrm{MTBF}_{\\text{target}}$ and the latency constraint $N \\le L_{\\max}$. Express your final answer as the integer $N$ with no units. No rounding is required beyond exact integer selection.",
            "solution": "The problem requires deriving an expression for the Mean Time Between Failures (MTBF) from first principles as described in the prompt.\n\nThe rate of failures, $R_{\\text{fail}}$, is the product of the rate at which the system enters a metastable state and the probability that this state persists long enough to cause a failure.\n\n$1.$ The rate of sampling an asynchronous data transition within the vulnerable timing window of the first flip-flop is proportional to the clock frequency, the data toggle frequency, and the width of this window. The problem provides an effective parameter $T_0$ that \"captures the width of the vulnerable aperture\". Therefore, the rate of entering a metastable state can be expressed as:\n$$ R_{\\text{enter-meta}} = T_{0} f_{\\text{clk}} f_{\\text{data}} $$\n\n$2.$ The probability that a metastable state, once initiated, does not resolve within an available time $t$ is given as proportional to $\\exp(-t/\\tau)$. A failure occurs if the state persists longer than the available resolution time, $T_{\\text{res}}$. The problem statement implies the constant of proportionality is unity when using the parameter $T_0$. Thus, the probability of failure, given that a metastable event has occurred, is:\n$$ P(\\text{failure} | \\text{meta}) = \\exp(-T_{\\text{res}}/\\tau) $$\n\n$3.$ The overall failure rate is the product of these two quantities:\n$$ R_{\\text{fail}} = R_{\\text{enter-meta}} \\times P(\\text{failure} | \\text{meta}) = \\left( T_{0} f_{\\text{clk}} f_{\\text{data}} \\right) \\exp(-T_{\\text{res}}/\\tau) $$\n\n$4.$ The MTBF is the reciprocal of the failure rate. This yields the requested analytical expression for MTBF as a function of $T_{\\text{res}}$:\n$$ \\mathrm{MTBF}(T_{\\text{res}}) = \\frac{1}{R_{\\text{fail}}} = \\frac{\\exp(T_{\\text{res}}/\\tau)}{T_{0} f_{\\text{clk}} f_{\\text{data}}} $$\n\nNext, we substitute the given expression for the resolution time, $T_{\\text{res}} = N T_{\\text{clk}} - T_{\\text{guard}}$, to express the MTBF as a function of the number of stages $N$:\n$$ \\mathrm{MTBF}(N) = \\frac{\\exp((N T_{\\text{clk}} - T_{\\text{guard}})/\\tau)}{T_{0} f_{\\text{clk}} f_{\\text{data}}} $$\n\nThe problem requires finding the smallest integer $N$ that satisfies two conditions:\n$1.$ $\\mathrm{MTBF}(N) \\ge \\mathrm{MTBF}_{\\text{target}}$\n$2.$ $N \\le L_{\\max}$\n\nWe can solve for the minimum $N$ from the first condition. We rearrange the inequality to isolate $N$:\n$$ \\frac{\\exp((N T_{\\text{clk}} - T_{\\text{guard}})/\\tau)}{T_{0} f_{\\text{clk}} f_{\\text{data}}} \\ge \\mathrm{MTBF}_{\\text{target}} $$\nTaking the natural logarithm of both sides:\n$$ \\frac{N T_{\\text{clk}} - T_{\\text{guard}}}{\\tau} \\ge \\ln(\\mathrm{MTBF}_{\\text{target}} \\cdot T_{0} \\cdot f_{\\text{clk}} \\cdot f_{\\text{data}}) $$\n$$ N T_{\\text{clk}} - T_{\\text{guard}} \\ge \\tau \\ln(\\mathrm{MTBF}_{\\text{target}} \\cdot T_{0} \\cdot f_{\\text{clk}} \\cdot f_{\\text{data}}) $$\n$$ N \\ge \\frac{T_{\\text{guard}} + \\tau \\ln(\\mathrm{MTBF}_{\\text{target}} \\cdot T_{0} \\cdot f_{\\text{clk}} \\cdot f_{\\text{data}})}{T_{\\text{clk}}} $$\n\nNow, we substitute the given numerical values into this inequality.\nFirst, convert $\\mathrm{MTBF}_{\\text{target}}$ to seconds:\n$$ \\mathrm{MTBF}_{\\text{target}} = 10 \\, \\text{years} \\times 3.1536 \\times 10^{7} \\, \\frac{\\text{s}}{\\text{year}} = 3.1536 \\times 10^{8} \\, \\text{s} $$\nNext, calculate the argument of the logarithm:\n$$ C = \\mathrm{MTBF}_{\\text{target}} \\cdot T_{0} \\cdot f_{\\text{clk}} \\cdot f_{\\text{data}} $$\n$$ C = (3.1536 \\times 10^{8} \\, \\text{s}) \\cdot (20 \\times 10^{-12} \\, \\text{s}) \\cdot (1.0 \\times 10^{9} \\, \\text{s}^{-1}) \\cdot (2.0 \\times 10^{8} \\, \\text{s}^{-1}) $$\n$$ C = (3.1536 \\times 10^{8}) \\cdot (20 \\times 10^{-12}) \\cdot (2.0 \\times 10^{17}) = 3.1536 \\cdot 20 \\cdot 2.0 \\times 10^{(8-12+17)} $$\n$$ C = 126.144 \\times 10^{13} = 1.26144 \\times 10^{15} $$\nThis value is dimensionless, as expected.\n\nNow, compute the natural logarithm:\n$$ \\ln(C) = \\ln(1.26144 \\times 10^{15}) \\approx 34.770976 $$\n\nSubstitute this back into the inequality for $N$:\n$$ N \\ge \\frac{(150 \\times 10^{-12} \\, \\text{s}) + (30 \\times 10^{-12} \\, \\text{s}) \\cdot (34.770976)}{1.0 \\times 10^{-9} \\, \\text{s}} $$\n$$ N \\ge \\frac{150 \\times 10^{-12} + 1043.12928 \\times 10^{-12}}{1.0 \\times 10^{-9}} $$\n$$ N \\ge \\frac{1193.12928 \\times 10^{-12}}{1.0 \\times 10^{-9}} $$\n$$ N \\ge 1.19312928 $$\n\nSince $N$ must be an integer, the smallest integer value for $N$ that satisfies the MTBF requirement is $N=2$.\n\nFinally, we must check this result against the latency constraint: $N \\le L_{\\max}$.\nThe given maximum latency is $L_{\\max}=2$ clock cycles.\nOur calculated value $N=2$ satisfies this constraint: $2 \\le 2$.\n\nThe possible integer values for $N$ are constrained by $N \\ge 1$ (a synchronizer must have at least one stage) and $N \\le L_{\\max}=2$. So, we only need to check $N=1$ and $N=2$.\nFor $N=1$, the inequality $1 \\ge 1.193...$ is false, so a single-stage synchronizer is insufficient.\nFor $N=2$, the inequality $2 \\ge 1.193...$ is true, so a two-stage synchronizer is sufficient.\n\nThus, the smallest integer number of stages that meets both the MTBF target and the latency constraint is $2$.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Synchronizing a single bit is a solved problem, but real systems often require transferring multi-bit data buses across clock domains. This practice expands the scope to address the critical issue of data coherency, where inter-signal skew can cause the receiving logic to capture a logically invalid, intermediate state that never existed in the source domain. You will first quantify the probability of this dangerous 'mis-decode' error for a binary-coded bus and then reason from first principles why a simple change in data encoding—using a Gray code—can completely eliminate this failure mode . This highlights a powerful design principle: sometimes the best solution to a physical timing problem lies in the logical domain.",
            "id": "4259963",
            "problem": "A digital system employs clock domain crossing from a source clock domain to a receiving clock domain. The source domain drives a two-bit state bus that is binary encoded with states $\\{00,01,10,11\\}$. The receiving domain uses two independent two-stage flip-flop synchronizers, one per bit, to sample the bus. The receiving domain clock has period $T_{r}$, and the phase offset of any data transition relative to a given receiving clock edge is modeled as uniformly distributed on $[0,T_{r})$. All transitions on the bus are driven by source-domain logic that causes the two bits to change nominally at the same source clock edge when moving between certain states; however, due to path differences, the arrival times of the two bit transitions at the inputs of the first-stage synchronizers differ by a random skew $S$ with magnitude uniformly distributed on $[0,S_{\\max}]$. Assume $S_{\\max} < T_{r}$ and that $S$ is independent of the receiving clock phase.\n\nA decoding error within the receiving domain is said to occur if, during a single receiving clock edge, one synchronizer captures the “old” value of its bit while the other captures the “new” value of its bit, producing a mixed two-bit code that equals a valid but unintended binary state and is therefore misinterpreted by downstream logic for one receiving cycle. Treat metastability in the synchronizers as resolved within one cycle so that the only error mechanism considered is misdecoding caused by reconvergent mixed states when both bits transition.\n\nLet the fraction of state transitions that involve both bits toggling in the binary encoding be $\\alpha$. For the parameters $T_{r} = 5\\,\\text{ns}$, $S_{\\max} = 0.45\\,\\text{ns}$, and $\\alpha = 0.30$, compute the average probability of decoding error per source-domain state transition. Round your final numerical probability to four significant figures.\n\nFinally, explain, starting from the defining property of Gray coding (only one bit changes between adjacent states), why this particular mixed-code misdecode error mode is eliminated if the state bus is Gray coded and only adjacent Gray transitions are permitted. You must justify the elimination without invoking any shortcut formulas, by reasoning directly from the stated stochastic sampling model and the one-bit-change property.",
            "solution": "The solution is divided into two parts as requested: first, the computation of the decoding error probability, and second, a conceptual explanation regarding Gray coding.\n\n### Part 1: Calculation of Average Error Probability\n\nThe average probability of a decoding error per source-domain state transition, denoted $P_{\\text{error}}$, is the product of two probabilities:\n$1$. The probability that a state transition involves both bits toggling.\n$2$. The conditional probability that a decoding error occurs, given that both bits are toggling.\n\nThe problem states that the fraction of state transitions involving both bits toggling is $\\alpha$. Thus,\n$$P(\\text{2-bit transition}) = \\alpha$$\nA decoding error, as defined, can only occur during such a 2-bit transition. Our task reduces to finding the conditional probability, $P(\\text{error} | \\text{2-bit transition})$, and then computing the total probability as $P_{\\text{error}} = \\alpha \\times P(\\text{error} | \\text{2-bit transition})$.\n\nLet us analyze the condition for a decoding error. An error occurs when the receiving clock's sampling edge arrives in the time interval between the first bit's transition and the second bit's transition. This interval is the \"danger window\". During this window, one bit has its \"new\" value while the other still has its \"old\" value.\n\nLet the duration of this danger window be defined by the skew, $S$. The skew $S$ is the magnitude of the difference in arrival times of the two transitioning bits. The problem specifies that $S$ is a random variable, uniformly distributed over the interval $[0, S_{\\max}]$. The probability density function (PDF) of $S$ is:\n$$f_S(s) = \\begin{cases} \\frac{1}{S_{\\max}} & \\text{for } 0 \\le s \\le S_{\\max} \\\\ 0 & \\text otherwise \\end{cases}$$\nThe problem also states that the phase offset of a data transition relative to a receiving clock edge is uniformly distributed on $[0, T_r)$. This is equivalent to stating that for a data bus with changing signals, the probability of a random sampling clock edge falling within any specific time interval of duration $\\Delta t$ is given by $\\frac{\\Delta t}{T_r}$, provided $\\Delta t < T_r$.\n\nFor a specific instance of a 2-bit transition with a given skew value $s$, the duration of the danger window is $s$. The probability that the sampling clock edge falls within this window is:\n$$P(\\text{error} | S=s) = \\frac{s}{T_r}$$\nThis is valid because the problem specifies $S_{\\max} < T_r$, which implies $s < T_r$ for all possible values of $s$.\n\nTo find the average probability of error given a 2-bit transition, we must average this conditional probability over all possible values of the skew $S$, weighted by the PDF of $S$. This is calculated by finding the expected value of $P(\\text{error}|S)$.\n$$P(\\text{error} | \\text{2-bit transition}) = E[P(\\text{error} | S)] = E\\left[\\frac{S}{T_r}\\right] = \\frac{1}{T_r} E[S]$$\nThe expected value of a random variable $S$ uniformly distributed on $[0, S_{\\max}]$ is:\n$$E[S] = \\int_{-\\infty}^{\\infty} s f_S(s) ds = \\int_{0}^{S_{\\max}} s \\left(\\frac{1}{S_{\\max}}\\right) ds = \\frac{1}{S_{\\max}} \\left[ \\frac{s^2}{2} \\right]_0^{S_{\\max}} = \\frac{1}{S_{\\max}} \\left( \\frac{S_{\\max}^2}{2} - 0 \\right) = \\frac{S_{\\max}}{2}$$\nSubstituting this result back, we get the conditional probability of error:\n$$P(\\text{error} | \\text{2-bit transition}) = \\frac{1}{T_r} \\left( \\frac{S_{\\max}}{2} \\right) = \\frac{S_{\\max}}{2T_r}$$\nFinally, the average probability of decoding error per source-domain state transition is:\n$$P_{\\text{error}} = \\alpha \\times P(\\text{error} | \\text{2-bit transition}) = \\alpha \\frac{S_{\\max}}{2T_r}$$\nWe are given the numerical values: $T_r = 5\\,\\text{ns}$, $S_{\\max} = 0.45\\,\\text{ns}$, and $\\alpha = 0.30$. Substituting these into the expression:\n$$P_{\\text{error}} = 0.30 \\times \\frac{0.45\\,\\text{ns}}{2 \\times 5\\,\\text{ns}} = 0.30 \\times \\frac{0.45}{10} = 0.30 \\times 0.045 = 0.0135$$\nThe problem requires the answer to be rounded to four significant figures.\n$$P_{\\text{error}} = 0.01350$$\n\n### Part 2: Justification for Gray Coding\n\nThe problem asks for an explanation of why the specified error mode is eliminated if the state bus is Gray coded and only adjacent state transitions are permitted. The justification must be based on first principles.\n\n$1$. **Definition of the Error Mode**: The error is defined as a \"mixed-code misdecode\". This occurs when, for a multi-bit bus, the receiving synchronizers sample the bits during the interval of skew between them. This results in a captured state vector composed of a mix of \"old\" and \"new\" bit values, which happens to form a valid but unintended state. The necessary precondition for this error is that *at least two bits must change their value* during the state transition.\n\n$2$. **Defining Property of Gray Codes**: The fundamental property of a Gray code is that any two adjacent code words in the sequence differ by only a single bit. The problem constrains the system to only permit \"adjacent Gray transitions\".\n\n$3$. **Analysis of a Transition**: Consider a state transition from a State $A$ to an adjacent State $B$ on a Gray-coded bus. Let the state be represented by a vector of bits. Due to the Gray code property, State $A$ and State $B$ differ in value at exactly one bit position. Let's say bit $k$ is the one that changes, while all other bits $i \\neq k$ remain constant.\n\n$4$. **Sampling of Constant Bits**: For any bit $i \\neq k$, its value is stable and does not change during the transition. The synchronizer for each of these bits receives a constant input. Consequently, regardless of the timing of the receiving clock edge, it will correctly and unambiguously sample the constant value of its corresponding bit.\n\n$5$. **Sampling of the Changing Bit**: The single bit $k$ that is changing will transition from its old value, $B_k^{\\text{old}}$, to its new value, $B_k^{\\text{new}}$. The synchronizer for bit $k$ will sample the data line at some point. Depending on whether the sampling clock edge arrives before or after the transition of bit $k$, the synchronizer will capture either $B_k^{\\text{old}}$ or $B_k^{\\text{new}}$. (Under the problem's simplifying assumption, we ignore the case where it becomes metastable and fails to resolve).\n\n$6$. **Resulting Sampled States**: Combining these outcomes, the complete state vector captured by the receiving domain logic has two and only two possibilities:\n    - All bits are captured with their old values (if bit $k$ is captured before its transition). This reconstructs the original State $A$.\n    - All stable bits are captured with their constant value, and the single changing bit $k$ is captured with its new value. This reconstructs the final State $B$.\n\n$7$. **Elimination of the Error**: Since the only possible states that the receiving logic can sample are the correct initial state ($A$) or the correct final state ($B$), it is structurally impossible to form any other state. The \"mixed-code misdecode\" error, which is defined by the creation of a valid but *unintended* state, cannot occur. The concept of an inter-bit skew \"danger window\" is not applicable, as there is only one changing bit; there are no multiple, concurrent transitions between which a skew could manifest. Therefore, the use of a Gray code for adjacent state transitions entirely eliminates this specific error mechanism by its very nature.",
            "answer": "$$\n\\boxed{0.01350}\n$$"
        }
    ]
}