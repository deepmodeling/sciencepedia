## 应用与跨学科连接

在前面的章节中，我们已经探讨了构成[片上系统](@entry_id:1131845)（SoC）架构基础的核心原理与机制。然而，这些原理的真正价值体现在其解决现实世界复杂工程问题的能力上。本章旨在搭建理论与实践之间的桥梁，展示这些核心概念如何在多样化的应用场景和跨学科背景下被运用、扩展和集成。

我们将不再重复介绍核心概念，而是将重点放在展示它们的实用性上。通过一系列源于真实设计挑战的应用案例，我们将探索[SoC架构](@entry_id:1131841)师如何在高性能计算、操作系统集成、系统安全与可靠性以及前沿集成范式等领域中，利用这些基础知识进行权衡、分析和创新。从高速互连的[性能建模](@entry_id:753340)到硬件与驱动程序的协同设计，再到确保多电源域SoC的安全与可测试性，本章将揭示SoC设计的艺术性与科学性。我们的目标是使读者不仅理解“是什么”，更能领悟“如何做”以及“为什么这样做”，从而将理论知识转化为强大的工程实践能力。

### 高性能系统设计与分析

在SoC设计中，满足严苛的性能指标（如带宽、延迟和吞吐量）是首要任务。这要求对系统行为进行精确的量化分析和建模，尤其是在设计关键的互连和存储子系统时。

#### 接口架构的权衡

SoC中加速器与系统其它部分的集成方式对性能和软件复杂性有深远影响。一个基本的架构决策是在存储器映射（Memory-Mapped）接口和流式（Streaming）接口之间进行选择。存储器映射接口将加速器实现为一系列可通过地址访问的寄存器和存储空间，所有控制和数据传输都通过总线上的读/写事务完成。这种方法的反压（backpressure）机制内嵌于[互连网络](@entry_id:750720)中，当加速器无法接收数据时，总线事务会自然暂停，瞬时的[数据缓冲](@entry_id:173397)主要由互连结构本身承担。对于大块数据传输，通常由CPU配置一次直接存储器访问（DMA）引擎，后者自主完成数据搬运，从而实现较低的CPU开销。

相比之下，流式接口采用基于“有效-就绪”（valid-ready）[握手协议](@entry_id:174594)的同步数据流模型。数据仅在生产者断言`valid`且消费者断言`ready`时才进行传输。反压通过消费者撤销`ready`信号来直接实现。这种模式要求在接口处使用显式的先进先出（FIFO）队列来吸收速率不匹配和仲裁[抖动](@entry_id:200248)。FIFO的深度必须经过精心计算，以确保在最坏的情况下（例如，生产者在短时间内以峰值速率发送数据）不会发生数据溢出。一个足以保证无数据丢失的最小FIFO深度$D$可以通过生产者峰值速率$\lambda_{\max}$、消费者速率$\mu$以及峰值持续时间$G$来确定：$D \ge (\lambda_{\max} - \mu) G$。尽管两种接口都可以实现高效的数据传输，但它们在硬件实现、缓冲策略和软件控制模型上呈现出显著的差异，架构师必须根据应用的具体需求进行权衡。

#### 互连[性能建模](@entry_id:753340)

片上网络（NoC）的性能直接决定了SoC的整体数据处理能力。为了保证链路能够满足特定的带宽需求，必须对其物理参数进行精确建模。一条同步互连链路的有效载荷吞吐量$W_{\text{eff}}$可以表示为其数据[路径宽度](@entry_id:273205)$D$（比特）、时钟频率$f$（赫兹）和链路利用率$\eta$的乘积，即 $W_{\text{eff}} = D \cdot f \cdot \eta$。利用率$\eta$是一个小于1的因子，它量化了由于协议开销、仲裁、流控制等因素导致的带宽损失。

因此，为了满足一个给定的峰值载荷带宽目标$W$，所需要的最小整数数据宽度$D_{\min}$可以从基本的不等式 $D \cdot f \cdot \eta \ge W$ 推导出来。求解$D$并考虑其整数特性，我们得到：
$$D_{\min} = \left\lceil \frac{W}{f \eta} \right\rceil$$
这个公式是SoC早期性能规划和[物理设计](@entry_id:1129644)的基石。例如，在给定 $W = 1.28 \times 10^{11}$ 比特/秒，$f = 1.0 \times 10^{9}$ 赫兹，以及 $\eta = 0.8$ 的参数下，所需的最小数据宽度为 $160$ 比特。然而，选择更宽的数据路径（如 $2 \times D_{\min}$）虽然能显著降低大数据包的串行化延迟（serialization latency），但也可能因为物理布线复杂性增加而导致更深的流水线，从而增加每跳（hop）的固定延迟。最终的延迟是串行化延迟和流水线[传播延迟](@entry_id:170242)之和。在设计中，必须权衡串行化延迟的减少量和流水线延迟的增加量，以确定对整体端到端延迟最优的数据[路径宽度](@entry_id:273205)。

#### 高带宽存储器集成

对于如图形处理单元（GPU）和[人工智能加速器](@entry_id:1120909)这[类数](@entry_id:156164)据密集型应用，[主存](@entry_id:751652)带宽是主要的性能瓶颈。高带宽存储器（[HBM](@entry_id:1126106)）技术通过在硅中介层（interposer）上集成多个独立的存储器通道，提供了前所未有的带宽。分析[HBM](@entry_id:1126106)的峰值载荷带宽是评估系统性能的关键步骤。

一个[HBM](@entry_id:1126106)堆栈的总带宽由其通道数量$C$、每个通道的位宽$w$、以及数据速率$R$（单位为MT/s，即每秒百万次传输）共同决定。每个堆栈的总原始比特率是所有通道比特率的总和。然而，由于协议开销（如刷新、命令编码和流控制），只有一部分原始带宽可用于有效载荷。这个比例由效率因子$\eta$表示。因此，一个[HBM](@entry_id:1126106)堆栈的峰值有效载荷带宽$B_{\text{payload}}$（单位为GB/s，其中$1 \text{ GB} = 10^9$ 字节）可以表示为：
$$B_{\text{GB/s}} = \frac{\eta \times C \times w \times R}{8 \times 10^3}$$
例如，对于一个配置了$C=8$个通道、每通道位宽$w=128$比特、数据速率$R=3200$ MT/s且效率$\eta=0.92$的[HBM](@entry_id:1126106)2E堆栈，其峰值有效载荷带宽可达到约$376.8$ GB/s。这个计算表明，通过[并行化](@entry_id:753104)和高速接口技术，现代SoC能够满足极端的数据带宽需求。

#### 一致性与预取动态

在多核SoC中，[缓存一致性协议](@entry_id:747051)虽然保证了数据视图的统一，但也可能引发微妙的性能问题。一个典型例子是[伪共享](@entry_id:634370)（false sharing），即当多个核频繁访问同一缓存行内不同的数据字时，会导致该缓存行在不同核心的私有缓存之间“乒乓”，产生大量不必要的[缓存一致性](@entry_id:747053)流量，尽管这些访问在逻辑上并无依赖关系。

推测性预取（speculative prefetching）机制，虽然旨在隐藏访存延迟，但可能加剧[伪共享](@entry_id:634370)问题。当一个预取器将一个[伪共享](@entry_id:634370)的缓存行以“共享”（Shared）状态加载到多个非访问核心的私有缓存中时，这些核心就被注册为该行的共享者。当一个活跃核心需要写入该行时，它必须向所有共享者（包括那些仅因预取而持有该行的核心）发送失效（invalidation）消息。这导致一致性消息的数量显著增加，从而放大了[伪共享](@entry_id:634370)带来的流量。例如，如果除了两个活跃核心外，还有$k=3$个核心由于预取而持有该行，那么每次写操作的失效消息接收者就从1个增加到4个，显著增加了NoC的流量和延迟。

为了缓解这种“[伪共享](@entry_id:634370)放大”效应，可以采用多种架构性缓解措施。一种方法是采用“仅标签”预取（tag-only prefetch），即预取器只获取数据地址标签而不将数据置于一致性状态，从而避免注册为共享者。另一种更实用的策略是，将可能导致[伪共享](@entry_id:634370)的预取重定向到共享的末级缓存（LLC），而不是私有缓存，这样就不会产生额外的私有共享者。此外，还可以实现动态[反馈控制](@entry_id:272052)机制，通过监控每个数据流的[失效率](@entry_id:266388)（例如，每千条指令的失效次数），当该比率超过阈值时，动态地“节流”预取器的激进程度，从而在不影响行为良好的数据流的性能前提下，减少不必要的共享状态创建。

### 硬件-软件契约：操作系统、驱动与同步

SoC的硬件能力必须通过软件（尤其是操作系统和设备驱动）才能被有效利用和安全管理。硬件与软件之间的接口，即所谓的“硬件-软件契约”，定义了两者如何交互，对系统的性能、安全性和可靠性至关重要。

#### 加速器的操作系统支持

为SoC中的硬件[加速器设计](@entry_id:746209)操作系统支持是一个典型的权衡过程，需要在性能、CPU开销和安全性之间找到平衡。考虑一个通过DMA处理数据块的加速器，一种不安全的设计是将其[内存映射](@entry_id:175224)I/O（MMIO）控制寄存器直接映射到用户空间。虽然这允许应用程序零开销地控制设备，但它打破了特权级隔离，一个恶意或有缺陷的应用可以轻易地破坏整个系统。

一个更安全但低效的方法是让内核通过程序控制I/O（PIO）逐块地向设备喂数据，但这会消耗大量CPU周期并成为性能瓶颈。同样，让用户空间通过[轮询](@entry_id:754431)（polling）等待设备完成，虽然避免了中断开销，但对于耗时较长的操作，会浪费大量CPU资源，导致极高的[CPU利用率](@entry_id:748026)。

最佳实践通常是实现一个内核驱动程序，它提供一个[系统调用接口](@entry_id:755774)。应用程序通过一次[系统调用](@entry_id:755772)提交一批（batch）任务描述符。驱动程序在[内核模式](@entry_id:755664)下执行所有特权操作：将用户空间的I/O缓冲区“钉”在物理内存中以防被换出，为这些缓冲区设置[IOMMU](@entry_id:750812)[地址转换](@entry_id:746280)，并通过MMIO“敲门”（ring the doorbell）启动设备。为了摊销软件开销，设备被配置为每批任务仅产生一次中断（[中断合并](@entry_id:750774)）。这种批处理、基于DMA和中断的内[核驱动模型](@entry_id:1126896)，既保证了系统安全，又能实现高[吞吐量](@entry_id:271802)和低[CPU利用率](@entry_id:748026)，是现代高性能设备驱动的标准设计模式。

#### I/O一致性与DMA

当CPU的缓存系统与DMA引擎共存时，一个核心的挑战是确保[数据一致性](@entry_id:748190)。如果CPU将数据写入一个被其缓存的内存区域（例如，一个DMA描述符环），这些更新可能只存在于CPU的私有缓存中（在[写回](@entry_id:756770)式[缓存策略](@entry_id:747066)下）。如果DMA引擎是非一致性的，它将直接从[主存](@entry_id:751652)读取数据，从而读到过时（stale）的数据。反之，当DMA将完成状态[写回](@entry_id:756770)[主存](@entry_id:751652)时，CPU可能从其缓存中读到旧的状态。

解决此问题的一种简单方法是将[共享内存](@entry_id:754738)区域（如描述符环）配置为“不可缓存”（Normal Non-Cacheable）。这保证了CPU和DMA都直接访问[主存](@entry_id:751652)，从而看到一致的数据。然而，这会严重影响CPU访问该区域的性能，因为每次访问都将承受[主存](@entry_id:751652)的完整延迟。一个危险且错误的做法是，在内存可缓存的情况下使用非一致性DMA，并寄希望于[内存屏障](@entry_id:751859)（memory barrier）指令能解决问题。[内存屏障](@entry_id:751859)仅保证操作的顺序，而不保证将缓存数据[写回](@entry_id:756770)[主存](@entry_id:751652)。

现代SoC提供的最佳解决方案是硬件管理的I/O一致性。通过使用支持一致性的总线协议（如AXI与ACE-Lite扩展），DMA控制器可以成为一致性域的一部分。当一致性DMA需要读取数据时，它可以“窥探”（snoop）[CPU缓存](@entry_id:748001)，并直接从缓存中获取最新的数据。当它写入数据时，一致性硬件会自动将[CPU缓存](@entry_id:748001)中对应的缓存行置为无效。这种硬件方法允许共享内存区域对CPU保持可缓存，以实现最高性能，同时自动保证[数据一致性](@entry_id:748190)，无需软件进行显式的、开销高昂的缓存刷新（flush）或失效（invalidate）操作。

#### 同步与[内存排序](@entry_id:751873)

在弱[内存排序](@entry_id:751873)（weakly ordered）的体系结构中，CPU和设备之间的正确交互依赖于显式的[内存屏障](@entry_id:751859)指令来强制执行操作的顺序。考虑一个典型的网络数据包发送流程：DMA引擎将数据包载荷写入内存缓冲区$P$，完成后设置一个内存标志位$F$；[CPU轮询](@entry_id:748018)此标志位，确认载荷准备就绪后，构造头部$H$，填充一个指向$H$和$P$的描述符$D$，最后通过MMIO写操作敲响网络接口控制器（NIC）的门铃以启动发送。

这个过程存在多个潜在的排序风险。首先，CPU在读到$F=1$后，必须确保DMA对$P$的写入对后续操作可见。由于弱序模型允许加载重排，CPU可能在$P$的内容完全可见之前就开始后续操作。因此，在CPU确认$F=1$之后，必须插入一个读[内存屏障](@entry_id:751859)（read memory barrier, `rmb`），它确保所有在屏障之前的加载操作（读取$F$）在所有在屏障之后的内存访问（例如NIC读取$P$）之前被全局观察到。

其次，CPU写入描述符$D$和头部$H$的操作相对于将描述符标记为就绪（例如，设置`D.ready = 1`）的写操作也可能被重排。为保证NIC在看到描述符就绪时能读到完整、正确的内容，必须在设置就绪位之前插入一个写[内存屏障](@entry_id:751859)（write memory barrier, `wmb`）。

最后，将描述符标记为就绪的普通内存写操作与敲门铃的MMIO写操作之间也可能被重排，导致NIC在描述符尚未就绪时就被唤醒。因此，在设置就绪位之后、敲门铃之前，必须再插入一个`wmb`。`wmb`确保所有之前的普通内存写操作在后续的MMIO写操作之前全局可见。因此，正确且必要的屏障安放对于在弱序SoC上编写可靠的设备驱动至关重要。

另一个微妙的同步问题发生在CPU的[原子指令](@entry_id:746562)（如加载链接/条件存储 [LL/SC](@entry_id:751376)）与一致性DMA的交互中。许多[处理器架构](@entry_id:753770)以缓存行（cache-line）的粒度来跟踪LL指令建立的“预留”（reservation）。这意味着对该缓存行内任何地址的写入都会导致预留失效。如果一个锁变量和一个DMA频繁写入的状态计数器碰巧位于同一个缓存行内，就会发生“[伪共享](@entry_id:634370)”导致的干扰：即使DMA写入的是不同的地址，其一致性写操作也会使CPU对锁变量的预留失效，导致SC指令持续失败，严重影响性能。

解决此问题的最根本方法是利用[IOMMU](@entry_id:750812)进行硬件隔离。通过在[IOMMU](@entry_id:750812)[页表](@entry_id:753080)中为该设备配置访问权限，可以明确禁止其对包含锁变量的内存页进行写操作。这样，任何来自设备的非法写入尝试都会被[IOMMU](@entry_id:750812)在硬件层面阻断，从而完全避免了对CPU同步操作的干扰。这展示了[IOMMU](@entry_id:750812)不仅是地址翻译单元，更是强制实现硬件-软件隔离和保障系统鲁棒性的关键组件。

### [系统可靠性](@entry_id:274890)、安全性与可测试性

除了性能和功能，现代SoC设计必须高度关注系统的可靠性、安全性和可测试性。这些“非功能性”需求渗透到架构设计的方方面面，确保系统在整个生命周期内都能稳健、安全地运行。

#### [安全启动](@entry_id:754616)与信任链

SoC的安全性始于一个可信的启动过程。[安全启动](@entry_id:754616)（Secure Boot）机制通过构建一个“信任链”（chain-of-trust）来确保系统只加载和执行经过授权和验证的软件。这个过程始于一个不可更改的[硬件信任根](@entry_id:1125916)（Root-of-Trust），通常是一段固化在掩模ROM中的代码。

[信任链](@entry_id:747264)的执行是顺序的：首先，ROM代码验证第一阶段引导加载程序（BL1）的真实性和完整性。验证通过后，控制权交给BL1，BL1再以同样的方式验证第二阶段引导加载程序（BL2）。最后，BL2验证主固件镜像。每个验证步骤通常包括两个操作：首先，使用硬件加速的哈希引擎（如SHA-256）计算待加载镜像的摘要（digest）；然后，使用非对称加密算法（如E[CDS](@entry_id:137107)A）验证该摘要上的[数字签名](@entry_id:269311)。

分析安全启动的总时间对于评估系统启动性能至关重要。总时间是所有验证阶段时间的总和。每个阶段的时间包括固定的[密码学](@entry_id:139166)引擎初始化开销、签名验证延迟，以及与镜像大小成正比的哈希计算时间。哈希计算的有效吞吐量受限于哈希加速器本身的速度和从非易失性存储（如闪存）读取数据的带宽，取两者中的较小值。例如，即使SoC拥有一个$1.6$ GB/s的SHA-256加速器，但如果闪存读取带宽仅为$160$ MB/s，那么哈希过程的实际瓶颈就在于I/O。对整个启动过程的精确时间建模，有助于架构师在设计启动流程和选择存储介质时做出明智的决策。

#### 复杂SoC的可测试性设计

随着SoC集成度的提高，测试其在制造后是否存在缺陷变得极具挑战性。可测试性设计（Design for Test, DFT）将测试功能直接构建到芯片中，是保证产品质量和良率的关键。

对于嵌入式存储器（SRAM），内存内建自测试（Memory Built-In Self-Test, MBIST）是一种重要的DFT技术。MBIST控制器能够自动生成测试向量并验证SRAM的功能。一个常见的测试算法是March测试，它由一系列“March元素”组成。每个元素定义了一组针对每个存储单元的读/写操作序列，并以升序或降序地址遍历整个存储器。通过精心设计的操作序列，March测试可以高效地检测多种[故障模型](@entry_id:1124860)，如[固定型故障](@entry_id:171196)（stuck-at faults）、转换故障（transition faults）和字内耦合故障（intra-word coupling faults）。总测试时间可以通过分析算法中的基本读/写操作总数来确定。例如，一个包含$w$次迭代（每次针对一位）以测试字内耦合故障的March算法，其总操作数可以表示为$D \times (8w + 2)$，其中$D$是存储器深度。将总操作数除以测试时钟频率$f_t$，即可得到总测试时间。这个分析对于规划生产测试流程和时间至关重要。

在具有多个独立开关电源域的SoC中，即使是标准的JTAG[边界扫描](@entry_id:1121813)测试（[IEEE 1149.1](@entry_id:170153)）也面临着新的挑战。测试访问端口（TAP）控制器必须在任何电源配置下都能正常工作，并且扫描链在穿过掉电的电源域时不能引起电气问题或功能不确定性。一个不安全的设计是直接将TAP控制信号[扇出](@entry_id:173211)到所有电源域，当某个域掉电时，驱动信号进入无电的[逻辑门](@entry_id:178011)会导致漏电甚至损坏。

正确的解决方案要求将TAP控制器和关键的扫描路径切换逻辑放置在一个永远在线（Always-On, AON）的电源域中。当一个可开关的电源域掉电时，必须有一种机制能够动态地将其内部的[扫描链](@entry_id:171661)段从总扫描路径中“旁路”（bypass）掉。行业标准IEEE 1687（IJTAG）为此定义了段插入位（Segment Insertion Bit, SIB）等结构。SIB是一个位于AON域的受控开关，它可以根据对应电源域的“电源良好”（power-good）信号，选择性地将该域的扫描链接入主扫描路径，或者切换到一个位于AON域内的短旁路寄存器。同时，所有跨越电源域边界的信号都必须通过特殊的隔离单元和带掉电保护的[电平转换器](@entry_id:174696)，以确保电气安全。这种分层、可重构的测试架构是现代复杂SoC实现全面、安全测试的基础。

### 先进集成范式与未来扩展

随着传统登纳德缩放定律（Dennard scaling）的终结，SoC设计的创新[焦点](@entry_id:174388)正从单纯的晶体管尺寸缩小，转向更广阔的系统级集成策略和新架构范式。

#### 专用领[域架构](@entry_id:171487)（DSA）

面对[通用计算](@entry_id:275847)效率提升的放缓，采用专用领[域架构](@entry_id:171487)（Domain-Specific Architectures, DSA）成为提高性能和能效的关键途径。针对特定应用（如[密码学](@entry_id:139166)、机器学习），设计者可以在全定制的[专用集成电路](@entry_id:180670)（[ASIC](@entry_id:180670)）、可重构的[现场可编程门阵列](@entry_id:173712)（FPGA）和粒度更粗的可重构计算阵列（CGRA）之间进行选择。

这个选择是一个复杂的多维度权衡。[ASIC](@entry_id:180670)提供最高的性能和能效，因为它为特定算法量身定制了数据路径。例如，一个用于AES-GCM加密的[ASIC](@entry_id:180670)流水线可以达到非常高的时钟频率（如$1$ GHz）和极低的启动间隔（如每个时钟周期处理一个[数据块](@entry_id:748187)），从而实现超过$100$ Gbps的[吞吐量](@entry_id:271802)。然而，[ASIC](@entry_id:180670)的非经常性工程（NRE）成本极高（数百万美元）。

FPGA提供了灵活性和快速上市时间，其NRE成本远低于[ASIC](@entry_id:180670)。虽然其性能（时钟频率和[资源限制](@entry_id:192963)）不如[ASIC](@entry_id:180670)，但通过[并行化](@entry_id:753104)等技术，一个中端FPGA仍可能满足例如$10$ Gbps级别的[吞吐量](@entry_id:271802)需求。其固定的单价较高，但对于中低产量（如数千至数万片）的产品，其摊销后的总单位成本可能最低。

CGRA则介于两者之间，它在SoC上提供一个可编程的粗粒度功能单元阵列，比FPGA效率更高，但灵活性较低。其NRE成本和单位成本也介于[ASIC](@entry_id:180670)和FPGA之间。在做决策时，必须对每个选项的吞吐量、延迟确定性（例如，是否有多任务共享导致的[抖动](@entry_id:200248)）以及在目标产量下的总摊销成本进行定量分析，以选择最符合项目需求的方案。

#### 异构SoC中的[物理设计](@entry_id:1129644)约束

在集成了多个独立时钟域和电源域的复杂SoC中，物理设计约束对系统架构和[时序性](@entry_id:924959)能有直接影响。跨越不同电压或时钟域的信号路径会引入额外的延迟，必须在系统级时序分析中精确核算。

当信号从一个可以独立掉电的源域传输到一个目标域时，接口处必须插入一系列特殊单元以确保电气安全和功能正确。首先是隔离单元（isolation cell），用于在源域掉电时防止其不确定的输出信号传播到目标域。其次是[电平转换器](@entry_id:174696)（level shifter），用于将信号从源域的电压摆幅安全地转换为目标域的电压摆幅。对于[异步时钟域](@entry_id:1121164)，还需要[时钟域交叉](@entry_id:173614)（Clock Domain Crossing, CDC）[同步器](@entry_id:175850)（通常是两级触发器链），以防止亚稳态。这些单元——保持型触发器、隔离单元、[电平转换器](@entry_id:174696)、布线和CDC同步器——各自都会引入[传播延迟](@entry_id:170242)。在进行端到端[延迟计算](@entry_id:755964)时，必须将这些物理引入的延迟与逻辑路径延迟和[同步器](@entry_id:175850)所需的多个[时钟周期](@entry_id:165839)惩罚相加，才能得到真实的最坏情况下的接口延迟。

#### 超越光罩：晶圆级集成

随着对计算规模需求的不断增长，超越单个芯片（die）的集成技术变得日益重要。晶圆级集成（Wafer-Scale Integration, WSI）是一种雄心勃勃的策略，它旨在将整个硅晶圆作为一个巨大的计算系统来使用，而不是将其切割成数百个独立的芯片。由于[光刻技术](@entry_id:158096)中的光罩（reticle）尺寸有限，无法一次性曝光整个晶圆，因此WSI系统必须被设计成由许多通过晶圆上金属互连连接起来的、重复的计算“瓦片”（tile）组成的阵列。

WSI与传统的单片SoC和多芯片模块（MCM）形成鲜明对比。单片SoC受限于光罩尺寸。MCM通过将多个经过测试的“已知良好裸片”（Known Good Dies）封装在一个基板上，来构建大型系统。WSI的主要挑战和优势均源于其独特的物理形式。最大的挑战之一是良率：由于制造缺陷在晶圆上随机分布，制造一个完美无瑕的、与晶圆同等大小的单片电路几乎是不可能的。因此，WSI系统必须内建大量的冗余和可重构网络，使其能够绕过有缺陷的瓦片，从而实现远高于单片方法的系统级良率。

另一个关键挑战是[互连延迟](@entry_id:1126583)。对于晶圆上的长距离连线，其电阻$R$和电容$C$都与长度$L$近似成正比，导致其$RC$延迟以$L^2$的超线性关系增长。这使得全局通信的开销非常大，对架构设计提出了严格的局部性要求，尤其适合于像[脉冲神经网络](@entry_id:1132168)这样通信模式本身具有[空间局部性](@entry_id:637083)的应用。

#### “超越摩尔”策略

摩尔定律所描述的晶体管尺寸按比例缩小的趋势，即“更多摩尔”（More Moore），在过去几十年中一直是半导体行业发展的核心驱动力。然而，随着物理极限的临近，这种传统缩放的红利正在递减。一个关键瓶颈是，由于亚阈值摆幅存在约$60$ mV/dec的玻尔兹曼物理极限，阈值电压$V_T$难以继续降低，进而导致供电电压$V_{DD}$的缩放停滞。由于动态功耗与$V_{DD}^2$成正比，电压停滞意味着单纯缩小晶体管尺寸对[能效](@entry_id:272127)的提升越来越有限。此外，数据移动（访存和片上互连）的能耗在系统总能耗中的占比越来越高，往往超过了计算本身的能耗。

在这一背景下，“超越摩尔”（More-than-Moore）成为与“更多摩尔”并行的重要发展战略。它指的是通过功能多样化（functional diversification）来增加芯片的价值和能力，而不是仅仅追求更高的晶体管密度。“超越摩尔”强调在单个芯片或封装中集成异构的功能模块，例如射频（RF）前端、传感器、[电源管理](@entry_id:753652)单元（PMIC）、非易失性存储器等。这种[异构集成](@entry_id:1126021)通过将不同的功能在物理上拉近，极大地减少了它们之间的数据移动距离和能量开销，从而在系统层面实现能效的提升。3D集成和基于芯粒（chiplet）的异构系统是实现“超越摩尔”的重要技术路径。因此，“超越摩尔”代表了一种战略转变：从以器件为中心的维度缩放，转向以系统为中心的功能集成，以应对后缩放时代的[能效](@entry_id:272127)和性能挑战。