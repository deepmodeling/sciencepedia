{
    "hands_on_practices": [
        {
            "introduction": "Understanding the theory of parallel prefix networks is one thing; implementing one is another. This first exercise  challenges you to translate the recursive logic of the Ladner-Fischer architecture into a working algorithmic generator. By building the prefix graph from the ground up and verifying its output against arithmetic truth, you will gain a concrete mastery of the associative composition operator that lies at the heart of all carry-lookahead schemes.",
            "id": "4255508",
            "problem": "You are given the task of constructing an algorithmic generator for Ladner–Fischer parallel prefix graphs applied to binary addition within the domain of Electronic Design Automation (EDA). The goal is to compute the prefix carry pairs for all bit positions using a balanced tree decomposition, and to verify the correctness of the resulting network by induction on the tree structure.\n\nThe fundamental base for this task consists of the canonical propagate and generate definitions for a single-bit full adder. Let $a_i$ and $b_i$ denote the $i$-th least significant bits of two nonnegative integers $A$ and $B$, respectively, and let $c_i$ denote the carry into bit position $i$, with $c_0$ as the initial carry-in. Define the single-bit generate and propagate signals by $g_i = a_i \\land b_i$ and $p_i = a_i \\oplus b_i$. The carry recurrence is given by $c_{i+1} = g_i \\lor (p_i \\land c_i)$. For any contiguous range of bit positions $[l..r]$, define the group pair $(G_{l,r}, P_{l,r})$ as the unique pair satisfying $c_{r+1} = G_{l,r} \\lor (P_{l,r} \\land c_l)$ for all admissible $c_l$. The binary operation on such group pairs for two adjacent ranges $[l..m]$ and $[m+1..r]$ is defined by associativity of carry composition over concatenation of ranges; use this fact to construct the group pair for $[l..r]$ from the pairs for $[l..m]$ and $[m+1..r]$.\n\nYour program must:\n- Construct a Ladner–Fischer parallel prefix graph over $n$ bits by recursively decomposing the index range $[0..n-1]$ into two halves at each step, computing prefixes for the left half $[l..m]$, computing local prefixes for the right half $[m+1..r]$ relative to their own starting index, and then combining the left prefix $[l..m]$ with each right-local prefix to obtain global prefixes for all indices in $[m+1..r]$. The graph should be represented algorithmically as a list of operations, where each operation combines two previously available group pairs to produce a new group pair. Each node corresponds to either an input pair $(g_i, p_i)$ or the result of combining two nodes; track dependencies to ensure a valid topological order.\n- Evaluate the constructed graph to obtain $(G_{0,i}, P_{0,i})$ for all $i \\in \\{0,1,\\dots,n-1\\}$.\n- Compute all carries and sum bits using $c_{i+1} = G_{0,i} \\lor (P_{0,i} \\land c_0)$ and $s_i = p_i \\oplus c_i$ for all $i \\in \\{0,1,\\dots,n-1\\}$, where $c_0$ is the given initial carry-in. Form the computed arithmetic result as the integer $S = \\sum_{i=0}^{n-1} s_i \\cdot 2^i + c_n \\cdot 2^n$.\n- Verify correctness by comparing $S$ to the ground-truth arithmetic sum $A + B + c_0$ for each specified test case.\n\nUse purely logical representations of signals, where $a_i$, $b_i$, $g_i$, $p_i$, $c_i$, $G_{l,r}$, and $P_{l,r}$ are treated as Boolean values. All indices and widths are integers. No physical units are involved.\n\nTest Suite:\n- Case $1$: $n=1$, $A=1$, $B=1$, $c_0=0$.\n- Case $2$: $n=4$, $A=9$, $B=6$, $c_0=1$.\n- Case $3$: $n=8$, $A=90$, $B=60$, $c_0=0$.\n- Case $4$: $n=8$, $A=255$, $B=1$, $c_0=1$.\n- Case $5$: $n=32$, $A=4042322160$, $B=252645135$, $c_0=0$.\n- Case $6$: $n=32$, $A=2147483648$, $B=2147483648$, $c_0=1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[result_1,result_2,\\dots]$). Each result must be a Boolean indicating whether the computed $S$ equals the ground-truth arithmetic sum $A + B + c_0$ for that test case. The output must be exactly of the form $[r_1,r_2,r_3,r_4,r_5,r_6]$ with no additional whitespace or text.",
            "solution": "### Principle-Based Design\n\nThe solution hinges on the principle of parallel prefix computation, which transforms a serially dependent calculation (like carry propagation) into a parallel-friendly one using an associative binary operator.\n\n**1. Bit-level Carry Propagation**\nFor the addition of two $n$-bit binary numbers, $A = \\sum_{i=0}^{n-1} a_i 2^i$ and $B = \\sum_{i=0}^{n-1} b_i 2^i$, the carry $c_{i+1}$ generated at bit position $i$ depends on the inputs $a_i$, $b_i$, and the carry $c_i$ into that position. This relationship is captured by the generate signal, $g_i$, and the propagate signal, $p_i$.\n- A carry is **generated** at position $i$ if both $a_i$ and $b_i$ are $1$: $g_i = a_i \\land b_i$.\n- A carry is **propagated** through position $i$ if exactly one of $a_i$ or $b_i$ is $1$: $p_i = a_i \\oplus b_i$.\n\nThe carry-out of bit $i$, denoted $c_{i+1}$, is $1$ if a carry is generated at this stage, or if a carry was propagated from the previous stage. This gives the fundamental carry recurrence relation:\n$$c_{i+1} = g_i \\lor (p_i \\land c_i)$$\n\n**2. Group Generate/Propagate and Associative Composition**\nTo parallelize the carry computation, we generalize the $(g, p)$ concept to blocks of bits. For any contiguous range of bits from index $l$ to $r$ (inclusive), we define a group generate/propagate pair $(G_{l,r}, P_{l,r})$. This pair establishes a direct relationship between the carry-in to the block, $c_l$, and the carry-out of the block, $c_{r+1}$, as follows:\n$$c_{r+1} = G_{l,r} \\lor (P_{l,r} \\land c_l)$$\nThis definition must hold for any valid input carry $c_l$. The single-bit pair $(g_i, p_i)$ is a special case: $(G_{i,i}, P_{i,i}) = (g_i, p_i)$.\n\nThe key to parallel prefix computation is that this block composition is associative. Consider two adjacent blocks, $[l..m]$ and $[m+1..r]$. We have:\n$$c_{m+1} = G_{l,m} \\lor (P_{l,m} \\land c_l)$$\n$$c_{r+1} = G_{m+1,r} \\lor (P_{m+1,r} \\land c_{m+1})$$\nSubstituting the expression for $c_{m+1}$ into the equation for $c_{r+1}$:\n$$c_{r+1} = G_{m+1,r} \\lor (P_{m+1,r} \\land (G_{l,m} \\lor (P_{l,m} \\land c_l)))$$\nApplying the distributive law ($X \\lor (Y \\land Z) = (X \\lor Y) \\land (X \\lor Z)$ is incorrect here, we need $X \\land (Y \\lor Z) = (X \\land Y) \\lor (X \\land Z)$) yields:\n$$c_{r+1} = G_{m+1,r} \\lor (P_{m+1,r} \\land G_{l,m}) \\lor (P_{m+1,r} \\land P_{l,m} \\land c_l)$$\nBy grouping terms and comparing with the definition $c_{r+1} = G_{l,r} \\lor (P_{l,r} \\land c_l)$, we derive the composition operator $\\circ$:\n$$(G_{l,r}, P_{l,r}) = (G_{m+1,r}, P_{m+1,r}) \\circ (G_{l,m}, P_{l,m})$$\nwhere the composition is defined as:\n$$G_{l,r} = G_{m+1,r} \\lor (P_{m+1,r} \\land G_{l,m})$$\n$$P_{l,r} = P_{m+1,r} \\land P_{l,m}$$\n\n**3. Algorithmic Construction: Recursive Prefix Computation**\nThe problem describes a recursive algorithm that mirrors the structure of a Ladner-Fischer prefix network. We aim to compute all prefix pairs $(G_{0,i}, P_{0,i})$ for $i \\in \\{0, 1, ..., n-1\\}$. The algorithm is implemented as a recursive function, `get_prefix_pairs(l, r)`, which computes all prefix pairs $(G_{l,i}, P_{l,i})$ for $i$ in the range $[l, r]$.\n\n- **Base Case**: If the range contains a single bit, $l=r$, the only prefix pair is the initial $(g_l, p_l)$. The function returns a list containing this single pair.\n- **Recursive Step**: For a range $[l,r]$, we find the midpoint $m = l + \\lfloor(r-l)/2\\rfloor$.\n    1.  Recursively compute all prefixes for the left half: `left_prefixes` = `get_prefix_pairs(l, m)`. This yields $\\{(G_{l,i}, P_{l,i}) | i \\in [l,m]\\}$.\n    2.  Recursively compute all local prefixes for the right half: `right_local_prefixes` = `get_prefix_pairs(m+1, r)`. This yields $\\{(G_{m+1,j}, P_{m+1,j}) | j \\in [m+1,r]\\}$.\n    3.  The final prefixes for indices $i \\in [l,m]$ are already in `left_prefixes`.\n    4.  To obtain the global prefixes for indices $j \\in [m+1,r]$, we must compose each local right prefix with the total group prefix of the entire left block. This total prefix is $(G_{l,m}, P_{l,m})$, which is the last element of `left_prefixes`.\n    5.  For each $(G_{m+1,j}, P_{m+1,j})$ in `right_local_prefixes`, we compute the global prefix $(G_{0,j}, P_{0,j})$ as $(G_{m+1,j}, P_{m+1,j}) \\circ (G_{l,m}, P_{l,m})$.\n    6.  The final result is the concatenation of the left-half global prefixes and the newly computed right-half global prefixes.\n\nMemoization is used to store the results for each range `(l,r)`, avoiding redundant computations and effectively modeling the sharing of sub-computations in the prefix graph.\n\n**4. Final Summation and Verification**\nOnce the prefix pairs $(G_{0,i}, P_{0,i})$ for all $i \\in \\{0, \\dots, n-1\\}$ are computed, the carry $c_{i+1}$ into the next bit position can be calculated directly from the initial carry-in $c_0$:\n$$c_{i+1} = G_{0,i} \\lor (P_{0,i} \\land c_0)$$\nThe carry into bit position $i$ is $c_i$, where for $i>0$, $c_i = G_{0,i-1} \\lor (P_{0,i-1} \\land c_0)$. The sum bit $s_i$ is then the exclusive OR of the propagate signal $p_i$ and the carry-in $c_i$:\n$$s_i = p_i \\oplus c_i = (a_i \\oplus b_i) \\oplus c_i$$\nThe final integer sum $S$ is assembled from the sum bits and the final carry-out $c_n$:\n$$S = \\left(\\sum_{i=0}^{n-1} s_i \\cdot 2^i\\right) + c_n \\cdot 2^n$$\nThis computed sum $S$ is then verified by comparing it against the arithmetically correct value $A+B+c_0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Ladner-Fischer adder.\n    \"\"\"\n    test_cases = [\n        # Case 1: n=1, A=1, B=1, c_0=0\n        (1, 1, 1, 0),\n        # Case 2: n=4, A=9, B=6, c_0=1\n        (4, 9, 6, 1),\n        # Case 3: n=8, A=90, B=60, c_0=0\n        (8, 90, 60, 0),\n        # Case 4: n=8, A=255, B=1, c_0=1\n        (8, 255, 1, 1),\n        # Case 5: n=32, A=4042322160, B=252645135, c_0=0\n        (32, 4042322160, 252645135, 0),\n        # Case 6: n=32, A=2147483648, B=2147483648, c_0=1\n        (32, 2147483648, 2147483648, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, A, B, c_0 = case\n        is_correct = run_ladner_fischer_test(n, A, B, c_0)\n        results.append(is_correct)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_ladner_fischer_test(n, A, B, c_0):\n    \"\"\"\n    Constructs and evaluates a Ladner-Fischer adder for a single test case.\n\n    Args:\n        n (int): The number of bits.\n        A (int): The first integer operand.\n        B (int): The second integer operand.\n        c_0 (int): The initial carry-in (0 or 1).\n\n    Returns:\n        bool: True if the computed sum equals the arithmetic sum, False otherwise.\n    \"\"\"\n    if n == 0:\n        ground_truth = A + B + c_0\n        # For n=0, sum is just the carry-in.\n        S = c_0\n        return S == ground_truth\n\n    # Convert integers to bit arrays (lsb first)\n    a = [(A >> i) & 1 for i in range(n)]\n    b = [(B >> i) & 1 for i in range(n)]\n    c_0_bool = bool(c_0)\n\n    # 1. Compute initial generate (g) and propagate (p) signals\n    # g_i = a_i AND b_i\n    # p_i = a_i XOR b_i\n    initial_gp = [(bool(a[i] & b[i]), bool(a[i] ^ b[i])) for i in range(n)]\n\n    # Memoization cache for the recursive prefix computation\n    memo = {}\n\n    # 2. Define the associative composition operator for (G, P) pairs\n    def op(gp2, gp1):\n        \"\"\"\n        Computes (G2, P2) o (G1, P1).\n        This corresponds to the group pair for a range formed by concatenating\n        the range of gp1 followed by the range of gp2.\n        \"\"\"\n        G1, P1 = gp1\n        G2, P2 = gp2\n        # G_out = G2 OR (P2 AND G1)\n        # P_out = P2 AND P1\n        return (G2 or (P2 and G1), P2 and P1)\n\n    # 3. Recursive function to compute prefix pairs\n    def get_prefix_pairs(l, r):\n        \"\"\"\n        Recursively computes all prefix (G, P) pairs for the index range [l, r].\n        The i-th element of the returned list is the group pair for the range [l, l+i].\n        \"\"\"\n        if (l, r) in memo:\n            return memo[(l, r)]\n\n        # Base case: a range of a single bit\n        if l == r:\n            result = [initial_gp[l]]\n            memo[(l, r)] = result\n            return result\n\n        # Recursive step: divide and conquer\n        m = l + (r - l) // 2\n        left_prefixes = get_prefix_pairs(l, m)\n        right_local_prefixes = get_prefix_pairs(m + 1, r)\n\n        # The group (G, P) for the entire left block\n        broadcast_gp = left_prefixes[-1]\n\n        # Combine the left block's total group (G, P) with each of the\n        # right block's local prefixes to get global prefixes.\n        right_global_prefixes = [op(rp, broadcast_gp) for rp in right_local_prefixes]\n\n        result = left_prefixes + right_global_prefixes\n        memo[(l, r)] = result\n        return result\n\n    # Compute all prefix pairs (G_{0,i}, P_{0,i}) for i from 0 to n-1\n    prefix_pairs = get_prefix_pairs(0, n - 1)\n\n    # 4. Compute all carries c_1, ..., c_n using the prefix pairs\n    # c_{i+1} = G_{0,i} OR (P_{0,i} AND c_0)\n    carries = [c_0_bool]\n    for i in range(n):\n        G_0_i, P_0_i = prefix_pairs[i]\n        c_i_plus_1 = G_0_i or (P_0_i and c_0_bool)\n        carries.append(c_i_plus_1)\n\n    # 5. Compute sum bits\n    # s_i = p_i XOR c_i\n    sum_bits = []\n    for i in range(n):\n        p_i = initial_gp[i][1]\n        c_i = carries[i]\n        s_i = p_i ^ c_i\n        sum_bits.append(s_i)\n\n    # 6. Compute the final integer sum and verify\n    S = 0\n    for i in range(n):\n        if sum_bits[i]:\n            S += 1 << i\n\n    # Add the final carry-out c_n\n    c_n = carries[n]\n    if c_n:\n        S += 1 << n\n\n    ground_truth = A + B + c_0\n    \n    return S == ground_truth\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Effective digital design involves navigating a landscape of architectural trade-offs. In this practice , you will analyze a block carry-lookahead adder, a structure that balances the delay of carry generation within blocks against the delay of carry propagation between blocks. By applying a hypothetical gate delay model, you will use analytical methods to derive the optimal block size that minimizes the total carry propagation time, illustrating a core principle of performance optimization in hardware design.",
            "id": "4255521",
            "problem": "Consider an $n$-bit two-level block Carry Lookahead Adder (CLA), organized into $n/b$ contiguous blocks of size $b$. The CLA is designed under a standard Electronic Design Automation (EDA) timing model in which the delay of a logic gate with fan-in $k \\geq 2$ is given by $t_{2} + (k-2)\\Delta$, where $t_{2}$ is the delay of a two-input gate and $\\Delta$ is the incremental delay per additional input beyond two. The adder employs bit-level propagate and generate signals defined by $p_{i} = a_{i} \\oplus b_{i}$ and $g_{i} = a_{i} \\wedge b_{i}$, respectively, for bit index $i \\in \\{0,1,\\dots,n-1\\}$. Within each block $j$, the group propagate is $P_{j} = \\bigwedge_{i \\in \\text{block } j} p_{i}$ and the group generate $G_{j}$ is formed by a sum-of-products lookahead network from the $\\{p_{i},g_{i}\\}$ of the block. Assume that the precomputation needed to feed the final wide $b$-input $\\vee$ gate for $G_{j}$, built from only two-input primitives, has a fixed depth and thus contributes a constant delay independent of $b$.\n\nInter-block carry computation follows the carry recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$ and is implemented as a chain of per-block two-input gates, one $\\wedge$ followed by one $\\vee$ per block along the carry path. Assume $p_{i}$ and $g_{i}$ are available after a constant head delay (from the adder inputs) that does not depend on $b$, and that the dominant $b$-dependent delays inside a block are the single $b$-input $\\wedge$ for $P_{j}$ and the single $b$-input $\\vee$ for $G_{j}$.\n\nUsing only the fundamental carry definitions $C_{i+1} = g_{i} \\vee (p_{i} \\wedge C_{i})$, the block group definitions for $P_{j}$ and $G_{j}$ stated above, and the specified gate delay model $t(k) = t_{2} + (k-2)\\Delta$, derive the block size $b$ that minimizes the worst-case carry-out delay of the adder as a function of $n$, $t_{2}$, and $\\Delta$. Express your final result for the optimal $b$ as a single closed-form analytical expression. No numerical evaluation is required.",
            "solution": "The starting point is the carry recurrence at the bit level, $C_{i+1} = g_{i} \\vee (p_{i} \\wedge C_{i})$, which generalizes at the block level to $C_{j+1} = G_{j} \\vee \\left(P_{j} \\wedge C_{j}\\right)$ once block group propagate and generate signals $P_{j}$ and $G_{j}$ have been formed. The critical-path delay to the adder carry-out must account for three components: the time to form bit-level signals $\\{p_{i},g_{i}\\}$, the time to form the block-level signals $\\{P_{j},G_{j}\\}$, and the time to propagate through the chain of $n/b$ blocks via the recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$.\n\nUnder the given gate delay model, any $k$-input gate has delay $t(k) = t_{2} + (k-2)\\Delta$. Let the constant delay required from the adder inputs to the availability of all $\\{p_{i},g_{i}\\}$ be denoted by $T_{\\text{head}}$, which may include the delays of $\\oplus$ and $\\wedge$ operations and any local buffering, and does not depend on $b$. Inside a block of size $b$, the group propagate $P_{j}$ is formed by a single $b$-input $\\wedge$, incurring delay $t_{P}(b) = t_{2} + (b-2)\\Delta$ beyond the availability of $\\{p_{i}\\}$. The group generate $G_{j}$ is assumed to be formed by a final $b$-input $\\vee$ whose inputs are precomputed by a fixed-depth network of two-input gates; let the fixed precomputation delay be $T_{\\text{pre}}$. Therefore, the dominant $b$-dependent portion for $G_{j}$ is the $b$-input $\\vee$ with delay $t_{G}(b) = t_{2} + (b-2)\\Delta$ beyond the precomputation. The earliest time at which both $P_{j}$ and $G_{j}$ are available for all blocks is thus\n$$\nT_{\\text{blk}}(b) = T_{\\text{head}} + T_{\\text{pre}} + \\left[t_{2} + (b-2)\\Delta\\right],\n$$\nwhere the bracketed term captures the $b$-dependent wide-gate delay and the sum $T_{\\text{head}} + T_{\\text{pre}}$ is independent of $b$.\n\nAcross blocks, the carry recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$ is implemented per block by one two-input $\\wedge$ followed by one two-input $\\vee$, so each block along the carry chain contributes a delay of $2 t_{2}$. For $n/b$ blocks, the inter-block carry propagation delay is\n$$\nT_{\\text{chain}}(b) = 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nNeglecting constant terms independent of $b$ when searching for the minimizing $b$, the total worst-case carry-out delay can be written as\n$$\nD(b) = \\underbrace{T_{\\text{head}} + T_{\\text{pre}}}_{\\text{independent of } b} + \\left[t_{2} + (b-2)\\Delta\\right] + 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nDefine $K = T_{\\text{head}} + T_{\\text{pre}} + t_{2} - 2\\Delta$, which is independent of $b$. Then\n$$\nD(b) = K + \\Delta b + 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nTo minimize $D(b)$ with respect to continuous $b > 0$, differentiate and set the derivative to zero:\n$$\n\\frac{dD}{db} = \\Delta - 2 t_{2} \\cdot \\frac{n}{b^{2}} = 0.\n$$\nSolving for $b$ gives\n$$\n\\Delta = 2 t_{2} \\cdot \\frac{n}{b^{2}} \\quad \\Rightarrow \\quad b^{2} = \\frac{2 t_{2} n}{\\Delta} \\quad \\Rightarrow \\quad b^{\\star} = \\sqrt{\\frac{2 t_{2} n}{\\Delta}}.\n$$\nA second derivative check confirms convexity:\n$$\n\\frac{d^{2}D}{db^{2}} = 4 t_{2} \\cdot \\frac{n}{b^{3}} > 0 \\quad \\text{for} \\quad b > 0,\n$$\nso the stationary point is indeed a global minimum. The constants $T_{\\text{head}}$ and $T_{\\text{pre}}$ do not affect the optimal $b$, as they do not depend on $b$. Therefore, the optimal block size that minimizes the worst-case carry-out delay under the specified model is\n$$\nb^{\\star} = \\sqrt{\\frac{2 t_{2} n}{\\Delta}}.\n$$\nIf an integer block size is required in implementation, one would choose the nearest integer to $b^{\\star}$, but the closed-form analytical minimizer as requested is as above.",
            "answer": "$$\\boxed{\\sqrt{\\frac{2 t_{2} n}{\\Delta}}}$$"
        },
        {
            "introduction": "An elegant architecture must be backed by a high-performance circuit implementation to achieve its potential. This final practice  takes you down to the transistor level, using the powerful method of logical effort to optimize a critical path within a prefix adder. You will calculate the intrinsic logical effort and parasitic delay of a prefix cell and use these parameters to determine the optimal stage effort and transistor sizing, bridging the gap between logical architecture and physical circuit performance.",
            "id": "4255542",
            "problem": "A parallel-prefix carry network uses black prefix cells to accelerate carries in a $64$-bit adder. Along the critical generate path, there are $N=6$ identical black prefix cells in series. Each black cell is implemented as a static Complementary Metal-Oxide-Semiconductor (CMOS) complex gate of the And-Or-Invert (AOI) or Or-And-Invert (OAI) type with fan-in $4$ (functionally equivalent to an $\\text{AOI22}$ or its dual $\\text{OAI22}$). Use the method of logical effort to model delay, with the following normalization and physical assumptions:\n\n- The minimum inverter used for normalization has $n$-channel width $1$ and $p$-channel width $2$ (chosen to equalize pull-up and pull-down resistances). Its input capacitance is denoted $C_{\\text{inv}}$ and is proportional to the sum of its device widths. Gate input capacitance is proportional to the sum of the widths of the transistors driven by that input.\n- Series devices in a pull-up or pull-down conduction path are upsized so that the worst-case path resistance equals that of the minimum inverter.\n- The parasitic delay of a gate is proportional to the total diffusion capacitance connected to its output and is normalized to the inverter’s parasitic; assume the diffusion contribution per device at the output sums linearly.\n- There is no branching along this path (branching effort equal to $1$).\n\nThe path must drive a final load of $C_{L} = 256\\,C_{\\text{inv}}$. The source that drives the first black cell cannot be upsized and constrains the input capacitance seen by the first black cell to be at most $4\\,C_{\\text{inv}}$. You may assume the first black cell is sized to exactly meet this input capacitance budget. Measure delay in the logical-effort delay unit $\\tau$.\n\nTasks:\n1. Derive the logical effort $g$ and the parasitic delay $p$ of the $\\text{AOI22}$/$\\text{OAI22}$ black cell under the sizing rule stated above.\n2. Using the method of logical effort and the given load and input-capacitance constraint, determine the optimal per-stage effort and the corresponding sizing progression along the path (expressed as the input capacitance of each stage in multiples of $C_{\\text{inv}}$).\n3. Compute the minimum path delay $D_{\\min}$ in units of $\\tau$.\n\nReport only the numerical value of $D_{\\min}$ in units of $\\tau$ as your final answer. No rounding is required.",
            "solution": "**Solution Derivation**\n\nThe solution proceeds in three parts as requested by the problem statement:\n1.  Derive the logical effort $g$ and parasitic delay $p$ of the black prefix cell.\n2.  Determine the optimal per-stage effort.\n3.  Compute the minimum path delay $D_{\\min}$.\n\n**1. Logical Effort and Parasitic Delay of the AOI22 Cell**\n\nThe black prefix cell is an AOI22 gate, with the Boolean function $F = \\overline{(A \\cdot B) + (C \\cdot D)}$. We must first determine the transistor sizes required to give this gate the same drive strength as the reference inverter. The reference inverter has an $n$-channel transistor of width $1$ and a $p$-channel transistor of width $2$. This sizing equalizes the pull-up and pull-down resistances, which we denote as $R_{\\text{inv}}$. The input capacitance of this inverter is proportional to the sum of its gate widths, $1+2=3$.\n\n**Sizing the AOI22 Gate:**\n- **Pull-Down Network (PDN):** The PDN consists of two parallel branches, where each branch has two $n$-channel transistors in series (e.g., A in series with B). The worst-case pull-down resistance occurs when only one branch is active. This path consists of two series $n$-channel transistors. To make the total resistance equal to $R_{\\text{inv}}$, each of these transistors must have a resistance of $R_{\\text{inv}}/2$. Since resistance is inversely proportional to width, their width must be twice that of the reference $n$-channel transistor. Thus, all $n$-channel transistors must have a width of $2 \\times 1 = 2$.\n- **Pull-Up Network (PUN):** The PUN is the dual of the PDN. It consists of two series blocks, each containing two parallel $p$-channel transistors (e.g., A in parallel with C). The worst-case pull-up resistance occurs when a path is formed through one transistor in each of the series blocks. This path consists of two series $p$-channel transistors. To make their total resistance equal to $R_{\\text{inv}}$, each must have a resistance of $R_{\\text{inv}}/2$. The reference $p$-channel transistor has width $2$ and resistance $R_{\\text{inv}}$. Therefore, to achieve half the resistance, the width must be doubled. Thus, all $p$-channel transistors must have a width of $2 \\times 2 = 4$.\n\n**Logical Effort ($g$):**\nThe logical effort of a gate is the ratio of its input capacitance to that of an inverter with the same output drive strength.\n- The input capacitance of the AOI22 gate at any input (e.g., A) is proportional to the sum of the widths of the transistors it drives (one $n$-channel, one $p$-channel): $C_{\\text{in,AOI22}} \\propto W_n + W_p = 2 + 4 = 6$.\n- The input capacitance of the reference inverter is proportional to $W_{n,\\text{inv}} + W_{p,\\text{inv}} = 1 + 2 = 3$.\n- The logical effort $g$ is the ratio of these capacitances:\n$$g = \\frac{C_{\\text{in,AOI22}}}{C_{\\text{in,inv}}} = \\frac{6}{3} = 2$$\nThe analysis for an OAI22 gate yields the same result.\n\n**Parasitic Delay ($p$):**\nThe parasitic delay is the ratio of the gate's output diffusion capacitance to that of the reference inverter. Diffusion capacitance is proportional to the total width of the transistor drains connected to the output node.\n- **AOI22 Output Node:** The output is connected to the drains of two $n$-channel transistors and two $p$-channel transistors.\n- The total diffusion width at the output of the AOI22 is the sum of the widths of these four transistors: $W_{\\text{diff,AOI22}} = 2 \\cdot W_n + 2 \\cdot W_p = 2 \\cdot 2 + 2 \\cdot 4 = 4 + 8 = 12$.\n- **Inverter Output Node:** The output is connected to the drain of one $n$-channel and one $p$-channel transistor. The total diffusion width is: $W_{\\text{diff,inv}} = 1 \\cdot W_{n,\\text{inv}} + 1 \\cdot W_{p,\\text{inv}} = 1 \\cdot 1 + 1 \\cdot 2 = 3$.\n- The parasitic delay $p$ is the ratio of these diffusion widths (assuming $p_{\\text{inv}}=1$ by normalization):\n$$p = \\frac{W_{\\text{diff,AOI22}}}{W_{\\text{diff,inv}}} = \\frac{12}{3} = 4$$\n\n**2. Optimal Stage Effort and Path Parameters**\n\nThe path consists of $N=6$ identical stages. The delay of a path is minimized when the effort of each stage is the same. The stage effort is $f_i = g_i h_i$, where $g_i$ is the logical effort and $h_i$ is the electrical effort.\n- Path logical effort: $G = \\prod_{i=1}^{N} g_i = g^N = 2^6 = 64$.\n- Path electrical effort: $H = \\frac{C_L}{C_{\\text{in},1}}$, where $C_L$ is the final load and $C_{\\text{in},1}$ is the input capacitance of the first stage.\n$$H = \\frac{256\\,C_{\\text{inv}}}{4\\,C_{\\text{inv}}} = 64$$\n- Total path effort: $F = GBH$. Since the branching effort $B=1$, $F=GH$.\n$$F = 64 \\times 64 = 4096$$\nThe optimal stage effort, $f_{\\text{opt}}$, is the $N$-th root of the total path effort:\n$$f_{\\text{opt}} = F^{1/N} = (4096)^{1/6} = (2^{12})^{1/6} = 2^{12/6} = 2^2 = 4$$\n\n**3. Minimum Path Delay ($D_{\\min}$)**\n\nThe total path delay, $D$, is the sum of the individual stage delays, $d_i = f_i + p_i$. When minimized, all stage efforts are equal to $f_{\\text{opt}}$.\nThe minimum path delay is given by the formula:\n$$D_{\\min} = N \\cdot f_{\\text{opt}} + P_{\\text{path}}$$\nwhere $P_{\\text{path}}$ is the sum of the parasitic delays of all stages in the path.\n- Path parasitic delay: $P_{\\text{path}} = \\sum_{i=1}^{N} p_i = N \\cdot p = 6 \\times 4 = 24$.\nSubstituting the values for $N$, $f_{\\text{opt}}$, and $P_{\\text{path}}$:\n$$D_{\\min} = (6 \\times 4) + 24 = 24 + 24 = 48$$\nThe delay is measured in units of $\\tau$, the fundamental delay unit of the logical effort methodology.\nThe sizing of the stages would be such that the electrical effort of each stage is $h_i = f_{\\text{opt}} / g = 4 / 2 = 2$.\nThis leads to a sequence of input capacitances: $C_{\\text{in},1} = 4\\,C_{\\text{inv}}$, $C_{\\text{in},2} = 8\\,C_{\\text{inv}}$, ..., $C_{\\text{in},6} = 128\\,C_{\\text{inv}}$. The output of the last stage is $h_6 \\cdot C_{\\text{in},6} = 2 \\cdot 128\\,C_{\\text{inv}} = 256\\,C_{\\text{inv}}$, which correctly matches the load $C_L$.\nThe minimum delay is therefore $48\\,\\tau$.",
            "answer": "$$\\boxed{48}$$"
        }
    ]
}