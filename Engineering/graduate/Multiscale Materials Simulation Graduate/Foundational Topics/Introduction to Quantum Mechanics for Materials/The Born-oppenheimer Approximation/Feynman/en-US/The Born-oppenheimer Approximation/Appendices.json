{
    "hands_on_practices": [
        {
            "introduction": "The Born-Oppenheimer approximation provides the potential energy surface (PES) that governs nuclear motion. This practice bridges the gap between an abstract, numerically computed PES and a functional analytical form by fitting its properties to a Morse potential, a cornerstone model for diatomic interactions . By relating the potential's curvature and anharmonicity to its dissociation energy, you will gain insight into how quantum chemical calculations directly inform models of molecular vibration and stability.",
            "id": "204375",
            "problem": "In the framework of the Born-Oppenheimer approximation, the electronic energy of a diatomic molecule, for a given electronic state, defines a potential energy curve (PEC), $U(R)$, as a function of the internuclear distance $R$. A widely used analytical model for this PEC is the Morse potential, given by:\n$$ V(R) = D_e \\left(1 - e^{-a(R - R_e)}\\right)^2 $$\nHere, $D_e$ is the dissociation energy relative to the potential minimum, $R_e$ is the equilibrium bond distance, and $a$ is a parameter that controls the curvature of the potential well.\n\nA high-precision quantum chemistry calculation has been performed for a diatomic molecule, yielding the PEC, $U(R)$. Instead of fitting to a large set of data points, it is often convenient to characterize the potential by its properties near the minimum. The following quantities have been determined from the calculated PEC:\n1. The equilibrium bond distance, $R_e$.\n2. The harmonic force constant, $k_f = \\frac{d^2U}{dR^2}\\bigg|_{R=R_e}$.\n3. The cubic anharmonicity constant, $\\gamma = \\frac{d^3U}{dR^3}\\bigg|_{R=R_e}$.\n\nYour task is to find the parameters of the Morse potential that best reproduce the properties of the calculated PEC around its minimum. By matching the second and third derivatives of the Morse potential $V(R)$ to the given constants $k_f$ and $\\gamma$ at $R=R_e$, determine an analytical expression for the dissociation energy $D_e$ in terms of $k_f$ and $\\gamma$.",
            "solution": "The Morse potential is \n$$V(R)=D_e\\bigl(1-e^{-a(R-R_e)}\\bigr)^2.\\quad\\text{Let }x=R-R_e.$$\nExpand and differentiate:\n$$V(R)=D_e\\bigl(1-2e^{-ax}+e^{-2ax}\\bigr).$$\nFirst derivative:\n$$V'=D_e\\bigl(2a e^{-ax}-2a e^{-2ax}\\bigr).$$\nSecond derivative:\n$$V''=D_e\\bigl(-2a^2 e^{-ax}+4a^2 e^{-2ax}\\bigr)=2a^2D_e\\bigl(-e^{-ax}+2e^{-2ax}\\bigr).$$\nAt equilibrium ($x=0$):\n$$V''(0)=2a^2D_e=k_f.\\quad(1)$$\nThird derivative:\n$$V'''=D_e\\bigl(2a^3 e^{-ax}-8a^3 e^{-2ax}\\bigr)=2a^3D_e\\bigl(e^{-ax}-4e^{-2ax}\\bigr).$$\nAt $x=0$:\n$$V'''(0)=-6a^3D_e=\\gamma.\\quad(2)$$\nFrom (2)/(1):\n$$\\frac{\\gamma}{k_f}=\\frac{-6a^3D_e}{2a^2D_e}=-3a\\quad\\Longrightarrow\\quad a=-\\frac{\\gamma}{3k_f}.$$\nSubstitute into (1):\n$$D_e=\\frac{k_f}{2a^2}\n=\\frac{k_f}{2\\bigl(\\frac{\\gamma^2}{9k_f^2}\\bigr)}\n=\\frac{9k_f^3}{2\\gamma^2}.$$",
            "answer": "$$\\boxed{\\frac{9k_f^3}{2\\gamma^2}}$$"
        },
        {
            "introduction": "The Born-Oppenheimer approximation relies on a clear separation of energy scales between electrons and nuclei, a condition that fails near so-called \"avoided crossings\" of potential energy surfaces. This exercise provides a fundamental look into this breakdown by having you derive the non-adiabatic derivative coupling for a classic two-state model system . Calculating this coupling will illuminate how it peaks precisely where the adiabatic energy gap is smallest, providing a quantitative measure of the mixing between electronic states that the BO approximation neglects.",
            "id": "3844478",
            "problem": "In multiscale materials simulation, the Born–Oppenheimer (BO) approximation separates fast electronic motion from slow nuclear motion by solving the electronic eigenproblem at fixed nuclear coordinates. Consider a two-state avoided crossing described in a diabatic basis $\\{|\\chi_{1}\\rangle,|\\chi_{2}\\rangle\\}$ that is independent of the scalar nuclear coordinate $R$. The electronic Hamiltonian in this diabatic basis is\n$$\nH_{d}(R)=\\begin{pmatrix} a R & \\Delta \\\\ \\Delta & -a R \\end{pmatrix},\n$$\nwhere $a$ and $\\Delta$ are real, $R$-independent parameters, and $R$ is a real nuclear coordinate. The adiabatic electronic states $\\{|\\phi_{1}(R)\\rangle,|\\phi_{2}(R)\\rangle\\}$ are defined as the orthonormal eigenvectors of $H_{d}(R)$ at fixed $R$, chosen to be real and continuous in $R$. The adiabatic nonadiabatic derivative coupling is defined by\n$$\nd_{12}(R)=\\langle \\phi_{1}(R)|\\partial_{R}\\phi_{2}(R)\\rangle.\n$$\nStarting only from the definition of the adiabatic states as eigenvectors of $H_{d}(R)$ and the definition of the derivative coupling above, derive the closed-form expression for the magnitude of the coupling $|d_{12}(R)|$ as a function of $R$, $a$, and $\\Delta$, without invoking any special-case formulas beyond linear algebra and differentiation. Express your final answer as a single analytic expression in terms of $R$, $a$, and $\\Delta$. No numerical evaluation is required, and no rounding is needed.",
            "solution": "The problem is well-posed and scientifically grounded, representing a standard model for an avoided crossing in quantum dynamics. We will proceed with a rigorous derivation starting from first principles as stipulated.\n\nThe adiabatic states $|\\phi_k(R)\\rangle$ and their corresponding energies $E_k(R)$ are defined by the time-independent electronic Schrödinger equation for a fixed nuclear coordinate $R$:\n$$H_{d}(R) |\\phi_k(R)\\rangle = E_k(R) |\\phi_k(R)\\rangle$$\nwhere $k \\in \\{1, 2\\}$. The states are orthonormal, $\\langle\\phi_j(R)|\\phi_k(R)\\rangle = \\delta_{jk}$.\n\nTo find an expression for the nonadiabatic derivative coupling $d_{12}(R) = \\langle \\phi_1(R)|\\partial_R\\phi_2(R)\\rangle$, we begin by differentiating the eigenvalue equation for $|\\phi_2(R)\\rangle$ with respect to $R$:\n$$\\frac{\\partial}{\\partial R} \\left( H_d(R) |\\phi_2(R)\\rangle \\right) = \\frac{\\partial}{\\partial R} \\left( E_2(R) |\\phi_2(R)\\rangle \\right)$$\nApplying the product rule for differentiation yields:\n$$\\left(\\partial_R H_d(R)\\right) |\\phi_2(R)\\rangle + H_d(R) \\left(\\partial_R |\\phi_2(R)\\rangle\\right) = \\left(\\partial_R E_2(R)\\right) |\\phi_2(R)\\rangle + E_2(R) \\left(\\partial_R |\\phi_2(R)\\rangle\\right)$$\nTo isolate the term involving $\\partial_R |\\phi_2(R)\\rangle$, we project this entire equation onto the state $\\langle \\phi_1(R)|$:\n$$\\langle \\phi_1(R)| \\left(\\partial_R H_d(R)\\right) |\\phi_2(R)\\rangle + \\langle \\phi_1(R)| H_d(R) |\\partial_R \\phi_2(R)\\rangle = (\\partial_R E_2(R)) \\langle \\phi_1(R)|\\phi_2(R)\\rangle + E_2(R) \\langle \\phi_1(R)|\\partial_R \\phi_2(R)\\rangle$$\nWe can simplify this expression using the properties of the adiabatic states. First, due to orthonormality, $\\langle \\phi_1(R)|\\phi_2(R)\\rangle = 0$. Second, since $H_d(R)$ is a real symmetric (and therefore Hermitian) matrix, it acts on its own bra-eigenvectors from the left as $\\langle \\phi_1(R)| H_d(R) = E_1(R) \\langle \\phi_1(R)|$. Applying these two properties, the equation becomes:\n$$\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle + E_1(R) \\langle \\phi_1(R)|\\partial_R \\phi_2(R)\\rangle = E_2(R) \\langle \\phi_1(R)|\\partial_R \\phi_2(R)\\rangle$$\nBy definition, $d_{12}(R) = \\langle \\phi_1(R)|\\partial_R\\phi_2(R)\\rangle$. Substituting this into the equation, we get:\n$$\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle + E_1(R) d_{12}(R) = E_2(R) d_{12}(R)$$\nFor the non-degenerate case where $E_1(R) \\neq E_2(R)$, we can rearrange to solve for $d_{12}(R)$:\n$$d_{12}(R) = \\frac{\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle}{E_2(R) - E_1(R)}$$\nThis expression is derived directly from the problem definitions and does not invoke any unstated formulas. We now proceed to calculate the three components: the energy difference $E_2(R) - E_1(R)$, the derivative of the Hamiltonian $\\partial_R H_d(R)$, and the matrix element $\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle$.\n\n1.  **Eigenvalue Difference:** The eigenvalues $E(R)$ are the roots of the characteristic equation $\\det(H_d(R) - E I) = 0$:\n    $$\n    \\det \\begin{pmatrix} a R - E & \\Delta \\\\ \\Delta & -a R - E \\end{pmatrix} = (aR - E)(-aR - E) - \\Delta^2 = 0\n    $$\n    $$E^2 - (aR)^2 - \\Delta^2 = 0 \\implies E^2 = a^2R^2 + \\Delta^2$$\n    The two eigenvalues are $E(R) = \\pm \\sqrt{a^2R^2 + \\Delta^2}$. We define $E_2(R)$ as the upper state and $E_1(R)$ as the lower state:\n    $$E_1(R) = -\\sqrt{a^2R^2 + \\Delta^2} \\quad \\text{and} \\quad E_2(R) = \\sqrt{a^2R^2 + \\Delta^2}$$\n    The energy difference is therefore:\n    $$E_2(R) - E_1(R) = 2\\sqrt{a^2R^2 + \\Delta^2}$$\n\n2.  **Derivative of the Hamiltonian:** The Hamiltonian is $H_{d}(R)=\\begin{pmatrix} a R & \\Delta \\\\ \\Delta & -a R \\end{pmatrix}$. Its derivative with respect to $R$ is:\n    $$\\partial_R H_d(R) = \\frac{d}{dR} \\begin{pmatrix} a R & \\Delta \\\\ \\Delta & -a R \\end{pmatrix} = \\begin{pmatrix} a & 0 \\\\ 0 & -a \\end{pmatrix}$$\n\n3.  **Matrix Element:** To compute $\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle$, we must first find expressions for the eigenvectors $|\\phi_1(R)\\rangle$ and $|\\phi_2(R)\\rangle$. A general real, orthonormal set of eigenvectors for a $2 \\times 2$ real symmetric matrix can be written in terms of a mixing angle $\\theta(R)$:\n    $$|\\phi_1(R)\\rangle = \\begin{pmatrix} -\\sin\\theta(R) \\\\ \\cos\\theta(R) \\end{pmatrix}, \\quad |\\phi_2(R)\\rangle = \\begin{pmatrix} \\cos\\theta(R) \\\\ \\sin\\theta(R) \\end{pmatrix}$$\n    The matrix element is then:\n    $$\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle = \\begin{pmatrix} -\\sin\\theta(R) & \\cos\\theta(R) \\end{pmatrix} \\begin{pmatrix} a & 0 \\\\ 0 & -a \\end{pmatrix} \\begin{pmatrix} \\cos\\theta(R) \\\\ \\sin\\theta(R) \\end{pmatrix}$$\n    $$= \\begin{pmatrix} -\\sin\\theta(R) & \\cos\\theta(R) \\end{pmatrix} \\begin{pmatrix} a\\cos\\theta(R) \\\\ -a\\sin\\theta(R) \\end{pmatrix} = -a\\sin\\theta(R)\\cos\\theta(R) - a\\cos\\theta(R)\\sin\\theta(R)$$\n    $$= -2a\\sin\\theta(R)\\cos\\theta(R) = -a\\sin(2\\theta(R))$$\n    To find $\\sin(2\\theta(R))$, we can relate $\\theta(R)$ to the components of $H_d(R)$. The eigenvector equation for $|\\phi_2(R)\\rangle$ gives:\n    $$\\begin{pmatrix} aR & \\Delta \\\\ \\Delta & -aR \\end{pmatrix} \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix} = E_2 \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}$$\n    From the first row: $aR\\cos\\theta + \\Delta\\sin\\theta = E_2\\cos\\theta \\implies \\Delta\\sin\\theta = (E_2 - aR)\\cos\\theta$.\n    From the second row: $\\Delta\\cos\\theta - aR\\sin\\theta = E_2\\sin\\theta \\implies \\Delta\\cos\\theta = (E_2 + aR)\\sin\\theta$.\n    Dividing these two equations gives: $\\frac{\\Delta\\sin\\theta}{\\Delta\\cos\\theta} = \\frac{(E_2 - aR)\\cos\\theta}{(E_2 + aR)\\sin\\theta} \\implies \\tan^2\\theta = \\frac{E_2 - aR}{E_2 + aR}$.\n    An alternative approach is to consider $H_d(R) = aR\\sigma_z + \\Delta\\sigma_x$ where $\\sigma_z, \\sigma_x$ are Pauli matrices. The rotation that diagonalizes this Hamiltonian is defined by an axis in the $x$-$z$ plane. The angle $2\\theta$ corresponds to the polar angle of the vector $( \\Delta, aR)$. Thus, we have $\\tan(2\\theta(R)) = \\frac{\\Delta}{aR}$.\n    From this relationship, we can determine $\\sin(2\\theta(R))$ by considering a right triangle with opposite side $\\Delta$ and adjacent side $aR$. The hypotenuse is $\\sqrt{(aR)^2 + \\Delta^2} = \\sqrt{a^2R^2 + \\Delta^2}$.\n    $$\\sin(2\\theta(R)) = \\frac{\\text{opposite}}{\\text{hypotenuse}} = \\frac{\\Delta}{\\sqrt{a^2R^2 + \\Delta^2}}$$\n    Substituting this into the expression for the matrix element:\n    $$\\langle \\phi_1(R)| \\partial_R H_d(R) |\\phi_2(R)\\rangle = -a \\left( \\frac{\\Delta}{\\sqrt{a^2R^2 + \\Delta^2}} \\right)$$\n\nFinally, we assemble the pieces into the expression for $d_{12}(R)$:\n$$d_{12}(R) = \\frac{\\langle \\phi_1| \\partial_R H_d |\\phi_2\\rangle}{E_2 - E_1} = \\frac{-a \\frac{\\Delta}{\\sqrt{a^2R^2 + \\Delta^2}}}{2\\sqrt{a^2R^2 + \\Delta^2}} = \\frac{-a\\Delta}{2(a^2R^2 + \\Delta^2)}$$\nThe problem asks for the magnitude of this coupling:\n$$|d_{12}(R)| = \\left| \\frac{-a\\Delta}{2(a^2R^2 + \\Delta^2)} \\right|$$\nSince $a$ and $\\Delta$ are real parameters and $R$ is a real coordinate, $a^2R^2 + \\Delta^2 \\ge 0$. The equality holds only if $a=0$ or $R=0$, and $\\Delta=0$, which is a trivial case. Thus, the denominator is positive.\n$$|d_{12}(R)| = \\frac{|a\\Delta|}{2(a^2R^2 + \\Delta^2)}$$\nThis is the final closed-form expression for the magnitude of the nonadiabatic coupling.",
            "answer": "$$\n\\boxed{\\frac{|a\\Delta|}{2(a^2R^2 + \\Delta^2)}}\n$$"
        },
        {
            "introduction": "Understanding the limitations of the Born-Oppenheimer approximation is not merely a theoretical exercise; it is crucial for developing robust and efficient simulation tools for complex materials. This advanced practice demonstrates how metrics that signal the breakdown of the BO approximation—high potential curvature and strong derivative coupling—can be repurposed to guide an active learning strategy for a machine-learning potential . By developing a sensitivity-guided acquisition function, you will see how to intelligently focus computational resources on physically challenging regions of configuration space, a key technique in modern materials modeling.",
            "id": "3760540",
            "problem": "Consider a one-dimensional nuclear coordinate $x$ describing a local distortion mode in a representative high-entropy alloy cluster. Assume the electrons are described by a two-state diabatic Hamiltonian that depends linearly on $x$, given by the matrix\n$$\n\\hat{H}(x)=\n\\begin{pmatrix}\n\\alpha x & \\Delta \\\\\n\\Delta & -\\alpha x\n\\end{pmatrix},\n$$\nwhere $\\alpha$ and $\\Delta$ are positive real parameters. Starting from the time-independent Schrödinger equation and the Born-Oppenheimer approximation (which separates fast electronic and slow nuclear degrees of freedom), you must obtain the adiabatic ground-state energy $E_{-}(x)$, the first and second derivatives $\\frac{d E_{-}}{dx}$ and $\\frac{d^2 E_{-}}{dx^2}$, and the adiabatic derivative coupling between the ground and excited states as a function of $x$.\n\nDefine a sensitivity-guided acquisition score for active learning that prioritizes nuclear configurations where the Born-Oppenheimer approximation is most sensitive. Let the sensitivity score be\n$$\nS(x)=w_c\\, \\mathcal{N}\\!\\left(\\left|\\frac{d^2 E_{-}}{dx^2}\\right|\\right) + w_d\\, \\mathcal{N}\\!\\left(\\left|\\left\\langle \\psi_{-}(x)\\middle|\\frac{d}{dx}\\psi_{+}(x)\\right\\rangle\\right|\\right),\n$$\nwhere $w_c$ and $w_d$ are nonnegative weights satisfying $w_c+w_d=1$, $\\psi_{\\pm}(x)$ are the adiabatic electronic eigenstates, and $\\mathcal{N}(\\cdot)$ denotes min-max normalization on a finite grid $x\\in[-L,L]$:\n$$\n\\mathcal{N}(f(x))=\\frac{f(x)-\\min_{x\\in[-L,L]} f(x)}{\\max_{x\\in[-L,L]} f(x)-\\min_{x\\in[-L,L]} f(x)}.\n$$\nConstruct an active-learning loop for a machine-learning potential that models $E_{-}(x)$ using polynomial regression on a training set of points. Begin with an initial training set comprising $N_0$ points uniformly spaced on a grid of $N_g$ points in the interval $[-L,L]$. Fit a polynomial of degree $p$ by least squares to approximate $E_{-}(x)$ from the training data. Define an uncertainty proxy at a grid point $x$ as the distance to the nearest training point in $x$-space, and define the acquisition function as\n$$\nA(x)=S(x)\\times U(x),\n$$\nwhere $U(x)$ is the uncertainty proxy. Select the top $M$ grid points (excluding already selected training points) that maximize $A(x)$, augment the training set, refit the polynomial model, and evaluate the mean absolute error over the entire grid before and after augmentation.\n\nYour program must:\n- Derive $E_{-}(x)$, its derivatives, and the adiabatic derivative coupling from the diabatic Hamiltonian using diagonalization and appropriate definitions that arise from the Born-Oppenheimer approximation.\n- Implement the sensitivity score $S(x)$ with $w_c=w_d=\\frac{1}{2}$ and min-max normalization over the grid.\n- Use the acquisition function $A(x)$ to select new training points and retrain the polynomial model.\n- Compute the mean absolute error (MAE) over the grid before and after augmentation for each test case.\n\nUse the following test suite, which specifies $(\\alpha,\\Delta,L,N_0,N_g,M,p)$:\n- Test case $1$: $(\\alpha,\\Delta,L,N_0,N_g,M,p)=(1.0,0.05,3.0,8,801,12,5)$.\n- Test case $2$: $(\\alpha,\\Delta,L,N_0,N_g,M,p)=(1.0,1.0,3.0,8,801,12,5)$.\n- Test case $3$: $(\\alpha,\\Delta,L,N_0,N_g,M,p)=(2.0,0.2,4.0,6,1001,20,5)$.\n\nNo physical units are required; treat all quantities as dimensionless. Angles, if introduced internally, must be handled in radians. For each test case, output the pair of floats $[\\mathrm{MAE}_{\\text{before}},\\mathrm{MAE}_{\\text{after}}]$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each element itself being a list of two floats for a test case, for example, $[[a,b],[c,d],[e,f]]$.",
            "solution": "The problem requires the development and implementation of an active learning procedure for modeling a one-dimensional adiabatic potential energy surface. The process involves several interconnected steps: first, the analytical derivation of the ground-state properties from a given two-state diabatic Hamiltonian; second, the formulation of a physics-informed sensitivity score; and third, the implementation of an active learning loop that uses this score to intelligently augment a training set and improve a polynomial machine-learning model.\n\n### 1. Analytical Derivation of Adiabatic Quantities\n\nThe system is described by a $2 \\times 2$ diabatic Hamiltonian matrix that depends linearly on a nuclear coordinate $x$:\n$$\n\\hat{H}(x) = \\begin{pmatrix} \\alpha x & \\Delta \\\\ \\Delta & -\\alpha x \\end{pmatrix}\n$$\nwhere $\\alpha$ and $\\Delta$ are positive real parameters. The adiabatic potential energy surfaces, $E_{\\pm}(x)$, are the eigenvalues of this matrix. They are obtained by solving the characteristic equation $\\det(\\hat{H}(x) - E\\hat{I}) = 0$.\n$$\n(\\alpha x - E)(-\\alpha x - E) - \\Delta^2 = 0 \\\\\nE^2 - (\\alpha x)^2 - \\Delta^2 = 0 \\\\\nE^2 = (\\alpha x)^2 + \\Delta^2\n$$\nThis gives two eigenvalues, corresponding to the excited $(+)$ and ground $(-)$ adiabatic states:\n$$\nE_{\\pm}(x) = \\pm\\sqrt{(\\alpha x)^2 + \\Delta^2}\n$$\nThe problem focuses on the ground-state energy surface:\n$$\nE_{-}(x) = -\\sqrt{(\\alpha x)^2 + \\Delta^2}\n$$\nThe first and second derivatives of $E_{-}(x)$ with respect to the nuclear coordinate $x$ are required for the sensitivity score. Using the chain rule:\n$$\n\\frac{dE_{-}}{dx} = -\\frac{1}{2\\sqrt{(\\alpha x)^2 + \\Delta^2}} \\cdot (2\\alpha^2 x) = -\\frac{\\alpha^2 x}{\\sqrt{(\\alpha x)^2 + \\Delta^2}}\n$$\nDifferentiating a second time using the quotient rule:\n$$\n\\frac{d^2E_{-}}{dx^2} = -\\alpha^2 \\frac{\\sqrt{(\\alpha x)^2 + \\Delta^2} - x \\left( \\frac{\\alpha^2 x}{\\sqrt{(\\alpha x)^2 + \\Delta^2}} \\right)}{(\\alpha x)^2 + \\Delta^2} \\\\\n= -\\alpha^2 \\frac{(\\alpha x)^2 + \\Delta^2 - \\alpha^2 x^2}{((\\alpha x)^2 + \\Delta^2)^{3/2}} \\\\\n= -\\frac{\\alpha^2 \\Delta^2}{((\\alpha x)^2 + \\Delta^2)^{3/2}}\n$$\nThe final required quantity is the adiabatic derivative coupling, $d_{-,+}(x) = \\langle \\psi_{-}(x) | \\frac{d}{dx} \\psi_{+}(x) \\rangle$, where $\\psi_{\\pm}(x)$ are the corresponding normalized eigenvectors (adiabatic states). This term quantifies the mixing between adiabatic states induced by nuclear motion and is a key indicator of the breakdown of the Born-Oppenheimer approximation. It can be calculated using the off-diagonal Hellmann-Feynman theorem:\n$$\nd_{-,+}(x) = \\frac{\\langle \\psi_{-}(x) | \\frac{d\\hat{H}}{dx} | \\psi_{+}(x) \\rangle}{E_{+}(x) - E_{-}(x)}\n$$\nFirst, we find the derivative of the Hamiltonian:\n$$\n\\frac{d\\hat{H}}{dx} = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & -\\alpha \\end{pmatrix} = \\alpha\\sigma_z\n$$\nThe energy denominator is $E_{+} - E_{-} = 2\\sqrt{(\\alpha x)^2 + \\Delta^2}$. The matrix element in the numerator can be found most easily by expressing the eigenvectors in terms of a mixing angle $\\theta(x)$ where $\\tan(2\\theta) = \\Delta/(\\alpha x)$. The eigenvectors are $\\psi_{+} = (\\cos\\theta, \\sin\\theta)^T$ and $\\psi_{-} = (-\\sin\\theta, \\cos\\theta)^T$. The matrix element becomes:\n$$\n\\langle \\psi_{-}(x) | \\alpha\\sigma_z | \\psi_{+}(x) \\rangle = \\alpha \\begin{pmatrix} -\\sin\\theta & \\cos\\theta \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix} = \\alpha(-\\sin\\theta\\cos\\theta - \\cos\\theta\\sin\\theta) = -\\alpha\\sin(2\\theta)\n$$\nSince $\\tan(2\\theta) = \\Delta/(\\alpha x)$, we have $\\sin(2\\theta) = \\Delta / \\sqrt{(\\alpha x)^2 + \\Delta^2}$. Thus, the matrix element is $-\\alpha\\Delta / \\sqrt{(\\alpha x)^2 + \\Delta^2}$.\nSubstituting back into the formula for the coupling:\n$$\nd_{-,+}(x) = \\frac{-\\alpha\\Delta / \\sqrt{(\\alpha x)^2 + \\Delta^2}}{2\\sqrt{(\\alpha x)^2 + \\Delta^2}} = -\\frac{\\alpha\\Delta}{2((\\alpha x)^2 + \\Delta^2)}\n$$\n\n### 2. Active Learning Framework\n\nThe goal of the active learning loop is to efficiently construct an accurate polynomial model for $E_{-}(x)$ by adding training points in a targeted manner. The acquisition function $A(x) = S(x) \\times U(x)$ directs this selection process.\n\n**Sensitivity Score $S(x)$**: This score identifies regions where the physics is most challenging to model. It is a weighted sum of two normalized terms:\n$$\nS(x) = w_c\\, \\mathcal{N}\\!\\left(\\left|\\frac{d^2 E_{-}}{dx^2}\\right|\\right) + w_d\\, \\mathcal{N}\\!\\left(\\left|d_{-,+}(x)\\right|\\right)\n$$\nWith $w_c = w_d = 0.5$, this becomes:\n$$\nS(x) = \\frac{1}{2} \\mathcal{N}\\left(\\frac{\\alpha^2 \\Delta^2}{((\\alpha x)^2 + \\Delta^2)^{3/2}}\\right) + \\frac{1}{2} \\mathcal{N}\\left(\\frac{\\alpha\\Delta}{2((\\alpha x)^2 + \\Delta^2)}\\right)\n$$\nBoth terms are largest near $x=0$, where the energy gap $E_{+} - E_{-}$ is minimal (an avoided crossing), indicating high curvature and strong non-adiabatic effects. Normalization $\\mathcal{N}(\\cdot)$ scales each component to the range $[0, 1]$ across the grid $[-L,L]$, ensuring they contribute equally to the score.\n\n**Uncertainty Proxy $U(x)$**: This term promotes exploration. It is defined as the distance from a grid point $x$ to the nearest point in the current training set. A large $U(x)$ signifies a region of configuration space that is poorly represented by the current data, where model error is likely to be high.\n\n**Acquisition Function $A(x)$**: By multiplying sensitivity and uncertainty, $A(x)$ favors points that are both physically significant (high $S(x)$) and poorly sampled (high $U(x)$). This hybrid strategy is more efficient than random sampling or sampling based on uncertainty alone.\n\n### 3. Computational Procedure\n\nThe algorithm proceeds as follows for each test case:\n1.  **Initialization**: A uniform grid of $N_g$ points is created in the interval $[-L, L]$. An initial training set is formed by selecting $N_0$ of these points with uniform spacing.\n2.  **Ground Truth**: The exact analytical expressions for $E_{-}(x)$ and the components for $S(x)$ are evaluated for all points on the grid.\n3.  **Initial Model Evaluation**: A polynomial of degree $p$ is fitted to the initial training data $(x_i, E_{-}(x_i))$ using least squares. The mean absolute error (MAE) of this model, $\\mathrm{MAE}_{\\text{before}}$, is calculated over the entire grid.\n4.  **Acquisition**: The sensitivity score $S(x)$ and uncertainty proxy $U(x)$ are computed for all grid points. The acquisition function $A(x)$ is formed.\n5.  **Augmentation**: The $M$ grid points not already in the training set that have the highest acquisition scores are identified. These points are added to the training set.\n6.  **Retrained Model Evaluation**: A new polynomial of degree $p$ is fitted to the augmented training set. The MAE of this new model, $\\mathrm{MAE}_{\\text{after}}$, is calculated over the entire grid.\n7.  **Output**: The pair $[\\mathrm{MAE}_{\\text{before}}, \\mathrm{MAE}_{\\text{after}}]$ is recorded. This process demonstrates the improvement in model accuracy gained from a single step of targeted data acquisition.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the active learning problem for a series of test cases.\n\n    This function iterates through predefined test cases, each specifying parameters\n    for a 2-level quantum system and an active learning loop. For each case, it:\n    1.  Calculates the ground truth energy surface and sensitivity metrics.\n    2.  Builds an initial polynomial model on a sparse grid and calculates its error (MAE_before).\n    3.  Uses a physics-informed acquisition function to select new training points.\n    4.  Retrains the model with the augmented data and calculates the new error (MAE_after).\n    5.  Collects and prints the results in the specified format.\n    \"\"\"\n    # Test cases: (alpha, Delta, L, N_0, N_g, M, p)\n    test_cases = [\n        (1.0, 0.05, 3.0, 8, 801, 12, 5),\n        (1.0, 1.0, 3.0, 8, 801, 12, 5),\n        (2.0, 0.2, 4.0, 6, 1001, 20, 5),\n    ]\n\n    results = []\n\n    def min_max_normalize(arr: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Performs min-max normalization on a numpy array.\n        Scales the array values to the range [0, 1].\n        If all values are the same, returns an array of zeros.\n        \"\"\"\n        min_val = np.min(arr)\n        max_val = np.max(arr)\n        if max_val == min_val:\n            return np.zeros_like(arr)\n        return (arr - min_val) / (max_val - min_val)\n\n    for case in test_cases:\n        alpha, Delta, L, N_0, N_g, M, p = case\n\n        # 1. Grid and Ground Truth Calculation\n        x_grid = np.linspace(-L, L, N_g)\n        \n        # Ground state energy E_-(x)\n        common_term = (alpha * x_grid)**2 + Delta**2\n        E_true = -np.sqrt(common_term)\n\n        # 2. Sensitivity Score S(x)\n        # Component from |d^2E/dx^2|\n        f_c = (alpha**2 * Delta**2) / (common_term**1.5)\n        \n        # Component from |<psi_-|d/dx|psi_+>|\n        f_d = (alpha * Delta) / (2 * common_term)\n        \n        w_c, w_d = 0.5, 0.5\n        S_score = w_c * min_max_normalize(f_c) + w_d * min_max_normalize(f_d)\n\n        # 3. Initial Training Set and Model\n        initial_train_indices = np.linspace(0, N_g - 1, N_0, dtype=int)\n        x_train_before = x_grid[initial_train_indices]\n        y_train_before = E_true[initial_train_indices]\n\n        # Fit and evaluate model BEFORE augmentation\n        coeffs_before = np.polyfit(x_train_before, y_train_before, p)\n        E_pred_before = np.polyval(coeffs_before, x_grid)\n        mae_before = np.mean(np.abs(E_pred_before - E_true))\n\n        # 4. Acquisition of New Points\n        # Uncertainty proxy U(x): distance to nearest training point\n        abs_diffs = np.abs(x_grid[:, np.newaxis] - x_train_before)\n        U_proxy = np.min(abs_diffs, axis=1)\n\n        # Acquisition function A(x) = S(x) * U(x)\n        A_func = S_score * U_proxy\n        \n        # Exclude already selected points from being chosen again\n        A_func[initial_train_indices] = -1.0 \n        \n        # Select top M points with the highest acquisition score\n        new_indices = np.argsort(A_func)[-M:]\n\n        # 5. Augmented Training Set and Retrained Model\n        augmented_train_indices = np.union1d(initial_train_indices, new_indices)\n        x_train_after = x_grid[augmented_train_indices]\n        y_train_after = E_true[augmented_train_indices]\n\n        # Fit and evaluate model AFTER augmentation\n        coeffs_after = np.polyfit(x_train_after, y_train_after, p)\n        E_pred_after = np.polyval(coeffs_after, x_grid)\n        mae_after = np.mean(np.abs(E_pred_after - E_true))\n\n        results.append([mae_before, mae_after])\n\n    # Final print statement in the exact required format.\n    print(results)\n\nsolve()\n```"
        }
    ]
}