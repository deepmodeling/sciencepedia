{
    "hands_on_practices": [
        {
            "introduction": "This problem explores a foundational concept in explicit dynamics simulations: the interplay between the mass matrix formulation and numerical stability. In the finite element method, seemingly minor choices in the numerical scheme can have profound effects on the simulation's efficiency. This exercise provides a hands-on opportunity to quantify exactly how the common technique of \"mass lumping\" alters the spectral properties of the system and, consequently, the maximum stable time step, offering a clear view into the trade-offs between computational cost and accuracy. ",
            "id": "3855310",
            "problem": "Consider explicit time integration of the semi-discrete elastodynamic equations of an isotropic homogeneous elastic solid using the Finite Element Method (FEM) with linear tetrahedral elements. Let the solid have density $\\rho$ and Lamé parameters $\\lambda$ and $\\mu$. To capture the stability-limiting dilatational response, model the fastest mode by the scalar wave equation surrogate $\\,\\rho\\,\\ddot{u} - \\kappa\\,\\nabla^{2}u = 0\\,$ with $\\kappa = \\rho c^{2}$ and $c = \\sqrt{(\\lambda + 2\\mu)/\\rho}$ equal to the compressional-wave speed. After standard Galerkin discretization on a single regular tetrahedron of edge length $s$, the semi-discrete system takes the form $\\,\\mathbf{M}\\,\\ddot{\\mathbf{u}} + \\mathbf{K}\\,\\mathbf{u} = \\mathbf{0}\\,$, where $\\,\\mathbf{M}\\,$ and $\\,\\mathbf{K}\\,$ are, respectively, the element mass and stiffness matrices associated with the four scalar nodal degrees of freedom and $\\,\\mathbf{u}\\,$ is the vector of nodal values of $u$. Let $\\,\\Delta t\\,$ be the time step of the explicit central difference scheme applied to this system.\n\nStarting from fundamental principles—namely the semi-discrete equation of motion, the definition of the stiffness matrix $\\,\\mathbf{K}\\,$ via the gradient of linear shape functions on a tetrahedron, and the consistent versus row-sum lumped definitions of the mass matrix $\\,\\mathbf{M}\\,$—derive how mass lumping alters the spectrum of the operator $\\,\\mathbf{M}^{-1}\\mathbf{K}\\,$ and thus the maximum stable time step $\\,\\Delta t\\,$. Quantify this effect for a single regular tetrahedral element by computing the exact ratio $\\,\\Delta t_{\\mathrm{lump}}/\\Delta t_{\\mathrm{cons}}\\,$, where $\\,\\Delta t_{\\mathrm{lump}}\\,$ and $\\,\\Delta t_{\\mathrm{cons}}\\,$ denote the central-difference stability limits under, respectively, row-sum lumped and consistent mass matrices.\n\nProvide your final answer as a single exact value with no units. No rounding is required.",
            "solution": "The user wants to find the ratio of maximum stable time steps for explicit central difference integration of the Finite Element Method (FEM) semi-discretization of a scalar wave equation. The comparison is between using a row-sum lumped mass matrix ($\\mathbf{M}_{\\mathrm{lump}}$) and a consistent mass matrix ($\\mathbf{M}_{\\mathrm{cons}}$) for a single regular linear tetrahedral element.\n\n### Step 1: Problem Validation\n\n**1.1. Extraction of Givens**\n- **Physical System**: Isotropic homogeneous elastic solid, with stability analysis performed on a surrogate scalar wave equation $\\rho\\,\\ddot{u} - \\kappa\\,\\nabla^{2}u = 0$.\n- **Material & Model Parameters**: Density $\\rho$, wave modulus $\\kappa = \\rho c^{2}$ where $c = \\sqrt{(\\lambda + 2\\mu)/\\rho}$ is the compressional-wave speed.\n- **Discretization Method**: Galerkin Finite Element Method.\n- **Element Type**: A single regular tetrahedron with edge length $s$. Linear shape functions are used, leading to $4$ nodal degrees of freedom.\n- **Semi-Discrete Equation**: $\\mathbf{M}\\,\\ddot{\\mathbf{u}} + \\mathbf{K}\\,\\mathbf{u} = \\mathbf{0}$, where $\\mathbf{u}$ is the vector of nodal values of $u$.\n- **Mass Matrices**: Two cases are considered: the consistent mass matrix $\\mathbf{M}_{\\mathrm{cons}}$ and the row-sum lumped mass matrix $\\mathbf{M}_{\\mathrm{lump}}$.\n- **Time Integration**: Explicit central difference scheme with time step $\\Delta t$.\n- **Objective**: Derive the effect of mass lumping on the spectrum of $\\mathbf{M}^{-1}\\mathbf{K}$ and compute the exact ratio of the stability limits, $\\Delta t_{\\mathrm{lump}}/\\Delta t_{\\mathrm{cons}}$.\n\n**1.2. Validation against Criteria**\n- **Scientific Grounding**: The problem is firmly rooted in the standard theory of computational solid mechanics and finite element analysis. The use of a scalar wave equation as a surrogate for elastodynamic stability, the concepts of consistent and lumped mass matrices, and the stability analysis of the central difference scheme are all established principles.\n- **Well-Posedness**: The problem is well-posed. It specifies the physical model, the element geometry (regular tetrahedron), the element type (linear), and the analysis to be performed. This information is sufficient to uniquely determine the element matrices and their spectral properties, leading to a single, computable ratio.\n- **Objectivity**: The problem is stated in precise, objective mathematical and engineering terms, free from any subjectivity or ambiguity.\n- **Other Flaws**: The problem is self-contained, plausible, non-trivial, and verifiable through standard mathematical procedures. It does not violate any of the invalidity criteria.\n\n**1.3. Verdict**\nThe problem is valid. A full solution will be provided.\n\n### Step 2: Derivation of the Solution\n\nThe stability of the explicit central difference scheme for the system $\\mathbf{M}\\,\\ddot{\\mathbf{u}} + \\mathbf{K}\\,\\mathbf{u} = \\mathbf{0}$ is governed by the Courant-Friedrichs-Lewy (CFL) condition, which dictates that the time step $\\Delta t$ must not exceed a critical value $\\Delta t_{\\mathrm{max}}$. This limit is related to the highest natural frequency $\\omega_{\\max}$ of the semi-discrete system by:\n$$\n\\Delta t \\le \\Delta t_{\\mathrm{max}} = \\frac{2}{\\omega_{\\max}}\n$$\nThe natural frequencies $\\omega$ are the square roots of the eigenvalues $\\lambda_{\\mathrm{eig}}$ of the generalized eigenvalue problem $\\mathbf{K}\\mathbf{v} = \\omega^{2}\\mathbf{M}\\mathbf{v}$. This is equivalent to finding the eigenvalues of the matrix $\\mathbf{D} = \\mathbf{M}^{-1}\\mathbf{K}$. Thus, $\\omega_{\\max} = \\sqrt{\\lambda_{\\max}(\\mathbf{M}^{-1}\\mathbf{K})}$, and the stability limit is:\n$$\n\\Delta t_{\\mathrm{max}} = \\frac{2}{\\sqrt{\\lambda_{\\max}(\\mathbf{M}^{-1}\\mathbf{K})}}\n$$\nWe seek the ratio $\\frac{\\Delta t_{\\mathrm{lump}}}{\\Delta t_{\\mathrm{cons}}}$, which can be expressed in terms of the maximum eigenvalues as:\n$$\n\\frac{\\Delta t_{\\mathrm{lump}}}{\\Delta t_{\\mathrm{cons}}} = \\frac{2/\\sqrt{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{lump}}^{-1}\\mathbf{K})}}{2/\\sqrt{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{cons}}^{-1}\\mathbf{K})}} = \\sqrt{\\frac{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{cons}}^{-1}\\mathbf{K})}{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{lump}}^{-1}\\mathbf{K})}}\n$$\nTo evaluate this ratio, we must first construct the element stiffness and mass matrices for a regular linear tetrahedron.\n\n**2.1. Element Matrices for a Regular Tetrahedron**\n\nA linear tetrahedron has $4$ nodes. Let the shape functions be $N_i(\\mathbf{x})$ for $i=1, 2, 3, 4$. The element matrices are defined as:\n$$\nK_{ij} = \\int_{V_e} \\kappa (\\nabla N_i \\cdot \\nabla N_j) \\, dV\n$$\n$$\n(M_{\\mathrm{cons}})_{ij} = \\int_{V_e} \\rho N_i N_j \\, dV\n$$\nwhere $V_e$ is the volume of the element. For a regular tetrahedron of edge length $s$, the volume is $V_e = \\frac{s^3}{6\\sqrt{2}}$.\n\nFor a regular tetrahedron, the geometry is fully symmetric. This symmetry is reflected in the structure of the element matrices. Both $\\mathbf{K}$ and $\\mathbf{M}_{\\mathrm{cons}}$ will be of the form $a\\mathbf{I} + b\\mathbf{J}$, where $\\mathbf{I}$ is the $4 \\times 4$ identity matrix and $\\mathbf{J}$ is the $4 \\times 4$ matrix of all ones.\n\n**Stiffness Matrix $\\mathbf{K}$**:\nFor a linear element, the gradients $\\nabla N_i$ are constant within the element. Due to the symmetry of a regular tetrahedron, the dot products of these gradients have a specific structure: $|\\nabla N_i|^2$ has the same value for all $i$, let's call it $\\alpha_g$, and $\\nabla N_i \\cdot \\nabla N_j$ for $i \\ne j$ has the same value for all pairs, let's call it $\\beta_g$. From the property that $\\sum_{i=1}^4 \\nabla N_i = \\mathbf{0}$, we have $\\nabla N_i \\cdot (\\sum_{j=1}^4 \\nabla N_j) = 0$, which leads to $\\alpha_g + 3\\beta_g = 0$, or $\\beta_g = -\\alpha_g/3$.\nIt can be shown that for a regular tetrahedron of edge length $s$, $\\alpha_g = \\frac{3}{2s^2}$. Thus, $\\beta_g = -\\frac{1}{2s^2}$.\nThe stiffness matrix entries are $K_{ij} = \\kappa V_e (\\nabla N_i \\cdot \\nabla N_j)$.\n$$\n\\mathbf{K} = \\kappa V_e \\begin{pmatrix} \\alpha_g & \\beta_g & \\beta_g & \\beta_g \\\\ \\beta_g & \\alpha_g & \\beta_g & \\beta_g \\\\ \\beta_g & \\beta_g & \\alpha_g & \\beta_g \\\\ \\beta_g & \\beta_g & \\beta_g & \\alpha_g \\end{pmatrix} = \\kappa \\frac{s^3}{6\\sqrt{2}} \\frac{1}{2s^2} \\begin{pmatrix} 3 & -1 & -1 & -1 \\\\ -1 & 3 & -1 & -1 \\\\ -1 & -1 & 3 & -1 \\\\ -1 & -1 & -1 & 3 \\end{pmatrix} = \\frac{\\kappa s}{12\\sqrt{2}} \\begin{pmatrix} 3 & -1 & -1 & -1 \\\\ -1 & 3 & -1 & -1 \\\\ -1 & -1 & 3 & -1 \\\\ -1 & -1 & -1 & 3 \\end{pmatrix}\n$$\nThis matrix can be compactly written as $\\mathbf{K} = \\frac{\\kappa s}{12\\sqrt{2}}(4\\mathbf{I} - \\mathbf{J})$.\n\n**Consistent Mass Matrix $\\mathbf{M}_{\\mathrm{cons}}$**:\nThe standard formula for the consistent mass matrix of a linear tetrahedron, derived from integrating the products of barycentric shape functions, is:\n$$\n\\mathbf{M}_{\\mathrm{cons}} = \\frac{\\rho V_e}{20} \\begin{pmatrix} 2 & 1 & 1 & 1 \\\\ 1 & 2 & 1 & 1 \\\\ 1 & 1 & 2 & 1 \\\\ 1 & 1 & 1 & 2 \\end{pmatrix}\n$$\nSubstituting $V_e = \\frac{s^3}{6\\sqrt{2}}$, we get:\n$$\n\\mathbf{M}_{\\mathrm{cons}} = \\frac{\\rho s^3}{120\\sqrt{2}} \\begin{pmatrix} 2 & 1 & 1 & 1 \\\\ 1 & 2 & 1 & 1 \\\\ 1 & 1 & 2 & 1 \\\\ 1 & 1 & 1 & 2 \\end{pmatrix} = \\frac{\\rho s^3}{120\\sqrt{2}}(\\mathbf{I} + \\mathbf{J})\n$$\n\n**Lumped Mass Matrix $\\mathbf{M}_{\\mathrm{lump}}$**:\nThe row-sum lumped mass matrix is a diagonal matrix where each diagonal entry is the sum of the entries in the corresponding row of the consistent mass matrix.\nSumming any row of $\\mathbf{M}_{\\mathrm{cons}}$ gives: $\\frac{\\rho s^3}{120\\sqrt{2}} (2 + 1 + 1 + 1) = \\frac{5\\rho s^3}{120\\sqrt{2}} = \\frac{\\rho s^3}{24\\sqrt{2}}$.\nThus, the lumped mass matrix is:\n$$\n\\mathbf{M}_{\\mathrm{lump}} = \\frac{\\rho s^3}{24\\sqrt{2}} \\mathbf{I}\n$$\n\n**2.2. Spectral Analysis**\n\nThe matrices $\\mathbf{K}$ and $\\mathbf{M}_{\\mathrm{cons}}$ are both of the form $a\\mathbf{I} + b\\mathbf{J}$. Such matrices share a common set of eigenvectors.\nThe matrix $\\mathbf{J}$ (matrix of all ones) has two distinct eigenvalues:\n- $\\lambda_1 = 4$, with eigenvector $\\mathbf{v}_1 = (1, 1, 1, 1)^T$. This corresponds to the uniform (rigid-body translation) mode.\n- $\\lambda_2 = 0$, with a $3$-dimensional eigenspace of vectors orthogonal to $\\mathbf{v}_1$. These correspond to higher-order deformation modes.\n\nThe eigenvalues of a matrix $a\\mathbf{I} + b\\mathbf{J}$ are $a+4b$ (once) and $a$ (thrice).\nLet's apply this to our matrix eigenvalue problems.\n\n**Lumped Mass Case**:\nWe need the eigenvalues of $\\mathbf{D}_{\\mathrm{lump}} = \\mathbf{M}_{\\mathrm{lump}}^{-1}\\mathbf{K}$.\n$$\n\\mathbf{D}_{\\mathrm{lump}} = \\left(\\frac{\\rho s^3}{24\\sqrt{2}}\\mathbf{I}\\right)^{-1} \\left(\\frac{\\kappa s}{12\\sqrt{2}}(4\\mathbf{I} - \\mathbf{J})\\right) = \\frac{24\\sqrt{2}}{\\rho s^3} \\frac{\\kappa s}{12\\sqrt{2}} (4\\mathbf{I} - \\mathbf{J}) = \\frac{2\\kappa}{\\rho s^2}(4\\mathbf{I} - \\mathbf{J})\n$$\nThe eigenvalues of $4\\mathbf{I}-\\mathbf{J}$ are $4-4=0$ and $4-0=4$.\nThe eigenvalues of $\\mathbf{D}_{\\mathrm{lump}}$ are $\\frac{2\\kappa}{\\rho s^2} \\times \\{0, 4, 4, 4\\}$.\nThe maximum eigenvalue is therefore:\n$$\n\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{lump}}^{-1}\\mathbf{K}) = \\frac{2\\kappa}{\\rho s^2} \\times 4 = \\frac{8\\kappa}{\\rho s^2}\n$$\n\n**Consistent Mass Case**:\nWe need the eigenvalues $\\lambda_{\\mathrm{eig}}$ of the generalized eigenvalue problem $\\mathbf{K}\\mathbf{v} = \\lambda_{\\mathrm{eig}} \\mathbf{M}_{\\mathrm{cons}}\\mathbf{v}$.\n$$\n\\frac{\\kappa s}{12\\sqrt{2}}(4\\mathbf{I} - \\mathbf{J})\\mathbf{v} = \\lambda_{\\mathrm{eig}} \\frac{\\rho s^3}{120\\sqrt{2}}(\\mathbf{I} + \\mathbf{J})\\mathbf{v}\n$$\nMultiplying by $\\frac{120\\sqrt{2}}{\\rho s^3}$ simplifies the equation to:\n$$\n\\frac{10\\kappa}{\\rho s^2}(4\\mathbf{I} - \\mathbf{J})\\mathbf{v} = \\lambda_{\\mathrm{eig}} (\\mathbf{I} + \\mathbf{J})\\mathbf{v}\n$$\nWe test the common eigenvectors of $\\mathbf{K}$ and $\\mathbf{M}_{\\mathrm{cons}}$:\n1.  For the uniform mode $\\mathbf{v}_1=(1,1,1,1)^T$:\n    $$\n    \\frac{10\\kappa}{\\rho s^2}(4\\mathbf{v}_1 - 4\\mathbf{v}_1) = \\lambda_{\\mathrm{eig}} (\\mathbf{v}_1 + 4\\mathbf{v}_1) \\implies \\mathbf{0} = \\lambda_{\\mathrm{eig}}(5\\mathbf{v}_1) \\implies \\lambda_{\\mathrm{eig}} = 0\n    $$\n2.  For a higher-order mode $\\mathbf{v}_k$ (orthogonal to $\\mathbf{v}_1$, so $\\mathbf{J}\\mathbf{v}_k=\\mathbf{0}$):\n    $$\n    \\frac{10\\kappa}{\\rho s^2}(4\\mathbf{v}_k - \\mathbf{0}) = \\lambda_{\\mathrm{eig}} (\\mathbf{v}_k + \\mathbf{0}) \\implies \\frac{40\\kappa}{\\rho s^2}\\mathbf{v}_k = \\lambda_{\\mathrm{eig}}\\mathbf{v}_k\n    $$\n    This gives $\\lambda_{\\mathrm{eig}} = \\frac{40\\kappa}{\\rho s^2}$. This is a triple eigenvalue.\n\nThe maximum eigenvalue for the consistent mass case is:\n$$\n\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{cons}}^{-1}\\mathbf{K}) = \\frac{40\\kappa}{\\rho s^2}\n$$\n\n**2.3. Calculation of the Time Step Ratio**\n\nThe ratio of the maximum allowable time steps is:\n$$\n\\frac{\\Delta t_{\\mathrm{lump}}}{\\Delta t_{\\mathrm{cons}}} = \\sqrt{\\frac{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{cons}}^{-1}\\mathbf{K})}{\\lambda_{\\max}(\\mathbf{M}_{\\mathrm{lump}}^{-1}\\mathbf{K})}} = \\sqrt{\\frac{40\\kappa / (\\rho s^2)}{8\\kappa / (\\rho s^2)}} = \\sqrt{\\frac{40}{8}} = \\sqrt{5}\n$$\nThis result shows that mass lumping increases the maximum stable time step by a factor of $\\sqrt{5}$ for a regular linear tetrahedron. This is because lumping effectively reduces the spectral radius of the operator $\\mathbf{M}^{-1}\\mathbf{K}$, making the system appear \"softer\" at its highest frequencies and thus less restrictive on the time step.",
            "answer": "$$\\boxed{\\sqrt{5}}$$"
        },
        {
            "introduction": "Real-world physical systems often exhibit dynamics that vary dramatically in time, from long periods of relative calm to brief, violent events. Using a single, fixed time step for such simulations can be highly inefficient, as it must be small enough for the most challenging events. This practice guides you through the design and analytical justification of an \"event-aware\" adaptive time-stepping rule that responds to the local physics, automatically shortening the step in challenging regions of the potential energy surface and lengthening it elsewhere to maximize efficiency without sacrificing accuracy. ",
            "id": "3855317",
            "problem": "You are tasked with designing and implementing an event-aware adaptive time step selection rule for deterministic Molecular Dynamics (MD) on a Potential Energy Surface (PES). The objective is to reduce the time step $\\,\\Delta t\\,$ near rapid transitions (for example, crossing a barrier between metastable basins) by monitoring local indicators such as the force magnitude $\\,\\|\\nabla V\\|\\,$ and the acceleration magnitude $\\,\\|\\mathbf{a}\\|\\,$, and to justify analytically the thresholds used in the rule. The rule must be derived from first principles starting from Newton's Second Law $\\,m\\,\\ddot{\\mathbf{x}} = -\\nabla V(\\mathbf{x})\\,$ and standard linearization arguments for local stiffness and stability. The final time step selection must combine constraints ensuring numerical stability and controlled local change over a single step.\n\nYour implementation must accept, for each test case, a potential $\\,V\\,$, its gradient $\\,\\nabla V\\,$ and its Hessian $\\,\\nabla^2 V\\,$ evaluated at the current state $\\,\\mathbf{x}\\,$, a current velocity $\\,\\mathbf{v}\\,$, a mass $\\,m\\,$, and user-chosen constants that reflect admissible fractional changes per step. The selection rule must combine at least the following three conceptually distinct constraints:\n\n- A local linear stability bound derived by approximating the PES near $\\,\\mathbf{x}\\,$ as quadratic and ensuring stability of an explicit second-order integrator.\n- A bound that limits the fractional change in velocity per step through the acceleration magnitude, expressed as a fraction of $\\,\\|\\mathbf{v}\\|\\,$.\n- A bound that limits the fractional change in force per step through the Hessian norm and the step-induced displacement $\\,\\|\\mathbf{v}\\|\\,\\Delta t\\,$, expressed as a fraction of $\\,\\|\\nabla V(\\mathbf{x})\\|\\,$.\n\nYou must justify these constraints analytically and operationalize them into a computable rule that selects $\\,\\Delta t\\,$ as the minimum among the applicable bounds and a given maximum time step $\\,\\Delta t_{\\max}\\,$. Your program must compute and output the selected $\\,\\Delta t\\,$ in seconds for each test case, as described below. If some denominator is zero due to $\\,\\mathbf{v}=\\mathbf{0}\\,$ or $\\,\\nabla V(\\mathbf{x})=\\mathbf{0}\\,$ at a stationary point, your rule must remain well-defined and numerically robust by using a small positive regularization constant.\n\nAll physical quantities must be handled and reported in the International System of Units (SI). In particular, distances must be in meters ($\\,\\mathrm{m}\\,$), velocities in meters per second ($\\,\\mathrm{m/s}\\,$), mass in kilograms ($\\,\\mathrm{kg}\\,$), energy in joules ($\\,\\mathrm{J}\\,$), and time in seconds ($\\,\\mathrm{s}\\,$). The final outputs must be expressed in seconds ($\\,\\mathrm{s}\\,$) as floating-point numbers.\n\nYou must evaluate your rule on the following test suite of $\\,5\\,$ cases that probe distinct regimes:\n\n- Case $\\,1\\,$ (one-dimensional double-well, approaching the barrier from the left basin): Let $\\,V(x) = a\\,(x^2 - b^2)^2\\,$ with $\\,a = 10^{20}\\,\\mathrm{J/m^4}\\,$, $\\,b = 10^{-10}\\,\\mathrm{m}\\,$, position $\\,x = -0.8\\,b\\,$, velocity $\\,v = 10^3\\,\\mathrm{m/s}\\,$, mass $\\,m = 10^{-26}\\,\\mathrm{kg}\\,$, maximum time step $\\,\\Delta t_{\\max} = 10^{-12}\\,\\mathrm{s}\\,$, fractional velocity change constant $\\,\\kappa = 0.1\\,$, fractional force change constant $\\,\\beta = 0.1\\,$, and stability safety factor $\\,s = 0.9\\,$. Treat $\\,x\\,$ and $\\,v\\,$ as one-dimensional vectors for uniformity.\n- Case $\\,2\\,$ (one-dimensional double-well, near the barrier top): Same $\\,V(x)\\,$, $\\,a\\,$, and $\\,b\\,$ as Case $\\,1\\,$, now with $\\,x = 0\\,$, $\\,v = 10^2\\,\\mathrm{m/s}\\,$, $\\,m = 10^{-26}\\,\\mathrm{kg}\\,$, $\\,\\Delta t_{\\max} = 10^{-12}\\,\\mathrm{s}\\,$, $\\,\\kappa = 0.1\\,$, $\\,\\beta = 0.1\\,$, and $\\,s = 0.9\\,$.\n- Case $\\,3\\,$ (two-dimensional anisotropic quadratic well, stiff direction present): Let $\\,V(x,y) = \\tfrac{1}{2}k_x x^2 + \\tfrac{1}{2}k_y y^2\\,$ with $\\,k_x = 1\\,\\mathrm{N/m}\\,$, $\\,k_y = 10^3\\,\\mathrm{N/m}\\,$, position $\\,\\mathbf{x} = (10^{-10}, 10^{-10})\\,\\mathrm{m}\\,$, velocity $\\,\\mathbf{v} = (0, 10^3)\\,\\mathrm{m/s}\\,$, $\\,m = 10^{-26}\\,\\mathrm{kg}\\,$, $\\,\\Delta t_{\\max} = 10^{-12}\\,\\mathrm{s}\\,$, $\\,\\kappa = 0.1\\,$, $\\,\\beta = 0.1\\,$, and $\\,s = 0.9\\,$.\n- Case $\\,4\\,$ (one-dimensional double-well, at the minimum, stationary): Same $\\,V(x)\\,$, $\\,a\\,$, and $\\,b\\,$ as Case $\\,1\\,$, with $\\,x = b\\,$, $\\,v = 0\\,\\mathrm{m/s}\\,$, $\\,m = 10^{-26}\\,\\mathrm{kg}\\,$, $\\,\\Delta t_{\\max} = 10^{-12}\\,\\mathrm{s}\\,$, $\\,\\kappa = 0.1\\,$, $\\,\\beta = 0.1\\,$, and $\\,s = 0.9\\,$. This case probes behavior when $\\,\\nabla V(\\mathbf{x}) = \\mathbf{0}\\,$ and $\\,\\mathbf{v} = \\mathbf{0}\\,$.\n- Case $\\,5\\,$ (one-dimensional double-well, just past the barrier with large acceleration): Same $\\,V(x)\\,$, $\\,a\\,$, and $\\,b\\,$ as Case $\\,1\\,$, with $\\,x = 0.2\\,b\\,$, $\\,v = 2\\times 10^3\\,\\mathrm{m/s}\\,$, $\\,m = 10^{-26}\\,\\mathrm{kg}\\,$, $\\,\\Delta t_{\\max} = 10^{-12}\\,\\mathrm{s}\\,$, $\\,\\kappa = 0.1\\,$, $\\,\\beta = 0.1\\,$, and $\\,s = 0.9\\,$.\n\nYour program should produce a single line of output containing the results for the $\\,5\\,$ test cases as a comma-separated list enclosed in square brackets. For example, if the results are $\\,r_1,\\dots,r_5\\,$, the output must be of the form $\\,\\big[ r_1, r_2, r_3, r_4, r_5 \\big]\\,$ with each $\\,r_i\\,$ a floating-point number in seconds.\n\nNote: Define any acronyms you use on first appearance. For example, Molecular Dynamics (MD) and Potential Energy Surface (PES).",
            "solution": "The problem requires the design and analytical justification of an adaptive time step, $\\Delta t$, selection rule for Molecular Dynamics (MD) simulations. The core principle is to adjust $\\Delta t$ based on the local characteristics of the Potential Energy Surface (PES), denoted by $V(\\mathbf{x})$, to ensure both numerical stability and accuracy. The dynamics are governed by Newton's Second Law,\n$$\nm\\,\\ddot{\\mathbf{x}} = \\mathbf{F}(\\mathbf{x}) = -\\nabla V(\\mathbf{x})\n$$\nwhere $m$ is the mass, $\\mathbf{x}$ is the position vector, $\\ddot{\\mathbf{x}}$ is the acceleration, and $\\mathbf{F}(\\mathbf{x})$ is the force.\n\nThe proposed time step $\\Delta t$ will be the minimum of a user-defined maximum, $\\Delta t_{\\max}$, and three distinct physical and numerical constraints. We shall derive each constraint from first principles.\n\n**1. Constraint from Local Linear Stability ($\\Delta t_1$)**\n\nNumerical stability of explicit integration schemes, such as the widely used Verlet algorithm, is limited by the highest frequency of motion the system can exhibit. To determine this local frequency, we linearize the equation of motion around the current position $\\mathbf{x}$. A small perturbation $\\delta\\mathbf{x}$ evolves according to:\n$$\nm\\,\\delta\\ddot{\\mathbf{x}} \\approx -(\\nabla^2 V(\\mathbf{x})) \\delta\\mathbf{x}\n$$\nwhere $\\nabla^2 V(\\mathbf{x})$ is the Hessian matrix of the potential, which acts as a local stiffness matrix. This is a system of coupled harmonic oscillators. The normal mode frequencies, $\\omega_i$, are determined by the eigenvalues, $\\lambda_i$, of the Hessian. Specifically, $\\omega_i^2 = \\lambda_i / m$. For a mode to be oscillatory and stable, its corresponding eigenvalue $\\lambda_i$ must be positive.\n\nThe highest frequency in the system, $\\omega_{\\max}$, dictates the stability limit. It corresponds to the largest positive eigenvalue of the Hessian, $\\lambda_{\\max} = \\max(\\{\\lambda_i > 0\\})$. Standard stability analysis for second-order integrators like Verlet shows that the time step must satisfy $\\Delta t < 2 / \\omega_{\\max}$. To ensure robustness, we introduce a safety factor $s \\in (0, 1)$. Thus, the stability-based time step constraint, $\\Delta t_1$, is:\n$$\n\\Delta t_1 = \\frac{2s}{\\omega_{\\max}} = 2s\\sqrt{\\frac{m}{\\lambda_{\\max}}}\n$$\nIf the Hessian has no positive eigenvalues (i.e., $\\lambda_{\\max} \\le 0$), the system is locally unstable or at a point of inflection. There are no high-frequency oscillations to resolve. In this scenario, the stability constraint is not the limiting factor, and we can consider it to be satisfied for any $\\Delta t$, which we formalize by setting $\\Delta t_1 \\to \\infty$.\n\n**2. Constraint from Fractional Velocity Change ($\\Delta t_2$)**\n\nTo ensure accuracy and a smooth trajectory, we must limit how much the velocity vector $\\mathbf{v}$ changes in a single step. The change in velocity, $\\Delta\\mathbf{v}$, over a time step $\\Delta t$ is approximately:\n$$\n\\Delta\\mathbf{v} \\approx \\mathbf{a}\\,\\Delta t\n$$\nwhere $\\mathbf{a} = \\mathbf{F}/m = -\\nabla V(\\mathbf{x})/m$ is the current acceleration. We impose the condition that the magnitude of this change is a small fraction, $\\kappa$, of the current velocity's magnitude:\n$$\n\\|\\Delta\\mathbf{v}\\| \\le \\kappa \\|\\mathbf{v}\\|\n$$\nSubstituting the approximation for $\\Delta\\mathbf{v}$ yields $\\|\\mathbf{a}\\|\\,\\Delta t \\le \\kappa \\|\\mathbf{v}\\|$. This gives the time step bound $\\Delta t_2$:\n$$\n\\Delta t_2 = \\kappa \\frac{\\|\\mathbf{v}\\|}{\\|\\mathbf{a}\\|} = \\kappa \\frac{m \\|\\mathbf{v}\\|}{\\|\\nabla V(\\mathbf{x})\\|}\n$$\nThis constraint becomes ill-defined or overly restrictive in certain physical limits.\n- If $\\|\\nabla V(\\mathbf{x})\\| \\approx 0$ (i.e., the particle is at or near a stationary point), the acceleration $\\mathbf{a}$ is near zero, and the velocity change is minimal. The constraint should not be restrictive. We handle this by setting $\\Delta t_2 \\to \\infty$ if $\\|\\mathbf{a}\\|$ is below a small numerical tolerance.\n- If $\\|\\mathbf{v}\\| \\approx 0$ but $\\|\\mathbf{a}\\| \\neq 0$ (e.g., a particle at rest on a slope), the criterion as stated gives $\\Delta t_2 \\approx 0$, which is unphysical as it would halt the simulation. The concept of \"fractional change\" is not meaningful for a zero quantity. Therefore, if $\\|\\mathbf{v}\\|$ is below a numerical tolerance, this specific criterion is not applicable, and we set $\\Delta t_2 \\to \\infty$. The evolution of the system from rest is then controlled by the other criteria.\n\n**3. Constraint from Fractional Force Change ($\\Delta t_3$)**\n\nThe force $\\mathbf{F}(\\mathbf{x})$ changes as the particle moves. A large change in force over a single time step indicates that the linear-force assumption (constant acceleration) underlying the integrator is breaking down. The displacement over one step is approximately $\\Delta\\mathbf{x} \\approx \\mathbf{v}\\,\\Delta t$. The first-order Taylor expansion of the force is:\n$$\n\\mathbf{F}(\\mathbf{x} + \\Delta\\mathbf{x}) \\approx \\mathbf{F}(\\mathbf{x}) + (\\nabla_{\\mathbf{x}}\\mathbf{F}(\\mathbf{x})) \\Delta\\mathbf{x}\n$$\nThe change in force, $\\Delta\\mathbf{F}$, is thus:\n$$\n\\Delta\\mathbf{F} \\approx (\\nabla_{\\mathbf{x}}\\mathbf{F}(\\mathbf{x})) (\\mathbf{v}\\,\\Delta t) = -(\\nabla^2 V(\\mathbf{x})) \\mathbf{v}\\,\\Delta t\n$$\nWe require this change to be a small fraction, $\\beta$, of the current force magnitude:\n$$\n\\|\\Delta\\mathbf{F}\\| \\le \\beta \\|\\mathbf{F}(\\mathbf{x})\\|\n$$\nSubstituting the expression for $\\Delta\\mathbf{F}$ gives $\\|(\\nabla^2 V(\\mathbf{x})) \\mathbf{v}\\|\\,\\Delta t \\le \\beta \\|\\nabla V(\\mathbf{x})\\|$. This yields the time step bound $\\Delta t_3$:\n$$\n\\Delta t_3 = \\beta \\frac{\\|\\nabla V(\\mathbf{x})\\|}{\\|(\\nabla^2 V(\\mathbf{x})) \\mathbf{v}\\|}\n$$\nSimilar to the previous constraints, we must handle limiting cases for numerical robustness.\n- If $\\|\\nabla V(\\mathbf{x})\\| \\approx 0$ (zero force), the notion of a fractional change is undefined. In this situation, the force is not changing to first order, so this constraint should be loose. We set $\\Delta t_3 \\to \\infty$ if $\\|\\nabla V(\\mathbf{x})\\|$ is below a numerical tolerance.\n- If the denominator term $\\|(\\nabla^2 V(\\mathbf{x})) \\mathbf{v}\\|$ is near zero (e.g., if $\\mathbf{v}=\\mathbf{0}$, or if $\\mathbf{v}$ is in a null space of the Hessian), this indicates the velocity is pointing in a direction where the force field is locally constant. The constraint becomes non-restrictive, and setting $\\Delta t_3 \\to \\infty$ is appropriate.\n\n**Final Adaptive Time Step Rule**\n\nThe adaptive time step, $\\Delta t$, is chosen as the most restrictive of all bounds, ensuring that all physical and numerical criteria are simultaneously met:\n$$\n\\Delta t = \\min(\\Delta t_{\\max}, \\Delta t_1, \\Delta t_2, \\Delta t_3)\n$$\nThis composite rule robustly adapts the simulation time scale, decreasing $\\Delta t$ in regions of high curvature (large $\\lambda_{\\max}$), high acceleration, or rapid force variation, and increasing it in smooth, slowly-varying regions of the PES.",
            "answer": "```python\nimport numpy as np\n\ndef compute_dt(V_grad, V_hess, v, m, κ, β, s, dt_max):\n    \"\"\"\n    Computes the adaptive time step based on local stability and accuracy criteria.\n\n    Args:\n        V_grad (np.ndarray): Gradient of the potential V at the current position.\n        V_hess (np.ndarray): Hessian of the potential V at the current position.\n        v (np.ndarray): Current velocity vector.\n        m (float): Mass of the particle.\n        κ (float): Fractional velocity change constant.\n        β (float): Fractional force change constant.\n        s (float): Stability safety factor.\n        dt_max (float): Maximum allowed time step.\n\n    Returns:\n        float: The selected adaptive time step, dt.\n    \"\"\"\n    # Define a small tolerance for checking against zero to handle numerical robustness\n    TOL = 1e-15\n\n    # --- 1. Constraint from Local Linear Stability (dt1) ---\n    # Hessian is symmetric, so we can use eigvalsh\n    eigenvalues = np.linalg.eigvalsh(V_hess)\n    lambda_max = np.max(eigenvalues) if eigenvalues.size > 0 else -1.0\n\n    if lambda_max > TOL:\n        omega_max = np.sqrt(lambda_max / m)\n        dt1 = (2.0 * s) / omega_max\n    else:\n        # No positive eigenvalues means no local oscillation, so stability is not an issue.\n        dt1 = np.inf\n\n    # --- 2. Constraint from Fractional Velocity Change (dt2) ---\n    F = -V_grad\n    a = F / m\n    norm_v = np.linalg.norm(v)\n    norm_a = np.linalg.norm(a)\n\n    if norm_v  TOL or norm_a  TOL:\n        # If velocity is zero, fractional change is ill-defined.\n        # If acceleration is zero, velocity does not change.\n        dt2 = np.inf\n    else:\n        dt2 = κ * norm_v / norm_a\n\n    # --- 3. Constraint from Fractional Force Change (dt3) ---\n    norm_F = np.linalg.norm(F)\n\n    if norm_F  TOL:\n        # If force is zero, fractional change is ill-defined.\n        dt3 = np.inf\n    else:\n        # Rate of change of force w.r.t. displacement along v\n        dF = V_hess @ v\n        norm_dF = np.linalg.norm(dF)\n        if norm_dF  TOL:\n            # Velocity is in a direction where force doesn't change\n            dt3 = np.inf\n        else:\n            dt3 = β * norm_F / norm_dF\n\n    # --- Final Time Step Selection ---\n    dt = min(dt_max, dt1, dt2, dt3)\n\n    return dt\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the adaptive time step rule.\n    \"\"\"\n    # Parameters for the double-well potential V(x) = a(x^2 - b^2)^2\n    a = 1.0e20  # J/m^4\n    b = 1.0e-10  # m\n    m_dw = 1.0e-26 # kg\n\n    # Functions for the 1D double-well potential\n    def grad_V_dw(x, a_val, b_val):\n        return np.array([4 * a_val * x[0] * (x[0]**2 - b_val**2)])\n\n    def hess_V_dw(x, a_val, b_val):\n        return np.array([[4 * a_val * (3 * x[0]**2 - b_val**2)]])\n\n    # Parameters for the 2D harmonic potential V(x,y) = 0.5*kx*x^2 + 0.5*ky*y^2\n    k_x = 1.0     # N/m\n    k_y = 1000.0  # N/m\n    m_ho = 1.0e-26 # kg\n\n    def grad_V_ho(x, kx_val, ky_val):\n        return np.array([kx_val * x[0], ky_val * x[1]])\n\n    def hess_V_ho(x, kx_val, ky_val):\n        return np.array([[kx_val, 0.0], [0.0, ky_val]])\n\n    # Define the 5 test cases\n    test_cases = [\n        # Case 1: 1D double-well, approaching barrier\n        {'case_id': 1, 'x': np.array([-0.8 * b]), 'v': np.array([1000.0]),\n         'm': m_dw, 'dt_max': 1e-12, 'κ': 0.1, 'β': 0.1, 's': 0.9,\n         'grad_func': lambda x: grad_V_dw(x, a, b),\n         'hess_func': lambda x: hess_V_dw(x, a, b)},\n        # Case 2: 1D double-well, at barrier top\n        {'case_id': 2, 'x': np.array([0.0]), 'v': np.array([100.0]),\n         'm': m_dw, 'dt_max': 1e-12, 'κ': 0.1, 'β': 0.1, 's': 0.9,\n         'grad_func': lambda x: grad_V_dw(x, a, b),\n         'hess_func': lambda x: hess_V_dw(x, a, b)},\n        # Case 3: 2D harmonic well, anisotropic\n        {'case_id': 3, 'x': np.array([1e-10, 1e-10]), 'v': np.array([0.0, 1000.0]),\n         'm': m_ho, 'dt_max': 1e-12, 'κ': 0.1, 'β': 0.1, 's': 0.9,\n         'grad_func': lambda x: grad_V_ho(x, k_x, k_y),\n         'hess_func': lambda x: hess_V_ho(x, k_x, k_y)},\n        # Case 4: 1D double-well, at minimum, stationary\n        {'case_id': 4, 'x': np.array([b]), 'v': np.array([0.0]),\n         'm': m_dw, 'dt_max': 1e-12, 'κ': 0.1, 'β': 0.1, 's': 0.9,\n         'grad_func': lambda x: grad_V_dw(x, a, b),\n         'hess_func': lambda x: hess_V_dw(x, a, b)},\n        # Case 5: 1D double-well, past barrier\n        {'case_id': 5, 'x': np.array([0.2 * b]), 'v': np.array([2000.0]),\n         'm': m_dw, 'dt_max': 1e-12, 'κ': 0.1, 'β': 0.1, 's': 0.9,\n         'grad_func': lambda x: grad_V_dw(x, a, b),\n         'hess_func': lambda x: hess_V_dw(x, a, b)},\n    ]\n\n    results = []\n    for case in test_cases:\n        V_grad = case['grad_func'](case['x'])\n        V_hess = case['hess_func'](case['x'])\n        dt = compute_dt(V_grad, V_hess, case['v'], case['m'], case['κ'], case['β'], case['s'], case['dt_max'])\n        results.append(f\"{dt:.5e}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Moving from deterministic to stochastic dynamics, as in simulations designed to sample a thermal equilibrium state, introduces a new layer of complexity to time step selection. The goal is no longer merely to approximate a single trajectory accurately but to generate a sequence of states that correctly represents a target probability distribution. This exercise delves into the critical and often subtle rules that govern adaptive time-stepping and step rejection in this context, highlighting how naive strategies can introduce statistical bias and lead to unphysical results. ",
            "id": "3855339",
            "problem": "Consider overdamped Langevin dynamics for a particle in a smooth potential $U(x)$ on $\\mathbb{R}^{d}$ at inverse temperature $\\beta0$, defined by the stochastic differential equation (SDE) $dx_{t}=-\\nabla U(x_{t})\\,dt+\\sqrt{2\\beta^{-1}}\\,dW_{t}$, where $W_{t}$ is standard $d$-dimensional Wiener process. The target invariant density for the continuous dynamics is the Boltzmann–Gibbs density $\\rho(x)\\propto\\exp(-\\beta U(x))$. A widely used time discretization is the Euler–Maruyama scheme: given $x_{n}$, propose\n$$\nx_{n+1}^{\\mathrm{trial}}=x_{n}-\\nabla U(x_{n})\\,\\Delta t+\\sqrt{2\\beta^{-1}\\,\\Delta t}\\,\\xi_{n},\n$$\nwith $\\xi_{n}\\sim\\mathcal{N}(0,I_{d})$. In multiscale materials simulation, one often desires to adapt the time step $\\Delta t$ and possibly reject steps to maintain stability or accuracy. In deterministic ordinary differential equation (ODE) integration for $\\dot{x}=f(x)$, adaptive time stepping with step rejection is standard, for example halving $\\Delta t$ when a local error estimator exceeds a tolerance.\n\nStarting from the definitions of the invariant density and the transition kernel for Euler–Maruyama proposals, as well as the concept of detailed balance, analyze how step rejection and time step adaptation impact invariant measures in deterministic versus stochastic integrators. In particular, reason about whether rejection criteria that depend on the realized noise increment $\\xi_{n}$ can alter the sampled distribution, and under what corrections unbiased sampling of $\\rho(x)$ is retained.\n\nSelect all statements that are correct:\n\nA. For deterministic integrators applied to ordinary differential equations, rejecting a step based solely on a local truncation error estimator and recomputing with a smaller $\\Delta t$ does not bias any invariant distribution, because the evolution is deterministic and the adaptive time discretization only controls approximation error rather than sampling a target measure.\n\nB. In overdamped Langevin dynamics discretized by Euler–Maruyama, rejecting a trial move whenever the realized Gaussian increment has magnitude above a fixed threshold and then reusing the same increment scaled to the smaller $\\Delta t$ preserves the Boltzmann–Gibbs invariant density $\\rho(x)$.\n\nC. In overdamped Langevin dynamics, adapting $\\Delta t$ based exclusively on the current state (for example, a bound derived from $\\lVert\\nabla^{2}U(x_{n})\\rVert$) and performing a Metropolis–Hastings correction for the final proposal, with fresh Gaussian noise upon any retry, preserves the Boltzmann–Gibbs invariant density $\\rho(x)$.\n\nD. In stochastic thermostatted dynamics, a rule that accepts only energy-decreasing proposals (rejecting energy-increasing ones) without any probabilistic correction maintains the invariant measure because the random noise compensates for the rejection.\n\nE. In underdamped Langevin dynamics with splitting into deterministic Hamiltonian flow and stochastic Ornstein–Uhlenbeck momentum refreshment, using a time-reversible, volume-preserving integrator for the Hamiltonian substep with a Metropolis correction on that substep, while allowing $\\Delta t$ to be adapted for the Hamiltonian part and keeping the Ornstein–Uhlenbeck refresh exact, preserves the Boltzmann–Gibbs invariant density.",
            "solution": "The fundamental principle governing the correct sampling of a target probability density $\\rho(x)$ by a Markov Chain Monte Carlo (MCMC) algorithm is the preservation of $\\rho(x)$ as the invariant measure of the generated chain. A sufficient condition for this is the detailed balance condition, which states that for any two states $x$ and $x'$, the rate of transitioning from $x$ to $x'$ must equal the rate of transitioning from $x'$ to $x$ in equilibrium. If the transition probability density is $P(x'|x)$, detailed balance is expressed as:\n$$\n\\rho(x) P(x'|x) = \\rho(x') P(x|x')\n$$\nThe Metropolis-Hastings algorithm provides a general framework to enforce this condition. Given a proposal density $q(x'|x)$, a proposed move from $x$ to $x'$ is accepted with probability $\\alpha(x'|x)$ given by:\n$$\n\\alpha(x'|x) = \\min\\left(1, \\frac{\\rho(x')q(x|x')}{\\rho(x)q(x'|x)}\\right)\n$$\nIf the move is rejected, the state remains $x$. The resulting effective transition kernel satisfies detailed balance. In the context of the given problem, the Euler-Maruyama scheme acts as a proposal mechanism. The target density is $\\rho(x) \\propto \\exp(-\\beta U(x))$. The proposal $x' = x - \\nabla U(x)\\,\\Delta t + \\sqrt{2\\beta^{-1}\\,\\Delta t}\\,\\xi$ with $\\xi \\sim \\mathcal{N}(0,I_{d})$ corresponds to a Gaussian proposal density $q(x'|x)$.\n\nWe now evaluate each statement based on these principles.\n\nA. For deterministic integrators applied to ordinary differential equations, rejecting a step based solely on a local truncation error estimator and recomputing with a smaller $\\Delta t$ does not bias any invariant distribution, because the evolution is deterministic and the adaptive time discretization only controls approximation error rather than sampling a target measure.\n\nThis statement addresses deterministic dynamics, $\\dot{x}=f(x)$. The goal of a numerical integrator is to approximate the true trajectory $x(t)$. An adaptive time-stepping scheme aims to control the local error, i.e., the deviation of the numerical solution from the true trajectory over a single step. When a step is rejected (e.g., the local error estimate exceeds a tolerance), the algorithm returns to the previous state and re-integrates over a smaller time interval, $\\Delta t'  \\Delta t$. The entire process is a numerical procedure to generate a more accurate approximation of the single, unique trajectory emanating from the initial condition. The concept of an \"invariant distribution\" for an ODE relates to the measure that is preserved by the true flow of the system (e.g., the Liouville measure for Hamiltonian systems). The adaptive integrator is merely a tool to approximate this flow. It does not alter the underlying dynamics or the measure it preserves. Its purpose is to control the accuracy with which the trajectory (which generates the samples) is computed. It does not introduce a sampling bias in the MCMC sense. The procedure is fully deterministic once the initial state is fixed. Therefore, this strategy is a matter of computational accuracy and efficiency, not of statistical sampling correctness in the sense of MCMC.\n\n**Verdict: Correct.**\n\nB. In overdamped Langevin dynamics discretized by Euler–Maruyama, rejecting a trial move whenever the realized Gaussian increment has magnitude above a fixed threshold and then reusing the same increment scaled to the smaller $\\Delta t$ preserves the Boltzmann–Gibbs invariant density $\\rho(x)$.\n\nThis statement proposes a rejection rule based on the realization of the random noise $\\xi_n$. Specifically, if $\\lVert\\xi_n\\rVert$ exceeds some threshold, the step is modified. This means the proposal mechanism is no longer a simple Euler-Maruyama step. The probability distribution of the actual displacement is altered from the original Gaussian. For example, large-magnitude moves driven by noise are systematically suppressed or changed. In MCMC, any rule that affects the proposal process must be accounted for in the detailed balance condition, typically via the acceptance probability in a Metropolis-Hastings framework. The statement suggests that this procedure, by itself (\"preserves the... invariant density\"), is sufficient. It is not. Such a procedure violates detailed balance because the proposal density $q(x'|x)$ is no longer a simple Gaussian, and the procedure does not use the modified proposal density to compute a valid Metropolis-Hastings correction. Rejecting or modifying proposals based on the realization of the random numbers without a corresponding correction in the acceptance probability will bias the sampling and lead to an incorrect stationary distribution.\n\n**Verdict: Incorrect.**\n\nC. In overdamped Langevin dynamics, adapting $\\Delta t$ based exclusively on the current state (for example, a bound derived from $\\lVert\\nabla^{2}U(x_{n})\\rVert$) and performing a Metropolis–Hastings correction for the final proposal, with fresh Gaussian noise upon any retry, preserves the Boltzmann–Gibbs invariant density $\\rho(x)$.\n\nThis describes a valid MCMC procedure. Here, the time step $\\Delta t$ becomes a function of the current state, $\\Delta t_n = \\Delta t(x_n)$. The proposal $x'$ is generated using this state-dependent time step. The crucial elements that ensure correctness are:\n$1$. The adaptation depends only on the current state $x_n$, not on the proposed state $x'$ or the random noise $\\xi_n$.\n$2$. A Metropolis-Hastings (MH) correction is performed. This correction must properly account for the state-dependent time step. The proposal density for the forward move is $q(x'|x_n) \\propto \\exp\\left(-\\frac{\\beta}{4\\Delta t(x_n)} \\lVert x' - x_n + \\nabla U(x_n) \\Delta t(x_n) \\rVert^2\\right)$. The proposal density for the reverse move, from $x'$ to $x_n$, must use the time step corresponding to state $x'$, i.e., $\\Delta t(x')$. Thus, $q(x_n|x') \\propto \\exp\\left(-\\frac{\\beta}{4\\Delta t(x')} \\lVert x_n - x' + \\nabla U(x') \\Delta t(x') \\rVert^2\\right)$. Using these two distinct proposal densities in the MH acceptance ratio $\\alpha(x'|x_n)$ ensures that detailed balance is satisfied.\n$3$. The use of \"fresh Gaussian noise upon any retry\" ensures that each proposal is an independent attempt, satisfying the Markovian property required for the MCMC analysis.\nThis procedure, known as state-dependent or adaptive MALA (Metropolis-Adjusted Langevin Algorithm), is a well-established and valid method for sampling the target distribution $\\rho(x)$.\n\n**Verdict: Correct.**\n\nD. In stochastic thermostatted dynamics, a rule that accepts only energy-decreasing proposals (rejecting energy-increasing ones) without any probabilistic correction maintains the invariant measure because the random noise compensates for the rejection.\n\nThis statement describes a procedure where any proposed move that increases the potential energy, $U(x')  U(x)$, is rejected with probability $1$. Such a rule fundamentally violates detailed balance for any finite temperature system. For the Boltzmann-Gibbs distribution $\\rho(x) \\propto \\exp(-\\beta U(x))$, detailed balance requires that uphill moves ($U(x')  U(x)$) are possible. Specifically, the Metropolis algorithm accepts such moves with probability $\\exp(-\\beta(U(x')-U(x)))$. Forbidding all uphill moves prevents the system from escaping local potential energy minima, and it will not explore the state space according to the Boltzmann-Gibbs distribution. The system would instead perform a noisy energy minimization. The claim that \"the random noise compensates for the rejection\" is physically and mathematically baseless. The noise is part of the proposal mechanism, and the hard rejection of all energy-increasing steps biases the sampling towards a $T \\to 0$ (zero temperature) limit, not the desired finite temperature $\\beta^{-1}$.\n\n**Verdict: Incorrect.**\n\nE. In underdamped Langevin dynamics with splitting into deterministic Hamiltonian flow and stochastic Ornstein–Uhlenbeck momentum refreshment, using a time-reversible, volume-preserving integrator for the Hamiltonian substep with a Metropolis correction on that substep, while allowing $\\Delta t$ to be adapted for the Hamiltonian part and keeping the Ornstein–Uhlenbeck refresh exact, preserves the Boltzmann–Gibbs invariant density.\n\nThis describes a sophisticated but valid MCMC algorithm for underdamped Langevin dynamics, often related to Generalized Hybrid Monte Carlo (GHMC). The algorithm is split into:\n$1$. A deterministic part (Hamiltonian dynamics), integrated numerically. Using a time-reversible and volume-preserving (symplectic) integrator is crucial for the structure of the algorithm.\n$2$. A stochastic part (Ornstein–Uhlenbeck process for velocity), which can be solved exactly.\nThe error introduced by the numerical integration of the Hamiltonian part violates the conservation of energy, $H(x,v) = U(x)+\\frac{1}{2}v^T M v$. To make the sampling of the phase-space density $\\pi(x,v) \\propto \\exp(-\\beta H(x,v))$ exact, a Metropolis correction is applied to the entire Hamiltonian substep. The acceptance probability is typically $\\min(1, \\exp(-\\beta \\Delta H))$, which corrects for the integrator's error. This is a valid GHMC step. The statement then suggests adapting $\\Delta t$ for the Hamiltonian part. As established in the analysis of option C, this is permissible provided the adaptation depends on the state at the beginning of the step, and the Metropolis correction is formulated to correctly account for this adaptation. This requires including the Jacobian of the time-step transformation or ensuring the proposal remains reversible, which can be complex but is theoretically possible. The phrasing \"with a Metropolis correction on that substep\" implies that the necessary correction to maintain detailed balance is indeed performed. Therefore, the combination of a reversible integrator, an exact stochastic step, and an appropriate Metropolis correction (that accounts for any state-dependent time stepping) constitutes a valid algorithm for sampling the Boltzmann-Gibbs distribution.\n\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}