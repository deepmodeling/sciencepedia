{
    "hands_on_practices": [
        {
            "introduction": "统计力学的基石之一是能够将微观涨落与宏观热力学性质联系起来。本练习通过展示如何直接从正则蒙特卡洛模拟中采样的势能方差来计算定容热容——一个关键的热力学响应函数，从而阐释了这一原理。通过完成此练习 ，您将亲身体验到涨落-耗散定理在计算物理学中最强大的应用之一。",
            "id": "3795411",
            "problem": "考虑一个小型三维 Lennard-Jones (LJ) 流体，它正在进行正则系综（恒定粒子数、体积、温度）蒙特卡洛模拟，在蒙特卡洛 (MC) 采样中通常简称为 NVT 系综。该 LJ 流体在约化单位制下进行描述，其中 LJ 能量标度 $\\epsilon$、长度标度 $\\sigma$ 和 Boltzmann 常数 $k_{\\mathrm{B}}$ 使得 $\\epsilon = 1$、$\\sigma = 1$ 且 $k_{\\mathrm{B}} = 1$。定容热容的构型贡献，记作 $C_V^{\\mathrm{conf}}$，仅由势能涨落定义，不包括动能部分。您的任务是从正则系综的第一性原理出发，推导出 $C_V^{\\mathrm{conf}}$ 的估计量，然后使用提供的合成样本势能时间序列，计算两个温度下的 $C_V^{\\mathrm{conf}}$，并结合 LJ 流体的已知相行为比较结果。\n\n出发点与推导要求：\n- 从正则系综的定义出发，使用逆温度 $\\beta = 1/(k_{\\mathrm{B}} T)$、配分函数 $Z(\\beta)$ 以及哈密顿量 $H$ 的系综平均值。仅使用正则系综的基本定义和标准热力学恒等式，推导出 $C_V$ 关于平衡能量涨落的显式表达式。然后，论证经典体系中动能和势能贡献分离的合理性，并展示如何将其特化为 $C_V^{\\mathrm{conf}}$ 关于势能涨落的表达式。推导过程必须阐明 $C_V^{\\mathrm{conf}}$ 是什么、其有效性为何，以及它如何从正则系综中得出，不得使用预先给定的简化公式。\n\n计算要求：\n- 您将获得三个合成测试用例，代表来自小体系 NVT MC 运行的采样势能时间序列。每个测试用例都指定了温度 $T$、时间序列的长度 $M$ 以及确定性伪随机数生成器的参数，用于将序列构建为一个具有指定均值和标准差的高斯过程，作为平衡采样的受控代理。对于每个情况 $j$，使用给定的均值、标准差和种子，通过正态分布生成一个势能序列 $\\{U_i^{(j)}\\}_{i=1}^{M_j}$。在 LJ 约化单位制下（其中 $k_{\\mathrm{B}} = 1$）解释这些数据。根据生成的时间序列，使用势能方差的无偏估计量计算 $C_V^{\\mathrm{conf}}$。除了使用无偏样本方差外，不要假设独立性；不需要进行相关性校正。\n\n物理单位与数值输出：\n- 所有量均采用约化的无量纲 LJ 单位。以 $k_{\\mathrm{B}}$ 为单位报告 $C_V^{\\mathrm{conf}}$（在此约化单位体系中是无量纲的）。最终结果表示为四位小数。\n- 除了前两个温度下的热容外，还需报告一个逻辑比较，指明较低温度下的构型热容是否超过较高温度下的构型热容（这与构型热容在结构性更强、更稠密的类液态中比在稀疏的类气态中更大的预期相符）。同时，计算第三个稀疏高温情况下的 $C_V^{\\mathrm{conf}}$，该情况作为一个构型涨落很小的边缘案例。\n\n测试套件：\n- 情况 1：温度 $T_1 = 0.7$，序列长度 $M_1 = 400$，生成器种子 $s_1 = 123$，正态均值 $\\mu_1 = -170.0$，正态标准差 $\\sigma_1 = 5.0$。\n- 情况 2：温度 $T_2 = 2.0$，序列长度 $M_2 = 400$，生成器种子 $s_2 = 456$，正态均值 $\\mu_2 = -100.0$，正态标准差 $\\sigma_2 = 3.0$。\n- 情况 3（边缘案例，稀疏和高温）：温度 $T_3 = 3.0$，序列长度 $M_3 = 400$，生成器种子 $s_3 = 789$，正态均值 $\\mu_3 = -2.0$，正态标准差 $\\sigma_3 = 0.5$。\n\n必需的算法步骤：\n- 对于每种情况 $j \\in \\{1,2,3\\}$：\n  1. 使用参数 $(\\mu_j, \\sigma_j)$ 和种子 $s_j$ 通过正态分布生成 $M_j$ 个样本 $U_i^{(j)}$。\n  2. 使用适用于流数据的数值稳定方法，计算势能时间序列的无偏样本方差 $s_j^2$。\n  3. 根据方差和温度计算 $C_{V,j}^{\\mathrm{conf}}$。\n- 在计算 $C_{V,1}^{\\mathrm{conf}}$ 和 $C_{V,2}^{\\mathrm{conf}}$ 之后，计算布尔值 $b$ 以指明是否 $C_{V,1}^{\\mathrm{conf}} > C_{V,2}^{\\mathrm{conf}}$。\n\n最终输出规格：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按以下顺序包含四个条目：$[C_{V,1}^{\\mathrm{conf}}, C_{V,2}^{\\mathrm{conf}}, b, C_{V,3}^{\\mathrm{conf}}]$，其中三个热容值四舍五入到四位小数，$b$ 是一个布尔值。\n\n科学真实性与解释：\n- 较低温度的情况 $T_1$ 对应于一个稠密的类液态 LJ 态，其中构型涨落和 $C_V^{\\mathrm{conf}}$ 预计会更大。\n- 较高温度的情况 $T_2$ 代表一个在较高热能下的超临界或类气态，其中构型涨落减少，$C_V^{\\mathrm{conf}}$ 预计会比情况 1 小。\n- 第三个情况 $T_3$ 模拟了一个稀疏、高温的区域，其中相互作用很弱，$C_V^{\\mathrm{conf}}$ 预计会接近于零。\n\n您的程序必须精确实现此逻辑，并以所需的格式生成最终的单行输出：例如，$[x_1,x_2,\\text{True},x_3]$，其中 $x_1$、$x_2$ 和 $x_3$ 是四舍五入到四位小数的浮点数。",
            "solution": "该问题被评估为有效，因为它在科学上基于统计力学，问题设定良好、客观，并包含了获得唯一、可验证解所需的所有必要信息。它代表了计算统计物理学中的一个标准练习。\n\n首要任务是从正则系综的第一性原理推导出定容热容的构型贡献（记为 $C_V^{\\mathrm{conf}}$）的估计量。随后，将此估计量应用于合成的势能数据，以计算 Lennard-Jones 流体在三个不同状态点下的 $C_V^{\\mathrm{conf}}$。\n\n首先，我们开始推导。在正则系综中，一个包含 $N$ 个粒子、体积为 $V$、温度为 $T$ 的系统由正则配分函数 $Z$ 描述。对于经典系统，$Z$ 是对所有可能的粒子位置 $\\mathbf{r}^N$ 和动量 $\\mathbf{p}^N$ 的积分：\n$$\nZ(N, V, T) = \\frac{1}{N! h^{3N}} \\int d\\mathbf{r}^N d\\mathbf{p}^N e^{-\\beta H(\\mathbf{r}^N, \\mathbf{p}^N)}\n$$\n此处，$\\beta = 1/(k_{\\mathrm{B}} T)$ 是逆温度，$k_{\\mathrm{B}}$ 是 Boltzmann 常数。$H(\\mathbf{r}^N, \\mathbf{p}^N)$ 是系统的经典哈密顿量，因子 $1/(N! h^{3N})$ 确保了状态计数的正确性和量纲的一致性。哈密顿量是动能 $K(\\mathbf{p}^N)$ 和势能 $U(\\mathbf{r}^N)$ 的和：\n$$\nH(\\mathbf{r}^N, \\mathbf{p}^N) = K(\\mathbf{p}^N) + U(\\mathbf{r}^N) = \\sum_{i=1}^{N} \\frac{|\\mathbf{p}_i|^2}{2m} + U(\\mathbf{r}^N)\n$$\n因为哈密顿量可以分离为依赖于动量的部分和依赖于位置的部分，所以配分函数可以因式分解：\n$$\nZ = \\left( \\frac{1}{h^{3N}} \\int d\\mathbf{p}^N e^{-\\beta K(\\mathbf{p}^N)} \\right) \\left( \\frac{1}{N!} \\int d\\mathbf{r}^N e^{-\\beta U(\\mathbf{r}^N)} \\right)\n$$\n这将 $Z$ 分离为一个动能（或理想气体）分量和一个构型分量。构型积分 $Q$ 定义为：\n$$\nQ(N, V, T) = \\int_V d\\mathbf{r}^N e^{-\\beta U(\\mathbf{r}^N)}\n$$\n热力学和统计力学之间的联系通过亥姆霍兹自由能 $A = -k_{\\mathrm{B}} T \\ln Z = -1/\\beta \\ln Z$ 建立。平均内能 $\\langle E \\rangle$ 可以从 $Z$ 导出：\n$$\n\\langle E \\rangle = \\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\n$$\n定容热容 $C_V$ 定义为平均内能对温度在恒定体积和粒子数下的偏导数：\n$$\nC_V = \\left( \\frac{\\partial \\langle E \\rangle}{\\partial T} \\right)_{N,V}\n$$\n为了用涨落来表示它，我们首先将对 $T$ 的导数转换为对 $\\beta$ 的导数。使用链式法则，$\\frac{\\partial}{\\partial T} = \\frac{d\\beta}{dT} \\frac{\\partial}{\\partial \\beta} = -\\frac{1}{k_{\\mathrm{B}} T^2} \\frac{\\partial}{\\partial \\beta} = -k_{\\mathrm{B}} \\beta^2 \\frac{\\partial}{\\partial \\beta}$。将此应用于 $C_V$ 的定义：\n$$\nC_V = -k_{\\mathrm{B}} \\beta^2 \\frac{\\partial \\langle E \\rangle}{\\partial \\beta} = -k_{\\mathrm{B}} \\beta^2 \\frac{\\partial}{\\partial \\beta} \\left( -\\frac{\\partial \\ln Z}{\\partial \\beta} \\right) = k_{\\mathrm{B}} \\beta^2 \\frac{\\partial^2 \\ln Z}{\\partial \\beta^2}\n$$\n可以证明 $\\ln Z$ 的二阶导数等于总能量 $E = H$ 的方差：\n$$\n\\frac{\\partial^2 \\ln Z}{\\partial \\beta^2} = \\frac{\\partial}{\\partial \\beta} \\left( \\frac{1}{Z} \\frac{\\partial Z}{\\partial \\beta} \\right) = \\frac{1}{Z}\\frac{\\partial^2 Z}{\\partial \\beta^2} - \\frac{1}{Z^2}\\left(\\frac{\\partial Z}{\\partial \\beta}\\right)^2 = \\langle E^2 \\rangle - \\langle E \\rangle^2 = \\sigma_E^2\n$$\n这就得到了著名的热容涨落-耗散公式：\n$$\nC_V = k_{\\mathrm{B}} \\beta^2 (\\langle E^2 \\rangle - \\langle E \\rangle^2) = \\frac{\\langle E^2 \\rangle - \\langle E \\rangle^2}{k_{\\mathrm{B}} T^2}\n$$\n总热容 $C_V$ 可以分为动能和构型贡献。由于 $\\langle E \\rangle = \\langle K \\rangle + \\langle U \\rangle$，我们有：\n$$\nC_V = \\left( \\frac{\\partial \\langle K \\rangle}{\\partial T} \\right)_{N,V} + \\left( \\frac{\\partial \\langle U \\rangle}{\\partial T} \\right)_{N,V} = C_V^{\\mathrm{kin}} + C_V^{\\mathrm{conf}}\n$$\n对于一个具有 $3N$ 个二次动能自由度的经典系统，能量均分定理指出 $\\langle K \\rangle = \\frac{3N}{2} k_{\\mathrm{B}} T$。因此，对热容的动能贡献是一个常数：\n$$\nC_V^{\\mathrm{kin}} = \\frac{\\partial}{\\partial T} \\left( \\frac{3N}{2} k_{\\mathrm{B}} T \\right) = \\frac{3N}{2} k_{\\mathrm{B}}\n$$\n构型贡献 $C_V^{\\mathrm{conf}}$ 来自平均势能对温度的依赖性：\n$$\nC_V^{\\mathrm{conf}} = \\left( \\frac{\\partial \\langle U \\rangle}{\\partial T} \\right)_{N,V}\n$$\n遵循与推导总 $C_V$ 相同的过程，但从平均势能 $\\langle U \\rangle = -\\frac{\\partial \\ln Q}{\\partial \\beta}$ 出发，我们发现：\n$$\nC_V^{\\mathrm{conf}} = k_{\\mathrm{B}} \\beta^2 (\\langle U^2 \\rangle - \\langle U \\rangle^2) = \\frac{\\langle U^2 \\rangle - \\langle U \\rangle^2}{k_{\\mathrm{B}} T^2}\n$$\n这个推导是有效的，因为纯粹依赖动量的函数（如 $K$）和纯粹依赖位置的函数（如 $U$）的乘积的统计平均值可以分解为它们各自平均值的乘积，即 $\\langle KU \\rangle = \\langle K \\rangle \\langle U \\rangle$。因此，$K$ 和 $U$ 之间的协方差为零，总能量方差是动能和势能方差之和：$\\sigma_E^2 = \\sigma_K^2 + \\sigma_U^2$。这证实了将 $C_V$ 分离为独立的动能和构型部分的合理性。\n\n对于此问题的计算部分，我们使用推导出的 $C_V^{\\mathrm{conf}}$ 表达式。问题指定使用约化单位制，其中 $k_{\\mathrm{B}} = 1$，因此公式简化为：\n$$\nC_V^{\\mathrm{conf}} = \\frac{\\langle U^2 \\rangle - \\langle U \\rangle^2}{T^2} = \\frac{\\text{Var}(U)}{T^2}\n$$\n在模拟中，真实的系综平均方差 $\\text{Var}(U)$ 是通过有限的势能样本时间序列 $\\{U_i\\}_{i=1}^M$ 来估计的。问题要求使用方差的无偏估计量，即样本方差 $s^2$：\n$$\ns^2 = \\frac{1}{M-1} \\sum_{i=1}^M (U_i - \\bar{U})^2\n$$\n其中 $\\bar{U} = \\frac{1}{M} \\sum_{i=1}^M U_i$ 是样本均值。提示中提到的数值稳定性问题，可以通过使用现代数值库（如 NumPy）中固有的高精度算术来解决，其标准方差函数对于本问题的范围是稳健的。\n\n对于三个测试用例中的每一个，过程如下：\n1. 使用伪随机数生成器，从具有指定均值 $\\mu_j$、标准差 $\\sigma_j$ 和种子 $s_j$ 的正态分布中生成一个长度为 $M_j$ 的势能值序列。\n2. 计算该序列的无偏样本方差 $s_j^2$。\n3. 使用公式 $C_{V,j}^{\\mathrm{conf}} = s_j^2 / T_j^2$ 计算构型热容。\n4. 在计算 $C_{V,1}^{\\mathrm{conf}}$ 和 $C_{V,2}^{\\mathrm{conf}}$ 后，进行布尔比较 $b = (C_{V,1}^{\\mathrm{conf}} > C_{V,2}^{\\mathrm{conf}})$，以检查热容是否在较低温度下更大，这与从稠密液体到超临界流体的转变的物理预期相符。第三个案例作为一个在稀疏、高温区域构型贡献应极小的校验。\n最终输出由这些计算值组成，并按规定进行四舍五入。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the configurational heat capacity from synthetic data and performs a comparison.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, M, seed, mean, std_dev)\n        (0.7, 400, 123, -170.0, 5.0), # Case 1: Dense liquid-like\n        (2.0, 400, 456, -100.0, 3.0), # Case 2: Supercritical/gas-like\n        (3.0, 400, 789, -2.0, 0.5),   # Case 3: Dilute, high-T gas\n    ]\n\n    cv_results = []\n    \n    # Process each test case\n    for case in test_cases:\n        T, M, seed, mu, sigma = case\n        \n        # 1. Generate M samples using a normal distribution with the given parameters.\n        # Set the seed for reproducibility.\n        np.random.seed(seed)\n        # Generate the potential energy time series.\n        potential_energies = np.random.normal(loc=mu, scale=sigma, size=M)\n        \n        # 2. Compute the unbiased sample variance of the potential energy time series.\n        # The parameter ddof=1 (delta degrees of freedom) ensures the denominator\n        # is N-1, providing an unbiased estimator.\n        # This is a numerically stable method for the data in this problem.\n        potential_energy_variance = np.var(potential_energies, ddof=1)\n        \n        # 3. Compute the configurational heat capacity.\n        # In reduced units, k_B = 1.\n        # C_V_conf = ( Var(U) ) / ( k_B * T^2 ) = Var(U) / T^2\n        cv_conf = potential_energy_variance / (T**2)\n        \n        cv_results.append(cv_conf)\n\n    # Extract results for clarity\n    cv_conf_1 = cv_results[0]\n    cv_conf_2 = cv_results[1]\n    cv_conf_3 = cv_results[2]\n\n    # 4. Compute the boolean 'b' indicating if C_V_conf at T1 > C_V_conf at T2.\n    # This is expected behavior as the liquid state has larger configurational\n    # fluctuations than the gas-like state.\n    comparison_bool = cv_conf_1 > cv_conf_2\n\n    # Format the final output as a comma-separated list in brackets,\n    # with heat capacity values rounded to four decimal places.\n    # The boolean value is automatically converted to 'True' or 'False'.\n    output_list = [\n        f\"{cv_conf_1:.4f}\",\n        f\"{cv_conf_2:.4f}\",\n        str(comparison_bool),\n        f\"{cv_conf_3:.4f}\"\n    ]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(output_list)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "从模拟中获得结果只是成功了一半；严格地量化其统计不确定性也同等重要。蒙特卡洛模拟产生的数据具有内在的时间相关性，这使得简单的误差估计方法失效。本练习  将指导您实现分块平均技术，这是一种计算相关数据均值标准误差的稳健方法，可确保您报告的结果在统计上是可靠的。",
            "id": "3795397",
            "problem": "你的任务是为正则系综（Number–Volume–Temperature, NVT）蒙特卡洛（MC）模拟所生成的样本，设计并实现一个用于计算单粒子势能及其统计不确定性的实用估计量。该估计量必须依赖分块平均法，以严格处理采样数据中的时间相关性。你的程序必须是一个完整、可运行的实现，它在一个固定的测试套件上计算该估计量，并按照下面指定的精确格式，将结果单行输出。\n\n从适用于正则系综（NVT）和蒙特卡洛（MC）采样的有效基础出发：\n- 正则系综为微观态赋予一个与玻尔兹曼因子 $e^{-\\beta U(\\mathbf{x})}$ 成正比的概率密度，其中 $U(\\mathbf{x})$ 是势能，$\\beta$ 是逆温度。可观测量的系综平均是相对于此概率密度的期望值。\n- 在广泛的正则性条件下，一个遍历的马尔可夫链蒙特卡洛（MC）采样器会产生一个平稳的可观测量值时间序列，其长时间平均收敛于系综平均期望值。\n- 与独立采样相比，时间序列中的自相关会增加样本均值的不确定性。分块平均法是一种减弱自相关的原则性方法，它通过将相关样本粗粒化为非重叠数据块的平均值来实现。\n\n你的任务是：\n1. 使用上述基础，设计并实现一个系综平均单粒子势能的估计量，以及一个相应的统计不确定性估计量，该估计量通过分块平均法对相关的MC样本有效。此估计量必须从平稳遍历过程的第一性原理构建，而不能依赖于没有理论依据的简化公式。\n2. 实现一个程序，将此估计量应用于三个单粒子势能的合成MC轨迹。这些轨迹由一个平稳的一阶自回归递归生成，以模拟真实的时间相关性。每个轨迹 $u_t$ 都是以无量纲的 Lennard-Jones 约化能量单位（即，以 Lennard-Jones 能量尺度 $\\varepsilon$ 为单位，因此结果是 $\\varepsilon$ 的无量纲倍数）生成的，其公式为\n$$\nu_t = \\mu + \\phi \\left(u_{t-1} - \\mu\\right) + \\sigma \\,\\xi_t\n$$\n其中 $\\xi_t \\sim \\mathcal{N}(0,1)$ 是独立的标准正态随机变量，$\\mu$ 是平均水平，$\\phi$ 控制相关强度，$\\sigma$ 设定新息振幅。对于每个轨迹，初始值 $u_0$ 被设置为 $u_0 = \\mu + \\sigma \\,\\xi_0$，具有相同的噪声分布。你必须严格按照下面测试套件中给出的指定参数和种子来生成这些轨迹。\n\n估计量构建与选择规则：\n- 将整个轨迹的时间平均值作为系综平均单粒子势能的点估计。\n- 对于分块平均法，考虑长度为 $b$ 的非重叠块并计算块平均值。利用块平均值之间的变异性，为每个块大小 $b$ 构建一个关于总样本均值的统计不确定性（标准误差）的相合估计量。\n- 为了选择块大小，请使用确定性规则：从提供的列表中选择能够产生至少4个完整块的最大的块大小 $b$（也就是说，如果 $N$ 是轨迹长度，选择 $b$ 使得 $\\left\\lfloor N/b \\right\\rfloor \\ge 4$）。如果不存在这样的 $b$，则选择能够产生至少2个完整块的最大的 $b$。此规则在确保充分粗粒化的同时，也保留了足够数量的块来进行方差估计。\n\n单位与格式要求：\n- 所有能量均以约化的 Lennard-Jones 单位表示，即 $\\varepsilon$ 的倍数，因此是无量纲的。以相同的单位报告单粒子势能及其不确定性。\n- 不涉及角度。\n- 输出中不含百分比；任何阈值或比率都必须作为纯小数处理（例如，$0.02$）。\n- 将所有报告的数值结果四舍五入到6位小数。\n\n测试套件：\n使用上述递归公式以及以下参数和种子生成三个轨迹。对于每种情况，都使用相同的块大小列表 $b \\in \\{1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000\\}$。\n\n- 情况 1 (一般理想路径，强相关，长轨迹)：\n  - 长度 $N = 50000$，\n  - 平均值 $\\mu = 1.25$，\n  - 相关参数 $\\phi = 0.95$，\n  - 新息振幅 $\\sigma = 0.5$，\n  - 随机种子 $1234$。\n- 情况 2 (边界条件，强相关，短轨迹)：\n  - 长度 $N = 1500$，\n  - 平均值 $\\mu = -0.25$，\n  - 相关参数 $\\phi = 0.9$，\n  - 新息振幅 $\\sigma = 0.3$，\n  - 随机种子 $5678$。\n- 情况 3 (边缘情况，近似独立样本)：\n  - 长度 $N = 20000$，\n  - 平均值 $\\mu = 0.0$，\n  - 相关参数 $\\phi = 0.0$，\n  - 新息振幅 $\\sigma = 1.0$，\n  - 随机种子 $42$。\n\n最终输出格式要求：\n- 你的程序应产生单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是一个包含两个元素的列表，其中包括估计的单粒子平均势能和使用所选块大小估计的标准误差，两者均四舍五入到6位小数。例如，\n$[[\\hat{\\mu}_1,\\mathrm{SE}_1],[\\hat{\\mu}_2,\\mathrm{SE}_2],[\\hat{\\mu}_3,\\mathrm{SE}_3]]$。",
            "solution": "目标是根据蒙特卡洛模拟生成的时间相关数据序列 $\\{u_t\\}_{t=0}^{N-1}$，设计并实现一个用于计算系综平均单粒子势能 $\\langle u \\rangle$ 及其统计不确定性的估计量。采用分块平均法来处理这类数据中固有的自相关。\n\n首先，我们建立平均单粒子势能的估计量。对于一个平稳遍历过程，大数定律保证了时间平均收敛于系综平均。因此，样本均值是 $\\langle u \\rangle$ 的一个相合且无偏的估计量：\n$$\n\\hat{\\mu} = \\frac{1}{N} \\sum_{t=0}^{N-1} u_t\n$$\n其中 $N$ 是轨迹中的总样本数。该估计量将用作单粒子势能的点估计。\n\n接下来，我们处理 $\\hat{\\mu}$ 的统计不确定性（即标准误差）的估计问题。对于独立同分布（i.i.d.）的随机变量序列，样本均值的方差为 $\\mathrm{Var}(\\hat{\\mu}) = \\sigma_u^2/N$，其中 $\\sigma_u^2$ 是基础分布的方差。然而，来自MC模拟的数据构成一个马尔可夫链，并且通常在时间上是相关的。对于一个平稳的相关时间序列，样本均值的方差由下式给出：\n$$\n\\mathrm{Var}(\\hat{\\mu}) = \\frac{1}{N^2} \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\mathrm{Cov}(u_i, u_j) = \\frac{\\sigma_u^2}{N} \\left( 1 + 2 \\sum_{k=1}^{N-1} \\left(1 - \\frac{k}{N}\\right) \\rho(k) \\right)\n$$\n其中 $\\rho(k)$ 是滞后为 $k$ 时的自相关函数。对于正相关数据（$\\rho(k)>0$），这在物理模拟中很常见，朴素的 i.i.d. 公式会严重低估真实方差。\n\n分块平均法是一种无需显式计算完整自相关函数就能估计 $\\mathrm{Var}(\\hat{\\mu})$ 的稳健技术。其核心原理是将时间序列粗粒化为足够长的块，使得这些块近似统计独立。\n\n其步骤如下：\n1.  将完整的数据序列 $\\{u_t\\}_{t=0}^{N-1}$ 划分为 $N_b = \\lfloor N/b \\rfloor$ 个非重叠的块，每个块的长度为 $b$。序列末尾任何剩余的 $N \\pmod b$ 个数据点在此部分分析中被舍弃。\n\n2.  对每个块 $k \\in \\{1, 2, \\dots, N_b\\}$，计算一个块平均值：\n    $$\n    \\bar{u}_k = \\frac{1}{b} \\sum_{i=0}^{b-1} u_{(k-1)b + i}\n    $$\n\n3.  分块平均法的中心假设是：如果块长度 $b$ 足够大，特别是远大于过程的积分自相关时间，那么块平均值 $\\{\\bar{u}_k\\}$ 将近似不相关。然后，我们可以将它们视为从一个均值为 $\\langle u \\rangle$、方差为某个值 $\\sigma_{\\bar{u}}^2$ 的分布中抽取的 $N_b$ 个新的独立同分布样本。\n\n4.  在这个独立性假设下，我们可以使用无偏样本方差的标准公式来估计块平均值总体的方差 $\\sigma_{\\bar{u}}^2$：\n    $$\n    \\hat{\\sigma}_{\\bar{u}}^2 = \\frac{1}{N_b - 1} \\sum_{k=1}^{N_b} (\\bar{u}_k - \\hat{\\mu}_B)^2\n    $$\n    其中 $\\hat{\\mu}_B = \\frac{1}{N_b} \\sum_{k=1}^{N_b} \\bar{u}_k$ 是块平均值的均值。\n\n5.  总样本均值 $\\hat{\\mu}$ 近似等于这些块平均值的均值。根据中心极限定理， $N_b$ 个独立同分布样本的均值的方差等于单个样本的方差除以 $N_b$。因此，我们的总均值估计量 $\\hat{\\mu}$ 的估计方差为：\n    $$\n    \\widehat{\\mathrm{Var}}(\\hat{\\mu}) \\approx \\frac{\\hat{\\sigma}_{\\bar{u}}^2}{N_b} = \\frac{1}{N_b(N_b - 1)} \\sum_{k=1}^{N_b} (\\bar{u}_k - \\hat{\\mu}_B)^2\n    $$\n\n6.  统计不确定性，即均值标准误差 ($\\mathrm{SE}(\\hat{\\mu})$)，是这个估计方差的平方根：\n    $$\n    \\mathrm{SE}(\\hat{\\mu}) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\mu})} = \\sqrt{\\frac{\\hat{\\sigma}_{\\bar{u}}^2}{N_b}}\n    $$\n只要所选的块大小 $b$ 足够大，这就为不确定性提供了一个统计上可靠的估计量，该估计量能恰当地处理时间相关性。\n\n该实现将使用指定的一阶自回归模型 $u_t = \\mu + \\phi(u_{t-1} - \\mu) + \\sigma\\xi_t$ 来生成合成轨迹，该模型模仿了MC数据的相关性。块大小 $b$ 根据提供的确定性规则选择：从候选列表中选择能够产生至少4个完整块的最大的块大小。如果没有，则选择能够产生至少2个块的最大尺寸。此规则平衡了为确保块平均值去相关而需要较大 $b$ 的需求，以及为获得可靠的方差 $\\hat{\\sigma}_{\\bar{u}}^2$ 估计而需要足够数量的块 $N_b$ 的需求。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the potential energy per particle and its statistical uncertainty\n    for synthetic Monte Carlo trajectories using block averaging.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: general happy path, strong correlation, long trajectory\n        {'N': 50000, 'mu': 1.25, 'phi': 0.95, 'sigma': 0.5, 'seed': 1234},\n        # Case 2: boundary condition, strong correlation, short trajectory\n        {'N': 1500, 'mu': -0.25, 'phi': 0.9, 'sigma': 0.3, 'seed': 5678},\n        # Case 3: edge case, nearly independent samples\n        {'N': 20000, 'mu': 0.0, 'phi': 0.0, 'sigma': 1.0, 'seed': 42},\n    ]\n\n    block_sizes_candidate = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n    \n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        mu = case['mu']\n        phi = case['phi']\n        sigma = case['sigma']\n        seed = case['seed']\n        \n        # 1. Generate the synthetic trajectory using the AR(1) model.\n        rng = np.random.default_rng(seed)\n        trajectory = np.zeros(N)\n        \n        # Generate noise terms\n        xi = rng.standard_normal(N)\n        \n        # Initial value u_0\n        trajectory[0] = mu + sigma * xi[0]\n        \n        # Generate the rest of the trajectory\n        for t in range(1, N):\n            trajectory[t] = mu + phi * (trajectory[t-1] - mu) + sigma * xi[t]\n            \n        # 2. Compute the point estimate for the mean potential energy.\n        mean_potential_energy = np.mean(trajectory)\n        \n        # 3. Select the appropriate block size based on the specified rule.\n        selected_b = -1\n        # First-pass rule: find largest b yielding at least 4 blocks.\n        for b in reversed(block_sizes_candidate):\n            if N // b >= 4:\n                selected_b = b\n                break\n        \n        # Second-pass rule if first pass fails: find largest b yielding at least 2 blocks.\n        if selected_b == -1:\n            for b in reversed(block_sizes_candidate):\n                if N // b >= 2:\n                    selected_b = b\n                    break\n        \n        if selected_b == -1:\n            # This case should not be reached with the given test suite.\n            raise ValueError(\"Could not find a suitable block size for the given N.\")\n\n        # 4. Perform block averaging to compute the standard error.\n        num_blocks = N // selected_b\n        \n        # Truncate trajectory to an integer number of blocks.\n        blocked_trajectory = trajectory[:num_blocks * selected_b]\n        \n        # Reshape into blocks.\n        blocks = blocked_trajectory.reshape((num_blocks, selected_b))\n        \n        # Compute the mean of each block.\n        block_means = np.mean(blocks, axis=1)\n        \n        # 5. Calculate the standard error of the overall mean.\n        # Variance of the block means (using N_b-1 in the denominator).\n        variance_of_block_means = np.var(block_means, ddof=1)\n        \n        # Variance of the overall mean is Var(block_means) / num_blocks.\n        variance_of_mean = variance_of_block_means / num_blocks\n        \n        # Standard error is the square root of the variance of the mean.\n        standard_error = np.sqrt(variance_of_mean)\n        \n        # 6. Format and store the results.\n        rounded_mean = round(mean_potential_energy, 6)\n        rounded_se = round(standard_error, 6)\n        \n        results.append([rounded_mean, rounded_se])\n\n    # Final print statement in the exact required format.\n    # The str() representation of a Python list is the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "简单的蒙特卡洛模拟在处理复杂的能量形貌时可能会遇到困难，常常会陷入局部最小值中，无法有效地对状态空间进行采样。并行回火，或称副本交换蒙特卡洛，是一种为克服这一挑战而设计的强大增强采样方法。在这个高级练习  中，您将处理一项关键的实践任务：设计一个高效的温度阶梯，这是确保副本能够交换构型并彻底探索能量形貌的关键。",
            "id": "3795407",
            "problem": "您需要实现一个完整的、可运行的程序，该程序为正则系综中的并行回火（副本交换）设计温度方案，并从相邻温度下的能量直方图计算稠密 Lennard–Jones (LJ) 流体的预期交换接受率。在粒子数-体积-温度 (NVT) 系综中的正则蒙特卡洛方法假设微观状态的能量根据玻尔兹曼权重分布。并行回火通过在不同温度的副本之间交换构型来增强正则蒙特卡洛方法，以改善采样。从以下基本原理开始：在温度 $T$ 下，能量 $E$ 的正则概率密度为 $P(E;T) = Z(T)^{-1} g(E) \\exp(-\\beta E)$，其中 $Z(T)$ 是配分函数，$g(E)$ 是简并度，$\\beta = 1/(k_{\\mathrm{B}} T)$，$k_{\\mathrm{B}}$ 是玻尔兹曼常数。在温度 $T_a$ 和 $T_b$ 之间，当前能量分别为 $E_a$ 和 $E_b$ 的副本交换的 Metropolis 接受概率为 $\\alpha(E_a,E_b; \\beta_a,\\beta_b) = \\min\\left(1, \\exp\\left[(\\beta_a - \\beta_b)(E_b - E_a)\\right]\\right)$。两个相邻副本之间的预期交换接受率是 $\\alpha$ 在 $T_a$ 和 $T_b$ 下的联合能量分布上的正则期望值。使用总能量的离散直方图来近似这个期望值。\n\n使用离散近似方法构建两个温度 $T_a$ 和 $T_b$ 之间的预期接受率，其中为您提供了温度 $T_a$ 的直方图箱中心数组 $\\{E_i\\}$ 和归一化箱概率数组 $\\{p_i\\}$，以及温度 $T_b$ 相应的 $\\{F_j\\}$ 和 $\\{q_j\\}$。假设在给定温度的条件下，两个副本的能量是相互独立的。预期接受率必须通过以下双重求和计算：\n$$\n\\mathbb{E}[\\alpha] \\approx \\sum_{i} \\sum_{j} p_i \\, q_j \\, \\min\\left(1, \\exp\\left[(\\beta_a - \\beta_b)(F_j - E_i)\\right]\\right).\n$$\n使用约化的 Lennard–Jones 单位，其中 $k_{\\mathrm{B}} = 1$，因此温度和能量是无量纲的。\n\n设计一个算法，在给定一个精细的候选温度集 $\\{T_k\\}$ 以及每个 $T_k$ 对应的能量直方图的情况下，从 $T_{\\min}$ 到 $T_{\\max}$ 选择一个子集方案 $\\{T_{s(\\ell)}\\}$，目标是使所选方案中每对相邻温度的预期交换接受率都落在目标区间 $[p_{\\mathrm{low}}, p_{\\mathrm{high}}]$ 内。您的选择应贪婪地最小化副本数量，方法是：在每一步中，从所有满足预期接受率不低于 $p_{\\mathrm{low}}$ 的后续候选温度中，选择温度最高（即步长最大）的那一个。如果当前温度之后的候选温度中没有一个能达到至少 $p_{\\mathrm{low}}$ 的接受率，您仍必须选择紧邻的下一个温度，并标记此步骤未能达到下限。构建方案后，还需报告是否所有相邻对都满足了上限。所有能量和温度均使用约化的 Lennard–Jones 单位。\n\n为评估您的实现，请使用以下测试套件。其中，总能量直方图由高斯分布生成，这与稠密 Lennard-Jones 流体的中心极限定理一致：总能量 $E$ 被建模为正态分布，其均值为 $N \\mu(T)$，方差为 $N \\sigma^2(T)$，其中 $N$ 是粒子数，$\\mu(T)$ 和 $\\sigma^2(T)$ 是单位粒子的均值和方差函数。对于每个温度 $T$，构建一个包含 $n_{\\mathrm{bins}}$ 个等间距箱中心的直方图，范围覆盖均值两侧的 $\\pm n_\\sigma$ 个标准差，并通过将正态概率密度函数乘以箱宽并进行归一化，将其转换为离散的箱概率。使用 $k_{\\mathrm{B}} = 1$。\n\n测试用例 1 (理想情况):\n- 粒子数 $N = 64$，候选温度 $\\{T_k\\} = [0.70, 0.78, 0.86, 0.94, 1.02]$，单位粒子均值 $\\mu(T) = a_0 + a_1 T + a_2/T$，其中 $a_0 = -6.0, a_1 = 0.1, a_2 = -0.5$，单位粒子方差 $\\sigma^2(T) = c_0 T + c_1$，其中 $c_0 = 0.05, c_1 = 0.02$，直方图参数 $n_{\\mathrm{bins}} = 201, n_\\sigma = 4.0$，目标区间 $[p_{\\mathrm{low}}, p_{\\mathrm{high}}] = [0.20, 0.40]$。\n\n测试用例 2 (窄直方图的边界条件):\n- 粒子数 $N = 64$，候选温度 $\\{T_k\\} = [0.70, 0.72, 0.74, 0.76, 0.78]$，单位粒子均值 $\\mu(T) = a_0 + a_1 T + a_2/T$，其中 $a_0 = -6.0, a_1 = 0.1, a_2 = -0.5$，单位粒子方差 $\\sigma^2(T) = c_0 T$，其中 $c_0 = 0.01$，直方图参数 $n_{\\mathrm{bins}} = 201, n_\\sigma = 4.0$，目标区间 $[p_{\\mathrm{low}}, p_{\\mathrm{high}}] = [0.15, 0.50]$。\n\n测试用例 3 (只有两个温度的边缘情况):\n- 粒子数 $N = 16$，候选温度 $\\{T_k\\} = [0.70, 1.00]$，单位粒子均值 $\\mu(T) = a_0 + a_1 T + a_2/T$，其中 $a_0 = -6.0, a_1 = 0.1, a_2 = -0.5$，单位粒子方差 $\\sigma^2(T) = c_0 T + c_1$，其中 $c_0 = 0.05, c_1 = 0.02$，直方图参数 $n_{\\mathrm{bins}} = 201, n_\\sigma = 4.0$，目标区间 $[p_{\\mathrm{low}}, p_{\\mathrm{high}}] = [0.20, 0.60]$。\n\n您的程序必须：\n- 对于每个测试用例，使用指定的参数和高斯模型为所有候选温度生成总能量直方图。\n- 使用从 Metropolis 准则推导出的正则期望的离散双重求和近似，计算所选方案中相邻温度之间的预期交换接受率。\n- 根据上述贪婪规则构建方案，从最低温度开始，到最高温度结束。\n- 生成单行输出，其中包含所有测试用例的结果，格式为用方括号括起来的逗号分隔列表。每个测试用例的结果必须是一个列表，包含：所选温度列表、所选方案中每对相邻温度的预期接受率列表、一个布尔值（指示所有接受率是否达到下限）和一个布尔值（指示所有接受率是否满足上限）。例如，输出格式必须为 $[ [ \\ldots ], [ \\ldots ], [ \\ldots ] ]$，其中每个内部列表包含 $[ \\text{温度列表}, \\text{接受率列表}, \\text{是否达到下限}, \\text{是否满足上限} ]$。\n\n所有能量和温度均使用约化的 Lennard-Jones 单位（无量纲）。不出现角度。输出中不含百分比；仅使用十进制数。",
            "solution": "该问题要求设计并实现一个算法，为并行回火（或称副本交换）蒙特卡洛模拟构建一个最优的温度方案。优化的目标是在保持相邻副本间的预期交换接受率处于指定目标区间内的同时，最小化覆盖给定温度范围（从最低温度 $T_{\\min}$ 到最高温度 $T_{\\max}$）所需的副本数量。该问题定义明确，并基于统计力学和计算模拟的原理。\n\n首先，我们建立理论背景。在正则 ($NVT$) 系综中，一个系统在温度 $T$ 下具有能量 $E$ 的概率由玻尔兹曼分布给出：\n$$\nP(E;T) = \\frac{1}{Z(T)} g(E) \\exp(-\\beta E)\n$$\n其中 $g(E)$ 是态密度（或简并度），$Z(T)$ 是正则配分函数，$\\beta = 1/(k_{\\mathrm{B}} T)$ 是逆温度。对于此问题，我们使用约化的 Lennard-Jones 单位，其中玻尔兹曼常数 $k_{\\mathrm{B}}$ 设为 1，因此 $\\beta = 1/T$。\n\n并行回火通过并行运行同一系统的多个模拟（副本）来增强采样，每个副本处于温度方案 $\\{T_0, T_1, \\ldots, T_{M-1}\\}$ 中的不同温度。系统会周期性地提议在相邻温度（例如 $T_a$ 和 $T_b$）的副本之间交换构型。如果副本 $a$ 的能量为 $E_a$，副本 $b$ 的能量为 $E_b$，则该交换以 Metropolis 概率被接受：\n$$\n\\alpha(E_a, E_b; \\beta_a, \\beta_b) = \\min\\left(1, \\exp\\left[(\\beta_a - \\beta_b)(E_b - E_a)\\right]\\right)\n$$\n这维持了包含所有副本的扩展系综的细致平衡条件。\n\n为了实现高效采样，这些交换的接受率应该相当高，但又不能高到让构型无法在温度空间中远距离移动。一个常见的目标是接受率在约 0.2 到 0.4 之间。预期接受率 $\\mathbb{E}[\\alpha]$ 是在假设两个副本的能量相互独立的情况下，$\\alpha$ 在联合能量分布 $P(E_a; T_a)P(E_b; T_b)$ 上的正则平均值。该问题提供了一个基于每次温度模拟获得的能量直方图的离散近似来计算该期望值：\n$$\n\\mathbb{E}[\\alpha(T_a, T_b)] \\approx \\sum_{i} \\sum_{j} p_i \\, q_j \\, \\min\\left(1, \\exp\\left[(\\beta_a - \\beta_b)(F_j - E_i)\\right]\\right)\n$$\n这里，$\\{E_i\\}$ 和 $\\{p_i\\}$ 是温度 $T_a$ 下直方图的能量箱中心和归一化概率，而 $\\{F_j\\}$ 和 $\\{q_j\\}$ 是温度 $T_b$ 的相应量。\n\n算法解决方案包括三个主要阶段：\n\n1.  **能量直方图生成**：\n    对于测试用例中提供的每个候选温度 $T_k$，我们必须首先生成一个离散的能量直方图。问题规定 $N$ 粒子系统的总能量 $E$ 被建模为高斯随机变量。该分布的均值和方差由以下公式给出：\n    *   均值：$\\bar{E}(T) = N \\cdot \\mu(T)$\n    *   方差：$\\text{Var}(E, T) = N \\cdot \\sigma^2(T)$\n    *   标准差：$S(T) = \\sqrt{\\text{Var}(E, T)}$\n    每个测试用例都提供了函数 $\\mu(T)$ 和 $\\sigma^2(T)$。\n    一个包含 $n_{\\mathrm{bins}}$ 个箱的直方图构建在以均值 $\\bar{E}(T)$ 为中心、跨越 $\\pm n_\\sigma$ 个标准差的能量范围内，即 $[\\bar{E}(T) - n_\\sigma S(T), \\bar{E}(T) + n_\\sigma S(T)]$。箱中心 $\\{E_i\\}$ 在此范围内等距分布。与每个箱中心 $E_i$ 相关联的概率 $p_i$ 是通过在 $E_i$ 处评估正态概率密度函数 (PDF) $f(E; \\bar{E}, \\text{Var})$，乘以箱宽 $\\Delta E$，最后对得到的概率进行归一化使其总和为 1 来确定的。\n\n2.  **接受率计算**：\n    实现一个函数，使用上面的离散公式计算 $\\mathbb{E}[\\alpha(T_a, T_b)]$。该函数以两个能量直方图（即温度 $T_a$ 和 $T_b$ 的箱中心和概率）作为输入。计算过程是对两个直方图的箱进行双重求和。这可以通过向量化操作高效实现。设 $\\mathbf{p}$ 为温度 $T_a$ 下直方图的概率向量，$\\mathbf{q}$ 为 $T_b$ 下的概率向量。我们构建一个能量差矩阵 $\\Delta E_{ij} = F_j - E_i$ 和一个相应的交换概率矩阵 $\\alpha_{ij} = \\min(1, \\exp((\\beta_a - \\beta_b)\\Delta E_{ij}))$。然后，预期接受率是概率向量的外积 $\\mathbf{p} \\otimes \\mathbf{q}$ 与接受矩阵 $\\mathbf{\\alpha}$ 的逐元素乘积之和：$\\mathbb{E}[\\alpha] = \\sum_{i,j} p_i q_j \\alpha_{ij}$。\n\n3.  **贪婪温度方案选择**：\n    问题的核心是一个贪婪算法，用于从候选温度集 $\\{T_k\\}$ 中选择一个最优的温度子集。该方案必须从 $T_{\\min}$（集合中的第一个温度）开始，到 $T_{\\max}$（最后一个温度）结束。目标是最小化副本数量，这通过采取尽可能大的温度步长来实现，但前提是该步长的预期接受率至少为 $p_{\\mathrm{low}}$。算法流程如下：\n    a. 用 $T_{\\min}$ 初始化方案。设当前温度在候选列表中的索引为 $i_{\\text{current}}$，初始值为 0。\n    b. 当当前温度不是 $T_{\\max}$ 时（即 $i_{\\text{current}}  \\text{len}(\\{T_k\\}) - 1$）：\n        i. 识别所有索引 $j > i_{\\text{current}}$ 的可能的下一个温度 $T_j$。\n        ii. 对于每个 $T_j$，计算预期接受率 $\\mathbb{E}[\\alpha(T_{i_{\\text{current}}}, T_j)]$。\n        iii. 将所有接受率大于或等于 $p_{\\mathrm{low}}$ 的索引 $j$ 收集到一个有效索引集 $J_{\\text{valid}}$ 中。\n        iv. 如果 $J_{\\text{valid}}$ 为空，则没有潜在的下一步满足最低接受标准。在这种情况下，为确保前进，我们必须选择候选列表中紧邻的下一个温度 $T_{i_{\\text{current}}+1}$，从而迈出最小的一步。此步骤被标记为未能达到下限 $p_{\\mathrm{low}}$。\n        v. 如果 $J_{\\text{valid}}$ 不为空，我们选择能最大化步长的下一个温度。这对应于从 $J_{\\text{valid}}$ 中选择具有最大索引的温度，即 $i_{\\text{next}} = \\max(J_{\\text{valid}})$。\n        vi. 将选定的温度 $T_{i_{\\text{next}}}$ 添加到方案中，记录相应的接受率，并更新 $i_{\\text{current}} = i_{\\text{next}}$。\n    c. 方案完全构建后，检查记录的接受率列表，以确定所有步骤是否都满足了上限 $p_{\\mathrm{high}}$。\n\n此过程将应用于每个测试用例，并且结果——所选的温度方案、相邻接受率列表以及两个指示所有步骤是否遵守了上下限的布尔值——将按要求格式化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # The p_tgt parameter is removed from the problem statement as the greedy\n    # rule provided (choose furthest valid temp) does not use it for tie-breaking.\n    test_cases = [\n        # Test case 1 (ideal path)\n        {\n            \"N\": 64,\n            \"T_k\": [0.70, 0.78, 0.86, 0.94, 1.02],\n            \"mu_params\": {\"a0\": -6.0, \"a1\": 0.1, \"a2\": -0.5},\n            \"sigma_sq_params\": {\"c0\": 0.05, \"c1\": 0.02},\n            \"n_bins\": 201,\n            \"n_sigma\": 4.0,\n            \"p_low\": 0.20,\n            \"p_high\": 0.40,\n        },\n        # Test case 2 (boundary condition with narrow histograms)\n        {\n            \"N\": 64,\n            \"T_k\": [0.70, 0.72, 0.74, 0.76, 0.78],\n            \"mu_params\": {\"a0\": -6.0, \"a1\": 0.1, \"a2\": -0.5},\n            \"sigma_sq_params\": {\"c0\": 0.01, \"c1\": 0.0},\n            \"n_bins\": 201,\n            \"n_sigma\": 4.0,\n            \"p_low\": 0.15,\n            \"p_high\": 0.50,\n        },\n        # Test case 3 (edge case with only two temperatures)\n        {\n            \"N\": 16,\n            \"T_k\": [0.70, 1.00],\n            \"mu_params\": {\"a0\": -6.0, \"a1\": 0.1, \"a2\": -0.5},\n            \"sigma_sq_params\": {\"c0\": 0.05, \"c1\": 0.02},\n            \"n_bins\": 201,\n            \"n_sigma\": 4.0,\n            \"p_low\": 0.20,\n            \"p_high\": 0.60,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        # The output format requires Python's default string representation of lists\n        # without spaces.\n        result_str = str(result).replace(\" \", \"\").replace(\"array(\",\"\").replace(\")\",\"\")\n        results.append(result_str)\n\n    print(f\"[{','.join(results)}]\")\n\ndef get_energy_histogram(T, N, mu_params, sigma_sq_params, n_bins, n_sigma):\n    \"\"\"\n    Generates a discrete energy histogram based on a Gaussian model.\n    \"\"\"\n    # Per-particle mean and variance functions\n    mu_T = mu_params[\"a0\"] + mu_params[\"a1\"] * T + mu_params.get(\"a2\", 0) / T if T != 0 else mu_params[\"a0\"]\n    sigma_sq_T = sigma_sq_params[\"c0\"] * T + sigma_sq_params.get(\"c1\", 0.0)\n\n    # Total energy mean and variance\n    mean_E = N * mu_T\n    var_E = N * sigma_sq_T\n    std_E = np.sqrt(var_E) if var_E > 0 else 0\n\n    # Define histogram range\n    E_min = mean_E - n_sigma * std_E\n    E_max = mean_E + n_sigma * std_E\n    \n    # Create bin centers\n    bin_centers = np.linspace(E_min, E_max, n_bins)\n    \n    # Calculate probabilities\n    if std_E > 1e-9: # Check for non-zero variance\n        bin_width = (E_max - E_min) / (n_bins - 1) if n_bins > 1 else 0\n        probabilities = norm.pdf(bin_centers, loc=mean_E, scale=std_E) * bin_width\n    else: # Delta function case if variance is zero\n        probabilities = np.zeros(n_bins)\n        center_idx = np.argmin(np.abs(bin_centers - mean_E))\n        probabilities[center_idx] = 1.0\n    \n    # Normalize probabilities\n    prob_sum = np.sum(probabilities)\n    if prob_sum > 0:\n        probabilities /= prob_sum\n        \n    return bin_centers, probabilities\n\ndef calculate_acceptance_rate(hist_a, T_a, hist_b, T_b):\n    \"\"\"\n    Computes the expected swap acceptance rate between two temperatures.\n    \"\"\"\n    E_i, p_i = hist_a\n    F_j, q_j = hist_b\n    \n    beta_a = 1.0 / T_a\n    beta_b = 1.0 / T_b\n    delta_beta = beta_a - beta_b\n\n    # Outer product to create a matrix of energy differences F_j - E_i\n    delta_E_matrix = F_j[None, :] - E_i[:, None]\n    \n    # Calculate acceptance probability for each pair of energy states\n    arg = delta_beta * delta_E_matrix\n    acceptance_matrix = np.minimum(1.0, np.exp(arg))\n\n    # Calculate expected value by summing over all state pairs weighted by their probabilities\n    expected_acceptance = np.sum(p_i[:, None] * q_j[None, :] * acceptance_matrix)\n    \n    return expected_acceptance\n\ndef process_case(case):\n    \"\"\"\n    Processes a single test case to generate the temperature schedule.\n    \"\"\"\n    T_k = np.array(case[\"T_k\"])\n    n_temps = len(T_k)\n\n    # Pre-compute all histograms\n    histograms = {T: get_energy_histogram(T, case[\"N\"], case[\"mu_params\"], case[\"sigma_sq_params\"], case[\"n_bins\"], case[\"n_sigma\"]) for T in T_k}\n\n    schedule = [T_k[0]]\n    acceptances = []\n    low_bound_met_flags = []\n    \n    current_idx = 0\n    while current_idx  n_temps - 1:\n        current_T = T_k[current_idx]\n        \n        valid_next_indices = []\n        for next_idx in range(current_idx + 1, n_temps):\n            next_T = T_k[next_idx]\n            acc_rate = calculate_acceptance_rate(histograms[current_T], current_T, histograms[next_T], next_T)\n            if acc_rate >= case[\"p_low\"]:\n                valid_next_indices.append(next_idx)\n\n        if not valid_next_indices:\n            # If no valid step, take the smallest possible step\n            next_step_idx = current_idx + 1\n            low_bound_met_flags.append(False)\n        else:\n            # Greedily choose the \"furthest\" valid temperature (largest index)\n            next_step_idx = max(valid_next_indices)\n            low_bound_met_flags.append(True)\n            \n        next_T = T_k[next_step_idx]\n        final_acc_rate = calculate_acceptance_rate(histograms[current_T], current_T, histograms[next_T], next_T)\n        \n        schedule.append(next_T)\n        acceptances.append(final_acc_rate)\n        \n        current_idx = next_step_idx\n\n    all_low_ok = all(low_bound_met_flags)\n    all_high_ok = all(acc = case[\"p_high\"] for acc in acceptances) if acceptances else True\n    \n    return [schedule, acceptances, all_low_ok, all_high_ok]\n\nsolve()\n```"
        }
    ]
}