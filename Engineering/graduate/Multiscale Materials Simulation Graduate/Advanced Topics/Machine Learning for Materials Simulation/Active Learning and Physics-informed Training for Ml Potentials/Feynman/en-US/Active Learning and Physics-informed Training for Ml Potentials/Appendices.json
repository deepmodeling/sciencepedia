{
    "hands_on_practices": [
        {
            "introduction": "A robust machine-learned potential often requires a diverse training set, which may involve combining data from different sources, such as Density Functional Theory calculations run with different codes or settings. This practice addresses a critical and practical challenge in data curation: establishing a common, thermodynamically consistent energy reference across these disparate datasets. This exercise  demonstrates why this alignment is necessary and how to perform it, ensuring the resulting model can correctly predict physically meaningful quantities like formation energies and phase stability.",
            "id": "3789397",
            "problem": "A research group is training a Machine Learning (ML) interatomic potential to be used in multiscale materials simulation. The training data comprise total energies, atomic forces, and stresses for configurations of multicomponent materials collected via two independent Density Functional Theory (DFT) workflows that use different pseudopotentials and settings. Let the datasets be indexed by $d \\in \\{1,2\\}$ and configurations by $i$, with per-configuration composition given by stoichiometric counts $n_s^{(i)}$ for species $s$ in a species set $\\mathcal{S}$. Denote the reported total energy by $E_d^{(i)}$, atomic positions by $\\mathbf{R}^{(i)}$, forces by $\\mathbf{F}_d^{(i)}$, and Cauchy stress by $\\boldsymbol{\\sigma}_d^{(i)}$. The ML potential predicts an energy $\\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})$ with parameters $\\boldsymbol{\\theta}$, forces $\\hat{\\mathbf{F}}(\\mathbf{R},\\boldsymbol{\\theta})=-\\nabla_{\\mathbf{R}}\\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})$, and stress $\\hat{\\boldsymbol{\\sigma}}(\\mathbf{R},\\boldsymbol{\\theta}) = \\frac{1}{V}\\frac{\\partial \\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\varepsilon}}$ for small homogeneous strain $\\boldsymbol{\\varepsilon}$ and volume $V$. In physics-informed training and active learning, the group seeks to mix the datasets to improve coverage of phase space while maintaining thermodynamic consistency across compositions.\n\nIt is known that absolute total energies from different electronic structure codes or settings can differ by dataset-specific constant shifts and species-dependent reference choices (e.g., different zeros of energy for isolated atoms or bulk reference phases). Consider how such shifts affect the physically relevant quantities in training and how to construct a consistent common energy reference when mixing datasets.\n\nSelect all options that present a physically consistent reasoning and a valid procedure to align energies across datasets from different codes or settings, suitable for physics-informed ML potential training and active learning, and justify the importance of doing so.\n\nA. Because forces are defined by $\\mathbf{F}=-\\nabla_{\\mathbf{R}}E$ and stresses by $\\boldsymbol{\\sigma}=\\frac{1}{V}\\frac{\\partial E}{\\partial \\boldsymbol{\\varepsilon}}$, adding a dataset-specific constant $b_d$ to all energies in dataset $d$ leaves $\\mathbf{F}$ and $\\boldsymbol{\\sigma}$ invariant, but biases any loss term that uses $E$. A consistent alignment can be obtained by introducing per-species reference energies $\\mu_s$ and per-dataset scalar offsets $b_d$, and estimating them by a least-squares fit over stoichiometries that enforces a common zero of formation energy, with a gauge-fixing constraint (e.g., anchoring one $b_{d^\\star}=0$). After alignment, train on $\\left(E_d^{(i)}-\\sum_{s\\in\\mathcal{S}} n_s^{(i)}\\mu_s - b_d\\right)$ together with forces and stresses.\n\nB. To remove systematic differences between datasets, subtract the mean per-atom energy of each configuration, i.e., replace $E_d^{(i)}$ by $E_d^{(i)} - \\frac{E_d^{(i)}}{N^{(i)}}$, where $N^{(i)}=\\sum_{s\\in\\mathcal{S}} n_s^{(i)}$. This equalizes scales across codes and preserves all relevant thermodynamics, making explicit alignment unnecessary.\n\nC. Since constant energy shifts do not affect $\\mathbf{F}$ or $\\boldsymbol{\\sigma}$, discard all energy labels and train only on forces and stresses. This guarantees correct thermodynamics (e.g., formation energies and phase stability) across compositions even when mixing datasets with different energy zeros.\n\nD. Use active learning driven by force uncertainty to select new configurations, and when mixing datasets, determine a per-configuration offset $c^{(i)}$ for each $E_d^{(i)}$ by matching forces: set $E_d^{(i)} \\mapsto E_d^{(i)} - c^{(i)}$ so that $\\hat{\\mathbf{F}}(\\mathbf{R}^{(i)},\\boldsymbol{\\theta})$ agrees with $\\mathbf{F}_d^{(i)}$. This enforces a common energy reference and avoids species-wise corrections.\n\nE. Compute formation energies within each dataset using that dataset’s own consistent elemental reference energies $E_{d,s}^{\\mathrm{ref}}$ (e.g., the energy per atom of the bulk standard state or isolated atom in the same DFT setup), i.e., $E_{d,\\mathrm{form}}^{(i)} = E_d^{(i)} - \\sum_{s\\in\\mathcal{S}} n_s^{(i)} E_{d,s}^{\\mathrm{ref}}$. Then estimate a single scalar offset $b_d$ for each dataset by using overlapping or nominally equivalent structures across datasets, anchoring one dataset (e.g., $b_{d^\\star}=0$). Train on $E_{d,\\mathrm{form}}^{(i)}-b_d$ together with $\\mathbf{F}$ and $\\boldsymbol{\\sigma}$ to ensure a common thermodynamic scale across codes.",
            "solution": "The user requires a critical validation of the problem statement followed by a detailed solution and evaluation of all provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Datasets are indexed by $d \\in \\{1, 2\\}$, representing two independent Density Functional Theory (DFT) workflows.\n-   Configurations are indexed by $i$.\n-   Composition of configuration $i$ is given by stoichiometric counts $n_s^{(i)}$ for species $s$ in a set $\\mathcal{S}$.\n-   Reported total energy from dataset $d$ for configuration $i$ is $E_d^{(i)}$.\n-   Atomic positions for configuration $i$ are $\\mathbf{R}^{(i)}$.\n-   Forces from dataset $d$ for configuration $i$ are $\\mathbf{F}_d^{(i)}$.\n-   Cauchy stress from dataset $d$ for configuration $i$ is $\\boldsymbol{\\sigma}_d^{(i)}$.\n-   The Machine Learning (ML) potential predicts an energy $\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$ with parameters $\\boldsymbol{\\theta}$.\n-   The ML potential predicts forces $\\hat{\\mathbf{F}}(\\mathbf{R}, \\boldsymbol{\\theta}) = -\\nabla_{\\mathbf{R}}\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$.\n-   The ML potential predicts stress $\\hat{\\boldsymbol{\\sigma}}(\\mathbf{R}, \\boldsymbol{\\theta}) = \\frac{1}{V}\\frac{\\partial \\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\varepsilon}}$ for a small homogeneous strain $\\boldsymbol{\\varepsilon}$ and volume $V$.\n-   The goal is to mix datasets for training, which requires maintaining thermodynamic consistency.\n-   It is stated that absolute total energies can differ by dataset-specific constant shifts and species-dependent reference energy choices.\n-   The question is to identify all valid and physically consistent procedures for aligning energies across these datasets.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in computational materials science and the development of interatomic potentials. The fact that absolute total energies from different electronic structure codes (or different settings within the same code, e.g., pseudopotentials, k-point meshes, cutoff energies) are not directly comparable is a fundamental and practical issue. The definitions of forces and stress as derivatives of energy are correct. The concept of using formation energies to establish a common thermodynamic reference is standard practice. The problem is scientifically sound.\n-   **Well-Posed:** The problem is well-posed. It clearly articulates a common challenge and asks for a valid method to address it. The goal—achieving a consistent common energy reference—is specific enough to allow for a determinable set of valid solutions.\n-   **Objective:** The problem is stated in precise, objective, and technical language. Terms like \"stoichiometric counts,\" \"Cauchy stress,\" and \"pseudopotentials\" are well-defined in the field. There is no ambiguity or subjectivity.\n\n**Step 3: Verdict and Action**\n-   **Verdict:** The problem statement is **valid**. It is scientifically sound, well-posed, and objective, describing a real-world challenge in multiscale materials simulation.\n-   **Action:** Proceed to derive the solution and analyze the given options.\n\n### Solution Derivation\n\nThe fundamental principle is that in quantum mechanics, only energy differences are physical observables. The absolute value of total energy is arbitrary and depends on the chosen zero of the energy scale. For a system with multiple chemical species, this ambiguity manifests in two main ways when comparing data from different sources (e.g., DFT codes with different settings):\n$1$. A species-dependent shift: The reference energy of each atomic species $s$ (e.g., the energy of an isolated atom or a bulk elemental phase) can differ.\n$2$. A global constant shift: There might be an additional constant offset applied to all energies from a given dataset due to numerical conventions or settings.\n\nTherefore, the total energy $E_d^{(i)}$ from dataset $d$ for a configuration $i$ with atom counts $n_s^{(i)}$ can be modeled in relation to a hypothetical, consistent underlying energy $E_{\\text{consistent}}^{(i)}$ as:\n$$E_d^{(i)} \\approx E_{\\text{consistent}}^{(i)} + \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d$$\nwhere $\\alpha_{d,s}$ represents the reference energy for species $s$ in dataset $d$'s specific setup, and $\\beta_d$ is a constant offset for dataset $d$. To train a single ML potential $\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$ that is predictive across all compositions and thermodynamically consistent, it must be trained on a target energy that is independent of the dataset $d$. This requires finding and removing the dataset-dependent shifts.\n\nCrucially, forces and stresses are derivatives of the energy with respect to atomic positions $\\mathbf{R}$ and strain $\\boldsymbol{\\varepsilon}$, respectively. The shift term, $\\sum_s n_s^{(i)} \\alpha_{d,s} + \\beta_d$, is a function of the atom counts $n_s^{(i)}$ but is independent of the specific atomic coordinates $\\mathbf{R}^{(i)}$ or the cell strain $\\boldsymbol{\\varepsilon}$. Consequently, its derivatives are zero:\n$$\\nabla_{\\mathbf{R}} \\left( \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d \\right) = \\mathbf{0}$$\n$$\\frac{\\partial}{\\partial \\boldsymbol{\\varepsilon}} \\left( \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d \\right) = \\mathbf{0}$$\nThis means that the forces $\\mathbf{F}_d^{(i)}$ and stresses $\\boldsymbol{\\sigma}_d^{(i)}$ from the different datasets are already on a common physical footing and can be used for training without any alignment. The challenge is confined to the energy values $E_d^{(i)}$.\n\nA valid procedure must propose a way to estimate and subtract the shifts, which are linear in the stoichiometric counts $n_s^{(i)}$ plus a constant, to create a consistent set of energy targets for the ML model.\n\n### Option-by-Option Analysis\n\n**A. Because forces are defined by $\\mathbf{F}=-\\nabla_{\\mathbf{R}}E$ and stresses by $\\boldsymbol{\\sigma}=\\frac{1}{V}\\frac{\\partial E}{\\partial \\boldsymbol{\\varepsilon}}$, adding a dataset-specific constant $b_d$ to all energies in dataset $d$ leaves $\\mathbf{F}$ and $\\boldsymbol{\\sigma}$ invariant, but biases any loss term that uses $E$. A consistent alignment can be obtained by introducing per-species reference energies $\\mu_s$ and per-dataset scalar offsets $b_d$, and estimating them by a least-squares fit over stoichiometries that enforces a common zero of formation energy, with a gauge-fixing constraint (e.g., anchoring one $b_{d^\\star}=0$). After alignment, train on $\\left(E_d^{(i)}-\\sum_{s\\in\\mathcal{S}} n_s^{(i)}\\mu_s - b_d\\right)$ together with forces and stresses.**\n\nThis option describes a robust and widely-used procedure. It correctly identifies that forces and stresses are invariant to the types of energy shifts in question. It proposes modeling the required energy correction for each data point $(i, d)$ as a linear function of its stoichiometry, $\\sum_s n_s^{(i)}\\mu_s$, plus a dataset-specific constant, $b_d$. These parameters $(\\mu_s, b_d)$ can be determined by a linear least-squares fit, typically performed iteratively during the training of the ML potential parameters $\\boldsymbol{\\theta}$. The loss function for the energies would aim to minimize discrepancies of the form:\n$$L_E = \\sum_{d, i} \\left\\| \\hat{E}(\\mathbf{R}^{(i)}, \\boldsymbol{\\theta}) - \\left( E_d^{(i)} - \\sum_{s \\in \\mathcal{S}} n_s^{(i)}\\mu_s - b_d \\right) \\right\\|^2$$\nwhere $\\hat{E}$, $\\mu_s$, and $b_d$ are all optimized. This system of equations for the linear parameters $(\\mu_s, b_d)$ is degenerate (possesses a gauge freedom), and the proposal correctly notes the necessity of a gauge-fixing constraint, such as setting one offset $b_{d^\\star}=0$. The entire procedure is physically sound and standard in the field.\n\n**Verdict: Correct**\n\n**B. To remove systematic differences between datasets, subtract the mean per-atom energy of each configuration, i.e., replace $E_d^{(i)}$ by $E_d^{(i)} - \\frac{E_d^{(i)}}{N^{(i)}}$, where $N^{(i)}=\\sum_{s\\in\\mathcal{S}} n_s^{(i)}$. This equalizes scales across codes and preserves all relevant thermodynamics, making explicit alignment unnecessary.**\n\nThis procedure is physically incorrect. The total energy $E$ is an extensive property, meaning it scales linearly with the system size $N$ for a homogeneous system. The energy per atom, $E/N$, is an intensive property. The proposed transformation, $E \\to E' = E - E/N = E(1 - 1/N)$, creates a new quantity $E'$ that is no longer extensive. For example, if we double the system size by combining two identical cells, the energy $E$ and atom count $N$ both double, but the transformed energy $E'$ does not: $E'_{\\text{double}} = 2E(1 - 1/(2N)) = 2E - E/N$, which is not equal to $2E' = 2E(1-1/N) = 2E - 2E/N$. This violation of extensivity invalidates the use of the resulting energies for any thermodynamic calculations, such as formation or reaction energies, which rely on proper energy balances. The claim that this \"preserves all relevant thermodynamics\" is false.\n\n**Verdict: Incorrect**\n\n**C. Since constant energy shifts do not affect $\\mathbf{F}$ or $\\boldsymbol{\\sigma}$, discard all energy labels and train only on forces and stresses. This guarantees correct thermodynamics (e.g., formation energies and phase stability) across compositions even when mixing datasets with different energy zeros.**\n\nThe premise is partly correct: training only on forces and stresses (a \"force-matching\" approach) circumvents the energy alignment problem. However, the conclusion is fatally flawed. The potential energy surface $E$ is mathematically the integral of the forces $\\mathbf{F}$. Integrating forces can determine the shape of the potential energy surface, but it leaves the constant of integration for each disconnected part of the configuration space undetermined. This means the model will have no information about the relative energies of different phases, stoichiometries, or molecular structures (e.g., reactants vs. products). Predicting phase stability requires comparing the energies (or free energies) of competing phases, e.g., phase A is more stable than B if $E_A < E_B$. By discarding all energy data, the ability to predict any thermodynamic property that relies on energy differences between disparate configurations is lost. Thus, this method cannot \"guarantee correct thermodynamics.\"\n\n**Verdict: Incorrect**\n\n**D. Use active learning driven by force uncertainty to select new configurations, and when mixing datasets, determine a per-configuration offset $c^{(i)}$ for each $E_d^{(i)}$ by matching forces: set $E_d^{(i)} \\mapsto E_d^{(i)} - c^{(i)}$ so that $\\hat{\\mathbf{F}}(\\mathbf{R}^{(i)},\\boldsymbol{\\theta})$ agrees with $\\mathbf{F}_d^{(i)}$. This enforces a common energy reference and avoids species-wise corrections.**\n\nThis proposal is conceptually incoherent and methodologically unsound. First, introducing a separate fitting parameter $c^{(i)}$ for each energy data point provides excessive flexibility, which would lead to perfect fitting of the training data but zero predictive power (overfitting). The model would not learn any underlying physics. Second, the mechanism proposed to determine $c^{(i)}$ is circular and nonsensical. A scalar offset $c^{(i)}$ to the target energy $E_d^{(i)}$ has no effect on the target forces $\\mathbf{F}_d^{(i)}$, which are provided by DFT. The forces $\\mathbf{F}_d^{(i)}$ are fixed inputs to the training process. The ML forces $\\hat{\\mathbf{F}}$ depend on the ML potential $\\hat{E}$, which is what we are trying to train. One cannot adjust the energy target $E_d^{(i)}$ with an offset $c^{(i)}$ to make forces match, as the energy offset does not change forces. The logic is self-contradictory.\n\n**Verdict: Incorrect**\n\n**E. Compute formation energies within each dataset using that dataset’s own consistent elemental reference energies $E_{d,s}^{\\mathrm{ref}}$ (e.g., the energy per atom of the bulk standard state or isolated atom in the same DFT setup), i.e., $E_{d,\\mathrm{form}}^{(i)} = E_d^{(i)} - \\sum_{s\\in\\mathcal{S}} n_s^{(i)} E_{d,s}^{\\mathrm{ref}}$. Then estimate a single scalar offset $b_d$ for each dataset by using overlapping or nominally equivalent structures across datasets, anchoring one dataset (e.g., $b_{d^\\star}=0$). Train on $E_{d,\\mathrm{form}}^{(i)}-b_d$ together with $\\mathbf{F}$ and $\\boldsymbol{\\sigma}$ to ensure a common thermodynamic scale across codes.**\n\nThis describes a valid, physically transparent, two-step procedure. Step one involves calculating the formation energy, $E_{d,\\mathrm{form}}^{(i)}$, for each configuration within its native dataset $d$. This correctly removes the dominant, species-dependent reference energy shifts. Since forces and stresses are unaffected by subtracting a term linear in atom counts, the original $\\mathbf{F}_d^{(i)}$ and $\\boldsymbol{\\sigma}_d^{(i)}$ remain the correct training targets. Step two addresses any remaining constant offset $b_d$ between the datasets' formation energy scales. Estimating these offsets, for instance by comparing the formation energies of identical structures present in multiple datasets, is a standard technique. Anchoring one dataset ($b_{d^\\star}=0$) is the necessary gauge fixing. Training the ML potential on the aligned formation energies $E_{d,\\mathrm{form}}^{(i)}-b_d$ results in a model with a consistent thermodynamic reference scale. This procedure is a well-established and valid alternative to the simultaneous fitting described in option A.\n\n**Verdict: Correct**",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "One of the primary applications of machine-learned potentials is enabling large-scale molecular dynamics (MD) simulations, which are impossible with more expensive first-principles methods. However, the stability of an MD simulation hinges on the mathematical quality of the underlying potential energy surface. This exercise  explores the fundamental requirement that the potential energy $E(\\mathbf{R}, \\mathbf{Z})$ be continuously differentiable (at least $C^1$) to produce smooth, conservative forces, and introduces diagnostic tests to detect non-physical discontinuities that can arise from numerical artifacts like descriptor cutoffs.",
            "id": "3789446",
            "problem": "Consider a Machine Learning (ML) interatomic potential represented by a differentiable scalar field $E(\\mathbf{R}, \\mathbf{Z})$ on atomic positions $\\mathbf{R} = (\\mathbf{R}_1, \\dots, \\mathbf{R}_N)$ and species identifiers $\\mathbf{Z} = (Z_1, \\dots, Z_N)$, intended for use in Molecular Dynamics (MD). The force on atom $i$ is defined by $\\mathbf{F}_i(\\mathbf{R}, \\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} E(\\mathbf{R}, \\mathbf{Z})$. The potential employs local descriptors truncated at a cutoff radius $r_c$, possibly with a switching function that transitions interactions to zero near $r_c$. In multiscale materials simulation, training and validation must ensure physically consistent trajectories and stable time integration.\n\nWhich option best formulates the role of differentiability of $E(\\mathbf{R}, \\mathbf{Z})$ with respect to positions for stable MD and proposes a physics-informed, falsifiable diagnostic test to detect nonphysical discontinuities arising from descriptor truncation or cutoff switching?\n\nA. Differentiability of $E(\\mathbf{R}, \\mathbf{Z})$ with respect to $\\mathbf{R}$ ensures that $\\mathbf{F}(\\mathbf{R}, \\mathbf{Z}) = -\\nabla_{\\mathbf{R}} E(\\mathbf{R}, \\mathbf{Z})$ is at least continuous; if $\\mathbf{F}$ is locally Lipschitz in $\\mathbf{R}$, existence and uniqueness of solutions to the Newtonian initial value problem $m_i \\ddot{\\mathbf{R}}_i = \\mathbf{F}_i(\\mathbf{R}, \\mathbf{Z})$ follow, and symplectic integrators avoid spurious impulses. A diagnostic consists of two parts: (i) a one-dimensional radial sweep in which a neighbor’s pair distance $r_{jk}(s)$ is varied smoothly across $r_c$, recording $E(s)$ and $\\mathbf{F}(s)$ and testing for boundedness of $\\lim_{\\Delta s \\to 0} \\|\\Delta \\mathbf{F}\\|/\\Delta r$ at $r_{jk} = r_c$; and (ii) a closed-loop work test in configuration space that evaluates $\\oint \\mathbf{F}(\\mathbf{R}, \\mathbf{Z}) \\cdot d\\mathbf{R}$ along a small loop traversing the cutoff region, which must be $0$ (within tolerance) for a conservative, differentiable potential. Any nonzero circulation or force jump independent of step size indicates nonphysical discontinuities from descriptor truncation or cutoff switching.\n\nB. Differentiability of $E(\\mathbf{R}, \\mathbf{Z})$ with respect to $\\mathbf{R}$ is not necessary for MD stability because discontinuous forces can be controlled by choosing a sufficiently small time step; a practical test is to run a long MD trajectory and check whether the total energy fluctuates within an acceptable bound without monitoring forces near the cutoff.\n\nC. Stable MD requires $E(\\mathbf{R}, \\mathbf{Z})$ to be twice differentiable and globally convex so that the Hessian $\\nabla^2_{\\mathbf{R}} E(\\mathbf{R}, \\mathbf{Z})$ is positive definite; a suitable test is to compute $\\nabla^2_{\\mathbf{R}} E(\\mathbf{R}, \\mathbf{Z})$ at representative configurations far from cutoffs and verify positive definiteness, which guarantees no discontinuities occur at descriptor truncations.\n\nD. Continuity of $E(\\mathbf{R}, \\mathbf{Z})$ with respect to $\\mathbf{R}$ is sufficient for MD stability; to detect cutoff issues, apply a linear tapering function at $r_c$ to enforce continuous $E$ and then test only $E$ differences $\\Delta E$ across $r_{jk} \\approx r_c$, ignoring the behavior of $\\mathbf{F}$ because force discontinuities average out over time.",
            "solution": "The foundational starting point is Newton’s second law and the definition of forces from a potential energy. For atom $i$ with mass $m_i$, the motion obeys\n$$\nm_i \\ddot{\\mathbf{R}}_i(t) = \\mathbf{F}_i(\\mathbf{R}(t), \\mathbf{Z}) \\quad \\text{with} \\quad \\mathbf{F}_i(\\mathbf{R}, \\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} E(\\mathbf{R}, \\mathbf{Z}).\n$$\nThis is a system of ordinary differential equations (ODEs). The existence and uniqueness theorem for ODEs (Picard–Lindelöf) ensures that if the right-hand side $\\mathbf{F}(\\mathbf{R}, \\mathbf{Z})$ is locally Lipschitz continuous in $\\mathbf{R}$, then given initial conditions $(\\mathbf{R}(0), \\dot{\\mathbf{R}}(0))$, there exists a unique solution locally in time. For a scalar potential $E(\\mathbf{R}, \\mathbf{Z})$ that is at least $C^1$ in $\\mathbf{R}$, the force field $\\mathbf{F}(\\mathbf{R}, \\mathbf{Z})$ is continuous; if $E$ is $C^2$, then $\\mathbf{F}$ is $C^1$, and typically locally Lipschitz. Discontinuities in $\\mathbf{F}$ arise when $E$ is non-differentiable with respect to $\\mathbf{R}$, for example due to descriptor truncation or improper cutoff switching, which can produce impulsive forces that violate the assumptions behind standard MD integrators (such as velocity Verlet) and can lead to numerical instability and nonphysical trajectories.\n\nFurthermore, because $\\mathbf{F}$ arises as a gradient of a scalar potential, it is a conservative field: the work along any closed path in configuration space must be zero,\n$$\n\\oint \\mathbf{F}(\\mathbf{R}, \\mathbf{Z}) \\cdot d\\mathbf{R} = 0,\n$$\nprovided $E(\\mathbf{R}, \\mathbf{Z})$ is differentiable on and within the loop. If discontinuities or nonconservative behavior are introduced by descriptor truncation or cutoff switching, this circulation can become nonzero.\n\nTo design a physics-informed test, consider a parametrized path $\\mathbf{R}(s)$ that moves one neighbor across the cutoff $r_c$ while keeping other atoms fixed or moving smoothly. Along this path,\n$$\n\\frac{dE}{ds} = \\sum_{i=1}^N \\nabla_{\\mathbf{R}_i} E(\\mathbf{R}(s), \\mathbf{Z}) \\cdot \\frac{d\\mathbf{R}_i}{ds} = -\\sum_{i=1}^N \\mathbf{F}_i(\\mathbf{R}(s), \\mathbf{Z}) \\cdot \\frac{d\\mathbf{R}_i}{ds}.\n$$\nAt $r_{jk}(s) = r_c$, if $E$ is $C^1$, the one-sided limits of $\\mathbf{F}(\\mathbf{R}(s), \\mathbf{Z})$ and $\\frac{dE}{ds}$ should match. A discontinuity manifests as a jump in $\\mathbf{F}$ that does not diminish as the step size shrinks. A complementary check is to construct a small closed loop in configuration space that encircles the cutoff region and compute\n$$\n\\oint \\mathbf{F}(\\mathbf{R}, \\mathbf{Z}) \\cdot d\\mathbf{R},\n$$\nwhich should be $0$ within numerical tolerance for a conservative, differentiable potential; a nonzero value indicates nonconservative artifacts.\n\nThese principles motivate active learning and physics-informed training strategies: penalizing large gradients of descriptors near $r_c$, enforcing smooth cutoff functions that are at least $C^1$ (preferably $C^2$), including force consistency losses, and querying configurations where the measured force jump or closed-loop work exceeds a threshold to augment the training set.\n\nOption-by-option analysis:\n\nA. This option correctly ties differentiability of $E(\\mathbf{R}, \\mathbf{Z})$ to the continuity and local Lipschitz character of $\\mathbf{F}(\\mathbf{R}, \\mathbf{Z})$, which underpins existence and uniqueness for the ODE $m_i \\ddot{\\mathbf{R}}_i = \\mathbf{F}_i(\\mathbf{R}, \\mathbf{Z})$. It explicitly proposes two rigorous diagnostics: a local sweep across $r_c$ that examines the behavior of $\\|\\Delta \\mathbf{F}\\|/\\Delta r$ as the step size shrinks, and a closed-loop circulation test $\\oint \\mathbf{F} \\cdot d\\mathbf{R}$ near the cutoff. Both directly target nonphysical discontinuities and nonconservative artifacts introduced by descriptor truncation or cutoff switching. Verdict — Correct.\n\nB. This option claims differentiability is unnecessary and suggests that a sufficiently small time step can stabilize discontinuous forces. However, discontinuities in $\\mathbf{F}$ can generate impulses that violate the assumptions of standard MD integrators and undermine the ODE’s existence–uniqueness conditions based on local Lipschitz continuity. The proposed test—monitoring long-time total energy fluctuations without examining forces near $r_c$—can miss localized nonphysical jumps and nonconservative artifacts. Verdict — Incorrect.\n\nC. This option demands global convexity and positive definiteness of the Hessian $\\nabla^2_{\\mathbf{R}} E(\\mathbf{R}, \\mathbf{Z})$, which is neither necessary nor typical for realistic materials potentials, where $E(\\mathbf{R}, \\mathbf{Z})$ is often nonconvex to accommodate bonding, phase changes, and defects. Moreover, evaluating the Hessian far from cutoffs does not diagnose discontinuities introduced at $r_c$; a potential could be nonconvex yet perfectly differentiable, or have discontinuities localized at cutoffs while being well behaved elsewhere. Verdict — Incorrect.\n\nD. This option asserts that continuity of $E(\\mathbf{R}, \\mathbf{Z})$ is sufficient for MD stability and focuses only on $E$ continuity near $r_c$. However, stable MD requires at least continuous forces, i.e., $E$ should be $C^1$ in $\\mathbf{R}$. Linear tapering at $r_c$ can enforce continuity of $E$ while leaving $\\nabla_{\\mathbf{R}} E$ discontinuous, producing force jumps. Ignoring the behavior of $\\mathbf{F}$ and relying on energy differences alone fails to detect nonphysical discontinuities in forces. Verdict — Incorrect.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Active learning provides a powerful framework for systematically improving a potential by intelligently selecting new configurations to add to the training set. Rather than sampling randomly, we want to choose data that is most informative. This hands-on problem  implements a sophisticated and effective exploration strategy known as maximin distance sampling, which identifies candidate structures that are most dissimilar to the existing training data. You will use the Maximum Mean Discrepancy (MMD) to define a robust, kernel-based distance metric between entire atomic configurations, providing a practical foundation for building a robust active learning loop.",
            "id": "3789380",
            "problem": "Consider the task of active learning for Machine Learning (ML) interatomic potentials in multiscale materials simulation. In Molecular Dynamics (MD), each frame can be represented by a set of per-atom descriptor vectors embedded in a finite-dimensional Euclidean space. Let each descriptor vector be an element $x \\in \\mathbb{R}^d$, where $d$ is the descriptor dimension. Suppose we have a current labeled set of frames $\\mathcal{S} = \\{ S_1, S_2, \\dots, S_m \\}$, and an unlabeled batch of candidate frames $\\mathcal{C} = \\{ C_1, C_2, \\dots, C_k \\}$. Each frame $S_i$ or $C_j$ is a finite set of descriptor vectors, respectively $S_i = \\{ s_{i,1},\\dots,s_{i,n_i} \\} \\subset \\mathbb{R}^d$ and $C_j = \\{ c_{j,1},\\dots,c_{j,p_j} \\} \\subset \\mathbb{R}^d$.\n\nWe define similarity via a Gaussian Radial Basis Function (RBF) kernel induced by a positive semidefinite metric matrix. Let $M \\in \\mathbb{R}^{d \\times d}$ be symmetric positive semidefinite, and let $\\ell > 0$ be a length scale. The kernel between two descriptor vectors $x,y \\in \\mathbb{R}^d$ is\n$$\nk(x,y) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (x-y)^\\top M (x-y) \\right).\n$$\nThis kernel induces an inner product in a Reproducing Kernel Hilbert Space (RKHS), and the kernel mean embedding of a frame $A = \\{ a_1,\\dots,a_{n_A} \\}$ is the empirical mean element $\\mu_A = \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i)$, where $\\phi(\\cdot)$ is the feature map associated with $k(\\cdot,\\cdot)$. The squared distance between mean embeddings is the biased squared Maximum Mean Discrepancy (MMD),\n$$\n\\operatorname{MMD}^2_{\\text{biased}}(A,B) = \\left\\| \\mu_A - \\mu_B \\right\\|_{\\mathcal{H}}^2\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j)\n+ \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j)\n- \\frac{2}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j),\n$$\nwhich is well-defined for any $n_A \\ge 1$ and $n_B \\ge 1$.\n\nMaximin distance sampling in descriptor space selects the candidate frame $C^* \\in \\mathcal{C}$ that maximizes its minimum distance to the current set $\\mathcal{S}$, where the distance between frames is the RKHS norm of the difference of mean embeddings. Concretely, define\n$$\nd(C,\\mathcal{S}) = \\min_{S \\in \\mathcal{S}} \\sqrt{ \\operatorname{MMD}^2_{\\text{biased}}(C,S) }.\n$$\nThe maximin choice is\n$$\nC^* = \\arg\\max_{C \\in \\mathcal{C}} d(C,\\mathcal{S}).\n$$\nWhen multiple candidates attain the same maximum value of $d(C,\\mathcal{S})$, the tie must be resolved by returning the smallest candidate index (that is, the smallest $j$ such that $C_j$ attains the maximum).\n\nYour task is to write a complete program that:\n- Implements the RBF kernel $k(x,y)$ parameterized by $M$ and $\\ell$.\n- Computes $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$ for any two frames $A,B$.\n- For each test case, computes $d(C_j,\\mathcal{S})$ for all candidates $C_j$, selects $C^*$ according to the maximin rule, and returns the index of $C^*$ as an integer.\n\nNo physical units apply in this problem; all quantities are dimensionless. Angles are not used. Percentages are not used.\n\nTest Suite:\nFor each test case, you are given $d$, $M$, $\\ell$, the current set $\\mathcal{S}$, and the candidate set $\\mathcal{C}$. All descriptor vectors are provided explicitly as lists of components. Your program must process the following four cases:\n\n- Case $1$ (happy path, isotropic metric):\n  - $d = 2$, $M = I_2$, $\\ell = 1.0$.\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0), (1.0, 0.0), (0.5, 0.5) \\}$,\n    - $S_2 = \\{ (2.0, 2.0), (2.5, 2.0) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (3.0, 3.0), (2.8, 3.2) \\}$,\n    - $C_2 = \\{ (0.9, 0.1), (0.6, 0.4) \\}$,\n    - $C_3 = \\{ (-1.0, -1.0), (-0.5, -0.2) \\}$.\n\n- Case $2$ (candidate identical to a current frame, isotropic metric, different length scale):\n  - $d = 2$, $M = I_2$, $\\ell = 0.8$.\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0), (1.0, 0.0) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.0, 0.0), (1.0, 0.0) \\}$,\n    - $C_2 = \\{ (3.0, 0.0), (3.5, 0.5) \\}$,\n    - $C_3 = \\{ (1.2, 0.1), (1.1, -0.1) \\}$.\n\n- Case $3$ (anisotropic metric, higher dimension):\n  - $d = 3$, $M = \\operatorname{diag}(2.0, 1.0, 0.5)$, $\\ell = 1.5$.\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0, 0.0), (0.2, -0.1, 0.0) \\}$,\n    - $S_2 = \\{ (1.0, 0.0, 0.0), (1.1, 0.1, -0.1) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.9, 0.0, 0.0), (1.2, -0.2, 0.2) \\}$,\n    - $C_2 = \\{ (-1.0, 0.0, 0.0), (-1.2, 0.2, -0.1) \\}$,\n    - $C_3 = \\{ (0.0, 1.0, 0.0), (0.0, 1.2, 0.2) \\}$.\n\n- Case $4$ (single-descriptor frames, isotropic metric, small length scale):\n  - $d = 2$, $M = I_2$, $\\ell = 0.5$.\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0) \\}$,\n    - $S_2 = \\{ (0.2, 0.2) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.0, 0.1) \\}$,\n    - $C_2 = \\{ (1.0, 1.0) \\}$,\n    - $C_3 = \\{ (0.25, 0.25) \\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4]$, where each $r_i$ is the selected candidate index in integer form for Case $i$. Indices are $1$-based with respect to $\\mathcal{C} = \\{ C_1, C_2, \\dots \\}$ in each case.",
            "solution": "We present a principled derivation and algorithm for maximin distance sampling in descriptor space using a kernel-induced metric, suitable for active learning of Machine Learning (ML) interatomic potentials. The objective is to select a candidate MD frame that is maximally dissimilar to the current labeled frames in terms of physically meaningful descriptors while respecting symmetry and invariance encoded by the kernel.\n\nStep $1$: Kernel-induced similarity and metric. Let $x,y \\in \\mathbb{R}^d$ be descriptor vectors. A Gaussian Radial Basis Function (RBF) kernel with an anisotropic metric matrix $M \\in \\mathbb{R}^{d \\times d}$ and positive length scale $\\ell$ is defined by\n$$\nk(x,y) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (x-y)^\\top M (x-y) \\right).\n$$\nIf $M$ is symmetric positive semidefinite, then the quantity $(x-y)^\\top M (x-y)$ is a valid squared seminorm, and $k(x,y)$ is positive definite. This ensures existence of a Reproducing Kernel Hilbert Space (RKHS) $\\mathcal{H}$ and a feature map $\\phi : \\mathbb{R}^d \\to \\mathcal{H}$ such that $k(x,y) = \\langle \\phi(x), \\phi(y) \\rangle_{\\mathcal{H}}$. Physically, $M$ can encode anisotropic scalings across descriptor dimensions, reflecting physics-informed weighting of descriptor components (for example, strengthening sensitivity along certain invariant features).\n\nStep $2$: Mean embedding of a frame. For a frame $A = \\{ a_1,\\dots,a_{n_A} \\}$, define its empirical mean element in $\\mathcal{H}$ as\n$$\n\\mu_A = \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i).\n$$\nThis construction aggregates per-atom information into a frame-level representation that preserves symmetries captured by the kernel. The RKHS norm $\\|\\mu_A - \\mu_B\\|_{\\mathcal{H}}$ measures distance between frames $A$ and $B$ through their distributions of descriptors.\n\nStep $3$: Squared Maximum Mean Discrepancy (MMD). The squared distance between the mean embeddings is\n$$\n\\left\\| \\mu_A - \\mu_B \\right\\|_{\\mathcal{H}}^2\n= \\left\\langle \\mu_A, \\mu_A \\right\\rangle_{\\mathcal{H}}\n+ \\left\\langle \\mu_B, \\mu_B \\right\\rangle_{\\mathcal{H}}\n- 2 \\left\\langle \\mu_A, \\mu_B \\right\\rangle_{\\mathcal{H}},\n$$\nand, by the reproducing property,\n$$\n\\left\\langle \\mu_A, \\mu_A \\right\\rangle_{\\mathcal{H}}\n= \\left\\langle \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i), \\frac{1}{n_A} \\sum_{j=1}^{n_A} \\phi(a_j) \\right\\rangle_{\\mathcal{H}}\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} \\left\\langle \\phi(a_i), \\phi(a_j) \\right\\rangle_{\\mathcal{H}}\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j).\n$$\nSimilarly,\n$$\n\\left\\langle \\mu_B, \\mu_B \\right\\rangle_{\\mathcal{H}} = \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j),\n\\quad\n\\left\\langle \\mu_A, \\mu_B \\right\\rangle_{\\mathcal{H}} = \\frac{1}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j).\n$$\nTherefore,\n$$\n\\operatorname{MMD}^2_{\\text{biased}}(A,B)\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j)\n+ \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j)\n- \\frac{2}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j).\n$$\nThis biased estimator equals the squared RKHS distance between empirical mean embeddings and is defined for any $n_A \\ge 1$ and $n_B \\ge 1$, which is essential for frames containing a single descriptor vector.\n\nStep $4$: Maximin distance selection. For a candidate $C$ and a current set $\\mathcal{S} = \\{ S_1, \\dots, S_m \\}$, define the candidate-to-set distance\n$$\nd(C,\\mathcal{S}) = \\min_{S \\in \\mathcal{S}} \\sqrt{ \\operatorname{MMD}^2_{\\text{biased}}(C,S) }.\n$$\nMaximin sampling selects\n$$\nC^* = \\arg\\max_{C \\in \\mathcal{C}} d(C,\\mathcal{S}).\n$$\nThis rule promotes exploration by prioritizing candidates that are maximally dissimilar (in RKHS mean embedding distance) to the nearest current frame. From a physics-informed perspective, this reduces extrapolation risk by ensuring new frames occupy underrepresented regions of descriptor space, respecting the anisotropic scaling encoded in $M$ and characteristic length $\\ell$.\n\nStep $5$: Algorithmic implementation.\n- Compute pairwise kernel matrices $K_{AA}$, $K_{BB}$, and $K_{AB}$ via\n$$\nK_{ij}^{AB} = k(a_i,b_j) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (a_i-b_j)^\\top M (a_i-b_j) \\right).\n$$\nEfficient evaluation uses the identity\n$$\n(a-b)^\\top M (a-b) = a^\\top M a + b^\\top M b - 2 a^\\top M b,\n$$\nprecomputing $a^\\top M a$, $b^\\top M b$, and $a^\\top M b$ for all pairs.\n- Compute $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$ as above.\n- For each candidate $C_j$, evaluate $d(C_j,\\mathcal{S}) = \\min_{S_i \\in \\mathcal{S}} \\sqrt{\\operatorname{MMD}^2_{\\text{biased}}(C_j,S_i)}$.\n- Select $C^*$ by maximizing $d(C_j,\\mathcal{S})$ across $j$. Break ties by the smallest $j$ (first maximum encountered).\n\nStep $6$: Edge cases and numerical considerations.\n- Because $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$ is nonnegative by construction, numerical roundoff may produce tiny negative values; enforce nonnegativity by clamping below at $0$ before taking the square root.\n- When candidates match a current frame exactly, the kernel matrices yield $\\operatorname{MMD}^2_{\\text{biased}}(C,S) = 0$, hence $d(C,\\mathcal{S}) = 0$, and the algorithm correctly avoids selecting that candidate unless all candidates are equally close.\n\nStep $7$: Output specification. For each of the four test cases, return the $1$-based index of the selected candidate as an integer. Aggregate the four integers into a single line in the format $[r_1,r_2,r_3,r_4]$.\n\nThe provided program follows this derivation, implements the kernel and MMD computations, applies the maximin rule for each test case, and prints the required single-line output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rbf_kernel_matrix(X: np.ndarray, Y: np.ndarray, M: np.ndarray, ell: float) -> np.ndarray:\n    \"\"\"\n    Compute the Gaussian RBF kernel matrix K between two sets of descriptor vectors X and Y\n    using an anisotropic metric M and length scale ell.\n\n    k(x,y) = exp( - (1/(2*ell^2)) * (x - y)^T M (x - y) )\n\n    Parameters:\n        X: shape (n_x, d)\n        Y: shape (n_y, d)\n        M: shape (d, d), symmetric positive semidefinite\n        ell: positive float\n\n    Returns:\n        K: shape (n_x, n_y)\n    \"\"\"\n    # Precompute terms using quadratic form identity:\n    # (x - y)^T M (x - y) = x^T M x + y^T M y - 2 x^T M y\n    X_M = X @ M           # shape (n_x, d)\n    Y_M = Y @ M           # shape (n_y, d)\n\n    xMx = np.einsum('ij,ij->i', X, X_M)  # shape (n_x,)\n    yMy = np.einsum('ij,ij->i', Y, Y_M)  # shape (n_y,)\n\n    cross = X @ M @ Y.T                   # shape (n_x, n_y)\n\n    # Broadcast to form pairwise metric distances squared\n    dist2 = xMx[:, None] + yMy[None, :] - 2.0 * cross\n\n    # Numerical safety: ensure non-negative due to PSD M\n    dist2 = np.maximum(dist2, 0.0)\n\n    K = np.exp(-0.5 * dist2 / (ell ** 2))\n    return K\n\ndef mmd2_biased(A: np.ndarray, B: np.ndarray, M: np.ndarray, ell: float) -> float:\n    \"\"\"\n    Compute the biased squared MMD between two frames A and B (sets of descriptors),\n    using the Gaussian RBF kernel with metric M and length scale ell.\n\n    MMD^2_biased(A,B) = (1/n_A^2) sum_{i,j} k(a_i,a_j)\n                      + (1/n_B^2) sum_{i,j} k(b_i,b_j)\n                      - (2/(n_A n_B)) sum_{i,j} k(a_i,b_j)\n    \"\"\"\n    nA = A.shape[0]\n    nB = B.shape[0]\n\n    KA = rbf_kernel_matrix(A, A, M, ell)\n    KB = rbf_kernel_matrix(B, B, M, ell)\n    KAB = rbf_kernel_matrix(A, B, M, ell)\n\n    term_A = np.sum(KA) / (nA ** 2)\n    term_B = np.sum(KB) / (nB ** 2)\n    term_AB = (2.0 * np.sum(KAB)) / (nA * nB)\n\n    mmd2 = term_A + term_B - term_AB\n\n    # Clamp small negative due to numerical roundoff\n    if mmd2 < 0.0 and mmd2 > -1e-12:\n        mmd2 = 0.0\n\n    return float(mmd2)\n\ndef maximin_candidate_index(current_frames, candidate_frames, M, ell):\n    \"\"\"\n    Given a list of current frames and candidate frames (each a numpy array of shape (n_i, d)),\n    return the 1-based index of the candidate that maximizes the minimum sqrt(MMD^2_biased)\n    to the current frames. Ties are broken by smallest index (np.argmax behavior).\n    \"\"\"\n    min_distances = []\n    for C in candidate_frames:\n        # Compute distance to each current frame\n        dists = []\n        for S in current_frames:\n            mmd2 = mmd2_biased(C, S, M, ell)\n            # Ensure non-negative before sqrt\n            dists.append(np.sqrt(max(mmd2, 0.0)))\n        # Candidate-to-set distance is min over current frames\n        min_distances.append(min(dists))\n\n    # Select the candidate with maximum min-distance; 1-based index\n    # np.argmax returns first occurrence in case of ties -> smallest index tie-break\n    best_idx = int(np.argmax(min_distances)) + 1\n    return best_idx\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    test_cases = []\n\n    # Case 1\n    d1 = 2\n    M1 = np.eye(d1)\n    ell1 = 1.0\n    S1_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0],\n                     [0.5, 0.5]])\n    S1_2 = np.array([[2.0, 2.0],\n                     [2.5, 2.0]])\n    C1_1 = np.array([[3.0, 3.0],\n                     [2.8, 3.2]])\n    C1_2 = np.array([[0.9, 0.1],\n                     [0.6, 0.4]])\n    C1_3 = np.array([[-1.0, -1.0],\n                     [-0.5, -0.2]])\n    test_cases.append(( [S1_1, S1_2], [C1_1, C1_2, C1_3], M1, ell1 ))\n\n    # Case 2\n    d2 = 2\n    M2 = np.eye(d2)\n    ell2 = 0.8\n    S2_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0]])\n    C2_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0]])  # identical to S2_1\n    C2_2 = np.array([[3.0, 0.0],\n                     [3.5, 0.5]])\n    C2_3 = np.array([[1.2, 0.1],\n                     [1.1, -0.1]])\n    test_cases.append(( [S2_1], [C2_1, C2_2, C2_3], M2, ell2 ))\n\n    # Case 3\n    d3 = 3\n    M3 = np.diag([2.0, 1.0, 0.5])\n    ell3 = 1.5\n    S3_1 = np.array([[0.0, 0.0, 0.0],\n                     [0.2, -0.1, 0.0]])\n    S3_2 = np.array([[1.0, 0.0, 0.0],\n                     [1.1, 0.1, -0.1]])\n    C3_1 = np.array([[0.9, 0.0, 0.0],\n                     [1.2, -0.2, 0.2]])\n    C3_2 = np.array([[-1.0, 0.0, 0.0],\n                     [-1.2, 0.2, -0.1]])\n    C3_3 = np.array([[0.0, 1.0, 0.0],\n                     [0.0, 1.2, 0.2]])\n    test_cases.append(( [S3_1, S3_2], [C3_1, C3_2, C3_3], M3, ell3 ))\n\n    # Case 4\n    d4 = 2\n    M4 = np.eye(d4)\n    ell4 = 0.5\n    S4_1 = np.array([[0.0, 0.0]])\n    S4_2 = np.array([[0.2, 0.2]])\n    C4_1 = np.array([[0.0, 0.1]])\n    C4_2 = np.array([[1.0, 1.0]])\n    C4_3 = np.array([[0.25, 0.25]])\n    test_cases.append(( [S4_1, S4_2], [C4_1, C4_2, C4_3], M4, ell4 ))\n\n    results = []\n    for current_frames, candidate_frames, M, ell in test_cases:\n        idx = maximin_candidate_index(current_frames, candidate_frames, M, ell)\n        results.append(idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}