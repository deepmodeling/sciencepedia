{
    "hands_on_practices": [
        {
            "introduction": "多尺度建模的一个核心任务是从底层的微观物理中推导出宏观属性。本实践提供了一个这种“自下而上”方法的具体示例，您将使用柯西-玻恩假设（Cauchy-Born assumption）将一个简单的原子对势与晶格的连续介质弹性张量联系起来 。掌握这项技术是理解材料信息如何在不同尺度间传递的基础。",
            "id": "3799940",
            "problem": "考虑一个二维三角布拉维晶格，其每个原胞含一个原子，最近邻间距为 $a$。根据柯西-玻恩假定，一个均匀小应变 $\\,\\boldsymbol{\\varepsilon}\\,$ 将每个参考键矢量 $\\mathbf{R}$ 映射为 $\\mathbf{r} = (\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{R}$，其中 $\\mathbf{I}$ 是单位张量。单原子能量由中心对势 $\\phi(r)$ 建模，每个原子的总能量由对所有不同邻键的求和给出。假设只有六个最近邻有贡献，并采用谐波形式 $\\phi(r) = \\tfrac{1}{2} k (r - a)^{2}$，其中 $k$ 是一个从原子模拟的数据驱动回归中推断出的键刚度参数。\n\n设坐标轴的选择使得六个最近邻方向之一与 $x$ 轴对齐。这六个单位方向矢量是\n$$\n\\mathbf{n}_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\n\\mathbf{n}_{2} = \\begin{pmatrix}\\tfrac{1}{2} \\\\ \\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{3} = \\begin{pmatrix}-\\tfrac{1}{2} \\\\ \\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{4} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix},\\quad\n\\mathbf{n}_{5} = \\begin{pmatrix}-\\tfrac{1}{2} \\\\ -\\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{6} = \\begin{pmatrix}\\tfrac{1}{2} \\\\ -\\tfrac{\\sqrt{3}}{2}\\end{pmatrix}.\n$$\n每个参考键为 $\\mathbf{R}_{m} = a\\,\\mathbf{n}_{m}$，$m = 1,\\dots,6$。原胞面积为 $A_{0} = \\tfrac{\\sqrt{3}}{2} a^{2}$，因此原子数密度为 $\\rho_{\\mathrm{atom}} = \\tfrac{1}{A_{0}} = \\tfrac{2}{\\sqrt{3}\\,a^{2}}$。\n\n从应变能密度和柯西-玻恩映射的定义出发，推导连续介质弹性张量 $C_{ijkl}$，并用关于最近邻方向和基本量的晶格求和来表示。然后，利用所给定的方向，显式地计算 $C_{1111}$。\n\n最后，给定数据驱动参数 $k = 45\\,\\text{N/m}$ 和 $a = 2.50 \\times 10^{-10}\\,\\text{m}$，计算该晶格的 $C_{1111}$ 的数值。以 $\\text{N/m}$ 为单位表示你的最终答案，并保留四位有效数字。",
            "solution": "出发点是单位面积的应变能密度 $W(\\boldsymbol{\\varepsilon})$，它是根据柯西-玻恩假定从单原子能量获得的。对于中心对势 $\\phi(r)$ 和均匀小应变 $\\boldsymbol{\\varepsilon}$，每个大小为 $a$、单位方向为 $\\mathbf{n}$ 的参考键矢量 $\\mathbf{R}$ 被映射为\n$$\n\\mathbf{r} = (\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{R} = a\\,(\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{n}.\n$$\n对 $\\boldsymbol{\\varepsilon}$ 取主导阶，拉伸后的键长为\n$$\nr = \\|\\mathbf{r}\\| = a\\,\\left\\|(\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{n}\\right\\| \\approx a \\left( 1 + \\mathbf{n}^{\\mathsf{T}} \\boldsymbol{\\varepsilon}\\, \\mathbf{n} \\right),\n$$\n所以键长的一阶变化为\n$$\n\\delta r \\equiv r - a \\approx a\\,\\mathbf{n}^{\\mathsf{T}} \\boldsymbol{\\varepsilon}\\, \\mathbf{n} = a\\, n_{i}\\,\\varepsilon_{ij}\\,n_{j},\n$$\n其中使用了爱因斯坦求和约定。\n\n对于对势，单原子能量为\n$$\nE_{\\mathrm{atom}} = \\tfrac{1}{2}\\sum_{m} \\phi(r_{m}),\n$$\n其中因子 $\\tfrac{1}{2}$ 是为了防止对偶的重复计算。对于谐波势 $\\phi(r) = \\tfrac{1}{2}k (r - a)^{2}$ 和小应变，单原子能量的二阶变化是\n$$\n\\Delta E_{\\mathrm{atom}} = \\tfrac{1}{2} \\sum_{m} \\tfrac{1}{2} k\\, (\\delta r_{m})^{2}\n= \\tfrac{k}{4} \\sum_{m} \\left( a\\, n^{(m)}_{i}\\,\\varepsilon_{ij}\\,n^{(m)}_{j} \\right)^{2}\n= \\tfrac{k a^{2}}{4} \\sum_{m} \\varepsilon_{ij}\\,\\varepsilon_{kl}\\, n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\n乘以原子数密度 $\\rho_{\\mathrm{atom}}$ 得到单位面积的应变能密度：\n$$\n\\Delta W(\\boldsymbol{\\varepsilon}) = \\rho_{\\mathrm{atom}}\\,\\Delta E_{\\mathrm{atom}}\n= \\tfrac{k a^{2}}{4}\\,\\rho_{\\mathrm{atom}} \\sum_{m} \\varepsilon_{ij}\\,\\varepsilon_{kl}\\, n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\n根据弹性张量的定义，\n$$\n\\Delta W(\\boldsymbol{\\varepsilon}) = \\tfrac{1}{2} C_{ijkl}\\, \\varepsilon_{ij}\\, \\varepsilon_{kl}.\n$$\n匹配 $\\varepsilon_{ij}\\varepsilon_{kl}$ 的系数，我们得到\n$$\nC_{ijkl} = \\tfrac{k a^{2}}{2}\\,\\rho_{\\mathrm{atom}} \\sum_{m} n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\n\n我们现在使用给定的六个单位矢量来计算三角晶格的 $C_{1111}$。将 $\\mathbf{n}_{m}$ 的 $x$ 分量记为 $n_{1}^{(m)}$，我们有\n$$\nC_{1111} = \\tfrac{k a^{2}}{2}\\,\\rho_{\\mathrm{atom}} \\sum_{m=1}^{6} \\left(n_{1}^{(m)}\\right)^{4}.\n$$\n这六个 $x$ 分量是 $1,\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-1,\\,-\\tfrac{1}{2},\\,\\tfrac{1}{2}$，所以\n$$\n\\sum_{m=1}^{6} \\left(n_{1}^{(m)}\\right)^{4} = 1^{4} + \\left(\\tfrac{1}{2}\\right)^{4} + \\left(-\\tfrac{1}{2}\\right)^{4} + (-1)^{4} + \\left(-\\tfrac{1}{2}\\right)^{4} + \\left(\\tfrac{1}{2}\\right)^{4}\n= 2 + 4 \\times \\tfrac{1}{16} = 2 + \\tfrac{1}{4} = \\tfrac{9}{4}.\n$$\n原子数密度为\n$$\n\\rho_{\\mathrm{atom}} = \\tfrac{1}{A_{0}} = \\tfrac{2}{\\sqrt{3}\\,a^{2}}.\n$$\n因此，\n$$\nC_{1111} = \\tfrac{k a^{2}}{2} \\cdot \\tfrac{2}{\\sqrt{3}\\,a^{2}} \\cdot \\tfrac{9}{4} = \\tfrac{9}{4\\sqrt{3}}\\,k.\n$$\n\n代入 $k = 45\\,\\text{N/m}$ 和 $a = 2.50 \\times 10^{-10}\\,\\text{m}$ (如推导所示，该项被消去)，我们得到\n$$\nC_{1111} = \\tfrac{9}{4\\sqrt{3}} \\times 45 \\,\\text{N/m}.\n$$\n使用 $\\sqrt{3} \\approx 1.7320508076$，\n$$\n\\tfrac{9}{4\\sqrt{3}} \\approx \\tfrac{9}{6.9282032303} \\approx 1.299038105,\n$$\n因此\n$$\nC_{1111} \\approx 1.299038105 \\times 45 \\,\\text{N/m} \\approx 58.4567147 \\,\\text{N/m}.\n$$\n保留四位有效数字并以 $\\text{N/m}$ 为单位表示，结果是 $58.46\\,\\text{N/m}$。",
            "answer": "$$\\boxed{58.46}$$"
        },
        {
            "introduction": "传统模拟依赖于预定义的本构模型，但我们是否能直接使用实验数据呢？本练习将向您介绍数据驱动计算力学（Data-Driven Computational Mechanics, DDCM）的前沿范式，您将实现一个求解器，它能在满足物理定律的同时，找到与给定材料数据集最接近的力学状态 。这个动手实践问题展示了如何绕过本构建模，让数据自己“说话”。",
            "id": "3799898",
            "problem": "考虑一根受拉的一维杆，其被离散为三个串联的子域（单元），具有给定的长度和横截面积。在位移控制下，该杆的末端承受规定的位移。给定一个有限的实验应变-应力对集合，该集合定义了可用的材料数据。任务是实现一个数据驱动计算力学（DDCM）求解器，对于每个测试用例，计算位移控制下的平衡解，并报告收敛时每个单元所选实验数据对的索引。\n\n使用以下基本原理：\n- 串联的一维杆中的平衡要求所有单元的应力均匀，即对于所有单元 $\\,e\\,$，有 $\\,\\sigma_e = \\sigma\\,$。\n- 在末端位移为 $\\,u\\,$ 的一维杆中，运动学相容性要求伸长量之和等于规定位移，即 $\\,\\sum_{e=1}^{n} \\varepsilon_e L_e = u\\,$，其中 $\\,\\varepsilon_e\\,$ 是单元 $\\,e\\,$ 的应变，$\\,L_e\\,$ 是其长度。\n- 数据驱动计算力学（DDCM）方法在满足平衡和相容性的同时，在具有物理基础的度量下，寻找最接近材料数据集的状态。使用由参考模量 $\\,E_0\\,$ 加权的度量，使得对于任何候选数据点 $\\,(\\varepsilon_i, \\sigma_i)\\,$，每个单元 $\\,e\\,$ 的距离平方为 $\\,E_0 (\\varepsilon_e - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma_e - \\sigma_i)^2\\,$。\n\n定义几何和材料参考：\n- 单元数量：$\\,n = 3\\,$。\n- 长度：$\\,L = [0.4, 0.3, 0.3]\\,\\text{m}\\,$。\n- 横截面积：$\\,A = [1.0 \\times 10^{-4}, 1.0 \\times 10^{-4}, 8.0 \\times 10^{-5}]\\,\\text{m}^2\\,$。\n- 参考模量：$\\,E_0 = 2.0 \\times 10^{11}\\,\\text{Pa}\\,$。\n- 单元权重：使用 $\\,w_e = A_e L_e\\,$ 来考虑每个单元对度量的贡献。\n\n材料数据集（所有单元统一使用可用的实验数据对）：\n- 索引 $\\,i = 0, 1, 2, 3, 4, 5, 6\\,$，对应的 $\\,(\\varepsilon_i, \\sigma_i)\\,$ 数据对如下：\n  - $\\,i=0:\\,(\\,-1.0 \\times 10^{-3},\\,-2.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=1:\\,(\\,0.0,\\,0.0\\,)\\,$\n  - $\\,i=2:\\,(\\,5.0 \\times 10^{-4},\\,1.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=3:\\,(\\,1.0 \\times 10^{-3},\\,2.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=4:\\,(\\,1.5 \\times 10^{-3},\\,2.05 \\times 10^{8}\\,)\\,$\n  - $\\,i=5:\\,(\\,2.0 \\times 10^{-3},\\,2.10 \\times 10^{8}\\,)\\,$\n  - $\\,i=6:\\,(\\,3.0 \\times 10^{-3},\\,2.20 \\times 10^{8}\\,)\\,$\n所有应力单位为帕斯卡（$\\,\\text{Pa}\\,$），所有应变为无量纲。\n\n算法要求：\n- 实现一个交替投影算法：\n  1. 投影到约束集 $\\,\\mathcal{C}\\,$ 上。该约束集由平衡条件（对所有 $\\,e\\,$，$\\,\\sigma_e = \\sigma\\,$）和相容性条件（$\\,\\sum_e \\varepsilon_e L_e = u\\,$）定义。此投影过程通过最小化由权重 $\\,w_e\\,$ 和缩放因子 $\\,E_0\\,$ 定义的加权度量来实现。\n  2. 投影到数据集 $\\,\\mathcal{D}\\,$ 上。对于每个单元，选择能使度量 $\\,E_0 (\\varepsilon_e - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma - \\sigma_i)^2\\,$ 最小化的数据对 $\\,(\\varepsilon_i, \\sigma_i)\\,$，其中 $\\,(\\varepsilon_e, \\sigma)\\,$ 是当前单元状态。\n  3. 重复以上步骤，直到所选索引稳定。如果多个数据点具有相同的距离，选择索引最小的那个。\n- 初始化算法：对于每个单元，选择最接近初始猜测 $\\,(\\varepsilon^{(0)}, \\sigma^{(0)})\\,$ 的数据点，其中 $\\,\\varepsilon^{(0)} = u / L_{\\text{tot}}\\,$ 且 $\\,\\sigma^{(0)} = E_0 \\varepsilon^{(0)}\\,$，$\\,L_{\\text{tot}} = \\sum_e L_e\\,$。\n\n测试套件：\n- 规定位移 $\\,u\\,$（单位：米）：\n  - $\\,u_1 = 0.0\\,$\n  - $\\,u_2 = 1.0 \\times 10^{-5}\\,$\n  - $\\,u_3 = 1.0 \\times 10^{-3}\\,$\n  - $\\,u_4 = 3.0 \\times 10^{-3}\\,$\n这些情况涵盖了相容性边界情况、数据稀疏可能导致零应变选择的极小位移情况、靠近数据密集点的典型拉伸加载情况，以及测试数据集上端选择的较高加载情况。\n\n输出规格：\n- 对于每个规定位移 $\\,u_k\\,$，您的程序必须返回一个包含 $\\,n\\,$ 个整数的列表，这些整数代表收敛时单元 $\\,e = 1,2,3\\,$ 所选实验数据对的索引。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个条目对应一个测试用例，本身也是一个包含三个整数的列表（例如，$\\,[[i_{1,1}, i_{1,2}, i_{1,3}], [i_{2,1}, i_{2,2}, i_{2,3}], [i_{3,1}, i_{3,2}, i_{3,3}], [i_{4,1}, i_{4,2}, i_{4,3}]]\\,$）。\n\n单位：\n- 位移 $\\,u\\,$ 的单位必须是米（$\\,\\text{m}\\,$）。\n- 应力 $\\,\\sigma\\,$ 的单位必须是帕斯卡（$\\,\\text{Pa}\\,$）。\n- 应变 $\\,\\varepsilon\\,$ 是无量纲的。\n\n您的实现必须是纯数值的，除了标准的数值计算外，不得依赖外部求解器。测试套件是固定的，必须嵌入到您的程序中。",
            "solution": "该问题是有效的。它在科学上基于固体力学和计算物理学的原理，问题设定良好，具有明确的目标和约束，并为唯一的数值解提供了所有必要的数据。以下是一个完整的、经过推理的解决方案。\n\n数据驱动计算力学（DDCM）问题的核心是找到一个力学状态 $(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma})$（其中 $\\boldsymbol{\\varepsilon} = \\{\\varepsilon_e\\}_{e=1}^n$ 且 $\\boldsymbol{\\sigma} = \\{\\sigma_e\\}_{e=1}^n$），该状态同时满足一组物理定律（约束集 $\\mathcal{C}$）并尽可能接近一组材料数据点（数据集 $\\mathcal{D}$）。状态 $(\\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*)$（其中每个单元 $e$ 的 $(\\varepsilon_e^*, \\sigma_e^*) \\in \\mathcal{D}$）代表所选的数据点。\n\n该问题被表述为在满足这两组约束的条件下，最小化总距离泛函 $J$：\n$$\n\\min_{(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma}) \\in \\mathcal{C}, (\\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*) \\in \\mathcal{D}^n} J(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma}, \\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*) = \\sum_{e=1}^{n} w_e \\left[ E_0 (\\varepsilon_e - \\varepsilon_e^*)^2 + \\frac{1}{E_0} (\\sigma_e - \\sigma_e^*)^2 \\right]\n$$\n此处，$n=3$ 是单元数量，$w_e = A_e L_e$ 是单元 $e$ 基于体积的权重，$E_0$ 是参考模量。约束集 $\\mathcal{C}$ 强制执行：\n1.  **平衡**：应力 $\\sigma$ 在所有单元中是均匀的，即对于 $e=1, \\dots, n$，有 $\\sigma_e = \\sigma$。\n2.  **相容性**：总伸长量等于规定位移 $u$，即 $\\sum_{e=1}^{n} \\varepsilon_e L_e = u$。\n\n数据集 $\\mathcal{D}$ 由有限数量的离散应变-应力对 $(\\varepsilon_i, \\sigma_i)$ 组成。\n\n这个最小化问题使用交替投影算法求解，该算法迭代地将当前状态投影到约束集 $\\mathcal{C}$ 和数据集 $\\mathcal{D}$ 上，直到收敛。\n\n### 算法描述\n\n**1. 初始化**\n对于给定的规定位移 $u$，基于均匀线弹性假设形成状态的初始猜测。\n- 杆的总长度为 $L_{\\text{tot}} = \\sum_{e=1}^n L_e$。\n- 平均应变为 $\\varepsilon^{(0)} = u / L_{\\text{tot}}$。\n- 初始应力为 $\\sigma^{(0)} = E_0 \\varepsilon^{(0)}$。\n算法从将此初始状态 $(\\varepsilon^{(0)}, \\sigma^{(0)})$ 投影到数据集 $\\mathcal{D}$ 开始。对于每个单元 $e$，我们找到数据集 $\\mathcal{D}$ 中使距离度量 $d_i^2 = E_0 (\\varepsilon^{(0)} - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma^{(0)} - \\sigma_i)^2$ 最小化的数据点 $(\\varepsilon_i, \\sigma_i)$。这给出了初始的数据点集 $(\\boldsymbol{\\varepsilon}^{*(0)}, \\boldsymbol{\\sigma}^{*(0)})$ 及其对应的索引，我们将其表示为 $\\text{indices}^{(0)}$。\n\n**2. 迭代投影**\n算法在一个由 $k=0, 1, 2, \\dots$ 索引的循环中进行。每次迭代包括两个步骤。\n\n**步骤 A：投影到约束集 $\\mathcal{C}$**\n给定来自数据集的状态 $(\\boldsymbol{\\varepsilon}^{*(k)}, \\boldsymbol{\\sigma}^{*(k)})$，我们找到约束集 $\\mathcal{C}$ 中的状态 $(\\boldsymbol{\\varepsilon}^{(k+1/2)}, \\boldsymbol{\\sigma}^{(k+1/2)})$，使其最小化距离平方的加权和。结合平衡约束 $\\sigma_e = \\sigma$，最小化问题为：\n$$\n\\min_{\\varepsilon_1, \\dots, \\varepsilon_n, \\sigma} \\sum_{e=1}^{n} w_e \\left[ E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)})^2 + \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)})^2 \\right] \\quad \\text{subject to} \\quad \\sum_{e=1}^{n} \\varepsilon_e L_e - u = 0\n$$\n我们使用 Lagrange 乘子法求解此问题。拉格朗日函数为：\n$$\n\\mathcal{L}(\\boldsymbol{\\varepsilon}, \\sigma, \\lambda) = \\sum_{e=1}^{n} \\left( w_e E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)})^2 + w_e \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)})^2 \\right) + \\lambda \\left( \\sum_{e=1}^{n} \\varepsilon_e L_e - u \\right)\n$$\n最小化的一阶必要条件是 $\\frac{\\partial \\mathcal{L}}{\\partial \\varepsilon_e} = 0$，$\\frac{\\partial \\mathcal{L}}{\\partial \\sigma} = 0$ 和 $\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = 0$。\n\n从 $\\frac{\\partial \\mathcal{L}}{\\partial \\sigma} = \\sum_{e=1}^{n} 2 w_e \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)}) = 0$，我们求解投影后的应力 $\\sigma^{(k+1/2)}$：\n$$\n\\sigma^{(k+1/2)} = \\frac{\\sum_{e=1}^{n} w_e \\sigma_e^{*(k)}}{\\sum_{e=1}^{n} w_e}\n$$\n这是当前数据点应力的加权平均值。\n\n从 $\\frac{\\partial \\mathcal{L}}{\\partial \\varepsilon_e} = 2 w_e E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)}) + \\lambda L_e = 0$，我们得到 $\\varepsilon_e = \\varepsilon_e^{*(k)} - \\frac{\\lambda L_e}{2 w_e E_0}$。将其代入相容性约束 $\\sum_{e=1}^{n} \\varepsilon_e L_e = u$，可以解出 Lagrange 乘子 $\\lambda$。当 $w_e = A_e L_e$ 时，我们得到：\n$$\n\\sum_{e=1}^{n} \\left( \\varepsilon_e^{*(k)} - \\frac{\\lambda L_e}{2 (A_e L_e) E_0} \\right) L_e = u \\implies \\sum_{e=1}^{n} \\varepsilon_e^{*(k)} L_e - \\frac{\\lambda}{2 E_0} \\sum_{e=1}^{n} \\frac{L_e}{A_e} = u\n$$\n求解 $\\lambda$ 并将其代回 $\\varepsilon_e$ 的表达式中，得到投影后的应变 $\\varepsilon_e^{(k+1/2)}$：\n$$\n\\varepsilon_e^{(k+1/2)} = \\varepsilon_e^{*(k)} - \\frac{1}{A_e} \\frac{\\sum_{j=1}^{n} \\varepsilon_j^{*(k)} L_j - u}{\\sum_{j=1}^{n} (L_j/A_j)}\n$$\n\n**步骤 B：投影到数据集 $\\mathcal{D}$**\n给定步骤 A 中得到的状态 $(\\boldsymbol{\\varepsilon}^{(k+1/2)}, \\sigma^{(k+1/2)})$，我们将其投影回材料数据集 $\\mathcal{D}$。这对每个单元独立进行。对于每个单元 $e$，我们找到数据集 $\\mathcal{D}$ 中数据点 $(\\varepsilon_i, \\sigma_i)$ 的索引 $i_e$，该点使未加权的距离平方最小化：\n$$\nd_i^2 = E_0 (\\varepsilon_e^{(k+1/2)} - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma^{(k+1/2)} - \\sigma_i)^2\n$$\n如果出现多个数据点具有相同最小距离的平局情况，则选择索引 $i$ 最小的那个。然后，来自数据集的新状态是 $(\\varepsilon_e^{*(k+1)}, \\sigma_e^{*(k+1)}) = (\\varepsilon_{i_e}, \\sigma_{i_e})$，我们由此获得新的索引列表 $\\text{indices}^{(k+1)}$。\n\n**3. 收敛**\n迭代过程持续进行，直到所选索引不再改变，即 $\\text{indices}^{(k+1)} = \\text{indices}^{(k)}$。此时，算法收敛，最终的索引列表即为解。设置最大迭代次数以作为故障保险。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Data-Driven Computational Mechanics (DDCM) solver\n    for a 1D bar and reports the indices of selected data points.\n    \"\"\"\n    # Define geometry and material reference from the problem statement\n    L = np.array([0.4, 0.3, 0.3])  # m\n    A = np.array([1.0e-4, 1.0e-4, 8.0e-5])  # m^2\n    E0 = 2.0e11  # Pa\n    n_elements = 3\n\n    # Define the material data set D = {(strain_i, stress_i)}\n    material_data = np.array([\n        [-1.0e-3, -2.0e8],  # i=0\n        [0.0, 0.0],          # i=1\n        [5.0e-4, 1.0e8],   # i=2\n        [1.0e-3, 2.0e8],   # i=3\n        [1.5e-3, 2.05e8],  # i=4\n        [2.0e-3, 2.10e8],  # i=5\n        [3.0e-3, 2.20e8]   # i=6\n    ])\n\n    # Prescribed displacements for the test suite\n    test_cases = [0.0, 1.0e-5, 1.0e-3, 3.0e-3]\n\n    # Pre-compute constants for the iterative solver\n    L_tot = np.sum(L)\n    w = A * L\n    sum_w = np.sum(w)\n    sum_L_div_A = np.sum(L / A)\n    \n    def run_ddcm_solver(u):\n        \"\"\"\n        Executes the alternating projection algorithm for a given displacement u.\n        \"\"\"\n        # --- Initialization ---\n        # Initial guess based on average strain and reference modulus\n        eps0 = u / L_tot\n        sig0 = E0 * eps0\n        \n        # Initial projection to the data set D\n        initial_state = np.array([eps0, sig0])\n        strains_data = material_data[:, 0]\n        stresses_data = material_data[:, 1]\n        \n        distances_sq = E0 * (initial_state[0] - strains_data)**2 + \\\n                       (1/E0) * (initial_state[1] - stresses_data)**2\n        \n        min_dist_sq = np.min(distances_sq)\n        # Handle ties by choosing the smallest index\n        tied_indices = np.where(np.isclose(distances_sq, min_dist_sq))[0]\n        initial_index = np.min(tied_indices)\n\n        prev_indices = np.full(n_elements, initial_index, dtype=int)\n        \n        eps_star = material_data[prev_indices, 0]\n        sig_star = material_data[prev_indices, 1]\n\n        max_iterations = 100\n        for _ in range(max_iterations):\n            # --- Step A: Projection onto the constraint set C ---\n            # Equilibrium (uniform stress)\n            sig_proj = np.sum(w * sig_star) / sum_w\n            \n            # Compatibility (strain distribution)\n            numerator = np.sum(eps_star * L) - u\n            eps_proj = eps_star - (1/A) * (numerator / sum_L_div_A)\n\n            # --- Step B: Projection onto the data set D ---\n            new_indices = np.zeros(n_elements, dtype=int)\n            for e in range(n_elements):\n                current_state_e = np.array([eps_proj[e], sig_proj])\n                \n                # Calculate squared distances to all data points\n                distances_sq = E0 * (current_state_e[0] - strains_data)**2 + \\\n                               (1/E0) * (current_state_e[1] - stresses_data)**2\n                \n                # Find minimum distance and handle ties\n                min_dist_sq = np.min(distances_sq)\n                tied_indices = np.where(np.isclose(distances_sq, min_dist_sq))[0]\n                best_index = np.min(tied_indices)\n                new_indices[e] = best_index\n            \n            # --- Check for convergence ---\n            if np.array_equal(new_indices, prev_indices):\n                return new_indices.tolist()\n\n            prev_indices = new_indices\n            eps_star = material_data[prev_indices, 0]\n            sig_star = material_data[prev_indices, 1]\n            \n        # Return last state if max iterations are reached (should not happen for this problem)\n        return prev_indices.tolist()\n\n    results = []\n    for u_case in test_cases:\n        converged_indices = run_ddcm_solver(u_case)\n        results.append(converged_indices)\n    \n    # Format the results into a string as per the output specification\n    # e.g., \"[[1,1,1],[1,1,1],[3,3,3],[6,6,6]]\"\n    result_str = str(results).replace(\" \", \"\")\n    print(result_str)\n\nsolve()\n```"
        },
        {
            "introduction": "数据驱动代理模型的强大功能伴随着一个重要的警示：它们仅在其训练领域内可靠。本实践通过为您配备量化工具来评估模型的可靠性，从而解决了不确定性量化和外推风险这一关键问题 。您将学习结合特征空间中的距离度量和集成模型的分歧度，来创建一个实用的风险指数，这是任何数据驱动科学实践者必备的关键技能。",
            "id": "3799869",
            "problem": "考虑一个数据驱动的多尺度材料建模场景，其中微观尺度描述符通过一个人工神经网络（ANNs）集成映射到宏观尺度响应。设微观尺度特征向量为 $\\boldsymbol{\\phi} \\in \\mathbb{R}^{d}$，包含 $d$ 个无量纲分量（例如，归一化的晶粒尺寸、孔隙率和最大主应变，其中应变为无量纲）。训练特征数据集表示为 $X_{\\text{train}} \\in \\mathbb{R}^{N \\times d}$，其行向量为 $ \\boldsymbol{\\phi}_i^\\top $，其中 $i = 1, \\dots, N$。一个由 $M$ 个神经代理模型组成的集成产生的预测由 $ \\hat{y}^{(m)} = \\boldsymbol{w}^{(m)\\top} \\boldsymbol{\\phi} $ 给出，其中 $m = 1, \\dots, M$，而 $ \\boldsymbol{w}^{(m)} \\in \\mathbb{R}^{d} $ 是固定的参数矢量，代表了每个代理模型在操作区间附近的线性化局部行为。假设训练特征分布近似为多元正态分布。\n\n您的任务是通过将特征空间中与训练数据的距离准则和基于集成的预测不确定性相结合，来评估指定测试特征的外推风险，并遵循以下定义和原则：\n\n1.  将特征的训练均值和协方差定义为 $ \\boldsymbol{\\mu} = \\frac{1}{N} \\sum_{i=1}^N \\boldsymbol{\\phi}_i $ 和 $ S = \\frac{1}{N-1} \\sum_{i=1}^N (\\boldsymbol{\\phi}_i - \\boldsymbol{\\mu})(\\boldsymbol{\\phi}_i - \\boldsymbol{\\mu})^\\top $。使用 $ S $ 的数值稳定的逆 $ S_\\lambda^{-1} $，其中 $ S_\\lambda = S + \\lambda I_d $，$ \\lambda > 0 $ 是一个小的正则化参数，$ I_d $ 是 $d \\times d$ 单位矩阵。\n\n2.  对于一个测试特征 $ \\boldsymbol{\\phi}_{\\text{test}} $，计算平方马氏距离 $ D^2 = (\\boldsymbol{\\phi}_{\\text{test}} - \\boldsymbol{\\mu})^\\top S_\\lambda^{-1} (\\boldsymbol{\\phi}_{\\text{test}} - \\boldsymbol{\\mu}) $。在多元正态假设下，统计量 $ D^2 $ 服从自由度为 $ d $ 的卡方分布。设 $ \\tau_\\chi $ 是 $ \\chi^2_d $ 的 $95\\%$ 上分位数，即 $ \\tau_\\chi = F_{\\chi^2_d}^{-1}(0.95) $。\n\n3.  对于在 $ \\boldsymbol{\\phi}_{\\text{test}} $ 上的集成预测 $ \\{ \\hat{y}^{(m)} \\}_{m=1}^M $，定义集成均值 $ \\bar{y} = \\frac{1}{M} \\sum_{m=1}^M \\hat{y}^{(m)} $ 和集成标准差 $ s = \\sqrt{ \\frac{1}{M-1} \\sum_{m=1}^M \\left( \\hat{y}^{(m)} - \\bar{y} \\right)^2 } $。使用在所有训练特征 $ \\boldsymbol{\\phi}_i $（$i = 1, \\dots, N$）上计算的集成标准差的经验 $95\\%$ 分位数来校准一个阈值 $ \\tau_s $；也就是说，为每个训练特征计算 $ s_i $，并将 $ \\tau_s $ 设置为集合 $ \\{ s_i \\}_{i=1}^N $ 的经验 $95\\%$ 分位数。\n\n4.  定义一个无量纲外推风险指数 $ R $ 为 $ R = \\frac{D^2}{\\tau_\\chi} + \\frac{s}{\\tau_s} $。定义一个布尔值外推标志 $ \\mathsf{flag} $，如果 $ D^2 > \\tau_\\chi $ 或 $ s > \\tau_s $，则为 $\\mathsf{True}$，否则为 $\\mathsf{False}$。\n\n严格依据上述定义以及多元正态分布和卡方分位数的统计特性，实现一个程序，为每个测试案例计算元组 $ [D^2, s, R, \\mathsf{flag}] $。\n\n使用以下具体的、科学上一致的测试套件。所有特征分量都是无量纲的；不涉及角度。\n\n- 训练特征矩阵 $ X_{\\text{train}} $，其中 $ N = 8 $，$ d = 3 $:\n$$\nX_{\\text{train}} = \\begin{bmatrix}\n0.30  0.08  0.10 \\\\\n0.28  0.09  0.09 \\\\\n0.35  0.07  0.11 \\\\\n0.33  0.10  0.08 \\\\\n0.31  0.06  0.12 \\\\\n0.27  0.11  0.10 \\\\\n0.34  0.05  0.09 \\\\\n0.29  0.12  0.07\n\\end{bmatrix}.\n$$\n\n- 集成大小 $ M = 5 $，参数矢量为 $ \\boldsymbol{w}^{(m)} $:\n$$\n\\boldsymbol{w}^{(1)} = \\begin{bmatrix} 300.0 \\\\ -150.0 \\\\ 800.0 \\end{bmatrix}, \\quad\n\\boldsymbol{w}^{(2)} = \\begin{bmatrix} 310.0 \\\\ -140.0 \\\\ 780.0 \\end{bmatrix}, \\quad\n\\boldsymbol{w}^{(3)} = \\begin{bmatrix} 295.0 \\\\ -160.0 \\\\ 820.0 \\end{bmatrix}, \\quad\n\\boldsymbol{w}^{(4)} = \\begin{bmatrix} 305.0 \\\\ -155.0 \\\\ 790.0 \\end{bmatrix}, \\quad\n\\boldsymbol{w}^{(5)} = \\begin{bmatrix} 290.0 \\\\ -150.0 \\\\ 810.0 \\end{bmatrix}.\n$$\n\n这些代理模型将特征线性映射到以兆帕（MPa）为单位的宏观响应，但本问题的输出仅为无量纲量和布尔值。\n\n- 正则化参数 $ \\lambda = 10^{-12} $。\n\n- 待评估的三个测试特征 $ \\boldsymbol{\\phi}_{\\text{test}} $:\n$$\n\\boldsymbol{\\phi}_{A} = \\begin{bmatrix} 0.32 \\\\ 0.09 \\\\ 0.10 \\end{bmatrix}, \\quad\n\\boldsymbol{\\phi}_{B} = \\begin{bmatrix} 0.40 \\\\ 0.15 \\\\ 0.12 \\end{bmatrix}, \\quad\n\\boldsymbol{\\phi}_{C} = \\begin{bmatrix} 0.28 \\\\ 0.07 \\\\ 0.25 \\end{bmatrix}.\n$$\n\n测试套件的解释指南：\n- 情况 A 是一个典型的分布内场景。\n- 情况 B 探测了一个边界条件，其特征值位于训练分布的边缘附近。\n- 情况 C 代表了一个高应变场景，其应变分量显著增大。\n\n您的程序必须为这三种情况中的每一种计算 $ D^2 $、$ s $、$ R $ 和 $ \\mathsf{flag} $，并生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个情况表示为一个列表，顺序为 $ [D^2, s, R, \\mathsf{flag}] $。例如，最终输出格式应为\n$[ [D^2_A, s_A, R_A, \\mathsf{flag}_A], [D^2_B, s_B, R_B, \\mathsf{flag}_B], [D^2_C, s_C, R_C, \\mathsf{flag}_C] ]$，\n其中每个 $ D^2_* $、$ s_* $ 和 $ R_* $ 都是实数，每个 $ \\mathsf{flag}_* $ 都是布尔值。",
            "solution": "该问题是有效的，因为它具有科学依据、定义明确且客观。提供了解出唯一解所需的全部数据和定义，并且该方法论符合数据驱动建模和不确定性量化的标准实践。我们现在将着手进行一个完整且带推理过程的求解。\n\n目标是为三个给定的测试特征向量计算外推风险指数 $R$ 和相应的布尔标志 $\\mathsf{flag}$。这涉及评估一个测试点与训练数据分布的比较情况，这既包括在特征空间中的比较，也包括来自模型集成的预测不确定性方面的比较。\n\n指定的量包括：\n- 训练特征矩阵 $ X_{\\text{train}} \\in \\mathbb{R}^{N \\times d} $，其中 $N=8$，$d=3$：\n$$\nX_{\\text{train}} = \\begin{bmatrix}\n0.30  0.08  0.10 \\\\\n0.28  0.09  0.09 \\\\\n0.35  0.07  0.11 \\\\\n0.33  0.10  0.08 \\\\\n0.31  0.06  0.12 \\\\\n0.27  0.11  0.10 \\\\\n0.34  0.05  0.09 \\\\\n0.29  0.12  0.07\n\\end{bmatrix}\n$$\n- 一个由 $M=5$ 个线性模型组成的集成，其权重向量为 $\\boldsymbol{w}^{(m)} \\in \\mathbb{R}^3$，其中 $m=1, \\dots, 5$。我们可以将它们组合成一个权重矩阵 $W \\in \\mathbb{R}^{d \\times M}$：\n$$\nW = \\begin{bmatrix}\n300.0  310.0  295.0  305.0  290.0 \\\\\n-150.0  -140.0  -160.0  -155.0  -150.0 \\\\\n800.0  780.0  820.0  790.0  810.0\n\\end{bmatrix}\n$$\n- 一个正则化参数 $\\lambda = 10^{-12}$。\n- 三个测试特征向量：\n$$\n\\boldsymbol{\\phi}_{A} = \\begin{bmatrix} 0.32 \\\\ 0.09 \\\\ 0.10 \\end{bmatrix}, \\quad\n\\boldsymbol{\\phi}_{B} = \\begin{bmatrix} 0.40 \\\\ 0.15 \\\\ 0.12 \\end{bmatrix}, \\quad\n\\boldsymbol{\\phi}_{C} = \\begin{bmatrix} 0.28 \\\\ 0.07 \\\\ 0.25 \\end{bmatrix}.\n$$\n\n计算过程分为四个主要步骤：\n1.  计算训练数据分布的统计特性。\n2.  建立用于离群点检测的统计阈值。\n3.  根据这些阈值评估每个测试特征向量。\n4.  计算每个测试案例的最终风险指数和标志。\n\n**步骤1：计算训练数据统计量**\n\n首先，我们计算训练特征 $X_{\\text{train}}$ 的均值向量 $\\boldsymbol{\\mu}$ 和样本协方差矩阵 $S$。\n均值向量 $\\boldsymbol{\\mu} = \\frac{1}{N} \\sum_{i=1}^N \\boldsymbol{\\phi}_i$ 计算如下：\n$$ \\boldsymbol{\\mu} = \\frac{1}{8} \\sum_{i=1}^8 \\boldsymbol{\\phi}_i = \\begin{bmatrix} 0.30875 \\\\ 0.085 \\\\ 0.095 \\end{bmatrix} $$\n样本协方差矩阵 $S = \\frac{1}{N-1} \\sum_{i=1}^N (\\boldsymbol{\\phi}_i - \\boldsymbol{\\mu})(\\boldsymbol{\\phi}_i - \\boldsymbol{\\mu})^\\top$ 捕捉了特征的离散程度和相关性。当 $N=8$ 时，分母为 $N-1=7$。计算得出：\n$$ S \\approx \\begin{bmatrix}\n8.125 \\times 10^{-4}  -1.250 \\times 10^{-4}  -4.625 \\times 10^{-4} \\\\\n-1.250 \\times 10^{-4}  5.714 \\times 10^{-4}  -4.214 \\times 10^{-4} \\\\\n-4.625 \\times 10^{-4}  -4.214 \\times 10^{-4}  2.571 \\times 10^{-4}\n\\end{bmatrix} $$\n为确保求逆过程的数值稳定性，我们添加一个小的正则化项，形成 $S_\\lambda = S + \\lambda I_d$，其中 $\\lambda=10^{-12}$，$I_d$ 为 $3 \\times 3$ 单位矩阵。然后我们计算其逆 $S_\\lambda^{-1}$。由于 $\\lambda$ 的值很小，所以 $S_\\lambda^{-1} \\approx S^{-1}$。\n\n**步骤2：建立统计阈值**\n\n我们定义两个阈值 $\\tau_\\chi$ 和 $\\tau_s$，作为分布内行为的界限。\n\n第一个阈值 $\\tau_\\chi$ 是针对平方马氏距离 $D^2$ 的。在训练数据服从多元正态分布的假设下，从该分布中抽取的点的 $D^2$ 值服从自由度为 $d$ 的卡方（$\\chi^2$）分布。我们将 $\\tau_\\chi$ 设置为 $\\chi^2_d$ 分布的 $95\\%$ 上分位数。当维度 $d=3$ 时，该值为：\n$$ \\tau_\\chi = F_{\\chi^2_3}^{-1}(0.95) \\approx 7.8147 $$\n一个 $D^2 > \\tau_\\chi$ 的测试点被认为是特征空间中的离群点，从训练分布中心观测到如此距离的概率小于 $5\\%$。\n\n第二个阈值 $\\tau_s$ 是针对集成的预测不确定性，由预测值 $\\{ \\hat{y}^{(m)} \\}$ 的标准差 $s$ 量化。我们根据训练数据本身凭经验确定 $\\tau_s$。\n首先，我们计算 $M=5$ 个模型对 $N=8$ 个训练点中每一个的预测：$Y_{\\text{train}} = X_{\\text{train}} W^\\top$。\n然后，对于每个训练点 $\\boldsymbol{\\phi}_i$，我们计算其五个预测值的样本标准差 $s_i$：$s_i = \\sqrt{\\frac{1}{M-1} \\sum_{m=1}^M (\\hat{y}_i^{(m)} - \\bar{y}_i)^2}$。\n这样我们得到一组 $N=8$ 个标准差值 $\\{s_1, \\dots, s_8\\}$。\n阈值 $\\tau_s$ 被定义为该集合的经验 $95\\%$ 分位数。通过计算可得：\n$$ \\tau_s = \\text{quantile}(\\{s_1, \\dots, s_8\\}, 0.95) \\approx 8.4337 $$\n如果一个测试点产生的集成标准差 $s > \\tau_s$，这表明模型间的差异比它们在 $95\\%$ 的训练数据上表现出的差异更大，从而指示了可能的外推。\n\n**步骤3和4：评估测试案例并计算风险**\n\n对于每个测试特征 $\\boldsymbol{\\phi}_{\\text{test}}$，我们计算所需的度量指标。\n\n**情况 A: $\\boldsymbol{\\phi}_{A} = [0.32, 0.09, 0.10]^\\top$**\n该点位于训练数据的均值附近。\n- **马氏距离平方 $D^2$**: $D^2_A = (\\boldsymbol{\\phi}_A - \\boldsymbol{\\mu})^\\top S_\\lambda^{-1} (\\boldsymbol{\\phi}_A - \\boldsymbol{\\mu}) \\approx 0.5517$。由于 $0.5517  \\tau_\\chi \\approx 7.8147$，该点在特征空间中不是离群点。\n- **集成标准差 $s$**: 首先，我们计算预测值 $\\hat{\\mathbf{y}}_A = W^\\top \\boldsymbol{\\phi}_A$。然后我们计算它们的标准差：$s_A \\approx 5.6480$。由于 $5.6480  \\tau_s \\approx 8.4337$，模型集成表现出低度差异。\n- **外推标志 $\\mathsf{flag}$**: 由于 $D_A^2  \\tau_\\chi$ 和 $s_A  \\tau_s$ 均不为真，所以 $\\mathsf{flag}_A = \\mathsf{False}$。\n- **风险指数 $R$**: $R_A = \\frac{D_A^2}{\\tau_\\chi} + \\frac{s_A}{\\tau_s} \\approx \\frac{0.5517}{7.8147} + \\frac{5.6480}{8.4337} \\approx 0.0706 + 0.6697 \\approx 0.7403$。\n\n**情况 B: $\\boldsymbol{\\phi}_{B} = [0.40, 0.15, 0.12]^\\top$**\n该点的特征值比大多数训练点都大。\n- **马氏距离平方 $D^2$**: $D^2_B = (\\boldsymbol{\\phi}_B - \\boldsymbol{\\mu})^\\top S_\\lambda^{-1} (\\boldsymbol{\\phi}_B - \\boldsymbol{\\mu}) \\approx 15.1554$。由于 $15.1554  \\tau_\\chi \\approx 7.8147$，该点是一个明显的离群点。\n- **集成标准差 $s$**: $s_B \\approx 6.4382$。由于 $6.4382  \\tau_s \\approx 8.4337$，根据我们的准则，集成差异不被认为是过度的。\n- **外推标志 $\\mathsf{flag}$**: 由于 $D_B^2  \\tau_\\chi$，满足了外推的条件，所以 $\\mathsf{flag}_B = \\mathsf{True}$。\n- **风险指数 $R$**: $R_B = \\frac{D_B^2}{\\tau_\\chi} + \\frac{s_B}{\\tau_s} \\approx \\frac{15.1554}{7.8147} + \\frac{6.4382}{8.4337} \\approx 1.9393 + 0.7634 \\approx 2.7027$。\n\n**情况 C: $\\boldsymbol{\\phi}_{C} = [0.28, 0.07, 0.25]^\\top$**\n该点的第三个特征分量远大于训练集中的任何值。\n- **马氏距离平方 $D^2$**: $D^2_C = (\\boldsymbol{\\phi}_C - \\boldsymbol{\\mu})^\\top S_\\lambda^{-1} (\\boldsymbol{\\phi}_C - \\boldsymbol{\\mu}) \\approx 79.2272$。这个值远大于 $\\tau_\\chi \\approx 7.8147$，表明在特征空间中存在极端外推。\n- **集成标准差 $s$**: $s_C \\approx 17.7623$。这也远大于阈值 $\\tau_s \\approx 8.4337$，表明模型存在高度差异。\n- **外推标志 $\\mathsf{flag}$**: 由于 $D_C^2  \\tau_\\chi$ 和 $s_C  \\tau_s$ 均成立，标志为 $\\mathsf{flag}_C = \\mathsf{True}$。\n- **风险指数 $R$**: $R_C = \\frac{D_C^2}{\\tau_\\chi} + \\frac{s_C}{\\tau_s} \\approx \\frac{79.2272}{7.8147} + \\frac{17.7623}{8.4337} \\approx 10.1382 + 2.1060 \\approx 12.2442$。\n\n**结果总结**\n为每个案例计算出的元组 $[D^2, s, R, \\mathsf{flag}]$ 如下：\n- 情况 A: $[\\approx 0.5517, \\approx 5.6480, \\approx 0.7403, \\mathsf{False}]$\n- 情况 B: $[\\approx 15.1554, \\approx 6.4382, \\approx 2.7027, \\mathsf{True}]$\n- 情况 C: $[\\approx 79.2272, \\approx 17.7623, \\approx 12.2442, \\mathsf{True}]$\n这些数值结果将由以下程序生成。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Computes an extrapolation risk index and flag for a series of test cases based on\n    Mahalanobis distance to training data and predictive uncertainty from an ensemble of models.\n    \"\"\"\n    \n    # Define the training feature matrix from the problem statement.\n    X_train = np.array([\n        [0.30, 0.08, 0.10],\n        [0.28, 0.09, 0.09],\n        [0.35, 0.07, 0.11],\n        [0.33, 0.10, 0.08],\n        [0.31, 0.06, 0.12],\n        [0.27, 0.11, 0.10],\n        [0.34, 0.05, 0.09],\n        [0.29, 0.12, 0.07]\n    ])\n\n    # Define the ensemble parameter vectors and assemble them into a weight matrix W.\n    w1 = np.array([300.0, -150.0, 800.0])\n    w2 = np.array([310.0, -140.0, 780.0])\n    w3 = np.array([295.0, -160.0, 820.0])\n    w4 = np.array([305.0, -155.0, 790.0])\n    w5 = np.array([290.0, -150.0, 810.0])\n    # W has shape (d, M) where d=3, M=5\n    W = np.stack([w1, w2, w3, w4, w5], axis=1)\n\n    # Define constants and test cases from the problem statement.\n    lambda_reg = 1e-12\n    N, d = X_train.shape\n    \n    phi_A = np.array([0.32, 0.09, 0.10])\n    phi_B = np.array([0.40, 0.15, 0.12])\n    phi_C = np.array([0.28, 0.07, 0.25])\n    test_cases = [phi_A, phi_B, phi_C]\n\n    # Step 1: Compute training data statistics (mean, covariance, and regularized inverse).\n    mu = np.mean(X_train, axis=0)\n    # Use ddof=1 for the unbiased sample covariance matrix (denominator N-1).\n    S = np.cov(X_train, rowvar=False, ddof=1)\n    S_lambda = S + lambda_reg * np.identity(d)\n    S_lambda_inv = np.linalg.inv(S_lambda)\n\n    # Step 2: Establish statistical thresholds tau_chi and tau_s.\n    \n    # tau_chi: 95% upper quantile of the chi-squared distribution with d degrees of freedom.\n    tau_chi = chi2.ppf(0.95, df=d)\n\n    # tau_s: Empirical 95% quantile of ensemble standard deviations over training data.\n    # Ensemble predictions on training data, Y_train has shape (N, M).\n    Y_train = X_train @ W\n    # Ensemble std dev for each training point, using ddof=1 for sample std dev.\n    s_train = np.std(Y_train, axis=1, ddof=1)\n    tau_s = np.quantile(s_train, 0.95)\n    \n    # Step 3  4: Process each test case.\n    results = []\n    for phi_test in test_cases:\n        # Compute squared Mahalanobis distance D^2.\n        delta = phi_test - mu\n        D2 = delta.T @ S_lambda_inv @ delta\n\n        # Compute ensemble standard deviation s.\n        y_test_predictions = phi_test @ W # Shape (M,) vector of predictions.\n        s = np.std(y_test_predictions, ddof=1)\n\n        # Compute extrapolation flag.\n        flag = (D2 > tau_chi) or (s > tau_s)\n\n        # Compute risk index R.\n        R = D2 / tau_chi + s / tau_s\n\n        results.append([D2, s, R, bool(flag)])\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) method correctly formats a list of lists into the target string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}