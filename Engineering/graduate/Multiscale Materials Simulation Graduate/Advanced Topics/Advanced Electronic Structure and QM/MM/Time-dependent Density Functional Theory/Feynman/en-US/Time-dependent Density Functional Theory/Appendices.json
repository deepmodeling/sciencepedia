{
    "hands_on_practices": [
        {
            "introduction": "The heart of any real-time Time-Dependent Density Functional Theory (TDDFT) simulation is the numerical integration of the time-dependent Kohn-Sham equations. This exercise takes you into the engine room of these simulations, tasking you with implementing a single propagation step for a set of Kohn-Sham orbitals. By comparing the well-established Crank–Nicolson scheme with the second-order Magnus expansion, you will gain first-hand experience with the challenges of time-dependent potentials and the predictor–corrector methods used to handle them, providing a foundational understanding of how these complex dynamics are modeled computationally .",
            "id": "2932905",
            "problem": "You are asked to implement, from first principles, a one-step real-time propagation of Kohn–Sham orbitals in Time-Dependent Density Functional Theory (TDDFT) using a second-order midpoint evaluation of the Hamiltonian with two different propagators: the Crank–Nicolson scheme and the second-order Magnus exponential. Work entirely in atomic units, so that electron mass, elementary charge, reduced Planck constant, and Coulomb constant are all equal to $1$. Start from the time-dependent Kohn–Sham equation\n$$\n\\mathrm{i}\\,\\frac{\\partial}{\\partial t}\\,\\phi_j(x,t)\\;=\\;\\hat{H}_{\\mathrm{s}}[n(\\cdot,t)]\\,\\phi_j(x,t),\n$$\nwith the Slater determinant built from occupied orbitals $\\{\\phi_j\\}_{j=1}^{N_{\\mathrm{occ}}}$ and density\n$$\nn(x,t)\\;=\\;\\sum_{j=1}^{N_{\\mathrm{occ}}}\\lvert \\phi_j(x,t)\\rvert^2.\n$$\nIn this problem, the Kohn–Sham Hamiltonian is modeled as\n$$\n\\hat{H}_{\\mathrm{s}}[n]\\;=\\;-\\frac{1}{2}\\frac{d^2}{dx^2}\\;+\\;v_{\\mathrm{ext}}(x)\\;+\\;v_{\\mathrm{xc}}(n(x)),\n$$\nwhere $v_{\\mathrm{ext}}(x)$ is a static harmonic confining potential and $v_{\\mathrm{xc}}(n)$ is an Adiabatic Local Density Approximation (ALDA) exchange–correlation potential. To keep the model fully local and self-contained, neglect the Hartree potential and use the following forms:\n- Harmonic external potential\n$$\nv_{\\mathrm{ext}}(x)\\;=\\;\\frac{1}{2}\\,\\omega^2\\,x^2,\n$$\nwith angular frequency $\\omega$.\n- Local ALDA-type exchange–correlation potential\n$$\nv_{\\mathrm{xc}}(n)\\;=\\;-\\,\\alpha\\,C\\,n^{1/3},\\quad C=\\left(\\frac{3}{\\pi}\\right)^{1/3},\n$$\nwith a dimensionless scaling parameter $\\alpha$.\n\nDiscretize space on a uniform periodic grid of $N$ points over the interval $[-L/2,L/2)$ with spacing $\\Delta x=L/N$, and approximate the kinetic energy operator with the second-order central finite-difference Laplacian with periodic boundary conditions. The initial occupied Kohn–Sham orbitals at time $t=0$ are taken to be the lowest harmonic oscillator eigenfunctions of frequency $\\omega$ (in the continuum), truncated to the grid and then orthonormalized on the grid. For $N_{\\mathrm{occ}}=1$, take the ground state\n$$\n\\phi_0(x)\\;=\\;\\left(\\frac{\\omega}{\\pi}\\right)^{1/4}\\exp\\!\\left(-\\frac{\\omega}{2}x^2\\right).\n$$\nFor $N_{\\mathrm{occ}}=2$, take $\\phi_0(x)$ as above and the first excited state\n$$\n\\phi_1(x)\\;=\\;\\sqrt{2\\,\\omega}\\,x\\,\\phi_0(x).\n$$\nApply a weak impulsive electric field at $t=0$ modeled by the so-called $\\delta$-kick, which results in a phase factor multiplying each orbital,\n$$\n\\phi_j(x,0^+)\\;=\\;\\exp\\!\\big(-\\mathrm{i}\\,k\\,x\\big)\\,\\phi_j(x,0^-),\n$$\nwith small $k$ to remain in the linear response regime. Then, for a single time step of size $\\Delta t$, construct a midpoint Hamiltonian $\\hat{H}_{\\mathrm{s}}[n(t+\\Delta t/2)]$ using a predictor–corrector strategy:\n- Predictor: propagate from $t$ to $t+\\Delta t/2$ using the Hamiltonian at time $t$ to obtain a predicted midpoint density $n(x,t+\\Delta t/2)$.\n- Corrector: form the midpoint Hamiltonian with $v_{\\mathrm{xc}}(n(x,t+\\Delta t/2))$ and use it for the final $t\\to t+\\Delta t$ propagation.\n\nImplement the two following second-order propagators with the same midpoint Hamiltonian:\n- Crank–Nicolson (CN): solve\n$$\n\\Big(\\mathbf{I}+\\frac{\\mathrm{i}\\,\\Delta t}{2}\\,\\mathbf{H}_{\\mathrm{mid}}\\Big)\\,\\Phi(t+\\Delta t)\\;=\\;\\Big(\\mathbf{I}-\\frac{\\mathrm{i}\\,\\Delta t}{2}\\,\\mathbf{H}_{\\mathrm{mid}}\\Big)\\,\\Phi(t),\n$$\nwhere bold symbols denote the matrix representation on the grid and $\\Phi$ stacks the occupied orbitals as columns. Solve separately for each column.\n- Second-order Magnus (exponential midpoint):\n$$\n\\Phi(t+\\Delta t)\\;=\\;\\exp\\!\\big(-\\mathrm{i}\\,\\Delta t\\,\\mathbf{H}_{\\mathrm{mid}}\\big)\\,\\Phi(t).\n$$\nAfter propagation, re-orthonormalize the occupied orbitals with respect to the discrete inner product $\\langle f,g\\rangle=\\sum_\\ell \\overline{f_\\ell}\\,g_\\ell\\,\\Delta x$. Compute the density from each propagated Slater determinant and report the weighted $\\mathrm{L}^2$-norm of the density difference between the two schemes,\n$$\nD\\;=\\;\\Bigg(\\sum_{\\ell=1}^{N}\\big(n_{\\mathrm{CN}}(x_\\ell)-n_{\\mathrm{Mag}}(x_\\ell)\\big)^2\\,\\Delta x\\Bigg)^{1/2}.\n$$\n\nYour program must implement the above from first principles and produce results for the following test suite, each specified by the tuple $(N,L,\\Delta t,\\omega,\\alpha,k,N_{\\mathrm{occ}})$:\n- Test $1$: $(N,L,\\Delta t,\\omega,\\alpha,k,N_{\\mathrm{occ}})=(\\,128,\\,20,\\,0.05,\\,0.5,\\,0.8,\\,0.001,\\,1\\,)$.\n- Test $2$: $(N,L,\\Delta t,\\omega,\\alpha,k,N_{\\mathrm{occ}})=(\\,128,\\,20,\\,0.005,\\,0.5,\\,0.8,\\,0.001,\\,1\\,)$.\n- Test $3$: $(N,L,\\Delta t,\\omega,\\alpha,k,N_{\\mathrm{occ}})=(\\,128,\\,20,\\,0.10,\\,0.5,\\,0.8,\\,0.001,\\,1\\,)$.\n- Test $4$: $(N,L,\\Delta t,\\omega,\\alpha,k,N_{\\mathrm{occ}})=(\\,128,\\,20,\\,0.05,\\,0.5,\\,0.8,\\,0.0005,\\,2\\,)$.\n\nAll quantities are in atomic units. Angles and phases are in radians. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4]$, where each $r_i$ is the floating-point value of $D$ for the corresponding test case as defined above. No additional text should be printed.",
            "solution": "The problem requires the implementation of a single time step in a Time-Dependent Density Functional Theory (TDDFT) simulation for a one-dimensional system. We are tasked to compare two second-order propagation schemes, Crank-Nicolson and the Magnus exponential, using a predictor-corrector method for the time-dependent potential. The analysis proceeds as follows.\n\nFirst, we must establish a discrete representation for the problem on a spatial grid. The continuous spatial coordinate $x$ over the domain $[-L/2, L/2)$ is discretized into $N$ points $x_\\ell = -L/2 + \\ell \\Delta x$ for $\\ell = 0, 1, \\dots, N-1$, with grid spacing $\\Delta x = L/N$. A quantum state (orbital) $\\phi(x)$ is represented by a column vector $\\boldsymbol{\\phi}$ of its values on these grid points, $\\phi_\\ell = \\phi(x_\\ell)$. The inner product between two states $\\phi$ and $\\psi$ is approximated by the discrete sum $\\langle\\phi|\\psi\\rangle = \\sum_{\\ell=0}^{N-1} \\overline{\\phi_\\ell} \\psi_\\ell \\Delta x$.\n\nThe Kohn-Sham Hamiltonian $\\hat{H}_{\\mathrm{s}} = \\hat{T} + \\hat{V}$ consists of a kinetic part $\\hat{T} = -\\frac{1}{2}\\frac{d^2}{dx^2}$ and a potential part $\\hat{V} = v_{\\mathrm{ext}}(x) + v_{\\mathrm{xc}}(n(x))$. The potential operator $\\hat{V}$ acts locally in position space, so its matrix representation $\\mathbf{V}$ is diagonal, with entries $V_{\\ell\\ell} = v_{\\mathrm{ext}}(x_\\ell) + v_{\\mathrm{xc}}(n(x_\\ell))$. The kinetic operator $\\hat{T}$ is approximated using a second-order central finite-difference formula for the Laplacian with periodic boundary conditions:\n$$\n(\\hat{T} \\phi)_\\ell \\approx -\\frac{1}{2\\Delta x^2} \\big( \\phi_{\\ell+1} - 2\\phi_\\ell + \\phi_{\\ell-1} \\big)\n$$\nwhere indices are taken modulo $N$. This results in a real, symmetric, circulant matrix $\\mathbf{T}$ of size $N \\times N$. The full Hamiltonian at a given time is then represented by the dense matrix $\\mathbf{H} = \\mathbf{T} + \\mathbf{V}$.\n\nThe initial state at time $t=0^-$ is constructed from the provided analytic forms of the harmonic oscillator eigenfunctions. For $N_{\\mathrm{occ}}$ occupied orbitals, we form a matrix $\\Phi_{cont}$ of size $N \\times N_{\\mathrm{occ}}$ by evaluating the functions on the grid. These continuum functions are orthonormal with respect to integration, but their discrete counterparts are not necessarily orthonormal with respect to the discrete inner product. Therefore, we must perform an on-grid orthonormalization. This is achieved by applying a Gram-Schmidt procedure (or, more robustly, a QR decomposition) to the matrix $\\sqrt{\\Delta x} \\Phi_{cont}$, whose columns are then orthonormal in the standard Euclidean sense. The resulting orthonormal matrix, when scaled by $1/\\sqrt{\\Delta x}$, yields the initial orbitals $\\Phi(0^-)$ that are properly orthonormalized on the grid.\n\nAt $t=0$, an impulsive electric field (a $\\delta$-kick) is applied. This imparts a momentum kick $k$ to the electrons, which in position space corresponds to multiplying each orbital by a phase factor:\n$$\n\\Phi(x,0^+) = \\exp(-\\mathrm{i}kx) \\Phi(x,0^-)\n$$\nThis operation is unitary and preserves the orthonormality of the orbitals. The resulting state matrix $\\Phi(0) \\equiv \\Phi(0^+)$ serves as the initial condition for the time propagation.\n\nThe core of the problem lies in the single-step propagation from $t=0$ to $t=\\Delta t$. The Hamiltonian is density-dependent, and thus time-dependent, through the $v_{\\mathrm{xc}}(n(x,t))$ term. To maintain second-order accuracy in the time step $\\Delta t$, a predictor-corrector scheme is employed to approximate the Hamiltonian at the midpoint of the interval, $\\mathbf{H}_{\\mathrm{mid}} \\approx \\mathbf{H}(t+\\Delta t/2)$.\n\nPredictor step: We first estimate the orbitals at the midpoint, $\\Phi_{pred}(\\Delta t/2)$. This is done by propagating the initial state $\\Phi(0)$ over a half-step $\\Delta t/2$ using the Hamiltonian at the initial time, $\\mathbf{H}_0 = \\mathbf{H}[n(0)]$. We use a unitary exponential propagator for this prediction:\n$$\n\\Phi_{pred}(\\Delta t/2) = \\exp(-\\mathrm{i} \\frac{\\Delta t}{2} \\mathbf{H}_0) \\Phi(0)\n$$\nFrom these predicted orbitals, we compute the predicted midpoint density $n_{pred}(\\Delta t/2) = \\sum_j |\\phi_{j,pred}(\\Delta t/2)|^2$.\n\nCorrector step: Using this predicted density, we construct the midpoint exchange-correlation potential $v_{\\mathrm{xc,mid}} = v_{\\mathrm{xc}}(n_{pred}(\\Delta t/2))$ and the corresponding midpoint Hamiltonian $\\mathbf{H}_{\\mathrm{mid}} = \\mathbf{T} + \\mathbf{V}_{\\mathrm{ext}} + \\mathrm{diag}(v_{\\mathrm{xc,mid}})$. This Hamiltonian is now treated as constant over the full time step $[0, \\Delta t]$.\n\nWith the fixed midpoint Hamiltonian $\\mathbf{H}_{\\mathrm{mid}}$, we perform the propagation from $t=0$ to $t=\\Delta t$ using two distinct methods:\n\n1.  Crank-Nicolson (CN): This implicit method is based on a second-order Padé approximation of the exponential propagator, $\\exp(-z) \\approx (1-z/2)/(1+z/2)$. The time-evolution equation becomes a system of linear equations for the state at the new time, $\\Phi(\\Delta t)$:\n    $$\n    \\left(\\mathbf{I} + \\frac{\\mathrm{i}\\Delta t}{2} \\mathbf{H}_{\\mathrm{mid}}\\right) \\Phi_{\\mathrm{CN}}(\\Delta t) = \\left(\\mathbf{I} - \\frac{\\mathrm{i}\\Delta t}{2} \\mathbf{H}_{\\mathrm{mid}}\\right) \\Phi(0)\n    $$\n    We solve this system for each orbital in the matrix $\\Phi_{\\mathrm{CN}}(\\Delta t)$. While this method is unconditionally stable for linear problems, its propagator is not exactly unitary, which can lead to slight norm deviation.\n\n2.  Second-order Magnus (Exponential Midpoint): This method uses the exact exponential of the midpoint Hamiltonian as the propagator. It is exactly unitary for the time-independent $\\mathbf{H}_{\\mathrm{mid}}$:\n    $$\n    \\Phi_{\\mathrm{Mag}}(\\Delta t) = \\exp(-\\mathrm{i} \\Delta t \\mathbf{H}_{\\mathrm{mid}}) \\Phi(0)\n    $$\n    The matrix exponential is computed numerically, for example, using a Padé approximant-based algorithm as implemented in `scipy.linalg.expm`.\n\nAfter propagating the orbitals with both schemes, we obtain $\\Phi_{\\mathrm{CN}}(\\Delta t)$ and $\\Phi_{\\mathrm{Mag}}(\\Delta t)$. As a final step, we re-orthonormalize the set of occupied orbitals for each method separately to correct for any numerical drift and ensure that the density is computed from an orthonormal set. From the orthonormalized orbitals, we compute the final densities $n_{\\mathrm{CN}}(\\Delta t)$ and $n_{\\mathrm{Mag}}(\\Delta t)$.\n\nThe final result is the weighted $L^2$-norm of the difference between the two densities, which quantifies the disagreement between the two propagation schemes for the given set of parameters:\n$$\nD = \\left( \\sum_{\\ell=0}^{N-1} \\left( n_{\\mathrm{CN}}(x_\\ell) - n_{\\mathrm{Mag}}(x_\\ell) \\right)^2 \\Delta x \\right)^{1/2}\n$$\nThis procedure is implemented for each test case to produce the required output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm, solve as linsolve\n\ndef run_one_step(N, L, dt, omega, alpha, k, N_occ):\n    \"\"\"\n    Implements a one-step real-time TDDFT propagation using Crank-Nicolson\n    and Magnus propagators and computes the density difference.\n    \"\"\"\n    # 1. Grid and constants setup\n    dx = L / N\n    x = np.arange(N) * dx - L / 2\n    C = (3 / np.pi)**(1/3)\n\n    # 2. Kinetic energy operator matrix (T) from 2nd-order finite difference\n    diag_val = -2.0 / dx**2\n    off_diag_val = 1.0 / dx**2\n    \n    # Laplacian matrix (D2)\n    D2 = np.diag(np.full(N, diag_val)) + \\\n         np.diag(np.full(N - 1, off_diag_val), k=1) + \\\n         np.diag(np.full(N - 1, off_diag_val), k=-1)\n    \n    # Periodic boundary conditions\n    D2[0, N - 1] = off_diag_val\n    D2[N - 1, 0] = off_diag_val\n    \n    T = -0.5 * D2\n\n    # 3. Initial Kohn-Sham orbitals (at t = 0^-)\n    phi_mat_0_minus = np.zeros((N, N_occ), dtype=np.complex128)\n    \n    # Ground state of harmonic oscillator\n    phi0_analytic = (omega / np.pi)**(0.25) * np.exp(-0.5 * omega * x**2)\n    phi_mat_0_minus[:, 0] = phi0_analytic\n    \n    if N_occ == 2:\n        # First excited state of harmonic oscillator\n        phi1_analytic = np.sqrt(2 * omega) * x * phi0_analytic\n        phi_mat_0_minus[:, 1] = phi1_analytic\n        \n    # Orthonormalize initial orbitals on the grid using QR decomposition\n    # We want <psi_i | psi_j> = sum_l(psi_i_l* . psi_j_l) * dx = delta_ij\n    # This is equivalent to ensuring the columns of sqrt(dx) * Phi are orthonormal.\n    q, _ = np.linalg.qr(np.sqrt(dx) * phi_mat_0_minus)\n    phi_mat_0_minus = q / np.sqrt(dx)\n\n    # 4. Apply delta-kick perturbation to get state at t = 0^+\n    kick_factor = np.exp(-1j * k * x)\n    # Use broadcasting to apply the kick to each orbital column\n    phi_mat_0 = kick_factor[:, np.newaxis] * phi_mat_0_minus\n\n    # 5. Predictor-Corrector scheme for the midpoint Hamiltonian\n    # --- Predictor Step ---\n    # Calculate density and potential at t=0\n    n_0 = np.sum(np.abs(phi_mat_0)**2, axis=1)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        v_xc_0 = -alpha * C * np.cbrt(n_0)\n        v_xc_0[n_0 == 0] = 0 # Handle n=0 case explicitly\n    \n    v_ext = 0.5 * omega**2 * x**2\n    V_0 = np.diag(v_ext + v_xc_0)\n    H_0 = T + V_0\n    \n    # Predict orbitals at t = dt/2 using Magnus propagator\n    U_pred = expm(-1j * (dt / 2) * H_0)\n    phi_mat_pred = U_pred @ phi_mat_0\n    \n    # Calculate predicted midpoint density\n    n_mid_pred = np.sum(np.abs(phi_mat_pred)**2, axis=1)\n\n    # --- Corrector Step ---\n    # Build midpoint Hamiltonian H_mid\n    with np.errstate(divide='ignore', invalid='ignore'):\n        v_xc_mid = -alpha * C * np.cbrt(n_mid_pred)\n        v_xc_mid[n_mid_pred == 0] = 0\n    \n    V_mid = np.diag(v_ext + v_xc_mid)\n    H_mid = T + V_mid\n\n    # 6. Main propagation from t=0 to t=dt with H_mid\n    # --- Crank-Nicolson Propagator ---\n    I = np.identity(N, dtype=np.complex128)\n    A_cn = I + 0.5j * dt * H_mid\n    B_cn = I - 0.5j * dt * H_mid\n    rhs_cn = B_cn @ phi_mat_0\n    # Solve the linear system for each orbital\n    phi_mat_cn_raw = linsolve(A_cn, rhs_cn)\n\n    # --- Second-order Magnus Propagator ---\n    U_mag = expm(-1j * dt * H_mid)\n    phi_mat_mag_raw = U_mag @ phi_mat_0\n\n    # 7. Post-processing\n    # Re-orthonormalize propagated orbitals\n    q_cn, _ = np.linalg.qr(np.sqrt(dx) * phi_mat_cn_raw)\n    phi_mat_cn_final = q_cn / np.sqrt(dx)\n    \n    q_mag, _ = np.linalg.qr(np.sqrt(dx) * phi_mat_mag_raw)\n    phi_mat_mag_final = q_mag / np.sqrt(dx)\n    \n    # Calculate final densities\n    n_cn_final = np.sum(np.abs(phi_mat_cn_final)**2, axis=1)\n    n_mag_final = np.sum(np.abs(phi_mat_mag_final)**2, axis=1)\n\n    # 8. Compute the weighted L2-norm of the density difference\n    density_diff_sq = (n_cn_final - n_mag_final)**2\n    D = np.sqrt(np.sum(density_diff_sq) * dx)\n    \n    return D\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, L, dt, omega, alpha, k, N_occ)\n        (128, 20, 0.05,   0.5, 0.8, 0.001,  1),\n        (128, 20, 0.005,  0.5, 0.8, 0.001,  1),\n        (128, 20, 0.10,   0.5, 0.8, 0.001,  1),\n        (128, 20, 0.05,   0.5, 0.8, 0.0005, 2),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, L, dt, omega, alpha, k, N_occ = case\n        result = run_one_step(N, L, dt, omega, alpha, k, N_occ)\n        results.append(f\"{result:.10e}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once we can propagate orbitals in time, we can simulate how a molecule responds to external fields and extract spectroscopic information. This practice demonstrates the powerful link between time-domain dynamics and frequency-domain spectroscopy. You will start with a synthetic time-dependent dipole moment, mimicking the response of a molecule to a pulse of light, and then use the Fourier transform to reconstruct the material's absorption spectrum, a process central to comparing TDDFT predictions with experimental results .",
            "id": "2932976",
            "problem": "You are given a simplified, fully specified linear-response scenario meant to emulate how a real-time Time-Dependent Density Functional Theory (TDDFT) simulation yields an absorption spectrum after a small impulsive electric field (\"delta kick\") and how to compare that spectrum to results from Casida’s equation. Your task is to construct a complete program that, for a set of prescribed test cases, reconstructs the oscillator strength distribution from a synthetic time-domain dipole trajectory and compares the recovered peak positions and intensities to the reference Casida excitation energies and oscillator strengths. The final output must aggregate the error metrics from all test cases into a single line, as specified below.\n\nFundamental base for derivation and algorithm design:\n- In linear response, a weak time-dependent external field induces a dipole moment described by the Kubo response function. The frequency-dependent polarizability $ \\alpha(\\omega) $ characterizes the proportionality between the induced dipole moment and the external field in frequency space.\n- Within the adiabatic approximation of Time-Dependent Density Functional Theory (TDDFT), Casida’s equation yields a discrete set of excitation energies $ \\{\\omega_k\\} $ and oscillator strengths $ \\{f_k\\} $ for a given direction (assume parallel alignment of the kick and dipole). These oscillator strengths are dimensionless and satisfy the Thomas–Reiche–Kuhn sum rule in the complete basis limit.\n- The absorption spectrum in the linear regime is proportional to $ \\omega \\,\\mathrm{Im}\\,\\alpha(\\omega) $. A standard, well-tested relation connects the oscillator strength distribution to the dynamical polarizability as $ S(\\omega) = \\dfrac{2}{\\pi}\\,\\omega\\,\\mathrm{Im}\\,\\alpha(\\omega) $, where $S(\\omega)$ integrates to the total oscillator strength and reduces to a sum of delta peaks $\\sum_k f_k \\,\\delta(\\omega-\\omega_k)$ in the ideal, infinite-time, zero-damping limit.\n\nFor the purposes of this problem, assume the following modeling choices are valid in the strict linear regime:\n- A \"delta-kick\" at time $ t=0 $ produces a synthetic time-dependent dipole moment trajectory modeled as a finite sum of exponentially damped sinusoids\n  $$ d(t) = \\sum_{k=1}^{K} \\frac{2 f_k}{\\omega_k}\\,\\sin(\\omega_k t)\\,e^{-\\eta t}, \\quad t \\ge 0, $$\n  where $ \\eta $ is a positive damping parameter that models dephasing and provides spectral broadening. All quantities are in atomic units: angular frequency $ \\omega $ in Hartree, time $ t $ in atomic time units, and $ \\eta $ in Hartree.\n- The oscillator strength density is reconstructed from the time signal by a one-sided discrete Fourier transform approximation to $\\alpha(\\omega)$,\n  $$ \\alpha(\\omega) \\approx \\int_{0}^{T} d(t)\\,e^{i \\omega t}\\,dt, $$\n  followed by\n  $$ S(\\omega) = \\frac{2}{\\pi}\\,\\omega\\,\\mathrm{Im}\\,\\alpha(\\omega). $$\n  In numerics, $ T $ is finite and the integral is replaced by a Riemann sum over a uniform time grid $ t_n = n\\,\\Delta t $, $ n=0,\\dots,N-1 $.\n\nProgram requirements:\n1. Input is implicit: implement the three test cases listed below directly in code. No user input or file I/O is permitted.\n2. For each test case, do all of the following:\n   - Construct $ d(t) $ on a uniform grid with the provided $ \\Delta t $, $ N $, $ \\eta $, $ \\{\\omega_k\\} $, and $ \\{f_k\\} $.\n   - Compute a one-sided discrete Fourier transform approximation to recover $\\alpha(\\omega)$ on the nonnegative angular-frequency grid associated with the transform. From this, compute $S(\\omega)$ via $S(\\omega) = \\dfrac{2}{\\pi}\\,\\omega\\,\\mathrm{Im}\\,\\alpha(\\omega)$.\n   - Using only $S(\\omega)$, extract for each prescribed reference peak $\\omega_k$:\n     a) A peak position estimate $\\widehat{\\omega}_k$ computed as the spectral centroid over a non-overlapping interval surrounding $\\omega_k$. Define the interval boundaries as midpoints between adjacent reference $\\omega_k$ values, with the first interval’s lower bound set to $\\omega_1 - 6\\eta$ and the last interval’s upper bound set to $\\omega_K + 6\\eta$. Clip any bound below $0$ to $0$. Use only data within each interval when computing $\\widehat{\\omega}_k$:\n     $$ \\widehat{\\omega}_k = \\frac{\\int_{\\mathrm{interval}_k} \\omega\\,S(\\omega)\\,d\\omega}{\\int_{\\mathrm{interval}_k} S(\\omega)\\,d\\omega}. $$\n     b) A peak intensity estimate $\\widehat{f}_k$ computed as the area under $S(\\omega)$ over the same interval:\n     $$ \\widehat{f}_k = \\int_{\\mathrm{interval}_k} S(\\omega)\\,d\\omega. $$\n   - Compute the following error metrics:\n     a) Maximum absolute peak-position error across all peaks in the test:\n     $$ \\varepsilon_{\\omega}^{\\max} = \\max_k \\left| \\widehat{\\omega}_k - \\omega_k \\right|, $$\n     expressed in Hartree.\n     b) Peak-intensity error aggregated as follows. For each $k$ with $f_k > 0$, define a relative error\n     $$ \\varepsilon_{f,k}^{\\mathrm{rel}} = \\frac{\\left|\\widehat{f}_k - f_k\\right|}{f_k}. $$\n     For any $k$ with $f_k = 0$, define an absolute area error\n     $$ \\varepsilon_{f,k}^{\\mathrm{abs0}} = \\left|\\widehat{f}_k\\right|. $$\n     Report the single worst-case peak-intensity error for the test as\n     $$ \\varepsilon_{f}^{\\max} = \\max\\Big(\\{\\varepsilon_{f,k}^{\\mathrm{rel}}: f_k>0\\}\\cup\\{\\varepsilon_{f,k}^{\\mathrm{abs0}}: f_k=0\\}\\Big). $$\n3. Output formatting: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Specifically, for the three tests below, print\n   $$ [\\varepsilon_{\\omega,1}^{\\max},\\varepsilon_{f,1}^{\\max},\\varepsilon_{\\omega,2}^{\\max},\\varepsilon_{f,2}^{\\max},\\varepsilon_{\\omega,3}^{\\max},\\varepsilon_{f,3}^{\\max}] $$\n   with no additional text. The units for $\\varepsilon_{\\omega}^{\\max}$ are Hartree, and the peak-intensity error entries are decimal numbers without any percentage sign.\n\nTest suite (hard-code these into your program):\n- Test 1 (well-separated lines):\n  - $ \\omega = [0.30,\\,0.55,\\,0.90] $ (Hartree),\n  - $ f = [0.20,\\,0.06,\\,0.12] $ (dimensionless),\n  - $ \\eta = 0.006 $ (Hartree),\n  - $ \\Delta t = 0.2 $ (atomic time units),\n  - $ N = 16384 $ (integer).\n- Test 2 (near-degenerate doublet):\n  - $ \\omega = [0.500,\\,0.515,\\,0.82] $ (Hartree),\n  - $ f = [0.10,\\,0.08,\\,0.02] $,\n  - $ \\eta = 0.004 $,\n  - $ \\Delta t = 0.2 $,\n  - $ N = 16384 $.\n- Test 3 (includes a dark state):\n  - $ \\omega = [0.40,\\,0.70,\\,0.95] $ (Hartree),\n  - $ f = [0.15,\\,0.00,\\,0.04] $,\n  - $ \\eta = 0.006 $,\n  - $ \\Delta t = 0.2 $,\n  - $ N = 16384 $.\n\nImplementation notes:\n- All computations are in atomic units. Explicitly report $\\varepsilon_{\\omega}^{\\max}$ in Hartree and the peak-intensity error values as decimal numbers (no percentage sign).\n- Use numerical quadrature via the trapezoidal rule on the discrete frequency grid to implement all $\\omega$-domain integrals.\n- Ensure all peak intervals constructed as described are non-overlapping and clipped to $\\omega \\ge 0$.\n- The algorithm must be robust to line overlap and finite-time windowing errors, and the test suite explores a typical case, a near-degenerate case, and the presence of a dark (forbidden) transition. The final numerical outputs must be floats.",
            "solution": "The problem presented is a well-posed computational task grounded in the principles of time-dependent density functional theory (TDDFT) in the linear response regime. It asks for the implementation of a standard workflow: generation of a time-domain dipole signal from a set of known electronic excitations, numerical Fourier transformation to obtain an absorption spectrum, and subsequent analysis of that spectrum to recover the original excitation properties. The problem is scientifically sound, internally consistent, and complete. All parameters, models, and procedures are specified unambiguously. Therefore, the problem is deemed valid and a complete solution will be constructed.\n\nThe algorithm is designed to follow the prescribed sequence of operations for each test case. All calculations are performed in atomic units.\n\nFirst, the synthetic time-dependent dipole moment, denoted $d(t)$, is constructed on a discrete time grid. The problem specifies the model for the dipole response to a delta-function electric field pulse at time $t=0$ as a sum over $K$ electronic transitions:\n$$\nd(t) = \\sum_{k=1}^{K} \\frac{2 f_k}{\\omega_k}\\,\\sin(\\omega_k t)\\,e^{-\\eta t}, \\quad t \\ge 0\n$$\nHere, $\\{\\omega_k\\}$ are the reference excitation energies, $\\{f_k\\}$ are the dimensionless oscillator strengths, and $\\eta$ is a phenomenological damping parameter that broadens the spectral lines into Lorentzians. The time grid is uniform, defined by $t_n = n\\,\\Delta t$ for $n = 0, 1, \\dots, N-1$, where $\\Delta t$ is the time step and $N$ is the total number of points. For a given test case, the signal $d(t_n)$ is computed by summing the contributions from each transition with a non-zero oscillator strength $f_k > 0$.\n\nSecond, the absorption spectrum is derived from the frequency-dependent polarizability, $\\alpha(\\omega)$. The problem defines a one-sided Fourier transform to approximate $\\alpha(\\omega)$ from the time-domain signal:\n$$\n\\alpha(\\omega) \\approx \\int_{0}^{T} d(t)\\,e^{i \\omega t}\\,dt\n$$\nwhere the integration limit $T$ corresponds to the total simulation time, $T = N \\Delta t$. This integral is numerically evaluated using a discrete Fourier transform. Specifically, the expression $\\sum_{n=0}^{N-1} d(t_n) e^{i \\omega_m t_n} \\Delta t$ is computed, where the discrete frequencies are $\\omega_m = 2\\pi m / (N \\Delta t)$. This specific sum corresponds to the inverse Discrete Fourier Transform (IDFT), scaled by the total time duration $N\\Delta t$. We use `numpy.fft.ifft` to compute the IDFT and then perform the scaling. The calculation yields $\\alpha(\\omega)$ on a grid of discrete frequencies. We retain only the components corresponding to non-negative frequencies, $\\omega \\ge 0$. From this, the oscillator strength density, $S(\\omega)$, is calculated using the provided relation:\n$$\nS(\\omega) = \\frac{2}{\\pi}\\,\\omega\\,\\mathrm{Im}\\,\\alpha(\\omega)\n$$\n\nThird, the computed spectrum $S(\\omega)$ is analyzed to extract estimates of the peak positions, $\\widehat{\\omega}_k$, and peak intensities, $\\widehat{f}_k$. This requires partitioning the frequency axis into a set of $K$ non-overlapping intervals, one for each reference peak $\\omega_k$. The boundaries of these intervals are defined as the midpoints between adjacent reference frequencies, i.e., $(\\omega_i + \\omega_{i+1})/2$. The first interval begins at $\\omega_1 - 6\\eta$, and the last interval ends at $\\omega_K + 6\\eta$. All interval boundaries are clipped to be non-negative. Within each interval $k$, the estimated peak position $\\widehat{\\omega}_k$ is calculated as the spectral centroid, while the estimated intensity $\\widehat{f}_k$ is the total area under the spectral curve:\n$$\n\\widehat{\\omega}_k = \\frac{\\int_{\\mathrm{interval}_k} \\omega\\,S(\\omega)\\,d\\omega}{\\int_{\\mathrm{interval}_k} S(\\omega)\\,d\\omega}, \\quad \\widehat{f}_k = \\int_{\\mathrm{interval}_k} S(\\omega)\\,d\\omega\n$$\nThese integrals are performed numerically over the discrete frequency grid using the trapezoidal rule, as specified by the `scipy.integrate.trapezoid` function.\n\nFinally, for each test case, two error metrics are computed to quantify the accuracy of the recovery process. The maximum absolute peak-position error, $\\varepsilon_{\\omega}^{\\max}$, is the largest deviation between an estimated peak position and its reference value:\n$$\n\\varepsilon_{\\omega}^{\\max} = \\max_k |\\widehat{\\omega}_k - \\omega_k|\n$$\nThe maximum peak-intensity error, $\\varepsilon_{f}^{\\max}$, is defined in a hybrid manner to handle both bright states ($f_k > 0$) and dark states ($f_k = 0$). For bright states, a relative error is used, $\\varepsilon_{f,k}^{\\mathrm{rel}} = |\\widehat{f}_k - f_k|/f_k$. For dark states, an absolute area error is used, $\\varepsilon_{f,k}^{\\mathrm{abs0}} = |\\widehat{f}_k|$. The final metric is the maximum of all these individual errors:\n$$\n\\varepsilon_{f}^{\\max} = \\max\\Big(\\{\\varepsilon_{f,k}^{\\mathrm{rel}}: f_k>0\\}\\cup\\{\\varepsilon_{f,k}^{\\mathrm{abs0}}: f_k=0\\}\\Big)\n$$\nThe program processes all $3$ test cases, aggregates the $2$ error metrics from each into a single list, and prints the result in the required format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import trapezoid\n\ndef process_case(case_params):\n    \"\"\"\n    Processes a single test case to compute spectral reconstruction errors.\n\n    Args:\n        case_params (tuple): A tuple containing the parameters for the test case:\n            (ref_omegas, ref_fs, eta, delta_t, N).\n\n    Returns:\n        tuple: A tuple containing the two error metrics (eps_omega_max, eps_f_max).\n    \"\"\"\n    ref_omegas, ref_fs, eta, delta_t, N = case_params\n\n    # Step 1: Construct the time-dependent dipole moment d(t)\n    t = np.arange(N) * delta_t\n    d_t = np.zeros(N, dtype=np.float64)\n    for omega_k, f_k in zip(ref_omegas, ref_fs):\n        # The model formula involves 1/omega_k, so we only add terms for non-zero frequencies\n        if omega_k > 0 and f_k > 0:\n            d_t += (2.0 * f_k / omega_k) * np.sin(omega_k * t) * np.exp(-eta * t)\n\n    # Step 2: Compute the spectrum S(omega) via Fourier Transform\n    # The required transform is integral[d(t) * exp(i*omega*t)] dt.\n    # This corresponds to N * dt * ifft(d_t).\n    alpha_omega_full = N * delta_t * np.fft.ifft(d_t)\n    omega_grid_full = np.fft.fftfreq(N, delta_t) * 2.0 * np.pi\n\n    # For robustness, fftshift to get a monotonic frequency axis.\n    alpha_omega_shifted = np.fft.fftshift(alpha_omega_full)\n    omega_grid_shifted = np.fft.fftshift(omega_grid_full)\n    \n    # Keep only the non-negative frequency part of the spectrum.\n    zero_idx = np.searchsorted(omega_grid_shifted, 0.0)\n    omega_grid = omega_grid_shifted[zero_idx:]\n    alpha_omega_nonneg = alpha_omega_shifted[zero_idx:]\n\n    # Calculate the oscillator strength density S(omega)\n    S_omega = (2.0 / np.pi) * omega_grid * np.imag(alpha_omega_nonneg)\n\n    # Step 3: Analyze peaks by integrating over specified intervals\n    K = len(ref_omegas)\n    if K > 1:\n        midpoints = (ref_omegas[:-1] + ref_omegas[1:]) / 2.0\n        bounds = np.concatenate(\n            ([ref_omegas[0] - 6.0 * eta], midpoints, [ref_omegas[-1] + 6.0 * eta])\n        )\n    else: # Handle case with a single peak\n        bounds = np.array([ref_omegas[0] - 6.0 * eta, ref_omegas[0] + 6.0 * eta])\n        \n    bounds = np.maximum(0.0, bounds)\n\n    omega_hats = []\n    f_hats = []\n\n    for k in range(K):\n        w_min, w_max = bounds[k], bounds[k + 1]\n\n        # Find the slice of the frequency grid corresponding to the interval\n        start_idx = np.searchsorted(omega_grid, w_min, side='left')\n        end_idx = np.searchsorted(omega_grid, w_max, side='right')\n\n        # Ensure we have at least two points for trapezoidal rule\n        if end_idx > start_idx:\n            omega_sub = omega_grid[start_idx:end_idx]\n            S_sub = S_omega[start_idx:end_idx]\n\n            # Numerically integrate using the trapezoidal rule\n            area = trapezoid(S_sub, omega_sub)\n            centroid_numerator = trapezoid(omega_sub * S_sub, omega_sub)\n            \n            f_hat = area\n            if np.abs(area) < 1e-15:\n                # Avoid division by zero for dark states or empty intervals\n                omega_hat = (w_min + w_max) / 2.0\n            else:\n                omega_hat = centroid_numerator / area\n        else: # Interval contains less than 2 points\n            omega_hat = (w_min + w_max) / 2.0\n            f_hat = 0.0\n\n        omega_hats.append(omega_hat)\n        f_hats.append(f_hat)\n\n    omega_hats = np.array(omega_hats)\n    f_hats = np.array(f_hats)\n\n    # Step 4: Compute error metrics\n    eps_omega_max = np.max(np.abs(omega_hats - ref_omegas))\n    \n    f_errors = []\n    for k in range(K):\n        if ref_fs[k] > 0:\n            error = np.abs(f_hats[k] - ref_fs[k]) / ref_fs[k]\n        else:  # For dark states (f_k = 0)\n            error = np.abs(f_hats[k])\n        f_errors.append(error)\n    \n    eps_f_max = np.max(f_errors)\n    \n    return eps_omega_max, eps_f_max\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test 1 (well-separated lines)\n        (np.array([0.30, 0.55, 0.90]), np.array([0.20, 0.06, 0.12]), 0.006, 0.2, 16384),\n        # Test 2 (near-degenerate doublet)\n        (np.array([0.500, 0.515, 0.82]), np.array([0.10, 0.08, 0.02]), 0.004, 0.2, 16384),\n        # Test 3 (includes a dark state)\n        (np.array([0.40, 0.70, 0.95]), np.array([0.15, 0.00, 0.04]), 0.006, 0.2, 16384),\n    ]\n\n    results = []\n    for case in test_cases:\n        # To ensure robustness, sort peaks by frequency for interval calculation logic\n        omegas, fs, eta, dt, N = case\n        sort_indices = np.argsort(omegas)\n        sorted_case = (omegas[sort_indices], fs[sort_indices], eta, dt, N)\n        \n        eps_omega_max, eps_f_max = process_case(sorted_case)\n        results.append(eps_omega_max)\n        results.append(eps_f_max)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A skilled practitioner must not only know how to use a tool but also when it is likely to fail. This exercise illuminates one of the most well-known limitations of standard TDDFT approximations: the description of long-range charge-transfer excitations. Starting from fundamental principles, you will derive both the physically correct expression for the excitation energy and the erroneous prediction made by semilocal functionals, thereby gaining a deep, conceptual understanding of why these functionals fail and why more advanced methods are often necessary .",
            "id": "2466214",
            "problem": "You are asked to write a complete, runnable program that demonstrates, within a minimal but scientifically grounded model, how Time-Dependent Density Functional Theory (TD-DFT) using a standard Generalized Gradient Approximation (GGA) functional can wrongly predict a spuriously low-energy charge-transfer excitation in a spatially separated donor–acceptor pair. Your program must implement the following logic from first principles.\n\nBegin from the fundamental definitions of ionization potential and electron affinity in density functional theory (DFT), and from the electrostatic interaction of separated charges. Use these principles to derive an expression for the lowest donor-to-acceptor charge-transfer excitation energy at large separation. Then, using linear-response TD-DFT and the fact that for spatially nonoverlapping orbitals the adiabatic semilocal Hartree–exchange–correlation kernel yields vanishing coupling, derive the corresponding prediction made by a semilocal GGA functional. Finally, connect the Kohn–Sham orbital energy difference to the fundamental gap by including the derivative discontinuity. Do not use or quote any pre-existing shortcut formulas in your derivation; instead, reason from the following foundational bases only:\n- Fundamental definitions: the ionization potential $I$ and electron affinity $A$ defined via total energy differences, and the electrostatic interaction energy of two unit charges separated by a distance $R$.\n- Linear-response theory core ideas: that the excitation energy arises from a response pole determined by a noninteracting transition energy and a coupling term, and that for charge-transfer between spatially separated fragments with negligible orbital overlap, a local and adiabatic kernel provides negligible long-range coupling.\n- The well-tested conceptual fact that the many-body fundamental gap is related to the Kohn–Sham gap by the derivative discontinuity.\n\nImplement a minimal two-fragment model with the following parameters for each test case:\n- Donor ionization potential $I_D$ in Hartree.\n- Acceptor electron affinity $A_A$ in Hartree.\n- Center-to-center separation $R$ in bohr.\n- An effective positive derivative-discontinuity parameter $\\Delta_{\\mathrm{xc}}$ in Hartree that captures the gap underestimation characteristic of a semilocal GGA functional.\n\nFor each test case, compute:\n1. The physically motivated large-separation charge-transfer excitation energy, based on the above principles, expressed in Hartree and denoted here as $E_{\\mathrm{true}}$.\n2. The adiabatic semilocal GGA TD-DFT prediction for the same charge-transfer excitation, expressed in Hartree and denoted here as $E_{\\mathrm{GGA}}$.\n3. The signed error $\\Delta E = E_{\\mathrm{GGA}} - E_{\\mathrm{true}}$ in Hartree.\n4. A boolean flag that is true if and only if the GGA prediction is spuriously low, defined by the strict inequality $E_{\\mathrm{GGA}} < E_{\\mathrm{true}}$.\n\nYour program must use the following fixed test suite of parameter tuples $(I_D,A_A,R,\\Delta_{\\mathrm{xc}})$, in atomic units (Hartree for energies, bohr for distances):\n- Test 1 (general separated pair): $(0.30, 0.08, 30.0, 0.12)$.\n- Test 2 (very large separation): $(0.30, 0.08, 200.0, 0.12)$.\n- Test 3 (small fundamental gap leading to near-zero GGA excitation): $(0.20, 0.08, 25.0, 0.12)$.\n- Test 4 (numerical balance where the underestimation equals the missing electrostatics at this $R$): $(0.25, 0.05, 8.\\overline{3}, 0.12)$, where $8.\\overline{3}$ denotes $25/3$ in bohr.\n\nAll energies must be expressed in Hartree and rounded to six decimal places. For each test case, your program must output the four values $E_{\\mathrm{true}}$, $E_{\\mathrm{GGA}}$, $\\Delta E$, and the boolean flag, in that order. Aggregate the results for all test cases into a single flat list. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,...]\").\n\nAngle units are not involved. No external input is permitted; the program must be fully self-contained and produce the required single-line output upon execution.",
            "solution": "The problem statement is scientifically grounded, well-posed, and contains all necessary information to derive a unique solution. It describes a well-known failure mode of common density functional approximations. The problem is therefore deemed valid, and a solution will be constructed based on the provided first principles.\n\nWe begin by deriving the expression for the physically correct charge-transfer ($CT$) excitation energy at large separation, denoted $E_{\\mathrm{true}}$. A $CT$ excitation involves moving an electron from a donor molecule, $D$, to an acceptor molecule, $A$, separated by a distance $R$. This process can be represented as $D^0A^0 \\rightarrow D^+A^-$. The energy of this excitation, $\\omega_{CT}$, is the difference in the total energies of the final and initial states:\n$$ \\omega_{CT} = E(D^+A^-) - E(D^0A^0) $$\nIn the limit of large separation $R$, the energy of a combined system can be approximated as the sum of the energies of its non-interacting constituent fragments plus their classical electrostatic interaction energy. For the initial neutral state, this is:\n$$ E(D^0A^0) \\approx E(D^0) + E(A^0) $$\nFor the final ionic state, the energy includes the electrostatic attraction between the newly formed ions:\n$$ E(D^+A^-) \\approx E(D^+) + E(A^-) + E_{\\mathrm{int}} $$\nHere, $E(X)$ represents the total energy of species $X$. The interaction energy, $E_{\\mathrm{int}}$, between a point charge of $+1e$ on $D^+$ and $-1e$ on $A^-$ is given by Coulomb's law. In atomic units, where energy is in Hartree and distance is in bohr, this is:\n$$ E_{\\mathrm{int}} = -\\frac{1}{R} $$\nBy substituting these expressions into the equation for $\\omega_{CT}$, we obtain:\n$$ \\omega_{CT} \\approx \\left( E(D^+) + E(A^-) - \\frac{1}{R} \\right) - \\left( E(D^0) + E(A^0) \\right) $$\nRearranging the terms to group them by species yields:\n$$ \\omega_{CT} \\approx \\left( E(D^+) - E(D^0) \\right) + \\left( E(A^-) - E(A^0) \\right) - \\frac{1}{R} $$\nThe terms in parentheses correspond to fundamental definitions. The ionization potential of the donor, $I_D$, is the energy required to remove an electron:\n$$ I_D = E(D^+) - E(D^0) $$\nThe electron affinity of the acceptor, $A_A$, is the energy released upon capturing an electron, defined as:\n$$ A_A = E(A^0) - E(A^-) $$\nFrom this definition, it follows that $E(A^-) - E(A^0) = -A_A$. By substituting these definitions for $I_D$ and $A_A$, we arrive at the expression for the true large-separation charge-transfer excitation energy:\n$$ E_{\\mathrm{true}} = I_D - A_A - \\frac{1}{R} $$\n\nNext, we derive the corresponding prediction from adiabatic semilocal Time-Dependent Density Functional Theory ($TD-DFT$), denoted $E_{\\mathrm{GGA}}$. Within linear-response $TD-DFT$, the excitation energies $\\omega$ are obtained as the eigenvalues of a matrix equation. For a single excitation from an occupied Kohn-Sham ($KS$) orbital $\\phi_i$ to a virtual $KS$ orbital $\\phi_a$, the excitation energy in the adiabatic approximation is given by:\n$$ \\omega_{ia} = \\varepsilon_a - \\varepsilon_i + K_{ia,ia} $$\nwhere $\\varepsilon_i$ and $\\varepsilon_a$ are the energies of the $KS$ orbitals, and $K_{ia,ia}$ is the coupling matrix element. This element depends on the Hartree-exchange-correlation ($HXC$) kernel, $f_{HXC}$:\n$$ K_{ia,ia} = \\iint \\phi_i^*(\\mathbf{r})\\phi_a(\\mathbf{r}) f_{HXC}(\\mathbf{r}, \\mathbf{r}') \\phi_a^*(\\mathbf{r}')\\phi_i(\\mathbf{r}') d\\mathbf{r} d\\mathbf{r}' $$\nFor the $CT$ excitation under consideration, the occupied orbital $\\phi_i$ is the highest occupied molecular orbital of the donor ($HOMO_D$) and the virtual orbital $\\phi_a$ is the lowest unoccupied molecular orbital of the acceptor ($LUMO_A$). At large separation $R$, these orbitals are spatially isolated, and their overlap product, $\\phi_i(\\mathbf{r})\\phi_a(\\mathbf{r})$, is negligible for all $\\mathbf{r}$.\nFor a semilocal functional, such as a Generalized Gradient Approximation ($GGA$), the kernel $f_{HXC}^{GGA}(\\mathbf{r}, \\mathbf{r}')$ is effectively local, meaning it vanishes rapidly as the distance $|\\mathbf{r} - \\mathbf{r}'|$ increases. The combination of a local kernel and vanishing orbital overlap causes the coupling integral $K_{ia,ia}$ to become zero:\n$$ K_{ia,ia}^{GGA} \\approx 0 $$\nConsequently, the $TD-GGA$ excitation energy spuriously reduces to the simple difference in the energies of the $KS$ orbitals involved:\n$$ E_{\\mathrm{GGA}} = \\omega_{CT}^{GGA} \\approx \\varepsilon_{LUMO,A} - \\varepsilon_{HOMO,D} $$\nTo make this expression useful, we must relate this $KS$ orbital energy gap to the physical quantities $I_D$ and $A_A$. The fundamental many-body gap of the combined $D-A$ system is $E_{gap} = I_D - A_A$. The corresponding $KS$ gap is $\\varepsilon_{gap}^{KS} = \\varepsilon_{LUMO,A} - \\varepsilon_{HOMO,D}$. For an exact functional, these quantities are related via the derivative discontinuity of the exchange-correlation potential, $\\Delta_{xc}$:\n$$ E_{gap} = \\varepsilon_{gap}^{KS} + \\Delta_{xc} \\implies I_D - A_A = (\\varepsilon_{LUMO,A} - \\varepsilon_{HOMO,D}) + \\Delta_{xc} $$\nApproximate functionals like $GGA$ are known to suffer from a systematic error that effectively corresponds to a missing derivative discontinuity. The problem provides an effective parameter, $\\Delta_{\\mathrm{xc}} > 0$, to model this deficiency. Rearranging the equation for the $KS$ gap as predicted within a $GGA$ framework gives:\n$$ \\varepsilon_{LUMO,A}^{GGA} - \\varepsilon_{HOMO,D}^{GGA} = (I_D - A_A) - \\Delta_{\\mathrm{xc}} $$\nThis provides the final expression for the $TD-GGA$ charge-transfer excitation energy:\n$$ E_{\\mathrm{GGA}} = I_D - A_A - \\Delta_{\\mathrm{xc}} $$\nThis result incorrectly shows the excitation energy approaching a constant value at large $R$, completely missing the correct $-1/R$ asymptotic behavior.\n\nFinally, we compute the signed error $\\Delta E$ and establish the condition for a spuriously low prediction. The error is the difference between the $GGA$ value and the true value:\n$$ \\Delta E = E_{\\mathrm{GGA}} - E_{\\mathrm{true}} = (I_D - A_A - \\Delta_{\\mathrm{xc}}) - \\left(I_D - A_A - \\frac{1}{R}\\right) $$\n$$ \\Delta E = \\frac{1}{R} - \\Delta_{\\mathrm{xc}} $$\nThe $GGA$ prediction is spuriously low if and only if $E_{\\mathrm{GGA}} < E_{\\mathrm{true}}$, which implies $\\Delta E < 0$. This gives the condition:\n$$ \\frac{1}{R} - \\Delta_{\\mathrm{xc}} < 0 \\implies \\frac{1}{R} < \\Delta_{\\mathrm{xc}} $$\nAs separation $R$ increases, $1/R$ decreases. For any system with a non-zero gap-underestimation error ($\\Delta_{\\mathrm{xc}} > 0$), there exists a separation beyond which this inequality holds, demonstrating the fundamental failure of adiabatic semilocal functionals for describing long-range charge transfer. The following program implements these derived formulas.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the true and TD-GGA charge-transfer excitation energies for a\n    series of donor-acceptor pairs to demonstrate the failure of semilocal DFT.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple is (I_D, A_A, R, delta_xc) in atomic units.\n    test_cases = [\n        # Test 1: General separated pair\n        (0.30, 0.08, 30.0, 0.12),\n        # Test 2: Very large separation\n        (0.30, 0.08, 200.0, 0.12),\n        # Test 3: Small fundamental gap\n        (0.20, 0.08, 25.0, 0.12),\n        # Test 4: Numerical balance point\n        (0.25, 0.05, 25.0/3.0, 0.12),\n    ]\n\n    results = []\n    for case in test_cases:\n        I_D, A_A, R, delta_xc = case\n        \n        # 1. Calculate the physically motivated charge-transfer energy, E_true.\n        # This is derived from E_true = I_D - A_A - 1/R.\n        E_true = I_D - A_A - 1.0/R\n        \n        # 2. Calculate the adiabatic semilocal GGA TD-DFT prediction, E_GGA.\n        # This is derived from E_GGA = I_D - A_A - delta_xc.\n        E_gga = I_D - A_A - delta_xc\n        \n        # 3. Calculate the signed error, delta_E.\n        # This is delta_E = E_GGA - E_true, which simplifies to 1/R - delta_xc.\n        delta_E = 1.0/R - delta_xc\n\n        # 4. Determine if the GGA prediction is spuriously low.\n        # This is true if E_GGA < E_true.\n        is_spurious = E_gga < E_true\n\n        # Append the four required results for this test case.\n        # Energies are rounded to six decimal places.\n        results.append(np.round(E_true, 6))\n        results.append(np.round(E_gga, 6))\n        results.append(np.round(delta_E, 6))\n        results.append(is_spurious)\n        \n    # Final print statement in the exact required format.\n    # The boolean `True`/`False` is converted to string \"True\"/\"False\".\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}