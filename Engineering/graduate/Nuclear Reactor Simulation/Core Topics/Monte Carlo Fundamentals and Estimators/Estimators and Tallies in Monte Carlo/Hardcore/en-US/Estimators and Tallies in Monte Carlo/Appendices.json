{
    "hands_on_practices": [
        {
            "introduction": "In Monte Carlo $k$-eigenvalue calculations, the raw output of a reaction rate tally is a dimensionless number whose physical interpretation depends entirely on the normalization convention used. This exercise explores the two most common conventions—normalization per source particle and per fission event—which are essential for correctly interpreting simulation results. By working through the derivation to convert between these normalizations, you will gain a fundamental understanding of how to transform abstract tally scores into physically meaningful reaction rates .",
            "id": "4224230",
            "problem": "A steady-state neutron transport problem is solved using a Monte Carlo $k$-eigenvalue simulation for a homogeneous reactor with no external source, where the fission source drives the population from generation to generation. In such simulations, two common flux normalizations are used: per-source-particle normalization and per-fission-event normalization.\n\nStart from the $k$-eigenvalue form of the steady-state neutron balance, which can be written symbolically as\n$$ \\mathcal{L}\\,\\phi = \\frac{1}{k_{\\text{eff}}}\\,\\mathcal{F}\\,\\phi, $$\nwhere $\\mathcal{L}$ is the streaming-and-loss operator, $\\mathcal{F}$ is the fission production operator containing the average number of neutrons produced per fission $\\nu$, and $k_{\\text{eff}}$ is the effective neutron multiplication factor. Let the total fission rate be $F \\equiv \\int_{V}\\Sigma_{f}(\\mathbf{r},E)\\,\\phi(\\mathbf{r},E)\\,\\mathrm{d}V\\,\\mathrm{d}E$ and the total fission neutron production rate be $P \\equiv \\int_{V}\\nu(\\mathbf{r},E)\\,\\Sigma_{f}(\\mathbf{r},E)\\,\\phi(\\mathbf{r},E)\\,\\mathrm{d}V\\,\\mathrm{d}E$. Let $R_{r} \\equiv \\int_{V}\\Sigma_{r}(\\mathbf{r},E)\\,\\phi(\\mathbf{r},E)\\,\\mathrm{d}V\\,\\mathrm{d}E$ denote the volume-integrated reaction rate for some reaction $r$.\n\nExplain the conceptual difference between per-source-particle normalization and per-fission-event normalization in terms of how $\\phi$ is scaled and how $F$ and $P$ relate to $k_{\\text{eff}}$. Then, using first-principles definitions, derive a general expression to convert a reaction rate tally $R_{r}$ reported per source particle into the corresponding per-fission-event normalized reaction rate.\n\nFinally, apply your derivation to the following measured tallies, all reported per source particle in the same $k$-eigenvalue simulation:\n- Effective multiplication factor $k_{\\text{eff}} = 1.0150$,\n- Volume-integrated fission rate $F_{\\text{s}} = 0.4150$,\n- Volume-integrated fission neutron production rate $P_{\\text{s}} = 1.0150$,\n- Volume-integrated reaction rate for reaction $r$ (a specific capture reaction in an absorber material) $R_{r,\\text{s}} = 0.00790$.\n\nCompute the per-fission-event normalized value of $R_{r}$ and express your final result in events per fission event. Round your answer to four significant figures.",
            "solution": "The posed problem is scientifically grounded, self-contained, and well-posed. The provided definitions and equations are standard in the field of nuclear reactor physics and Monte Carlo methods. The numerical values are consistent with the theoretical framework, particularly the identity between the reported $k_{\\text{eff}}$ and the fission neutron production rate per source particle, which is a known consequence of the chosen normalization. The problem is therefore deemed valid and a solution may be constructed.\n\nThe problem asks for three components: a conceptual explanation of two common normalization schemes, a derivation of a conversion formula between them, and the application of this formula to a specific set of tallies.\n\nFirst, we address the conceptual difference between the normalization schemes. The fundamental solution to the steady-state $k$-eigenvalue neutron balance equation,\n$$ \\mathcal{L}\\,\\phi = \\frac{1}{k_{\\text{eff}}}\\,\\mathcal{F}\\,\\phi $$\nis the eigenfunction $\\phi$, which represents the neutron flux distribution. As with any eigenfunction, its absolute magnitude is arbitrary; only its shape is determined by the equation. To obtain quantitative reaction rates, the flux must be normalized. This is achieved by imposing a constraint on some integrated property of the flux.\n\nIn per-source-particle normalization, typically used in Monte Carlo $k$-eigenvalue simulations, the flux magnitude is scaled such that the total source strength for a subsequent generation is unity. In a simulation driven by a fission source, the source of neutrons for generation $n+1$ is the population of neutrons produced by fissions in generation $n$. The operator for this source is $\\frac{1}{k_{\\text{eff}}}\\,\\mathcal{F}$. Let the flux normalized per source particle be denoted $\\phi_{\\text{s}}$. The total source strength is the integral of the source term over all phase space. The normalization condition is thus:\n$$ \\int_{V}\\int_{E} \\frac{1}{k_{\\text{eff}}}\\,\\mathcal{F}\\,\\phi_{\\text{s}}(\\mathbf{r},E) \\,\\mathrm{d}E\\,\\mathrm{d}V = 1 $$\nBy definition, the total fission neutron production rate is $P_{\\text{s}} = \\int_{V}\\int_{E} \\mathcal{F}\\,\\phi_{\\text{s}}(\\mathbf{r},E) \\,\\mathrm{d}E\\,\\mathrm{d}V$. Substituting this into the normalization condition gives:\n$$ \\frac{P_{\\text{s}}}{k_{\\text{eff}}} = 1 \\implies P_{\\text{s}} = k_{\\text{eff}} $$\nThis identity confirms that in a per-source-particle normalized system, the tally for the total fission neutron production rate is numerically equal to the effective multiplication factor, $k_{\\text{eff}}$. The problem statement provides $k_{\\text{eff}} = 1.0150$ and $P_{\\text{s}} = 1.0150$, which is consistent with this principle. Any reaction rate tally $R_{r,\\text{s}}$ is then reported in units of \"events of type $r$ per simulated source particle.\"\n\nIn per-fission-event normalization, the flux magnitude is scaled such that the total number of fission events occurring in the system is unity. Let this flux be denoted $\\phi_{\\text{f}}$. The total fission rate is defined as $F \\equiv \\int_{V}\\int_{E}\\Sigma_{f}(\\mathbf{r},E)\\,\\phi(\\mathbf{r},E)\\,\\mathrm{d}E\\,\\mathrm{d}V$. The normalization condition is therefore:\n$$ F_{\\text{f}} = \\int_{V}\\int_{E}\\Sigma_{f}(\\mathbf{r},E)\\,\\phi_{\\text{f}}(\\mathbf{r},E)\\,\\mathrm{d}E\\,\\mathrm{d}V = 1 $$\nWith this normalization, a reaction rate tally $R_{r,\\text{f}}$ is reported in units of \"events of type $r$ per fission event in the system.\" The total fission neutron production rate $P_{\\text{f}}$ would be the average number of neutrons produced per fission event, commonly denoted $\\bar{\\nu}$.\n\nNext, we derive the conversion formula. Since $\\phi_{\\text{s}}$ and $\\phi_{\\text{f}}$ represent the same fundamental mode (eigenfunction), they must be proportional to each other. We can write:\n$$ \\phi_{\\text{f}} = C \\cdot \\phi_{\\text{s}} $$\nwhere $C$ is a constant conversion factor. To find $C$, we use the definition of the per-fission-event normalization.\n$$ F_{\\text{f}} = 1 = \\int_{V}\\int_{E}\\Sigma_{f}\\,\\phi_{\\text{f}}\\,\\mathrm{d}E\\,\\mathrm{d}V = \\int_{V}\\int_{E}\\Sigma_{f}\\,(C \\cdot \\phi_{\\text{s}})\\,\\mathrm{d}E\\,\\mathrm{d}V $$\nFactoring out the constant $C$:\n$$ 1 = C \\cdot \\int_{V}\\int_{E}\\Sigma_{f}\\,\\phi_{\\text{s}}\\,\\mathrm{d}E\\,\\mathrm{d}V $$\nThe integral on the right is, by definition, the per-source-particle fission rate, $F_{\\text{s}}$.\n$$ 1 = C \\cdot F_{\\text{s}} \\implies C = \\frac{1}{F_{\\text{s}}} $$\nNow we can convert any arbitrary reaction rate, $R_{r}$. The per-fission-event rate is $R_{r,\\text{f}}$ and the per-source-particle rate is $R_{r,\\text{s}}$.\n$$ R_{r,\\text{f}} = \\int_{V}\\int_{E}\\Sigma_{r}\\,\\phi_{\\text{f}}\\,\\mathrm{d}E\\,\\mathrm{d}V = \\int_{V}\\int_{E}\\Sigma_{r}\\,\\left(\\frac{1}{F_{\\text{s}}}\\phi_{\\text{s}}\\right)\\,\\mathrm{d}E\\,\\mathrm{d}V $$\n$$ R_{r,\\text{f}} = \\frac{1}{F_{\\text{s}}} \\int_{V}\\int_{E}\\Sigma_{r}\\,\\phi_{\\text{s}}\\,\\mathrm{d}E\\,\\mathrm{d}V $$\nThe integral is the definition of $R_{r,\\text{s}}$. Therefore, the general expression to convert a reaction rate tally from per-source-particle to per-fission-event is:\n$$ R_{r,\\text{f}} = \\frac{R_{r,\\text{s}}}{F_{\\text{s}}} $$\nThis shows that to convert any tally from a per-source-particle basis to a per-fission-event basis, one must divide the tally value by the total fission rate that was calculated on the per-source-particle basis.\n\nFinally, we apply this derivation to compute the requested value. The problem provides the following tallies, all reported per source particle:\n- Volume-integrated fission rate: $F_{\\text{s}} = 0.4150$\n- Volume-integrated reaction rate for reaction $r$: $R_{r,\\text{s}} = 0.00790$\n\nUsing the derived formula:\n$$ R_{r,\\text{f}} = \\frac{R_{r,\\text{s}}}{F_{\\text{s}}} = \\frac{0.00790}{0.4150} $$\nCalculating the numerical value:\n$$ R_{r,\\text{f}} \\approx 0.019036144... $$\nThe number of significant figures in the input data are three for $R_{r,\\text{s}}$ ($0.00790$) and four for $F_{\\text{s}}$ ($0.4150$). Standard scientific practice for division dictates that the result should be reported to the lesser number of significant figures, which is three. However, the problem provides an explicit instruction to \"round your answer to four significant figures.\" Adhering to this direct mandate, we round the result to four significant figures.\n$$ R_{r,\\text{f}} \\approx 0.01904 $$\nThis value represents the number of events of reaction $r$ per fission event in the reactor.",
            "answer": "$$\\boxed{0.01904}$$"
        },
        {
            "introduction": "A key goal in Monte Carlo simulations is to obtain the most precise estimate possible for a given amount of computational effort. This practice delves into variance reduction, a set of techniques designed to achieve this by strategically altering the sampling process. You will explore how stratifying the particle population—in this case, by collision order—can eliminate certain sources of variance and learn how to optimally combine results from different estimators to construct a single, minimum-variance estimate .",
            "id": "4224231",
            "problem": "Consider a homogeneous, isotropically scattering medium in which a Monte Carlo (MC) particle history produces a per-history score for an absorption reaction rate tally via the collision estimator. Let the per-history tally score be a random variable $X$, and let $K \\in \\{1,2,3\\}$ denote the collision order of the history at which the reaction contribution is scored. The unconditional target is the reaction rate per source history $R = \\mathbb{E}[X]$. Suppose that under the natural, unstratified sampling of histories: $\\mathbb{P}(K = 1) = p_{1} = \\frac{1}{2}$, $\\mathbb{P}(K = 2) = p_{2} = \\frac{3}{10}$, $\\mathbb{P}(K = 3) = p_{3} = \\frac{1}{5}$; and the conditional moments of $X$ given $K = k$ are $\\mathbb{E}[X \\mid K = 1] = \\mu_{1} = \\frac{4}{5}$, $\\mathbb{E}[X \\mid K = 2] = \\mu_{2} = \\frac{1}{2}$, $\\mathbb{E}[X \\mid K = 3] = \\mu_{3} = \\frac{1}{5}$, and $\\operatorname{Var}(X \\mid K = 1) = \\sigma_{1}^{2} = 2$, $\\operatorname{Var}(X \\mid K = 2) = \\sigma_{2}^{2} = 1$, $\\operatorname{Var}(X \\mid K = 3) = \\sigma_{3}^{2} = \\frac{1}{2}$. You may assume that histories are independent.\n\n1. Using only the law of total expectation and the law of total variance as the foundational base, deduce the variance of the simple random sampling estimator $\\bar{X}_{N}$ of $R$, formed from $N$ independent histories without stratification. Then, derive the variance of the stratified estimator $\\hat{R}_{\\text{strat}} = \\sum_{k=1}^{3} p_{k} \\bar{X}_{k}$, where $\\bar{X}_{k}$ is the sample mean of the scores from stratum $K = k$, under a fixed allocation $n_{k}$ with $\\sum_{k=1}^{3} n_{k} = N$. Specialize this to proportional allocation $n_{k} = N p_{k}$ and show explicitly, for $N = 900$, how stratification over collision order reduces variance relative to simple random sampling, quantifying the reduction.\n\n2. Derive from first principles the optimal allocation $n_{k}$ (as a closed-form expression in $N$, $p_{k}$, and $\\sigma_{k}$) that minimizes the variance of $\\hat{R}_{\\text{strat}}$ over all allocations with $\\sum_{k=1}^{3} n_{k} = N$, assuming equal computational cost per history in each stratum.\n\n3. Now consider three independent, unbiased estimators $\\hat{R}_{1}$, $\\hat{R}_{2}$, and $\\hat{R}_{3}$ of the same reaction rate $R$, each constructed by conditioning histories to collide exactly at order $K = 1$, $K = 2$, and $K = 3$, respectively (for example, via Russian roulette and splitting or path conditioning) so that each $\\hat{R}_{k}$ is unbiased for $R$ but with different variances $v_{1} = 2$, $v_{2} = 1$, and $v_{3} = \\frac{1}{2}$. Derive the optimal variance-minimizing weights $w_{1}$, $w_{2}$, and $w_{3}$ for the linear unbiased combination $\\hat{R}_{\\text{comb}} = w_{1} \\hat{R}_{1} + w_{2} \\hat{R}_{2} + w_{3} \\hat{R}_{3}$ subject to $w_{1} + w_{2} + w_{3} = 1$, and compute their numerical values. Express the final weights as a three-entry row vector with exact fractions, and do not include units.\n\nRound any numerical values you are asked to compute to exact fractions wherever possible; no rounding by significant figures is required in this problem. The final reported answer must be the requested row vector.",
            "solution": "The problem statement has been rigorously validated and is found to be scientifically sound, well-posed, and contains sufficient information for a unique solution. The problem is a standard application of statistical principles to Monte Carlo estimators in particle transport, and all provided data are internally consistent. We shall proceed with the solution.\n\nThe problem is divided into three parts. We will address each in sequence.\n\n**Part 1: Variance of Simple Random Sampling (SRS) vs. Stratified Sampling**\n\nFirst, we calculate the unconditional mean $R = \\mathbb{E}[X]$ and variance $\\operatorname{Var}(X)$ of a per-history score $X$. The givens are the stratum probabilities $p_k = \\mathbb{P}(K=k)$ and the conditional moments $\\mu_k = \\mathbb{E}[X \\mid K=k]$ and $\\sigma_k^2 = \\operatorname{Var}(X \\mid K=k)$ for strata $k \\in \\{1, 2, 3\\}$.\n\nAccording to the law of total expectation, the unconditional mean is:\n$$\nR = \\mathbb{E}[X] = \\sum_{k=1}^{3} \\mathbb{E}[X \\mid K=k] \\mathbb{P}(K=k) = \\sum_{k=1}^{3} \\mu_k p_k\n$$\nSubstituting the given values:\n$$\nR = \\left(\\frac{4}{5}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{3}{10}\\right) + \\left(\\frac{1}{5}\\right)\\left(\\frac{1}{5}\\right) = \\frac{4}{10} + \\frac{3}{20} + \\frac{1}{25} = \\frac{40+15+4}{100} = \\frac{59}{100}\n$$\n\nNext, we use the law of total variance to find the unconditional variance $\\operatorname{Var}(X)$:\n$$\n\\operatorname{Var}(X) = \\mathbb{E}[\\operatorname{Var}(X \\mid K)] + \\operatorname{Var}(\\mathbb{E}[X \\mid K])\n$$\nThe first term is the expectation of the conditional variance:\n$$\n\\mathbb{E}[\\operatorname{Var}(X \\mid K)] = \\sum_{k=1}^{3} \\operatorname{Var}(X \\mid K=k) \\mathbb{P}(K=k) = \\sum_{k=1}^{3} \\sigma_k^2 p_k\n$$\n$$\n\\mathbb{E}[\\operatorname{Var}(X \\mid K)] = (2)\\left(\\frac{1}{2}\\right) + (1)\\left(\\frac{3}{10}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{5}\\right) = 1 + \\frac{3}{10} + \\frac{1}{10} = 1 + \\frac{4}{10} = \\frac{14}{10} = \\frac{7}{5}\n$$\nThe second term is the variance of the conditional expectation:\n$$\n\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = \\mathbb{E}[(\\mathbb{E}[X \\mid K])^2] - (\\mathbb{E}[\\mathbb{E}[X \\mid K]])^2 = \\left(\\sum_{k=1}^{3} \\mu_k^2 p_k\\right) - R^2\n$$\nWe calculate the sum of squares:\n$$\n\\sum_{k=1}^{3} \\mu_k^2 p_k = \\left(\\frac{4}{5}\\right)^2\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{2}\\right)^2\\left(\\frac{3}{10}\\right) + \\left(\\frac{1}{5}\\right)^2\\left(\\frac{1}{5}\\right) = \\left(\\frac{16}{25}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{4}\\right)\\left(\\frac{3}{10}\\right) + \\left(\\frac{1}{25}\\right)\\left(\\frac{1}{5}\\right)\n$$\n$$\n\\sum_{k=1}^{3} \\mu_k^2 p_k = \\frac{16}{50} + \\frac{3}{40} + \\frac{1}{125} = \\frac{320+75+8}{1000} = \\frac{403}{1000}\n$$\nSo, the variance of the conditional expectation is:\n$$\n\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = \\frac{403}{1000} - \\left(\\frac{59}{100}\\right)^2 = \\frac{4030}{10000} - \\frac{3481}{10000} = \\frac{549}{10000}\n$$\nThe total variance is therefore:\n$$\n\\operatorname{Var}(X) = \\frac{7}{5} + \\frac{549}{10000} = \\frac{14000}{10000} + \\frac{549}{10000} = \\frac{14549}{10000}\n$$\nFor the simple random sampling estimator $\\bar{X}_{N} = \\frac{1}{N}\\sum_{i=1}^{N} X_i$, comprised of $N$ independent histories, the variance is:\n$$\n\\operatorname{Var}(\\bar{X}_{N}) = \\frac{\\operatorname{Var}(X)}{N} = \\frac{1}{N}\\left(\\frac{14549}{10000}\\right)\n$$\nNow, consider the stratified estimator $\\hat{R}_{\\text{strat}} = \\sum_{k=1}^{3} p_{k} \\bar{X}_{k}$, where $\\bar{X}_{k}$ is the sample mean of $n_k$ scores from stratum $k$. The samples from different strata are independent, so the variance is:\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{strat}}) = \\operatorname{Var}\\left(\\sum_{k=1}^{3} p_{k} \\bar{X}_{k}\\right) = \\sum_{k=1}^{3} p_{k}^2 \\operatorname{Var}(\\bar{X}_{k})\n$$\nThe variance of the sample mean in stratum $k$ is $\\operatorname{Var}(\\bar{X}_{k}) = \\frac{\\operatorname{Var}(X \\mid K=k)}{n_k} = \\frac{\\sigma_k^2}{n_k}$. Thus, the variance of the stratified estimator for a fixed allocation $\\{n_k\\}$ is:\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{strat}}) = \\sum_{k=1}^{3} \\frac{p_{k}^2 \\sigma_k^2}{n_k}\n$$\nFor proportional allocation, we set $n_k = N p_k$. Substituting this into the variance expression:\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{strat, prop}}) = \\sum_{k=1}^{3} \\frac{p_{k}^2 \\sigma_k^2}{N p_k} = \\frac{1}{N} \\sum_{k=1}^{3} p_k \\sigma_k^2\n$$\nThis is precisely the within-strata variance component, scaled by $1/N$:\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{strat, prop}}) = \\frac{1}{N} \\mathbb{E}[\\operatorname{Var}(X \\mid K)] = \\frac{1}{N}\\left(\\frac{7}{5}\\right)\n$$\nTo quantify the variance reduction for $N=900$, we compare the two variances:\n$$\n\\operatorname{Var}(\\bar{X}_{900}) = \\frac{1}{900}\\left(\\frac{14549}{10000}\\right) = \\frac{14549}{9000000}\n$$\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{strat, prop}}) = \\frac{1}{900}\\left(\\frac{7}{5}\\right) = \\frac{1}{900}\\left(\\frac{14000}{10000}\\right) = \\frac{14000}{9000000}\n$$\nThe absolute reduction in variance is:\n$$\n\\operatorname{Var}(\\bar{X}_{900}) - \\operatorname{Var}(\\hat{R}_{\\text{strat, prop}}) = \\frac{14549 - 14000}{9000000} = \\frac{549}{9000000}\n$$\nThis reduction is precisely the between-strata variance component $\\frac{\\operatorname{Var}(\\mathbb{E}[X \\mid K])}{N}$, which stratification with proportional allocation eliminates.\n\n**Part 2: Optimal Allocation for Stratified Sampling**\n\nWe seek to minimize the variance of the stratified estimator, $V(n_1, n_2, n_3) = \\sum_{k=1}^{3} \\frac{p_{k}^2 \\sigma_k^2}{n_k}$, subject to the constraint that the total number of samples is fixed: $g(n_1, n_2, n_3) = \\sum_{k=1}^{3} n_k - N = 0$. We employ the method of Lagrange multipliers. The Lagrangian is:\n$$\nL(n_1, n_2, n_3, \\lambda) = \\sum_{k=1}^{3} \\frac{p_k^2 \\sigma_k^2}{n_k} + \\lambda\\left(\\sum_{k=1}^{3} n_k - N\\right)\n$$\nTo find the minimum, we set the partial derivatives with respect to each $n_k$ to zero:\n$$\n\\frac{\\partial L}{\\partial n_k} = -\\frac{p_k^2 \\sigma_k^2}{n_k^2} + \\lambda = 0 \\quad \\implies \\quad n_k^2 = \\frac{p_k^2 \\sigma_k^2}{\\lambda}\n$$\nTaking the positive square root, as sample sizes must be positive, we get $n_k = \\frac{p_k \\sigma_k}{\\sqrt{\\lambda}}$.\nWe substitute this into the constraint equation to solve for $\\sqrt{\\lambda}$:\n$$\n\\sum_{k=1}^{3} n_k = \\sum_{k=1}^{3} \\frac{p_k \\sigma_k}{\\sqrt{\\lambda}} = \\frac{1}{\\sqrt{\\lambda}} \\sum_{j=1}^{3} p_j \\sigma_j = N\n$$\nThis yields $\\frac{1}{\\sqrt{\\lambda}} = \\frac{N}{\\sum_{j=1}^{3} p_j \\sigma_j}$.\nSubstituting this back into the expression for $n_k$, we obtain the optimal allocation, known as Neyman allocation:\n$$\nn_k = N \\frac{p_k \\sigma_k}{\\sum_{j=1}^{3} p_j \\sigma_j}\n$$\nThis expression gives the optimal number of samples $n_k$ for each stratum $k$ as a function of the total number of samples $N$, the stratum probability $p_k$, and the stratum standard deviation $\\sigma_k$.\n\n**Part 3: Optimal Combination of Independent Estimators**\n\nWe are given three independent, unbiased estimators $\\hat{R}_1, \\hat{R}_2, \\hat{R}_3$ for the same quantity $R$, with variances $v_1, v_2, v_3$. We form a linear combination $\\hat{R}_{\\text{comb}} = \\sum_{k=1}^{3} w_k \\hat{R}_k$.\nThe estimator must be unbiased, which means $\\mathbb{E}[\\hat{R}_{\\text{comb}}] = R$.\n$$\n\\mathbb{E}\\left[\\sum_{k=1}^{3} w_k \\hat{R}_k\\right] = \\sum_{k=1}^{3} w_k \\mathbb{E}[\\hat{R}_k] = \\sum_{k=1}^{3} w_k R = R \\sum_{k=1}^{3} w_k\n$$\nFor this to equal $R$, we must have the constraint $\\sum_{k=1}^{3} w_k = 1$.\nThe variance of the combined estimator, due to the independence of the $\\hat{R}_k$, is:\n$$\n\\operatorname{Var}(\\hat{R}_{\\text{comb}}) = \\operatorname{Var}\\left(\\sum_{k=1}^{3} w_k \\hat{R}_k\\right) = \\sum_{k=1}^{3} w_k^2 \\operatorname{Var}(\\hat{R}_k) = \\sum_{k=1}^{3} w_k^2 v_k\n$$\nOur objective is to minimize this variance subject to the unbiasedness constraint. We again use the method of Lagrange multipliers. The Lagrangian is:\n$$\nL(w_1, w_2, w_3, \\lambda) = \\sum_{k=1}^{3} w_k^2 v_k - \\lambda\\left(\\sum_{k=1}^{3} w_k - 1\\right)\n$$\nSetting the partial derivatives with respect to each $w_k$ to zero:\n$$\n\\frac{\\partial L}{\\partial w_k} = 2 w_k v_k - \\lambda = 0 \\quad \\implies \\quad w_k = \\frac{\\lambda}{2 v_k}\n$$\nThis shows that the optimal weights are inversely proportional to the variances of the individual estimators.\nWe substitute this result into the constraint equation to find $\\lambda$:\n$$\n\\sum_{k=1}^{3} w_k = \\sum_{k=1}^{3} \\frac{\\lambda}{2 v_k} = \\frac{\\lambda}{2} \\sum_{j=1}^{3} \\frac{1}{v_j} = 1\n$$\nThis gives $\\frac{\\lambda}{2} = \\left(\\sum_{j=1}^{3} \\frac{1}{v_j}\\right)^{-1}$.\nSubstituting this back into the expression for $w_k$, we find the optimal weights:\n$$\nw_k = \\frac{1/v_k}{\\sum_{j=1}^{3} (1/v_j)}\n$$\nNow we compute the numerical values using the given variances: $v_1=2$, $v_2=1$, and $v_3=1/2$.\nThe inverse variances are:\n$1/v_1 = 1/2$\n$1/v_2 = 1/1 = 1$\n$1/v_3 = 1/(1/2) = 2$\nThe sum of the inverse variances is:\n$$\n\\sum_{j=1}^{3} \\frac{1}{v_j} = \\frac{1}{2} + 1 + 2 = \\frac{1+2+4}{2} = \\frac{7}{2}\n$$\nThe optimal weights are therefore:\n$$\nw_1 = \\frac{1/2}{7/2} = \\frac{1}{7}\n$$\n$$\nw_2 = \\frac{1}{7/2} = \\frac{2}{7}\n$$\n$$\nw_3 = \\frac{2}{7/2} = \\frac{4}{7}\n$$\nThe final weights are $(w_1, w_2, w_3) = (1/7, 2/7, 4/7)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{7}  \\frac{2}{7}  \\frac{4}{7} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The ultimate measure of a Monte Carlo method's efficiency is its Figure of Merit (FOM), which balances the statistical quality of an estimate against the computational time required to achieve it. This hands-on problem guides you through building a model to analyze the FOM for a mesh tally in a complex, heterogeneous environment. By exploring how mesh coarsening affects both tally variance and particle tracking time, you will develop the critical skill of optimizing simulation parameters for maximum efficiency .",
            "id": "4224244",
            "problem": "A simulation team is building a high-fidelity neutron transport Monte Carlo (MC) model of a heterogeneous reactor core to predict spatially resolved flux using a track-length estimator on a Cartesian mesh tally. They want to understand how geometry tracking cost contributes to the Figure of Merit (FOM) and how coarsening the mesh tally affects efficiency in a core with strong material heterogeneity. The team adopts the following scientifically plausible assumptions for modeling and derivation:\n\n- The per-history tally score for a given mesh bin is an unbiased estimator of the quantity of interest with per-history random variable $X$ having finite mean $E[X]$ and variance $\\mathrm{Var}(X)$, and histories are independent.\n- The FOM is defined conventionally as $1/(R^{2} T)$, where $R$ is the relative error of the tally and $T$ is the total runtime to achieve that error target, with $T = N t_{h}$ for $N$ independent histories and per-history wall-clock time $t_{h}$.\n- The per-history time decomposes additively into $t_{h} = t_{\\mathrm{coll}} + t_{\\mathrm{geom}} + t_{\\mathrm{tally}}$, where $t_{\\mathrm{coll}}$ accounts for collision physics sampling, $t_{\\mathrm{geom}}$ accounts for geometry tracking (surface intersection checks and boundary crossings in the physical core geometry), and $t_{\\mathrm{tally}}$ accounts for mesh tally bookkeeping (segment-to-cell mapping and accumulation).\n- Geometry tracking time is proportional to the expected number of core-geometry surface interactions along a history. For histories with mean track length $L$ and core-geometry interface density $\\Lambda_{\\mathrm{geo}}$ (expected surface intersections per unit track length), $t_{\\mathrm{geom}}$ is modeled as $t_{\\mathrm{geom}} = c_{g} L \\Lambda_{\\mathrm{geo}}$, where $c_{g}  0$ is the mean cost per intersection check/crossing.\n- Mesh tally time is proportional to the expected number of mesh-face crossings along a history. For a Cartesian mesh with fine-cell edge length $a_{\\mathrm{fine}}$, the line-face crossing intensity is $\\Lambda_{\\mathrm{mesh}} = k_{m}/a_{\\mathrm{fine}}$ with geometry-independent constant $k_{m}  0$, and $t_{\\mathrm{tally}} = c_{t} L \\Lambda_{\\mathrm{mesh}}$ with $c_{t}  0$ the mean cost per mesh crossing tally operation.\n- The reactor core is three-dimensional and the team considers coarsening the mesh by a factor $r  1$ in each Cartesian direction, so the coarse-cell edge length is $a_{\\mathrm{coarse}} = r\\, a_{\\mathrm{fine}}$, which aggregates $K = r^{3}$ fine cells per coarse cell. Under coarsening, $\\Lambda_{\\mathrm{mesh}}$ scales inversely with edge length: $\\Lambda_{\\mathrm{mesh,coarse}} = \\Lambda_{\\mathrm{mesh}}/r$.\n- The coarse-bin tally score is the sum of the $K$ fine-bin scores. To capture heterogeneity-driven spatial correlation, the team models the $K$ fine-bin per-history scores aggregated into one coarse bin as having common per-bin variance $\\sigma^{2}$ and equal pairwise correlation coefficient $\\rho \\in [0,1]$ among distinct fine bins within a coarse bin for a given history. This yields a variance of the coarse-bin sum that accounts for covariance.\n\nBased on these assumptions:\n\n- Derive, from first principles, an expression for the per-bin FOM that explicitly exposes the contribution of geometry tracking cost as an additive term in $t_{h}$.\n- Then derive a closed-form expression for the efficiency gain $G$ defined as the ratio of the coarse-bin FOM to the fine-bin FOM, $G = \\mathrm{FOM}_{\\mathrm{coarse}} / \\mathrm{FOM}_{\\mathrm{fine}}$, in terms of $K$, $\\rho$, $L$, $t_{\\mathrm{coll}}$, $c_{g}$, $\\Lambda_{\\mathrm{geo}}$, $c_{t}$, and $\\Lambda_{\\mathrm{mesh}}$, under the stated scaling of $\\Lambda_{\\mathrm{mesh}}$ with $r$.\n\nSelect the option that provides the correct pair of expressions for the per-bin FOM and the efficiency gain $G$.\n\nA. $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}, \\quad G = \\frac{r^{3}}{1 + \\rho \\left(r^{3} - 1\\right)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\dfrac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}.$\n\nB. $\\displaystyle \\mathrm{FOM} = \\left(\\frac{E[X]^{2}}{\\mathrm{Var}(X)}\\right)\\left(c_{g} L \\Lambda_{\\mathrm{geo}}\\right), \\quad G = r^{3} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\dfrac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}.$\n\nC. $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}, \\quad G = \\frac{r}{1 + \\rho \\left(r - 1\\right)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\dfrac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}.$\n\nD. $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{\\left(t_{\\mathrm{coll}} + c_{t} L \\Lambda_{\\mathrm{mesh}}\\right)\\left(1 + c_{g} L \\Lambda_{\\mathrm{geo}}\\right)}, \\quad G = \\frac{r^{3}}{1 - \\rho \\left(r^{3} - 1\\right)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\dfrac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}.$",
            "solution": "The problem statement is evaluated to be valid as it is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. The models presented for calculation time and variance are standard and plausible within the context of Monte Carlo nuclear reactor simulation.\n\nThe solution is derived in two parts, consistent with the problem's request: first, the derivation of the Figure of Merit (FOM), and second, the derivation of the efficiency gain $G$.\n\n### Part 1: Derivation of the per-bin Figure of Merit (FOM)\n\n1.  **Definition of FOM**: The Figure of Merit is defined as $\\mathrm{FOM} = 1/(R^2 T)$, where $R$ is the relative error of the tally and $T$ is the total runtime.\n\n2.  **Relative Error ($R$)**: The tally score for a single history is a random variable $X$ with mean $E[X]$ and variance $\\mathrm{Var}(X)$. The simulation runs $N$ independent histories. The sample mean is $\\bar{X}_N = \\frac{1}{N} \\sum_{i=1}^{N} X_i$.\n    The expected value of the sample mean is $E[\\bar{X}_N] = E[X]$.\n    The variance of the sample mean for independent histories is $\\mathrm{Var}(\\bar{X}_N) = \\mathrm{Var}(X)/N$.\n    The relative error $R$ is the standard error of the mean divided by the mean:\n    $$R = \\frac{\\sqrt{\\mathrm{Var}(\\bar{X}_N)}}{E[\\bar{X}_N]} = \\frac{\\sqrt{\\mathrm{Var}(X)/N}}{E[X]} = \\frac{1}{\\sqrt{N}} \\frac{\\sqrt{\\mathrm{Var}(X)}}{E[X]}$$\n    Squaring the relative error gives:\n    $$R^2 = \\frac{1}{N} \\frac{\\mathrm{Var}(X)}{(E[X])^2}$$\n\n3.  **Total Runtime ($T$)**: The total runtime is given as $T = N t_h$, where $t_h$ is the average wall-clock time per history.\n\n4.  **Substituting into FOM**: We substitute the expressions for $R^2$ and $T$ into the definition of FOM:\n    $$\\mathrm{FOM} = \\frac{1}{R^2 T} = \\frac{1}{\\left(\\frac{1}{N} \\frac{\\mathrm{Var}(X)}{(E[X])^2}\\right) (N t_h)} = \\frac{(E[X])^2 N}{\\mathrm{Var(X)} N t_h} = \\frac{(E[X])^2}{\\mathrm{Var}(X) t_h}$$\n    This is a standard result, showing that FOM is independent of the number of histories $N$. The term $(E[X])^2/\\mathrm{Var}(X)$ can be related to the coefficient of variation of the per-history score.\n\n5.  **Per-History Time ($t_h$)**: The problem provides an additive decomposition of the per-history time:\n    $$t_h = t_{\\mathrm{coll}} + t_{\\mathrm{geom}} + t_{\\mathrm{tally}}$$\n    The problem also models the geometry and tally tracking times as:\n    $$t_{\\mathrm{geom}} = c_{g} L \\Lambda_{\\mathrm{geo}}$$\n    $$t_{\\mathrm{tally}} = c_{t} L \\Lambda_{\\mathrm{mesh}}$$\n    Substituting these into the expression for $t_h$ gives:\n    $$t_h = t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}$$\n\n6.  **Final FOM Expression**: Substituting the full expression for $t_h$ into the FOM equation yields the final expression for the per-bin FOM, with the geometry tracking cost explicitly shown:\n    $$\\mathrm{FOM} = \\frac{(E[X])^2}{\\mathrm{Var}(X) t_h} = \\frac{(E[X])^2}{\\mathrm{Var}(X)} \\cdot \\frac{1}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}$$\n\n### Part 2: Derivation of the Efficiency Gain ($G$)\n\n1.  **Definition of G**: The efficiency gain $G$ is the ratio of the coarse-bin FOM to the fine-bin FOM:\n    $$G = \\frac{\\mathrm{FOM}_{\\mathrm{coarse}}}{\\mathrm{FOM}_{\\mathrm{fine}}}$$\n\n2.  **Ratio of FOMs**: Using the general expression for FOM derived above, we can write the ratio as:\n    $$G = \\frac{(E[X_{\\mathrm{coarse}}])^2 / (\\mathrm{Var}(X_{\\mathrm{coarse}}) t_{h, \\mathrm{coarse}})}{(E[X_{\\mathrm{fine}}])^2 / (\\mathrm{Var}(X_{\\mathrm{fine}}) t_{h, \\mathrm{fine}})} = \\left(\\frac{E[X_{\\mathrm{coarse}}]}{E[X_{\\mathrm{fine}}]}\\right)^2 \\cdot \\frac{\\mathrm{Var}(X_{\\mathrm{fine}})}{\\mathrm{Var}(X_{\\mathrm{coarse}})} \\cdot \\frac{t_{h, \\mathrm{fine}}}{t_{h, \\mathrm{coarse}}}$$\n\n3.  **Analysis of Ratio Components**: We evaluate each of the three ratios.\n    *   **Expectation Ratio**: A coarse bin is an aggregation of $K = r^3$ fine bins. The score in the coarse bin, $X_{\\mathrm{coarse}}$, is the sum of the scores of the constituent fine bins, $X_{\\mathrm{fine}, i}$: $X_{\\mathrm{coarse}} = \\sum_{i=1}^{K} X_{\\mathrm{fine}, i}$. By linearity of expectation, $E[X_{\\mathrm{coarse}}] = \\sum_{i=1}^{K} E[X_{\\mathrm{fine}, i}]$. Assuming the quantity of interest is approximately uniform across the fine bins within a coarse bin, we can posit $E[X_{\\mathrm{fine}, i}] \\approx E[X_{\\mathrm{fine}}]$ for a representative fine bin. Thus, $E[X_{\\mathrm{coarse}}] \\approx K \\cdot E[X_{\\mathrm{fine}}]$. The ratio of squared expectations is:\n        $$\\left(\\frac{E[X_{\\mathrm{coarse}}]}{E[X_{\\mathrm{fine}}]}\\right)^2 \\approx \\left(\\frac{K \\cdot E[X_{\\mathrm{fine}}]}{E[X_{\\mathrm{fine}}]}\\right)^2 = K^2$$\n    *   **Variance Ratio**: The problem states that the fine-bin scores have a common variance, $\\mathrm{Var}(X_{\\mathrm{fine}, i}) = \\sigma^2 = \\mathrm{Var}(X_{\\mathrm{fine}})$, and a common pairwise correlation, $\\mathrm{Corr}(X_{\\mathrm{fine}, i}, X_{\\mathrm{fine}, j}) = \\rho$, for $i \\neq j$. This implies $\\mathrm{Cov}(X_{\\mathrm{fine}, i}, X_{\\mathrm{fine}, j}) = \\rho \\sigma^2$. The variance of the sum is:\n        $$\\mathrm{Var}(X_{\\mathrm{coarse}}) = \\mathrm{Var}\\left(\\sum_{i=1}^{K} X_{\\mathrm{fine}, i}\\right) = \\sum_{i=1}^{K} \\mathrm{Var}(X_{\\mathrm{fine}, i}) + \\sum_{i \\neq j} \\mathrm{Cov}(X_{\\mathrm{fine}, i}, X_{\\mathrm{fine}, j})$$\n        There are $K$ variance terms and $K(K-1)$ covariance terms.\n        $$\\mathrm{Var}(X_{\\mathrm{coarse}}) = K \\sigma^2 + K(K-1) \\rho \\sigma^2 = K \\sigma^2 [1 + (K-1)\\rho]$$\n        The inverse ratio of variances is:\n        $$\\frac{\\mathrm{Var}(X_{\\mathrm{fine}})}{\\mathrm{Var}(X_{\\mathrm{coarse}})} = \\frac{\\sigma^2}{K \\sigma^2 [1 + (K-1)\\rho]} = \\frac{1}{K[1 + (K-1)\\rho]}$$\n    *   **Time Ratio**: The per-history time depends on the tally mesh.\n        For the fine mesh: $t_{h, \\mathrm{fine}} = t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}$.\n        For the coarse mesh, the cell edge length is $r$ times larger, so the mesh crossing intensity scales as $\\Lambda_{\\mathrm{mesh,coarse}} = \\Lambda_{\\mathrm{mesh}}/r$.\n        The time for the coarse mesh is: $t_{h, \\mathrm{coarse}} = t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh,coarse}} = t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\frac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}$.\n        The ratio of times is:\n        $$\\frac{t_{h, \\mathrm{fine}}}{t_{h, \\mathrm{coarse}}} = \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\frac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}$$\n\n4.  **Assembling the Gain ($G$)**: We multiply the three component ratios:\n    $$G = (K^2) \\cdot \\left(\\frac{1}{K[1 + (K-1)\\rho]}\\right) \\cdot \\left(\\frac{t_{h, \\mathrm{fine}}}{t_{h, \\mathrm{coarse}}}\\right)$$\n    $$G = \\frac{K}{1 + (K-1)\\rho} \\cdot \\frac{t_{h, \\mathrm{fine}}}{t_{h, \\mathrm{coarse}}}$$\n    Substituting $K=r^3$ and the full expressions for time:\n    $$G = \\frac{r^3}{1 + \\rho(r^3 - 1)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\frac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}$$\n\n### Evaluation of Options\n\nThe derived expressions are:\n-   $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}$\n-   $\\displaystyle G = \\frac{r^{3}}{1 + \\rho \\left(r^{3} - 1\\right)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\frac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}$\n\nNow we assess each option against these results.\n\n**A.** The expression for FOM is $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}$. This is identical to our derived FOM.\nThe expression for $G$ is $\\displaystyle G = \\frac{r^{3}}{1 + \\rho \\left(r^{3} - 1\\right)} \\cdot \\frac{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + c_{t} L \\Lambda_{\\mathrm{mesh}}}{t_{\\mathrm{coll}} + c_{g} L \\Lambda_{\\mathrm{geo}} + \\dfrac{c_{t} L \\Lambda_{\\mathrm{mesh}}}{r}}$. This is identical to our derived gain $G$.\n**Verdict**: Correct.\n\n**B.** The expression for FOM is $\\displaystyle \\mathrm{FOM} = \\left(\\frac{E[X]^{2}}{\\mathrm{Var}(X)}\\right)\\left(c_{g} L \\Lambda_{\\mathrm{geo}}\\right)$. This is dimensionally and structurally incorrect, as it is proportional to a component of time, not inversely proportional to total time. The expression for $G$ is also incorrect, as it omits the variance reduction factor $[1 + \\rho(r^3 - 1)]^{-1}$.\n**Verdict**: Incorrect.\n\n**C.** The expression for FOM is correct. However, the expression for $G$, $\\displaystyle G = \\frac{r}{1 + \\rho \\left(r - 1\\right)} \\cdot \\ldots$, incorrectly uses $r$ in place of $K=r^3$ in the variance ratio term. This would only be valid for a one-dimensional problem, which contradicts the stated problem setup ($3$D core, $K=r^3$).\n**Verdict**: Incorrect.\n\n**D.** The expression for FOM, $\\displaystyle \\mathrm{FOM} = \\frac{E[X]^{2}}{\\mathrm{Var}(X)} \\cdot \\frac{1}{\\left(t_{\\mathrm{coll}} + c_{t} L \\Lambda_{\\mathrm{mesh}}\\right)\\left(1 + c_{g} L \\Lambda_{\\mathrm{geo}}\\right)}$, incorrectly models the time contributions as a multiplicative structure rather than an additive one. The expression for $G$ has a sign error in the denominator of the variance factor ($1 - \\rho(r^3-1)$ instead of $1 + \\rho(r^3-1)$). This is a critical mathematical error.\n**Verdict**: Incorrect.\n\nBased on the derivations from first principles, only option A provides the correct pair of expressions.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}