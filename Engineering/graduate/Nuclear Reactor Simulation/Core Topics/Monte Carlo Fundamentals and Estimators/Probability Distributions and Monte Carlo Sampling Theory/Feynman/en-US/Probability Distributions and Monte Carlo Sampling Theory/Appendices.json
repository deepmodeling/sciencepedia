{
    "hands_on_practices": [
        {
            "introduction": "Before we can sample from a probability distribution in a Monte Carlo simulation, we must ensure it is mathematically valid. This practice focuses on the foundational axioms that any probability density function (PDF) must satisfy: non-negativity and normalization to unity. Using a common first-order model for anisotropic neutron scattering, you will derive the constraints on the model's anisotropy parameter, $\\alpha$, that are imposed by these fundamental principles . This exercise reinforces the crucial link between a physical model and its underlying mathematical integrity.",
            "id": "4242635",
            "problem": "In neutron transport Monte Carlo for an infinite, homogeneous, one-speed medium with elastic scattering, a commonly used first-order anisotropy model for the cosine of the scattering angle, denoted by $\\mu \\in [-1,1]$, is specified by a probability density of the form $p(\\mu) = \\frac{1}{2}\\big(1 + \\alpha \\mu\\big)$. This model represents the leading-order truncation of a Legendre expansion of the differential scattering kernel and is employed to bias sampling toward forward ($\\mu \\approx 1$) or backward ($\\mu \\approx -1$) directions depending on the sign of $\\alpha$. Starting only from the foundational facts that a probability density must be nonnegative and integrate to unity over its support, and that the expected value is defined by $E[\\mu] = \\int_{-1}^{1} \\mu\\, p(\\mu)\\, d\\mu$, do the following:\n\n1. Derive the constraint on the parameter $\\alpha$ so that $p(\\mu)$ is a valid probability density on the interval $[-1,1]$, based solely on nonnegativity and normalization requirements.\n2. Compute the first moment $E[\\mu]$ in closed form as a function of $\\alpha$.\n\nProvide your final answer as a row matrix containing, in order, the analytical expression for $E[\\mu]$ as a function of $\\alpha$, followed by the lower and upper endpoint values of $\\alpha$ that preserve nonnegativity. No rounding is required. Do not include units. Your final answer must consist only of these three entries in the specified order, with all mathematical entities in LaTeX.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n-   **System:** Infinite, homogeneous, one-speed medium with elastic scattering in neutron transport Monte Carlo.\n-   **Variable:** $\\mu$, the cosine of the scattering angle.\n-   **Support of the variable:** $\\mu \\in [-1,1]$.\n-   **Probability Density Function (PDF):** $p(\\mu) = \\frac{1}{2}\\big(1 + \\alpha \\mu\\big)$.\n-   **Parameter:** $\\alpha$.\n-   **Fundamental Axioms of a PDF:**\n    1.  Non-negativity: $p(\\mu) \\ge 0$ for all $\\mu$ in its support.\n    2.  Normalization: $\\int_{-1}^{1} p(\\mu)\\, d\\mu = 1$.\n-   **Definition of First Moment (Expected Value):** $E[\\mu] = \\int_{-1}^{1} \\mu\\, p(\\mu)\\, d\\mu$.\n-   **Tasks:**\n    1.  Derive the constraint on $\\alpha$ for $p(\\mu)$ to be a valid PDF.\n    2.  Compute $E[\\mu]$ as a function of $\\alpha$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientific Groundedness:** The problem is scientifically sound. The function $p(\\mu) = \\frac{1}{2}\\big(1 + \\alpha \\mu\\big)$ is the standard, first-order Legendre polynomial ($P_1$) approximation for an anisotropic scattering kernel in transport theory. The parameter $\\alpha$ corresponds to $3$ times the average cosine of the scattering angle, a fundamental quantity. The axioms of probability theory are correctly stated and form the basis of the required derivation.\n-   **Well-Posedness:** The problem is well-posed. It provides all necessary information and definitions to derive a unique and meaningful solution for the constraints on $\\alpha$ and the value of $E[\\mu]$.\n-   **Objectivity:** The problem is stated in objective, formal language, free of ambiguity or subjectivity.\n-   **Completeness and Consistency:** The problem is self-contained. The provided PDF and definitions are sufficient. The two axioms (non-negativity and normalization) are consistent and form the complete basis for validating a PDF.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard, fundamental derivation in the field of transport theory and applied probability. The solution process will now be executed.\n\nThe derivation proceeds in two parts, as requested by the problem statement.\n\n### Part 1: Constraint on the parameter $\\alpha$\n\nFor $p(\\mu)$ to be a valid probability density function on the interval $[-1, 1]$, it must satisfy two conditions: normalization and non-negativity.\n\nFirst, we check the normalization condition: the integral of the PDF over its entire domain must be equal to $1$.\n$$ \\int_{-1}^{1} p(\\mu)\\, d\\mu = \\int_{-1}^{1} \\frac{1}{2}(1 + \\alpha \\mu)\\, d\\mu $$\nWe compute the integral:\n$$ \\frac{1}{2} \\int_{-1}^{1} (1 + \\alpha \\mu)\\, d\\mu = \\frac{1}{2} \\left[ \\mu + \\frac{\\alpha \\mu^2}{2} \\right]_{-1}^{1} $$\nEvaluating at the limits of integration:\n$$ \\frac{1}{2} \\left( \\left(1 + \\frac{\\alpha (1)^2}{2}\\right) - \\left(-1 + \\frac{\\alpha (-1)^2}{2}\\right) \\right) = \\frac{1}{2} \\left( 1 + \\frac{\\alpha}{2} - (-1 + \\frac{\\alpha}{2}) \\right) = \\frac{1}{2} \\left( 1 + \\frac{\\alpha}{2} + 1 - \\frac{\\alpha}{2} \\right) = \\frac{1}{2}(2) = 1 $$\nThe normalization condition is satisfied for any real value of $\\alpha$. Therefore, the constraints on $\\alpha$ arise solely from the non-negativity requirement.\n\nSecond, we impose the non-negativity condition: $p(\\mu) \\ge 0$ for all $\\mu \\in [-1, 1]$.\n$$ p(\\mu) = \\frac{1}{2}(1 + \\alpha \\mu) \\ge 0 $$\nSince the factor $\\frac{1}{2}$ is positive, this is equivalent to:\n$$ 1 + \\alpha \\mu \\ge 0 $$\nThe function $f(\\mu) = 1 + \\alpha \\mu$ is linear in $\\mu$. For a linear function over a closed interval, its minimum value must occur at one of the endpoints of the interval. We must therefore ensure the function is non-negative at $\\mu = -1$ and $\\mu = 1$.\n\nCase 1: At $\\mu = -1$.\n$$ 1 + \\alpha (-1) \\ge 0 \\implies 1 - \\alpha \\ge 0 \\implies \\alpha \\le 1 $$\n\nCase 2: At $\\mu = 1$.\n$$ 1 + \\alpha (1) \\ge 0 \\implies 1 + \\alpha \\ge 0 \\implies \\alpha \\ge -1 $$\n\nCombining both constraints, we find that $\\alpha$ must lie in the closed interval $[-1, 1]$.\n$$ -1 \\le \\alpha \\le 1 $$\nThe lower endpoint is $-1$ and the upper endpoint is $1$.\n\n### Part 2: Computation of the First Moment $E[\\mu]$\n\nThe first moment, or expected value, of $\\mu$ is given by the definition $E[\\mu] = \\int_{-1}^{1} \\mu\\, p(\\mu)\\, d\\mu$.\n$$ E[\\mu] = \\int_{-1}^{1} \\mu \\left( \\frac{1}{2}(1 + \\alpha \\mu) \\right) d\\mu $$\nWe expand the integrand:\n$$ E[\\mu] = \\frac{1}{2} \\int_{-1}^{1} (\\mu + \\alpha \\mu^2)\\, d\\mu $$\nWe can split the integral into two parts:\n$$ E[\\mu] = \\frac{1}{2} \\left( \\int_{-1}^{1} \\mu\\, d\\mu + \\int_{-1}^{1} \\alpha \\mu^2\\, d\\mu \\right) $$\nThe first integral, $\\int_{-1}^{1} \\mu\\, d\\mu$, is an integral of an odd function ($\\mu$) over a symmetric interval ($[-1, 1]$), which evaluates to $0$.\nThe second integral is:\n$$ \\int_{-1}^{1} \\alpha \\mu^2\\, d\\mu = \\alpha \\int_{-1}^{1} \\mu^2\\, d\\mu = \\alpha \\left[ \\frac{\\mu^3}{3} \\right]_{-1}^{1} = \\alpha \\left( \\frac{(1)^3}{3} - \\frac{(-1)^3}{3} \\right) = \\alpha \\left( \\frac{1}{3} - \\left(-\\frac{1}{3}\\right) \\right) = \\alpha \\left( \\frac{2}{3} \\right) $$\nSubstituting this back into the expression for $E[\\mu]$:\n$$ E[\\mu] = \\frac{1}{2} \\left( 0 + \\frac{2\\alpha}{3} \\right) = \\frac{\\alpha}{3} $$\nThe first moment of the distribution is $E[\\mu] = \\frac{\\alpha}{3}$.\n\n### Final Answer Assembly\nThe problem asks for a row matrix containing, in order:\n1.  The expression for $E[\\mu]$: $\\frac{\\alpha}{3}$.\n2.  The lower endpoint value for $\\alpha$: $-1$.\n3.  The upper endpoint value for $\\alpha$: $1$.\nThe final answer is a $1 \\times 3$ matrix of these values.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\alpha}{3}  -1  1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A critical step in any real-world simulation campaign is resource planning. Before launching a computationally intensive Monte Carlo calculation, we must estimate the number of particle histories required to achieve a target statistical precision. This exercise  guides you through applying the Central Limit Theorem (CLT) to this practical problem, focusing on the challenging but common scenario of estimating the probability of a rare event. By working through this, you will develop the skill to determine the necessary sample size to ensure your simulation results are statistically significant and meet design requirements.",
            "id": "4242630",
            "problem": "A pressurized water reactor core is simulated using Monte Carlo (MC) particle transport. Each simulated neutron history is categorized by a binary leakage outcome: leakage occurs with probability $p$, no leakage with probability $1-p$. Assume independent, identically distributed histories and that the leakage outcome for history $i$ is represented by a Bernoulli random variable $L_{i} \\in \\{0,1\\}$ with $\\mathbb{P}(L_{i}=1)=p$. The estimator of the leakage probability based on $N$ histories is the sample proportion $\\,\\hat{p} = \\frac{1}{N}\\sum_{i=1}^{N} L_{i}\\,$. Using the Central Limit Theorem (CLT), the sampling distribution of $\\,\\hat{p}\\,$ can be approximated by a normal distribution for sufficiently large $N$.\n\nYou are tasked to plan the number of histories $N$ to achieve a design precision target for estimating $p$ when $p \\approx 1.0 \\times 10^{-6}$. Define the design relative error as the ratio of the half-width of a two-sided CLT-based confidence interval to the true probability $p$. Require that this relative half-width be at most a specified tolerance $\\epsilon$ at a two-sided $95\\%$ confidence level.\n\nStarting from the fundamental definitions of Bernoulli variables and the CLT, derive an explicit closed-form expression for the minimum $N$ that guarantees the two-sided $95\\%$ CLT-based confidence interval for $\\,\\hat{p}\\,$ has relative half-width no greater than $\\epsilon$. Then, evaluate this minimum $N$ for $\\,p = 1.0 \\times 10^{-6}\\,$ and $\\,\\epsilon = 0.2\\,$, using the standard normal critical value $\\,z = 1.96\\,$ for the two-sided $95\\%$ level. Report the minimum integer number of histories required by taking the ceiling of the real-valued bound. No rounding to significant figures is needed beyond this ceiling operation. The final answer must be a single number without any units.",
            "solution": "The problem statement is evaluated and found to be valid. It is a well-posed statistical problem concerning sample size determination for a Bernoulli proportion, grounded in the established principles of the Central Limit Theorem and confidence interval construction. The problem provides a clear objective and all necessary data for its solution.\n\nWe begin by formalizing the statistical properties of the simulation. Each neutron history is a Bernoulli trial where leakage (success) occurs with probability $p$. The outcome of the $i$-th history is represented by the random variable $L_i$, where $L_i=1$ if leakage occurs and $L_i=0$ otherwise. The probability mass function is $\\mathbb{P}(L_i=1)=p$ and $\\mathbb{P}(L_i=0)=1-p$.\n\nThe mean (expected value) of this Bernoulli random variable is:\n$$ \\mathbb{E}[L_i] = 1 \\cdot \\mathbb{P}(L_i=1) + 0 \\cdot \\mathbb{P}(L_i=0) = p $$\nThe variance of $L_i$ is given by:\n$$ \\mathbb{V}[L_i] = \\mathbb{E}[L_i^2] - (\\mathbb{E}[L_i])^2 $$\nSince $L_i$ can only be $0$ or $1$, $L_i^2 = L_i$. Therefore, $\\mathbb{E}[L_i^2] = \\mathbb{E}[L_i] = p$. The variance is:\n$$ \\mathbb{V}[L_i] = p - p^2 = p(1-p) $$\nThe estimator for the leakage probability $p$ is the sample proportion $\\hat{p}$, defined as the average of $N$ independent and identically distributed (i.i.d.) observations:\n$$ \\hat{p} = \\frac{1}{N}\\sum_{i=1}^{N} L_{i} $$\nThe expected value of the estimator is:\n$$ \\mathbb{E}[\\hat{p}] = \\mathbb{E}\\left[\\frac{1}{N}\\sum_{i=1}^{N} L_{i}\\right] = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbb{E}[L_{i}] = \\frac{1}{N}(Np) = p $$\nSince the histories are independent, the variance of the estimator is:\n$$ \\mathbb{V}[\\hat{p}] = \\mathbb{V}\\left[\\frac{1}{N}\\sum_{i=1}^{N} L_{i}\\right] = \\frac{1}{N^2}\\sum_{i=1}^{N} \\mathbb{V}[L_{i}] = \\frac{1}{N^2}(N p(1-p)) = \\frac{p(1-p)}{N} $$\nThe standard deviation of the estimator, known as the standard error, is $\\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{N}}$.\n\nAccording to the Central Limit Theorem (CLT), for a sufficiently large number of histories $N$, the sampling distribution of $\\hat{p}$ is approximately normal with mean $p$ and variance $\\frac{p(1-p)}{N}$. That is, $\\hat{p} \\approx \\mathcal{N}\\left(p, \\frac{p(1-p)}{N}\\right)$.\n\nA two-sided $100(1-\\alpha)\\%$ confidence interval for $p$ is constructed as $\\hat{p} \\pm HW$, where $HW$ is the half-width of the interval. For planning purposes, before a sample is taken, the half-width is expressed using the true (or target) parameter $p$:\n$$ HW = z_{\\alpha/2} \\sigma_{\\hat{p}} = z_{\\alpha/2} \\sqrt{\\frac{p(1-p)}{N}} $$\nHere, $z_{\\alpha/2}$ is the critical value from the standard normal distribution corresponding to the confidence level. For a $95\\%$ confidence level, $1-\\alpha = 0.95$, so $\\alpha = 0.05$ and $\\alpha/2 = 0.025$. The problem provides the corresponding critical value $z \\equiv z_{0.025} = 1.96$.\n\nThe problem defines the design relative error as the ratio of the half-width to the true probability $p$, and requires this quantity to be no greater than a tolerance $\\epsilon$.\n$$ \\text{Relative Half-Width} = \\frac{HW}{p} = \\frac{z \\sqrt{\\frac{p(1-p)}{N}}}{p} \\leq \\epsilon $$\nOur first task is to derive a closed-form expression for the minimum $N$. We solve the inequality for $N$:\n$$ \\frac{z}{p} \\sqrt{\\frac{p(1-p)}{N}} \\leq \\epsilon $$\nIsolating the term with $N$:\n$$ \\sqrt{\\frac{p(1-p)}{N}} \\leq \\frac{p\\epsilon}{z} $$\nSquaring both sides (all quantities are non-negative):\n$$ \\frac{p(1-p)}{N} \\leq \\frac{p^2\\epsilon^2}{z^2} $$\nTo solve for $N$, we can invert both sides, which reverses the inequality sign:\n$$ \\frac{N}{p(1-p)} \\geq \\frac{z^2}{p^2\\epsilon^2} $$\nFinally, multiplying by $p(1-p)$ yields the expression for the minimum required sample size $N$:\n$$ N \\geq \\frac{z^2 p(1-p)}{p^2\\epsilon^2} $$\nSimplifying by canceling one factor of $p$:\n$$ N \\geq \\frac{z^2(1-p)}{p\\epsilon^2} $$\nThis is the required explicit closed-form expression.\n\nThe second task is to evaluate this minimum $N$ for the given values: $p = 1.0 \\times 10^{-6}$, $\\epsilon = 0.2$, and $z = 1.96$.\nSubstituting these values into the inequality:\n$$ N \\geq \\frac{(1.96)^2 (1 - 1.0 \\times 10^{-6})}{(1.0 \\times 10^{-6})(0.2)^2} $$\nWe perform the calculation:\n$$ N \\geq \\frac{3.8416 \\times 0.999999}{(1.0 \\times 10^{-6}) \\times 0.04} $$\n$$ N \\geq \\frac{3.8415961584}{4.0 \\times 10^{-8}} $$\n$$ N \\geq 96039903.96 $$\nSince the number of histories $N$ must be an integer, we must take the smallest integer that satisfies this condition. This is achieved by applying the ceiling function to the lower bound.\n$$ N_{\\text{min}} = \\lceil 96039903.96 \\rceil = 96039904 $$\nTherefore, a minimum of $96,039,904$ neutron histories must be simulated to achieve the specified precision.",
            "answer": "$$\\boxed{96039904}$$"
        },
        {
            "introduction": "In Monte Carlo methods, there are often multiple ways to estimate the same physical quantity. The art of the practice lies in choosing an estimator that provides the most precision for the least computational effort. This hands-on exercise  delves into this concept by directly comparing the efficiency of two classic methods for estimating particle current: the analog surface-crossing estimator and the non-analog next-event estimator. By deriving the variance of each estimator from first principles, you will quantitatively determine which is more efficient for a given problem, illustrating a core principle of variance reduction and simulation optimization.",
            "id": "4242639",
            "problem": "Consider a one-speed neutron transport in a homogeneous, purely absorbing half-space medium occupying $x0$, with macroscopic total cross section $\\Sigma_{t}$ independent of position and direction. A planar detector of unit area is located at $x=L$ and measures the net current flowing in the $+x$ direction. A monoenergetic source at $x=0$ emits neutrons into the $+x$ hemisphere with a semi-isotropic angular distribution: the cosine of the polar angle relative to the $+x$ axis, denoted by $\\mu$, is sampled uniformly on $[0,1]$, and each source particle has unit statistical weight. Assume neutrons travel in straight lines between collisions, and that the distance-to-collision along a trajectory is sampled from the exponential distribution with rate $\\Sigma_{t}$. Two Monte Carlo (MC) estimators are used to estimate the detector current $J$ per source particle:\n- Surface estimator: For each history, sample $\\mu \\sim \\mathrm{Uniform}(0,1)$ and a free-path length $s$ from the exponential distribution of rate $\\Sigma_{t}$. If the particle reaches the detector without collision, which occurs if $s \\geq L/\\mu$, score $X_{\\mathrm{surf}}=\\mu$, otherwise score $X_{\\mathrm{surf}}=0$.\n- Collision (next-event) estimator from the source: For each history, sample $\\mu \\sim \\mathrm{Uniform}(0,1)$ and score $X_{\\mathrm{coll}}=\\mu \\exp(-\\Sigma_{t} L/\\mu)$.\nAssume equal computational cost per history for both estimators, and define the MC efficiency of an estimator as the inverse of its per-history variance. Using probability distributions and Monte Carlo sampling theory from first principles, derive the per-history variance of each estimator and compute the ratio of efficiencies $R=\\varepsilon_{\\mathrm{surf}}/\\varepsilon_{\\mathrm{coll}}$ for the specified detector geometry and cross sections $\\Sigma_{t}=0.5\\ \\mathrm{cm}^{-1}$ and $L=2\\ \\mathrm{cm}$. Express the final ratio $R$ as a dimensionless number and round your answer to four significant figures.",
            "solution": "The goal is to compute the ratio of efficiencies, $R$, of the surface estimator ($X_{\\mathrm{surf}}$) and the collision estimator ($X_{\\mathrm{coll}}$). The efficiency, $\\varepsilon$, of an estimator is defined as the inverse of its per-history variance. Assuming equal computational cost per history, the ratio of efficiencies is given by the inverse ratio of their variances:\n$$R = \\frac{\\varepsilon_{\\mathrm{surf}}}{\\varepsilon_{\\mathrm{coll}}} = \\frac{1 / \\mathrm{Var}(X_{\\mathrm{surf}})}{1 / \\mathrm{Var}(X_{\\mathrm{coll}})} = \\frac{\\mathrm{Var}(X_{\\mathrm{coll}})}{\\mathrm{Var}(X_{\\mathrm{surf}})}$$\nThe variance of a random variable $X$ is given by the formula $\\mathrm{Var}(X) = E[X^2] - (E[X])^2$. We must therefore compute the first and second moments of each estimator. Both estimators are designed to estimate the same physical quantity: the net current $J$ at the detector plane $x=L$ per source particle. Thus, they must be unbiased, meaning their expected values should be equal to the true current, $J$.\n\nFirst, let's determine the true value of the current, $J$. A source particle is emitted at $x=0$ with an angle whose cosine is $\\mu$, where $\\mu$ is drawn from $p(\\mu)=1$ on $[0,1]$. For this particle to reach the detector at $x=L$, it must travel a distance of at least $L/\\mu$ without a collision. The probability of this occurring is $\\exp(-\\Sigma_t (L/\\mu))$. If the particle reaches the detector, its contribution to the net current is its weight (which is $1$) multiplied by $\\mu$. The total expected current $J$ is obtained by integrating this contribution over all possible source directions:\n$$J = \\int_{0}^{1} (\\text{current contribution}) \\times (\\text{probability of reaching detector}) \\times p(\\mu) d\\mu$$\n$$J = \\int_{0}^{1} \\mu \\cdot \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right) \\cdot 1 \\,d\\mu = \\int_{0}^{1} \\mu \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right) d\\mu$$\nThis integral can be expressed in terms of the exponential integral function, $E_n(z) = \\int_{1}^{\\infty} t^{-n} \\exp(-zt) dt$. By making the substitution $u=1/\\mu$, we have $d\\mu = -du/u^2$. The limits of integration change from $\\mu=0 \\to 1$ to $u=\\infty \\to 1$.\n$$J = \\int_{\\infty}^{1} \\frac{1}{u} \\exp(-\\Sigma_t L u) \\left(-\\frac{du}{u^2}\\right) = \\int_{1}^{\\infty} \\frac{\\exp(-\\Sigma_t L u)}{u^3} du = E_3(\\Sigma_t L)$$\n\nNext, we verify that both estimators are unbiased and calculate their second moments.\n\n**Analysis of the Surface Estimator ($X_{\\mathrm{surf}}$)**\nThe score is $X_{\\mathrm{surf}} = \\mu$ if $s \\ge L/\\mu$, and $0$ otherwise. The expectation is found by averaging over the distributions of both $\\mu$ and $s$. We use the law of total expectation, $E[X] = E_{\\mu}[E_s[X|\\mu]]$. For a fixed $\\mu$, the probability of a successful event ($s \\ge L/\\mu$) is $P(s \\ge L/\\mu) = \\int_{L/\\mu}^{\\infty} \\Sigma_t \\exp(-\\Sigma_t s) ds = \\exp(-\\Sigma_t L/\\mu)$.\nThe conditional expectation of the score for a given $\\mu$ is:\n$$E_s[X_{\\mathrm{surf}}|\\mu] = \\mu \\cdot P(s \\ge L/\\mu) + 0 \\cdot P(s  L/\\mu) = \\mu \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right)$$\nThe total expectation is then found by averaging over $\\mu$:\n$$E[X_{\\mathrm{surf}}] = \\int_{0}^{1} E_s[X_{\\mathrm{surf}}|\\mu] p(\\mu) d\\mu = \\int_{0}^{1} \\mu \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right) d\\mu = J = E_3(\\Sigma_t L)$$\nThe estimator is unbiased. The second moment is calculated similarly:\n$$E_s[X_{\\mathrm{surf}}^2|\\mu] = \\mu^2 \\cdot P(s \\ge L/\\mu) + 0^2 \\cdot P(s  L/\\mu) = \\mu^2 \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right)$$\n$$E[X_{\\mathrm{surf}}^2] = \\int_{0}^{1} \\mu^2 \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right) d\\mu$$\nUsing the same substitution $u=1/\\mu$, this integral becomes:\n$$E[X_{\\mathrm{surf}}^2] = \\int_{\\infty}^{1} \\frac{1}{u^2} \\exp(-\\Sigma_t L u) \\left(-\\frac{du}{u^2}\\right) = \\int_{1}^{\\infty} \\frac{\\exp(-\\Sigma_t L u)}{u^4} du = E_4(\\Sigma_t L)$$\nThe variance of the surface estimator is:\n$$\\mathrm{Var}(X_{\\mathrm{surf}}) = E[X_{\\mathrm{surf}}^2] - (E[X_{\\mathrm{surf}}])^2 = E_4(\\Sigma_t L) - [E_3(\\Sigma_t L)]^2$$\n\n**Analysis of the Collision (Next-Event) Estimator ($X_{\\mathrm{coll}}$)**\nThe score is $X_{\\mathrm{coll}} = \\mu \\exp(-\\Sigma_t L/\\mu)$, which is a deterministic function of the random variable $\\mu$.\nThe expectation is:\n$$E[X_{\\mathrm{coll}}] = \\int_{0}^{1} X_{\\mathrm{coll}}(\\mu) p(\\mu) d\\mu = \\int_{0}^{1} \\mu \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right) d\\mu = J = E_3(\\Sigma_t L)$$\nThe estimator is also unbiased. The second moment is:\n$$E[X_{\\mathrm{coll}}^2] = \\int_{0}^{1} [X_{\\mathrm{coll}}(\\mu)]^2 p(\\mu) d\\mu = \\int_{0}^{1} \\left(\\mu \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right)\\right)^2 d\\mu = \\int_{0}^{1} \\mu^2 \\exp\\left(-\\frac{2\\Sigma_t L}{\\mu}\\right) d\\mu$$\nUsing the substitution $u=1/\\mu$, this integral becomes:\n$$E[X_{\\mathrm{coll}}^2] = \\int_{\\infty}^{1} \\frac{1}{u^2} \\exp(-2\\Sigma_t L u) \\left(-\\frac{du}{u^2}\\right) = \\int_{1}^{\\infty} \\frac{\\exp(-2\\Sigma_t L u)}{u^4} du = E_4(2\\Sigma_t L)$$\nThe variance of the collision estimator is:\n$$\\mathrm{Var}(X_{\\mathrm{coll}}) = E[X_{\\mathrm{coll}}^2] - (E[X_{\\mathrm{coll}}])^2 = E_4(2\\Sigma_t L) - [E_3(\\Sigma_t L)]^2$$\n\n**Ratio of Efficiencies**\nNow we can write the expression for the ratio of efficiencies, $R$:\n$$R = \\frac{\\mathrm{Var}(X_{\\mathrm{coll}})}{\\mathrm{Var}(X_{\\mathrm{surf}})} = \\frac{E_4(2\\Sigma_t L) - [E_3(\\Sigma_t L)]^2}{E_4(\\Sigma_t L) - [E_3(\\Sigma_t L)]^2}$$\n\n**Numerical Calculation**\nThe problem provides the values $\\Sigma_t = 0.5\\ \\mathrm{cm}^{-1}$ and $L = 2\\ \\mathrm{cm}$. The dimensionless optical thickness is $\\tau = \\Sigma_t L = (0.5)(2) = 1$.\nSubstituting $\\tau=1$ into the expression for $R$:\n$$R = \\frac{E_4(2) - [E_3(1)]^2}{E_4(1) - [E_3(1)]^2}$$\nWe use standard library values for the exponential integral functions $E_n(z)$:\n- $E_3(1) \\approx 0.10969197$\n- $E_4(1) \\approx 0.08606241$\n- $E_4(2) \\approx 0.02502268$\n\nNow, we compute the variances:\n- First, the square of the mean value:\n$$[E_3(1)]^2 \\approx (0.10969197)^2 \\approx 0.01203233$$\n- Variance of the collision estimator:\n$$\\mathrm{Var}(X_{\\mathrm{coll}}) = E_4(2) - [E_3(1)]^2 \\approx 0.02502268 - 0.01203233 = 0.01299035$$\n- Variance of the surface estimator:\n$$\\mathrm{Var}(X_{\\mathrm{surf}}) = E_4(1) - [E_3(1)]^2 \\approx 0.08606241 - 0.01203233 = 0.07403008$$\nFinally, we compute the ratio $R$:\n$$R = \\frac{0.01299035}{0.07403008} \\approx 0.17547444$$\nRounding the result to four significant figures, we get $0.1755$.",
            "answer": "$$\\boxed{0.1755}$$"
        }
    ]
}