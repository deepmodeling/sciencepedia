{
    "hands_on_practices": [
        {
            "introduction": "Understanding how control actions affect the power distribution is central to reactor operation and safety. This exercise  provides hands-on practice with one of the most powerful tools for this task: first-order perturbation theory. By deriving and implementing a sensitivity analysis for the neutron diffusion equation, you will learn to predict changes in the axial and radial power shape resulting from local perturbations, such as changes in the absorption cross section $\\Sigma_a$, without the need for expensive re-simulations.",
            "id": "4214988",
            "problem": "You are to model and analyze axial and radial power shape control in a two-dimensional, one-energy-group neutron diffusion reactor simulation using sensitivity and perturbation theory. Begin from the steady-state one-energy-group neutron diffusion equation in a homogeneous rectangular core with vacuum (Dirichlet) boundary conditions. The governing equation is the balance between diffusion, absorption, and fission source, expressed as\n$$\n-\\nabla \\cdot \\left(D \\nabla \\phi(\\mathbf{r})\\right) + \\Sigma_a(\\mathbf{r}) \\,\\phi(\\mathbf{r}) = \\frac{1}{k} \\,\\nu \\Sigma_f(\\mathbf{r}) \\,\\phi(\\mathbf{r}),\n$$\nwhere $D$ is the diffusion coefficient, $\\Sigma_a$ is the macroscopic absorption cross section, $\\nu \\Sigma_f$ is the macroscopic fission production cross section, $\\phi(\\mathbf{r})$ is the neutron flux, and $k$ is the multiplication factor. Cast this into the generalized eigenvalue problem\n$$\nL \\,\\phi = \\lambda \\,F \\,\\phi,\n$$\nwith $\\lambda = \\frac{1}{k}$, where $L$ is the discrete diffusion-plus-absorption operator and $F$ is the discrete fission production operator. Use a uniform, Cartesian finite-difference discretization with $N_x$ points in the axial direction and $N_y$ points in the radial direction, and vacuum boundary conditions implemented as fixed-zero flux on the boundary. All quantities are dimensionless; $D$, $\\Sigma_a$, and $\\nu \\Sigma_f$ are spatially varying only insofar as perturbations are applied.\n\nDefine the power density vector $p$ as the fission source weighted by flux,\n$$\np = F \\,\\phi,\n$$\nand define the normalized power shape $s$ as\n$$\ns = \\frac{p}{\\sum_i p_i},\n$$\nwhere the sum is over all spatial degrees of freedom. Assume $L$ and $F$ are symmetric positive operators under the standard Euclidean inner product for the discrete problem, and that the fundamental mode dominates.\n\nPerturb the absorption cross section field by a small, spatially varying amount $\\delta \\Sigma_a(\\mathbf{r})$ so that\n$$\n\\Sigma_a(\\mathbf{r}) \\rightarrow \\Sigma_a(\\mathbf{r}) + \\epsilon\\,\\delta \\Sigma_a(\\mathbf{r}),\n$$\nwith small scalar $\\epsilon > 0$. Under first-order perturbation theory, derive from the generalized eigenproblem the first-order expressions for the change in the eigenvalue $\\delta \\lambda$, the change in the eigenfunction $\\delta \\phi$, and the corresponding change in the normalized power shape $\\delta s$. Formulate any necessary normalization constraints and any auxiliary linear systems required to make the problem well-posed. Your derivation must start from the governing balance equation and proceed through the generalized eigenproblem formulation without invoking any shortcut formulas.\n\nImplement a program that:\n- Discretizes a rectangular core with $N_x = 20$, $N_y = 20$, constant $D = 1$, baseline $\\Sigma_a = 0.01$, and baseline $\\nu \\Sigma_f = 0.02$.\n- Computes the fundamental generalized eigenpair $(\\phi, \\lambda)$ using an inverse power iteration on $L^{-1} F$ and normalizes $\\phi$ such that $\\phi^\\top F \\phi = 1$, then computes the baseline normalized power shape $s$.\n- Applies three test-case perturbations of the absorption field, each scaled by $\\epsilon = 10^{-4}$, and for each:\n  1. Predicts the first-order change $\\delta s$ via the sensitivity and perturbation theory you have derived.\n  2. Independently computes the actual change in shape by resolving the perturbed eigenproblem and forming $s'$ from the perturbed $(\\phi', \\lambda')$, then computes $s' - s$.\n  3. Outputs a scalar error defined as the infinity-norm of the difference between the predicted and actual changes, i.e., $\\|\\delta s - (s' - s)\\|_\\infty$.\n\nUse the following test suite of perturbations $\\delta \\Sigma_a(\\mathbf{r})$:\n- Case A (axial top-half absorber): $\\delta \\Sigma_a(\\mathbf{r}_{i,j}) = 1$ for axial indices $i \\in \\{10,11,\\dots,19\\}$ and $0$ otherwise.\n- Case B (radial rim absorber): $\\delta \\Sigma_a(\\mathbf{r}_{i,j}) = 1$ for any cell with minimum distance to the rectangular boundary $\\leq 2$ grid cells, and $0$ otherwise.\n- Case C (no perturbation): $\\delta \\Sigma_a(\\mathbf{r}_{i,j}) = 0$ for all cells.\n\nThe final output must be a single line containing the three error values for Cases A, B, and C, in that order, as a comma-separated list enclosed in square brackets, for example, $[x_A,x_B,x_C]$. All quantities are dimensionless, and the output values must be plain floats with no units.",
            "solution": "The user wants to analyze the effect of perturbations in the absorption cross-section on the power distribution in a nuclear reactor. This is a classic problem in reactor physics, which can be solved using first-order perturbation theory for a generalized eigenvalue problem. The solution involves both a theoretical derivation and a numerical implementation to verify the theory.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- **Governing Equation:** $-\\nabla \\cdot \\left(D \\nabla \\phi(\\mathbf{r})\\right) + \\Sigma_a(\\mathbf{r}) \\,\\phi(\\mathbf{r}) = \\frac{1}{k} \\,\\nu \\Sigma_f(\\mathbf{r}) \\,\\phi(\\mathbf{r})$\n- **Operator Form:** $L \\,\\phi = \\lambda \\,F \\,\\phi$, with $\\lambda = \\frac{1}{k}$.\n- **Operators:** $L$ is the discrete diffusion-plus-absorption operator, $F$ is the discrete fission production operator. Assumed symmetric and positive.\n- **Power Definition:** Power density $p = F \\,\\phi$, normalized power shape $s = p / \\sum_i p_i$.\n- **Perturbation:** $\\Sigma_a(\\mathbf{r}) \\rightarrow \\Sigma_a(\\mathbf{r}) + \\epsilon\\,\\delta \\Sigma_a(\\mathbf{r})$, where $\\epsilon = 10^{-4}$.\n- **Discretization:** Uniform Cartesian finite difference, $N_x=20$ (axial), $N_y=20$ (radial). Vacuum (zero-flux) boundary conditions.\n- **Baseline Parameters:** $D=1$, $\\Sigma_a=0.01$, $\\nu\\Sigma_f=0.02$. All quantities are dimensionless.\n- **Normalization:** The fundamental eigenfunction $\\phi$ is normalized such that $\\phi^\\top F \\phi = 1$.\n- **Test Cases for $\\delta \\Sigma_a(\\mathbf{r}_{i,j})$:**\n  - Case A (axial top-half): $1$ for axial indices $i \\in \\{10,11,\\dots,19\\}$ (assuming 0-indexed grid), $0$ otherwise.\n  - Case B (radial rim): $1$ for any cell with minimum distance to the boundary $\\leq 2$ grid cells, $0$ otherwise. Interpreted as indices $i$ or $j$ in $\\{0, 1, 18, 19\\}$.\n  - Case C (no perturbation): $0$ for all cells.\n- **Task:**\n  1. Derive first-order expressions for $\\delta \\lambda$, $\\delta \\phi$, and $\\delta s$.\n  2. Implement a program to compute the baseline state $(\\phi, \\lambda)$.\n  3. For each test case, calculate the predicted change $\\delta s$ and the \"actual\" change $s' - s$ (from re-solving the perturbed eigenproblem).\n  4. Output the infinity-norm of the difference, $\\|\\delta s - (s'-s)\\|_\\infty$, for each case.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is based on the one-group neutron diffusion equation, a cornerstone of reactor physics. The use of perturbation theory is a standard and valid analytical technique in this field. The setup is a well-established academic model. The parameters are physically reasonable for a dimensionless model.\n- **Well-Posed:** The problem is a generalized eigenvalue problem for a system with symmetric positive operators. The fundamental mode is guaranteed to exist and be unique (up to scaling). The problem specifies a normalization condition, making the solution for $\\phi$ unique. The problem asks for the derivation of an auxiliary linear system to find $\\delta\\phi$, indicating awareness of the ill-posed nature of the naive perturbation equation and how to correct it.\n- **Objective:** The problem is stated in precise mathematical and physical terms, free of subjectivity.\n- **Completeness:** All necessary parameters ($N_x, N_y, D, \\Sigma_a, \\nu\\Sigma_f, \\epsilon$) and boundary conditions are specified. The test cases are clearly defined. The method for calculating eigenvalues (inverse power iteration) and the error metric are specified.\n- **Consistency:** There are no apparent contradictions in the problem statement.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, and complete. It represents a standard, rigorous exercise in numerical reactor physics.\n**Verdict: Valid.** I will proceed with the solution.\n\n### Theoretical Derivation\n\nThe analysis begins with the unperturbed, time-independent generalized eigenvalue problem in operator form:\n$$ L_0 \\phi_0 = \\lambda_0 F_0 \\phi_0 $$\nwhere $\\phi_0$ is the fundamental mode eigenfunction (neutron flux) and $\\lambda_0 = 1/k_0$ is the corresponding fundamental eigenvalue. The problem states that the operators $L_0$ (diffusion and absorption) and $F_0$ (fission production) are real and symmetric. Consequently, the adjoint eigenfunctions are identical to the forward eigenfunctions.\n\nA small perturbation is introduced in the absorption cross-section, $\\Sigma_a \\rightarrow \\Sigma_a + \\delta\\Sigma_a$. This affects only the operator $L$. The fission operator $F$ remains unchanged. The perturbed system is:\n$$ L' \\phi' = \\lambda' F_0 \\phi' $$\nwhere $L' = L_0 + \\delta L$, $\\lambda' = \\lambda_0 + \\delta\\lambda$, and $\\phi' = \\phi_0 + \\delta\\phi$. The perturbation operator $\\delta L$ is a diagonal matrix whose entries are the changes in the macroscopic absorption cross-section, $\\delta\\Sigma_a$, at each spatial point. For this problem, $\\delta L = \\epsilon \\cdot \\text{diag}(\\delta\\Sigma_{a,i})$, where $\\delta\\Sigma_{a,i}$ is the pattern of the absorber perturbation.\n\nSubstituting the perturbed quantities into the eigenvalue equation:\n$$ (L_0 + \\delta L)(\\phi_0 + \\delta\\phi) = (\\lambda_0 + \\delta\\lambda) F_0 (\\phi_0 + \\delta\\phi) $$\nExpanding and retaining only terms up to first order in the small perturbation gives:\n$$ L_0 \\phi_0 + L_0 \\delta\\phi + \\delta L \\phi_0 \\approx \\lambda_0 F_0 \\phi_0 + \\lambda_0 F_0 \\delta\\phi + \\delta\\lambda F_0 \\phi_0 $$\nThe unperturbed terms $L_0 \\phi_0 = \\lambda_0 F_0 \\phi_0$ cancel, leaving the first-order equation:\n$$ (L_0 - \\lambda_0 F_0) \\delta\\phi \\approx (\\delta\\lambda F_0 - \\delta L) \\phi_0 $$\n\n**1. Change in Eigenvalue, $\\delta\\lambda$**\nTo find $\\delta\\lambda$, we take the inner product (here, the standard vector dot product) of the first-order equation with the unperturbed eigenfunction $\\phi_0$:\n$$ \\langle \\phi_0, (L_0 - \\lambda_0 F_0) \\delta\\phi \\rangle = \\langle \\phi_0, (\\delta\\lambda F_0 - \\delta L) \\phi_0 \\rangle $$\nUsing the symmetry of $L_0$ and $F_0$, the left-hand side is $\\langle (L_0 - \\lambda_0 F_0) \\phi_0, \\delta\\phi \\rangle = \\langle 0, \\delta\\phi \\rangle = 0$. Thus, the right-hand side must also be zero:\n$$ \\langle \\phi_0, (\\delta\\lambda F_0 - \\delta L) \\phi_0 \\rangle = 0 $$\n$$ \\delta\\lambda \\langle \\phi_0, F_0 \\phi_0 \\rangle - \\langle \\phi_0, \\delta L \\phi_0 \\rangle = 0 $$\nSolving for $\\delta\\lambda$ yields the classical first-order perturbation theory result:\n$$ \\delta\\lambda = \\frac{\\langle \\phi_0, \\delta L \\phi_0 \\rangle}{\\langle \\phi_0, F_0 \\phi_0 \\rangle} $$\nWith the specified normalization $\\langle \\phi_0, F_0 \\phi_0 \\rangle = \\phi_0^\\top F_0 \\phi_0 = 1$, this simplifies to $\\delta\\lambda = \\langle \\phi_0, \\delta L \\phi_0 \\rangle$.\n\n**2. Change in Eigenfunction, $\\delta\\phi$**\nThe equation for $\\delta\\phi$ is $(L_0 - \\lambda_0 F_0) \\delta\\phi = (\\delta\\lambda F_0 - \\delta L) \\phi_0$. The operator $(L_0 - \\lambda_0 F_0)$ is singular, as $\\lambda_0$ is its eigenvalue. A solution exists because the right-hand side is orthogonal to the null space of the adjoint operator $(L_0 - \\lambda_0 F_0)^\\dagger = (L_0 - \\lambda_0 F_0)$, which is spanned by $\\phi_0$. However, the solution is not unique; any multiple of $\\phi_0$ can be added to it. To obtain a unique solution, we must impose an additional constraint. A standard choice for generalized eigenvalue problems is to require the perturbation $\\delta\\phi$ to be $F_0$-orthogonal to the original eigenfunction $\\phi_0$:\n$$ \\langle \\phi_0, F_0 \\delta\\phi \\rangle = 0 $$\nThe singular linear system for $\\delta\\phi$ and the orthogonality constraint can be combined into a single, non-singular block matrix system:\n$$\n\\begin{pmatrix}\nL_0 - \\lambda_0 F_0 & F_0 \\phi_0 \\\\\n\\phi_0^\\top F_0 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n\\delta\\phi \\\\ c\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(\\delta\\lambda F_0 - \\delta L) \\phi_0 \\\\ 0\n\\end{pmatrix}\n$$\nwhere $c$ is a Lagrange multiplier which turns out to be zero. Solving this $(N+1) \\times (N+1)$ system yields the unique $\\delta\\phi$ that satisfies both the perturbation equation and the orthogonality constraint.\n\n**3. Change in Normalized Power Shape, $\\delta s$**\nThe normalized power shape is $s = p / (\\mathbf{1}^\\top p)$, where $p = F_0 \\phi$ and $\\mathbf{1}$ is a vector of ones. The perturbed shape is $s' = s + \\delta s$. To first order:\n$$ s' = \\frac{F_0(\\phi_0 + \\delta\\phi)}{\\mathbf{1}^\\top F_0(\\phi_0 + \\delta\\phi)} = \\frac{p_0 + \\delta p}{P_{tot,0} + \\delta P_{tot}} $$\nwhere $p_0=F_0\\phi_0$, $\\delta p=F_0\\delta\\phi$, $P_{tot,0}=\\mathbf{1}^\\top p_0$, and $\\delta P_{tot}=\\mathbf{1}^\\top \\delta p$.\nUsing the first-order approximation $(1+x)^{-1} \\approx 1-x$:\n$$ s' \\approx \\frac{p_0 + \\delta p}{P_{tot,0}} \\left(1 - \\frac{\\delta P_{tot}}{P_{tot,0}}\\right) \\approx \\frac{p_0}{P_{tot,0}} + \\frac{\\delta p}{P_{tot,0}} - \\frac{p_0 \\delta P_{tot}}{P_{tot,0}^2} $$\nRecognizing that $s_0 = p_0 / P_{tot,0}$, we find the first-order change in the power shape:\n$$ \\delta s = s' - s_0 \\approx \\frac{\\delta p}{P_{tot,0}} - s_0 \\frac{\\delta P_{tot}}{P_{tot,0}} $$\nThe sum of entries in $\\delta s$ is $\\mathbf{1}^\\top\\delta s = \\frac{\\mathbf{1}^\\top\\delta p}{P_{tot,0}} - (\\mathbf{1}^\\top s_0) \\frac{\\delta P_{tot}}{P_{tot,0}} = \\frac{\\delta P_{tot}}{P_{tot,0}} - 1 \\cdot \\frac{\\delta P_{tot}}{P_{tot,0}} = 0$, which is a necessary condition for a change in a normalized distribution.\n\n### Numerical Implementation Plan\nThe implementation will proceed as follows:\n1.  **Discretization:** Set up a 2D grid of size $N_x \\times N_y = 20 \\times 20$. Construct the sparse system matrices $L_0$ and $F_0$ using a 5-point finite difference stencil for the Laplacian on a grid with unit spacing ($h_x=h_y=1$) and zero-flux boundary conditions. The operators are represented as $N \\times N$ sparse matrices, where $N=N_x N_y = 400$.\n2.  **Baseline Solution:** Solve the unperturbed generalized eigenvalue problem $L_0\\phi_0 = \\lambda_0 F_0\\phi_0$ for the fundamental eigenpair $(\\lambda_0, \\phi_0)$. This is accomplished using inverse power iteration on the operator $L_0^{-1}F_0$, which converges to the eigenvector corresponding to the largest eigenvalue $k_0 = 1/\\lambda_0$. The resulting flux $\\phi_0$ is normalized such that $\\phi_0^\\top F_0 \\phi_0 = 1$. The baseline power shape $s_0$ is then computed.\n3.  **Perturbation Analysis (for each case):**\n    a. Construct the perturbation matrix $\\delta L$ based on the given $\\delta\\Sigma_a$.\n    b. Calculate the predicted eigenvalue change $\\delta\\lambda$ using the derived formula.\n    c. Form and solve the augmented linear system to find the predicted flux change $\\delta\\phi$.\n    d. Calculate the predicted power shape change $\\delta s$ from $\\delta\\phi$.\n4.  **Direct Solution (for each case):**\n    a. Construct the perturbed operator $L' = L_0 + \\delta L$.\n    b. Solve the new eigenvalue problem $L'\\phi' = \\lambda' F_0\\phi'$ using the same inverse power iteration method.\n    c. Normalize the perturbed flux $\\phi'$ and compute the new power shape $s'$.\n    d. The \"actual\" change is the difference $s'-s_0$.\n5.  **Error Calculation:** For each of the three cases, compute the error as the infinity-norm of the difference between the predicted and actual power shape changes: $\\|\\delta s - (s'-s_0)\\|_\\infty$.\n6.  **Output:** Report the three error values in the specified format. Case C serves as a valuable sanity check, as the predicted and actual changes should both be zero, resulting in a zero error.",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse import diags, csc_matrix, bmat\nfrom scipy.sparse.linalg import spsolve\n\ndef build_operators(Nx, Ny, D, Sigma_a, nu_Sigma_f):\n    \"\"\"\n    Builds the finite difference operators L and F for the 2D neutron diffusion equation.\n    \n    Args:\n        Nx (int): Number of grid points in the x-direction.\n        Ny (int): Number of grid points in the y-direction.\n        D (float or np.ndarray): Diffusion coefficient.\n        Sigma_a (float or np.ndarray): Absorption cross-section.\n        nu_Sigma_f (float or np.ndarray): Fission production cross-section.\n        \n    Returns:\n        (csc_matrix, csc_matrix): Sparse matrices L and F.\n    \"\"\"\n    N = Nx * Ny\n    # Assume grid spacing hx=hy=1 as problem is dimensionless\n    hx2, hy2 = 1.0, 1.0\n\n    # Create the 5-point stencil for the Laplacian part of L\n    # Main diagonal from centered difference and absorption\n    diag_L = (2 * D / hx2 + 2 * D / hy2) * np.ones(N) + Sigma_a.flatten()\n    \n    # Off-diagonals for x-dir coupling\n    off_diag_x = -D / hx2 * np.ones(N - Ny)\n    \n    # Off-diagonals for y-dir coupling\n    off_diag_y = -D / hy2 * np.ones(N - 1)\n    # Remove connections at grid boundaries (row wraps)\n    for i in range(1, Nx):\n        off_diag_y[i * Ny - 1] = 0\n\n    L = diags(\n        [off_diag_x, off_diag_y, diag_L, off_diag_y, off_diag_x],\n        [-Ny, -1, 0, 1, Ny],\n        format='csc'\n    )\n    \n    # Fission operator F is a diagonal matrix\n    F = diags([nu_Sigma_f.flatten()], [0], format='csc')\n    \n    return L, F\n\ndef inverse_power_iteration(L, F, tol=1e-10, max_iter=200):\n    \"\"\"\n    Solves the generalized eigenvalue problem L*phi = lambda*F*phi for the\n    fundamental mode (largest k = 1/lambda) using inverse power iteration.\n    \n    Args:\n        L (csc_matrix): Diffusion/absorption operator.\n        F (csc_matrix): Fission operator.\n        tol (float): Convergence tolerance.\n        max_iter (int): Maximum number of iterations.\n        \n    Returns:\n        (float, np.ndarray): Fundamental eigenvalue lambda_0 and eigenvector phi_0.\n    \"\"\"\n    N = L.shape[0]\n    # Initial guess for the flux (must be positive for fundamental mode)\n    phi_guess = np.ones(N)\n    \n    k_eff = 1.0\n    for _ in range(max_iter):\n        source = F @ phi_guess\n        # Solve L * phi_new = source\n        phi_new = spsolve(L, source)\n        \n        # New eigenvalue estimate k = 1/lambda\n        k_new = np.linalg.norm(phi_new)\n        \n        # Normalize for next iteration\n        phi_new /= k_new\n        \n        # Check for convergence\n        if np.linalg.norm(phi_new - phi_guess) < tol:\n            break\n        \n        phi_guess = phi_new\n        k_eff = k_new\n\n    # Final eigenvalue is 1/k_eff\n    lambda_val = 1.0 / k_eff\n    phi_vec = phi_new\n    \n    return lambda_val, phi_vec\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the perturbation analysis.\n    \"\"\"\n    # 1. Problem setup\n    Nx, Ny = 20, 20\n    D_val = 1.0\n    Sigma_a_base = 0.01\n    nu_Sigma_f_base = 0.02\n    epsilon = 1e-4\n\n    N = Nx * Ny\n    \n    Sigma_a_grid = np.full((Nx, Ny), Sigma_a_base)\n    nu_Sigma_f_grid = np.full((Nx, Ny), nu_Sigma_f_base)\n\n    # 2. Baseline Calculation\n    L0, F0 = build_operators(Nx, Ny, D_val, Sigma_a_grid, nu_Sigma_f_grid)\n    lambda0_un, phi0_un = inverse_power_iteration(L0, F0)\n    \n    # Normalize phi0 such that phi0.T @ F0 @ phi0 = 1\n    norm_factor = np.sqrt(phi0_un.T @ F0 @ phi0_un)\n    phi0 = phi0_un / norm_factor\n    \n    # Recalculate lambda0 with normalized phi0 for better accuracy\n    lambda0 = (phi0.T @ L0 @ phi0) / (phi0.T @ F0 @ phi0)\n    \n    # Calculate baseline power shape s0\n    p0 = F0 @ phi0\n    P_total0 = np.sum(p0)\n    s0 = p0 / P_total0\n\n    # 3. Define Test Cases for delta_Sigma_a\n    test_cases = []\n\n    # Case A: Axial top-half absorber\n    delta_Sa_A = np.zeros((Nx, Ny))\n    delta_Sa_A[10:20, :] = 1.0\n    test_cases.append(delta_Sa_A)\n\n    # Case B: Radial rim absorber\n    delta_Sa_B = np.zeros((Nx, Ny))\n    for i in range(Nx):\n        for j in range(Ny):\n            if i <= 1 or i >= Nx - 2 or j <= 1 or j >= Ny - 2:\n                delta_Sa_B[i, j] = 1.0\n    test_cases.append(delta_Sa_B)\n    \n    # Case C: No perturbation\n    delta_Sa_C = np.zeros((Nx, Ny))\n    test_cases.append(delta_Sa_C)\n    \n    errors = []\n\n    for delta_Sa_pattern in test_cases:\n        # --- PERTURBATION THEORY PREDICTION ---\n        delta_L = diags([epsilon * delta_Sa_pattern.flatten()], [0], format='csc')\n        \n        # Predicted change in eigenvalue (using phi0.T @ F0 @ phi0 = 1)\n        delta_lambda = phi0.T @ delta_L @ phi0\n        \n        # Form RHS for the delta_phi system\n        rhs = (delta_lambda * F0 - delta_L) @ phi0\n\n        # Form and solve the augmented system for delta_phi\n        N = L0.shape[0]\n        op_A = L0 - lambda0 * F0\n        F_phi_col = F0 @ phi0\n        \n        # Build augmented matrix\n        A_aug = bmat([\n            [op_A, csc_matrix(F_phi_col).T],\n            [csc_matrix(F_phi_col), None]\n        ], format='csc')\n        \n        b_aug = np.zeros(N + 1)\n        b_aug[:N] = rhs\n        \n        x_aug = spsolve(A_aug, b_aug)\n        delta_phi = x_aug[:N]\n        \n        # Predicted change in power shape\n        delta_p = F0 @ delta_phi\n        delta_P_total = np.sum(delta_p)\n        delta_s_predicted = (delta_p / P_total0) - (s0 * delta_P_total / P_total0)\n        \n        # --- \"ACTUAL\" CHANGE FROM DIRECT RE-SOLVE ---\n        L_prime = L0 + delta_L\n        lambda_prime_un, phi_prime_un = inverse_power_iteration(L_prime, F0)\n\n        # Normalize phi_prime\n        norm_factor_prime = np.sqrt(phi_prime_un.T @ F0 @ phi_prime_un)\n        phi_prime = phi_prime_un / norm_factor_prime\n        \n        # Calculate new power shape s_prime\n        p_prime = F0 @ phi_prime\n        P_total_prime = np.sum(p_prime)\n        s_prime = p_prime / P_total_prime\n        \n        delta_s_actual = s_prime - s0\n        \n        # --- ERROR CALCULATION ---\n        error = np.linalg.norm(delta_s_predicted - delta_s_actual, np.inf)\n        errors.append(f\"{error:.6e}\")\n        \n    print(f\"[{','.join(errors)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "The power shape in a reactor core is not static; it evolves continuously as fuel is consumed and material compositions change. This practice  delves into the core computational challenge of this process: the coupled relationship between the neutron flux $\\phi(\\mathbf{r},t)$ and the nuclide densities $\\{N_j(\\mathbf{r},t)\\}$. You will analyze predictor-corrector algorithms designed to solve this coupled system accurately, gaining insight into how to maintain physical constraints like constant total power $P_0$ while correctly capturing the feedback between local burnup and the evolving power distribution.",
            "id": "4241754",
            "problem": "A thermal nuclear reactor core is modeled as a three-dimensional domain with spatial coordinates denoted by $(\\mathbf{r})$. Let the neutron scalar flux be $\\phi(\\mathbf{r},t)$ and the macroscopic fission cross section be $\\Sigma_f(\\mathbf{r},t)$, which depends on nuclide number densities through depletion. The local thermal power density is $q(\\mathbf{r},t)$, defined by $q(\\mathbf{r},t)=\\kappa\\,\\Sigma_f(\\mathbf{r},t)\\,\\phi(\\mathbf{r},t)$, where $\\kappa$ is the mean energy released per fission multiplied by an appropriate unit conversion factor. The total reactor power is $P_{\\mathrm{tot}}(t)=\\int_V q(\\mathbf{r},t)\\,\\mathrm{d}V$. Assume an operational constraint that $P_{\\mathrm{tot}}(t)$ is held constant at $P_0$ during the time interval $[t_n,t_{n+1}]$.\n\nNuclide number densities $\\{N_j(\\mathbf{r},t)\\}$ evolve by coupled Ordinary Differential Equations (ODEs) driven by reaction rates and decay, with the depletion written generically as\n$$\n\\frac{\\partial N_j(\\mathbf{r},t)}{\\partial t}=\\sum_{k} \\lambda_{k\\to j} N_k(\\mathbf{r},t) - \\lambda_j N_j(\\mathbf{r},t) - \\sum_{r} \\sigma_{r,j}(\\mathbf{r},t)\\,\\phi(\\mathbf{r},t)\\,N_j(\\mathbf{r},t),\n$$\nwhere $\\lambda_j$ are decay constants, $\\lambda_{k\\to j}$ are transmutation yields and $\\sigma_{r,j}$ are microscopic cross sections for reactions $r$ (e.g., fission, capture).\n\nAt the beginning of the step $t_n$, the flux shape is known and represented by a nonnegative function $s_n(\\mathbf{r})$ normalized such that $\\int_V s_n(\\mathbf{r})\\,\\mathrm{d}V=1$. A common approximation over a small depletion time step $\\Delta t=t_{n+1}-t_n$ is to express the flux as a product of a scalar normalization and a shape, $\\phi(\\mathbf{r},t)\\approx C(t)\\,s(\\mathbf{r},t)$, where $s(\\mathbf{r},t)$ captures the axial and radial distribution of the flux (equivalently, of the power density), and $C(t)$ ensures the total power constraint.\n\nFrom first principles of reaction-rate-driven depletion and power definition, explain how spatial variations in $s(\\mathbf{r},t)$ (axial or radial power distributions) influence the local depletion of nuclides and, based on this understanding, select the predictor–corrector coupling strategy that maintains shape-consistent normalization and enforces the total power constraint in $[t_n,t_{n+1}]$.\n\nWhich option most correctly captures both the influence of spatial power distributions on local depletion and a scientifically consistent predictor–corrector algorithm that maintains shape-consistent normalization under constant total power?\n\nA. Model the flux as $\\phi(\\mathbf{r},t)\\approx C(t)\\,s_n(\\mathbf{r})$ in the predictor, where $C_{\\mathrm{pred}}$ is chosen to satisfy $P_0=\\int_V \\kappa\\,\\Sigma_f^n(\\mathbf{r})\\,s_n(\\mathbf{r})\\,C_{\\mathrm{pred}}\\,\\mathrm{d}V$ using beginning-of-step compositions. Integrate the depletion ODEs over $\\Delta t$ to obtain predicted number densities $\\{N_j^{\\mathrm{pred}}(\\mathbf{r})\\}$. In the corrector, recompute the flux shape $s_{n+1}(\\mathbf{r})$ and cross sections $\\Sigma_f^{n+1}(\\mathbf{r})$ from neutronics with $\\{N_j^{\\mathrm{pred}}(\\mathbf{r})\\}$, and determine $C_{\\mathrm{corr}}$ from $P_0=\\int_V \\kappa\\,\\Sigma_f^{n+1}(\\mathbf{r})\\,s_{n+1}(\\mathbf{r})\\,C_{\\mathrm{corr}}\\,\\mathrm{d}V$. Reintegrate the depletion ODEs over $\\Delta t$ using trapezoidal averages $s_{\\mathrm{avg}}(\\mathbf{r})$ proportional to $s_n(\\mathbf{r})+s_{n+1}(\\mathbf{r})$ and $C_{\\mathrm{avg}}=(C_{\\mathrm{pred}}+C_{\\mathrm{corr}})/2$, ensuring $P_0=\\int_V \\kappa\\,\\overline{\\Sigma_f}(\\mathbf{r})\\,s_{\\mathrm{avg}}(\\mathbf{r})\\,C_{\\mathrm{avg}}\\,\\mathrm{d}V$, with $\\overline{\\Sigma_f}$ an appropriate average over the step. This couples axial/radial power shape to local reaction rates and maintains shape-consistent normalization.\n\nB. Hold the flux shape fixed at $s_n(\\mathbf{r})$ over $[t_n,t_{n+1}]$, and at each substep choose $C(t)$ such that $\\max_{\\mathbf{r}\\in V} q(\\mathbf{r},t)$ equals its value at $t_n$. This ensures the hottest node does not change power, which stabilizes depletion locally regardless of changes in $\\Sigma_f(\\mathbf{r},t)$.\n\nC. Use predictor–corrector iterations to update $s(\\mathbf{r},t)$, but normalize the flux by enforcing a constant total neutron flux $\\int_V \\phi(\\mathbf{r},t)\\,\\mathrm{d}V$, since this guarantees the reaction-rate integral remains unchanged even as $\\Sigma_f(\\mathbf{r},t)$ evolves.\n\nD. Replace spatially resolved depletion with a single-volume model in which $N_j(\\mathbf{r},t)$ are volume-averaged and depleted uniformly using $P_0/V$. Predictor–corrector is unnecessary because axial/radial shape does not influence the uniform burnup imposed by constant total power.\n\nE. In the predictor step, use $\\phi(\\mathbf{r},t)\\approx C(t)\\,s_n(\\mathbf{r})$ with $C(t)$ from $P_0$; in the corrector step, redistribute $C(t)$ among nodes so that the time-integrated burnup $\\int_{t_n}^{t_{n+1}} q(\\mathbf{r},t)\\,\\mathrm{d}t$ is equal in every node, thereby ensuring uniform depletion and preserving shape normalization by construction.",
            "solution": "## Problem Validation\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n- **Domain:** A three-dimensional domain with spatial coordinates denoted by $\\mathbf{r}$.\n- **Neutron Scalar Flux:** $\\phi(\\mathbf{r},t)$.\n- **Macroscopic Fission Cross Section:** $\\Sigma_f(\\mathbf{r},t)$, which depends on nuclide number densities.\n- **Local Thermal Power Density:** $q(\\mathbf{r},t)=\\kappa\\,\\Sigma_f(\\mathbf{r},t)\\,\\phi(\\mathbf{r},t)$, where $\\kappa$ is the mean energy released per fission multiplied by a unit conversion factor.\n- **Total Reactor Power:** $P_{\\mathrm{tot}}(t)=\\int_V q(\\mathbf{r},t)\\,\\mathrm{d}V$.\n- **Operational Constraint:** $P_{\\mathrm{tot}}(t)$ is held constant at $P_0$ during the time interval $[t_n,t_{n+1}]$.\n- **Depletion Equation:** The evolution of nuclide number densities $\\{N_j(\\mathbf{r},t)\\}$ is given by the system of ODEs:\n$$\n\\frac{\\partial N_j(\\mathbf{r},t)}{\\partial t}=\\sum_{k} \\lambda_{k\\to j} N_k(\\mathbf{r},t) - \\lambda_j N_j(\\mathbf{r},t) - \\sum_{r} \\sigma_{r,j}(\\mathbf{r},t)\\,\\phi(\\mathbf{r},t)\\,N_j(\\mathbf{r},t)\n$$\n- **Flux Approximation:** Over a small time step $\\Delta t = t_{n+1} - t_n$, the flux is approximated as a product of a scalar normalization $C(t)$ and a shape function $s(\\mathbf{r},t)$: $\\phi(\\mathbf{r},t)\\approx C(t)\\,s(\\mathbf{r},t)$.\n- **Initial Condition at $t_n$:** The flux shape $s_n(\\mathbf{r})$ is known and normalized such that $\\int_V s_n(\\mathbf{r})\\,\\mathrm{d}V=1$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scrutinized against the validation criteria.\n\n- **Scientifically Grounded:** The problem is firmly based on the standard model of nuclear reactor physics. The definition of power density, the total power integral, the Bateman equations for nuclide depletion, and the quasi-static approximation of separating neutron flux into a magnitude and shape component are all fundamental and universally accepted concepts in nuclear engineering and reactor analysis.\n- **Well-Posed:** The problem provides a clear physical and mathematical framework and asks for the identification of a consistent numerical algorithm (predictor-corrector) to solve the coupled system. The goal is well-defined: maintain a constant total power while accurately modeling the spatially-dependent depletion. A unique conceptual answer is expected.\n- **Objective:** The terminology is precise and standard within the field of reactor physics. The equations are presented in their conventional form. The problem is free of subjective or ambiguous language.\n- **Completeness and Consistency:** The problem provides all necessary elements to understand the coupling between neutronics (flux shape and magnitude) and depletion (material composition changes). The feedback loop is implicitly defined: $\\phi \\rightarrow N_j \\rightarrow \\Sigma_f \\rightarrow \\phi$. The constraint of constant total power is explicitly stated. The setup is internally consistent and sufficient for a conceptual analysis of numerical methods.\n- **Realism:** The scenario describes a standard operational mode (constant power) and a standard computational challenge in fuel cycle analysis. While a simplification of a real reactor, the model captures the essential physics and is not unrealistic or infeasible.\n\n### Step 3: Verdict and Action\nThe problem statement is scientifically sound, well-posed, objective, and internally consistent. It presents a valid and standard problem from the field of computational reactor physics. Therefore, the problem is **valid**, and I will proceed with a full solution.\n\n## Solution Derivation\n\nThe core of the problem lies in the coupling between the neutron flux $\\phi(\\mathbf{r},t)$ and the nuclide number densities $N_j(\\mathbf{r},t)$. The depletion equation,\n$$\n\\frac{\\partial N_j}{\\partial t} = \\dots - \\sigma_{r,j}\\phi N_j\n$$\nshows that the rate of change of nuclide concentrations at a specific location $\\mathbf{r}$ is directly proportional to the local neutron flux $\\phi(\\mathbf{r},t)$. Higher flux leads to faster transmutation and burnup of materials.\n\nThe material composition, represented by the set of all $\\{N_j(\\mathbf{r},t)\\}$, determines the macroscopic cross sections, including the fission cross section:\n$$\n\\Sigma_f(\\mathbf{r},t) = \\sum_j N_j(\\mathbf{r},t) \\sigma_{f,j}\n$$\nwhere $\\sigma_{f,j}$ is the microscopic fission cross section for nuclide $j$.\n\nThe neutron flux distribution $\\phi(\\mathbf{r},t)$ itself is the solution to the neutron transport (or diffusion) equation, whose coefficients are the macroscopic cross sections. Therefore, as nuclide densities change due to depletion, the cross sections change, which in turn alters the shape and magnitude of the equilibrium flux distribution.\n\nThe problem imposes a constraint of constant total power, $P_0$. Using the flux separation approximation $\\phi(\\mathbf{r},t) \\approx C(t)s(\\mathbf{r},t)$, the power constraint becomes:\n$$\nP_0 = \\int_V \\kappa\\,\\Sigma_f(\\mathbf{r},t)\\,C(t)s(\\mathbf{r},t)\\,\\mathrm{d}V\n$$\nThis allows us to determine the normalization factor $C(t)$:\n$$\nC(t) = \\frac{P_0}{\\int_V \\kappa\\,\\Sigma_f(\\mathbf{r},t)\\,s(\\mathbf{r},t)\\,\\mathrm{d}V}\n$$\nAs both $\\Sigma_f(\\mathbf{r},t)$ and the flux shape $s(\\mathbf{r},t)$ evolve during the time step $[t_n, t_{n+1}]$, the normalization $C(t)$ must also be adjusted to maintain $P_0$. A simple \"explicit\" method that uses the flux $\\phi(\\mathbf{r},t_n)$ for the entire step is prone to significant error, as it ignores this evolution.\n\nA predictor-corrector method addresses this by:\n1.  **Predictor Step:** Estimate the state at the end of the step, $t_{n+1}$, using information from the beginning of the step, $t_n$. A common approach is to assume the flux remains constant over the step, $\\phi(\\mathbf{r},t) \\approx \\phi(\\mathbf{r},t_n)$.\n2.  **Corrector Step:** Use the predicted end-of-step state to form a better approximation of the behavior *within* the step (e.g., by averaging beginning and end states) and then re-calculate the final state with this improved approximation.\n\nLet us now evaluate the options based on these principles.\n\n### Option-by-Option Analysis\n\n**A. Model the flux as $\\phi(\\mathbf{r},t)\\approx C(t)\\,s_n(\\mathbf{r})$ in the predictor, where $C_{\\mathrm{pred}}$ is chosen to satisfy $P_0=\\int_V \\kappa\\,\\Sigma_f^n(\\mathbf{r})\\,s_n(\\mathbf{r})\\,C_{\\mathrm{pred}}\\,\\mathrm{d}V$ using beginning-of-step compositions. Integrate the depletion ODEs over $\\Delta t$ to obtain predicted number densities $\\{N_j^{\\mathrm{pred}}(\\mathbf{r})\\}$. In the corrector, recompute the flux shape $s_{n+1}(\\mathbf{r})$ and cross sections $\\Sigma_f^{n+1}(\\mathbf{r})$ from neutronics with $\\{N_j^{\\mathrm{pred}}(\\mathbf{r})\\}$, and determine $C_{\\mathrm{corr}}$ from $P_0=\\int_V \\kappa\\,\\Sigma_f^{n+1}(\\mathbf{r})\\,s_{n+1}(\\mathbf{r})\\,C_{\\mathrm{corr}}\\,\\mathrm{d}V$. Reintegrate the depletion ODEs over $\\Delta t$ using trapezoidal averages $s_{\\mathrm{avg}}(\\mathbf{r})$ proportional to $s_n(\\mathbf{r})+s_{n+1}(\\mathbf{r})$ and $C_{\\mathrm{avg}}=(C_{\\mathrm{pred}}+C_{\\mathrm{corr}})/2$, ensuring $P_0=\\int_V \\kappa\\,\\overline{\\Sigma_f}(\\mathbf{r})\\,s_{\\mathrm{avg}}(\\mathbf{r})\\,C_{\\mathrm{avg}}\\,\\mathrm{d}V$, with $\\overline{\\Sigma_f}$ an appropriate average over the step. This couples axial/radial power shape to local reaction rates and maintains shape-consistent normalization.**\n\nThis option describes a scientifically rigorous predictor-corrector scheme.\n- **Predictor:** It correctly uses the beginning-of-step (BOS) flux shape $s_n$ and calculates the normalization $C_{\\mathrm{pred}}$ to satisfy the power constraint $P_0$ with BOS compositions $\\Sigma_f^n$. It then solves the depletion equations to get a first estimate of the end-of-step (EOS) nuclide densities $N_j^{\\mathrm{pred}}$. This is a standard explicit Euler or first-order predictor.\n- **Corrector:** It correctly uses the predicted densities $N_j^{\\mathrm{pred}}$ to update the cross sections to $\\Sigma_f^{n+1}$ and then performs a new neutronics calculation to find the updated EOS flux shape $s_{n+1}$. This directly accounts for the feedback of depletion on the flux shape. It also calculates a new normalization $C_{\\mathrm{corr}}$ consistent with the EOS state. Finally, it performs the depletion calculation again using an average flux representation (combining BOS and EOS information, characteristic of a trapezoidal or second-order method), which provides a more accurate solution for the final EOS densities. This entire process correctly couples the spatial power distribution to local depletion rates and maintains consistency with the macroscopic power constraint.\nThe verdict is **Correct**.\n\n**B. Hold the flux shape fixed at $s_n(\\mathbf{r})$ over $[t_n,t_{n+1}]$, and at each substep choose $C(t)$ such that $\\max_{\\mathbf{r}\\in V} q(\\mathbf{r},t)$ equals its value at $t_n$. This ensures the hottest node does not change power, which stabilizes depletion locally regardless of changes in $\\Sigma_f(\\mathbf{r},t)$.**\n\nThis option has two major flaws. First, it proposes a method that only \"holds the flux shape fixed\", which is an explicit, first-order method, not a predictor-corrector one. It fails to update the flux shape based on changing material compositions. Second, and more critically, it uses an incorrect operational constraint. The problem states the *total* power $\\int_V q(\\mathbf{r},t)\\,\\mathrm{d}V$ is constant, not the *peak* power density $\\max_{\\mathbf{r}\\in V} q(\\mathbf{r},t)$. In a reactor operating at constant total power, the power shape flattens over time, meaning the peak power density typically decreases. This option describes a physically incorrect operational mode.\nThe verdict is **Incorrect**.\n\n**C. Use predictor–corrector iterations to update $s(\\mathbf{r},t)$, but normalize the flux by enforcing a constant total neutron flux $\\int_V \\phi(\\mathbf{r},t)\\,\\mathrm{d}V$, since this guarantees the reaction-rate integral remains unchanged even as $\\Sigma_f(\\mathbf{r},t)$ evolves.**\n\nThis option proposes an incorrect normalization constraint. The problem explicitly states that the constant quantity is the total power $P_0 = \\int_V \\kappa\\,\\Sigma_f(\\mathbf{r},t)\\,\\phi(\\mathbf{r},t)\\,\\mathrm{d}V$. As fuel is burned, the macroscopic fission cross section $\\Sigma_f(\\mathbf{r},t)$ generally decreases throughout the core. To maintain constant power, the flux level $\\phi(\\mathbf{r},t)$ must increase. Therefore, the total neutron flux $\\int_V \\phi(\\mathbf{r},t)\\,\\mathrm{d}V$ is not constant but typically increases over the fuel cycle. The premise of this option is physically false.\nThe verdict is **Incorrect**.\n\n**D. Replace spatially resolved depletion with a single-volume model in which $N_j(\\mathbf{r},t)$ are volume-averaged and depleted uniformly using $P_0/V$. Predictor–corrector is unnecessary because axial/radial shape does not influence the uniform burnup imposed by constant total power.**\n\nThis option is a direct evasion of the problem. The question is specifically about how *spatial variations* influence local depletion. By proposing a single-volume (or \"point\") model, this option discards all spatial information from the outset. In such a model, there is no flux shape $s(\\mathbf{r},t)$ to speak of, and thus no way to analyze its influence on depletion. This approach is fundamentally incapable of addressing the question posed. While predictor-corrector methods can still be useful in point models to handle non-linearities, the reasoning provided here is flawed and misses the entire point of the problem.\nThe verdict is **Incorrect**.\n\n**E. In the predictor step, use $\\phi(\\mathbf{r},t)\\approx C(t)\\,s_n(\\mathbf{r})$ with $C(t)$ from $P_0$; in the corrector step, redistribute $C(t)$ among nodes so that the time-integrated burnup $\\int_{t_n}^{t_{n+1}} q(\\mathbf{r},t)\\,\\mathrm{d}t$ is equal in every node, thereby ensuring uniform depletion and preserving shape normalization by construction.**\n\nThe predictor step described is reasonable. However, the corrector step is physically impossible and nonsensical. The flux distribution in a reactor is governed by the neutron transport equation; it is a fundamental property of the system's geometry and material composition. It is inherently non-uniform. The idea of \"redistributing\" the flux to achieve uniform burnup (equal time-integrated power density everywhere) would require a flux shape that violates the governing physics. Such a procedure is not a \"corrector\" in the numerical sense; it is an arbitrary and unphysical manipulation of the system state. Uniform depletion is a fictional concept, not a computational goal for a realistic simulation.\nThe verdict is **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While global power distribution is a key operational parameter, safety margins are often dictated by the peak power density within individual fuel pins. This problem  tackles the practical challenge of \"pin power reconstruction,\" a method for obtaining high-fidelity local detail from coarse-mesh simulation results. You will explore how to design a computationally efficient data structure for representing power form functions that depend on both spatial coordinates and multiple physical parameters, learning to balance accuracy, memory, and evaluation speed using advanced approximation techniques.",
            "id": "4241011",
            "problem": "In high-fidelity pin power reconstruction, the transverse shape functions are represented as the separable product of a two-dimensional pin-wise radial form function and a one-dimensional axial form function. For each pin index $p$, define the two-dimensional radial form function $F_{p}^{xy}(x,y;\\mathbf{s})$ over the pin cross-section and the one-dimensional axial form function $F^{z}(z;\\mathbf{s})$ over the core height. Here $\\mathbf{s}\\in\\mathbb{R}^{d}$ is a state vector capturing local operating and material parameters (e.g., burnup, coolant density, fuel temperature, boron concentration, and control insertion fraction), with $d=5$. Assume:\n\n- The reconstructed local fission power density is $q_{p}(x,y,z;\\mathbf{s})=\\Phi_{p}^{\\mathrm{avg}}(\\mathbf{s})\\,F_{p}^{xy}(x,y;\\mathbf{s})\\,F^{z}(z;\\mathbf{s})$, where $\\Phi_{p}^{\\mathrm{avg}}(\\mathbf{s})$ is the pin-averaged quantity provided by a coarse-mesh solver.\n- Both $F_{p}^{xy}(x,y;\\mathbf{s})$ and $F^{z}(z;\\mathbf{s})$ are smooth in their spatial variables and analytic in $\\mathbf{s}$ within the operating envelope, consistent with the elliptic character of the multi-group diffusion operator and smooth parameter dependence of macroscopic cross sections.\n- The form functions are normalized so that $\\int_{\\text{pin}}F_{p}^{xy}(x,y;\\mathbf{s})\\,\\mathrm{d}A=1$ and $\\int_{0}^{H}F^{z}(z;\\mathbf{s})\\,\\mathrm{d}z=1$, where $H$ is the core height.\n\nYou must choose a data structure to store and evaluate $F_{p}^{xy}(x,y;\\mathbf{s})$ and $F^{z}(z;\\mathbf{s})$ subject to the following constraints:\n\n- The simulation has $P=50{,}000$ pins grouped into $T=10$ pin types with shared geometry and similar shapes; you may share data by pin type but not assume identity across all $\\mathbf{s}$.\n- The query workload is $Q=2\\times 10^{7}$ point evaluations per time step for various $(x,y,z)$ and $\\mathbf{s}$ values, with an accuracy target of relative error $\\leq 10^{-3}$ in $L^{2}$ for both radial and axial shapes.\n- The memory budget for storing all form-function data is $1\\,\\mathrm{GB}$ in double precision (each double is $8$ bytes), and evaluation should be friendly to single-instruction multiple-data (SIMD) vectorization.\n- Evaluations must support gradients $\\nabla_{xy}F_{p}^{xy}(x,y;\\mathbf{s})$ and $\\partial_{z}F^{z}(z;\\mathbf{s})$ at negligible extra cost compared to the function value.\n\nStarting from the governing properties of the diffusion operator (smooth spatial and parametric dependence and absence of internal discontinuities within a pin), and standard notions of function approximation complexity, choose the most appropriate data structure from the options below and justify your choice in terms of memory complexity and interpolation/evaluation speed. Treat $F_{p}^{xy}(x,y;\\mathbf{s})$ and $F^{z}(z;\\mathbf{s})$ separately if appropriate, but ensure the overall design meets the constraints.\n\nA. Use a separable low-rank representation across the state vector via Proper Orthogonal Decomposition (POD): for each pin type, represent $F_{p}^{xy}(x,y;\\mathbf{s})\\approx\\sum_{k=1}^{r}a_{p,k}(\\mathbf{s})\\,\\phi_{k}^{xy}(x,y)$, where each spatial mode $\\phi_{k}^{xy}$ is stored as a tensor-product Chebyshev expansion of orders $N_{x}=N_{y}=16$, and each coefficient map $a_{p,k}(\\mathbf{s})$ is stored using a Smolyak sparse grid in $d=5$ with level $\\ell=3$ hierarchical surpluses. For $F^{z}(z;\\mathbf{s})$, store a cubic Hermite spline with $M_{z}=32$ knots per pin type, and represent the knot values as $\\sum_{m=1}^{r_{z}}b_{m}(\\mathbf{s})\\,\\psi_{m}^{z}$ with $r_{z}=3$ and the $b_{m}(\\mathbf{s})$ on the same sparse grid. Evaluate using the Clenshaw algorithm and spline recurrence; gradients use derivative recurrences at negligible extra cost.\n\nB. For each pin, store raw nodal tables: a uniform $64\\times 64$ grid of $F_{p}^{xy}$ values over $(x,y)$ for each point of a full tensor state grid with $8$ nodes per state dimension (total $8^{5}$ states), interpolated bilinearly in $(x,y)$ and multilinearly in $\\mathbf{s}$. For $F^{z}$, store $128$ uniformly spaced samples per state grid point with linear interpolation in $z$.\n\nC. For each pin type, build an adaptive quadtree over $(x,y)$ for each distinct state sample in a training set; store piecewise linear segments per leaf, and use nearest-neighbor lookup in $\\mathbf{s}$. For $F^{z}$, store an adaptive piecewise linear partition with state-dependent breakpoints. Evaluation traverses the tree per query.\n\nD. For each pin type, store a full tensor-product cubic B-spline over $(x,y,\\mathbf{s})$ with $K_{x}=K_{y}=21$ spatial knots and $K_{s}=6$ knots per state dimension in $d=5$ (uniform knots), with standard spline coefficients. For $F^{z}$, store a separate cubic B-spline with $64$ knots in $z$ and $6$ knots per state dimension. Evaluation uses local B-spline basis functions; gradients obtained by differentiating basis polynomials.\n\nWhich option best satisfies the smoothness-informed approximation properties, the memory budget, and the evaluation speed constraints, and why? Select the single best option.",
            "solution": "The problem asks for an evaluation of four distinct data structures for representing pin-wise fission power form functions in a nuclear reactor simulation. The choice must satisfy stringent constraints on memory, evaluation speed, accuracy, and support for gradients, while being consistent with the physical properties of the underlying neutron diffusion equation.\n\nThe core of the problem is to approximate two functions: a radial form function $F_{p}^{xy}(x,y;\\mathbf{s})$ and an axial form function $F^{z}(z;\\mathbf{s})$. These functions are known to be smooth in their spatial variables $(x,y,z)$ and analytic in the state-parameter vector $\\mathbf{s} \\in \\mathbb{R}^{5}$. We must select the best representation from the given options, considering all constraints.\n\nThe constraints are as follows:\n- Number of pins, $P = 50,000$.\n- Number of pin types, $T = 10$.\n- State vector dimension, $d = 5$.\n- Memory budget: $1\\,\\mathrm{GB}$, which is $1 \\times 1024^3 \\text{ bytes} / (8 \\text{ bytes/double}) = 134,217,728$ doubles.\n- Accuracy: Relative $L^2$ error $\\leq 10^{-3}$.\n- Evaluation: Must be fast, SIMD-friendly, and provide spatial gradients at negligible extra cost.\n\nWe will now analyze each option.\n\n### Option-by-Option Analysis\n\n**Option A: Separable Low-Rank (POD) + Chebyshev + Sparse Grid**\n\nThis option proposes a sophisticated, multi-level hierarchical approximation.\n\n- **Radial Function, $F_{p}^{xy}(x,y;\\mathbf{s})$**: The representation is $F_{p}^{xy}(x,y;\\mathbf{s}) \\approx \\sum_{k=1}^{r} a_{p,k}(\\mathbf{s}) \\phi_{k}^{xy}(x,y)$. This separates spatial dependence (in $\\phi_{k}^{xy}$) from parametric dependence (in $a_{p,k}$).\n    - The spatial modes $\\phi_{k}^{xy}(x,y)$ are represented by tensor-product Chebyshev expansions of order $N_{x}=N_{y}=16$. For a smooth function, a Chebyshev expansion provides spectral accuracy (exponential convergence), which is ideal for meeting a tight error tolerance like $10^{-3}$ with a modest number of terms. The number of coefficients per mode is $(N_x+1)(N_y+1) = 17 \\times 17 = 289$. The modes are per pin type, so their storage is $T \\times r \\times 289$ doubles.\n    - The coefficient maps $a_{p,k}(\\mathbf{s})$ are defined per pin and depend on the state vector $\\mathbf{s}$. They are represented on a Smolyak sparse grid of dimension $d=5$ and level $\\ell=3$. Sparse grids are an advanced technique to combat the curse of dimensionality for smooth functions in moderate-to-high dimensions. The number of nodes for a level-$3$ sparse grid in $5$ dimensions (with Clenshaw-Curtis points) is $171$. Storing the hierarchical surpluses for each map requires $171$ doubles. Since these maps are pin-specific, this part of the storage is $P \\times r \\times 171$ doubles.\n- **Axial Function, $F^{z}(z;\\mathbf{s})$**: A cubic Hermite spline with $M_{z}=32$ knots is used for the spatial dependence. This provides $C^1$ continuity and efficient evaluation. The parametric dependence of the $2 \\times M_z = 64$ spline parameters (function values and derivatives at knots) is handled by another low-rank decomposition of rank $r_z=3$, with coefficients stored on the same sparse grid. This is per pin type. The memory footprint for this part is negligible: $T \\times (r_z \\times 64 + r_z \\times 171) = 10 \\times (3 \\times 64 + 3 \\times 171) = 7,050$ doubles.\n- **Memory Calculation**: The total memory is dominated by the pin-specific coefficients for the radial function: $M_{total} = (P \\times r \\times 171) + (T \\times r \\times 289) + 7,050 = r \\times (50,000 \\times 171 + 10 \\times 289) + 7,050 = r \\times (8,550,000 + 2,890) + 7,050 \\approx r \\times 8.55 \\times 10^6$ doubles. The rank $r$ is not specified, but it must be sufficient for the $10^{-3}$ accuracy. For POD representations of smooth parametric problems, a rank of $r \\in [10, 15]$ is typical. For $r=12$, the memory is approximately $12 \\times 8.55 \\times 10^6 \\approx 102.6 \\times 10^6$ doubles. This fits within the $134.2 \\times 10^6$ budget.\n- **Evaluation and Gradients**: Evaluation involves sparse grid interpolation, Chebyshev polynomial evaluation (via the Clenshaw algorithm), and a dot product. All these operations are computationally efficient and highly regular, making them amenable to SIMD vectorization. Crucially, the derivatives of Chebyshev polynomials and splines can be computed via recurrence relations at a cost comparable to the function evaluation itself, matching the \"negligible extra cost\" constraint.\n- **Conclusion for A**: This option is scientifically sound, leveraging advanced numerical methods (spectral methods, sparse grids, POD) that are optimally suited for the stated smoothness and analyticity properties. It satisfies all constraints, albeit with a tight but feasible memory budget dependent on the required POD rank.\n\n**Option B: Raw Nodal Tables**\n\nThis option proposes a simple lookup table with multilinear interpolation.\n\n- **Memory Calculation**: The scheme requires storing a $64 \\times 64$ spatial grid for each of the $8^5$ state grid points. If stored per pin type, the memory for the radial function is $T \\times (64 \\times 64) \\times 8^5 = 10 \\times 4,096 \\times 32,768 = 1,342,177,280$ doubles. This is $1.34 \\times 10^9$ doubles, which is ten times the memory budget of $1.34 \\times 10^8$ doubles. This calculation is for the radial function alone. The axial function adds even more. If the data were stored per pin, the memory requirement would be absurdly large ($P$ times larger). The use of a full tensor product grid in the $d=5$ state space suffers from the curse of dimensionality, which this calculation clearly demonstrates.\n- **Evaluation and Gradients**: Interpolation is fast, but the gradient approximation is poor. Multilinear interpolation yields piecewise constant gradients, which cannot accurately represent the gradients of a smooth function.\n- **Conclusion for B**: This option fails catastrophically on the memory constraint. It is a brute-force method that does not scale to a $5$-dimensional parameter space.\n\n**Option C: Adaptive Quadtree + Nearest Neighbor**\n\nThis option uses an adaptive spatial grid but a very crude parametric representation.\n\n- **Approximation Quality**: The use of nearest-neighbor lookup in the state space $\\mathbf{s}$ results in a piecewise-constant approximation of the form function's dependence on parameters. This is fundamentally unsuitable for an analytic function, as it introduces artificial discontinuities and provides zero-order accuracy in $\\mathbf{s}$. To meet the $10^{-3}$ error target, an extremely dense set of training samples in the state space would be required, leading to a massive memory footprint.\n- **Evaluation and Gradients**: Evaluation involves a nearest-neighbor search, which is slow for large datasets, followed by quadtree traversal. Tree traversal involves pointer-chasing and is notoriously difficult to optimize with SIMD. The spatial gradient is piecewise constant within each leaf of the quadtree, offering poor accuracy. The gradient with respect to state parameters, $\\nabla_{\\mathbf{s}}F$, is zero everywhere except at the boundaries between nearest-neighbor regions, where it is undefined. This fails the gradient requirement completely.\n- **Conclusion for C**: This option is fundamentally flawed in its treatment of the state-space dependence and is unsuitable for SIMD or for providing accurate gradients.\n\n**Option D: Full Tensor Product B-Spline**\n\nThis option uses B-splines for both spatial and parametric dimensions in a full tensor product structure.\n\n- **Memory Calculation**:\n    - For $F^{xy}$, the number of coefficients per pin type is the product of the number of basis functions in each of the $7$ dimensions ($x, y, s_1, ..., s_5$). For cubic splines ($p=3$), the number of basis functions is typically (\\#intervals + degree). With $K_x=K_y=21$ knots, we have $20$ intervals, so $23$ basis functions. With $K_s=6$ knots, we have $5$ intervals, so $8$ basis functions. The total coefficients per type are $23 \\times 23 \\times 8^5 = 529 \\times 32,768 = 17,332,288$. For $T=10$ types, this is $173,322,880$ doubles.\n    - For $F^z$, the coefficients per type are $(64-1+3) \\times 8^5 = 66 \\times 32,768 \\approx 2.16 \\times 10^6$. For $T=10$ types, this is $21.6 \\times 10^6$ doubles.\n    - The total memory is approximately $173.3 \\times 10^6 + 21.6 \\times 10^6 = 194.9 \\times 10^6$ doubles. This exceeds the budget of $134.2 \\times 10^6$ doubles by over $45\\%$.\n- **Evaluation and Gradients**: B-splines have excellent properties. They provide $C^2$ smoothness, evaluation is fast due to local support, and gradients are easily and cheaply computed by differentiating the spline basis. This part of the proposal is strong.\n- **Conclusion for D**: While B-splines are a good choice for approximating smooth functions, this option's reliance on a full tensor product over the $5$-dimensional state space makes it too memory-intensive, similar to Option B. It fails the memory constraint.\n\n### Final Verdict\n\nComparing the four options:\n- **Option A** is the only one that satisfies all constraints. It employs a hierarchy of advanced, modern numerical methods that are specifically designed to handle the characteristics of the problem: smoothness (Chebyshev), high-dimensionality (sparse grids), and separability (POD).\n- **Option B** and **Option D** fail due to the curse of dimensionality, leading to excessive memory consumption by using full tensor product grids in the state space.\n- **Option C** fails fundamentally by using a piecewise-constant approximation (nearest neighbor) for an analytic function and by using a data structure (tree) that is not conducive to high-performance computing.\n\nTherefore, Option A represents the most sophisticated and appropriate design, balancing accuracy, memory, and computational performance in a manner consistent with best practices in computational science.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}