{
    "hands_on_practices": [
        {
            "introduction": "To truly understand a numerical method, we must first analyze its accuracy from a theoretical standpoint. This foundational exercise guides you through a pen-and-paper derivation to quantify the local truncation error of a common second-order predictor-corrector scheme. By comparing the method's Taylor series expansion to that of the exact solution, you will isolate the leading-order error term, providing direct insight into why this method is considered second-order accurate .",
            "id": "4241718",
            "problem": "Consider a linearized depletion system under constant neutron flux over a single time step, represented by the ordinary differential equation (ODE) $\\dot{\\mathbf{N}}(t) = \\mathbf{A}\\,\\mathbf{N}(t) + \\mathbf{b}$, where $\\mathbf{N}(t)$ is the nuclide density vector, $\\mathbf{A}$ is a constant matrix over the step, and $\\mathbf{b}$ is a constant vector over the step. Assume $\\mathbf{A}$ is invertible. Let $t_{n}$ denote the current time, $t_{n+1} = t_{n} + h$ the next time, and $\\mathbf{N}_{n} = \\mathbf{N}(t_{n})$. Starting from fundamental ODE theory and definitions of the matrix exponential, derive the exact one-step update for $\\mathbf{N}_{n+1} = \\mathbf{N}(t_{n+1})$, and express the inhomogeneous contribution in closed form using only $\\mathbf{A}$, $\\mathbf{b}$, and the matrix exponential.\n\nNext, apply a second-order explicit predictor-corrector (PC) method, specifically the two-stage explicit trapezoidal rule (also known as Heun’s method), defined by the predictor $\\mathbf{N}^{\\mathrm{p}} = \\mathbf{N}_{n} + h\\,\\mathbf{f}(\\mathbf{N}_{n})$ and the corrector $\\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\mathbf{N}_{n} + \\frac{h}{2}\\left[\\mathbf{f}(\\mathbf{N}_{n}) + \\mathbf{f}(\\mathbf{N}^{\\mathrm{p}})\\right]$, where $\\mathbf{f}(\\mathbf{N}) = \\mathbf{A}\\mathbf{N} + \\mathbf{b}$. Using a Taylor expansion about $t_{n}$ and keeping terms consistently to the first nonvanishing order beyond the method’s nominal order, determine the leading-order coefficient (the vector multiplying $h^{3}$) in the local truncation error, defined as $\\mathbf{N}(t_{n+1}) - \\mathbf{N}_{n+1}^{\\mathrm{PC}}$ when the method is initialized with the exact $\\mathbf{N}_{n}$.\n\nProvide as your final answer the simplified closed-form expression for this $h^{3}$ coefficient in terms of $\\mathbf{A}$, $\\mathbf{b}$, and $\\mathbf{N}_{n}$. No numerical evaluation is required. The final answer must be a single closed-form analytic expression.",
            "solution": "The user has provided a valid, well-posed problem from the field of numerical analysis as applied to nuclear engineering simulations. The problem is divided into two parts: first, to derive the exact one-step solution for a linear ordinary differential equation (ODE) system, and second, to determine the leading-order local truncation error for a specific predictor-corrector method applied to this system.\n\nThe system is described by the ODE:\n$$ \\dot{\\mathbf{N}}(t) = \\mathbf{A}\\,\\mathbf{N}(t) + \\mathbf{b} $$\nwhere $\\mathbf{N}(t)$ is the vector of nuclide densities, $\\mathbf{A}$ is a constant, invertible matrix, and $\\mathbf{b}$ is a constant vector over a time step of length $h$. The initial condition at time $t_n$ is $\\mathbf{N}(t_n) = \\mathbf{N}_n$.\n\n**Part 1: Derivation of the Exact Solution**\n\nThe given ODE is a first-order linear inhomogeneous system with constant coefficients. We can solve it using an integrating factor. Let the integrating factor be $\\exp(-\\mathbf{A}t)$. Multiplying the ODE, rewritten as $\\dot{\\mathbf{N}}(t) - \\mathbf{A}\\mathbf{N}(t) = \\mathbf{b}$, by the integrating factor gives:\n$$ \\exp(-\\mathbf{A}t)\\dot{\\mathbf{N}}(t) - \\exp(-\\mathbf{A}t)\\mathbf{A}\\mathbf{N}(t) = \\exp(-\\mathbf{A}t)\\mathbf{b} $$\nThe left-hand side is the result of the product rule for differentiation applied to $\\exp(-\\mathbf{A}t)\\mathbf{N}(t)$:\n$$ \\frac{d}{dt}\\left[\\exp(-\\mathbf{A}t)\\mathbf{N}(t)\\right] = \\exp(-\\mathbf{A}t)\\mathbf{b} $$\nWe integrate this equation over the time interval $[t_n, t_{n+1}]$, where $t_{n+1} = t_n + h$:\n$$ \\int_{t_n}^{t_{n+1}} \\frac{d}{d\\tau}\\left[\\exp(-\\mathbf{A}\\tau)\\mathbf{N}(\\tau)\\right] d\\tau = \\int_{t_n}^{t_{n+1}} \\exp(-\\mathbf{A}\\tau)\\mathbf{b} \\, d\\tau $$\n$$ \\left[\\exp(-\\mathbf{A}\\tau)\\mathbf{N}(\\tau)\\right]_{t_n}^{t_{n+1}} = \\left(\\int_{t_n}^{t_{n+1}} \\exp(-\\mathbf{A}\\tau) \\, d\\tau\\right) \\mathbf{b} $$\n$$ \\exp(-\\mathbf{A}t_{n+1})\\mathbf{N}(t_{n+1}) - \\exp(-\\mathbf{A}t_n)\\mathbf{N}_n = \\left(\\int_{t_n}^{t_{n+1}} \\exp(-\\mathbf{A}\\tau) \\, d\\tau\\right) \\mathbf{b} $$\nSince $\\mathbf{A}$ is a constant and invertible matrix, we can evaluate the integral:\n$$ \\int_{t_n}^{t_{n+1}} \\exp(-\\mathbf{A}\\tau) \\, d\\tau = \\left[-\\mathbf{A}^{-1}\\exp(-\\mathbf{A}\\tau)\\right]_{t_n}^{t_{n+1}} = -\\mathbf{A}^{-1}\\left(\\exp(-\\mathbf{A}t_{n+1}) - \\exp(-\\mathbf{A}t_n)\\right) $$\nSubstituting this back into the integrated equation:\n$$ \\exp(-\\mathbf{A}t_{n+1})\\mathbf{N}(t_{n+1}) - \\exp(-\\mathbf{A}t_n)\\mathbf{N}_n = -\\mathbf{A}^{-1}\\left(\\exp(-\\mathbf{A}t_{n+1}) - \\exp(-\\mathbf{A}t_n)\\right)\\mathbf{b} $$\nTo solve for $\\mathbf{N}(t_{n+1})$, we multiply the entire equation from the left by $\\exp(\\mathbf{A}t_{n+1})$:\n$$ \\mathbf{N}(t_{n+1}) - \\exp(\\mathbf{A}(t_{n+1}-t_n))\\mathbf{N}_n = -\\exp(\\mathbf{A}t_{n+1})\\mathbf{A}^{-1}\\left(\\exp(-\\mathbf{A}t_{n+1}) - \\exp(-\\mathbf{A}t_n)\\right)\\mathbf{b} $$\nUsing the fact that a matrix commutes with its inverse and its exponential, and defining $h = t_{n+1} - t_n$:\n$$ \\mathbf{N}(t_{n+1}) - \\exp(\\mathbf{A}h)\\mathbf{N}_n = -\\mathbf{A}^{-1}\\left(\\exp(\\mathbf{A}t_{n+1})\\exp(-\\mathbf{A}t_{n+1}) - \\exp(\\mathbf{A}t_{n+1})\\exp(-\\mathbf{A}t_n)\\right)\\mathbf{b} $$\n$$ \\mathbf{N}(t_{n+1}) - \\exp(\\mathbf{A}h)\\mathbf{N}_n = -\\mathbf{A}^{-1}\\left(\\mathbf{I} - \\exp(\\mathbf{A}(t_{n+1}-t_n))\\right)\\mathbf{b} $$\n$$ \\mathbf{N}(t_{n+1}) = \\exp(\\mathbf{A}h)\\mathbf{N}_n + \\mathbf{A}^{-1}\\left(\\exp(\\mathbf{A}h) - \\mathbf{I}\\right)\\mathbf{b} $$\nThis is the exact solution for the one-step update. The inhomogeneous contribution is $\\mathbf{A}^{-1}(\\exp(\\mathbf{A}h) - \\mathbf{I})\\mathbf{b}$.\n\n**Part 2: Local Truncation Error Analysis**\n\nThe local truncation error is defined as $\\mathbf{N}(t_{n+1}) - \\mathbf{N}_{n+1}^{\\mathrm{PC}}$, where we assume $\\mathbf{N}(t_n)$ is exact.\n\nFirst, we expand the exact solution $\\mathbf{N}(t_{n+1})$ in a Taylor series about $t_n$:\n$$ \\mathbf{N}(t_{n+1}) = \\mathbf{N}(t_n+h) = \\mathbf{N}_n + h\\dot{\\mathbf{N}}_n + \\frac{h^2}{2!}\\ddot{\\mathbf{N}}_n + \\frac{h^3}{3!}\\dddot{\\mathbf{N}}_n + O(h^4) $$\nThe derivatives evaluated at $t_n$ are:\n$$ \\dot{\\mathbf{N}}_n = \\mathbf{A}\\mathbf{N}_n + \\mathbf{b} $$\n$$ \\ddot{\\mathbf{N}}_n = \\frac{d}{dt}\\left(\\mathbf{A}\\mathbf{N}(t) + \\mathbf{b}\\right)\\bigg|_{t=t_n} = \\mathbf{A}\\dot{\\mathbf{N}}_n = \\mathbf{A}(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) = \\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b} $$\n$$ \\dddot{\\mathbf{N}}_n = \\frac{d}{dt}\\left(\\mathbf{A}^2\\mathbf{N}(t) + \\mathbf{A}\\mathbf{b}\\right)\\bigg|_{t=t_n} = \\mathbf{A}^2\\dot{\\mathbf{N}}_n = \\mathbf{A}^2(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) = \\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b} $$\nSubstituting these into the Taylor series:\n$$ \\mathbf{N}(t_{n+1}) = \\mathbf{N}_n + h\\left(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}\\right) + \\frac{h^2}{2}\\left(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}\\right) + \\frac{h^3}{6}\\left(\\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b}\\right) + O(h^4) $$\n\nNext, we determine the expression for the numerical solution $\\mathbf{N}_{n+1}^{\\mathrm{PC}}$ from the two-stage explicit trapezoidal rule (Heun's method). The right-hand side function is $\\mathbf{f}(\\mathbf{N}) = \\mathbf{A}\\mathbf{N} + \\mathbf{b}$.\n\nPredictor step:\n$$ \\mathbf{N}^{\\mathrm{p}} = \\mathbf{N}_n + h\\,\\mathbf{f}(\\mathbf{N}_n) = \\mathbf{N}_n + h(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) $$\nCorrector step:\n$$ \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\mathbf{N}_n + \\frac{h}{2}\\left[\\mathbf{f}(\\mathbf{N}_n) + \\mathbf{f}(\\mathbf{N}^{\\mathrm{p}})\\right] $$\nWe need to evaluate $\\mathbf{f}$ at the predictor value $\\mathbf{N}^{\\mathrm{p}}$:\n$$ \\mathbf{f}(\\mathbf{N}^{\\mathrm{p}}) = \\mathbf{A}\\mathbf{N}^{\\mathrm{p}} + \\mathbf{b} = \\mathbf{A}\\left[\\mathbf{N}_n + h(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b})\\right] + \\mathbf{b} $$\n$$ \\mathbf{f}(\\mathbf{N}^{\\mathrm{p}}) = \\mathbf{A}\\mathbf{N}_n + h\\mathbf{A}^2\\mathbf{N}_n + h\\mathbf{A}\\mathbf{b} + \\mathbf{b} = (\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + h(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}) $$\nSubstituting $\\mathbf{f}(\\mathbf{N}_n)$ and $\\mathbf{f}(\\mathbf{N}^{\\mathrm{p}})$ into the corrector formula:\n$$ \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\mathbf{N}_n + \\frac{h}{2}\\left[ (\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + \\left((\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + h(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b})\\right) \\right] $$\n$$ \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\mathbf{N}_n + \\frac{h}{2}\\left[ 2(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + h(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}) \\right] $$\n$$ \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\mathbf{N}_n + h(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + \\frac{h^2}{2}(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}) $$\n\nFinally, we find the local truncation error by subtracting the numerical solution from the exact Taylor series expansion:\n$$ \\mathbf{N}(t_{n+1}) - \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\left( \\mathbf{N}_n + h(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + \\frac{h^2}{2}(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}) + \\frac{h^3}{6}(\\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b}) + O(h^4) \\right) $$\n$$ - \\left( \\mathbf{N}_n + h(\\mathbf{A}\\mathbf{N}_n + \\mathbf{b}) + \\frac{h^2}{2}(\\mathbf{A}^2\\mathbf{N}_n + \\mathbf{A}\\mathbf{b}) \\right) $$\nThe terms of order $h^0$, $h^1$, and $h^2$ cancel out. The remaining leading-order term is:\n$$ \\mathbf{N}(t_{n+1}) - \\mathbf{N}_{n+1}^{\\mathrm{PC}} = \\frac{h^3}{6}\\left(\\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b}\\right) + O(h^4) $$\nThe problem asks for the coefficient of the $h^3$ term in the local truncation error. This coefficient is the vector $\\frac{1}{6}(\\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b})$.",
            "answer": "$$\\boxed{\\frac{1}{6}\\left(\\mathbf{A}^3\\mathbf{N}_n + \\mathbf{A}^2\\mathbf{b}\\right)}$$"
        },
        {
            "introduction": "Theoretical analysis must be complemented by practical verification to ensure a correct implementation. This practice moves from theory to code, tasking you with implementing a predictor-corrector integrator and measuring its empirical convergence rate against a known analytic solution for a linear depletion chain . This process of code verification is a cornerstone of scientific computing, building confidence that your simulation tool behaves as mathematically intended.",
            "id": "4241745",
            "problem": "Consider a linear three-nuclide depletion chain in a nuclear reactor simulation with constant neutron flux. The chain is defined by nuclide $1$ decaying to nuclide $2$, which decays to nuclide $3$, and nuclide $3$ decaying to an out-of-chain sink. Each nuclide also undergoes neutron absorption that removes it from the chain but does not produce other nuclides. The governing ordinary differential equations (ODEs) are\n$$\n\\frac{d \\mathbf{n}(t)}{dt} = \\mathbf{A} \\, \\mathbf{n}(t),\n$$\nwhere $\\mathbf{n}(t) = [n_1(t), n_2(t), n_3(t)]^\\top$ are number densities (dimensionless number fractions), and the coefficient matrix $\\mathbf{A}$ is\n$$\n\\mathbf{A} =\n\\begin{bmatrix}\n-(\\lambda_1 + \\sigma_1 \\, \\phi) & 0 & 0 \\\\\n\\lambda_1 & -(\\lambda_2 + \\sigma_2 \\, \\phi) & 0 \\\\\n0 & \\lambda_2 & -(\\lambda_3 + \\sigma_3 \\, \\phi)\n\\end{bmatrix}.\n$$\nHere, $\\lambda_i$ are decay constants in $\\mathrm{s}^{-1}$, $\\sigma_i$ are absorption cross sections in $\\mathrm{cm}^2$, and $\\phi$ is the scalar neutron flux in $\\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$. The effective removal constants are $\\alpha_i = \\lambda_i + \\sigma_i \\, \\phi$ in $\\mathrm{s}^{-1}$. The chain is linear and time-invariant with a known analytic solution derived from the Bateman equations for distinct $\\alpha_i$. \n\nYour task is to:\n- Implement a predictor-corrector integrator (the explicit trapezoidal rule, also known as the second-order Heun method) for the ODE with coupling that uses beginning-of-step coefficients to predict end-of-step number densities and then corrects using end-of-step coefficients. In this linear constant-coefficient setting, this reduces to the classical explicit trapezoidal method for $\\mathbf{n}' = \\mathbf{A}\\mathbf{n}$. \n- Implement the analytic solution for the linear chain using Bateman’s formula with distinct $\\alpha_i$ (assume no degeneracy).\n- Define a verification test to measure the observed convergence rate of the predictor-corrector method by computing the numerical error at the final time $T$ for successively refined step sizes, and estimating the order $p$ via the relation $E(h) \\approx C h^p$, so that\n$$\np \\approx \\frac{\\log(E(h_1)) - \\log(E(h_2))}{\\log(h_1) - \\log(h_2)},\n$$\nwith $h_2 = h_1 / 2$. Use the Euclidean norm of the final-number-density error vector at time $T$ as $E(h)$.\n\nAll physical quantities must use the following units:\n- Time in $\\mathrm{s}$.\n- Decay constants in $\\mathrm{s}^{-1}$.\n- Absorption cross sections in $\\mathrm{cm}^2$.\n- Flux in $\\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$.\n- Number densities as dimensionless number fractions.\n\nImplement a program that, for each test case, computes the numerical solution at $T$ using the predictor-corrector method with three step counts $N_1$, $N_2$, and $N_3$, where $N_2 = 2N_1$ and $N_3 = 2N_2$; computes the corresponding errors $E(h_1)$, $E(h_2)$, $E(h_3)$; and returns the measured convergence rate by averaging the two pairwise estimates:\n$$\np_{12} = \\frac{\\log(E(h_1)) - \\log(E(h_2))}{\\log(h_1) - \\log(h_2)}, \\quad\np_{23} = \\frac{\\log(E(h_2)) - \\log(E(h_3))}{\\log(h_2) - \\log(h_3)}, \\quad\np = \\frac{p_{12} + p_{23}}{2}.\n$$\n\nUse the following test suite:\n\n- Test Case $1$ (pure decay chain, moderate rates):\n  - $\\lambda_1 = 0.1 \\ \\mathrm{s}^{-1}$, $\\lambda_2 = 0.05 \\ \\mathrm{s}^{-1}$, $\\lambda_3 = 0.0 \\ \\mathrm{s}^{-1}$.\n  - $\\sigma_1 = 0.0 \\ \\mathrm{cm}^2$, $\\sigma_2 = 0.0 \\ \\mathrm{cm}^2$, $\\sigma_3 = 0.0 \\ \\mathrm{cm}^2$.\n  - $\\phi = 0.0 \\ \\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$.\n  - Initial condition $\\mathbf{n}(0) = [1.0, 0.0, 0.0]^\\top$.\n  - Final time $T = 5.0 \\ \\mathrm{s}$.\n  - Step counts $(N_1, N_2, N_3) = (50, 100, 200)$.\n\n- Test Case $2$ (decay plus absorption, distinct initial composition):\n  - $\\lambda_1 = 0.05 \\ \\mathrm{s}^{-1}$, $\\lambda_2 = 0.02 \\ \\mathrm{s}^{-1}$, $\\lambda_3 = 0.01 \\ \\mathrm{s}^{-1}$.\n  - $\\sigma_1 = 3 \\times 10^{-24} \\ \\mathrm{cm}^2$, $\\sigma_2 = 4 \\times 10^{-24} \\ \\mathrm{cm}^2$, $\\sigma_3 = 2 \\times 10^{-24} \\ \\mathrm{cm}^2$.\n  - $\\phi = 1 \\times 10^{14} \\ \\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$.\n  - Initial condition $\\mathbf{n}(0) = [0.6, 0.4, 0.0]^\\top$.\n  - Final time $T = 10.0 \\ \\mathrm{s}$.\n  - Step counts $(N_1, N_2, N_3) = (50, 100, 200)$.\n\n- Test Case $3$ (stiff decay chain):\n  - $\\lambda_1 = 20.0 \\ \\mathrm{s}^{-1}$, $\\lambda_2 = 10.0 \\ \\mathrm{s}^{-1}$, $\\lambda_3 = 5.0 \\ \\mathrm{s}^{-1}$.\n  - $\\sigma_1 = 0.0 \\ \\mathrm{cm}^2$, $\\sigma_2 = 0.0 \\ \\mathrm{cm}^2$, $\\sigma_3 = 0.0 \\ \\mathrm{cm}^2$.\n  - $\\phi = 0.0 \\ \\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$.\n  - Initial condition $\\mathbf{n}(0) = [1.0, 0.0, 0.0]^\\top$.\n  - Final time $T = 0.5 \\ \\mathrm{s}$.\n  - Step counts $(N_1, N_2, N_3) = (50, 100, 200)$.\n\nYour program should produce a single line of output containing the measured convergence rates for the three test cases as a comma-separated list of floats enclosed in square brackets (e.g., \"[p1,p2,p3]\"). No other output should be produced. Express the final convergence rates as dimensionless floats (no units).",
            "solution": "The problem requires the verification of the convergence rate for a predictor-corrector numerical method applied to a linear system of ordinary differential equations (ODEs) modeling nuclide depletion. This involves implementing the numerical method, deriving and implementing the analytic solution, and then using these to compute the empirical order of convergence.\n\n### 1. Governing Equations and System Matrix\nThe time evolution of the nuclide number densities $\\mathbf{n}(t) = [n_1(t), n_2(t), n_3(t)]^\\top$ is described by the linear, constant-coefficient ODE system:\n$$\n\\frac{d \\mathbf{n}(t)}{dt} = \\mathbf{A} \\, \\mathbf{n}(t)\n$$\nThe system matrix $\\mathbf{A}$ is defined based on the decay constants $\\lambda_i$, absorption cross sections $\\sigma_i$, and the neutron flux $\\phi$. It is a lower triangular matrix given by:\n$$\n\\mathbf{A} =\n\\begin{bmatrix}\n-(\\lambda_1 + \\sigma_1 \\, \\phi) & 0 & 0 \\\\\n\\lambda_1 & -(\\lambda_2 + \\sigma_2 \\, \\phi) & 0 \\\\\n0 & \\lambda_2 & -(\\lambda_3 + \\sigma_3 \\, \\phi)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-\\alpha_1 & 0 & 0 \\\\\n\\lambda_1 & -\\alpha_2 & 0 \\\\\n0 & \\lambda_2 & -\\alpha_3\n\\end{bmatrix}\n$$\nwhere $\\alpha_i = \\lambda_i + \\sigma_i \\, \\phi$ is the total removal constant for nuclide $i$.\n\n### 2. Analytic Solution via Bateman Equations\nFor a linear chain with distinct removal constants $\\alpha_i$, the analytic solution can be found using the Bateman equations. The solution at time $t$ for an initial state $\\mathbf{n}(0)$ is found by summing the contributions from each initial nuclide concentration. For the given 3-nuclide system, the solution is:\n\n$n_1(t) = n_1(0) e^{-\\alpha_1 t}$\n\n$n_2(t) = n_1(0) \\frac{\\lambda_1}{\\alpha_2 - \\alpha_1} (e^{-\\alpha_1 t} - e^{-\\alpha_2 t}) + n_2(0) e^{-\\alpha_2 t}$\n\n$n_3(t) = n_1(0) \\lambda_1 \\lambda_2 \\left( \\frac{e^{-\\alpha_1 t}}{(\\alpha_2 - \\alpha_1)(\\alpha_3 - \\alpha_1)} + \\frac{e^{-\\alpha_2 t}}{(\\alpha_1 - \\alpha_2)(\\alpha_3 - \\alpha_2)} + \\frac{e^{-\\alpha_3 t}}{(\\alpha_1 - \\alpha_3)(\\alpha_2 - \\alpha_3)} \\right) + n_2(0) \\frac{\\lambda_2}{\\alpha_3 - \\alpha_2} (e^{-\\alpha_2 t} - e^{-\\alpha_3 t}) + n_3(0) e^{-\\alpha_3 t}$\n\nThese equations are valid under the problem's assumption that all $\\alpha_i$ are distinct.\n\n### 3. Numerical Method: Explicit Trapezoidal Rule (Heun's Method)\nThe problem specifies a predictor-corrector scheme. For a general ODE system $\\mathbf{y}'=\\mathbf{f}(t, \\mathbf{y})$, one step from $t_k$ to $t_{k+1}=t_k+h$ consists of:\n1.  **Predictor Step**: An explicit Euler step to find a preliminary value $\\mathbf{y}^*_{k+1}$ at the end of the interval.\n    $$\n    \\mathbf{y}^*_{k+1} = \\mathbf{y}_k + h \\mathbf{f}(t_k, \\mathbf{y}_k)\n    $$\n2.  **Corrector Step**: An implicit trapezoidal step using the predicted value to evaluate the function at the end of the interval, thus improving accuracy.\n    $$\n    \\mathbf{y}_{k+1} = \\mathbf{y}_k + \\frac{h}{2} \\left[ \\mathbf{f}(t_k, \\mathbf{y}_k) + \\mathbf{f}(t_{k+1}, \\mathbf{y}^*_{k+1}) \\right]\n    $$\nFor our specific linear system, $\\mathbf{f}(t, \\mathbf{n}) = \\mathbf{A}\\mathbf{n}$. The method simplifies as follows:\n1.  **Predictor**: $\\mathbf{n}^*_{k+1} = \\mathbf{n}_k + h (\\mathbf{A} \\mathbf{n}_k)$\n2.  **Corrector**: $\\mathbf{n}_{k+1} = \\mathbf{n}_k + \\frac{h}{2} (\\mathbf{A} \\mathbf{n}_k + \\mathbf{A} \\mathbf{n}^*_{k+1})$\n\nThe problem phrasing \"coupling that uses beginning-of-step coefficients\" for the prediction and \"end-of-step coefficients\" for the correction hints at scenarios where matrix $\\mathbf{A}$ might depend on $\\mathbf{n}$. In this problem, $\\mathbf{A}$ is constant, so \"end-of-step coefficients\" are evaluated using the predicted density but result in the same constant matrix $\\mathbf{A}$. The implementation thus corresponds to the standard second-order Heun's method for linear systems.\n\n### 4. Convergence Rate Verification\nThe theoretical order of convergence for Heun's method is $p=2$. To verify this empirically, we compute the error of the numerical solution for a sequence of decreasing step sizes. The error $E(h)$ at the final time $T$ for a step size $h$ is defined as the Euclidean norm of the difference between the numerical and analytic solutions:\n$$\nE(h) = \\|\\mathbf{n}_{\\text{numerical}}(T) - \\mathbf{n}_{\\text{analytic}}(T)\\|_2\n$$\nAssuming the error follows the relation $E(h) \\approx C h^p$, where $C$ is a constant, we can estimate $p$ using results from two different step sizes, $h_1$ and $h_2$:\n$$\np \\approx \\frac{\\log(E(h_1)) - \\log(E(h_2))}{\\log(h_1) - \\log(h_2)}\n$$\nGiven step counts $N_1$, $N_2=2N_1$, and $N_3=2N_2$, the corresponding step sizes are $h_1=T/N_1$, $h_2=T/N_2=h_1/2$, and $h_3=T/N_3=h_2/2$. The denominator simplifies: $\\log(h_1) - \\log(h_2) = \\log(h_1/h_2) = \\log(2)$. We compute two estimates for $p$:\n$$\np_{12} = \\frac{\\log(E(h_1)/E(h_2))}{\\log(2)}, \\quad p_{23} = \\frac{\\log(E(h_2)/E(h_3))}{\\log(2)}\n$$\nThe final reported convergence rate is the average of these two estimates: $p = (p_{12} + p_{23}) / 2$. An empirical value of $p \\approx 2.0$ would confirm the method's expected second-order accuracy.\n\n### 5. Implementation Strategy\nA Python program is structured to solve the problem:\n1.  A function `bateman_solution` implements the analytic formulas for $n_1(t)$, $n_2(t)$, and $n_3(t)$. It takes the physical parameters, initial conditions, and time $t$ as input.\n2.  A function `heun_solver` implements the predictor-corrector scheme. It iterates for a given number of steps, updating the density vector at each step.\n3.  The main function `solve` orchestrates the process for each test case. It:\n    a.  Sets up the parameters ($\\lambda_i, \\sigma_i, \\phi, \\mathbf{n}(0), T, N_k$).\n    b.  Constructs the matrix $\\mathbf{A}$.\n    c.  Calculates the exact solution at time $T$.\n    d.  Iterates through the specified step counts ($N_1, N_2, N_3$), calls `heun_solver` for each, and computes the error norm $E(h_k)$.\n    e.  Uses the collected errors to compute the average convergence rate $p$.\n    f.  Collects the rates from all test cases and prints them in the specified format.\nAll vector and matrix operations are performed using the `numpy` library.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bateman_solution(lambdas, alphas, n0, t):\n    \"\"\"\n    Computes the analytic solution for the 3-nuclide chain using Bateman's equations.\n    Assumes distinct alpha values.\n    \n    Args:\n        lambdas (list or np.ndarray): decay constants [lambda_1, lambda_2, lambda_3].\n        alphas (list or np.ndarray): effective removal constants [alpha_1, alpha_2, alpha_3].\n        n0 (np.ndarray): initial number densities [n1(0), n2(0), n3(0)].\n        t (float): time at which to evaluate the solution.\n\n    Returns:\n        np.ndarray: number density vector [n1(t), n2(t), n3(t)].\n    \"\"\"\n    l1, l2, _ = lambdas\n    a1, a2, a3 = alphas\n    n1_0, n2_0, n3_0 = n0\n\n    # These assertions confirm the problem constraint of distinct alphas\n    assert a1 != a2, \"alpha_1 and alpha_2 cannot be equal.\"\n    assert a1 != a3, \"alpha_1 and alpha_3 cannot be equal.\"\n    assert a2 != a3, \"alpha_2 and alpha_3 cannot be equal.\"\n\n    # Exponential terms\n    exp_a1t = np.exp(-a1 * t)\n    exp_a2t = np.exp(-a2 * t)\n    exp_a3t = np.exp(-a3 * t)\n\n    # --- n1(t) ---\n    n1_t = n1_0 * exp_a1t\n\n    # --- n2(t) ---\n    n2_t_from_n1_0 = n1_0 * l1 / (a2 - a1) * (exp_a1t - exp_a2t)\n    n2_t_from_n2_0 = n2_0 * exp_a2t\n    n2_t = n2_t_from_n1_0 + n2_t_from_n2_0\n\n    # --- n3(t) ---\n    # Contribution from n1(0)\n    c1 = 1.0 / ((a2 - a1) * (a3 - a1))\n    c2 = 1.0 / ((a1 - a2) * (a3 - a2))\n    c3 = 1.0 / ((a1 - a3) * (a2 - a3))\n    n3_t_from_n1_0 = n1_0 * l1 * l2 * (c1 * exp_a1t + c2 * exp_a2t + c3 * exp_a3t)\n    \n    # Contribution from n2(0)\n    if l2 > 0:\n        n3_t_from_n2_0 = n2_0 * l2 / (a3 - a2) * (exp_a2t - exp_a3t)\n    else:\n        n3_t_from_n2_0 = 0.0\n\n    # Contribution from n3(0)\n    n3_t_from_n3_0 = n3_0 * exp_a3t\n    \n    n3_t = n3_t_from_n1_0 + n3_t_from_n2_0 + n3_t_from_n3_0\n\n    return np.array([n1_t, n2_t, n3_t])\n\ndef heun_solver(A, n0, h, num_steps):\n    \"\"\"\n    Solves dn/dt = An using the explicit trapezoidal (Heun's) method.\n    \n    Args:\n        A (np.ndarray): The coefficient matrix.\n        n0 (np.ndarray): The initial number density vector.\n        h (float): The time step size.\n        num_steps (int): The number of time steps to take.\n\n    Returns:\n        np.ndarray: The numerical solution vector at the final time.\n    \"\"\"\n    n = np.copy(n0)\n    for _ in range(num_steps):\n        # Predictor step\n        k1 = A @ n\n        n_pred = n + h * k1\n        \n        # Corrector step\n        k2 = A @ n_pred\n        n = n + (h / 2.0) * (k1 + k2)\n    return n\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute convergence rates.\n    \"\"\"\n    test_cases = [\n        {\n            \"lambdas\": np.array([0.1, 0.05, 0.0]),\n            \"sigmas\": np.array([0.0, 0.0, 0.0]),\n            \"phi\": 0.0,\n            \"n0\": np.array([1.0, 0.0, 0.0]),\n            \"T\": 5.0,\n            \"Ns\": (50, 100, 200),\n        },\n        {\n            \"lambdas\": np.array([0.05, 0.02, 0.01]),\n            \"sigmas\": np.array([3e-24, 4e-24, 2e-24]),\n            \"phi\": 1e14,\n            \"n0\": np.array([0.6, 0.4, 0.0]),\n            \"T\": 10.0,\n            \"Ns\": (50, 100, 200),\n        },\n        {\n            \"lambdas\": np.array([20.0, 10.0, 5.0]),\n            \"sigmas\": np.array([0.0, 0.0, 0.0]),\n            \"phi\": 0.0,\n            \"n0\": np.array([1.0, 0.0, 0.0]),\n            \"T\": 0.5,\n            \"Ns\": (50, 100, 200),\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        lambdas = case[\"lambdas\"]\n        sigmas = case[\"sigmas\"]\n        phi = case[\"phi\"]\n        n0 = case[\"n0\"]\n        T = case[\"T\"]\n        Ns = case[\"Ns\"]\n\n        # Calculate effective removal constants and build the matrix A\n        alphas = lambdas + sigmas * phi\n        A = np.array([\n            [-alphas[0], 0, 0],\n            [lambdas[0], -alphas[1], 0],\n            [0, lambdas[1], -alphas[2]],\n        ])\n\n        # Get the exact solution at the final time T\n        n_exact = bateman_solution(lambdas, alphas, n0, T)\n        \n        errors = []\n        step_sizes = []\n\n        for N in Ns:\n            h = T / N\n            step_sizes.append(h)\n            \n            # Get the numerical solution\n            n_numerical = heun_solver(A, n0, h, N)\n            \n            # Calculate the Euclidean norm of the error\n            error = np.linalg.norm(n_numerical - n_exact)\n            errors.append(error)\n\n        # Calculate pairwise convergence rates\n        # p = log(E1/E2) / log(h1/h2) where h1/h2 = 2\n        p12 = np.log(errors[0] / errors[1]) / np.log(step_sizes[0] / step_sizes[1])\n        p23 = np.log(errors[1] / errors[2]) / np.log(step_sizes[1] / step_sizes[2])\n\n        # Average the two estimates\n        p_avg = (p12 + p23) / 2.0\n        results.append(p_avg)\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Ultimately, the choice of an integrator depends on a trade-off between accuracy, stability, and computational cost, especially for nonlinear problems where coefficients are not constant. This final practice situates the predictor-corrector method within a more realistic context, comparing its performance on a nonlinear depletion benchmark against both a simpler first-order method and a sophisticated adaptive solver . By quantifying the errors and computational costs of each, you will develop a practical understanding of how to select the right tool for a given simulation challenge.",
            "id": "4241782",
            "problem": "Consider a simplified, scientifically consistent depletion benchmark representative of nuclear reactor simulation. The system consists of three nuclide number densities, denoted by the vector $N(t) = [N_F(t), N_M(t), N_X(t)]^\\top$ with units atoms per cubic centimeter. The governing equations are the Bateman-type coupled system\n$$\n\\frac{dN}{dt} = Q\\big(N(t)\\big)\\,N(t),\n$$\nwhere $Q(N)$ is a $3\\times 3$ rate matrix whose entries are determined by neutron-induced reactions and radioactive decay. The neutron flux is modeled with composition feedback by\n$$\n\\phi(N) = \\frac{\\phi_0}{1 + \\kappa\\,N_X},\n$$\nwith $\\phi_0$ in neutrons per square centimeter per second and $\\kappa$ in cubic centimeters per atom. The physical processes included are:\n- Absorption and fission of the fissile species $F$ with microscopic cross sections $\\sigma_{F,a}$ and $\\sigma_{F,f}$ in square centimeters.\n- Absorption of the medium species $M$ with $\\sigma_{M,a}$, and absorption of the poison species $X$ with $\\sigma_{X,a}$.\n- Radioactive decay with decay constants $\\lambda_F$, $\\lambda_M$, and $\\lambda_X$ in inverse seconds.\n- A fraction $b_{M\\rightarrow F}$ of $M$ decays to $F$, and the poison $X$ is produced from $F$ fissions with independent yield $y_X$ (dimensionless).\n\nUnder these assumptions, the entries of $Q(N)$ are defined such that\n$$\n\\begin{aligned}\n\\frac{dN_F}{dt} &= -\\big(\\sigma_{F,a}+\\sigma_{F,f}\\big)\\,\\phi(N)\\,N_F - \\lambda_F\\,N_F + b_{M\\rightarrow F}\\,\\lambda_M\\,N_M,\\\\\n\\frac{dN_M}{dt} &= +\\sigma_{F,a}\\,\\phi(N)\\,N_F - \\sigma_{M,a}\\,\\phi(N)\\,N_M - \\lambda_M\\,N_M,\\\\\n\\frac{dN_X}{dt} &= +y_X\\,\\sigma_{F,f}\\,\\phi(N)\\,N_F - \\sigma_{X,a}\\,\\phi(N)\\,N_X - \\lambda_X\\,N_X.\n\\end{aligned}\n$$\nThis defines $Q(N)$ via $dN/dt = Q(N)\\,N$.\n\nYour task is to implement and compare three time-integration strategies over a fixed time horizon $T$ with given initial condition $N(0)=N_0$, and to quantify accuracy and computational cost:\n1. Matrix Exponential with Frozen Rates (ME): Over a macro time step $\\Delta t$, freeze $Q$ at the beginning of the step $Q_k = Q(N_k)$ and compute $N_{k+1} = \\exp\\!\\big(\\Delta t\\,Q_k\\big)\\,N_k$.\n2. Predictor-Corrector Depletion (PC): Over a macro time step $\\Delta t$, compute the predictor $N^{\\mathrm{pred}} = \\exp\\!\\big(\\Delta t\\,Q(N_k)\\big)\\,N_k$, then form $Q_{\\mathrm{avg}} = \\tfrac{1}{2}\\big(Q(N_k)+Q(N^{\\mathrm{pred}})\\big)$ and compute the corrected state $N_{k+1} = \\exp\\!\\big(\\Delta t\\,Q_{\\mathrm{avg}}\\big)\\,N_k$.\n3. Backward Differentiation Formula (BDF): Use an implicit variable-step solver for $dN/dt = Q(N)\\,N$.\n\nDefine the accuracy metric as the relative $2$-norm error at the final time,\n$$\n\\varepsilon = \\frac{\\left\\|N_{\\mathrm{method}}(T)-N_{\\mathrm{ref}}(T)\\right\\|_2}{\\left\\|N_{\\mathrm{ref}}(T)\\right\\|_2},\n$$\nwhere the reference $N_{\\mathrm{ref}}(T)$ is:\n- In the linear case (constant flux), the exact solution $N_{\\mathrm{ref}}(T)=\\exp\\!\\big(T\\,Q_{\\mathrm{const}}\\big)\\,N_0$ with $Q_{\\mathrm{const}}=Q(N_0)$ and $\\kappa=0$, which makes $Q$ constant over time.\n- In the nonlinear feedback cases ($\\kappa>0$), a high-accuracy Backward Differentiation Formula (BDF) solution with tight tolerances.\n\nDefine computational cost proxies as follows:\n- For ME: the number of rate matrix evaluations $n_Q$ and the number of matrix exponential evaluations $n_{\\exp}$.\n- For PC: the number of rate matrix evaluations $n_Q$ and the number of matrix exponential evaluations $n_{\\exp}$.\n- For BDF: the number of right-hand side evaluations $n_{\\mathrm{fev}}$ and Jacobian evaluations $n_{\\mathrm{jev}}$ reported by the solver.\n\nAll physical units must be consistent: number densities in atoms per cubic centimeter, flux in neutrons per square centimeter per second, cross sections in square centimeters, and time in seconds. Express all numeric outputs as floats, using the accuracy metric defined above (dimensionless) and integer counts for computational cost proxies.\n\nImplement your program to run the following test suite, each specified by $(N_0,\\phi_0,\\kappa,T,\\Delta t)$ along with fixed microscopic and decay parameters:\n\nFixed parameters for all tests:\n- $\\sigma_{F,a} = 6\\times 10^{-24}$, $\\sigma_{F,f} = 5.85\\times 10^{-22}$, $\\sigma_{M,a} = 2\\times 10^{-24}$, $\\sigma_{X,a} = 2\\times 10^{-18}$.\n- $\\lambda_F = 0$, $\\lambda_M = 1\\times 10^{-6}$, $\\lambda_X = 2.1\\times 10^{-5}$.\n- $b_{M\\rightarrow F} = 0.5$, $y_X = 3\\times 10^{-3}$.\n\nTest cases:\n- Case A (linear, constant flux baseline): $N_0 = [5\\times 10^{20},\\,2\\times 10^{20},\\,1\\times 10^{16}]^\\top$, $\\phi_0 = 1\\times 10^{14}$, $\\kappa=0$, $T=3.6\\times 10^{3}$, $\\Delta t = 6.0\\times 10^{2}$.\n- Case B (nonlinear, mild feedback): $N_0 = [5\\times 10^{20},\\,2\\times 10^{20},\\,1\\times 10^{16}]^\\top$, $\\phi_0 = 1\\times 10^{14}$, $\\kappa=1\\times 10^{-21}$, $T=3.6\\times 10^{3}$, $\\Delta t = 6.0\\times 10^{2}$.\n- Case C (nonlinear, stiff with strong poisoning): $N_0 = [5\\times 10^{20},\\,2\\times 10^{20},\\,1\\times 10^{16}]^\\top$, $\\phi_0 = 3\\times 10^{14}$, $\\kappa=5\\times 10^{-21}$, $T=3.6\\times 10^{3}$, $\\Delta t = 6.0\\times 10^{1}$.\n\nFor each case, compute:\n- The ME method’s final-time relative error $\\varepsilon_{\\mathrm{ME}}$, $n_Q$ and $n_{\\exp}$.\n- The PC method’s final-time relative error $\\varepsilon_{\\mathrm{PC}}$, $n_Q$ and $n_{\\exp}$.\n- The BDF method’s final-time relative error $\\varepsilon_{\\mathrm{BDF}}$, $n_{\\mathrm{fev}}$ and $n_{\\mathrm{jev}}$ (with moderate tolerances).\n\nUse for the BDF reference in nonlinear cases a tight tolerance with relative tolerance $10^{-10}$ and absolute tolerance $10^{-12}$ per component; for the BDF method under comparison use a moderate tolerance with relative tolerance $10^{-8}$ and absolute tolerance $10^{-10}$ per component. The linear case reference should use the exact matrix exponential as described.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list\n$$\n\\big[\\varepsilon_{\\mathrm{ME}},\\,n_{Q,\\mathrm{ME}},\\,n_{\\exp,\\mathrm{ME}},\\,\\varepsilon_{\\mathrm{PC}},\\,n_{Q,\\mathrm{PC}},\\,n_{\\exp,\\mathrm{PC}},\\,\\varepsilon_{\\mathrm{BDF}},\\,n_{\\mathrm{fev,BDF}},\\,n_{\\mathrm{jev,BDF}}\\big].\n$$\nFormat the printed list with no spaces (e.g., $[[\\dots],[\\dots],[\\dots]]$).",
            "solution": "The problem posed is to implement and compare three numerical time-integration schemes for a system of coupled nonlinear ordinary differential equations (ODEs) that model nuclide depletion in a simplified nuclear reactor setting. The problem is scientifically consistent, well-posed, and provides all necessary data and specifications for a rigorous computational analysis. The evaluation criteria are clearly defined in terms of accuracy and computational cost proxies. Therefore, the problem is valid, and a full solution follows.\n\nThe system dynamics are described by the vector equation:\n$$\n\\frac{d}{dt} N(t) = Q\\big(N(t)\\big) N(t)\n$$\nwhere $N(t) = [N_F(t), N_M(t), N_X(t)]^\\top$ is the vector of number densities for the fissile ($F$), medium ($M$), and poison ($X$) species, respectively. The evolution is governed by the state-dependent rate matrix $Q(N)$, whose elements are functions of physical constants and a neutron flux $\\phi(N)$ that exhibits feedback from the poison concentration $N_X$:\n$$\n\\phi(N) = \\frac{\\phi_0}{1 + \\kappa N_X}\n$$\nThe individual ODEs are given as:\n$$\n\\begin{aligned}\n\\frac{dN_F}{dt} &= -\\big(\\sigma_{F,a}+\\sigma_{F,f}\\big)\\,\\phi(N)\\,N_F - \\lambda_F\\,N_F + b_{M\\rightarrow F}\\,\\lambda_M\\,N_M \\\\\n\\frac{dN_M}{dt} &= +\\sigma_{F,a}\\,\\phi(N)\\,N_F - \\sigma_{M,a}\\,\\phi(N)\\,N_M - \\lambda_M\\,N_M \\\\\n\\frac{dN_X}{dt} &= +y_X\\,\\sigma_{F,f}\\,\\phi(N)\\,N_F - \\sigma_{X,a}\\,\\phi(N)\\,N_X - \\lambda_X\\,N_X\n\\end{aligned}\n$$\nFrom this system, the $3 \\times 3$ rate matrix $Q(N)$ is constructed as follows:\n$$\nQ(N) =\n\\begin{pmatrix}\n-\\left(\\sigma_{F,a}+\\sigma_{F,f}\\right)\\phi(N) - \\lambda_F & b_{M\\rightarrow F}\\lambda_M & 0 \\\\\n\\sigma_{F,a}\\phi(N) & -\\sigma_{M,a}\\phi(N) - \\lambda_M & 0 \\\\\ny_X\\sigma_{F,f}\\phi(N) & 0 & -\\sigma_{X,a}\\phi(N) - \\lambda_X\n\\end{pmatrix}\n$$\nThe task involves solving this initial value problem from $t=0$ to $t=T$ with a given $N(0)=N_0$ using three distinct methods and comparing their performance.\n\n1.  **Matrix Exponential with Frozen Rates (ME)**: This is a first-order explicit method. For each time step of duration $\\Delta t$ from $t_k$ to $t_{k+1}$, the rate matrix $Q$ is assumed to be constant, evaluated at the beginning of the step, $Q_k = Q(N_k)$. The solution is then advanced using the matrix exponential:\n    $$\n    N_{k+1} = \\exp\\left(\\Delta t \\, Q_k\\right) N_k\n    $$\n    The computational cost for one step is one evaluation of $Q(N)$ and one matrix exponential calculation.\n\n2.  **Predictor-Corrector Depletion (PC)**: This is a second-order explicit method designed to improve accuracy over ME. Each time step involves two stages:\n    -   **Predictor stage**: An intermediate state $N^{\\mathrm{pred}}$ is computed using the ME method:\n        $$\n        N^{\\mathrm{pred}} = \\exp\\left(\\Delta t \\, Q(N_k)\\right) N_k\n        $$\n    -   **Corrector stage**: A new, more accurate rate matrix $Q_{\\mathrm{avg}}$ is formed by averaging the rates at the beginning and the predicted end of the step:\n        $$\n        Q_{\\mathrm{avg}} = \\frac{1}{2}\\left(Q(N_k) + Q(N^{\\mathrm{pred}})\\right)\n        $$\n        This averaged matrix is then used to compute the final state for the step, starting again from $N_k$:\n        $$\n        N_{k+1} = \\exp\\left(\\Delta t \\, Q_{\\mathrm{avg}}\\right) N_k\n        $$\n    The cost for one step is two evaluations of $Q(N)$ and two matrix exponential calculations.\n\n3.  **Backward Differentiation Formula (BDF)**: This represents a family of implicit, variable-step, multi-step methods, well-suited for solving stiff ODEs. We will use a high-quality library implementation (`scipy.integrate.solve_ivp` with `method='BDF'`). The solver automatically adjusts its internal step size to meet a specified error tolerance, making it fundamentally different from the fixed-step ME and PC methods. Its cost is measured by the number of right-hand side function evaluations ($n_{\\mathrm{fev}}$) and Jacobian matrix evaluations ($n_{\\mathrm{jev}}$), which are reported by the solver.\n\nThe comparison is based on a relative $L_2$-norm error metric at the final time $T$:\n$$\n\\varepsilon = \\frac{\\left\\|N_{\\mathrm{method}}(T)-N_{\\mathrm{ref}}(T)\\right\\|_2}{\\left\\|N_{\\mathrm{ref}}(T)\\right\\|_2}\n$$\nA high-fidelity reference solution $N_{\\mathrm{ref}}(T)$ is generated for each case. In the linear case ($\\kappa=0$), $Q$ is constant, and the exact solution is $N(T) = \\exp(T Q) N_0$. In the nonlinear cases ($\\kappa>0$), a BDF solution with very stringent tolerances (`rtol=1e-10`, `atol=1e-12`) is used as the reference.\n\nThe implementation will proceed by first defining a function to construct $Q(N)$ based on the problem parameters. Then, separate functions will implement the ME, PC, and BDF solution schemes. The main routine will iterate through the specified test cases, compute the reference solution, run each of the three methods, and calculate their respective accuracy and cost metrics.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Implements and compares three time-integration strategies for a simplified\n    nuclear reactor nuclide depletion problem.\n    \"\"\"\n    \n    # Fixed physical parameters for all test cases\n    params = {\n        'sigma_F_a': 6e-24,\n        'sigma_F_f': 5.85e-22,\n        'sigma_M_a': 2e-24,\n        'sigma_X_a': 2e-18,\n        'lambda_F': 0.0,\n        'lambda_M': 1e-6,\n        'lambda_X': 2.1e-5,\n        'b_M_to_F': 0.5,\n        'y_X': 3e-3\n    }\n\n    # Test case definitions: (N0, phi0, kappa, T, dt)\n    test_cases = [\n        # Case A: linear, constant flux baseline\n        {'N0': np.array([5e20, 2e20, 1e16]), 'phi0': 1e14, 'kappa': 0.0,\n         'T': 3.6e3, 'dt': 6.0e2},\n        # Case B: nonlinear, mild feedback\n        {'N0': np.array([5e20, 2e20, 1e16]), 'phi0': 1e14, 'kappa': 1e-21,\n         'T': 3.6e3, 'dt': 6.0e2},\n        # Case C: nonlinear, stiff with strong poisoning\n        {'N0': np.array([5e20, 2e20, 1e16]), 'phi0': 3e14, 'kappa': 5e-21,\n         'T': 3.6e3, 'dt': 6.0e1},\n    ]\n\n    # Helper function to get the rate matrix Q(N)\n    def get_Q(N, phi0, kappa, p):\n        N_X = N[2]\n        flux = phi0 / (1.0 + kappa * N_X)\n        \n        Q = np.zeros((3, 3))\n        \n        # dN_F/dt terms\n        Q[0, 0] = -(p['sigma_F_a'] + p['sigma_F_f']) * flux - p['lambda_F']\n        Q[0, 1] = p['b_M_to_F'] * p['lambda_M']\n        \n        # dN_M/dt terms\n        Q[1, 0] = p['sigma_F_a'] * flux\n        Q[1, 1] = -p['sigma_M_a'] * flux - p['lambda_M']\n        \n        # dN_X/dt terms\n        Q[2, 0] = p['y_X'] * p['sigma_F_f'] * flux\n        Q[2, 2] = -p['sigma_X_a'] * flux - p['lambda_X']\n        \n        return Q\n\n    # Right-hand side function for ODE solver\n    def rhs(t, N, phi0, kappa, p):\n        Q = get_Q(N, phi0, kappa, p)\n        return Q @ N\n\n    # Error calculation function\n    def calculate_relative_error(N_method, N_ref):\n        return np.linalg.norm(N_method - N_ref) / np.linalg.norm(N_ref)\n\n    all_results = []\n    for case in test_cases:\n        N0, phi0, kappa, T, dt = case['N0'], case['phi0'], case['kappa'], case['T'], case['dt']\n\n        # --- Generate Reference Solution ---\n        if kappa == 0:  # Linear case\n            Q_const = get_Q(N0, phi0, kappa, params)\n            N_ref = expm(T * Q_const) @ N0\n        else:  # Nonlinear case\n            sol_ref = solve_ivp(\n                lambda t, y: rhs(t, y, phi0, kappa, params),\n                (0, T), N0, method='BDF', rtol=1e-10, atol=1e-12\n            )\n            N_ref = sol_ref.y[:, -1]\n\n        # --- 1. Matrix Exponential (ME) Method ---\n        N_me = N0.copy()\n        num_steps = int(round(T / dt))\n        n_Q_me, n_exp_me = 0, 0\n        for _ in range(num_steps):\n            Q_k = get_Q(N_me, phi0, kappa, params)\n            n_Q_me += 1\n            N_me = expm(dt * Q_k) @ N_me\n            n_exp_me += 1\n        eps_me = calculate_relative_error(N_me, N_ref)\n\n        # --- 2. Predictor-Corrector (PC) Method ---\n        N_pc = N0.copy()\n        n_Q_pc, n_exp_pc = 0, 0\n        for _ in range(num_steps):\n            Q_k = get_Q(N_pc, phi0, kappa, params)\n            n_Q_pc += 1\n            \n            N_pred = expm(dt * Q_k) @ N_pc\n            n_exp_pc += 1\n            \n            Q_pred = get_Q(N_pred, phi0, kappa, params)\n            n_Q_pc += 1\n            \n            Q_avg = 0.5 * (Q_k + Q_pred)\n            N_pc = expm(dt * Q_avg) @ N_pc\n            n_exp_pc += 1\n        eps_pc = calculate_relative_error(N_pc, N_ref)\n\n        # --- 3. BDF Method ---\n        sol_bdf = solve_ivp(\n            lambda t, y: rhs(t, y, phi0, kappa, params),\n            (0, T), N0, method='BDF', rtol=1e-8, atol=1e-10\n        )\n        N_bdf = sol_bdf.y[:, -1]\n        eps_bdf = calculate_relative_error(N_bdf, N_ref)\n        n_fev_bdf = sol_bdf.nfev\n        n_jev_bdf = sol_bdf.njev\n\n        case_results = [\n            eps_me, n_Q_me, n_exp_me,\n            eps_pc, n_Q_pc, n_exp_pc,\n            eps_bdf, n_fev_bdf, n_jev_bdf,\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string\n    outer_list_str = []\n    for case_res in all_results:\n        inner_list_str = f\"[{','.join(f'{val:.6e}' if isinstance(val, float) else str(val) for val in case_res)}]\"\n        outer_list_str.append(inner_list_str)\n    \n    print(f\"[{','.join(outer_list_str)}]\")\n\nsolve()\n```"
        }
    ]
}