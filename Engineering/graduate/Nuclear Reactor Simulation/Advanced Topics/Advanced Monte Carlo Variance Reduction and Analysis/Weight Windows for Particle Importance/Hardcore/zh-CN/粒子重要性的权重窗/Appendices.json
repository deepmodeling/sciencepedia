{
    "hands_on_practices": [
        {
            "introduction": "为了建立对权重窗机理具体、分步的理解，我们从一个简化的确定性模型开始。本练习将引导你模拟一个粒子在穿过介质时，其权重和模拟增殖数（multiplicity）如何演变 。通过手动追踪分裂和轮盘赌决策，你可以在处理更复杂的统计分析之前，对权重窗方法的基本机制获得扎实的直观认识。",
            "id": "3535413",
            "problem": "我们考虑一个厚度为 $L$ 的一维平板中的单能光子输运问题。光子在源表面（$x=0$）发射，探测器在远端表面（$x=L$）记录透射的粒子流。介质是均匀的，其宏观总截面为 $\\Sigma_t$（单位为 $\\mathrm{m}^{-1}$），深穿透输运被建模为一个没有散射的吸收过程。给定一个在 $N+1$ 个离散位置 $x_0=0, x_1, \\dots, x_N=L$ 上的伴随通量图 $\\psi^\\dagger(x)$。目标是利用此伴随图设计权重窗界限，并从第一性原理预测权重窗方法相对于模拟蒙特卡罗方法的方差减少因子。\n\n基本原理：\n- 随机变量期望值的变化率由 Kolmogorov 前向方程决定，在适当的假设下，该方程对于物质中的粒子输运可简化为线性玻尔兹曼输运方程。其伴随形式定义了伴随通量 $\\psi^\\dagger(\\vec{r}, E, \\Omega)$，它量化了相空间点 $(\\vec{r}, E, \\Omega)$ 上的粒子对特定响应泛函的重要性。\n- 在一维平板几何、单能光子和纯吸收介质中，粒子通过模拟方式透射的概率为 $P = \\exp(-\\Sigma_t L)$。\n- 在蒙特卡罗（MC）辐射输运中，权重窗（WW）方法是一种基于重要性采样的方差减少（VR）技术：给定一个标量化的重要性函数 $I(x)$，目标粒子权重为 $W_t(x) \\propto 1/I(x)$，这样当 $w > W_u(x)$ 时通过分裂，当 $w  W_l(x)$ 时通过轮盘赌，将粒子权重保持在一个预设的区间附近，其中 $W_u(x)$ 和 $W_l(x)$ 是权重窗的上下界。这种启发式方法旨在逼近当使用精确的伴随解来定义重要性时所能达到的零方差极限。\n\n任务：\n1. 对于离散位置 $x_i$，令标量重要性为 $I(x_i) = \\psi^\\dagger(x_i)$。将位置 $x_i$ 处的目标权重定义为 $W_t(x_i) = C / I(x_i)$，其中 $C$ 是一个归一化常数，选择它以使得 $W_t(x_0) = 1$（即 $C = I(x_0)$）。\n2. 给定一个窗半宽参数 $\\alpha \\geq 1$，将位置 $x_i$ 处的权重窗界限定义为 $W_u(x_i) = \\alpha W_t(x_i)$ 和 $W_l(x_i) = W_t(x_i) / \\alpha$。\n3. 考虑一个按顺序从 $x_0$ 穿越到 $x_N$ 的粒子历史。该粒子以权重 $w_0 = 1$ 开始。在每个位置 $x_i$（其中 $i=1,2,\\dots,N$），执行以下对标准权重窗逻辑的确定性近似：\n   - 如果 $w_{i-1} > W_u(x_i)$，则分裂成 $n_i = \\lceil w_{i-1} / W_t(x_i) \\rceil$ 个子代粒子，每个子代粒子的新权重为 $w_i = w_{i-1} / n_i$。累积总分裂增殖率 $M \\leftarrow M \\cdot n_i$。\n   - 否则，如果 $w_{i-1}  W_l(x_i)$，则应用期望轮盘赌调整：设置 $w_i = W_t(x_i)$。不改变 $M$（轮盘赌不增加期望增殖率）。\n   - 否则，设置 $w_i = w_{i-1}$ 且不改变 $M$。\n   以 $M=1$ 开始。\n4. 将每次历史的模拟透射流得分建模为一个伯努利随机变量 $X$，其中 $\\mathbb{P}(X=1) = P = \\exp(-\\Sigma_t L)$。在权重窗分裂下，得分变为 $S = \\sum_{j=1}^{M} (1/M) X_j$，其中 $X_j$ 是具有相同透射概率 $P$ 的独立同分布伯努利变量。利用独立变量和的方差，推导出权重窗下的方差为 $\\mathrm{Var}(S) = P(1-P)/M$，而模拟方差为 $\\mathrm{Var}(X) = P(1-P)$。因此，相对于模拟方法的方差减少因子为 $\\mathrm{VRF} = \\mathrm{Var}(X) / \\mathrm{Var}(S) = M$。\n5. 实现一个程序，对于每个测试用例，构造 $W_t(x_i)$、窗界限 $\\{W_l(x_i), W_u(x_i)\\}$，使用上述确定性权重窗近似方法在各个位置上演化权重和增殖率 $M$，并输出预测的方差减少因子 $\\mathrm{VRF} = M$。\n\n物理单位：\n- $\\Sigma_t$ 的单位使用 $\\mathrm{m}^{-1}$，$L$ 的单位使用 $\\mathrm{m}$。输出的 $\\mathrm{VRF}$ 是无量纲的。\n\n角度单位：\n- 不适用，因为问题是一维的。\n\n百分比：\n- 任何概率值都必须作为小数处理，而不是百分比。\n\n测试套件：\n- 案例 1 (正常路径): $\\Sigma_t = 1.0\\,\\mathrm{m}^{-1}$, $L = 1.0\\,\\mathrm{m}$, $\\alpha = 2.0$, 且在位置 $[x_0, x_1, x_2, x_3, x_4, x_5]$ 处的 $\\psi^\\dagger$ 为 $[1.0, 1.5, 2.5, 4.0, 6.0, 9.0]$。\n- 案例 2 (边界条件，无分裂): $\\Sigma_t = 0.8\\,\\mathrm{m}^{-1}$, $L = 1.0\\,\\mathrm{m}$, $\\alpha = 10.0$, 且 $\\psi^\\dagger$ 为 $[1.0, 1.0, 1.0, 1.0]$。\n- 案例 3 (强深穿透): $\\Sigma_t = 2.0\\,\\mathrm{m}^{-1}$, $L = 2.0\\,\\mathrm{m}$, $\\alpha = 1.5$, 且 $\\psi^\\dagger$ 为 $[1.0, 3.0, 9.0, 27.0]$。\n- 案例 4 (导致轮盘赌的振荡重要性): $\\Sigma_t = 0.5\\,\\mathrm{m}^{-1}$, $L = 1.0\\,\\mathrm{m}$, $\\alpha = 1.2$, 且 $\\psi^\\dagger$ 为 $[1.0, 0.8, 1.2, 0.9, 1.5]$。\n\n答案规格：\n- 对于每个测试用例，计算方差减少因子 $\\mathrm{VRF}$（作为浮点数）。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$\\texttt{[result1,result2,result3,result4]}$）。",
            "solution": "该问题要求计算一维平板中单能光子输运问题的预测方差减少因子（VRF）。VRF是通过实现权重窗方差减少技术的一个确定性的、简化的版本来确定的。该计算基于一个给定的离散伴随通量图 $\\psi^\\dagger(x_i)$，它用作重要性函数。\n\n基本原则是，粒子的权重应与其所在位置的重要性成反比。这使得权重和重要性的乘积（衡量对得分的预期未来贡献）大致保持恒定。重要性函数 $I(x)$ 由伴随通量给出，$I(x_i) = \\psi^\\dagger(x_i)$。位置 $x_i$ 处的目标权重，记为 $W_t(x_i)$，定义为 $W_t(x_i) = C / I(x_i)$，其中 $C$ 是一个归一化常数。问题规定源粒子在 $x_0 = 0$ 处的权重为 1，因此我们设置 $W_t(x_0) = 1$。这意味着 $C = I(x_0) = \\psi^\\dagger(x_0)$，从而得到在任何位置 $x_i$ 处的目标权重公式：\n$$\nW_t(x_i) = \\frac{\\psi^\\dagger(x_0)}{\\psi^\\dagger(x_i)}\n$$\n\n权重窗方法使用此目标权重在每个位置 $x_i$ 定义一个可接受的权重范围 $[W_l(x_i), W_u(x_i)]$。这些下界和上界由一个窗半宽参数 $\\alpha \\geq 1$ 确定：\n$$\nW_u(x_i) = \\alpha W_t(x_i)\n$$\n$$\nW_l(x_i) = \\frac{W_t(x_i)}{\\alpha}\n$$\n\n该算法模拟了粒子权重在穿过平板中离散位置 $x_0, x_1, \\dots, x_N$ 时的演化过程。它以初始权重 $w_0 = 1$ 和初始总增殖率 $M=1$ 开始。在随后的每个位置 $x_i$（对于 $i=1, \\dots, N$），将传入的权重 $w_{i-1}$ 与权重窗 $[W_l(x_i), W_u(x_i)]$ 进行比较。问题定义了一套确定性规则：\n1. 如果权重 $w_{i-1}$ 高于权重窗，$w_{i-1} > W_u(x_i)$，则粒子被分裂。这是为了在一个每个粒子被认为更重要（由较低的目标权重表示）的区域中增加样本数量。分裂出的子代粒子数 $n_i$ 的计算是为了使新权重接近目标权重：\n$$\nn_i = \\left\\lceil \\frac{w_{i-1}}{W_t(x_i)} \\right\\rceil\n$$\n每个子代粒子的新权重变为 $w_i = w_{i-1} / n_i$。总粒子增殖率通过乘以分裂因子来更新：$M \\leftarrow M \\cdot n_i$。\n\n2. 如果权重 $w_{i-1}$ 低于权重窗，$w_{i-1}  W_l(x_i)$，则应用轮盘赌的期望值近似。不是概率性地终止粒子，而是确定性地将其权重重置为目标权重，$w_i = W_t(x_i)$。在这个简化模型中，轮盘赌不改变总增殖率 $M$，因为它是一个平均而言会减少粒子数量的过程。\n\n3. 如果权重 $w_{i-1}$ 在权重窗内，$W_l(x_i) \\leq w_{i-1} \\leq W_u(x_i)$，则不采取任何行动。权重被继承，$w_i = w_{i-1}$，增殖率 $M$ 保持不变。\n\n问题假设了一个模型，其中方差减少因子直接等于粒子从 $x_0$ 穿越到 $x_N=L$ 结束时累积的总增殖率 $M$。这是基于这样一种启发式方法：将一个粒子分裂成 $M$ 个独立的子代粒子，等效于运行 $M$ 次独立的模拟，从而将均值估计的方差减少 $M$ 倍。\n$$\n\\mathrm{VRF} = \\frac{\\mathrm{Var}(\\text{Analog})}{\\mathrm{Var}(\\text{WW})} = M\n$$\n\n求解算法首先使用给定的 $\\psi^\\dagger$ 值计算所有 $i \\in \\{0, 1, \\dots, N\\}$ 的目标权重 $W_t(x_i)$。然后，它初始化 $w=1.0$ 和 $M=1$，并从 $i=1$ 迭代到 $N$，在每一步应用确定性的分裂和轮盘赌逻辑来更新 $w$ 和 $M$。在 $x_N$ 处的最后一步之后 $M$ 的最终值就是计算出的 VRF。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It iterates through each test case, calculates the VRF, and prints\n    the results in the specified format.\n    \"\"\"\n    # Test suite as defined in the problem statement.\n    # Each tuple contains: (Sigma_t, L, alpha, psi_dagger_list)\n    test_cases = [\n        (1.0, 1.0, 2.0, [1.0, 1.5, 2.5, 4.0, 6.0, 9.0]),\n        (0.8, 1.0, 10.0, [1.0, 1.0, 1.0, 1.0]),\n        (2.0, 2.0, 1.5, [1.0, 3.0, 9.0, 27.0]),\n        (0.5, 1.0, 1.2, [1.0, 0.8, 1.2, 0.9, 1.5]),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters for the current case.\n        # Sigma_t and L are not directly used in the VRF calculation as defined,\n        # but are part of the problem's physical context.\n        _sigma_t, _L, alpha, psi_dagger = case\n        \n        # Initialize simulation state for a single particle history\n        current_w = 1.0\n        # M is the total multiplicity, which is the predicted VRF.\n        # It's an integer value, as it comes from products of integers.\n        M = 1\n\n        # The importance at the source (x=0) is used for normalization.\n        psi_dagger_0 = psi_dagger[0]\n        \n        # Calculate target weights W_t(x_i) = psi_dagger(x_0) / psi_dagger(x_i)\n        target_weights = [psi_dagger_0 / p_d for p_d in psi_dagger]\n        \n        # Iterate through the slab positions from x_1 to x_N\n        # The loop starts at index 1 because x_0 is the source position.\n        for i in range(1, len(psi_dagger)):\n            # Define the weight-window for the current position x_i\n            w_t_i = target_weights[i]\n            w_u_i = alpha * w_t_i\n            w_l_i = w_t_i / alpha\n            \n            # Apply the deterministic weight-window logic\n            if current_w > w_u_i:\n                # Splitting logic: if weight is above the upper bound.\n                # n_i is the number of particles to split into.\n                n_i = int(np.ceil(current_w / w_t_i))\n                M *= n_i\n                current_w /= n_i\n            elif current_w  w_l_i:\n                # Russian roulette logic: if weight is below the lower bound.\n                # In this deterministic model, the weight is reset to the target weight.\n                current_w = w_t_i\n            # If the weight is within the window, no action is taken.\n        \n        # The final multiplicity M is the variance reduction factor.\n        # The result is required as a float.\n        results.append(float(M))\n\n    # Print the final results in the specified format: [result1,result2,...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在理解了单个粒子的权重调整机制后，我们现在将其推广到大量粒子群体的统计行为。本练习要求你计算期望分支因子——即平均每个粒子经过权重窗操作后产生的粒子数 。为此，你需要将入射粒子的权重视为遵循对数正态分布的随机变量，这对于理解权重窗如何从整体上控制粒子数量并维持模拟稳定性至关重要。",
            "id": "4260917",
            "problem": "在核反应堆模拟的中子输运计算中，一种蒙特卡罗（MC）权重窗方差缩减方案根据目标粒子权重来实施分裂和俄罗斯轮盘赌。设入射粒子权重为 $W$，定义无量纲比率 $X = W / w_T$，其中 $w_T$ 是目标权重。设定一个权重窗，其下界为 $w_L = \\frac{w_T}{2}$，上界为 $w_U = 2 w_T$。分裂和俄罗斯轮盘赌的规则如下：\n\n- 若 $X > \\frac{w_U}{w_T} = 2$，则进行无偏分裂，使得子粒子的期望数量等于 $X$，且期望总出射权重等于 $W$。一种无偏的实现方式是随机取整，它可以在不偏倚期望权重的情况下实现期望重数 $X$。\n- 若 $X  \\frac{w_L}{w_T} = \\frac{1}{2}$，则进行存活概率为 $p = X$ 的俄罗斯轮盘赌。如果粒子存活，其权重提升至 $w_T$；否则，粒子被终止。\n- 若 $\\frac{1}{2} \\leq X \\leq 2$，则不进行分裂或轮盘赌，粒子以其当前权重继续。\n\n假设 $X$ 服从参数为 $\\mu = 0$ 和 $\\sigma = 0.5$ 的对数正态分布；等价地，$Y = \\ln X$ 服从均值为 $0$、方差为 $\\sigma^2 = 0.25$ 的正态分布。仅使用这些定义以及正态分布和对数正态分布的标准性质，推导并计算期望分支因子 $B$，该因子定义为在此方案下，每个入射粒子经过权重窗操作后离开的粒子期望数量。将最终数值结果四舍五入至四位有效数字。",
            "solution": "分支因子 $B$ 定义为每个入射粒子经过权重窗操作后出射的粒子数 $N_{out}$ 的期望值。我们可以使用全期望定律来求得此值：$B = E[N_{out}] = E[E[N_{out}|X]]$。\n\n我们来确定问题中定义的三种情况下，条件期望 $E[N_{out}|X=x]$ 的值。\n1.  对于分裂情况，当 $x > 2$ 时：问题陈述子粒子的期望数量为 $x$。因此，$E[N_{out}|X=x] = x$。\n2.  对于俄罗斯轮盘赌情况，当 $x  \\frac{1}{2}$ 时：粒子以概率 $p=x$ 存活，产生 1 个粒子；以概率 $1-x$ 被终止，产生 0 个粒子。期望粒子数为 $E[N_{out}|X=x] = 1 \\cdot p + 0 \\cdot (1-p) = p = x$。\n3.  对于通过情况，当 $\\frac{1}{2} \\leq x \\leq 2$ 时：单个粒子未经修改继续运动。因此，$E[N_{out}|X=x] = 1$。\n\n我们可以定义一个函数 $g(x) = E[N_{out}|X=x]$：\n$$\ng(x) =\n\\begin{cases}\nx  \\text{if } 0  x  1/2 \\\\\n1  \\text{if } 1/2 \\leq x \\leq 2 \\\\\nx  \\text{if } x > 2\n\\end{cases}\n$$\n\n总的期望分支因子 $B$ 是 $g(X)$ 的期望值，通过将 $g(x)$ 与 $X$ 的概率密度函数（PDF）$f(x)$ 相乘并积分来计算。\n$$\nB = E[g(X)] = \\int_0^\\infty g(x) f(x) dx\n$$\n根据 $g(x)$ 的定义，这个积分可以分为三个部分：\n$$\nB = \\int_0^{1/2} x f(x) dx + \\int_{1/2}^2 1 \\cdot f(x) dx + \\int_2^\\infty x f(x) dx\n$$\n变量 $X$ 服从参数为 $\\mu=0$ 和 $\\sigma=0.5$ 的对数正态分布。其概率密度函数（PDF）为：\n$$\nf(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}\\right) \\quad \\text{for } x > 0\n$$\n为了计算这些积分，将积分变量更换为 $Y = \\ln X$ 更为方便。变量 $Y$ 服从均值为 $\\mu_Y = \\mu = 0$、方差为 $\\sigma_Y^2 = \\sigma^2 = 0.25$ 的正态分布。$Y$ 的概率密度函数，我们记为 $\\phi(y)$，是：\n$$\n\\phi(y) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y - \\mu)^2}{2\\sigma^2}\\right)\n$$\n变量代换关系为 $x = e^y$ 和 $dx = e^y dy$。$Y$ 的积分限变为：$x \\to 0 \\implies y \\to -\\infty$；$x=1/2 \\implies y=\\ln(1/2)=-\\ln(2)$；$x=2 \\implies y=\\ln(2)$；$x \\to \\infty \\implies y \\to \\infty$。\n\n我们来计算 $B$ 的每一项。\n\n中间项是 $X$ 落在通过窗口内的概率：\n$$\n\\int_{1/2}^2 f(x) dx = P\\left(\\frac{1}{2} \\leq X \\leq 2\\right) = P(-\\ln(2) \\leq Y \\leq \\ln(2))\n$$\n用 $Z = \\frac{Y-\\mu}{\\sigma} = \\frac{Y}{0.5} = 2Y$ 对 $Y$ 进行标准化，其中 $Z$ 服从标准正态分布 $N(0,1)$，我们得到：\n$$\nP(-2\\ln(2) \\leq Z \\leq 2\\ln(2)) = \\Phi(2\\ln(2)) - \\Phi(-2\\ln(2))\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数（CDF）。\n\n对于第一项和第三项，它们涉及 $\\int x f(x) dx$，我们使用对数正态分布的一个已知性质。设 $Y' \\sim N(\\mu+\\sigma^2, \\sigma^2)$。那么 $\\int_a^b x f(x) dx = E[X] \\cdot P(a \\le e^{Y'} \\le b)$，更简单地，可以证明 $\\int_a^b xf(x)dx = E[X] P(\\ln a \\le Y' \\le \\ln b)$。\n$E[X] = \\exp(\\mu + \\sigma^2/2)$ 是对数正态分布 $X$ 的均值。\n\n现在我们可以计算 $B$ 的第一项和第三项：\n$$\n\\int_0^{1/2} x f(x) dx = E[X] \\int_{-\\infty}^{-\\ln(2)} \\phi'(y) dy = E[X] \\cdot P(Y' \\leq -\\ln(2))\n$$\n其中 $\\phi'(y)$ 是 $Y'$ 的PDF。用 $Z = \\frac{Y'-\\mu'}{\\sigma}$ 对 $Y'$ 进行标准化，其中 $\\mu' = \\mu+\\sigma^2$，我们得到：\n$$\nP\\left(Z \\leq \\frac{-\\ln(2) - \\mu'}{\\sigma}\\right) = \\Phi\\left(\\frac{-\\ln(2) - (\\mu+\\sigma^2)}{\\sigma}\\right)\n$$\n对于第三项：\n$$\n\\int_2^\\infty x f(x) dx = E[X] \\int_{\\ln(2)}^{\\infty} \\phi'(y) dy = E[X] \\cdot P(Y' \\geq \\ln(2)) = E[X] \\left(1 - \\Phi\\left(\\frac{\\ln(2) - \\mu'}{\\sigma}\\right)\\right)\n$$\n\n现在，我们代入给定值：$\\mu=0$ 和 $\\sigma=0.5$（因此 $\\sigma^2=0.25$）。\n$E[X] = \\exp(0 + 0.25/2) = \\exp(0.125) \\approx 1.133148$。\n$\\mu' = 0 + 0.25 = 0.25$。\n$\\Phi$ 函数的自变量为：\n对于中间项：\n$z_1 = \\frac{\\ln(2)}{\\sigma} = \\frac{\\ln(2)}{0.5} = 2\\ln(2) \\approx 1.38629$。\n$\\int_{1/2}^2 f(x) dx = \\Phi(1.38629) - \\Phi(-1.38629) \\approx 0.917165 - 0.082835 = 0.834330$。\n\n对于第一项：\n$z_2 = \\frac{-\\ln(2) - \\mu'}{\\sigma} = \\frac{-\\ln(2) - 0.25}{0.5} = -2\\ln(2) - 0.5 \\approx -1.38629 - 0.5 = -1.88629$。\n$\\int_0^{1/2} x f(x) dx = \\exp(0.125) \\cdot \\Phi(-1.88629) \\approx 1.133148 \\times 0.029630 = 0.033586$。\n\n对于第三项：\n$z_3 = \\frac{\\ln(2) - \\mu'}{\\sigma} = \\frac{\\ln(2) - 0.25}{0.5} = 2\\ln(2) - 0.5 \\approx 1.38629 - 0.5 = 0.88629$。\n$\\int_2^\\infty x f(x) dx = \\exp(0.125) \\cdot (1 - \\Phi(0.88629)) \\approx 1.133148 \\times (1 - 0.812284) = 1.133148 \\times 0.187716 = 0.212711$。\n\n最后，我们将这三项相加得到 $B$：\n$$\nB \\approx 0.033586 + 0.834330 + 0.212711 = 1.080627\n$$\n问题要求将结果四舍五入到四位有效数字。前四位有效数字是 $1.080$，第五位数字是 $6$。因此，我们向上舍入。\n$$\nB \\approx 1.081\n$$",
            "answer": "$$\n\\boxed{1.081}\n$$"
        },
        {
            "introduction": "在实际应用中，用于生成权重窗的重要性函数通常是来自确定性计算的近似值，因此不可避免地包含误差。这个高级练习旨在探讨这些不完美性带来的后果 。你将需要推导伴随重要性函数中的误差如何传播到蒙特卡罗模拟的方差中，通过进行这种灵敏度分析，你将对权重窗方法的鲁棒性以及方差减少技术中的实际权衡有更深刻的理解。",
            "id": "4260973",
            "problem": "考虑一个反应堆屏蔽问题中的深穿透中子响应统计量，该问题被离散为 $B$ 个不相交的相空间箱，由 $b \\in \\{1,\\dots,B\\}$ 索引。设一个历史在箱 $b$ 中实现其贡献的模拟概率为 $p_b$，并设确定性伴随重要性为 $I_b$，该重要性与对统计量的箱式贡献成正比。假设由权重窗引起的蒙特卡洛偏倚使用的抽样分布与确定性伴随重要性和模拟概率的乘积成正比。具体来说，预期的最优重要性抽样分布应为 $q_b^{\\ast} \\propto I_b p_b$。在实践中，确定性伴随重要性包含依赖于箱的小分数误差，因此实施的重要性为 $\\hat{I}_b = I_b (1 + \\varepsilon_b)$，其中 $|\\varepsilon_b| \\ll 1$。因此，实施的抽样分布为 $q_b = C (1 + \\varepsilon_b) I_b p_b$，其中 $C$ 是确保 $\\sum_{b=1}^{B} q_b = 1$ 的归一化常数。\n\n您将使用标准的响应重要性抽样估计量，\n$$\n\\mu = \\sum_{b=1}^{B} I_b p_b,\n$$\n每个历史的权重为\n$$\nw_b = \\frac{I_b p_b}{q_b}.\n$$\n从重要性抽样的基本原理出发：估计量是无偏的，$E_{q}[w] = \\mu$，每个历史的方差是 $\\sigma_{1}^{2} = E_{q}[w^{2}] - \\mu^{2}$。推导至小参数 $\\varepsilon_b$ 的二阶，得到由权重窗引起的方差增量的闭式表达式，即在 $\\sigma_{1}^{2}(\\boldsymbol{\\varepsilon})$ 中仅由 $q_b$ 和 $q_b^{\\ast}$ 之间的不匹配引起的首个非零项。然后，采用品质因子（FOM）的标准定义，其中品质因子（FOM）为 $F = 1/(\\sigma^{2} T)$，并且每个历史的中央处理器（CPU）时间是恒定的，$T = \\kappa N$ 对于 $N$ 个历史和常数 $\\kappa > 0$，计算 $F$ 对各箱中分数误差 $\\varepsilon_b$ 的灵敏度，表示为梯度向量 $\\nabla_{\\boldsymbol{\\varepsilon}} F$，其第 $b$ 个分量是 $\\partial F / \\partial \\varepsilon_b$。\n\n您的推导必须从重要性抽样的无偏性和方差定义开始，并通过对小参数 $\\varepsilon_b$ 的系统性展开进行。将您关于灵敏度的最终答案表示为关于 $I_b$、$p_b$、$\\varepsilon_b$、$\\kappa$ 和 $\\mu$ 的单个闭式解析行向量。无需进行数值评估。最终答案必须是解析表达式。不要在最终的方框答案中包含单位。",
            "solution": "待估计的响应由所有相空间箱 $b$ 的总和给出：\n$$\n\\mu = \\sum_{b=1}^{B} I_b p_b\n$$\n其中 $I_b$ 是真实的伴随重要性，$p_b$ 是一个历史在箱 $b$ 中贡献的模拟概率。\n\n实施的、非理想的抽样分布是 $q_b = C \\hat{I}_b p_b = C I_b (1 + \\varepsilon_b) p_b$，其中 $\\hat{I}_b$ 是带有小分数误差 $\\varepsilon_b$ 的实施的重要性，而 $C$ 是一个归一化常数。条件 $\\sum_{b=1}^{B} q_b = 1$ 决定了 $C$：\n$$\n\\sum_{b=1}^{B} C I_b (1 + \\varepsilon_b) p_b = 1\n$$\n$$\nC \\left( \\sum_{b=1}^{B} I_b p_b + \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) = 1\n$$\n$$\nC \\left( \\mu + \\sum_{j=1}^{B} \\varepsilon_j I_j p_j \\right) = 1\n$$\n$$\nC = \\frac{1}{\\mu + \\sum_{j=1}^{B} \\varepsilon_j I_j p_j}\n$$\n一个历史在箱 $b$ 中贡献的权重由 $w_b = \\frac{I_b p_b}{q_b}$ 给出。代入 $q_b$ 的表达式：\n$$\nw_b = \\frac{I_b p_b}{C I_b (1 + \\varepsilon_b) p_b} = \\frac{1}{C (1 + \\varepsilon_b)}\n$$\n代入 $C$ 的表达式：\n$$\nw_b = \\frac{\\mu + \\sum_{j=1}^{B} \\varepsilon_j I_j p_j}{1 + \\varepsilon_b}\n$$\n\n每个历史的方差 $\\sigma_{1}^{2}$ 定义为 $\\sigma_{1}^{2} = E_{q}[w^{2}] - (E_{q}[w])^{2}$。估计量是无偏的，因此 $E_q[w] = \\sum_b w_b q_b = \\sum_b \\frac{I_b p_b}{q_b} q_b = \\sum_b I_b p_b = \\mu$。于是方差为 $\\sigma_{1}^{2} = E_{q}[w^{2}] - \\mu^{2}$。\n\n我们现在计算 $E_{q}[w^{2}] = \\sum_{b=1}^{B} w_b^2 q_b$：\n$$\nE_{q}[w^{2}] = \\sum_{b=1}^{B} \\left(\\frac{I_b p_b}{q_b}\\right)^2 q_b = \\sum_{b=1}^{B} \\frac{(I_b p_b)^2}{q_b}\n$$\n代入 $q_b = C I_b (1 + \\varepsilon_b) p_b$：\n$$\nE_{q}[w^{2}] = \\sum_{b=1}^{B} \\frac{(I_b p_b)^2}{C I_b (1 + \\varepsilon_b) p_b} = \\frac{1}{C} \\sum_{b=1}^{B} \\frac{I_b p_b}{1 + \\varepsilon_b}\n$$\n代入 $C$ 的表达式：\n$$\nE_{q}[w^{2}] = \\left(\\mu + \\sum_{j=1}^{B} \\varepsilon_j I_j p_j\\right) \\left(\\sum_{b=1}^{B} \\frac{I_b p_b}{1 + \\varepsilon_b}\\right)\n$$\n由于 $|\\varepsilon_b| \\ll 1$，我们使用泰勒级数展开 $\\frac{1}{1+x} = 1 - x + x^2 - O(x^3)$。我们需要保留至 $\\varepsilon_b$ 的二阶项，以找到方差中的首个非零项。\n$$\n\\sum_{b=1}^{B} \\frac{I_b p_b}{1 + \\varepsilon_b} \\approx \\sum_{b=1}^{B} I_b p_b (1 - \\varepsilon_b + \\varepsilon_b^2) = \\sum_{b=1}^{B} I_b p_b - \\sum_{b=1}^{B} \\varepsilon_b I_b p_b + \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b\n$$\n我们定义 $S_1 = \\sum_{b=1}^{B} \\varepsilon_b I_b p_b$ 和 $S_2 = \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b$。上面的表达式变为 $\\mu - S_1 + S_2$。\n现在，我们将其代回 $E_{q}[w^{2}]$ 的表达式中：\n$$\nE_{q}[w^{2}] \\approx (\\mu + S_1) (\\mu - S_1 + S_2) = \\mu^2 - \\mu S_1 + \\mu S_2 + S_1 \\mu - S_1^2 + S_1 S_2\n$$\n保留至 $\\varepsilon$ 的二阶项（注意 $S_1$ 是 $O(\\varepsilon)$ 阶，$S_2$ 是 $O(\\varepsilon^2)$ 阶）：\n$$\nE_{q}[w^{2}] \\approx \\mu^2 + \\mu S_2 - S_1^2 = \\mu^2 + \\mu \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b - \\left(\\sum_{b=1}^{B} \\varepsilon_b I_b p_b\\right)^2\n$$\n方差增量 $\\sigma_{1}^{2}(\\boldsymbol{\\varepsilon})$ 则为：\n$$\n\\sigma_{1}^{2}(\\boldsymbol{\\varepsilon}) = E_{q}[w^{2}] - \\mu^2 \\approx \\mu \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b - \\left(\\sum_{b=1}^{B} \\varepsilon_b I_b p_b\\right)^2\n$$\n这是对 $\\varepsilon_b$ 而言，由权重窗引起的方差增量到二阶的所需闭式表达式。注意，如果所有 $\\varepsilon_b = 0$，则 $\\sigma_{1}^{2} = 0$，这与在这种离散形式下理想重要性抽样的预期相符。\n\n接下来，我们计算品质因子（FOM）$F$ 对误差 $\\varepsilon_b$ 的灵敏度。FOM定义为 $F = 1/(\\sigma^2 T)$，其中 $\\sigma^2 = \\sigma_1^2/N$ 是 $N$ 个历史后均值的方差，而 $T = \\kappa N$ 是总CPU时间。因此：\n$$\nF = \\frac{1}{(\\sigma_1^2/N)(\\kappa N)} = \\frac{1}{\\kappa \\sigma_1^2}\n$$\n我们需要计算梯度向量 $\\nabla_{\\boldsymbol{\\varepsilon}} F$，其第 $b$ 个分量是 $\\frac{\\partial F}{\\partial \\varepsilon_b}$。使用链式法则：\n$$\n\\frac{\\partial F}{\\partial \\varepsilon_b} = \\frac{dF}{d\\sigma_1^2} \\frac{\\partial \\sigma_1^2}{\\partial \\varepsilon_b}\n$$\n第一项是：\n$$\n\\frac{dF}{d\\sigma_1^2} = -\\frac{1}{\\kappa (\\sigma_1^2)^2}\n$$\n第二项需要对我们关于 $\\sigma_1^2$ 的表达式对特定的误差分量 $\\varepsilon_k$ 求导：\n$$\n\\frac{\\partial \\sigma_1^2}{\\partial \\varepsilon_k} = \\frac{\\partial}{\\partial \\varepsilon_k} \\left[ \\mu \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b - \\left(\\sum_{b=1}^{B} \\varepsilon_b I_b p_b\\right)^2 \\right]\n$$\n逐项求导：\n$$\n\\frac{\\partial}{\\partial \\varepsilon_k} \\left( \\mu \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b \\right) = \\mu (2 \\varepsilon_k I_k p_k)\n$$\n$$\n\\frac{\\partial}{\\partial \\varepsilon_k} \\left( \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right)^2 = 2 \\left( \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) \\frac{\\partial}{\\partial \\varepsilon_k} \\left( \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) = 2 \\left( \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) (I_k p_k)\n$$\n结合这些结果：\n$$\n\\frac{\\partial \\sigma_1^2}{\\partial \\varepsilon_k} = 2 \\mu \\varepsilon_k I_k p_k - 2 I_k p_k \\left( \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) = 2 I_k p_k \\left( \\mu \\varepsilon_k - \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right)\n$$\n现在，我们组合 $F$ 的梯度的分量：\n$$\n\\frac{\\partial F}{\\partial \\varepsilon_k} = -\\frac{1}{\\kappa (\\sigma_1^2)^2} \\left[ 2 I_k p_k \\left( \\mu \\varepsilon_k - \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right) \\right]\n$$\n代入 $\\sigma_1^2$ 的表达式：\n$$\n\\frac{\\partial F}{\\partial \\varepsilon_k} = - \\frac{2 I_k p_k \\left( \\mu \\varepsilon_k - \\sum_{b=1}^{B} \\varepsilon_b I_b p_b \\right)}{\\kappa \\left[ \\mu \\sum_{b=1}^{B} \\varepsilon_b^2 I_b p_b - \\left(\\sum_{b=1}^{B} \\varepsilon_b I_b p_b\\right)^2 \\right]^2}\n$$\n梯度向量 $\\nabla_{\\boldsymbol{\\varepsilon}} F$ 是一个行向量，其第 $b$ 个分量由该表达式给出。\n$$\n\\nabla_{\\boldsymbol{\\varepsilon}} F = \\left( \\frac{\\partial F}{\\partial \\varepsilon_1}, \\frac{\\partial F}{\\partial \\varepsilon_2}, \\dots, \\frac{\\partial F}{\\partial \\varepsilon_B} \\right)\n$$\n这可以通过陈述通用的第 $b$ 个分量的表达式来简写，这构成了最终答案。",
            "answer": "$$\n\\boxed{\n\\left( - \\frac{2 I_b p_b \\left( \\mu \\varepsilon_b - \\sum_{j=1}^{B} \\varepsilon_j I_j p_j \\right)}{\\kappa \\left[ \\mu \\sum_{j=1}^{B} \\varepsilon_j^2 I_j p_j - \\left(\\sum_{j=1}^{B} \\varepsilon_j I_j p_j\\right)^2 \\right]^2} \\right)_{b=1, \\dots, B}\n}\n$$"
        }
    ]
}