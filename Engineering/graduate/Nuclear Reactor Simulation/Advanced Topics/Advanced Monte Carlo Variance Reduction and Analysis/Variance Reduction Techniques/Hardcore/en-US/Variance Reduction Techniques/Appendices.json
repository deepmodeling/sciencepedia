{
    "hands_on_practices": [
        {
            "introduction": "Splitting and Russian Roulette are the cornerstones of particle population control in Monte Carlo simulations. This exercise  challenges you to derive the optimal strategy for applying these techniques from first principles. Your goal is to minimize the statistical variance that arises from weight adjustments while strictly preserving the simulation's unbiasedness, uncovering the mathematical foundation for this essential technique.",
            "id": "4259825",
            "problem": "A neutron of weight $w0$ in a Monte Carlo (MC) reactor core simulation enters a region of higher or lower importance characterized by an importance ratio $m0$ relative to the previous region, defined consistently with the adjoint-weighted flux normalization used in reactor physics. To maintain unbiasedness of tallies after population control, the post-event total weight $W_{\\text{out}}$ must satisfy the constraint $\\mathbb{E}[W_{\\text{out}}]=w$. Consider two variance reduction techniques:\n\n1. Splitting for $m \\geq 1$: The number of offspring $N$ is an integer-valued random variable. Each offspring is assigned weight $w/m$, and the total post-event weight is $W_{\\text{out}}=N\\cdot(w/m)$. The pair $(n,p)$ specifies a two-point distribution for $N$, where $N=n$ with probability $1-p$ and $N=n+1$ with probability $p$, with $n \\in \\mathbb{Z}_{\\ge 0}$ and $p \\in [0,1]$.\n\n2. Russian roulette for $0m1$: The number of offspring $N$ is Bernoulli. The particle is killed with probability $1-p$ or survives as one offspring of weight $w/m$ with probability $p$, giving $W_{\\text{out}}=N\\cdot(w/m)$.\n\nStarting from the unbiasedness requirement $\\mathbb{E}[W_{\\text{out}}]=w$, derive the variance $\\mathrm{Var}(W_{\\text{out}})$ for splitting and for Russian roulette. Then, for a fixed ratio $m0$, determine the optimal pair $(n,p)$ that minimizes the variance of $W_{\\text{out}}$ subject to the unbiasedness constraint. Express the final $(n,p)$ in closed form as a function of $m$. The final answer must be a single analytical expression. No rounding is required and no units are needed.",
            "solution": "The problem requires the derivation of the variance of the post-event weight, $W_{\\text{out}}$, for two variance reduction techniques, splitting and Russian roulette, and the determination of the optimal parameters $(n,p)$ that minimize this variance for any given importance ratio $m0$, subject to an unbiasedness constraint.\n\nFirst, we must validate the problem statement.\n\n**Step 1: Extract Givens**\n- Initial neutron weight: $w0$.\n- Importance ratio: $m0$.\n- Post-event total weight: $W_{\\text{out}} = N \\cdot (w/m)$, where $N$ is the number of offspring.\n- Unbiasedness constraint: $\\mathbb{E}[W_{\\text{out}}]=w$.\n- For both splitting and Russian roulette, the number of offspring $N$ is governed by a two-point probability distribution: $N=n$ with probability $1-p$ and $N=n+1$ with probability $p$.\n- The parameters are constrained: $n \\in \\mathbb{Z}_{\\ge 0}$ and $p \\in [0,1]$.\n- Splitting is the case where $m \\geq 1$.\n- Russian roulette is the case where $0  m  1$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is firmly rooted in the established theory of Monte Carlo methods for particle transport, a core topic in nuclear reactor physics and computational physics. Splitting and Russian roulette are standard, well-documented variance reduction techniques. The use of an unbiased estimator, defined by $\\mathbb{E}[W_{\\text{out}}]=w$, is a fundamental principle.\n- **Well-Posedness**: The problem is clearly stated with all necessary definitions, variables, and constraints. The objective to minimize variance subject to these constraints is a standard optimization problem that leads to a well-defined solution.\n- **Objectivity**: The language is precise and mathematical, free of subjective or ambiguous terminology.\n\nThe problem is scientifically sound, self-contained, and objective. It is a valid, well-posed problem in computational physics.\n\n**Solution Derivation**\nThe problem can be solved by treating splitting and Russian roulette within a single, unified framework defined by the two-point distribution for $N$.\n\n1.  **Imposing the Unbiasedness Constraint**\nThe expectation of the post-event weight is $\\mathbb{E}[W_{\\text{out}}] = \\mathbb{E}[N \\cdot \\frac{w}{m}] = \\frac{w}{m} \\mathbb{E}[N]$.\nThe unbiasedness constraint, $\\mathbb{E}[W_{\\text{out}}] = w$, thus requires that the expected number of offspring be equal to the importance ratio:\n$$ \\mathbb{E}[N] = m $$\nThe number of offspring $N$ follows the distribution $P(N=n)=1-p$ and $P(N=n+1)=p$. The expectation of $N$ is:\n$$ \\mathbb{E}[N] = n \\cdot P(N=n) + (n+1) \\cdot P(N=n+1) = n(1-p) + (n+1)p = n - np + np + p = n+p $$\nEquating this with $m$, we obtain a direct relationship between the parameters $n$, $p$, and the importance ratio $m$:\n$$ n+p = m $$\n\n2.  **Deriving the Variance of $W_{\\text{out}}$**\nThe variance of the post-event weight is given by $\\mathrm{Var}(W_{\\text{out}}) = \\mathrm{Var}(N \\cdot \\frac{w}{m})$. Using the property $\\mathrm{Var}(cX) = c^2\\mathrm{Var}(X)$, we have:\n$$ \\mathrm{Var}(W_{\\text{out}}) = \\left(\\frac{w}{m}\\right)^2 \\mathrm{Var}(N) $$\nTo find $\\mathrm{Var}(N)$, we first compute the second moment, $\\mathbb{E}[N^2]$:\n$$ \\mathbb{E}[N^2] = n^2(1-p) + (n+1)^2 p = n^2 - n^2p + (n^2+2n+1)p = n^2 + 2np + p $$\nThe variance of $N$ is $\\mathrm{Var}(N) = \\mathbb{E}[N^2] - (\\mathbb{E}[N])^2$. Substituting the expressions for $\\mathbb{E}[N^2]$ and $\\mathbb{E}[N]=n+p$:\n$$ \\mathrm{Var}(N) = (n^2 + 2np + p) - (n+p)^2 = (n^2 + 2np + p) - (n^2 + 2np + p^2) = p - p^2 = p(1-p) $$\nThus, the variance of the post-event weight is:\n$$ \\mathrm{Var}(W_{\\text{out}}) = \\left(\\frac{w}{m}\\right)^2 p(1-p) $$\n\n3.  **Minimizing the Variance**\nThe goal is to find the pair $(n,p)$ that minimizes $\\mathrm{Var}(W_{\\text{out}})$ subject to the given constraints:\n1.  $n+p = m$\n2.  $n \\in \\mathbb{Z}_{\\ge 0}$ (i.e., $n$ is a non-negative integer)\n3.  $p \\in [0,1]$ (i.e., $p$ is a valid probability)\n\nFrom constraint (1), we have $p = m - n$. Substituting this into constraint (3), we obtain an inequality for $n$:\n$$ 0 \\le m - n \\le 1 $$\nThis is a compound inequality which can be split into two parts:\n- $m - n \\ge 0 \\implies n \\le m$\n- $m - n \\le 1 \\implies n \\ge m - 1$\n\nCombining these with the constraint that $n$ must be a non-negative integer, we find that $n$ must be a non-negative integer satisfying $m-1 \\le n \\le m$.\n\nLet us analyze the possible integer values for $n$.\n- If $m$ is not an integer, the interval $(m-1, m)$ has a length of $1$ and contains exactly one integer. This integer must be $\\lfloor m \\rfloor$. Therefore, the choice for $n$ is uniquely determined as $n = \\lfloor m \\rfloor$. Consequently, $p$ is also uniquely determined as $p = m - \\lfloor m \\rfloor$. Since this is the only value of $(n,p)$ that satisfies all constraints, it is trivially the optimal solution.\n- If $m$ is an integer, the interval $[m-1, m]$ contains two integers: $n=m-1$ and $n=m$ (assuming $m \\ge 1$, which is true for integer values in the splitting regime).\n    - If we choose $n=m$, then $p = m-m=0$. The variance becomes $\\mathrm{Var}(W_{\\text{out}}) = (\\frac{w}{m})^2 \\cdot 0 \\cdot (1-0) = 0$.\n    - If we choose $n=m-1$, then $p = m-(m-1)=1$. The variance becomes $\\mathrm{Var}(W_{\\text{out}}) = (\\frac{w}{m})^2 \\cdot 1 \\cdot (1-1) = 0$.\nBoth choices yield a variance of $0$, which is the absolute minimum possible. Thus, both are optimal solutions.\n\nThe problem asks for a single analytical expression for the optimal pair $(n,p)$ for any $m0$. The expression $n = \\lfloor m \\rfloor$ provides a valid and optimal choice in all cases. For non-integer $m$, it is the only choice. For integer $m$, it gives $n=m$, which is one of the two zero-variance solutions.\n\nTherefore, the general optimal choice for $n$ is:\n$$ n = \\lfloor m \\rfloor $$\nThe corresponding optimal value for $p$ is determined by the unbiasedness condition $p = m-n$:\n$$ p = m - \\lfloor m \\rfloor $$\nThis single pair of expressions provides the optimal parameters for the entire range $m  0$.\n- For **splitting** ($m \\ge 1$), we have $n = \\lfloor m \\rfloor \\ge 1$.\n- For **Russian roulette** ($0  m  1$), we have $n = \\lfloor m \\rfloor = 0$. This reduces the two-point distribution for $N$ to $P(N=0)=1-p$ and $P(N=1)=p$. With $p=m-0=m$, this becomes $P(N=1)=m$ and $P(N=0)=1-m$, consistent with the standard formulation of Russian roulette where the survival probability is equal to the importance ratio.\n\nThe optimal pair $(n,p)$ is a function of $m$ only.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\lfloor m \\rfloor  m - \\lfloor m \\rfloor \\end{pmatrix} } $$"
        },
        {
            "introduction": "We can reduce variance not just by managing particle populations, but by ensuring each history contributes more information. This practice  explores survival biasing, a technique where absorption is treated implicitly by reducing a particle's weight instead of terminating its history. You will quantify its powerful effect on the variance of common estimators, revealing the conditions under which it can be a near-perfect variance reduction method.",
            "id": "4259769",
            "problem": "Consider a one-speed neutron history in an infinite, homogeneous medium characterized by macroscopic absorption cross section $\\Sigma_{a}  0$ and macroscopic scattering cross section $\\Sigma_{s} \\ge 0$, so that the total macroscopic cross section is $\\Sigma_{t} = \\Sigma_{a} + \\Sigma_{s}$. A single neutron of initial statistical weight $1$ is born at an arbitrary location with an isotropic direction. Assume a standard Monte Carlo (MC) free-flight model: segment lengths $\\ell$ are independent and identically distributed with probability density $p(\\ell) = \\Sigma_{t} \\exp(-\\Sigma_{t} \\ell)$, and, in analog transport, each collision is absorption with probability $\\Sigma_{a}/\\Sigma_{t}$ and scattering with probability $\\Sigma_{s}/\\Sigma_{t}$. The scalar flux integrated over all space is tallied using either the collision estimator or the track-length estimator per history, defined as follows:\n\n- Collision estimator: Each collision contributes $w/\\Sigma_{t}$ to the tally, where $w$ is the particle’s current statistical weight at that collision.\n- Track-length estimator: Each free-flight segment contributes $w \\ell$ to the tally, where $w$ is the particle’s current statistical weight during that segment.\n\nNow apply survival biasing (also called implicit capture): at every collision, force a scattering event and reduce the particle’s weight by the factor $c = \\Sigma_{s}/\\Sigma_{t}$, with no termination. Under this scheme, the collision estimator and track-length estimator are modified by the geometric weight sequence $1, c, c^{2}, \\ldots$, applied at successive collisions and the intervening flight segments.\n\nStarting only from the stated free-flight law and event selection probabilities, and using basic probability facts about independent sums and simple discrete distributions, derive for a single history in this infinite medium:\n\n(i) The expectation and variance of the collision estimator and of the track-length estimator under analog transport.\n\n(ii) The expectation and variance of the collision estimator and of the track-length estimator under survival biasing.\n\nThen, form the ratios\n$$\nR_{\\mathrm{TL}} = \\frac{\\operatorname{Var}_{\\mathrm{SB}}(\\Phi_{\\mathrm{TL}})}{\\operatorname{Var}_{\\mathrm{AN}}(\\Phi_{\\mathrm{TL}})}, \n\\qquad\nR_{\\mathrm{C}} = \\frac{\\operatorname{Var}_{\\mathrm{SB}}(\\Phi_{\\mathrm{C}})}{\\operatorname{Var}_{\\mathrm{AN}}(\\Phi_{\\mathrm{C}})},\n$$\nwhere $\\Phi_{\\mathrm{TL}}$ and $\\Phi_{\\mathrm{C}}$ are the per-history track-length and collision flux estimators, respectively, and the subscripts $\\mathrm{SB}$ and $\\mathrm{AN}$ denote survival biasing and analog transport. Express your final answer as a single row matrix whose first entry is $R_{\\mathrm{TL}}$ and whose second entry is $R_{\\mathrm{C}}$, in closed form as analytic functions of $\\Sigma_{a}$ and $\\Sigma_{s}$. No numerical approximation or rounding is required, and no units need be reported.",
            "solution": "The problem statement has been validated and is deemed a well-posed, scientifically grounded problem in the field of Monte Carlo methods for particle transport. We proceed with the derivation.\n\nLet the macroscopic scattering and absorption cross sections be $\\Sigma_s$ and $\\Sigma_a$, respectively. The total cross section is $\\Sigma_t = \\Sigma_a + \\Sigma_s$. The survival probability per collision, which is the probability of scattering, is $c = \\Sigma_s / \\Sigma_t$. The absorption probability is $1-c = \\Sigma_a / \\Sigma_t$. The problem states $\\Sigma_a  0$, which implies $c  1$.\n\nA particle's free-flight segment length, $\\ell$, is a random variable $L$ following an exponential distribution with parameter $\\Sigma_t$. The probability density function is $p(\\ell) = \\Sigma_t \\exp(-\\Sigma_t \\ell)$ for $\\ell \\ge 0$. The expectation and variance of the flight path length are:\n$$\n\\operatorname{E}[L] = \\frac{1}{\\Sigma_t}\n$$\n$$\n\\operatorname{Var}(L) = \\frac{1}{\\Sigma_t^2}\n$$\nFrom this, we can also find the second moment:\n$$\n\\operatorname{E}[L^2] = \\operatorname{Var}(L) + (\\operatorname{E}[L])^2 = \\frac{1}{\\Sigma_t^2} + \\left(\\frac{1}{\\Sigma_t}\\right)^2 = \\frac{2}{\\Sigma_t^2}\n$$\n\n**Part (i): Analog Transport**\n\nIn analog transport, a particle history terminates upon absorption. Let $N$ be the random variable representing the total number of collisions a particle undergoes. The history continues as long as the particle scatters. The probability of scattering at a collision is $c$. The probability of being absorbed at collision $k$ is the probability of surviving the first $k-1$ collisions and then being absorbed at the $k$-th, which is $c^{k-1}(1-c)$.\nThus, $N$ follows a geometric distribution with success parameter $p=1-c$.\nThe probability mass function is $P(N=k) = c^{k-1}(1-c)$ for $k=1, 2, \\ldots$.\nThe expectation and variance of $N$ are:\n$$\n\\operatorname{E}[N] = \\frac{1}{1-c} = \\frac{1}{\\Sigma_a / \\Sigma_t} = \\frac{\\Sigma_t}{\\Sigma_a}\n$$\n$$\n\\operatorname{Var}(N) = \\frac{c}{(1-c)^2} = \\frac{\\Sigma_s / \\Sigma_t}{(\\Sigma_a / \\Sigma_t)^2} = \\frac{\\Sigma_s \\Sigma_t}{\\Sigma_a^2}\n$$\n\n**Analog Collision Estimator ($\\Phi_{\\mathrm{C,AN}}$)**\nIn analog transport, the particle weight $w$ is always $1$. The score from each collision is $1/\\Sigma_t$. For a history with $N$ collisions, the total score is:\n$$\n\\Phi_{\\mathrm{C,AN}} = \\sum_{i=1}^{N} \\frac{1}{\\Sigma_t} = \\frac{N}{\\Sigma_t}\n$$\nThe expectation is:\n$$\n\\operatorname{E}[\\Phi_{\\mathrm{C,AN}}] = \\operatorname{E}\\left[\\frac{N}{\\Sigma_t}\\right] = \\frac{1}{\\Sigma_t} \\operatorname{E}[N] = \\frac{1}{\\Sigma_t} \\frac{\\Sigma_t}{\\Sigma_a} = \\frac{1}{\\Sigma_a}\n$$\nThe variance is:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{C,AN}}) = \\operatorname{Var}\\left(\\frac{N}{\\Sigma_t}\\right) = \\frac{1}{\\Sigma_t^2} \\operatorname{Var}(N) = \\frac{1}{\\Sigma_t^2} \\frac{\\Sigma_s \\Sigma_t}{\\Sigma_a^2} = \\frac{\\Sigma_s}{\\Sigma_t \\Sigma_a^2} = \\frac{\\Sigma_s}{(\\Sigma_a + \\Sigma_s) \\Sigma_a^2}\n$$\n\n**Analog Track-Length Estimator ($\\Phi_{\\mathrm{TL,AN}}$)**\nThe score from each flight segment of length $L_i$ is $w \\ell = \\ell$. A history with $N$ collisions consists of $N$ flight segments $L_1, \\ldots, L_N$. The total score is the sum of these lengths:\n$$\n\\Phi_{\\mathrm{TL,AN}} = \\sum_{i=1}^{N} L_i\n$$\nThis is a sum of a random number of i.i.d. random variables. The expectation is given by Wald's identity:\n$$\n\\operatorname{E}[\\Phi_{\\mathrm{TL,AN}}] = \\operatorname{E}[N] \\operatorname{E}[L] = \\left(\\frac{\\Sigma_t}{\\Sigma_a}\\right) \\left(\\frac{1}{\\Sigma_t}\\right) = \\frac{1}{\\Sigma_a}\n$$\nThe variance is given by the Blackwell-Girshick equation (a consequence of the law of total variance):\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,AN}}) = \\operatorname{E}[N] \\operatorname{Var}(L) + (\\operatorname{E}[L])^2 \\operatorname{Var}(N)\n$$\nSubstituting the known values:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,AN}}) = \\left(\\frac{\\Sigma_t}{\\Sigma_a}\\right) \\left(\\frac{1}{\\Sigma_t^2}\\right) + \\left(\\frac{1}{\\Sigma_t}\\right)^2 \\left(\\frac{\\Sigma_s \\Sigma_t}{\\Sigma_a^2}\\right) = \\frac{1}{\\Sigma_a \\Sigma_t} + \\frac{\\Sigma_s}{\\Sigma_t \\Sigma_a^2}\n$$\nCombining terms with a common denominator $\\Sigma_t \\Sigma_a^2$:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,AN}}) = \\frac{\\Sigma_a}{\\Sigma_t \\Sigma_a^2} + \\frac{\\Sigma_s}{\\Sigma_t \\Sigma_a^2} = \\frac{\\Sigma_a + \\Sigma_s}{\\Sigma_t \\Sigma_a^2} = \\frac{\\Sigma_t}{\\Sigma_t \\Sigma_a^2} = \\frac{1}{\\Sigma_a^2}\n$$\n\n**Part (ii): Survival Biasing**\n\nUnder survival biasing, every collision is forced to be a scatter event, and the particle's weight is reduced. The weight before the $k$-th collision (and during the $k$-th flight segment) is $w_k = c^{k-1}$, starting with $w_1=1$. The history is an infinite sequence of flights and collisions.\n\n**Survival Biasing Collision Estimator ($\\Phi_{\\mathrm{C,SB}}$)**\nThe score at the $k$-th collision is $w_k/\\Sigma_t = c^{k-1}/\\Sigma_t$. The total score is the sum over all (infinite) collisions:\n$$\n\\Phi_{\\mathrm{C,SB}} = \\sum_{k=1}^{\\infty} \\frac{w_k}{\\Sigma_t} = \\sum_{k=1}^{\\infty} \\frac{c^{k-1}}{\\Sigma_t}\n$$\nThis is a deterministic geometric series. As $c  1$, it converges:\n$$\n\\Phi_{\\mathrm{C,SB}} = \\frac{1}{\\Sigma_t} \\sum_{j=0}^{\\infty} c^j = \\frac{1}{\\Sigma_t} \\frac{1}{1-c} = \\frac{1}{\\Sigma_t} \\frac{1}{\\Sigma_a/\\Sigma_t} = \\frac{1}{\\Sigma_a}\n$$\nSince the score for any history is a constant value $1/\\Sigma_a$, the estimator is free of statistical fluctuation.\nThe expectation is:\n$$\n\\operatorname{E}[\\Phi_{\\mathrm{C,SB}}] = \\operatorname{E}\\left[\\frac{1}{\\Sigma_a}\\right] = \\frac{1}{\\Sigma_a}\n$$\nThe variance is:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{C,SB}}) = \\operatorname{Var}\\left(\\frac{1}{\\Sigma_a}\\right) = 0\n$$\n\n**Survival Biasing Track-Length Estimator ($\\Phi_{\\mathrm{TL,SB}}$)**\nThe score from the $k$-th flight segment of length $L_k$ is $w_k L_k = c^{k-1}L_k$. The total score is the sum over all segments:\n$$\n\\Phi_{\\mathrm{TL,SB}} = \\sum_{k=1}^{\\infty} w_k L_k = \\sum_{k=1}^{\\infty} c^{k-1} L_k\n$$\nwhere the $L_k$ are i.i.d. exponential random variables. The expectation is:\n$$\n\\operatorname{E}[\\Phi_{\\mathrm{TL,SB}}] = \\operatorname{E}\\left[\\sum_{k=1}^{\\infty} c^{k-1} L_k\\right] = \\sum_{k=1}^{\\infty} c^{k-1} \\operatorname{E}[L_k] = \\operatorname{E}[L] \\sum_{k=1}^{\\infty} c^{k-1} = \\frac{1}{\\Sigma_t} \\frac{1}{1-c} = \\frac{1}{\\Sigma_a}\n$$\nSince the terms in the sum are independent random variables, the variance of the sum is the sum of the variances:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,SB}}) = \\operatorname{Var}\\left(\\sum_{k=1}^{\\infty} c^{k-1} L_k\\right) = \\sum_{k=1}^{\\infty} \\operatorname{Var}(c^{k-1} L_k) = \\sum_{k=1}^{\\infty} (c^{k-1})^2 \\operatorname{Var}(L_k)\n$$\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,SB}}) = \\operatorname{Var}(L) \\sum_{k=1}^{\\infty} (c^2)^{k-1} = \\frac{1}{\\Sigma_t^2} \\sum_{j=0}^{\\infty} (c^2)^j\n$$\nThe series is a geometric series with ratio $c^2  1$, so it converges:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,SB}}) = \\frac{1}{\\Sigma_t^2} \\frac{1}{1-c^2} = \\frac{1}{\\Sigma_t^2(1 - (\\Sigma_s/\\Sigma_t)^2)} = \\frac{1}{\\Sigma_t^2 - \\Sigma_s^2}\n$$\nUsing $\\Sigma_t = \\Sigma_a + \\Sigma_s$, the denominator becomes:\n$$\n\\Sigma_t^2 - \\Sigma_s^2 = (\\Sigma_a+\\Sigma_s)^2 - \\Sigma_s^2 = \\Sigma_a^2 + 2\\Sigma_a\\Sigma_s + \\Sigma_s^2 - \\Sigma_s^2 = \\Sigma_a^2 + 2\\Sigma_a\\Sigma_s = \\Sigma_a(\\Sigma_a + 2\\Sigma_s)\n$$\nTherefore, the variance is:\n$$\n\\operatorname{Var}(\\Phi_{\\mathrm{TL,SB}}) = \\frac{1}{\\Sigma_a(\\Sigma_a + 2\\Sigma_s)}\n$$\n\n**Part (iii): Variance Ratios**\n\nWe now form the required ratios using the variances derived above.\n\nRatio for the track-length estimator:\n$$\nR_{\\mathrm{TL}} = \\frac{\\operatorname{Var}_{\\mathrm{SB}}(\\Phi_{\\mathrm{TL}})}{\\operatorname{Var}_{\\mathrm{AN}}(\\Phi_{\\mathrm{TL}})} = \\frac{1 / (\\Sigma_a(\\Sigma_a + 2\\Sigma_s))}{1 / \\Sigma_a^2} = \\frac{\\Sigma_a^2}{\\Sigma_a(\\Sigma_a + 2\\Sigma_s)} = \\frac{\\Sigma_a}{\\Sigma_a + 2\\Sigma_s}\n$$\n\nRatio for the collision estimator:\n$$\nR_{\\mathrm{C}} = \\frac{\\operatorname{Var}_{\\mathrm{SB}}(\\Phi_{\\mathrm{C}})}{\\operatorname{Var}_{\\mathrm{AN}}(\\Phi_{\\mathrm{C}})} = \\frac{0}{\\Sigma_s / ((\\Sigma_a + \\Sigma_s) \\Sigma_a^2)}\n$$\nGiven $\\Sigma_a  0$. If $\\Sigma_s  0$, the denominator is non-zero, so $R_{\\mathrm{C}} = 0$. If $\\Sigma_s = 0$, the numerator and denominator are both $0$. However, the expression must apply for all $\\Sigma_s \\ge 0$. As $\\Sigma_s \\to 0^+$, the ratio remains $0$. Thus, we define $R_{\\mathrm{C}} = 0$ for all valid parameters.\n\nThe final results for the ratios are $R_{\\mathrm{TL}} = \\frac{\\Sigma_a}{\\Sigma_a + 2\\Sigma_s}$ and $R_{\\mathrm{C}} = 0$.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{\\Sigma_a}{\\Sigma_a + 2\\Sigma_s}  0 \\end{pmatrix} } $$"
        },
        {
            "introduction": "Effective variance reduction often involves biasing the underlying physics to preferentially sample 'important' events that are more likely to contribute to the final answer. This hands-on coding challenge  guides you through implementing exponential angular biasing, a powerful technique for deep-penetration shielding problems. By writing code to numerically compare the biased simulation's variance against the analog case, you will directly experience how importance sampling can dramatically improve simulation efficiency.",
            "id": "4259798",
            "problem": "A fast-neutron point detector is located immediately downstream of a plane-parallel hydrogenous shield of thickness $L$ oriented normal to the $z$-axis. A collimated, monoenergetic, forward-directed source impinges on the upstream face at $z=0$. Consider a single-collision approximation in which each neutron undergoes exactly one elastic collision within the slab and then streams without further interaction to the exit at $z=L$. The shield is homogeneous with macroscopic total cross section $\\Sigma_t$. The angular cosine of the post-collision neutron direction relative to the $+z$ axis is denoted by $\\mu \\in [-1,1]$. Only $\\mu0$ particles can contribute to the downstream detector that records neutrons crossing the plane $z=L$ after their single scatter.\n\nAssume the laboratory-frame scattering angular probability density function (PDF) on $\\mu \\in [-1,1]$ is represented by the first-order anisotropy model\n$$\np_0(\\mu) = \\frac{1 + a \\mu}{2},\n$$\nwhere $a \\in [-1,1]$ is the anisotropy parameter that encodes material and energy effects. In the hydrogenous shield at fast energies, a mixture of Hydrogen and Carbon yields values of $a$ spanning near-isotropic to forward-peaked scattering. Restricting to $\\mu \\in [0,1]$, define the renormalized physical (analog) post-scatter PDF\n$$\np_0^+(\\mu) = \\frac{1 + a \\mu}{1 + \\frac{a}{2}}, \\quad \\mu \\in [0,1].\n$$\nWithin the single-collision approximation, for a collision at depth $x \\in [0,L]$, the free-flight path length to the exit is $(L-x)/\\mu$ for $\\mu0$, giving the survival probability $\\exp\\!\\left(-\\Sigma_t \\frac{L-x}{\\mu}\\right)$. Averaging uniformly over collision depth $x$, the acceptance-survival factor is\n$$\ng(\\mu; L, \\Sigma_t) = \\frac{1}{L} \\int_0^L \\exp\\!\\left(-\\Sigma_t \\frac{L-x}{\\mu}\\right) \\, dx = \n\\begin{cases}\n\\frac{\\mu}{\\Sigma_t L} \\left(1 - \\exp\\!\\left(-\\frac{\\Sigma_t L}{\\mu}\\right)\\right),  \\mu  0,\\\\\n0,  \\mu \\le 0.\n\\end{cases}\n$$\n\nVariance reduction by importance sampling seeks a biasing angular PDF $q(\\mu)$ to sample $\\mu$ while maintaining an unbiased estimator $w(\\mu) = \\frac{p_0^+(\\mu)}{q(\\mu)} g(\\mu;L,\\Sigma_t)$ for the detector response\n$$\nS(L,\\Sigma_t,a) = \\int_0^1 p_0^+(\\mu) \\, g(\\mu;L,\\Sigma_t) \\, d\\mu.\n$$\nThe zero-variance solution targets $q(\\mu) \\propto p_0^+(\\mu) g(\\mu;L,\\Sigma_t)$, which is not directly accessible in practice. A physically motivated parametric family that emphasizes forward-peaked paths is the exponential angular bias\n$$\nq_\\beta(\\mu) = \n\\begin{cases}\n\\displaystyle \\frac{\\beta}{e^{\\beta}-1} \\, e^{\\beta \\mu},  \\beta \\ne 0 \\\\\n1,  \\beta = 0\n\\end{cases}, \\quad \\mu \\in [0,1],\n$$\nwhere $\\beta \\ge 0$ tunes the forward emphasis (larger $\\beta$ increases forward-peaking). This functional form is justified by approximating the adjoint flux toward a downstream detector, which increases with larger $\\mu$ due to reduced path length and attenuation, and by the ubiquity of exponential tilting in importance sampling for transport problems.\n\nFor any fixed $(L,\\Sigma_t,a,\\beta)$, the variance of the unbiased estimator under $q_\\beta$ is\n$$\n\\operatorname{Var}_{q_\\beta}[w] = \\mathbb{E}_{q_\\beta}\\!\\left[w(\\mu)^2\\right] - S(L,\\Sigma_t,a)^2\n= \\int_0^1 \\frac{p_0^+(\\mu)^2 \\, g(\\mu;L,\\Sigma_t)^2}{q_\\beta(\\mu)} \\, d\\mu \\;-\\; S(L,\\Sigma_t,a)^2.\n$$\nThe analog (no-bias) variance, obtained by sampling $\\mu$ from $p_0^+(\\mu)$ and using the estimator $g(\\mu;L,\\Sigma_t)$, is\n$$\n\\operatorname{Var}_{\\text{analog}}[g] = \\int_0^1 p_0^+(\\mu) \\, g(\\mu;L,\\Sigma_t)^2 \\, d\\mu \\;-\\; S(L,\\Sigma_t,a)^2.\n$$\nDefine the relative variance ratio\n$$\nR(L,\\Sigma_t,a,\\beta) = \\frac{\\operatorname{Var}_{q_\\beta}[w]}{\\operatorname{Var}_{\\text{analog}}[g]},\n$$\nwhich is dimensionless. Values $R1$ indicate improvement relative to analog sampling.\n\nYour task is to write a complete, runnable program that, for the test suite below, computes $R(L,\\Sigma_t,a,\\beta)$ via numerical integration on $\\mu \\in [0,1]$ using stable quadrature. Handle the limiting behavior of $g(\\mu;L,\\Sigma_t)$ near $\\mu \\to 0^+$ in a numerically robust manner. All lengths must be expressed in centimeters (cm); all cross sections in inverse centimeters ($\\text{cm}^{-1}$). Angles are represented by the dimensionless cosine $\\mu$.\n\nTest suite parameter sets $(L,\\Sigma_t,a,\\beta)$:\n1. $(20 \\text{ cm}, 0.10 \\text{ cm}^{-1}, 0.20, 2.0)$\n2. $(50 \\text{ cm}, 0.20 \\text{ cm}^{-1}, 0.00, 3.0)$\n3. $(20 \\text{ cm}, 0.10 \\text{ cm}^{-1}, -0.30, 2.0)$\n4. $(20 \\text{ cm}, 0.10 \\text{ cm}^{-1}, 0.20, 0.0)$\n5. $(30 \\text{ cm}, 0.15 \\text{ cm}^{-1}, -0.80, 6.0)$\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"). Each result must be a floating-point number rounded to six decimal places.",
            "solution": "The problem is valid as it is scientifically grounded in neutron transport theory and Monte Carlo methods, is mathematically well-posed, and provides a complete and consistent set of definitions and parameters. The task is to compute the relative variance ratio, $R(L,\\Sigma_t,a,\\beta)$, which quantifies the effectiveness of an exponential biasing importance sampling scheme compared to an analog simulation for a simplified radiation shielding problem. The solution requires the numerical evaluation of three distinct integrals over the post-collision angular cosine, $\\mu \\in [0,1]$.\n\nThe core of the problem is to compute the ratio of two variances:\n$$\nR(L,\\Sigma_t,a,\\beta) = \\frac{\\operatorname{Var}_{q_\\beta}[w]}{\\operatorname{Var}_{\\text{analog}}[g]} = \\frac{\\int_0^1 \\frac{p_0^+(\\mu)^2 \\, g(\\mu;L,\\Sigma_t)^2}{q_\\beta(\\mu)} \\, d\\mu \\;-\\; S(L,\\Sigma_t,a)^2}{\\int_0^1 p_0^+(\\mu) \\, g(\\mu;L,\\Sigma_t)^2 \\, d\\mu \\;-\\; S(L,\\Sigma_t,a)^2}.\n$$\nThis computation proceeds in three main steps: defining the necessary functions, evaluating the integrals numerically, and combining the results.\n\nFirst, we must implement the mathematical functions provided in the problem statement. The renormalized physical post-scatter probability density function (PDF) for forward-scattered neutrons ($\\mu  0$) is:\n$$\np_0^+(\\mu) = \\frac{1 + a \\mu}{1 + a/2}, \\quad \\mu \\in [0,1].\n$$\nThe parameter $a$ is restricted to $[-1,1]$, ensuring the denominator $1+a/2$ is always positive, ranging from $1/2$ to $3/2$.\n\nThe acceptance-survival factor, $g(\\mu; L, \\Sigma_t)$, represents the probability that a neutron scattering at a random depth in the slab will reach the exit plane without another collision. Its form is:\n$$\ng(\\mu; L, \\Sigma_t) = \\frac{\\mu}{\\Sigma_t L} \\left(1 - \\exp\\left(-\\frac{\\Sigma_t L}{\\mu}\\right)\\right), \\quad \\mu  0.\n$$\nFor numerical stability, we must consider the behavior as $\\mu \\to 0^+$. In this limit, the argument of the exponential, $-\\frac{\\Sigma_t L}{\\mu}$, becomes large and negative, causing $\\exp(-\\frac{\\Sigma_t L}{\\mu})$ to underflow to zero in floating-point arithmetic. The function then safely simplifies to $g(\\mu; L, \\Sigma_t) \\approx \\frac{\\mu}{\\Sigma_t L}$. The value at $\\mu=0$ is exactly $0$, ensuring the function is continuous. A robust implementation will switch to the linear approximation for very small $\\mu$ to avoid numerical issues. For convenience, we define the optical thickness $\\tau = \\Sigma_t L$.\n\nThe exponential biasing PDF, $q_\\beta(\\mu)$, is a parametric function used for importance sampling:\n$$\nq_\\beta(\\mu) = \n\\begin{cases}\n\\displaystyle \\frac{\\beta}{e^{\\beta}-1} \\, e^{\\beta \\mu},  \\beta \\ne 0,\\\\\n1,  \\beta = 0,\n\\end{cases}\n\\quad \\mu \\in [0,1].\n$$\nThis function is properly normalized over $\\mu \\in [0,1]$. The special case $\\beta=0$ corresponds to uniform importance sampling, which is distinct from the physical (analog) sampling from $p_0^+(\\mu)$.\n\nSecond, we formulate the three integrals required for the calculation of $R$.\n1. The expected detector response, $S$, is the first moment of the analog estimator $g(\\mu)$ with respect to the physical PDF $p_0^+(\\mu)$:\n$$\nS(L,\\Sigma_t,a) = \\mathbb{E}_{p_0^+}[g] = \\int_0^1 p_0^+(\\mu) \\, g(\\mu;L,\\Sigma_t) \\, d\\mu.\n$$\n2. The second moment of the biased estimator, $w(\\mu) = \\frac{p_0^+(\\mu)}{q_\\beta(\\mu)} g(\\mu)$, is required for the numerator variance:\n$$\n\\mathbb{E}_{q_\\beta}[w^2] = \\int_0^1 w(\\mu)^2 q_\\beta(\\mu) \\, d\\mu = \\int_0^1 \\frac{\\left(p_0^+(\\mu) \\, g(\\mu;L,\\Sigma_t)\\right)^2}{q_\\beta(\\mu)} \\, d\\mu.\n$$\n3. The second moment of the analog estimator is required for the denominator variance:\n$$\n\\mathbb{E}_{\\text{analog}}[g^2] = \\mathbb{E}_{p_0^+}[g^2] = \\int_0^1 g(\\mu;L,\\Sigma_t)^2 \\, p_0^+(\\mu) \\, d\\mu.\n$$\nThese are all definite integrals of well-behaved, continuous functions over a finite domain $[0,1]$, making them suitable for standard numerical quadrature methods.\n\nThird, using the results of the numerical integrations, we compute the variances and their ratio. The variance of the biased estimator is:\n$$\n\\operatorname{Var}_{q_\\beta}[w] = \\mathbb{E}_{q_\\beta}[w^2] - S^2.\n$$\nNote that the expectation of the biased estimator is $\\mathbb{E}_{q_\\beta}[w] = \\int_0^1 \\frac{p_0^+(\\mu)}{q_\\beta(\\mu)} g(\\mu) q_\\beta(\\mu) d\\mu = S$, confirming it is an unbiased estimator. The variance of the analog estimator is:\n$$\n\\operatorname{Var}_{\\text{analog}}[g] = \\mathbb{E}_{\\text{analog}}[g^2] - S^2.\n$$\nThe final relative variance ratio is then calculated as $R = \\operatorname{Var}_{q_\\beta}[w] / \\operatorname{Var}_{\\text{analog}}[g]$. The implementation will systematically apply this procedure to each parameter set in the test suite, using a high-quality numerical integration routine to ensure accuracy.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Computes the relative variance ratio R for a simplified neutron transport problem\n    using an exponential biasing importance sampling scheme.\n    \"\"\"\n\n    def p_plus(mu: float, a: float) - float:\n        \"\"\"\n        Renormalized physical post-scatter PDF for mu in [0,1].\n        p_0^+(\\mu) = (1 + a*\\mu) / (1 + a/2)\n        \"\"\"\n        if not (0.0 = mu = 1.0):\n            return 0.0\n        # The constraint a in [-1, 1] ensures the denominator is non-zero.\n        return (1.0 + a * mu) / (1.0 + a / 2.0)\n\n    def g_func(mu: float, tau: float) - float:\n        \"\"\"\n        Acceptance-survival factor, g(\\mu; L, \\Sigma_t).\n        g = (\\mu / \\tau) * (1 - exp(-\\tau / \\mu))\n        tau is the optical thickness L * Sigma_t.\n        \"\"\"\n        if mu = 1e-12: # For mu - 0+, g - 0\n            return 0.0\n        \n        arg = tau / mu\n        # Use approximation for large arg to avoid underflow of exp(-arg)\n        # exp(-709) is near the limit of float64 precision.\n        if arg  709.0:\n            return mu / tau\n        else:\n            return (mu / tau) * (1.0 - np.exp(-arg))\n\n    def q_beta(mu: float, beta: float) - float:\n        \"\"\"\n        Exponential biasing PDF for importance sampling.\n        q_\\beta(\\mu)\n        \"\"\"\n        if not (0.0 = mu = 1.0):\n            return 0.0\n            \n        if abs(beta)  1e-9: # Case beta = 0\n            return 1.0\n        else:\n            # The constraint beta = 0 ensures the denominator is non-zero.\n            return (beta / (np.exp(beta) - 1.0)) * np.exp(beta * mu)\n\n    def calculate_R(L: float, Sigma_t: float, a: float, beta: float) - float:\n        \"\"\"\n        Calculates the relative variance ratio R for a given set of parameters.\n        \"\"\"\n        tau = L * Sigma_t\n\n        # Integrands for the three required integrals\n        # I1: S = E_p+[g]\n        integrand_S = lambda mu: p_plus(mu, a) * g_func(mu, tau)\n        \n        # I2: E_q[w^2] = integral of (p+ * g)^2 / q_beta\n        integrand_E_w_sq = lambda mu: (p_plus(mu, a) * g_func(mu, tau))**2 / q_beta(mu, beta)\n        \n        # I3: E_analog[g^2] = E_p+[g^2]\n        integrand_E_g_sq = lambda mu: p_plus(mu, a) * (g_func(mu, tau))**2\n\n        # Perform numerical integrations using scipy.integrate.quad\n        S, _ = quad(integrand_S, 0, 1, epsabs=1e-12, epsrel=1e-12)\n        E_w_sq, _ = quad(integrand_E_w_sq, 0, 1, epsabs=1e-12, epsrel=1e-12)\n        E_g_sq, _ = quad(integrand_E_g_sq, 0, 1, epsabs=1e-12, epsrel=1e-12)\n\n        # Calculate variances\n        var_q_beta = E_w_sq - S**2\n        var_analog = E_g_sq - S**2\n\n        # Calculate the relative variance ratio\n        # Avoid division by zero if analog variance is negligible\n        if abs(var_analog)  1e-30:\n            # If both variances are zero, the performance is identical (R=1).\n            # If only analog variance is zero, the ratio is infinite.\n            # This case is unlikely given the physical context.\n            return 1.0 if abs(var_q_beta)  1e-30 else np.inf\n        \n        R = var_q_beta / var_analog\n        return R\n\n    # Define the test cases from the problem statement.\n    # (L, Sigma_t, a, beta)\n    test_cases = [\n        (20.0, 0.10, 0.20, 2.0),\n        (50.0, 0.20, 0.00, 3.0),\n        (20.0, 0.10, -0.30, 2.0),\n        (20.0, 0.10, 0.20, 0.0),\n        (30.0, 0.15, -0.80, 6.0)\n    ]\n\n    results = []\n    for case in test_cases:\n        L, Sigma_t, a, beta = case\n        result = calculate_R(L, Sigma_t, a, beta)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}