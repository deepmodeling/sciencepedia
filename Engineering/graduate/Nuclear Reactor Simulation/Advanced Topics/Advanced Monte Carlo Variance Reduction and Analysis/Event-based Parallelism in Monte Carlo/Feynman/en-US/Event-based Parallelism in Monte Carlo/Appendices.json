{
    "hands_on_practices": [
        {
            "introduction": "The first step in optimizing any massively parallel computation is ensuring that the work assigned to the processor is large enough to make the effort worthwhile. On architectures like GPUs, launching a computational kernel incurs a fixed time overhead, regardless of the amount of work. This practice guides you through creating a simple but powerful performance model to determine the minimum batch size needed to amortize this overhead and achieve a target computational efficiency, a fundamental balance in designing high-throughput event-based systems. ",
            "id": "4224488",
            "problem": "In an event-based Monte Carlo neutron transport kernel used for nuclear reactor simulation on a graphics processing unit (GPU), a batch of $N$ events is processed per kernel launch. Each launch incurs a fixed kernel-launch overhead time $\\tau_k$ and each event in the batch requires a constant compute time $c$. Define the efficiency $\\eta(N)$ of a batch as the ratio of useful per-event compute time to the total wall-clock time for the batch. Using only the foundational definitions that (i) overhead adds a constant time $\\tau_k$ independent of $N$, (ii) the per-event compute time accumulates linearly as $N c$, and (iii) efficiency is the ratio of useful compute time to the total time, derive the minimal integer batch size $N_{\\min}$ that guarantees a target efficiency $\\eta$ with $0\\eta1$.\n\nThen, for a specific reactor-physics throughput target, take $\\tau_k = 8.0\\,\\mu\\mathrm{s}$, $c = 25\\,\\mathrm{ns}$, and $\\eta = 0.9$. Compute the minimal integer batch size $N_{\\min}$ that meets the target efficiency, and validate your result by evaluating the efficiency at $N_{\\min}$ using the simple timing model implied by the definitions. Express the final answer as an integer with no units.",
            "solution": "Following the provided definitions, we first formalize the expression for efficiency, $\\eta(N)$. The \"useful per-event compute time\" for a batch of $N$ events is the total time spent on computation, which is the product of the number of events and the time per event.\nLet $T_{\\text{compute}}$ be the total useful compute time. Based on definition (ii):\n$$T_{\\text{compute}}(N) = N c$$\n\nThe \"total wall-clock time for the batch\", let's call it $T_{\\text{total}}(N)$, is the sum of the useful compute time and the fixed kernel-launch overhead. Based on definitions (i) and (ii):\n$$T_{\\text{total}}(N) = T_{\\text{compute}}(N) + \\tau_k = N c + \\tau_k$$\n\nThe efficiency $\\eta(N)$ is a function of the batch size $N$. According to definition (iii), it is the ratio of useful compute time to total wall-clock time:\n$$\\eta(N) = \\frac{T_{\\text{compute}}(N)}{T_{\\text{total}}(N)} = \\frac{N c}{N c + \\tau_k}$$\n\nThe problem requires finding the minimal integer batch size, $N_{\\min}$, that guarantees a target efficiency $\\eta$. This translates to the inequality:\n$$\\eta(N) \\ge \\eta$$\nSubstituting the expression for $\\eta(N)$, we have:\n$$\\frac{N c}{N c + \\tau_k} \\ge \\eta$$\nSince $N$ is a batch size, $N \\ge 1$. The constants $c$ and $\\tau_k$ are times, so they are positive. Therefore, the denominator $N c + \\tau_k$ is strictly positive. We can multiply both sides of the inequality by this term without changing the direction of the inequality:\n$$N c \\ge \\eta (N c + \\tau_k)$$\n$$N c \\ge \\eta N c + \\eta \\tau_k$$\nTo solve for $N$, we gather all terms containing $N$ on one side:\n$$N c - \\eta N c \\ge \\eta \\tau_k$$\n$$N(c - \\eta c) \\ge \\eta \\tau_k$$\n$$N c (1 - \\eta) \\ge \\eta \\tau_k$$\nThe problem states that $0  \\eta  1$, which implies that $1 - \\eta$ is a positive quantity. We can therefore divide the inequality by $c(1 - \\eta)$ without changing its direction:\n$$N \\ge \\frac{\\eta \\tau_k}{c (1 - \\eta)}$$\nThis inequality specifies the condition that the batch size $N$ must satisfy. The problem asks for the *minimal integer* batch size, $N_{\\min}$. This is the smallest integer value of $N$ that satisfies the condition. Such an integer is found by taking the ceiling of the right-hand side expression:\n$$N_{\\min} = \\left\\lceil \\frac{\\eta \\tau_k}{c(1-\\eta)} \\right\\rceil$$\n\nThis completes the symbolic derivation. Now, we compute the numerical value for $N_{\\min}$ using the provided data: $\\tau_k = 8.0\\,\\mu\\mathrm{s}$, $c = 25\\,\\mathrm{ns}$, and $\\eta = 0.9$.\nFirst, we ensure consistent units. Let's convert both time values to seconds:\n$\\tau_k = 8.0 \\times 10^{-6}\\,\\mathrm{s}$\n$c = 25 \\times 10^{-9}\\,\\mathrm{s}$\n\nWe can compute the dimensionless ratio $\\frac{\\tau_k}{c}$:\n$$\\frac{\\tau_k}{c} = \\frac{8.0 \\times 10^{-6}}{25 \\times 10^{-9}} = \\frac{8.0}{25} \\times 10^3 = 0.32 \\times 10^3 = 320$$\nNow, substitute the values of $\\eta$ and the ratio $\\frac{\\tau_k}{c}$ into the inequality for $N$:\n$$N \\ge \\frac{0.9}{1 - 0.9} \\left( \\frac{\\tau_k}{c} \\right)$$\n$$N \\ge \\frac{0.9}{0.1} \\times 320$$\n$$N \\ge 9 \\times 320$$\n$$N \\ge 2880$$\nSince the lower bound is an integer, the minimal integer $N$ that satisfies the inequality is $N_{\\min} = 2880$.\n$$N_{\\min} = 2880$$\n\nFinally, we validate this result by calculating the efficiency achieved with a batch size of $N_{\\min} = 2880$.\n$$\\eta(N_{\\min}) = \\eta(2880) = \\frac{2880 \\cdot c}{2880 \\cdot c + \\tau_k}$$\nTo simplify, we can divide the numerator and the denominator by $c$:\n$$\\eta(2880) = \\frac{2880}{2880 + \\frac{\\tau_k}{c}}$$\nUsing our previously calculated ratio $\\frac{\\tau_k}{c} = 320$:\n$$\\eta(2880) = \\frac{2880}{2880 + 320} = \\frac{2880}{3200}$$\nSimplifying the fraction:\n$$\\eta(2880) = \\frac{288}{320} = \\frac{144}{160} = \\frac{72}{80} = \\frac{36}{40} = \\frac{9}{10} = 0.9$$\nThe efficiency at $N_{\\min} = 2880$ is exactly $0.9$, which matches the target efficiency $\\eta$. This validates our calculation of $N_{\\min}$.",
            "answer": "$$\\boxed{2880}$$"
        },
        {
            "introduction": "A key challenge in harnessing the power of GPUs is their Single Instruction, Multiple Threads (SIMT) execution model, where performance suffers if threads in an execution group (a \"warp\") diverge down different conditional paths. This exercise explores a powerful, architecture-aware optimization technique called bucketization to combat this very issue in a neutron scattering kernel. By sorting particles into groups based on their computational path before processing, you can minimize divergence and dramatically improve performance, demonstrating a core principle of adapting algorithms to the underlying hardware. ",
            "id": "4224563",
            "problem": "Consider an event-based Monte Carlo (MC) simulation of neutron transport in a nuclear reactor core where scattering events are processed on a Graphics Processing Unit (GPU) with Single Instruction Multiple Threads (SIMT) execution. The angular scattering of neutrons is described by a normalized anisotropic kernel over the cosine of the scattering angle, denoted by $\\mu \\in [-1,1]$, with a Legendre expansion up to second order: \n$$\np(\\mu) = \\frac{1}{2}\\left(1 + a_1 \\mu + \\frac{a_2}{2}\\left(3\\mu^2 - 1\\right)\\right),\n$$\nwhere $a_1$ and $a_2$ are anisotropy coefficients. The normalization constant is chosen so that $\\int_{-1}^{1} p(\\mu)\\,d\\mu = 1$. The scattering kernel leads to angle-dependent code paths in the scattering routine: forward scattering, central scattering, and backscattering. These paths are triggered by the angle thresholds defined by a single parameter $\\mu_t \\in (0,1)$, such that:\n- Forward path is taken if $\\mu \\in [\\mu_t, 1]$,\n- Central path is taken if $\\mu \\in (-\\mu_t, \\mu_t)$,\n- Backscattering path is taken if $\\mu \\in [-1, -\\mu_t]$.\n\nAssume each path has a fixed path execution cost, modeled in unitless time units, given by $c_f$ for forward, $c_m$ for central, and $c_b$ for backscattering. The GPU warp size is $W$ threads. In SIMT execution, warp-level divergence occurs when threads in a warp take different branches; the warp executes all present branches serially, paying the cost of each distinct branch present in the warp once, independently of the number of threads that took that branch.\n\nYou are to design a bucketization (remapping) strategy that assigns particles to contiguous buckets by their angle-dependent path key (forward, central, backscattering) in order to minimize intra-warp divergence. The remapping requires sorting particles by an integer bucket key (three buckets), with an estimated overhead modeled by a counting-sort-like cost \n$$\nT_{\\text{sort}} = \\gamma N + \\delta B,\n$$\nwhere $N$ is the number of particles, $B$ is the number of buckets (here $B=3$), and $\\gamma,\\delta$ are positive constants. After sorting, each bucket is processed with full warps of size $W$; a partially filled warp at the end of a bucket still incurs the full path cost for that bucket.\n\nStarting only from the fundamental base comprising the Boltzmann transport framework (scattering kernel and normalization), SIMT divergence behavior, and integer-key sorting cost model as specified above, derive the following:\n- The probabilities $p_b$, $p_m$, $p_f$ of landing in the backscattering, central, and forward buckets, respectively, by integrating the provided $p(\\mu)$ over the corresponding angle intervals.\n- The expected total execution time without any remapping, expressed in unitless time units, for $N$ particles processed in warps of size $W$, where each warpâ€™s time is the sum of the costs of the distinct paths present in that warp.\n- The total execution time with bucketization into three buckets, including both the sorting overhead and the bucketed execution time, where the number of warps per bucket is the ceiling of the expected bucket occupancy divided by $W$.\n\nYour program must compute, for each test case specified below, two outputs: the total time without remapping and the total time with bucketization into three angle buckets. Express all final results as unitless floating-point numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order: for each test case, output first the no-remapping total time, then the bucketized total time; thus, the final list length is twice the number of test cases.\n\nTest Suite:\n- Case A (happy path): $N=65536$, $W=32$, $a_1=0.2$, $a_2=0.1$, $\\mu_t=0.6$, $c_f=6.0$, $c_m=4.0$, $c_b=7.0$, $\\gamma=0.25$, $\\delta=400.0$.\n- Case B (forward-peaked anisotropy): $N=65536$, $W=32$, $a_1=0.6$, $a_2=0.2$, $\\mu_t=0.8$, $c_f=8.0$, $c_m=5.0$, $c_b=9.0$, $\\gamma=0.2$, $\\delta=400.0$.\n- Case C (boundary, no divergence due to $W=1$): $N=1000$, $W=1$, $a_1=0.0$, $a_2=0.0$, $\\mu_t=0.5$, $c_f=6.0$, $c_m=6.0$, $c_b=6.0$, $\\gamma=0.3$, $\\delta=200.0$.\n- Case D (larger warp size): $N=262144$, $W=64$, $a_1=0.3$, $a_2=-0.1$, $\\mu_t=0.7$, $c_f=7.0$, $c_m=4.0$, $c_b=8.0$, $\\gamma=0.25$, $\\delta=600.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots]$), where the list entries are floating-point numbers corresponding to, for each test case in order A, B, C, D: $(\\text{no-remap total}),(\\text{bucketized total})$. All computations must be performed analytically from the definitions given, without any stochastic sampling. All outputs must be unitless as specified.",
            "solution": "This solution presents the analytical derivations for the total execution time of a Monte Carlo neutron scattering simulation on a GPU, both with and without a particle bucketization strategy.\n\n### 1. Derivation of Path Probabilities\n\nThe probability of a neutron scattering into a specific angular range is determined by integrating the normalized anisotropic scattering kernel, $p(\\mu)$, over the corresponding interval of $\\mu$, the cosine of the scattering angle.\n\nThe scattering kernel is given as a Legendre expansion up to the second order:\n$$\np(\\mu) = \\frac{1}{2}\\left(1 + a_1 \\mu + \\frac{a_2}{2}\\left(3\\mu^2 - 1\\right)\\right)\n$$\nThis probability density function is normalized such that $\\int_{-1}^{1} p(\\mu)\\,d\\mu = 1$. The three angular paths are defined by the parameter $\\mu_t \\in (0,1)$:\n- Forward path (f): $\\mu \\in [\\mu_t, 1]$\n- Central path (m): $\\mu \\in (-\\mu_t, \\mu_t)$\n- Backscattering path (b): $\\mu \\in [-1, -\\mu_t]$\n\nTo find the probability of each path, we compute the definite integral of $p(\\mu)$ over each interval. First, we find the indefinite integral of $p(\\mu)$, which we denote as $P(\\mu)$:\n$$\nP(\\mu) = \\int p(\\mu)\\,d\\mu = \\frac{1}{2} \\int \\left( \\left(1-\\frac{a_2}{2}\\right) + a_1 \\mu + \\frac{3a_2}{2}\\mu^2 \\right) d\\mu\n$$\n$$\nP(\\mu) = \\frac{1}{2} \\left( \\left(1-\\frac{a_2}{2}\\right)\\mu + \\frac{a_1}{2}\\mu^2 + \\frac{a_2}{2}\\mu^3 \\right) + C\n$$\n\nThe probabilities $p_f$, $p_m$, and $p_b$ are:\n\n**Central path probability ($p_m$):**\n$$\np_m = \\int_{-\\mu_t}^{\\mu_t} p(\\mu)\\,d\\mu = P(\\mu_t) - P(-\\mu_t)\n$$\n$$\np_m = \\frac{1}{2} \\left[ \\left( \\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_1}{2}\\mu_t^2 + \\frac{a_2}{2}\\mu_t^3 \\right) - \\left( -\\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_1}{2}\\mu_t^2 - \\frac{a_2}{2}\\mu_t^3 \\right) \\right]\n$$\n$$\np_m = \\frac{1}{2} \\left[ 2\\left(1-\\frac{a_2}{2}\\right)\\mu_t + 2\\frac{a_2}{2}\\mu_t^3 \\right] = \\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_2}{2}\\mu_t^3 = \\mu_t + \\frac{a_2}{2}\\left(\\mu_t^3 - \\mu_t\\right)\n$$\n\n**Forward path probability ($p_f$):**\n$$\np_f = \\int_{\\mu_t}^{1} p(\\mu)\\,d\\mu = P(1) - P(\\mu_t)\n$$\n$$\nP(1) = \\frac{1}{2} \\left( \\left(1-\\frac{a_2}{2}\\right) + \\frac{a_1}{2} + \\frac{a_2}{2} \\right) = \\frac{1}{2}\\left(1 + \\frac{a_1}{2}\\right)\n$$\n$$\np_f = \\frac{1}{2}\\left(1 + \\frac{a_1}{2}\\right) - \\frac{1}{2} \\left( \\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_1}{2}\\mu_t^2 + \\frac{a_2}{2}\\mu_t^3 \\right)\n$$\n$$\np_f = \\frac{1}{2} \\left[ 1 + \\frac{a_1}{2} - \\left(1-\\frac{a_2}{2}\\right)\\mu_t - \\frac{a_1}{2}\\mu_t^2 - \\frac{a_2}{2}\\mu_t^3 \\right]\n$$\n\n**Backscattering path probability ($p_b$):**\n$$\np_b = \\int_{-1}^{-\\mu_t} p(\\mu)\\,d\\mu = P(-\\mu_t) - P(-1)\n$$\n$$\nP(-1) = \\frac{1}{2} \\left( -\\left(1-\\frac{a_2}{2}\\right) + \\frac{a_1}{2} - \\frac{a_2}{2} \\right) = \\frac{1}{2}\\left(-1 + \\frac{a_1}{2}\\right)\n$$\n$$\np_b = \\frac{1}{2} \\left( -\\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_1}{2}\\mu_t^2 - \\frac{a_2}{2}\\mu_t^3 \\right) - \\frac{1}{2}\\left(-1 + \\frac{a_1}{2}\\right)\n$$\n$$\np_b = \\frac{1}{2} \\left[ 1 - \\frac{a_1}{2} - \\left(1-\\frac{a_2}{2}\\right)\\mu_t + \\frac{a_1}{2}\\mu_t^2 - \\frac{a_2}{2}\\mu_t^3 \\right]\n$$\nThese three probabilities sum to $1$.\n\n### 2. Execution Time Without Remapping ($T_{\\text{no-remap}}$)\n\nWithout remapping, threads corresponding to $N$ particles are grouped into warps of size $W$. On a SIMT architecture, if threads within a warp diverge (take different code paths), the warp executes each distinct path serially. The cost for one warp is the sum of the costs of all unique paths taken by its threads.\n\nLet's find the expected execution time for a single warp of size $w$. The probability that a specific path (e.g., forward path, $f$) is present in the warp is $1$ minus the probability that *no* thread in the warp takes that path. The probability that a single thread does *not* take path $f$ is $1 - p_f$. For $w$ independent threads, this probability is $(1 - p_f)^w$.\n- Probability path $f$ is present: $P(\\text{f present}) = 1 - (1 - p_f)^w$\n- Probability path $m$ is present: $P(\\text{m present}) = 1 - (1 - p_m)^w$\n- Probability path $b$ is present: $P(\\text{b present}) = 1 - (1 - p_b)^w$\n\nThe expected time for a warp of size $w$, $E[T_{\\text{warp}}(w)]$, is the sum of each path's cost multiplied by the probability of its presence:\n$$\nE[T_{\\text{warp}}(w)] = c_f \\left(1 - (1-p_f)^w\\right) + c_m \\left(1 - (1-p_m)^w\\right) + c_b \\left(1 - (1-p_b)^w\\right)\n$$\nFor $N$ total particles, there are $N_{full} = \\lfloor N/W \\rfloor$ full warps of size $W$ and, if $N$ is not a multiple of $W$, one partial warp of size $W_{\\text{last}} = N \\pmod W$.\n\nThe total expected time is the sum of expected times for all warps:\n$$\nT_{\\text{no-remap}} = \\lfloor N/W \\rfloor \\cdot E[T_{\\text{warp}}(W)] + E[T_{\\text{warp}}(N \\pmod W)]\n$$\nwhere the second term is added only if $N \\pmod W  0$.\n\n### 3. Execution Time With Bucketization ($T_{\\text{remap}}$)\n\nThe bucketization strategy involves two stages: sorting and execution. The total time is the sum of the time for each stage.\n$$\nT_{\\text{remap}} = T_{\\text{sort}} + T_{\\text{exec,bucketed}}\n$$\n\n**Sorting Cost ($T_{\\text{sort}}$):**\nThe problem provides a model for the sorting overhead:\n$$\nT_{\\text{sort}} = \\gamma N + \\delta B\n$$\nWith $B=3$ buckets (forward, central, backscattering), the cost is:\n$$\nT_{\\text{sort}} = \\gamma N + 3\\delta\n$$\n\n**Bucketed Execution Cost ($T_{\\text{exec,bucketed}}$):**\nAfter sorting, particles are grouped by their destined path. All threads in a warp processing a specific bucket will execute the same code path, thus eliminating intra-warp divergence.\nThe expected number of particles in each bucket is $N_f = N p_f$, $N_m = N p_m$, and $N_b = N p_b$.\nThe problem specifies that the number of warps for each bucket is calculated as the ceiling of the expected bucket occupancy divided by the warp size $W$:\n- Warps for forward bucket: $N_{\\text{warps},f} = \\lceil N p_f / W \\rceil$\n- Warps for central bucket: $N_{\\text{warps},m} = \\lceil N p_m / W \\rceil$\n- Warps for backscattering bucket: $N_{\\text{warps},b} = \\lceil N p_b / W \\rceil$\n\nEach warp in the forward bucket costs $c_f$, in the central bucket $c_m$, and in the backscattering bucket $c_b$. The total bucketed execution time is:\n$$\nT_{\\text{exec,bucketed}} = N_{\\text{warps},f} \\cdot c_f + N_{\\text{warps},m} \\cdot c_m + N_{\\text{warps},b} \\cdot c_b\n$$\n$$\nT_{\\text{exec,bucketed}} = \\lceil Np_f/W \\rceil c_f + \\lceil Np_m/W \\rceil c_m + \\lceil Np_b/W \\rceil c_b\n$$\nThe total time with remapping is the sum of these two components.\n\n### Summary of Formulas\nThe computation proceeds by first calculating $p_f, p_m, p_b$ for a given test case. Then, these probabilities are used to compute $T_{\\text{no-remap}}$ and $T_{\\text{remap}}$ using the derived formulas.\n- $T_{\\text{no-remap}} = \\lfloor N/W \\rfloor \\left( \\sum_{k \\in \\{f,m,b\\}} c_k(1-(1-p_k)^W) \\right) + \\mathbf{1}_{N \\pmod W \\neq 0} \\left( \\sum_{k \\in \\{f,m,b\\}} c_k(1-(1-p_k)^{N \\pmod W}) \\right)$\n- $T_{\\text{remap}} = (\\gamma N + 3\\delta) + c_f \\lceil Np_f/W \\rceil + c_m \\lceil Np_m/W \\rceil + c_b \\lceil Np_b/W \\rceil$\n\nThese formulas will be implemented to solve for the given test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It calculates the total execution time for a Monte Carlo simulation \n    both without and with a particle bucketization strategy.\n    \"\"\"\n    \n    # Test cases are defined as tuples of parameters:\n    # (N, W, a1, a2, mu_t, c_f, c_m, c_b, gamma, delta)\n    test_cases = [\n        # Case A (happy path)\n        (65536, 32, 0.2, 0.1, 0.6, 6.0, 4.0, 7.0, 0.25, 400.0),\n        # Case B (forward-peaked anisotropy)\n        (65536, 32, 0.6, 0.2, 0.8, 8.0, 5.0, 9.0, 0.2, 400.0),\n        # Case C (boundary, no divergence due to W=1)\n        (1000, 1, 0.0, 0.0, 0.5, 6.0, 6.0, 6.0, 0.3, 200.0),\n        # Case D (larger warp size)\n        (262144, 64, 0.3, -0.1, 0.7, 7.0, 4.0, 8.0, 0.25, 600.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        time_no_remap, time_remap = calculate_times_for_case(*case)\n        results.append(time_no_remap)\n        results.append(time_remap)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_times_for_case(N, W, a1, a2, mu_t, c_f, c_m, c_b, gamma, delta):\n    \"\"\"\n    Calculates execution times for a single test case.\n    \n    Args:\n        N (int): Number of particles.\n        W (int): Warp size.\n        a1, a2 (float): Anisotropy coefficients.\n        mu_t (float): Angle threshold.\n        c_f, c_m, c_b (float): Path execution costs.\n        gamma, delta (float): Sorting cost coefficients.\n\n    Returns:\n        tuple: (total time without remapping, total time with bucketization).\n    \"\"\"\n\n    # 1. Calculate Path Probabilities (p_f, p_m, p_b)\n    # p_m = mu_t + a2/2 * (mu_t^3 - mu_t)\n    p_m = mu_t + 0.5 * a2 * (mu_t**3 - mu_t)\n    \n    # p_f = 0.5 * [1 + a1/2 - (1-a2/2)*mu_t - a1/2*mu_t^2 - a2/2*mu_t^3]\n    p_f = 0.5 * (1 + 0.5 * a1 - (1 - 0.5 * a2) * mu_t - 0.5 * a1 * mu_t**2 - 0.5 * a2 * mu_t**3)\n\n    # p_b can be derived from p_f and p_m, or calculated directly.\n    # To maintain precision, we use the direct formula, but 1 - p_f - p_m is also valid.\n    # p_b = 0.5 * [1 - a1/2 - (1-a2/2)*mu_t + a1/2*mu_t^2 - a2/2*mu_t^3]\n    p_b = 1.0 - p_f - p_m\n\n    # 2. Calculate Execution Time Without Remapping (T_no_remap)\n    \n    # Function to calculate expected time for a warp of a given size `w`\n    def get_expected_warp_time(w, p_f, p_m, p_b, c_f, c_m, c_b):\n        if w == 0:\n            return 0.0\n        time = 0.0\n        # Contribution from forward path\n        prob_f_present = 1.0 - (1.0 - p_f)**w\n        time += c_f * prob_f_present\n        # Contribution from central path\n        prob_m_present = 1.0 - (1.0 - p_m)**w\n        time += c_m * prob_m_present\n        # Contribution from backscattering path\n        prob_b_present = 1.0 - (1.0 - p_b)**w\n        time += c_b * prob_b_present\n        return time\n\n    num_full_warps = N // W\n    last_warp_size = N % W\n\n    expected_time_full_warp = get_expected_warp_time(W, p_f, p_m, p_b, c_f, c_m, c_b)\n    total_time_no_remap = num_full_warps * expected_time_full_warp\n    \n    if last_warp_size > 0:\n        expected_time_last_warp = get_expected_warp_time(last_warp_size, p_f, p_m, p_b, c_f, c_m, c_b)\n        total_time_no_remap += expected_time_last_warp\n\n    # 3. Calculate Execution Time With Bucketization (T_remap)\n    # T_remap = T_sort + T_exec_bucketed\n    \n    # Sorting cost\n    B = 3  # Number of buckets\n    T_sort = gamma * N + delta * B\n\n    # Bucketed execution cost\n    # Expected number of particles per bucket\n    N_f = N * p_f\n    N_m = N * p_m\n    N_b = N * p_b\n\n    # Number of warps per bucket\n    num_warps_f = np.ceil(N_f / W)\n    num_warps_m = np.ceil(N_m / W)\n    num_warps_b = np.ceil(N_b / W)\n\n    T_exec_bucketed = num_warps_f * c_f + num_warps_m * c_m + num_warps_b * c_b\n    \n    total_time_remap = T_sort + T_exec_bucketed\n\n    return total_time_no_remap, total_time_remap\n\n# Execute the main function when the script is run.\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Performance is meaningless if the results are incorrect. The complexity of parallel programming can introduce subtle bugs like race conditions, where threads interfere with shared resources and corrupt the simulation's statistical integrity. This exercise presents a hypothetical scenario where a race condition on a random number generator (RNG) creates spurious correlations between theoretically independent events. You will analyze the statistical signature of this bug and devise a principled test to detect it, providing a crucial lesson in the verification and validation of parallel Monte Carlo codes. ",
            "id": "4224517",
            "problem": "In event-based Monte Carlo radiation transport for nuclear reactor simulation, collision, flight, and tally events are executed as discrete items in a global event pool processed by $K$ threads. Each thread $k \\in \\{1,\\dots,K\\}$ accumulates a batch-level tally $Y_{t,k}$ during batch $t \\in \\{1,\\dots,T\\}$, where the batch groups a fixed amount of work to reduce serial correlation. Consider a linear track-length reaction-rate estimator, where each event contribution is a random variable $X_{t,k,i}$ that is identically distributed with finite mean $E[X_{t,k,i}] = \\mu$ and variance $\\operatorname{Var}(X_{t,k,i}) = \\sigma^2$. A thread-level batch tally is $Y_{t,k} = \\sum_{i=1}^{N_{t,k}} X_{t,k,i}$ and the overall batch estimator is $\\hat{\\theta}_t = \\frac{1}{\\sum_{k=1}^{K} N_{t,k}} \\sum_{k=1}^{K} Y_{t,k}$. The run-level estimator is $\\bar{\\theta} = \\frac{1}{T} \\sum_{t=1}^{T} \\hat{\\theta}_t$.\n\nAssume all event contributions are identically distributed as above and that event-based scheduling would render tallies across threads independent under correct random number generator (RNG) handling. Now suppose a race condition causes the random number generator (RNG) state to be inadvertently shared between some pairs of threads with probability $\\rho \\in (0,1)$ per draw, resulting in duplicated random variates across threads within the same batch. Model this by positing that a fraction $\\rho$ of the $X_{t,k,i}$ used by thread $k$ within batch $t$ are exact duplicates of corresponding draws used by another thread $\\ell \\neq k$ in the same batch, while the remaining $1-\\rho$ draws are independent.\n\nAnalyze the effect of this RNG state sharing on the bias of the run-level estimator $\\bar{\\theta}$ and propose a statistically principled detection test based on the cross-correlation of per-thread batch tallies $\\{Y_{t,k}\\}_{t=1}^{T}$ across threads. You may assume the following well-tested facts: linear Monte Carlo estimators are unbiased if their input random variables are correctly distributed; and under the null of zero correlation, the Fisher transformation of the sample Pearson correlation is asymptotically normal.\n\nWhich option best characterizes the bias and proposes a valid detection test?\n\nA. RNG state sharing produces a positive bias in $E[\\bar{\\theta}]$ that scales as $\\rho \\mu$, because duplicated draws overweight high-contribution events; detect by computing the sample Pearson correlation at lag $0$ between threads and declaring bias if any correlation exceeds a fixed threshold $r > 0$ without multiple-comparison correction.\n\nB. For linear estimators, RNG state sharing does not bias $E[\\bar{\\theta}]$ because duplicated draws remain identically distributed, but it inflates $\\operatorname{Var}(\\bar{\\theta})$ via positive cross-thread covariance; detect by estimating the pairwise lag-$0$ Pearson correlation $r_{k\\ell}$ of $\\{Y_{t,k}\\}$ and $\\{Y_{t,\\ell}\\}$ over $t=1,\\dots,T$, applying the Fisher transformation $z_{k\\ell} = \\tfrac{1}{2}\\ln\\frac{1+r_{k\\ell}}{1-r_{k\\ell}}$, and testing $|z_{k\\ell}|$ against $z_{1-\\alpha/(2M)} \\sqrt{\\frac{1}{T-3}}$ with Bonferroni correction across $M = \\frac{K(K-1)}{2}$ thread pairs.\n\nC. RNG state sharing creates a negative bias in $E[\\bar{\\theta}]$ because absorption events are over-sampled, and detection should rely exclusively on single-thread autocorrelation of $\\{Y_{t,k}\\}$ at nonzero lags, since cross-thread correlations vanish under race conditions.\n\nD. Bias arises only when tallies are non-linear functionals such as ratios of two random sums; detection must be based on comparing estimated variances between threads rather than correlations, because Pearson cross-correlation is insensitive to RNG state sharing in event-based schedules.\n\nSelect the correct option.",
            "solution": "This analysis proceeds in two parts: first, we assess the effect of the random number generator (RNG) flaw on the bias of the estimator $\\bar{\\theta}$; second, we devise a statistical test to detect the flaw and evaluate the given options.\n\n**1. Analysis of Bias**\n\nThe run-level estimator is $\\bar{\\theta} = \\frac{1}{T} \\sum_{t=1}^{T} \\hat{\\theta}_t$. By linearity of expectation, its expected value is $E[\\bar{\\theta}] = E[\\hat{\\theta}_t]$ for any batch $t$, as batches are identically set up. We analyze the expectation of a single batch estimator, dropping the index $t$ for clarity:\n$$ \\hat{\\theta} = \\frac{\\sum_{k=1}^{K} Y_{k}}{\\sum_{k=1}^{K} N_{k}} = \\frac{\\sum_{k=1}^{K} \\sum_{i=1}^{N_{k}} X_{k,i}}{\\sum_{k=1}^{K} N_{k}} $$\nThe core question regarding bias is whether the RNG flaw changes the expected value of the individual event contributions, $E[X_{k,i}]$. The problem states that the flaw causes some contributions $X_{k,i}$ to be duplicates of others, e.g., $X_{k,i} = X_{\\ell,j}$. This introduces dependence (correlation) between contributions, but it does not alter the marginal probability distribution from which any single contribution is drawn. Each $X_{k,i}$ is still a realization of the same random variable with expectation $\\mu$. The flaw makes the contributions not *independent*, but they remain *identically distributed*.\n\nTherefore, $E[X_{k,i}] = \\mu$ for all $k,i$. By linearity of expectation, the expectation of the numerator is:\n$$ E\\left[ \\sum_{k,i} X_{k,i} \\right] = \\sum_{k,i} E[X_{k,i}] = \\sum_{k,i} \\mu = \\mu \\sum_k N_k $$\nSince the estimator $\\hat{\\theta}$ is linear, we can see that its expectation is $\\mu$. More formally, using the law of total expectation by conditioning on the event counts $\\mathcal{N} = \\{N_1, \\dots, N_K\\}$:\n$$ E[\\hat{\\theta}] = E[E[\\hat{\\theta} | \\mathcal{N}]] = E\\left[ \\frac{1}{\\sum_k N_k} E\\left[ \\sum_{k,i} X_{k,i} \\right] \\right] = E\\left[ \\frac{1}{\\sum_k N_k} \\left( \\mu \\sum_k N_k \\right) \\right] = E[\\mu] = \\mu $$\nThe estimator $\\bar{\\theta}$ remains unbiased for the true mean $\\mu$. The primary effect of the flaw is not bias, but an inflation of the variance of the estimator due to the induced positive covariance between thread tallies, $\\operatorname{Cov}(Y_{t,k}, Y_{t,\\ell}) > 0$.\n\n**2. Statistical Detection Test and Option Evaluation**\n\nThe signature of the flaw is a positive correlation between the batch tally sequences from different threads. A valid test must check for this lag-0 cross-correlation.\n\n- **Hypothesis**: For any pair of threads $(k, \\ell)$ where $k \\neq \\ell$, we test the null hypothesis $H_0: p_{k\\ell} = 0$ (no correlation) against the alternative $H_1: p_{k\\ell} > 0$.\n- **Test Statistic**: We compute the sample Pearson correlation coefficient, $r_{k\\ell}$, between the two time series of batch tallies $\\{Y_{t,k}\\}_{t=1}^T$ and $\\{Y_{t,\\ell}\\}_{t=1}^T$.\n- **Test Procedure**: To test the significance of $r_{k\\ell}$, we use the Fisher $z$-transformation: $z_{k\\ell} = \\frac{1}{2} \\ln\\left(\\frac{1+r_{k\\ell}}{1-r_{k\\ell}}\\right)$. Under $H_0$, $z_{k\\ell}$ is approximately normally distributed with mean $0$ and standard deviation $\\sigma_z = 1/\\sqrt{T-3}$.\n- **Multiple Comparisons**: Since we must perform this test for all $M = K(K-1)/2$ unique pairs of threads, we must apply a multiple-comparison correction to control the family-wise error rate. The Bonferroni correction is a standard method, where the significance level $\\alpha$ for the family of tests is divided among the $M$ individual tests, yielding a per-test significance level of $\\alpha/M$. The corresponding two-sided critical z-score is $z_{1-\\alpha/(2M)}$. We reject $H_0$ for a given pair if $|z_{k\\ell}| > z_{1-\\alpha/(2M)} \\cdot \\frac{1}{\\sqrt{T-3}}$.\n\nNow we evaluate the options based on this derivation.\n\n*   **A:** Incorrect. Claims there is bias. Proposes a statistically non-rigorous test without multiple comparison correction.\n*   **B:** Correct. Accurately states that the linear estimator is not biased but its variance is inflated. It proposes a statistically sound detection test based on pairwise lag-0 Pearson correlation, using the correct Fisher transformation, the correct standard error formula, and the necessary Bonferroni correction for multiple comparisons. The critical value comparison is also stated correctly.\n*   **C:** Incorrect. Claims there is a negative bias. Proposes detection via single-thread autocorrelation, which is not the primary signal, and incorrectly states that cross-thread correlations vanish.\n*   **D:** Incorrect. Correctly implies no bias for linear estimators but incorrectly claims that Pearson cross-correlation is insensitive to this flaw. Cross-correlation is the most direct and sensitive indicator of this specific defect.\n\nThe correct choice is B. It provides a complete and accurate characterization of both the statistical effect and the appropriate detection method.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}