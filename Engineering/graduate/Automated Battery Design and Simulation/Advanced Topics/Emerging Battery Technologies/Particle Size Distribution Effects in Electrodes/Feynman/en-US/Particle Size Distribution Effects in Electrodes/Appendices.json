{
    "hands_on_practices": [
        {
            "introduction": "Our understanding of any particle size distribution (PSD) begins with its measurement, which often yields binned data from techniques like laser diffraction or image analysis. This exercise provides hands-on practice in the fundamental task of converting raw histogram counts into a continuous probability density function and its corresponding statistical moments. By exploring the effects of data truncation, you will also develop a critical appreciation for how measurement limitations can influence the quantitative description of a material's microstructure. ",
            "id": "3938198",
            "problem": "A particle size distribution (PSD) of electrode active material is acquired via image analysis, which yields binned counts of particle diameters. Let $d$ denote the particle diameter in meters, and let $f(d)$ denote the Probability Density Function (PDF) of $d$, normalized so that $\\int f(d)\\,\\mathrm{d}d = 1$. The $k$-th raw moment is defined as $m_k = \\int d^k f(d)\\,\\mathrm{d}d$ and has units of $\\mathrm{m}^k$. You are given finite-resolution histograms defined by bin edges $\\{a_i,b_i\\}_{i=1}^{n}$ with $0  a_1  b_n$, $a_i  b_i$ for each bin, and nonnegative counts $\\{c_i\\}_{i=1}^{n}$ observed in each bin. The imaging system may truncate the upper tail by failing to detect particles above a threshold diameter $T$, which effectively restricts the support of the observed distribution to $d \\le T$.\n\nStarting only from the definitions of a Probability Density Function (PDF), moments, and the Riemann integral, construct consistent estimates of the first four raw moments $m_k$ for $k \\in \\{1,2,3,4\\}$ using only the given bin edges and counts, under a scientifically reasonable assumption about the distribution of $d$ within each bin. Then assess the sensitivity of these moment estimates to upper-tail truncation at a specified threshold $T$ by computing a scalar sensitivity measure defined as the maximum absolute relative change across the first four moments:\n$$\nS(T) = \\max_{k\\in\\{1,2,3,4\\}} \\left| \\frac{m_k(T) - m_k}{m_k} \\right|,\n$$\nwhere $m_k(T)$ denotes the $k$-th raw moment computed from the truncated distribution restricted to $d \\le T$.\n\nYour program must implement the following without using any external files or user input:\n1. Construct moment estimates $m_k$ for $k \\in \\{1,2,3,4\\}$ in $\\mathrm{m}^k$ from the provided binned data.\n2. Implement upper-tail truncation at threshold $T$ by partially including any bin that straddles $T$ according to a physically justified rule based on your within-bin assumption, then renormalize the truncated distribution to form a valid Probability Density Function (PDF).\n3. Compute $S(T)$ as defined above for each test case.\n\nUse the following test suite, where bin edges are specified in meters and counts are dimensionless:\n- Test Case 1 (typical lognormal-like PSD):\n  - Bin edges: $[2.0\\times 10^{-7},\\,4.0\\times 10^{-7},\\,6.0\\times 10^{-7},\\,9.0\\times 10^{-7},\\,1.3\\times 10^{-6},\\,1.8\\times 10^{-6},\\,2.5\\times 10^{-6},\\,3.5\\times 10^{-6},\\,5.0\\times 10^{-6}]$\n  - Counts: $[5,\\,20,\\,60,\\,100,\\,140,\\,120,\\,80,\\,30]$\n  - Truncation threshold: $T = 3.0\\times 10^{-6}\\,\\mathrm{m}$\n- Test Case 2 (heavy upper tail):\n  - Bin edges: $[5.0\\times 10^{-7},\\,1.0\\times 10^{-6},\\,1.5\\times 10^{-6},\\,2.0\\times 10^{-6},\\,3.0\\times 10^{-6},\\,4.0\\times 10^{-6},\\,6.0\\times 10^{-6},\\,8.0\\times 10^{-6},\\,1.0\\times 10^{-5},\\,1.2\\times 10^{-5},\\,1.4\\times 10^{-5},\\,1.7\\times 10^{-5},\\,2.0\\times 10^{-5}]$\n  - Counts: $[10,\\,15,\\,20,\\,25,\\,40,\\,60,\\,90,\\,120,\\,100,\\,80,\\,60,\\,40]$\n  - Truncation threshold: $T = 8.0\\times 10^{-6}\\,\\mathrm{m}$\n- Test Case 3 (left-heavy, sparse upper tail):\n  - Bin edges: $[5.0\\times 10^{-8},\\,1.0\\times 10^{-7},\\,2.0\\times 10^{-7},\\,3.0\\times 10^{-7},\\,5.0\\times 10^{-7},\\,8.0\\times 10^{-7},\\,1.2\\times 10^{-6}]$\n  - Counts: $[200,\\,150,\\,80,\\,30,\\,10,\\,5]$\n  - Truncation threshold: $T = 6.0\\times 10^{-7}\\,\\mathrm{m}$\n- Test Case 4 (zeros in some bins):\n  - Bin edges: $[1.0\\times 10^{-7},\\,5.0\\times 10^{-7},\\,1.0\\times 10^{-6},\\,2.0\\times 10^{-6},\\,4.0\\times 10^{-6}]$\n  - Counts: $[0,\\,50,\\,0,\\,150]$\n  - Truncation threshold: $T = 1.2\\times 10^{-6}\\,\\mathrm{m}$\n\nYour program should produce a single line of output containing the four scalar sensitivity results $S(T)$ for the four test cases as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places, for example, $[0.123456,0.234567,0.345678,0.456789]$. Since $S(T)$ is a ratio, it is dimensionless. All intermediate moment computations must be internally handled in $\\mathrm{m}^k$ units for $k \\in \\{1,2,3,4\\}$.",
            "solution": "The problem requires the estimation of the first four raw moments of a particle size distribution from binned histogram data and the evaluation of the sensitivity of these estimates to upper-tail truncation. The solution shall be constructed from first principles, beginning with the definition of a probability density function and its moments.\n\n**1. Constructing the Probability Density Function (PDF) from Histogram Data**\n\nThe provided data consists of a set of $n$ bins, each defined by a lower edge $a_i$ and an upper edge $b_i$, and a corresponding particle count $c_i$ for $i \\in \\{1, \\dots, n\\}$. The total number of observed particles is $C = \\sum_{i=1}^{n} c_i$.\n\nTo proceed, a \"scientifically reasonable assumption about the distribution of $d$ within each bin\" is required. The most direct and standard assumption is that the probability density is uniform within each bin. This models the underlying continuous Probability Density Function (PDF), denoted $f(d)$, as a piecewise-constant function.\n\nFor the $i$-th bin, $[a_i, b_i]$, the probability $p_i$ of a particle's diameter falling within this range is given by the relative frequency of counts:\n$$\np_i = \\frac{c_i}{C}\n$$\nAccording to the definition of a PDF, this probability is also the integral of $f(d)$ over the bin's interval:\n$$\np_i = \\int_{a_i}^{b_i} f(d) \\, \\mathrm{d}d\n$$\nAssuming $f(d)$ is a constant, let's call it $h_i$, for $d \\in [a_i, b_i]$, the integral becomes:\n$$\np_i = h_i (b_i - a_i)\n$$\nBy equating the two expressions for $p_i$, we can solve for the constant density $h_i$ for each bin:\n$$\nh_i = \\frac{p_i}{b_i - a_i} = \\frac{c_i}{C(b_i - a_i)}\n$$\nThis defines our estimated PDF over the full range of observation, $[a_1, b_n]$:\n$$\nf(d) = \\begin{cases}\nh_i  \\text{for } d \\in [a_i, b_i], i \\in \\{1,\\dots,n\\} \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThis function is properly normalized, as $\\int_{a_1}^{b_n} f(d) \\, \\mathrm{d}d = \\sum_{i=1}^n h_i(b_i-a_i) = \\sum_{i=1}^n \\frac{c_i}{C} = 1$.\n\n**2. Calculation of Raw Moments**\n\nThe $k$-th raw moment, $m_k$, is defined as the expectation of $d^k$:\n$$\nm_k = \\int_{0}^{\\infty} d^k f(d) \\, \\mathrm{d}d\n$$\nUsing our piecewise-constant PDF, the integral becomes a sum over the bins:\n$$\nm_k = \\sum_{i=1}^{n} \\int_{a_i}^{b_i} d^k h_i \\, \\mathrm{d}d = \\sum_{i=1}^{n} h_i \\int_{a_i}^{b_i} d^k \\, \\mathrm{d}d\n$$\nThe integral of $d^k$ is a standard result from calculus: $\\int d^k \\, \\mathrm{d}d = \\frac{d^{k+1}}{k+1}$. Applying the limits of integration for each bin yields:\n$$\nm_k = \\sum_{i=1}^{n} h_i \\left[ \\frac{d^{k+1}}{k+1} \\right]_{a_i}^{b_i} = \\sum_{i=1}^{n} h_i \\left( \\frac{b_i^{k+1} - a_i^{k+1}}{k+1} \\right)\n$$\nSubstituting the expression for $h_i$, we arrive at the final formula for the moments based on the histogram data:\n$$\nm_k = \\frac{1}{C(k+1)} \\sum_{i=1}^{n} c_i \\frac{b_i^{k+1} - a_i^{k+1}}{b_i - a_i}\n$$\nThis formula is used to compute the first four raw moments, $m_k$, for $k \\in \\{1, 2, 3, 4\\}$.\n\n**3. Implementing Upper-Tail Truncation**\n\nTruncating the distribution at a diameter $T$ means constructing a new PDF, $f_T(d)$, that is zero for $d  T$ and proportional to the original PDF $f(d)$ for $d \\le T$. This requires renormalization.\n\nThe new PDF is defined as:\n$$\nf_T(d) = \\begin{cases}\n\\frac{f(d)}{P(T)}  \\text{for } d \\le T \\\\\n0  \\text{for } d  T\n\\end{cases}\n$$\nwhere $P(T)$ is the total probability mass of the original distribution up to the threshold $T$:\n$$\nP(T) = \\int_0^T f(d) \\, \\mathrm{d}d\n$$\nTo compute $P(T)$, we find the bin $j$ that contains $T$, such that $a_j \\le T  b_j$. The integral is the sum of probabilities of all bins fully below $T$, plus the partial probability of the bin straddling $T$:\n$$\nP(T) = \\left( \\sum_{i=1}^{j-1} \\int_{a_i}^{b_i} h_i \\, \\mathrm{d}d \\right) + \\int_{a_j}^{T} h_j \\, \\mathrm{d}d = \\left( \\sum_{i=1}^{j-1} h_i (b_i - a_i) \\right) + h_j (T - a_j)\n$$\nThis is a \"physically justified rule\" as it is a direct consequence of the uniform intra-bin density assumption.\n\n**4. Calculation of Truncated Moments and Sensitivity**\n\nThe $k$-th raw moment of the truncated distribution, $m_k(T)$, is computed using $f_T(d)$:\n$$\nm_k(T) = \\int_0^\\infty d^k f_T(d) \\, \\mathrm{d}d = \\frac{1}{P(T)} \\int_0^T d^k f(d) \\, \\mathrm{d}d\n$$\nThe integral in the numerator is calculated similarly to $P(T)$:\n$$\n\\int_0^T d^k f(d) \\, \\mathrm{d}d = \\left( \\sum_{i=1}^{j-1} \\int_{a_i}^{b_i} d^k h_i \\, \\mathrm{d}d \\right) + \\int_{a_j}^{T} d^k h_j \\, \\mathrm{d}d = \\left( \\sum_{i=1}^{j-1} h_i \\frac{b_i^{k+1} - a_i^{k+1}}{k+1} \\right) + h_j \\frac{T^{k+1} - a_j^{k+1}}{k+1}\n$$\nWith both the original moments $m_k$ and the truncated moments $m_k(T)$ computed for $k \\in \\{1, 2, 3, 4\\}$, the scalar sensitivity measure $S(T)$ is calculated as the maximum absolute relative change:\n$$\nS(T) = \\max_{k\\in\\{1,2,3,4\\}} \\left| \\frac{m_k(T) - m_k}{m_k} \\right|\n$$\nThe implementation will systematically apply these derived formulas to the provided test cases. All calculations will be performed using standard floating-point arithmetic, with care taken to handle the potential for large exponents in the moment calculations by using base SI units throughout.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print the results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"edges\": np.array([2.0e-7, 4.0e-7, 6.0e-7, 9.0e-7, 1.3e-6, 1.8e-6, 2.5e-6, 3.5e-6, 5.0e-6]),\n            \"counts\": np.array([5, 20, 60, 100, 140, 120, 80, 30]),\n            \"T\": 3.0e-6\n        },\n        {\n            \"edges\": np.array([5.0e-7, 1.0e-6, 1.5e-6, 2.0e-6, 3.0e-6, 4.0e-6, 6.0e-6, 8.0e-6, 1.0e-5, 1.2e-5, 1.4e-5, 1.7e-5, 2.0e-5]),\n            \"counts\": np.array([10, 15, 20, 25, 40, 60, 90, 120, 100, 80, 60, 40]),\n            \"T\": 8.0e-6\n        },\n        {\n            \"edges\": np.array([5.0e-8, 1.0e-7, 2.0e-7, 3.0e-7, 5.0e-7, 8.0e-7, 1.2e-6]),\n            \"counts\": np.array([200, 150, 80, 30, 10, 5]),\n            \"T\": 6.0e-7\n        },\n        {\n            \"edges\": np.array([1.0e-7, 5.0e-7, 1.0e-6, 2.0e-6, 4.0e-6]),\n            \"counts\": np.array([0, 50, 0, 150]),\n            \"T\": 1.2e-6\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        sensitivity = calculate_sensitivity(case[\"edges\"], case[\"counts\"], case[\"T\"])\n        results.append(f\"{sensitivity:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_sensitivity(bin_edges, counts, T):\n    \"\"\"\n    Calculates the sensitivity S(T) for a given PSD histogram.\n\n    Args:\n        bin_edges (np.array): Array of bin edges in meters (size n+1).\n        counts (np.array): Array of particle counts for each bin (size n).\n        T (float): Truncation threshold in meters.\n\n    Returns:\n        float: The scalar sensitivity S(T).\n    \"\"\"\n    n_bins = len(counts)\n    a = bin_edges[:-1]\n    b = bin_edges[1:]\n    \n    total_count = np.sum(counts)\n    if total_count == 0:\n        return 0.0\n\n    # Ensure bin widths are not zero to avoid division by zero\n    bin_widths = b - a\n    # Mask to handle bins with zero width or zero count to avoid NaN\n    valid_bins = (counts > 0)  (bin_widths > 0)\n\n    # 1. Calculate PDF heights h_i for each bin\n    h = np.zeros(n_bins)\n    h[valid_bins] = counts[valid_bins] / (total_count * bin_widths[valid_bins])\n\n    m_full = np.zeros(4)\n    m_trunc = np.zeros(4)\n    \n    # 2. Calculate untruncated moments m_k\n    for k_idx, k in enumerate(range(1, 5)):\n        k_plus_1 = float(k + 1)\n        # Integral of d^k over each bin\n        moment_contribs = (b**k_plus_1 - a**k_plus_1) / k_plus_1\n        m_full[k_idx] = np.sum(h * moment_contribs)\n\n    # 3. Calculate terms for truncated moments m_k(T)\n    # Find the index of the bin that contains T\n    # np.searchsorted returns j such that a[j-1] = T  a[j]\n    j = np.searchsorted(bin_edges, T)\n    \n    # Bins to be fully included are from index 0 to j-2 (since bin_edges has size n+1)\n    # The straddling bin is at index j-1.\n    \n    # Calculate P(T), the normalization factor for the truncated distribution\n    prob_mass_T = 0.0\n    if j > 1: # There are fully included bins\n        prob_mass_T += np.sum(h[:j-1] * bin_widths[:j-1])\n    if j > 0 and j = n_bins: # There is a straddling bin\n        if T > a[j-1]:\n            prob_mass_T += h[j-1] * (T - a[j-1])\n            \n    if prob_mass_T = 0: # This case shouldn't happen with given test data\n        return 0.0\n\n    # Calculate numerator of truncated moments: integral of d^k * f(d) up to T\n    for k_idx, k in enumerate(range(1, 5)):\n        k_plus_1 = float(k + 1)\n        moment_integral_T = 0.0\n        \n        # Contribution from fully included bins\n        if j > 1:\n            full_contribs = h[:j-1] * (b[:j-1]**k_plus_1 - a[:j-1]**k_plus_1) / k_plus_1\n            moment_integral_T += np.sum(full_contribs)\n        \n        # Contribution from straddling bin\n        if j > 0 and j = n_bins:\n            if T > a[j-1]:\n                partial_contrib = h[j-1] * (T**k_plus_1 - a[j-1]**k_plus_1) / k_plus_1\n                moment_integral_T += partial_contrib\n        \n        m_trunc[k_idx] = moment_integral_T / prob_mass_T\n\n    # 4. Calculate sensitivity S(T)\n    rel_changes = np.abs((m_trunc - m_full) / m_full)\n    max_rel_change = np.max(rel_changes)\n    \n    return max_rel_change\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "With a quantitative description of the PSD, we can begin to model its direct impact on electrochemical performance and degradation. This practice focuses on the formation of the Solid Electrolyte Interphase (SEI), a critical process where capacity is irreversibly lost, and which is fundamentally governed by the total active surface area. By analyzing a bimodal distribution of fine and coarse particles, you will derive how the number fraction of fines disproportionately increases capacity loss, providing a concrete link between microstructure and cell lifetime. ",
            "id": "3938205",
            "problem": "Consider a negative electrode composed of spherical graphite particles with a bimodal size distribution. The total number density distribution per unit electrode volume is $f_n(d)$ (units: $\\mathrm{m}^{-4}$), so that $\\int f_n(d)\\,dd$ is the particle number density. Each particle of diameter $d$ has surface area $a_s(d)$ and volume $v_p(d)$ given by the sphere formulas $a_s(d)=\\pi d^{2}$ and $v_p(d)=\\frac{\\pi}{6}d^{3}$. Let the Solid Electrolyte Interphase (SEI) form during an initial formation hold of duration $t$ with a molar flux per unit particle surface area $J(d)$ that depends on diameter via $J(d)=J_{0}\\left(\\frac{d_{\\mathrm{ref}}}{d}\\right)^{m}$, where $J_{0}$, $d_{\\mathrm{ref}}$, and $m$ are known constants. The charge passed per mole of SEI species is $zF$, where $z$ is the effective electron number and $F$ is Faraday’s constant.\n\nStarting from Faraday’s law and conservation of surface area in a porous packing, the cumulative SEI formation charge per electrode area is\n$$\nQ_{\\mathrm{SEI}}=zF\\,t\\,L\\,\\int a_s(d)\\,J(d)\\,f_n(d)\\,dd,\n$$\nwhere $L$ is the electrode thickness. The porous solid volume fraction is fixed at $\\phi_{s}$, which implies the number density $f_n(d)$ must satisfy the volume constraint\n$$\n\\phi_{s}=\\int v_p(d)\\,f_n(d)\\,dd.\n$$\nAssume a bimodal mixture with fines of diameter $d_{f}$ and coarse particles of diameter $d_{c}$, defined by a number-fraction parameter $p_{f}$ through\n$$\nf_n(d)=n_{\\mathrm{tot}}(p_{f})\\left[p_{f}\\,\\delta(d-d_{f})+(1-p_{f})\\,\\delta(d-d_{c})\\right],\n$$\nwhere $\\delta(\\cdot)$ is the Dirac delta and $n_{\\mathrm{tot}}(p_{f})$ is chosen to enforce the solid volume constraint at all $p_{f}$. The electrode has areal discharge capacity $C_{A}$ (charge per area), and the fractional capacity lost to SEI is defined as $\\chi(p_{f})=\\frac{Q_{\\mathrm{SEI}}(p_{f})}{C_{A}}$.\n\nUsing these definitions and fundamental laws, derive the sensitivity of fractional capacity loss to the fines number-fraction at the coarse-only baseline, i.e.,\n$$\nS=\\left.\\frac{d\\chi}{dp_{f}}\\right|_{p_{f}=0}.\n$$\nEvaluate $S$ numerically for the following scientifically plausible parameters: $z=2$, $F=96485\\,\\mathrm{C\\,mol^{-1}}$, $t=7200\\,\\mathrm{s}$, $L=60\\times 10^{-6}\\,\\mathrm{m}$, $J_{0}=1.0\\times 10^{-8}\\,\\mathrm{mol\\,m^{-2}\\,s^{-1}}$, $d_{\\mathrm{ref}}=10\\times 10^{-6}\\,\\mathrm{m}$, $m=1$, $\\phi_{s}=0.50$, $d_{f}=4\\times 10^{-6}\\,\\mathrm{m}$, $d_{c}=12\\times 10^{-6}\\,\\mathrm{m}$, and $C_{A}=3.0\\,\\mathrm{mAh\\,cm^{-2}}$ converted to $\\mathrm{C\\,m^{-2}}$ using $1\\,\\mathrm{mAh}=3.6\\,\\mathrm{C}$. Express the final sensitivity $S$ as a decimal fraction (unitless), and round your answer to four significant figures.",
            "solution": "The problem requires the derivation of the sensitivity of fractional capacity loss, $\\chi$, to the number-fraction of fine particles, $p_f$, evaluated at the baseline where no fines are present ($p_f=0$). This sensitivity is defined as $S = \\left.\\frac{d\\chi}{dp_f}\\right|_{p_f=0}$.\n\n**Step 1: Express Total Particle Number Density**\nFirst, we express the total particle number density $n_{\\mathrm{tot}}(p_f)$ by enforcing the solid volume fraction constraint $\\phi_s$:\n$$\n\\phi_s = \\int v_p(d) f_n(d) \\,dd = \\int \\frac{\\pi}{6}d^3 n_{\\mathrm{tot}}(p_f) \\left[p_f\\,\\delta(d-d_f) + (1-p_f)\\,\\delta(d-d_c)\\right] \\,dd\n$$\n$$\n\\phi_s = n_{\\mathrm{tot}}(p_f) \\frac{\\pi}{6} \\left[p_f d_f^3 + (1-p_f)d_c^3\\right]\n$$\nSolving for $n_{\\mathrm{tot}}(p_f)$ gives:\n$$\nn_{\\mathrm{tot}}(p_f) = \\frac{6\\phi_s}{\\pi\\left[p_f d_f^3 + (1-p_f)d_c^3\\right]}\n$$\n\n**Step 2: Express SEI Formation Charge**\nNext, we find the total SEI formation charge, $Q_{\\mathrm{SEI}}(p_f)$. The integrand involves the product of surface area $a_s(d) = \\pi d^2$ and flux $J(d) = J_0(d_{\\mathrm{ref}}/d)^m$. With $m=1$, this product is $\\pi d^2 \\cdot J_0 d_{\\mathrm{ref}}/d = \\pi J_0 d_{\\mathrm{ref}} d$. The integral over the bimodal PSD is:\n$$\n\\int a_s(d)J(d)f_n(d)\\,dd = n_{\\mathrm{tot}}(p_f) \\pi J_0 d_{\\mathrm{ref}} \\left[p_f d_f + (1-p_f)d_c\\right]\n$$\nSubstituting this and $n_{\\mathrm{tot}}(p_f)$ into the expression for $Q_{\\mathrm{SEI}}$ yields:\n$$\nQ_{\\mathrm{SEI}}(p_f) = (zFtL) (n_{\\mathrm{tot}}(p_f) \\pi J_0 d_{\\mathrm{ref}} \\left[p_f d_f + (1-p_f)d_c\\right]) = 6zFtL\\phi_s J_0 d_{\\mathrm{ref}} \\frac{p_f d_f + (1-p_f)d_c}{p_f d_f^3 + (1-p_f)d_c^3}\n$$\n\n**Step 3: Derive the Sensitivity**\nThe fractional capacity loss is $\\chi(p_f) = Q_{\\mathrm{SEI}}(p_f)/C_A$. To find the sensitivity $S$, we compute the derivative of $\\chi(p_f)$ with respect to $p_f$ and evaluate it at $p_f=0$. It is convenient to use logarithmic differentiation. Let $K = 6zFtL\\phi_s J_0 d_{\\mathrm{ref}}$, $N(p_f)=p_f d_f + (1-p_f)d_c$, and $D(p_f)=p_f d_f^3 + (1-p_f)d_c^3$. Then $\\chi(p_f) = \\frac{K}{C_A}\\frac{N(p_f)}{D(p_f)}$.\nThe derivative is $\\frac{d\\chi}{dp_f} = \\chi(p_f) \\left( \\frac{N'(p_f)}{N(p_f)} - \\frac{D'(p_f)}{D(p_f)} \\right)$. We evaluate this at $p_f=0$:\n$N(0)=d_c$, $D(0)=d_c^3$, $N'(p_f)=d_f-d_c$, and $D'(p_f)=d_f^3-d_c^3$.\n$$\nS = \\left.\\frac{d\\chi}{dp_f}\\right|_{p_f=0} = \\chi(0) \\left( \\frac{N'(0)}{N(0)} - \\frac{D'(0)}{D(0)} \\right)\n$$\n$$\nS = \\chi(0) \\left( \\frac{d_f-d_c}{d_c} - \\frac{d_f^3-d_c^3}{d_c^3} \\right) = \\chi(0) \\left( \\frac{d_c^2(d_f-d_c) - (d_f^3-d_c^3)}{d_c^3} \\right)\n$$\n$$\nS = \\chi(0) \\left( \\frac{d_c^2 d_f - d_c^3 - d_f^3 + d_c^3}{d_c^3} \\right) = \\chi(0) \\frac{d_f(d_c^2 - d_f^2)}{d_c^3}\n$$\n\n**Step 4: Numerical Evaluation**\nFirst, convert areal capacity to SI units: $C_A = 3.0\\,\\mathrm{mAh\\,cm^{-2}} = 3.0 \\times 3.6\\,\\mathrm{C} / (10^{-2}\\,\\mathrm{m})^2 = 1.08 \\times 10^5\\,\\mathrm{C\\,m^{-2}}$.\nNext, calculate the baseline fractional loss $\\chi(0)$:\n$$\n\\chi(0) = \\frac{Q_{\\mathrm{SEI}}(0)}{C_A} = \\frac{6zFtL\\phi_s J_0 d_{\\mathrm{ref}}}{C_A} \\frac{d_c}{d_c^3} = \\frac{6zFtL\\phi_s J_0 d_{\\mathrm{ref}}}{C_A d_c^2}\n$$\n$$\n\\chi(0) = \\frac{6(2)(96485)(7200)(60\\times 10^{-6})(0.5)(1.0\\times 10^{-8})(10\\times 10^{-6})}{(1.08 \\times 10^5) (12\\times 10^{-6})^2} \\approx 0.00160809\n$$\nFinally, calculate the sensitivity $S$:\n$$\nS = (0.00160809) \\frac{4\\times 10^{-6}((12\\times 10^{-6})^2 - (4\\times 10^{-6})^2)}{(12\\times 10^{-6})^3} = (0.00160809) \\frac{4(144-16)}{1728}\n$$\n$$\nS \\approx 0.00160809 \\times \\frac{512}{1728} \\approx 0.00047647\n$$\nRounding to four significant figures, the sensitivity is $0.0004765$.",
            "answer": "$$\n\\boxed{0.0004765}\n$$"
        },
        {
            "introduction": "To accurately simulate battery behavior, it is essential to move beyond single-particle approximations and incorporate the full particle size distribution into electrochemical models. This advanced practice introduces the Quadrature-Based Method of Moments (QBMM), a powerful numerical technique for achieving this representation efficiently. You will implement the core algorithm to reconstruct a multi-point approximation of a PSD from its moments and use it to compute an aggregate property, demonstrating how complex microstructural information can be robustly integrated into macro-scale battery simulations. ",
            "id": "3938240",
            "problem": "Consider an automated battery design and simulation task where the Pseudo-Two-Dimensional (P2D) single-particle model is extended to account for a distribution of particle sizes using a Quadrature-Based Method of Moments (QBMM). The goal is to formalize the closure of particle-size-dependent fluxes using a finite set of Particle Size Distribution (PSD) moments, and to implement a computational procedure that reconstructs a quadrature over particle radii from moments and uses it to approximate integrals needed for electrode flux calculations.\n\nAssume an electrode composed of spherical particles with radius $R \\ge 0$. Let $n(R)$ denote the particle number density per unit electrode volume as a function of radius. The $k$-th raw moment of $n(R)$ is defined as\n$$\n\\mu_k = \\int_{0}^{\\infty} R^k n(R)\\, dR,\n$$\nfor $k \\in \\{0,1,2,3\\}$, where $\\mu_0$ is the total particle number density per unit electrode volume. Consider a particle-surface intercalation flux per unit area that depends on particle size as\n$$\nj_\\mathrm{surf}(R) = k\\, R^\\gamma,\n$$\nwhere $k  0$ and $\\gamma \\ge 0$ are constants. The electrode volumetric intercalation current density is the integral of surface flux over all particle surfaces per unit electrode volume:\n$$\nJ = \\int_{0}^{\\infty} 4\\pi R^2\\, j_\\mathrm{surf}(R)\\, n(R)\\, dR = 4\\pi k \\int_{0}^{\\infty} R^{2+\\gamma} n(R)\\, dR.\n$$\n\nThe QBMM closure approximates integrals over $R$ by a finite quadrature constructed to match a finite number of moments. Specifically, using a two-node quadrature,\n$$\n\\int_{0}^{\\infty} f(R)\\, n(R)\\, dR \\approx w_1 f(r_1) + w_2 f(r_2),\n$$\nwith nodes $r_1, r_2  0$ and weights $w_1, w_2  0$ chosen such that the quadrature is exact for polynomials up to degree $3$, i.e.,\n$$\nw_1 r_1^k + w_2 r_2^k = \\mu_k \\quad \\text{for} \\quad k=0,1,2,3.\n$$\nA constructive way to obtain $r_1, r_2$ is via the generalized eigenvalue problem associated with the moment Hankel matrices,\n$$\nH_0 = \\begin{bmatrix} \\mu_0  \\mu_1 \\\\ \\mu_1  \\mu_2 \\end{bmatrix}, \\quad\nH_1 = \\begin{bmatrix} \\mu_1  \\mu_2 \\\\ \\mu_2  \\mu_3 \\end{bmatrix},\n$$\nby solving for eigenvalues $\\lambda$ in\n$$\nH_1 \\mathbf{v} = \\lambda\\, H_0 \\mathbf{v}.\n$$\nUnder standard moment positivity conditions, the eigenvalues are real and equal to $r_1$ and $r_2$. The weights $w_1$ and $w_2$ are then obtained by solving\n$$\n\\begin{bmatrix} 1  1 \\\\ r_1  r_2 \\end{bmatrix}\n\\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} =\n\\begin{bmatrix} \\mu_0 \\\\ \\mu_1 \\end{bmatrix}.\n$$\n\nStarting from the definitions above and the conservation-law interpretation that the electrode volumetric current density $J$ is an area-weighted integral of the intercalation flux over the PSD, derive the QBMM closure and implement it to compute an approximation $J_\\mathrm{QBMM}$ to $J$. For test distributions where analytic expressions for moments of arbitrary real order are available, compare $J_\\mathrm{QBMM}$ against the exact value\n$$\nJ_\\mathrm{exact} = 4\\pi k\\, \\mu_{2+\\gamma},\n$$\nand report the relative error\n$$\ne = \\frac{|J_\\mathrm{QBMM} - J_\\mathrm{exact}|}{J_\\mathrm{exact}}.\n$$\n\nUse the following scientifically plausible test suite of PSDs and parameters. In each case, compute $\\mu_k$ for $k \\in \\{0,1,2,3\\}$ from the given PSD, reconstruct the two-node quadrature, compute $J_\\mathrm{QBMM}$, and produce the relative error $e$ as a float. When the PSD is a finite mixture of delta distributions, additionally verify node recovery.\n\nDefinitions and facts to use:\n- For a lognormal PSD with parameters median $m$ and geometric standard deviation $s_g$, where $\\ln R \\sim \\mathcal{N}(\\ln m, (\\ln s_g)^2)$, the real-order raw moment is\n$$\n\\mu_q = N_0\\, \\mathbb{E}[R^q] = N_0\\, \\exp\\!\\left(q \\ln m + \\tfrac{1}{2} q^2 (\\ln s_g)^2\\right),\n$$\nfor any real $q$, and $N_0$ is the total particle number density per unit volume.\n- For a two-point atomic PSD $n(R) = N_1\\, \\delta(R-a) + N_2\\, \\delta(R-b)$ with $a,b0$, the raw moments are $\\mu_k = N_1 a^k + N_2 b^k$ for all integer $k \\ge 0$.\n\nTest cases:\n1. Lognormal PSD with $N_0 = 1.0\\times 10^{18}$, $m = 5.0\\times 10^{-6}$, $s_g = 1.5$, $k = 2.5$, $\\gamma = 1.0$. Report the relative error $e$ (dimensionless).\n2. Nearly monodisperse lognormal PSD with $N_0 = 1.0\\times 10^{18}$, $m = 5.0\\times 10^{-6}$, $s_g = 1.01$, $k = 1.75$, $\\gamma = 0.5$. Report the relative error $e$ (dimensionless).\n3. Broad lognormal PSD with $N_0 = 1.0\\times 10^{18}$, $m = 2.0\\times 10^{-6}$, $s_g = 3.0$, $k = 3.0$, $\\gamma = 1.2$. Report the relative error $e$ (dimensionless).\n4. Atomic two-point PSD with $N_1 = 6.0\\times 10^{17}$, $N_2 = 4.0\\times 10^{17}$, $a = 3.0\\times 10^{-6}$, $b = 8.0\\times 10^{-6}$. Reconstruct the quadrature nodes $r_1, r_2$ and weights $w_1, w_2$ from $\\mu_0, \\mu_1, \\mu_2, \\mu_3$ and verify whether $\\{r_1, r_2\\}$ matches $\\{a,b\\}$ and $\\{w_1, w_2\\}$ matches $\\{N_1, N_2\\}$ to within an absolute tolerance of $1.0\\times 10^{-12}$. Report the result as a boolean.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases above (i.e., $[e_1,e_2,e_3,b_4]$). All reported errors are dimensionless floats, and the final entry is a boolean.",
            "solution": "The problem requires the derivation and implementation of a Quadrature-Based Method of Moments (QBMM) closure to approximate the volumetric intercalation current density in a battery electrode. This involves using a two-node quadrature, constructed from the first four moments of the particle size distribution (PSD), to approximate an integral over the PSD.\n\nThe electrode volumetric intercalation current density, $J$, is given by the integral of the surface flux over all particle surfaces within a unit volume of the electrode. Given a particle number density $n(R)$ and a surface flux $j_{\\mathrm{surf}}(R) = k R^\\gamma$, where $R$ is the particle radius, $k  0$ and $\\gamma \\ge 0$, the expression for $J$ is:\n$$\nJ = \\int_{0}^{\\infty} (4\\pi R^2) \\, j_{\\mathrm{surf}}(R) \\, n(R) \\, dR\n$$\nSubstituting the expression for $j_{\\mathrm{surf}}(R)$, we get:\n$$\nJ = \\int_{0}^{\\infty} 4\\pi R^2 \\, (k R^\\gamma) \\, n(R) \\, dR = 4\\pi k \\int_{0}^{\\infty} R^{2+\\gamma} n(R) \\, dR\n$$\nBy the definition of the $q$-th raw moment of the PSD, $\\mu_q = \\int_{0}^{\\infty} R^q n(R) dR$, the exact expression for the current density is:\n$$\nJ_{\\mathrm{exact}} = 4\\pi k \\, \\mu_{2+\\gamma}\n$$\n\nThe QBMM approach approximates the integral over the PSD using a finite quadrature. For a two-node quadrature with nodes $r_1, r_2$ and weights $w_1, w_2$, the approximation is:\n$$\n\\int_{0}^{\\infty} f(R) \\, n(R) \\, dR \\approx w_1 f(r_1) + w_2 f(r_2)\n$$\nIn our case, the function to be integrated is $f(R) = R^{2+\\gamma}$. Applying this approximation to the integral in the expression for $J$ yields the QBMM-approximated current density, $J_{\\mathrm{QBMM}}$:\n$$\nJ_{\\mathrm{QBMM}} = 4\\pi k \\left( w_1 r_1^{2+\\gamma} + w_2 r_2^{2+\\gamma} \\right)\n$$\nThis expression constitutes the QBMM closure for the volumetric current density.\n\nThe core of the method is the reconstruction of the quadrature nodes and weights from a set of known moments. The problem specifies that the two-node quadrature must be exact for polynomials of degree up to $3$. This requires the nodes and weights to satisfy the following system of four equations, using the first four moments $\\mu_0, \\mu_1, \\mu_2, \\mu_3$:\n$$\nw_1 r_1^k + w_2 r_2^k = \\mu_k \\quad \\text{for} \\quad k \\in \\{0, 1, 2, 3\\}\n$$\n\nA standard and robust algorithm to determine the nodes $r_1, r_2$ from these moments involves solving a generalized eigenvalue problem. First, two Hankel matrices are constructed from the moments:\n$$\nH_0 = \\begin{bmatrix} \\mu_0  \\mu_1 \\\\ \\mu_1  \\mu_2 \\end{bmatrix}, \\quad\nH_1 = \\begin{bmatrix} \\mu_1  \\mu_2 \\\\ \\mu_2  \\mu_3 \\end{bmatrix}\n$$\nThe quadrature nodes, $r_1$ and $r_2$, are the eigenvalues $\\lambda$ of the generalized eigenvalue problem $H_1 \\mathbf{v} = \\lambda H_0 \\mathbf{v}$. For a valid set of moments from a positive measure (which is the case for any physically realistic PSD), $H_0$ is positive definite and the eigenvalues are guaranteed to be real and positive, corresponding to the quadrature nodes.\n\nOnce the nodes $r_1$ and $r_2$ are found, the weights $w_1$ and $w_2$ can be determined by solving the first two moment-matching equations ($k=0$ and $k=1$), which form a linear system:\n$$\n\\begin{bmatrix} 1  1 \\\\ r_1  r_2 \\end{bmatrix}\n\\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} =\n\\begin{bmatrix} \\mu_0 \\\\ \\mu_1 \\end{bmatrix}\n$$\nThis system is guaranteed to have a unique solution for $w_1, w_2$ since the determinant of the coefficient matrix, $r_2 - r_1$, is non-zero for distinct nodes, a condition met by non-monodisperse distributions.\n\nThe overall computational procedure for each test case is as follows:\n1.  **Calculate Moments**: Given a PSD, calculate the first four raw moments $\\mu_0, \\mu_1, \\mu_2, \\mu_3$.\n    - For a lognormal PSD with parameters $N_0$, $m$, $s_g$, the moments are $\\mu_k = N_0 \\exp(k \\ln m + \\frac{1}{2} k^2 (\\ln s_g)^2)$.\n    - For a two-point atomic PSD $n(R) = N_1\\delta(R-a) + N_2\\delta(R-b)$, the moments are $\\mu_k = N_1 a^k + N_2 b^k$.\n2.  **Determine Quadrature**:\n    - Construct the Hankel matrices $H_0$ and $H_1$.\n    - Solve the generalized eigenvalue problem $H_1 \\mathbf{v} = \\lambda H_0 \\mathbf{v}$ to find the nodes $r_1, r_2$ (the eigenvalues $\\lambda$).\n    - Solve the linear system for the weights $w_1, w_2$.\n3.  **Compute Current Density and Error (Cases 1-3)**:\n    - Calculate $J_{\\mathrm{QBMM}} = 4\\pi k (w_1 r_1^{2+\\gamma} + w_2 r_2^{2+\\gamma})$.\n    - Calculate the exact moment $\\mu_{2+\\gamma}$ using the analytical formula for the lognormal distribution.\n    - Calculate $J_{\\mathrm{exact}} = 4\\pi k \\mu_{2+\\gamma}$.\n    - Compute the relative error $e = |J_{\\mathrm{QBMM}} - J_{\\mathrm{exact}}| / J_{\\mathrm{exact}}$.\n4.  **Verify Node/Weight Recovery (Case 4)**:\n    - A two-node quadrature is exact for an atomic distribution with two support points. Therefore, the reconstructed nodes $\\{r_1, r_2\\}$ and weights $\\{w_1, w_2\\}$ must match the true locations $\\{a, b\\}$ and magnitudes $\\{N_1, N_2\\}$ of the delta functions, respectively.\n    - We verify this by comparing the sorted sets of reconstructed and true parameters, checking if the absolute differences are within the specified tolerance of $1.0 \\times 10^{-12}$.\n\nThis procedure is implemented numerically using `scipy.linalg.eig` for the generalized eigenvalue problem and `numpy.linalg.solve` for the linear system determining the weights.",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n\n    def calculate_lognormal_moments(N0, m, sg, k_orders):\n        \"\"\"Calculates moments for a lognormal distribution.\"\"\"\n        ln_m = np.log(m)\n        ln_sg_sq = np.log(sg)**2\n        moments = [N0 * np.exp(k * ln_m + 0.5 * k**2 * ln_sg_sq) for k in k_orders]\n        return moments\n\n    def calculate_atomic_moments(N1, N2, a, b, k_orders):\n        \"\"\"Calculates moments for a two-point atomic distribution.\"\"\"\n        moments = [N1 * a**k + N2 * b**k for k in k_orders]\n        return moments\n\n    def reconstruct_quadrature(mu):\n        \"\"\"Reconstructs two-node quadrature from the first four moments.\"\"\"\n        mu0, mu1, mu2, mu3 = mu\n        \n        # Construct Hankel matrices\n        H0 = np.array([[mu0, mu1], [mu1, mu2]])\n        H1 = np.array([[mu1, mu2], [mu2, mu3]])\n\n        # Solve the generalized eigenvalue problem H1*v = lambda*H0*v for the nodes\n        # The eigenvalues are the nodes r1, r2.\n        # We take the real part to discard negligible imaginary parts from numerical error.\n        nodes = np.real(linalg.eig(H1, H0)[0])\n        r1, r2 = nodes[0], nodes[1]\n\n        # Solve the linear system for the weights w1, w2\n        # [ 1  1 ] [w1] = [mu0]\n        # [r1 r2] [w2]   [mu1]\n        A = np.array([[1, 1], [r1, r2]])\n        b = np.array([mu0, mu1])\n        weights = linalg.solve(A, b)\n        \n        return nodes, weights\n\n    def solve_lognormal_case(N0, m, sg, k_const, gamma):\n        \"\"\"Solves a lognormal PSD case and returns the relative error.\"\"\"\n        # Calculate the first four moments (k=0,1,2,3)\n        mu = calculate_lognormal_moments(N0, m, sg, [0, 1, 2, 3])\n        \n        # Reconstruct quadrature\n        nodes, weights = reconstruct_quadrature(mu)\n        r1, r2 = nodes[0], nodes[1]\n        w1, w2 = weights[0], weights[1]\n        \n        # Calculate J_QBMM\n        integral_approx = w1 * r1**(2 + gamma) + w2 * r2**(2 + gamma)\n        J_QBMM = 4 * np.pi * k_const * integral_approx\n        \n        # Calculate J_exact\n        mu_exact_order = 2 + gamma\n        mu_exact = calculate_lognormal_moments(N0, m, sg, [mu_exact_order])[0]\n        J_exact = 4 * np.pi * k_const * mu_exact\n        \n        # Calculate relative error\n        if J_exact == 0:\n            return 0.0 # Avoid division by zero\n        relative_error = np.abs(J_QBMM - J_exact) / np.abs(J_exact)\n        return relative_error\n\n    def solve_atomic_case(N1, N2, a, b, tol):\n        \"\"\"Solves the atomic PSD case and verifies node/weight recovery.\"\"\"\n        # Calculate the first four moments\n        mu = calculate_atomic_moments(N1, N2, a, b, [0, 1, 2, 3])\n\n        # Reconstruct quadrature\n        nodes_recon, weights_recon_unsorted = reconstruct_quadrature(mu)\n\n        # Sort the reconstructed nodes and their corresponding weights\n        sort_indices_recon = np.argsort(nodes_recon)\n        r_recon_sorted = nodes_recon[sort_indices_recon]\n        w_recon_sorted = weights_recon_unsorted[sort_indices_recon]\n\n        # Define and sort the true nodes and weights\n        nodes_true = np.array([a, b])\n        weights_true = np.array([N1, N2])\n        sort_indices_true = np.argsort(nodes_true)\n        r_true_sorted = nodes_true[sort_indices_true]\n        w_true_sorted = weights_true[sort_indices_true]\n\n        # Verify recovery within tolerance\n        nodes_match = np.allclose(r_recon_sorted, r_true_sorted, atol=tol, rtol=0)\n        weights_match = np.allclose(w_recon_sorted, w_true_sorted, atol=tol, rtol=0)\n        \n        return nodes_match and weights_match\n\n    # Test Case 1\n    err1 = solve_lognormal_case(N0=1.0e18, m=5.0e-6, sg=1.5, k_const=2.5, gamma=1.0)\n\n    # Test Case 2\n    err2 = solve_lognormal_case(N0=1.0e18, m=5.0e-6, sg=1.01, k_const=1.75, gamma=0.5)\n\n    # Test Case 3\n    err3 = solve_lognormal_case(N0=1.0e18, m=2.0e-6, sg=3.0, k_const=3.0, gamma=1.2)\n\n    # Test Case 4\n    bool4 = solve_atomic_case(N1=6.0e17, N2=4.0e17, a=3.0e-6, b=8.0e-6, tol=1.0e-12)\n\n    results = [err1, err2, err3, bool4]\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}