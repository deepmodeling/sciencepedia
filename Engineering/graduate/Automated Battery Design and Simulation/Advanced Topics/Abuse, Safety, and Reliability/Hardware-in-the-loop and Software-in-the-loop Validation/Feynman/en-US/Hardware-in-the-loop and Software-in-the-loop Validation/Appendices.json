{
    "hands_on_practices": [
        {
            "introduction": "A core function of a Battery Management System (BMS) is to estimate internal states, such as State of Charge (SOC), from external measurements like voltage and current. Before validating a model in a SIL or HIL environment, we must first confirm that it is theoretically possible to infer these states. This practice guides you through a formal observability analysis, connecting the physical shape of the battery's Open-Circuit Voltage (OCV) curve to the mathematical conditions required for successful state estimation . By constructing the observability Gramian, you will gain a rigorous understanding of why SOC estimation is more reliable in certain operating regions than in others.",
            "id": "3918287",
            "problem": "A battery pack is modeled for automated battery design and simulation using an Equivalent Circuit Model with a single resistive-capacitive polarization branch and the State of Charge (SOC). The model is embedded in both Software-in-the-Loop (SIL) and Hardware-in-the-Loop (HIL) validation environments. Consider a constant-current charge experiment over a finite horizon $[0, T]$, with known charging current $I$ and nominal state $(\\mathrm{SOC}_{0}, v_{rc,0})$. The terminal voltage measurement is available. Define Open-Circuit Voltage (OCV) as a function $E(\\mathrm{SOC})$, with local slope $k \\equiv \\frac{\\partial E}{\\partial \\mathrm{SOC}}\\big|_{\\mathrm{SOC}_{0}}$.\n\nStarting from conservation of charge and linear energy storage in the polarization branch, linearize the system about $(\\mathrm{SOC}_{0}, v_{rc,0})$ under constant-current charging. Let the small-signal state vector be $x = [x_{1}, x_{2}]^{\\top}$, where $x_{1}$ is the SOC deviation and $x_{2}$ is the polarization voltage deviation. Assume the resistive drop from the series resistance is compensated in post-processing using the known current $I$, so the small-signal output is $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$.\n\nUnder these conditions:\n- The SOC deviation $x_{1}$ obeys charge conservation with constant current (no small-signal input), and the polarization voltage $x_{2}$ relaxes with a time constant $\\tau > 0$.\n- The local linearization yields a linear time-invariant state-space model with state matrix $A$ and output matrix $C$ depending on $k$ and $\\tau$.\n\nConstruct an observability test for SOC by deriving the finite-horizon observability Gramian over $[0, T]$ for the linearized model and computing its determinant. Then, to eliminate units and isolate the role of time scales, report the dimensionless normalized determinant\n$$\\Delta \\equiv \\frac{\\det(W_{o})}{k^{2} \\tau^{2}},$$\nwhere $W_{o}$ is the observability Gramian over $[0, T]$.\n\nJustify, through your derivation, how the slope $k = \\frac{\\partial E}{\\partial \\mathrm{SOC}}\\big|_{\\mathrm{SOC}_{0}}$ enters the observability Gramian and affects SOC observability. Provide your final answer as a single closed-form analytic expression for $\\Delta$ in terms of $T$ and $\\tau$. No numerical evaluation or rounding is required. Acronyms to use: State of Charge (SOC), Open-Circuit Voltage (OCV), Hardware-in-the-Loop (HIL), Software-in-the-Loop (SIL).",
            "solution": "The user wants me to solve the problem by following these steps:\n1.  **Validate the problem statement**: I will check for scientific soundness, well-posedness, and other criteria.\n2.  If valid, **derive the solution**: I will formulate the state-space model, derive the observability Gramian, compute its determinant, and finally find the normalized determinant $\\Delta$.\n\n### Step 1: Extract Givens\n-   System: Battery pack modeled with a single resistive-capacitive (RC) polarization branch and State of Charge (SOC).\n-   Validation context: Software-in-the-Loop (SIL) and Hardware-in-the-Loop (HIL).\n-   Experiment: Constant-current charge with current $I$ over a time horizon $[0, T]$.\n-   Initial state: Nominal state $(\\mathrm{SOC}_{0}, v_{rc,0})$.\n-   Measurement: Terminal voltage.\n-   Definition: Open-Circuit Voltage (OCV) is a function $E(\\mathrm{SOC})$.\n-   Parameter: $k \\equiv \\frac{\\partial E}{\\partial \\mathrm{SOC}}\\big|_{\\mathrm{SOC}_{0}}$.\n-   Linearization: About $(\\mathrm{SOC}_{0}, v_{rc,0})$.\n-   Small-signal state vector: $x = [x_{1}, x_{2}]^{\\top}$, where $x_{1}$ is SOC deviation and $x_{2}$ is polarization voltage deviation.\n-   Small-signal output: $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$, assuming series resistance drop is compensated.\n-   Dynamics assumption 1: SOC deviation $x_{1}$ obeys charge conservation with constant current (no small-signal input).\n-   Dynamics assumption 2: Polarization voltage deviation $x_{2}$ relaxes with a time constant $\\tau > 0$.\n-   Task 1: Construct an observability test by deriving the finite-horizon observability Gramian $W_{o}$ over $[0, T]$.\n-   Task 2: Compute its determinant, $\\det(W_o)$.\n-   Task 3: Report the dimensionless normalized determinant $\\Delta \\equiv \\frac{\\det(W_{o})}{k^{2} \\tau^{2}}$.\n-   Task 4: Justify how $k$ affects SOC observability through the derivation.\n-   Task 5: Provide the final answer for $\\Delta$ as a closed-form expression in terms of $T$ and $\\tau$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The use of an Equivalent Circuit Model (ECM) with an RC branch, state-space representation, linearization, and observability analysis are all standard, well-established techniques in battery modeling, simulation, and control for automated design. The problem is well-posed, providing sufficient information and clear assumptions to construct a linear time-invariant (LTI) model and perform the required analysis. The language is objective and precise. The assumptions, such as \"no small-signal input\" for the autonomous system observability analysis and the defined form of the small-signal output, are explicit and allow for a unique formalization. The problem is self-contained and does not violate any physical or mathematical principles. There are no contradictions or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe solution is structured as follows: First, we derive the linearized state-space model $(A, C)$ based on the problem description. Second, we justify the role of the OCV slope $k$ in observability. Third, we compute the finite-horizon observability Gramian $W_o$. Fourth, we calculate its determinant. Finally, we derive the normalized determinant $\\Delta$.\n\n**1. State-Space Model Formulation**\n\nWe are asked to find a linear time-invariant state-space model of the form $\\dot{x}(t) = Ax(t)$ and $y(t) = Cx(t)$ for the small-signal deviations $x(t) = [x_1(t), x_2(t)]^\\top$.\n\nThe state $x_1$ represents the SOC deviation. The fundamental equation for SOC is $\\frac{d(\\mathrm{SOC})}{dt} = \\frac{I(t)}{Q_n}$, where $Q_n$ is the nominal capacity and $I(t)$ is the input current. For observability analysis of an LTI system, we consider the autonomous system (zero input). The problem states \"no small-signal input,\" which implies we analyze the system's inherent dynamics. The SOC itself is not a function of the other states (SOC, $v_{rc}$), but is driven by the integral of current. In the absence of a small-signal current input, the rate of change of the SOC *deviation* is zero. This corresponds to the dynamics of a pure integrator. Therefore, the state equation for $x_1$ is:\n$$\n\\dot{x}_1(t) = 0\n$$\n\nThe state $x_2$ is the polarization voltage deviation. The problem states that this deviation \"relaxes with a time constant $\\tau > 0$\". This describes a first-order decay process, characteristic of an RC circuit's voltage response in the absence of an input current. The dynamics are therefore:\n$$\n\\dot{x}_2(t) = -\\frac{1}{\\tau} x_2(t)\n$$\n\nCombining these two equations into a matrix form $\\dot{x} = Ax$:\n$$\n\\begin{pmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n$$\nThus, the state matrix $A$ is:\n$$\nA = \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\n\nNext, we formulate the output equation $y = Cx$. The problem defines the small-signal output as $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$. To linearize this, we use a first-order Taylor expansion for $E(\\mathrm{SOC})$ around $\\mathrm{SOC}_0$:\n$$\nE(\\mathrm{SOC}_{0} + x_{1}(t)) \\approx E(\\mathrm{SOC}_{0}) + \\frac{\\partial E}{\\partial \\mathrm{SOC}}\\bigg|_{\\mathrm{SOC}_{0}} x_1(t) = E(\\mathrm{SOC}_{0}) + k x_1(t)\n$$\nSubstituting this into the expression for $y(t)$:\n$$\ny(t) \\approx (E(\\mathrm{SOC}_{0}) + k x_1(t)) - E(\\mathrm{SOC}_{0}) + x_2(t) = k x_1(t) + x_2(t)\n$$\nIn matrix form, this is:\n$$\ny(t) = \\begin{pmatrix} k & 1 \\end{pmatrix} \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}\n$$\nThus, the output matrix $C$ is:\n$$\nC = \\begin{pmatrix} k & 1 \\end{pmatrix}\n$$\n\n**2. Justification of the Role of $k$ in Observability**\n\nObservability determines whether the initial state of the system can be uniquely determined from the output measurements over a period of time. The parameter $k = \\frac{\\partial E}{\\partial \\mathrm{SOC}}$ represents the sensitivity of the open-circuit voltage to changes in the state of charge.\n\nPhysically, the state $x_1$ (SOC deviation) influences the output $y$ only through the term $k x_1$. If $k=0$, the OCV-SOC curve is flat at the operating point, meaning the voltage provides no information about small changes in SOC. In this case, the output becomes $y(t) = x_2(t)$, and it is impossible to infer anything about $x_1$ from the measurement, making the SOC unobservable.\n\nMathematically, this is verified by the Kalman observability rank condition. The observability matrix $\\mathcal{O}$ for this system is:\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}\n$$\nWe compute $CA$:\n$$\nCA = \\begin{pmatrix} k & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix} = \\begin{pmatrix} 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\nThe observability matrix is:\n$$\n\\mathcal{O} = \\begin{pmatrix} k & 1 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\nThe system is observable if and only if $\\mathcal{O}$ has full rank, which for a $2 \\times 2$ matrix means its determinant is non-zero.\n$$\n\\det(\\mathcal{O}) = (k)\\left(-\\frac{1}{\\tau}\\right) - (1)(0) = -\\frac{k}{\\tau}\n$$\nSince $\\tau > 0$, the system is observable if and only if $k \\neq 0$. This provides a rigorous justification for the critical role of $k$.\n\n**3. Observability Gramian Calculation**\n\nThe finite-horizon observability Gramian over the interval $[0, T]$ is given by:\n$$\nW_o = \\int_0^T e^{A^\\top t} C^\\top C e^{At} dt\n$$\nFirst, we find the state transition matrix $e^{At}$. Since $A$ is a diagonal matrix, its exponential is the exponential of its diagonal elements:\n$$\ne^{At} = \\begin{pmatrix} e^{0 \\cdot t} & 0 \\\\ 0 & e^{-\\frac{1}{\\tau}t} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix}\n$$\nSince $A$ is symmetric, $A^\\top = A$, and thus $e^{A^\\top t} = e^{At}$.\nNext, we calculate the product $C^\\top C$:\n$$\nC^\\top C = \\begin{pmatrix} k \\\\ 1 \\end{pmatrix} \\begin{pmatrix} k & 1 \\end{pmatrix} = \\begin{pmatrix} k^2 & k \\\\ k & 1 \\end{pmatrix}\n$$\nNow we compute the integrand $e^{A^\\top t} C^\\top C e^{At}$:\n$$\ne^{At} C^\\top C e^{At} = \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix} \\begin{pmatrix} k^2 & k \\\\ k & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} k^2 & k \\\\ k e^{-t/\\tau} & e^{-t/\\tau} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix} = \\begin{pmatrix} k^2 & k e^{-t/\\tau} \\\\ k e^{-t/\\tau} & e^{-2t/\\tau} \\end{pmatrix}\n$$\nFinally, we integrate this matrix from $t=0$ to $t=T$ to obtain $W_o$:\n$$\nW_o = \\int_0^T \\begin{pmatrix} k^2 & k e^{-t/\\tau} \\\\ k e^{-t/\\tau} & e^{-2t/\\tau} \\end{pmatrix} dt = \\begin{pmatrix} \\int_0^T k^2 dt & \\int_0^T k e^{-t/\\tau} dt \\\\ \\int_0^T k e^{-t/\\tau} dt & \\int_0^T e^{-2t/\\tau} dt \\end{pmatrix}\n$$\nWe evaluate each integral:\n$$\nW_{o,11} = \\int_0^T k^2 dt = k^2 [t]_0^T = k^2 T\n$$\n$$\nW_{o,12} = W_{o,21} = \\int_0^T k e^{-t/\\tau} dt = k \\left[ -\\tau e^{-t/\\tau} \\right]_0^T = k(-\\tau e^{-T/\\tau} + \\tau e^0) = k\\tau(1 - e^{-T/\\tau})\n$$\n$$\nW_{o,22} = \\int_0^T e^{-2t/\\tau} dt = \\left[ -\\frac{\\tau}{2} e^{-2t/\\tau} \\right]_0^T = -\\frac{\\tau}{2} e^{-2T/\\tau} + \\frac{\\tau}{2} e^0 = \\frac{\\tau}{2}(1 - e^{-2T/\\tau})\n$$\nThe observability Gramian is:\n$$\nW_o = \\begin{pmatrix} k^2 T & k\\tau(1 - e^{-T/\\tau}) \\\\ k\\tau(1 - e^{-T/\\tau}) & \\frac{\\tau}{2}(1 - e^{-2T/\\tau}) \\end{pmatrix}\n$$\nHere again, we see that if $k=0$, the first row and column of $W_o$ become zero, rendering the matrix singular ($\\det(W_o)=0$) and the system unobservable.\n\n**4. Determinant of the Gramian and Normalized Determinant $\\Delta$**\n\nWe compute the determinant of $W_o$:\n$$\n\\det(W_o) = (W_{o,11})(W_{o,22}) - (W_{o,12})^2\n$$\n$$\n\\det(W_o) = (k^2 T) \\left(\\frac{\\tau}{2}(1 - e^{-2T/\\tau})\\right) - \\left(k\\tau(1 - e^{-T/\\tau})\\right)^2\n$$\n$$\n\\det(W_o) = \\frac{k^2 T \\tau}{2}(1 - e^{-2T/\\tau}) - k^2 \\tau^2 (1 - e^{-T/\\tau})^2\n$$\nThe problem asks for the normalized determinant $\\Delta = \\frac{\\det(W_o)}{k^2 \\tau^2}$.\n$$\n\\Delta = \\frac{1}{k^2 \\tau^2} \\left[ \\frac{k^2 T \\tau}{2}(1 - e^{-2T/\\tau}) - k^2 \\tau^2 (1 - e^{-T/\\tau})^2 \\right]\n$$\n$$\n\\Delta = \\frac{T}{2\\tau}(1 - e^{-2T/\\tau}) - (1 - e^{-T/\\tau})^2\n$$\nThis expression can be left as is. For clarity, we will use the `\\exp` function notation as required.\n$$\n\\Delta = \\frac{T}{2\\tau}(1 - \\exp(-2T/\\tau)) - (1 - \\exp(-T/\\tau))^2\n$$\nThis is the final closed-form analytic expression for the dimensionless normalized determinant in terms of the experiment duration $T$ and the polarization time constant $\\tau$.",
            "answer": "$$ \\boxed{ \\frac{T}{2\\tau} \\left( 1 - \\exp\\left(-\\frac{2T}{\\tau}\\right) \\right) - \\left( 1 - \\exp\\left(-\\frac{T}{\\tau}\\right) \\right)^{2} } $$"
        },
        {
            "introduction": "When comparing simulated data from a Software-in-the-Loop (SIL) or Hardware-in-the-Loop (HIL) environment to experimental ground truth, discrepancies arise from both model inaccuracies and systemic artifacts like communication latency. A crucial validation skill is to decouple these error sources to make a fair assessment of the model itself. This exercise provides a hands-on method to address signal delays by deriving a time-alignment algorithm that minimizes Root-Mean-Square Error (RMSE) . By optimizing the phase shift between signals, you learn to isolate and quantify the model's dynamic performance, preventing hardware-induced latency from corrupting your validation results.",
            "id": "3918356",
            "problem": "A battery pack terminal voltage ripple caused by a periodic load is used to validate a physics-based electrochemical model within both Hardware-In-The-Loop (HIL) and Software-In-The-Loop (SIL) workflows for automated battery design and simulation. The simulated voltage, denoted $v_{s}(t)$, and the measured voltage, denoted $v_{m}(t)$, are dominated by a single-frequency component due to the applied load. Under steady operation, over any observation interval of one period, both can be modeled as\n$$v_{s}(t) = V_{0} + A_{s}\\sin(\\omega t + \\theta_{s}), \\quad v_{m}(t) = V_{0} + A_{m}\\sin\\big(\\omega(t - L) + \\theta_{m}\\big) + \\epsilon(t),$$\nwhere $V_{0}$ is the direct current baseline voltage, $A_{s}$ and $A_{m}$ are ripple amplitudes from the simulation and the measurement respectively, $\\omega$ is the angular frequency, $\\theta_{s}$ and $\\theta_{m}$ are phase offsets, $L$ is a known pipeline latency due to the HIL data acquisition chain, and $\\epsilon(t)$ is zero-mean measurement noise that is small enough to be neglected in the derivation. Consider a time-alignment algorithm that adjusts the simulation by an additional phase shift $\\delta$, defining the aligned simulation signal as\n$$v_{s,\\delta}(t) = V_{0} + A_{s}\\sin\\big(\\omega t + \\theta_{s} + \\delta\\big).$$\nOver a single period $T = 2\\pi/\\omega$, define the root-mean-square error (RMSE) of the aligned simulation relative to the measurement by\n$$\\mathrm{RMSE}(\\delta) = \\sqrt{\\frac{1}{T}\\int_{t_{0}}^{t_{0}+T}\\big(v_{s,\\delta}(t) - v_{m}(t)\\big)^{2}\\,dt},$$\nwhere $t_{0}$ is arbitrary. Starting only from the definition of $\\mathrm{RMSE}(\\delta)$ and fundamental properties of trigonometric functions (including their orthogonality over a period), derive the value of $\\delta$ that minimizes $\\mathrm{RMSE}(\\delta)$. Then, quantify the effect of the time alignment by computing the post-alignment reported accuracy defined as\n$$a = 1 - \\frac{\\mathrm{RMSE}(\\delta_{\\mathrm{opt}})}{\\mathrm{RMS}_{m}},$$\nwhere $\\mathrm{RMS}_{m}$ is the root-mean-square of the measured ripple $v_{m}(t) - V_{0}$ over the same period $T$. Use the following scientifically realistic parameters for a battery pack undergoing a low-frequency periodic load:\n- $V_{0} = 3.7\\,\\text{V}$,\n- $A_{s} = 0.050\\,\\text{V}$,\n- $A_{m} = 0.048\\,\\text{V}$,\n- $\\omega = \\pi\\,\\text{rad/s}$,\n- $L = 0.35\\,\\text{s}$,\n- $\\theta_{s} = 0.2\\,\\text{rad}$,\n- $\\theta_{m} = -0.1\\,\\text{rad}$,\n- neglect $\\epsilon(t)$ in the analytic derivation.\n\nProvide your final answer as a row matrix containing the optimal phase shift $\\delta_{\\mathrm{opt}}$ in radians and the post-alignment accuracy $a$ as a decimal fraction. Round each quantity to four significant figures. Express the phase shift in radians.",
            "solution": "The problem requires us to determine the optimal phase shift, $\\delta_{\\mathrm{opt}}$, that minimizes the root-mean-square error (RMSE) between a simulated voltage signal and a measured one. Subsequently, we are to compute a post-alignment accuracy metric, $a$.\n\nThe simulated and measured voltage signals, after incorporating the alignment phase shift $\\delta$ and neglecting the noise term $\\epsilon(t)$, are given by:\n$$v_{s,\\delta}(t) = V_{0} + A_{s}\\sin(\\omega t + \\theta_{s} + \\delta)$$\n$$v_{m}(t) = V_{0} + A_{m}\\sin(\\omega(t - L) + \\theta_{m}) = V_{0} + A_{m}\\sin(\\omega t - \\omega L + \\theta_{m})$$\n\nThe root-mean-square error, $\\mathrm{RMSE}(\\delta)$, is defined over a single period $T = 2\\pi/\\omega$ as:\n$$\\mathrm{RMSE}(\\delta) = \\sqrt{\\frac{1}{T}\\int_{t_{0}}^{t_{0}+T}\\big(v_{s,\\delta}(t) - v_{m}(t)\\big)^{2}\\,dt}$$\n\nTo find the value of $\\delta$ that minimizes $\\mathrm{RMSE}(\\delta)$, we can equivalently minimize its square, denoted as $E_{\\mathrm{sq}}(\\delta) = \\left(\\mathrm{RMSE}(\\delta)\\right)^{2}$.\n$$E_{\\mathrm{sq}}(\\delta) = \\frac{1}{T}\\int_{t_{0}}^{t_{0}+T}\\big(v_{s,\\delta}(t) - v_{m}(t)\\big)^{2}\\,dt$$\n\nThe difference between the signals is:\n$$v_{s,\\delta}(t) - v_{m}(t) = A_{s}\\sin(\\omega t + \\theta_{s} + \\delta) - A_{m}\\sin(\\omega t - \\omega L + \\theta_{m})$$\nLet us define the phase arguments for clarity:\n$\\phi_s(\\delta) = \\omega t + \\theta_{s} + \\delta$\n$\\phi_m = \\omega t - \\omega L + \\theta_{m}$\n\nThe integrand becomes:\n$$\\big(A_{s}\\sin(\\phi_s(\\delta)) - A_{m}\\sin(\\phi_m)\\big)^{2} = A_{s}^{2}\\sin^{2}(\\phi_s(\\delta)) + A_{m}^{2}\\sin^{2}(\\phi_m) - 2A_{s}A_{m}\\sin(\\phi_s(\\delta))\\sin(\\phi_m)$$\n\nWe now integrate this expression over one period, $[t_0, t_0+T]$. We use the following standard trigonometric integrals:\n1. $\\int_{t_{0}}^{t_{0}+T} \\sin^{2}(\\omega t + \\alpha) \\,dt = \\frac{T}{2}$\n2. $\\int_{t_{0}}^{t_{0}+T} \\sin(\\omega t + \\alpha_{1})\\sin(\\omega t + \\alpha_{2}) \\,dt = \\frac{T}{2}\\cos(\\alpha_{1} - \\alpha_{2})$\n\nApplying these identities to the terms of the expanded squared error:\n$$\\int_{t_{0}}^{t_{0}+T} A_{s}^{2}\\sin^{2}(\\phi_s(\\delta)) \\,dt = A_{s}^{2} \\frac{T}{2}$$\n$$\\int_{t_{0}}^{t_{0}+T} A_{m}^{2}\\sin^{2}(\\phi_m) \\,dt = A_{m}^{2} \\frac{T}{2}$$\n$$\\int_{t_{0}}^{t_{0}+T} -2A_{s}A_{m}\\sin(\\phi_s(\\delta))\\sin(\\phi_m) \\,dt = -2A_{s}A_{m} \\frac{T}{2}\\cos\\big((\\theta_{s} + \\delta) - (-\\omega L + \\theta_{m})\\big)$$\n$$ = -A_{s}A_{m}T\\cos(\\theta_{s} - \\theta_{m} + \\omega L + \\delta)$$\n\nSumming these integrated terms and dividing by $T$ gives $E_{\\mathrm{sq}}(\\delta)$:\n$$E_{\\mathrm{sq}}(\\delta) = \\frac{A_{s}^{2}}{2} + \\frac{A_{m}^{2}}{2} - A_{s}A_{m}\\cos(\\theta_{s} - \\theta_{m} + \\omega L + \\delta)$$\n\nTo minimize $E_{\\mathrm{sq}}(\\delta)$, we must maximize the term $A_{s}A_{m}\\cos(\\theta_{s} - \\theta_{m} + \\omega L + \\delta)$. Since amplitudes $A_s$ and $A_m$ are positive, this is equivalent to maximizing the cosine term. The maximum value of $\\cos(x)$ is $1$, which occurs when its argument $x$ is an even integer multiple of $\\pi$, i.e., $x = 2k\\pi$ for any integer $k$.\nThus, for the minimum error, we must have:\n$$\\theta_{s} - \\theta_{m} + \\omega L + \\delta_{\\mathrm{opt}} = 2k\\pi$$\nSolving for $\\delta_{\\mathrm{opt}}$ gives:\n$$\\delta_{\\mathrm{opt}} = 2k\\pi - (\\theta_{s} - \\theta_{m} + \\omega L) = 2k\\pi + \\theta_{m} - \\theta_{s} - \\omega L$$\nWe typically seek the principal value, which is usually the one with the smallest magnitude (by choosing $k=0$ or another integer to bring the result into the interval $(-\\pi, \\pi]$). Let's choose $k=0$ for the general expression:\n$$\\delta_{\\mathrm{opt}} = \\theta_{m} - \\theta_{s} - \\omega L$$\nSubstituting the given numerical values:\n$\\theta_{m} = -0.1\\,\\text{rad}$, $\\theta_{s} = 0.2\\,\\text{rad}$, $\\omega = \\pi\\,\\text{rad/s}$, $L = 0.35\\,\\text{s}$.\n$$\\delta_{\\mathrm{opt}} = -0.1 - 0.2 - (\\pi \\times 0.35) = -0.3 - 0.35\\pi$$\nNumerically, $\\delta_{\\mathrm{opt}} \\approx -0.3 - 0.35 \\times 3.14159265 = -0.3 - 1.09955743 = -1.39955743\\,\\text{rad}$.\nThis value lies within the interval $(-\\pi, \\pi]$, so it is an acceptable principal value. Rounding to four significant figures, we get $\\delta_{\\mathrm{opt}} = -1.400\\,\\text{rad}$.\n\nNext, we must calculate the post-alignment accuracy, $a$.\n$$a = 1 - \\frac{\\mathrm{RMSE}(\\delta_{\\mathrm{opt}})}{\\mathrm{RMS}_{m}}$$\nFirst, we find $\\mathrm{RMSE}(\\delta_{\\mathrm{opt}})$. At the optimal shift, $\\cos(\\theta_{s} - \\theta_{m} + \\omega L + \\delta_{\\mathrm{opt}}) = 1$.\n$$E_{\\mathrm{sq}}(\\delta_{\\mathrm{opt}}) = (\\mathrm{RMSE}(\\delta_{\\mathrm{opt}}))^{2} = \\frac{A_{s}^{2}}{2} + \\frac{A_{m}^{2}}{2} - A_{s}A_{m} = \\frac{1}{2}(A_{s}^{2} - 2A_{s}A_{m} + A_{m}^{2}) = \\frac{(A_{s} - A_{m})^{2}}{2}$$\n$$\\mathrm{RMSE}(\\delta_{\\mathrm{opt}}) = \\sqrt{\\frac{(A_{s} - A_{m})^{2}}{2}} = \\frac{|A_{s} - A_{m}|}{\\sqrt{2}}$$\n\nNext, we find $\\mathrm{RMS}_{m}$, the root-mean-square of the measured ripple $v_{m}(t) - V_{0} = A_{m}\\sin(\\omega t - \\omega L + \\theta_{m})$.\n$$(\\mathrm{RMS}_{m})^{2} = \\frac{1}{T}\\int_{t_{0}}^{t_{0}+T} \\big(A_{m}\\sin(\\omega t - \\omega L + \\theta_{m})\\big)^{2}\\,dt$$\n$$(\\mathrm{RMS}_{m})^{2} = \\frac{A_{m}^{2}}{T} \\int_{t_{0}}^{t_{0}+T} \\sin^{2}(\\omega t - \\omega L + \\theta_{m}) \\,dt = \\frac{A_{m}^{2}}{T} \\cdot \\frac{T}{2} = \\frac{A_{m}^{2}}{2}$$\n$$\\mathrm{RMS}_{m} = \\sqrt{\\frac{A_{m}^{2}}{2}} = \\frac{A_{m}}{\\sqrt{2}}$$\n(since $A_m$ is a positive amplitude).\n\nNow we can compute the accuracy $a$:\n$$a = 1 - \\frac{\\mathrm{RMSE}(\\delta_{\\mathrm{opt}})}{\\mathrm{RMS}_{m}} = 1 - \\frac{|A_{s} - A_{m}|/\\sqrt{2}}{A_{m}/\\sqrt{2}} = 1 - \\frac{|A_{s} - A_{m}|}{A_{m}}$$\nSubstituting the given amplitude values:\n$A_{s} = 0.050\\,\\text{V}$ and $A_{m} = 0.048\\,\\text{V}$.\n$$a = 1 - \\frac{|0.050 - 0.048|}{0.048} = 1 - \\frac{0.002}{0.048} = 1 - \\frac{2}{48} = 1 - \\frac{1}{24}$$\nNumerically, $a = 1 - 0.041666... = 0.958333...$\nRounding to four significant figures, we get $a = 0.9583$.\n\nThe final results are $\\delta_{\\mathrm{opt}} = -1.400\\,\\text{rad}$ and $a = 0.9583$.",
            "answer": "$$\\boxed{\\begin{pmatrix}-1.400 & 0.9583\\end{pmatrix}}$$"
        },
        {
            "introduction": "A key challenge that distinguishes HIL simulation from offline analysis is the need to meet strict real-time constraints. All computational tasks—running the plant model, executing control logic, and logging data—must be completed on a real-time processor without missing their deadlines. This exercise places you in the role of a systems integrator responsible for verifying the performance of a HIL validation rig . By applying classical Rate-Monotonic Scheduling (RMS) theory, you will determine the operational limits of the system and construct a task schedule to prove that even the lowest-priority task meets its deadline, guaranteeing the temporal integrity of the simulation.",
            "id": "3918331",
            "problem": "A battery Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) validation rig executes three periodic real-time tasks under a single-core preemptive fixed-priority kernel using Rate-Monotonic Scheduling (RMS): a state estimator for a reduced-order electrochemical model, a current-control loop to drive the load emulator, and a data logger that writes synchronized measurements and state estimates to non-volatile storage. All tasks have deadlines equal to their periods, synchronous release at time $t = 0$, negligible release jitter, and zero context-switch and interrupt overheads. The estimator and controller have measured worst-case execution times on the target platform, while the logger’s worst-case execution time must be chosen to ensure schedulability.\n\n- Estimator task $E$: period $T_{E} = 1$ ms, worst-case execution time $C_{E} = 0.18$ ms.\n- Control task $C$: period $T_{C} = 2$ ms, worst-case execution time $C_{C} = 0.22$ ms.\n- Logging task $L$: period $T_{L} = 10$ ms, worst-case execution time $C_{L}$ (to be determined).\n\nTasks are prioritized by their periods according to Rate-Monotonic Scheduling. Using first principles of fixed-priority schedulability analysis and the classical utilization-based sufficient schedulability bound for periodic tasks, do the following:\n\n1. Determine the maximum allowable $C_{L}$ that guarantees the task set is schedulable under Rate-Monotonic Scheduling.\n2. Construct the executable schedule over one hyperperiod from $t = 0$ to $t = 10$ ms at the computed maximum $C_{L}$, and argue why $L$ meets its deadline at $t = 10$ ms.\n\nRound your final numerical answer for the maximum allowable $C_{L}$ to four significant figures. Express the final answer in milliseconds.",
            "solution": "The problem statement is coherent, internally consistent, and grounded in the established principles of real-time systems scheduling theory. All necessary parameters for analysis are provided. The context, a Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) validation rig for battery systems, is a credible and relevant application of such theory. The problem is therefore deemed valid and a formal solution can be constructed.\n\nThe problem requires a two-part solution: first, to determine the maximum worst-case execution time $C_L$ for the logging task $L$ that guarantees schedulability based on a sufficient utilization-based test; second, to construct the explicit schedule over one hyperperiod to demonstrate that the lowest-priority task meets its deadline.\n\n**1. Determination of Maximum Allowable $C_L$**\n\nThe scheduling policy is Rate-Monotonic Scheduling (RMS), a preemptive fixed-priority scheme where priority is inversely proportional to the task's period. The given tasks are:\n- Estimator task $E$: $T_{E} = 1$ ms, $C_{E} = 0.18$ ms.\n- Control task $C$: $T_{C} = 2$ ms, $C_{C} = 0.22$ ms.\n- Logging task $L$: $T_{L} = 10$ ms, $C_{L}$ to be determined.\n\nGiven $T_{E} < T_{C} < T_{L}$, the priority assignment is $Priority(E) > Priority(C) > Priority(L)$.\n\nThe problem specifies using the classical utilization-based sufficient schedulability bound for a set of $n$ periodic tasks, established by Liu and Layland. The condition states that a task set is schedulable under RMS if its total processor utilization $U$ does not exceed a specific bound:\n$$ U = \\sum_{i=1}^{n} \\frac{C_i}{T_i} \\le n(2^{1/n} - 1) $$\nFor the given system, the number of tasks is $n = 3$. The utilization bound is:\n$$ U_{bound} = 3(2^{1/3} - 1) $$\nWe calculate the utilizations of the known tasks:\n$$ U_E = \\frac{C_E}{T_E} = \\frac{0.18\\,\\text{ms}}{1\\,\\text{ms}} = 0.18 $$\n$$ U_C = \\frac{C_C}{T_C} = \\frac{0.22\\,\\text{ms}}{2\\,\\text{ms}} = 0.11 $$\nThe utilization of the logging task is $U_L = \\frac{C_L}{T_L} = \\frac{C_L}{10}$.\n\nThe total utilization $U = U_E + U_C + U_L$ must satisfy the schedulability condition:\n$$ 0.18 + 0.11 + \\frac{C_L}{10} \\le 3(2^{1/3} - 1) $$\n$$ 0.29 + \\frac{C_L}{10} \\le 3(2^{1/3} - 1) $$\nTo find the maximum allowable $C_L$, we solve for $C_L$:\n$$ \\frac{C_L}{10} \\le 3(2^{1/3} - 1) - 0.29 $$\n$$ C_L \\le 10 \\left( 3(2^{1/3} - 1) - 0.29 \\right) $$\nNumerically evaluating the expression:\n$$ C_L \\le 10 \\left( 3(1.259921...) - 3 - 0.29 \\right) $$\n$$ C_L \\le 10 \\left( 0.779763... - 0.29 \\right) $$\n$$ C_L \\le 10 \\left( 0.489763... \\right) $$\n$$ C_L \\le 4.89763... \\,\\text{ms} $$\nRounding to four significant figures as required, the maximum allowable worst-case execution time for the logging task is $C_L = 4.898$ ms.\n\n**2. Schedule Construction and Verification**\n\nWe now construct the schedule for one hyperperiod using the computed value $C_L = 4.898$ ms. The hyperperiod is the least common multiple of the task periods: $H = \\text{lcm}(1, 2, 10) = 10$ ms. All tasks are released synchronously at $t=0$.\n\nThe schedule over the interval $[0, 10]$ ms is as follows, tracking the execution of each job and noting preemptions:\n- **`t = 0.000`**: Jobs $E_1$, $C_1$, and $L_1$ are released. $E_1$ (highest priority) runs.\n- **`[0.000, 0.180]`**: $E_1$ executes for $C_E=0.18$ ms and completes.\n- **`[0.180, 0.400]`**: $C_1$ (next highest priority) executes for $C_C=0.22$ ms and completes.\n- **`[0.400, 1.000]`**: $L_1$ (lowest priority) executes for $0.600$ ms. Remaining execution time for $L_1$ is $4.898 - 0.600 = 4.298$ ms.\n- **`t = 1.000`**: Job $E_2$ is released and preempts $L_1$.\n- **`[1.000, 1.180]`**: $E_2$ executes and completes.\n- **`[1.180, 2.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 4.298 - 0.820 = 3.478$ ms.\n- **`t = 2.000`**: Jobs $E_3$ and $C_2$ are released. $E_3$ preempts $L_1$.\n- **`[2.000, 2.180]`**: $E_3$ executes and completes.\n- **`[2.180, 2.400]`**: $C_2$ executes and completes.\n- **`[2.400, 3.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 3.478 - 0.600 = 2.878$ ms.\n- **`t = 3.000`**: Job $E_4$ is released and preempts $L_1$.\n- **`[3.000, 3.180]`**: $E_4$ executes and completes.\n- **`[3.180, 4.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 2.878 - 0.820 = 2.058$ ms.\n- **`t = 4.000`**: Jobs $E_5$ and $C_3$ are released. $E_5$ preempts $L_1$.\n- **`[4.000, 4.180]`**: $E_5$ executes and completes.\n- **`[4.180, 4.400]`**: $C_3$ executes and completes.\n- **`[4.400, 5.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 2.058 - 0.600 = 1.458$ ms.\n- **`t = 5.000`**: Job $E_6$ is released and preempts $L_1$.\n- **`[5.000, 5.180]`**: $E_6$ executes and completes.\n- **`[5.180, 6.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 1.458 - 0.820 = 0.638$ ms.\n- **`t = 6.000`**: Jobs $E_7$ and $C_4$ are released. $E_7$ preempts $L_1$.\n- **`[6.000, 6.180]`**: $E_7$ executes and completes.\n- **`[6.180, 6.400]`**: $C_4$ executes and completes.\n- **`[6.400, 7.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 0.638 - 0.600 = 0.038$ ms.\n- **`t = 7.000`**: Job $E_8$ is released and preempts $L_1$.\n- **`[7.000, 7.180]`**: $E_8$ executes and completes.\n- **`[7.180, 7.218]`**: $L_1$ resumes, executing for its final $0.038$ ms. **$L_1$ completes at $t=7.218$ ms.**\n- **`t > 7.218`**: The processor is idle until the next job release at $t=8.000$. Subsequent jobs ($E_9, C_5, E_{10}$) also run and complete well within their deadlines in the remaining portion of the hyperperiod.\n\n**Argument for Deadline Satisfaction:**\nThe analysis of the schedule provides the definitive argument. The first and only job of the logging task, $L_1$, is released at $t=0$ and has a deadline at $t=T_L=10$ ms. The detailed schedule simulation shows that after being preempted by $8$ jobs of task $E$ and $4$ jobs of task $C$, job $L_1$ accumulates its required execution time of $4.898$ ms and completes at time $t_{finish} = 7.218$ ms. Since its completion time $t_{finish} = 7.218$ ms is less than its deadline $D_L = 10$ ms, task $L$ meets its deadline. By inspection, all higher-priority tasks also meet their deadlines, as they are subject to no preemption. Therefore, the task set is schedulable with $C_L = 4.898$ ms.",
            "answer": "$$\\boxed{4.898}$$"
        }
    ]
}