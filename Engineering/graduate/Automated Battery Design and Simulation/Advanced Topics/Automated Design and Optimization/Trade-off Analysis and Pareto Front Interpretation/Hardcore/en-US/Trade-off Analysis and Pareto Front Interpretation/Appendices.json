{
    "hands_on_practices": [
        {
            "introduction": "The first step in any trade-off analysis is to identify the set of optimal solutions, known as the Pareto front. This exercise provides a foundational test of your understanding of Pareto dominance, the core principle for comparing solutions with multiple conflicting objectives. By manually comparing a small set of candidate battery designs, you will practice applying the formal definition to distinguish between dominated and nondominated solutions, a fundamental skill for interpreting multi-objective optimization results. ",
            "id": "3958423",
            "problem": "In an automated battery design and simulation pipeline, the performance of each candidate cell design is evaluated by two normalized objective functions $f_1$ and $f_2$ derived from physics-based electrochemical-thermal models. The objective $f_1$ aggregates a thermal stress proxy based on temperature rise under a standardized $C$-rate profile, and the objective $f_2$ aggregates a mechanistic degradation proxy based on predicted loss of active material per cycle. Both $f_1$ and $f_2$ are constructed so that smaller values indicate better performance and are to be minimized. Three candidate designs have been aggregated as two-dimensional objective vectors: $A=(0.8,1.1)$, $B=(0.9,1.0)$, and $C=(0.7,1.3)$, where each component corresponds to $(f_1,f_2)$ in arbitrary normalized units. Determine the nondominated set of these designs under bi-objective minimization and justify the conclusion using the appropriate dominance definition. Report as your final answer the cardinality of the nondominated set as an integer. No rounding is required.",
            "solution": "The problem is found to be valid after a rigorous check against all specified criteria. It is scientifically grounded in the field of multi-objective optimization as applied to battery engineering, is well-posed with all necessary information provided, and is expressed with objective, unambiguous language.\n\nThe problem requires the identification of the nondominated set from a given collection of three candidate designs, each represented by a vector of two objective function values, $(f_1, f_2)$, where smaller values are preferable for both objectives. The candidate designs are given as $A=(0.8, 1.1)$, $B=(0.9, 1.0)$, and $C=(0.7, 1.3)$.\n\nThe core of this problem lies in the concept of Pareto dominance. For a bi-objective minimization problem, a vector $\\mathbf{u} = (u_1, u_2)$ is said to *dominate* another vector $\\mathbf{v} = (v_1, v_2)$, denoted as $\\mathbf{u} \\prec \\mathbf{v}$, if and only if two conditions are met:\n$1$. $u_i \\le v_i$ for all objectives $i \\in \\{1, 2\\}$.\n$2$. $u_j  v_j$ for at least one objective $j \\in \\{1, 2\\}$.\nIn simpler terms, a design dominates another if it is at least as good in all objectives and strictly better in at least one objective.\n\nA design is considered *nondominated* (or Pareto optimal) if no other design in the set dominates it. The set of all such nondominated designs is called the nondominated set or the Pareto front.\n\nWe will now systematically compare each pair of designs to determine dominance relationships. The given objective vectors are:\n- Design $A$: $\\mathbf{f}(A) = (0.8, 1.1)$\n- Design $B$: $\\mathbf{f}(B) = (0.9, 1.0)$\n- Design $C$: $\\mathbf{f}(C) = (0.7, 1.3)$\n\n**Comparison of Design $A$ and Design $B$:**\n- Does $A$ dominate $B$? We compare $(0.8, 1.1)$ with $(0.9, 1.0)$. For the first objective, $f_1(A) = 0.8  f_1(B) = 0.9$. For the second objective, $f_2(A) = 1.1 > f_2(B) = 1.0$. Since $A$ is better in $f_1$ but worse in $f_2$, $A$ does not dominate $B$.\n- Does $B$ dominate $A$? We compare $(0.9, 1.0)$ with $(0.8, 1.1)$. For the first objective, $f_1(B) = 0.9 > f_1(A) = 0.8$. For the second objective, $f_2(B) = 1.0  f_2(A) = 1.1$. Since $B$ is better in $f_2$ but worse in $f_1$, $B$ does not dominate $A$.\n- Conclusion: $A$ and $B$ are mutually nondominated.\n\n**Comparison of Design $A$ and Design $C$:**\n- Does $A$ dominate $C$? We compare $(0.8, 1.1)$ with $(0.7, 1.3)$. For the first objective, $f_1(A) = 0.8 > f_1(C) = 0.7$. Since $A$ is not at least as good as $C$ in all objectives, $A$ does not dominate $C$.\n- Does $C$ dominate $A$? We compare $(0.7, 1.3)$ with $(0.8, 1.1)$. For the first objective, $f_1(C) = 0.7  f_1(A) = 0.8$. For the second objective, $f_2(C) = 1.3 > f_2(A) = 1.1$. Since $C$ is better in $f_1$ but worse in $f_2$, $C$ does not dominate $A$.\n- Conclusion: $A$ and $C$ are mutually nondominated.\n\n**Comparison of Design $B$ and Design $C$:**\n- Does $B$ dominate $C$? We compare $(0.9, 1.0)$ with $(0.7, 1.3)$. For the first objective, $f_1(B) = 0.9 > f_1(C) = 0.7$. Since $B$ is not at least as good as $C$ in all objectives, $B$ does not dominate $C$.\n- Does $C$ dominate $B$? We compare $(0.7, 1.3)$ with $(0.9, 1.0)$. For the first objective, $f_1(C) = 0.7  f_1(B) = 0.9$. For the second objective, $f_2(C) = 1.3 > f_2(B) = 1.0$. Since $C$ is better in $f_1$ but worse in $f_2$, $C$ does not dominate $B$.\n- Conclusion: $B$ and $C$ are mutually nondominated.\n\nBased on this exhaustive pairwise analysis, no design is dominated by any other design in the set. Each design presents a unique trade-off between the thermal stress proxy ($f_1$) and the degradation proxy ($f_2$). Specifically:\n- $C$ has the best thermal performance ($f_1=0.7$) but the worst degradation performance ($f_2=1.3$).\n- $B$ has the best degradation performance ($f_2=1.0$) but the worst thermal performance ($f_1=0.9$).\n- $A$ provides an intermediate trade-off for both objectives.\n\nSince no design is dominated, all three designs are part of the nondominated set. Therefore, the nondominated set is $\\{A, B, C\\}$.\n\nThe problem asks for the cardinality of this set, which is the number of elements it contains. The cardinality of $\\{A, B, C\\}$ is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Once a Pareto front is identified, a key challenge is selecting a single, balanced design for implementation. This practice introduces a powerful technique for this task: identifying the \"knee\" point, which represents the region of maximum trade-off. You will learn to approximate the geometric curvature of a discrete Pareto front, allowing you to quantitatively pinpoint the design that offers the most significant improvement in one objective for a minimal sacrifice in another. ",
            "id": "3958344",
            "problem": "In automated multi-objective battery design and simulation for a lithium-ion cell, consider a design study that simultaneously seeks to maximize normalized gravimetric energy density, denoted by $x$, and minimize a normalized degradation proxy, denoted by $y$. After running a simulation-driven optimizer that returns nondominated designs, the following discrete Pareto set in objective space is obtained (ordered by increasing $x$): $\\{(0.7,1.5),(0.8,1.2),(0.9,1.05),(1.0,1.0)\\}$. Interpret the Pareto set as samples from a smooth, monotonically decreasing curve $y(x)$ in objective space. The goal is to identify the “knee” point, i.e., the point at which marginal improvement in $x$ causes the most pronounced marginal worsening in $y$, reflected by the local geometric curvature of the Pareto front.\n\nStarting from the geometric definition of curvature for a planar curve, and from the definition of derivatives as limits of difference quotients, derive an appropriate second-derivative-based discrete approximation of curvature at the interior points of the sampled curve. Use this approximation to select the knee point as the point with the largest curvature magnitude among the interior points. Assume that the samples in $x$ are uniformly spaced and restrict attention to the two interior points of the set. Report, as your final answer, the $x$-coordinate $x^{\\star}$ of the identified knee point. Provide the exact value (no rounding required).",
            "solution": "The problem asks to identify the \"knee\" point of a discrete Pareto front, where the knee is defined as the point of maximum curvature. The analysis is to be performed on the interior points of the given set.\n\nThe problem is first validated.\n**Step 1: Extracted Givens**\n- **Objectives:** Maximize normalized gravimetric energy density ($x$) and minimize normalized degradation proxy ($y$).\n- **Pareto Set:** The discrete set of points is $\\{(0.7, 1.5), (0.8, 1.2), (0.9, 1.05), (1.0, 1.0)\\}$.\n- **Interpretation:** The set is to be treated as samples from a smooth, monotonically decreasing curve $y(x)$.\n- **Goal:** Identify the knee point, defined as the point with the largest curvature magnitude among the interior points.\n- **Method:** Derive a discrete, second-derivative-based approximation for curvature starting from the continuous definition and the limit definition of derivatives.\n- **Constraints:** The samples in $x$ are uniformly spaced, and the analysis is restricted to the two interior points of the set.\n- **Required Output:** The $x$-coordinate, $x^{\\star}$, of the identified knee point.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is scientifically grounded, as Pareto fronts, trade-off analysis, and curvature-based knee point detection are standard concepts in engineering optimization. The problem is well-posed, providing all necessary data and a clear objective. The language is objective and precise. The data is consistent; the $x$-coordinates are uniformly spaced with a step of $0.1$. The problem is not flawed and is deemed valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution process will now proceed.\n\n**Derivation of Discrete Curvature**\n\nThe geometric curvature $\\kappa$ for a planar curve given by a function $y(x)$ is defined as:\n$$\n\\kappa(x) = \\frac{|y''(x)|}{(1 + [y'(x)]^2)^{3/2}}\n$$\nwhere $y'(x)$ is the first derivative and $y''(x)$ is the second derivative of $y$ with respect to $x$.\n\nThe problem states that the Pareto set is a discrete sampling of this curve. Let the points be denoted as $(x_i, y_i)$. The problem also specifies that the sampling in $x$ is uniform, so $x_{i+1} - x_i = h$ for a constant spacing $h$. For the given set of points, we have $h = 0.8 - 0.7 = 0.1$.\n\nTo approximate the curvature at a point $(x_i, y_i)$, we need discrete approximations for the derivatives $y'(x_i)$ and $y''(x_i)$. Following the problem's instruction to start from the definition of derivatives as limits of difference quotients, we use the central difference formulas, which provide a second-order accurate approximation for the derivatives at the interior points of a grid.\n\nThe central difference approximation for the first derivative $y'(x_i)$ is:\n$$\ny'(x_i) \\approx \\frac{y(x_i + h) - y(x_i - h)}{2h} = \\frac{y_{i+1} - y_{i-1}}{2h}\n$$\nThe central difference approximation for the second derivative $y''(x_i)$ is:\n$$\ny''(x_i) \\approx \\frac{y'(x_i + h/2) - y'(x_i - h/2)}{h} \\approx \\frac{\\frac{y_{i+1}-y_i}{h} - \\frac{y_i-y_{i-1}}{h}}{h} = \\frac{y_{i+1} - 2y_i + y_{i-1}}{h^2}\n$$\nSubstituting these discrete approximations into the continuous curvature formula gives the discrete curvature $\\kappa_i$ at the point $(x_i, y_i)$:\n$$\n\\kappa_i \\approx \\frac{\\left| \\frac{y_{i+1} - 2y_i + y_{i-1}}{h^2} \\right|}{\\left(1 + \\left(\\frac{y_{i+1} - y_{i-1}}{2h}\\right)^2\\right)^{3/2}}\n$$\n\n**Application to the Given Pareto Set**\n\nThe given set of points is:\n$P_0 = (0.7, 1.5)$\n$P_1 = (0.8, 1.2)$\n$P_2 = (0.9, 1.05)$\n$P_3 = (1.0, 1.0)$\n\nThe analysis is restricted to the two interior points, $P_1$ and $P_2$. The uniform spacing is $h = 0.1$.\n\n**Calculation of Curvature at $P_1 = (0.8, 1.2)$**\nFor this point, $i=1$. The required points are $P_0$, $P_1$, and $P_2$. We have:\n- $x_1 = 0.8$, $y_1 = 1.2$\n- $y_{i-1} = y_0 = 1.5$\n- $y_{i+1} = y_2 = 1.05$\n- $h = 0.1$\n\nFirst, we compute the approximations for the derivatives at $x_1$:\n$$\ny'(x_1) \\approx \\frac{y_2 - y_0}{2h} = \\frac{1.05 - 1.5}{2(0.1)} = \\frac{-0.45}{0.2} = -2.25\n$$\n$$\ny''(x_1) \\approx \\frac{y_2 - 2y_1 + y_0}{h^2} = \\frac{1.05 - 2(1.2) + 1.5}{(0.1)^2} = \\frac{1.05 - 2.4 + 1.5}{0.01} = \\frac{0.15}{0.01} = 15\n$$\nNow, we calculate the curvature $\\kappa_1$:\n$$\n\\kappa_1 = \\frac{|15|}{(1 + (-2.25)^2)^{3/2}} = \\frac{15}{(1 + 5.0625)^{3/2}} = \\frac{15}{(6.0625)^{3/2}}\n$$\nTo simplify, $6.0625 = \\frac{97}{16}$.\n$$\n\\kappa_1 = \\frac{15}{(\\frac{97}{16})^{3/2}} = \\frac{15 \\cdot 16^{3/2}}{97^{3/2}} = \\frac{15 \\cdot (4^2)^{3/2}}{97\\sqrt{97}} = \\frac{15 \\cdot 4^3}{97\\sqrt{97}} = \\frac{15 \\cdot 64}{97\\sqrt{97}} = \\frac{960}{97\\sqrt{97}}\n$$\n\n**Calculation of Curvature at $P_2 = (0.9, 1.05)$**\nFor this point, $i=2$. The required points are $P_1$, $P_2$, and $P_3$. We have:\n- $x_2 = 0.9$, $y_2 = 1.05$\n- $y_{i-1} = y_1 = 1.2$\n- $y_{i+1} = y_3 = 1.0$\n- $h = 0.1$\n\nFirst, we compute the approximations for the derivatives at $x_2$:\n$$\ny'(x_2) \\approx \\frac{y_3 - y_1}{2h} = \\frac{1.0 - 1.2}{2(0.1)} = \\frac{-0.2}{0.2} = -1\n$$\n$$\ny''(x_2) \\approx \\frac{y_3 - 2y_2 + y_1}{h^2} = \\frac{1.0 - 2(1.05) + 1.2}{(0.1)^2} = \\frac{1.0 - 2.1 + 1.2}{0.01} = \\frac{0.1}{0.01} = 10\n$$\nNow, we calculate the curvature $\\kappa_2$:\n$$\n\\kappa_2 = \\frac{|10|}{(1 + (-1)^2)^{3/2}} = \\frac{10}{(1 + 1)^{3/2}} = \\frac{10}{2^{3/2}} = \\frac{10}{2\\sqrt{2}} = \\frac{5}{\\sqrt{2}}\n$$\n\n**Comparison and Conclusion**\nWe must now compare $\\kappa_1$ and $\\kappa_2$ to find the point with the largest curvature.\n$$\n\\kappa_1 = \\frac{960}{97\\sqrt{97}}\n$$\n$$\n\\kappa_2 = \\frac{5}{\\sqrt{2}}\n$$\nTo compare these values, we can compare their squares to avoid dealing with the square roots directly.\n$$\n\\kappa_1^2 = \\left(\\frac{960}{97\\sqrt{97}}\\right)^2 = \\frac{960^2}{97^2 \\cdot 97} = \\frac{921600}{97^3} = \\frac{921600}{912673} \\approx 1.01\n$$\n$$\n\\kappa_2^2 = \\left(\\frac{5}{\\sqrt{2}}\\right)^2 = \\frac{25}{2} = 12.5\n$$\nSince $\\kappa_2^2 > \\kappa_1^2$, it follows that $\\kappa_2 > \\kappa_1$.\nThe point with the largest curvature magnitude is $P_2 = (0.9, 1.05)$. The problem asks for the $x$-coordinate of this knee point.\n\nTherefore, the $x$-coordinate of the knee point is $x^{\\star} = 0.9$.",
            "answer": "$$\\boxed{0.9}$$"
        },
        {
            "introduction": "Understanding how optimization algorithms generate the Pareto front is crucial for advanced applications and for diagnosing unexpected results. This exercise explores the practical limitations of the widely-used weighted-sum scalarization method, demonstrating why it can fail to find important solutions on nonconvex fronts. By contrasting this with the more robust weighted Chebyshev method, you will gain insight into the theoretical underpinnings of multi-objective optimizers and why the geometry of the trade-off space matters. ",
            "id": "3958387",
            "problem": "An automated battery pack design pipeline uses a high-fidelity electrochemical-thermal simulation to evaluate candidate designs across two objectives to be maximized: normalized specific energy $\\phi_1$ and normalized cycle life $\\phi_2$. In a particular design study, three nondominated candidates are reported in normalized objective space as points $\\{(0.8,1.2),(0.9,1.0),(1.1,0.95)\\}$, where each component is dimensionless because it has been normalized by a fixed baseline. Assume both objectives are to be maximized, and consider scalarization-based trade-off analysis.\n\nStarting from the core definition of Pareto optimality and the construction of scalarization functions from multi-objective optimization, do the following:\n\n1. Using a weighted-sum scalarization with positive weights $(w_1, w_2)$ satisfying $w_1+w_2=1$ and $w_1,w_2>0$, explain why the weighted sum can fail to select certain Pareto-optimal points on a nonconvex front. Then, with $(w_1, w_2)=(0.5,0.5)$, compute the scalarized values for the three points and identify which point would be selected. Next, prove that there is no choice of positive weights $(w_1, w_2)$ that would make the middle point $(0.9,1.0)$ the unique maximizer of the weighted sum, thereby formalizing the failure on this nonconvex front segment.\n\n2. Define the ideal reference point $z^{\\star}$ as the component-wise maximum of the objective values across the three candidates. Formulate the weighted Chebyshev (maximum-norm) scalarization \n$$\\min_{x}\\max\\{w_1(z_1^{\\star}-\\phi_1(x)), w_2(z_2^{\\star}-\\phi_2(x))\\}$$\nfor the same weights $(w_1, w_2)=(0.5,0.5)$, and evaluate this scalarization at each of the three given points. Identify which point is selected by Chebyshev scalarization and compute the minimal Chebyshev objective value attained at that point.\n\nExpress the final value as a dimensionless number. Round your answer to four significant figures.",
            "solution": "The problem is valid as it is scientifically grounded in multi-objective optimization theory, well-posed with sufficient and consistent data, and stated in objective, formalizable language. All necessary information to perform the requested analysis is provided.\n\nThe two objective functions to be maximized are the normalized specific energy, denoted $\\phi_1$, and the normalized cycle life, denoted $\\phi_2$. We are given a set of three nondominated points in the objective space: let's label them $P_A = (0.8, 1.2)$, $P_B = (0.9, 1.0)$, and $P_C = (1.1, 0.95)$.\n\nPart 1: Weighted-Sum Scalarization\n\nThe weighted-sum scalarization method combines the multiple objectives into a single objective function, $S$, by taking a weighted sum. For a maximization problem with two objectives, the function is $S(\\phi_1, \\phi_2) = w_1 \\phi_1 + w_2 \\phi_2$, where the weights $w_1$ and $w_2$ are positive constants. The goal is to find the point that maximizes this single objective $S$.\n\nGeometrically, the equation $w_1 \\phi_1 + w_2 \\phi_2 = C$ defines a line in the $(\\phi_1, \\phi_2)$ plane with a constant slope of $-\\frac{w_1}{w_2}$. Maximizing $S$ is equivalent to finding the largest possible value of the constant $C$ for which this line still intersects the feasible objective region. The solution is the point of tangency between the line and the boundary of the feasible region, known as the Pareto front.\n\nThe weighted-sum method is guaranteed to find any point on a convex Pareto front. However, it can fail to find certain points on a nonconvex front. A front is nonconvex if the line segment connecting two points on the front contains points that are not in the feasible region (or are dominated by other points). In our discrete case, the Pareto front is formed by the three given points. Let's examine the line segment connecting $P_A = (0.8, 1.2)$ and $P_C = (1.1, 0.95)$. The coordinates of any point on this segment can be parameterized by $\\lambda \\in [0, 1]$ as $\\lambda P_A + (1-\\lambda) P_C$. At the $\\phi_1$ coordinate of point $P_B$, which is $\\phi_1 = 0.9$, we find the corresponding $\\lambda$.\n$$0.9 = \\lambda(0.8) + (1-\\lambda)(1.1) = 1.1 - 0.3\\lambda$$\n$$0.3\\lambda = 0.2 \\implies \\lambda = \\frac{2}{3}$$\nAt this value of $\\lambda$, the corresponding $\\phi_2$ coordinate on the line segment is:\n$$\\phi_2 = \\frac{2}{3}(1.2) + \\left(1-\\frac{2}{3}\\right)(0.95) = \\frac{2}{3}(1.2) + \\frac{1}{3}(0.95) = 0.8 + \\frac{0.95}{3} \\approx 0.8 + 0.3167 = 1.1167$$\nSince the $\\phi_2$ value of point $P_B$ is $1.0$, which is less than $1.1167$, $P_B$ lies below the line segment connecting $P_A$ and $P_C$. This forms a nonconvex \"dent\" in the Pareto front. Consequently, no line with a constant slope can be tangent to the front uniquely at point $P_B$; any such line would intersect the convex hull of the points at a higher value of $S$. These points are sometimes referred to as unsupported Pareto optimal points.\n\nNow, we apply the weighted sum with weights $(w_1, w_2) = (0.5, 0.5)$. The scalarized objective is $S(\\phi_1, \\phi_2) = 0.5 \\phi_1 + 0.5 \\phi_2$. We evaluate this for each point:\nFor $P_A = (0.8, 1.2)$: $S_A = 0.5(0.8) + 0.5(1.2) = 0.4 + 0.6 = 1.0$.\nFor $P_B = (0.9, 1.0)$: $S_B = 0.5(0.9) + 0.5(1.0) = 0.45 + 0.5 = 0.95$.\nFor $P_C = (1.1, 0.95)$: $S_C = 0.5(1.1) + 0.5(0.95) = 0.55 + 0.475 = 1.025$.\nComparing the values, we find $\\max\\{1.0, 0.95, 1.025\\} = 1.025$, which corresponds to point $P_C = (1.1, 0.95)$. Thus, with weights $(0.5, 0.5)$, point $P_C$ is selected.\n\nNext, we prove that there is no choice of positive weights $(w_1, w_2)$ with $w_1+w_2=1$ that would make $P_B = (0.9, 1.0)$ the unique maximizer. Let $w_1 = w$, so $w_2 = 1-w$, with $w \\in (0, 1)$. The scalarized values are:\n$S_A = w(0.8) + (1-w)(1.2) = 1.2 - 0.4w$\n$S_B = w(0.9) + (1-w)(1.0) = 1.0 - 0.1w$\n$S_C = w(1.1) + (1-w)(0.95) = 0.95 + 0.15w$\n\nFor $P_B$ to be the unique maximizer, its scalarized value $S_B$ must be strictly greater than both $S_A$ and $S_C$.\n1. $S_B > S_A \\implies 1.0 - 0.1w > 1.2 - 0.4w \\implies 0.3w > 0.2 \\implies w > \\frac{2}{3}$.\n2. $S_B > S_C \\implies 1.0 - 0.1w > 0.95 + 0.15w \\implies 0.05 > 0.25w \\implies w  \\frac{0.05}{0.25} = \\frac{1}{5}$.\n\nThe two conditions are $w > \\frac{2}{3}$ and $w  \\frac{1}{5}$. Since $\\frac{2}{3} \\approx 0.667$ and $\\frac{1}{5} = 0.2$, these conditions are mutually exclusive. There is no value of $w \\in (0, 1)$ that can satisfy both inequalities simultaneously. Therefore, the point $P_B=(0.9, 1.0)$ can never be the unique maximizer of the weighted sum for any choice of positive weights.\n\nPart 2: Weighted Chebyshev Scalarization\n\nThe weighted Chebyshev method measures the weighted distance from an ideal reference point $z^\\star$. The ideal point $z^\\star=(z_1^\\star, z_2^\\star)$ is defined as the component-wise maximum of all objective values in the set of nondominated points. For our set $\\{P_A, P_B, P_C\\}$, the ideal point is:\n$z_1^\\star = \\max\\{0.8, 0.9, 1.1\\} = 1.1$\n$z_2^\\star = \\max\\{1.2, 1.0, 0.95\\} = 1.2$\nSo, the ideal point is $z^\\star = (1.1, 1.2)$.\n\nThe Chebyshev scalarization function to be minimized is given by:\n$$C(x) = \\max\\{w_1(z_1^\\star - \\phi_1(x)), w_2(z_2^\\star - \\phi_2(x))\\}$$\nUsing the specified weights $(w_1, w_2) = (0.5, 0.5)$, we evaluate this function for each of the three points. Geometrically, this method finds the point that is closest to the ideal point in terms of the weighted $L_\\infty$ norm. This method is capable of finding all Pareto-optimal points, including those on nonconvex parts of the front.\n\nFor $P_A = (0.8, 1.2)$:\nThe two terms are $0.5(1.1 - 0.8) = 0.5(0.3) = 0.15$ and $0.5(1.2 - 1.2) = 0.5(0) = 0$.\n$C(P_A) = \\max\\{0.15, 0\\} = 0.15$.\n\nFor $P_B = (0.9, 1.0)$:\nThe two terms are $0.5(1.1 - 0.9) = 0.5(0.2) = 0.1$ and $0.5(1.2 - 1.0) = 0.5(0.2) = 0.1$.\n$C(P_B) = \\max\\{0.1, 0.1\\} = 0.1$.\n\nFor $P_C = (1.1, 0.95)$:\nThe two terms are $0.5(1.1 - 1.1) = 0.5(0) = 0$ and $0.5(1.2 - 0.95) = 0.5(0.25) = 0.125$.\n$C(P_C) = \\max\\{0, 0.125\\} = 0.125$.\n\nTo select a point, we find the one that minimizes the Chebyshev value:\n$$\\min\\{C(P_A), C(P_B), C(P_C)\\} = \\min\\{0.15, 0.1, 0.125\\} = 0.1$$\nThe minimum value is $0.1$, which is achieved at point $P_B = (0.9, 1.0)$. Therefore, the Chebyshev scalarization method successfully selects the unsupported point $P_B$ that the weighted-sum method failed to find.\n\nThe minimal Chebyshev objective value is $0.1$. The problem requires this to be rounded to four significant figures.",
            "answer": "$$\\boxed{0.1000}$$"
        }
    ]
}