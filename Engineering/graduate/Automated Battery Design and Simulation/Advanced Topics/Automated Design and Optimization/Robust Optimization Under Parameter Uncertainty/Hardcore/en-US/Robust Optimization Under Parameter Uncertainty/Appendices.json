{
    "hands_on_practices": [
        {
            "introduction": "To effectively apply robust optimization, we must first learn how to translate a robust constraint into a tractable mathematical form. This foundational exercise guides you through the core mechanics of handling budgeted uncertainty, a popular and intuitive model for parameter deviations . By reformulating a robust voltage drop constraint for a busbar into a standard Linear Program (LP), you will gain a first-principles understanding of how the uncertainty budget, $\\Gamma$, controls the trade-off between performance and robustness.",
            "id": "3947214",
            "problem": "In automated battery pack design and simulation, the steady-state busbar voltage drop is governed by Ohm’s law. For a pack with $N$ series busbar segments carrying discharge currents, the total voltage drop is the sum of segment drops, modeled by $V_{\\text{drop}} = \\sum_{k=1}^{N} r_{k} i_{k}$, where $r_{k}$ is the resistance of segment $k$, and $i_{k} \\ge 0$ is the corresponding current. Under manufacturing variability and thermal effects, segment resistances are uncertain. Assume one-sided resistance increases $r_{k} = r_{k}^{0} + \\delta_{k}$, where $r_{k}^{0}$ is the nominal resistance and $0 \\le \\delta_{k} \\le d_{k}$ is an unknown deviation bounded by $d_{k}$. To regulate overall conservatism, use the budget-of-uncertainty parameter $\\Gamma$ introduced in robust optimization: at most $\\Gamma$ segments can simultaneously experience their full deviation, while the others may deviate partially.\n\nConsider a robust design requirement that the worst-case voltage drop does not exceed an allowable upper bound $V_{\\max}$, i.e., the constraint must hold for all deviations satisfying the budget-of-uncertainty. Reformulate this robust linear constraint using Linear Programming (LP) with auxiliary variables so that it is enforceable within a standard LP solver. Then, by first principles and appropriate dual reasoning, derive how the budget $\\Gamma$ controls the magnitude of the worst-case additive penalty on the nominal voltage drop.\n\nFinally, apply your formulation to the following four-segment case ($N=4$) with discharge currents and resistance data:\n- Currents: $i_{1} = 80$, $i_{2} = 60$, $i_{3} = 50$, $i_{4} = 40$ (all in $\\mathrm{A}$).\n- Nominal resistances: $r_{1}^{0} = 0.5$, $r_{2}^{0} = 0.8$, $r_{3}^{0} = 0.3$, $r_{4}^{0} = 0.6$ (all in $\\mathrm{m}\\Omega$).\n- Deviation bounds: $d_{1} = 0.1$, $d_{2} = 0.2$, $d_{3} = 0.05$, $d_{4} = 0.15$ (all in $\\mathrm{m}\\Omega$).\n\nAssume $\\Gamma = 2.3$ and compute the worst-case total voltage drop $V_{\\text{drop}}^{\\star}(\\Gamma)$ implied by your robust LP reformulation and analysis. Express the final answer in volts and round your answer to four significant figures. Provide only the final worst-case voltage drop value requested; do not include intermediate steps in your answer box.",
            "solution": "The user wants to solve a robust optimization problem related to battery pack design.\n\nHere's my thinking process to arrive at the solution:\n\n1.  **Deconstruct and Validate the Problem:**\n    *   **Core Physics:** The problem is based on Ohm's law, $V=IR$. Specifically, the total voltage drop across a series of components is the sum of individual voltage drops: $V_{\\text{drop}} = \\sum V_k = \\sum i_k r_k$. This is a fundamental and correct application of circuit theory for a DC analysis.\n    *   **Core Mathematics (Optimization):** The problem introduces uncertainty in the resistances, $r_k$, and models this using the Bertsimas  Sim \"budget-of-uncertainty\" framework. This is a well-established, theoretically sound method in robust optimization. The uncertainty set is defined by individual bounds ($0 \\le \\delta_k \\le d_k$) and a global budget constraint on the scaled deviations ($\\sum \\delta_k/d_k \\le \\Gamma$).\n    *   **Problem Objectives:** The request is threefold:\n        1.  Reformulate a robust constraint into a standard Linear Programming (LP) form.\n        2.  Explain, using first principles and duality, how the budget parameter $\\Gamma$ controls the worst-case outcome.\n        3.  Apply this formulation to a concrete numerical example and calculate the worst-case voltage drop.\n    *   **Data and Constraints:** The problem provides all necessary data: number of segments ($N$), currents ($i_k$), nominal resistances ($r_k^0$), resistance deviation bounds ($d_k$), and the uncertainty budget ($\\Gamma$). The units (A, mΩ) are consistent.\n    *   **Verdict:** The problem is scientifically grounded, well-posed, objective, and self-contained. There are no contradictions or ambiguities. It is a standard, albeit non-trivial, application of robust optimization. Therefore, the problem is **valid**.\n\n2.  **Develop the Solution Strategy:**\n\n    *   **Part 1: LP Reformulation.** The core of the problem lies in dealing with the robust constraint:\n        $$ \\sum_{k=1}^{N} r_k i_k \\le V_{\\text{max}} \\quad \\forall (r_1, \\dots, r_N) \\in \\text{Uncertainty Set} $$\n        Substituting $r_k = r_k^0 + \\delta_k$, this is equivalent to:\n        $$ \\sum_{k=1}^{N} r_k^0 i_k + \\max_{\\delta \\in U} \\left( \\sum_{k=1}^{N} \\delta_k i_k \\right) \\le V_{\\text{max}} $$\n        The term $\\max_{\\delta \\in U} (\\dots)$ is itself an optimization problem (the \"inner\" or \"adversarial\" problem). The key insight of the Bertsimas  Sim method is to replace this maximization term with the optimal value of its LP dual. This transforms a semi-infinite problem (infinite constraints) into a finite set of linear constraints.\n        *   **Step 1:** Formulate the inner maximization problem. Let's call its optimal value $\\Pi(\\Gamma)$.\n        *   **Step 2:** Formulate the dual of this inner problem. By strong duality (which holds for LPs), the optimal value of the primal (the max problem) equals the optimal value of the dual (a min problem).\n        *   **Step 3:** Substitute the dual formulation back into the original constraint. The dual objective becomes part of the left-hand side, and the dual constraints are added to the overall problem statement. This gives the final LP reformulation.\n\n    *   **Part 2: Role of Γ.** The question asks for a derivation based on \"first principles.\" This suggests directly solving the inner maximization problem.\n        *   **Step 1:** I recognize the inner problem, $\\max \\sum \\delta_k i_k$ subject to $\\sum \\delta_k/d_k \\le \\Gamma$ and $0 \\le \\delta_k \\le d_k$, as a variant of the knapsack problem. By letting $z_k = \\delta_k/d_k$, it takes the canonical form of a **continuous knapsack problem**:\n            $$ \\max \\sum_{k=1}^{N} (i_k d_k) z_k \\quad \\text{s.t.} \\quad \\sum_{k=1}^{N} z_k \\le \\Gamma, \\quad 0 \\le z_k \\le 1 $$\n        *   **Step 2:** The solution to the continuous knapsack problem is found via a simple greedy algorithm. We calculate the \"value density\" for each item, which here is simply the value $v_k = i_k d_k$ (since all \"weights\" are 1). We then \"fill the knapsack\" by taking the items with the highest value first, taking them fully ($z_k=1$) until the budget $\\Gamma$ is nearly used up, and then taking a fraction of the next-best item to exactly meet the budget.\n        *   **Step 3:** I will write down the explicit formula derived from this greedy strategy. This formula for the worst-case penalty, $\\Pi(\\Gamma)$, will clearly show its dependence on $\\Gamma$ (it's a piecewise linear, convex function). The \"dual reasoning\" part involves showing that this result matches the one obtained from the dual formulation, which I've already planned for Part 1. I can briefly explain how the optimal dual variable $\\lambda^*$ is related to the sorted values of $i_k d_k$.\n\n    *   **Part 3: Numerical Calculation.** This is a straightforward application of the formula derived in Part 2.\n        *   **Step 1:** Calculate the nominal voltage drop, $V_{\\text{nom}} = \\sum r_k^0 i_k$.\n        *   **Step 2:** Calculate the \"value\" terms, $v_k = i_k d_k$, for each segment.\n        *   **Step 3:** Sort these values in descending order.\n        *   **Step 4:** Plug the sorted values and $\\Gamma=2.3$ into the penalty formula $\\Pi(\\Gamma)$.\n        *   **Step 5:** Calculate the final worst-case voltage drop, $V_{\\text{drop}}^{\\star} = V_{\\text{nom}} + \\Pi(\\Gamma)$.\n        *   **Step 6:** Ensure the final answer is in the correct units (Volts) and rounded to the specified number of significant figures (four).\n\n3.  **Final Polish and Formatting:**\n    *   I will write the solution clearly, following the logical flow established above.\n    *   I'll be extremely careful with the mandatory LaTeX formatting. Every single number, variable, and symbol will be enclosed in `$...$` or `$$...$$`. For example, `i_1 = 80` becomes `$i_{1} = 80$`.\n    *   The final boxed answer in `final_answer` will contain only the numerical value, `0.1488`, as requested. No units, no text, no variables.\n\nThis detailed plan ensures all aspects of the user's request are addressed accurately, rigorously, and in the specified format. It moves from general theory to specific application, providing the required derivations along the way.The problem is scientifically and mathematically valid. It describes a standard application of robust optimization using a budget-of-uncertainty model, which is a well-established technique for handling parameter uncertainty in linear programs. The underlying physical model is a correct application of Ohm's law. All necessary data are provided, and there are no internal contradictions.\n\nThe problem requires a three-part solution: the reformulation of a robust constraint into a standard Linear Programming (LP) form, a derivation of how the uncertainty budget $\\Gamma$ controls the worst-case penalty, and the calculation of a specific worst-case voltage drop.\n\nFirst, we define the total voltage drop. Given the resistance of segment $k$ is $r_k = r_k^0 + \\delta_k$, the total voltage drop is:\n$$ V_{\\text{drop}} = \\sum_{k=1}^{N} r_k i_k = \\sum_{k=1}^{N} (r_k^0 + \\delta_k) i_k = \\sum_{k=1}^{N} r_k^0 i_k + \\sum_{k=1}^{N} \\delta_k i_k $$\nThe first term, $\\sum_{k=1}^{N} r_k^0 i_k$, is the nominal voltage drop, which we denote as $V_{\\text{nom}}$. The second term is the additional voltage drop due to resistance deviations.\n\nThe robust design requirement is that the constraint $V_{\\text{drop}} \\le V_{\\max}$ must hold for all possible deviations $\\delta_k$ within the specified uncertainty set. This is equivalent to ensuring that the worst-case voltage drop does not exceed $V_{\\max}$:\n$$ \\max_{\\delta \\in U} \\left( \\sum_{k=1}^{N} r_k^0 i_k + \\sum_{k=1}^{N} \\delta_k i_k \\right) \\le V_{\\max} $$\n$$ V_{\\text{nom}} + \\max_{\\delta \\in U} \\left( \\sum_{k=1}^{N} \\delta_k i_k \\right) \\le V_{\\max} $$\nThe uncertainty set $U$ is defined by the constraints: $0 \\le \\delta_k \\le d_k$ for all $k \\in \\{1, \\dots, N\\}$, and the budget constraint $\\sum_{k=1}^{N} \\frac{\\delta_k}{d_k} \\le \\Gamma$.\n\nThe core of the problem is the inner maximization problem, which finds the worst-case penalty on the voltage drop:\n$$ \\Pi(\\Gamma) = \\max \\sum_{k=1}^{N} i_k \\delta_k $$\nSubject to:\n$$ \\sum_{k=1}^{N} \\frac{1}{d_k} \\delta_k \\le \\Gamma $$\n$$ 0 \\le \\delta_k \\le d_k, \\quad k=1, \\dots, N $$\nThis is a linear program. To obtain the LP reformulation of the robust constraint, we derive the dual of this problem. Let $\\lambda \\ge 0$ be the dual variable for the budget constraint, and $\\rho_k \\ge 0$ be the dual variables for the upper bound constraints $\\delta_k \\le d_k$. The constraint $\\delta_k \\ge 0$ is handled implicitly.\n\nThe dual problem is:\n$$ \\min_{\\lambda \\ge 0, \\rho_k \\ge 0} \\left( \\Gamma \\lambda + \\sum_{k=1}^{N} d_k \\rho_k \\right) $$\nSubject to:\n$$ \\frac{\\lambda}{d_k} + \\rho_k \\ge i_k, \\quad k=1, \\dots, N $$\nBy strong duality for LPs, $\\Pi(\\Gamma)$ is equal to the optimal value of this dual problem. Thus, the original robust constraint is equivalent to the following system of linear constraints involving the auxiliary variables $\\lambda$ and $\\rho_k$:\n$$ V_{\\text{nom}} + \\Gamma \\lambda + \\sum_{k=1}^{N} d_k \\rho_k \\le V_{\\max} $$\n$$ \\lambda + d_k \\rho_k \\ge i_k d_k, \\quad k=1, \\dots, N $$\n$$ \\lambda \\ge 0, \\quad \\rho_k \\ge 0 $$\nThis is the requested LP reformulation.\n\nNext, we derive how $\\Gamma$ controls the magnitude of the worst-case penalty, $\\Pi(\\Gamma)$. We solve the primal maximization problem directly. Let us introduce scaled deviation variables $z_k = \\delta_k/d_k$, so that $0 \\le z_k \\le 1$. The problem becomes:\n$$ \\Pi(\\Gamma) = \\max \\sum_{k=1}^{N} (i_k d_k) z_k $$\nSubject to:\n$$ \\sum_{k=1}^{N} z_k \\le \\Gamma $$\n$$ 0 \\le z_k \\le 1, \\quad k=1, \\dots, N $$\nThis is a continuous knapsack problem. The optimal solution can be found with a greedy approach. We should prioritize the segments with the largest potential voltage drop increase, which is given by the product $v_k = i_k d_k$. Let $\\pi$ be a permutation of the indices $\\{1, \\dots, N\\}$ such that $v_{\\pi(1)} \\ge v_{\\pi(2)} \\ge \\dots \\ge v_{\\pi(N)}$.\n\nThe greedy strategy is to set $z_k$ to its maximum value of $1$ for the largest $v_k$ values until the budget $\\Gamma$ is depleted. Let $m = \\lfloor \\Gamma \\rfloor$ be the integer part of $\\Gamma$ and $\\{\\Gamma\\} = \\Gamma - m$ be its fractional part.\nThe optimal solution is to set:\n$z_{\\pi(k)} = 1$ for $k = 1, \\dots, m$.\n$z_{\\pi(m+1)} = \\{\\Gamma\\}$.\n$z_{\\pi(k)} = 0$ for $k  m+1$.\nThe total sum is $\\sum z_k = m \\cdot 1 + \\{\\Gamma\\} + 0 = \\Gamma$, satisfying the budget constraint.\nThe worst-case additive penalty is therefore:\n$$ \\Pi(\\Gamma) = \\sum_{k=1}^{N} v_k z_k = \\sum_{k=1}^{m} v_{\\pi(k)} \\cdot 1 + v_{\\pi(m+1)} \\cdot \\{\\Gamma\\} + \\sum_{k=m+2}^{N} v_{\\pi(k)} \\cdot 0 $$\n$$ \\Pi(\\Gamma) = \\sum_{k=1}^{\\lfloor \\Gamma \\rfloor} v_{\\pi(k)} + \\{\\Gamma\\} \\cdot v_{\\pi(\\lfloor \\Gamma \\rfloor + 1)} $$\nThis explicit formula shows that the penalty is a piecewise linear, convex function of $\\Gamma$. The slope of the penalty function decreases as $\\Gamma$ increases, with the slope in the interval $\\Gamma \\in [m, m+1]$ being equal to the $(m+1)$-th largest value of $i_k d_k$.\n\nFinally, we apply this to the given four-segment case.\nData:\nCurrents: $i_{1} = 80 \\, \\mathrm{A}$, $i_{2} = 60 \\, \\mathrm{A}$, $i_{3} = 50 \\, \\mathrm{A}$, $i_{4} = 40 \\, \\mathrm{A}$.\nNominal resistances: $r_{1}^{0} = 0.5 \\, \\mathrm{m}\\Omega$, $r_{2}^{0} = 0.8 \\, \\mathrm{m}\\Omega$, $r_{3}^{0} = 0.3 \\, \\mathrm{m}\\Omega$, $r_{4}^{0} = 0.6 \\, \\mathrm{m}\\Omega$.\nDeviation bounds: $d_{1} = 0.1 \\, \\mathrm{m}\\Omega$, $d_{2} = 0.2 \\, \\mathrm{m}\\Omega$, $d_{3} = 0.05 \\, \\mathrm{m}\\Omega$, $d_{4} = 0.15 \\, \\mathrm{m}\\Omega$.\nBudget: $\\Gamma = 2.3$.\n\nFirst, calculate the nominal voltage drop $V_{\\text{nom}}$ (in millivolts, $\\mathrm{mV}$):\n$$ V_{\\text{nom}} = (80)(0.5) + (60)(0.8) + (50)(0.3) + (40)(0.6) = 40 + 48 + 15 + 24 = 127 \\, \\mathrm{mV} $$\nNext, calculate the products $v_k = i_k d_k$ (in millivolts, $\\mathrm{mV}$):\n$v_1 = i_1 d_1 = (80)(0.1) = 8 \\, \\mathrm{mV}$\n$v_2 = i_2 d_2 = (60)(0.2) = 12 \\, \\mathrm{mV}$\n$v_3 = i_3 d_3 = (50)(0.05) = 2.5 \\, \\mathrm{mV}$\n$v_4 = i_4 d_4 = (40)(0.15) = 6 \\, \\mathrm{mV}$\n\nSort these values in descending order:\n$v_2 = 12$\n$v_1 = 8$\n$v_4 = 6$\n$v_3 = 2.5$\nThe sorted order of indices $\\pi$ is $(2, 1, 4, 3)$. The sorted values are $v_{\\pi(1)}=12$, $v_{\\pi(2)}=8$, $v_{\\pi(3)}=6$, $v_{\\pi(4)}=2.5$.\n\nFor $\\Gamma = 2.3$, we have $\\lfloor \\Gamma \\rfloor = 2$ and $\\{\\Gamma\\} = 0.3$.\nUsing the formula for the worst-case penalty $\\Pi(\\Gamma)$:\n$$ \\Pi(2.3) = v_{\\pi(1)} + v_{\\pi(2)} + 0.3 \\cdot v_{\\pi(3)} $$\n$$ \\Pi(2.3) = 12 + 8 + 0.3 \\cdot 6 = 20 + 1.8 = 21.8 \\, \\mathrm{mV} $$\nThe worst-case total voltage drop is the sum of the nominal drop and the worst-case penalty:\n$$ V_{\\text{drop}}^{\\star}(\\Gamma) = V_{\\text{nom}} + \\Pi(\\Gamma) = 127 \\, \\mathrm{mV} + 21.8 \\, \\mathrm{mV} = 148.8 \\, \\mathrm{mV} $$\nConverting to volts:\n$$ V_{\\text{drop}}^{\\star}(2.3) = 0.1488 \\, \\mathrm{V} $$\nThis value has four significant figures.",
            "answer": "$$\\boxed{0.1488}$$"
        },
        {
            "introduction": "While direct reformulation is powerful, many real-world engineering systems are described by complex, nonlinear models like the Doyle-Fuller-Newman (DFN) model for batteries, where a closed-form robust counterpart is often unavailable. This practice introduces a sophisticated algorithmic approach, the cutting-plane method, to tackle such problems . You will explore how to construct a \"separation oracle\" for ellipsoidal uncertainty sets, a key subroutine that iteratively finds the worst-case parameter violation, allowing you to solve robust design problems for high-fidelity physical models.",
            "id": "3947142",
            "problem": "Consider a robust design problem for a lithium-ion cell where the decision variables $x$ (such as porosities, tortuosities, and thicknesses of the electrodes and separator) are chosen to ensure that the cell terminal voltage predicted by the Doyle–Fuller–Newman (DFN) model, defined as $V(x;\\theta)$, does not drop below a specification $V_{\\min}$ under uncertain electrochemical parameters $\\theta \\in \\mathbb{R}^{p}$. Define the robust constraint as\n$$\ng(x,\\theta) \\equiv V_{\\min} - V(x;\\theta) \\le 0 \\quad \\text{for all } \\theta \\in \\mathcal{U},\n$$\nwhere the uncertainty set is ellipsoidal,\n$$\n\\mathcal{U} \\equiv \\left\\{ \\theta \\in \\mathbb{R}^{p} : \\left\\| W\\left(\\theta - \\bar{\\theta}\\right)\\right\\|_{2} \\le \\rho \\right\\},\n$$\nwith nominal parameters $\\bar{\\theta}$, radius $\\rho  0$, and a nonsingular matrix $W \\in \\mathbb{R}^{p \\times p}$ that encodes parameter scaling or covariance. The DFN model is governed by conservation of charge and mass in the solid and electrolyte phases with Butler–Volmer kinetics; under sufficiently smooth dependence on $\\theta$ and for fixed discharge current profile, local linearization in $\\theta$ at $\\bar{\\theta}$ yields\n$$\ng(x,\\theta) \\approx g\\left(x,\\bar{\\theta}\\right) + s(x)^{\\top}\\left(\\theta - \\bar{\\theta}\\right),\n$$\nwhere $s(x) = \\nabla_{\\theta} g(x,\\theta)\\big|_{\\theta=\\bar{\\theta}}$ is the parameter sensitivity vector obtained, for a given $x$, from an adjoint of the DFN model. Cutting-plane methods for robust optimization solve a master problem over $x$ using a finite working set of scenarios $\\Theta_{k} \\subset \\mathcal{U}$, and then invoke a separation oracle to either certify that $g(x,\\theta) \\le 0$ for all $\\theta \\in \\mathcal{U}$ or produce a worst-case $\\theta^{\\star} \\in \\mathcal{U}$ that violates the robust constraint, which is then added to $\\Theta_{k}$ as a new cut.\n\nWhich option correctly describes how the cutting-plane method iteratively adds worst-case parameter cuts for this robust DFN-constrained design and proposes a valid separation oracle based on the linearization and the ellipsoidal uncertainty set above?\n\nA. Given the current design $x_{k}$, compute the sensitivity $s_{k} = \\nabla_{\\theta} g(x_{k},\\theta)\\big|_{\\theta=\\bar{\\theta}}$ via the DFN adjoint. The separation oracle solves $\\max_{\\theta \\in \\mathcal{U}} g(x_{k},\\theta)$ under the linearization and returns\n$$\n\\theta^{\\star} = \\bar{\\theta} + \\rho\\, W^{-1}\\,\\frac{W^{-T}\\, s_{k}}{\\left\\|W^{-T}\\, s_{k}\\right\\|_{2}},\n$$\nand the cut $g(x,\\theta^{\\star}) \\le 0$ is added to the master problem; the process repeats until no violation is found.\n\nB. Given $x_{k}$, take a gradient ascent step in the design space using $s_{k}$ and add the linear cut $s_{k}^{\\top}(x - x_{k}) \\le -g(x_{k},\\bar{\\theta})$; the separation oracle returns $x$-cuts rather than $\\theta$ scenarios because the uncertainty is embedded into the design via sensitivity.\n\nC. Given $x_{k}$, compute $s_{k}$ and return the single deterministic inequality\n$$\ng\\left(x,\\bar{\\theta}\\right) + \\rho \\left\\|W^{-T}\\, s(x)\\right\\|_{2} \\le 0,\n$$\nto replace the infinite family of robust constraints; iteratively adding scenario cuts is unnecessary because the robust counterpart is captured by a conic inequality.\n\nD. Given $x_{k}$, select the worst-case parameter by maximizing each component independently using $\\theta^{\\star}_{i} = \\bar{\\theta}_{i} + \\rho\\, \\mathrm{sign}\\left(s_{k,i}\\right)$ and add the cut $g(x,\\theta^{\\star}) \\le 0$, since the worst case over an ellipsoid can be found by pushing each coordinate to its bound.",
            "solution": "The user has provided a problem in the domain of robust optimization applied to the design of lithium-ion cells. The task is to identify the correct description of a separation oracle within a cutting-plane algorithm for a specific problem formulation.\n\n### Problem Validation\n\nFirst, I will validate the problem statement.\n\n**Step 1: Extract Givens**\n\n-   **Decision variables:** $x$ (design parameters like porosities, tortuosities, thicknesses).\n-   **Model:** Doyle–Fuller–Newman (DFN) model.\n-   **Performance function:** Cell terminal voltage $V(x;\\theta)$.\n-   **Uncertain parameters:** $\\theta \\in \\mathbb{R}^{p}$.\n-   **Robust constraint:** $g(x,\\theta) \\equiv V_{\\min} - V(x;\\theta) \\le 0$ for all $\\theta \\in \\mathcal{U}$.\n-   **Uncertainty set:** An ellipsoid $\\mathcal{U} \\equiv \\left\\{ \\theta \\in \\mathbb{R}^{p} : \\left\\| W\\left(\\theta - \\bar{\\theta}\\right)\\right\\|_{2} \\le \\rho \\right\\}$.\n-   **Parameters of $\\mathcal{U}$:** Nominal parameters $\\bar{\\theta}$, radius $\\rho  0$, and a nonsingular matrix $W \\in \\mathbb{R}^{p \\times p}$.\n-   **Approximation:** The constraint function is linearized with respect to $\\theta$ at $\\bar{\\theta}$: $g(x,\\theta) \\approx g\\left(x,\\bar{\\theta}\\right) + s(x)^{\\top}\\left(\\theta - \\bar{\\theta}\\right)$.\n-   **Sensitivity vector:** $s(x) = \\nabla_{\\theta} g(x,\\theta)\\big|_{\\theta=\\bar{\\theta}}$ (computed via an adjoint method).\n-   **Algorithm:** A cutting-plane method that iteratively solves a master problem and calls a separation oracle to find a worst-case parameter violation $\\theta^{\\star}$, which is then added as a new cut.\n-   **Question:** Identify the correct description of the separation oracle and the cutting-plane update step for this problem.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientific Grounding:** The problem is well-grounded. The DFN model is a standard, physics-based model for lithium-ion battery electrochemistry. Robust optimization is a rigorous branch of optimization theory. Cutting-plane algorithms are classical methods for solving convex optimization problems, including those arising from robust optimization. The use of adjoint methods for sensitivity analysis is a standard and efficient technique in computational science and engineering. The formulation is scientifically and mathematically sound.\n-   **Well-Posed:** The problem is well-posed. It asks for the derivation of the worst-case parameter within a specified mathematical framework (linearization of a function over an ellipsoidal set). This subproblem, known as the separation problem, has a unique analytical solution, which makes the question answerable and not ill-posed.\n-   **Objective:** The language is formal, precise, and objective, using standard terminology from optimization and battery modeling.\n-   **Completeness and Consistency:** The problem provides all necessary definitions to derive the separation oracle: the objective function to be maximized ($g(x, \\theta)$), its linear approximation, and the constraint set ($\\mathcal{U}$). There are no contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is a well-posed, scientifically grounded problem in robust optimization. I will proceed to derive the solution.\n\n### Principle-Based Derivation of the Separation Oracle\n\nThe cutting-plane method requires a separation oracle. For a given design iterate $x_k$, the oracle must solve the following subproblem to find the parameter $\\theta$ within the uncertainty set $\\mathcal{U}$ that causes the maximum (worst-case) violation of the constraint:\n$$\n\\max_{\\theta \\in \\mathcal{U}} g(x_k, \\theta)\n$$\nIf the result of this maximization is positive, the constraint is violated, and the maximizing parameter $\\theta^{\\star}$ must be returned. Using the provided linear approximation for $g(x, \\theta)$ and denoting $s_k = s(x_k)$, the subproblem becomes:\n$$\n\\max_{\\theta \\in \\mathcal{U}} \\left[ g(x_k, \\bar{\\theta}) + s_k^{\\top}(\\theta - \\bar{\\theta}) \\right]\n$$\nSince $g(x_k, \\bar{\\theta})$ and $s_k$ are constant with respect to the optimization variable $\\theta$, this is equivalent to solving:\n$$\ng(x_k, \\bar{\\theta}) + \\max_{\\theta \\in \\mathcal{U}} \\left[ s_k^{\\top}(\\theta - \\bar{\\theta}) \\right]\n$$\nThe core optimization problem is $\\max_{\\theta} s_k^{\\top}(\\theta - \\bar{\\theta})$ subject to the constraint $\\left\\| W(\\theta - \\bar{\\theta}) \\right\\|_{2} \\le \\rho$.\n\nTo solve this, we introduce a change of variables. Let $z = W(\\theta - \\bar{\\theta})$. Since $W$ is nonsingular, we can write $\\theta - \\bar{\\theta} = W^{-1} z$. The constraint on $z$ is simply $\\left\\| z \\right\\|_{2} \\le \\rho$. Substituting into the objective function:\n$$\ns_k^{\\top}(\\theta - \\bar{\\theta}) = s_k^{\\top} W^{-1} z = (W^{-T} s_k)^{\\top} z\n$$\nThe problem is now transformed into a standard form:\n$$\n\\max_{z} (W^{-T} s_k)^{\\top} z \\quad \\text{subject to} \\quad \\|z\\|_{2} \\le \\rho\n$$\nBy the Cauchy-Schwarz inequality, the dot product $(W^{-T} s_k)^{\\top} z$ is maximized when the vector $z$ is collinear with the vector $W^{-T} s_k$ and has the maximum possible magnitude. The maximum magnitude allowed by the constraint is $\\rho$. Therefore, the optimal $z^{\\star}$ is:\n$$\nz^{\\star} = \\rho \\frac{W^{-T} s_k}{\\left\\|W^{-T} s_k\\right\\|_{2}}\n$$\nThis assumes $s_k \\neq 0$. If $s_k=0$, the objective is zero for any $\\theta$, and any $\\theta \\in \\mathcal{U}$ is optimal. We assume the non-trivial case.\n\nTo find the worst-case parameter $\\theta^{\\star}$, we transform back from $z^{\\star}$:\n$$\nW(\\theta^{\\star} - \\bar{\\theta}) = z^{\\star}\n$$\n$$\n\\theta^{\\star} - \\bar{\\theta} = W^{-1} z^{\\star} = W^{-1} \\left( \\rho \\frac{W^{-T} s_k}{\\left\\|W^{-T} s_k\\right\\|_{2}} \\right)\n$$\nThus, the worst-case parameter is:\n$$\n\\theta^{\\star} = \\bar{\\theta} + \\rho W^{-1} \\frac{W^{-T} s_k}{\\left\\|W^{-T} s_k\\right\\|_{2}}\n$$\nThe cutting-plane algorithm then adds a constraint involving this $\\theta^\\star$ (e.g., $g(x, \\theta^\\star) \\le 0$) to the master problem, which is then re-solved to find the next design iterate $x_{k+1}$.\n\n### Option-by-Option Analysis\n\n**A. Given the current design $x_{k}$, compute the sensitivity $s_{k} = \\nabla_{\\theta} g(x_{k},\\theta)\\big|_{\\theta=\\bar{\\theta}}$ via the DFN adjoint. The separation oracle solves $\\max_{\\theta \\in \\mathcal{U}} g(x_{k},\\theta)$ under the linearization and returns\n$$\n\\theta^{\\star} = \\bar{\\theta} + \\rho\\, W^{-1}\\,\\frac{W^{-T}\\, s_{k}}{\\left\\|W^{-T}\\, s_{k}\\right\\|_{2}},\n$$\nand the cut $g(x,\\theta^{\\star}) \\le 0$ is added to the master problem; the process repeats until no violation is found.**\n\nThis option correctly describes the procedure. It correctly identifies the role of the sensitivity vector $s_k$. It correctly formulates the expression for the worst-case parameter $\\theta^{\\star}$ that maximizes the linearized function over the given ellipsoidal uncertainty set, matching our derivation precisely. Finally, it correctly describes the iteration of a cutting-plane algorithm, where the new scenario $\\theta^\\star$ is used to generate a new cut for the master problem.\n\n**Verdict: Correct**\n\n**B. Given $x_{k}$, take a gradient ascent step in the design space using $s_{k}$ and add the linear cut $s_{k}^{\\top}(x - x_{k}) \\le -g(x_{k},\\bar{\\theta})$; the separation oracle returns $x$-cuts rather than $\\theta$ scenarios because the uncertainty is embedded into the design via sensitivity.**\n\nThis option is fundamentally flawed. The vector $s_k=\\nabla_{\\theta} g(x_k, \\theta)|_{\\bar{\\theta}}$ is the gradient of the constraint function with respect to the *parameters* $\\theta$, not the *design variables* $x$. A gradient-based optimization step in the design space $x$ would require $\\nabla_x g$. Furthermore, the problem explicitly describes a cutting-plane method where the separation oracle identifies a worst-case *parameter scenario* $\\theta^\\star$ from the uncertainty set $\\mathcal{U}$. This option incorrectly describes a method that generates cuts on the design variable $x$ and does not align with the algorithm described in the problem statement.\n\n**Verdict: Incorrect**\n\n**C. Given $x_{k}$, compute $s_{k}$ and return the single deterministic inequality\n$$\ng\\left(x,\\bar{\\theta}\\right) + \\rho \\left\\|W^{-T}\\, s(x)\\right\\|_{2} \\le 0,\n$$\nto replace the infinite family of robust constraints; iteratively adding scenario cuts is unnecessary because the robust counterpart is captured by a conic inequality.**\n\nThis option describes the \"robust counterpart\" formulation of the problem. As shown in the derivation, the maximum value of the linearized constraint function over $\\mathcal{U}$ is indeed $g(x, \\bar{\\theta}) + \\rho \\|W^{-T} s(x)\\|_2$. Therefore, the semi-infinite constraint $\\sup_{\\theta \\in \\mathcal{U}} g(x, \\theta) \\le 0$ is equivalent to the single, deterministic, second-order cone constraint $g(x, \\bar{\\theta}) + \\rho \\|W^{-T} s(x)\\|_2 \\le 0$. While this is a valid and powerful method to solve the robust optimization problem, it is an *alternative* to the cutting-plane method. The question specifically asks how the *cutting-plane method* iteratively adds cuts. This option argues that such a method is unnecessary, thereby failing to answer the question posed.\n\n**Verdict: Incorrect**\n\n**D. Given $x_{k}$, select the worst-case parameter by maximizing each component independently using $\\theta^{\\star}_{i} = \\bar{\\theta}_{i} + \\rho\\, \\mathrm{sign}\\left(s_{k,i}\\right)$ and add the cut $g(x,\\theta^{\\star}) \\le 0$, since the worst case over an ellipsoid can be found by pushing each coordinate to its bound.**\n\nThis option proposes an incorrect method for finding the worst-case parameter. Maximizing a linear function over a constraint set by independently pushing each variable to an extreme value is generally valid only for hyper-rectangle (box) uncertainty sets of the form $\\|\\theta - \\bar{\\theta}\\|_\\infty \\le \\text{const}$. For an ellipsoidal set, defined by an $L_2$-norm constraint $\\left\\| W(\\theta - \\bar{\\theta}) \\right\\|_{2} \\le \\rho$, the variables are coupled. The point constructed by this option, $\\theta^\\star$ such that $\\theta^{\\star}_{i} = \\bar{\\theta}_{i} + \\rho\\, \\mathrm{sign}\\left(s_{k,i}\\right)$, will in general lie outside the ellipsoid $\\mathcal{U}$ and is therefore not a feasible solution to the separation subproblem. The premise that the worst case over an ellipsoid is found this way is false.\n\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The final step in robust design is often tuning the level of conservatism to match the specific application's risk tolerance and performance goals. This hands-on coding problem bridges theory and practice by tasking you with implementing a full data-driven workflow to optimize a fast-charging protocol for a battery pack . By solving a series of robust linear programs and evaluating their solutions against out-of-sample data, you will learn how to select the optimal budget parameter, $\\Gamma$, that maximizes a risk-adjusted performance metric, a crucial skill for deploying robust solutions in real-world engineering.",
            "id": "3947183",
            "problem": "Consider a simplified but scientifically plausible fast-charging design problem for a Lithium-ion battery pack under voltage limits. The terminal voltage at discrete time step $t \\in \\{0,\\dots,T-1\\}$ is modeled as a sum of three contributions: the open-circuit voltage $U_{\\mathrm{nom},t}$ from nominal simulation, an ohmic drop proportional to the applied current $I_t$, and a transient polarization proportional to the step-to-step current change magnitude $s_t = |I_t - I_{t-1}|$ (with the convention $I_{-1} = 0$). The model is\n$$\nV_t = U_{\\mathrm{nom},t} + R_{\\mathrm{nom}} I_t + P_{\\mathrm{nom}} s_t,\n$$\nwhere $R_{\\mathrm{nom}}$ (ohmic resistance) and $P_{\\mathrm{nom}}$ (transient polarization coefficient) are nominal coefficients obtained from prior simulation and identification. The voltage limit requires $V_t \\le V_{\\max}$ for all $t$.\n\nWe account for parameter uncertainty in $R$ and $P$ by a budgeted uncertainty model (Bertsimas–Sim) with budget parameter $\\Gamma \\in [0,2]$ per time step. Specifically, we assume $R = R_{\\mathrm{nom}} + \\delta_R$ and $P = P_{\\mathrm{nom}} + \\delta_P$, where the nonnegative deviations $\\delta_R \\in [0,\\hat R]$ and $\\delta_P \\in [0,\\hat P]$ are bounded by uncertainty radii $\\hat R$ and $\\hat P$ estimated from training data. Under budget $\\Gamma$, at each time step $t$, at most $\\Gamma$ of the two uncertain contributions can take their worst-case values simultaneously, with fractional allowance when $\\Gamma$ is non-integer. The robust counterpart for the voltage constraint at time $t$ is\n$$\nU_{\\mathrm{nom},t} + R_{\\mathrm{nom}} I_t + P_{\\mathrm{nom}} s_t + \\Gamma z_t + p_{t,1} + p_{t,2} \\le V_{\\max},\n$$\nwith auxiliary variables $z_t \\ge 0$, $p_{t,i} \\ge 0$ and linear constraints\n$$\np_{t,1} \\ge \\hat R\\, I_t - z_t, \\quad p_{t,2} \\ge \\hat P\\, s_t - z_t.\n$$\nThese are the standard Linear Programming robust counterpart constraints for budgeted uncertainty in coefficients of a linear inequality. The absolute value $s_t = |I_t - I_{t-1}|$ is enforced by linear inequalities\n$$\ns_t \\ge I_t - I_{t-1}, \\quad s_t \\ge I_{t-1} - I_t, \\quad s_t \\ge 0, \\quad I_{-1} = 0.\n$$\n\nThe design objective is to maximize the total charged quantity $Q = \\Delta t \\sum_{t=0}^{T-1} I_t$ (in ampere-seconds), subject to $0 \\le I_t \\le I_{\\max}$ and the robust voltage constraints for all $t$. We will tune the budget parameter $\\Gamma$ using out-of-sample validation to balance robustness (respecting voltage limits under uncertainty) against performance (large $Q$). Given a fixed candidate $\\Gamma$, we solve the above robust Linear Program to obtain a charging current profile $I_t$ and the associated step-change magnitudes $s_t$. We then evaluate the out-of-sample violation rate using independent validation scenarios of $(\\delta_R,\\delta_P)$ drawn from a specified distribution, computing for each scenario whether any $t$ violates $V_t \\le V_{\\max}$. The risk-adjusted performance metric is defined as\n$$\n\\widetilde{Q} = Q \\cdot (1 - \\text{violation\\_rate}),\n$$\nand we select the $\\Gamma$ maximizing $\\widetilde{Q}$ on validation data, breaking ties by choosing the smallest $\\Gamma$.\n\nYour task is to implement this robust tuning procedure with the following test suite of parameter values. All physical quantities must be interpreted in the International System of Units (SI). Express all voltages in volts ($\\mathrm{V}$), currents in amperes ($\\mathrm{A}$), time in seconds ($\\mathrm{s}$), and charge in ampere-seconds ($\\mathrm{A}\\cdot \\mathrm{s}$). Angles do not appear. The final output must be the selected $\\Gamma$ values for each test case, as floats.\n\nFor each test case, use training data to estimate $(\\hat R, \\hat P)$ as empirical $0.95$-quantiles of nonnegative deviations drawn from the specified training distributions. Use validation data to compute the violation rate from the specified mixture distributions. For all cases, use $\\Gamma$ candidates $\\{0.0, 0.5, 1.0, 1.5, 2.0\\}$.\n\nTest Case $1$ (happy path):\n- Horizon length $T = 12$, step $\\Delta t = 5$.\n- Nominal open-circuit voltage sequence $U_{\\mathrm{nom},t} = 380 + 0.4 t$ for $t = 0, \\dots, 11$.\n- Voltage limit $V_{\\max} = 402$.\n- Current bound $I_{\\max} = 180$.\n- Nominal ohmic resistance $R_{\\mathrm{nom}} = 0.010$.\n- Nominal polarization coefficient $P_{\\mathrm{nom}} = 0.004$.\n- Training deviations are independent draws: $\\delta_R^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_R^2)|$ with $\\sigma_R = 0.001$, and $\\delta_P^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_P^2)|$ with $\\sigma_P = 0.0005$; sample size $N_{\\mathrm{train}} = 200$; random seed $123$.\n- Validation deviations follow a mixture: with probability $0.9$, draw $(\\delta_R, \\delta_P)$ from $|\\mathcal{N}(0, \\sigma_R^2)| \\times |\\mathcal{N}(0, \\sigma_P^2)|$; with probability $0.1$, draw from $|\\mathcal{N}(0, \\sigma_{R,\\mathrm{hi}}^2)| \\times |\\mathcal{N}(0, \\sigma_{P,\\mathrm{hi}}^2)|$, where $\\sigma_{R,\\mathrm{hi}} = 0.002$, $\\sigma_{P,\\mathrm{hi}} = 0.0008$; sample size $N_{\\mathrm{val}} = 1000$; random seed $456$.\n\nTest Case $2$ (tight voltage headroom boundary):\n- Horizon length $T = 12$, step $\\Delta t = 5$.\n- Nominal open-circuit voltage sequence $U_{\\mathrm{nom},t} = 397 + 0.3 t$ for $t = 0, \\dots, 11$.\n- Voltage limit $V_{\\max} = 401$.\n- Current bound $I_{\\max} = 200$.\n- Nominal ohmic resistance $R_{\\mathrm{nom}} = 0.012$.\n- Nominal polarization coefficient $P_{\\mathrm{nom}} = 0.005$.\n- Training deviations: $\\delta_R^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_R^2)|$ with $\\sigma_R = 0.0012$, and $\\delta_P^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_P^2)|$ with $\\sigma_P = 0.0006$; sample size $N_{\\mathrm{train}} = 200$; random seed $789$.\n- Validation deviations mixture: with probability $0.85$, draw from the base $\\sigma_R, \\sigma_P$; with probability $0.15$, draw from $\\sigma_{R,\\mathrm{hi}} = 0.0024$, $\\sigma_{P,\\mathrm{hi}} = 0.001$; sample size $N_{\\mathrm{val}} = 1000$; random seed $2468$.\n\nTest Case $3$ (edge case small horizon):\n- Horizon length $T = 4$, step $\\Delta t = 5$.\n- Nominal open-circuit voltage sequence $U_{\\mathrm{nom},t} = 380 + 0.6 t$ for $t = 0, \\dots, 3$.\n- Voltage limit $V_{\\max} = 390$.\n- Current bound $I_{\\max} = 220$.\n- Nominal ohmic resistance $R_{\\mathrm{nom}} = 0.009$.\n- Nominal polarization coefficient $P_{\\mathrm{nom}} = 0.0035$.\n- Training deviations: $\\delta_R^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_R^2)|$ with $\\sigma_R = 0.0008$, and $\\delta_P^{\\mathrm{train}} = |\\mathcal{N}(0, \\sigma_P^2)|$ with $\\sigma_P = 0.0004$; sample size $N_{\\mathrm{train}} = 200$; random seed $1357$.\n- Validation deviations mixture: with probability $0.95$, draw from the base $\\sigma_R, \\sigma_P$; with probability $0.05$, draw from $\\sigma_{R,\\mathrm{hi}} = 0.0016$, $\\sigma_{P,\\mathrm{hi}} = 0.0007$; sample size $N_{\\mathrm{val}} = 1000$; random seed $97531$.\n\nAlgorithmic requirements:\n- For each test case, estimate $\\hat R$ and $\\hat P$ from training samples as empirical $0.95$-quantiles.\n- For each candidate $\\Gamma \\in \\{0.0, 0.5, 1.0, 1.5, 2.0\\}$, solve the robust Linear Program to find $I_t$ and $s_t$ maximizing $Q$ subject to robust constraints and bounds.\n- Using the validation scenarios, compute the violation rate of $V_t \\le V_{\\max}$ across $t$ for the obtained profile $(I_t, s_t)$, and compute $\\widetilde{Q} = Q \\cdot (1 - \\text{violation\\_rate})$.\n- Select the $\\Gamma$ that maximizes $\\widetilde{Q}$; if multiple $\\Gamma$ tie, choose the smallest.\n\nFinal output specification:\n- Your program should produce a single line of output containing the selected $\\Gamma$ values for the above three test cases as a comma-separated list enclosed in square brackets (e.g., $[0.0,1.0,1.5]$). The results must be floats.\n\nScientific bases and realism:\n- The voltage model uses Ohm's Law and a standard first-order polarization term, widely used in equivalent-circuit battery models.\n- The robust counterpart follows the well-tested budgeted uncertainty framework by Bertsimas and Sim, resulting in Linear Programming constraints suitable for algorithmic solution.\n- All parameters and magnitudes are chosen to be plausible for an automotive-scale battery pack, with voltages in the hundreds of volts and currents in the hundreds of amperes.",
            "solution": "The problem presented is a robust optimization task for designing a fast-charging current profile for a Lithium-ion battery pack. The problem is scientifically grounded, well-defined, and all necessary parameters and procedures are provided.\nThe core of the task is to determine the optimal value of a robustness budget parameter, $\\Gamma$, by balancing charging performance against the risk of violating voltage safety limits under parameter uncertainty. The problem is valid and can be solved algorithmically.\n\nThe procedure involves the following principal steps for each test case:\n1.  **Stochastic Data Generation**: Generate training and validation samples for the uncertain parameters based on the specified statistical distributions.\n2.  **Uncertainty Set Estimation**: Use the training data to define the uncertainty set for the robust optimization model by estimating the uncertainty radii $\\hat{R}$ and $\\hat{P}$.\n3.  **Iterative Robust Optimization**: For a set of candidate $\\Gamma$ values, solve a robust Linear Program (LP) to find the optimal charging current profile.\n4.  **Out-of-Sample Validation**: Evaluate the performance and robustness of each profile using the independent validation data set.\n5.  **Optimal Parameter Selection**: Choose the $\\Gamma$ value that maximizes a risk-adjusted performance metric.\n\nWe now detail the mathematical formulation and algorithmic procedure.\n\n**1. Model and Objective Function**\n\nThe terminal voltage $V_t$ at each discrete time step $t \\in \\{0, \\dots, T-1\\}$ is given by:\n$$\nV_t(I_t, s_t; R, P) = U_{\\mathrm{nom},t} + R I_t + P s_t\n$$\nwhere $U_{\\mathrm{nom},t}$ is the nominal open-circuit voltage, $I_t$ is the charging current, $s_t = |I_t - I_{t-1}|$ is the magnitude of the current change (with $I_{-1} = 0$), and $R$ and $P$ are the uncertain ohmic resistance and polarization coefficient, respectively.\n\nThe objective is to maximize the total charge delivered to the battery, $Q$, over the time horizon $T$:\n$$\n\\text{Maximize} \\quad Q = \\Delta t \\sum_{t=0}^{T-1} I_t\n$$\nwhere $\\Delta t$ is the duration of a time step.\n\n**2. Robust Optimization Formulation**\n\nThe parameters $R$ and $P$ are modeled as $R = R_{\\mathrm{nom}} + \\delta_R$ and $P = P_{\\mathrm{nom}} + \\delta_P$, with deviations $\\delta_R \\in [0, \\hat{R}]$ and $\\delta_P \\in [0, \\hat{P}]$. The radii $\\hat{R}$ and $\\hat{P}$ are determined as the empirical $0.95$-quantiles of training data drawn from specified distributions.\n\nThe voltage constraint $V_t \\le V_{\\max}$ must hold for all $t$ and for all admissible parameter deviations. Using the Bertsimas-Sim budgeted uncertainty approach with budget $\\Gamma \\in [0, 2]$, the worst-case realization of the uncertainty for each time step $t$ is formulated. This leads to the robust counterpart of the voltage constraint:\n$$\nU_{\\mathrm{nom},t} + R_{\\mathrm{nom}} I_t + P_{\\mathrm{nom}} s_t + \\underbrace{\\max_{\\substack{S \\subseteq \\{1, 2\\}, |S| \\le \\Gamma}} \\left\\{ \\sum_{i \\in S} \\text{dev}_i \\right\\}}_{\\text{Robustness Term}} \\le V_{\\max}\n$$\nwhere $\\text{dev}_1 = \\hat{R}I_t$ and $\\text{dev}_2 = \\hat{P}s_t$. The dual of this inner maximization problem yields a set of linear constraints. The complete optimization problem is formulated as a Linear Program (LP).\n\n**Decision Variables**:\nFor each time step $t \\in \\{0, \\dots, T-1\\}$, we define the following variables:\n- $I_t$: Charging current.\n- $s_t$: Magnitude of current change.\n- $z_t, p_{t,1}, p_{t,2}$: Auxiliary variables for the robust counterpart.\n\nThe full vector of decision variables is $\\mathbf{x} \\in \\mathbb{R}^{5T}$, structured as:\n$$\n\\mathbf{x} = [I_0, \\dots, I_{T-1}, s_0, \\dots, s_{T-1}, z_0, \\dots, z_{T-1}, p_{0,1}, \\dots, p_{T-1,1}, p_{0,2}, \\dots, p_{T-1,2}]^T\n$$\n\n**Linear Program Formulation**:\nThe problem is to solve:\n$$\n\\max_{\\mathbf{x}} \\quad \\mathbf{c}^T \\mathbf{x} \\quad \\text{subject to} \\quad \\mathbf{A}_{\\text{ub}} \\mathbf{x} \\le \\mathbf{b}_{\\text{ub}} \\quad \\text{and} \\quad \\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u}\n$$\nwhere the objective vector $\\mathbf{c}$ has entries $\\Delta t$ for each $I_t$ and $0$ otherwise. Since $\\Delta t$ is a positive constant, we can equivalently maximize $\\sum I_t$ and multiply the result by $\\Delta t$.\n\n**Constraints for each $t \\in \\{0, \\dots, T-1\\}$**:\n1.  **Robust Voltage Constraint**:\n    $$R_{\\mathrm{nom}} I_t + P_{\\mathrm{nom}} s_t + \\Gamma z_t + p_{t,1} + p_{t,2} \\le V_{\\max} - U_{\\mathrm{nom},t}$$\n2.  **Robust Counterpart Auxiliary Constraints**:\n    $$\\hat{R} I_t - z_t - p_{t,1} \\le 0$$\n    $$\\hat{P} s_t - z_t - p_{t,2} \\le 0$$\n3.  **Absolute Value Linearization**: The constraint $s_t \\ge |I_t - I_{t-1}|$ is linearized as:\n    $$I_t - I_{t-1} - s_t \\le 0$$\n    $$I_{t-1} - I_t - s_t \\le 0$$\n    (with the convention $I_{-1} = 0$).\n4.  **Variable Bounds**:\n    $$0 \\le I_t \\le I_{\\max}$$\n    $$s_t \\ge 0, \\quad z_t \\ge 0, \\quad p_{t,1} \\ge 0, \\quad p_{t,2} \\ge 0$$\n\n**3. Tuning the Budget Parameter $\\Gamma$**\n\nThe main task is to select the best $\\Gamma$ from the candidate set $\\{0.0, 0.5, 1.0, 1.5, 2.0\\}$. The selection is based on a risk-adjusted performance metric, $\\widetilde{Q}$, evaluated on out-of-sample validation data.\n\nFor each candidate $\\Gamma$:\n1.  The LP defined above is constructed and solved to find the optimal current profile $\\{I_t^*\\}_{t=0}^{T-1}$ and corresponding current changes $\\{s_t^*\\}_{t=0}^{T-1}$.\n2.  The total charge is calculated: $Q^* = \\Delta t \\sum_{t=0}^{T-1} I_t^*$.\n3.  The robustness of this profile is assessed using $N_{\\mathrm{val}}$ validation scenarios $(\\delta_{R,j}, \\delta_{P,j})$. For each scenario $j=1, \\dots, N_{\\mathrm{val}}$, a violation occurs if the voltage limit is breached at any time step:\n    $$\n    \\exists t \\in \\{0, \\dots, T-1\\} \\quad \\text{s.t.} \\quad U_{\\mathrm{nom},t} + (R_{\\mathrm{nom}} + \\delta_{R,j})I_t^* + (P_{\\mathrm{nom}} + \\delta_{P,j})s_t^*  V_{\\max}\n    $$\n4.  The violation rate, $v$, is the fraction of validation scenarios that result in a violation.\n5.  The risk-adjusted charge is computed: $\\widetilde{Q} = Q^* \\cdot (1 - v)$.\n\nThe optimal budget parameter, $\\Gamma_{\\text{opt}}$, is the one that maximizes $\\widetilde{Q}$. In case of a tie in $\\widetilde{Q}$ values, the smallest $\\Gamma$ is chosen.\n\n**4. Algorithmic Implementation**\n\nFor each test case, the algorithm proceeds as follows:\n1.  Set the random number generator seed for reproducibility. Generate $N_{\\mathrm{train}}=200$ samples of $(\\delta_R^{\\mathrm{train}}, \\delta_P^{\\mathrm{train}})$ from a folded normal distribution $|\\mathcal{N}(0, \\sigma^2)|$.\n2.  Compute $\\hat{R}$ and $\\hat{P}$ as the $0.95$-quantiles of the generated $\\delta_R^{\\mathrm{train}}$ and $\\delta_P^{\\mathrm{train}}$ samples, respectively.\n3.  Set a new seed and generate $N_{\\mathrm{val}}=1000$ validation samples $(\\delta_R^{\\mathrm{val}}, \\delta_P^{\\mathrm{val}})$ from the specified mixture distribution.\n4.  Initialize $\\Gamma_{\\text{opt}} = -1.0$ and $\\widetilde{Q}_{\\max} = -1.0$.\n5.  Iterate through each $\\Gamma \\in \\{0.0, 0.5, 1.0, 1.5, 2.0\\}$:\n    a. Construct the LP matrices $\\mathbf{c}$, $\\mathbf{A}_{\\text{ub}}$, $\\mathbf{b}_{\\text{ub}}$ and bounds $(\\mathbf{l}, \\mathbf{u})$ based on the problem parameters, the estimated $(\\hat{R}, \\hat{P})$, and the current $\\Gamma$.\n    b. Solve the LP using a standard solver (e.g., `scipy.optimize.linprog`) to obtain the optimal solution vector $\\mathbf{x}^*$.\n    c. Extract the optimal current profile $\\{I_t^*\\}$ and step changes $\\{s_t^*\\}$.\n    d. Calculate $Q^*$ and the violation rate $v$ using the validation data.\n    e. Compute $\\widetilde{Q} = Q^* \\cdot (1 - v)$.\n    f. If $\\widetilde{Q}  \\widetilde{Q}_{\\max}$, update $\\widetilde{Q}_{\\max} = \\widetilde{Q}$ and $\\Gamma_{\\text{opt}} = \\Gamma$. The tie-breaking rule (select smallest $\\Gamma$) is handled by the strict inequality.\n6.  The final result for the test case is $\\Gamma_{\\text{opt}}$. This entire procedure is repeated for all three test cases.\n\nThis systematic approach ensures that the chosen charging strategy is not only high-performing in terms of charge delivered but also robust to the anticipated variations in battery parameters, a critical consideration for safe and reliable operation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Main solver function that iterates through test cases and prints the final result.\n    \"\"\"\n    \n    test_cases = [\n        # Test Case 1 (happy path)\n        {\n            \"T\": 12, \"delta_t\": 5.0,\n            \"U_nom_func\": lambda t: 380.0 + 0.4 * t,\n            \"V_max\": 402.0, \"I_max\": 180.0,\n            \"R_nom\": 0.010, \"P_nom\": 0.004,\n            \"train_params\": {\"N\": 200, \"sigma_R\": 0.001, \"sigma_P\": 0.0005, \"seed\": 123},\n            \"val_params\": {\n                \"N\": 1000, \"seed\": 456, \"mix_prob\": 0.1,\n                \"base_sigma_R\": 0.001, \"base_sigma_P\": 0.0005,\n                \"hi_sigma_R\": 0.002, \"hi_sigma_P\": 0.0008,\n            }\n        },\n        # Test Case 2 (tight voltage headroom)\n        {\n            \"T\": 12, \"delta_t\": 5.0,\n            \"U_nom_func\": lambda t: 397.0 + 0.3 * t,\n            \"V_max\": 401.0, \"I_max\": 200.0,\n            \"R_nom\": 0.012, \"P_nom\": 0.005,\n            \"train_params\": {\"N\": 200, \"sigma_R\": 0.0012, \"sigma_P\": 0.0006, \"seed\": 789},\n            \"val_params\": {\n                \"N\": 1000, \"seed\": 2468, \"mix_prob\": 0.15,\n                \"base_sigma_R\": 0.0012, \"base_sigma_P\": 0.0006,\n                \"hi_sigma_R\": 0.0024, \"hi_sigma_P\": 0.001,\n            }\n        },\n        # Test Case 3 (edge case small horizon)\n        {\n            \"T\": 4, \"delta_t\": 5.0,\n            \"U_nom_func\": lambda t: 380.0 + 0.6 * t,\n            \"V_max\": 390.0, \"I_max\": 220.0,\n            \"R_nom\": 0.009, \"P_nom\": 0.0035,\n            \"train_params\": {\"N\": 200, \"sigma_R\": 0.0008, \"sigma_P\": 0.0004, \"seed\": 1357},\n            \"val_params\": {\n                \"N\": 1000, \"seed\": 97531, \"mix_prob\": 0.05,\n                \"base_sigma_R\": 0.0008, \"base_sigma_P\": 0.0004,\n                \"hi_sigma_R\": 0.0016, \"hi_sigma_P\": 0.0007,\n            }\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        best_gamma = run_test_case(params)\n        results.append(best_gamma)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_test_case(params):\n    \"\"\"\n    Executes the full robust tuning procedure for a single test case.\n    \"\"\"\n    T = params[\"T\"]\n    delta_t = params[\"delta_t\"]\n    U_nom = np.array([params[\"U_nom_func\"](t) for t in range(T)])\n    V_max = params[\"V_max\"]\n    I_max = params[\"I_max\"]\n    R_nom = params[\"R_nom\"]\n    P_nom = params[\"P_nom\"]\n    \n    gamma_candidates = [0.0, 0.5, 1.0, 1.5, 2.0]\n\n    # --- Step 1: Data Generation ---\n    # Training data\n    train_p = params[\"train_params\"]\n    rng_train = np.random.default_rng(train_p[\"seed\"])\n    delta_R_train = np.abs(rng_train.normal(0, train_p[\"sigma_R\"], train_p[\"N\"]))\n    delta_P_train = np.abs(rng_train.normal(0, train_p[\"sigma_P\"], train_p[\"N\"]))\n\n    # Validation data\n    val_p = params[\"val_params\"]\n    rng_val = np.random.default_rng(val_p[\"seed\"])\n    N_val = val_p[\"N\"]\n    \n    N_hi = int(N_val * val_p[\"mix_prob\"])\n    N_base = N_val - N_hi\n    \n    delta_R_val_base = np.abs(rng_val.normal(0, val_p[\"base_sigma_R\"], N_base))\n    delta_P_val_base = np.abs(rng_val.normal(0, val_p[\"base_sigma_P\"], N_base))\n\n    delta_R_val_hi = np.abs(rng_val.normal(0, val_p[\"hi_sigma_R\"], N_hi))\n    delta_P_val_hi = np.abs(rng_val.normal(0, val_p[\"hi_sigma_P\"], N_hi))\n\n    delta_R_val = np.concatenate((delta_R_val_base, delta_R_val_hi))\n    delta_P_val = np.concatenate((delta_P_val_base, delta_P_val_hi))\n    val_scenarios = np.stack((delta_R_val, delta_P_val), axis=1) # Shape (N_val, 2)\n    rng_val.shuffle(val_scenarios) # Shuffle to mix the groups\n\n    # --- Step 2: Uncertainty Radii Estimation ---\n    R_hat = np.quantile(delta_R_train, 0.95)\n    P_hat = np.quantile(delta_P_train, 0.95)\n\n    best_gamma = -1.0\n    max_q_tilde = -1.0\n\n    # --- Step 3  4  5: Tuning Loop ---\n    for gamma in gamma_candidates:\n        # --- Construct and Solve the LP ---\n        # Variable vector x = [I_0..I_T-1, s_0..s_T-1, z_0..z_T-1, p1_0..p1_T-1, p2_0..p2_T-1]\n        # Total variables: 5 * T\n        I_offset, s_offset, z_offset, p1_offset, p2_offset = 0, T, 2 * T, 3 * T, 4 * T\n\n        # Objective: Maximize sum(I_t), so minimize -sum(I_t)\n        c = np.zeros(5 * T)\n        c[I_offset : I_offset + T] = -1.0\n\n        num_constraints = 5 * T\n        A_ub = np.zeros((num_constraints, 5 * T))\n        b_ub = np.zeros(num_constraints)\n        \n        row_idx = 0\n        for t in range(T):\n            # Robust voltage constraint\n            A_ub[row_idx, I_offset + t] = R_nom\n            A_ub[row_idx, s_offset + t] = P_nom\n            A_ub[row_idx, z_offset + t] = gamma\n            A_ub[row_idx, p1_offset + t] = 1.0\n            A_ub[row_idx, p2_offset + t] = 1.0\n            b_ub[row_idx] = V_max - U_nom[t]\n            row_idx += 1\n        \n        for t in range(T):\n            # Robust counterpart constraint 1\n            A_ub[row_idx, I_offset + t] = R_hat\n            A_ub[row_idx, z_offset + t] = -1.0\n            A_ub[row_idx, p1_offset + t] = -1.0\n            b_ub[row_idx] = 0.0\n            row_idx += 1\n            \n        for t in range(T):\n            # Robust counterpart constraint 2\n            A_ub[row_idx, s_offset + t] = P_hat\n            A_ub[row_idx, z_offset + t] = -1.0\n            A_ub[row_idx, p2_offset + t] = -1.0\n            b_ub[row_idx] = 0.0\n            row_idx += 1\n\n        for t in range(T):\n            # Absolute value s_t = I_t - I_{t-1}\n            A_ub[row_idx, I_offset + t] = 1.0\n            if t  0:\n                A_ub[row_idx, I_offset + t - 1] = -1.0\n            A_ub[row_idx, s_offset + t] = -1.0\n            b_ub[row_idx] = 0.0\n            row_idx += 1\n\n        for t in range(T):\n            # Absolute value s_t = I_{t-1} - I_t\n            A_ub[row_idx, I_offset + t] = -1.0\n            if t  0:\n                A_ub[row_idx, I_offset + t - 1] = 1.0\n            A_ub[row_idx, s_offset + t] = -1.0\n            b_ub[row_idx] = 0.0\n            row_idx += 1\n            \n        # Bounds on variables\n        bounds = [(0, I_max)] * T + [(0, None)] * (4 * T)\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n\n        if not res.success:\n            # If LP fails, this gamma is non-viable. Assign worst performance.\n            q_tilde = -1.0\n        else:\n            I_opt = res.x[I_offset : I_offset + T]\n            s_opt = res.x[s_offset : s_offset + T]\n            \n            Q = delta_t * np.sum(I_opt)\n\n            # Evaluate violation rate\n            violation_count = 0\n            for delta_R, delta_P in val_scenarios:\n                R_val = R_nom + delta_R\n                P_val = P_nom + delta_P\n                \n                V_val = U_nom + R_val * I_opt + P_val * s_opt\n                \n                if np.any(V_val  V_max):\n                    violation_count += 1\n            \n            violation_rate = violation_count / N_val\n            q_tilde = Q * (1 - violation_rate)\n        \n        # Update best gamma\n        if q_tilde  max_q_tilde:\n            max_q_tilde = q_tilde\n            best_gamma = gamma\n            \n    return best_gamma\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}