{
    "hands_on_practices": [
        {
            "introduction": "The power of Particle Swarm Optimization lies in the delicate balance between a particle's tendency to trust its own experience (the cognitive component) and its inclination to follow the swarm's success (the social component). This exercise is a thought experiment that explores the extreme consequences of disabling one of these behaviors. By analyzing the PSO update rule when either the cognitive coefficient $c_1$ or the social coefficient $c_2$ is set to zero, you will gain a deeper understanding of the risks of premature convergence and stagnation, which is crucial for effective parameter tuning .",
            "id": "3938439",
            "problem": "A battery design team uses Particle Swarm Optimization (PSO) to tune two continuous design variables: electrode porosity $\\phi$ and separator thickness $L_{\\mathrm{sep}}$. The admissible ranges are $\\phi \\in [0.30,\\,0.60]$ and $L_{\\mathrm{sep}} \\in [10\\times 10^{-6}\\,\\mathrm{m},\\,40\\times 10^{-6}\\,\\mathrm{m}]$. The objective function $J(\\phi, L_{\\mathrm{sep}})$ encodes trade-offs between energy density and power capability subject to transport and safety constraints. For instance, effective ionic conductivity follows a Bruggeman-type scaling $\\sigma_{\\mathrm{eff}} = \\sigma_{\\mathrm{bulk}} \\,\\phi^{\\beta}$ with $\\beta \\approx 1.5$, while excessive $L_{\\mathrm{sep}}$ raises internal resistance but aids safety; thus, $J(\\phi,L_{\\mathrm{sep}})$ is multi-modal in realistic regimes.\n\nThe PSO state of particle $i$ at iteration $k$ is $x_i(k) = [\\phi_i(k),\\,L_{\\mathrm{sep},i}(k)]^{\\top}$ with velocity $v_i(k)$. The standard PSO updates are\n$$\nv_i(k+1) \\;=\\; w\\,v_i(k) + c_1\\,r_{1,i}(k)\\,\\big(p_i - x_i(k)\\big) + c_2\\,r_{2,i}(k)\\,\\big(g - x_i(k)\\big),\n$$\n$$\nx_i(k+1) \\;=\\; x_i(k) + v_i(k),\n$$\nwhere $w \\in (0,1)$ is the inertia weight, $c_1>0$ and $c_2>0$ are the cognitive and social acceleration coefficients, $r_{1,i}(k), r_{2,i}(k) \\sim \\mathrm{Uniform}(0,1)$ are independent scalar random variables applied componentwise, $p_i$ is particle $i$’s personal best position, and $g$ is the current global best position. Assume a quasi-static attractor regime over a short window of iterations in which $p_i$ and $g$ do not move appreciably across the window. Define swarm diversity at iteration $k$ as the sample covariance matrix of $\\{x_i(k)\\}_{i=1}^N$; equivalently, diversity decays if inter-particle variance in both $\\phi$ and $L_{\\mathrm{sep}}$ decreases across iterations.\n\nConsider two extreme tunings: setting $c_1=0$ (social-only) or setting $c_2=0$ (cognitive-only). Under the above assumptions and with $w \\in (0,1)$, evaluate the consequences for the expected evolution of swarm diversity in $(\\phi,L_{\\mathrm{sep}})$ and the risk of premature convergence versus stagnation. Which statements are correct?\n\nA. With $c_1=0$ and $c_2>0$, the expected spectral radius of the linearized map about $g$ is less than $1$ for typical $w \\in (0,1)$, implying geometric decay of inter-particle variance in $(\\phi,L_{\\mathrm{sep}})$ toward zero; this accelerates consensus around the current global best and increases the risk of premature convergence.\n\nB. With $c_2=0$ and $c_1>0$, each particle converges toward its own personal best $p_i$, so the asymptotic inter-particle variance in $(\\phi,L_{\\mathrm{sep}})$ equals the variance of the set $\\{p_i\\}$; swarm diversity is maintained unless the $\\{p_i\\}$ themselves coalesce.\n\nC. With $c_1=0$, diversity increases because inertial motion dominates, causing particles to spread out and sample more of $(\\phi,L_{\\mathrm{sep}})$.\n\nD. With $c_2=0$, the dynamics are linearly unstable for typical $w \\in (0,1)$ and $c_1>0$, leading to unbounded dispersion in $(\\phi,L_{\\mathrm{sep}})$.\n\nE. Setting either $c_1=0$ or $c_2=0$ guarantees faster attainment of the true global optimum in multi-modal battery design landscapes.",
            "solution": "The problem statement is scientifically and mathematically sound, well-posed, and objective. It presents a standard analysis task for a known metaheuristic, Particle Swarm Optimization (PSO), applied to a realistic engineering context. The assumptions, such as the quasi-static nature of personal and global bests for analysis, are standard simplifying techniques in the study of PSO dynamics. The PSO update equations, while using a slightly less common form for the position update, are clearly defined and mathematically tractable. Therefore, a full analysis is warranted.\n\nThe problem requires an analysis of the PSO dynamics under two specific parameterizations: a \"social-only\" model where the cognitive coefficient $c_1=0$, and a \"cognitive-only\" model where the social coefficient $c_2=0$. The analysis will focus on the evolution of swarm diversity, defined by the inter-particle variance.\n\nThe state of a particle $i$ at iteration $k$ can be described by a vector containing its position $x_i(k)$ and velocity $v_i(k)$. The dynamics are given by:\n$$\nv_i(k+1) \\;=\\; w\\,v_i(k) + c_1\\,r_{1,i}(k)\\,\\big(p_i - x_i(k)\\big) + c_2\\,r_{2,i}(k)\\,\\big(g - x_i(k)\\big)\n$$\n$$\nx_i(k+1) \\;=\\; x_i(k) + v_i(k)\n$$\nWe analyze the system by linearizing it around its attractors, assuming $p_i$ and $g$ are constant, as per the problem statement. The analysis can be performed for a single dimension without loss of generality, as the update equations for the design variables $\\phi$ and $L_{\\mathrm{sep}}$ are uncoupled.\n\nLet's define a state vector for a single particle's component, say $x$, as $z(k) = [x(k), v(k)]^{\\top}$. The update equations can be written in state-space form.\n$$\n\\begin{pmatrix} x_i(k+1) \\\\ v_i(k+1) \\end{pmatrix} =\n\\begin{pmatrix} 1 & 1 \\\\ -(c_1 r_{1,i} + c_2 r_{2,i}) & w \\end{pmatrix}\n\\begin{pmatrix} x_i(k) \\\\ v_i(k) \\end{pmatrix} +\n\\begin{pmatrix} 0 \\\\ c_1 r_{1,i} p_i + c_2 r_{2,i} g \\end{pmatrix}\n$$\nTo study stability and convergence, we analyze the homogeneous part of this system, which describes the evolution of deviations from a fixed point. The behavior of the swarm is often studied by analyzing the expected dynamics, where the random variables $r_{1,i}$ and $r_{2,i}$ are replaced by their expectation, $E[r] = 0.5$.\n\n**Case 1: Social-Only Model ($c_1=0$, $c_2>0$)**\n\nThe update equations simplify to:\n$$\nv_i(k+1) = w\\,v_i(k) + c_2\\,r_{2,i}(k)\\,(g - x_i(k))\n$$\n$$\nx_i(k+1) = x_i(k) + v_i(k)\n$$\nIn this case, all particles are attracted to a single point: the global best position $g$. To analyze convergence, we consider the deviation of a particle from the attractor $(g, 0)$, i.e., $\\delta x_i(k) = x_i(k) - g$ and $\\delta v_i(k) = v_i(k)$. The dynamics of this deviation are:\n$$\n\\begin{pmatrix} \\delta x_i(k+1) \\\\ \\delta v_i(k+1) \\end{pmatrix} =\n\\begin{pmatrix} 1 & 1 \\\\ -c_2 r_{2,i}(k) & w \\end{pmatrix}\n\\begin{pmatrix} \\delta x_i(k) \\\\ \\delta v_i(k) \\end{pmatrix}\n$$\nThe expected dynamics are governed by the matrix $M_{\\mathrm{exp}} = \\begin{pmatrix} 1 & 1 \\\\ -0.5 c_2 & w \\end{pmatrix}$. The system is stable if the eigenvalues of this matrix have a magnitude less than $1$ (i.e., its spectral radius $\\rho(M_{\\mathrm{exp}}) < 1$). The characteristic polynomial is $\\lambda^2 - (1+w)\\lambda + (w+0.5c_2) = 0$. For stability, the Jury conditions must be met. A key condition is that $w+0.5c_2 < 1$. The problem's phrasing \"for typical $w \\in (0,1)$\" implies that we assume parameter values that ensure stability, as unstable parameters lead to a divergent, useless algorithm.\n\nUnder this stability assumption, $\\delta x_i(k) \\to 0$ and $\\delta v_i(k) \\to 0$ as $k \\to \\infty$. This means that for every particle $i$, its position $x_i(k)$ converges to the global best position $g$. Since all particles converge to the same point, the inter-particle variance must geometrically decay to zero. The swarm reaches a consensus. This rapid loss of diversity means that if the current global best $g$ is a local optimum and not the true global optimum, the swarm will get trapped. This phenomenon is known as premature convergence.\n\n**Case 2: Cognitive-Only Model ($c_2=0$, $c_1>0$)**\n\nThe update equations simplify to:\n$$\nv_i(k+1) = w\\,v_i(k) + c_1\\,r_{1,i}(k)\\,(p_i - x_i(k))\n$$\n$$\nx_i(k+1) = x_i(k) + v_i(k)\n$$\nIn this scenario, social interaction is eliminated. Each particle $i$ is attracted only to its own personal best position $p_i$. The dynamics of the particles are decoupled from one another. The analysis for each particle $i$ is analogous to Case 1, but the attractor is now $(p_i, 0)$. The expected dynamics matrix for the deviation from $p_i$ is $M_{i, \\mathrm{exp}} = \\begin{pmatrix} 1 & 1 \\\\ -0.5 c_1 & w \\end{pmatrix}$.\n\nAssuming \"typical\" parameters for which the dynamics are stable (e.g., $w+0.5c_1 < 1$), each particle's position $x_i(k)$ converges to its own personal best $p_i$. Since different particles generally have different personal bests (found during their individual search history), the particles will converge to different points in the search space.\nAsymptotically, the set of particle positions $\\{x_i\\}$ will become the set of personal bests $\\{p_i\\}$. Therefore, the swarm diversity, measured by the inter-particle variance, does not collapse to zero. Instead, it converges to the variance of the set $\\{p_i\\}$. Diversity is maintained, but the lack of information sharing prevents the swarm from collectively moving towards a single, superior solution. This state is often described as stagnation.\n\nNow we evaluate each option:\n\n**A. With $c_1=0$ and $c_2>0$, the expected spectral radius of the linearized map about $g$ is less than $1$ for typical $w \\in (0,1)$, implying geometric decay of inter-particle variance in $(\\phi,L_{\\mathrm{sep}})$ toward zero; this accelerates consensus around the current global best and increases the risk of premature convergence.**\n\nThis statement accurately describes the social-only model (Case 1). The assumption that the spectral radius is less than $1$ for \"typical\" parameters is a reasonable interpretation for a functional algorithm. This stability directly implies convergence of all particles to the single attractor $g$, causing the geometric decay of inter-particle variance (loss of diversity). This consensus around a potentially suboptimal $g$ is the definition of premature convergence.\n**Verdict: Correct.**\n\n**B. With $c_2=0$ and $c_1>0$, each particle converges toward its own personal best $p_i$, so the asymptotic inter-particle variance in $(\\phi,L_{\\mathrm{sep}})$ equals the variance of the set $\\{p_i\\}$; swarm diversity is maintained unless the $\\{p_i\\}$ themselves coalesce.**\n\nThis statement accurately describes the cognitive-only model (Case 2). Under stable dynamics, each particle indeed converges to its personal best $p_i$. Consequently, the final swarm configuration mirrors the distribution of the $\\{p_i\\}$, and the swarm's diversity is determined by the diversity of these personal best positions. This maintains diversity at the cost of collective problem-solving, which can lead to stagnation.\n**Verdict: Correct.**\n\n**C. With $c_1=0$, diversity increases because inertial motion dominates, causing particles to spread out and sample more of $(\\phi,L_{\\mathrm{sep}})$.**\n\nThis is incorrect. With $c_1=0$ and $c_2>0$, the social term provides a strong attraction towards a single point $g$. For stable parameters ($w \\in (0,1)$), this attractive force leads to convergence and a decrease in diversity. Inertial motion does not dominate; it is balanced by the social attraction. Diversity would only increase if the system were unstable, which is not the \"typical\" case for a working algorithm.\n**Verdict: Incorrect.**\n\n**D. With $c_2=0$, the dynamics are linearly unstable for typical $w \\in (0,1)$ and $c_1>0$, leading to unbounded dispersion in $(\\phi,L_{\\mathrm{sep}})$.**\n\nThis is incorrect. The cognitive-only model is not inherently unstable. Similar to the social-only model, its stability depends on the choice of parameters $w$ and $c_1$. For \"typical\" (i.e., well-chosen, stable) parameters, each particle converges to a finite position $p_i$. This leads to a stable swarm configuration, not unbounded dispersion.\n**Verdict: Incorrect.**\n\n**E. Setting either $c_1=0$ or $c_2=0$ guarantees faster attainment of the true global optimum in multi-modal battery design landscapes.**\n\nThis is incorrect. The balance between cognitive exploration ($c_1$) and social exploitation ($c_2$) is crucial for the effectiveness of PSO, especially on complex, multi-modal landscapes. Setting $c_1=0$ leads to premature convergence, trapping the swarm in local optima. Setting $c_2=0$ leads to stagnation, as particles fail to share information and search cooperatively. Neither extreme is guaranteed—or even likely—to improve performance. In fact, both severely cripple the algorithm's search capability.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{AB}$$"
        },
        {
            "introduction": "In any real-world engineering problem like battery design, variables such as electrode porosity or thickness have strict physical and manufacturing limits. A key practical challenge is ensuring the PSO swarm respects these boundaries without introducing algorithmic biases. This practice moves from theory to application by having you develop a principled method for velocity clamping, a technique to prevent particles from 'flying off' the valid search space and congregating at the edges . You will derive the maximum allowable velocity based on geometric reasoning, providing a powerful tool for robust implementation.",
            "id": "3938424",
            "problem": "An automated lithium-ion battery design process seeks to jointly optimize the cathode microstructure through two design variables: the electrode thickness and the porosity. For numerical stability and unit consistency, both design variables are affinely normalized to the unit interval, so the swarm operates in the normalized domain $\\Omega = [0,1]^2$. The search is performed using Particle Swarm Optimization (PSO), where each particle’s position $\\boldsymbol{x}_t \\in \\Omega$ is updated by $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$ and the velocity obeys the canonical update rule with inertia weight and stochastic acceleration terms. When a position update leaves $\\Omega$, the particle is projected back onto the nearest boundary of $\\Omega$.\n\nProjection causes boundary bias by truncating out-of-bounds moves, which increases the time particles spend on or near $\\partial \\Omega$. As an alternative to using a constriction factor to reduce velocity magnitude indirectly, consider employing velocity clamping: impose a per-component bound $|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$ for $i \\in \\{1,2\\}$ in the normalized space, where $v_{\\text{max}}$ is a scalar applied to both dimensions.\n\nStarting from the core definitions of PSO kinematics and the geometric measure of subsets in $\\Omega$, justify why velocity clamping can suppress boundary bias in bounded normalized design domains by directly controlling the set of positions from which a single-step boundary interaction is possible. Then, under the assumption that the particle positions are approximately uniformly distributed in $\\Omega$ at the moment of an update, define a target upper bound $\\alpha \\in (0,1)$ on the fraction of particles that can interact with the boundary (i.e., start within one clamped step of $\\partial \\Omega$) during a single iteration. Using only this geometric reasoning in the normalized domain, derive the maximal safe clamping value $v_{\\text{max}}(\\alpha)$ that ensures the boundary-interaction fraction does not exceed $\\alpha$.\n\nExpress your final answer as a single closed-form analytic expression for $v_{\\text{max}}$ in terms of $\\alpha$, in normalized units. No numerical evaluation is required.",
            "solution": "The problem asks for a justification of velocity clamping as a method to reduce boundary bias in Particle Swarm Optimization (PSO) and for the derivation of a maximal velocity clamp value, $v_{\\text{max}}$, as a function of a desired boundary-interaction fraction, $\\alpha$.\n\nFirst, we validate the problem statement.\nThe problem is set within the standard framework of swarm intelligence and numerical optimization. All provided elements are well-defined and consistent:\n- The optimization domain is a normalized unit square, $\\Omega = [0,1]^2$.\n- The PSO kinematics, $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$, are canonical.\n- The boundary handling method (projection) and its associated problem (boundary bias) are known phenomena in PSO literature.\n- The proposed mitigation strategy, velocity clamping ($|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$), is a standard technique.\n- The request to derive $v_{\\text{max}}(\\alpha)$ is based on a clear geometric interpretation and a simplifying but formalizable assumption (uniform particle distribution).\nThe problem is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It does not violate any of the invalidity criteria. Therefore, the problem is deemed valid and a solution will be constructed.\n\n**Part 1: Justification for Velocity Clamping**\n\nA particle at position $\\boldsymbol{x}_t = (x_t^{(1)}, x_t^{(2)})$ in the domain $\\Omega = [0,1]^2$ can interact with the boundary during the update to step $t+1$ only if its new position, $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$, lies outside of $\\Omega$. This means at least one component of $\\boldsymbol{x}_{t+1}$ must be less than $0$ or greater than $1$.\n\nWithout velocity clamping, the components of the velocity vector $\\boldsymbol{v}_{t+1}$ can be arbitrarily large. This implies that a particle located anywhere in $\\Omega$, even at the center $(\\frac{1}{2}, \\frac{1}{2})$, could potentially generate a velocity large enough to move it outside the domain in a single step, thus triggering the projection mechanism. This frequent projection from a wide range of starting positions leads to an accumulation of particles at the boundaries, a phenomenon known as boundary bias.\n\nVelocity clamping introduces a hard limit, $v_{\\text{max}}$, on the magnitude of each velocity component: $|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$ for $i \\in \\{1,2\\}$. This directly constrains the maximum distance a particle can travel in any single dimension during one time step.\n\nLet's analyze the condition for a particle to cross a boundary. For the first component $x^{(1)}$, an out-of-bounds move occurs if $x_{t+1}^{(1)} < 0$ or $x_{t+1}^{(1)} > 1$.\nSubstituting the update rule, this is $x_t^{(1)} + v_{t+1}^{(1)} < 0$ or $x_t^{(1)} + v_{t+1}^{(1)} > 1$.\n\nWith the velocity clamp, the minimum value for $v_{t+1}^{(1)}$ is $-v_{\\text{max}}$ and the maximum is $+v_{\\text{max}}$.\n- To cross the lower boundary ($x_{t+1}^{(1)} < 0$), a particle must have $x_t^{(1)} + v_{t+1}^{(1)} < 0$. This is only possible if $x_t^{(1)}$ is small enough to be overcome by a negative velocity. The most extreme case is $x_t^{(1)} - v_{\\text{max}} < 0$, which implies $x_t^{(1)} < v_{\\text{max}}$.\n- To cross the upper boundary ($x_{t+1}^{(1)} > 1$), a particle must have $x_t^{(1)} + v_{t+1}^{(1)} > 1$. This is only possible if $x_t^{(1)}$ is large enough. The most extreme case is $x_t^{(1)} + v_{\\text{max}} > 1$, which implies $x_t^{(1)} > 1 - v_{\\text{max}}$.\n\nTherefore, a particle can only interact with the boundaries at $x^{(1)}=0$ or $x^{(1)}=1$ if its position $x_t^{(1)}$ is within the set $[0, v_{\\text{max}}) \\cup (1-v_{\\text{max}}, 1]$. A particle with $x_t^{(1)} \\in [v_{\\text{max}}, 1-v_{\\text{max}}]$ is guaranteed not to cross these specific boundaries in the next step.\n\nBy imposing velocity clamping, we define a \"safe\" sub-region within $\\Omega$ from which a boundary interaction is impossible in a single step. The effect of boundary bias is thus suppressed because the set of particles that are susceptible to projection is explicitly confined to a well-defined \"boundary interaction zone.\" This directly addresses the problem of uncontrolled boundary interactions by limiting the kinematic reach of each particle.\n\n**Part 2: Derivation of $v_{\\text{max}}(\\alpha)$**\n\nThe problem asks for the maximal clamping value $v_{\\text{max}}$ such that the fraction of particles that can interact with the boundary does not exceed a target upper bound $\\alpha$. We are to assume that particle positions are approximately uniformly distributed in the normalized domain $\\Omega = [0,1]^2$.\n\nUnder the uniform distribution assumption, the fraction of particles in any subset of $\\Omega$ is equal to the area of that subset, since the total area of $\\Omega$ is $1^2=1$. The goal is thus to find the area of the boundary-interaction zone, set it equal to $\\alpha$, and solve for $v_{\\text{max}}$.\n\nA particle at position $\\boldsymbol{x} = (x^{(1)}, x^{(2)})$ can interact with the boundary if its position satisfies any of the following conditions, as derived in Part 1:\n- $x^{(1)} < v_{\\text{max}}$\n- $x^{(1)} > 1 - v_{\\text{max}}$\n- $x^{(2)} < v_{\\text{max}}$\n- $x^{(2)} > 1 - v_{\\text{max}}$\n\nThis set of points forms a \"frame\" around the perimeter of the unit square $\\Omega$. It is more convenient to calculate the area of its complement, the \"safe zone\" $S$, and subtract this from the total area. The safe zone $S$ is the region where a particle *cannot* interact with the boundary. A particle is in $S$ if its position satisfies all of the following conditions:\n- $v_{\\text{max}} \\leq x^{(1)} \\leq 1 - v_{\\text{max}}$\n- $v_{\\text{max}} \\leq x^{(2)} \\leq 1 - v_{\\text{max}}$\n\nThis geometrically defines a square centered within $\\Omega$. The side length of this inner square is $(1 - v_{\\text{max}}) - v_{\\text{max}} = 1 - 2v_{\\text{max}}$. For this to be a valid, non-degenerate square, we must have $1 - 2v_{\\text{max}} > 0$, or $v_{\\text{max}} < \\frac{1}{2}$. Given that $\\alpha \\in (0,1)$, the resulting $v_{\\text{max}}$ will satisfy this.\n\nThe area of the safe zone, $A_S$, is the square of its side length:\n$$A_S = (1 - 2v_{\\text{max}})^2$$\n\nThe area of the boundary-interaction zone, $A_Z$, is the total area of $\\Omega$ minus the area of the safe zone:\n$$A_Z = A_{\\Omega} - A_S = 1 - (1 - 2v_{\\text{max}})^2$$\n\nThe problem requires that this fraction of particles (and thus this area) be no more than $\\alpha$. To find the maximal safe clamping value $v_{\\text{max}}$, we set this area equal to $\\alpha$:\n$$1 - (1 - 2v_{\\text{max}})^2 = \\alpha$$\n\nWe now solve this equation for $v_{\\text{max}}$:\n$$(1 - 2v_{\\text{max}})^2 = 1 - \\alpha$$\n\nTaking the square root of both sides, we select the positive root because the side length $1 - 2v_{\\text{max}}$ must be positive:\n$$1 - 2v_{\\text{max}} = \\sqrt{1 - \\alpha}$$\nThe condition $\\alpha \\in (0,1)$ ensures that $1 - \\alpha > 0$, so the square root is well-defined and real.\n\nRearranging the terms to isolate $v_{\\text{max}}$:\n$$2v_{\\text{max}} = 1 - \\sqrt{1 - \\alpha}$$\n$$v_{\\text{max}}(\\alpha) = \\frac{1 - \\sqrt{1 - \\alpha}}{2}$$\nThis expression can also be written as $\\frac{1}{2}(1 - \\sqrt{1 - \\alpha})$. This is the final closed-form expression for the maximal safe clamping value as a function of the desired boundary-interaction fraction $\\alpha$.",
            "answer": "$$\\boxed{\\frac{1}{2}\\left(1 - \\sqrt{1 - \\alpha}\\right)}$$"
        },
        {
            "introduction": "A 'one-size-fits-all' set of parameters is rarely optimal for the entire duration of a complex optimization run. The most sophisticated PSO algorithms can adapt their strategy in real-time, shifting from broad exploration to focused exploitation as the search progresses. In this final practice, you will design and implement an adaptive PSO by deriving a mechanism to automatically adjust the inertia weight $w_t$ based on the swarm's measured rate of progress . This hands-on task bridges the gap between a standard PSO and a more intelligent, self-tuning optimizer.",
            "id": "3938452",
            "problem": "You are tasked with deriving and implementing an adaptive Particle Swarm Optimization (PSO) procedure for automated battery design. The adaptation must be based on an online estimation of progress using moving averages of fitness improvement. The core requirement is to derive, from first principles, a progress estimator and a principled mapping to adjust the inertia weight in order to avoid stagnation. Then implement the full algorithm to solve a dimensionless surrogate battery design problem.\n\nThe surrogate battery design problem is defined on a four-dimensional continuous decision vector $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$, where $f_{\\mathrm{c}}$ is the cathode active-material volume fraction, $f_{\\mathrm{a}}$ is the anode active-material volume fraction, $\\phi$ is the electrolyte porosity, and $\\tau$ is a dimensionless separator thickness scaling. The bounds are:\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\nThe composite dimensionless cost to be minimized is defined as\n$$\nF(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi),\n$$\nwith non-negative Gaussian evaluation noise optionally added as $n \\sim \\mathcal{N}(0,\\sigma^2)$ for robustness testing, yielding the evaluated cost\n$$\n\\tilde{F}(x) = F(x;k_E,k_R) + n.\n$$\n\nYour derivation must begin from the canonical PSO update rules (a well-tested base):\n- Position update: $x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$\n- Velocity update: $v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$\nwhere $i$ indexes particles, $t$ is the iteration, $w_t$ is the inertia weight at time $t$, $c_1$ and $c_2$ are acceleration coefficients, $r_1(t)$ and $r_2(t)$ are independent uniform random variables on $[0,1]$, $p_i(t)$ is the best-known position of particle $i$, and $g(t)$ is the global best position.\n\nFrom this base, you must:\n- Define an online progress signal using the non-negative improvement of the global best cost $\\Delta_t = \\max\\{0,\\, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$.\n- Construct short-term and long-term moving averages of $\\Delta_t$ using either the Simple Moving Average (SMA) or Exponential Moving Average (EMA), ensuring that your estimator is causal and numerically stable. Denote these as $S_t$ and $L_t$, respectively, with $S_t$ emphasizing recent progress and $L_t$ capturing trend-level progress.\n- Derive a dimensionless progress ratio $R_t$ from $S_t$ and $L_t$ that is sensitive to stagnation versus continued improvement.\n- From this progress estimator, derive a monotone mapping $w_t = \\mathcal{W}(R_t)$ that increases $w_t$ when $R_t$ indicates stagnation (to encourage exploration) and decreases $w_t$ when $R_t$ indicates strong progress (to encourage exploitation). Enforce $w_t \\in [w_{\\min}, w_{\\max}]$ with fixed $w_{\\min}$ and $w_{\\max}$ chosen to preserve stability.\n\nYour program must implement the full PSO algorithm with the derived $w_t$ law, apply it to the surrogate battery design problem, and report results for a defined test suite. You must use $c_1 = 1.4$ and $c_2 = 1.4$. Particle positions must be clipped to the bounds after each position update. The personal bests $p_i(t)$ and global best $g(t)$ must be updated with strict improvement only.\n\nTest Suite:\nProvide results for the following four test cases, each specified by particle count $N$, iteration count $T$, short-term and long-term EMA coefficients $\\alpha_s$ and $\\alpha_\\ell$, inertia bounds $w_{\\min}$ and $w_{\\max}$, progress-to-inertia mapping parameters $\\kappa$ and $r_0$, noise standard deviation $\\sigma$, surrogate parameters $k_E$ and $k_R$, pseudo-random seed $\\text{seed}$, and whether all particles start from the same midpoint position $\\text{init\\_same}$:\n\n- Case $1$: $N=30$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.90$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.01$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=42$, $\\text{init\\_same}=\\text{False}$.\n- Case $2$: $N=20$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.02$, $w_{\\min}=0.40$, $w_{\\max}=0.95$, $\\kappa=5.0$, $r_0=1.2$, $\\sigma=0.00$, $k_E=0.50$, $k_R=0.35$, $\\text{seed}=123$, $\\text{init\\_same}=\\text{False}$.\n- Case $3$: $N=10$, $T=80$, $\\alpha_s=0.25$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.00$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=7$, $\\text{init\\_same}=\\text{True}$.\n- Case $4$: $N=40$, $T=150$, $\\alpha_s=0.15$, $\\alpha_\\ell=0.03$, $w_{\\min}=0.35$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=0.8$, $\\sigma=0.05$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=2024$, $\\text{init\\_same}=\\text{False}$.\n\nOutput specification:\n- For each test case, run your adaptive PSO and record the final best cost value $\\tilde{F}(g(T))$ as a real number rounded to $4$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, for example: $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$.\n- Each list element must be a float. No units are involved because the objective and output are dimensionless by construction.\n\nAll mathematics in your derivation and implementation description must strictly adhere to the definitions above. The final answer must be a complete, runnable program that implements your derived method and produces the output in the exact format specified. No user input or external files are allowed.",
            "solution": "The problem of designing an adaptive Particle Swarm Optimization (PSO) algorithm for a surrogate battery design problem is a valid, well-posed, and scientifically grounded task in computational optimization and engineering. The problem provides all necessary definitions, constants, and test cases for a complete and verifiable solution. We will first derive the adaptive mechanism as required, then implement the full algorithm.\n\n### Derivation of the Adaptive Inertia Weight Mechanism\n\nThe foundation of our adaptive PSO is the canonical set of update equations. For each particle $i$ at iteration $t$, the velocity $v_i$ and position $x_i$ are updated as follows:\n$$v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$$\n$$x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$$\nwhere $w_t$ is the adaptive inertia weight we aim to derive. $p_i(t)$ is the personal best position of particle $i$, and $g(t)$ is the global best position found by the swarm so far. The coefficients $c_1$ and $c_2$ are acceleration constants, and $r_1(t), r_2(t)$ are random numbers sampled from a uniform distribution $U(0,1)$.\n\nThe goal is to dynamically adjust $w_t$ based on the search progress to balance exploration (searching new areas) and exploitation (refining existing good solutions). A high inertia weight encourages exploration, while a low inertia weight favors exploitation.\n\n**1. Online Progress Signal ($\\Delta_t$)**\nWe define a progress signal based on the improvement of the global best cost at each iteration. Let $\\tilde{F}(x)$ be the evaluated cost function, which we seek to minimize. The global best cost at iteration $t$ is $\\tilde{F}(g(t))$. The improvement $\\Delta_t$ from iteration $t-1$ to $t$ is defined as the non-negative change in this cost:\n$$\\Delta_t = \\max\\{0, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$$\nThis signal is positive when a better solution is found and zero otherwise.\n\n**2. Short-Term and Long-Term Progress Averages ($S_t, L_t$)**\nTo distinguish between recent performance and the long-term trend, we employ two Exponential Moving Averages (EMAs) of the progress signal $\\Delta_t$. The EMA is chosen for its computational efficiency and causal nature.\nThe short-term average, $S_t$, uses a larger smoothing factor $\\alpha_s$ to be more responsive to recent changes in progress.\n$$S_t = \\alpha_s \\Delta_t + (1 - \\alpha_s) S_{t-1}$$\nThe long-term average, $L_t$, uses a smaller smoothing factor $\\alpha_\\ell$ (where $\\alpha_\\ell < \\alpha_s$) to capture the broader trend of improvement.\n$$L_t = \\alpha_\\ell \\Delta_t + (1 - \\alpha_\\ell) L_{t-1}$$\nBoth averages are initialized to zero, i.e., $S_0 = 0$ and $L_0 = 0$.\n\n**3. Dimensionless Progress Ratio ($R_t$)**\nWe form a dimensionless ratio, $R_t$, to quantify the state of the search. This ratio compares the short-term progress to the long-term progress:\n$$R_t = \\frac{S_t + \\epsilon}{L_t + \\epsilon}$$\nA small positive constant $\\epsilon$ (e.g., $10^{-9}$) is added to both the numerator and denominator to ensure numerical stability, particularly at the beginning of the search when both $S_t$ and $L_t$ can be zero.\n- If $R_t > 1$, it implies that recent progress is greater than the long-term average, indicating the swarm is making good progress (exploitation may be beneficial).\n- If $R_t < 1$, it implies that recent progress has fallen below the long-term average, suggesting the search might be stagnating (exploration may be needed).\n\n**4. Inertia Weight Mapping ($w_t = \\mathcal{W}(R_t)$)**\nThe final step is to create a mapping from the progress ratio $R_t$ to the inertia weight $w_t$. The mapping must satisfy two criteria:\n- It must be monotone, mapping $R_t \\in [0, \\infty)$ to $w_t \\in [w_{\\min}, w_{\\max}]$.\n- It must increase $w_t$ when $R_t$ is small (stagnation) and decrease $w_t$ when $R_t$ is large (strong progress). This implies $\\mathcal{W}$ must be a monotonically decreasing function of $R_t$.\n\nA suitable function that meets these requirements and incorporates the provided test parameters $\\kappa$ and $r_0$ is the inverted logistic (sigmoid) function. We define the mapping as:\n$$w_t = \\mathcal{W}(R_t) = w_{\\min} + (w_{\\max} - w_{\\min}) \\cdot \\frac{1}{1 + \\exp\\left(\\kappa (R_t - r_0)\\right)}$$\nLet's analyze this mapping:\n- The parameter $r_0$ acts as a reference or pivot point for the progress ratio. When $R_t = r_0$, the exponential term is $\\exp(0) = 1$, the fraction becomes $1/2$, and $w_t$ is set to the midpoint of its range: $w_t = w_{\\min} + 0.5(w_{\\max} - w_{\\min})$.\n- The parameter $\\kappa > 0$ controls the steepness of the transition. A larger $\\kappa$ results in a more aggressive switch between exploration and exploitation around the pivot $r_0$.\n- As $R_t \\to \\infty$ (strong progress), the exponential term goes to infinity, the fraction approaches $0$, and $w_t \\to w_{\\min}$. This correctly reduces inertia to encourage exploitation of the promising region.\n- As $R_t \\to 0$ (stagnation), the exponential term approaches $\\exp(-\\kappa r_0)$, the fraction approaches $(1+\\exp(-\\kappa r_0))^{-1}$, which is close to $1$, and thus $w_t$ approaches $w_{\\max}$. This correctly increases inertia to promote exploration and escape the local minimum.\n\nThe final value of $w_t$ is clipped to the interval $[w_{\\min}, w_{\\max}]$ to strictly enforce the bounds, although the chosen function naturally keeps the value within this range. The initial inertia weight for the first iteration, $w_0$, is set to $w_{\\max}$ to encourage broad exploration at the start.\n\n### The Surrogate Battery Design Problem\n\nThe optimization is performed on the four-dimensional vector $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$ within the bounds:\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\nThe evaluated cost to be minimized is $\\tilde{F}(x) = F(x;k_E,k_R) + n$, where $n \\sim \\mathcal{N}(0,\\sigma^2)$ is Gaussian noise and the base cost is:\n$$F(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi)$$\n\nThe implementation will follow the logic derived above, executing the adaptive PSO for each test case specified in the problem statement.",
            "answer": "```python\nimport numpy as np\n\ndef run_adaptive_pso(\n    N, T, alpha_s, alpha_ell, w_min, w_max, kappa, r_0,\n    sigma, k_E, k_R, seed, init_same\n):\n    \"\"\"\n    Runs the adaptive Particle Swarm Optimization algorithm for one test case.\n\n    Args:\n        N (int): Number of particles.\n        T (int): Number of iterations.\n        alpha_s (float): Short-term EMA coefficient.\n        alpha_ell (float): Long-term EMA coefficient.\n        w_min (float): Minimum inertia weight.\n        w_max (float): Maximum inertia weight.\n        kappa (float): Steepness parameter for inertia mapping.\n        r_0 (float): Pivot parameter for inertia mapping.\n        sigma (float): Standard deviation of evaluation noise.\n        k_E (float): Energy parameter for the objective function.\n        k_R (float): Resistance parameter for the objective function.\n        seed (int): Seed for the pseudo-random number generator.\n        init_same (bool): If True, all particles start at the center of the search space.\n\n    Returns:\n        float: The best cost found by the algorithm.\n    \"\"\"\n    # Constants and parameters from the problem statement\n    DIMS = 4\n    C1 = 1.4\n    C2 = 1.4\n    EPSILON = 1e-9  # For numerical stability in progress ratio\n\n    # Search space bounds\n    bounds_lo = np.array([0.3, 0.3, 0.2, 0.4])\n    bounds_hi = np.array([0.7, 0.7, 0.5, 1.0])\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    def objective_function(x_vec):\n        \"\"\"Calculates the surrogate cost for a given design vector x.\"\"\"\n        f_c, f_a, phi, tau = x_vec[0], x_vec[1], x_vec[2], x_vec[3]\n        term_R = k_R * tau / (phi**1.5)\n        term_E = k_E * (f_c + f_a) * (1.0 - 0.5 * tau) * (1.0 - 0.4 * phi)\n        cost = term_R - term_E\n        noise = rng.normal(0, sigma) if sigma > 0 else 0.0\n        return cost + noise\n\n    # Initialization (t=0)\n    if init_same:\n        mid_point = (bounds_lo + bounds_hi) / 2.0\n        positions = np.tile(mid_point, (N, 1))\n    else:\n        positions = rng.uniform(low=bounds_lo, high=bounds_hi, size=(N, DIMS))\n    \n    velocities = np.zeros((N, DIMS))\n    \n    # Evaluate initial positions\n    costs = np.array([objective_function(p) for p in positions])\n    \n    # Initialize personal and global bests\n    pbest_positions = np.copy(positions)\n    pbest_costs = np.copy(costs)\n    \n    min_cost_idx = np.argmin(pbest_costs)\n    gbest_position = np.copy(pbest_positions[min_cost_idx])\n    gbest_cost = pbest_costs[min_cost_idx]\n    \n    # Initialize adaptive mechanism variables\n    short_term_avg = 0.0\n    long_term_avg = 0.0\n    w = w_max  # Start with high inertia for exploration\n    prev_gbest_cost = gbest_cost\n\n    # Main PSO loop for T iterations\n    for _ in range(T):\n        # Update velocities and positions for all particles (vectorized)\n        r1 = rng.random(size=(N, DIMS))\n        r2 = rng.random(size=(N, DIMS))\n        \n        cognitive_comp = C1 * r1 * (pbest_positions - positions)\n        social_comp = C2 * r2 * (gbest_position - positions)\n        \n        velocities = w * velocities + cognitive_comp + social_comp\n        positions = positions + velocities\n        \n        # Apply bounds (clipping)\n        positions = np.clip(positions, bounds_lo, bounds_hi)\n        \n        # Evaluate new positions\n        costs = np.array([objective_function(p) for p in positions])\n        \n        # Update personal bests (strict improvement)\n        improved_mask = costs  pbest_costs\n        pbest_positions[improved_mask] = positions[improved_mask]\n        pbest_costs[improved_mask] = costs[improved_mask]\n        \n        # Update global best (strict improvement)\n        min_pbest_idx = np.argmin(pbest_costs)\n        if pbest_costs[min_pbest_idx]  gbest_cost:\n            gbest_cost = pbest_costs[min_pbest_idx]\n            gbest_position = pbest_positions[min_pbest_idx]\n\n        # --- Adaptive Inertia Weight Update ---\n        # 1. Calculate progress signal\n        delta = max(0, prev_gbest_cost - gbest_cost)\n        prev_gbest_cost = gbest_cost\n        \n        # 2. Update moving averages\n        short_term_avg = alpha_s * delta + (1.0 - alpha_s) * short_term_avg\n        long_term_avg = alpha_ell * delta + (1.0 - alpha_ell) * long_term_avg\n        \n        # 3. Calculate progress ratio\n        progress_ratio = (short_term_avg + EPSILON) / (long_term_avg + EPSILON)\n        \n        # 4. Calculate new inertia weight using the derived mapping\n        sigmoid_term = 1.0 / (1.0 + np.exp(kappa * (progress_ratio - r_0)))\n        w_new = w_min + (w_max - w_min) * sigmoid_term\n        w = np.clip(w_new, w_min, w_max)\n        \n    return gbest_cost\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the adaptive PSO algorithm.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {\"N\": 30, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.90, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.01, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 42, \"init_same\": False},\n        # Case 2\n        {\"N\": 20, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.02, \"w_min\": 0.40, \n         \"w_max\": 0.95, \"kappa\": 5.0, \"r_0\": 1.2, \"sigma\": 0.00, \"k_E\": 0.50, \n         \"k_R\": 0.35, \"seed\": 123, \"init_same\": False},\n        # Case 3\n        {\"N\": 10, \"T\": 80, \"alpha_s\": 0.25, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.00, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 7, \"init_same\": True},\n        # Case 4\n        {\"N\": 40, \"T\": 150, \"alpha_s\": 0.15, \"alpha_ell\": 0.03, \"w_min\": 0.35, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 0.8, \"sigma\": 0.05, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 2024, \"init_same\": False},\n    ]\n\n    results = []\n    for params in test_cases:\n        final_cost = run_adaptive_pso(**params)\n        results.append(round(final_cost, 4))\n        \n    # Print the results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}