{
    "hands_on_practices": [
        {
            "introduction": "A fundamental challenge in applying PSO to real-world design problems is handling the boundaries of the search space. Simply forcing particles back into the valid domain can lead to an undesirable clumping effect known as boundary bias. This exercise  moves beyond simple heuristics by guiding you through a mathematical derivation of a velocity clamping strategy. By reasoning about the geometry of the search space, you will develop a principled method for setting the maximum velocity, $v_{\\text{max}}$, to directly control the likelihood of boundary interactions, thereby enhancing the swarm's exploratory behavior.",
            "id": "3938424",
            "problem": "An automated lithium-ion battery design process seeks to jointly optimize the cathode microstructure through two design variables: the electrode thickness and the porosity. For numerical stability and unit consistency, both design variables are affinely normalized to the unit interval, so the swarm operates in the normalized domain $\\Omega = [0,1]^2$. The search is performed using Particle Swarm Optimization (PSO), where each particle’s position $\\boldsymbol{x}_t \\in \\Omega$ is updated by $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$ and the velocity obeys the canonical update rule with inertia weight and stochastic acceleration terms. When a position update leaves $\\Omega$, the particle is projected back onto the nearest boundary of $\\Omega$.\n\nProjection causes boundary bias by truncating out-of-bounds moves, which increases the time particles spend on or near $\\partial \\Omega$. As an alternative to using a constriction factor to reduce velocity magnitude indirectly, consider employing velocity clamping: impose a per-component bound $|v_{t+1}^{(i)}| \\leq v_{\\text{max}}|$ for $i \\in \\{1,2\\}$ in the normalized space, where $v_{\\text{max}}$ is a scalar applied to both dimensions.\n\nStarting from the core definitions of PSO kinematics and the geometric measure of subsets in $\\Omega$, justify why velocity clamping can suppress boundary bias in bounded normalized design domains by directly controlling the set of positions from which a single-step boundary interaction is possible. Then, under the assumption that the particle positions are approximately uniformly distributed in $\\Omega$ at the moment of an update, define a target upper bound $\\alpha \\in (0,1)$ on the fraction of particles that can interact with the boundary (i.e., start within one clamped step of $\\partial \\Omega$) during a single iteration. Using only this geometric reasoning in the normalized domain, derive the maximal safe clamping value $v_{\\text{max}}(\\alpha)$ that ensures the boundary-interaction fraction does not exceed $\\alpha$.\n\nExpress your final answer as a single closed-form analytic expression for $v_{\\text{max}}$ in terms of $\\alpha$, in normalized units. No numerical evaluation is required.",
            "solution": "The problem asks for a justification of velocity clamping as a method to reduce boundary bias in Particle Swarm Optimization (PSO) and for the derivation of a maximal velocity clamp value, $v_{\\text{max}}$, as a function of a desired boundary-interaction fraction, $\\alpha$.\n\nFirst, we validate the problem statement.\nThe problem is set within the standard framework of swarm intelligence and numerical optimization. All provided elements are well-defined and consistent:\n- The optimization domain is a normalized unit square, $\\Omega = [0,1]^2$.\n- The PSO kinematics, $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$, are canonical.\n- The boundary handling method (projection) and its associated problem (boundary bias) are known phenomena in PSO literature.\n- The proposed mitigation strategy, velocity clamping ($|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$), is a standard technique.\n- The request to derive $v_{\\text{max}}(\\alpha)$ is based on a clear geometric interpretation and a simplifying but formalizable assumption (uniform particle distribution).\nThe problem is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It does not violate any of the invalidity criteria. Therefore, the problem is deemed valid and a solution will be constructed.\n\n**Part 1: Justification for Velocity Clamping**\n\nA particle at position $\\boldsymbol{x}_t = (x_t^{(1)}, x_t^{(2)})$ in the domain $\\Omega = [0,1]^2$ can interact with the boundary during the update to step $t+1$ only if its new position, $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$, lies outside of $\\Omega$. This means at least one component of $\\boldsymbol{x}_{t+1}$ must be less than $0$ or greater than $1$.\n\nWithout velocity clamping, the components of the velocity vector $\\boldsymbol{v}_{t+1}$ can be arbitrarily large. This implies that a particle located anywhere in $\\Omega$, even at the center $(\\frac{1}{2}, \\frac{1}{2})$, could potentially generate a velocity large enough to move it outside the domain in a single step, thus triggering the projection mechanism. This frequent projection from a wide range of starting positions leads to an accumulation of particles at the boundaries, a phenomenon known as boundary bias.\n\nVelocity clamping introduces a hard limit, $v_{\\text{max}}$, on the magnitude of each velocity component: $|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$ for $i \\in \\{1,2\\}$. This directly constrains the maximum distance a particle can travel in any single dimension during one time step.\n\nLet's analyze the condition for a particle to cross a boundary. For the first component $x^{(1)}$, an out-of-bounds move occurs if $x_{t+1}^{(1)} < 0$ or $x_{t+1}^{(1)} > 1$.\nSubstituting the update rule, this is $x_t^{(1)} + v_{t+1}^{(1)} < 0$ or $x_t^{(1)} + v_{t+1}^{(1)} > 1$.\n\nWith the velocity clamp, the minimum value for $v_{t+1}^{(1)}$ is $-v_{\\text{max}}$ and the maximum is $+v_{\\text{max}}$.\n- To cross the lower boundary ($x_{t+1}^{(1)} < 0$), a particle must have $x_t^{(1)} + v_{t+1}^{(1)} < 0$. This is only possible if $x_t^{(1)}$ is small enough to be overcome by a negative velocity. The most extreme case is $x_t^{(1)} - v_{\\text{max}} < 0$, which implies $x_t^{(1)} < v_{\\text{max}}$.\n- To cross the upper boundary ($x_{t+1}^{(1)} > 1$), a particle must have $x_t^{(1)} + v_{t+1}^{(1)} > 1$. This is only possible if $x_t^{(1)}$ is large enough. The most extreme case is $x_t^{(1)} + v_{\\text{max}} > 1$, which implies $x_t^{(1)} > 1 - v_{\\text{max}}$.\n\nTherefore, a particle can only interact with the boundaries at $x^{(1)}=0$ or $x^{(1)}=1$ if its position $x_t^{(1)}$ is within the set $[0, v_{\\text{max}}) \\cup (1-v_{\\text{max}}, 1]$. A particle with $x_t^{(1)} \\in [v_{\\text{max}}, 1-v_{\\text{max}}]$ is guaranteed not to cross these specific boundaries in the next step.\n\nBy imposing velocity clamping, we define a \"safe\" sub-region within $\\Omega$ from which a boundary interaction is impossible in a single step. The effect of boundary bias is thus suppressed because the set of particles that are susceptible to projection is explicitly confined to a well-defined \"boundary interaction zone.\" This directly addresses the problem of uncontrolled boundary interactions by limiting the kinematic reach of each particle.\n\n**Part 2: Derivation of $v_{\\text{max}}(\\alpha)$**\n\nThe problem asks for the maximal clamping value $v_{\\text{max}}$ such that the fraction of particles that can interact with the boundary does not exceed a target upper bound $\\alpha$. We are to assume that particle positions are approximately uniformly distributed in the normalized domain $\\Omega = [0,1]^2$.\n\nUnder the uniform distribution assumption, the fraction of particles in any subset of $\\Omega$ is equal to the area of that subset, since the total area of $\\Omega$ is $1^2=1$. The goal is thus to find the area of the boundary-interaction zone, set it equal to $\\alpha$, and solve for $v_{\\text{max}}$.\n\nA particle at position $\\boldsymbol{x} = (x^{(1)}, x^{(2)})$ can interact with the boundary if its position satisfies any of the following conditions, as derived in Part 1:\n- $x^{(1)} < v_{\\text{max}}$\n- $x^{(1)} > 1 - v_{\\text{max}}$\n- $x^{(2)} < v_{\\text{max}}$\n- $x^{(2)} > 1 - v_{\\text{max}}$\n\nThis set of points forms a \"frame\" around the perimeter of the unit square $\\Omega$. It is more convenient to calculate the area of its complement, the \"safe zone\" $S$, and subtract this from the total area. The safe zone $S$ is the region where a particle *cannot* interact with the-boundary. A particle is in $S$ if its position satisfies all of the following conditions:\n- $v_{\\text{max}} \\leq x^{(1)} \\leq 1 - v_{\\text{max}}$\n- $v_{\\text{max}} \\leq x^{(2)} \\leq 1 - v_{\\text{max}}$\n\nThis geometrically defines a square centered within $\\Omega$. The side length of this inner square is $(1 - v_{\\text{max}}) - v_{\\text{max}} = 1 - 2v_{\\text{max}}$. For this to be a valid, non-degenerate square, we must have $1 - 2v_{\\text{max}} > 0$, or $v_{\\text{max}} < \\frac{1}{2}$. Given that $\\alpha \\in (0,1)$, the resulting $v_{\\text{max}}$ will satisfy this.\n\nThe area of the safe zone, $A_S$, is the square of its side length:\n$$A_S = (1 - 2v_{\\text{max}})^2$$\n\nThe area of the boundary-interaction zone, $A_Z$, is the total area of $\\Omega$ minus the area of the safe zone:\n$$A_Z = A_{\\Omega} - A_S = 1 - (1 - 2v_{\\text{max}})^2$$\n\nThe problem requires that this fraction of particles (and thus this area) be no more than $\\alpha$. To find the maximal safe clamping value $v_{\\text{max}}$, we set this area equal to $\\alpha$:\n$$1 - (1 - 2v_{\\text{max}})^2 = \\alpha$$\n\nWe now solve this equation for $v_{\\text{max}}$:\n$$(1 - 2v_{\\text{max}})^2 = 1 - \\alpha$$\n\nTaking the square root of both sides, we select the positive root because the side length $1 - 2v_{\\text{max}}$ must be positive:\n$$1 - 2v_{\\text{max}} = \\sqrt{1 - \\alpha}$$\nThe condition $\\alpha \\in (0,1)$ ensures that $1 - \\alpha > 0$, so the square root is well-defined and real.\n\nRearranging the terms to isolate $v_{\\text{max}}$:\n$$2v_{\\text{max}} = 1 - \\sqrt{1 - \\alpha}$$\n$$v_{\\text{max}}(\\alpha) = \\frac{1 - \\sqrt{1 - \\alpha}}{2}$$\nThis expression can also be written as $\\frac{1}{2}(1 - \\sqrt{1 - \\alpha})$. This is the final closed-form expression for the maximal safe clamping value as a function of the desired boundary-interaction fraction $\\alpha$.",
            "answer": "$$\\boxed{\\frac{1}{2}\\left(1 - \\sqrt{1 - \\alpha}\\right)}$$"
        },
        {
            "introduction": "While PSO is a powerful tool for global exploration, its convergence can be slow once it nears an optimal region. To accelerate the final stages of optimization, we can create a hybrid algorithm that integrates a more efficient local search method, such as gradient descent. This practice  challenges you to implement such a hybrid PSO, but with a realistic twist: you must develop and apply quantitative criteria to decide when a gradient, whether from a surrogate model or a noisy adjoint-like computation, is reliable enough to be used for local refinement. This exercise bridges the gap between textbook algorithms and the practical complexities of optimizing expensive, real-world battery simulations.",
            "id": "3938429",
            "problem": "You are asked to design and implement a hybrid Particle Swarm Optimization (PSO) algorithm for a dimensionless battery electrode design problem. The hybrid algorithm must apply a local gradient-based refinement step near promising designs, but only when gradients obtained from surrogate models or adjoint computations are deemed reliable by principled, quantitative criteria. Your implementation must produce deterministic results for a fixed random seed and must aggregate results for multiple test cases into a single line of output in a specified format.\n\nFundamental base and domain. Consider a continuous design vector $\\mathbf{x} = (p,s,t) \\in [0,1]^3$, representing normalized porosity $p$, normalized solid fraction $s$, and normalized thickness $t$. Let the design objective be a differentiable scalar function $J(\\mathbf{x})$ that trades off energy density, ohmic behavior, and reaction kinetics. The design goal is to solve the constrained minimization problem\n$$\n\\min_{\\mathbf{x} \\in [0,1]^3} J(\\mathbf{x}),\n$$\nwhere\n$$\nJ(p,s,t) = -s\\,t\\,\\left(1 - 0.5\\,p\\right) + 0.2\\,\\frac{t^2}{p + 0.1} + 0.3\\,\\left(1-p\\right)^2 + 0.1\\,\\frac{s^2}{0.3 + p} + 0.02\\,\\sin(5\\,p)\\,\\cos(5\\,s)\\,\\sin(5\\,t).\n$$\nAll variables are dimensionless, so no physical units are required in the output.\n\nAlgorithmic requirements. Your program must implement:\n- A hybrid Particle Swarm Optimization (PSO) algorithm based on the fundamental ideas of stochastic search and personal-best/global-best information sharing. For $N$ particles at iteration $k$, PSO updates positions $\\mathbf{x}_{i}^{(k)}$ and velocities $\\mathbf{v}_{i}^{(k)}$ using bounded steps within $[0,1]^3$, with standard inertia and acceleration coefficients. Do not rely on any shortcut formulas beyond the foundational definitions of iterative search with inertia and attraction to personal and global bests.\n- A local gradient-based refinement step around promising designs (e.g., the top performers by objective value) executed every $r$ iterations, using a backtracking line search with step size $\\alpha$ and projection onto $[0,1]^3$. A refinement step must only occur when gradient reliability checks pass, as detailed below.\n\nGradient sources and reliability criteria. Your hybrid method must support three gradient sources:\n- Exact gradient: the analytic gradient $\\nabla J(\\mathbf{x})$ derived from the given $J(\\mathbf{x})$ is considered always reliable in this setting.\n- Surrogate gradient: compute $\\tilde{\\nabla} J(\\mathbf{x})$ from a local quadratic surrogate fit around $\\mathbf{x}$ using $K$ nearest previously evaluated points. Accept a surrogate-based gradient only if two conditions are satisfied:\n  1. The local root-mean-square error (RMSE) of the surrogate predictions over its $K$ points does not exceed a threshold $\\varepsilon$.\n  2. The surrogate’s gradient at $\\mathbf{x}$ is close to a finite-difference estimate, meaning\n  $$\n  \\frac{\\left\\|\\tilde{\\nabla} J(\\mathbf{x}) - \\nabla_h J(\\mathbf{x})\\right\\|_2}{\\left\\|\\nabla_h J(\\mathbf{x})\\right\\|_2 + 10^{-12}} \\le \\delta,\n  $$\n  where $\\nabla_h J(\\mathbf{x})$ is the central finite-difference gradient with a small step $h$.\n- Adjoint gradient: simulate an adjoint-like gradient $\\tilde{\\nabla} J(\\mathbf{x})$ by perturbing the exact gradient with zero-mean Gaussian noise of standard deviation $\\sigma$. Accept this gradient only if a directional-derivative test passes: for $D$ random unit directions $\\mathbf{u}_j$, the predicted directional derivatives $\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j$ agree with finite differences,\n  $$\n  \\left|\\frac{\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j - \\frac{J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)}{2h}}{\\frac{\\left|J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)\\right|}{2h} + 10^{-12}}\\right| \\le \\tau,\n  $$\n  for at least a fraction $\\rho$ of the $D$ directions, and with the mean relative error not exceeding $\\tau$. Here $h$ is the finite-difference step size.\n\nRefinement step. When a reliable gradient $\\mathbf{g}(\\mathbf{x})$ is available for a promising design, perform a projected backtracking line search that tries steps $\\mathbf{x}_{\\text{new}} = \\Pi_{[0,1]^3}\\left(\\mathbf{x} - \\alpha\\,\\mathbf{g}(\\mathbf{x})\\right)$, shrinking $\\alpha$ geometrically until finding a descent step or a minimum step size is reached. Update the particle’s personal best and the global best accordingly.\n\nTest suite. Your program must evaluate the hybrid optimizer on the following five test cases. For each case, output the best objective value found, rounded to $6$ decimal places. The cases are:\n\n- Case $1$ (happy path, exact gradient):\n  - Gradient source: $\\text{exact}$.\n  - Swarm size $N = 24$, iterations $T = 60$, refinement period $r = 5$.\n  - PSO coefficients: inertia $w = 0.7$, cognitive $c_1 = 1.5$, social $c_2 = 1.5$.\n  - Random seed $= 42$.\n\n- Case $2$ (surrogate gradient, reliable):\n  - Gradient source: $\\text{surrogate}$.\n  - $N = 28$, $T = 70$, $r = 4$, $K = 25$ nearest neighbors, ridge regularization $\\lambda = 10^{-6}$.\n  - Surrogate RMSE threshold $\\varepsilon = 10^{-3}$, gradient relative error threshold $\\delta = 0.25$.\n  - $w = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, seed $= 1337$.\n\n- Case $3$ (surrogate gradient, unreliable):\n  - Gradient source: $\\text{surrogate}$.\n  - $N = 18$, $T = 50$, $r = 4$, $K = 20$, $\\lambda = 10^{-6}$.\n  - $\\varepsilon = 10^{-6}$, $\\delta = 0.10$.\n  - $w = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, seed $= 202$.\n\n- Case $4$ (adjoint-like gradient, low noise):\n  - Gradient source: $\\text{adjoint}$.\n  - $N = 22$, $T = 60$, $r = 5$, noise $\\sigma = 0.01$, directional sample size $D = 5$, acceptance fraction $\\rho = 0.6$, tolerance $\\tau = 0.20$.\n  - $w = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, seed $= 99$.\n\n- Case $5$ (adjoint-like gradient, high noise, boundary initialization):\n  - Gradient source: $\\text{adjoint}$.\n  - $N = 22$, $T = 60$, $r = 5$, $\\sigma = 0.30$, $D = 5$, $\\rho = 0.6$, $\\tau = 0.15$.\n  - Initialize half the particles near the lower boundary ($\\mathbf{x}\\approx \\mathbf{0}$) and half near the upper boundary ($\\mathbf{x}\\approx \\mathbf{1}$), then apply projection at every update.\n  - $w = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, seed $= 111$.\n\nFinal output format. Your program should produce a single line of output containing a comma-separated list of the five best objective values in square brackets, rounded to $6$ decimal places (e.g., $[v_1,v_2,v_3,v_4,v_5]$). No other output should be printed.",
            "solution": "The problem presented is a well-posed task in the field of computational optimization, specifically focused on a hybrid metaheuristic algorithm for a constrained continuous optimization problem stylized as battery electrode design. The problem is scientifically grounded, self-contained (with minor, standard parameters left to the implementer's discretion), and objectively specified. It is therefore deemed valid. The following solution outlines the theoretical and algorithmic framework for the required implementation.\n\n### 1. Problem Formulation\n\nThe core of the problem is to find the minimum of a scalar objective function $J(\\mathbf{x})$ over a three-dimensional continuous design space $\\mathbf{x} \\in [0,1]^3$. The design vector is $\\mathbf{x} = (p,s,t)$, representing normalized porosity, solid fraction, and thickness, respectively. The objective function to be minimized is given by:\n$$\nJ(p,s,t) = -s\\,t\\,\\left(1 - 0.5\\,p\\right) + 0.2\\,\\frac{t^2}{p + 0.1} + 0.3\\,\\left(1-p\\right)^2 + 0.1\\,\\frac{s^2}{0.3 + p} + 0.02\\,\\sin(5\\,p)\\,\\cos(5\\,s)\\,\\sin(5\\,t)\n$$\nThis function is non-convex and differentiable everywhere within the domain of interest, $[0,1]^3$, as the denominators $(p+0.1)$ and $(0.3+p)$ are strictly positive for $p \\in [0,1]$.\n\n### 2. Algorithmic Framework: Hybrid Particle Swarm Optimization\n\nThe chosen optimization strategy is a hybrid Particle Swarm Optimization (PSO) algorithm. This method combines the global search capabilities of PSO with the local convergence properties of gradient-based methods.\n\n#### 2.1. Particle Swarm Optimization Core\n\nThe PSO algorithm maintains a swarm of $N$ particles, where each particle $i$ has a position $\\mathbf{x}_i \\in [0,1]^3$ and a velocity $\\mathbf{v}_i \\in \\mathbb{R}^3$. At each iteration $k$, the velocity and position of each particle are updated based on its own best-known position, $\\mathbf{p}_{\\text{best},i}$, and the global best-known position found by any particle in the swarm, $\\mathbf{g}_{\\text{best}}$.\n\nThe update equations are:\n$$\n\\mathbf{v}_i^{(k+1)} = w\\,\\mathbf{v}_i^{(k)} + c_1\\,r_1 \\left(\\mathbf{p}_{\\text{best},i}^{(k)} - \\mathbf{x}_i^{(k)}\\right) + c_2\\,r_2 \\left(\\mathbf{g}_{\\text{best}}^{(k)} - \\mathbf{x}_i^{(k)}\\right)\n$$\n$$\n\\mathbf{x}_i^{(k+1)} = \\Pi_{[0,1]^3} \\left( \\mathbf{x}_i^{(k)} + \\mathbf{v}_i^{(k+1)} \\right)\n$$\nwhere:\n- $w$ is the inertia weight.\n- $c_1$ and $c_2$ are the cognitive and social acceleration coefficients.\n- $r_1, r_2 \\sim U(0,1)$ are random numbers sampled independently for each particle and dimension.\n- $\\Pi_{[0,1]^3}(\\cdot)$ is the projection operator that clamps the vector components to the interval $[0,1]$.\n\nVelocities are also clamped to a reasonable range, $[-0.5, 0.5]^3$, to prevent divergence. The personal best $\\mathbf{p}_{\\text{best},i}$ is updated if a particle finds a position with a lower objective value. The global best $\\mathbf{g}_{\\text{best}}$ is updated whenever any particle's personal best improves upon the existing global best.\n\n#### 2.2. Local Gradient-Based Refinement\n\nEvery $r$ iterations, a local refinement step is triggered for the most promising design, which is taken to be the current global best position $\\mathbf{g}_{\\text{best}}$. This step uses a gradient-based method to search for a better solution in the vicinity of $\\mathbf{g}_{\\text{best}}$. However, this refinement is only performed if a reliable gradient can be obtained, as determined by criteria specific to the gradient source.\n\n### 3. Gradient Sources and Reliability Assessment\n\nThe hybrid algorithm supports three distinct sources for the gradient $\\nabla J(\\mathbf{x})$.\n\n#### 3.1. Exact Gradient\nThe analytical gradient, $\\nabla J(\\mathbf{x})$, is computed directly from the partial derivatives of $J(p,s,t)$:\n$$\n\\frac{\\partial J}{\\partial p} = 0.5st - \\frac{0.2 t^2}{(p+0.1)^2} - 0.6(1-p) - \\frac{0.1 s^2}{(0.3+p)^2} + 0.1\\cos(5p)\\cos(5s)\\sin(5t)\n$$\n$$\n\\frac{\\partial J}{\\partial s} = -t(1-0.5p) + \\frac{0.2s}{0.3+p} - 0.1\\sin(5p)\\sin(5s)\\sin(5t)\n$$\n$$\n\\frac{\\partial J}{\\partial t} = -s(1-0.5p) + \\frac{0.4t}{p+0.1} + 0.1\\sin(5p)\\cos(5s)\\cos(5t)\n$$\nIn this problem context, the exact gradient is considered perfectly reliable and is always used for refinement when specified.\n\n#### 3.2. Surrogate Gradient\nA local quadratic surrogate model is constructed to approximate $J(\\mathbf{x})$ around a point of interest $\\mathbf{x}^*$. The model takes the form $\\tilde{J}(\\mathbf{x}) = \\mathbf{w}^\\top \\phi(\\mathbf{x})$, where $\\phi(\\mathbf{x}) = (1, p, s, t, p^2, s^2, t^2, ps, pt, st)^\\top$ is a vector of quadratic features. The coefficient vector $\\mathbf{w} \\in \\mathbb{R}^{10}$ is determined by fitting the model to the $K$ nearest points to $\\mathbf{x}^*$ from the history of all function evaluations, using ridge regression to solve $(\\mathbf{\\Phi}^\\top\\mathbf{\\Phi} + \\lambda \\mathbf{I})\\mathbf{w} = \\mathbf{\\Phi}^\\top\\mathbf{y}$.\nThe gradient of this surrogate, $\\tilde{\\nabla} J(\\mathbf{x}^*) = \\nabla (\\mathbf{w}^\\top \\phi(\\mathbf{x}^*))$, is accepted as reliable only if:\n1.  The root-mean-square error (RMSE) of the surrogate's predictions on the $K$ training points is below a threshold $\\varepsilon$.\n2.  The surrogate gradient $\\tilde{\\nabla} J(\\mathbf{x}^*)$ is sufficiently close to a numerical gradient estimate $\\nabla_h J(\\mathbf{x}^*)$ obtained via central finite differences with step size $h=10^{-6}$, satisfying $\\frac{\\left\\|\\tilde{\\nabla} J(\\mathbf{x}^*) - \\nabla_h J(\\mathbf{x}^*)\\right\\|_2}{\\left\\|\\nabla_h J(\\mathbf{x}^*)\\right\\|_2 + 10^{-12}} \\le \\delta$.\n\n#### 3.3. Adjoint-like Gradient\nAn adjoint-like gradient is simulated by corrupting the exact gradient with zero-mean Gaussian noise: $\\tilde{\\nabla} J(\\mathbf{x}) = \\nabla J(\\mathbf{x}) + \\mathbf{z}$, where $\\mathbf{z} \\sim \\mathcal{N}(0, \\sigma^2 I)$. This noisy gradient is deemed reliable if it passes a directional derivative test:\n1.  The relative error between the directional derivative predicted by the noisy gradient, $\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j$, and a finite-difference approximation, $\\frac{J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)}{2h}$, must be less than or equal to a tolerance $\\tau$ for at least a fraction $\\rho$ of $D$ random unit directions $\\mathbf{u}_j$.\n2. The mean of this relative error over all $D$ directions must not exceed $\\tau$. A finite-difference step of $h=10^{-6}$ is used.\n\n### 4. Projected Backtracking Line Search\n\nIf a reliable gradient $\\mathbf{g}(\\mathbf{x})$ is obtained for a point $\\mathbf{x}$, a backtracking line search is performed to find a better point. The search proceeds by testing candidate points $\\mathbf{x}_{\\text{new}} = \\Pi_{[0,1]^3}(\\mathbf{x} - \\alpha\\,\\mathbf{g}(\\mathbf{x}))$, starting with an initial step size $\\alpha=1.0$. If the new point does not yield a decrease in the objective function value, i.e., $J(\\mathbf{x}_{\\text{new}}) \\ge J(\\mathbf{x})$, the step size $\\alpha$ is geometrically reduced (e.g., by a factor of $0.5$) and the process is repeated. The search terminates upon finding a descent step or when $\\alpha$ falls below a minimum threshold of $10^{-8}$. If a better point is found, the global best position and value are updated accordingly.\n\n### 5. Test Suite Execution\n\nThe hybrid PSO algorithm is executed for each of the five specified test cases. Each case defines the swarm size $N$, total iterations $T$, refinement period $r$, PSO coefficients ($w, c_1, c_2$), a random seed, and parameters for the specific gradient source. The deterministic nature of the process is ensured by seeding a pseudo-random number generator for each case. The final result for each case is the best objective value found, $\\min(J(\\mathbf{g}_{\\text{best}}))$, rounded to six decimal places.",
            "answer": "```python\nimport numpy as np\nimport collections\n\n#\n# Problem-specific functions: Objective function and its exact gradient\n#\n\ndef objective_function(x):\n    \"\"\"Computes the objective function J(x) for a given design vector x=(p,s,t).\"\"\"\n    p, s, t = x[0], x[1], x[2]\n    term1 = -s * t * (1 - 0.5 * p)\n    term2 = 0.2 * (t**2) / (p + 0.1)\n    term3 = 0.3 * (1 - p)**2\n    term4 = 0.1 * (s**2) / (0.3 + p)\n    term5 = 0.02 * np.sin(5 * p) * np.cos(5 * s) * np.sin(5 * t)\n    return term1 + term2 + term3 + term4 + term5\n\ndef exact_gradient(x):\n    \"\"\"Computes the analytical gradient of J(x) at a given design vector x=(p,s,t).\"\"\"\n    p, s, t = x[0], x[1], x[2]\n    grad = np.zeros(3)\n    \n    # Gradient w.r.t. p\n    grad[0] = (0.5 * s * t) \\\n            - (0.2 * t**2 / (p + 0.1)**2) \\\n            - (0.6 * (1 - p)) \\\n            - (0.1 * s**2 / (0.3 + p)**2) \\\n            + (0.1 * np.cos(5*p) * np.cos(5*s) * np.sin(5*t))\n\n    # Gradient w.r.t. s\n    grad[1] = -t * (1 - 0.5 * p) \\\n            + (0.2 * s / (0.3 + p)) \\\n            - (0.1 * np.sin(5*p) * np.sin(5*s) * np.sin(5*t))\n\n    # Gradient w.r.t. t\n    grad[2] = -s * (1 - 0.5 * p) \\\n            + (0.4 * t / (p + 0.1)) \\\n            + (0.1 * np.sin(5*p) * np.cos(5*s) * np.cos(5*t))\n            \n    return grad\n\n#\n# Hybrid PSO Solver\n#\n\nclass HybridPSOSolver:\n    def __init__(self, params):\n        self.params = params\n        self.rng = np.random.default_rng(self.params['seed'])\n        self.dim = 3\n        \n        # PSO parameters\n        self.N = params['N']\n        self.T = params['T']\n        self.w = params['w']\n        self.c1 = params['c1']\n        self.c2 = params['c2']\n        \n        # Refinement parameters\n        self.r = params['r']\n        self.gradient_source = params['gradient_source']\n\n        # Shared parameters\n        self.h_fd = 1e-6 # Finite difference step size\n\n        # Initialize state\n        self.positions = None\n        self.velocities = None\n        self.p_best_pos = None\n        self.p_best_val = None\n        self.g_best_pos = None\n        self.g_best_val = np.inf\n        \n        # History for surrogate models\n        self.history_pos = []\n        self.history_val = []\n\n    def _initialize_swarm(self):\n        \"\"\"Initializes the swarm's positions and velocities.\"\"\"\n        if self.params.get('special_init', False):\n            # Case 5 specific initialization\n            n_half = self.N // 2\n            self.positions = np.zeros((self.N, self.dim))\n            self.positions[:n_half, :] = self.rng.uniform(0.0, 0.1, size=(n_half, self.dim))\n            self.positions[n_half:, :] = self.rng.uniform(0.9, 1.0, size=(self.N - n_half, self.dim))\n        else:\n            self.positions = self.rng.uniform(0.0, 1.0, size=(self.N, self.dim))\n\n        self.velocities = np.zeros((self.N, self.dim))\n        \n        self.p_best_pos = np.copy(self.positions)\n        self.p_best_val = np.array([objective_function(p) for p in self.positions])\n        \n        self.history_pos.extend(list(self.positions))\n        self.history_val.extend(list(self.p_best_val))\n        \n        best_particle_idx = np.argmin(self.p_best_val)\n        self.g_best_val = self.p_best_val[best_particle_idx]\n        self.g_best_pos = self.p_best_pos[best_particle_idx]\n\n    def _finite_diff_gradient(self, x):\n        \"\"\"Computes gradient using central finite differences.\"\"\"\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_plus_h[i] += self.h_fd\n            x_minus_h = x.copy()\n            x_minus_h[i] -= self.h_fd\n            grad[i] = (objective_function(x_plus_h) - objective_function(x_minus_h)) / (2 * self.h_fd)\n        return grad\n\n    def _get_surrogate_gradient(self, x_ref):\n        \"\"\"Computes and validates a gradient from a surrogate model.\"\"\"\n        K = self.params['K']\n        reg = self.params.get('lambda', 1e-6)\n        \n        if len(self.history_pos) < K:\n            return None\n\n        # Find K nearest neighbors\n        hist_pos_arr = np.array(self.history_pos)\n        distances = np.linalg.norm(hist_pos_arr - x_ref, axis=1)\n        k_indices = np.argsort(distances)[:K]\n        \n        neighbor_pos = hist_pos_arr[k_indices]\n        neighbor_val = np.array(self.history_val)[k_indices]\n        \n        # Build feature matrix for quadratic model\n        def get_features(x):\n            p, s, t = x\n            return [1, p, s, t, p**2, s**2, t**2, p*s, p*t, s*t]\n        \n        phi_matrix = np.array([get_features(pos) for pos in neighbor_pos])\n        \n        # Solve for coefficients w using ridge regression\n        try:\n            A = phi_matrix.T @ phi_matrix + reg * np.identity(phi_matrix.shape[1])\n            b = phi_matrix.T @ neighbor_val\n            w = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return None\n\n        # --- Reliability Check 1: RMSE ---\n        y_pred = phi_matrix @ w\n        rmse = np.sqrt(np.mean((y_pred - neighbor_val)**2))\n        if rmse > self.params['epsilon']:\n            return None\n\n        # --- Reliability Check 2: Gradient Match ---\n        p_ref, s_ref, t_ref = x_ref\n        grad_phi_p = np.array([0, 1, 0, 0, 2*p_ref, 0, 0, s_ref, t_ref, 0])\n        grad_phi_s = np.array([0, 0, 1, 0, 0, 2*s_ref, 0, p_ref, 0, t_ref])\n        grad_phi_t = np.array([0, 0, 0, 1, 0, 0, 2*t_ref, 0, p_ref, s_ref])\n        \n        g_surr = np.array([grad_phi_p @ w, grad_phi_s @ w, grad_phi_t @ w])\n        g_fd = self._finite_diff_gradient(x_ref)\n        \n        g_fd_norm = np.linalg.norm(g_fd)\n        rel_err = np.linalg.norm(g_surr - g_fd) / (g_fd_norm + 1e-12)\n\n        if rel_err > self.params['delta']:\n            return None\n\n        return g_surr\n\n    def _get_adjoint_gradient(self, x_ref):\n        \"\"\"Computes and validates an adjoint-like gradient.\"\"\"\n        g_exact = exact_gradient(x_ref)\n        noise = self.rng.normal(0, self.params['sigma'], size=self.dim)\n        g_adj = g_exact + noise\n\n        # --- Reliability Check: Directional Derivatives ---\n        D = self.params['D']\n        rho = self.params['rho']\n        tau = self.params['tau']\n        \n        passed_count = 0\n        total_rel_err = 0.0\n        \n        for _ in range(D):\n            u = self.rng.normal(size=self.dim)\n            u /= np.linalg.norm(u)\n            \n            dd_adj = g_adj @ u\n            dd_fd = (objective_function(x_ref + self.h_fd * u) - objective_function(x_ref - self.h_fd * u)) / (2 * self.h_fd)\n            \n            # Record historical evaluations for surrogates\n            self.history_pos.append(x_ref + self.h_fd * u)\n            self.history_pos.append(x_ref - self.h_fd * u)\n            self.history_val.append(objective_function(x_ref + self.h_fd * u))\n            self.history_val.append(objective_function(x_ref - self.h_fd * u))\n\n            denominator = abs(dd_fd) + 1e-12\n            rel_err = abs(dd_adj - dd_fd) / denominator\n            \n            total_rel_err += rel_err\n            if rel_err <= tau:\n                passed_count += 1\n        \n        mean_rel_err = total_rel_err / D\n        fraction_passed = passed_count / D\n        \n        if fraction_passed >= rho and mean_rel_err <= tau:\n            return g_adj\n        else:\n            return None\n\n    def _backtracking_line_search(self, x, g):\n        \"\"\"Performs a projected backtracking line search.\"\"\"\n        alpha = 1.0\n        beta = 0.5\n        min_alpha = 1e-8\n        \n        current_val = objective_function(x)\n\n        for _ in range(10): # Max 10 backtracking steps\n            x_new = x - alpha * g\n            x_new = np.clip(x_new, 0, 1)\n            \n            new_val = objective_function(x_new)\n            self.history_pos.append(x_new)\n            self.history_val.append(new_val)\n            \n            if new_val < current_val:\n                return x_new, new_val\n            \n            alpha *= beta\n            if alpha < min_alpha:\n                break\n        \n        return x, current_val\n        \n    def _refinement_step(self):\n        \"\"\"Executes the gradient-based refinement step on the global best position.\"\"\"\n        x_ref = self.g_best_pos\n        g = None\n        \n        if self.gradient_source == 'exact':\n            g = exact_gradient(x_ref)\n        elif self.gradient_source == 'surrogate':\n            g = self._get_surrogate_gradient(x_ref)\n        elif self.gradient_source == 'adjoint':\n            g = self._get_adjoint_gradient(x_ref)\n        \n        if g is not None:\n            new_pos, new_val = self._backtracking_line_search(x_ref, g)\n            if new_val < self.g_best_val:\n                self.g_best_pos = new_pos\n                self.g_best_val = new_val\n\n    def optimize(self):\n        self._initialize_swarm()\n        \n        v_max = 0.5\n\n        for k in range(self.T):\n            r1 = self.rng.uniform(0, 1, size=(self.N, self.dim))\n            r2 = self.rng.uniform(0, 1, size=(self.N, self.dim))\n\n            # Update velocities\n            cognitive_comp = self.c1 * r1 * (self.p_best_pos - self.positions)\n            social_comp = self.c2 * r2 * (self.g_best_pos - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_comp + social_comp\n            \n            # Clamp velocities\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            # Update positions\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, 0, 1)\n\n            # Evaluate objective\n            current_vals = np.array([objective_function(p) for p in self.positions])\n            self.history_pos.extend(list(self.positions))\n            self.history_val.extend(list(current_vals))\n\n            # Update personal bests\n            improvement_mask = current_vals < self.p_best_val\n            self.p_best_pos[improvement_mask] = self.positions[improvement_mask]\n            self.p_best_val[improvement_mask] = current_vals[improvement_mask]\n            \n            # Update global best\n            best_particle_idx = np.argmin(self.p_best_val)\n            if self.p_best_val[best_particle_idx] < self.g_best_val:\n                self.g_best_val = self.p_best_val[best_particle_idx]\n                self.g_best_pos = self.p_best_pos[best_particle_idx]\n\n            # Perform refinement step periodically\n            if (k + 1) % self.r == 0:\n                self._refinement_step()\n        \n        return self.g_best_val\n\ndef solve():\n    test_cases = [\n        # Case 1 (happy path, exact gradient)\n        {\n            'gradient_source': 'exact', 'N': 24, 'T': 60, 'r': 5,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 42\n        },\n        # Case 2 (surrogate gradient, reliable)\n        {\n            'gradient_source': 'surrogate', 'N': 28, 'T': 70, 'r': 4,\n            'K': 25, 'lambda': 1e-6, 'epsilon': 1e-3, 'delta': 0.25,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 1337\n        },\n        # Case 3 (surrogate gradient, unreliable)\n        {\n            'gradient_source': 'surrogate', 'N': 18, 'T': 50, 'r': 4,\n            'K': 20, 'lambda': 1e-6, 'epsilon': 1e-6, 'delta': 0.10,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 202\n        },\n        # Case 4 (adjoint-like gradient, low noise)\n        {\n            'gradient_source': 'adjoint', 'N': 22, 'T': 60, 'r': 5,\n            'sigma': 0.01, 'D': 5, 'rho': 0.6, 'tau': 0.20,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 99\n        },\n        # Case 5 (adjoint-like gradient, high noise, boundary initialization)\n        {\n            'gradient_source': 'adjoint', 'N': 22, 'T': 60, 'r': 5,\n            'sigma': 0.30, 'D': 5, 'rho': 0.6, 'tau': 0.15,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 111,\n            'special_init': True\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        solver = HybridPSOSolver(params)\n        best_value = solver.optimize()\n        results.append(f\"{best_value:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "The performance of PSO is highly sensitive to its parameters, particularly the inertia weight $w$, which balances the swarm's tendency to explore new regions versus exploit known good ones. Instead of relying on a fixed, manually-tuned value, a more robust approach is to allow the algorithm to adapt this parameter during the search. This advanced practice  guides you through the derivation and implementation of an adaptive PSO. You will design a control system that uses moving averages of the swarm's progress to automatically adjust the inertia weight, enabling the algorithm to dynamically shift between exploration and exploitation to solve the design problem more effectively.",
            "id": "3938452",
            "problem": "You are tasked with deriving and implementing an adaptive Particle Swarm Optimization (PSO) procedure for automated battery design. The adaptation must be based on an online estimation of progress using moving averages of fitness improvement. The core requirement is to derive, from first principles, a progress estimator and a principled mapping to adjust the inertia weight in order to avoid stagnation. Then implement the full algorithm to solve a dimensionless surrogate battery design problem.\n\nThe surrogate battery design problem is defined on a four-dimensional continuous decision vector $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$, where $f_{\\mathrm{c}}$ is the cathode active-material volume fraction, $f_{\\mathrm{a}}$ is the anode active-material volume fraction, $\\phi$ is the electrolyte porosity, and $\\tau$ is a dimensionless separator thickness scaling. The bounds are:\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\nThe composite dimensionless cost to be minimized is defined as\n$$\nF(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi),\n$$\nwith non-negative Gaussian evaluation noise optionally added as $n \\sim \\mathcal{N}(0,\\sigma^2)$ for robustness testing, yielding the evaluated cost\n$$\n\\tilde{F}(x) = F(x;k_E,k_R) + n.\n$$\n\nYour derivation must begin from the canonical PSO update rules (a well-tested base):\n- Position update: $x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$\n- Velocity update: $v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$\nwhere $i$ indexes particles, $t$ is the iteration, $w_t$ is the inertia weight at time $t$, $c_1$ and $c_2$ are acceleration coefficients, $r_1(t)$ and $r_2(t)$ are independent uniform random variables on $[0,1]$, $p_i(t)$ is the best-known position of particle $i$, and $g(t)$ is the global best position.\n\nFrom this base, you must:\n- Define an online progress signal using the non-negative improvement of the global best cost $\\Delta_t = \\max\\{0,\\, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$.\n- Construct short-term and long-term moving averages of $\\Delta_t$ using either the Simple Moving Average (SMA) or Exponential Moving Average (EMA), ensuring that your estimator is causal and numerically stable. Denote these as $S_t$ and $L_t$, respectively, with $S_t$ emphasizing recent progress and $L_t$ capturing trend-level progress.\n- Derive a dimensionless progress ratio $R_t$ from $S_t$ and $L_t$ that is sensitive to stagnation versus continued improvement.\n- From this progress estimator, derive a monotone mapping $w_t = \\mathcal{W}(R_t)$ that increases $w_t$ when $R_t$ indicates stagnation (to encourage exploration) and decreases $w_t$ when $R_t$ indicates strong progress (to encourage exploitation). Enforce $w_t \\in [w_{\\min}, w_{\\max}]$ with fixed $w_{\\min}$ and $w_{\\max}$ chosen to preserve stability.\n\nYour program must implement the full PSO algorithm with the derived $w_t$ law, apply it to the surrogate battery design problem, and report results for a defined test suite. You must use $c_1 = 1.4$ and $c_2 = 1.4$. Particle positions must be clipped to the bounds after each position update. The personal bests $p_i(t)$ and global best $g(t)$ must be updated with strict improvement only.\n\nTest Suite:\nProvide results for the following four test cases, each specified by particle count $N$, iteration count $T$, short-term and long-term EMA coefficients $\\alpha_s$ and $\\alpha_\\ell$, inertia bounds $w_{\\min}$ and $w_{\\max}$, progress-to-inertia mapping parameters $\\kappa$ and $r_0$, noise standard deviation $\\sigma$, surrogate parameters $k_E$ and $k_R$, pseudo-random seed $\\text{seed}$, and whether all particles start from the same midpoint position $\\text{init\\_same}$:\n\n- Case $1$: $N=30$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.90$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.01$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=42$, $\\text{init\\_same}=\\text{False}$.\n- Case $2$: $N=20$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.02$, $w_{\\min}=0.40$, $w_{\\max}=0.95$, $\\kappa=5.0$, $r_0=1.2$, $\\sigma=0.00$, $k_E=0.50$, $k_R=0.35$, $\\text{seed}=123$, $\\text{init\\_same}=\\text{False}$.\n- Case $3$: $N=10$, $T=80$, $\\alpha_s=0.25$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.00$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=7$, $\\text{init\\_same}=\\text{True}$.\n- Case $4$: $N=40$, $T=150$, $\\alpha_s=0.15$, $\\alpha_\\ell=0.03$, $w_{\\min}=0.35$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=0.8$, $\\sigma=0.05$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=2024$, $\\text{init\\_same}=\\text{False}$.\n\nOutput specification:\n- For each test case, run your adaptive PSO and record the final best cost value $\\tilde{F}(g(T))$ as a real number rounded to $4$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, for example: $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$.\n- Each list element must be a float. No units are involved because the objective and output are dimensionless by construction.\n\nAll mathematics in your derivation and implementation description must strictly adhere to the definitions above. The final answer must be a complete, runnable program that implements your derived method and produces the output in the exact format specified. No user input or external files are allowed.",
            "solution": "The problem of designing an adaptive Particle Swarm Optimization (PSO) algorithm for a surrogate battery design problem is a valid, well-posed, and scientifically grounded task in computational optimization and engineering. The problem provides all necessary definitions, constants, and test cases for a complete and verifiable solution. We will first derive the adaptive mechanism as required, then implement the full algorithm.\n\n### Derivation of the Adaptive Inertia Weight Mechanism\n\nThe foundation of our adaptive PSO is the canonical set of update equations. For each particle $i$ at iteration $t$, the velocity $v_i$ and position $x_i$ are updated as follows:\n$$v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$$\n$$x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$$\nwhere $w_t$ is the adaptive inertia weight we aim to derive. $p_i(t)$ is the personal best position of particle $i$, and $g(t)$ is the global best position found by the swarm so far. The coefficients $c_1$ and $c_2$ are acceleration constants, and $r_1(t), r_2(t)$ are random numbers sampled from a uniform distribution $U(0,1)$.\n\nThe goal is to dynamically adjust $w_t$ based on the search progress to balance exploration (searching new areas) and exploitation (refining existing good solutions). A high inertia weight encourages exploration, while a low inertia weight favors exploitation.\n\n**1. Online Progress Signal ($\\Delta_t$)**\nWe define a progress signal based on the improvement of the global best cost at each iteration. Let $\\tilde{F}(x)$ be the evaluated cost function, which we seek to minimize. The global best cost at iteration $t$ is $\\tilde{F}(g(t))$. The improvement $\\Delta_t$ from iteration $t-1$ to $t$ is defined as the non-negative change in this cost:\n$$\\Delta_t = \\max\\{0, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$$\nThis signal is positive when a better solution is found and zero otherwise.\n\n**2. Short-Term and Long-Term Progress Averages ($S_t, L_t$)**\nTo distinguish between recent performance and the long-term trend, we employ two Exponential Moving Averages (EMAs) of the progress signal $\\Delta_t$. The EMA is chosen for its computational efficiency and causal nature.\nThe short-term average, $S_t$, uses a larger smoothing factor $\\alpha_s$ to be more responsive to recent changes in progress.\n$$S_t = \\alpha_s \\Delta_t + (1 - \\alpha_s) S_{t-1}$$\nThe long-term average, $L_t$, uses a smaller smoothing factor $\\alpha_\\ell$ (where $\\alpha_\\ell < \\alpha_s$) to capture the broader trend of improvement.\n$$L_t = \\alpha_\\ell \\Delta_t + (1 - \\alpha_\\ell) L_{t-1}$$\nBoth averages are initialized to zero, i.e., $S_0 = 0$ and $L_0 = 0$.\n\n**3. Dimensionless Progress Ratio ($R_t$)**\nWe form a dimensionless ratio, $R_t$, to quantify the state of the search. This ratio compares the short-term progress to the long-term progress:\n$$R_t = \\frac{S_t + \\epsilon}{L_t + \\epsilon}$$\nA small positive constant $\\epsilon$ (e.g., $10^{-9}$) is added to both the numerator and denominator to ensure numerical stability, particularly at the beginning of the search when both $S_t$ and $L_t$ can be zero.\n- If $R_t > 1$, it implies that recent progress is greater than the long-term average, indicating the swarm is making good progress (exploitation may be beneficial).\n- If $R_t < 1$, it implies that recent progress has fallen below the long-term average, suggesting the search might be stagnating (exploration may be needed).\n\n**4. Inertia Weight Mapping ($w_t = \\mathcal{W}(R_t)$)**\nThe final step is to create a mapping from the progress ratio $R_t$ to the inertia weight $w_t$. The mapping must satisfy two criteria:\n- It must be monotone, mapping $R_t \\in [0, \\infty)$ to $w_t \\in [w_{\\min}, w_{\\max}]$.\n- It must increase $w_t$ when $R_t$ is small (stagnation) and decrease $w_t$ when $R_t$ is large (strong progress). This implies $\\mathcal{W}$ must be a monotonically decreasing function of $R_t$.\n\nA suitable function that meets these requirements and incorporates the provided test parameters $\\kappa$ and $r_0$ is the inverted logistic (sigmoid) function. We define the mapping as:\n$$w_t = \\mathcal{W}(R_t) = w_{\\min} + (w_{\\max} - w_{\\min}) \\cdot \\frac{1}{1 + \\exp\\left(\\kappa (R_t - r_0)\\right)}$$\nLet's analyze this mapping:\n- The parameter $r_0$ acts as a reference or pivot point for the progress ratio. When $R_t = r_0$, the exponential term is $\\exp(0) = 1$, the fraction becomes $1/2$, and $w_t$ is set to the midpoint of its range: $w_t = w_{\\min} + 0.5(w_{\\max} - w_{\\min})$.\n- The parameter $\\kappa > 0$ controls the steepness of the transition. A larger $\\kappa$ results in a more aggressive switch between exploration and exploitation around the pivot $r_0$.\n- As $R_t \\to \\infty$ (strong progress), the exponential term goes to infinity, the fraction approaches $0$, and $w_t \\to w_{\\min}$. This correctly reduces inertia to encourage exploitation of the promising region.\n- As $R_t \\to 0$ (stagnation), the exponential term approaches $\\exp(-\\kappa r_0)$, the fraction approaches $(1+\\exp(-\\kappa r_0))^{-1}$, which is close to $1$, and thus $w_t$ approaches $w_{\\max}$. This correctly increases inertia to promote exploration and escape the local minimum.\n\nThe final value of $w_t$ is clipped to the interval $[w_{\\min}, w_{\\max}]$ to strictly enforce the bounds, although the chosen function naturally keeps the value within this range. The initial inertia weight for the first iteration, $w_0$, is set to $w_{\\max}$ to encourage broad exploration at the start.\n\n### The Surrogate Battery Design Problem\n\nThe optimization is performed on the four-dimensional vector $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$ within the bounds:\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\nThe evaluated cost to be minimized is $\\tilde{F}(x) = F(x;k_E,k_R) + n$, where $n \\sim \\mathcal{N}(0,\\sigma^2)$ is Gaussian noise and the base cost is:\n$$F(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi)$$\n\nThe implementation will follow the logic derived above, executing the adaptive PSO for each test case specified in the problem statement.",
            "answer": "```python\nimport numpy as np\n\ndef run_adaptive_pso(\n    N, T, alpha_s, alpha_ell, w_min, w_max, kappa, r_0,\n    sigma, k_E, k_R, seed, init_same\n):\n    \"\"\"\n    Runs the adaptive Particle Swarm Optimization algorithm for one test case.\n\n    Args:\n        N (int): Number of particles.\n        T (int): Number of iterations.\n        alpha_s (float): Short-term EMA coefficient.\n        alpha_ell (float): Long-term EMA coefficient.\n        w_min (float): Minimum inertia weight.\n        w_max (float): Maximum inertia weight.\n        kappa (float): Steepness parameter for inertia mapping.\n        r_0 (float): Pivot parameter for inertia mapping.\n        sigma (float): Standard deviation of evaluation noise.\n        k_E (float): Energy parameter for the objective function.\n        k_R (float): Resistance parameter for the objective function.\n        seed (int): Seed for the pseudo-random number generator.\n        init_same (bool): If True, all particles start at the center of the search space.\n\n    Returns:\n        float: The best cost found by the algorithm.\n    \"\"\"\n    # Constants and parameters from the problem statement\n    DIMS = 4\n    C1 = 1.4\n    C2 = 1.4\n    EPSILON = 1e-9  # For numerical stability in progress ratio\n\n    # Search space bounds\n    bounds_lo = np.array([0.3, 0.3, 0.2, 0.4])\n    bounds_hi = np.array([0.7, 0.7, 0.5, 1.0])\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    def objective_function(x_vec):\n        \"\"\"Calculates the surrogate cost for a given design vector x.\"\"\"\n        f_c, f_a, phi, tau = x_vec[0], x_vec[1], x_vec[2], x_vec[3]\n        term_R = k_R * tau / (phi**1.5)\n        term_E = k_E * (f_c + f_a) * (1.0 - 0.5 * tau) * (1.0 - 0.4 * phi)\n        cost = term_R - term_E\n        noise = rng.normal(0, sigma) if sigma > 0 else 0.0\n        return cost + noise\n\n    # Initialization (t=0)\n    if init_same:\n        mid_point = (bounds_lo + bounds_hi) / 2.0\n        positions = np.tile(mid_point, (N, 1))\n    else:\n        positions = rng.uniform(low=bounds_lo, high=bounds_hi, size=(N, DIMS))\n    \n    velocities = np.zeros((N, DIMS))\n    \n    # Evaluate initial positions\n    costs = np.array([objective_function(p) for p in positions])\n    \n    # Initialize personal and global bests\n    pbest_positions = np.copy(positions)\n    pbest_costs = np.copy(costs)\n    \n    min_cost_idx = np.argmin(pbest_costs)\n    gbest_position = np.copy(pbest_positions[min_cost_idx])\n    gbest_cost = pbest_costs[min_cost_idx]\n    \n    # Initialize adaptive mechanism variables\n    short_term_avg = 0.0\n    long_term_avg = 0.0\n    w = w_max  # Start with high inertia for exploration\n    prev_gbest_cost = gbest_cost\n\n    # Main PSO loop for T iterations\n    for _ in range(T):\n        # Update velocities and positions for all particles (vectorized)\n        r1 = rng.random(size=(N, DIMS))\n        r2 = rng.random(size=(N, DIMS))\n        \n        cognitive_comp = C1 * r1 * (pbest_positions - positions)\n        social_comp = C2 * r2 * (gbest_position - positions)\n        \n        velocities = w * velocities + cognitive_comp + social_comp\n        positions = positions + velocities\n        \n        # Apply bounds (clipping)\n        positions = np.clip(positions, bounds_lo, bounds_hi)\n        \n        # Evaluate new positions\n        costs = np.array([objective_function(p) for p in positions])\n        \n        # Update personal bests (strict improvement)\n        improved_mask = costs < pbest_costs\n        pbest_positions[improved_mask] = positions[improved_mask]\n        pbest_costs[improved_mask] = costs[improved_mask]\n        \n        # Update global best (strict improvement)\n        min_pbest_idx = np.argmin(pbest_costs)\n        if pbest_costs[min_pbest_idx] < gbest_cost:\n            gbest_cost = pbest_costs[min_pbest_idx]\n            gbest_position = pbest_positions[min_pbest_idx]\n\n        # --- Adaptive Inertia Weight Update ---\n        # 1. Calculate progress signal\n        delta = max(0, prev_gbest_cost - gbest_cost)\n        prev_gbest_cost = gbest_cost\n        \n        # 2. Update moving averages\n        short_term_avg = alpha_s * delta + (1.0 - alpha_s) * short_term_avg\n        long_term_avg = alpha_ell * delta + (1.0 - alpha_ell) * long_term_avg\n        \n        # 3. Calculate progress ratio\n        progress_ratio = (short_term_avg + EPSILON) / (long_term_avg + EPSILON)\n        \n        # 4. Calculate new inertia weight using the derived mapping\n        sigmoid_term = 1.0 / (1.0 + np.exp(kappa * (progress_ratio - r_0)))\n        w_new = w_min + (w_max - w_min) * sigmoid_term\n        w = np.clip(w_new, w_min, w_max)\n        \n    return gbest_cost\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the adaptive PSO algorithm.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {\"N\": 30, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.90, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.01, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 42, \"init_same\": False},\n        # Case 2\n        {\"N\": 20, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.02, \"w_min\": 0.40, \n         \"w_max\": 0.95, \"kappa\": 5.0, \"r_0\": 1.2, \"sigma\": 0.00, \"k_E\": 0.50, \n         \"k_R\": 0.35, \"seed\": 123, \"init_same\": False},\n        # Case 3\n        {\"N\": 10, \"T\": 80, \"alpha_s\": 0.25, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.00, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 7, \"init_same\": True},\n        # Case 4\n        {\"N\": 40, \"T\": 150, \"alpha_s\": 0.15, \"alpha_ell\": 0.03, \"w_min\": 0.35, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 0.8, \"sigma\": 0.05, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 2024, \"init_same\": False},\n    ]\n\n    results = []\n    for params in test_cases:\n        final_cost = run_adaptive_pso(**params)\n        results.append(round(final_cost, 4))\n        \n    # Print the results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}