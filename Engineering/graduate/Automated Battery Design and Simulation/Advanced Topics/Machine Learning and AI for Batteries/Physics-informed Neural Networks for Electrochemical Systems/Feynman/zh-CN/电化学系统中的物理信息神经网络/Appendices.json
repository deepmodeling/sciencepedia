{
    "hands_on_practices": [
        {
            "introduction": "在电化学系统中，许多关键现象发生在极小的空间尺度上，例如电极/电解质界面处的双电层或反应锋面，这导致了物理场（如电势或浓度）的急剧变化。标准的神经网络由于其“谱偏差”（spectral bias），天然地倾向于学习低频函数，因此在捕捉这些高频或尖锐的梯度时会遇到困难。本实践将向您介绍一种强大的技术——傅里叶特征嵌入，它通过将输入坐标映射到更高维度的正弦和余弦特征空间，显著增强了模型捕捉局部高频变化的能力，从而更准确地近似复杂解。",
            "id": "3940605",
            "problem": "考虑一个沿着厚度坐标的一维电解质域，无量纲化为 $\\xi \\in [0,1]$。设电解质电位表示为 $\\phi_e(\\xi)$，电解质离子电导率取为常数，无量纲单位下等于 $\\kappa_e = 1$。根据电荷守恒和欧姆定律，在一维空间中，控制方程简化为二阶线性常微分方程\n$$\\frac{d^2 \\phi_e}{d \\xi^2} = s(\\xi),$$\n其在 $\\xi = 0$ 和 $\\xi = 1$ 处服从狄利克雷边界条件。为了生成一个能够产生急剧梯度的物理一致源项 $s(\\xi)$，我们定义一个具有局部过渡层的基准真实电位，\n$$\\phi_e^{\\mathrm{true}}(\\xi) = V_0 + (V_1 - V_0)\\,\\xi + A\\,\\tanh\\left(\\frac{\\xi - \\xi_0}{\\varepsilon}\\right),$$\n其中 $V_0$ 和 $V_1$ 是边界电位，$A$ 是局部特征的振幅，$\\xi_0$ 是过渡区的中心，$\\varepsilon$ 控制过渡层的宽度。然后，源项设置为\n$$s(\\xi) = \\frac{d^2 \\phi_e^{\\mathrm{true}}}{d \\xi^2}(\\xi),$$\n以确保 $\\phi_e^{\\mathrm{true}}(\\xi)$ 是该边值问题的精确解，其边界条件为 $\\phi_e(0) = \\phi_e^{\\mathrm{true}}(0)$ 和 $\\phi_e(1) = \\phi_e^{\\mathrm{true}}(1)$。\n\n您必须使用两种物理信息模型来近似 $\\phi_e(\\xi)$，并比较它们的准确性：\n- 一个基准多项式嵌入 $\\gamma_P(\\xi) = [\\xi^0, \\xi^1, \\xi^2, \\ldots, \\xi^P]$，其中 $P$ 是一个正整数。模型为 $\\hat{\\phi}_P(\\xi) = \\mathbf{w}_P^\\top \\gamma_P(\\xi)$。\n- 一个旨在捕捉急剧梯度的傅里叶特征嵌入 $\\gamma_F(\\xi) = [1, \\xi, \\sin(2\\pi \\omega_1 \\xi), \\cos(2\\pi \\omega_1 \\xi), \\ldots, \\sin(2\\pi \\omega_K \\xi), \\cos(2\\pi \\omega_K \\xi)]$，其中 $\\omega_k = k\\,\\omega_0$ 对于 $k \\in \\{1,2,\\ldots,K\\}$，基频 $\\omega_0 > 0$。模型为 $\\hat{\\phi}_F(\\xi) = \\mathbf{w}_F^\\top \\gamma_F(\\xi)$。\n\n两种模型都必须通过最小化一个物理信息目标函数进行训练，该目标函数惩罚内部配置点上的控制方程残差、在 $\\xi = 0$ 和 $\\xi = 1$ 处的边界不匹配，以及权重的 $\\ell_2$ 正则化。设配置点集为在 $(0,1)$ 内均匀分布的 $\\{\\xi_i\\}_{i=1}^{N_c}$，边界权重和残差权重分别为 $w_b > 0$ 和 $w_r > 0$。对于一个通用嵌入 $\\gamma(\\xi)$，训练问题是关于权重向量 $\\mathbf{w}$ 的岭正则化最小二乘问题：\n$$\\min_{\\mathbf{w}} \\left( \\sum_{i=1}^{N_c} w_r \\left( \\frac{d^2}{d \\xi^2} \\big( \\mathbf{w}^\\top \\gamma(\\xi_i) \\big) - s(\\xi_i) \\right)^2 + w_b \\left( \\mathbf{w}^\\top \\gamma(0) - \\phi_e^{\\mathrm{true}}(0) \\right)^2 + w_b \\left( \\mathbf{w}^\\top \\gamma(1) - \\phi_e^{\\mathrm{true}}(1) \\right)^2 + \\lambda \\|\\mathbf{w}\\|_2^2 \\right),$$\n其中 $\\lambda > 0$ 是正则化参数。请注意，对于傅里叶嵌入，$\\sin$ 和 $\\cos$ 分量关于 $\\xi$ 的二阶导数是原始 $\\sin$ 或 $\\cos$ 分量乘以 $-\\left(2\\pi \\omega_k\\right)^2$，而常数项和线性项的二阶导数为零；对于多项式嵌入，$\\xi^n$ 的二阶导数在 $n \\geq 2$ 时为 $n(n-1)\\,\\xi^{n-2}$，否则为零。\n\n将均匀评估网格 $\\{\\xi_j\\}_{j=1}^{N_{\\mathrm{eval}}}$ 上的相对 $\\ell_2$ 近似误差定义为\n$$\\mathcal{E}(\\hat{\\phi}) = \\sqrt{\\frac{\\sum_{j=1}^{N_{\\mathrm{eval}}} \\left( \\hat{\\phi}(\\xi_j) - \\phi_e^{\\mathrm{true}}(\\xi_j) \\right)^2}{\\sum_{j=1}^{N_{\\mathrm{eval}}} \\left( \\phi_e^{\\mathrm{true}}(\\xi_j) \\right)^2}},$$\n该值是无量纲的。对于每个测试用例，计算改进因子\n$$I = \\frac{\\mathcal{E}(\\hat{\\phi}_P)}{\\mathcal{E}(\\hat{\\phi}_F)},$$\n因此 $I > 1$ 表明傅里叶特征嵌入相对于多项式基准提高了准确性。\n\n实现一个完整的、可运行的程序，该程序构建两种嵌入，通过求解岭正则化正规方程来训练相应的物理信息模型，评估相对 $\\ell_2$ 误差，并报告每个测试用例的改进因子。使用以下测试套件，它涵盖了一个典型案例、急剧梯度案例以及一个傅里叶特征不足的边缘案例：\n- 测试用例 1：$A = 0.2$，$\\varepsilon = 0.03$，$\\xi_0 = 0.5$， $V_0 = 0.0$， $V_1 = 0.1$，$K = 20$， $\\omega_0 = 3.0$，$P = 7$，$N_c = 200$，$N_{\\mathrm{eval}} = 1000$，$w_r = 1.0$，$w_b = 1000.0$，$\\lambda = 10^{-6}$。\n- 测试用例 2：$A = 0.2$，$\\varepsilon = 0.005$，$\\xi_0 = 0.5$， $V_0 = 0.0$， $V_1 = 0.1$，$K = 60$， $\\omega_0 = 5.0$，$P = 11$，$N_c = 400$，$N_{\\mathrm{eval}} = 1200$，$w_r = 1.0$，$w_b = 1000.0$，$\\lambda = 10^{-6}$。\n- 测试用例 3：$A = 0.2$，$\\varepsilon = 0.10$，$\\xi_0 = 0.5$， $V_0 = 0.0$， $V_1 = 0.1$，$K = 8$， $\\omega_0 = 2.0$，$P = 5$，$N_c = 100$，$N_{\\mathrm{eval}} = 800$，$w_r = 1.0$，$w_b = 500.0$，$\\lambda = 10^{-6}$。\n- 测试用例 4 (傅里叶特征不足的边缘案例)：$A = 0.2$，$\\varepsilon = 0.02$，$\\xi_0 = 0.5$， $V_0 = 0.0$， $V_1 = 0.1$，$K = 3$， $\\omega_0 = 1.0$，$P = 9$，$N_c = 200$，$N_{\\mathrm{eval}} = 1000$，$w_r = 1.0$，$w_b = 1000.0$，$\\lambda = 10^{-6}$。\n\n您的程序应生成单行输出，其中包含四个测试用例的改进因子，格式为方括号内以逗号分隔的列表（例如，$[\\mathrm{I}_1,\\mathrm{I}_2,\\mathrm{I}_3,\\mathrm{I}_4]$）。改进因子是无量纲的浮点数。不应产生任何其他输出。",
            "solution": "该问题要求使用两种不同的物理信息线性模型来近似一个一维二阶线性常微分方程（ODE）的解。需要比较这两种模型的准确性，其中一个基于多项式嵌入，另一个基于傅里叶特征嵌入。该问题是适定的，并为其解决方案提供了完整的规范。我们将首先将训练任务表述为一个标准的岭正则化线性最小二乘问题，然后为每个模型构建必要的矩阵，求解最优模型权重，最后评估近似误差。\n\n电解质电位 $\\phi_e(\\xi)$ 的控制常微分方程由下式给出：\n$$\n\\frac{d^2 \\phi_e}{d \\xi^2} = s(\\xi), \\quad \\xi \\in [0, 1]\n$$\n在 $\\xi=0$ 和 $\\xi=1$ 处具有狄利克雷边界条件。源项 $s(\\xi)$ 是从一个已知的基准真实解 $\\phi_e^{\\mathrm{true}}(\\xi)$ 构造的，以方便进行误差分析：\n$$\n\\phi_e^{\\mathrm{true}}(\\xi) = V_0 + (V_1 - V_0)\\,\\xi + A\\,\\tanh\\left(\\frac{\\xi - \\xi_0}{\\varepsilon}\\right)\n$$\n源项是该函数的二阶导数：\n$$\ns(\\xi) = \\frac{d^2 \\phi_e^{\\mathrm{true}}}{d \\xi^2}(\\xi) = -\\frac{2A}{\\varepsilon^2} \\mathrm{sech}^2\\left(\\frac{\\xi - \\xi_0}{\\varepsilon}\\right) \\tanh\\left(\\frac{\\xi - \\xi_0}{\\varepsilon}\\right)\n$$\n边界条件被设置为与基准真实值匹配：$\\phi_e(0) = \\phi_e^{\\mathrm{true}}(0)$ 和 $\\phi_e(1) = \\phi_e^{\\mathrm{true}}(1)$。\n\n一个通用线性模型将电位近似为基函数 $\\gamma_m(\\xi)$ 的加权和：\n$$\n\\hat{\\phi}(\\xi) = \\mathbf{w}^\\top \\gamma(\\xi) = \\sum_{m=1}^{M} w_m \\gamma_m(\\xi)\n$$\n其中 $\\gamma(\\xi)$ 是一个包含 $M$ 个基函数的列向量，$\\mathbf{w}$ 是相应权重的向量。权重通过最小化一个复合目标函数来确定，该函数包括偏微分方程（PDE）残差、边界条件不匹配和 $\\ell_2$ 正则化：\n$$\nL(\\mathbf{w}) = w_r \\sum_{i=1}^{N_c} \\left( \\frac{d^2 \\hat{\\phi}}{d \\xi^2}(\\xi_i) - s(\\xi_i) \\right)^2 + w_b \\left( \\hat{\\phi}(0) - \\phi_e^{\\mathrm{true}}(0) \\right)^2 + w_b \\left( \\hat{\\phi}(1) - \\phi_e^{\\mathrm{true}}(1) \\right)^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\n这是一个标准的岭回归问题，可以表示为矩阵形式 $\\min_{\\mathbf{w}} \\|\\mathbf{A}\\mathbf{w} - \\mathbf{b}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2$。最优权重向量 $\\mathbf{w}$ 通过求解正规方程得到：\n$$\n(\\mathbf{A}^\\top \\mathbf{A} + \\lambda \\mathbf{I}) \\mathbf{w} = \\mathbf{A}^\\top \\mathbf{b}\n$$\n其中 $\\mathbf{I}$ 是大小为 $M \\times M$ 的单位矩阵。\n\n系统矩阵 $\\mathbf{A}$ 和目标向量 $\\mathbf{b}$ 是通过汇集残差项和边界项的贡献来构建的。设 $\\gamma''(\\xi)$ 为基函数的二阶导数向量。大小为 $(N_c + 2) \\times M$ 的矩阵 $\\mathbf{A}$ 和大小为 $(N_c + 2) \\times 1$ 的向量 $\\mathbf{b}$ 分别是：\n$$\n\\mathbf{A} = \\begin{pmatrix}\n\\sqrt{w_r} (\\gamma''(\\xi_1))^\\top \\\\\n\\vdots \\\\\n\\sqrt{w_r} (\\gamma''(\\xi_{N_c}))^\\top \\\\\n\\sqrt{w_b} (\\gamma(0))^\\top \\\\\n\\sqrt{w_b} (\\gamma(1))^\\top\n\\end{pmatrix}, \\quad\n\\mathbf{b} = \\begin{pmatrix}\n\\sqrt{w_r} s(\\xi_1) \\\\\n\\vdots \\\\\n\\sqrt{w_r} s(\\xi_{N_c}) \\\\\n\\sqrt{w_b} \\phi_e^{\\mathrm{true}}(0) \\\\\n\\sqrt{w_b} \\phi_e^{\\mathrm{true}}(1)\n\\end{pmatrix}\n$$\n我们现在详细说明这两个模型的构建方法。\n\n**模型 1：多项式嵌入**\n基函数是单项式 $\\gamma_{P,n}(\\xi) = \\xi^{n-1}$，其中 $n=1, \\ldots, P+1$。基的大小为 $M_P = P+1$。\n基函数向量为 $\\gamma_P(\\xi) = [\\xi^0, \\xi^1, \\dots, \\xi^P]^\\top$。\n二阶导数向量为 $\\gamma_P''(\\xi) = [0, 0, 2\\xi^0, 6\\xi^1, \\dots, P(P-1)\\xi^{P-2}]^\\top$。\n这些表达式用于构建系统矩阵 $\\mathbf{A}_P$ 并求解权重 $\\mathbf{w}_P$。\n\n**模型 2：傅里叶特征嵌入**\n基由一个常数项、一个线性项以及 $K$ 对正弦和余弦函数组成。基的大小为 $M_F = 2 + 2K$。基函数向量为 $\\gamma_F(\\xi) = [1, \\xi, \\sin(2\\pi \\omega_1 \\xi), \\cos(2\\pi \\omega_1 \\xi), \\ldots, \\sin(2\\pi \\omega_K \\xi), \\cos(2\\pi \\omega_K \\xi)]^\\top$，其中 $\\omega_k = k \\omega_0$。\n相应的二阶导数对于常数项和线性项为零，对于三角函数项为：\n$\\frac{d^2}{d\\xi^2}\\sin(2\\pi \\omega_k \\xi) = -(2\\pi \\omega_k)^2 \\sin(2\\pi \\omega_k \\xi)$\n$\\frac{d^2}{d\\xi^2}\\cos(2\\pi \\omega_k \\xi) = -(2\\pi \\omega_k)^2 \\cos(2\\pi \\omega_k \\xi)$\n这些关系用于构建系统矩阵 $\\mathbf{A}_F$ 并求解权重 $\\mathbf{w}_F$。\n\n在为每个测试用例找到最优权重 $\\mathbf{w}_P$ 和 $\\mathbf{w}_F$ 后，我们在一个精细的评估网格 $\\{\\xi_j\\}_{j=1}^{N_{\\mathrm{eval}}}$ 上预测电位 $\\hat{\\phi}_P(\\xi)$ 和 $\\hat{\\phi}_F(\\xi)$。为每个模型计算相对 $\\ell_2$ 近似误差：\n$$\n\\mathcal{E}(\\hat{\\phi}) = \\sqrt{\\frac{\\sum_{j=1}^{N_{\\mathrm{eval}}} \\left( \\hat{\\phi}(\\xi_j) - \\phi_e^{\\mathrm{true}}(\\xi_j) \\right)^2}{\\sum_{j=1}^{N_{\\mathrm{eval}}} \\left( \\phi_e^{\\mathrm{true}}(\\xi_j) \\right)^2}}\n$$\n最终的度量指标是改进因子 $I = \\mathcal{E}(\\hat{\\phi}_P) / \\mathcal{E}(\\hat{\\phi}_F)$，它量化了傅里叶特征模型相对于多项式基准的性能增益。值 $I > 1$ 表示有所改进。\n\n实现将遍历每个测试用例，为多项式和傅里叶模型构建并求解线性系统，计算它们各自的误差，并报告最终的改进因子。",
            "answer": "```python\n# The final answer must be a single, complete, standalone program.\n# Execution Environment: Python 3.12, numpy 1.23.5\n# No other libraries outside the Python standard library are permitted.\n\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the physics-informed regression problem for polynomial and Fourier embeddings\n    and computes the improvement factor for each test case.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: Typical sharp gradient\n        {'A': 0.2, 'eps': 0.03, 'xi0': 0.5, 'V0': 0.0, 'V1': 0.1, 'K': 20, 'omega0': 3.0, 'P': 7,\n         'Nc': 200, 'N_eval': 1000, 'wr': 1.0, 'wb': 1000.0, 'lambda_reg': 1e-6},\n        # Case 2: Very sharp gradient, more features\n        {'A': 0.2, 'eps': 0.005, 'xi0': 0.5, 'V0': 0.0, 'V1': 0.1, 'K': 60, 'omega0': 5.0, 'P': 11,\n         'Nc': 400, 'N_eval': 1200, 'wr': 1.0, 'wb': 1000.0, 'lambda_reg': 1e-6},\n        # Case 3: Smoother gradient\n        {'A': 0.2, 'eps': 0.10, 'xi0': 0.5, 'V0': 0.0, 'V1': 0.1, 'K': 8, 'omega0': 2.0, 'P': 5,\n         'Nc': 100, 'N_eval': 800, 'wr': 1.0, 'wb': 500.0, 'lambda_reg': 1e-6},\n        # Case 4: Edge case with insufficient Fourier features\n        {'A': 0.2, 'eps': 0.02, 'xi0': 0.5, 'V0': 0.0, 'V1': 0.1, 'K': 3, 'omega0': 1.0, 'P': 9,\n         'Nc': 200, 'N_eval': 1000, 'wr': 1.0, 'wb': 1000.0, 'lambda_reg': 1e-6},\n    ]\n\n    improvement_factors = []\n\n    for case in test_cases:\n        A, eps, xi0, V0, V1 = case['A'], case['eps'], case['xi0'], case['V0'], case['V1']\n        K, omega0, P = case['K'], case['omega0'], case['P']\n        Nc, N_eval = case['Nc'], case['N_eval']\n        wr, wb, lambda_reg = case['wr'], case['wb'], case['lambda_reg']\n\n        xi_c = np.linspace(0, 1, Nc + 2)[1:-1]\n        xi_eval = np.linspace(0, 1, N_eval)\n\n        def phi_true(xi):\n            return V0 + (V1 - V0) * xi + A * np.tanh((xi - xi0) / eps)\n\n        def source(xi):\n            u = (xi - xi0) / eps\n            sech_u = 1.0 / np.cosh(u)\n            return -2.0 * A / (eps**2) * (sech_u**2) * np.tanh(u)\n\n        phi_true_eval = phi_true(xi_eval)\n        phi_true_0 = phi_true(0.0)\n        phi_true_1 = phi_true(1.0)\n        s_c = source(xi_c)\n\n        def get_model_error(basis_type):\n            if basis_type == 'poly':\n                M = P + 1\n                n = np.arange(M)\n                gamma_eval = np.power.outer(xi_eval, n)\n                coeffs = n * (n - 1)\n                gamma_ddot_c = coeffs[None, :] * np.power.outer(xi_c, n - 2)\n                gamma_ddot_c[:, :2] = 0.0\n                gamma_0 = np.power.outer(np.array([0.0]), n).flatten()\n                gamma_1 = np.power.outer(np.array([1.0]), n).flatten()\n\n            elif basis_type == 'fourier':\n                M = 2 + 2 * K\n                omegas = omega0 * np.arange(1, K + 1)\n\n                def build_gamma(xi_grid):\n                    N_grid = len(xi_grid)\n                    gamma = np.zeros((N_grid, M))\n                    gamma[:, 0] = 1.0\n                    gamma[:, 1] = xi_grid\n                    if K > 0:\n                        arg_matrix = 2 * np.pi * xi_grid[:, None] * omegas[None, :]\n                        gamma[:, 2::2] = np.sin(arg_matrix)\n                        gamma[:, 3::2] = np.cos(arg_matrix)\n                    return gamma\n\n                def build_gamma_ddot(xi_grid):\n                    N_grid = len(xi_grid)\n                    gamma_ddot = np.zeros((N_grid, M))\n                    if K > 0:\n                        arg_matrix = 2 * np.pi * xi_grid[:, None] * omegas[None, :]\n                        factors = -(2 * np.pi * omegas)**2\n                        gamma_ddot[:, 2::2] = factors * np.sin(arg_matrix)\n                        gamma_ddot[:, 3::2] = factors * np.cos(arg_matrix)\n                    return gamma_ddot\n                \n                gamma_eval = build_gamma(xi_eval)\n                gamma_ddot_c = build_gamma_ddot(xi_c)\n                gamma_0 = build_gamma(np.array([0.0])).flatten()\n                gamma_1 = build_gamma(np.array([1.0])).flatten()\n            else:\n                raise ValueError(\"Unknown basis type\")\n\n            sqrt_wr, sqrt_wb = np.sqrt(wr), np.sqrt(wb)\n            A_res = sqrt_wr * gamma_ddot_c\n            A_b0 = sqrt_wb * gamma_0\n            A_b1 = sqrt_wb * gamma_1\n            A_mat = np.vstack([A_res, A_b0.reshape(1, -1), A_b1.reshape(1, -1)])\n            \n            b_res = sqrt_wr * s_c\n            b_b0 = sqrt_wb * phi_true_0\n            b_b1 = sqrt_wb * phi_true_1\n            b_vec = np.concatenate([b_res, [b_b0], [b_b1]])\n\n            lhs = A_mat.T @ A_mat + lambda_reg * np.identity(M)\n            rhs = A_mat.T @ b_vec\n            w = np.linalg.solve(lhs, rhs)\n\n            phi_hat_eval = gamma_eval @ w\n            numerator = np.sum((phi_hat_eval - phi_true_eval)**2)\n            denominator = np.sum(phi_true_eval**2)\n            \n            if denominator == 0:\n                return 0.0 if numerator == 0.0 else np.inf\n            return np.sqrt(numerator / denominator)\n\n        error_poly = get_model_error('poly')\n        error_fourier = get_model_error('fourier')\n        \n        if error_fourier > 0:\n            improvement = error_poly / error_fourier\n        else:\n            improvement = np.inf if error_poly > 1e-12 else 1.0\n        \n        improvement_factors.append(improvement)\n\n    print(f\"[{','.join(f'{f:.8f}' for f in improvement_factors)}]\")\n\n# Self-contained execution\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "仅仅依靠偏微分方程（PDE）残差项来训练物理信息神经网络（PINN），虽然能保证模型在一定程度上遵循控制方程，但并不能自动确保其预测结果在物理上始终是合理的。例如，浓度不应为负，固相中的锂嵌入浓度也不能超过其物理上限。本实践将演示如何通过构建光滑的惩罚函数（如 softplus 函数）来将这些不等式约束融入到损失函数中，从而引导训练过程，确保模型的输出始终保持在物理允许的范围之内。",
            "id": "3940640",
            "problem": "设计并实现一个程序，为锂离子电池（LIB）电极-电解质系统构建物理信息神经网络（PINN）的损失项，以便在训练期间强制执行物理上允许的状态。该 PINN 在时空配置点上进行训练，并输出预测的场。目标是定义三个光滑的损失项，以施加以下基于物理的约束：电解质浓度的非负性、固相锂浓度的上限，以及对进入析锂状态的偏移进行惩罚。该程序必须为指定的预测值测试套件计算这些损失，并返回每个测试用例的总损失。\n\n使用以下情境作为基本依据：\n\n- 质量守恒意味着电解质浓度为非负，因此 $c_e \\ge 0$。\n- 主体固体的嵌入容量是有限的，这意味着存在一个最大允许固相浓度 $c_s \\le c_{s,\\max}$。\n- 反应热力学和动力学意味着当界面过电位 $\\eta$ 驱动还原分支超出嵌入偏好时，存在析锂风险。特别地，Butler-Volmer (BV) 关系中 $\\eta$ 的符号和大小可用于诊断风险；$\\eta$ 的负值会增加金属沉积的趋势。使用符合标准电化学惯例的反应过电位 $\\eta$ 的定义作为惩罚析锂的驱动变量。\n\n您的程序必须：\n\n- 推导并实现光滑、可微的惩罚项，以近似表示违反约束的指示函数。对于通用的光滑铰链损失，使用经典的 softplus 函数，其定义为 $\\mathrm{softplus}(x) = \\ln\\left(1 + e^{x}\\right)$，它近似于 $\\max(0,x)$，但对所有 $x$ 保持可微。\n- 将三个损失项定义为：\n  1. 电解质非负性惩罚：\n     $$L_{e}^{\\ge 0} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[\\mathrm{softplus}\\left(-c_{e,i}\\right)\\right]^2.$$\n  2. 固相浓度上限惩罚：\n     $$L_{s}^{\\le c_{s,\\max}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[\\mathrm{softplus}\\left(c_{s,i} - c_{s,\\max}\\right)\\right]^2.$$\n  3. 由电解质耗尽加权的析锂惩罚：\n     $$w_i = 1 + \\exp\\left(-\\frac{c_{e,i}}{c_{e,\\mathrm{ref}}}\\right), \\quad L_{\\mathrm{plate}} = \\frac{1}{N} \\sum_{i=1}^{N} w_i \\left[\\mathrm{softplus}\\left(-\\eta_i\\right)\\right]^2.$$\n- 将各项损失汇总为总损失：\n  $$L_{\\mathrm{total}} = \\alpha \\, L_{e}^{\\ge 0} + \\beta \\, L_{s}^{\\le c_{s,\\max}} + \\gamma \\, L_{\\mathrm{plate}},$$\n  权重为 $\\alpha = 1$、$\\beta = 1$、$\\gamma = 1$。\n\n所有量，包括 $c_e$、$c_s$、$c_{s,\\max}$、$\\eta$ 和 $c_{e,\\mathrm{ref}}$，都必须被视作实值场或参数。电解质浓度 $c_e$ 和固相浓度 $c_s$ 必须以 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$ 表示，过电位 $\\eta$ 必须以 $\\mathrm{V}$ 表示。最终的损失值为无量纲实数。您的程序必须使用下面指定的测试套件，并以浮点数形式生成最终输出，四舍五入到六位小数。\n\n参数值测试套件（数组是每个配置点的预测值；数组维度为 $N$，其中 $N$ 是每种情况下数组的长度）：\n\n- 情况 1（标称工况；所有约束近似满足）：\n  - $c_e$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[1000, 950, 1100, 1020, 980, 1010]$,\n  - $c_s$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[24000, 23000, 25000, 24500, 23500, 24200]$,\n  - $c_{s,\\max}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $30000$,\n  - $\\eta$ (单位 $\\mathrm{V}$): $[0.02, 0.015, 0.03, 0.01, 0.025, 0.018]$,\n  - $c_{e,\\mathrm{ref}}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $1000$.\n\n- 情况 2（电解质出现负值且边界附近有轻微的上限违规）：\n  - $c_e$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[10, -5, 0, 20, -1, 15]$,\n  - $c_s$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[29000, 30500, 29500, 30000, 31000, 28500]$,\n  - $c_{s,\\max}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $30000$,\n  - $\\eta$ (单位 $\\mathrm{V}$): $[0.0, 0.005, -0.005, 0.01, -0.002, 0.0]$,\n  - $c_{e,\\mathrm{ref}}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $1000$.\n\n- 情况 3（固相容量违规占主导；过电位为正）：\n  - $c_e$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[1000, 800, 900, 950, 700, 850]$,\n  - $c_s$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[32000, 31000, 30500, 31500, 32500, 30000]$,\n  - $c_{s,\\max}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $30000$,\n  - $\\eta$ (单位 $\\mathrm{V}$): $[0.02, 0.015, 0.01, 0.02, 0.005, 0.012]$,\n  - $c_{e,\\mathrm{ref}}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $1000$.\n\n- 情况 4（析锂工况，具有强负过电位和电解质耗尽）：\n  - $c_e$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[200, 150, 100, 80, 50, 120]$,\n  - $c_s$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $[25000, 26000, 24000, 23000, 22000, 24500]$,\n  - $c_{s,\\max}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $30000$,\n  - $\\eta$ (单位 $\\mathrm{V}$): $[-0.05, -0.08, -0.12, -0.03, -0.06, -0.09]$,\n  - $c_{e,\\mathrm{ref}}$ (单位 $\\mathrm{mol}\\,\\mathrm{m}^{-3}$): $1000$.\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目是对应测试用例的总损失 $L_{\\mathrm{total}}$，即 $[L_{\\mathrm{total}}^{(1)}, L_{\\mathrm{total}}^{(2)}, L_{\\mathrm{total}}^{(3)}, L_{\\mathrm{total}}^{(4)}]$，并四舍五入到六位小数。",
            "solution": "该问题经评估有效。其科学基础植根于电化学工程原理，采用了标准的约束优化数值技术，问题陈述适定，提供了所有必要信息，并且没有任何矛盾或含糊之处。\n\n目标是为应用于锂离子电池（LIB）模型的物理信息神经网络（PINN）计算总损失 $L_{\\mathrm{total}}$。此损失函数旨在强制网络对关键状态变量的预测具有物理容许性。总损失是三个不同惩罚项的聚合，每个惩罚项对应一个基本的物理约束。计算将针对四个独立的测试用例进行，每个用例代表一种不同的操作工况。\n\n该方法的核心在于使用一个光滑、可微的惩罚函数来近似约束违规的指示函数。这对于在基于梯度的优化算法（训练神经网络的标准方法）中使用至关重要。问题指定了 softplus 函数，定义为 $\\mathrm{softplus}(x) = \\ln(1 + e^x)$。该函数平滑地近似了修正函数 $\\max(0, x)$。通过向 softplus 函数输入适当的参数，我们可以构建一个惩罚项，当约束满足时该惩罚项接近于零，并随着违规幅度的平方而增长。\n\n三个损失分量推导如下：\n\n1.  电解质非负性惩罚，$L_{e}^{\\ge 0}$：质量守恒的物理原理规定电解质浓度 $c_e$ 不能为负。约束为 $c_{e,i} \\ge 0$ 对每个配置点 $i$ 成立。为惩罚违规（$c_{e,i}  0$），我们将 softplus 函数的参数构造为 $-c_{e,i}$。如果 $c_{e,i} \\ge 0$，则 $-c_{e,i} \\le 0$，并且 $\\mathrm{softplus}(-c_{e,i})$ 接近于 $0$。如果 $c_{e,i}  0$，则 $-c_{e,i} > 0$，并且 $\\mathrm{softplus}(-c_{e,i}) \\approx -c_{e,i} = |c_{e,i}|$。在所有 $N$ 个配置点上取平均的平方惩罚由下式给出：\n    $$L_{e}^{\\ge 0} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[\\mathrm{softplus}\\left(-c_{e,i}\\right)\\right]^2$$\n\n2.  固相浓度上限惩罚，$L_{s}^{\\le c_{s,\\max}}$：电极中的嵌入主体材料对锂离子有有限的容量，这为固相浓度 $c_s$ 施加了上限。约束为 $c_{s,i} \\le c_{s,\\max}$。当 $c_{s,i} > c_{s,\\max}$ 时发生违规。因此，softplus 函数的参数为 $c_{s,i} - c_{s,\\max}$。如果 $c_{s,i} \\le c_{s,\\max}$，则参数为非正数，softplus 的输出接近于零。如果 $c_{s,i} > c_{s,\\max}$，则参数为正数，并且 $\\mathrm{softplus}(c_{s,i} - c_{s,\\max}) \\approx c_{s,i} - c_{s,\\max}$。相应的损失项为：\n    $$L_{s}^{\\le c_{s,\\max}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[\\mathrm{softplus}\\left(c_{s,i} - c_{s,\\max}\\right)\\right]^2$$\n\n3.  析锂惩罚，$L_{\\mathrm{plate}}$：析锂是一种不希望发生的副反应，在强负界面过电位（$\\eta  0$）下更可能发生。此惩罚项旨在抑制此类条件。softplus 函数的参数为 $-\\eta_i$。如果 $\\eta_i \\ge 0$，惩罚可忽略不计。如果 $\\eta_i  0$，则会产生一个与其大小成比例的惩罚。此外，电解质耗尽（低 $c_e$）会加剧此风险。引入一个权重因子 $w_i = 1 + \\exp\\left(-c_{e,i}/c_{e,\\mathrm{ref}}\\right)$，以在 $c_{e,i}$ 较低时放大惩罚。当 $c_{e,i} \\to 0$ 时，$w_i \\to 2$；对于大的 $c_{e,i}$，$w_i \\to 1$。组合的析锂损失为：\n    $$L_{\\mathrm{plate}} = \\frac{1}{N} \\sum_{i=1}^{N} w_i \\left[\\mathrm{softplus}\\left(-\\eta_i\\right)\\right]^2$$\n\n最后，总损失 $L_{\\mathrm{total}}$ 是这三个分量的加权和。问题指定权重为 $\\alpha = 1$，$\\beta = 1$ 和 $\\gamma = 1$。因此，总损失是一个简单的求和：\n$$L_{\\mathrm{total}} = L_{e}^{\\ge 0} + L_{s}^{\\le c_{s,\\max}} + L_{\\mathrm{plate}}$$\n\n程序将实现这四个方程。对于每个测试用例，它将使用 $c_e$、$c_s$ 和 $\\eta$ 的预测值数组，以及标量参数 $c_{s,\\max}$ 和 $c_{e,\\mathrm{ref}}$ 来计算 $L_{\\mathrm{total}}$。对数值数组进行向量化操作是计算配置点上总和的最有效方法。每个用例的最终结果将按要求四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes total physics-informed loss for lithium-ion battery PINN predictions.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"c_e\": np.array([1000, 950, 1100, 1020, 980, 1010]),\n            \"c_s\": np.array([24000, 23000, 25000, 24500, 23500, 24200]),\n            \"c_s_max\": 30000,\n            \"eta\": np.array([0.02, 0.015, 0.03, 0.01, 0.025, 0.018]),\n            \"c_e_ref\": 1000,\n        },\n        {\n            \"c_e\": np.array([10, -5, 0, 20, -1, 15]),\n            \"c_s\": np.array([29000, 30500, 29500, 30000, 31000, 28500]),\n            \"c_s_max\": 30000,\n            \"eta\": np.array([0.0, 0.005, -0.005, 0.01, -0.002, 0.0]),\n            \"c_e_ref\": 1000,\n        },\n        {\n            \"c_e\": np.array([1000, 800, 900, 950, 700, 850]),\n            \"c_s\": np.array([32000, 31000, 30500, 31500, 32500, 30000]),\n            \"c_s_max\": 30000,\n            \"eta\": np.array([0.02, 0.015, 0.01, 0.02, 0.005, 0.012]),\n            \"c_e_ref\": 1000,\n        },\n        {\n            \"c_e\": np.array([200, 150, 100, 80, 50, 120]),\n            \"c_s\": np.array([25000, 26000, 24000, 23000, 22000, 24500]),\n            \"c_s_max\": 30000,\n            \"eta\": np.array([-0.05, -0.08, -0.12, -0.03, -0.06, -0.09]),\n            \"c_e_ref\": 1000,\n        },\n    ]\n\n    # Loss weights, as specified in the problem\n    alpha = 1.0\n    beta = 1.0\n    gamma = 1.0\n\n    def softplus(x):\n        \"\"\"\n        Computes the softplus function log(1 + exp(x)).\n        This implementation is numerically stable.\n        \"\"\"\n        # For large x, softplus(x) approx x.\n        # For large negative x, softplus(x) approx 0.\n        return np.log1p(np.exp(-np.abs(x))) + np.maximum(0, x)\n\n    results = []\n    for case in test_cases:\n        c_e = case[\"c_e\"]\n        c_s = case[\"c_s\"]\n        eta = case[\"eta\"]\n        c_s_max = case[\"c_s_max\"]\n        c_e_ref = case[\"c_e_ref\"]\n        \n        # 1. Electrolyte non-negativity penalty\n        l_e = np.mean(softplus(-c_e) ** 2)\n        \n        # 2. Solid concentration upper-bound penalty\n        l_s = np.mean(softplus(c_s - c_s_max) ** 2)\n\n        # 3. Plating penalty\n        w = 1.0 + np.exp(-c_e / c_e_ref)\n        l_plate = np.mean(w * (softplus(-eta) ** 2))\n        \n        # 4. Total Loss\n        l_total = alpha * l_e + beta * l_s + gamma * l_plate\n        \n        results.append(round(l_total, 6))\n\n    # Format the final output string\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在为多物理场系统（如电池）构建 PINN 时，一个常见的实际挑战是“刚性”问题。当模型中耦合的不同物理过程（如固相扩散和液相扩散）具有迥异的特征时间或长度尺度时，会导致损失函数的不同组成部分的梯度大小相差悬殊。这种不平衡会严重阻碍训练的收敛性和效果。本实践将介绍一种系统的策略，它结合了基于物理时间尺度的预处理和基于梯度大小的自适应加权，以有效平衡不同损失项的贡献，从而显著改善训练的稳定性和最终模型的精度。",
            "id": "3940664",
            "problem": "考虑为一个电化学电池模型训练一个物理信息神经网络 (PINN)，该模型的控制方程基于守恒定律和唯象输运关系。重点关注一维空间域，坐标为 $x \\in [0,L]$，时间为 $t \\ge 0$。核心物理基础是：\n\n- 固相中锂的质量守恒与菲克扩散定律相结合：固相浓度 $c_s(x,t)$ 服从 $\\frac{\\partial c_s}{\\partial t} = D_s \\frac{\\partial^2 c_s}{\\partial x^2}$，其中 $D_s$ 是固相扩散系数。\n- 电解质相中锂的质量守恒与菲克扩散定律相结合：电解质浓度 $c_e(x,t)$ 服从 $\\frac{\\partial c_e}{\\partial t} = D_e \\frac{\\partial^2 c_e}{\\partial x^2}$，其中 $D_e$ 是电解质扩散系数。\n- 在 $x=0$ 和 $x=L$ 处施加边界条件，以确保物理上一致的通量和连续性；相应的边界残差在此任务中被通用表示，不需要明确的公式。\n\n标准的 PINN 残差损失是偏微分方程 (PDE) 项和边界条件在所有配置点上的残差平方的加权和。当与 PDE 项相关的特征时间尺度相差数个数量级时，会出现训练刚度问题。我们寻求一种预处理策略，该策略能够重新缩放 PDE 残差以降低刚度，并自适应地加权损失分量，以在优化过程中平衡梯度的大小。\n\n从上述物理基础出发，推导一种有原则的预处理和自适应加权方法，以实现以下目标：\n\n1. 通过无量纲化对 PDE 残差进行预处理：\n   - 定义特征长度尺度 $L$（单位为米）以及固相和电解质相的扩散系数 $D_s$ 和 $D_e$（单位为 $\\mathrm{m}^2/\\mathrm{s}$）。\n   - 从菲克扩散推导出特征时间尺度 $T_s = \\frac{L^2}{D_s}$ 和 $T_e = \\frac{L^2}{D_e}$（单位为秒）。\n   - 构建残差缩放因子 $s_s$ 和 $s_e$，使得固相和电解质相扩散残差的有效时间尺度相等。用 $T_s$ 和 $T_e$ 明确定义 $s_s$ 和 $s_e$。\n\n2. 基于梯度大小的自适应损失加权：\n   - 给出三个任务的损失分量的梯度大小序列：固相扩散残差（$g_s$ 序列）、电解质扩散残差（$g_e$ 序列）和边界条件残差（$g_{bc}$ 序列）。\n   - 使用指数移动平均 (EMA) 将每个序列聚合为一个代表性大小。对于序列 $\\{u_t\\}$，EMA 定义为 $m_1 = u_1$ 以及当 $t \\ge 2$ 时 $m_t = \\beta m_{t-1} + (1-\\beta) u_t$，其中 $\\beta \\in (0,1)$ 是一个平滑参数。使用 $\\beta = 0.9$。\n   - 从代表性大小 $m_s$、$m_e$ 和 $m_{bc}$ 构建自适应权重 $w_s$、$w_e$ 和 $w_{bc}$，通过 $w_k \\propto (m_k + \\varepsilon)^{-\\alpha}$，其中 $\\alpha \\in (0,1]$ 且 $\\varepsilon > 0$ 是一个避免除以零的小常数；使用 $\\alpha = 0.5$ 和 $\\varepsilon = 10^{-12}$。归一化权重，使其算术平均值等于 $1$。\n\n3. 量化该策略带来的改进：\n   - 将预处理前的时间尺度条件因子定义为 $\\kappa_{\\text{before}} = \\frac{\\max(T_s, T_e)}{\\min(T_s, T_e)}$，预处理后的定义为 $\\kappa_{\\text{after}} = \\frac{\\max(T_s s_s, T_e s_e)}{\\min(T_s s_s, T_e s_e)}$。\n   - 将加权前三个任务的梯度不平衡定义为变异系数 (CV)，$\\mathrm{CV}_{\\text{before}} = \\frac{\\sigma(\\{m_s, m_e, m_{bc}\\})}{\\mu(\\{m_s, m_e, m_{bc}\\})}$，加权后的定义为 $\\mathrm{CV}_{\\text{after}} = \\frac{\\sigma(\\{w_s m_s, w_e m_e, w_{bc} m_{bc}\\})}{\\mu(\\{w_s m_s, w_e m_e, w_{bc} m_{bc}\\})}$，其中 $\\sigma$ 和 $\\mu$ 分别表示标准差和均值。\n   - 将综合改进分数定义为两个改进比率的几何平均值：$I = \\sqrt{\\left(\\frac{\\kappa_{\\text{before}}}{\\kappa_{\\text{after}}}\\right) \\left(\\frac{\\mathrm{CV}_{\\text{before}}}{\\mathrm{CV}_{\\text{after}}}\\right)}$。$I$ 是无量纲的，应以浮点数形式报告。\n\n实现一个程序，为每个提供的测试用例计算 $I$，并按以下规定将所有结果输出到单行中。\n\n输入参数 $L$ 必须使用物理单位米，$D_s$、$D_e$ 必须使用 $\\mathrm{m}^2/\\mathrm{s}$。时间尺度 $T_s$ 和 $T_e$ 必须以秒为单位计算。最终的改进分数 $I$ 是无量纲的；请以浮点数形式报告。\n\n测试套件：\n- 案例 1 (刚性扩散对比): $L = 10^{-4} \\ \\mathrm{m}$, $D_s = 10^{-14} \\ \\mathrm{m}^2/\\mathrm{s}$, $D_e = 10^{-10} \\ \\mathrm{m}^2/\\mathrm{s}$, 梯度序列 $g_s = [1000, 900, 800, 700, 650]$, $g_e = [5, 5.5, 6, 5.8, 5.7]$, $g_{bc} = [20, 18, 17, 16, 16]$。\n- 案例 2 (中等对比): $L = 10^{-4} \\ \\mathrm{m}$, $D_s = 10^{-12} \\ \\mathrm{m}^2/\\mathrm{s}$, $D_e = 2 \\cdot 10^{-12} \\ \\mathrm{m}^2/\\mathrm{s}$, 梯度序列 $g_s = [10, 9.5, 9, 9.2, 9.1]$, $g_e = [8, 8.2, 8.1, 8.0, 8.05]$, $g_{bc} = [9, 9, 8.9, 9.1, 9.0]$。\n- 案例 3 (极端刚性): $L = 5 \\cdot 10^{-5} \\ \\mathrm{m}$, $D_s = 10^{-16} \\ \\mathrm{m}^2/\\mathrm{s}$, $D_e = 5 \\cdot 10^{-10} \\ \\mathrm{m}^2/\\mathrm{s}$, 梯度序列 $g_s = [5000, 4000, 3000, 2500, 2300]$, $g_e = [3, 3.1, 3.2, 3.3, 3.25]$, $g_{bc} = [15, 14, 13, 12.5, 12.2]$。\n- 案例 4 (接近平衡的扩散，不平衡的梯度): $L = 10^{-4} \\ \\mathrm{m}$, $D_s = 10^{-12} \\ \\mathrm{m}^2/\\mathrm{s}$, $D_e = 1.1 \\cdot 10^{-12} \\ \\mathrm{m}^2/\\mathrm{s}$, 梯度序列 $g_s = [50, 49, 48, 47, 46]$, $g_e = [2, 2.1, 2.2, 2.15, 2.1]$, $g_{bc} = [1, 1.1, 1.2, 1.15, 1.1]$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[result1,result2,result3,result4]$），其中每个 $resulti$ 是案例 $i$ 的综合改进分数 $I$，表示为浮点数。",
            "solution": "该问题要求推导并实现一种结合了预处理和自适应加权的策略，以缓解用于简化电化学电池模型的物理信息神经网络 (PINN) 的训练刚度。该策略带来的改进将通过一个综合分数 $I$ 来量化。该模型由两个非耦合的菲克扩散方程组成，分别描述了在一维域 $x \\in [0,L]$ 中固相浓度 $c_s(x,t)$ 和电解质相浓度 $c_e(x,t)$ 的变化。\n\n控制偏微分方程 (PDE) 如下：\n$$\n\\frac{\\partial c_s}{\\partial t} = D_s \\frac{\\partial^2 c_s}{\\partial x^2}\n$$\n$$\n\\frac{\\partial c_e}{\\partial t} = D_e \\frac{\\partial^2 c_e}{\\partial x^2}\n$$\n其中 $D_s$ 和 $D_e$ 分别是各自的扩散系数。当这些过程的特征时间尺度差异巨大时，就会产生刚度。解决方案按问题中概述的三个部分呈现。\n\n**1. 通过无量纲化对 PDE 残差进行预处理**\n\n第一个目标是重新缩放 PDE 残差，以使其有效时间尺度相等。对于扩散系数为 $D$、长度为 $L$ 的扩散过程，其特征时间尺度通过量纲分析可得 $T = \\frac{L^2}{D}$。对于固相和电解质相，这些尺度为：\n$$\nT_s = \\frac{L^2}{D_s} \\quad \\text{和} \\quad T_e = \\frac{L^2}{D_e}\n$$\n这些时间尺度之间的差异是刚度的主要来源。这种差异可以通过时间尺度条件因子来量化，定义为较大时间尺度与较小时间尺度之比：\n$$\n\\kappa_{\\text{before}} = \\frac{\\max(T_s, T_e)}{\\min(T_s, T_e)}\n$$\n较大的 $\\kappa_{\\text{before}}$ 值表示存在显著的刚度。该策略是引入缩放因子 $s_s$ 和 $s_e$，在 PINN 损失函数中分别乘以固相和电解质相的 PDE 残差。问题将缩放后的“有效时间尺度”定义为 $T_s s_s$ 和 $T_e s_e$。目标是选择 $s_s$ 和 $s_e$，使得这些有效时间尺度相等：\n$$\nT_s s_s = T_e s_e\n$$\n这个方程对于 $s_s$ 和 $s_e$ 有无穷多组解。一个有原则且对称的选择是将两个有效时间尺度都设置为一个公共参考尺度 $T_{\\text{ref}}$，而这个参考尺度本身由 $T_s$ 和 $T_e$ 构建。几何平均值是该参考尺度的自然选择：\n$$\nT_{\\text{ref}} = \\sqrt{T_s T_e}\n$$\n通过设定 $T_s s_s = T_{\\text{ref}}$ 和 $T_e s_e = T_{\\text{ref}}$，我们推导出缩放因子：\n$$\ns_s = \\frac{T_{\\text{ref}}}{T_s} = \\frac{\\sqrt{T_s T_e}}{T_s} = \\sqrt{\\frac{T_e}{T_s}}\n$$\n$$\ns_e = \\frac{T_{\\text{ref}}}{T_e} = \\frac{\\sqrt{T_s T_e}}{T_e} = \\sqrt{\\frac{T_s}{T_e}}\n$$\n使用这些因子后，新的有效时间尺度完全相等：$T_s s_s = \\sqrt{T_s T_e}$ 和 $T_e s_e = \\sqrt{T_s T_e}$。因此，预处理后的条件因子为：\n$$\n\\kappa_{\\text{after}} = \\frac{\\max(T_s s_s, T_e s_e)}{\\min(T_s s_s, T_e s_e)} = \\frac{\\sqrt{T_s T_e}}{\\sqrt{T_s T_e}} = 1\n$$\n这表明预处理完美地平衡了 PDE 分量的时间尺度。\n\n**2. 基于梯度大小的自适应损失加权**\n\n第二个目标是在训练期间平衡总损失函数不同分量（固相扩散残差、电解质扩散残差和边界条件残差）的贡献。这是通过根据每个分量相对于网络参数的梯度大小自适应地加权每个分量来实现的。\n\n首先，从各自的时间序列数据（$g_s$、$g_e$、$g_{bc}$）中计算出每个损失分量梯度的代表性大小。为此使用了指数移动平均 (EMA)。对于一个通用的梯度大小序列 $\\{u_t\\}$，EMA 序列 $\\{m_t\\}$ 的计算方式如下：\n$$\nm_1 = u_1\n$$\n$$\nm_t = \\beta m_{t-1} + (1-\\beta) u_t \\quad \\text{当 } t \\ge 2\n$$\n平滑参数为 $\\beta = 0.9$。该序列的最后一个值被视为该梯度的代表性大小，对于任务 $k \\in \\{s, e, bc\\}$，表示为 $m_k$。\n\n接下来，从这些代表性大小 $m_k$ 构建自适应权重 $w_k$。公式为 $w_k \\propto (m_k + \\varepsilon)^{-\\alpha}$，其中 $\\alpha = 0.5$，$\\varepsilon = 10^{-12}$ 是一个用于稳定的小常数。设未归一化的权重为 $w'_k = (m_k + \\varepsilon)^{-\\alpha}$。\n\n这些权重必须被归一化，使其算术平均值等于 $1$。对于这三个任务，此条件为 $\\frac{1}{3}(w_s + w_e + w_{bc}) = 1$，可简化为 $w_s + w_e + w_{bc} = 3$。归一化按如下方式执行：\n$$\nw_k = \\frac{3 \\cdot w'_k}{\\sum_{j \\in \\{s, e, bc\\}} w'_j} = \\frac{3 \\cdot (m_k + \\varepsilon)^{-\\alpha}}{\\sum_{j \\in \\{s, e, bc\\}} (m_j + \\varepsilon)^{-\\alpha}}\n$$\n\n**3. 量化改进效果**\n\n问题的最后一部分是将预处理和自适应加权的效果合并为一个单一的综合改进分数 $I$。\n\n梯度平衡的改进通过比较加权前后梯度大小的变异系数 (CV) 来量化。CV 是标准差 $\\sigma$ 与均值 $\\mu$ 的比率。\n\n加权前，大小集合为 $\\{m_s, m_e, m_{bc}\\}$。不平衡度为：\n$$\n\\mathrm{CV}_{\\text{before}} = \\frac{\\sigma(\\{m_s, m_e, m_{bc}\\})}{\\mu(\\{m_s, m_e, m_{bc}\\})}\n$$\n加权后，有效大小为 $\\{w_s m_s, w_e m_e, w_{bc} m_{bc}\\}$。不平衡度为：\n$$\n\\mathrm{CV}_{\\text{after}} = \\frac{\\sigma(\\{w_s m_s, w_e m_e, w_{bc} m_{bc}\\})}{\\mu(\\{w_s m_s, w_e m_e, w_{bc} m_{bc}\\})}\n$$\n综合改进分数 $I$ 是时间尺度条件和梯度不平衡改进比率的几何平均值：\n$$\nI = \\sqrt{\\left(\\frac{\\kappa_{\\text{before}}}{\\kappa_{\\text{after}}}\\right) \\left(\\frac{\\mathrm{CV}_{\\text{before}}}{\\mathrm{CV}_{\\text{after}}}\\right)}\n$$\n代入 $\\kappa_{\\text{after}} = 1$，公式简化为：\n$$\nI = \\sqrt{\\kappa_{\\text{before}} \\frac{\\mathrm{CV}_{\\text{before}}}{\\mathrm{CV}_{\\text{after}}}}\n$$\n该分数全面地衡量了由不同时间尺度和不平衡梯度贡献所导致的刚度的降低程度，为所提出策略的有效性提供了定量评估。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PINN preconditioning and weighting problem for all test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (stiff diffusion contrast)\n        {\n            \"L\": 1e-4, \"Ds\": 1e-14, \"De\": 1e-10,\n            \"gs\": [1000, 900, 800, 700, 650],\n            \"ge\": [5, 5.5, 6, 5.8, 5.7],\n            \"gbc\": [20, 18, 17, 16, 16]\n        },\n        # Case 2 (moderate contrast)\n        {\n            \"L\": 1e-4, \"Ds\": 1e-12, \"De\": 2e-12,\n            \"gs\": [10, 9.5, 9, 9.2, 9.1],\n            \"ge\": [8, 8.2, 8.1, 8.0, 8.05],\n            \"gbc\": [9, 9, 8.9, 9.1, 9.0]\n        },\n        # Case 3 (extreme stiffness)\n        {\n            \"L\": 5e-5, \"Ds\": 1e-16, \"De\": 5e-10,\n            \"gs\": [5000, 4000, 3000, 2500, 2300],\n            \"ge\": [3, 3.1, 3.2, 3.3, 3.25],\n            \"gbc\": [15, 14, 13, 12.5, 12.2]\n        },\n        # Case 4 (near-balanced diffusion, unbalanced gradients)\n        {\n            \"L\": 1e-4, \"Ds\": 1e-12, \"De\": 1.1e-12,\n            \"gs\": [50, 49, 48, 47, 46],\n            \"ge\": [2, 2.1, 2.2, 2.15, 2.1],\n            \"gbc\": [1, 1.1, 1.2, 1.15, 1.1]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        I = calculate_improvement(\n            case[\"L\"], case[\"Ds\"], case[\"De\"],\n            case[\"gs\"], case[\"ge\"], case[\"gbc\"]\n        )\n        results.append(f\"{I:.10f}\") # Using f-string formatting to avoid trailing zeros\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_ema(sequence, beta):\n    \"\"\"\n    Computes the Exponential Moving Average of a sequence.\n    \"\"\"\n    m = sequence[0]\n    for i in range(1, len(sequence)):\n        m = beta * m + (1 - beta) * sequence[i]\n    return m\n\ndef calculate_cv(data):\n    \"\"\"\n    Calculates the Coefficient of Variation (sigma / mu) for a dataset.\n    Uses population standard deviation (ddof=0).\n    \"\"\"\n    mean = np.mean(data)\n    std_dev = np.std(data, ddof=0)\n    if mean == 0:\n        return 0.0 # Or handle as an error, but for this problem, mean > 0\n    return std_dev / mean\n\ndef calculate_improvement(L, Ds, De, gs, ge, gbc):\n    \"\"\"\n    Calculates the composite improvement score I for a single test case.\n    \"\"\"\n    # Constants from the problem description\n    beta = 0.9\n    alpha = 0.5\n    epsilon = 1e-12\n\n    # Part 1: Preconditioning\n    Ts = L**2 / Ds\n    Te = L**2 / De\n\n    kappa_before = max(Ts, Te) / min(Ts, Te)\n    # As derived, the preconditioning equalizes the time scales perfectly.\n    kappa_after = 1.0\n    \n    kappa_ratio = kappa_before / kappa_after\n\n    # Part 2: Adaptive Weighting\n    # Calculate representative gradient magnitudes using EMA\n    ms = calculate_ema(gs, beta)\n    me = calculate_ema(ge, beta)\n    mbc = calculate_ema(gbc, beta)\n    \n    magnitudes_before = np.array([ms, me, mbc])\n\n    # Part 3: Quantify Improvement\n    # Calculate CV before weighting\n    cv_before = calculate_cv(magnitudes_before)\n    \n    # Calculate weights and weighted magnitudes\n    # Unnormalized weights: w_k' = (m_k + eps)^-alpha\n    w_prime_s = (ms + epsilon)**(-alpha)\n    w_prime_e = (me + epsilon)**(-alpha)\n    w_prime_bc = (mbc + epsilon)**(-alpha)\n    \n    w_primes = np.array([w_prime_s, w_prime_e, w_prime_bc])\n\n    # Normalization constant C = 3 / sum(w_primes)\n    norm_const = 3.0 / np.sum(w_primes)\n    \n    # Normalized weights\n    ws = w_prime_s * norm_const\n    we = w_prime_e * norm_const\n    wbc = w_prime_bc * norm_const\n\n    # Magnitudes after weighting\n    magnitudes_after = np.array([ws * ms, we * me, wbc * mbc])\n\n    # Calculate CV after weighting\n    cv_after = calculate_cv(magnitudes_after)\n    \n    if cv_after == 0:\n        # If perfect balancing occurs, the improvement ratio is theoretically infinite.\n        # This case is unlikely with alpha=0.5 but handle for robustness.\n        # For this problem, it will not happen, so we can assume cv_after > 0.\n        cv_ratio = np.inf\n    else:\n        cv_ratio = cv_before / cv_after\n    \n    # Calculate composite improvement score\n    I = np.sqrt(kappa_ratio * cv_ratio)\n    \n    return I\n\nsolve()\n\n```"
        }
    ]
}