{
    "hands_on_practices": [
        {
            "introduction": "任何机器学习应用的第一步都是将研究对象转化为计算机可以理解的数值语言。在材料科学中，这意味着将化学成分或晶体结构表示为数值“特征向量”或“描述符”。本练习将引导您计算一种常见的基于成分的描述符，该描述符通过对元素固有属性进行统计平均来为材料创建数字指纹，这是构建机器学习代理模型的基础步骤。",
            "id": "3926519",
            "problem": "在用于层状氧化物正极材料的自动化电池设计与仿真流程中，通过使用源自“与材料无关的信息学与探索平台”（Materials-Agnostic Platform for Informatics and Exploration, MAGPIE）的成分描述符来加速筛选过程。这些描述符通过使用化学计量原子分数计算的统计摘要来聚合整个组分的元素性质。作为符合上下文的基本依据，您可以使用以下内容：对于一个具有化学计量系数的化合物，元素 $i$ 的原子分数 $x_{i}$ 是其化学计量系数除以所有化学计量系数的总和；对于与元素 $i$ 相关的性质 $p_{i}$，成分加权平均值为 $\\mu_{p}=\\sum_{i}x_{i}p_{i}$，成分加权方差为 $\\sigma_{p}^{2}=\\sum_{i}x_{i}\\left(p_{i}-\\mu_{p}\\right)^{2}$。\n\n考虑层状氧化物 $\\mathrm{LiNi_{0.6}Mn_{0.2}Co_{0.2}O_{2}}$，其化学计量为 $\\mathrm{Li}_{1}\\mathrm{Ni}_{0.6}\\mathrm{Mn}_{0.2}\\mathrm{Co}_{0.2}\\mathrm{O}_{2}$。使用以下元素性质：\n- Pauling 电负性 $\\chi$:\n  - $\\mathrm{Li}$: $\\chi=0.98$\n  - $\\mathrm{Ni}$: $\\chi=1.91$\n  - $\\mathrm{Mn}$: $\\chi=1.55$\n  - $\\mathrm{Co}$: $\\chi=1.88$\n  - $\\mathrm{O}$: $\\chi=3.44$\n- 共价半径 $r$（单位为 $\\mathrm{\\AA}$）：\n  - $\\mathrm{Li}$: $r=1.28$\n  - $\\mathrm{Ni}$: $r=1.24$\n  - $\\mathrm{Mn}$: $r=1.39$\n  - $\\mathrm{Co}$: $r=1.26$\n  - $\\mathrm{O}$: $r=0.66$\n\n通过计算成分加权平均电负性 $\\mu_{\\chi}$、成分加权方差 $\\sigma_{\\chi}^{2}$ 和成分加权平均共价半径 $\\mu_{r}$，为该成分构建上述两种性质的 MAGPIE 风格的描述符组件。基于这些值，定义一个标量筛选分数\n$$\nS=\\alpha\\,\\mu_{\\chi}+\\beta\\,\\sigma_{\\chi}^{2}+\\gamma\\,\\mu_{r},\n$$\n其系数 $\\alpha=0.90$、$\\beta=-0.25$ 和 $\\gamma=0.30\\,\\mathrm{\\AA}^{-1}$ 的选择是为了得到一个无量纲的分数。计算 $S$ 并将最终答案四舍五入到四位有效数字。将 $S$ 报告为无量纲量。此外，解释这种描述符构建中元素性质统计聚合所依据的假设，包括这些假设如何与用于加速材料筛选的机器学习相结合。",
            "solution": "经评估，问题陈述有效。它在科学上基于计算材料科学和用于材料发现的机器学习的原理。化合物 $\\mathrm{LiNi_{0.6}Mn_{0.2}Co_{0.2}O_{2}}$ 是一种公认的正极材料。基于元素性质统计聚合的 MAGPIE 风格描述符是材料信息学中的一种标准技术。这个问题提法得当，提供了所有必要的定义、数据和常数，以得出一个唯一的、可验证的解。其语言客观，任务明确。\n\n求解过程分为两部分：首先，筛选分数 $S$ 的数值计算；其次，解释其基本假设及其在机器学习中的应用背景。\n\n第一部分：筛选分数 $S$ 的计算\n\n第一步是确定化合物 $\\mathrm{Li}_{1}\\mathrm{Ni}_{0.6}\\mathrm{Mn}_{0.2}\\mathrm{Co}_{0.2}\\mathrm{O}_{2}$ 中各元素的原子分数 $x_i$。化学计量系数为 $s_{\\mathrm{Li}}=1$、$s_{\\mathrm{Ni}}=0.6$、$s_{\\mathrm{Mn}}=0.2$、$s_{\\mathrm{Co}}=0.2$ 和 $s_{\\mathrm{O}}=2$。\n\n化学计量系数的总和 $S_{total}$ 是：\n$$\nS_{total} = s_{\\mathrm{Li}} + s_{\\mathrm{Ni}} + s_{\\mathrm{Mn}} + s_{\\mathrm{Co}} + s_{\\mathrm{O}} = 1 + 0.6 + 0.2 + 0.2 + 2 = 4\n$$\n各元素 $i$ 的原子分数 $x_i$ 计算公式为 $x_i = s_i / S_{total}$：\n$$\nx_{\\mathrm{Li}} = \\frac{1}{4} = 0.25\n$$\n$$\nx_{\\mathrm{Ni}} = \\frac{0.6}{4} = 0.15\n$$\n$$\nx_{\\mathrm{Mn}} = \\frac{0.2}{4} = 0.05\n$$\n$$\nx_{\\mathrm{Co}} = \\frac{0.2}{4} = 0.05\n$$\n$$\nx_{\\mathrm{O}} = \\frac{2}{4} = 0.50\n$$\n原子分数的总和为 $\\sum x_i = 0.25 + 0.15 + 0.05 + 0.05 + 0.50 = 1$，符合要求。\n\n接下来，我们使用公式 $\\mu_{p}=\\sum_{i}x_{i}p_{i}$ 和给定的 Pauling 电负性值 $\\chi_i$ 来计算成分加权平均电负性 $\\mu_{\\chi}$：\n$$\n\\mu_{\\chi} = x_{\\mathrm{Li}}\\chi_{\\mathrm{Li}} + x_{\\mathrm{Ni}}\\chi_{\\mathrm{Ni}} + x_{\\mathrm{Mn}}\\chi_{\\mathrm{Mn}} + x_{\\mathrm{Co}}\\chi_{\\mathrm{Co}} + x_{\\mathrm{O}}\\chi_{\\mathrm{O}}\n$$\n$$\n\\mu_{\\chi} = (0.25)(0.98) + (0.15)(1.91) + (0.05)(1.55) + (0.05)(1.88) + (0.50)(3.44)\n$$\n$$\n\\mu_{\\chi} = 0.245 + 0.2865 + 0.0775 + 0.094 + 1.72 = 2.423\n$$\n\n然后，我们使用公式 $\\sigma_{p}^{2}=\\sum_{i}x_{i}(p_{i}-\\mu_{p})^{2}$ 来计算电负性的成分加权方差 $\\sigma_{\\chi}^{2}$：\n$$\n\\sigma_{\\chi}^{2} = x_{\\mathrm{Li}}(\\chi_{\\mathrm{Li}}-\\mu_{\\chi})^2 + x_{\\mathrm{Ni}}(\\chi_{\\mathrm{Ni}}-\\mu_{\\chi})^2 + x_{\\mathrm{Mn}}(\\chi_{\\mathrm{Mn}}-\\mu_{\\chi})^2 + x_{\\mathrm{Co}}(\\chi_{\\mathrm{Co}}-\\mu_{\\chi})^2 + x_{\\mathrm{O}}(\\chi_{\\mathrm{O}}-\\mu_{\\chi})^2\n$$\n$$\n\\sigma_{\\chi}^{2} = (0.25)(0.98-2.423)^2 + (0.15)(1.91-2.423)^2 + (0.05)(1.55-2.423)^2 + (0.05)(1.88-2.423)^2 + (0.50)(3.44-2.423)^2\n$$\n$$\n\\sigma_{\\chi}^{2} = (0.25)(-1.443)^2 + (0.15)(-0.513)^2 + (0.05)(-0.873)^2 + (0.05)(-0.543)^2 + (0.50)(1.017)^2\n$$\n$$\n\\sigma_{\\chi}^{2} = (0.25)(2.082249) + (0.15)(0.263169) + (0.05)(0.762129) + (0.05)(0.294849) + (0.50)(1.034289)\n$$\n$$\n\\sigma_{\\chi}^{2} \\approx 0.52056 + 0.03948 + 0.03811 + 0.01474 + 0.51714 = 1.13003\n$$\n\n接下来，我们使用给定的半径 $r_i$ 来计算成分加权平均共价半径 $\\mu_{r}$：\n$$\n\\mu_{r} = x_{\\mathrm{Li}}r_{\\mathrm{Li}} + x_{\\mathrm{Ni}}r_{\\mathrm{Ni}} + x_{\\mathrm{Mn}}r_{\\mathrm{Mn}} + x_{\\mathrm{Co}}r_{\\mathrm{Co}} + x_{\\mathrm{O}}r_{\\mathrm{O}}\n$$\n$$\n\\mu_{r} = (0.25)(1.28\\,\\mathrm{\\AA}) + (0.15)(1.24\\,\\mathrm{\\AA}) + (0.05)(1.39\\,\\mathrm{\\AA}) + (0.05)(1.26\\,\\mathrm{\\AA}) + (0.50)(0.66\\,\\mathrm{\\AA})\n$$\n$$\n\\mu_{r} = 0.32\\,\\mathrm{\\AA} + 0.186\\,\\mathrm{\\AA} + 0.0695\\,\\mathrm{\\AA} + 0.063\\,\\mathrm{\\AA} + 0.33\\,\\mathrm{\\AA} = 0.9685\\,\\mathrm{\\AA}\n$$\n\n最后，我们使用给定的公式和系数 $\\alpha=0.90$、$\\beta=-0.25$ 和 $\\gamma=0.30\\,\\mathrm{\\AA}^{-1}$ 来计算标量筛选分数 $S$：\n$$\nS = \\alpha\\,\\mu_{\\chi} + \\beta\\,\\sigma_{\\chi}^{2} + \\gamma\\,\\mu_{r}\n$$\n$$\nS = (0.90)(2.423) + (-0.25)(1.13003) + (0.30\\,\\mathrm{\\AA}^{-1})(0.9685\\,\\mathrm{\\AA})\n$$\n$$\nS = 2.1807 - 0.2825075 + 0.29055\n$$\n$$\nS \\approx 2.1887425\n$$\n四舍五入到四位有效数字，我们得到 $S \\approx 2.189$。\n\n第二部分：假设及其在机器学习中的应用背景\n\n这些描述符的构建基于几个关键假设，这些假设是在物理准确性和计算效率之间经过深思熟虑的权衡。\n\n1.  **原子可加性和均质化**：基本假设是，材料的宏观或体属性可以通过其构成元素的内在属性的统计聚合来近似。这种“原子袋”方法有效地将材料均质化，将其视为简单的混合物。它在很大程度上忽略了晶体结构、局部配位环境、键合类型（离子键、共价键、金属键）、氧化态以及长程电子和结构相互作用等复杂而具体的细节。例如，一个元素的 Pauling 电负性是一个固定值，但它在化合物中的有效电负性会受到其化学环境的调节。\n\n2.  **化学计量比例性**：使用原子分数作为权重，是假定每个原子对聚合性质的贡献与其在化学式中的丰度成正比。这是一个一阶近似，没有考虑由不同原子的特定排列和相互作用产生的非线性效应。例如，如果一个少数元素占据了晶格中的关键位置，它可能对某个性质产生不成比例的巨大影响。\n\n3.  **与上下文无关的元素性质**：该模型使用的元素性质（例如，共价半径）是在参考状态下为元素定义的。问题指定了共价半径，这与共价键最为相关。然而，像 $\\mathrm{LiNi_{0.6}Mn_{0.2}Co_{0.2}O_{2}}$ 这样的材料具有显著的离子键特征。使用共价半径而非（例如）离子半径是一种简化。描述符生成框架接受这种不完美，并假设即使绝对值不完全具有代表性，它们的相对趋势和加权平均值仍然包含预测信息。\n\n这些假设对于与用于加速材料筛选的机器学习相结合至关重要：\n\n-   **特征工程**：机器学习的核心任务是学习从输入特征到输出目标的映射。这些统计聚合的描述符（$\\mu_{\\chi}$、$\\sigma_{\\chi}^{2}$、$\\mu_{r}$ 等）作为一个定长的数值特征向量，代表一个化学成分。这种从化学式到向量的转换为标准机器学习算法的应用所必需。\n\n-   **抽象化和降维**：这些描述符提供了一个低维的、基于成分的抽象，而不是通过晶胞中每个原子的显式坐标（一种高维且可变大小的表示）来描述材料。这种简化使得筛选过程在计算上是可行的。\n\n-   **代理建模**：这种方法的目的是创建一个快速、近似的“代理模型”。无需对数百万种潜在材料成分中的每一种都进行昂贵的高保真度量子力学模拟（如密度泛函理论）或耗时的实验室实验，人们可以几乎瞬时地计算出这些简单的描述符。一个在已知描述符和目标属性（例如，电池电压、离子电导率）的数据集上训练的机器学习模型，会学习近似特征与真实材料行为之间复杂的非线性关系。\n\n-   **加速筛选流程**：机器学习模型一旦训练完成，就可以在几分钟或几小时内预测数百万种假想成分的目标属性。这使得研究人员能够快速筛选广阔的化学空间，并筛选出少量有希望的候选材料，以进行更严格、更昂贵的验证。这种方法的成功取决于这样一个事实：虽然其基本假设在物理上是简化的，但由此产生的特征保留了足够的关键化学和物理“信号”，足以让机器学习模型识别出有意义的相关性并做出有用的预测。方差项 $\\sigma_{\\chi}^{2}$ 尤为重要，因为它捕捉了元素异质性的程度，而这是一个简单的平均值会完全忽略的性质。",
            "answer": "$$\n\\boxed{2.189}\n$$"
        },
        {
            "introduction": "拥有一个预测材料属性的机器学习代理模型本身只是第一步；真正的加速来自于使用该模型智能地指导我们的下一步实验。本练习探讨了贝叶斯优化中的一个核心概念——上置信界（UCB）采集函数。您将学习如何使用模型的预测和不确定性来平衡“探索”（Exploration）未知化学空间和“利用”（Exploitation）已知高性能区域，从而高效地筛选候选材料。",
            "id": "3926501",
            "problem": "一个电池研究团队正在使用高斯过程 (GP) 代理模型来加速筛选一维锂分数轴 $x \\in [0,1]$ 上的候选固体电解质成分。目标属性是对数尺度的离子电导率，它被建模为在任何候选 $x$ 处的 GP 后验预测分布，该分布为均值为 $\\mu(x)$、标准差为 $\\sigma(x)$ 的高斯分布，由平方指数核函数和先验训练数据计算得出。为了选择下一个实验点，该团队使用上置信界 (UCB) 采集函数，该函数由每个 $x$ 处高斯预测分布的上 $q$-分位数定义，其中“探索率”是分位数水平 $q \\in (0.5,1)$，相应的 UCB 由 $q$-分位数 $\\mu(x) + \\kappa\\,\\sigma(x)$ 给出，其中 $\\kappa = \\Phi^{-1}(q)$，$\\Phi^{-1}$ 是标准正态分布的逆累积分布函数。\n\n我们为您提供了在三个候选成分 $x_1=0.21$，$x_2=0.58$ 和 $x_3=0.83$ 处预先计算的 GP 后验预测均值和标准差。这些值是使用相同的核函数超参数，但在代表不同实验设置的两种同方差观测噪声情景下获得的：\n\n- 均值（由于训练数据密集，在两种噪声情景下近似不变）：$\\mu(x_1)=2.10$，$\\mu(x_2)=2.05$，$\\mu(x_3)=1.95$。\n- 低噪声预测标准差：$\\sigma_{\\mathrm{L}}(x_1)=0.06$，$\\sigma_{\\mathrm{L}}(x_2)=0.09$，$\\sigma_{\\mathrm{L}}(x_3)=0.14$。\n- 高噪声预测标准差：$\\sigma_{\\mathrm{H}}(x_1)=0.10$，$\\sigma_{\\mathrm{H}}(x_2)=0.13$，$\\sigma_{\\mathrm{H}}(x_3)=0.20$。\n\n假设团队为其下一个选择设定了 $q=0.90$ 的探索率（分位数水平）。请使用高斯 $q$-分位数的定义，通过在低噪声预测标准差下最大化 UCB 来计算下一个查询成分 $x^{\\star}$。然后，基于相同的定义和数据，分析在低噪声和高噪声标准差下，$x^{\\star}$ 的身份将如何作为 $\\kappa$（等价于 $q$）的函数而变化，并推导出最大化器在候选者之间切换的 $\\kappa$ 临界值。您的分析应从 GP 预测分布和 UCB 分位数解释的定义开始，并根据第一性原理进行推导。\n\n仅报告在低噪声情况下选择的最终成分 $x^{\\star}$，作为一个在 $[0,1]$ 区间内的纯数字，并四舍五入到三位有效数字。不要在最终数值答案中包含任何单位。",
            "solution": "首先对问题进行验证，以确保其是良构的、有科学依据的，并包含所有必要信息。\n\n**步骤1：提取已知条件**\n- 锂分数域：$x \\in [0,1]$。\n- 模型：高斯过程 (GP)，后验预测分布为 $N(\\mu(x), \\sigma(x)^2)$。\n- 采集函数：上置信界 (UCB)，定义为预测分布的 $q$-分位数。\n- UCB 公式：$\\text{UCB}(x) = \\mu(x) + \\kappa\\,\\sigma(x)$，其中 $\\kappa = \\Phi^{-1}(q)$。\n- 初始选择的分位数水平：$q = 0.90$。\n- 候选成分：$x_1=0.21$，$x_2=0.58$，$x_3=0.83$。\n- 预测均值：$\\mu(x_1)=2.10$，$\\mu(x_2)=2.05$，$\\mu(x_3)=1.95$。\n- 低噪声预测标准差：$\\sigma_{\\mathrm{L}}(x_1)=0.06$，$\\sigma_{\\mathrm{L}}(x_2)=0.09$，$\\sigma_{\\mathrm{L}}(x_3)=0.14$。\n- 高噪声预测标准差：$\\sigma_{\\mathrm{H}}(x_1)=0.10$，$\\sigma_{\\mathrm{H}}(x_2)=0.13$，$\\sigma_{\\mathrm{H}}(x_3)=0.20$。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了一个标准的贝叶斯优化循环，使用 GP 代理模型和 UCB 采集函数，这是机器学习在材料科学领域广泛接受的方法。所有概念都是统计学和机器学习中的标准概念。\n- **良构性：** 该问题提供了一个离散的候选集和一个定义明确的待最大化目标函数。它提供了执行计算和分析所需的所有数值。\n- **目标：** 问题以精确、定量的术语陈述，没有歧义或主观陈述。\n\n**步骤3：结论与行动**\n问题有效。将提供完整的解答。\n\n**解题推导**\n\n问题的核心是确定哪个候选成分 $x_i$ 能最大化上置信界 (UCB) 采集函数，其定义为：\n$$\n\\text{UCB}(x) = \\mu(x) + \\kappa\\,\\sigma(x)\n$$\n在这里，$\\mu(x)$ 是后验均值，$\\sigma(x)$ 是后验标准差，$\\kappa = \\Phi^{-1}(q)$ 是一个控制在利用（高均值）和探索（高不确定性）之间权衡的参数，其中 $\\Phi^{-1}$ 是标准正态分布的逆累积分布函数 (CDF)。问题要求我们首先在低噪声条件下为特定的分位数 $q=0.90$ 找到最大化器，然后分析在低噪声和高噪声两种情景下，最大化器如何作为 $\\kappa$ 的函数而变化。\n\n**第一部分：在低噪声情况下，当 $q=0.90$ 时的选择**\n\n对于探索率（分位数水平）$q=0.90$，参数 $\\kappa$ 为：\n$$\n\\kappa = \\Phi^{-1}(0.90) \\approx 1.28155\n$$\n我们现在使用低噪声标准差 $\\sigma_{\\mathrm{L}}$ 计算三个候选者中每一个的 UCB 值。\n\n对于候选者 $x_1=0.21$：\n$$\n\\text{UCB}_{\\mathrm{L}}(x_1) = \\mu(x_1) + \\kappa\\,\\sigma_{\\mathrm{L}}(x_1) = 2.10 + (1.28155)(0.06) \\approx 2.10 + 0.07689 = 2.17689\n$$\n\n对于候选者 $x_2=0.58$：\n$$\n\\text{UCB}_{\\mathrm{L}}(x_2) = \\mu(x_2) + \\kappa\\,\\sigma_{\\mathrm{L}}(x_2) = 2.05 + (1.28155)(0.09) \\approx 2.05 + 0.11534 = 2.16534\n$$\n\n对于候选者 $x_3=0.83$：\n$$\n\\text{UCB}_{\\mathrm{L}}(x_3) = \\mu(x_3) + \\kappa\\,\\sigma_{\\mathrm{L}}(x_3) = 1.95 + (1.28155)(0.14) \\approx 1.95 + 0.17942 = 2.12942\n$$\n\n比较这三个值：\n$$\n\\text{UCB}_{\\mathrm{L}}(x_1) > \\text{UCB}_{\\mathrm{L}}(x_2) > \\text{UCB}_{\\mathrm{L}}(x_3)\n$$\n使 UCB 最大化的成分是 $x_1$。因此，下一个查询成分是 $x^{\\star} = x_1 = 0.21$。\n\n**第二部分：$\\kappa$ 临界值分析**\n\n最优候选者 $x^{\\star}$ 的身份取决于 $\\kappa$ 的值。对于每个候选者 $i$，UCB 是 $\\kappa$ 的一个线性函数：$\\text{UCB}_i(\\kappa) = \\mu_i + \\kappa\\sigma_i$。最优选择从候选者 $i$ 切换到候选者 $j$ 的临界 $\\kappa$ 值，是在它们的 UCB 相等时：\n$$\n\\mu_i + \\kappa_{ij}\\sigma_i = \\mu_j + \\kappa_{ij}\\sigma_j\n$$\n求解临界值 $\\kappa_{ij}$ 得：\n$$\n\\kappa_{ij} = \\frac{\\mu_i - \\mu_j}{\\sigma_j - \\sigma_i}\n$$\n我们只对正的 $\\kappa$ 值感兴趣，因为 $q \\in (0.5, 1)$ 意味着 $\\kappa > 0$。\n\n**低噪声情况 ($\\sigma_{\\mathrm{L}}$) 分析：**\n- $x_1$ 和 $x_2$ 之间的交叉点：\n$$\n\\kappa_{12,\\mathrm{L}} = \\frac{\\mu(x_1) - \\mu(x_2)}{\\sigma_{\\mathrm{L}}(x_2) - \\sigma_{\\mathrm{L}}(x_1)} = \\frac{2.10 - 2.05}{0.09 - 0.06} = \\frac{0.05}{0.03} = \\frac{5}{3} \\approx 1.667\n$$\n- $x_2$ 和 $x_3$ 之间的交叉点：\n$$\n\\kappa_{23,\\mathrm{L}} = \\frac{\\mu(x_2) - \\mu(x_3)}{\\sigma_{\\mathrm{L}}(x_3) - \\sigma_{\\mathrm{L}}(x_2)} = \\frac{2.05 - 1.95}{0.14 - 0.09} = \\frac{0.10}{0.05} = 2\n$$\n- $x_1$ 和 $x_3$ 之间的交叉点：\n$$\n\\kappa_{13,\\mathrm{L}} = \\frac{\\mu(x_1) - \\mu(x_3)}{\\sigma_{\\mathrm{L}}(x_3) - \\sigma_{\\mathrm{L}}(x_1)} = \\frac{2.10 - 1.95}{0.14 - 0.06} = \\frac{0.15}{0.08} = \\frac{15}{8} = 1.875\n$$\n当 $\\kappa=0$ 时，$x_1$ 是最优的，因为 $\\mu(x_1)$ 最大。它将一直保持最优，直到其 UCB 被超越。涉及 $x_1$ 的第一个交叉点是与 $x_2$ 在 $\\kappa \\approx 1.667$ 处的交叉。从 $x_2$ 到 $x_3$ 的交叉稍后发生在 $\\kappa = 2$ 处。\n因此，对于低噪声情况，最优候选者的序列是：\n- 对于 $\\kappa \\in [0, 5/3)$，$x_1$ 是最优的。\n- 对于 $\\kappa \\in [5/3, 2)$，$x_2$ 是最优的。\n- 对于 $\\kappa \\ge 2$，$x_3$ 是最优的。\n我们的值 $\\kappa \\approx 1.28155$ 落在第一个区间内，证实了 $x_1$ 是正确的选择。\n\n**高噪声情况 ($\\sigma_{\\mathrm{H}}$) 分析：**\n- $x_1$ 和 $x_2$ 之间的交叉点：\n$$\n\\kappa_{12,\\mathrm{H}} = \\frac{\\mu(x_1) - \\mu(x_2)}{\\sigma_{\\mathrm{H}}(x_2) - \\sigma_{\\mathrm{H}}(x_1)} = \\frac{2.10 - 2.05}{0.13 - 0.10} = \\frac{0.05}{0.03} = \\frac{5}{3} \\approx 1.667\n$$\n- $x_2$ 和 $x_3$ 之间的交叉点：\n$$\n\\kappa_{23,\\mathrm{H}} = \\frac{\\mu(x_2) - \\mu(x_3)}{\\sigma_{\\mathrm{H}}(x_3) - \\sigma_{\\mathrm{H}}(x_2)} = \\frac{2.05 - 1.95}{0.20 - 0.13} = \\frac{0.10}{0.07} = \\frac{10}{7} \\approx 1.429\n$$\n- $x_1$ 和 $x_3$ 之间的交叉点：\n$$\n\\kappa_{13,\\mathrm{H}} = \\frac{\\mu(x_1) - \\mu(x_3)}{\\sigma_{\\mathrm{H}}(x_3) - \\sigma_{\\mathrm{H}}(x_1)} = \\frac{2.10 - 1.95}{0.20 - 0.10} = \\frac{0.15}{0.10} = 1.5\n$$\n当 $\\kappa=0$ 时，$x_1$ 是最优的。涉及 $x_1$ 的第一个临界值是 $\\kappa_{13,\\mathrm{H}}=1.5$。在这一点上，$\\text{UCB}_{\\mathrm{H}}(x_1) = \\text{UCB}_{\\mathrm{H}}(x_3)$。对于 $\\kappa > 1.5$，$\\text{UCB}_{\\mathrm{H}}(x_3) > \\text{UCB}_{\\mathrm{H}}(x_1)$。我们必须检查 $x_2$ 的状态。由于 $\\kappa_{23,\\mathrm{H}} \\approx 1.429  1.5$，对于任何 $\\kappa  1.429$，我们都有 $\\text{UCB}_{\\mathrm{H}}(x_3)  \\text{UCB}_{\\mathrm{H}}(x_2)$。因此，在切换点 $\\kappa=1.5$ 处，$x_3$ 的 UCB 值超过了 $x_1$，并且已经大于 $x_2$ 的 UCB 值。在高噪声情景中，候选者 $x_2$ 从不是最优的。\n因此，对于高噪声情况，最优候选者的序列是：\n- 对于 $\\kappa \\in [0, 1.5)$，$x_1$ 是最优的。\n- 对于 $\\kappa \\ge 1.5$，$x_3$ 是最优的。\n\n题目只要求给出在低噪声情况下，$q=0.90$ 时的最终选定成分 $x^{\\star}$。根据第一部分的计算，这是 $x_1=0.21$。题目要求答案四舍五入到三位有效数字。\n\n最终答案：$x^{\\star} = 0.210$。",
            "answer": "$$\\boxed{0.210}$$"
        },
        {
            "introduction": "在现实世界的材料设计中，我们很少只优化单一属性。通常，我们必须在多个相互冲突的目标之间寻求权衡，例如在追求高离子导电性的同时不能牺牲热力学稳定性。本练习将向您介绍一种处理这种复杂性的高级方法，即使用考虑了预测不确定性的“鲁棒帕累托优化”来识别在一组冲突目标下的最佳折衷候选材料集。",
            "id": "3926474",
            "problem": "您的任务是在两个目标（热力学稳定性和离子电导率）的预测不确定性下，为电池电极材料筛选构建一个稳健的帕累托集。设计背景是利用机器学习预测进行加速材料筛选的自动化电池设计和仿真。每种候选材料都通过以下特征来表征：一个关于凸包以上能量（表示为 $\\Delta E_{\\mathrm{hull}}$，单位为毫电子伏特/原子，即 meV/atom）的预测分布，以及一个关于离子电导率（表示为 $\\sigma$，单位为毫西门子/厘米，即 mS/cm）的预测分布。\n\n基本基础：\n- 假设机器学习模型为每种材料 $i$ 输出以下内容：\n  - 一个关于 $\\Delta E_{\\mathrm{hull}, i}$ 的预测正态分布，其均值为 $\\mu_{E,i}$，标准差为 $s_{E,i}$，模型为 $\\Delta E_{\\mathrm{hull}, i} \\sim \\mathcal{N}(\\mu_{E,i}, s_{E,i}^2)$。\n  - 一个关于电导率 $\\sigma_i$ 的预测对数正态分布，使得 $\\ln \\sigma_i \\sim \\mathcal{N}(\\mu_{\\ell,i}, s_{\\ell,i}^2)$，其中 $\\mu_{\\ell,i}$ 和 $s_{\\ell,i}$ 分别是电导率自然对数的均值和标准差。\n\n- 稳健可行性通过机会约束来强制执行：\n  - 稳定性机会约束：$\\mathbb{P}(\\Delta E_{\\mathrm{hull}, i} \\le 0) \\ge 1-\\alpha$。\n  - 电导率机会约束：$\\mathbb{P}(\\sigma_i \\ge \\sigma_0) \\ge 1-\\beta$。\n  此处，$\\alpha \\in (0,1)$ 和 $\\beta \\in (0,1)$ 是用户指定的风险水平，$\\sigma_0$ 是需要满足的电导率阈值。将 $\\Delta E_{\\mathrm{hull}, i} \\le 0$ meV/atom 解释为相对于凸包的热力学稳定性，将 $\\sigma_i \\ge \\sigma_0$ mS/cm 解释为满足最低所需电导率。\n\n- 在这些机会约束下，用于帕累托比较的稳健性能指标使用保守分位数：\n  - 对于稳定性，使用 $\\Delta E_{\\mathrm{hull}, i}$ 的上 $1-\\alpha$ 分位数 $q_{E,i}^{\\mathrm{up}}$。\n  - 对于电导率，使用 $\\sigma_i$ 的下 $\\beta$ 分位数 $q_{\\sigma,i}^{\\mathrm{low}}$。\n  这些分位数使用标准正态分位数 $z_p$ 定义，该分位数满足累积分布函数 $\\Phi$ 的 $\\Phi(z_p) = p$。对于正态变量 $\\Delta E_{\\mathrm{hull}, i}$，$q_{E,i}^{\\mathrm{up}} = \\mu_{E,i} + z_{1-\\alpha} s_{E,i}$。对于对数正态变量 $\\sigma_i$，$q_{\\sigma,i}^{\\mathrm{low}} = \\exp\\left(\\mu_{\\ell,i} + z_{\\beta} s_{\\ell,i}\\right)$。如果 $s_{E,i} = 0$ 或 $s_{\\ell,i} = 0$，则将分布解释为确定性的，因此相应的分位数等于变量的均值。\n\n- 可行性下的稳健帕累托集定义：\n  - 首先，确定稳健可行集 $\\mathcal{F} = \\{ i : \\mathbb{P}(\\Delta E_{\\mathrm{hull}, i} \\le 0) \\ge 1-\\alpha,\\, \\mathbb{P}(\\sigma_i \\ge \\sigma_0) \\ge 1-\\beta \\}$。\n  - 在 $i \\in \\mathcal{F}$ 中，如果 $q_{E,a}^{\\mathrm{up}} \\le q_{E,b}^{\\mathrm{up}}$ 且 $q_{\\sigma,a}^{\\mathrm{low}} \\ge q_{\\sigma,b}^{\\mathrm{low}}$，并且至少有一个严格不等式成立，则定义候选者 $a$ 在稳健意义上支配候选者 $b$。稳健帕累托集 $\\mathcal{P} \\subseteq \\mathcal{F}$ 是不受任何其他可行候选者支配的候选者集合。\n\n- 选择概率：\n  - 对于一个决策策略，当 $\\mathcal{P} \\neq \\emptyset$ 时从 $\\mathcal{P}$ 中均匀随机选择，当 $\\mathcal{P} = \\emptyset$ 时不选择任何对象，候选者 $i$ 的选择概率定义为：如果 $i \\in \\mathcal{P}$，则 $p^{\\mathrm{sel}}_i = \\frac{1}{|\\mathcal{P}|}$，否则 $p^{\\mathrm{sel}}_i = 0$。\n\n所有物理量必须以其指定的单位处理：$\\Delta E_{\\mathrm{hull}}$ 以 meV/atom 为单位，$\\sigma$ 以 mS/cm 为单位。角度不属于此问题。所有答案均为无单位的选择概率，表示为浮点数。\n\n您的任务是实现一个完整的、可运行的程序，该程序：\n- 通过机会约束评估每个测试用例的稳健可行性。\n- 使用保守分位数指标构建稳健帕累托集。\n- 按照描述计算每个候选者的选择概率。\n\n测试套件：\n- 案例 1（正常路径）：\n  - 参数：$\\alpha = 0.1$, $\\beta = 0.1$, $\\sigma_0 = 1.5$ mS/cm。\n  - 候选者（每个元组列出 $(\\mu_{E}\\,[\\mathrm{meV/atom}],\\, s_{E}\\,[\\mathrm{meV/atom}],\\, \\mu_{\\ell},\\, s_{\\ell})$）：\n    - M1: $(-1.0, 0.5, \\ln 1.8, 0.1)$\n    - M2: $(-0.5, 0.3, \\ln 1.2, 0.2)$\n    - M3: $(1.5, 1.0, \\ln 2.5, 0.3)$\n    - M4: $(4.0, 2.0, \\ln 4.0, 0.25)$\n    - M5: $(0.1, 0.7, \\ln 0.8, 0.2)$\n- 案例 2（严格约束边缘案例）：\n  - 参数：$\\alpha = 0.01$, $\\beta = 0.05$, $\\sigma_0 = 2.0$ mS/cm。\n  - 候选者：与案例 1 相同。\n- 案例 3（确定性变量边缘案例）：\n  - 参数：$\\alpha = 0.2$, $\\beta = 0.2$, $\\sigma_0 = 1.5$ mS/cm。\n  - 候选者：\n    - F1: $(0.0, 0.0, \\ln 1.7, 0.0)$\n    - F2: $(-0.5, 0.3, \\ln 2.0, 0.3)$\n    - F3: $(4.0, 8.0, \\ln 0.5, 0.4)$\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素对应一个测试用例，并且本身是该测试用例中候选者选择概率的浮点数列表，顺序与候选者顺序相同。例如，一个有效的输出结构形式为 $[ [p_1, p_2], [q_1, q_2, q_3] ]$。",
            "solution": "该问题要求在不确定性下为筛选电池电极材料构建一个稳健的帕累托集。目标是基于两个相互冲突的目标——最大化热力学稳定性和最大化离子电导率——来识别一组非支配的候选者。机器学习对这些属性预测的不确定性通过概率分布来建模。解决方案涉及一个多步骤过程，包括稳健可行性分析、多目标优化和选择概率的计算。\n\n首先，我们必须形式化候选材料被视为“稳健可行”的条件。问题使用机会约束来定义可行性，这些约束为满足特定性能阈值的概率设定了下限。\n\n对于热力学稳定性，我们关注的属性是每种材料 $i$ 的凸包以上能量 $\\Delta E_{\\mathrm{hull}, i}$。这被建模为一个正态分布，$\\Delta E_{\\mathrm{hull}, i} \\sim \\mathcal{N}(\\mu_{E,i}, s_{E,i}^2)$。如果材料的能量为非正值，即 $\\Delta E_{\\mathrm{hull}, i} \\le 0$，则认为该材料是稳定的。稳定性机会约束要求此条件以至少 $1-\\alpha$ 的概率成立：\n$$\n\\mathbb{P}(\\Delta E_{\\mathrm{hull}, i} \\le 0) \\ge 1-\\alpha\n$$\n为了使此条件可操作，我们将随机变量标准化。设 $Z \\sim \\mathcal{N}(0, 1)$ 为一个标准正态变量。该约束变为：\n$$\n\\mathbb{P}\\left(\\frac{\\Delta E_{\\mathrm{hull}, i} - \\mu_{E,i}}{s_{E,i}} \\le \\frac{0 - \\mu_{E,i}}{s_{E,i}}\\right) \\ge 1-\\alpha \\quad \\implies \\quad \\Phi\\left(\\frac{-\\mu_{E,i}}{s_{E,i}}\\right) \\ge 1-\\alpha\n$$\n其中 $\\Phi$ 是标准正态分布的累积分布函数（CDF）。利用属性 $\\Phi(-x) = 1-\\Phi(x)$，这等价于 $1 - \\Phi\\left(\\frac{\\mu_{E,i}}{s_{E,i}}\\right) \\ge 1-\\alpha$，可简化为 $\\Phi\\left(\\frac{\\mu_{E,i}}{s_{E,i}}\\right) \\le \\alpha$。应用逆CDF $\\Phi^{-1}$（也称为分位数函数或概率单位函数），我们得到 $\\frac{\\mu_{E,i}}{s_{E,i}} \\le z_{\\alpha}$，其中 $z_p = \\Phi^{-1}(p)$。这可以重新排列为 $\\mu_{E,i} - z_{\\alpha} s_{E,i} \\le 0$。利用恒等式 $z_{\\alpha} = -z_{1-\\alpha}$，条件变为 $\\mu_{E,i} + z_{1-\\alpha} s_{E,i} \\le 0$。这个表达式正是 $\\Delta E_{\\mathrm{hull}, i}$ 的上 $1-\\alpha$ 分位数，表示为 $q_{E,i}^{\\mathrm{up}}$。因此，稳定性可行性条件被巧妙地简化为：\n$$\nq_{E,i}^{\\mathrm{up}} = \\mu_{E,i} + z_{1-\\alpha} s_{E,i} \\le 0\n$$\n\n对于离子电导率 $\\sigma_i$，该属性由一个对数正态分布建模，使其自然对数遵循正态分布：$\\ln \\sigma_i \\sim \\mathcal{N}(\\mu_{\\ell,i}, s_{\\ell,i}^2)$。电导率机会约束要求 $\\sigma_i$ 至少达到一个阈值 $\\sigma_0$，且概率至少为 $1-\\beta$：\n$$\n\\mathbb{P}(\\sigma_i \\ge \\sigma_0) \\ge 1-\\beta\n$$\n通过取自然对数（这是一个单调函数），我们可以处理正态分布的变量 $\\ln \\sigma_i$：\n$$\n\\mathbb{P}(\\ln \\sigma_i \\ge \\ln \\sigma_0) \\ge 1-\\beta\n$$\n将此变量标准化得到：\n$$\n\\mathbb{P}\\left(\\frac{\\ln \\sigma_i - \\mu_{\\ell,i}}{s_{\\ell,i}} \\ge \\frac{\\ln \\sigma_0 - \\mu_{\\ell,i}}{s_{\\ell,i}}\\right) \\ge 1-\\beta \\quad \\implies \\quad 1 - \\Phi\\left(\\frac{\\ln \\sigma_0 - \\mu_{\\ell,i}}{s_{\\ell,i}}\\right) \\ge 1-\\beta\n$$\n这简化为 $\\Phi\\left(\\frac{\\ln \\sigma_0 - \\mu_{\\ell,i}}{s_{\\ell,i}}\\right) \\le \\beta$。应用逆CDF，我们得到 $\\frac{\\ln \\sigma_0 - \\mu_{\\ell,i}}{s_{\\ell,i}} \\le z_{\\beta}$，重新排列为 $\\ln \\sigma_0 \\le \\mu_{\\ell,i} + z_{\\beta} s_{\\ell,i}$。对两边取指数得到 $\\sigma_0 \\le \\exp(\\mu_{\\ell,i} + z_{\\beta} s_{\\ell,i})$。右侧是 $\\sigma_i$ 的下 $\\beta$ 分位数的定义，表示为 $q_{\\sigma,i}^{\\mathrm{low}}$。所以，电导率可行性条件是：\n$$\nq_{\\sigma,i}^{\\mathrm{low}} = \\exp(\\mu_{\\ell,i} + z_{\\beta} s_{\\ell,i}) \\ge \\sigma_0\n$$\n一个候选材料 $i$ 当且仅当它同时满足这两个基于分位数的条件时，才是稳健可行的。所有这些材料的集合表示为 $\\mathcal{F}$。\n\n下一步是从可行集 $\\mathcal{F}$ 中找到稳健帕累托集 $\\mathcal{P}$。优化目标是最小化稳健稳定性指标 $q_{E,i}^{\\mathrm{up}}$（值越低越好）和最大化稳健电导率指标 $q_{\\sigma,i}^{\\mathrm{low}}$（值越高越好）。对于任意两个可行候选者 $a, b \\in \\mathcal{F}$，如果满足以下条件，则称候选者 $a$ 支配候选者 $b$：\n$$\n(q_{E,a}^{\\mathrm{up}} \\le q_{E,b}^{\\mathrm{up}} \\land q_{\\sigma,a}^{\\mathrm{low}} \\ge q_{\\sigma,b}^{\\mathrm{low}}) \\land (q_{E,a}^{\\mathrm{up}}  q_{E,b}^{\\mathrm{up}} \\lor q_{\\sigma,a}^{\\mathrm{low}} > q_{\\sigma,b}^{\\mathrm{low}})\n$$\n这意味着 $a$ 在两个目标上都至少与 $b$ 一样好，并且在至少一个目标上严格更优。稳健帕累托集 $\\mathcal{P}$ 是 $\\mathcal{F}$ 中所有不被 $\\mathcal{F}$ 中任何其他候选者支配的候选者的子集。找到 $\\mathcal{P}$ 的算法如下：对于每个候选者 $i \\in \\mathcal{F}$，将其与每个其他候选者 $j \\in \\mathcal{F}$ 进行比较。如果任何 $j$ 支配 $i$，那么 $i$ 不在帕累托集中。如果在检查完所有其他可行候选者后不存在这样的 $j$，那么 $i$ 是 $\\mathcal{P}$ 的成员。\n\n最后，我们计算每个候选者的选择概率。该概率是基于从非空帕累托集中均匀随机选择的策略定义的。如果帕累托集 $\\mathcal{P}$ 非空（$|\\mathcal{P}| > 0$），则候选者 $i$ 的选择概率 $p^{\\mathrm{sel}}_i$ 为：\n$$\np^{\\mathrm{sel}}_i =\n\\begin{cases}\n1/|\\mathcal{P}|  \\text{if } i \\in \\mathcal{P} \\\\\n0  \\text{if } i \\notin \\mathcal{P}\n\\end{cases}\n$$\n如果帕累托集为空（$\\mathcal{P} = \\emptyset$），这发生在可行集 $\\mathcal{F}$ 为空时，则所有候选者的选择概率均为 $0$。\n\n每个测试用例的总体流程是：\n1.  读取控制参数 $\\alpha$、$\\beta$、$\\sigma_0$ 和候选材料数据 $(\\mu_{E,i}, s_{E,i}, \\mu_{\\ell,i}, s_{\\ell,i})$。\n2.  使用数值库计算必要的标准正态分位数 $z_{1-\\alpha}$ 和 $z_{\\beta}$。\n3.  对于每个候选者 $i$：\n    a. 计算稳健性能指标 $q_{E,i}^{\\mathrm{up}}$ 和 $q_{\\sigma,i}^{\\mathrm{low}}$。\n    b. 检查是否 $q_{E,i}^{\\mathrm{up}} \\le 0$ 且 $q_{\\sigma,i}^{\\mathrm{low}} \\ge \\sigma_0$。\n    c. 如果可行，存储候选者的索引及其目标向量 $(q_{E,i}^{\\mathrm{up}}, q_{\\sigma,i}^{\\mathrm{low}})$。\n4.  通过识别所有非支配成员，从可行候选者集合中构建帕累托集 $\\mathcal{P}$。\n5.  根据 $\\mathcal{P}$ 的大小和组成，计算所有初始候选者的选择概率。\n6.  收集当前测试用例的概率列表，并对所有案例重复此过程。最终输出是这些概率列表的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the robust materials screening problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"params\": {\"alpha\": 0.1, \"beta\": 0.1, \"sigma_0\": 1.5},\n            \"candidates\": [\n                # M1: mu_E, s_E, mu_l, s_l\n                (-1.0, 0.5, np.log(1.8), 0.1),\n                # M2\n                (-0.5, 0.3, np.log(1.2), 0.2),\n                # M3\n                (1.5, 1.0, np.log(2.5), 0.3),\n                # M4\n                (4.0, 2.0, np.log(4.0), 0.25),\n                # M5\n                (0.1, 0.7, np.log(0.8), 0.2)\n            ]\n        },\n        {\n            \"params\": {\"alpha\": 0.01, \"beta\": 0.05, \"sigma_0\": 2.0},\n            \"candidates\": [\n                # M1\n                (-1.0, 0.5, np.log(1.8), 0.1),\n                # M2\n                (-0.5, 0.3, np.log(1.2), 0.2),\n                # M3\n                (1.5, 1.0, np.log(2.5), 0.3),\n                # M4\n                (4.0, 2.0, np.log(4.0), 0.25),\n                # M5\n                (0.1, 0.7, np.log(0.8), 0.2)\n            ]\n        },\n        {\n            \"params\": {\"alpha\": 0.2, \"beta\": 0.2, \"sigma_0\": 1.5},\n            \"candidates\": [\n                # F1\n                (0.0, 0.0, np.log(1.7), 0.0),\n                # F2\n                (-0.5, 0.3, np.log(2.0), 0.3),\n                # F3\n                (4.0, 8.0, np.log(0.5), 0.4)\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        params = case[\"params\"]\n        candidates_data = case[\"candidates\"]\n        \n        alpha = params[\"alpha\"]\n        beta = params[\"beta\"]\n        sigma_0 = params[\"sigma_0\"]\n        num_candidates = len(candidates_data)\n\n        # Compute standard normal quantiles\n        z_1_minus_alpha = norm.ppf(1 - alpha)\n        z_beta = norm.ppf(beta)\n        \n        feasible_candidates = []\n        for i, (mu_E, s_E, mu_l, s_l) in enumerate(candidates_data):\n            # Calculate robust performance metrics (quantiles)\n            q_E_up = mu_E + z_1_minus_alpha * s_E\n            q_sigma_low = np.exp(mu_l + z_beta * s_l)\n            \n            # Check for robust feasibility\n            is_stable = (q_E_up = 0)\n            is_conductive = (q_sigma_low >= sigma_0)\n            \n            if is_stable and is_conductive:\n                feasible_candidates.append({\n                    \"id\": i,\n                    \"q_E\": q_E_up,\n                    \"q_sigma\": q_sigma_low\n                })\n\n        # Construct the robust Pareto set\n        pareto_set_indices = []\n        if feasible_candidates:\n            for i, cand_i in enumerate(feasible_candidates):\n                is_dominated = False\n                for j, cand_j in enumerate(feasible_candidates):\n                    if i == j:\n                        continue\n                    \n                    # Check if cand_j dominates cand_i\n                    # Objectives: minimize q_E, maximize q_sigma\n                    c1 = cand_j[\"q_E\"] = cand_i[\"q_E\"]\n                    c2 = cand_j[\"q_sigma\"] >= cand_i[\"q_sigma\"]\n                    c3 = cand_j[\"q_E\"]  cand_i[\"q_E\"] or cand_j[\"q_sigma\"] > cand_i[\"q_sigma\"]\n                    \n                    if c1 and c2 and c3:\n                        is_dominated = True\n                        break\n                \n                if not is_dominated:\n                    pareto_set_indices.append(cand_i[\"id\"])\n\n        # Calculate selection probabilities\n        probabilities = [0.0] * num_candidates\n        if pareto_set_indices:\n            prob = 1.0 / len(pareto_set_indices)\n            for idx in pareto_set_indices:\n                probabilities[idx] = prob\n        \n        results.append(probabilities)\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list of lists matches the example format.\n    print(results)\n\nsolve()\n```"
        }
    ]
}