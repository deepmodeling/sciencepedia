{
    "hands_on_practices": [
        {
            "introduction": "电池的循环测试会产生高维数据，其中每个循环都可能包含数十个特征。主成分分析（PCA）是一种强大的降维技术，可以将这些复杂的特征提炼为少数几个信息丰富的“主成分”。本练习将引导你从第一性原理出发，推导主成分如何捕捉数据的总方差，这是特征工程和探索性数据分析中的一项核心技能 。",
            "id": "3926067",
            "problem": "一个包含 $n$ 个锂离子电池循环的数据集由每个循环提取的 $p$ 个标量特征描述：充电过程中的电压平台持续时间、$\\mathrm{LiC}_6/\\mathrm{LiC}_{12}$ 相变附近的微分容量峰值大小、中频下的阻抗幅值、达到预设截止条件的充电时间以及往返能量效率。每个特征在整个数据集中被标准化，以实现零均值和单位方差。设均值中心化和标准化的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，无偏样本协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。\n\n请定义主成分分析 (PCA)，并从协方差和标准正交特征分解的定义出发，根据第一性原理推导前 $k$ 个主成分解释的总方差比例的表达式（用 $\\Sigma$ 的特征值表示）。\n\n然后，在 $p = 5$ 的特定情况下，$\\Sigma$ 的特征值为 $\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$ 和 $\\lambda_{5} = 0.2$，计算前 $k = 2$ 个主成分解释的方差比例。将您的最终结果表示为小数，并将答案四舍五入到四位有效数字。不要使用百分号。",
            "solution": "首先验证问题，以确保其具有科学依据、提法恰当且客观。\n\n**步骤 1：提取已知条件**\n- 一个包含 $n$ 个锂离子电池循环的数据集。\n- 每个循环提取 $p$ 个标量特征。\n- 特征被标准化为零均值和单位方差。\n- 均值中心化和标准化的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$。\n- 无偏样本协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。\n- 任务 1：定义主成分分析 (PCA)，并从协方差和标准正交特征分解的定义出发，推导前 $k$ 个主成分解释的总方差比例的表达式（用 $\\Sigma$ 的特征值表示）。推导必须从协方差和标准正交特征分解的定义开始。\n- 任务 2：在 $p = 5$ 且 $\\Sigma$ 的特征值为 $\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$ 和 $\\lambda_{5} = 0.2$ 的特定情况下，计算前 $k = 2$ 个主成分解释的方差比例。\n- 最终数值结果必须表示为四舍五入到四位有效数字的小数。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 问题在实际应用（电池数据分析）的背景下，使用了线性代数和统计学的标准、公认原理（PCA、协方差、特征值）。其前提是合理的。一个关键的一致性检查是，对于标准化数据（其中每个特征的方差为 $1$），总方差等于特征数量 $p$。总方差也是协方差矩阵的迹，它等于其特征值的总和。此处，$p=5$，给定特征值的总和为 $\\lambda_1 + \\lambda_2 + \\lambda_3 + \\lambda_4 + \\lambda_5 = 2.1 + 1.3 + 0.9 + 0.5 + 0.2 = 5.0$。这与 $p=5$ 相符，证实了问题陈述的内部一致性和科学有效性。\n- **提法恰当：** 问题要求进行标准的理论推导和具体的计算。它为得出唯一解提供了所有必要的信息。\n- **客观性：** 语言清晰、精确，并且没有任何主观论断。\n\n**步骤 3：结论与行动**\n问题有效。将提供解答，首先进行推导，然后进行具体计算。\n\n### 第 1 部分：推导\n\n主成分分析 (PCA) 是一种用于降维的线性变换技术。它将一组可能相关的变量的观测值，转换为一组称为主成分的线性不相关变量的值。该变换的定义方式是：第一个主成分具有最大可能的方差（即，它尽可能多地解释数据中的变异性），而后续的每个成分则在与前面所有成分正交的约束下，具有尽可能大的方差。\n\n设均值中心化的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$。无偏样本协方差矩阵 $\\Sigma$ 由下式给出：\n$$\n\\Sigma = \\frac{1}{n-1} X^T X\n$$\n主成分是原始特征的线性组合。这个线性组合的方向可以用一个单位向量 $w \\in \\mathbb{R}^p$ (其中 $w^T w = 1$) 表示。这 $n$ 个数据点投影到这个方向上的得分由向量 $z = Xw$ 给出。\n\n这些投影得分的方差为：\n$$\n\\text{Var}(z) = \\frac{1}{n-1} z^T z = \\frac{1}{n-1} (Xw)^T (Xw) = \\frac{1}{n-1} w^T X^T X w\n$$\n代入 $\\Sigma$ 的表达式，我们得到：\n$$\n\\text{Var}(z) = w^T \\left( \\frac{1}{n-1} X^T X \\right) w = w^T \\Sigma w\n$$\n第一个主成分是通过选择使该方差最大化的方向 $w_1$ 来找到的，其约束条件是 $w_1$ 为单位向量。这是一个约束优化问题：\n$$\n\\max_{w_1} w_1^T \\Sigma w_1 \\quad \\text{subject to} \\quad w_1^T w_1 = 1\n$$\n我们使用拉格朗日乘子法。拉格朗日函数是：\n$$\nL(w_1, \\lambda) = w_1^T \\Sigma w_1 - \\lambda(w_1^T w_1 - 1)\n$$\n为了求最大值，我们计算关于 $w_1$ 的梯度并将其设为零。由于 $\\Sigma$ 是对称的， $w_1^T \\Sigma w_1$ 关于 $w_1$ 的导数是 $2\\Sigma w_1$。$w_1^T w_1$ 的导数是 $2w_1$。\n$$\n\\frac{\\partial L}{\\partial w_1} = 2\\Sigma w_1 - 2\\lambda w_1 = 0\n$$\n这可以简化为特征值方程：\n$$\n\\Sigma w_1 = \\lambda w_1\n$$\n这表明最优方向 $w_1$ 必须是协方差矩阵 $\\Sigma$ 的一个特征向量，而 $\\lambda$ 是其对应的特征值。为了确定哪个特征向量使方差最大化，我们将 $\\Sigma w_1 = \\lambda w_1$ 代回方差表达式中：\n$$\n\\text{Var}(z) = w_1^T \\Sigma w_1 = w_1^T (\\lambda w_1) = \\lambda (w_1^T w_1)\n$$\n由于 $w_1^T w_1 = 1$，我们有：\n$$\n\\text{Var}(z) = \\lambda\n$$\n数据投影到特征向量上的方差等于对应的特征值。为了使方差最大化，我们必须选择对应于最大特征值 $\\lambda_1$ 的特征向量 $w_1$。因此，第一个主成分是具有最大特征值的特征向量的方向，它解释的方差为 $\\lambda_1$。\n\n后续的主成分通过在与所有先前成分正交的方向上最大化方差来找到。这个过程系统地按照相应特征值降序选择 $\\Sigma$ 的特征向量。第 $j$ 个主成分对应于具有第 $j$ 大特征值 $\\lambda_j$ 的特征向量 $w_j$，它解释的方差为 $\\lambda_j$。\n\n原始数据集的总方差是各个特征方差的总和，也就是协方差矩阵对角线元素之和，即其迹：\n$$\n\\text{Total Variance} = \\text{tr}(\\Sigma) = \\sum_{i=1}^{p} \\Sigma_{ii}\n$$\n协方差矩阵 $\\Sigma$ 是一个实对称矩阵，因此它允许进行标准正交特征分解 $\\Sigma = W \\Lambda W^T$，其中 $W$ 是一个正交矩阵 ($W^T W = I$)，其列是特征向量 $w_j$，而 $\\Lambda$ 是由特征值 $\\lambda_j$ 构成的对角矩阵。利用迹的循环性质 ($\\text{tr}(ABC) = \\text{tr}(BCA)$)：\n$$\n\\text{tr}(\\Sigma) = \\text{tr}(W \\Lambda W^T) = \\text{tr}(W^T W \\Lambda) = \\text{tr}(I \\Lambda) = \\text{tr}(\\Lambda)\n$$\n对角矩阵 $\\Lambda$ 的迹是其对角线元素之和，即特征值之和：\n$$\n\\text{Total Variance} = \\sum_{j=1}^{p} \\lambda_j\n$$\n数据集的总方差等于其协方差矩阵的特征值之和。\n\n前 $k$ 个主成分解释的方差是它们各自方差的总和：\n$$\n\\text{Variance explained by first } k \\text{ PCs} = \\sum_{j=1}^{k} \\lambda_j\n$$\n因此，前 $k$ 个主成分解释的总方差比例是它们解释的方差与总方差之比：\n$$\n\\text{Fraction of Variance} = \\frac{\\sum_{j=1}^{k} \\lambda_j}{\\sum_{j=1}^{p} \\lambda_j}\n$$\n推导至此完成。\n\n### 第 2 部分：计算\n\n给定 $p = 5$ 个特征，要求计算前 $k=2$ 个主成分解释的方差比例。特征值按降序给出：\n$\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$, 和 $\\lambda_{5} = 0.2$。\n\n前 $k=2$ 个主成分解释的方差是前两个特征值的和：\n$$\n\\sum_{j=1}^{2} \\lambda_j = \\lambda_1 + \\lambda_2 = 2.1 + 1.3 = 3.4\n$$\n总方差是所有 $p=5$ 个特征值的和：\n$$\n\\sum_{j=1}^{5} \\lambda_j = \\lambda_1 + \\lambda_2 + \\lambda_3 + \\lambda_4 + \\lambda_5 = 2.1 + 1.3 + 0.9 + 0.5 + 0.2 = 5.0\n$$\n前 $k=2$ 个主成分解释的方差比例为：\n$$\n\\text{Fraction} = \\frac{\\sum_{j=1}^{2} \\lambda_j}{\\sum_{j=1}^{5} \\lambda_j} = \\frac{3.4}{5.0} = 0.68\n$$\n题目要求答案四舍五入到四位有效数字。\n$$\n0.68 = 0.6800\n$$",
            "answer": "$$\\boxed{0.6800}$$"
        },
        {
            "introduction": "预测电池寿命是机器学习在电池领域的关键应用，但实验数据常常受到传感器故障或测试中断导致的异常值的干扰。标准的平方误差损失对这些异常值非常敏感，可能导致模型出现偏差，而Huber损失则通过结合平方损失和绝对值损失的优点，提供了一种更为稳健的选择。通过推导Huber损失的梯度，本练习将揭示其如何通过限制异常样本对梯度的贡献，来提高模型在处理含噪声电池数据时的稳定性和准确性 。",
            "id": "3926194",
            "problem": "在自动化电池设计和仿真中，考虑使用监督回归，从高保真仿真描述符中预测循环寿命。令输入描述符向量为 $\\{x_i\\}_{i=1}^{N}$，其中 $x_i \\in \\mathbb{R}^{d}$，测得的循环寿命为 $\\{y_i\\}_{i=1}^{N}$，其中每个 $y_i$ 是达到指定寿命终结标准前的充放电循环次数。假设一个线性预测器 $f_{\\theta}(x) = x^{\\top}\\theta$，其参数向量为 $\\theta \\in \\mathbb{R}^{d}$，残差为 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$。由于测试中断和传感器校准不当，$y_i$ 的测量过程会偶尔出现较大误差，从而导致重尾残差分布。\n\n从经验风险最小化原则出发，定义一个鲁棒损失函数，该函数在小残差时插值为平方损失，在大残差时插值为绝对值损失。使用此定义作为数据保真度项，为数据集 $\\{(x_i, y_i)\\}_{i=1}^{N}$ 构建经验目标函数 $J(\\theta)$，并推导其梯度 $\\nabla_{\\theta} J(\\theta)$。你的推导必须从基于损失的风险的基本定义开始，并通过应用向量值参数的链式法则进行。\n\n利用你推导出的梯度的结构，解释为什么在存在噪声电池寿命测量的情况下，这种损失比纯平方损失对离群点更鲁棒。明确描述当 $|r_i(\\theta)|$ 增大时，每个样本对梯度的贡献如何变化，以及这如何影响面对极端残差时的优化稳定性。\n\n将你的最终答案表示为关于 $x_i$、$y_i$、$\\theta$ 和一个正常数阈值参数 $\\delta$ 的单个闭式解析表达式，其中包含 $N$ 个样本。不需要进行数值评估。不要报告中间结果。如果你在推导中引入了任何辅助函数，请在推导中定义它们，但要确保最终答案写成单个表达式。最终答案必须是无单位的，并且不需要四舍五入。",
            "solution": "该问题陈述被评估为有效。它在科学上基于标准的机器学习原理，问题设定良好，目标明确，并且没有任何列出的无效缺陷。\n\n**1. 鲁棒损失函数的定义**\n\n经验风险最小化原则指出，我们寻求一个参数向量 $\\theta$ 来最小化一个目标函数 $J(\\theta)$，该函数定义为在数据集上的平均损失。\n$$\nJ(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f_{\\theta}(x_i))\n$$\n问题要求一个鲁棒的损失函数，该函数在小残差时插值为平方损失（$L_2$），在大残差时插值为绝对值损失（$L_1$）。这是 Huber 损失的特性，它使用一个正常数阈值参数 $\\delta$ 来定义。设残差为 $r = f_{\\theta}(x) - y = x^{\\top}\\theta - y$。Huber 损失 $L_{\\delta}(r)$ 由下式给出：\n$$\nL_{\\delta}(r) =\n\\begin{cases}\n\\frac{1}{2} r^2  \\text{if } |r| \\le \\delta \\\\\n\\delta|r| - \\frac{1}{2}\\delta^2  \\text{if } |r| > \\delta\n\\end{cases}\n$$\n该函数对于小残差（$|r| \\le \\delta$）是二次的，以提高效率；对于大残差（$|r| > \\delta$）是线性的，以提供对离群点的鲁棒性。项 $-\\frac{1}{2}\\delta^2$ 确保了函数在 $|r| = \\delta$ 点是连续的。损失函数对残差 $r$ 的一阶导数也是连续的：\n$$\n\\frac{dL_{\\delta}}{dr}(r) =\n\\begin{cases}\nr  \\text{if } |r| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(r)  \\text{if } |r| > \\delta\n\\end{cases}\n$$\n其中 $\\text{sgn}(r)$ 是符号函数。\n\n**2. 经验目标函数的构建与梯度推导**\n\n使用 Huber 损失作为数据保真度项，数据集 $\\{(x_i, y_i)\\}_{i=1}^{N}$ 的经验目标函数 $J(\\theta)$ 是所有样本的平均损失：\n$$\nJ(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L_{\\delta}(r_i(\\theta))\n$$\n其中 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$。\n\n为了求梯度 $\\nabla_{\\theta} J(\\theta)$，我们将 $J(\\theta)$ 对向量 $\\theta$ 求导。根据梯度算子的线性性质：\n$$\n\\nabla_{\\theta} J(\\theta) = \\nabla_{\\theta} \\left( \\frac{1}{N} \\sum_{i=1}^{N} L_{\\delta}(r_i(\\theta)) \\right) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} L_{\\delta}(r_i(\\theta))\n$$\n我们对求和中的每一项应用向量值参数的链式法则。损失 $L_{\\delta}$ 是标量残差 $r_i$ 的标量函数，而 $r_i$ 又是向量参数 $\\theta$ 的标量函数。\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) = \\frac{dL_{\\delta}}{dr_i}(r_i(\\theta)) \\cdot \\nabla_{\\theta} r_i(\\theta)\n$$\n首先，我们计算残差 $r_i(\\theta)$ 对 $\\theta$ 的梯度：\n$$\nr_i(\\theta) = x_i^{\\top}\\theta - y_i\n$$\n$$\n\\nabla_{\\theta} r_i(\\theta) = \\nabla_{\\theta} (x_i^{\\top}\\theta - y_i) = x_i\n$$\n现在，将导数代回链式法则表达式中：\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) = \\left( \\begin{cases} r_i(\\theta)  \\text{if } |r_i(\\theta)| \\le \\delta \\\\ \\delta \\cdot \\text{sgn}(r_i(\\theta))  \\text{if } |r_i(\\theta)| > \\delta \\end{cases} \\right) \\cdot x_i\n$$\n代入 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$，每个样本对梯度的贡献为：\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) =\n\\begin{cases}\n(x_i^{\\top}\\theta - y_i)x_i  \\text{if } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i  \\text{if } |x_i^{\\top}\\theta - y_i| > \\delta\n\\end{cases}\n$$\n最后，对所有 $N$ 个样本求和并除以 $N$，得到目标函数的完整梯度：\n$$\n\\nabla_{\\theta} J(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N}\n\\begin{cases}\n(x_i^{\\top}\\theta - y_i)x_i  \\text{if } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i  \\text{if } |x_i^{\\top}\\theta - y_i| > \\delta\n\\end{cases}\n$$\n\n**3. 对离群点鲁棒性的分析**\n\nHuber 损失的鲁棒性从其梯度的结构中显而易见，特别是与纯平方损失（均方误差，MSE）的梯度相比。对于 MSE，单个样本的损失是 $\\frac{1}{2}r_i^2$，其对应的梯度贡献始终是 $r_i(\\theta)x_i = (x_i^{\\top}\\theta - y_i)x_i$。\n\n-   **对于小残差 ($|r_i(\\theta)| \\le \\delta$)：** Huber 损失的梯度贡献是 $(x_i^{\\top}\\theta - y_i)x_i$。这与平方损失的梯度贡献相同。在这个范围内，数据点被认为是“内点”并且与模型拟合得很好，优化行为类似于标准最小二乘法。\n\n-   **对于大残差 ($|r_i(\\theta)| > \\delta$)：** 这是鲁棒性的关键区域。\n    -   对于**平方损失**，梯度贡献的幅度 $\\|(x_i^{\\top}\\theta - y_i)x_i\\| = |r_i(\\theta)| \\|x_i\\|$ 会随着残差幅度 $|r_i(\\theta)|$ 的增加而*线性且无界地增长*。一个具有非常大残差的离群点（由于传感器校准不当等原因）将产生一个不成比例的大梯度。在像梯度下降这样的优化算法中，这单个离群点可能会主导梯度更新步骤，将参数向量 $\\theta$ 拉离对其他数据最优的解。这会导致不稳定性，并使最终模型严重偏向离群点。\n\n    -   对于**Huber 损失**，一旦残差超过 $\\delta$，梯度贡献的幅度就变为常数。其贡献为 $\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i$，其幅度为 $\\|\\delta \\cdot \\text{sgn}(r_i(\\theta)) \\cdot x_i\\| = \\delta \\|x_i\\|$。该值与残差幅度 $|r_i(\\theta)|$ *无关*。这意味着一个具有极大残差的离群点对梯度更新的贡献不会超过一个残差刚刚超过 $\\delta$ 的点。梯度被有效地“裁剪”（clipped）。\n\n这种裁剪机制防止了离群点对梯度产生无界的影响。它确保了优化过程更加稳定，并且最终参数 $\\theta$ 能反映大多数数据的基本趋势，而不是被少数异常测量值所扭曲。因此，在存在重尾噪声和离群点（如问题中所述的噪声电池寿命测量）的情况下，Huber 损失比平方损失更鲁棒。",
            "answer": "$$ \\boxed{ \\frac{1}{N} \\sum_{i=1}^{N} \\begin{cases} (x_i^{\\top}\\theta - y_i)x_i  \\text{if } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\ \\delta \\, \\text{sgn}(x_i^{\\top}\\theta - y_i) x_i  \\text{if } |x_i^{\\top}\\theta - y_i| > \\delta \\end{cases} } $$"
        },
        {
            "introduction": "电池失效预测是一个经典的分类问题，但失效事件通常很罕见，导致数据集高度不平衡。用于交叉验证的简单随机抽样可能会产生不包含任何失效样本的折叠，从而使模型评估不可靠，而分层抽样则能确保每个折叠都反映整体的类别分布。本练习模拟了一个带有批次效应的复杂场景，要求你在保证类别平衡和批次多样性的双重约束下构建交叉验证折叠，这有助于你深入理解分层策略在处理不平衡工业数据时的重要性 。",
            "id": "3926147",
            "problem": "一个用于“自动化电池设计与仿真”的电池失效预测数据集，包含了按制造批次分组的电芯级测量数据。每个电芯被标记为三个类别之一：类别 $0$（健康）、类别 $1$（早期容量衰减）和类别 $2$（内部短路）。该数据集共有 $B=10$ 个批次，总计 $N=500$ 个电芯。每个批次的计数如下：\n- 批次 $1$：类别 $0$：$50$，类别 $1$：$5$，类别 $2$：$2$。\n- 批次 $2$：类别 $0$：$40$，类别 $1$：$8$，类别 $2$：$0$。\n- 批次 $3$：类别 $0$：$45$，类别 $1$：$9$，类别 $2$：$1$。\n- 批次 $4$：类别 $0$：$48$，类别 $1$：$8$，类别 $2$：$3$。\n- 批次 $5$：类别 $0$：$42$，类别 $1$：$12$，类别 $2$：$2$。\n- 批次 $6$：类别 $0$：$39$，类别 $1$：$10$，类别 $2$：$1$。\n- 批次 $7$：类别 $0$：$45$，类别 $1$：$12$，类别 $2$：$0$。\n- 批次 $8$：类别 $0$：$41$，类别 $1$：$8$，类别 $2$：$5$。\n- 批次 $9$：类别 $0$：$25$，类别 $1$：$5$，类别 $2$：$3$。\n- 批次 $10$：类别 $0$：$25$，类别 $1$：$3$，类别 $2$：$3$。\n\n总计为：类别 $0$：$400$，类别 $1$：$80$，类别 $2$：$20$，因此全局类别比例为 $p_0=400/500=0.8$，$p_1=80/500=0.16$ 和 $p_2=20/500=0.04$。\n\n要求您在以下约束条件下构建 $K=5$ 个用于交叉验证 (CV) 的分层折，这些约束旨在确保少数失效类别的最小批次代表性：\n- 每个折必须包含来自至少 $m_1=3$ 个包含类别 $1$ 的不同批次的样本，以及来自至少 $m_2=2$ 个包含类别 $2$ 的不同批次的样本。\n- 如果一个批次为某个折贡献了类别 $1$ 的样本，则从该批次分配至少 $s_{\\min,1}=2$ 个类别 $1$ 的样本到该折。如果一个批次为某个折贡献了类别 $2$ 的样本，则从该批次分配至少 $s_{\\min,2}=1$ 个类别 $2$ 的样本到该折。\n- 在一个折中满足这些最小批次代表性约束后，通过对剩余样本池进行分层抽样来填充该折中的剩余位置，并尽可能保持剩余样本的全局类别比例。\n- 每个折的大小为 $N/K=100$。\n\n从分层抽样的定义和全期望定律出发，解释在具有批次效应的电池数据集中，分层划分如何处理不平衡的失效类别，并根据上述约束计算每个折中的期望类别比例。选择每个折期望类别比例的正确选项。\n\nA. 类别 $0$：$0.80$，类别 $1$：$0.16$，类别 $2$：$0.04$。\n\nB. 类别 $0$：$0.78$，类别 $1$：$0.18$，类别 $2$：$0.04$。\n\nC. 类别 $0$：$0.80$，类别 $1$：$0.12$，类别 $2$：$0.08$。\n\nD. 类别 $0$：$0.79$，类别 $1$：$0.15$，类别 $2$：$0.06$。",
            "solution": "问题陈述已经过验证，并且在其约束的標準解釋下被认为是具有科学依据、一致且提法明确的。所有给定数据，包括类别计数（$N_0=400$，$N_1=80$，$N_2=20$）和总样本量（$N=500$），都是内部一致的。任务是双重的：首先，解释分层划分对于具有批次效应的不平衡数据集的作用；其次，计算 $K=5$ 个交叉验证折中每个折的期望类别比例。\n\n**分层划分的概念性解释**\n\n在机器学习中，尤其是在处理像电池失效预测这类不平衡数据集时，用于交叉验证的标准随机抽样可能会带来问题。像“内部短路”（类别 $2$）这样的少数类别，可能偶然地在某个测试折中完全缺失。这将导致在该次交叉验证迭代中无法对该类别进行性能评估，从而得出一个不可靠且有偏的总体性能估计。\n\n分层抽样直接解决了这个问题。根据定义，分层是在抽样前将总体划分为同质子群（层）的过程。在交叉验证的背景下，这些层就是各个类别。分层划分确保每个折都是整个数据集的一个缩影，尽可能地保持全局类别比例。例如，如果类别 $2$ 占总数据的 $4\\%$，那么每个折也将包含大约 $4\\%$ 的类别 $2$ 样本。这保证了模型在每个折中都能在所有类别上进行训练和评估，从而对其泛化性能产生更稳定和准确的评估。\n\n该问题引入了一个额外的复杂层面：批次效应。来自不同制造批次的电芯可能存在影响其性能和失效模式的微小差异。一个模型可能在处理来自一个批次的失效时表现良好，但在处理另一个批次时表现不佳。为失效类别（类别 $1$ 为 $m_1=3$，类别 $2$ 为 $m_2=2$）包含来自最少数量不同批次的样本这一约束，就是为了应对这种情况。这迫使每个测试折都包含来自不同批次的各种失效“特征”，从而对模型不仅在样本间泛化，而且在制造批次间泛化的能力提供更严格的测试。\n\n**期望类别比例的推导**\n\n问题要求计算每个折中的期望类别比例。这可以通过概率和对称性的第一性原理来确定，并且这个结论可以通过逐步执行所述的复杂抽样过程来验证。\n\n**方法1：基于对称性和期望的论证**\n\n设 $N_c$ 是数据集中类别 $c$ 的样本总数，其中 $c \\in \\{0, 1, 2\\}$。我们有 $N_0 = 400$，$N_1 = 80$ 和 $N_2 = 20$。样本总数为 $N = \\sum_c N_c = 500$。任务是将这 $N$ 个样本划分到 $K=5$ 个折中。\n\n设 $N_{k,c}$ 是表示特定折 $k$ 中类别 $c$ 样本数量的随机变量。划分规则意味着每个样本必须且只能属于一个折，因此对所有折求和必须得到该类别的样本总数：\n$$ \\sum_{k=1}^{K} N_{k,c} = N_c $$\n根据期望的线性性质，期望值的和等于和的期望：\n$$ \\sum_{k=1}^{K} E[N_{k,c}] = E\\left[\\sum_{k=1}^{K} N_{k,c}\\right] = E[N_c] = N_c $$\n最后一个等式成立，因为 $N_c$ 是一个给定的固定量。\n\n问题描述了一套构建折的规则。关键在于，这些规则对每个折都是相同的；该过程不区分折 $1$、折 $2$ 等。因此，根据对称性，每个折的期望构成必须相同。这意味着类别 $c$ 的期望样本数对所有折都是相同的：\n$$ E[N_{1,c}] = E[N_{2,c}] = \\dots = E[N_{K,c}] $$\n让我们将这个共同的期望值记为 $E_c$。将其代入总和中：\n$$ \\sum_{k=1}^{K} E_c = K \\cdot E_c = N_c $$\n这为我们提供了在任何给定折 $k$ 中任意类别 $c$ 的期望样本数的一个基本结果：\n$$ E[N_{k,c}] = \\frac{N_c}{K} $$\n只要问题中指定的约束条件允许一个有效的划分，这个结果就成立，而它们确实允许。\n\n使用给定值：\n- 类别 $0$ 的期望计数：$E[N_{k,0}] = \\frac{400}{5} = 80$。\n- 类别 $1$ 的期望计数：$E[N_{k,1}] = \\frac{80}{5} = 16$。\n- 类别 $2$ 的期望计数：$E[N_{k,2}] = \\frac{20}{5} = 4$。\n\n每个折的大小是 $N/K = 500/5 = 100$。期望比例是：\n- 类别 $0$ 的比例：$\\frac{80}{100} = 0.80$。\n- 类别 $1$ 的比例：$\\frac{16}{100} = 0.16$。\n- 类别 $2$ 的比例：$\\frac{4}{100} = 0.04$。\n\n这些期望比例与全局类别比例相同。\n\n**方法2：通过指定的抽样过程进行验证**\n\n我们可以通过细致地遵循所描述的两阶段过程来验证这一结果。这表明这个复杂的过程与对称性论证是一致的。该过程包括一个“约束分配”阶段，随后是一个“分层填充”阶段。我们假设“分配至少 $s_{\\min}$”这个模棱两可的短语意味着为约束部分精确分配所需的最小样本数，这是一种标准的解释。\n\n**阶段1：约束分配**\n对于 $K=5$ 个折中的每一个，我们必须分配样本以满足最小批次代表性约束。\n- 对于类别 $1$：每个折需要来自 $m_1=3$ 个批次的样本，每个批次至少 $s_{\\min,1}=2$ 个样本。预分配到每个折的类别 $1$ 样本数为 $3 \\times 2 = 6$。\n- 对于类别 $2$：每个折需要来自 $m_2=2$ 个批次的样本，每个批次至少 $s_{\\min,2}=1$ 个样本。预分配到每个折的类别 $2$ 样本数为 $2 \\times 1 = 2$。\n- 对于类别 $0$：没有此类约束，因此预分配 $0$ 个样本。\n\n在此阶段，所有 $5$ 个折中分配的样本总数为：\n- 类别 $1$：$5 \\text{ 折} \\times 6 \\text{ 样本/折} = 30$ 个样本。\n- 类别 $2$：$5 \\text{ 折} \\times 2 \\text{ 样本/折} = 10$ 个样本。\n- 类别 $0$：$5 \\text{ 折} \\times 0 \\text{ 样本/折} = 0$ 个样本。\n\n**阶段2：分层填充**\n现在，我们计算待分配的剩余样本池。\n- 剩余类别 $0$ 样本：$400 - 0 = 400$。\n- 剩余类别 $1$ 样本：$80 - 30 = 50$。\n- 剩余类别 $2$ 样本：$20 - 10 = 10$。\n- 剩余样本总数：$400 + 50 + 10 = 460$。\n\n接下来，我们计算每个折中剩余的位置数。\n- 每个折的总大小为 $100$。\n- 在阶段1中，每个折被分配了 $6$（类别 $1$）$+ 2$（类别 $2$）$= 8$ 个样本。\n- 每个折的剩余位置数：$100 - 8 = 92$。\n- 所有折的总剩余位置数：$5 \\times 92 = 460$，与剩余样本总数相匹配，证实了一致性。\n\n每个折的这 $92$ 个位置通过对剩余的 $460$ 个样本池进行分层抽样来填充。添加到每个折中的各类别的期望样本数是：\n- 添加的类别 $0$：$92 \\times \\frac{400}{460} = 92 \\times \\frac{40}{46} = 2 \\times 40 = 80$。\n- 添加的类别 $1$：$92 \\times \\frac{50}{460} = 92 \\times \\frac{5}{46} = 2 \\times 5 = 10$。\n- 添加的类别 $2$：$92 \\times \\frac{10}{460} = 92 \\times \\frac{1}{46} = 2 \\times 1 = 2$。\n\n**最终构成**\n每个折中各类别的总期望计数是阶段1和阶段2的总和。\n- 期望类别 $0$ 计数：$0 (\\text{阶段 } 1) + 80 (\\text{阶段 } 2) = 80$。\n- 期望类别 $1$ 计数：$6 (\\text{阶段 } 1) + 10 (\\text{阶段 } 2) = 16$。\n- 期望类别 $2$ 计数：$2 (\\text{阶段 } 1) + 2 (\\text{阶段 } 2) = 4$。\n\n每个折的总计数为 $80 + 16 + 4 = 100$。期望比例是：\n- 类别 $0$ 比例：$80/100 = 0.80$。\n- 类别 $1$ 比例：$16/100 = 0.16$。\n- 类别 $2$ 比例：$4/100 = 0.04$。\n\n两种方法得出了相同的结果。这些复杂的约束在确保批次多样性的同时，其构建方式在期望上完美地保持了分层原则。\n\n**逐项分析**\n\nA. 类别 $0$：$0.80$，类别 $1$：$0.16$，类别 $2$：$0.04$。\n此选项与我们推导出的期望比例 $\\{0.80, 0.16, 0.04\\}$ 相符。\n**结论：正确。**\n\nB. 类别 $0$：$0.78$，类别 $1$：$0.18$，类别 $2$：$0.04$。\n此选项表明有 $78$ 个类别 $0$ 样本，$18$ 个类别 $1$ 样本和 $4$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**\n\nC. 类别 $0$：$0.80$，类别 $1$：$0.12$，类别 $2$：$0.08$。\n此选项表明有 $80$ 个类别 $0$ 样本，$12$ 个类别 $1$ 样本和 $8$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**\n\nD. 类别 $0$：$0.79$，类别 $1$：$0.15$，类别 $2$：$0.06$。\n此选项表明有 $79$ 个类别 $0$ 样本，$15$ 个类别 $1$ 样本和 $6$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}