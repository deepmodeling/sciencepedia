{
    "hands_on_practices": [
        {
            "introduction": "“置信上界”（Upper Confidence Bound, UCB）方法体现了“面对不确定性时的乐观主义”原则。本练习将指导你从第一性原理出发，推导出UCB的探索参数，以确保在很高的概率下，真实值不会超出我们对多个候选点的乐观估计。掌握这项技能有助于构建稳健的主动学习代理，从而智能地平衡对已知良好选项的利用和对有潜力新选项的探索。",
            "id": "3891996",
            "problem": "一个实验室正在进行自动化实验选择，以在固定的循环协议下优化一种锂离子电池设计的放电容量。设从设计参数矢量到放电容量的未知映射表示为 $f(\\mathbf{x})$，单位为毫安时 (mAh)。该实验室采用贝叶斯推断框架，对 $f$ 使用高斯过程 (GP) 先验。在对已收集的数据进行条件化后，每个候选实验设置 $\\mathbf{x}_{i}$ 的单步后验预测分布是一个单变量高斯分布。也就是说，对于每个候选 $i \\in \\{1,2,3\\}$，$f(\\mathbf{x}_{i})$ 的后验分布为 $f(\\mathbf{x}_{i}) \\sim \\mathcal{N}(\\mu_{i}, \\sigma_{i}^{2})$，其中 $\\mu_{i}$ 和 $\\sigma_{i}$ 分别是后验均值和标准差。\n\n为遵循一个控制当前所有候选方案低估的族风险（family-wise risk）的乐观原则，该实验室决定对每个 $\\mathbf{x}_{i}$ 使用形式为 $\\mu_{i} + \\kappa \\sigma_{i}$ 的乐观置信上界，其中 $\\kappa$ 是一个非负标量，其选择要确保在整个候选集上，所有真实容量 $f(\\mathbf{x}_{i})$ 不超过其各自乐观界 $\\mu_{i} + \\kappa \\sigma_{i}$ 的概率至少为 $1 - \\delta$。置信参数为 $\\delta$，候选数量为 $M$。\n\n从高斯尾部和基本概率论的第一性原理出发（不援引任何专门的快捷公式），推导出最小 $\\kappa$ 关于 $\\delta$、$M$ 和标准正态累积分布函数 $\\Phi(\\cdot)$ 的显式表达式。然后，使用此表达式，计算具有以下后验参数的三个候选方案中的最大乐观置信上界值：\n- 候选 1：$\\mu_{1} = 2650\\,\\text{mAh}$，$\\sigma_{1} = 50\\,\\text{mAh}$，\n- 候选 2：$\\mu_{2} = 2610\\,\\text{mAh}$，$\\sigma_{2} = 80\\,\\text{mAh}$，\n- 候选 3：$\\mu_{3} = 2580\\,\\text{mAh}$，$\\sigma_{3} = 120\\,\\text{mAh}$，\n\n在由 $\\delta = 0.075$ 和 $M = 3$ 指定的族置信要求下。\n\n你的最终答案必须是这三个候选方案中的最大乐观置信上界的单个实数值。将答案四舍五入到四位有效数字，并以 $\\text{mAh}$ 为单位表示。",
            "solution": "已分析用户提供的问题并确定其有效。该问题在科学上基于贝叶斯优化和高斯过程的原理，信息充分且一致，问题是良定的，并以客观、正式的语言陈述。因此，我们可以进行完整解答。\n\n问题要求两个主要步骤：首先，从第一性原理推导最小乐观置信界参数 $\\kappa$ 的表达式；其次，使用该表达式计算给定一组候选实验的最大乐观置信上界 (UCB) 值。\n\n设有 $M$ 个候选实验设置，由 $i \\in \\{1, 2, \\dots, M\\}$ 索引。在每个设置 $\\mathbf{x}_{i}$ 处，放电容量 $f(\\mathbf{x}_{i})$ 的后验预测分布由一个单变量高斯分布给出：\n$$f(\\mathbf{x}_{i}) \\sim \\mathcal{N}(\\mu_{i}, \\sigma_{i}^{2})$$\n每个候选的乐观置信上界定义为 $UCB_i = \\mu_{i} + \\kappa \\sigma_{i}$。\n\n核心要求是找到最小的非负标量 $\\kappa$，使得所有候选的真实容量 $f(\\mathbf{x}_{i})$ 同时不超过其对应的 UCB 的概率至少为 $1 - \\delta$。设 $E_i$ 为候选 $i$ 的真实容量在其界限内的事件，即 $E_i = \\{f(\\mathbf{x}_{i}) \\le \\mu_{i} + \\kappa \\sigma_{i}\\}$。要求是所有这些事件的交集，我们记为 $E = \\bigcap_{i=1}^{M} E_i$。我们必须找到最小的 $\\kappa$ 使得：\n$$P(E) = P\\left(\\bigcap_{i=1}^{M} \\{f(\\mathbf{x}_{i}) \\le \\mu_{i} + \\kappa \\sigma_{i}\\}\\right) \\ge 1 - \\delta$$\n处理补事件 $E^c$ 更为方便，该事件指至少有一个真实容量超过其界限。根据德摩根定律，$E^c = \\bigcup_{i=1}^{M} E_i^c$，其中 $E_i^c = \\{f(\\mathbf{x}_{i}) > \\mu_{i} + \\kappa \\sigma_{i}\\}$。概率要求可以重写为：\n$$P(E^c) \\le \\delta$$\n问题没有说明随机变量 $f(\\mathbf{x}_{i})$是独立的。在一个典型的高斯过程模型中，不同点的后验值是相关的。因此，为确保该条件在没有未经证实的独立性假设下成立，我们应用布尔不等式（Boole's inequality），也称为联合界：\n$$P(E^c) = P\\left(\\bigcup_{i=1}^{M} E_i^c\\right) \\le \\sum_{i=1}^{M} P(E_i^c)$$\n为满足 $P(E^c) \\le \\delta$，施加一个更强的条件，即该和的上界小于或等于 $\\delta$，是充分的：\n$$\\sum_{i=1}^{M} P(f(\\mathbf{x}_{i}) > \\mu_{i} + \\kappa \\sigma_{i}) \\le \\delta$$\n让我们分析单个概率项 $P(f(\\mathbf{x}_{i}) > \\mu_{i} + \\kappa \\sigma_{i})$。我们可以通过定义 $Z_i = \\frac{f(\\mathbf{x}_{i}) - \\mu_{i}}{\\sigma_{i}}$ 来标准化随机变量 $f(\\mathbf{x}_{i})$，其中 $Z_i$ 服从标准正态分布 $Z_i \\sim \\mathcal{N}(0, 1)$。该不等式变为：\n$$P\\left(\\frac{f(\\mathbf{x}_{i}) - \\mu_{i}}{\\sigma_{i}} > \\kappa\\right) = P(Z_i > \\kappa)$$\n这个概率可以用标准正态累积分布函数 (CDF) $\\Phi(\\cdot)$ 表示为 $P(Z_i > \\kappa) = 1 - P(Z_i \\le \\kappa) = 1 - \\Phi(\\kappa)$。\n由于这个概率对于所有 $i \\in \\{1, \\dots, M\\}$ 都是相同的，所以和变为：\n$$M(1 - \\Phi(\\kappa))$$\n将此代回到我们的充分条件中，我们得到：\n$$M(1 - \\Phi(\\kappa)) \\le \\delta$$\n为了找到保证此不等式成立的最小 $\\kappa$ 值，我们求解最紧的界，即等式成立的情况：\n$$M(1 - \\Phi(\\kappa)) = \\delta$$\n求解 $\\kappa$：\n$$1 - \\Phi(\\kappa) = \\frac{\\delta}{M}$$\n$$\\Phi(\\kappa) = 1 - \\frac{\\delta}{M}$$\n$$\\kappa = \\Phi^{-1}\\left(1 - \\frac{\\delta}{M}\\right)$$\n这就是使用联合界满足族置信要求的最小 $\\kappa$ 的显式表达式。\n\n现在，我们进行计算。问题提供了以下参数：族置信参数 $\\delta = 0.075$ 和候选数量 $M = 3$。我们可以计算 $\\kappa$：\n$$\\kappa = \\Phi^{-1}\\left(1 - \\frac{0.075}{3}\\right) = \\Phi^{-1}(1 - 0.025) = \\Phi^{-1}(0.975)$$\n值 $\\Phi^{-1}(0.975)$ 对应于标准正态分布中的 z-分数，其右侧的尾部概率为 $1 - 0.975 = 0.025$。这是一个标准值，通常已知约为 $1.959964$。我们将使用这个值作为 $\\kappa$。\n\n下一步是为三个候选方案中的每一个计算 UCB, $\\mu_{i} + \\kappa \\sigma_{i}$：\n- 候选 1：$\\mu_{1} = 2650\\,\\text{mAh}$，$\\sigma_{1} = 50\\,\\text{mAh}$\n- 候选 2：$\\mu_{2} = 2610\\,\\text{mAh}$，$\\sigma_{2} = 80\\,\\text{mAh}$\n- 候选 3：$\\mu_{3} = 2580\\,\\text{mAh}$，$\\sigma_{3} = 120\\,\\text{mAh}$\n\nUCB 值为：\n$$UCB_1 = \\mu_1 + \\kappa \\sigma_1 = 2650 + \\Phi^{-1}(0.975) \\times 50$$\n$$UCB_2 = \\mu_2 + \\kappa \\sigma_2 = 2610 + \\Phi^{-1}(0.975) \\times 80$$\n$$UCB_3 = \\mu_3 + \\kappa \\sigma_3 = 2580 + \\Phi^{-1}(0.975) \\times 120$$\n\n代入 $\\kappa$ 的数值 $\\approx 1.959964$：\n$$UCB_1 \\approx 2650 + 1.959964 \\times 50 = 2650 + 97.9982 = 2747.9982$$\n$$UCB_2 \\approx 2610 + 1.959964 \\times 80 = 2610 + 156.79712 = 2766.79712$$\n$$UCB_3 \\approx 2580 + 1.959964 \\times 120 = 2580 + 235.19568 = 2815.19568$$\n\n问题要求这三个候选方案中的最大乐观置信上界值。\n$$\\max(UCB_1, UCB_2, UCB_3) \\approx \\max(2747.9982, 2766.79712, 2815.19568) = 2815.19568$$\n最后，我们必须将此答案四舍五入到四位有效数字。前四位有效数字是 $2$、$8$、$1$ 和 $5$。接下来的数字是 $1$，所以我们向下舍入。\n结果是 $2815$。",
            "answer": "$$\\boxed{2815}$$"
        },
        {
            "introduction": "“期望提升”（Expected Improvement, EI）是贝叶斯优化的基石，它直接以找到更优解为目标。本练习要求你推导EI的闭式表达式，该表达式巧妙地结合了超越当前最佳观测值的概率与该潜在提升的幅度。这个基础练习揭示了EI如何智能地权衡探索与利用的数学核心。",
            "id": "3892015",
            "problem": "一个自动化的电池设计与仿真工作流使用贝叶斯优化（BO）来主动选择下一个实验，以最大化镍锰钴正极材料组分在$100$次循环后的化成后容量保持率。其代理模型是一个高斯过程（GP），其在候选组分$x^{\\ast}$处对容量保持率的后验预测分布近似为正态分布。设在$x^{\\ast}$处的预测容量保持率为随机变量$Y$，且$Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$，其中$\\mu$和$\\sigma$分别是高斯过程的后验预测均值和标准差。当前观测到的最佳容量保持率为$y_{\\text{best}}$。为实施一种谨慎的探索策略，其采集函数为带非负提升余量$\\xi$的期望提升（EI），对于一个最大化目标，该随机提升量定义为$I = \\max\\{0, Y - (y_{\\text{best}} + \\xi)\\}$。从数学期望和正态概率密度函数的基本定义出发，推导在正态预测模型下期望提升$\\mathbb{E}[I]$的闭式表达式，并使用以下科学上合理的值进行计算：$\\mu = 0.92$，$\\sigma = 0.03$，$y_{\\text{best}} = 0.90$，以及$\\xi = 0.01$。将容量保持率视为一个无量纲分数。将你的最终数值答案四舍五入到四位有效数字，并将其表示为一个无量纲分数（最终数值中不含单位符号）。",
            "solution": "用户希望解决以下问题：\n一个自动化的电池设计与仿真工作流使用贝叶斯优化（BO）来主动选择下一个实验，以最大化镍锰钴正极材料组分在$100$次循环后的化成后容量保持率。其代理模型是一个高斯过程（GP），其在候选组分$x^{\\ast}$处对容量保持率的后验预测分布近似为正态分布。设在$x^{\\ast}$处的预测容量保持率为随机变量$Y$，且$Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$，其中$\\mu$和$\\sigma$分别是高斯过程的后验预测均值和标准差。当前观测到的最佳容量保持率为$y_{\\text{best}}$。为实施一种谨慎的探索策略，其采集函数为带非负提升余量$\\xi$的期望提升（EI），对于一个最大化目标，该随机提升量定义为$I = \\max\\{0, Y - (y_{\\text{best}} + \\xi)\\}$。从数学期望和正态概率密度函数的基本定义出发，推导在正态预测模型下期望提升$\\mathbb{E}[I]$的闭式表达式，并使用以下科学上合理的值进行计算：$\\mu = 0.92$，$\\sigma = 0.03$，$y_{\\text{best}} = 0.90$，以及$\\xi = 0.01$。将容量保持率视为一个无量纲分数。将你的最终数值答案四舍五入到四位有效数字，并将其表示为一个无量纲分数（最终数值中不含单位符号）。\n\n### 步骤 1：提取已知条件\n- 候选点预测容量保持率的随机变量是 $Y$。\n- $Y$ 的分布是正态分布：$Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$。\n- $\\mu$ 是后验预测均值。\n- $\\sigma$ 是后验预测标准差。\n- $y_{\\text{best}}$ 是当前观测到的最佳容量保持率。\n- $\\xi$ 是一个非负的提升余量。\n- 随机提升量定义为 $I = \\max\\{0, Y - (y_{\\text{best}} + \\xi)\\}$。\n- 目标是推导期望提升 $\\mathbb{E}[I]$ 的闭式表达式。\n- 用于求值的数值为：$\\mu = 0.92$，$\\sigma = 0.03$，$y_{\\text{best}} = 0.90$，$\\xi = 0.01$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据指定标准对问题陈述进行验证。\n- **科学依据**：该问题在机器学习（贝叶斯优化、高斯过程）和材料科学（电池设计）领域有充分的依据。期望提升是一个标准的采集函数，其在高斯过程模型下的推导是一个典型问题。背景和数值在科学上是合理的。\n- **适定性**：该问题在数学上是适定的。随机变量、其分布以及要求值的函数都已明确指定。存在唯一解，并且可以从第一性原理推导得出。\n- **客观性**：问题使用精确、客观和形式化的数学语言陈述。\n\n所有其他有效性标准也得到满足。不存在矛盾、信息缺失或歧义。\n\n### 步骤 3：结论与行动\n该问题有效。将提供一个完整的、有理有据的解答。\n\n### 解答推导\n\n期望提升 $\\mathbb{E}[I]$ 由提升函数 $I = \\max\\{0, Y - (y_{\\text{best}} + \\xi)\\}$ 的期望定义。随机变量 $Y$ 服从正态分布 $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其概率密度函数 (PDF) 为 $f_Y(y)$。\n\n期望的定义是：\n$$ \\mathbb{E}[I] = \\int_{-\\infty}^{\\infty} \\max\\{0, y - (y_{\\text{best}} + \\xi)\\} f_Y(y) \\, dy $$\n我们定义一个阈值 $y_{\\text{th}} = y_{\\text{best}} + \\xi$。只有当 $y > y_{\\text{th}}$ 时，被积函数才不为零。因此，积分简化为：\n$$ \\mathbb{E}[I] = \\int_{y_{\\text{th}}}^{\\infty} (y - y_{\\text{th}}) f_Y(y) \\, dy $$\n正态分布的概率密度函数由下式给出：\n$$ f_Y(y) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right) $$\n将此式代入 $\\mathbb{E}[I]$ 的积分中：\n$$ \\mathbb{E}[I] = \\int_{y_{\\text{th}}}^{\\infty} (y - y_{\\text{th}}) \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right) \\, dy $$\n为了求解这个积分，我们进行变量替换，转换为标准正态分布。令 $z = \\frac{y-\\mu}{\\sigma}$。这意味着 $y = \\mu + z\\sigma$ 并且 $dy = \\sigma \\, dz$。积分下限从 $y_{\\text{th}}$ 变为 $z_{\\text{th}} = \\frac{y_{\\text{th}}-\\mu}{\\sigma}$。积分上限保持为 $\\infty$。\n\n积分变为：\n$$ \\mathbb{E}[I] = \\int_{z_{\\text{th}}}^{\\infty} (\\mu + z\\sigma - y_{\\text{th}}) \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) \\sigma \\, dz $$\n令 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$ 为标准正态分布的概率密度函数 (PDF)。积分简化为：\n$$ \\mathbb{E}[I] = \\int_{z_{\\text{th}}}^{\\infty} ((\\mu - y_{\\text{th}}) + z\\sigma) \\phi(z) \\, dz $$\n我们可以将其分成两部分：\n$$ \\mathbb{E}[I] = (\\mu - y_{\\text{th}}) \\int_{z_{\\text{th}}}^{\\infty} \\phi(z) \\, dz + \\sigma \\int_{z_{\\text{th}}}^{\\infty} z \\phi(z) \\, dz $$\n我们来分别计算每一部分。\n第一个积分是标准正态分布的尾部概率。令 $\\Phi(z)$ 为标准正态分布的累积分布函数 (CDF)。\n$$ \\int_{z_{\\text{th}}}^{\\infty} \\phi(z) \\, dz = P(Z > z_{\\text{th}}) = 1 - \\Phi(z_{\\text{th}}) $$\n第二个积分可以直接求解：\n$$ \\int_{z_{\\text{th}}}^{\\infty} z \\phi(z) \\, dz = \\int_{z_{\\text{th}}}^{\\infty} z \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) \\, dz $$\n使用换元法 $u = -z^2/2$，则 $du = -z \\, dz$：\n$$ \\int z \\exp\\left(-\\frac{z^2}{2}\\right) \\, dz = -\\int \\exp(u) \\, du = -\\exp(u) = -\\exp\\left(-\\frac{z^2}{2}\\right) $$\n计算定积分：\n$$ \\frac{1}{\\sqrt{2\\pi}} \\left[ -\\exp\\left(-\\frac{z^2}{2}\\right) \\right]_{z_{\\text{th}}}^{\\infty} = \\frac{1}{\\sqrt{2\\pi}} \\left( 0 - \\left(-\\exp\\left(-\\frac{z_{\\text{th}}^2}{2}\\right)\\right) \\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z_{\\text{th}}^2}{2}\\right) = \\phi(z_{\\text{th}}) $$\n结合这两个部分，期望提升的表达式为：\n$$ \\mathbb{E}[I] = (\\mu - y_{\\text{th}})(1 - \\Phi(z_{\\text{th}})) + \\sigma \\phi(z_{\\text{th}}) $$\n我们定义提升差值 $\\Delta = \\mu - y_{\\text{th}} = \\mu - (y_{\\text{best}} + \\xi)$。那么 $z_{\\text{th}} = \\frac{y_{\\text{th}} - \\mu}{\\sigma} = -\\frac{\\Delta}{\\sigma}$。\n将此代入方程，并利用标准正态分布的性质 $\\phi(-x) = \\phi(x)$ 和 $1 - \\Phi(-x) = \\Phi(x)$：\n$$ \\mathbb{E}[I] = \\Delta (1 - \\Phi(-\\Delta/\\sigma)) + \\sigma \\phi(-\\Delta/\\sigma) $$\n$$ \\mathbb{E}[I] = \\Delta \\Phi(\\Delta/\\sigma) + \\sigma \\phi(\\Delta/\\sigma) $$\n这就是期望提升的闭式表达式。\n\n### 数值计算\n\n现在我们用给定的值来计算这个表达式：$\\mu = 0.92$，$\\sigma = 0.03$，$y_{\\text{best}} = 0.90$，以及 $\\xi = 0.01$。\n\n首先，计算提升差值 $\\Delta$：\n$$ \\Delta = \\mu - (y_{\\text{best}} + \\xi) = 0.92 - (0.90 + 0.01) = 0.92 - 0.91 = 0.01 $$\n接下来，计算标准化提升 $Z_{\\text{std}}$：\n$$ Z_{\\text{std}} = \\frac{\\Delta}{\\sigma} = \\frac{0.01}{0.03} = \\frac{1}{3} $$\n$\\mathbb{E}[I]$ 的表达式变为：\n$$ \\mathbb{E}[I] = (0.01) \\cdot \\Phi\\left(\\frac{1}{3}\\right) + (0.03) \\cdot \\phi\\left(\\frac{1}{3}\\right) $$\n我们需要标准正态分布的概率密度函数 (PDF) $\\phi(z)$ 和累积分布函数 (CDF) $\\Phi(z)$ 在 $z = 1/3$ 处的值。\n$$ \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) $$\n$$ \\phi\\left(\\frac{1}{3}\\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(1/3)^2}{2}\\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{18}\\right) \\approx 0.377390 $$\n$$ \\Phi(z) = \\int_{-\\infty}^{z} \\phi(t) \\, dt $$\n从标准表格中查得 $z=1/3$ 处的累积分布函数值为：\n$$ \\Phi\\left(\\frac{1}{3}\\right) \\approx 0.630559 $$\n将这些值代入 $\\mathbb{E}[I]$ 的表达式中：\n$$ \\mathbb{E}[I] \\approx (0.01) \\cdot (0.630559) + (0.03) \\cdot (0.377390) $$\n$$ \\mathbb{E}[I] \\approx 0.00630559 + 0.0113217 $$\n$$ \\mathbb{E}[I] \\approx 0.01762729 $$\n问题要求将最终答案四舍五入到四位有效数字。\n$$ \\mathbb{E}[I] \\approx 0.01763 $$",
            "answer": "$$\n\\boxed{0.01763}\n$$"
        },
        {
            "introduction": "除了寻找单一最优点，主动学习还可以用于尽可能高效地学习一个系统。本练习将我们的视角转向信息论方法，其中最佳实验被定义为能最大程度减少我们对模型参数不确定性（熵）的实验。你将实现一个算法，该算法选择能够最大化此信息增益的实验，这是科学发现和系统辨识中的一项强大技术。",
            "id": "3892001",
            "problem": "您正在为估算一个简化电化学模型的参数设计一种自动化实验选择策略，该模型与自动化电池设计和仿真相关。考虑一个未知参数矢量 $\\theta \\in \\mathbb{R}^n$，其高斯先验分布为 $p_0(\\theta) = \\mathcal{N}(\\mu_0, \\Sigma_0)$。一个实验由一个设计来表征，该设计产生一个标量测量值，（在预期操作条件附近进行线性化后）其模型为 $y = h^\\top \\theta + \\varepsilon$，其中 $h \\in \\mathbb{R}^n$ 是与该设计相关的灵敏度矢量，$\\varepsilon$ 是方差为 $\\sigma^2$ 的零均值高斯噪声。您必须选择能够最大化在执行单次测量后 $\\theta$ 的后验熵预期减少量的实验。\n\n从以下基本原理开始：\n- 用于更新信度的贝叶斯定理：$p(\\theta \\mid y, h) \\propto p(y \\mid \\theta, h) \\, p_0(\\theta)$。\n- 高斯似然 $p(y \\mid \\theta, h) = \\mathcal{N}(h^\\top \\theta, \\sigma^2)$ 和高斯先验 $p_0(\\theta) = \\mathcal{N}(\\mu_0, \\Sigma_0)$ 会得到一个高斯后验分布。\n- 对于一个概率密度函数 (PDF) 为 $p(x)$ 的连续随机变量，其香农微分熵定义为 $H(X) = - \\int p(x) \\ln p(x) \\, dx$，其中使用自然对数，因此熵的单位是奈特 (nats)。\n\n您的任务是实现一个程序，给定一组候选灵敏度矢量 $h$、一个先验协方差 $\\Sigma_0$ 和一个噪声方差 $\\sigma^2$，计算每个候选设计下 $\\theta$ 的熵的预期减少量（以奈特为单位），并返回能够最大化此预期减少量的设计的索引（使用从零开始的索引）。如果多个设计达到相同的最大预期减少量，则选择最小的索引。您的程序的输出应该是一行，包含所有测试用例的结果，形式为一个用方括号括起来的逗号分隔列表；例如，[$r_1$,$r_2$,$r_3$]。\n\n以奈特为单位计算熵。本问题不涉及角度。无需输出物理单位。\n\n测试套件：\n- 案例 1（正常路径，二维参数，信息丰富的测量）：\n  - 先验协方差：$$\\Sigma_0 = \\begin{bmatrix} 0.04  0 \\\\ 0  0.09 \\end{bmatrix}$$\n  - 噪声方差：$\\sigma^2 = 0.01$\n  - 候选灵敏度矢量：$h^{(0)} = [0.8, 0.1]$，$h^{(1)} = [0.2, 1.0]$，$h^{(2)} = [0.5, 0.5]$\n- 案例 2（边界条件，测量噪声非常大）：\n  - 先验协方差：$$\\Sigma_0 = \\begin{bmatrix} 0.04  0 \\\\ 0  0.09 \\end{bmatrix}$$\n  - 噪声方差：$\\sigma^2 = 10.0$\n  - 候选灵敏度矢量：$h^{(0)} = [0.8, 0.1]$，$h^{(1)} = [0.2, 1.0]$，$h^{(2)} = [0.5, 0.5]$\n- 案例 3（边缘情况，高度各向异性的先验）：\n  - 先验协方差：$$\\Sigma_0 = \\begin{bmatrix} 0.0001  0 \\\\ 0  4.0 \\end{bmatrix}$$\n  - 噪声方差：$\\sigma^2 = 0.5$\n  - 候选灵敏度矢量：$h^{(0)} = [1.0, 0.0]$，$h^{(1)} = [0.0, 1.0]$，$h^{(2)} = [0.5, 0.5]$\n- 案例 4（标量参数，包含一个非信息性设计）：\n  - 先验协方差：$$\\Sigma_0 = \\begin{bmatrix} 1.0 \\end{bmatrix}$$\n  - 噪声方差：$\\sigma^2 = 0.1$\n  - 候选灵敏度矢量：$h^{(0)} = [0.0]$，$h^{(1)} = [0.1]$，$h^{(2)} = [2.0]$\n- 案例 5（平局情况，不同设计的信息量相等）：\n  - 先验协方差：$$\\Sigma_0 = \\begin{bmatrix} 1.0  0 \\\\ 0  1.0 \\end{bmatrix}$$\n  - 噪声方差：$\\sigma^2 = 0.5$\n  - 候选灵敏度矢量：$h^{(0)} = [1.0, 0.0]$，$h^{(1)} = [0.0, 1.0]$\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果。每个元素应为对应案例所选设计的从零开始的索引。例如，[$r_1$,$r_2$,$r_3$,$r_4$,$r_5$]。",
            "solution": "用户希望我从一组候选项中确定最优的实验设计，以最大化关于未知参数矢量 $\\theta$ 所获得的信息。该问题定义明确，并在贝叶斯推断和信息论方面有坚实的科学基础，特别是在线性高斯系统的贝叶斯最优实验设计（BOED）背景下。\n\n核心任务是选择由灵敏度矢量 $h$ 表征的实验，以最大化参数矢量 $\\theta$ 的香农微分熵的预期减少量。关于 $\\theta$ 的先验信度由高斯分布 $p_0(\\theta) = \\mathcal{N}(\\mu_0, \\Sigma_0)$ 给出。单次实验根据线性模型 $y = h^\\top \\theta + \\varepsilon$ 产生一个标量测量值 $y$，其中测量噪声 $\\varepsilon$ 也是高斯分布，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n熵的预期减少量等价于未知参数 $\\theta$ 和测量值 $y$ 之间的互信息，记为 $I(\\theta; y)$。根据定义，互信息可以用两种等价的方式表示：\n$$I(\\theta; y) = H(\\theta) - H(\\theta|y)$$\n$$I(\\theta; y) = H(y) - H(y|\\theta)$$\n这里，$H(\\theta)$ 是参数的先验熵，$H(\\theta|y)$ 是观测到 $y$ 后的后验熵，$H(y)$ 是测量值边缘分布的熵（“预后验”或证据），$H(y|\\theta)$ 是在给定真实参数下测量值的熵。对于这个问题，通过第二种形式 $H(y) - H(y|\\theta)$ 来计算 $I(\\theta; y)$ 更为直接。目标是找到最大化此量的设计矢量 $h$。\n\n让我们首先确定所需的分布及其熵。所有熵的单位均为奈特。\n\n1.  **条件熵 $H(y|\\theta)$**：测量模型为 $p(y | \\theta, h) = \\mathcal{N}(h^\\top \\theta, \\sigma^2)$。这是一个关于 $y$ 的一元高斯分布。方差为 $\\sigma^2_z$ 的高斯随机变量的微分熵是 $\\frac{1}{2} \\ln(2\\pi e \\sigma^2_z)$。因此，在给定特定 $\\theta$ 的情况下，$y$ 的熵是恒定的：\n    $$H(y|\\theta) = \\frac{1}{2} \\ln(2\\pi e \\sigma^2)$$\n    这个值既不依赖于 $\\theta$，也不依赖于所选的设计 $h$。\n\n2.  **边缘熵 $H(y)$**：测量值 $y$ 的边缘分布 $p(y|h)$ 是通过对所有可能的 $\\theta$ 积分联合分布 $p(y, \\theta|h)$ 得到的：\n    $$p(y|h) = \\int p(y|\\theta, h) p_0(\\theta) d\\theta$$\n    这是模型的证据。由于 $\\theta$ 的先验和 $y$ 的似然都是高斯分布，它们的卷积结果是另一个高斯分布。随机变量 $y$ 是两个独立高斯随机变量 $h^\\top\\theta$ 和 $\\varepsilon$ 的和。$y$ 的均值为 $\\mathbb{E}[y] = \\mathbb{E}[h^\\top\\theta + \\varepsilon] = h^\\top\\mathbb{E}[\\theta] + \\mathbb{E}[\\varepsilon] = h^\\top\\mu_0$。$y$ 的方差为：\n    $$\\text{Var}(y) = \\text{Var}(h^\\top\\theta + \\varepsilon) = \\text{Var}(h^\\top\\theta) + \\text{Var}(\\varepsilon)$$\n    利用方差的性质，$\\text{Var}(h^\\top\\theta) = h^\\top \\text{Cov}(\\theta) h = h^\\top \\Sigma_0 h$。噪声方差为 $\\text{Var}(\\varepsilon) = \\sigma^2$。因此，$y$ 的边缘分布是高斯分布：\n    $$p(y|h) = \\mathcal{N}(h^\\top\\mu_0, h^\\top\\Sigma_0 h + \\sigma^2)$$\n    该分布的熵为：\n    $$H(y) = \\frac{1}{2} \\ln\\left(2\\pi e (h^\\top\\Sigma_0 h + \\sigma^2)\\right)$$\n\n3.  **互信息 / 熵的预期减少量**：现在我们可以计算给定设计 $h$ 的互信息：\n    $$I(\\theta; y) = H(y) - H(y|\\theta)$$\n    $$I(\\theta; y) = \\frac{1}{2} \\ln\\left(2\\pi e (h^\\top\\Sigma_0 h + \\sigma^2)\\right) - \\frac{1}{2} \\ln\\left(2\\pi e \\sigma^2\\right)$$\n    使用属性 $\\ln(a) - \\ln(b) = \\ln(a/b)$，这可以简化为：\n    $$I(\\theta; y) = \\frac{1}{2} \\ln\\left(\\frac{2\\pi e (h^\\top\\Sigma_0 h + \\sigma^2)}{2\\pi e \\sigma^2}\\right) = \\frac{1}{2} \\ln\\left(\\frac{h^\\top\\Sigma_0 h + \\sigma^2}{\\sigma^2}\\right)$$\n    $$I(\\theta; y) = \\frac{1}{2} \\ln\\left(1 + \\frac{h^\\top\\Sigma_0 h}{\\sigma^2}\\right)$$\n    这个最终表达式代表了通过执行由 $h$ 定义的实验所实现的 $\\theta$ 的熵的预期减少量。\n\n4.  **最优设计选择**：任务是从一组候选矢量 $\\{h^{(i)}\\}$ 中选择能够最大化此信息增益的灵敏度矢量 $h$。\n    $$\\text{argmax}_{h^{(i)}} \\; \\frac{1}{2} \\ln\\left(1 + \\frac{(h^{(i)})^\\top\\Sigma_0 h^{(i)}}{\\sigma^2}\\right)$$\n    自然对数 $\\ln(x)$ 是一个严格单调递增函数。因此，最大化该表达式等价于最大化其参数 $1 + \\frac{(h^{(i)})^\\top\\Sigma_0 h^{(i)}}{\\sigma^2}$。由于对于任何给定的测试用例，$\\sigma^2$ 是一个正常数，这进一步等价于最大化二次型 $(h^{(i)})^\\top\\Sigma_0 h^{(i)}$。\n\n    量 $h^\\top\\Sigma_0 h$ 有明确的物理解释：它是测量信号部分 $h^\\top\\theta$ 的先验方差。因此，最优实验是在参数不确定性（由 $\\Sigma_0$ 描述）导致预期测量结果不确定性最大的方向上探测系统。这使得测量结果具有“出人意料”的潜力最大化，从而提供最多的信息。\n\n算法如下：对于每个候选矢量 $h^{(i)}$，计算标量值 $q_i = (h^{(i)})^\\top \\Sigma_0 h^{(i)}$。最优设计是对应于最大 $q_i$ 值的设计。如果出现平局，问题规定选择索引最小的设计。请注意，计算此值不需要先验均值 $\\mu_0$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimal experiment design problem for a series of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"Sigma0\": np.array([[0.04, 0.0], [0.0, 0.09]]),\n            \"sigma_sq\": 0.01,\n            \"h_candidates\": [\n                np.array([0.8, 0.1]),\n                np.array([0.2, 1.0]),\n                np.array([0.5, 0.5])\n            ]\n        },\n        {\n            \"Sigma0\": np.array([[0.04, 0.0], [0.0, 0.09]]),\n            \"sigma_sq\": 10.0,\n            \"h_candidates\": [\n                np.array([0.8, 0.1]),\n                np.array([0.2, 1.0]),\n                np.array([0.5, 0.5])\n            ]\n        },\n        {\n            \"Sigma0\": np.array([[0.0001, 0.0], [0.0, 4.0]]),\n            \"sigma_sq\": 0.5,\n            \"h_candidates\": [\n                np.array([1.0, 0.0]),\n                np.array([0.0, 1.0]),\n                np.array([0.5, 0.5])\n            ]\n        },\n        {\n            \"Sigma0\": np.array([[1.0]]),\n            \"sigma_sq\": 0.1,\n            \"h_candidates\": [\n                np.array([0.0]),\n                np.array([0.1]),\n                np.array([2.0])\n            ]\n        },\n        {\n            \"Sigma0\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"sigma_sq\": 0.5,\n            \"h_candidates\": [\n                np.array([1.0, 0.0]),\n                np.array([0.0, 1.0])\n            ]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        Sigma0 = case[\"Sigma0\"]\n        h_candidates = case[\"h_candidates\"]\n        \n        # As derived, maximizing the expected entropy reduction is equivalent to\n        # maximizing the quadratic form h^T * Sigma0 * h.\n        # The noise variance sigma^2 does not affect the choice of the optimal h.\n        \n        q_values = []\n        for h in h_candidates:\n            # h is a 1D array, so we can use np.dot for h.T @ Sigma0 and then another dot.\n            # Or just use the @ operator which handles it correctly.\n            q = h.T @ Sigma0 @ h\n            q_values.append(q)\n            \n        # np.argmax returns the index of the first occurrence of the maximum value,\n        # which satisfies the tie-breaking rule (select the smallest index).\n        best_index = np.argmax(q_values)\n        results.append(best_index)\n\n    # Format the output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}