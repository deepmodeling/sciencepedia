{
    "hands_on_practices": [
        {
            "introduction": "State estimators for battery management systems are implemented on digital microcontrollers, requiring discrete-time models of battery dynamics. This practice bridges the gap between the continuous-time differential equations that describe the battery's physics and the discrete-time representation needed for a Kalman filter. By deriving the exact zero-order hold discretization for an equivalent circuit model and comparing it to a common approximation, you will gain crucial insight into the modeling errors that can affect filter performance. ",
            "id": "3922770",
            "problem": "In automated battery design and simulation, discrete-time models of electrochemical dynamics are necessary for implementing the Kalman filter (KF) and the particle filter (PF) for state estimation. Consider a canonical two-branch resistor-capacitor network, the two-resistor-two-capacitor Equivalent Circuit Model (ECM), driven by an applied current input. Let the states be the branch capacitor voltages, denoted by $v_{1}(t)$ and $v_{2}(t)$, associated with resistor-capacitor pairs $(R_{1},C_{1})$ and $(R_{2},C_{2})$, respectively. Assume the continuous-time linear time-invariant dynamics for the RC branches are governed by fundamental circuit relations for a capacitor, $i_{C} = C \\, dv/dt$, and Ohm’s law, $v = R i$, under superposition of branch currents driven by the applied current $i(t)$, with the following state-space representation:\n$$\n\\frac{d}{dt}\n\\begin{pmatrix}\nv_{1}(t) \\\\ v_{2}(t)\n\\end{pmatrix}\n=\n\\underbrace{\n\\begin{pmatrix}\n-\\frac{1}{R_{1} C_{1}}  0 \\\\\n0  -\\frac{1}{R_{2} C_{2}}\n\\end{pmatrix}}_{A}\n\\begin{pmatrix}\nv_{1}(t) \\\\ v_{2}(t)\n\\end{pmatrix}\n+\n\\underbrace{\n\\begin{pmatrix}\n\\frac{1}{C_{1}} \\\\\n\\frac{1}{C_{2}}\n\\end{pmatrix}}_{B}\n\\, i(t).\n$$\nLet the sampling period be $\\Delta t > 0$, and assume a Zero-Order Hold (ZOH) on the input, meaning $i(t)$ is constant over each interval $[k \\Delta t,(k+1)\\Delta t)$.\n\nStarting from the fundamental solution of linear time-invariant systems, derive the exact ZOH discrete-time state transition matrices $(A_{d},B_{d})$ corresponding to the mapping\n$$\n\\begin{pmatrix}\nv_{1}( (k+1)\\Delta t) \\\\ v_{2}( (k+1)\\Delta t)\n\\end{pmatrix}\n=\nA_{d}\n\\begin{pmatrix}\nv_{1}(k \\Delta t) \\\\ v_{2}(k \\Delta t)\n\\end{pmatrix}\n+\nB_{d} \\, i(k \\Delta t).\n$$\nThen, quantify the discretization error of the first-order forward Euler method relative to the exact ZOH discretization by forming the block matrices $G_{d} = [\\, A_{d} \\; B_{d} \\,]$ and $G_{e} = [\\, A_{e} \\; B_{e} \\,]$, where $A_{e}$ and $B_{e}$ are the first-order Euler discretizations derived from the same continuous-time $(A,B)$. Define the error magnitude as the Frobenius norm\n$$\n\\| G_{d} - G_{e} \\|_{F},\n$$\nand express this scalar exactly in terms of $R_{1}$, $C_{1}$, $R_{2}$, $C_{2}$, and $\\Delta t$.\n\nYour final reported quantity must be the exact closed-form analytical expression for $\\| G_{d} - G_{e} \\|_{F}$ as a function of $R_{1}$, $C_{1}$, $R_{2}$, $C_{2}$, and $\\Delta t$. Do not round. No physical units are required for the reported scalar.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in linear systems theory and electrical circuit analysis, well-posed with all necessary information, and expressed objectively. The tasks are computationally intensive but mathematically well-defined, leading to a unique analytical solution.\n\nThe problem requires a derivation of the discretization error between the exact Zero-Order Hold (ZOH) method and the first-order forward Euler method for a given continuous-time linear time-invariant (LTI) system. The system describes a two-resistor-two-capacitor (2R2C) equivalent circuit model for a battery. The error is quantified by the Frobenius norm of the difference between the augmented state-transition matrices.\n\nLet the state vector be $\\mathbf{x}(t) = \\begin{pmatrix} v_{1}(t) \\\\ v_{2}(t) \\end{pmatrix}$ and the input be $u(t) = i(t)$. The continuous-time state-space representation is $\\dot{\\mathbf{x}}(t) = A\\mathbf{x}(t) + B u(t)$, with matrices:\n$$\nA = \\begin{pmatrix} -\\frac{1}{R_{1} C_{1}}  0 \\\\ 0  -\\frac{1}{R_{2} C_{2}} \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} \\frac{1}{C_{1}} \\\\ \\frac{1}{C_{2}} \\end{pmatrix}\n$$\nWe define the time constants $\\tau_{1} = R_{1}C_{1}$ and $\\tau_{2} = R_{2}C_{2}$. The matrix $A$ is diagonal:\n$$\nA = \\begin{pmatrix} -\\frac{1}{\\tau_{1}}  0 \\\\ 0  -\\frac{1}{\\tau_{2}} \\end{pmatrix}\n$$\n\n**1. Exact Zero-Order Hold (ZOH) Discretization**\n\nThe solution to the LTI system equation over a sampling interval $[k\\Delta t, (k+1)\\Delta t]$ is given by the variation of constants formula. For a ZOH input where $u(t) = u(k\\Delta t) = u_k$ is constant over the interval, the exact discrete-time equivalent is:\n$$\n\\mathbf{x}((k+1)\\Delta t) = e^{A\\Delta t} \\mathbf{x}(k\\Delta t) + \\left( \\int_{0}^{\\Delta t} e^{As} ds \\right) B u(k\\Delta t)\n$$\nThis gives the discrete-time matrices $A_d = e^{A\\Delta t}$ and $B_d = \\left( \\int_{0}^{\\Delta t} e^{As} ds \\right) B$.\n\nSince $A$ is a diagonal matrix, its matrix exponential is found by exponentiating the diagonal elements:\n$$\nA_d = e^{A\\Delta t} = \\begin{pmatrix} \\exp\\left(-\\frac{\\Delta t}{\\tau_{1}}\\right)  0 \\\\ 0  \\exp\\left(-\\frac{\\Delta t}{\\tau_{2}}\\right) \\end{pmatrix} = \\begin{pmatrix} \\exp\\left(-\\frac{\\Delta t}{R_1 C_1}\\right)  0 \\\\ 0  \\exp\\left(-\\frac{\\Delta t}{R_2 C_2}\\right) \\end{pmatrix}\n$$\nThe integral term is also computed element-wise:\n$$\n\\int_{0}^{\\Delta t} e^{As} ds = \\begin{pmatrix} \\int_{0}^{\\Delta t} \\exp\\left(-\\frac{s}{\\tau_{1}}\\right) ds  0 \\\\ 0  \\int_{0}^{\\Delta t} \\exp\\left(-\\frac{s}{\\tau_{2}}\\right) ds \\end{pmatrix} = \\begin{pmatrix} [-\\tau_{1} \\exp\\left(-\\frac{s}{\\tau_{1}}\\right)]_{0}^{\\Delta t}  0 \\\\ 0  [-\\tau_{2} \\exp\\left(-\\frac{s}{\\tau_{2}}\\right)]_{0}^{\\Delta t} \\end{pmatrix}\n$$\n$$\n\\int_{0}^{\\Delta t} e^{As} ds = \\begin{pmatrix} \\tau_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{\\tau_{1}}\\right)\\right)  0 \\\\ 0  \\tau_{2} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{\\tau_{2}}\\right)\\right) \\end{pmatrix}\n$$\nNow, we compute $B_d$:\n$$\nB_d = \\begin{pmatrix} \\tau_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{\\tau_{1}}\\right)\\right)  0 \\\\ 0  \\tau_{2} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{\\tau_{2}}\\right)\\right) \\end{pmatrix} \\begin{pmatrix} \\frac{1}{C_{1}} \\\\ \\frac{1}{C_{2}} \\end{pmatrix}\n$$\nSubstituting $\\tau_1 = R_1 C_1$ and $\\tau_2 = R_2 C_2$:\n$$\nB_d = \\begin{pmatrix} R_{1}C_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{1}C_{1}}\\right)\\right) \\frac{1}{C_{1}} \\\\ R_{2}C_{2} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{2}C_{2}}\\right)\\right) \\frac{1}{C_{2}} \\end{pmatrix} = \\begin{pmatrix} R_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{1}C_{1}}\\right)\\right) \\\\ R_{2} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{2}C_{2}}\\right)\\right) \\end{pmatrix}\n$$\n\n**2. First-Order Forward Euler Discretization**\n\nThe forward Euler method approximates the derivative $\\dot{\\mathbf{x}}(t)$ by the forward difference $\\frac{\\mathbf{x}_{k+1} - \\mathbf{x}_k}{\\Delta t}$. Applying this to the continuous-time system:\n$$\n\\frac{\\mathbf{x}_{k+1} - \\mathbf{x}_k}{\\Delta t} = A \\mathbf{x}_k + B u_k\n$$\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + A\\Delta t \\mathbf{x}_k + B\\Delta t u_k = (I + A\\Delta t) \\mathbf{x}_k + (B\\Delta t) u_k\n$$\nThis gives the Euler approximation matrices $A_e = I + A\\Delta t$ and $B_e = B\\Delta t$.\n$$\nA_e = I + A\\Delta t = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} -\\frac{\\Delta t}{R_1 C_1}  0 \\\\ 0  -\\frac{\\Delta t}{R_2 C_2} \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{\\Delta t}{R_1 C_1}  0 \\\\ 0  1 - \\frac{\\Delta t}{R_2 C_2} \\end{pmatrix}\n$$\n$$\nB_e = B\\Delta t = \\begin{pmatrix} \\frac{1}{C_{1}} \\\\ \\frac{1}{C_{2}} \\end{pmatrix} \\Delta t = \\begin{pmatrix} \\frac{\\Delta t}{C_{1}} \\\\ \\frac{\\Delta t}{C_{2}} \\end{pmatrix}\n$$\n\n**3. Error Matrix and Frobenius Norm Calculation**\n\nWe form the augmented matrices $G_d = [A_d \\ B_d]$ and $G_e = [A_e \\ B_e]$. The error matrix is $\\Delta G = G_d - G_e$.\n$$\n\\Delta G = [A_d - A_e \\quad B_d - B_e]\n$$\nLet's compute the components of $\\Delta G$.\nThe first block is $A_d - A_e$:\n$$\nA_d - A_e = \\begin{pmatrix} \\exp\\left(-\\frac{\\Delta t}{R_1 C_1}\\right) - \\left(1 - \\frac{\\Delta t}{R_1 C_1}\\right)  0 \\\\ 0  \\exp\\left(-\\frac{\\Delta t}{R_2 C_2}\\right) - \\left(1 - \\frac{\\Delta t}{R_2 C_2}\\right) \\end{pmatrix}\n$$\nThe second block is $B_d - B_e$:\n$$\nB_d - B_e = \\begin{pmatrix} R_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{1}C_{1}}\\right)\\right) - \\frac{\\Delta t}{C_{1}} \\\\ R_{2} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{2}C_{2}}\\right)\\right) - \\frac{\\Delta t}{C_{2}} \\end{pmatrix}\n$$\nWe can rewrite the second block by factoring out $R_1$ and $R_2$:\n$$\n\\frac{\\Delta t}{C_1} = R_1 \\frac{\\Delta t}{R_1 C_1}\n$$\nSo the first component of $B_d - B_e$ is:\n$$\nR_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{1}C_{1}}\\right)\\right) - R_1 \\frac{\\Delta t}{R_1 C_1} = R_{1} \\left(1 - \\exp\\left(-\\frac{\\Delta t}{R_{1}C_{1}}\\right) - \\frac{\\Delta t}{R_{1}C_{1}}\\right)\n$$\nThis can be written as $-R_1$ times the $(1,1)$ element of $A_d - A_e$. Let $E_1 = \\exp\\left(-\\frac{\\Delta t}{R_1 C_1}\\right) - 1 + \\frac{\\Delta t}{R_1 C_1}$ and $E_2 = \\exp\\left(-\\frac{\\Delta t}{R_2 C_2}\\right) - 1 + \\frac{\\Delta t}{R_2 C_2}$.\nThe error matrix $\\Delta G$ is:\n$$\n\\Delta G = \\begin{pmatrix} E_1  0  -R_1 E_1 \\\\ 0  E_2  -R_2 E_2 \\end{pmatrix}\n$$\nThe Frobenius norm is $\\|M\\|_F = \\sqrt{\\sum_{i,j} |m_{ij}|^2}$.\n$$\n\\|\\Delta G\\|_{F}^2 = E_1^2 + 0^2 + (-R_1 E_1)^2 + 0^2 + E_2^2 + (-R_2 E_2)^2\n$$\n$$\n\\|\\Delta G\\|_{F}^2 = E_1^2 + R_1^2 E_1^2 + E_2^2 + R_2^2 E_2^2\n$$\n$$\n\\|\\Delta G\\|_{F}^2 = (1 + R_1^2) E_1^2 + (1 + R_2^2) E_2^2\n$$\nTaking the square root and substituting the expressions for $E_1$ and $E_2$:\n$$\n\\|\\Delta G\\|_{F} = \\sqrt{(1 + R_1^2) \\left(\\exp\\left(-\\frac{\\Delta t}{R_1 C_1}\\right) - 1 + \\frac{\\Delta t}{R_1 C_1}\\right)^2 + (1 + R_2^2) \\left(\\exp\\left(-\\frac{\\Delta t}{R_2 C_2}\\right) - 1 + \\frac{\\Delta t}{R_2 C_2}\\right)^2}\n$$\nThis is the exact, closed-form expression for the error magnitude.",
            "answer": "$$\\boxed{\\sqrt{\\left(1+R_1^2\\right) \\left(\\exp\\left(-\\frac{\\Delta t}{R_1 C_1}\\right) - 1 + \\frac{\\Delta t}{R_1 C_1}\\right)^2 + \\left(1+R_2^2\\right) \\left(\\exp\\left(-\\frac{\\Delta t}{R_2 C_2}\\right) - 1 + \\frac{\\Delta t}{R_2 C_2}\\right)^2}}$$"
        },
        {
            "introduction": "The Kalman filter is the cornerstone of state estimation for linear systems. This exercise provides a direct, hands-on application of the filter's two-step, predict-correct algorithm to a common battery equivalent circuit model. By manually computing each component of a full filter iteration—from the state prediction and innovation to the Kalman gain and final state update—you will build a concrete understanding of how the filter optimally fuses model predictions with noisy measurements. ",
            "id": "3922746",
            "problem": "Consider a Lithium-Ion cell approximated by a one resistor–capacitor (1-RC) Thevenin equivalent under constant-current sampling over the interval. The internal RC polarization voltage and State of Charge (SoC) are modeled in discrete time by a linear Gaussian state-space system. Let the state be $x_{k} = \\begin{pmatrix} v_{\\mathrm{rc},k} \\\\ z_{k} \\end{pmatrix}$, where $v_{\\mathrm{rc},k}$ is the RC branch voltage and $z_{k}$ is the SoC (expressed as a fraction between $0$ and $1$). The current input is $u_{k}$ (positive for discharge), and the measured terminal voltage is $y_{k}$. The discrete-time dynamics and measurement are given by\n$$\nx_{k+1} = A_{d}\\,x_{k} + B_{d}\\,u_{k} + w_{k}, \\quad w_{k} \\sim \\mathcal{N}(0, Q_{d}),\n$$\n$$\ny_{k} = V_{0} + C_{d}\\,x_{k} + D_{d}\\,u_{k} + \\eta_{k}, \\quad \\eta_{k} \\sim \\mathcal{N}(0, R),\n$$\nwith known matrices and scalars\n$$\nA_{d} = \\begin{pmatrix} 0.951229  0 \\\\ 0  1 \\end{pmatrix}, \\quad B_{d} = \\begin{pmatrix} -0.0004877 \\\\ -5.5556 \\times 10^{-5} \\end{pmatrix}, \\quad C_{d} = \\begin{pmatrix} -1  0.2 \\end{pmatrix}, \\quad D_{d} = -0.02,\n$$\n$$\nQ_{d} = \\begin{pmatrix} 1.0 \\times 10^{-5}  0 \\\\ 0  1.0 \\times 10^{-6} \\end{pmatrix}, \\quad R = 1.0 \\times 10^{-4}, \\quad V_{0} = 3.7.\n$$\nAssume a prior state estimate and covariance at time $k=0$ of\n$$\nx_{0|0} = \\begin{pmatrix} 0.050 \\\\ 0.800 \\end{pmatrix}, \\quad P_{0|0} = \\begin{pmatrix} 2.0 \\times 10^{-3}  0 \\\\ 0  4.0 \\times 10^{-4} \\end{pmatrix}.\n$$\nYou are given the following sequence of current inputs and measured terminal voltages:\n$$\nu_{1} = 2.0, \\quad y_{1} = 3.760; \\quad u_{2} = 1.5, \\quad y_{2} = 3.770; \\quad u_{3} = 0.0, \\quad y_{3} = 3.780.\n$$\nStarting from the fundamental definition of a discrete-time linear Gaussian state-space model and the minimum-variance linear estimator, perform one complete iteration of the Kalman Filter (KF) at $k=1$ using the pair $(u_{1}, y_{1})$ to compute:\n- the predicted state $x_{1|0}$,\n- the innovation $v_{1}$,\n- the innovation covariance $S_{1}$,\n- the Kalman gain $K_{1}$,\n- the updated state $x_{1|1}$,\n- and the updated covariance $P_{1|1}$ (use the Joseph-stabilized form for the covariance update).\n\nReport voltages in $\\mathrm{V}$, SoC as a unitless fraction, and covariances in the appropriate squared units; the innovation and its covariance pertain to the voltage channel. Round your final numerical values to four significant figures. Express the final answer as a single row matrix containing, in order,\n$$\n\\big( v_{\\mathrm{rc},1|0}, \\, z_{1|0}, \\, v_{1}, \\, S_{1}, \\, K_{1}^{(1)}, \\, K_{1}^{(2)}, \\, v_{\\mathrm{rc},1|1}, \\, z_{1|1}, \\, P_{1|1}^{(1,1)}, \\, P_{1|1}^{(1,2)}, \\, P_{1|1}^{(2,1)}, \\, P_{1|1}^{(2,2)} \\big).\n$$\nDo not include units in the boxed final answer.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to perform one iteration of a discrete-time Kalman Filter. The model is a standard linear-Gaussian state-space representation of a battery's electrical behavior, and the requested task is a direct application of a well-established algorithm.\n\nThe Kalman Filter is a recursive algorithm that provides the optimal (in the minimum mean square error sense) estimate of the state of a linear-Gaussian system. It operates in a two-step cycle: a prediction (or time update) step and a correction (or measurement update) step.\n\nLet the state estimate at time step $k-1$ be $x_{k-1|k-1}$ with its associated error covariance $P_{k-1|k-1}$. The system is described by:\n$$x_{k} = A_{d}\\,x_{k-1} + B_{d}\\,u_{k-1} + w_{k-1}, \\quad w_{k-1} \\sim \\mathcal{N}(0, Q_{d})$$\n$$y_{k} = C_{d}\\,x_{k} + D_{d}\\,u_{k} + \\eta_{k}, \\quad \\eta_{k} \\sim \\mathcal{N}(0, R)$$\nFor this problem, the measurement equation is given as $y_{k} = V_{0} + C_{d}\\,x_{k} + D_{d}\\,u_{k} + \\eta_{k}$.\n\nThe initial conditions at time $k=0$ are provided:\n$$x_{0|0} = \\begin{pmatrix} 0.050 \\\\ 0.800 \\end{pmatrix}, \\quad P_{0|0} = \\begin{pmatrix} 2.0 \\times 10^{-3}  0 \\\\ 0  4.0 \\times 10^{-4} \\end{pmatrix}$$\nThe task is to perform one full iteration for $k=1$, using the input $u_{1} = 2.0$ and measurement $y_{1} = 3.760$.\n\n**Step 1: Prediction (Time Update)**\n\nThe prediction step projects the state and covariance from $k=0$ to $k=1$, before incorporating the measurement at $k=1$.\n\nThe predicted state mean $x_{1|0}$ is calculated as:\n$$x_{1|0} = A_{d}\\,x_{0|0} + B_{d}\\,u_{1}$$\n$$x_{1|0} = \\begin{pmatrix} 0.951229  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 0.050 \\\\ 0.800 \\end{pmatrix} + \\begin{pmatrix} -0.0004877 \\\\ -5.5556 \\times 10^{-5} \\end{pmatrix} (2.0)$$\n$$x_{1|0} = \\begin{pmatrix} 0.04756145 \\\\ 0.800 \\end{pmatrix} + \\begin{pmatrix} -0.0009754 \\\\ -0.000111112 \\end{pmatrix} = \\begin{pmatrix} 0.04658605 \\\\ 0.79988889 \\end{pmatrix}$$\nSo, $v_{\\mathrm{rc},1|0} \\approx 0.046586$ and $z_{1|0} \\approx 0.79989$.\n\nThe predicted error covariance $P_{1|0}$ is calculated as:\n$$P_{1|0} = A_{d}\\,P_{0|0}\\,A_{d}^T + Q_{d}$$\n$$P_{1|0} = \\begin{pmatrix} 0.951229  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 0.002  0 \\\\ 0  0.0004 \\end{pmatrix} \\begin{pmatrix} 0.951229  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 1.0 \\times 10^{-5}  0 \\\\ 0  1.0 \\times 10^{-6} \\end{pmatrix}$$\n$$P_{1|0} = \\begin{pmatrix} (0.951229)^2(0.002)  0 \\\\ 0  (1)^2(0.0004) \\end{pmatrix} + \\begin{pmatrix} 0.00001  0 \\\\ 0  0.000001 \\end{pmatrix}$$\n$$P_{1|0} = \\begin{pmatrix} 0.00180967  0 \\\\ 0  0.0004 \\end{pmatrix} + \\begin{pmatrix} 0.00001  0 \\\\ 0  0.000001 \\end{pmatrix} = \\begin{pmatrix} 0.00181967  0 \\\\ 0  0.000401 \\end{pmatrix}$$\n\n**Step 2: Correction (Measurement Update)**\n\nThe correction step refines the predicted state and covariance using the measurement $y_{1}$.\n\nThe innovation, or measurement residual, $v_{1}$ is the difference between the actual measurement and the predicted measurement:\n$$v_{1} = y_{1} - \\hat{y}_{1|0} = y_{1} - (V_{0} + C_{d}\\,x_{1|0} + D_{d}\\,u_{1})$$\n$$v_{1} = 3.760 - \\left( 3.7 + \\begin{pmatrix} -1  0.2 \\end{pmatrix} \\begin{pmatrix} 0.04658605 \\\\ 0.79988889 \\end{{pmatrix} + (-0.02)(2.0) \\right)$$\n$$v_{1} = 3.760 - (3.7 - 0.04658605 + 0.15997778 - 0.04) = 3.760 - 3.77339173 = -0.01339173$$\n\nThe innovation covariance $S_{1}$ is calculated as:\n$$S_{1} = C_{d}\\,P_{1|0}\\,C_{d}^T + R$$\n$$S_{1} = \\begin{pmatrix} -1  0.2 \\end{pmatrix} \\begin{pmatrix} 0.00181967  0 \\\\ 0  0.000401 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 0.2 \\end{pmatrix} + 1.0 \\times 10^{-4}$$\n$$S_{1} = ((-1)^2(0.00181967) + (0.2)^2(0.000401)) + 0.0001$$\n$$S_{1} = (0.00181967 + 0.00001604) + 0.0001 = 0.00183571 + 0.0001 = 0.00193571$$\n\nThe optimal Kalman gain $K_{1}$ is:\n$$K_{1} = P_{1|0}\\,C_{d}^T\\,S_{1}^{-1}$$\n$$P_{1|0}\\,C_{d}^T = \\begin{pmatrix} 0.00181967  0 \\\\ 0  0.000401 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 0.2 \\end{pmatrix} = \\begin{pmatrix} -0.00181967 \\\\ 0.0000802 \\end{pmatrix}$$\n$$K_{1} = \\begin{pmatrix} -0.00181967 \\\\ 0.0000802 \\end{pmatrix} (0.00193571)^{-1} = \\begin{pmatrix} -0.940053 \\\\ 0.0414320 \\end{pmatrix}$$\nThus, $K_{1}^{(1)} \\approx -0.94005$ and $K_{1}^{(2)} \\approx 0.041432$.\n\nThe updated state estimate $x_{1|1}$ is:\n$$x_{1|1} = x_{1|0} + K_{1}\\,v_{1}$$\n$$x_{1|1} = \\begin{pmatrix} 0.04658605 \\\\ 0.79988889 \\end{pmatrix} + \\begin{pmatrix} -0.940053 \\\\ 0.0414320 \\end{pmatrix} (-0.01339173)$$\n$$x_{1|1} = \\begin{pmatrix} 0.04658605 \\\\ 0.79988889 \\end{pmatrix} + \\begin{pmatrix} 0.0125889 \\\\ -0.0005548 \\end{pmatrix} = \\begin{pmatrix} 0.059175 \\\\ 0.799334 \\end{pmatrix}$$\nSo, $v_{\\mathrm{rc},1|1} \\approx 0.059175$ and $z_{1|1} \\approx 0.79933$.\n\nThe updated error covariance $P_{1|1}$ is calculated using the Joseph-stabilized form as requested, which guarantees symmetry and positive semi-definiteness:\n$$P_{1|1} = (I - K_{1}\\,C_{d})\\,P_{1|0}\\,(I - K_{1}\\,C_{d})^T + K_{1}\\,R\\,K_{1}^T$$\nFirst term calculation:\n$$I - K_{1}\\,C_{d} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} - \\begin{pmatrix} -0.940053 \\\\ 0.0414320 \\end{pmatrix}\\begin{pmatrix} -1  0.2 \\end{pmatrix} = \\begin{pmatrix} 1-0.940053  0.1880106 \\\\ 0.0414320  1-0.0082864 \\end{pmatrix} = \\begin{pmatrix} 0.059947  0.1880106 \\\\ 0.0414320  0.9917136 \\end{pmatrix}$$\nLet $M = I-K_1 C_d$. The first term is $M P_{1|0} M^T$:\n$$ M P_{1|0} M^T \\approx \\begin{pmatrix} 2.0713 \\times 10^{-5}  7.9287 \\times 10^{-5} \\\\ 7.9287 \\times 10^{-5}  3.9751 \\times 10^{-4} \\end{pmatrix}$$\nSecond term calculation, $K_{1}\\,R\\,K_{1}^T$:\n$$K_{1}\\,R\\,K_{1}^T = \\begin{pmatrix} -0.940053 \\\\ 0.0414320 \\end{pmatrix} (1.0 \\times 10^{-4}) \\begin{pmatrix} -0.940053  0.0414320 \\end{pmatrix}$$\n$$K_{1}\\,R\\,K_{1}^T \\approx \\begin{pmatrix} 8.8370 \\times 10^{-5}  -3.8943 \\times 10^{-6} \\\\ -3.8943 \\times 10^{-6}  1.7166 \\times 10^{-7} \\end{pmatrix}$$\nAdding the two terms:\n$$P_{1|1} = \\begin{pmatrix} 2.0713 \\times 10^{-5} + 8.8370 \\times 10^{-5}  7.9287 \\times 10^{-5} - 3.8943 \\times 10^{-6} \\\\ 7.9287 \\times 10^{-5} - 3.8943 \\times 10^{-6}  3.9751 \\times 10^{-4} + 1.7166 \\times 10^{-7} \\end{pmatrix}$$\n$$P_{1|1} = \\begin{pmatrix} 1.09083 \\times 10^{-4}  7.5393 \\times 10^{-5} \\\\ 7.5393 \\times 10^{-5}  3.9768 \\times 10^{-4} \\end{pmatrix}$$\n\nRounding the final results to four significant figures:\n$v_{\\mathrm{rc},1|0} \\approx 0.04659$\n$z_{1|0} \\approx 0.7999$\n$v_{1} \\approx -0.01339$\n$S_{1} \\approx 0.001936$\n$K_{1}^{(1)} \\approx -0.9401$\n$K_{1}^{(2)} \\approx 0.04143$\n$v_{\\mathrm{rc},1|1} \\approx 0.05917$\n$z_{1|1} \\approx 0.7993$\n$P_{1|1}^{(1,1)} \\approx 1.091 \\times 10^{-4}$\n$P_{1|1}^{(1,2)} \\approx 7.539 \\times 10^{-5}$\n$P_{1|1}^{(2,1)} \\approx 7.539 \\times 10^{-5}$\n$P_{1|1}^{(2,2)} \\approx 3.977 \\times 10^{-4}$\n\nThese values are formatted into the required row matrix for the final answer.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.04659  0.7999  -0.01339  0.001936  -0.9401  0.04143  0.05917  0.7993  0.0001091  0.00007539  0.00007539  0.0003977\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "When battery models exhibit significant nonlinearity, the Particle Filter (PF) offers a powerful alternative to the Kalman filter family. This practice focuses on the PF's core mechanism: the measurement update based on importance sampling, where particle weights are adjusted according to how well each particle explains the latest measurement. Calculating the effective sample size ($N_{\\text{eff}}$) will demonstrate the critical challenge of particle degeneracy and clarify the rationale behind the resampling step, which is essential for maintaining a healthy and representative particle set. ",
            "id": "3922794",
            "problem": "Consider a particle-based Bayesian state estimator for a lithium-ion cell within an automated battery design and simulation pipeline. The estimator uses a Particle Filter (PF) to track the battery’s internal state and applies a nonlinear measurement model for terminal voltage. Assume the voltage measurement at time $k$ is modeled by $y_{k} = h(x_{k}) + v_{k}$, where $h(\\cdot)$ is a nonlinear function of the battery state $x_{k}$ and $v_{k}$ is zero-mean Gaussian measurement noise with standard deviation $\\sigma_{v}$. Prior to receiving $y_{k}$, the PF holds $N=5$ propagated particles $\\{x_{k}^{(i)}\\}_{i=1}^{5}$ with equal prior weights $w_{k-1}^{(i)} = \\frac{1}{5}$, and their predicted terminal voltages under the model $h(\\cdot)$ are given by\n$$\n\\hat{v}_{k}^{(1)} = 3.95,\\quad \\hat{v}_{k}^{(2)} = 3.90,\\quad \\hat{v}_{k}^{(3)} = 4.00,\\quad \\hat{v}_{k}^{(4)} = 3.96,\\quad \\hat{v}_{k}^{(5)} = 3.88,\n$$\nin volts. Suppose the new measurement is $y_{k} = 3.95$ volts and the measurement noise standard deviation is $\\sigma_{v} = 0.01$ volts. The resampling threshold is set to $\\tau = 0.5 N$.\n\nStarting from the foundational principles of Bayesian inference and the definition of the Gaussian likelihood for $v_{k}$, perform the measurement update to obtain the normalized posterior importance weights $\\{w_{k}^{(i)}\\}_{i=1}^{5}$. Then, starting from the core definition of the effective sample size as a measure of weight degeneracy in importance sampling, derive the expression used to compute the effective sample size and evaluate it numerically for the given data.\n\nDecide whether resampling should be triggered by comparing the effective sample size to the threshold $\\tau$. Round the effective sample size to four significant figures. Express the final answer as a row matrix containing two entries: the rounded effective sample size and a binary resampling decision indicator $I$, where $I = 1$ if resampling is triggered and $I = 0$ otherwise. No physical units are required in the final answer.",
            "solution": "The problem requires a two-part calculation: first, the update of the particle weights based on a new measurement, and second, the calculation of the effective sample size to decide on resampling.\n\n**Part 1: Measurement Update of Particle Weights**\n\nThe core of the Particle Filter's measurement update step is rooted in Bayesian inference. The posterior belief is proportional to the prior belief multiplied by the likelihood of the measurement. For each particle, this translates to updating its weight:\n$$\nw_{k}^{(i)} \\propto w_{k-1}^{(i)} \\cdot p(y_k | x_k^{(i)})\n$$\nHere, $w_{k-1}^{(i)}$ is the prior weight and $p(y_k | x_k^{(i)})$ is the likelihood of observing the measurement $y_k$ given the state of particle $i$, $x_k^{(i)}$.\n\nThe problem states that the prior weights are uniform: $w_{k-1}^{(i)} = \\frac{1}{N} = \\frac{1}{5}$. The measurement model is $y_{k} = h(x_{k}) + v_{k}$, where $v_{k} \\sim \\mathcal{N}(0, \\sigma_v^2)$. This implies that the likelihood function $p(y_k | x_k^{(i)})$ is the probability density function (PDF) of a Gaussian distribution with mean $\\mu = h(x_k^{(i)})$ and variance $\\sigma_v^2$, evaluated at $y_k$.\n$$\np(y_k | x_k^{(i)}) = \\frac{1}{\\sqrt{2\\pi\\sigma_v^2}} \\exp\\left(-\\frac{(y_k - h(x_k^{(i)}))^2}{2\\sigma_v^2}\\right)\n$$\nThe predicted measurement is given as $\\hat{v}_k^{(i)} = h(x_k^{(i)})$. The unnormalized posterior weight, $\\tilde{w}_k^{(i)}$, is proportional to the likelihood, as the prior weights are constant for all particles. The constant term $\\frac{1}{\\sqrt{2\\pi\\sigma_v^2}}$ can be dropped as it will cancel out during normalization.\n$$\n\\tilde{w}_k^{(i)} = \\exp\\left(-\\frac{(y_k - \\hat{v}_k^{(i)})^2}{2\\sigma_v^2}\\right)\n$$\nWe are given $y_k = 3.95$ and $\\sigma_v = 0.01$, so $\\sigma_v^2 = (0.01)^2 = 0.0001$. We first compute the squared residuals $(y_k - \\hat{v}_k^{(i)})^2$ for each particle $i=1, \\dots, 5$:\n*   $i=1$: $(3.95 - 3.95)^2 = 0^2 = 0$\n*   $i=2$: $(3.95 - 3.90)^2 = 0.05^2 = 0.0025$\n*   $i=3$: $(3.95 - 4.00)^2 = (-0.05)^2 = 0.0025$\n*   $i=4$: $(3.95 - 3.96)^2 = (-0.01)^2 = 0.0001$\n*   $i=5$: $(3.95 - 3.88)^2 = 0.07^2 = 0.0049$\n\nNow, we compute the unnormalized weights $\\tilde{w}_k^{(i)}$ using the exponent term $-\\frac{\\text{residual}^2}{2\\sigma_v^2} = -\\frac{\\text{residual}^2}{2(0.0001)} = -\\frac{\\text{residual}^2}{0.0002}$.\n*   $\\tilde{w}_k^{(1)} = \\exp\\left(-\\frac{0}{0.0002}\\right) = \\exp(0) = 1$\n*   $\\tilde{w}_k^{(2)} = \\exp\\left(-\\frac{0.0025}{0.0002}\\right) = \\exp(-12.5)$\n*   $\\tilde{w}_k^{(3)} = \\exp\\left(-\\frac{0.0025}{0.0002}\\right) = \\exp(-12.5)$\n*   $\\tilde{w}_k^{(4)} = \\exp\\left(-\\frac{0.0001}{0.0002}\\right) = \\exp(-0.5)$\n*   $\\tilde{w}_k^{(5)} = \\exp\\left(-\\frac{0.0049}{0.0002}\\right) = \\exp(-24.5)$\n\nTo obtain the normalized posterior weights $w_k^{(i)}$, we sum the unnormalized weights and divide each by the sum:\n$$\nw_k^{(i)} = \\frac{\\tilde{w}_k^{(i)}}{\\sum_{j=1}^N \\tilde{w}_k^{(j)}}\n$$\nThe sum is $S_w = \\sum_{j=1}^5 \\tilde{w}_k^{(j)} = 1 + 2\\exp(-12.5) + \\exp(-0.5) + \\exp(-24.5)$.\n\n**Part 2: Effective Sample Size and Resampling Decision**\n\nThe effective sample size, $N_{\\text{eff}}$, quantifies the degeneracy of the particle weights. A perfectly healthy set of particles has uniform weights, $w^{(i)} = 1/N$, while a completely degenerate set has one particle with weight $w^{(j)}=1$ and all others with weight $0$. A principled way to define $N_{\\text{eff}}$ is based on the sum of the squares of the normalized weights, $\\sum (w^{(i)})^2$.\n\nFor an \"ideal\" sample of $M$ particles with uniform weights $w^{(i)} = 1/M$, the sum of squared weights is $\\sum_{i=1}^M (1/M)^2 = M \\cdot (1/M^2) = 1/M$. We define the effective sample size $N_{\\text{eff}}$ by equating the sum of squared weights of our current particle set to that of an ideal set of size $N_{\\text{eff}}$:\n$$\n\\frac{1}{N_{\\text{eff}}} = \\sum_{i=1}^{N} (w_k^{(i)})^2\n$$\nThis yields the standard formula for the effective sample size:\n$$\nN_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^{N} (w_k^{(i)})^2}\n$$\nThe value of $N_{\\text{eff}}$ ranges from $1$ (complete degeneracy) to $N$ (no degeneracy, all weights are equal).\n\nTo calculate $N_{\\text{eff}}$, we use the unnormalized weights to avoid premature rounding.\n$$\nN_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^{N} \\left(\\frac{\\tilde{w}_k^{(i)}}{S_w}\\right)^2} = \\frac{S_w^2}{\\sum_{i=1}^N (\\tilde{w}_k^{(i)})^2} = \\frac{\\left(\\sum_i \\tilde{w}_k^{(i)}\\right)^2}{\\sum_i (\\tilde{w}_k^{(i)})^2}\n$$\nLet's compute the two sums:\n$S_w = \\sum_{i=1}^5 \\tilde{w}_k^{(i)} = 1 + 2\\exp(-12.5) + \\exp(-0.5) + \\exp(-24.5)$\n$\\sum_{i=1}^5 (\\tilde{w}_k^{(i)})^2 = 1^2 + (\\exp(-12.5))^2 + (\\exp(-12.5))^2 + (\\exp(-0.5))^2 + (\\exp(-24.5))^2 = 1 + 2\\exp(-25) + \\exp(-1) + \\exp(-49)$\n\nUsing numerical values:\n$S_w \\approx 1 + 2(3.720 \\times 10^{-6}) + 0.60653066 + 1.690 \\times 10^{-11} \\approx 1.6065381$\n$\\sum (\\tilde{w}_k^{(i)})^2 \\approx 1 + 2(1.384 \\times 10^{-11}) + 0.36787944 + 2.855 \\times 10^{-22} \\approx 1.3678794$\n$N_{\\text{eff}} = \\frac{(1.6065381)^2}{1.3678794} \\approx \\frac{2.5809653}{1.3678794} \\approx 1.886835$\n\nRounding to four significant figures, we get $N_{\\text{eff}} = 1.887$.\n\nFinally, we must decide whether to resample. The resampling threshold is $\\tau = 0.5 N = 0.5 \\times 5 = 2.5$. Resampling is triggered if $N_{\\text{eff}}  \\tau$.\nWe compare our calculated value: $1.887  2.5$. The condition is satisfied.\nTherefore, resampling is triggered, and the resampling indicator is $I=1$.\n\nThe final answer comprises the rounded effective sample size and the resampling indicator.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.887  1\n\\end{pmatrix}\n}\n$$"
        }
    ]
}