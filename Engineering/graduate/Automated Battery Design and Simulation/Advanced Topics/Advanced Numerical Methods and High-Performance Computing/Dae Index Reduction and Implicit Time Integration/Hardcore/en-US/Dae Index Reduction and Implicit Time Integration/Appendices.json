{
    "hands_on_practices": [
        {
            "introduction": "Any simulation of a differential-algebraic equation (DAE) must begin from a state that respects the system's algebraic constraints. This exercise tackles the crucial task of finding such consistent initial conditions for a semi-discretized Doyle-Fuller-Newman (DFN) model, a cornerstone of battery simulation. By translating fundamental electrochemical laws into a system of nonlinear equations and implementing a Newton solver, you will gain hands-on experience setting up a physically valid starting point for a complex battery simulation .",
            "id": "3903333",
            "problem": "Consider the Doyle–Fuller–Newman (DFN) model of a Lithium-ion battery under semi-discretization in space, where the solid-phase and electrolyte-phase electric potentials are algebraic variables and the concentrations are differential variables. At the start of an implicit time integration (e.g., backward Euler), consistent initial conditions must satisfy the algebraic constraints at time $t = 0$ for a specified applied current and state of charge. Assume a two-electrode cell with a negative electrode (n) and a positive electrode (p), and suppose that the electrolyte potential at the negative electrode is chosen as the gauge reference $0$ (index-reduction via gauge fixing). The following well-tested scientific relations are taken as the fundamental base:\n\n- Charge conservation at each electrode interface equates the reaction current density to the applied current scaled by interfacial area.\n- Butler–Volmer kinetics with symmetric transfer coefficients relate reaction current density to the activation overpotential.\n- An ohmic relation in the electrolyte approximates the electrolyte potential drop between electrodes as proportional to the applied current.\n\nLet $i_{\\mathrm{app}}$ denote the dimensionless applied current (normalized by a characteristic current and area), $a_n$ and $a_p$ denote dimensionless interfacial area scalings for the negative and positive electrodes, respectively, $k_n$ and $k_p$ denote dimensionless kinetic prefactors, $r_e$ denote the dimensionless electrolyte resistance, and let the open-circuit potentials $U_n$ and $U_p$ be given by a Nernst-type relation\n$$\nU_{\\ell}(c_{\\ell}) = U_{\\ell,\\mathrm{ref}} + \\beta_{\\ell}\\,\\ln\\!\\left(\\frac{c_{\\ell}}{1 - c_{\\ell}}\\right), \\quad \\ell \\in \\{n,p\\},\n$$\nwhere $c_{\\ell}\\in(0,1)$ is the dimensionless solid-phase lithium fraction at the electrode surface (equal initially to the state of charge at each electrode), $U_{\\ell,\\mathrm{ref}}$ is a dimensionless reference potential, and $\\beta_{\\ell}$ is a dimensionless coefficient.\n\nLet the unknowns be the solid-phase potentials at each electrode $\\phi_{s,n}$, $\\phi_{s,p}$ and the electrolyte potential at the positive electrode $\\phi_{e,p}$, with the gauge $\\phi_{e,n} = 0$. The Butler–Volmer reaction current densities are\n$$\nj_n = 2\\,k_n\\,\\sinh\\!\\left(\\frac{\\phi_{s,n} - \\phi_{e,n} - U_n(c_n)}{2}\\right) = 2\\,k_n\\,\\sinh\\!\\left(\\frac{\\phi_{s,n} - U_n(c_n)}{2}\\right),\n$$\n$$\nj_p = 2\\,k_p\\,\\sinh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p(c_p)}{2}\\right),\n$$\nand the algebraic system to enforce consistency with the specified applied current and state of charge is\n$$\nF_1(\\phi_{s,n}) = a_n\\,j_n - i_{\\mathrm{app}} = 0,\n$$\n$$\nF_2(\\phi_{s,p},\\phi_{e,p}) = a_p\\,j_p + i_{\\mathrm{app}} = 0,\n$$\n$$\nF_3(\\phi_{e,p}) = \\phi_{e,p} - r_e\\,i_{\\mathrm{app}} = 0.\n$$\nThe initial solid concentrations are differential variables and are therefore free to be set by the specified state of charge at $t=0$, i.e., $c_n = \\mathrm{SOC}_n$ and $c_p = \\mathrm{SOC}_p$. The problem asks to formulate this system and outline a Newton method to solve it.\n\nTasks:\n1. Starting from the fundamental base stated above, write the nonlinear system $F(\\mathbf{x}) = \\mathbf{0}$ with $\\mathbf{x} = [\\phi_{s,n}, \\phi_{s,p}, \\phi_{e,p}]^\\top$ that must be solved to find initial potentials and concentrations consistent with a specified initial current $i_{\\mathrm{app}}$ and state of charge values $c_n$ and $c_p$.\n2. Derive the analytic Jacobian matrix $J(\\mathbf{x}) = \\partial F/\\partial \\mathbf{x}$ suitable for Newton iterations.\n3. Implement a damped Newton method to solve for $\\phi_{s,n}$, $\\phi_{s,p}$, and $\\phi_{e,p}$ given parameter values and initial guesses. Use the gauge $\\phi_{e,n} = 0$. Treat $c_n$ and $c_p$ as equal to the given $\\mathrm{SOC}_n$ and $\\mathrm{SOC}_p$, respectively.\n4. Provide a test suite of three parameter sets that test different regimes:\n   - A typical operating current case.\n   - A near-equilibrium case with $i_{\\mathrm{app}} = 0$.\n   - A high-current case.\n   For each case, specify $(i_{\\mathrm{app}}, \\mathrm{SOC}_n, \\mathrm{SOC}_p, a_n, a_p, k_n, k_p, r_e, U_{n,\\mathrm{ref}}, U_{p,\\mathrm{ref}}, \\beta_n, \\beta_p)$.\n5. Final output format: Your program should produce a single line of output containing the results aggregated across all test cases as a comma-separated list enclosed in square brackets. For each test case, output the six floats $[\\phi_{s,n},\\phi_{e,n},\\phi_{s,p},\\phi_{e,p},c_n,c_p]$ flattened into a single list over all test cases, in that order. All quantities are dimensionless, so no physical units are required.\n\nTest suite parameters to use:\n- Case 1 (typical): $(i_{\\mathrm{app}}, \\mathrm{SOC}_n, \\mathrm{SOC}_p, a_n, a_p, k_n, k_p, r_e, U_{n,\\mathrm{ref}}, U_{p,\\mathrm{ref}}, \\beta_n, \\beta_p) = (0.5, 0.7, 0.4, 1.0, 1.0, 1.0, 1.0, 0.2, 0.1, 4.0, 0.1, 0.1)$.\n- Case 2 (near-equilibrium): $(0.0, 0.6, 0.6, 1.0, 1.0, 1.0, 1.0, 0.3, 0.15, 3.9, 0.2, 0.2)$.\n- Case 3 (high-current): $(2.0, 0.9, 0.3, 1.0, 1.0, 1.5, 1.0, 0.5, 0.2, 4.2, 0.15, 0.12)$.\n\nYour program must implement the Newton solve for the nonlinear system defined above and produce the specified output format. No user input is required.",
            "solution": "The problem requires the formulation and solution of a nonlinear algebraic system to determine consistent initial conditions for a semi-discretized Doyle-Fuller-Newman (DFN) battery model. The analysis proceeds in three steps: first, formulating the governing system of equations; second, deriving the Jacobian matrix required for a Newton-Raphson iterative solver; and third, outlining the implementation of a damped Newton method to find the solution.\n\n### 1. Formulation of the Nonlinear System\n\nThe state vector of unknowns is defined as $\\mathbf{x} = [\\phi_{s,n}, \\phi_{s,p}, \\phi_{e,p}]^\\top$, representing the solid-phase potential at the negative electrode, the solid-phase potential at the positive electrode, and the electrolyte-phase potential at the positive electrode, respectively. The electrolyte potential at the negative electrode is fixed by a gauge condition, $\\phi_{e,n} = 0$. The initial solid-phase surface concentrations, $c_n$ and $c_p$, are given as fixed parameters, equal to the electrode-specific states of charge, $\\mathrm{SOC}_n$ and $\\mathrm{SOC}_p$.\n\nThe system of equations, $F(\\mathbf{x}) = \\mathbf{0}$, arises from fundamental electrochemical and transport principles:\n\n1.  **Charge Conservation at the Negative Electrode Interface:** The total current generated by the electrochemical reaction over the entire interfacial area must equal the applied current, $i_{\\mathrm{app}}$. This gives the first equation:\n    $$F_1 = a_n\\,j_n - i_{\\mathrm{app}} = 0$$\n    Here, $a_n$ is the interfacial area scaling, and $j_n$ is the reaction current density at the negative electrode.\n\n2.  **Charge Conservation at the Positive Electrode Interface:** Similarly, accounting for the sign convention (current enters the positive electrode during discharge), we have:\n    $$F_2 = a_p\\,j_p + i_{\\mathrm{app}} = 0$$\n    where $a_p$ is the area scaling and $j_p$ is the reaction current density at the positive electrode.\n\n3.  **Ohmic Drop in the Electrolyte:** A simplified ohmic model relates the potential drop in the electrolyte to the applied current:\n    $$F_3 = \\phi_{e,p} - \\phi_{e,n} - r_e\\,i_{\\mathrm{app}} = 0$$\n    With the gauge $\\phi_{e,n}=0$, this simplifies to:\n    $$F_3 = \\phi_{e,p} - r_e\\,i_{\\mathrm{app}} = 0$$\n    where $r_e$ is the effective dimensionless resistance of the electrolyte.\n\nThe reaction current densities, $j_n$ and $j_p$, are described by the Butler-Volmer equation for symmetric transfer coefficients ($\\alpha_a = \\alpha_c = 0.5$):\n$$j_{\\ell} = 2\\,k_{\\ell}\\,\\sinh\\!\\left(\\frac{\\eta_{\\ell}}{2}\\right), \\quad \\ell \\in \\{n, p\\}$$\nwhere $k_{\\ell}$ is the kinetic rate prefactor and $\\eta_{\\ell}$ is the activation overpotential, defined as $\\eta_{\\ell} = \\phi_{s,\\ell} - \\phi_{e,\\ell} - U_{\\ell}(c_{\\ell})$. The open-circuit potentials, $U_n$ and $U_p$, are functions of the surface concentrations and are given by:\n$$U_{\\ell}(c_{\\ell}) = U_{\\ell,\\mathrm{ref}} + \\beta_{\\ell}\\,\\ln\\!\\left(\\frac{c_{\\ell}}{1 - c_{\\ell}}\\right)$$\nFor this initialization problem, $c_n$ and $c_p$ are fixed, so $U_n$ and $U_p$ are treated as constants.\n\nSubstituting the expressions for $j_n$ and $j_p$ into the conservation equations, we obtain the explicit nonlinear system $F(\\mathbf{x}) = [F_1, F_2, F_3]^\\top = \\mathbf{0}$:\n$$\nF_1(\\phi_{s,n}) = 2\\,a_n\\,k_n\\,\\sinh\\!\\left(\\frac{\\phi_{s,n} - U_n}{2}\\right) - i_{\\mathrm{app}} = 0\n$$\n$$\nF_2(\\phi_{s,p}, \\phi_{e,p}) = 2\\,a_p\\,k_p\\,\\sinh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right) + i_{\\mathrm{app}} = 0\n$$\n$$\nF_3(\\phi_{e,p}) = \\phi_{e,p} - r_e\\,i_{\\mathrm{app}} = 0\n$$\n\n### 2. Derivation of the Jacobian Matrix\n\nThe Newton-Raphson method requires the Jacobian matrix, $J(\\mathbf{x}) = \\partial F / \\partial \\mathbf{x}$, whose elements are $J_{ij} = \\partial F_i / \\partial x_j$. The state vector is $\\mathbf{x} = [\\phi_{s,n}, \\phi_{s,p}, \\phi_{e,p}]^\\top$.\n\nThe partial derivatives are calculated as follows, using the chain rule and the fact that $d(\\sinh(u))/dx = \\cosh(u) \\cdot du/dx$.\n\n- **Derivatives of $F_1$:**\n  - $\\frac{\\partial F_1}{\\partial \\phi_{s,n}} = 2\\,a_n\\,k_n\\,\\cosh\\!\\left(\\frac{\\phi_{s,n} - U_n}{2}\\right) \\cdot \\frac{1}{2} = a_n\\,k_n\\,\\cosh\\!\\left(\\frac{\\phi_{s,n} - U_n}{2}\\right)$\n  - $\\frac{\\partial F_1}{\\partial \\phi_{s,p}} = 0$\n  - $\\frac{\\partial F_1}{\\partial \\phi_{e,p}} = 0$\n\n- **Derivatives of $F_2$:**\n  - $\\frac{\\partial F_2}{\\partial \\phi_{s,n}} = 0$\n  - $\\frac{\\partial F_2}{\\partial \\phi_{s,p}} = 2\\,a_p\\,k_p\\,\\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right) \\cdot \\frac{1}{2} = a_p\\,k_p\\,\\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right)$\n  - $\\frac{\\partial F_2}{\\partial \\phi_{e,p}} = 2\\,a_p\\,k_p\\,\\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right) \\cdot \\left(-\\frac{1}{2}\\right) = -a_p\\,k_p\\,\\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right)$\n\n- **Derivatives of $F_3$:**\n  - $\\frac{\\partial F_3}{\\partial \\phi_{s,n}} = 0$\n  - $\\frac{\\partial F_3}{\\partial \\phi_{s,p}} = 0$\n  - $\\frac{\\partial F_3}{\\partial \\phi_{e,p}} = 1$\n\nAssembling these components yields the Jacobian matrix:\n$$\nJ(\\mathbf{x}) = \\begin{pmatrix}\na_n k_n \\cosh\\!\\left(\\frac{\\phi_{s,n} - U_n}{2}\\right) & 0 & 0 \\\\\n0 & a_p k_p \\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right) & -a_p k_p \\cosh\\!\\left(\\frac{\\phi_{s,p} - \\phi_{e,p} - U_p}{2}\\right) \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nThe upper triangular structure of the Jacobian indicates that the system is only partially coupled.\n\n### 3. Damped Newton Method\n\nThe Newton-Raphson method is an iterative procedure for finding the root of $F(\\mathbf{x}) = \\mathbf{0}$. Starting from an initial guess $\\mathbf{x}_0$, successive approximations $\\mathbf{x}_{k+1}$ are found by solving a linear system based on the first-order Taylor expansion of $F(\\mathbf{x})$ around the current iterate $\\mathbf{x}_k$.\n\nThe iterative update is given by:\n$$ \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\Delta\\mathbf{x}_k $$\nwhere the step direction $\\Delta\\mathbf{x}_k$ is the solution to the linear system:\n$$ J(\\mathbf{x}_k) \\Delta\\mathbf{x}_k = -F(\\mathbf{x}_k) $$\nThe scalar $\\alpha_k \\in (0, 1]$ is a damping factor, chosen to ensure convergence from a wider range of initial guesses. A backtracking line search is employed to select $\\alpha_k$: starting with $\\alpha_k = 1$, it is successively reduced (e.g., by half) until the condition $\\|F(\\mathbf{x}_k + \\alpha_k \\Delta\\mathbf{x}_k)\\| < \\|F(\\mathbf{x}_k)\\|$ is met, ensuring a decrease in the residual norm at each step.\n\nThe algorithm proceeds as follows:\n1.  Initialize with a guess $\\mathbf{x}_0$. A physically motivated choice is $\\mathbf{x}_0 = [U_n, U_p, 0]^\\top$, corresponding to the equilibrium state.\n2.  For $k=0, 1, 2, \\dots$:\n    a. Evaluate the residual vector $F(\\mathbf{x}_k)$ and its norm $\\|F(\\mathbf{x}_k)\\|$. If the norm is below a specified tolerance $\\epsilon$, the algorithm has converged.\n    b. Evaluate the Jacobian matrix $J(\\mathbf{x}_k)$.\n    c. Solve the linear system $J(\\mathbf{x}_k) \\Delta\\mathbf{x}_k = -F(\\mathbf{x}_k)$ for the update step $\\Delta\\mathbf{x}_k$.\n    d. Perform a backtracking line search to find a suitable damping factor $\\alpha_k$.\n    e. Update the solution: $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\Delta\\mathbf{x}_k$.\n3.  The final iterate $\\mathbf{x}_k$ is the numerical solution for the initial potentials $[\\phi_{s,n}, \\phi_{s,p}, \\phi_{e,p}]^\\top$.\nThe initial conditions to be used in a subsequent time integration are then given by the solved potentials and the specified initial concentrations.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve for consistent initial conditions for all test cases.\n    \"\"\"\n    # Test suite parameters:\n    # (i_app, SOC_n, SOC_p, a_n, a_p, k_n, k_p, r_e, U_n_ref, U_p_ref, beta_n, beta_p)\n    test_cases = [\n        # Case 1 (typical)\n        (0.5, 0.7, 0.4, 1.0, 1.0, 1.0, 1.0, 0.2, 0.1, 4.0, 0.1, 0.1),\n        # Case 2 (near-equilibrium)\n        (0.0, 0.6, 0.6, 1.0, 1.0, 1.0, 1.0, 0.3, 0.15, 3.9, 0.2, 0.2),\n        # Case 3 (high-current)\n        (2.0, 0.9, 0.3, 1.0, 1.0, 1.5, 1.0, 0.5, 0.2, 4.2, 0.15, 0.12),\n    ]\n\n    all_results_flat = []\n\n    for i, case_params in enumerate(test_cases):\n        params = {\n            'i_app': case_params[0],\n            'soc_n': case_params[1],\n            'soc_p': case_params[2],\n            'a_n': case_params[3],\n            'a_p': case_params[4],\n            'k_n': case_params[5],\n            'k_p': case_params[6],\n            'r_e': case_params[7],\n            'U_n_ref': case_params[8],\n            'U_p_ref': case_params[9],\n            'beta_n': case_params[10],\n            'beta_p': case_params[11],\n        }\n\n        # Calculate open-circuit potentials\n        params['U_n'] = _calc_ocp(params['U_n_ref'], params['beta_n'], params['soc_n'])\n        params['U_p'] = _calc_ocp(params['U_p_ref'], params['beta_p'], params['soc_p'])\n\n        # Initial guess for x = [phi_s,n, phi_s,p, phi_e,p]\n        # A good guess is the equilibrium potential state.\n        x0 = np.array([params['U_n'], params['U_p'], 0.0])\n\n        # Solve the nonlinear system using the Newton method\n        x_sol = _newton_solver(params, x0)\n\n        phi_sn_sol, phi_sp_sol, phi_ep_sol = x_sol\n\n        # Collect results for this case in the specified order\n        # [phi_s,n, phi_e,n, phi_s,p, phi_e,p, c_n, c_p]\n        # phi_e,n is 0 by gauge choice. c_n/c_p are the given SOCs.\n        case_results = [\n            phi_sn_sol,\n            0.0,\n            phi_sp_sol,\n            phi_ep_sol,\n            params['soc_n'],\n            params['soc_p'],\n        ]\n        all_results_flat.extend(case_results)\n\n    # Print the flattened list in the required format\n    print(f\"[{','.join(f'{v:.6f}' for v in all_results_flat)}]\")\n\n\ndef _calc_ocp(U_ref, beta, c):\n    \"\"\"Calculates the open-circuit potential using the Nernst-type relation.\"\"\"\n    if not (0 < c < 1):\n        raise ValueError(\"Concentration c must be in the interval (0, 1).\")\n    return U_ref + beta * np.log(c / (1.0 - c))\n\n\ndef _evaluate_F(x, params):\n    \"\"\"\n    Evaluates the residual vector F(x) of the nonlinear system.\n    x = [phi_s,n, phi_s,p, phi_e,p]\n    \"\"\"\n    phi_sn, phi_sp, phi_ep = x\n\n    # Butler-Volmer current densities\n    jn = 2.0 * params['k_n'] * np.sinh((phi_sn - params['U_n']) / 2.0)\n    jp = 2.0 * params['k_p'] * np.sinh((phi_sp - phi_ep - params['U_p']) / 2.0)\n\n    # Residuals\n    F1 = params['a_n'] * jn - params['i_app']\n    F2 = params['a_p'] * jp + params['i_app']\n    F3 = phi_ep - params['r_e'] * params['i_app']\n\n    return np.array([F1, F2, F3])\n\n\ndef _evaluate_J(x, params):\n    \"\"\"\n    Evaluates the Jacobian matrix J(x) of the nonlinear system.\n    x = [phi_s,n, phi_s,p, phi_e,p]\n    \"\"\"\n    phi_sn, phi_sp, phi_ep = x\n\n    # Jacobian components\n    J11 = params['a_n'] * params['k_n'] * np.cosh((phi_sn - params['U_n']) / 2.0)\n\n    common_term_p = params['a_p'] * params['k_p'] * np.cosh((phi_sp - phi_ep - params['U_p']) / 2.0)\n    J22 = common_term_p\n    J23 = -common_term_p\n\n    return np.array([\n        [J11, 0.0, 0.0],\n        [0.0, J22, J23],\n        [0.0, 0.0, 1.0]\n    ])\n\n\ndef _newton_solver(params, x0, tol=1e-10, max_iter=50, max_backtrack=10):\n    \"\"\"\n    Solves F(x)=0 using a damped Newton-Raphson method.\n    \"\"\"\n    x = np.copy(x0).astype(float)\n\n    for _ in range(max_iter):\n        F = _evaluate_F(x, params)\n        norm_F = np.linalg.norm(F)\n\n        if norm_F < tol:\n            return x\n\n        J = _evaluate_J(x, params)\n        if np.linalg.det(J) == 0:\n            raise RuntimeError(\"Newton solver failed: Jacobian is singular.\")\n\n        delta_x = np.linalg.solve(J, -F)\n\n        # Damping via backtracking line search\n        alpha = 1.0\n        for _ in range(max_backtrack):\n            x_new = x + alpha * delta_x\n            norm_F_new = np.linalg.norm(_evaluate_F(x_new, params))\n            if norm_F_new < norm_F:\n                break\n            alpha /= 2.0\n        else: # Loop completed without break\n            raise RuntimeError(\"Newton solver failed: line search did not converge.\")\n\n        x = x_new\n    \n    raise RuntimeError(\"Newton solver failed: maximum iterations reached.\")\n\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "Implicit time integration methods are essential for the stable solution of stiff DAEs found in battery models, but they require solving a large algebraic system at each time step. This practice explores the structure of this system, which arises from applying an implicit Euler step to a battery pack model formulated with Modified Nodal Analysis (MNA). You will learn to identify the resulting saddle-point structure and develop an efficient block-elimination solver, a powerful technique for creating scalable and performant simulators .",
            "id": "3903309",
            "problem": "You are designing an implicit time integrator for a battery pack model assembled using Modified Nodal Analysis (MNA). Your task is to derive and implement the Newton system for a single implicit Euler step of a two-node battery pack Differential-Algebraic Equation (DAE), and to exploit the resulting sparse, symmetric indefinite saddle-point structure to construct an efficient linear solver based on block elimination.\n\nFundamental base:\n- Kirchhoff’s Current Law (KCL): the algebraic sum of currents into a node is zero.\n- Capacitor constitutive law: $i_C = C \\, \\dfrac{dv}{dt}$.\n- Resistor constitutive law: $i_R = \\dfrac{v}{R}$.\n- Nonlinear Faradaic interface current modeled by a hyperbolic sine: $i_F(v) = i_0 \\, \\sinh\\!\\big(\\beta \\, (v - E)\\big)$.\n\nModel setup:\n- There are two dynamic nodes with voltages $v_1$ and $v_2$ measured relative to ground, forming the vector $v = \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$.\n- Capacitors to ground at each node with capacitances $C_1$ and $C_2$, forming the diagonal matrix $C = \\mathrm{diag}(C_1,C_2)$.\n- Internal resistors to ground with resistances $R_1$ at node $1$ and $R_2$ at node $2$.\n- An interconnect resistor between node $1$ and node $2$ with resistance $R_{12}$.\n- Nonlinear Faradaic currents at each node: $i_{F,1}(v_1) = i_{0,1} \\, \\sinh\\!\\big(\\beta \\, (v_1 - E_1)\\big)$ and $i_{F,2}(v_2) = i_{0,2} \\, \\sinh\\!\\big(\\beta \\, (v_2 - E_2)\\big)$.\n- A single ideal voltage source that constrains node $2$ to a specified value $V_{\\mathrm{src}}(t)$; this introduces an algebraic constraint $A \\, v = g(t)$ with $A = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$ and $g(t) = V_{\\mathrm{src}}(t)$, and a corresponding Lagrange multiplier $\\lambda$ representing the source current.\n\nUsing MNA, the semi-explicit DAE can be written in the form\n$$\nC \\, \\dfrac{dv}{dt} + G \\, v + i_F(v) + A^\\top \\lambda = s(t), \\quad A \\, v = g(t),\n$$\nwhere $G \\in \\mathbb{R}^{2 \\times 2}$ is the symmetric conductance matrix assembled from the resistors:\n$$\nG = \\begin{bmatrix}\n\\dfrac{1}{R_1} + \\dfrac{1}{R_{12}} & -\\dfrac{1}{R_{12}} \\\\\n-\\dfrac{1}{R_{12}} & \\dfrac{1}{R_2} + \\dfrac{1}{R_{12}}\n\\end{bmatrix},\n$$\nand $s(t) \\in \\mathbb{R}^2$ is a known source vector (assume $s(t) = 0$ for this problem). The Jacobian of $i_F(v)$ is diagonal:\n$$\nJ_F(v) = \\mathrm{diag}\\!\\Big(i_{0,1} \\beta \\cosh\\!\\big(\\beta (v_1 - E_1)\\big), \\; i_{0,2} \\beta \\cosh\\!\\big(\\beta (v_2 - E_2)\\big)\\Big).\n$$\n\nImplicit Euler step:\nFor a time step of size $\\Delta t$ from time $t_n$ to $t_{n+1}$, denote the known previous state by $v_n$ and the unknown next state by $v_{n+1}$. Discretize the DAE with implicit Euler to obtain two nonlinear equations in $v_{n+1}$ and $\\lambda_{n+1}$.\n\nYour tasks:\n1. Derive the residual equations for the implicit Euler step starting from the fundamental laws and definitions given above, and set up the Newton linearization. Show that the Newton system at an iterate $(v^{(k)}, \\lambda^{(k)})$ has the saddle-point form\n$$\n\\begin{bmatrix}\nM(v^{(k)}) & A^\\top \\\\\nA & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\delta v^{(k)} \\\\\n\\delta \\lambda^{(k)}\n\\end{bmatrix}\n=\n-\n\\begin{bmatrix}\nr_v(v^{(k)}, \\lambda^{(k)}) \\\\\nr_c(v^{(k)})\n\\end{bmatrix},\n$$\nand identify $M(v^{(k)})$, $r_v(\\cdot)$, and $r_c(\\cdot)$ explicitly in terms of $C$, $G$, $J_F(v^{(k)})$, $v_n$, $s(t_{n+1})$, and $g(t_{n+1})$.\n2. Propose an efficient solver that exploits the sparse, symmetric indefinite structure of the Newton matrix. Specifically, use block elimination to form the Schur complement in $\\lambda$ and solve using sparse linear algebra, assuming $M(v^{(k)})$ is symmetric positive definite. Clearly state the sequence of linear solves required to obtain $(\\delta v^{(k)}, \\delta \\lambda^{(k)})$.\n3. Implement a program that, for each test case below, performs Newton iterations for a single implicit Euler time step starting from the initial guess $v^{(0)} = v_n$ and $\\lambda^{(0)} = 0$, stopping when the Euclidean norm of the voltage update satisfies $\\|\\delta v^{(k)}\\|_2 < \\varepsilon$ with tolerance $\\varepsilon = 10^{-12}$ or when a maximum of $50$ iterations is reached. Use the block-elimination solver described in task $2$, with a fallback to a direct sparse solve of the full saddle-point system if the Schur complement becomes ill-conditioned. For each test case, output the final Euclidean norm $\\|v_{n+1} - v_n\\|_2$ of the converged voltage increment. Express the output values in volts (V) as decimal numbers.\n\nTest suite:\n- Case $1$ (happy path): $C_1 = 500 \\text{ F}$, $C_2 = 500 \\text{ F}$, $R_1 = 0.01 \\, \\Omega$, $R_2 = 0.01 \\, \\Omega$, $R_{12} = 0.02 \\, \\Omega$, $i_{0,1} = 2 \\text{ A}$, $i_{0,2} = 2 \\text{ A}$, $\\beta = 10 \\text{ V}^{-1}$, $E_1 = 3.7 \\text{ V}$, $E_2 = 3.7 \\text{ V}$, $V_{\\mathrm{src}}(t_{n+1}) = 3.8 \\text{ V}$, $\\Delta t = 1 \\times 10^{-3} \\text{ s}$, $v_n = \\begin{bmatrix} 3.7 \\\\ 3.8 \\end{bmatrix} \\text{ V}$.\n- Case $2$ (stiff small-step edge): $C_1 = 200 \\text{ F}$, $C_2 = 200 \\text{ F}$, $R_1 = 0.005 \\, \\Omega$, $R_2 = 0.005 \\, \\Omega$, $R_{12} = 0.001 \\, \\Omega$, $i_{0,1} = 5 \\text{ A}$, $i_{0,2} = 5 \\text{ A}$, $\\beta = 20 \\text{ V}^{-1}$, $E_1 = 3.75 \\text{ V}$, $E_2 = 3.75 \\text{ V}$, $V_{\\mathrm{src}}(t_{n+1}) = 3.9 \\text{ V}$, $\\Delta t = 1 \\times 10^{-6} \\text{ s}$, $v_n = \\begin{bmatrix} 3.75 \\\\ 3.9 \\end{bmatrix} \\text{ V}$.\n- Case $3$ (weak coupling boundary): $C_1 = 100 \\text{ F}$, $C_2 = 100 \\text{ F}$, $R_1 = 0.02 \\, \\Omega$, $R_2 = 0.02 \\, \\Omega$, $R_{12} = 1000 \\, \\Omega$, $i_{0,1} = 0.5 \\text{ A}$, $i_{0,2} = 0.5 \\text{ A}$, $\\beta = 5 \\text{ V}^{-1}$, $E_1 = 3.6 \\text{ V}$, $E_2 = 3.6 \\text{ V}$, $V_{\\mathrm{src}}(t_{n+1}) = 3.6 \\text{ V}$, $\\Delta t = 1 \\times 10^{-1} \\text{ s}$, $v_n = \\begin{bmatrix} 3.6 \\\\ 3.6 \\end{bmatrix} \\text{ V}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of the test suite cases, for example, $[r_1, r_2, r_3]$, where $r_k$ is the final Euclidean norm $\\|v_{n+1} - v_n\\|_2$ in volts (V) for case $k$.",
            "solution": "The user has requested the derivation and implementation of a Newton-based implicit Euler solver for a two-node battery pack model. The core tasks are to:\n1.  Derive the Newton system for one implicit Euler step.\n2.  Propose a block-elimination solver for the resulting linear system.\n3.  Implement the solver and run it for three test cases.\n\nThe problem statement has been validated and is found to be scientifically grounded, well-posed, and complete. All necessary physical laws, component models, and parameters are provided. The tasks are mathematically and computationally well-defined.\n\n### Task 1: Derivation of the Newton System\n\nThe system is described by a set of Differential-Algebraic Equations (DAEs) in the Modified Nodal Analysis (MNA) formulation. Let $v(t) \\in \\mathbb{R}^2$ be the vector of node voltages and $\\lambda(t) \\in \\mathbb{R}$ be the Lagrange multiplier for the voltage source constraint.\n\nThe governing DAEs are:\n$$\n\\begin{align*}\nC \\, \\frac{dv}{dt} + G \\, v + i_F(v) + A^\\top \\lambda &= s(t) \\quad &(1a) \\\\\nA \\, v &= g(t) \\quad &(1b)\n\\end{align*}\n$$\nwhere $C$ is the capacitance matrix, $G$ is the conductance matrix, $i_F(v)$ is the vector of nonlinear Faradaic currents, $A$ is the constraint matrix, $\\lambda$ is the current through the voltage source, $s(t)$ is the external current source vector (given as $s(t)=0$), and $g(t)$ is the specified voltage from the source.\n\nWe discretize the time derivative $\\frac{dv}{dt}$ using the implicit Euler method for a time step from $t_n$ to $t_{n+1}$ with step size $\\Delta t = t_{n+1} - t_n$:\n$$\n\\frac{dv}{dt}\\bigg|_{t_{n+1}} \\approx \\frac{v_{n+1} - v_n}{\\Delta t}\n$$\nHere, $v_n = v(t_n)$ is the known voltage vector from the previous time step, and $v_{n+1} = v(t_{n+1})$ is the unknown voltage vector at the current time step. Substituting this into the DAE system (1a) and evaluating all terms at $t_{n+1}$ yields the nonlinear algebraic system for the unknowns $v_{n+1}$ and $\\lambda_{n+1}$:\n$$\n\\begin{align*}\nC \\frac{v_{n+1} - v_n}{\\Delta t} + G v_{n+1} + i_F(v_{n+1}) + A^\\top \\lambda_{n+1} - s(t_{n+1}) &= 0 \\\\\nA v_{n+1} - g(t_{n+1}) &= 0\n\\end{align*}\n$$\nTo solve this nonlinear system, we use Newton's method. Let $(v^{(k)}, \\lambda^{(k)})$ be the $k$-th iterate for the solution $(v_{n+1}, \\lambda_{n+1})$. We define the residual functions:\n$$\n\\begin{align*}\nr_v(v, \\lambda) &= \\frac{C(v - v_n)}{\\Delta t} + Gv + i_F(v) + A^\\top \\lambda - s(t_{n+1}) \\\\\nr_c(v) &= Av - g(t_{n+1})\n\\end{align*}\n$$\nThe Newton update step is defined by solving the linear system $J^{(k)} \\begin{bmatrix} \\delta v^{(k)} \\\\ \\delta \\lambda^{(k)} \\end{bmatrix} = - \\begin{bmatrix} r_v(v^{(k)}, \\lambda^{(k)}) \\\\ r_c(v^{(k)}) \\end{bmatrix}$, where $J^{(k)}$ is the Jacobian of the residual vector $\\begin{bmatrix} r_v \\\\ r_c \\end{bmatrix}$ evaluated at $(v^{(k)}, \\lambda^{(k)})$, and $(\\delta v^{(k)}, \\delta \\lambda^{(k)})$ is the update, such that $v^{(k+1)} = v^{(k)} + \\delta v^{(k)}$ and $\\lambda^{(k+1)} = \\lambda^{(k)} + \\delta \\lambda^{(k)}$.\n\nThe Jacobian matrix $J$ is composed of partial derivatives:\n$$\nJ(v, \\lambda) = \\begin{bmatrix} \\frac{\\partial r_v}{\\partial v} & \\frac{\\partial r_v}{\\partial \\lambda} \\\\ \\frac{\\partial r_c}{\\partial v} & \\frac{\\partial r_c}{\\partial \\lambda} \\end{bmatrix}\n$$\nThe individual blocks are:\n- $\\frac{\\partial r_v}{\\partial v} = \\frac{C}{\\Delta t} + G + \\frac{\\partial i_F(v)}{\\partial v} = \\frac{C}{\\Delta t} + G + J_F(v)$, where $J_F(v)$ is the Jacobian of the Faradaic current.\n- $\\frac{\\partial r_v}{\\partial \\lambda} = A^\\top$\n- $\\frac{\\partial r_c}{\\partial v} = A$\n- $\\frac{\\partial r_c}{\\partial \\lambda} = 0$ (a zero matrix, or scalar $0$ in this case)\n\nThe Newton system at iteration $k$ is therefore:\n$$\n\\begin{bmatrix}\n\\frac{C}{\\Delta t} + G + J_F(v^{(k)}) & A^\\top \\\\\nA & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\delta v^{(k)} \\\\\n\\delta \\lambda^{(k)}\n\\end{bmatrix}\n=\n-\n\\begin{bmatrix}\nr_v(v^{(k)}, \\lambda^{(k)}) \\\\\nr_c(v^{(k)})\n\\end{bmatrix}\n$$\nThis is the required saddle-point form. By comparing with the problem statement's template, we identify:\n- $M(v^{(k)}) = \\frac{C}{\\Delta t} + G + J_F(v^{(k)})$\n- $r_v(v^{(k)}, \\lambda^{(k)}) = \\frac{C}{\\Delta t}(v^{(k)} - v_n) + Gv^{(k)} + i_F(v^{(k)}) + A^\\top \\lambda^{(k)} - s(t_{n+1})$\n- $r_c(v^{(k)}) = Av^{(k)} - g(t_{n+1})$\n\nThe matrix $M(v^{(k)})$ is symmetric because $C$, $G$, and $J_F(v^{(k)})$ are all symmetric. It is also positive definite because $C$ and $J_F$ are diagonal with positive entries, $G$ is positive semi-definite, and $\\Delta t > 0$. The sum is therefore symmetric positive definite (SPD).\n\n### Task 2: Block-Elimination Solver\n\nThe Newton system has a $2 \\times 2$ block structure, commonly known as a Karush-Kuhn-Tucker (KKT) or saddle-point system.\n$$\n\\begin{align*}\nM \\delta v + A^\\top \\delta \\lambda &= -r_v \\quad &(2a) \\\\\nA \\delta v &= -r_c \\quad &(2b)\n\\end{align*}\n$$\nGiven that $M = M(v^{(k)})$ is SPD and thus invertible, we can solve for $\\delta v$ from (2a):\n$$\n\\delta v = M^{-1}(-r_v - A^\\top \\delta \\lambda) \\quad (3)\n$$\nSubstituting this into (2b):\n$$\nA \\big( M^{-1}(-r_v - A^\\top \\delta \\lambda) \\big) = -r_c\n$$\n$$\n-A M^{-1} r_v - (A M^{-1} A^\\top) \\delta \\lambda = -r_c\n$$\nRearranging to solve for the scalar update $\\delta \\lambda$:\n$$\n(A M^{-1} A^\\top) \\delta \\lambda = r_c - A M^{-1} r_v\n$$\nThe term $S = A M^{-1} A^\\top$ is the Schur complement of the system with respect to the block $M$. Since $M$ is SPD and $A$ has full row rank (in this case $A = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\neq 0$), the Schur complement $S$ is also SPD. As it is a $1 \\times 1$ matrix (a scalar), this means $S > 0$.\n\nThe efficient solution procedure, which avoids explicitly forming a large inverse in the general sparse case, is as follows:\n1.  Form the matrix $M(v^{(k)})$.\n2.  Solve the linear system $M z_v = r_v$ for the vector $z_v$.\n3.  Solve the linear system $M z_A = A^\\top$ for the vector $z_A$.\n4.  Compute the Schur complement: $S = A z_A$.\n5.  Solve for the Lagrange multiplier update: $\\delta \\lambda = S^{-1} (r_c - A z_v)$. For a scalar $S$, this is a simple division $\\delta \\lambda = (r_c - A z_v) / S$.\n6.  Back-substitute to find the voltage update: $\\delta v = -z_v - z_A \\delta \\lambda$.\n\nThis method requires two linear solves with the matrix $M$ (which can be factorized once) and scalar/vector operations, making it efficient for large-scale systems where a direct solve on the full indefinite system can be less stable or more expensive. For the given $2 \\times 2$ problem, solving with $M$ is trivial, but this procedure demonstrates the general principle.\n\n### Task 3: Implementation\n\nThe provided Python code implements the Newton's method using the block-elimination (Schur complement) solver derived above. It iterates until the L2-norm of the voltage update, $\\|\\delta v^{(k)}\\|_2$, falls below a tolerance of $\\varepsilon = 10^{-12}$. A fallback to a direct sparse solve of the full $3 \\times 3$ KKT system is included for the case where the Schur complement $S$ is near-zero (ill-conditioned), although this is unlikely given the problem's structure. For each test case, the program calculates and reports the L2-norm of the total voltage change for the time step, $\\|v_{n+1} - v_n\\|_2$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"C1\": 500.0, \"C2\": 500.0, \"R1\": 0.01, \"R2\": 0.01, \"R12\": 0.02,\n            \"i01\": 2.0, \"i02\": 2.0, \"beta\": 10.0, \"E1\": 3.7, \"E2\": 3.7,\n            \"V_src\": 3.8, \"dt\": 1e-3, \"v_n\": np.array([3.7, 3.8]),\n        },\n        {\n            \"C1\": 200.0, \"C2\": 200.0, \"R1\": 0.005, \"R2\": 0.005, \"R12\": 0.001,\n            \"i01\": 5.0, \"i02\": 5.0, \"beta\": 20.0, \"E1\": 3.75, \"E2\": 3.75,\n            \"V_src\": 3.9, \"dt\": 1e-6, \"v_n\": np.array([3.75, 3.9]),\n        },\n        {\n            \"C1\": 100.0, \"C2\": 100.0, \"R1\": 0.02, \"R2\": 0.02, \"R12\": 1000.0,\n            \"i01\": 0.5, \"i02\": 0.5, \"beta\": 5.0, \"E1\": 3.6, \"E2\": 3.6,\n            \"V_src\": 3.6, \"dt\": 0.1, \"v_n\": np.array([3.6, 3.6]),\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_newton_step(params)\n        results.append(f\"{result:.15f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef run_newton_step(params):\n    \"\"\"\n    Performs Newton iterations for a single implicit Euler time step.\n    \n    Args:\n        params (dict): A dictionary containing all the parameters for the simulation.\n\n    Returns:\n        float: The Euclidean norm of the converged voltage increment ||v_{n+1} - v_n||_2.\n    \"\"\"\n    # Unpack parameters\n    C1, C2 = params[\"C1\"], params[\"C2\"]\n    R1, R2, R12 = params[\"R1\"], params[\"R2\"], params[\"R12\"]\n    i01, i02, beta = params[\"i01\"], params[\"i02\"], params[\"beta\"]\n    E1, E2 = params[\"E1\"], params[\"E2\"]\n    V_src, dt, v_n = params[\"V_src\"], params[\"dt\"], params[\"v_n\"]\n    \n    # Constants and constant matrices\n    C = np.diag([C1, C2])\n    G = np.array([\n        [1/R1 + 1/R12, -1/R12],\n        [-1/R12, 1/R2 + 1/R12]\n    ])\n    A = np.array([[0.0, 1.0]])\n    A_T = A.T\n    g = V_src\n    s = np.zeros(2) # s(t) = 0\n    \n    # Newton iteration settings\n    v_k = np.copy(v_n)\n    lambda_k = 0.0\n    max_iter = 50\n    tolerance = 1e-12\n\n    for _ in range(max_iter):\n        v1k, v2k = v_k\n        \n        # Evaluate nonlinear currents and their Jacobian\n        arg1 = beta * (v1k - E1)\n        arg2 = beta * (v2k - E2)\n        \n        # Check for potential overflow in sinh/cosh\n        if np.abs(arg1) > 100 or np.abs(arg2) > 100:\n             # If arguments get too big, Newton is likely diverging.\n             # Terminate and let the max_iter condition handle it.\n             break\n\n        iF = np.array([i01 * np.sinh(arg1), i02 * np.sinh(arg2)])\n        \n        JF_diag = np.array([\n            i01 * beta * np.cosh(arg1),\n            i02 * beta * np.cosh(arg2)\n        ])\n        JF = np.diag(JF_diag)\n        \n        # Calculate residuals\n        r_v = (C @ (v_k - v_n)) / dt + G @ v_k + iF + A_T.flatten() * lambda_k - s\n        r_c = (A @ v_k)[0] - g\n        \n        # Form the (1,1) block of the Newton matrix\n        M = C / dt + G + JF\n        \n        # --- Solve the KKT system ---\n        # Schur Complement: S = A * M^-1 * A^T\n        # For A = [0, 1], S is the (2,2) element of M^-1\n        det_M = M[0, 0] * M[1, 1] - M[0, 1] * M[1, 0]\n        \n        # Use Schur complement by default\n        # The condition for fallback is if Schur complement is ill-conditioned (near zero)\n        if abs(det_M) < 1e-20 or abs(M[0, 0]/det_M) < 1e-14:\n            # Fallback to direct sparse solve of the full KKT system\n            KKT_mat = np.zeros((3, 3))\n            KKT_mat[0:2, 0:2] = M\n            KKT_mat[0:2, 2] = A_T.flatten()\n            KKT_mat[2, 0:2] = A.flatten()\n            KKT_sparse = csr_matrix(KKT_mat)\n            \n            rhs = -np.concatenate([r_v, [r_c]])\n            \n            delta_x = spsolve(KKT_sparse, rhs)\n            delta_v = delta_x[:2]\n            delta_lambda = delta_x[2]\n        else:\n            # Block elimination via Schur complement\n            M_inv = (1.0 / det_M) * np.array([[M[1, 1], -M[0, 1]], [-M[1, 0], M[0, 0]]])\n            S = M_inv[1, 1] # A M^-1 A.T\n\n            # Solve for delta_lambda\n            # delta_lambda = S^-1 * (r_c - A * M^-1 * r_v)\n            z_v = M_inv @ r_v\n            A_z_v = z_v[1] # A @ z_v\n            delta_lambda = (r_c - A_z_v) / S\n            \n            # Solve for delta_v\n            # delta_v = -M^-1 * r_v - M^-1 * A^T * delta_lambda\n            z_A = M_inv @ A_T\n            delta_v = -z_v - z_A.flatten() * delta_lambda\n\n        # Update solution\n        v_k += delta_v\n        lambda_k += delta_lambda\n        \n        # Check for convergence\n        if np.linalg.norm(delta_v) < tolerance:\n            break\n            \n    v_np1 = v_k\n    return np.linalg.norm(v_np1 - v_n)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Realistic battery simulations must account for abrupt operational changes, such as varying loads or switching events, which manifest as discontinuities in the DAE system. This practice addresses the challenge of restarting an integration scheme after such an event. You will implement an algorithm to compute a new, consistent set of initial values by enforcing state continuity and satisfying the system's algebraic constraints and their time derivatives immediately after a jump, mastering a key technique for robust, event-driven simulation .",
            "id": "3903350",
            "problem": "In automated battery design and simulation, implicit integrators such as Backward Differentiation Formula (BDF) require a consistent initialization of all variables at a switching instant when an input undergoes a jump discontinuity. Consider a semi-explicit Differential-Algebraic Equation (DAE) model of a lumped electrochemical interface that captures the split of an applied current into a charge-transfer branch and an electrolyte conduction branch. Let the differential state be the double-layer voltage $x \\equiv V_{\\mathrm{c}}$, and the algebraic variable be the electrolyte potential $z \\equiv \\phi$. The right-hand-side input is the applied current $I(t)$, which is piecewise-constant and has a jump at time $t_0$. The constitutive equations are derived from Kirchhoff’s current law and the capacitor relation and are given by\n$$ C \\,\\dot{V}_{\\mathrm{c}} \\;=\\; \\frac{1}{R_{\\mathrm{ct}}}\\,\\big(\\phi - V_{\\mathrm{c}}\\big), $$\n$$ 0 \\;=\\; I(t) \\;-\\; \\frac{1}{R_{\\mathrm{ct}}}\\,\\big(\\phi - V_{\\mathrm{c}}\\big) \\;-\\; \\frac{1}{R_{\\mathrm{e}}}\\,\\big(\\phi - V_{\\mathrm{ref}}\\big), $$\nwhere $C > 0$ is the double-layer capacitance, $R_{\\mathrm{ct}} > 0$ is the charge-transfer resistance, $R_{\\mathrm{e}} > 0$ is the electrolyte resistance, and the reference potential $V_{\\mathrm{ref}}$ is taken as $0\\,\\mathrm{V}$. The model is a semi-explicit DAE of the form $M\\,\\dot{x} = f(x,z,t)$ and $g(x,z,t)=0$ with $M=C$. When $I(t)$ has a jump at $t_0$, the state $x$ must remain continuous at $t_0$ in the absence of impulsive forcing, while the algebraic variable $z$ may jump to satisfy the algebraic constraint. For the purpose of consistent initialization of an implicit method immediately after the jump, one must compute the right-limit values $x(t_0^+)$, $z(t_0^+)$, and consistent right-limit derivatives $\\dot{x}(t_0^+)$ and $\\dot{z}(t_0^+)$ obtained by differentiating the algebraic constraint.\n\nDesign an algorithm that, given $(C,R_{\\mathrm{ct}},R_{\\mathrm{e}},V_{\\mathrm{c}}(t_0^-),I(t_0^-),I(t_0^+))$, computes the tuple $\\big(\\phi(t_0^+),\\dot{V}_{\\mathrm{c}}(t_0^+),\\dot{\\phi}(t_0^+)\\big)$ by enforcing: (i) continuity of $V_{\\mathrm{c}}$ at $t_0$, (ii) satisfaction of the algebraic constraint at $t_0^+$, and (iii) satisfaction of the time-differentiated algebraic constraint at $t_0^+$ under the assumption that $I(t)$ is right-constant after the jump, so that $\\dot{I}(t_0^+)=0$. Your algorithm should not assume closed-form formulas for the algebraic variable and must be based on solving the nonlinear algebraic equation $g(x,z,t_0^+)=0$ using a robust Newton iteration, followed by evaluation of $\\dot{x}(t_0^+)$ from the differential equation and $\\dot{z}(t_0^+)$ from the linearized differentiated constraint\n$$ g_x(x,z,t)\\,\\dot{x} \\;+\\; g_z(x,z,t)\\,\\dot{z} \\;+\\; g_t(x,z,t) \\;=\\; 0, $$\nwhere $g_x$ and $g_z$ denote partial derivatives with respect to $x$ and $z$, and $g_t$ the explicit time derivative.\n\nAll physical quantities must be expressed in International System of Units (SI): current in amperes $(\\mathrm{A})$, voltage in volts $(\\mathrm{V})$, resistance in ohms $(\\Omega)$, capacitance in farads $(\\mathrm{F})$, and time in seconds $(\\mathrm{s})$. The numerical test suite below specifies parameter values, the pre-jump value $I(t_0^-)$, and the post-jump value $I(t_0^+)$ of the input. For each test case, compute and return the triple $\\big(\\phi(t_0^+),\\dot{V}_{\\mathrm{c}}(t_0^+),\\dot{\\phi}(t_0^+)\\big)$ in SI units as real numbers.\n\nTest suite:\n- Case $1$: $C = 100\\,\\mathrm{F}$, $R_{\\mathrm{ct}} = 10\\,\\Omega$, $R_{\\mathrm{e}} = 1\\,\\Omega$, $V_{\\mathrm{c}}(t_0^-) = 1.0\\,\\mathrm{V}$, $I(t_0^-) = 2.0\\,\\mathrm{A}$, $I(t_0^+) = 5.0\\,\\mathrm{A}$.\n- Case $2$: $C = 50\\,\\mathrm{F}$, $R_{\\mathrm{ct}} = 5\\,\\Omega$, $R_{\\mathrm{e}} = 10^9\\,\\Omega$, $V_{\\mathrm{c}}(t_0^-) = 0.1\\,\\mathrm{V}$, $I(t_0^-) = 0.0\\,\\mathrm{A}$, $I(t_0^+) = -3.0\\,\\mathrm{A}$.\n- Case $3$: $C = 10\\,\\mathrm{F}$, $R_{\\mathrm{ct}} = 10^{-3}\\,\\Omega$, $R_{\\mathrm{e}} = 0.05\\,\\Omega$, $V_{\\mathrm{c}}(t_0^-) = 0.0\\,\\mathrm{V}$, $I(t_0^-) = 0.0\\,\\mathrm{A}$, $I(t_0^+) = 100.0\\,\\mathrm{A}$.\n- Case $4$: $C = 1.0\\,\\mathrm{F}$, $R_{\\mathrm{ct}} = 2.0\\,\\Omega$, $R_{\\mathrm{e}} = 3.0\\,\\Omega$, $V_{\\mathrm{c}}(t_0^-) = 0.5\\,\\mathrm{V}$, $I(t_0^-) = 1.0\\,\\mathrm{A}$, $I(t_0^+) = 1.0\\,\\mathrm{A}$.\n\nYour program must implement the above algorithm and apply it to the four cases. Your program should produce a single line of output containing the results as a comma-separated list of four lists, each inner list ordered as $\\big[\\phi(t_0^+),\\dot{V}_{\\mathrm{c}}(t_0^+),\\dot{\\phi}(t_0^+)\\big]$, all in SI units, enclosed in square brackets. For example, the required format is\n$[[...],[...],[...],[...]]$,\nwhere the dots represent the computed floating-point numbers. The output must be a single line with no additional text.",
            "solution": "The problem requires the design of an algorithm to compute a consistent set of initial values for a Differential-Algebraic Equation (DAE) model of an electrochemical interface immediately following a jump discontinuity in the input current $I(t)$. The required values are the post-jump algebraic variable $\\phi(t_0^+)$, and the post-jump time derivatives of the state and algebraic variables, $\\dot{V}_{\\mathrm{c}}(t_0^+)$ and $\\dot{\\phi}(t_0^+)$.\n\nThe DAE system is given by:\n$$ C \\frac{d V_{\\mathrm{c}}}{dt} = \\frac{1}{R_{\\mathrm{ct}}}\\big(\\phi - V_{\\mathrm{c}}\\big) \\quad \\text{(Differential Equation)} $$\n$$ 0 = I(t) - \\frac{1}{R_{\\mathrm{ct}}}\\big(\\phi - V_{\\mathrm{c}}\\big) - \\frac{1}{R_{\\mathrm{e}}}\\phi \\quad \\text{(Algebraic Constraint)} $$\n\nLet us denote the state variable as $x(t) \\equiv V_{\\mathrm{c}}(t)$ and the algebraic variable as $z(t) \\equiv \\phi(t)$. The DAE is of the semi-explicit form $M\\dot{x} = f(x, z, t)$ and $g(x, z, t) = 0$, where $M=C$, $f(x, z, t) = (z-x)/R_{\\mathrm{ct}}$, and $g(x, z, t) = I(t) - (z-x)/R_{\\mathrm{ct}} - z/R_{\\mathrm{e}}$. For a DAE to be physically consistent, the state variable $x(t)$ must be continuous across any finite jump in the input, unless there is an impulsive forcing (a Dirac delta function), which is not the case here. Conversely, the algebraic variable $z(t)$ is not required to be continuous and will generally jump to a new value to ensure the algebraic constraint is satisfied at $t_0^+$.\n\nThe algorithm to find the consistent post-jump values proceeds in four steps.\n\n**Step 1: Determine the post-jump state variable $V_{\\mathrm{c}}(t_0^+)$**\nThe principle of continuity for state variables dictates that the value of $V_{\\mathrm{c}}(t)$ immediately after the jump must equal its value immediately before the jump.\n$$ V_{\\mathrm{c}}(t_0^+) = V_{\\mathrm{c}}(t_0^-) $$\nThe value $V_{\\mathrm{c}}(t_0^-)$ is provided for each test case.\n\n**Step 2: Determine the post-jump algebraic variable $\\phi(t_0^+)$**\nThe algebraic constraint $g(x, z, t) = 0$ must be satisfied for all time $t$, including at the instant $t_0^+$. We must therefore solve the following equation for $\\phi(t_0^+)$:\n$$ g(V_{\\mathrm{c}}(t_0^+), \\phi(t_0^+), t_0^+) = I(t_0^+) - \\frac{1}{R_{\\mathrm{ct}}}\\big(\\phi(t_0^+) - V_{\\mathrm{c}}(t_0^+)\\big) - \\frac{1}{R_{\\mathrm{e}}}\\phi(t_0^+) = 0 $$\nWhile this is a linear equation in $\\phi(t_0^+)$ and could be solved directly, the problem mandates the use of Newton's method. Let $z_{plus} \\equiv \\phi(t_0^+)$. We want to find the root of the function $h(z_{plus}) = I(t_0^+) - \\frac{1}{R_{\\mathrm{ct}}}(z_{plus} - V_{\\mathrm{c}}(t_0^+)) - \\frac{1}{R_{\\mathrm{e}}}z_{plus}$. The Newton-Raphson iteration is given by:\n$$ z_{k+1} = z_k - \\frac{h(z_k)}{h'(z_k)} $$\nThe derivative $h'(z_{plus})$ with respect to $z_{plus}$ is:\n$$ h'(z_{plus}) = \\frac{\\partial g}{\\partial \\phi} = -\\frac{1}{R_{\\mathrm{ct}}} - \\frac{1}{R_{\\mathrm{e}}} $$\nSince the function $h$ is linear, Newton's method will converge to the exact solution in a single iteration from any initial guess. A physically meaningful initial guess is the pre-jump value $\\phi(t_0^-)$, which can be calculated from the algebraic constraint at $t_0^-$.\n\n**Step 3: Determine the post-jump state derivative $\\dot{V}_{\\mathrm{c}}(t_0^+)$**\nWith $V_{\\mathrm{c}}(t_0^+)$ and $\\phi(t_0^+)$ known, the state derivative $\\dot{V}_{\\mathrm{c}}(t_0^+) \\equiv dV_{\\mathrm{c}}/dt(t_0^+)$ is computed by evaluating the differential equation at $t_0^+$:\n$$ C \\dot{V}_{\\mathrm{c}}(t_0^+) = \\frac{1}{R_{\\mathrm{ct}}}\\big(\\phi(t_0^+) - V_{\\mathrm{c}}(t_0^+)\\big) $$\n$$ \\implies \\dot{V}_{\\mathrm{c}}(t_0^+) = \\frac{1}{C R_{\\mathrm{ct}}}\\big(\\phi(t_0^+) - V_{\\mathrm{c}}(t_0^+)\\big) $$\n\n**Step 4: Determine the post-jump algebraic derivative $\\dot{\\phi}(t_0^+)$**\nTo maintain consistency, the time derivative of the algebraic constraint must also be zero. We differentiate $g(V_{\\mathrm{c}}(t), \\phi(t), t) = 0$ with respect to time using the chain rule:\n$$ \\frac{d g}{d t} = \\frac{\\partial g}{\\partial V_{\\mathrm{c}}} \\frac{d V_{\\mathrm{c}}}{dt} + \\frac{\\partial g}{\\partial \\phi} \\frac{d \\phi}{dt} + \\frac{\\partial g}{\\partial t} = 0 $$\nLet's compute the partial derivatives:\n$$ \\frac{\\partial g}{\\partial V_{\\mathrm{c}}} = \\frac{\\partial}{\\partial V_{\\mathrm{c}}} \\left( I(t) - \\frac{1}{R_{\\mathrm{ct}}}(\\phi - V_{\\mathrm{c}}) - \\frac{1}{R_{\\mathrm{e}}}\\phi \\right) = \\frac{1}{R_{\\mathrm{ct}}} $$\n$$ \\frac{\\partial g}{\\partial \\phi} = \\frac{\\partial}{\\partial \\phi} \\left( I(t) - \\frac{1}{R_{\\mathrm{ct}}}(\\phi - V_{\\mathrm{c}}) - \\frac{1}{R_{\\mathrm{e}}}\\phi \\right) = -\\frac{1}{R_{\\mathrm{ct}}} - \\frac{1}{R_{\\mathrm{e}}} $$\n$$ \\frac{\\partial g}{\\partial t} = \\frac{\\partial}{\\partial t} \\left( I(t) - \\frac{1}{R_{\\mathrm{ct}}}(\\phi - V_{\\mathrm{c}}) - \\frac{1}{R_{\\mathrm{e}}}\\phi \\right) = \\frac{dI}{dt} $$\nThe problem states that the input current $I(t)$ is right-constant after the jump, which means $dI/dt(t_0^+) = 0$. Evaluating the differentiated constraint at $t_0^+$ gives:\n$$ \\frac{1}{R_{\\mathrm{ct}}} \\dot{V}_{\\mathrm{c}}(t_0^+) + \\left(-\\frac{1}{R_{\\mathrm{ct}}} - \\frac{1}{R_{\\mathrm{e}}}\\right) \\dot{\\phi}(t_0^+) + 0 = 0 $$\nSolving for $\\dot{\\phi}(t_0^+) \\equiv d\\phi/dt(t_0^+)$ yields:\n$$ \\dot{\\phi}(t_0^+) = \\frac{1/R_{\\mathrm{ct}}}{1/R_{\\mathrm{ct}} + 1/R_{\\mathrm{e}}} \\dot{V}_{\\mathrm{c}}(t_0^+) $$\nMultiplying the numerator and denominator by $R_{\\mathrm{ct}}R_{\\mathrm{e}}$ gives a simpler form:\n$$ \\dot{\\phi}(t_0^+) = \\frac{R_{\\mathrm{e}}}{R_{\\mathrm{e}} + R_{\\mathrm{ct}}} \\dot{V}_{\\mathrm{c}}(t_0^+) $$\nThis four-step procedure provides the required tuple $(\\phi(t_0^+), \\dot{V}_{\\mathrm{c}}(t_0^+), \\dot{\\phi}(t_0^+))$ and is implemented for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_consistent_initialization(C, R_ct, R_e, Vc_minus, I_minus, I_plus):\n    \"\"\"\n    Computes consistent DAE initialization at a switching instant t_0.\n\n    Args:\n        C (float): Double-layer capacitance (F).\n        R_ct (float): Charge-transfer resistance (Ohm).\n        R_e (float): Electrolyte resistance (Ohm).\n        Vc_minus (float): Pre-jump double-layer voltage Vc(t_0^-) (V).\n        I_minus (float): Pre-jump applied current I(t_0^-) (A).\n        I_plus (float): Post-jump applied current I(t_0^+) (A).\n\n    Returns:\n        list: A list containing [phi(t_0^+), Vc_dot(t_0^+), phi_dot(t_0^+)].\n    \"\"\"\n    # Step 1: Determine Vc(t_0^+)\n    # State variable is continuous across the jump.\n    Vc_plus = Vc_minus\n\n    # Step 2: Determine phi(t_0^+) using Newton's method\n    # The algebraic constraint g(Vc, phi, I) = 0 must hold at t_0^+.\n    # g = I_plus - (phi_plus - Vc_plus)/R_ct - phi_plus/R_e\n    \n    # Define the function for the root-finding and its derivative\n    inv_R_ct = 1.0 / R_ct\n    inv_R_e = 1.0 / R_e\n    \n    def g(phi):\n        return I_plus - (phi - Vc_plus) * inv_R_ct - phi * inv_R_e\n        \n    def g_prime(phi):\n        return -inv_R_ct - inv_R_e\n\n    # Use a reasonable initial guess for the iteration. The pre-jump value\n    # phi(t_0^-) is a good choice.\n    # phi(t_0^-) = (I_minus + Vc_minus/R_ct) / (1/R_ct + 1/R_e)\n    try:\n        phi_guess = (I_minus + Vc_minus * inv_R_ct) / (inv_R_ct + inv_R_e)\n    except ZeroDivisionError:\n        # Handle case where both resistances are infinite, although problem states > 0\n        phi_guess = 0.0\n\n    phi_k = phi_guess\n    \n    # Since the equation is linear, one iteration is sufficient, but a loop\n    # is a more general implementation of Newton's method. We use a fixed\n    # number of iterations which is more than enough for convergence here.\n    for _ in range(5):\n        g_val = g(phi_k)\n        g_prime_val = g_prime(phi_k)\n        \n        # Avoid division by zero if g_prime_val is zero\n        if abs(g_prime_val) < 1e-20:\n            break\n            \n        delta = -g_val / g_prime_val\n        phi_k += delta\n        \n        # Convergence check\n        if abs(delta) < 1e-15:\n            break\n\n    phi_plus = phi_k\n\n    # Step 3: Determine Vc_dot(t_0^+)\n    # From the differential equation: Vc_dot = (1/(C*R_ct)) * (phi - Vc)\n    Vc_dot_plus = (1.0 / (C * R_ct)) * (phi_plus - Vc_plus)\n\n    # Step 4: Determine phi_dot(t_0^+)\n    # From the differentiated algebraic constraint:\n    # phi_dot = (R_e / (R_e + R_ct)) * Vc_dot\n    phi_dot_plus = (R_e / (R_e + R_ct)) * Vc_dot_plus\n\n    return [phi_plus, Vc_dot_plus, phi_dot_plus]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (C, R_ct, R_e, Vc(t0-), I(t0-), I(t0+))\n        (100.0, 10.0, 1.0, 1.0, 2.0, 5.0),\n        (50.0, 5.0, 1e9, 0.1, 0.0, -3.0),\n        (10.0, 1e-3, 0.05, 0.0, 0.0, 100.0),\n        (1.0, 2.0, 3.0, 0.5, 1.0, 1.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        C, R_ct, R_e, Vc_minus, I_minus, I_plus = case\n        result = compute_consistent_initialization(C, R_ct, R_e, Vc_minus, I_minus, I_plus)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The str() function on a list automatically adds brackets and spaces.\n    # The format requirement is [[...],[...]], so we build the string manually.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}