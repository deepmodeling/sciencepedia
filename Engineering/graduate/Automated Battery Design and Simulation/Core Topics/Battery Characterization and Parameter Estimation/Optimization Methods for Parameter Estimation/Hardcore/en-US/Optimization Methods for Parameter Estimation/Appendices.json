{
    "hands_on_practices": [
        {
            "introduction": "Gradient-based optimization is a cornerstone of modern parameter estimation for complex physical models. For dynamic systems like battery equivalent circuit models, a key challenge is the efficient calculation of the objective function's gradient with respect to all model parameters. This practice guides you through implementing reverse-mode automatic differentiation (AD) from first principles, providing a deep, hands-on understanding of the computational engine that powers large-scale optimization. ",
            "id": "3935107",
            "problem": "You are given a single-resistor, single-capacitor Thevenin Equivalent Circuit Model (ECM) of a rechargeable battery, to be simulated in discrete time and made differentiable with respect to a set of parameters. Your task is to design and implement a reverse-mode automatic differentiation algorithm that computes Jacobian-transpose vector products for residuals between simulated terminal voltages and synthetically generated measurements. The Jacobian is taken with respect to ECM parameters, and the vector is a user-specified weighting vector. The computed quantity must use reverse-mode automatic differentiation to obtain $$J(\\theta)^{\\top} v$$ for a differentiable simulator.\n\nFundamental base for the model and simulator:\n- The ECM comprises an ohmic resistance and a single first-order polarization branch. The terminal voltage at time $t$ is defined as $$V_{\\mathrm{term}}(t) = V_{\\mathrm{OCV}}(z(t)) - R_{0} I(t) - V_{1}(t),$$ where $V_{\\mathrm{OCV}}$ is the open-circuit voltage as a function of state of charge $z$, $R_{0}$ is the ohmic resistance, $I(t)$ is the applied current (positive for discharge), and $V_{1}$ is the polarization voltage across the first-order branch.\n- The polarization voltage dynamics are $$\\frac{d V_{1}}{dt} = -\\frac{1}{R_{1} C_{1}} V_{1} + \\frac{1}{C_{1}} I(t),$$ with $R_{1} > 0$ and $C_{1} > 0$.\n- The state of charge evolves according to charge balance $$\\frac{d z}{dt} = -\\frac{I(t)}{Q},$$ where $Q$ is the battery capacity in coulombs.\n\nDiscretization and differentiable simulator:\n- Implement a forward Euler discretization with time step $\\Delta t$:\n$$V_{1,k+1} = V_{1,k} + \\Delta t\\left(-\\frac{1}{R_{1} C_{1}} V_{1,k} + \\frac{1}{C_{1}} I_{k}\\right),$$\n$$z_{k+1} = z_{k} + \\Delta t\\left(-\\frac{I_{k}}{Q}\\right),$$\n$$V_{\\mathrm{term},k} = V_{\\mathrm{OCV}}(z_{k}) - R_{0} I_{k} - V_{1,k}.$$\n- Use a smooth polynomial open-circuit voltage $$V_{\\mathrm{OCV}}(z) = a_{0} + a_{1} z + a_{2} z^{2},$$ with constants $a_{0}$, $a_{1}$, $a_{2}$ provided in the test suite.\n\nResidual mapping and Jacobian-transpose vector product:\n- Define parameters $$\\theta = [R_{0}, R_{1}, C_{1}]$$ in the specified units.\n- For a sequence of $N$ time steps, define residuals $$r_{k}(\\theta) = V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}, \\quad k = 0,1,\\ldots,N-1,$$ where $V^{\\mathrm{meas}}_{k}$ are synthetic measurements generated by simulating the same ECM with known \"true\" parameters $\\theta^{\\mathrm{true}}$.\n- For a given weighting vector $$v \\in \\mathbb{R}^{N},$$ define $$g(\\theta) = \\sum_{k=0}^{N-1} v_{k} r_{k}(\\theta).$$ Using reverse-mode automatic differentiation and the chain rule, compute $$\\nabla_{\\theta} g(\\theta) = J(\\theta)^{\\top} v,$$ where $J(\\theta)$ is the Jacobian of $r(\\theta)$ with respect to $\\theta$.\n\nUnits and physical realism:\n- Use $R_{0}$ and $R_{1}$ in ohms, $C_{1}$ in farads, $I$ in amperes, $Q$ in coulombs, $\\Delta t$ in seconds, $V$ in volts, and $z$ as a unitless fraction in $[0,1]$.\n- All given parameters and inputs are physically plausible and consistent.\n\nAlgorithmic requirement:\n- Implement reverse-mode automatic differentiation by constructing a computational graph of scalar operations and performing backpropagation to accumulate gradients through the discrete-time simulator. Do not use any external automatic differentiation library; instead, implement the chain rule and gradient propagation from first principles.\n- The Jacobian-transpose vector product must be computed as described by $\\nabla_{\\theta} g(\\theta)$.\n\nTest suite:\n- Use the following three test cases. For each case, first generate $V^{\\mathrm{meas}}_{k}$ by simulating the ECM with the \"true\" parameters $\\theta^{\\mathrm{true}}$ and the specified input. Then compute $J(\\theta)^{\\top} v$ at the \"estimate\" parameters $\\theta$.\n\n- Case $1$ (happy path):\n    - $N = 10$, $\\Delta t = 1.0$ s, $Q = 7200$ C, $z_{0} = 0.7$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 5.0 \\sin\\left(\\frac{2\\pi k}{10}\\right)$ A for $k = 0,\\ldots,9$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.012, 0.025, 1800]$.\n    - Estimate parameters: $\\theta = [0.015, 0.020, 2000]$.\n    - Weighting vector $v$ as a linear ramp: $v_{k} = 0.1 + 0.1 k$ for $k = 0,\\ldots,9$.\n\n- Case $2$ (boundary condition with slow polarization):\n    - $N = 12$, $\\Delta t = 0.5$ s, $Q = 7200$ C, $z_{0} = 0.5$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 3.0$ A for $k = 0,\\ldots,11$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.006, 0.009, 12000]$.\n    - Estimate parameters: $\\theta = [0.005, 0.010, 10000]$.\n    - Weighting vector $v$ alternating signs: $v_{k} = 0.5 (-1)^{k}$.\n\n- Case $3$ (edge case with zero current):\n    - $N = 8$, $\\Delta t = 2.0$ s, $Q = 7200$ C, $z_{0} = 0.9$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 0.0$ A for $k = 0,\\ldots,7$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.020, 0.035, 3500]$.\n    - Estimate parameters: $\\theta = [0.020, 0.040, 3000]$.\n    - Weighting vector $v$ all ones: $v_{k} = 1.0$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the concatenation of the three $J(\\theta)^{\\top} v$ vectors (in the order of the cases $1$, $2$, $3$), each vector ordered as $[\\,\\frac{\\partial g}{\\partial R_{0}}, \\frac{\\partial g}{\\partial R_{1}}, \\frac{\\partial g}{\\partial C_{1}}\\,]$.\n- The final output must be a comma-separated list enclosed in square brackets, with each floating-point number rounded to six decimal places (e.g., $\"[x_{1},x_{2},\\ldots,x_{9}]\"$). No units should be included in the output; values are pure numbers in consistent SI units as per the model definition.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in established battery modeling principles (Thevenin Equivalent Circuit Model), mathematically well-posed, objective, and provides a complete, consistent problem statement. The task is to implement a specific, verifiable numerical algorithm (reverse-mode automatic differentiation) from first principles, which is a substantial and well-defined problem in scientific computing.\n\nThe objective is to compute the Jacobian-transpose vector product, $\\nabla_{\\theta} g(\\theta) = J(\\theta)^{\\top} v$, for a scalar function $g(\\theta) = \\sum_{k=0}^{N-1} v_{k} r_{k}(\\theta)$. The parameters are $\\theta = [R_{0}, R_{1}, C_{1}]$, and the residuals are $r_{k}(\\theta) = V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}$. The term $V^{\\mathrm{meas}}_{k}$ is generated using true parameters $\\theta^{\\mathrm{true}}$ and is therefore constant with respect to the estimate parameters $\\theta$. Consequently, its derivative is zero: $\\nabla_{\\theta} V^{\\mathrm{meas}}_{k} = 0$. The gradient calculation simplifies to:\n$$ \\nabla_{\\theta} g(\\theta) = \\nabla_{\\theta} \\left( \\sum_{k=0}^{N-1} v_{k} (V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}) \\right) = \\sum_{k=0}^{N-1} v_{k} \\nabla_{\\theta} V_{\\mathrm{term},k}(\\theta) $$\nThis quantity is computed efficiently using reverse-mode automatic differentiation (AD), also known as the adjoint method or backpropagation. This method involves two main stages: a forward pass to simulate the system and a backward pass to propagate gradients.\n\nThe discrete-time model equations are:\n$$ z_{k+1} = z_{k} - \\frac{\\Delta t}{Q} I_{k} $$\n$$ V_{1,k+1} = V_{1,k} \\left(1 - \\frac{\\Delta t}{R_{1} C_{1}}\\right) + \\frac{\\Delta t}{C_{1}} I_{k} $$\n$$ V_{\\mathrm{term},k} = (a_{0} + a_{1} z_{k} + a_{2} z_{k}^{2}) - R_{0} I_{k} - V_{1,k} $$\nThe initial condition for the polarization voltage, $V_{1,0}$, is not explicitly specified. A standard and physically consistent assumption is that the battery is at rest before the simulation begins, implying no polarization effects. Therefore, we set $V_{1,0} = 0$.\n\n**1. Forward Pass**\nThe system is simulated forward in time from $k=0$ to $k=N-1$ using the estimate parameters $\\theta = [R_{0}, R_{1}, C_{1}]$. During this pass, the time-history of the state variables, $z_k$ and $V_{1,k}$, for $k=0, \\ldots, N$, are computed and stored. These stored values are required for the backward pass.\n\n**2. Backward Pass (Adjoint Method)**\nThe backward pass computes the gradients by propagating sensitivities back in time, from $k=N-1$ to $k=0$. We use the notation $\\bar{x} = \\frac{\\partial g}{\\partial x}$ to represent the adjoint of a variable $x$. The goal is to compute the adjoints of the parameters, $\\bar{R}_{0}$, $\\bar{R}_{1}$, and $\\bar{C}_{1}$. These are initialized to zero and accumulated throughout the pass.\n\nThe process starts from the final time step. The adjoints of the states at the end of the simulation horizon are zero, i.e., $\\bar{z}_{N} = 0$ and $\\bar{V}_{1,N} = 0$, as they do not influence any subsequent calculations that contribute to $g(\\theta)$.\n\nThe algorithm proceeds by iterating backward from $k=N-1$ down to $0$. At each step $k$, we compute the adjoints of the states at that time, $\\bar{z}_{k}$ and $\\bar{V}_{1,k}$, based on the adjoints from the \"future\" step $k+1$. Using the multivariable chain rule, the adjoint update equations are derived:\n\nThe adjoint of state $z_k$ is the sum of its influence on the output at time $k$ and the state at time $k+1$:\n$$ \\bar{z}_{k} = \\frac{\\partial g}{\\partial z_{k}} = \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}}\\frac{\\partial V_{\\mathrm{term},k}}{\\partial z_{k}} + \\frac{\\partial g}{\\partial z_{k+1}}\\frac{\\partial z_{k+1}}{\\partial z_{k}} $$\nFrom the model equations, $\\frac{\\partial g}{\\partial V_{\\mathrm{term},k}} = v_k$, $\\frac{\\partial V_{\\mathrm{term},k}}{\\partial z_{k}} = a_{1} + 2a_{2}z_{k}$, and $\\frac{\\partial z_{k+1}}{\\partial z_{k}} = 1$. This gives:\n$$ \\bar{z}_{k} = v_{k}(a_{1} + 2a_{2}z_{k}) + \\bar{z}_{k+1} $$\n\nSimilarly, for the adjoint of state $V_{1,k}$:\n$$ \\bar{V}_{1,k} = \\frac{\\partial g}{\\partial V_{1,k}} = \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}}\\frac{\\partial V_{\\mathrm{term},k}}{\\partial V_{1,k}} + \\frac{\\partial g}{\\partial V_{1,k+1}}\\frac{\\partial V_{1,k+1}}{\\partial V_{1,k}} $$\nWith $\\frac{\\partial V_{\\mathrm{term},k}}{\\partial V_{1,k}} = -1$ and $\\frac{\\partial V_{1,k+1}}{\\partial V_{1,k}} = 1 - \\frac{\\Delta t}{R_{1}C_{1}}$, we get:\n$$ \\bar{V}_{1,k} = -v_{k} + \\bar{V}_{1,k+1}\\left(1 - \\frac{\\Delta t}{R_{1} C_{1}}\\right) $$\n\nDuring this backward iteration, the gradients with respect to the parameters $\\theta$ are accumulated. The total gradient for a parameter is the sum of its influence across all time steps.\nThe gradient for $R_0$ arises from its direct influence on $V_{\\mathrm{term},k}$:\n$$ \\bar{R}_{0} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}} \\frac{\\partial V_{\\mathrm{term},k}}{\\partial R_{0}} = \\sum_{k=0}^{N-1} v_{k}(-I_{k}) $$\nThe gradients for $R_1$ and $C_1$ arise from their influence on the state transition $V_{1,k} \\to V_{1,k+1}$:\n$$ \\bar{R}_{1} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{1,k+1}} \\frac{\\partial V_{1,k+1}}{\\partial R_{1}} = \\sum_{k=0}^{N-1} \\bar{V}_{1,k+1} \\left( V_{1,k} \\frac{\\Delta t}{R_{1}^{2} C_{1}} \\right) $$\n$$ \\bar{C}_{1} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{1,k+1}} \\frac{\\partial V_{1,k+1}}{\\partial C_{1}} = \\sum_{k=0}^{N-1} \\bar{V}_{1,k+1} \\left( V_{1,k}\\frac{\\Delta t}{R_{1}C_{1}^{2}} - I_{k}\\frac{\\Delta t}{C_{1}^{2}} \\right) $$\n\nBy initializing the parameter adjoints to zero and adding the contribution from each time step $k$ during the backward loop, we efficiently compute the final total gradients $\\bar{R}_{0}, \\bar{R}_{1}, \\bar{C}_{1}$, which form the vector $J(\\theta)^{\\top}v$.",
            "answer": "```python\nimport numpy as np\n\ndef compute_jtvp(params):\n    \"\"\"\n    Computes the Jacobian-transpose vector product J^T v for the battery ECM.\n\n    This function implements reverse-mode automatic differentiation from first principles.\n    It first performs a forward pass to simulate the system states and stores their\n    history. Then, a backward pass propagates gradients back in time to compute\n    the final Jacobian-transpose vector product with respect to the model parameters.\n    \"\"\"\n    N = params['N']\n    dt = params['dt']\n    Q = params['Q']\n    z0 = params['z0']\n    a0, a1, a2 = params['a_coeffs']\n    I_seq = params['I_seq']\n    R0, R1, C1 = params['theta_est']\n    v_weights = params['v_weights']\n    \n    # Per problem description, a resting battery has V1_0 = 0.\n    V1_0 = 0.0\n\n    # --- Forward Pass: Simulate the system dynamics ---\n    z_hist = np.zeros(N + 1)\n    V1_hist = np.zeros(N + 1)\n    z_hist[0] = z0\n    V1_hist[0] = V1_0\n\n    # Pre-calculate factors for efficiency\n    if R1 > 0 and C1 > 0:\n        V1_factor = 1 - dt / (R1 * C1)\n    else:\n        # Handle potential division by zero, although problem constraints prevent this.\n        V1_factor = 1.0\n\n    for k in range(N):\n        z_hist[k+1] = z_hist[k] - (dt / Q) * I_seq[k]\n        V1_hist[k+1] = V1_hist[k] * V1_factor + (dt / C1) * I_seq[k]\n\n    # --- Backward Pass: Propagate gradients (adjoints) ---\n    # Initialize parameter gradients (adjoints)\n    R0_bar = 0.0\n    R1_bar = 0.0\n    C1_bar = 0.0\n\n    # Initialize state adjoints for step k+1 (starting with t=N, they are 0)\n    z_bar_next = 0.0\n    V1_bar_next = 0.0\n\n    # Loop backward in time from k = N-1 down to 0\n    for k in range(N - 1, -1, -1):\n        # Retrieve values from the forward pass history\n        z_k = z_hist[k]\n        V1_k = V1_hist[k]\n        I_k = I_seq[k]\n        v_k = v_weights[k]\n\n        # --- Accumulate gradients for parameters for step k ---\n\n        # 1. Gradient for R0 (from V_term,k)\n        # d(g)/d(R0) += d(g)/d(V_term,k) * d(V_term,k)/d(R0)\n        # The first term is v_k, the second is -I_k.\n        R0_bar += -v_k * I_k\n\n        # 2. Gradients for R1 and C1 (from V1_{k+1})\n        # d(g)/d(R1) += d(g)/d(V1_{k+1}) * d(V1_{k+1})/d(R1)\n        # The first term is V1_bar_next.\n        if R1 > 0 and C1 > 0:\n            # Partial derivative of V1_{k+1} w.r.t. R1\n            dV1kp1_dR1 = V1_k * dt / (R1**2 * C1)\n            R1_bar += V1_bar_next * dV1kp1_dR1\n            \n            # Partial derivative of V1_{k+1} w.r.t. C1\n            dV1kp1_dC1 = V1_k * dt / (R1 * C1**2) - I_k * dt / C1**2\n            C1_bar += V1_bar_next * dV1kp1_dC1\n\n        # --- Update state adjoints for the next backward step (k-1) ---\n\n        # 1. Adjoint for z_k\n        # d(g)/d(z_k) = d(g)/d(V_term,k)*d(V_term,k)/d(z_k) + d(g)/d(z_{k+1})*d(z_{k+1})/d(z_k)\n        dz_bar_k = v_k * (a1 + 2 * a2 * z_k) + z_bar_next\n\n        # 2. Adjoint for V1_k\n        # d(g)/d(V1_k) = d(g)/d(V_term,k)*d(V_term,k)/d(V1_k) + d(g)/d(V1_{k+1})*d(V1_{k+1})/d(V1_k)\n        dV1_bar_k = -v_k + V1_bar_next * V1_factor\n        \n        # Propagate adjoints to the next iteration\n        z_bar_next = dz_bar_k\n        V1_bar_next = dV1_bar_k\n\n    return [R0_bar, R1_bar, C1_bar]\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the solver for each, and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 10, \"dt\": 1.0, \"Q\": 7200.0, \"z0\": 0.7, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.array([5.0 * np.sin(2 * np.pi * k / 10) for k in range(10)]),\n            \"theta_est\": (0.015, 0.020, 2000.0),\n            \"v_weights\": np.array([0.1 + 0.1 * k for k in range(10)])\n        },\n        {\n            \"N\": 12, \"dt\": 0.5, \"Q\": 7200.0, \"z0\": 0.5, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.full(12, 3.0),\n            \"theta_est\": (0.005, 0.010, 10000.0),\n            \"v_weights\": np.array([0.5 * (-1)**k for k in range(12)])\n        },\n        {\n            \"N\": 8, \"dt\": 2.0, \"Q\": 7200.0, \"z0\": 0.9, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.zeros(8),\n            \"theta_est\": (0.020, 0.040, 3000.0),\n            \"v_weights\": np.ones(8)\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_vector = compute_jtvp(case)\n        all_results.extend(result_vector)\n\n    # Format the final output string as specified\n    formatted_results = [f'{val:.6f}' for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After implementing a complex numerical routine like an adjoint-based gradient solver, rigorous verification is essential to ensure the optimizer receives correct information. The Taylor remainder test is a powerful technique for this, checking if the error of a first-order approximation shrinks quadratically as expected, which confirms the gradient's accuracy. This exercise provides hands-on practice with this fundamental verification method, a critical skill for developing reliable scientific and optimization software. ",
            "id": "3935080",
            "problem": "A verification task for adjoint-based gradient computation is embedded in a least-squares parameter estimation problem for a single-resistor single-capacitor model of a lithium-ion cell. The forward model uses a single resistance in series with a parallel resistor-capacitor branch to represent transient polarization. The terminal voltage prediction under a constant discharge current is modeled as\n$$\nV_{\\text{model}}(R_0,R_1) \\,=\\, V_{\\text{oc}} \\,-\\, I\\,R_0 \\,-\\, I\\,R_1\\Big(1 - \\exp\\big(-t/(R_1 C_1)\\big)\\Big),\n$$\nwhere $R_0$ and $R_1$ are the ohmic and polarization resistances, respectively, $C_1$ is the polarization capacitance, $I$ is the applied current (positive for discharge), $t$ is the sampling time, and $V_{\\text{oc}}$ is the open-circuit voltage. The parameter vector is $\\theta \\,=\\, (R_0,R_1)$. The scalar residual is\n$$\nf(\\theta) \\,=\\, V_{\\text{model}}(\\theta) \\,-\\, V_{\\text{meas}},\n$$\nand the least-squares objective is\n$$\nJ(\\theta) \\,=\\, \\tfrac{1}{2}\\,f(\\theta)^2.\n$$\n\nYou are given the constants $V_{\\text{oc}} = 3.7$ V, $I = 2$ A, $t = 0.5$ s, and $C_1 = 100$ F. Consider the nominal parameter $\\theta_0=(R_0,R_1)=(0.005,\\,0.01)$ in ohms. The measured voltage is taken to be exactly the model prediction at $\\theta_0$, that is,\n$$\nV_{\\text{meas}} \\,=\\, V_{\\text{model}}(\\theta_0).\n$$\nAn adjoint-based implementation in the code returns the gradient of $J$ at $\\theta_0$, denoted $g_{\\text{adj}}$, which, by construction, coincides with the exact gradient at $\\theta_0$. To verify this gradient via a Taylor remainder test, choose the perturbation direction\n$$\np \\,=\\, (1,\\,1),\n$$\nand define the Taylor remainder function\n$$\nR(h) \\,=\\, \\big|\\,J(\\theta_0 + h\\,p) \\,-\\, J(\\theta_0) \\,-\\, h\\, g_{\\text{adj}}^{\\top} p\\,\\big|, \\qquad h \\in \\mathbb{R}.\n$$\n\nStarting from fundamental definitions and without invoking pre-derived verification formulas, derive from first principles the limit\n$$\nC \\,=\\, \\lim_{h \\to 0}\\,\\frac{R(h)}{h^2},\n$$\nin terms of the problem data, and then evaluate it numerically using the provided constants and $\\theta_0$. Express the final coefficient $C$ in V$^2$ and round your answer to four significant figures.",
            "solution": "The problem asks for the derivation and evaluation of the limit $C \\,=\\, \\lim_{h \\to 0}\\,\\frac{R(h)}{h^2}$, where $R(h)$ is the Taylor remainder for the objective function $J(\\theta)$. We will first derive an analytical expression for $C$ from first principles and then substitute the given numerical values.\n\nThe Taylor remainder function is given by\n$$R(h) \\,=\\, \\big|\\,J(\\theta_0 + h\\,p) \\,-\\, J(\\theta_0) \\,-\\, h\\, g_{\\text{adj}}^{\\top} p\\,\\big|$$\nTo analyze this expression in the limit $h \\to 0$, we consider the Taylor expansion of the function $J(\\theta)$ around the point $\\theta_0$ in the direction of $p$. Let $\\Phi(h) = J(\\theta_0 + h p)$. The Taylor expansion of $\\Phi(h)$ around $h=0$ is\n$$\\Phi(h) \\,=\\, \\Phi(0) \\,+\\, h\\,\\Phi'(0) \\,+\\, \\frac{h^2}{2}\\Phi''(0) \\,+\\, O(h^3)$$\nThe terms in this expansion correspond to evaluations of $J$ and its derivatives at $\\theta_0$:\n1.  $\\Phi(0) \\,=\\, J(\\theta_0)$\n2.  By the chain rule, $\\Phi'(h) \\,=\\, \\frac{d}{dh} J(\\theta_0 + h p) \\,=\\, \\nabla J(\\theta_0 + h p)^{\\top} p$. Evaluating at $h=0$, we get $\\Phi'(0) \\,=\\, \\nabla J(\\theta_0)^{\\top} p$.\n3.  Similarly, $\\Phi''(h) \\,=\\, \\frac{d}{dh} \\left(\\nabla J(\\theta_0 + h p)^{\\top} p\\right) \\,=\\, p^{\\top} H_J(\\theta_0 + h p)\\,p$, where $H_J$ is the Hessian matrix of $J$. At $h=0$, we have $\\Phi''(0) \\,=\\, p^{\\top} H_J(\\theta_0)\\,p$.\n\nSubstituting these into the expansion gives:\n$$J(\\theta_0 + h p) \\,=\\, J(\\theta_0) \\,+\\, h\\,\\nabla J(\\theta_0)^{\\top} p \\,+\\, \\frac{h^2}{2} p^{\\top} H_J(\\theta_0)\\,p \\,+\\, O(h^3)$$\nThe problem states that $g_{\\text{adj}}$ is the exact gradient of $J$ at $\\theta_0$, so $g_{\\text{adj}} = \\nabla J(\\theta_0)$. Substituting this and the Taylor expansion into the definition of $R(h)$:\n$$R(h) \\,=\\, \\left| \\left( J(\\theta_0) \\,+\\, h\\,\\nabla J(\\theta_0)^{\\top} p \\,+\\, \\frac{h^2}{2} p^{\\top} H_J(\\theta_0)\\,p \\,+\\, O(h^3) \\right) \\,-\\, J(\\theta_0) \\,-\\, h\\,\\nabla J(\\theta_0)^{\\top} p \\right|$$\n$$R(h) \\,=\\, \\left| \\frac{h^2}{2} p^{\\top} H_J(\\theta_0)\\,p \\,+\\, O(h^3) \\right|$$\nNow we can evaluate the limit for $C$:\n$$C \\,=\\, \\lim_{h \\to 0}\\,\\frac{R(h)}{h^2} \\,=\\, \\lim_{h \\to 0}\\,\\frac{\\left| \\frac{h^2}{2} p^{\\top} H_J(\\theta_0)\\,p \\,+\\, O(h^3) \\right|}{h^2} \\,=\\, \\lim_{h \\to 0}\\,\\left| \\frac{1}{2} p^{\\top} H_J(\\theta_0)\\,p \\,+\\, O(h) \\right|$$\n$$C \\,=\\, \\left| \\frac{1}{2} p^{\\top} H_J(\\theta_0)\\,p \\right|$$\nFor a least-squares problem, the Hessian is positive semi-definite near a minimum, so we can drop the absolute value, assuming $p^{\\top} H_J(\\theta_0)\\,p \\ge 0$.\n$$C \\,=\\, \\frac{1}{2} p^{\\top} H_J(\\theta_0)\\,p$$\nNext, we must determine the Hessian $H_J(\\theta_0)$. The objective function is $J(\\theta) \\,=\\, \\frac{1}{2}f(\\theta)^2$.\nThe gradient is $\\nabla J(\\theta) \\,=\\, f(\\theta) \\nabla f(\\theta)$.\nThe Hessian is found by differentiating the gradient:\n$$H_J(\\theta) \\,=\\, \\nabla\\left(f(\\theta)\\nabla f(\\theta)\\right) \\,=\\, \\nabla f(\\theta) \\nabla f(\\theta)^{\\top} \\,+\\, f(\\theta) H_f(\\theta)$$\nwhere $H_f$ is the Hessian of the residual function $f(\\theta)$.\n\nA critical piece of information is that $V_{\\text{meas}} \\,=\\, V_{\\text{model}}(\\theta_0)$. This implies that the residual at the nominal parameter $\\theta_0$ is zero:\n$$f(\\theta_0) \\,=\\, V_{\\text{model}}(\\theta_0) \\,-\\, V_{\\text{meas}} \\,=\\, 0$$\nThis simplifies the gradient and Hessian at $\\theta_0$ considerably:\n$$\\nabla J(\\theta_0) \\,=\\, f(\\theta_0) \\nabla f(\\theta_0) \\,=\\, 0 \\cdot \\nabla f(\\theta_0) \\,=\\, \\mathbf{0}$$\n$$H_J(\\theta_0) \\,=\\, \\nabla f(\\theta_0) \\nabla f(\\theta_0)^{\\top} \\,+\\, f(\\theta_0) H_f(\\theta_0) \\,=\\, \\nabla f(\\theta_0) \\nabla f(\\theta_0)^{\\top}$$\nThe expression for $C$ becomes:\n$$C \\,=\\, \\frac{1}{2} p^{\\top} \\left( \\nabla f(\\theta_0) \\nabla f(\\theta_0)^{\\top} \\right) p \\,=\\, \\frac{1}{2} \\left( p^{\\top} \\nabla f(\\theta_0) \\right) \\left( \\nabla f(\\theta_0)^{\\top} p \\right) \\,=\\, \\frac{1}{2} \\left( p^{\\top} \\nabla f(\\theta_0) \\right)^2$$\nWe now need to compute the gradient of the residual function, $\\nabla f(\\theta)$, and evaluate it at $\\theta_0 = (R_0, R_1) = (0.005, 0.01)$. The residual is:\n$$f(R_0, R_1) \\,=\\, V_{\\text{oc}} \\,-\\, I R_0 \\,-\\, I R_1 \\left(1 - \\exp\\left(-\\frac{t}{R_1 C_1}\\right)\\right) \\,-\\, V_{\\text{meas}}$$\nThe components of the gradient $\\nabla f = \\left( \\frac{\\partial f}{\\partial R_0}, \\frac{\\partial f}{\\partial R_1} \\right)^{\\top}$ are:\n$$\\frac{\\partial f}{\\partial R_0} \\,=\\, -I$$\n$$\\frac{\\partial f}{\\partial R_1} \\,=\\, -I \\frac{\\partial}{\\partial R_1} \\left[ R_1 - R_1 \\exp\\left(-\\frac{t}{R_1 C_1}\\right) \\right] \\,=\\, -I \\left[ 1 - \\left( \\exp\\left(-\\frac{t}{R_1 C_1}\\right) + R_1 \\exp\\left(-\\frac{t}{R_1 C_1}\\right) \\frac{t}{R_1^2 C_1} \\right) \\right]$$\n$$\\frac{\\partial f}{\\partial R_1} \\,=\\, -I \\left[ 1 - \\left( 1 + \\frac{t}{R_1 C_1} \\right) \\exp\\left(-\\frac{t}{R_1 C_1}\\right) \\right]$$\nNow we evaluate these derivatives at $\\theta_0$ using the given constants: $I = 2$ A, $t = 0.5$ s, $C_1 = 100$ F, and $R_1 = 0.01$ $\\Omega$.\nThe argument of the exponential is $\\frac{t}{R_1 C_1} = \\frac{0.5}{0.01 \\times 100} = \\frac{0.5}{1} = 0.5$.\n$$\\left.\\frac{\\partial f}{\\partial R_0}\\right|_{\\theta_0} \\,=\\, -2$$\n$$\\left.\\frac{\\partial f}{\\partial R_1}\\right|_{\\theta_0} \\,=\\, -2 \\left[ 1 - (1 + 0.5) \\exp(-0.5) \\right] \\,=\\, -2 \\left[ 1 - 1.5 \\exp(-0.5) \\right]$$\nSo, the gradient of the residual at $\\theta_0$ is:\n$$\\nabla f(\\theta_0) \\,=\\, \\begin{pmatrix} -2 \\\\ -2(1 - 1.5 \\exp(-0.5)) \\end{pmatrix}$$\nThe perturbation direction is $p = (1, 1)^{\\top}$. We can now compute the dot product $p^{\\top} \\nabla f(\\theta_0)$:\n$$p^{\\top} \\nabla f(\\theta_0) \\,=\\, 1 \\cdot (-2) + 1 \\cdot \\left(-2(1 - 1.5 \\exp(-0.5))\\right)$$\n$$p^{\\top} \\nabla f(\\theta_0) \\,=\\, -2 - 2(1 - 1.5 \\exp(-0.5)) \\,=\\, -2 - 2 + 3 \\exp(-0.5) \\,=\\, 3 \\exp(-0.5) - 4$$\nFinally, we substitute this into the expression for $C$:\n$$C \\,=\\, \\frac{1}{2} \\left( 3 \\exp(-0.5) - 4 \\right)^2$$\nNow we perform the numerical evaluation:\n$$C \\,=\\, \\frac{1}{2} \\left( 3 \\times 0.6065306597... - 4 \\right)^2$$\n$$C \\,=\\, \\frac{1}{2} \\left( 1.819591979... - 4 \\right)^2$$\n$$C \\,=\\, \\frac{1}{2} \\left( -2.18040802... \\right)^2$$\n$$C \\,=\\, \\frac{1}{2} \\left( 4.75418140... \\right)$$\n$$C \\,=\\, 2.3770907...$$\nThe units of $J$ are V$^2$. The parameter $h$ is dimensionless. The coefficient $C$ thus has units of V$^2$. Rounding the result to four significant figures, we get $2.377$.",
            "answer": "$$\\boxed{2.377}$$"
        },
        {
            "introduction": "A robust parameter estimation workflow requires more than just an efficient optimizer; it needs the intelligence to know when to stop. Running an optimization for too few iterations yields a suboptimal model, while running it for too long risks overfitting to the training data, harming the model's ability to generalize. This practice explores the design of practical stopping criteria that balance optimization convergence with the prevention of overfitting by using a validation dataset.  You will learn to evaluate sophisticated rules that incorporate metrics like gradient norms, validation loss trends, and generalization gaps.",
            "id": "3935068",
            "problem": "A lithium-ion cell is modeled in automated simulation by a physics-based electrochemical surrogate that enforces conservation of mass and charge, Fickian diffusion, Ohm's law, and Butlerâ€“Volmer interfacial kinetics. The simulator predicts terminal voltage as a function of time, denoted by $V_{\\text{sim}}(\\boldsymbol{\\theta};t)$, where $\\boldsymbol{\\theta}\\in\\mathbb{R}^m$ is a vector of model parameters to be estimated (such as diffusion coefficients, reaction rate constants, and conductivity terms). The data consist of two disjoint experimental sequences: a training set $\\mathcal{D}_{\\text{train}}=\\{(t_i,I_i,V_{\\text{meas}}(t_i))\\}_{i=1}^{N_{\\text{train}}}$ and a validation set $\\mathcal{D}_{\\text{val}}=\\{(s_j,J_j,V_{\\text{meas}}(s_j))\\}_{j=1}^{N_{\\text{val}}}$, each comprising time stamps, applied current profiles, and measured voltages. Measurement noise on voltage is modeled as zero-mean Gaussian with variance $\\sigma_V^2$, which is estimated from repeated calibration pulses. Parameter estimation is posed as empirical risk minimization with a noise-normalized mean-squared error,\n$$\nL_{\\text{train}}(\\boldsymbol{\\theta})=\\frac{1}{N_{\\text{train}}}\\sum_{i=1}^{N_{\\text{train}}}\\frac{\\big(V_{\\text{sim}}(\\boldsymbol{\\theta};t_i)-V_{\\text{meas}}(t_i)\\big)^2}{\\sigma_V^2},\\quad\nL_{\\text{val}}(\\boldsymbol{\\theta})=\\frac{1}{N_{\\text{val}}}\\sum_{j=1}^{N_{\\text{val}}}\\frac{\\big(V_{\\text{sim}}(\\boldsymbol{\\theta};s_j)-V_{\\text{meas}}(s_j)\\big)^2}{\\sigma_V^2}.\n$$\nAn iterative gradient-based optimizer generates a sequence $\\{\\boldsymbol{\\theta}_k\\}_{k\\geq 0}$ with associated quantities $g(k)=\\|\\nabla L_{\\text{train}}(\\boldsymbol{\\theta}_k)\\|_2$ (the training gradient norm), $d_{\\theta}(k)=\\|\\boldsymbol{\\theta}_k-\\boldsymbol{\\theta}_{k-1}\\|_2$ (the parameter change norm), and the generalization gap $G(k)=L_{\\text{val}}(\\boldsymbol{\\theta}_k)-L_{\\text{train}}(\\boldsymbol{\\theta}_k)$. To mitigate sensitivity to high-frequency fluctuations in $L_{\\text{val}}$, define a moving average $\\bar{L}_{\\text{val}}(k)$ over a window of $w$ recent epochs, and let $p$ be a patience parameter that counts consecutive epochs with insufficient validation improvement. Consider that the primary goals are to (i) ensure optimization convergence toward a stationary point of the training objective and (ii) avoid overfitting by detecting when validation performance ceases to improve or degrades beyond what is explainable by measurement noise. A noise-aware margin $\\gamma$ is set from the validation distribution of $G(k)$ under resampling (e.g., via bootstrapping), interpreted as a high quantile of the null variability due to noise.\n\nWhich stopping rule best balances optimization convergence with avoidance of overfitting, under the assumptions above?\n\nA. Stop at epoch $k$ if $g(k)\\leq \\varepsilon_g$ and the average rate of decrease of $L_{\\text{train}}(\\boldsymbol{\\theta}_\\ell)$ over the last $p$ epochs is below a tolerance $\\eta$; ignore validation signals entirely.\n\nB. Stop at the earliest epoch $k$ such that $L_{\\text{val}}(\\boldsymbol{\\theta}_k)$ exceeds its previous minimum by at least $\\eta$, regardless of $g(k)$ or $d_{\\theta}(k)$; do not smooth $L_{\\text{val}}$ and do not consider the generalization gap $G(k)$.\n\nC. Stop at epoch $k$ if $g(k)\\geq \\varepsilon_g$ while $L_{\\text{val}}(\\boldsymbol{\\theta}_k)$ is still decreasing; rely on the decrease of $L_{\\text{val}}$ to indicate progress and accept a large gradient to avoid premature termination.\n\nD. Stop at epoch $k$ when both a convergence indicator and a noise-aware overfitting indicator are satisfied, namely:\n- $g(k)\\leq \\varepsilon_g$ or $d_{\\theta}(k)\\leq \\varepsilon_{\\theta}$, and\n- for $p$ consecutive epochs, the smoothed validation metric shows no significant improvement, i.e., $\\bar{L}_{\\text{val}}(k)-\\bar{L}_{\\text{val}}(k-p)\\geq \\eta\\,\\bar{L}_{\\text{val}}(k-p)$, and\n- the generalization gap is larger than a noise margin, i.e., $G(k)\\geq \\gamma$,\nwith $\\eta>0$, $\\varepsilon_g>0$, $\\varepsilon_{\\theta}>0$, and $\\gamma$ set by resampling on $\\mathcal{D}_{\\text{val}}$ to reflect the variability due to $\\sigma_V^2$.\n\nSelect the single best choice.",
            "solution": "The problem asks to identify the best stopping rule that balances two goals: (i) ensuring convergence toward a stationary point of the training objective and (ii) avoiding overfitting by monitoring validation performance. A robust rule should use the sophisticated tools provided: smoothed validation loss ($\\bar{L}_{\\text{val}}$), a patience parameter ($p$), and a statistically-derived noise margin ($\\gamma$).\n\nLet's analyze the options:\n\n**A.** This rule only considers the training loss and its gradient. By ignoring the validation set entirely, it fails to address the second primary goal of avoiding overfitting. An optimizer could converge to a model that fits the training data perfectly but generalizes poorly.\n\n**B.** This is a naive early stopping rule. It stops at the earliest sign of validation loss increase, without smoothing or a patience window. This makes it highly sensitive to noise and prone to premature termination, stopping before the best possible model has been found. It ignores the robust mechanisms provided in the problem statement.\n\n**C.** This rule's logic is inverted. It suggests stopping when the optimizer has *not* converged (gradient is large) and the model is still *improving* on the validation set. This is precisely when training should continue. Following this rule would lead to prematurely stopping and a suboptimal model.\n\n**D.** This rule provides a comprehensive and robust criterion by combining conditions for both convergence and overfitting. It stops only when:\n1.  **Convergence is met:** The optimizer has slowed down, indicated by a small training gradient norm ($g(k) \\leq \\varepsilon_g$) or a small parameter update ($d_{\\theta}(k) \\leq \\varepsilon_{\\theta}$). This satisfies Goal (i).\n2.  **Overfitting is confirmed:** This is checked with two robust conditions:\n    *   The smoothed validation loss has shown no significant improvement (or has degraded) over a patience window `p`. This uses smoothing and patience to avoid being fooled by noise.\n    *   The generalization gap $G(k)$ is larger than the statistically significant noise margin $\\gamma$. This confirms that the difference between training and validation performance is not just a statistical fluke.\n\nBy requiring that the optimizer has first converged *and* that there is strong, statistically sound evidence of overfitting, this rule effectively balances the two conflicting goals. It avoids stopping prematurely while still preventing the model from degrading due to overfitting. Therefore, it is the best choice.",
            "answer": "$$\\boxed{D}$$"
        }
    ]
}