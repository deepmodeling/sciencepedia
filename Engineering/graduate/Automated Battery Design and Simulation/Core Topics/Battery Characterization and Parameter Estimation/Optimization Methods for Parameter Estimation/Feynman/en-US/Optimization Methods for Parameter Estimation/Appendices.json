{
    "hands_on_practices": [
        {
            "introduction": "Gradient-based optimization is the workhorse of modern parameter estimation, but how do we efficiently compute gradients for a model that is a complex, time-dependent simulation? This exercise takes you under the hood to implement the adjoint method, a powerful application of reverse-mode automatic differentiation. By building this gradient computation engine from first principles for a battery equivalent circuit model, you will gain a foundational skill for tackling large-scale estimation problems where performance is critical. ",
            "id": "3935107",
            "problem": "You are given a single-resistor, single-capacitor Thevenin Equivalent Circuit Model (ECM) of a rechargeable battery, to be simulated in discrete time and made differentiable with respect to a set of parameters. Your task is to design and implement a reverse-mode automatic differentiation algorithm that computes Jacobian-transpose vector products for residuals between simulated terminal voltages and synthetically generated measurements. The Jacobian is taken with respect to ECM parameters, and the vector is a user-specified weighting vector. The computed quantity must use reverse-mode automatic differentiation to obtain $$J(\\theta)^{\\top} v$$ for a differentiable simulator.\n\nFundamental base for the model and simulator:\n- The ECM comprises an ohmic resistance and a single first-order polarization branch. The terminal voltage at time $t$ is defined as $$V_{\\mathrm{term}}(t) = V_{\\mathrm{OCV}}(z(t)) - R_{0} I(t) - V_{1}(t),$$ where $V_{\\mathrm{OCV}}$ is the open-circuit voltage as a function of state of charge $z$, $R_{0}$ is the ohmic resistance, $I(t)$ is the applied current (positive for discharge), and $V_{1}$ is the polarization voltage across the first-order branch.\n- The polarization voltage dynamics are $$\\frac{d V_{1}}{dt} = -\\frac{1}{R_{1} C_{1}} V_{1} + \\frac{1}{C_{1}} I(t),$$ with $R_{1} > 0$ and $C_{1} > 0$.\n- The state of charge evolves according to charge balance $$\\frac{d z}{dt} = -\\frac{I(t)}{Q},$$ where $Q$ is the battery capacity in coulombs.\n\nDiscretization and differentiable simulator:\n- Implement a forward Euler discretization with time step $\\Delta t$:\n$$V_{1,k+1} = V_{1,k} + \\Delta t\\left(-\\frac{1}{R_{1} C_{1}} V_{1,k} + \\frac{1}{C_{1}} I_{k}\\right),$$\n$$z_{k+1} = z_{k} + \\Delta t\\left(-\\frac{I_{k}}{Q}\\right),$$\n$$V_{\\mathrm{term},k} = V_{\\mathrm{OCV}}(z_{k}) - R_{0} I_{k} - V_{1,k}.$$\n- Use a smooth polynomial open-circuit voltage $$V_{\\mathrm{OCV}}(z) = a_{0} + a_{1} z + a_{2} z^{2},$$ with constants $a_{0}$, $a_{1}$, $a_{2}$ provided in the test suite.\n\nResidual mapping and Jacobian-transpose vector product:\n- Define parameters $$\\theta = [R_{0}, R_{1}, C_{1}]$$ in the specified units.\n- For a sequence of $N$ time steps, define residuals $$r_{k}(\\theta) = V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}, \\quad k = 0,1,\\ldots,N-1,$$ where $V^{\\mathrm{meas}}_{k}$ are synthetic measurements generated by simulating the same ECM with known \"true\" parameters $\\theta^{\\mathrm{true}}$.\n- For a given weighting vector $$v \\in \\mathbb{R}^{N},$$ define $$g(\\theta) = \\sum_{k=0}^{N-1} v_{k} r_{k}(\\theta).$$ Using reverse-mode automatic differentiation and the chain rule, compute $$\\nabla_{\\theta} g(\\theta) = J(\\theta)^{\\top} v,$$ where $J(\\theta)$ is the Jacobian of $r(\\theta)$ with respect to $\\theta$.\n\nUnits and physical realism:\n- Use $R_{0}$ and $R_{1}$ in ohms, $C_{1}$ in farads, $I$ in amperes, $Q$ in coulombs, $\\Delta t$ in seconds, $V$ in volts, and $z$ as a unitless fraction in $[0,1]$.\n- All given parameters and inputs are physically plausible and consistent.\n\nAlgorithmic requirement:\n- Implement reverse-mode automatic differentiation by constructing a computational graph of scalar operations and performing backpropagation to accumulate gradients through the discrete-time simulator. Do not use any external automatic differentiation library; instead, implement the chain rule and gradient propagation from first principles.\n- The Jacobian-transpose vector product must be computed as described by $\\nabla_{\\theta} g(\\theta)$.\n\nTest suite:\n- Use the following three test cases. For each case, first generate $V^{\\mathrm{meas}}_{k}$ by simulating the ECM with the \"true\" parameters $\\theta^{\\mathrm{true}}$ and the specified input. Then compute $J(\\theta)^{\\top} v$ at the \"estimate\" parameters $\\theta$.\n\n- Case $1$ (happy path):\n    - $N = 10$, $\\Delta t = 1.0$ s, $Q = 7200$ C, $z_{0} = 0.7$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 5.0 \\sin\\left(\\frac{2\\pi k}{10}\\right)$ A for $k = 0,\\ldots,9$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.012, 0.025, 1800]$.\n    - Estimate parameters: $\\theta = [0.015, 0.020, 2000]$.\n    - Weighting vector $v$ as a linear ramp: $v_{k} = 0.1 + 0.1 k$ for $k = 0,\\ldots,9$.\n\n- Case $2$ (boundary condition with slow polarization):\n    - $N = 12$, $\\Delta t = 0.5$ s, $Q = 7200$ C, $z_{0} = 0.5$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 3.0$ A for $k = 0,\\ldots,11$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.006, 0.009, 12000]$.\n    - Estimate parameters: $\\theta = [0.005, 0.010, 10000]$.\n    - Weighting vector $v$ alternating signs: $v_{k} = 0.5 (-1)^{k}$.\n\n- Case $3$ (edge case with zero current):\n    - $N = 8$, $\\Delta t = 2.0$ s, $Q = 7200$ C, $z_{0} = 0.9$, $a_{0} = 3.6$ V, $a_{1} = 0.4$ V, $a_{2} = 0.1$ V.\n    - Current sequence: $I_{k} = 0.0$ A for $k = 0,\\ldots,7$.\n    - True parameters: $\\theta^{\\mathrm{true}} = [0.020, 0.035, 3500]$.\n    - Estimate parameters: $\\theta = [0.020, 0.040, 3000]$.\n    - Weighting vector $v$ all ones: $v_{k} = 1.0$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the concatenation of the three $J(\\theta)^{\\top} v$ vectors (in the order of the cases $1$, $2$, $3$), each vector ordered as $[\\,\\frac{\\partial g}{\\partial R_{0}}, \\frac{\\partial g}{\\partial R_{1}}, \\frac{\\partial g}{\\partial C_{1}}\\,]$.\n- The final output must be a comma-separated list enclosed in square brackets, with each floating-point number rounded to six decimal places (e.g., $\"[x_{1},x_{2},\\ldots,x_{9}]\"$). No units should be included in the output; values are pure numbers in consistent SI units as per the model definition.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in established battery modeling principles (Thevenin Equivalent Circuit Model), mathematically well-posed, objective, and provides a complete, consistent problem statement. The task is to implement a specific, verifiable numerical algorithm (reverse-mode automatic differentiation) from first principles, which is a substantial and well-defined problem in scientific computing.\n\nThe objective is to compute the Jacobian-transpose vector product, $\\nabla_{\\theta} g(\\theta) = J(\\theta)^{\\top} v$, for a scalar function $g(\\theta) = \\sum_{k=0}^{N-1} v_{k} r_{k}(\\theta)$. The parameters are $\\theta = [R_{0}, R_{1}, C_{1}]$, and the residuals are $r_{k}(\\theta) = V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}$. The term $V^{\\mathrm{meas}}_{k}$ is generated using true parameters $\\theta^{\\mathrm{true}}$ and is therefore constant with respect to the estimate parameters $\\theta$. Consequently, its derivative is zero: $\\nabla_{\\theta} V^{\\mathrm{meas}}_{k} = 0$. The gradient calculation simplifies to:\n$$ \\nabla_{\\theta} g(\\theta) = \\nabla_{\\theta} \\left( \\sum_{k=0}^{N-1} v_{k} (V_{\\mathrm{term},k}(\\theta) - V^{\\mathrm{meas}}_{k}) \\right) = \\sum_{k=0}^{N-1} v_{k} \\nabla_{\\theta} V_{\\mathrm{term},k}(\\theta) $$\nThis quantity is computed efficiently using reverse-mode automatic differentiation (AD), also known as the adjoint method or backpropagation. This method involves two main stages: a forward pass to simulate the system and a backward pass to propagate gradients.\n\nThe discrete-time model equations are:\n$$ z_{k+1} = z_{k} - \\frac{\\Delta t}{Q} I_{k} $$\n$$ V_{1,k+1} = V_{1,k} \\left(1 - \\frac{\\Delta t}{R_{1} C_{1}}\\right) + \\frac{\\Delta t}{C_{1}} I_{k} $$\n$$ V_{\\mathrm{term},k} = (a_{0} + a_{1} z_{k} + a_{2} z_{k}^{2}) - R_{0} I_{k} - V_{1,k} $$\nThe initial condition for the polarization voltage, $V_{1,0}$, is not explicitly specified. A standard and physically consistent assumption is that the battery is at rest before the simulation begins, implying no polarization effects. Therefore, we set $V_{1,0} = 0$.\n\n**1. Forward Pass**\nThe system is simulated forward in time from $k=0$ to $k=N-1$ using the estimate parameters $\\theta = [R_{0}, R_{1}, C_{1}]$. During this pass, the time-history of the state variables, $z_k$ and $V_{1,k}$, for $k=0, \\ldots, N$, are computed and stored. These stored values are required for the backward pass.\n\n**2. Backward Pass (Adjoint Method)**\nThe backward pass computes the gradients by propagating sensitivities back in time, from $k=N-1$ to $k=0$. We use the notation $\\bar{x} = \\frac{\\partial g}{\\partial x}$ to represent the adjoint of a variable $x$. The goal is to compute the adjoints of the parameters, $\\bar{R}_{0}$, $\\bar{R}_{1}$, and $\\bar{C}_{1}$. These are initialized to zero and accumulated throughout the pass.\n\nThe process starts from the final time step. The adjoints of the states at the end of the simulation horizon are zero, i.e., $\\bar{z}_{N} = 0$ and $\\bar{V}_{1,N} = 0$, as they do not influence any subsequent calculations that contribute to $g(\\theta)$.\n\nThe algorithm proceeds by iterating backward from $k=N-1$ down to $0$. At each step $k$, we compute the adjoints of the states at that time, $\\bar{z}_{k}$ and $\\bar{V}_{1,k}$, based on the adjoints from the \"future\" step $k+1$. Using the multivariable chain rule, the adjoint update equations are derived:\n\nThe adjoint of state $z_k$ is the sum of its influence on the output at time $k$ and the state at time $k+1$:\n$$ \\bar{z}_{k} = \\frac{\\partial g}{\\partial z_{k}} = \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}}\\frac{\\partial V_{\\mathrm{term},k}}{\\partial z_{k}} + \\frac{\\partial g}{\\partial z_{k+1}}\\frac{\\partial z_{k+1}}{\\partial z_{k}} $$\nFrom the model equations, $\\frac{\\partial g}{\\partial V_{\\mathrm{term},k}} = v_k$, $\\frac{\\partial V_{\\mathrm{term},k}}{\\partial z_{k}} = a_{1} + 2a_{2}z_{k}$, and $\\frac{\\partial z_{k+1}}{\\partial z_{k}} = 1$. This gives:\n$$ \\bar{z}_{k} = v_{k}(a_{1} + 2a_{2}z_{k}) + \\bar{z}_{k+1} $$\n\nSimilarly, for the adjoint of state $V_{1,k}$:\n$$ \\bar{V}_{1,k} = \\frac{\\partial g}{\\partial V_{1,k}} = \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}}\\frac{\\partial V_{\\mathrm{term},k}}{\\partial V_{1,k}} + \\frac{\\partial g}{\\partial V_{1,k+1}}\\frac{\\partial V_{1,k+1}}{\\partial V_{1,k}} $$\nWith $\\frac{\\partial V_{\\mathrm{term},k}}{\\partial V_{1,k}} = -1$ and $\\frac{\\partial V_{1,k+1}}{\\partial V_{1,k}} = 1 - \\frac{\\Delta t}{R_{1}C_{1}}$, we get:\n$$ \\bar{V}_{1,k} = -v_{k} + \\bar{V}_{1,k+1}\\left(1 - \\frac{\\Delta t}{R_{1} C_{1}}\\right) $$\n\nDuring this backward iteration, the gradients with respect to the parameters $\\theta$ are accumulated. The total gradient for a parameter is the sum of its influence across all time steps.\nThe gradient for $R_0$ arises from its direct influence on $V_{\\mathrm{term},k}$:\n$$ \\bar{R}_{0} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{\\mathrm{term},k}} \\frac{\\partial V_{\\mathrm{term},k}}{\\partial R_{0}} = \\sum_{k=0}^{N-1} v_{k}(-I_{k}) $$\nThe gradients for $R_1$ and $C_1$ arise from their influence on the state transition $V_{1,k} \\to V_{1,k+1}$:\n$$ \\bar{R}_{1} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{1,k+1}} \\frac{\\partial V_{1,k+1}}{\\partial R_{1}} = \\sum_{k=0}^{N-1} \\bar{V}_{1,k+1} \\left( V_{1,k} \\frac{\\Delta t}{R_{1}^{2} C_{1}} \\right) $$\n$$ \\bar{C}_{1} = \\sum_{k=0}^{N-1} \\frac{\\partial g}{\\partial V_{1,k+1}} \\frac{\\partial V_{1,k+1}}{\\partial C_{1}} = \\sum_{k=0}^{N-1} \\bar{V}_{1,k+1} \\left( V_{1,k}\\frac{\\Delta t}{R_{1}C_{1}^{2}} - I_{k}\\frac{\\Delta t}{C_{1}^{2}} \\right) $$\n\nBy initializing the parameter adjoints to zero and adding the contribution from each time step $k$ during the backward loop, we efficiently compute the final total gradients $\\bar{R}_{0}, \\bar{R}_{1}, \\bar{C}_{1}$, which form the vector $J(\\theta)^{\\top}v$.",
            "answer": "```python\nimport numpy as np\n\ndef compute_jtvp(params):\n    \"\"\"\n    Computes the Jacobian-transpose vector product J^T v for the battery ECM.\n\n    This function implements reverse-mode automatic differentiation from first principles.\n    It first performs a forward pass to simulate the system states and stores their\n    history. Then, a backward pass propagates gradients back in time to compute\n    the final Jacobian-transpose vector product with respect to the model parameters.\n    \"\"\"\n    N = params['N']\n    dt = params['dt']\n    Q = params['Q']\n    z0 = params['z0']\n    a0, a1, a2 = params['a_coeffs']\n    I_seq = params['I_seq']\n    R0, R1, C1 = params['theta_est']\n    v_weights = params['v_weights']\n    \n    # Per problem description, a resting battery has V1_0 = 0.\n    V1_0 = 0.0\n\n    # --- Forward Pass: Simulate the system dynamics ---\n    z_hist = np.zeros(N + 1)\n    V1_hist = np.zeros(N + 1)\n    z_hist[0] = z0\n    V1_hist[0] = V1_0\n\n    # Pre-calculate factors for efficiency\n    if R1 > 0 and C1 > 0:\n        V1_factor = 1 - dt / (R1 * C1)\n    else:\n        # Handle potential division by zero, although problem constraints prevent this.\n        V1_factor = 1.0\n\n    for k in range(N):\n        z_hist[k+1] = z_hist[k] - (dt / Q) * I_seq[k]\n        V1_hist[k+1] = V1_hist[k] * V1_factor + (dt / C1) * I_seq[k]\n\n    # --- Backward Pass: Propagate gradients (adjoints) ---\n    # Initialize parameter gradients (adjoints)\n    R0_bar = 0.0\n    R1_bar = 0.0\n    C1_bar = 0.0\n\n    # Initialize state adjoints for step k+1 (starting with t=N, they are 0)\n    z_bar_next = 0.0\n    V1_bar_next = 0.0\n\n    # Loop backward in time from k = N-1 down to 0\n    for k in range(N - 1, -1, -1):\n        # Retrieve values from the forward pass history\n        z_k = z_hist[k]\n        V1_k = V1_hist[k]\n        I_k = I_seq[k]\n        v_k = v_weights[k]\n\n        # --- Accumulate gradients for parameters for step k ---\n\n        # 1. Gradient for R0 (from V_term,k)\n        # d(g)/d(R0) += d(g)/d(V_term,k) * d(V_term,k)/d(R0)\n        # The first term is v_k, the second is -I_k.\n        R0_bar += -v_k * I_k\n\n        # 2. Gradients for R1 and C1 (from V1_{k+1})\n        # d(g)/d(R1) += d(g)/d(V1_{k+1}) * d(V1_{k+1})/d(R1)\n        # The first term is V1_bar_next.\n        if R1 > 0 and C1 > 0:\n            # Partial derivative of V1_{k+1} w.r.t. R1\n            dV1kp1_dR1 = V1_k * dt / (R1**2 * C1)\n            R1_bar += V1_bar_next * dV1kp1_dR1\n            \n            # Partial derivative of V1_{k+1} w.r.t. C1\n            dV1kp1_dC1 = V1_k * dt / (R1 * C1**2) - I_k * dt / C1**2\n            C1_bar += V1_bar_next * dV1kp1_dC1\n\n        # --- Update state adjoints for the next backward step (k-1) ---\n\n        # 1. Adjoint for z_k\n        # d(g)/d(z_k) = d(g)/d(V_term,k)*d(V_term,k)/d(z_k) + d(g)/d(z_{k+1})*d(z_{k+1})/d(z_k)\n        dz_bar_k = v_k * (a1 + 2 * a2 * z_k) + z_bar_next\n\n        # 2. Adjoint for V1_k\n        # d(g)/d(V1_k) = d(g)/d(V_term,k)*d(V_term,k)/d(V1_k) + d(g)/d(V1_{k+1})*d(V1_{k+1})/d(V1_k)\n        dV1_bar_k = -v_k + V1_bar_next * V1_factor\n        \n        # Propagate adjoints to the next iteration\n        z_bar_next = dz_bar_k\n        V1_bar_next = dV1_bar_k\n\n    return [R0_bar, R1_bar, C1_bar]\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the solver for each, and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 10, \"dt\": 1.0, \"Q\": 7200.0, \"z0\": 0.7, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.array([5.0 * np.sin(2 * np.pi * k / 10) for k in range(10)]),\n            \"theta_est\": (0.015, 0.020, 2000.0),\n            \"v_weights\": np.array([0.1 + 0.1 * k for k in range(10)])\n        },\n        {\n            \"N\": 12, \"dt\": 0.5, \"Q\": 7200.0, \"z0\": 0.5, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.full(12, 3.0),\n            \"theta_est\": (0.005, 0.010, 10000.0),\n            \"v_weights\": np.array([0.5 * (-1)**k for k in range(12)])\n        },\n        {\n            \"N\": 8, \"dt\": 2.0, \"Q\": 7200.0, \"z0\": 0.9, \"a_coeffs\": (3.6, 0.4, 0.1),\n            \"I_seq\": np.zeros(8),\n            \"theta_est\": (0.020, 0.040, 3000.0),\n            \"v_weights\": np.ones(8)\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_vector = compute_jtvp(case)\n        all_results.extend(result_vector)\n\n    # Format the final output string as specified\n    formatted_results = [f'{val:.6f}' for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Finding a good parameter set is not just about running an optimizer until its convergence metrics are small; it's about finding parameters that generalize to new, unseen data. This exercise challenges you to design a robust stopping criterion that intelligently balances optimization convergence with overfitting avoidance. By combining training and validation data with statistical awareness, you will learn to construct practical rules that prevent a model from merely memorizing the training data, a critical skill for developing reliable and predictive simulations. ",
            "id": "3935068",
            "problem": "A lithium-ion cell is modeled in automated simulation by a physics-based electrochemical surrogate that enforces conservation of mass and charge, Fickian diffusion, Ohm's law, and Butler–Volmer interfacial kinetics. The simulator predicts terminal voltage as a function of time, denoted by $V_{\\text{sim}}(\\boldsymbol{\\theta};t)$, where $\\boldsymbol{\\theta}\\in\\mathbb{R}^m$ is a vector of model parameters to be estimated (such as diffusion coefficients, reaction rate constants, and conductivity terms). The data consist of two disjoint experimental sequences: a training set $\\mathcal{D}_{\\text{train}}=\\{(t_i,I_i,V_{\\text{meas}}(t_i))\\}_{i=1}^{N_{\\text{train}}}$ and a validation set $\\mathcal{D}_{\\text{val}}=\\{(s_j,J_j,V_{\\text{meas}}(s_j))\\}_{j=1}^{N_{\\text{val}}}$, each comprising time stamps, applied current profiles, and measured voltages. Measurement noise on voltage is modeled as zero-mean Gaussian with variance $\\sigma_V^2$, which is estimated from repeated calibration pulses. Parameter estimation is posed as empirical risk minimization with a noise-normalized mean-squared error,\n$$\nL_{\\text{train}}(\\boldsymbol{\\theta})=\\frac{1}{N_{\\text{train}}}\\sum_{i=1}^{N_{\\text{train}}}\\frac{\\big(V_{\\text{sim}}(\\boldsymbol{\\theta};t_i)-V_{\\text{meas}}(t_i)\\big)^2}{\\sigma_V^2},\\quad\nL_{\\text{val}}(\\boldsymbol{\\theta})=\\frac{1}{N_{\\text{val}}}\\sum_{j=1}^{N_{\\text{val}}}\\frac{\\big(V_{\\text{sim}}(\\boldsymbol{\\theta};s_j)-V_{\\text{meas}}(s_j)\\big)^2}{\\sigma_V^2}.\n$$\nAn iterative gradient-based optimizer generates a sequence $\\{\\boldsymbol{\\theta}_k\\}_{k\\geq 0}$ with associated quantities $g(k)=\\|\\nabla L_{\\text{train}}(\\boldsymbol{\\theta}_k)\\|_2$ (the training gradient norm), $d_{\\theta}(k)=\\|\\boldsymbol{\\theta}_k-\\boldsymbol{\\theta}_{k-1}\\|_2$ (the parameter change norm), and the generalization gap $G(k)=L_{\\text{val}}(\\boldsymbol{\\theta}_k)-L_{\\text{train}}(\\boldsymbol{\\theta}_k)$. To mitigate sensitivity to high-frequency fluctuations in $L_{\\text{val}}$, define a moving average $\\bar{L}_{\\text{val}}(k)$ over a window of $w$ recent epochs, and let $p$ be a patience parameter that counts consecutive epochs with insufficient validation improvement. Consider that the primary goals are to (i) ensure optimization convergence toward a stationary point of the training objective and (ii) avoid overfitting by detecting when validation performance ceases to improve or degrades beyond what is explainable by measurement noise. A noise-aware margin $\\gamma$ is set from the validation distribution of $G(k)$ under resampling (e.g., via bootstrapping), interpreted as a high quantile of the null variability due to noise.\n\nWhich stopping rule best balances optimization convergence with avoidance of overfitting, under the assumptions above?\n\nA. Stop at epoch $k$ if $g(k)\\leq \\varepsilon_g$ and the average rate of decrease of $L_{\\text{train}}(\\boldsymbol{\\theta}_\\ell)$ over the last $p$ epochs is below a tolerance $\\eta$; ignore validation signals entirely.\n\nB. Stop at the earliest epoch $k$ such that $L_{\\text{val}}(\\boldsymbol{\\theta}_k)$ exceeds its previous minimum by at least $\\eta$, regardless of $g(k)$ or $d_{\\theta}(k)$; do not smooth $L_{\\text{val}}$ and do not consider the generalization gap $G(k)$.\n\nC. Stop at epoch $k$ if $g(k)\\geq \\varepsilon_g$ while $L_{\\text{val}}(\\boldsymbol{\\theta}_k)$ is still decreasing; rely on the decrease of $L_{\\text{val}}$ to indicate progress and accept a large gradient to avoid premature termination.\n\nD. Stop at epoch $k$ when both a convergence indicator and a noise-aware overfitting indicator are satisfied, namely:\n- $g(k)\\leq \\varepsilon_g$ or $d_{\\theta}(k)\\leq \\varepsilon_{\\theta}$, and\n- for $p$ consecutive epochs, the smoothed validation metric shows no significant improvement, i.e., $\\bar{L}_{\\text{val}}(k)-\\bar{L}_{\\text{val}}(k-p)\\geq \\eta\\,\\bar{L}_{\\text{val}}(k-p)$, and\n- the generalization gap is larger than a noise margin, i.e., $G(k)\\geq \\gamma$,\nwith $\\eta>0$, $\\varepsilon_g>0$, $\\varepsilon_{\\theta}>0$, and $\\gamma$ set by resampling on $\\mathcal{D}_{\\text{val}}$ to reflect the variability due to $\\sigma_V^2$.\n\nSelect the single best choice.",
            "solution": "The problem describes a robust and realistic setup for parameter estimation and asks for the best rule to terminate the iterative optimization process. A good stopping rule must balance two often competing goals: ensuring the optimizer has converged to a good solution for the training data, and preventing the model from overfitting to the training data, which would harm its ability to generalize to new data.\n\nThe optimal stopping rule must therefore consider signals from both the training process and the validation process.\n\n- **Goal 1: Ensure Convergence.** A rule must check if the optimizer is still making meaningful progress. This is typically measured by the gradient norm of the training loss, $g(k)$, or the magnitude of parameter updates, $d_{\\theta}(k)$. If these are small, the optimizer has likely found a stationary point (e.g., a local minimum).\n- **Goal 2: Avoid Overfitting.** A rule must monitor performance on the validation set. Overfitting occurs when training loss continues to decrease but validation loss, $L_{\\text{val}}$, begins to increase. A robust rule should use the tools provided to make this check reliable: smoothing ($L_{\\text{val}}$), a patience window ($p$), and a statistical threshold for the generalization gap ($\\gamma$).\n\nLet's analyze the options based on these criteria:\n\n**A.** This rule only considers the training loss and its gradient. By explicitly ignoring validation signals, it completely fails to detect or prevent overfitting. An optimizer could find a perfect minimum for the training data that performs terribly on any other data. This violates Goal 2.\n\n**B.** This rule implements a naive form of early stopping. While it monitors validation loss, it is highly sensitive to noise because it uses the raw $L_{\\text{val}}$ value, has no patience mechanism, and stops at the \"earliest epoch\" of degradation. A single noisy measurement could prematurely halt the entire optimization process. It ignores the sophisticated, robust mechanisms described in the problem.\n\n**C.** This rule's logic is inverted. It proposes stopping when the training gradient is large ($g(k) \\geq \\varepsilon_g$) and the validation loss is decreasing. This is precisely the scenario where training *should* continue, as the model has not yet converged and its generalization performance is still improving. Stopping here is the definition of premature termination.\n\n**D.** This option presents a comprehensive and multi-faceted criterion. It correctly balances the two goals by requiring conditions related to both:\n1.  **Convergence check:** It first ensures that the optimizer has slowed down or stopped making significant progress ($g(k)\\leq \\varepsilon_g$ or $d_{\\theta}(k)\\leq \\varepsilon_{\\theta}$).\n2.  **Overfitting check:** It then confirms that overfitting is occurring in a statistically significant way, using three robust indicators:\n    - The *smoothed* validation metric is used to be robust against noise.\n    - A check over a *patience* window ensures the lack of improvement is persistent.\n    - The generalization gap $G(k)$ must exceed a *noise-aware margin* $\\gamma$, confirming that the divergence between training and validation performance is not just a random fluctuation.\n\nBy requiring that the optimizer has first converged and then that robust indicators of overfitting are present, this rule avoids stopping prematurely while still effectively preventing the model from learning noise. It thoughtfully incorporates all the advanced techniques mentioned in the problem setup to create the most reliable and balanced stopping criterion among the choices. Therefore, it is the best option.",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "A single point estimate for a parameter, no matter how optimal, tells us nothing about the confidence we should have in that value. This practice introduces the Bayesian paradigm, a powerful framework for moving beyond point estimates to full uncertainty quantification. You will implement a Metropolis-Hastings MCMC sampler to explore the entire landscape of plausible parameters, generating a posterior distribution that provides a rich, probabilistic understanding of the model's time constants. ",
            "id": "3935091",
            "problem": "You are designing an algorithmic routine for automated battery design and simulation that estimates time constants in an Equivalent Circuit Model (ECM) from pulse test data via Bayesian inference. The ECM is assumed to be a Thevenin-type model consisting of a series ohmic resistance and one or more resistive-capacitive branches. The objective is to construct and implement a Metropolis–Hastings Markov Chain Monte Carlo (MCMC) scheme to sample from the posterior distribution of the ECM’s time constant parameters, given noisy voltage measurements from a current step (pulse test). The final program must output posterior mean estimates of the time constants, expressed in seconds, for a provided test suite of scenarios.\n\nThe physical starting point is the first-order differential equation describing the voltage across each Resistive–Capacitive (RC) branch under a step current. Consider a constant current step $I$ applied at time $t=0$ to a Thevenin ECM consisting of an ohmic resistance $R_{0}$ in series with $m$ parallel RC branches, where branch $k$ has resistance $R_{k}$ and capacitance $C_{k}$. Denote the branch voltage for branch $k$ by $v_{k}(t)$ and the time constant $\\tau_{k}$ by $\\tau_{k} = R_{k} C_{k}$. Under a current step input $I$, the linear time-invariant dynamics yield the branch response governed by\n$$\n\\frac{d v_{k}(t)}{dt} = -\\frac{1}{\\tau_{k}} v_{k}(t) + \\frac{R_{k}}{\\tau_{k}} I,\n$$\nwith initial condition $v_{k}(0^{+}) = 0$ for a fully relaxed branch. Solving this first-order linear ordinary differential equation produces the branch response\n$$\nv_{k}(t) = I R_{k} \\left(1 - e^{-t / \\tau_{k}}\\right),\n$$\nand the total incremental terminal voltage across the ECM following the current step is\n$$\n\\Delta V(t; \\boldsymbol{\\tau}) = I R_{0} + \\sum_{k=1}^{m} I R_{k} \\left(1 - e^{-t / \\tau_{k}}\\right),\n$$\nwhere $\\boldsymbol{\\tau} = (\\tau_{1}, \\dots, \\tau_{m})$ and $t \\ge 0$.\n\nAssume the observed voltages $\\{y_{i}\\}_{i=1}^{n}$ measured at times $\\{t_{i}\\}_{i=1}^{n}$ follow the measurement model\n$$\ny_{i} = \\Delta V(t_{i}; \\boldsymbol{\\tau}) + \\varepsilon_{i}, \\quad \\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2}),\n$$\nwith independent and identically distributed Gaussian noise of known variance $\\sigma^{2}$.\n\nWe seek the posterior distribution of the time constants given data $\\mathbf{y}$ and model parameters $\\{I, R_{0}, R_{1}, \\dots, R_{m}\\}$. To ensure positivity of time constants and ease of proposal design, parameterize by the logarithms of time constants, letting $x_{k} = \\ln \\tau_{k}$. Place independent Normal priors on $x_{k}$,\n$$\nx_{k} \\sim \\mathcal{N}(\\mu_{k}, s_{k}^{2}), \\quad k = 1, \\ldots, m.\n$$\nUnder this parameterization, the posterior density over $\\mathbf{x} = (x_{1}, \\dots, x_{m})$ is proportional to the product of the likelihood and the prior, with the likelihood depending on $\\tau_{k} = e^{x_{k}}$:\n$$\n\\log p(\\mathbf{x} \\mid \\mathbf{y}) = -\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n} \\left[y_{i} - \\Delta V\\left(t_{i}; e^{x_{1}}, \\dots, e^{x_{m}}\\right)\\right]^{2} - \\frac{1}{2} \\sum_{k=1}^{m} \\left(\\frac{x_{k} - \\mu_{k}}{s_{k}}\\right)^{2} + \\text{constant}.\n$$\n\nConstruct a Metropolis–Hastings scheme with a symmetric Gaussian proposal in log-time-constant space:\n$$\n\\mathbf{x}' = \\mathbf{x} + \\boldsymbol{\\eta}, \\quad \\boldsymbol{\\eta} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\operatorname{diag}(v_{1}^{2}, \\dots, v_{m}^{2})\\right).\n$$\nGiven the current state $\\mathbf{x}$ and a proposed state $\\mathbf{x}'$, compute the acceptance probability\n$$\n\\alpha = \\min\\left(1, \\exp\\left[\\log p(\\mathbf{x}' \\mid \\mathbf{y}) - \\log p(\\mathbf{x} \\mid \\mathbf{y})\\right]\\right),\n$$\nand accept the proposal with probability $\\alpha$, otherwise retain the current state. After burn-in and thinning to reduce autocorrelation, estimate the posterior means of the time constants by transforming the retained samples back to $\\boldsymbol{\\tau} = (e^{x_{1}}, \\dots, e^{x_{m}})$ and averaging.\n\nYour program must implement this MCMC sampler and apply it to the following test suite. For each test case, generate synthetic measurement data using the specified ground-truth time constants and a fixed random seed for reproducibility, then run the MCMC with its specified configuration, and finally report the posterior mean of each time constant in seconds.\n\nTest Suite (all time constants must be reported in seconds):\n- Case A (single RC branch, moderate noise, typical pulse duration):\n    - Current step magnitude: $I = 5 \\ \\mathrm{A}$.\n    - Ohmic resistance: $R_{0} = 0.015 \\ \\Omega$.\n    - One RC branch: $m = 1$, with $R_{1} = 0.020 \\ \\Omega$.\n    - Ground-truth time constant: $\\tau_{1}^{\\star} = 20.0 \\ \\mathrm{s}$.\n    - Measurement times: $t_{i} = 2 i \\ \\mathrm{s}$ for $i = 0, 1, \\dots, 50$ (that is, $t \\in \\{0, 2, 4, \\dots, 100\\} \\ \\mathrm{s}$).\n    - Noise standard deviation: $\\sigma = 0.002 \\ \\mathrm{V}$.\n    - Prior on $x_{1} = \\ln \\tau_{1}$: $\\mu_{1} = \\ln(25.0)$, $s_{1} = 0.5$.\n    - Proposal standard deviation: $v_{1} = 0.20$.\n    - MCMC configuration: total iterations $N = 20000$, burn-in $B = 5000$, thinning interval $L = 5$.\n    - Synthetic data generation seed: $s_{\\mathrm{data}} = 123$; MCMC seed: $s_{\\mathrm{mcmc}} = 321$.\n- Case B (two RC branches, low noise, mixed fast/slow dynamics):\n    - Current step magnitude: $I = 10 \\ \\mathrm{A}$.\n    - Ohmic resistance: $R_{0} = 0.010 \\ \\Omega$.\n    - Two RC branches: $m = 2$, with $R_{1} = 0.015 \\ \\Omega$, $R_{2} = 0.010 \\ \\Omega$.\n    - Ground-truth time constants: $\\tau_{1}^{\\star} = 2.0 \\ \\mathrm{s}$, $\\tau_{2}^{\\star} = 50.0 \\ \\mathrm{s}$.\n    - Measurement times: $t_{i} = 1 i \\ \\mathrm{s}$ for $i = 0, 1, \\dots, 60$ (that is, $t \\in \\{0, 1, 2, \\dots, 60\\} \\ \\mathrm{s}$).\n    - Noise standard deviation: $\\sigma = 0.001 \\ \\mathrm{V}$.\n    - Priors: $x_{1} = \\ln \\tau_{1}$ with $\\mu_{1} = \\ln(3.0)$, $s_{1} = 0.6$; $x_{2} = \\ln \\tau_{2}$ with $\\mu_{2} = \\ln(40.0)$, $s_{2} = 0.6$.\n    - Proposal standard deviations: $v_{1} = 0.25$, $v_{2} = 0.25$.\n    - MCMC configuration: total iterations $N = 25000$, burn-in $B = 6000$, thinning interval $L = 5$.\n    - Synthetic data generation seed: $s_{\\mathrm{data}} = 456$; MCMC seed: $s_{\\mathrm{mcmc}} = 654$.\n- Case C (single RC branch, short record, higher noise; boundary identifiability stress):\n    - Current step magnitude: $I = 2 \\ \\mathrm{A}$.\n    - Ohmic resistance: $R_{0} = 0.012 \\ \\Omega$.\n    - One RC branch: $m = 1$, with $R_{1} = 0.010 \\ \\Omega$.\n    - Ground-truth time constant: $\\tau_{1}^{\\star} = 5.0 \\ \\mathrm{s}$.\n    - Measurement times: $t_{i} = 1 i \\ \\mathrm{s}$ for $i = 0, 1, \\dots, 10$ (that is, $t \\in \\{0, 1, \\dots, 10\\} \\ \\mathrm{s}$).\n    - Noise standard deviation: $\\sigma = 0.005 \\ \\mathrm{V}$.\n    - Prior on $x_{1} = \\ln \\tau_{1}$: $\\mu_{1} = \\ln(4.0)$, $s_{1} = 0.7$.\n    - Proposal standard deviation: $v_{1} = 0.30$.\n    - MCMC configuration: total iterations $N = 20000$, burn-in $B = 5000$, thinning interval $L = 5$.\n    - Synthetic data generation seed: $s_{\\mathrm{data}} = 789$; MCMC seed: $s_{\\mathrm{mcmc}} = 987$.\n\nImplementation requirements:\n- Use the above measurement model to generate synthetic voltage observations $\\{y_{i}\\}$ with the specified seeds and noise level for each case.\n- Implement the Metropolis–Hastings sampler in log-time-constant space with independent Gaussian proposals per dimension as specified.\n- After burn-in and thinning, compute the posterior mean of each time constant, in seconds, for each case.\n- Express the final output as a single line containing a list of lists, where each inner list contains the posterior mean time constants for that case in seconds, formatted with six digits after the decimal point and no spaces. For example, if there are three cases with one, two, and one time constants respectively, the output must be of the form\n$[\\,[\\tau_{A}],\\,[\\tau_{B1},\\tau_{B2}],\\,[\\tau_{C}]\\,]$\nwith actual numerical values replacing symbols, written without spaces, e.g., $[[19.500000],[1.950000,48.000000],[5.100000]]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, exactly as described above, and must not print any other text. All reported time constants must be in $\\mathrm{s}$ (seconds).",
            "solution": "The problem is valid. It is a well-defined task in computational statistics applied to a standard model in battery engineering. All physical principles, mathematical formulations, and provided data are sound and self-consistent.\n\nThe objective is to estimate the time constants $\\boldsymbol{\\tau} = (\\tau_{1}, \\dots, \\tau_{m})$ of a Thevenin-type Equivalent Circuit Model (ECM) for a battery. The estimation is to be performed within a Bayesian framework, utilizing a Metropolis-Hastings Markov Chain Monte Carlo (MCMC) algorithm to sample from the posterior distribution of the parameters given noisy voltage measurements from a current pulse test.\n\nFirst, we establish the forward model that relates the parameters $\\boldsymbol{\\tau}$ to the observable quantity, which is the terminal voltage. The ECM consists of an ohmic resistor $R_{0}$ in series with $m$ parallel RC branches. For a constant current step $I$ applied at time $t=0$, the total incremental voltage across the ECM is given by:\n$$\n\\Delta V(t; \\boldsymbol{\\tau}) = I R_{0} + \\sum_{k=1}^{m} I R_{k} \\left(1 - e^{-t / \\tau_{k}}\\right)\n$$\nHere, $R_{k}$ is the resistance of the $k$-th RC branch, and $\\tau_{k} = R_{k} C_{k}$ is its corresponding time constant.\n\nNext, we define the statistical model. The observed voltage measurements $\\{y_{i}\\}_{i=1}^{n}$ at discrete time points $\\{t_{i}\\}_{i=1}^{n}$ are assumed to be corrupted by independent and identically distributed Gaussian noise, $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2})$, where the noise variance $\\sigma^{2}$ is known. The measurement model is:\n$$\ny_{i} = \\Delta V(t_{i}; \\boldsymbol{\\tau}) + \\varepsilon_{i}\n$$\nThis leads to a Gaussian likelihood function for the parameters $\\boldsymbol{\\tau}$ given the data $\\mathbf{y} = \\{y_{1}, \\dots, y_{n}\\}$:\n$$\n\\mathcal{L}(\\boldsymbol{\\tau} \\mid \\mathbf{y}) = p(\\mathbf{y} \\mid \\boldsymbol{\\tau}) \\propto \\exp\\left(-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n} \\left[y_{i} - \\Delta V(t_{i}; \\boldsymbol{\\tau})\\right]^{2}\\right)\n$$\nTo enforce the physical constraint that time constants must be positive, $\\tau_k > 0$, we reparameterize the model in terms of the logarithm of the time constants, $x_{k} = \\ln \\tau_{k}$. This transforms the domain of the parameters from $(0, \\infty)$ to $(-\\infty, \\infty)$, which is more convenient for many numerical optimization and sampling schemes.\n\nIn the Bayesian framework, we must specify prior distributions for the parameters. The problem states that independent Normal priors are placed on the log-time-constants $x_k$:\n$$\nx_{k} \\sim \\mathcal{N}(\\mu_{k}, s_{k}^{2}), \\quad k = 1, \\dots, m\n$$\nThis is equivalent to assuming a Log-Normal prior on the original time constants $\\tau_{k}$. The joint prior probability density for the vector $\\mathbf{x} = (x_{1}, \\dots, x_{m})$ is:\n$$\n\\pi(\\mathbf{x}) \\propto \\exp\\left(-\\frac{1}{2} \\sum_{k=1}^{m} \\left(\\frac{x_{k} - \\mu_{k}}{s_{k}}\\right)^{2}\\right)\n$$\nAccording to Bayes' theorem, the posterior probability density is proportional to the product of the likelihood and the prior: $p(\\mathbf{x} \\mid \\mathbf{y}) \\propto \\mathcal{L}(\\mathbf{x} \\mid \\mathbf{y}) \\pi(\\mathbf{x})$. For numerical stability and computational convenience, it is standard practice to work with the log-posterior:\n$$\n\\log p(\\mathbf{x} \\mid \\mathbf{y}) = \\log \\mathcal{L}(\\mathbf{x} \\mid \\mathbf{y}) + \\log \\pi(\\mathbf{x}) + \\text{constant}\n$$\nSubstituting the expressions for the log-likelihood and log-prior, we get the target log-posterior density function:\n$$\n\\log p(\\mathbf{x} \\mid \\mathbf{y}) = -\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n} \\left[y_{i} - \\Delta V\\left(t_{i}; e^{x_{1}}, \\dots, e^{x_{m}}\\right)\\right]^{2} - \\frac{1}{2} \\sum_{k=1}^{m} \\left(\\frac{x_{k} - \\mu_{k}}{s_{k}}\\right)^{2} + \\text{constant}\n$$\nThe problem is to sample from this posterior distribution $p(\\mathbf{x} \\mid \\mathbf{y})$ using the Metropolis-Hastings MCMC algorithm. The algorithm proceeds as follows:\n1.  Initialize the state of the Markov chain, $\\mathbf{x}^{(0)}$. A sensible choice is the mean of the prior distribution, $\\mathbf{x}^{(0)} = (\\mu_{1}, \\dots, \\mu_{m})$.\n2.  For each iteration $j = 1, \\dots, N$:\n    a. Generate a new candidate state $\\mathbf{x}'$ from a proposal distribution $q(\\mathbf{x}' \\mid \\mathbf{x}^{(j-1)})$. The problem specifies a symmetric a Gaussian proposal distribution centered at the current state:\n    $$\n    \\mathbf{x}' = \\mathbf{x}^{(j-1)} + \\boldsymbol{\\eta}, \\quad \\text{where } \\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{V})\n    $$\n    with $\\mathbf{V}$ being a diagonal covariance matrix, $\\mathbf{V} = \\operatorname{diag}(v_{1}^{2}, \\dots, v_{m}^{2})$.\n    b. Calculate the acceptance probability, $\\alpha$. For a symmetric proposal distribution, this simplifies to the ratio of posterior probabilities:\n    $$\n    \\alpha(\\mathbf{x}', \\mathbf{x}^{(j-1)}) = \\min\\left(1, \\frac{p(\\mathbf{x}' \\mid \\mathbf{y})}{p(\\mathbf{x}^{(j-1)} \\mid \\mathbf{y})}\\right) = \\min\\left(1, \\exp\\left[\\log p(\\mathbf{x}' \\mid \\mathbf{y}) - \\log p(\\mathbf{x}^{(j-1)} \\mid \\mathbf{y})\\right]\\right)\n    $$\n    c. Draw a random number $u$ from a uniform distribution $U(0,1)$. If $u < \\alpha$, accept the proposal and set $\\mathbf{x}^{(j)} = \\mathbf{x}'$. Otherwise, reject the proposal and set $\\mathbf{x}^{(j)} = \\mathbf{x}^{(j-1)}$.\n3.  Store the sequence of states $\\{\\mathbf{x}^{(j)}\\}_{j=1}^{N}$. After a sufficient number of iterations, this sequence forms a set of samples from the posterior distribution $p(\\mathbf{x} \\mid \\mathbf{y})$.\n\nTo obtain final estimates, the collected samples are post-processed. An initial number of samples, the burn-in period ($B$), are discarded to allow the chain to converge to the stationary distribution. To reduce autocorrelation between successive samples, the chain is thinned by keeping only every $L$-th sample.\n\nThe remaining samples $\\{ \\mathbf{x}^{(j)} \\}_{j=B+1, B+L+1, \\dots}$ are then transformed back from the logarithmic space to the original time constant space: $\\boldsymbol{\\tau}^{(j)} = (e^{x_{1}^{(j)}}, \\dots, e^{x_{m}^{(j)}})$. The posterior mean of each time constant $\\tau_{k}$ is estimated by computing the sample mean of these transformed values:\n$$\n\\hat{\\tau}_{k, \\text{mean}} = \\frac{L}{N - B} \\sum_{j} e^{x_{k}^{(j)}} \\quad \\text{for } j \\in \\{B+1, B+L+1, \\ldots \\text{ up to } N\\}\n$$\nThis procedure is applied to each test case provided, generating synthetic data first and then running the MCMC sampler to recover the time constant estimates.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC estimation for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A\n        {\n            \"m\": 1, \"I\": 5.0, \"R0\": 0.015, \"Rk\": np.array([0.020]),\n            \"tau_star\": np.array([20.0]),\n            \"times\": np.arange(0, 101, 2, dtype=float),\n            \"sigma\": 0.002, \"mu_k\": np.array([np.log(25.0)]), \"s_k\": np.array([0.5]),\n            \"v_k\": np.array([0.20]),\n            \"N\": 20000, \"B\": 5000, \"L\": 5,\n            \"data_seed\": 123, \"mcmc_seed\": 321\n        },\n        # Case B\n        {\n            \"m\": 2, \"I\": 10.0, \"R0\": 0.010, \"Rk\": np.array([0.015, 0.010]),\n            \"tau_star\": np.array([2.0, 50.0]),\n            \"times\": np.arange(0, 61, 1, dtype=float),\n            \"sigma\": 0.001, \"mu_k\": np.array([np.log(3.0), np.log(40.0)]),\n            \"s_k\": np.array([0.6, 0.6]), \"v_k\": np.array([0.25, 0.25]),\n            \"N\": 25000, \"B\": 6000, \"L\": 5,\n            \"data_seed\": 456, \"mcmc_seed\": 654\n        },\n        # Case C\n        {\n            \"m\": 1, \"I\": 2.0, \"R0\": 0.012, \"Rk\": np.array([0.010]),\n            \"tau_star\": np.array([5.0]),\n            \"times\": np.arange(0, 11, 1, dtype=float),\n            \"sigma\": 0.005, \"mu_k\": np.array([np.log(4.0)]), \"s_k\": np.array([0.7]),\n            \"v_k\": np.array([0.30]),\n            \"N\": 20000, \"B\": 5000, \"L\": 5,\n            \"data_seed\": 789, \"mcmc_seed\": 987\n        }\n    ]\n\n    results_str_list = []\n    \n    for case in test_cases:\n        # Generate synthetic data\n        y_data = generate_synthetic_data(\n            case[\"times\"], case[\"I\"], case[\"R0\"], case[\"Rk\"],\n            case[\"tau_star\"], case[\"sigma\"], case[\"data_seed\"]\n        )\n        \n        # Run MCMC sampler\n        estimated_tau = run_mcmc_sampler(\n            y_data, case[\"times\"], case[\"I\"], case[\"R0\"], case[\"Rk\"],\n            case[\"sigma\"], case[\"mu_k\"], case[\"s_k\"], case[\"v_k\"],\n            case[\"N\"], case[\"B\"], case[\"L\"], case[\"mcmc_seed\"]\n        )\n        \n        # Format result string for this case\n        case_result_str = f\"[{','.join(f'{val:.6f}' for val in estimated_tau)}]\"\n        results_str_list.append(case_result_str)\n\n    # Print final combined result string\n    print(f\"[{','.join(results_str_list)}]\")\n\n\ndef voltage_model(t, I, R0, Rk, tau):\n    \"\"\"\n    Calculates the ECM voltage at given time points.\n    t, Rk, tau can be arrays.\n    \"\"\"\n    if t.ndim == 1:\n        t = t[:, np.newaxis]\n    \n    # Each column corresponds to an RC branch\n    # tau = [tau1, tau2, ...] -> shape (m,)\n    # t = [t1, t2, ...]^T -> shape (n, 1)\n    # exponential term: exp(-t / tau) -> shape (n, m) via broadcasting\n    rc_voltage_sum = np.sum(I * Rk * (1 - np.exp(-t / tau)), axis=1)\n    return I * R0 + rc_voltage_sum\n\n\ndef generate_synthetic_data(times, I, R0, Rk, tau_star, sigma, seed):\n    \"\"\"\n    Generates noisy voltage data based on the ECM model.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    true_voltage = voltage_model(times, I, R0, Rk, tau_star)\n    noise = rng.normal(0, sigma, size=len(times))\n    return true_voltage + noise\n\n\ndef log_posterior(x, y_data, times, I, R0, Rk, sigma, mu_k, s_k):\n    \"\"\"\n    Computes the log of the posterior probability (up to a constant).\n    x is the vector of log-time-constants.\n    \"\"\"\n    tau = np.exp(x)\n    \n    # Log-likelihood term\n    predicted_voltage = voltage_model(times, I, R0, Rk, tau)\n    log_likelihood = -0.5 / (sigma**2) * np.sum((y_data - predicted_voltage)**2)\n    \n    # Log-prior term\n    log_prior = -0.5 * np.sum(((x - mu_k) / s_k)**2)\n    \n    return log_likelihood + log_prior\n\n\ndef run_mcmc_sampler(y_data, times, I, R0, Rk, sigma, mu_k, s_k, v_k, N, B, L, seed):\n    \"\"\"\n    Implements the Metropolis-Hastings MCMC sampler.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    m = len(mu_k)\n    \n    # Initial state of the chain (from prior mean)\n    x_current = mu_k.copy()\n    \n    # Store all samples for later processing\n    samples_x = np.zeros((N, m))\n    \n    # Compute initial log posterior\n    log_p_current = log_posterior(x_current, y_data, times, I, R0, Rk, sigma, mu_k, s_k)\n    \n    for i in range(N):\n        # Propose a new state\n        eta = rng.normal(0, v_k)\n        x_proposal = x_current + eta\n        \n        # Compute log posterior of the proposal\n        log_p_proposal = log_posterior(x_proposal, y_data, times, I, R0, Rk, sigma, mu_k, s_k)\n        \n        # Calculate acceptance probability in log space\n        log_alpha = log_p_proposal - log_p_current\n        \n        # Accept or reject\n        if np.log(rng.uniform())  log_alpha:\n            x_current = x_proposal\n            log_p_current = log_p_proposal\n            \n        samples_x[i, :] = x_current\n\n    # Post-processing: burn-in and thinning\n    retained_samples_x = samples_x[B::L, :]\n    \n    # Transform back to tau space\n    retained_samples_tau = np.exp(retained_samples_x)\n    \n    # Compute posterior mean\n    posterior_mean_tau = np.mean(retained_samples_tau, axis=0)\n    \n    return posterior_mean_tau\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}