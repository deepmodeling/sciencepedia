{
    "hands_on_practices": [
        {
            "introduction": "A crucial skill in battery modeling is translating raw experimental data into meaningful physical parameters. This first practice challenges you to derive a model from first principles—Fick's laws of diffusion—to analyze data from a Galvanostatic Intermittent Titration Technique (GITT) experiment. By connecting the observed voltage relaxation to the underlying lithium concentration changes, you will extract a key kinetic parameter, the solid-phase diffusion coefficient $D_s$ .",
            "id": "3937359",
            "problem": "You are given Galvanostatic Intermittent Titration Technique (GITT) relaxation data for a lithium-intercalation electrode comprised of monodisperse spherical active material particles, and your goal is to identify the solid-phase diffusion coefficient using first-principles modeling and parameterization logic. The relaxation segment begins immediately after a constant-current pulse is turned off. For sufficiently short relaxation times, assume diffusion in the vicinity of the particle surface can be approximated as semi-infinite and one-dimensional, and that the open-circuit voltage change is locally proportional to the change in the particle surface concentration. Starting from the following fundamental bases:\n\n- Fick’s second law in the solid phase for lithium concentration $c_s(r,t)$,\n- Fick’s first law relating molar flux density $J$ to the concentration gradient at the particle surface,\n- Linearization of the equilibrium potential with respect to the surface concentration using a known slope $dU/dc_s$,\n\nderive an expression that relates the slope of the voltage relaxation versus $\\sqrt{t}$ to the solid-phase diffusion coefficient $D_s$ and the applied current history. The derivation must begin from the diffusion equation in the solid phase, the boundary and initial conditions implied by the constant-current pulse and the subsequent zero-flux relaxation, and the local linear relationship between voltage and surface concentration. You may treat the spherical geometry as locally planar during the very early relaxation times and justify the use of the semi-infinite approximation on this basis.\n\nDefinitions and given quantities:\n\n- Let the particles be spheres of radius $R_p$ with total count $N_p$, each having surface area $A_p = 4\\pi R_p^2$, and a total particle surface area $A_{\\text{tot}} = N_p \\cdot 4\\pi R_p^2$.\n- Let the constant current magnitude applied during the pulse be $I_{\\text{tot}}$ in amperes, the number of electrons per intercalated lithium be $n$, and the Faraday constant be $F = 96485\\,\\text{C}\\,\\text{mol}^{-1}$.\n- The molar flux density at the particle surface during the pulse is $J = I_{\\text{tot}}/(n F A_{\\text{tot}})$ in $\\text{mol}\\,\\text{m}^{-2}\\,\\text{s}^{-1}$.\n- Upon current interruption, during the short-time relaxation regime, the measured voltage $U(t)$ exhibits a linear dependence on $\\sqrt{t}$ with slope $S = dU/d(\\sqrt{t})$ in $\\text{V}\\,\\text{s}^{-1/2}$.\n- The equilibrium potential sensitivity is known as $dU/dc_s$ in $\\text{V}\\,\\text{m}^3\\,\\text{mol}^{-1}$, and the relation between small changes in voltage and small changes in the particle surface concentration is $\\Delta U(t) \\approx (dU/dc_s)\\,\\Delta c_s(R_p,t)$.\n\nAssumptions:\n\n- Early-time relaxation after current interruption is used, such that the semi-infinite diffusion approximation is valid; i.e., $t \\ll R_p^2/D_s$.\n- Spatial variation is radial; near the surface and at early times the curvature is negligible and can be approximated by a semi-infinite Cartesian domain.\n- The voltage response is dominated by the change in particle surface concentration, and non-idealities such as double-layer capacitance and contact resistances are negligible over the chosen time window.\n\nTask:\n\n1. Based on the above definitions and assumptions, derive a relation that connects the measured slope $S$ to $D_s$, $J$, and $dU/dc_s$. The derivation must start with Fick’s second law and the boundary conditions, then connect concentration relaxation to voltage relaxation via the linearized equilibrium potential.\n2. Using the derived relation, compute $D_s$ for each test case described below. Express each $D_s$ in $\\text{m}^2/\\text{s}$.\n3. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each number in scientific notation with six significant digits (for example, $[1.234567e-08,9.876543e-12]$).\n\nUse $n = 1$ in all cases. The test suite contains four distinct cases to probe typical, higher-diffusivity, and lower-diffusivity regimes, as well as sensitivity to geometry and current:\n\n- Case $1$ (general case):\n  - $R_p = 5.0\\times 10^{-6}\\,\\text{m}$\n  - $N_p = 3.0\\times 10^{8}$\n  - $I_{\\text{tot}} = 1.0\\,\\text{A}$\n  - $dU/dc_s = 4.0\\times 10^{-5}\\,\\text{V}\\,\\text{m}^3\\,\\text{mol}^{-1}$\n  - $S = 1.5\\times 10^{-3}\\,\\text{V}\\,\\text{s}^{-1/2}$\n\n- Case $2$ (smaller slope implies larger $D_s$):\n  - $R_p = 5.0\\times 10^{-6}\\,\\text{m}$\n  - $N_p = 3.0\\times 10^{8}$\n  - $I_{\\text{tot}} = 1.0\\,\\text{A}$\n  - $dU/dc_s = 4.0\\times 10^{-5}\\,\\text{V}\\,\\text{m}^3\\,\\text{mol}^{-1}$\n  - $S = 5.0\\times 10^{-4}\\,\\text{V}\\,\\text{s}^{-1/2}$\n\n- Case $3$ (larger slope implies smaller $D_s$):\n  - $R_p = 5.0\\times 10^{-6}\\,\\text{m}$\n  - $N_p = 3.0\\times 10^{8}$\n  - $I_{\\text{tot}} = 1.0\\,\\text{A}$\n  - $dU/dc_s = 4.0\\times 10^{-5}\\,\\text{V}\\,\\text{m}^3\\,\\text{mol}^{-1}$\n  - $S = 4.0\\times 10^{-3}\\,\\text{V}\\,\\text{s}^{-1/2}$\n\n- Case $4$ (different geometry and current; tests sensitivity):\n  - $R_p = 2.0\\times 10^{-6}\\,\\text{m}$\n  - $N_p = 2.0\\times 10^{8}$\n  - $I_{\\text{tot}} = 0.5\\,\\text{A}$\n  - $dU/dc_s = 6.0\\times 10^{-5}\\,\\text{V}\\,\\text{m}^3\\,\\text{mol}^{-1}$\n  - $S = 1.0\\times 10^{-3}\\,\\text{V}\\,\\text{s}^{-1/2}$\n\nYour program must compute $A_{\\text{tot}}$, the molar flux density $J$, and then $D_s$ for each case, and print the four $D_s$ values in the specified single-line output format.",
            "solution": "The problem requires the derivation of an expression for the solid-phase diffusion coefficient, $D_s$, from Galvanostatic Intermittent Titration Technique (GITT) relaxation data and its subsequent calculation for a set of test cases. The derivation will begin with fundamental principles of diffusion and electrochemistry, adhering to the specified assumptions.\n\n**Part 1: Derivation of the relationship for $D_s$**\n\nThe derivation proceeds in three main stages: (1) solving the diffusion equation for the concentration profile under the GITT conditions, (2) relating the concentration change to the voltage change, and (3) extracting the relationship between the experimentally measured slope $S$ and the diffusion coefficient $D_s$.\n\n**1. Concentration Profile from Diffusion Equation**\n\nWe begin with Fick's second law of diffusion. The problem states that for short relaxation times, the diffusion near the surface of the spherical particles can be approximated as semi-infinite and one-dimensional. Let $x$ be the spatial coordinate pointing from the particle surface ($x=0$) into the particle's interior ($x>0$), and $c_s(x,t)$ be the concentration of lithium in the solid phase. The governing partial differential equation is:\n$$\n\\frac{\\partial c_s(x,t)}{\\partial t} = D_s \\frac{\\partial^2 c_s(x,t)}{\\partial x^2}\n$$\nwhere $D_s$ is the solid-phase diffusion coefficient, assumed to be constant.\n\nThe GITT experiment involves applying a constant current pulse for a duration $\\tau$, followed by a relaxation period where the current is zero. This process can be modeled using the principle of superposition for the linear diffusion equation. The current pulse corresponds to a constant molar flux density, $J$, at the particle surface. Turning off the current is equivalent to superimposing a flux of $-J$ at the moment the pulse ends.\n\nLet the experiment begin at time $t_p=0$. A constant flux $J$ is applied at the boundary $x=0$ for $0 \\le t_p \\le \\tau$. The boundary condition is given by Fick's first law:\n$$\n-D_s \\frac{\\partial c_s}{\\partial x}\\bigg|_{x=0} = J\n$$\nThe solution to the diffusion equation in a semi-infinite medium with an initial uniform concentration $c_0$ and a constant flux boundary condition is well-known. The change in concentration at the surface ($x=0$) as a function of time $t_p$ is:\n$$\n\\Delta c_s(0, t_p) = c_s(0, t_p) - c_0 = \\frac{2J\\sqrt{t_p}}{\\sqrt{\\pi D_s}}\n$$\nAt time $t_p = \\tau$, the current is turned off. We can model this by adding a flux of $-J$ for all times $t_p > \\tau$. The total change in surface concentration for $t_p > \\tau$ is the sum of the response to the flux $+J$ starting at $t_p=0$ and the response to the flux $-J$ starting at $t_p=\\tau$.\n$$\n\\Delta c_{s, \\text{total}}(0, t_p) = \\frac{2J\\sqrt{t_p}}{\\sqrt{\\pi D_s}} - \\frac{2J\\sqrt{t_p - \\tau}}{\\sqrt{\\pi D_s}} = \\frac{2J}{\\sqrt{\\pi D_s}} \\left( \\sqrt{t_p} - \\sqrt{t_p - \\tau} \\right)\n$$\nThis equation describes the evolution of the surface concentration relative to the initial concentration $c_0$ during the relaxation phase.\n\nLet us define the relaxation time as $t = t_p - \\tau$. The relaxation starts at $t=0$. Substituting $t_p = t + \\tau$ into the equation above gives the total concentration change as a function of relaxation time $t$:\n$$\n\\Delta c_{s, \\text{total}}(0, \\tau+t) = \\frac{2J}{\\sqrt{\\pi D_s}} \\left( \\sqrt{\\tau+t} - \\sqrt{t} \\right)\n$$\nWe are interested in the change in concentration *during* the relaxation period, i.e., relative to the concentration at the end of the pulse ($t_p=\\tau$, or $t=0$). The concentration change at the end of the pulse is $\\Delta c_s(0, \\tau) = \\frac{2J\\sqrt{\\tau}}{\\sqrt{\\pi D_s}}$. The change in concentration during relaxation is therefore:\n$$\n\\Delta c_{s, \\text{relax}}(0, t) = \\Delta c_{s, \\text{total}}(0, \\tau+t) - \\Delta c_s(0, \\tau) = \\frac{2J}{\\sqrt{\\pi D_s}} \\left( \\sqrt{\\tau+t} - \\sqrt{t} - \\sqrt{\\tau} \\right)\n$$\nThe problem specifies that the analysis is for \"sufficiently short relaxation times\". This implies that the relaxation time $t$ is much smaller than the pulse duration $\\tau$ (i.e., $t \\ll \\tau$). Under this condition, we can use a Taylor expansion for the term $\\sqrt{\\tau+t}$:\n$$\n\\sqrt{\\tau+t} = \\sqrt{\\tau(1+t/\\tau)} \\approx \\sqrt{\\tau}\\left(1 + \\frac{1}{2}\\frac{t}{\\tau}\\right)\n$$\nSubstituting this approximation into the expression for $\\Delta c_{s, \\text{relax}}(0, t)$:\n$$\n\\Delta c_{s, \\text{relax}}(0, t) \\approx \\frac{2J}{\\sqrt{\\pi D_s}} \\left( \\left(\\sqrt{\\tau} + \\frac{t}{2\\sqrt{\\tau}}\\right) - \\sqrt{t} - \\sqrt{\\tau} \\right) = \\frac{2J}{\\sqrt{\\pi D_s}} \\left( \\frac{t}{2\\sqrt{\\tau}} - \\sqrt{t} \\right)\n$$\nFor very short times ($t \\to 0$), the $\\sqrt{t}$ term is dominant compared to the $t$ term. Thus, the expression simplifies to:\n$$\n\\Delta c_{s, \\text{relax}}(0, t) \\approx -\\frac{2J}{\\sqrt{\\pi D_s}}\\sqrt{t}\n$$\nThis equation shows that for short relaxation times, the change in surface concentration is linearly proportional to the square root of the relaxation time.\n\n**2. Voltage Response**\n\nThe problem states that the change in open-circuit voltage, $\\Delta U(t)$, is locally proportional to the change in surface concentration, $\\Delta c_s(R_p, t)$, via a known sensitivity, $dU/dc_s$:\n$$\n\\Delta U(t) \\approx \\left(\\frac{dU}{dc_s}\\right) \\Delta c_s(R_p, t)\n$$\nApplying this to the change during relaxation, $\\Delta U_{\\text{relax}}(t)$:\n$$\n\\Delta U_{\\text{relax}}(t) \\approx \\left(\\frac{dU}{dc_s}\\right) \\Delta c_{s, \\text{relax}}(0, t) \\approx -\\left(\\frac{dU}{dc_s}\\right) \\frac{2J}{\\sqrt{\\pi D_s}}\\sqrt{t}\n$$\nThis derived relationship confirms the experimental observation stated in the problem: the voltage during relaxation, $U(t)$, exhibits a linear dependence on $\\sqrt{t}$.\n\n**3. Relation between Slope $S$ and $D_s$**\n\nThe slope $S$ is defined as $S = dU/d(\\sqrt{t})$. From our derived expression for the voltage change during relaxation, we can compute this slope:\n$$\nS = \\frac{d(\\Delta U_{\\text{relax}}(t))}{d(\\sqrt{t})} = -\\left(\\frac{dU}{dc_s}\\right) \\frac{2J}{\\sqrt{\\pi D_s}}\n$$\nThe problem provides positive values for $S$ and $dU/dc_s$. As the surface concentration decreases during relaxation, the voltage (which increases with $c_s$) also decreases, making the true slope negative. Therefore, the given $S$ must be interpreted as the magnitude of the slope:\n$$\nS = \\left| -\\left(\\frac{dU}{dc_s}\\right) \\frac{2J}{\\sqrt{\\pi D_s}} \\right| = \\left(\\frac{dU}{dc_s}\\right) \\frac{2J}{\\sqrt{\\pi D_s}}\n$$\nOur goal is to find an expression for $D_s$. Rearranging the equation:\n$$\n\\sqrt{\\pi D_s} = \\frac{2J}{S} \\left(\\frac{dU}{dc_s}\\right)\n$$\nSquaring both sides gives:\n$$\n\\pi D_s = \\left( \\frac{2J}{S} \\left(\\frac{dU}{dc_s}\\right) \\right)^2 = \\frac{4J^2}{S^2} \\left(\\frac{dU}{dc_s}\\right)^2\n$$\nFinally, isolating $D_s$, we arrive at the desired relationship:\n$$\nD_s = \\frac{4}{\\pi} \\left( \\frac{J}{S} \\frac{dU}{dc_s} \\right)^2\n$$\nThis expression relates the solid-phase diffusion coefficient $D_s$ to the measured slope $S$, the applied flux density $J$, and the thermodynamic factor $dU/dc_s$. The flux $J$ is calculated from the total applied current $I_{\\text{tot}}$ and the total active surface area $A_{\\text{tot}}$:\n$$\nJ = \\frac{I_{\\text{tot}}}{nF A_{\\text{tot}}}, \\quad \\text{where} \\quad A_{\\text{tot}} = N_p \\cdot 4\\pi R_p^2\n$$\n\n**Part 2: Calculation of $D_s$ for Test Cases**\n\nUsing the derived formula, we will now compute $D_s$ for the four test cases provided. The values $n=1$ and $F = 96485\\,\\text{C}\\,\\text{mol}^{-1}$ are used throughout. The calculation for each case involves first computing $A_{\\text{tot}}$ and $J$, then substituting these into the expression for $D_s$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the solid-phase diffusion coefficient (D_s) for a series of\n    GITT experiment test cases based on a derived first-principles model.\n    \"\"\"\n    \n    # Define physical constants\n    F = 96485  # Faraday constant in C/mol\n    n = 1      # Number of electrons transferred per Li ion\n\n    # Test cases from the problem statement\n    # Each tuple contains: (R_p, N_p, I_tot, dU_dcs, S)\n    test_cases = [\n        # Case 1 (general case)\n        (5.0e-6, 3.0e8, 1.0, 4.0e-5, 1.5e-3),\n        # Case 2 (smaller slope implies larger D_s)\n        (5.0e-6, 3.0e8, 1.0, 4.0e-5, 5.0e-4),\n        # Case 3 (larger slope implies smaller D_s)\n        (5.0e-6, 3.0e8, 1.0, 4.0e-5, 4.0e-3),\n        # Case 4 (different geometry and current)\n        (2.0e-6, 2.0e8, 0.5, 6.0e-5, 1.0e-3),\n    ]\n\n    results = []\n    for case in test_cases:\n        Rp, Np, Itot, dU_dcs, S = case\n\n        # Step 1: Calculate the total particle surface area (A_tot)\n        # A_p = 4 * pi * R_p^2 for a single spherical particle\n        # A_tot = N_p * A_p\n        A_tot = Np * 4.0 * np.pi * (Rp**2)\n\n        # Step 2: Calculate the molar flux density (J) at the particle surface\n        # J = I_tot / (n * F * A_tot)\n        J = Itot / (n * F * A_tot)\n\n        # Step 3: Calculate the solid-phase diffusion coefficient (D_s)\n        # The derived formula is D_s = (4/pi) * (J * dU/dc_s / S)^2\n        term_in_paren = (J * dU_dcs) / S\n        D_s = (4.0 / np.pi) * (term_in_paren**2)\n        \n        results.append(D_s)\n\n    # Format the results into a single string as specified:\n    # Comma-separated list in scientific notation with six significant digits.\n    # The format specifier {:.5e} provides 1 digit before the decimal and 5 after,\n    # totaling 6 significant digits.\n    formatted_results = [f\"{res:.5e}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Parameter values are never known with perfect certainty; they are estimates subject to experimental noise and model assumptions. This exercise moves beyond single-point estimation to a more robust statistical approach using weighted least squares to determine the Bruggeman exponent $\\beta$ for an electrolyte. You will not only find the best-fit value but also quantify its uncertainty, learning how the precision and range of your data points directly impact the confidence in your parameter .",
            "id": "3937395",
            "problem": "You are tasked with parameterizing a physics-based scaling for electrolyte effective conductivity in a porous medium and identifying a key structural parameter. Consider a porous electrode saturated with a liquid electrolyte of intrinsic conductivity. Under homogenization in porous media and Ohm’s law, the effective bulk ionic conduction may be modeled by a dimensionless porosity exponent. Specifically, assume the following widely used and experimentally supported scaling law in porous media: the effective electrolyte conductivity $\\kappa_{\\mathrm{eff}}$ as a function of porosity $\\varepsilon$ follows a power law $\\kappa_{\\mathrm{eff}}(\\varepsilon) = \\kappa_{0}\\,\\varepsilon^{\\beta}$, where $\\kappa_{0} > 0$ is a constant reference conductivity (for the same electrolyte in a non-tortuous geometry), and $\\beta$ is a dimensionless porosity-tortuosity exponent that encodes morphology and transport impediments.\n\nMeasurements are taken of $\\kappa_{\\mathrm{eff}}$ at different porosities $\\varepsilon_{i}$, and you should treat these as realizations of a stochastic measurement model in logarithmic space. Define $x_{i} = \\ln(\\varepsilon_{i})$ and $y_{i}^{\\mathrm{obs}} = \\ln(\\kappa_{\\mathrm{eff},i}^{\\mathrm{obs}})$, and assume additive Gaussian noise in logarithmic space $y_{i}^{\\mathrm{obs}} = \\alpha + \\beta x_{i} + e_{i}$, where $\\alpha = \\ln(\\kappa_{0})$, $e_{i} \\sim \\mathcal{N}(0,\\sigma_{i}^{2})$ are independent, and all $\\sigma_{i} > 0$ are known. Under these assumptions, estimating $\\beta$ and its uncertainty reduces to a weighted linear regression in the transformed variables.\n\nStarting from the fundamental physical definition of effective conductivity via Ohm’s law in porous media, and treating the logarithmic measurement model as a consequence of multiplicative errors on conductivity measurements, construct a parameter estimation algorithm that:\n- Sets up the weighted least squares estimator for $(\\alpha,\\beta)$ using the design matrix with columns $[1, x_{i}]$ and diagonal weight matrix $W = \\mathrm{diag}(w_{i})$ with $w_{i} = 1/\\sigma_{i}^{2}$.\n- Computes the maximum likelihood estimate for $\\beta$ under the Gaussian noise model in logarithmic space.\n- Computes the standard uncertainty (one standard deviation) for $\\beta$ using the inverse of the Fisher information, which equals the parameter covariance matrix $(X^{\\mathsf{T}} W X)^{-1}$ under the stated assumptions. The uncertainty to report is $\\sqrt{\\left[(X^{\\mathsf{T}} W X)^{-1}\\right]_{22}}$, the square root of the $(2,2)$ element of the covariance matrix corresponding to $\\beta$.\n\nAll $\\kappa_{\\mathrm{eff}}$ measurements are given in siemens per meter, which is abbreviated as S/m. The porosity is dimensionless and strictly between $0$ and $1$. Use the natural logarithm (base $e$) throughout.\n\nYour program must implement the above and process the following test suite of three cases, each with three measurements:\n- Test case $1$ (general case with well-separated porosities and moderate uncertainties):\n  - Porosities $\\varepsilon$: $[0.30,\\,0.60,\\,0.75]$\n  - Measured effective conductivities $\\kappa_{\\mathrm{eff}}$ in S/m: $[0.42,\\,1.15,\\,1.60]$\n  - Log-space standard deviations $\\sigma$: $[0.05,\\,0.05,\\,0.05]$\n- Test case $2$ (boundary case with closely clustered porosities leading to larger geometric parameter uncertainty):\n  - Porosities $\\varepsilon$: $[0.58,\\,0.60,\\,0.62]$\n  - Measured effective conductivities $\\kappa_{\\mathrm{eff}}$ in S/m: $[1.10,\\,1.16,\\,1.22]$\n  - Log-space standard deviations $\\sigma$: $[0.02,\\,0.02,\\,0.02]$\n- Test case $3$ (edge case with widely separated porosities and heteroscedastic uncertainties):\n  - Porosities $\\varepsilon$: $[0.20,\\,0.50,\\,0.90]$\n  - Measured effective conductivities $\\kappa_{\\mathrm{eff}}$ in S/m: $[0.27,\\,1.05,\\,2.60]$\n  - Log-space standard deviations $\\sigma$: $[0.10,\\,0.05,\\,0.20]$\n\nFor each test case, estimate $\\beta$ and its standard uncertainty. The final output must be dimensionless floats. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-element list $[\\hat{\\beta},\\,u_{\\beta}]$ for the corresponding test case, with each float rounded to six decimal places, for example: $[[\\hat{\\beta}_{1},u_{\\beta,1}],\\,[\\hat{\\beta}_{2},u_{\\beta,2}],\\,[\\hat{\\beta}_{3},u_{\\beta,3}]]$.",
            "solution": "The problem of estimating the porosity-tortuosity exponent $\\beta$ from experimental data is a classic parameter identification task in materials science and electrochemistry. The problem is well-posed and scientifically grounded. I will proceed with a full solution.\n\nThe physical model provided is the power-law relationship for effective conductivity $\\kappa_{\\mathrm{eff}}$ in a porous medium:\n$$\n\\kappa_{\\mathrm{eff}}(\\varepsilon) = \\kappa_{0} \\, \\varepsilon^{\\beta}\n$$\nwhere $\\varepsilon$ is the porosity, $\\kappa_{0}$ is a reference conductivity, and $\\beta$ is the dimensionless exponent to be determined. This model is a form of the Bruggeman correlation or Archie's law, which is widely used to describe transport properties in composite media.\n\nTo facilitate parameter estimation from experimental data $(\\varepsilon_i, \\kappa_{\\mathrm{eff},i}^{\\mathrm{obs}})$, we linearize the model by taking the natural logarithm of both sides:\n$$\n\\ln(\\kappa_{\\mathrm{eff}}) = \\ln(\\kappa_{0}) + \\beta \\ln(\\varepsilon)\n$$\nThis transforms the power-law relationship into a linear one. We define the transformed variables $y = \\ln(\\kappa_{\\mathrm{eff}})$, $x = \\ln(\\varepsilon)$, and the constant $\\alpha = \\ln(\\kappa_{0})$. The model becomes:\n$$\ny = \\alpha + \\beta x\n$$\nThe problem specifies a stochastic measurement model where the observed values, $y_{i}^{\\mathrm{obs}} = \\ln(\\kappa_{\\mathrm{eff},i}^{\\mathrm{obs}})$, contain additive Gaussian noise, $e_i$, with known, independent variances, $\\sigma_i^2$:\n$$\ny_{i}^{\\mathrm{obs}} = \\alpha + \\beta x_{i} + e_{i}, \\quad \\text{where } e_{i} \\sim \\mathcal{N}(0, \\sigma_{i}^{2})\n$$\nOur goal is to find the best estimates for the parameters $\\alpha$ and $\\beta$, specifically $\\hat{\\beta}$, and to quantify the uncertainty of this estimate, $u_{\\beta}$.\n\nUnder the assumption of independent Gaussian errors, the maximum likelihood estimator (MLE) for the parameters $(\\alpha, \\beta)$ is the one that minimizes the weighted sum of squared residuals, often denoted as $\\chi^2$:\n$$\n\\chi^2(\\alpha, \\beta) = \\sum_{i=1}^{n} \\left( \\frac{y_{i}^{\\mathrm{obs}} - (\\alpha + \\beta x_i)}{\\sigma_i} \\right)^2 = \\sum_{i=1}^{n} w_i (y_{i}^{\\mathrm{obs}} - (\\alpha + \\beta x_i))^2\n$$\nwhere $n$ is the number of measurements and $w_i = 1/\\sigma_i^2$ are the weights. This is the principle of Weighted Least Squares (WLS).\n\nTo solve this minimization problem efficiently, we adopt a matrix formulation. Let the vector of parameters be $\\boldsymbol{\\theta}$, the vector of observations be $\\mathbf{y}$, and the design matrix be $X$:\n$$\n\\boldsymbol{\\theta} = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}, \\quad \\mathbf{y} = \\begin{pmatrix} y_1^{\\mathrm{obs}} \\\\ y_2^{\\mathrm{obs}} \\\\ \\vdots \\\\ y_n^{\\mathrm{obs}} \\end{pmatrix}, \\quad X = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix}\n$$\nLet $W$ be the diagonal matrix of weights:\n$$\nW = \\mathrm{diag}(w_1, w_2, \\dots, w_n) = \\begin{pmatrix} 1/\\sigma_1^2 & 0 & \\dots & 0 \\\\ 0 & 1/\\sigma_2^2 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1/\\sigma_n^2 \\end{pmatrix}\n$$\nThe $\\chi^2$ objective function can be written in matrix form as:\n$$\n\\chi^2(\\boldsymbol{\\theta}) = (\\mathbf{y} - X\\boldsymbol{\\theta})^{\\mathsf{T}} W (\\mathbf{y} - X\\boldsymbol{\\theta})\n$$\nThe solution that minimizes this expression is found by setting the gradient with respect to $\\boldsymbol{\\theta}$ to zero, which yields the normal equations for WLS:\n$$\n(X^{\\mathsf{T}} W X) \\hat{\\boldsymbol{\\theta}} = X^{\\mathsf{T}} W \\mathbf{y}\n$$\nThe WLS estimate for the parameter vector $\\hat{\\boldsymbol{\\theta}}$ is therefore:\n$$\n\\hat{\\boldsymbol{\\theta}} = (X^{\\mathsf{T}} W X)^{-1} X^{\\mathsf{T}} W \\mathbf{y}\n$$\nThe estimate for the porosity exponent, $\\hat{\\beta}$, is the second element of the vector $\\hat{\\boldsymbol{\\theta}}$.\n\nA key result from statistical theory is that the covariance matrix of the estimated parameters, $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$, is given by the inverse of the Fisher information matrix. For this linear model with Gaussian noise, this is simply:\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = (X^{\\mathsf{T}} W X)^{-1}\n$$\nThe matrix $X^{\\mathsf{T}} W X$ is a $2 \\times 2$ matrix:\n$$\nX^{\\mathsf{T}} W X = \\begin{pmatrix} \\sum_{i=1}^{n} w_i & \\sum_{i=1}^{n} w_i x_i \\\\ \\sum_{i=1}^{n} w_i x_i & \\sum_{i=1}^{n} w_i x_i^2 \\end{pmatrix}\n$$\nThe diagonal elements of $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$ are the variances of the individual parameter estimates. We are interested in the variance of $\\hat{\\beta}$, which is the second diagonal element, denoted $(\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}))_{22}$. The standard uncertainty, $u_{\\beta}$, is the square root of this variance:\n$$\nu_{\\beta} = \\sqrt{ \\left[ (X^{\\mathsf{T}} W X)^{-1} \\right]_{22} }\n$$\nThe algorithm will implement these matrix equations. For each test case, we will:\n1.  Take the natural logarithm of the given porosity, $\\varepsilon_i$, and conductivity, $\\kappa_{\\mathrm{eff},i}$, data to obtain $x_i$ and $y_i^{\\mathrm{obs}}$.\n2.  Construct the design matrix $X$, the observation vector $\\mathbf{y}$, and the weight matrix $W$ from the $\\sigma_i$ values.\n3.  Compute the matrix product $C = X^{\\mathsf{T}} W X$.\n4.  Invert this matrix to obtain the covariance matrix, $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = C^{-1}$.\n5.  Compute the parameter vector estimate $\\hat{\\boldsymbol{\\theta}} = C^{-1} X^{\\mathsf{T}} W \\mathbf{y}$.\n6.  The estimate $\\hat{\\beta}$ is the second element of $\\hat{\\boldsymbol{\\theta}}$.\n7.  The standard uncertainty $u_{\\beta}$ is the square root of the second element on the diagonal of $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$.\n\nThis procedure will be applied to each of the three test cases provided.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the porosity-tortuosity exponent and its uncertainty for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"epsilons\": np.array([0.30, 0.60, 0.75]),\n            \"kappas_eff\": np.array([0.42, 1.15, 1.60]),\n            \"sigmas\": np.array([0.05, 0.05, 0.05]),\n        },\n        # Test case 2\n        {\n            \"epsilons\": np.array([0.58, 0.60, 0.62]),\n            \"kappas_eff\": np.array([1.10, 1.16, 1.22]),\n            \"sigmas\": np.array([0.02, 0.02, 0.02]),\n        },\n        # Test case 3\n        {\n            \"epsilons\": np.array([0.20, 0.50, 0.90]),\n            \"kappas_eff\": np.array([0.27, 1.05, 2.60]),\n            \"sigmas\": np.array([0.10, 0.05, 0.20]),\n        },\n    ]\n\n    def estimate_beta_and_uncertainty(epsilons, kappas_eff, sigmas):\n        \"\"\"\n        Performs weighted linear regression to estimate beta and its uncertainty.\n        \n        Args:\n            epsilons (np.ndarray): Array of porosity values.\n            kappas_eff (np.ndarray): Array of measured effective conductivities.\n            sigmas (np.ndarray): Array of standard deviations in log-space.\n            \n        Returns:\n            tuple: A tuple containing the estimated beta (float) and its standard\n                   uncertainty (float).\n        \"\"\"\n        # Step 1: Transform variables to linear space (y = alpha + beta*x)\n        x = np.log(epsilons)\n        y_obs = np.log(kappas_eff)\n        \n        # Step 2: Set up the components for Weighted Least Squares (WLS)\n        # Design matrix X\n        X = np.vstack((np.ones_like(x), x)).T\n        \n        # Weights w_i = 1/sigma_i^2\n        weights = 1.0 / (sigmas**2)\n        \n        # Weight matrix W (diagonal matrix of weights)\n        W = np.diag(weights)\n        \n        # Step 3: Compute the WLS solution for the parameters [alpha, beta]\n        # Calculate the matrix (X^T * W * X)\n        XT_W_X = X.T @ W @ X\n        \n        # Calculate its inverse, which is the covariance matrix of parameters\n        try:\n            cov_matrix = np.linalg.inv(XT_W_X)\n        except np.linalg.LinAlgError:\n            # This case occurs if the matrix is singular (e.g., all x values are the same)\n            return (np.nan, np.nan)\n            \n        # Calculate the vector (X^T * W * y)\n        XT_W_y = X.T @ W @ y_obs\n        \n        # The parameter vector estimate theta_hat = [alpha_hat, beta_hat]\n        theta_hat = cov_matrix @ XT_W_y\n        \n        # Step 4: Extract the results for beta\n        # The estimate for beta is the second element of theta_hat\n        beta_hat = theta_hat[1]\n        \n        # The standard uncertainty for beta is the square root of the (2,2) element\n        # of the covariance matrix.\n        uncertainty_beta = np.sqrt(cov_matrix[1, 1])\n        \n        return beta_hat, uncertainty_beta\n\n    results = []\n    for case in test_cases:\n        beta, u_beta = estimate_beta_and_uncertainty(\n            case[\"epsilons\"], case[\"kappas_eff\"], case[\"sigmas\"]\n        )\n        results.append([beta, u_beta])\n    \n    # Format the final output string as specified in the problem\n    formatted_results = [f\"[{beta:.6f},{u_beta:.6f}]\" for beta, u_beta in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Effective parameterization is not just about analyzing existing data, but also about designing new experiments to gather the most informative data possible. This advanced practice introduces the Fisher Information Matrix as a powerful tool for a priori experimental design. You will quantitatively compare the information content of time-domain and frequency-domain (EIS) experiments, learning how to strategically combine datasets to minimize the uncertainty of multiple parameters in an equivalent circuit model .",
            "id": "3937437",
            "problem": "Consider a physics-based equivalent circuit for a lithium-ion cell that is commonly used in automated battery design and simulation: a series ohmic resistance in ohms, denoted by $R_s$, followed by a parallel combination of a charge-transfer resistance in ohms, denoted by $R_{ct}$, and a double-layer capacitance in farads, denoted by $C_{dl}$. Assume a galvanostatic current input of amplitude $I_0$ in amperes. For time-domain experiments, a current step of magnitude $I_0$ is applied at time $t=0$, and the terminal voltage is measured at a set of times $t_k$ in seconds. For frequency-domain experiments using Electrochemical Impedance Spectroscopy (EIS), a small-signal sinusoidal current perturbation at angular frequency $\\omega$ in radians per second is applied, and the complex impedance $Z(\\mathrm{j}\\omega)$ in ohms is measured; the real and imaginary parts of the impedance are recorded as independent scalar observations. Assume additive, independent, zero-mean Gaussian measurement noise in both domains: for the time domain, the voltage noise has standard deviation $\\sigma_V$ in volts; for the frequency domain, the real and imaginary parts of the impedance each have standard deviation $\\sigma_Z$ in ohms.\n\nYour task is to compute the expected reduction in marginal parameter uncertainty when augmenting a time-domain dataset with EIS measurements, by evaluating and combining the Fisher information matrices from both domains. Use the following fundamental base:\n- For a parametric measurement model $y = h(\\boldsymbol{\\theta}) + \\varepsilon$ with parameter vector $\\boldsymbol{\\theta}$ and independent, zero-mean Gaussian noise $\\varepsilon$ with covariance matrix $\\Sigma$, the Fisher information matrix is $J = \\sum_i \\left(\\nabla_{\\boldsymbol{\\theta}} h_i\\right)^\\top \\Sigma_i^{-1} \\left(\\nabla_{\\boldsymbol{\\theta}} h_i\\right)$, where the sum is over independent observations $i$ and $h_i$ is the model output for observation $i$.\n- For independent datasets, the total Fisher information is additive: $J_{\\text{total}} = J_1 + J_2$.\n- The Cramér–Rao lower bound (CRLB) approximates the achievable covariance of any unbiased estimator by $P \\approx J^{-1}$; when $J$ is not invertible, use the Moore–Penrose pseudoinverse.\n\nStarting only from Kirchhoff’s laws and the constitutive relation for the capacitor $i_C(t) = C \\,\\mathrm{d}v_C(t)/\\mathrm{d}t$, derive the time-domain terminal voltage response to a step current input and the frequency-domain impedance function for the given circuit. Then, compute the Jacobians of these responses with respect to the parameters $\\boldsymbol{\\theta} = [R_s, R_{ct}, C_{dl}]^\\top$. Using these Jacobians, assemble the time-domain Fisher information matrix $J_{\\text{time}}$ and the EIS Fisher information matrix $J_{\\text{eis}}$. Compute the time-only covariance $P_{\\text{time}} \\approx J_{\\text{time}}^{-1}$ and the combined covariance $P_{\\text{comb}} \\approx \\left(J_{\\text{time}} + J_{\\text{eis}}\\right)^{-1}$, using the Moore–Penrose pseudoinverse when needed. Finally, report the elementwise ratios of the marginal variances on the diagonal, $\\operatorname{diag}(P_{\\text{comb}}) \\oslash \\operatorname{diag}(P_{\\text{time}})$, for the three parameters $R_s$, $R_{ct}$, and $C_{dl}$, in that order. These ratios are unitless decimals; values less than $1$ indicate a reduction in uncertainty when adding EIS.\n\nCompute the above for the following test suite. For each case, use $I_0 = 1.0 \\,\\mathrm{A}$. For the time-domain dataset, use the specified measurement times in seconds. For the EIS dataset, use the specified angular frequencies in radians per second. Noise levels are given for each domain. All resistances must be in ohms, capacitances in farads, voltages in volts, times in seconds, and angular frequencies in radians per second. Express the final ratios as decimals rounded to six places.\n\nTest suite (each case is a tuple specifying parameters and data):\n- Case A (general, informative in both domains):\n  - Parameters: $R_s = 0.01$, $R_{ct} = 0.05$, $C_{dl} = 5.0$\n  - Time samples $t_k$: $[0.02,\\,0.1,\\,0.5,\\,1.0,\\,2.0]$\n  - EIS angular frequencies $\\omega_k$: $[0.5,\\,1.0,\\,5.0,\\,10.0,\\,50.0]$\n  - Noise: $\\sigma_V = 1.0\\times 10^{-4} \\,\\mathrm{V},\\; \\sigma_Z = 1.0\\times 10^{-3} \\,\\Omega$\n- Case B (EIS dominated by noise):\n  - Parameters: $R_s = 0.01$, $R_{ct} = 0.05$, $C_{dl} = 5.0$\n  - Time samples $t_k$: $[0.02,\\,0.1,\\,0.5,\\,1.0,\\,2.0]$\n  - EIS angular frequencies $\\omega_k$: $[0.5,\\,1.0,\\,5.0,\\,10.0,\\,50.0]$\n  - Noise: $\\sigma_V = 1.0\\times 10^{-4} \\,\\mathrm{V},\\; \\sigma_Z = 5.0\\times 10^{-2} \\,\\Omega$\n- Case C (short time window; EIS adds critical information):\n  - Parameters: $R_s = 0.01$, $R_{ct} = 0.05$, $C_{dl} = 5.0$\n  - Time samples $t_k$: $[0.001,\\,0.002,\\,0.005,\\,0.01]$\n  - EIS angular frequencies $\\omega_k$: $[0.1,\\,1.0,\\,10.0,\\,100.0]$\n  - Noise: $\\sigma_V = 1.0\\times 10^{-4} \\,\\mathrm{V},\\; \\sigma_Z = 1.0\\times 10^{-3} \\,\\Omega$\n- Case D (high-frequency EIS only; limited added information):\n  - Parameters: $R_s = 0.01$, $R_{ct} = 0.05$, $C_{dl} = 5.0$\n  - Time samples $t_k$: $[0.02,\\,0.1,\\,0.5,\\,1.0,\\,2.0]$\n  - EIS angular frequencies $\\omega_k$: $[500.0,\\,1000.0]$\n  - Noise: $\\sigma_V = 1.0\\times 10^{-4} \\,\\mathrm{V},\\; \\sigma_Z = 1.0\\times 10^{-3} \\,\\Omega$\n\nProgram requirements:\n- Implement the derivation-based models and Jacobians described above to compute the Fisher information matrices for both domains and their combination.\n- Use the Moore–Penrose pseudoinverse to compute covariance approximations when inversion is unstable or not possible.\n- For each case, output the three variance ratios $\\left[\\frac{P_{\\text{comb},11}}{P_{\\text{time},11}},\\,\\frac{P_{\\text{comb},22}}{P_{\\text{time},22}},\\,\\frac{P_{\\text{comb},33}}{P_{\\text{time},33}}\\right]$, rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list of three ratios for one case, in the order A, B, C, D. For example, a valid output format is $[\\,[r_{A,1},r_{A,2},r_{A,3}],\\,[r_{B,1},r_{B,2},r_{B,3}],\\,[r_{C,1},r_{C,2},r_{C,3}],\\,[r_{D,1},r_{D,2},r_{D,3}]\\,]$.",
            "solution": "The user's request is a valid scientific problem. This verdict is reached after a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Circuit Model**: An ohmic resistor $R_s$ in series with a parallel combination of a charge-transfer resistance $R_{ct}$ and a double-layer capacitance $C_{dl}$.\n- **Parameter Vector**: $\\boldsymbol{\\theta} = [R_s, R_{ct}, C_{dl}]^\\top$.\n- **Time-Domain Experiment**:\n    - **Input**: Galvanostatic current step of amplitude $I_0$ applied at $t=0$.\n    - **Measurements**: Terminal voltage $V(t)$ measured at a set of times $t_k$.\n    - **Noise**: Additive, independent, zero-mean Gaussian noise on voltage with standard deviation $\\sigma_V$.\n- **Frequency-Domain (EIS) Experiment**:\n    - **Input**: Small-signal sinusoidal current perturbation at angular frequency $\\omega$.\n    - **Measurements**: Real and imaginary parts of the complex impedance $Z(\\mathrm{j}\\omega)$ are recorded as independent scalar observations.\n    - **Noise**: Additive, independent, zero-mean Gaussian noise on real and imaginary impedance parts, each with standard deviation $\\sigma_Z$.\n- **Fisher Information Matrix (FIM)**: For a model $y = h(\\boldsymbol{\\theta}) + \\varepsilon$ with noise covariance $\\Sigma$, the FIM is $J = \\sum_i \\left(\\nabla_{\\boldsymbol{\\theta}} h_i\\right)^\\top \\Sigma_i^{-1} \\left(\\nabla_{\\boldsymbol{\\theta}} h_i\\right)$.\n- **FIM Additivity**: For independent datasets, $J_{\\text{total}} = J_{\\text{time}} + J_{\\text{eis}}$.\n- **Cramér–Rao Lower Bound (CRLB)**: The covariance matrix of an unbiased estimator is approximated by $P \\approx J^{-1}$. The Moore–Penrose pseudoinverse ($J^\\dagger$) is to be used if $J$ is not invertible.\n- **Task**: For each test case, compute the elementwise ratio of the diagonal elements of the combined and time-only covariance matrices: $\\operatorname{diag}(P_{\\text{comb}}) \\oslash \\operatorname{diag}(P_{\\text{time}})$, where $P_{\\text{comb}} = (J_{\\text{time}} + J_{\\text{eis}})^\\dagger$ and $P_{\\text{time}} = J_{\\text{time}}^\\dagger$.\n- **Constants and Test Data**:\n    - $I_0 = 1.0 \\, \\mathrm{A}$ for all cases.\n    - **Case A**: $\\boldsymbol{\\theta}=[0.01, 0.05, 5.0]$, $t_k=[0.02, 0.1, 0.5, 1.0, 2.0]$, $\\omega_k=[0.5, 1.0, 5.0, 10.0, 50.0]$, $\\sigma_V=10^{-4}$, $\\sigma_Z=10^{-3}$.\n    - **Case B**: $\\boldsymbol{\\theta}=[0.01, 0.05, 5.0]$, $t_k=[0.02, 0.1, 0.5, 1.0, 2.0]$, $\\omega_k=[0.5, 1.0, 5.0, 10.0, 50.0]$, $\\sigma_V=10^{-4}$, $\\sigma_Z=5 \\times 10^{-2}$.\n    - **Case C**: $\\boldsymbol{\\theta}=[0.01, 0.05, 5.0]$, $t_k=[0.001, 0.002, 0.005, 0.01]$, $\\omega_k=[0.1, 1.0, 10.0, 100.0]$, $\\sigma_V=10^{-4}$, $\\sigma_Z=10^{-3}$.\n    - **Case D**: $\\boldsymbol{\\theta}=[0.01, 0.05, 5.0]$, $t_k=[0.02, 0.1, 0.5, 1.0, 2.0]$, $\\omega_k=[500.0, 1000.0]$, $\\sigma_V=10^{-4}$, $\\sigma_Z=10^{-3}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded**: The problem is based on the standard Randles equivalent circuit for electrochemical cells, Kirchhoff's circuit laws, first-order linear ordinary differential equations, and complex impedance analysis. The statistical framework uses the Fisher Information Matrix and the Cramér–Rao Lower Bound, which are fundamental concepts in estimation theory and system identification. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The problem is clearly defined with a specific computational goal. All necessary parameters, model definitions, stimuli, and statistical assumptions are provided. The use of the Moore–Penrose pseudoinverse ensures a stable and unique solution exists even if an FIM is singular, which is a realistic possibility in parameter estimation problems.\n- **Objective**: The problem statement is formal and quantitative, free of any subjective or ambiguous language.\n\nThe problem does not exhibit any of the invalidity flaws. It is self-contained, consistent, and solvable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. Proceeding with the solution.\n\n### Derivations and Computational Strategy\n\nThe solution requires deriving the analytical models for the cell's response in both the time and frequency domains, computing their Jacobians with respect to the parameters $\\boldsymbol{\\theta} = [R_s, R_{ct}, C_{dl}]^\\top$, and then assembling the Fisher Information Matrices.\n\n#### 1. Time-Domain Analysis\nThe total terminal voltage $V(t)$ is the sum of the voltage across the series resistor, $V_{R_s}(t)$, and the voltage across the parallel RC block, $V_{RC}(t)$.\n$V(t) = V_{R_s}(t) + V_{RC}(t)$\nFor a current step $I(t) = I_0$ at $t=0$, the voltage across $R_s$ is simply $V_{R_s}(t) = I_0 R_s$.\nBy Kirchhoff's current law for the parallel block, the total current $I_0$ splits between $R_{ct}$ and $C_{dl}$:\n$$ I_0 = i_{R_{ct}}(t) + i_{C_{dl}}(t) = \\frac{V_{RC}(t)}{R_{ct}} + C_{dl} \\frac{\\mathrm{d}V_{RC}(t)}{\\mathrm{d}t} $$\nThis is a first-order linear non-homogeneous differential equation. Rearranging gives:\n$$ \\frac{\\mathrm{d}V_{RC}(t)}{\\mathrm{d}t} + \\frac{1}{R_{ct}C_{dl}}V_{RC}(t) = \\frac{I_0}{C_{dl}} $$\nWith the initial condition that the capacitor is uncharged, $V_{RC}(0)=0$, the solution is:\n$$ V_{RC}(t) = I_0 R_{ct} \\left(1 - e^{-t/(R_{ct}C_{dl})}\\right) $$\nThe total terminal voltage response, which is our measurement model $h_{\\text{time}}(t, \\boldsymbol{\\theta})$, is:\n$$ V(t) = I_0 R_s + I_0 R_{ct} \\left(1 - e^{-t/(R_{ct}C_{dl})}\\right) $$\nThe Jacobian is the vector of partial derivatives, $\\nabla_{\\boldsymbol{\\theta}} V(t) = [\\frac{\\partial V}{\\partial R_s}, \\frac{\\partial V}{\\partial R_{ct}}, \\frac{\\partial V}{\\partial C_{dl}}]$:\n$$ \\frac{\\partial V}{\\partial R_s} = I_0 $$\n$$ \\frac{\\partial V}{\\partial R_{ct}} = I_0 \\left(1 - e^{-t/(R_{ct}C_{dl})} \\left(1 + \\frac{t}{R_{ct}C_{dl}}\\right)\\right) $$\n$$ \\frac{\\partial V}{\\partial C_{dl}} = -I_0 \\frac{t}{C_{dl}^2} e^{-t/(R_{ct}C_{dl})} $$\nThe time-domain FIM, $J_{\\text{time}}$, is assembled by summing the contributions from each measurement time $t_k$. Since the noise is i.i.d. with variance $\\sigma_V^2$:\n$$ J_{\\text{time}} = \\frac{1}{\\sigma_V^2} \\sum_{k} \\left(\\nabla_{\\boldsymbol{\\theta}} V(t_k)\\right)^\\top \\left(\\nabla_{\\boldsymbol{\\theta}} V(t_k)\\right) $$\n\n#### 2. Frequency-Domain Analysis (EIS)\nIn the frequency domain, resistors have impedance $R$ and capacitors have impedance $1/(\\mathrm{j}\\omega C)$, where $\\mathrm{j}$ is the imaginary unit.\nThe impedance of the parallel RC block is:\n$$ Z_{RC}(\\mathrm{j}\\omega) = \\left(\\frac{1}{R_{ct}} + \\frac{1}{1/(\\mathrm{j}\\omega C_{dl})}\\right)^{-1} = \\left(\\frac{1}{R_{ct}} + \\mathrm{j}\\omega C_{dl}\\right)^{-1} = \\frac{R_{ct}}{1 + \\mathrm{j}\\omega R_{ct}C_{dl}} $$\nThe total complex impedance $Z(\\mathrm{j}\\omega)$ is the sum of $R_s$ and $Z_{RC}(\\mathrm{j}\\omega)$:\n$$ Z(\\mathrm{j}\\omega) = R_s + \\frac{R_{ct}}{1 + \\mathrm{j}\\omega R_{ct}C_{dl}} $$\nTo find the real and imaginary parts, we multiply the numerator and denominator of the second term by the complex conjugate of its denominator:\n$$ Z(\\mathrm{j}\\omega) = R_s + \\frac{R_{ct}(1 - \\mathrm{j}\\omega R_{ct}C_{dl})}{1 + (\\omega R_{ct}C_{dl})^2} $$\nThe real and imaginary parts of the impedance are our measurement models $h_{\\text{eis,Re}}(\\omega, \\boldsymbol{\\theta})$ and $h_{\\text{eis,Im}}(\\omega, \\boldsymbol{\\theta})$:\n$$ Z_{\\text{Re}}(\\omega) = \\operatorname{Re}[Z(\\mathrm{j}\\omega)] = R_s + \\frac{R_{ct}}{1 + (\\omega R_{ct}C_{dl})^2} $$\n$$ Z_{\\text{Im}}(\\omega) = \\operatorname{Im}[Z(\\mathrm{j}\\omega)] = -\\frac{\\omega R_{ct}^2 C_{dl}}{1 + (\\omega R_{ct}C_{dl})^2} $$\nFor each frequency $\\omega_k$, we compute the $2 \\times 3$ Jacobian matrix $H_k = \\nabla_{\\boldsymbol{\\theta}} [Z_{\\text{Re}}(\\omega_k), Z_{\\text{Im}}(\\omega_k)]^\\top$. Let $\\tau = R_{ct}C_{dl}$. The partial derivatives are:\n$$ \\frac{\\partial Z_{\\text{Re}}}{\\partial R_s} = 1, \\quad \\frac{\\partial Z_{\\text{Re}}}{\\partial R_{ct}} = \\frac{1 - (\\omega\\tau)^2}{(1+(\\omega\\tau)^2)^2}, \\quad \\frac{\\partial Z_{\\text{Re}}}{\\partial C_{dl}} = \\frac{-2\\omega^2 R_{ct}^3 C_{dl}}{(1+(\\omega\\tau)^2)^2} $$\n$$ \\frac{\\partial Z_{\\text{Im}}}{\\partial R_s} = 0, \\quad \\frac{\\partial Z_{\\text{Im}}}{\\partial R_{ct}} = \\frac{-2\\omega\\tau}{(1+(\\omega\\tau)^2)^2}, \\quad \\frac{\\partial Z_{\\text{Im}}}{\\partial C_{dl}} = \\frac{-\\omega R_{ct}^2(1 - (\\omega\\tau)^2)}{(1+(\\omega\\tau)^2)^2} $$\nThe real and imaginary parts have independent noise with variance $\\sigma_Z^2$. The EIS FIM, $J_{\\text{eis}}$, is the sum of contributions from each frequency $\\omega_k$:\n$$ J_{\\text{eis}} = \\frac{1}{\\sigma_Z^2} \\sum_{k} H_k^\\top H_k $$\nwhere $H_k$ is the $2 \\times 3$ Jacobian evaluated at $\\omega_k$.\n\n#### 3. Final Computation\nFor each test case, the following steps are executed:\n1.  Compute $J_{\\text{time}}$ using the time-domain Jacobian and measurement times $t_k$.\n2.  Compute $J_{\\text{eis}}$ using the frequency-domain Jacobian and angular frequencies $\\omega_k$.\n3.  Calculate the time-only covariance matrix: $P_{\\text{time}} = J_{\\text{time}}^\\dagger$.\n4.  Calculate the combined FIM: $J_{\\text{comb}} = J_{\\text{time}} + J_{\\text{eis}}$.\n5.  Calculate the combined covariance matrix: $P_{\\text{comb}} = J_{\\text{comb}}^\\dagger$.\n6.  Extract the diagonal elements (marginal variances) from both covariance matrices: $\\operatorname{diag}(P_{\\text{time}})$ and $\\operatorname{diag}(P_{\\text{comb}})$.\n7.  Compute the elementwise ratio: $\\operatorname{diag}(P_{\\text{comb}}) \\oslash \\operatorname{diag}(P_{\\text{time}})$.\n8.  The three resulting ratios for parameters [$R_s, R_{ct}, C_{dl}$] are collected for each case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the reduction in parameter uncertainty by augmenting a time-domain\n    dataset with EIS measurements for a Randles circuit model.\n    \"\"\"\n\n    # Test cases defined in the problem statement\n    test_cases = [\n        # Case A: General case\n        {\n            \"params\": {\"Rs\": 0.01, \"Rct\": 0.05, \"Cdl\": 5.0},\n            \"t_samples\": [0.02, 0.1, 0.5, 1.0, 2.0],\n            \"w_samples\": [0.5, 1.0, 5.0, 10.0, 50.0],\n            \"noise\": {\"sigma_V\": 1.0e-4, \"sigma_Z\": 1.0e-3}\n        },\n        # Case B: EIS dominated by noise\n        {\n            \"params\": {\"Rs\": 0.01, \"Rct\": 0.05, \"Cdl\": 5.0},\n            \"t_samples\": [0.02, 0.1, 0.5, 1.0, 2.0],\n            \"w_samples\": [0.5, 1.0, 5.0, 10.0, 50.0],\n            \"noise\": {\"sigma_V\": 1.0e-4, \"sigma_Z\": 5.0e-2}\n        },\n        # Case C: Short time window\n        {\n            \"params\": {\"Rs\": 0.01, \"Rct\": 0.05, \"Cdl\": 5.0},\n            \"t_samples\": [0.001, 0.002, 0.005, 0.01],\n            \"w_samples\": [0.1, 1.0, 10.0, 100.0],\n            \"noise\": {\"sigma_V\": 1.0e-4, \"sigma_Z\": 1.0e-3}\n        },\n        # Case D: High-frequency EIS only\n        {\n            \"params\": {\"Rs\": 0.01, \"Rct\": 0.05, \"Cdl\": 5.0},\n            \"t_samples\": [0.02, 0.1, 0.5, 1.0, 2.0],\n            \"w_samples\": [500.0, 1000.0],\n            \"noise\": {\"sigma_V\": 1.0e-4, \"sigma_Z\": 1.0e-3}\n        },\n    ]\n\n    I0 = 1.0  # Current amplitude in Amperes\n    all_results = []\n\n    for case in test_cases:\n        Rs, Rct, Cdl = case[\"params\"][\"Rs\"], case[\"params\"][\"Rct\"], case[\"params\"][\"Cdl\"]\n        t_samples = np.array(case[\"t_samples\"])\n        w_samples = np.array(case[\"w_samples\"])\n        sigma_V = case[\"noise\"][\"sigma_V\"]\n        sigma_Z = case[\"noise\"][\"sigma_Z\"]\n\n        # 1. Compute Time-Domain FIM\n        J_time = np.zeros((3, 3))\n        tau = Rct * Cdl\n        for t in t_samples:\n            if t == 0: continue\n            exp_term = np.exp(-t / tau)\n            \n            # Jacobian of V(t) w.r.t. [Rs, Rct, Cdl]\n            j_v = np.zeros(3)\n            j_v[0] = I0  # dV/dRs\n            j_v[1] = I0 * (1 - (1 + t / tau) * exp_term)  # dV/dRct\n            j_v[2] = -I0 * Rct * (t / (Rct * Cdl**2)) * exp_term # dV/dCdl\n            \n            J_time += np.outer(j_v, j_v)\n        \n        J_time /= (sigma_V**2)\n\n        # 2. Compute EIS FIM\n        J_eis = np.zeros((3, 3))\n        for w in w_samples:\n            tau = Rct * Cdl\n            w_tau = w * tau\n            denom = 1 + w_tau**2\n            \n            # Jacobian of [Z_re, Z_im] w.r.t. [Rs, Rct, Cdl]\n            H_k = np.zeros((2, 3))\n            \n            # Row 1: Derivatives of Z_re\n            H_k[0, 0] = 1.0 # dZ_re/dRs\n            H_k[0, 1] = (1 - w_tau**2) / (denom**2) # dZ_re/dRct\n            H_k[0, 2] = (-2 * w**2 * Rct**3 * Cdl) / (denom**2) # dZ_re/dCdl\n\n            # Row 2: Derivatives of Z_im\n            H_k[1, 0] = 0.0 # dZ_im/dRs\n            H_k[1, 1] = (-2 * w * Rct * Cdl) / (denom**2) # dZ_im/dRct\n            H_k[1, 2] = (-w * Rct**2 * (1 - w_tau**2)) / (denom**2) # dZ_im/dCdl\n\n            J_eis += H_k.T @ H_k\n            \n        J_eis /= (sigma_Z**2)\n\n        # 3. Compute Covariances and Ratios\n        P_time = np.linalg.pinv(J_time)\n        \n        J_comb = J_time + J_eis\n        P_comb = np.linalg.pinv(J_comb)\n        \n        var_time = np.diag(P_time)\n        var_comb = np.diag(P_comb)\n        \n        # Element-wise division, handle division by zero if a variance is zero\n        ratios = np.divide(var_comb, var_time, out=np.ones_like(var_comb), where=var_time!=0)\n        \n        # Round to six decimal places\n        rounded_ratios = [round(r, 6) for r in ratios]\n        all_results.append(rounded_ratios)\n\n    # Print results in the specified single-line format for a list of lists.\n    # The str() representation of a list of lists matches the required visual format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}