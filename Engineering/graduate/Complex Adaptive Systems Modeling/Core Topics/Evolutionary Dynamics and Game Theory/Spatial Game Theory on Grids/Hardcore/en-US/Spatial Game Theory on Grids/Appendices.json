{
    "hands_on_practices": [
        {
            "introduction": "Before exploring complex dynamics, it is crucial to master the fundamental building block of any spatial game: calculating an agent's total payoff. This exercise grounds the abstract payoff matrix of the Prisoner's Dilemma in a concrete spatial context. By deriving the payoff for a cooperator based on the composition of its local neighborhood, you will develop the core skill needed to understand and model agent decision-making in any grid-based system .",
            "id": "4143772",
            "problem": "Consider a population of players located on the sites of an $L \\times L$ two-dimensional toroidal lattice (periodic boundary conditions), where each site $i$ has the four nearest neighbors in the von Neumann neighborhood, so the degree is $d=4$. Each player $i$ chooses a strategy $s_i \\in \\{C,D\\}$, where $C$ denotes cooperation and $D$ denotes defection. Each player repeatedly plays the same one-shot two-player Prisoner’s Dilemma (PD) with every neighbor $j \\in \\mathcal{N}(i)$, and the total payoff to player $i$ from one interaction round is the sum of the pairwise payoffs over its neighbors. Let the one-shot PD payoff function be $\\pi(s_i,s_j)$ with the standard ordering for PD: the mutual cooperation payoff $R$, the temptation payoff $T$, the mutual defection payoff $P$, and the sucker’s payoff $S$, satisfying $T  R  P  S$. Suppose the payoffs are parameterized by $R=1$, $T=b$, $P=0$, and $S=-\\epsilon$, with $b1$ and $\\epsilon0$.\n\nStarting from the definition that the total payoff to player $i$ is given by\n$$\n\\Pi_i \\;=\\; \\sum_{j \\in \\mathcal{N}(i)} \\pi(s_i,s_j),\n$$\nderive the expression for $\\Pi_i$ in terms of the number of cooperating neighbors and the degree, and then compute $\\Pi_i$ when the focal player $i$ is a cooperator, $s_i=C$, and has exactly $k$ cooperating neighbors (with $0 \\leq k \\leq 4$). Express your final answer as a single closed-form analytical expression in $k$ and $\\epsilon$. No rounding is required, and no physical units apply.",
            "solution": "The user has requested the derivation of a payoff expression for a player in a spatial Prisoner's Dilemma on a lattice.\n\n### Step 1: Extract Givens\n- A player population is on an $L \\times L$ two-dimensional toroidal lattice.\n- Each site $i$ has a von Neumann neighborhood with degree $d=4$.\n- Player strategies are $s_i \\in \\{C, D\\}$, representing cooperation and defection.\n- The total payoff for player $i$ is $\\Pi_i = \\sum_{j \\in \\mathcal{N}(i)} \\pi(s_i,s_j)$.\n- The game is a Prisoner's Dilemma with payoff ordering $T  R  P  S$.\n- Payoff values are parameterized as $R=1$, $T=b$, $P=0$, $S=-\\epsilon$.\n- Parameter constraints are $b1$ and $\\epsilon0$.\n- The task is to compute $\\Pi_i$ for a cooperator ($s_i=C$) with exactly $k$ cooperating neighbors, where $0 \\leq k \\leq 4$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation against the specified criteria.\n- **Scientific Grounding**: The problem is a standard exercise in the field of spatial game theory, a sub-discipline of complex adaptive systems modeling. The Prisoner's Dilemma on a grid with periodic boundary conditions is a canonical model. The payoff structure $TRPS$ is the definition of the Prisoner's Dilemma. The given parameterization, $R=1$, $T=b$, $P=0$, $S=-\\epsilon$, with constraints $b1$ and $\\epsilon0$, correctly implements this ordering as $b  1  0  -\\epsilon$. The setup is scientifically and mathematically sound.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary information—the lattice structure, neighborhood type, payoff matrix, focal player's strategy, and composition of its neighborhood—to calculate a unique, deterministic payoff value.\n- **Objectivity**: The problem is stated in precise, objective, mathematical language, free from ambiguity or subjective claims.\n- **Flaw Checklist**: The problem does not exhibit any of the listed flaws. It is scientifically sound, formalizable, complete, feasible as a theoretical model, well-posed, non-trivial, and mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. The solution process will now proceed.\n\n### Derivation\nThe total payoff to a player $i$, denoted by $\\Pi_i$, is the sum of the payoffs from pairwise interactions with its $d$ neighbors. The payoff from a single interaction between player $i$ with strategy $s_i$ and player $j$ with strategy $s_j$ is given by the function $\\pi(s_i, s_j)$. Using the specified parameterization, the payoff matrix is:\n- $\\pi(C, C) = R = 1$ (mutual cooperation)\n- $\\pi(C, D) = S = -\\epsilon$ (sucker's payoff for the cooperator)\n- $\\pi(D, C) = T = b$ (temptation to defect)\n- $\\pi(D, D) = P = 0$ (mutual defection)\n\nThe general expression for the total payoff to player $i$ with strategy $s_i$ is:\n$$\n\\Pi_i = \\sum_{j \\in \\mathcal{N}(i)} \\pi(s_i, s_j)\n$$\nThe neighborhood $\\mathcal{N}(i)$ consists of $d=4$ players. Let $k_i$ be the number of cooperating neighbors of player $i$. Consequently, the number of defecting neighbors is $d - k_i = 4 - k_i$. The sum can be split into two parts: a sum over cooperating neighbors and a sum over defecting neighbors.\n$$\n\\Pi_i = \\sum_{j \\in \\mathcal{N}(i), s_j=C} \\pi(s_i, s_j) + \\sum_{j \\in \\mathcal{N}(i), s_j=D} \\pi(s_i, s_j)\n$$\nSince the payoff is the same for all neighbors with the same strategy, this simplifies to:\n$$\n\\Pi_i = k_i \\cdot \\pi(s_i, C) + (4 - k_i) \\cdot \\pi(s_i, D)\n$$\nThis is the general expression for the payoff to player $i$ in terms of the number of its cooperating neighbors.\n\nThe problem requires the calculation for a specific case: the focal player $i$ is a cooperator, so $s_i=C$, and this player has exactly $k$ cooperating neighbors, so $k_i=k$. Let us denote the payoff for this specific case as $\\Pi_C(k)$.\nSubstituting $s_i = C$ and $k_i = k$ into the general expression yields:\n$$\n\\Pi_C(k) = k \\cdot \\pi(C, C) + (4 - k) \\cdot \\pi(C, D)\n$$\nWe now substitute the specific payoff values, $\\pi(C, C) = R = 1$ and $\\pi(C, D) = S = -\\epsilon$, into this equation.\n$$\n\\Pi_C(k) = k \\cdot (1) + (4 - k) \\cdot (-\\epsilon)\n$$\nExpanding and simplifying the expression gives the final result:\n$$\n\\Pi_C(k) = k - 4\\epsilon + k\\epsilon\n$$\nFactoring out $k$ provides a more compact form:\n$$\n\\Pi_C(k) = k(1 + \\epsilon) - 4\\epsilon\n$$\nThis is the closed-form analytical expression for the total payoff to a cooperator with $k$ cooperating neighbors, as a function of $k$ and $\\epsilon$.",
            "answer": "$$\n\\boxed{k(1 + \\epsilon) - 4\\epsilon}\n$$"
        },
        {
            "introduction": "From static payoffs, we move to dynamics and the emergence of global patterns from local interactions. This practice explores the stability of a classic checkerboard configuration in an anti-coordination game, a scenario where agents are rewarded for being different from their neighbors. By analyzing how the neighborhood structure affects an agent's decision to switch strategies, you will gain insight into the concept of a Best Response (BR) fixed point and learn how spatial arrangements can become stable or be destabilized by changing the scale of interaction .",
            "id": "4143744",
            "problem": "Consider a two-strategy anti-coordination game on a periodic square lattice (a torus) modeled as the discrete set $\\mathbb{Z}_N \\times \\mathbb{Z}_N$, where $N$ is a positive integer. Each site $(i,j)$ holds a strategy $s_{i,j} \\in \\{0,1\\}$, and the interaction neighborhood of radius $r$ for a focal site $(i,j)$ is the set of sites whose Manhattan (L1) distance on the torus from $(i,j)$ is less than or equal to $r$, excluding $(i,j)$ itself. The Manhattan distance on the torus between $(i,j)$ and $(u,v)$ is defined as\n$$\nd_1\\big((i,j),(u,v)\\big) \\equiv \\min\\big(|i-u|,\\, N - |i-u|\\big) + \\min\\big(|j-v|,\\, N - |j-v|\\big).\n$$\nThe pairwise anti-coordination payoff is defined by\n$$\nu\\big(s_{i,j}, s_{u,v}\\big) = \\mathbf{1}\\big[s_{i,j} \\ne s_{u,v}\\big],\n$$\nwhere $\\mathbf{1}[\\cdot]$ denotes the indicator function. The total payoff to $(i,j)$ under radius $r$ is\n$$\nU_{i,j}(r; s) = \\sum_{\\substack{(u,v) \\in \\mathbb{Z}_N^2 \\\\ (u,v) \\ne (i,j) \\\\ d_1\\big((i,j),(u,v)\\big) \\le r}} u\\big(s_{i,j}, s_{u,v}\\big).\n$$\nAgents update strategies by synchronous Best Response (BR): at each round, each agent replaces its current strategy $s_{i,j}$ with a strategy $x \\in \\{0,1\\}$ that maximizes $U_{i,j}(r; s^{(t)}|_{s_{i,j} \\mapsto x})$. In case of a tie, agents keep their current strategy. A configuration $s$ is a BR fixed point if for every site $(i,j)$, the current $s_{i,j}$ is among the BR choices.\n\nWe study the checkerboard configuration defined by\n$$\ns^{\\text{cb}}_{i,j} \\equiv (i+j) \\bmod 2,\n$$\nwhich alternates strategies by parity. Your task is to evaluate the emergence and stability of this checkerboard configuration under various neighborhood radii, and determine the minimal radius at which this configuration is not a BR fixed point (i.e., destabilized).\n\nStarting from the fundamental definitions above and standard counting properties of Manhattan circles in $\\mathbb{Z}^2$, derive a principled algorithm that decides, for any given $N$ and $r$, whether $s^{\\text{cb}}$ is a BR fixed point under the anti-coordination payoff. Then, for a collection of test cases $(N, \\mathcal{R})$ with $\\mathcal{R}$ a finite list of candidate radii, compute the minimal $r \\in \\mathcal{R}$ for which the checkerboard configuration is not a BR fixed point. If the checkerboard configuration is a BR fixed point for all $r \\in \\mathcal{R}$, return $0$ for that test case.\n\nImportant modeling specifications:\n- The lattice is periodic (a torus), so distances and neighborhoods are computed using the toroidal Manhattan distance $d_1$.\n- The BR rule uses synchronous updates and the tie-breaking rule “keep current strategy.”\n- You must enforce the condition $2r  N$ when you apply any counting formula that assumes non-wrapping neighborhoods; otherwise, you must fall back to explicit toroidal counting.\n\nDesign a program that produces a single line of output containing the results as a comma-separated list enclosed in square brackets, with one integer per test case representing the minimal destabilizing radius (or $0$ if none among the candidates). The program should implement your derived algorithm and evaluate the following test suite:\n\n- Test case $1$: $N=40$, $\\mathcal{R}=[1,2,3,4,5,6]$.\n- Test case $2$: $N=11$, $\\mathcal{R}=[1,2,3,4,5]$.\n- Test case $3$: $N=8$, $\\mathcal{R}=[1]$.\n- Test case $4$: $N=10$, $\\mathcal{R}=[1,2]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[result1,result2,result3,result4]}$). No physical units are involved. All outputs must be integers.",
            "solution": "The problem requires determining the stability of a checkerboard strategy configuration in a spatial anti-coordination game on a periodic square lattice. A configuration is stable if it is a Best Response (BR) fixed point. We will first derive the condition for stability and then develop an algorithm to test it.\n\nA site $(i,j)$ with strategy $s_{i,j}$ has a total payoff $U_{i,j}$ equal to the number of its neighbors with the opposite strategy. Let the set of neighbors of $(i,j)$ within a toroidal Manhattan distance $r$ be denoted by $\\mathcal{N}_{i,j}(r)$. The payoff is:\n$$\nU_{i,j}(r; s) = \\sum_{(u,v) \\in \\mathcal{N}_{i,j}(r)} \\mathbf{1}[s_{i,j} \\ne s_{u,v}]\n$$\nAn agent at $(i,j)$ considers switching its strategy from $s_{i,j}$ to the alternative strategy $s'_{i,j} = 1 - s_{i,j}$. The payoff for this alternative strategy would be:\n$$\nU_{i,j}(r; s|_{s_{i,j} \\mapsto s'_{i,j}}) = \\sum_{(u,v) \\in \\mathcal{N}_{i,j}(r)} \\mathbf{1}[s'_{i,j} \\ne s_{u,v}] = \\sum_{(u,v) \\in \\mathcal{N}_{i,j}(r)} \\mathbf{1}[s_{i,j} = s_{u,v}]\n$$\nLet $K_{\\text{diff}}(i,j,r)$ be the number of neighbors with a different strategy and $K_{\\text{same}}(i,j,r)$ be the number of neighbors with the same strategy. The current payoff is $K_{\\text{diff}}(i,j,r)$ and the potential payoff from switching is $K_{\\text{same}}(i,j,r)$.\n\nAccording to the specified synchronous Best Response rule with the tie-breaking condition \"keep current strategy,\" an agent at $(i,j)$ will not switch its strategy if its current payoff is greater than or equal to the payoff it would receive by switching. Thus, the strategy $s_{i,j}$ is stable if:\n$$\nU_{i,j}(r; s) \\ge U_{i,j}(r; s|_{s_{i,j} \\mapsto 1-s_{i,j}}) \\implies K_{\\text{diff}}(i,j,r) \\ge K_{\\text{same}}(i,j,r)\n$$\nThe entire checkerboard configuration $s^{\\text{cb}}_{i,j} = (i+j) \\bmod 2$ is a BR fixed point if this condition holds for all sites $(i,j) \\in \\mathbb{Z}_N \\times \\mathbb{Z}_N$.\n\nDue to the translational symmetry of the toroidal lattice and the periodic nature of the checkerboard pattern, the stability condition is identical for every site. We can therefore analyze the stability for a single, arbitrary site, for which we choose the origin $(0,0)$.\n\nAt site $(0,0)$, the strategy is $s^{\\text{cb}}_{0,0} = (0+0) \\bmod 2 = 0$. For any neighboring site $(u,v) \\in \\mathcal{N}_{0,0}(r)$, its strategy is $s^{\\text{cb}}_{u,v} = (u+v) \\bmod 2$.\nA neighbor $(u,v)$ has the same strategy as $(0,0)$ if $s^{\\text{cb}}_{u,v} = 0$, which occurs when $(u+v)$ is even.\nA neighbor $(u,v)$ has a different strategy if $s^{\\text{cb}}_{u,v} = 1$, which occurs when $(u+v)$ is odd.\n\nLet $K_{\\text{even}}(r)$ be the number of neighbors of $(0,0)$ within radius $r$ for which $(u+v)$ is even, and $K_{\\text{odd}}(r)$ be the number of neighbors for which $(u+v)$ is odd. The stability condition for the checkerboard configuration simplifies to:\n$$\nK_{\\text{odd}}(r) \\ge K_{\\text{even}}(r)\n$$\nThe problem is reduced to counting neighbors with even and odd coordinate sums within a toroidal Manhattan ball.\n\nWe consider two cases as specified by the problem.\n\nCase 1: Non-wrapping neighborhood ($2r  N$).\nIn this case, the toroidal Manhattan distance from $(0,0)$ to any neighbor $(u,v)$ simplifies to the standard Manhattan distance: $d_1((0,0),(u,v)) = |u|+|v|$. The neighborhood is a diamond shape on the infinite grid $\\mathbb{Z}^2$.\nConsider the set of all neighbors at a fixed Manhattan distance $k$, where $1 \\le k \\le r$. These are the integer points on the perimeter of the square with vertices $(k,0), (0,k), (-k,0), (0,-k)$. There are exactly $4k$ such points.\nLet's analyze the parity of the coordinate sum $u+v$ for a point $(u,v)$ with $|u|+|v|=k$. The sum $u+v$ has the same parity as $|u|+|v|$ if and only if $u$ and $v$ are both non-negative or both non-positive. However, a simpler observation is that $u+v$ has the same parity as $k$ itself. For any point $(u,v)$ on the Manhattan circle of radius $k$, $(u+v) \\equiv k \\pmod 2$. For example, if we move from $(u,v)$ to an adjacent point $(u \\pm 1, v)$ or $(u, v \\pm 1)$, the Manhattan distance changes by $1$ and the coordinate sum changes by $\\pm 1$, thus preserving the relationship between the parity of the distance and the parity of the sum. Since the point $(k,0)$ has distance $k$ and sum $k$, all points at distance $k$ must have sums with the same parity as $k$.\nTherefore, for a given distance $k$:\n- If $k$ is odd, all $4k$ neighbors contribute to $K_{\\text{odd}}(r)$.\n- If $k$ is even, all $4k$ neighbors contribute to $K_{\\text{even}}(r)$.\n\nWe can now compute the total counts by summing over $k$ from $1$ to $r$:\n$$\nK_{\\text{odd}}(r) = \\sum_{\\substack{k=1 \\\\ k \\text{ is odd}}}^r 4k \\quad \\text{and} \\quad K_{\\text{even}}(r) = \\sum_{\\substack{k=1 \\\\ k \\text{ is even}}}^r 4k\n$$\nThe stability condition is $K_{\\text{odd}}(r) \\ge K_{\\text{even}}(r)$. Let's analyze the difference $\\Delta(r) = K_{\\text{odd}}(r) - K_{\\text{even}}(r)$:\n$$\n\\Delta(r) = 4 \\sum_{k=1}^r (-1)^{k+1} k = 4(1 - 2 + 3 - 4 + \\dots + (-1)^{r+1}r)\n$$\n- If $r$ is odd, let $r = 2m-1$. The sum is $(1-2)+(3-4)+\\dots+((2m-3)-(2m-2))+(2m-1)$, which simplifies to $(m-1) \\times (-1) + (2m-1) = m$. So, $\\Delta(r) = 4m = 4 \\frac{r+1}{2} = 2(r+1)  0$. The configuration is stable.\n- If $r$ is even, let $r = 2m$. The sum is $(1-2)+(3-4)+\\dots+((2m-1)-2m)$, which simplifies to $m \\times (-1) = -m$. So, $\\Delta(r) = -4m = -4 \\frac{r}{2} = -2r  0$. The configuration is unstable.\n\nConclusion for the non-wrapping case ($2r  N$): The checkerboard configuration is a BR fixed point if and only if the radius $r$ is odd.\n\nCase 2: Wrapping neighborhood ($2r \\ge N$).\nThe analytical shortcut is no longer valid because the toroidal distance formula $d_1\\big((i,j),(u,v)\\big) = \\min\\big(|i-u|,\\, N - |i-u|\\big) + \\min\\big(|j-v|,\\, N - |j-v|\\big)$ must be used directly. The number and parity distribution of neighbors can no longer be described by the simple formula. We must perform an explicit count.\nThe algorithm for this case is to iterate through all sites $(u,v) \\in \\mathbb{Z}_N \\times \\mathbb{Z}_N$ (excluding $(0,0)$), calculate their toroidal Manhattan distance to $(0,0)$, and if the distance is less than or equal to $r$, classify the site as a neighbor. We then tally the counts $K_{\\text{odd}}(r)$ and $K_{\\text{even}}(r)$ based on the parity of the sum $(u+v)$ for these neighbors. The stability is then checked using the condition $K_{\\text{odd}}(r) \\ge K_{\\text{even}}(r)$.\n\nThe final algorithm for each test case $(N, \\mathcal{R})$ proceeds as follows:\n1. Initialize a variable `min_destabilizing_r` to $0$.\n2. For each radius $r$ in the provided list $\\mathcal{R}$, sorted in increasing order:\n   a. Check if the configuration is stable for $(N, r)$.\n   b. If $2r  N$, stability is determined by the parity of $r$: stable if odd, unstable if even.\n   c. If $2r \\ge N$, perform the explicit toroidal neighbor count to determine stability.\n   d. If the configuration is found to be unstable, set `min_destabilizing_r = r` and terminate the search for this test case.\n3. The value of `min_destabilizing_r` is the result for the test case.\n\nFor all test cases provided in the problem, the condition $2r  N$ holds for all candidate radii $r \\in \\mathcal{R}$. Thus, we only need to apply the analytical result: the first even radius in the list $\\mathcal{R}$ will be the minimal destabilizing radius. If all radii in $\\mathcal{R}$ are odd, the configuration remains stable for all of them, and the result is $0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy\n\ndef solve():\n    \"\"\"\n    Solves the spatial game theory problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        (40, [1, 2, 3, 4, 5, 6]),\n        (11, [1, 2, 3, 4, 5]),\n        (8, [1]),\n        (10, [1, 2]),\n    ]\n\n    results = []\n    for N, R_list in test_cases:\n        min_destabilizing_r = 0\n        sorted_R = sorted(R_list)\n\n        for r in sorted_R:\n            # The problem requires a principled derivation and algorithm, which may involve\n            # two cases: non-wrapping (2r  N) and wrapping (2r = N).\n            # The is_stable function implements this logic.\n            if not is_stable(N, r):\n                min_destabilizing_r = r\n                break\n        \n        results.append(min_destabilizing_r)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef is_stable(N, r):\n    \"\"\"\n    Determines if the checkerboard configuration is a BR fixed point for a given\n    lattice size N and neighborhood radius r.\n\n    Args:\n        N (int): The size of the square lattice (N x N).\n        r (int): The Manhattan neighborhood radius.\n\n    Returns:\n        bool: True if the configuration is a BR fixed point (stable), False otherwise.\n    \"\"\"\n    # Case 1: Non-wrapping neighborhood.\n    # The condition 2r  N ensures that the Manhattan ball does not wrap around the torus.\n    if 2 * r  N:\n        # From the analytical derivation, for non-wrapping neighborhoods, the checkerboard\n        # is stable if and only if the radius r is odd.\n        # Stability condition: K_odd = K_even\n        # For odd r, K_odd  K_even. Stable.\n        # For even r, K_odd  K_even. Unstable.\n        return r % 2 != 0\n\n    # Case 2: Wrapping neighborhood.\n    # The analytical formula is invalid. Fall back to explicit toroidal counting.\n    else:\n        count_same = 0  # Neighbors with the same strategy as origin (s=0, so u+v is even)\n        count_diff = 0  # Neighbors with a different strategy (s=1, so u+v is odd)\n\n        # Iterate through all sites on the NxN grid to find neighbors of (0,0)\n        for u in range(N):\n            for v in range(N):\n                if u == 0 and v == 0:\n                    continue\n\n                # Calculate toroidal Manhattan distance from (0,0)\n                dist_u = min(u, N - u)\n                dist_v = min(v, N - v)\n                distance = dist_u + dist_v\n\n                if distance = r:\n                    # This site is a neighbor. Determine its strategy relative to the origin.\n                    # The checkerboard strategy is s_uv = (u+v) % 2.\n                    # The origin's strategy is s_00 = 0.\n                    # A neighbor has the same strategy if (u+v) is even.\n                    if (u + v) % 2 == 0:\n                        count_same += 1\n                    else:\n                        count_diff += 1\n        \n        # The configuration is stable if the payoff for the current strategy (count_diff)\n        # is greater than or equal to the payoff for switching (count_same), due to the\n        # tie-breaking rule of keeping the current strategy.\n        return count_diff = count_same\n\nsolve()\n\n```"
        },
        {
            "introduction": "This final practice synthesizes the concepts of payoff, strategy updates, and spatial structure into a full-fledged agent-based simulation. You will investigate one of the most celebrated findings in spatial game theory: the ability of \"spatial reciprocity\" to sustain cooperation, and how this benefit can be eroded by agent mobility. By implementing a model with stochastic Fermi updates and agent movement, and then using a binary search to find the critical mobility rate at which cooperation collapses, you will engage in a realistic modeling exercise that mirrors how researchers probe for phase transitions in complex adaptive systems .",
            "id": "4143783",
            "problem": "You are asked to formalize, implement, and compute the critical mobility rate $m^\\ast$ beyond which spatial reciprocity breaks down in a spatial Prisoner’s Dilemma (PD) under a Fermi imitation rule on a periodic grid. The target quantity $m^\\ast$ is defined as the smallest mobility rate $m \\in [0,1]$ such that the long-run mean cooperation density falls below a specified tolerance threshold. The problem must be solved from first principles using spatial game theory on grids within complex adaptive systems modeling.\n\nThe fundamental base consists of the following definitions and well-tested facts:\n- The Prisoner’s Dilemma (PD) is a two-player game with payoffs satisfying $T  R  P  S$, where $T$ is the temptation to defect, $R$ is the mutual cooperation reward, $P$ is the mutual defection punishment, and $S$ is the sucker’s payoff.\n- The Fermi imitation rule specifies that agent $i$ imitates neighbor $j$’s strategy with probability $p_{i \\leftarrow j} = \\frac{1}{1 + \\exp\\!\\left(-\\beta \\left(\\pi_j - \\pi_i\\right)\\right)}$, where $\\beta  0$ is the selection intensity, and $\\pi_i$ and $\\pi_j$ are the current accumulated payoffs of agents $i$ and $j$ computed from interactions with their neighbors.\n- Network reciprocity may sustain cooperation on structured populations when clusters of cooperators can form and persist. Increased mobility tends to randomize structure, pushing the system toward the well-mixed limit in which defection dominates for PD.\n\nModel specification:\n- Spatial domain: a two-dimensional square grid of size $L \\times L$ with periodic boundary conditions, so every site has $4$ von Neumann neighbors (up, down, left, right).\n- Strategies: each site holds a strategy $s \\in \\{C,D\\}$, encoded as $s=1$ for cooperation and $s=0$ for defection.\n- Payoffs: each agent’s payoff $\\pi$ is the sum over its $4$ neighbors using the PD matrix:\n  - If $(s_i,s_j)=(1,1)$ add $R$ to $\\pi_i$.\n  - If $(s_i,s_j)=(1,0)$ add $S$ to $\\pi_i$.\n  - If $(s_i,s_j)=(0,1)$ add $T$ to $\\pi_i$.\n  - If $(s_i,s_j)=(0,0)$ add $P$ to $\\pi_i$.\n- Mobility: in each discrete time step, a fraction $m$ of sites (in expectation) are selected to participate in random disjoint pairwise swaps of positions, modeling unbiased random motion. Concretely, at each step, draw $2K$ distinct sites uniformly at random without replacement, where $K = \\left\\lfloor \\frac{m L^2}{2} \\right\\rfloor$, randomly pair the first $K$ sites with the second $K$ sites, and swap their strategies. This yields $2K$ relocated agents, implementing a mobility rate $m$ with disjoint swaps.\n- Update dynamics per Monte Carlo step (MCS): one synchronous iteration consists of:\n  1. Apply mobility with rate $m$ via disjoint random pair swaps.\n  2. Compute each site’s payoff $\\pi$ by summing PD payoffs against its $4$ neighbors.\n  3. For each site, select a single neighbor uniformly from its $4$ neighbors and apply the Fermi imitation rule with selection intensity $\\beta$. Adoption is synchronous.\n\nInitial condition:\n- At $t=0$, strategies are independently and uniformly sampled across the grid with exactly one of $\\{C,D\\}$ per site, with $C$ and $D$ equally likely (mean initial cooperation density approximately $0.5$). No external inputs are used beyond the parameters given below.\n\nBreakdown criterion:\n- Spatial reciprocity is said to have broken down at mobility $m$ if the mean cooperation density, averaged over the last $w$ Monte Carlo steps of a run of $T_{\\text{steps}}$ steps, is less than or equal to a tolerance $\\varepsilon$, where $\\varepsilon$ is specified per test case.\n\nTarget quantity:\n- The critical mobility rate $m^\\ast$ is defined as the smallest $m \\in [0,1]$ for which the breakdown criterion holds. If breakdown holds already at $m=0$, then $m^\\ast = 0$. If breakdown does not hold even at $m=1$, then $m^\\ast = 1$.\n\nRequired implementation method:\n- For any parameter set, estimate $m^\\ast$ by evaluating the system at $m=0$ and $m=1$ to bracket the outcome. If the breakdown criterion is met at $m=0$, set $m^\\ast = 0$. If the breakdown criterion fails at $m=1$, set $m^\\ast = 1$. Otherwise, perform a binary search on $m \\in [0,1]$ for a fixed number of iterations, at each query running the above dynamics and computing the long-run mean cooperation density. To reduce stochastic variance, average the final cooperation density over at least $3$ independent runs with distinct fixed random seeds. Return the minimal $m$ found by the search that satisfies the breakdown criterion. All computations are dimensionless; no physical units are involved.\n\nTest suite:\n- You must compute $m^\\ast$ for each of the following parameter sets. All quantities appearing below are dimensionless and must be treated as real numbers in the program.\n  1. Case A (happy path): $L=40$, $R=1.0$, $S=0.0$, $T=1.4$, $P=0.0$, $\\beta=1.0$, $T_{\\text{steps}}=400$, $w=100$, $\\varepsilon=0.05$, number of independent runs $=3$.\n  2. Case B (near boundary with low temptation): $L=40$, $R=1.0$, $S=0.0$, $T=1.05$, $P=0.0$, $\\beta=1.0$, $T_{\\text{steps}}=300$, $w=80$, $\\varepsilon=0.05$, number of independent runs $=3$.\n  3. Case C (edge case with high temptation): $L=40$, $R=1.0$, $S=0.0$, $T=1.8$, $P=0.0$, $\\beta=1.0$, $T_{\\text{steps}}=400$, $w=100$, $\\varepsilon=0.05$, number of independent runs $=3$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the above test cases. For example, output must look like $\\texttt{[0.375,0.962,0.0]}$ with each entry a floating-point number. Round each returned $m^\\ast$ to $3$ decimal places in the final output.",
            "solution": "The user-provided problem is valid. It is scientifically grounded in the established field of spatial game theory, is well-posed with all necessary parameters and dynamics defined, and is objective in its formulation. We can therefore proceed with a full solution.\n\n### 1. Problem Formulation and Objective\n\nThe central objective is to compute the critical mobility rate $m^\\ast$ for a spatial Prisoner's Dilemma (PD) game on a grid. This critical rate is defined as the smallest mobility rate $m \\in [0,1]$ at which cooperation, sustained by spatial reciprocity, breaks down. A breakdown is formally defined as the long-run average cooperation density, $\\langle c \\rangle$, falling below a specified tolerance threshold $\\varepsilon$.\n\nThe system is defined on an $L \\times L$ grid with periodic boundary conditions, where each agent can be a cooperator ($s=1$) or a defector ($s=0$). The PD game is defined by the payoffs for mutual cooperation ($R$), mutual defection ($P$), unilateral cooperation (the sucker's payoff, $S$), and unilateral defection (the temptation, $T$), satisfying $T  R  P  S$.\n\nThe dynamics unfold in discrete Monte Carlo steps (MCS), each consisting of three synchronous phases:\n1.  **Mobility**: A fraction $m$ of agents are randomly swapped.\n2.  **Payoff Calculation**: Each agent's payoff $\\pi$ is calculated as the sum of payoffs from interactions with its $4$ von Neumann neighbors.\n3.  **Strategy Update**: Each agent $i$ randomly selects one of its $4$ neighbors, say agent $j$, and adopts agent $j$'s strategy with probability $p_{i \\leftarrow j} = \\frac{1}{1 + \\exp\\!\\left(-\\beta \\left(\\pi_j - \\pi_i\\right)\\right)}$, where $\\beta$ is the selection intensity.\n\nThe long-run average cooperation density $\\langle c \\rangle$ is computed by averaging the fraction of cooperators on the grid over the last $w$ steps of a simulation run of total length $T_{\\text{steps}}$. To ensure robustness against stochastic fluctuations, this value is further averaged over multiple independent simulation runs.\n\nThe breakdown criterion is met if $\\langle c \\rangle \\le \\varepsilon$. Our goal is to find $m^\\ast = \\min \\{ m \\in [0,1] \\mid \\langle c(m) \\rangle \\le \\varepsilon \\}$.\n\n### 2. Algorithmic Approach: Binary Search\n\nThe mobility of agents tends to break up clusters of cooperators, which are essential for sustaining cooperation through network reciprocity. Increased mobility randomizes the interaction structure, making the system behave more like a well-mixed population where defection is the dominant strategy in the PD. Therefore, the long-run cooperation density $\\langle c(m) \\rangle$ is expected to be a monotonically non-increasing function of the mobility rate $m$.\n\nThis monotonicity makes a binary search algorithm an efficient and appropriate method for finding the critical threshold $m^\\ast$. The search is performed on the interval $[0,1]$. We define a function, `check_breakdown(m)`, which returns `True` if the breakdown criterion is met for a given $m$, and `False` otherwise.\n\nThe search proceeds as follows:\n1.  **Check Boundaries**:\n    *   If `check_breakdown(0)` is `True`, cooperation is unsustainable even without mobility, so $m^\\ast = 0$.\n    *   If `check_breakdown(1)` is `False`, cooperation persists even at maximum mobility, so $m^\\ast = 1$.\n2.  **Binary Search**: If cooperation exists at $m=0$ but breaks down at $m=1$, we initialize a search interval with `low` $=0$ and `high` $=1$. We iterate for a fixed number of steps ($15$ in our implementation, providing precision far greater than the required $10^{-3}$). In each iteration, we test the midpoint `mid` $= (\\text{low} + \\text{high}) / 2$.\n    *   If `check_breakdown(mid)` is `True`, it means breakdown occurs at or before this mobility rate. The critical value $m^\\ast$ could be `mid` or a smaller value. We thus update the search space by setting `high` = `mid`.\n    *   If `check_breakdown(mid)` is `False`, then mobility `mid` is not sufficient for breakdown, and we must search for higher values. We update by setting `low` = `mid`.\n3.  **Result**: After the iterations, the value `high` is our estimate for $m^\\ast$, as it represents the smallest mobility rate tested in the search that was found to satisfy the breakdown criterion.\n\n### 3. Simulation Details\n\nTo implement the `check_breakdown(m)` function, we simulate the system's evolution for the given parameters. One full simulation run provides a single estimate of the long-run cooperation density.\n\n#### 3.1. Initialization\nFor each run, a new random number generator is seeded to ensure independence. The $L \\times L$ grid is initialized with cooperators ($1$) and defectors ($0$) chosen with equal probability at each site.\n\n#### 3.2. Monte Carlo Step (MCS)\n\nEach MCS applies the three phases synchronously.\n\n**a) Mobility Phase:**\nThe mobility rate $m$ is implemented by swapping $K = \\lfloor m L^2 / 2 \\rfloor$ disjoint pairs of agents. This is achieved by:\n1.  Generating a list of all site indices from $0$ to $L^2-1$.\n2.  Randomly choosing $2K$ distinct indices without replacement.\n3.  Pairing the first $K$ chosen indices with the second $K$.\n4.  Swapping the strategies of the agents at these paired locations. This operation is most cleanly performed on a flattened $1$-D representation of the strategy grid.\n\n**b) Payoff Calculation Phase:**\nThis phase can be heavily optimized using vectorized operations. Let the strategy grid be a NumPy array `grid` where `grid[i,j]=1` for cooperators and $0$ for defectors.\n1.  The number of cooperating neighbors for each site is calculated by summing four shifted versions of the `grid` array, using `numpy.roll` to handle the periodic boundary conditions.\n    $$ N_C = \\text{roll}(\\text{grid}, 1, \\text{axis}=0) + \\text{roll}(\\text{grid}, -1, \\text{axis}=0) + \\text{roll}(\\text{grid}, 1, \\text{axis}=1) + \\text{roll}(\\text{grid}, -1, \\text{axis}=1) $$\n2.  The number of defecting neighbors is simply $N_D = 4 - N_C$.\n3.  The potential payoffs if a site were a cooperator ($\\pi_C$) or a defector ($\\pi_D$) are computed for the entire grid at once:\n    $$ \\Pi_C = N_C \\cdot R + N_D \\cdot S $$\n    $$ \\Pi_D = N_C \\cdot T + N_D \\cdot P $$\n4.  The final payoff grid $\\Pi$ is constructed by selecting the appropriate payoff based on the actual strategy at each site:\n    $$ \\Pi = \\text{grid} \\cdot \\Pi_C + (1 - \\text{grid}) \\cdot \\Pi_D $$\n\n**c) Strategy Update Phase:**\nA synchronous update requires computing the next state of the grid, `next_grid`, based on the current `grid` and `payoff` arrays. We iterate through each site $(i,j)$:\n1.  A single neighbor $(n_i, n_j)$ is chosen uniformly at random from the four von Neumann neighbors.\n2.  The payoffs $\\pi_i = \\Pi[i,j]$ and $\\pi_j = \\Pi[n_i, n_j]$ are retrieved.\n3.  The probability of agent $i$ adopting agent $j$'s strategy, $p_{i \\leftarrow j}$, is calculated using the Fermi function.\n4.  A random number $u \\in [0,1)$ is drawn. If $u  p_{i \\leftarrow j}$, agent $i$ adopts agent $j$'s strategy in the next time step (`next_grid[i,j] = grid[n_i, n_j]`). Otherwise, it keeps its own (`next_grid[i,j] = grid[i,j]`).\nAfter this process is completed for all sites, the main grid is updated: `grid = next_grid`.\n\n#### 3.3. Data Collection\nAfter each MCS, if the step count $t$ is within the final window ($t \\ge T_{\\text{steps}} - w$), the grid-wide cooperation density, $\\text{mean}(\\text{grid})$, is recorded. The average of these recorded values at the end of the simulation gives the long-run cooperation density $\\langle c \\rangle$ for that run. The final value passed to the binary search is the mean of these densities across all $3$ independent runs.\n\nThis methodical, principle-based design ensures a correct and robust implementation that directly follows the problem specification.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_simulation(m, L, R, S, T, P, beta, T_steps, w, seed):\n    \"\"\"\n    Runs a single simulation of the spatial Prisoner's Dilemma with mobility.\n\n    Args:\n        m (float): Mobility rate.\n        L (int): Grid size.\n        R, S, T, P (float): Payoff matrix values.\n        beta (float): Selection intensity for the Fermi rule.\n        T_steps (int): Total number of Monte Carlo steps.\n        w (int): Window size for averaging cooperation density.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        float: The average cooperation density over the last w steps.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Initial condition: Strategies are C (1) or D (0) with equal probability.\n    grid = rng.integers(0, 2, size=(L, L), dtype=np.int8)\n    \n    cooperation_history = []\n    \n    neighbor_offsets = np.array([[-1, 0], [1, 0], [0, -1], [0, 1]])\n\n    for step in range(T_steps):\n        # 1. Mobility phase\n        num_swaps = int(m * L * L / 2)\n        if num_swaps  0:\n            indices = rng.choice(L * L, size=2 * num_swaps, replace=False)\n            indices1 = indices[:num_swaps]\n            indices2 = indices[num_swaps:]\n            \n            flat_grid = grid.flatten()\n            strategies1 = flat_grid[indices1]\n            strategies2 = flat_grid[indices2]\n            flat_grid[indices1] = strategies2\n            flat_grid[indices2] = strategies1\n            grid = flat_grid.reshape((L, L))\n\n        # 2. Payoff calculation phase (vectorized)\n        num_C_neighbors = (np.roll(grid, 1, axis=0) + np.roll(grid, -1, axis=0) +\n                           np.roll(grid, 1, axis=1) + np.roll(grid, -1, axis=1))\n        num_D_neighbors = 4 - num_C_neighbors\n        \n        payoff_if_C = num_C_neighbors * R + num_D_neighbors * S\n        payoff_if_D = num_C_neighbors * T + num_D_neighbors * P\n        \n        payoffs = grid * payoff_if_C + (1 - grid) * payoff_if_D\n\n        # 3. Strategy update phase (synchronous)\n        next_grid = np.zeros_like(grid)\n        \n        # Pre-generate random choices for vectorization speed-up\n        random_neighbor_indices = rng.integers(0, 4, size=(L, L))\n        random_uniforms = rng.random(size=(L,L))\n        \n        rows, cols = np.ogrid[:L, :L]\n        \n        # Get neighbor coordinates\n        neighbor_row_offsets = neighbor_offsets[random_neighbor_indices, 0]\n        neighbor_col_offsets = neighbor_offsets[random_neighbor_indices, 1]\n        \n        neighbor_rows = (rows + neighbor_row_offsets) % L\n        neighbor_cols = (cols + neighbor_col_offsets) % L\n        \n        # Get neighbor payoffs and strategies\n        payoffs_j = payoffs[neighbor_rows, neighbor_cols]\n        strategies_j = grid[neighbor_rows, neighbor_cols]\n        \n        # Fermi update rule\n        delta_pi = payoffs_j - payoffs\n        prob_imitate = 1.0 / (1.0 + np.exp(-beta * delta_pi))\n        \n        imitates = random_uniforms  prob_imitate\n        \n        # Build next grid\n        next_grid = np.where(imitates, strategies_j, grid)\n        \n        grid = next_grid\n\n        # Record cooperation density in the final window\n        if step = T_steps - w:\n            cooperation_history.append(np.mean(grid))\n\n    return np.mean(cooperation_history) if cooperation_history else 0.0\n\ndef find_critical_mobility(L, R, S, T, P, beta, T_steps, w, epsilon, num_runs):\n    \"\"\"\n    Finds the critical mobility rate m* using binary search.\n    \"\"\"\n    \n    def check_breakdown(m):\n        \"\"\"\n        Checks if the breakdown criterion is met for a given mobility rate m.\n        Averages results over num_runs independent simulations.\n        \"\"\"\n        coop_densities = []\n        for i in range(num_runs):\n            # Use distinct fixed seeds for reproducibility\n            seed = i * 100 \n            density = run_single_simulation(m, L, R, S, T, P, beta, T_steps, w, seed)\n            coop_densities.append(density)\n        \n        avg_coop_density = np.mean(coop_densities)\n        return avg_coop_density = epsilon\n\n    # Handle boundary conditions first\n    if check_breakdown(m=0.0):\n        return 0.0\n    \n    if not check_breakdown(m=1.0):\n        return 1.0\n\n    # Binary search for m*\n    low = 0.0\n    high = 1.0\n    num_bisections = 15  # Sufficient for 3 decimal places of precision\n\n    for _ in range(num_bisections):\n        mid = (low + high) / 2\n        if check_breakdown(m=mid):\n            high = mid  # Breakdown occurs, m* could be mid or lower\n        else:\n            low = mid   # No breakdown, m* must be higher\n            \n    return high\n\ndef solve():\n    \"\"\"\n    Runs the full analysis for the test cases provided in the problem.\n    \"\"\"\n    # (L, R, S, T, P, beta, T_steps, w, epsilon, num_runs)\n    test_cases = [\n        (40, 1.0, 0.0, 1.4, 0.0, 1.0, 400, 100, 0.05, 3), # Case A\n        (40, 1.0, 0.0, 1.05, 0.0, 1.0, 300, 80, 0.05, 3),  # Case B\n        (40, 1.0, 0.0, 1.8, 0.0, 1.0, 400, 100, 0.05, 3),  # Case C\n    ]\n\n    results = []\n    for case in test_cases:\n        m_star = find_critical_mobility(*case)\n        results.append(f\"{m_star:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}