{
    "hands_on_practices": [
        {
            "introduction": "The \"wisdom of crowds\" is a cornerstone of collective intelligence, but its effectiveness is not unconditional. This foundational exercise explores the mathematical underpinnings of group accuracy by relating it to group size $n$, individual agent variance $\\sigma^2$, and, most critically, the correlation $\\rho$ between agent errors. By deriving the variance of the group average from first principles, you will gain a quantitative understanding of why diversity of opinion is as important as individual accuracy and how correlated biases can limit the benefits of simple aggregation .",
            "id": "4128693",
            "problem": "A group of $n$ agents collaboratively estimates a fixed scalar quantity $\\theta$ by reporting individual estimates $Y_{i} = \\theta + \\varepsilon_{i}$ for $i \\in \\{1,\\dots,n\\}$. The errors $\\varepsilon_{i}$ are unbiased, $ \\mathbb{E}[\\varepsilon_{i}] = 0$, and exchangeable with common variance $\\operatorname{Var}(\\varepsilon_{i}) = \\sigma^{2}$ and constant pairwise correlation $\\operatorname{Corr}(\\varepsilon_{i},\\varepsilon_{j}) = \\rho$ for all $i \\neq j$. The group forms the simple average $ \\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i} $ as its collective estimate.\n\nStarting from the core definitions of variance and covariance, and without invoking any shortcut formulas, derive a closed-form expression for $\\operatorname{Var}(\\bar{Y})$ in terms of $n$, $\\sigma^{2}$, and $\\rho$. Then evaluate this expression for $n=25$, $\\sigma^{2}=1$, and $\\rho=0.2$. Finally, compute the ratio of the group-average variance to the single-agent variance, that is, $\\operatorname{Var}(\\bar{Y}) / \\sigma^{2}$.\n\nProvide your final answers for the pair $\\big(\\operatorname{Var}(\\bar{Y}),\\ \\operatorname{Var}(\\bar{Y}) / \\sigma^{2}\\big)$ as exact values. Do not round. Your final answer must be given as a row matrix using the $\\text{pmatrix}$ environment.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in standard probability theory, well-posed with all necessary information, and stated objectively. The provided numerical values ($n=25$, $\\sigma^2=1$, $\\rho=0.2$) are consistent; specifically, the correlation $\\rho$ lies in the valid range for an $n$-dimensional exchangeable correlation matrix, which is $\\rho \\in [-\\frac{1}{n-1}, 1]$. For $n=25$, this range is $[-\\frac{1}{24}, 1]$, and $\\rho=0.2$ is well within these bounds.\n\nThe task is to derive an expression for the variance of the group average, $\\operatorname{Var}(\\bar{Y})$, and then evaluate it. The group average is defined as $\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i}$.\n\nFirst, we express $\\bar{Y}$ in terms of the true quantity $\\theta$ and the error terms $\\varepsilon_i$.\n$$\n\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} (\\theta + \\varepsilon_{i}) = \\frac{1}{n} \\left( \\sum_{i=1}^{n} \\theta + \\sum_{i=1}^{n} \\varepsilon_{i} \\right) = \\frac{1}{n} \\left( n\\theta + \\sum_{i=1}^{n} \\varepsilon_{i} \\right) = \\theta + \\frac{1}{n} \\sum_{i=1}^{n} \\varepsilon_{i}\n$$\nThe variance of a random variable shifted by a constant is the variance of the random variable itself. Therefore,\n$$\n\\operatorname{Var}(\\bar{Y}) = \\operatorname{Var}\\left(\\theta + \\frac{1}{n} \\sum_{i=1}^{n} \\varepsilon_{i}\\right) = \\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\varepsilon_{i}\\right)\n$$\nUsing the property $\\operatorname{Var}(aX) = a^{2}\\operatorname{Var}(X)$, where $a = \\frac{1}{n}$ is a constant, we have:\n$$\n\\operatorname{Var}(\\bar{Y}) = \\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)\n$$\nThe problem requires deriving the variance of the sum from core definitions. Let $S = \\sum_{i=1}^{n} \\varepsilon_{i}$. The variance of $S$ is defined as $\\operatorname{Var}(S) = \\mathbb{E}[(S - \\mathbb{E}[S])^2]$.\nFirst, we find the expectation of $S$:\n$$\n\\mathbb{E}[S] = \\mathbb{E}\\left[\\sum_{i=1}^{n} \\varepsilon_{i}\\right] = \\sum_{i=1}^{n} \\mathbb{E}[\\varepsilon_{i}]\n$$\nGiven that $\\mathbb{E}[\\varepsilon_{i}] = 0$ for all $i$, we have $\\mathbb{E}[S] = 0$.\nThe variance of $S$ simplifies to:\n$$\n\\operatorname{Var}(S) = \\mathbb{E}[(S - 0)^2] = \\mathbb{E}[S^2]\n$$\nWe now expand $S^2$:\n$$\nS^2 = \\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)^2 = \\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)\\left(\\sum_{j=1}^{n} \\varepsilon_{j}\\right) = \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\varepsilon_{i}\\varepsilon_{j}\n$$\nWe can split this double summation into terms where the indices are equal ($i=j$) and terms where they are not ($i \\neq j$):\n$$\nS^2 = \\sum_{i=1}^{n} \\varepsilon_{i}^2 + \\sum_{i \\neq j} \\varepsilon_{i}\\varepsilon_{j}\n$$\nNow, we take the expectation of $S^2$:\n$$\n\\mathbb{E}[S^2] = \\mathbb{E}\\left[ \\sum_{i=1}^{n} \\varepsilon_{i}^2 + \\sum_{i \\neq j} \\varepsilon_{i}\\varepsilon_{j} \\right] = \\sum_{i=1}^{n} \\mathbb{E}[\\varepsilon_{i}^2] + \\sum_{i \\neq j} \\mathbb{E}[\\varepsilon_{i}\\varepsilon_{j}]\n$$\nWe relate these expectation terms to the given variance and correlation.\nFor any random variable $X$, $\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$. Since $\\mathbb{E}[\\varepsilon_{i}] = 0$ and $\\operatorname{Var}(\\varepsilon_{i}) = \\sigma^2$, we have:\n$$\n\\sigma^2 = \\mathbb{E}[\\varepsilon_{i}^2] - 0^2 \\implies \\mathbb{E}[\\varepsilon_{i}^2] = \\sigma^2\n$$\nFor any two random variables $X$ and $Y$, $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$. For $i \\neq j$, since $\\mathbb{E}[\\varepsilon_{i}] = \\mathbb{E}[\\varepsilon_{j}] = 0$, we have:\n$$\n\\operatorname{Cov}(\\varepsilon_{i}, \\varepsilon_{j}) = \\mathbb{E}[\\varepsilon_{i}\\varepsilon_{j}] - 0 \\cdot 0 \\implies \\mathbb{E}[\\varepsilon_{i}\\varepsilon_{j}] = \\operatorname{Cov}(\\varepsilon_{i}, \\varepsilon_{j})\n$$\nThe correlation is defined as $\\operatorname{Corr}(\\varepsilon_{i}, \\varepsilon_{j}) = \\frac{\\operatorname{Cov}(\\varepsilon_{i}, \\varepsilon_{j})}{\\sqrt{\\operatorname{Var}(\\varepsilon_{i})\\operatorname{Var}(\\varepsilon_{j})}}$. With the given values $\\operatorname{Corr}(\\varepsilon_{i}, \\varepsilon_{j}) = \\rho$ and $\\operatorname{Var}(\\varepsilon_{i}) = \\sigma^2$, we find the covariance for $i \\neq j$:\n$$\n\\operatorname{Cov}(\\varepsilon_{i}, \\varepsilon_{j}) = \\rho \\sqrt{\\sigma^2 \\cdot \\sigma^2} = \\rho \\sigma^2\n$$\nNow we substitute these results back into the expression for $\\mathbb{E}[S^2]$:\n$$\n\n\\operatorname{Var}(S) = \\mathbb{E}[S^2] = \\sum_{i=1}^{n} \\sigma^2 + \\sum_{i \\neq j} \\rho\\sigma^2\n$$\nThe first sum has $n$ identical terms, so its value is $n\\sigma^2$. The second sum is over all pairs of distinct indices $(i,j)$. There are $n(n-1)$ such pairs. Thus, the value of the second sum is $n(n-1)\\rho\\sigma^2$.\n$$\n\\operatorname{Var}(S) = n\\sigma^2 + n(n-1)\\rho\\sigma^2\n$$\nFinally, we substitute this back into our expression for $\\operatorname{Var}(\\bar{Y})$:\n$$\n\\operatorname{Var}(\\bar{Y}) = \\frac{1}{n^2} \\operatorname{Var}(S) = \\frac{1}{n^2} [n\\sigma^2 + n(n-1)\\rho\\sigma^2]\n$$\nFactoring out $n\\sigma^2$ from the bracketed term gives the closed-form expression:\n$$\n\\operatorname{Var}(\\bar{Y}) = \\frac{n\\sigma^2}{n^2} [1 + (n-1)\\rho] = \\frac{\\sigma^2}{n}[1 + (n-1)\\rho]\n$$\nThis completes the derivation.\n\nNext, we evaluate this expression for $n=25$, $\\sigma^2=1$, and $\\rho=0.2$.\n$$\n\\operatorname{Var}(\\bar{Y}) = \\frac{1}{25}[1 + (25-1)(0.2)] = \\frac{1}{25}[1 + (24)(0.2)] = \\frac{1}{25}[1 + 4.8] = \\frac{5.8}{25}\n$$\nTo provide an exact value, we convert the decimal to a fraction:\n$$\n\\operatorname{Var}(\\bar{Y}) = \\frac{5.8}{25} = \\frac{58}{250} = \\frac{29}{125}\n$$\nFinally, we compute the ratio of the group-average variance to the single-agent variance, $\\operatorname{Var}(\\bar{Y}) / \\sigma^2$.\nUsing the derived closed-form expression:\n$$\n\\frac{\\operatorname{Var}(\\bar{Y})}{\\sigma^2} = \\frac{1}{\\sigma^2} \\left( \\frac{\\sigma^2}{n}[1 + (n-1)\\rho] \\right) = \\frac{1}{n}[1 + (n-1)\\rho]\n$$\nUsing the provided values:\n$$\n\\frac{\\operatorname{Var}(\\bar{Y})}{\\sigma^2} = \\frac{1}{25}[1 + (24)(0.2)] = \\frac{5.8}{25} = \\frac{29}{125}\n$$\nAlternatively, using the previously calculated value for $\\operatorname{Var}(\\bar{Y})$ and the given $\\sigma^2=1$:\n$$\n\\frac{\\operatorname{Var}(\\bar{Y})}{\\sigma^2} = \\frac{29/125}{1} = \\frac{29}{125}\n$$\nThe pair of answers is $\\left(\\operatorname{Var}(\\bar{Y}), \\frac{\\operatorname{Var}(\\bar{Y})}{\\sigma^2}\\right) = \\left(\\frac{29}{125}, \\frac{29}{125}\\right)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{29}{125} & \\frac{29}{125} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond static aggregation, collective intelligence often emerges from dynamic social interactions. The DeGroot model offers a fundamental framework for how repeated local averaging within a network can lead to a global consensus. This practice challenges you to determine the final consensus value for a given network structure, revealing that the outcome is a weighted average of initial opinions. The weights themselves are a measure of each agent's long-run influence, which is determined by the network's topology .",
            "id": "4128727",
            "problem": "Consider a group of $n=3$ agents attempting to aggregate their individual scalar opinions through repeated local averaging in a connected social network, modeling collective intelligence within complex adaptive systems. Let the opinion vector at discrete time $t$ be $x(t) \\in \\mathbb{R}^{3}$, and suppose the opinion update is given by the DeGroot linear averaging rule $x(t+1) = W x(t)$, where $W$ is a row-stochastic influence matrix encoding how each agent weights the opinions of its neighbors. Assume the network is strongly connected and includes self-weights, so that convergence to a consensus is well defined by standard results on nonnegative, primitive matrices. The influence matrix is\n$$\nW=\\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2}\n\\end{pmatrix}.\n$$\nGiven the initial opinions\n$$\nx(0)=\\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix},\n$$\ndetermine the exact consensus value, defined as the common scalar limit to which all components of $x(t)$ converge as $t \\to \\infty$. Express your answer as an exact fraction. No rounding is required.",
            "solution": "The DeGroot model specifies that opinions evolve according to $x(t+1)=W x(t)$, where $W$ is a nonnegative, row-stochastic matrix. A row-stochastic matrix satisfies $W \\mathbf{1}=\\mathbf{1}$, where $\\mathbf{1} \\in \\mathbb{R}^{3}$ denotes the vector whose entries are all $1$. If $W$ is primitive (irreducible and aperiodic), then by the Perron–Frobenius theorem and standard ergodic limit results for products of stochastic matrices, the powers of $W$ converge to a rank-one limit:\n$$\n\\lim_{t \\to \\infty} W^{t} = \\mathbf{1} v^{\\top},\n$$\nwhere $v \\in \\mathbb{R}^{3}$ is the unique probability vector (nonnegative components summing to $1$) that satisfies the left eigenvector relation\n$$\nv^{\\top} W = v^{\\top},\n$$\nequivalently\n$$\nW^{\\top} v = v,\n$$\ntogether with the normalization $v^{\\top} \\mathbf{1} = 1$. Under this limit, for any initial condition $x(0)$, one has\n$$\n\\lim_{t \\to \\infty} x(t) = \\lim_{t \\to \\infty} W^{t} x(0) = \\mathbf{1} \\left(v^{\\top} x(0)\\right),\n$$\nso all agents converge to the scalar consensus value $v^{\\top} x(0)$.\n\nWe first verify the conditions. The matrix $W$ is nonnegative, and each row sums to $1$, so $W$ is row-stochastic. Because each diagonal entry $W_{ii}=\\frac{1}{2}$ is strictly positive, the chain is aperiodic. The directed graph induced by positive entries of $W$ has edges that allow paths between any pair of nodes (for example, node $1$ listens to nodes $1$ and $2$; node $2$ listens to nodes $2$ and $3$; node $3$ listens to nodes $1$ and $3$), which yields strong connectivity. Hence $W$ is primitive, and consensus is guaranteed.\n\nTo compute the consensus value, we find $v$ by solving $W^{\\top} v = v$ with $v_{1}+v_{2}+v_{3}=1$. Compute\n$$\nW^{\\top} = \\begin{pmatrix}\n\\frac{1}{2} & 0 & \\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n0 & \\frac{1}{2} & \\frac{1}{2}\n\\end{pmatrix}.\n$$\nLet $v = \\begin{pmatrix} v_{1} \\\\ v_{2} \\\\ v_{3} \\end{pmatrix}$. The eigenvector equation $W^{\\top} v = v$ yields\n\n$$\n\\begin{cases}\nv_{1} = \\frac{1}{2} v_{1} + \\frac{1}{2} v_{3}, \\\\\nv_{2} = \\frac{1}{2} v_{1} + \\frac{1}{2} v_{2}, \\\\\nv_{3} = \\frac{1}{2} v_{2} + \\frac{1}{2} v_{3}.\n\\end{cases}\n$$\n\nRearranging each equation gives\n\n$$\n\\begin{cases}\n\\frac{1}{2} v_{1} = \\frac{1}{2} v_{3} \\Rightarrow v_{1} = v_{3}, \\\\\n\\frac{1}{2} v_{2} = \\frac{1}{2} v_{1} \\Rightarrow v_{2} = v_{1}, \\\\\n\\frac{1}{2} v_{3} = \\frac{1}{2} v_{2} \\Rightarrow v_{3} = v_{2}.\n\\end{cases}\n$$\n\nTherefore $v_{1} = v_{2} = v_{3}$. With the normalization $v_{1}+v_{2}+v_{3}=1$, it follows that $v_{1} = v_{2} = v_{3} = \\frac{1}{3}$, hence\n$$\nv = \\begin{pmatrix} \\frac{1}{3} \\\\ \\frac{1}{3} \\\\ \\frac{1}{3} \\end{pmatrix}.\n$$\nThe consensus value is $v^{\\top} x(0)$, so with $x(0)=\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$,\n$$\nv^{\\top} x(0) = \\begin{pmatrix} \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{3}.\n$$\nThus all agents’ opinions converge to the exact value $\\frac{1}{3}$.",
            "answer": "$$\\boxed{\\frac{1}{3}}$$"
        },
        {
            "introduction": "Building upon the basic consensus model, this exercise introduces a more realistic feature of social systems: the presence of \"stubborn\" agents who do not update their opinions. These agents can represent committed individuals, media outlets, or other fixed external signals influencing a population. By calculating the steady-state opinions of the adaptive agents, you will discover how their final beliefs are anchored by the opinions of the stubborn agents. This practice provides a powerful tool for modeling how external information or inflexible subgroups shape collective outcomes in complex adaptive systems .",
            "id": "4128756",
            "problem": "Consider a collective opinion formation process modeled by the linear weighted averaging dynamics (often called the DeGroot model): at discrete time $t \\in \\{0,1,2,\\dots\\}$, the opinion vector $x(t) \\in \\mathbb{R}^{n}$ evolves according to $x(t+1) = W x(t)$, where $W \\in \\mathbb{R}^{n \\times n}$ is a row-stochastic influence matrix with nonnegative entries and each row summing to $1$. In this setting, a stubborn agent is encoded by a row of $W$ equal to a standard basis vector, which imposes a self-weight $1$ and zero weight on all others, thereby fixing its opinion over time. Such a subset of stubborn agents represents exogenous signals in the population, and the rest of the agents are adaptive.\n\nConstruct the following network of $n=5$ agents with two stubborn agents and three adaptive agents. Agents $1$ and $4$ are stubborn. The influence matrix $W$ is given by\n$$\nW \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0\\\\\n0.3 & 0.4 & 0.2 & 0.1 & 0\\\\\n0 & 0.3 & 0.5 & 0.2 & 0\\\\\n0 & 0 & 0 & 1 & 0\\\\\n0.1 & 0 & 0.5 & 0.4 & 0\n\\end{pmatrix}.\n$$\nLet the stubborn opinions be $x_{1}(0) = s_{1} = 0.3$ and $x_{4}(0) = s_{4} = 0.9$, which remain fixed for all time due to the encoding of stubbornness in $W$. The initial opinions of the adaptive agents $2$, $3$, and $5$ are arbitrary finite real numbers.\n\nStarting from the core definitions of linear weighted averaging dynamics, absorbing behavior induced by stubborn agents, and the steady-state condition $x^{\\ast} = W x^{\\ast}$, derive the steady-state opinions of the adaptive agents and determine the steady-state opinion of agent $5$. Express the final value for agent $5$ as an exact fraction. No units are required.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the established theory of linear consensus models (the DeGroot model), is well-posed with a unique solution, and is expressed in objective, formal language. There are no contradictions, missing data, or other flaws that would invalidate it. We may therefore proceed with the derivation.\n\nThe dynamics of the collective opinion formation process are described by the linear system $x(t+1) = W x(t)$, where $x(t) \\in \\mathbb{R}^{5}$ is the vector of opinions at time $t$ and $W \\in \\mathbb{R}^{5 \\times 5}$ is the influence matrix. The steady-state opinion vector, denoted by $x^{\\ast}$, must satisfy the condition $x^{\\ast} = W x^{\\ast}$. This represents a fixed point of the dynamical system, where the opinions no longer change over time.\n\nThe influence matrix $W$ is given as:\n$$\nW \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0\\\\\n0.3 & 0.4 & 0.2 & 0.1 & 0\\\\\n0 & 0.3 & 0.5 & 0.2 & 0\\\\\n0 & 0 & 0 & 1 & 0\\\\\n0.1 & 0 & 0.5 & 0.4 & 0\n\\end{pmatrix}\n$$\nAgents $1$ and $4$ are stubborn. This is reflected in the first and fourth rows of $W$, which are the standard basis vectors $e_1^T = (1, 0, 0, 0, 0)$ and $e_4^T = (0, 0, 0, 1, 0)$, respectively. This structure ensures that their opinions are fixed, i.e., $x_1(t+1) = x_1(t)$ and $x_4(t+1) = x_4(t)$ for all $t$. Their opinions are given as exogenous signals: $x_1(t) = s_1 = 0.3$ and $x_4(t) = s_4 = 0.9$ for all $t \\geq 0$. Consequently, their steady-state opinions are $x_1^{\\ast} = 0.3$ and $x_4^{\\ast} = 0.9$.\n\nAgents $2$, $3$, and $5$ are adaptive, and their steady-state opinions are determined by the influence of the entire network. We can write the steady-state condition $x^{\\ast} = W x^{\\ast}$ as a system of linear equations:\n$x_1^{\\ast} = 1 \\cdot x_1^{\\ast}$\n$x_2^{\\ast} = 0.3 x_1^{\\ast} + 0.4 x_2^{\\ast} + 0.2 x_3^{\\ast} + 0.1 x_4^{\\ast} + 0 x_5^{\\ast}$\n$x_3^{\\ast} = 0 x_1^{\\ast} + 0.3 x_2^{\\ast} + 0.5 x_3^{\\ast} + 0.2 x_4^{\\ast} + 0 x_5^{\\ast}$\n$x_4^{\\ast} = 1 \\cdot x_4^{\\ast}$\n$x_5^{\\ast} = 0.1 x_1^{\\ast} + 0 x_2^{\\ast} + 0.5 x_3^{\\ast} + 0.4 x_4^{\\ast} + 0 x_5^{\\ast}$\n\nThe first and fourth equations are identities, consistent with the stubborn nature of agents $1$ and $4$. We substitute the known values of $x_1^{\\ast} = 0.3$ and $x_4^{\\ast} = 0.9$ into the equations for the adaptive agents:\nFor agent $2$:\n$x_2^{\\ast} = 0.3(0.3) + 0.4 x_2^{\\ast} + 0.2 x_3^{\\ast} + 0.1(0.9)$\n$x_2^{\\ast} = 0.09 + 0.4 x_2^{\\ast} + 0.2 x_3^{\\ast} + 0.09$\nRearranging the terms to solve for $x_2^{\\ast}$:\n$(1 - 0.4) x_2^{\\ast} - 0.2 x_3^{\\ast} = 0.18$\n$0.6 x_2^{\\ast} - 0.2 x_3^{\\ast} = 0.18$\nMultiplying by $10$ for clarity:\n$6 x_2^{\\ast} - 2 x_3^{\\ast} = 1.8 \\implies 3 x_2^{\\ast} - x_3^{\\ast} = 0.9 \\quad (1)$\n\nFor agent $3$:\n$x_3^{\\ast} = 0.3 x_2^{\\ast} + 0.5 x_3^{\\ast} + 0.2(0.9)$\n$x_3^{\\ast} = 0.3 x_2^{\\ast} + 0.5 x_3^{\\ast} + 0.18$\nRearranging the terms:\n$(1 - 0.5) x_3^{\\ast} - 0.3 x_2^{\\ast} = 0.18$\n$0.5 x_3^{\\ast} - 0.3 x_2^{\\ast} = 0.18$\nMultiplying by $10$:\n$5 x_3^{\\ast} - 3 x_2^{\\ast} = 1.8 \\quad (2)$\n\nWe now have a system of two linear equations for $x_2^{\\ast}$ and $x_3^{\\ast}$. From equation $(1)$, we can express $x_3^{\\ast}$ in terms of $x_2^{\\ast}$:\n$x_3^{\\ast} = 3 x_2^{\\ast} - 0.9$\n\nSubstitute this expression for $x_3^{\\ast}$ into equation $(2)$:\n$5 (3 x_2^{\\ast} - 0.9) - 3 x_2^{\\ast} = 1.8$\n$15 x_2^{\\ast} - 4.5 - 3 x_2^{\\ast} = 1.8$\n$12 x_2^{\\ast} = 1.8 + 4.5$\n$12 x_2^{\\ast} = 6.3$\n$x_2^{\\ast} = \\frac{6.3}{12} = \\frac{63}{120}$\nTo simplify this fraction, we divide the numerator and denominator by their greatest common divisor, which is $3$:\n$x_2^{\\ast} = \\frac{63 \\div 3}{120 \\div 3} = \\frac{21}{40}$\n\nNow we can find $x_3^{\\ast}$:\n$x_3^{\\ast} = 3 x_2^{\\ast} - 0.9 = 3 \\left(\\frac{21}{40}\\right) - \\frac{9}{10} = \\frac{63}{40} - \\frac{36}{40} = \\frac{27}{40}$\n\nFinally, we determine the steady-state opinion of agent $5$ using its corresponding equation:\n$x_5^{\\ast} = 0.1 x_1^{\\ast} + 0.5 x_3^{\\ast} + 0.4 x_4^{\\ast}$\nSubstitute the known values of $x_1^{\\ast}$, $x_3^{\\ast}$, and $x_4^{\\ast}$:\n$x_5^{\\ast} = 0.1(0.3) + 0.5\\left(\\frac{27}{40}\\right) + 0.4(0.9)$\n$x_5^{\\ast} = 0.03 + \\frac{1}{2}\\left(\\frac{27}{40}\\right) + 0.36$\n$x_5^{\\ast} = \\frac{3}{100} + \\frac{27}{80} + \\frac{36}{100}$\nCombine the terms with denominator $100$:\n$x_5^{\\ast} = \\frac{39}{100} + \\frac{27}{80}$\nTo add these fractions, we find a common denominator. The least common multiple of $100 = 2^2 \\cdot 5^2$ and $80 = 2^4 \\cdot 5$ is $2^4 \\cdot 5^2 = 16 \\cdot 25 = 400$.\n$x_5^{\\ast} = \\frac{39 \\cdot 4}{100 \\cdot 4} + \\frac{27 \\cdot 5}{80 \\cdot 5}$\n$x_5^{\\ast} = \\frac{156}{400} + \\frac{135}{400}$\n$x_5^{\\ast} = \\frac{156 + 135}{400} = \\frac{291}{400}$\n\nThe fraction $\\frac{291}{400}$ is in simplest form because the prime factorization of the numerator is $291 = 3 \\cdot 97$, and the prime factorization of the denominator is $400 = 2^4 \\cdot 5^2$. They share no common prime factors.\nThus, the steady-state opinion of agent $5$ is $\\frac{291}{400}$.",
            "answer": "$$\\boxed{\\frac{291}{400}}$$"
        }
    ]
}