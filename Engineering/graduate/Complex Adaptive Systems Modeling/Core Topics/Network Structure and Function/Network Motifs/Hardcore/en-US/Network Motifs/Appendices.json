{
    "hands_on_practices": [
        {
            "introduction": "Network motifs are more than just static over-represented patterns; they are the building blocks of complex dynamic behaviors. This practice explores the famous coherent type-1 feed-forward loop (C1-FFL), guiding you through a mathematical analysis to reveal how its specific wiring diagram gives rise to a sign-sensitive response delay . By deriving and solving the underlying differential equations, you will uncover the mechanism that allows this motif to function as a persistence detector, filtering out transient signals.",
            "id": "4366055",
            "problem": "Consider a gene regulatory network motif known as the coherent Type-1 feed-forward loop (C1-FFL), in which a transcription factor $X$ activates an intermediate gene product $Y$, and both $X$ and $Y$ positively regulate a downstream gene product $Z$. In systems biomedicine, such motifs are modeled using first-order production and degradation kinetics and Hill-type input-output relationships for transcriptional activation. A standard activation Hill function for an input $U$ acting on a target is defined as $f(U) = \\dfrac{U^{n}}{K^{n} + U^{n}}$, where $n$ is the Hill coefficient and $K$ is the activation constant. Assume negligible basal expression when the activating input is absent.\n\nStarting from these core definitions:\n\n1) Derive ordinary differential equations for $Y$ and $Z$ consistent with first-order degradation and Hill-type activation by $X$ and $Y$, under the assumption that $Z$ implements an AND logic gate for its two inputs. Use symbols $\\alpha_Y$, $\\alpha_Z$ for maximal production rates, $\\beta_Y$, $\\beta_Z$ for degradation rates, and independent Hill functions $f_X(X)$, $g_X(X)$, and $h_Y(Y)$ for the regulatory effects of $X$ on $Y$, $X$ on $Z$, and $Y$ on $Z$, respectively.\n\n2) To analyze sign-sensitive delays, consider the following protocol and parameter regime:\n- Hill coefficients are $n=1$ for all regulatory links.\n- The input $X(t)$ is a step: $X(t) = 0$ for $t<0$ and $X(t) = X_{0}$ for $t \\ge 0$.\n- Initial conditions are $Y(0)=0$ and $Z(0)=0$.\n- The AND gate at $Z$ is implemented by the product $g_X(X)\\,h_Y(Y)$.\n- The production term $h_Y(Y)$ is in the weak activation regime for $Y$, namely $Y(t) \\ll K_{Y}$, so that $h_Y(Y) \\approx \\dfrac{Y}{K_{Y}}$.\n- Degradation rates of $Y$ and $Z$ are equal: $\\beta_Y = \\beta_Z = \\beta > 0$.\n- There is no production when $X=0$, i.e., $f_X(0)=0$ and $g_X(0)=0$.\n\nUnder these assumptions:\n(a) Derive $Z(t)$ for $t \\ge 0$ when $X$ is stepped from $0$ to $X_{0}$ and held constant.\n(b) Define the dimensionless ON half-time $\\theta_{\\mathrm{on}} = \\beta\\,t_{\\mathrm{on}}$, where $t_{\\mathrm{on}}$ is the time after $t=0$ at which $Z(t)$ first reaches one-half of its steady-state level for constant $X_{0}$, and solve for $\\theta_{\\mathrm{on}}$ in closed form.\n(c) Suppose the system has reached steady state under $X=X_{0}$ and then, at a later time $t=T_{\\mathrm{off}}$, $X$ is switched instantaneously to $0$. Define the dimensionless OFF half-time $\\theta_{\\mathrm{off}} = \\beta\\,(t_{\\mathrm{off}}-T_{\\mathrm{off}})$ as the time after shutoff needed for $Z$ to decay to one-half of its previous steady-state level, and solve for $\\theta_{\\mathrm{off}}$ in closed form.\n(d) Using parts (b) and (c), compute the dimensionless delay difference $\\Delta \\theta = \\theta_{\\mathrm{on}} - \\theta_{\\mathrm{off}}$ as a single closed-form analytic expression.\n\nExplain in your derivation why the AND logic together with negligible basal activity and the temporal ordering of $X \\to Y \\to Z$ produces a sign-sensitive delay (slow ON, fast OFF) for this motif. The final answer must be only the expression for $\\Delta \\theta$. No numerical evaluation is required, and no units should be included in the final answer.",
            "solution": "The user-provided problem is assessed to be valid as it is scientifically grounded in the principles of biochemical kinetics and systems biology, is well-posed with a clear and complete set of definitions and constraints, and is expressed in objective, formalizable language.\n\n### Part 1: Derivation of Ordinary Differential Equations (ODEs)\n\nThe dynamics of the concentrations of gene products $Y$ and $Z$ are modeled by first-order ordinary differential equations that balance production and degradation.\n\nThe rate of change of the concentration of $Y$, denoted as $[Y]$, is given by its production rate activated by $X$ minus its first-order degradation. The activation is described by the Hill function $f_X(X)$, and the maximal production rate is $\\alpha_Y$. The degradation rate is $\\beta_Y$. Thus, the ODE for $Y$ is:\n$$ \\frac{d[Y]}{dt} = \\alpha_Y f_X([X]) - \\beta_Y [Y] $$\nFor simplicity, we will denote the concentrations $[X]$, $[Y]$, and $[Z]$ as $X$, $Y$, and $Z$.\n$$ \\frac{dY}{dt} = \\alpha_Y f_X(X) - \\beta_Y Y $$\n\nThe production of $Z$ is co-activated by $X$ and $Y$. The problem states that this regulation implements an AND logic gate, which is modeled as the product of the individual Hill functions $g_X(X)$ and $h_Y(Y)$. The maximal production rate for $Z$ is $\\alpha_Z$, and its degradation rate is $\\beta_Z$. The ODE for $Z$ is therefore:\n$$ \\frac{dZ}{dt} = \\alpha_Z g_X(X) h_Y(Y) - \\beta_Z Z $$\n\n### Part 2: Analysis of Sign-Sensitive Delay\n\nWe now apply the specific assumptions provided for the analysis.\n\n#### (a) Derivation of $Z(t)$ for the ON-response\n\nThe assumptions are:\n- Hill coefficient $n=1$, so the Hill function is $f(U) = \\frac{U}{K+U}$.\n- Input $X(t) = X_0$ for $t \\ge 0$.\n- Initial conditions $Y(0)=0$ and $Z(0)=0$.\n- AND gate production term is $\\alpha_Z g_X(X) h_Y(Y)$.\n- Weak activation by $Y$: $Y(t) \\ll K_Y$, so $h_Y(Y) = \\frac{Y}{K_Y+Y} \\approx \\frac{Y}{K_Y}$.\n- Equal degradation rates: $\\beta_Y = \\beta_Z = \\beta > 0$.\n\nFirst, we solve for $Y(t)$. The ODE for $Y$ becomes:\n$$ \\frac{dY}{dt} = \\alpha_Y \\frac{X_0}{K_X + X_0} - \\beta Y $$\nwhere $K_X$ is the activation constant for the $X \\to Y$ link.\nThis is a linear first-order ODE. Let the constant production term be $S_Y = \\alpha_Y \\frac{X_0}{K_X + X_0}$. The equation is $\\frac{dY}{dt} + \\beta Y = S_Y$. The solution with the initial condition $Y(0)=0$ is:\n$$ Y(t) = \\frac{S_Y}{\\beta} (1 - \\exp(-\\beta t)) = Y_{ss} (1 - \\exp(-\\beta t)) $$\nwhere $Y_{ss} = S_Y/\\beta$ is the steady-state concentration of $Y$.\n\nNext, we solve for $Z(t)$. The ODE for $Z$ is:\n$$ \\frac{dZ}{dt} = \\alpha_Z \\left( \\frac{X_0}{K'_X + X_0} \\right) \\left( \\frac{Y(t)}{K_Y} \\right) - \\beta Z $$\nwhere $K'_X$ and $K_Y$ are the activation constants for the $X \\to Z$ and $Y \\to Z$ links, respectively. Let the constant terms be grouped into a single production constant $S_Z = \\frac{\\alpha_Z}{K_Y} \\frac{X_0}{K'_X+X_0}$.\nThe ODE becomes:\n$$ \\frac{dZ}{dt} + \\beta Z = S_Z Y(t) = S_Z Y_{ss} (1 - \\exp(-\\beta t)) $$\nThis is a linear first-order non-homogeneous ODE. We solve it using an integrating factor, $\\mu(t) = \\exp(\\int \\beta dt) = \\exp(\\beta t)$.\n$$ \\frac{d}{dt}(Z \\exp(\\beta t)) = S_Z Y_{ss} (1 - \\exp(-\\beta t)) \\exp(\\beta t) = S_Z Y_{ss} (\\exp(\\beta t) - 1) $$\nIntegrating from $0$ to $t$:\n$$ Z(t)\\exp(\\beta t) - Z(0)\\exp(0) = \\int_0^t S_Z Y_{ss} (\\exp(\\beta \\tau) - 1) d\\tau $$\nUsing $Z(0)=0$:\n$$ Z(t)\\exp(\\beta t) = S_Z Y_{ss} \\left[ \\frac{1}{\\beta}\\exp(\\beta \\tau) - \\tau \\right]_0^t = S_Z Y_{ss} \\left( (\\frac{1}{\\beta}\\exp(\\beta t) - t) - (\\frac{1}{\\beta} - 0) \\right) $$\n$$ Z(t) = S_Z Y_{ss} \\left( \\frac{1}{\\beta} - t \\exp(-\\beta t) - \\frac{1}{\\beta}\\exp(-\\beta t) \\right) $$\nThe steady-state value of $Z$ is $Z_{ss} = \\lim_{t\\to\\infty} Z(t) = \\frac{S_Z Y_{ss}}{\\beta}$.\nSubstituting this back, we get the expression for $Z(t)$:\n$$ Z(t) = Z_{ss} (1 - \\exp(-\\beta t) - \\beta t \\exp(-\\beta t)) $$\n\n#### (b) Derivation of the dimensionless ON half-time, $\\theta_{\\mathrm{on}}$\n\nThe ON half-time, $t_{\\mathrm{on}}$, is the time at which $Z(t_{\\mathrm{on}}) = \\frac{1}{2}Z_{ss}$.\n$$ \\frac{1}{2} Z_{ss} = Z_{ss} (1 - \\exp(-\\beta t_{\\mathrm{on}}) - \\beta t_{\\mathrm{on}} \\exp(-\\beta t_{\\mathrm{on}})) $$\n$$ \\frac{1}{2} = 1 - (1 + \\beta t_{\\mathrm{on}}) \\exp(-\\beta t_{\\mathrm{on}}) $$\n$$ (1 + \\beta t_{\\mathrm{on}}) \\exp(-\\beta t_{\\mathrm{on}}) = \\frac{1}{2} $$\nLet $\\theta_{\\mathrm{on}} = \\beta t_{\\mathrm{on}}$. The equation becomes:\n$$ (1 + \\theta_{\\mathrm{on}}) \\exp(-\\theta_{\\mathrm{on}}) = \\frac{1}{2} $$\nThis is a transcendental equation whose solution can be expressed using the Lambert W function, $W(z)$, which is defined as the solution to $z = W(z) \\exp(W(z))$. To transform our equation into this form, let $u = -(1 + \\theta_{\\mathrm{on}})$. Then $\\theta_{\\mathrm{on}} = -u-1$.\n$$ (-u) \\exp(-(-u-1)) = \\frac{1}{2} \\implies -u \\exp(u+1) = \\frac{1}{2} \\implies u \\exp(u) = -\\frac{1}{2e} $$\nThe solution is $u = W_k(-\\frac{1}{2e})$, where $k$ is the branch index. Since $\\theta_{\\mathrm{on}} = \\beta t_{\\mathrm{on}}$ must be a positive real number, we require $\\theta_{\\mathrm{on}} = -u-1 > 0$, which implies $u < -1$. The argument $-\\frac{1}{2e}$ is in the interval $[-\\frac{1}{e}, 0)$, for which two real branches of the Lambert W function exist, $W_0$ and $W_{-1}$. The range of the principal branch $W_0$ is $[-1, \\infty)$, while the range of the $W_{-1}$ branch is $(-\\infty, -1]$. To satisfy $u < -1$, we must choose the $k=-1$ branch.\n$$ u = W_{-1}\\left(-\\frac{1}{2e}\\right) $$\nTherefore, the dimensionless ON half-time is:\n$$ \\theta_{\\mathrm{on}} = -1 - u = -1 - W_{-1}\\left(-\\frac{1}{2e}\\right) $$\n\n#### (c) Derivation of the dimensionless OFF half-time, $\\theta_{\\mathrm{off}}$\n\nFor the OFF-response, the system starts at steady-state ($Y(T_{\\mathrm{off}}) = Y_{ss}$, $Z(T_{\\mathrm{off}})=Z_{ss}$) and at time $t=T_{\\mathrm{off}}$, the input is switched to $X=0$. Since $f_X(0)=0$ and $g_X(0)=0$, all production ceases. The ODE for $Z$ for time $t' = t - T_{\\mathrm{off}} \\ge 0$ is:\n$$ \\frac{dZ}{dt'} = -\\beta Z $$\nwith the initial condition $Z(t'=0) = Z_{ss}$. The solution is simple exponential decay:\n$$ Z(t') = Z_{ss} \\exp(-\\beta t') $$\nThe OFF half-time, $t'_{\\mathrm{off}} = t_{\\mathrm{off}} - T_{\\mathrm{off}}$, is the time at which $Z(t'_{\\mathrm{off}}) = \\frac{1}{2}Z_{ss}$.\n$$ \\frac{1}{2} Z_{ss} = Z_{ss} \\exp(-\\beta t'_{\\mathrm{off}}) $$\n$$ \\frac{1}{2} = \\exp(-\\beta t'_{\\mathrm{off}}) $$\nTaking the natural logarithm of both sides:\n$$ \\ln\\left(\\frac{1}{2}\\right) = -\\beta t'_{\\mathrm{off}} \\implies -\\ln(2) = -\\beta t'_{\\mathrm{off}} $$\nThe dimensionless OFF half-time is $\\theta_{\\mathrm{off}} = \\beta t'_{\\mathrm{off}}$, which gives:\n$$ \\theta_{\\mathrm{off}} = \\ln(2) $$\n\n#### (d) Computation of the dimensionless delay difference, $\\Delta\\theta$\n\nThe dimensionless delay difference is $\\Delta\\theta = \\theta_{\\mathrm{on}} - \\theta_{\\mathrm{off}}$.\n$$ \\Delta\\theta = \\left(-1 - W_{-1}\\left(-\\frac{1}{2e}\\right)\\right) - \\ln(2) $$\n\n### Explanation of Sign-Sensitive Delay\n\nThe C1-FFL with AND logic inherently produces a sign-sensitive delay, characterized by a slow ON-response and a fast OFF-response.\nThe **fast OFF-response** occurs because the production of $Z$ requires both $X$ and $Y$ to be present. When the input signal $X$ is switched OFF, the production term for $Z$, $\\alpha_Z g_X(X) h_Y(Y)$, immediately drops to zero because $g_X(0)=0$. The concentration of $Z$ then decays exponentially with a rate constant $\\beta$, which is a rapid process. The system does not need to wait for $Y$ to decay; the shutoff is gated directly by $X$.\nThe **slow ON-response** is due to the delay in the accumulation of the intermediate, $Y$. When $X$ is switched ON, the production of $Z$ cannot begin at its maximal rate immediately. Although the input from the $X \\to Z$ path is present, the input from the $Y \\to Z$ path is initially zero ($Y(0)=0$). $Z$ production only builds up as $Y$ itself is produced and accumulates. This two-step activation cascade ($X \\to Y$ and $(X,Y) \\to Z$) creates a lag. Mathematically, this lag is evident because the time derivative of $Z$ at $t=0$ is zero: $\\frac{dZ}{dt}|_{t=0} = S_Z Y(0) - \\beta Z(0) = 0$. This contrasts with a simple single-input system, where the initial rate of production would be maximal. The resulting response curve for $Z(t)$ is sigmoidal, reflecting the initial lag phase before a faster rise. This mechanism allows the motif to function as a *persistence detector*, filtering out brief input pulses that are not long enough for $Y$ to accumulate sufficiently.\nThe difference, $\\Delta \\theta$, quantifies this asymmetry in response times. Since $\\theta_{\\mathrm{on}} \\approx 1.678$ (from numerical evaluation of the symbolic result) and $\\theta_{\\mathrm{off}} = \\ln(2) \\approx 0.693$, the ON-time is significantly longer than the OFF-time.",
            "answer": "$$\n\\boxed{-1 - W_{-1}\\left(-\\frac{1}{2e}\\right) - \\ln(2)}\n$$"
        },
        {
            "introduction": "Simply counting motifs is not enough; a high count might be an artifact of simpler network properties, such as the presence of high-degree hub nodes. This exercise demonstrates the crucial concept of statistical significance by having you normalize motif counts against a baseline expectation derived from a configuration null model . You will derive from first principles why hubs inflate counts and then compute a normalized score that isolates non-trivial structural organization from the effects of the degree sequence.",
            "id": "4134009",
            "problem": "Consider a directed network motif known as a feed-forward loop, defined on distinct nodes $i,j,k$ by the presence of directed edges $i \\rightarrow j$, $j \\rightarrow k$, and $i \\rightarrow k$. In the directed configuration model (Chung–Lu) for sparse networks, assume the baseline expected probability of an edge from node $u$ to node $v$ is given by $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$, where $k_{u}^{\\mathrm{out}}$ is the out-degree of node $u$, $k_{v}^{\\mathrm{in}}$ is the in-degree of node $v$, and $m$ is the total number of edges. Work under the independence approximation for edge occurrences.\n\nYou are given the directed network on nodes $a,b,c,d,e$ with the following edges:\n$a \\rightarrow b$, $a \\rightarrow c$, $a \\rightarrow d$, $a \\rightarrow e$, $b \\rightarrow c$, $b \\rightarrow d$, $b \\rightarrow e$, $c \\rightarrow d$, $c \\rightarrow e$, $d \\rightarrow e$.\n\nUsing only fundamental definitions and the stated baseline, first justify from first principles why nodes with large $k^{\\mathrm{out}}$ or large $k^{\\mathrm{in}}$ tend to inflate raw feed-forward loop counts under this baseline. Then, derive a normalization in which each observed feed-forward loop on $(i,j,k)$ is assigned a weight equal to the inverse of the product of the baseline edge probabilities for its three edges, and define the normalized motif score $S$ as the sum of these weights over all observed feed-forward loops in the given network.\n\nCompute the exact value of $S$ for this network. Express your final answer as an exact value; no rounding is required. Do not include any units in your final answer.",
            "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- **Motif Definition**: A feed-forward loop (FFL) is defined on distinct nodes $i,j,k$ by the presence of directed edges $i \\rightarrow j$, $j \\rightarrow k$, and $i \\rightarrow k$.\n- **Network Model**: Directed configuration model (Chung–Lu) for sparse networks.\n- **Baseline Edge Probability**: The probability of an edge from node $u$ to node $v$ is $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$.\n- **Model Parameters**: $k_{u}^{\\mathrm{out}}$ is the out-degree of node $u$, $k_{v}^{\\mathrm{in}}$ is the in-degree of node $v$, and $m$ is the total number of edges.\n- **Approximation**: Edge occurrences are treated as independent events.\n- **Network Specification**: Nodes are $\\{a,b,c,d,e\\}$. Edges are $a \\rightarrow b$, $a \\rightarrow c$, $a \\rightarrow d$, $a \\rightarrow e$, $b \\rightarrow c$, $b \\rightarrow d$, $b \\rightarrow e$, $c \\rightarrow d$, $c \\rightarrow e$, $d \\rightarrow e$.\n- **Task 1**: Justify from first principles why nodes with large $k^{\\mathrm{out}}$ or $k^{\\mathrm{in}}$ inflate raw FFL counts under this baseline.\n- **Task 2**: Define a normalized motif score $S$ where each observed FFL on $(i,j,k)$ is weighted by the inverse of the product of the baseline probabilities of its three constituent edges. $S$ is the sum of these weights.\n- **Task 3**: Compute the exact value of $S$ for the given network.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the field of network science and complex systems. The feed-forward loop is a canonical network motif. The directed configuration model (or Chung-Lu model) is a standard null model used for motif significance analysis. The method of normalization by inverse null-model probability is a valid and established technique.\n- **Well-Posedness**: The problem is well-posed. The network structure is explicitly given, the null model is defined, and the quantity to be calculated ($S$) is specified by a clear mathematical procedure. All necessary information is present to compute a unique solution.\n- **Objectivity**: The problem statement is objective, using precise, formal definitions and avoiding any ambiguity or subjective language.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically sound, well-posed, and objective. A complete solution will be provided.\n\n### Solution Derivation\n\nThe solution proceeds in three stages: first, a principled justification for the inflation of motif counts; second, a detailed analysis of the given network to determine its properties and identify all FFLs; and third, the computation of the normalized score $S$.\n\n**Part 1: Justification of Raw Count Inflation**\n\nThe feed-forward loop (FFL) on distinct nodes $(i,j,k)$ consists of the edges $i \\rightarrow j$, $j \\rightarrow k$, and $i \\rightarrow k$. In the specified Chung-Lu baseline model, the occurrence of each potential edge is an independent probabilistic event. The probability of an edge from a node $u$ to a node $v$ is given by $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$.\n\nThe expected number of FFLs, $N_{\\mathrm{FFL}}^{\\mathrm{exp}}$, in a random network generated by this model is the sum, over all distinct triples of nodes $(i,j,k)$, of the probability that this triple forms an FFL. Due to the independence assumption, this probability is the product of the individual edge probabilities:\n$$P(\\text{FFL on } i,j,k) = p_{ij} p_{jk} p_{ik}$$\nSubstituting the given baseline probability formula:\n$$P(\\text{FFL on } i,j,k) = \\left(\\frac{k_{i}^{\\mathrm{out}} k_{j}^{\\mathrm{in}}}{m}\\right) \\left(\\frac{k_{j}^{\\mathrm{out}} k_{k}^{\\mathrm{in}}}{m}\\right) \\left(\\frac{k_{i}^{\\mathrm{out}} k_{k}^{\\mathrm{in}}}{m}\\right) = \\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}$$\nThe total expected number of FFLs is the sum of these probabilities over all possible triples:\n$$N_{\\mathrm{FFL}}^{\\mathrm{exp}} = \\sum_{i \\neq j \\neq k \\neq i} \\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}$$\nThis expression demonstrates from first principles that the expected number of FFLs is not uniform across all network structures but is highly dependent on the degree sequence. Specifically, the contribution of any potential FFL involving nodes $i, j, k$ to the expected count scales with the square of the out-degree of the source node $i$, the square of the in-degree of the sink node $k$, and the product of the in- and out-degrees of the intermediate node $j$. Consequently, nodes with large degrees (hubs) disproportionately increase the expected number of FFLs. A raw count of FFLs in an observed network is therefore \"inflated\" by the presence of high-degree nodes, as this baseline expectation is high regardless of any higher-order structural organization. Normalization is required to disentangle the contribution of the degree sequence from true structural over-representation.\n\n**Part 2: Network Analysis and FFL Identification**\n\nThe given network has $5$ nodes $\\{a,b,c,d,e\\}$ and $10$ edges. The total number of edges is $m=10$. We first compute the in-degrees ($k^{\\mathrm{in}}$) and out-degrees ($k^{\\mathrm{out}}$) for each node.\n- Node $a$: $k_{a}^{\\mathrm{in}} = 0$, $k_{a}^{\\mathrm{out}} = 4$\n- Node $b$: $k_{b}^{\\mathrm{in}} = 1$, $k_{b}^{\\mathrm{out}} = 3$\n- Node $c$: $k_{c}^{\\mathrm{in}} = 2$, $k_{c}^{\\mathrm{out}} = 2$\n- Node $d$: $k_{d}^{\\mathrm{in}} = 3$, $k_{d}^{\\mathrm{out}} = 1$\n- Node $e$: $k_{e}^{\\mathrm{in}} = 4$, $k_{e}^{\\mathrm{out}} = 0$\nThe sums of degrees are $\\sum k^{\\mathrm{in}} = 10$ and $\\sum k^{\\mathrm{out}} = 10$, consistent with $m=10$.\n\nNext, we systematically identify all FFLs $(i,j,k)$ in the network. An FFL requires a path of length two ($i \\rightarrow j \\rightarrow k$) and a direct \"shortcut\" edge ($i \\rightarrow k$).\n1. FFL $(a,b,c)$: Path $a \\rightarrow b \\rightarrow c$ exists. Shortcut $a \\rightarrow c$ exists.\n2. FFL $(a,b,d)$: Path $a \\rightarrow b \\rightarrow d$ exists. Shortcut $a \\rightarrow d$ exists.\n3. FFL $(a,b,e)$: Path $a \\rightarrow b \\rightarrow e$ exists. Shortcut $a \\rightarrow e$ exists.\n4. FFL $(a,c,d)$: Path $a \\rightarrow c \\rightarrow d$ exists. Shortcut $a \\rightarrow d$ exists.\n5. FFL $(a,c,e)$: Path $a \\rightarrow c \\rightarrow e$ exists. Shortcut $a \\rightarrow e$ exists.\n6. FFL $(a,d,e)$: Path $a \\rightarrow d \\rightarrow e$ exists. Shortcut $a \\rightarrow e$ exists.\n7. FFL $(b,c,d)$: Path $b \\rightarrow c \\rightarrow d$ exists. Shortcut $b \\rightarrow d$ exists.\n8. FFL $(b,c,e)$: Path $b \\rightarrow c \\rightarrow e$ exists. Shortcut $b \\rightarrow e$ exists.\n9. FFL $(b,d,e)$: Path $b \\rightarrow d \\rightarrow e$ exists. Shortcut $b \\rightarrow e$ exists.\n10. FFL $(c,d,e)$: Path $c \\rightarrow d \\rightarrow e$ exists. Shortcut $c \\rightarrow e$ exists.\nThere are a total of $10$ FFLs in the network.\n\n**Part 3: Computation of the Normalized Score S**\n\nThe normalized score $S$ is the sum of weights for all observed FFLs. The weight $w_{ijk}$ for an FFL on nodes $(i,j,k)$ is the inverse of the product of the baseline probabilities of its constituent edges:\n$$w_{ijk} = \\frac{1}{p_{ij} p_{jk} p_{ik}} = \\frac{1}{\\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}} = \\frac{m^{3}}{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}$$\nWe compute this weight for each of the $10$ identified FFLs, using $m=10$ (so $m^3=1000$) and the degree values calculated earlier.\n\n- $w_{abc} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{c}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(2)^{2}} = \\frac{1000}{192}$\n- $w_{abd} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(3)^{2}} = \\frac{1000}{432}$\n- $w_{abe} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(4)^{2}} = \\frac{1000}{768}$\n- $w_{acd} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(2)(2)(3)^{2}} = \\frac{1000}{576}$\n- $w_{ace} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(2)(2)(4)^{2}} = \\frac{1000}{1024}$\n- $w_{ade} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(3)(1)(4)^{2}} = \\frac{1000}{768}$\n- $w_{bcd} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(2)(2)(3)^{2}} = \\frac{1000}{324}$\n- $w_{bce} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(2)(2)(4)^{2}} = \\frac{1000}{576}$\n- $w_{bde} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(3)(1)(4)^{2}} = \\frac{1000}{432}$\n- $w_{cde} = \\frac{1000}{(k_{c}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(2)^{2}(3)(1)(4)^{2}} = \\frac{1000}{192}$\n\nThe total score $S$ is the sum of these $10$ weights:\n$$S = \\frac{1000}{192} + \\frac{1000}{432} + \\frac{1000}{768} + \\frac{1000}{576} + \\frac{1000}{1024} + \\frac{1000}{768} + \\frac{1000}{324} + \\frac{1000}{576} + \\frac{1000}{432} + \\frac{1000}{192}$$\nGrouping terms with identical denominators:\n$$S = 1000 \\left( \\frac{2}{192} + \\frac{2}{432} + \\frac{2}{768} + \\frac{2}{576} + \\frac{1}{1024} + \\frac{1}{324} \\right)$$\n$$S = 1000 \\left( \\frac{1}{96} + \\frac{1}{216} + \\frac{1}{384} + \\frac{1}{288} + \\frac{1}{1024} + \\frac{1}{324} \\right)$$\nTo sum these fractions, we find the least common multiple of the denominators:\n$96 = 2^5 \\times 3^1$, $216 = 2^3 \\times 3^3$, $384 = 2^7 \\times 3^1$, $288 = 2^5 \\times 3^2$, $1024 = 2^{10}$, $324 = 2^2 \\times 3^4$.\nThe LCM is $2^{10} \\times 3^4 = 1024 \\times 81 = 82944$.\nExpressing each fraction with this common denominator:\n$$S = 1000 \\left( \\frac{864}{82944} + \\frac{384}{82944} + \\frac{216}{82944} + \\frac{288}{82944} + \\frac{81}{82944} + \\frac{256}{82944} \\right)$$\n$$S = 1000 \\left( \\frac{864+384+216+288+81+256}{82944} \\right) = 1000 \\left( \\frac{2089}{82944} \\right)$$\n$$S = \\frac{2089000}{82944}$$\nThis fraction can be simplified by canceling common factors. $1000 = 8 \\times 125 = 2^3 \\times 5^3$ and $82944 = 8 \\times 10368$.\n$$S = \\frac{125 \\times 2089}{10368}$$\nThe denominator $10368 = 2^7 \\times 3^4$ has no factors of $5$. The numerator $2089$ is not divisible by $2$ or $3$ (sum of digits is $19$) and is prime. Therefore, the fraction is in its simplest form.\nNumerator: $125 \\times 2089 = 261125$.\nDenominator: $10368$.\n$$S = \\frac{261125}{10368}$$\nThis is the exact value of the normalized motif score.",
            "answer": "$$\\boxed{\\frac{261125}{10368}}$$"
        },
        {
            "introduction": "The ultimate goal of motif analysis is often to understand the functional roles of different components within a system. This practice provides a complete computational workflow to move from raw network data to functional classification based on node-level motif participation profiles . You will implement a pipeline that calculates motif counts, compares them against a degree-preserving null model to generate $z$-scores, and uses these significance profiles to classify nodes based on their structural environment.",
            "id": "4291115",
            "problem": "You are given undirected, simple graphs represented by adjacency matrices. Your task is to compute node-level motif participation profiles for each node and use these profiles to classify nodes into functional roles. The motifs considered are the $3$-node triangle and the $3$-node wedge (open triad centered at a node). The classification must be computed from first principles and be deterministic.\n\nFundamental base definitions and constraints:\n- A graph is represented by a symmetric adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with $A_{ii} = 0$ for all $i$, where $n$ is the number of nodes.\n- For node $i$, let $N(i) = \\{j \\in \\{1,\\dots,n\\} \\mid A_{ij} = 1\\}$ denote its neighbor set, and $d_i = |N(i)|$ its degree.\n- A triangle participated by node $i$ is defined as any unordered pair $\\{j,k\\} \\subset N(i)$ with $A_{jk}=1$. The node-level triangle count is\n$$\nT_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j<k} \\mathbf{1}\\{A_{jk} = 1\\}.\n$$\n- A wedge participated by node $i$ is defined as any unordered pair $\\{j,k\\} \\subset N(i)$ with $A_{jk}=0$. The node-level wedge count is\n$$\nW_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j<k} \\mathbf{1}\\{A_{jk} = 0\\}.\n$$\n- The combination identity $T_i + W_i = \\binom{d_i}{2}$ must hold for all $i$.\n\nNull model and statistical profiling:\n- Use a degree-preserving randomization based on edge swaps (also called the switching model) to generate reference graphs. One swap attempt picks two edges $\\{u,v\\}$ and $\\{x,y\\}$ with $u < v$, $x < y$ and all endpoints distinct, and proposes rewiring to either $\\{u,y\\}, \\{x,v\\}$ or $\\{u,x\\}, \\{v,y\\}$ chosen uniformly, provided the proposed edges do not already exist and do not create self-loops. Accepted swaps preserve degrees and maintain a simple graph.\n- For each test case, generate $R$ randomized graphs and for each randomized graph perform $S$ swap attempts starting from the original $A$ to encourage mixing. For each node $i$ record $T_i^{(r)}$ and $W_i^{(r)}$ across $r \\in \\{1,\\dots,R\\}$.\n- Estimate the node-level expectations and standard deviations under the null as\n$$\n\\mu_{T,i} = \\frac{1}{R} \\sum_{r=1}^{R} T_i^{(r)}, \\quad \\sigma_{T,i} = \\sqrt{\\frac{1}{R-1} \\sum_{r=1}^{R} \\left(T_i^{(r)} - \\mu_{T,i}\\right)^2},\n$$\n$$\n\\mu_{W,i} = \\frac{1}{R} \\sum_{r=1}^{R} W_i^{(r)}, \\quad \\sigma_{W,i} = \\sqrt{\\frac{1}{R-1} \\sum_{r=1}^{R} \\left(W_i^{(r)} - \\mu_{W,i}\\right)^2}.\n$$\n- Define node-level motif $z$-scores\n$$\nz_{T,i} = \\begin{cases}\n\\frac{T_i - \\mu_{T,i}}{\\sigma_{T,i}}, & \\text{if } \\sigma_{T,i} > 0,\\\\\n0, & \\text{otherwise,}\n\\end{cases}\n\\qquad\nz_{W,i} = \\begin{cases}\n\\frac{W_i - \\mu_{W,i}}{\\sigma_{W,i}}, & \\text{if } \\sigma_{W,i} > 0,\\\\\n0, & \\text{otherwise.}\n\\end{cases}\n$$\n\nRole classification:\n- Assign each node a role based on its node-level motif significance profile $(z_{T,i}, z_{W,i})$ and degree $d_i$ using the following deterministic rule:\n    - If $d_i < 2$, assign role $0$ (peripheral).\n    - Else, if $z_{T,i} \\ge z_{W,i}$, assign role $1$ (clique-oriented).\n    - Else, assign role $2$ (broker-oriented).\nThis rule operationalizes the intuition that triangles indicate local clustering (clique-oriented) and wedges indicate bridging potential (broker-oriented).\n\nTest suite:\n- Use the following three test graphs, each specified by its number of nodes and undirected edge list. The values of $R$ (number of randomized graphs), $S$ (swap attempts per randomized graph), and the pseudorandom seed are also specified for reproducibility. All numbers are fixed.\n    1. Graph $G_1$ (a $4$-clique with a dangling bridge):\n        - Nodes: $n = 6$.\n        - Edges: $\\{(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(0,4),(4,5)\\}$.\n        - Randomization parameters: $R = 200$, $S = 400$, seed $= 202311$.\n    2. Graph $G_2$ (a $6$-cycle):\n        - Nodes: $n = 6$.\n        - Edges: $\\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)\\}$.\n        - Randomization parameters: $R = 200$, $S = 400$, seed $= 202312$.\n    3. Graph $G_3$ (a $6$-node star):\n        - Nodes: $n = 6$.\n        - Edges: $\\{(0,1),(0,2),(0,3),(0,4),(0,5)\\}$.\n        - Randomization parameters: $R = 200$, $S = 400$, seed $= 202313$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the classification results for all test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list enclosed in square brackets of the per-node integer roles in node index order. For example, an output of the form $[[r_{1,0},r_{1,1},\\dots],[r_{2,0},\\dots],[r_{3,0},\\dots]]$ must be printed exactly with no spaces: \"[[...],[...],[...]]\".\n- All outputs are integers; there are no physical units involved.\n\nYour implementation must be a complete, runnable program adhering strictly to the specified environment.",
            "solution": "We begin with the fundamental representation of a simple undirected graph by a symmetric adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with zero diagonal. For each node $i$, its neighbor set $N(i)$ and degree $d_i$ are defined by $N(i) = \\{j \\mid A_{ij} = 1\\}$ and $d_i = |N(i)|$.\n\nThe node-level motifs considered are the triangle and the wedge (an open triad centered at the node). The triangle count $T_i$ counts unordered neighbor pairs $\\{j,k\\} \\subset N(i)$ that are mutually connected, while the wedge count $W_i$ counts unordered neighbor pairs that are not connected. Formally,\n$$\nT_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j<k} \\mathbf{1}\\{A_{jk} = 1\\}, \\quad\nW_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j<k} \\mathbf{1}\\{A_{jk} = 0\\}.\n$$\nBecause every unordered pair of neighbors is either connected or not, we have the identity\n$$\nT_i + W_i = \\binom{d_i}{2}.\n$$\n\nTo interpret motif participation in a statistically grounded way, we compare the observed counts $(T_i, W_i)$ to a null model that preserves degrees. The switching model (degree-preserving edge swaps) constructs randomized graphs with the same degree sequence by repeatedly selecting two edges $\\{u,v\\}$ and $\\{x,y\\}$ with all endpoints distinct and proposing a rewiring to either $\\{u,y\\}, \\{x,v\\}$ or $\\{u,x\\}, \\{v,y\\}$ uniformly, provided the rewiring does not create self-loops and does not introduce duplicate edges. Accepting such swaps preserves degrees of all nodes and maintains a simple graph.\n\nFor a fixed graph $A$, we generate $R$ randomized graphs by starting from $A$ and performing $S$ swap attempts per randomized graph. On each randomized graph $r \\in \\{1,\\dots,R\\}$ we compute node-level counts $T_i^{(r)}$ and $W_i^{(r)}$. From these samples we estimate the per-node expectations and standard deviations,\n$$\n\\mu_{T,i} = \\frac{1}{R} \\sum_{r=1}^{R} T_i^{(r)}, \\quad\n\\sigma_{T,i} = \\sqrt{\\frac{1}{R-1} \\sum_{r=1}^{R} \\left(T_i^{(r)} - \\mu_{T,i}\\right)^2},\n$$\n$$\n\\mu_{W,i} = \\frac{1}{R} \\sum_{r=1}^{R} W_i^{(r)}, \\quad\n\\sigma_{W,i} = \\sqrt{\\frac{1}{R-1} \\sum_{r=1}^{R} \\left(W_i^{(r)} - \\mu_{W,i}\\right)^2}.\n$$\nWe then compute node-level $z$-scores,\n$$\nz_{T,i} = \\begin{cases}\n\\frac{T_i - \\mu_{T,i}}{\\sigma_{T,i}}, & \\text{if } \\sigma_{T,i} > 0,\\\\\n0, & \\text{otherwise,}\n\\end{cases}\n\\qquad\nz_{W,i} = \\begin{cases}\n\\frac{W_i - \\mu_{W,i}}{\\sigma_{W,i}}, & \\text{if } \\sigma_{W,i} > 0,\\\\\n0, & \\text{otherwise.}\n\\end{cases}\n$$\nThis normalization ensures that nodes are compared relative to the variability expected under the degree-preserving null model. If the variability is zero (which can occur for certain degree sequences or small graphs), setting the corresponding $z$-score to $0$ avoids undefined behavior.\n\nFinally, we classify nodes into roles:\n- If $d_i < 2$, we assign role $0$ (peripheral). This accounts for nodes that cannot participate in any $3$-node motif by definition, since $\\binom{d_i}{2} = 0$ when $d_i < 2$.\n- Otherwise, we compare $z_{T,i}$ and $z_{W,i}$. If $z_{T,i} \\ge z_{W,i}$, we assign role $1$ (clique-oriented); else role $2$ (broker-oriented). This deterministic rule uses the node-level motif significance profile to favor triangle participation as indicative of local clustering versus wedge participation as indicative of bridging structure.\n\nAlgorithmic steps:\n1. Construct the adjacency matrix $A$ from the given edge list.\n2. Compute $d_i$ for all $i$ and the observed $(T_i, W_i)$ using pairwise checks within $N(i)$.\n3. For the given $R$, $S$, and fixed seed, draw $R$ randomized graphs via degree-preserving edge swaps, each with $S$ swap attempts starting from $A$.\n4. On each randomized graph, compute $(T_i^{(r)}, W_i^{(r)})$ for all nodes; aggregate into $\\mu_{T,i}$, $\\sigma_{T,i}$, $\\mu_{W,i}$, $\\sigma_{W,i}$.\n5. Compute $z_{T,i}$ and $z_{W,i}$ with the fallback to $0$ if the standard deviation is $0$.\n6. Apply the role classification rule to produce an integer role for each node.\n7. Repeat for each test graph and aggregate the per-graph role lists into the required output format without spaces.\n\nDesign considerations ensure scientific realism:\n- The motifs, counts, and null model are standard in network science, preserving the degree sequence which is a fundamental structural property.\n- The classification rule derives from the principle that triangles contribute to local cohesion while wedges contribute to brokerage, anchored by $z$-scores that measure deviation from a well-defined null model.\n- Boundary conditions are explicitly handled via the degree threshold $d_i < 2$.\n\nThe program implements these steps and produces the required single-line output of integer lists for the provided test suite.",
            "answer": "```python\nimport numpy as np\n\ndef build_adjacency(n, edges):\n    \"\"\"Build symmetric adjacency matrix for an undirected simple graph.\"\"\"\n    A = np.zeros((n, n), dtype=int)\n    for u, v in edges:\n        if u == v:\n            continue\n        A[u, v] = 1\n        A[v, u] = 1\n    np.fill_diagonal(A, 0)\n    return A\n\ndef neighbors_of(A, i):\n    \"\"\"Return neighbors of node i.\"\"\"\n    return np.where(A[i] == 1)[0]\n\ndef count_triangles_wedges_per_node(A):\n    \"\"\"Count triangles and wedges per node.\"\"\"\n    n = A.shape[0]\n    triangles = np.zeros(n, dtype=int)\n    wedges = np.zeros(n, dtype=int)\n    for i in range(n):\n        nbrs = neighbors_of(A, i)\n        k = len(nbrs)\n        if k < 2:\n            continue\n        # count unordered pairs among neighbors\n        for a in range(k):\n            for b in range(a + 1, k):\n                u = nbrs[a]\n                v = nbrs[b]\n                if A[u, v] == 1:\n                    triangles[i] += 1\n                else:\n                    wedges[i] += 1\n    return triangles, wedges\n\ndef get_edge_list(A):\n    \"\"\"Return list of undirected edges (u,v) with u < v.\"\"\"\n    n = A.shape[0]\n    edges = []\n    for u in range(n):\n        for v in range(u + 1, n):\n            if A[u, v] == 1:\n                edges.append((u, v))\n    return edges\n\ndef attempt_swap(A, rng):\n    \"\"\"Attempt a single degree-preserving edge swap; return True if performed.\"\"\"\n    edges = get_edge_list(A)\n    m = len(edges)\n    if m < 2:\n        return False\n    # choose two distinct edges uniformly at random\n    idx = rng.integers(0, m, size=2)\n    if idx[0] == idx[1]:\n        return False\n    (u, v) = edges[idx[0]]\n    (x, y) = edges[idx[1]]\n    # ensure all endpoints distinct\n    endpoints = {u, v, x, y}\n    if len(endpoints) < 4:\n        return False\n    # choose one of two rewiring options at random\n    if rng.integers(0, 2) == 0:\n        a, b = u, y\n        c, d = x, v\n    else:\n        a, b = u, x\n        c, d = v, y\n    # avoid self-loops\n    if a == b or c == d:\n        return False\n    # avoid existing edges and parallel edges\n    if A[a, b] == 1 or A[c, d] == 1:\n        return False\n    # perform swap: remove original edges, add new edges\n    A[u, v] = 0\n    A[v, u] = 0\n    A[x, y] = 0\n    A[y, x] = 0\n    A[a, b] = 1\n    A[b, a] = 1\n    A[c, d] = 1\n    A[d, c] = 1\n    return True\n\ndef randomize_graph(A, swaps, rng):\n    \"\"\"Return a randomized graph via degree-preserving swaps starting from A.\"\"\"\n    Ar = A.copy()\n    attempts = 0\n    successes = 0\n    # perform up to 'swaps' attempts; successful swaps will be <= swaps\n    while attempts < swaps:\n        attempts += 1\n        if attempt_swap(Ar, rng):\n            successes += 1\n    return Ar\n\ndef null_stats(A, R, S, rng):\n    \"\"\"Compute null model mean and std for triangles and wedges per node.\"\"\"\n    n = A.shape[0]\n    tri_samples = np.zeros((R, n), dtype=float)\n    wed_samples = np.zeros((R, n), dtype=float)\n    for r in range(R):\n        Ar = randomize_graph(A, S, rng)\n        T, W = count_triangles_wedges_per_node(Ar)\n        tri_samples[r] = T\n        wed_samples[r] = W\n    mu_T = tri_samples.mean(axis=0)\n    mu_W = wed_samples.mean(axis=0)\n    # sample standard deviation (ddof=1); handle R==1 separately if needed\n    if R > 1:\n        sigma_T = tri_samples.std(axis=0, ddof=1)\n        sigma_W = wed_samples.std(axis=0, ddof=1)\n    else:\n        sigma_T = np.zeros(n, dtype=float)\n        sigma_W = np.zeros(n, dtype=float)\n    return mu_T, sigma_T, mu_W, sigma_W\n\ndef classify_roles(A, R, S, seed):\n    \"\"\"Classify nodes into roles 0,1,2 based on node-level motif z-scores.\"\"\"\n    rng = np.random.default_rng(seed)\n    degrees = A.sum(axis=1)\n    T_obs, W_obs = count_triangles_wedges_per_node(A)\n    mu_T, sigma_T, mu_W, sigma_W = null_stats(A, R, S, rng)\n    # compute z-scores with zero fallback\n    z_T = np.zeros_like(mu_T)\n    z_W = np.zeros_like(mu_W)\n    for i in range(A.shape[0]):\n        if sigma_T[i] > 0:\n            z_T[i] = (T_obs[i] - mu_T[i]) / sigma_T[i]\n        else:\n            z_T[i] = 0.0\n        if sigma_W[i] > 0:\n            z_W[i] = (W_obs[i] - mu_W[i]) / sigma_W[i]\n        else:\n            z_W[i] = 0.0\n    roles = []\n    for i in range(A.shape[0]):\n        if degrees[i] < 2:\n            roles.append(0)  # peripheral\n        else:\n            if z_T[i] >= z_W[i]:\n                roles.append(1)  # clique-oriented\n            else:\n                roles.append(2)  # broker-oriented\n    return roles\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, edges, R, S, seed)\n        (6, [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(0,4),(4,5)], 200, 400, 202311),\n        (6, [(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)], 200, 400, 202312),\n        (6, [(0,1),(0,2),(0,3),(0,4),(0,5)], 200, 400, 202313),\n    ]\n\n    results = []\n    for n, edges, R, S, seed in test_cases:\n        A = build_adjacency(n, edges)\n        roles = classify_roles(A, R, S, seed)\n        results.append(roles)\n\n    # Format the output as a single line with no spaces: [[...],[...],[...]]\n    formatted = \"[\" + \",\".join(\"[\" + \",\".join(map(str, r)) + \"]\" for r in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}