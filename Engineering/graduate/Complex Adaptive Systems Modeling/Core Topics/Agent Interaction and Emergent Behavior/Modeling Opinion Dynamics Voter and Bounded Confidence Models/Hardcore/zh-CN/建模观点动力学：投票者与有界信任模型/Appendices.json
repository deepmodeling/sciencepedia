{
    "hands_on_practices": [
        {
            "introduction": "这项练习将引导您完成投票者模型的一个基本证明。通过运用鞅 ($martingale$) 的概念，您将证明系统最终达成全体为“1”的共识的概率，恰好等于持有该意见的个体在初始时刻的比例 。这个优美的结果揭示了模型动态核心的深层守恒定律，并为分析此类模型提供了强有力的工具。",
            "id": "4129388",
            "problem": "考虑一个包含 $N$ 个顶点的有限、连通、无向、简单图 $G$，该图是 $k$-正则的，其中 $k \\geq 1$ 是某个整数。在离散时间 $t \\in \\mathbb{N}$，每个顶点 $i \\in \\{1,\\dots,N\\}$ 持有一个观点 $X_i(t) \\in \\{0,1\\}$。系统根据标准的投票者模型进行演化：在每个时间步 $t \\mapsto t+1$，从 $\\{1,\\dots,N\\}$ 中均匀随机地选择一个顶点 $I_t$，然后从 $I_t$ 的 $k$ 个邻居中均匀随机地选择一个邻居 $J_t \\in \\mathcal{N}(I_t)$。顶点 $I_t$ 更新其观点以匹配其所选邻居的观点，即 $X_{I_t}(t+1) = X_{J_t}(t)$，而所有其他顶点保持其观点不变，即对所有 $i \\neq I_t$ 都有 $X_i(t+1) = X_i(t)$。设初始构型是任意的，并定义观点 $1$ 的初始比例为 $p_0 := \\frac{1}{N}\\sum_{i=1}^{N} X_i(0)$。\n\n定义在时间 $t$ 观点 $1$ 的经验比例为 $M(t) := \\frac{1}{N}\\sum_{i=1}^{N} X_i(t)$，并令 $T$ 为系统首次达到共识的时间，即 $T := \\inf\\{t \\geq 0 : X_i(t) = X_j(t) \\text{ for all } i,j\\}$。吸收态是全-$0$ 构型和全-$1$ 构型。\n\n从投票者模型动力学的基本定义出发，并仅使用关于条件期望和鞅的第一性原理，推导系统最终达到全-$1$ 共识的概率表达式，用 $p_0$ 表示。你的推导必须基于证明 $M(t)$ 是关于自然滤的鞅，并应用鞅的可选停止定理 (OST)。将你的最终答案表示为单个闭式解析表达式。不需要数值近似或四舍五入，也不适用任何物理单位。",
            "solution": "我们首先将动力学过程和我们感兴趣的量进行形式化。所指定的投票者模型是一个在有限状态空间 $\\{0,1\\}^{N}$ 上的时齐马尔可夫链。令 $\\mathcal{F}_t$ 表示由该过程直到时间 $t$ 生成的自然滤，即 $\\mathcal{F}_t = \\sigma\\big((X_i(s))_{i=1}^{N}, 0 \\leq s \\leq t\\big)$。我们感兴趣的量是系统达到全-$1$ 吸收态的概率。令 $A$ 表示在时间 $T$ 达到的共识是全-$1$ 的事件，即 $A := \\{X_i(T) = 1 \\text{ for all } i\\}$。\n\n我们将时间 $t$ 观点 $1$ 的经验比例定义为\n$$\nM(t) := \\frac{1}{N}\\sum_{i=1}^{N} X_i(t).\n$$\n我们将证明 $\\{M(t)\\}_{t \\geq 0}$ 是关于 $\\{\\mathcal{F}_t\\}_{t \\geq 0}$ 的鞅，然后对停时 $T$ 应用鞅的可选停止定理 (OST)。\n\n步骤 $1$：计算 $M(t)$ 的单步条件期望。\n\n根据构造，在时间 $t$ 和 $t+1$ 之间，只有一个坐标可能改变，即 $X_{I_t}$。更新规则是 $X_{I_t}(t+1) = X_{J_t}(t)$，其中 $I_t$ 在 $\\{1,\\dots,N\\}$ 上均匀分布，$J_t$ 在 $\\mathcal{N}(I_t)$ 上均匀分布，并且在给定 $\\mathcal{F}_t$ 的条件下与过去独立。因此，\n$$\nM(t+1) - M(t) = \\frac{1}{N}\\big(X_{I_t}(t+1) - X_{I_t}(t)\\big) = \\frac{1}{N}\\big(X_{J_t}(t) - X_{I_t}(t)\\big).\n$$\n在给定 $\\mathcal{F}_t$ 的条件下取条件期望，并利用独立性和均匀选择，\n$$\n\\mathbb{E}\\big[M(t+1) - M(t) \\mid \\mathcal{F}_t\\big] = \\frac{1}{N}\\left(\\mathbb{E}\\big[X_{J_t}(t) \\mid \\mathcal{F}_t\\big] - \\mathbb{E}\\big[X_{I_t}(t) \\mid \\mathcal{F}_t\\big]\\right).\n$$\n我们分别计算这两个期望。由于 $I_t$ 在 $\\{1,\\dots,N\\}$ 上是均匀的，\n$$\n\\mathbb{E}\\big[X_{I_t}(t) \\mid \\mathcal{F}_t\\big] = \\frac{1}{N}\\sum_{i=1}^{N} X_i(t) = M(t).\n$$\n对于 $\\mathbb{E}\\big[X_{J_t}(t) \\mid \\mathcal{F}_t\\big]$，注意到在条件 $I_t=i$ 下，$J_t$ 在 $\\mathcal{N}(i)$ 上是均匀的，所以\n$$\n\\mathbb{E}\\big[X_{J_t}(t) \\mid I_t=i, \\mathcal{F}_t\\big] = \\frac{1}{k}\\sum_{j \\in \\mathcal{N}(i)} X_j(t).\n$$\n对 $I_t$ 进行平均，\n$$\n\\mathbb{E}\\big[X_{J_t}(t) \\mid \\mathcal{F}_t\\big] = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{1}{k}\\sum_{j \\in \\mathcal{N}(i)} X_j(t).\n$$\n因为图是 $k$-正则且无向的，和 $\\sum_{i=1}^{N}\\sum_{j \\in \\mathcal{N}(i)} X_j(t)$ 在所有有向关联 $(i,j)$ 中对每个顶点 $j$ 恰好计数 $\\deg(j)=k$ 次，因此\n$$\n\\sum_{i=1}^{N} \\sum_{j \\in \\mathcal{N}(i)} X_j(t) = \\sum_{j=1}^{N} X_j(t)\\deg(j) = k \\sum_{j=1}^{N} X_j(t).\n$$\n所以，\n$$\n\\mathbb{E}\\big[X_{J_t}(t) \\mid \\mathcal{F}_t\\big] = \\frac{1}{N}\\cdot \\frac{1}{k}\\cdot k \\sum_{j=1}^{N} X_j(t) = \\frac{1}{N}\\sum_{j=1}^{N} X_j(t) = M(t).\n$$\n结合两者，\n$$\n\\mathbb{E}\\big[M(t+1) - M(t) \\mid \\mathcal{F}_t\\big] = \\frac{1}{N}\\big(M(t) - M(t)\\big) = 0,\n$$\n这意味着\n$$\n\\mathbb{E}\\big[M(t+1) \\mid \\mathcal{F}_t\\big] = M(t).\n$$\n因此 $\\{M(t)\\}_{t \\geq 0}$ 是关于 $\\{\\mathcal{F}_t\\}_{t \\geq 0}$ 的一个鞅。\n\n步骤 $2$：有界性与可选停止定理 (OST) 的适用性。\n\n根据定义，对所有 $t$ 都有 $M(t) \\in [0,1]$，所以该鞅是有界的。在一个有限、连通的图上，由于投票者模型与汇合随机游走的对偶性（汇合随机游走几乎必然地汇合成单个粒子），该模型几乎必然在有限时间内达到共识；因此 $T  \\infty$ 几乎必然成立。有界鞅是一致可积的，因此可选停止定理 (OST) 适用于停时 $T$ 并得出\n$$\n\\mathbb{E}\\big[M(T)\\big] = \\mathbb{E}\\big[M(0)\\big] = M(0) = p_0.\n$$\n\n步骤 $3$：将 $\\mathbb{E}\\big[M(T)\\big]$ 与全-$1$ 共识的概率等同起来。\n\n在停时 $T$，构型要么是全-$0$，要么是全-$1$。因此，\n$$\nM(T) = \\begin{cases}\n0  \\text{若共识是全-$0$},\\\\\n1  \\text{若共识是全-$1$}.\n\\end{cases}\n$$\n因此，$M(T)$ 正是事件 $A$ 的指示函数，即 $M(T) = \\mathbf{1}_{A}$。由此可得\n$$\n\\mathbb{E}\\big[M(T)\\big] = \\mathbb{E}\\big[\\mathbf{1}_{A}\\big] = \\mathbb{P}(A).\n$$\n与可选停止定理的结果相结合，\n$$\n\\mathbb{P}(\\text{共识是全-$1$}) = \\mathbb{P}(A) = p_0.\n$$\n\n因此，在一个有限、连通、无向、$k$-正则图上，投票者模型达到所有观点均为 $1$ 的吸收态的概率等于观点 $1$ 的初始比例 $p_0$。",
            "answer": "$$\\boxed{p_0}$$"
        },
        {
            "introduction": "现实世界中的观点会受到外部影响和随机变化的干扰，我们将其建模为“噪声”。本练习挑战您分析带噪声的选民模型，并揭示其从单峰（共识）状态到双峰（极化）状态的奇妙相变 。您将使用 Fokker-Planck 方程来推导临界噪声阈值，然后编写程序对系统行为进行分类，从而搭建起从微观规则到宏观模式的桥梁。",
            "id": "4129384",
            "problem": "考虑一个完全图上的对称噪声投票者模型，该模型包含 $N$ 个智能体，每个智能体持有 $\\{0,1\\}$ 中的一个二元观点。在连续时间内，每个智能体按如下方式更新：以速率 $c$，智能体复制一个随机选择的邻居的观点；以速率 $a$，智能体因外源噪声而自发地翻转其观点。定义无量纲噪声参数 $\\eta = a/c$。令 $n$ 表示持有观点 $1$ 的智能体数量，$x = n/N$ 表示持有观点 $1$ 的智能体比例。\n\n从完全图上关于 $n$ 的生灭过程出发，利用以下原理：对于一维生灭链，当 $N$ 很大时，其宏观演化可以用一个关于 $x$ 的扩散过程来近似，该过程的漂移 $f(x)$ 和扩散系数 $g(x)$ 可以从微观转移速率推导得出。根据此扩散近似以及相应的福克-普朗克方程（在 $x=0$ 和 $x=1$ 处具有零概率流和反射边界）的稳态解，推导出一个判据，用以判断当参数 $\\eta$ 变化时，$x$ 的稳态分布是单峰的（在 $x=1/2$ 处有峰值）还是双峰的（在边界 $x=0$ 和 $x=1$ 附近有峰值）。对于固定的 $c$，将分岔条件完全用 $N$ 和 $\\eta$ 来表示。\n\n你的程序必须实现这个判据，对给定 $(N,\\eta)$ 对的稳态分布形状进行分类。将分类映射到一个整数，具体如下：如果为单峰，返回 $1$；如果为双峰，返回 $-1$；如果恰好处于分岔点（临界情况），返回 $0$。分类必须由一个根据 $N$ 和 $\\eta$ 在数学上推导出的条件确定。\n\n使用以下参数值测试套件，以覆盖正常行为、阈下、阈上和边界情况：\n- $N=100$, $\\eta=0.020$\n- $N=100$, $\\eta=0.005$\n- $N=100$, $\\eta=0.010$\n- $N=2$, $\\eta=0.500$\n- $N=50$, $\\eta=0.000$\n- $N=50$, $\\eta=1.000$\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，例如 $[r_1,r_2,r_3,r_4,r_5,r_6]$，其中每个 $r_i$ 是对应测试用例按所列顺序的整数分类。不涉及物理单位。不出现角度。不出现百分比。所有数值输出均为整数。",
            "solution": "问题陈述是一个有效的、适定的科学问题，它基于随机过程理论及其在观点动力学建模中的应用。所有必要的参数和定义都已提供，不存在矛盾或歧义。我们将进行推导和求解。\n\n该系统由完全图上的 $N$ 个智能体组成，每个智能体持有 $\\{0,1\\}$ 中的一个二元观点。系统状态可以用持有观点 $1$ 的智能体数量 $n$ 来描述，其中 $n \\in \\{0, 1, \\dots, N\\}$。持有观点 $1$ 的智能体比例为 $x=n/N$。\n\n我们将系统演化建模为变量 $n$ 的一维生灭过程。“出生”对应于从 $n$ 到 $n+1$ 的转移，“死亡”对应于从 $n$ 到 $n-1$ 的转移。我们首先确定转移速率，$T^+(n)$ 表示 $n \\to n+1$ 的速率，$T^-(n)$ 表示 $n \\to n-1$ 的速率。\n\n当一个持有观点 $0$ 的智能体将其观点变为 $1$ 时，发生 $n \\to n+1$ 的转移。有 $N-n$ 个这样的智能体。这种变化可以通过两种方式发生：\n1. 自发翻转：一个持有观点 $0$ 的智能体由于外源噪声而翻转为 $1$。$N-n$ 个智能体中的每一个都以速率 $a$ 发生此过程。此过程的总速率为 $a(N-n)$。\n2. 复制：一个持有观点 $0$ 的智能体复制一个随机选择的邻居的观点。由于图是完全图，任何其他智能体都是邻居。持有观点 $1$ 的智能体比例为 $n/N$。智能体以速率 $c$ 复制邻居的观点。因此，$N-n$ 个持有观点 $0$ 的智能体通过复制方式翻转为 $1$ 的总速率为 $c (N-n) \\frac{n}{N}$。\n\n总出生速率是这两个速率之和：\n$$T^+(n) = c(N-n)\\frac{n}{N} + a(N-n) = (N-n)\\left(c\\frac{n}{N} + a\\right)$$\n\n类似地，当一个持有观点 $1$ 的智能体（共有 $n$ 个）将其观点变为 $0$ 时，发生 $n \\to n-1$ 的转移。\n1. 自发翻转：一个持有观点 $1$ 的智能体以速率 $a$ 翻转为 $0$。总速率为 $an$。\n2. 复制：一个持有观点 $1$ 的智能体复制一个持有观点 $0$ 的智能体。持有观点 $0$ 的智能体比例为 $(N-n)/N$。总速率为 $c n \\frac{N-n}{N}$。\n\n总死亡速率为：\n$$T^-(n) = cn\\frac{N-n}{N} + an = n\\left(c\\frac{N-n}{N} + a\\right)$$\n\n对于大的 $N$，这个生灭过程可以用一个关于比例 $x=n/N$ 的连续扩散过程来近似。概率密度 $\\mathcal{P}(x,t)$ 的演化由福克-普朗克方程描述：\n$$\\frac{\\partial \\mathcal{P}(x, t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [f(x) \\mathcal{P}(x,t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [g(x) \\mathcal{P}(x,t)]$$\n漂移系数 $f(x)$ 和扩散系数 $g(x)$ 从变化量 $\\Delta x = \\pm 1/N$ 的矩推导得出：\n$$f(x) = \\lim_{\\Delta t \\to 0} \\frac{\\langle \\Delta x \\rangle}{\\Delta t} = \\frac{1}{N} [T^+(Nx) - T^-(Nx)]$$\n$$g(x) = \\lim_{\\Delta t \\to 0} \\frac{\\langle (\\Delta x)^2 \\rangle}{\\Delta t} = \\frac{1}{N^2} [T^+(Nx) + T^-(Nx)]$$\n\n代入速率表达式，其中 $n=Nx$：\n$$f(x) = \\frac{1}{N} \\left[ (N-Nx)\\left(cx+a\\right) - Nx\\left(c(1-x)+a\\right) \\right]$$\n$$f(x) = (1-x)(cx+a) - x(c(1-x)+a) = cx(1-x)+a(1-x) - cx(1-x)-ax = a(1-2x)$$\n\n$$g(x) = \\frac{1}{N^2} \\left[ (N-Nx)\\left(cx+a\\right) + Nx\\left(c(1-x)+a\\right) \\right]$$\n$$g(x) = \\frac{1}{N} \\left[ (1-x)(cx+a) + x(c(1-x)+a) \\right] = \\frac{1}{N} [2cx(1-x) + a(1-x+x)] = \\frac{1}{N} [2cx(1-x)+a]$$\n\n稳态分布 $\\mathcal{P}_{st}(x)$ 可通过将时间导数设为零来求得，这意味着概率流为常数。在 $x=0$ 和 $x=1$ 处有反射边界，该概率流为零。稳态解满足：\n$$f(x) \\mathcal{P}_{st}(x) - \\frac{1}{2} \\frac{d}{dx} [g(x) \\mathcal{P}_{st}(x)] = 0$$\n解此方程可得 $\\mathcal{P}_{st}(x)$ 正比于 $\\frac{1}{g(x)} \\exp\\left(\\int \\frac{2f(x)}{g(x)} dx\\right)$。\n\n稳态分布的形状（单峰或双峰）由其极值决定，极值出现在 $\\frac{d\\mathcal{P}_{st}(x)}{dx} = 0$ 的地方。分析势 $V(x) = -\\ln \\mathcal{P}_{st}(x)$ 的极值更为方便。$\\mathcal{P}_{st}(x)$ 的极大值对应于 $V(x)$ 的极小值。\n极值的条件是 $V'(x)=0$。从零流方程，我们有 $2f(x)/g(x) = (d/dx)\\ln(g(x)\\mathcal{P}_{st}(x))$。同时，$V'(x) = -\\frac{\\mathcal{P}_{st}'(x)}{\\mathcal{P}_{st}(x)}$。零流方程可写作 $f(x) = \\frac{1}{2}g'(x) + \\frac{1}{2}g(x)\\frac{\\mathcal{P}_{st}'(x)}{\\mathcal{P}_{st}(x)}$。整理得到 $-\\frac{\\mathcal{P}_{st}'(x)}{\\mathcal{P}_{st}(x)} = \\frac{g'(x)-2f(x)}{g(x)}$。因此，极值位于 $V'(x)=0$ 的根处，这意味着 $g'(x) - 2f(x) = 0$。\n\n让我们计算各项：\n$f(x) = a(1-2x)$\n$g'(x) = \\frac{d}{dx}\\left[\\frac{1}{N}(2cx-2cx^2+a)\\right] = \\frac{1}{N}(2c-4cx) = \\frac{2c}{N}(1-2x)$\n\n极值条件变为：\n$$\\frac{2c}{N}(1-2x) - 2a(1-2x) = 0$$\n$$2\\left(\\frac{c}{N} - a\\right)(1-2x) = 0$$\n该方程总是在 $x=1/2$ 处有解，这里是观点空间的中心。分布是对称的，这是它的中心极值点。它是极大值（单峰分布）还是极小值（双峰分布）取决于二阶导数 $V''(1/2)$ 的符号。\n\n我们计算 $V''(x) = \\frac{d}{dx}\\left(\\frac{g'(x)-2f(x)}{g(x)}\\right)$。在 $x=1/2$ 处，我们有 $f(1/2)=0$ 和 $g'(1/2)=0$。\n使用商法则，$V''(1/2)$ 的分子是 $(g''(1/2)-2f'(1/2))g(1/2) - (g'(1/2)-2f(1/2))g'(1/2)$。第二项为零。\n$f'(x) = -2a$\n$g''(x) = -\\frac{4c}{N}$\n$g(1/2) = \\frac{1}{N}(2c(\\frac{1}{2})(1-\\frac{1}{2})+a) = \\frac{1}{N}(\\frac{c}{2}+a)$。由于 $c0, a\\ge0, N0$，我们有 $g(1/2)  0$。\n所以，$V''(1/2) = \\frac{g''(1/2)-2f'(1/2)}{g(1/2)} = \\frac{-4c/N - 2(-2a)}{g(1/2)} = \\frac{4(a-c/N)}{g(1/2)}$。\n\n$V''(1/2)$ 的符号由 $a-c/N$ 的符号决定。\n1. 单峰分布：分布在 $x=1/2$ 处有单个峰值。这对应于势 $V(x)$ 在 $x=1/2$ 处的极小值，因此 $V''(1/2)  0$。这要求 $a-c/N  0$，即 $a  c/N$。\n2. 双峰分布：分布在边界附近有两个峰值，在 $x=1/2$ 处有一个极小值。这对应于 $V(x)$ 在 $x=1/2$ 处的极大值，因此 $V''(1/2)  0$。这要求 $a-c/N  0$，即 $a  c/N$。\n3. 临界情况（分岔）：当 $x=1/2$ 处的曲率为零时发生，即 $V''(1/2) = 0$。这要求 $a-c/N = 0$，即 $a = c/N$。\n\n我们将此判据用无量纲噪声参数 $\\eta = a/c$ 表示。由于 $c$ 是速率，所以 $c0$。\n- 单峰：$a/c  1/N \\implies \\eta  1/N$。映射到整数 $1$。\n- 双峰：$a/c  1/N \\implies \\eta  1/N$。映射到整数 $-1$。\n- 临界：$a/c = 1/N \\implies \\eta = 1/N$。映射到整数 $0$。\n\n这为任意给定的数对 $(N, \\eta)$ 提供了对稳态分布进行分类所需的数学判据。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Applies the derived criterion to classify the stationary distribution shape\n    for the noisy voter model based on N and eta.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, eta)\n        (100, 0.020),\n        (100, 0.005),\n        (100, 0.010),\n        (2, 0.500),\n        (50, 0.000),\n        (50, 1.000),\n    ]\n\n    results = []\n    for N, eta in test_cases:\n        # The bifurcation condition separating unimodal from bimodal\n        # stationary distributions for the symmetric noisy voter model\n        # on a complete graph is derived from a Fokker-Planck approximation.\n        # The criterion compares the dimensionless noise parameter eta = a/c\n        # with the inverse of the system size N.\n        #\n        # - Unimodal (peaked at x=1/2): eta > 1/N\n        # - Bimodal (peaked near x=0 and x=1): eta  1/N\n        # - Critical (at the bifurcation): eta = 1/N\n\n        critical_eta = 1.0 / N\n\n        # Use np.isclose for robust floating-point comparison.\n        if np.isclose(eta, critical_eta):\n            # Critical case\n            classification = 0\n        elif eta > critical_eta:\n            # Unimodal case\n            classification = 1\n        else: # eta  critical_eta\n            # Bimodal case\n            classification = -1\n        \n        results.append(classification)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当我们面对真实数据时，如何在诸如选民模型和有界信任模型等竞争模型之间做出选择？这个综合性练习让您扮演计算社会科学家的角色，构建一个模型验证框架 。您将实现这两种模型，对合成数据进行参数拟合，并利用样本外预测来判断哪种模型能更好地解释观察到的动态，这是任何应用建模工作中都至关重要的一项技能。",
            "id": "4129409",
            "problem": "给定两个观点动力学模型在一张固定无向网络上的规范定义，以及一种生成合成观测数据的方法。你的任务是实现一个验证框架，该框架整合了结构化网络数据和观测到的观点时间序列，通过比较它们的样本外预测性能来区分投票者模型和有界信任模型。输出必须是为提供的测试套件预测的模型索引，占一行。\n\n基本基础。考虑一个静态、简单、无向图 $G = (V, E)$，其中有 $|V| = N$ 个节点，邻接矩阵为 $A \\in \\{0,1\\}^{N \\times N}$，如果 $(i,j) \\in E$，则 $A_{ij} = 1$，否则 $A_{ij} = 0$。令 $x(t) = (x_1(t), \\dots, x_N(t))$ 表示离散时间 $t$ 时的观点向量，其中 $t \\in \\{0, 1, 2, \\dots\\}$。一个时间步定义为一轮 $N$ 次异步成对更新，在每次更新中，从 $E$ 中均匀随机地抽样一条边 $(i,j)$。观点根据以下模型之一演化：\n\n- 投票者模型。观点是二元的，即 $x_i(t) \\in \\{0,1\\}$。在每次异步更新中，均匀随机选择一条边 $(i,j)$ 和一个随机方向；然后，被选中的节点复制其邻居的观点：\n$$\nx_i(t+1) \\leftarrow x_j(t) \\quad \\text{或} \\quad x_j(t+1) \\leftarrow x_i(t).\n$$\n一轮应用 $N$ 次此类更新。\n\n- 有界信任模型 (Deffuant-Weisbuch)。观点是连续的，即 $x_i(t) \\in [0,1]$。在每次异步更新中，均匀随机选择一条边 $(i,j)$。如果观点差异在信任边界 $\\epsilon  0$ 之内，两个端点都通过一个收敛参数 $\\mu \\in (0, \\tfrac{1}{2}]$ 向彼此移动，使用对称更新：\n$$\n\\text{如果 } |x_i - x_j| \\le \\epsilon: \\quad \\begin{cases}\nx_i \\leftarrow x_i + \\mu (x_j - x_i), \\\\\nx_j \\leftarrow x_j + \\mu (x_i - x_j),\n\\end{cases}\n\\quad \\text{否则: 无变化。}\n$$\n一轮应用 $N$ 次此类更新。\n\n观测与预测协议。令 $T_{\\mathrm{obs}} \\in \\mathbb{N}$ 表示观测到的时间步数，$T_{\\mathrm{pred}} \\in \\mathbb{N}$ 表示预留区间的长度。你将获得网络 $A$ 和完整的时间序列 $x(0), x(1), \\dots, x(T_{\\mathrm{obs}} + T_{\\mathrm{pred}})$，但你必须仅使用前 $T_{\\mathrm{obs}}$ 步来拟合模型，并在长度为 $T_{\\mathrm{pred}}$ 的预留区间上评估预测性能。使用蒙特卡洛集成预报，每个预测有 $K \\in \\mathbb{N}$ 次独立运行，从最后一个观测状态 $x(T_{\\mathrm{obs}})$ 开始并向前模拟。对于一个预测区间 $h \\in \\{1,\\dots,T_{\\mathrm{pred}}\\}$，集成均值预测 $\\hat{x}(T_{\\mathrm{obs}}+h)$ 是在步骤 $h$ 时 $K$ 条模拟轨迹上的平均状态。\n\n模型选择规则。通过对所有节点和预测步骤的集成均值预测与预留状态之间的平方偏差求平均，计算每个候选模型的样本外均方误差 (Mean Squared Error (MSE))：\n$$\n\\mathrm{MSE}(M) = \\frac{1}{N \\, T_{\\mathrm{pred}}} \\sum_{h=1}^{T_{\\mathrm{pred}}} \\sum_{i=1}^{N} \\left( \\hat{x}_i(T_{\\mathrm{obs}}+h; M) - x_i(T_{\\mathrm{obs}}+h) \\right)^2.\n$$\n对于有界信任模型，通过网格搜索选择 $(\\epsilon, \\mu)$，以最小化一个仅在观测片段上计算的训练标准，具体来说是 $t \\in \\{0,\\dots,T_{\\mathrm{obs}}-1\\}$ 上的平均单步向前 MSE，使用从 $x(t)$ 到 $x(t+1)$ 的集成均值预测。对于投票者模型，在所述假设下没有可调参数。拟合后，选择具有较小样本外 $\\mathrm{MSE}$ 的模型。如果在数值容差范围内完全相等（取容差 $\\tau = 10^{-9}$），则选择投票者模型。\n\n测试套件与要求输出。实现上述框架，并将其应用于以下四个合成测试用例。为保证可复现性，请按规定固定所有随机种子。对于每个用例，在规定的真实模型和参数下，生成网络 $A$、初始观点 $x(0)$ 和完整的时间序列 $x(t)$（其中 $t=1,\\dots,T_{\\mathrm{obs}}+T_{\\mathrm{pred}}$）。使用一个时间步定义为一轮 $N$ 次异步成对更新。\n\n所有用例的通用设置：\n- 节点数：$N = 30$。\n- 观测步数：$T_{\\mathrm{obs}} = 20$。\n- 预留步数：$T_{\\mathrm{pred}} = 5$。\n- 蒙特卡洛集成大小：$K = 50$。\n- 用于拟合的有界信任参数网格：$\\epsilon \\in \\{0.15, 0.25, 0.35\\}$, $\\mu \\in \\{0.3, 0.5\\}$。\n- 样本外 $\\mathrm{MSE}$ 相等时的决胜容差：$\\tau = 10^{-9}$。\n\n用例定义：\n1. 用例 1（有界信任，环形图）：\n   - 网络：一个包含 $N$ 个节点的环形（循环）图，边为 $(i,(i+1) \\bmod N)$。\n   - 真实模型：有界信任模型，参数为 $\\epsilon_{\\mathrm{true}} = 0.25$, $\\mu_{\\mathrm{true}} = 0.5$。\n   - 初始观点：$x_i(0) \\sim \\mathrm{Uniform}(0,1)$，使用随机种子 $\\mathrm{seed} = 7$。\n\n2. 用例 2（投票者，Erdős–Rényi 图）：\n   - 网络：Erdős–Rényi 图 $G(N,p)$，其中 $p = 0.2$，使用图种子 $\\mathrm{seed} = 123$。\n   - 真实模型：投票者模型。\n   - 初始观点：$x_i(0) \\sim \\mathrm{Bernoulli}(0.5)$，使用随机种子 $\\mathrm{seed} = 5$。\n\n3. 用例 3（有界信任，具有两个社群的非连通图）：\n   - 网络：两个大小分别为 $15$ 和 $15$ 的不相交环（每个块中都有环形边的块对角邻接矩阵）。\n   - 真实模型：有界信任模型，参数为 $\\epsilon_{\\mathrm{true}} = 0.20$, $\\mu_{\\mathrm{true}} = 0.5$。\n   - 初始观点：$x_i(0) \\sim \\mathrm{Uniform}(0,1)$，使用随机种子 $\\mathrm{seed} = 33$。\n\n4. 用例 4（投票者，星形图）：\n   - 网络：$N$ 个节点上的星形图，中心节点 $0$ 连接到所有其他节点。\n   - 真实模型：投票者模型。\n   - 初始观点：$x_i(0) \\sim \\mathrm{Bernoulli}(0.5)$，使用随机种子 $\\mathrm{seed} = 21$。\n\n程序要求：\n- 实现模拟每个模型一个时间步（一轮）的函数，如上定义。\n- 仅使用 $x(0),\\dots,x(T_{\\mathrm{obs}})$ 实现有界信任参数 $(\\epsilon,\\mu)$ 的集成预报和训练网格搜索。\n- 对两个模型计算在 $x(T_{\\mathrm{obs}}+1),\\dots,x(T_{\\mathrm{obs}}+T_{\\mathrm{pred}})$ 上的样本外 $\\mathrm{MSE}$（对于有界信任模型使用拟合的 $(\\epsilon,\\mu)$），并选择 $\\mathrm{MSE}$ 较低的模型，如果差值在容差 $\\tau$ 以内则选择投票者模型。\n- 对于每个测试用例，输出预测的模型索引作为整数：投票者模型输出 $0$，有界信任模型输出 $1$。\n\n最终输出格式：\n你的程序应生成一行输出，其中包含一个逗号分隔的列表，并用方括号括起（例如，$[0,1,1,0]$）。不应打印其他文本。\n\n此问题不涉及物理单位、角度单位或百分比。所有量均为无量纲实数或整数。",
            "solution": "用户提供的问题是一个在复杂自适应系统建模领域中明确定义的计算任务，具体涉及网络观点动力学的模型选择。该问题具有科学依据、内部一致，并包含获得唯一、可验证解所需的所有信息。因此，该问题被视为有效，并将在下方提供完整解决方案。\n\n核心任务是在给定网络结构和观点时间序列的情况下，区分投票者模型和有界信任（BC）模型。方法论遵循一个标准的实证验证框架：\n1.  **数据生成**：对于每个测试用例，根据指定的“真实”模型，生成一个包含网络和完整观点时间序列 `x(0), ..., x(T_{obs} + T_{pred})` 的合成数据集。\n2.  **模型拟合**：将可用数据划分为训练集 `x(0), ..., x(T_{obs})` 和测试集 `x(T_{obs}+1), ..., x(T_{obs}+T_{pred})`。投票者模型没有自由参数。BC模型的参数 $(\\epsilon, \\mu)$ 通过网格搜索在训练集上最小化单步向前预测误差来拟合。\n3.  **样本外预测**：使用投票者模型和拟合后的BC模型，为测试集区间 `h = 1, ..., T_{pred}` 生成预测。这些预测从最后一个观测状态 `x(T_{obs})` 开始，并通过对 $K$ 个独立的随机模拟进行平均来产生。\n4.  **模型选择**：每个模型的预测准确性通过在测试集上的均方误差（MSE）来量化。选择具有较低样本外MSE的模型。一个特定的决胜规则偏向于投票者模型。\n\n我们将系统地实现这个框架的每个组成部分。\n\n### 1. 网络和数据生成\n\n对于每个测试用例，我们首先将指定的网络拓扑构建为一个邻接矩阵 $A \\in \\{0,1\\}^{N \\times N}$。从 $A$ 中，我们导出边列表 $E$，这对于需要均匀随机抽样边的模拟步骤来说更高效。\n\n初始观点向量 $x(0)$ 是通过从均匀分布（对于BC模型）或伯努利分布（对于投票者模型）中抽样生成的，使用指定的随机种子以确保可复现性。\n\n然后，通过从 $x(0)$ 开始，迭代应用真实模型的更新规则 $T_{\\mathrm{obs}}+T_{\\mathrm{pred}}$ 个时间步，生成完整的时间序列 $x(1), \\dots, x(T_{\\mathrm{obs}}+T_{\\mathrm{pred}})$。单个时间步包括一轮 $N$ 次异步更新，如问题中所定义。\n\n### 2. 观点动力学模拟\n\n观点的演化由网络上的随机、成对互动控制。两个模型的单个时间步都包含 $N$ 次微更新。在每次微更新中，从所有边的集合 $E$ 中均匀随机选择一条边 $(i,j)$。观点状态向量在这一轮中顺序更新。\n\n**投票者模型模拟步骤**：\n给定状态 $x(t)$，通过在 $x(t)$ 的副本上执行 $N$ 次更新来获得状态 $x(t+1)$。对于每次更新：\n1.  从 $E$ 中均匀随机抽样一条边 $(i,j)$。\n2.  抽样一个方向，即选择一个节点作为复制者，另一个作为源。这等同于选择 $u, v \\in \\{i,j\\}$ 且 $u \\neq v$。\n3.  更新观点：$x_u \\leftarrow x_v$。\n\n**有界信任模型模拟步骤**：\n给定状态 $x(t)$ 和参数 $(\\epsilon, \\mu)$，通过执行 $N$ 次更新来获得状态 $x(t+1)$。对于每次更新：\n1.  从 $E$ 中均匀随机抽样一条边 $(i,j)$。\n2.  检查信任条件：如果 $|x_i - x_j| \\le \\epsilon$。\n3.  如果条件满足，执行对称更新。为避免竞争条件，变化是基于更新前的状态计算的：\n    $$ \\Delta x = \\mu (x_j - x_i) $$\n    然后新的观点是：\n    $$ x_i \\leftarrow x_i + \\Delta x $$\n    $$ x_j \\leftarrow x_j - \\Delta x $$\n    如果条件不满足，则不发生变化。\n\n### 3. 预测和参数拟合\n\n**集成预报**：\n为了预测系统的演化，我们使用蒙特卡洛模拟。从给定的起始状态 $x_{\\mathrm{start}}$ 开始，我们为指定的预测时间步数 $T_{\\mathrm{forecast}}$ 运行 $K$ 次独立的模拟。由于更新规则的随机性，这 $K$ 次模拟中的每一次都会产生不同的轨迹。在未来步骤 $h$ 的集成均值预测是该步骤所有 $K$ 条轨迹上观点向量的平均值：\n$$ \\hat{x}(x_{\\mathrm{start}}, h) = \\frac{1}{K} \\sum_{k=1}^{K} x^{(k)}(h) $$\n其中 $x^{(k)}(h)$ 是第 $k$ 次模拟运行在步骤 $h$ 时的状态。\n\n**拟合有界信任模型**：\nBC模型有两个参数，信任边界 $\\epsilon$ 和收敛参数 $\\mu$。这些参数从预定义的网格 $\\{\\epsilon_1, \\dots, \\epsilon_m\\} \\times \\{\\mu_1, \\dots, \\mu_n\\}$ 中选择。最优对 $(\\epsilon^*, \\mu^*)$ 是最小化样本内单步向前预测误差的那个。这个训练标准是在观测到的时间序列 $x(0), \\dots, x(T_{\\mathrm{obs}})$ 上计算的：\n$$ (\\epsilon^*, \\mu^*) = \\underset{(\\epsilon, \\mu)}{\\arg\\min} \\frac{1}{N T_{\\mathrm{obs}}} \\sum_{t=0}^{T_{\\mathrm{obs}}-1} \\sum_{i=1}^{N} \\left( \\hat{x}_i(x(t), 1; \\epsilon, \\mu) - x_i(t+1) \\right)^2 $$\n这里，$\\hat{x}(x(t), 1; \\epsilon, \\mu)$ 是从真实观测状态 $x(t)$ 开始，使用参数 $(\\epsilon, \\mu)$ 的单步向前集成均值预测。\n\n### 4. 模型选择\n\n在确定BC模型的最佳参数 $(\\epsilon^*, \\mu^*)$ 后，我们在预留的测试数据上评估两个候选模型，测试数据包括时间步 $T_{\\mathrm{obs}}+1, \\dots, T_{\\mathrm{obs}}+T_{\\mathrm{pred}}$。\n\n对于每个模型 $M \\in \\{\\text{Voter}, \\text{BC}(\\epsilon^*, \\mu^*)\\}$，我们首先为整个预测区间 $h=1, \\dots, T_{\\mathrm{pred}}$ 生成样本外集成均值预测 $\\hat{x}(T_{\\mathrm{obs}}+h; M)$。所有预测都从最后一个观测状态 $x(T_{\\mathrm{obs}})$ 开始。\n\n然后为每个模型计算样本外均方误差（MSE）：\n$$ \\mathrm{MSE}(M) = \\frac{1}{N T_{\\mathrm{pred}}} \\sum_{h=1}^{T_{\\mathrm{pred}}} \\sum_{i=1}^{N} \\left( \\hat{x}_i(T_{\\mathrm{obs}}+h; M) - x_i(T_{\\mathrm{obs}}+h) \\right)^2 $$\n其中 $x_i(T_{\\mathrm{obs}}+h)$ 是从预先生成的时间序列中得到的“真实值”。\n\n最终的决策规则是：\n1.  计算 $\\mathrm{MSE}_{\\mathrm{Voter}}$ 和 $\\mathrm{MSE}_{\\mathrm{BC}}$。\n2.  如果 $\\mathrm{MSE}_{\\mathrm{BC}}  \\mathrm{MSE}_{\\mathrm{Voter}} - \\tau$，其中 $\\tau = 10^{-9}$ 是数值容差，则选择有界信任模型（索引 $1$）。\n3.  否则，选择投票者模型（索引 $0$）。这包括 $\\mathrm{MSE}_{\\mathrm{Voter}} \\le \\mathrm{MSE}_{\\mathrm{BC}}$ 或两者几乎相等的情况。\n\n这个过程将独立地应用于问题陈述中定义的四个测试用例。实现将使用 `numpy` 进行高效的数值计算，并将使用指定的种子仔细管理随机数生成器以确保可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef make_ring_graph(n):\n    \"\"\"Generates an adjacency matrix and edge list for a ring graph.\"\"\"\n    adj = np.zeros((n, n), dtype=int)\n    for i in range(n):\n        adj[i, (i + 1) % n] = 1\n        adj[(i + 1) % n, i] = 1\n    edges = np.argwhere(np.triu(adj, k=1))\n    return adj, edges\n\ndef make_er_graph(n, p, rng):\n    \"\"\"Generates an adjacency matrix and edge list for an Erdős–Rényi graph.\"\"\"\n    adj = np.zeros((n, n), dtype=int)\n    for i in range(n):\n        for j in range(i + 1, n):\n            if rng.random()  p:\n                adj[i, j] = 1\n                adj[j, i] = 1\n    edges = np.argwhere(np.triu(adj, k=1))\n    return adj, edges\n\ndef make_two_rings_graph(n1, n2):\n    \"\"\"Generates two disjoint rings.\"\"\"\n    n = n1 + n2\n    adj = np.zeros((n, n), dtype=int)\n    # First ring\n    for i in range(n1):\n        adj[i, (i + 1) % n1] = 1\n        adj[(i + 1) % n1, i] = 1\n    # Second ring\n    for i in range(n1, n):\n        idx_in_block = i - n1\n        neighbor_in_block = (idx_in_block + 1) % n2\n        adj[i, n1 + neighbor_in_block] = 1\n        adj[n1 + neighbor_in_block, i] = 1\n    edges = np.argwhere(np.triu(adj, k=1))\n    return adj, edges\n\ndef make_star_graph(n):\n    \"\"\"Generates a star graph with center node 0.\"\"\"\n    adj = np.zeros((n, n), dtype=int)\n    for i in range(1, n):\n        adj[0, i] = 1\n        adj[i, 0] = 1\n    edges = np.argwhere(np.triu(adj, k=1))\n    return adj, edges\n\ndef simulate_voter_sweep(x, n_nodes, edges, rng):\n    \"\"\"Simulates one sweep of the Voter model.\"\"\"\n    x_new = x.copy()\n    if edges.shape[0] == 0:\n        return x_new\n    \n    edge_indices = rng.integers(0, len(edges), size=n_nodes)\n    for edge_idx in edge_indices:\n        i, j = edges[edge_idx]\n        # Randomly choose direction\n        if rng.random()  0.5:\n            x_new[i] = x_new[j]\n        else:\n            x_new[j] = x_new[i]\n    return x_new\n\ndef simulate_bc_sweep(x, n_nodes, edges, epsilon, mu, rng):\n    \"\"\"Simulates one sweep of the Bounded Confidence model.\"\"\"\n    x_new = x.copy()\n    if edges.shape[0] == 0:\n        return x_new\n        \n    edge_indices = rng.integers(0, len(edges), size=n_nodes)\n    for edge_idx in edge_indices:\n        i, j = edges[edge_idx]\n        if abs(x_new[i] - x_new[j]) = epsilon:\n            dx = mu * (x_new[j] - x_new[i])\n            x_new[i] += dx\n            x_new[j] -= dx\n    return x_new\n\ndef generate_full_timeseries(x0, n_steps, true_model, params):\n    \"\"\"Generates the ground truth time series.\"\"\"\n    n_nodes = len(x0)\n    timeseries = np.zeros((n_steps + 1, n_nodes))\n    timeseries[0] = x0\n    x_current = x0.copy()\n    \n    for t in range(1, n_steps + 1):\n        if true_model == 'voter':\n            x_current = simulate_voter_sweep(x_current, n_nodes, params['edges'], params['rng'])\n        else: # bc\n            x_current = simulate_bc_sweep(x_current, n_nodes, params['edges'], params['epsilon'], params['mu'], params['rng'])\n        timeseries[t] = x_current\n    return timeseries\n\ndef ensemble_forecast(x_start, model_type, t_forecast, k_ensemble, n_nodes, edges, rng, **model_params):\n    \"\"\"Generates an ensemble forecast.\"\"\"\n    trajectories = np.zeros((k_ensemble, t_forecast, n_nodes))\n    \n    for k in range(k_ensemble):\n        x_current = x_start.copy()\n        for h in range(t_forecast):\n            if model_type == 'voter':\n                x_current = simulate_voter_sweep(x_current, n_nodes, edges, rng)\n            else: # bc\n                x_current = simulate_bc_sweep(x_current, n_nodes, edges, model_params['epsilon'], model_params['mu'], rng)\n            trajectories[k, h, :] = x_current\n            \n    return np.mean(trajectories, axis=0)\n\ndef solve():\n    common_settings = {\n        'N': 30,\n        'T_obs': 20,\n        'T_pred': 5,\n        'K': 50,\n        'bc_param_grid': {'epsilon': [0.15, 0.25, 0.35], 'mu': [0.3, 0.5]},\n        'tau': 1e-9\n    }\n\n    test_cases = [\n        {\n            'name': 'Case 1', 'graph_type': 'ring', 'true_model': 'bc',\n            'model_params': {'epsilon_true': 0.25, 'mu_true': 0.5},\n            'opinion_dist': 'uniform', 'op_seed': 7, 'graph_seed': None\n        },\n        {\n            'name': 'Case 2', 'graph_type': 'er', 'graph_params': {'p': 0.2}, 'true_model': 'voter',\n            'model_params': {}, 'opinion_dist': 'bernoulli', 'op_seed': 5, 'graph_seed': 123\n        },\n        {\n            'name': 'Case 3', 'graph_type': 'two_rings', 'graph_params': {'n1': 15, 'n2': 15}, 'true_model': 'bc',\n            'model_params': {'epsilon_true': 0.20, 'mu_true': 0.5},\n            'opinion_dist': 'uniform', 'op_seed': 33, 'graph_seed': None\n        },\n        {\n            'name': 'Case 4', 'graph_type': 'star', 'true_model': 'voter',\n            'model_params': {}, 'opinion_dist': 'bernoulli', 'op_seed': 21, 'graph_seed': None\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N = common_settings['N']\n        T_obs = common_settings['T_obs']\n        T_pred = common_settings['T_pred']\n        K = common_settings['K']\n        \n        # Setup RNGs for reproducibility\n        master_seed = case['op_seed'] if case['graph_seed'] is None else case['graph_seed']\n        rng = np.random.default_rng(master_seed)\n        \n        # --- 1. Data Generation ---\n        if case['graph_type'] == 'ring':\n            adj, edges = make_ring_graph(N)\n        elif case['graph_type'] == 'er':\n            graph_rng = np.random.default_rng(case['graph_seed'])\n            adj, edges = make_er_graph(N, case['graph_params']['p'], graph_rng)\n        elif case['graph_type'] == 'two_rings':\n            adj, edges = make_two_rings_graph(case['graph_params']['n1'], case['graph_params']['n2'])\n        elif case['graph_type'] == 'star':\n            adj, edges = make_star_graph(N)\n\n        op_rng = np.random.default_rng(case['op_seed'])\n        if case['opinion_dist'] == 'uniform':\n            x0 = op_rng.uniform(0, 1, size=N)\n        else:  # bernoulli\n            x0 = op_rng.integers(0, 2, size=N).astype(float)\n        \n        sim_params = {'edges': edges, 'rng': rng}\n        if case['true_model'] == 'bc':\n            sim_params['epsilon'] = case['model_params']['epsilon_true']\n            sim_params['mu'] = case['model_params']['mu_true']\n            \n        full_ts = generate_full_timeseries(x0, T_obs + T_pred, case['true_model'], sim_params)\n        \n        x_obs = full_ts[:T_obs + 1]\n        x_start_pred = x_obs[-1]\n        x_heldout = full_ts[T_obs + 1:]\n\n        # --- 2. Fit Bounded Confidence Model ---\n        best_bc_params = {}\n        min_train_mse = float('inf')\n        bc_grid = common_settings['bc_param_grid']\n        \n        for eps_val in bc_grid['epsilon']:\n            for mu_val in bc_grid['mu']:\n                total_se = 0\n                for t in range(T_obs):\n                    x_t = x_obs[t]\n                    x_t_plus_1_true = x_obs[t + 1]\n                    x_t_plus_1_pred = ensemble_forecast(x_t, 'bc', 1, K, N, edges, rng, epsilon=eps_val, mu=mu_val)[0]\n                    total_se += np.sum((x_t_plus_1_pred - x_t_plus_1_true)**2)\n                \n                train_mse = total_se / (N * T_obs)\n                if train_mse  min_train_mse:\n                    min_train_mse = train_mse\n                    best_bc_params = {'epsilon': eps_val, 'mu': mu_val}\n        \n        # --- 3. Out-of-Sample Evaluation ---\n        # Voter Model\n        voter_preds = ensemble_forecast(x_start_pred, 'voter', T_pred, K, N, edges, rng)\n        mse_voter = np.mean((voter_preds - x_heldout)**2)\n        \n        # Bounded Confidence Model\n        bc_preds = ensemble_forecast(x_start_pred, 'bc', T_pred, K, N, edges, rng, **best_bc_params)\n        mse_bc = np.mean((bc_preds - x_heldout)**2)\n        \n        # --- 4. Model Selection ---\n        if mse_bc  mse_voter - common_settings['tau']:\n            results.append(1) # Bounded Confidence\n        else:\n            results.append(0) # Voter\n            \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}