{
    "hands_on_practices": [
        {
            "introduction": "波利亚罐子模型是理解路径依赖最经典的模型之一，它清晰地展示了“富者愈富”的增强反馈机制。本练习  旨在通过构建一个增广状态空间，将一个表面上依赖于历史的随机过程转化为一个马尔可夫链。通过这个过程，你将掌握如何用严谨的数学语言来刻画路径依赖现象，并理解历史信息是如何被“编码”到系统的当前状态中的。",
            "id": "4136085",
            "problem": "考虑一个包含红色和蓝色两种颜色的经典波利亚坛子。在时间 $t=0$ 时，坛子中包含 $r_{0} \\in \\mathbb{N}$ 个红球和 $b_{0} \\in \\mathbb{N}$ 个蓝球。在每个离散时间步 $t \\mapsto t+1$，从坛子中均匀随机地抽取一个球，观察其颜色，然后将该球放回坛子，并额外添加一个同色的球。令 $X_{t} \\in \\{\\text{red}, \\text{blue}\\}$ 表示在时间 $t$ 抽出的球的颜色，令 $R_{t}$ 和 $B_{t}$ 分别表示在时间 $t$ 抽球之前坛子中红球和蓝球的数量。\n\n你需要使用马尔可夫性质来形式化此过程的路径依赖性和历史偶然性。从马尔可夫性质的标准定义和坛子的抽样规则出发，确定一个最小充分的增广状态过程 $S_{t} = \\varphi\\!\\left(X_{0}, X_{1}, \\dots, X_{t}\\right)$，使得 $\\{S_{t}\\}_{t \\ge 0}$ 是一个时间齐次的马尔可夫链，其一步转移概率不显式地依赖于 $t$。根据使动力学系统成为时间齐次马尔可夫过程所需的最少历史信息来证明其最小性。\n\n然后，推导这个增广状态下的一步转移概率：对于一个泛型状态 $(r,b)$，其中 $r \\in \\mathbb{N}$ 且 $b \\in \\mathbb{N}$，写出到两个可能的下一个状态，即 $(r+1,b)$ 和 $(r,b+1)$ 的转移概率，表示为关于 $r$ 和 $b$ 的精确代数表达式。\n\n你的最终答案必须是一个单行矩阵，包含按此顺序对应的这两个转移概率。不要对任何量进行近似。",
            "solution": "所述问题具有科学依据，是适定的、客观的且内部一致的。它描述了经典的波利亚坛子模型，这是一个基础的随机过程，用于阐释强化和路径依赖的概念。所有必要的信息都已提供，足以形式化该过程并推导其转移概率。因此，该问题是有效的。\n\n问题的核心是在马尔可夫链的框架内，形式化波利亚坛子过程的路径依赖性。路径依赖意味着事件的历史会影响未来的结果。相比之下，马尔可夫过程是无记忆的：其未来的演化仅依赖于当前状态，而与到达该状态的路径无关。解决方法在于定义一个状态变量，该变量完全封装了所有来自过去的相关信息。\n\n令系统在时间 $t \\geq 0$ 的状态由序对 $S_t = (R_t, B_t)$ 定义，其中 $R_t$ 和 $B_t$ 分别是在时间 $t$ 抽球之前坛子中红球和蓝球的数量。初始状态为 $S_0 = (r_0, b_0)$。\n\n状态 $S_t$ 是抽球历史 $\\{X_0, X_1, \\dots, X_{t-1}\\}$ 的函数。具体来说，对于 $t \\ge 1$，红球的数量 $R_t$ 是初始数量 $r_0$ 加上在前 $t$ 步中抽到红球的次数。类似的逻辑也适用于蓝球。形式上：\n$$R_t = r_0 + \\sum_{i=0}^{t-1} \\mathbb{I}(X_i = \\text{red})$$\n$$B_t = b_0 + \\sum_{i=0}^{t-1} \\mathbb{I}(X_i = \\text{blue})$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。状态 $S_t=(R_t, B_t)$ 是累积了历史信息的“增广状态”。不同的抽球序列（路径）可以导致不同的状态 $(R_t, B_t)$，这一事实是该模型中历史偶然性的本质。在时间 $t$ 的总球数为 $N_t = R_t + B_t = r_0 + b_0 + t$。\n\n我们现在必须证明过程 $\\{S_t\\}_{t \\geq 0}$ 是一个时间齐次的马尔可夫链，并且 $S_t$ 是一个最小充分状态。\n\n**1. 马尔可夫性质与时间齐次性**\n\n为证明马尔可夫性质，我们必须表明下一状态 $S_{t+1}$ 的条件概率仅依赖于当前状态 $S_t$，而不依赖于任何过去的状态 $S_{t-1}, \\dots, S_0$。\n从 $S_t$ 到 $S_{t+1}$ 的状态转移通过在时间 $t$ 的抽球发生。令当前状态为 $S_t = (R_t, B_t) = (r, b)$。总球数为 $r+b$。\n在时间 $t$ 抽到红球的概率为：\n$$P(X_t = \\text{red} | S_t=(r,b), S_{t-1}, \\dots, S_0) = \\frac{r}{r+b}$$\n此概率仅依赖于当前状态 $S_t=(r,b)$ 的分量。如果抽到红球，则下一步坛子中的组成变为 $(r+1, b)$。因此，下一个状态是 $S_{t+1}=(r+1, b)$。\n抽到蓝球的概率为：\n$$P(X_t = \\text{blue} | S_t=(r,b), S_{t-1}, \\dots, S_0) = \\frac{b}{r+b}$$\n这也只依赖于 $S_t$。如果抽到蓝球，下一个状态是 $S_{t+1}=(r, b+1)$。\n\n从状态 $(r,b)$ 出发的一步转移概率为：\n$$P(S_{t+1}=(r+1, b) | S_t=(r,b)) = \\frac{r}{r+b}$$\n$$P(S_{t+1}=(r, b+1) | S_t=(r,b)) = \\frac{b}{r+b}$$\n由于这些概率仅依赖于当前状态 $(r,b)$ 而不依赖于时间索引 $t$，因此过程 $\\{S_t\\}_{t \\geq 0}$ 是一个时间齐次的马尔可夫链。\n\n**2. 最小性**\n\n为了证明 $S_t=(R_t, B_t)$ 是一个最小充分状态，我们必须表明没有更小的信息集可以定义一个时间齐次的马尔可夫过程。转移概率从根本上取决于红球与总球数的比率 $R_t/(R_t+B_t)$，以及蓝球与总球数的比率 $B_t/(R_t+B_t)$。要计算这些比率，需要同时知道 $R_t$ 和 $B_t$。\n- 如果状态仅由 $R_t$ 定义，我们将无法在不知道 $t$ 或 $B_t$ 的情况下计算分母 $R_t+B_t$。\n- 如果状态仅由总球数 $N_t = R_t+B_t = r_0+b_0+t$ 定义（这等价于知道时间 $t$），我们将无法计算分子 $R_t$ 或 $B_t$。\n- 如果状态是红球的比例 $P_t=R_t/(R_t+B_t)$，那么到下一个比例的转移将取决于总球数 $N_t$，由于 $N_t$ 随时间确定性地变化，这将使过程成为时间非齐次的。\n因此，序对 $(R_t, B_t)$ 是在不显式引用时间 $t$ 的情况下指定转移概率所需的最小历史表示。\n\n**3. 转移概率的推导**\n\n现在，我们为泛型状态 $(r,b)$ 推导所要求的转移概率，其中 $r \\in \\mathbb{N}$ 且 $b \\in \\mathbb{N}$。坛子中包含 $r$ 个红球和 $b$ 个蓝球，总共 $r+b$ 个球。\n\n第一个可能的下一个状态是 $(r+1, b)$。当且仅当抽到红球时，才会达到此状态。此事件的概率是红球数除以总球数。\n$$P((r,b) \\to (r+1,b)) = \\frac{r}{r+b}$$\n\n第二个可能的下一个状态是 $(r, b+1)$。当且仅当抽到蓝球时，才会达到此状态。此事件的概率是蓝球数除以总球数。\n$$P((r,b) \\to (r,b+1)) = \\frac{b}{r+b}$$\n\n这是从状态 $(r,b)$ 出发的仅有的两种可能的一步转移。它们的和为 $\\frac{r}{r+b} + \\frac{b}{r+b} = \\frac{r+b}{r+b} = 1$，这符合后继状态的完备概率分布的要求。\n\n最终答案要求将这两个概率写成一个行矩阵。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{r}{r+b}  \\frac{b}{r+b} \\end{pmatrix} } $$"
        },
        {
            "introduction": "Kauffman 的 $N\\text{-}K$ 模型是研究复杂适应系统中“适应性景观”的基石，它揭示了基因间的相互作用（上位性）如何塑造演化路径。这个练习  要求你推导景观崎岖度的一个关键度量——自相关长度 $\\ell$，并证明增加系统的复杂性（即增大 $K$ 值）会导致景观变得更加崎岖。这将帮助你理解，在一个崎岖的景观上，局部搜索或演化过程的最终结果为何会高度依赖于其起始点和历史轨迹，这是路径依赖在演化动力学中的核心体现。",
            "id": "4136136",
            "problem": "考虑一个适应度景观的Kauffman $N\\text{-}K$模型（NK），其中基因型是一个二进制字符串 $x \\in \\{0,1\\}^{N}$，基因型 $x$ 的适应度定义为 $W(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_{i}(x_{i}, x_{i_{1}}, \\dots, x_{i_{K}})$，其中对于每个索引 $i$，局部适应度贡献 $f_{i}$ 取决于位点 $i$ 和其他 $K$ 个位点 $i_{1}, \\dots, i_{K}$ 的状态，并满足以下假设：(i) 对每个 $i$，其邻域 $\\{i, i_{1}, \\dots, i_{K}\\}$ 是从 $\\{1, \\dots, N\\}$ 中无放回地均匀随机选择的，且满足 $|\\{i, i_{1}, \\dots, i_{K}\\}| = K+1$；(ii) 在给定其输入的情况下，$f_{i}$ 是一个独立同分布的随机变量，其在所有输入配置上的均值为 $0$，方差为 $\\sigma^2$；(iii) 在给定其输入的情况下，不同索引的适应度贡献是相互独立的。设两个基因型 $x$ 和 $y$ 之间的汉明距离为 $h = \\sum_{j=1}^{N} \\mathbf{1}\\{x_{j} \\neq y_{j}\\}$。\n\n定义汉明距离为 $h$ 时的归一化自相关函数为\n$$\n\\rho(h) = \\frac{\\operatorname{Cov}(W(X), W(Y_{h}))}{\\operatorname{Var}(W(X))},\n$$\n其中 $X$ 在 $\\{0,1\\}^{N}$ 中均匀随机，而 $Y_{h}$ 在与 $X$ 的汉明距离为 $h$ 的基因型中均匀随机。仅使用模型定义以及标准的概率和协方差规则，推导出 $\\rho(h)$ 作为 $N$、$K$ 和 $h$ 的精确函数。\n\n接下来，定义自相关长度 $\\ell$ 为满足下式的正实数\n$$\n\\rho(1) = \\exp\\!\\left(-\\frac{1}{\\ell}\\right),\n$$\n它可作为一个粗糙度度量。明确推导出 $\\ell$ 作为 $N$ 和 $K$ 的闭式解析表达式，然后解析地证明增加 $K$（在 $[0, N-1]$ 中视为实数参数）会严格减小 $\\ell$。最后，讨论这种相关长度的缩短如何意味着景观上局部搜索轨迹的路径依赖性更大，但最终数值结果仅提供 $\\ell(N,K)$ 的闭式表达式。不需要数值舍入，也不涉及单位。你的最终答案必须是一个单一的闭式表达式。",
            "solution": "该问题陈述是复杂自适应系统领域内一个有效的理论练习，特别关注 Kauffman $N\\text-K$ 适应度景观的统计特性。所有定义都是标准的，前提在科学和数学上都是合理的。我们将进行推导。\n\n我们的目标是首先推导出归一化自相关函数 $\\rho(h)$，然后从中推导出自相关长度 $\\ell$。自相关函数定义为\n$$\n\\rho(h) = \\frac{\\operatorname{Cov}(W(X), W(Y_{h}))}{\\operatorname{Var}(W(X))}\n$$\n其中 $W(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_{i}(x)$ 是基因型 $x$ 的适应度，期望是针对基因型 $X \\in \\{0,1\\}^N$ 和 $Y_h$（一个与 $X$ 汉明距离为 $h$ 的基因型）的均匀分布以及随机适应度景观的系综来计算的。\n\n首先，我们计算分母 $\\operatorname{Var}(W(X))$。$W(X)$ 的期望是\n$$\n\\mathbb{E}[W(X)] = \\mathbb{E}\\left[\\frac{1}{N} \\sum_{i=1}^{N} f_{i}(X)\\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}[f_{i}(X)]\n$$\n根据假设 (ii)，对于任何特定的输入配置，局部适应度贡献 $f_i$ 的均值为 $0$。由于 $X$ 是一个均匀随机的基因型，其各位是 $f_i$ 的均匀随机输入。对所有可能的输入求平均，期望 $\\mathbb{E}[f_i(X)]$ 为 $0$。因此，$\\mathbb{E}[W(X)] = 0$。\n\n那么方差为 $\\operatorname{Var}(W(X)) = \\mathbb{E}[W(X)^2] - (\\mathbb{E}[W(X)])^2 = \\mathbb{E}[W(X)^2]$。\n$$\n\\mathbb{E}[W(X)^2] = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} f_{i}(X)\\right)^2\\right] = \\frac{1}{N^2} \\mathbb{E}\\left[\\sum_{i=1}^{N} \\sum_{j=1}^{N} f_{i}(X) f_{j}(X)\\right] = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\mathbb{E}[f_{i}(X) f_{j}(X)]\n$$\n根据假设 (iii)，当 $i \\neq j$ 时，适应度贡献 $f_i$ 和 $f_j$ 是独立的。因此，对于 $i \\neq j$，$\\mathbb{E}[f_{i}(X) f_{j}(X)] = \\mathbb{E}[f_{i}(X)]\\mathbb{E}[f_{j}(X)] = 0 \\cdot 0 = 0$。求和简化为对角线项，即 $i=j$ 的情况：\n$$\n\\operatorname{Var}(W(X)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\mathbb{E}[f_i(X)^2]\n$$\n根据假设 (ii)，对于任何输入，随机变量 $f_i$ 的均值为 $0$，方差为 $\\sigma^2$。其平方的期望，在所有可能的输入（由随机基因型 $X$ 决定）上求平均，就是其方差：$\\mathbb{E}[f_i(X)^2] = \\sigma^2$。\n$$\n\\operatorname{Var}(W(X)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sigma^2 = \\frac{N\\sigma^2}{N^2} = \\frac{\\sigma^2}{N}\n$$\n\n接下来，我们计算分子 $\\operatorname{Cov}(W(X), W(Y_h))$。由于 $\\mathbb{E}[W(X)]=0$ 且 $\\mathbb{E}[W(Y_h)]=0$（因为 $Y_h$ 在所有基因型上也具有均匀的边缘分布），协方差简化为\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\mathbb{E}[W(X)W(Y_h)] = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} f_i(X)\\right)\\left(\\frac{1}{N} \\sum_{j=1}^{N} f_j(Y_h)\\right)\\right] = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\mathbb{E}[f_i(X)f_j(Y_h)]\n$$\n同样，对于 $i \\neq j$，由于独立性，这些项为零。我们只剩下对角线项：\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\mathbb{E}[f_i(X)f_i(Y_h)]\n$$\n期望 $\\mathbb{E}[f_i(X)f_i(Y_h)]$ 仅当来自 $X$ 和 $Y_h$ 的 $f_i$ 的输入相同时才非零。设来自基因型 $z$ 的对 $f_i$ 的输入为 $z_{\\mathcal{N}_i}$，其中 $\\mathcal{N}_i$ 是 $i$ 的邻域（一个包含 $K+1$ 个位点的集合）。根据假设 (ii)，对于不同的输入，$f_i$ 的值是不相关的。所以，$\\mathbb{E}[f_i(u)f_i(v)] = \\sigma^2 \\delta_{u,v}$，其中 $\\delta_{u,v}$ 是克罗内克 δ。对基因型和景观的期望是\n$$\n\\mathbb{E}[f_i(X)f_i(Y_h)] = \\sigma^2 P(X_{\\mathcal{N}_i} = (Y_h)_{\\mathcal{N}_i})\n$$\n输入 $X_{\\mathcal{N}_i}$ 和 $(Y_h)_{\\mathcal{N}_i}$ 相同，当且仅当 $X$ 和 $Y_h$ 之间不同的 $h$ 个位点中没有一个落入邻域 $\\mathcal{N}_i$。不同的位点集合 $S_h$ 是从 $\\{1, \\dots, N\\}$ 中均匀随机选出的一个大小为 $h$ 的子集。邻域 $\\mathcal{N}_i$ 是一个包含 $K+1$ 个位点的集合。从 $h$ 个位点的随机抽样与一个固定的包含 $K+1$ 个位点的集合不相交的概率由超几何分布给出。我们从 $N$ 个位点中选择 $h$ 个，并且我们希望从 $\\mathcal{N}_i$ 中的 $K+1$ 个中选择 $0$ 个，从 $\\mathcal{N}_i$ 外的 $N-(K+1)$ 个中选择 $h$ 个。\n$$\nP(X_{\\mathcal{N}_i} = (Y_h)_{\\mathcal{N}_i}) = P(S_h \\cap \\mathcal{N}_i = \\emptyset) = \\frac{\\binom{K+1}{0} \\binom{N-(K+1)}{h}}{\\binom{N}{h}} = \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n这个概率对于所有的 $i$ 都是相同的。将此代回协方差表达式：\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sigma^2 \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}} = \\frac{N\\sigma^2}{N^2} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}} = \\frac{\\sigma^2}{N} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n现在我们可以计算 $\\rho(h)$：\n$$\n\\rho(h) = \\frac{\\frac{\\sigma^2}{N} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}}{\\frac{\\sigma^2}{N}} = \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n这是自相关函数的精确表达式。此式在 $h \\le N-K-1$ 时有效；当 $h  N-K-1$ 时，$\\rho(h)=0$。\n\n接下来，我们推导由 $\\rho(1) = \\exp(-1/\\ell)$ 定义的自相关长度 $\\ell$。我们计算 $\\rho(h)$ 在 $h=1$ 处的值：\n$$\n\\rho(1) = \\frac{\\binom{N-K-1}{1}}{\\binom{N}{1}} = \\frac{N-K-1}{N} = 1 - \\frac{K+1}{N}\n$$\n使用 $\\ell$ 的定义：\n$$\n\\exp\\left(-\\frac{1}{\\ell}\\right) = 1 - \\frac{K+1}{N}\n$$\n通过对两边取自然对数来求解 $\\ell$：\n$$\n-\\frac{1}{\\ell} = \\ln\\left(1 - \\frac{K+1}{N}\\right)\n$$\n$$\n\\ell = -\\frac{1}{\\ln\\left(1 - \\frac{K+1}{N}\\right)}\n$$\n这就是 $\\ell$ 关于 $N$ 和 $K$ 的闭式表达式。\n\n最后，我们必须证明 $\\ell$ 是 $K$ 的严格递减函数，将 $K$ 视为在 $[0, N-1)$ 区间内的实数参数。我们计算导数 $\\frac{d\\ell}{dK}$：\n令 $u(K) = 1 - \\frac{K+1}{N}$。那么 $\\frac{du}{dK} = -\\frac{1}{N}$。\n$\\ell$ 的表达式为 $\\ell(K) = -(\\ln(u(K)))^{-1}$。使用链式法则：\n$$\n\\frac{d\\ell}{dK} = -(-1)(\\ln(u(K)))^{-2} \\cdot \\frac{d}{dK}(\\ln(u(K))) = (\\ln(u(K)))^{-2} \\cdot \\frac{1}{u(K)} \\cdot \\frac{du}{dK}\n$$\n代入 $u(K)$ 及其导数的表达式：\n$$\n\\frac{d\\ell}{dK} = \\frac{1}{\\left(\\ln\\left(1 - \\frac{K+1}{N}\\right)\\right)^2} \\cdot \\frac{1}{1 - \\frac{K+1}{N}} \\cdot \\left(-\\frac{1}{N}\\right)\n$$\n我们分析在 $K \\in [0, N-1)$ 区间内每一项的符号：\n1. 对于 $K \\in [0, N-1)$，我们有 $1 \\le K+1  N$，所以 $0  \\frac{K+1}{N}  1$。\n2. 这意味着 $0  1 - \\frac{K+1}{N}  1$。\n3. 介于 $0$ 和 $1$ 之间的数的对数是负数，所以 $\\ln\\left(1 - \\frac{K+1}{N}\\right)  0$。其平方是正数：$\\left(\\ln\\left(1 - \\frac{K+1}{N}\\right)\\right)^2  0$。\n4. 项 $1 - \\frac{K+1}{N}$ 是正数。其倒数也是正数。\n5. 最后一项 $-\\frac{1}{N}$ 是负数，因为 $N \\ge 1$。\n综合这些，$\\frac{d\\ell}{dK}$ 是两个正项和一个负项的乘积。因此，对于所有 $K \\in [0, N-1)$，$\\frac{d\\ell}{dK}  0$。这证明了 $\\ell$ 是 $K$ 的一个严格递减函数。\n\n随着上位性 $K$ 的增加，相关长度 $\\ell$ 的减小表明适应度景观变得更加“崎岖”。一个较小的 $\\ell$ 意味着基因型的适应度值随着汉明距离的增加而更快地去相关。在一个崎岖的景观上，适应性行走（例如，局部爬山法）更有可能被困在次优的局部适应度峰值上。达到的具体峰值对起始基因型和突变序列高度敏感。最终状态对历史轨迹的这种强烈依赖性是路径依赖的本质。因此，增加 $K$ 会增加景观的崎岖度，这反过来又导致进化动力学中更大的路径依赖性。",
            "answer": "$$\n\\boxed{-\\frac{1}{\\ln\\left(1 - \\frac{K+1}{N}\\right)}}\n$$"
        },
        {
            "introduction": "双阱势模型广泛用于描述物理学和社会科学中具有多个稳定状态的系统。本练习  将引导你分析一个在此类势场中运动并受随机噪声扰动的粒子，其动态由郎之万方程描述。你的任务是运用克莱默斯速率理论来估算系统从一个稳定“阱”逃逸到另一个“阱”的期望时间，从而理解为何微小的、偶然的历史事件（噪声驱动的翻越）能够将系统“锁定”在一个全新的、持久的路径上，这正是历史偶然性的一个深刻体现。",
            "id": "4136056",
            "problem": "考虑一个过阻尼的、基于智能体的聚合体，在介观尺度上由一个单一状态变量 $x_t \\in \\mathbb{R}$ 表示，该变量在双阱势下演化。其粗粒化动力学由过阻尼朗之万随机微分方程 (SDE) 建模，定义如下\n$$\ndx_t \\;=\\; -V'(x_t)\\,dt \\;+\\; \\sqrt{2\\,\\varepsilon}\\,dW_t,\n$$\n其中 $W_t$ 是一个标准维纳过程，$\\varepsilon  0$ 是一个小的无量纲噪声强度，$V(x)$ 是势能景观。该势函数为\n$$\nV(x) \\;=\\; \\frac{\\alpha}{4}\\,x^{4} \\;-\\; \\frac{\\beta}{2}\\,x^{2},\n$$\n参数为 $\\alpha = 1$ 和 $\\beta = 3$。时间 $t$ 以秒为单位。假设系统从左势阱中靠近局部最小值 $x = -\\sqrt{\\beta/\\alpha}$ 的位置开始，并且 $\\varepsilon = 0.2$。在小噪声情形下，从一个势阱到另一个势阱的逃逸是稀有事件，其期望时间尺度由能垒和噪声驱动的激活所决定。\n\n从梯度流、亚稳态之间的势垒以及过阻尼福克-普朗克动力学的准静态分布等基本定义出发，从第一性原理推导出能垒 $\\Delta V$，然后使用过阻尼极限下的经典 Kramers 速率来估计从左势阱越过中心鞍点的期望逃逸时间。通过解释为什么罕见的早期逃逸可以在很长的时间范围内将系统锁定在一个不同的吸引盆中，将此计算与路径依赖和历史偶然性的概念联系起来。\n\n计算期望逃逸时间的数值，并以秒为单位表示最终答案。将最终数值四舍五入到四位有效数字。",
            "solution": "系统的动力学由势能景观 $V(x)$ 上的梯度流决定，并受到一个随机项的扰动。势函数由下式给出：\n$$\nV(x) = \\frac{\\alpha}{4}x^{4} - \\frac{\\beta}{2}x^{2}\n$$\n动力学的确定性部分由力 $F(x) = -V'(x)$ 驱动。系统的平衡点对应于该力为零的位置，即势梯度为零的位置：\n$$\nV'(x) = \\frac{d}{dx}\\left(\\frac{\\alpha}{4}x^{4} - \\frac{\\beta}{2}x^{2}\\right) = \\alpha x^{3} - \\beta x = 0\n$$\n对表达式进行因式分解得到 $x(\\alpha x^2 - \\beta) = 0$，由此得出三个平衡点：\n$x_1 = 0$\n$x_2 = \\sqrt{\\frac{\\beta}{\\alpha}}$\n$x_3 = -\\sqrt{\\frac{\\beta}{\\alpha}}$\n\n为确定这些点的稳定性，我们考察势的二阶导数 $V''(x)$：\n$$\nV''(x) = \\frac{d}{dx}(\\alpha x^{3} - \\beta x) = 3\\alpha x^{2} - \\beta\n$$\n- 在 $x_1 = 0$ 处：$V''(0) = -\\beta$。由于 $\\beta = 3 > 0$，所以 $V''(0)  0$。这表明 $x=0$ 是一个局部极大值，对应于一个不稳定平衡（一个鞍点或势垒峰值）。\n- 在 $x_{2,3} = \\pm\\sqrt{\\frac{\\beta}{\\alpha}}$ 处：$V''\\left(\\pm\\sqrt{\\frac{\\beta}{\\alpha}}\\right) = 3\\alpha\\left(\\frac{\\beta}{\\alpha}\\right) - \\beta = 3\\beta - \\beta = 2\\beta$。由于 $\\beta=3>0$，所以 $V''(\\pm\\sqrt{\\beta/\\alpha})  0$。这表明这两点是局部极小值，对应于稳定平衡态（势阱的底部）。\n\n问题陈述系统从左势阱开始，这是稳定极小值 $x_{\\text{min}} = -\\sqrt{\\beta/\\alpha}$ 的吸引盆。为了让系统逃逸到右势阱（$x=+\\sqrt{\\beta/\\alpha}$ 附近），它必须越过位于鞍点 $x_{\\text{saddle}} = 0$ 的势垒。\n\n能垒 $\\Delta V$ 是鞍点与初始势阱极小值之间的势能差：\n$$\n\\Delta V = V(x_{\\text{saddle}}) - V(x_{\\text{min}}) = V(0) - V\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)\n$$\n我们计算这些点的势能：\n$V(0) = \\frac{\\alpha}{4}(0)^{4} - \\frac{\\beta}{2}(0)^{2} = 0$\n$V\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right) = \\frac{\\alpha}{4}\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)^4 - \\frac{\\beta}{2}\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)^2 = \\frac{\\alpha}{4}\\left(\\frac{\\beta^2}{\\alpha^2}\\right) - \\frac{\\beta}{2}\\left(\\frac{\\beta}{\\alpha}\\right) = \\frac{\\beta^2}{4\\alpha} - \\frac{\\beta^2}{2\\alpha} = -\\frac{\\beta^2}{4\\alpha}$\n因此，能垒为：\n$$\n\\Delta V = 0 - \\left(-\\frac{\\beta^2}{4\\alpha}\\right) = \\frac{\\beta^2}{4\\alpha}\n$$\n期望逃逸时间 $\\tau$ 可以使用过阻尼极限下的 Kramers 速率公式来估计。逃逸率 $k$（单位时间内发生逃逸事件的概率）由下式给出：\n$$\nk = \\frac{\\sqrt{V''(x_{\\text{min}}) |V''(x_{\\text{saddle}})|}}{2\\pi} \\exp\\left(-\\frac{\\Delta V}{\\varepsilon}\\right)\n$$\n在这里，我们将给定的 SDE 中的噪声项 $\\varepsilon$ 与标准物理学表述中的热能标度 $k_B T$ 等同起来，并且摩擦系数隐含为 $\\gamma=1$。\n我们有：\n$V''(x_{\\text{min}}) = V''(-\\sqrt{\\beta/\\alpha}) = 2\\beta$\n$V''(x_{\\text{saddle}}) = V''(0) = -\\beta$，所以 $|V''(x_{\\text{saddle}})| = \\beta$。\n\n将这些代入速率公式：\n$$\nk = \\frac{\\sqrt{(2\\beta)(\\beta)}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\sqrt{2\\beta^2}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\beta\\sqrt{2}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right)\n$$\n期望逃逸时间 $\\tau$ 是速率 $k$ 的倒数：\n$$\n\\tau = \\frac{1}{k} = \\frac{2\\pi}{\\beta\\sqrt{2}} \\exp\\left(\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\pi\\sqrt{2}}{\\beta} \\exp\\left(\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right)\n$$\n该表达式给出了从左势阱到右势阱的平均首达时间。\n\n**与路径依赖和历史偶然性的联系**\n这个模型为路径依赖和历史偶然性提供了一个清晰的例证。\n1.  **路径依赖：** 系统的长期状态依赖于其历史。初始条件将系统置于左势阱中。由于能垒 $\\Delta V$ 和小噪声强度 $\\varepsilon$，系统将长时间被困在这个势阱中，平均持续时间为 $\\tau$。在任何时间 $t \\ll \\tau$，系统状态极有可能位于左势阱中。因此，未来状态表现出对其过去轨迹的强烈依赖。\n2.  **历史偶然性：** 从左势阱到右势阱的转换是一个罕见的随机事件。确切的逃逸时刻是不可预测的；它是一个“偶然”事件。如果偶然地，一系列足够大的噪声涨落叠加起来，在早期将系统推过势垒（一个“历史偶然事件”），系统的命运就会被戏剧性地改变。它会被“锁定”在右势阱的吸引盆中，并将在那里再次停留很长时间（平均而言，又一个周期 $\\tau$）。因此，系统的长期历史不是预先注定的，而是取决于这个罕见逃逸事件的随机发生。一个在发生这种转换很久之后观察到该系统的观察者可能无法推断出其原始状态，因为系统现在似乎自然地属于右势阱。\n\n**数值计算**\n我们将给定值 $\\alpha = 1$, $\\beta = 3$, 和 $\\varepsilon = 0.2$ 代入 $\\tau$ 的表达式中。\n首先，我们计算指数函数的参数：\n$$\n\\frac{\\Delta V}{\\varepsilon} = \\frac{\\beta^2}{4\\alpha\\varepsilon} = \\frac{3^2}{4(1)(0.2)} = \\frac{9}{0.8} = 11.25\n$$\n现在，我们计算指数前因子：\n$$\n\\frac{\\pi\\sqrt{2}}{\\beta} = \\frac{\\pi\\sqrt{2}}{3}\n$$\n将所有部分组合起来：\n$$\n\\tau = \\frac{\\pi\\sqrt{2}}{3} \\exp(11.25)\n$$\n我们现在计算数值：\n$$\n\\tau \\approx \\frac{3.14159 \\times 1.41421}{3} \\times \\exp(11.25) \\approx \\frac{4.44288}{3} \\times 76878.56 \\approx 1.48096 \\times 76878.56\n$$\n$$\n\\tau \\approx 113851.34\n$$\n题目要求将最终答案四舍五入到四位有效数字。\n$$\n\\tau \\approx 113900 \\text{ s}\n$$\n这可以用科学记数法表示为 $1.139 \\times 10^5$ 秒。",
            "answer": "$$\\boxed{1.139 \\times 10^{5}}$$"
        }
    ]
}