{
    "hands_on_practices": [
        {
            "introduction": "信息熵是量化不确定性的基石。本练习将通过一个具体实例，引导你从第一性原理出发计算离散随机变量的香农熵，并将其与均匀分布下的最大熵进行比较。这个过程不仅能加深你对熵作为“平均意外程度”的理解，还能让你直观地体会到概率分布的非均匀性如何体现为信息的冗余。",
            "id": "4126716",
            "problem": "在一个复杂自适应系统中，主体根据经验自适应地选择行动。考虑单个主体，其行动选择机制已收敛到一个离散分布，该分布作用于一个大小为 $3$ 的行动集上，分配给三个行动的概率为 $p=(1/2,1/3,1/6)$。使用香农熵作为自信息期望值的基本定义，以及自然对数（奈特）和以2为底的对数（比特）之间的标准转换规则，完成以下任务：计算此分布的熵（以奈特和比特为单位），并将其与3个结果上的均匀分布的熵进行比较。你必须从第一性原理推导所有表达式，并清楚地证明所使用的任何底数转换的合理性。你最终报告的答案必须是均匀分布的熵与 $p$ 的熵之差的精确闭式表达式（以比特为单位），即 $H(u)-H(p)$（以比特为单位），其中 $u$ 表示3个结果上的均匀分布。不要四舍五入；提供一个精确表达式。最终答案必须是一个不带单位的单一表达式。",
            "solution": "在尝试解答之前，对问题进行验证。\n\n### 步骤 1：提取已知条件\n-   系统：一个复杂自适应系统中的单个主体。\n-   行动集大小：$3$。\n-   行动的概率分布，$p$：$(1/2, 1/3, 1/6)$。\n-   任务 1：计算分布 $p$ 的香农熵，单位为奈特和比特。\n-   任务 2：将 $p$ 的熵与 3 个结果上的均匀分布（记为 $u$）的熵进行比较。\n-   任务 3：从第一性原理推导所有表达式，并证明对数底数转换的合理性。\n-   最终答案要求：提供差值 $H(u) - H(p)$ 的精确闭式表达式，单位为比特。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学依据：** 该问题牢固地植根于信息论，这是数学和物理学的核心学科，也是复杂系统定量研究的核心。香农熵、自信息和对数底数转换等概念都是标准且成熟的。\n-   **适定性：** 该问题是适定的。给定的概率分布 $p = (1/2, 1/3, 1/6)$ 是有效的，因为概率为非负且总和为 1：$\\frac{1}{2} + \\frac{1}{3} + \\frac{1}{6} = \\frac{3}{6} + \\frac{2}{6} + \\frac{1}{6} = \\frac{6}{6} = 1$。任务是具体的，并能导出一个唯一的、有意义的解。\n-   **客观性：** 问题陈述使用精确、客观的语言，没有歧义或主观断言。\n\n该问题没有表现出验证标准中列出的任何缺陷。它在科学上是合理的，结构上是形式化的，内部是一致的，并且需要严格应用基本原理。\n\n### 步骤 3：结论与行动\n问题是**有效的**。将提供解答。\n\n### 解题推导\n\n一个以概率 $p_i$ 发生的结果 $i$ 的自信息定义为 $I(p_i) = -\\log(p_i)$。对数的底决定了信息的单位。对于本问题，我们将使用底为 $e$（自然对数，$\\ln$）计算奈特，以及底为 $2$（二进制对数，$\\log_2$）计算比特。\n\n离散概率分布 $P = \\{p_1, p_2, \\dots, p_n\\}$ 的香农熵 $H$ 是所有可能结果的自信息的期望值：\n$$H(P) = E[I(p_i)] = \\sum_{i=1}^{n} p_i I(p_i) = -\\sum_{i=1}^{n} p_i \\log(p_i)$$\n\n首先，我们以奈特为单位计算给定分布 $p = (1/2, 1/3, 1/6)$ 的熵。这需要使用自然对数。设 $H_e(p)$ 为以奈特为单位的熵。\n$$H_e(p) = -\\left( \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) + \\frac{1}{3} \\ln\\left(\\frac{1}{3}\\right) + \\frac{1}{6} \\ln\\left(\\frac{1}{6}\\right) \\right)$$\n使用对数恒等式 $\\ln(1/x) = -\\ln(x)$：\n$$H_e(p) = \\frac{1}{2} \\ln(2) + \\frac{1}{3} \\ln(3) + \\frac{1}{6} \\ln(6)$$\n我们可以使用恒等式 $\\ln(ab) = \\ln(a) + \\ln(b)$ 来简化 $\\ln(6)$：\n$$H_e(p) = \\frac{1}{2} \\ln(2) + \\frac{1}{3} \\ln(3) + \\frac{1}{6} (\\ln(2) + \\ln(3))$$\n合并含有 $\\ln(2)$ 和 $\\ln(3)$ 的项：\n$$H_e(p) = \\left(\\frac{1}{2} + \\frac{1}{6}\\right) \\ln(2) + \\left(\\frac{1}{3} + \\frac{1}{6}\\right) \\ln(3)$$\n$$H_e(p) = \\left(\\frac{3}{6} + \\frac{1}{6}\\right) \\ln(2) + \\left(\\frac{2}{6} + \\frac{1}{6}\\right) \\ln(3)$$\n$$H_e(p) = \\frac{4}{6} \\ln(2) + \\frac{3}{6} \\ln(3) = \\frac{2}{3} \\ln(2) + \\frac{1}{2} \\ln(3)$$\n这就是分布 $p$ 以奈特为单位的熵。\n\n接下来，我们将此熵转换为比特。不同底数 $a$ 和 $b$ 的对数之间的转换由换底公式给出：$\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}$。为了从奈特（底为 $e$）转换为比特（底为 $2$），我们设 $a=e$ 和 $b=2$：\n$$\\log_2(x) = \\frac{\\ln(x)}{\\ln(2)}$$\n以比特为单位的熵 $H_2(P)$ 定义为 $H_2(P) = -\\sum p_i \\log_2(p_i)$。代入换底公式：\n$$H_2(P) = -\\sum p_i \\frac{\\ln(p_i)}{\\ln(2)} = \\frac{1}{\\ln(2)} \\left( -\\sum p_i \\ln(p_i) \\right) = \\frac{H_e(P)}{\\ln(2)}$$\n这就是转换的基本理由：以比特为单位的熵等于以奈特为单位的熵除以常数 $\\ln(2)$。\n使用这个转换，我们求出分布 $p$ 以比特为单位的熵 $H_2(p)$：\n$$H_2(p) = \\frac{H_e(p)}{\\ln(2)} = \\frac{\\frac{2}{3} \\ln(2) + \\frac{1}{2} \\ln(3)}{\\ln(2)}$$\n$$H_2(p) = \\frac{2}{3} \\frac{\\ln(2)}{\\ln(2)} + \\frac{1}{2} \\frac{\\ln(3)}{\\ln(2)}$$\n再次使用换底公式，$\\frac{\\ln(3)}{\\ln(2)} = \\log_2(3)$。\n$$H_2(p) = \\frac{2}{3} + \\frac{1}{2} \\log_{2}(3)$$\n这就是分布 $p$ 以比特为单位的熵。\n\n现在，我们以比特为单位计算 3 个结果上的均匀分布 $u = (1/3, 1/3, 1/3)$ 的熵。设其为 $H_2(u)$。\n$$H_2(u) = -\\sum_{i=1}^{3} u_i \\log_{2}(u_i) = -\\sum_{i=1}^{3} \\frac{1}{3} \\log_{2}\\left(\\frac{1}{3}\\right)$$\n$$H_2(u) = -3 \\cdot \\frac{1}{3} \\log_{2}\\left(\\frac{1}{3}\\right) = -\\log_{2}\\left(\\frac{1}{3}\\right)$$\n使用对数恒等式 $\\log(1/x) = -\\log(x)$：\n$$H_2(u) = \\log_{2}(3)$$\n这证实了一般性结论，即 $N$ 个状态上的均匀分布的熵为 $\\log_{2}(N)$ 比特。\n\n最后，我们计算所要求的差值 $H(u) - H(p)$（以比特为单位）。这对应于 $H_2(u) - H_2(p)$。\n$$H_2(u) - H_2(p) = \\log_{2}(3) - \\left(\\frac{2}{3} + \\frac{1}{2} \\log_{2}(3)\\right)$$\n$$H_2(u) - H_2(p) = \\log_{2}(3) - \\frac{2}{3} - \\frac{1}{2} \\log_{2}(3)$$\n合并 $\\log_{2}(3)$ 项：\n$$H_2(u) - H_2(p) = \\left(1 - \\frac{1}{2}\\right) \\log_{2}(3) - \\frac{2}{3}$$\n$$H_2(u) - H_2(p) = \\frac{1}{2} \\log_{2}(3) - \\frac{2}{3}$$\n这就是熵差的最终、精确的闭式表达式。这个量也被称为分布 $p$ 的冗余度，或其相对于均匀分布的库尔贝克-莱布勒散度。",
            "answer": "$$\\boxed{\\frac{1}{2} \\log_{2}(3) - \\frac{2}{3}}$$"
        },
        {
            "introduction": "真实世界的复杂系统在时间中演化，产生数据流。本练习将你的技能从分析静态概率分布提升到评估动态过程的复杂性，核心是估算熵率——系统单位时间内产生新信息的速率。你将通过编程，从经验数据中估算块熵和熵率，并学习应用米勒-马多修正来处理有限样本带来的系统性偏差，这是将信息论应用于实际数据分析的关键一步。",
            "id": "4126703",
            "problem": "给定从一个平稳二元随机过程的单次长实现中采样的所有长度为 $2$ 和 $3$ 的二元块的经验计数。您的任务是使用一个直接从香农熵和平稳过程熵率的基本定义中导出的插件估计量来估计熵率，然后使用从渐近偏差分析中导出的有原则的校正方法来量化和解释有限样本偏差。\n\n从以下基本依据出发：\n- 对于有限集 $\\mathcal{X}$ 上的离散分布 $P$，香农熵定义为 $H(P) = -\\sum_{x \\in \\mathcal{X}} p(x) \\log_2 p(x)$。\n- 对于有限字母表上的平稳随机过程 $\\{X_t\\}_{t \\in \\mathbb{Z}}$，熵率定义为 $h = \\lim_{L \\to \\infty} H(X_1^L) - H(X_1^{L-1})$，其中 $X_1^L$ 表示长度为 $L$ 的块，$H(X_1^L)$ 是该块分布的香农熵。\n- 插件估计量用观测计数形成的经验块分布替代真实的块分布，并从相应的经验块熵构建熵率估计量。\n- 经验块熵必须使用极限约定 $\\lim_{p \\to 0^+} p \\log p = 0$ 来处理零概率事件，以避免未定义的项。\n\n基于这些依据，设计一个程序，该程序：\n1. 对于二元字母表 $\\{0,1\\}$，根据提供的计数计算长度为 $2$ 和长度为 $3$ 的块的经验块概率。长度为 $2$ 的块顺序固定为 $[00,01,10,11]$，长度为 $3$ 的块顺序固定为 $[000,001,010,011,100,101,110,111]$。\n2. 计算长度为 $2$ 和 $3$ 的经验块熵（单位：比特）。\n3. 从这些经验块熵构建插件熵率估计。\n4. 使用分别应用于长度为 $2$ 和长度为 $3$ 的经验块熵的 Miller-Madow 校正来量化有限样本偏差。对于具有 $N$ 个样本和 $K$ 个观测类别（非零计数）的离散分布，校正后的熵（单位：比特）为 $H_{\\text{MM}} = H_{\\text{plug-in}} + \\frac{K-1}{2N \\log 2}$，其中 $\\log$ 表示自然对数。使用此校正生成一个偏差调整后的熵率估计，并为插件熵率估计量提供隐含的偏差校正。\n5. 将所有熵和熵率以比特为单位表示为浮点数。\n\n科学现实性说明：尽管通过滑动窗口形成的块样本对于有限的 $L$ 是相关的，但 Miller-Madow 校正为离散分布的熵提供了一种有原则的、广泛使用的一阶偏差调整。在重叠块的情况下，这种校正是近似的，您应谨慎解释它。\n\n您的程序必须使用以下测试套件。每个测试用例提供两个列表：长度为 $2$ 的块的经验计数和长度为 $3$ 的块的经验计数，按上述规定排序。\n\n测试套件（五个案例）：\n- 案例 A（近似独立的公平硬币）：\n  - 长度为 $2$ 的计数：$[2500,2500,2500,2500]$\n  - 长度为 $3$ 的计数：$[1250,1250,1250,1250,1250,1250,1250,1250]$\n- 案例 B（近似确定性的交替序列 $0101\\ldots$）：\n  - 长度为 $2$ 的计数：$[0,5000,5000,0]$\n  - 长度为 $3$ 的计数：$[0,2500,0,0,0,2500,0,0]$\n- 案例 C（强持续性的类马尔可夫二元行为）：\n  - 长度为 $2$ 的计数：$[4500,500,500,4500]$\n  - 长度为 $3$ 的计数：$[4000,500,250,250,250,250,500,4000]$\n- 案例 D（混有零的小样本）：\n  - 长度为 $2$ 的计数：$[4,1,1,4]$\n  - 长度为 $3$ 的计数：$[3,0,1,0,1,0,0,3]$\n- 案例 E（具有极端偏斜的近确定性）：\n  - 长度为 $2$ 的计数：$[9,0,0,1]$\n  - 长度为 $3$ 的计数：$[9,0,0,0,0,0,0,1]$\n\n输出规范：\n- 对于每个测试用例，生成一个包含三个浮点数的列表：插件熵率估计（单位：比特），使用 Miller-Madow 校正的偏差调整后熵率估计（单位：比特），以及隐含的偏差校正（偏差调整后估计减去插件估计）。\n- 您的程序应生成单行输出，其中包含五个案例的结果，格式为方括号括起来的列表的逗号分隔列表，每个浮点数四舍五入到六位小数，例如：`[[hA_plugin,hA_MM,hA_corr],[hB_plugin,hB_MM,hB_corr],...]`。\n\n不需要物理单位或角度。熵必须以比特表示。不得使用百分比；任何比例在适用时必须表示为小数。",
            "solution": "该问题是有效的。它在科学上基于信息论的原理，定义清晰，解题路径唯一，表述客观。解决问题所需的所有数据和常数均已提供。\n\n任务是从经验块计数中估计一个平稳二元随机过程的熵率。这将通过三个主要步骤完成：\n1.  基于长度为 $2$ 和长度为 $3$ 的块的经验熵，计算熵率的插件估计。\n2.  对经验块熵应用 Miller-Madow 偏差校正，以解决有限样本效应。\n3.  从校正后的块熵构建偏差调整后的熵率估计，并量化总校正量。\n\n设 $\\{X_t\\}$ 为一个平稳二元随机过程。\n\n**1. 插件熵率估计**\n\n一个平稳过程的熵率 $h$ 由以下极限定义：\n$$h = \\lim_{L \\to \\infty} h_L = \\lim_{L \\to \\infty} [H(X_1^L) - H(X_1^{L-1})]$$\n其中 $X_1^L$ 表示一个由 $L$ 个连续变量 $(X_1, X_2, \\ldots, X_L)$ 组成的块，$H(X_1^L)$ 是其香non熵。在实践中，我们通过在较小的块长度处截断此极限来从有限数据中估计 $h$，本例中使用 $L=3$。因此，熵率的估计量为 $h \\approx h_3 = H(X_1^3) - H(X_1^2)$。\n\n我们被给予了每个长度为 $L \\in \\{2, 3\\}$ 的二元块 $w$ 的经验计数 $c_L(w)$。首先，我们计算观测到的长度为 $L$ 的块的总数：\n$$N_L = \\sum_{w \\in \\{0,1\\}^L} c_L(w)$$\n那么，块 $w$ 的经验概率（或相对频率）为：\n$$\\hat{p}_L(w) = \\frac{c_L(w)}{N_L}$$\n块熵的插件估计量 $\\hat{H}_L$ 是这个经验分布的香农熵：\n$$\\hat{H}_L = -\\sum_{w \\in \\{0,1\\}^L} \\hat{p}_L(w) \\log_2 \\hat{p}_L(w)$$\n其中 $\\hat{p}_L(w) = 0$ 的项对总和没有贡献，遵循约定 $\\lim_{p \\to 0^+} p \\log p = 0$。\n\n使用这些 $L=2$ 和 $L=3$ 的经验块熵，熵率的插件估计量为：\n$$\\hat{h}_{\\text{plugin}} = \\hat{H}_3 - \\hat{H}_2$$\n\n**2. 有限样本偏差校正**\n\n已知插件估计量 $\\hat{H}_L$ 是有偏的。它会系统性地低估真实熵，尤其是在小样本量 $N_L$ 的情况下。对这种偏差的一阶校正由 Miller-Madow 公式给出。对于一个包含 $|\\mathcal{X}_L|$ 种可能块的字母表，其中 $K_L$ 种在样本中被观测到（即具有非零计数），偏差近似为：\n$$\\text{Bias}(\\hat{H}_L) \\approx -\\frac{K_L - 1}{2N_L \\ln 2}$$\n分母中包含 $\\ln 2$ 是为了将以奈特（nats）为自然单位的偏差转换为比特（bits），这与我们使用 $\\log_2$ 计算熵是一致的。因此，校正后的熵 $\\hat{H}_{L, \\text{MM}}$ 为：\n$$\\hat{H}_{L, \\text{MM}} = \\hat{H}_L + \\frac{K_L - 1}{2N_L \\ln 2}$$\n此校正必须分别应用于 $\\hat{H}_2$ 和 $\\hat{H}_3$，使用它们各自的样本量（$N_2$、$N_3$）和观测到的块类型数（$K_2$、$K_3$）。\n\n**3. 偏差调整后的熵率和隐含校正**\n\n偏差调整后的熵率估计是通过取校正后块熵的差来构建的：\n$$\\hat{h}_{\\text{MM}} = \\hat{H}_{3, \\text{MM}} - \\hat{H}_{2, \\text{MM}}$$\n代入校正后熵的表达式：\n$$\\hat{h}_{\\text{MM}} = \\left(\\hat{H}_3 + \\frac{K_3 - 1}{2N_3 \\ln 2}\\right) - \\left(\\hat{H}_2 + \\frac{K_2 - 1}{2N_2 \\ln 2}\\right)$$\n熵率估计的隐含总校正量 $\\hat{h}_{\\text{corr}}$ 是调整后估计与插件估计之间的差：\n$$\\hat{h}_{\\text{corr}} = \\hat{h}_{\\text{MM}} - \\hat{h}_{\\text{plugin}}$$\n这可以简化为各个偏差校正量之差：\n$$\\hat{h}_{\\text{corr}} = \\left(\\frac{K_3 - 1}{2N_3 \\ln 2}\\right) - \\left(\\frac{K_2 - 1}{2N_2 \\ln 2}\\right)$$\n\n程序将为每个提供的测试用例实现这一系列计算。它将首先计算 $\\hat{H}_2$ 和 $\\hat{H}_3$，从中导出 $\\hat{h}_{\\text{plugin}}$。然后，它将计算各自的 Miller-Madow 校正以找到 $\\hat{H}_{2, \\text{MM}}$ 和 $\\hat{H}_{2, \\text{MM}}$，从而得到 $\\hat{h}_{\\text{MM}}$。最后，它将计算差值 $\\hat{h}_{\\text{corr}}$。对于每个案例，将返回这三个量（$\\hat{h}_{\\text{plugin}}$、$\\hat{h}_{\\text{MM}}$、$\\hat{h}_{\\text{corr}}$）。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes plug-in and bias-corrected entropy rate estimates for a binary process.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (approximately independent fair coin)\n        (\n            [2500, 2500, 2500, 2500],\n            [1250, 1250, 1250, 1250, 1250, 1250, 1250, 1250]\n        ),\n        # Case B: (approximately deterministic alternating sequence 0101...)\n        (\n            [0, 5000, 5000, 0],\n            [0, 2500, 0, 0, 0, 2500, 0, 0]\n        ),\n        # Case C: (strongly persistent binary Markov-like behavior)\n        (\n            [4500, 500, 500, 4500],\n            [4000, 500, 250, 250, 250, 250, 500, 4000]\n        ),\n        # Case D: (small-sample mixed with zeros)\n        (\n            [4, 1, 1, 4],\n            [3, 0, 1, 0, 1, 0, 0, 3]\n        ),\n        # Case E: (nearly deterministic with extreme skew)\n        (\n            [9, 0, 0, 1],\n            [9, 0, 0, 0, 0, 0, 0, 1]\n        )\n    ]\n\n    def compute_metrics(counts):\n        \"\"\"\n        Computes empirical entropy and Miller-Madow correction parameters.\n\n        Args:\n            counts (np.ndarray): Array of empirical counts for blocks.\n\n        Returns:\n            tuple: (empirical_entropy, num_samples, num_observed_categories)\n        \"\"\"\n        counts = np.array(counts, dtype=float)\n        num_samples = np.sum(counts)\n\n        if num_samples == 0:\n            return 0.0, 0, 0\n\n        # Non-zero counts and their corresponding probabilities\n        non_zero_counts = counts[counts > 0]\n        probs = non_zero_counts / num_samples\n\n        # Empirical entropy (plug-in)\n        empirical_entropy = -np.sum(probs * np.log2(probs))\n\n        # Number of observed categories (non-zero counts)\n        num_observed_categories = len(non_zero_counts)\n\n        return empirical_entropy, num_samples, num_observed_categories\n\n    results = []\n    for counts2, counts3 in test_cases:\n        # 1. Compute metrics for L=2 and L=3 blocks\n        H2, N2, K2 = compute_metrics(counts2)\n        H3, N3, K3 = compute_metrics(counts3)\n\n        # 2. Compute plug-in entropy rate estimate\n        h_plugin = H3 - H2\n\n        # 3. Compute Miller-Madow bias corrections for H2 and H3\n        bias_H2 = 0.0\n        if N2 > 0 and K2 > 1:\n            bias_H2 = (K2 - 1) / (2 * N2 * np.log(2))\n\n        bias_H3 = 0.0\n        if N3 > 0 and K3 > 1:\n            bias_H3 = (K3 - 1) / (2 * N3 * np.log(2))\n\n        # 4. Compute bias-adjusted entropies and the resulting entropy rate\n        H2_mm = H2 + bias_H2\n        H3_mm = H3 + bias_H3\n        h_mm = H3_mm - H2_mm\n\n        # 5. Compute the implied correction on the entropy rate estimate\n        h_corr = h_mm - h_plugin\n        \n        results.append([h_plugin, h_mm, h_corr])\n\n    # Format the output string as a comma-separated list of lists,\n    # with each float rounded to six decimal places.\n    formatted_sublists = []\n    for sublist in results:\n        formatted_numbers = [f\"{num:.6f}\" for num in sublist]\n        formatted_sublists.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output = f\"[{','.join(formatted_sublists)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "除了统计上的随机性，另一种衡量复杂性的深刻思想是算法复杂性，即描述一个对象所需的最短程序长度。本练习将带你探索这一理论的实践应用，通过编程实现经典的Lempel-Ziv（LZ76）解析算法，并与通用的DEFLATE压缩算法进行比较。通过对一系列具有不同结构（从高度有序到伪随机）的字符串进行分析，你将亲身体验如何使用这些可计算的代理指标来近似不可计算的柯氏复杂性。",
            "id": "4126693",
            "problem": "在此任务中，您需要实现并比较在复杂自适应系统背景下，有限二进制字符串算法复杂度的两种可计算代理：Lempel–Ziv $1976$ (LZ76) 解析复杂度和通过标准通用压缩器获得的归一化压缩长度。其目的是在一个受控的测试套件上，根据作为复杂度度量的熵率，经验性地展示这两种代理在结构规律性不同的字符串上的行为。\n\n从以下基本基础出发：\n- 算法（Kolmogorov）复杂度（KC）是指输出给定字符串的最短程序的长度。该复杂度是不可计算的，但可以通过通用压缩和通用解析方案从上方进行近似。\n- 对于大小为 $b$ 的有限字母表上的平稳遍历信源，当 Lempel–Ziv 增量解析复杂度 $C_{LZ}(s)$ 通过 $\\log_b n$（其中 $n = |s|$）进行适当归一化后，几乎必然收敛到信源的熵率（以 $\\log_b$ 为单位）；类似地，通用压缩器的每符号压缩长度依概率收敛到熵率。\n\n需要实现的定义：\n1) 对于长度为 $n$ 的有限二进制字符串 $s$，Lempel–Ziv $1976$ 解析复杂度 $C_{LZ}(s)$ 定义为通过增量解析获得的短语数量。该解析过程从左到右进行，在每一步选择最短的下一个短语 $s[i{:}j]$，该短语在已解析的前缀 $s[0{:}j-1]$ 的任何地方都未作为子串出现过。形式上，初始化 $i \\leftarrow 0$, $C_{LZ} \\leftarrow 0$。当 $i < n$ 时，选择最小的 $j > i$ 使得 $s[i{:}j]$ 不是 $s[0{:}j-1]$ 的子串，设置 $C_{LZ} \\leftarrow C_{LZ} + 1$，并更新 $i \\leftarrow j$。如果不存在这样的 $j \\le n$，则将 $j \\leftarrow n$ 作为最后一个短语。\n2) 归一化的 Lempel–Ziv 复杂度为\n$$\nc_{LZ}(s) \\equiv \n\\begin{cases}\n0, & n \\le 1, \\\\\n\\displaystyle \\frac{C_{LZ}(s)\\,\\log_2 n}{n}, & n \\ge 2.\n\\end{cases}\n$$\n该估计量是无量纲的，并且在广泛条件下，对于二进制信源，它会收敛到以每符号比特为单位的熵率。\n\n3) 设 $Z$ 是 DEFLATE 算法的一个固定的、确定性的实现，该算法操作于字节序列上（为具体起见，使用标准的 zlib 实现）。定义归一化压缩长度\n$$\nc_{zip}(s) \\equiv \n\\begin{cases}\n0, & n = 0, \\\\\n\\displaystyle \\frac{8\\,|Z(\\mathrm{pack}(s))|}{n}, & n \\ge 1,\n\\end{cases}\n$$\n其中 $\\mathrm{pack}(s)$ 通过取 $s$ 的连续 $8$ 比特块（每个字节内最高有效位在前），并在必要时将最后一个块在右侧用零填充以补全一个字节，从而将二进制字符串 $s$ 映射为字节序列。操作符 $|\\cdot|$ 表示以字节为单位的长度。归一化后得到一个无量纲的每比特压缩长度。\n\n任务：\n- 实现如上文所定义的精确 Lempel–Ziv $1976$ 增量解析计数 $C_{LZ}(s)$，并计算 $c_{LZ}(s)$。\n- 实现 $\\mathrm{pack}(s)$，要求每个字节内最高有效位在前，并按规定对最后一个字节进行右侧零填充。\n- 使用具有固定压缩级别的标准 zlib DEFLATE 压缩器，计算 $c_{zip}(s)$。\n- 对于下方的每个测试用例，按此精确顺序返回三元组 $[c_{LZ}(s), c_{zip}(s), c_{zip}(s) - c_{LZ}(s)]$。\n\n测试套件（按此顺序提供结果）：\n- 情况 A（高度规则）：$s_A$ 是由 $n = 512$ 个零组成的字符串。\n- 情况 B（周期为2的规则）：$s_B$ 是无限周期字符串 $\\dots 010101 \\dots$ 的长度为512的前缀，即 $s_B = (01)^{256}$。\n- 情况 C（通过线性同余生成器生成的伪随机）：$s_C$ 由以下递推关系构造\n$$\nx_{0} = 1,\\quad x_{k+1} \\equiv (1664525 \\cdot x_k + 1013904223) \\bmod 2^{32},\\quad b_k \\equiv \\left\\lfloor \\frac{x_k}{2^{31}} \\right\\rfloor \\bmod 2,\n$$\n且 $s_C = b_0 b_1 \\dots b_{511}$ 的长度为 $n = 512$。\n- 情况 D（Thue–Morse 序列）：$s_D$ 是长度为512的前缀，定义为 $b_i$ 等于 $i$ 的二进制展开中1的数量的奇偶性（即 $b_i \\equiv \\left(\\sum_j \\mathrm{bit}_j(i)\\right) \\bmod 2$），其中 $i = 0,1,\\dots,511$；设置 $s_D = b_0 b_1 \\dots b_{511}$。\n- 情况 E（边界情况）：$s_E$ 是长度为 $n = 0$ 的空字符串。\n- 情况 F（块重复）：$s_F$ 的获取方式是，首先使用与情况 C 相同的线性同余生成器，但初始种子为 $x_0 = 12345$，并采用相同的更新和比特提取规则，生成一个长度为64的块 $u$，然后将 $u$ 精确重复 $8$ 次，得到一个长度为 $n = 512$ 的字符串。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素依次是A到F六种情况下对应的三元组列表 $[c_{LZ}(s), c_{zip}(s), c_{zip}(s) - c_{LZ}(s)]$。例如，一个语法正确的输出形状是\n$[[x_{A},y_{A},y_{A}-x_{A}],[x_{B},y_{B},y_{B}-x_{B}],\\dots,[x_{F},y_{F},y_{F}-x_{F}]]$,\n其中每个 $x_{\\cdot}$ 和 $y_{\\cdot}$ 都是一个浮点数。这些量是无量纲的；不涉及物理单位。不使用角度。不得使用百分比；所有比率都应以十进制浮点数报告。",
            "solution": "该问题提出了一个任务，要求实现并比较有限二进制字符串算法复杂度的两种可计算近似方法：Lempel-Ziv 1976 解析复杂度和通过 DEFLATE 算法得到的归一化压缩长度。比较将在一个包含六个具有不同结构特性的测试字符串的套件上进行。\n\n该问题被认为是有效的，因为它在科学上基于信息论和复杂性的既定原则，定义精确且可形式化，问题陈述良好，并且其语言和要求是客观的。为获得唯一解所需的所有数据和定义均已提供。\n\n解决方案通过系统地实现所需的组件，并将其应用于指定的测试用例来进行。\n\n首先，我们处理六个测试字符串（表示为 $s_A$ 到 $s_F$）的生成。设 $n$ 为字符串 $s$ 的长度。\n\n-   情况 A（高度规则）：$s_A$ 是一个由 $n=512$ 个零组成的字符串，$s_A = 0^{512}$。\n-   情况 B（周期为2的规则）：$s_B$ 是周期性字符串 $(01)^{256}$，长度为 $n=512$。\n-   情况 C（伪随机）：$s_C$ 是一个长度为 $n=512$ 的二进制字符串，$s_C = b_0 b_1 \\dots b_{511}$，使用线性同余生成器（LCG）生成。状态 $x_k \\in \\mathbb{Z}_{2^{32}}$ 通过递推关系 $x_{k+1} \\equiv (a \\cdot x_k + c) \\bmod M$ 更新，初始种子为 $x_0 = 1$，参数为 $a = 1664525$，$c = 1013904223$，$M = 2^{32}$。第 $k$ 个比特 $b_k$ 是 $x_k$ 的最高有效位，通过 $b_k = (x_k \\gg 31) & 1$ 提取。\n-   情况 D（Thue–Morse 序列）：$s_D$ 是一个长度为 $n=512$ 的二进制字符串，$s_D = b_0 b_1 \\dots b_{511}$。比特 $b_i$ 由索引 $i$ 的二进制表示中1的数量的奇偶性确定。形式上，$b_i \\equiv (\\sum_j \\mathrm{bit}_j(i)) \\bmod 2$，其中 $\\mathrm{bit}_j(i)$ 是 $i$ 的第 $j$ 个比特。\n-   情况 E（边界情况）：$s_E$ 是空字符串，长度为 $n=0$。\n-   情况 F（块重复）：$s_F$ 是一个长度为 $n=512$ 的字符串，通过将一个64比特的块 $u$ 重复8次构成。块 $u$ 本身使用与情况 C 中相同的 LCG 方法生成，但初始种子不同，为 $x_0 = 12345$。\n\n接下来，我们实现两种复杂度度量。\n\n1.  **Lempel-Ziv 1976 解析复杂度 ($C_{LZ}(s)$)**\n    问题定义了一个特定的增量解析算法。对于一个长度为 $n$ 的字符串 $s$，我们从一个长度为 $i=0$ 的已解析字符串和一个复杂度计数 $C_{LZ}=0$ 开始。在一个循环中，当 $i < n$ 时，我们增加 $C_{LZ}$ 并找到最小的整数 $j > i$，使得候选短语 $s[i{:}j]$ 不是前缀 $s[0{:}j-1]$ 的子串。必须注意，这个前缀 $s[0{:}j-1]$ 包含了已经解析的字符串部分 $s[0{:}i]$，以及正在构建的部分短语 $s[i{:}j-1]$。这个定义虽然不寻常，但却是无歧义的。如果找到了这样一个 $j \\le n$，解析器通过设置 $i \\leftarrow j$ 前进到该位置。如果遍历所有可能的 $j$（从 $i+1$ 到 $n$）的循环完成而没有找到这样的短语（即，每个候选短语 $s[i{:}j]$ 都在其对应的前缀 $s[0{:}j-1]$ 中被找到），则字符串的剩余部分 $s[i{:}n]$ 被视为最后一个短语，并通过设置 $i \\leftarrow n$ 终止过程。\n\n    然后计算归一化的 Lempel-Ziv 复杂度 $c_{LZ}(s)$。\n    $$\n    c_{LZ}(s) \\equiv \n    \\begin{cases}\n    0, & n \\le 1, \\\\\n    \\displaystyle \\frac{C_{LZ}(s)\\,\\log_2 n}{n}, & n \\ge 2.\n    \\end{cases}\n    $$\n    对于 $n=512$，这简化为 $c_{LZ}(s) = C_{LZ}(s) \\cdot (\\log_2 512) / 512 = 9 \\cdot C_{LZ}(s) / 512$。\n\n\n2.  **归一化压缩长度 ($c_{zip}(s)$)**\n    该度量需要两个步骤：将二进制字符串打包成字节序列，然后对其进行压缩。\n    \n    打包函数 $\\mathrm{pack}(s)$ 将二进制字符串 $s$ 转换为字节序列。字符串以8比特的块进行处理。每个块被解释为一个字节，最高有效位在前。如果 $s$ 的长度 $n$ 不是8的倍数，则最后的非完整块将在右侧用零填充，以形成一个完整的8比特字节。\n    \n    得到的字节序列 $\\mathrm{pack}(s)$ 随后使用一个固定的、确定性的 DEFLATE 实现进行压缩。我们使用 Python 的标准 `zlib.compress` 函数及其默认压缩级别，这提供了所要求的一致实现。\n    \n    归一化的压缩长度 $c_{zip}(s)$ 定义为：\n    $$\n    c_{zip}(s) \\equiv \n    \\begin{cases}\n    0, & n = 0, \\\\\n    \\displaystyle \\frac{8\\,|Z(\\mathrm{pack}(s))|}{n}, & n \\ge 1,\n    \\end{cases}\n    $$\n    其中 $|Z(\\mathrm{pack}(s))|$ 是压缩数据的字节长度。因子8将此长度从字节转换为比特，从而得到一个以比特/比特为单位的无量纲复杂度度量。\n\n最后，对于每个测试用例字符串 $s_k$（$k \\in \\{A, B, C, D, E, F\\}$），我们计算复杂度值对 $(c_{LZ}(s_k), c_{zip}(s_k))$ 及其差值 $c_{zip}(s_k) - c_{LZ}(s_k)$。然后将结果按指定顺序聚合成一个三元组列表 $[c_{LZ}(s_k), c_{zip}(s_k), c_{zip}(s_k) - c_{LZ}(s_k)]$。\n\n该实现将这些步骤封装到一个单独的程序中，该程序生成每个字符串，应用复杂度算法，并按要求格式化输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport zlib\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the generation of test strings,\n    computation of complexity measures, and final output formatting.\n    \"\"\"\n\n    def compute_CLZ(s: str) -> int:\n        \"\"\"\n        Computes the Lempel-Ziv 1976 parsing complexity C_LZ(s)\n        based on the exact, literal definition provided in the problem.\n        \"\"\"\n        n = len(s)\n        if n == 0:\n            return 0\n        \n        i = 0\n        c_lz = 0\n        while i  n:\n            c_lz += 1\n            # Find the smallest j > i such that s[i:j] is not a substring of s[0:j-1]\n            best_j = -1\n            for j_candidate in range(i + 1, n + 1):\n                phrase = s[i:j_candidate]\n                context = s[0:j_candidate - 1]\n                if phrase not in context:\n                    best_j = j_candidate\n                    break  # Found the shortest new phrase\n            \n            if best_j != -1:\n                # A new phrase was found, advance i\n                i = best_j\n            else:\n                # No such phrase exists, the rest of the string is the last phrase\n                i = n\n        return c_lz\n\n    def compute_c_LZ(s: str) -> float:\n        \"\"\"Computes the normalized Lempel-Ziv complexity c_LZ(s).\"\"\"\n        n = len(s)\n        if n = 1:\n            return 0.0\n        \n        clz_count = compute_CLZ(s)\n        return (clz_count * np.log2(n)) / n\n\n    def pack_string(s: str) -> bytes:\n        \"\"\"Packs a binary string into a byte sequence with MSB first and zero padding.\"\"\"\n        n = len(s)\n        if n == 0:\n            return b''\n        \n        byte_list = []\n        for i in range(0, n, 8):\n            chunk = s[i:i+8]\n            # Pad the final chunk with zeros on the right\n            if len(chunk)  8:\n                chunk = chunk.ljust(8, '0')\n            byte_val = int(chunk, 2)\n            byte_list.append(byte_val)\n        \n        return bytes(byte_list)\n\n    def compute_c_zip(s: str) -> float:\n        \"\"\"Computes the normalized compressed length c_zip(s).\"\"\"\n        n = len(s)\n        if n == 0:\n            return 0.0\n\n        packed_data = pack_string(s)\n        # Use zlib with default, fixed compression level for determinism\n        compressed_data = zlib.compress(packed_data)\n        compressed_len_bytes = len(compressed_data)\n        \n        return (8 * compressed_len_bytes) / n\n\n    def generate_lcg_string(length: int, seed: int) -> str:\n        \"\"\"Generates a pseudo-random binary string using a linear congruential generator.\"\"\"\n        a = 1664525\n        c = 1013904223\n        m = 2**32\n        \n        bits = []\n        x = seed\n        for _ in range(length):\n            # Extract the most significant bit\n            bit = (x >> 31)  1\n            bits.append(str(bit))\n            # Update the LCG state\n            x = (a * x + c) % m\n        return \"\".join(bits)\n\n    # --- Generate Test Case Strings ---\n\n    n_val = 512\n    # Case A: Highly regular (all zeros)\n    s_A = '0' * n_val\n    \n    # Case B: Period-2 regular\n    s_B = '01' * (n_val // 2)\n\n    # Case C: Pseudo-random by LCG\n    s_C = generate_lcg_string(n_val, seed=1)\n\n    # Case D: Thue-Morse sequence\n    thue_morse_bits = [(bin(i).count('1') % 2) for i in range(n_val)]\n    s_D = \"\".join(map(str, thue_morse_bits))\n\n    # Case E: Empty string\n    s_E = \"\"\n\n    # Case F: Block-repeat\n    block_u = generate_lcg_string(length=64, seed=12345)\n    s_F = block_u * 8\n    \n    test_cases_strings = [s_A, s_B, s_C, s_D, s_E, s_F]\n    \n    results = []\n    for s in test_cases_strings:\n        c_lz_val = compute_c_LZ(s)\n        c_zip_val = compute_c_zip(s)\n        diff = c_zip_val - c_lz_val\n        results.append([c_lz_val, c_zip_val, diff])\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list includes spaces, so we custom format it.\n    formatted_results = []\n    for res_triple in results:\n        # Format each triple as a string like \"[num1,num2,num3]\"\n        formatted_triple = f\"[{res_triple[0]},{res_triple[1]},{res_triple[2]}]\"\n        formatted_results.append(formatted_triple)\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}