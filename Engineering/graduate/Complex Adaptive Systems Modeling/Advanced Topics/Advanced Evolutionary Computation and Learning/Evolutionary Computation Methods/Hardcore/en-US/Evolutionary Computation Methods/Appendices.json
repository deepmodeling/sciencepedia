{
    "hands_on_practices": [
        {
            "introduction": "Mutation is a fundamental source of variation in evolutionary algorithms, acting as a primary driver for exploration of the search space. While its outcome on a single individual is stochastic, its average effect across a population is predictable and crucial for tuning the algorithm's behavior. This exercise  builds a foundational skill by using probability theory to derive the expected amount of change introduced by a bit-flip mutation operator, a key step in the theoretical analysis of genetic algorithms.",
            "id": "4122025",
            "problem": "Consider a binary-encoded genotype represented by a string of length $L$ over the alphabet $\\{0,1\\}$. A bit-flip mutation operator acts independently on each position: for each index $i \\in \\{1,2,\\ldots,L\\}$, the bit at position $i$ is flipped with probability $p$ and left unchanged with probability $1-p$. Let the Hamming distance $d_{H}$ between a parent string and its mutated offspring be defined as the number of positions at which the two strings differ.\n\nStarting solely from the definition of the Hamming distance, the interpretation of mutation as a set of Bernoulli trials, and the definition of expected value in probability theory, derive a general expression for the expected Hamming distance $\\mathbb{E}[d_{H}]$ as a function of $p$ and $L$. Then evaluate this expression for $p=0.01$ and $L=100$. Provide your final numerical answer as an exact value with no rounding.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It presents a standard problem in the theory of evolutionary algorithms, drawing upon fundamental principles of probability theory. All terms are clearly defined, and sufficient information is provided to derive a unique solution. Therefore, the problem is valid.\n\nThe objective is to derive the expected Hamming distance, $\\mathbb{E}[d_{H}]$, between a parent binary string of length $L$ and its offspring after applying a bit-flip mutation operator. The mutation at each position is an independent event occurring with probability $p$.\n\nLet the parent string be $S = (s_1, s_2, \\ldots, s_L)$ and the offspring string be $S' = (s'_1, s'_2, \\ldots, s'_L)$, where $s_i, s'_i \\in \\{0, 1\\}$. The Hamming distance $d_H(S, S')$ is the number of positions $i$ for which $s_i \\neq s'_i$.\n\nThe core of the problem lies in recognizing that the mutation at each position is an independent Bernoulli trial. For each position $i \\in \\{1, 2, \\ldots, L\\}$, a bit flip occurs if and only if $s_i \\neq s'_i$. The probability of a flip is given as $p$.\n\nTo formally derive the expected value, we can define a set of indicator random variables. Let $X_i$ be an indicator random variable for the event that a bit flip occurs at position $i$. By definition:\n$$\nX_i =\n\\begin{cases}\n1 & \\text{if the bit at position } i \\text{ is flipped} \\\\\n0 & \\text{if the bit at position } i \\text{ is not flipped}\n\\end{cases}\n$$\nThe probability distribution for each $X_i$ is given by the problem statement:\n$$\nP(X_i = 1) = p\n$$\n$$\nP(X_i = 0) = 1-p\n$$\nEach $X_i$ is a Bernoulli random variable with parameter $p$. The expected value of an indicator random variable is the probability of the event it indicates. Using the formal definition of expected value for a discrete random variable:\n$$\n\\mathbb{E}[X_i] = \\sum_{k \\in \\{0,1\\}} k \\cdot P(X_i = k) = (1 \\cdot P(X_i=1)) + (0 \\cdot P(X_i=0)) = (1 \\cdot p) + (0 \\cdot (1-p)) = p\n$$\nThe Hamming distance, $d_H$, is the total number of positions at which the strings differ, which is equivalent to the total number of bit flips. Therefore, $d_H$ can be expressed as the sum of our indicator random variables:\n$$\nd_H = \\sum_{i=1}^{L} X_i\n$$\nWe seek the expected value of $d_H$, which is $\\mathbb{E}[d_H]$. A fundamental property of expectation is the linearity of expectation, which states that the expected value of a sum of random variables is the sum of their individual expected values. This property holds regardless of whether the variables are independent.\n$$\n\\mathbb{E}[d_H] = \\mathbb{E}\\left[\\sum_{i=1}^{L} X_i\\right] = \\sum_{i=1}^{L} \\mathbb{E}[X_i]\n$$\nWe have already determined that $\\mathbb{E}[X_i] = p$ for every position $i$. Since the probability of mutation $p$ is the same for all positions, each $\\mathbb{E}[X_i]$ has the same value. We are summing $L$ identical terms:\n$$\n\\mathbb{E}[d_H] = \\sum_{i=1}^{L} p = L \\cdot p\n$$\nThis is the general expression for the expected Hamming distance as a function of the string length $L$ and the mutation probability $p$.\n\nThe problem then requires us to evaluate this expression for the specific values $L=100$ and $p=0.01$. Substituting these values into our derived formula:\n$$\n\\mathbb{E}[d_H] = 100 \\times 0.01 = 1\n$$\nThus, for a string of length $100$ with a per-bit mutation probability of $0.01$, the expected number of differing bits between a parent and its offspring is $1$.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Selection is the engine of adaptation in evolutionary computation, determining which individuals contribute their genetic material to the next generation. The choice of a selection mechanism is a critical design decision, as it directly controls the selective pressure and the balance between exploration and exploitation. Through this practical exercise , you will calculate and compare the selection probabilities for several canonical methods, gaining a quantitative understanding of how they translate raw fitness scores into reproductive opportunities.",
            "id": "4122109",
            "problem": "In the study of Complex Adaptive Systems (CAS), Evolutionary Computation (EC) methods such as Genetic Algorithms (GA) rely on selection mechanisms that translate a population's fitness landscape into sampling probabilities for reproductive events. Consider a population of size $N=4$ with individuals $\\{x_1,x_2,x_3,x_4\\}$ having fitness values given by the vector $(2,2,4,8)$. Three canonical selection mechanisms are considered:\n\n1. Fitness-Proportionate Selection (also known as roulette-wheel selection): By definition, the probability of selecting individual $x_i$ is proportional to its fitness $f_i$, with normalization applied so that the probabilities sum to $1$.\n\n2. Linear Rank Selection (Bakerâ€™s scheme) with selective pressure parameter $s=2$: The selection mechanism operates on ranks rather than raw fitness. Individuals are ranked from worst to best, with ties resolved by assigning midranks (i.e., if two individuals occupy ranks $1$ and $2$, each receives rank $1.5$). The selection probabilities increase linearly with rank and are constrained so that the worst-ranked individual has selection probability $(2-s)/N$ and the best-ranked individual has selection probability $s/N$, with linear interpolation across ranks. Assume $1 \\leq s \\leq 2$ and use $s=2$.\n\n3. Tournament Selection with tournament size $t=3$: One tournament is formed by uniformly sampling $t$ distinct individuals without replacement from the population, and the individual with the highest fitness among the tournament participants is selected. If there is a tie for the highest fitness within the tournament, break ties uniformly at random among the tied individuals.\n\nStarting from the stated definitions and constraints on each selection mechanism, derive the selection probability assigned to each individual under each mechanism. Use the fixed order $(x_1,x_2,x_3,x_4)$ corresponding to fitness values $(2,2,4,8)$ for reporting. Express your final answer as a single row matrix using the LaTeX `pmatrix` environment, listing the twelve probabilities in the following order:\n- The four probabilities for fitness-proportionate selection,\n- followed by the four probabilities for linear rank selection with $s=2$,\n- followed by the four probabilities for tournament selection with $t=3$.\n\nNo rounding is required. There are no physical units to report.",
            "solution": "The problem statement will be validated against the established criteria before a solution is attempted.\n\n### Step 1: Extract Givens\n- Population size: $N=4$\n- Individuals: $\\{x_1, x_2, x_3, x_4\\}$\n- Fitness values: The vector of fitnesses is $(f_1, f_2, f_3, f_4) = (2, 2, 4, 8)$.\n- Mechanism 1 (Fitness-Proportionate Selection): The selection probability $P(x_i)$ for an individual $x_i$ is proportional to its fitness $f_i$, i.e., $P(x_i) \\propto f_i$.\n- Mechanism 2 (Linear Rank Selection): Baker's scheme is used with a selective pressure parameter $s=2$. Individuals are ranked from worst to best. Ties are resolved using midranks. The probability for the worst-ranked individual (rank $1$) is $(2-s)/N$ and for the best-ranked individual (rank $N$) is $s/N$. Probabilities are linearly interpolated for ranks between $1$ and $N$.\n- Mechanism 3 (Tournament Selection): The tournament size is $t=3$. A tournament consists of $t$ distinct individuals sampled uniformly without replacement. The individual with the highest fitness wins. Ties for the highest fitness are broken uniformly at random.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, being a standard exercise in the field of evolutionary computation. It is well-posed, with all necessary parameters ($N$, fitness values, $s$, $t$) and definitions (including tie-breaking rules) provided to determine a unique set of probabilities. The problem statement is objective and uses precise, unambiguous language. The setup is internally consistent and does not contain any contradictions or unrealistic conditions. Therefore, the problem is deemed valid.\n\n### Step 3: Derivation of Selection Probabilities\n\nThe selection probabilities for each of the three mechanisms are derived below for the individuals $\\{x_1, x_2, x_3, x_4\\}$ with fitnesses $(2, 2, 4, 8)$.\n\n**1. Fitness-Proportionate Selection**\n\nThe probability of selecting an individual $x_i$ is given by its fitness $f_i$ divided by the total fitness of the population, $F_{total}$.\n\nFirst, calculate the total fitness:\n$$F_{total} = \\sum_{i=1}^{N} f_i = 2 + 2 + 4 + 8 = 16$$\nThe selection probability for each individual $x_i$ is $P(x_i) = \\frac{f_i}{F_{total}}$.\n\n- For $x_1$ (fitness $f_1=2$):\n  $$P(x_1) = \\frac{2}{16} = \\frac{1}{8}$$\n- For $x_2$ (fitness $f_2=2$):\n  $$P(x_2) = \\frac{2}{16} = \\frac{1}{8}$$\n- For $x_3$ (fitness $f_3=4$):\n  $$P(x_3) = \\frac{4}{16} = \\frac{1}{4}$$\n- For $x_4$ (fitness $f_4=8$):\n  $$P(x_4) = \\frac{8}{16} = \\frac{1}{2}$$\n\nThe vector of probabilities for fitness-proportionate selection is $(\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{4}, \\frac{1}{2})$.\n\n**2. Linear Rank Selection**\n\nThis mechanism uses ranks instead of raw fitness values. First, we must rank the individuals from worst to best based on their fitness values $(2, 2, 4, 8)$.\n- The two individuals $x_1$ and $x_2$ have the lowest fitness of $2$. They are tied for ranks $1$ and $2$. The midrank is $\\frac{1+2}{2} = 1.5$. So, $\\text{rank}(x_1) = 1.5$ and $\\text{rank}(x_2) = 1.5$.\n- The individual $x_3$ has the next highest fitness of $4$ and is assigned rank $3$. So, $\\text{rank}(x_3) = 3$.\n- The individual $x_4$ has the highest fitness of $8$ and is assigned rank $4$. So, $\\text{rank}(x_4) = 4$.\nThe rank vector is $(1.5, 1.5, 3, 4)$.\n\nThe selection probability $P(R)$ is a linear function of the rank $R$. The function is determined by the probabilities for the worst possible rank (rank $1$) and the best possible rank (rank $N=4$).\n- Probability for rank $R=1$: $P(1) = \\frac{2-s}{N} = \\frac{2-2}{4} = 0$.\n- Probability for rank $R=4$: $P(4) = \\frac{s}{N} = \\frac{2}{4} = \\frac{1}{2}$.\n\nThe linear function $P(R) = mR + c$ passes through the points $(1, 0)$ and $(4, \\frac{1}{2})$.\nThe slope $m$ is $\\frac{P(4) - P(1)}{4 - 1} = \\frac{1/2 - 0}{3} = \\frac{1}{6}$.\nThe intercept $c$ can be found using the point $(1, 0)$: $0 = m(1) + c \\implies c = -m = -\\frac{1}{6}$.\nSo the probability function is $P(R) = \\frac{1}{6}R - \\frac{1}{6} = \\frac{R-1}{6}$.\n\nWe now apply this function to the specific ranks of our individuals:\n- For $x_1$ (rank $1.5$):\n  $$P(x_1) = P(1.5) = \\frac{1.5 - 1}{6} = \\frac{0.5}{6} = \\frac{1}{12}$$\n- For $x_2$ (rank $1.5$):\n  $$P(x_2) = P(1.5) = \\frac{1.5 - 1}{6} = \\frac{0.5}{6} = \\frac{1}{12}$$\n- For $x_3$ (rank $3$):\n  $$P(x_3) = P(3) = \\frac{3 - 1}{6} = \\frac{2}{6} = \\frac{1}{3}$$\n- For $x_4$ (rank $4$):\n  $$P(x_4) = P(4) = \\frac{4 - 1}{6} = \\frac{3}{6} = \\frac{1}{2}$$\n\nThe vector of probabilities for linear rank selection is $(\\frac{1}{12}, \\frac{1}{12}, \\frac{1}{3}, \\frac{1}{2})$.\n\n**3. Tournament Selection**\n\nIn tournament selection with size $t=3$ from a population of $N=4$, a tournament is formed by selecting $3$ distinct individuals. The number of possible distinct tournaments is given by the binomial coefficient $\\binom{N}{t}$:\n$$\\binom{4}{3} = \\frac{4!}{3!(4-3)!} = 4$$\nSince sampling is uniform, each of these $4$ possible tournaments has a probability of $\\frac{1}{4}$ of being selected. Let's list the tournaments and determine the winner of each. The fitnesses are $f=(2, 2, 4, 8)$ for $(x_1, x_2, x_3, x_4)$.\n\n- Tournament 1: $\\{x_1, x_2, x_3\\}$. Fitnesses are $(2, 2, 4)$. The winner is $x_3$ (highest fitness).\n- Tournament 2: $\\{x_1, x_2, x_4\\}$. Fitnesses are $(2, 2, 8)$. The winner is $x_4$.\n- Tournament 3: $\\{x_1, x_3, x_4\\}$. Fitnesses are $(2, 4, 8)$. The winner is $x_4$.\n- Tournament 4: $\\{x_2, x_3, x_4\\}$. Fitnesses are $(2, 4, 8)$. The winner is $x_4$.\n\nThe tie-breaking rule (uniform random choice among tied individuals) is not invoked, as there are no ties for the *highest* fitness in any of the possible tournaments.\n\nThe overall probability of an individual being selected is the sum of the probabilities of the tournaments in which it wins.\n- For $x_1$: Wins $0$ out of $4$ tournaments.\n  $$P(x_1) = 0 \\times \\frac{1}{4} = 0$$\n- For $x_2$: Wins $0$ out of $4$ tournaments.\n  $$P(x_2) = 0 \\times \\frac{1}{4} = 0$$\n- For $x_3$: Wins Tournament 1.\n  $$P(x_3) = 1 \\times \\frac{1}{4} = \\frac{1}{4}$$\n- For $x_4$: Wins Tournaments 2, 3, and 4.\n  $$P(x_4) = 3 \\times \\frac{1}{4} = \\frac{3}{4}$$\n\nThe vector of probabilities for tournament selection is $(0, 0, \\frac{1}{4}, \\frac{3}{4})$.\n\nFinally, the twelve probabilities are concatenated in the specified order to form the final answer.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{8} & \\frac{1}{8} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{12} & \\frac{1}{12} & \\frac{1}{3} & \\frac{1}{2} & 0 & 0 & \\frac{1}{4} & \\frac{3}{4} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Many real-world problems require optimizing multiple, often conflicting, objectives simultaneously. Algorithms like the Non-dominated Sorting Genetic Algorithm II (NSGA-II) are designed for this challenge, replacing simple fitness with a more nuanced selection process based on Pareto dominance and solution diversity. This problem  walks you through the core mechanics of NSGA-II's environmental selection, giving you practical experience with nondominated sorting and the crowding-distance metric used to preserve a well-spread Pareto front.",
            "id": "4122126",
            "problem": "Consider a small population in a Multi-Objective Evolutionary Algorithm (MOEA) context under the Non-dominated Sorting Genetic Algorithm II (NSGA-II). The two objective functions, denoted by $f_1$ and $f_2$, are both to be minimized. The environmental selection step must be carried out by performing nondominated sorting into Pareto fronts and, if a front cannot be entirely accommodated in the next generation due to capacity, applying the NSGA-II crowding-distance tie-break to prefer individuals with greater local objective-space sparsity.\n\nThe current population consists of $8$ individuals indexed by $i \\in \\{1,2,3,4,5,6,7,8\\}$ with objective vectors $(f_1, f_2)$ as follows:\n- Individual $i=1$: $(f_1, f_2) = (1.0, 8.0)$\n- Individual $i=2$: $(f_1, f_2) = (2.0, 6.0)$\n- Individual $i=3$: $(f_1, f_2) = (3.0, 4.0)$\n- Individual $i=4$: $(f_1, f_2) = (4.0, 3.5)$\n- Individual $i=5$: $(f_1, f_2) = (5.0, 3.2)$\n- Individual $i=6$: $(f_1, f_2) = (7.5, 2.0)$\n- Individual $i=7$: $(f_1, f_2) = (2.5, 7.0)$\n- Individual $i=8$: $(f_1, f_2) = (6.5, 2.8)$\n\nUse the formal definition of Pareto dominance for minimization to perform nondominated sorting into fronts $F_1, F_2, \\dots$ from first principles. If the highest-priority front that cannot be fully accommodated must be truncated to satisfy the next-generation capacity $N_{\\text{sel}}$, use the canonical NSGA-II crowding-distance ordering to break ties, where boundary individuals for each objective are treated as having maximal crowding distance.\n\nLet the next-generation capacity be $N_{\\text{sel}} = 5$. After completing the nondominated sorting and any necessary crowding-distance tie-breaks, let $\\mathcal{I}$ be the index set of the $N_{\\text{sel}}$ selected individuals. Report the single scalar quantity\n$$\nT = \\sum_{i \\in \\mathcal{I}} i.\n$$\nExpress $T$ as an exact integer. No rounding is required, and no units are involved.",
            "solution": "The problem is evaluated as valid. It is scientifically grounded in the established theory of evolutionary computation, specifically the NSGA-II algorithm. The problem is well-posed, with a complete and consistent set of data and a clearly defined, objective question that leads to a unique, verifiable answer. All terms are standard within the field.\n\nThe problem requires the selection of $N_{\\text{sel}} = 5$ individuals from a population of $8$ based on the environmental selection mechanism of the NSGA-II algorithm, which prioritizes solutions by Pareto front rank and uses crowding distance as a tie-breaker within a front.\n\nThe population consists of $8$ individuals, with their objective vectors $(f_1, f_2)$ given, where both objectives are to be minimized.\n- Individual $1$: $(1.0, 8.0)$\n- Individual $2$: $(2.0, 6.0)$\n- Individual $3$: $(3.0, 4.0)$\n- Individual $4$: $(4.0, 3.5)$\n- Individual $5$: $(5.0, 3.2)$\n- Individual $6$: $(7.5, 2.0)$\n- Individual $7$: $(2.5, 7.0)$\n- Individual $8$: $(6.5, 2.8)$\n\nLet $\\mathbf{v}_i = (f_{1,i}, f_{2,i})$ be the objective vector for individual $i$. For minimization, an individual $i$ Pareto dominates individual $j$ (denoted $\\mathbf{v}_i \\prec \\mathbf{v}_j$) if $f_{1,i} \\le f_{1,j}$ and $f_{2,i} \\le f_{2,j}$, with at least one inequality being strict.\n\nThe first step is to perform nondominated sorting to partition the population into Pareto fronts $F_1, F_2, \\dots$. An individual is in the first front, $F_1$, if it is not dominated by any other individual in the population.\n\nWe perform pairwise comparisons to determine dominance relationships:\n- Individual $2$ with $\\mathbf{v}_2=(2.0, 6.0)$ dominates individual $7$ with $\\mathbf{v}_7=(2.5, 7.0)$, because $2.0 < 2.5$ and $6.0 < 7.0$.\n- No other dominance relationships exist among the given $8$ individuals. For any other pair of individuals $(i, j)$, neither $\\mathbf{v}_i \\prec \\mathbf{v}_j$ nor $\\mathbf{v}_j \\prec \\mathbf{v}_i$ holds.\n\nThe domination count, $n_i$, for each individual $i$ is the number of individuals that dominate it.\n- $n_7 = 1$ (dominated by individual $2$).\n- For all other individuals $i \\in \\{1, 2, 3, 4, 5, 6, 8\\}$, $n_i = 0$.\n\nThe first Pareto front, $F_1$, consists of all individuals with a domination count of $0$.\n$$F_1 = \\{1, 2, 3, 4, 5, 6, 8\\}$$\nThe size of this front is $|F_1| = 7$.\n\nTo find the next front, we consider the individuals dominated by $F_1$. Individual $2 \\in F_1$ dominates individual $7$. We decrement the domination count of individual $7$, which becomes $n_7 = 1 - 1 = 0$. The only remaining individual is $7$, and its new domination count is $0$. Thus, it forms the second front.\n$$F_2 = \\{7\\}$$\nThe size of this front is $|F_2| = 1$. All individuals have been sorted into fronts.\n\nThe next step is environmental selection. The next generation has a capacity of $N_{\\text{sel}} = 5$. We add individuals from fronts in order of their rank ($F_1$, then $F_2$, etc.).\nSince $|F_1| = 7 > N_{\\text{sel}} = 5$, the next generation will be composed entirely of individuals from $F_1$. We must select $5$ individuals from the $7$ in $F_1$. This selection is based on the crowding distance, where individuals with larger distances are preferred.\n\nWe now calculate the crowding distance for each individual in $F_1$. The individuals in $F_1$ are:\n$1: (1.0, 8.0)$, $2: (2.0, 6.0)$, $3: (3.0, 4.0)$, $4: (4.0, 3.5)$, $5: (5.0, 3.2)$, $6: (7.5, 2.0)$, $8: (6.5, 2.8)$.\n\nThe crowding distance calculation requires normalizing by the range of objective values within the front.\nFor objective $f_1$, the values in $F_1$ are $\\{1.0, 2.0, 3.0, 4.0, 5.0, 6.5, 7.5\\}$.\n$f_{1, \\text{max}} = 7.5$ and $f_{1, \\text{min}} = 1.0$. The range is $f_{1, \\text{max}} - f_{1, \\text{min}} = 6.5$.\nFor objective $f_2$, the values in $F_1$ are $\\{8.0, 6.0, 4.0, 3.5, 3.2, 2.8, 2.0\\}$.\n$f_{2, \\text{max}} = 8.0$ and $f_{2, \\text{min}} = 2.0$. The range is $f_{2, \\text{max}} - f_{2, \\text{min}} = 6.0$.\n\nIndividuals at the boundary of each objective's range are assigned an infinite crowding distance.\n- For $f_1$, individual $1$ has the minimum value and individual $6$ has the maximum. Thus, their crowding distances are $CD_1 = \\infty$ and $CD_6 = \\infty$.\n- For $f_2$, individual $6$ has the minimum value and individual $1$ has the maximum. This confirms $CD_1 = \\infty$ and $CD_6 = \\infty$.\n\nFor any interior individual $j$, the crowding distance is the sum of its distances for each objective: $CD_j = d_{1,j} + d_{2,j}$, where $d_{m,j} = \\frac{f_m(\\text{neighbor } j+1) - f_m(\\text{neighbor } j-1)}{f_{m, \\text{max}} - f_{m, \\text{min}}}$.\n\nTo calculate the distances, we sort the individuals in $F_1$ based on each objective.\nSorted by $f_1$: $(1, 2, 3, 4, 5, 8, 6)$.\nSorted by $f_2$: $(6, 8, 5, 4, 3, 2, 1)$.\n\nCalculation of $d_{m,j}$:\n$d_{1,2} = \\frac{f_{1,3} - f_{1,1}}{6.5} = \\frac{3.0 - 1.0}{6.5} = \\frac{2.0}{6.5} = \\frac{4}{13}$.\n$d_{1,3} = \\frac{f_{1,4} - f_{1,2}}{6.5} = \\frac{4.0 - 2.0}{6.5} = \\frac{2.0}{6.5} = \\frac{4}{13}$.\n$d_{1,4} = \\frac{f_{1,5} - f_{1,3}}{6.5} = \\frac{5.0 - 3.0}{6.5} = \\frac{2.0}{6.5} = \\frac{4}{13}$.\n$d_{1,5} = \\frac{f_{1,8} - f_{1,4}}{6.5} = \\frac{6.5 - 4.0}{6.5} = \\frac{2.5}{6.5} = \\frac{5}{13}$.\n$d_{1,8} = \\frac{f_{1,6} - f_{1,5}}{6.5} = \\frac{7.5 - 5.0}{6.5} = \\frac{2.5}{6.5} = \\frac{5}{13}$.\n\n$d_{2,2} = \\frac{f_{2,1} - f_{2,3}}{6.0} = \\frac{8.0 - 4.0}{6.0} = \\frac{4.0}{6.0} = \\frac{2}{3}$.\n$d_{2,3} = \\frac{f_{2,2} - f_{2,4}}{6.0} = \\frac{6.0 - 3.5}{6.0} = \\frac{2.5}{6.0} = \\frac{5}{12}$.\n$d_{2,4} = \\frac{f_{2,3} - f_{2,5}}{6.0} = \\frac{4.0 - 3.2}{6.0} = \\frac{0.8}{6.0} = \\frac{2}{15}$.\n$d_{2,5} = \\frac{f_{2,4} - f_{2,8}}{6.0} = \\frac{3.5 - 2.8}{6.0} = \\frac{0.7}{6.0} = \\frac{7}{60}$.\n$d_{2,8} = \\frac{f_{2,5} - f_{2,6}}{6.0} = \\frac{3.2 - 2.0}{6.0} = \\frac{1.2}{6.0} = \\frac{1}{5}$.\n\nTotal crowding distances for interior points:\n$CD_2 = d_{1,2} + d_{2,2} = \\frac{4}{13} + \\frac{2}{3} = \\frac{12+26}{39} = \\frac{38}{39}$.\n$CD_3 = d_{1,3} + d_{2,3} = \\frac{4}{13} + \\frac{5}{12} = \\frac{48+65}{156} = \\frac{113}{156}$.\n$CD_4 = d_{1,4} + d_{2,4} = \\frac{4}{13} + \\frac{2}{15} = \\frac{60+26}{195} = \\frac{86}{195}$.\n$CD_5 = d_{1,5} + d_{2,5} = \\frac{5}{13} + \\frac{7}{60} = \\frac{300+91}{780} = \\frac{391}{780}$.\n$CD_8 = d_{1,8} + d_{2,8} = \\frac{5}{13} + \\frac{1}{5} = \\frac{25+13}{65} = \\frac{38}{65}$.\n\nTo compare these values, we can convert them to decimals or use a common denominator ($780$):\n$CD_2 = \\frac{38}{39} = \\frac{760}{780} \\approx 0.974$\n$CD_3 = \\frac{113}{156} = \\frac{565}{780} \\approx 0.724$\n$CD_8 = \\frac{38}{65} = \\frac{456}{780} \\approx 0.585$\n$CD_5 = \\frac{391}{780} \\approx 0.501$\n$CD_4 = \\frac{86}{195} = \\frac{344}{780} \\approx 0.441$\n\nSorting the individuals in $F_1$ in descending order of crowding distance gives the ranking:\n1. Individual $1$ ($CD_1 = \\infty$)\n2. Individual $6$ ($CD_6 = \\infty$)\n3. Individual $2$ ($CD_2 \\approx 0.974$)\n4. Individual $3$ ($CD_3 \\approx 0.724$)\n5. Individual $8$ ($CD_8 \\approx 0.585$)\n6. Individual $5$ ($CD_5 \\approx 0.501$)\n7. Individual $4$ ($CD_4 \\approx 0.441$)\n\nWe need to select $N_{\\text{sel}} = 5$ individuals. We take the top $5$ from this list. The index set of selected individuals is $\\mathcal{I} = \\{1, 6, 2, 3, 8\\}$.\n\nThe final step is to calculate the sum $T$ of the indices in $\\mathcal{I}$:\n$$T = \\sum_{i \\in \\mathcal{I}} i = 1 + 2 + 3 + 6 + 8$$\n$$T = 20$$",
            "answer": "$$\\boxed{20}$$"
        }
    ]
}