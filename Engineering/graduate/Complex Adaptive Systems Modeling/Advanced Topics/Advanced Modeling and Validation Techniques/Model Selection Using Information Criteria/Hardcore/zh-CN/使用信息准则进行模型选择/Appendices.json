{
    "hands_on_practices": [
        {
            "introduction": "本练习将信息论的理论基础与模型选择的实践联系起来。通过从Kullback-Leibler散度出发推导赤池信息准则（AIC），您将深刻理解AIC如何在模型拟合优度与复杂性之间进行权衡，从而为模型比较提供了一个有力的工具。 这个练习将巩固您对AIC作为预测误差估计量的理解。",
            "id": "4127428",
            "problem": "在一项关于多智能体交互的复杂自适应系统建模研究中，假设您观察到一个由分布为 $p^{\\star}$ 的未知平稳机制生成的智能体行动序列 $\\{y_i\\}_{i=1}^{n}$。您拟合了两个相互竞争的参数模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$，每个模型都指定了一个由自由参数向量 $\\theta \\in \\mathbb{R}^{k}$ 构成的族 $\\{p_{\\theta}(y)\\}$。两个模型都是正则的且设定正确的，即在每个族内都存在参数 $\\theta_1^{\\star}$ 和 $\\theta_2^{\\star}$，使得相对于 $p^{\\star}$ 的库尔贝克-莱布勒散度最小化。设 $\\hat{\\theta}_j$ 表示在模型 $\\mathcal{M}_j$ 下通过最大化样本对数似然 $\\ell_j(\\theta) = \\sum_{i=1}^{n} \\ln p_{\\theta}(y_i)$ 得到的最大似然估计量，其中 $j \\in \\{1,2\\}$。\n\n从库尔贝克-莱布勒散度的定义 $\\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta}) = \\mathbb{E}_{p^{\\star}}\\!\\left[\\ln p^{\\star}(Y) - \\ln p_{\\theta}(Y)\\right]$ 和最大似然估计 (MLE) 的大样本性质出发，推导出一个信息准则。该准则仅使用最大化的样本内对数似然和自由参数的数量，为一个已拟合的参数模型提供其期望样本外库尔贝克-莱布勒风险的近似无偏估计（相差一个与模型无关的加法常数）。陈述该准则所蕴含的选择规则。\n\n给定以下拟合摘要：\n- 模型 $\\mathcal{M}_1$：最大化对数似然 $\\ell_1(\\hat{\\theta}_1) = -235.4$，参数数量 $k_1 = 8$。\n- 模型 $\\mathcal{M}_2$：最大化对数似然 $\\ell_2(\\hat{\\theta}_2) = -238.1$，参数数量 $k_2 = 5$。\n\n计算 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的准则值，并确定该准则偏好哪个模型。将所有报告的准则值四舍五入到四位有效数字。将最终答案表示为一个行向量，其中包含按 $(\\mathcal{M}_1,\\mathcal{M}_2)$ 顺序排列的两个准则值，后跟一个整数 $i \\in \\{1,2\\}$，表示偏好模型的索引。",
            "solution": "问题陈述具有科学依据，定义明确且客观。它提出了统计模型选择中的一个标准情景，要求从第一性原理出发推导一个信息准则，并将其应用于所提供的数据集。完成此任务所需的所有要素都已定义且一致。因此，该问题被认为是有效的。\n\n目标是推导一个信息准则，作为已拟合模型期望样本外库尔贝克-莱布勒 (KL) 风险的近似无偏估计量。此风险量化了真实、未知的数据生成分布 $p^{\\star}$ 与模型的预测分布 $p_{\\hat{\\theta}}$ 之间的差异，其中 $\\hat{\\theta}$ 是从训练样本 $Y = \\{y_i\\}_{i=1}^n$ 中推导出的最大似然估计 (MLE)。\n\nKL 散度定义为：\n$$ \\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta}) = \\mathbb{E}_{Z \\sim p^{\\star}}\\!\\left[\\ln p^{\\star}(Z) - \\ln p_{\\theta}(Z)\\right] $$\n其中 $Z$ 是从 $p^{\\star}$ 中抽取的一个新数据点，独立于训练数据 $Y$。估计量 $\\hat{\\theta}$ 是 $Y$ 的函数，因此它是一个随机变量。我们寻求在所有可能的训练集分布上估计期望风险：\n$$ R = \\mathbb{E}_{Y \\sim (p^{\\star})^n} \\left[ \\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\hat{\\theta}(Y)}) \\right] $$\n展开此表达式可得：\n$$ R = \\mathbb{E}_{Y} \\left[ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p^{\\star}(Z)] - \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] \\right] $$\n项 $\\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p^{\\star}(Z)]$ 是真实分布的负熵，它是一个与所评估模型无关的未知常数。对于模型选择，我们只需比较依赖于模型的项 $\\mathbb{E}_{Y} [ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] ]$。最大化此项等价于最小化 KL 风险。习惯上使用该项负值的缩放版本，特别是其值的 $-2n$ 倍，这与偏差 (deviance) 相关。需要估计的目标量（相差一个加法常数）是期望样本外偏差：\n$$ \\Delta_{\\mathrm{out}} = \\mathbb{E}_{Y} \\left[ -2 \\sum_{i=1}^n \\mathbb{E}_{Z_i \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z_i)] \\right] = \\mathbb{E}_{Y} \\left[ -2n\\ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] \\right] $$\n该量的一个朴素估计量是样本内偏差 $-2\\ell(\\hat{\\theta})$，其中 $\\ell(\\hat{\\theta}) = \\sum_{i=1}^n \\ln p_{\\hat{\\theta}}(y_i)$ 是最大化的对数似然。然而，由于 $\\hat{\\theta}$ 是在样本 $Y$ 上优化的，这个估计量存在乐观偏差。推导过程旨在量化并校正这种偏差。\n\n设 $\\theta^{\\star}$ 为模型族内使 $\\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta})$ 最小化的参数值。我们依赖于大样本 ($n \\to \\infty$) 近似。\n首先，我们分析期望样本外对数似然。将 $\\ln p_{\\theta}(Z)$ 在 $\\theta^{\\star}$ 附近进行二阶泰勒展开：\n$$ \\ln p_{\\hat{\\theta}}(Z) \\approx \\ln p_{\\theta^{\\star}}(Z) + (\\hat{\\theta} - \\theta^{\\star})^T \\nabla_{\\theta}\\ln p_{\\theta^{\\star}}(Z) + \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T \\nabla^2_{\\theta}\\ln p_{\\theta^{\\star}}(Z)(\\hat{\\theta} - \\theta^{\\star}) $$\n对 $Z \\sim p^{\\star}$ 取期望，并注意到 $\\mathbb{E}_Z[\\nabla_{\\theta}\\ln p_{\\theta^{\\star}}(Z)] = 0$（因为 $\\theta^{\\star}$ 是 KL 散度的最小值点）和 $\\mathbb{E}_Z[\\nabla^2_{\\theta}\\ln p_{\\theta^{\\star}}(Z)] = -I_1(\\theta^{\\star})$（单个观测值的费雪信息矩阵的负数），我们得到：\n$$ \\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T I_1(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star}) $$\n对训练数据 $Y$ 取期望，并利用随机变量二次型的性质：\n$$ \\mathbb{E}_{Y}[\\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)]] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2}\\mathrm{Tr}\\left(I_1(\\theta^{\\star}) \\mathrm{Cov}_{Y}(\\hat{\\theta})\\right) $$\n根据大样本 MLE 理论，估计量的协方差为 $\\mathrm{Cov}_{Y}(\\hat{\\theta}) \\approx (nI_1(\\theta^{\\star}))^{-1}$。代入可得：\n$$ \\mathbb{E}_{Y}[\\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)]] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2n}\\mathrm{Tr}(I_{k \\times k}) = \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{k}{2n} $$\n其中 $k$ 是参数的数量。因此，对于完整的期望样本外对数似然：\n$$ \\mathbb{E}_{Y}[\\ell_{\\mathrm{out}}(\\hat{\\theta})] \\approx n\\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{k}{2} $$\n接下来，我们分析期望样本内对数似然。将 $\\ell(\\theta^{\\star})$ 在 MLE $\\hat{\\theta}$ 附近进行泰勒展开可得：\n$$ \\ell(\\theta^{\\star}) \\approx \\ell(\\hat{\\theta}) + (\\theta^{\\star} - \\hat{\\theta})^T \\nabla_{\\theta}\\ell(\\hat{\\theta}) + \\frac{1}{2}(\\theta^{\\star} - \\hat{\\theta})^T \\nabla^2_{\\theta}\\ell(\\hat{\\theta}) (\\theta^{\\star} - \\hat{\\theta}) $$\n由于 $\\nabla_{\\theta}\\ell(\\hat{\\theta})=0$ 且在大样本下 $\\nabla^2_{\\theta}\\ell(\\hat{\\theta}) \\approx -I_n(\\theta^{\\star}) = -nI_1(\\theta^{\\star})$，我们有：\n$$ \\ell(\\theta^{\\star}) \\approx \\ell(\\hat{\\theta}) - \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T I_n(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star}) $$\n对 $Y$ 取期望：\n$$ \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] \\approx \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] - \\frac{1}{2}\\mathbb{E}_{Y}\\left[(\\hat{\\theta} - \\theta^{\\star})^T I_n(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star})\\right] $$\n右侧期望内的项渐近服从 $\\chi^2_k$ 分布，其期望值为 $k$。因此：\n$$ \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] \\approx \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] - \\frac{k}{2} \\implies \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] \\approx \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] + \\frac{k}{2} $$\n由于 $\\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] = n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}(Z)]$，我们得到期望样本内对数似然为：\n$$ \\mathbb{E}_{Y}[\\ell_{\\mathrm{in}}(\\hat{\\theta})] \\approx n\\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] + \\frac{k}{2} $$\n偏差，或称乐观度，是期望样本内对数似然与期望样本外对数似然之差：\n$$ \\text{Optimism} = \\mathbb{E}_{Y}[\\ell_{\\mathrm{in}}(\\hat{\\theta})] - \\mathbb{E}_{Y}[\\ell_{\\mathrm{out}}(\\hat{\\theta})] \\approx \\left( n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}] + \\frac{k}{2} \\right) - \\left( n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}] - \\frac{k}{2} \\right) = k $$\n期望样本外对数似然 $\\mathbb{E}_{Y}[\\ell_{\\mathrm{out}}(\\hat{\\theta})]$ 的一个近似无偏估计量是经过偏差校正的样本内对数似然：$\\ell(\\hat{\\theta}) - k$。为获得期望样本外偏差的估计量，我们乘以 $-2$：\n$$ \\text{Criterion} = -2\\left(\\ell(\\hat{\\theta}) - k\\right) = -2\\ell(\\hat{\\theta}) + 2k $$\n这就是赤池信息准则 (Akaike Information Criterion, AIC)。\n\n该准则所蕴含的选择规则是选择使该值最小化的模型，因为较小的值表示较小的估计样本外预测误差。\n\n现在我们计算这两个模型的准则值。\n对于模型 $\\mathcal{M}_1$：\n- 最大化对数似然 $\\ell_1(\\hat{\\theta}_1) = -235.4$\n- 参数数量 $k_1 = 8$\n准则值为：\n$$ \\text{AIC}_1 = -2\\ell_1(\\hat{\\theta}_1) + 2k_1 = -2(-235.4) + 2(8) = 470.8 + 16 = 486.8 $$\n\n对于模型 $\\mathcal{M}_2$：\n- 最大化对数似然 $\\ell_2(\\hat{\\theta}_2) = -238.1$\n- 参数数量 $k_2 = 5$\n准则值为：\n$$ \\text{AIC}_2 = -2\\ell_2(\\hat{\\theta}_2) + 2k_2 = -2(-238.1) + 2(5) = 476.2 + 10 = 486.2 $$\n\n比较这两个值：\n$$ \\text{AIC}_1 = 486.8 $$\n$$ \\text{AIC}_2 = 486.2 $$\n由于 $486.2  486.8$，该准则偏好模型 $\\mathcal{M}_2$。报告的值已给出四位有效数字。\n\n最终答案包含 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 各自的准则值，后跟偏好模型的索引，即 $2$。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 486.8   486.2   2 \\end{pmatrix} } $$"
        },
        {
            "introduction": "从频率派方法转向贝叶斯模型选择，本练习将介绍偏差信息准则（DIC）。您将学习如何利用贝叶斯后验模拟（如MCMC）的输出结果来计算DIC及其复杂度惩罚项 $p_D$。 这提供了一种在贝叶斯框架内进行模型比较的实用方法。",
            "id": "4127464",
            "problem": "一个团队正在对一个自适应交互网络进行建模，其中智能体根据局部收益和模仿动态更新策略。观测数据 $y$ 包括 $N$ 个时间点的总体协调水平，其似然 $p(y \\mid \\theta)$ 在一个贝叶斯智能体模型下进行评估，该模型带有一个参数矢量 $\\theta$ 用于控制网络重连强度和决策噪声。研究人员利用后验模拟，将每次抽样的偏差计算为对数似然的变换，并总结了两个量：后验平均偏差 $\\overline{D}$ 和后验均值参数下的偏差 $D(\\overline{\\theta})$。这些摘要用于量化模型的有效复杂性，并构建一个权衡拟合度和简约性的模型选择分数，适用于在复杂自适应系统中比较候选模型。\n\n对于一个特定的候选模型，后验抽样得出 $\\overline{D} = 210.4$ 和 $D(\\overline{\\theta}) = 205.9$。使用贝叶斯模型评估中偏差和模型复杂度惩罚的基本定义，计算有效参数数量 $p_D$ 和偏差信息准则 (DIC)。根据这些值，简要解释在该模型中，复杂度惩罚相对于整体拟合度是大还是小。\n\n将有序对 $\\left(p_D,\\ \\mathrm{DIC}\\right)$ 报告为精确值。不需要四舍五入，这些量也没有物理单位。",
            "solution": "该问题要求基于贝叶斯模型后验提供的摘要统计数据，计算有效参数数量 $p_D$ 和偏差信息准则 (DIC)。该问题是适定的，并且在科学上基于贝叶斯模型选择的原理。\n\n偏差信息准则 (DIC) 是 Akaike 信息准则 (AIC) 在分层建模中的推广。它是用于贝叶斯模型比较的一种度量，旨在平衡模型的拟合度和复杂性。偏差定义为 $D(\\theta) = -2 \\ln p(y \\mid \\theta) + C$，其中 $p(y \\mid \\theta)$ 是给定参数 $\\theta$ 时数据 $y$ 的似然，而 $C$ 是一个常数，在所有涉及偏差差异的计算中都会被抵消。\n\n问题提供了从后验模拟中得出的两个关键量：\n1.  偏差的后验均值，$\\overline{D} = E_{\\theta|y}[D(\\theta)]$.\n2.  在参数后验均值处评估的偏差， $D(\\overline{\\theta})$，其中 $\\overline{\\theta} = E_{\\theta|y}[\\theta]$。\n\n给定值为 $\\overline{D} = 210.4$ 和 $D(\\overline{\\theta}) = 205.9$。\n\n首先，我们计算有效参数数量，记为 $p_D$。这个量是模型复杂性的度量，表示模型中有多少参数被数据有效地约束。它被定义为后验平均偏差与后验均值参数下偏差之间的差值。\n\n$p_D$ 的公式为：\n$$p_D = \\overline{D} - D(\\overline{\\theta})$$\n\n代入给定值：\n$$p_D = 210.4 - 205.9 = 4.5$$\n因此，该模型的有效参数数量为 $4.5$。\n\n接下来，我们计算偏差信息准则 (DIC)。DIC 被定义为一种由模型复杂性惩罚的模型拟合度度量。DIC 的一个常见定义是后验均值参数下的偏差加上一个等于有效参数数量两倍的惩罚项。\n\nDIC 的公式为：\n$$\\mathrm{DIC} = D(\\overline{\\theta}) + 2 p_D$$\n\n代入 $D(\\overline{\\theta})$ 的值和计算出的 $p_D$ 值：\n$$\\mathrm{DIC} = 205.9 + 2 \\times 4.5 = 205.9 + 9.0 = 214.9$$\n\nDIC 的另一个等价公式使用后验平均偏差和有效参数数量：\n$$\\mathrm{DIC} = \\overline{D} + p_D$$\n使用此公式进行检验：\n$$\\mathrm{DIC} = 210.4 + 4.5 = 214.9$$\n两个公式得出了相同的结果，证实了计算的正确性。该模型的 DIC 为 $214.9$。\n\n最后，问题要求简要解释复杂度惩罚相对于整体拟合度是大还是小。复杂度惩罚是 $p_D = 4.5$。拟合度的度量是偏差，$\\overline{D} = 210.4$ 和 $D(\\overline{\\theta}) = 205.9$。总体分数 DIC 是 $214.9$。为了评估惩罚的相对大小，我们可以将 $p_D$ 与像 $\\overline{D}$ 这样的拟合度度量进行比较。该比率为 $p_D / \\overline{D} = 4.5 / 210.4 \\approx 0.0214$。这表明模型复杂度的惩罚仅占后验平均偏差的约 $2.1\\%$。因此，相对于模型失拟（偏差）的总体度量，复杂度惩罚是小的。这表明模型的灵活性并未对其总体分数增加实质性的惩罚，模型的性能主要由其对数据的拟合优度决定。\n\n所要求的有序对是 $(p_D, \\mathrm{DIC})$。根据我们的计算，结果是 $(4.5, 214.9)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4.5   214.9\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "这项高级练习深入探讨了分层模型中DIC的实际应用，分层模型是复杂系统建模中的一种常见结构。通过一个具体的编程示例，您不仅将实现DIC的计算，还将遇到并理解其一个关键局限性——有效参数数量 $p_D$ 可能为负值。 这凸显了在模型选择中进行诊断检查和理解准则背后假设的重要性。",
            "id": "4127431",
            "problem": "考虑一个在复杂自适应系统建模中常用的分层模型，用于表示异构代理组。假设有 $J$ 个组，索引为 $j \\in \\{1,\\dots,J\\}$，对于每个组 $j$，有观测值 $\\{y_{ij}\\}_{i=1}^{n_j}$，这些观测值是条件独立生成的，即 $y_{ij} \\sim \\mathcal{N}(t_j, \\sigma^2)$，其中 $t_j$ 是组级随机效应，$\\sigma^2$ 是观测方差。假设一个马尔可夫链蒙特卡洛 (MCMC) 过程已经生成了参数向量 $\\theta = (t_1,\\dots,t_J,\\sigma^2)$ 的后验样本。\n\n从偏差定义为对数似然乘以负二（$D(\\theta) = -2 \\log p(y \\mid \\theta)$）这一基本基础出发，并考虑到独立于 $\\theta$ 的加性常数不影响模型选择决策，请推导如何使用 $\\theta$ 的后验样本来计算偏差信息准则 (DIC) 和有效参数数量 ($p_D$)。您的推导应从正态模型的似然函数开始，然后发展为一个可实现的算法，该算法使用后验样本为给定的数据集和后验样本集生成一个单一标量 DIC 和一个单一标量 $p_D$。解释为什么在分层设置中 $p_D$ 可能是负数或不稳定的。\n\n您的任务是实现一个程序，对于下面的每个测试用例，使用给定的观测值和后验样本来计算每个样本 $s$ 的 $D(\\theta^{(s)})$、后验均值代入偏差 $D(\\hat{\\theta})$、后验平均偏差 $\\bar{D}$、有效参数数量 $p_D = \\bar{D} - D(\\hat{\\theta})$ 以及偏差信息准则 $\\mathrm{DIC} = \\bar{D} + p_D$。所有计算都应省略不依赖于 $\\theta$ 的加性常数。\n\n每个测试用例的最终输出必须是一个包含两个浮点数的列表：$[\\mathrm{DIC}, p_D]$，每个浮点数四舍五入到六位小数。您的程序应生成单行输出，其中包含所有测试用例的结果，形式为逗号分隔的列表，并用方括号括起来，例如 $[[\\mathrm{DIC}_1, p_{D,1}], [\\mathrm{DIC}_2, p_{D,2}], [\\mathrm{DIC}_3, p_{D,3}]]$。\n\n测试套件：\n\n- 测试用例 1（表现良好的后验，预期 $p_D$ 为正）：\n  - 组和观测值：\n    - 组 1：$y_{1} = [\\,1.0,\\,1.2,\\,0.8\\,]$\n    - 组 2：$y_{2} = [\\,2.1,\\,1.9,\\,2.0\\,]$\n    - 组 3：$y_{3} = [\\,0.5,\\,0.7,\\,0.6\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.04,\\,0.05,\\,0.03,\\,0.045,\\,0.04,\\,0.035\\,]$\n    - $t_1$ 样本：$[\\,0.95,\\,1.02,\\,1.00,\\,0.98,\\,1.04,\\,0.97\\,]$\n    - $t_2$ 样本：$[\\,2.05,\\,1.95,\\,2.02,\\,2.00,\\,1.98,\\,2.03\\,]$\n    - $t_3$ 样本：$[\\,0.62,\\,0.58,\\,0.60,\\,0.59,\\,0.61,\\,0.57\\,]$\n\n- 测试用例 2（边界情况，残差方差接近于零，由于凹性预期 $p_D$ 为负）：\n  - 组和观测值：\n    - 组 1：$y_{1} = [\\,1.5,\\,1.5,\\,1.5\\,]$\n    - 组 2：$y_{2} = [\\,0.7,\\,0.7\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.001,\\,0.002,\\,0.005,\\,0.05,\\,0.2,\\,0.01\\,]$\n    - $t_1$ 样本：$[\\,1.5,\\,1.5,\\,1.5,\\,1.5,\\,1.5,\\,1.5\\,]$\n    - $t_2$ 样本：$[\\,0.7,\\,0.7,\\,0.7,\\,0.7,\\,0.7,\\,0.7\\,]$\n\n- 测试用例 3（弱可识别性和高后验离散度，$p_D$ 可能不稳定）：\n  - 组和观测值：\n    - 组 1：$y_{1} = [\\,5.0\\,]$\n    - 组 2：$y_{2} = [\\,0.0\\,]$\n    - 组 3：$y_{3} = [\\,3.2\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.5,\\,3.0,\\,0.8,\\,2.5,\\,1.2,\\,4.0\\,]$\n    - $t_1$ 样本：$[\\,4.0,\\,6.0,\\,5.2,\\,3.5,\\,7.0,\\,4.8\\,]$\n    - $t_2$ 样本：$[\\,{-0.5},\\,0.5,\\,0.0,\\,{-1.0},\\,1.0,\\,0.2\\,]$\n    - $t_3$ 样本：$[\\,2.0,\\,4.0,\\,3.0,\\,5.0,\\,1.5,\\,3.5\\,]$\n\n您的程序必须为每个测试用例实现以下内容：\n- 使用正态似然函数计算每个后验样本的 $D(\\theta^{(s)})$，省略与 $\\theta$ 无关的加性常数。使用 $D(\\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\left[ \\log(\\sigma^2) + \\frac{(y_{ij} - t_j)^2}{\\sigma^2} \\right]$，这等价于 $D(\\theta) = n \\log(\\sigma^2) + \\sum_{j,i} \\frac{(y_{ij} - t_j)^2}{\\sigma^2}$，其中 $n = \\sum_{j=1}^{J} n_j$。\n- 计算 $\\bar{D}$ 作为 $D(\\theta^{(s)})$ 在样本 $s = 1,\\dots,S$ 上的平均值。\n- 计算 $\\hat{\\theta}$ 作为 $t_j$ 和 $\\sigma^2$ 的分量后验均值，然后在这个代入估计值处评估 $D(\\hat{\\theta})$。\n- 计算 $p_D = \\bar{D} - D(\\hat{\\theta})$ 和 $\\mathrm{DIC} = \\bar{D} + p_D$。\n- 为每个测试用例返回 $[\\mathrm{DIC}, p_D]$，四舍五入到六位小数。\n\n您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表，并用方括号括起来，例如：$[[\\mathrm{DIC}_1, p_{D,1}], [\\mathrm{DIC}_2, p_{D,2}], [\\mathrm{DIC}_3, p_{D,3}]]$。不适用物理单位，也不适用角度。所有输出均为四舍五入到六位小数的浮点数。",
            "solution": "该问题要求对一个特定的分层正态模型推导偏差信息准则 (DIC) 和有效参数数量 ($p_D$)，解释 $p_D$ 可能出现的病态情况，并为给定的测试用例实现计算。\n\n### 偏差函数的推导\n\n偏差信息准则 (DIC) 的基础是偏差，定义为 $D(\\theta) = -2 \\log p(y \\mid \\theta)$，其中 $p(y \\mid \\theta)$ 是给定参数向量 $\\theta$ 时数据 $y$ 的似然函数。问题明确指出，在对数似然中任何独立于 $\\theta$ 的加性常数都可以忽略，因为它们在模型比较中会抵消掉。\n\n模型由组 $j \\in \\{1,\\dots,J\\}$ 和个体 $i \\in \\{1,\\dots,n_j\\}$ 的观测值 $y_{ij}$ 定义，这些观测值从正态分布中生成：\n$$\ny_{ij} \\mid t_j, \\sigma^2 \\sim \\mathcal{N}(t_j, \\sigma^2)\n$$\n参数向量为 $\\theta = (t_1, \\dots, t_J, \\sigma^2)$。单个观测值 $y_{ij}$ 的概率密度函数是：\n$$\np(y_{ij} \\mid t_j, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_{ij} - t_j)^2}{2\\sigma^2} \\right)\n$$\n假设在给定参数的条件下，观测值是条件独立的，那么整个数据集 $y = \\{y_{ij}\\}$ 的总似然是各个密度的乘积：\n$$\np(y \\mid \\theta) = \\prod_{j=1}^{J} \\prod_{i=1}^{n_j} p(y_{ij} \\mid t_j, \\sigma^2)\n$$\n相应的对数似然是：\n$$\n\\log p(y \\mid \\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\log p(y_{ij} \\mid t_j, \\sigma^2)\n$$\n$$\n\\log p(y \\mid \\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\left[ -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma^2) - \\frac{(y_{ij} - t_j)^2}{2\\sigma^2} \\right]\n$$\n令 $n = \\sum_{j=1}^{J} n_j$ 为总观测数。对数似然可以写成：\n$$\n\\log p(y \\mid \\theta) = -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n偏差是 $D(\\theta) = -2 \\log p(y \\mid \\theta)$：\n$$\nD(\\theta) = n\\log(2\\pi) + n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n项 $n\\log(2\\pi)$ 不依赖于参数 $\\theta$。根据问题陈述，我们可以为了模型选择的目的而忽略它。这得到了指定的偏差函数：\n$$\nD(\\theta) = n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n\n### DIC 计算算法\n\nDIC 由两个主要部分构成，两者都使用从 MCMC 模拟中获得的后验样本 $\\{\\theta^{(s)}\\}_{s=1}^S$ 进行估计。\n\n1.  **后验平均偏差 ($\\bar{D}$)**：该项衡量拟合优度，在参数的后验分布上取平均。它通过在每个后验样本上计算的偏差的均值来估计：\n    $$\n    \\bar{D} = E_{\\theta|y}[D(\\theta)] \\approx \\frac{1}{S} \\sum_{s=1}^{S} D(\\theta^{(s)})\n    $$\n\n2.  **代入估计的偏差 ($D(\\hat{\\theta})$)**：该项是在参数的点估计 $\\hat{\\theta}$ 处评估的偏差。对于 DIC，这个点估计是参数的后验均值。\n    $$\n    \\hat{\\theta} = E_{\\theta|y}[\\theta] \\approx \\frac{1}{S} \\sum_{s=1}^{S} \\theta^{(s)}\n    $$\n    这个期望是针对向量 $\\theta=(t_1,\\dots,t_J,\\sigma^2)$ 的每个分量计算的。令 $\\hat{t}_j = E[t_j|y]$ 和 $\\hat{\\sigma}^2 = E[\\sigma^2|y]$。则代入偏差为：\n    $$\n    D(\\hat{\\theta}) = n\\log(\\hat{\\sigma}^2) + \\frac{1}{\\hat{\\sigma}^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - \\hat{t}_j)^2\n    $$\n\n3.  **有效参数数量 ($p_D$)**: 模型的复杂性由 $p_D$ 衡量，定义为后验平均偏差与后验均值估计处的偏差之差：\n    $$\n    p_D = \\bar{D} - D(\\hat{\\theta})\n    $$\n\n4.  **偏差信息准则 (DIC)**: DIC 平衡了模型拟合 ($\\bar{D}$) 和复杂性 ($p_D$)。它定义为：\n    $$\n    \\mathrm{DIC} = \\bar{D} + p_D = 2\\bar{D} - D(\\hat{\\theta})\n    $$\n    DIC 值越低，表示模型越好。\n\n### $p_D$ 的不稳定性与负值\n\n有效参数数量 $p_D = E_{\\theta|y}[D(\\theta)] - D(E_{\\theta|y}[\\theta])$，可以解释为偏差后验方差的一种度量。根据詹森不等式，如果 $D(\\theta)$ 是 $\\theta$ 的凸函数，那么 $E[D(\\theta)] \\ge D(E[\\theta])$，这保证了 $p_D \\ge 0$。然而，偏差并不总是参数的凸函数。\n\n让我们检查给定模型的偏差函数：\n$$\nD(\\theta) = n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n虽然第二项关于 $t_j$ 是凸的，但第一项 $n\\log(\\sigma^2)$ 是 $\\sigma^2$ 的严格凹函数。偏差相对于某些参数的凹性可能导致违反詹森不等式的条件，从而可能导致 $p_D  0$。\n\n这个问题在分层模型中尤其突出，原因有几个：\n- **偏态后验**：方差参数如 $\\sigma^2$ 的后验分布常常是高度偏斜的（例如，逆伽马分布），尤其是在数据量较少时。\n- **不良的点估计**：对于一个偏斜的分布，后验均值可能是中心趋势的一个不良概括。后验的众数可能是一个更具代表性的点，但 DIC 的原始公式指定使用均值。当后验均值 $\\hat{\\theta}$ 落在后验概率密度较低的区域时，$D(\\hat{\\theta})$ 可能会异常大。\n- **凹项的主导作用**：在残差平方和非常小的情况下（如测试用例 2，其中残差平方和为零），偏差主要由凹的对数项主导，$D(\\theta) \\approx n\\log(\\sigma^2)$。对于一个严格凹函数 $f$，詹森不等式反转：$E[f(X)]  f(E[X])$。这直接意味着 $\\bar{D}  D(\\hat{\\theta})$，因此 $p_D  0$。\n\n此外，当参数被数据弱识别时，$p_D$ 可能会**不稳定**，如测试用例 3 中每个组只有一个观测值。这导致非常弥散（高方差）的后验分布。结果，后验均值 $\\hat{\\theta}$ 和后验平均偏差 $\\bar{D}$ 可能对特定的 MCMC 样本集非常敏感，使得它们的差值 $p_D$ 在不同的 MCMC 运行之间会显著波动。一个负的或不稳定的 $p_D$ 是一个强烈的信号，表明标准 DIC 在给定情境下可能是一个不可靠的模型选择准则。",
            "answer": "```\n[[-10.435764,4.316442],[-30.584063,-3.959828],[20.738871,3.701193]]\n```"
        }
    ]
}