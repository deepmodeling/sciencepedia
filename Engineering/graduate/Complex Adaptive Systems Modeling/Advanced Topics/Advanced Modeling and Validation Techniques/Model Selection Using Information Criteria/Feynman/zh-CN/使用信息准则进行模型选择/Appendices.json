{
    "hands_on_practices": [
        {
            "introduction": "理论与实践的第一步始于理解最广泛使用的信息准则——赤池信息量准则（AIC）。AIC并不仅仅是一个即插即用的公式；它深刻植根于信息论，旨在估计模型的样本外预测误差。这项练习将指导您从作为模型选择基础理论的库尔贝克-莱布勒（Kullback-Leibler）散度出发，推导出实用的AIC公式，从而清晰地揭示模型拟合优度与复杂性惩罚项之间的权衡关系。通过完成此练习，您将掌握AIC背后的核心逻辑，并能将其应用于实际的模型比较任务中。",
            "id": "4127428",
            "problem": "在一项关于多智能体交互的复杂自适应系统建模研究中，假设您观察到一个智能体行为序列 $\\{y_i\\}_{i=1}^{n}$，它由一个分布为 $p^{\\star}$ 的未知平稳机制生成。您拟合了两个竞争的参数模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$，每个模型都指定了一个由自由参数向量 $\\theta \\in \\mathbb{R}^{k}$ 定义的分布族 $\\{p_{\\theta}(y)\\}$。两个模型都是正则的，并且是设定正确的，即在每个分布族中都存在参数 $\\theta_1^{\\star}$ 和 $\\theta_2^{\\star}$，使得相对于 $p^{\\star}$ 的 Kullback–Leibler 散度最小。令 $\\hat{\\theta}_j$ 表示在模型 $\\mathcal{M}_j$ 下，通过最大化样本对数似然 $\\ell_j(\\theta) = \\sum_{i=1}^{n} \\ln p_{\\theta}(y_i)$ 得到的最大似然估计量，其中 $j \\in \\{1,2\\}$。\n\n从 Kullback–Leibler 散度的定义 $\\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta}) = \\mathbb{E}_{p^{\\star}}\\!\\left[\\ln p^{\\star}(Y) - \\ln p_{\\theta}(Y)\\right]$ 和最大似然估计 (MLE) 的大样本性质出发，推导一个信息准则。该准则为一个拟合参数模型的期望样本外 Kullback–Leibler 风险提供一个近似无偏估计量（在相差一个与模型无关的加性常数的情况下），并且该准则仅使用最大化的样本内对数似然和自由参数的数量。陈述该准则所蕴含的选择规则。\n\n给定以下拟合摘要：\n- 模型 $\\mathcal{M}_1$：最大化对数似然 $\\ell_1(\\hat{\\theta}_1) = -235.4$，参数数量 $k_1 = 8$。\n- 模型 $\\mathcal{M}_2$：最大化对数似然 $\\ell_2(\\hat{\\theta}_2) = -238.1$，参数数量 $k_2 = 5$。\n\n计算 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的准则值，并确定该准则偏好哪个模型。将所有报告的准则值四舍五入到四位有效数字。将您的最终答案表示为一个行向量，其中包含按 $(\\mathcal{M}_1, \\mathcal{M}_2)$ 顺序排列的两个准则值，后面跟着表示所偏好模型索引的单个整数 $i \\in \\{1,2\\}$。",
            "solution": "问题陈述具有科学依据、提法恰当且客观。它提出了一个统计模型选择中的标准场景，要求从第一性原理推导出一个信息准则，并将其应用于所提供的数据集。完成此任务所需的所有组成部分都已定义且一致。因此，该问题被认为是有效的。\n\n目标是推导出一个信息准则，该准则可作为一个拟合模型的期望样本外 Kullback–Leibler (KL) 风险的近似无偏估计量。该风险量化了真实的、未知的数据生成分布 $p^{\\star}$ 与模型的预测分布 $p_{\\hat{\\theta}}$ 之间的差异，其中 $\\hat{\\theta}$ 是从训练样本 $Y = \\{y_i\\}_{i=1}^n$ 中导出的最大似然估计 (MLE)。\n\nKL 散度的定义为：\n$$ \\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta}) = \\mathbb{E}_{Z \\sim p^{\\star}}\\!\\left[\\ln p^{\\star}(Z) - \\ln p_{\\theta}(Z)\\right] $$\n其中 $Z$ 是从 $p^{\\star}$ 中抽取的一个新数据点，独立于训练数据 $Y$。估计量 $\\hat{\\theta}$ 是 $Y$ 的函数，因此它是一个随机变量。我们寻求估计在所有可能的训练集分布上的期望风险：\n$$ R = \\mathbb{E}_{Y \\sim (p^{\\star})^n} \\left[ \\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\hat{\\theta}(Y)}) \\right] $$\n展开此表达式可得：\n$$ R = \\mathbb{E}_{Y} \\left[ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p^{\\star}(Z)] - \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] \\right] $$\n项 $\\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p^{\\star}(Z)]$ 是真实分布的负熵，它是一个与所评估模型无关的未知常数。对于模型选择，我们只需要比较依赖于模型的项 $\\mathbb{E}_{Y} [ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] ]$。最大化该项等价于最小化 KL 风险。习惯上使用该项负值的缩放版本，具体为其值的 $-2n$ 倍，这与偏离度（deviance）有关。在相差一个加性常数的情况下，要估计的目标量是期望样本外偏离度：\n$$ \\Delta_{\\text{out}} = \\mathbb{E}_{Y} \\left[ -2 \\sum_{i=1}^n \\mathbb{E}_{Z_i \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z_i)] \\right] = \\mathbb{E}_{Y} \\left[ -2n\\ \\mathbb{E}_{Z \\sim p^{\\star}}[\\ln p_{\\hat{\\theta}(Y)}(Z)] \\right] $$\n该量的一个朴素估计量是样本内偏离度 $-2\\ell(\\hat{\\theta})$，其中 $\\ell(\\hat{\\theta}) = \\sum_{i=1}^n \\ln p_{\\hat{\\theta}}(y_i)$ 是最大化对数似然。然而，由于 $\\hat{\\theta}$ 是在样本 $Y$ 上优化的，该估计量存在乐观偏差。此推导旨在量化并校正这种偏差。\n\n设 $\\theta^{\\star}$ 是模型族内使 $\\mathrm{D}_{\\mathrm{KL}}(p^{\\star} \\Vert p_{\\theta})$ 最小化的参数值。我们依赖于大样本 ($n \\to \\infty$) 近似。\n首先，我们分析期望样本外对数似然。$\\ln p_{\\theta}(Z)$ 在 $\\theta^{\\star}$ 附近的二阶泰勒展开为：\n$$ \\ln p_{\\hat{\\theta}}(Z) \\approx \\ln p_{\\theta^{\\star}}(Z) + (\\hat{\\theta} - \\theta^{\\star})^T \\nabla_{\\theta}\\ln p_{\\theta^{\\star}}(Z) + \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T \\nabla^2_{\\theta}\\ln p_{\\theta^{\\star}}(Z)(\\hat{\\theta} - \\theta^{\\star}) $$\n对 $Z \\sim p^{\\star}$ 取期望，并注意到 $\\mathbb{E}_Z[\\nabla_{\\theta}\\ln p_{\\theta^{\\star}}(Z)] = 0$（因为 $\\theta^{\\star}$ 是 KL 散度的最小值点）以及 $\\mathbb{E}_Z[\\nabla^2_{\\theta}\\ln p_{\\theta^{\\star}}(Z)] = -I_1(\\theta^{\\star})$（单个观测值的费雪信息矩阵的负数），我们得到：\n$$ \\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T I_1(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star}) $$\n对训练数据 $Y$ 取期望，并利用随机变量二次型的性质：\n$$ \\mathbb{E}_{Y}[\\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)]] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2}\\mathrm{Tr}\\left(I_1(\\theta^{\\star}) \\mathrm{Cov}_{Y}(\\hat{\\theta})\\right) $$\n根据大样本 MLE 理论，估计量的协方差为 $\\mathrm{Cov}_{Y}(\\hat{\\theta}) \\approx (nI_1(\\theta^{\\star}))^{-1}$。代入可得：\n$$ \\mathbb{E}_{Y}[\\mathbb{E}_{Z}[\\ln p_{\\hat{\\theta}}(Z)]] \\approx \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{1}{2n}\\mathrm{Tr}(I_{k \\times k}) = \\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{k}{2n} $$\n其中 $k$ 是参数的数量。因此，对于完整的期望样本外对数似然：\n$$ \\mathbb{E}_{Y}[\\ell_{\\text{out}}(\\hat{\\theta})] \\approx n\\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] - \\frac{k}{2} $$\n接下来，我们分析期望样本内对数似然。$\\ell(\\theta^{\\star})$ 在 MLE $\\hat{\\theta}$ 附近的泰勒展开得出：\n$$ \\ell(\\theta^{\\star}) \\approx \\ell(\\hat{\\theta}) + (\\theta^{\\star} - \\hat{\\theta})^T \\nabla_{\\theta}\\ell(\\hat{\\theta}) + \\frac{1}{2}(\\theta^{\\star} - \\hat{\\theta})^T \\nabla^2_{\\theta}\\ell(\\hat{\\theta}) (\\theta^{\\star} - \\hat{\\theta}) $$\n由于 $\\nabla_{\\theta}\\ell(\\hat{\\theta})=0$，并且在大样本中 $\\nabla^2_{\\theta}\\ell(\\hat{\\theta}) \\approx -I_n(\\theta^{\\star}) = -nI_1(\\theta^{\\star})$，我们有：\n$$ \\ell(\\theta^{\\star}) \\approx \\ell(\\hat{\\theta}) - \\frac{1}{2}(\\hat{\\theta} - \\theta^{\\star})^T I_n(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star}) $$\n对 $Y$ 取期望：\n$$ \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] \\approx \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] - \\frac{1}{2}\\mathbb{E}_{Y}\\left[(\\hat{\\theta} - \\theta^{\\star})^T I_n(\\theta^{\\star}) (\\hat{\\theta} - \\theta^{\\star})\\right] $$\n右侧期望内的项渐近服从自由度为 $k$ 的 $\\chi^2$ 分布，其期望值为 $k$。因此：\n$$ \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] \\approx \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] - \\frac{k}{2} \\implies \\mathbb{E}_{Y}[\\ell(\\hat{\\theta})] \\approx \\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] + \\frac{k}{2} $$\n由于 $\\mathbb{E}_{Y}[\\ell(\\theta^{\\star})] = n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}(Z)]$，我们发现期望样本内对数似然为：\n$$ \\mathbb{E}_{Y}[\\ell_{\\text{in}}(\\hat{\\theta})] \\approx n\\mathbb{E}_{Z}[\\ln p_{\\theta^{\\star}}(Z)] + \\frac{k}{2} $$\n偏差，或称为乐观度，是期望样本内对数似然与期望样本外对数似然之间的差值：\n$$ \\text{Optimism} = \\mathbb{E}_{Y}[\\ell_{\\text{in}}(\\hat{\\theta})] - \\mathbb{E}_{Y}[\\ell_{\\text{out}}(\\hat{\\theta})] \\approx \\left( n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}] + \\frac{k}{2} \\right) - \\left( n\\mathbb{E}_Z[\\ln p_{\\theta^{\\star}}] - \\frac{k}{2} \\right) = k $$\n期望样本外对数似然 $\\mathbb{E}_{Y}[\\ell_{\\text{out}}(\\hat{\\theta})]$ 的一个近似无偏估计量是经偏差校正的样本内对数似然：$\\ell(\\hat{\\theta}) - k$。\n为了获得期望样本外偏离度的估计量，我们乘以 $-2$：\n$$ \\text{Criterion} = -2\\left(\\ell(\\hat{\\theta}) - k\\right) = -2\\ell(\\hat{\\theta}) + 2k $$\n这就是赤池信息准则 (Akaike Information Criterion, AIC)。\n\n该准则所蕴含的选择规则是选择使该值最小化的模型，因为较小的值表示较小的估计样本外预测误差。\n\n现在我们为这两个模型计算准则值。\n对于模型 $\\mathcal{M}_1$：\n- 最大化对数似然 $\\ell_1(\\hat{\\theta}_1) = -235.4$\n- 参数数量 $k_1 = 8$\n准则值为：\n$$ \\text{AIC}_1 = -2\\ell_1(\\hat{\\theta}_1) + 2k_1 = -2(-235.4) + 2(8) = 470.8 + 16 = 486.8 $$\n\n对于模型 $\\mathcal{M}_2$：\n- 最大化对数似然 $\\ell_2(\\hat{\\theta}_2) = -238.1$\n- 参数数量 $k_2 = 5$\n准则值为：\n$$ \\text{AIC}_2 = -2\\ell_2(\\hat{\\theta}_2) + 2k_2 = -2(-238.1) + 2(5) = 476.2 + 10 = 486.2 $$\n\n比较这两个值：\n$$ \\text{AIC}_1 = 486.8 $$\n$$ \\text{AIC}_2 = 486.2 $$\n由于 $486.2  486.8$，该准则偏好模型 $\\mathcal{M}_2$。报告的值已经保留了四位有效数字。\n\n最终答案包含 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的两个准则值，其后是所偏好模型的索引，即 $2$。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 486.8  486.2  2 \\end{pmatrix} } $$"
        },
        {
            "introduction": "虽然AIC是一个强大的工具，但其推导依赖于大样本假设。在复杂适应系统等研究领域，数据量相对于模型参数的数量可能并不充裕，此时标准的AIC可能会倾向于选择过于复杂的模型。为了应对这一挑战，修正的赤池信息量准则（AICc）被提出，它对惩罚项进行了调整，以在小样本情况下提供更准确的评估。这项练习将让您亲手计算AICc，并量化该修正相对于标准AIC惩罚项的重要性，从而深化您对何时以及为何应优先使用AICc的理解。",
            "id": "4127469",
            "problem": "一个研究团队正在对一个具有自适应策略和网络化交互的异质主体市场进行建模。他们通过最大似然估计（MLE）在一个长度为 $n=50$ 个时间点的单个独立实现上校准了一个候选模型，使用了 $k=12$ 个自由参数来编码行为倾向和交互率。拟合模型的最大化对数似然为 $\\ell=-120.5$。在复杂自适应系统建模中，候选模型间的选择是基于最小化预期的样本外预测差异，该差异通过 Kullback–Leibler（KL）散度来度量。Akaike 方法使用一个信息准则，通过结合拟合优度项和简约性惩罚项，从有限数据中估计这个预期差异。当样本量相对于参数数量不大时，可以应用小样本修正。\n\n仅使用这些原则，计算该拟合模型的赤池信息准则（AIC）和小样本修正的赤池信息准则（AICc）。然后，通过报告 AICc 修正与 $2k$ 的比率，量化小样本修正相对于基线复杂度惩罚的大小。将您的最终答案报告为一个包含 $\\text{AIC}$、$\\text{AICc}$ 以及修正与 $2k$ 的比率的三个条目的行向量。无需四舍五入。",
            "solution": "问题陈述已经过验证，被认为是合理、自洽且适定的。提供了唯一解所需的所有必要信息，其背景基于统计模型选择的既定原则。\n\n任务是计算赤池信息准则（AIC）、小样本修正的赤池信息准则（AICc），以及小样本修正项与基线复杂度惩罚项的比率。这些度量用于模型选择中，以估计预期的样本外预测性能，该性能由 Kullback-Leibler 散度正式度量。\n\n给定值为：\n- 样本量，$n = 50$。\n- 自由参数数量，$k = 12$。\n- 最大化对数似然，$\\ell = -120.5$。\n\n首先，我们计算赤池信息准则（AIC）。AIC 定义为最大化对数似然和模型参数数量的函数。它在由似然项表示的拟合优度和由惩罚项表示的模型复杂度之间取得平衡。公式为：\n$$ \\text{AIC} = -2\\ell + 2k $$\n将给定值代入此方程：\n$$ \\text{AIC} = -2(-120.5) + 2(12) $$\n$$ \\text{AIC} = 241 + 24 $$\n$$ \\text{AIC} = 265 $$\n\n接下来，我们计算小样本修正的赤池信息准则（AICc）。标准 AIC 是在样本量较大的假设下推导出来的。当样本量 $n$ 相对于参数数量 $k$ 不大时，AIC 可能会有偏差，倾向于选择参数过多的模型。AICc 对惩罚项应用一个修正来补偿这种偏差。当比率 $\\frac{n}{k}$ 较小（通常低于 $40$）时，推荐使用 AICc。在本问题中，该比率为 $\\frac{n}{k} = \\frac{50}{12} \\approx 4.17$，远低于该阈值，因此使用 AICc至关重要。\n\nAICc 的公式为：\n$$ \\text{AICc} = \\text{AIC} + \\frac{2k(k+1)}{n-k-1} $$\n第二项 $\\frac{2k(k+1)}{n-k-1}$ 是小样本修正项。让我们先计算这个值：\n$$ \\text{修正项} = \\frac{2(12)(12+1)}{50-12-1} = \\frac{2(12)(13)}{37} = \\frac{24 \\times 13}{37} = \\frac{312}{37} $$\n现在，我们可以通过将此修正值加到先前计算的 AIC 值上来计算 AICc 的值：\n$$ \\text{AICc} = 265 + \\frac{312}{37} $$\n为了将其表示为单个分数：\n$$ \\text{AICc} = \\frac{265 \\times 37}{37} + \\frac{312}{37} = \\frac{9805}{37} + \\frac{312}{37} = \\frac{9805 + 312}{37} = \\frac{10117}{37} $$\n\n最后，问题要求计算 AICc 修正与基线复杂度惩罚的比率。标准 AIC 公式中的基线复杂度惩罚是 $2k$ 项。\n$$ \\text{基线惩罚} = 2k = 2(12) = 24 $$\n因此，该比率是修正项的值除以这个基线惩罚：\n$$ \\text{比率} = \\frac{\\text{修正项}}{\\text{基线惩罚}} = \\frac{\\frac{2k(k+1)}{n-k-1}}{2k} $$\n通过消去分子和分母中的 $2k$ 项，该表达式在代数上得以简化：\n$$ \\text{比率} = \\frac{k+1}{n-k-1} $$\n代入 $k$ 和 $n$ 的值：\n$$ \\text{比率} = \\frac{12+1}{50-12-1} = \\frac{13}{37} $$\n\n所要求的三个值为 $\\text{AIC} = 265$、$\\text{AICc} = \\frac{10117}{37}$，以及比率 $\\frac{13}{37}$。这些值需要以一个包含三个条目的行向量的形式报告。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 265  \\frac{10117}{37}  \\frac{13}{37} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "当我们的建模框架从频率主义转向贝叶斯主义时，我们需要采用与之相适应的模型选择工具。偏差信息准则（DIC）是贝叶斯框架下与AIC地位相当的一个重要指标，它同样旨在平衡模型的拟合度与复杂度。这项实践练习要求您直接基于马尔可夫链蒙特卡洛（MCMC）方法产生的后验样本，通过编程实现DIC的计算。您不仅将学习如何从原始输出中计算“有效参数数量”$p_D$和最终的DIC值，还将通过具体案例探讨DIC在特定条件下可能出现的不稳定性（例如$p_D$为负值），这对于在实践中稳健地应用贝叶斯模型选择至关重要。",
            "id": "4127431",
            "problem": "考虑一个在复杂适应性系统建模中常用的、用于表示异构智能体群体的分层模型。设有 $J$ 个组，索引为 $j \\in \\{1,\\dots,J\\}$，对于每个组 $j$，有观测值 $\\{y_{ij}\\}_{i=1}^{n_j}$，这些观测值是条件独立地生成的，服从 $y_{ij} \\sim \\mathcal{N}(t_j, \\sigma^2)$，其中 $t_j$ 是组级别的随机效应，$\\sigma^2$ 是观测方差。假设一个马尔可夫链蒙特卡洛（MCMC）过程已经生成了参数向量 $\\theta = (t_1,\\dots,t_J,\\sigma^2)$ 的后验样本。\n\n从偏差（deviance）定义为负二倍对数似然 $D(\\theta) = -2 \\log p(y \\mid \\theta)$ 这一基本出发点，并考虑到与 $\\theta$ 无关的加法常数不影响模型选择决策，请推导如何使用 $\\theta$ 的后验样本来计算偏差信息准则（DIC）和有效参数数量（$p_D$）。您的推导应从正态模型的似然函数开始，最终形成一个可实现的算法，该算法使用后验样本，为给定的数据集和后验样本集生成一个标量 DIC 和一个标量 $p_D$。解释为什么在分层设置中 $p_D$ 可能会为负或不稳定。\n\n您的任务是实现一个程序，对下面的每个测试用例，使用给定的观测值和后验样本，为每个样本 $s$ 计算 $D(\\theta^{(s)})$、后验均值代入偏差 $D(\\hat{\\theta})$、后验平均偏差 $\\bar{D}$、有效参数数量 $p_D = \\bar{D} - D(\\hat{\\theta})$ 以及偏差信息准则 $\\mathrm{DIC} = \\bar{D} + p_D$。所有计算都应省略不依赖于 $\\theta$ 的加法常数。\n\n每个测试用例的最终输出必须是一个包含两个浮点数的列表：$[\\mathrm{DIC}, p_D]$，每个浮点数四舍五入到六位小数。您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号括起来的逗号分隔列表，例如 $[[\\mathrm{DIC}_1, p_{D,1}], [\\mathrm{DIC}_2, p_{D,2}], [\\mathrm{DIC}_3, p_{D,3}]]$.\n\n测试套件：\n\n- 测试用例 $1$（行为良好的后验，预期 $p_D$ 为正）：\n  - 组和观测值：\n    - 组 $1$：$y_{1} = [\\,1.0,\\,1.2,\\,0.8\\,]$\n    - 组 $2$：$y_{2} = [\\,2.1,\\,1.9,\\,2.0\\,]$\n    - 组 $3$：$y_{3} = [\\,0.5,\\,0.7,\\,0.6\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.04,\\,0.05,\\,0.03,\\,0.045,\\,0.04,\\,0.035\\,]$\n    - $t_1$ 样本：$[\\,0.95,\\,1.02,\\,1.00,\\,0.98,\\,1.04,\\,0.97\\,]$\n    - $t_2$ 样本：$[\\,2.05,\\,1.95,\\,2.02,\\,2.00,\\,1.98,\\,2.03\\,]$\n    - $t_3$ 样本：$[\\,0.62,\\,0.58,\\,0.60,\\,0.59,\\,0.61,\\,0.57\\,]$\n\n- 测试用例 $2$（边界情况，残差方差接近于零，由于凹性预期 $p_D$ 为负）：\n  - 组和观测值：\n    - 组 $1$：$y_{1} = [\\,1.5,\\,1.5,\\,1.5\\,]$\n    - 组 $2$：$y_{2} = [\\,0.7,\\,0.7\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.001,\\,0.002,\\,0.005,\\,0.05,\\,0.2,\\,0.01\\,]$\n    - $t_1$ 样本：$[\\,1.5,\\,1.5,\\,1.5,\\,1.5,\\,1.5,\\,1.5\\,]$\n    - $t_2$ 样本：$[\\,0.7,\\,0.7,\\,0.7,\\,0.7,\\,0.7,\\,0.7\\,]$\n\n- 测试用例 $3$（弱可识别性和高后验离散度，$p_D$ 可能不稳定）：\n  - 组和观测值：\n    - 组 $1$：$y_{1} = [\\,5.0\\,]$\n    - 组 $2$：$y_{2} = [\\,0.0\\,]$\n    - 组 $3$：$y_{3} = [\\,3.2\\,]$\n  - 后验样本 ($S = 6$)：\n    - $\\sigma^2$ 样本：$[\\,0.5,\\,3.0,\\,0.8,\\,2.5,\\,1.2,\\,4.0\\,]$\n    - $t_1$ 样本：$[\\,4.0,\\,6.0,\\,5.2,\\,3.5,\\,7.0,\\,4.8\\,]$\n    - $t_2$ 样本：$[\\,{-0.5},\\,0.5,\\,0.0,\\,{-1.0},\\,1.0,\\,0.2\\,]$\n    - $t_3$ 样本：$[\\,2.0,\\,4.0,\\,3.0,\\,5.0,\\,1.5,\\,3.5\\,]$\n\n您的程序必须为每个测试用例实现以下内容：\n- 使用正态似然函数为每个后验样本计算 $D(\\theta^{(s)})$，省略与 $\\theta$ 无关的加法常数。使用 $D(\\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\left[ \\log(\\sigma^2) + \\frac{(y_{ij} - t_j)^2}{\\sigma^2} \\right]$，这等价于 $D(\\theta) = n \\log(\\sigma^2) + \\sum_{j,i} \\frac{(y_{ij} - t_j)^2}{\\sigma^2}$，其中 $n = \\sum_{j=1}^{J} n_j$。\n- 计算 $\\bar{D}$，即 $D(\\theta^{(s)})$ 在所有样本 $s = 1,\\dots,S$ 上的平均值。\n- 计算 $\\hat{\\theta}$，即 $t_j$ 和 $\\sigma^2$ 的逐分量后验均值，然后在这个代入估计值上计算 $D(\\hat{\\theta})$。\n- 计算 $p_D = \\bar{D} - D(\\hat{\\theta})$ 和 $\\mathrm{DIC} = \\bar{D} + p_D$。\n- 为每个测试用例返回四舍五入到六位小数的 $[\\mathrm{DIC}, p_D]$。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号括起来的逗号分隔列表，例如：$[[\\mathrm{DIC}_1, p_{D,1}], [\\mathrm{DIC}_2, p_{D,2}], [\\mathrm{DIC}_3, p_{D,3}]]$. 无物理单位适用，角度不适用。所有输出均为四舍五入到六位小数的浮点数。",
            "solution": "该问题要求针对一个特定的分层正态模型，推导偏差信息准则（DIC）和有效参数数量（$p_D$），解释 $p_D$ 中潜在的病态问题，并为给定的测试用例实现计算。\n\n### 偏差函数的推导\n\n偏差信息准则（DIC）的基础是偏差（deviance），其定义为 $D(\\theta) = -2 \\log p(y \\mid \\theta)$，其中 $p(y \\mid \\theta)$ 是在给定参数向量 $\\theta$ 时数据 $y$ 的似然。问题指明，在对数似然中任何与 $\\theta$ 无关的加法常数都可以忽略，因为它们在模型比较中会抵消。\n\n该模型由观测值 $y_{ij}$ 定义，其中 $j \\in \\{1,\\dots,J\\}$ 为组， $i \\in \\{1,\\dots,n_j\\}$ 为个体，这些观测值从正态分布中生成：\n$$\ny_{ij} \\mid t_j, \\sigma^2 \\sim \\mathcal{N}(t_j, \\sigma^2)\n$$\n参数向量为 $\\theta = (t_1, \\dots, t_J, \\sigma^2)$。单个观测值 $y_{ij}$ 的概率密度函数是：\n$$\np(y_{ij} \\mid t_j, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_{ij} - t_j)^2}{2\\sigma^2} \\right)\n$$\n假设在给定参数的条件下观测值是条件独立的，那么整个数据集 $y = \\{y_{ij}\\}$ 的总似然是各个密度的乘积：\n$$\np(y \\mid \\theta) = \\prod_{j=1}^{J} \\prod_{i=1}^{n_j} p(y_{ij} \\mid t_j, \\sigma^2)\n$$\n相应的对数似然是：\n$$\n\\log p(y \\mid \\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\log p(y_{ij} \\mid t_j, \\sigma^2)\n$$\n$$\n\\log p(y \\mid \\theta) = \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} \\left[ -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma^2) - \\frac{(y_{ij} - t_j)^2}{2\\sigma^2} \\right]\n$$\n令 $n = \\sum_{j=1}^{J} n_j$ 为观测总数。对数似然可以写成：\n$$\n\\log p(y \\mid \\theta) = -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n偏差为 $D(\\theta) = -2 \\log p(y \\mid \\theta)$：\n$$\nD(\\theta) = n\\log(2\\pi) + n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n项 $n\\log(2\\pi)$ 不依赖于参数 $\\theta$。根据问题陈述，为了模型选择的目的，我们可以省略它。这得到了指定的偏差函数：\n$$\nD(\\theta) = n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n\n### DIC 计算算法\n\nDIC 由两个主要部分构成，两者都使用从 MCMC 模拟中获得的后验样本 $\\{\\theta^{(s)}\\}_{s=1}^S$ 进行估计。\n\n1.  **后验平均偏差 ($\\bar{D}$)**：此项衡量拟合优度，在参数的后验分布上取平均。它通过在每个后验样本上计算的偏差的均值来估计：\n    $$\n    \\bar{D} = E_{\\theta|y}[D(\\theta)] \\approx \\frac{1}{S} \\sum_{s=1}^{S} D(\\theta^{(s)})\n    $$\n\n2.  **在代入估计值处的偏差 ($D(\\hat{\\theta})$)**：此项是在参数的点估计值 $\\hat{\\theta}$ 处计算的偏差。对于 DIC，该点估计值是参数的后验均值。\n    $$\n    \\hat{\\theta} = E_{\\theta|y}[\\theta] \\approx \\frac{1}{S} \\sum_{s=1}^{S} \\theta^{(s)}\n    $$\n    这个期望是针对向量 $\\theta=(t_1,\\dots,t_J,\\sigma^2)$ 逐分量计算的。令 $\\hat{t}_j = E[t_j|y]$ 和 $\\hat{\\sigma}^2 = E[\\sigma^2|y]$。那么代入偏差为：\n    $$\n    D(\\hat{\\theta}) = n\\log(\\hat{\\sigma}^2) + \\frac{1}{\\hat{\\sigma}^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - \\hat{t}_j)^2\n    $$\n\n3.  **有效参数数量 ($p_D$)**：模型的复杂度由 $p_D$ 衡量，其定义为后验平均偏差与在后验均值估计处的偏差之差：\n    $$\n    p_D = \\bar{D} - D(\\hat{\\theta})\n    $$\n\n4.  **偏差信息准则 (DIC)**：DIC 平衡了模型拟合 ($\\bar{D}$) 和复杂度 ($p_D$)。其定义为：\n    $$\n    \\mathrm{DIC} = \\bar{D} + p_D = 2\\bar{D} - D(\\hat{\\theta})\n    $$\n    DIC 值越低，表示模型越好。\n\n### $p_D$ 的不稳定性与负值\n\n有效参数数量 $p_D = E_{\\theta|y}[D(\\theta)] - D(E_{\\theta|y}[\\theta])$，可以解释为偏差的后验方差的一种度量。根据 Jensen 不等式，如果 $D(\\theta)$ 是 $\\theta$ 的凸函数，则 $E[D(\\theta)] \\ge D(E[\\theta])$，这保证了 $p_D \\ge 0$。然而，偏差并不总是参数的凸函数。\n\n让我们检查给定模型的偏差函数：\n$$\nD(\\theta) = n\\log(\\sigma^2) + \\frac{1}{\\sigma^2} \\sum_{j=1}^{J} \\sum_{i=1}^{n_j} (y_{ij} - t_j)^2\n$$\n虽然第二项关于 $t_j$ 是凸的，但第一项 $n\\log(\\sigma^2)$ 是 $\\sigma^2$ 的严格凹函数。偏差相对于某些参数的凹性可能导致违反 Jensen 不等式的条件，从而可能导致 $p_D  0$。\n\n在分层模型中，这个问题由于几个原因而特别突出：\n- **偏态后验**：像 $\\sigma^2$ 这样的方差参数通常具有高度偏斜的后验分布（例如，逆伽马分布），尤其是在数据量较少的情况下。\n- **不良的点估计**：对于偏态分布，后验均值可能不是中心趋势的良好概括。后验众数可能是一个更具代表性的点，但 DIC 的原始公式指定使用均值。当后验均值 $\\hat{\\theta}$ 落在后验概率密度较低的区域时，$D(\\hat{\\theta})$ 可能会异常大。\n- **凹项的主导作用**：在残差平方和非常小的情况下（如测试用例 2，其中残差平方和为零），偏差主要由凹的对数项主导，$D(\\theta) \\approx n\\log(\\sigma^2)$。对于一个严格凹函数 $f$，Jensen 不等式会反向：$E[f(X)]  f(E[X])$。这直接意味着 $\\bar{D}  D(\\hat{\\theta})$，因此 $p_D  0$。\n\n此外，当参数被数据弱识别时，$p_D$ 可能会**不稳定**，例如在测试用例 3 中，每个组只有一个观测值。这会导致非常弥散（高方差）的后验分布。因此，后验均值 $\\hat{\\theta}$ 和后验平均偏差 $\\bar{D}$ 可能对特定的 MCMC 样本集高度敏感，使得它们的差值 $p_D$ 在不同的 MCMC 运行之间会发生显著波动。负的或不稳定的 $p_D$ 是一个强烈的信号，表明标准 DIC 在给定情境下可能是一个不可靠的模型选择准则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_dic_pd(y_groups, post_samples):\n    \"\"\"\n    Computes DIC and p_D for the given hierarchical model.\n    \n    Args:\n        y_groups (list of np.array): Observations for each group.\n        post_samples (dict): Posterior samples for parameters 's2', 't1', 't2', etc.\n        \n    Returns:\n        list: A list containing [DIC, p_D], rounded to six decimal places.\n    \"\"\"\n    # Number of groups\n    J = len(y_groups)\n    \n    # Total number of observations\n    n = sum(len(yg) for yg in y_groups)\n    \n    # Extract posterior samples\n    s2_samples = post_samples['s2']\n    t_samples_list = [post_samples[f't{j+1}'] for j in range(J)]\n    num_samples = len(s2_samples)\n    \n    # Step 1: Calculate posterior mean of parameters (hat_theta)\n    hat_s2 = np.mean(s2_samples)\n    hat_t = [np.mean(ts) for ts in t_samples_list]\n    \n    # Step 2: Calculate D(theta^s) for each posterior sample\n    d_s_values = []\n    for s in range(num_samples):\n        # Parameters for the current sample\n        s2_current = s2_samples[s]\n        \n        # Calculate sum of squared errors for the current sample\n        total_sq_err = 0\n        for j in range(J):\n            t_current = t_samples_list[j][s]\n            y_j = y_groups[j]\n            total_sq_err += np.sum((y_j - t_current)**2)\n        \n        # Calculate deviance for the current sample\n        dev = n * np.log(s2_current) + total_sq_err / s2_current\n        d_s_values.append(dev)\n        \n    # Step 3: Calculate posterior average deviance (D_bar)\n    d_bar = np.mean(d_s_values)\n    \n    # Step 4: Calculate deviance at the posterior mean estimate (D(hat_theta))\n    total_sq_err_hat = 0\n    for j in range(J):\n        t_hat_j = hat_t[j]\n        y_j = y_groups[j]\n        total_sq_err_hat += np.sum((y_j - t_hat_j)**2)\n        \n    d_hat_theta = n * np.log(hat_s2) + total_sq_err_hat / hat_s2\n    \n    # Step 5: Calculate effective number of parameters (p_D) and DIC\n    p_d = d_bar - d_hat_theta\n    dic = d_bar + p_d  # or 2 * d_bar - d_hat_theta\n    \n    return [round(dic, 6), round(p_d, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        {\n            \"y_groups\": [\n                [1.0, 1.2, 0.8],\n                [2.1, 1.9, 2.0],\n                [0.5, 0.7, 0.6]\n            ],\n            \"post_samples\": {\n                's2': [0.04, 0.05, 0.03, 0.045, 0.04, 0.035],\n                't1': [0.95, 1.02, 1.00, 0.98, 1.04, 0.97],\n                't2': [2.05, 1.95, 2.02, 2.00, 1.98, 2.03],\n                't3': [0.62, 0.58, 0.60, 0.59, 0.61, 0.57]\n            }\n        },\n        # Test Case 2\n        {\n            \"y_groups\": [\n                [1.5, 1.5, 1.5],\n                [0.7, 0.7]\n            ],\n            \"post_samples\": {\n                's2': [0.001, 0.002, 0.005, 0.05, 0.2, 0.01],\n                't1': [1.5, 1.5, 1.5, 1.5, 1.5, 1.5],\n                't2': [0.7, 0.7, 0.7, 0.7, 0.7, 0.7]\n            }\n        },\n        # Test Case 3\n        {\n            \"y_groups\": [\n                [5.0],\n                [0.0],\n                [3.2]\n            ],\n            \"post_samples\": {\n                's2': [0.5, 3.0, 0.8, 2.5, 1.2, 4.0],\n                't1': [4.0, 6.0, 5.2, 3.5, 7.0, 4.8],\n                't2': [-0.5, 0.5, 0.0, -1.0, 1.0, 0.2],\n                't3': [2.0, 4.0, 3.0, 5.0, 1.5, 3.5]\n            }\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Convert lists to numpy arrays for vectorized operations\n        y_groups_np = [np.array(y) for y in case[\"y_groups\"]]\n        post_samples_np = {k: np.array(v) for k, v in case[\"post_samples\"].items()}\n        \n        res = calculate_dic_pd(y_groups_np, post_samples_np)\n        results.append(res)\n\n    # Format the final output string exactly as required\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}