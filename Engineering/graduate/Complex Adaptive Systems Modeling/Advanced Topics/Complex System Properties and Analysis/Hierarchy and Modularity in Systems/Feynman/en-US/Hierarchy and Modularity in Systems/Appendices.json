{
    "hands_on_practices": [
        {
            "introduction": "A primary goal in analyzing complex systems is to uncover their underlying organization. This exercise  provides hands-on practice with a foundational technique: agglomerative hierarchical clustering. By starting with a matrix of pairwise dissimilarities, you will apply the average-linkage algorithm to iteratively merge the most similar modules, directly revealing the system's hierarchical structure step by step.",
            "id": "4126046",
            "problem": "Consider a complex adaptive system composed of five interacting modules $M_{1}, M_{2}, M_{3}, M_{4}, M_{5}$. Suppose inter-module dissimilarity has been quantified using a scientifically validated metric derived from long-run behavioral divergence, yielding the following symmetric distance matrix $D$ (entries are dimensionless and the diagonal is $0$):\n$$\nD=\\begin{pmatrix}\n0 & 0.18 & 0.55 & 0.60 & 0.40 \\\\\n0.18 & 0 & 0.58 & 0.59 & 0.42 \\\\\n0.55 & 0.58 & 0 & 0.22 & 0.45 \\\\\n0.60 & 0.59 & 0.22 & 0 & 0.47 \\\\\n0.40 & 0.42 & 0.45 & 0.47 & 0\n\\end{pmatrix}.\n$$\nFrom first principles of hierarchical organization in complex adaptive systems, use the core definition of average-linkage hierarchical clustering: the distance between two clusters $U$ and $V$ is the mean of $D(i,j)$ over all pairs $(i,j)$ with $i \\in U$ and $j \\in V$. Begin with each module as a singleton cluster and iteratively merge the two clusters with the smallest inter-cluster distance. Perform exactly three merges and report the dendrogram merge heights, defined as the cluster-to-cluster distance at the moment of each merge. Express the three heights together as a single row matrix and provide exact decimal values. No rounding is required, and the values are dimensionless.",
            "solution": "The task is to perform agglomerative hierarchical clustering with average linkage on the given modules. We start from the fundamental definition: in average-linkage clustering, for any two clusters $U$ and $V$, the inter-cluster distance is\n$$\nd(U,V) = \\frac{1}{|U|\\,|V|} \\sum_{i \\in U} \\sum_{j \\in V} D(i,j),\n$$\nwhere $|U|$ and $|V|$ denote the number of elements in clusters $U$ and $V$, respectively. The dendrogram merge height at each agglomeration step is the value of $d(U,V)$ for the pair of clusters $U$ and $V$ that are merged at that step.\n\nWe begin with five singleton clusters: $\\{M_{1}\\}$, $\\{M_{2}\\}$, $\\{M_{3}\\}$, $\\{M_{4}\\}$, $\\{M_{5}\\}$. For singleton clusters, the inter-cluster distance equals the corresponding entry in the matrix $D$.\n\n**Step 1: First Merge**\nWe identify the smallest distance among all pairs of singletons by inspecting the off-diagonal entries of the matrix $D$. The minimum value is $D(1,2) = 0.18$.\n- **Action**: Merge clusters $\\{M_{1}\\}$ and $\\{M_{2}\\}$.\n- **Merge Height 1**: $0.18$.\nThe current clusters are $\\{M_{1},M_{2}\\}$, $\\{M_{3}\\}$, $\\{M_{4}\\}$, $\\{M_{5}\\}$.\n\n**Step 2: Second Merge**\nWe must now calculate the distances between the new cluster $\\{M_{1},M_{2}\\}$ and the remaining singletons, and compare them to the distances between the remaining singletons themselves.\n- $d(\\{M_{1},M_{2}\\},\\{M_{3}\\}) = \\frac{D(1,3) + D(2,3)}{1 \\times 2} = \\frac{0.55 + 0.58}{2} = 0.565$.\n- $d(\\{M_{1},M_{2}\\},\\{M_{4}\\}) = \\frac{D(1,4) + D(2,4)}{1 \\times 2} = \\frac{0.60 + 0.59}{2} = 0.595$.\n- $d(\\{M_{1},M_{2}\\},\\{M_{5}\\}) = \\frac{D(1,5) + D(2,5)}{1 \\times 2} = \\frac{0.40 + 0.42}{2} = 0.41$.\nThe remaining singleton-to-singleton distances are $D(3,4) = 0.22$, $D(3,5) = 0.45$, and $D(4,5) = 0.47$.\nComparing all current inter-cluster distances $\\{0.565, 0.595, 0.41, 0.22, 0.45, 0.47\\}$, the minimum is $D(3,4) = 0.22$.\n- **Action**: Merge clusters $\\{M_{3}\\}$ and $\\{M_{4}\\}$.\n- **Merge Height 2**: $0.22$.\nThe current clusters are $\\{M_{1},M_{2}\\}$, $\\{M_{3},M_{4}\\}$, $\\{M_{5}\\}$.\n\n**Step 3: Third Merge**\nWe compute the distances between these three remaining clusters.\n- $d(\\{M_{1},M_{2}\\},\\{M_{5}\\}) = 0.41$ (calculated in Step 2).\n- $d(\\{M_{3},M_{4}\\},\\{M_{5}\\}) = \\frac{D(3,5) + D(4,5)}{1 \\times 2} = \\frac{0.45 + 0.47}{2} = 0.46$.\n- $d(\\{M_{1},M_{2}\\},\\{M_{3},M_{4}\\}) = \\frac{D(1,3) + D(1,4) + D(2,3) + D(2,4)}{2 \\times 2} = \\frac{0.55 + 0.60 + 0.58 + 0.59}{4} = \\frac{2.32}{4} = 0.58$.\nComparing the three inter-cluster distances $\\{0.41, 0.46, 0.58\\}$, the minimum is $0.41$.\n- **Action**: Merge clusters $\\{M_{1},M_{2}\\}$ and $\\{M_{5}\\}$.\n- **Merge Height 3**: $0.41$.\n\n**Final Result**\nThe three merge heights, in order of occurrence, are $0.18$, $0.22$, and $0.41$. Expressed as a row matrix, this is:\n$$\n\\begin{pmatrix}\n0.18 & 0.22 & 0.41\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}0.18 & 0.22 & 0.41\\end{pmatrix}}$$"
        },
        {
            "introduction": "While hierarchical clustering builds a full dendrogram, many analyses focus on finding a single optimal partition of a network into modules or communities. This practice  delves into the mechanics of the Louvain method, a highly effective and popular heuristic for modularity maximization. By manually executing the algorithm's 'local moving' phase, you will calculate the change in modularity, $\\Delta Q$, to make greedy decisions, gaining a concrete understanding of how this optimization process discovers community structure.",
            "id": "4126110",
            "problem": "Consider a weighted, undirected toy network with $6$ nodes labeled $\\{1,2,3,4,5,6\\}$ whose adjacency matrix $\\mathbf{A}$ is\n$$\n\\mathbf{A} \\;=\\;\n\\begin{pmatrix}\n0 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 0.1 & 0 \\\\\n1 & 1 & 0 & 0.1 & 0 & 0 \\\\\n0 & 0 & 0.1 & 0 & 1 & 1 \\\\\n0 & 0.1 & 0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 1 & 1 & 0 \\\\\n\\end{pmatrix}.\n$$\nAll weights are symmetric, and there are no self-loops initially. Let $m$ denote the total edge weight (the sum of weights over undirected edges), and let $k_i$ be the weighted degree of node $i$.\n\nYou will execute one pass of the Louvain heuristic, beginning from the partition in which each node is its own community. Use the standard definition of modularity for weighted, undirected networks with resolution parameter $\\gamma = 1$ and proceed as follows.\n\n- Local moving phase: visit nodes in increasing index order $1 \\rightarrow 2 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow 6$. For a node $i$, consider moving it into the community of each neighbor $j$ that is adjacent to $i$ (based on $\\mathbf{A}$) and compute the change in modularity $\\Delta Q$ for each candidate move given the current partition. If all candidate $\\Delta Q \\leq 0$, keep node $i$ in its current community. If any candidate $\\Delta Q > 0$, move $i$ into the neighbor’s community that yields the largest $\\Delta Q$. In the event of a tie in $\\Delta Q$, choose the neighbor connected to $i$ by the largest edge weight (and if still tied, choose the neighbor with the smallest index). Perform sweeps until a complete sweep occurs with no moves, indicating convergence of the local moving phase.\n- Aggregation phase: aggregate the communities found at the end of the local moving phase into super-nodes. The weight of a self-loop on a super-node equals the total weight of internal edges in that community, and the weight between two super-nodes equals the sum of weights of edges between the two communities in the original graph.\n\nStarting from the modularity definition, derive the appropriate $\\Delta Q$ expressions needed to carry out the local moving phase on this network, evaluate the candidate moves according to the rule above, and identify the final communities after convergence. Then construct the aggregated network and compute the improved modularity $Q$ of the partition found by the local moving phase, evaluated on the aggregated network. Express the final modularity as a reduced rational number. No rounding is permitted. Your final answer must be a single closed-form value for $Q$.",
            "solution": "This problem requires executing the Louvain method's local moving phase to find a modular partition and then calculating the modularity of that partition.\n\n**Step 1: Network Properties**\nFirst, we compute the necessary properties from the adjacency matrix $\\mathbf{A}$.\nThe weighted degree of each node, $k_i = \\sum_j A_{ij}$, is:\n$k_1 = 1+1 = 2$\n$k_2 = 1+1+0.1 = 2.1$\n$k_3 = 1+1+0.1 = 2.1$\n$k_4 = 0.1+1+1 = 2.1$\n$k_5 = 0.1+1+1 = 2.1$\n$k_6 = 1+1 = 2$\n\nThe total edge weight of the network is $m = \\frac{1}{2} \\sum_i k_i$:\n$m = \\frac{1}{2} (2 + 2.1 + 2.1 + 2.1 + 2.1 + 2) = \\frac{12.4}{2} = 6.2$.\n\nThe change in modularity $\\Delta Q$ for moving a node $i$ from its community $D$ to a neighbor's community $C$ is:\n$$ \\Delta Q = \\left( \\frac{k_{i,C}}{m} - \\frac{\\Sigma_{tot}^{(C)} k_i}{2m^2} \\right) - \\left( \\frac{k_{i, D \\setminus \\{i\\}}}{m} - \\frac{(\\Sigma_{tot}^{(D)} - k_i)k_i}{2m^2} \\right) $$\nwhere $k_{i,C}$ is the sum of weights of edges from node $i$ to nodes in community $C$, and $\\Sigma_{tot}^{(C)}$ is the sum of degrees of nodes in community $C$. When node $i$ starts in its own community, this simplifies to $\\Delta Q = \\frac{k_{i,C}}{m} - \\frac{\\Sigma_{tot}^{(C)} k_i}{2m^2}$. We use $2m^2 = 2 \\times (6.2)^2 = 76.88$.\n\n**Step 2: Local Moving Phase - Sweep 1**\nWe start with each node in its own community: $\\{\\{1\\},\\{2\\},\\{3\\},\\{4\\},\\{5\\},\\{6\\}\\}$.\n\n- **Node 1 (Neighbors: 2, 3)**:\n  - Move $1 \\to \\{2\\}$: $C=\\{2\\}, k_{1,C}=1, \\Sigma_{tot}^{(C)}=k_2=2.1, k_1=2$. $\\Delta Q = \\frac{1}{6.2} - \\frac{2.1 \\times 2}{76.88} = \\frac{12.4-4.2}{76.88} = \\frac{8.2}{76.88} > 0$.\n  - Move $1 \\to \\{3\\}$: $C=\\{3\\}, k_{1,C}=1, \\Sigma_{tot}^{(C)}=k_3=2.1, k_1=2$. $\\Delta Q = \\frac{8.2}{76.88} > 0$.\n  - Tie in $\\Delta Q$. Edge weights $A_{12}=1$ and $A_{13}=1$ are also tied. Choose neighbor with smallest index (2).\n  - **Action**: Move $1 \\to \\{2\\}$. Partition: $\\{\\{1,2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}$.\n\n- **Node 2 (in $\\{1,2\\}$; Neighbors: 1, 3, 5)**: We check moves to communities of neighbors 3 and 5. A move would only be made if $\\Delta Q > 0$. Calculations show $\\Delta Q  0$ for both potential moves. **Action**: Node 2 does not move.\n\n- **Node 3 (Neighbors: 1, 2, 4)**:\n  - Move $3 \\to \\{1,2\\}$: $C=\\{1,2\\}, k_{3,C}=A_{31}+A_{32}=2, \\Sigma_{tot}^{(C)}=k_1+k_2=4.1, k_3=2.1$. $\\Delta Q = \\frac{2}{6.2} - \\frac{4.1 \\times 2.1}{76.88} = \\frac{24.8 - 8.61}{76.88} = \\frac{16.19}{76.88} > 0$.\n  - Move $3 \\to \\{4\\}$: $\\Delta Q  0$.\n  - **Action**: Move $3 \\to \\{1,2\\}$. Partition: $\\{\\{1,2,3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}$.\n\n- **Node 4 (Neighbors: 3, 5, 6)**:\n  - Move $4 \\to \\{1,2,3\\}$: $\\Delta Q  0$.\n  - Move $4 \\to \\{5\\}$: $C=\\{5\\}, k_{4,C}=1, \\Sigma_{tot}^{(C)}=k_5=2.1, k_4=2.1$. $\\Delta Q = \\frac{1}{6.2} - \\frac{2.1 \\times 2.1}{76.88} = \\frac{7.99}{76.88} > 0$.\n  - Move $4 \\to \\{6\\}$: $C=\\{6\\}, k_{4,C}=1, \\Sigma_{tot}^{(C)}=k_6=2.0, k_4=2.1$. $\\Delta Q = \\frac{1}{6.2} - \\frac{2.0 \\times 2.1}{76.88} = \\frac{8.2}{76.88} > 0$.\n  - The move to community $\\{6\\}$ yields a higher $\\Delta Q$.\n  - **Action**: Move $4 \\to \\{6\\}$. Partition: $\\{\\{1,2,3\\}, \\{4,6\\}, \\{5\\}\\}$.\n\n- **Node 5 (Neighbors: 2, 4, 6)**:\n  - Move $5 \\to \\{1,2,3\\}$: $\\Delta Q  0$.\n  - Move $5 \\to \\{4,6\\}$: $C=\\{4,6\\}, k_{5,C}=A_{54}+A_{56}=2, \\Sigma_{tot}^{(C)}=k_4+k_6=4.1, k_5=2.1$. $\\Delta Q = \\frac{2}{6.2} - \\frac{4.1 \\times 2.1}{76.88} = \\frac{16.19}{76.88} > 0$.\n  - **Action**: Move $5 \\to \\{4,6\\}$. Partition: $\\{\\{1,2,3\\}, \\{4,5,6\\}\\}$.\n\n- **Node 6 (in $\\{4,5,6\\}$; Neighbors: 4, 5)**: All neighbors are in its current community. **Action**: Node 6 does not move.\n\n**Step 3: Local Moving Phase - Sweep 2 and Convergence**\nThe partition is now $\\{\\{1,2,3\\}, \\{4,5,6\\}\\}$. We sweep through all nodes again.\n- **Node 1**: Neighbors 2, 3 are in its community $\\{1,2,3\\}$. No move.\n- **Node 2**: Neighbor 5 is in community $\\{4,5,6\\}$. A move from $\\{1,2,3\\}$ to $\\{4,5,6\\}$ would result in $\\Delta Q  0$. No move.\n- **Symmetry**: By symmetry of the problem, nodes 3, 4, and 5 also have no profitable moves. Node 6 has no inter-community neighbors.\nSince no nodes moved during the entire sweep, the local moving phase has converged. The final partition is $P_{final} = \\{\\{1,2,3\\}, \\{4,5,6\\}\\}$.\n\n**Step 4: Modularity Calculation**\nWe compute the modularity $Q$ of $P_{final}$ using the formula $Q = \\sum_{C} \\left[ \\frac{\\Sigma_{in}^{(C)}}{m} - \\left( \\frac{\\Sigma_{tot}^{(C)}}{2m} \\right)^2 \\right]$.\nLet $C_1 = \\{1,2,3\\}$ and $C_2 = \\{4,5,6\\}$.\n- For $C_1$:\n  - Internal weight $\\Sigma_{in}^{(C_1)} = A_{12}+A_{13}+A_{23} = 1+1+1=3$.\n  - Sum of degrees $\\Sigma_{tot}^{(C_1)} = k_1+k_2+k_3 = 2+2.1+2.1 = 6.2$.\n- For $C_2$:\n  - Internal weight $\\Sigma_{in}^{(C_2)} = A_{45}+A_{46}+A_{56} = 1+1+1=3$.\n  - Sum of degrees $\\Sigma_{tot}^{(C_2)} = k_4+k_5+k_6 = 2.1+2.1+2 = 6.2$.\n\nNow we calculate $Q$:\n$$ Q = \\left[ \\frac{3}{6.2} - \\left( \\frac{6.2}{2 \\times 6.2} \\right)^2 \\right] + \\left[ \\frac{3}{6.2} - \\left( \\frac{6.2}{2 \\times 6.2} \\right)^2 \\right] $$\n$$ Q = 2 \\times \\left( \\frac{3}{6.2} - \\left( \\frac{1}{2} \\right)^2 \\right) = 2 \\times \\left( \\frac{3}{6.2} - \\frac{1}{4} \\right) $$\n$$ Q = \\frac{6}{6.2} - \\frac{1}{2} = \\frac{60}{62} - \\frac{1}{2} = \\frac{30}{31} - \\frac{1}{2} $$\n$$ Q = \\frac{60 - 31}{62} = \\frac{29}{62} $$\nThe fraction is irreducible.\nThe aggregation phase would create a new network with two super-nodes, but the modularity of the partition is evaluated on the original graph, which we have just done.",
            "answer": "$$\\boxed{\\frac{29}{62}}$$"
        },
        {
            "introduction": "Finding a single \"optimal\" partition can be misleading, as complex systems often exhibit a degeneracy of high-modularity solutions. This advanced practice  challenges you to computationally demonstrate this phenomenon by constructing distinct partitions with nearly identical modularity scores. Furthermore, it introduces a powerful information-theoretic metric, the Variation of Information ($VI$), to rigorously quantify the structural differences between these alternative system descriptions, moving beyond simple optimization to a more nuanced analysis of system organization.",
            "id": "4126097",
            "problem": "Construct a program that, for a family of graphs exhibiting hierarchical and modular structure, explicitly demonstrates the degeneracy of high modularity by producing distinct community partitions with near-identical modularity and quantifies their difference using Variation of Information. The graphs are rings of cliques and the partitions are: one where each clique is its own module and one where adjacent cliques are merged into larger modules. Your solution must rely only on fundamental definitions and well-tested formulas to compute the required quantities and must not assume any heuristic community detection algorithm.\n\nFundamental base and core definitions to use:\n- Consider an undirected, weighted graph represented by an adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$ with $A_{ij} \\ge 0$ and $A_{ii} = 0$. The degree of node $i$ is $k_i = \\sum_{j=1}^{n} A_{ij}$. The total edge weight is $m = \\tfrac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} A_{ij}$.\n- Given a partition (a community label assignment) $g \\in \\{1,\\dots,G\\}^n$ of the $n$ nodes, define the modularity $Q$ of the partition as\n$$\nQ = \\frac{1}{2m} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left(A_{ij} - \\frac{k_i k_j}{2m}\\right) \\,\\delta(g_i,g_j),\n$$\nwhere $\\delta(g_i,g_j)$ is $1$ if $g_i=g_j$ and $0$ otherwise.\n- Define the Shannon entropy of a partition $X$ with community probabilities $\\{p_c\\}$ as $H(X) = - \\sum_{c} p_c \\ln p_c$. Define the mutual information of partitions $X$ and $Y$ with joint probabilities $\\{p_{cd}\\}$ as $I(X;Y) = \\sum_{c} \\sum_{d} p_{cd} \\ln \\frac{p_{cd}}{p_c p_d}$. The Variation of Information (VI) between partitions $X$ and $Y$ is $VI(X,Y) = H(X) + H(Y) - 2 I(X;Y)$ in natural logarithm units (nats).\n\nGraph family specification:\n- A ring of cliques is parameterized by three integers $(c,s,b)$ with $c$ even. There are $c$ cliques arranged cyclically; each clique is a complete subgraph of $s$ nodes (so the number of internal edges per clique is $e = \\tfrac{s(s-1)}{2}$). Between each pair of adjacent cliques on the ring, exactly $b$ distinct inter-clique edges connect the two cliques. The total number of nodes is $n = c s$. Each inter-clique edge has unit weight, and all internal clique edges have unit weight.\n- You must construct the adjacency matrix $A$ deterministically as follows: for each clique, connect all pairs of distinct nodes within that clique; for each ring adjacency (clique $i$ to clique $(i+1) \\bmod c$), connect node indices $0,1,\\dots,(b-1)$ of clique $i$ to the corresponding indices $0,1,\\dots,(b-1)$ of clique $(i+1) \\bmod c$.\n\nPartitions to compare on the same graph:\n- Partition $\\mathcal{P}_1$: each clique is one community; that is, there are $c$ communities, each of size $s$.\n- Partition $\\mathcal{P}_2$: merge adjacent cliques pairwise; that is, there are $\\tfrac{c}{2}$ communities, each of size $2s$, formed by consecutive pairs $(0,1)$, $(2,3)$, $\\dots$, $(c-2,c-1)$ of cliques.\n\nRequired computations for each parameter set $(c,s,b)$:\n- Compute $Q(\\mathcal{P}_1)$, $Q(\\mathcal{P}_2)$, the absolute difference $\\Delta Q = |Q(\\mathcal{P}_1) - Q(\\mathcal{P}_2)|$, and the Variation of Information $VI(\\mathcal{P}_1,\\mathcal{P}_2)$ in nats.\n- Using a tolerance parameter $\\varepsilon$, determine the boolean degeneracy indicator $D$ defined as $D = (\\Delta Q \\le \\varepsilon)$.\n\nTest suite:\nProvide the following parameter sets and a single tolerance $\\varepsilon$ shared by all cases:\n- Case $1$: $(c,s,b) = (8,3,1)$ with $\\varepsilon = 10^{-2}$.\n- Case $2$: $(c,s,b) = (14,4,1)$ with $\\varepsilon = 10^{-2}$.\n- Case $3$: $(c,s,b) = (20,5,1)$ with $\\varepsilon = 10^{-2}$.\n\nDesign for coverage:\n- Case $1$ demonstrates exact degeneracy of high modularity across distinct partitions for a small clique size.\n- Case $2$ demonstrates exact degeneracy for a larger internal clique size.\n- Case $3$ demonstrates near-degeneracy (nonzero but small $\\Delta Q$) close to the analytic equality condition.\n\nFinal output format:\nYour program should produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets, where each case result is itself a list of the form $[Q(\\mathcal{P}_1),Q(\\mathcal{P}_2),\\Delta Q,VI(\\mathcal{P}_1,\\mathcal{P}_2),D]$. There must be no spaces anywhere in the line. An example schematic format is $[[q_{11},q_{12},dq_1,vi_1,d_1],[q_{21},q_{22},dq_2,vi_2,d_2],[q_{31},q_{32},dq_3,vi_3,d_3]]$ with all values computed by your program.",
            "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in network science, mathematically well-posed, and all terms and procedures are defined unambiguously. The problem is a non-trivial exercise in implementing and interpreting fundamental metrics of network structure and information theory, and the test cases are well-designed to illustrate the scientific concept of modularity degeneracy.\n\nThe core of this problem is to investigate modularity degeneracy in a specific family of synthetic graphs: rings of cliques. This structure is a canonical model for systems with both strong local clustering (modularity, via cliques) and hierarchical organization (cliques forming a larger cyclic structure). Degeneracy, in this context, refers to the existence of multiple, structurally-distinct community partitions that yield nearly identical, high modularity scores. This phenomenon complicates the search for a single \"optimal\" community structure and highlights the complex landscape of modularity optimization.\n\nWe are asked to compare two natural partitions on this graph.\nPartition $\\mathcal{P}_1$ treats each clique as a distinct community. This is a fine-grained partition that emphasizes the most local structure.\nPartition $\\mathcal{P}_2$ merges adjacent pairs of cliques, representing a coarser-grained view of the network's structure.\n\nThe analysis will proceed in two stages: first, an analytical derivation of the required quantities to build a conceptual understanding and to verify the final numerical results; second, the development of a computational algorithm that constructs the graph and computes the metrics from their fundamental definitions.\n\n**Analytical Formulation**\n\nLet the ring of cliques be parameterized by $(c, s, b)$, where $c$ is the number of cliques, $s$ is the size of each clique, and $b$ is the number of edges connecting adjacent cliques. The number of nodes is $n=cs$.\n\nThe total weight of edges, $2m$, is the sum of weights from internal clique edges and inter-clique edges. Each of the $c$ cliques has $\\binom{s}{2}$ edges of weight $1$. There are $c$ connections between adjacent cliques, each with $b$ edges of weight $1$.\n$$2m = c s(s-1) + 2cb = c(s^2-s+2b)$$\n\nNode degrees ($k_i$) depend on whether a node connects to other cliques. There are $b$ \"bridge\" nodes per clique and $s-b$ \"internal\" nodes. A bridge node connects to $s-1$ nodes in its clique and to two nodes in adjacent cliques, so its degree is $k_b = (s-1)+2 = s+1$. An internal node only connects within its clique, so its degree is $k_{int} = s-1$.\n\nThe modularity $Q$ of a partition is given by $Q = \\sum_{k=1}^{G} \\left[ \\frac{L_k}{m} - \\left(\\frac{K_k}{2m}\\right)^2 \\right]$, where $L_k$ is the sum of edge weights within community $k$ and $K_k$ is the sum of degrees of nodes in community $k$.\n\nFor Partition $\\mathcal{P}_1$ ($c$ communities of size $s$):\nEach community is a single clique. By symmetry, all $c$ communities are equivalent. For one such community:\nThe internal weight is $L_1 = s(s-1)/2$.\nThe sum of degrees is $K_1 = b \\cdot k_b + (s-b) \\cdot k_{int} = b(s+1) + (s-b)(s-1) = s^2-s+2b$.\nThe modularity is:\n$$Q(\\mathcal{P}_1) = c \\left[ \\frac{s(s-1)/2}{m} - \\left(\\frac{s^2-s+2b}{2m}\\right)^2 \\right] = c \\left[ \\frac{s(s-1)}{c(s^2-s+2b)} - \\left(\\frac{s^2-s+2b}{c(s^2-s+2b)}\\right)^2 \\right]$$\n$$Q(\\mathcal{P}_1) = \\frac{s(s-1)}{s^2-s+2b} - \\frac{1}{c}$$\n\nFor Partition $\\mathcal{P}_2$ ($c/2$ communities of size $2s$):\nEach community is a pair of adjacent cliques. By symmetry, all $c/2$ communities are equivalent. For one such community:\nThe internal weight is a sum of weights within the two cliques plus the $b$ connecting edges: $L_2 = 2 \\cdot \\frac{s(s-1)}{2} + b = s(s-1)+b$.\nThe sum of degrees is the sum for two cliques: $K_2 = 2(s^2-s+2b)$.\nThe modularity is:\n$$Q(\\mathcal{P}_2) = \\frac{c}{2} \\left[ \\frac{s(s-1)+b}{m} - \\left(\\frac{2(s^2-s+2b)}{2m}\\right)^2 \\right] = \\frac{c}{2} \\left[ \\frac{2(s(s-1)+b)}{c(s^2-s+2b)} - \\left(\\frac{2}{c}\\right)^2 \\right]$$\n$$Q(\\mathcal{P}_2) = \\frac{s(s-1)+b}{s^2-s+2b} - \\frac{2}{c}$$\n\nThe absolute difference in modularity is:\n$$\\Delta Q = |Q(\\mathcal{P}_1) - Q(\\mathcal{P}_2)| = \\left| \\left(\\frac{s(s-1)}{s^2-s+2b} - \\frac{1}{c}\\right) - \\left(\\frac{s(s-1)+b}{s^2-s+2b} - \\frac{2}{c}\\right) \\right|$$\n$$\\Delta Q = \\left| \\frac{-b}{s^2-s+2b} + \\frac{1}{c} \\right|$$\nDegeneracy ($Q(\\mathcal{P}_1) \\approx Q(\\mathcal{P}_2)$) occurs when $\\Delta Q \\approx 0$, which implies $c \\approx \\frac{s^2-s+2b}{b}$. The test cases are chosen to probe this condition. For $b=1$, this simplifies to $c \\approx s^2-s+2$. For cases 1 and 2, this equality holds exactly, leading to $\\Delta Q = 0$. For case 3, $c=20$ while $s^2-s+2 = 22$, yielding a small, non-zero $\\Delta Q$.\n\nThe Variation of Information, $VI(X,Y) = H(X) + H(Y) - 2I(X,Y)$, quantifies the distance between two partitions.\nFor $\\mathcal{P}_1$, there are $c$ communities of equal size $s$. The probability of a node being in any given community is $p_c = s/n = 1/c$. The entropy is $H(\\mathcal{P}_1) = - \\sum_{i=1}^c \\frac{1}{c} \\ln(\\frac{1}{c}) = \\ln c$.\nFor $\\mathcal{P}_2$, there are $c/2$ communities of equal size $2s$. The probability is $p_d = 2s/n = 2/c$. The entropy is $H(\\mathcal{P}_2) = - \\sum_{j=1}^{c/2} \\frac{2}{c} \\ln(\\frac{2}{c}) = \\ln(c/2)$.\nPartition $\\mathcal{P}_1$ is a refinement of $\\mathcal{P}_2$. This means that knowing a node's community in $\\mathcal{P}_1$ determines its community in $\\mathcal{P}_2$. Consequently, the mutual information $I(\\mathcal{P}_1, \\mathcal{P}_2)$ is equal to the entropy of the coarser partition, $H(\\mathcal{P}_2)$.\n$$I(\\mathcal{P}_1, \\mathcal{P}_2) = H(\\mathcal{P}_2) = \\ln(c/2)$$\nSubstituting these into the $VI$ formula:\n$$VI(\\mathcal{P}_1, \\mathcal{P}_2) = H(\\mathcal{P}_1) + H(\\mathcal{P}_2) - 2H(\\mathcal{P}_2) = H(\\mathcal{P}_1) - H(\\mathcal{P}_2) = \\ln c - \\ln(c/2) = \\ln(c / (c/2)) = \\ln 2$$\nThe Variation of Information between these two partitions is a constant, $\\ln 2 \\approx 0.693147$ nats, irrespective of the graph parameters $(c, s, b)$. This indicates that the two partitions are always distinct in a structurally consistent manner, even when their modularity scores are identical.\n\n**Computational Strategy**\n\nThe program will implement the general formulas provided, validating the analytical results.\n1.  **Graph Construction**: For each $(c,s,b)$, an adjacency matrix $A$ of size $n \\times n$ (where $n=cs$) is constructed.\n    - Intra-clique edges: For each clique $i \\in \\{0, \\dots, c-1\\}$, all pairs of nodes with indices from $is$ to $(i+1)s-1$ are connected.\n    - Inter-clique edges: For each clique $i \\in \\{0, \\dots, c-1\\}$ and for each $k \\in \\{0, \\dots, b-1\\}$, an edge is added between node $is+k$ and node $((i+1)\\pmod c)s+k$.\n2.  **Partition Generation**: Two integer arrays, $g_1$ and $g_2$, of length $n$ are created to represent $\\mathcal{P}_1$ and $\\mathcal{P}_2$.\n    - For $\\mathcal{P}_1$: node $i$ is in community $\\lfloor i/s \\rfloor$.\n    - For $\\mathcal{P}_2$: node $i$ is in community $\\lfloor \\lfloor i/s \\rfloor / 2 \\rfloor$.\n3.  **Modularity Calculation**: A function computes $Q$ for a given partition $g$. It first computes the total edge weight $m$ and the degree vector $k$. Then, it calculates the sum:\n    $$Q = \\frac{1}{2m} \\sum_{i,j} \\left(A_{ij} - \\frac{k_i k_j}{2m}\\right) \\delta(g_i, g_j)$$\n    This is implemented efficiently using matrix operations.\n4.  **Variation of Information Calculation**: A function computes $VI(\\mathcal{P}_1, \\mathcal{P}_2)$.\n    - It first computes $H(\\mathcal{P}_1)$ and $H(\\mathcal{P}_2)$ from the community size distributions.\n    - It then computes the joint probability distribution of the two partitions by building a contingency table, which counts how many nodes are shared between each pair of communities from $\\mathcal{P}_1$ and $\\mathcal{P}_2$.\n    - The mutual information $I(\\mathcal{P}_1, \\mathcal{P}_2)$ is calculated from the joint and marginal probabilities. Care is taken to handle terms where probabilities are zero, as $0\\ln 0=0$.\n    - Finally, $VI$ is assembled from $H(\\mathcal{P}_1)$, $H(\\mathcal{P}_2)$, and $I(\\mathcal{P}_1, \\mathcal{P}_2)$.\n5.  **Result Aggregation**: The computed values—$Q(\\mathcal{P}_1)$, $Q(\\mathcal{P}_2)$, $\\Delta Q = |Q(\\mathcal{P}_1)-Q(\\mathcal{P}_2)|$, $VI(\\mathcal{P}_1, \\mathcal{P}_2)$, and the boolean degeneracy indicator $D = (\\Delta Q \\le \\varepsilon)$—are collected for each test case and formatted into the required output string.\n\nThis computational approach, while more demanding than using the analytical formulas directly, robustly verifies the principles from first definitions and adheres to the problem's implied methodology of starting from the constructed adjacency matrix.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef compute_modularity(A, k, m, partition):\n    \"\"\"\n    Computes the modularity of a given partition on a graph.\n    \n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        k (np.ndarray): The degree vector of the graph nodes.\n        m (float): The total edge weight of the graph.\n        partition (np.ndarray): An array where partition[i] is the community ID of node i.\n        \n    Returns:\n        float: The modularity Q.\n    \"\"\"\n    if m == 0:\n        return 0.0\n    \n    n = A.shape[0]\n    Q = 0.0\n    for i in range(n):\n        for j in range(n):\n            if partition[i] == partition[j]:\n                Q += (A[i, j] - (k[i] * k[j]) / (2 * m))\n    \n    return Q / (2 * m)\n\ndef compute_vi(p1, p2):\n    \"\"\"\n    Computes the Variation of Information between two partitions.\n    \n    Args:\n        p1 (np.ndarray): The first partition vector.\n        p2 (np.ndarray): The second partition vector.\n        \n    Returns:\n        float: The Variation of Information in nats.\n    \"\"\"\n    n = len(p1)\n    if n == 0:\n        return 0.0\n\n    # Entropy H(P1)\n    _, counts1 = np.unique(p1, return_counts=True)\n    probs1 = counts1 / n\n    h1 = -np.sum(probs1 * np.log(probs1))\n\n    # Entropy H(P2)\n    _, counts2 = np.unique(p2, return_counts=True)\n    probs2 = counts2 / n\n    h2 = -np.sum(probs2 * np.log(probs2))\n\n    # Mutual Information I(P1, P2)\n    # Use unique inverse to handle non-contiguous community labels\n    c1_labels, c1_inverse = np.unique(p1, return_inverse=True)\n    c2_labels, c2_inverse = np.unique(p2, return_inverse=True)\n    nc1 = len(c1_labels)\n    nc2 = len(c2_labels)\n\n    contingency = np.zeros((nc1, nc2), dtype=float)\n    np.add.at(contingency, (c1_inverse, c2_inverse), 1)\n    \n    joint_probs = contingency / n\n    \n    # Marginal probabilities can be re-derived from joint_probs\n    p1_marginal = np.sum(joint_probs, axis=1)\n    p2_marginal = np.sum(joint_probs, axis=0)\n\n    # Compute I(P1, P2)\n    I = 0.0\n    outer_prod = np.outer(p1_marginal, p2_marginal)\n    # Mask for non-zero joint probabilities to avoid log(0)\n    nz_mask = joint_probs > 0\n    I = np.sum(joint_probs[nz_mask] * np.log(joint_probs[nz_mask] / outer_prod[nz_mask]))\n\n    # VI(P1, P2) = H(P1) + H(P2) - 2*I(P1, P2)\n    vi = h1 + h2 - 2 * I\n    return vi\n\ndef process_case(params):\n    \"\"\"\n    Processes a single case, computes all required quantities.\n    \n    Args:\n        params (tuple): A tuple (c, s, b, epsilon).\n        \n    Returns:\n        list: A list containing [Q1, Q2, dQ, VI, D].\n    \"\"\"\n    c, s, b, epsilon = params\n    n = c * s\n    \n    # 1. Construct adjacency matrix A\n    A = np.zeros((n, n), dtype=float)\n    \n    # Intra-clique edges\n    for i in range(c):\n        start_node = i * s\n        end_node = (i + 1) * s\n        for u in range(start_node, end_node):\n            for v in range(u + 1, end_node):\n                A[u, v] = 1.0\n                A[v, u] = 1.0\n    \n    # Inter-clique edges\n    for i in range(c):\n        clique1_idx = i\n        clique2_idx = (i + 1) % c\n        for k in range(b):\n            node1 = clique1_idx * s + k\n            node2 = clique2_idx * s + k\n            A[node1, node2] = 1.0\n            A[node2, node1] = 1.0\n\n    # 2. Calculate graph-wide properties\n    k = A.sum(axis=1)\n    m = k.sum() / 2.0\n\n    # 3. Define partitions\n    nodes = np.arange(n)\n    p1 = nodes // s\n    p2 = (nodes // s) // 2\n\n    # 4. Compute modularities\n    q1 = compute_modularity(A, k, m, p1)\n    q2 = compute_modularity(A, k, m, p2)\n    delta_q = abs(q1 - q2)\n    degeneracy_indicator = delta_q = epsilon\n    \n    # 5. Compute Variation of Information\n    vi = compute_vi(p1, p2)\n    \n    return [q1, q2, delta_q, vi, degeneracy_indicator]\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        (8, 3, 1, 1e-2),  # Case 1\n        (14, 4, 1, 1e-2), # Case 2\n        (20, 5, 1, 1e-2)  # Case 3\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    # Format the output string to strictly match requirements (no spaces)\n    result_strings = []\n    for res in results:\n        # Convert each element to string, bool becomes 'True'/'False'\n        # The list comprehension handles the formatting of each value\n        # to achieve a compact string representation.\n        s_list = [str(v) for v in res]\n        result_strings.append(f\"[{','.join(s_list)}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n\n```"
        }
    ]
}