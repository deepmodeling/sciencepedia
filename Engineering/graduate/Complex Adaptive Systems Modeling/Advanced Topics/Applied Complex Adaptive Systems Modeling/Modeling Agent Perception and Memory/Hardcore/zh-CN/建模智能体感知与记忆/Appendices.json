{
    "hands_on_practices": [
        {
            "introduction": "在智能体能够理解世界之前，它必须首先了解其自身传感器的特性。本练习深入探讨了校准传感器噪声特性的基本统计问题。通过推导噪声协方差矩阵的最大似然估计（MLE），您将亲身体验多元统计的核心原理，并理解我们如何从原始数据中建立感知不确定性的形式化模型。",
            "id": "4128168",
            "problem": "一个复杂自适应系统中的智能体使用一个 $p$ 维传感器来感知环境特征。在校准过程中，该智能体观察 $J$ 个静态校准目标，索引为 $j \\in \\{1,\\dots,J\\}$。每个目标都有一个已知的潜在状态 $\\mathbf{s}_j$ 和一个已知的前向观测映射 $h(\\cdot)$，该映射预测一个无噪声测量值 $\\boldsymbol{\\mu}_j = h(\\mathbf{s}_j) \\in \\mathbb{R}^p$。对于目标 $j$，该智能体收集 $n_j$ 次重复测量 $\\{\\mathbf{z}_{j,k}\\}_{k=1}^{n_j}$。这些测量值被建模为来自均值为 $\\boldsymbol{\\mu}_j$、未知对称正定协方差矩阵为 $R \\in \\mathbb{R}^{p \\times p}$ 的多元正态分布的独立抽取，即 $\\mathbf{z}_{j,k} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_j, R)$，且在 $j$ 和 $k$ 上独立。定义残差 $\\mathbf{r}_{j,k} = \\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j$，并令总样本量为 $N = \\sum_{j=1}^J n_j$。\n\n从多元正态性下的似然定义和最大似然估计量 (MLE) 的定义出发，推导出用于从这些重复测量中校准传感器噪声协方差的估计量 $\\hat{R}$。然后，通过表示 $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R)$ 的极限分布，利用 MLE 的渐近正态性来量化 $\\hat{R}$ 中的不确定性，其中 $\\mathrm{vec}(\\cdot)$ 表示向量化。在你的推导中，请使用以下基本事实：\n- 对于 $\\mathbf{z} \\in \\mathbb{R}^p$，其均值为 $\\boldsymbol{\\mu} \\in \\mathbb{R}^p$，协方差为 $R \\in \\mathbb{R}^{p \\times p}$ 的多元正态概率密度函数是 $f(\\mathbf{z}; \\boldsymbol{\\mu}, R) = \\frac{1}{(2\\pi)^{p/2} |R|^{1/2}} \\exp\\left(-\\frac{1}{2} (\\mathbf{z} - \\boldsymbol{\\mu})^\\top R^{-1} (\\mathbf{z} - \\boldsymbol{\\mu})\\right)$。\n- 最大似然估计量 (MLE) 是通过最大化独立样本的联合似然得到的。\n- 在正则性条件下，MLE 是一致的且是渐近正态的，其协方差由费雪信息的逆给出，其中费雪信息定义为 $I(\\theta) = \\mathbb{E}\\left[-\\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta \\partial \\theta^\\top}\\right]$，$\\ell(\\theta)$ 是对数似然。\n\n对于渐近协方差，你可以使用标准的线性代数算子来表示结果：\n- $\\mathrm{vec}(\\cdot)$ 是向量化算子。\n- $\\otimes$ 是克罗内克积。\n- $K_p \\in \\mathbb{R}^{p^2 \\times p^2}$ 是交换矩阵，其定义为对于任意 $A \\in \\mathbb{R}^{p \\times p}$，有 $K_p\\,\\mathrm{vec}(A) = \\mathrm{vec}(A^\\top)$。\n- $\\mathrm{vech}(\\cdot)$ 是半向量化，它将对称矩阵的上三角元素堆叠起来。\n- $D_p \\in \\mathbb{R}^{p^2 \\times p(p+1)/2}$ 是复制矩阵，它满足对于任意对称矩阵 $S \\in \\mathbb{R}^{p \\times p}$，有 $\\mathrm{vec}(S) = D_p\\,\\mathrm{vech}(S)$。\n\n最后，找出唯一一个同时正确陈述了 MLE $\\hat{R}$ 和 $\\mathrm{vec}(\\hat{R})$（或等价地，通过复制矩阵得到的 $\\mathrm{vech}(\\hat{R})$）的有效渐近协方差的选项。只选择一个选项。\n\nA. $\\hat{R} = \\frac{1}{N} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top$，并且 $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}\\!\\left(\\mathbf{0},\\,(I_p + K_p)\\,(R \\otimes R)\\right)$；等价地，对于 $\\mathrm{vech}$，渐近协方差为 $I_{\\mathrm{sym}}^{-1}$，其中 $I_{\\mathrm{sym}} = \\frac{N}{2} D_p^\\top (R^{-1} \\otimes R^{-1}) D_p$，因此 $\\mathrm{vech}(R)$ 的一个近似 $(1-\\alpha)$ 置信椭球是 $\\left\\{\\theta \\in \\mathbb{R}^{p(p+1)/2} : (\\theta - \\mathrm{vech}(\\hat{R}))^\\top I_{\\mathrm{sym}}\\,(\\theta - \\mathrm{vech}(\\hat{R})) \\leq \\chi^2_{p(p+1)/2,\\,1-\\alpha}\\right\\}$。\n\nB. $\\hat{R} = \\frac{1}{N-1} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top$，并且 $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}\\!\\left(\\mathbf{0},\\, (R^{-1} \\otimes R^{-1})\\right)$；因此 $\\mathrm{vec}(\\hat{R})$ 的渐近协方差是 $\\frac{1}{N}(R^{-1} \\otimes R^{-1})$。\n\nC. $\\hat{R} = \\frac{1}{J} \\sum_{j=1}^{J} \\left(\\frac{1}{n_j} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top\\right)$，并且 $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}\\!\\left(\\mathbf{0},\\, \\frac{1}{\\sum_{j=1}^{J} n_j^2}\\,(I_p + K_p)\\,(R \\otimes R)\\right)$。\n\nD. $\\hat{R} = \\frac{1}{N} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} (\\mathbf{z}_{j,k} - \\bar{\\mathbf{z}})\\,(\\mathbf{z}_{j,k} - \\bar{\\mathbf{z}})^\\top$，其中 $\\bar{\\mathbf{z}} = \\frac{1}{N}\\sum_{j=1}^{J}\\sum_{k=1}^{n_j}\\mathbf{z}_{j,k}$，并且 $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}\\!\\left(\\mathbf{0},\\, (R \\otimes R)\\right)$；因此 $\\mathrm{vec}(\\hat{R})$ 的渐近协方差是 $\\frac{1}{N}(R \\otimes R)$。",
            "solution": "### 步骤 1：提取已知条件\n\n问题陈述提供了以下信息：\n- 一个智能体使用一个 $p$ 维传感器。\n- 有 $J$ 个静态校准目标，索引为 $j \\in \\{1,\\dots,J\\}$。\n- 每个目标 $j$ 有一个已知的潜在状态 $\\mathbf{s}_j$ 和一个已知的前向观测映射 $h(\\cdot)$。\n- 目标 $j$ 的无噪声测量（均值）是已知的，由 $\\boldsymbol{\\mu}_j = h(\\mathbf{s}_j) \\in \\mathbb{R}^p$ 给出。\n- 对每个目标 $j$，收集了 $n_j$ 次重复测量：$\\{\\mathbf{z}_{j,k}\\}_{k=1}^{n_j}$。\n- 测量值被建模为来自多元正态分布的独立抽取：$\\mathbf{z}_{j,k} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_j, R)$。\n- 协方差矩阵 $R \\in \\mathbb{R}^{p \\times p}$ 是未知的、对称正定的，并且对所有测量都相同。\n- 样本在索引 $j$ 和 $k$ 上都是独立的。\n- 残差定义为 $\\mathbf{r}_{j,k} = \\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j$。\n- 总样本量为 $N = \\sum_{j=1}^J n_j$。\n- 对于 $\\mathbf{z} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, R)$ 的概率密度函数是 $f(\\mathbf{z}; \\boldsymbol{\\mu}, R) = \\frac{1}{(2\\pi)^{p/2} |R|^{1/2}} \\exp\\left(-\\frac{1}{2} (\\mathbf{z} - \\boldsymbol{\\mu})^\\top R^{-1} (\\mathbf{z} - \\boldsymbol{\\mu})\\right)$。\n- 提供了 MLE、费雪信息及其与渐近正态性关系的标准定义。\n- 定义了标准矩阵算子：$\\mathrm{vec}(\\cdot)$, $\\otimes$, $K_p$, $\\mathrm{vech}(\\cdot)$, $D_p$。\n\n### 步骤 2：使用提取的已知条件进行验证\n\n- **科学基础**：该问题牢固地植根于多元正态分布参数的最大似然估计理论。这是统计学中一个基础且完善的课题。提到的所有概念和工具都是该领域的标准。该设置在科学和数学上是合理的。\n- **良态问题**：问题是推导一个特定的估计量（$\\hat{R}$）及其渐近性质。给定的条件足以完成此推导。在标准正则性条件下，存在唯一的 MLE，其渐近性质是明确定义的，这通过提及渐近正态性得到了隐含的假设。\n- **客观性**：语言精确、数学化，没有任何主观性或模糊性。\n\n该问题是多元统计推断中的一个标准练习。它完整、一致且科学上合理。没有发现任何缺陷。\n\n### 步骤 3：结论和行动\n\n问题陈述是 **有效的**。开始求解。\n\n### MLE $\\hat{R}$ 的推导\n\n所有观测值的集合是 $\\{\\mathbf{z}_{j,k}\\}_{j=1, k=1}^{J, n_j}$。由于观测值是独立的，联合似然函数 $L(R)$ 是各个概率密度的乘积。\n$$ L(R) = \\prod_{j=1}^{J} \\prod_{k=1}^{n_j} f(\\mathbf{z}_{j,k}; \\boldsymbol{\\mu}_j, R) $$\n对数似然函数 $\\ell(R) = \\ln L(R)$ 为：\n$$ \\ell(R) = \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\ln f(\\mathbf{z}_{j,k}; \\boldsymbol{\\mu}_j, R) $$\n代入多元正态 PDF：\n$$ \\ell(R) = \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\left[ -\\frac{p}{2} \\ln(2\\pi) - \\frac{1}{2}\\ln|R| - \\frac{1}{2} (\\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j)^\\top R^{-1} (\\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j) \\right] $$\n设 $N = \\sum_{j=1}^J n_j$ 为总样本数。合并各项：\n$$ \\ell(R) = -\\frac{Np}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|R| - \\frac{1}{2} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} (\\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j)^\\top R^{-1} (\\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j) $$\n使用迹的性质 $\\mathbf{x}^\\top A \\mathbf{x} = \\mathrm{tr}(\\mathbf{x}^\\top A \\mathbf{x}) = \\mathrm{tr}(A\\mathbf{x}\\mathbf{x}^\\top)$ 以及残差的定义 $\\mathbf{r}_{j,k} = \\mathbf{z}_{j,k} - \\boldsymbol{\\mu}_j$：\n$$ \\ell(R) = C - \\frac{N}{2}\\ln|R| - \\frac{1}{2} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathrm{tr}(R^{-1} \\mathbf{r}_{j,k}\\mathbf{r}_{j,k}^\\top) $$\n$$ \\ell(R) = C - \\frac{N}{2}\\ln|R| - \\frac{1}{2} \\mathrm{tr}\\left(R^{-1} \\left(\\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\mathbf{r}_{j,k}^\\top\\right)\\right) $$\n令 $S_r = \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\mathbf{r}_{j,k}^\\top$。这是残差平方和矩阵。\n为了找到最大值，我们将 $\\ell(R)$ 对 $R$ 求导，并令导数等于零。使用标准的矩阵微积分求导法则 $\\frac{\\partial \\ln|R|}{\\partial R} = (R^{-1})^\\top = R^{-1}$ 和 $\\frac{\\partial \\mathrm{tr}(AR^{-1})}{\\partial R} = -(R^{-1}AR^{-1})^\\top = -R^{-1}AR^{-1}$（对于对称的 $A, R$）：\n$$ \\frac{\\partial \\ell(R)}{\\partial R} = -\\frac{N}{2}R^{-1} - \\frac{1}{2} (-R^{-1}S_r R^{-1}) = \\frac{1}{2}R^{-1}(S_r - NR)R^{-1} $$\n将梯度设为零：\n$$ \\frac{1}{2}\\hat{R}^{-1}(S_r - N\\hat{R})\\hat{R}^{-1} = 0 $$\n由于 $\\hat{R}^{-1}$ 是可逆的，这意味着 $S_r - N\\hat{R} = 0$，从而得出最大似然估计量 (MLE)：\n$$ \\hat{R} = \\frac{1}{N} S_r = \\frac{1}{N} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\mathbf{r}_{j,k}^\\top $$\n\n### $\\hat{R}$ 的渐近分布\n\nMLE 的渐近分布由费雪信息矩阵的逆决定。对于参数向量 $\\theta$ 的 MLE $\\hat{\\theta}$，在正则性条件下，$\\sqrt{N}(\\hat{\\theta} - \\theta) \\xrightarrow{d} \\mathcal{N}(0, I_1(\\theta)^{-1})$，其中 $I_1(\\theta)$ 是单个观测值的费雪信息。\n\n我们感兴趣的参数是对称矩阵 $R$ 的唯一元素，记为 $\\theta = \\mathrm{vech}(R)$，它是一个长度为 $p(p+1)/2$ 的向量。\n多元分析中的一个标准结果给出了单个来自 $\\mathcal{N}(\\boldsymbol{\\mu}, R)$（其中 $\\boldsymbol{\\mu}$ 已知）的观测值关于 $\\mathrm{vech}(R)$ 的费雪信息矩阵为：\n$$ I_1(\\mathrm{vech}(R)) = \\frac{1}{2} D_p^\\top (R^{-1} \\otimes R^{-1}) D_p $$\n其中 $D_p$ 是复制矩阵。\n$\\sqrt{N}(\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R))$ 的渐近协方差因此是 $I_1(\\mathrm{vech}(R))^{-1}$。\n$$ \\mathrm{AsyCov}(\\sqrt{N}(\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R))) = \\left( \\frac{1}{2} D_p^\\top (R^{-1} \\otimes R^{-1}) D_p \\right)^{-1} = 2 \\left( D_p^\\top (R^{-1} \\otimes R^{-1}) D_p \\right)^{-1} $$\n使用此类矩阵逆的恒等式，$(D_p^\\top(A \\otimes A)D_p)^{-1} = D_p^+(A^{-1} \\otimes A^{-1})(D_p^+)^\\top$，其中 $D_p^+ = (D_p^\\top D_p)^{-1}D_p^\\top$ 是 $D_p$ 的 Moore-Penrose 逆：\n$$ \\mathrm{AsyCov}(\\sqrt{N}(\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R))) = 2 D_p^+ (R \\otimes R) (D_p^+)^\\top $$\n我们需要 $\\sqrt{N}(\\mathrm{vec}(\\hat{R}) - \\mathrm{vec}(R))$ 的渐近协方差。我们使用关系式 $\\mathrm{vec}(A) = D_p \\mathrm{vech}(A)$ 对于任何对称矩阵 $A$。\n$$ \\sqrt{N}(\\mathrm{vec}(\\hat{R}) - \\mathrm{vec}(R)) = \\sqrt{N} D_p (\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R)) $$\n这个变换后向量的协方差是：\n$$ \\mathrm{AsyCov}(\\sqrt{N}(\\mathrm{vec}(\\hat{R}) - \\mathrm{vec}(R))) = D_p \\left( 2 D_p^+ (R \\otimes R) (D_p^+)^\\top \\right) D_p^\\top $$\n使用恒等式 $D_p D_p^+ = \\frac{1}{2}(I_{p^2} + K_p)$，其中 $K_p$ 是交换矩阵：\n$$ = 2 (D_p D_p^+) (R \\otimes R) (D_p D_p^+)^\\top $$\n$$ = 2 \\left( \\frac{1}{2}(I_{p^2} + K_p) \\right) (R \\otimes R) \\left( \\frac{1}{2}(I_{p^2} + K_p) \\right)^\\top $$\n由于 $K_p$ 是对称的（$K_p^\\top=K_p$），这可以简化为：\n$$ = \\frac{1}{2} (I_{p^2} + K_p) (R \\otimes R) (I_{p^2} + K_p) $$\n对于像 $R$ 这样的对称矩阵，有 $(R \\otimes R)K_p = K_p(R \\otimes R)$。并且，$K_p^2=I_{p^2}$。\n$$ = \\frac{1}{2} (I_{p^2} + 2K_p + K_p^2) (R \\otimes R) $$\n$$ = \\frac{1}{2} (2I_{p^2} + 2K_p) (R \\otimes R) = (I_{p^2} + K_p) (R \\otimes R) $$\n因此，极限分布为：\n$$ \\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}(\\mathbf{0}, (I_p + K_p)(R \\otimes R)) $$\n\n### 选项评估\n\n- **选项 A**:\n  - MLE: $\\hat{R} = \\frac{1}{N} \\sum_{j=1}^{J} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top$。这与我们推导出的 MLE 相符。\n  - 渐近分布: $\\sqrt{N}\\,\\mathrm{vec}(\\hat{R} - R) \\xrightarrow{d} \\mathcal{N}\\!\\left(\\mathbf{0},\\,(I_p + K_p)\\,(R \\otimes R)\\right)$。这与我们推导出的渐近协方差相符。\n  - 置信椭球: 对于大小为 $N$ 的样本，参数向量 $\\theta = \\mathrm{vech}(R)$ 的总费雪信息是 $I_N(\\theta) = N \\cdot I_1(\\theta)$。使用我们之前对 $I_1$ 的结果：\n    $$ I_{\\mathrm{sym}} = I_N(\\mathrm{vech}(R)) = N \\left( \\frac{1}{2} D_p^\\top (R^{-1} \\otimes R^{-1}) D_p \\right) = \\frac{N}{2} D_p^\\top (R^{-1} \\otimes R^{-1}) D_p $$\n    这与选项中 $I_{\\mathrm{sym}}$ 的定义相符。$\\mathrm{vech}(\\hat{R})$ 的渐近分布是 $\\mathcal{N}(\\mathrm{vech}(R), I_{\\mathrm{sym}}^{-1})$。利用这一点，二次型 $(\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R))^\\top I_{\\mathrm{sym}} (\\mathrm{vech}(\\hat{R}) - \\mathrm{vech}(R))$ 渐近服从自由度为 $p(p+1)/2$ 的 $\\chi^2$ 分布。这构成了 $\\mathrm{vech}(R)$ 的置信椭球的基础。所给出的表达式对于一个 $(1-\\alpha)$ 置信椭球是正确的。\n  - 结论: **正确**。\n\n- **选项 B**:\n  - MLE: $\\hat{R} = \\frac{1}{N-1} \\sum \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top$。归一化因子是 $N-1$，这在均值也需要估计时是无偏估计量的典型特征。由于均值 $\\boldsymbol{\\mu}_j$ 是已知的，MLE 的因子是 $N$。这个估计量是错误的。\n  - 渐近协方差: 形式 $\\frac{1}{N}(R^{-1} \\otimes R^{-1})$ 是错误的。对 $R$ 的估计量的协方差必须与 $R$ 的幂成比例，而不是 $R^{-1}$。\n  - 结论: **错误**。\n\n- **选项 C**:\n  - MLE: $\\hat{R} = \\frac{1}{J} \\sum_{j=1}^{J} \\left(\\frac{1}{n_j} \\sum_{k=1}^{n_j} \\mathbf{r}_{j,k}\\,\\mathbf{r}_{j,k}^\\top\\right)$。这是对每个目标的协方差估计的未加权平均。真正的 MLE 会汇集所有 $N$ 个数据点，实际上是按样本量 $n_j$ 对每个目标的估计进行加权。这个估计量只有在所有 $n_j$ 都相等时才是正确的。在一般情况下，它不是 MLE。\n  - 渐近协方差: 缩放因子不正确。\n  - 结论: **错误**。\n\n- **选项 D**:\n  - MLE: $\\hat{R} = \\frac{1}{N} \\sum_{j,k} (\\mathbf{z}_{j,k} - \\bar{\\mathbf{z}})\\,(\\mathbf{z}_{j,k} - \\bar{\\mathbf{z}})^\\top$。这个估计量错误地假设所有观测值共享一个单一的共同均值，并将其估计为 $\\bar{\\mathbf{z}}$。问题陈述中指出，观测值来自具有已知、不同均值 $\\boldsymbol{\\mu}_j$ 的不同总体。因此这个估计量是错误的。\n  - 渐近协方差: 表达式 $(R \\otimes R)$ 缺少了 $(I_p + K_p)$ 因子，该因子对于考虑 $R$ 的对称性是必要的。\n  - 结论: **错误**。\n\n根据推导，只有选项 A 提供了正确的 MLE、其向量化形式的正确渐近分布，以及相应置信椭球的正确公式。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "复杂系统中的智能体很少拥有完美的世界模型。本实践通过考察一个具有错误感知模型的智能体，探讨了这种不完美性带来的后果。您将计算智能体的有偏后验信念，并使用Kullback-Leibler（KL）散度来量化其与“真实”后验信念的偏差，从而为认知偏差导致的信息损失提供一个具体的衡量标准。",
            "id": "4128046",
            "problem": "考虑一个复杂自适应系统中的单代理贝叶斯估计器，它必须从单个线索 $y$ 推断潜在刺激 $s \\in \\mathbb{R}$。该代理对 $s$ 维持一个基于记忆的先验，由均值为 $m_{0}$、方差为 $v_{0}$ 的高斯分布给出。物理环境根据一个真实的似然函数生成线索，该似然函数是均值为 $s$、方差为 $\\sigma_{\\text{true}}^{2}$ 的高斯分布。然而，由于感知偏差和不完美的内部建模，该代理使用了一个错误设定的似然函数，该函数是均值为 $s + b$（一个固定的移位偏差）、方差为 $\\sigma_{\\text{mis}}^{2}$ 的高斯分布。给定以下参数值：$m_{0} = 0$，$v_{0} = 1$，$\\sigma_{\\text{true}}^{2} = 1$，$\\sigma_{\\text{mis}}^{2} = 4$，$b = 0.5$ 以及一个实现的线索 $y = 1$。\n\n仅从贝叶斯规则和高斯概率密度函数的定义出发，首先通过配方法推导出真实后验概率 $p_{\\text{T}}(s \\mid y)$ 和代理的错误设定后验概率 $p_{\\text{A}}(s \\mid y)$ 为高斯密度，并明确指出它们的均值和方差。然后，使用Kullback-Leibler散度（KLD）的定义，计算从真实后验到代理后验的散度 $D_{\\mathrm{KL}}(p_{\\text{T}}(\\cdot \\mid y) \\,\\|\\, p_{\\text{A}}(\\cdot \\mid y))$，结果为一个标量值。\n\n将最终数值答案四舍五入到 $4$ 位有效数字。将最终结果表示为一个无单位的纯数。",
            "solution": "问题要求推导一个真实后验分布和一个错误设定的后验分布，然后计算它们之间的Kullback-Leibler（KL）散度。分析从贝叶斯规则开始，该规则指出后验概率与似然和先验的乘积成正比：$p(s \\mid y) \\propto p(y \\mid s) p(s)$。由于所涉及的所有分布都是高斯分布，它们的乘积也将是高斯分布。对于一个均值为 $\\mu$、方差为 $\\sigma^2$ 的变量 $x$，其高斯概率密度函数（PDF）由 $\\mathcal{N}(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$ 给出。\n\n我们可以通过检查后验概率的对数来找到后验高斯分布的参数，该对数是潜在变量 $s$ 的二次函数。\n$\\ln p(s \\mid y) = \\ln p(y \\mid s) + \\ln p(s) + \\text{constant}$。\n后验概率对数中与 $s$ 相关的项具有以下形式：\n$$ \\ln p(s \\mid y) = -\\frac{(s-\\mu_{\\text{post}})^2}{2v_{\\text{post}}} + C = -\\frac{1}{2v_{\\text{post}}}s^2 + \\frac{\\mu_{\\text{post}}}{v_{\\text{post}}}s - \\frac{\\mu_{\\text{post}}^2}{2v_{\\text{post}}} + C $$\n其中 $\\mu_{\\text{post}}$ 和 $v_{\\text{post}}$ 分别是后验均值和后验方差。通过组合对数似然和对数先验，然后匹配 $s^2$ 和 $s$ 的系数，我们可以推导出后验参数。\n\n问题给出的先验为 $p(s) = \\mathcal{N}(s \\mid m_0, v_0)$，其中 $m_0=0$ 且 $v_0=1$。\n对数先验为 $\\ln p(s) = -\\frac{(s-m_0)^2}{2v_0} + C_1$。\n\n首先，我们推导真实后验 $p_{\\text{T}}(s \\mid y)$。\n真实似然为 $p_{\\text{T}}(y \\mid s) = \\mathcal{N}(y \\mid s, \\sigma_{\\text{true}}^2)$，其中 $\\sigma_{\\text{true}}^2=1$。\n对数似然为 $\\ln p_{\\text{T}}(y \\mid s) = -\\frac{(y-s)^2}{2\\sigma_{\\text{true}}^2} + C_2$。\n对数后验为：\n$$ \\ln p_{\\text{T}}(s \\mid y) \\propto -\\frac{(s-m_0)^2}{2v_0} - \\frac{(y-s)^2}{2\\sigma_{\\text{true}}^2} $$\n$$ = -\\frac{1}{2}\\left( \\frac{s^2 - 2sm_0 + m_0^2}{v_0} + \\frac{s^2 - 2sy + y^2}{\\sigma_{\\text{true}}^2} \\right) $$\n按 $s$ 的幂次分组各项：\n$$ = -\\frac{1}{2}\\left[ s^2\\left(\\frac{1}{v_0} + \\frac{1}{\\sigma_{\\text{true}}^2}\\right) - 2s\\left(\\frac{m_0}{v_0} + \\frac{y}{\\sigma_{\\text{true}}^2}\\right) \\right] + \\text{constant} $$\n将其与对数高斯分布的一般形式进行比较，我们确定真实后验方差 $v_{\\text{T}}$ 的倒数和均值 $m_{\\text{T}}$：\n$$ \\frac{1}{v_{\\text{T}}} = \\frac{1}{v_0} + \\frac{1}{\\sigma_{\\text{true}}^2} \\implies v_{\\text{T}} = \\left(\\frac{1}{v_0} + \\frac{1}{\\sigma_{\\text{true}}^2}\\right)^{-1} $$\n$$ \\frac{m_{\\text{T}}}{v_{\\text{T}}} = \\frac{m_0}{v_0} + \\frac{y}{\\sigma_{\\text{true}}^2} \\implies m_{\\text{T}} = v_{\\text{T}}\\left(\\frac{m_0}{v_0} + \\frac{y}{\\sigma_{\\text{true}}^2}\\right) $$\n代入给定值 $m_0=0, v_0=1, \\sigma_{\\text{true}}^2=1, y=1$：\n$$ v_{\\text{T}} = \\left(\\frac{1}{1} + \\frac{1}{1}\\right)^{-1} = (2)^{-1} = 0.5 $$\n$$ m_{\\text{T}} = 0.5 \\left(\\frac{0}{1} + \\frac{1}{1}\\right) = 0.5(1) = 0.5 $$\n因此，真实后验为 $p_{\\text{T}}(s \\mid y) = \\mathcal{N}(s \\mid m_{\\text{T}}, v_{\\text{T}}) = \\mathcal{N}(s \\mid 0.5, 0.5)$。\n\n接下来，我们推导代理的错误设定后验 $p_{\\text{A}}(s \\mid y)$。\n代理使用相同的先验 $p(s) = \\mathcal{N}(s \\mid m_0, v_0)$，但使用错误设定的似然 $p_{\\text{A}}(y \\mid s) = \\mathcal{N}(y \\mid s+b, \\sigma_{\\text{mis}}^2)$，其中 $b=0.5$ 且 $\\sigma_{\\text{mis}}^2=4$。\n代理使用的对数似然为 $\\ln p_{\\text{A}}(y \\mid s) = -\\frac{(y-(s+b))^2}{2\\sigma_{\\text{mis}}^2} + C_3 = -\\frac{((y-b)-s)^2}{2\\sigma_{\\text{mis}}^2} + C_3$。\n这与真实似然具有相同的函数形式，但观测值 $y$ 被替换为“有效观测值” $y' = y-b$，方差 $\\sigma_{\\text{true}}^2$ 被替换为 $\\sigma_{\\text{mis}}^2$。\n推导结构是相同的。代理的后验方差 $v_{\\text{A}}$ 和均值 $m_{\\text{A}}$ 为：\n$$ v_{\\text{A}} = \\left(\\frac{1}{v_0} + \\frac{1}{\\sigma_{\\text{mis}}^2}\\right)^{-1} $$\n$$ m_{\\text{A}} = v_{\\text{A}}\\left(\\frac{m_0}{v_0} + \\frac{y-b}{\\sigma_{\\text{mis}}^2}\\right) $$\n代入给定值 $m_0=0, v_0=1, \\sigma_{\\text{mis}}^2=4, b=0.5, y=1$：\n$$ v_{\\text{A}} = \\left(\\frac{1}{1} + \\frac{1}{4}\\right)^{-1} = \\left(\\frac{5}{4}\\right)^{-1} = \\frac{4}{5} = 0.8 $$\n$$ m_{\\text{A}} = 0.8 \\left(\\frac{0}{1} + \\frac{1-0.5}{4}\\right) = 0.8 \\left(\\frac{0.5}{4}\\right) = 0.8(0.125) = 0.1 $$\n因此，代理的后验为 $p_{\\text{A}}(s \\mid y) = \\mathcal{N}(s \\mid m_{\\text{A}}, v_{\\text{A}}) = \\mathcal{N}(s \\mid 0.1, 0.8)$。\n\n最后，我们计算从真实后验到代理后验的KL散度 $D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}})$。\n对于两个一维高斯分布 $p_1 = \\mathcal{N}(\\mu_1, v_1)$ 和 $p_2 = \\mathcal{N}(\\mu_2, v_2)$，KL散度由以下公式给出：\n$$ D_{\\mathrm{KL}}(p_1 \\| p_2) = \\frac{1}{2} \\left( \\ln\\left(\\frac{v_2}{v_1}\\right) - 1 + \\frac{v_1}{v_2} + \\frac{(\\mu_1-\\mu_2)^2}{v_2} \\right) $$\n在我们的情况下，$p_1$ 是真实后验 $p_{\\text{T}}$，$p_2$ 是代理的后验 $p_{\\text{A}}$。参数为：\n$\\mu_1 = m_{\\text{T}} = 0.5$, $v_1 = v_{\\text{T}} = 0.5$\n$\\mu_2 = m_{\\text{A}} = 0.1$, $v_2 = v_{\\text{A}} = 0.8$\n\n将这些值代入KL散度公式：\n$$ D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}}) = \\frac{1}{2} \\left( \\ln\\left(\\frac{0.8}{0.5}\\right) - 1 + \\frac{0.5}{0.8} + \\frac{(0.5-0.1)^2}{0.8} \\right) $$\n我们计算括号内的每一项：\n$$ \\frac{v_{\\text{A}}}{v_{\\text{T}}} = \\frac{0.8}{0.5} = 1.6 $$\n$$ \\frac{v_{\\text{T}}}{v_{\\text{A}}} = \\frac{0.5}{0.8} = 0.625 $$\n$$ \\frac{(m_{\\text{T}}-m_{\\text{A}})^2}{v_{\\text{A}}} = \\frac{(0.4)^2}{0.8} = \\frac{0.16}{0.8} = 0.2 $$\n现在将这些代回散度的表达式中：\n$$ D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}}) = \\frac{1}{2} \\left( \\ln(1.6) - 1 + 0.625 + 0.2 \\right) $$\n$$ D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}}) = \\frac{1}{2} \\left( \\ln(1.6) - 0.175 \\right) $$\n使用计算器计算自然对数：\n$$ \\ln(1.6) \\approx 0.470003629 $$\n$$ D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}}) \\approx \\frac{1}{2} (0.470003629 - 0.175) = \\frac{1}{2} (0.295003629) \\approx 0.1475018145 $$\n问题要求答案四舍五入到4位有效数字。\n$$ D_{\\mathrm{KL}}(p_{\\text{T}} \\| p_{\\text{A}}) \\approx 0.1475 $$\n这个值表示用代理的错误设定后验分布来近似真实后验分布时的信息损失，以奈特（nats）为单位。",
            "answer": "$$\\boxed{0.1475}$$"
        },
        {
            "introduction": "任何自适应智能体面临的一个关键挑战是如何在学习新信息的同时不覆盖或忘记过去的知识。这个编码练习通过实现一种受贝叶斯原理和生物学概念（如经验回放）启发的记忆巩固策略，来解决灾难性遗忘问题。通过推导和实现此学习过程的闭式解，您将获得关于智能体如何实现稳定、终身学习的实用见解。",
            "id": "4128155",
            "problem": "考虑一个带有参数向量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^d$ 的自适应代理，它按顺序学习任务。对于每个任务 $t$，将感知损失建模为严格凸的二次形式 $L_t(\\boldsymbol{\\theta}) = \\frac{1}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)^\\top A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)$，其中 $A_t \\in \\mathbb{R}^{d \\times d}$ 是半正定矩阵，$\\boldsymbol{\\mu}_t \\in \\mathbb{R}^d$ 是任务特定的偏好参数向量。假设一个先前学到的参数 $\\boldsymbol{\\theta}_{\\text{prev}}$ 总结了在没有新任务的情况下过去任务的解，该解通过最小化 $\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta})$ 获得。\n\n从贝叶斯原理和最大后验（MAP）估计器出发，并使用带有对角费雪信息的拉普拉斯近似，推导一个用于巩固（consolidation）的优化目标，该目标惩罚对过去任务重要的参数的变化。重要性权重由费雪信息矩阵的对角线 $\\operatorname{diag}(F)$ 给出，其中 $F \\in \\mathbb{R}^{d \\times d}$ 是对角且半正定的。形式上证明一个形如下式的目标\n$$\nJ(\\boldsymbol{\\theta}) = L_{\\text{new}}(\\boldsymbol{\\theta}) + \\frac{\\lambda}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}),\n$$\n其中 $L_{\\text{new}}$ 是当前任务的损失，$F$ 捕捉了过去任务的参数重要性，$\\lambda  0$ 是一个巩固强度。然后通过在目标中加入过去任务损失的加权和来并入经验回放：\n$$\nJ_{\\text{replay}}(\\boldsymbol{\\theta}) = L_{\\text{new}}(\\boldsymbol{\\theta}) + \\sum_{t=1}^{T_{\\text{past}}} \\alpha_t L_t(\\boldsymbol{\\theta}) + \\frac{\\lambda}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}),\n$$\n其中 $\\alpha_t \\ge 0$ 是回放权重。对于严格凸二次型，这些目标的最小化解存在且唯一。\n\n将灾难性遗忘定义为在适应新任务时累积的过去任务损失的增加量：\n$$\n\\Delta(\\boldsymbol{\\theta}_\\star) = \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_\\star)\\right) - \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_{\\text{prev}})\\right),\n$$\n其中 $\\boldsymbol{\\theta}_\\star$ 是在指定目标下学习新任务后的参数。通过评估差值来计算回放如何减少灾难性遗忘\n$$\nR = \\Delta(\\boldsymbol{\\theta}_\\star^{\\text{no-replay}}) - \\Delta(\\boldsymbol{\\theta}_\\star^{\\text{replay}}),\n$$\n其中更大的 $R$ 表示更大的减少量。\n\n您的程序必须实现二次目标的最小化解的闭式解，并为每个测试用例计算 $R$。不涉及物理单位。不涉及角度。所有数值输出均表示为四舍五入到六位小数的浮点数。\n\n在整个测试套件中使用 $d=3$，$T_{\\text{past}}=2$ 以及以下参数值。向量以行数组形式给出，对角矩阵由其对角线元素指定。\n\n除非明确覆盖，否则所有测试用例共享：\n- $\\boldsymbol{\\mu}_1 = [1.0,-1.0,0.5]$\n- $\\boldsymbol{\\mu}_2 = [0.0,1.0,-0.5]$\n- $\\boldsymbol{\\mu}_{\\text{new}} = [1.5,0.5,0.0]$\n- $\\operatorname{diag}(A_1) = [1.0,0.5,2.0]$\n- $\\operatorname{diag}(A_2) = [0.8,1.2,1.5]$\n- $\\operatorname{diag}(A_{\\text{new}}) = [1.0,1.0,1.0]$\n\n将 $\\boldsymbol{\\theta}_{\\text{prev}}$ 定义为 $L_1(\\boldsymbol{\\theta}) + L_2(\\boldsymbol{\\theta})$ 的唯一最小化解。\n\n测试套件包含5个用例：\n- 用例 1（正常路径）：$\\lambda = 2.0$, $\\alpha_1 = 0.5$, $\\alpha_2 = 0.5$, $\\operatorname{diag}(F) = [1.8,1.7,3.5]$。\n- 用例 2（无巩固，无回放）：$\\lambda = 0.0$, $\\alpha_1 = 0.0$, $\\alpha_2 = 0.0$, $\\operatorname{diag}(F) = [1.8,1.7,3.5]$。\n- 用例 3（强回放，弱巩固）：$\\lambda = 0.1$, $\\alpha_1 = 5.0$, $\\alpha_2 = 5.0$, $\\operatorname{diag}(F) = [1.8,1.7,3.5]$。\n- 用例 4（各向异性重要性，无回放）：$\\lambda = 1.0$, $\\alpha_1 = 0.0$, $\\alpha_2 = 0.0$, $\\operatorname{diag}(F) = [0.1,0.1,100.0]$。\n- 用例 5（近似奇异的新任务曲率，仅巩固）：覆盖 $\\operatorname{diag}(A_{\\text{new}}) = [0.0,0.0,0.1]$, $\\lambda = 0.2$, $\\alpha_1 = 0.0$, $\\alpha_2 = 0.0$, $\\operatorname{diag}(F) = [0.2,0.2,0.2]$。\n\n算法要求：\n- 从 $L_1 + L_2$ 一次性计算 $\\boldsymbol{\\theta}_{\\text{prev}}$。\n- 对于每个用例，构建无回放和有回放的目标函数，求解它们的唯一最小化解的闭式解，并评估 $R$。\n- 使用精确的线性代数为二次型最小化求解。所有矩阵都是对角的和半正定的；通过给定的参数确保海森矩阵的可逆性。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来（例如 $[r_1,r_2,r_3,r_4,r_5]$），其中每个 $r_i$ 是用例 $i$ 的浮点数 $R$，四舍五入到六位小数。",
            "solution": "该问题要求我们首先为一个在持续学习中使用的特定二次正则化目标提供理论证明，该目标源自贝叶斯原理。其次，它要求推导出在该目标下以及包含经验回放的扩展版本下的最优参数的闭式解。最后，我们需要实现这些解，为一系列测试用例计算灾难性遗忘减少的度量。\n\n### 巩固目标的理论证明\n\n目标是为一个学习新任务的优化目标提供证明，该目标惩罚对过去任务重要的参数的变动。提议的目标是：\n$$\nJ(\\boldsymbol{\\theta}) = L_{\\text{new}}(\\boldsymbol{\\theta}) + \\frac{\\lambda}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})\n$$\n这种形式是诸如弹性权重巩固（EWC）等方法的核心，可以从贝叶斯视角推导出来。\n\n1.  **贝叶斯推断**：当学习一个由数据 $D_{\\text{new}}$ 代表的新任务时，我们使用贝叶斯定理来寻找参数 $\\boldsymbol{\\theta}$ 的后验分布：\n    $$\n    p(\\boldsymbol{\\theta} | D_{\\text{new}}) = \\frac{p(D_{\\text{new}} | \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})}{p(D_{\\text{new}})} \\propto p(D_{\\text{new}} | \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})\n    $$\n    这里，$p(D_{\\text{new}} | \\boldsymbol{\\theta})$ 是给定参数下新数据的似然，$p(\\boldsymbol{\\theta})$ 是参数的先验分布。\n\n2.  **最大后验（MAP）估计**：MAP估计 $\\boldsymbol{\\theta}_{\\text{MAP}}$ 是使后验最大化的参数向量。这等同于最小化负对数后验：\n    $$\n    \\boldsymbol{\\theta}_{\\text{MAP}} = \\arg\\max_{\\boldsymbol{\\theta}} p(\\boldsymbol{\\theta} | D_{\\text{new}}) = \\arg\\min_{\\boldsymbol{\\theta}} \\left[ -\\log p(D_{\\text{new}} | \\boldsymbol{\\theta}) - \\log p(\\boldsymbol{\\theta}) \\right]\n    $$\n\n3.  **持续学习中的似然和先验**：\n    -   负对数似然 $-\\log p(D_{\\text{new}} | \\boldsymbol{\\theta})$ 是新任务的误差或损失函数。假设数据似然遵循高斯分布，该项变为平方误差损失。问题将其定义为二次损失 $L_{\\text{new}}(\\boldsymbol{\\theta})$。\n    -   在持续学习的背景下，先验 $p(\\boldsymbol{\\theta})$ 应包含从先前任务中学到的知识。一个自然的选择是将在学习完过去任务后的后验分布 $p(\\boldsymbol{\\theta} | D_{\\text{past}})$ 作为这个先验。\n\n4.  **拉普拉斯近似**：后验分布 $p(\\boldsymbol{\\theta} | D_{\\text{past}})$ 通常是难以处理的。拉普拉斯近似用一个以其众数为中心的高斯分布来近似这个后验分布。后验的众数是过去任务的MAP估计。问题将此参数向量定义为 $\\boldsymbol{\\theta}_{\\text{prev}}$。该近似为：\n    $$\n    p(\\boldsymbol{\\theta} | D_{\\text{past}}) \\approx \\mathcal{N}(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}_{\\text{prev}}, H_{\\text{past}}^{-1})\n    $$\n    其中 $H_{\\text{past}}$ 是过去任务的负对数后验的海森矩阵，在 $\\boldsymbol{\\theta}_{\\text{prev}}$ 处求值。海森矩阵衡量损失曲面的曲率；高曲率表示参数是敏感且重要的。\n\n5.  **费雪信息矩阵**：在某些正则性条件下以及在大数据极限下，负对数似然的海森矩阵可以由费雪信息矩阵（FIM）$F$ 近似。因此，我们设 $H_{\\text{past}} \\approx F$，其中 $F$ 是过去任务的FIM。问题指定了一个对角FIM，这对应于参数重要性是独立的假设。\n\n6.  **构建目标函数**：使用高斯近似作为先验，负对数先验项变为：\n    $$\n    -\\log p(\\boldsymbol{\\theta}) \\approx -\\log \\mathcal{N}(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}_{\\text{prev}}, F^{-1}) = \\frac{1}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}) + \\text{常数}\n    $$\n    将损失 $L_{\\text{new}}(\\boldsymbol{\\theta})$ 和这个负对数先验代入MAP目标，并去掉常数项，我们得到：\n    $$\n    \\arg\\min_{\\boldsymbol{\\theta}} \\left[ L_{\\text{new}}(\\boldsymbol{\\theta}) + \\frac{1}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}) \\right]\n    $$\n    引入超参数 $\\lambda  0$ 以控制新任务损失与保留旧知识（先验）之间的相对重要性。这可以看作是调整对先验的置信度。这直接导出了指定的目标函数 $J(\\boldsymbol{\\theta})$。\n\n### 闭式最小化解的推导\n\n所有目标都是二次型的和，导致总目标也是一个二次形式 $Q(\\boldsymbol{\\theta}) = \\frac{1}{2}\\boldsymbol{\\theta}^{\\top} H \\boldsymbol{\\theta} - \\boldsymbol{b}^{\\top}\\boldsymbol{\\theta} + c$。这样的函数通过求解 $\\nabla Q(\\boldsymbol{\\theta}) = H\\boldsymbol{\\theta} - \\boldsymbol{b} = \\boldsymbol{0}$ 来最小化，得出解 $\\boldsymbol{\\theta}_{\\star} = H^{-1}\\boldsymbol{b}$，前提是海森矩阵 $H$ 是可逆的。鉴于所有矩阵 $A_t$ 和 $F$ 都是半正定的，海森矩阵至少是半正定的。问题中的参数确保它们实际上是正定的，从而保证了唯一的最小化解。\n\n任务 $t$ 的损失是 $L_t(\\boldsymbol{\\theta}) = \\frac{1}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)^\\top A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)$。其梯度是 $\\nabla L_t(\\boldsymbol{\\theta}) = A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)$。\n\n1.  **过去任务的最小化解，$\\boldsymbol{\\theta}_{\\text{prev}}$**：\n    $\\boldsymbol{\\theta}_{\\text{prev}}$ 最小化累积的过去损失 $L_{\\text{past}}(\\boldsymbol{\\theta}) = \\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta})$。\n    将梯度设为零：\n    $$\n    \\nabla L_{\\text{past}}(\\boldsymbol{\\theta}) = \\sum_{t=1}^{T_{\\text{past}}} A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t) = \\left(\\sum_{t=1}^{T_{\\text{past}}} A_t\\right)\\boldsymbol{\\theta} - \\sum_{t=1}^{T_{\\text{past}}} A_t\\boldsymbol{\\mu}_t = \\boldsymbol{0}\n    $$\n    求解 $\\boldsymbol{\\theta}$：\n    $$\n    \\boldsymbol{\\theta}_{\\text{prev}} = \\left(\\sum_{t=1}^{T_{\\text{past}}} A_t\\right)^{-1} \\left(\\sum_{t=1}^{T_{\\text{past}}} A_t\\boldsymbol{\\mu}_t\\right)\n    $$\n    对于 $T_{\\text{past}}=2$，即为 $\\boldsymbol{\\theta}_{\\text{prev}} = (A_1 + A_2)^{-1} (A_1\\boldsymbol{\\mu}_1 + A_2\\boldsymbol{\\mu}_2)$。\n\n2.  **无回放的最小化解，$\\boldsymbol{\\theta}_\\star^{\\text{no-replay}}$**：\n    这是 $J(\\boldsymbol{\\theta}) = L_{\\text{new}}(\\boldsymbol{\\theta}) + \\frac{\\lambda}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})$ 的最小化解。\n    将梯度设为零：\n    $$\n    \\nabla J(\\boldsymbol{\\theta}) = A_{\\text{new}}(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_{\\text{new}}) + \\lambda F (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}) = (A_{\\text{new}} + \\lambda F)\\boldsymbol{\\theta} - (A_{\\text{new}}\\boldsymbol{\\mu}_{\\text{new}} + \\lambda F\\boldsymbol{\\theta}_{\\text{prev}}) = \\boldsymbol{0}\n    $$\n    求解 $\\boldsymbol{\\theta}$：\n    $$\n    \\boldsymbol{\\theta}_\\star^{\\text{no-replay}} = (A_{\\text{new}} + \\lambda F)^{-1} (A_{\\text{new}}\\boldsymbol{\\mu}_{\\text{new}} + \\lambda F\\boldsymbol{\\theta}_{\\text{prev}})\n    $$\n\n3.  **有回放的最小化解，$\\boldsymbol{\\theta}_\\star^{\\text{replay}}$**：\n    这是 $J_{\\text{replay}}(\\boldsymbol{\\theta}) = L_{\\text{new}}(\\boldsymbol{\\theta}) + \\sum_{t=1}^{T_{\\text{past}}} \\alpha_t L_t(\\boldsymbol{\\theta}) + \\frac{\\lambda}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})^\\top F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}})$ 的最小化解。\n    将梯度设为零：\n    $$\n    \\nabla J_{\\text{replay}}(\\boldsymbol{\\theta}) = A_{\\text{new}}(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_{\\text{new}}) + \\sum_{t=1}^{T_{\\text{past}}} \\alpha_t A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t) + \\lambda F(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prev}}) = \\boldsymbol{0}\n    $$\n    令 $H_{\\text{replay}} = A_{\\text{new}} + \\sum_{t=1}^{T_{\\text{past}}} \\alpha_t A_t + \\lambda F$ 且 $\\boldsymbol{b}_{\\text{replay}} = A_{\\text{new}}\\boldsymbol{\\mu}_{\\text{new}} + \\sum_{t=1}^{T_{\\text{past}}} \\alpha_t A_t\\boldsymbol{\\mu}_t + \\lambda F\\boldsymbol{\\theta}_{\\text{prev}}$。\n    梯度方程为 $H_{\\text{replay}}\\boldsymbol{\\theta} - \\boldsymbol{b}_{\\text{replay}} = \\boldsymbol{0}$。求解 $\\boldsymbol{\\theta}$：\n    $$\n    \\boldsymbol{\\theta}_\\star^{\\text{replay}} = H_{\\text{replay}}^{-1} \\boldsymbol{b}_{\\text{replay}}\n    $$\n    由于所有矩阵（$A_t$, $F$）都是对角的，它们的和与逆也是对角的。这极大地简化了计算，因为 $d$ 维问题解耦为 $d$ 个独立的标量方程。\n\n### 遗忘减少量 $R$ 的计算\n\n灾难性遗忘通过适应新任务后过去任务累积损失的增加来量化：\n$$\n\\Delta(\\boldsymbol{\\theta}_\\star) = \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_\\star)\\right) - \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_{\\text{prev}})\\right)\n$$\n由回放引起的遗忘减少量 $R$ 是无回放解和有回放解此值的差：\n$$\nR = \\Delta(\\boldsymbol{\\theta}_\\star^{\\text{no-replay}}) - \\Delta(\\boldsymbol{\\theta}_\\star^{\\text{replay}})\n$$\n代入 $\\Delta$ 的定义并消去公共项 $-\\sum L_t(\\boldsymbol{\\theta}_{\\text{prev}})$：\n$$\nR = \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_\\star^{\\text{no-replay}})\\right) - \\left(\\sum_{t=1}^{T_{\\text{past}}} L_t(\\boldsymbol{\\theta}_\\star^{\\text{replay}})\\right)\n$$\n要为每个测试用例计算 $R$，我们将：\n1.  一次性计算共享参数 $\\boldsymbol{\\theta}_{\\text{prev}}$。\n2.  对于每个用例，使用特定于用例的参数（$\\lambda, \\alpha_t, F$，可能还有 $A_{\\text{new}}$）来使用推导出的闭式解计算 $\\boldsymbol{\\theta}_\\star^{\\text{no-replay}}$ 和 $\\boldsymbol{\\theta}_\\star^{\\text{replay}}$。\n3.  对 $\\boldsymbol{\\theta}_\\star^{\\text{no-replay}}$ 和 $\\boldsymbol{\\theta}_\\star^{\\text{replay}}$ 计算累积的过去损失 $\\sum_{t=1}^{2} L_t(\\boldsymbol{\\theta})$。\n4.  计算它们的差以求得 $R$。\n给定 $\\boldsymbol{\\theta}$ 的损失计算为 $L_t(\\boldsymbol{\\theta}) = \\frac{1}{2}(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)^\\top A_t(\\boldsymbol{\\theta} - \\boldsymbol{\\mu}_t)$。\n实现将直接使用这些公式。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the reduction in catastrophic forgetting due to experience replay\n    for a set of test cases.\n    \"\"\"\n    # Shared parameters\n    mu1 = np.array([1.0, -1.0, 0.5])\n    mu2 = np.array([0.0, 1.0, -0.5])\n    munew_base = np.array([1.5, 0.5, 0.0])\n\n    diag_A1 = np.array([1.0, 0.5, 2.0])\n    diag_A2 = np.array([0.8, 1.2, 1.5])\n    diag_Anew_base = np.array([1.0, 1.0, 1.0])\n    \n    A1 = np.diag(diag_A1)\n    A2 = np.diag(diag_A2)\n\n    # Test cases\n    test_cases = [\n        # Case 1: happy path\n        {'lambda': 2.0, 'alpha1': 0.5, 'alpha2': 0.5, 'diag_F': np.array([1.8, 1.7, 3.5])},\n        # Case 2: no consolidation, no replay\n        {'lambda': 0.0, 'alpha1': 0.0, 'alpha2': 0.0, 'diag_F': np.array([1.8, 1.7, 3.5])},\n        # Case 3: strong replay, weak consolidation\n        {'lambda': 0.1, 'alpha1': 5.0, 'alpha2': 5.0, 'diag_F': np.array([1.8, 1.7, 3.5])},\n        # Case 4: anisotropic importance, no replay\n        {'lambda': 1.0, 'alpha1': 0.0, 'alpha2': 0.0, 'diag_F': np.array([0.1, 0.1, 100.0])},\n        # Case 5: near-singular new-task curvature, consolidation only\n        {'lambda': 0.2, 'alpha1': 0.0, 'alpha2': 0.0, 'diag_F': np.array([0.2, 0.2, 0.2]), \n         'diag_Anew': np.array([0.0, 0.0, 0.1])},\n    ]\n\n    # --- Step 1: Compute theta_prev, the minimizer of L1 + L2\n    # H_prev * theta_prev = b_prev\n    # (A1 + A2) * theta_prev = A1*mu1 + A2*mu2\n    H_prev_inv = np.diag(1.0 / (diag_A1 + diag_A2))\n    b_prev = A1 @ mu1 + A2 @ mu2\n    theta_prev = H_prev_inv @ b_prev\n\n    results = []\n\n    # Helper function to compute loss\n    def compute_task_loss(theta, mu, A):\n        diff = theta - mu\n        return 0.5 * diff.T @ A @ diff\n\n    for case in test_cases:\n        lam = case['lambda']\n        alpha1 = case['alpha1']\n        alpha2 = case['alpha2']\n        diag_F = case['diag_F']\n        F = np.diag(diag_F)\n\n        # Handle overrides for specific cases\n        if 'diag_Anew' in case:\n            diag_Anew = case['diag_Anew']\n        else:\n            diag_Anew = diag_Anew_base\n        Anew = np.diag(diag_Anew)\n        munew = munew_base # Does not change in test cases\n\n        # --- Step 2: Compute theta_star_no_replay\n        # (A_new + lambda*F) * theta = A_new*mu_new + lambda*F*theta_prev\n        diag_H_no_replay = diag_Anew + lam * diag_F\n        # Add a small epsilon to avoid division by zero, although problem setup avoids it.\n        diag_H_no_replay[diag_H_no_replay == 0] = 1e-12 \n        H_no_replay_inv = np.diag(1.0 / diag_H_no_replay)\n        \n        b_no_replay = Anew @ munew + lam * F @ theta_prev\n        theta_star_no_replay = H_no_replay_inv @ b_no_replay\n        \n        # --- Step 3: Compute theta_star_replay\n        # (A_new + a1*A1 + a2*A2 + lambda*F) * theta = A_new*mu_new + a1*A1*mu1 + a2*A2*mu2 + lambda*F*theta_prev\n        diag_H_replay = diag_Anew + alpha1 * diag_A1 + alpha2 * diag_A2 + lam * diag_F\n        diag_H_replay[diag_H_replay == 0] = 1e-12\n        H_replay_inv = np.diag(1.0 / diag_H_replay)\n\n        b_replay = Anew @ munew + alpha1 * A1 @ mu1 + alpha2 * A2 @ mu2 + lam * F @ theta_prev\n        theta_star_replay = H_replay_inv @ b_replay\n\n        # --- Step 4: Calculate R\n        past_loss_no_replay = compute_task_loss(theta_star_no_replay, mu1, A1) + \\\n                              compute_task_loss(theta_star_no_replay, mu2, A2)\n        \n        past_loss_replay = compute_task_loss(theta_star_replay, mu1, A1) + \\\n                           compute_task_loss(theta_star_replay, mu2, A2)\n\n        R = past_loss_no_replay - past_loss_replay\n        results.append(f\"{R:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}