{
    "hands_on_practices": [
        {
            "introduction": "为了将级联失效的理论与实际应用联系起来，我们的第一个实践练习将模拟电力网络中的失效过程。我们将使用在电力系统工程中广泛应用的线性化直流（DC）潮流模型。通过这个练习，你将亲手实现级联失效的核心循环——计算流量、识别过载、移除组件并重新计算——同时处理网络孤岛等实际问题，从而深入理解负载重分配在真实基础设施网络中的动态后果。",
            "id": "4266617",
            "problem": "考虑一个由 $N$ 个节点和 $E$ 条无向线路组成的网络，每条线路连接一对节点。该网络使用线性化直流（DC）潮流近似法进行建模。设净注入功率向量为 $P \\in \\mathbb{R}^N$，其中节点 $i$ 的 $P_i$ 对发电为正，对负载为负。设每条线路 $e$ 具有正电纳 $b_e$ 和热容量限制 $C_e  0$。直流模型假定，线路 $e$ 上的有功功率流 $f_e$ 与其两端电压相角之差成正比，并且节点功率平衡由基尔霍夫电流定律强制执行。您将计算潮流、检测过载、按特定规则移除过载线路，并模拟由此产生的连锁故障，直到达到稳定状态。\n\n建模基本依据：\n- 基尔霍夫电流定律：流入节点 $i$ 的潮流代数和等于该节点的净注入功率 $P_i$。\n- 线性化直流潮流关系：对于任何线路 $e = (u,v)$，有功功率流满足 $f_e = b_e \\left(\\theta_u - \\theta_v\\right)$，其中 $\\theta_i$ 是节点 $i$ 的电压相角。\n- 基于关联矩阵的公式：使用一个有向关联矩阵 $A \\in \\mathbb{R}^{E \\times N}$，对于从节点 $u$ 指向节点 $v$ 的线路 $e=(u,v)$，定义 $A_{e,u} = +1$ 和 $A_{e,v} = -1$（其他位置为零），则基尔霍夫电流定律变为 $A^\\top f = P$，线性化直流关系变为 $f = \\operatorname{diag}(b) \\, A \\, \\theta$。这导出了在每个连通分量上，固定一个参考相角后的加权拉普拉斯系统 $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$。除非每个分量固定一个参考（松弛）相角，否则加权拉普拉斯矩阵是奇异的。\n\n需实现的连锁故障程序：\n1. 通过在每个连通分量上求解 $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$ 来计算线路潮流 $f_e$。松弛节点选择为该分量中索引最小的节点，并将其相角固定为零。当一个分量只有一个节点时，该分量中没有潮流。\n2. 对每条有效线路 $e$，定义利用率 $r_e = \\left|f_e\\right| / C_e$。\n3. 如果存在任何 $r_e  1$ 的线路，则移除且仅移除一条线路：$r_e$ 值最大的那条。如果多条线路的 $r_e$ 值并列最大，则移除线路索引最小的那条。重新计算连通分量，并从步骤 1 开始重复。\n4. 当所有剩余线路都满足 $r_e \\le 1$ 或没有线路剩下时，终止程序。最终状态被认为是稳定的。\n\n处理孤岛效应：\n- 线路的移除可能会将网络断开成多个连通分量（孤岛）。在每个孤岛中，将该孤岛内索引最小的节点定义为松弛节点。通过固定的参考相角，松弛节点隐式地调整其净注入功率以吸收该孤岛中的任何总功率不平衡，这为其他节点的相角提供了一个可解的简化拉普拉斯系统。这种方法纯粹是数学上的，并不限制松弛节点的容量。\n\n您的程序必须精确实现此连锁故障模拟，并为每个测试用例返回三元组 $[k, R, M]$，其中：\n- $k$ 是达到最终稳定状态前移除的线路整数数量，\n- $R$ 是所有剩余线路中的最终最大利用率，定义为 $R = \\max_e r_e$（其中 $r_e = \\left|f_e\\right| / C_e$），表示为一个四舍五入到六位小数的实数，\n- $M$ 是最终网络中连通分量（包括孤立节点）的整数数量。\n\n请使用以下参数值测试套件。在所有情况下，节点由从 0 开始的整数标记，每条线路通过其 $(u,v)$ 端点、电纳 $b_e$ 和容量 $C_e$ 指定，矩阵 $A$ 的方向是从第一个端点 $u$ 到第二个端点 $v$。\n\n测试用例 1 (带弦的环形网络):\n- $N = 4$\n- 线路: $e_0 = (0,1,b_0=5,C_0=8)$, $e_1 = (1,2,b_1=5,C_1=8)$, $e_2 = (2,3,b_2=5,C_2=8)$, $e_3 = (3,0,b_3=5,C_3=8)$, $e_4 = (1,3,b_4=5,C_4=6)$\n- 净注入功率: $P = [3,-1,-2,0]$\n\n测试用例 2 (一个限制紧张的星形网络):\n- $N = 5$\n- 线路: $e_0 = (0,1,b_0=4,C_0=4)$, $e_1 = (0,2,b_1=4,C_1=4)$, $e_2 = (0,3,b_2=4,C_2=4)$, $e_3 = (0,4,b_3=4,C_3=0.5)$\n- 净注入功率: $P = [4,-1,-1,-1,-1]$\n\n测试用例 3 (三角形网络，容量充裕):\n- $N = 3$\n- 线路: $e_0 = (0,1,b_0=10,C_0=100)$, $e_1 = (1,2,b_1=10,C_1=100)$, $e_2 = (0,2,b_2=10,C_2=100)$\n- 净注入功率: $P = [1,-0.5,-0.5]$\n\n测试用例 4 (处于精确极限的链式网络):\n- $N = 3$\n- 线路: $e_0 = (0,1,b_0=10,C_0=5)$, $e_1 = (1,2,b_1=10,C_1=5)$\n- 净注入功率: $P = [5,0,-5]$\n\n测试用例 5 (过载时需要打破平局的链式网络):\n- $N = 4$\n- 线路: $e_0 = (0,1,b_0=10,C_0=3)$, $e_1 = (1,2,b_1=10,C_1=2)$, $e_2 = (2,3,b_2=10,C_2=100)$\n- 净注入功率: $P = [6,-2,-2,-2]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例的结果为一个子列表 $[k,R,M]$。例如，输出必须类似于 $[[k_1,R_1,M_1],[k_2,R_2,M_2],\\dots]$，其中 $R_i$ 四舍五入到六位小数。",
            "solution": "该问题要求模拟电力网络中的连锁故障，该网络使用线性化直流（DC）潮流近似法进行建模。模拟以离散步骤进行，在每一步中，计算潮流，移除最过载的输电线路，这可能导致网络分裂（孤岛效应）和潮流的进一步重新分布，直到达到稳定状态。\n\n模拟的核心在于为网络的每个连通分量求解直流潮流方程。其控制方程是一个线性系统，源自基尔霍夫电流定律和有功功率的类欧姆定律关系。\n\n设网络有 $N$ 个节点和 $E$ 条线路。我们定义一个有向关联矩阵 $A \\in \\mathbb{R}^{E \\times N}$，对于从节点 $u$ 指向节点 $v$ 的线路 $e$，有 $A_{e,u} = 1$ 和 $A_{e,v} = -1$，该行所有其他条目为 $0$。设 $\\theta \\in \\mathbb{R}^N$ 为节点电压相角向量，$P \\in \\mathbb{R}^N$ 为净注入功率向量，$b \\in \\mathbb{R}^E$ 为线路电纳向量，$f \\in \\mathbb{R}^E$ 为线路上功率流的向量。\n\n该模型由两个基本关系定义：\n1.  具有电纳 $b_e$ 的线路 $e=(u,v)$ 上的潮流 $f_e$ 由 $f_e = b_e(\\theta_u - \\theta_v)$ 给出。其矩阵形式为 $f = \\mathrm{diag}(b) A \\theta$。\n2.  进入或离开任何节点的功率流总和必须与该节点的净注入功率相平衡。这是基尔霍夫电流定律（KCL），表示为 $A^\\top f = P$。\n\n将第一个方程代入第二个方程，得到相角的系统方程：\n$$\nA^\\top \\left( \\mathrm{diag}(b) A \\theta \\right) = P\n$$\n$$\n(A^\\top \\mathrm{diag}(b) A) \\theta = P\n$$\n这通常写成 $L \\theta = P$，其中 $L = A^\\top \\mathrm{diag}(b) A$ 是网络的加权拉普拉斯矩阵。任何图的拉普拉斯矩阵都是奇异的，这反映了一个物理事实：只有相角*差*决定功率流，而不是它们的绝对值。为了获得唯一解，我们必须建立一个参考。\n\n问题指定了一个程序来处理这种奇异性以及网络可能的分裂：\n1.  **识别连通分量**：使用图遍历算法（如广度优先搜索 (BFS) 或深度优先搜索 (DFS)）将网络划分为其连通分量。每个分量都被视为一个独立的子问题。\n\n2.  **为每个分量求解**：对于每个具有节点集 $\\mathcal{V}_\\mathcal{C}$ 和线路集 $\\mathcal{E}_\\mathcal{C}$ 的连通分量 $\\mathcal{C}$：\n    - 如果 $|\\mathcal{V}_\\mathcal{C}| \\le 1$，则该分量内没有线路，因此不计算潮流。\n    - 如果 $|\\mathcal{V}_\\mathcal{C}|  1$，必须选择一个参考节点或“松弛”节点。问题规定选择 $\\mathcal{V}_\\mathcal{C}$ 中索引最小的节点作为松弛节点 $s$。其相角固定为 $\\theta_s = 0$。\n    - 设 $\\mathcal{V'}_\\mathcal{C} = \\mathcal{V}_\\mathcal{C} \\setminus \\{s\\}$ 是分量中非松弛节点的集合。我们构建一个简化的线性系统 $L' \\theta' = P'$ 来求解非松弛节点的相角 $\\theta'$。\n    - $L'$ 是分量的拉普拉斯矩阵 $L_\\mathcal{C}$ 中移除与松弛节点 $s$ 对应的行和列后得到的子矩阵。对于连通分量，这个简化的矩阵 $L'$ 是可逆的。\n    - $P'$ 是功率注入向量 $P$ 中对应于非松弛节点 $\\mathcal{V'}_\\mathcal{C}$ 的子向量。分量中的功率不平衡 $\\sum_{i \\in \\mathcal{V}_\\mathcal{C}} P_i$ 由松弛节点隐式吸收。\n    - 通过求解线性系统找到非松弛相角：$\\theta' = (L')^{-1} P'$。\n    - 在确定了分量的所有节点相角 $\\theta$（包括 $\\theta_s=0$）后，计算该分量内每条线路 $e=(u,v)$ 上的潮流 $f_e$：$f_e = b_e(\\theta_u - \\theta_v)$。\n\n整个模拟过程以循环方式进行：\n\n**第一步：初始化**\n- 模拟从完整的线路集合开始。移除的线路数 $k$ 初始化为 $0$。\n\n**第二步：迭代连锁故障**\n模拟进入一个循环，直到没有线路过载为止。\n- **a) 潮流计算**：对于当前的网络拓扑，执行上述程序（分量识别和分量级线性系统求解）以计算所有线路潮流 $f_e$。\n- **b) 过载评估**：对于每条容量为 $C_e$ 的线路 $e$，计算其利用率：$r_e = |f_e| / C_e$。识别出最大比率 $r_{\\max} = \\max_e r_e$。如果没有线路剩下，$r_{\\max}$ 取为 $0$。\n- **c) 稳定性检查**：如果 $r_{\\max} \\le 1$，则网络是稳定的。模拟终止。\n- **d) 线路移除**：如果 $r_{\\max}  1$，则网络不稳定。必须移除一条线路。要移除的线路 $e^*$ 是具有最大利用率 $r_{e^*} = r_{\\max}$ 的那条。如果存在平局，则选择原始索引最小的线路。从网络中移除线路 $e^*$，将 $k$ 增加 1，然后从第二步-a 重复循环。\n\n**第三步：最终输出**\n终止时，最终状态由以下特征描述：\n- $k$：连锁故障期间移除的线路总数。\n- $R$：最终的最大利用率 $r_{\\max}$，四舍五入到六位小数。\n- $M$：最终稳定网络图中的连通分量数量。\n\n这个综合算法确定性地模拟了指定的连锁故障过程。其实现需要用于查找分量的稳健图算法和用于求解矩阵方程的数值线性代数例程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_components(num_nodes, active_lines_indices, lines_def):\n    \"\"\"Finds connected components in the graph using BFS.\"\"\"\n    if num_nodes == 0:\n        return 0, []\n        \n    adj = [[] for _ in range(num_nodes)]\n    for line_idx in active_lines_indices:\n        u, v, _, _, _ = lines_def[line_idx]\n        adj[u].append(v)\n        adj[v].append(u)\n\n    visited = [False] * num_nodes\n    components = []\n    for i in range(num_nodes):\n        if not visited[i]:\n            component_nodes = set()\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head  len(q):\n                u = q[head]\n                head += 1\n                component_nodes.add(u)\n                for v in adj[u]:\n                    if not visited[v]:\n                        visited[v] = True\n                        q.append(v)\n            components.append(sorted(list(component_nodes)))\n    return len(components), components\n\ndef solve_cascade(num_nodes, lines, power_injections):\n    \"\"\"\n    Simulates the cascading failure process.\n    \"\"\"\n    lines_def = [(u, v, b, c, idx) for idx, (u, v, b, c) in enumerate(lines)]\n    active_lines_indices = set(range(len(lines_def)))\n    \n    removed_lines_count = 0\n\n    while True:\n        if not active_lines_indices:\n            num_components, _ = find_components(num_nodes, active_lines_indices, lines_def)\n            return removed_lines_count, 0.0, num_components\n\n        num_components, components = find_components(num_nodes, active_lines_indices, lines_def)\n\n        flows = {}  # Using dict to store flows by line index\n\n        for comp_nodes in components:\n            if len(comp_nodes) = 1:\n                continue\n\n            # Map component-local indices to global node indices\n            node_map = {node_idx: i for i, node_idx in enumerate(comp_nodes)}\n            \n            comp_lines = []\n            for line_idx in active_lines_indices:\n                u, v, _, _, _ = lines_def[line_idx]\n                if u in comp_nodes and v in comp_nodes:\n                    comp_lines.append(line_idx)\n            \n            if not comp_lines:\n                continue\n\n            comp_size = len(comp_nodes)\n            laplacian = np.zeros((comp_size, comp_size))\n\n            # Build weighted Laplacian for the component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                u_comp, v_comp = node_map[u], node_map[v]\n                laplacian[u_comp, u_comp] += b\n                laplacian[v_comp, v_comp] += b\n                laplacian[u_comp, v_comp] -= b\n                laplacian[v_comp, u_comp] -= b\n            \n            # Select slack bus (smallest index in component)\n            slack_node_global = comp_nodes[0]\n            slack_node_comp = node_map[slack_node_global]\n            \n            non_slack_indices_comp = [i for i in range(comp_size) if i != slack_node_comp]\n            non_slack_indices_global = [node for node in comp_nodes if node != slack_node_global]\n            \n            # Reduced system\n            reduced_laplacian = laplacian[np.ix_(non_slack_indices_comp, non_slack_indices_comp)]\n            reduced_p = np.array([power_injections[i] for i in non_slack_indices_global])\n\n            # Solve for non-slack angles\n            try:\n                non_slack_thetas = np.linalg.solve(reduced_laplacian, reduced_p)\n            except np.linalg.LinAlgError:\n                # This can happen if a component is just a line, making L' singular.\n                # It's an issue with how the problem is defined, but we must handle it.\n                # For safety, use pinv if solve fails.\n                non_slack_thetas = np.linalg.pinv(reduced_laplacian) @ reduced_p\n\n            # Reconstruct full theta vector for the component\n            thetas_comp = np.zeros(comp_size)\n            thetas_comp[non_slack_indices_comp] = non_slack_thetas\n            \n            thetas_global = {comp_nodes[i]: thetas_comp[i] for i in range(comp_size)}\n\n            # Calculate flows for lines in this component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                flow = b * (thetas_global[u] - thetas_global[v])\n                flows[line_idx] = flow\n\n        # Assess overload\n        max_ratio = -1.0\n        line_to_remove = -1\n\n        ratios = []\n        for line_idx in sorted(list(active_lines_indices)):\n            u, v, b, c, _ = lines_def[line_idx]\n            flow_val = flows.get(line_idx, 0.0)\n            ratio = abs(flow_val) / c if c  0 else float('inf')\n            ratios.append((ratio, line_idx))\n\n        if not ratios:\n            # This case is handled at the loop start, but as a safeguard\n            max_ratio_val = 0.0\n        else:\n            # Sort by ratio (desc), then line index (asc)\n            ratios.sort(key=lambda x: (-x[0], x[1]))\n            max_ratio_val = ratios[0][0]\n            line_to_remove = ratios[0][1]\n\n        if max_ratio_val = 1.0:\n            final_max_ratio = max_ratio_val if ratios else 0.0\n            return removed_lines_count, final_max_ratio, num_components\n        else:\n            active_lines_indices.remove(line_to_remove)\n            removed_lines_count += 1\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 5, 8), (1, 2, 5, 8), (2, 3, 5, 8), (3, 0, 5, 8), (1, 3, 5, 6)],\n            \"P\": [3, -1, -2, 0]\n        },\n        {\n            \"N\": 5,\n            \"lines\": [(0, 1, 4, 4), (0, 2, 4, 4), (0, 3, 4, 4), (0, 4, 4, 0.5)],\n            \"P\": [4, -1, -1, -1, -1]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 100), (1, 2, 10, 100), (0, 2, 10, 100)],\n            \"P\": [1, -0.5, -0.5]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 5), (1, 2, 10, 5)],\n            \"P\": [5, 0, -5]\n        },\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 10, 3), (1, 2, 10, 2), (2, 3, 10, 100)],\n            \"P\": [6, -2, -2, -2]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        k, R, M = solve_cascade(case[\"N\"], case[\"lines\"], case[\"P\"])\n        # Format the result with R rounded to 6 decimal places\n        results.append(f\"[{k},{R:.6f},{M}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "最后，我们将从“模拟”转向“优化”，探讨如何识别网络中最具破坏性的初始故障。这个练习要求你设计一个最坏情况下的攻击策略，通过选择一小组初始移除节点来最大化级联失效的最终规模。通过实现穷举搜索来寻找最优解，你将直面组合优化的挑战，并能从实践中理解为何简单的贪心策略可能失效，这涉及到子模性（submodularity）等更深层次的理论概念。",
            "id": "4266579",
            "problem": "给定一个有限、加权、无向网络，由图 $G = (V, E)$ 表示，其中 $|V| = n$。同时给定一个非负基础负载向量 $\\ell \\in \\mathbb{R}_{\\ge 0}^{n}$，一个非负容量向量 $c \\in \\mathbb{R}_{\\ge 0}^{n}$，以及一个非负、对称的邻接权重矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$，其中对所有 $i,j \\in V$ 都有 $W_{ij} = W_{ji}$，且对所有 $i \\in V$ 都有 $W_{ii} = 0$。对于任意节点 $i \\in V$，定义其邻居集合为 $N(i) = \\{ j \\in V : W_{ij}  0 \\}$。考虑一个具有以下机制的离散时间负载重分配级联：\n\n- 负载以轮次演化，并保存在一个向量 $L \\in \\mathbb{R}_{\\ge 0}^{n}$ 中；初始时 $L = \\ell$。\n- 定向移除策略是一个子集 $S \\subseteq V$，其大小为 $|S| = k$。在第 $t = 0$ 轮，集合 $S$ 中的所有节点都会失效（被移除），并且每个此类节点的当前负载将按边权重比例重新分配给其存活的邻居。\n- 更精确地说，当一个节点 $i$ 在一轮开始时失效，计算其存活邻居的集合 $N_{\\text{surv}}(i) = \\{ j \\in N(i) : j \\text{ 在本轮开始时未失效} \\}$。令 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。如果 $\\sigma(i)  0$，则每个存活邻居 $j \\in N_{\\text{surv}}(i)$ 在该轮中会收到一个附加负载 $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$；如果 $\\sigma(i) = 0$，则负载 $L_i$ 被丢弃（丢失）。\n- 在计算完当前轮次中所有失效节点的重分配并将其应用于 $L$ 后，这些失效节点将被永久移除，不再接收任何负载。一个存活的节点 $j$ 如果其负载 $L_j  c_j$，则会在下一轮失效。这种同步更新将重复进行，直到没有更多节点失效为止。\n- 定义级联规模函数 $f(S)$ 为从初始移除集合 $S$ 开始，最终失效的节点总数（包括 $S$ 中的节点）。\n\n目标是构建一个给定基数 $k$ 的最坏情况定向移除策略 $S^{\\star}$，该策略在所述的负载重分配规则下能最大化级联规模 $f(S)$。此外，需要通过子模性论证来证明您构建的策略的最优性，或者在子模性失效的情况下提供反例，并解释为何在这种情况下需要穷举搜索才能获得精确最优性。\n\n您的程序必须实现上述级联模型，并对下面的每个测试用例，通过搜索所有大小为 $k$ 的子集 $S \\subseteq V$ 来计算精确的最坏情况移除集合 $S^{\\star}$ 和相应的最大级联规模 $f(S^{\\star})$。当 $f(S)$ 出现平局时，应选择节点索引升序排序时字典序最小的集合 $S$。所有节点索引都是从 $0$ 开始的整数。\n\n所有答案均为纯数学结果，无单位。本问题不涉及角度和物理单位。\n\n测试套件规范：\n\n为以下测试用例提供结果。在每个用例中，网络通过列出非零对称边及其权重来指定，同时还包括基础负载 $\\ell$、容量 $c$ 和移除预算 $k$。\n\n- 测试用例 1 (顺利场景星形级联):\n  - 节点: $n = 5$，标记为 $0, 1, 2, 3, 4$。\n  - 非零对称边及其权重: $(0,1)$ 权重为 $1$，$(0,2)$ 权重为 $1$，$(0,3)$ 权重为 $1$，$(0,4)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.80, 0.31, 0.31, 0.31, 0.31]$。\n  - 容量: $c = [1.20, 0.50, 0.50, 0.50, 0.50]$。\n  - 预算: $k = 1$。\n\n- 测试用例 2 (边界情况，无移除):\n  - 节点: $n = 4$，标记为 $0, 1, 2, 3$。\n  - 非零对称边及其权重: $(0,1)$ 权重为 $1$，$(1,2)$ 权重为 $1$，$(2,3)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.20, 0.20, 0.20, 0.20]$。\n  - 容量: $c = [0.50, 0.50, 0.50, 0.50]$。\n  - 预算: $k = 0$。\n\n- 测试用例 3 (边缘情况协同效应及子模性反例):\n  - 节点: $n = 5$，标记为 $0, 1, 2, 3, 4$。\n  - 非零对称边及其权重: $(0,2)$ 权重为 $1$，$(1,2)$ 权重为 $1$，$(2,3)$ 权重为 $1$，$(2,4)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.50, 0.50, 0.60, 0.40, 0.40]$。\n  - 容量: $c = [0.60, 0.60, 1.20, 0.50, 0.50]$。\n  - 预算: $k = 2$。\n\n要求的最终输出格式：\n\n您的程序应生成单行输出，其中包含三个测试用例的结果，格式为一个逗号分隔的列表，并用方括号括起来。每个结果必须是一个包含两个元素的列表，其中包含最大级联规模（一个整数）和相应的字典序最小的最大化集合 $S^{\\star}$（一个整数列表）。例如，输出应类似于 $[[f_1, S_1],[f_2, S_2],[f_3, S_3]]$，其中 $f_i$ 是测试用例 $i$ 的最大级联规模，$S_i$ 是最大化集合。\n\n您的程序不得读取任何输入，并且除了要求的单行输出外，不得打印任何其他文本。",
            "solution": "所提供的问题陈述在网络科学和复杂系统领域是一个有效且定义明确的问题。它涉及通过选择一个最优的初始失效节点集来最大化网络上的级联规模函数。\n\n该问题具有科学依据，是基于负载的级联失效的形式化表示，这是一种在电力网和金融网络等情境中研究的现象。其动态过程是确定性的，并用数学精度进行了定义，确保了对于任何初始失效集合 $S$，级联规模函数 $f(S)$ 都是良定义的。鉴于节点数量 $n$ 是有限的且移除预算 $k$ 是固定的，一个最大化 $f(S)$ 的最优集合 $S^{\\star}$ 必定存在。问题是完整的，提供了所有必要的参数和规则，并且没有内部矛盾或歧义。对于测试用例中指定的小网络规模，通过穷举搜索找到精确解的要求在计算上是可行的。\n\n我们将首先形式化级联模型，然后讨论优化方法及其理由，最后概述实现算法。\n\n**1. 级联模型**\n\n在任何离散时间步 $t \\ge 0$，网络的状态可以用负载向量 $L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$ 和失效节点集合（我们称之为 $\\mathcal{F}^{(t)} \\subseteq V$）来描述。\n\n*   **初始化 ($t=0$):**\n    选择一个节点集合 $S \\subseteq V$ 进行初始移除，其中 $|S|=k$。所有失效节点的集合初始化为 $\\mathcal{F}^{(0)} = S$。初始负载向量是基础负载向量 $L = \\ell$。然而，问题规定 $S$ 中的节点首先失效并重新分配其负载。我们可以将其建模为一系列轮次。设 $\\mathcal{F}_{\\text{total}}$ 为到当前为止所有已失效节点的集合，初始化为 $S$。设 $F_0 = S$ 为第 $0$ 轮失效的节点集合。\n\n*   **级联轮次 ($t=0, 1, 2, \\dots$):**\n    级联以同步轮次的方式进行。在每一轮 $t$ 中，一组节点 $F_t$ 失效。\n\n    1.  如果 $F_t = \\emptyset$，级联已终止。过程停止。\n    2.  一个中间负载增量向量 $\\Delta L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$ 被初始化为全零。\n    3.  对于当前轮次中失效的每个节点 $i \\in F_t$，其负载 $L_i$ 必须被重新分配。其尚未失效的邻居集合是 $N_{\\text{surv}}(i) = N(i) \\setminus \\mathcal{F}_{\\text{total}}$。\n    4.  到这些存活邻居的权重总和为 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。\n    5.  如果 $\\sigma(i)  0$，每个存活邻居 $j \\in N_{\\text{surv}}(i)$ 会收到一个附加负载。由于节点 $i$ 失效而导致节点 $j$ 的增量为 $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$。此值被加到 $\\Delta L_j^{(t)}$。如果 $\\sigma(i)=0$，负载 $L_i$ 将丢失。\n    6.  在计算完来自 $F_t$ 中所有节点的负载增量后，存活节点的负载被同步更新：对于所有 $j \\notin \\mathcal{F}_{\\text{total}}$，$L_j \\leftarrow L_j + \\Delta L_j^{(t)}$。请注意，失效节点本身的负载不再更新。\n    7.  所有失效节点的集合被更新：$\\mathcal{F}_{\\text{total}} \\leftarrow \\mathcal{F}_{\\text{total}} \\cup F_t$。\n    8.  识别出下一轮将要失效的新节点集合 $F_{t+1}$。这些是尚未失效但其新负载超过其容量的节点：\n        $$F_{t+1} = \\{ j \\in V \\setminus \\mathcal{F}_{\\text{total}} : L_j > c_j \\}$$\n    9.  过程以集合 $F_{t+1}$ 对第 $t+1$ 轮重复。\n\n对于一个初始集合 $S$，级联的总规模由函数 $f(S) = |\\mathcal{F}_{\\text{final}}|$ 给出，其中 $\\mathcal{F}_{\\text{final}}$ 是过程终止时的集合 $\\mathcal{F}_{\\text{total}}$。\n\n**2. 优化与理由**\n\n目标是找到一个集合 $S^{\\star}$，以解决以下优化问题：\n$$ S^{\\star} = \\underset{S \\subseteq V, |S|=k}{\\text{argmax}} \\; f(S) $$\n平局情况通过选择字典序最小的集合 $S$ 来打破。\n\n这是一个组合优化问题。对于许多此类问题，如果目标函数 $f(S)$ 是子模的，一个简单的贪心算法可以提供一个有性能保证的解。一个集合函数 $f$ 如果展现出“收益递减”特性，则它是子模的。形式上，对于任何集合 $A \\subseteq B \\subseteq V$ 和任何元素 $v \\in V \\setminus B$，必须满足：\n$$ f(A \\cup \\{v\\}) - f(A) \\ge f(B \\cup \\{v\\}) - f(B) $$\n然而，阈值模型中的级联规模函数通常不是子模的。问题陈述正确地暗示了这种可能性。我们可以使用测试用例 3 来证明子模性的失效。\n\n令 $f$ 为测试用例 3 的级联规模函数。\n-   令 $A = \\{0\\}$ 和 $B = \\emptyset$。注意 $B \\subset A$。我们来评估添加节点 $\\{1\\}$ 的边际增益。\n-   $f(\\emptyset) = 0$，因为没有节点初始过载。\n-   $f(\\{0\\})$: 节点 $0$ 失效。其负载 $L_0=0.5$ 被转移到其唯一的邻居节点 $2$。节点 $2$ 的负载变为 $L_2' = 0.6 + 0.5 = 1.1$。这小于其容量 $c_2 = 1.2$。级联停止。因此，$f(\\{0\\}) = 1$。\n-   $f(\\{1\\})$: 与节点 $0$ 对称，节点 $1$ 的失效同样不会引发级联。因此，$f(\\{1\\}) = 1$。\n-   $f(\\{0, 1\\})$: 节点 $0$ 和 $1$ 同时失效。它们都将其负载（$L_0=0.5, L_1=0.5$）重新分配给它们的共同邻居节点 $2$。节点 $2$ 的负载变为 $L_2' = 0.6 + 0.5 + 0.5 = 1.6$。这超过了其容量 $c_2 = 1.2$，所以节点 $2$ 在下一轮失效。当节点 $2$ 失效时，其新负载 $1.6$ 被重新分配给其存活的邻居 $\\{3, 4\\}$，它们各自接收 $0.8$。它们的负载变为 $L_3' = 0.4+0.8=1.2  c_3=0.5$ 和 $L_4' = 0.4+0.8=1.2  c_4=0.5$。它们都失效了。整个网络崩溃。因此，$f(\\{0, 1\\}) = 5$。\n\n现在，我们用 $A = \\{0\\}$ 和 $B = \\emptyset$（所以 $B \\subseteq A$）以及元素 $v = 1$ 来检查子模性不等式。不等式要求 $f(B \\cup \\{v\\}) - f(B) \\ge f(A \\cup \\{v\\}) - f(A)$。\n-   将节点 $1$ 添加到空集 $B$ 的边际增益是：$f(\\{1\\}) - f(\\emptyset) = 1 - 0 = 1$。\n-   将节点 $1$ 添加到集合 $A=\\{0\\}$ 的边际增益是：$f(\\{0,1\\}) - f(\\{0\\}) = 5 - 1 = 4$。\n\n我们有 $1  4$，这意味着 $f(B \\cup \\{v\\}) - f(B)  f(A \\cup \\{v\\}) - f(A)$。这违反了子模性条件。该函数表现出协同效应，或称为收益递增，即两个节点失效的联合效应大于它们各自效应的总和。由于缺乏子模性，贪心算法不能保证找到最优解。因此，如问题陈述所要求，必须对所有 $\\binom{n}{k}$ 种可能的初始集合进行穷举搜索，以保证最优性。\n\n**3. 算法方法**\n\n该算法将由一个协调搜索的主循环和一个为给定初始集模拟级联的核心函数组成。\n\n1.  **主程序：** 对于每个测试用例 $(n, W, \\ell, c, k)$：\n    a. 初始化 `max_cascade_size = -1` 和 `optimal_set = []`。\n    b. 生成所有大小为 $k$ 的唯一节点子集 $S$。`itertools.combinations` 函数很适用，因为它按字典序生成这些子集。\n    c. 对于每个子集 $S$：\n        i. 调用一个模拟函数 `simulate_cascade(S, n, W, l, c)`，它返回最终的级联规模 $f(S)$。\n        ii. 如果返回的规模大于 `max_cascade_size`，则将 `max_cascade_size` 更新为这个新规模，并将 `optimal_set` 设置为当前的 $S$。因为我们是按字典序遍历集合的，所以第一个达到最大可能规模的集合将是符合平局规则的正确集合。\n    d. 存储该测试用例的最终 (`max_cascade_size`, `optimal_set`) 对。\n\n2.  **`simulate_cascade(S, n, W, l, c)` 函数：**\n    a. 初始化 `loads = copy(l)`，`total_failed = set(S)`，和 `newly_failed = set(S)`。\n    b. 进入一个 `while` 循环，只要 `newly_failed` 不为空就继续。\n    c. 在循环内部，令 `failing_this_round = newly_failed`。将 `newly_failed` 重置为空集。\n    d. 初始化 `load_increments = zeros(n)`。\n    e. 对于 `failing_this_round` 中的每个节点 $i$：\n        i. 确定存活邻居的集合 $N_{\\text{surv}}(i) = \\{ j \\mid W_{ij}0 \\text{ and } j \\notin \\text{total\\_failed} \\}$。\n        ii. 计算 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。\n        iii. 如果 $\\sigma(i)  0$，对于每个 $j \\in N_{\\text{surv}}(i)$，将 $loads[i] \\cdot \\frac{W_{ij}}{\\sigma(i)}$ 加到 `load_increments[j]`。\n    f. 遍历完 `failing_this_round` 中的所有节点后，更新主 `loads` 向量：`loads += load_increments`。\n    g. 更新失效节点的总集合：`total_failed.update(failing_this_round)`。\n    h. 遍历所有节点 $j \\in \\{0, \\dots, n-1\\}$。如果 $j \\notin \\text{total\\_failed}$ 且 $loads[j]  c[j]$，则将 $j$ 添加到 `newly_failed` 集合中。\n    i. 循环继续。\n    j. 一旦循环终止，返回 `len(total_failed)`。\n\n这个设计忠实地实现了指定的模型，并执行了所需的穷举搜索，为每个测试用例找到了精确的最优解。",
            "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Solves the cascading failure problem for a set of predefined test cases.\n    It finds the initial removal set of size k that maximizes the total cascade size.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (happy path star cascade)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 1, 1), (0, 2, 1), (0, 3, 1), (0, 4, 1)],\n            \"l\": [0.80, 0.31, 0.31, 0.31, 0.31],\n            \"c\": [1.20, 0.50, 0.50, 0.50, 0.50],\n            \"k\": 1,\n        },\n        # Test Case 2 (boundary, no removals)\n        {\n            \"n\": 4,\n            \"edges\": [(0, 1, 1), (1, 2, 1), (2, 3, 1)],\n            \"l\": [0.20, 0.20, 0.20, 0.20],\n            \"c\": [0.50, 0.50, 0.50, 0.50],\n            \"k\": 0,\n        },\n        # Test Case 3 (edge-case synergy and submodularity counterexample)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 2, 1), (1, 2, 1), (2, 3, 1), (2, 4, 1)],\n            \"l\": [0.50, 0.50, 0.60, 0.40, 0.40],\n            \"c\": [0.60, 0.60, 1.20, 0.50, 0.50],\n            \"k\": 2,\n        },\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        edges = case[\"edges\"]\n        l_vec = np.array(case[\"l\"], dtype=float)\n        c_vec = np.array(case[\"c\"], dtype=float)\n        k = case[\"k\"]\n\n        # Build the weighted adjacency matrix W\n        W = np.zeros((n, n), dtype=float)\n        for i, j, w in edges:\n            W[i, j] = w\n            W[j, i] = w\n\n        max_cascade_size = -1\n        best_s = []\n\n        # Generate all subsets of nodes of size k.\n        # itertools.combinations generates them in lexicographical order.\n        initial_sets = itertools.combinations(range(n), k)\n        \n        for s_tuple in initial_sets:\n            initial_failures = set(s_tuple)\n            \n            # Run the cascade simulation for the current set S\n            loads = np.copy(l_vec)\n            total_failed = set(initial_failures)\n            newly_failed = set(initial_failures)\n\n            while newly_failed:\n                failing_this_round = set(newly_failed)\n                newly_failed = set()\n                \n                # Update total failed set before calculating redistributions\n                # from this round's failures. This is to ensure a node failing\n                # in the same round doesn't receive load from another.\n                current_round_total_failed = total_failed.union(failing_this_round)\n                \n                load_increments = np.zeros(n)\n\n                for i in failing_this_round:\n                    surviving_neighbors = []\n                    weight_sum_surv = 0.0\n                    \n                    # Find surviving neighbors and sum of weights\n                    for j in range(n):\n                        if W[i, j]  0 and j not in current_round_total_failed:\n                            surviving_neighbors.append(j)\n                            weight_sum_surv += W[i, j]\n\n                    # Redistribute load\n                    if weight_sum_surv  0:\n                        for j in surviving_neighbors:\n                            load_increments[j] += loads[i] * (W[i, j] / weight_sum_surv)\n                \n                # Synchronous update of loads\n                loads += load_increments\n                \n                # Update total failed set after redistributions are calculated\n                total_failed.update(failing_this_round)\n\n                # Identify nodes failing in the next round\n                for j in range(n):\n                    if j not in total_failed and loads[j]  c_vec[j]:\n                        newly_failed.add(j)\n\n            current_cascade_size = len(total_failed)\n            \n            # Update best result found so far.\n            # Due to lexicographical order of combinations, the first set\n            # that achieves the max size will be the lexicographically smallest.\n            if current_cascade_size  max_cascade_size:\n                max_cascade_size = current_cascade_size\n                best_s = list(s_tuple)\n        \n        # Handle k=0 case which results in no loops\n        if k == 0 and max_cascade_size == -1:\n             max_cascade_size = 0\n             best_s = []\n\n        final_results.append([max_cascade_size, best_s])\n    \n    # Format the final output string exactly as specified.\n    result_str = \",\".join([f\"[{size},{s}]\" for size, s in final_results])\n    print(f\"[{result_str}]\".replace(\" \", \"\"))\n\n\nsolve()\n```"
        }
    ]
}