{
    "hands_on_practices": [
        {
            "introduction": "格兰杰因果关系和传递熵通常使用向量自回归（VAR）模型进行估计。这些方法的一个核心假设是平稳性，对于VAR模型而言，这转化为一个稳定性条件。本练习提供了一种动手实践的方法来检验这一关键先决条件，确保我们构建的模型是有效的。",
            "id": "4116835",
            "problem": "给定一组向量自回归模型，您必须通过构建并分析分块伴随矩阵的特征值来判断它们的稳定性，此过程需基于线性系统概念进行严谨推导。其背景是复杂自适应系统建模，其中诸如 Granger causality (GC) 和 transfer entropy (TE) 等因果关系检测方法依赖于底层多元时间序列存在平稳分布。一个 $k$ 维过程的 $p$ 阶向量自回归 (VAR) 由基本关系 $X_t = \\sum_{i=1}^{p} A_i X_{t-i} + \\varepsilon_t$ 定义，其中 $X_t \\in \\mathbb{R}^k$ 是状态， $A_i \\in \\mathbb{R}^{k \\times k}$ 是系数矩阵，而 $\\varepsilon_t$ 是零均值白噪声。通过状态增广获得的稳定线性时不变 (LTI) 实现中，状态转移矩阵的所有特征值都严格位于复平面的单位圆内部。您的任务是，对于每个给定的模型，从第一性原理出发推导并构建相应的分块伴随矩阵，然后计算其特征值以评估稳定性。根据以下基于谱半径的规则，将每个模型分类为稳定、边界或不稳定：如果特征值的最大模严格小于 $1$，则分类为稳定；如果在容差 $\\tau$ 范围内等于 $1$，则分类为边界；如果大于 $1$，则分类为不稳定。与 $1$ 进行比较时，使用数值比较容差 $\\tau = 10^{-10}$。每个测试用例的最终输出必须是一个包含两项的列表，其中包括一个整数分类代码和一个浮点谱半径，其中稳定编码为 $1$，边界编码为 $0$，不稳定编码为 $-1$。谱半径必须四舍五入到 $6$ 位小数。\n\n实现算法以：\n- 构建由 VAR($p$) 定义所隐含的分块伴随矩阵 $C \\in \\mathbb{R}^{kp \\times kp}$，\n- 计算 $C$ 的所有特征值，\n- 计算谱半径，即这些特征值模的最大值，\n- 使用上述指定的相对于单位圆的阈值规则对稳定性进行分类。\n\n测试套件：\n- 案例 $1$ (正常路径，VAR($1$)，明显稳定): $k = 2$, $p = 1$, $A_1 = \\begin{bmatrix} 0.5  0.0 \\\\ 0.0  0.3 \\end{bmatrix}$。\n- 案例 $2$ (边界情况，单位根正好在单位圆上): $k = 2$, $p = 2$, $A_1 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  0.2 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$。\n- 案例 $3$ (不稳定，单位根在单位圆外): $k = 2$, $p = 2$, $A_1 = \\begin{bmatrix} 1.1  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$。\n- 案例 $4$ (边缘案例，具有交叉滞后相互作用和复数特征值，预期为稳定): $k = 3$, $p = 2$, $A_1 = \\begin{bmatrix} 0.5  0.1  0.0 \\\\ 0.0  0.4  0.2 \\\\ 0.0  0.0  0.3 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} -0.1  0.0  0.0 \\\\ 0.0  -0.2  0.0 \\\\ 0.0  0.0  -0.1 \\end{bmatrix}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且本身是一个包含两项的列表 $[c, r]$，其中 $c \\in \\{-1, 0, 1\\}$ 是分类代码，$r$ 是四舍五入到 $6$ 位小数的谱半径。例如，整体输出的结构应类似于 $[[c_1, r_1],[c_2, r_2],[c_3, r_3],[c_4, r_4]]$。\n\n本问题不涉及物理单位。也不涉及角度。",
            "solution": "该问题要求评估几个向量自回归 (VAR) 模型的稳定性。如果一个 VAR 过程是协方差平稳的，那么它就是稳定的。此性质对于有效应用 Granger Causality 和 Transfer Entropy 等因果关系检测方法至关重要，因为这些方法依赖于底层时间序列存在平稳分布。VAR($p$) 过程的稳定性由其相关的分块伴随矩阵的特征值决定。该过程是稳定的，当且仅当该矩阵的所有特征值都严格位于复平面的单位圆内。\n\n我们的任务是从第一性原理出发推导该伴随矩阵的结构，为每个给定模型构建它，计算其特征值，确定谱半径（最大特征值模），并根据该半径是小于、等于还是大于 $1$ 来对模型的稳定性进行分类。\n\n**1. 分块伴随矩阵的推导**\n\n一个 $k$ 维的 $p$ 阶 VAR 过程，记为 VAR($p$)，由以下线性递推关系定义：\n$$\nX_t = \\sum_{i=1}^{p} A_i X_{t-i} + \\varepsilon_t\n$$\n其中 $X_t \\in \\mathbb{R}^k$ 是时间 $t$ 的状态向量，$A_i \\in \\mathbb{R}^{k \\times k}$ 是系数矩阵，$\\varepsilon_t \\in \\mathbb{R}^k$ 是一个零均值白噪声项向量。\n\n这个 $p$ 阶系统可以通过增广状态向量以包含过去的值，从而转换为等价的一阶系统（一个 VAR($1$) 过程）。让我们定义一个新的增广状态向量 $Y_t \\in \\mathbb{R}^{kp}$，它堆叠了当前状态 $X_t$ 及其最近的 $p-1$ 个滞后项：\n$$\nY_t = \\begin{bmatrix}\nX_t \\\\\nX_{t-1} \\\\\n\\vdots \\\\\nX_{t-p+1}\n\\end{bmatrix}\n$$\n我们的目标是找到一个状态转移矩阵 $C$，使得 $Y_t$ 遵循一阶递推关系 $Y_t = C Y_{t-1} + E_t$，其中 $E_t$ 是相应的噪声向量。向量 $Y_{t-1}$ 是：\n$$\nY_{t-1} = \\begin{bmatrix}\nX_{t-1} \\\\\nX_{t-2} \\\\\n\\vdots \\\\\nX_{t-p}\n\\end{bmatrix}\n$$\n我们现在可以构建 $Y_t$ 和 $Y_{t-1}$ 之间的关系：\n\n- $Y_t$ 的第一个分块行是 $X_t$。根据 VAR($p$) 的定义，我们有：\n  $X_t = A_1 X_{t-1} + A_2 X_{t-2} + \\dots + A_p X_{t-p} + \\varepsilon_t$。该方程将 $Y_t$ 的前 $k$ 个分量表示为 $Y_{t-1}$ 各分量的线性组合。\n\n- $Y_t$ 的第二个分块行是 $X_{t-1}$。根据定义，这正是 $Y_{t-1}$ 的第一个分块行。因此，$X_{t-1} = I_k X_{t-1}$，其中 $I_k$ 是 $k \\times k$ 的单位矩阵。\n\n- $Y_t$ 的第三个分块行是 $X_{t-2}$，也就是 $Y_{t-1}$ 的第二个分块行。\n\n- 这个模式一直持续到 $Y_t$ 的最后一个分块行，即 $X_{t-p+1}$，它对应于 $Y_{t-1}$ 的第 $(p-1)$ 个分块行。\n\n将这些关系合并成一个单一的矩阵方程，我们得到：\n$$\n\\begin{bmatrix}\nX_t \\\\\nX_{t-1} \\\\\nX_{t-2} \\\\\n\\vdots \\\\\nX_{t-p+1}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nA_1  A_2  \\dots  A_{p-1}  A_p \\\\\nI_k  0_k  \\dots  0_k  0_k \\\\\n0_k  I_k  \\dots  0_k  0_k \\\\\n\\vdots  \\vdots  \\ddots  \\vdots  \\vdots \\\\\n0_k  0_k  \\dots  I_k  0_k\n\\end{bmatrix}\n\\begin{bmatrix}\nX_{t-1} \\\\\nX_{t-2} \\\\\nX_{t-3} \\\\\n\\vdots \\\\\nX_{t-p}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\varepsilon_t \\\\\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{bmatrix}\n$$\n这个方程的形式为 $Y_t = C Y_{t-1} + E_t$，其中 $C$ 是 $kp \\times kp$ 的分块伴随矩阵：\n$$\nC = \\begin{bmatrix}\nA_1  A_2  \\dots  A_{p-1}  A_p \\\\\nI_k  0_k  \\dots  0_k  0_k \\\\\n0_k  I_k  \\dots  0_k  0_k \\\\\n\\vdots  \\vdots  \\ddots  \\vdots  \\vdots \\\\\n0_k  0_k  \\dots  I_k  0_k\n\\end{bmatrix}\n$$\n而 $0_k$ 是 $k \\times k$ 的零矩阵。\n\n**2. 稳定性判据和算法**\n\n原始 VAR($p$) 过程的稳定性等价于这个增广 VAR($1$) 系统的稳定性。一个离散时间线性时不变系统是稳定的，当且仅当其状态转移矩阵的所有特征值的模（或绝对值）严格小于 $1$。伴随矩阵 $C$ 的特征值是特征多项式 $\\det(\\lambda^p I_k - \\sum_{i=1}^p \\lambda^{p-i} A_i) = 0$ 的根。\n\n谱半径 $\\rho(C)$ 定义为 $C$ 的所有特征值中的最大模。稳定性条件可以简洁地表述为：\n- 如果 $\\rho(C)  1$，系统是**稳定**的。\n- 如果 $\\rho(C) = 1$，系统处于稳定性的**边界**（具有单位根）。\n- 如果 $\\rho(C) > 1$，系统是**不稳定**的。\n\n解决每个测试用例问题的算法如下：\n1.  根据给定的参数 $k$、$p$ 和系数矩阵列表 $\\{A_1, A_2, \\dots, A_p\\}$，构建 $kp \\times kp$ 的分块伴随矩阵 $C$。\n    - $C$ 的前 $k$ 行由水平拼接矩阵 $A_1, \\dots, A_p$ 形成。\n    - 对于从 $1$ 到 $p-1$ 的每个分块行 $j$，在第 $j$ 行和第 $j-1$ 列（使用基于0的分块索引）的分块位置上放置一个 $k \\times k$ 的单位矩阵 $I_k$。\n2.  使用标准的数值线性代数程序计算矩阵 $C$ 的 $kp$ 个特征值。\n3.  计算每个特征值的模（绝对值）。\n4.  通过找到这些模的最大值来确定谱半径 $\\rho(C)$。\n5.  基于 $\\rho(C)$ 和容差 $\\tau = 10^{-10}$ 对模型的稳定性进行分类：\n    - 如果 $|\\rho(C) - 1.0| \\le \\tau$，分类为**边界**（代码 $0$）。\n    - 如果 $\\rho(C)  1.0$，分类为**稳定**（代码 $1$）。\n    - 如果 $\\rho(C) > 1.0$，分类为**不稳定**（代码 $-1$）。\n6.  将输出格式化为一个列表，包含整数分类代码和四舍五入到 $6$ 位小数的谱半径。\n\n此程序将应用于每个提供的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the VAR model stability problem for a given suite of test cases.\n    \"\"\"\n\n    def check_var_stability(k, p, a_matrices):\n        \"\"\"\n        Constructs the companion matrix for a VAR(p) model and checks its stability.\n\n        Args:\n            k (int): The dimensionality of the time series.\n            p (int): The order of the VAR model.\n            a_matrices (list of np.ndarray): A list of coefficient matrices [A_1, ..., A_p].\n\n        Returns:\n            list: A list containing [classification_code, spectral_radius].\n                  - classification_code: 1 for stable, 0 for boundary, -1 for unstable.\n                  - spectral_radius: The spectral radius rounded to 6 decimal places.\n        \"\"\"\n        # A VAR(1) model's companion matrix is simply the coefficient matrix itself.\n        if p == 1:\n            companion_matrix = a_matrices[0]\n        else:\n            # General construction for VAR(p) models where p > 1\n            kp_dim = k * p\n            companion_matrix = np.zeros((kp_dim, kp_dim))\n            \n            # The first block row consists of the concatenated A_i matrices.\n            companion_matrix[:k, :] = np.hstack(a_matrices)\n            \n            # The sub-diagonal blocks are identity matrices.\n            # This populates the blocks that propagate the lagged variables.\n            # C[(i+1)k:(i+2)k, ik:(i+1)k] = I_k for i in 0..p-2\n            identity_block = np.eye(k)\n            for i in range(p - 1):\n                row_start = (i + 1) * k\n                row_end = row_start + k\n                col_start = i * k\n                col_end = col_start + k\n                companion_matrix[row_start:row_end, col_start:col_end] = identity_block\n\n        # Compute eigenvalues of the companion matrix\n        eigenvalues = np.linalg.eigvals(companion_matrix)\n\n        # Compute the spectral radius (maximum of the magnitudes of the eigenvalues)\n        spectral_radius = np.max(np.abs(eigenvalues))\n        \n        # Classify stability based on the spectral radius\n        # Use a tolerance tau for comparison with 1.0\n        tolerance = 1e-10\n        if np.abs(spectral_radius - 1.0) = tolerance:\n            # Boundary case\n            classification_code = 0\n        elif spectral_radius  1.0:\n            # Stable case\n            classification_code = 1\n        else: # spectral_radius > 1.0\n            # Unstable case\n            classification_code = -1\n            \n        return [classification_code, round(spectral_radius, 6)]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: k=2, p=1, A_1\n        (2, 1, [np.array([[0.5, 0.0], [0.0, 0.3]])]),\n        \n        # Case 2: k=2, p=2, A_1, A_2\n        (2, 2, [np.array([[1.0, 0.0], [0.0, 0.2]]), \n                np.array([[0.0, 0.0], [0.0, 0.0]])]),\n        \n        # Case 3: k=2, p=2, A_1, A_2\n        (2, 2, [np.array([[1.1, 0.0], [0.0, 0.9]]), \n                np.array([[0.0, 0.0], [0.0, 0.0]])]),\n\n        # Case 4: k=3, p=2, A_1, A_2\n        (3, 2, [np.array([[0.5, 0.1, 0.0], [0.0, 0.4, 0.2], [0.0, 0.0, 0.3]]), \n                np.array([[-0.1, 0.0, 0.0], [0.0, -0.2, 0.0], [0.0, 0.0, -0.1]])])\n    ]\n\n    results = []\n    for k, p, a_mats in test_cases:\n        result = check_var_stability(k, p, a_mats)\n        results.append(result)\n\n    # Format the final output list as a string.\n    # e.g., [[1, 0.5], [0, 1.0], ...] -> \"[[1, 0.500000],[0, 1.000000],...]\"\n    # The float formatting ensures 6 decimal places.\n    result_strings = [f\"[{res[0]}, {res[1]:.6f}]\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "混淆变量是因果推断中的一个主要陷阱，而共同驱动因素是其常见来源。如果两个时间序列都受到一个共同的外部因素（如季节性）的影响，那么朴素的因果检验可能会发现一个伪因果关系。本练习通过模拟这样一个场景，展示了如何正确地控制混淆变量，从而揭示真实的因果结构。",
            "id": "4116757",
            "problem": "你必须编写一个完整的、可运行的程序，构建一个模拟场景。在该场景中，遗漏的季节性会产生伪格兰杰因果关系（spurious Granger causality），然后程序需要展示包含季节性项如何消除这种假象。此任务必须从复杂适应性系统建模的第一性原理出发，使用基于线性自回归和嵌套模型比较的因果关系检测方法来解决。\n\n假设有两个标量随机时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，在整数时间 $t \\in \\{0,1,\\dots,T-1\\}$ 进行采样。存在一个未观测到的季节性驱动因素 $\\{Z_t\\}$，它是确定性的，周期为 $S$，由 $Z_t = \\sin\\!\\left(2\\pi t / S\\right)$ 给出。数据生成过程为\n$$\nX_t = a_x\\, Z_t + \\varepsilon_{x,t},\\qquad Y_t = a_y\\, Z_{t-\\delta} + \\varepsilon_{y,t},\n$$\n其中 $\\varepsilon_{x,t} \\sim \\mathcal{N}(0,\\sigma_x^2)$ 和 $\\varepsilon_{y,t} \\sim \\mathcal{N}(0,\\sigma_y^2)$ 在时间 $t$ 和序列间是独立的，并且从 $\\{X_t\\}$到 $\\{Y_t\\}$ 没有直接的因果影响。因此，当 $Z$ 被忽略时，$X$ 对 $Y$ 的任何预测能力都必然是由于共同的季节性驱动因素而产生的伪关系。\n\n从 $\\{X_t\\}$ 到 $\\{Y_t\\}$ 在滞后阶数 $p$ 上的格兰杰因果关系定义如下：如果 $\\{X_t\\}$ 的过去值在 $\\{Y_t\\}$ 自身过去值之外，为预测 $\\{Y_t\\}$ 提供了统计上显著的增量预测能力，则称 $\\{X_t\\}$ 格兰杰导致 $\\{Y_t\\}$。通过比较在 $t \\in \\{p,\\dots,T-1\\}$ 上针对 $Y_t$ 的两个嵌套线性模型来操作化此定义：\n- 一个受限模型，仅使用 $Y_t$ 的最高为 $p$ 阶的内生滞后项（以及一个截距），如果包含季节性回归量，则可选择性地用其增强。\n- 一个非受限模型，在受限模型的基础上增加了 $\\{X_t\\}$ 的最高为 $p$ 阶的滞后项。\n\n使用普通最小二乘法拟合这两个模型，并使用经典的嵌套模型检验，基于增加 $p$ 个 $X_t$ 的滞后预测变量所带来的残差平方和减少量来构建一个检验统计量。使用显著性水平 $\\alpha$ 将该检验统计量转换为一个布尔决策：检测到 $X \\to Y$ 或未检测到。你必须使用线性代数和一个在原假设下检验统计量的众所周知的连续参考分布来实现这个检验，而不依赖任何外部时间序列库。\n\n你必须运行以下测试套件，其中包含三个参数集，旨在测试一个典型案例、一个关于滞后阶数的边界条件以及一个无季节性的边缘案例。对于每个案例，使用给定的参数模拟 $\\{X_t\\}$ 和 $\\{Y_t\\}$，固定一个全局随机种子以确保结果是确定性的，并执行两次从 $X$ 到 $Y$ 的格兰杰因果关系检验：\n- 第一次检验，在受限和非受限模型中都省略季节性项。\n- 第二次检验，在受限和非受限模型中都包含季节性项，使用基本谐波 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 作为外生回归量。\n\n对于每个案例，产生两个布尔输出：\n- $b_1$：当省略季节性时，在水平 $\\alpha$ 上是否检测到从 $X$到 $Y$ 的格兰杰因果关系。\n- $b_2$：当包含季节性项时，在水平 $\\alpha$ 上是否未检测到从 $X$ 到 $Y$ 的格兰杰因果关系，这表明假象已被消除。\n\n使用以下测试套件，其中所有数学常数都已指定：\n- 案例 1：$T=1000$, $S=24$, $a_x=5.0$, $a_y=5.0$, $\\delta=1$, $\\sigma_x=0.3$, $\\sigma_y=0.3$, $p=1$, $\\alpha=0.01$。\n- 案例 2：$T=1000$, $S=24$, $a_x=5.0$, $a_y=5.0$, $\\delta=3$, $\\sigma_x=0.5$, $\\sigma_y=0.5$, $p=1$, $\\alpha=0.01$。\n- 案例 3：$T=1000$, $S=24$, $a_x=0.0$, $a_y=0.0$, $\\delta=1$, $\\sigma_x=1.0$, $\\sigma_y=1.0$, $p=1$, $\\alpha=0.01$。\n\n你的程序必须：\n- 实现针对指定参数的数据生成。\n- 实现普通最小二乘法拟合和一个用于滞后阶数 $p$ 格兰杰因果关系的嵌套模型假设检验，包含和不包含季节性回归量 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 两种情况。\n- 使用固定的随机种子，以使输出是确定性的。\n- 对于每个案例，返回如上定义的对 $[b_1,b_2]$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须为每个案例包含一个双元素列表，按上述案例顺序排列。例如，打印的行必须具有“[[b1_case1,b2_case1],[b1_case2,b2_case2],[b1_case3,b2_case3]]”的形式，并使用布尔字面量。",
            "solution": "用户提供的问题是有效的。它在科学上基于时间序列分析和计量经济学的原理，特别是解决了由遗漏变量偏差引起的伪因果关系这一有充分文献记载的问题。该问题是适定的，具有明确定义的数据生成过程、精确的统计方法（通过嵌套线性模型和F检验进行格兰杰因果关系检验），以及一套完整的模拟参数。它是客观且可形式化的，要求实现标准的、可验证的算法。该任务直接关系到在复杂适应性系统建模中进行因果关系检测的特定主题，因为它演示了如果系统建模不完整，由共同环境驱动因素介导的间接影响如何可能被误认为是直接的因果联系。\n\n### 引言\n该问题要求通过实证演示因果关系检测中的一个关键假象：由于未观测到的共同驱动因素（特别是季节性成分）而产生的伪格兰杰因果关系。我们将模拟两个时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，它们之间没有因果联系，但都受到一个共同的正弦信号的影响。然后，我们将展示当此信号从模型中被忽略时，标准的格兰杰因果关系检验会错误地检测到从 $X$ 到 $Y$ 的因果联系。随后，我们将证明，通过在回归模型中恰当地包含确定性季节性项，这种伪因果推断被正确地消除了。\n\n### 数据生成过程\n两个标量随机时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$（对于 $t \\in \\{0, 1, \\dots, T-1\\}$）根据以下过程生成：\n$$\nZ_t = \\sin\\left(\\frac{2\\pi t}{S}\\right)\n$$\n$$\nX_t = a_x Z_t + \\varepsilon_{x,t}\n$$\n$$\nY_t = a_y Z_{t-\\delta} + \\varepsilon_{y,t}\n$$\n其中 $\\{Z_t\\}$ 是一个周期为 $S$ 的确定性季节性驱动因素。项 $\\varepsilon_{x,t}$ 和 $\\varepsilon_{y,t}$ 是独立同分布的高斯白噪声过程，均值为 $0$，方差分别为 $\\sigma_x^2$ 和 $\\sigma_y^2$。关键在于，该结构规定了从 $\\{X_t\\}$ 到 $\\{Y_t\\}$ 没有直接的因果影响；它们的统计关联完全源于 $\\{Z_t\\}$ 的共同影响。\n\n### 格兰杰因果关系检验的构建\n格兰杰因果关系是一种统计假设检验，用于确定一个时间序列是否有助于预测另一个时间序列。我们评估 $\\{X_t\\}$ 的过去值是否包含了超出 $\\{Y_t\\}$ 自身过去值已包含信息之外的、有助于预测 $\\{Y_t\\}$ 的信息。这通过使用F检验比较两个嵌套线性自回归模型来形式化。\n\n对于一个滞后阶数 $p$，模型在时间范围 $t \\in \\{p, \\dots, T-1\\}$ 上定义。\n\n1.  **受限模型 ($M_R$):** 该模型仅用 $Y_t$ 自身的过去值（和一个截距）对其进行回归。\n    $$\n    Y_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + \\epsilon_{R,t}\n    $$\n\n2.  **非受限模型 ($M_U$):** 该模型将 $X_t$ 的过去值作为额外的预测变量加入。\n    $$\n    Y_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + \\sum_{i=1}^{p} \\gamma_i X_{t-i} + \\epsilon_{U,t}\n    $$\n\n检验的原假设 ($H_0$) 是 $\\{X_t\\}$ 不格兰杰导致 $\\{Y_t\\}$，这对应于所有滞后 $X_t$ 变量的系数均为零：\n$$\nH_0: \\gamma_1 = \\gamma_2 = \\dots = \\gamma_p = 0\n$$\n\n### 参数估计与假设检验\n两个模型的系数都使用普通最小二乘法（OLS）进行估计。对于一个给定的模型 $y = \\mathbf{A}\\boldsymbol{\\theta} + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{y}$ 是因变量观测值的向量，$\\mathbf{A}$ 是预测变量的设计矩阵，$\\boldsymbol{\\theta}$ 是系数向量，OLS估计值为 $\\hat{\\boldsymbol{\\theta}} = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\\mathbf{y}$。\n\n每个模型的拟合优度通过其残差平方和（RSS）来衡量，定义为 $RSS = \\sum_{t=p}^{T-1} (Y_t - \\hat{Y}_t)^2$，其中 $\\hat{Y}_t$ 是从拟合模型得到的预测值。设 $RSS_R$ 和 $RSS_U$ 分别为受限模型和非受限模型的RSS。\n\n构建F统计量来检验从 $M_R$ 转换到 $M_U$ 时RSS的减少是否显著：\n$$\nF = \\frac{(RSS_R - RSS_U) / q}{RSS_U / (n - k)}\n$$\n其中：\n- $n = T-p$ 是用于回归的观测数量。\n- $q = p$ 是非受限模型中额外预测变量的数量（即 $H_0$ 下的约束数量）。\n- $k$ 是非受限模型中总预测变量的数量（包括截距）。\n\n在原假设下，该统计量遵循自由度为 $q$ 和 $n-k$ 的F分布，即 $F(q, n-k)$。我们计算与观测到的F统计量相关的 $p$-值。如果此 $p$-值小于所选的显著性水平 $\\alpha$，我们拒绝 $H_0$ 并断定 $\\{X_t\\}$ 格兰杰导致 $\\{Y_t\\}$。\n\n### 伪因果关系及其修正\n**1. 遗漏的季节性：**\n当季节性驱动因素被遗漏时，$X$ 的过去值，即 $X_{t-i} = a_x Z_{t-i} + \\varepsilon_{x, t-i}$，充当了未观测到的季节性项 $Z_{t-i}$ 的代理变量。由于 $Y_t$ 是由 $Z_{t-\\delta}$ 驱动的，并且不同滞后的正弦波是相关的，因此 $X_{t-i}$ 将与 $Y_t$ 相关。即使在考虑了 $Y$ 的过去值 $Y_{t-i}$ 之后，这种相关性也可能持续存在。因此，向模型中添加滞后的 $X$ 值会显著减少RSS（$RSS_U \\ll RSS_R$），导致大的F统计量和小的 $p$-值。这导致了错误的因果关系检测（$b_1 = \\text{True}$）。\n\n**2. 包含的季节性：**\n为了修正这一点，我们用明确捕捉季节性模式的外生回归量来增强受限和非受限模型。一个周期为 $S$ 的正弦信号可以完全由 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 的线性组合来描述。\n增强后的受限模型变为：\n$$\nY_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + s_1 \\sin\\left(\\frac{2\\pi t}{S}\\right) + s_2 \\cos\\left(\\frac{2\\pi t}{S}\\right) + \\epsilon'_{R,t}\n$$\n这个模型现在可以直接解释来自 $Z_{t-\\delta}$ 的季节性影响，因为 $Z_{t-\\delta} = \\sin(2\\pi(t-\\delta)/S)$ 是 $\\sin$ 和 $\\cos$ 回归量的一个线性组合。一旦这种效应在受限模型中得到恰当的建模，滞后的 $X_t$ 值（它们是相同季节性信号的含噪声版本）便不再提供显著的额外预测能力。因此，$RSS_R \\approx RSS_U$，F统计量很小， $p$-值很大，我们正确地未能拒绝原假设（$b_2 = \\text{True}$）。\n\n### 算法实现\n解决方案按以下方式实现：\n1.  **数据生成**：对于每组参数，根据指定的DGP生成长度为 $T=1000$ 的时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，使用固定的随机种子以保证可复现性。\n2.  **模型设定**：定义两种测试配置：一种不含季节性项，另一种以 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 作为外生回归量。\n3.  **格兰杰因果关系检验**：对于每种配置：\n    a.  构建响应向量 $\\mathbf{y} = [Y_p, \\dots, Y_{T-1}]^T$。\n    b.  根据滞后序列和任何季节性回归量，构建受限模型和非受限模型的设计矩阵 $\\mathbf{A}_R$ 和 $\\mathbf{A}_U$。\n    c.  使用 `numpy.linalg.lstsq` 找到每个模型的OLS系数。\n    d.  为确保稳健性，手动计算每个模型的RSS。\n    e.  使用 `scipy.stats.f` 的生存函数（`sf`）计算F统计量及其对应的 $p$-值。\n    f.  将 $p$-值与 $\\alpha$ 比较，以确定是否检测到因果关系。\n4.  **输出汇编**：对于每个测试案例，将两个布尔结果（$b_1$：无季节性项时检测到因果关系；$b_2$：有季节性项时未检测到因果关系）汇编成一个列表。最终输出是这些列表的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import f\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and Granger causality tests\n    for the specified test cases.\n    \"\"\"\n    # Fix the random seed for reproducibility.\n    RANDOM_SEED = 42\n    np.random.seed(RANDOM_SEED)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Typical case with seasonality\n        {'T': 1000, 'S': 24, 'a_x': 5.0, 'a_y': 5.0, 'delta': 1, 'sigma_x': 0.3, 'sigma_y': 0.3, 'p': 1, 'alpha': 0.01},\n        # Case 2: Boundary condition with larger lag in seasonal driver\n        {'T': 1000, 'S': 24, 'a_x': 5.0, 'a_y': 5.0, 'delta': 3, 'sigma_x': 0.5, 'sigma_y': 0.5, 'p': 1, 'alpha': 0.01},\n        # Case 3: Edge case with no seasonality (pure noise)\n        {'T': 1000, 'S': 24, 'a_x': 0.0, 'a_y': 0.0, 'delta': 1, 'sigma_x': 1.0, 'sigma_y': 1.0, 'p': 1, 'alpha': 0.01},\n    ]\n\n    final_results = []\n    for params in test_cases:\n        case_results = perform_single_case(**params)\n        final_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\ndef generate_data(T, S, a_x, a_y, delta, sigma_x, sigma_y):\n    \"\"\"\n    Generates two time series X and Y based on the specified DGP.\n    \"\"\"\n    t = np.arange(T)\n    # Seasonal driver Z_t for X and Z_{t-delta} for Y\n    Z_x = a_x * np.sin(2 * np.pi * t / S)\n    Z_y = a_y * np.sin(2 * np.pi * (t - delta) / S)\n    \n    # Gaussian white noise\n    eps_x = np.random.normal(0, sigma_x, size=T)\n    eps_y = np.random.normal(0, sigma_y, size=T)\n    \n    # Final time series\n    X = Z_x + eps_x\n    Y = Z_y + eps_y\n    \n    return X, Y\n\ndef ols_fit_and_rss(y, A):\n    \"\"\"\n    Performs OLS regression and returns the Residual Sum of Squares (RSS).\n    \"\"\"\n    # Use np.linalg.lstsq for robust OLS solution\n    coeffs, _, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    \n    # Calculate residuals and RSS manually for clarity and robustness\n    predictions = A @ coeffs\n    residuals = y - predictions\n    rss = np.sum(residuals**2)\n    \n    return rss\n\ndef run_granger_test(X, Y, p, S, alpha, include_seasonality):\n    \"\"\"\n    Performs a Granger causality test from X to Y.\n\n    Returns:\n        bool: True if Granger causality is detected at significance alpha.\n    \"\"\"\n    T = len(X)\n    n = T - p  # Number of observations for regression\n\n    # Target variable for regression: Y_t for t in {p, ..., T-1}\n    y_target = Y[p:]\n\n    # --- Construct predictor matrices ---\n\n    # Intercept\n    intercept = np.ones((n, 1))\n\n    # Lags of Y\n    lags_Y_list = [Y[p-i:T-i] for i in range(1, p + 1)]\n    lags_Y = np.vstack(lags_Y_list).T\n\n    # Lags of X\n    lags_X_list = [X[p-i:T-i] for i in range(1, p + 1)]\n    lags_X = np.vstack(lags_X_list).T\n\n    # --- Restricted Model (Y's lags only) ---\n    A_R_components = [intercept, lags_Y]\n    if include_seasonality:\n        t_reg = np.arange(p, T)\n        sin_term = np.sin(2 * np.pi * t_reg / S).reshape(-1, 1)\n        cos_term = np.cos(2 * np.pi * t_reg / S).reshape(-1, 1)\n        A_R_components.extend([sin_term, cos_term])\n    \n    A_R = np.hstack(A_R_components)\n    \n    # --- Unrestricted Model (Y's lags + X's lags) ---\n    A_U = np.hstack([A_R, lags_X])\n\n    # --- Calculate RSS for both models ---\n    RSS_R = ols_fit_and_rss(y_target, A_R)\n    RSS_U = ols_fit_and_rss(y_target, A_U)\n\n    # --- Perform F-test ---\n    k = A_U.shape[1] # Total number of parameters in the unrestricted model\n    q = p            # Number of restrictions (coefficients of lagged X)\n    \n    df1 = q\n    df2 = n - k\n\n    # Ensure df2 is positive\n    if df2 = 0:\n        # This case is unlikely with the given parameters but is good practice\n        return False\n\n    F_statistic = ((RSS_R - RSS_U) / df1) / (RSS_U / df2)\n    \n    p_value = f.sf(F_statistic, df1, df2)\n\n    return p_value  alpha\n\ndef perform_single_case(T, S, a_x, a_y, delta, sigma_x, sigma_y, p, alpha):\n    \"\"\"\n    Runs both Granger causality tests for a single set of parameters.\n    \"\"\"\n    # 1. Generate data\n    X, Y = generate_data(T, S, a_x, a_y, delta, sigma_x, sigma_y)\n\n    # 2. Test without seasonal terms\n    # b1: True if Granger causality IS detected\n    gc_detected_no_season = run_granger_test(X, Y, p, S, alpha, include_seasonality=False)\n    b1 = gc_detected_no_season\n\n    # 3. Test with seasonal terms\n    # b2: True if Granger causality IS NOT detected\n    gc_detected_with_season = run_granger_test(X, Y, p, S, alpha, include_seasonality=True)\n    b2 = not gc_detected_with_season\n\n    return [b1, b2]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "在探讨了实际应用中的陷阱之后，我们转向一个更深层次的概念性问题：强耦合是否总意味着强的格兰杰因果关系或传递熵？本练习探讨了一个反直觉的场景，其中两个完全相同的系统表现出零预测因果性。这揭示了这些度量标准的核心——它们量化的是“新”的预测信息，而不仅仅是相关性或耦合强度。",
            "id": "4116811",
            "problem": "考虑一个复杂自适应系统中的一对相互作用的子系统，由两个标量时间序列 $\\{x_t\\}$ 和 $\\{y_t\\}$ 表示。源子系统 $X$ 遵循一个一阶平稳线性高斯自回归模型演化，\n$$\nx_t \\;=\\; a\\,x_{t-1} \\;+\\; \\epsilon_t,\n$$\n其中 $|a|1$，$\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^{2})$ 是独立同分布的创新项，初始条件 $x_0$ 从平稳分布中抽取，因此 $\\{x_t\\}$ 是严格平稳的。目标子系统 $Y$ 通过恒等映射与 $X$ 确定性地瞬时耦合\n$$\ny_t \\;=\\; x_t \\quad \\text{for all } t,\n$$\n因此两个观测到的时间序列是相同的。在此设定下，对两种因果关系度量均采用标准的滞后1嵌入约定。仅使用基于预测信息和方差缩减的因果关系核心定义：\n\n- 将从 $X$ 到 $Y$ 在滞后1时的传递熵（TE）定义为条件互信息\n$$\nT_{X\\to Y}(1) \\;=\\; I\\!\\left(X_{t-1};\\,Y_t \\,\\big|\\, Y_{t-1}\\right),\n$$\n在平稳分布下进行评估。使用自然对数，因此任何信息论量都以奈特（nats）为单位。\n\n- 将在滞后1时的从 $X$ 到 $Y$ 的线性高斯格兰杰因果关系定义为：仅以 $Y_{t-1}$ 为条件的 $Y_t$ 的受限预测模型，与同时以 $Y_{t-1}$ 和 $X_{t-1}$ 为条件的无约束预测模型之间的对数似然比；等价地，在高斯创新项的假设下，它可以表示为这两个模型的残差方差之比的自然对数。\n\n在这些假设和定义下，计算 $T_{X\\to Y}(1)$ 和从 $X$ 到 $Y$ 在滞后1时的线性高斯格兰杰因果关系，并给出两种度量所取的共同值。无需四舍五入。在你的推导中解释为什么尽管存在强耦合 $y_t = x_t$，这两种度量的值都为零。",
            "solution": "该问题陈述经证实具有科学依据、问题明确且客观。它在时间序列分析中提出了一个清晰、可形式化的场景，用以探究传递熵和格兰杰因果关系的基本定义。所有提供的信息都是自洽的，足以推导出唯一解。\n\n问题的核心在于确定性的恒等耦合 $y_t = x_t$，这使得两个时间序列完全相同。我们将分析这个恒等关系对传递熵和格兰杰因果关系定义的影响。\n\n**1. 传递熵的计算 ($T_{X\\to Y}(1)$)**\n\n从过程 $X$ 到过程 $Y$ 在滞后1时的传递熵定义为条件互信息：\n$$\nT_{X\\to Y}(1) = I(X_{t-1}; Y_t | Y_{t-1})\n$$\n这个量度量的是，在已知 $Y$ 的过去状态 $Y_{t-1}$ 的情况下，通过知晓 $X$ 的过去状态 $X_{t-1}$，对 $Y$ 的当前状态 $Y_t$ 的不确定性的减少程度。\n\n使用以条件熵表示的互信息定义，我们可以写出：\n$$\nT_{X\\to Y}(1) = H(Y_t | Y_{t-1}) - H(Y_t | Y_{t-1}, X_{t-1})\n$$\n其中 $H(A|B)$ 是在给定 $B$ 的情况下 $A$ 的条件熵。\n\n问题陈述 $y_t = x_t$ 对所有时间步 $t$ 成立。这意味着不仅当前状态，所有过去的状态也都存在确定性关系。具体来说，对于滞后1的项，我们有 $y_{t-1} = x_{t-1}$。这意味着随机变量 $Y_{t-1}$ 和 $X_{t-1}$ 是相同的。\n\n鉴于此恒等关系，第二项中的条件集 $(Y_{t-1}, X_{t-1})$ 包含了冗余信息。知晓 $Y_{t-1}$ 的值就完全确定了 $X_{t-1}$ 的值。因此，以这两个变量为条件等价于仅以其中一个为条件：\n$$\nH(Y_t | Y_{t-1}, X_{t-1}) = H(Y_t | Y_{t-1})\n$$\n将此代入传递熵的表达式中：\n$$\nT_{X\\to Y}(1) = H(Y_t | Y_{t-1}) - H(Y_t | Y_{t-1}) = 0\n$$\n另外，从一个更基本的角度来看，当 $C$ 已知时，条件互信息 $I(A; B | C)$ 为零当且仅当 $A$ 不提供关于 $B$ 的额外信息。在我们的案例中，$A=X_{t-1}$，$B=Y_t$，而 $C=Y_{t-1}$。由于 $X_{t-1}$ 和 $Y_{t-1}$ 是同一个变量，包含在 $X_{t-1}$ 中的所有信息都已在条件变量 $Y_{t-1}$ 中。因此，$X_{t-1}$ 没有提供关于 $Y_t$ 的*新*信息，条件互信息必须为零。\n\n**2. 格兰杰因果关系的计算 ($GC_{X\\to Y}(1)$)**\n\n线性高斯格兰杰因果关系定义为两个预测模型残差方差之比的自然对数。\n\n设 $\\Sigma_1$ 为受限模型的残差方差，该模型仅使用其自身的过去值 $Y_{t-1}$ 来预测 $Y_t$。模型为：\n$$\nY_t = c_1 Y_{t-1} + \\text{residual}_1\n$$\n设 $\\Sigma_2$ 为无约束模型的残差方差，该模型同时使用其自身的过去值 $Y_{t-1}$ 和源的过去值 $X_{t-1}$ 来预测 $Y_t$。模型为：\n$$\nY_t = c_2 Y_{t-1} + c_3 X_{t-1} + \\text{residual}_2\n$$\n则格兰杰因果关系度量为 $GC_{X\\to Y}(1) = \\ln(\\Sigma_1 / \\Sigma_2)$。\n\n首先，我们分析受限模型。利用给定的关系 $y_t = x_t$ 和 $x_t = a x_{t-1} + \\epsilon_t$，我们可以写出 $Y_t$ 的模型：\n$$\nY_t = X_t = a X_{t-1} + \\epsilon_t = a Y_{t-1} + \\epsilon_t\n$$\n这是从 $Y_{t-1}$ 对 $Y_t$ 的最佳线性预测，因此系数 $c_1$ 等于 $a$。该模型的残差为 $\\text{residual}_1 = \\epsilon_t$。该残差的方差为：\n$$\n\\Sigma_1 = \\text{Var}(\\epsilon_t) = \\sigma^2\n$$\n接下来，我们分析无约束模型。预测变量是 $Y_{t-1}$ 和 $X_{t-1}$。由于恒等关系 $y_t = x_t$，我们有 $Y_{t-1} = X_{t-1}$。这意味着两个预测变量是完全共线的。预测变量集合 $\\{Y_{t-1}, X_{t-1}\\}$ 所包含的信息与仅有集合 $\\{Y_{t-1}\\}$ 的信息完全相同。因此，将 $X_{t-1}$ 加入模型并不能提供任何可用于改善 $Y_t$ 预测的新信息。\n\n从集合 $\\{Y_{t-1}, X_{t-1}\\}$ 对 $Y_t$ 的最佳线性预测与仅从 $Y_{t-1}$ 进行的最佳线性预测是相同的。\n$$\n\\widehat{Y_t}_{\\text{unrestricted}} = \\widehat{Y_t}_{\\text{restricted}} = a Y_{t-1}\n$$\n因此，无约束模型的残差也是相同的：\n$$\n\\text{residual}_2 = Y_t - \\widehat{Y_t}_{\\text{unrestricted}} = Y_t - a Y_{t-1} = \\epsilon_t\n$$\n该残差的方差为：\n$$\n\\Sigma_2 = \\text{Var}(\\epsilon_t) = \\sigma^2\n$$\n现在我们计算格兰杰因果关系：\n$$\nGC_{X\\to Y}(1) = \\ln\\left(\\frac{\\Sigma_1}{\\Sigma_2}\\right) = \\ln\\left(\\frac{\\sigma^2}{\\sigma^2}\\right) = \\ln(1) = 0\n$$\n\n**3. 结论与解释**\n\n传递熵和格兰杰因果关系得出的值均为 $0$。共同值为 $0$。\n\n尽管存在强确定性耦合 $y_t = x_t$，但得到这个结果的原因在于这些因果关系度量的基本性质。传递熵（TE）和格兰杰因果关系（GC）都旨在量化*预测改进*。它们不衡量瞬时相关性或耦合；相反，它们衡量的是源变量的过去在多大程度上为预测目标变量提供了*新*信息，即超越了目标变量自身过去已包含的信息。\n\n在这个具体案例中，恒等耦合 $y_t = x_t$ 意味着源的过去 $X_{t-1}$ 与目标的过去 $Y_{t-1}$ 完全相同。当我们提出因果性问题——“在给定 $Y_{t-1}$ 的情况下，$X_{t-1}$ 是否有助于预测 $Y_t$？”——答案是肯定的。这是因为 $X_{t-1}$ 中的所有信息已经被对 $Y_{t-1}$ 的条件化所解释。变量 $X_{t-1}$ 在信息上是冗余的。因此，在加入 $X_{t-1}$ 后，不确定性没有减少（对于TE），残差方差也没有减少（对于GC）。两种度量都正确地报告了零值，表明在这种特定的信息结构下，不存在从 $X$ 到 $Y$ 的时滞预测因果联系。这个例子巧妙地证明了强耦合并不意味着非零的TE或GC；这些度量只对那些从目标自身历史中尚不明显的影響敏感。",
            "answer": "$$\n\\boxed{0}\n$$"
        }
    ]
}