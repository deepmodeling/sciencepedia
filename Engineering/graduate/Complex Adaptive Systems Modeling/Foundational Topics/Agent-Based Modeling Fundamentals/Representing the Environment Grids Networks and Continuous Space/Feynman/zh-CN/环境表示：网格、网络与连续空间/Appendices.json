{
    "hands_on_practices": [
        {
            "introduction": "网格是表示空间环境的直观方法，但边界处的规则对系统动力学至关重要。本练习  将通过一个一维网格上的随机游走模型，探讨两种不同边界条件——反射与吸收——如何从根本上改变主体到达目标的行为。通过从第一性原理推导平均首次到达时间（MFPT），您将亲身体验环境定义（特别是边界）对模型结果的深刻影响。",
            "id": "4140773",
            "problem": "考虑一个在一维网格上的离散时间、无偏随机游走，网格点为 $0, 1, 2, \\dots, L$，其中 $L \\in \\mathbb{N}$ 且 $L \\geq 2$。在每个内部格点 $i \\in \\{1, 2, \\dots, L-1\\}$，游走者以 $1/2$ 的概率移动到 $i-1$，以 $1/2$ 的概率移动到 $i+1$。边界处的动态因情景而异，目标集为单个格点 $0$。\n\n情景 R（在 $L$ 处为反射边界）：当位于 $L$ 时，游走者在一个时间步内确定性地移动到 $L-1$。设 $T^{(R)}_i$ 表示在情景 R 下，从格点 $i \\in \\{1, \\dots, L\\}$ 出发，到达目标集 $\\{0\\}$ 的平均首达时间（MFPT）。\n\n情景 A（在 $L$ 处为吸收边界）：当位于 $L$ 时，游走者被吸收，过程终止。设 $T^{(A|0)}_i$ 表示从格点 $i \\in \\{1, \\dots, L-1\\}$ 出发，在被 $L$ 吸收之前到达格点 $0$ 的条件下，到达目标集 $\\{0\\}$ 的 MFPT。\n\n从马尔可夫链的后向方程定义的 MFPT 基础出发，不使用任何预先推导的快捷公式，推导 $T^{(R)}_i$ 和 $T^{(A|0)}_i$ 作为 $L$ 和 $i$ 的函数表达式。然后，计算比率\n$$\n\\frac{T^{(A|0)}_i}{T^{(R)}_i}\n$$\n并以最简精确形式给出。无需四舍五入。最终答案必须是写成最简分数形式的单个实数。",
            "solution": "**第一部分：情景 R（在 $L$ 处为反射边界）**\n\n设 $E_i = T^{(R)}_i$ 为从格点 $i$ 出发到目标 $0$ 的平均首达时间（MFPT）。MFPT 满足后向主方程：\n$$\nE_i = 1 + \\sum_j P_{ij} E_j\n$$\n其中 $P_{ij}$ 是从格点 $i$ 到 $j$ 的转移概率。\n根据问题定义，我们有以下方程组：\n- 目标条件：$E_0 = 0$\n- 内部格点 $i \\in \\{1, \\dots, L-1\\}$：$E_i = 1 + \\frac{1}{2} E_{i-1} + \\frac{1}{2} E_{i+1}$\n- 反射边界 $i=L$：$E_L = 1 + E_{L-1}$\n\n整理内部格点的方程，我们得到一个二阶线性差分方程：\n$$\nE_{i+1} - 2E_i + E_{i-1} = -2\n$$\n定义一阶差分 $\\Delta_i = E_i - E_{i-1}$。该方程可写为 $\\Delta_{i+1} - \\Delta_i = -2$，这表明 $\\Delta_i$ 是一个公差为 $-2$ 的等差数列。因此，$\\Delta_i = \\Delta_1 - 2(i-1)$。\n由于 $E_0=0$，我们有 $\\Delta_1 = E_1 - E_0 = E_1$。所以，$\\Delta_i = E_1 - 2(i-1)$。\n通过对差分求和来重构 $E_i$：\n$$\nE_i = E_i - E_0 = \\sum_{k=1}^{i} (E_k - E_{k-1}) = \\sum_{k=1}^{i} \\Delta_k = \\sum_{k=1}^{i} (E_1 - 2(k-1))\n$$\n$$\nE_i = iE_1 - 2 \\sum_{k=0}^{i-1} k = iE_1 - 2 \\frac{(i-1)i}{2} = iE_1 - i(i-1)\n$$\n为了确定 $E_1$，我们使用在 $L$ 处的边界条件 $E_L = 1 + E_{L-1}$：\n$$\nL E_1 - L(L-1) = 1 + \\left[ (L-1)E_1 - (L-1)(L-2) \\right]\n$$\n$$\nL E_1 - (L-1)E_1 = 1 - (L-1)(L-2) + L(L-1)\n$$\n$$\nE_1 = 1 + (L-1)(-L+2+L) = 1 + 2(L-1) = 2L - 1\n$$\n将 $E_1$ 代回 $E_i$ 的表达式中：\n$$\nT^{(R)}_i = E_i = i(2L-1) - i(i-1) = 2Li - i - i^2 + i = i(2L - i)\n$$\n\n**第二部分：情景 A（在 $L$ 处有吸收边界的条件 MFPT）**\n\n设 $F_i = T^{(A|0)}_i$。这是一个条件 MFPT。首先，我们需求解从 $i$ 出发，在到达 $L$ 之前先到达 $0$ 的概率，记为 $h_i$。$h_i$ 满足后向方程：\n$$\nh_i = \\frac{1}{2}h_{i-1} + \\frac{1}{2}h_{i+1}\n$$\n边界条件为 $h_0=1$（成功）和 $h_L=0$（失败）。这是一个线性递推关系，其解为 $h_i = 1 - \\frac{i}{L}$。\n\n条件 MFPT $F_i$ 的后向方程为：\n$$\nF_i = 1 + \\sum_j \\frac{P_{ij}h_j}{h_i} F_j = 1 + \\frac{h_{i-1}}{2h_i} F_{i-1} + \\frac{h_{i+1}}{2h_i} F_{i+1}\n$$\n代入 $h_i = (L-i)/L$ 的表达式：\n$$\nF_i = 1 + \\frac{L-i+1}{2(L-i)} F_{i-1} + \\frac{L-i-1}{2(L-i)} F_{i+1}\n$$\n边界条件为 $F_0=0$。定义差分 $\\delta_i = F_i - F_{i-1}$。整理上述递推关系可得关于 $\\delta_i$ 的新关系：\n$$\n(L-i-1)\\delta_{i+1} - (L-i+1)\\delta_i = -2(L-i)\n$$\n可以验证该方程的解为 $\\delta_i = \\frac{2(L-i)+1}{3}$。\n通过对差分求和来重构 $F_i$：\n$$\nF_i = \\sum_{k=1}^{i} \\delta_k = \\sum_{k=1}^{i} \\frac{2(L-k)+1}{3} = \\frac{1}{3} \\left( \\sum_{k=1}^{i} (2L+1) - 2\\sum_{k=1}^{i} k \\right)\n$$\n$$\nF_i = \\frac{1}{3} \\left( i(2L+1) - 2\\frac{i(i+1)}{2} \\right) = \\frac{i}{3} (2L+1 - i - 1) = \\frac{i(2L-i)}{3}\n$$\n因此，情景 A 下的条件 MFPT 为：\n$$\nT^{(A|0)}_i = \\frac{i(2L-i)}{3}\n$$\n\n**第三部分：计算比率**\n\n现在我们计算所求的比率，其中 $i \\in \\{1, \\dots, L-1\\}$：\n$$\n\\frac{T^{(A|0)}_i}{T^{(R)}_i} = \\frac{\\frac{i(2L - i)}{3}}{i(2L - i)}\n$$\n由于对于 $i \\in \\{1, \\dots, L-1\\}$，项 $i(2L-i)$ 非零，我们可以消去它：\n$$\n\\frac{T^{(A|0)}_i}{T^{(R)}_i} = \\frac{1}{3}\n$$\n该比率是一个与起始位置 $i$ 和系统大小 $L$ 无关的常数。",
            "answer": "$$\n\\boxed{\\frac{1}{3}}\n$$"
        },
        {
            "introduction": "与结构化的网格不同，网络为环境提供了一种更抽象的拓扑表示，侧重于节点间的关系而非空间邻近性。Erdős–Rényi 随机图是研究随机网络结构如何形成的基本模型。此练习  旨在引导您推导“巨型连通分量”出现的临界阈值，这是一个经典的相变现象，揭示了微观的随机连接规则如何在宏观尺度上催生出全局结构。",
            "id": "4140762",
            "problem": "一个相互作用的智能体群体嵌入一个随机网络中，该网络用于表示环境，并被建模为一个 Erdős–Rényi (ER) 随机图 $G(n,p)$：图中存在 $n$ 个已标记顶点，并且 $\\frac{n(n-1)}{2}$ 条可能的无向边中的每一条都以概率 $p$ 独立存在。均匀选择的一个顶点的度分布为 $\\mathrm{Binomial}(n-1,p)$，并且对于大的 $n$，该图在有限距离内以高概率是局部树状的。令 $p = p(n)$ 并定义 $c_{n} \\equiv n p(n)$。在 $n \\to \\infty$ 的渐近状态下，仅使用这些基础性质来确定精确的阈值 $c^{\\star}$，使得如果 $c_{n} \\to c  c^{\\star}$，则最大连通分量的大小以高概率为 $o(n)$；而如果 $c_{n} \\to c > c^{\\star}$，则该图以高概率包含一个大小为 $\\Theta(n)$ 的连通分量。请以单个精确实数的形式提供 $c^{\\star}$ 的值。将最终答案表示为未经四舍五入的精确值。",
            "solution": "该问题要求解出 Erdős–Rényi 随机图 $G(n,p)$ 中“巨型”连通分量出现的临界阈值。从所有分量都很小（大小为 $o(n)$）的状态过渡到存在单个大分量（大小为 $\\Theta(n)$）的状态是一种经典的相变现象。我们可以通过将连通分量的探索过程建模为分支过程来确定阈值 $c^{\\star}$，这种方法由给定的性质——即图在 $n$ 很大时是局部树状的——所证明是合理的。\n\n我们来考虑探索包含一个随机选择顶点的连通分量的过程。这可以看作是一次广度优先搜索。我们从单个顶点（第 $0$ 代）开始。它的邻居构成第 $1$ 代。第 $1$ 代顶点的邻居（未被发现的）构成第 $2$ 代，依此类推。在 $n \\to \\infty$ 的极限下，对于有限步数，遇到已访问顶点的概率可以忽略不计。这使我们能够将分量探索近似为一个 Galton-Watson 分支过程，其中顶点是个体，连接到新顶点的边代表后代。\n\n分支过程的命运（灭绝还是无限存续）由每个个体的平均后代数决定，我们将其表示为 $\\mu$。分支过程的一个基本定理指出，如果 $\\mu > 1$，则存续的概率非零；而如果 $\\mu \\le 1$，则过程以概率 $1$ 灭绝。在我们的图论背景下，“存续”对应于一个大小为 $\\Theta(n)$ 的巨型分量，而“灭绝”对应于一个大小为 $o(n)$ 的小分量。因此，相变发生在 $\\mu=1$ 处。\n\n我们的任务简化为计算平均后代数 $\\mu$，将其作为参数 $c = \\lim_{n \\to \\infty} c_n = \\lim_{n \\to \\infty} n p(n)$ 的函数。在探索过程中，一个顶点 $v$ 的“后代”是它的邻居，不包括发现 $v$ 的那个顶点。因此，这样的后代数量为 $d(v) - 1$，其中 $d(v)$ 是 $v$ 的度。\n\n首先，我们确定一个随机均匀选择的顶点的度分布。问题指出这是一个二项分布，$D \\sim \\mathrm{Binomial}(n-1, p)$。在 $n \\to \\infty$ 且 $p = c_n/n$ 且 $c_n \\to c$ 的渐近状态下，该二项分布收敛于均值为 $c$ 的泊松分布。一个顶点度为 $k$ 的概率质量函数变为：\n$$ \\mathbb{P}(D=k) \\to \\frac{c^k e^{-c}}{k!} $$\n平均度为 $\\langle D \\rangle = \\sum_{k=0}^{\\infty} k \\, \\mathbb{P}(D=k) = c$。\n\n接下来，我们必须找到后代数量的分布。对于分支过程中除根节点外的任何顶点，我们都是通过遍历一条边到达它的。沿着一条随机边到达的顶点的度不遵循相同的 $\\mathrm{Poisson}(c)$ 分布。高度顶点连接的边更多，因此它们更有可能被选中。一条边通向一个度为 $k$ 的顶点的概率与 $k \\mathbb{P}(D=k)$ 成正比。因此，在一条随机边末端的顶点的度分布 $D_{\\text{edge}}$ 为：\n$$ \\mathbb{P}(D_{\\text{edge}}=k) = \\frac{k \\mathbb{P}(D=k)}{\\sum_j j \\mathbb{P}(D=j)} = \\frac{k \\mathbb{P}(D=k)}{\\langle D \\rangle} $$\n这样一个顶点的后代数量是其度减一，即 $D_{\\text{edge}} - 1$。平均后代数 $\\mu$ 是这个量的期望值：\n$$ \\mu = \\mathbb{E}[D_{\\text{edge}} - 1] = \\mathbb{E}[D_{\\text{edge}}] - 1 $$\n期望值 $\\mathbb{E}[D_{\\text{edge}}]$ 为：\n$$ \\mathbb{E}[D_{\\text{edge}}] = \\sum_{k=1}^{\\infty} k \\, \\mathbb{P}(D_{\\text{edge}}=k) = \\sum_{k=1}^{\\infty} k \\frac{k \\mathbb{P}(D=k)}{\\langle D \\rangle} = \\frac{1}{\\langle D \\rangle} \\sum_{k=0}^{\\infty} k^2 \\mathbb{P}(D=k) = \\frac{\\langle D^2 \\rangle}{\\langle D \\rangle} $$\n对于参数为 $c$ 的泊松分布，均值为 $\\langle D \\rangle = c$，方差为 $\\mathrm{Var}(D) = c$。二阶矩由 $\\langle D^2 \\rangle = \\mathrm{Var}(D) + \\langle D \\rangle^2 = c + c^2$ 给出。\n代入这些值，我们得到平均后代数：\n$$ \\mu = \\frac{\\langle D^2 \\rangle}{\\langle D \\rangle} - 1 = \\frac{c + c^2}{c} - 1 = (1+c) - 1 = c $$\n在分支过程近似中，平均后代数等于 $c$，即图的渐近平均度。\n\n相变的临界阈值对应于平均后代数恰好为 $1$ 的点。\n$$ \\mu = 1 $$\n$$ c = 1 $$\n因此，阈值为 $c^{\\star} = 1$。如果 $c_n \\to c  1$，分支过程会消亡，意味着最大分量的大小为 $o(n)$。如果 $c_n \\to c > 1$，分支过程以非零概率存续，意味着存在一个大小为 $\\Theta(n)$ 的巨型分量。这与问题陈述中给出的条件完全一致。精确的阈值为 $1$。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "在许多复杂自适应系统中，环境是连续且非均匀的，这给直接模拟带来了挑战。瘦身算法（thinning algorithm）为此提供了一种优雅而强大的计算方法，用于生成非齐次泊松过程的点。在本练习  中，您不仅需要从基本原理上证明该算法的正确性，还将通过代码实现它，从而将泊松过程的理论定义与在非均匀连续空间中进行模拟的实用技术联系起来。",
            "id": "4140718",
            "problem": "您的任务是设计并实现一个细化算法，以模拟连续域上的非齐次泊松点过程，并基于第一性原理对其正确性进行论证。在一个可测域 $\\Omega \\subset \\mathbb{R}^{d}$ 上，具有非负可积强度函数 $\\lambda(x)$ 的非齐次泊松点过程由以下两个性质定义：对于任意有界可测子集 $A \\subset \\Omega$，点数 $N(A)$ 服从均值为 $\\int_{A} \\lambda(x)\\,dx$ 的泊松分布；对于两两不交的可测子集 $A_{1}, \\dots, A_{k}$，随机变量 $N(A_{1}), \\dots, N(A_{k})$ 是独立的。\n\n您必须从同一域上速率恒为 $\\Lambda_{\\max}$ 的齐次泊松点过程出发，推导并实现一个基于细化的模拟器，其中 $\\Lambda_{\\max} \\ge \\sup_{x \\in \\Omega} \\lambda(x)$。该算法必须纯粹用数学术语表达，并用代码实现。角度必须以弧度为单位。\n\n您可以假定的基本基础包括泊松点过程的定义、泊松分布的性质以及标准的独立性和条件化规则。目标细化算法不能直接假定，必须从基础推导出来。您还必须通过证明您的模拟器输出满足非齐次泊松点过程的定义属性来论证其正确性。\n\n算法任务：为代表连续空间的两种环境实现以下细化模拟器。\n\n1. 对于区间 $[0, T]$ 上的一维时间，强度为 $\\lambda(t)$，上界为 $\\Lambda_{\\max}$：\n   - 通过抽取一个泊松数 $N \\sim \\mathrm{Poisson}(\\Lambda_{\\max} T)$ 作为候选时间点，并将其独立均匀地放置在 $[0, T]$ 中，来生成一个速率为 $\\Lambda_{\\max}$ 的齐次泊松过程。\n   - 对于每个候选时间点 $t$，以概率 $p(t) = \\lambda(t)/\\Lambda_{\\max}$ 独立地保留它，否则丢弃它。\n   - 对保留的时间点进行排序，以获得模拟的非齐次过程。\n\n2. 对于矩形 $[a_{x}, b_{x}] \\times [a_{y}, b_{y}]$ 上的二维空间，强度为 $\\lambda(x,y)$，上界为 $\\Lambda_{\\max}$：\n   - 通过抽取 $N \\sim \\mathrm{Poisson}(\\Lambda_{\\max} |[a_{x}, b_{x}] \\times [a_{y}, b_{y}]|)$ 个候选点，并将它们独立均匀地放置在矩形内，来生成一个速率为 $\\Lambda_{\\max}$ 的齐次泊松点过程。\n   - 对于每个候选点 $(x, y)$，以概率 $p(x,y) = \\lambda(x,y)/\\Lambda_{\\max}$ 独立地保留它，否则丢弃它。\n\n对于一维情况，定义积分强度 $\\Lambda(t) = \\int_{0}^{t} \\lambda(s)\\,ds$。对于一次实现，若保留的时间点为 $0  t_{1}  \\dots  t_{n} \\le T$，定义变换后的增量 $e_{i} = \\Lambda(t_{i}) - \\Lambda(t_{i-1})$，并约定 $t_{0} = 0$。时间重标度定理指出，如果 $(t_{i})$ 是一个强度为 $\\lambda(t)$ 的非齐次泊松过程，那么 $(e_{i})$ 是独立同分布于 $\\mathrm{Exponential}(1)$ 的随机变量。\n\n您的实现必须使用上述算法和以下固定的测试套件来产生确定性输出。为了可复现性，您必须为伪随机数生成器使用指定的种子。所有角度都以弧度为单位。不涉及物理单位。\n\n测试套件：\n\n- 测试 $1$（一维正弦强度）：在 $[0, T]$ 上进行模拟，其中 $T = 10$，$\\lambda(t) = 2 + \\sin(t)$，$\\Lambda_{\\max} = 3$。使用伪随机数种子 $314159$。令 $n_{1}$ 为保留事件的数量，令 $D_{1}$ 为通过单样本 Kolmogorov–Smirnov 检验，比较 $(e_{i})$ 的经验分布与 $\\mathrm{Exponential}(1)$ 分布的 Kolmogorov–Smirnov 统计量。\n\n- 测试 $2$（$x$ 方向上的二维线性强度）：在 $[a_{x}, b_{x}] \\times [a_{y}, b_{y}] = [0, 1] \\times [0, 1]$ 上进行模拟，其中 $\\lambda(x,y) = 10 (1 + x)$，$\\Lambda_{\\max} = 20$。使用伪随机数种子 $271828$。令 $n_{2}$ 为保留点的数量，令 $\\bar{x}_{2}$ 为保留点 $x$ 坐标的样本均值，令 $\\delta_{2} = \\bar{x}_{2} - \\frac{5}{9}$，其中 $\\frac{5}{9}$ 是在 $[0,1]$ 上与 $1+x$ 成正比的归一化密度下的精确期望 $x$ 均值。\n\n- 测试 $3$（带零值区域的一维分段强度）：在 $[0, T]$ 上进行模拟，其中 $T = 5$，当 $t \\in [0, 2.5]$ 时 $\\lambda(t) = 0$，当 $t \\in (2.5, 5]$ 时 $\\lambda(t) = 4$，且 $\\Lambda_{\\max} = 4$。使用伪随机数种子 $161803$。令 $n_{3}^{(L)}$ 为在 $[0, 2.5]$ 中保留的事件数，令 $n_{3}^{(R)}$ 为在 $(2.5, 5]$ 中保留的事件数。\n\n- 测试 $4$（一维极低齐次强度）：在 $[0, T]$ 上进行模拟，其中 $T = 10$，$\\lambda(t) = 10^{-3}$，$\\Lambda_{\\max} = 10^{-3}$。使用伪随机数种子 $141421$。令 $n_{4}$ 为保留事件的总数。\n\n答案规格：\n\n- 您的程序必须输出包含测试套件结果的单行，结果的顺序和类型如下：$[n_{1}, D_{1}, n_{2}, \\bar{x}_{2}, \\delta_{2}, n_{3}^{(L)}, n_{3}^{(R)}, n_{4}]$。\n- 浮点数 $D_{1}$、$\\bar{x}_{2}$ 和 $\\delta_{2}$ 必须四舍五入到小数点后六位。整数必须不经四舍五入直接打印。输出必须是单行，形式为一个用逗号分隔并用方括号括起来的列表，且不含空格，例如 $[42,0.123456,17,0.555556,0.000000,0,9,0]$。",
            "solution": "该任务是推导和证明用于模拟非齐次泊松点过程（IPPP）的细化算法的正确性，然后为定义的测试套件实现该算法。推导必须从第一性原理出发。\n\n在域 $\\Omega \\subset \\mathbb{R}^{d}$ 上，具有非负可积强度函数 $\\lambda(x)$ 的 IPPP 由两个定义属性来刻画：\n1.  对于任何有界可测子集 $A \\subset \\Omega$，点数 $N(A)$ 服从均值为 $\\mu(A) = \\int_{A} \\lambda(x)\\,dx$ 的泊松分布。\n2.  对于任何有限个两两不交的可测子集 $A_{1}, \\dots, A_{k} \\subset \\Omega$，随机变量 $N(A_{1}), \\dots, N(A_{k})$ 是独立的。\n\n细化算法模拟了这样一个过程。它从同一域 $\\Omega$ 上的一个齐次泊松点过程（HPPP）开始，该过程记为 $\\mathcal{P}_{\\text{hom}}$，具有恒定速率 $\\Lambda_{\\max}$，其中 $\\Lambda_{\\max}$ 是强度函数的上界，即 $\\Lambda_{\\max} \\ge \\sup_{x \\in \\Omega} \\lambda(x)$。然后，通过以与位置相关的概率 $p(x) = \\lambda(x) / \\Lambda_{\\max}$ 独立地保留来自 $\\mathcal{P}_{\\text{hom}}$ 的每个点 $x$，生成一个新的点过程 $\\mathcal{P}_{\\text{thin}}$。这个过程被称为细化。我们现在必须证明所得到的过程 $\\mathcal{P}_{\\text{thin}}$ 确实是一个强度为 $\\lambda(x)$ 的 IPPP。\n\n**正确性证明**\n\n我们必须验证 $\\mathcal{P}_{\\text{thin}}$ 满足 IPPP 的两个定义属性。\n\n**1. 点数分布**\n令 $A$ 为 $\\Omega$ 的一个有界可测子集。我们需要证明来自细化过程中位于 $A$ 内的点数，记为 $N_{\\text{thin}}(A)$，服从均值为 $\\int_{A} \\lambda(x)\\,dx$ 的泊松分布。\n\n来自 HPPP 在集合 $A$ 中的点数，记为 $N_{\\text{hom}}(A)$，是一个随机变量，服从均值为 $\\Lambda_{\\max} |A|$ 的泊松分布，其中 $|A|$ 是 $A$ 的勒贝格测度。其概率质量函数为 $P(N_{\\text{hom}}(A)=k) = e^{-\\Lambda_{\\max} |A|} \\frac{(\\Lambda_{\\max} |A|)^k}{k!}$，对于 $k \\in \\{0, 1, 2, \\dots\\}$。\n\n给定 $N_{\\text{hom}}(A) = k$，HPPP 的 $k$ 个点独立且均匀地分布在集合 $A$ 内。设这些点为 $\\{Y_1, \\dots, Y_k\\}$。每个点 $Y_j$ 以概率 $p(Y_j) = \\lambda(Y_j) / \\Lambda_{\\max}$ 被保留。令 $I_j$ 为指示变量，如果点 $Y_j$ 被保留，则其值为 $1$，否则为 $0$。在 $A$ 中保留的总点数为 $N_{\\text{thin}}(A) = \\sum_{j=1}^k I_j$。\n\n保留一个在 $A$ 中均匀分布的任意单点的概率是 $p(y)$ 在 $A$ 上的平均值：\n$$ \\bar{p}_A = E[p(Y_j)] = \\int_A p(y) f_Y(y)\\,dy = \\int_A \\frac{\\lambda(y)}{\\Lambda_{\\max}} \\frac{1}{|A|}\\,dy = \\frac{1}{\\Lambda_{\\max} |A|} \\int_A \\lambda(y)\\,dy $$\n其中 $f_Y(y) = 1/|A|$（对于 $y \\in A$）是在 $A$ 中均匀选择一个点的概率密度函数。\n\n在 $N_{\\text{hom}}(A) = k$ 的条件下，保留的点数 $N_{\\text{thin}}(A)$ 服从二项分布 $B(k, \\bar{p}_A)$。因此，$P(N_{\\text{thin}}(A)=n | N_{\\text{hom}}(A)=k) = \\binom{k}{n} (\\bar{p}_A)^n (1-\\bar{p}_A)^{k-n}$。\n\n使用全概率定律，$N_{\\text{thin}}(A)$ 的无条件概率质量函数为：\n$$ P(N_{\\text{thin}}(A)=n) = \\sum_{k=n}^{\\infty} P(N_{\\text{thin}}(A)=n | N_{\\text{hom}}(A)=k) P(N_{\\text{hom}}(A)=k) $$\n$$ P(N_{\\text{thin}}(A)=n) = \\sum_{k=n}^{\\infty} \\left[ \\binom{k}{n} (\\bar{p}_A)^n (1-\\bar{p}_A)^{k-n} \\right] \\left[ e^{-\\Lambda_{\\max} |A|} \\frac{(\\Lambda_{\\max} |A|)^k}{k!} \\right] $$\n通过重新整理各项：\n$$ P(N_{\\text{thin}}(A)=n) = \\frac{(\\bar{p}_A \\Lambda_{\\max} |A|)^n}{n!} e^{-\\Lambda_{\\max} |A|} \\sum_{k=n}^{\\infty} \\frac{1}{(k-n)!} \\left( (1-\\bar{p}_A) \\Lambda_{\\max} |A| \\right)^{k-n} $$\n令 $j=k-n$。求和部分变为 $\\sum_{j=0}^{\\infty} \\frac{1}{j!} ((1-\\bar{p}_A)\\Lambda_{\\max} |A|)^j$，这是 $e^{(1-\\bar{p}_A)\\Lambda_{\\max} |A|}$ 的泰勒级数。\n将其代回，我们得到：\n$$ P(N_{\\text{thin}}(A)=n) = \\frac{(\\bar{p}_A \\Lambda_{\\max} |A|)^n}{n!} e^{-\\Lambda_{\\max} |A|} e^{(1-\\bar{p}_A)\\Lambda_{\\max} |A|} $$\n$$ P(N_{\\text{thin}}(A)=n) = \\frac{(\\bar{p}_A \\Lambda_{\\max} |A|)^n}{n!} e^{-\\bar{p}_A \\Lambda_{\\max} |A|} $$\n这是均值为 $\\mu_{\\text{thin}} = \\bar{p}_A \\Lambda_{\\max} |A|$ 的泊松分布的概率质量函数。代入 $\\bar{p}_A$ 的表达式：\n$$ \\mu_{\\text{thin}} = \\left( \\frac{1}{\\Lambda_{\\max} |A|} \\int_A \\lambda(y)\\,dy \\right) \\Lambda_{\\max} |A| = \\int_A \\lambda(y)\\,dy $$\n因此，$N_{\\text{thin}}(A) \\sim \\text{Poisson}(\\int_A \\lambda(x)\\,dx)$，满足第一个性质。\n\n**2. 计数的独立性**\n令 $A_1, \\dots, A_k$ 为 $\\Omega$ 的两两不交的可测子集。我们必须证明计数 $N_{\\text{thin}}(A_1), \\dots, N_{\\text{thin}}(A_k)$ 是独立的随机变量。\n\nHPPP $\\mathcal{P}_{\\text{hom}}$ 的一个基本性质是，限制在不相交集合上的点过程是独立的。这意味着随机点集 $\\mathcal{P}_{\\text{hom}} \\cap A_1, \\dots, \\mathcal{P}_{\\text{hom}} \\cap A_k$ 是相互独立的。\n\n细化操作对 $\\mathcal{P}_{\\text{hom}}$ 的每个点独立于所有其他点进行。保留一个点 $x \\in A_i$ 的决定仅取决于其位置 $x$ 和一次独立的随机抽样（例如，将 $\\lambda(x)/\\Lambda_{\\max}$ 与从 $U(0,1)$ 中抽取的值进行比较）。这个决定不受任何在另一集合 $A_j$（其中 $j \\neq i$）中的点的存在或保留情况的影响。\n\n由于不相交集合 $A_i$ 中的初始点配置是独立的，并且每个集合内的细化操作与其他集合的操作是独立的，因此得到的细化点配置 $\\mathcal{P}_{\\text{thin}} \\cap A_1, \\dots, \\mathcal{P}_{\\text{thin}} \\cap A_k$ 也是相互独立的。因此，它们各自的计数 $N_{\\text{thin}}(A_1), \\dots, N_{\\text{thin}}(A_k)$ 是独立的随机变量。这就确立了第二个性质。\n\nIPPP 的两个定义属性都得到了满足。因此，细化算法正确地生成了具有期望强度函数 $\\lambda(x)$ 的非齐次泊松点过程的实现。条件 $\\Lambda_{\\max} \\ge \\sup \\lambda(x)$ 至关重要，因为它保证了保留概率 $p(x) = \\lambda(x)/\\Lambda_{\\max}$ 是良定义的，并且位于区间 $[0, 1]$ 内。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the thinning algorithm simulator.\n    \"\"\"\n    \n    def test_1(seed):\n        \"\"\"\n        Test 1: 1D sinusoidal intensity.\n        Simulates on [0, T] with T = 10, lambda(t) = 2 + sin(t), and Lambda_max = 3.\n        Calculates number of events and KS statistic vs. Exponential(1).\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        T = 10.0\n        Lambda_max = 3.0\n        \n        lambda_t = lambda t: 2 + np.sin(t)\n        \n        # 1. Generate homogeneous Poisson process candidates\n        num_candidates = rng.poisson(Lambda_max * T)\n        candidate_times = rng.uniform(0, T, num_candidates)\n        \n        # 2. Thin the candidates\n        retention_probs = lambda_t(candidate_times) / Lambda_max\n        retained_mask = rng.uniform(0, 1, num_candidates)  retention_probs\n        retained_times = candidate_times[retained_mask]\n        \n        n1 = len(retained_times)\n        \n        # 3. Sort times and perform time-rescaling\n        retained_times.sort()\n        \n        # Integrated intensity: Lambda(t) = integral_0^t (2+sin(s))ds = 2t - cos(t) + 1\n        Lambda_of_t = lambda t: 2 * t - np.cos(t) + 1\n        \n        if n1  2:\n            # KS test requires at least one data point, and increments require at least 2.\n            D1 = 0.0\n        else:\n            Lambda_vals = Lambda_of_t(retained_times)\n            # Transformed increments e_i = Lambda(t_i) - Lambda(t_{i-1})\n            e_values = np.diff(Lambda_vals, prepend=Lambda_of_t(0))\n            # 4. Compare with Exponential(1) using KS test\n            ks_result = stats.kstest(e_values, 'expon')\n            D1 = ks_result.statistic\n        \n        return n1, D1\n\n    def test_2(seed):\n        \"\"\"\n        Test 2: 2D linear intensity in x.\n        Simulates on [0, 1]x[0, 1] with lambda(x,y) = 10(1+x), Lambda_max = 20.\n        Calculates number of points, sample mean of x, and its deviation from theoretical mean.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        ax, bx = 0.0, 1.0\n        ay, by = 0.0, 1.0\n        Lambda_max = 20.0\n        \n        area = (bx - ax) * (by - ay)\n        lambda_xy = lambda x, y: 10 * (1 + x)\n        \n        # 1. Generate homogeneous Poisson process candidates\n        num_candidates = rng.poisson(Lambda_max * area)\n        candidate_points_x = rng.uniform(ax, bx, num_candidates)\n        candidate_points_y = rng.uniform(ay, by, num_candidates)\n        \n        # 2. Thin the candidates\n        retention_probs = lambda_xy(candidate_points_x, candidate_points_y) / Lambda_max\n        retained_mask = rng.uniform(0, 1, num_candidates)  retention_probs\n        retained_points_x = candidate_points_x[retained_mask]\n        \n        n2 = len(retained_points_x)\n        \n        if n2 == 0:\n            x_bar_2 = 0.0\n        else:\n            x_bar_2 = np.mean(retained_points_x)\n            \n        # Theoretical mean E[X] for density proportional to 1+x on [0,1] is 5/9\n        delta_2 = x_bar_2 - 5/9\n        \n        return n2, x_bar_2, delta_2\n\n    def test_3(seed):\n        \"\"\"\n        Test 3: 1D piecewise intensity.\n        Simulates on [0, 5] with lambda(t) = 0 for t in [0, 2.5] and 4 for t in (2.5, 5].\n        Lambda_max = 4. Counts events in each part of the interval.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        T = 5.0\n        Lambda_max = 4.0\n        \n        def lambda_t(t):\n            return np.piecewise(t, [t = 2.5], [0, 4])\n\n        # 1. Generate homogeneous Poisson process candidates\n        num_candidates = rng.poisson(Lambda_max * T)\n        candidate_times = rng.uniform(0, T, num_candidates)\n        \n        # 2. Thin the candidates\n        retention_probs = lambda_t(candidate_times) / Lambda_max\n        retained_mask = rng.uniform(0, 1, num_candidates)  retention_probs\n        retained_times = candidate_times[retained_mask]\n        \n        # 3. Count events in specified intervals\n        n3_L = np.sum(retained_times = 2.5)\n        n3_R = np.sum(retained_times  2.5)\n        \n        return n3_L, n3_R\n\n    def test_4(seed):\n        \"\"\"\n        Test 4: 1D very low homogeneous intensity.\n        Simulates on [0, 10] with lambda(t) = 1e-3, Lambda_max = 1e-3.\n        Calculates total number of events.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        T = 10.0\n        lambda_val = 1e-3\n        Lambda_max = 1e-3 # This implies retention probability is 1\n        \n        # Since lambda/Lambda_max = 1, all candidates are retained.\n        # The number of events is just a draw from Poisson(lambda * T).\n        n4 = rng.poisson(lambda_val * T)\n        \n        return n4\n\n    # Run all tests with specified seeds\n    n1, D1 = test_1(seed=314159)\n    n2, x_bar_2, delta_2 = test_2(seed=271828)\n    n3_L, n3_R = test_3(seed=161803)\n    n4 = test_4(seed=141421)\n\n    # Assemble results and format them as specified\n    output_list = [\n        str(n1),\n        f'{D1:.6f}',\n        str(n2),\n        f'{x_bar_2:.6f}',\n        f'{delta_2:.6f}',\n        str(n3_L),\n        str(n3_R),\n        str(n4)\n    ]\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(output_list)}]\")\n\nsolve()\n```"
        }
    ]
}