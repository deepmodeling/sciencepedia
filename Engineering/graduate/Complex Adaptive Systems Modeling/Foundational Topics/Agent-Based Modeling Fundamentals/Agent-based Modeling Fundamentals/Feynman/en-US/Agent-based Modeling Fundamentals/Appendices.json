{
    "hands_on_practices": [
        {
            "introduction": "This first practice delves into the fundamental mechanics of an agent-based model. You will perform a manual simulation of a single time step in a system where agents, arranged on a ring network, update their state based on their neighbors' activity. This exercise hones the core skill of applying a local, deterministic rule to predict the system's evolution, providing a concrete understanding of how simple interactions drive collective behavior. ",
            "id": "4113515",
            "problem": "Consider an Agent-Based Modeling (ABM) system on a ring network with $n$ agents, where $n$ is fixed at $n=10$. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. The network is a one-dimensional ring: indices are taken modulo $n$, so that for any index $i \\in \\{1,\\dots,n\\}$, the predecessor of $1$ is $n$ and the successor of $n$ is $1$. For each agent $i$, the neighborhood $N(i)$ consists of the two nearest neighbors on each side, specifically $N(i)=\\{i-2,i-1,i+1,i+2\\}$ with indices interpreted modulo $n$. The synchronous update rule is defined by the indicator function\n$$\nx_i(t+1) \\;=\\; \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\;\\geq\\; \\theta \\right\\},\n$$\nwhere $\\theta$ is a fixed threshold applied uniformly to all agents.\n\nYou are given the initial configuration at time $t=0$ as\n$$\nx(0) \\;=\\; \\bigl(x_1(0),x_2(0),x_3(0),x_4(0),x_5(0),x_6(0),x_7(0),x_8(0),x_9(0),x_{10}(0)\\bigr)\n\\;=\\; (1,0,1,1,0,0,1,0,1,0),\n$$\nand the threshold $\\theta=3$.\n\nUsing only the definitions above and the stated synchronous update rule, compute the next state vector $x(1)$. Express your final answer as a single row matrix containing the components in order $\\bigl(x_1(1),x_2(1),\\dots,x_{10}(1)\\bigr)$. No rounding is required, and no units apply.",
            "solution": "The problem statement is validated as being scientifically grounded, well-posed, objective, complete, and consistent. It describes a standard discrete-time dynamical system, specifically a type of one-dimensional cellular automaton on a ring, for which all necessary parameters and initial conditions are provided to compute the subsequent state. The problem is a formalizable exercise in applying a defined rule set and is directly pertinent to the field of agent-based modeling. Therefore, a solution can be derived.\n\nThe problem asks for the state vector $x(1)$ at time $t=1$, given the initial state vector $x(0)$ at time $t=0$. The system consists of $n=10$ agents on a ring. The state of each agent $i$ is binary, $x_i(t) \\in \\{0,1\\}$. The update rule for each agent $i$ is synchronous and determined by its neighbors' states at the previous time step. The neighborhood of agent $i$ is $N(i)=\\{i-2, i-1, i+1, i+2\\}$, with indices taken modulo $n$. The update rule is given by the indicator function:\n$$x_i(t+1) = \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\geq \\theta \\right\\}$$\nwhere $\\mathbb{I}\\{\\cdot\\}$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise. The threshold is given as $\\theta=3$. The initial state vector at $t=0$ is:\n$$x(0) = (x_1(0), \\dots, x_{10}(0)) = (1,0,1,1,0,0,1,0,1,0)$$\nWe must compute $x_i(1)$ for each agent $i \\in \\{1, 2, \\dots, 10\\}$. This involves calculating the sum of the states of the four neighbors for each agent and comparing it to the threshold $\\theta=3$. The indices are interpreted modulo $10$, where the set of indices is $\\{1, 2, \\dots, 10\\}$. For example, for agent $i=1$, the neighbor $i-1=0$ corresponds to agent $10$, and $i-2=-1$ corresponds to agent $9$.\n\nFor agent $i=1$:\nThe neighborhood is $N(1) = \\{9, 10, 2, 3\\}$.\nThe sum of neighbors' states is $S_1 = x_9(0) + x_{10}(0) + x_2(0) + x_3(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_1=2  \\theta=3$, the new state is $x_1(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=2$:\nThe neighborhood is $N(2) = \\{10, 1, 3, 4\\}$.\nThe sum of neighbors' states is $S_2 = x_{10}(0) + x_1(0) + x_3(0) + x_4(0) = 0 + 1 + 1 + 1 = 3$.\nSince $S_2=3 \\geq \\theta=3$, the new state is $x_2(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=3$:\nThe neighborhood is $N(3) = \\{1, 2, 4, 5\\}$.\nThe sum of neighbors' states is $S_3 = x_1(0) + x_2(0) + x_4(0) + x_5(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_3=2  \\theta=3$, the new state is $x_3(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=4$:\nThe neighborhood is $N(4) = \\{2, 3, 5, 6\\}$.\nThe sum of neighbors' states is $S_4 = x_2(0) + x_3(0) + x_5(0) + x_6(0) = 0 + 1 + 0 + 0 = 1$.\nSince $S_4=1  \\theta=3$, the new state is $x_4(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=5$:\nThe neighborhood is $N(5) = \\{3, 4, 6, 7\\}$.\nThe sum of neighbors' states is $S_5 = x_3(0) + x_4(0) + x_6(0) + x_7(0) = 1 + 1 + 0 + 1 = 3$.\nSince $S_5=3 \\geq \\theta=3$, the new state is $x_5(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=6$:\nThe neighborhood is $N(6) = \\{4, 5, 7, 8\\}$.\nThe sum of neighbors' states is $S_6 = x_4(0) + x_5(0) + x_7(0) + x_8(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_6=2  \\theta=3$, the new state is $x_6(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=7$:\nThe neighborhood is $N(7) = \\{5, 6, 8, 9\\}$.\nThe sum of neighbors' states is $S_7 = x_5(0) + x_6(0) + x_8(0) + x_9(0) = 0 + 0 + 0 + 1 = 1$.\nSince $S_7=1  \\theta=3$, the new state is $x_7(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=8$:\nThe neighborhood is $N(8) = \\{6, 7, 9, 10\\}$.\nThe sum of neighbors' states is $S_8 = x_6(0) + x_7(0) + x_9(0) + x_{10}(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_8=2  \\theta=3$, the new state is $x_8(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=9$:\nThe neighborhood is $N(9) = \\{7, 8, 10, 1\\}$.\nThe sum of neighbors' states is $S_9 = x_7(0) + x_8(0) + x_{10}(0) + x_1(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_9=2  \\theta=3$, the new state is $x_9(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=10$:\nThe neighborhood is $N(10) = \\{8, 9, 1, 2\\}$.\nThe sum of neighbors' states is $S_{10} = x_8(0) + x_9(0) + x_1(0) + x_2(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_{10}=2  \\theta=3$, the new state is $x_{10}(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nCombining these results, the state vector at time $t=1$ is:\n$$x(1) = \\bigl(x_1(1), x_2(1), x_3(1), x_4(1), x_5(1), x_6(1), x_7(1), x_8(1), x_9(1), x_{10}(1)\\bigr) = (0, 1, 0, 0, 1, 0, 0, 0, 0, 0)$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  1  0  0  1  0  0  0  0  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Building on the concept of state updates, this practice illuminates a critical and subtle aspect of agent-based modeling: the update regime. By calculating and comparing the trajectories of a simple two-agent system under both synchronous and sequential update rules, you will directly observe how this modeling choice can lead to fundamentally different system-level dynamics. This exercise underscores the importance of carefully considering and justifying the temporal assumptions that underpin your model. ",
            "id": "4113495",
            "problem": "Consider an Agent-Based Model (ABM) in the domain of complex adaptive systems modeling with two agents labeled $i \\in \\{1,2\\}$ on an undirected network consisting of a single edge connecting the two agents. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. The ABM employs a deterministic threshold decision rule: an agent becomes active at the next time step if and only if the fraction of its neighbors that are active meets or exceeds its threshold. Formally, for any agent $i$, let $N_i$ denote the set of neighbors of $i$, and let $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$ be the fraction of neighbors active at an update reference time $\\tau$. The threshold parameter for agent $i$ is $\\theta_i \\in [0,1]$, and the individual update rule is\n$$\nx_i(\\text{next}) = \n\\begin{cases}\n1,  \\text{if } m_i(\\tau) \\ge \\theta_i, \\\\\n0,  \\text{if } m_i(\\tau)  \\theta_i.\n\\end{cases}\n$$\nTwo update regimes are considered:\n\n- Synchronous update: Both agents compute $m_i(t)$ using the states at time $t$ and simultaneously set $x_i(t+1)$ according to the threshold rule.\n- Sequential update with fixed order $(1,2)$: Agent $1$ updates first using $m_1(t)$ to set $x_1(t+1)$, and then agent $2$ updates using $m_2(t+1)$, where $m_2(t+1)$ is computed from the latest available neighbor state after agent $1$ has updated.\n\nSuppose the initial condition is $x_1(0) = 0$ and $x_2(0) = 1$, and the thresholds are $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. Because the network has a single edge, each agent’s $m_i(\\tau)$ equals the neighbor’s state at the specified reference time. Define the trajectory difference over a finite horizon $T$ as the cumulative Hamming distance between the two regime trajectories,\n$$\nD(T) = \\sum_{t=0}^{T} \\left( \\left| x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t) \\right| + \\left| x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t) \\right| \\right),\n$$\nwhere $x_i^{\\text{sync}}(t)$ and $x_i^{\\text{seq}}(t)$ denote the state of agent $i$ at time $t$ under synchronous and sequential updating, respectively.\n\nCompute $D(T)$ for the horizon $T = 10$. Provide your final answer as a single real number. No rounding instruction is necessary for this problem.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of Agent-Based Models (ABMs) and Complex Adaptive Systems, and contains all necessary information for a unique solution. The validation criteria are met.\n\nThe task is to compute the cumulative Hamming distance, $D(T)$, between the state trajectories of a two-agent system under synchronous and sequential update regimes for a time horizon of $T=10$. We begin by analyzing the agent update rules, then simulate the trajectories for both regimes, and finally compute the required sum.\n\nFirst, we formalize the update rules for agent $i \\in \\{1, 2\\}$ with thresholds $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. The network consists of a single edge connecting the two agents, so the set of neighbors for agent $1$ is $N_1 = \\{2\\}$ and for agent $2$ is $N_2 = \\{1\\}$. The fraction of active neighbors for agent $i$ is $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$. This simplifies to $m_1(\\tau) = x_2(\\tau)$ and $m_2(\\tau) = x_1(\\tau)$.\n\nThe individual update rule is $x_i(\\text{next}) = 1$ if $m_i(\\tau) \\ge \\theta_i$ and $x_i(\\text{next}) = 0$ otherwise. Given the binary state space $x_i \\in \\{0, 1\\}$, the rules for each agent become:\n- For agent $1$: $x_1(\\text{next}) = 1$ if and only if $x_2(\\tau) \\ge \\theta_1 = \\frac{1}{2}$. This means $x_1(\\text{next}) = 1$ only if $x_2(\\tau)=1$. Thus, the rule is $x_1(\\text{next}) = x_2(\\tau)$.\n- For agent $2$: $x_2(\\text{next}) = 1$ if and only if $x_1(\\tau) \\ge \\theta_2 = 1$. This means $x_2(\\text{next}) = 1$ only if $x_1(\\tau)=1$. Thus, the rule is $x_2(\\text{next}) = x_1(\\tau)$.\n\nNow we generate the trajectories for both update regimes starting from the initial condition $(x_1(0), x_2(0)) = (0, 1)$.\n\n**1. Synchronous Update Trajectory**\nUnder synchronous updating, both agents' next states are computed based on the current state of the system at time $t$. The rules are:\n$$\n\\begin{cases}\nx_1^{\\text{sync}}(t+1) = x_2^{\\text{sync}}(t) \\\\\nx_2^{\\text{sync}}(t+1) = x_1^{\\text{sync}}(t)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{sync}}(t), x_2^{\\text{sync}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$: $(x_1(1), x_2(1)) = (x_2(0), x_1(0)) = (1, 0)$\n- $t=2$: $(x_1(2), x_2(2)) = (x_2(1), x_1(1)) = (0, 1)$\n- $t=3$: $(x_1(3), x_2(3)) = (x_2(2), x_1(2)) = (1, 0)$\nThe system oscillates with a period of $2$. The state is $(0, 1)$ for even values of $t$ and $(1, 0)$ for odd values of $t$.\n\n**2. Sequential Update Trajectory (Order 1, 2)**\nUnder sequential updating with order $(1, 2)$, agent $1$ first updates its state for time $t+1$ based on states at time $t$. Then, agent $2$ updates its state for time $t+1$ using the most recent states, which includes the newly updated state of agent $1$.\nThe rules for one time step from $t$ to $t+1$ are:\n$$\n\\begin{cases}\nx_1^{\\text{seq}}(t+1) = x_2^{\\text{seq}}(t) \\\\\nx_2^{\\text{seq}}(t+1) = x_1^{\\text{seq}}(t+1)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(1) = x_2^{\\text{seq}}(0) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(1) = x_1^{\\text{seq}}(1) = 1$.\n  - The state at $t=1$ is $(1, 1)$.\n- $t=2$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(2) = x_2^{\\text{seq}}(1) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(2) = x_1^{\\text{seq}}(2) = 1$.\n  - The state at $t=2$ is $(1, 1)$.\nThe system reaches a fixed point $(1, 1)$ at $t=1$. Therefore, for all $t \\ge 1$, the state is $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t)) = (1, 1)$.\n\n**3. Compute the Trajectory Difference $D(10)$**\nThe trajectory difference is defined as $D(T) = \\sum_{t=0}^{T} d(t)$, where the per-step Hamming distance is $d(t) = |x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t)| + |x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t)|$. We calculate $d(t)$ for each $t$ from $0$ to $10$.\n\n- For $t=0$:\n  - $x^{\\text{sync}}(0) = (0, 1)$ and $x^{\\text{seq}}(0) = (0, 1)$.\n  - $d(0) = |0-0| + |1-1| = 0$.\n\n- For $t \\ge 1$:\n  - The sequential trajectory is fixed: $x^{\\text{seq}}(t) = (1, 1)$.\n  - The synchronous trajectory alternates.\n  - For odd $t \\in \\{1, 3, 5, 7, 9\\}$:\n    - $x^{\\text{sync}}(t) = (1, 0)$.\n    - $d(t) = |1-1| + |0-1| = 0 + 1 = 1$.\n  - For even $t \\in \\{2, 4, 6, 8, 10\\}$:\n    - $x^{\\text{sync}}(t) = (0, 1)$.\n    - $d(t) = |0-1| + |1-1| = 1 + 0 = 1$.\n\nSo, we have $d(0)=0$ and $d(t)=1$ for all $t \\in \\{1, 2, \\dots, 10\\}$.\n\nFinally, we sum these values to find $D(10)$:\n$$\nD(10) = \\sum_{t=0}^{10} d(t) = d(0) + \\sum_{t=1}^{10} d(t)\n$$\n$$\nD(10) = 0 + (d(1) + d(2) + \\dots + d(10))\n$$\n$$\nD(10) = 0 + \\sum_{t=1}^{10} 1 = 10 \\times 1 = 10\n$$\nThe cumulative Hamming distance over the horizon $T=10$ is $10$.",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "This final practice transitions from theoretical calculation to the practical craft of building robust and verifiable computational models. You are tasked with implementing a stochastic agent transition function and, crucially, developing a suite of unit tests to confirm its correctness under various conditions, including the conservation of agents. This exercise emphasizes that sound scientific modeling requires not only valid theory but also rigorous software engineering practices to ensure your simulation is a reliable tool for inquiry. ",
            "id": "4113503",
            "problem": "You are modeling a discrete-time, finite-state Agent-Based Modeling (ABM) system with a closed population. Each agent occupies one of $M$ states, and at each time step transitions according to a row-stochastic transition matrix. Let $M \\in \\mathbb{N}$ denote the number of states, let $\\mathbf{x} \\in \\mathbb{N}_0^M$ be the vector of agent counts per state at time $t$, and let $\\mathbf{P} \\in \\mathbb{R}^{M \\times M}$ be the row-stochastic transition matrix such that each row sums to $1$, and each entry is nonnegative. The state transition function maps $\\left(\\mathbf{x}, \\mathbf{P}\\right)$ to a new count vector $\\mathbf{y} \\in \\mathbb{N}_0^M$ by sampling, for each state $i$, a multinomial allocation of the $x_i$ agents across destination states with probabilities given by the $i$-th row of $\\mathbf{P}$. The population is closed, so there are no births or deaths, and the conservation of agents must hold.\n\nFundamental base and definitions:\n- An Agent-Based Modeling (ABM) system consists of individual agents whose states evolve over discrete time steps $t \\in \\mathbb{N}_0$ via defined interaction rules. In a finite-state model, each agent occupies one of $M$ categorical states.\n- A row-stochastic matrix $\\mathbf{P}$ satisfies $\\sum_{j=1}^M P_{ij} = 1$ for each row $i \\in \\{1,\\dots,M\\}$ and $P_{ij} \\ge 0$ for all entries.\n- For each state $i$, given $x_i$ agents and a probability vector $\\left(P_{i1},\\dots,P_{iM}\\right)$, the number of agents transitioning to each destination state is distributed according to the multinomial distribution with parameters $x_i$ and $\\left(P_{i1},\\dots,P_{iM}\\right)$, which conserves the total number of agents within state $i$.\n\nTask:\n1. Implement a state transition function that, given $\\mathbf{x}$ and $\\mathbf{P}$, computes a stochastic next-state count vector $\\mathbf{y}$ and also returns the full flow matrix $\\mathbf{F} \\in \\mathbb{N}_0^{M \\times M}$, where $F_{ij}$ is the number of agents that moved from state $i$ to state $j$ in one time step. The function must validate inputs: nonnegative integer counts, nonnegative entries in $\\mathbf{P}$, and each row of $\\mathbf{P}$ summing to $1$ within a small tolerance. If validation fails, the function must raise an exception rather than silently correcting.\n2. Construct unit tests that verify invariant properties of the transition function under a closed population:\n   - Conservation of agents: $\\sum_{j=1}^M y_j = \\sum_{i=1}^M x_i$.\n   - Nonnegativity and integrality: $y_j \\in \\mathbb{N}_0$ for all $j$, and $F_{ij} \\in \\mathbb{N}_0$ for all $i,j$.\n   - Rowwise consistency: for each state $i$, $\\sum_{j=1}^M F_{ij} = x_i$.\n   - Idempotence under identity transition: if $\\mathbf{P} = \\mathbf{I}_M$ then $\\mathbf{y} = \\mathbf{x}$ and $\\mathbf{F}$ equals a diagonal matrix with diagonal entries $\\mathbf{x}$.\n   - Absorbing state behavior: if a state $k$ is absorbing, so that the $k$-th row of $\\mathbf{P}$ equals the $k$-th standard basis vector, then all agents in state $k$ remain in state $k$ and the corresponding row of $\\mathbf{F}$ has $F_{kk} = x_k$ and $F_{kj} = 0$ for $j \\ne k$.\n   - Input validation: non-stochastic rows (row sum not equal to $1$ within tolerance) and negative entries in $\\mathbf{P}$ must cause the function to raise an error.\n   - Reproducibility: with a fixed random seed parameter, repeated calls produce identical $\\mathbf{y}$ and $\\mathbf{F}$ for the same inputs.\n   - Numerical stability for large populations: conservation and nonnegativity must hold for large $x_i$.\n\nProgram requirements:\n- The program must be self-contained, deterministic where specified by a fixed seed, and implement the above function and unit tests.\n- No physical units are involved; all counts are unitless nonnegative integers, and probabilities are dimensionless decimals.\n- Provide a test suite comprising the following $8$ parameterized cases, which collectively exercise the invariants, boundary conditions, and error handling:\n  - Test $1$ (happy path, conservation and consistency): $M=3$, $\\mathbf{x} = [10, 5, 0]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.7  0.2  0.1 \\\\ 0.0  0.6  0.4 \\\\ 0.1  0.0  0.9 \\end{bmatrix},$$\n    fixed seed $42$.\n  - Test $2$ (zero population boundary): $M=3$, $\\mathbf{x} = [0, 0, 0]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.5  0.3  0.2 \\\\ 0.2  0.5  0.3 \\\\ 0.1  0.2  0.7 \\end{bmatrix},$$\n    no seed.\n  - Test $3$ (idempotence under identity): $M=3$, $\\mathbf{x} = [7, 3, 9]$, $\\mathbf{P} = \\mathbf{I}_3$, any seed or none.\n  - Test $4$ (absorbing state behavior): $M=3$, $\\mathbf{x} = [3, 4, 5]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.2  0.3  0.5 \\\\ 0.1  0.6  0.3 \\\\ 0.0  0.0  1.0 \\end{bmatrix},$$\n    fixed seed $17$; state $3$ is absorbing.\n  - Test $5$ (invalid row sum): $M=3$, $\\mathbf{x} = [8, 1, 1]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.5  0.4  0.0 \\\\ 0.2  0.5  0.3 \\\\ 0.1  0.2  0.7 \\end{bmatrix},$$\n    where the first row sums to $0.9$; expect an error.\n  - Test $6$ (negative probability entry): $M=3$, $\\mathbf{x} = [5, 5, 0]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.7  -0.1  0.4 \\\\ 0.2  0.5  0.3 \\\\ 0.1  0.2  0.7 \\end{bmatrix},$$\n    expect an error.\n  - Test $7$ (large population stability): $M=3$, $\\mathbf{x} = [100000, 0, 0]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.2  0.3  0.5 \\\\ 0.0  1.0  0.0 \\\\ 0.0  0.0  1.0 \\end{bmatrix},$$\n    fixed seed $12345$.\n  - Test $8$ (reproducibility with fixed seed): $M=3$, $\\mathbf{x} = [50, 50, 0]$, \n    $$\\mathbf{P} = \\begin{bmatrix} 0.6  0.3  0.1 \\\\ 0.1  0.7  0.2 \\\\ 0.2  0.2  0.6 \\end{bmatrix},$$\n    fixed seed $999$; calling the transition twice with the same seed must produce identical results.\n\nAnswer specification:\n- For each of the $8$ tests, compute a boolean indicating whether the expected invariant or behavior holds (for error tests, the boolean is $\\text{True}$ if and only if the function raises the expected exception).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots,\\text{result}_8]$). The booleans must be written as $\\text{True}$ or $\\text{False}$ in Python boolean syntax.",
            "solution": "The problem requires the implementation and validation of a stochastic state transition function for a closed-population Agent-Based Model (ABM). The system is defined by a set of $M$ discrete states, a population vector $\\mathbf{x} \\in \\mathbb{N}_0^M$ counting agents in each state, and a row-stochastic transition matrix $\\mathbf{P} \\in \\mathbb{R}^{M \\times M}$. At each time step, for each state $i$, the $x_i$ agents residing in it are redistributed among the $M$ possible destination states $j$ according to a multinomial distribution. The parameters for this distribution are the number of trials, $x_i$, and the event probabilities, given by the $i$-th row of $\\mathbf{P}$, $(P_{i1}, P_{i2}, \\dots, P_{iM})$.\n\nThe core of the task is to develop a function that simulates one time step of this process. This function must take the current state vector $\\mathbf{x}$ and the transition matrix $\\mathbf{P}$ as input and produce two outputs: the next state vector $\\mathbf{y}$ and a flow matrix $\\mathbf{F}$. The element $F_{ij}$ of the flow matrix represents the number of agents that transitioned from state $i$ to state $j$.\n\nFirst, we design the state transition function, which we will name `state_transition`. This function must incorporate rigorous input validation as a prerequisite to any computation.\n\n1.  **Input Validation**: The function must first verify the integrity of its inputs.\n    -   The state vector $\\mathbf{x}$ must be a one-dimensional array of non-negative integers. Any violation, such as negative counts or non-integer values, must result in an error.\n    -   The transition matrix $\\mathbf{P}$ must be a two-dimensional square matrix with dimensions compatible with $\\mathbf{x}$.\n    -   All entries $P_{ij}$ of the matrix $\\mathbf{P}$ must be non-negative, as they represent probabilities.\n    -   Each row of $\\mathbf{P}$ must sum to $1$, satisfying the definition of a row-stochastic matrix. Since floating-point arithmetic is involved, this check must be performed within a small tolerance, for instance, $10^{-9}$.\n    -   If any of these conditions are not met, the function will raise a `ValueError` to prevent execution with invalid parameters.\n\n2.  **Stochastic Transition Logic**: If the inputs are valid, the function proceeds with the simulation.\n    -   A flow matrix $\\mathbf{F}$ of size $M \\times M$ is initialized with zeros. Its data type must be integer to store agent counts.\n    -   The function iterates through each state $i$ from $1$ to $M$. For each state $i$, it considers the $x_i$ agents currently in that state.\n    -   The key step is sampling from the multinomial distribution. For each row $i$, the number of agents transitioning to each state $j$ is determined by drawing a single sample from the multinomial distribution with $n = x_i$ trials and probability vector $\\mathbf{p} = (P_{i1}, P_{i2}, \\dots, P_{iM})$. This sample is a vector of $M$ integers $(F_{i1}, F_{i2}, \\dots, F_{iM})$ where $\\sum_{j=1}^M F_{ij} = x_i$. This vector becomes the $i$-th row of the flow matrix $\\mathbf{F}$. If $x_i=0$, the resulting row in $\\mathbf{F}$ will correctly be all zeros.\n    -   To ensure reproducibility for testing, the function must accept an optional random seed. This seed is used to initialize a random number generator, which is then used for all multinomial sampling within a single call.\n\n3.  **Output Calculation**:\n    -   The flow matrix $\\mathbf{F}$ is now fully populated. Each entry $F_{ij}$ is a non-negative integer.\n    -   The new state vector $\\mathbf{y}$ is calculated from $\\mathbf{F}$. The number of agents $y_j$ in state $j$ after the transition is the sum of all agents that moved *into* state $j$ from any source state $i$. This corresponds to the sum of the $j$-th column of the flow matrix: $y_j = \\sum_{i=1}^M F_{ij}$.\n\nThis design ensures that fundamental invariants of a closed system are maintained.\n-   **Conservation of Agents**: The total number of agents must be constant. This is guaranteed because $\\sum_{j=1}^M y_j = \\sum_{j=1}^M \\sum_{i=1}^M F_{ij} = \\sum_{i=1}^M \\sum_{j=1}^M F_{ij} = \\sum_{i=1}^M x_i$. The multinomial sampling for each row ensures $\\sum_j F_{ij} = x_i$.\n-   **Integrality and Nonnegativity**: Both $\\mathbf{F}$ and $\\mathbf{y}$ will consist of non-negative integers as they are either direct outputs of the multinomial distribution (which produces integer counts) or sums of such outputs.\n\nThe second part of the task is to construct a unit test suite to verify the correctness of the implementation against a set of specified behaviors and invariants. Each test case will be executed, and its success or failure will be recorded as a boolean value.\n\n-   **Test 1 (Conservation and Consistency)**: For $\\mathbf{x} = [10, 5, 0]$ and $\\mathbf{P} = \\begin{bmatrix} 0.7  0.2  0.1 \\\\ 0.0  0.6  0.4 \\\\ 0.1  0.0  0.9 \\end{bmatrix}$, we verify that $\\sum y_j = \\sum x_i$, that all entries of $\\mathbf{y}$ and $\\mathbf{F}$ are non-negative integers, and that the sum of each row of $\\mathbf{F}$ equals the corresponding entry in $\\mathbf{x}$.\n-   **Test 2 (Zero Population)**: For $\\mathbf{x} = [0, 0, 0]$, the function must produce $\\mathbf{y} = [0, 0, 0]$ and an all-zero flow matrix $\\mathbf{F}$, regardless of $\\mathbf{P}$.\n-   **Test 3 (Idempotence under Identity)**: If $\\mathbf{P}$ is the identity matrix $\\mathbf{I}_3$, no agent should change state. Thus, for $\\mathbf{x} = [7, 3, 9]$, the output must be $\\mathbf{y} = \\mathbf{x}$ and $\\mathbf{F}$ must be a diagonal matrix with the entries of $\\mathbf{x}$ on its diagonal.\n-   **Test 4 (Absorbing State)**: Given a matrix $\\mathbf{P}$ where state $3$ (index $2$) is absorbing (i.e., row $2$ is $[0, 0, 1]$) and an initial state $\\mathbf{x} = [3, 4, 5]$, we must verify that all $5$ agents in state $3$ remain in state $3$. This means the $3$rd row of the flow matrix $\\mathbf{F}$ must be $[0, 0, 5]$.\n-   **Test 5 (Invalid Row Sum)**: We provide a matrix $\\mathbf{P}$ where a row does not sum to $1$. The test succeeds if and only if the function raises a `ValueError`.\n-   **Test 6 (Negative Probability)**: We provide a matrix $\\mathbf{P}$ containing a negative entry. The test succeeds if and only if the function raises a `ValueError`.\n-   **Test 7 (Large Population Stability)**: With a large initial population, e.g., $\\mathbf{x} = [100000, 0, 0]$, we verify that the fundamental invariants of agent conservation and nonnegativity still hold, demonstrating numerical stability.\n-   **Test 8 (Reproducibility)**: We call the function twice with the same inputs ($\\mathbf{x}$, $\\mathbf{P}$) and the same fixed random seed. The test passes if and only if the outputs ($\\mathbf{y}_1, \\mathbf{F}_1$) from the first call are identical to the outputs ($\\mathbf{y}_2, \\mathbf{F}_2$) from the second call.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef state_transition(x: np.ndarray, P: np.ndarray, seed: int = None):\n    \"\"\"\n    Computes a stochastic state transition for an agent-based model.\n\n    Args:\n        x (np.ndarray): 1D array of non-negative integers representing agent counts per state.\n        P (np.ndarray): 2D row-stochastic transition matrix.\n        seed (int, optional): Seed for the random number generator for reproducibility.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing:\n            - y (np.ndarray): The new state vector.\n            - F (np.ndarray): The flow matrix, where F[i, j] is the number of agents\n                              that moved from state i to state j.\n\n    Raises:\n        ValueError: If inputs are invalid (shape, type, non-negativity, or stochasticity).\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(x, np.ndarray) or x.ndim != 1:\n        raise ValueError(\"x must be a 1D numpy array.\")\n    if not np.issubdtype(x.dtype, np.integer):\n        raise ValueError(\"Elements of x must be integers.\")\n    if np.any(x  0):\n        raise ValueError(\"Elements of x must be non-negative.\")\n\n    if not isinstance(P, np.ndarray) or P.ndim != 2:\n        raise ValueError(\"P must be a 2D numpy array.\")\n    if P.shape[0] != P.shape[1]:\n        raise ValueError(\"P must be a square matrix.\")\n    if x.shape[0] != P.shape[0]:\n        raise ValueError(\"Dimension of x must match dimensions of P.\")\n    if np.any(P  0):\n        raise ValueError(\"Elements of P must be non-negative.\")\n    \n    # Check for row-stochastic property with tolerance\n    row_sums = P.sum(axis=1)\n    if not np.all(np.isclose(row_sums, 1.0, rtol=1e-9, atol=1e-9)):\n        raise ValueError(\"Rows of P must sum to 1.\")\n\n    # --- Transition Logic ---\n    M = x.shape[0]\n    rng = np.random.default_rng(seed)\n    F = np.zeros((M, M), dtype=np.int64)\n\n    for i in range(M):\n        n_i = x[i]\n        if n_i  0:\n            # The probability vector might not sum to exactly 1 due to float precision.\n            # np.multinomial normalizes it internally if needed.\n            # But the validation above should be strict.\n            p_i = P[i, :]\n            # Explicit normalization to handle tiny floating point inaccuracies close to 1.\n            p_i_normalized = p_i / p_i.sum()\n            F[i, :] = rng.multinomial(n_i, p_i_normalized)\n\n    y = F.sum(axis=0)\n\n    return y, F\n\ndef solve():\n    \"\"\"\n    Runs the test suite and prints the formatted results.\n    \"\"\"\n    results = []\n\n    # Test 1: Happy path, conservation and consistency\n    try:\n        x = np.array([10, 5, 0])\n        P = np.array([[0.7, 0.2, 0.1], [0.0, 0.6, 0.4], [0.1, 0.0, 0.9]])\n        y, F = state_transition(x, P, seed=42)\n        conservation_ok = (np.sum(y) == np.sum(x))\n        nonnegativity_ok = (np.all(y = 0) and np.all(F = 0))\n        integrality_ok = (np.issubdtype(y.dtype, np.integer) and np.issubdtype(F.dtype, np.integer))\n        consistency_ok = np.array_equal(F.sum(axis=1), x)\n        results.append(conservation_ok and nonnegativity_ok and integrality_ok and consistency_ok)\n    except Exception:\n        results.append(False)\n\n    # Test 2: Zero population boundary\n    try:\n        x = np.array([0, 0, 0])\n        P = np.array([[0.5, 0.3, 0.2], [0.2, 0.5, 0.3], [0.1, 0.2, 0.7]])\n        y, F = state_transition(x, P)\n        results.append(np.array_equal(y, [0, 0, 0]) and np.array_equal(F, np.zeros((3, 3))))\n    except Exception:\n        results.append(False)\n\n    # Test 3: Idempotence under identity\n    try:\n        x = np.array([7, 3, 9])\n        P = np.identity(3)\n        y, F = state_transition(x, P)\n        results.append(np.array_equal(y, x) and np.array_equal(F, np.diag(x)))\n    except Exception:\n        results.append(False)\n\n\n    # Test 4: Absorbing state behavior\n    try:\n        x = np.array([3, 4, 5])\n        P = np.array([[0.2, 0.3, 0.5], [0.1, 0.6, 0.3], [0.0, 0.0, 1.0]])\n        y, F = state_transition(x, P, seed=17)\n        absorbing_row_correct = np.array_equal(F[2, :], [0, 0, 5])\n        results.append(absorbing_row_correct)\n    except Exception:\n        results.append(False)\n\n    # Test 5: Invalid row sum\n    try:\n        x = np.array([8, 1, 1])\n        P = np.array([[0.5, 0.4, 0.0], [0.2, 0.5, 0.3], [0.1, 0.2, 0.7]]) # Row 0 sums to 0.9\n        state_transition(x, P)\n        results.append(False) # Should have raised an error\n    except ValueError:\n        results.append(True) # Expected error caught\n    except Exception:\n        results.append(False) # Wrong error type\n\n    # Test 6: Negative probability entry\n    try:\n        x = np.array([5, 5, 0])\n        P = np.array([[0.7, -0.1, 0.4], [0.2, 0.5, 0.3], [0.1, 0.2, 0.7]])\n        state_transition(x, P)\n        results.append(False)\n    except ValueError:\n        results.append(True)\n    except Exception:\n        results.append(False)\n\n    # Test 7: Large population stability\n    try:\n        x = np.array([100000, 0, 0])\n        P = np.array([[0.2, 0.3, 0.5], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n        y, F = state_transition(x, P, seed=12345)\n        conservation_ok = (np.sum(y) == np.sum(x))\n        nonnegativity_ok = (np.all(y = 0) and np.all(F = 0))\n        results.append(conservation_ok and nonnegativity_ok)\n    except Exception:\n        results.append(False)\n\n    # Test 8: Reproducibility with fixed seed\n    try:\n        x = np.array([50, 50, 0])\n        P = np.array([[0.6, 0.3, 0.1], [0.1, 0.7, 0.2], [0.2, 0.2, 0.6]])\n        y1, F1 = state_transition(x, P, seed=999)\n        y2, F2 = state_transition(x, P, seed=999)\n        results.append(np.array_equal(y1, y2) and np.array_equal(F1, F2))\n    except Exception:\n        results.append(False)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}