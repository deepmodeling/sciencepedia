{
    "hands_on_practices": [
        {
            "introduction": "复杂系统的核心挑战之一是连接微观个体行为与宏观集体现象。平均场近似是一种强大的理论工具，它通过用一个平均效应来代替个体间的复杂相互作用，从而简化了这个问题。这项实践练习  将指导你完成一个典型的推导过程，从个体动力学方程出发，构建宏观序参量，并最终得到其近似的动力学方程，从而掌握从微观规则中推导涌现行为的分析技能。",
            "id": "4121309",
            "problem": "考虑一个由 $N$ 个相同代理组成的全连接群体，其标量微观状态 $x_i(t) \\in \\mathbb{R}$ 在耦合常微分方程（ODE）系统下演化\n$$\n\\dot{x}_i(t) \\;=\\; f\\!\\big(x_i(t)\\big) \\;+\\; \\sum_{j=1}^{N} g\\!\\big(x_i(t),\\,x_j(t)\\big),\n$$\n其中 $f:\\mathbb{R}\\to\\mathbb{R}$ 和 $g:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R}$ 分别是表示自动态和成对相互作用的光滑函数。定义宏观序参量为\n$$\nm(t) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} x_i(t).\n$$\n假设均匀混合和弱的、密集的耦合，通过归一化\n$$\ng\\!\\big(x_i,x_j\\big) \\;=\\; \\frac{\\kappa}{N}\\,h\\!\\big(x_i,x_j\\big),\n$$\n使得当 $N\\to\\infty$ 时，耦合保持为 $\\mathcal{O}(1)$，其中 $\\kappa\\in\\mathbb{R}$ 为常数， $h:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R}$ 是一个对称的 Lipschitz 函数，满足 $h(x,y)=h(y,x)$。使用平均场闭合方法，推导序参量 $m(t)$ 的近似自治动力学。该方法基于大 $N$ 极限下经验分布的可交换性和围绕 $m(t)$ 的集中性。通过在一阶平均场闭合（忽略方差和协方差校正）下将其漂移表示为 $m(t)$ 的闭合函数来完成推导。从基本定义和经过充分检验的事实（例如，大数定律）出发，清晰地陈述闭合成立所需的模型假设。你的最终答案必须是在所述假设下获得的、$m(t)$ 的宏观漂移关于 $m$ 的单一闭合形式解析表达式。最终表达式中不应包含等号。不需要进行数值评估。",
            "solution": "该问题陈述是复杂系统建模领域中一个有效且适定的问题，具体涉及使用平均场近似从微观规则推导宏观动力学。其前提在统计物理和动力系统理论的标准框架中有科学依据。术语精确，所提供的信息自洽且足以进行推导.\n\n目标是为宏观序参量 $m(t)$ 推导出一个近似的自治动力学方程，该序参量定义为微观状态 $x_i(t)$ 的群体平均值。出发点是针对由 $N$ 个相同代理组成的群体的耦合常微分方程（ODE）系统：\n$$\n\\dot{x}_i(t) \\;=\\; f\\!\\big(x_i(t)\\big) \\;+\\; \\sum_{j=1}^{N} g\\!\\big(x_i(t),\\,x_j(t)\\big)\n$$\n其中 $i=1, \\dots, N$。相互作用函数 $g$ 被指定为 $g(x_i, x_j) = \\frac{\\kappa}{N} h(x_i, x_j)$。\n\n首先，我们通过对序参量 $m(t)$ 的定义对时间 $t$ 求导来确定其时间演化：\n$$\nm(t) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} x_i(t)\n$$\n$$\n\\dot{m}(t) \\;=\\; \\frac{d}{dt} \\left( \\frac{1}{N}\\sum_{i=1}^{N} x_i(t) \\right) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} \\dot{x}_i(t)\n$$\n代入给定 ODE 系统中 $\\dot{x}_i(t)$ 的表达式：\n$$\n\\dot{m}(t) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} \\left[ f\\big(x_i(t)\\big) \\;+\\; \\sum_{j=1}^{N} g\\big(x_i(t), x_j(t)\\big) \\right]\n$$\n现在，我们代入耦合函数的具体形式 $g\\big(x_i, x_j\\big) = \\frac{\\kappa}{N} h\\big(x_i, x_j\\big)$：\n$$\n\\dot{m}(t) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} \\left[ f\\big(x_i(t)\\big) \\;+\\; \\sum_{j=1}^{N} \\frac{\\kappa}{N} h\\big(x_i(t), x_j(t)\\big) \\right]\n$$\n我们可以通过分配外层求和来分离各项：\n$$\n\\dot{m}(t) \\;=\\; \\frac{1}{N}\\sum_{i=1}^{N} f\\big(x_i(t)\\big) \\;+\\; \\frac{1}{N}\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\frac{\\kappa}{N} h\\big(x_i(t), x_j(t)\\big)\n$$\n重新整理常数，我们得到均值变化率的精确表达式：\n$$\n\\dot{m}(t) \\;=\\; \\left(\\frac{1}{N}\\sum_{i=1}^{N} f\\big(x_i(t)\\big)\\right) \\;+\\; \\kappa \\left(\\frac{1}{N^2}\\sum_{i=1}^{N} \\sum_{j=1}^{N} h\\big(x_i(t), x_j(t)\\big)\\right)\n$$\n这个表达式是精确的，但不是闭合的，因为它的右侧依赖于各个微观状态 $x_i(t)$，而不仅仅是它们的均值 $m(t)$。为了获得 $m(t)$ 的闭合形式动力学，我们必须根据问题中概述的假设引入近似。\n\n一阶平均场闭合所需的假设如下：\n1. **大群体极限 ($N \\to \\infty$)：** 代理的数量被假定为无穷大。在此极限下，根据大数定律，群体上的经验平均值收敛到基于底层状态概率分布的期望值。例如，项 $\\frac{1}{N}\\sum_{i=1}^{N} \\phi(x_i)$ 收敛于期望 $\\mathbb{E}[\\phi(x)]$。\n2. **平均场与统计独立性：** 平均场近似的核心思想是，整个群体对单个代理的影响可以被一个平均场的影響所取代。这一思想的一个关键推论，即所谓的“混沌传播”，是在 $N \\to \\infty$ 的极限下，任何两个不同的代理 $i \\neq j$ 在统计上变得独立。它们状态的联合概率分布 $p(x_i, x_j)$ 可以分解为它们相同的边缘分布的乘积 $p(x_i) p(x_j)$。相互作用函数 $h(x, y)$ 的对称性和代理的相同性（可交换性）是此性质成立的关键。\n3. **一阶闭合（忽略涨落）：** 问题明确要求一阶闭合，即忽略状态分布的方差和更高阶的中心矩。这等同于假设状态分布 $p(x,t)$ 在其均值 $m(t)$ 附近呈尖峰状，因此可以用狄拉克δ函数来近似：$p(x,t) \\approx \\delta(x - m(t))$。这是最强的假设，它将函数的期望简化为期望的函数。\n\n将这些假设应用于 $\\dot{m}(t)$ 方程中的各项：\n\n对于第一项，即 $f(x_i)$ 的经验平均值：\n$$\n\\frac{1}{N}\\sum_{i=1}^{N} f\\big(x_i(t)\\big) \\quad \\xrightarrow{N\\to\\infty} \\quad \\mathbb{E}\\big[f(x)\\big] \\;=\\; \\int f(x) p(x,t) dx\n$$\n应用一阶闭合假设，$p(x,t) \\approx \\delta(x - m(t))$：\n$$\n\\mathbb{E}\\big[f(x)\\big] \\approx \\int f(x) \\delta\\big(x - m(t)\\big) dx \\;=\\; f\\big(m(t)\\big)\n$$\n\n对于第二项，即涉及 $h(x_i, x_j)$ 的双重求和：\n$$\n\\frac{1}{N^2}\\sum_{i=1}^{N} \\sum_{j=1}^{N} h\\big(x_i(t), x_j(t)\\big) \\quad \\xrightarrow{N\\to\\infty} \\quad \\mathbb{E}\\big[h(x,y)\\big] \\;=\\; \\iint h(x,y) p(x,t)p(y,t) dx dy\n$$\n在这里，我们已经使用了统计独立性假设，将联合期望写为边缘密度乘积的积分。现在，应用一阶闭合假设：\n$$\n\\mathbb{E}\\big[h(x,y)\\big] \\approx \\iint h(x,y) \\delta\\big(x - m(t)\\big)\\delta\\big(y - m(t)\\big) dx dy \\;=\\; h\\big(m(t), m(t)\\big)\n$$\n\n将这些近似值代回 $\\dot{m}(t)$ 的方程中：\n$$\n\\dot{m}(t) \\approx f\\big(m(t)\\big) + \\kappa h\\big(m(t), m(t)\\big)\n$$\n这就是序参量 $m(t)$ 的近似自治动力学。宏观漂移是此方程的右侧，表示为序参量 $m$ 的函数。省略显式的时间依赖性，漂移函数为 $f(m) + \\kappa h(m, m)$。",
            "answer": "$$\\boxed{f(m) + \\kappa h(m, m)}$$"
        },
        {
            "introduction": "从动物皮毛的斑纹到城市区域的形成，许多自组织模式都源于一个共同的机制：局部正反馈（激活）和全局负反馈（抑制）。这项动手实践  提供了一个宝贵的机会，让你亲手构建一个反应-扩散模型来模拟这一过程。通过编写代码，你将能直接观察到稳定的空间模式如何从微小的随机扰动中自发涌现，深刻理解模式形成的动力学原理。",
            "id": "4121327",
            "problem": "考虑一个具有周期性边界条件的一维环，该环由 $N$ 个位点组成，索引为 $i \\in \\{0,1,\\dots,N-1\\}$。每个位点带有一个激活水平 $u_i(t) \\in \\mathbb{R}_{\\ge 0}$，该水平由于局部扩散和局部自催化生长而随时间演化。同时，存在一个单一的全局资源 $r(t) \\in \\mathbb{R}_{\\ge 0}$，它与所有位点耦合以提供负反馈。该模型由以下常微分方程组和离散拉普拉斯近似定义：\n$$\n\\frac{d u_i}{d t} = D \\left(u_{i-1} - 2 u_i + u_{i+1}\\right) + \\kappa\\, r(t)\\, u_i + \\alpha\\, u_i^2 - \\mu\\, u_i^3 - \\nu\\, u_i,\n$$\n其中周期性边界条件为 $u_{-1} \\equiv u_{N-1}$ 和 $u_{N} \\equiv u_{0}$，全局资源动力学为\n$$\n\\frac{d r}{d t} = \\rho\\, (r_0 - r) - \\eta\\, r\\, \\bar{u}(t),\n\\quad\\text{其中}\\quad\n\\bar{u}(t) = \\frac{1}{N}\\sum_{i=0}^{N-1} u_i(t).\n$$\n所有变量均为无量纲。系数为 $D$ 的项根据 Fick 定律实现局部扩散；项 $\\alpha\\, u_i^2$ 提供局部正反馈（自催化）；项 $-\\mu\\, u_i^3$ 使增长饱和并防止无界激活；项 $-\\nu\\, u_i$ 提供基线衰减；项 $\\kappa\\, r(t)\\, u_i$ 将全局资源与局部增长耦合。资源 $r(t)$ 以速率 $\\rho$ 向基线值 $r_0$ 松弛，并以与 $r(t)$ 和全局平均激活 $\\bar{u}(t)$ 成正比的速率被消耗，这代表了通过共享竞争实现的全局负反馈。\n\n你的任务是构建一个完整的程序，该程序能够：\n- 使用固定时间步长 $\\Delta t$ 的显式欧拉时间离散化方法，在大小为 $N$ 且具有周期性边界条件的环上模拟上述模型，总共进行 $T$ 步。离散拉普拉斯算子应实现为 $u_{i-1} - 2 u_i + u_{i+1}$，并具有周期性环绕。\n- 将激活水平初始化为在一个小基线值附近的微小随机扰动：$u_i(0) = u_0 \\,(1 + \\epsilon_i)$，其中 $\\epsilon_i$ 是在 $[-\\varepsilon, \\varepsilon]$ 区间内的独立同分布均匀随机变量，并将资源初始化为 $r(0) = r_0$。使用确定性随机种子以确保可复现性。\n- 模拟结束后，判断是否已出现稳定的自组织模式。将“稳定的自组织模式”定义为具有持久空间结构的非均匀稳态构型，通过以下方式量化：\n  1. 最终时刻的非平凡空间方差 $\\mathrm{Var}(u(T)) = \\frac{1}{N}\\sum_{i=0}^{N-1}\\left(u_i(T) - \\bar{u}(T)\\right)^2$，严格大于阈值 $\\theta_{\\mathrm{var}}$，以及\n  2. 在模拟的最后窗口期内，每步的平均变化量 $\\Delta_{\\mathrm{avg}} = \\frac{1}{W}\\sum_{t=T-W}^{T-1} \\left(\\frac{1}{N}\\sum_{i=0}^{N-1} \\left|u_i(t+1) - u_i(t)\\right|\\right)$，对于指定的窗口长度 $W$，该值严格小于阈值 $\\theta_{\\mathrm{chg}}$。\n- 如果存在稳定模式，则通过计算最终空间剖面 $u_i(T)$ 中满足 $u_i(T) > u_{i-1}(T)$ 和 $u_i(T) > u_{i+1}(T)$ 以及 $u_i(T) > \\tau$ 条件的索引 $i$ 的数量，来计算主导峰的整数数量 $P$。其中 $\\tau$ 是一个阈值，定义为 $\\tau = \\phi \\cdot \\max_i u_i(T)$。如果构型在容差范围内是均匀的，即 $\\max_i u_i(T) - \\min_i u_i(T)  \\theta_{\\mathrm{hom}}$，则设置 $P = 0$。\n\n将你的推理和参数选择基于以下基本原理和定义：\n- 局部扩散遵循 Fick 定律，产生离散拉普拉斯项 $u_{i-1} - 2 u_i + u_{i+1}$。\n- 自催化生长通过类质量作用动力学捕捉局部正反馈，由 $u_i$ 的一个超线性项表示，此处为 $\\alpha\\, u_i^2$。\n- 饱和非线性模拟了有限容量并防止数值发散，此处为 $-\\mu\\, u_i^3$。\n- 全局负反馈源于对共享资源的竞争，该资源的可用性随总使用量的增加而减少，此处为 $-\\eta\\, r\\, \\bar{u}$。\n- 均匀平衡点的稳定性可以通过线性化分析：扩散会抑制高波数模式，而全局耦合会改变均匀模式。\n\n使用以下固定的数值参数和测试套件来实现你的模拟，这些参数必须嵌入程序中，而不是从输入中读取：\n\n- 离散化和检测参数：\n  - 域大小：$N = 128$。\n  - 时间步长：$\\Delta t = 0.005$。\n  - 步数：$T = 10000$。\n  - 初始化基线值：$u_0 = 10^{-4}$。\n  - 初始化噪声幅度：$\\varepsilon = 10^{-2}$。\n  - 随机种子：$42$。\n  - 最终窗口长度：$W = 500$。\n  - 方差阈值：$\\theta_{\\mathrm{var}} = 10^{-6}$。\n  - 变化阈值：$\\theta_{\\mathrm{chg}} = 10^{-6}$。\n  - 均匀性容差：$\\theta_{\\mathrm{hom}} = 10^{-8}$。\n  - 峰值阈值分数：$\\phi = 0.2$。\n\n- 模型参数 $(D, \\kappa, \\alpha, \\mu, \\nu, \\rho, \\eta, r_0)$ 的测试套件：\n  1. 情况 A (预期的模式维持区域): $(D, \\kappa, \\alpha, \\mu, \\nu, \\rho, \\eta, r_0) = (0.02, 1.0, 2.0, 1.0, 0.1, 0.5, 1.0, 1.0)$。\n  2. 情况 B (高扩散边界，模式被抑制): $(D, \\kappa, \\alpha, \\mu, \\nu, \\rho, \\eta, r_0) = (0.40, 1.0, 2.0, 1.0, 0.1, 0.5, 1.0, 1.0)$。\n  3. 情况 C (弱全局负反馈，预期为均匀激活): $(D, \\kappa, \\alpha, \\mu, \\nu, \\rho, \\eta, r_0) = (0.02, 1.0, 2.0, 1.0, 0.1, 0.5, 0.05, 1.0)$。\n  4. 情况 D (强衰减，预期为灭绝): $(D, \\kappa, \\alpha, \\mu, \\nu, \\rho, \\eta, r_0) = (0.02, 1.0, 2.0, 1.0, 1.0, 0.5, 1.0, 1.0)$。\n\n你的程序应独立模拟每种情况，应用稳定性和峰值计数标准，并生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个条目是按顺序（情况 A 到情况 D）对应案例的主导峰整数数量 $P$。例如，程序应打印形如 $[p_A,p_B,p_C,p_D]$ 的输出，其中每个 $p_\\bullet$ 都是一个整数。",
            "solution": "该问题是有效的。它提出了一个带有全局耦合的适定反应扩散偏微分方程系统，这是复杂自适应系统和模式形成研究中的一个标准模型。该模型在科学上基于局部自催化、扩散、饱和和全局抑制的既定原理。所有参数、初始条件、数值方法和分析标准都以足够的精度被指定，并且相互一致，使得问题自洽且可解。没有违反科学原理、数学逻辑或客观性的地方。\n\n解决方案的构建首先是对连续时间模型进行离散化，然后实现数值模拟，最后对模拟输出进行定量分析，以表征涌现出的模式。\n\n**1. 模型离散化与模拟算法**\n\n该模型由一个耦合常微分方程组（ODEs）组成。为模拟其演化，我们采用显式欧拉方法进行时间离散化。一个由 $\\frac{dy}{dt} = f(y(t), t)$ 控制的状态变量 $y(t)$，在离散时间步 $t_k = k \\Delta t$ 上根据规则 $y(t_{k+1}) = y(t_k) + \\Delta t \\cdot f(y(t_k), t_k)$ 进行更新。\n\n将此方法应用于激活水平 $u_i$ 和全局资源 $r$，我们得到以下更新方程：\n$$\nu_i(t+\\Delta t) = u_i(t) + \\Delta t \\left[ D \\left(u_{i-1}(t) - 2 u_i(t) + u_{i+1}(t)\\right) + \\kappa\\, r(t)\\, u_i(t) + \\alpha\\, u_i(t)^2 - \\mu\\, u_i(t)^3 - \\nu\\, u_i(t) \\right]\n$$\n$$\nr(t+\\Delta t) = r(t) + \\Delta t \\left[ \\rho\\, (r_0 - r(t)) - \\eta\\, r(t)\\, \\bar{u}(t) \\right]\n$$\n其中 $\\bar{u}(t) = \\frac{1}{N}\\sum_{j=0}^{N-1} u_j(t)$。右侧的所有变量都在当前时间步 $t$ 进行求值。\n\n整个包含 $N$ 个位点的系统由一个向量 $u(t) = [u_0(t), u_1(t), \\dots, u_{N-1}(t)]$ 表示。这允许进行高效的向量化计算。模拟扩散的离散拉普拉斯项 $L(u)_i = u_{i-1} - 2 u_i + u_{i+1}$ 可以对所有位点同时计算。在周期性边界条件（$u_{-1} \\equiv u_{N-1}$ 和 $u_{N} \\equiv u_{0}$）下，此操作在像 NumPy 这样的数值库中等效于 `np.roll(u, 1) + np.roll(u, -1) - 2*u`。\n\n**2. 算法实现**\n\n模拟按以下步骤进行：\n\n- **初始化**：\n  1. 使用指定值 $42$ 为随机数生成器设定种子，以确保可复现性。\n  2. 初始化大小为 $N=128$ 的激活向量 $u$。对于每个位点 $i$，$u_i(0) = u_0 (1 + \\epsilon_i)$，其中 $u_0 = 10^{-4}$，$\\epsilon_i$ 从均匀分布 $U[-\\varepsilon, \\varepsilon]$（$\\varepsilon = 10^{-2}$）中抽取。\n  3. 全局资源 $r$ 初始化为其基线值 $r(0) = r_0$。\n\n- **时间演化循环**：\n  系统状态 $(u, r)$ 以 $\\Delta t = 0.005$ 的时间步长演化总共 $T = 10000$ 步。在每一步中：\n  1. 从当前激活向量 $u(t)$ 计算平均激活 $\\bar{u}(t)$。\n  2. 使用当前状态 $(u(t), r(t))$ 和离散化方程计算时间导数 $\\frac{du}{dt}$（一个向量）和 $\\frac{dr}{dt}$（一个标量）。\n  3. 使用欧拉步将状态更新为 $(u(t+\\Delta t), r(t+\\Delta t))$。\n  4. 在模拟的最后 $W=500$ 步（即，对于从 $T-W$ 到 $T-1$ 的 $t$），计算并存储每个位点的平均绝对变化量 $\\frac{1}{N}\\sum_{i=0}^{N-1} |u_i(t+1) - u_i(t)|$。这用于计算稳态度量 $\\Delta_{\\mathrm{avg}}$。\n\n**3. 模拟后分析与模式表征**\n\n完成 $T$ 步模拟后，分析最终状态 $u(T)$ 以确定峰数 $P$。此分析遵循一套严格的、分层的标准：\n\n1.  **均匀性检查**：首先，我们测试最终构型是否实际上是均匀的。计算最大和最小激活水平之间的差异 $\\max_i u_i(T) - \\min_i u_i(T)$。如果该值小于均匀性容差 $\\theta_{\\mathrm{hom}} = 10^{-8}$，则该状态被认为是均匀的，峰数 $P$ 设为 $0$。\n\n2.  **稳定模式验证**：如果根据上述标准，构型不是均匀的，我们检查它是否符合问题中定义的“稳定自组织模式”的资格。这需要同时满足两个条件：\n    a. **非平凡的空间方差**：最终激活剖面的空间方差 $\\mathrm{Var}(u(T)) = \\frac{1}{N}\\sum_{i=0}^{N-1}\\left(u_i(T) - \\bar{u}(T)\\right)^2$ 必须严格大于阈值 $\\theta_{\\mathrm{var}} = 10^{-6}$。否则，该模式缺乏显著的空间结构，$P$ 设为 $0$。\n    b. **稳态性**：系统必须已稳定到一个近乎稳态的状态。这通过平均变化度量 $\\Delta_{\\mathrm{avg}} = \\frac{1}{W}\\sum_{t=T-W}^{T-1} \\left(\\frac{1}{N}\\sum_{i=0}^{N-1} \\left|u_i(t+1) - u_i(t)\\right|\\right)$ 来量化。该值必须严格小于变化阈值 $\\theta_{\\mathrm{chg}} = 10^{-6}$。如果系统仍在过快演化，则它是不稳定的，$P$ 设为 $0$。\n\n3.  **峰值计数**：如果构型通过了所有前面的检查（即非均匀、具有足够方差且是稳态的），我们便开始计算主导峰的数量。如果一个位点 $i$ 满足以下三个条件，则被计为一个峰：\n    a. 它是一个局部最大值：$u_i(T) > u_{i-1}(T)$ 且 $u_i(T) > u_{i+1}(T)$（索引具有周期性）。\n    b. 它的激活是显著的：$u_i(T) > \\tau$，其中阈值 $\\tau$ 定义为全局最大激活值的一部分，$\\tau = \\phi \\cdot \\max_j u_j(T)$，且 $\\phi = 0.2$。\n\n满足这些条件的位点总数即为峰的整数数量 $P$。这整个过程被独立地应用于所提供的四个测试案例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print the results.\n    \"\"\"\n\n    # Discretization and detection parameters from the problem statement\n    sim_config = {\n        'N': 128,          # Domain size\n        'dt': 0.005,       # Time step\n        'T_steps': 10000,  # Number of steps\n        'u0': 1e-4,        # Initialization baseline\n        'epsilon': 1e-2,   # Initialization noise amplitude\n        'seed': 42,        # Random seed\n        'W': 500,          # Final window length for stability check\n        'theta_var': 1e-6, # Variance threshold\n        'theta_chg': 1e-6, # Change threshold\n        'theta_hom': 1e-8, # Homogeneity tolerance\n        'phi': 0.2,        # Peak threshold fraction\n    }\n\n    # Test suite of model parameters (D, kappa, alpha, mu, nu, rho, eta, r0)\n    test_cases = [\n        # Case A: anticipated pattern-sustaining regime\n        (0.02, 1.0, 2.0, 1.0, 0.1, 0.5, 1.0, 1.0),\n        # Case B: high diffusion boundary, pattern suppressed\n        (0.40, 1.0, 2.0, 1.0, 0.1, 0.5, 1.0, 1.0),\n        # Case C: weak global negative feedback, homogeneous activation expected\n        (0.02, 1.0, 2.0, 1.0, 0.1, 0.5, 0.05, 1.0),\n        # Case D: strong decay, extinction expected\n        (0.02, 1.0, 2.0, 1.0, 1.0, 0.5, 1.0, 1.0),\n    ]\n\n    results = []\n    # Set the seed once for reproducibility across all cases\n    np.random.seed(sim_config['seed'])\n    # Generate the initial random perturbations once\n    initial_perturbations = sim_config['u0'] * (\n        1 + (np.random.rand(sim_config['N']) * 2 - 1) * sim_config['epsilon']\n    )\n\n    for params in test_cases:\n        p = run_simulation(params, sim_config, initial_perturbations.copy())\n        results.append(p)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(params, config, initial_u):\n    \"\"\"\n    Simulates the model for one set of parameters and returns the number of peaks.\n    \"\"\"\n    D, kappa, alpha, mu, nu, rho, eta, r0 = params\n    N, dt, T_steps, W = config['N'], config['dt'], config['T_steps'], config['W']\n    \n    # Initialization\n    u = initial_u\n    r = r0\n    \n    changes_in_window = []\n\n    # Time evolution loop\n    for t_step in range(T_steps):\n        u_old = u.copy()\n        \n        # Calculate discrete Laplacian with periodic boundary conditions\n        u_left_shifted = np.roll(u, 1)\n        u_right_shifted = np.roll(u, -1)\n        laplacian = u_left_shifted - 2 * u + u_right_shifted\n\n        # Calculate time derivative for u\n        du_dt = (D * laplacian + \n                 kappa * r * u + \n                 alpha * u**2 - \n                 mu * u**3 - \n                 nu * u)\n        \n        # Calculate time derivative for r\n        u_bar = np.mean(u)\n        dr_dt = rho * (r0 - r) - eta * r * u_bar\n\n        # Update u and r using Euler's method\n        u = u + dt * du_dt\n        r = r + dt * dr_dt\n        \n        # Ensure activations remain non-negative\n        u[u < 0] = 0\n\n        # Collect data for stability check in the final window\n        if t_step >= T_steps - W:\n            step_change = np.mean(np.abs(u - u_old))\n            changes_in_window.append(step_change)\n\n    # Post-simulation analysis\n    u_final = u\n\n    # 1. Homogeneity check\n    if np.max(u_final) - np.min(u_final) < config['theta_hom']:\n        return 0\n\n    # 2. Stable pattern verification\n    # a. Variance check\n    var_u = np.var(u_final)\n    if var_u <= config['theta_var']:\n        return 0\n    \n    # b. Stationarity check\n    delta_avg = np.mean(changes_in_window)\n    if delta_avg >= config['theta_chg']:\n        return 0\n        \n    # 3. Peak counting\n    u_max = np.max(u_final)\n    if u_max == 0: # Extinct state\n        return 0\n        \n    peak_threshold = config['phi'] * u_max\n    \n    u_final_left = np.roll(u_final, 1)\n    u_final_right = np.roll(u_final, -1)\n\n    is_peak = ( (u_final > u_final_left) & \n                (u_final > u_final_right) & \n                (u_final > peak_threshold) )\n    \n    num_peaks = np.sum(is_peak)\n    \n    return num_peaks\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "当涌现结构形成后，我们需要定量的方法来探测和刻画它们。谱图论为分析复杂网络中的宏观组织提供了一个极其强大的数学框架，它能揭示连接模式中隐藏的结构信息。这项实践练习  侧重于应用图拉普拉斯算子的谱特性，特别是利用其特征向量来识别网络的社群结构或二分性，让你学会如何将抽象的连接数据转化为有意义的宏观洞见。",
            "id": "4121314",
            "problem": "考虑一个由无向、无权图建模的网络，该网络有 $n$ 个节点，由一个对称邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 表示，其元素 $A_{ij} \\in \\{0,1\\}$ 且对所有 $i$ 都有 $A_{ii} = 0$。定义度向量 $d \\in \\mathbb{R}^{n}$ 为 $d_i = \\sum_{j=1}^n A_{ij}$，对角度矩阵为 $D = \\mathrm{diag}(d)$，（未归一化的）组合拉普拉斯矩阵为 $L = D - A$，以及归一化拉普拉斯矩阵为 $\\mathcal{L} = I - D^{-1/2} A D^{-1/2}$。约定对于任何度 $d_i = 0$ 的节点 $i$，设置 $(D^{-1/2})_{ii} = 0$。这些构造源于谱图理论，是研究复杂自适应系统中涌现和自组织的基础：由 $A$ 编码的简单局部交互规则可以导致涌现的模块性（社群）或二分结构，这些结构可以通过 $L$ 和 $\\mathcal{L}$ 的谱量来检测。\n\n使用以下经过充分检验的事实作为基础：\n- 对于任何无向图，$L$ 是对称半正定的，且 $L$ 的特征值 $0$ 的重数等于连通分量的数量。\n- $L$ 的第二小特征值，记为 $\\lambda_2$，及其关联的特征向量（Fiedler 向量）为基于切割的社群发现问题提供了一个松弛解法：对 Fiedler 向量进行阈值处理可以得到一个信息丰富的二分划分，该划分通常与涌现的社群结构一致。\n- 归一化拉普拉斯矩阵 $\\mathcal{L}$ 的特征值在区间 $[0,2]$ 内，一个连通图是二分图当且仅当 $\\mathcal{L}$ 的最大特征值等于 $2$。\n\n您的任务是实现一个完整的程序，对于一个给定的小型图测试套件，检测涌现的二分结构，并通过 Fiedler 向量生成一个指示社群结构的光谱二分划分。对于每个测试用例，执行以下步骤：\n1. 从 $A$ 计算 $L$ 和 $\\mathcal{L}$。\n2. 计算 $L$ 的特征值，并通过计算满足 $\\lambda  \\epsilon$（其中 $\\epsilon = 10^{-8}$）的特征值数量来确定连通分量的数量 $c$。\n3. 计算 $\\mathcal{L}$ 的特征值，如果 $\\max \\mathrm{spec}(\\mathcal{L})$ 在 $2$ 的 $\\delta$ 范围内，即 $|2 - \\lambda_{\\max}(\\mathcal{L})| \\le \\delta$（其中 $\\delta = 10^{-8}$），则将二分性指示符 $b$ 设置为 true，否则设置为 false。\n4. 计算 $L$ 的 Fiedler 向量 $v$（与第二小特征值 $\\lambda_2$ 相关联的特征向量）。通过在 $0$ 处进行阈值处理来构造一个二分划分 $(S_+, S_-)$：$S_+ = \\{ i \\mid v_i \\ge 0 \\}$ 和 $S_- = \\{ i \\mid v_i  0 \\}$。如果其中一个集合为空，则改用 $v$ 的中位数作为阈值，以确保两个部分都非空。\n5. 计算划分的归一化切割值，定义为\n$$\n\\mathrm{NCut}(S_+, S_-) = \\mathrm{cut}(S_+, S_-) \\left( \\frac{1}{\\mathrm{vol}(S_+)} + \\frac{1}{\\mathrm{vol}(S_-)} \\right),\n$$\n其中\n$$\n\\mathrm{cut}(S_+, S_-) = \\sum_{i \\in S_+} \\sum_{j \\in S_-} A_{ij}, \\quad \\mathrm{vol}(S) = \\sum_{i \\in S} d_i.\n$$\n如果 $\\mathrm{vol}(S_+)$ 或 $\\mathrm{vol}(S_-)$ 为零，当 $\\mathrm{cut}(S_+, S_-) = 0$ 时定义 $\\mathrm{NCut}(S_+, S_-) = 0$，否则定义为 $+\\infty$。\n\n对于每个测试用例，生成一个结果列表 $[\\;b,\\;c,\\;\\lambda_2,\\;\\mathrm{NCut}(S_+, S_-)\\;]$，其中 $b$ 是布尔值，$c$ 是整数，$\\lambda_2$ 和 $\\mathrm{NCut}(S_+, S_-)$ 是四舍五入到 $6$ 位小数的浮点数。\n\n测试套件规范：\n- 用例 1 (完全二分图 $K_{3,3}$): 节点 $\\{0,1,2\\}$ 和 $\\{3,4,5\\}$，存在所有交叉边，即对于所有 $i \\in \\{0,1,2\\}$ 和 $j \\in \\{3,4,5\\}$ 存在边 $(i,j)$。\n- 用例 2 (两个由弱连接桥接的密集社群): 节点 $\\{0,1,2,3\\}$ 形成一个团，节点 $\\{4,5,6,7\\}$ 形成一个团，并有两条桥接边 $(1,5)$ 和 $(2,6)$。\n- 用例 3 ($K_{3,3}$ 加上一条破坏二分性的部分内边): 用例 1 的所有边，外加一条边 $(0,1)$。\n- 用例 4 (路径图 $P_6$): 节点 $\\{0,1,2,3,4,5\\}$，边为 $(0,1)$, $(1,2)$, $(2,3)$, $(3,4)$, $(4,5)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例按上述顺序贡献一个子列表。例如，格式为 $[\\,[\\ldots],\\,[\\ldots],\\,[\\ldots],\\,[\\ldots]\\,]$。此问题不涉及物理单位或角度单位。所有浮点输出必须按规定四舍五入到 $6$ 位小数。公差参数必须精确取为 $\\epsilon = 10^{-8}$ 和 $\\delta = 10^{-8}$。程序必须是自包含的，且不需要任何输入。",
            "solution": "所提出的问题是有效的。它在科学上基于谱图理论的原理，谱图理论是数学和计算机科学中一个成熟的学科，用于研究复杂网络的性质。该问题是适定的，提供了一套完整且明确的定义、数据和程序性指令。它是客观的，没有主观论断，并且在计算上是可行的。任务是使用图的光谱特性来分析一系列图，这是理解复杂自适应系统中涌现结构的核心技术。\n\n解决方案的流程是为测试套件中的每个图实现指定的分析步骤。我们将首先为每个图构建邻接矩阵 $A$。从 $A$ 中，我们推导出用于谱分析的基本矩阵：度矩阵 $D$、组合拉普拉斯矩阵 $L = D - A$ 以及归一化拉普拉斯矩阵 $\\mathcal{L} = I - D^{-1/2} A D^{-1/2}$。\n\n**1. 矩阵构造与特征分解**\n\n对于一个有 $n$ 个节点的图，邻接矩阵 $A$ 是一个 $n \\times n$ 的矩阵，其中如果节点 $i$ 和 $j$ 之间存在边，则 $A_{ij}=1$，否则 $A_{ij}=0$。节点 $i$ 的度 $d_i$ 是连接到它的边的数量，计算公式为 $d_i = \\sum_{j=1}^n A_{ij}$。度矩阵 $D$ 是一个对角矩阵，其对角线上的元素为度 $d_i$，即 $D_{ii} = d_i$。\n\n组合拉普拉斯矩阵是 $L = D - A$。归一化拉普拉斯矩阵 $\\mathcal{L}$ 使用矩阵 $D^{-1/2}$ 构建，这是一个对角矩阵，其元素 $(D^{-1/2})_{ii} = 1/\\sqrt{d_i}$（如果 $d_i > 0$）和 $0$（如果 $d_i=0$）。然后，$\\mathcal{L} = I - D^{-1/2} A D^{-1/2}$。\n\n由于对于任何无向图，$L$ 和 $\\mathcal{L}$ 都是实对称矩阵，它们的特征值是实数，并且它们拥有一整套正交的特征向量。我们可以使用数值线性代数库来计算这些值，具体来说就是求解特征值问题 $Mx = \\lambda x$。\n\n**2. 算法流程**\n\n对于每个图，我们执行以下计算序列：\n\n- **步骤 1：计算拉普拉斯矩阵。** 给定邻接矩阵 $A$，我们根据定义计算度向量 $d$、度矩阵 $D$、组合拉普拉斯矩阵 $L$ 和归一化拉普拉斯矩阵 $\\mathcal{L}$。\n\n- **步骤 2：确定连通性。** 我们计算 $L$ 的特征值。根据谱图理论，图中的连通分量数 $c$ 等于特征值 $0$ 的重数。在数值计算上，我们统计小于一个小的公差 $\\epsilon = 10^{-8}$ 的特征值 $\\lambda$ 的数量。\n\n- **步骤 3：测试二分性。** 我们计算归一化拉普拉斯矩阵 $\\mathcal{L}$ 的特征值。一个连通图是二分图当且仅当其最大特征值为 $2$。如果最大特征值 $\\lambda_{\\max}(\\mathcal{L})$ 满足 $|2 - \\lambda_{\\max}(\\mathcal{L})| \\le \\delta$（其中 $\\delta = 10^{-8}$），我们将布尔指示符 $b$ 设置为 true。\n\n- **步骤 4：谱二分。** 与 $L$ 的第二小特征值（$\\lambda_2$）相对应的特征向量称为 Fiedler 向量，记为 $v$。该向量为离散图划分问题提供了连续松弛。我们通过对 Fiedler 向量的分量进行阈值处理来构建图节点的二分划分 $(S_+, S_-)$。满足 $v_i \\ge 0$ 的节点 $i$ 放入集合 $S_+$，满足 $v_i  0$ 的节点放入集合 $S_-$。如果此过程导致其中一个集合为空，我们转而使用 Fiedler 向量分量的中位数进行阈值处理，以确保得到一个非平凡的划分。\n\n- **步骤 5：计算归一化切割。** 划分 $(S_+, S_-)$ 的质量由归一化切割值 $\\mathrm{NCut}$ 来量化。其定义为：\n$$\n\\mathrm{NCut}(S_+, S_-) = \\mathrm{cut}(S_+, S_-) \\left( \\frac{1}{\\mathrm{vol}(S_+)} + \\frac{1}{\\mathrm{vol}(S_-)} \\right)\n$$\n这里，$\\mathrm{cut}(S_+, S_-) = \\sum_{i \\in S_+} \\sum_{j \\in S_-} A_{ij}$ 是连接两个划分的边的数量，而 $\\mathrm{vol}(S) = \\sum_{i \\in S} d_i$ 是一个划分 $S$ 中节点度的总和。当体积为零的特殊情况按规定处理：如果 $\\mathrm{vol}(S_+)$ 或 $\\mathrm{vol}(S_-)$ 为零，若切割值也为零，则 $\\mathrm{NCut}$ 为 $0$，否则为 $\\infty$。对于给定的测试用例，所有图都是连通的，因此任何非空划分的体积都将为正，不会遇到这种特殊情况。\n\n每个图的最终输出是一个列表，包含二分性指示符 $b$、连通分量数 $c$、Fiedler 值 $\\lambda_2$ 和归一化切割值 $\\mathrm{NCut}$，其中浮点数四舍五入到 $6$ 位小数。\n\n**应用于测试用例**\n\n该程序应用于代表四个测试用例的邻接矩阵：\n1.  **$K_{3,3}$**：一个完全二分图。预期：$c=1$，$b=\\text{true}$。Fiedler 向量将完美地分离开二分划分的两个节点集。\n2.  **两个由弱连接桥接的团**：一个具有强社群结构的图。预期：$c=1$，$b=\\text{false}$。$\\lambda_2$ 应该很小，表示一个良好但非平凡的切割。Fiedler 向量应该能分离开两个团。\n3.  **带有一条额外边的 $K_{3,3}$**：一个近似二分图。预期：$c=1$，$b=\\text{false}$。其性质应与 $K_{3,3}$ 的性质相近，但二分性被破坏。\n4.  **路径图 $P_6$**：一个简单的二分图。预期：$c=1$，$b=\\text{true}$。Fiedler 向量将产生一个与路径图的自然着色相对应的划分。\n\n该实现将使用 `numpy` 进行所有矩阵运算和特征分解。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run analysis, and print results.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n\n    # Case 1: Complete bipartite graph K_3,3\n    # Nodes {0,1,2} and {3,4,5}\n    A1 = np.zeros((6, 6), dtype=int)\n    for i in range(3):\n        for j in range(3, 6):\n            A1[i, j] = 1\n            A1[j, i] = 1\n\n    # Case 2: Two dense communities weakly bridged\n    # Cliques {0,1,2,3} and {4,5,6,7}. Bridges (1,5) and (2,6).\n    A2 = np.zeros((8, 8), dtype=int)\n    # Clique 1\n    for i in range(4):\n        for j in range(i + 1, 4):\n            A2[i, j] = 1\n            A2[j, i] = 1\n    # Clique 2\n    for i in range(4, 8):\n        for j in range(i + 1, 8):\n            A2[i, j] = 1\n            A2[j, i] = 1\n    # Bridges\n    A2[1, 5] = A2[5, 1] = 1\n    A2[2, 6] = A2[6, 2] = 1\n\n    # Case 3: K_3,3 plus one intra-part edge (0,1)\n    A3 = A1.copy()\n    A3[0, 1] = A3[1, 0] = 1\n\n    # Case 4: Path graph P_6\n    # Nodes {0,1,2,3,4,5}\n    A4 = np.zeros((6, 6), dtype=int)\n    for i in range(5):\n        A4[i, i + 1] = 1\n        A4[i + 1, i] = 1\n\n    test_cases = [A1, A2, A3, A4]\n    \n    results = []\n    for A in test_cases:\n        result = analyze_graph(A)\n        results.append(result)\n\n    # Format output as a list of lists.\n    # str() correctly converts booleans to 'True'/'False' and numbers to strings.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef analyze_graph(A, epsilon=1e-8, delta=1e-8):\n    \"\"\"\n    Performs spectral analysis on a graph given its adjacency matrix A.\n    \n    Args:\n        A (np.ndarray): The symmetric adjacency matrix of the graph.\n        epsilon (float): Tolerance for counting zero eigenvalues of L.\n        delta (float): Tolerance for checking bipartiteness from eigenvalues of L_norm.\n\n    Returns:\n        list: A list containing [b, c, lambda_2, NCut].\n    \"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return [False, 0, 0.0, 0.0]\n\n    # --- Step 1: Compute Laplacians ---\n    d = A.sum(axis=1)\n    D = np.diag(d)\n    L = D - A\n\n    # Normalized Laplacian L_norm = I - D^(-1/2) * A * D^(-1/2)\n    # Handle nodes with degree 0\n    d_inv_sqrt_vals = np.zeros(n)\n    d_gt_0_indices = d > 0\n    d_inv_sqrt_vals[d_gt_0_indices] = 1.0 / np.sqrt(d[d_gt_0_indices])\n    D_inv_sqrt = np.diag(d_inv_sqrt_vals)\n    L_norm = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt\n\n    # --- Step 2: Determine Connectivity ---\n    # np.linalg.eigh is for symmetric matrices, returns sorted eigenvalues.\n    eigvals_L, eigvecs_L = np.linalg.eigh(L)\n    c = np.sum(eigvals_L < epsilon)\n    \n    # Second smallest eigenvalue (Fiedler value)\n    lambda_2 = 0.0\n    if n > 1:\n        lambda_2 = eigvals_L[1]\n\n    # --- Step 3: Test for Bipartiteness ---\n    eigvals_L_norm = np.linalg.eigvalsh(L_norm)\n    lambda_max_L_norm = np.max(eigvals_L_norm) if eigvals_L_norm.size > 0 else 0.0\n    b = np.abs(lambda_max_L_norm - 2.0) <= delta\n\n    # --- Step 4: Spectral Bipartitioning ---\n    S_plus_indices = np.array([], dtype=int)\n    S_minus_indices = np.array([], dtype=int)\n    if n > 1:\n        # Fiedler vector is the eigenvector for lambda_2\n        v_fiedler = eigvecs_L[:, 1]\n        \n        S_plus_indices = np.where(v_fiedler >= 0)[0]\n        S_minus_indices = np.where(v_fiedler < 0)[0]\n\n        # If one set is empty, threshold at the median\n        if S_plus_indices.size == 0 or S_minus_indices.size == 0:\n            median = np.median(v_fiedler)\n            # This refined logic handles cases where median is min/max\n            if np.all(v_fiedler >= median):\n                 # move the element with smallest value to S_minus\n                 min_val_idx = np.argmin(v_fiedler)\n                 S_plus_indices = np.setdiff1d(np.arange(n), [min_val_idx])\n                 S_minus_indices = np.array([min_val_idx])\n            else:\n                 S_plus_indices = np.where(v_fiedler >= median)[0]\n                 S_minus_indices = np.where(v_fiedler < median)[0]\n\n\n    # --- Step 5: Compute Normalized Cut ---\n    cut_val = 0.0\n    ncut_val = 0.0\n    if S_plus_indices.size > 0 and S_minus_indices.size > 0:\n        # A[S_plus, S_minus] is not valid, need to expand slicing\n        cut_val = A[S_plus_indices[:, np.newaxis], S_minus_indices].sum()\n\n    vol_S_plus = d[S_plus_indices].sum()\n    vol_S_minus = d[S_minus_indices].sum()\n\n    if vol_S_plus == 0 or vol_S_minus == 0:\n        if cut_val > 0:\n            ncut_val = np.inf\n        else:\n            ncut_val = 0.0\n    else:\n        ncut_val = cut_val * (1.0 / vol_S_plus + 1.0 / vol_S_minus)\n\n    # Format results with rounding\n    return [b, int(c), round(lambda_2, 6), round(ncut_val, 6)]\n\n# Execute the solution\nsolve()\n\n```"
        }
    ]
}