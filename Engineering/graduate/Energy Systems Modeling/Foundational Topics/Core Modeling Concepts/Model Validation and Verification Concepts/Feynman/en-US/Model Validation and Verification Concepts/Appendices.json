{
    "hands_on_practices": [
        {
            "introduction": "Verification often begins at the component level, ensuring that the numerical implementation of a model respects fundamental physical laws and operational constraints. This exercise demonstrates verification through *invariant checking*, where invariants are properties, such as the conservation of energy or state variable bounds, that must hold true for any valid simulation. By implementing automated checks for these invariants, you build a suite of unit tests that provide a foundational layer of confidence in your model's correctness, as demonstrated here for a battery storage model .",
            "id": "4105658",
            "problem": "Consider a discrete-time model of an electrochemical energy storage device (battery) in an energy systems context. Let the time index be $t \\in \\{0,1,\\dots,T\\}$, with uniform time step $\\Delta t$ measured in hours. Let $p_t$ denote electrical power in kilowatts, positive for charging and negative for discharging, and let $s_t$ denote the state of charge in kilowatt-hours. The device has a charge conversion efficiency $\\eta_c \\in (0,1]$, a discharge conversion efficiency $\\eta_d \\in (0,1]$, and a maximum energy capacity $E_{\\max}$ in kilowatt-hours. The maximum allowable ramp rate magnitude is $R_{\\max}$ in kilowatts per hour. A numerical tolerance $\\varepsilon > 0$ is used to guard against floating-point rounding.\n\nFundamental base: Energy conservation implies that the change in stored energy over one time step equals the net converted input energy. Specifically, defining the positive part of power as $\\max(p_t,0)$ and the magnitude of the negative part as $\\max(-p_t,0)$, the energy balance for the storage reads\n$$s_{t+1} - s_t = \\eta_c \\cdot \\max(p_t,0)\\cdot \\Delta t - \\frac{1}{\\eta_d}\\cdot \\max(-p_t,0)\\cdot \\Delta t.$$\nPhysical feasibility requires the following invariants:\n- Non-negativity and capacity bound of state of charge: for all $t$, $0 \\le s_t \\le E_{\\max}$, interpreted numerically as $s_t \\ge -\\varepsilon$ and $s_t \\le E_{\\max} + \\varepsilon$.\n- Bounded ramp rate: for all $t \\ge 1$, $|\\lvert p_t - p_{t-1} \\rvert \\le R_{\\max}\\cdot \\Delta t + \\varepsilon|$.\n- Monotonicity on sign-consistent segments: for any step $t$, if $p_t \\ge 0$ then $s_{t+1} - s_t \\ge -\\varepsilon$, and if $p_t < 0$ then $s_{t+1} - s_t \\le \\varepsilon$.\n- Energy consistency over the horizon: $s_T$ equals $s_0 + \\sum_{t=0}^{T-1}\\left(\\eta_c \\cdot \\max(p_t,0)\\cdot \\Delta t - \\frac{1}{\\eta_d}\\cdot \\max(-p_t,0)\\cdot \\Delta t\\right)$ within tolerance $\\varepsilon$.\n\nTask: Starting from the above base, implement a program that, for each test case below, computes the trajectory $\\{s_t\\}_{t=0}^{T}$ from the given parameters and sequence $\\{p_t\\}_{t=0}^{T-1}$, checks all invariants over the trajectory, and returns a boolean indicating whether all invariants hold for the case.\n\nYou must respect the following units in all calculations and checks: energy in kilowatt-hours (kWh), power in kilowatts (kW), time in hours, ramp rate in kilowatts per hour (kW/h). Angles are not used. All final boolean results must be computed with the specified tolerance $\\varepsilon$.\n\nTest suite:\n- Case $1$ (happy path): $E_{\\max}=100$ kWh, $s_0=50$ kWh, $\\eta_c=0.95$, $\\eta_d=0.9$, $\\Delta t=1$ hour, $R_{\\max}=20$ kW/h, $\\varepsilon=10^{-8}$, $p=[10,10,-5,-5,0]$ kW.\n- Case $2$ (ramp violation): $E_{\\max}=100$ kWh, $s_0=50$ kWh, $\\eta_c=0.95$, $\\eta_d=0.9$, $\\Delta t=1$ hour, $R_{\\max}=30$ kW/h, $\\varepsilon=10^{-8}$, $p=[0,50,-50]$ kW.\n- Case $3$ (state-of-charge negative violation): $E_{\\max}=50$ kWh, $s_0=5$ kWh, $\\eta_c=0.95$, $\\eta_d=0.9$, $\\Delta t=1$ hour, $R_{\\max}=100$ kW/h, $\\varepsilon=10^{-8}$, $p=[-10,-10]$ kW.\n- Case $4$ (capacity overflow violation): $E_{\\max}=100$ kWh, $s_0=95$ kWh, $\\eta_c=0.95$, $\\eta_d=0.9$, $\\Delta t=1$ hour, $R_{\\max}=100$ kW/h, $\\varepsilon=10^{-8}$, $p=[10,10]$ kW.\n- Case $5$ (boundary with tolerance): $E_{\\max}=100$ kWh, $s_0=100$ kWh, $\\eta_c=1$, $\\eta_d=1$, $\\Delta t=1$ hour, $R_{\\max}=100$ kW/h, $\\varepsilon=10^{-8}$, $p=[10^{-9},-10^{-9}]$ kW.\n- Case $6$ (varying time step and pure charging): $E_{\\max}=200$ kWh, $s_0=100$ kWh, $\\eta_c=0.9$, $\\eta_d=0.9$, $\\Delta t=0.5$ hour, $R_{\\max}=100$ kW/h, $\\varepsilon=10^{-8}$, $p=[20,30,0,0]$ kW.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots]$), where each $result_i$ is the boolean outcome for case $i$ computed using the above invariants and tolerance.",
            "solution": "The problem statement provides a discrete-time model for an electrochemical energy storage device and a set of physical invariants. The task is to write a program that simulates the device's state of charge based on a given power profile and verifies if the trajectory adheres to all specified invariants.\n\nThe problem has been validated and is deemed sound. It is scientifically grounded in standard energy storage modeling principles, well-posed with a unique computational outcome for each test case, and all necessary parameters and conditions are provided. The procedure is as follows:\n\nFirst, we will construct a function to process a single test case. This function will accept the device parameters ($E_{\\max}$, $s_0$, $\\eta_c$, $\\eta_d$, $\\Delta t$, $R_{\\max}$, $\\varepsilon$) and the input power sequence $\\{p_t\\}_{t=0}^{T-1}$.\n\nThe core of the function involves two main steps: simulation and validation.\n\n**1. State of Charge Trajectory Simulation**\n\nThe state of charge (SOC) trajectory, denoted by $\\{s_t\\}_{t=0}^{T}$, is computed iteratively. Let the length of the given power sequence $p$ be $N$, so $T=N$. The trajectory $\\{s_t\\}$ will have $N+1$ elements.\nThe initial state $s_0$ is given. Subsequent states $s_{t+1}$ for $t \\in \\{0, 1, \\dots, T-1\\}$ are calculated using the energy balance equation provided:\n$$s_{t+1} = s_t + \\Delta s_t$$\nwhere the change in SOC, $\\Delta s_t$, is:\n$$\\Delta s_t = \\eta_c \\cdot \\max(p_t,0)\\cdot \\Delta t - \\frac{1}{\\eta_d}\\cdot \\max(-p_t,0)\\cdot \\Delta t$$\nHere, $p_t$ is the power at time step $t$, $\\Delta t$ is the duration of the time step, $\\eta_c$ is the charging efficiency, and $\\eta_d$ is the discharging efficiency. The $\\max(\\cdot,0)$ functions correctly separate the charging (positive power) and discharging (negative power) components.\n\n**2. Invariant Verification**\n\nAfter computing the full SOC trajectory $\\{s_t\\}_{t=0}^{T}$, we must verify four physical feasibility invariants. A boolean flag, initially true, will be set to false if any invariant is violated.\n\n**Invariant 1: SOC Bounds**\nFor all time steps $t \\in \\{0, 1, \\dots, T\\}$, the state of charge $s_t$ must remain within the physical capacity of the device. The check is performed with a numerical tolerance $\\varepsilon > 0$:\n$$-\\varepsilon \\le s_t \\le E_{\\max} + \\varepsilon$$\nThis check is applied to every element of the computed SOC trajectory, including the initial state $s_0$.\n\n**Invariant 2: Bounded Ramp Rate**\nThe rate of change of power must not exceed the device's maximum ramp rate, $R_{\\max}$. This constraint applies for all $t \\in \\{1, \\dots, T-1\\}$:\n$$\\lvert p_t - p_{t-1} \\rvert \\le R_{\\max}\\cdot \\Delta t + \\varepsilon$$\nThe absolute difference in power between consecutive time steps is compared against the maximum allowed change over the interval $\\Delta t$, including the tolerance $\\varepsilon$.\n\n**Invariant 3: Monotonicity**\nThis invariant ensures that charging increases the SOC and discharging decreases it. It is a direct consequence of the energy balance equation, assuming positive efficiencies ($\\eta_c > 0, \\eta_d > 0$). The check serves as a validation of the numerical implementation for each time step $t \\in \\{0, 1, \\dots, T-1\\}$:\n- If charging ($p_t \\ge 0$), the change in SOC must be non-negative: $s_{t+1} - s_t \\ge -\\varepsilon$.\n- If discharging ($p_t < 0$), the change in SOC must be non-positive: $s_{t+1} - s_t \\le \\varepsilon$.\n\n**Invariant 4: Energy Consistency**\nThis final check verifies the integrity of the overall simulation by comparing the final state $s_T$ from the iterative computation against a value calculated directly from the initial state $s_0$ and the sum of all energy changes over the entire horizon. This guards against the accumulation of significant floating-point errors.\nFirst, we calculate the expected final state $s_{T, \\text{check}}$:\n$$s_{T, \\text{check}} = s_0 + \\sum_{t=0}^{T-1}\\left(\\eta_c \\cdot \\max(p_t,0)\\cdot \\Delta t - \\frac{1}{\\eta_d}\\cdot \\max(-p_t,0)\\cdot \\Delta t\\right)$$\nThen, we compare this with the iteratively computed $s_T$:\n$$\\lvert s_T - s_{T, \\text{check}} \\rvert \\le \\varepsilon$$\n\nIf all four invariants hold true for a given test case, the function returns `True`; otherwise, it returns `False`. The main program will execute this process for each test case in the provided suite and format the boolean results into the required output string.",
            "answer": "```python\nimport numpy as np\n\ndef check_single_case(E_max, s_0, eta_c, eta_d, delta_t, R_max, epsilon, p_seq):\n    \"\"\"\n    Simulates the battery trajectory and checks all physical invariants.\n\n    Args:\n        E_max (float): Maximum energy capacity in kWh.\n        s_0 (float): Initial state of charge in kWh.\n        eta_c (float): Charge conversion efficiency.\n        eta_d (float): Discharge conversion efficiency.\n        delta_t (float): Time step in hours.\n        R_max (float): Maximum ramp rate in kW/h.\n        epsilon (float): Numerical tolerance.\n        p_seq (list or tuple): Sequence of power values in kW.\n\n    Returns:\n        bool: True if all invariants hold, False otherwise.\n    \"\"\"\n    p = np.array(p_seq, dtype=float)\n    T = len(p)\n\n    # 1. Compute the state of charge trajectory s_t\n    s = np.zeros(T + 1, dtype=float)\n    s[0] = s_0\n\n    # This check is done first as s_0 is an input.\n    # Invariant 1 check for s_0\n    if not (-epsilon <= s[0] <= E_max + epsilon):\n        return False\n\n    for t in range(T):\n        p_t = p[t]\n        charge_term = eta_c * max(p_t, 0) * delta_t\n        discharge_term = (1 / eta_d) * max(-p_t, 0) * delta_t\n        delta_s = charge_term - discharge_term\n        s[t + 1] = s[t] + delta_s\n\n        # Invariant 1: SOC bounds (checked iteratively)\n        if not (-epsilon <= s[t + 1] <= E_max + epsilon):\n            return False\n            \n        # Invariant 3: Monotonicity\n        if p_t >= 0:\n            if delta_s < -epsilon:\n                return False\n        else:  # p_t < 0\n            if delta_s > epsilon:\n                return False\n\n    # Invariant 2: Bounded ramp rate\n    ramp_limit = R_max * delta_t\n    for t in range(1, T):\n        if abs(p[t] - p[t - 1]) > ramp_limit + epsilon:\n            return False\n\n    # Invariant 4: Energy consistency over the horizon\n    total_energy_change_sum = 0\n    for t in range(T):\n        p_t = p[t]\n        charge_term = eta_c * max(p_t, 0) * delta_t\n        discharge_term = (1 / eta_d) * max(-p_t, 0) * delta_t\n        total_energy_change_sum += (charge_term - discharge_term)\n\n    s_T_check = s_0 + total_energy_change_sum\n    \n    if abs(s[T] - s_T_check) > epsilon:\n        return False\n        \n    return True\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # E_max, s_0, eta_c, eta_d, delta_t, R_max, epsilon, p\n    test_cases = [\n        (100, 50, 0.95, 0.9, 1, 20, 1e-8, [10, 10, -5, -5, 0]),\n        (100, 50, 0.95, 0.9, 1, 30, 1e-8, [0, 50, -50]),\n        (50, 5, 0.95, 0.9, 1, 100, 1e-8, [-10, -10]),\n        (100, 95, 0.95, 0.9, 1, 100, 1e-8, [10, 10]),\n        (100, 100, 1, 1, 1, 100, 1e-8, [1e-9, -1e-9]),\n        (200, 100, 0.9, 0.9, 0.5, 100, 1e-8, [20, 30, 0, 0]),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = check_single_case(*case)\n        results.append(result)\n\n    # Format the output as a single-line comma-separated list of booleans\n    # The default str() for a boolean is 'True' or 'False' (capitalized).\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "For models governed by complex partial differential equations (PDEs), verifying the accuracy of the numerical solver is a major challenge, especially when exact solutions to the real-world problem are unknown. The Method of Manufactured Solutions (MMS) provides a rigorous and powerful framework for this code verification task. The core idea is to invent, or \"manufacture,\" a smooth analytical function, substitute it into the PDE to derive the required source term, and then confirm that your numerical code can reproduce the manufactured solution to the expected order of accuracy. This practice  focuses on the crucial first step of MMS: deriving the precise source term that makes a chosen function an exact solution to the governing PDE.",
            "id": "4105668",
            "problem": "A one-dimensional steady pipeline of constant cross-sectional area transports a dilute fuel species with mass fraction $c(x,t)$ along coordinate $x$ and time $t$. Starting from the conservation of species mass in a differential control volume, the constitutive flux for advection and diffusion is $J(x,t) = u\\,c(x,t) - D\\,\\frac{\\partial c}{\\partial x}(x,t)$, where $u$ is the constant mean axial velocity and $D$ is the constant effective axial diffusion coefficient. A linear first-order loss term models consumption or leakage as $-\\,\\kappa\\,c(x,t)$, where $\\kappa > 0$ is the rate constant. To perform code verification using the Method of Manufactured Solutions (MMS), an artificial source term $S(x,t)$ is added so that a chosen exact solution is satisfied by the governing Partial Differential Equation (PDE).\n\nUsing the above conservation and constitutive statements as the fundamental base, consider the linear advection–diffusion–reaction PDE with source,\n$$\\frac{\\partial c}{\\partial t} + u\\,\\frac{\\partial c}{\\partial x} = D\\,\\frac{\\partial^{2} c}{\\partial x^{2}} - \\kappa\\,c + S(x,t),$$\nwith positive constants $u$, $D$, and $\\kappa$. For MMS, choose the manufactured solution\n$$c(x,t) = \\exp(\\alpha t)\\,\\big(\\sin(\\beta x) + x^{2}\\big) + \\exp(\\sigma t)\\,\\cos(\\beta x),$$\nwhere $\\alpha$, $\\sigma$, and $\\beta$ are nonzero constants.\n\nDerive the explicit closed-form expression for the source term $S(x,t)$ that makes the above $c(x,t)$ an exact solution of the PDE. Express your final answer as a single analytic expression in terms of $x$, $t$, $u$, $D$, $\\kappa$, $\\alpha$, $\\sigma$, and $\\beta$. Do not include units. No numerical evaluation or rounding is required.",
            "solution": "The problem requires the derivation of an artificial source term $S(x,t)$ for a given Partial Differential Equation (PDE) such that a chosen manufactured solution $c(x,t)$ is an exact solution. This is a standard procedure in the Method of Manufactured Solutions (MMS) used for code verification.\n\nThe governing linear advection–diffusion–reaction PDE is given as:\n$$\n\\frac{\\partial c}{\\partial t} + u\\,\\frac{\\partial c}{\\partial x} = D\\,\\frac{\\partial^{2} c}{\\partial x^{2}} - \\kappa\\,c + S(x,t)\n$$\nTo find the source term $S(x,t)$, we rearrange the PDE to isolate $S(x,t)$:\n$$\nS(x,t) = \\frac{\\partial c}{\\partial t} + u\\,\\frac{\\partial c}{\\partial x} - D\\,\\frac{\\partial^{2} c}{\\partial x^{2}} + \\kappa\\,c\n$$\nThe manufactured solution is provided as:\n$$\nc(x,t) = \\exp(\\alpha t)\\,\\big(\\sin(\\beta x) + x^{2}\\big) + \\exp(\\sigma t)\\,\\cos(\\beta x)\n$$\nwhere $u$, $D$, $\\kappa$ are positive constants, and $\\alpha$, $\\sigma$, $\\beta$ are nonzero constants.\n\nThe derivation proceeds by computing the necessary partial derivatives of $c(x,t)$ and substituting them into the expression for $S(x,t)$.\n\nFirst, we calculate the partial derivative of $c(x,t)$ with respect to time $t$:\n$$\n\\frac{\\partial c}{\\partial t} = \\frac{\\partial}{\\partial t} \\left[ \\exp(\\alpha t)\\,\\big(\\sin(\\beta x) + x^{2}\\big) + \\exp(\\sigma t)\\,\\cos(\\beta x) \\right]\n$$\n$$\n\\frac{\\partial c}{\\partial t} = \\alpha \\exp(\\alpha t)\\,\\big(\\sin(\\beta x) + x^{2}\\big) + \\sigma \\exp(\\sigma t)\\,\\cos(\\beta x)\n$$\n\nNext, we calculate the first partial derivative of $c(x,t)$ with respect to the spatial coordinate $x$:\n$$\n\\frac{\\partial c}{\\partial x} = \\frac{\\partial}{\\partial x} \\left[ \\exp(\\alpha t)\\,\\big(\\sin(\\beta x) + x^{2}\\big) + \\exp(\\sigma t)\\,\\cos(\\beta x) \\right]\n$$\n$$\n\\frac{\\partial c}{\\partial x} = \\exp(\\alpha t)\\,\\big(\\beta \\cos(\\beta x) + 2x\\big) - \\beta \\exp(\\sigma t)\\,\\sin(\\beta x)\n$$\n\nThen, we calculate the second partial derivative with respect to $x$:\n$$\n\\frac{\\partial^{2} c}{\\partial x^{2}} = \\frac{\\partial}{\\partial x} \\left[ \\exp(\\alpha t)\\,\\big(\\beta \\cos(\\beta x) + 2x\\big) - \\beta \\exp(\\sigma t)\\,\\sin(\\beta x) \\right]\n$$\n$$\n\\frac{\\partial^{2} c}{\\partial x^{2}} = \\exp(\\alpha t)\\,\\big(-\\beta^{2} \\sin(\\beta x) + 2\\big) - \\beta^{2} \\exp(\\sigma t)\\,\\cos(\\beta x)\n$$\n\nNow we substitute $c(x,t)$ and its derivatives into the expression for $S(x,t)$:\n$$\nS(x,t) = \\left[ \\alpha \\exp(\\alpha t)\\big(\\sin(\\beta x) + x^{2}\\big) + \\sigma \\exp(\\sigma t)\\cos(\\beta x) \\right] + u \\left[ \\exp(\\alpha t)\\big(\\beta \\cos(\\beta x) + 2x\\big) - \\beta \\exp(\\sigma t)\\sin(\\beta x) \\right] - D \\left[ \\exp(\\alpha t)\\big(-\\beta^{2} \\sin(\\beta x) + 2\\big) - \\beta^{2} \\exp(\\sigma t)\\cos(\\beta x) \\right] + \\kappa \\left[ \\exp(\\alpha t)\\big(\\sin(\\beta x) + x^{2}\\big) + \\exp(\\sigma t)\\cos(\\beta x) \\right]\n$$\nTo obtain the final closed-form expression, we expand and collect terms based on their functional dependence on $x$ and $t$.\n\nExpanding all terms:\n$$\nS(x,t) = \\alpha \\exp(\\alpha t)\\sin(\\beta x) + \\alpha \\exp(\\alpha t)x^{2} + \\sigma \\exp(\\sigma t)\\cos(\\beta x) + u\\beta \\exp(\\alpha t)\\cos(\\beta x) + 2ux \\exp(\\alpha t) - u\\beta \\exp(\\sigma t)\\sin(\\beta x) + D\\beta^{2} \\exp(\\alpha t)\\sin(\\beta x) - 2D \\exp(\\alpha t) + D\\beta^{2} \\exp(\\sigma t)\\cos(\\beta x) + \\kappa \\exp(\\alpha t)\\sin(\\beta x) + \\kappa \\exp(\\alpha t)x^{2} + \\kappa \\exp(\\sigma t)\\cos(\\beta x)\n$$\nNow, we group the coefficients of the distinct functional forms: $\\sin(\\beta x)$, $\\cos(\\beta x)$, and the polynomial in $x$.\n\nFor the terms proportional to $\\sin(\\beta x)$:\n$$\n\\big(\\alpha \\exp(\\alpha t) - u\\beta \\exp(\\sigma t) + D\\beta^{2} \\exp(\\alpha t) + \\kappa \\exp(\\alpha t)\\big) \\sin(\\beta x) = \\left[ (\\alpha + \\kappa + D\\beta^{2})\\exp(\\alpha t) - u\\beta\\exp(\\sigma t) \\right] \\sin(\\beta x)\n$$\nFor the terms proportional to $\\cos(\\beta x)$:\n$$\n\\big(\\sigma \\exp(\\sigma t) + u\\beta \\exp(\\alpha t) + D\\beta^{2} \\exp(\\sigma t) + \\kappa \\exp(\\sigma t)\\big) \\cos(\\beta x) = \\left[ u\\beta\\exp(\\alpha t) + (\\sigma + \\kappa + D\\beta^{2})\\exp(\\sigma t) \\right] \\cos(\\beta x)\n$$\nFor the terms that are polynomial in $x$:\n$$\n\\alpha \\exp(\\alpha t)x^{2} + 2ux \\exp(\\alpha t) - 2D\\exp(\\alpha t) + \\kappa \\exp(\\alpha t)x^{2} = \\left[ (\\alpha+\\kappa)x^{2} + 2ux - 2D \\right] \\exp(\\alpha t)\n$$\nCombining these groups yields the final expression for the source term $S(x,t)$:\n$$\nS(x,t) = \\left[ (\\alpha + \\kappa + D\\beta^{2})\\exp(\\alpha t) - u\\beta\\exp(\\sigma t) \\right] \\sin(\\beta x) + \\left[ u\\beta\\exp(\\alpha t) + (\\sigma + \\kappa + D\\beta^{2})\\exp(\\sigma t) \\right] \\cos(\\beta x) + \\left[ (\\alpha+\\kappa)x^{2} + 2ux - 2D \\right] \\exp(\\alpha t)\n$$\nThis is the required explicit closed-form expression for the source term.",
            "answer": "$$\n\\boxed{\\left[ (\\alpha + \\kappa + D\\beta^{2})\\exp(\\alpha t) - u\\beta\\exp(\\sigma t) \\right] \\sin(\\beta x) + \\left[ u\\beta\\exp(\\alpha t) + (\\sigma + \\kappa + D\\beta^{2})\\exp(\\sigma t) \\right] \\cos(\\beta x) + \\left[ (\\alpha+\\kappa)x^{2} + 2ux - 2D \\right] \\exp(\\alpha t)}\n$$"
        },
        {
            "introduction": "After verifying that a model is \"built right,\" the next step is to understand its behavior, which forms a bridge to validation—ensuring it's the \"right model.\" Complex energy system models often contain numerous input parameters, and it is crucial to identify which ones most significantly impact the results. This exercise introduces *global sensitivity analysis* (GSA) using the Morris one-at-a-time screening method, an efficient technique for exploring the entire input space to rank parameters by their influence. Identifying these influential parameters  is vital for directing validation efforts, as it highlights which inputs demand the most accurate data and careful calibration to ensure the model's credibility.",
            "id": "4105669",
            "problem": "Consider a single-period capacity planning cost model as a scalar mapping from a set of normalized inputs to a real-valued output. Let the normalized input vector be $\\mathbf{u} \\in [0,1]^k$ with $k=4$ inputs representing growth rate $g$, per-unit capacity cost $c$, storage effectiveness $s$, and forecast bias $b$. The normalized inputs are linearly mapped to physical ranges by $x_i = a_i + u_i(b_i - a_i)$ for each component $i \\in \\{0,1,2,3\\}$, where $(a_i,b_i)$ are the lower and upper bounds of the parameter ranges. The model output is the total cost $J(\\mathbf{x})$, defined by\n$$\nD_T = D_0(1+g)^T, \\quad \\hat{D}_T = (1+b)D_T, \\quad K = \\lambda \\,\\hat{D}_T,\n$$\n$$\nJ(\\mathbf{x}) = c \\, K + P\\, (1 - s)\\, \\max\\{0, D_T - K\\} + Q\\, \\max\\{0, K - D_T\\},\n$$\nwhere $D_0$ is the base demand, $T$ is the horizon length in years, $\\lambda$ is a fixed planning safety factor, $P$ is the shortage penalty weight, and $Q$ is the overbuild penalty weight. Use the following physically plausible constants and parameter bounds:\n- $D_0 = 1000$, $T = 10$, $\\lambda = 1.05$, $P = 3000$, $Q = 500$.\n- $g \\in [0, 0.1]$, $c \\in [500, 1500]$, $s \\in [0, 1]$, $b \\in [-0.1, 0.1]$.\n\nYour task is to implement the Morris one-at-a-time (OAT) screening design to compute elementary effects for each input and identify influential parameters for model validation and verification purposes. Begin from the following fundamental base:\n- One-at-a-time sensitivity analysis defines the elementary effect for input $i$ at point $\\mathbf{u}$ as\n$$\nEE_i(\\mathbf{u}) = \\frac{J(\\mathbf{x}(\\mathbf{u} + \\Delta \\mathbf{e}_i)) - J(\\mathbf{x}(\\mathbf{u}))}{\\Delta},\n$$\nwhere $\\mathbf{e}_i$ is the $i$-th standard basis vector, $\\Delta$ is a design step on a discrete grid in $[0,1]^k$, and $\\mathbf{x}(\\cdot)$ is the affine mapping from normalized inputs to physical values.\n- The Morris screening method requires a discrete grid with $p$ levels per input, with grid step size $h = \\frac{1}{p-1}$, and a trajectory design that changes one input at a time by a fixed step $\\Delta$ chosen such that both the base point and the perturbed point lie on the grid. For even $p$, a canonical choice is\n$$\n\\Delta = \\frac{p}{2(p-1)} = \\left(\\frac{p}{2}\\right) \\cdot h,\n$$\nwhich ensures that $\\Delta$ is an integer multiple of $h$ and that trajectories can be constructed within the unit hypercube without leaving the grid.\n\nDerive the Morris trajectory construction and the computation of elementary effects from these fundamentals, including the affine mapping from normalized variables to physical ranges. Then, implement a program that:\n- Constructs $r$ random Morris trajectories for given $(k,p,\\Delta)$ with even $p$, choosing base points $\\mathbf{u}$ on the grid such that $\\mathbf{u} + \\Delta \\mathbf{e}_i \\in [0,1]^k$ for all inputs changed along the trajectory, and permuting the order of input changes uniformly at random.\n- Computes all elementary effects $\\{EE_i\\}$ across the trajectories for each input $i$ and aggregates them by their absolute mean and standard deviation:\n$$\n\\mu_i^\\star = \\text{mean}\\left( |EE_i| \\right), \\quad \\sigma_i = \\text{std}\\left(EE_i\\right).\n$$\n- Identifies influential parameters as those indices $i$ for which $\\mu_i^\\star$ exceeds the median of $\\{\\mu_j^\\star\\}_{j=0}^{k-1}$. Return the list of influential indices for each test case as $0$-based integers.\n\nDesign a test suite that exercises different facets of the design:\n- Case $1$ (happy path): $k=4$, $p=8$, $r=20$.\n- Case $2$ (coarse grid boundary): $k=4$, $p=4$, $r=15$.\n- Case $3$ (minimal replication edge case): $k=4$, $p=6$, $r=1$.\n\nAll cases use the same parameter bounds and constants given above. Use a fixed random seed to ensure reproducibility. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the list of influential parameter indices for one test case, for example, $\"[[i_1,i_2],[j_1],[k_1,k_2,k_3]]\"$, with the exact indices determined by your computations.",
            "solution": "The problem requires the implementation of the Morris one-at-a-time (OAT) screening method to perform a sensitivity analysis on a given capacity planning cost model. The goal is to identify which of the four input parameters—growth rate ($g$), per-unit capacity cost ($c$), storage effectiveness ($s$), and forecast bias ($b$)—are most influential on the total cost output $J$.\n\nFirst, we formalize the components of the problem.\n\n**1. The Cost Model**\n\nThe model takes a normalized input vector $\\mathbf{u} \\in [0,1]^4$ and maps it to a physical parameter vector $\\mathbf{x} = (g, c, s, b)$. The mapping is affine:\n$x_i = a_i + u_i(b_i - a_i)$, where $[a_i, b_i]$ are the physical bounds for the $i$-th parameter.\nThe given bounds are:\n- $g \\in [0, 0.1]$, so $a_0 = 0$, $b_0 = 0.1$.\n- $c \\in [500, 1500]$, so $a_1 = 500$, $b_1 = 1500$.\n- $s \\in [0, 1]$, so $a_2 = 0$, $b_2 = 1$.\n- $b \\in [-0.1, 0.1]$, so $a_3 = -0.1$, $b_3 = 0.1$.\n\nThe total cost $J$ is a function of these physical parameters $\\mathbf{x}$:\n$$\nJ(\\mathbf{x}) = c \\cdot K + P(1-s)\\max\\{0, D_T - K\\} + Q\\max\\{0, K - D_T\\}\n$$\nwhere the intermediate quantities are defined as:\n- Future demand: $D_T = D_0(1+g)^T$\n- Forecasted demand: $\\hat{D}_T = (1+b)D_T$\n- Planned capacity: $K = \\lambda \\hat{D}_T$\n\nThe constants are fixed: $D_0 = 1000$, $T = 10$, $\\lambda = 1.05$, $P = 3000$, and $Q = 500$.\n\n**2. The Morris Screening Method**\n\nThe Morris method is a global sensitivity analysis technique that estimates the influence of each input parameter by computing its *elementary effect* (EE) at various points in the input space. An elementary effect is a finite difference approximation of the local derivative of the model output with respect to one input.\n\nFor an input $i$, its elementary effect at a point $\\mathbf{u}$ is:\n$$\nEE_i(\\mathbf{u}) = \\frac{J(\\mathbf{x}(\\mathbf{u} + \\Delta \\mathbf{e}_i)) - J(\\mathbf{x}(\\mathbf{u}))}{\\Delta}\n$$\nHere, $\\mathbf{e}_i$ is the $i$-th standard basis vector and $\\Delta$ is a step size chosen from a discrete grid. The input space $[0,1]^k$ is discretized into a grid with $p$ levels for each dimension. The grid points for a single dimension are $\\{0, h, 2h, \\dots, 1\\}$, where the grid spacing is $h = 1/(p-1)$. For an even number of levels $p$, a canonical choice for the step size is $\\Delta = \\frac{p}{2(p-1)}$, which is an integer multiple of $h$, specifically $\\Delta = (p/2)h$.\n\nTo get a global sense of sensitivity, we compute elementary effects along randomly generated trajectories through the input space. Each trajectory yields one EE value for each of the $k$ inputs. This process is repeated for $r$ trajectories.\n\n**3. Trajectory Construction**\n\nA single Morris trajectory of length $k+1$ is constructed as follows:\n1.  **Select a random base point $\\mathbf{u}^{(0)}$**. The point must be chosen from the grid such that subsequent steps of size $\\Delta$ do not leave the unit hypercube $[0,1]^k$. With $\\Delta = \\frac{p}{2(p-1)}$, any component $u_i$ of the base point must be in the range $[0, 1-\\Delta]$. On the grid, this means $u_i$ must be chosen from the set $\\{0, h, 2h, \\dots, (p/2 - 1)h\\}$.\n2.  **Generate a random permutation of input indices**. Let this permutation be $(idx_0, idx_1, \\dots, idx_{k-1})$. This randomizes the order in which inputs are perturbed.\n3.  **Construct the path**. Starting from $\\mathbf{u}^{(0)}$, generate a sequence of $k$ points by successively perturbing one input at a time according to the permutation.\n    - The first step is from $\\mathbf{u}^{(0)}$ to $\\mathbf{u}^{(1)} = \\mathbf{u}^{(0)} + \\Delta \\mathbf{e}_{idx_0}$.\n    - The second step is from $\\mathbf{u}^{(1)}$ to $\\mathbf{u}^{(2)} = \\mathbf{u}^{(1)} + \\Delta \\mathbf{e}_{idx_1}$.\n    - In general, $\\mathbf{u}^{(j+1)} = \\mathbf{u}^{(j)} + \\Delta \\mathbf{e}_{idx_j}$.\n\nFor each step along the trajectory, from $\\mathbf{u}^{(j)}$ to $\\mathbf{u}^{(j+1)}$, we compute the elementary effect for the perturbed input $idx_j$:\n$$\nEE_{idx_j} = \\frac{J(\\mathbf{x}(\\mathbf{u}^{(j+1)})) - J(\\mathbf{x}(\\mathbf{u}^{(j)}))}{\\Delta}\n$$\nAfter one trajectory of $k$ steps is completed, we will have computed one elementary effect for each of the $k$ inputs.\n\n**4. Aggregation and Interpretation**\n\nWe repeat the trajectory generation process $r$ times. For each input $i$, this yields a sample of $r$ elementary effects, $\\{EE_i^{(1)}, EE_i^{(2)}, \\dots, EE_i^{(r)}\\}$. We then compute two key statistics for each input:\n- **Mean of absolute values, $\\mu_i^\\star$**: $\\mu_i^\\star = \\frac{1}{r} \\sum_{j=1}^{r} |EE_i^{(j)}|$. This metric estimates the overall influence of parameter $i$ on the output. A high $\\mu_i^\\star$ indicates an influential parameter.\n- **Standard deviation, $\\sigma_i$**: $\\sigma_i = \\sqrt{\\frac{1}{r} \\sum_{j=1}^{r} (EE_i^{(j)} - \\bar{EE_i})^2}$, where $\\bar{EE_i}$ is the mean of the raw EEs. This metric indicates non-linear effects or interactions with other parameters.\n\n**5. Identifying Influential Parameters**\n\nThe problem defines a simple criterion for influence: a parameter $i$ is considered influential if its $\\mu_i^\\star$ value is greater than the median of the set of all $\\mu_j^\\star$ values, $\\{\\mu_0^\\star, \\mu_1^\\star, \\dots, \\mu_{k-1}^\\star\\}$.\n\n**6. Implementation Strategy**\n\nThe implementation will follow these steps:\n1.  Define a function to compute the cost $J(\\mathbf{x}(\\mathbf{u}))$ given a normalized input vector $\\mathbf{u}$. This function will encapsulate the model equations and constants.\n2.  Define a main loop that iterates through the three test cases specified.\n3.  For each test case $(k,p,r)$:\n    a. Initialize a fixed-seed random number generator for reproducibility.\n    b. Calculate grid parameters $h$ and $\\Delta$.\n    c. For each of the $r$ trajectories:\n        i. Randomly generate a valid base point $\\mathbf{u}^{(0)}$ on the grid.\n        ii. Generate a random permutation of input indices.\n        iii. Traverse the trajectory, calculating one elementary effect for each input and storing it.\n    d. After all trajectories are run, compute $\\mu_i^\\star$ and $\\sigma_i$ for each input $i$.\n    e. Compute the median of the $\\mu^\\star$ values.\n    f. Identify the indices of influential parameters based on the specified criterion.\n    g. Store the sorted list of influential indices.\n4.  Finally, format the collected results into the required single-line string output.\n\nThis systematic approach ensures that the implementation correctly follows the principles of the Morris method as defined in the problem statement and produces a verifiable result.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Morris screening analysis for all test cases.\n    \"\"\"\n\n    # --- Problem Constants and Parameter Bounds ---\n    CONSTANTS = {\n        'D0': 1000, 'T': 10, 'LMBDA': 1.05, 'P': 3000, 'Q': 500\n    }\n    \n    # Bounds dictionary: key is index, value is (lower, upper)\n    # 0: g, 1: c, 2: s, 3: b\n    BOUNDS = {\n        0: (0.0, 0.1),\n        1: (500, 1500),\n        2: (0.0, 1.0),\n        3: (-0.1, 0.1)\n    }\n    \n    def compute_cost(u, consts, bounds):\n        \"\"\"\n        Computes the total cost J for a given normalized input vector u.\n        \n        Args:\n            u (np.ndarray): Normalized input vector of size k.\n            consts (dict): Dictionary of model constants.\n            bounds (dict): Dictionary of parameter bounds.\n            \n        Returns:\n            float: The total cost J.\n        \"\"\"\n        # Un-normalize inputs\n        x = np.zeros_like(u)\n        for i in range(len(u)):\n            a_i, b_i = bounds[i]\n            x[i] = a_i + u[i] * (b_i - a_i)\n        \n        g, c, s, b = x[0], x[1], x[2], x[3]\n        \n        # Calculate intermediate values\n        D_T = consts['D0'] * (1 + g)**consts['T']\n        hat_D_T = (1 + b) * D_T\n        K = consts['LMBDA'] * hat_D_T\n        \n        # Calculate cost components\n        investment_cost = c * K\n        shortage_cost = consts['P'] * (1 - s) * np.maximum(0, D_T - K)\n        overbuild_cost = consts['Q'] * np.maximum(0, K - D_T)\n        \n        # Total cost\n        J = investment_cost + shortage_cost + overbuild_cost\n        return J\n\n    def run_morris_case(k, p, r, rng, consts, bounds):\n        \"\"\"\n        Runs one full Morris screening test case.\n        \n        Args:\n            k (int): Number of input parameters.\n            p (int): Number of grid levels (must be even).\n            r (int): Number of trajectories.\n            rng (np.random.Generator): Random number generator for reproducibility.\n            consts (dict): Dictionary of model constants.\n            bounds (dict): Dictionary of parameter bounds.\n            \n        Returns:\n            list: A sorted list of influential parameter indices.\n        \"\"\"\n        # Calculate grid parameters\n        h = 1.0 / (p - 1)\n        delta = p / (2.0 * (p - 1))\n        \n        # Possible grid levels for base point components {0, h, ..., (p/2-1)h}\n        base_grid_levels = np.arange(p / 2)\n        \n        # Store elementary effects for each input parameter\n        all_ees = [[] for _ in range(k)]\n        \n        for _ in range(r):\n            # 1. Generate a random base point u_base\n            # Choose a random level index for each dimension\n            base_indices = rng.choice(base_grid_levels, size=k).astype(int)\n            u_base = base_indices * h\n            \n            # 2. Generate a random permutation of input indices\n            permutation = rng.permutation(k)\n            \n            # 3. Walk the trajectory\n            u_current = u_base.copy()\n            J_current = compute_cost(u_current, consts, bounds)\n            \n            for idx in permutation:\n                u_next = u_current.copy()\n                u_next[idx] += delta\n                \n                J_next = compute_cost(u_next, consts, bounds)\n                \n                ee = (J_next - J_current) / delta\n                all_ees[idx].append(ee)\n                \n                # Update for next step in trajectory\n                u_current = u_next\n                J_current = J_next\n                \n        # 4. Aggregate results\n        mu_star = np.array([np.mean(np.abs(ees)) for ees in all_ees])\n        \n        # Required to compute sigma, even if not used for filtering\n        # The problem asks to compute it.\n        # Handle r=1 case where std is 0.\n        sigmas = np.array([np.std(ees) if len(ees) > 1 else 0.0 for ees in all_ees])\n        \n        # 5. Identify influential parameters\n        median_mu_star = np.median(mu_star)\n        influential_indices = sorted([i for i, mu in enumerate(mu_star) if mu > median_mu_star])\n        \n        return influential_indices\n\n    # Define test cases from the problem statement\n    test_cases = [\n        (4, 8, 20),  # Case 1 (happy path)\n        (4, 4, 15),  # Case 2 (coarse grid boundary)\n        (4, 6, 1),   # Case 3 (minimal replication edge case)\n    ]\n\n    # Use a fixed random seed for reproducibility\n    rng = np.random.default_rng(seed=42)\n\n    results = []\n    for k, p, r in test_cases:\n        case_result = run_morris_case(k, p, r, rng, CONSTANTS, BOUNDS)\n        results.append(case_result)\n\n    # Final print statement in the exact required format\n    # The default str() of a list is '[...]', which is what we need.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}