{
    "hands_on_practices": [
        {
            "introduction": "负载特性的一个基本任务是量化其可变性。本练习将探讨一个基础模型：一个具有随机占空比的开关型负载。通过从第一性原理出发，您将推导出负载平均功率的变异系数（$CV$）与其占空比的统计特性之间的直接关系，从而揭示用户行为的随机性如何转化为电网可观测到的功率波动。",
            "id": "4101854",
            "problem": "一个电器被建模为一个开关负载，其开启状态下的恒定有功功率为 $P_{\\text{on}} \\gt 0$。令 $I(t) \\in \\{0,1\\}$ 表示其在时间 $t$ 的状态指示器，其中当设备开启时 $I(t) = 1$，否则 $I(t) = 0$。瞬时有功功率为 $p(t) = P_{\\text{on}} I(t)$。考虑一个持续时间为 $T$ 的观测窗口，该时间 $T$ 相对于设备的内部切换时间尺度而言很大，并将窗口平均功率定义为 $\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$。将此窗口内的占空比定义为 $D_T = \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt$。由于慢速的外源性变化（例如，用户行为或环境条件），占空比 $D_T$ 在不同窗口间是一个支撑集为 $[0,1]$ 的随机变量 $D$，其均值为 $\\mu_D = \\mathbb{E}[D] \\in (0,1]$，方差为 $\\sigma_D^2 = \\operatorname{Var}(D) \\ge 0$。假设 $T$ 足够大，以至于窗口内由快速切换引起的变化与由 $D$ 捕获的慢速变化相比可以忽略不计。\n\n仅使用窗口平均、期望、方差和变异系数（对于随机变量 $X$ 定义为 $CV = \\sigma_X / \\mu_X$）的定义，推导随机窗口平均功率 $\\overline{P}_T$ 的变异系数的闭式表达式，用 $P_{\\text{on}}$、$\\mu_D$ 和 $\\sigma_D$ 表示。你的最终答案必须是单一的解析表达式。将最终结果表示为一个纯数（无量纲）。无需四舍五入。",
            "solution": "首先对问题进行验证检查。\n\n### 步骤 1：提取已知条件\n- 一个电器被建模为一个开关负载。\n- 恒定开启状态有功功率：$P_{\\text{on}} > 0$。\n- 时间 $t$ 的状态指示器：$I(t) \\in \\{0,1\\}$，其中 $I(t) = 1$ 表示“开启”，$I(t) = 0$ 表示“关闭”。\n- 瞬时有功功率：$p(t) = P_{\\text{on}} I(t)$。\n- 观测窗口持续时间：$T$。\n- $T$ 相对于设备的内部切换时间尺度而言很大。\n- 窗口平均功率：$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$。\n- 此窗口内的占空比：$D_T = \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt$。\n- $D_T$ 在不同窗口间被视为一个随机变量 $D$。\n- $D$ 的支撑集是 $[0,1]$。\n- $D$ 的均值：$\\mu_D = \\mathbb{E}[D] \\in (0,1]$。\n- $D$ 的方差：$\\sigma_D^2 = \\operatorname{Var}(D) \\ge 0$。\n- 假设 $T$ 足够大，使得窗口内的变化与 $D$ 的慢速变化相比可以忽略不计。\n- 随机变量 $X$ 的变异系数定义为 $CV_X = \\sigma_X / \\mu_X$。\n- 目标是推导随机窗口平均功率 $CV_{\\overline{P}_T}$ 的变异系数的闭式表达式，用 $P_{\\text{on}}$、$\\mu_D$ 和 $\\sigma_D$ 表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据。将间歇性负载建模为具有占空比的模型，是电气工程和能源系统分析中一个标准且基础的抽象方法。将占空比视为随机变量以解释较慢的变化条件（例如用户行为）是一种有效且常见的建模技术。该问题是适定的，提供了推导所需量所需的所有必要定义（平均功率、占空比、均值、方差、变异系数）和参数。语言客观且数学上精确。问题是自洽的、一致的，并且不违反任何物理或数学原理。这是一个与负载特性直接相关的可形式化问题。\n\n### 步骤 3：结论与行动\n问题被认为是有效的。将提供完整解答。\n\n目标是求出窗口平均功率 $\\overline{P}_T$ 的变异系数。该量记为 $CV_{\\overline{P}_T}$，定义为其标准差与其均值的比率：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_{\\overline{P}_T}}{\\mu_{\\overline{P}_T}}$$\n我们必须首先求出随机变量 $\\overline{P}_T$ 的均值 $\\mu_{\\overline{P}_T} = \\mathbb{E}[\\overline{P}_T]$ 和标准差 $\\sigma_{\\overline{P}_T} = \\sqrt{\\operatorname{Var}(\\overline{P}_T)}$。\n\n首先，我们建立窗口平均功率 $\\overline{P}_T$ 和占空比 $D_T$ 之间的直接关系。根据定义，\n$$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$$\n代入瞬时功率的表达式 $p(t) = P_{\\text{on}} I(t)$，我们得到：\n$$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} P_{\\text{on}} I(t) \\, dt$$\n由于 $P_{\\text{on}}$ 是一个常数，可以将其从积分中提出：\n$$\\overline{P}_T = P_{\\text{on}} \\left( \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt \\right)$$\n括号中的项是占空比 $D_T$ 的定义。因此，窗口平均功率与该窗口的占空比成正比：\n$$\\overline{P}_T = P_{\\text{on}} D_T$$\n问题陈述，由于慢速变化，当在多个窗口上观察时，占空比 $D_T$ 被视为一个随机变量 $D$。因此，$\\overline{P}_T$ 也是一个随机变量，通过线性变换 $\\overline{P}_T = P_{\\text{on}} D$ 与 $D$ 相关。现在我们可以使用 $D$ 的已知性质来计算 $\\overline{P}_T$ 的统计特性。\n\n接下来，我们计算 $\\overline{P}_T$ 的均值。$\\overline{P}_T$ 的均值或期望为：\n$$\\mu_{\\overline{P}_T} = \\mathbb{E}[\\overline{P}_T] = \\mathbb{E}[P_{\\text{on}} D]$$\n利用期望算子的线性性质，常数 $P_{\\text{on}}$ 可以被提出：\n$$\\mu_{\\overline{P}_T} = P_{\\text{on}} \\mathbb{E}[D]$$\n问题给出 $\\mathbb{E}[D] = \\mu_D$。因此，窗口平均功率的均值为：\n$$\\mu_{\\overline{P}_T} = P_{\\text{on}} \\mu_D$$\n由于 $P_{\\text{on}} > 0$ 且 $\\mu_D \\in (0,1]$，平均功率 $\\mu_{\\overline{P}_T}$ 严格为正。\n\n现在，我们计算 $\\overline{P}_T$ 的方差。方差定义为 $\\sigma_{\\overline{P}_T}^2 = \\operatorname{Var}(\\overline{P}_T)$。\n$$\\sigma_{\\overline{P}_T}^2 = \\operatorname{Var}(\\overline{P}_T) = \\operatorname{Var}(P_{\\text{on}} D)$$\n使用方差的性质 $\\operatorname{Var}(aX) = a^2 \\operatorname{Var}(X)$（其中 $a$ 是常数，$X$ 是随机变量），我们有：\n$$\\sigma_{\\overline{P}_T}^2 = (P_{\\text{on}})^2 \\operatorname{Var}(D)$$\n问题给出 $\\operatorname{Var}(D) = \\sigma_D^2$。因此，窗口平均功率的方差为：\n$$\\sigma_{\\overline{P}_T}^2 = P_{\\text{on}}^2 \\sigma_D^2$$\n标准差 $\\sigma_{\\overline{P}_T}$ 是方差的平方根。由于标准差是非负的且 $P_{\\text{on}} > 0$，我们有：\n$$\\sigma_{\\overline{P}_T} = \\sqrt{P_{\\text{on}}^2 \\sigma_D^2} = |P_{\\text{on}}| |\\sigma_D| = P_{\\text{on}} \\sigma_D$$\n\n最后，我们可以通过将均值和标准差的表达式代入其定义来计算 $\\overline{P}_T$ 的变异系数：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_{\\overline{P}_T}}{\\mu_{\\overline{P}_T}} = \\frac{P_{\\text{on}} \\sigma_D}{P_{\\text{on}} \\mu_D}$$\n常数项 $P_{\\text{on}}$ 同时出现在分子和分母中。由于 $P_{\\text{on}} > 0$，我们可以消去它：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_D}{\\mu_D}$$\n此表达式仅根据占空比的统计特性 $\\mu_D$ 和 $\\sigma_D$ 给出了窗口平均功率的变异系数。结果与开启状态的功率水平 $P_{\\text{on}}$ 无关。这表明平均功率的相对变异性与占空比本身的相对变异性相同。结果是无量纲的，因为 $\\sigma_D$ 和 $\\mu_D$ 都是无量纲的量。",
            "answer": "$$\\boxed{\\frac{\\sigma_D}{\\mu_D}}$$"
        },
        {
            "introduction": "选择正确的度量指标对于准确评估设备压力至关重要，而简单的平均值往往具有误导性。本练习以工业变频器（VSD）为例，阐明了为何基于平均功率的利用率因子不足以评估其热应力。您将通过分析发现，对于与电流平方成正比的传导损耗，基于功率均方根（RMS）的指标能更真实地反映负载的严酷程度，这对于设备选型和可靠性分析至关重要。",
            "id": "4101853",
            "problem": "一台工业变频器 (VSD) 从一个强电网为一台三相电机供电，该电网在其工作范围内具有近似恒定的线电压和接近于1的功率因数。考虑两个为时一小时的工作周期，它们向被驱动的工艺过程提供相同的净能量。VSD 和上游导体的热限制主要来自于与电流平方成正比的传导相关损耗。假设在工作范围内，输入电流约与输入电功率成正比，因此内部焦耳热和传导损耗与输入功率平方的时间积分成正比。同时假设限制性元件的热时间常数远大于周期时长，因此累计损耗能量是相关的严重性度量。\n\n设 VSD 的额定输入功率为 $P_{\\text{rated}} = 10\\,\\text{kW}$。定义两个时长为 $T = 1\\,\\text{h}$ 的工作周期：\n\n- 方案 A：在所有 $t \\in [0,T]$ 时间内，输入功率恒为 $P(t) = 5\\,\\text{kW}$。\n- 方案 B：方波输入功率，当 $t \\in [0,0.5T)$ 时 $P(t) = 10\\,\\text{kW}$，当 $t \\in [0.5T,T]$ 时 $P(t) = 0\\,\\text{kW}$。\n\n两种方案都提供相同的净能量 $\\int_{0}^{T} P(t)\\,dt$。\n\n一个常用的利用率因子定义为平均输入功率与额定输入功率之比。在实践中，该因子常用于对工作负荷严重性进行分类。请您评估在上述变速运行的假设下，此因子是否能恰当地反映热严重性，如果不能，请评估一个修正的严重性度量，该度量能根据假设的损耗机制对功率峰值进行惩罚。\n\n以下哪个陈述是正确的？\n\nA. 因为两种方案具有相同的平均输入功率，所以利用率因子正确地推断出，对于这两种方案，按平方比例变化的热严重性是相同的。\n\nB. 一个与假设的损耗机制一致、并通过能量吞吐量和额定功率进行归一化的无量纲修正严重性度量，对于这两种方案，得出的值为 $M_{\\text{A}} = 0.5$ 和 $M_{\\text{B}} = 1.0$，从而将方案 B 排为更严重。\n\nC. 在所述假设下，周期内累计的传导相关热损耗与 $\\int_{0}^{T} P(t)\\,dt$ 成正比，因此两种方案在热学上是等效的。\n\nD. 如果输入功率波形 $P(t)$ 乘以一个恒定振幅因子 $c>0$，而 $P_{\\text{rated}}$ 保持不变，则修正的严重性度量保持不变。\n\nE. 陈述 B 中的修正严重性度量可以等效地写为比率 $\\dfrac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}}$，其中 $P_{\\text{RMS}}^{2} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P^{2}(t)\\,dt$ 且 $P_{\\text{avg}} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P(t)\\,dt$。",
            "solution": "首先根据指定标准对问题陈述进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n*   **系统**：一台工业变频器 (VSD) 从一个强电网为一台三相电机供电。\n*   **电网条件**：近似恒定的线电压。\n*   **功率因数**：在工作范围内接近于1。\n*   **热限制**：主要由传导相关损耗引起。\n*   **损耗比例假设**：损耗与电流的平方 ($I^2$) 成正比。\n*   **电流-功率假设**：输入电流约与输入电功率成正比，$I \\propto P(t)$。\n*   **由此产生的损耗比例**：内部焦耳热和传导损耗与输入功率平方的时间积分成正比。这意味着累计损耗能量 $E_{\\text{loss}}$ 与 $\\int_{0}^{T} P^{2}(t)\\,dt$ 成正比。\n*   **热时间常数假设**：限制性元件的热时间常数远大于周期时长。\n*   **严重性度量**：累计损耗能量是相关的严重性度量。\n*   **额定功率**：$P_{\\text{rated}} = 10\\,\\text{kW}$。\n*   **周期时长**：$T = 1\\,\\text{h}$。\n*   **方案 A**：在所有 $t \\in [0,T]$ 时间内，输入功率恒为 $P(t) = 5\\,\\text{kW}$。\n*   **方案 B**：方波输入功率，当 $t \\in [0,0.5T)$ 时 $P(t) = 10\\,\\text{kW}$，当 $t \\in [0.5T,T]$ 时 $P(t) = 0\\,\\text{kW}$。\n*   **能量等效**：两种方案都提供相同的净能量 $\\int_{0}^{T} P(t)\\,dt$。\n*   **定义**：利用率因子定义为平均输入功率与额定输入功率之比。\n\n**步骤2：使用提取的已知条件进行验证**\n\n1.  **科学依据**：该问题在电气工程和电气设备热分析的原理方面有扎实的基础。传导损耗（$I^2R$ 损耗）占主导地位的假设是合理的。当电压 $V_{LL}$ 和功率因数 $\\cos(\\phi)$ 假定为常数时，$I \\propto P(t)$ 的假设可以从功率方程 $P = \\sqrt{3} V_{LL} I \\cos(\\phi)$ 得出，这在问题中已明确说明（强电网，接近于1的功率因数）。损耗能量与 $\\int P^2(t)\\,dt$ 成比例的结论是基于这些前提的直接且合乎逻辑的推论。长热时间常数的假设是将工作周期分析简化为基于能量的方法的标准做法。\n\n2.  **适定性**：该问题是适定的。所有必要的数据和定义都已提供，足以进行所需的计算并评估各个陈述。问题具体且可回答。\n\n3.  **客观性**：问题以客观的技术语言陈述，没有主观或有偏见的措辞。\n\n4.  **完整性和一致性**：问题设置既完整又内部一致。两种方案提供相同净能量的说法可以验证：\n    *   方案 A 的能量：$E_A = \\int_{0}^{T} (5\\,\\text{kW})\\,dt = (5\\,\\text{kW}) \\cdot T$。\n    *   方案 B 的能量：$E_B = \\int_{0}^{0.5T} (10\\,\\text{kW})\\,dt + \\int_{0.5T}^{T} (0\\,\\text{kW})\\,dt = (10\\,\\text{kW}) \\cdot (0.5T) = (5\\,\\text{kW}) \\cdot T$。\n    *   能量确实相等，证实了陈述的一致性。\n\n**步骤3：结论与行动**\n\n问题陈述是有效的。它在科学上是合理的、自洽的、适定的，并且基于合理且明确陈述的物理假设。可以进行求解过程。\n\n### 解题推导\n\n问题的核心是比较两个工作周期的热严重性。根据问题陈述，热严重性由累计损耗能量决定，该能量与输入功率平方的时间积分成正比。设比例常数为 $k$。\n$$E_{\\text{loss}} = k \\int_{0}^{T} P(t)^2 \\,dt$$\n为了比较不同方案的严重性，我们需要为每个方案计算这个积分。使用均方根 (RMS) 功率进行计算很方便，因为其平方与损耗能量产生的平均速率成正比。\n平均功率为 $P_{\\text{avg}} = \\frac{1}{T}\\int_{0}^{T} P(t)\\,dt$。\n均方功率为 $P_{\\text{RMS}}^2 = \\frac{1}{T}\\int_{0}^{T} P^2(t)\\,dt$。\n因此，总损耗能量为 $E_{\\text{loss}} = k \\cdot T \\cdot P_{\\text{RMS}}^2$。对于固定的时长 $T$，热严重性与 $P_{\\text{RMS}}^2$ 成正比。\n\n**方案 A 的计算：**\n功率是恒定的，$P_A(t) = 5\\,\\text{kW}$。\n平均功率为：\n$$P_{A, \\text{avg}} = \\frac{1}{T} \\int_{0}^{T} 5 \\,dt = 5\\,\\text{kW}$$\n均方功率为：\n$$P_{A, \\text{RMS}}^2 = \\frac{1}{T} \\int_{0}^{T} (5)^2 \\,dt = \\frac{1}{T} \\int_{0}^{T} 25 \\,dt = 25\\,(\\text{kW})^2$$\n\n**方案 B 的计算：**\n功率是方波，$P_B(t) = 10\\,\\text{kW}$ 对于 $t \\in [0, 0.5T)$ 且 $P_B(t) = 0\\,\\text{kW}$ 对于 $t \\in [0.5T, T]$。\n平均功率为：\n$$P_{B, \\text{avg}} = \\frac{1}{T} \\left( \\int_{0}^{0.5T} 10 \\,dt + \\int_{0.5T}^{T} 0 \\,dt \\right) = \\frac{1}{T} (10 \\cdot 0.5T) = 5\\,\\text{kW}$$\n均方功率为：\n$$P_{B, \\text{RMS}}^2 = \\frac{1}{T} \\left( \\int_{0}^{0.5T} (10)^2 \\,dt + \\int_{0.5T}^{T} (0)^2 \\,dt \\right) = \\frac{1}{T} (100 \\cdot 0.5T) = 50\\,(\\text{kW})^2$$\n\n**热严重性比较：**\n热严重性与 $P_{\\text{RMS}}^2$ 成正比。\n对于方案 A，严重性与 $25\\,(\\text{kW})^2$ 成正比。\n对于方案 B，严重性与 $50\\,(\\text{kW})^2$ 成正比。\n尽管平均功率相同，方案 B 的热严重性是方案 A 的两倍。\n\n### 逐项分析\n\n**A. 因为两种方案具有相同的平均输入功率，所以利用率因子正确地推断出，对于这两种方案，按平方比例变化的热严重性是相同的。**\n两种方案的平均功率都是 $P_{\\text{avg}} = 5\\,\\text{kW}$。额定功率是 $P_{\\text{rated}} = 10\\,\\text{kW}$。两者的利用率因子都是 $\\frac{5\\,\\text{kW}}{10\\,\\text{kW}} = 0.5$。如果这个因子是衡量热严重性的正确标准，那么它将意味着两种方案的严重性是相同的。然而，我们的分析表明，热严重性（与 $P_{\\text{RMS}}^2$ 成正比）对于方案 A 是 $25\\,(\\text{kW})^2$，对于方案 B 是 $50\\,(\\text{kW})^2$。严重性并不同。因此，基于平均功率的利用率因子对于这种损耗机制是一个不正确的度量。\n结论：错误。\n\n**B. 一个与假设的损耗机制一致、并通过能量吞吐量和额定功率进行归一化的无量纲修正严重性度量，对于这两种方案，得出的值为 $M_{\\text{A}} = 0.5$ 和 $M_{\\text{B}} = 1.0$，从而将方案 B 排为更严重。**\n与损耗机制一致的度量必须与总损耗能量 $\\int_{0}^{T} P(t)^2\\,dt$ 成正比。能量吞吐量为 $E_{\\text{net}} = \\int_{0}^{T} P(t)\\,dt$。通过能量吞吐量和额定功率进行归一化，建议使用以下形式的度量：\n$$M = \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}}$$\n让我们为两种方案计算这个值。我们知道对于两种方案，$P_{\\text{rated}} = 10\\,\\text{kW}$ 且 $\\int_{0}^{T} P(t)\\,dt = (5\\,\\text{kW}) \\cdot T$。\n对于方案 A：\n$$M_A = \\frac{\\int_{0}^{T} (5)^2\\,dt}{(5T) \\cdot 10} = \\frac{25T}{50T} = 0.5$$\n对于方案 B：\n$$M_B = \\frac{\\int_{0}^{0.5T} (10)^2\\,dt}{(5T) \\cdot 10} = \\frac{100 \\cdot (0.5T)}{50T} = \\frac{50T}{50T} = 1.0$$\n计算出的值 $M_A = 0.5$ 和 $M_B = 1.0$ 与陈述相符。这个度量正确地将方案 B ($M_B=1.0$) 排为比方案 A ($M_A=0.5$) 更严重。\n结论：正确。\n\n**C. 在所述假设下，周期内累计的传导相关热损耗与 $\\int_{0}^{T} P(t)\\,dt$ 成正比，因此两种方案在热学上是等效的。**\n这个陈述与问题的基本前提直接矛盾。问题明确指出损耗与电流的平方成正比，而电流与功率成正比。因此，累计损耗与 $\\int_{0}^{T} P(t)^2\\,dt$ 成正比，而不是与 $\\int_{0}^{T} P(t)\\,dt$ 成正比。由于两种方案的 $P(t)$ 积分相同，但 $P(t)^2$ 的积分不同，所以热等效的结论是错误的。\n结论：错误。\n\n**D. 如果输入功率波形 $P(t)$ 乘以一个恒定振幅因子 $c>0$，而 $P_{\\text{rated}}$ 保持不变，则修正的严重性度量保持不变。**\n设新波形为 $P'(t) = c \\cdot P(t)$。选项 B 中的修正度量为 $M = \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}}$。让我们为波形 $P'(t)$ 计算新的度量 $M'$：\n$$M' = \\frac{\\int_{0}^{T} (P'(t))^2\\,dt}{(\\int_{0}^{T} P'(t)\\,dt) \\cdot P_{\\text{rated}}} = \\frac{\\int_{0}^{T} (c \\cdot P(t))^2\\,dt}{(\\int_{0}^{T} c \\cdot P(t)\\,dt) \\cdot P_{\\text{rated}}}$$\n$$M' = \\frac{c^2 \\int_{0}^{T} P(t)^2\\,dt}{c \\int_{0}^{T} P(t)\\,dt \\cdot P_{\\text{rated}}} = c \\left( \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}} \\right) = c \\cdot M$$\n度量 $M'$ 等于 $c \\cdot M$，而不是 $M$。因此，该度量不是不变的；它与因子 $c$ 呈线性关系。\n结论：错误。\n\n**E. 陈述 B 中的修正严重性度量可以等效地写为比率 $\\dfrac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}}$，其中 $P_{\\text{RMS}}^{2} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P^{2}(t)\\,dt$ 且 $P_{\\text{avg}} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P(t)\\,dt$。**\n让我们将 $P_{\\text{RMS}}^2$ 和 $P_{\\text{avg}}$ 的定义代入给定的比率中：\n$$\\frac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}} = \\frac{\\frac{1}{T}\\int_{0}^{T} P(t)^2\\,dt}{P_{\\text{rated}} \\cdot \\left(\\frac{1}{T}\\int_{0}^{T} P(t)\\,dt\\right)}$$\n分子和分母中的因子 $\\frac{1}{T}$ 相互抵消，剩下：\n$$\\frac{\\int_{0}^{T} P(t)^2\\,dt}{P_{\\text{rated}} \\cdot \\int_{0}^{T} P(t)\\,dt}$$\n这个表达式与我们在分析选项 B 时为修正严重性度量 $M$ 所构建的表达式相同。因此，该陈述是对该度量的正确代数重构。\n结论：正确。",
            "answer": "$$\\boxed{BE}$$"
        },
        {
            "introduction": "随着智能电表数据的普及，我们正从分析单个负载转向对大规模用户群体进行分类。本练习将引导您进入数据驱动的负载特性分析领域，通过从零开始实现 $k$-means 聚类算法，对日负荷曲线进行无监督分类。您还将学习如何使用轮廓系数（silhouette score）这一关键指标来确定最佳的聚类数量，从而以数据驱动的方式自动发现并区分不同的用电行为模式。",
            "id": "4101893",
            "problem": "考虑一组每日电力负荷曲线，表示为一天内每小时的平均功率测量值。设每条曲线为一个向量 $x \\in \\mathbb{R}^{24}$，其分量为非负值，单位为千瓦。为关注负荷周期的形状而非绝对大小，每条曲线都通过日总能量归一化进行转换：对于给定的 $x$，定义 $y = x / \\left(\\sum_{t=1}^{24} x_t\\right)$；归一化后的曲线 $y \\in \\mathbb{R}^{24}$ 满足 $\\sum_{t=1}^{24} y_t = 1$，并编码了日能量在各小时的相对分布。\n\n任务是，从基本原理出发，推导并实现使用 $k$-均值（$k$-means）方法对这些归一化曲线进行聚类，然后使用轮廓分数确定聚类数量 $k$，以捕捉不同的负荷周期类别。使用以下基本依据：\n\n- 在 $\\mathbb{R}^{T}$ (其中 $T=24$) 中欧几里得距离的定义，对于两个向量 $u,v \\in \\mathbb{R}^{24}$，其平方距离为 $\\|u - v\\|_2^2 = \\sum_{t=1}^{24} (u_t - v_t)^2$。\n- $k$-均值聚类目标，定义为最小化数据点与其分配的簇中心之间的簇内平方欧氏距离之和。\n- 对于给定的聚类，每个数据点 $i$ 的轮廓分数定义为 $s(i) = \\dfrac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}$，其中 $a(i)$ 是点 $i$ 到其所在簇中其他点的平均距离，而 $b(i)$ 是点 $i$ 到其他簇中各点的平均距离的最小值。总轮廓分数是所有点 $s(i)$ 的平均值。\n\n您必须：\n- 从上述基本依据和定义出发，基于最小化簇内平方欧氏距离，推导 $k$-均值的中心更新规则和分配规则。\n- 基于簇内和最近的其他簇的平均距离，从基本原理推导轮廓分数公式。\n- 从零开始实现 $k$-均值算法（不使用外部聚类库），并对归一化曲线 $y$ 进行操作。\n- 为选择 $k$，评估候选 $k$ 值的平均轮廓分数，并选择使该分数最大化的 $k$。如果不同 $k$ 值的平均轮廓分数相同，则选择其中最小的 $k$。\n\n设计程序处理以下测试套件，每个测试用例指定一个合成数据集和一组候选 $k$ 值。所有随机生成过程必须按照指定设置种子，以确保可复现性。\n\n测试用例 1（理想情况，三个不同的负荷周期类别）：\n- 小时数 $T = 24$。\n- 曲线数量 $N = 90$。\n- 使用小时索引 $t \\in \\{1,\\dots,24\\}$ 在 $\\mathbb{R}^{24}$ 中构建三个原型归一化形状：\n  - 连续基载：对所有 $t$，$p^{(1)}_t = 1$。\n  - 日间高峰：$p^{(2)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-13)^2}{2\\cdot 3^2}\\right)$。\n  - 夜间高峰：$p^{(3)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-20)^2}{2\\cdot 2^2}\\right)$。\n- 通过添加独立的、$\\sigma = 0.05$ 的高斯噪声 $n_t \\sim \\mathcal{N}(0, \\sigma^2)$，从每个原型生成 $30$ 条曲线，然后使用一个小的下限值 $\\epsilon = 10^{-6}$ 将结果裁剪为非负值，最后归一化使其总和为1，即 $y = x / \\left(\\sum_{t=1}^{24} x_t\\right)$。\n- 归一化前的随机幅度缩放：对每个样本，将 $p^{(j)}$ 乘以一个从 $[0.8, 1.2]$ 上的均匀分布中抽取的因子 $\\alpha$。\n- 此测试用例的随机种子：$\\text{seed} = 42$。\n- 候选 $k$ 值：$\\{2,3,4,5\\}$。\n\n测试用例 2（两个类别部分重叠，测试轮廓分数避免过度分割的能力）：\n- 小时数 $T = 24$。\n- 曲线数量 $N = 80$。\n- 构建两个原型归一化形状：\n  - 早间高峰：$p^{(4)}_t = 0.25 + \\exp\\left(-\\dfrac{(t-8)^2}{2\\cdot 3^2}\\right)$。\n  - 午间高峰：$p^{(5)}_t = 0.25 + \\exp\\left(-\\dfrac{(t-13)^2}{2\\cdot 4^2}\\right)$。\n- 通过添加 $\\sigma = 0.08$ 的高斯噪声，从每个原型生成 $40$ 条曲线，使用 $\\epsilon = 10^{-6}$ 将结果裁剪为非负值，并归一化使其总和为1。\n- 归一化前的随机幅度缩放：$\\alpha \\sim \\text{Uniform}[0.85, 1.15]$。\n- 此测试用例的随机种子：$\\text{seed} = 123$。\n- 候选 $k$ 值：$\\{2,3,4,5\\}$。\n\n测试用例 3（边界条件，使用非常小的数据集）：\n- 小时数 $T = 24$。\n- 曲线数量 $N = 4$。\n- 构建两个原型归一化形状：\n  - 夜间重载：$p^{(6)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-19)^2}{2\\cdot 2^2}\\right)$。\n  - 平坦基线：对所有 $t$，$p^{(7)}_t = 1$。\n- 通过添加 $\\sigma = 0.02$ 的高斯噪声，从每个原型生成 $2$ 条曲线，使用 $\\epsilon = 10^{-6}$ 将结果裁剪为非负值，并归一化使其总和为1。\n- 归一化前的随机幅度缩放：$\\alpha \\sim \\text{Uniform}[0.9, 1.1]$。\n- 此测试用例的随机种子：$\\text{seed} = 999$。\n- 候选 $k$ 值：$\\{2,3,4\\}$。\n\n算法要求：\n- 实现 $k$-均值算法，通过选择 $k$ 个不同的数据点作为初始中心进行随机初始化。迭代执行分配和中心更新步骤，直到收敛。收敛的定义是：分配结果不再变化，或最大中心位移小于容差 $\\tau = 10^{-6}$，或达到最大迭代次数 $I_{\\max} = 300$。\n- 为减轻对初始化的敏感性，执行 $R = 10$ 次随机重启，并选择使簇内平方距离之和最小的那次运行结果。通过将空簇的中心重新初始化为一个随机选择的数据点来处理空簇问题。\n- 在归一化曲线上使用欧几里得距离计算轮廓分数。对于只包含一个成员的簇（单一成员簇），在计算轮廓公式时，为其成员定义 $a(i) = 0$。\n\n输出规范：\n- 对于每个测试用例，从其候选集中选择使平均轮廓分数最大化的 $k$。如果在数值容差 $\\delta = 10^{-9}$ 内，多个 $k$ 值达到相同的最大平均轮廓分数，则选择其中最小的 $k$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $[k_1,k_2,k_3]$，其中 $k_j$ 是为测试用例 $j$ 选择的聚类数量。",
            "solution": "该问题是有效的，因为它在科学上基于聚类分析的原理，在数学上是适定的，并提供了一套完整且一致的定义、算法和测试用例。这是能源系统建模标准领域中的一个客观且可验证的任务。\n\n### $k$-均值算法的推导\n\n$k$-均值算法旨在将一组 $N$ 个数据点 $\\{y_1, y_2, \\dots, y_N\\}$（其中每个 $y_i \\in \\mathbb{R}^{T}$）划分成 $k$ 个不相交的簇 $\\{C_1, C_2, \\dots, C_k\\}$。其目标是最小化簇内平方和（Within-Cluster Sum of Squares, WCSS），也称为惯量。目标函数 $J$ 定义为每个数据点与其所属簇的中心之间的平方欧氏距离之和。\n\n设 $\\mu_j$ 为簇 $C_j$ 的中心。目标函数为：\n$$\nJ = \\sum_{j=1}^{k} \\sum_{y_i \\in C_j} \\|y_i - \\mu_j\\|_2^2\n$$\n其中 $\\|y_i - \\mu_j\\|_2^2 = \\sum_{t=1}^{T} (y_{it} - \\mu_{jt})^2$ 是平方欧氏距离。\n\n对于簇分配（集合 $C_j$）和簇中心（向量 $\\mu_j$）同时最小化 $J$ 是一个计算上的难题。$k$-均值算法采用迭代坐标下降法，交替地固定一组变量，同时优化另一组变量。该过程包括两个步骤：分配步骤和更新步骤。\n\n**1. 分配步骤（E-step）：**\n在此步骤中，我们假设簇中心 $\\{\\mu_1, \\dots, \\mu_k\\}$是固定的。我们的目标是通过将每个数据点 $y_i$ 分配到一个簇来最小化 $J$。由于 $J$ 是所有簇的总和，且每个点只属于一个簇，我们可以通过独立最小化每个点的贡献来最小化 $J$。对于单个点 $y_i$，它对 $J$ 的贡献是 $\\|y_i - \\mu_j\\|_2^2$，其中 $j$ 是 $y_i$ 被分配到的簇的索引。为最小化此项，我们必须将 $y_i$ 分配给具有最近中心的簇。这给出了分配规则：\n$$\ny_i \\in C_j \\iff \\|y_i - \\mu_j\\|_2 \\le \\|y_i - \\mu_l\\|_2 \\quad \\forall l \\in \\{1, \\dots, k\\}\n$$\n在实践中，这等同于比较平方距离，这样计算效率更高：\n$$\ny_i \\text{ 被分配到簇 } j^* = \\arg\\min_{j \\in \\{1,\\dots,k\\}} \\|y_i - \\mu_j\\|_2^2\n$$\n\n**2. 更新步骤（M-step）：**\n在此步骤中，我们假设簇分配 $\\{C_1, \\dots, C_k\\}$ 是固定的。我们的目标是通过更新簇中心 $\\{\\mu_1, \\dots, \\mu_k\\}$ 来最小化 $J$。目标函数 $J$ 是多项之和，其中每一项仅依赖于一个中心 $\\mu_j$。因此，我们可以通过独立最小化每一项来最小化 $J$：\n$$\n\\min_{\\mu_j} \\left( J_j = \\sum_{y_i \\in C_j} \\|y_i - \\mu_j\\|_2^2 \\right) \\quad \\text{对于每个 } j \\in \\{1, \\dots, k\\}\n$$\n为找到使平方距离之和 $J_j$ 最小化的向量 $\\mu_j$，我们对 $J_j$ 关于 $\\mu_j$ 求梯度并将其设为零。\n簇 $j$ 的目标是 $J_j = \\sum_{y_i \\in C_j} (y_i - \\mu_j)^T (y_i - \\mu_j)$。其梯度为：\n$$\n\\nabla_{\\mu_j} J_j = \\nabla_{\\mu_j} \\sum_{y_i \\in C_j} (y_i^T y_i - 2y_i^T \\mu_j + \\mu_j^T \\mu_j) = \\sum_{y_i \\in C_j} (-2y_i + 2\\mu_j)\n$$\n将梯度设为零以找到最小值：\n$$\n\\sum_{y_i \\in C_j} (-2y_i + 2\\mu_j) = 0 \\implies \\sum_{y_i \\in C_j} 2\\mu_j = \\sum_{y_i \\in C_j} 2y_i\n$$\n设 $|C_j|$ 为簇 $C_j$ 中的点数。则 $\\sum_{y_i \\in C_j} \\mu_j = |C_j| \\mu_j$。\n$$\n|C_j| \\mu_j = \\sum_{y_i \\in C_j} y_i \\implies \\mu_j = \\frac{1}{|C_j|} \\sum_{y_i \\in C_j} y_i\n$$\n该推导表明，一个簇的最优中心是分配给该簇的所有数据点的算术平均值（质心）。\n\n算法在这两个步骤之间迭代，直到收敛。收敛通常定义为簇分配不再改变，或簇中心的移动量可忽略不计。\n\n### 轮廓分数的推导\n\n轮廓分数是一种用于评估聚类质量的度量。它量化了每个数据点与其所在簇的匹配程度，以及与其他相邻簇的对比情况。该分数是为每个点计算，然后对所有点取平均值。\n\n对于簇 $C_j$ 中的单个数据点 $y_i$：\n\n**1. 簇内距离 $a(i)$：**\n该值衡量了点与其所在簇的内聚性。它定义为 $y_i$ 到同一簇 $C_j$ 中所有其他点的平均欧氏距离。\n$$\na(i) = \\frac{1}{|C_j| - 1} \\sum_{y_l \\in C_j, l \\ne i} \\|y_i - y_l\\|_2\n$$\n$a(i)$ 的值越小，表示该点与其簇的匹配度越好。如果簇 $C_j$ 只包含一个点（即单一成员簇，$|C_j|=1$），则求和为空，$a(i)$ 定义为 $0$。\n\n**2. 簇间距离 $b(i)$：**\n该值衡量了点与其他簇的分离度。它定义为 $y_i$ 到任何其他簇 $C_m$（其中 $m \\ne j$）中所有点的平均距离的最小值。\n首先，对于每个其他簇 $C_m$，我们计算 $y_i$ 到该簇中各点的平均距离：\n$$\nd(i, C_m) = \\frac{1}{|C_m|} \\sum_{y_l \\in C_m} \\|y_i - y_l\\|_2\n$$\n然后，$b(i)$ 是 $y_i$ 到其不属于的所有簇的这些平均距离值中的最小值。这代表了到“最近邻簇”的距离。\n$$\nb(i) = \\min_{m \\ne j} \\{ d(i, C_m) \\}\n$$\n$b(i)$ 的值越大，表示该点远离其他簇。\n\n**3. 轮廓系数 $s(i)$：**\n点 $y_i$ 的轮廓系数将 $a(i)$ 和 $b(i)$ 组合成一个归一化的分数：\n$$\ns(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n$$\n$s(i)$ 的取值范围为 $-1$ 到 $1$：\n- $s(i) \\approx 1$：表示该点聚类效果好。其簇内距离 $a(i)$ 远小于其簇间距离 $b(i)$。\n- $s(i) \\approx 0$：表示该点位于两个簇的决策边界上或附近。其距离 $a(i)$ 和 $b(i)$ 相当。\n- $s(i) \\approx -1$：表示该点可能被错误分类。其簇内距离 $a(i)$ 远大于其簇间距离 $b(i)$，表明它更接近相邻的簇，而不是其所在的簇。\n\n对于给定的 $k$，聚类的总体质量是所有 $N$ 个数据点的平均轮廓分数：\n$$\nS_k = \\frac{1}{N} \\sum_{i=1}^{N} s(i)\n$$\n最优的聚类数 $k$ 被选为使该平均分数最大化的那个值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_data(T, prototypes, n_per_proto, noise_sigma, amp_range, seed):\n    \"\"\"Generates synthetic load profile data for a test case.\"\"\"\n    rng = np.random.default_rng(seed)\n    data = []\n    t_coords = np.arange(1, T + 1)\n    \n    # Pre-defined prototype shapes\n    proto_defs = {\n        1: lambda t: np.ones_like(t, dtype=float),\n        2: lambda t: 0.2 + np.exp(-(t - 13)**2 / (2 * 3**2)),\n        3: lambda t: 0.2 + np.exp(-(t - 20)**2 / (2 * 2**2)),\n        4: lambda t: 0.25 + np.exp(-(t - 8)**2 / (2 * 3**2)),\n        5: lambda t: 0.25 + np.exp(-(t - 13)**2 / (2 * 4**2)),\n        6: lambda t: 0.2 + np.exp(-(t - 19)**2 / (2 * 2**2)),\n        7: lambda t: np.ones_like(t, dtype=float),\n    }\n\n    for proto_idx, n in zip(prototypes, n_per_proto):\n        p_base = proto_defs[proto_idx](t_coords)\n        for _ in range(n):\n            alpha = rng.uniform(amp_range[0], amp_range[1])\n            noise = rng.normal(0, noise_sigma, size=T)\n            \n            x = alpha * p_base + noise\n            x = np.maximum(x, 1e-6)  # Clip to be non-negative\n            \n            y = x / np.sum(x)  # Normalize to unit daily energy\n            data.append(y)\n    \n    return np.array(data)\n\ndef kmeans(data, k, n_restarts, max_iter, tol, seed):\n    \"\"\"\n    Implements k-means clustering from first principles.\n    \n    Returns the best clustering (labels, centroids, wcss) found over all restarts.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    n_samples, n_features = data.shape\n    \n    best_wcss = np.inf\n    best_labels = None\n    best_centroids = None\n    \n    restart_seeds = rng.integers(0, 2**32 - 1, size=n_restarts)\n\n    for i in range(n_restarts):\n        restart_rng = np.random.default_rng(restart_seeds[i])\n        \n        initial_indices = restart_rng.choice(n_samples, k, replace=False)\n        centroids = data[initial_indices]\n        \n        current_labels = np.full(n_samples, -1, dtype=int)\n\n        for iteration in range(max_iter):\n            # Assignment step\n            dist_sq = np.sum((data[:, np.newaxis, :] - centroids[np.newaxis, :, :])**2, axis=2)\n            new_labels = np.argmin(dist_sq, axis=1)\n\n            # Convergence check: no change in assignments\n            if np.array_equal(new_labels, current_labels):\n                break\n            \n            current_labels = new_labels\n            \n            # Update step\n            old_centroids = np.copy(centroids)\n            for c_idx in range(k):\n                cluster_points = data[current_labels == c_idx]\n                if len(cluster_points) == 0:\n                    # Handle empty cluster by re-initializing to a random point\n                    reinit_idx = restart_rng.choice(n_samples)\n                    centroids[c_idx] = data[reinit_idx]\n                else:\n                    centroids[c_idx] = cluster_points.mean(axis=0)\n\n            # Convergence check: centroid shift below tolerance\n            centroid_shifts = np.linalg.norm(centroids - old_centroids, axis=1)\n            if np.max(centroid_shifts)  tol:\n                break\n        \n        # Calculate WCSS for this run\n        wcss = 0\n        for c_idx in range(k):\n            cluster_points = data[current_labels == c_idx]\n            if len(cluster_points) > 0:\n                wcss += np.sum((cluster_points - centroids[c_idx])**2)\n        \n        if wcss  best_wcss:\n            best_wcss = wcss\n            best_labels = current_labels\n            best_centroids = centroids\n            \n    return best_labels, best_centroids, best_wcss\n\ndef calculate_silhouette_score(data, labels):\n    \"\"\"Calculates the average silhouette score for a given clustering.\"\"\"\n    n_samples = data.shape[0]\n    unique_labels = np.unique(labels)\n    n_clusters = len(unique_labels)\n    \n    if n_clusters = 1:\n        return 0.0\n    if n_clusters == n_samples:\n        return 1.0\n\n    dist_matrix = np.linalg.norm(data[:, np.newaxis, :] - data[np.newaxis, :, :], axis=2)\n    \n    s_scores = np.zeros(n_samples)\n    for i in range(n_samples):\n        my_label = labels[i]\n        \n        # Intra-cluster distance a(i)\n        in_cluster_mask = (labels == my_label)\n        in_cluster_mask[i] = False\n        n_in_cluster = np.sum(in_cluster_mask)\n        \n        if n_in_cluster == 0:\n            a_i = 0.0  # Singleton cluster\n        else:\n            in_cluster_dists = dist_matrix[i, in_cluster_mask]\n            a_i = np.mean(in_cluster_dists)\n\n        # Inter-cluster distance b(i)\n        b_i = np.inf\n        other_labels = unique_labels[unique_labels != my_label]\n        for other_label in other_labels:\n            other_cluster_mask = (labels == other_label)\n            other_cluster_dists = dist_matrix[i, other_cluster_mask]\n            mean_dist = np.mean(other_cluster_dists)\n            if mean_dist  b_i:\n                b_i = mean_dist\n        \n        if max(a_i, b_i) == 0:\n            s_scores[i] = 0.0\n        else:\n            s_scores[i] = (b_i - a_i) / max(a_i, b_i)\n            \n    return np.mean(s_scores)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": 24, \"N\": 90,\n            \"prototypes\": [1, 2, 3], \"n_per_proto\": [30, 30, 30],\n            \"noise_sigma\": 0.05, \"amp_range\": [0.8, 1.2],\n            \"seed\": 42, \"candidate_k\": [2, 3, 4, 5]\n        },\n        {\n            \"T\": 24, \"N\": 80,\n            \"prototypes\": [4, 5], \"n_per_proto\": [40, 40],\n            \"noise_sigma\": 0.08, \"amp_range\": [0.85, 1.15],\n            \"seed\": 123, \"candidate_k\": [2, 3, 4, 5]\n        },\n        {\n            \"T\": 24, \"N\": 4,\n            \"prototypes\": [6, 7], \"n_per_proto\": [2, 2],\n            \"noise_sigma\": 0.02, \"amp_range\": [0.9, 1.1],\n            \"seed\": 999, \"candidate_k\": [2, 3, 4]\n        }\n    ]\n\n    # Algorithmic parameters\n    I_MAX = 300\n    TOL = 1e-6\n    R = 10\n    DELTA = 1e-9\n\n    results = []\n    case_idx = 0\n    for case in test_cases:\n        case_idx += 1\n        data = generate_data(\n            T=case[\"T\"],\n            prototypes=case[\"prototypes\"],\n            n_per_proto=case[\"n_per_proto\"],\n            noise_sigma=case[\"noise_sigma\"],\n            amp_range=case[\"amp_range\"],\n            seed=case[\"seed\"]\n        )\n        \n        best_k = -1\n        max_silhouette = -np.inf\n        \n        # Use a consistent seed for k-means runs for reproducibility\n        kmeans_seed_base = case[\"seed\"]\n\n        for k in sorted(case[\"candidate_k\"]):\n            labels, _, _ = kmeans(\n                data=data, k=k, n_restarts=R,\n                max_iter=I_MAX, tol=TOL, seed=kmeans_seed_base\n            )\n            score = calculate_silhouette_score(data, labels)\n            \n            # Select k that maximizes silhouette score.\n            # Only update if score is significantly better.\n            # This preserves the smallest k in case of a tie.\n            if score > max_silhouette + DELTA:\n                max_silhouette = score\n                best_k = k\n        \n        results.append(best_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}