{
    "hands_on_practices": [
        {
            "introduction": "在经验曲线建模中，我们不能简单地假设模型中的变量是相互独立的。成本和生产量常常相互影响，产生一种被称为内生性的“鸡生蛋、蛋生鸡”问题，这会导致我们的估计结果出现偏差。本练习  旨在挑战我们在一个常见的市场情景中诊断这个问题，并像计量经济学家一样思考，利用工具变量找到一个有效的解决方案。",
            "id": "4109578",
            "problem": "一个能源技术产业由单因素经验曲线建模，该曲线将单位成本与累计产出联系起来。令 $C_t$ 表示时间 $t$ 的单位成本，$Q_t$ 表示时间 $t$ 的累计产出，$\\varepsilon_t$ 表示时间 $t$ 的一个未观测到的、均值为零的成本冲击。经验设定为\n$$\n\\ln C_t = \\alpha - b \\ln Q_t + \\varepsilon_t,\n$$\n其中 $b > 0$。假设产品价格 $p_t$ 由竞争性或固定加成环境决定，因此 $p_t$ 与 $C_t$ 成正比；为具体起见，设 $p_t = C_t$。市场数量由需求决定：$Q_t = D(p_t, Z_t)$，其中 $D(\\cdot,\\cdot)$ 是其第一个参数的向下倾斜的需求函数，$Z_t$ 是不直接影响生产技术的外生需求转移向量。假设标准的正则性条件保证了唯一、稳定的均衡。\n\n你有兴趣使用普通最小二乘法估计 $b$。然而，存在一个担忧，即 $\\ln Q_t$ 可能是内生的，因为企业和采纳者通过需求调整生产和采纳来应对成本冲击。在上述假设下，从市场均衡和成本方程出发，判断 $\\ln Q_t$ 是外生的还是内生的，如果是内生的，则判断其对 $b$ 的估计所隐含的普通最小二乘法偏差的符号。然后，选择一个既能正确解释产生内生性的机制，又能为 $\\ln Q_t$ 提出一个有效的、理论上合理的工具变量的选项，该工具变量在此情境下满足工具变量相关性和排他性约束。\n\n哪个选项是正确的？\n\nA. 内生性不是一个问题，因为 $Q_t$ 是累计的，因此相对于同期的 $\\varepsilon_t$ 是预先决定的。一个合适的工具变量是 $\\ln Q_{t-1}$，它与 $\\ln Q_t$ 高度相关，并且必然与 $\\varepsilon_t$ 不相关。\n\nB. 内生性之所以产生，是因为降低成本的未观测因素也会增加需求，使得 $\\ln Q_t$ 与 $\\varepsilon_t$ 相关。一个合适的工具变量是用于制造该技术的投入商品价格指数（例如，锂或多晶硅价格指数），因为这些价格是生产量的强预测因子，但不会改变经验曲线方程中的成本。\n\nC. 内生性之所以产生，是因为负的成本冲击 $\\varepsilon_t$ 降低了 $p_t$，在需求曲线向下倾斜的情况下，这会增加 $Q_t$，从而导致 $\\operatorname{Cov}(\\ln Q_t, \\varepsilon_t)  0$。这使得对 $\\ln Q_t$ 斜率的普通最小二乘估计更负，从而高估了 $b$。一个合适的工具变量是外生的下游需求转移因子 $Z_t$（例如，采纳地区的人口加权供暖和制冷度日数，或预先宣布的改变采纳行为的政策义务），它通过需求影响 $Q_t$，但在控制变量条件下与同期的生产成本冲击 $\\varepsilon_t$ 正交。\n\nD. 内生性之所以产生，是因为价格调整以出清市场，所以 $\\ln Q_t$ 与 $\\varepsilon_t$ 存在机械性相关。一个合适的工具变量是实现的产品价格 $\\ln p_t$，它与 $\\ln Q_t$ 强相关，但由市场力量决定，因此与 $\\varepsilon_t$ 无关。",
            "solution": "此问题要求我们诊断经验曲线模型中的内生性问题，并为之寻找解决方案。\n\n**1. 内生性机制与偏差分析**\n\n首先，我们需要确定 $\\ln Q_t$ 是否是内生的。内生性意味着解释变量 $\\ln Q_t$ 与误差项 $\\varepsilon_t$ 相关。\n\n*   **模型设定**:\n    *   成本方程：$\\ln C_t = \\alpha - b \\ln Q_t + \\varepsilon_t$\n    *   价格设定：$p_t = C_t$\n    *   需求方程：$Q_t = D(p_t, Z_t)$，其中需求函数 $D$ 对价格 $p_t$ 向下倾斜。\n\n*   **传导机制**:\n    1.  一个随机的成本冲击 $\\varepsilon_t$ 发生。例如，一个负向冲击（$\\varepsilon_t  0$）意味着一个未被模型捕捉到的成本降低因素（如生产流程的意外创新）。\n    2.  这个冲击直接影响成本：$C_t$ 下降。\n    3.  成本下降导致价格下降：$p_t$ 下降。\n    4.  由于需求曲线向下倾斜，价格下降导致需求量增加：$Q_t$ 上升。\n\n*   **结论**: 负的成本冲击 $\\varepsilon_t$ 导致了 $\\ln Q_t$ 的增加。因此，$\\ln Q_t$ 与 $\\varepsilon_t$ 之间存在负相关关系，即 $\\operatorname{Cov}(\\ln Q_t, \\varepsilon_t)  0$。这证实了 $\\ln Q_t$ 是一个内生变量。\n\n*   **偏差方向**:\n    *   我们使用普通最小二乘法 (OLS) 估计回归方程中 $\\ln Q_t$ 的系数，即 $-b$。\n    *   OLS 估计量的偏差由以下公式给出：$\\text{Bias} = \\frac{\\operatorname{Cov}(\\ln Q_t, \\varepsilon_t)}{\\operatorname{Var}(\\ln Q_t)}$。\n    *   由于 $\\operatorname{Cov}(\\ln Q_t, \\varepsilon_t)  0$ 且方差 $\\operatorname{Var}(\\ln Q_t) > 0$，所以偏差为负。\n    *   这意味着 OLS 估计出的系数 $(\\widehat{-b})$ 将会比真实的系数 $-b$ 更小（即更负）。\n    *   我们最终关心的参数是学习指数 $b$。$\\hat{b}_{OLS} = -(\\widehat{-b})$。由于 $\\widehat{-b}  -b$，两边乘以 -1 会使不等号反向，得到 $\\hat{b}_{OLS} > b$。\n    *   因此，OLS 会**高估 (overestimate)** 学习指数 $b$。\n\n**2. 逐项分析选项**\n\n*   **A**: 错误。该选项声称内生性不是问题，这与我们的分析相悖。$Q_t$ 是在时间 $t$ 形成的，包含了受 $\\varepsilon_t$ 影响的同期产出，因此并非相对于 $\\varepsilon_t$ 完全预先决定。\n*   **B**: 错误。这个选项描述了一种可能的内生性来源，但其建议的工具变量——投入品价格指数——是无效的。投入品价格是生产成本 $C_t$ 的一个组成部分。因此，它会直接影响 $C_t$，从而与成本冲击 $\\varepsilon_t$ 相关（或者本身就是 $\\varepsilon_t$ 的一部分），违反了工具变量的“排他性约束”。\n*   **C**: **正确**。该选项准确地描述了内生性的产生机制（$\\varepsilon_t \\downarrow \\implies p_t \\downarrow \\implies Q_t \\uparrow$），正确地指出了协方差为负（$\\operatorname{Cov}(\\ln Q_t, \\varepsilon_t)  0$），并正确地推断出这会导致对 $b$ 的高估。更重要的是，它提出了一个有效的工具变量 $Z_t$（外生需求转移因子）。\n    *   **相关性**: $Z_t$ 通过需求函数 $D(p_t, Z_t)$ 影响 $Q_t$，满足相关性要求。\n    *   **排他性**: $Z_t$ 被定义为“不直接影响生产技术”，这意味着它只通过需求渠道影响系统，而与成本方程中的误差项 $\\varepsilon_t$ 不相关。因此，它满足排他性约束。所举的例子（如天气、预先宣布的政策）都是这类有效工具变量的典范。\n*   **D**: 错误。建议的工具变量 $\\ln p_t$ 是无效的。由于 $p_t$ 直接由 $C_t$ 决定，而 $C_t$ 又受 $\\varepsilon_t$ 影响，所以 $\\ln p_t$ 与误差项 $\\varepsilon_t$ 相关，违反了排他性约束。它本身就是一个内生变量。\n\n**3. 最终答案**\n\n选项 C 提供了对内生性问题及其解决方案的最准确和最完整的解释。\n\n$$\\boxed{C}$$",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "在设定模型后，特别是双因素模型，我们需要检查其基础是否稳定。当两个解释变量（如累计产量和研发投入）高度相似时，就像试图用靠得太近的两条腿站立一样——结果会摇摆不定。这个问题被称为多重共线性，它会放大我们参数估计的不确定性。在这个动手编程练习  中，我们将从零开始实现一个标准诊断工具——方差膨胀因子（Variance Inflation Factor, VIF），来量化这种不稳定性。",
            "id": "4109606",
            "problem": "考虑一个用于能源技术单位成本的双因素经验曲线模型，其对数设定为 $\\ln C = \\alpha - b \\ln Q - c \\ln S$。其中，$C$ 表示单位成本（以每能量单位的固定货币单位计量），$Q$ 表示累积产量（以能量单位计量），$S$ 表示累积溢出或知识存量（一个无量纲指数），$\\alpha$、$b$、$c$ 是待估计的未知参数。在使用普通最小二乘法（OLS）进行实际估计时，预测变量之间的强线性相关性会增大参数估计值的不确定性，这种现象被称为多重共线性。一种基于OLS和决定系数的标准诊断方法是方差膨胀因子（VIF），它应用于回归中的每个预测变量。您的任务是，仅依赖OLS和决定系数的定义，从基本原理出发，实现一个程序，通过计算每个预测变量的VIF来诊断预测变量对 $(\\ln Q, \\ln S)$ 中的多重共线性。VIF的计算需要通过辅助回归，即对每个预测变量，用它对另一个预测变量和一个截距项进行回归。三角函数中的角度必须以弧度处理。\n\n使用以下包含三个合成数据集的测试套件，这些数据集对于能源系统建模是科学上合理的。对于每个数据集，在指定的索引范围内构建序列 $\\{Q_i\\}$ 和 $\\{S_i\\}$，然后在执行诊断前将其转换为 $x_{1,i} = \\ln Q_i$ 和 $x_{2,i} = \\ln S_i$。\n\n- 数据集A（一般情况，中度相关）：对于 $i = 1,2,\\dots,20$，\n  $$ Q_i = 3.0 \\times 10^{5} + 1.8 \\times 10^{4} \\cdot i^{1.1}, $$\n  $$ S_i = 2.5 \\times 10^{4} + 7.0 \\times 10^{3} \\cdot \\sin(0.2 \\, i) + 1.4 \\times 10^{3} \\cdot i. $$\n  对 $\\sin(\\cdot)$ 使用弧度。\n\n- 数据集B（近共线性边界情况）：对于 $i = 1,2,\\dots,40$，\n  $$ Q_i = 1.0 \\times 10^{5} + 1.0 \\times 10^{4} \\cdot i, $$\n  $$ S_i = 1.0 \\times 10^{2} \\cdot Q_i^{0.97} \\cdot \\left(1 + 10^{-4} \\cdot \\cos(i)\\right). $$\n  对 $\\cos(\\cdot)$ 使用弧度。\n\n- 数据集C（小样本边界情况）：对于 $i = 1,2,\\dots,6$，\n  $u = [0, 2, 1, 3, 0.5, 2.5]$, $v = [2, 0, -1, 1.5, 2.2, 0.5]$,\n  $$ Q_i = 1.2 \\times 10^{5} + 2.0 \\times 10^{4} \\cdot u_i, $$\n  $$ S_i = 4.5 \\times 10^{4} + 2.0 \\times 10^{3} \\cdot v_i. $$\n\n对每个数据集执行以下步骤：\n1. 计算 $x_{1,i} = \\ln Q_i$ 和 $x_{2,i} = \\ln S_i$。\n2. 对于 $\\{x_1, x_2\\}$ 中的每个预测变量 $x_j$，估计 $x_j$ 对一个截距项和另一个预测变量 $x_k$（其中 $j \\neq k$）的辅助OLS回归。根据这个辅助回归，使用其基于平方和的定义来计算决定系数 $R_j^2$。\n3. 使用基于辅助回归得到的 $R_j^2$ 的方差膨胀框架，量化每个预测变量的多重共线性，并报告所得的VIF值。\n4. 使用两条决策规则来解释能源成本数据集中的关注阈值。为每个数据集定义两个布尔值：一个表示是否有任何预测变量的VIF严格超过 $5$（中度关注），另一个表示是否有任何预测变量的VIF严格超过 $10$（高度关注）。所有比较都使用小数表示，而不是百分号。\n\n输出规格：\n- 对每个数据集，生成一个包含四个条目的列表：$\\ln Q$ 的VIF（四舍五入到 $3$ 位小数）、$\\ln S$ 的VIF（四舍五入到 $3$ 位小数）、一个表示是否有VIF $ 5$ 的布尔值，以及一个表示是否有VIF $ 10$ 的布尔值。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个数据集的结果都用各自的方括号括起来，并按A、B、C的顺序排列。例如，输出结构必须是 $[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$。\n- 不允许外部输入；所有计算必须是自包含的。",
            "solution": "该问题要求从基本原理出发，为一个双因素经验曲线模型实现多重共线性诊断。单位成本 $C$ 的模型由以下对数设定给出：\n$$ \\ln C = \\alpha - b \\ln Q - c \\ln S $$\n其中 $Q$ 是累积产量，$S$ 是累积知识存量，而 $\\alpha$、$b$ 和 $c$ 是参数。此线性模型中的预测变量是 $x_1 = \\ln Q$ 和 $x_2 = \\ln S$。当这些预测变量高度线性相关时，就会出现多重共线性，这会使参数 $b$ 和 $c$ 的普通最小二乘法（OLS）估计的方差增大，从而使其不可靠。\n\n所选的诊断工具是方差膨胀因子（VIF）。对于多元回归模型中的一个给定预测变量 $x_j$，其VIF量化了由于它与其他预测变量的线性相关性，其估计系数的方差增加了多少。预测变量 $x_j$ 的VIF定义为：\n$$ \\text{VIF}_j = \\frac{1}{1 - R_j^2} $$\n此处，$R_j^2$ 来自一个辅助OLS回归的决定系数，在该回归中，$x_j$ 被视为因变量，而所有其他预测变量（在本例中仅为 $x_k$，其中 $k \\neq j$）和一个截距项是自变量。\n\n任务是为三个给定的数据集计算预测变量 $x_1 = \\ln Q$ 和 $x_2 = \\ln S$ 的 $\\text{VIF}_1$ 和 $\\text{VIF}_2$。这需要从基本原理出发执行两个辅助简单线性回归：\n1.  将 $x_1$ 对 $x_2$ 进行回归：$x_{1,i} = \\beta_{10} + \\beta_{11} x_{2,i} + \\epsilon_{1,i}$\n2.  将 $x_2$ 对 $x_1$ 进行回归：$x_{2,i} = \\beta_{20} + \\beta_{21} x_{1,i} + \\epsilon_{2,i}$\n\n对于一组 $n$ 个观测值 $\\{(x_i, y_i)\\}_{i=1}^n$，将因变量 $y$ 对自变量 $x$ 进行的一般简单线性回归，其模型为 $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$。最小化残差平方和的OLS估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 由以下公式给出：\n$$ \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n其中 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ 和 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 是样本均值。\n\n一旦估计出系数，就可以计算决定系数 $R^2$。$R^2$ 衡量因变量方差中可由自变量（们）预测的比例。其定义为：\n$$ R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}} $$\n其中：\n-   总平方和（SST），$\\text{SST} = \\sum_{i=1}^n (y_i - \\bar{y})^2$，衡量因变量的总样本方差。\n-   残差平方和（SSR），$\\text{SSR} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$，衡量模型未能解释的方差，其中 $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$ 是预测值。\n\n在两个预测变量 $x_1$ 和 $x_2$ 的特定情况下，将 $x_1$ 对 $x_2$ 回归得到的决定系数 ($R_1^2$) 与将 $x_2$ 对 $x_1$ 回归得到的决定系数 ($R_2^2$) 是相同的。两者都等于 $x_1$ 和 $x_2$ 之间皮尔逊相关系数的平方，即 $R_1^2 = R_2^2 = r_{x_1, x_2}^2$。因此，它们的VIF值也必须相同：$\\text{VIF}_1 = \\text{VIF}_2$。这提供了一个有用的一致性检查。\n\n每个数据集的计算过程如下：\n1.  根据提供的公式，生成累积产量 $\\{Q_i\\}$ 和知识存量 $\\{S_i\\}$ 的时间序列数据。对于数据集 A，其中 $i = 1, 2, \\dots, 20$：\n    $Q_i = 3.0 \\times 10^{5} + 1.8 \\times 10^{4} \\cdot i^{1.1}$\n    $S_i = 2.5 \\times 10^{4} + 7.0 \\times 10^{3} \\cdot \\sin(0.2 \\, i) + 1.4 \\times 10^{3} \\cdot i$\n    对于数据集 B，其中 $i = 1, 2, \\dots, 40$：\n    $Q_i = 1.0 \\times 10^{5} + 1.0 \\times 10^{4} \\cdot i$\n    $S_i = 1.0 \\times 10^{2} \\cdot Q_i^{0.97} \\cdot (1 + 10^{-4} \\cdot \\cos(i))$\n    对于数据集 C，其中 $i = 1, 2, \\dots, 6$：\n    $u = [0, 2, 1, 3, 0.5, 2.5]$, $v = [2, 0, -1, 1.5, 2.2, 0.5]$\n    $Q_i = 1.2 \\times 10^{5} + 2.0 \\times 10^{4} \\cdot u_i$\n    $S_i = 4.5 \\times 10^{4} + 2.0 \\times 10^{3} \\cdot v_i$\n2.  使用自然对数转换数据：$x_{1,i} = \\ln Q_i$ 和 $x_{2,i} = \\ln S_i$。\n3.  为计算 $x_1 = \\ln Q$ 的 $\\text{VIF}_1$：\n    a.  以 $y=x_1$ 和 $x=x_2$ 进行OLS回归，求得 $\\hat{\\beta}_{10}, \\hat{\\beta}_{11}$。\n    b.  使用此回归的SST和SSR计算 $R_1^2$。\n    c.  计算 $\\text{VIF}_1 = 1 / (1 - R_1^2)$。\n4.  为计算 $x_2 = \\ln S$ 的 $\\text{VIF}_2$：\n    a.  以 $y=x_2$ 和 $x=x_1$ 进行OLS回归，求得 $\\hat{\\beta}_{20}, \\hat{\\beta}_{21}$。\n    b.  计算 $R_2^2$。\n    c.  计算 $\\text{VIF}_2 = 1 / (1 - R_2^2)$。\n5.  应用决策规则：确定是否有任何VIF值超过 $5$（中度关注）和 $10$（高度关注）的阈值。\n6.  每个数据集的最终结果是一个列表，包含四舍五入到3位小数的 $\\ln Q$ 的VIF、四舍五入到3位小数的 $\\ln S$ 的VIF，以及与决策规则相对应的两个布尔值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multicollinearity diagnosis problem for three datasets.\n    \"\"\"\n\n    def calculate_vif(y_vec, x_vec):\n        \"\"\"\n        Computes the Variance Inflation Factor (VIF) for a predictor by regressing it\n        on another predictor from first principles (OLS and R-squared).\n\n        Args:\n            y_vec (np.ndarray): The dependent variable vector (the predictor for which VIF is calculated).\n            x_vec (np.ndarray): The independent variable vector (the other predictor).\n\n        Returns:\n            float: The calculated VIF. Returns np.inf for perfect multicollinearity.\n        \"\"\"\n        n = len(y_vec)\n        if n  2:\n            return np.nan \n\n        # Calculate means\n        y_mean = np.mean(y_vec)\n        x_mean = np.mean(x_vec)\n\n        # Calculate OLS coefficient beta_1 for y = beta_0 + beta_1*x\n        numerator = np.sum((x_vec - x_mean) * (y_vec - y_mean))\n        denominator = np.sum((x_vec - x_mean)**2)\n\n        if denominator == 0:\n            # The independent variable has zero variance, regression is ill-defined.\n            return np.nan\n\n        beta_1 = numerator / denominator\n        beta_0 = y_mean - beta_1 * x_mean\n\n        # Calculate predicted values and sums of squares\n        y_pred = beta_0 + beta_1 * x_vec\n        sst = np.sum((y_vec - y_mean)**2)\n        ssr = np.sum((y_vec - y_pred)**2)\n\n        if sst == 0:\n            # The dependent variable has zero variance.\n            return np.nan\n\n        # Calculate R-squared\n        r_squared = 1.0 - (ssr / sst)\n\n        # Handle perfect multicollinearity case (R^2 = 1)\n        if r_squared >= 1.0 - 1e-12: # Use a tolerance for floating point comparison\n            return np.inf\n\n        # Calculate VIF\n        vif = 1.0 / (1.0 - r_squared)\n        return vif\n\n    # Define the datasets\n    # Dataset A\n    i_A = np.arange(1, 21)\n    Q_A = 3.0e5 + 1.8e4 * np.power(i_A, 1.1)\n    S_A = 2.5e4 + 7.0e3 * np.sin(0.2 * i_A) + 1.4e3 * i_A\n\n    # Dataset B\n    i_B = np.arange(1, 41)\n    Q_B = 1.0e5 + 1.0e4 * i_B\n    S_B = 1.0e2 * np.power(Q_B, 0.97) * (1.0 + 1e-4 * np.cos(i_B))\n\n    # Dataset C\n    u_C = np.array([0.0, 2.0, 1.0, 3.0, 0.5, 2.5])\n    v_C = np.array([2.0, 0.0, -1.0, 1.5, 2.2, 0.5])\n    Q_C = 1.2e5 + 2.0e4 * u_C\n    S_C = 4.5e4 + 2.0e3 * v_C\n\n    test_cases = [\n        {\"name\": \"A\", \"Q\": Q_A, \"S\": S_A},\n        {\"name\": \"B\", \"Q\": Q_B, \"S\": S_B},\n        {\"name\": \"C\", \"Q\": Q_C, \"S\": S_C},\n    ]\n\n    all_results_str = []\n    \n    for case in test_cases:\n        # Step 1: Compute transformed predictors\n        x1 = np.log(case[\"Q\"])  # x1 corresponds to ln(Q)\n        x2 = np.log(case[\"S\"])  # x2 corresponds to ln(S)\n\n        # Step 2  3: Compute VIF for each predictor\n        # VIF for ln(Q) is based on regression of ln(Q) on ln(S)\n        vif_lnQ = calculate_vif(y_vec=x1, x_vec=x2)\n        \n        # VIF for ln(S) is based on regression of ln(S) on ln(Q)\n        vif_lnS = calculate_vif(y_vec=x2, x_vec=x1)\n        \n        # Step 4: Apply decision rules\n        # Since VIFs must be equal for 2 predictors, we can check one\n        moderate_concern = vif_lnQ > 5.0\n        strong_concern = vif_lnQ > 10.0\n        \n        # Round VIFs for output\n        vif_lnQ_rounded = round(vif_lnQ, 3)\n        vif_lnS_rounded = round(vif_lnS, 3)\n        \n        # Format the result string for this case to avoid spaces\n        # Python's str(bool) gives 'True'/'False' literals\n        result_str = (\n            f\"[{vif_lnQ_rounded},\"\n            f\"{vif_lnS_rounded},\"\n            f\"{str(moderate_concern)},\"\n            f\"{str(strong_concern)}]\"\n        )\n        all_results_str.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们常常面临一个选择：一个简单的单因素模型是否足够好，还是一个更复杂的双因素模型能提供更深刻的洞见？答案在于预测性能。这最后一个练习  将指导我们实现一种稳健的验证技术——分块K折交叉验证（blocked K-fold cross-validation），以严格比较单因素和双因素模型在时间序列数据上的预测准确性，帮助我们做出基于证据的决策。",
            "id": "4109570",
            "problem": "您的任务是设计并实现一个程序化的 $K$ 折交叉验证（CV）程序，以比较能源系统建模中单因素与双因素经验曲线模型的预测性能。因变量是单位成本的自然对数，损失函数必须在对数成本空间中运行。交叉验证必须通过将连续的数据块分配到各个折（fold）中来尊重时间结构。比较必须在三个由科学上合理、自洽的生成过程构建的合成测试用例上进行。\n\n起点和基本原理：假设某能源技术的单位成本受规模和另一个驱动因素的恒定弹性支配。具有乘法可分性的恒定弹性意味着，在取自然对数后，模型在参数上变为线性。因此，模型训练必须使用普通最小二乘法（OLS），并且模型比较必须在对数成本空间中一个明确指定的损失函数下进行。\n\n要求：\n- 使用分块 $K$ 折交叉验证（CV），其定义为将按时间排序的数据划分为 $K$ 个连续的块，依次使用每个块作为验证集，其余的块联合作为训练集。\n- 将对数成本上的损失定义为所有折中所有验证点的均方误差（Mean Squared Error, MSE）。如果 $\\hat{y}_i$ 表示预测的对数成本，$y_i$ 表示观测的对数成本，并且所有折中总共有 $m$ 个验证点，则损失必须为\n$$\n\\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^{m} \\left(y_i - \\hat{y}_i\\right)^2.\n$$\n- 成本以美元/千瓦（$USD/kW$）为单位。在取对数之前，通过除以 $1\\ USD/kW$ 进行归一化，以使自然对数应用于一个无量纲的比率。\n- 单因素模型：将对数成本对一个源自规模（经对数转换）的单一解释变量进行回归。\n- 双因素模型：将对数成本对两个源自规模和另一个驱动因素（均经对数转换）的解释变量进行回归。\n- 使用 OLS 在训练折上估计参数线性模型，并在留出的折上生成验证预测。\n\n测试套件和数据生成：\n用确定性生成过程构建三个测试用例。在所有案例中，令 $t \\in \\{1,2,\\dots,N\\}$ 表示时间索引，$S_t$ 表示累积规模，$D_t$ 表示另一个驱动因素，$C_t$ 表示单位成本。使用指定的序列定义 $S_t$ 和 $D_t$，然后将单位成本定义为\n$$\nC_t = A \\cdot S_t^{-b} \\cdot D_t^{-g} \\cdot e^{\\varepsilon_t},\n$$\n其中 $A$ 是一个单位为 $USD/kW$ 的正尺度参数，$\\varepsilon_t$ 是一个确定性扰动。观测到的因变量是 $y_t = \\ln\\left(C_t / (1\\ \\text{USD}/\\text{kW})\\right)$。\n\n- 案例 A（通用的“理想路径”双因素）：\n  - $N = 30$, $K = 5$, $A = 1000$, $b = 0.3$, $g = 0.2$。\n  - 生产增量：$s_t = 0.5 + 0.02 t + 0.1 \\sin(0.1 t)$，累积规模：$S_t = \\sum_{i=1}^{t} s_i$。\n  - 知识增量：$d_t = 0.2 + 0.01 t$，知识存量：$D_t = \\sum_{i=1}^{t} d_i$。\n  - 扰动：$\\varepsilon_t = 0.05 \\sin(0.3 t)$。\n\n- 案例 B（由单因素主导的边缘案例）：\n  - $N = 8$, $K = 4$, $A = 800$, $b = 0.35$, $g = 0$。\n  - 生产增量：$s_t = 0.6 + 0.03 t$，累积规模：$S_t = \\sum_{i=1}^{t} s_i$。\n  - 附加驱动因素为常数：对于所有 $t$，$D_t = 1$。\n  - 扰动：$\\varepsilon_t = 0.02 \\cos(0.5 t)$。\n\n- 案例 C（具有强共线性和留一法交叉验证的边界案例）：\n  - $N = 12$, $K = 12$, $A = 900$, $b = 0.25$, $g = 0.1$。\n  - 生产增量：$s_t = 0.7 + 0.01 t$，累积规模：$S_t = \\sum_{i=1}^{t} s_i$。\n  - 附加驱动因素：$D_t = 1.05 S_t + 0.5$。\n  - 扰动：$\\varepsilon_t = 0.04 \\sin(0.2 t)$。\n\n实现细节：\n- 对于每个案例，使用上述定义构建 $S_t$、$D_t$ 和 $C_t$，并将归一化成本的自然对数计算为 $y_t$。\n- 对于单因素模型，对一个截距项和 $\\ln(S_t)$ 拟合 $y_t$。\n- 对于双因素模型，对一个截距项、$\\ln(S_t)$ 和 $\\ln(D_t)$ 拟合 $y_t$。\n- 使用分块 $K$ 折交叉验证：将索引 $\\{1,\\dots,N\\}$ 划分为 $K$ 个连续的折，其大小差异最多为 1。在每个折中，验证集是当前块，训练集是其余部分。\n- 计算 $\\mathcal{L}_{1}$ 作为单因素模型在所有折上的平均验证 MSE，并类似地计算双因素模型的 $\\mathcal{L}_{2}$。\n\n要求的最终输出：\n- 对于每个测试用例，计算标量差 $\\Delta = \\mathcal{L}_{1} - \\mathcal{L}_{2}$，单位为对数成本单位（无量纲）。将这三个值报告为纯十进制数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[$\\text{result1}$,$\\text{result2}$,$\\text{result3}$]”），不含其他文本。\n\n所有三角函数的计算都必须以弧度表示，所有数值输出必须是十进制数，不带百分号。",
            "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于经验曲线建模和统计模型验证的原则，其设置清晰完整，问题提法得当，并且其表述是客观的。提供的测试用例是确定性的，确保了唯一且可验证的解。因此，我们可以着手解决问题。\n\n任务是，为三个不同的、综合生成的测试用例，以编程方式实现一个分块 $K$ 折交叉验证（CV）程序，以比较单因素经验曲线模型与双因素模型。比较指标是在留出验证集上的均方误差（MSE）之差，该误差在所有折上进行汇总。\n\n在时间 $t$ 的单位成本 $C_t$ 的生成过程由一个具有恒定弹性的乘法模型给出：\n$$\nC_t = A \\cdot S_t^{-b} \\cdot D_t^{-g} \\cdot e^{\\varepsilon_t}\n$$\n这里，$S_t$ 是生产的累积规模，$D_t$ 是一个额外的解释性驱动因素（例如，知识存量），$A$ 是一个基准成本参数，$b$ 和 $g$ 分别是相对于规模和附加驱动因素的学习弹性，$\\varepsilon_t$ 是一个确定性扰动项。\n\n通过取自然对数并将成本用 $1 \\text{ USD/kW}$ 进行归一化以创建一个无量纲的量，我们得到了一个参数呈线性的模型：\n$$\ny_t = \\ln\\left(\\frac{C_t}{1 \\text{ USD/kW}}\\right) = \\ln(A) - b\\ln(S_t) - g\\ln(D_t) + \\varepsilon_t\n$$\n这个对数线性形式是我们估计程序的基础。我们将比较两个使用普通最小二乘法（OLS）在此对数转换数据上拟合的模型。\n\n模型 1（单因素）：此模型仅将对数成本 $y_t$ 与累积规模的对数 $\\ln(S_t)$ 相关联。它包含一个截距项。模型方程为：\n$$\ny_t = \\beta_0 + \\beta_1 \\ln(S_t) + u_t\n$$\n其中 $\\beta_0$ 和 $\\beta_1$ 是待估计的系数，$u_t$ 是误差项。\n\n模型 2（双因素）：此模型通过包含附加驱动因素的对数 $\\ln(D_t)$ 作为第二个解释变量来扩展单因素模型。模型方程为：\n$$\ny_t = \\gamma_0 + \\gamma_1 \\ln(S_t) + \\gamma_2 \\ln(D_t) + v_t\n$$\n其中 $\\gamma_0$、$\\gamma_1$ 和 $\\gamma_2$ 是待估计的系数，$v_t$ 是误差项。\n\n分析的核心是分块 $K$ 折交叉验证程序。选择此方法是为了尊重数据的时间顺序，这在时间序列背景下至关重要，以防止前视偏差。包含 $N$ 个观测值的数据集被划分为 $K$ 个连续的、不重叠的块（折）。该过程迭代 $K$ 次。在每次迭代 $k \\in \\{1, \\dots, K\\}$ 中，第 $k$ 个数据块用作验证集，其余 $K-1$ 个数据块组合成训练集。\n\n对于 $K$ 次迭代中的每一次，我们执行以下步骤：\n1.  使用 OLS 在训练数据上估计两个模型的模型参数（$\\beta$ 和 $\\gamma$）。对于一个通用线性模型 $y = X\\beta + \\epsilon$，OLS 估计值为 $\\hat{\\beta} = (X^T X)^{-1} X^T y$。此计算使用数值稳定的算法，例如 `numpy.linalg.lstsq` 提供的算法。\n2.  然后使用拟合的模型来预测验证集中观测值 $i$ 的对数成本 $\\hat{y}_i$。\n3.  存储验证集的真实观测对数成本 $y_i$ 和预测对数成本 $\\hat{y}_i$。\n\n完成所有 $K$ 个折后，汇总所有存储的验证预测。每个模型的总体性能通过所有 $m$ 个验证点上的均方误差（MSE）来量化，其中 $m=N$。损失函数定义为：\n$$\n\\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n$$\n设 $\\mathcal{L}_1$ 为单因素模型的损失，$\\mathcal{L}_2$ 为双因素模型的损失。最终比较通过计算差值 $\\Delta = \\mathcal{L}_1 - \\mathcal{L}_2$ 来进行。一个正的 $\\Delta$ 值表示双因素模型具有更低的 MSE，因此在此评估框架下具有更优的预测性能。\n\n这整个过程应用于三个不同的测试用例，每个用例都由一组特定的参数（$A, b, g, N, K$）以及 $S_t$、$D_t$ 和 $\\varepsilon_t$ 的函数形式定义。该逻辑封装在一个 Python 程序中，该程序首先为每个案例生成数据，然后执行所述的交叉验证工作流以计算 $\\mathcal{L}_1$ 和 $\\mathcal{L}_2$，最后计算它们的差值 $\\Delta$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the cross-validation comparison for all test cases.\n    \"\"\"\n\n    def perform_kfold_cv(X, y, K):\n        \"\"\"\n        Performs blocked K-fold cross-validation for a given model.\n\n        Args:\n            X (np.ndarray): The design matrix, including an intercept column.\n            y (np.ndarray): The dependent variable vector.\n            K (int): The number of folds.\n\n        Returns:\n            float: The mean squared error over all validation predictions.\n        \"\"\"\n        n_samples = len(y)\n        indices = np.arange(n_samples)\n\n        # Determine the size of each contiguous block for the folds.\n        # This ensures fold sizes differ by at most 1.\n        base_fold_size = n_samples // K\n        num_larger_folds = n_samples % K\n        \n        fold_start_indices = [0]\n        current_idx = 0\n        for i in range(K):\n            fold_size = base_fold_size + 1 if i  num_larger_folds else base_fold_size\n            current_idx += fold_size\n            if i  K - 1:\n                fold_start_indices.append(current_idx)\n\n        all_y_true = []\n        all_y_pred = []\n\n        for i in range(K):\n            # Define validation and training indices for the current fold\n            val_start = fold_start_indices[i]\n            val_end = fold_start_indices[i+1] if i + 1  K else n_samples\n            val_idx = indices[val_start:val_end]\n            \n            train_mask = np.ones(n_samples, dtype=bool)\n            train_mask[val_idx] = False\n            train_idx = indices[train_mask]\n\n            X_train, y_train = X[train_idx], y[train_idx]\n            X_val, y_val = X[val_idx], y[val_idx]\n\n            # Fit model using OLS on the training set\n            # np.linalg.lstsq is numerically robust and handles (multi)collinearity\n            try:\n                coeffs = np.linalg.lstsq(X_train, y_train, rcond=None)[0]\n            except np.linalg.LinAlgError:\n                # This should not occur with the given test cases, but is a safeguard.\n                # If it occurs, prediction quality is zero.\n                coeffs = np.zeros(X_train.shape[1])\n\n            # Predict on the validation set\n            y_pred = X_val @ coeffs\n            \n            all_y_true.append(y_val)\n            all_y_pred.append(y_pred)\n\n        # Concatenate results from all folds\n        y_true_flat = np.concatenate(all_y_true)\n        y_pred_flat = np.concatenate(all_y_pred)\n        \n        # Calculate overall Mean Squared Error\n        mse = np.mean((y_true_flat - y_pred_flat)**2)\n        return mse\n\n    def run_case(params):\n        \"\"\"\n        Generates data and runs the CV comparison for a single test case.\n        \"\"\"\n        case_id, N, K, A, b, g, s_func, d_spec, eps_func = params\n\n        # Generate data based on the case specification\n        t = np.arange(1, N + 1)\n        \n        s_t = s_func(t)\n        S_t = np.cumsum(s_t)\n\n        if case_id == 'A':\n            d_t = d_spec(t)\n            D_t = np.cumsum(d_t)\n        elif case_id == 'B':\n            D_t = np.full(N, d_spec)\n        elif case_id == 'C':\n            D_t = d_spec(S_t)\n\n        epsilon_t = eps_func(t)\n        \n        # Compute cost and the log-transformed dependent variable y_t\n        C_t = A * (S_t ** -b) * (D_t ** -g) * np.exp(epsilon_t)\n        y = np.log(C_t)\n\n        # Prepare regressor data\n        log_S = np.log(S_t)\n        log_D = np.log(D_t)\n        intercept = np.ones_like(y)\n\n        # Create design matrices for the two models\n        X1 = np.stack([intercept, log_S], axis=1) # One-factor model\n        X2 = np.stack([intercept, log_S, log_D], axis=1) # Two-factor model\n\n        # Perform CV and get MSE for each model\n        loss1 = perform_kfold_cv(X1, y, K)\n        loss2 = perform_kfold_cv(X2, y, K)\n\n        # Return the difference in loss\n        return loss1 - loss2\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        ('A', 30, 5, 1000, 0.3, 0.2, \n         lambda t: 0.5 + 0.02 * t + 0.1 * np.sin(0.1 * t), \n         lambda t: 0.2 + 0.01 * t,\n         lambda t: 0.05 * np.sin(0.3 * t)),\n        ('B', 8, 4, 800, 0.35, 0,\n         lambda t: 0.6 + 0.03 * t,\n         1.0,\n         lambda t: 0.02 * np.cos(0.5 * t)),\n        ('C', 12, 12, 900, 0.25, 0.1,\n         lambda t: 0.7 + 0.01 * t,\n         lambda S: 1.05 * S + 0.5,\n         lambda t: 0.04 * np.sin(0.2 * t))\n    ]\n    \n    results = [run_case(case) for case in test_cases]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}