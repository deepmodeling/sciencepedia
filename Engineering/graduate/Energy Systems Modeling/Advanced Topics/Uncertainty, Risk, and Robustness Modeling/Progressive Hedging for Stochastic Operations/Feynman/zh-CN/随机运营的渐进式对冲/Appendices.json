{
    "hands_on_practices": [
        {
            "introduction": "要真正理解逐步对冲算法，没有什么比亲手进行一次计算更能加深理解了。第一个实践将引导您针对一个小规模电力系统，完整地执行一次算法迭代 。通过求解特定场景的子问题，然后计算更新后的共识变量，您将对驱动该分解方法的核心机制获得一个具体而清晰的认识。",
            "id": "4114574",
            "problem": "考虑一个两阶段随机运营模型，该模型用于一个小型能源系统，该系统包含两个火力发电机（索引为 $j \\in \\{1,2\\}$）和两个情景（索引为 $s \\in \\{1,2\\}$），情景概率分别为 $p_{1} = 0.7$ 和 $p_{2} = 0.3$。第一阶段决策是与情景无关的日前基本发电向量 $u = (u_{1}, u_{2})$，单位为兆瓦 (MW)，通过跨情景的非预见性约束强制执行。在渐进对冲 (Progressive Hedging, PH) 算法中，为实现分解，引入了针对特定情景的副本 $u_{s} = (u_{1,s}, u_{2,s})$，并通过带有惩罚参数 $\\rho$ 的增广拉格朗日函数来强制执行非预见性。\n\n每个情景的基本发电计划都有一个二次运营成本，\n$$\nf_{s}(u_{s}) \\;=\\; \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} \\;+\\; \\beta_{j,s}\\,u_{j,s} \\right),\n$$\n受限于发电机容量边界 $0 \\leq u_{j,s} \\leq U_{j}$。为符合物理现实，取 $U_{1} = 100$ 兆瓦和 $U_{2} = 80$ 兆瓦，以及情景系数：\n$$\n\\alpha_{1,1} = 2,\\;\\; \\beta_{1,1} = 10;\\quad \\alpha_{2,1} = 4,\\;\\; \\beta_{2,1} = 8; \\\\\n\\alpha_{1,2} = 3,\\;\\; \\beta_{1,2} = 6;\\quad \\alpha_{2,2} = 1,\\;\\; \\beta_{2,2} = 5.\n$$\n假设 PH 惩罚参数为 $\\rho = 2$，初始乘子为 $\\lambda_{1}^{0} = (0,0)$ 和 $\\lambda_{2}^{0} = (0,0)$，初始平均计划为 $\\bar{u}^{0} = (20, 30)$ 兆瓦。执行一次从迭代 $k=0$ 到 $k=1$ 的渐进对冲算法迭代：对于每个情景 $s$，求解 PH 情景子问题。该子问题通过将 $u_s$ 拉向 $\\bar{u}^0$ 的惩罚项和当前乘子 $\\lambda_{s}^{0}$ 来增广 $f_{s}(u_{s})$，并受限于给定的边界条件。假设无约束最小化解是内部解（即，它们无需投影即满足边界条件）。然后，计算新的概率加权非预见性平均值\n$$\n\\bar{u}^{1} \\;=\\; \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1},\n$$\n其中 $u_{s}^{1}$ 表示在此次迭代中获得的情景解。将最终答案表示为一个包含 $\\bar{u}^{1}$ 各分量的二元行向量，单位为兆瓦。以精确的简化分数形式提供各分量；不要四舍五入。",
            "solution": "首先根据既定标准对问题进行验证。\n\n### 问题验证\n\n**步骤1：提取的已知条件**\n- **模型：** 一个两阶段随机运营模型。\n- **发电机：** 索引为 $j \\in \\{1,2\\}$。\n- **情景：** 索引为 $s \\in \\{1,2\\}$。\n- **情景概率：** $p_{1} = 0.7$ 和 $p_{2} = 0.3$。\n- **第一阶段决策：** 与情景无关的发电向量 $u = (u_{1}, u_{2})$。\n- **渐进对冲 (PH) 算法：**\n  - 特定情景的决策副本：$u_{s} = (u_{1,s}, u_{2,s})$。\n  - 惩罚参数：$\\rho = 2$。\n- **情景成本函数：** $f_{s}(u_{s}) = \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} \\right)$。\n- **发电机容量边界：** $0 \\leq u_{j,s} \\leq U_{j}$，其中 $U_{1} = 100$ MW 和 $U_{2} = 80$ MW。\n- **成本系数：**\n  - 对于 $s=1$：$\\alpha_{1,1} = 2$，$\\beta_{1,1} = 10$；$\\alpha_{2,1} = 4$，$\\beta_{2,1} = 8$。\n  - 对于 $s=2$：$\\alpha_{1,2} = 3$，$\\beta_{1,2} = 6$；$\\alpha_{2,2} = 1$，$\\beta_{2,2} = 5$。\n- **初始条件（迭代 $k=0$）：**\n  - 乘子：$\\lambda_{1}^{0} = (0,0)$ 和 $\\lambda_{2}^{0} = (0,0)$。\n  - 平均计划：$\\bar{u}^{0} = (20, 30)$。\n- **任务：** 执行一次 PH 迭代，计算 $s=1,2$ 的子问题解 $u_{s}^{1}$，然后计算新的概率加权平均值 $\\bar{u}^{1} = \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1}$。\n- **假设：** 子问题的无约束最小化解在容量边界内部。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用了随机优化（渐进对冲算法）中的标准方法，并应用于能源系统建模（二次发电机成本）。该问题是适定的，具有凸二次目标函数和线性约束，保证了子问题有唯一解。所有必要的数据和条件都已提供，并且没有内部矛盾。数值在当前情境下是物理上合理的。该问题是客观、可形式化和可验证的。\n\n**步骤3：结论与行动**\n问题有效。将提供解答。\n\n### 解\n\n渐进对冲 (PH) 算法按情景分解一个随机优化问题。对每个情景 $s$，求解一个子问题。在迭代 $k+1$ 时，情景 $s$ 的子问题是找到决策向量 $u_s^{k+1}$，以最小化增广拉格朗日函数：\n$$ u_{s}^{k+1} = \\arg\\min_{u_{s} \\in C_{s}} \\left\\{ f_{s}(u_{s}) + (\\lambda_{s}^{k})^{T} u_{s} + \\frac{\\rho}{2} \\| u_{s} - \\bar{u}^{k} \\|_{2}^{2} \\right\\} $$\n其中 $C_s$ 表示情景 $s$ 的可行集，在本例中由发电机容量边界 $0 \\leq u_{j,s} \\leq U_{j}$ 定义。\n\n我们需要执行一次迭代，从 $k=0$ 开始以找到 $\\bar{u}^1$。需要为情景 $s$ 最小化的目标函数是：\n$$ L_s(u_s) = f_{s}(u_{s}) + (\\lambda_{s}^{0})^{T} u_{s} + \\frac{\\rho}{2} \\| u_{s} - \\bar{u}^{0} \\|_{2}^{2} $$\n鉴于初始乘子是零向量，$\\lambda_s^0 = (0,0)$，项 $(\\lambda_{s}^{0})^{T} u_{s}$ 为零。目标函数简化为：\n$$ L_s(u_s) = \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} \\right) + \\frac{\\rho}{2} \\sum_{j=1}^{2} (u_{j,s} - \\bar{u}_{j}^{0})^{2} $$\n该目标函数对于发电机索引 $j$ 是可分的。因此，对于每个情景 $s$ 和每个发电机 $j$，我们可以求解一个独立的一维优化问题：\n$$ \\min_{u_{j,s}} \\left\\{ J_{j,s}(u_{j,s}) = \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} + \\frac{\\rho}{2} (u_{j,s} - \\bar{u}_{j}^{0})^{2} \\right\\} $$\n约束条件为 $0 \\leq u_{j,s} \\leq U_{j}$。\n\n由于 $\\alpha_{j,s} > 0$ 和 $\\rho > 0$，目标函数 $J_{j,s}(u_{j,s})$ 是一个严格凸的二次函数。其无约束最小化解可以通过将其关于 $u_{j,s}$ 的一阶导数设为零来找到：\n$$ \\frac{dJ_{j,s}}{du_{j,s}} = \\alpha_{j,s}\\,u_{j,s} + \\beta_{j,s} + \\rho(u_{j,s} - \\bar{u}_{j}^{0}) = 0 $$\n求解 $u_{j,s}$ 得到本次迭代的情景子问题的解，记为 $u_{j,s}^1$：\n$$ (\\alpha_{j,s} + \\rho)u_{j,s}^1 = \\rho\\,\\bar{u}_{j}^{0} - \\beta_{j,s} \\implies u_{j,s}^{1} = \\frac{\\rho\\,\\bar{u}_{j}^{0} - \\beta_{j,s}}{\\alpha_{j,s} + \\rho} $$\n问题陈述要求假设此无约束解是内部解，即它位于边界 $[0, U_j]$ 内。我们将在计算后验证此假设。我们使用给定的值：$\\rho = 2$ 和 $\\bar{u}^{0} = (20, 30)$。\n\n**情景 $s=1$：**\n- 对于发电机 $j=1$：$\\alpha_{1,1}=2$，$\\beta_{1,1}=10$，$\\bar{u}_1^0=20$。\n  $$ u_{1,1}^{1} = \\frac{2 \\cdot 20 - 10}{2 + 2} = \\frac{40 - 10}{4} = \\frac{30}{4} = \\frac{15}{2} $$\n- 对于发电机 $j=2$：$\\alpha_{2,1}=4$，$\\beta_{2,1}=8$，$\\bar{u}_2^0=30$。\n  $$ u_{2,1}^{1} = \\frac{2 \\cdot 30 - 8}{4 + 2} = \\frac{60 - 8}{6} = \\frac{52}{6} = \\frac{26}{3} $$\n情景 1 的解为 $u_1^1 = (\\frac{15}{2}, \\frac{26}{3})$。验证边界：$0 \\leq \\frac{15}{2} \\leq 100$ 和 $0 \\leq \\frac{26}{3} \\leq 80$。两者都成立。\n\n**情景 $s=2$：**\n- 对于发电机 $j=1$：$\\alpha_{1,2}=3$，$\\beta_{1,2}=6$，$\\bar{u}_1^0=20$。\n  $$ u_{1,2}^{1} = \\frac{2 \\cdot 20 - 6}{3 + 2} = \\frac{40 - 6}{5} = \\frac{34}{5} $$\n- 对于发电机 $j=2$：$\\alpha_{2,2}=1$，$\\beta_{2,2}=5$，$\\bar{u}_2^0=30$。\n  $$ u_{2,2}^{1} = \\frac{2 \\cdot 30 - 5}{1 + 2} = \\frac{60 - 5}{3} = \\frac{55}{3} $$\n情景 2 的解为 $u_2^1 = (\\frac{34}{5}, \\frac{55}{3})$。验证边界：$0 \\leq \\frac{34}{5} \\leq 100$ 和 $0 \\leq \\frac{55}{3} \\leq 80$。两者都成立。假设成立。\n\n最后一步是计算新的概率加权平均计划 $\\bar{u}^1$：\n$$ \\bar{u}^{1} = \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1} = p_{1}\\,u_{1}^{1} + p_{2}\\,u_{2}^{1} $$\n使用 $p_1 = 0.7 = \\frac{7}{10}$ 和 $p_2 = 0.3 = \\frac{3}{10}$，我们分别计算 $\\bar{u}^1 = (\\bar{u}_1^1, \\bar{u}_2^1)$ 的分量。\n\n- 分量 $\\bar{u}_1^1$：\n  $$ \\bar{u}_{1}^{1} = p_{1}\\,u_{1,1}^{1} + p_{2}\\,u_{1,2}^{1} = \\frac{7}{10} \\cdot \\frac{15}{2} + \\frac{3}{10} \\cdot \\frac{34}{5} $$\n  $$ \\bar{u}_{1}^{1} = \\frac{105}{20} + \\frac{102}{50} = \\frac{21}{4} + \\frac{51}{25} $$\n  $$ \\bar{u}_{1}^{1} = \\frac{21 \\cdot 25}{4 \\cdot 25} + \\frac{51 \\cdot 4}{25 \\cdot 4} = \\frac{525}{100} + \\frac{204}{100} = \\frac{729}{100} $$\n\n- 分量 $\\bar{u}_2^1$：\n  $$ \\bar{u}_{2}^{1} = p_{1}\\,u_{2,1}^{1} + p_{2}\\,u_{2,2}^{1} = \\frac{7}{10} \\cdot \\frac{26}{3} + \\frac{3}{10} \\cdot \\frac{55}{3} $$\n  $$ \\bar{u}_{2}^{1} = \\frac{182}{30} + \\frac{165}{30} = \\frac{182 + 165}{30} = \\frac{347}{30} $$\n\n一次迭代后更新的平均发电计划为 $\\bar{u}^1 = (\\frac{729}{100}, \\frac{347}{30})$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{729}{100}  & \\frac{347}{30}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "惩罚参数 $\\rho$ 是逐步对冲算法的核心，它控制着场景特定最优性与非预见性约束之间的平衡。本练习通过分析 $\\rho$ 在两种极端情况下的行为——当 $\\rho$ 趋近于零和无穷大时——来探索其基本作用 。这种分析方法将揭示 $\\rho$ 是如何决定算法优先考虑单个场景解，还是强制执行严格的共识。",
            "id": "4114638",
            "problem": "考虑一个双情景随机能源采购模型，该模型具有单一的第一阶段决策变量 $q \\in \\mathbb{R}$，根据非预见性（nonanticipativity）原则，该变量在所有情景中必须相同。情景 $s \\in \\{1,2\\}$ 以已知概率 $p_{s} \\in (0,1)$ 发生，并具有一个凸二次运营成本\n$$\nF_{s}(q) \\;=\\; \\frac{1}{2} a_{s} q^{2} + b_{s} q,\n$$\n其中 $a_{s} \\in \\mathbb{R}_{>0}$ 和 $b_{s} \\in \\mathbb{R}$ 是给定系数，且 $p_{1}+p_{2}=1$。为通过情景分解强制实现非预见性，应用渐进对冲（Progressive Hedging, PH）方法。该方法将 $q$ 复制为 $(q_{1},q_{2})$，并通过一个共识变量 $z \\in \\mathbb{R}$ 和带有二次惩罚参数 $\\rho \\in \\mathbb{R}_{>0}$ 的情景乘子 $(u_{1},u_{2}) \\in \\mathbb{R}^{2}$ 将这些副本耦合起来。在迭代 $k \\in \\mathbb{N}$ 次时，PH 算法为每个情景 $s \\in \\{1,2\\}$ 求解无约束子问题\n$$\n\\min_{q_{s} \\in \\mathbb{R}} \\; F_{s}(q_{s}) \\;+\\; u_{s}^{k}\\left(q_{s}-z^{k}\\right) \\;+\\; \\frac{\\rho}{2}\\left(q_{s}-z^{k}\\right)^{2},\n$$\n然后通过概率加权平均来设定共识更新\n$$\nz^{k+1} \\;=\\; p_{1} q_{1}^{k+1} \\;+\\; p_{2} q_{2}^{k+1},\n$$\n并按如下方式更新乘子\n$$\nu_{s}^{k+1} \\;=\\; u_{s}^{k} \\;+\\; \\rho \\left(q_{s}^{k+1} - z^{k+1}\\right).\n$$\n假设标准初始化为 $u_{1}^{0}=u_{2}^{0}=0$ 和一个任意的 $z^{0} \\in \\mathbb{R}$，并考虑第一个 PH 迭代 $(k=0 \\to 1)$。从情景子问题的凸优化最优性第一原理和给定的 PH 更新规则出发，推导 $z^{1}$ 关于 $\\rho$, $a_{1}$, $a_{2}$, $b_{1}$, $b_{2}$, $p_{1}$, $p_{2}$ 和 $z^{0}$ 的闭式表达式。然后，计算两个极限值\n$$\n\\lim_{\\rho \\to 0} z^{1}\n\\quad \\text{和} \\quad\n\\lim_{\\rho \\to \\infty} z^{1},\n$$\n并根据独立情景解与在非预见性共识集上的投影来解释这些极限。\n\n以包含两个闭式极限的单行形式提供你的最终答案，顺序为 $\\left(\\lim_{\\rho \\to 0} z^{1}, \\; \\lim_{\\rho \\to \\infty} z^{1}\\right)$。无需四舍五入，也无需单位。你的答案必须是单一的解析表达式。",
            "solution": "该问题要求在一个用于双情景随机规划的渐进对冲（PH）方案中，推导第一次迭代的共识变量 $z^{1}$，并评估当惩罚参数 $\\rho$ 趋近于零和无穷大时的极限值。\n\n### 步骤 1：求解情景子问题\nPH 算法在迭代 $k=0$ 时开始，初始共识变量为 $z^{0} \\in \\mathbb{R}$，初始乘子为 $u_{1}^{0}=0$ 和 $u_{2}^{0}=0$。对于每个情景 $s \\in \\{1,2\\}$，我们求解一个无约束子问题来找到 $q_{s}^{1}$。情景 $s$ 的子问题是：\n$$\n\\min_{q_{s} \\in \\mathbb{R}} \\; F_{s}(q_{s}) \\;+\\; u_{s}^{0}\\left(q_{s}-z^{0}\\right) \\;+\\; \\frac{\\rho}{2}\\left(q_{s}-z^{0}\\right)^{2}\n$$\n给定成本函数 $F_{s}(q_{s}) = \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s}$ 和初始化条件 $u_{s}^{0}=0$，子问题的目标函数（我们记为 $L_{s}(q_{s})$）简化为：\n$$\nL_{s}(q_{s}) = \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s} + \\frac{\\rho}{2}\\left(q_{s}-z^{0}\\right)^{2}\n$$\n这是一个无约束凸优化问题。目标函数 $L_{s}(q_{s})$ 在 $q_{s}$ 上是严格凸的，因为系数 $a_{s}$ 和 $\\rho$ 被给定为严格正数（$a_{s} \\in \\mathbb{R}_{>0}$, $\\rho \\in \\mathbb{R}_{>0}$）。通过应用一阶最优性条件，即将 $L_{s}(q_{s})$ 关于 $q_{s}$ 的导数设为零，可以找到唯一的最小值。\n$$\n\\frac{d L_{s}}{d q_{s}} = \\frac{d}{d q_{s}} \\left( \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s} + \\frac{\\rho}{2}(q_{s}^{2} - 2q_{s}z^{0} + (z^{0})^{2}) \\right) = 0\n$$\n$$\na_{s} q_{s} + b_{s} + \\rho(q_{s}-z^{0}) = 0\n$$\n设 $q_{s}^{1}$ 为此方程的解。我们重排各项来求解 $q_{s}^{1}$：\n$$\n(a_{s} + \\rho) q_{s}^{1} + b_{s} - \\rho z^{0} = 0\n$$\n$$\n(a_{s} + \\rho) q_{s}^{1} = \\rho z^{0} - b_{s}\n$$\n$$\nq_{s}^{1} = \\frac{\\rho z^{0} - b_{s}}{a_{s} + \\rho}\n$$\n这为第一次迭代中每个特定情景的子问题提供了最优解。\n\n### 步骤 2：更新共识变量\nPH 算法的下一步是通过计算各个情景解 $q_{s}^{1}$ 的概率加权平均值来更新共识变量 $z$。$z^{1}$ 的更新规则是：\n$$\nz^{1} = p_{1} q_{1}^{1} + p_{2} q_{2}^{1}\n$$\n代入上一步推导出的 $q_{1}^{1}$ 和 $q_{2}^{1}$ 的表达式：\n$$\nz^{1} = p_{1} \\left( \\frac{\\rho z^{0} - b_{1}}{a_{1} + \\rho} \\right) + p_{2} \\left( \\frac{\\rho z^{0} - b_{2}}{a_{2} + \\rho} \\right)\n$$\n这就是所要求的 $z^{1}$ 的闭式表达式。\n\n### 步骤 3：计算 $\\rho \\to 0$ 时的极限\n我们首先计算当 $\\rho$ 趋近于 $0$ 时 $z^{1}$ 的极限。由于 $\\rho$ 被定义为正参数，我们实际上考虑的是从右侧趋近的极限，即 $\\rho \\to 0^{+}$。$z^{1}$ 的表达式是关于 $\\rho$ 的有理函数。由于 $a_{s} > 0$，分母 $a_{s}+\\rho$ 在 $\\rho=0$ 时不为零。因此，可以通过直接代入 $\\rho=0$ 来求得极限：\n$$\n\\lim_{\\rho \\to 0} z^{1} = \\lim_{\\rho \\to 0} \\left[ p_{1} \\left( \\frac{\\rho z^{0} - b_{1}}{a_{1} + \\rho} \\right) + p_{2} \\left( \\frac{\\rho z^{0} - b_{2}}{a_{2} + \\rho} \\right) \\right]\n$$\n$$\n\\lim_{\\rho \\to 0} z^{1} = p_{1} \\left( \\frac{0 \\cdot z^{0} - b_{1}}{a_{1} + 0} \\right) + p_{2} \\left( \\frac{0 \\cdot z^{0} - b_{2}}{a_{2} + 0} \\right) = p_{1} \\left( \\frac{-b_{1}}{a_{1}} \\right) + p_{2} \\left( \\frac{-b_{2}}{a_{2}} \\right)\n$$\n$$\n\\lim_{\\rho \\to 0} z^{1} = -\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)\n$$\n这个极限有一个清晰的解释。量 $q_{s}^{*} = -b_{s}/a_{s}$ 是 $\\min_{q} F_{s}(q)$ 的解，即如果情景 $s$ 确定会发生时的最优决策。因此，当对不一致的惩罚消失时（$\\rho \\to 0$），子问题变成对原始情景成本的解耦最小化。得到的共识变量 $z^{1}$ 是独立的、情景最优解的概率加权平均值。这代表了将个体最优解向量 $(q_{1}^{*}, q_{2}^{*})$ 投影到非预见性共识集上。\n\n### 步骤 4：计算 $\\rho \\to \\infty$ 时的极限\n接下来，我们计算当 $\\rho \\to \\infty$ 时 $z^{1}$ 的极限。为了评估这个极限，我们可以分析 $z^{1}$ 表达式中每一项的渐近行为。我们将每个分式的分子和分母都除以 $\\rho$：\n$$\nz^{1} = p_{1} \\left( \\frac{z^{0} - \\frac{b_{1}}{\\rho}}{\\frac{a_{1}}{\\rho} + 1} \\right) + p_{2} \\left( \\frac{z^{0} - \\frac{b_{2}}{\\rho}}{\\frac{a_{2}}{\\rho} + 1} \\right)\n$$\n现在，我们取 $\\rho \\to \\infty$ 的极限。当 $\\rho \\to \\infty$ 时，项 $\\frac{b_{s}}{\\rho}$ 和 $\\frac{a_{s}}{\\rho}$ 都趋近于 $0$。\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = \\lim_{\\rho \\to \\infty} \\left[ p_{1} \\left( \\frac{z^{0} - \\frac{b_{1}}{\\rho}}{\\frac{a_{1}}{\\rho} + 1} \\right) + p_{2} \\left( \\frac{z^{0} - \\frac{b_{2}}{\\rho}}{\\frac{a_{2}}{\\rho} + 1} \\right) \\right]\n$$\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = p_{1} \\left( \\frac{z^{0} - 0}{0 + 1} \\right) + p_{2} \\left( \\frac{z^{0} - 0}{0 + 1} \\right) = p_{1}z^{0} + p_{2}z^{0}\n$$\n利用 $p_{1} + p_{2} = 1$ 这一事实：\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = (p_{1} + p_{2}) z^{0} = 1 \\cdot z^{0} = z^{0}\n$$\n这个结果表明，当惩罚参数 $\\rho$ 变得无限大时，项 $\\frac{\\rho}{2}(q_{s} - z^{0})^{2}$ 在子问题目标中占主导地位。最小化这个主导项需要强制 $q_{s}^{1}$ 等于 $z^{0}$。因此，更新后的共识变量 $z^{1}$，作为所有值都等于 $z^{0}$ 的平均值，就等于 $z^{0}$。在这种情况下，算法无法从初始共识猜测中取得进展，因为偏离它的惩罚是压倒性的。在共识集上的投影是平凡的，因为子问题的解已经被强制与初始共识值一致。\n\n因此，两个极限值为 $-\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)$ 和 $z^{0}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)  & z^{0}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "尽管逐步对冲算法在处理连续问题时非常强大，但将其应用于混合整数问题（如机组组合）时会带来独特的挑战。本实践将探讨一个关键的陷阱：算法可能过早地收敛到一个次优的整数解，特别是当惩罚参数 $\\rho$ 选择不当时 。通过一个具体的例子，您将理解为什么过大的 $\\rho$ 会将算法锁定在一个次优的决策上，这揭示了在实际应用中需要重点关注的一个问题。",
            "id": "4114608",
            "problem": "考虑一个能源系统中单个火力发电机的两阶段随机机组组合模型。第 $0$ 阶段的启停决策是二元变量 $x \\in \\{0,1\\}$，其中 $x=1$ 表示发电机投入运行（可用），$x=0$ 表示未投入运行。在概率为 $p_s$ 的场景 $s \\in \\{1,2\\}$ 中，第 $1$ 阶段的发电决策 $q^s \\in [0,Q]$ 会产生可变成本 $c q^s$。如果需求 $D^s$ 未被完全满足，则对未满足的电量支付每兆瓦时 $U$ 的缺电惩罚。发电机容量为 $Q$，投入运行时有固定成本 $F$。假设 $Q \\ge \\max\\{D^1, D^2\\}$ 且 $c  U$。在这些条件下，如果 $x=1$，则最优发电调度为 $q^s = D^s$，场景成本为 $C_s(1) = F + c D^s$；而如果 $x=0$，则 $q^s = 0$，场景成本为 $C_s(0) = U D^s$。\n\n非预见性要求第 $0$ 阶段的决策在所有场景中保持一致。渐进对冲 (PH) 算法通过对带有增广拉格朗日量的场景子问题进行迭代来强制实现非预见性。在第 $k$ 次迭代中，给定场景乘子 $w_s^k$ 和当前的概率加权平均值 $\\bar x^k = \\sum_s p_s x_s^k$，场景 $s$ 的 PH 子问题通过最小化以下函数来选择 $x_s^{k+1} \\in \\{0,1\\}$：\n$$\nC_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}\\left(x_s - \\bar x^k\\right)^2,\n$$\n然后更新 $\\bar x^{k+1} = \\sum_s p_s x_s^{k+1}$ 和 $w_s^{k+1} = w_s^k + \\rho\\left(x_s^{k+1} - \\bar x^{k+1}\\right)$。\n\n取数值 $F = 3000$，$c = 50$，$U = 200$，$D^1 = 100$，$D^2 = 15$，$p_1 = 0.4$，$p_2 = 0.6$，且 $Q \\ge 100$。考虑一次 PH 迭代，其中 $w_1^k = w_2^k = 0$ 且 $\\bar x^k = 0$。使用第一性原理和以上定义：\n\n- 推导惩罚参数 $\\rho$ 如何通过二次邻近项与二元启停决策相互作用，并将选择 $x_s=1$ 与选择 $x_s=0$ 之间的邻近惩罚差异表示为 $\\rho$ 和 $\\bar x^k$ 的函数。\n- 确定真实的非预见性最优启停决策 $x$ 及其期望成本。\n- 证明在 $\\bar x^k=0$ 时，对于满足 $C_s(1) - C_s(0)  0$ 的场景，在 $\\rho$ 的何种阈值条件下，该场景仍会选择 $x_s^{k+1}=0$，并解释为何在混合整数决策的 PH 算法中，过大的 $\\rho$ 会迫使算法过早地收敛到一个次优的整数模式。\n\n下列哪些陈述是正确的？\n\nA. 在 $\\bar x^k = 0$ 时，如果 $\\rho > 12000$，场景 $1$ 会选择 $x_1^{k+1} = 0$，从而强制在 $x=0$ 处达成共识，尽管期望最优解是 $x=1$。\n\nB. 对于二元变量 $x \\in \\{0,1\\}$，在给定的 $\\bar x$下，选择 $x=1$ 与选择 $x=0$ 之间的渐进对冲邻近惩罚差异等于 $\\frac{\\rho}{2}\\left(1 - 2\\bar x\\right)$，这相当于一个添加到场景目标中的、与场景无关的转换成本。\n\nC. 根据给定数据，期望的非预见性最优解是 $x=1$，其期望成本为 $5450$。但在 $\\bar x^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$，从而在一个次优的整数模式上过早地达成共识。\n\nD. 渐进对冲惩罚项是 $\\rho\\,\\lvert x_s - \\bar x^k\\rvert$，因此对于二元变量 $x$，其在 $\\bar x^k=0$ 和 $\\bar x^k=1$ 时的效果是相同的。\n\nE. 在处理混合整数决策的渐进对冲算法中，取 $\\rho \\to \\infty$ 可以保证收敛到全局最优的非预见性解，因为惩罚项中和了所有偏差。\n\n选择所有适用项。",
            "solution": "用户提供了一个关于渐进对冲 (PH) 算法应用于两阶段随机机组组合问题的问题陈述。任务是验证问题，从第一性原理推导解决方案，并评估给定的选项。\n\n### 问题验证\n\n首先，我将提取已知条件并验证问题陈述。\n\n**步骤 1：提取已知条件**\n- **模型：** 单个火力发电机的两阶段随机机组组合模型。\n- **第0阶段决策：** 二元启停决策 $x \\in \\{0, 1\\}$。\n- **场景：** $s \\in \\{1, 2\\}$，概率为 $p_s$。\n- **第1阶段决策：** 发电量 $q^s \\in [0, Q]$。\n- **成本：** 可变成本 $c q^s$，对未满足需求的缺电惩罚为 $U$/MWh，若 $x=1$ 则有固定成本 $F$。\n- **参数：** 容量 $Q$，需求 $D^s$。\n- **假设：** $Q \\ge \\max\\{D^1, D^2\\}$, $c  U$。\n- **推导出的场景成本：**\n    - 若 $x=1$，成本为 $C_s(1) = F + c D^s$。\n    - 若 $x=0$，成本为 $C_s(0) = U D^s$。\n- **渐进对冲 (PH) 算法：**\n    - **第 k+1 次迭代中场景 s 的子问题：** 选择 $x_s^{k+1} \\in \\{0, 1\\}$ 以最小化 $C_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$。\n    - **变量更新：**\n        - $\\bar{x}^{k+1} = \\sum_s p_s x_s^{k+1}$\n        - $w_s^{k+1} = w_s^k + \\rho(x_s^{k+1} - \\bar{x}^{k+1})$\n- **数值数据：**\n    - $F = 3000$\n    - $c = 50$\n    - $U = 200$\n    - $D^1 = 100$\n    - $D^2 = 15$\n    - $p_1 = 0.4$\n    - $p_2 = 0.6$\n    - $Q \\ge 100$\n- **初始 PH 状态：** $w_1^k = w_2^k = 0$, $\\bar{x}^k = 0$。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，是渐进对冲算法在能源系统建模中一个著名问题（随机机组组合）上的标准应用。假设 ($c  U$) 是标准的，确保了发电逻辑是直接的（生产总是比承担惩罚更便宜）。所提供的成本函数 $C_s(x)$ 是基于这些假设的正确推导。PH 算法的数学表述是标准的。该问题是适定的、客观的、自洽的，没有矛盾。\n\n**步骤 3：结论与行动**\n问题陈述是**有效的**。我将继续进行推导和分析。\n\n### 解题推导\n\n解题过程将分为三个部分：首先，确定真实的非预见性最优解；其次，分析给定迭代中 PH 算法的行为；第三，评估每个选项。\n\n**第一部分：真实的非预见性最优解**\n\n真实问题是找到 $x \\in \\{0, 1\\}$ 以最小化期望成本 $\\mathbb{E}[C(x)] = \\sum_s p_s C_s(x)$。\n\n首先，使用给定数据计算 $x \\in \\{0, 1\\}$ 和 $s \\in \\{1, 2\\}$ 的场景成本 $C_s(x)$：\n- $F = 3000$, $c = 50$, $U = 200$, $D^1 = 100$, $D^2 = 15$。\n\n对于场景 $s=1$：\n- 投入运行的成本 ($x=1$)：$C_1(1) = F + c D^1 = 3000 + 50 \\times 100 = 3000 + 5000 = 8000$。\n- 未投入运行的成本 ($x=0$)：$C_1(0) = U D^1 = 200 \\times 100 = 20000$。\n\n对于场景 $s=2$：\n- 投入运行的成本 ($x=1$)：$C_2(1) = F + c D^2 = 3000 + 50 \\times 15 = 3000 + 750 = 3750$。\n- 未投入运行的成本 ($x=0$)：$C_2(0) = U D^2 = 200 \\times 15 = 3000$。\n\n接下来，使用概率 $p_1 = 0.4$ 和 $p_2 = 0.6$ 计算每个非预见性决策 $x \\in \\{0, 1\\}$ 的期望成本：\n- $x=1$ 的期望成本：\n$$ \\mathbb{E}[C(1)] = p_1 C_1(1) + p_2 C_2(1) = 0.4 \\times 8000 + 0.6 \\times 3750 = 3200 + 2250 = 5450 $$\n- $x=0$ 的期望成本：\n$$ \\mathbb{E}[C(0)] = p_1 C_1(0) + p_2 C_2(0) = 0.4 \\times 20000 + 0.6 \\times 3000 = 8000 + 1800 = 9800 $$\n\n比较期望成本，$\\mathbb{E}[C(1)] = 5450  \\mathbb{E}[C(0)] = 9800$。因此，真实的非预见性最优启停决策是 $x=1$，其期望成本为 $5450$。\n\n**第二部分：渐进对冲迭代分析**\n\n场景 $s$ 的 PH 子问题旨在找到 $x_s^{k+1} \\in \\{0, 1\\}$ 以最小化增广成本函数：\n$$ J_s(x_s) = C_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2 $$\n我们已知迭代开始时的状态：$w_1^k = 0$，$w_2^k = 0$，以及 $\\bar{x}^k = 0$。目标函数简化为：\n$$ J_s(x_s) = C_s(x_s) + (0) \\cdot x_s + \\frac{\\rho}{2}(x_s - 0)^2 = C_s(x_s) + \\frac{\\rho}{2}x_s^2 $$\n由于 $x_s$ 是二元变量，$x_s \\in \\{0, 1\\}$，我们有 $x_s^2 = x_s$。目标函数进一步简化为：\n$$ J_s(x_s) = C_s(x_s) + \\frac{\\rho}{2}x_s $$\n为了找到最优的 $x_s^{k+1}$，我们比较 $x_s=0$ 和 $x_s=1$ 时的目标函数值：\n- $x_s=0$ 时的值：$J_s(0) = C_s(0) + \\frac{\\rho}{2}(0) = C_s(0)$。\n- $x_s=1$ 时的值：$J_s(1) = C_s(1) + \\frac{\\rho}{2}(1) = C_s(1) + \\frac{\\rho}{2}$。\n\n如果 $J_s(1)  J_s(0)$，子问题将选择 $x_s^{k+1}=1$，即 $C_s(1) + \\frac{\\rho}{2}  C_s(0)$。整理后，选择 $x_s^{k+1}=1$ 的条件是：\n$$ C_s(1) - C_s(0)  -\\frac{\\rho}{2} $$\n否则，将选择 $x_s^{k+1}=0$。\n\n现在，我们将此条件应用于每个场景：\n- **场景 1：** $C_1(1) - C_1(0) = 8000 - 20000 = -12000$。\n  选择 $x_1^{k+1}=1$ 的条件是 $-12000  -\\frac{\\rho}{2}$，化简为 $12000 > \\frac{\\rho}{2}$，或 $\\rho  24000$。\n  因此，对于场景 1，如果 $\\rho > 24000$，将选择 $x_1^{k+1}=0$。\n\n- **场景 2：** $C_2(1) - C_2(0) = 3750 - 3000 = 750$。\n  选择 $x_2^{k+1}=1$ 的条件是 $750  -\\frac{\\rho}{2}$。由于 $\\rho > 0$，右侧为负。此不等式永远无法满足。\n  因此，对于场景 2，在本次迭代中，对于任何 $\\rho > 0$，都将选择 $x_2^{k+1}=0$。\n\n此分析表明，如果 $\\rho > 24000$，两个场景都将决定 $x_1^{k+1}=0$ 和 $x_2^{k+1}=0$。这导致在次优解 $x=0$ 处达成共识（$\\bar{x}^{k+1}=0$）。算法随后会陷入困境，因为残差 $x_s^{k+1} - \\bar{x}^{k+1}$ 将为零，导致乘子 $w_s$ 不再更新，下一次迭代将从相同的状态开始。\n\n**第三部分：逐项分析**\n\n**A. 在 $\\bar x^k = 0$ 时，如果 $\\rho > 12000$，场景 $1$ 会选择 $x_1^{k+1} = 0$，从而强制在 $x=0$ 处达成共识，尽管期望最优解是 $x=1$。**\n如第二部分推导所示，场景 1 在 $\\rho > 24000$ 时选择 $x_1^{k+1}=0$。$\\rho > 12000$ 这个阈值是错误的。尽管对于足够大的 $\\rho$，其所描述的后果（强制在次优解 $x=0$ 处达成共识）是正确的，但具体条件是错误的。\n**结论：错误**\n\n**B. 对于二元变量 $x \\in \\{0,1\\}$，在给定的 $\\bar x$下，选择 $x=1$ 与选择 $x=0$ 之间的渐进对冲邻近惩罚差异等于 $\\frac{\\rho}{2}\\left(1 - 2\\bar x\\right)$，这相当于一个添加到场景目标中的、与场景无关的转换成本。**\n邻近惩罚项是 $P(x_s) = \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$。我们来计算 $x_s=1$ 与 $x_s=0$ 之间的差异：\n$$ P(1) - P(0) = \\frac{\\rho}{2}(1 - \\bar{x}^k)^2 - \\frac{\\rho}{2}(0 - \\bar{x}^k)^2 = \\frac{\\rho}{2}\\left[ (1 - 2\\bar{x}^k + (\\bar{x}^k)^2) - (\\bar{x}^k)^2 \\right] = \\frac{\\rho}{2}(1 - 2\\bar{x}^k) $$\n数学表达式是正确的。为了理解其作用，考虑完整的决策准则：如果总成本更低，则选择 $x_s=1$ 而非 $x_s=0$。总成本的差异是 $\\Delta J_s = (C_s(1) - C_s(0)) + w_s^k + (P(1) - P(0))$。$\\frac{\\rho}{2}(1 - 2\\bar{x}^k)$ 这一项修改了选择 $x_s=1$ 和 $x_s=0$ 之间的成本差异。该项与场景 $s$ 无关，仅取决于 $\\rho$ 和当前的平均值 $\\bar{x}^k$。因此，它起到了一个对所有场景都共同的、选择 $x_s=1$ 的“转换成本”（或收益）的作用，从而推动它们达成共识。这个解释是合理的。\n**结论：正确**\n\n**C. 根据给定数据，期望的非预见性最优解是 $x=1$，其期望成本为 $5450$。但在 $\\bar x^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$，从而在一个次优的整数模式上过早地达成共识。**\n这个陈述是三个主张的组合。\n1. “期望的非预见性最优解是 $x=1$，其期望成本为 $5450$”。如第一部分所示，这是正确的。\n2. “在 $\\bar x^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$”。如第二部分所示，对于场景 1，如果 $\\rho > 24000$，则选择 $x_1^{k+1}=0$。由于 $30000 > 24000$，此条件成立。对于场景 2，对于任何 $\\rho > 0$，都选择 $x_2^{k+1}=0$。因此，两个场景都选择 $x_s^{k+1}=0$。这是正确的。\n3. “从而在一个次优的整数模式上过早地达成共识”。共识在 $x=0$ 处达成，而最优解是 $x=1$。这是一个在第一次正式迭代中就达成的次优共识。这个主张也是正确的。\n由于陈述的所有部分都为真，因此整个陈述是正确的。\n**结论：正确**\n\n**D. 渐进对冲惩罚项是 $\\rho\\,\\lvert x_s - \\bar x^k\\rvert$，因此对于二元变量 $x$，其在 $\\bar x^k=0$ 和 $\\bar x^k=1$ 时的效果是相同的。**\n这个前提是错误的。问题陈述正确地将标准的 PH 惩罚项定义为二次项 $\\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$，而不是 L1 范数 $\\rho|x_s - \\bar{x}^k|$。该陈述以一个相对于问题定义而言不符合事实的公式开始。\n**结论：错误**\n\n**E. 在处理混合整数决策的渐进对冲算法中，取 $\\rho \\to \\infty$ 可以保证收敛到全局最优的非预见性解，因为惩罚项中和了所有偏差。**\n这是一个关于 PH 应用于混合整数规划 (MIP) 问题的普遍性论断。众所周知，PH 算法是用于解决像混合整数规划这类非凸问题的启发式算法，并不保证收敛到全局最优解。一个非常大的 $\\rho$ 会严重惩罚非共识，常常在对偶乘子 ($w_s$) 能够引导搜索朝向真实最优解之前，就迫使所有整数变量在一个次优模式上达成一致。我们当前的问题提供了一个直接的反例：对于任何 $\\rho > 24000$，算法都会收敛到次优解 $x=0$。因此，取 $\\rho \\to \\infty$ 并不能保证最优性。\n**结论：错误**",
            "answer": "$$\\boxed{BC}$$"
        }
    ]
}