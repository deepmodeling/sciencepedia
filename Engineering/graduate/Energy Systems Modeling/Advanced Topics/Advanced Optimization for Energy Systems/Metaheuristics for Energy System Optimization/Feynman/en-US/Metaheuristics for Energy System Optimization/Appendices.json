{
    "hands_on_practices": [
        {
            "introduction": "Simulated Annealing (SA) is a powerful trajectory-based metaheuristic inspired by the physical process of annealing in metallurgy. The core of its ability to escape local optima lies in the Metropolis acceptance criterion, which allows the algorithm to stochastically accept non-improving solutions. This practice isolates this fundamental mechanism, providing a hands-on calculation of acceptance probabilities to build an intuitive understanding of how temperature $T$ and the objective change $\\Delta E$ govern the search process .",
            "id": "4103172",
            "problem": "Consider a unit commitment and economic dispatch toy model over four discrete time periods for three thermal generators. Let the net demand profile be $D_{t}$ for $t \\in \\{1,2,3,4\\}$, with $D_{t}$ given as $[120,140,160,130]$ megawatts. Each generator $i \\in \\{1,2,3\\}$ has a convex quadratic production cost in period $t$, $C_{i}(P_{i,t}) = \\alpha_{i} P_{i,t}^{2} + \\beta_{i} P_{i,t} + \\gamma_{i}$, with coefficients $(\\alpha_{1},\\beta_{1},\\gamma_{1})=(2.0 \\times 10^{-3},18,120)$, $(\\alpha_{2},\\beta_{2},\\gamma_{2})=(1.6 \\times 10^{-3},22,100)$, and $(\\alpha_{3},\\beta_{3},\\gamma_{3})=(2.4 \\times 10^{-3},16,130)$. At each period, load balance is penalized quadratically by a term $\\lambda \\left(\\sum_{i=1}^{3} P_{i,t} - D_{t}\\right)^{2}$ with $\\lambda=0.06$, and the multi-period objective is the sum over periods of production cost plus the load-balance penalty. Assume nameplate capacities and ramp-rate constraints are satisfied and need not be enforced explicitly for this question.\n\nYou are at a current feasible dispatch $x^{(k)}$ and apply Simulated Annealing (SA) with the Metropolis acceptance mechanism grounded in the Boltzmann distribution. Three single-move proposals are generated and evaluated against the multi-period objective, yielding objective changes $\\Delta E$ for the proposed new states relative to $x^{(k)}$. The temperature is fixed at $T=5$ in the same cost units as the objective. For the three proposals, the objective changes and independent uniform random variates used for the acceptance test are\n$$\n\\Delta E_{1} = 3.2, \\quad \\Delta E_{2} = -1.0, \\quad \\Delta E_{3} = 7.5,\n$$\nand\n$$\nu_{1} = 0.20, \\quad u_{2} = 0.70, \\quad u_{3} = 0.80,\n$$\nrespectively.\n\nUsing first principles that connect the Boltzmann distribution to the Metropolis acceptance criterion, determine the acceptance decisions for the three proposals, encoded as $a_{j} \\in \\{0,1\\}$ for $j \\in \\{1,2,3\\}$, where $a_{j}=1$ denotes accept and $a_{j}=0$ denotes reject. Express your final answer as a row matrix $\\begin{pmatrix} a_{1} & a_{2} & a_{3} \\end{pmatrix}$. No rounding is required, and the entries are dimensionless indicators.",
            "solution": "The problem asks for the acceptance decisions for three proposed moves in a Simulated Annealing (SA) optimization process, based on the Metropolis acceptance criterion. The context is an energy system economic dispatch model, but the core task only requires the change in the objective function ($\\Delta E$), the system temperature ($T$), and a random number ($u$) for each proposal.\n\nThe Metropolis acceptance criterion is derived from the principles of statistical mechanics, specifically the Boltzmann distribution, which states that at thermal equilibrium, the probability of a system being in a state with energy $E$ is proportional to the Boltzmann factor, $\\exp(-E/T)$, where $T$ is the temperature (in energy units, as $k_B$ is absorbed). In SA, the objective function $E$ is analogous to energy. The algorithm seeks to find a low-energy (low-cost) state by stochastically exploring the state space.\n\nA move from a current state with objective value $E_{k}$ to a proposed new state with objective value $E_{new}$ results in a change $\\Delta E = E_{new} - E_{k}$. The Metropolis criterion determines whether to accept this move. The rule is implemented as follows:\n\n$1$. If the move leads to a decrease in the objective function ($\\Delta E < 0$), the move is always accepted. This corresponds to moving to a better solution.\n$2$. If the move leads to an increase in the objective function ($\\Delta E \\ge 0$), the move is accepted with a probability $P_{acc} = \\exp(-\\frac{\\Delta E}{T})$. This allows the algorithm to escape local minima by occasionally accepting worse solutions.\n\nA unified way to express this rule is to generate a uniform random number $u \\in [0, 1)$ and accept the move if $u < \\exp(-\\frac{\\Delta E}{T})$.\nIf $\\Delta E < 0$, then $-\\frac{\\Delta E}{T} > 0$, which means $\\exp(-\\frac{\\Delta E}{T}) > 1$. Since $u$ is always less than $1$, the condition is always satisfied, and the move is accepted.\nIf $\\Delta E \\ge 0$, then $-\\frac{\\Delta E}{T} \\le 0$, which means $\\exp(-\\frac{\\Delta E}{T}) \\in (0, 1]$. The move is accepted if the random number $u$ falls below this probability value.\n\nThe problem provides the temperature $T=5$ and the data for three proposals. We apply the acceptance criterion to each. An acceptance decision is encoded as $a_j=1$ and a rejection as $a_j=0$.\n\n**Proposal 1:**\n- Change in objective function: $\\Delta E_{1} = 3.2$.\n- Random number: $u_{1} = 0.20$.\n- Since $\\Delta E_{1} > 0$, this is a non-improving move. The acceptance depends on the probability check.\n- We must check if $u_{1} < \\exp(-\\frac{\\Delta E_{1}}{T})$.\n- The condition is $0.20 < \\exp(-\\frac{3.2}{5}) = \\exp(-0.64)$.\n- To verify this inequality without calculating the exponential, we can take the natural logarithm of both sides. As $\\ln(x)$ is a strictly increasing function for $x>0$, the inequality is preserved: $\\ln(0.20) < -0.64$.\n- The natural logarithm of a number less than $1$ is negative. We know $\\ln(1/e) = \\ln(\\exp(-1)) = -1$. Since $0.20$ is less than $1/e \\approx 0.3678$, its logarithm $\\ln(0.20)$ will be less than $-1$.\n- Specifically, $\\ln(0.20) = \\ln(1/5) = -\\ln(5) \\approx -1.609$.\n- The condition is $-1.609 < -0.64$, which is true.\n- Therefore, the condition $u_{1} < \\exp(-\\frac{\\Delta E_{1}}{T})$ is met. The move is accepted.\n- $a_{1} = 1$.\n\n**Proposal 2:**\n- Change in objective function: $\\Delta E_{2} = -1.0$.\n- Random number: $u_{2} = 0.70$.\n- Since $\\Delta E_{2} < 0$, this is an improving move. According to the Metropolis criterion, it must always be accepted.\n- Let's verify this using the unified rule: check if $u_{2} < \\exp(-\\frac{\\Delta E_{2}}{T})$.\n- The condition is $0.70 < \\exp(-\\frac{-1.0}{5}) = \\exp(0.2)$.\n- Since the argument of the exponential function, $0.2$, is positive, $\\exp(0.2) > 1$.\n- Any random number $u \\in [0, 1)$ will be less than a value greater than $1$.\n- The condition $0.70 < \\exp(0.2)$ is true. The move is accepted.\n- $a_{2} = 1$.\n\n**Proposal 3:**\n- Change in objective function: $\\Delta E_{3} = 7.5$.\n- Random number: $u_{3} = 0.80$.\n- Since $\\Delta E_{3} > 0$, this is a non-improving move.\n- We must check if $u_{3} < \\exp(-\\frac{\\Delta E_{3}}{T})$.\n- The condition is $0.80 < \\exp(-\\frac{7.5}{5}) = \\exp(-1.5)$.\n- Again, we can compare the logarithms: $\\ln(0.80) < -1.5$?\n- We know that $\\ln(0.80) \\approx -0.223$.\n- The condition becomes $-0.223 < -1.5$, which is false.\n- Therefore, the condition $u_{3} < \\exp(-\\frac{\\Delta E_{3}}{T})$ is not met. The move is rejected.\n- $a_{3} = 0$.\n\nCombining the decisions for the three proposals, we get the acceptance vector $(a_{1}, a_{2}, a_{3}) = (1, 1, 0)$.\nThe final answer is presented as a row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 1 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Particle Swarm Optimization (PSO) is a population-based algorithm that draws inspiration from the collective intelligence of social organisms like bird flocks. Each candidate solution, or 'particle,' navigates the search space by adjusting its velocity based on its own experience and the swarm's collective knowledge. This exercise focuses on the core kinematic update rules of PSO, demystifying how the interplay between inertia, cognitive attraction, and social attraction guides the swarm's exploration and how simple projection can be used to handle constraints .",
            "id": "4103138",
            "problem": "Consider a simplified Optimal Power Flow (OPF)-like continuous optimization problem for a two-generator system with decision vector $\\mathbf{p} = (p_{1}, p_{2})$ representing active power outputs. The penalized objective combines a quadratic generation cost and quadratic penalties for power balance and a single line flow under a Direct Current (DC) power flow approximation: $$J(\\mathbf{p}) = \\sum_{i=1}^{2} \\left( a_{i} p_{i}^{2} + b_{i} p_{i} \\right) + \\lambda \\left( p_{1} + p_{2} - D \\right)^{2} + \\mu \\left( h_{1} p_{1} + h_{2} p_{2} - F_{\\max} \\right)^{2},$$ where $a_{1} = 0.005$, $a_{2} = 0.008$, $b_{1} = 12$, $b_{2} = 15$, $D = 220$, $\\lambda = 0.2$, $\\mu = 0.05$, $\\mathbf{h} = (h_{1}, h_{2}) = (0.8, -0.5)$, and $F_{\\max} = 70$. The box constraints for generator outputs are $p_{1} \\in [50, 250]$ and $p_{2} \\in [20, 150]$, and the Euclidean projection onto this box is understood componentwise by clamping any out-of-range component to the nearest bound.\n\nYou are asked to perform one iteration of Particle Swarm Optimization (PSO), defined by inertia, cognitive, and social components, for two particles. The algorithmic hyperparameters are inertia weight $w = 0.6$, cognitive coefficient $c_{1} = 1.7$, and social coefficient $c_{2} = 3.0$. The particles (labeled $A$ and $B$) have current positions, velocities, and personal bests as follows:\n- Particle $A$: $\\mathbf{x}_{A}^{t} = (120, 80)$, $\\mathbf{v}_{A}^{t} = (5, -50)$, $\\mathbf{pbest}_{A} = (130, 70)$.\n- Particle $B$: $\\mathbf{x}_{B}^{t} = (160, 40)$, $\\mathbf{v}_{B}^{t} = (-4, 6)$, $\\mathbf{pbest}_{B} = (150, 50)$.\nThe common global best is $\\mathbf{gbest} = (210, 60)$.\n\nUse the standard interpretation of Particle Swarm Optimization (PSO) where each particleâ€™s velocity is updated using its inertia, attraction to its personal best, and attraction to the global best, with independent uniform random multipliers. For this iteration, take the random scalars for particle $A$ as $r_{1,A} = 0.3$ and $r_{2,A} = 0.9$, and for particle $B$ as $r_{1,B} = 0.8$ and $r_{2,B} = 1.0$. After computing the updated velocities and positions, project the new positions onto the box constraints as defined above.\n\nReport, in order, the eight numbers comprising the updated velocity components and the projected updated positions for particle $A$ followed by particle $B$, i.e., $\\left(v_{A,1}^{t+1}, v_{A,2}^{t+1}, x_{A,1}^{t+1,\\mathrm{proj}}, x_{A,2}^{t+1,\\mathrm{proj}}, v_{B,1}^{t+1}, v_{B,2}^{t+1}, x_{B,1}^{t+1,\\mathrm{proj}}, x_{B,2}^{t+1,\\mathrm{proj}}\\right)$. Round every reported number to four significant figures. Express the final numerical answer as a single row vector using the LaTeX $\\mathrm{pmatrix}$ environment, with no units.",
            "solution": "The user has provided a well-posed problem that requires a single iteration of the Particle Swarm Optimization (PSO) algorithm for two particles in a two-dimensional search space. The problem is validated as sound, complete, and devoid of scientific or logical flaws. The objective function $J(\\mathbf{p})$ is provided for context but is not necessary for solving the posed question, which focuses solely on the kinematic update step of the algorithm (velocity and position updates).\n\nThe standard PSO update equations for a particle $i$ at iteration $t$ are given by:\nVelocity update:\n$$ \\mathbf{v}_{i}^{t+1} = w \\mathbf{v}_{i}^{t} + c_{1} r_{1,i} (\\mathbf{pbest}_{i} - \\mathbf{x}_{i}^{t}) + c_{2} r_{2,i} (\\mathbf{gbest} - \\mathbf{x}_{i}^{t}) $$\nPosition update:\n$$ \\mathbf{x}_{i}^{t+1} = \\mathbf{x}_{i}^{t} + \\mathbf{v}_{i}^{t+1} $$\nwhere $\\mathbf{v}$ is the velocity vector, $\\mathbf{x}$ is the position vector (equivalent to the decision vector $\\mathbf{p}$), $w$ is the inertia weight, $c_1$ and $c_2$ are the cognitive and social coefficients, $r_{1,i}$ and $r_{2,i}$ are random numbers, $\\mathbf{pbest}_{i}$ is the personal best position of particle $i$, and $\\mathbf{gbest}$ is the global best position found by any particle.\n\nThe problem specifies the following hyperparameters: $w = 0.6$, $c_{1} = 1.7$, and $c_{2} = 3.0$. The box constraints for the positions are $p_1 \\in [50, 250]$ and $p_2 \\in [20, 150]$.\n\nWe will now compute the updated velocity and position for each particle and then project the new position onto the specified box constraints.\n\n**Particle A: Update Calculation**\n\nThe initial state and random numbers for particle A are:\n-   Current position: $\\mathbf{x}_{A}^{t} = \\begin{pmatrix} 120 \\\\ 80 \\end{pmatrix}$\n-   Current velocity: $\\mathbf{v}_{A}^{t} = \\begin{pmatrix} 5 \\\\ -50 \\end{pmatrix}$\n-   Personal best position: $\\mathbf{pbest}_{A} = \\begin{pmatrix} 130 \\\\ 70 \\end{pmatrix}$\n-   Global best position: $\\mathbf{gbest} = \\begin{pmatrix} 210 \\\\ 60 \\end{pmatrix}$\n-   Random scalars: $r_{1,A} = 0.3$, $r_{2,A} = 0.9$\n\nFirst, we update the velocity $\\mathbf{v}_{A}^{t+1}$:\n$$ \\mathbf{v}_{A}^{t+1} = (0.6) \\mathbf{v}_{A}^{t} + (1.7)(0.3)(\\mathbf{pbest}_{A} - \\mathbf{x}_{A}^{t}) + (3.0)(0.9)(\\mathbf{gbest} - \\mathbf{x}_{A}^{t}) $$\n$$ \\mathbf{v}_{A}^{t+1} = 0.6 \\begin{pmatrix} 5 \\\\ -50 \\end{pmatrix} + 0.51\\left( \\begin{pmatrix} 130 \\\\ 70 \\end{pmatrix} - \\begin{pmatrix} 120 \\\\ 80 \\end{pmatrix} \\right) + 2.7\\left( \\begin{pmatrix} 210 \\\\ 60 \\end{pmatrix} - \\begin{pmatrix} 120 \\\\ 80 \\end{pmatrix} \\right) $$\n$$ \\mathbf{v}_{A}^{t+1} = \\begin{pmatrix} 3 \\\\ -30 \\end{pmatrix} + 0.51 \\begin{pmatrix} 10 \\\\ -10 \\end{pmatrix} + 2.7 \\begin{pmatrix} 90 \\\\ -20 \\end{pmatrix} $$\n$$ \\mathbf{v}_{A}^{t+1} = \\begin{pmatrix} 3 \\\\ -30 \\end{pmatrix} + \\begin{pmatrix} 5.1 \\\\ -5.1 \\end{pmatrix} + \\begin{pmatrix} 243 \\\\ -54 \\end{pmatrix} $$\n$$ \\mathbf{v}_{A}^{t+1} = \\begin{pmatrix} 3 + 5.1 + 243 \\\\ -30 - 5.1 - 54 \\end{pmatrix} = \\begin{pmatrix} 251.1 \\\\ -89.1 \\end{pmatrix} $$\nNext, we update the position $\\mathbf{x}_{A}^{t+1}$:\n$$ \\mathbf{x}_{A}^{t+1} = \\mathbf{x}_{A}^{t} + \\mathbf{v}_{A}^{t+1} = \\begin{pmatrix} 120 \\\\ 80 \\end{pmatrix} + \\begin{pmatrix} 251.1 \\\\ -89.1 \\end{pmatrix} = \\begin{pmatrix} 371.1 \\\\ -9.1 \\end{pmatrix} $$\nFinally, we project the new position $\\mathbf{x}_{A}^{t+1}$ onto the box constraints $p_1 \\in [50, 250]$ and $p_2 \\in [20, 150]$:\n$$ x_{A,1}^{t+1, \\mathrm{proj}} = \\max(50, \\min(371.1, 250)) = 250 $$\n$$ x_{A,2}^{t+1, \\mathrm{proj}} = \\max(20, \\min(-9.1, 150)) = 20 $$\nSo, the projected position is $\\mathbf{x}_{A}^{t+1, \\mathrm{proj}} = \\begin{pmatrix} 250 \\\\ 20 \\end{pmatrix}$.\n\n**Particle B: Update Calculation**\n\nThe initial state and random numbers for particle B are:\n-   Current position: $\\mathbf{x}_{B}^{t} = \\begin{pmatrix} 160 \\\\ 40 \\end{pmatrix}$\n-   Current velocity: $\\mathbf{v}_{B}^{t} = \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix}$\n-   Personal best position: $\\mathbf{pbest}_{B} = \\begin{pmatrix} 150 \\\\ 50 \\end{pmatrix}$\n-   Global best position: $\\mathbf{gbest} = \\begin{pmatrix} 210 \\\\ 60 \\end{pmatrix}$\n-   Random scalars: $r_{1,B} = 0.8$, $r_{2,B} = 1.0$\n\nFirst, we update the velocity $\\mathbf{v}_{B}^{t+1}$:\n$$ \\mathbf{v}_{B}^{t+1} = (0.6) \\mathbf{v}_{B}^{t} + (1.7)(0.8)(\\mathbf{pbest}_{B} - \\mathbf{x}_{B}^{t}) + (3.0)(1.0)(\\mathbf{gbest} - \\mathbf{x}_{B}^{t}) $$\n$$ \\mathbf{v}_{B}^{t+1} = 0.6 \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix} + 1.36\\left( \\begin{pmatrix} 150 \\\\ 50 \\end{pmatrix} - \\begin{pmatrix} 160 \\\\ 40 \\end{pmatrix} \\right) + 3.0\\left( \\begin{pmatrix} 210 \\\\ 60 \\end{pmatrix} - \\begin{pmatrix} 160 \\\\ 40 \\end{pmatrix} \\right) $$\n$$ \\mathbf{v}_{B}^{t+1} = \\begin{pmatrix} -2.4 \\\\ 3.6 \\end{pmatrix} + 1.36 \\begin{pmatrix} -10 \\\\ 10 \\end{pmatrix} + 3.0 \\begin{pmatrix} 50 \\\\ 20 \\end{pmatrix} $$\n$$ \\mathbf{v}_{B}^{t+1} = \\begin{pmatrix} -2.4 \\\\ 3.6 \\end{pmatrix} + \\begin{pmatrix} -13.6 \\\\ 13.6 \\end{pmatrix} + \\begin{pmatrix} 150 \\\\ 60 \\end{pmatrix} $$\n$$ \\mathbf{v}_{B}^{t+1} = \\begin{pmatrix} -2.4 - 13.6 + 150 \\\\ 3.6 + 13.6 + 60 \\end{pmatrix} = \\begin{pmatrix} 134 \\\\ 77.2 \\end{pmatrix} $$\nNext, we update the position $\\mathbf{x}_{B}^{t+1}$:\n$$ \\mathbf{x}_{B}^{t+1} = \\mathbf{x}_{B}^{t} + \\mathbf{v}_{B}^{t+1} = \\begin{pmatrix} 160 \\\\ 40 \\end{pmatrix} + \\begin{pmatrix} 134 \\\\ 77.2 \\end{pmatrix} = \\begin{pmatrix} 294 \\\\ 117.2 \\end{pmatrix} $$\nFinally, we project the new position $\\mathbf{x}_{B}^{t+1}$ onto the box constraints:\n$$ x_{B,1}^{t+1, \\mathrm{proj}} = \\max(50, \\min(294, 250)) = 250 $$\n$$ x_{B,2}^{t+1, \\mathrm{proj}} = \\max(20, \\min(117.2, 150)) = 117.2 $$\nSo, the projected position is $\\mathbf{x}_{B}^{t+1, \\mathrm{proj}} = \\begin{pmatrix} 250 \\\\ 117.2 \\end{pmatrix}$.\n\n**Final Result Assembly**\n\nThe requested output is the ordered set of eight numbers:\n$$ \\left(v_{A,1}^{t+1}, v_{A,2}^{t+1}, x_{A,1}^{t+1,\\mathrm{proj}}, x_{A,2}^{t+1,\\mathrm{proj}}, v_{B,1}^{t+1}, v_{B,2}^{t+1}, x_{B,1}^{t+1,\\mathrm{proj}}, x_{B,2}^{t+1,\\mathrm{proj}}\\right) $$\nThe calculated values are:\n$$ (251.1, -89.1, 250, 20, 134, 77.2, 250, 117.2) $$\nRounding each number to four significant figures as required:\n-   $v_{A,1}^{t+1} = 251.1$ (already 4 SF)\n-   $v_{A,2}^{t+1} = -89.1 \\to -89.10$\n-   $x_{A,1}^{t+1,\\mathrm{proj}} = 250 \\to 250.0$\n-   $x_{A,2}^{t+1,\\mathrm{proj}} = 20 \\to 20.00$\n-   $v_{B,1}^{t+1} = 134 \\to 134.0$\n-   $v_{B,2}^{t+1} = 77.2 \\to 77.20$\n-   $x_{B,1}^{t+1,\\mathrm{proj}} = 250 \\to 250.0$\n-   $x_{B,2}^{t+1,\\mathrm{proj}} = 117.2$ (already 4 SF)\n\nThe final vector of numbers is $(251.1, -89.10, 250.0, 20.00, 134.0, 77.20, 250.0, 117.2)$.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 251.1 & -89.10 & 250.0 & 20.00 & 134.0 & 77.20 & 250.0 & 117.2 \\end{pmatrix} } $$"
        },
        {
            "introduction": "Differential Evolution (DE) is a remarkably effective and straightforward population-based metaheuristic for global optimization problems. It works by evolving a population of candidate solutions through iterative cycles of mutation, crossover, and selection, using vector differences between population members to create new trial solutions. This comprehensive practice simulates one full generation of the DE algorithm, providing a holistic view of how a population improves and how constraints can be managed through penalty functions within the objective evaluation .",
            "id": "4103167",
            "problem": "Consider a single-period economic dispatch problem with four thermal generators, where the total load is fixed at demand $D = 500$ megawatt (MW). The operating cost of generator $i$ is modeled by a quadratic function $C_i(P_i) = a_i + b_i P_i + c_i P_i^2$, where $P_i$ is the power output (in MW), and $a_i$, $b_i$, $c_i$ are nonnegative coefficients. The generators have feasible operating bounds $P_i^{\\min} \\leq P_i \\leq P_i^{\\max}$. Constraint handling is performed via a quadratic penalty on violations: the penalized objective is\n$$\nJ(\\mathbf{P}) = \\sum_{i=1}^{4} \\left(a_i + b_i P_i + c_i P_i^2\\right) + \\rho \\left(\\sum_{i=1}^{4} P_i - D\\right)^2 + \\phi \\sum_{i=1}^{4} \\left(\\max\\{0, P_i - P_i^{\\max}\\}^2 + \\max\\{0, P_i^{\\min} - P_i\\}^2\\right),\n$$\nwith penalty coefficients $\\rho$ and $\\phi$.\n\nYou are asked to carry out exactly one generation of the Differential Evolution (DE) metaheuristic using the DE/rand/1/bin strategy and selection, and then report the new best (lowest) penalized cost obtained. Use the following data:\n\n- Cost coefficients:\n  - Generator $1$: $a_1 = 500$, $b_1 = 5.3$, $c_1 = 0.002$.\n  - Generator $2$: $a_2 = 400$, $b_2 = 5.0$, $c_2 = 0.003$.\n  - Generator $3$: $a_3 = 200$, $b_3 = 4.5$, $c_3 = 0.004$.\n  - Generator $4$: $a_4 = 100$, $b_4 = 4.0$, $c_4 = 0.005$.\n- Operating bounds:\n  - Generator $1$: $P_1^{\\min} = 50$, $P_1^{\\max} = 200$.\n  - Generator $2$: $P_2^{\\min} = 50$, $P_2^{\\max} = 180$.\n  - Generator $3$: $P_3^{\\min} = 30$, $P_3^{\\max} = 160$.\n  - Generator $4$: $P_4^{\\min} = 20$, $P_4^{\\max} = 150$.\n- Penalty parameters: $\\rho = 100$, $\\phi = 200$.\n- Initial population of $N_p = 5$ candidate dispatch vectors (each satisfies $\\sum_i P_i = D$):\n  - $\\mathbf{X}_1 = [120,\\ 150,\\ 110,\\ 120]$,\n  - $\\mathbf{X}_2 = [80,\\ 160,\\ 140,\\ 120]$,\n  - $\\mathbf{X}_3 = [150,\\ 140,\\ 100,\\ 110]$,\n  - $\\mathbf{X}_4 = [60,\\ 170,\\ 130,\\ 140]$,\n  - $\\mathbf{X}_5 = [180,\\ 100,\\ 90,\\ 130]$.\n- Differential Evolution (DE) parameters and operators:\n  - Mutation strategy DE/rand/1: for each target index $i$, form the mutant $\\mathbf{V}_i = \\mathbf{X}_{r_1} + F\\left(\\mathbf{X}_{r_2} - \\mathbf{X}_{r_3}\\right)$ with distinct indices $r_1, r_2, r_3 \\in \\{1,2,3,4,5\\}\\setminus\\{i\\}$, using $F = 0.6$.\n  - Crossover: binomial crossover with rate $CR = 1.0$, so the trial vector is $\\mathbf{U}_i = \\mathbf{V}_i$.\n  - Selection: if $J(\\mathbf{U}_i) \\leq J(\\mathbf{X}_i)$, then replace $\\mathbf{X}_i \\leftarrow \\mathbf{U}_i$; otherwise keep $\\mathbf{X}_i$.\n- Use the following predetermined mutation indices:\n  - For $i=1$: $(r_1, r_2, r_3) = (2, 3, 4)$.\n  - For $i=2$: $(r_1, r_2, r_3) = (5, 1, 3)$.\n  - For $i=3$: $(r_1, r_2, r_3) = (4, 5, 2)$.\n  - For $i=4$: $(r_1, r_2, r_3) = (1, 2, 5)$.\n  - For $i=5$: $(r_1, r_2, r_3) = (3, 4, 1)$.\n\nPerform the single DE generation exactly as specified above. Then, among the new population after selection, determine the lowest penalized cost value. Round your final answer to four significant figures. Express this value as a single number, without units.",
            "solution": "The objective is to compute the penalized cost\n$$\nJ(\\mathbf{P}) = \\sum_{i=1}^{4} \\left(a_i + b_i P_i + c_i P_i^2\\right) + \\rho \\left(\\sum_{i=1}^{4} P_i - D\\right)^2 + \\phi \\sum_{i=1}^{4} \\left(\\max\\{0, P_i - P_i^{\\max}\\}^2 + \\max\\{0, P_i^{\\min} - P_i\\}^2\\right)\n$$\nfor each candidate, apply one generation of Differential Evolution (DE), and then select the improved candidates to form the next population. The fundamental base here is the definition of the economic dispatch quadratic cost and the DE operators (mutation, crossover, and selection), with constraints enforced via quadratic penalties.\n\nFirst, compute the baseline costs $J(\\mathbf{X}_i)$ for the initial population. Since each $\\mathbf{X}_i$ satisfies $\\sum_{i=1}^{4} P_i = D$ and all components are within bounds, the penalty terms are zero.\n\nDefine per-generator cost functions:\n- Generator $1$: $C_1(P_1) = 500 + 5.3 P_1 + 0.002 P_1^2$.\n- Generator $2$: $C_2(P_2) = 400 + 5.0 P_2 + 0.003 P_2^2$.\n- Generator $3$: $C_3(P_3) = 200 + 4.5 P_3 + 0.004 P_3^2$.\n- Generator $4$: $C_4(P_4) = 100 + 4.0 P_4 + 0.005 P_4^2$.\n\nCompute $J(\\mathbf{X}_i)$:\n\n$1)$ For $\\mathbf{X}_1 = [120,\\ 150,\\ 110,\\ 120]$:\n- $C_1(120) = 500 + 5.3 \\cdot 120 + 0.002 \\cdot 120^2 = 500 + 636 + 28.8 = 1164.8$.\n- $C_2(150) = 400 + 5.0 \\cdot 150 + 0.003 \\cdot 150^2 = 400 + 750 + 67.5 = 1217.5$.\n- $C_3(110) = 200 + 4.5 \\cdot 110 + 0.004 \\cdot 110^2 = 200 + 495 + 48.4 = 743.4$.\n- $C_4(120) = 100 + 4.0 \\cdot 120 + 0.005 \\cdot 120^2 = 100 + 480 + 72 = 652$.\nThus $J(\\mathbf{X}_1) = 1164.8 + 1217.5 + 743.4 + 652 = 3777.7$.\n\n$2)$ For $\\mathbf{X}_2 = [80,\\ 160,\\ 140,\\ 120]$:\n- $C_1(80) = 500 + 5.3 \\cdot 80 + 0.002 \\cdot 80^2 = 500 + 424 + 12.8 = 936.8$.\n- $C_2(160) = 400 + 5.0 \\cdot 160 + 0.003 \\cdot 160^2 = 400 + 800 + 76.8 = 1276.8$.\n- $C_3(140) = 200 + 4.5 \\cdot 140 + 0.004 \\cdot 140^2 = 200 + 630 + 78.4 = 908.4$.\n- $C_4(120) = 652$.\nThus $J(\\mathbf{X}_2) = 936.8 + 1276.8 + 908.4 + 652 = 3774.0$.\n\n$3)$ For $\\mathbf{X}_3 = [150,\\ 140,\\ 100,\\ 110]$:\n- $C_1(150) = 500 + 5.3 \\cdot 150 + 0.002 \\cdot 150^2 = 500 + 795 + 45 = 1340$.\n- $C_2(140) = 400 + 5.0 \\cdot 140 + 0.003 \\cdot 140^2 = 400 + 700 + 58.8 = 1158.8$.\n- $C_3(100) = 690$.\n- $C_4(110) = 100 + 4.0 \\cdot 110 + 0.005 \\cdot 110^2 = 100 + 440 + 60.5 = 600.5$.\nThus $J(\\mathbf{X}_3) = 1340 + 1158.8 + 690 + 600.5 = 3789.3$.\n\n$4)$ For $\\mathbf{X}_4 = [60,\\ 170,\\ 130,\\ 140]$:\n- $C_1(60) = 500 + 5.3 \\cdot 60 + 0.002 \\cdot 60^2 = 500 + 318 + 7.2 = 825.2$.\n- $C_2(170) = 400 + 5.0 \\cdot 170 + 0.003 \\cdot 170^2 = 400 + 850 + 86.7 = 1336.7$.\n- $C_3(130) = 200 + 4.5 \\cdot 130 + 0.004 \\cdot 130^2 = 200 + 585 + 67.6 = 852.6$.\n- $C_4(140) = 100 + 4.0 \\cdot 140 + 0.005 \\cdot 140^2 = 100 + 560 + 98 = 758$.\nThus $J(\\mathbf{X}_4) = 825.2 + 1336.7 + 852.6 + 758 = 3772.5$.\n\n$5)$ For $\\mathbf{X}_5 = [180,\\ 100,\\ 90,\\ 130]$:\n- $C_1(180) = 500 + 5.3 \\cdot 180 + 0.002 \\cdot 180^2 = 500 + 954 + 64.8 = 1518.8$.\n- $C_2(100) = 400 + 5.0 \\cdot 100 + 0.003 \\cdot 100^2 = 400 + 500 + 30 = 930$.\n- $C_3(90) = 200 + 4.5 \\cdot 90 + 0.004 \\cdot 90^2 = 200 + 405 + 32.4 = 637.4$.\n- $C_4(130) = 100 + 4.0 \\cdot 130 + 0.005 \\cdot 130^2 = 100 + 520 + 84.5 = 704.5$.\nThus $J(\\mathbf{X}_5) = 1518.8 + 930 + 637.4 + 704.5 = 3790.7$.\n\nThe initial best is $\\mathbf{X}_4$ with $J(\\mathbf{X}_4) = 3772.5$.\n\nNext, perform DE mutation with $F = 0.6$, crossover with $CR = 1.0$ (so $\\mathbf{U}_i = \\mathbf{V}_i$), and selection. Because all initial $\\mathbf{X}_i$ satisfy $\\sum_{j=1}^{4} P_j = D$ and mutation uses differences of population members, each mutant will also satisfy $\\sum_{j=1}^{4} V_{i,j} = D$:\n$$\n\\sum_{j=1}^{4} V_{i,j} = \\sum_{j=1}^{4} X_{r_1,j} + F \\left(\\sum_{j=1}^{4} X_{r_2,j} - \\sum_{j=1}^{4} X_{r_3,j}\\right) = D + F(D - D) = D,\n$$\nso the demand penalty is zero for all trials. Only bound violations can incur penalties.\n\nCompute mutants $\\mathbf{V}_i$:\n\n$1)$ $i=1$, $(r_1,r_2,r_3)=(2,3,4)$:\n$$\n\\mathbf{V}_1 = \\mathbf{X}_2 + 0.6(\\mathbf{X}_3 - \\mathbf{X}_4) = [80,160,140,120] + 0.6\\cdot[90,-30,-30,-30] = [134,142,122,102].\n$$\n\n$2)$ $i=2$, $(r_1,r_2,r_3)=(5,1,3)$:\n$$\n\\mathbf{V}_2 = \\mathbf{X}_5 + 0.6(\\mathbf{X}_1 - \\mathbf{X}_3) = [180,100,90,130] + 0.6\\cdot[-30,10,10,10] = [162,106,96,136].\n$$\n\n$3)$ $i=3$, $(r_1,r_2,r_3)=(4,5,2)$:\n$$\n\\mathbf{V}_3 = \\mathbf{X}_4 + 0.6(\\mathbf{X}_5 - \\mathbf{X}_2) = [60,170,130,140] + 0.6\\cdot[100,-60,-50,10] = [120,134,100,146].\n$$\n\n$4)$ $i=4$, $(r_1,r_2,r_3)=(1,2,5)$:\n$$\n\\mathbf{V}_4 = \\mathbf{X}_1 + 0.6(\\mathbf{X}_2 - \\mathbf{X}_5) = [120,150,110,120] + 0.6\\cdot[-100,60,50,-10] = [60,186,140,114].\n$$\n\n$5)$ $i=5$, $(r_1,r_2,r_3)=(3,4,1)$:\n$$\n\\mathbf{V}_5 = \\mathbf{X}_3 + 0.6(\\mathbf{X}_4 - \\mathbf{X}_1) = [150,140,100,110] + 0.6\\cdot[-60,20,20,20] = [114,152,112,122].\n$$\n\nAssess bound violations:\n- $\\mathbf{V}_1$ components $[134,142,122,102]$ are all within bounds.\n- $\\mathbf{V}_2$ components $[162,106,96,136]$ are all within bounds.\n- $\\mathbf{V}_3$ components $[120,134,100,146]$ are all within bounds.\n- $\\mathbf{V}_4$ has $P_2 = 186 > P_2^{\\max} = 180$, violation of $6$ MW. Penalty contribution is $\\phi \\cdot 6^2 = 200 \\cdot 36 = 7200$.\n- $\\mathbf{V}_5$ components $[114,152,112,122]$ are all within bounds.\n\nCompute $J(\\mathbf{V}_i)$ (including any penalties):\n\n$1)$ $\\mathbf{V}_1 = [134,142,122,102]$:\n- $C_1(134) = 500 + 5.3 \\cdot 134 + 0.002 \\cdot 134^2 = 500 + 710.2 + 35.912 = 1246.112$.\n- $C_2(142) = 400 + 5.0 \\cdot 142 + 0.003 \\cdot 142^2 = 400 + 710 + 60.492 = 1170.492$.\n- $C_3(122) = 200 + 4.5 \\cdot 122 + 0.004 \\cdot 122^2 = 200 + 549 + 59.536 = 808.536$.\n- $C_4(102) = 100 + 4.0 \\cdot 102 + 0.005 \\cdot 102^2 = 100 + 408 + 52.02 = 560.02$.\nTotal $J(\\mathbf{V}_1) = 1246.112 + 1170.492 + 808.536 + 560.02 = 3785.16$.\n\n$2)$ $\\mathbf{V}_2 = [162,106,96,136]$:\n- $C_1(162) = 500 + 5.3 \\cdot 162 + 0.002 \\cdot 162^2 = 500 + 858.6 + 52.488 = 1411.088$.\n- $C_2(106) = 400 + 5.0 \\cdot 106 + 0.003 \\cdot 106^2 = 400 + 530 + 33.708 = 963.708$.\n- $C_3(96) = 200 + 4.5 \\cdot 96 + 0.004 \\cdot 96^2 = 200 + 432 + 36.864 = 668.864$.\n- $C_4(136) = 100 + 4.0 \\cdot 136 + 0.005 \\cdot 136^2 = 100 + 544 + 92.48 = 736.48$.\nTotal $J(\\mathbf{V}_2) = 1411.088 + 963.708 + 668.864 + 736.48 = 3780.14$.\n\n$3)$ $\\mathbf{V}_3 = [120,134,100,146]$:\n- $C_1(120) = 1164.8$.\n- $C_2(134) = 400 + 5.0 \\cdot 134 + 0.003 \\cdot 134^2 = 400 + 670 + 53.868 = 1123.868$.\n- $C_3(100) = 690$.\n- $C_4(146) = 100 + 4.0 \\cdot 146 + 0.005 \\cdot 146^2 = 100 + 584 + 106.58 = 790.58$.\nTotal $J(\\mathbf{V}_3) = 1164.8 + 1123.868 + 690 + 790.58 = 3769.248$.\n\n$4)$ $\\mathbf{V}_4 = [60,186,140,114]$:\n- $C_1(60) = 825.2$.\n- $C_2(186) = 400 + 5.0 \\cdot 186 + 0.003 \\cdot 186^2 = 400 + 930 + 103.788 = 1433.788$.\n- $C_3(140) = 908.4$.\n- $C_4(114) = 100 + 4.0 \\cdot 114 + 0.005 \\cdot 114^2 = 100 + 456 + 64.98 = 620.98$.\nBase cost sum $= 825.2 + 1433.788 + 908.4 + 620.98 = 3788.368$. Add penalty $7200$, giving $J(\\mathbf{V}_4) = 3788.368 + 7200 = 10988.368$.\n\n$5)$ $\\mathbf{V}_5 = [114,152,112,122]$:\n- $C_1(114) = 500 + 5.3 \\cdot 114 + 0.002 \\cdot 114^2 = 500 + 604.2 + 25.992 = 1130.192$.\n- $C_2(152) = 400 + 5.0 \\cdot 152 + 0.003 \\cdot 152^2 = 400 + 760 + 69.312 = 1229.312$.\n- $C_3(112) = 200 + 4.5 \\cdot 112 + 0.004 \\cdot 112^2 = 200 + 504 + 50.176 = 754.176$.\n- $C_4(122) = 100 + 4.0 \\cdot 122 + 0.005 \\cdot 122^2 = 100 + 488 + 74.42 = 662.42$.\nTotal $J(\\mathbf{V}_5) = 1130.192 + 1229.312 + 754.176 + 662.42 = 3776.10$.\n\nApply selection for each target $i$:\n- $i=1$: $J(\\mathbf{V}_1) = 3785.16 > J(\\mathbf{X}_1) = 3777.7$, keep $\\mathbf{X}_1$.\n- $i=2$: $J(\\mathbf{V}_2) = 3780.14 > J(\\mathbf{X}_2) = 3774.0$, keep $\\mathbf{X}_2$.\n- $i=3$: $J(\\mathbf{V}_3) = 3769.248 < J(\\mathbf{X}_3) = 3789.3$, replace $\\mathbf{X}_3 \\leftarrow \\mathbf{V}_3$.\n- $i=4$: $J(\\mathbf{V}_4) = 10988.368 \\gg J(\\mathbf{X}_4) = 3772.5$, keep $\\mathbf{X}_4$.\n- $i=5$: $J(\\mathbf{V}_5) = 3776.10 < J(\\mathbf{X}_5) = 3790.7$, replace $\\mathbf{X}_5 \\leftarrow \\mathbf{V}_5$.\n\nThe new population after one generation and selection is:\n- $\\mathbf{X}_1' = \\mathbf{X}_1$, with $J(\\mathbf{X}_1') = 3777.7$,\n- $\\mathbf{X}_2' = \\mathbf{X}_2$, with $J(\\mathbf{X}_2') = 3774.0$,\n- $\\mathbf{X}_3' = \\mathbf{V}_3 = [120,134,100,146]$, with $J(\\mathbf{X}_3') = 3769.248$,\n- $\\mathbf{X}_4' = \\mathbf{X}_4$, with $J(\\mathbf{X}_4') = 3772.5$,\n- $\\mathbf{X}_5' = \\mathbf{V}_5 = [114,152,112,122]$, with $J(\\mathbf{X}_5') = 3776.10$.\n\nThe best (lowest) penalized cost in the new population is $J(\\mathbf{X}_3') = 3769.248$. Rounding to four significant figures yields $3769$.",
            "answer": "$$\\boxed{3769}$$"
        }
    ]
}