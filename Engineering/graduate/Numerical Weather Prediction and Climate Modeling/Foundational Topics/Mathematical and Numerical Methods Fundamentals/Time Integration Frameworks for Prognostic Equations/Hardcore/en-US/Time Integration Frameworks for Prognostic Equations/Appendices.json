{
    "hands_on_practices": [
        {
            "introduction": "The stability of any numerical model is a non-negotiable first principle. This exercise provides a foundational calculation to determine the maximum stable time step for an explicit scheme, illustrating the famous Courant–Friedrichs–Lewy (CFL) condition. By comparing the limits imposed by different physical phenomena—slow advection versus fast acoustic waves—you will directly confront the numerical 'stiffness' that motivates the development of more advanced time integration frameworks .",
            "id": "4105163",
            "problem": "Consider a one-dimensional slice of a compressible dynamical core used in numerical weather prediction, with prognostic equations discretized on a uniform grid of spacing $\\Delta x$. The model integrates in time using a fully explicit scheme for both advection and acoustic propagation. The fundamental base for stability is that explicit discretizations of hyperbolic partial differential equations obey the Courant–Friedrichs–Lewy (CFL) condition, which constrains the non-dimensional Courant number $\\nu$ defined by $\\nu = \\frac{v\\,\\Delta t}{\\Delta x}$, where $v$ is an appropriate characteristic signal speed, to satisfy $\\nu \\leq 1$ for linear stability.\n\nStarting from:\n- the linear advection equation $\\partial_t \\phi + U\\,\\partial_x \\phi = 0$ with characteristic speed $|U|$, and\n- the linearized acoustic subsystem of the compressible Euler equations, which has characteristic sound speed $c_s$,\n\nderive the maximal explicit time-step constraints imposed separately by the advective CFL condition and the acoustic CFL condition, and then determine the single maximal time step that satisfies both constraints simultaneously by taking the more restrictive of the two. Use the following scientifically plausible parameters: grid spacing $\\Delta x = 10\\,\\text{km}$, wind speed $U = 20\\,\\text{m s}^{-1}$, and sound speed $c_s = 320\\,\\text{m s}^{-1}$. Express your final numeric answer in seconds and round to four significant figures. In your reasoning, interpret which mode (advective or acoustic) is limiting under these conditions.",
            "solution": "The problem requires the determination of the maximum stable time step for a fully explicit numerical scheme used in a one-dimensional compressible dynamical core. The stability of such a scheme for hyperbolic partial differential equations is governed by the Courant–Friedrichs–Lewy (CFL) condition.\n\nThe CFL condition is formulated using the non-dimensional Courant number, $\\nu$, defined as:\n$$ \\nu = \\frac{v \\, \\Delta t}{\\Delta x} $$\nwhere $v$ is the characteristic speed of the relevant wave phenomenon, $\\Delta t$ is the time step, and $\\Delta x$ is the grid spacing. For the linear stability of many explicit schemes, the condition requires that $\\nu \\leq 1$. This inequality can be rearranged to establish an upper bound on the time step:\n$$ \\Delta t \\leq \\frac{\\Delta x}{v} $$\nConsequently, the maximum allowable time step, $\\Delta t_{max}$, for a process with characteristic speed $v$ is:\n$$ \\Delta t_{max} = \\frac{\\Delta x}{v} $$\nThe system described involves two distinct physical processes: advection and acoustic propagation. We must evaluate the CFL constraint for each process to determine the overall stability limit.\n\nThe provided parameters are:\n- Grid spacing: $\\Delta x = 10\\,\\text{km}$\n- Wind speed: $U = 20\\,\\text{m s}^{-1}$\n- Sound speed: $c_s = 320\\,\\text{m s}^{-1}$\n\nFor dimensional consistency, all quantities must be in SI units. The grid spacing is converted from kilometers to meters:\n$$ \\Delta x = 10\\,\\text{km} = 10 \\times 10^3\\,\\text{m} = 10^4\\,\\text{m} $$\n\nWe now derive the time-step constraint for each mode individually.\n\n1.  **Advective Time-Step Constraint:**\n    The linear advection equation, $\\partial_t \\phi + U\\,\\partial_x \\phi = 0$, governs the transport by the background wind. The characteristic speed for this process is the magnitude of the wind speed, $v_{adv} = |U|$. The CFL condition for advection is:\n    $$ \\nu_{adv} = \\frac{|U| \\, \\Delta t}{\\Delta x} \\leq 1 $$\n    This imposes a maximum time step, $\\Delta t_{adv}$, for the advective process:\n    $$ \\Delta t \\leq \\frac{\\Delta x}{|U|} \\implies \\Delta t_{adv} = \\frac{\\Delta x}{|U|} $$\n    Substituting the given numerical values:\n    $$ \\Delta t_{adv} = \\frac{10^4\\,\\text{m}}{|20\\,\\text{m s}^{-1}|} = \\frac{10000}{20}\\,\\text{s} = 500\\,\\text{s} $$\n\n2.  **Acoustic Time-Step Constraint:**\n    The linearized acoustic subsystem governs the propagation of sound waves. The characteristic speed for this process is the speed of sound, $v_{ac} = c_s$. The CFL condition for acoustic waves is:\n    $$ \\nu_{ac} = \\frac{c_s \\, \\Delta t}{\\Delta x} \\leq 1 $$\n    This imposes a maximum time step, $\\Delta t_{ac}$, for the acoustic process:\n    $$ \\Delta t \\leq \\frac{\\Delta x}{c_s} \\implies \\Delta t_{ac} = \\frac{\\Delta x}{c_s} $$\n    Substituting the given numerical values:\n    $$ \\Delta t_{ac} = \\frac{10^4\\,\\text{m}}{320\\,\\text{m s}^{-1}} = \\frac{10000}{320}\\,\\text{s} = \\frac{1000}{32}\\,\\text{s} = 31.25\\,\\text{s} $$\n\n3.  **Composite Stability Constraint:**\n    A fully explicit integration scheme must be stable with respect to all physical processes modeled. Therefore, the time step $\\Delta t$ must satisfy both the advective and acoustic constraints simultaneously. This means that $\\Delta t$ must be less than or equal to the minimum of the individual maximum allowable time steps:\n    $$ \\Delta t \\leq \\min(\\Delta t_{adv}, \\Delta t_{ac}) $$\n    The single maximal time step, $\\Delta t_{max}$, that ensures the stability of the entire system is the more restrictive (i.e., smaller) of the two values:\n    $$ \\Delta t_{max} = \\min(500\\,\\text{s}, 31.25\\,\\text{s}) $$\n    Thus, the overall maximum stable time step is:\n    $$ \\Delta t_{max} = 31.25\\,\\text{s} $$\n    The problem requests the answer rounded to four significant figures. The calculated value $31.25$ is an exact result with three significant figures, which is consistent with this requirement.\n\n**Interpretation:**\nA comparison of the two constraints, $\\Delta t_{adv} = 500\\,\\text{s}$ and $\\Delta t_{ac} = 31.25\\,\\text{s}$, reveals that $\\Delta t_{ac}$ is significantly smaller than $\\Delta t_{adv}$. This indicates that the **acoustic mode is the limiting factor** for the stability of the explicit scheme. The high propagation speed of sound waves ($c_s = 320\\,\\text{m s}^{-1}$) forces the use of a very small time step, whereas the meteorologically significant advection process ($U = 20\\,\\text{m s}^{-1}$) would permit a much larger one. This disparity is a classic challenge in atmospheric modeling that motivates the development of more computationally efficient time integration methods, such as split-explicit or semi-implicit schemes, which treat the fast and slow modes differently.",
            "answer": "$$\n\\boxed{31.25}\n$$"
        },
        {
            "introduction": "Having established the strict stability limits of explicit methods, we now explore an alternative approach with implicit schemes. This practice guides you through the analysis of the Crank-Nicolson method, a classic scheme that offers unconditional stability for oscillatory problems, thus bypassing the acoustic CFL limit. By deriving its amplification factor and phase error, you will uncover the crucial trade-off between numerical stability and the accuracy with which a scheme represents wave propagation .",
            "id": "4105191",
            "problem": "In numerical weather prediction (Numerical Weather Prediction (NWP)) and climate modeling, prognostic equations support oscillatory normal modes (for example, inertia–gravity waves) whose single horizontal Fourier component can be represented by a complex amplitude that satisfies a linear ordinary differential equation (Ordinary Differential Equation (ODE)) of the form $\\frac{dy}{dt}=\\lambda y$. Consider a single such mode with purely oscillatory frequency, so that $\\lambda=i\\omega$ with $\\omega0$ real, and let $\\Delta t0$ denote a fixed time step. Define the nondimensional step $z=\\lambda \\Delta t$ and $\\Omega=\\omega \\Delta t$ so that $z=i\\Omega$. \n\nStarting from the integral form $y^{n+1}-y^{n}=\\int_{t_n}^{t_{n+1}} f(y(t))\\,dt$ with $f(y)=\\lambda y$, construct the Crank–Nicolson (Crank–Nicolson (CN)) one-step time integration method by applying the trapezoidal rule to the right-hand side. For the linear test equation $\\frac{dy}{dt}=\\lambda y$, derive the corresponding linear amplification factor $R(z)$, defined by $y^{n+1}=R(z)\\,y^{n}$, as a function of $z$. Then specialize to the oscillatory case $z=i\\Omega$ and define the numerical phase $\\theta(\\Omega)=\\arg\\big(R(i\\Omega)\\big)$, with angles measured in radians. Using series expansions valid for small $\\Omega$, obtain the phase error $\\varepsilon(\\Omega)=\\theta(\\Omega)-\\Omega$ as a power series in $\\Omega$ up to and including terms of order $\\Omega^{5}$. \n\nProvide your final result as a single closed-form expression for $\\varepsilon(\\Omega)$ truncated at $\\mathcal{O}(\\Omega^{5})$, with angles in radians. No numerical rounding is required.",
            "solution": "The problem statement is evaluated and found to be valid. It is a standard, well-posed problem in the field of numerical analysis applied to geophysical fluid dynamics, free of any scientific, logical, or formal flaws.\n\nThe solution proceeds as follows. We are given the prognostic equation $\\frac{dy}{dt} = \\lambda y$, which for a purely oscillatory mode becomes $\\frac{dy}{dt} = i\\omega y$, where $\\omega  0$ is a real constant. The task is to analyze the Crank-Nicolson time integration scheme for this equation.\n\nFirst, we construct the Crank-Nicolson scheme. We start with the integral form of the equation over a time step $\\Delta t$ from $t_n$ to $t_{n+1} = t_n + \\Delta t$:\n$$y(t_{n+1}) - y(t_n) = \\int_{t_n}^{t_{n+1}} \\lambda y(t) \\, dt$$\nUsing the notation $y^k = y(t_k)$, this is:\n$$y^{n+1} - y^{n} = \\int_{t_n}^{t_{n+1}} \\lambda y(t) \\, dt$$\nThe Crank-Nicolson method is derived by applying the trapezoidal rule to the integral on the right-hand side. The trapezoidal rule approximates an integral as:\n$$\\int_{a}^{b} g(t) \\, dt \\approx \\frac{b-a}{2} [g(a) + g(b)]$$\nApplying this to our problem with $g(t) = \\lambda y(t)$, $a = t_n$, and $b = t_{n+1}$, we obtain the discrete scheme:\n$$y^{n+1} - y^{n} = \\frac{t_{n+1} - t_n}{2} [\\lambda y(t_n) + \\lambda y(t_{n+1})]$$\n$$y^{n+1} - y^{n} = \\frac{\\Delta t}{2} (\\lambda y^n + \\lambda y^{n+1})$$\nTo derive the amplification factor $R(z)$, we introduce the non-dimensional step size $z = \\lambda \\Delta t$. The scheme can be rewritten as:\n$$y^{n+1} - y^{n} = \\frac{z}{2} (y^n + y^{n+1})$$\nWe now rearrange the equation to solve for $y^{n+1}$ as a function of $y^n$:\n$$y^{n+1} \\left(1 - \\frac{z}{2}\\right) = y^n \\left(1 + \\frac{z}{2}\\right)$$\n$$y^{n+1} = \\left(\\frac{1 + z/2}{1 - z/2}\\right) y^n$$\nBy the definition $y^{n+1} = R(z) y^n$, the linear amplification factor for the Crank-Nicolson scheme is:\n$$R(z) = \\frac{1 + z/2}{1 - z/2}$$\nFor the specified purely oscillatory case, we have $\\lambda = i\\omega$, which makes the non-dimensional step $z = i\\omega \\Delta t = i\\Omega$, where $\\Omega = \\omega \\Delta t  0$. Substituting $z = i\\Omega$ into the expression for $R(z)$:\n$$R(i\\Omega) = \\frac{1 + i\\Omega/2}{1 - i\\Omega/2}$$\nThe numerical phase $\\theta(\\Omega)$ is the argument of this complex number. Using the property that for a complex number $w$, $\\arg(w/\\bar{w}) = 2\\arg(w)$, or by computing $\\arg(1+i\\Omega/2) - \\arg(1-i\\Omega/2)$, we find:\n$$\\theta(\\Omega) = \\arg(R(i\\Omega)) = \\arg(1 + i\\Omega/2) - \\arg(1 - i\\Omega/2)$$\nThe argument of a complex number $x+iy$ is $\\arctan(y/x)$. Therefore:\n$$\\arg(1 + i\\Omega/2) = \\arctan\\left(\\frac{\\Omega/2}{1}\\right) = \\arctan\\left(\\frac{\\Omega}{2}\\right)$$\n$$\\arg(1 - i\\Omega/2) = \\arctan\\left(\\frac{-\\Omega/2}{1}\\right) = -\\arctan\\left(\\frac{\\Omega}{2}\\right)$$\nCombining these gives the numerical phase:\n$$\\theta(\\Omega) = \\arctan\\left(\\frac{\\Omega}{2}\\right) - \\left(-\\arctan\\left(\\frac{\\Omega}{2}\\right)\\right) = 2 \\arctan\\left(\\frac{\\Omega}{2}\\right)$$\nThe exact solution to $\\frac{dy}{dt} = i\\omega y$ is $y(t) = y(0) \\exp(i\\omega t)$. Over one time step $\\Delta t$, the phase of the exact solution advances by $\\omega \\Delta t = \\Omega$. The phase error, $\\varepsilon(\\Omega)$, is the difference between the numerical phase and the exact phase:\n$$\\varepsilon(\\Omega) = \\theta(\\Omega) - \\Omega = 2 \\arctan\\left(\\frac{\\Omega}{2}\\right) - \\Omega$$\nTo find the power series of $\\varepsilon(\\Omega)$ up to order $\\Omega^5$, we use the Maclaurin series for the arctangent function:\n$$\\arctan(x) = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\mathcal{O}(x^7)$$\nWe substitute $x = \\Omega/2$ into this series:\n$$\\arctan\\left(\\frac{\\Omega}{2}\\right) = \\left(\\frac{\\Omega}{2}\\right) - \\frac{1}{3}\\left(\\frac{\\Omega}{2}\\right)^3 + \\frac{1}{5}\\left(\\frac{\\Omega}{2}\\right)^5 - \\mathcal{O}(\\Omega^7)$$\n$$\\arctan\\left(\\frac{\\Omega}{2}\\right) = \\frac{\\Omega}{2} - \\frac{\\Omega^3}{24} + \\frac{\\Omega^5}{160} - \\mathcal{O}(\\Omega^7)$$\nNow substitute this expansion back into the expression for the phase error $\\varepsilon(\\Omega)$:\n$$\\varepsilon(\\Omega) = 2 \\left( \\frac{\\Omega}{2} - \\frac{\\Omega^3}{24} + \\frac{\\Omega^5}{160} - \\mathcal{O}(\\Omega^7) \\right) - \\Omega$$\nDistributing the factor of $2$:\n$$\\varepsilon(\\Omega) = \\left( \\Omega - \\frac{\\Omega^3}{12} + \\frac{\\Omega^5}{80} - \\mathcal{O}(\\Omega^7) \\right) - \\Omega$$\nFinally, subtracting $\\Omega$ yields the phase error expansion:\n$$\\varepsilon(\\Omega) = -\\frac{\\Omega^3}{12} + \\frac{\\Omega^5}{80} - \\mathcal{O}(\\Omega^7)$$\nTruncating this series to include terms up to and including the order $\\Omega^5$ gives the desired expression.",
            "answer": "$$\\boxed{-\\frac{\\Omega^{3}}{12} + \\frac{\\Omega^{5}}{80}}$$"
        },
        {
            "introduction": "This final practice bridges the gap between theory and practical implementation, a core skill in computational modeling. You will develop an adaptive time-stepping controller based on an embedded Runge–Kutta method, a sophisticated technique for optimizing efficiency while controlling numerical error. By coding and testing this controller against different scenarios , you will gain hands-on experience with the dynamic error-management strategies that underpin many modern prognostic models.",
            "id": "4105199",
            "problem": "Consider a one-dimensional prognostic ordinary differential equation initial value problem for a scalar state variable evolving under a tendency, representative of a time-discrete column in numerical weather prediction and climate modeling. Let the state be $x(t)$ governed by the ordinary differential equation $dx/dt = f(t, x)$ with an initial condition $x(t_0) = x_0$. Assume that the time integration algorithm is a single-step explicit embedded Runge–Kutta pair, where the lower-order solution has formal order $p$ and the higher-order solution provides a local error estimate, consistent with the widely accepted fact that the local truncation error scales as $\\mathcal{O}(\\Delta t^{p+1})$ for methods of order $p$. The adaptive time step controller must use this scaling to adjust the step size to maintain a user-specified tolerance on the local error, and also include safety features that bound the rate of change of $\\Delta t$ between successive steps.\n\nYour tasks are:\n- Starting from the definition of the local truncation error for a one-step method and its scaling with $\\Delta t$, derive a step-size control law that rescales $\\Delta t$ by a power of the ratio between the target tolerance and the current local error estimate. Enforce safety and practicality by imposing multiplicative lower and upper bounds on the step-size change per accepted step, and absolute minimum and maximum step sizes. Incorporate a safety factor strictly less than $1$ to avoid saturating the tolerance boundary.\n- Implement, in code, an embedded explicit Runge–Kutta pair consistent with the above assumptions, which yields both a higher-order solution update and an error estimate appropriate for controlling the step size in a single scalar equation.\n- Apply the adaptive controller to three test problems that are consistent with physically interpretable tendencies:\n    1. A smooth tendency: $f(t, x) = -\\lambda x + \\sin(\\omega t)$ with $t \\in [t_0, t_f]$, where $\\lambda$ is a positive relaxation rate and $\\omega$ is the angular frequency, representing a slowly varying forcing.\n    2. A rapidly changing tendency: $f(t, x) = -\\lambda x + A \\exp\\left(-\\tfrac{1}{2} \\left(\\tfrac{t - t_c}{\\sigma}\\right)^2\\right)$ with $t \\in [t_0, t_f]$, where $A$ is the amplitude, $t_c$ is the center time of a pulse, and $\\sigma$ is the pulse width, representing a sharp transient event.\n    3. A degenerate tendency: $f(t, x) = 0$ with $t \\in [t_0, t_f]$, representing a state that is exactly steady, which serves as an edge case for the controller when the error estimator is vanishingly small.\n\nFor each integration, define the following quantitative metrics to assess stability and responsiveness of the controller:\n- A boolean stability indicator defined as true if both the fraction of rejected steps is less than or equal to $0.3$ and the maximum ratio of attempted local error to tolerance does not exceed $2.0$.\n- The minimum accepted step size encountered, reported in seconds.\n- A responsiveness index defined as the ratio between the initial step size and the minimum accepted step size, which is dimensionless.\n- The fraction of rejected steps, which is dimensionless.\n- A variability index defined as the standard deviation of accepted step sizes divided by their mean, which is dimensionless.\n\nDesign details and constraints:\n- Use an explicit embedded Runge–Kutta $4(5)$ pair for both the state update and the local error estimate.\n- Use the following parameters and initial conditions for the test suite:\n    - Test case $1$ (smooth tendency):\n        - $p = 4$, safety factor $s = 0.9$, multiplicative bounds $\\text{fac}_{\\min} = 0.3$, $\\text{fac}_{\\max} = 2.0$, tolerance $\\text{tol} = 10^{-6}$, absolute bounds $\\Delta t_{\\min} = 10^{-6}$, $\\Delta t_{\\max} = 1.0$, initial step size $\\Delta t_0 = 0.1$, interval $[t_0, t_f] = [0, 10]$, initial condition $x_0 = 0$, relaxation rate $\\lambda = 0.5$, angular frequency $\\omega = 1.0$.\n    - Test case $2$ (rapid pulse tendency):\n        - $p = 4$, safety factor $s = 0.9$, multiplicative bounds $\\text{fac}_{\\min} = 0.3$, $\\text{fac}_{\\max} = 2.0$, tolerance $\\text{tol} = 10^{-6}$, absolute bounds $\\Delta t_{\\min} = 10^{-6}$, $\\Delta t_{\\max} = 1.0$, initial step size $\\Delta t_0 = 0.1$, interval $[t_0, t_f] = [0, 10]$, initial condition $x_0 = 0$, relaxation rate $\\lambda = 0.5$, pulse amplitude $A = 8.0$, center time $t_c = 5.0$, width $\\sigma = 0.05$.\n    - Test case $3$ (degenerate tendency):\n        - $p = 4$, safety factor $s = 0.95$, multiplicative bounds $\\text{fac}_{\\min} = 0.2$, $\\text{fac}_{\\max} = 1.1$, tolerance $\\text{tol} = 10^{-8}$, absolute bounds $\\Delta t_{\\min} = 10^{-9}$, $\\Delta t_{\\max} = 2.0$, initial step size $\\Delta t_0 = 0.1$, interval $[t_0, t_f] = [0, 10]$, initial condition $x_0 = 0$.\n- The Runge–Kutta implementation must ensure that if a proposed step is rejected, the step size is reduced using the same control logic, but without permitting any increase on a rejected attempt. The update must never exceed the final time $t_f$.\n- All reported step sizes must be expressed in seconds. The other metrics are dimensionless.\n\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each test case contributes a sublist in the form $[\\text{stable}, \\text{min\\_dt\\_sec}, \\text{responsiveness\\_index}, \\text{fraction\\_rejected}, \\text{dt\\_variability}]$. For example, the output format must look like $[[\\dots],[\\dots],[\\dots]]$ with no additional text.",
            "solution": "The problem requires the derivation and implementation of an adaptive time-stepping algorithm based on an embedded Runge-Kutta pair to solve a scalar ordinary differential equation (ODE). The validity of the problem has been confirmed as it is scientifically grounded, well-posed, and objective, representing a standard task in numerical analysis and computational science.\n\n### 1. Derivation of the Adaptive Step-Size Control Law\n\nThe core of an adaptive time-stepping method is a control law that adjusts the step size, $\\Delta t$, to maintain the local error per step near a user-defined tolerance, $\\text{tol}$.\n\nA one-step numerical method of order $p$ for the ODE $\\frac{dx}{dt} = f(t,x)$ has a local truncation error (LTE) that scales as the $(p+1)$-th power of the step size. For a step from $t_n$ to $t_{n+1} = t_n + \\Delta t$, the LTE is given by:\n$$\n\\text{LTE} = x(t_{n+1}) - x_{n+1}^{(\\text{num})} = C \\Delta t^{p+1} + \\mathcal{O}(\\Delta t^{p+2})\n$$\nwhere $x(t_{n+1})$ is the true solution, $x_{n+1}^{(\\text{num})}$ is the numerical solution, and $C$ is a constant that depends on the derivatives of $f(t,x)$ but is assumed to be approximately constant over a few steps.\n\nAn embedded Runge-Kutta pair provides two solutions at each step: a higher-order solution of order $p+1$, which we take as the new state $x_{n+1}$, and a lower-order solution of order $p$. The difference between these two solutions serves as an estimate, $E_{n+1}$, of the LTE of the lower-order method.\n$$\nE_{n+1} = |x_{n+1}^{(p+1)} - x_{n+1}^{(p)}| \\approx |\\text{LTE}^{(p)}|\n$$\nThus, for the current step size $\\Delta t_{\\text{current}}$, the estimated error is:\n$$\nE_{\\text{current}} \\approx C (\\Delta t_{\\text{current}})^{p+1}\n$$\nThe objective is to find a new step size, $\\Delta t_{\\text{new}}$, for which the estimated error, $E_{\\text{new}}$, will be approximately equal to the desired tolerance, $\\text{tol}$.\n$$\n\\text{tol} \\approx C (\\Delta t_{\\text{new}})^{p+1}\n$$\nAssuming $C$ is constant between the two hypothetical steps, we can form a ratio of the two error equations:\n$$\n\\frac{\\text{tol}}{E_{\\text{current}}} \\approx \\frac{C (\\Delta t_{\\text{new}})^{p+1}}{C (\\Delta t_{\\text{current}})^{p+1}} = \\left(\\frac{\\Delta t_{\\text{new}}}{\\Delta t_{\\text{current}}}\\right)^{p+1}\n$$\nSolving for $\\Delta t_{\\text{new}}$ yields the fundamental control law:\n$$\n\\Delta t_{\\text{new}} = \\Delta t_{\\text{current}} \\left(\\frac{\\text{tol}}{E_{\\text{current}}}\\right)^{\\frac{1}{p+1}}\n$$\nTo ensure robustness and prevent the controller from taking steps that are exactly on the tolerance boundary, a safety factor $s  1$ is introduced. This factor provides a conservative margin.\n$$\n\\Delta t_{\\text{optimal}} = s \\cdot \\Delta t_{\\text{current}} \\left(\\frac{\\text{tol}}{E_{\\text{current}}}\\right)^{\\frac{1}{p+1}}\n$$\nThe problem specifies a Runge-Kutta $4(5)$ pair, so the order of the lower-order method is $p=4$, and the exponent in the control law is $\\frac{1}{p+1} = \\frac{1}{5} = 0.2$.\n\nTo prevent overly aggressive or timid changes in the step size, which can lead to instability or inefficiency, the scaling factor is bounded by multiplicative factors $\\text{fac}_{\\min}$ and $\\text{fac}_{\\max}$. Let the calculated scaling factor be $\\text{fac} = s \\left(\\frac{\\text{tol}}{E_{\\text{current}}}\\right)^{0.2}$. The proposed step size is then:\n$$\n\\Delta t_{\\text{proposed}} = \\Delta t_{\\text{current}} \\cdot \\min(\\text{fac}_{\\max}, \\max(\\text{fac}_{\\min}, \\text{fac}))\n$$\nThis logic applies to both accepted steps ($E_{\\text{current}} \\leq \\text{tol}$) and rejected steps ($E_{\\text{current}}  \\text{tol}$). If a step is rejected, $E_{\\text{current}}  \\text{tol}$, which means the term $(\\text{tol}/E_{\\text{current}})$ is less than $1$, causing the scaling factor $\\text{fac}$ to be less than $s$ (and thus less than $1$). This naturally leads to a reduction in step size, satisfying the constraint that no increase is permitted on a rejected attempt.\n\nFinally, absolute bounds, $\\Delta t_{\\min}$ and $\\Delta t_{\\max}$, are imposed to handle physical or numerical constraints of the problem:\n$$\n\\Delta t_{\\text{final}} = \\min(\\Delta t_{\\max}, \\max(\\Delta t_{\\min}, \\Delta t_{\\text{proposed}}))\n$$\nA special edge case arises when the error estimate $E_{\\text{current}}$ is vanishingly small or zero, as in the degenerate tendency test case. This would cause a division-by-zero or floating-point overflow. In this scenario, the error is well within tolerance, and the step size should be increased as aggressively as the bounds permit. The control law handles this by setting the scaling factor to its maximum allowed value, $\\text{fac}_{\\max}$.\n\n### 2. Implementation of the RK4(5) Integrator\n\nThe integrator is implemented using the coefficients of the Dormand-Prince $4(5)$ pair, which is a widely used and well-regarded choice. It is a $7$-stage explicit method that is First Same As Last (FSAL), meaning the last stage evaluation, $k_7$, can be reused as the first stage evaluation, $k_1$, of the subsequent step if the current step is accepted. This optimization saves one function evaluation per accepted step.\n\nThe stages are computed as:\n$$\nk_i = f\\left(t_n + c_i \\Delta t, x_n + \\Delta t \\sum_{j=1}^{i-1} a_{ij} k_j\\right) \\quad \\text{for } i=1, \\dots, 7\n$$\nThe higher-order (order $5$) solution, which is used to advance the state, is:\n$$\nx_{n+1} = x_n + \\Delta t \\sum_{i=1}^{7} b_i k_i\n$$\nThe error estimate is the scaled difference between the higher-order and lower-order solutions:\n$$\nE_{n+1} = \\left| \\Delta t \\sum_{i=1}^{7} (b_i - b_i^*) k_i \\right| = \\left| \\Delta t \\sum_{i=1}^{7} e_i k_i \\right|\n$$\nThe overall algorithm proceeds as follows:\n1. Initialize time $t = t_0$, state $x = x_0$, and step size $\\Delta t = \\Delta t_0$.\n2. Compute the initial stage $k_1 = f(t, x)$.\n3. Loop while $t  t_f$:\n   a. Ensure the step does not overshoot the final time $t_f$.\n   b. Enter a loop for step retries (in case of rejection).\n   c. Compute stages $k_2$ through $k_7$ using the Butcher tableau coefficients.\n   d. Calculate the error estimate $E$.\n   e. If $E \\leq \\text{tol}$, the step is accepted. Break the retry loop.\n   f. If $E  \\text{tol}$, the step is rejected. Calculate a new, smaller $\\Delta t$ using the control law, and continue the retry loop from the same state $(t, x)$.\n4. Upon acceptance:\n   a. Update the state $x$ using the 5th-order formula.\n   b. Update time $t$.\n   c. Record metrics for the accepted step.\n   d. Calculate the optimal $\\Delta t$ for the next step using the control law.\n   e. Reuse $k_7$ as the $k_1$ for the next step (FSAL).\n5. After the integration is complete, compute the final summary metrics as specified.\n\nThis procedure is applied to the three distinct test cases to evaluate the controller's performance under smooth, rapidly changing, and degenerate forcing conditions.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the adaptive time-stepping problem for three test cases and prints the results.\n    \"\"\"\n\n    # Dormand-Prince 4(5) Butcher Tableau coefficients\n    C = np.array([0, 1/5, 3/10, 4/5, 8/9, 1, 1], dtype=np.float64)\n    A = np.array([\n        [0, 0, 0, 0, 0, 0, 0],\n        [1/5, 0, 0, 0, 0, 0, 0],\n        [3/40, 9/40, 0, 0, 0, 0, 0],\n        [44/45, -56/15, 32/9, 0, 0, 0, 0],\n        [19372/6561, -25360/2187, 64448/6561, -212/729, 0, 0, 0],\n        [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656, 0, 0],\n        [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0]\n    ], dtype=np.float64)\n    B = np.array([35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0], dtype=np.float64)\n    E = np.array([71/57600, 0, -71/16695, 71/1920, -17253/339200, 22/525, -1/40], dtype=np.float64)\n\n    def adaptive_rk45_integrator(f, t_span, x0, params):\n        \"\"\"\n        Integrates a scalar ODE using an adaptive RK4(5) method.\n        \"\"\"\n        t0, tf = t_span\n        t = t0\n        x = x0\n        dt = params['dt0']\n        \n        num_accepted = 0\n        num_rejected = 0\n        accepted_dts = []\n        max_error_ratio = 0.0\n\n        p = params['p']\n        s = params['s']\n        tol = params['tol']\n        fac_min = params['fac_min']\n        fac_max = params['fac_max']\n        dt_min = params['dt_min']\n        dt_max = params['dt_max']\n        \n        # FSAL: First Same As Last. k1 of the next step is k7 of the current.\n        k = np.zeros(7, dtype=np.float64)\n        k[0] = f(t, x)\n\n        while t  tf:\n            dt = min(dt, tf - t)\n            \n            step_accepted = False\n            while not step_accepted:\n                if t + dt = t: # Step size is too small\n                    # This can happen if dt shrinks below machine epsilon relative to t.\n                    # We treat this as an unrecoverable failure.\n                    # Raise an exception or return failure indicators.\n                    # For this problem, we assume parameters prevent this.\n                    # But as a safeguard:\n                    raise RuntimeError(\"Step size underflow.\")\n\n                # Compute stages k2 to k6\n                for i in range(1, 6):\n                    x_stage = x + dt * np.dot(A[i, :i], k[:i])\n                    k[i] = f(t + C[i] * dt, x_stage)\n\n                # Compute the 5th order solution candidate (without kr) for k7 eval\n                x_new = x + dt * np.dot(B, k)\n                \n                # Compute k7\n                k[6] = f(t + dt, x_new)\n\n                # Estimate error\n                error_est = abs(dt * np.dot(E, k))\n                \n                # Track max error ratio for stability metric\n                if tol  0:\n                    max_error_ratio = max(max_error_ratio, error_est / tol)\n                \n                if error_est = tol:\n                    step_accepted = True\n                    t += dt\n                    x = x_new\n                    \n                    num_accepted += 1\n                    accepted_dts.append(dt)\n                    \n                    # Store k7 for FSAL optimization\n                    k1_next = k[6]\n                    \n                else: # Step rejected\n                    num_rejected += 1\n\n                # Step size controller\n                if error_est == 0.0:\n                    scale = fac_max\n                else:\n                    scale = s * (tol / error_est)**(1.0 / (p + 1.0))\n\n                dt_new_scaling = min(fac_max, max(fac_min, scale))\n                \n                if step_accepted:\n                    dt = min(dt_max, max(dt_min, dt * dt_new_scaling))\n                else: # On rejection, only decrease is allowed\n                    # Our logic naturally does this, but clamp to 1.0 just in case\n                    dt_new_scaling = min(1.0, dt_new_scaling) \n                    dt = min(dt_max, max(dt_min, dt * dt_new_scaling))\n            \n            # Use k7 as k1 for the next step (FSAL)\n            k[0] = k1_next\n\n        # Calculate metrics\n        total_steps = num_accepted + num_rejected\n        fraction_rejected = num_rejected / total_steps if total_steps  0 else 0.0\n        \n        stable = (fraction_rejected = 0.3) and (max_error_ratio = 2.0)\n        \n        if not accepted_dts:\n            min_dt_sec = np.nan\n            responsiveness_index = np.nan\n            dt_variability = np.nan\n        else:\n            min_dt_sec = np.min(accepted_dts)\n            responsiveness_index = params['dt0'] / min_dt_sec\n            if len(accepted_dts)  1 and np.mean(accepted_dts)  0:\n                dt_variability = np.std(accepted_dts) / np.mean(accepted_dts)\n            else:\n                dt_variability = 0.0\n                \n        return [stable, min_dt_sec, responsiveness_index, fraction_rejected, dt_variability]\n\n    # --- Test Cases Definition ---\n    \n    # Case 1: Smooth tendency\n    params1 = {\n        'p': 4, 's': 0.9, 'fac_min': 0.3, 'fac_max': 2.0, 'tol': 1e-6,\n        'dt_min': 1e-6, 'dt_max': 1.0, 'dt0': 0.1\n    }\n    def f1(t, x, lam=0.5, w=1.0):\n        return -lam * x + np.sin(w * t)\n\n    # Case 2: Rapid pulse tendency\n    params2 = {\n        'p': 4, 's': 0.9, 'fac_min': 0.3, 'fac_max': 2.0, 'tol': 1e-6,\n        'dt_min': 1e-6, 'dt_max': 1.0, 'dt0': 0.1\n    }\n    def f2(t, x, lam=0.5, A=8.0, tc=5.0, sig=0.05):\n        pulse = A * np.exp(-0.5 * ((t - tc) / sig)**2)\n        return -lam * x + pulse\n        \n    # Case 3: Degenerate tendency\n    params3 = {\n        'p': 4, 's': 0.95, 'fac_min': 0.2, 'fac_max': 1.1, 'tol': 1e-8,\n        'dt_min': 1e-9, 'dt_max': 2.0, 'dt0': 0.1\n    }\n    def f3(t, x):\n        return 0.0\n\n    test_cases = [\n        {'f': f1, 't_span': [0.0, 10.0], 'x0': 0.0, 'params': params1},\n        {'f': f2, 't_span': [0.0, 10.0], 'x0': 0.0, 'params': params2},\n        {'f': f3, 't_span': [0.0, 10.0], 'x0': 0.0, 'params': params3}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = adaptive_rk45_integrator(case['f'], case['t_span'], case['x0'], case['params'])\n        results.append(result)\n    \n    # Format the final output string\n    def format_results(res_list):\n        output_str = \"[\"\n        for i, res in enumerate(res_list):\n            stable_str = 'True' if res[0] else 'False'\n            # Format numbers to a reasonable precision for clean output\n            num_strs = [f\"{x:.6e}\" for x in res[1:]] \n            output_str += f\"[{stable_str},{','.join(num_strs)}]\"\n            if i  len(res_list) - 1:\n                output_str += \",\"\n        output_str += \"]\"\n        return output_str\n        \n    print(format_results(results))\n\nsolve()\n```"
        }
    ]
}