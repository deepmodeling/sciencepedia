{
    "hands_on_practices": [
        {
            "introduction": "The ultimate goal of Model Output Statistics (MOS) and Bayesian Model Averaging (BMA) is to produce probabilistic forecasts that are superior to the raw output from numerical models. To quantify this improvement, we need robust evaluation tools. This exercise focuses on the Continuous Ranked Probability Score (CRPS), a premier scoring rule for assessing the quality of probabilistic forecasts for continuous variables like temperature. By deriving the CRPS for a Gaussian distribution and applying it to both a raw and a calibrated forecast, you will gain a deep, quantitative understanding of how post-processing corrects for bias and adjusts spread to improve overall forecast skill .",
            "id": "4065230",
            "problem": "A site-specific $2\\,\\mathrm{m}$ air temperature forecast from a Numerical Weather Prediction (NWP) system is verified against an observation. The raw ensemble is approximated by a Gaussian predictive distribution with mean $\\mu_{\\mathrm{r}} = 289\\,\\mathrm{K}$ and standard deviation $\\sigma_{\\mathrm{r}} = 2\\,\\mathrm{K}$. A calibrated predictive distribution obtained via Model Output Statistics (MOS) and consistent with Bayesian Model Averaging (BMA) principles is represented by a Gaussian with mean $\\mu_{\\mathrm{c}} = 291\\,\\mathrm{K}$ and standard deviation $\\sigma_{\\mathrm{c}} = 2.5\\,\\mathrm{K}$. The verifying observation is $y = 291\\,\\mathrm{K}$. \n\nStarting from the formal definition of the Continuous Ranked Probability Score (CRPS) as a functional of a predictive cumulative distribution function and the observation, derive a closed-form expression for the CRPS of a normal predictive distribution in terms of the standardized error $z = (y - \\mu)/\\sigma$, the standard normal probability density function, and the standard normal cumulative distribution function. Then, use this expression to compute the CRPS for both the raw ensemble ($\\mu_{\\mathrm{r}}, \\sigma_{\\mathrm{r}}$) and the calibrated MOS/BMA distribution ($\\mu_{\\mathrm{c}}, \\sigma_{\\mathrm{c}}$) at the verifying observation $y$. \n\nDefine the improvement due to calibration as $\\Delta = \\mathrm{CRPS}_{\\mathrm{raw}} - \\mathrm{CRPS}_{\\mathrm{calibrated}}$. Compute $\\Delta$ and express your final numerical answer in $\\mathrm{K}$. Round your final answer to four significant figures. In addition, explain qualitatively, using the derived expression and scientifically supported reasoning, how calibration of the ensemble (bias correction and spread adjustment) affects the CRPS relative to the raw ensemble.",
            "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and complete.\n\n### Step 1: Extract Givens\n- Verifying observation: $y = 291\\,\\mathrm{K}$\n- Raw ensemble predictive distribution: A Gaussian distribution with mean $\\mu_{\\mathrm{r}} = 289\\,\\mathrm{K}$ and standard deviation $\\sigma_{\\mathrm{r}} = 2\\,\\mathrm{K}$.\n- Calibrated MOS/BMA predictive distribution: A Gaussian distribution with mean $\\mu_{\\mathrm{c}} = 291\\,\\mathrm{K}$ and standard deviation $\\sigma_{\\mathrm{c}} = 2.5\\,\\mathrm{K}$.\n- Definition of improvement: $\\Delta = \\mathrm{CRPS}_{\\mathrm{raw}} - \\mathrm{CRPS}_{\\mathrm{calibrated}}$.\n- Task 1: Derive the closed-form expression for the Continuous Ranked Probability Score (CRPS) for a normal predictive distribution $N(\\mu, \\sigma^2)$ and an observation $y$, in terms of the standardized error $z = (y - \\mu)/\\sigma$, the standard normal probability density function $\\phi(z)$, and the standard normal cumulative distribution function $\\Phi(z)$.\n- Task 2: Compute $\\mathrm{CRPS}_{\\mathrm{raw}}$ and $\\mathrm{CRPS}_{\\mathrm{calibrated}}$.\n- Task 3: Compute $\\Delta$ to four significant figures.\n- Task 4: Provide a qualitative explanation for how calibration affects the CRPS.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-grounded in the field of numerical weather prediction and forecast verification. The Continuous Ranked Probability Score (CRPS), Model Output Statistics (MOS), and Bayesian Model Averaging (BMA) are all standard and well-established concepts. The physical quantities and their values (air temperature in Kelvin, standard deviations) are realistic. The problem is self-contained, with all necessary data and definitions provided. The tasks are clearly stated and lead to a unique, meaningful solution. There are no scientific or logical contradictions, ambiguities, or unrealistic assumptions.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. The solution process will now proceed.\n\n### Derivation of the CRPS for a Normal Distribution\nThe CRPS for a predictive cumulative distribution function (CDF) $F(x)$ and a single scalar observation $y$ can be defined using an alternative, computationally convenient form:\n$$\n\\mathrm{CRPS}(F, y) = E_F[|X - y|] - \\frac{1}{2} E_F[|X - X'|]\n$$\nwhere $X$ and $X'$ are independent random variables drawn from the predictive distribution with CDF $F$.\n\nIn this problem, the predictive distribution is Gaussian, $X \\sim N(\\mu, \\sigma^2)$.\n\nFirst, we evaluate the second term, $\\frac{1}{2} E_F[|X - X'|]$.\nLet $Z = X - X'$. Since $X$ and $X'$ are independent and identically distributed as $N(\\mu, \\sigma^2)$, their difference $Z$ follows a normal distribution with mean $E[Z] = E[X] - E[X'] = \\mu - \\mu = 0$ and variance $\\mathrm{Var}(Z) = \\mathrm{Var}(X) + \\mathrm{Var}(X') = \\sigma^2 + \\sigma^2 = 2\\sigma^2$. So, $Z \\sim N(0, 2\\sigma^2)$. The standard deviation of $Z$ is $\\sigma_Z = \\sqrt{2}\\sigma$.\nThe expectation of the absolute value of a zero-mean normal variable $Z$ is its mean absolute deviation, given by $\\sigma_Z \\sqrt{2/\\pi}$.\n$$\nE[|X - X'|] = E[|Z|] = (\\sqrt{2}\\sigma) \\sqrt{\\frac{2}{\\pi}} = \\frac{2\\sigma}{\\sqrt{\\pi}}\n$$\nThus, the second term is:\n$$\n\\frac{1}{2} E[|X - X'|] = \\frac{1}{2} \\left( \\frac{2\\sigma}{\\sqrt{\\pi}} \\right) = \\frac{\\sigma}{\\sqrt{\\pi}}\n$$\n\nNext, we evaluate the first term, $E_F[|X - y|]$.\nLet $W = X - y$. The random variable $W$ follows a normal distribution with mean $E[W] = E[X] - y = \\mu - y$ and variance $\\mathrm{Var}(W) = \\mathrm{Var}(X) = \\sigma^2$. So, $W \\sim N(\\mu - y, \\sigma^2)$.\nWe need to compute $E[|W|]$. Let $\\mu_W = \\mu - y$.\n$$\nE[|W|] = \\int_{-\\infty}^{\\infty} |w| \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(w - \\mu_W)^2}{2\\sigma^2}\\right) dw\n$$\nLet's perform a change of variables to the standard normal space: $u = (w - \\mu_W)/\\sigma$, so $w = \\sigma u + \\mu_W$ and $dw = \\sigma du$. The standard normal PDF is $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-u^2/2)$.\n$$\nE[|W|] = \\int_{-\\infty}^{\\infty} |\\sigma u + \\mu_W| \\phi(u) du = \\sigma \\int_{-\\infty}^{\\infty} |u + \\mu_W/\\sigma| \\phi(u) du\n$$\nWe recognize the standardized error $z = (y - \\mu)/\\sigma$, so $\\mu_W/\\sigma = (\\mu-y)/\\sigma = -z$.\n$$\nE[|X - y|] = \\sigma \\int_{-\\infty}^{\\infty} |u - z| \\phi(u) du\n$$\nWe split the integral at $u=z$:\n$$\nE[|X - y|] = \\sigma \\left[ \\int_{-\\infty}^{z} (z-u)\\phi(u)du + \\int_{z}^{\\infty} (u-z)\\phi(u)du \\right]\n$$\n$$\n= \\sigma \\left[ z\\int_{-\\infty}^{z}\\phi(u)du - \\int_{-\\infty}^{z}u\\phi(u)du + \\int_{z}^{\\infty}u\\phi(u)du - z\\int_{z}^{\\infty}\\phi(u)du \\right]\n$$\nWe use the properties of the standard normal distribution:\n- $\\int_{-\\infty}^{z}\\phi(u)du = \\Phi(z)$\n- $\\int_{z}^{\\infty}\\phi(u)du = 1 - \\Phi(z)$\n- $\\int u\\phi(u)du = -\\phi(u)$ (since $d\\phi(u)/du = -u\\phi(u)$), so $\\int_{-\\infty}^{z}u\\phi(u)du = [-\\phi(u)]_{-\\infty}^{z} = -\\phi(z)$, and $\\int_{z}^{\\infty}u\\phi(u)du = [-\\phi(u)]_{z}^{\\infty} = \\phi(z)$.\n\nSubstituting these results:\n$$\nE[|X - y|] = \\sigma \\left[ z\\Phi(z) - (-\\phi(z)) + (\\phi(z)) - z(1 - \\Phi(z)) \\right]\n$$\n$$\n= \\sigma \\left[ z\\Phi(z) + \\phi(z) + \\phi(z) - z + z\\Phi(z) \\right]\n$$\n$$\n= \\sigma \\left[ 2z\\Phi(z) - z + 2\\phi(z) \\right] = \\sigma \\left[ z(2\\Phi(z) - 1) + 2\\phi(z) \\right]\n$$\nCombining both terms, we get the final expression for the CRPS of a normal distribution:\n$$\n\\mathrm{CRPS}(N(\\mu, \\sigma^2), y) = \\sigma \\left[ z(2\\Phi(z) - 1) + 2\\phi(z) \\right] - \\frac{\\sigma}{\\sqrt{\\pi}}\n$$\n$$\n\\mathrm{CRPS} = \\sigma \\left( z(2\\Phi(z) - 1) + 2\\phi(z) - \\frac{1}{\\sqrt{\\pi}} \\right)\n$$\nThis is the required closed-form expression.\n\n### Computation of CRPS for Raw and Calibrated Ensembles\nWe will use the following numerical values for the constants:\n- $\\Phi(0) = 0.5$\n- $\\phi(0) = 1/\\sqrt{2\\pi} \\approx 0.398942$\n- For $z=1$: $\\Phi(1) \\approx 0.841345$, $\\phi(1) = \\exp(-0.5)/\\sqrt{2\\pi} \\approx 0.241971$\n- $1/\\sqrt{\\pi} \\approx 0.564190$\n\n**1. CRPS for the raw ensemble ($\\mathrm{CRPS}_{\\mathrm{raw}}$)**\n- Given: $\\mu_{\\mathrm{r}} = 289\\,\\mathrm{K}$, $\\sigma_{\\mathrm{r}} = 2\\,\\mathrm{K}$, $y = 291\\,\\mathrm{K}$.\n- Standardized error: $z_{\\mathrm{r}} = (291 - 289)/2 = 1$.\n- $\\mathrm{CRPS}_{\\mathrm{raw}} = \\sigma_{\\mathrm{r}} \\left( z_{\\mathrm{r}}(2\\Phi(z_{\\mathrm{r}}) - 1) + 2\\phi(z_{\\mathrm{r}}) - \\frac{1}{\\sqrt{\\pi}} \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{raw}} = 2 \\left( 1(2\\Phi(1) - 1) + 2\\phi(1) - \\frac{1}{\\sqrt{\\pi}} \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{raw}} \\approx 2 \\left( 1(2 \\times 0.841345 - 1) + 2 \\times 0.241971 - 0.564190 \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{raw}} \\approx 2 \\left( (1.68269 - 1) + 0.483942 - 0.564190 \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{raw}} \\approx 2 \\left( 0.68269 + 0.483942 - 0.564190 \\right) = 2(0.602442) \\approx 1.20488\\,\\mathrm{K}$.\n\n**2. CRPS for the calibrated ensemble ($\\mathrm{CRPS}_{\\mathrm{calibrated}}$)**\n- Given: $\\mu_{\\mathrm{c}} = 291\\,\\mathrm{K}$, $\\sigma_{\\mathrm{c}} = 2.5\\,\\mathrm{K}$, $y = 291\\,\\mathrm{K}$.\n- Standardized error: $z_{\\mathrm{c}} = (291 - 291)/2.5 = 0$.\n- $\\mathrm{CRPS}_{\\mathrm{calibrated}} = \\sigma_{\\mathrm{c}} \\left( z_{\\mathrm{c}}(2\\Phi(z_{\\mathrm{c}}) - 1) + 2\\phi(z_{\\mathrm{c}}) - \\frac{1}{\\sqrt{\\pi}} \\right)$\n- With $z_c = 0$, the first term becomes $0$.\n- $\\mathrm{CRPS}_{\\mathrm{calibrated}} = 2.5 \\left( 2\\phi(0) - \\frac{1}{\\sqrt{\\pi}} \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{calibrated}} \\approx 2.5 \\left( 2 \\times 0.398942 - 0.564190 \\right)$\n- $\\mathrm{CRPS}_{\\mathrm{calibrated}} \\approx 2.5 \\left( 0.797884 - 0.564190 \\right) = 2.5(0.233694) \\approx 0.584235\\,\\mathrm{K}$.\n\n### Computation of Improvement ($\\Delta$)\nThe improvement is the reduction in CRPS due to calibration.\n$$\n\\Delta = \\mathrm{CRPS}_{\\mathrm{raw}} - \\mathrm{CRPS}_{\\mathrm{calibrated}}\n$$\n$$\n\\Delta \\approx 1.20488\\,\\mathrm{K} - 0.584235\\,\\mathrm{K} \\approx 0.620645\\,\\mathrm{K}\n$$\nRounding to four significant figures, we get $\\Delta \\approx 0.6206\\,\\mathrm{K}$.\n\n### Qualitative Explanation\nThe derived formula, $\\mathrm{CRPS} = \\sigma ( z(2\\Phi(z) - 1) + 2\\phi(z) - 1/\\sqrt{\\pi} )$, reveals how the two main components of calibration—bias correction and spread adjustment—affect the score. The CRPS is a proper scoring rule that assesses both the sharpness (concentration) and reliability (statistical consistency) of a probabilistic forecast. A lower CRPS indicates a better forecast.\n\n1.  **Bias Correction (affecting $z$):** Bias correction adjusts the mean $\\mu$ of the forecast distribution to be closer, on average, to the observed outcome $y$. This directly reduces the magnitude of the standardized error, $|z| = |y-\\mu|/\\sigma$. The term in the parentheses, $g(z) = z(2\\Phi(z) - 1) + 2\\phi(z) - 1/\\sqrt{\\pi}$, is a non-negative function of $z$ that has a global minimum at $z=0$ (i.e., when the forecast mean equals the observation). Therefore, reducing bias by bringing $\\mu$ closer to $y$ (and thus $z$ closer to $0$) will always reduce the value of $g(z)$, leading to a lower (better) CRPS, provided $\\sigma$ is held constant. In this problem, the calibration was perfect in its bias correction for this specific instance, moving $\\mu$ from $289\\,\\mathrm{K}$ to $291\\,\\mathrm{K}$, which coincided with the observation. This changed $z$ from $1$ to $0$, substantially lowering the value of $g(z)$ and thus providing a large improvement to the score.\n\n2.  **Spread Adjustment (affecting $\\sigma$):** Spread adjustment modifies the standard deviation $\\sigma$ of the forecast distribution. Raw ensembles are often under-dispersive (overconfident), meaning their spread is too small to accurately represent the true forecast uncertainty. Calibration, particularly using methods like BMA, often increases the spread to a more reliable value. The impact of changing $\\sigma$ on the CRPS is twofold:\n    - There is a direct linear scaling factor $\\sigma$ in front of the expression. Increasing $\\sigma$ directly increases the CRPS, penalizing forecasts that are not sharp.\n    - The value of $z$ also depends on $\\sigma$.\n    In our specific case, the spread was increased from $\\sigma_{\\mathrm{r}} = 2\\,\\mathrm{K}$ to $\\sigma_{\\mathrm{c}} = 2.5\\,\\mathrm{K}$. For the calibrated case, $z=0$, so $\\mathrm{CRPS}_{\\mathrm{calibrated}} \\propto \\sigma_{\\mathrm{c}}$. The increase in spread from $2\\,\\mathrm{K}$ to $2.5\\,\\mathrm{K}$ acted to worsen the score. However, this penalty was much smaller than the substantial gain from eliminating the bias (reducing $z$ from $1$ to $0$). The net effect was a significant improvement ($\\Delta > 0$). This illustrates the fundamental trade-off that CRPS evaluates: the calibrated forecast is less sharp (larger $\\sigma$) but more reliable (unbiased), and in this case, the gain in reliability far outweighed the loss in sharpness. For a deterministic forecast ($\\sigma \\to 0$), the CRPS converges to the absolute error, $|y-\\mu|$. Calibration ensures the probabilistic forecast is penalized for being overconfident when it is wrong.\n\nIn summary, calibration improved the overall forecast quality by correcting the significant bias of the raw ensemble, even though it required increasing the forecast spread. The CRPS metric correctly identifies this as a net improvement.",
            "answer": "$$\\boxed{0.6206}$$"
        },
        {
            "introduction": "While a single score like the CRPS provides a holistic evaluation, diagnosing specific model deficiencies is crucial for iterative improvement. A common failure mode in predictive models is miscalibration of variance, leading to prediction intervals that are either too wide (underconfident) or too narrow (overconfident). This practice challenges you to mathematically explore this issue by deriving the actual coverage probability of a nominal prediction interval when the forecast variance is incorrect . This analysis is fundamental for understanding and ensuring the reliability of uncertainty estimates in operational forecasting.",
            "id": "4065264",
            "problem": "In numerical weather prediction, postprocessing using Model Output Statistics (MOS) aims to correct systematic errors in raw model output and produce a predictive distribution for a weather quantity (for example, near-surface temperature) at a given site and lead time. A common, well-tested approach in MOS is to assume that conditional on predictors (e.g., ensemble mean and spread), the verifying observation $Y$ is Gaussian with a mean corrected by linear regression and a variance estimated from past errors. Suppose the MOS predictive distribution for $Y$ given predictors is Gaussian with mean $\\mu_{\\text{MOS}}$ and variance $\\sigma_{\\text{MOS}}^{2}$, and prediction intervals are constructed by inverting this predictive cumulative distribution function. The intended nominal two-sided prediction interval at level $1-\\alpha$ uses symmetric quantiles around the MOS mean. However, in practice, variance estimates can be miscalibrated relative to the true verifying distribution due to sampling variability, regime shifts, or imperfect spread-skill relationships, even when the predictive mean is unbiased.\n\nAssume the following scientifically realistic and self-consistent setting:\n- The MOS predictive distribution is $Y \\mid \\text{predictors} \\sim \\mathcal{N}\\!\\left(\\mu_{\\text{MOS}},\\,\\sigma_{\\text{MOS}}^{2}\\right)$.\n- The actual verifying distribution is unbiased in mean but has a multiplicative variance miscalibration factor $\\lambda>0$: $Y \\mid \\text{predictors} \\sim \\mathcal{N}\\!\\left(\\mu_{\\text{MOS}},\\,\\lambda\\,\\sigma_{\\text{MOS}}^{2}\\right)$.\n- Let $\\Phi$ denote the cumulative distribution function of the standard normal distribution, and let $\\Phi^{-1}$ denote its quantile function. Let $z_{p}=\\Phi^{-1}(p)$ for $p\\in(0,1)$.\n\nTask:\n1. Starting from the definition of a prediction interval as the inverse image of the predictive cumulative distribution function, construct the nominal two-sided $(1-\\alpha)$ prediction interval for $Y$ implied by the MOS predictive distribution.\n2. Using the frequentist definition of coverage probability and the properties of the Gaussian distribution, derive the actual coverage probability of this nominal $(1-\\alpha)$ prediction interval under the true verifying distribution with variance factor $\\lambda$.\n\nExpress your final answer as a single closed-form analytic expression for the actual coverage probability in terms of $\\alpha$ and $\\lambda$. No numerical evaluation is required. If you introduce any additional functions, clearly define them in your derivation. The final answer must be a single expression and must not include units or inequalities.",
            "solution": "The problem statement has been validated and is deemed scientifically sound, well-posed, and free of contradictions. The task is to derive the actual coverage probability of a nominal prediction interval when the variance of the underlying Gaussian process is miscalibrated.\n\nThe derivation proceeds in two parts as requested.\n\n**Part 1: Construction of the Nominal Prediction Interval**\n\nThe nominal prediction interval is constructed based on the assumed Model Output Statistics (MOS) predictive distribution. This distribution is given as a normal distribution for the verifying observation $Y$, conditional on the predictors:\n$$ Y \\mid \\text{predictors} \\sim \\mathcal{N}\\!\\left(\\mu_{\\text{MOS}},\\,\\sigma_{\\text{MOS}}^{2}\\right) $$\nA two-sided prediction interval with a nominal coverage level of $1-\\alpha$ is defined by the quantiles of this distribution. Specifically, a symmetric interval is constructed using the $\\frac{\\alpha}{2}$ and $1-\\frac{\\alpha}{2}$ quantiles.\n\nLet $F_{\\text{MOS}}$ be the cumulative distribution function (CDF) of this nominal distribution. The interval $[L, U]$ is constructed such that $F_{\\text{MOS}}(L) = \\frac{\\alpha}{2}$ and $F_{\\text{MOS}}(U) = 1 - \\frac{\\alpha}{2}$. To find these quantiles, we standardize the random variable $Y$ according to the nominal distribution. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$.\n$$ Z = \\frac{Y - \\mu_{\\text{MOS}}}{\\sigma_{\\text{MOS}}} $$\nThe quantiles of the standard normal distribution are denoted by $z_{p} = \\Phi^{-1}(p)$, where $\\Phi$ is the CDF of the standard normal distribution. The desired quantiles for $Z$ are $z_{\\alpha/2}$ and $z_{1-\\alpha/2}$.\nThe nominal interval is constructed to satisfy:\n$$ P(z_{\\alpha/2} \\le Z \\le z_{1-\\alpha/2}) = 1 - \\alpha $$\nSubstituting the expression for $Z$:\n$$ P\\left(z_{\\alpha/2} \\le \\frac{Y - \\mu_{\\text{MOS}}}{\\sigma_{\\text{MOS}}} \\le z_{1-\\alpha/2}\\right) = 1 - \\alpha $$\nWe can solve for $Y$ by rearranging the inequality:\n$$ \\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{\\alpha/2} \\le Y \\le \\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{1-\\alpha/2} $$\nThe nominal $(1-\\alpha)$ prediction interval, denoted as $I_{\\text{nom}}$, is therefore:\n$$ I_{\\text{nom}} = [\\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{\\alpha/2}, \\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{1-\\alpha/2}] $$\nDue to the symmetry of the standard normal distribution, we have $z_{\\alpha/2} = -z_{1-\\alpha/2}$. The interval can be expressed more compactly as:\n$$ I_{\\text{nom}} = [\\mu_{\\text{MOS}} - \\sigma_{\\text{MOS}}z_{1-\\alpha/2}, \\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{1-\\alpha/2}] $$\n\n**Part 2: Derivation of the Actual Coverage Probability**\n\nThe actual coverage probability is the probability that a random draw from the *true* verifying distribution falls within the *nominal* prediction interval $I_{\\text{nom}}$.\nThe true distribution is given as:\n$$ Y \\mid \\text{predictors} \\sim \\mathcal{N}\\!\\left(\\mu_{\\text{MOS}},\\,\\lambda\\,\\sigma_{\\text{MOS}}^{2}\\right) $$\nwhere $\\lambda > 0$ is the multiplicative variance miscalibration factor. The key features are that the mean is still $\\mu_{\\text{MOS}}$ (unbiased), but the true variance is $\\lambda\\sigma_{\\text{MOS}}^2$, and thus the true standard deviation is $\\sqrt{\\lambda}\\sigma_{\\text{MOS}}$.\n\nWe need to calculate the probability $P(Y \\in I_{\\text{nom}})$, where $Y$ follows this true distribution.\n$$ P_{\\text{actual}} = P(\\mu_{\\text{MOS}} - \\sigma_{\\text{MOS}}z_{1-\\alpha/2} \\le Y \\le \\mu_{\\text{MOS}} + \\sigma_{\\text{MOS}}z_{1-\\alpha/2}) $$\nTo evaluate this probability, we must standardize $Y$ using its true mean and true standard deviation. Let $Z'$ be a standard normal random variable defined as:\n$$ Z' = \\frac{Y - \\mu_{\\text{MOS}}}{\\sqrt{\\lambda}\\sigma_{\\text{MOS}}} \\sim \\mathcal{N}(0, 1) $$\nWe now transform the inequality for $Y$ into an inequality for $Z'$.\n\nFirst, subtract the mean $\\mu_{\\text{MOS}}$ from all parts of the inequality:\n$$ -\\sigma_{\\text{MOS}}z_{1-\\alpha/2} \\le Y - \\mu_{\\text{MOS}} \\le \\sigma_{\\text{MOS}}z_{1-\\alpha/2} $$\nNext, divide all parts by the true standard deviation, $\\sqrt{\\lambda}\\sigma_{\\text{MOS}}$ (since $\\lambda > 0$ and $\\sigma_{\\text{MOS}} > 0$, the inequality direction is preserved):\n$$ \\frac{-\\sigma_{\\text{MOS}}z_{1-\\alpha/2}}{\\sqrt{\\lambda}\\sigma_{\\text{MOS}}} \\le \\frac{Y - \\mu_{\\text{MOS}}}{\\sqrt{\\lambda}\\sigma_{\\text{MOS}}} \\le \\frac{\\sigma_{\\text{MOS}}z_{1-\\alpha/2}}{\\sqrt{\\lambda}\\sigma_{\\text{MOS}}} $$\nSimplifying the expressions on the left and right sides yields:\n$$ -\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}} \\le Z' \\le \\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}} $$\nThe actual coverage probability is the probability that the standard normal variable $Z'$ lies within this new interval:\n$$ P_{\\text{actual}} = P\\left(-\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}} \\le Z' \\le \\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right) $$\nThis probability can be expressed using the standard normal CDF, $\\Phi(x)$:\n$$ P_{\\text{actual}} = \\Phi\\left(\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right) - \\Phi\\left(-\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right) $$\nUsing the symmetry property of the standard normal CDF, $\\Phi(-x) = 1 - \\Phi(x)$, we can simplify this expression:\n$$ P_{\\text{actual}} = \\Phi\\left(\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right) - \\left[1 - \\Phi\\left(\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right)\\right] $$\n$$ P_{\\text{actual}} = 2\\Phi\\left(\\frac{z_{1-\\alpha/2}}{\\sqrt{\\lambda}}\\right) - 1 $$\nFinally, we substitute the definition $z_{1-\\alpha/2} = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)$ to obtain the final expression for the actual coverage probability in terms of $\\alpha$ and $\\lambda$:\n$$ P_{\\text{actual}} = 2\\Phi\\left(\\frac{\\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)}{\\sqrt{\\lambda}}\\right) - 1 $$\nThis is the required closed-form analytic expression.",
            "answer": "$$\n\\boxed{2\\Phi\\left(\\frac{\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)}{\\sqrt{\\lambda}}\\right) - 1}\n$$"
        },
        {
            "introduction": "Effective statistical models must be not only accurate but also computationally feasible, especially in an operational context with large datasets and tight deadlines. Bayesian Model Averaging is a powerful technique, but its implementation via the Expectation-Maximization (EM) algorithm has associated computational costs. This final practice moves from statistical theory to computational reality, asking you to analyze the algorithmic complexity of the EM algorithm as applied to BMA . By determining how the runtime scales with the number of observations ($n$) and ensemble members ($K$), you will develop the critical skill of assessing the practical viability of a modeling approach for large-scale applications.",
            "id": "4065271",
            "problem": "Consider a Model Output Statistics (MOS) calibration problem for daily maximum temperature in a numerical weather prediction ensemble, where Bayesian Model Averaging (BMA) is used to combine $K$ ensemble members into a predictive mixture. Let $x_{i,k}$ denote the forecast from ensemble member $k \\in \\{1,\\dots,K\\}$ for case $i \\in \\{1,\\dots,n\\}$, and let $y_{i}$ denote the verifying observation. Assume a BMA model with Gaussian kernels where the conditional predictive density for $y_{i}$ is a finite mixture,\n$$\np(y_{i} \\mid x_{i,1},\\dots,x_{i,K}) \\;=\\; \\sum_{k=1}^{K} w_{k} \\, \\phi\\!\\left(y_{i} \\,\\big|\\, \\mu_{i,k}, \\sigma_{k}^{2}\\right),\n$$\nwith mixture weights $w_{k} \\ge 0$, $\\sum_{k=1}^{K} w_{k} = 1$, component means $\\mu_{i,k} = a_{k} + b_{k} x_{i,k}$, and component variances $\\sigma_{k}^{2} > 0$. Here $\\phi(\\cdot \\mid \\mu,\\sigma^{2})$ denotes the Gaussian probability density function. The parameters $\\{w_{k},a_{k},b_{k},\\sigma_{k}^{2}\\}_{k=1}^{K}$ are estimated by the Expectation–Maximization (EM) algorithm.\n\nThe EM algorithm proceeds by alternating the following steps:\n- Expectation (E) step: compute the responsibilities\n$$\nr_{i,k} \\;=\\; \\frac{w_{k} \\, \\phi\\!\\left(y_{i} \\,\\big|\\, a_{k} + b_{k} x_{i,k}, \\sigma_{k}^{2}\\right)}{\\sum_{j=1}^{K} w_{j} \\, \\phi\\!\\left(y_{i} \\,\\big|\\, a_{j} + b_{j} x_{i,j}, \\sigma_{j}^{2}\\right)} \\quad \\text{for all } i \\in \\{1,\\dots,n\\},\\; k \\in \\{1,\\dots,K\\}.\n$$\n- Maximization (M) step: update $w_{k}$, $(a_{k},b_{k})$, and $\\sigma_{k}^{2}$ using weighted sufficient statistics based on $\\{r_{i,k}\\}$; in particular, for each $k$ define the weighted sums\n$$\nS_{0,k} = \\sum_{i=1}^{n} r_{i,k}, \\quad S_{x,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k}, \\quad S_{y,k} = \\sum_{i=1}^{n} r_{i,k} y_{i}, \\quad S_{xx,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k}^{2}, \\quad S_{xy,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k} y_{i},\n$$\nand obtain $(a_{k},b_{k})$ by solving the $2 \\times 2$ normal equations for weighted least squares and update $\\sigma_{k}^{2}$ via the weighted residual sum of squares.\n\nAssume the following computational cost model:\n- Evaluating one Gaussian density $\\phi(y \\mid \\mu,\\sigma^{2})$ at given $(y,\\mu,\\sigma^{2})$ (including computing $\\mu = a + b x$) uses a constant number of floating-point operations, denoted $c_{\\mathrm{dens}}$, independent of $n$ and $K$.\n- Each arithmetic operation ($+$, $-$, $\\times$, $\\div$) counts as $1$ floating-point operation, and computing a scalar exponential is included in $c_{\\mathrm{dens}}$.\n- Solving each $2 \\times 2$ linear system for $(a_{k},b_{k})$ is $O(1)$ with a constant number of floating-point operations $c_{\\mathrm{lin}}$, independent of $n$ and $K$.\n- Ignore memory access costs and any parallelization overhead; treat all evaluations as sequential.\n\nStarting from these definitions and the EM algorithm structure, derive a tight asymptotic expression for the total floating-point operation count of one EM iteration as a function of $n$ and $K$, and provide the dominant scaling in Big–O notation. Express your final answer as a single symbolic Big–O expression with respect to $n$ and $K$. Do not provide intermediate derivations or bounds in the final answer.",
            "solution": "The user wants to determine the computational complexity of one iteration of the Expectation-Maximization (EM) algorithm for a specific Bayesian Model Averaging (BMA) model. The total complexity will be the sum of the complexities of its two constituent steps: the Expectation (E) step and the Maximization (M) step.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens:**\n-   **Model:** Bayesian Model Averaging (BMA) with $K$ ensemble members and $n$ cases.\n-   **Data:** Forecast $x_{i,k}$ for case $i \\in \\{1,\\dots,n\\}$ and member $k \\in \\{1,\\dots,K\\}$. Observation $y_i$ for case $i$.\n-   **Predictive Density:** $p(y_{i} \\mid x_{i,1},\\dots,x_{i,K}) = \\sum_{k=1}^{K} w_{k} \\, \\phi(y_{i} \\mid \\mu_{i,k}, \\sigma_{k}^{2})$, where $\\phi(\\cdot \\mid \\mu,\\sigma^{2})$ is the Gaussian PDF.\n-   **Parameters:** Weights $w_k \\ge 0$ with $\\sum w_k = 1$, component means $\\mu_{i,k} = a_{k} + b_{k} x_{i,k}$, and component variances $\\sigma_{k}^{2} > 0$. The full parameter set is $\\{w_{k}, a_{k}, b_{k}, \\sigma_{k}^{2}\\}_{k=1}^{K}$.\n-   **E-Step Formula:** The responsibility $r_{i,k}$ is given by\n    $$\n    r_{i,k} = \\frac{w_{k} \\, \\phi(y_{i} \\mid a_{k} + b_{k} x_{i,k}, \\sigma_{k}^{2})}{\\sum_{j=1}^{K} w_{j} \\, \\phi(y_{i} \\mid a_{j} + b_{j} x_{i,j}, \\sigma_{j}^{2})}.\n    $$\n-   **M-Step Description:** Parameters are updated using sufficient statistics: $S_{0,k} = \\sum_{i=1}^{n} r_{i,k}$, $S_{x,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k}$, $S_{y,k} = \\sum_{i=1}^{n} r_{i,k} y_{i}$, $S_{xx,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k}^{2}$, $S_{xy,k} = \\sum_{i=1}^{n} r_{i,k} x_{i,k} y_{i}$. The pairs $(a_k, b_k)$ are found by solving a $2 \\times 2$ linear system, and $\\sigma_k^2$ is updated via weighted residual sum of squares.\n-   **Cost Model:**\n    -   Evaluation of one Gaussian density $\\phi(\\cdot)$, including the mean calculation $\\mu=a+bx$, costs $c_{\\mathrm{dens}}$ floating-point operations (FLOPs).\n    -   Arithmetic operations $(+, -, \\times, \\div)$ each count as $1$ FLOP.\n    -   Solving a $2 \\times 2$ linear system costs $c_{\\mathrm{lin}}$ FLOPs.\n    -   Costs are sequential; parallelization and memory costs are ignored.\n\n**1.2. Validate Using Extracted Givens:**\n-   **Scientifically Grounded:** The problem describes a standard application of the EM algorithm to a Gaussian mixture model for statistical post-processing in numerical weather prediction. This is a well-established and scientifically sound method.\n-   **Well-Posed:** The problem is well-defined. It provides a specific algorithm and a cost model, asking for a derivation of computational complexity, which is a deterministic mathematical task.\n-   **Objective:** The problem is stated using precise mathematical definitions and algorithmic steps, free from any subjectivity.\n-   **Completeness:** All necessary components for the analysis are provided. The phrase \"in particular\" for the sufficient statistics correctly implies that the list may not be exhaustive, and the standard formula for the variance update might require additional statistics, which is a reasonable and standard aspect of such derivations.\n\n**1.3. Verdict and Action:**\nThe problem is valid. It is scientifically sound, well-posed, objective, and self-contained. I will now proceed with the solution.\n\n### Step 2: Derivation of a Tight Asymptotic Expression\n\nThe total computational cost for one EM iteration, $T(n,K)$, is the sum of the costs of the E-step, $T_E(n,K)$, and the M-step, $T_M(n,K)$.\n\n**Analysis of the E-Step**\n\nThe E-step involves computing the responsibility $r_{i,k}$ for each case $i \\in \\{1, \\dots, n\\}$ and each component $k \\in \\{1, \\dots, K\\}$.\nLet's denote the numerator term as $d_{i,k} = w_{k} \\, \\phi(y_{i} \\mid a_{k} + b_{k} x_{i,k}, \\sigma_{k}^{2})$. The denominator is then $D_i = \\sum_{j=1}^{K} d_{i,j}$.\n\n1.  **Compute all $d_{i,k}$ terms:** For each pair $(i,k)$, we compute $d_{i,k}$. According to the cost model, evaluating $\\phi(y_{i} \\mid a_{k} + b_{k} x_{i,k}, \\sigma_{k}^{2})$ costs $c_{\\mathrm{dens}}$ FLOPs. This is followed by one multiplication with the weight $w_k$.\n    -   Cost per term $d_{i,k}$: $c_{\\mathrm{dens}} + 1$ FLOPs.\n    -   There are $n \\times K$ such terms.\n    -   Total cost to compute all numerators: $nK(c_{\\mathrm{dens}} + 1)$ FLOPs.\n\n2.  **Compute all denominators $D_i$:** For each case $i$, the denominator $D_i$ is the sum of $K$ terms ($d_{i,1}, \\dots, d_{i,K}$) which have already been computed. This summation requires $K-1$ additions.\n    -   This is done for each of the $n$ cases.\n    -   Total cost to compute all denominators: $n(K-1)$ FLOPs.\n\n3.  **Compute all responsibilities $r_{i,k}$:** For each pair $(i,k)$, the responsibility is calculated as $r_{i,k} = d_{i,k} / D_i$. This is one division.\n    -   There are $n \\times K$ responsibilities.\n    -   Total cost for divisions: $nK$ FLOPs.\n\nThe total cost for the E-step, $T_E(n,K)$, is the sum of these costs:\n$$\nT_E(n,K) = nK(c_{\\mathrm{dens}} + 1) + n(K-1) + nK = nKc_{\\mathrm{dens}} + nK + nK - n + nK = (c_{\\mathrm{dens}} + 3)nK - n.\n$$\n\n**Analysis of the M-Step**\n\nThe M-step updates the parameters $\\{w_{k}, a_{k}, b_{k}, \\sigma_{k}^{2}\\}_{k=1}^{K}$ using the responsibilities $r_{i,k}$. This involves two phases: calculating sufficient statistics and then updating the parameters.\n\n1.  **Calculate Sufficient Statistics:** The update rules require weighted sums. The problem lists five sums. The update for $\\sigma_k^2$ is \"via the weighted residual sum of squares\", which for a linear model $\\mu_{i,k} = a_k + b_k x_{i,k}$ is $\\sum_{i=1}^n r_{i,k} (y_i - \\mu_{i,k})^2$. Expanding this reveals that it is a function of the listed statistics plus an additional one, $S_{yy,k} = \\sum_{i=1}^n r_{i,k} y_i^2$. We thus need to compute a total of six sufficient statistics for each component $k$: $\\{S_{0,k}, S_{x,k}, S_{y,k}, S_{xx,k}, S_{xy,k}, S_{yy,k}\\}$.\n\n    An efficient way to compute these $6K$ sums is with a nested loop structure:\n    -   Initialize all $6K$ sums to $0$. This cost is $O(K)$ and is negligible compared to the main computation.\n    -   Loop over $i$ from $1$ to $n$:\n        -   Pre-compute $y_i^2$. Cost: $1$ multiplication.\n        -   Loop over $k$ from $1$ to $K$:\n            -   `S_{0,k} += r_{i,k}`: $1$ addition.\n            -   `S_{x,k} += r_{i,k} * x_{i,k}`: $1$ multiplication, $1$ addition.\n            -   `S_{y,k} += r_{i,k} * y_i`: $1$ multiplication, $1$ addition.\n            -   `S_{xx,k} += r_{i,k} * x_{i,k}^2`: $2$ multiplications ($x_{i,k}^2$ and then by $r_{i,k}$), $1$ addition.\n            -   `S_{xy,k} += r_{i,k} * x_{i,k} * y_i`: $2$ multiplications, $1$ addition.\n            -   `S_{yy,k} += r_{i,k} * y_i^2`: $1$ multiplication (with pre-computed $y_i^2$), $1$ addition.\n    -   Total FLOPs per $(i,k)$ pair inside the inner loop: $(0+1) + (1+1) + (1+1) + (2+1) + (2+1) + (1+1) = 13$ FLOPs.\n    -   The total cost of the double loop is $n \\times (1 + K \\times 13) = n + 13nK$.\n\n2.  **Update Parameters:** After computing the sufficient statistics:\n    -   **Update $w_k$:** The update is $w_k = S_{0,k} / n$. This requires one division for each of the $K$ components. Total cost: $K$ FLOPs.\n    -   **Update $(a_k, b_k)$:** For each $k$, this involves setting up and solving a $2 \\times 2$ system using the computed statistics. The problem states this costs $c_{\\mathrm{lin}}$ FLOPs per component. Total cost: $Kc_{\\mathrm{lin}}$ FLOPs.\n    -   **Update $\\sigma_k^2$:** The update is $\\sigma_k^2 = \\frac{1}{S_{0,k}} \\sum_{i=1}^n r_{i,k} (y_i - (a_k + b_k x_{i,k}))^2$. This expression can be computed using the sufficient statistics and the newly found $a_k, b_k$. This calculation involves a constant number of arithmetic operations for each $k$. Let this constant cost be $c_{\\mathrm{var}}$. Total cost: $Kc_{\\mathrm{var}}$ FLOPs.\n\nThe total cost for the M-step, $T_M(n,K)$, is the sum of these costs:\n$$\nT_M(n,K) = (n + 13nK) + K + Kc_{\\mathrm{lin}} + Kc_{\\mathrm{var}} = 13nK + n + K(1 + c_{\\mathrm{lin}} + c_{\\mathrm{var}}).\n$$\n\n**Total Cost for One EM Iteration**\n\nThe total number of FLOPs, $T(n,K)$, is the sum of the E-step and M-step costs:\n$$\nT(n,K) = T_E(n,K) + T_M(n,K)\n$$\n$$\nT(n,K) = \\left((c_{\\mathrm{dens}} + 3)nK - n\\right) + \\left(13nK + n + K(1 + c_{\\mathrm{lin}} + c_{\\mathrm{var}})\\right)\n$$\n$$\nT(n,K) = (c_{\\mathrm{dens}} + 3 + 13)nK + (-n + n) + K(1 + c_{\\mathrm{lin}} + c_{\\mathrm{var}})\n$$\n$$\nT(n,K) = (c_{\\mathrm{dens}} + 16)nK + (1 + c_{\\mathrm{lin}} + c_{\\mathrm{var}})K.\n$$\nThis is the tight asymptotic expression for the total operation count.\n\n### Step 3: Dominant Scaling in Big-O Notation\n\nThe expression for the total cost is $T(n,K) = C_1 nK + C_2 K$, where $C_1 = c_{\\mathrm{dens}} + 16$ and $C_2 = 1 + c_{\\mathrm{lin}} + c_{\\mathrm{var}}$ are positive constants independent of $n$ and $K$. For typical applications where the number of training cases $n$ and ensemble members $K$ are large, the term proportional to $nK$ will dominate the term proportional to $K$.\nTherefore, the dominant scaling of the computational complexity is given by:\n$$\nT(n,K) \\in O(nK).\n$$",
            "answer": "$$\n\\boxed{O(nK)}\n$$"
        }
    ]
}