{
    "hands_on_practices": [
        {
            "introduction": "To truly master a verification metric, it is invaluable to explore its behavior in controlled, idealized scenarios. This practice challenges you to derive the Fractions Skill Score (FSS) analytically for a perfect but spatially displaced forecast on a checkerboard grid . By working through this thought experiment, you will gain fundamental insights into how FSS quantifies displacement error and how its value is modulated by the neighborhood window size, revealing the mathematical core of the neighborhood method.",
            "id": "4045627",
            "problem": "Consider an infinite two-dimensional periodic square grid with unit grid spacing and binary fields defined on gridpoint centers. Let the observed binary field $O(i,j)$ be a perfect checkerboard such that $O(i,j) = 1$ if $i+j$ is even and $O(i,j) = 0$ if $i+j$ is odd, for all integers $i$ and $j$. The forecast binary field is a one-gridpoint shift of the observed field in the $x$-direction, $F(i,j) = O(i+1,j)$. You will evaluate the Fractions Skill Score (FSS) under the neighborhood method using square windows.\n\nDefine the neighborhood fractions $o_{s}(i,j)$ and $f_{s}(i,j)$ as the mean of $O$ and $F$, respectively, over the $s \\times s$ square of gridpoints centered at $(i,j)$, where $s \\in \\mathbb{N}$ is the window side length measured in gridpoints. Assume periodicity so that window sums are well-defined at every $(i,j)$. Define the Fractions Skill Score (FSS) for window size $s$ as\n$$\n\\mathrm{FSS}(s) \\equiv 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)},\n$$\nwhere\n$$\n\\mathrm{MSE}(s) \\equiv \\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left(f_{s}(i,j) - o_{s}(i,j)\\right)^{2},\n$$\nand\n$$\n\\mathrm{MSE}_{\\mathrm{ref}}(s) \\equiv \\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left(f_{s}(i,j)^{2} + o_{s}(i,j)^{2}\\right).\n$$\n\nStarting from these definitions and using only fundamental properties of averages and periodicity, derive a closed-form analytic expression for $\\mathrm{FSS}(s)$ that is valid for all integer $s \\geq 1$. Then, adopting the widely used operational definition of the “useful scale” as the smallest $s$ such that $\\mathrm{FSS}(s)$ exceeds the base-rate-dependent threshold\n$$\nT \\equiv \\frac{1}{2} + \\frac{f}{2},\n$$\nwhere $f$ is the domain-mean of $O$ at the native grid scale, determine the useful scale $s^{\\ast}$ for this configuration.\n\nProvide two outputs: (i) the analytic expression for $\\mathrm{FSS}(s)$ valid for all integer $s \\geq 1$, and (ii) the smallest integer $s^{\\ast}$ meeting the above threshold criterion. No rounding is required. The final answer must be presented as a two-entry row matrix as specified.",
            "solution": "The problem asks for an analytical expression for the Fractions Skill Score, $\\mathrm{FSS}(s)$, for a specific configuration of observed and forecast fields, and for the \"useful scale\" $s^{\\ast}$ derived from it.\n\nThe observed field is a checkerboard pattern, $O(i,j) = 1$ if $i+j$ is even and $O(i,j) = 0$ if $i+j$ is odd. The forecast field is a one-gridpoint shift, $F(i,j) = O(i+1,j)$.\n\nFirst, we establish a relationship between the fields $O(i,j)$ and $F(i,j)$.\nThe value of $O(i,j)$ depends on the parity of $i+j$.\nThe value of $F(i,j) = O(i+1,j)$ depends on the parity of $(i+1)+j = (i+j)+1$.\nIf $i+j$ is even, $O(i,j)=1$. Then $(i+j)+1$ is odd, so $F(i,j)=O(i+1,j)=0$.\nIf $i+j$ is odd, $O(i,j)=0$. Then $(i+j)+1$ is even, so $F(i,j)=O(i+1,j)=1$.\nIn both cases, $F(i,j) = 1 - O(i,j)$. The forecast field is the complement of the observed field.\n\nThe neighborhood fractions, $o_{s}(i,j)$ and $f_{s}(i,j)$, are the means of $O$ and $F$ over an $s \\times s$ window. Due to the linearity of the averaging operator, a similar relationship holds for the fractions:\n$$f_{s}(i,j) = \\frac{1}{s^2} \\sum_{\\text{window}} F(k,l) = \\frac{1}{s^2} \\sum_{\\text{window}} (1 - O(k,l)) = 1 - \\frac{1}{s^2} \\sum_{\\text{window}} O(k,l) = 1 - o_{s}(i,j)$$\n\nNow we can rewrite the Mean Squared Error (MSE) terms. The notation $\\langle \\cdot \\rangle$ will be used for the spatial average $\\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} (\\cdot)$.\n$$\\mathrm{MSE}(s) = \\langle (f_{s}(i,j) - o_{s}(i,j))^2 \\rangle = \\langle (1 - o_{s}(i,j) - o_{s}(i,j))^2 \\rangle = \\langle (1 - 2o_{s}(i,j))^2 \\rangle$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = \\langle f_{s}(i,j)^2 + o_{s}(i,j)^2 \\rangle = \\langle (1 - o_{s}(i,j))^2 + o_{s}(i,j)^2 \\rangle$$\n\nExpanding these expressions:\n$$\\mathrm{MSE}(s) = \\langle 1 - 4o_{s}(i,j) + 4o_{s}(i,j)^2 \\rangle = 1 - 4 \\langle o_{s} \\rangle + 4 \\langle o_{s}^2 \\rangle$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = \\langle 1 - 2o_{s}(i,j) + 2o_{s}(i,j)^2 \\rangle = 1 - 2 \\langle o_{s} \\rangle + 2 \\langle o_{s}^2 \\rangle$$\nTo proceed, we need to compute the spatial averages $\\langle o_s \\rangle$ and $\\langle o_s^2 \\rangle$.\n\nThe average of the convolved field $o_s$ is the average of the original field $O$. The field $O$ consists of equal numbers of $1$s and $0$s. Therefore, its spatial average is $\\frac{1}{2}$.\n$$\\langle O \\rangle = \\frac{1}{2} \\implies \\langle o_s \\rangle = \\frac{1}{2} \\text{ for any } s \\ge 1$$\n\nThe calculation of $\\langle o_s^2 \\rangle$ depends on the parity of the window size $s$.\n\nCase 1: $s$ is even.\nLet $s=2k$ for some integer $k \\ge 1$. An $s \\times s$ window can be perfectly tiled by $k^2$ non-overlapping $2 \\times 2$ blocks. In a checkerboard grid, any $2 \\times 2$ block of grid points contains exactly two points where $O=1$ and two points where $O=0$. Thus, the sum of $O$ over a $2 \\times 2$ block is $2$. The sum of $O$ over an $s \\times s$ window is $k^2 \\times 2 = (s/2)^2 \\times 2 = s^2/2$.\nThe fraction of $1$s in any $s \\times s$ window is constant:\n$$o_{s}(i,j) = \\frac{s^2/2}{s^2} = \\frac{1}{2} \\quad (\\text{for } s \\text{ even})$$\nSince $o_s(i,j)$ is a constant, its average is $\\langle o_s \\rangle = \\frac{1}{2}$ and its mean square is $\\langle o_s^2 \\rangle = (\\frac{1}{2})^2 = \\frac{1}{4}$.\nNow we find the MSE terms for even $s$:\n$$\\mathrm{MSE}(s) = 1 - 4(\\frac{1}{2}) + 4(\\frac{1}{4}) = 1 - 2 + 1 = 0$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = 1 - 2(\\frac{1}{2}) + 2(\\frac{1}{4}) = 1 - 1 + \\frac{1}{2} = \\frac{1}{2}$$\nThe FSS for even $s$ is:\n$$\\mathrm{FSS}(s) = 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)} = 1 - \\frac{0}{1/2} = 1$$\n\nCase 2: $s$ is odd.\nLet $s=2k+1$ for some integer $k \\ge 0$. The total number of points in the window is $s^2$. In this case, the number of $1$s and $0$s is not equal.\nFor a window centered at $(i,j)$, if $O(i,j)=1$ (i.e., $i+j$ is even), the window contains $\\frac{s^2+1}{2}$ points with value $1$. If $O(i,j)=0$ (i.e., $i+j$ is odd), it contains $\\frac{s^2-1}{2}$ points with value $1$.\nSo, $o_s(i,j)$ takes on two possible values:\n$$o_s(i,j) = \\frac{s^2+1}{2s^2} \\quad \\text{if } i+j \\text{ is even}$$\n$$o_s(i,j) = \\frac{s^2-1}{2s^2} \\quad \\text{if } i+j \\text{ is odd}$$\nSince $i+j$ is even for half the grid points and odd for the other half, the spatial average $\\langle o_s^2 \\rangle$ is:\n$$\\langle o_s^2 \\rangle = \\frac{1}{2} \\left( \\frac{s^2+1}{2s^2} \\right)^2 + \\frac{1}{2} \\left( \\frac{s^2-1}{2s^2} \\right)^2$$\n$$\\langle o_s^2 \\rangle = \\frac{1}{2 \\cdot 4s^4} \\left[ (s^4+2s^2+1) + (s^4-2s^2+1) \\right] = \\frac{1}{8s^4} (2s^4+2) = \\frac{s^4+1}{4s^4}$$\nNow we find the MSE terms for odd $s$:\n$$\\mathrm{MSE}(s) = 1 - 4(\\frac{1}{2}) + 4\\left(\\frac{s^4+1}{4s^4}\\right) = 1 - 2 + \\frac{s^4+1}{s^4} = -1 + 1 + \\frac{1}{s^4} = \\frac{1}{s^4}$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = 1 - 2(\\frac{1}{2}) + 2\\left(\\frac{s^4+1}{4s^4}\\right) = 1 - 1 + \\frac{s^4+1}{2s^4} = \\frac{s^4+1}{2s^4}$$\nThe FSS for odd $s$ is:\n$$\\mathrm{FSS}(s) = 1 - \\frac{1/s^4}{(s^4+1)/(2s^4)} = 1 - \\frac{2s^4}{s^4(s^4+1)} = 1 - \\frac{2}{s^4+1} = \\frac{s^4+1-2}{s^4+1} = \\frac{s^4-1}{s^4+1}$$\n\nTo provide a single analytic expression for all integer $s \\ge 1$:\n$$ \\mathrm{FSS}(s) = \\begin{cases} \\frac{s^4-1}{s^4+1} & \\text{if } s \\text{ is odd} \\\\ 1 & \\text{if } s \\text{ is even} \\end{cases} $$\nThis can be unified using the term $(-1)^s$:\n$$\\mathrm{FSS}(s) = \\frac{1-(-1)^s}{2} \\left(\\frac{s^4-1}{s^4+1}\\right) + \\frac{1+(-1)^s}{2} (1) = \\frac{(1-(-1)^s)(s^4-1) + (1+(-1)^s)(s^4+1)}{2(s^4+1)}$$\n$$= \\frac{s^4-1 - (-1)^s s^4 + (-1)^s + s^4+1 + (-1)^s s^4 + (-1)^s}{2(s^4+1)} = \\frac{2s^4 + 2(-1)^s}{2(s^4+1)} = \\frac{s^4+(-1)^s}{s^4+1}$$\nThis expression correctly yields $1$ for even $s$ and $\\frac{s^4-1}{s^4+1}$ for odd $s$.\n\nNext, we determine the useful scale $s^{\\ast}$. This is the smallest integer $s$ such that $\\mathrm{FSS}(s) > T$, where $T = \\frac{1}{2} + \\frac{f}{2}$.\nThe base rate $f$ is the domain-mean of $O$ at the native scale, which is $f = \\langle O \\rangle = \\frac{1}{2}$.\nThe threshold is $T = \\frac{1}{2} + \\frac{1/2}{2} = \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4}$.\n\nWe seek the smallest integer $s \\ge 1$ such that $\\mathrm{FSS}(s) > \\frac{3}{4}$.\nLet's test small integer values of $s$:\nFor $s=1$ (odd):\n$$\\mathrm{FSS}(1) = \\frac{1^4-1}{1^4+1} = 0$$\n$0 \\ngtr \\frac{3}{4}$, so $s=1$ is not the useful scale.\nFor $s=2$ (even):\n$$\\mathrm{FSS}(2) = 1$$\n$1 > \\frac{3}{4}$, so $s=2$ meets the criterion.\nSince we are looking for the smallest integer $s$, and we have found that $s=2$ satisfies the condition while $s=1$ does not, the useful scale is $s^{\\ast}=2$.\n\nThe two required outputs are the expression for $\\mathrm{FSS}(s)$ and the value of $s^{\\ast}$.\n(i) $\\mathrm{FSS}(s) = \\frac{s^4+(-1)^s}{s^4+1}$\n(ii) $s^{\\ast}=2$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{s^4+(-1)^s}{s^4+1} & 2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While analytical derivations provide insight, applying the FSS to real data requires a robust computational implementation. This exercise bridges the gap between theory and practice by guiding you through the construction of a numerically stable FSS calculator . You will implement critical safeguards to handle rare events and finite-precision arithmetic, ensuring your tool produces reliable and meaningful skill scores rather than spurious artifacts.",
            "id": "4045673",
            "problem": "You are given two-dimensional binary exceedance fields representing a numerical weather prediction (forecast) and a verifying analysis (observation). For each grid point, a neighborhood method computes the local fraction of exceedance by averaging the binary field within a square window. The Fractions Skill Score (FSS) compares these neighborhood fractions to quantify spatial forecast skill. Let $X \\in \\{0,1\\}^{M \\times N}$ denote the forecast binary field and $Y \\in \\{0,1\\}^{M \\times N}$ denote the observation binary field. For a square window of radius $r$ (so window width is $2r+1$) centered at grid point $(i,j)$, define the neighborhood fraction for the forecast and observation as\n$$\nf_{ij} = \\frac{1}{A_{ij}} \\sum_{(p,q) \\in W_{ij}} X_{pq}, \\quad o_{ij} = \\frac{1}{A_{ij}} \\sum_{(p,q) \\in W_{ij}} Y_{pq},\n$$\nwhere $W_{ij}$ is the set of in-domain indices within the square window centered at $(i,j)$, and $A_{ij}$ is the number of in-domain points in $W_{ij}$. The domain-level Fractions Skill Score is defined by aggregating over all grid points:\n$$\n\\mathrm{FSS} = \\frac{2 \\sum_{i,j} f_{ij} \\, o_{ij}}{\\sum_{i,j} f_{ij}^2 + \\sum_{i,j} o_{ij}^2}.\n$$\nIn practice, when the denominator is small (for example, for very rare events), numerical instability and spurious inflation of the score can occur due to finite precision and noise. Your task is to implement a numerically stable computation of $\\mathrm{FSS}$ that includes safeguards against spurious inflation.\n\nStarting from the fundamental definitions above, design and implement an algorithm that:\n- Computes neighborhood fractions $f_{ij}$ and $o_{ij}$ using square windows with boundary truncation (i.e., $A_{ij}$ equals the actual number of in-domain points in the window).\n- Aggregates $\\mathrm{FSS}$ as a ratio of sums as given above, not as an average of local ratios.\n- Applies the following safeguards:\n  1. Validity gating: exclude grid points where $f_{ij} + o_{ij} < \\theta$ for a user-specified threshold $\\theta$, to remove non-informative windows with negligible event mass.\n  2. Denominator regularization: replace the denominator $D = \\sum_{i,j} f_{ij}^2 + \\sum_{i,j} o_{ij}^2$ by $D_{\\mathrm{reg}} = D + \\varepsilon_{\\mathrm{reg}}$, where $\\varepsilon_{\\mathrm{reg}}$ is an adaptive positive constant derived from machine precision and empirical minimum non-zero fraction. Specifically, set\n     $$\n     \\varepsilon_{\\mathrm{reg}} = \\lambda \\, \\max\\!\\big( N_{\\mathrm{eff}} \\, \\epsilon_{\\mathrm{mach}}, \\, N_{\\mathrm{eff}} \\, p_{\\min}^2 \\big),\n     $$\n     where $N_{\\mathrm{eff}}$ is the number of included grid points after validity gating, $\\epsilon_{\\mathrm{mach}}$ is machine epsilon for double-precision arithmetic, $p_{\\min}$ is the minimum strictly positive value among $\\{f_{ij}, o_{ij}\\}$ over included points, and $\\lambda$ is a user-specified scaling constant.\n  3. Convention for zero-information cases: if $N_{\\mathrm{eff}} = 0$, return $\\mathrm{FSS} = 1$ (the forecast and observation are both effectively “no-event” everywhere under the gating threshold) rather than producing an undefined result.\n  4. Range enforcement: clip the final score to $[0,1]$.\n  \nYour program must implement the above and compute the stabilized $\\mathrm{FSS}$ for a provided test suite. All inputs are dimensionless and the outputs must be dimensionless real numbers. Express all outputs as decimal floats rounded to $6$ decimals.\n\nTest Suite:\nUse the following five test cases. Each case specifies $(X, Y, r, \\theta, \\lambda)$ with $M = N = 8$. In all cases, indices are zero-based and inclusive of endpoints for slice notation. Define $X$ and $Y$ exactly as specified.\n\n- Case $1$ (moderate event, small shift, typical denominator):\n  - $r = 1$, $\\theta = 0.05$, $\\lambda = 1.0$.\n  - $X$ has ones in rows $[3:6]$ and columns $[3:6]$ (a $3 \\times 3$ block centered), zeros elsewhere.\n  - $Y$ has ones in rows $[4:7]$ and columns $[3:6]$ (the same block shifted down by one), zeros elsewhere.\n- Case $2$ (rare events, small denominators, slight mismatch):\n  - $r = 1$, $\\theta = 0.05$, $\\lambda = 1.0$.\n  - $X$ has ones at coordinates $(0,0)$ and $(1,2)$, zeros elsewhere.\n  - $Y$ has a one at $(0,1)$, zeros elsewhere.\n- Case $3$ (no events, zero denominator):\n  - $r = 1$, $\\theta = 0.05$, $\\lambda = 1.0$.\n  - $X$ is all zeros.\n  - $Y$ is all zeros.\n- Case $4$ (completely mismatched clusters, normal denominator):\n  - $r = 1$, $\\theta = 0.05$, $\\lambda = 1.0$.\n  - $X$ has ones in rows $[0:3]$ and columns $[0:3]$ (top-left $3 \\times 3$ block), zeros elsewhere.\n  - $Y$ has ones in rows $[5:8]$ and columns $[5:8]$ (bottom-right $3 \\times 3$ block), zeros elsewhere.\n- Case $5$ (perfect single-point match, extremely rare):\n  - $r = 2$, $\\theta = 0.05$, $\\lambda = 1.0$.\n  - $X$ has a one at $(4,4)$, zeros elsewhere.\n  - $Y$ has a one at $(4,4)$, zeros elsewhere.\n\nOutput Specification:\nYour program should produce a single line of output containing the stabilized $\\mathrm{FSS}$ results for the five cases as a comma-separated list enclosed in square brackets, rounded to $6$ decimals, for example $[0.123456,0.234567,0.345678,0.456789,0.567890]$. No additional text may be printed.",
            "solution": "The problem requires the implementation of a numerically stable Fractions Skill Score (FSS) calculation for comparing binary forecast fields to observation fields. The FSS is a neighborhood-based verification metric widely used in meteorology. The core task involves computing local fractions of exceedance, aggregating them into a skill score, and applying specific numerical safeguards to handle common failure modes, such as division by near-zero denominators in cases of rare events.\n\nThe algorithm proceeds in four main stages:\n1.  Calculation of neighborhood fractions.\n2.  Application of a validity gate to filter non-informative grid points.\n3.  Aggregation of the score components (numerator and denominator) from the valid points.\n4.  Application of numerical regularization and final score calculation with clipping.\n\nLet $X$ and $Y$ be the $M \\times N$ binary forecast and observation fields, respectively. The window radius is $r$.\n\n**Step 1: Neighborhood Fraction Calculation**\n\nThe neighborhood fractions, $f_{ij}$ for the forecast and $o_{ij}$ for the observation, are computed at each grid point $(i,j)$. The fraction represents the density of 'event' points (value $1$) within a square window of width $W = 2r+1$ centered at $(i,j)$. The definition is:\n$$\nf_{ij} = \\frac{1}{A_{ij}} \\sum_{(p,q) \\in W_{ij}} X_{pq}, \\quad o_{ij} = \\frac{1}{A_{ij}} \\sum_{(p,q) \\in W_{ij}} Y_{pq}\n$$\nHere, $W_{ij}$ is the set of grid indices within the window centered at $(i,j)$, and $A_{ij}$ is the number of points in this window that lie within the domain boundaries (i.e., boundary truncation).\n\nThis operation is efficiently implemented using a 2D convolution. Let $K$ be a kernel of size $(2r+1) \\times (2r+1)$ with all elements equal to $1$. The sums $\\sum X_{pq}$ and $\\sum Y_{pq}$ can be computed by convolving $X$ and $Y$ with $K$.\n$$\n\\text{Sum}_{X} = X * K, \\quad \\text{Sum}_{Y} = Y * K\n$$\nThe convolution must handle boundaries by assuming values outside the domain are $0$, which corresponds to the `mode='constant', cval=0` setting in `scipy.ndimage.convolve`.\n\nThe normalization factor $A_{ij}$, which accounts for truncated windows near the boundaries, can be computed by convolving a field of ones, $I$ (where $I_{pq}=1$ for all $p,q$), with the same kernel $K$.\n$$\nA = I * K\n$$\nThe fraction fields are then obtained by element-wise division:\n$$\nf = \\frac{\\text{Sum}_{X}}{A}, \\quad o = \\frac{\\text{Sum}_{Y}}{A}\n$$\n\n**Step 2: Validity Gating**\n\nTo prevent non-informative regions (where both forecast and observation have near-zero event fractions) from influencing the score, a validity gate is applied. A grid point $(i,j)$ is considered valid only if the sum of its fractions meets or exceeds a threshold $\\theta$:\n$$\nf_{ij} + o_{ij} \\geq \\theta\n$$\nThis creates a boolean mask of valid grid points. The number of effective (valid) points, $N_{\\mathrm{eff}}$, is the total count of such points.\n\nA special case arises if $N_{\\mathrm{eff}} = 0$. This indicates that for the chosen window size and threshold, there are no significant events in either the forecast or the observation. Per the problem specification, this is considered a \"perfect\" forecast of a no-event field, and the FSS is defined to be $1$.\n\n**Step 3: Aggregation of Score Components**\n\nIf $N_{\\mathrm{eff}} > 0$, we proceed to calculate the primary components of the FSS formula over the set of valid grid points only. Let $V$ be the set of indices of valid points. The FSS numerator $N_{\\mathrm{FSS}}$ and denominator $D_{\\mathrm{FSS}}$ are:\n$$\nN_{\\mathrm{FSS}} = 2 \\sum_{(i,j) \\in V} f_{ij} \\, o_{ij}\n$$\n$$\nD_{\\mathrm{FSS}} = \\sum_{(i,j) \\in V} \\left( f_{ij}^2 + o_{ij}^2 \\right)\n$$\nThe standard FSS would be the ratio $N_{\\mathrm{FSS}} / D_{\\mathrm{FSS}}$.\n\n**Step 4: Denominator Regularization and Final Score Calculation**\n\nFor rare events, the denominator $D_{\\mathrm{FSS}}$ can be very small, leading to numerical instability and potentially inflated scores. To mitigate this, a regularization term $\\varepsilon_{\\mathrm{reg}}$ is added to the denominator. The term is adaptively defined as:\n$$\n\\varepsilon_{\\mathrm{reg}} = \\lambda \\, \\max\\!\\big( N_{\\mathrm{eff}} \\, \\epsilon_{\\mathrm{mach}}, \\, N_{\\mathrm{eff}} \\, p_{\\min}^2 \\big)\n$$\nwhere:\n- $\\lambda$ is a user-specified scaling factor.\n- $\\epsilon_{\\mathrm{mach}}$ is the machine epsilon for double-precision floating-point numbers, representing the smallest number such that $1.0 + \\epsilon_{\\mathrm{mach}} \\neq 1.0$.\n- $p_{\\min}$ is the minimum strictly positive value among all fraction values $\\{f_{ij}, o_{ij}\\}$ over the set of valid points $V$. If $N_{\\mathrm{eff}} > 0$ and $\\theta > 0$, at least one such positive fraction must exist.\n\nThe regularized denominator is $D_{\\mathrm{reg}} = D_{\\mathrm{FSS}} + \\varepsilon_{\\mathrm{reg}}$. The raw FSS is then computed as:\n$$\n\\mathrm{FSS}_{\\mathrm{raw}} = \\frac{N_{\\mathrm{FSS}}}{D_{\\mathrm{reg}}}\n$$\nThis regularization ensures the denominator is bounded away from zero, providing stability.\n\nFinally, the score is clipped to the range $[0,1]$ to enforce its definition as a skill score where $1$ is perfect and $0$ indicates no skill.\n$$\n\\mathrm{FSS} = \\mathrm{clip}(\\mathrm{FSS}_{\\mathrm{raw}}, 0, 1)\n$$\nThis final value is the numerically stabilized Fractions Skill Score.",
            "answer": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef compute_stabilized_fss(X, Y, r, theta, lambd):\n    \"\"\"\n    Computes the numerically stabilized Fractions Skill Score (FSS).\n\n    Args:\n        X (np.ndarray): The M x N binary forecast field.\n        Y (np.ndarray): The M x N binary observation field.\n        r (int): The radius for the square neighborhood window.\n        theta (float): The validity gating threshold.\n        lambd (float): The regularization scaling constant.\n\n    Returns:\n        float: The stabilized FSS value.\n    \"\"\"\n    if X.shape != Y.shape:\n        raise ValueError(\"Input fields X and Y must have the same shape.\")\n\n    M, N = X.shape\n    width = 2 * r + 1\n    kernel = np.ones((width, width))\n\n    # Step 1: Compute neighborhood fractions\n    # Use convolution to get sums in the sliding window.\n    # mode='constant', cval=0 handles boundaries correctly for this problem.\n    sum_X = convolve(X.astype(float), kernel, mode='constant', cval=0)\n    sum_Y = convolve(Y.astype(float), kernel, mode='constant', cval=0)\n\n    # To get the normalization factor A_ij (number of in-domain points),\n    # convolve a field of ones with the same kernel.\n    A = convolve(np.ones((M, N), dtype=float), kernel, mode='constant', cval=0)\n    \n    # Avoid division by zero, although A should be > 0 for r >= 0.\n    A[A == 0] = 1.0 \n    \n    f = sum_X / A\n    o = sum_Y / A\n\n    # Step 2: Apply validity gating\n    valid_mask = (f + o) >= theta\n    N_eff = np.sum(valid_mask)\n\n    # Step 3 (rule 3): Handle zero-information case\n    if N_eff == 0:\n        return 1.0\n\n    # Filter fractions to include only valid points\n    f_valid = f[valid_mask]\n    o_valid = o[valid_mask]\n\n    # Step 4: Aggregate score components\n    numerator_fss = 2.0 * np.sum(f_valid * o_valid)\n    denominator_fss = np.sum(f_valid**2) + np.sum(o_valid**2)\n    \n    if denominator_fss == 0:\n        # If numerator is also zero, it's a perfect no-event case\n        # (already covered by N_eff=0). If num > 0, it's an issue not\n        # expected by problem statement. A safe return for N=0, D=0 would be 1.\n        return 1.0 if numerator_fss == 0 else 0.0\n\n    # Step 5: Compute regularization term\n    positive_fractions = np.concatenate((f_valid[f_valid > 0], o_valid[o_valid > 0]))\n    \n    if positive_fractions.size == 0:\n        # This case should ideally not be reached if N_eff > 0 and theta > 0.\n        # If it is, it means all valid fractions were zero, so D=0, handled above.\n        # We can treat this as having no regularization.\n        p_min_sq = 0.0\n    else:\n        p_min = np.min(positive_fractions)\n        p_min_sq = p_min**2\n\n    eps_mach = np.finfo(np.float64).eps\n    eps_reg = lambd * max(N_eff * eps_mach, N_eff * p_min_sq)\n\n    # Step 6: Compute regularized FSS and clip\n    denominator_reg = denominator_fss + eps_reg\n    \n    # Final division, protected against zero denominator\n    fss_raw = numerator_fss / denominator_reg if denominator_reg != 0 else 0.0\n    \n    fss_final = np.clip(fss_raw, 0.0, 1.0)\n\n    return fss_final\n\ndef solve():\n    \"\"\"\n    Runs the test suite for the stabilized FSS computation.\n    \"\"\"\n    \n    M, N = 8, 8\n\n    # Case 1\n    X1 = np.zeros((M, N))\n    X1[3:6, 3:6] = 1\n    Y1 = np.zeros((M, N))\n    Y1[4:7, 3:6] = 1\n    case1 = (X1, Y1, 1, 0.05, 1.0)\n    \n    # Case 2\n    X2 = np.zeros((M, N))\n    X2[0, 0] = 1\n    X2[1, 2] = 1\n    Y2 = np.zeros((M, N))\n    Y2[0, 1] = 1\n    case2 = (X2, Y2, 1, 0.05, 1.0)\n\n    # Case 3\n    X3 = np.zeros((M, N))\n    Y3 = np.zeros((M, N))\n    case3 = (X3, Y3, 1, 0.05, 1.0)\n\n    # Case 4\n    X4 = np.zeros((M, N))\n    X4[0:3, 0:3] = 1\n    Y4 = np.zeros((M, N))\n    Y4[5:8, 5:8] = 1\n    case4 = (X4, Y4, 1, 0.05, 1.0)\n\n    # Case 5\n    X5 = np.zeros((M, N))\n    X5[4, 4] = 1\n    Y5 = np.zeros((M, N))\n    Y5[4, 4] = 1\n    case5 = (X5, Y5, 2, 0.05, 1.0)\n\n    test_cases = [case1, case2, case3, case4, case5]\n    \n    results = []\n    for params in test_cases:\n        X, Y, r, theta, lambd = params\n        fss = compute_stabilized_fss(X, Y, r, theta, lambd)\n        results.append(round(fss, 6))\n\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "The Fractions Skill Score is a powerful tool for diagnosing the performance of modern ensemble prediction systems. In this advanced practice, you will apply the FSS to an ensemble of forecasts to determine the \"useful scale\"—the spatial scale at which the forecasts become skillful . By computing this metric for both individual ensemble members and the ensemble mean, you will learn how to characterize the overall performance and internal variability of a probabilistic forecast system.",
            "id": "4045696",
            "problem": "You are given a gridded event field representing the occurrence of a meteorological phenomenon (e.g., thresholded precipitation \"yes/no\") and an ensemble of forecast fields, each represented as a binary array where the value $1$ denotes event occurrence and $0$ denotes non-occurrence. Your task is to construct a method to compute the \"useful scale\" for each ensemble member and for the ensemble mean using a neighborhood-based evaluation with the Fraction Skill Score (FSS), and to compare the distributions of useful scales across ensemble members.\n\nThe fundamental base in this setting consists of the following definitions and well-tested formulas:\n\n1. Let the forecast field be a binary array $F \\in \\{0,1\\}^{N_x \\times N_y}$ and the observation field be a binary array $O \\in \\{0,1\\}^{N_x \\times N_y}$.\n\n2. For a given neighborhood scale $s$ (in kilometers), and grid spacing $\\Delta x$ (in kilometers), define an odd integer window width in grid cells $w(s)$ by choosing the odd integer closest to $s/\\Delta x$. Given a square averaging kernel $K_s$ with $K_s(i,j) = 1$ for $-r \\le i,j \\le r$ where $w(s) = 2r+1$, define the neighborhood fraction fields $f_s$ and $o_s$ by discrete convolution\n   $$\n   f_s = \\frac{1}{w(s)^2} \\left( K_s * F \\right), \\quad o_s = \\frac{1}{w(s)^2} \\left( K_s * O \\right),\n   $$\n   where $*$ denotes two-dimensional discrete convolution and reflective boundary conditions are used so that values at the edges are treated by symmetric reflection.\n\n3. The Fraction Skill Score (FSS) at scale $s$ is defined by the normalized mean squared error formula\n   $$\n   \\mathrm{FSS}(s) = 1 - \\frac{\\sum_{i=1}^{N_x} \\sum_{j=1}^{N_y} \\left( f_s(i,j) - o_s(i,j) \\right)^2}{\\sum_{i=1}^{N_x} \\sum_{j=1}^{N_y} \\left( f_s(i,j)^2 + o_s(i,j)^2 \\right)}.\n   $$\n   If the denominator is zero (which can occur only when both $f_s$ and $o_s$ are identically zero), define $\\mathrm{FSS}(s) = 1$.\n\n4. For an ensemble of $M$ members $\\{F^{(m)}\\}_{m=1}^M$, define the ensemble mean field $E$ by\n   $$\n   E = \\frac{1}{M} \\sum_{m=1}^M F^{(m)},\n   $$\n   which is a real-valued field in $[0,1]^{N_x \\times N_y}$. At scale $s$, compute the smoothed ensemble mean fraction field $e_s$ by\n   $$\n   e_s = \\frac{1}{w(s)^2} \\left( K_s * E \\right),\n   $$\n   and compute $\\mathrm{FSS}_{\\text{mean}}(s)$ by replacing $f_s$ with $e_s$ in the Fraction Skill Score formula.\n\n5. Given a critical skill threshold $q \\in (0,1)$, define the useful scale $s^\\ast$ for a forecast (either a single member or the ensemble mean) as\n   $$\n   s^\\ast = \\min \\{ s \\in \\mathcal{S} : \\mathrm{FSS}(s) \\ge q \\},\n   $$\n   where $\\mathcal{S}$ is the set of tested scales. If no tested scale meets or exceeds the threshold, set $s^\\ast = \\max(\\mathcal{S})$.\n\nImplement a program that applies these definitions and computes, for each provided test case:\n- The useful scale for the ensemble mean, expressed in kilometers.\n- The median useful scale across ensemble members, expressed in kilometers.\n- The variance of the useful scales across ensemble members, expressed in square kilometers.\n\nUse the neighborhood method as defined above and the Fraction Skill Score (FSS) to compute useful scales. Reflective boundary conditions must be used during convolution. All outputs must be expressed in kilometers (for variance, square kilometers) without percentage signs. Angles are not involved. The program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, aggregating the results from all test cases as a list of lists in the form\n\"[ [case1_mean,case1_median,case1_variance], [case2_mean,case2_median,case2_variance], [case3_mean,case3_median,case3_variance] ]\"\nwith all entries being floats.\n\nTest Suite:\n\nAll test cases use a grid of size $N_x = N_y = 64$ with grid spacing $\\Delta x = 2$ kilometers. The observation and ensemble members are disks (filled circles) defined by a center $(c_x,c_y)$ in grid indices and a radius $R$ in grid cells. A disk of radius $R$ cells means all grid points $(i,j)$ satisfying $(i - c_x)^2 + (j - c_y)^2 \\le R^2$ are assigned the value $1$, otherwise $0$.\n\n- Test Case 1 (general case with varying member errors):\n  - Observation: center $(32,32)$, radius $R_O = 8$.\n  - Ensemble members (each specified as $(c_x,c_y,R)$):\n    $$\n    \\{(27,28,8), (29,34,9), (34,31,7), (36,35,9), (30,37,8), (38,26,10), (32,32,8), (33,33,8), (31,30,8), (35,28,7), (26,37,11), (37,38,10)\\}.\n    $$\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 6, 10, 14, 18, 22, 26]$.\n  - Critical threshold: $q = 0.5$.\n\n- Test Case 2 (perfect forecasts):\n  - Observation: center $(30,30)$, radius $R_O = 6$.\n  - Ensemble members: six identical copies of the observation $(30,30,6)$.\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 4, 6, 8, 10]$.\n  - Critical threshold: $q = 0.7$.\n\n- Test Case 3 (poor forecasts far from the observation):\n  - Observation: center $(28,35)$, radius $R_O = 10$.\n  - Ensemble members:\n    $$\n    \\{(5,5,4), (55,55,4), (5,55,4), (55,5,4), (10,50,3), (50,10,3), (20,20,3), (44,44,3)\\}.\n    $$\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 10, 18, 26, 34]$.\n  - Critical threshold: $q = 0.5$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[result1_case1,result2_case1,result3_case1],[result1_case2,result2_case2,result3_case2],[result1_case3,result2_case3,result3_case3]]\"), where each \"result\" is a float as defined above, in kilometers for the first two entries and in square kilometers for the third entry in each case.",
            "solution": "The problem statement is formally validated as scientifically grounded, well-posed, and objective. It presents a clear, self-contained task based on established principles in meteorological forecast verification, specifically the Fractions Skill Score (FSS) and neighborhood methods for ensemble forecasts. All definitions, formulas, and data are provided explicitly and are consistent, allowing for a unique and meaningful solution.\n\nThe methodology for solving this problem proceeds in a sequence of well-defined steps, adhering strictly to the provided definitions.\n\nFirst, for each test case, we must construct the binary grid fields for the observation and for each ensemble member. The grid has dimensions $N_x = 64, N_y = 64$, with a grid spacing of $\\Delta x = 2$ km. An event, represented as a filled circle (disk), is defined by its center $(c_x, c_y)$ and radius $R$. A grid cell at integer coordinates $(j, i)$ (column, row) is assigned a value of $1$ if the condition $(j-c_x)^2 + (i-c_y)^2 \\le R^2$ is met, and $0$ otherwise. We interpret the given center coordinates $(c_x, c_y)$ as $0$-indexed grid coordinates corresponding to (column, row).\n\nSecond, we compute the Fractions Skill Score, $\\mathrm{FSS}(s)$, for a set of specified neighborhood scales $\\mathcal{S}$. This requires several sub-steps for each scale $s \\in \\mathcal{S}$:\n\n1.  Determine the neighborhood window width, $w(s)$, defined as the odd integer closest to the ratio $s/\\Delta x$. In cases where $s/\\Delta x$ is equidistant from two odd integers (e.g., if $s/\\Delta x$ is an even integer), we adopt the convention of choosing the larger odd integer.\n2.  Generate the neighborhood fraction fields. For an observation field $O$ and a forecast field $F$ (which can be a single ensemble member $F^{(m)}$ or the ensemble mean $E$), we compute the fraction fields $o_s$ and $f_s$ (or $e_s$ for the ensemble mean). This is accomplished via a two-dimensional discrete convolution with a square kernel $K_s$ of size $w(s) \\times w(s)$ consisting entirely of ones. The convolution must use reflective boundary conditions. The resulting field is normalized by dividing by the area of the kernel, $w(s)^2$.\n    $$\n    o_s = \\frac{1}{w(s)^2} (K_s * O), \\quad f_s = \\frac{1}{w(s)^2} (K_s * F^{(m)}), \\quad e_s = \\frac{1}{w(s)^2} (K_s * E)\n    $$\n3.  Calculate the $\\mathrm{FSS}(s)$ using the provided formula:\n    $$\n    \\mathrm{FSS}(s) = 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)} = 1 - \\frac{\\sum_{j=1}^{N_x} \\sum_{i=1}^{N_y} ( f_s(j,i) - o_s(j,i) )^2}{\\sum_{j=1}^{N_x} \\sum_{i=1}^{N_y} ( f_s(j,i)^2 + o_s(j,i)^2 )}\n    $$\n    If the denominator $\\mathrm{MSE}_{\\mathrm{ref}}(s)$ is zero, which occurs only if both fields $F$ and $O$ are identically zero, we set $\\mathrm{FSS}(s) = 1$.\n\nThird, we determine the \"useful scale,\" $s^\\ast$, for each forecast. Given a critical skill threshold $q$, the useful scale is defined as the smallest scale $s \\in \\mathcal{S}$ for which the score meets or exceeds the threshold:\n$$\ns^\\ast = \\min \\{ s \\in \\mathcal{S} : \\mathrm{FSS}(s) \\ge q \\}\n$$\nIf no scale in $\\mathcal{S}$ achieves the threshold $q$, the useful scale is set to the maximum tested scale, $\\max(\\mathcal{S})$. This procedure is applied to each of the $M$ ensemble members to obtain a set of useful scales $\\{s^\\ast_m\\}_{m=1}^M$, and to the ensemble mean forecast $E$ to obtain its useful scale $s^\\ast_{\\text{mean}}$.\n\nFinally, we compute the required output statistics for each test case:\n1.  The useful scale for the ensemble mean, $s^\\ast_{\\text{mean}}$.\n2.  The median of the useful scales across the individual ensemble members, $\\mathrm{median}(\\{s^\\ast_m\\})$.\n3.  The variance of the useful scales across the individual ensemble members, $\\mathrm{var}(\\{s^\\ast_m\\})$.\n\nThe entire process is implemented in a program using the `NumPy` library for efficient array manipulations and the `SciPy` library for the convolution operation, following the specified execution environment.",
            "answer": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (32, 32), \"radius\": 8},\n            \"ensemble_params\": [\n                {\"center\": (27, 28), \"radius\": 8}, {\"center\": (29, 34), \"radius\": 9},\n                {\"center\": (34, 31), \"radius\": 7}, {\"center\": (36, 35), \"radius\": 9},\n                {\"center\": (30, 37), \"radius\": 8}, {\"center\": (38, 26), \"radius\": 10},\n                {\"center\": (32, 32), \"radius\": 8}, {\"center\": (33, 33), \"radius\": 8},\n                {\"center\": (31, 30), \"radius\": 8}, {\"center\": (35, 28), \"radius\": 7},\n                {\"center\": (26, 37), \"radius\": 11}, {\"center\": (37, 38), \"radius\": 10},\n            ],\n            \"scales_km\": np.array([2.0, 6.0, 10.0, 14.0, 18.0, 22.0, 26.0]),\n            \"q\": 0.5,\n        },\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (30, 30), \"radius\": 6},\n            \"ensemble_params\": [\n                {\"center\": (30, 30), \"radius\": 6} for _ in range(6)\n            ],\n            \"scales_km\": np.array([2.0, 4.0, 6.0, 8.0, 10.0]),\n            \"q\": 0.7,\n        },\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (28, 35), \"radius\": 10},\n            \"ensemble_params\": [\n                {\"center\": (5, 5), \"radius\": 4}, {\"center\": (55, 55), \"radius\": 4},\n                {\"center\": (5, 55), \"radius\": 4}, {\"center\": (55, 5), \"radius\": 4},\n                {\"center\": (10, 50), \"radius\": 3}, {\"center\": (50, 10), \"radius\": 3},\n                {\"center\": (20, 20), \"radius\": 3}, {\"center\": (44, 44), \"radius\": 3},\n            ],\n            \"scales_km\": np.array([2.0, 10.0, 18.0, 26.0, 34.0]),\n            \"q\": 0.5,\n        }\n    ]\n    \n    all_results = []\n    \n    for case in test_cases:\n        all_results.append(solve_case(case))\n        \n    # Format the final output string exactly as required\n    inner_parts = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output = f\"[{','.join(inner_parts)}]\"\n    print(final_output)\n\ndef create_disk_field(grid_size, center, radius):\n    \"\"\"\n    Creates a binary grid with a filled circle (disk).\n    \n    Args:\n        grid_size (tuple): (Ny, Nx) dimensions of the grid.\n        center (tuple): (cx, cy) 0-indexed center coordinates (column, row).\n        radius (int): Radius of the disk in grid cells.\n        \n    Returns:\n        np.ndarray: A 2D binary grid.\n    \"\"\"\n    ny, nx = grid_size\n    cx, cy = center\n    radius_sq = radius**2\n    \n    y_indices, x_indices = np.ogrid[:ny, :nx]\n    \n    dist_sq = (x_indices - cx)**2 + (y_indices - cy)**2\n    \n    return (dist_sq <= radius_sq).astype(float)\n\ndef get_window_width(s, dx):\n    \"\"\"\n    Calculates the odd integer window width closest to s/dx.\n    Tie-breaking rule: choose the larger odd integer.\n    \"\"\"\n    val = s / dx\n    w = int(round(val))\n    if w <= 0:\n        return 1\n    if w % 2 == 0:\n        if val < w:\n            w = w - 1\n        else:\n            w = w + 1\n    return w\n\ndef calculate_fss_over_scales(forecast_field, obs_field, scales_km, dx):\n    \"\"\"\n    Computes the Fraction Skill Score (FSS) over a range of scales.\n    \n    Args:\n        forecast_field, obs_field (np.ndarray): The 2D fields.\n        scales_km (np.ndarray): Array of scales in kilometers.\n        dx (float): Grid spacing in kilometers.\n        \n    Returns:\n        np.ndarray: Array of FSS values for each scale.\n    \"\"\"\n    fss_values = []\n    for s in scales_km:\n        w = get_window_width(s, dx)\n        kernel = np.ones((w, w))\n        \n        o_s = convolve(obs_field, kernel, mode='reflect') / (w**2)\n        f_s = convolve(forecast_field, kernel, mode='reflect') / (w**2)\n        \n        mse = np.sum((f_s - o_s)**2)\n        mse_ref = np.sum(f_s**2 + o_s**2)\n        \n        if mse_ref == 0:\n            fss = 1.0\n        else:\n            fss = 1.0 - (mse / mse_ref)\n        fss_values.append(fss)\n        \n    return np.array(fss_values)\n\ndef find_useful_scale(fss_values, scales_km, q):\n    \"\"\"\n    Determines the useful scale from a set of FSS values.\n    \"\"\"\n    above_threshold = np.where(fss_values >= q)[0]\n    \n    if len(above_threshold) > 0:\n        return scales_km[above_threshold[0]]\n    else:\n        return np.max(scales_km)\n\ndef solve_case(case_params):\n    \"\"\"\n    Solves a single test case.\n    \"\"\"\n    grid_size = case_params[\"grid_size\"]\n    dx_km = case_params[\"dx_km\"]\n    obs_params = case_params[\"obs_params\"]\n    ensemble_params = case_params[\"ensemble_params\"]\n    scales_km = case_params[\"scales_km\"]\n    q = case_params[\"q\"]\n\n    # Create observation field\n    obs_field = create_disk_field(grid_size, obs_params[\"center\"], obs_params[\"radius\"])\n\n    # Process each ensemble member\n    ensemble_fields = []\n    member_useful_scales = []\n    for params in ensemble_params:\n        member_field = create_disk_field(grid_size, params[\"center\"], params[\"radius\"])\n        ensemble_fields.append(member_field)\n        \n        fss_values = calculate_fss_over_scales(member_field, obs_field, scales_km, dx_km)\n        s_star = find_useful_scale(fss_values, scales_km, q)\n        member_useful_scales.append(s_star)\n\n    member_useful_scales = np.array(member_useful_scales)\n\n    # Calculate statistics for members\n    median_s_star = np.median(member_useful_scales)\n    variance_s_star = np.var(member_useful_scales)\n    \n    # Process ensemble mean\n    ensemble_mean_field = np.mean(ensemble_fields, axis=0)\n    mean_fss_values = calculate_fss_over_scales(ensemble_mean_field, obs_field, scales_km, dx_km)\n    mean_s_star = find_useful_scale(mean_fss_values, scales_km, q)\n    \n    return [mean_s_star, median_s_star, variance_s_star]\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}