{
    "hands_on_practices": [
        {
            "introduction": "第一个练习将为最优插值奠定数学基础。通过从第一性原理出发推导分析误差协方差和最优增益矩阵，你将证明为何该方法被视为“最佳线性无偏估计”（Best Linear Unbiased Estimator, BLUE）。这项实践对于理解数据同化如何量化地减少我们对状态估计的不确定性至关重要。",
            "id": "4070587",
            "problem": "考虑在线性、无偏的数据同化设置下的最优插值（OI），该方法寻求最佳线性无偏估计（BLUE）。设真实状态为 $x \\in \\mathbb{R}^{n}$，背景（先验）为 $x_{b} = x + e_{b}$，其中背景误差 $e_{b}$ 满足 $\\mathbb{E}[e_{b}] = 0$ 和 $\\operatorname{Cov}(e_{b}) = B \\in \\mathbb{R}^{n \\times n}$。观测为 $y = H x + \\epsilon$，其中 $H \\in \\mathbb{R}^{m \\times n}$ 是线性观测算子，观测误差 $\\epsilon$ 满足 $\\mathbb{E}[\\epsilon] = 0$ 和 $\\operatorname{Cov}(\\epsilon) = R \\in \\mathbb{R}^{m \\times m}$，且背景误差和观测误差不相关，即 $\\operatorname{Cov}(e_{b}, \\epsilon) = 0$。OI 分析由线性估计量 $x_{a} = x_{b} + K \\left(y - H x_{b}\\right)$ 定义，其中 $K \\in \\mathbb{R}^{n \\times m}$ 是一个待定增益，通过在无偏性约束下最小化分析误差方差来确定。\n\n仅从这些原则出发，完成以下任务：\n\n- 推导分析误差协方差矩阵 $A = \\operatorname{Cov}(x - x_{a})$（用 $K$、$H$、$B$ 和 $R$ 表示），并确定唯一的 $K$，该 $K$ 通过最小化 $\\operatorname{tr}(A)$ 来最小化总分析方差。\n- 使用您推导出的最优 $K$，将 $A$ 表示为 $B$ 与一个依赖于 $H$、$B$ 和 $R$ 的半正定矩阵之差，从而证明 $A$ 的每个对角元素都小于或等于 $B$ 的相应对角元素；即，$A$ 的对角线元素给出了相对于 $B$ 的分析方差的减小。\n- 对于标量情况，即 $x \\in \\mathbb{R}$、$H \\in \\mathbb{R}$、$B \\in \\mathbb{R}$ 和 $R \\in \\mathbb{R}$，且 $H \\neq 0$、$B > 0$、$R > 0$，计算方差减小因子 $\\gamma = A / B$，并给出其关于 $H$、$B$ 和 $R$ 的闭式表达式。\n\n提供 $\\gamma$ 的单一解析表达式作为最终答案。不需要进行数值舍入。",
            "solution": "所述问题是数据同化领域的一个标准推导，特别涉及最优插值（OI）或最佳线性无偏估计（BLUE）。给定的条件定义清晰，科学上一致，目标是良定的数学任务。所有提供的术语和假设在数值天气预报和气候模拟的文献中都是标准的。因此，该问题是有效的。\n\n我们首先将分析误差 $e_a$ 定义为分析状态 $x_a$ 与真实状态 $x$ 之间的差：\n$$e_a = x_a - x$$\n分析状态 $x_a$ 由以下线性估计量给出：\n$$x_a = x_b + K(y - Hx_b)$$\n其中 $K$ 是增益矩阵，$x_b$ 是背景状态，$y$ 是观测向量，$H$ 是观测算子。我们还已知背景和观测与真实状态 $x$ 及其各自误差 $e_b$ 和 $\\epsilon$ 的关系：\n$$x_b = x + e_b$$\n$$y = Hx + \\epsilon$$\n误差是无偏的，即 $\\mathbb{E}[e_b] = 0$ 和 $\\mathbb{E}[\\epsilon] = 0$，并且是不相关的，即 $\\operatorname{Cov}(e_b, \\epsilon) = \\mathbb{E}[e_b \\epsilon^T] = 0$。\n\n首先，我们用背景误差 $e_b$ 和观测误差 $\\epsilon$ 来表示分析误差 $e_a$：\n$$e_a = (x_b + K(y - Hx_b)) - x$$\n代入 $x_b$ 和 $y$ 的表达式：\n$$e_a = (x + e_b) + K((Hx + \\epsilon) - H(x + e_b)) - x$$\n$$e_a = e_b + K(Hx + \\epsilon - Hx - He_b)$$\n$$e_a = e_b + K(\\epsilon - He_b)$$\n$$e_a = (I - KH)e_b + K\\epsilon$$\n其中 $I$ 是大小为 $n \\times n$ 的单位矩阵。\n\n分析误差协方差矩阵 $A$ 定义为 $A = \\operatorname{Cov}(e_a) = \\mathbb{E}[e_a e_a^T]$。使用 $e_a$ 的表达式，我们得到：\n$$A = \\mathbb{E}[((I - KH)e_b + K\\epsilon)((I - KH)e_b + K\\epsilon)^T]$$\n$$A = \\mathbb{E}[((I - KH)e_b + K\\epsilon)(e_b^T(I - KH)^T + \\epsilon^T K^T)]$$\n展开此表达式得到四项：\n$$A = \\mathbb{E}[(I - KH)e_b e_b^T (I - KH)^T] + \\mathbb{E}[(I - KH)e_b \\epsilon^T K^T] + \\mathbb{E}[K\\epsilon e_b^T (I - KH)^T] + \\mathbb{E}[K\\epsilon \\epsilon^T K^T]$$\n利用期望的线性性质和给定的协方差信息（$\\operatorname{Cov}(e_b) = \\mathbb{E}[e_b e_b^T] = B$，$\\operatorname{Cov}(\\epsilon) = \\mathbb{E}[\\epsilon \\epsilon^T] = R$ 和 $\\mathbb{E}[e_b \\epsilon^T] = 0$），交叉项为零：\n$$\\mathbb{E}[(I - KH)e_b \\epsilon^T K^T] = (I - KH)\\mathbb{E}[e_b \\epsilon^T]K^T = 0$$\n$$\\mathbb{E}[K\\epsilon e_b^T (I - KH)^T] = K\\mathbb{E}[\\epsilon e_b^T](I - KH)^T = 0$$\n$A$ 的表达式简化为：\n$$A(K) = (I - KH) \\mathbb{E}[e_b e_b^T] (I - KH)^T + K \\mathbb{E}[\\epsilon \\epsilon^T] K^T$$\n$$A(K) = (I - KH)B(I - KH)^T + KRK^T$$\n这就是用 $K$、$H$、$B$ 和 $R$ 表示的分析误差协方差矩阵。\n\n为了找到最小化总分析方差的最优增益 $K$，我们最小化 $A$ 的迹，记为 $J(K) = \\operatorname{tr}(A(K))$。首先，我们展开 $A(K)$ 的表达式：\n$$A(K) = (B - KHB)(I - H^T K^T) + KRK^T$$\n$$A(K) = B - KHB - BH^T K^T + KHBH^T K^T + KRK^T$$\n$$A(K) = B - KHB - BH^T K^T + K(HBH^T + R)K^T$$\n成本函数为：\n$$J(K) = \\operatorname{tr}(B) - \\operatorname{tr}(KHB) - \\operatorname{tr}(BH^T K^T) + \\operatorname{tr}(K(HBH^T + R)K^T)$$\n利用迹的循环性质，$\\operatorname{tr}(BH^T K^T) = \\operatorname{tr}(K^T BH^T) = \\operatorname{tr}((KHB)^T) = \\operatorname{tr}(KHB)$。因此：\n$$J(K) = \\operatorname{tr}(B) - 2\\operatorname{tr}(KHB) + \\operatorname{tr}(K(HBH^T + R)K^T)$$\n为了找到最小值，我们计算 $J(K)$ 关于 $K$ 的梯度并将其设为零。使用标准的矩阵微积分恒等式（对于对称矩阵 $A$，有 $\\nabla_X \\operatorname{tr}(AXB) = A^T B^T$ 和 $\\nabla_X \\operatorname{tr}(AXA^T) = 2AX$），我们得到：\n$$\\nabla_K J(K) = -2 (HB)^T + 2K(HBH^T + R)$$\n因为 $B$ 是一个协方差矩阵，所以它是对称的（$B=B^T$）。同样，$HBH^T+R$ 也是对称的。\n$$\\nabla_K J(K) = -2BH^T + 2K(HBH^T + R)$$\n为达到最优，将梯度设为零：\n$$-2BH^T + 2K(HBH^T + R) = 0$$\n$$K(HBH^T + R) = BH^T$$\n因此，最优增益矩阵 $K$ 是：\n$$K = BH^T (HBH^T + R)^{-1}$$\n\n接下来，我们表示这个最优 $K$ 对应的分析误差协方差 $A$。可以证明，对于最优 $K$，$A$ 的表达式可以简化。我们从 $A = B - KHB - BH^T K^T + K(HBH^T + R)K^T$ 开始。代入 $K(HBH^T + R) = BH^T$：\n$$A = B - KHB - BH^T K^T + (BH^T)K^T$$\n$$A = B - KHB$$\n现在，代入最优 $K$ 的表达式：\n$$A = B - (BH^T (HBH^T + R)^{-1}) H B$$\n设矩阵 $M = BH^T (HBH^T + R)^{-1} H B$。那么 $A = B - M$。为了证明 $M$ 是半正定的，我们考虑对于任意向量 $z \\in \\mathbb{R}^n$ 的 $z^T M z$：\n$$z^T M z = z^T B H^T (HBH^T + R)^{-1} H B z$$\n由于 $B$ 是对称的，我们可以将其写为 $(HBz)^T (HBH^T + R)^{-1} (HBz)$。令 $w = HBz \\in \\mathbb{R}^m$。表达式变为 $w^T (HBH^T + R)^{-1} w$。矩阵 $B$ 是半正定的。矩阵 $HBH^T$ 也是半正定的，因为对于任意向量 $u \\in \\mathbb{R}^m$，有 $u^T(HBH^T)u = (H^Tu)^T B (H^Tu) \\ge 0$。观测误差协方差 $R$ 假定为正定的（因为它必须是可逆的）。一个半正定矩阵和一个正定矩阵的和是正定的。因此，$HBH^T + R$ 是正定的，其逆矩阵也是正定的。所以，对于任意 $w \\neq 0$，有 $w^T (HBH^T + R)^{-1} w > 0$，而当 $w=0$ 时，其值为 $0$。这意味着对于所有 $z$，都有 $z^T M z \\ge 0$，所以 $M$ 是半正定的。\n\n$A$ 和 $B$ 的对角元素 $A_{ii}$ 和 $B_{ii}$ 分别表示状态向量第 $i$ 个分量的分析方差和背景方差。我们有 $A = B - M$，所以按分量来看，$A_{ii} = B_{ii} - M_{ii}$。半正定矩阵的对角元素是非负的，所以 $M_{ii} \\ge 0$。这意味着：\n$$A_{ii} \\le B_{ii}$$\n这证明了每个状态变量的分析方差都小于或等于背景方差，这就是所期望的方差减小。\n\n最后，我们考虑标量情况，其中 $x, H, B, R$ 都是标量，且 $H \\neq 0$, $B > 0$, $R > 0$。矩阵方程变为标量方程。最优增益 $K$ 为：\n$$K = B H (H B H + R)^{-1} = \\frac{BH}{H^2 B + R}$$\n分析误差方差 $A$ 由 $A = (1 - KH)B$ 给出：\n$$A = \\left(1 - \\left(\\frac{BH}{H^2 B + R}\\right) H\\right) B$$\n$$A = \\left(1 - \\frac{H^2 B}{H^2 B + R}\\right) B$$\n$$A = \\left(\\frac{H^2 B + R - H^2 B}{H^2 B + R}\\right) B$$\n$$A = \\frac{R}{H^2 B + R} B = \\frac{BR}{H^2 B + R}$$\n方差减小因子 $\\gamma$ 定义为比率 $A / B$：\n$$\\gamma = \\frac{A}{B} = \\frac{1}{B} \\left(\\frac{BR}{H^2 B + R}\\right)$$\n$$\\gamma = \\frac{R}{H^2 B + R}$$\n这就是在标量情况下方差减小因子的闭式表达式。",
            "answer": "$$\\boxed{\\frac{R}{H^{2} B + R}}$$"
        },
        {
            "introduction": "从抽象理论转向空间应用，本练习将探讨单个观测的“影响足迹”。你将推导并实现空间影响函数，它展示了来自一个数据点的信息如何传播到周围的格点。这项实践为背景误差相关结构如何塑造分析增量提供了切实的视觉化呈现。",
            "id": "4070623",
            "problem": "给定一个嵌入在数值天气预报和气候模拟所用背景场中的地球物理场的单点标量观测。任务是针对均匀且各向同性的高斯背景误差协方差，推导并实现使用最优插值 (OI) 进行客观分析的空间影响函数。场景如下。\n\n假设一个定义在二维水平域上的标量场 $x(\\mathbf{r})$，其背景估计为 $x^{b}(\\mathbf{r})$，背景误差为 $e^{b}(\\mathbf{r}) = x(\\mathbf{r}) - x^{b}(\\mathbf{r})$。假设 $e^{b}(\\mathbf{r})$ 是一个零均值、二阶平稳随机场，其特征是方差 $\\sigma_{b}^{2}$ 和一个仅依赖于径向距离 $r = \\|\\mathbf{r} - \\mathbf{r}'\\|$ 的相关函数 $C(r; L)$。设相关是高斯型的，相关长度尺度为 $L$，即 $C(r; L)$ 随 $r$ 单调递减，并编码了空间均匀性和各向同性。在位置 $\\mathbf{r}_{o}$ 有一个单点观测 $y$，其观测算子 $H$ 提取 $\\mathbf{r}_{o}$ 处的真实场值，并伴随一个独立的观测误差 $\\epsilon$，该误差是高斯的、零均值的，且方差为 $R$，因此 $y = H x + \\epsilon$。所有变量 $x$、$x^{b}$、$y$、$e^{b}$ 和 $\\epsilon$ 都假定为联合高斯分布。该域仅为水平域；不考虑垂直结构。\n\n从高斯假设下的最佳线性无偏估计 (BLUE) 和最优插值的定义出发，推导位于原点的单个观测的空间影响函数 $\\phi(r)$。该函数定义为乘以标量新息 $d = y - H x^{b}$ 以产生距离观测点径向距离为 $r$ 的格点上的分析增量的无量纲权重。用背景误差方差 $\\sigma_{b}^{2}$、观测误差方差 $R$、相关函数 $C(r; L)$ 和相关长度 $L$ 来表示 $\\phi(r)$。然后，实现一个程序，对一组给定的半径数值计算 $\\phi(r)$。\n\n假设高斯相关函数为 $C(r; L) = \\exp\\left(-\\frac{r^2}{2L^2}\\right)$。设背景误差方差 $\\sigma_{b}^{2}$ 和观测误差方差 $R$ 为常数标量。距离必须以公里 (km) 为单位处理和报告。影响函数 $\\phi(r)$ 是一个无量纲数。此外，推导由条件 $\\phi(r_{e}) = \\phi(0)/e$ 定义的影响函数的 e-折叠半径 $r_{e}$，并为每个测试用例计算 $r_{e}$。以公里 (km) 为单位表示 $r_{e}$。\n\n您的程序必须为每个测试用例计算在五个半径 $r \\in \\{0, L, 2L, 4L, 10L\\}$（均以公里为单位）处的影响函数 $\\phi(r)$ 的值，然后计算 e-折叠半径 $r_{e}$（以公里为单位）。程序必须将所有测试用例的结果汇总到单行输出中，格式为用方括号括起来的逗号分隔列表，其中每个测试用例的结果本身是按 $[\\phi(0), \\phi(L), \\phi(2L), \\phi(4L), \\phi(10L), r_{e}]$ 顺序排列的六个浮点数的列表。\n\n使用以下测试套件，它探讨了不同的参数范围：\n\n- 测试用例 1（通用正常情况）：$\\sigma_{b}^{2} = 4.0$, $L = 100.0$ km, $R = 1.0$。\n- 测试用例 2（大观测误差方差）：$\\sigma_{b}^{2} = 4.0$, $L = 100.0$ km, $R = 100.0$。\n- 测试用例 3（短相关长度）：$\\sigma_{b}^{2} = 4.0$, $L = 20.0$ km, $R = 1.0$。\n- 测试用例 4（零观测误差方差边界情况）：$\\sigma_{b}^{2} = 4.0$, $L = 50.0$ km, $R = 0.0$。\n\n对于所有半径，距离必须以公里 (km) 为单位。输出的影响值 $\\phi(r)$ 必须是无量纲浮点数。e-折叠半径 $r_{e}$ 必须以公里 (km) 为单位报告。您的程序应生成单行输出，其中包含结果，格式为用方括号括起来的逗号分隔列表，每个测试用例的结果为按指定顺序排列的六个浮点数的列表。",
            "solution": "该问题要求在单标量观测的背景下，推导并实现最优插值 (OI) 的空间影响函数。推导从最佳线性无偏估计 (BLUE) 的基本方程开始，该方程将分析场态 $x^a$ 定义为对背景场态（或初估场态）$x^b$ 的更新。\n\n域中特定位置 $\\mathbf{r}$ 的分析更新由下式给出：\n$$\nx^a(\\mathbf{r}) = x^b(\\mathbf{r}) + \\delta x^a(\\mathbf{r})\n$$\n其中 $\\delta x^a(\\mathbf{r})$ 是分析增量。OI 的核心是将此增量计算为新息（观测值减去其背景对应值）的线性组合。对于位置 $\\mathbf{r}_o$ 处的单个观测 $y$，新息为 $d = y - \\mathbf{H} x^b$。算子 $\\mathbf{H}$ 将状态场映射到观测空间。在此问题中，$\\mathbf{H}$ 仅提取 $\\mathbf{r}_o$ 处的场值，因此 $\\mathbf{H} x^b = x^b(\\mathbf{r}_o)$。那么，点 $\\mathbf{r}$ 处的分析增量为：\n$$\n\\delta x^a(\\mathbf{r}) = K(\\mathbf{r}) (y - x^b(\\mathbf{r}_o))\n$$\n项 $K(\\mathbf{r})$ 是使分析误差方差最小化的最优权重或增益。在多变量情况下，增益矩阵 $\\mathbf{K}$ 的通用公式为：\n$$\n\\mathbf{K} = \\mathbf{B} \\mathbf{H}^T (\\mathbf{H} \\mathbf{B} \\mathbf{H}^T + \\mathbf{R})^{-1}\n$$\n此处，$\\mathbf{B}$ 是背景误差协方差矩阵，$\\mathbf{R}$ 是观测误差协方差矩阵。我们必须将此矩阵方程应用于我们这个连续场和单标量观测的特定情况。\n\n1.  项 $\\mathbf{B} \\mathbf{H}^T$ 表示分析格点上的背景误差 $e^b$ 与观测位置上的背景误差之间的协方差。对于单个分析点 $\\mathbf{r}$ 和单个观测点 $\\mathbf{r}_o$，此项变为标量协方差 $\\mathbb{E}[e^b(\\mathbf{r}) e^b(\\mathbf{r}_o)]$。问题陈述背景误差的特征是方差 $\\sigma_b^2$ 和相关函数 $C(r; L)$，其中 $r = \\|\\mathbf{r} - \\mathbf{r}_o\\|$。根据定义，协方差是方差乘以相关，所以：\n    $$\n    \\mathbb{E}[e^b(\\mathbf{r}) e^b(\\mathbf{r}_o)] = \\sigma_b^2 C(r; L)\n    $$\n\n2.  项 $\\mathbf{H} \\mathbf{B} \\mathbf{H}^T$ 表示观测空间中的背景误差方差。对于 $\\mathbf{r}_o$ 处的单个观测，这是该特定点的背景误差方差：$\\mathbb{E}[e^b(\\mathbf{r}_o) e^b(\\mathbf{r}_o)]$。这只是背景误差方差 $\\sigma_b^2$，因为一个点与自身的相关 $C(0; L)$ 为 1。\n    $$\n    \\mathbf{H} \\mathbf{B} \\mathbf{H}^T = \\sigma_b^2\n    $$\n\n3.  项 $\\mathbf{R}$ 是观测误差协方差矩阵。对于单个独立观测，这仅是标量观测误差方差 $R$。\n\n将这些分量代回增益公式，我们得到分析点 $\\mathbf{r}$ 的标量权重 $K(\\mathbf{r})$：\n$$\nK(\\mathbf{r}) = \\left(\\sigma_b^2 C(r; L)\\right) \\left(\\sigma_b^2 + R\\right)^{-1}\n$$\n问题将空间影响函数 $\\phi(r)$ 定义为乘以新息的无量纲权重。这恰好是我们推导出的增益 $K(\\mathbf{r})$。因此：\n$$\n\\phi(r) = \\frac{\\sigma_b^2 C(r; L)}{\\sigma_b^2 + R}\n$$\n问题指定了高斯相关函数：\n$$\nC(r; L) = \\exp\\left( -\\frac{r^2}{2 L^2} \\right)\n$$\n将此代入 $\\phi(r)$ 的表达式，我们得到影响函数的最终形式：\n$$\n\\phi(r) = \\frac{\\sigma_b^2}{\\sigma_b^2 + R} \\exp\\left(-\\frac{r^2}{2 L^2}\\right)\n$$\n此函数描述了单个观测新息的影响如何从其位置开始在空间上衰减。影响的幅度由背景误差方差与观测空间中总误差方差（背景加观测）之比来缩放，反映了对背景与观测的相对置信度。影响的空间结构完全由背景误差相关函数决定。\n\n接下来，我们推导 e-折叠半径 $r_e$，它由条件 $\\phi(r_e) = \\phi(0)/e$ 定义。首先，我们计算 $r=0$ 时的 $\\phi(r)$：\n$$\n\\phi(0) = \\frac{\\sigma_b^2}{\\sigma_b^2 + R} \\exp(0) = \\frac{\\sigma_b^2}{\\sigma_b^2 + R}\n$$\n现在我们建立 $r_e$ 的方程：\n$$\n\\phi(r_e) = \\frac{1}{e} \\phi(0)\n$$\n$$\n\\frac{\\sigma_b^2}{\\sigma_b^2 + R} \\exp\\left(-\\frac{r_e^2}{2 L^2}\\right) = \\frac{1}{e} \\left( \\frac{\\sigma_b^2}{\\sigma_b^2 + R} \\right)\n$$\n假设 $\\sigma_b^2 > 0$，我们可以消去两边的前置因子 $\\frac{\\sigma_b^2}{\\sigma_b^2 + R}$。使用恒等式 $1/e = e^{-1}$：\n$$\n\\exp\\left(-\\frac{r_e^2}{2 L^2}\\right) = e^{-1}\n$$\n对两边取自然对数得到：\n$$\n-\\frac{r_e^2}{2 L^2} = -1\n$$\n$$\nr_e^2 = 2 L^2\n$$\n解出 $r_e$（必须为非负值）：\n$$\nr_e = \\sqrt{2} L\n$$\n这个结果表明，影响函数的 e-折叠半径与背景误差协方差函数的相关长度尺度 $L$ 成正比，比例常数为 $\\sqrt{2}$。它与误差方差 $\\sigma_b^2$ 和 $R$ 无关。\n\n有了这两个推导出的公式，我们就可以进行数值实现了。\n- 影响函数： $\\phi(r) = \\frac{\\sigma_b^2}{\\sigma_b^2 + R} \\exp\\left(-\\frac{r^2}{2 L^2}\\right)$\n- e-折叠半径： $r_e = \\sqrt{2} L$\n对于 $R=0$ 且 $\\sigma_b^2 > 0$ 的特殊情况，前置因子变为 $\\frac{\\sigma_b^2}{\\sigma_b^2} = 1$，且 $\\phi(r) = C(r; L)$。这代表了完美观测的情况，此时观测位置的分析值与观测值完全匹配。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements the spatial influence function for Objective Analysis\n    using Optimal Interpolation (OI) for a single observation.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (sigma_b^2, L, R)\n    test_cases = [\n        # Test Case 1: general happy path\n        (4.0, 100.0, 1.0),\n        # Test Case 2: large observation-error variance\n        (4.0, 100.0, 100.0),\n        # Test Case 3: short correlation length\n        (4.0, 20.0, 1.0),\n        # Test Case 4: zero observation-error variance boundary\n        (4.0, 50.0, 0.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        sigma_b_sq, L, R = case\n        \n        case_results = []\n\n        # Define the influence function phi(r) based on the derived formula\n        def influence_function(r, sigma_b_sq, L, R):\n            \"\"\"\n            Computes the spatial influence function phi(r).\n            phi(r) = (sigma_b^2 / (sigma_b^2 + R)) * exp(-r^2 / (2 * L^2))\n            \"\"\"\n            # Handle the case R=0 where sigma_b_sq > 0. The pre-factor is 1.\n            # Avoids potential issues with large numbers but is robust either way.\n            if sigma_b_sq + R == 0:\n                # This case (sigma_b_sq=0 and R=0) is not in the test suite\n                # but represents no information from background or observation.\n                # Influence would be ill-defined or zero.\n                return 0.0\n            \n            prefactor = sigma_b_sq / (sigma_b_sq + R)\n            exponent = - (r**2) / (2 * L**2)\n            return prefactor * np.exp(exponent)\n\n        # Radii at which to compute the influence function\n        radii = [0 * L, 1 * L, 2 * L, 4 * L, 10 * L]\n        \n        # Calculate phi(r) for each radius\n        for r in radii:\n            phi_val = influence_function(r, sigma_b_sq, L, R)\n            case_results.append(phi_val)\n        \n        # Calculate the e-folding radius r_e based on the derived formula\n        # r_e = sqrt(2) * L\n        r_e = np.sqrt(2) * L\n        case_results.append(r_e)\n\n        all_results.append(case_results)\n\n    # Format the final output as a string representation of a list of lists.\n    # e.g., [[val1, val2, ...], [val7, val8, ...]]\n    # Python's default list-to-string conversion adds spaces, which is fine.\n    # The prompt's example f\"[{','.join(map(str, results))}]\" correctly constructs\n    # the string representation of a list of lists.\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n\n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界的数据同化常常受到对误差统计特性认知不完善的阻碍。最后一个练习将研究错误设定背景和观测误差方差所带来的后果。通过将由此产生的分析误差与真实的最优误差进行比较，你将量化性能下降的程度，并体会到在任何同化系统中准确表征误差的至关重要性。",
            "id": "4070701",
            "problem": "在数值天气预报和气候模拟的背景下，考虑标量最优插值 (OI)，其中有一个单一状态变量 $x$、一个背景场（初猜）$x_b$ 和一个测量相同状态分量的单一观测 $y$。假设线性观测模型为 $y = x + \\varepsilon_o$，背景场模型为 $x_b = x + \\varepsilon_b$。背景误差 $\\varepsilon_b$ 和观测误差 $\\varepsilon_o$ 是独立的、零均值的，并服从高斯分布，其真实方差分别为 $\\operatorname{Var}(\\varepsilon_b) = B_{\\text{true}}$ 和 $\\operatorname{Var}(\\varepsilon_o) = R_{\\text{true}}$。分析场通过 $x_a = x_b + K\\,(y - x_b)$ 形成，其中 $K$ 是分析者选择的一个标量增益，旨在利用假定的误差方差 $B_{\\text{assumed}}$ 和 $R_{\\text{assumed}}$ 来最小化期望分析误差平方。\n\n从这些假设以及无偏性和方差的定义出发，推导分析场 $x_a$ 的偏差和方差，将其表示为 $K$、$B_{\\text{true}}$ 和 $R_{\\text{true}}$ 的函数。然后，根据假定的方差 $B_{\\text{assumed}}$ 和 $R_{\\text{assumed}}$，求出分析者会选择的增益 $K$，并用它在真实误差统计下计算实际的分析误差方差。同时，也推导如果使用真实误差统计来选择增益所能得到的最优分析误差方差。\n\n为了说明因错误设定导致的最优性退化，考虑一个案例，其中真实误差方差为 $B_{\\text{true}} = 4$ 和 $R_{\\text{true}} = 1$，但分析者高估了背景误差并低估了观测误差，使用了 $B_{\\text{assumed}} = 9$ 和 $R_{\\text{assumed}} = 0.25$。计算实际分析误差方差（使用从 $B_{\\text{assumed}}$ 和 $R_{\\text{assumed}}$ 计算出的错误设定增益）与最优分析误差方差（使用从 $B_{\\text{true}}$ 和 $R_{\\text{true}}$ 计算出的增益）的比率。将最终比率表示为一个无量纲数，并四舍五入到四位有效数字。",
            "solution": "该问题是有效的，因为它是最优插值理论中一个适定的、有科学依据的、客观的练习，而最优插值是资料同化中的一个基本概念。所有必要信息都已提供，并且前提与既定原则一致。\n\n我们首先形式化分析误差及其统计特性。状态变量表示为 $x$，背景场估计表示为 $x_b$，观测表示为 $y$。背景场和观测模型如下：\n$$x_b = x + \\varepsilon_b$$\n$$y = x + \\varepsilon_o$$\n其中 $\\varepsilon_b$ 和 $\\varepsilon_o$ 分别是背景误差和观测误差。这些误差被假定为独立的、零均值的高斯随机变量。它们的真实方差为 $\\operatorname{Var}(\\varepsilon_b) = E[\\varepsilon_b^2] = B_{\\text{true}}$ 和 $\\operatorname{Var}(\\varepsilon_o) = E[\\varepsilon_o^2] = R_{\\text{true}}$。\n\n分析场 $x_a$ 是由背景场和观测新息 ($y-x_b$) 的线性组合构成的：\n$$x_a = x_b + K(y - x_b)$$\n其中 $K$ 是一个标量增益。我们可以将其改写为：\n$$x_a = (1-K)x_b + Ky$$\n\n分析误差 $\\varepsilon_a$ 定义为分析场与真实状态之间的差：\n$$\\varepsilon_a = x_a - x$$\n代入 $x_a$、$x_b$ 和 $y$ 的表达式：\n$$\\varepsilon_a = ((1-K)x_b + Ky) - x$$\n$$\\varepsilon_a = (1-K)(x + \\varepsilon_b) + K(x + \\varepsilon_o) - x$$\n$$\\varepsilon_a = (1-K)x + (1-K)\\varepsilon_b + Kx + K\\varepsilon_o - x$$\n$$\\varepsilon_a = (1-K+K-1)x + (1-K)\\varepsilon_b + K\\varepsilon_o$$\n$$\\varepsilon_a = (1-K)\\varepsilon_b + K\\varepsilon_o$$\n\n分析场的偏差是分析误差的期望值。利用期望算子的线性性质以及误差的零均值特性 ($E[\\varepsilon_b]=0$，$E[\\varepsilon_o]=0$)：\n$$E[\\varepsilon_a] = E[(1-K)\\varepsilon_b + K\\varepsilon_o] = (1-K)E[\\varepsilon_b] + KE[\\varepsilon_o] = (1-K)(0) + K(0) = 0$$\n对于标量增益 $K$ 的任何选择，分析场都是无偏的。\n\n分析误差的方差，记为 $A$，由 $A = \\operatorname{Var}(\\varepsilon_a) = E[\\varepsilon_a^2] - (E[\\varepsilon_a])^2$ 给出。由于偏差为零，这简化为 $A = E[\\varepsilon_a^2]$。该方差是所选增益 $K$ 的函数：\n$$A(K) = E[((1-K)\\varepsilon_b + K\\varepsilon_o)^2]$$\n$$A(K) = E[(1-K)^2\\varepsilon_b^2 + 2K(1-K)\\varepsilon_b\\varepsilon_o + K^2\\varepsilon_o^2]$$\n利用期望的线性性质以及 $\\varepsilon_b$ 和 $\\varepsilon_o$ 的独立性（这意味着 $E[\\varepsilon_b\\varepsilon_o] = E[\\varepsilon_b]E[\\varepsilon_o] = 0$）：\n$$A(K) = (1-K)^2 E[\\varepsilon_b^2] + 2K(1-K)E[\\varepsilon_b\\varepsilon_o] + K^2 E[\\varepsilon_o^2]$$\n$$A(K) = (1-K)^2 B_{\\text{true}} + K^2 R_{\\text{true}}$$\n这个方程给出了在真实误差统计 $B_{\\text{true}}$ 和 $R_{\\text{true}}$ 下，对于给定增益 $K$ 的实际分析误差方差。\n\n然而，分析者并不知道真实的方差。他们通过最小化*假定*的分析误差方差来选择增益 $K$，该方差是其假定方差 $B_{\\text{assumed}}$ 和 $R_{\\text{assumed}}$ 的函数。设此目标函数为 $J(K)$：\n$$J(K) = (1-K)^2 B_{\\text{assumed}} + K^2 R_{\\text{assumed}}$$\n为了找到最小化 $J(K)$ 的增益，我们对 $K$ 求导并令其为零：\n$$\\frac{dJ}{dK} = -2(1-K)B_{\\text{assumed}} + 2K R_{\\text{assumed}} = 0$$\n$$-2B_{\\text{assumed}} + 2KB_{\\text{assumed}} + 2KR_{\\text{assumed}} = 0$$\n$$2K(B_{\\text{assumed}} + R_{\\text{assumed}}) = 2B_{\\text{assumed}}$$\n分析者选择的增益，由于方差设定错误我们记为 $K_{\\text{subopt}}$，是：\n$$K_{\\text{subopt}} = \\frac{B_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}}$$\n\n使用这个次优增益所导致的实际分析误差方差，可以通过将 $K_{\\text{subopt}}$ 代入 $A(K)$ 的方程中求得：\n$$A_{\\text{actual}} = (1 - K_{\\text{subopt}})^2 B_{\\text{true}} + (K_{\\text{subopt}})^2 R_{\\text{true}}$$\n$$A_{\\text{actual}} = \\left(1 - \\frac{B_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}}\\right)^2 B_{\\text{true}} + \\left(\\frac{B_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}}\\right)^2 R_{\\text{true}}$$\n$$A_{\\text{actual}} = \\left(\\frac{R_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}}\\right)^2 B_{\\text{true}} + \\left(\\frac{B_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}}\\right)^2 R_{\\text{true}}$$\n\n最优分析误差方差 $A_{\\text{opt}}$ 是在增益使用真实方差计算时达到的。最优增益 $K_{\\text{opt}}$ 是：\n$$K_{\\text{opt}} = \\frac{B_{\\text{true}}}{B_{\\text{true}} + R_{\\text{true}}}$$\n得到的最小方差是：\n$$A_{\\text{opt}} = (1-K_{\\text{opt}})^2 B_{\\text{true}} + (K_{\\text{opt}})^2 R_{\\text{true}}$$\n$$A_{\\text{opt}} = \\left(\\frac{R_{\\text{true}}}{B_{\\text{true}} + R_{\\text{true}}}\\right)^2 B_{\\text{true}} + \\left(\\frac{B_{\\text{true}}}{B_{\\text{true}} + R_{\\text{true}}}\\right)^2 R_{\\text{true}}$$\n$$A_{\\text{opt}} = \\frac{R_{\\text{true}}^2 B_{\\text{true}} + B_{\\text{true}}^2 R_{\\text{true}}}{(B_{\\text{true}} + R_{\\text{true}})^2} = \\frac{B_{\\text{true}} R_{\\text{true}} (R_{\\text{true}} + B_{\\text{true}})}{(B_{\\text{true}} + R_{\\text{true}})^2} = \\frac{B_{\\text{true}} R_{\\text{true}}}{B_{\\text{true}} + R_{\\text{true}}}$$\n\n现在我们应用给定的具体数值：$B_{\\text{true}} = 4$，$R_{\\text{true}} = 1$，$B_{\\text{assumed}} = 9$，以及 $R_{\\text{assumed}} = 0.25$。\n\n首先，我们计算分析者选择的次优增益：\n$$K_{\\text{subopt}} = \\frac{B_{\\text{assumed}}}{B_{\\text{assumed}} + R_{\\text{assumed}}} = \\frac{9}{9 + 0.25} = \\frac{9}{9.25} = \\frac{36}{37}$$\n\n接下来，我们使用这个增益计算实际的分析误差方差 $A_{\\text{actual}}$：\n$$A_{\\text{actual}} = (1 - K_{\\text{subopt}})^2 B_{\\text{true}} + (K_{\\text{subopt}})^2 R_{\\text{true}}$$\n$$A_{\\text{actual}} = \\left(1 - \\frac{36}{37}\\right)^2 (4) + \\left(\\frac{36}{37}\\right)^2 (1) = \\left(\\frac{1}{37}\\right)^2 (4) + \\left(\\frac{36}{37}\\right)^2 (1)$$\n$$A_{\\text{actual}} = \\frac{4}{1369} + \\frac{1296}{1369} = \\frac{1300}{1369}$$\n\n然后，我们计算最优分析误差方差 $A_{\\text{opt}}$，这是在完全了解误差统计的情况下可以达到的：\n$$A_{\\text{opt}} = \\frac{B_{\\text{true}} R_{\\text{true}}}{B_{\\text{true}} + R_{\\text{true}}} = \\frac{4 \\times 1}{4 + 1} = \\frac{4}{5}$$\n\n最后，我们计算实际方差与最优方差的比率：\n$$\\text{Ratio} = \\frac{A_{\\text{actual}}}{A_{\\text{opt}}} = \\frac{\\frac{1300}{1369}}{\\frac{4}{5}} = \\frac{1300}{1369} \\times \\frac{5}{4} = \\frac{325 \\times 5}{1369} = \\frac{1625}{1369}$$\n将此分数转换为小数：\n$$\\text{Ratio} \\approx 1.1869978...$$\n四舍五入到四位有效数字，比率为 $1.187$。这个大于 $1$ 的值量化了因误差方差的错误设定而导致的分析质量的下降。",
            "answer": "$$\\boxed{1.187}$$"
        }
    ]
}