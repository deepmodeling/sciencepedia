{
    "hands_on_practices": [
        {
            "introduction": "第一个实践提供了模型构建的基础练习。你将构建两个线性回归模型来降尺度区域降水，其中一个模型明确地包含了地形效应。通过比较它们的性能，你将亲身体验如何量化添加基于物理知识的预测变量所带来的价值，这是开发稳健降尺度方案的一项核心任务。",
            "id": "4093954",
            "problem": "构建一个程序，该程序使用大尺度位势高度和湿度以及显式地形预测因子，对山区的日降水量进行统计降尺度，然后量化通过包含此类地形预测因子所实现的偏差降低。目标领域是数值天气预报 (NWP) 和气候模拟，该方法必须植根于第一性原理和经过充分检验的统计公式。\n\n基本原理和理论基础：\n- 降水的形成是由垂直运动和水汽可用性之间的相互作用支持的。在准地转框架下，天气尺度上升运动与较低的位势高度和正涡度平流相关；因此，较低的位势高度通常代表增强的上升运动。水汽可用性由比湿捕捉。地形增强是由湿润空气在地形上的抬升驱动的，并取决于坡度大小以及气流相对于地形坡向的排列。这些原理为结合大尺度场和显式地形项的预测因子集提供了理论依据。\n- 在加性高斯误差模型下的普通最小二乘法 (OLS) 为线性统计降尺度提供了一个基础估计量。给定设计矩阵 $X$ 和观测值 $y$，OLS 估计量 $\\hat{\\beta}$ 由下式给出\n$$\n\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y,\n$$\n当 $(X^{\\top} X)$ 可逆时，或在必要时等效地通过 Moore–Penrose 伪逆求解。然后预测值为 $X \\hat{\\beta}$，此处为尊重降水量永不为负的物理约束而截断为非负值：\n$$\n\\hat{y}^{+} = \\max(0, X \\hat{\\beta}),\n$$\n逐元素应用。\n\n待估计和比较的模型：\n- 仅使用大尺度预测因子的基线模型：\n$$\ny = \\beta_0 + \\beta_H H + \\beta_q q + \\varepsilon,\n$$\n其中 $H$ 表示位势高度，$q$ 表示比湿。\n- 地形增强模型：\n$$\ny = \\gamma_0 + \\gamma_H H + \\gamma_q q + \\gamma_z z + \\gamma_s s + \\gamma_u u + \\gamma_{su} (s \\cdot u) + \\varepsilon,\n$$\n其中 $z$ 是海拔，$s$ 是坡度大小，$u$ 是一个无量纲的迎风坡对齐因子，而 $(s \\cdot u)$ 是一个显式交互项，捕捉了坡度大小和迎风坡气流对齐的乘法效应。\n\n单位和角度规范：\n- 位势高度 $H$ 以米为单位提供。\n- 比湿 $q$ 以千克/千克为单位提供。\n- 海拔 $z$ 以米为单位提供。\n- 坡度大小 $s$ 以度为单位提供；在此任务中，角度必须以度为单位处理，不得转换为弧度。\n- 降水量 $y$ 以毫米/天为单位提供，并且必须以此单位进行预测。\n\n所需计算：\n1. 使用提供的校准数据集，通过 OLS 估计量来估计基线模型的 $\\hat{\\beta}$ 和地形增强模型的 $\\hat{\\gamma}$。\n2. 使用两种模型为测试套件生成降尺度预测，并将其截斷为非负值，即逐元素应用 $\\max(0,\\cdot)$。\n3. 计算每个测试案例的偏差，即模型预测减去观测降水量。然后，计算每个测试案例的分数偏差减少量：\n$$\nr_i = \\frac{|\\text{bias}_{\\text{baseline},i}| - |\\text{bias}_{\\text{orographic},i}|}{|\\text{bias}_{\\text{baseline},i}|},\n$$\n约定如果 $|\\text{bias}_{\\text{baseline},i}| = 0$，则 $r_i = 0$ 以避免除以零。\n4. 报告分数偏差减少量，四舍五入到四位小数。\n\n校准数据集（每个样本是一个具有不同地形和大规模条件的站点日）。对于每个样本 $i$，提供 $(H_i,q_i,z_i,s_i,u_i,y_i)$：\n- 样本 1：$(H_1 = 5600, q_1 = 0.004, z_1 = 800, s_1 = 10, u_1 = 0.2, y_1 = 11.2)$\n- 样本 2：$(H_2 = 5550, q_2 = 0.006, z_2 = 1500, s_2 = 25, u_2 = 0.7, y_2 = 19.0)$\n- 样本 3：$(H_3 = 5450, q_3 = 0.008, z_3 = 2200, s_3 = 30, u_3 = 0.9, y_3 = 26.6)$\n- 样本 4：$(H_4 = 5700, q_4 = 0.003, z_4 = 1200, s_4 = 15, u_4 = 0.4, y_4 = 8.9)$\n- 样本 5：$(H_5 = 5300, q_5 = 0.010, z_5 = 1800, s_5 = 20, u_5 = 0.6, y_5 = 29.2)$\n- 样本 6：$(H_6 = 5400, q_6 = 0.007, z_6 = 1000, s_6 = 12, u_6 = 0.3, y_6 = 20.22)$\n- 样本 7：$(H_7 = 5580, q_7 = 0.005, z_7 = 900, s_7 = 8, u_7 = 0.1, y_7 = 12.96)$\n- 样本 8：$(H_8 = 5490, q_8 = 0.0065, z_8 = 2000, s_8 = 28, u_8 = 0.8, y_8 = 22.43)$\n- 样本 9：$(H_9 = 5350, q_9 = 0.009, z_9 = 2500, s_9 = 35, u_9 = 1.0, y_9 = 32.0)$\n- 样本 10：$(H_{10} = 5620, q_{10} = 0.0045, z_{10} = 1600, s_{10} = 22, u_{10} = 0.5, y_{10} = 14.15)$\n- 样本 11：$(H_{11} = 5500, q_{11} = 0.0068, z_{11} = 1400, s_{11} = 18, u_{11} = 0.55, y_{11} = 19.58)$\n- 样本 12：$(H_{12} = 5380, q_{12} = 0.0075, z_{12} = 2100, s_{12} = 32, u_{12} = 0.85, y_{12} = 27.19)$\n\n测试套件：\n- 测试案例 A (一般的“理想路径”)：$(H_A = 5450, q_A = 0.007, z_A = 1700, s_A = 24, u_A = 0.7)$，观测降水量 $(y_A = 22.56)$，单位为 $\\mathrm{mm/day}$。\n- 测试案例 B (边界干燥且无迎风坡对齐)：$(H_B = 5700, q_B = 0.002, z_B = 2100, s_B = 30, u_B = 0.0)$，观测降水量 $(y_B = 7.1)$，单位为 $\\mathrm{mm/day}$。\n- 测试案例 C (强地形增强的边缘案例)：$(H_C = 5350, q_C = 0.0095, z_C = 2400, s_C = 34, u_C = 0.95)$，观测降水量 $(y_C = 32.11)$，单位为 $\\mathrm{mm/day}$。\n\n算法要求：\n- 使用普通最小二乘法 (OLS) 从校准数据集中拟合两个模型，并为测试套件生成预测。\n- 对预测应用非负性截断：对于每个预测值 $\\hat{y}$，计算 $\\hat{y}^{+} = \\max(0,\\hat{y})$。\n- 计算如上定义的分数偏差减少量 $r_A$、$r_B$ 和 $r_C$，并将每个值四舍五入到四位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，顺序为 $[r_A,r_B,r_C]$，例如 $[0.1234,0.5678,0.9012]$。",
            "solution": "该问题要求构建并比较两种用于日降水量统计降尺度的统计模型。第一种是使用大尺度大气预测因子的基线模型，第二种是包含局部地形预测因子的增强模型。比较将通过量化更复杂的模型所实现的预测偏差的分数减少量来进行。整个过程将基于普通最小二乘法 (OLS) 回归的原理。\n\n首先，我们按照规定定义两个线性模型。\n\n基线模型将降水量 $y$ 与大尺度位势高度 $H$ 和比湿 $q$ 联系起来：\n$$\ny = \\beta_0 + \\beta_H H + \\beta_q q + \\varepsilon\n$$\n这里，$\\beta_0$ 是截距，$\\beta_H$ 和 $\\beta_q$ 是相应预测因子的系数，$\\varepsilon$ 是误差项，假定为高斯分布。\n\n地形增强模型增加了与局部地形相关的预测因子：海拔 $z$、坡度大小 $s$、迎风坡对齐因子 $u$，以及坡度与对齐之间的交互项 $s \\cdot u$：\n$$\ny = \\gamma_0 + \\gamma_H H + \\gamma_q q + \\gamma_z z + \\gamma_s s + \\gamma_u u + \\gamma_{su} (s \\cdot u) + \\varepsilon\n$$\n该模型的系数用 $\\gamma_j$ 表示。两个模型都可以用线性模型的一般矩阵形式表示，$Y = X\\beta + \\varepsilon$，其中 $Y$ 是观测降水值的向量，$X$ 是包含预测因子值的设计矩阵（其中第一列为代表截距的全1列），$\\beta$ 是待估计的系数向量。\n\n系数向量 $\\hat{\\beta}$ 和 $\\hat{\\gamma}$ 的估计使用普通最小二乘法 (OLS) 进行。OLS 估计量提供了使观测值与预测值之间平方差之和最小化的系数值。解由正规方程给出：\n$$\n\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} Y\n$$\n当矩阵 $X^{\\top} X$ 可逆时，此解有效。在出现多重共线性或其他数值问题的情况下，Moore-Penrose 伪逆提供了一个稳健的替代方案。我们将使用一个隐式处理此问题的数值线性代数求解器，这等效于使用伪逆。\n\n第一步是从提供的包含 $N=12$ 个样本的校准数据集中构建设计矩阵和响应向量。响应向量 $Y$ 是：\n$$\nY = [11.2, 19.0, 26.6, 8.9, 29.2, 20.22, 12.96, 22.43, 32.0, 14.15, 19.58, 27.19]^{\\top}\n$$\n对于基线模型，设计矩阵 $X_{\\text{base}}$ 是一个 $12 \\times 3$ 的矩阵，其列分别对应于截距、$H$ 和 $q$：\n$$\nX_{\\text{base}} = \\begin{pmatrix}\n1 & 5600 & 0.004 \\\\\n1 & 5550 & 0.006 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & 5380 & 0.0075\n\\end{pmatrix}\n$$\n对于地形增强模型，设计矩阵 $X_{\\text{oro}}$ 是一个 $12 \\times 7$ 的矩阵，其列分别对应于截距、$H$、$q$、$z$、$s$、$u$ 以及交互项 $s \\cdot u$：\n$$\nX_{\\text{oro}} = \\begin{pmatrix}\n1 & 5600 & 0.004 & 800 & 10 & 0.2 & 2.0 \\\\\n1 & 5550 & 0.006 & 1500 & 25 & 0.7 & 17.5 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & 5380 & 0.0075 & 2100 & 32 & 0.85 & 27.2\n\\end{pmatrix}\n$$\n然后，通过使用校准数据为每个模型求解 OLS 问题来计算系数向量 $\\hat{\\beta}$ 和 $\\hat{\\gamma}$。\n\n接下来，我们使用拟合好的模型对三个测试案例（A、B、C）进行预测。对于每个测试案例 $i$，我们构建相应的预测因子向量，$x_{\\text{base},i}$（一个 $1 \\times 3$ 的行向量）和 $x_{\\text{oro},i}$（一个 $1 \\times 7$ 的行向量）。\n\n初始预测值计算为预测因子向量与相应估计系数向量的点积：\n$$\n\\hat{y}_{\\text{base}, i} = x_{\\text{base}, i} \\hat{\\beta}\n$$\n$$\n\\hat{y}_{\\text{oro}, i} = x_{\\text{oro}, i} \\hat{\\gamma}\n$$\n由于降水量不能为负，这些预测值在零处被截断：\n$$\n\\hat{y}^{+}_{\\text{base}, i} = \\max(0, \\hat{y}_{\\text{base}, i})\n$$\n$$\n\\hat{y}^{+}_{\\text{oro}, i} = \\max(0, \\hat{y}_{\\text{oro}, i})\n$$\n最后一步是量化性能改进。我们首先计算每个模型和测试案例的预测偏差，定义为预测值减去观测值 ($y_{\\text{obs},i}$):\n$$\n\\text{bias}_{\\text{base}, i} = \\hat{y}^{+}_{\\text{base}, i} - y_{\\text{obs}, i}\n$$\n$$\n\\text{bias}_{\\text{oro}, i} = \\hat{y}^{+}_{\\text{oro}, i} - y_{\\text{obs}, i}\n$$\n然后使用以下公式计算分数偏差减少量 $r_i$：\n$$\nr_i = \\frac{|\\text{bias}_{\\text{base},i}| - |\\text{bias}_{\\text{oro},i}|}{|\\text{bias}_{\\text{base},i}|}\n$$\n处理一个特殊情况，如果分母 $|\\text{bias}_{\\text{base},i}|$ 为零，则定义 $r_i$ 为 $0$。计算出的值 $r_A$、$r_B$ 和 $r_C$随后四舍五入到四位小数以供最终输出。整个过程在以下程序中实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs statistical downscaling of precipitation using two linear models,\n    and quantifies the bias reduction from including orographic predictors.\n    \"\"\"\n    # Define the calibration dataset from the problem statement.\n    # Each entry: (H, q, z, s, u, y)\n    calibration_data = [\n        (5600, 0.004, 800, 10, 0.2, 11.2),\n        (5550, 0.006, 1500, 25, 0.7, 19.0),\n        (5450, 0.008, 2200, 30, 0.9, 26.6),\n        (5700, 0.003, 1200, 15, 0.4, 8.9),\n        (5300, 0.010, 1800, 20, 0.6, 29.2),\n        (5400, 0.007, 1000, 12, 0.3, 20.22),\n        (5580, 0.005, 900, 8, 0.1, 12.96),\n        (5490, 0.0065, 2000, 28, 0.8, 22.43),\n        (5350, 0.009, 2500, 35, 1.0, 32.0),\n        (5620, 0.0045, 1600, 22, 0.5, 14.15),\n        (5500, 0.0068, 1400, 18, 0.55, 19.58),\n        (5380, 0.0075, 2100, 32, 0.85, 27.19),\n    ]\n\n    # Define the test suite.\n    # Each entry: (H, q, z, s, u, y_obs)\n    test_cases = [\n        (5450, 0.007, 1700, 24, 0.7, 22.56),   # Case A\n        (5700, 0.002, 2100, 30, 0.0, 7.1),     # Case B\n        (5350, 0.0095, 2400, 34, 0.95, 32.11)  # Case C\n    ]\n\n    # Prepare calibration data for OLS\n    calib_array = np.array(calibration_data)\n    y_calib = calib_array[:, 5]\n\n    # Construct design matrix for the baseline model\n    # Columns: intercept, H, q\n    X_base_calib = np.vstack([\n        np.ones(len(calib_array)),\n        calib_array[:, 0],\n        calib_array[:, 1]\n    ]).T\n\n    # Construct design matrix for the orographic-augmented model\n    # Columns: intercept, H, q, z, s, u, s*u\n    s_u_interaction = calib_array[:, 3] * calib_array[:, 4]\n    X_oro_calib = np.vstack([\n        np.ones(len(calib_array)),\n        calib_array[:, 0], # H\n        calib_array[:, 1], # q\n        calib_array[:, 2], # z\n        calib_array[:, 3], # s\n        calib_array[:, 4], # u\n        s_u_interaction\n    ]).T\n\n    # Fit the models using OLS (via numpy.linalg.lstsq)\n    # This is numerically robust and equivalent to using the Moore-Penrose pseudoinverse.\n    beta_hat, _, _, _ = np.linalg.lstsq(X_base_calib, y_calib, rcond=None)\n    gamma_hat, _, _, _ = np.linalg.lstsq(X_oro_calib, y_calib, rcond=None)\n    \n    results = []\n    \n    # Process each test case\n    for case in test_cases:\n        H, q, z, s, u, y_obs = case\n\n        # --- Baseline Model Prediction ---\n        x_base_test = np.array([1, H, q])\n        y_pred_base = x_base_test @ beta_hat\n        y_pred_base_truncated = max(0, y_pred_base)\n        bias_base = y_pred_base_truncated - y_obs\n\n        # --- Orographic-Augmented Model Prediction ---\n        s_u_interact_test = s * u\n        x_oro_test = np.array([1, H, q, z, s, u, s_u_interact_test])\n        y_pred_oro = x_oro_test @ gamma_hat\n        y_pred_oro_truncated = max(0, y_pred_oro)\n        bias_oro = y_pred_oro_truncated - y_obs\n\n        # --- Fractional Bias Reduction ---\n        abs_bias_base = abs(bias_base)\n        abs_bias_oro = abs(bias_oro)\n        \n        if abs_bias_base == 0:\n            r = 0.0\n        else:\n            r = (abs_bias_base - abs_bias_oro) / abs_bias_base\n            \n        results.append(round(r, 4))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "构建统计模型只是第一步；验证其假设也同样关键，尤其是在处理时间序列数据时。本练习专注于诊断并修正模型残差中的自相关问题，这是气候学分析中的一个常见挑战。你将学习实施标准的诊断检验，并应用Prais-Winsten方法来获得更有效、更可靠的系数估计，从而加深对严格模型检验重要性的理解。",
            "id": "4094057",
            "problem": "考虑一个统计降尺度情景，其中一个测站温度时间序列被建模为对大尺度预报因子的线性响应，并带有自回归噪声。设测站温度为 $T_t$（单位：摄氏度），大尺度位势高度为 $Z_t$（单位：米），大尺度比湿为 $H_t$（单位：千克/千克）。假设线性模型为\n$$\nT_t \\;=\\; \\beta_0 \\;+\\; \\beta_1 Z_t \\;+\\; \\beta_2 H_t \\;+\\; \\varepsilon_t,\n$$\n其误差为一阶自回归（AR(1)）误差，由下式给出\n$$\n\\varepsilon_t \\;=\\; \\phi\\,\\varepsilon_{t-1} \\;+\\; u_t,\n$$\n其中 $\\phi$ 是滞后1阶自回归系数，而 $u_t$ 是均值为零、方差有限的白噪声。任何三角函数中出现的角度必须以弧度处理。\n\n您必须实现线性模型的普通最小二乘（OLS）拟合以获得 $\\hat{\\beta}$，检验OLS残差的滞后1阶自相关性，然后通过应用带有估计值 $\\hat{\\phi}$ 的 Prais–Winsten 变换，在 AR(1) 误差下使用可行广义最小二乘（FGLS）来调整回归。对于自相关检验，计算 Durbin–Watson 统计量和滞后1阶的 Ljung–Box 检验统计量，使用自由度为1的卡方分布获得 $p$ 值。如果 $p$ 值小于 $0.05$，则声明检测到自相关。\n\n为确保可复现性且无外部随机性，通过线性同余生成器（LCG）确定性地生成伪随机均匀序列 $u_t$，并将其重新缩放以具有指定的目标标准差。使用递推关系\n$$\ns_t \\;=\\; (a\\,s_{t-1} + c)\\;\\bmod\\; m,\\quad x_t \\;=\\; \\frac{s_t}{m},\\quad v_t \\;=\\; x_t - \\frac{1}{2},\\quad u_t \\;=\\; \\frac{\\sigma}{\\sqrt{1/12}}\\; v_t,\n$$\n其中 $a=16807$，$c=0$，$m=2147483647$，以及指定的 $s_0$（种子）。单位如下：温度 $T_t$ 单位为摄氏度，位势高度 $Z_t$ 单位为米，比湿 $H_t$ 单位为千克/千克。所有最终回归系数 $\\beta_0$ 以摄氏度表示，$\\beta_1$ 以摄氏度/米表示，$\\beta_2$ 以摄氏度/（千克/千克）表示。Durbin–Watson 统计量和 Ljung–Box $p$ 值是无单位的。\n\n使用以下公式构建时间序列\n$$\nZ_t \\;=\\; z_0 \\;+\\; A_Z \\sin\\!\\left(\\frac{2\\pi t}{12}\\right),\n$$\n$$\nH_t \\;=\\; h_0 \\;+\\; A_H \\cos\\!\\left(\\frac{2\\pi t}{12} + \\theta\\right),\n$$\n其中 $t=1,2,\\dots,N$，以及 AR(1) 递推关系 $\\varepsilon_t = \\phi\\,\\varepsilon_{t-1} + u_t$ 且 $\\varepsilon_0 = 0$。\n\n对于每个测试用例，计算：\n- OLS 系数 $\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2$。\n- 根据 OLS 残差 $r_t$ 计算的 Durbin–Watson 统计量 $D$\n$$\nD \\;=\\; \\frac{\\sum_{t=2}^{N} (r_t - r_{t-1})^2}{\\sum_{t=1}^{N} r_t^2}.\n$$\n- 使用以下公式计算的 Ljung–Box 滞后1阶 $p$ 值\n$$\nr_1 \\;=\\; \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=1}^{N} r_t^2},\\quad\nQ \\;=\\; \\frac{N(N+2)}{N-1}\\, r_1^2,\\quad p \\;=\\; 1 - F_{\\chi^2,1}(Q),\n$$\n其中 $F_{\\chi^2,1}$ 是自由度为1的卡方分布的累积分布函数。\n- 自回归参数估计值\n$$\n\\hat{\\phi} \\;=\\; \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=2}^{N} r_{t-1}^2},\n$$\n为保证数值稳定性，该值被裁剪到区间 $[-0.99,0.99]$ 内。\n- Prais–Winsten FGLS 系数 $\\tilde{\\beta}_0, \\tilde{\\beta}_1, \\tilde{\\beta}_2$，通过以下方式变换设计矩阵和响应变量得到\n$$\nY_t^* =\n\\begin{cases}\n\\sqrt{1-\\hat{\\phi}^2}\\; Y_1, & t=1 \\\\\nY_t - \\hat{\\phi}\\,Y_{t-1}, & t=2,\\dots,N\n\\end{cases}\n\\qquad\nX_t^* =\n\\begin{cases}\n\\sqrt{1-\\hat{\\phi}^2}\\; X_1, & t=1 \\\\\nX_t - \\hat{\\phi}\\,X_{t-1}, & t=2,\\dots,N\n\\end{cases}\n$$\n然后通过 OLS 将 $Y^*$ 对 $X^*$ 进行回归，其中 $X_t = [1,\\;Z_t,\\;H_t]$ 包含截距项。\n\n使用以下参数集测试套件，每个由 $(N,\\;\\phi,\\;\\beta_0,\\;\\beta_1,\\;\\beta_2,\\;z_0,\\;A_Z,\\;h_0,\\;A_H,\\;\\theta,\\;\\sigma,\\;s_0)$ 指定：\n\n- 测试用例1（中等自相关的一般情况）：$(N=\\;120,\\;\\phi=\\;0.6,\\;\\beta_0=\\;5.0,\\;\\beta_1=\\;-0.004,\\;\\beta_2=\\;8.0,\\;z_0=\\;1500,\\;A_Z=\\;100,\\;h_0=\\;0.006,\\;A_H=\\;0.002,\\;\\theta=\\;0.7,\\;\\sigma=\\;0.5,\\;s_0=\\;13579)$。\n- 测试用例2（无自相关的边界情况）：$(N=\\;100,\\;\\phi=\\;0.0,\\;\\beta_0=\\;2.0,\\;\\beta_1=\\;0.003,\\;\\beta_2=\\;-4.0,\\;z_0=\\;3000,\\;A_Z=\\;50,\\;h_0=\\;0.012,\\;A_H=\\;0.001,\\;\\theta=\\;1.1,\\;\\sigma=\\;0.4,\\;s_0=\\;24680)$。\n- 测试用例3（接近单位根自相关的边缘情况）：$(N=\\;200,\\;\\phi=\\;0.95,\\;\\beta_0=\\;0.0,\\;\\beta_1=\\;0.001,\\;\\beta_2=\\;2.0,\\;z_0=\\;500,\\;A_Z=\\;200,\\;h_0=\\;0.010,\\;A_H=\\;0.003,\\;\\theta=\\;0.3,\\;\\sigma=\\;0.2,\\;s_0=\\;98765)$。\n\n您的程序必须：\n- 为每个测试用例构建 $Z_t, H_t$，通过 LCG 生成 $u_t$，通过 AR(1) 递推关系生成 $\\varepsilon_t$，然后根据指定的线性模型生成 $T_t$。\n- 执行 OLS 以获得 $\\hat{\\beta}$，计算 Durbin–Watson 统计量 $D$，计算 Ljung–Box $p$ 值，估计 $\\hat{\\phi}$，并执行 Prais–Winsten FGLS 以获得 $\\tilde{\\beta}$。\n- 对每个测试用例，按顺序生成展平序列\n$$\n\\left[\\hat{\\beta}_0,\\;\\hat{\\beta}_1,\\;\\hat{\\beta}_2,\\;D,\\;p,\\;\\hat{\\phi},\\;\\tilde{\\beta}_0,\\;\\tilde{\\beta}_1,\\;\\tilde{\\beta}_2\\right],\n$$\n其中所有浮点数四舍五入到六位小数。将所有三个测试用例的结果连接成一个单一列表。\n\n最终输出格式：您的程序应生成单行输出，包含一个逗号分隔的列表形式的结果，并用方括号括起来（例如，$[result1,result2,\\dots]$），其中所有浮点数均四舍五入到六位小数，布尔值（如有）将显示为 $True$ 或 $False$。角度必须以弧度为单位，所有物理量必须遵守上述单位。",
            "solution": "该问题要求为带有自回归误差的时间序列模型实现一个统计分析流程。该过程涉及数据生成、通过普通最小二乘（OLS）进行模型估计、自相关诊断检验，以及使用可行广义最小二乘（FGLS）通过 Prais-Winsten 变换进行模型校正。整个过程是确定性的，以确保可复现性。\n\n**1. 数据生成**\n\n第一步是为每个测试用例构建时间序列数据集。模型由下式给出：\n$$\nT_t = \\beta_0 + \\beta_1 Z_t + \\beta_2 H_t + \\varepsilon_t\n$$\n其中 $T_t$ 是响应变量（温度），$Z_t$ 和 $H_t$ 是预报因子（位势高度和比湿）。预报因子是关于时间 $t=1, 2, \\dots, N$ 的确定性正弦函数：\n$$\nZ_t = z_0 + A_Z \\sin\\left(\\frac{2\\pi t}{12}\\right)\n$$\n$$\nH_t = h_0 + A_H \\cos\\left(\\frac{2\\pi t}{12} + \\theta\\right)\n$$\n误差项 $\\varepsilon_t$ 遵循一阶自回归（AR(1)）过程，这引入了序列相关性：\n$$\n\\varepsilon_t = \\phi\\,\\varepsilon_{t-1} + u_t\n$$\n初始条件为 $\\varepsilon_0 = 0$。项 $u_t$ 代表白噪声，它是使用线性同余生成器（LCG）确定性地生成的，以确保结果可复现。LCG 序列 $s_t$ 由 $s_t = (a s_{t-1} + c) \\pmod m$ 定义，其中给定参数 $a = 16807$，$c = 0$，$m = 2147483647$ 以及特定的种子 $s_0$。该序列随后被变换成一个均值为零、具有指定标准差 $\\sigma$ 的序列 $u_t$。变换公式为：\n$$\nu_t = \\frac{\\sigma}{\\sqrt{1/12}} \\left( \\frac{s_t}{m} - \\frac{1}{2} \\right)\n$$\n这种缩放是正确的，因为 $[0,1]$ 上的均匀分布的方差为 $1/12$，减去 $1/2$ 会将均值中心化到 $0$ 而不改变方差。\n\n**2. 普通最小二乘（OLS）估计**\n\n我们首先使用 OLS 拟合模型，该方法假设误差 $\\varepsilon_t$ 是不相关的。模型以矩阵形式表示为 $Y = X\\beta + \\varepsilon$，其中 $Y$ 是温度 $T_t$ 的向量，$X$ 是设计矩阵，其列分别为截距项、$Z_t$ 和 $H_t$。$\\beta = [\\beta_0, \\beta_1, \\beta_2]^T$ 的 OLS 估计量为：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n$$\n这提供了初始估计值 $(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2)$。\n\n**3. 自相关诊断**\n\n由于数据是用 AR(1) 误差生成的（当 $\\phi \\neq 0$ 时），OLS 的不相关误差假设被违反。这可能导致系数估计效率低下和标准误有偏。我们使用 OLS 残差 $r_t = T_t - (\\hat{\\beta}_0 + \\hat{\\beta}_1 Z_t + \\hat{\\beta}_2 H_t)$ 来检验这一点。\n\n- **Durbin-Watson 统计量 ($D$)**: 该统计量用于检验一阶自相关。其计算公式为：\n  $$\n  D = \\frac{\\sum_{t=2}^{N} (r_t - r_{t-1})^2}{\\sum_{t=1}^{N} r_t^2}\n  $$\n  $D \\approx 2$ 的值表明无自相关，而接近 $0$ 的值表示正自相关，接近 $4$ 的值表示负自相关。\n\n- **Ljung-Box 检验**: 这是一个更通用的检验。对于滞后1阶，检验统计量 $Q$ 由残差的一阶样本自相关 $r_1$ 计算得出：\n  $$\n  r_1 = \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=1}^{N} r_t^2}, \\quad Q = \\frac{N(N+2)}{N-1} r_1^2\n  $$\n  在无自相关的原假设下，$Q$ 服从自由度为1的卡方分布（$\\chi^2_1$）。$p$ 值是观察到与 $Q$ 一样极端或更极端的检验统计量的概率，计算为 $p = 1 - F_{\\chi^2,1}(Q)$，其中 $F$ 是累积分布函数（CDF）。\n\n**4. 可行广义最小二乘（FGLS）估计**\n\n如果检测到自相关，我们可以应用 FGLS 来获得更有效的估计。Prais-Winsten 方法是针对 AR(1) 误差的 FGLS 过程。\n\n- **估计自相关系数 ($\\hat{\\phi}$)**: 首先，通过将 OLS 残差 $r_t$ 对 $r_{t-1}$ 进行回归来估计 AR(1) 参数 $\\phi$：\n  $$\n  \\hat{\\phi} = \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=2}^{N} r_{t-1}^2}\n  $$\n  为确保下一步的稳定性，此估计值被裁剪到区间 $[-0.99, 0.99]$ 内。\n\n- **Prais-Winsten 变换**: 对原始数据进行变换以消除自相关。该变换对数据进行准差分：\n  $$\n  Y_t^* = Y_t - \\hat{\\phi} Y_{t-1}, \\quad X_t^* = X_t - \\hat{\\phi} X_{t-1} \\quad \\text{for } t=2, \\dots, N\n  $$\n  第一个观测值（$t=1$）被特殊处理以保留其信息，并由 $\\sqrt{1-\\hat{\\phi}^2}$ 加权：\n  $$\n  Y_1^* = \\sqrt{1-\\hat{\\phi}^2} Y_1, \\quad X_1^* = \\sqrt{1-\\hat{\\phi}^2} X_1\n  $$\n  变换后的模型 $Y^* = X^*\\beta + u^*$ 现在具有一个近似为白噪声的误差项 $u^*$。\n\n- **对变换后的数据进行OLS**: 最后，对变换后的变量应用 OLS 以获得 FGLS 估计量 $\\tilde{\\beta}$：\n  $$\n  \\tilde{\\beta} = ((X^*)^T X^*)^{-1} (X^*)^T Y^*\n  $$\n这提供了校正后的 FGLS 系数 $(\\tilde{\\beta}_0, \\tilde{\\beta}_1, \\tilde{\\beta}_2)$，在存在序列相关的情况下，这些系数通常比 OLS 估计更有效。实现将对提供的三个测试用例中的每一个执行这整个序列。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    Generates time series data with AR(1) errors, performs OLS and FGLS,\n    and computes autocorrelation diagnostics.\n    \"\"\"\n    test_cases = [\n        # (N, phi, beta0, beta1, beta2, z0, AZ, h0, AH, theta, sigma, s0)\n        (120, 0.6, 5.0, -0.004, 8.0, 1500, 100, 0.006, 0.002, 0.7, 0.5, 13579),\n        (100, 0.0, 2.0, 0.003, -4.0, 3000, 50, 0.012, 0.001, 1.1, 0.4, 24680),\n        (200, 0.95, 0.0, 0.001, 2.0, 500, 200, 0.010, 0.003, 0.3, 0.2, 98765)\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, phi, beta0, beta1, beta2, z0, AZ, h0, AH, theta, sigma, s0 = case\n        \n        # 1. Data Generation\n        t = np.arange(1, N + 1)\n        \n        # Generate predictors\n        Z_t = z0 + AZ * np.sin(2 * np.pi * t / 12)\n        H_t = h0 + AH * np.cos(2 * np.pi * t / 12 + theta)\n        \n        # Generate white noise u_t using LCG\n        s = np.zeros(N, dtype=np.int64)\n        s_prev = s0\n        a, c, m = 16807, 0, 2147483647\n        for i in range(N):\n            s_curr = (a * s_prev + c) % m\n            s[i] = s_curr\n            s_prev = s_curr\n        \n        x_t = s / m\n        v_t = x_t - 0.5\n        u_t = (sigma / np.sqrt(1/12)) * v_t\n        \n        # Generate AR(1) errors epsilon_t\n        eps_t = np.zeros(N)\n        eps_t[0] = phi * 0 + u_t[0]  # eps_0 = 0\n        for i in range(1, N):\n            eps_t[i] = phi * eps_t[i-1] + u_t[i]\n            \n        # Generate response variable T_t\n        T_t = beta0 + beta1 * Z_t + beta2 * H_t + eps_t\n        \n        # 2. Ordinary Least Squares (OLS)\n        Y = T_t\n        X = np.c_[np.ones(N), Z_t, H_t]\n        \n        try:\n            beta_hat = np.linalg.inv(X.T @ X) @ X.T @ Y\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse for near-singular matrices\n            beta_hat = np.linalg.pinv(X.T @ X) @ X.T @ Y\n\n        b0_hat, b1_hat, b2_hat = beta_hat\n        \n        # 3. Autocorrelation Diagnostics\n        residuals = Y - X @ beta_hat\n        \n        # Durbin-Watson statistic\n        dw_num = np.sum((residuals[1:] - residuals[:-1])**2)\n        dw_den = np.sum(residuals**2)\n        D = dw_num / dw_den\n        \n        # Ljung-Box lag-1 test\n        r1_num = np.sum(residuals[1:] * residuals[:-1])\n        r1_den = np.sum(residuals**2)\n        r1 = r1_num / r1_den\n        Q = N * (N + 2) / (N - 1) * r1**2\n        p_value = 1.0 - chi2.cdf(Q, df=1)\n        \n        # 4. Feasible Generalized Least Squares (FGLS)\n        # Estimate phi from OLS residuals\n        phi_hat_num = np.sum(residuals[1:] * residuals[:-1])\n        phi_hat_den = np.sum(residuals[:-1]**2)\n        phi_hat_raw = phi_hat_num / phi_hat_den\n        phi_hat = np.clip(phi_hat_raw, -0.99, 0.99)\n        \n        # Prais-Winsten transformation\n        Y_star = np.zeros_like(Y)\n        X_star = np.zeros_like(X)\n        \n        pw_factor = np.sqrt(1 - phi_hat**2)\n        \n        Y_star[0] = pw_factor * Y[0]\n        X_star[0, :] = pw_factor * X[0, :]\n        \n        Y_star[1:] = Y[1:] - phi_hat * Y[:-1]\n        X_star[1:, :] = X[1:, :] - phi_hat * X[:-1, :]\n        \n        # OLS on transformed data\n        try:\n            beta_tilde = np.linalg.inv(X_star.T @ X_star) @ X_star.T @ Y_star\n        except np.linalg.LinAlgError:\n            beta_tilde = np.linalg.pinv(X_star.T @ X_star) @ X_star.T @ Y_star\n\n        b0_tilde, b1_tilde, b2_tilde = beta_tilde\n        \n        # 5. Collect and format results\n        # The problem asks for the clipped phi_hat to be reported\n        case_results = [\n            b0_hat, b1_hat, b2_hat,\n            D, p_value, phi_hat,\n            b0_tilde, b1_tilde, b2_tilde\n        ]\n        \n        all_results.extend([round(v, 6) for v in case_results])\n\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "随着降尺度模型变得越来越复杂，理解它们为何做出特定预测变得至关重要。最后一个练习将超越模型拟合，深入探讨模型的可解释性，解决“黑箱”问题。你将使用部分依赖图（Partial Dependence）和沙普利值（Shapley values）等先进技术来剖析一个非线性模型的行为，将其统计预测与降水的基本物理原理联系起来。",
            "id": "4093998",
            "problem": "您将分析一个用于数值天气预报和气候模拟的、物理上一致的人工合成统计降尺度模型。目标是使用部分依赖 (PD) 和 Shapley 值来解释模型的预测，并将结果与关于降水形成的物理预期进行交叉核对。\n\n该模型将大尺度预报因子映射到局地日降水强度，单位为毫米/天 (mm/day)。预报因子包括：\n- $850$ hPa 的比湿，记为 $q$，单位为 $\\mathrm{kg/kg}$。\n- 上升垂直运动的代理变量，记为 $a$，定义为 $a = \\max(0, -\\omega)$，其中 $\\omega$ 是 $700$ hPa 的垂直气压速度，单位为 $\\mathrm{Pa/s}$（因此 $a$ 的单位为 $\\mathrm{Pa/s}$ 且为非负值）。\n- 地形坡度大小，记为 $s$，为无量纲量，范围在 $[0,1]$。\n\n该降尺度模型是一个机器学习模型的非线性参数化代理，定义如下：\n$$\nf(q,a,s) = \\mathrm{softplus}\\left(\\beta_0 + \\beta_q \\cdot (1000\\,q) + \\beta_a \\cdot (10\\,a) + \\beta_s \\cdot s + \\beta_{\\mathrm{int}} \\cdot (1000\\,q)\\cdot(10\\,a)\\right),\n$$\n其中 $\\mathrm{softplus}(z) = \\ln(1 + e^z)$，系数固定为：\n$$\n\\beta_0 = -2.0,\\quad \\beta_q = 0.25,\\quad \\beta_a = 1.2,\\quad \\beta_s = 0.5,\\quad \\beta_{\\mathrm{int}} = 0.03.\n$$\n模型输出 $f(q,a,s)$ 必须解释为以 $\\mathrm{mm/day}$ 表示的日降水强度。\n\n假设 $(q,a,s)$ 的联合分布代表了一个气候学上合理的背景状态，并用于计算期望值：\n- $q \\sim \\mathcal{N}(\\mu_q, \\sigma_q^2)$，截断于区间 $[q_{\\min}, q_{\\max}]$，其中 $\\mu_q = 0.012\\,\\mathrm{kg/kg}$，$\\sigma_q = 0.003\\,\\mathrm{kg/kg}$，$q_{\\min} = 0.004\\,\\mathrm{kg/kg}$，$q_{\\max} = 0.020\\,\\mathrm{kg/kg}$。\n- $a \\sim \\mathcal{N}(\\mu_a, \\sigma_a^2)$，截断于区间 $[a_{\\min}, a_{\\max}]$，其中 $\\mu_a = 0.05\\,\\mathrm{Pa/s}$，$\\sigma_a = 0.03\\,\\mathrm{Pa/s}$，$a_{\\min} = 0.0\\,\\mathrm{Pa/s}$，$a_{\\max} = 0.3\\,\\mathrm{Pa/s}$。\n- $s \\sim \\mathrm{Uniform}(0,1)$。\n\n您必须基于第一性原理实现以下解释函数：\n1. 部分依赖 (PD)：部分依赖 (PD) 是指将一个特征设置为固定值，而其他特征在其背景分布上进行边缘化后的期望预测值。对于值为 $x_i$ 的特征索引 $i$，定义如下：\n$$\n\\mathrm{PD}_i(x_i) = \\mathbb{E}\\left[f\\left(X_1, X_2, X_3\\right) \\mid X_i = x_i\\right],\n$$\n其中期望是针对其他特征 $(X_j)_{j\\neq i}$ 的背景分布计算的。\n2. Shapley 值：使用合作博弈论中的 Shapley 值来量化每个特征在特定实例 $x = (q,a,s)$ 上的贡献。设子集 $S \\subseteq \\{1,2,3\\}$ 的价值函数为：\n$$\nv(S;x) = \\mathbb{E}\\left[f\\left(x_S, X_{-S}\\right)\\right],\n$$\n其中 $x_S$ 表示将集合 $S$ 中的特征固定为该实例的值，$X_{-S}$ 表示从背景分布中对剩余特征进行采样。基线值为 $v(\\emptyset;x) = \\mathbb{E}[f(X)]$。对于 $n=3$ 个特征，特征 $i$ 的 Shapley 值为：\n$$\n\\phi_i(x) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!(n - |S| - 1)!}{n!}\\left[v(S \\cup \\{i\\};x) - v(S;x)\\right],\n$$\n其中 $N=\\{1,2,3\\}$。使用干预式公式（集合 $S$ 之外的特征从背景分布中独立采样）。\n\n所有期望值必须使用从指定背景分布中进行的蒙特卡洛采样进行数值计算。$f$ 的所有量都必须以 $\\mathrm{mm/day}$ 表示，并且必须在这些单位上进行比较。不涉及任何角度。\n\n测试套件和要求输出：\n- 定义并评估以下案例：\n  1. $\\mathrm{PD}_q$ 的单调性：在 $q_{\\mathrm{low}}=0.006\\,\\mathrm{kg/kg}$ 和 $q_{\\mathrm{high}}=0.016\\,\\mathrm{kg/kg}$ 处评估 $\\mathrm{PD}_q(q_{\\mathrm{low}})$ 和 $\\mathrm{PD}_q(q_{\\mathrm{high}})$，并返回一个布尔值，指示是否 $\\mathrm{PD}_q(q_{\\mathrm{high}}) > \\mathrm{PD}_q(q_{\\mathrm{low}})$。\n  2. $\\mathrm{PD}_a$ 的单调性：在 $a_{\\mathrm{low}}=0.02\\,\\mathrm{Pa/s}$ 和 $a_{\\mathrm{high}}=0.20\\,\\mathrm{Pa/s}$ 处评估 $\\mathrm{PD}_a(a_{\\mathrm{low}})$ 和 $\\mathrm{PD}_a(a_{\\mathrm{high}})$，并返回一个布尔值，指示是否 $\\mathrm{PD}_a(a_{\\mathrm{high}}) > \\mathrm{PD}_a(a_{\\mathrm{low}})$。\n  3. 在 $x_1=(q,a,s)=(0.016\\,\\mathrm{kg/kg},\\,0.20\\,\\mathrm{Pa/s},\\,0.5)$ 处的 Shapley 效率：计算所有特征 $i$ 的 $\\phi_i(x_1)$，并检查是否满足\n     $$\n     \\left|\\left(f(x_1) - \\mathbb{E}[f(X)]\\right) - \\sum_{i=1}^3 \\phi_i(x_1)\\right|  \\tau,\n     $$\n     容差 $\\tau = 0.05\\,\\mathrm{mm/day}$。返回一个布尔值。\n  4. 在 $x_1$ 处 Shapley 值的符号一致性：返回两个布尔值，分别指示 $\\phi_q(x_1)  0$ 和 $\\phi_a(x_1)  0$。\n  5. $q$ 和 $a$ 之间的正协同效应：计算\n     $$\n     \\Delta_{\\mathrm{syn}} = \\mathbb{E}_s\\left[f(q_{\\mathrm{high}}, a_{\\mathrm{high}}, s) - f(q_{\\mathrm{high}}, a_{\\mathrm{low}}, s) - f(q_{\\mathrm{low}}, a_{\\mathrm{high}}, s) + f(q_{\\mathrm{low}}, a_{\\mathrm{low}}, s)\\right],\n     $$\n     使用上面定义的 $q_{\\mathrm{low}}, q_{\\mathrm{high}}, a_{\\mathrm{low}}, a_{\\mathrm{high}}$，并返回一个布尔值，指示是否 $\\Delta_{\\mathrm{syn}}  0$。期望是针对 $s \\sim \\mathrm{Uniform}(0,1)$ 计算的。\n  6. 干燥边界情况预测：计算 $f(0.004\\,\\mathrm{kg/kg},\\,0.00\\,\\mathrm{Pa/s},\\,0.2)$ 并以 $\\mathrm{mm/day}$ 为单位的浮点数形式返回所得的降水强度。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序完全如下：\n$[$case1, case2, case3, case4\\_q, case4\\_a, case5, case6$]$。\n前五个条目必须是布尔值，最后一个条目必须是单位为 $\\mathrm{mm/day}$ 的浮点数，并以标准浮点表示法表示。",
            "solution": "本问题的解决方案涉及实现并分析一个用于统计降尺度的非线性模型，重点是使用部分依赖（PD）和 Shapley 值来解释其行为。我们将遵循一个结构化的方法，该方法从模型实现和数据采样开始，然后进行核心解释性计算，最后验证模型的行为是否符合物理预期。\n\n**步骤 1：模型和背景分布的实现**\n首先，我们实现问题中定义的非线性模型函数 $f(q, a, s)$。该函数使用 `softplus` 激活函数，这是一种平滑的、可微的 ReLU 近似。为了数值稳定性，$\\ln(1+e^z)$ 将使用 `numpy.logaddexp(0, z)` 等效实现。\n接下来，我们需要一个代表背景气候状态的大量蒙特卡洛样本集。我们将根据指定的截断正态分布为预报因子 $q$ 和 $a$ 生成样本（使用 `scipy.stats.truncnorm`），并根据均匀分布为 $s$ 生成样本。这个样本集将作为计算所有期望值的基准。\n\n**步骤 2：部分依赖（PD）和 Shapley 值的计算**\n为了计算部分依赖图和 Shapley 值，我们需要一个能够计算模型在固定某些特征值、并在其余特征上进行边缘化（即取期望）的函数。\n- **部分依赖 (PD)**：对于一个给定的特征（例如 $q$）和一个特定值（例如 $q_{\\text{low}}$），我们将计算 $\\mathrm{PD}_q(q_{\\text{low}}) = \\mathbb{E}[f(q_{\\text{low}}, A, S)]$，其中期望值是在背景样本集 $(A, S)$ 上取平均得到的。\n- **Shapley 值**：计算一个实例 $x=(q,a,s)$ 的 Shapley 值需要计算所有特征子集的“价值函数” $v(S;x) = \\mathbb{E}[f(x_S, X_{-S})]$。这包括基线期望 $\\mathbb{E}[f(Q,A,S)]$，以及固定一个或多个特征的期望。得到所有价值函数后，我们应用 Shapley 值公式来为每个特征分配其对预测的贡献 $\\phi_i(x)$。\n\n**步骤 3：评估测试用例**\n我们将系统地解决每个测试用例：\n1.  **单调性检查**：通过计算并比较在“低”和“高”值处的 PD 值，来验证模型对 $q$ 和 $a$ 的响应是否如物理预期的那样单调增加。\n2.  **Shapley 效率**：验证计算出的 Shapley 值之和是否等于模型的总“收益”（即 $f(x) - \\mathbb{E}[f(X)]$）。由于蒙特卡洛采样的数值误差，我们将检查这个差的绝对值是否小于一个小的容差 $\\tau$。\n3.  **符号一致性**：检查 $q$ 和 $a$ 的 Shapley 值是否为正，这与它们对降水有积极贡献的物理直觉是一致的。\n4.  **协同效应**：计算交互作用项，以验证模型是否正确地捕捉了水汽和上升运动之间的正协同效应。\n5.  **边界情况预测**：直接评估模型在无上升运动和低水汽条件下的输出，以检查其行为是否合理。\n\n通过执行这些步骤，我们可以不仅验证模型的数值输出，还可以深入理解其内部工作机制，并将其与降水物理学联系起来。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import truncnorm\n\ndef solve():\n    \"\"\"\n    Solves the statistical downscaling interpretation problem.\n    \"\"\"\n    # Use a fixed seed for reproducibility of Monte Carlo sampling.\n    np.random.seed(42)\n\n    # --- 1. Define Model and Parameters ---\n\n    # Model coefficients\n    BETA = {\n        '0': -2.0,\n        'q': 0.25,\n        'a': 1.2,\n        's': 0.5,\n        'int': 0.03,\n    }\n\n    def model_f(q, a, s):\n        \"\"\"\n        Computes the precipitation from the downscaling model.\n        Inputs q, a, s can be scalars or numpy arrays.\n        \"\"\"\n        # Scaled predictors\n        q_scaled = 1000.0 * q\n        a_scaled = 10.0 * a\n\n        # Linear combination in the argument of softplus\n        z = (BETA['0'] +\n             BETA['q'] * q_scaled +\n             BETA['a'] * a_scaled +\n             BETA['s'] * s +\n             BETA['int'] * q_scaled * a_scaled)\n\n        # Numerically stable softplus function: log(1 + exp(z))\n        return np.logaddexp(0, z)\n\n    # --- 2. Background Distribution and Sampling ---\n\n    # Number of Monte Carlo samples\n    N_SAMPLES = 500000\n\n    # Parameters for q distribution (truncated normal)\n    q_params = {'mu': 0.012, 'sigma': 0.003, 'min': 0.004, 'max': 0.020}\n    q_a_bound = (q_params['min'] - q_params['mu']) / q_params['sigma']\n    q_b_bound = (q_params['max'] - q_params['mu']) / q_params['sigma']\n    q_dist = truncnorm(a=q_a_bound, b=q_b_bound, loc=q_params['mu'], scale=q_params['sigma'])\n\n    # Parameters for a distribution (truncated normal)\n    a_params = {'mu': 0.05, 'sigma': 0.03, 'min': 0.0, 'max': 0.3}\n    a_a_bound = (a_params['min'] - a_params['mu']) / a_params['sigma']\n    a_b_bound = (a_params['max'] - a_params['mu']) / a_params['sigma']\n    a_dist = truncnorm(a=a_a_bound, b=a_b_bound, loc=a_params['mu'], scale=a_params['sigma'])\n\n    # Generate a single background sample set for all expectations\n    q_samples = q_dist.rvs(N_SAMPLES)\n    a_samples = a_dist.rvs(N_SAMPLES)\n    s_samples = np.random.uniform(0.0, 1.0, N_SAMPLES)\n\n    # --- 3. Expectation Helper Function ---\n\n    def compute_expectation(fixed_vars={}):\n        \"\"\"\n        Computes the expected value of the model f using Monte Carlo,\n        fixing a subset of variables.\n        \"\"\"\n        q_eval = fixed_vars.get('q', q_samples)\n        a_eval = fixed_vars.get('a', a_samples)\n        s_eval = fixed_vars.get('s', s_samples)\n        return np.mean(model_f(q_eval, a_eval, s_eval))\n\n    # --- 4. Evaluate Test Cases ---\n\n    results = []\n\n    # Case 1: Monotonicity of PD_q\n    q_low, q_high = 0.006, 0.016\n    pd_q_low = compute_expectation({'q': q_low})\n    pd_q_high = compute_expectation({'q': q_high})\n    results.append(pd_q_high > pd_q_low)\n\n    # Case 2: Monotonicity of PD_a\n    a_low, a_high = 0.02, 0.20\n    pd_a_low = compute_expectation({'a': a_low})\n    pd_a_high = compute_expectation({'a': a_high})\n    results.append(pd_a_high > pd_a_low)\n\n    # Case 3  4: Shapley Values and Efficiency\n    x1 = {'q': 0.016, 'a': 0.20, 's': 0.5}\n    tau = 0.05\n\n    # Compute all necessary value functions for Shapley calculation\n    v_empty = compute_expectation({}) # E[f(Q,A,S)]\n    v_q = compute_expectation({'q': x1['q']}) # E[f(q,A,S)]\n    v_a = compute_expectation({'a': x1['a']}) # E[f(Q,a,S)]\n    v_s = compute_expectation({'s': x1['s']}) # E[f(Q,A,s)]\n    v_qa = compute_expectation({'q': x1['q'], 'a': x1['a']}) # E[f(q,a,S)]\n    v_qs = compute_expectation({'q': x1['q'], 's': x1['s']}) # E[f(q,A,s)]\n    v_as = compute_expectation({'a': x1['a'], 's': x1['s']}) # E[f(Q,a,s)]\n    v_qas = model_f(x1['q'], x1['a'], x1['s']) # f(q,a,s)\n\n    # Calculate Shapley values for n=3\n    # Using the standard formula weights: 1/3, 1/6, 1/6, 1/3\n    phi_q = (1/3)*(v_q - v_empty) + (1/6)*(v_qa - v_a) + (1/6)*(v_qs - v_s)\n    phi_a = (1/3)*(v_a - v_empty) + (1/6)*(v_qa - v_q) + (1/6)*(v_as - v_s)\n    phi_s = (1/3)*(v_s - v_empty) + (1/6)*(v_qs - v_q) + (1/6)*(v_as - v_a)\n    \n    # The term for the grand coalition is (v_qas - v_as) for phi_q, etc.\n    # The combinatorial formula is sum_{S subset N\\{i}} w * (v(S u {i}) - v(S))\n    # For phi_q:\n    # S=empty: w=1/3, term = v_q - v_empty\n    # S={a}:   w=1/6, term = v_qa - v_a\n    # S={s}:   w=1/6, term = v_qs - v_s\n    # S={a,s}: w=1/3, term = v_qas - v_as\n    phi_q = (1/3)*(v_q - v_empty) + (1/6)*(v_qa - v_a) + (1/6)*(v_qs - v_s) + (1/3)*(v_qas - v_as)\n    phi_a = (1/3)*(v_a - v_empty) + (1/6)*(v_qa - v_q) + (1/6)*(v_as - v_s) + (1/3)*(v_qas - v_qs)\n    phi_s = (1/3)*(v_s - v_empty) + (1/6)*(v_qs - v_q) + (1/6)*(v_as - v_a) + (1/3)*(v_qas - v_qa)\n\n\n    # Case 3: Shapley efficiency check\n    shapley_sum = phi_q + phi_a + phi_s\n    model_payout = v_qas - v_empty\n    results.append(np.abs(model_payout - shapley_sum)  tau)\n\n    # Case 4: Sign consistency of Shapley values\n    results.append(phi_q > 0)\n    results.append(phi_a > 0)\n\n    # Case 5: Positive synergy between q and a\n    # Re-using background samples for s for this expectation\n    f_hh = model_f(q_high, a_high, s_samples)\n    f_hl = model_f(q_high, a_low, s_samples)\n    f_lh = model_f(q_low, a_high, s_samples)\n    f_ll = model_f(q_low, a_low, s_samples)\n    delta_syn = np.mean(f_hh - f_hl - f_lh + f_ll)\n    results.append(delta_syn > 0)\n    \n    # Case 6: Dryness edge case prediction\n    q_dry, a_dry, s_dry = 0.004, 0.00, 0.2\n    precip_dry = model_f(q_dry, a_dry, s_dry)\n    results.append(precip_dry)\n\n    # --- 5. Print Final Result ---\n    # The output format is a list of 7 items: 6 booleans and 1 float.\n    # [case1, case2, case3, case4_q, case4_a, case5, case6]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}