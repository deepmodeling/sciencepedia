{
    "hands_on_practices": [
        {
            "introduction": "A primary challenge for machine learning emulators in climate science is ensuring they respect fundamental physical laws, such as the conservation of energy. An emulator that fails to conserve energy can introduce spurious warming or cooling trends, leading to unrealistic long-term climate drifts. This exercise  provides a hands-on method for validating an emulator by checking its predictions against the first law of thermodynamics, comparing the emulated temperature tendencies to the heating rate derived from radiative flux convergence.",
            "id": "4061564",
            "problem": "Consider a single homogeneous atmospheric layer of thickness $\\Delta z$ used in Numerical Weather Prediction (NWP) and climate modeling. An emulation model from Machine Learning (ML) provides hourly layer-mean temperature tendencies that aim to reproduce the effect of radiative parameterization. To validate the emulator's units and sign conventions against energy conservation, use the first-principles dry-air energy equation and radiative flux convergence.\n\nAssume dry-air thermodynamics and energy conservation, where the layer-mean radiative heating rate $q_{\\mathrm{rad}}(t)$ satisfies\n$$\n\\rho c_p \\frac{dT}{dt} \\approx -\\frac{F_{\\mathrm{net}}(z_{\\mathrm{top}},t)-F_{\\mathrm{net}}(z_{\\mathrm{bot}},t)}{\\Delta z},\n$$\nwith $\\rho$ the air density, $c_p$ the specific heat at constant pressure, and $F_{\\mathrm{net}}(z,t)$ the net vertical radiative flux (positive upward). Over discrete hourly times $t_k=k\\,\\Delta t$, $k=0,1,\\dots,23$, take $\\Delta t=3600\\,\\mathrm{s}$, and\n- $\\rho=1.2\\,\\mathrm{kg}\\,\\mathrm{m}^{-3}$, $c_p=1004\\,\\mathrm{J}\\,\\mathrm{kg}^{-1}\\,\\mathrm{K}^{-1}$, $\\Delta z=1000\\,\\mathrm{m}$,\n- $F_{\\mathrm{net}}(z_{\\mathrm{top}},t_k)=F_{t0}-A\\sin\\left(\\frac{2\\pi k}{24}\\right)$ with $F_{t0}=0\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$ and $A=30\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$,\n- $F_{\\mathrm{net}}(z_{\\mathrm{bot}},t_k)=F_{b0}-B\\sin\\left(\\frac{2\\pi k}{24}\\right)$ with $F_{b0}=10\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$ and $B=45\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$.\n\nThe ML emulator supplies hourly layer-mean temperature tendencies in units of $\\mathrm{K}\\,\\mathrm{s}^{-1}$ given by\n$$\n\\hat{q}_k=\\alpha+\\beta\\sin\\left(\\frac{2\\pi k}{24}\\right),\\quad \\alpha=\\frac{1}{120{,}480}+\\frac{1}{2{,}000{,}000},\\quad \\beta=-\\frac{1}{80{,}320}.\n$$\n\nTasks:\n1. Using the fluxes above, compute the $24$-hour accumulated physical radiative heating\n$$\n\\Delta T_{\\mathrm{rad}}=\\sum_{k=0}^{23} q_{\\mathrm{rad}}(t_k)\\,\\Delta t,\n$$\nwhere $q_{\\mathrm{rad}}(t_k)=-\\dfrac{F_{\\mathrm{net}}(z_{\\mathrm{top}},t_k)-F_{\\mathrm{net}}(z_{\\mathrm{bot}},t_k)}{\\rho c_p \\Delta z}$.\n2. Compute the $24$-hour accumulated emulator heating\n$$\n\\Delta T_{\\mathrm{ML}}=\\sum_{k=0}^{23} \\hat{q}_k\\,\\Delta t.\n$$\n3. Compute the diagnostic mismatch\n$$\n\\Delta=\\Delta T_{\\mathrm{ML}}-\\Delta T_{\\mathrm{rad}},\n$$\nas a way to validate the emulator's units and sign convention against radiative flux convergence.\n\nExpress your final answer for $\\Delta$ in kelvins and round your answer to four significant figures.",
            "solution": "The objective is to compute the diagnostic mismatch $\\Delta = \\Delta T_{\\mathrm{ML}} - \\Delta T_{\\mathrm{rad}}$ between the $24$-hour accumulated heating from a Machine Learning (ML) emulator and the physical radiative heating derived from flux-divergence. This serves as a validation of the emulator's energy conservation properties. The calculation is performed in three steps as requested.\n\nThe physical constants and parameters are:\nAir density, $\\rho=1.2\\,\\mathrm{kg}\\,\\mathrm{m}^{-3}$.\nSpecific heat at constant pressure, $c_p=1004\\,\\mathrm{J}\\,\\mathrm{kg}^{-1}\\,\\mathrm{K}^{-1}$.\nLayer thickness, $\\Delta z=1000\\,\\mathrm{m}$.\nTime step, $\\Delta t=3600\\,\\mathrm{s}$.\nThe product $\\rho c_p \\Delta z$ represents the heat capacity of the atmospheric layer per unit area.\n$$\n\\rho c_p \\Delta z = (1.2\\,\\mathrm{kg}\\,\\mathrm{m}^{-3}) \\times (1004\\,\\mathrm{J}\\,\\mathrm{kg}^{-1}\\,\\mathrm{K}^{-1}) \\times (1000\\,\\mathrm{m}) = 1,204,800\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}.\n$$\n\nFirst, we compute the $24$-hour accumulated physical radiative heating, $\\Delta T_{\\mathrm{rad}}$.\nThe physical radiative heating rate at discrete time $t_k = k \\Delta t$ is given by\n$$\nq_{\\mathrm{rad}}(t_k)=-\\dfrac{F_{\\mathrm{net}}(z_{\\mathrm{top}},t_k)-F_{\\mathrm{net}}(z_{\\mathrm{bot}},t_k)}{\\rho c_p \\Delta z}.\n$$\nThe net flux difference between the top and bottom of the layer is\n$$\nF_{\\mathrm{net}}(z_{\\mathrm{top}},t_k)-F_{\\mathrm{net}}(z_{\\mathrm{bot}},t_k) = \\left(F_{t0}-A\\sin\\left(\\frac{2\\pi k}{24}\\right)\\right) - \\left(F_{b0}-B\\sin\\left(\\frac{2\\pi k}{24}\\right)\\right) = (F_{t0}-F_{b0})-(A-B)\\sin\\left(\\frac{2\\pi k}{24}\\right).\n$$\nSubstituting the given values $F_{t0}=0\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$, $F_{b0}=10\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$, $A=30\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$, and $B=45\\,\\mathrm{W}\\,\\mathrm{m}^{-2}$:\n$$\nF_{\\mathrm{net}}(z_{\\mathrm{top}},t_k)-F_{\\mathrm{net}}(z_{\\mathrm{bot}},t_k) = (0 - 10) - (30 - 45)\\sin\\left(\\frac{2\\pi k}{24}\\right) = -10 + 15\\sin\\left(\\frac{2\\pi k}{24}\\right)\\,\\mathrm{W}\\,\\mathrm{m}^{-2}.\n$$\nThe radiative heating rate is then\n$$\nq_{\\mathrm{rad}}(t_k) = -\\frac{-10 + 15\\sin\\left(\\frac{2\\pi k}{24}\\right)}{1,204,800} = \\frac{10}{1,204,800} - \\frac{15}{1,204,800}\\sin\\left(\\frac{2\\pi k}{24}\\right).\n$$\nSimplifying the coefficients, we get\n$$\nq_{\\mathrm{rad}}(t_k) = \\frac{1}{120,480} - \\frac{1}{80,320}\\sin\\left(\\frac{2\\pi k}{24}\\right)\\,\\mathrm{K}\\,\\mathrm{s}^{-1}.\n$$\nThe total accumulated heating over $24$ hours is the sum over $k$ from $0$ to $23$:\n$$\n\\Delta T_{\\mathrm{rad}}=\\sum_{k=0}^{23} q_{\\mathrm{rad}}(t_k)\\,\\Delta t = \\Delta t \\sum_{k=0}^{23} \\left[ \\frac{1}{120,480} - \\frac{1}{80,320}\\sin\\left(\\frac{2\\pi k}{24}\\right) \\right].\n$$\nThe sum of a sine function over a full discrete period is zero: $\\sum_{k=0}^{N-1} \\sin(2\\pi k/N) = 0$. In this case, $N=24$.\n$$\n\\sum_{k=0}^{23} \\sin\\left(\\frac{2\\pi k}{24}\\right) = 0.\n$$\nTherefore, the summation simplifies to\n$$\n\\Delta T_{\\mathrm{rad}} = \\Delta t \\sum_{k=0}^{23} \\frac{1}{120,480} = (3600\\,\\mathrm{s}) \\times 24 \\times \\frac{1}{120,480} = \\frac{86,400}{120,480}\\,\\mathrm{K} = \\frac{8,640}{12,048}\\,\\mathrm{K} = \\frac{180}{251}\\,\\mathrm{K}.\n$$\n\nSecond, we compute the $24$-hour accumulated emulator heating, $\\Delta T_{\\mathrm{ML}}$.\nThe ML emulator provides temperature tendencies as\n$$\n\\hat{q}_k=\\alpha+\\beta\\sin\\left(\\frac{2\\pi k}{24}\\right),\n$$\nwith $\\alpha=\\frac{1}{120,480}+\\frac{1}{2,000,000}$ and $\\beta=-\\frac{1}{80,320}$.\nThe total accumulated heating from the ML model is\n$$\n\\Delta T_{\\mathrm{ML}}=\\sum_{k=0}^{23} \\hat{q}_k\\,\\Delta t = \\Delta t \\sum_{k=0}^{23} \\left[ \\alpha+\\beta\\sin\\left(\\frac{2\\pi k}{24}\\right) \\right].\n$$\nAgain, the sum of the sine term is zero.\n$$\n\\Delta T_{\\mathrm{ML}} = \\Delta t \\sum_{k=0}^{23} \\alpha = (3600\\,\\mathrm{s}) \\times 24 \\times \\alpha = 86,400 \\alpha.\n$$\nSubstituting the value of $\\alpha$:\n$$\n\\Delta T_{\\mathrm{ML}} = 86,400 \\left( \\frac{1}{120,480}+\\frac{1}{2,000,000} \\right) = \\frac{86,400}{120,480} + \\frac{86,400}{2,000,000}.\n$$\nThe first term is identical to $\\Delta T_{\\mathrm{rad}}$:\n$$\n\\Delta T_{\\mathrm{ML}} = \\frac{180}{251} + \\frac{86,400}{2,000,000} = \\frac{180}{251} + 0.0432\\,\\mathrm{K}.\n$$\n\nThird, we compute the diagnostic mismatch, $\\Delta$.\n$$\n\\Delta = \\Delta T_{\\mathrm{ML}} - \\Delta T_{\\mathrm{rad}} = \\left( \\frac{180}{251} + 0.0432 \\right) - \\frac{180}{251} = 0.0432\\,\\mathrm{K}.\n$$\nThe problem specifies that the final answer should be rounded to four significant figures. The number $0.0432$ has three significant figures (the digits $4$, $3$, and $2$). To express it with four significant figures, we add a trailing zero.\n$$\n\\Delta = 0.04320\\,\\mathrm{K}.\n$$\nThis mismatch arises from the small constant bias in the ML emulator's mean heating rate, represented by the term $\\frac{1}{2,000,000}$ in $\\alpha$. The emulator correctly captured the phase and amplitude of the diurnal cycle of heating (since $\\beta$ matches the physical value of $-\\frac{1}{80,320}$), but slightly misses the $24$-hour mean heating. This type of diagnostic is crucial for ensuring that ML emulators do not introduce systematic energy drifts in long climate simulations.",
            "answer": "$$\\boxed{0.04320}$$"
        },
        {
            "introduction": "While perfect conservation is the goal, emulators often exhibit small residual errors. Rather than retraining a complex model, a common and effective strategy is to apply post-hoc corrections that enforce physical constraints. This practice  demonstrates how to design such a correction for column-integrated moist static energy, a key conserved variable. You will first diagnose the energy imbalance from a given emulator and then formulate a minimal, physically-consistent adjustment to its output to restore exact energy balance.",
            "id": "4061580",
            "problem": "A Machine Learning (ML) emulator is used to predict subgrid diabatic tendencies for temperature and specific humidity in a single atmospheric column within a Numerical Weather Prediction (NWP) model. The emulator outputs layer-wise tendencies $\\dot{T}_{i}$ and $\\dot{q}_{i}$ on a pressure discretization. The column-integrated moist static energy tendency must be consistent with the externally provided net diabatic energy flux convergence target $F_{\\mathrm{req}}$ to ensure column energy balance. Start from the moist static energy per unit mass $h = c_{p} T + L_{v} q + g z$, where $c_{p}$ is the specific heat of dry air at constant pressure, $L_{v}$ is the latent heat of vaporization, and $g$ is gravitational acceleration. Assume hydrostatic balance, neglecting changes in the gravitational potential term at fixed layer boundaries. The column-integrated moist static energy tendency is defined as the mass-weighted vertical integral\n$$\nE = \\frac{1}{g} \\int_{p_{\\mathrm{top}}}^{p_{\\mathrm{sfc}}} \\left( c_{p} \\,\\dot{T}(p) + L_{v} \\,\\dot{q}(p) \\right) \\, dp,\n$$\nand, under a layer-wise approximation with layer thicknesses $\\Delta p_{i}$, is discretized as\n$$\nE_{\\mathrm{emul}} = \\frac{1}{g} \\sum_{i=1}^{N} \\Delta p_{i} \\left( c_{p} \\,\\dot{T}_{i} + L_{v} \\,\\dot{q}_{i} \\right).\n$$\nYou are given a three-layer column ($N=3$) with the following data:\n- $g = 9.81\\,\\mathrm{m\\,s^{-2}}$, $c_{p} = 1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}$, $L_{v} = 2.5 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}$,\n- $\\Delta p_{1} = 25000\\,\\mathrm{Pa}$, $\\Delta p_{2} = 40000\\,\\mathrm{Pa}$, $\\Delta p_{3} = 35000\\,\\mathrm{Pa}$,\n- $\\dot{T}_{1} = 1.5 \\times 10^{-5}\\,\\mathrm{K\\,s^{-1}}$, $\\dot{T}_{2} = -8.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}$, $\\dot{T}_{3} = 3.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}$,\n- $\\dot{q}_{1} = 2.0 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$, $\\dot{q}_{2} = 0.5 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$, $\\dot{q}_{3} = -1.0 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$,\n- $F_{\\mathrm{req}} = 95\\,\\mathrm{W\\,m^{-2}}$, and tolerance $\\epsilon = 1\\,\\mathrm{W\\,m^{-2}}$.\n\n(a) Compute the emulator-predicted column-integrated moist static energy tendency $E_{\\mathrm{emul}}$ and the residual\n$$\nR = E_{\\mathrm{emul}} - F_{\\mathrm{req}}.\n$$\n(b) Formulate a physically consistent correction to the emulator tendencies that adjusts only the temperature tendencies by a uniform offset $\\delta \\dot{T}_{i} = \\alpha$ (constant in $i$) and leaves humidity tendencies unchanged ($\\delta \\dot{q}_{i} = 0$), such that the corrected column-integrated tendency satisfies the energy balance within the tolerance $\\epsilon$, i.e.,\n$$\n\\left| \\left( E_{\\mathrm{emul}} + \\frac{1}{g} \\sum_{i=1}^{N} \\Delta p_{i} c_{p} \\alpha \\right) - F_{\\mathrm{req}} \\right| \\le \\epsilon.\n$$\nAssuming the minimal correction that enforces exact balance whenever $|R| > \\epsilon$ and otherwise applies no correction, derive the expression for $\\alpha$ and evaluate its numerical value for the given data. Express the final $\\alpha$ in $\\mathrm{K\\,s^{-1}}$ and round your answer to four significant figures.",
            "solution": "The problem is divided into two parts. First, we compute the emulator-predicted column-integrated moist static energy tendency, $E_{\\mathrm{emul}}$, and its residual, $R$, with respect to the required energy flux convergence, $F_{\\mathrm{req}}$. Second, we derive and compute a uniform correction, $\\alpha$, to the temperature tendencies to enforce energy balance.\n\n**Part (a): Computation of $E_{\\mathrm{emul}}$ and $R$.**\n\nThe column-integrated moist static energy tendency predicted by the emulator, $E_{\\mathrm{emul}}$, is given by the discretized formula:\n$$\nE_{\\mathrm{emul}} = \\frac{1}{g} \\sum_{i=1}^{N} \\Delta p_{i} \\left( c_{p} \\,\\dot{T}_{i} + L_{v} \\,\\dot{q}_{i} \\right)\n$$\nWe are given $N=3$ layers and the following constants and data:\n- $g = 9.81\\,\\mathrm{m\\,s^{-2}}$\n- $c_{p} = 1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}$\n- $L_{v} = 2.5 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}$\n- Layer $1$: $\\Delta p_{1} = 25000\\,\\mathrm{Pa}$, $\\dot{T}_{1} = 1.5 \\times 10^{-5}\\,\\mathrm{K\\,s^{-1}}$, $\\dot{q}_{1} = 2.0 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$\n- Layer $2$: $\\Delta p_{2} = 40000\\,\\mathrm{Pa}$, $\\dot{T}_{2} = -8.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}$, $\\dot{q}_{2} = 0.5 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$\n- Layer $3$: $\\Delta p_{3} = 35000\\,\\mathrm{Pa}$, $\\dot{T}_{3} = 3.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}$, $\\dot{q}_{3} = -1.0 \\times 10^{-8}\\,\\mathrm{kg\\,kg^{-1}\\,s^{-1}}$\n\nLet's compute the term $h_{i}^{\\prime} = c_{p} \\,\\dot{T}_{i} + L_{v} \\,\\dot{q}_{i}$ for each layer $i$:\nFor layer $1$:\n$h_{1}^{\\prime} = (1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}) (1.5 \\times 10^{-5}\\,\\mathrm{K\\,s^{-1}}) + (2.5 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}) (2.0 \\times 10^{-8}\\,\\mathrm{s^{-1}})$\n$h_{1}^{\\prime} = 0.01506\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} + 0.05\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} = 0.06506\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}}$\n\nFor layer $2$:\n$h_{2}^{\\prime} = (1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}) (-8.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}) + (2.5 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}) (0.5 \\times 10^{-8}\\,\\mathrm{s^{-1}})$\n$h_{2}^{\\prime} = -0.008032\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} + 0.0125\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} = 0.004468\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}}$\n\nFor layer $3$:\n$h_{3}^{\\prime} = (1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}) (3.0 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}) + (2.5 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}) (-1.0 \\times 10^{-8}\\,\\mathrm{s^{-1}})$\n$h_{3}^{\\prime} = 0.003012\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} - 0.025\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}} = -0.021988\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}}$\n\nNow, we compute the sum $\\sum_{i=1}^{3} \\Delta p_{i} h_{i}^{\\prime}$:\n$\\sum_{i=1}^{3} \\Delta p_{i} h_{i}^{\\prime} = (25000\\,\\mathrm{Pa})(0.06506\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}}) + (40000\\,\\mathrm{Pa})(0.004468\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}}) + (35000\\,\\mathrm{Pa})(-0.021988\\,\\mathrm{J\\,kg^{-1}\\,s^{-1}})$\n$\\sum_{i=1}^{3} \\Delta p_{i} h_{i}^{\\prime} = 1626.5 + 178.72 - 769.58 = 1035.64\\,\\mathrm{Pa \\cdot J \\cdot kg^{-1} \\cdot s^{-1}}$.\n\nNow, we calculate $E_{\\mathrm{emul}}$ (units of $\\mathrm{W\\,m^{-2}}$):\n$$\nE_{\\mathrm{emul}} = \\frac{1035.64}{9.81} \\approx 105.57003\\,\\mathrm{W\\,m^{-2}}\n$$\nThe residual $R$ is defined as $R = E_{\\mathrm{emul}} - F_{\\mathrm{req}}$. Given $F_{\\mathrm{req}} = 95\\,\\mathrm{W\\,m^{-2}}$:\n$$\nR = 105.57003\\,\\mathrm{W\\,m^{-2}} - 95\\,\\mathrm{W\\,m^{-2}} = 10.57003\\,\\mathrm{W\\,m^{-2}}\n$$\n\n**Part (b): Derivation and computation of the correction $\\alpha$.**\n\nA correction is to be applied to the temperature tendencies only, such that $\\delta \\dot{T}_{i} = \\alpha$ for all layers $i$, and $\\delta \\dot{q}_{i} = 0$. The corrected emulator tendency, $E_{\\mathrm{corr}}$, is then:\n$$\nE_{\\mathrm{corr}} = \\frac{1}{g} \\sum_{i=1}^{N} \\Delta p_{i} \\left( c_{p} (\\dot{T}_{i} + \\alpha) + L_{v} \\dot{q}_{i} \\right)\n$$\nWe can separate this into the original tendency and the correction term:\n$$\nE_{\\mathrm{corr}} = E_{\\mathrm{emul}} + \\frac{c_{p} \\alpha}{g} \\sum_{i=1}^{N} \\Delta p_{i}\n$$\nLet $\\Delta p_{\\mathrm{tot}} = \\sum_{i=1}^{N} \\Delta p_{i} = 25000 + 40000 + 35000 = 100000\\,\\mathrm{Pa}$.\nThe corrected tendency is:\n$$\nE_{\\mathrm{corr}} = E_{\\mathrm{emul}} + \\alpha \\frac{c_{p} \\Delta p_{\\mathrm{tot}}}{g}\n$$\nA correction is applied only if $|R| > \\epsilon$. We have $|R| \\approx 10.57\\,\\mathrm{W\\,m^{-2}}$ and $\\epsilon = 1\\,\\mathrm{W\\,m^{-2}}$. Since $|R| > \\epsilon$, a correction is necessary. The minimal correction is one that achieves exact energy balance: $E_{\\mathrm{corr}} = F_{\\mathrm{req}}$.\n$$\nF_{\\mathrm{req}} = E_{\\mathrm{emul}} + \\alpha \\frac{c_{p} \\Delta p_{\\mathrm{tot}}}{g}\n$$\nWe solve for $\\alpha$:\n$$\n\\alpha \\frac{c_{p} \\Delta p_{\\mathrm{tot}}}{g} = F_{\\mathrm{req}} - E_{\\mathrm{emul}} = -R\n$$\n$$\n\\alpha = -R \\left( \\frac{g}{c_{p} \\Delta p_{\\mathrm{tot}}} \\right)\n$$\nNow we insert the numerical values:\n$$\n\\alpha = -(10.57003\\,\\mathrm{W\\,m^{-2}}) \\left( \\frac{9.81\\,\\mathrm{m\\,s^{-2}}}{(1004\\,\\mathrm{J\\,kg^{-1}\\,K^{-1}}) (100000\\,\\mathrm{Pa})} \\right)\n$$\n$$\n\\alpha = -10.57003 \\left( \\frac{9.81}{100400000} \\right) \\mathrm{K\\,s^{-1}}\n$$\n$$\n\\alpha \\approx -10.57003 \\times (9.770916 \\times 10^{-8}) \\mathrm{K\\,s^{-1}}\n$$\n$$\n\\alpha \\approx -1.03287 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}\n$$\nRounding the result to four significant figures as requested:\n$$\n\\alpha \\approx -1.033 \\times 10^{-6}\\,\\mathrm{K\\,s^{-1}}\n$$\nThis corresponds to a small, uniform cooling applied to all layers to offset the excess energy generated by the emulator.",
            "answer": "$$\n\\boxed{-1.033 \\times 10^{-6}}\n$$"
        },
        {
            "introduction": "Physical accuracy and conservation are necessary but not sufficient for an emulator's success; it must also be computationally feasible for operational deployment. Weather and climate models run on tight time budgets, making computational cost a critical design constraint. This practice  explores this trade-off by comparing the performance of a simple Multi-Layer Perceptron (MLP) against a more sophisticated Fourier Neural Operator (FNO). You will estimate the parameter counts and floating-point operations (FLOPs) for each model to assess their viability within a realistic high-performance computing budget.",
            "id": "4061530",
            "problem": "A national weather center considers replacing a column physics parameterization with a Machine Learning emulator. Two candidate architectures are proposed: a Multi-Layer Perceptron (MLP) and a one-dimensional Fourier Neural Operator (FNO). The model is run on a horizontally discretized domain with $N_x = 1024$ and $N_y = 1024$, yielding $N_{\\text{col}} = N_x N_y$ independent vertical columns. The vertical grid has $N_z = 72$ levels. Each column provides $F_{\\text{in}} = 10$ input features per level and requires $F_{\\text{out}} = 6$ output features per level.\n\nThe operational constraint allocates a sustained performance budget of $P_{\\text{avail}} = 1.0 \\times 10^{15}$ floating-point operations per second (FLOPS) for physics emulation, with a per-call time budget of $B = 0.2$ seconds. Assume the following widely used operation counting approximations:\n- A fully connected layer mapping $\\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ costs approximately $2 n m + m$ floating-point operations (FLOPs) per application (the $+m$ accounts for biases), and nonlinear activation costs are negligible compared to matrix multiplies.\n- A complex Fast Fourier Transform (FFT) of length $n$ requires approximately $5 n \\log_{2}(n)$ FLOPs, and an inverse FFT has the same cost.\n- A complex dot product of length $C$ requires approximately $6 C$ FLOPs for complex multiplications and $2 (C - 1)$ FLOPs for complex additions; for counting simplicity, use $8 C$ FLOPs per output when forming a complex weighted sum over $C$ inputs.\n- Spectral convolution in the FNO uses $K$ complex modes and mixes $C$ input channels to $C$ output channels per mode via complex weighted sums.\n\nArchitectures:\n1. The Multi-Layer Perceptron (MLP) operates identically and independently at each vertical level with shared weights across levels. It has two hidden layers of width $64$ and a final linear layer to $F_{\\text{out}}$. Thus, for each level, the layer sizes are $F_{\\text{in}} = 10 \\to 64 \\to 64 \\to F_{\\text{out}} = 6$.\n2. The one-dimensional Fourier Neural Operator (FNO) acts along the vertical dimension. It consists of:\n   - A pointwise lift linear layer at each level mapping $F_{\\text{in}}$ to $C = 32$ channels.\n   - $L = 3$ Fourier layers. Each layer performs: a forward FFT along the vertical for each of the $C$ channels; a spectral convolution using $K = 16$ complex modes, mixing $C$ inputs to $C$ outputs per mode by complex weighted sums; an inverse FFT for each channel; and a pointwise linear mixing from $C$ to $C$ per level.\n   - A final pointwise projection linear layer at each level mapping $C$ channels to $F_{\\text{out}}$.\n\nTasks:\n- Derive and compute the total parameter counts for the MLP and the FNO given the above specifications.\n- Derive and compute the per-column forward-pass FLOPs for the MLP and the FNO.\n- Compute the total FLOPs per emulator call over the full horizontal domain for each architecture by multiplying the per-column costs by $N_{\\text{col}}$.\n- Let the available FLOPs per call be $P_{\\text{avail}} B$. Define the feasibility fractions $r_{\\text{FNO}} = \\frac{\\text{FLOPs}_{\\text{FNO, total}}}{P_{\\text{avail}} B}$ and $r_{\\text{MLP}} = \\frac{\\text{FLOPs}_{\\text{MLP, total}}}{P_{\\text{avail}} B}$. Compute these two fractions.\n\nRound your final numerical answers for $(r_{\\text{FNO}}, r_{\\text{MLP}})$ to three significant figures and express them as dimensionless decimals. Provide the final pair as a row matrix.",
            "solution": "The analysis is performed in four stages as requested: parameter counts, per-column FLOPs, total FLOPs, and feasibility fractions.\n\n**1. Parameter Counts**\n\nThe number of trainable parameters ($\\Theta$) is calculated for each architecture.\n\n**Multi-Layer Perceptron (MLP):**\nThe MLP operates per-level with shared weights. We count the parameters for a single per-level network.\n- Layer 1 ($10 \\to 64$): $\\Theta_1 = 10 \\times 64 + 64 = 704$.\n- Layer 2 ($64 \\to 64$): $\\Theta_2 = 64 \\times 64 + 64 = 4160$.\n- Layer 3 ($64 \\to 6$): $\\Theta_3 = 64 \\times 6 + 6 = 390$.\nTotal MLP parameters:\n$$ \\Theta_{\\text{MLP}} = 704 + 4160 + 390 = 5254 $$\n\n**Fourier Neural Operator (FNO):**\n- Lift Layer (pointwise $10 \\to 32$): $\\Theta_{\\text{lift}} = 10 \\times 32 + 32 = 352$.\n- Fourier Layers ($L=3$ layers):\n  - Spectral Convolution (per layer): Weights for $K=16$ modes mapping $C=32$ channels to $C=32$ channels. $2 \\times K \\times C \\times C = 2 \\times 16 \\times 32^2 = 32768$.\n  - Pointwise Linear Layer (per layer, $32 \\to 32$): $32 \\times 32 + 32 = 1056$.\n  Total for $L=3$ layers: $\\Theta_{\\text{fourier\\_layers}} = 3 \\times (32768 + 1056) = 101472$.\n- Projection Layer (pointwise $32 \\to 6$): $\\Theta_{\\text{proj}} = 32 \\times 6 + 6 = 198$.\nTotal FNO parameters:\n$$ \\Theta_{\\text{FNO}} = 352 + 101472 + 198 = 102022 $$\n\n**2. Per-Column Forward-Pass FLOPs**\n\n**MLP FLOPs per Column:**\nThe per-level MLP is applied at each of the $N_z=72$ levels.\n- FLOPs per level:\n  - Layer 1 ($10 \\to 64$): $2 \\times 10 \\times 64 + 64 = 1344$.\n  - Layer 2 ($64 \\to 64$): $2 \\times 64 \\times 64 + 64 = 8256$.\n  - Layer 3 ($64 \\to 6$): $2 \\times 64 \\times 6 + 6 = 774$.\n  Total per level: $1344 + 8256 + 774 = 10374$.\nTotal FLOPs per column:\n$$ \\text{FLOPs}_{\\text{MLP, col}} = N_z \\times 10374 = 72 \\times 10374 = 746928 $$\n\n**FNO FLOPs per Column:**\n- Lift Layer (pointwise $10 \\to 32$): $F_{\\text{lift}} = N_z \\times (2 \\times 10 \\times 32 + 32) = 72 \\times 672 = 48384$.\n- Fourier Layers ($L=3$ layers):\n  - FFT/IFFT (per layer): $2 \\times C \\times (5 N_z \\log_2(N_z)) = 2 \\times 32 \\times (5 \\times 72 \\times \\log_2(72)) = 23040 \\log_2(72)$.\n  - Spectral Convolution (per layer): $K \\times C \\times (8C) = 8 K C^2 = 8 \\times 16 \\times 32^2 = 131072$.\n  - Pointwise Linear Layer (per layer, $32 \\to 32$): $N_z \\times (2 C^2 + C) = 72 \\times (2 \\times 32^2 + 32) = 149760$.\n  Total for $L=3$ layers: $F_{\\text{fourier\\_layers}} = 3 \\times (23040 \\log_2(72) + 131072 + 149760) = 69120 \\log_2(72) + 842496$.\n- Projection Layer (pointwise $32 \\to 6$): $F_{\\text{proj}} = N_z \\times (2 \\times 32 \\times 6 + 6) = 72 \\times 390 = 28080$.\nTotal FLOPs per column (using $\\log_2(72) \\approx 6.1699$):\n$$ \\text{FLOPs}_{\\text{FNO, col}} = 48384 + (69120 \\times 6.1699 + 842496) + 28080 \\approx 918960 + 426521 \\approx 1345481 $$\n\n**3. Total FLOPs Per Emulator Call**\n\nNumber of columns $N_{\\text{col}} = 1024 \\times 1024 = 1048576$.\n- Total MLP FLOPs:\n$$ \\text{FLOPs}_{\\text{MLP, total}} = N_{\\text{col}} \\times \\text{FLOPs}_{\\text{MLP, col}} = 1048576 \\times 746928 \\approx 7.832 \\times 10^{11} $$\n- Total FNO FLOPs:\n$$ \\text{FLOPs}_{\\text{FNO, total}} = N_{\\text{col}} \\times \\text{FLOPs}_{\\text{FNO, col}} = 1048576 \\times 1345481 \\approx 1.411 \\times 10^{12} $$\n\n**4. Feasibility Fractions**\nAvailable FLOPs per call:\n$$ \\text{FLOPs}_{\\text{avail}} = P_{\\text{avail}} \\times B = (1.0 \\times 10^{15}) \\times (0.2) = 2.0 \\times 10^{14} \\text{ FLOPs} $$\n- MLP feasibility fraction:\n$$ r_{\\text{MLP}} = \\frac{7.832 \\times 10^{11}}{2.0 \\times 10^{14}} \\approx 0.003916 \\approx 0.00392 $$\n- FNO feasibility fraction:\n$$ r_{\\text{FNO}} = \\frac{1.411 \\times 10^{12}}{2.0 \\times 10^{14}} \\approx 0.007055 \\approx 0.00705 $$\n\nThe final feasibility fractions are $(r_{\\text{FNO}}, r_{\\text{MLP}}) = (0.00705, 0.00392)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.00705 & 0.00392\n\\end{pmatrix}\n}\n$$"
        }
    ]
}