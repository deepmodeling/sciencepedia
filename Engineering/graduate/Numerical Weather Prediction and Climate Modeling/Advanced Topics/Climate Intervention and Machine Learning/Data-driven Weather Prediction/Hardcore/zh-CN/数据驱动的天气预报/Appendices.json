{
    "hands_on_practices": [
        {
            "introduction": "第一个练习深入探讨了数据同化的基本原理。通过从第一性原理出发，推导一个简单标量情况下的解，您将清晰地理解预报（先验）和观测如何被最优地结合以产生分析（后验）。这构成了运用于业务化天气预报的更复杂数据同化系统的理论基石。",
            "id": "4030133",
            "problem": "考虑一个数值天气预报（NWP）系统中的一维数据同化步骤，针对由 $x$ 表示的单个格点的标量大气状态。关于 $x$ 的背景（先验）信息被建模为高斯随机变量 $x_b \\sim \\mathcal{N}(\\mu_b,\\sigma_b^2)$，其中 $x_b$ 代表背景预报，$\\mu_b$ 是其均值，$\\sigma_b^2$ 是其误差方差。通过线性测量模型 $y = x + \\epsilon$ 可获得一个对同一状态的同位观测值 $y$，其中观测误差 $\\epsilon$ 是高斯分布的，即 $\\epsilon \\sim \\mathcal{N}(0,\\sigma_o^2)$，并且与背景误差无关。假设所有分布和参数都已正确指定，并且 $x$ 是待推断的潜在真实状态。\n\n仅从 Bayes 定理以及高斯先验和高斯似然的定义出发，推导后验分布 $p(x \\mid y)$，并明确地求出后验均值 $\\mu_a$ 和后验方差 $\\sigma_a^2$ 的闭式表达式。将后验均值表示为背景均值和观测值的凸组合形式 $\\mu_a = w_b \\mu_b + w_o y$，并给出权重 $w_b$ 和 $w_o$ 关于 $\\sigma_b^2$ 和 $\\sigma_o^2$ 的解析表达式。将 $\\mu_a$、$\\sigma_a^2$、$w_b$ 和 $w_o$ 的最终答案表述为 $\\mu_b$、$y$、$\\sigma_b^2$ 和 $\\sigma_o^2$ 的显式函数。不需要进行数值计算，也无需四舍五入。最终答案必须以单行向量的形式给出，按顺序包含 $\\mu_a$、$\\sigma_a^2$、$w_b$ 和 $w_o$。",
            "solution": "该问题提出了一个在数据同化背景下的标准 Bayes 推断任务，在标量情况下通常被称为最优插值。该问题具有科学依据，数学上适定，信息完全，且客观。这是一个有效的问题。\n\n题目要求我们推导在给定观测值 $y$ 的情况下，状态 $x$ 的后验分布 $p(x | y)$。推导从 Bayes 定理开始：\n$$\np(x \\mid y) = \\frac{p(y \\mid x) p(x)}{p(y)}\n$$\n项 $p(y)$ 是一个不依赖于 $x$ 的归一化常数。因此，我们可以使用正比关系：\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x)\n$$\n\n首先，我们定义先验分布 $p(x)$。问题陈述，关于 $x$ 的背景信息被建模为均值为 $\\mu_b$、方差为 $\\sigma_b^2$ 的高斯随机变量。因此，真实状态 $x$ 的先验分布为：\n$$\np(x) = \\mathcal{N}(x \\mid \\mu_b, \\sigma_b^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_b^2}} \\exp\\left( -\\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right)\n$$\n\n接下来，我们定义似然函数 $p(y \\mid x)$。观测模型由 $y = x + \\epsilon$ 给出，其中观测误差 $\\epsilon$ 是一个均值为零、方差为 $\\sigma_o^2$ 的高斯随机变量，即 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_o^2)$。这意味着在给定真实状态 $x$ 的情况下，观测值 $y$ 是一个均值为 $x$、方差为 $\\sigma_o^2$ 的高斯随机变量。因此，似然函数为：\n$$\np(y \\mid x) = \\mathcal{N}(y \\mid x, \\sigma_o^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_o^2}} \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} \\right)\n$$\n\n现在，我们将这些表达式代入后验分布的正比关系中：\n$$\np(x \\mid y) \\propto \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma_o^2}} \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} \\right) \\right] \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma_b^2}} \\exp\\left( -\\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right) \\right]\n$$\n忽略常数乘法项，后验分布正比于指数项：\n$$\np(x \\mid y) \\propto \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} - \\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right)\n$$\n两个高斯分布（或其概率密度函数 PDF）的乘积结果是另一个高斯分布。我们知道后验分布 $p(x \\mid y)$ 将是一个高斯分布，我们将其表示为 $\\mathcal{N}(x \\mid \\mu_a, \\sigma_a^2)$，其形式为：\n$$\np(x \\mid y) \\propto \\exp\\left( -\\frac{(x - \\mu_a)^2}{2\\sigma_a^2} \\right)\n$$\n为了求出后验均值 $\\mu_a$ 和方差 $\\sigma_a^2$，我们必须处理我们推导出的后验分布的指数部分，使其与标准高斯形式匹配。这可以通过对 $x$ 使用配方法来实现。我们来分析指数部分，记为 $E(x)$：\n$$\nE(x) = -\\frac{(y - x)^2}{2\\sigma_o^2} - \\frac{(x - \\mu_b)^2}{2\\sigma_b^2}\n$$\n我们展开括号内的二次项：\n$$\nE(x) = -\\frac{1}{2}\\left( \\frac{y^2 - 2yx + x^2}{\\sigma_o^2} + \\frac{x^2 - 2x\\mu_b + \\mu_b^2}{\\sigma_b^2} \\right)\n$$\n我们根据 $x$ 的幂次合并各项：\n$$\nE(x) = -\\frac{1}{2}\\left[ x^2 \\left(\\frac{1}{\\sigma_o^2} + \\frac{1}{\\sigma_b^2}\\right) - 2x \\left(\\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2}\\right) + \\left(\\frac{y^2}{\\sigma_o^2} + \\frac{\\mu_b^2}{\\sigma_b^2}\\right) \\right]\n$$\n高斯分布 $\\mathcal{N}(x \\mid \\mu_a, \\sigma_a^2)$ 的指数部分的一般形式为：\n$$\n-\\frac{(x - \\mu_a)^2}{2\\sigma_a^2} = -\\frac{1}{2\\sigma_a^2}(x^2 - 2x\\mu_a + \\mu_a^2) = -\\frac{1}{2}\\left[ x^2\\left(\\frac{1}{\\sigma_a^2}\\right) - 2x\\left(\\frac{\\mu_a}{\\sigma_a^2}\\right) + \\frac{\\mu_a^2}{\\sigma_a^2} \\right]\n$$\n通过比较 $E(x)$ 中 $x^2$ 项的系数与一般形式，我们可以确定后验方差 $\\sigma_a^2$ 的倒数：\n$$\n\\frac{1}{\\sigma_a^2} = \\frac{1}{\\sigma_o^2} + \\frac{1}{\\sigma_b^2} = \\frac{\\sigma_b^2 + \\sigma_o^2}{\\sigma_o^2 \\sigma_b^2}\n$$\n求解 $\\sigma_a^2$ 得到后验方差：\n$$\n\\sigma_a^2 = \\left( \\frac{\\sigma_b^2 + \\sigma_o^2}{\\sigma_o^2 \\sigma_b^2} \\right)^{-1} = \\frac{\\sigma_o^2 \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n接下来，通过比较线性项 $x$ 的系数，我们发现：\n$$\n\\frac{\\mu_a}{\\sigma_a^2} = \\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2}\n$$\n求解后验均值 $\\mu_a$：\n$$\n\\mu_a = \\sigma_a^2 \\left( \\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2} \\right)\n$$\n代入我们关于 $\\sigma_a^2$ 的表达式：\n$$\n\\mu_a = \\left( \\frac{\\sigma_o^2 \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} \\right) \\left( \\frac{y\\sigma_b^2 + \\mu_b\\sigma_o^2}{\\sigma_o^2 \\sigma_b^2} \\right)\n$$\n项 $(\\sigma_o^2 \\sigma_b^2)$ 消去，得到：\n$$\n\\mu_a = \\frac{y\\sigma_b^2 + \\mu_b\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n问题要求将后验均值表示为凸组合 $\\mu_a = w_b \\mu_b + w_o y$。我们可以重新整理我们关于 $\\mu_a$ 的表达式以匹配此形式：\n$$\n\\mu_a = \\left( \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2} \\right) \\mu_b + \\left( \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} \\right) y\n$$\n通过与 $\\mu_a = w_b \\mu_b + w_o y$ 直接比较，我们确定权重 $w_b$ 和 $w_o$：\n$$\nw_b = \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n$$\nw_o = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n权重之和为 $w_b + w_o = \\frac{\\sigma_o^2 + \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} = 1$。由于方差是非负的，权重也是非负的，这证实了这是一个真凸组合。\n\n最终所需的表达式为：\n1.  后验均值 $\\mu_a = \\frac{\\mu_b \\sigma_o^2 + y \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}$\n2.  后验方差 $\\sigma_a^2 = \\frac{\\sigma_b^2 \\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}$\n3.  背景均值的权重 $w_b = \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}$\n4.  观测值的权重 $w_o = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}$\n\n这些是所要求的解析形式。",
            "answer": "$$\n\\boxed{\n\\left( \\frac{\\mu_b \\sigma_o^2 + y \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}, \\quad \\frac{\\sigma_b^2 \\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}, \\quad \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}, \\quad \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} \\right)\n}\n$$"
        },
        {
            "introduction": "在基础理论之上，本实践将问题从静态转向动态，通过卡尔曼滤波器模拟一个完整的数据同化循环。您将实现预报-更新循环，并批判性地检验模型误差协方差设置不当所带来的影响，这是现实世界应用中一个常见且关键的挑战。这个编程练习将揭示关于模型不确定性的不正确假设如何导致预报漂移和性能下降。",
            "id": "4030151",
            "problem": "考虑一个一维线性高斯状态空间模型，该模型用作数值天气预报（NWP）中数据同化（DA）的简化构建模块。物理量被抽象为无量纲标量。真实状态根据稳定或近乎稳定的自回归动态演化，观测是状态的直接带噪测量。您将使用卡尔曼滤波器（KF）实现一个分析循环，其中模型误差协方差可能被错误指定。您的任务是计算每个循环的分析增量，并在模型误差协方差被错误指定时，量化预报误差随时间的漂移。\n\n使用的基本原理：\n- 线性状态空间模型、高斯加性误差，以及线性高斯情况下的贝叶斯滤波。\n- 状态演化方程为 $x_{k+1} = a\\,x_k + w_k$，其中 $w_k$ 是均值为零、方差为 $Q_{\\text{true}}$ 的高斯模型误差。\n- 在循环 $k$ 的观测为 $y_k = x_k + v_k$，其中 $v_k$ 是均值为零、方差为 $R$ 的高斯观测误差。\n- 卡尔曼滤波器（KF）分析循环包括预测（预报）和更新（分析）步骤，这些步骤源自线性高斯贝叶斯框架和高斯-马尔可夫定理，不依赖于快捷公式。\n\n定义和待计算的量：\n- 预报均值 $x_f(k)$ 和预报方差 $P_f(k)$，通过将前一分析结果通过模型（使用 $(a)$ 和假定的模型误差方差 $Q_{\\text{assumed}}$）传播得到。\n- 分析均值 $x_a(k)$ 和分析方差 $P_a(k)$，通过在线性高斯更新规则下，结合预报和当前观测 $y_k$ 得到，该规则从第一性原理推导。\n- 在循环 $k$ 的分析增量：$\\Delta(k) = x_a(k) - x_f(k)$。\n- 在循环 $k$ 的预报误差：$e_f(k) = x_f(k) - x_{\\text{true}}(k)$。\n- 漂移度量：序列 $\\{e_f(k)\\}_{k=1}^N$ 相对于循环指数 $k$ 的最小二乘线性趋势（斜率）$s$，其中 $N$ 是总循环次数。也就是说，以最小二乘法拟合 $e_f(k) \\approx s\\,k + b$ 并报告 $s$。\n\n所有量都是无量纲的。不使用角度。不使用百分比。您必须将漂移度量 $s$ 和平均绝对分析增量 $\\overline{|\\Delta|}$ 表示为十进制浮点数。\n\n初始化：\n- 初始真实状态为 $x_{\\text{true}}(0) = x_0$。\n- 初始分析均值为 $x_a(0) = x_0$。\n- 初始分析方差为 $P_a(0) = P_0$。\n\n每个时间步 $k = 1,\\dots,N$ 的仿真和分析循环：\n- 使用 $x_{\\text{true}}(k) = a\\,x_{\\text{true}}(k-1) + w_k$推进真实状态，其中 $w_k$ 从一个均值为零、方差为 $Q_{\\text{true}}$ 的高斯分布中抽取。\n- 生成观测 $y_k = x_{\\text{true}}(k) + v_k$，其中 $v_k$ 从一个均值为零、方差为 $R$ 的高斯分布中抽取。\n- 使用步骤 $k-1$ 的分析结果和假定的模型误差方差 $Q_{\\text{assumed}}$ 计算预报均值 $x_f(k)$ 和预报方差 $P_f(k)$。\n- 使用带有观测 $y_k$ 的线性高斯贝叶斯更新计算分析均值 $x_a(k)$ 和分析方差 $P_a(k)$。不要依赖快捷公式；从第一性原理（高斯-马尔可夫定理所蕴含的新息和最小二乘加权）推导更新过程。\n- 计算分析增量 $\\Delta(k) = x_a(k) - x_f(k)$ 和预报误差 $e_f(k) = x_f(k) - x_{\\text{true}}(k)$。\n\n每个测试用例要报告的输出：\n- 平均绝对分析增量 $\\overline{|\\Delta|} = \\frac{1}{N}\\sum_{k=1}^{N} |\\Delta(k)|$。\n- 漂移度量 $s$（$e_f(k)$ 相对于 $k$ 的最小二乘拟合斜率），以每个循环的状态单位表示。\n\n提供以下具有固定随机种子的测试套件以保证可复现性：\n- 测试用例 1（理想情况，正确指定的 $Q$）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.04$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 2（欠分散的预报模型）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.0$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 3（过分散的预报模型）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.2$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 4（近乎不稳定的动态）：$a = 1.05$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.04$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 456$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号内以逗号分隔的列表，每个测试用例的结果是一个双元素列表 $[\\overline{|\\Delta|}, s]$。\n- 每个浮点数必须四舍五入到 $6$ 位小数。\n- 例如，输出应如下所示：$[[0.123456,-0.000789],[\\dots,\\dots],[\\dots,\\dots],[\\dots,\\dots]]$。",
            "solution": "该问题要求实现一个一维卡尔曼滤波器（KF）来执行数据同化分析循环。我们必须模拟一个真实状态，生成带噪观测，然后应用KF来估计该状态。一个关键方面是分析当滤波器使用的模型误差协方差 $Q_{\\text{assumed}}$ 与真实值 $Q_{\\text{true}}$ 不同时，滤波器的性能。要求的输出是平均绝对分析增量和预报误差的漂移度量。\n\n正如题目所规定，解决方案是根据第一性原理开发的。对于线性高斯状态空间系统，卡尔曼滤波器是最优线性估计器，其方程可以直接从贝叶斯原理推导得出。\n\n**1. 状态空间模型**\n\n该系统由一个线性状态空间模型定义：\n- **状态方程（过程模型）：** 在循环 $k$ 的真实状态 $x_{\\text{true}}(k)$ 根据带加性高斯噪声的一阶自回归过程演化：\n$$ x_{\\text{true}}(k) = a \\, x_{\\text{true}}(k-1) + w_{k-1} $$\n其中 $a$ 是动力学系数，$w_{k-1} \\sim \\mathcal{N}(0, Q_{\\text{true}})$ 是过程噪声，其真实方差为 $Q_{\\text{true}}$。\n\n- **观测方程（测量模型）：** 在循环 $k$ 的观测 $y_k$ 是真实状态的直接带噪测量：\n$$ y_k = x_{\\text{true}}(k) + v_k $$\n其中 $v_k \\sim \\mathcal{N}(0, R)$ 是测量噪声，其方差为 $R$。\n\n**2. 卡尔曼滤波器算法**\n\n卡尔曼滤波器通过执行一个两步循环来递归地计算状态的估计：预测（预报）和更新（分析）。\n\n**2.1. 预测（预报）步骤**\n\n预测步骤将状态估计及其不确定性向前投影到未来时间。从循环 $k-1$ 的状态的分析（后验）估计（我们用其均值 $x_a(k-1)$ 和方差 $P_a(k-1)$ 表示）开始，我们计算循环 $k$ 的预报（先验）估计。\n- **预报均值：** 在循环 $k$ 的状态期望值通过应用过程模型的确定性部分找到：\n$$ x_f(k) = E[a \\, x_a(k-1) + w_{k-1}] = a \\, E[x_a(k-1)] = a \\, x_a(k-1) $$\n- **预报方差：** 预报的方差是传播的分析方差和假定的模型误差方差之和。滤波器使用 $Q_{\\text{assumed}}$，它可能不等于 $Q_{\\text{true}}$。\n$$ P_f(k) = \\text{Var}[a \\, x_a(k-1) + w_{k-1}] = a^2 \\, \\text{Var}[x_a(k-1)] + \\text{Var}[w_{k-1}] = a^2 P_a(k-1) + Q_{\\text{assumed}} $$\n\n**2.2. 从第一性原理推导更新（分析）步骤**\n\n更新步骤通过整合新的观测 $y_k$ 来完善预报估计。这是一个贝叶斯更新，其中预报作为先验，观测提供似然。\n\n- **先验：** 预报为状态 $x_k$ 提供了一个先验概率分布，这是一个高斯分布：$p(x_k) = \\mathcal{N}(x_k | x_f(k), P_f(k))$。其概率密度函数（PDF）正比于：\n$$ p(x_k) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(x_k - x_f(k))^2}{P_f(k)}\\right) $$\n\n- **似然：** 观测模型 $y_k = x_k + v_k$ 给出了在给定状态 $x_k$ 时观测到 $y_k$ 的似然：$p(y_k|x_k) = \\mathcal{N}(y_k | x_k, R)$。其PDF正比于：\n$$ p(y_k|x_k) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(y_k - x_k)^2}{R}\\right) $$\n\n- **后验：** 根据贝叶斯定理，状态的后验分布 $p(x_k|y_k)$ 正比于先验和似然的乘积。这个后验即为分析分布 $\\mathcal{N}(x_k | x_a(k), P_a(k))$。\n$$ p(x_k|y_k) \\propto p(y_k|x_k) p(x_k) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(x_k - x_f(k))^2}{P_f(k)} + \\frac{(x_k - y_k)^2}{R} \\right]\\right) $$\n两个高斯PDF的乘积是另一个高斯PDF（相差一个归一化常数）。为了找到它的均值 $x_a(k)$ 和方差 $P_a(k)$，我们对指数中关于 $x_k$ 的项进行配方。关于 $x_k$ 的二次项是 $x_k^2 \\left(\\frac{1}{P_f(k)} + \\frac{1}{R}\\right)$，这意味着后验方差的倒数（精度）是先验精度的总和：\n$$ \\frac{1}{P_a(k)} = \\frac{1}{P_f(k)} + \\frac{1}{R} \\implies P_a(k) = \\frac{P_f(k) R}{P_f(k) + R} $$\n关于 $x_k$ 的一次项是 $-2x_k \\left(\\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R}\\right)$。通过将其与高斯指数的规范形式进行比较，我们找到后验均值 $x_a(k)$：\n$$ \\frac{x_a(k)}{P_a(k)} = \\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R} \\implies x_a(k) = P_a(k) \\left(\\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R}\\right) $$\n代入 $P_a(k)$ 的表达式并化简，得到预报和观测的加权平均：\n$$ x_a(k) = \\frac{R x_f(k) + P_f(k) y_k}{P_f(k) + R} $$\n这个方程可以重排成更常见的“新息”形式：\n$$ x_a(k) = x_f(k) + \\frac{P_f(k)}{P_f(k) + R}(y_k - x_f(k)) $$\n这里，$K_k = \\frac{P_f(k)}{P_f(k) + R}$ 是卡尔曼增益，而 $(y_k - x_f(k))$ 是新息或测量残差。这个从第一性原理的推导使得使用这些标准的KF更新方程变得合理。\n\n**3. 仿真与诊断**\n\n仿真从初始条件 $x_{\\text{true}}(0) = x_0$、$x_a(0) = x_0$ 和 $P_a(0) = P_0$ 开始，进行 $k = 1, \\dots, N$ 个循环。在每个循环中，我们：\n1.  使用给定的随机种子生成真实状态 $x_{\\text{true}}(k)$ 和观测 $y_k$。\n2.  执行KF预测步骤以获得 $x_f(k)$ 和 $P_f(k)$。\n3.  执行KF更新步骤以获得 $x_a(k)$ 和 $P_a(k)$。\n4.  计算所需的诊断量：\n    - **分析增量：** $\\Delta(k) = x_a(k) - x_f(k)$。这表示根据新观测对预报进行的修正。平均绝对增量计算为 $\\overline{|\\Delta|} = \\frac{1}{N}\\sum_{k=1}^{N} |\\Delta(k)|$。\n    - **预报误差：** $e_f(k) = x_f(k) - x_{\\text{true}}(k)$。这衡量了预报与（现实中不可知的）真实状态的偏差。\n    - **漂移度量 ($s$)：** 该度量量化了预报误差随时间的任何系统性漂移。它被计算为预报误差时间序列 $\\{e_f(k)\\}_{k=1}^N$ 相对于循环指数 $k$ 的线性最小二乘回归线的斜率。一个非零的斜率表示滤波器发散或次优的、有偏的性能。拟合模型为 $e_f(k) \\approx s \\cdot k + b$。\n\n**4. 实现**\n\n最终的实现将针对每个提供的测试用例遵循此逻辑。为了可复现性，随机数生成器被设定了种子。输出 $\\overline{|\\Delta|}$ 和 $s$ 按规定进行计算和格式化。$Q$ 的错误指定（$Q_{\\text{assumed}} \\neq Q_{\\text{true}}$）测试了滤波器的鲁棒性。如果 $Q_{\\text{assumed}}$ 太小（欠分散），滤波器会变得过于自信并可能忽略观测，导致误差漂移（$s \\neq 0$）。如果 $Q_{\\text{assumed}}$ 太大（过分散），滤波器会过于保守，过度依赖带噪的观测，导致性能次优但通常稳定。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_kalman_filter_simulation(a, Q_true, Q_assumed, R, x0, P0, N, seed):\n    \"\"\"\n    Performs a data assimilation simulation using a 1D Kalman Filter.\n\n    This function simulates a true state, generates observations, runs the Kalman\n    Filter, and computes diagnostic metrics.\n\n    Args:\n        a (float): State transition scalar.\n        Q_true (float): True variance of the model error.\n        Q_assumed (float): Assumed variance of the model error for the filter.\n        R (float): Variance of the observation error.\n        x0 (float): Initial true state and analysis mean.\n        P0 (float): Initial analysis variance.\n        N (int): Total number of simulation cycles.\n        seed (int): Seed for the random number generator for reproducibility.\n\n    Returns:\n        list: A two-element list containing the mean absolute analysis\n              increment and the forecast error drift metric (slope), both\n              rounded to 6 decimal places.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Initialize state variables and histories\n    x_true = x0\n    x_a = x0\n    P_a = P0\n\n    forecast_errors = []\n    analysis_increments = []\n\n    # Simulation loop for cycles k = 1, ..., N\n    for _ in range(1, N + 1):\n        # 1. Advance the true state\n        w_k = rng.normal(loc=0.0, scale=np.sqrt(Q_true))\n        x_true = a * x_true + w_k\n\n        # 2. Generate the observation from the new true state\n        v_k = rng.normal(loc=0.0, scale=np.sqrt(R))\n        y_k = x_true + v_k\n\n        # 3. Kalman Filter: Prediction (Forecast) Step\n        # Propagate state estimate and its variance using previous analysis\n        x_f = a * x_a\n        P_f = a * P_a * a + Q_assumed\n\n        # 4. Kalman Filter: Update (Analysis) Step\n        # Derivation: The analysis is the Bayesian combination of the forecast prior\n        # and observation likelihood. The resulting mean is a weighted average.\n        # This leads to the standard Kalman update equations.\n        innovation = y_k - x_f\n        # Innovation covariance S_k = H P_f H' + R, where H=1 in our 1D case.\n        S_k = P_f + R\n        # Kalman Gain K_k = P_f H' inv(S_k), where H=1, H'=1.\n        K_k = P_f / S_k\n        \n        # Update analysis (posterior) mean and variance\n        x_a = x_f + K_k * innovation\n        P_a = (1.0 - K_k) * P_f\n\n        # 5. Compute and store diagnostic quantities\n        delta_k = x_a - x_f\n        analysis_increments.append(delta_k)\n\n        e_f_k = x_f - x_true\n        forecast_errors.append(e_f_k)\n\n    # Post-processing to calculate final metrics\n    # a. Mean absolute analysis increment\n    mean_abs_delta = np.mean(np.abs(np.array(analysis_increments)))\n\n    # b. Drift metric 's' (slope of least-squares fit of forecast error vs. time)\n    k_values = np.arange(1, N + 1)\n    # np.polyfit returns coefficients [slope, intercept] for a degree 1 polynomial\n    poly_coeffs = np.polyfit(k_values, forecast_errors, 1)\n    s = poly_coeffs[0]\n\n    return [round(mean_abs_delta, 6), round(s, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (a, Q_true, Q_assumed, R, x0, P0, N, seed)\n        (0.95, 0.04, 0.04, 0.09, 1.0, 0.1, 60, 123),  # Test case 1\n        (0.95, 0.04, 0.0, 0.09, 1.0, 0.1, 60, 123),   # Test case 2\n        (0.95, 0.04, 0.2, 0.09, 1.0, 0.1, 60, 123),  # Test case 3\n        (1.05, 0.04, 0.04, 0.09, 1.0, 0.1, 60, 456),  # Test case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        a, Q_true, Q_assumed, R, x0, P0, N, seed = case\n        result = run_kalman_filter_simulation(a, Q_true, Q_assumed, R, x0, P0, N, seed)\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The default str() for a list includes spaces, so we build the string manually.\n    result_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "随着我们转向更复杂的深度学习模型，理解它们的决策过程变得至关重要。本实践介绍了显著性图，这是一种用于解释为降水预报而设计的卷积神经网络（CNN）的强大技术。通过计算预报相对于输入的梯度，您将能够可视化模型“关注”哪些大气特征，从而评估它是否学到了具有物理意义的关系。",
            "id": "4030093",
            "problem": "您将得到一个简化的、科学上合理的卷积神经网络（CNN）架构，用于在数值天气预报和气候建模（模拟）的背景下，从网格化大气输入场预测标量降雨量。该CNN使用带有“same”填充的互相关、整流线性单元（ReLU）激活函数和全局平均池化来产生单一的标量预测。您的任务是通过评估预测降雨量相对于输入场的梯度来计算此CNN的显著图，并总结显著性在物理上有意义地集中于高湿度和正辐合区域的情况。\n\n基本原理和定义：\n- 卷积神经网络（CNN）定义如下。设输入为 $x \\in \\mathbb{R}^{C \\times H \\times W}$，其中有 $C$ 个通道和空间维度 $H \\times W$。这里，$x^{(1)}$ 是柱积分水汽，单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$；$x^{(2)}$ 是近地表温度异常，单位为 $\\mathrm{K}$；$x^{(3)}$ 是水平辐合，单位为 $\\mathrm{s}^{-1}$。您可以假设 $C = 3$，$H = W = 16$。\n- 该CNN有 $F$ 个滤波器（这里 $F = 2$）。滤波器 $f$ 在位置 $(i,j)$ 的预激活图为\n$$\nz^{(f)}_{i,j} = \\sum_{c=1}^{C} \\sum_{u=1}^{k} \\sum_{v=1}^{k} K^{(f)}_{c,u,v}\\,x^{(c)}_{i+u',j+v'} + b^{(f)},\n$$\n其中 $K^{(f)} \\in \\mathbb{R}^{C \\times k \\times k}$ 是滤波器核，$b^{(f)} \\in \\mathbb{R}$ 是一个偏置，$k=3$，索引 $(u',v')$ 实现互相关中的“same”填充（前向传播中没有核旋转），且填充确保了对所有 $(i,j)$ 的求和都有明确定义。\n- 激活值为 $a^{(f)}_{i,j} = \\max(0, z^{(f)}_{i,j})$，全局平均池化后的特征为\n$$\ng^{(f)} = \\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} a^{(f)}_{i,j}.\n$$\n- 标量降雨量预测为\n$$\n\\hat{y} = \\sum_{f=1}^{F} w_f\\, g^{(f)} + b_{\\mathrm{out}},\n$$\n单位为 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$。\n\n显著性与物理解释：\n- 定义通道 $c$ 的显著图为\n$$\nS^{(c)}_{i,j} = \\frac{\\partial \\hat{y}}{\\partial x^{(c)}_{i,j}}.\n$$\n- 定义具有物理意义的掩码\n$$\nM_{i,j} = \\begin{cases}\n1  \\text{if } x^{(1)}_{i,j} > q_{\\mathrm{th}} \\text{ and } x^{(3)}_{i,j} > 0, \\\\\n0  \\text{otherwise},\n\\end{cases}\n$$\n阈值 $q_{\\mathrm{th}} = 25$（单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$）。\n- 定义显著性集中分数\n$$\n\\phi = \\frac{\\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\left| S^{(c)}_{i,j} \\right|\\, M_{i,j}}{\\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\left| S^{(c)}_{i,j} \\right|},\n$$\n该分数衡量了总显著性量值中位于高湿度、辐合区域的比例（$\\phi \\in [0,1]$，无量纲）。\n\n网络规格（固定且已知）：\n- 滤波器 $f=1$（“雨水支持”）：\n  - $K^{(1)}_{q} = 0.02 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $K^{(1)}_{T'} = 0.01 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $K^{(1)}_{c} = 500 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $b^{(1)} = 0$,\n  - $w_1 = 20$.\n- 滤波器 $f=2$（“锋面探测器”）：\n  - $K^{(2)}_{q} = \\mathbf{0}_{3 \\times 3}$,\n  - $K^{(2)}_{T'} = 0.5 \\times \\begin{bmatrix} -1  0  1 \\\\ -1  0  1 \\\\ -1  0  1 \\end{bmatrix}$,\n  - $K^{(2)}_{c} = \\mathbf{0}_{3 \\times 3}$,\n  - $b^{(2)} = 0$,\n  - $w_2 = 5$.\n- 输出偏置：$b_{\\mathrm{out}} = 0$。\n\n测试套件：\n在一个大小为 $H=W=16$ 的空间网格上进行操作，索引 $i,j \\in \\{0,1,\\dots,15\\}$，并为 $(x^{(1)}, x^{(2)}, x^{(3)})$ 构建以下4个测试案例：\n- 案例1（理想情况，中心湿润辐合羽流）：\n  - $x^{(1)}_{i,j} = 10 + 30 \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$,\n  - $x^{(2)}_{i,j} = 2 \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$,\n  - $x^{(3)}_{i,j} = 10^{-3} \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$.\n- 案例2（边界条件，角落羽流）：\n  - $x^{(1)}_{i,j} = 10 + 30 \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$,\n  - $x^{(2)}_{i,j} = 2 \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$,\n  - $x^{(3)}_{i,j} = 10^{-3} \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$.\n- 案例3（边缘情况，均匀场）：\n  - $x^{(1)}_{i,j} = 20$,\n  - $x^{(2)}_{i,j} = 0$,\n  - $x^{(3)}_{i,j} = 0$.\n- 案例4（反物理辐合，环状湿度和冷异常）：\n  - $x^{(1)}_{i,j} = 10 + 35 \\left[ G(i,j; c_x=8, c_y=8, \\sigma=3) - 0.7\\, G(i,j; c_x=8, c_y=8, \\sigma=1.5) \\right]$ 在下方裁剪为$0$,\n  - $x^{(2)}_{i,j} = -2 \\, G(i,j; c_x=8, c_y=8, \\sigma=2.5)$,\n  - $x^{(3)}_{i,j} = -10^{-3} \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$.\n- 此处高斯函数定义为\n$$\nG(i,j; c_x, c_y, \\sigma) = \\exp\\left( -\\frac{(i-c_x)^2 + (j-c_y)^2}{2\\sigma^2} \\right).\n$$\n\n任务：\n1. 实现指定的CNN前向映射，为每个案例获取$\\hat{y}$。\n2. 通过应用链式法则和互相关的定义，精确计算显著图 $S^{(c)}_{i,j} = \\partial \\hat{y} / \\partial x^{(c)}_{i,j}$。利用ReLU的导数在正预激活时为$1$，否则为$0$，以及全局平均池化的导数是一个常数缩放因子 $1/(H W)$。对于通过互相关的反向映射，使用上游梯度与每个通道旋转$180^\\circ$的核进行相关运算。\n3. 使用 $q_{\\mathrm{th}} = 25$（单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$）计算掩码 $M_{i,j}$，并按定义计算集中分数 $\\phi$。\n4. 为每个案例生成两个量：\n   - 预测降雨量 $\\hat{y}$，以 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$ 为单位表示，并四舍五入到三位小数。\n   - 无量纲的显著性集中分数 $\\phi$，四舍五入到三位小数。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个逗号分隔的列表，用方括号括起来，顺序为 $[\\hat{y}_1, \\phi_1, \\hat{y}_2, \\phi_2, \\hat{y}_3, \\phi_3, \\hat{y}_4, \\phi_4]$，其中下标索引对应于上述编号的测试案例。每个数字必须格式化为恰好三位小数。\n\n确保科学真实性：CNN和场必须按规定实现，所有计算必须是确定性的和自包含的，不依赖外部数据。本问题不使用角度。使用的单位是：输入为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$、$\\mathrm{K}$、$\\mathrm{s}^{-1}$，输出为 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$。",
            "solution": "用户提供的问题是一个在科学机器学习领域内定义明确的计算练习，具体涉及解释用于简化天气预报背景下的卷积神经网络（CNN）。该问题具有科学基础，数学上一致，并且提供了所有必要的参数和定义以确定唯一的解决方案。因此，我们将着手提供一个完整的解决方案。\n\n该解决方案涉及三个主要的计算步骤：\n1.  通过CNN的**前向传播**，为每个输入的大气状态计算标量降雨量预测 $\\hat{y}$。\n2.  使用链式法则进行**反向传播**，计算预测值 $\\hat{y}$ 相对于每个输入变量的梯度，从而得到显著图 $S^{(c)}$。\n3.  一个**分析步骤**，基于物理动机的掩码 $M$ 计算显著性集中分数 $\\phi$。\n\n我们现在将详细说明每个步骤的数学公式。\n\n### 1. 前向传播\n\n前向传播从输入张量 $x \\in \\mathbb{R}^{C \\times H \\times W}$（其中 $C=3$, $H=16$, $W=16$）计算预测的降雨量 $\\hat{y}$。输入通道为 $x^{(1)}$（水汽）、$x^{(2)}$（温度异常）和 $x^{(3)}$（辐合）。\n\n首先，对于 $F=2$ 个滤波器中的每一个，我们计算一个预激活图 $z^{(f)}$。这是通过对输入 $x$ 与滤波器核 $K^{(f)} \\in \\mathbb{R}^{C \\times k \\times k}$（$k=3$）进行多通道2D互相关运算，然后加上一个偏置项 $b^{(f)}$ 来实现的。该操作使用“same”填充，意味着输入被填充零，使得输出图与输入图具有相同的空间维度 $H \\times W$。\n\n滤波器 $f$ 在网格点 $(i,j)$ 的预激活为：\n$$\nz^{(f)}_{i,j} = b^{(f)} + \\sum_{c=1}^{C} (K^{(f)}_c \\star x^{(c)})_{i,j}\n$$\n其中 $\\star$ 表示2D互相关，而 $K^{(f)}_c$ 是通道 $c$ 的核切片。\n\n其次，将整流线性单元（ReLU）激活函数逐元素应用于预激活图。这为模型引入了非线性。\n$$\na^{(f)}_{i,j} = \\max(0, z^{(f)}_{i,j})\n$$\n\n第三，每个激活图 $a^{(f)}$ 通过全局平均池化被简化为单个标量特征 $g^{(f)}$。\n$$\ng^{(f)} = \\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} a^{(f)}_{i,j}\n$$\n\n最后，标量降雨量预测 $\\hat{y}$（单位 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$）被计算为特征 $g^{(f)}$ 的加权和，再加上一个输出偏置 $b_{\\mathrm{out}}$。\n$$\n\\hat{y} = b_{\\mathrm{out}} + \\sum_{f=1}^{F} w_f g^{(f)}\n$$\n所有网络参数（$K^{(f)}$、$b^{(f)}$、$w_f$、$b_{\\mathrm{out}}$）都在问题描述中给出。\n\n### 2. 用于显著图的反向传播\n\n输入通道 $c$ 的显著图 $S^{(c)}$ 定义为输出预测 $\\hat{y}$ 相对于输入图 $x^{(c)}$ 的偏导数。我们使用链式法则，将梯度从输出反向传播到输入来计算它。\n\n1.  **在输出层的梯度**：$\\hat{y}$ 相对于池化特征 $g^{(f)}$ 的导数就是输出权重 $w_f$。\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial g^{(f)}} = w_f\n    $$\n\n2.  **在池化层的梯度**：由于是平均操作，$g^{(f)}$ 相对于激活图 $a^{(f)}_{i,j}$ 的单个元素的导数是常数。\n    $$\n    \\frac{\\partial g^{(f)}}{\\partial a^{(f)}_{i,j}} = \\frac{1}{H W}\n    $$\n    根据链式法则，$\\hat{y}$ 相对于 $a^{(f)}_{i,j}$ 的梯度是一个常数图：\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial a^{(f)}_{i,j}} = \\frac{\\partial \\hat{y}}{\\partial g^{(f)}} \\frac{\\partial g^{(f)}}{\\partial a^{(f)}_{i,j}} = \\frac{w_f}{H W}\n    $$\n\n3.  **在激活层的梯度**：ReLU激活 $a^{(f)}_{i,j}$ 相对于其输入 $z^{(f)}_{i,j}$ 的导数，如果 $z^{(f)}_{i,j} > 0$ 则为 $1$，否则为 $0$。我们用亥维赛德阶跃函数 $H(\\cdot)$ 来表示。\n    $$\n    \\frac{\\partial a^{(f)}_{i,j}}{\\partial z^{(f)}_{i,j}} = H(z^{(f)}_{i,j}) = \\begin{cases} 1  \\text{if } z^{(f)}_{i,j} > 0 \\\\ 0  \\text{if } z^{(f)}_{i,j} \\le 0 \\end{cases}\n    $$\n    因此，预激活图的上游梯度为：\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial z^{(f)}_{i,j}} = \\frac{\\partial \\hat{y}}{\\partial a^{(f)}_{i,j}} \\frac{\\partial a^{(f)}_{i,j}}{\\partial z^{(f)}_{i,j}} = \\frac{w_f}{HW} H(z^{(f)}_{i,j})\n    $$\n    让这个上游梯度图表示为 $\\delta z^{(f)}$。\n\n4.  **在互相关层的梯度**：最后一步是求相对于输入 $x^{(c)}$ 的梯度。预激活 $z^{(f)}$ 是对输入通道进行互相关的总和。互相关操作相对于其输入的导数是与原始核的卷积操作。\n    $$\n    S^{(c)} = \\frac{\\partial \\hat{y}}{\\partial x^{(c)}} = \\sum_{f=1}^{F} \\frac{\\partial z^{(f)}}{\\partial x^{(c)}} \\frac{\\partial \\hat{y}}{\\partial z^{(f)}} = \\sum_{f=1}^{F} (\\delta z^{(f)} \\circledast K^{(f)}_c)\n    $$\n    其中 $\\circledast$ 表示2D卷积，$K^{(f)}_c$ 是滤波器 $f$ 和通道 $c$ 的核。此操作等效于将上游梯度图 $\\delta z^{(f)}$ 与旋转180度的核 $K^{(f)}_{c, \\text{rot180}}$ 进行互相关。每个通道 $c$ 的显著图是所有滤波器 $f$ 贡献的总和。\n\n### 3. 显著性集中分数\n\n分数 $\\phi$ 量化了模型的敏感性（显著性）在多大程度上集中在物理上有利于降雨的区域。\n\n首先，创建一个二元掩码 $M \\in \\{0,1\\}^{H \\times W}$。它识别出同时具有高大气湿度和正辐合的网格点，这是许多类型降水的前提条件。\n$$\nM_{i,j} = \\begin{cases} 1  \\text{if } x^{(1)}_{i,j} > q_{\\mathrm{th}} \\text{ and } x^{(3)}_{i,j} > 0 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n其中湿度阈值为 $q_{\\mathrm{th}} = 25 \\, \\mathrm{kg}\\,\\mathrm{m}^{-2}$。\n\n然后，显著性集中分数 $\\phi$ 计算为掩码区域内的总绝对显著性与整个区域的总绝对显著性之比。\n$$\n\\phi = \\frac{\\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |S^{(c)}_{i,j}| M_{i,j}}{\\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |S^{(c)}_{i,j}|}\n$$\n$\\phi$ 值接近 $1$ 表示模型主要使用来自物理相关区域的信息进行预测，这表明它学到了一个有物理意义的关系。接近 $0$ 的值则表示相反。如果总显著性为零，则定义 $\\phi$ 为 $0$。\n\n实现将对所提供的四个测试案例中的每一个案例遵循这些步骤。",
            "answer": "```python\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Main function to solve the CNN saliency problem for all test cases.\n    \"\"\"\n    \n    # -------------------\n    # Problem Configuration\n    # -------------------\n    H, W = 16, 16\n    C, F = 3, 2\n    k = 3\n    q_th = 25.0\n\n    # Network parameters\n    kernels = np.zeros((F, C, k, k))\n    # Filter f=1 (index 0)\n    kernels[0, 0, :, :] = 0.02 * np.ones((k, k))  # K_q\n    kernels[0, 1, :, :] = 0.01 * np.ones((k, k))  # K_T'\n    kernels[0, 2, :, :] = 500.0 * np.ones((k, k)) # K_c\n    # Filter f=2 (index 1)\n    kernels[1, 0, :, :] = 0.0 * np.zeros((k, k)) # K_q\n    kernels[1, 1, :, :] = 0.5 * np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]) # K_T'\n    kernels[1, 2, :, :] = 0.0 * np.zeros((k, k)) # K_c\n\n    biases_conv = np.array([0.0, 0.0])\n    weights_out = np.array([20.0, 5.0])\n    bias_out = 0.0\n\n    # -------------------\n    # Helper Functions\n    # -------------------\n    def gaussian(i_grid, j_grid, cx, cy, sigma):\n        return np.exp(-((i_grid - cx)**2 + (j_grid - cy)**2) / (2 * sigma**2))\n\n    # Grid for generating fields\n    i_grid, j_grid = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n\n    # Test Case Definitions\n    test_cases = [\n        # Case 1: Central plume\n        (\n            10 + 30 * gaussian(i_grid, j_grid, 8, 8, 2),\n            2 * gaussian(i_grid, j_grid, 8, 8, 2),\n            1e-3 * gaussian(i_grid, j_grid, 8, 8, 2)\n        ),\n        # Case 2: Corner plume\n        (\n            10 + 30 * gaussian(i_grid, j_grid, 3, 3, 2),\n            2 * gaussian(i_grid, j_grid, 3, 3, 2),\n            1e-3 * gaussian(i_grid, j_grid, 3, 3, 2)\n        ),\n        # Case 3: Uniform fields\n        (\n            20 * np.ones((H, W)),\n            0 * np.ones((H, W)),\n            0 * np.ones((H, W))\n        ),\n        # Case 4: Ring moisture, central cold anomaly, divergence\n        (\n            np.maximum(0, 10 + 35 * (gaussian(i_grid, j_grid, 8, 8, 3) - 0.7 * gaussian(i_grid, j_grid, 8, 8, 1.5))),\n            -2 * gaussian(i_grid, j_grid, 8, 8, 2.5),\n            -1e-3 * gaussian(i_grid, j_grid, 8, 8, 2)\n        )\n    ]\n    \n    results = []\n    \n    for case_data in test_cases:\n        x = np.array(case_data)  # Shape (C, H, W)\n\n        # -------------------\n        # 1. Forward Pass\n        # -------------------\n        z_maps = np.zeros((F, H, W))\n        a_maps = np.zeros((F, H, W))\n        g_features = np.zeros(F)\n\n        for f in range(F):\n            z_f = np.full((H, W), biases_conv[f])\n            for c in range(C):\n                z_f += signal.correlate2d(x[c, :, :], kernels[f, c, :, :], mode='same', boundary='fill', fillvalue=0)\n            z_maps[f, :, :] = z_f\n            a_maps[f, :, :] = np.maximum(0, z_f)\n            g_features[f] = np.mean(a_maps[f, :, :])\n\n        y_hat = np.sum(weights_out * g_features) + bias_out\n\n        # -------------------\n        # 2. Backward Pass (Saliency)\n        # -------------------\n        saliency_maps = np.zeros((C, H, W))\n        \n        for f in range(F):\n            # Upstream gradient from output layer, through pooling\n            d_y_hat_d_g_f = weights_out[f]\n            d_g_f_d_a_f = 1.0 / (H * W)\n            d_y_hat_d_a_f = d_y_hat_d_g_f * d_g_f_d_a_f\n            \n            # Upstream gradient through ReLU\n            d_a_f_d_z_f = (z_maps[f, :, :] > 0).astype(float)\n            delta_z_f = d_y_hat_d_a_f * d_a_f_d_z_f\n\n            # Gradient w.r.t input x\n            for c in range(C):\n                # Gradient of cross-correlation is convolution with original kernel\n                saliency_maps[c, :, :] += signal.convolve2d(delta_z_f, kernels[f, c, :, :], mode='same', boundary='fill', fillvalue=0)\n        \n        # -------------------\n        # 3. Saliency Concentration Fraction (phi)\n        # -------------------\n        mask = ((x[0, :, :] > q_th)  (x[2, :, :] > 0)).astype(float)\n        \n        saliency_abs_total = np.sum(np.abs(saliency_maps))\n        \n        numerator = np.sum(np.abs(saliency_maps) * mask[np.newaxis, :, :])\n        \n        phi = 0.0\n        if saliency_abs_total > 1e-12: # Avoid division by zero\n            phi = numerator / saliency_abs_total\n            \n        # Store results\n        results.append(y_hat)\n        results.append(phi)\n        \n    # Format and print the final output\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}