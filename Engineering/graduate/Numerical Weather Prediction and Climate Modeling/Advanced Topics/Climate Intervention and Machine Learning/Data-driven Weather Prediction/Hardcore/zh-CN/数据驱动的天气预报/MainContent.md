## 引言
在[数值天气预报](@entry_id:191656)领域，我们正处在一个由数据驱动的深刻变革时代。传统的预报严重依赖于对大气物理过程的精确建模，但面对大气的混沌本质和模型中不可避免的近似，仅靠物理模型已难以满足日益增长的预报精度和可靠性需求。海量、多源的[地球观测](@entry_id:1124094)数据为我们提供了前所未有的机遇，但同时也带来了核心挑战：如何系统性地将这些数据与物理模型相结合，以量化和减少不确定性，并生成值得信赖的[概率预报](@entry_id:183505)？

本文旨在全面解答这一问题，为读者构建一个从理论到实践的完整知识体系。我们将分三个核心章节展开：首先，在“原理与机制”中，我们将深入探讨支撑数据驱动预报的[概率基础](@entry_id:187304)和以数据同化为核心的关键机制，揭示如何将模型与现实联系起来。接着，在“应用与跨学科连接”中，我们将展示这些原理如何在地球系统建模、次网格过程[参数化](@entry_id:265163)以及与物理知识融合等前沿领域中发挥作用。最后，在“动手实践”部分，您将有机会通过具体的编程练习，亲手实现数据同化循环并探索模型解释技术，从而将理论知识转化为实践能力。

## 原理与机制

本章旨在深入探讨数据驱动天气预报背后的核心科学原理和基本机制。我们将从支撑该领域的[概率论基础](@entry_id:158925)出发，逐步解析数据同化、[集合预报](@entry_id:1124525)、统计后处理以及模型评估等关键环节。本章的[组织结构](@entry_id:146183)旨在构建一个连贯的知识体系，使读者能够理解如何将观测数据与物理模型相结合，以生成准确且可靠的天气预报。

### 预测的[概率基础](@entry_id:187304)

现代天气预报的根基在于对不确定性的量化，而这种不确定性的根源深植于大气系统的混沌本质。大气是一个非[线性动力系统](@entry_id:1127277)，其状态的微小差异会随着时间的推移呈指数级增长。这一现象限制了我们对未来大气状态进行精确、确定性预测的能力。

#### 可预报性、误差增长与李雅普诺夫指数

我们可以通过**[李雅普诺夫指数](@entry_id:136828)**（Lyapunov exponent）来量化这种误差增长。假设我们有一个由数据驱动模型（例如[循环神经网络](@entry_id:634803)）描述的[离散时间动力系统](@entry_id:276520) $x_{k+1} = F(x_k)$，其时间步长为 $\Delta t$。一个微小的初始扰动 $\delta x_0$ 将通过模型的切线性演化进行传播：$\delta x_{k+1} \approx J_k \delta x_k$，其中 $J_k$ 是模型在状态 $x_k$ 处的[雅可比矩阵](@entry_id:178326)。

在每个时间步，[误差范数](@entry_id:176398)的最大增长由 $J_k$ 的最大[奇异值](@entry_id:152907) $s_{\max}$ 决定。经过 $k$ 个时间步（即时间 $t = k \Delta t$），初始[误差范数](@entry_id:176398) $E_0$ 将增长到 $E(t) \approx E_0 (s_{\max})^{t/\Delta t}$。为了用连续时间来描述这种[指数增长](@entry_id:141869)，我们将其与[标准形式](@entry_id:153058) $E(t) \approx E_0 e^{\lambda t}$ 进行比较，由此可以定义**[最大李雅普诺夫指数](@entry_id:188872)** $\lambda$：

$$
\lambda = \frac{1}{\Delta t}\ln s_{\max}
$$

这个正的 $\lambda$ 值是[混沌系统](@entry_id:139317)的标志，它代表了误差增长的平均指数率。它直接决定了**可预报性时限**（predictability horizon）$T_p$，即预测误差从初始值 $E_0$ 增长到某个不可接受的容忍度 $E_{\text{tol}}$ 所需的时间。通过求解 $E_0 e^{\lambda T_p} = E_{\text{tol}}$，我们得到：

$$
T_p = \frac{1}{\lambda}\ln\left(\frac{E_{\text{tol}}}{E_0}\right)
$$

这个关系明确指出，即使拥有近乎完美的模型和极小的初始误差，我们对未来的确定性预报能力也存在一个固有的、有限的时间边界 。因此，我们必须转向[概率方法](@entry_id:197501)，将预报视为对未来可能状态的一个概率分布，而非单一的确定性结果。

#### 贝叶斯推断：融合模型与观测的框架

[贝叶斯定理](@entry_id:897366)为在不确定性下进行学习和推断提供了严谨的数学框架。在数据同化问题中，我们的目标是根据观测数据 $y$ 来更新我们对大气真实状态 $x$ 的认识。这一过程可以用**贝叶斯定理**来表述：

$$
p(x | y) \propto p(y | x) p(x)
$$

这个公式优雅地连接了三个核心概率分布，每一个都在大气状态估计中扮演着独特的**认知角色**（epistemic meaning）：

1.  **[先验概率](@entry_id:275634) $p(x)$ (Prior)**：这代表了在获得新观测 $y$ 之前我们对大气状态 $x$ 的全部知识。在实践中，这通常是由数值天气预报模型从上一个分析时刻演化而来的短期预报，即“背景场”。它封装了我们对大气动力学和物理过程的理解，反映了在观测到来之前我们关于系统状态的**认知不确定性**（epistemic uncertainty）。

2.  **[似然函数](@entry_id:921601) $p(y | x)$ (Likelihood)**：这描述了在给定一个假设的真实大气状态 $x$ 的条件下，观测到数据 $y$ 的概率。它由观测过程的模型 $y = h(x) + \varepsilon$ 决定，其中 $h$ 是观测算子，$\varepsilon$ 是[观测误差](@entry_id:752871)。[似然函数](@entry_id:921601)封装了我们关于测量仪器特性和观测代表性误差的知识。它将抽象的物理状态与具体的测量数据联系起来。

3.  **[后验概率](@entry_id:153467) $p(x | y)$ (Posterior)**：这是我们最终的目标，代表了在融合了[观测信息](@entry_id:165764)之后，我们对大气状态 $x$ 的更新后的知识。它综合了来自物理模型的先验知识和来自观测的新证据，为我们提供了对当前大气状态最可能的一个估计。

贝叶斯定理的分母，即证据因子 $p(y) = \int p(y | x) p(x) dx$，对于给定的观测 $y$ 是一个[归一化常数](@entry_id:752675)，确保后验概率的积分为 1。因此，数据同化的本质，就是通过贝叶斯定理，将先验知识与观测证据相结合，以减小我们对真实大气状态的认知不确定性 。

### 核心机制：数据同化

数据同化是实现数据驱动天气预报的引擎。它以一种循环往复的方式，系统性地将全球范围内海量的、时空不规则的观测数据融入到数值模型中，从而[生成对](@entry_id:906691)大气状态的最佳估计，并为下一次预报提供初始条件。

#### [分析-预报循环](@entry_id:1120997)

业务化天气预报系统的核心是一个持续不断的**[分析-预报循环](@entry_id:1120997)**（analysis-forecast cycle）。这个循环由两个关键步骤组成 ：

1.  **分析（Analysis）**：在每个同化窗口的开始时刻（例如 $t_k$），我们有一个**背景场**（background state）$(x_k^b, B_k)$，它代表了对该时刻大气状态的[先验估计](@entry_id:186098)及其[误差协方差](@entry_id:194780)。分析步骤通过使用贝叶斯定理（或其等价形式，如[变分法](@entry_id:166033)或卡尔曼滤波），将该背景场与在同化窗口 $[t_k, t_{k+1}]$ 内收集到的所有新观测数据相结合。这个过程产生一个**分析场**（analysis state）$(x_k^a, A_k)$，它代表了对 $t_k$ 时刻大气状态的后验估计，其不确定性（由分析[误差协方差](@entry_id:194780) $A_k$ 表示）通常小于背景场。

2.  **预报（Forecast）**：分析场 $x_k^a$ 被用作[数值天气预报](@entry_id:191656)模型 $\mathcal{M}_k$ 的初始条件。模型随后向前积分，将这个最佳估计[状态传播](@entry_id:634773)到下一个同化窗口的开始时刻 $t_{k+1}$。这个预报结果 $x_{k+1}^b = \mathcal{M}_k(x_k^a)$，连同其通过模型动力学演化并考虑了[模型误差](@entry_id:175815)后的协方差 $B_{k+1}$，就构成了下一个循环的背景场。

这个循环不断重复，例如每 6 小时一次，确保模型状态始终被最新的观测数据所约束，防止其因[混沌动力学](@entry_id:142566)而偏离真实的大气演变轨迹。

#### 连接模型与现实：[观测算子](@entry_id:752875)

为了将模型状态与观测数据相结合，我们必须能够将模型中的物理量（定义在三维网格上）转换为观测仪器所测量的物理量（在特定的点或区域）。这个转换由**[观测算子](@entry_id:752875)**（observation operator）$H$ 完成。在数据同化中，观测模型通常表示为：

$$
y = H(x) + \epsilon
$$

这里的[观测误差](@entry_id:752871)项 $\epsilon$ 包含了所有导致理想观测 $H(x)$ 与实际测量值 $y$ 之间产生差异的来源。它通常被分解为两个主要部分 ：

*   **测量误差 ($\epsilon^{\mathrm{meas}}$)**：由观测仪器本身的物理局限性引起，例如[电子噪声](@entry_id:894877)、标定偏差等。
*   **代表性误差 ($\epsilon^{\mathrm{rep}}$)**：这是一个更微妙但至关重要的误差来源。它源于模型和观测在空间和时间尺度上的不匹配。例如，一个网格间距为 10 公里的模型无法解析一个由单点[温度计](@entry_id:187929)测量的、受几米尺度[湍流](@entry_id:151300)影响的温度。[代表性误差](@entry_id:754253)就量化了这种由模型未解析的[次网格尺度过程](@entry_id:1132602)和观测算子 $H$ 本身的近似所引入的差异。

假设这两类误差不相关，总的[观测误差协方差](@entry_id:752872)矩阵 $R$ 就是两者协方差之和：$R = R_{\text{meas}} + R_{\text{rep}}$。通常，$R_{\text{meas}}$ 被假定为[对角矩阵](@entry_id:637782)（仪器噪声相互独立），而 $R_{\text{rep}}$ 则可能具有非对角的结构，因为邻近站点的代表性误差可能受到同一个未解析的物理过程（如局地环流）的影响而相互关联。

#### [变分同化](@entry_id:756436)方法

[变分数据同化](@entry_id:756439)（Variational Data Assimilation）通过最小化一个**代价函数**（cost function）来寻找最优的大气状态。在满足高斯误差假设的线性条件下，这个代价函数正比于后验概率的负对数。对于在单一时刻进行分析的**[三维变分同化](@entry_id:755953)**（3D-Var），代价函数 $J(\mathbf{x})$ 形式如下 ：

$$
J(\mathbf{x}) = \frac{1}{2}(\mathbf{x} - \mathbf{x}_b)^\top \mathbf{B}^{-1}(\mathbf{x} - \mathbf{x}_b) + \frac{1}{2}(\mathbf{y} - \mathbf{H}\mathbf{x})^\top \mathbf{R}^{-1}(\mathbf{y} - \mathbf{H}\mathbf{x})
$$

这个函数直观地表示了在两个信息源之间寻求平衡：
*   第一项，$J_b = \frac{1}{2}(\mathbf{x} - \mathbf{x}_b)^\top \mathbf{B}^{-1}(\mathbf{x} - \mathbf{x}_b)$，惩罚分析场 $\mathbf{x}$ 对背景场 $\mathbf{x}_b$ 的偏离，并由背景误差协方差的逆矩阵 $\mathbf{B}^{-1}$ 进行加权。
*   第二项，$J_o = \frac{1}{2}(\mathbf{y} - \mathbf{H}\mathbf{x})^\top \mathbf{R}^{-1}(\mathbf{y} - \mathbf{H}\mathbf{x})$，惩罚分析场在观测空间的投影 $\mathbf{H}\mathbf{x}$ 对实际观测 $\mathbf{y}$ 的偏离，并由[观测误差协方差](@entry_id:752872)的[逆矩阵](@entry_id:140380) $\mathbf{R}^{-1}$ 进行加权。

在业务应用中，[状态向量](@entry_id:154607) $\mathbf{x}$ 的维度（$n$）可以达到 $10^8$ 到 $10^9$。直接最小化 $J(\mathbf{x})$ 在数值上是极具挑战性的，因为背景误差协方差矩阵 $\mathbf{B}$ 包含了复杂的物理相关性，导致代价函数的 Hessian 矩阵 $\mathcal{H} = \mathbf{B}^{-1} + \mathbf{H}^\top \mathbf{R}^{-1}\mathbf{H}$ 严重病态。为了解决这个问题，通常会引入一个**[控制变量变换](@entry_id:747844)**（control-variable transformation）进行**[预处理](@entry_id:141204)**（preconditioning）。通过定义一个新的无量纲控制变量 $\mathbf{v}$，使得状态增量 $\mathbf{x} - \mathbf{x}_b = \mathbf{L}\mathbf{v}$，其中 $\mathbf{B} = \mathbf{L}\mathbf{L}^\top$，背景项代价函数被简化为 $J_b(\mathbf{v}) = \frac{1}{2}\mathbf{v}^\top\mathbf{v}$。这个变换极大地改善了优化问题的[条件数](@entry_id:145150)，使得梯度下降等[迭代算法](@entry_id:160288)能够高效收敛。

#### 考虑不完美模型：弱约束[四维变分同化](@entry_id:749536)

传统的**[强约束四维变分](@entry_id:755527)同化**（Strong-Constraint 4D-Var）假设数值模型是完美的，即状态演化严格遵循 $x_{k+1} = M(x_k)$。然而，所有模型都是真实大气过程的近似，都存在[模型误差](@entry_id:175815)。**弱约束[四维变分同化](@entry_id:749536)**（Weak-Constraint 4D-Var）通过引入一个代表[模型误差](@entry_id:175815)的随机项 $\eta_k \sim \mathcal{N}(0, Q)$ 来放宽这一假设，其中 $Q$ 是[模型误差协方差](@entry_id:752074)矩阵。

这种做法改变了代价函数，增加了一个惩罚模型误差的项。在弱约束框架下，代价函数需要同时最小化与背景场、观测和模型动力学的偏离 ：

$$
J(X_{0:K}) = \frac{1}{2} (x_0 - x_b)^\top B^{-1} (x_0 - x_b) + \frac{1}{2} \sum_{k=0}^{K-1} (x_{k+1} - M(x_k))^\top Q^{-1} (x_{k+1} - M(x_k)) + \frac{1}{2} \sum_{k=0}^{K} (y_k - H(x_k))^\top R^{-1} (y_k - H(x_k))
$$

这里的控制变量是整个时间窗口内的状态轨迹 $X_{0:K}$。[模型误差协方差](@entry_id:752074) $Q$ 的引入至关重要：它决定了在解释观测与背景场之间的不一致时，我们愿意将多大程度上归因于模型自身的缺陷。一个较大的 $Q$（小的 $Q^{-1}$）意味着我们允许分析轨迹偏离模型动力学以更好地拟合观测，而一个较小的 $Q$ 则表示我们更信任模型。在线性[高斯假设](@entry_id:170316)下，弱约束 4D-Var 的解与[卡尔曼平滑器](@entry_id:143392)（Kalman smoother）的解是等价的，其中 $Q$ 扮演着过程噪声的角色。

### 集合与统计方法

除了变分法，另一大[类数](@entry_id:156164)据驱动方法是基于集合（ensembles）和统计建模。这些方法在[量化不确定性](@entry_id:272064)和校正模式偏差方面尤其强大。

#### 集合预报与样本统计

[集合预报](@entry_id:1124525)通过运行一组（而不是单个）模型预报来捕捉预报的不确定性。这个集合的成员 $\\{x_i^f\\}_{i=1}^N$ 来自略微扰动的初始条件或模型参数，旨在抽样未来的可能性分布。

从这个集合中，我们可以计算样本统计量来表征预报分布。**[集合平均](@entry_id:1124520)** $\bar{x}^f = \frac{1}{N}\sum_{i=1}^N x_i^f$ 是对真实预报均值 $\mu$ 的一个无偏估计。更重要的是**[集合协方差](@entry_id:1124514)** $P^f = \frac{1}{N-1}\sum_{i=1}^N (x_i^f - \bar{x}^f)(x_i^f - \bar{x}^f)^\top$，它使用[贝塞尔校正](@entry_id:169538)因子 $N-1$ 来提供对真实预报协方差 $\Sigma$ 的无偏估计 。

然而，在业务化 NWP 中，集合成员数 $N$（通常为 20-100）远小于状态向量的维度 $m$（$10^8 - 10^9$）。这种 $m \gg N$ 的情况带来了两个严重的统计问题：

1.  **[秩亏](@entry_id:754065)**（Rank Deficiency）：由 $N$ 个成员计算出的样本协方差矩阵 $P^f$ 的秩最多为 $N-1$。这意味着 $P^f$ 是奇异的，它所描述的变化仅限于一个低维子空间，无法表示所有可能的误差结构。

2.  **伪相关**（Spurious Correlations）：由于有限样本的随机性，即使两个物理上不相关的变量（例如相距很远的两个格点），其样本[相关系数](@entry_id:147037)几乎肯定不为零。这些[伪相关](@entry_id:755254)的典型量级约为 $O(N^{-1/2})$。对于小集合，这些[噪声相关](@entry_id:1128753)性可能远远大于真实的远距离物理[遥相关](@entry_id:1132892)信号，从而在数据同化（如集合卡尔曼滤波）中引入错误的更新 。

#### [协方差局地化](@entry_id:164747)

为了解决[伪相关](@entry_id:755254)问题，[集合卡尔曼滤波](@entry_id:166109)（EnKF）中广泛采用**[协方差局地化](@entry_id:164747)**（covariance localization）技术。其核心思想是通过一个**[舒尔积](@entry_id:198876)**（Schur product，也称 Hadamard product）来滤除远距离的[噪声相关](@entry_id:1128753)性：

$$
P^f_{\text{loc}} = \rho \circ \hat{P}^f
$$

这里，$\hat{P}^f$ 是样本协方差矩阵，$\rho$ 是一个基于物理距离构造的[相关矩阵](@entry_id:262631)。$\rho$ 的对角线元素为 1，非对角[线元](@entry_id:196833)素 $\rho_{ij}$ 随着格点 $i$ 和 $j$ 之间距离的增加而平滑地递减至零。这种操作保留了被认为是可靠的局地协方差结构，同时抑制了由采样误差主导的远距离伪相关。根据[舒尔积定理](@entry_id:202887)，如果 $\rho$ 和 $\hat{P}^f$ 都是[半正定矩阵](@entry_id:155134)，那么它们的[舒尔积](@entry_id:198876) $P^f_{\text{loc}}$ 也保证是半正定的，从而维持了其作为协方差矩阵的数学有效性 。

#### 统计后处理与降尺度

数据驱动方法不仅用于状态估计，也广泛应用于模型输出的改进。

**模式输出统计**（Model Output Statistics, MOS）是一种经典的后处理技术，它通过统计回归来校正数值模式的系统性偏差。MOS 学习一个从模型输出（以及其他相关预测因子，如地形、一天中的时间等）到观测站实际观测值的映射关系。例如，它可以学习一个函数 $g(X_t) = \mathbb{E}[Y_t | X_t]$，其中 $X_t$ 是预测因子向量，$Y_t$ 是观测值。MOS 成功的关键在于：(1) 训练数据必须涵盖所有相关的天气型；(2) 预测因子与观测值之间的物理关系（即条件概率 $p(Y|X)$）在训练和应用期间必须保持**平稳**（stationary）；(3) 预测因子向量 $X_t$ 必须包含能够解释偏差来源的信息 。

当需要从粗分辨率模型输出生成高分辨率信息时，数据驱动方法也扮演着核心角色。**[统计降尺度](@entry_id:1132326)**（statistical downscaling）学习一个从粗分辨率模型场到高分辨率局地观测的经验映射。这与**动力降尺度**（dynamical downscaling）形成对比，后者通过在一个有限区域内运行一个高分辨率的物理模型来实现。统计降尺度计算成本低，但其物理一致性无法保证，除非在模型设计或训练过程中显式加入物理约束。而[动力降尺度](@entry_id:1124043)在物理上更为完备，能够自然地满足质量、能量等守恒定律，但计算成本极高 。

### [模型评估](@entry_id:164873)与引导

开发可靠的数据驱动模型不仅需要强大的算法，还需要健全的评估框架和对模型局限性的深刻理解。

#### [概率预报](@entry_id:183505)的评估与[不确定性分解](@entry_id:183314)

如前所述，由于大气的混沌特性，现代预报的终极目标是提供一个完整的**[概率预报](@entry_id:183505)**，即一个关于未来结果的概率分布 $p(y|\mathbf{x}, \mathcal{D})$。评估这类预报需要超越简单的确定性指标。**固有评分规则**（proper scoring rules）提供了一个理论上健全的框架。如果一个评分规则 $S(q, y)$ 是“固有的”，那么当且仅当预报者发布其真实的信念分布 $p$ 时，其期望得分 $\mathbb{E}_{Y \sim p}[S(q, Y)]$ 才能达到最大化。

*   **布里尔分数 (Brier Score)** $S(q, y) = -(q-y)^2$ 是评估二元事件（$y \in \{0,1\}$）概率预报 $q$ 的固有评分规则。
*   **对数分数 (Logarithmic Score)** $S(q, y) = \log q(y)$ 是评估离散或连续变量概率密度 $q(y)$ 的固有评分规则。最大化期望对数分数等价于最小化与真实分布的**[KL散度](@entry_id:140001)**（Kullback-Leibler divergence）。
*   **连续分级概率分数 (Continuous Ranked Probability Score, CRPS)** 是评估连续变量[累积分布函数](@entry_id:143135)（CDF）预报的固有评分规则。

在模型训练中，使用固有评分规则作为损失函数，可以激励模型学习生成“诚实”的、经过校准的[概率预报](@entry_id:183505) 。

理解预报[不确定性的来源](@entry_id:164809)也至关重要。总的预测不确定性可以分解为两部分 ：

1.  **随机不确定性（Aleatoric Uncertainty）**：源于系统固有的随机性，例如未解析的[次网格尺度过程](@entry_id:1132602)或测量噪声。即使我们拥有完美的模型，这种不确定性也无法消除。在贝叶斯模型中，它由 $\mathbb{E}_{\theta}[\text{Var}(Y|\mathbf{x},\theta)]$ 项表示。

2.  **认知不确定性（Epistemic Uncertainty）**：源于我们对模型本身的不确定性，例如模型参数或结构的不确定性，这通常是由于有限的训练数据造成的。原则上，这种不确定性可以通过更多的训练数据或更好的模型架构来减小。在贝叶斯模型中，它由 $\text{Var}_{\theta}[\mathbb{E}(Y|\mathbf{x},\theta)]$ 项表示。

#### 时间序列数据的验证

在评估为天气预报等时间序列任务训练的模型时，必须特别注意防止**[数据泄露](@entry_id:260649)**（data leakage）。由于数据点在时间上存在自相关，标准的随机[交叉验证方法](@entry_id:634398)是无效的，因为它会导致训练集和[验证集](@entry_id:636445)中的样本高度相关，从而产生过于乐观的性能评估。

正确的做法是采用**块状[交叉验证](@entry_id:164650)**（block-wise cross-validation），特别是**前向验证**（forward-chaining or walk-forward validation）。数据必须按时间顺序分割。更重要的是，在[训练集](@entry_id:636396)和验证/[测试集](@entry_id:637546)之间必须插入一个**清洗缓冲区**（purge buffer），其长度 $P$ 必须足以覆盖数据的[自相关时间](@entry_id:140108) $\tau_m$ 和模型的预报时效 $L$，即 $P \ge \tau_m + L$。这确保了训练期间的任何信息（包括最晚的训练目标）与验证期间的任何信息（包括最早的验证预测因子）在时间上是充分分离的 。

#### 物理引导的机器学习

纯粹的“黑箱”数据驱动模型在面对**分布外**（Out-of-Distribution, OOD）样本时，可能会表现出灾难性的失败，例如产生物理上不可能的结果（如负降水）或违反基本守恒律（如能量守恒或位涡守恒）。这是因为这些模型仅仅学习了训练数据中的统计相关性，而没有内化驱动系统的基本物理定律。

解决这一认知局限性的前沿方向是**物理引导的机器学习**（physics-informed machine learning）。其核心思想是将已知的物理知识融入模型架构或训练过程中。例如，我们可以用一个可解释的、保证水分守恒和正定性的“灰箱”[参数化](@entry_id:265163)方案来取代一个用于模拟[湿对流](@entry_id:1128092)的黑箱神经网络。

评估这类[混合模型](@entry_id:266571)也需要超越传统的统计指标。必须设计专门的物理测试来验证模型是否遵守了基本物理原则，例如，在理想化的绝热无摩擦设置下检查模型的[位涡守恒](@entry_id:270380)情况，或在[封闭系统](@entry_id:139565)中检查其水物质和能量收支。只有通过这种结合了统计性能和物理保真度的双重验证，我们才能建立对数据驱动[天气预报模型](@entry_id:1134014)在真实、复杂情景下可靠性的信心 。