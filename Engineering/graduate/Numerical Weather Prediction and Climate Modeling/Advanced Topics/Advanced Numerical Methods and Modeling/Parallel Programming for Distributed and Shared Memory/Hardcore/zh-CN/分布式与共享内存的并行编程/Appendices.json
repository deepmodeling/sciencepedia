{
    "hands_on_practices": [
        {
            "introduction": "在共享内存编程中，多个线程访问同一内存位置可能导致数据竞争，这是一个导致非确定性和错误结果的关键错误。本练习  通过数值模型中常见的“分散相加”(scatter-add)模式，提供了对这一问题的动手实践。你将实现一个有问题的朴素版本以亲身见证竞争条件，然后将其与两种健壮的解决方案——原子操作和归约进行对比，从而巩固你对基本同步技术的理解。",
            "id": "4074054",
            "problem": "考虑在数值天气预报中对一维预报场进行共享内存并行更新。设 $q_i^n$ 表示在离散时间层 $n$ 上，单元索引为 $i \\in \\{0,1,\\dots,N-1\\}$ 的预报变量的单元平均值。假设有 $M$ 个独立的贡献（例如，在面上计算的通量散度、次网格倾向或物理参数化增量）必须累加到场中以形成 $q^{n+1}$。每个贡献 $k \\in \\{0,1,\\dots,M-1\\}$ 由一个目标单元索引 $d_k \\in \\{0,1,\\dots,N-1\\}$ 和一个增量值 $\\Delta_k \\in \\mathbb{R}$ 来表征，更新的串行数学规范为\n$$\nq_i^{n+1} \\;=\\; q_i^n \\;+\\; \\sum_{k:\\, d_k = i} \\Delta_k \\quad \\text{for all } i \\in \\{0,1,\\dots,N-1\\}.\n$$\n定义任务。使用标准的共享内存并发术语，为该场景精确定义数据竞争。从基本定义开始：在一个具有先行发生关系的共享内存程序中，当存在两个或多个动态操作访问同一内存位置，其中至少一个是写操作，且这些访问没有被先行发生关系所排序时，就会发生数据竞争。然后，将此定义具体化到从 $q_i^n$ 和 $\\{(d_k,\\Delta_k)\\}_{k=0}^{M-1}$ 实现 $q_i^{n+1}$ 所需的读-改-写累加操作。\n\n构造任务。构造一个最小的并行化思想实验，以展示在这种累加中存在的竞争：将许多 $k$ 的 $q[d_k] \\mathrel{+}= \\Delta_k$ 并行更新建模为对同一内存位置 $q[i]$ 的并发读-改-写操作。解释为什么在没有同步的情况下，对于 $d_k = d_{k'} = i$，并发操作 $q[i] \\leftarrow q[i] + \\Delta_k$ 和 $q[i] \\leftarrow q[i] + \\Delta_{k'}$ 会因写-写冲突或丢失更新而丢失增量。然后展示两种基于第一性原理的解决方案：\n- 原子散射-加法语义：使每次更新 $q[d_k] \\mathrel{+}= \\Delta_k$ 成为一次原子的读-改-写操作，以便每个增量都被精确地应用一次。\n- 分组归约：对每个 $i$ 计算分组和 $S_i = \\sum_{k:\\, d_k = i} \\Delta_k$，然后执行单次写入 $q[i] \\leftarrow q[i] + S_i$，这等同于确定性的归约。\n\n编程任务。编写一个完整的、可运行的程序，对于给定的测试用例集合，为每个用例计算三个数组：\n- 一个朴素的向量化散射-加法，它通过执行 $q[d_k] \\mathrel{+}= \\Delta_k$ 来模拟有竞争的、非原子的重叠写入。此操作使用高级索引语义，不会将重叠部分确定性地解析为求和。\n- 一个类原子的散射-加法，它保证重复的索引 $d_k$ 会导致真正的累加，模拟正确的原子加法。\n- 一个分组归约，它为所有 $i$ 计算 $S_i$，然后对 $q[i]$ 进行一次精确更新。\n\n对于每个测试用例，计算两个标量诊断量：朴素结果与类原子结果之间的最大绝对差，以及分组归约结果与类原子结果之间的最大绝对差。这些诊断量必须是浮点数。\n\n测试套件。使用以下五个用例；在每个用例中，假设 $q^n$ 恒为零以隔离累加效应，并且所有数组都是一维的：\n- 用例 1（无冲突，理想路径）：$N = 5$, $M = 4$, $d = [0,1,2,3]$, $\\Delta = [1.0,1.0,1.0,1.0]$。\n- 用例 2（在一个单元上完全冲突）：$N = 3$, $M = 3$, $d = [1,1,1]$, $\\Delta = [0.1,0.2,0.3]$。\n- 用例 3（边界索引和相消增量）：$N = 4$, $M = 3$, $d = [3,3,0]$, $\\Delta = [-2.0,2.0,5.0]$。\n- 用例 4（空贡献边界情况）：$N = 10$, $M = 0$, $d = []$, $\\Delta = []$。\n- 用例 5（使用固定种子的随机压力测试）：$N = 100$, $M = 1000$，从 $\\{0,1,\\dots,99\\}$ 中独立且均匀地抽取 $d_k$，并从标准正态分布 $\\mathcal{N}(0,1)$ 中独立抽取 $\\Delta_k$，使用固定的伪随机种子以使结果具有确定性。\n\n最终输出格式。你的程序应生成单行输出，包含一个类似 JSON 的列表，长度为 5，其中第 $j$ 个元素是一个双元素列表 $[x_j,y_j]$。这里 $x_j$ 是用例 $j$ 中朴素结果与类原子结果之间的最大绝对差，而 $y_j$ 是用例 $j$ 中分组归约结果与类原子结果之间的最大绝对差。该行不得包含任何额外注释，例如：\n`[[0.0,0.0],[0.3,0.0],[2.0,0.0],[0.0,0.0],[\\ldots,0.0]]`\n单位。此问题中没有物理单位或角度；所有输出均为实数。将所有数字表示为普通小数。分组归约和类原子的结果应在舍入误差范围内一致，因此在这些用例中，$y_j$ 预计将精确为 $0.0$，而 $x_j$ 仅在没有索引冲突时才为 $0.0$。程序不得要求任何输入。它必须是自包含且确定性的。",
            "solution": "所提出的问题是有效的。它在科学上基于并行计算的原理，问题阐述清晰，目标明确，数据充分，语言客观，且内部一致。它探讨了在共享内存架构上实现数值算法时一个基本且非平凡的挑战。因此，我们可以着手提供一个解决方案。\n\n该问题包括三个任务：在并行散射-加法操作的背景下定义数据竞争，构造一个思想实验来说明竞争及其解决方案，以及实现一个程序来展示存在竞争的实现和正确实现的数值结果差异。\n\n**定义任务：并行累加中的数据竞争**\n\n数据竞争的基本定义如下：在一个具有明确先行发生关系的共享内存程序中，当存在两个或多个并发操作访问同一内存位置，其中至少一个操作是写操作，并且这些访问没有被先行发生关系所排序时，就会发生数据竞争。\n\n我们将此定义具体化到数值更新问题上。串行数学规范由下式给出\n$$\nq_i^{n+1} \\;=\\; q_i^n \\;+\\; \\sum_{k:\\, d_k = i} \\Delta_k \\quad \\text{for all } i \\in \\{0,1,\\dots,N-1\\}.\n$$\n并行实现可能会将计算和应用增量 $\\{\\Delta_k\\}_{k=0}^{M-1}$ 的任务分配给不同的线程。一种常见的并行策略是让每个线程迭代 $M$ 个贡献的一个子集。对于分配给它的每个贡献 $k$，线程执行更新 $q_{d_k} \\mathrel{+}= \\Delta_k$。\n\n共享内存位置是存储预报场的数组元素，我们表示为 $q$。具体来说，被访问的内存是对应于 $q_{i}$（$i \\in \\{0, \\dots, N-1\\}$）的位置。操作 $q_{d_k} \\mathrel{+}= \\Delta_k$ 不是单一的、瞬时的机器指令。它是一个复合的**读-改-写（RMW）**序列：\n1.  **读**：将 $q_{d_k}$ 的当前值加载到一个临时寄存器中。设此为 $v_{\\text{old}} \\leftarrow q_{d_k}$。\n2.  **改**：将增量加到寄存器中的值上。设此为 $v_{\\text{new}} \\leftarrow v_{\\text{old}} + \\Delta_k$。\n3.  **写**：将寄存器中的新值写回到 $q_{d_k}$ 的内存位置。设此为 $q_{d_k} \\leftarrow v_{\\text{new}}$。\n\n现在，考虑两个并发线程，线程 A 和线程 B，分别被分配了贡献 $k_A$ 和 $k_B$，且它们的目标索引相同：$d_{k_A} = d_{k_B} = i$。\n- 线程 A 打算对内存位置 $q_i$ 执行 $\\Delta_{k_A}$ 的 RMW 序列。\n- 线程 B 打算对内存位置 $q_i$ 执行 $\\Delta_{k_B}$ 的 RMW 序列。\n\n由于两个线程都访问同一内存位置 $q_i$，并且两个操作都涉及写操作，如果线程 A 的操作和线程 B 的操作的执行没有被先行发生关系所排序，就会发生数据竞争。在典型的非同步并行执行中，不保证存在这样的排序。两个线程各自的读、改、写步骤可能会以不可预测的方式交错执行，从而导致不正确的结果。这就为此特定的累加问题形式化了数据竞争。\n\n**构造任务：竞争条件与解决方案**\n\n我们构造一个最小的思想实验。设一个单元的初始值为 $q_i^n$。两个并发线程 A 和 B 分别负责向此单元添加增量 $\\Delta_A$ 和 $\\Delta_B$。正确的最终值应为 $q_i^{n+1} = q_i^n + \\Delta_A + \\Delta_B$。在没有同步的情况下，RMW 序列可能出现以下交错执行：\n\n1.  线程 A 将 $q_i^n$ 读入其私有寄存器。（寄存器 A 包含 $q_i^n$）\n2.  调度器抢占线程 A 并运行线程 B。\n3.  线程 B 将 $q_i^n$ 读入其私有寄存器。（寄存器 B 包含 $q_i^n$）\n4.  线程 B 计算其更新：$q_i^n + \\Delta_B$。它将此结果写回内存。内存 $q_i$ 现在的值为 $q_i^n + \\Delta_B$。\n5.  调度器恢复线程 A 的执行。\n6.  线程 A 未意识到线程 B 的活动，它基于在步骤 1 中读取的*陈旧值*来计算其更新：$q_i^n + \\Delta_A$。它将此结果写回内存。内存 $q_i$ 现在的值为 $q_i^n + \\Delta_A$。\n\n最终结果是 $q_i^n + \\Delta_A$，这意味着来自线程 B 的增量 $\\Delta_B$ 已经丢失。这种现象被称为**丢失更新**，是数据竞争的直接后果。线程 A 的写操作覆盖了线程 B 的写操作。最终状态取决于线程执行的任意时序，这是竞争条件的典型特征。\n\n两种主要策略可以解决这种竞争条件：\n\n1.  **原子散射-加法：** 此策略使整个读-改-写序列成为一个**原子操作**。硬件和/或操作系统保证原子操作能够不可分割地执行，不受访问同一内存位置的其他线程的干扰。当线程 A 开始对 $q_i$ 进行原子更新时，该内存位置被有效地“锁定”，阻止线程 B 读取它，直到线程 A 的写操作完成。这强制对冲突的访问执行串行顺序。如果线程 A 首先执行其原子 `+=` 操作，线程 B 将读取更新后的值 $q_i^n + \\Delta_A$，并正确计算出最终结果 $(q_i^n + \\Delta_A) + \\Delta_B$。每个增量 $\\Delta_k$ 都保证被精确地应用一次，从而实现数学上正确的总和。这通常被称为“散射-加法”，因为增量被“散射”到它们的目的地并相加。\n\n2.  **分组归约：** 此策略重构问题以避免多个线程写入同一目标单元。这是一个两阶段过程：\n    -   **阶段 1（归约）：** 首先，按目标索引 $i$ 对增量进行分组。对每个 $i \\in \\{0, \\dots, N-1\\}$，计算一个部分和 $S_i = \\sum_{k: d_k = i} \\Delta_k$。这个归约过程本身可以并行化。例如，可以为总和 $S$ 创建一个临时数组，并使用原子操作将贡献累加到其中。或者，可以将增量集合在线程间划分，每个线程在私有临时数组中计算其分区的总和，然后进行最终归约，将私有数组归约到全局 $S$ 数组中。\n    -   **阶段 2（更新）：** 一旦总和数组 $S$ 完成，通过对所有 $i$ 执行更新 $q_i^{n+1} = q_i^n + S_i$ 来计算最终场 $q^{n+1}$。第二阶段是易于并行的，因为每次更新都是独立的（每个目标 $i$ 只有一次写操作），因此在 $q$ 数组上不会发生竞争条件。这种方法是确定性的，并且在数学上等同于串行规范和原子散射-加法。\n\n下面的编程任务将实现一个朴素的、存在竞争条件的方法，以及类原子的散射-加法和分组归约方法，以在数值上展示这些概念。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport json\n\ndef solve():\n    \"\"\"\n    Solves the scatter-add problem for a suite of test cases, comparing\n    naive, atomic-like, and grouped reduction methods.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases_spec = [\n        # Case 1: No collisions\n        {'N': 5, 'M': 4, 'd': [0, 1, 2, 3], 'delta': [1.0, 1.0, 1.0, 1.0]},\n        # Case 2: Complete collision on one cell\n        {'N': 3, 'M': 3, 'd': [1, 1, 1], 'delta': [0.1, 0.2, 0.3]},\n        # Case 3: Boundary indices and canceling increments\n        {'N': 4, 'M': 3, 'd': [3, 3, 0], 'delta': [-2.0, 2.0, 5.0]},\n        # Case 4: Empty contributions\n        {'N': 10, 'M': 0, 'd': [], 'delta': []},\n        # Case 5: Randomized stress test\n        {'N': 100, 'M': 1000, 'random_seed': 42}\n    ]\n\n    results = []\n\n    for case in test_cases_spec:\n        N = case['N']\n        M = case['M']\n\n        if 'random_seed' in case:\n            # Generate random data for the stress test case\n            rng = np.random.default_rng(seed=case['random_seed'])\n            d = rng.integers(0, N, size=M)\n            delta = rng.normal(size=M)\n        else:\n            # Use predefined data\n            d = np.array(case['d'], dtype=int)\n            delta = np.array(case['delta'], dtype=float)\n\n        # Initial field q^n is all zeros\n        q_n = np.zeros(N, dtype=float)\n\n        # 1. Naive scatter-add (racy behavior)\n        # In NumPy, a[indices] += b is a \"buffered\" operation. If indices\n        # contains duplicates, the operation is performed for each element, and\n        # for a given index, the result of the last corresponding operation\n        # is written. This models a \"lost update\" race condition.\n        q_naive = q_n.copy()\n        if M > 0:\n            q_naive[d] += delta\n\n        # 2. Atomic-like scatter-add (correct accumulation)\n        # numpy.add.at performs an unbuffered in-place operation, which\n        # correctly accumulates values for repeated indices. This models\n        # an atomic scatter-add.\n        q_atomic = q_n.copy()\n        if M > 0:\n            np.add.at(q_atomic, d, delta)\n        \n        # 3. Grouped reduction (correct accumulation via pre-computation)\n        # This method first computes the total sum S_i for each cell i and\n        # then performs a single update per cell.\n        q_grouped = q_n.copy()\n        if M > 0:\n            # Phase 1: Compute the reduction S_i = sum_{k: d_k=i} Delta_k\n            S = np.zeros(N, dtype=float)\n            np.add.at(S, d, delta)\n            # Phase 2: Apply the single, non-conflicting update\n            q_grouped += S\n        \n        # Compute the required diagnostics\n        # max_abs_diff(naive, atomic)\n        diff_naive_atomic = np.max(np.abs(q_naive - q_atomic)) if N > 0 else 0.0\n        \n        # max_abs_diff(grouped, atomic)\n        # This should be zero up to floating point precision.\n        diff_grouped_atomic = np.max(np.abs(q_grouped - q_atomic)) if N > 0 else 0.0\n\n        results.append([float(diff_naive_atomic), float(diff_grouped_atomic)])\n\n    # Final print statement in the exact required format.\n    # The use of json.dumps ensures correct formatting without extra spaces.\n    print(json.dumps(results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "在分布式内存系统中，高效的通信至关重要，但交换边界数据通常涉及非连续的内存访问，这可能导致昂贵的手动数据打包。本练习  旨在挑战你掌握一项强大的MPI功能——派生数据类型——来解决这个问题。通过构建一个自定义的向量数据类型，你将学会如何向MPI库描述复杂的数据布局，从而实现对“幽灵区”(ghost zone)交换的直接、高性能的数据传输。",
            "id": "4074064",
            "problem": "考虑一个存储在三维网格上的大气状态变量，其索引为 $(i,j,k)$，其中 $i$ 是纬向索引，$j$ 是经向索引，$k$ 是垂直层次索引。假设采用行主序（C风格）内存布局，其中变化最快的索引是 $k$，其次是 $j$，然后是 $i$。设网格维度分别为 $N_i$、$N_j$ 和 $N_k$，每个元素是一个 $8$ 字节的 IEEE $754$ 双精度数。对于任意 $(i,j,k)$，线性内存偏移（以元素为单位）由广泛使用的映射定义：\n$$\n\\mathrm{offset}(i,j,k) = i\\cdot(N_j N_k) + j\\cdot N_k + k.\n$$\n在一种区域分解中，进程沿 $j$ 维度进行分区，每个进程必须与其相邻进程交换 $j$ 维度上的“幽灵”区（ghost zones）。一个宽度为 $G$ 的“幽灵”区包含 $j$ 维度边界上所有跨越 $k$ 的垂直列。对于一个给定的边界（低 $j$ 或高 $j$），要发送的数据是所有 $(i,j,k)$ 的集合，其中 $i\\in\\{0,\\dots,N_i-1\\}$，$j\\in J_\\mathrm{face}$（对于低边界，$J_\\mathrm{face}$ 是 $\\{0,\\dots,G-1\\}$；对于高边界，$J_\\mathrm{face}$ 是 $\\{N_j-G,\\dots,N_j-1\\}$），以及 $k\\in\\{0,\\dots,N_k-1\\}$。\n\n您必须设计一个消息传递接口（MPI）派生数据类型，该类型仅使用上述基本描述，无需应用层打包即可描述此发送模式。具体来说，构建一个矢量类型，其参数是以旧的基本数据类型（双精度元素）为单位的整数计数。然后，根据内存映射证明该派生数据类型在发送跨 $k$ 的垂直列时是免打包的，并量化每个垂直列传输的字节数，作为 $N_k$ 的函数。\n\n在数学和算法上，您的任务是：\n- 根据映射和“鬼”区宽度 $G$，为低 $j$ 和高 $j$ 边界推导出正确的矢量参数 $(\\mathrm{count}, \\mathrm{blocklength}, \\mathrm{stride})$，确保该描述普遍适用于任何满足 $G\\le N_j$ 的 $N_i$、$N_j$、$N_k$ 和 $G$。\n- 证明此派生数据类型根据映射关系，在每个块内部捕获了沿 $k$ 的连续数据段，并使用固定的步幅跨越 $i$，从而无需打包到中间缓冲区。\n- 计算每列的字节数，并以整数形式表示（单位为字节）。\n\n您的程序必须完全通过纯计算实现以下功能，无需使用MPI库：\n- 给定 $(N_i,N_j,N_k,G,\\mathrm{side})$，其中 $\\mathrm{side}\\in\\{\\text{\"low\"},\\text{\"high\"}\\}$ 指示边界，计算：\n  1. 每个垂直列的字节数 $B$，以字节为单位的整数。\n  2. 描述该边界上“幽灵”区发送缓冲区的 MPI 矢量参数 $(\\mathrm{count}, \\mathrm{blocklength}, \\mathrm{stride})$，以元素为单位。\n  3. 通过枚举“幽灵”区的内存映射预测的线性偏移量，并将其与矢量描述生成的偏移量进行比较，来断言免打包正确性的布尔值；两者必须完全匹配，才能认为该数据类型在无需应用层打包的意义上是免打包的。\n- 关于角度，未使用任何角度；不需要角度单位。\n- 字节数严格以字节表示。最终答案是整数，布尔值为 true 或 false。\n\n使用以下测试套件以确保覆盖范围：\n- 情况A（一般情况）：$N_i=4$, $N_j=5$, $N_k=10$, $G=1$, $\\mathrm{side}=\\text{\"low\"}$。\n- 情况B（更宽的“鬼”区，高边界）：$N_i=1$, $N_j=8$, $N_k=16$, $G=2$, $\\mathrm{side}=\\text{\"high\"}$。\n- 情况C（退化的 $j$）：$N_i=3$, $N_j=1$, $N_k=7$, $G=1$, $\\mathrm{side}=\\text{\"low\"}$。\n- 情况D（退化的 $k$）：$N_i=2$, $N_j=3$, $N_k=1$, $G=1$, $\\mathrm{side}=\\text{\"high\"}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目对应一个测试用例，并且本身是格式为 $[B,\\mathrm{count},\\mathrm{blocklength},\\mathrm{stride},\\mathrm{packing\\_free}]$ 的列表。例如，输出格式为 $[[b_1,c_1,bl_1,s_1,p_1],[b_2,c_2,bl_2,s_2,p_2],\\dots]$，不含空格，其中 $b_i$ 是整数（字节），$c_i$、$bl_i$、$s_i$ 是整数（元素），$p_i$ 是布尔值。",
            "solution": "该问题要求设计并验证一种消息传递接口（MPI）派生数据类型，用于描述三维网格中的“鬼”区交换，且无需手动进行数据打包。解决方案必须基于所提供的内存布局，从第一性原理推导得出。\n\n首先，我们分析内存映射以及待交换数据的结构。三维网格的维度为 $N_i, N_j, N_k$，位于索引 $(i,j,k)$ 处元素的内存偏移由行主序公式给出：\n$$\n\\mathrm{offset}(i,j,k) = i \\cdot (N_j N_k) + j \\cdot N_k + k\n$$\n该公式表明索引 $k$ 变化最快，意味着对于固定的 $(i,j)$，沿 $k$ 轴的元素（一个垂直列）在内存中是连续的。一个包含 $N_k$ 个此类元素的块之后是下一个 $j$ 索引的块，而一个包含 $N_j N_k$ 个元素（一个完整的 $j-k$ 平面）的块之后是下一个 $i$ 索引的块。\n\n为一个宽度为 $G$ 的“鬼”区发送的数据包含所有点 $(i,j,k)$，其中 $i \\in \\{0, \\dots, N_i-1\\}$，$k \\in \\{0, \\dots, N_k-1\\}$，且 $j$ 位于沿 $j$ 轴的区域分区的边界附近的特定范围 $J_{\\mathrm{face}}$ 内。对于“低”边界，$J_{\\mathrm{face}} = \\{0, \\dots, G-1\\}$；对于“高”边界，$J_{\\mathrm{face}} = \\{N_j-G, \\dots, N_j-1\\}$。\n\n我们将使用 MPI 矢量数据类型 `MPI_Type_vector`，它由三个整数参数定义：\n1.  $\\mathrm{count}$：数据类型中的块数量。\n2.  $\\mathrm{blocklength}$：每个块中的元素数量。\n3.  $\\mathrm{stride}$：从一个块的开始到下一个块的开始的内存位移（以元素为单位）。\n\n我们的目标是找到这些参数来描述“鬼”区的数据模式。让我们分析这些数据在内存中的结构。\n考虑一个固定的纬向索引 $i$ 的数据。要发送的索引是所有 $j \\in J_{\\mathrm{face}}$ 和所有 $k \\in \\{0, \\dots, N_k-1\\}$ 的 $(i,j,k)$。让我们检查它们的偏移量。\n$$\n\\mathrm{offset}(i,j,k) = i \\cdot N_j N_k + (j \\cdot N_k + k)\n$$\n对于固定的 $i$，项 $i \\cdot N_j N_k$ 是一个恒定的基准偏移量。这个 $i$ 切片内“鬼”区数据的内存布局由项 $j \\cdot N_k + k$ 决定。\n\n对于低 $j$ 边界，$j \\in \\{0, \\dots, G-1\\}$。项 $j \\cdot N_k + k$ 生成的偏移量从 $0 \\cdot N_k + 0 = 0$ 到 $(G-1) \\cdot N_k + (N_k-1) = G \\cdot N_k - 1$。这对应于一个包含 $G \\cdot N_k$ 个元素的单一连续块。该块的起始绝对偏移量是 $\\mathrm{offset}(i,0,0) = i \\cdot N_j N_k$。\n\n对于高 $j$ 边界，$j \\in \\{N_j-G, \\dots, N_j-1\\}$。我们定义一个相对索引 $j' = j - (N_j-G)$，所以 $j' \\in \\{0, \\dots, G-1\\}$。偏移项变为 $(j' + N_j - G) \\cdot N_k + k$。起始元素对应 $j=N_j-G, k=0$，其相对偏移为 $(N_j-G)N_k$。结束元素对应 $j=N_j-1, k=N_k-1$，其相对偏移为 $(N_j-1)N_k + (N_k-1) = N_j N_k - 1$。对于固定的 $i$，这些元素再次形成一个单一的连续内存块，范围从绝对偏移 $\\mathrm{offset}(i, N_j-G, 0)$ 到 $\\mathrm{offset}(i, N_j-1, N_k-1)$。这个块的大小同样是 $G \\cdot N_k$ 个元素。\n\n在这两种情况下，对于任何固定的 $i$，“鬼”区数据都形成一个大小为 $G \\cdot N_k$ 个元素的单一连续块。这立即给出了我们矢量类型的 `blocklength` 参数：\n$$\n\\mathrm{blocklength} = G \\cdot N_k\n$$\n\n接下来，我们必须考虑这些针对不同 $i$ 的块在内存中是如何排列的。数据需要涵盖从 $0$ 到 $N_i-1$ 的所有 $i$。这意味着有 $N_i$ 个这样的块。这给出了 `count` 参数：\n$$\n\\mathrm{count} = N_i\n$$\n\n最后，我们需要 `stride`：索引为 $i$ 的块的起始位置与索引为 $i+1$ 的块的起始位置之间的位移。\n对于低边界，索引 $i$ 的块的起始偏移是 $\\mathrm{offset}(i,0,0) = i \\cdot N_j N_k$。索引 $i+1$ 的块的起始偏移是 $\\mathrm{offset}(i+1,0,0) = (i+1) \\cdot N_j N_k$。步幅是它们的差值：\n$$\n\\mathrm{stride}_{\\mathrm{low}} = \\mathrm{offset}(i+1,0,0) - \\mathrm{offset}(i,0,0) = ((i+1) - i) \\cdot N_j N_k = N_j N_k\n$$\n对于高边界，索引 $i$ 的块的起始偏移是 $\\mathrm{offset}(i,N_j-G,0) = i \\cdot N_j N_k + (N_j-G)N_k$。索引 $i+1$ 的块的起始偏移是 $\\mathrm{offset}(i+1,N_j-G,0) = (i+1) \\cdot N_j N_k + (N_j-G)N_k$。步幅同样是它们的差值：\n$$\n\\mathrm{stride}_{\\mathrm{high}} = \\mathrm{offset}(i+1,N_j-G,0) - \\mathrm{offset}(i,N_j-G,0) = N_j N_k\n$$\n对于两个边界，步幅是相同的，并且与 $G$ 无关。因此，`stride` 参数是：\n$$\n\\mathrm{stride} = N_j N_k\n$$\n\n综合这些结果，描述“鬼”区数据的 MPI 矢量数据类型由参数 $(\\mathrm{count}, \\mathrm{blocklength}, \\mathrm{stride}) = (N_i, G \\cdot N_k, N_j \\cdot N_k)$ 定义。对于低边界，MPI 通信调用的起始内存地址将是元素 $(0,0,0)$ 的地址；对于高边界，则是元素 $(0, N_j-G, 0)$ 的地址。\n\n该数据类型描述是免打包的证明是直接的。我们已经表明，“鬼”区数据被构造为 $N_i$ 个段，每个 $i$ 平面一个段。每个段是大小为 $G \\cdot N_k$ 个元素的连续内存块。这些段之间由一个恒定的内存步幅 $N_j N_k$ 个元素分隔。这正是一个 `MPI_Type_vector` 用我们推导的参数所描述的内存访问模式。因此，MPI 库可以直接从这些不相交的内存位置读取（用于发送）或写入（用于接收），而无需一个中间的应用层缓冲区来手动收集或散布数据。这满足了免打包数据传输的定义。\n\n最后，我们必须计算每个垂直列传输的字节数。一个垂直列由固定的 $(i,j)$ 定义，而 $k$ 在其整个范围内变化。因此，一个垂直列包含 $N_k$ 个元素。由于每个元素是一个 $8$ 字节的双精度数，每列的总字节数 $B$ 为：\n$$\nB = 8 \\cdot N_k\n$$\n\n提供的测试用例将使用这些推导出的公式进行评估。矢量参数的正确性将通过算法进行验证：生成由该数据类型描述的内存偏移列表，并将其与通过显式枚举“鬼”区中所有 $(i,j,k)$ 索引生成的偏移列表进行比较。完全匹配将确认该数据类型的免打包正确性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes MPI vector datatype parameters for ghost zone exchange and verifies correctness.\n    \"\"\"\n    # Test suite as defined in the problem statement.\n    test_cases = [\n        (4, 5, 10, 1, \"low\"),   # Case A\n        (1, 8, 16, 2, \"high\"),  # Case B\n        (3, 1, 7, 1, \"low\"),   # Case C\n        (2, 3, 1, 1, \"high\")   # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        Ni, Nj, Nk, G, side = case\n\n        # 1. Compute bytes per vertical column (B)\n        bytes_per_element = 8\n        B = bytes_per_element * Nk\n\n        # 2. Compute MPI vector parameters (count, blocklength, stride)\n        # These are derived from the memory mapping and data structure.\n        # count: number of i-slices\n        # blocklength: contiguous block size for a fixed i (G vertical columns)\n        # stride: distance between the start of blocks in consecutive i-slices\n        count = Ni\n        blocklength = G * Nk\n        stride = Nj * Nk\n\n        # 3. Verify packing-free correctness\n        \n        # Helper for linear offset calculation\n        def get_offset(i, j, k, _nj, _nk):\n            return i * (_nj * _nk) + j * _nk + k\n\n        # Generate the list of true offsets by iterating through the specified indices\n        true_offsets = []\n        if side == \"low\":\n            j_indices = range(G)\n        else:  # side == \"high\"\n            j_indices = range(Nj - G, Nj)\n        \n        for i in range(Ni):\n            for j in j_indices:\n                for k in range(Nk):\n                    true_offsets.append(get_offset(i, j, k, Nj, Nk))\n        \n        # Generate the list of offsets using the derived vector datatype parameters\n        vector_offsets = []\n        \n        # The start of the MPI transfer is the first element of the ghost zone\n        if side == \"low\":\n            start_offset = 0 # offset(0,0,0)\n        else: # side == \"high\"\n            start_offset = get_offset(0, Nj - G, 0, Nj, Nk)\n\n        for c in range(count): # Iterate through blocks (i-slices)\n            block_start = start_offset + c * stride\n            for b in range(blocklength): # Iterate through elements within a block\n                vector_offsets.append(block_start + b)\n        \n        # The datatype is correct if the generated offset lists match exactly.\n        packing_free = (true_offsets == vector_offsets)\n\n        results.append([B, count, blocklength, stride, packing_free])\n\n    # Format the final output string exactly as required.\n    results_str = []\n    for res in results:\n        b, c, bl, s, p = res\n        p_str = str(p).lower()\n        res_str = f\"[{b},{c},{bl},{s},{p_str}]\"\n        results_str.append(res_str)\n    \n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在共享内存和分布式内存模型之间进行选择涉及根本性的权衡，尤其是在数据通信方面。本练习  将指导你完成一项基础性能分析，以量化这种差异。通过推导两种并行范式中典型“光环交换”(halo exchange)所需的数据移动成本，你将对分布式系统中固有的显式通信开销获得清晰的、定量的理解。",
            "id": "4074027",
            "problem": "一个用于数值天气预报的有限体积动力核心，在一个大小为 $n_x \\times n_y \\times n_z$ 的三维笛卡尔子域上，更新一个以双精度浮点值存储的单一标量预报场。对于每个时间积分子步，必须交换宽度为 $h$ 个单元的晕区（halo region），以满足下一次更新的模板依赖关系。\n\n考虑两种执行模式：\n\n- 使用消息传递接口（MPI）的分布式内存：子域通过在每个面上交换厚度为 $h$ 的晕板（halo slabs），与其六个面相邻的邻居进行通信。假设每个子步进行一次“仅面”交换，其中每个面发送一个完整的厚度为 $h$ 的板，其横截面积等于该面的面积，并且重叠的边和角区域不进行去重处理。将数据移动量定义为该子域在一个子步的晕圈交换期间发送给其所有邻居的总字节数；不包括接收的字节。\n\n- 使用开放多处理（OpenMP）的共享内存：同一个子域由多个线程更新，这些线程在单个共享数组上操作，并使用屏障同步；不执行显式的晕圈复制或线程间数据移动。\n\n使用核心定义，即发送的值的数量等于传输的晕圈单元的数量，并且字节数等于值的数量乘以每个值的字节大小，并假设双精度值每个占用 $8$ 字节，推导一个封闭形式的表达式（以字节为单位），表示在上述定义下一个子步中，分布式内存晕圈交换的数据移动量与共享内存模板更新的数据移动量之间的差值。将最终结果表示为关于 $n_x$、$n_y$、$n_z$ 和 $h$ 的单个解析表达式，并以字节为单位报告结果。无需四舍五入。",
            "solution": "题目要求我们计算在特定假设下，分布式内存晕圈交换和共享内存模板更新的数据移动量（以字节为单位）之间的差值。\n\n首先，我们规范化基本原则：\n\n1. 移动的字节数等于移动的值的数量乘以每个值的字节大小。设每个双精度值的字节大小为 $b = 8$。\n\n2. 在分布式内存情况下，子域与六个面邻居通信。对于每个面，发送一个厚度为 $h$ 的板，其横截面积等于该面的面积。发送的值的总数等于所有六个厚度为 $h$ 的面板中值的总和。边和角的重叠部分不进行去重，因此按面计数即可。\n\n3. 在这里定义的共享内存情况下，不存在显式的线程间晕圈区域内存复制；因此，根据数据移动量为显式发送的晕圈的定义，数据移动量等于 $0$。\n\n我们现在计算在分布式内存晕圈交换中发送的值的数量。\n\n- 考虑与 $x$ 轴正交的两个面（在索引空间中为 $x=1$ 和 $x=n_x$ 处的平面）。每个面的横截面积为 $n_y \\times n_z$，我们发送一个厚度为 $h$ 的板。通过两个 $x$ 面发送的值的数量为\n$$\n2 \\times h \\times n_y \\times n_z.\n$$\n\n- 对于与 $y$ 轴正交的两个面（在索引空间中为 $y=1$ 和 $y=n_y$ 处的平面），每个面的横截面积为 $n_x \\times n_z$。通过两个 $y$ 面发送的值的总数为\n$$\n2 \\times h \\times n_x \\times n_z.\n$$\n\n- 对于与 $z$ 轴正交的两个面（在索引空间中为 $z=1$ 和 $z=n_z$ 处的平面），每个面的横截面积为 $n_x \\times n_y$。通过两个 $z$ 面发送的值的总数为\n$$\n2 \\times h \\times n_x \\times n_y.\n$$\n\n将这些贡献相加，子域在一次晕圈交换期间发送的值的总数为\n$$\nN_{\\text{send}} \\;=\\; 2 h \\left( n_y n_z + n_x n_z + n_x n_y \\right).\n$$\n\n使用每个值的字节大小 $b = 8$，发送的总字节数为\n$$\nB_{\\text{dist}} \\;=\\; b \\, N_{\\text{send}} \\;=\\; 8 \\times 2 h \\left( n_y n_z + n_x n_z + n_x n_y \\right) \\;=\\; 16 h \\left( n_y n_z + n_x n_z + n_x n_y \\right).\n$$\n\n根据给定的共享内存情况的定义，没有显式的晕圈复制，因此\n$$\nB_{\\text{shared}} \\;=\\; 0.\n$$\n\n所要求的分布式内存和共享内存数据移动量之间的差值为\n$$\n\\Delta B \\;=\\; B_{\\text{dist}} - B_{\\text{shared}} \\;=\\; 16 h \\left( n_y n_z + n_x n_z + n_x n_y \\right).\n$$\n\n该表达式已用所需的变量表示，并且代表字节数，因为我们已经包含了每个双精度值 $8$ 字节的因子。",
            "answer": "$$\\boxed{16\\,h\\left(n_x n_y + n_x n_z + n_y n_z\\right)}$$"
        }
    ]
}