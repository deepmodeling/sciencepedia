{
    "hands_on_practices": [
        {
            "introduction": "校准古气候代用指标的一个基本挑战是，代用指标数据本身就存在测量误差。标准的回归技术忽略了这一点，导致对真实气候敏感性的系统性低估，这种现象被称为衰减偏误（attenuation bias）。本练习  将指导您运用变量误差（errors-in-variables, EIV）框架，推导出一个更准确的校准斜率估计值，并量化因忽略代用指标不确定性而产生的偏误。",
            "id": "4073673",
            "problem": "一项古气候校准研究试图在一个变量含误差（EIV）框架下，将海洋沉积物地球化学代用指标与仪器测量的海面温度关联起来。设 $Y_t$ 表示仪器测量的温度（单位：摄氏度），$X_t$ 表示潜在的、真实的代用指标状态（单位：无量纲代用指标单位）。对代用指标的观测受到分析测量误差的污染，因此观测到的代用指标为 $X_t^{\\ast} = X_t + u_t$，其中 $u_t$ 是一个均值为零、方差恒定的独立测量误差。连接温度和真实代用指标的物理校准模型是 $Y_t = \\alpha + \\beta X_t + \\varepsilon_t$，其中 $\\varepsilon_t$ 是一个均值为零的独立噪声项，且 $(u_t)$ 与 $(\\varepsilon_t)$ 和 $(X_t)$ 相互独立。在一个现代校准区间内，根据配对观测值 $\\{(Y_t, X_t^{\\ast})\\}_{t=1}^{n}$ 计算出以下汇总统计量：\n- 温度与观测代用指标之间的样本协方差为 $C_{Y X^{\\ast}} = 0.84$（摄氏度·代用指标单位）。\n- 观测代用指标的样本方差为 $V_{X^{\\ast}} = 1.50$（代用指标单位的平方）。\n- 独立的重复分析提供了一个测量误差方差的估计值，$\\sigma_u^2 = 0.60$（代用指标单位的平方）。\n\n在上述模型假设下，使用基于第一性原理的变量含误差方法来估计校准斜率 $\\beta$，并计算如果在将 $Y_t$ 对 $X_t^{\\ast}$ 进行回归时忽略 $X_t^{\\ast}$ 中的测量误差将会产生的衰减偏倚。将斜率和偏倚的单位表示为摄氏度每代用指标单位。将两个数字都四舍五入到四位有效数字。将你的最终答案以一个行矩阵的形式给出，其第一个元素是EIV斜率估计值，第二个元素是忽略测量误差时的衰减偏倚。",
            "solution": "首先验证问题以确保其是自洽的、科学上合理的和适定的。\n\n### 第 1 步：提取已知条件\n-   关联真实温度 $Y_t$ 和真实潜在代用指标状态 $X_t$ 的物理模型是：$Y_t = \\alpha + \\beta X_t + \\varepsilon_t$。\n-   观测代用指标 $X_t^{\\ast}$ 的测量模型是：$X_t^{\\ast} = X_t + u_t$。\n-   $\\varepsilon_t$ 是一个均值为零的独立噪声项。\n-   $u_t$ 是一个均值为零、方差恒定的独立测量误差，其方差为 $\\sigma_u^2$。\n-   误差序列 $(\\varepsilon_t)$ 和 $(u_t)$ 彼此独立，且与真实代用指标状态序列 $(X_t)$ 独立。\n-   温度与观测代用指标之间的样本协方差：$C_{Y X^{\\ast}} = 0.84$。\n-   观测代用指标的样本方差：$V_{X^{\\ast}} = 1.50$。\n-   测量误差的方差：$\\sigma_u^2 = 0.60$。\n\n### 第 2 步：使用提取的已知条件进行验证\n-   **科学基础：** 问题描述了一个标准的变量含误差（EIV）回归模型。这是一个基本的统计框架，广泛用于科学和工程领域中预测变量测量含误差的校准问题。该模型在数学上和科学上都是合理的。\n-   **适定性：** 问题提供了所有必要的模型假设和汇总统计量（$C_{Y X^{\\ast}}$、$V_{X^{\\ast}}$、$\\sigma_u^2$），足以推导出斜率参数 $\\beta$ 及其相关衰减偏倚的唯一估计值。\n-   **客观性：** 问题使用了统计学和回归分析中精确、标准的术语进行陈述，没有歧义或主观语言。\n\n### 第 3 步：结论与行动\n-   问题被判定为**有效**。将提供解答。\n\n### 解题推导\n\n目标是根据模型 $Y_t = \\alpha + \\beta X_t + \\varepsilon_t$ 估计真实的校准斜率 $\\beta$，而已知条件是我们只能观测到 $Y_t$ 和一个含噪声的预测变量 $X_t^{\\ast} = X_t + u_t$。\n\n我们首先建立观测变量的总体矩（方差和协方差）与底层模型参数之间的关系。我们将真实代用指标状态的方差表示为 $\\sigma_X^2 = \\text{Var}(X_t)$。\n\n观测温度 $Y_t$ 和观测代用指标 $X_t^{\\ast}$ 之间的总体协方差为：\n$$ \\text{Cov}(Y_t, X_t^{\\ast}) = \\text{Cov}(\\alpha + \\beta X_t + \\varepsilon_t, X_t + u_t) $$\n利用协方差算子的双线性性质以及独立性假设（$X_t$、$\\varepsilon_t$ 和 $u_t$ 相互独立），上式可简化为：\n$$ \\text{Cov}(Y_t, X_t^{\\ast}) = \\text{Cov}(\\beta X_t, X_t) + \\text{Cov}(\\beta X_t, u_t) + \\text{Cov}(\\varepsilon_t, X_t) + \\text{Cov}(\\varepsilon_t, u_t) $$\n$$ \\text{Cov}(Y_t, X_t^{\\ast}) = \\beta \\text{Var}(X_t) + \\beta \\text{Cov}(X_t, u_t) + \\text{Cov}(\\varepsilon_t, X_t) + \\text{Cov}(\\varepsilon_t, u_t) $$\n由于 $\\text{Cov}(X_t, u_t)=0$、$\\text{Cov}(\\varepsilon_t, X_t)=0$ 且 $\\text{Cov}(\\varepsilon_t, u_t)=0$，我们得到：\n$$ \\text{Cov}(Y_t, X_t^{\\ast}) = \\beta \\text{Var}(X_t) = \\beta \\sigma_X^2 $$\n\n观测代用指标 $X_t^{\\ast}$ 的方差是：\n$$ \\text{Var}(X_t^{\\ast}) = \\text{Var}(X_t + u_t) $$\n由于 $X_t$ 和 $u_t$ 是独立的，它们的和的方差等于它们各自方差的和：\n$$ \\text{Var}(X_t^{\\ast}) = \\text{Var}(X_t) + \\text{Var}(u_t) = \\sigma_X^2 + \\sigma_u^2 $$\n\n如果忽略测量误差 $u_t$ 并对 $Y_t$ 关于 $X_t^{\\ast}$ 进行普通最小二乘（OLS）回归，斜率估计量（我们记为 $\\hat{\\beta}_{OLS}$）的计算方式如下：\n$$ \\hat{\\beta}_{OLS} = \\frac{C_{Y X^{\\ast}}}{V_{X^{\\ast}}} $$\n在大样本极限下，该估计量收敛于：\n$$ \\beta_{OLS} = \\frac{\\text{Cov}(Y_t, X_t^{\\ast})}{\\text{Var}(X_t^{\\ast})} = \\frac{\\beta \\sigma_X^2}{\\sigma_X^2 + \\sigma_u^2} = \\beta \\left( \\frac{\\sigma_X^2}{\\sigma_X^2 + \\sigma_u^2} \\right) $$\n由于 $\\sigma_X^2 > 0$ 且 $\\sigma_u^2 > 0$，因子 $\\frac{\\sigma_X^2}{\\sigma_X^2 + \\sigma_u^2}$ 总是小于1。这表明 OLS 估计值是向零有偏的，这种现象被称为衰减偏倚。\n\n为了获得 $\\beta$ 的无偏估计，我们必须修正这种效应。EIV 方法利用了测量误差方差 $\\sigma_u^2$ 的信息。从 $X_t^{\\ast}$ 的方差方程中，我们可以将真实代用指标的未知方差表示为：\n$$ \\sigma_X^2 = \\text{Var}(X_t^{\\ast}) - \\sigma_u^2 $$\n将此代入协方差方程：\n$$ \\text{Cov}(Y_t, X_t^{\\ast}) = \\beta (\\text{Var}(X_t^{\\ast}) - \\sigma_u^2) $$\n对真实斜率 $\\beta$ 求解，通过用样本估计量代替总体矩，得到 EIV 估计量 $\\hat{\\beta}_{EIV}$：\n$$ \\hat{\\beta}_{EIV} = \\frac{C_{Y X^{\\ast}}}{V_{X^{\\ast}} - \\sigma_u^2} $$\n使用提供的数值：\n$$ C_{Y X^{\\ast}} = 0.84 $$\n$$ V_{X^{\\ast}} = 1.50 $$\n$$ \\sigma_u^2 = 0.60 $$\nEIV 斜率估计值为：\n$$ \\hat{\\beta}_{EIV} = \\frac{0.84}{1.50 - 0.60} = \\frac{0.84}{0.90} = \\frac{14}{15} \\approx 0.933333... $$\n四舍五入到四位有效数字，$\\hat{\\beta}_{EIV} = 0.9333$ 摄氏度每代用指标单位。\n\n接下来，我们计算使用朴素的 OLS 方法所产生的衰减偏倚。该偏倚是 OLS 斜率估计值与真实斜率（我们用其最佳估计值 $\\hat{\\beta}_{EIV}$ 代替）之间的差值。OLS 斜率估计值为：\n$$ \\hat{\\beta}_{OLS} = \\frac{C_{Y X^{\\ast}}}{V_{X^{\\ast}}} = \\frac{0.84}{1.50} = 0.56 $$\n衰减偏倚计算如下：\n$$ \\text{Bias} = \\hat{\\beta}_{OLS} - \\hat{\\beta}_{EIV} $$\n$$ \\text{Bias} = 0.56 - \\frac{14}{15} = \\frac{14}{25} - \\frac{14}{15} = 14 \\left( \\frac{1}{25} - \\frac{1}{15} \\right) = 14 \\left( \\frac{3 - 5}{75} \\right) = 14 \\left( \\frac{-2}{75} \\right) = -\\frac{28}{75} \\approx -0.373333... $$\n四舍五入到四位有效数字，衰减偏倚为 $-0.3733$ 摄氏度每代用指标单位。负号表示朴素的 OLS 回归低估了斜率的真实幅度。\n\n最终答案要求以行矩阵的形式呈现 EIV 斜率估计值和衰减偏倚。\n第一个元素：$\\hat{\\beta}_{EIV} = 0.9333$。\n第二个元素：$\\text{Bias} = -0.3733$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9333  -0.3733\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在构建校准模型时，增加更多的代用指标预测因子可能会改善对仪器数据的统计拟合，但存在过拟合的风险。为了在模型性能和复杂性之间进行权衡，我们依赖于信息准则。本练习  要求您推导并应用赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC），以客观地在两个相互竞争的校准模型中做出选择。",
            "id": "4073677",
            "problem": "一项区域夏季温度重建依赖于两种古气候代用指标对仪器记录的温度异常进行的线性校准。设目标为6月至8月平均温度异常时间序列 $\\{T_{t}\\}_{t=1}^{n}$，代用指标为标准化树轮宽度 $P_{1,t}$ 和标准化纤维素 $\\delta^{18}O$ $P_{2,t}$。考虑两个竞争性的线性校准模型，其残差为同方差、独立的高斯分布：\n- 模型 $\\mathcal{M}_{1}$: $T_{t} = \\beta_{0} + \\beta_{1} P_{1,t} + \\varepsilon_{t}$，\n- 模型 $\\mathcal{M}_{2}$: $T_{t} = \\beta_{0} + \\beta_{1} P_{1,t} + \\beta_{2} P_{2,t} + \\varepsilon_{t}$，\n\n其中 $\\varepsilon_{t} \\sim \\mathcal{N}(0,\\sigma^{2})$，而 $\\beta_{0},\\beta_{1},\\beta_{2}$ 和 $\\sigma^{2}$ 是待通过最大似然估计的参数。假设有 $n=120$ 年的成对代用指标-仪器数据，并且普通最小二乘拟合（对于高斯误差等价于最大似然估计）得到的残差平方和对于 $\\mathcal{M}_{1}$ 为 $\\mathrm{RSS}_{1} = 50.0$，对于 $\\mathcal{M}_{2}$ 为 $\\mathrm{RSS}_{2} = 45.0$。在参数计数中，将残差方差 $\\sigma^{2}$ 视为一个自由参数。\n\n从独立残差的高斯似然函数出发，推导具有残差平方和 $\\mathrm{RSS}$ 和样本量 $n$ 的线性校准模型的最大化对数似然 $\\ln \\hat{L}$，然后推导赤池信息准则（AIC, Akaike Information Criterion）和贝叶斯信息准则（BIC, Bayesian Information Criterion）作为 $\\mathrm{RSS}$、$n$ 和参数数量 $k$ 的函数表达式。计算 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$ 的 AIC 和 BIC，说明每个准则偏好哪个模型，并报告 AIC 差异 $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{2} - \\mathrm{AIC}_{1}$。\n\n将最终报告的 $\\Delta \\mathrm{AIC}$ 四舍五入到四位有效数字。将最终答案表示为一个不带单位的实数。",
            "solution": "首先将根据指定标准对问题进行验证。\n\n### 第1步：提取已知信息\n- 目标变量：6月至8月平均温度异常时间序列 $\\{T_{t}\\}_{t=1}^{n}$。\n- 代用指标变量：标准化树轮宽度 $P_{1,t}$ 和标准化纤维素 $\\delta^{18}O$ $P_{2,t}$。\n- 模型 $\\mathcal{M}_{1}$: $T_{t} = \\beta_{0} + \\beta_{1} P_{1,t} + \\varepsilon_{t}$。\n- 模型 $\\mathcal{M}_{2}$: $T_{t} = \\beta_{0} + \\beta_{1} P_{1,t} + \\beta_{2} P_{2,t} + \\varepsilon_{t}$。\n- 残差：$\\varepsilon_{t} \\sim \\mathcal{N}(0,\\sigma^{2})$，同方差且独立。\n- 样本量：$n=120$。\n- $\\mathcal{M}_{1}$ 的残差平方和：$\\mathrm{RSS}_{1} = 50.0$。\n- $\\mathcal{M}_{2}$ 的残差平方和：$\\mathrm{RSS}_{2} = 45.0$。\n- 参数计数约定：残差方差 $\\sigma^{2}$ 被视为一个自由参数。\n- 任务要求：\n    1. 推导通用线性模型的最大化对数似然 $\\ln \\hat{L}$。\n    2. 推导赤池信息准则（AIC）和贝叶斯信息准则（BIC）的表达式。\n    3. 计算两个模型的 AIC 和 BIC，并确定每个准则偏好哪个模型。\n    4. 报告 AIC 差异 $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{2} - \\mathrm{AIC}_{1}$，并四舍五入到四位有效数字。\n\n### 第2步：使用提取的已知信息进行验证\n对问题的有效性进行评估：\n- **科学依据：** 该问题设置在古气候重建的背景下，这是一个标准的科学学科。使用线性回归根据仪器记录校准代用指标数据是一种基础且广泛使用的技术。所采用的统计工具（最大似然估计、AIC、BIC）是模型选择的标准方法。该问题在科学上是合理的。\n- **良态问题：** 该问题提供了推导所需量和执行模型比较所需的所有必要信息。目标陈述清晰，并能导出一个唯一且有意义的解。\n- **客观性：** 问题以精确、定量和无偏见的语言陈述。没有主观或基于意见的元素。\n\n### 第3步：结论与行动\n该问题被确定为**有效**。现在开始推导解答。\n\n### 最大化对数似然的推导\n对于一个具有独立同分布高斯残差 $\\varepsilon_{t} \\sim \\mathcal{N}(0,\\sigma^{2})$ 的线性回归模型，单个残差 $\\varepsilon_{t} = T_t - (\\text{模型预测})_t$ 的概率密度函数为：\n$$f(\\varepsilon_{t}|\\sigma^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} \\exp\\left(-\\frac{\\varepsilon_{t}^{2}}{2\\sigma^{2}}\\right)$$\n给定 $n$ 个独立观测值的样本，似然函数 $L$ 是各个概率密度的乘积：\n$$L(\\boldsymbol{\\beta}, \\sigma^{2}) = \\prod_{t=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} \\exp\\left(-\\frac{(T_{t} - \\hat{T}_{t})^{2}}{2\\sigma^{2}}\\right)$$\n其中 $\\boldsymbol{\\beta}$ 代表回归系数向量，$\\hat{T}_{t}$ 是模型对观测值 $t$ 的预测。使用残差平方和的定义 $\\mathrm{RSS} = \\sum_{t=1}^{n} (T_{t} - \\hat{T}_{t})^{2}$，可以重写似然函数：\n$$L(\\boldsymbol{\\beta}, \\sigma^{2}) = (2\\pi\\sigma^{2})^{-n/2} \\exp\\left(-\\frac{\\mathrm{RSS}}{2\\sigma^{2}}\\right)$$\n对数似然 $\\ln L$ 为：\n$$\\ln L(\\boldsymbol{\\beta}, \\sigma^{2}) = -\\frac{n}{2}\\ln(2\\pi\\sigma^{2}) - \\frac{\\mathrm{RSS}}{2\\sigma^{2}}$$\n为了找到最大化对数似然 $\\ln \\hat{L}$，我们必须代入参数的最大似然估计（MLEs）。对于给定的 $\\sigma^2$，当 $\\mathrm{RSS}$ 最小时，对数似然最大化。问题提供了来自普通最小二乘拟合的最小化 $\\mathrm{RSS}$ 值，这些值即为回归系数 $\\boldsymbol{\\beta}$ 的最大似然估计。\n\n接下来，我们通过对 $\\ln L$ 关于 $\\sigma^{2}$ 求导并令结果为零，来找到方差的最大似然估计 $\\hat{\\sigma}^{2}$：\n$$\\frac{\\partial (\\ln L)}{\\partial \\sigma^{2}} = \\frac{\\partial}{\\partial \\sigma^{2}}\\left(-\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^{2}) - \\frac{\\mathrm{RSS}}{2\\sigma^{2}}\\right)$$\n$$\\frac{\\partial (\\ln L)}{\\partial \\sigma^{2}} = -\\frac{n}{2\\sigma^{2}} + \\frac{\\mathrm{RSS}}{2(\\sigma^{2})^{2}} = 0$$\n解出 $\\sigma^{2}$ 得到方差的最大似然估计：\n$$\\frac{\\mathrm{RSS}}{2(\\sigma^{2})^{2}} = \\frac{n}{2\\sigma^{2}} \\implies \\hat{\\sigma}^{2} = \\frac{\\mathrm{RSS}}{n}$$\n将此最大似然估计 $\\hat{\\sigma}^{2}$ 代回对数似然函数，得到最大化对数似然 $\\ln \\hat{L}$：\n$$\\ln \\hat{L} = -\\frac{n}{2}\\ln(2\\pi\\hat{\\sigma}^{2}) - \\frac{\\mathrm{RSS}}{2\\hat{\\sigma}^{2}} = -\\frac{n}{2}\\ln\\left(2\\pi \\frac{\\mathrm{RSS}}{n}\\right) - \\frac{\\mathrm{RSS}}{2(\\mathrm{RSS}/n)}$$\n$$\\ln \\hat{L} = -\\frac{n}{2}\\ln\\left(\\frac{2\\pi \\mathrm{RSS}}{n}\\right) - \\frac{n}{2}$$\n\n### AIC 和 BIC 表达式的推导\n赤池信息准则（AIC）定义为 $\\mathrm{AIC} = 2k - 2 \\ln \\hat{L}$，其中 $k$ 是估计参数的总数。代入 $\\ln \\hat{L}$ 的表达式：\n$$\\mathrm{AIC} = 2k - 2\\left[-\\frac{n}{2}\\ln\\left(\\frac{2\\pi \\mathrm{RSS}}{n}\\right) - \\frac{n}{2}\\right]$$\n$$\\mathrm{AIC} = 2k + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}}{n}\\right) + n$$\n贝叶斯信息准则（BIC）定义为 $\\mathrm{BIC} = k\\ln(n) - 2 \\ln \\hat{L}$。代入 $\\ln \\hat{L}$ 的表达式：\n$$\\mathrm{BIC} = k\\ln(n) - 2\\left[-\\frac{n}{2}\\ln\\left(\\frac{2\\pi \\mathrm{RSS}}{n}\\right) - \\frac{n}{2}\\right]$$\n$$\\mathrm{BIC} = k\\ln(n) + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}}{n}\\right) + n$$\n\n### 模型比较\n我们现在将这些准则应用于两个模型。AIC 和 BIC 的规则都是偏好值较低的模型。\n\n**参数数量：**\n- 对于模型 $\\mathcal{M}_{1}$：参数为 $\\beta_{0}$、$\\beta_{1}$ 和 $\\sigma^{2}$。因此，$k_{1} = 3$。\n- 对于模型 $\\mathcal{M}_{2}$：参数为 $\\beta_{0}$、$\\beta_{1}$、$\\beta_{2}$ 和 $\\sigma^{2}$。因此，$k_{2} = 4$。\n\n**数据：**\n- $n=120$.\n- $\\mathrm{RSS}_{1} = 50.0$.\n- $\\mathrm{RSS}_{2} = 45.0$.\n\n**AIC 计算与比较：**\n我们来计算两个模型的 AIC 值。\n$$\\mathrm{AIC}_{1} = 2k_{1} + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{1}}{n}\\right) + n = 2(3) + 120\\ln\\left(\\frac{2\\pi (50.0)}{120}\\right) + 120 \\approx 241.49$$\n$$\\mathrm{AIC}_{2} = 2k_{2} + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{2}}{n}\\right) + n = 2(4) + 120\\ln\\left(\\frac{2\\pi (45.0)}{120}\\right) + 120 \\approx 230.86$$\n由于 $\\mathrm{AIC}_{2}  \\mathrm{AIC}_{1}$，AIC 偏好模型 $\\mathcal{M}_{2}$。\n\n**BIC 计算与比较：**\n我们来计算两个模型的 BIC 值。\n$$\\mathrm{BIC}_{1} = k_{1}\\ln(n) + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{1}}{n}\\right) + n = 3\\ln(120) + 120\\ln\\left(\\frac{2\\pi (50.0)}{120}\\right) + 120 \\approx 249.85$$\n$$\\mathrm{BIC}_{2} = k_{2}\\ln(n) + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{2}}{n}\\right) + n = 4\\ln(120) + 120\\ln\\left(\\frac{2\\pi (45.0)}{120}\\right) + 120 \\approx 242.01$$\n由于 $\\mathrm{BIC}_{2}  \\mathrm{BIC}_{1}$，BIC 也偏好模型 $\\mathcal{M}_{2}$。在这种情况下，两个准则都同意，更复杂的模型 $\\mathcal{M}_{2}$ 在拟合优度上的提升（更低的 RSS）证明了增加额外参数 $\\beta_{2}$ 是合理的。\n\n**$\\Delta \\mathrm{AIC}$ 的计算：**\n最后，我们计算所要求的差值 $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{2} - \\mathrm{AIC}_{1}$。一个更直接的计算可以避免中间的数值代入。\n$$\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{2} - \\mathrm{AIC}_{1} = \\left[2k_{2} + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{2}}{n}\\right) + n\\right] - \\left[2k_{1} + n\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{1}}{n}\\right) + n\\right]$$\n$$\\Delta \\mathrm{AIC} = 2(k_{2} - k_{1}) + n\\left[\\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{2}}{n}\\right) - \\ln\\left(\\frac{2\\pi \\mathrm{RSS}_{1}}{n}\\right)\\right]$$\n$$\\Delta \\mathrm{AIC} = 2(k_{2} - k_{1}) + n\\ln\\left(\\frac{\\mathrm{RSS}_{2}}{\\mathrm{RSS}_{1}}\\right)$$\n代入数值：\n$$\\Delta \\mathrm{AIC} = 2(4 - 3) + 120\\ln\\left(\\frac{45.0}{50.0}\\right) = 2 + 120\\ln(0.9)$$\n使用 $\\ln(0.9) \\approx -0.10536051565$：\n$$\\Delta \\mathrm{AIC} \\approx 2 + 120(-0.10536051565) = 2 - 12.643261878 = -10.643261878$$\n四舍五入到四位有效数字得到 $-10.64$。",
            "answer": "$$\\boxed{-10.64}$$"
        },
        {
            "introduction": "代用指标系统建模的最终目标是解决反演问题：从不完整和充满噪声的代用指标记录中重建过去的气候状态。这通常是一个不适定问题（ill-posed problem），其朴素解对噪声高度敏感。本动手编码实践  介绍了作为地球物理反演基石的吉洪诺夫正则化（Tikhonov regularization），通过平衡对代用指标数据的保真度与解的光滑性，来寻找一个具有物理意义且稳定的气候重建结果。",
            "id": "4073786",
            "problem": "考虑一个线性古气候代理前向模型，其中潜在气候状态 $x \\in \\mathbb{R}^{n}$（无量纲温度异常）通过一个已知的平滑算子 $H \\in \\mathbb{R}^{m \\times n}$ 映射到代理观测值 $y \\in \\mathbb{R}^{m}$（无量纲代理异常），并带有加性确定性噪声 $\\epsilon \\in \\mathbb{R}^{m}$。所有量均为无量纲。出现在三角函数内的角度必须以弧度解释。前向模型定义为 $y = H x + \\epsilon$。您的任务是为正则化参数 $\\lambda$ 的指定值计算正则化重建 $\\hat{x}$，然后评估重建误差指标。重建应通过最小化二次 Tikhonov 泛函 $J(x) = \\lVert H x - y \\rVert_2^2 + \\lambda^2 \\lVert L x \\rVert_2^2$ 来获得，其中 $L$ 是一个惩罚 $x$ 粗糙度的一阶差分算子。\n\n使用以下具有科学依据且完全指定的设置：\n\n- 状态维度：$n = 64$。观测维度：$m = 48$。\n- 状态的离散时间指数：$t_j = j$，对于 $j = 0, 1, \\dots, n-1$。\n- 代理的离散时间指数：$p_i = i \\cdot \\frac{n}{m}$，对于 $i = 0, 1, \\dots, m-1$。\n- 平滑尺度（高斯核标准差）：$\\ell = 3.0$。\n- 前向算子 $H$ 的条目为\n$$\nH_{i j} = \\frac{\\exp\\!\\left(-\\frac{(p_i - t_j)^2}{2 \\ell^2}\\right)}{\\sum_{k=0}^{n-1} \\exp\\!\\left(-\\frac{(p_i - t_k)^2}{2 \\ell^2}\\right)} \\quad \\text{for } i = 0, \\dots, m-1,\\; j = 0, \\dots, n-1,\n$$\n也就是说，$H$ 的每一行都对以 $p_i$ 为中心的 $x$ 应用归一化的高斯加权平均。\n- 一阶差分正则化算子 $L \\in \\mathbb{R}^{(n-1) \\times n}$ 由下式给出\n$$\n(L x)_k = x_{k+1} - x_k \\quad \\text{for } k = 0, 1, \\dots, n-2.\n$$\n等价地，$L_{k,k} = -1$，$L_{k,k+1} = 1$，所有其他条目均为 $0$。\n- 真实状态 $x^{\\star} \\in \\mathbb{R}^n$ 由正弦和余弦之和定义：\n$$\nx^{\\star}_j = \\sin\\!\\left(\\frac{2 \\pi \\cdot 3 \\cdot j}{n}\\right) + 0.6 \\cos\\!\\left(\\frac{2 \\pi \\cdot 9 \\cdot j}{n}\\right) + 0.3 \\sin\\!\\left(\\frac{2 \\pi \\cdot 15 \\cdot j}{n}\\right), \\quad j = 0, 1, \\dots, n-1.\n$$\n- 确定性观测噪声为\n$$\n\\epsilon_i = 0.03 \\left[\\sin\\!\\left(0.37 \\cdot i \\right) + 0.5 \\cos\\!\\left(0.13 \\cdot i \\right)\\right], \\quad i = 0, 1, \\dots, m-1.\n$$\n- 观测值由 $y = H x^{\\star} + \\epsilon$ 给出。\n\n对于每个指定的正则化强度 $\\lambda$，计算最小化 $J(x)$ 的正则化解 $\\hat{x}$，然后评估以下误差指标：\n- 相对重建误差\n$$\nE_{\\mathrm{rel}}(\\hat{x}) = \\frac{\\lVert \\hat{x} - x^{\\star} \\rVert_2}{\\lVert x^{\\star} \\rVert_2}.\n$$\n- 归一化均方根误差 (NRMSE) 定义为\n$$\nE_{\\mathrm{nrmse}}(\\hat{x}) = \\frac{\\sqrt{\\frac{1}{n} \\sum_{j=0}^{n-1} \\left( \\hat{x}_j - x^{\\star}_j \\right)^2}}{\\sqrt{\\frac{1}{n} \\sum_{j=0}^{n-1} \\left( x^{\\star}_j - \\bar{x}^{\\star} \\right)^2}},\n$$\n其中 $\\bar{x}^{\\star} = \\frac{1}{n} \\sum_{j=0}^{n-1} x^{\\star}_j$ 是 $x^{\\star}$ 的平均值。\n- 每个观测的数据失配度\n$$\nE_{\\mathrm{misfit}}(\\hat{x}) = \\frac{\\lVert H \\hat{x} - y \\rVert_2}{\\sqrt{m}}.\n$$\n- 粗糙度比率\n$$\nE_{\\mathrm{rough}}(\\hat{x}) = \\frac{\\lVert L \\hat{x} \\rVert_2}{\\lVert L x^{\\star} \\rVert_2}.\n$$\n\n测试套件：\n- 情况 1：$\\lambda = 10^{-6}$。\n- 情况 2：$\\lambda = 10^{-2}$。\n- 情况 3：$\\lambda = 5 \\cdot 10^{-1}$。\n\n您的程序必须：\n- 完全按照上述定义构造 $H$、$L$、$x^{\\star}$、$\\epsilon$ 和 $y$。\n- 对于每个测试用例，计算与定义一致的 $J(x)$ 的数值精确最小化子 $\\hat{x}$。\n- 按顺序 $\\left[E_{\\mathrm{rel}}, E_{\\mathrm{nrmse}}, E_{\\mathrm{misfit}}, E_{\\mathrm{rough}}\\right]$ 计算每种情况下的四个指标。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个元素对应一个测试用例，并且本身是四个指标（四舍五入到六位小数）的列表。最终输出格式必须完全是\n$$\n\\left[ [e_{11}, e_{12}, e_{13}, e_{14}], [e_{21}, e_{22}, e_{23}, e_{24}], [e_{31}, e_{32}, e_{33}, e_{34}] \\right]\n$$\n打印为单行，没有空格，例如\n$$\n\\left[[0.123456,0.234567,0.345678,0.456789],[\\dots],[\\dots]\\right].\n$$",
            "solution": "问题陈述经评估有效。它具有科学依据，数学上适定，客观且自洽。它提出了一个用于线性反演模型的标准 Tikhonov 正则化问题，这是科学计算和数据分析中的常见任务，所有参数、算子和函数都有明确定义。没有矛盾、歧义或谬误。\n\n任务是找到最小化 Tikhonov 泛函 $J(x)$ 的状态向量 $\\hat{x} \\in \\mathbb{R}^n$：\n$$\nJ(x) = \\lVert H x - y \\rVert_2^2 + \\lambda^2 \\lVert L x \\rVert_2^2\n$$\n其中 $H \\in \\mathbb{R}^{m \\times n}$ 是前向算子，$y \\in \\mathbb{R}^m$ 是观测向量，$L \\in \\mathbb{R}^{(n-1) \\times n}$ 是正则化算子，$\\lambda$ 是正则化参数。所有量都在问题描述中提供。\n\n泛函 $J(x)$ 是 $x$ 的二次函数。存在唯一的最小化子 $\\hat{x}$，可以通过计算 $J(x)$ 关于 $x$ 的梯度并将其设为零来找到。首先，我们使用转置展开平方欧几里得范数：\n$$\nJ(x) = (H x - y)^T (H x - y) + \\lambda^2 (L x)^T (L x)\n$$\n展开乘积得到：\n$$\nJ(x) = (x^T H^T - y^T)(H x - y) + \\lambda^2 x^T L^T L x\n$$\n$$\nJ(x) = x^T H^T H x - x^T H^T y - y^T H x + y^T y + \\lambda^2 x^T L^T L x\n$$\n由于 $y^T H x$ 是一个标量，它等于其转置，即 $(y^T H x)^T = x^T H^T y$。因此，我们可以合并交叉项：\n$$\nJ(x) = x^T (H^T H + \\lambda^2 L^T L) x - 2 y^T H x + y^T y\n$$\n$J(x)$ 关于向量 $x$ 的梯度是：\n$$\n\\nabla_x J(x) = \\frac{\\partial}{\\partial x} \\left( x^T (H^T H + \\lambda^2 L^T L) x - 2 (H^T y)^T x + y^T y \\right)\n$$\n使用向量微积分的标准法则，特别是对于对称矩阵 $A$，有 $\\nabla_x(x^T A x) = 2Ax$，以及 $\\nabla_x(b^T x) = b$，我们得到：\n$$\n\\nabla_x J(x) = 2 (H^T H + \\lambda^2 L^T L) x - 2 H^T y\n$$\n将梯度设为零向量，$\\nabla_x J(\\hat{x}) = 0$，得到称为正则化问题的正规方程的线性方程组：\n$$\n(H^T H + \\lambda^2 L^T L) \\hat{x} = H^T y\n$$\n这是一个 $A\\hat{x} = b$ 形式的线性系统，其中矩阵 $A = H^T H + \\lambda^2 L^T L$ 是一个 $n \\times n$ 矩阵，向量 $b = H^T y$ 的大小为 $n \\times 1$。对于任何 $\\lambda  0$，矩阵 $A$ 都是对称正定的，这保证了唯一的稳定解 $\\hat{x}$ 的存在。这个解可以通过数值求解线性系统来找到。\n\n计算过程如下：\n1. 按照规定构造向量和矩阵：状态时间指数 $t_j$、代理时间指数 $p_i$、真实状态 $x^{\\star}$、噪声向量 $\\epsilon$、前向算子 $H$ 和正则化算子 $L$。\n2. 计算观测向量 $y = H x^{\\star} + \\epsilon$。\n3. 对于测试套件中给定的每个正则化参数 $\\lambda$ 值：\n    a. 构造 $n \\times n$ 矩阵 $A = H^T H + \\lambda^2 L^T L$。\n    b. 构造 $n \\times 1$ 向量 $b = H^T y$。\n    c. 求解线性系统 $A\\hat{x} = b$ 以获得重建状态 $\\hat{x}$。\n    d. 使用计算出的 $\\hat{x}$ 和已知的真实状态 $x^{\\star}$，计算四个指定的误差指标：相对重建误差 $E_{\\mathrm{rel}}(\\hat{x})$、归一化均方根误差 $E_{\\mathrm{nrmse}}(\\hat{x})$、每个观测的数据失配度 $E_{\\mathrm{misfit}}(\\hat{x})$ 和粗糙度比率 $E_{\\mathrm{rough}}(\\hat{x})$。\n4. 收集每个测试用例的最终结果并按规定格式化。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov-regularized paleoclimate reconstruction problem\n    and computes the specified error metrics for different regularization strengths.\n    \"\"\"\n    \n    # Define the test cases (regularization parameters) from the problem statement.\n    test_cases = [1e-6, 1e-2, 5e-1]\n\n    # --- Step 1: Construct all specified model components ---\n\n    # Define dimensions and parameters\n    n = 64  # State dimension\n    m = 48  # Observation dimension\n    l_scale = 3.0  # Smoothing scale\n\n    # Define discrete time indices\n    t = np.arange(n, dtype=np.float64)\n    p = np.arange(m, dtype=np.float64) * (n / m)\n\n    # Construct the forward operator H\n    # Using broadcasting: p[:, None] is (m, 1), t[None, :] is (1, n)\n    h_numerator = np.exp(-(p[:, None] - t[None, :])**2 / (2 * l_scale**2))\n    h_denominator = np.sum(h_numerator, axis=1, keepdims=True)\n    H = h_numerator / h_denominator\n\n    # Construct the first-difference regularization operator L\n    L = np.zeros((n - 1, n), dtype=np.float64)\n    rows = np.arange(n - 1)\n    L[rows, rows] = -1.0\n    L[rows, rows + 1] = 1.0\n\n    # Construct the true state x_star\n    j_indices = np.arange(n, dtype=np.float64)\n    x_star = (np.sin(2 * np.pi * 3 * j_indices / n) +\n              0.6 * np.cos(2 * np.pi * 9 * j_indices / n) +\n              0.3 * np.sin(2 * np.pi * 15 * j_indices / n))\n\n    # Construct the deterministic observation noise epsilon\n    i_indices = np.arange(m, dtype=np.float64)\n    epsilon = 0.03 * (np.sin(0.37 * i_indices) + 0.5 * np.cos(0.13 * i_indices))\n\n    # Construct the observations y\n    y = H @ x_star + epsilon\n\n    # --- Step 2: Pre-compute components for efficiency ---\n\n    # Pre-calculate norms of true state components for metric calculations\n    norm_x_star = np.linalg.norm(x_star)\n    # Denominator for NRMSE: ||x* - mean(x*)||_2\n    norm_x_star_centered = np.linalg.norm(x_star - np.mean(x_star))\n    norm_Lx_star = np.linalg.norm(L @ x_star)\n    \n    # Pre-compute matrix products for the normal equations\n    HTH = H.T @ H\n    LTL = L.T @ L\n    HTy = H.T @ y\n\n    all_case_results = []\n    \n    # --- Step 3: Loop through test cases, solve, and evaluate metrics ---\n\n    for lam in test_cases:\n        # Form the system matrix for the normal equations\n        A = HTH + lam**2 * LTL\n        \n        # Solve the linear system A * x_hat = HTy for x_hat\n        x_hat = np.linalg.solve(A, HTy)\n\n        # Calculate the four error metrics\n        # 1. Relative reconstruction error\n        E_rel = np.linalg.norm(x_hat - x_star) / norm_x_star\n\n        # 2. Normalized root-mean-square error (NRMSE)\n        # NRMSE = RMSE(x_hat, x_star) / std(x_star)\n        # This is equivalent to norm(x_hat - x_star) / norm(x_star - mean(x_star))\n        E_nrmse = np.linalg.norm(x_hat - x_star) / norm_x_star_centered\n        \n        # 3. Data misfit per observation\n        E_misfit = np.linalg.norm(H @ x_hat - y) / np.sqrt(m)\n        \n        # 4. Roughness ratio\n        E_rough = np.linalg.norm(L @ x_hat) / norm_Lx_star\n\n        all_case_results.append([E_rel, E_nrmse, E_misfit, E_rough])\n\n    # --- Step 4: Format and print the final output ---\n\n    # Format each list of metrics into a comma-separated string rounded to 6 decimal places\n    case_strings = [f\"[{','.join(f'{value:.6f}' for value in metrics)}]\" for metrics in all_case_results]\n    \n    # Join all case strings into the final required format\n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}