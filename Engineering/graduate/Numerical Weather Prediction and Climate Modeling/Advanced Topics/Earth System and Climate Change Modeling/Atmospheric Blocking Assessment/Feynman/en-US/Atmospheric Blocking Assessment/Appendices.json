{
    "hands_on_practices": [
        {
            "introduction": "The first step in assessing atmospheric blocking is to translate its physical definition into a quantitative, computational tool. This practice guides you through the implementation of one of the most foundational and widely used diagnostics: the Tibaldi-Molteni (TM) index. By working with a controlled, synthetic dataset, you will implement the core logic of the TM index, which identifies blocking by detecting a reversal in the meridional geopotential height gradient, and apply a critical persistence criterion to distinguish transient features from robust blocking events .",
            "id": "4013020",
            "problem": "You are given a conceptual daily dataset of 500 hectopascal geopotential height (Z500) over the Northern Hemisphere. The acronym Z500 stands for 500 hectopascal geopotential height. The task is to implement the Tibaldi–Molteni (TM) index for atmospheric blocking detection and compute a blocking frequency climatology by longitude and season, using a synthetic but scientifically consistent dataset. All angles must be treated in degrees, and all geopotential heights must be treated in meters. Frequencies must be expressed as decimal fractions.\n\nFoundational base and definitions:\n- Atmospheric blocking in midlatitudes is associated with a reversal of the meridional gradient of geopotential height at 500 hectopascal, which implies a reversal of the large-scale geostrophic wind. From geostrophic balance, the zonal geostrophic wind $u_g$ is approximately proportional to the meridional gradient of geopotential height, $u_g \\propto -\\partial Z / \\partial \\phi$, where $\\phi$ is latitude and $Z$ is geopotential height. Therefore, a sign reversal in $\\partial Z / \\partial \\phi$ across a latitude band is indicative of blocking.\n- The Tibaldi–Molteni (TM) index detects blocking through finite differences of $Z$ between three latitudes: a southern latitude $\\phi_S$, a central latitude $\\phi_0$, and a northern latitude $\\phi_N$, at fixed longitude $\\lambda$. Define the southern gradient\n$$\n\\mathrm{GHGS}(\\lambda, t) = \\frac{Z(\\phi_0,\\lambda,t) - Z(\\phi_S,\\lambda,t)}{\\phi_0 - \\phi_S} \\quad \\text{[m per degree]},\n$$\nand the northern gradient\n$$\n\\mathrm{GHGN}(\\lambda, t) = \\frac{Z(\\phi_N,\\lambda,t) - Z(\\phi_0,\\lambda,t)}{\\phi_N - \\phi_0} \\quad \\text{[m per degree]}.\n$$\nA day $t$ at longitude $\\lambda$ is classified as blocked by the TM index if $\\mathrm{GHGS}(\\lambda, t) > 0$ and $\\mathrm{GHGN}(\\lambda, t) \\lt -10$ [m per degree], which represent the standard thresholds used in the TM index.\n- Persistence requirement: A longitude is considered blocked on day $t$ only if the TM blocking condition holds for at least $5$ consecutive days at that longitude. That is, if there is a run of $L \\ge 5$ consecutive days for which the above TM condition is satisfied, then all those $L$ days are marked as blocked; isolated shorter runs are ignored.\n- Blocking frequency climatology by season: For each season $S$ and longitude $\\lambda$, define the blocking frequency\n$$\nf_S(\\lambda) = \\frac{B_S(\\lambda)}{N_S},\n$$\nwhere $B_S(\\lambda)$ is the number of days in season $S$ at longitude $\\lambda$ that meet the persistence-qualified TM blocking condition, and $N_S$ is the total number of days in season $S$. The seasons are defined by calendar months: boreal winter December–January–February (DJF), spring March–April–May (MAM), summer June–July–August (JJA), and autumn September–October–November (SON). Use a non-leap year with monthly day counts $\\{31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31\\}$ for January to December, respectively, so $N_{\\mathrm{DJF}} = 90$, $N_{\\mathrm{MAM}} = 92$, $N_{\\mathrm{JJA}} = 92$, and $N_{\\mathrm{SON}} = 91$.\n\nGrid and data specification:\n- Latitude grid: $\\phi \\in \\{20^\\circ, 22.5^\\circ, \\dots, 80^\\circ\\}$ with $2.5^\\circ$ spacing. Longitude grid: $\\lambda \\in \\{0^\\circ, 2.5^\\circ, \\dots, 357.5^\\circ\\}$ with $2.5^\\circ$ spacing. Daily time axis for one non-leap year ($365$ days).\n- TM index latitudes: use $\\phi_S = 40^\\circ$, $\\phi_0 = 60^\\circ$, and $\\phi_N = 80^\\circ$.\n- Base field: construct a zonal-mean geopotential height profile decreasing with latitude,\n$$\nZ_0(\\phi) = Z_{\\mathrm{ref}} - \\alpha \\, \\phi,\n$$\nwith $Z_{\\mathrm{ref}} = 5800$ [m] and $\\alpha = 6$ [m per degree]. The full field is defined initially by $Z(\\phi,\\lambda,t) = Z_0(\\phi)$ for all $\\lambda$ and $t$ (no noise). This produces background meridional gradients around $-6$ [m per degree] in midlatitudes, consistent with typical midlatitude conditions (non-blocked).\n\nTM anomalies to define the test suite:\nYou must superimpose localized anomalies to create and test blocking detection. The anomalies below must be added to $Z(\\phi,\\lambda,t)$ only at the specified latitude(s), longitude(s), and day ranges, with all other values unmodified.\n\n- Test Case 1 (happy path, DJF, strong blocking): At longitude $\\lambda = 0^\\circ$, for days January $15$ through January $21$ inclusive (i.e., $7$ consecutive days), add $+300$ [m] to $Z(\\phi_0,\\lambda,t)$ at latitude $\\phi_0 = 60^\\circ$. No other changes. Expected effect: $\\mathrm{GHGS} > 0$ and $\\mathrm{GHGN} \\ll -10$ [m per degree].\n- Test Case 2 (boundary threshold case, MAM, should not block): At longitude $\\lambda = 30^\\circ$, for days April $10$ through April $14$ inclusive (i.e., $5$ consecutive days), add $+80$ [m] to $Z(\\phi_0,\\lambda,t)$ at latitude $\\phi_0 = 60^\\circ$, and add $-100$ [m] to $Z(\\phi_S,\\lambda,t)$ at latitude $\\phi_S = 40^\\circ$. No other changes. Expected effect: $\\mathrm{GHGS} > 0$ and $\\mathrm{GHGN} = -10$ [m per degree] exactly, which fails the strict inequality $\\mathrm{GHGN} \\lt -10$, so no blocking should be registered even though the duration is $5$ days.\n- Test Case 3 (non-persistence case, JJA, should not block): At longitude $\\lambda = 90^\\circ$, for days July $5$ through July $8$ inclusive (i.e., $4$ consecutive days), add $+300$ [m] to $Z(\\phi_0,\\lambda,t)$ at latitude $\\phi_0 = 60^\\circ$. No other changes. Expected effect: TM condition holds, but persistence fails because $L = 4 \\lt 5$, so no blocking.\n- Test Case 4 (persistence edge, SON, exact $5$ days, should block): At longitude $\\lambda = 180^\\circ$, for days October $1$ through October $5$ inclusive (i.e., $5$ consecutive days), add $+300$ [m] to $Z(\\phi_0,\\lambda,t)$ at latitude $\\phi_0 = 60^\\circ$. No other changes. Expected effect: TM condition holds and persistence threshold is met exactly.\n\nComputation requirements:\n- Implement the TM index condition exactly as stated using the above $\\phi_S$, $\\phi_0$, and $\\phi_N$, with the gradient units understood as meters per degree. Treat angles in degrees.\n- Apply the persistence rule of at least $5$ consecutive days at each longitude independently.\n- Compute $f_S(\\lambda)$ for each of the four seasons.\n- Extract the following four scalar results:\n  1. $f_{\\mathrm{DJF}}(0^\\circ)$,\n  2. $f_{\\mathrm{MAM}}(30^\\circ)$,\n  3. $f_{\\mathrm{JJA}}(90^\\circ)$,\n  4. $f_{\\mathrm{SON}}(180^\\circ)$.\n- Express each frequency as a decimal fraction.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the four frequencies in the order listed above. For example, a syntactic illustration of the format is\n$[x_1,x_2,x_3,x_4]$.",
            "solution": "The user's request is to implement the Tibaldi–Molteni (TM) atmospheric blocking index, apply a persistence criterion, and calculate seasonal blocking frequencies for a set of specified test cases using a synthetic geopotential height dataset.\n\n### Step 1: Problem Validation\n\nThe problem statement provides a comprehensive and scientifically sound description of the task.\n\n- **Givens**:\n    - **Physical concept**: Atmospheric blocking detection using the Tibaldi–Molteni (TM) index based on the meridional gradient of $500$ hPa geopotential height ($Z$).\n    - **TM Index Formulas**:\n        - Southern gradient: $\\mathrm{GHGS}(\\lambda, t) = \\frac{Z(\\phi_0,\\lambda,t) - Z(\\phi_S,\\lambda,t)}{\\phi_0 - \\phi_S}$.\n        - Northern gradient: $\\mathrm{GHGN}(\\lambda, t) = \\frac{Z(\\phi_N,\\lambda,t) - Z(\\phi_0,\\lambda,t)}{\\phi_N - \\phi_0}$.\n    - **TM Blocking Condition**: $\\mathrm{GHGS}(\\lambda, t) > 0$ and $\\mathrm{GHGN}(\\lambda, t) \\lt -10$ m/degree.\n    - **Persistence**: The condition must hold for at least $5$ consecutive days.\n    - **Frequency Calculation**: $f_S(\\lambda) = B_S(\\lambda) / N_S$, where $B_S(\\lambda)$ is the number of blocked days and $N_S$ is the total days in season $S$.\n    - **Seasons & Year**: DJF ($N_{\\mathrm{DJF}}=90$), MAM ($N_{\\mathrm{MAM}}=92$), JJA ($N_{\\mathrm{JJA}}=92$), SON ($N_{\\mathrm{SON}}=91$), for a non-leap year ($365$ days).\n    - **Grid**: Latitude $\\phi \\in \\{20^\\circ, 22.5^\\circ, \\dots, 80^\\circ\\}$; Longitude $\\lambda \\in \\{0^\\circ, 2.5^\\circ, \\dots, 357.5^\\circ\\}$; daily time step.\n    - **TM Latitudes**: $\\phi_S = 40^\\circ, \\phi_0 = 60^\\circ, \\phi_N = 80^\\circ$.\n    - **Base Field**: $Z_0(\\phi) = Z_{\\mathrm{ref}} - \\alpha \\, \\phi$, with $Z_{\\mathrm{ref}} = 5800$ m and $\\alpha = 6$ m/degree.\n    - **Test Cases**: Four specific anomalies are defined with location, timing, and magnitude.\n    - **Required Outputs**: Four specific seasonal frequencies: $f_{\\mathrm{DJF}}(0^\\circ)$, $f_{\\mathrm{MAM}}(30^\\circ)$, $f_{\\mathrm{JJA}}(90^\\circ)$, $f_{\\mathrm{SON}}(180^\\circ)$.\n\n- **Validation Verdict**:\n    - The problem is **scientifically grounded**, based on a standard meteorological index. The physical premises and parameter values are realistic.\n    - It is **well-posed**, providing all necessary data, formulas, and constraints to arrive at a unique, deterministic solution.\n    - The language is **objective** and precise.\n    - The setup is **complete and consistent**. No contradictions or ambiguities are present.\n\nThe problem is deemed **valid**. We proceed to the solution.\n\n### Step 2: Algorithmic Design and Calculation\n\nThe solution follows a structured, principle-based approach.\n\n**2.1. Grid and Data Structure Initialization**\nFirst, we establish the computational domain. We create grids for time, latitude, and longitude. The time grid runs from day index $0$ to $364$. The spatial grids are defined by their start, end, and step size.\n- Latitude grid $\\phi$: from $20^\\circ$ to $80^\\circ$ in steps of $2.5^\\circ$.\n- Longitude grid $\\lambda$: from $0^\\circ$ to $357.5^\\circ$ in steps of $2.5^\\circ$.\n\nThe geopotential height field $Z$ is a 3D array of size (time, latitude, longitude). We initialize this field with the zonal-mean base state $Z(\\phi,\\lambda,t) = Z_0(\\phi) = 5800 - 6\\phi$. This is achieved by creating a 1D latitude-dependent profile and broadcasting it across the time and longitude dimensions.\n\n**2.2. Application of Test Case Anomalies**\nThe four specified test cases are superimposed onto the base field. This requires mapping calendar dates to day-of-year indices and spatial coordinates to grid indices. Let $t_{idx}$, $\\phi_{idx}$, and $\\lambda_{idx}$ be the indices for day, latitude, and longitude, respectively.\n\n- **Day-of-year mapping**: Day indices run from $0$ (Jan 1) to $364$ (Dec 31).\n    - Case 1: Jan 15-21 corresponds to day indices $14$ through $20$.\n    - Case 2: Apr 10-14 corresponds to day indices $99$ through $103$.\n    - Case 3: Jul 5-8 corresponds to day indices $185$ through $188$.\n    - Case 4: Oct 1-5 corresponds to day indices $273$ through $277$.\n\n- **Grid Indexing**: We find the array indices corresponding to the required latitudes ($\\phi_S=40^\\circ, \\phi_0=60^\\circ, \\phi_N=80^\\circ$) and longitudes ($\\lambda = 0^\\circ, 30^\\circ, 90^\\circ, 180^\\circ$).\n\n- **Anomaly Addition**: For each test case, the specified geopotential height anomaly is added to the corresponding slice of the $Z$ array.\n\n**2.3. Calculation of TM Gradients**\nThe core of the TM index lies in two meridional geopotential height gradients, $\\mathrm{GHGS}$ and $\\mathrm{GHGN}$.\nWe extract the time-longitude data slices at the three key latitudes: $Z_S(t, \\lambda) = Z(\\phi_S, t, \\lambda)$, $Z_0(t, \\lambda) = Z(\\phi_0, t, \\lambda)$, and $Z_N(t, \\lambda) = Z(\\phi_N, t, \\lambda)$.\n\nThe gradients are then computed for all longitudes and days simultaneously using vectorized operations:\n$$\n\\mathrm{GHGS} = \\frac{Z_0 - Z_S}{\\phi_0 - \\phi_S} = \\frac{Z_0 - Z_S}{20}\n$$\n$$\n\\mathrm{GHGN} = \\frac{Z_N - Z_0}{\\phi_N - \\phi_0} = \\frac{Z_N - Z_0}{20}\n$$\nThe results are two 2D arrays, $\\mathrm{GHGS}(t, \\lambda)$ and $\\mathrm{GHGN}(t, \\lambda)$.\n\n**2.4. Instantaneous Blocking Detection**\nA boolean mask, `is_blocked_instantaneous`, of shape (time, longitude) is created by applying the TM index conditions:\n$$\n\\text{is\\_blocked\\_instantaneous}(t, \\lambda) = (\\mathrm{GHGS}(t, \\lambda) > 0) \\land (\\mathrm{GHGN}(t, \\lambda) \\lt -10)\n$$\n\n**2.5. Persistence Criterion Application**\nTo satisfy the persistence requirement, a longitude must be instantaneously blocked for $L \\ge 5$ consecutive days. We process the `is_blocked_instantaneous` mask longitude by longitude. For each longitude's time series, we identify contiguous blocks of `True` values. If a block has a length of $5$ days or more, all days within that block are marked as persistently blocked in a new boolean mask, `is_blocked_persistent`. This is efficiently implemented using `scipy.ndimage.label` to identify the contiguous blocks and `scipy.ndimage.sum_labels` to find their lengths.\n\n**2.6. Manual Verification of Test Cases**\nLet's verify the outcome for each case based on our algorithm. The base state gradients are $\\mathrm{GHGS} = \\mathrm{GHGN} = -6$ m/degree.\n\n- **Case 1**: $\\lambda = 0^\\circ$, days 14-20 (7 days). Anomaly: $\\Delta Z(\\phi_0) = +300$ m.\n    - $\\mathrm{GHGS} = ( (5440+300) - 5560 ) / 20 = 180/20 = 9 > 0$.\n    - $\\mathrm{GHGN} = ( 5320 - (5440+300) ) / 20 = -420/20 = -21 \\lt -10$.\n    - The condition holds for $7$ days. Since $7 \\ge 5$, all $7$ days are persistently blocked. These days are in DJF.\n    - $B_{\\mathrm{DJF}}(0^\\circ) = 7$, so $f_{\\mathrm{DJF}}(0^\\circ) = 7 / 90$.\n\n- **Case 2**: $\\lambda = 30^\\circ$, days 99-103 (5 days). Anomaly: $\\Delta Z(\\phi_0) = +80$ m, $\\Delta Z(\\phi_S) = -100$ m.\n    - $\\mathrm{GHGS} = ( (5440+80) - (5560-100) ) / 20 = 60/20 = 3 > 0$.\n    - $\\mathrm{GHGN} = ( 5320 - (5440+80) ) / 20 = -200/20 = -10$.\n    - The condition $\\mathrm{GHGN} \\lt -10$ is not met. No days are instantaneously blocked.\n    - $B_{\\mathrm{MAM}}(30^\\circ) = 0$, so $f_{\\mathrm{MAM}}(30^\\circ) = 0 / 92 = 0$.\n\n- **Case 3**: $\\lambda = 90^\\circ$, days 185-188 (4 days). Anomaly: $\\Delta Z(\\phi_0) = +300$ m.\n    - As in Case 1, the instantaneous condition holds.\n    - The duration is $4$ days. Since $4 \\lt 5$, the persistence criterion is not met.\n    - $B_{\\mathrm{JJA}}(90^\\circ) = 0$, so $f_{\\mathrm{JJA}}(90^\\circ) = 0 / 92 = 0$.\n\n- **Case 4**: $\\lambda = 180^\\circ$, days 273-277 (5 days). Anomaly: $\\Delta Z(\\phi_0) = +300$ m.\n    - The instantaneous condition holds.\n    - The duration is $5$ days. Since $5 \\ge 5$, the persistence criterion is met. All $5$ days are persistently blocked. These days are in SON.\n    - $B_{\\mathrm{SON}}(180^\\circ) = 5$, so $f_{\\mathrm{SON}}(180^\\circ) = 5 / 91$.\n\n**2.7. Final Frequency Calculation**\nThe final step is to compute the required frequencies by counting the number of `True` values in the `is_blocked_persistent` mask within the appropriate seasonal day ranges and at the specified longitudes, then dividing by the total number of days in that season.\n- Seasonal Day Indices:\n    - DJF: days $0-58$ (Jan, Feb) and $334-364$ (Dec).\n    - MAM: days $59-150$.\n    - JJA: days $151-242$.\n    - SON: days $243-333$.\n- Final results:\n    1. $f_{\\mathrm{DJF}}(0^\\circ) = 7/90$.\n    2. $f_{\\mathrm{MAM}}(30^\\circ) = 0.0$.\n    3. $f_{\\mathrm{JJA}}(90^\\circ) = 0.0$.\n    4. $f_{\\mathrm{SON}}(180^\\circ) = 5/91$.\nThese values are then computed as floating-point numbers and formatted as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import ndimage\n\ndef solve():\n    \"\"\"\n    Implements the Tibaldi-Molteni blocking index and calculates seasonal blocking frequencies.\n    \"\"\"\n    # 1. Foundational base and definitions\n    Z_REF = 5800.0  # meters\n    ALPHA = 6.0  # m per degree\n    PHI_S, PHI_0, PHI_N = 40.0, 60.0, 80.0  # degrees\n    GHGN_THRESHOLD = -10.0  # m per degree\n    PERSISTENCE_DAYS = 5\n    \n    # Seasonal day counts\n    N_DAYS_MONTH = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n    N_DAYS_YEAR = sum(N_DAYS_MONTH)\n    N_DJF, N_MAM, N_JJA, N_SON = 90, 92, 92, 91\n\n    # 2. Grid and data specification\n    lat_grid = np.arange(20.0, 80.1, 2.5)\n    lon_grid = np.arange(0.0, 357.6, 2.5)\n    time_grid = np.arange(N_DAYS_YEAR)\n\n    n_time, n_lat, n_lon = len(time_grid), len(lat_grid), len(lon_grid)\n\n    # 3. Construct the base Z500 field\n    z500 = np.zeros((n_time, n_lat, n_lon))\n    z0_profile = Z_REF - ALPHA * lat_grid\n    z500[:, :, :] = z0_profile[np.newaxis, :, np.newaxis]\n\n    # Helper to find grid indices\n    def get_idx(grid, value):\n        return np.where(grid == value)[0][0]\n\n    lat_idx_S = get_idx(lat_grid, PHI_S)\n    lat_idx_0 = get_idx(lat_grid, PHI_0)\n    lat_idx_N = get_idx(lat_grid, PHI_N)\n\n    # 4. Apply test case anomalies\n    cum_days = np.cumsum([0] + N_DAYS_MONTH[:-1])\n\n    # Case 1: DJF, strong blocking\n    lon_idx_1 = get_idx(lon_grid, 0.0)\n    day_start_1 = cum_days[0] + 15 - 1\n    day_end_1 = cum_days[0] + 21 - 1\n    z500[day_start_1 : day_end_1 + 1, lat_idx_0, lon_idx_1] += 300.0\n\n    # Case 2: MAM, boundary threshold\n    lon_idx_2 = get_idx(lon_grid, 30.0)\n    day_start_2 = cum_days[3] + 10 - 1\n    day_end_2 = cum_days[3] + 14 - 1\n    z500[day_start_2 : day_end_2 + 1, lat_idx_0, lon_idx_2] += 80.0\n    z500[day_start_2 : day_end_2 + 1, lat_idx_S, lon_idx_2] -= 100.0\n\n    # Case 3: JJA, non-persistence\n    lon_idx_3 = get_idx(lon_grid, 90.0)\n    day_start_3 = cum_days[6] + 5 - 1\n    day_end_3 = cum_days[6] + 8 - 1\n    z500[day_start_3 : day_end_3 + 1, lat_idx_0, lon_idx_3] += 300.0\n\n    # Case 4: SON, persistence edge\n    lon_idx_4 = get_idx(lon_grid, 180.0)\n    day_start_4 = cum_days[9] + 1 - 1\n    day_end_4 = cum_days[9] + 5 - 1\n    z500[day_start_4 : day_end_4 + 1, lat_idx_0, lon_idx_4] += 300.0\n\n    # 5. Compute TM gradients and instantaneous blocking\n    z_S = z500[:, lat_idx_S, :]\n    z_0 = z500[:, lat_idx_0, :]\n    z_N = z500[:, lat_idx_N, :]\n    \n    ghgs = (z_0 - z_S) / (PHI_0 - PHI_S)\n    ghgn = (z_N - z_0) / (PHI_N - PHI_0)\n\n    is_blocked_instantaneous = (ghgs > 0)  (ghgn  GHGN_THRESHOLD)\n\n    # 6. Apply persistence requirement\n    is_blocked_persistent = np.full_like(is_blocked_instantaneous, False, dtype=bool)\n\n    for j in range(n_lon):\n        # Identify contiguous runs of True\n        labeled_array, num_features = ndimage.label(is_blocked_instantaneous[:, j])\n        if num_features > 0:\n            # Find the length of each run\n            run_indices = np.arange(1, num_features + 1)\n            run_lengths = ndimage.sum_labels(is_blocked_instantaneous[:, j], labeled_array, index=run_indices)\n            \n            # Find runs that meet the persistence criterion\n            persistent_runs = run_indices[run_lengths >= PERSISTENCE_DAYS]\n            \n            if persistent_runs.size > 0:\n                # Mark all days in those runs as persistently blocked\n                mask = np.isin(labeled_array, persistent_runs)\n                is_blocked_persistent[:, j] = mask\n\n    # 7. Compute seasonal frequencies for the required longitudes\n    # Seasonal day index ranges\n    # DJF: Jan, Feb, Dec\n    day_idx_jan_end = cum_days[1]\n    day_idx_feb_end = cum_days[2]\n    day_idx_dec_start = cum_days[11]\n    \n    # MAM: Mar, Apr, May\n    day_idx_mar_start = cum_days[2]\n    day_idx_may_end = cum_days[5]\n\n    # JJA: Jun, Jul, Aug\n    day_idx_jun_start = cum_days[5]\n    day_idx_aug_end = cum_days[8]\n    \n    # SON: Sep, Oct, Nov\n    day_idx_sep_start = cum_days[8]\n    day_idx_nov_end = cum_days[11]\n\n    # Result 1: f_DJF(0°)\n    blocked_days_djf_1 = np.sum(is_blocked_persistent[0:day_idx_feb_end, lon_idx_1])\n    blocked_days_djf_2 = np.sum(is_blocked_persistent[day_idx_dec_start:, lon_idx_1])\n    f_djf = (blocked_days_djf_1 + blocked_days_djf_2) / N_DJF\n    \n    # Result 2: f_MAM(30°)\n    blocked_days_mam = np.sum(is_blocked_persistent[day_idx_mar_start:day_idx_may_end, lon_idx_2])\n    f_mam = blocked_days_mam / N_MAM\n\n    # Result 3: f_JJA(90°)\n    blocked_days_jja = np.sum(is_blocked_persistent[day_idx_jun_start:day_idx_aug_end, lon_idx_3])\n    f_jja = blocked_days_jja / N_JJA\n\n    # Result 4: f_SON(180°)\n    blocked_days_son = np.sum(is_blocked_persistent[day_idx_sep_start:day_idx_nov_end, lon_idx_4])\n    f_son = blocked_days_son / N_SON\n\n    results = [f_djf, f_mam, f_jja, f_son]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the TM index provides a robust dynamical definition of blocking, other indices exist that are based on different physical principles. This exercise introduces the Pelly-Hoskins (PHI) index, which uses potential temperature gradients at the tropopause to identify blocks, reflecting a thermodynamic perspective. Your task is to implement both a TM-style and the PHI index and then perform a direct, event-by-event comparison, highlighting a critical aspect of atmospheric science: understanding the similarities and differences between various diagnostic methods for the same phenomenon .",
            "id": "4013011",
            "problem": "You are asked to design and implement a complete, runnable program that computes two blocking detection diagnostics from given synthetic daily latitude profiles of geopotential height and potential temperature, and then performs event-by-event comparisons across winter and summer seasons. The two diagnostics are (i) a Tibaldi–Molteni (TM) style detection defined via geostrophic wind reversal at midlatitudes, and (ii) a Pelly–Hoskins blocking index defined via meridional potential temperature gradient conditions on a representative tropopause-level surface. The goal is to quantitatively compare overlaps and discrepancies between the two detection methods, season by season, and to aggregate the comparison metrics.\n\nStart from the following fundamental bases and core definitions, without assuming any shortcut formulas.\n\n- Geostrophic balance for midlatitude synoptic flow: the geostrophic zonal wind $u_g$ satisfies $u_g = -\\frac{1}{f} \\frac{\\partial \\Phi}{\\partial y}$, where $\\Phi$ is the geopotential ($\\Phi = g Z$ for geopotential height $Z$), $f(\\phi) = 2 \\Omega \\sin \\phi$ is the Coriolis parameter at latitude $\\phi$, $g$ is gravitational acceleration, $\\Omega$ is the Earth's rotation rate, and $y$ is the meridional coordinate.\n- Finite-difference approximation of meridional derivatives on a sphere between two latitudes $\\phi_S$ and $\\phi_N$ around a central latitude $\\phi_0$: use $\\Delta y \\approx a \\Delta \\phi$ with $\\Delta \\phi$ in radians and Earth radius $a$. For a central wind estimate at $\\phi_0$, use a symmetric meridional difference over $\\phi_S$ and $\\phi_N$.\n- Thermal wind relation linking vertical shear of geostrophic wind to meridional temperature gradient implies that meridional potential temperature $\\theta$ gradients at the dynamical tropopause are indicative of jet structure; a reversal of the expected poleward decrease can signal blocking.\n\nDefine detection criteria to be implemented from the above bases:\n\n1. Tibaldi–Molteni (TM) style detection in this problem: compute a central geostrophic zonal wind $u_g(\\phi_0)$ at $\\phi_0 = 50^\\circ$ using a symmetric finite-difference of $\\Phi$ between $\\phi_S = 40^\\circ$ and $\\phi_N = 60^\\circ$,\n$$\nu_g(\\phi_0) \\approx -\\frac{\\Phi(\\phi_N) - \\Phi(\\phi_S)}{a \\Delta \\phi \\, f(\\phi_0)},\n$$\nwhere $\\Delta \\phi = \\phi_N - \\phi_S$ is in radians, $a$ is the Earth radius, $f(\\phi_0) = 2 \\Omega \\sin(\\phi_0)$, $\\Phi = g Z$, $g$ is gravitational acceleration, and $Z$ is in meters. A day is classified as TM-blocked if $u_g(\\phi_0) \\le -U_{\\mathrm{thr}}$ with threshold $U_{\\mathrm{thr}} = 10 \\, \\mathrm{m \\, s^{-1}}$. Apply a persistence criterion by defining blocking events as contiguous runs of TM-blocked days of length at least $L_{\\min} = 3$ days.\n\n2. Pelly–Hoskins blocking index (PHI) in this problem: compute meridional potential temperature gradients on a tropopause-representative surface,\n$$\n\\Delta \\theta_N = \\frac{\\theta(\\phi_N) - \\theta(\\phi_0)}{\\Delta \\phi_{\\deg}}, \\quad \\Delta \\theta_S = \\frac{\\theta(\\phi_0) - \\theta(\\phi_S)}{\\Delta \\phi_{\\deg}},\n$$\nwith $\\Delta \\phi_{\\deg} = 10^\\circ$. A day is classified as PHI-blocked if both $\\Delta \\theta_N  0$ (poleward reversal) and $\\Delta \\theta_S \\le -\\Gamma_\\theta$ with $\\Gamma_\\theta = 1 \\, \\mathrm{K \\, deg^{-1}}$. Apply the same persistence criterion: events are contiguous runs of PHI-blocked days of length at least $L_{\\min} = 3$ days.\n\nSeasons: Classify each day as “winter” or “summer” based on an externally provided label for that day. Events should be detected and segmented within seasons, meaning that an event cannot cross from one season to another; if a run of blocked days spans a season boundary, it should be split at that boundary.\n\nEvent-by-event comparison metrics to compute for each test case (aggregating across both seasons):\n\n- $N_{\\mathrm{PHI}}$: total number of Pelly–Hoskins events detected across winter and summer.\n- $N_{\\mathrm{TM}}$: total number of Tibaldi–Molteni events detected across winter and summer.\n- $N_{\\mathrm{ov}}$: the number of Pelly–Hoskins events that overlap at least one TM event within the same season. Each Pelly–Hoskins event contributes at most one to $N_{\\mathrm{ov}}$, even if it overlaps multiple TM events.\n- $N_{\\mathrm{PHIonly}} = N_{\\mathrm{PHI}} - N_{\\mathrm{ov}}$.\n- $N_{\\mathrm{TMonly}}$: the number of TM events that do not overlap any Pelly–Hoskins event within the same season.\n\nYour program must compute these metrics for each of the provided test cases and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s metrics are in order as a list of integers: $[N_{\\mathrm{PHI}}, N_{\\mathrm{TM}}, N_{\\mathrm{ov}}, N_{\\mathrm{PHIonly}}, N_{\\mathrm{TMonly}}]$. The final output must be a list of these lists, one per test case, e.g., $[[\\cdots],[\\cdots],\\ldots]$.\n\nPhysical units and constants:\n- Use $Z$ in $\\mathrm{m}$, $\\theta$ in $\\mathrm{K}$, angles in degrees (for $\\Delta \\phi_{\\deg}$) and radians (for $\\Delta \\phi$ in the geostrophic wind), Earth radius $a$ in $\\mathrm{m}$, gravitational acceleration $g$ in $\\mathrm{m \\, s^{-2}}$, and rotation rate $\\Omega$ in $\\mathrm{s^{-1}}$.\n- Express all thresholds and winds in $\\mathrm{m \\, s^{-1}}$.\n- Use $a = 6{,}371{,}000 \\, \\mathrm{m}$, $g = 9.81 \\, \\mathrm{m \\, s^{-2}}$, $\\Omega = 7.2921 \\times 10^{-5} \\, \\mathrm{s^{-1}}$.\n\nTest suite:\nImplement your program to use the following test cases with latitude points $\\phi_S = 40^\\circ$, $\\phi_0 = 50^\\circ$, $\\phi_N = 60^\\circ$.\n\n- Test Case $1$ (happy path with mixed-season overlap and discrepancy):\n  - Days $D = 12$; seasons: $[\\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"summer\"}, \\text{\"summer\"}, \\text{\"summer\"}, \\text{\"summer\"}, \\text{\"summer\"}, \\text{\"summer\"}]$.\n  - Daily potential temperature triples $\\theta(\\phi_S), \\theta(\\phi_0), \\theta(\\phi_N)$ in $\\mathrm{K}$:\n    $[[350,345,340],[350,338,345],[350,338,345],[350,338,345],[350,345,340],[350,345,340],[350,345,340],[350,338,345],[350,338,345],[350,338,345],[350,345,340],[350,345,340]]$.\n  - Daily geopotential height triples $Z(\\phi_S), Z(\\phi_0), Z(\\phi_N)$ in $\\mathrm{m}$:\n    $[[5600,5500,5400],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400]]$.\n\n- Test Case $2$ (boundary-threshold inclusion):\n  - Days $D = 6$; seasons: $[\\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"summer\"}, \\text{\"summer\"}, \\text{\"summer\"}]$.\n  - Daily potential temperature triples in $\\mathrm{K}$ (boundary PHI condition: $\\Delta \\theta_S = -1.0 \\, \\mathrm{K \\, deg^{-1}}$, $\\Delta \\theta_N = +0.1 \\, \\mathrm{K \\, deg^{-1}}$):\n    $[[350,340,341],[350,340,341],[350,340,341],[350,340,341],[350,340,341],[350,340,341]]$.\n  - Daily geopotential height triples in $\\mathrm{m}$ (boundary TM condition: $u_g \\approx -10 \\, \\mathrm{m \\, s^{-1}}$):\n    $[[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853]]$.\n\n- Test Case $3$ (no events):\n  - Days $D = 5$; seasons: $[\\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"summer\"}, \\text{\"summer\"}]$.\n  - Daily potential temperature triples in $\\mathrm{K}$:\n    $[[350,345,340],[350,345,340],[350,345,340],[350,345,340],[350,345,340]]$.\n  - Daily geopotential height triples in $\\mathrm{m}$:\n    $[[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400]]$.\n\n- Test Case $4$ (persistent all-block, single-season):\n  - Days $D = 5$; seasons: $[\\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}, \\text{\"winter\"}]$.\n  - Daily potential temperature triples in $\\mathrm{K}$:\n    $[[350,338,345],[350,338,345],[350,338,345],[350,338,345],[350,338,345]]$.\n  - Daily geopotential height triples in $\\mathrm{m}$:\n    $[[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100]]$.\n\nAngle unit: use degrees for $\\phi_S$, $\\phi_0$, $\\phi_N$, and for $\\Delta \\phi_{\\deg}$; use radians for $\\Delta \\phi$ in the geostrophic wind computation. Physical units: report and use $\\mathrm{m}$, $\\mathrm{K}$, and $\\mathrm{m \\, s^{-1}}$ as defined above. Percentages are not part of the requested outputs.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result is a list in the exact order $[N_{\\mathrm{PHI}}, N_{\\mathrm{TM}}, N_{\\mathrm{ov}}, N_{\\mathrm{PHIonly}}, N_{\\mathrm{TMonly}}]$. The final output must be a list of these lists, e.g., $[[r_{11},r_{12},r_{13},r_{14},r_{15}],[r_{21},r_{22},r_{23},r_{24},r_{25}],\\ldots]$.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of dynamic meteorology, specifically geostrophic balance and the thermal wind relationship, which are fundamental to understanding large-scale atmospheric flow. The problem is well-posed, providing all necessary physical constants, mathematical definitions, thresholds, and data to compute a unique solution. The definitions for the Tibaldi-Molteni (TM) and Pelly-Hoskins (PHI) blocking indices are clear and formalizable. The persistence criterion and the rules for handling seasonal boundaries are explicitly stated, removing ambiguity. The test cases are well-defined and allow for a rigorous verification of the implementation. The problem is objective and free from non-scientific or unverifiable claims.\n\nThe solution proceeds by first implementing the two blocking detection methods on a daily basis, then identifying persistent blocking events, and finally performing a comparative analysis of the events detected by each method.\n\n**1. Daily Blocking Index Calculation**\n\nFor each day in the time series, we determine if it qualifies as \"blocked\" according to each of the two criteria.\n\n**Tibaldi-Molteni (TM) Style Detection:**\nThis method is based on the reversal of the geostrophic zonal wind, $u_g$, at midlatitudes. The governing equation is the geostrophic wind relation:\n$$\nu_g = -\\frac{1}{f} \\frac{\\partial \\Phi}{\\partial y}\n$$\nwhere $\\Phi = g Z$ is the geopotential, $f(\\phi) = 2 \\Omega \\sin \\phi$ is the Coriolis parameter at latitude $\\phi$, and $y$ is the meridional coordinate. We approximate the partial derivative using a central finite difference between latitudes $\\phi_S = 40^\\circ$ and $\\phi_N = 60^\\circ$. The central latitude is $\\phi_0 = 50^\\circ$. The meridional distance $\\Delta y$ is approximated as $\\Delta y \\approx a (\\phi_N - \\phi_S)$, where the latitude difference must be in radians. The formula for the geostrophic wind at $\\phi_0$ is:\n$$\nu_g(\\phi_0) \\approx -\\frac{\\Phi(\\phi_N) - \\Phi(\\phi_S)}{a (\\phi_N^{\\mathrm{rad}} - \\phi_S^{\\mathrm{rad}}) \\, f(\\phi_0)}\n$$\nwhere $\\phi^{\\mathrm{rad}}$ denotes the latitude in radians.\nThe required constants are:\n- Earth radius, $a = 6{,}371{,}000 \\, \\mathrm{m}$\n- Gravitational acceleration, $g = 9.81 \\, \\mathrm{m \\, s^{-2}}$\n- Earth's rotation rate, $\\Omega = 7.2921 \\times 10^{-5} \\, \\mathrm{s^{-1}}$\nThe latitudes are $\\phi_S = 40^\\circ$, $\\phi_0 = 50^\\circ$, $\\phi_N = 60^\\circ$. The corresponding radian values are used in the calculation.\nA day is classified as TM-blocked if the calculated $u_g(\\phi_0)$ is less than or equal to the threshold $U_{\\mathrm{thr}} = -10 \\, \\mathrm{m \\, s^{-1}}$.\n\n**Pelly-Hoskins (PHI) Style Detection:**\nThis method identifies blocking by examining meridional potential temperature ($\\theta$) gradients on a tropopause-level surface. A reversal of the typical pole-to-equator gradient is a key indicator. Two gradients are computed:\n$$\n\\Delta \\theta_N = \\frac{\\theta(\\phi_N) - \\theta(\\phi_0)}{\\Delta \\phi_{\\deg}}\n$$\n$$\n\\Delta \\theta_S = \\frac{\\theta(\\phi_0) - \\theta(\\phi_S)}{\\Delta \\phi_{\\deg}}\n$$\nwhere $\\Delta \\phi_{\\deg} = \\phi_0 - \\phi_S = \\phi_N - \\phi_0 = 10^\\circ$.\nA day is classified as PHI-blocked if two conditions are met simultaneously:\n1. The northern gradient indicates a reversal: $\\Delta \\theta_N  0 \\, \\mathrm{K \\, deg^{-1}}$.\n2. The southern gradient is sufficiently strong and in the expected direction: $\\Delta \\theta_S \\le -\\Gamma_\\theta$, where the threshold is $\\Gamma_\\theta = 1 \\, \\mathrm{K \\, deg^{-1}}$.\n\n**2. Persistent Event Detection**\n\nAfter classifying each day, we identify blocking events. An event is defined as a contiguous sequence of blocked days with a minimum duration of $L_{\\min} = 3$ days. A crucial constraint is that events cannot cross seasonal boundaries. If a sequence of blocked days is interrupted by a change in season (e.g., from \"winter\" to \"summer\"), the sequence is split. Each resulting sub-sequence is then independently evaluated against the $L_{\\min}$ persistence criterion.\n\nThe algorithm for finding events is as follows:\n- Iterate through the daily blocking flags and season labels.\n- When a blocked day is encountered, start tracking a potential event.\n- Continue extending the event as long as subsequent days are also blocked and belong to the same season.\n- When the sequence of blocked days ends (or the season changes), check if its length meets or exceeds $L_{\\min}$.\n- If it does, record the event's start and end days.\n- Resume the search from the day after the sequence ended.\nThis process is applied separately to the daily flags generated by the TM and PHI methods.\n\n**3. Event Comparison Metrics**\n\nThe final step is to compare the sets of PHI and TM events to calculate five specific metrics, aggregated across both winter and summer seasons.\n\nLet $E_{\\mathrm{PHI}}$ be the set of all detected PHI events and $E_{\\mathrm{TM}}$ be the set of all detected TM events. An event is represented by its start and end day indices, e.g., $(d_{\\mathrm{start}}, d_{\\mathrm{end}})$.\n\n- $N_{\\mathrm{PHI}}$: Total number of PHI events. This is simply the size of the set $E_{\\mathrm{PHI}}$.\n- $N_{\\mathrm{TM}}$: Total number of TM events. This is the size of the set $E_{\\mathrm{TM}}$.\n- $N_{\\mathrm{ov}}$: The number of PHI events that overlap with at least one TM event. Two events, $(s_1, e_1)$ and $(s_2, e_2)$, are considered to overlap if their time intervals intersect and they occur in the same season. The condition for interval intersection is $\\max(s_1, s_2) \\le \\min(e_1, e_2)$. We iterate through each PHI event and check if it overlaps with any TM event from the same season.\n- $N_{\\mathrm{PHIonly}}$: The number of PHI events that do not overlap with any TM event. This is calculated as $N_{\\mathrm{PHIonly}} = N_{\\mathrm{PHI}} - N_{\\mathrm{ov}}$.\n- $N_{\\mathrm{TMonly}}$: The number of TM events that do not overlap with any PHI event. We iterate through each TM event and check if it overlaps with any PHI event from the same season. If no overlap is found for a given TM event, it is counted towards $N_{\\mathrm{TMonly}}$.\n\nThese five metrics are calculated for each test case, providing a quantitative comparison of the two blocking detection methodologies.",
            "answer": "```python\nimport numpy as np\n# scipy is permitted by the environment specification but not used in this solution.\n\ndef solve():\n    \"\"\"\n    Computes and compares two atmospheric blocking diagnostics (TM and PHI)\n    on synthetic daily data, following the specified problem definition.\n    \"\"\"\n\n    # Physical constants\n    A = 6_371_000.0  # Earth radius in meters\n    G = 9.81         # Gravitational acceleration in m/s^2\n    OMEGA = 7.2921e-5 # Earth's rotation rate in rad/s\n\n    # Latitudes\n    PHI_S_DEG = 40.0\n    PHI_0_DEG = 50.0\n    PHI_N_DEG = 60.0\n    \n    PHI_S_RAD = np.deg2rad(PHI_S_DEG)\n    PHI_0_RAD = np.deg2rad(PHI_0_DEG)\n    PHI_N_RAD = np.deg2rad(PHI_N_DEG)\n    \n    DELTA_PHI_RAD = PHI_N_RAD - PHI_S_RAD\n    DELTA_PHI_DEG = PHI_0_DEG - PHI_S_DEG # Given as 10 degrees\n\n    # Thresholds\n    U_THR = 10.0  # m/s\n    GAMMA_THETA = 1.0  # K/deg\n    L_MIN = 3 # days\n\n    # Pre-compute denominator for TM calculation\n    f0 = 2 * OMEGA * np.sin(PHI_0_RAD)\n    tm_denominator = A * DELTA_PHI_RAD * f0\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"seasons\": [\"winter\", \"winter\", \"winter\", \"winter\", \"winter\", \"winter\", \"summer\", \"summer\", \"summer\", \"summer\", \"summer\", \"summer\"],\n            \"theta\": np.array([[350,345,340],[350,338,345],[350,338,345],[350,338,345],[350,345,340],[350,345,340],[350,345,340],[350,338,345],[350,338,345],[350,338,345],[350,345,340],[350,345,340]]),\n            \"Z\": np.array([[5600,5500,5400],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400]]),\n        },\n        # Test Case 2\n        {\n            \"seasons\": [\"winter\", \"winter\", \"winter\", \"summer\", \"summer\", \"summer\"],\n            \"theta\": np.array([[350,340,341],[350,340,341],[350,340,341],[350,340,341],[350,340,341],[350,340,341]]),\n            \"Z\": np.array([[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853],[5600,5800,5853]]),\n        },\n        # Test Case 3\n        {\n            \"seasons\": [\"winter\", \"winter\", \"winter\", \"summer\", \"summer\"],\n            \"theta\": np.array([[350,345,340],[350,345,340],[350,345,340],[350,345,340],[350,345,340]]),\n            \"Z\": np.array([[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400],[5600,5500,5400]]),\n        },\n        # Test Case 4\n        {\n            \"seasons\": [\"winter\", \"winter\", \"winter\", \"winter\", \"winter\"],\n            \"theta\": np.array([[350,338,345],[350,338,345],[350,338,345],[350,338,345],[350,338,345]]),\n            \"Z\": np.array([[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100],[5500,5800,6100]]),\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        seasons = np.array(case[\"seasons\"])\n        theta_data = case[\"theta\"]\n        z_data = case[\"Z\"]\n        num_days = len(seasons)\n\n        # --- Step 1: Calculate daily blocking flags ---\n        \n        # PHI daily flags\n        theta_S = theta_data[:, 0]\n        theta_0 = theta_data[:, 1]\n        theta_N = theta_data[:, 2]\n        \n        delta_theta_N = (theta_N - theta_0) / DELTA_PHI_DEG\n        delta_theta_S = (theta_0 - theta_S) / DELTA_PHI_DEG\n        \n        phi_blocked_days = (delta_theta_N > 0)  (delta_theta_S = -GAMMA_THETA)\n\n        # TM daily flags\n        z_S = z_data[:, 0]\n        z_N = z_data[:, 2]\n        \n        phi_N_geo = G * z_N\n        phi_S_geo = G * z_S\n        \n        u_g = -(phi_N_geo - phi_S_geo) / tm_denominator\n        tm_blocked_days = u_g = -U_THR\n\n        # --- Step 2: Find persistent events, respecting seasonal boundaries ---\n        \n        def find_events(blocked_days, seasons, min_len):\n            events = []\n            i = 0\n            n = len(blocked_days)\n            while i  n:\n                if not blocked_days[i]:\n                    i += 1\n                    continue\n                \n                # Found a potential start of an event\n                start_day = i\n                current_season = seasons[i]\n                j = i\n                while j  n and blocked_days[j] and seasons[j] == current_season:\n                    j += 1\n                \n                # A run of blocked days ends at j-1\n                end_day = j - 1\n                duration = end_day - start_day + 1\n                \n                if duration >= min_len:\n                    events.append({'start': start_day, 'end': end_day, 'season': current_season})\n                \n                # Continue search from where the run ended\n                i = j\n            return events\n\n        phi_events = find_events(phi_blocked_days, seasons, L_MIN)\n        tm_events = find_events(tm_blocked_days, seasons, L_MIN)\n\n        # --- Step 3: Compute comparison metrics ---\n        \n        n_phi = len(phi_events)\n        n_tm = len(tm_events)\n        n_ov = 0\n        n_tm_only = 0\n\n        # Calculate N_ov\n        for phi_event in phi_events:\n            is_overlapped = False\n            for tm_event in tm_events:\n                # Check for overlap only within the same season\n                if phi_event['season'] == tm_event['season']:\n                    # Overlap condition: intervals [s1, e1] and [s2, e2] overlap\n                    # if s1 = e2 and s2 = e1.\n                    if (phi_event['start'] = tm_event['end'] and \n                        tm_event['start'] = phi_event['end']):\n                        is_overlapped = True\n                        break # Only need one overlap per PHI event\n            if is_overlapped:\n                n_ov += 1\n        \n        n_phi_only = n_phi - n_ov\n\n        # Calculate N_TMonly\n        for tm_event in tm_events:\n            is_overlapped = False\n            for phi_event in phi_events:\n                # Check for overlap only within the same season\n                if tm_event['season'] == phi_event['season']:\n                    if (tm_event['start'] = phi_event['end'] and \n                        phi_event['start'] = tm_event['end']):\n                        is_overlapped = True\n                        break # Only need one overlap\n            if not is_overlapped:\n                n_tm_only += 1\n\n        all_results.append([n_phi, n_tm, n_ov, n_phi_only, n_tm_only])\n\n    # Final print statement in the exact required format.\n    print(str(all_results).replace(\" \", \"\").replace(\"phi_N_geo\",\"phi_N\").replace(\"phi_S_geo\",\"phi_S\"))\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond daily, grid-point-based classifications, a more advanced approach to validation treats blocking events as coherent spatiotemporal objects. This final practice introduces sophisticated object-based verification techniques to assess how well an automated algorithm captures the full life cycle of blocking events compared to a manual reference catalog. You will use the Jaccard similarity index to quantify the spatiotemporal overlap between detected and manual events and apply an optimal matching algorithm to establish one-to-one correspondences, providing a much richer and more physically meaningful evaluation of detection skill .",
            "id": "4013038",
            "problem": "You are given a curated manual catalog of atmospheric blocking events and outputs from an automated detection algorithm. Each event is represented as a spatiotemporal object on a periodic longitude circle of circumference $360^{\\circ}$ and a discrete-time axis in days. A single event is completely described by a four-tuple $(\\ell, w, t_s, t_e)$ where $\\ell$ is the longitude center in degrees, $w$ is the longitudinal width in degrees with $0 \\lt w \\le 360$, $t_s$ is the onset day index, and $t_e$ is the cessation day index with $t_s \\le t_e$. The longitudinal arc occupied by an event is the set of longitudes\n$$\nA(\\ell,w) = \\{ \\lambda \\in [0,360) : \\text{the shortest arc centered at } \\ell \\text{ of length } w \\text{ contains } \\lambda \\},\n$$\ninterpreted on the circle with period $360^{\\circ}$. The temporal support of an event is the inclusive set of days\n$$\nI(t_s,t_e) = \\{ t \\in \\mathbb{Z} : t_s \\le t \\le t_e \\}.\n$$\n\nYour task is to validate the detector against the manual catalog by:\n- establishing one-to-one matches between manual and detected events using a similarity criterion based on set theory,\n- computing skill measures (precision, recall, and F1 score),\n- quantifying event timing accuracy in onset and cessation in days, and\n- reporting failure characteristics via counts of false positives and false negatives.\n\nFundamental base and definitions to use:\n- For any two sets $X$ and $Y$ on a common domain with finite, nonnegative measure, the Jaccard similarity is defined by the ratio $J(X,Y) = \\frac{|X \\cap Y|}{|X \\cup Y|}$, where $|\\cdot|$ denotes measure (length on the circle for longitude arcs in degrees, and cardinality for discrete-day intervals, with inclusive day counting).\n- Let $r_s$ denote the spatial Jaccard similarity $J(A(\\ell_m,w_m),A(\\ell_d,w_d))$ and let $r_t$ denote the temporal Jaccard similarity $J(I(t_{s,m},t_{e,m}), I(t_{s,d},t_{e,d}))$ for a manual event and a detected event, respectively. A candidate match is admissible if and only if $r_s \\ge \\tau_s$ and $r_t \\ge \\tau_t$ for given thresholds $\\tau_s$ and $\\tau_t$ in $[0,1]$.\n- Define a combined similarity score for admissible pairs by $S = r_s \\times r_t$ and $S = 0$ for inadmissible pairs. Establish a one-to-one matching between manual and detected events by maximizing the sum of $S$ over matched pairs subject to each event being used at most once.\n- Let $TP$ be the number of matched pairs with admissible similarity, $FN$ the number of manual events not matched, and $FP$ the number of detected events not matched. Precision is $P = \\frac{TP}{TP+FP}$ with the convention $P = 0$ if $TP+FP = 0$. Recall is $R = \\frac{TP}{TP+FN}$ with the convention $R = 0$ if $TP+FN = 0$. The F1 score is $F1 = \\frac{2PR}{P+R}$ with the convention $F1 = 0$ if $P+R = 0$.\n- For each matched manual–detected pair, define the onset timing error $e_s = t_{s,d} - t_{s,m}$ and the cessation timing error $e_e = t_{e,d} - t_{e,m}$. The event timing accuracy measures to report are the mean absolute onset error $\\overline{|e_s|}$ and mean absolute cessation error $\\overline{|e_e|}$, each expressed in days. If there are no matched pairs, report both timing accuracy measures as $0$ days.\n\nImportant implementation details:\n- Longitude geometry is periodic with period $360^{\\circ}$. Lengths of arc unions and intersections must be computed on the circle, honoring wrap-around at $0^{\\circ}$ and $360^{\\circ}$. Treat longitudinal arcs by their geometric length in degrees. Treat temporal intervals as inclusive on integer days, so that the length of $I(t_s,t_e)$ is $t_e - t_s + 1$ days.\n- The one-to-one matching must maximize the sum of combined similarity scores $S$ and respect admissibility defined by the thresholds. If multiple pairings achieve equal maximum score, any such optimal pairing is acceptable as long as it is consistent with the admissibility constraints.\n\nUse the following thresholds for all cases: $\\tau_s = 0.5$ and $\\tau_t = 0.5$.\n\nTest suite:\nEach test case is a pair of lists. The first list is the manual catalog, and the second list is the detections, both as lists of tuples $(\\ell, w, t_s, t_e)$ with $\\ell$ in degrees, $w$ in degrees, and $t_s,t_e$ in days.\n\n- Case 1 (general well-matched): manual $=[(30, 60, 2, 10),(200, 50, 15, 22)]$; detections $=[(35, 70, 3, 11),(205, 40, 16, 20)]$.\n- Case 2 (periodic wrap and one spurious): manual $=[(350, 40, 5, 12)]$; detections $=[(355, 50, 6, 13),(150, 30, 7, 10)]$.\n- Case 3 (duplicate detections for one manual event): manual $=[(100, 60, 0, 9)]$; detections $=[(102, 70, 0, 9),(98, 50, 2, 8)]$.\n- Case 4 (temporal fragmentation and a miss): manual $=[(250, 80, 10, 25),(300, 50, 5, 8)]$; detections $=[(252, 70, 10, 17),(252, 70, 18, 25),(30, 40, 0, 3)]$.\n- Case 5 (no detections): manual $=[(180, 100, 0, 10)]$; detections $=[]$.\n\nRequired outputs for each test case:\n- Precision $P$ as a real number rounded to three decimals.\n- Recall $R$ as a real number rounded to three decimals.\n- F1 score $F1$ as a real number rounded to three decimals.\n- Mean absolute onset error $\\overline{|e_s|}$ in days as a real number rounded to two decimals (unit: days).\n- Mean absolute cessation error $\\overline{|e_e|}$ in days as a real number rounded to two decimals (unit: days).\n- The integer count $FP$.\n- The integer count $FN$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of per-case result lists, with no spaces. For example, the output must look like\n$[ [P_1,R_1,F1_1,\\overline{|e_s|}_1,\\overline{|e_e|}_1,FP_1,FN_1], [P_2,R_2,F1_2,\\overline{|e_s|}_2,\\overline{|e_e|}_2,FP_2,FN_2], \\dots ]$\nbut without spaces. Concretely, your program should print a single line in the exact format\n\"[case1_list,case2_list,case3_list,case4_list,case5_list]\".",
            "solution": "The problem requires the validation of an automated atmospheric blocking detection algorithm against a manual reference catalog. The validation involves a multi-step procedure: quantifying the similarity of individual events, establishing an optimal one-to-one matching between manual and detected events, and finally, computing a suite of standard performance metrics. The entire process is grounded in set theory and combinatorial optimization.\n\nThe fundamental algorithm proceeds as follows:\n1.  For every possible pair of a manual event and a detected event, calculate their spatial and temporal similarity.\n2.  Use these similarities to compute a combined score, which is non-zero only for pairs that meet predefined admissibility thresholds.\n3.  Solve the assignment problem to find a one-to-one matching between manual and detected events that maximizes the total combined similarity score.\n4.  Based on this optimal matching, classify events into true positives, false positives, and false negatives.\n5.  Compute the final skill scores (precision, recall, F1) and timing accuracy measures (mean absolute onset and cessation errors).\n\nLet a manual event be $m_i = (\\ell_{m,i}, w_{m,i}, t_{s,m,i}, t_{e,m,i})$ and a detected event be $d_j = (\\ell_{d,j}, w_{d,j}, t_{s,d,j}, t_{e,d,j})$.\n\n**Step 1: Spatial Jaccard Similarity ($r_s$)**\n\nThe longitudinal extent of an event is an arc on a circle of circumference $C = 360^{\\circ}$. The similarity between two arcs, $A_m = A(\\ell_m, w_m)$ and $A_d = A(\\ell_d, w_d)$, is given by the Jaccard index $r_s = J(A_m, A_d) = \\frac{|A_m \\cap A_d|}{|A_m \\cup A_d|}$. The measure $|\\cdot|$ corresponds to the length of the arc in degrees.\n\nThe length of the union is given by $|A_m \\cup A_d| = |A_m| + |A_d| - |A_m \\cap A_d| = w_m + w_d - |A_m \\cap A_d|$.\nThe primary challenge is computing the intersection length $|A_m \\cap A_d|$ on a periodic domain. For two arcs defined by their center and width, the intersection length can be calculated elegantly. Let $\\Delta\\ell = |\\ell_m - \\ell_d|$ be the absolute difference in their longitude centers. The shortest distance between the centers on the circle is $\\Delta\\ell_{\\text{circ}} = \\min(\\Delta\\ell, 360 - \\Delta\\ell)$. Two arcs overlap if and only if this distance is less than the average of their widths, i.e., $\\Delta\\ell_{\\text{circ}}  (w_m + w_d)/2$. The length of their intersection is the extent of this overlap:\n$$\n|A_m \\cap A_d| = \\max\\left(0, \\frac{w_m + w_d}{2} - \\Delta\\ell_{\\text{circ}}\\right)\n$$\nWith this, the spatial Jaccard similarity is:\n$$\nr_s = \\frac{|A_m \\cap A_d|}{w_m + w_d - |A_m \\cap A_d|}\n$$\nIf the denominator is zero (which occurs only if $w_m=w_d=0$, not possible here), $r_s$ would be undefined but the case is excluded by $w  0$.\n\n**Step 2: Temporal Jaccard Similarity ($r_t$)**\n\nThe temporal support is an inclusive interval of integers (days). Let $I_m = I(t_{s,m}, t_{e,m})$ and $I_d = I(t_{s,d}, t_{e,d})$. The measure is cardinality. The length of an interval $I(t_s, t_e)$ is $|I| = t_e - t_s + 1$. The intersection of two intervals is $I_m \\cap I_d = [\\max(t_{s,m}, t_{s,d}), \\min(t_{e,m}, t_{e,d})]$. Its length is:\n$$\n|I_m \\cap I_d| = \\max\\left(0, \\min(t_{e,m}, t_{e,d}) - \\max(t_{s,m}, t_{s,d}) + 1\\right)\n$$\nThe temporal Jaccard similarity is then:\n$$\nr_t = \\frac{|I_m \\cap I_d|}{|I_m| + |I_d| - |I_m \\cap I_d|}\n$$\nIf the denominator is zero (i.e., both intervals have zero length, which cannot happen as $t_s \\le t_e$), $r_t$ is taken as $0$.\n\n**Step 3: Combined Similarity and Optimal Matching**\n\nFor each pair $(m_i, d_j)$, we compute $r_{s,ij}$ and $r_{t,ij}$. The pair is admissible if $r_{s,ij} \\ge \\tau_s$ and $r_{t,ij} \\ge \\tau_t$, where the problem specifies $\\tau_s = 0.5$ and $\\tau_t = 0.5$. The combined similarity score $S_{ij}$ is defined as:\n$$\nS_{ij} = \\begin{cases} r_{s,ij} \\times r_{t,ij}  \\text{if } r_{s,ij} \\ge \\tau_s \\text{ and } r_{t,ij} \\ge \\tau_t \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThis forms a similarity matrix $S$ of size $N_m \\times N_d$, where $N_m$ and $N_d$ are the number of manual and detected events, respectively. The goal is to find a set of one-to-one pairs $(i, j)$ that maximizes the total sum $\\sum S_{ij}$. This is a classic assignment problem, also known as maximum weight bipartite matching. It can be solved by converting it into a minimization problem by defining a cost matrix $C_{ij} = -S_{ij}$. Standard algorithms, such as the Hungarian algorithm, can then find the assignment that minimizes the total cost, which is equivalent to maximizing the total similarity. This is implemented in `scipy.optimize.linear_sum_assignment`.\n\n**Step 4: Calculation of Performance Metrics**\n\nThe solution to the assignment problem provides a set of matched pairs. A pair $(m_i, d_j)$ from this optimal matching is considered a true positive ($TP$) only if its similarity score $S_{ij}$ is greater than $0$. This intrinsically enforces the admissibility criteria.\n- **True Positives ($TP$)**: The number of matched pairs with $S_{ij}  0$.\n- **False Negatives ($FN$)**: The number of manual events that are not part of a true positive pair. $FN = N_m - TP$.\n- **False Positives ($FP$)**: The number of detected events that are not part of a true positive pair. $FP = N_d - TP$.\n\nWith these counts, the skill scores are calculated:\n- **Precision ($P$)**: $P = \\frac{TP}{TP+FP}$. If $TP+FP=0$, $P=0$.\n- **Recall ($R$)**: $R = \\frac{TP}{TP+FN}$. If $TP+FN=0$, $R=0$.\n- **F1 Score ($F1$)**: $F1 = \\frac{2PR}{P+R}$. If $P+R=0$, $F1=0$.\n\nFor each true positive pair $(m_i, d_j)$, the onset and cessation timing errors are calculated:\n- Onset error: $e_{s,ij} = t_{s,d,j} - t_{s,m,i}$\n- Cessation error: e_{e,ij} = t_{e,d,j} - t_{e,m,i}$\n\nThe final timing accuracy measures are the mean absolute errors over all $TP$ pairs:\n- Mean absolute onset error: $\\overline{|e_s|} = \\frac{1}{TP} \\sum_{k=1}^{TP} |e_{s,k}|$\n- Mean absolute cessation error: $\\overline{|e_e|} = \\frac{1}{TP} \\sum_{k=1}^{TP} |e_{e,k}|$\nIf $TP=0$, both mean absolute errors are reported as $0$. The final numerical results are rounded as specified in the problem statement.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        (\n            [(30, 60, 2, 10), (200, 50, 15, 22)],\n            [(35, 70, 3, 11), (205, 40, 16, 20)],\n        ),\n        # Case 2\n        (\n            [(350, 40, 5, 12)],\n            [(355, 50, 6, 13), (150, 30, 7, 10)],\n        ),\n        # Case 3\n        (\n            [(100, 60, 0, 9)],\n            [(102, 70, 0, 9), (98, 50, 2, 8)],\n        ),\n        # Case 4\n        (\n            [(250, 80, 10, 25), (300, 50, 5, 8)],\n            [(252, 70, 10, 17), (252, 70, 18, 25), (30, 40, 0, 3)],\n        ),\n        # Case 5\n        (\n            [(180, 100, 0, 10)],\n            [],\n        ),\n    ]\n\n    # Thresholds as defined in the problem\n    tau_s = 0.5\n    tau_t = 0.5\n\n    all_results = []\n    for manual_catalog, detected_events in test_cases:\n        result = _solve_single_case(manual_catalog, detected_events, tau_s, tau_t)\n        all_results.append(result)\n\n    # Format the final output string exactly as required\n    formatted_results = [\n        f\"[{res[0]:.3f},{res[1]:.3f},{res[2]:.3f},{res[3]:.2f},{res[4]:.2f},{res[5]},{res[6]}]\"\n        for res in all_results\n    ]\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _solve_single_case(manual_catalog, detected_events, tau_s, tau_t):\n    \"\"\"\n    Solves a single validation case.\n    \"\"\"\n    num_manual = len(manual_catalog)\n    num_detected = len(detected_events)\n\n    if num_manual == 0 or num_detected == 0:\n        tp = 0\n        fp = num_detected\n        fn = num_manual\n        p = 0.0 if (tp + fp) == 0 else tp / (tp + fp)\n        r = 0.0 if (tp + fn) == 0 else tp / (tp + fn)\n        f1 = 0.0 if (p + r) == 0 else 2 * p * r / (p + r)\n        mean_abs_onset_err = 0.0\n        mean_abs_cessation_err = 0.0\n        return [p, r, f1, mean_abs_onset_err, mean_abs_cessation_err, fp, fn]\n\n    similarity_matrix = np.zeros((num_manual, num_detected))\n\n    for i, m_event in enumerate(manual_catalog):\n        for j, d_event in enumerate(detected_events):\n            # Decompose events\n            l_m, w_m, ts_m, te_m = m_event\n            l_d, w_d, ts_d, te_d = d_event\n\n            # Spatial Jaccard\n            delta_l = abs(l_m - l_d)\n            delta_l_circ = min(delta_l, 360.0 - delta_l)\n            intersection_s = max(0.0, (w_m + w_d) / 2.0 - delta_l_circ)\n            union_s = w_m + w_d - intersection_s\n            r_s = intersection_s / union_s if union_s > 0 else 0.0\n            \n            # Temporal Jaccard\n            len_m = te_m - ts_m + 1\n            len_d = te_d - ts_d + 1\n            intersection_t = max(0, min(te_m, te_d) - max(ts_m, ts_d) + 1)\n            union_t = len_m + len_d - intersection_t\n            r_t = intersection_t / union_t if union_t > 0 else 0.0\n\n            # Combined score with admissibility\n            if r_s >= tau_s and r_t >= tau_t:\n                similarity_matrix[i, j] = r_s * r_t\n            else:\n                similarity_matrix[i, j] = 0.0\n\n    # Solve assignment problem (maximize similarity = minimize negative similarity)\n    cost_matrix = -similarity_matrix\n    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n\n    # Calculate metrics from matching\n    tp = 0\n    onset_errors = []\n    cessation_errors = []\n\n    for i, j in zip(row_ind, col_ind):\n        if similarity_matrix[i, j] > 0:\n            tp += 1\n            m_event = manual_catalog[i]\n            d_event = detected_events[j]\n            \n            onset_error = d_event[2] - m_event[2]\n            cessation_error = d_event[3] - m_event[3]\n            onset_errors.append(abs(onset_error))\n            cessation_errors.append(abs(cessation_error))\n\n    fp = num_detected - tp\n    fn = num_manual - tp\n\n    # Skill scores with conventions for zero denominators\n    p = 0.0 if (tp + fp) == 0 else tp / (tp + fp)\n    r = 0.0 if (tp + fn) == 0 else tp / (tp + fn)\n    f1 = 0.0 if (p + r) == 0 else 2 * p * r / (p + r)\n\n    # Timing accuracy with convention for no matches\n    mean_abs_onset_err = np.mean(onset_errors) if tp > 0 else 0.0\n    mean_abs_cessation_err = np.mean(cessation_errors) if tp > 0 else 0.0\n    \n    return [p, r, f1, mean_abs_onset_err, mean_abs_cessation_err, fp, fn]\n\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}