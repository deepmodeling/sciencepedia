{
    "hands_on_practices": [
        {
            "introduction": "Before any satellite radiance data can be assimilated, it must be rigorously monitored. This hands-on coding practice puts you in the role of an operational scientist analyzing Observation-minus-Background (O-B) statistics. By computing the bias and standard deviation from a set of O-B residuals, you will learn how to perform essential quality control, assess the consistency of your assumed error models ($R$ and $S = H B H^{\\top}$), and derive necessary corrections . This diagnostic step is fundamental to maintaining a healthy and effective data assimilation system.",
            "id": "4012568",
            "problem": "Consider the assimilation of satellite radiances in numerical weather prediction, focusing on Observation-minus-Background (O-B) diagnostics. Let the observed brightness temperatures be denoted by $y$, the background state by $x_b$, and the linearized observation operator by $H$. Under standard assumptions of linearity and additive noise, the observation model is $y = H x + \\varepsilon_o$, and the background is $x_b = x + \\varepsilon_b$, where $\\varepsilon_o$ and $\\varepsilon_b$ are zero-mean random errors. The O-B residual is defined by the difference $d \\equiv y - H x_b$, which can be written as $d = \\varepsilon_o - H \\varepsilon_b$. The observation error covariance is $R$, and the background error covariance mapped to observation space is $S = H B H^\\top$, where $B$ is the background error covariance in model space.\n\nYou are given monthly O-B samples for several channels (each channel corresponds to a distinct spectral measurement). For each channel, you are also given a prior observation error variance (the diagonal element of $R$ for that channel) and the corresponding background error variance in observation space $S$. Your tasks are:\n- For each channel, compute the sample mean (the bias) and the unbiased sample standard deviation of the O-B residuals. Express the bias and the standard deviation in Kelvin (K), rounded to three decimal places.\n- Assess whether the sample variance is consistent with the sum of the prior observation error variance and the background error variance in observation space. Specifically, declare consistency if the absolute difference between the sample variance and $R + S$ does not exceed a tolerance fraction $t$ of $R + S$. Use $t = 0.1$ (a decimal, not a percentage).\n- Propose adjustments for assimilation:\n  - A bias correction offset to be applied to the observed brightness temperature, equal to the negative of the estimated bias (so that the corrected O-B mean becomes closer to zero). Express this offset in Kelvin (K), rounded to three decimal places.\n  - An updated observation error variance $R_{\\text{new}}$ based on the method-of-moments principle that uses the sample variance and $S$. Use the rule $R_{\\text{new}} = \\max(r_{\\min}, \\text{sample\\_variance} - S)$ to ensure non-negativity and avoid degenerate values. Take $r_{\\min} = 0.01$ in $\\mathrm{K}^2$, and round $R_{\\text{new}}$ to three decimal places.\n\nUse the following test suite. For each test case, you are given multiple channels; for each channel, you are provided the O-B samples, the prior $R$ (variance in $\\mathrm{K}^2$), and $S$ (variance in $\\mathrm{K}^2$). All O-B values are in Kelvin (K).\n\nTest Case $1$:\n- Channel $1$: O-B samples $\\{0.4, 1.1, -0.2, 0.6, 0.5, -0.1, 0.9, -0.3, 1.3, 0.2, -0.4, 0.7, 0.8, -0.5, 1.0, 0.3, -0.2, 0.6, 0.4, 1.2\\}$, $R = 0.5$, $S = 0.5$.\n- Channel $2$: O-B samples $\\{-0.6, 0.7, 0.1, -0.4, 0.5, 0.2, -0.3, 0.4, -0.2, 0.3, 0.0, 0.5, -0.5, 0.6, -0.1, 0.2, -0.4, 0.3, -0.2, 0.4\\}$, $R = 0.8$, $S = 0.4$.\n- Channel $3$: O-B samples $\\{-1.5, 1.6, 0.9, -1.2, 1.3, -0.8, 1.1, -1.0, 1.4, -0.7, 1.0, -1.1, 1.5, -0.9, 1.2, -1.3, 1.4, -0.6, 0.8, -1.4\\}$, $R = 0.4$, $S = 0.3$.\n\nTest Case $2$:\n- Channel $1$: O-B samples $\\{0.1, 0.0, -0.1, 0.2, -0.2, 0.3, -0.3, 0.1, 0.0, -0.1, 0.2, -0.2, 0.3, -0.3, 0.1, 0.0, -0.1, 0.2, -0.2, 0.3\\}$, $R = 0.05$, $S = 0.4$.\n- Channel $2$: O-B samples $\\{2.0, 2.3, 1.7, 2.1, 1.9, 2.2, 2.4, 1.8, 2.0, 2.1, 1.9, 2.2, 2.3, 1.7, 2.1, 1.8, 2.0, 2.3, 1.9, 2.2\\}$, $R = 0.6$, $S = 0.5$.\n- Channel $3$: O-B samples $\\{0.3, -0.2, 0.1\\}$, $R = 0.3$, $S = 0.4$.\n\nTest Case $3$:\n- Channel $1$: O-B samples $\\{-1.1, 1.2, -0.9, 1.0, -1.2, 1.3, -1.0, 1.1, -1.1, 1.0, -0.9, 1.2, -1.0, 1.1, -1.2, 1.3, -1.0, 1.1, -1.1, 1.0\\}$, $R = 0.7$, $S = 0.5$.\n- Channel $2$: O-B samples $\\{-1.0, 1.1, -0.8, 0.9, -1.1, 1.2, -0.9, 1.0, -1.0, 0.9, -0.8, 1.1, -0.9, 1.0, -1.1, 1.2, -0.9, 1.0, -1.0, 0.9\\}$, $R = 0.3$, $S = 0.7$.\n\nYou must implement a complete, runnable program that:\n- Uses the provided test suite values as hard-coded inputs.\n- For each channel in each test case, computes the bias, unbiased sample standard deviation, consistency boolean (with tolerance $t = 0.1$), proposed bias correction offset (in Kelvin), and proposed updated observation error variance $R_{\\text{new}}$ (in $\\mathrm{K}^2$) with $r_{\\min} = 0.01$.\n- Produces a single line of output containing all test case results as a nested comma-separated list enclosed in square brackets. The outer list corresponds to the test cases; each inner list corresponds to the channels for that test case; each channel result is a list of five elements in the following order: [`bias_K`, `std_K`, `consistent`, `R_new_K2`, `bias_correction_K`], where the numerical entries are rounded to three decimals.\n\nAll biases and standard deviations must be expressed in Kelvin (K). All variances must be expressed in $\\mathrm{K}^2$. Round all numerical outputs to three decimal places.",
            "solution": "The problem has been validated and is deemed sound. It is a well-posed, scientifically grounded exercise in statistical diagnostics, a common practice in the field of satellite data assimilation for numerical weather prediction. We shall proceed with a formal solution.\n\nThe core of the problem lies in analyzing the Observation-minus-Background (O-B) residuals, denoted by $d$. The O-B residual for a given observation is defined as the difference between the observed value, $y$, and the model-predicted value, $H x_b$, where $H$ is the (linearized) observation operator and $x_b$ is the background state (a short-range forecast). The model for these quantities is:\n$$y = H x + \\varepsilon_o$$\n$$x_b = x + \\varepsilon_b$$\nwhere $x$ is the true state of the atmosphere, and $\\varepsilon_o$ and $\\varepsilon_b$ are the observation and background errors, respectively. These errors are assumed to be random variables with zero mean, i.e., $\\mathbb{E}[\\varepsilon_o] = 0$ and $\\mathbb{E}[\\varepsilon_b] = 0$.\n\nFrom these definitions, the O-B residual can be expressed in terms of the errors:\n$$d \\equiv y - H x_b = (H x + \\varepsilon_o) - H(x + \\varepsilon_b) = \\varepsilon_o - H \\varepsilon_b$$\n\nUnder the standard assumption that the observation and background errors are uncorrelated, the expected mean and variance of the O-B residuals can be derived.\n\nThe expected mean (or true bias) is:\n$$\\mathbb{E}[d] = \\mathbb{E}[\\varepsilon_o - H \\varepsilon_b] = \\mathbb{E}[\\varepsilon_o] - H\\mathbb{E}[\\varepsilon_b] = 0 - H \\cdot 0 = 0$$\nAny systematic deviation of the sample mean from $0$ indicates a bias in the observations or the model background.\n\nThe expected variance is:\n$$\\text{Var}(d) = \\text{Var}(\\varepsilon_o - H \\varepsilon_b)$$\nAssuming $\\varepsilon_o$ and $H\\varepsilon_b$ are uncorrelated, the variance of the difference is the sum of their variances:\n$$\\text{Var}(d) = \\text{Var}(\\varepsilon_o) + \\text{Var}(H \\varepsilon_b)$$\nThe variance of the observation error, $\\text{Var}(\\varepsilon_o)$, is a diagonal element of the observation error covariance matrix $R$. The problem provides this value for each channel. The variance of the background error projected into observation space, $\\text{Var}(H \\varepsilon_b)$, is a diagonal element of the matrix $S = HBH^\\top$, where $B$ is the background error covariance matrix. The problem provides this value $S$ as well. Therefore, the total expected variance of the O-B residuals for a single channel is:\n$$\\text{Var}(d) = R + S$$\n\nWith this theoretical foundation, we can outline the computational procedure for each channel given a set of $n$ O-B samples $\\{d_1, d_2, \\dots, d_n\\}$.\n\n1.  **Bias and Unbiased Sample Standard Deviation**:\n    The sample mean, which is an estimate of the bias, is calculated as:\n    $$\\text{bias} = \\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i$$\n    The unbiased sample variance is calculated to estimate the true variance of the population:\n    $$s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\bar{d})^2$$\n    The required unbiased sample standard deviation is the square root of this value, $s = \\sqrt{s^2}$. In the implementation, this is achieved using a degree of freedom `ddof=1`. The results are expressed in Kelvin (K).\n\n2.  **Consistency Assessment**:\n    This step verifies if the observed statistics are consistent with the a priori error assumptions. The sample variance $s^2$ is compared to the expected variance $R+S$. Consistency is declared if the absolute difference is within a specified tolerance fraction $t$ of the expected variance:\n    $$|s^2 - (R+S)| \\leq t \\cdot (R+S)$$\n    where the tolerance $t$ is given as $0.1$.\n\n3.  **Proposed Bias Correction**:\n    If a non-zero bias $\\bar{d}$ is detected, it should be removed from the observations to ensure they are unbiased relative to the model. The correction is applied to the observation $y$, so the corrected residual would be $(y - \\bar{d}) - Hx_b = d - \\bar{d}$. The appropriate correction offset to apply to the observation is therefore $-\\bar{d}$. This is the value we compute.\n\n4.  **Updated Observation Error Variance ($R_{\\text{new}}$)**:\n    The total sample variance $s^2$ is an estimate of the true total variance $R+S$. This suggests that an updated estimate of the observation error variance, $R_{\\text{new}}$, can be derived by subtracting the (assumed known) background contribution $S$ from the observed total variance. This is an application of the method-of-moments, often referred to as the Desroziers diagnostic:\n    $$R_{\\text{new}} = s^2 - S$$\n    To ensure the resulting variance is physically meaningful (i.e., non-negative) and to prevent instability from small samples, a minimum value $r_{\\min}$ is enforced:\n    $$R_{\\text{new}} = \\max(r_{\\min}, s^2 - S)$$\n    The problem specifies $r_{\\min} = 0.01 \\, \\mathrm{K}^2$. The result is expressed in $\\mathrm{K}^2$.\n\nAll numerical results are rounded to three decimal places as required. The implementation will process each channel in the test suite according to these principles.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Processes a suite of test cases for O-B diagnostics in satellite data assimilation.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        [\n            {'samples': [0.4, 1.1, -0.2, 0.6, 0.5, -0.1, 0.9, -0.3, 1.3, 0.2, -0.4, 0.7, 0.8, -0.5, 1.0, 0.3, -0.2, 0.6, 0.4, 1.2], 'R': 0.5, 'S': 0.5},\n            {'samples': [-0.6, 0.7, 0.1, -0.4, 0.5, 0.2, -0.3, 0.4, -0.2, 0.3, 0.0, 0.5, -0.5, 0.6, -0.1, 0.2, -0.4, 0.3, -0.2, 0.4], 'R': 0.8, 'S': 0.4},\n            {'samples': [-1.5, 1.6, 0.9, -1.2, 1.3, -0.8, 1.1, -1.0, 1.4, -0.7, 1.0, -1.1, 1.5, -0.9, 1.2, -1.3, 1.4, -0.6, 0.8, -1.4], 'R': 0.4, 'S': 0.3}\n        ],\n        # Test Case 2\n        [\n            {'samples': [0.1, 0.0, -0.1, 0.2, -0.2, 0.3, -0.3, 0.1, 0.0, -0.1, 0.2, -0.2, 0.3, -0.3, 0.1, 0.0, -0.1, 0.2, -0.2, 0.3], 'R': 0.05, 'S': 0.4},\n            {'samples': [2.0, 2.3, 1.7, 2.1, 1.9, 2.2, 2.4, 1.8, 2.0, 2.1, 1.9, 2.2, 2.3, 1.7, 2.1, 1.8, 2.0, 2.3, 1.9, 2.2], 'R': 0.6, 'S': 0.5},\n            {'samples': [0.3, -0.2, 0.1], 'R': 0.3, 'S': 0.4}\n        ],\n        # Test Case 3\n        [\n            {'samples': [-1.1, 1.2, -0.9, 1.0, -1.2, 1.3, -1.0, 1.1, -1.1, 1.0, -0.9, 1.2, -1.0, 1.1, -1.2, 1.3, -1.0, 1.1, -1.1, 1.0], 'R': 0.7, 'S': 0.5},\n            {'samples': [-1.0, 1.1, -0.8, 0.9, -1.1, 1.2, -0.9, 1.0, -1.0, 0.9, -0.8, 1.1, -0.9, 1.0, -1.1, 1.2, -0.9, 1.0, -1.0, 0.9], 'R': 0.3, 'S': 0.7}\n        ]\n    ]\n\n    t = 0.1  # Tolerance for consistency check\n    r_min = 0.01  # Minimum updated observation error variance\n\n    all_results = []\n    for test_case in test_cases:\n        case_results = []\n        for channel_data in test_case:\n            samples = np.array(channel_data['samples'])\n            R = channel_data['R']\n            S = channel_data['S']\n\n            # Ensure we can calculate unbiased variance (n > 1)\n            n_samples = len(samples)\n            if n_samples <= 1:\n                # This case is not in the problem data, but good practice to handle.\n                # The result would be undefined. Here we skip.\n                continue\n\n            # 1. Compute bias and unbiased sample standard deviation.\n            bias_K = np.mean(samples)\n            # Use ddof=1 for unbiased sample standard deviation.\n            std_K = np.std(samples, ddof=1)\n            \n            # 2. Assess consistency.\n            # Unbiased sample variance is the square of the unbiased standard deviation.\n            sample_variance = std_K**2\n            prior_total_variance = R + S\n            is_consistent = abs(sample_variance - prior_total_variance) <= t * prior_total_variance\n            \n            # 3. Propose bias correction offset.\n            bias_correction_K = -bias_K\n            \n            # 4. Propose updated observation error variance.\n            R_new_K2 = max(r_min, sample_variance - S)\n\n            # Store the five result items for the channel.\n            # No rounding yet, to maintain precision for formatting.\n            case_results.append([\n                bias_K,\n                std_K,\n                is_consistent,\n                R_new_K2,\n                bias_correction_K,\n            ])\n        all_results.append(case_results)\n\n    # Format the final output string as a nested list.\n    test_case_strings = []\n    for test_case_result in all_results:\n        channel_strings = []\n        for channel_result in test_case_result:\n            # Format each numerical value to 3 decimal places.\n            # Boolean is converted to string 'True' or 'False'.\n            items = [\n                f\"{channel_result[0]:.3f}\",\n                f\"{channel_result[1]:.3f}\",\n                str(channel_result[2]),\n                f\"{channel_result[3]:.3f}\",\n                f\"{channel_result[4]:.3f}\",\n            ]\n            channel_strings.append(f\"[{','.join(items)}]\")\n        test_case_strings.append(f\"[{','.join(channel_strings)}]\")\n    \n    final_output = f\"[{','.join(test_case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The previous exercise highlighted the critical role of the observation error variance, $R$. But how is this crucial quantity determined in practice? This exercise demystifies $R$ by guiding you through its construction from distinct physical error sources, including instrument noise, forward model uncertainty, and representativeness error . You will compute how specific scene characteristics, such as the presence of clouds, influence the total error budget, thereby learning how to assign a physically-based, situation-dependent weight to each observation.",
            "id": "4012550",
            "problem": "Consider a one-dimensional analysis of a layer-mean atmospheric temperature state, $x$ (in $\\mathrm{K}$), within the context of Numerical Weather Prediction (NWP) and climate data assimilation of infrared satellite radiances. Two channels of Brightness Temperature (BT) observations, $y_{1}$ and $y_{2}$ (each in $\\mathrm{K}$), are available from the same satellite over a heterogeneous scene with clouds. The observation operator is linearized about the background state, so that small perturbations satisfy $y' \\approx H x'$, where $H = [h_{1}, h_{2}]$ contains the linearized Jacobians $h_{1}$ and $h_{2}$ of BT with respect to the layer-mean temperature $x$. Observation errors are modeled as zero-mean, Gaussian, and mutually uncorrelated across channels under this scene, with observation-error covariance $\\mathbf{R} = \\mathrm{diag}(R_{11}, R_{22})$. Each channel’s error variance is the sum of three physically grounded contributions: instrument noise, forward-model error, and representativeness error arising from sub-footprint scene heterogeneity.\n\nUse the following scientifically plausible scene characteristics and instrument properties:\n- Background-error variance for $x$: $\\sigma_{b}^{2} = 4.0 \\,\\mathrm{K}^{2}$.\n- Linearized Jacobians: $h_{1} = 0.7$, $h_{2} = 0.4$.\n- Instrument noise (Noise-Equivalent Differential Temperature): $\\sigma_{\\mathrm{instr},1} = 0.12 \\,\\mathrm{K}$, $\\sigma_{\\mathrm{instr},2} = 0.18 \\,\\mathrm{K}$.\n- Forward-model error standard deviation (assumed channel-independent but uncorrelated for this scene): $\\sigma_{\\mathrm{fm}} = 0.07 \\,\\mathrm{K}$.\n- Cloud fraction: $f_{c} = 0.25$, sub-footprint temperature variability: $\\sigma_{\\mathrm{sub}} = 2.0 \\,\\mathrm{K}$.\n- Channel layer-sensitivity factors (fractional weighting of the target layer in the channel’s weighting function): $w_{1} = 0.8$, $w_{2} = 0.6$.\n- Representativeness error per channel is modeled as $\\sigma_{\\mathrm{repr},i} = w_{i}\\,\\sigma_{\\mathrm{sub}}\\,\\sqrt{f_{c}}$.\n\nTasks:\n1. Using the above definitions, compute $R_{11}$ and $R_{22}$ from $R_{ii} = \\sigma_{\\mathrm{instr},i}^{2} + \\sigma_{\\mathrm{fm}}^{2} + \\sigma_{\\mathrm{repr},i}^{2}$.\n2. Under linear-Gaussian assumptions with a scalar control variable $x$ and two observations, derive the scalar analysis-error variance $P^{a}$ in terms of the background-error variance and the observation-error covariance, and then compute its numerical value for this scene.\n3. Round your final answer to four significant figures. Express the final analysis-error variance in $\\mathrm{K}^{2}$.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, objective, and self-contained. The provided data and models are consistent with established principles in the field of satellite data assimilation for numerical weather prediction. We may therefore proceed with the solution.\n\nThe problem requires a three-part solution: first, the computation of the observation-error variances for two satellite channels; second, the derivation and computation of the analysis-error variance for a single atmospheric temperature state variable; and third, rounding the final result to the specified precision.\n\nFirst, we address the computation of the diagonal elements of the observation-error covariance matrix, $\\mathbf{R}$, which are $R_{11}$ and $R_{22}$. The problem states that the total observation-error variance for a given channel $i$, denoted $R_{ii}$, is the sum of variances from three independent error sources: instrument noise, forward-model error, and representativeness error. The formula is given as:\n$$R_{ii} = \\sigma_{\\mathrm{instr},i}^{2} + \\sigma_{\\mathrm{fm}}^{2} + \\sigma_{\\mathrm{repr},i}^{2}$$\nThe standard deviations for instrument noise ($\\sigma_{\\mathrm{instr},i}$) and forward-model error ($\\sigma_{\\mathrm{fm}}$) are provided. We must first calculate the representativeness error standard deviation, $\\sigma_{\\mathrm{repr},i}$, for each channel using the provided model:\n$$\\sigma_{\\mathrm{repr},i} = w_{i}\\,\\sigma_{\\mathrm{sub}}\\,\\sqrt{f_{c}}$$\nThe given parameters are: cloud fraction $f_{c} = 0.25$, sub-footprint temperature variability $\\sigma_{\\mathrm{sub}} = 2.0 \\, \\mathrm{K}$, and channel layer-sensitivity factors $w_{1} = 0.8$ and $w_{2} = 0.6$.\n\nFor channel $1$:\n$$\\sigma_{\\mathrm{repr},1} = w_{1}\\,\\sigma_{\\mathrm{sub}}\\,\\sqrt{f_{c}} = (0.8)(2.0)\\sqrt{0.25} = (0.8)(2.0)(0.5) = 0.8 \\, \\mathrm{K}$$\nFor channel $2$:\n$$\\sigma_{\\mathrm{repr},2} = w_{2}\\,\\sigma_{\\mathrm{sub}}\\,\\sqrt{f_{c}} = (0.6)(2.0)\\sqrt{0.25} = (0.6)(2.0)(0.5) = 0.6 \\, \\mathrm{K}$$\nNow, we can compute $R_{11}$ and $R_{22}$ using the given standard deviations for instrument noise ($\\sigma_{\\mathrm{instr},1} = 0.12 \\, \\mathrm{K}$, $\\sigma_{\\mathrm{instr},2} = 0.18 \\, \\mathrm{K}$) and forward-model error ($\\sigma_{\\mathrm{fm}} = 0.07 \\, \\mathrm{K}$).\n\nFor channel $1$:\n$$R_{11} = \\sigma_{\\mathrm{instr},1}^{2} + \\sigma_{\\mathrm{fm}}^{2} + \\sigma_{\\mathrm{repr},1}^{2} = (0.12)^{2} + (0.07)^{2} + (0.8)^{2}$$\n$$R_{11} = 0.0144 + 0.0049 + 0.64 = 0.6593 \\, \\mathrm{K}^{2}$$\nFor channel $2$:\n$$R_{22} = \\sigma_{\\mathrm{instr},2}^{2} + \\sigma_{\\mathrm{fm}}^{2} + \\sigma_{\\mathrm{repr},2}^{2} = (0.18)^{2} + (0.07)^{2} + (0.6)^{2}$$\n$$R_{22} = 0.0324 + 0.0049 + 0.36 = 0.3973 \\, \\mathrm{K}^{2}$$\n\nSecond, we derive the expression for the scalar analysis-error variance, $P^{a}$, and compute its value. The general formula for the inverse of the analysis-error covariance matrix, $\\mathbf{P}^{a}$, in linear-Gaussian estimation is:\n$$(\\mathbf{P}^{a})^{-1} = (\\mathbf{P}^{b})^{-1} + \\mathbf{H}^{T} \\mathbf{R}^{-1} \\mathbf{H}$$\nIn this problem, the state variable $x$ is a scalar, so its background-error covariance $\\mathbf{P}^{b}$ is the scalar variance $P^{b} = \\sigma_{b}^{2}$, and its analysis-error covariance $\\mathbf{P}^{a}$ is the scalar variance $P^{a}$. The observation vector has two components, so the Jacobian matrix $\\mathbf{H}$ (representing the sensitivity of the two observations to the single state variable) is a $2 \\times 1$ column vector:\n$$\\mathbf{H} = \\begin{pmatrix} h_{1} \\\\ h_{2} \\end{pmatrix}$$\nThe observation-error covariance matrix $\\mathbf{R}$ is a $2 \\times 2$ diagonal matrix, as the errors are uncorrelated:\n$$\\mathbf{R} = \\begin{pmatrix} R_{11} & 0 \\\\ 0 & R_{22} \\end{pmatrix}$$\nIts inverse is:\n$$\\mathbf{R}^{-1} = \\begin{pmatrix} \\frac{1}{R_{11}} & 0 \\\\ 0 & \\frac{1}{R_{22}} \\end{pmatrix}$$\nWe now compute the term $\\mathbf{H}^{T} \\mathbf{R}^{-1} \\mathbf{H}$:\n$$\\mathbf{H}^{T} \\mathbf{R}^{-1} \\mathbf{H} = \\begin{pmatrix} h_{1} & h_{2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{R_{11}} & 0 \\\\ 0 & \\frac{1}{R_{22}} \\end{pmatrix} \\begin{pmatrix} h_{1} \\\\ h_{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{h_{1}}{R_{11}} & \\frac{h_{2}}{R_{22}} \\end{pmatrix} \\begin{pmatrix} h_{1} \\\\ h_{2} \\end{pmatrix} = \\frac{h_{1}^{2}}{R_{11}} + \\frac{h_{2}^{2}}{R_{22}}$$\nThis term is a scalar, as expected. Substituting this into the scalar version of the analysis-error formula:\n$$\\frac{1}{P^{a}} = \\frac{1}{P^{b}} + \\frac{h_{1}^{2}}{R_{11}} + \\frac{h_{2}^{2}}{R_{22}}$$\nUsing $P^{b} = \\sigma_{b}^{2}$, the expression for $P^{a}$ is:\n$$P^{a} = \\left( \\frac{1}{\\sigma_{b}^{2}} + \\frac{h_{1}^{2}}{R_{11}} + \\frac{h_{2}^{2}}{R_{22}} \\right)^{-1}$$\nWe now substitute the numerical values: $\\sigma_{b}^{2} = 4.0 \\, \\mathrm{K}^{2}$, $h_{1} = 0.7$, $h_{2} = 0.4$, and the previously computed values for $R_{11}$ and $R_{22}$.\n\nFirst, calculate the individual terms of the sum (which represent information content, or precision, in units of $\\mathrm{K}^{-2}$):\n$$\\frac{1}{\\sigma_{b}^{2}} = \\frac{1}{4.0} = 0.25 \\, \\mathrm{K}^{-2}$$\n$$\\frac{h_{1}^{2}}{R_{11}} = \\frac{(0.7)^{2}}{0.6593} = \\frac{0.49}{0.6593} \\approx 0.7432125 \\, \\mathrm{K}^{-2}$$\n$$\\frac{h_{2}^{2}}{R_{22}} = \\frac{(0.4)^{2}}{0.3973} = \\frac{0.16}{0.3973} \\approx 0.4027183 \\, \\mathrm{K}^{-2}$$\nThe inverse of the analysis-error variance is the sum of these precisions:\n$$\\frac{1}{P^{a}} = 0.25 + 0.7432125... + 0.4027183... = 1.3959308... \\, \\mathrm{K}^{-2}$$\nThe analysis-error variance is the reciprocal of this sum:\n$$P^{a} = \\frac{1}{1.3959308...} \\approx 0.7163683 \\, \\mathrm{K}^{2}$$\n\nThird, the problem requires rounding the final answer to four significant figures.\n$$P^{a} \\approx 0.7164 \\, \\mathrm{K}^{2}$$\nThis final value represents the expected squared error of the atmospheric temperature estimate after optimally combining the background information with the two satellite observations. As expected, $P^{a} < \\sigma_{b}^{2}$, indicating that the observations have reduced the uncertainty in the state estimate.",
            "answer": "$$ \\boxed{0.7164} $$"
        },
        {
            "introduction": "Having explored how to diagnose observations and model their errors, we now turn to the mathematical core of data assimilation. This exercise focuses on calculating the analysis increment, which is the correction applied to the model's background state based on an observation. Using a simplified but complete variational framework, you will see precisely how the background-error covariance $\\mathbf{B}$, the observation-error covariance $\\mathbf{R}$, and the linearized observation operator $\\mathbf{K}$ combine to produce the optimal analysis . This fundamental calculation is the engine that drives forecast improvement in all modern assimilation systems.",
            "id": "4012633",
            "problem": "In a linearized variational data assimilation setting for Numerical Weather Prediction (NWP), consider a single bias-corrected satellite radiance channel being assimilated into a two-dimensional control space. The control vector $\\mathbf{x}$ represents two normalized, nondimensional control variables. The background-error covariance matrix $\\mathbf{B}$, the observation-error covariance $\\mathbf{R}$ (a scalar for a single channel), and the linearized observation operator Jacobian (often called the weighting function or Jacobian) $\\mathbf{K}$ are specified as\n$$\n\\mathbf{B} \\;=\\; \\begin{pmatrix} 2 & 0 \\\\[4pt] 0 & 1 \\end{pmatrix}, \n\\qquad \n\\mathbf{R} \\;=\\; 2,\n\\qquad \n\\mathbf{K} \\;=\\; \\begin{pmatrix} 1 & 2 \\end{pmatrix}.\n$$\nLet the innovation (observation minus model equivalent at the background) be the scalar\n$$\nd \\;=\\; y \\;-\\; H(\\mathbf{x_b}) \\;=\\; 3.\n$$\nAssume the standard linear-Gaussian setting with unbiased errors, where the analysis is obtained by minimizing the quadratic Bayesian cost function with background and observation terms, and where the linearization of the forward operator about the background yields $H(\\mathbf{x_b} + \\delta \\mathbf{x}) \\approx H(\\mathbf{x_b}) + \\mathbf{K}\\,\\delta \\mathbf{x}$.\n\nStarting from these foundations, derive the closed-form expressions for the analysis increment $\\delta \\mathbf{x}$ and the analysis residual $r_a = y - H(\\mathbf{x_a})$, where $\\mathbf{x_a} = \\mathbf{x_b} + \\delta \\mathbf{x}$. Then compute their numerical values for the specified $\\mathbf{B}$, $\\mathbf{R}$, $\\mathbf{K}$, and $d$.\n\nAll variables are nondimensional by construction; no physical units are required. Provide the final numerical answer as a single row matrix containing, in order, the two components of $\\delta \\mathbf{x}$ followed by the residual $r_a$. No rounding is required; give exact values.",
            "solution": "The problem is valid as it represents a standard, well-posed problem in variational data assimilation, with all necessary components defined consistently.\n\nThe analysis is determined by minimizing a quadratic cost function, $J$, which measures the misfit of the analysis state to both the background state and the observations, weighted by their respective error covariances. The control variable is the analysis increment, $\\delta \\mathbf{x} = \\mathbf{x_a} - \\mathbf{x_b}$, where $\\mathbf{x_a}$ is the analysis state and $\\mathbf{x_b}$ is the background state. The cost function $J(\\delta \\mathbf{x})$ is given by:\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2} (\\delta \\mathbf{x})^T \\mathbf{B}^{-1} \\delta \\mathbf{x} + \\frac{1}{2} (y - H(\\mathbf{x_b} + \\delta \\mathbf{x}))^T \\mathbf{R}^{-1} (y - H(\\mathbf{x_b} + \\delta \\mathbf{x}))\n$$\nUnder the assumption of linearity, the observation operator $H$ can be approximated around the background state $\\mathbf{x_b}$ as $H(\\mathbf{x_b} + \\delta \\mathbf{x}) \\approx H(\\mathbf{x_b}) + \\mathbf{K}\\delta \\mathbf{x}$, where $\\mathbf{K}$ is the Jacobian of $H$ evaluated at $\\mathbf{x_b}$. The second term of the cost function involves the difference between the observation $y$ and the model equivalent of the analysis, which can be written as:\n$$\ny - H(\\mathbf{x_a}) \\approx y - (H(\\mathbf{x_b}) + \\mathbf{K}\\delta \\mathbf{x}) = (y - H(\\mathbf{x_b})) - \\mathbf{K}\\delta \\mathbf{x} = d - \\mathbf{K}\\delta \\mathbf{x}\n$$\nHere, $d = y - H(\\mathbf{x_b})$ is the innovation vector (a scalar in this case). The cost function becomes:\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2} (\\delta \\mathbf{x})^T \\mathbf{B}^{-1} \\delta \\mathbf{x} + \\frac{1}{2} (d - \\mathbf{K}\\delta \\mathbf{x})^T \\mathbf{R}^{-1} (d - \\mathbf{K}\\delta \\mathbf{x})\n$$\nSince the observation is a single scalar value, $\\mathbf{R}$, $d$, and $\\mathbf{K}\\delta\\mathbf{x}$ are also scalars. The transpose in the second term can be omitted.\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2} (\\delta \\mathbf{x})^T \\mathbf{B}^{-1} \\delta \\mathbf{x} + \\frac{1}{2} \\mathbf{R}^{-1} (d - \\mathbf{K}\\delta \\mathbf{x})^{2}\n$$\nTo find the analysis increment $\\delta \\mathbf{x}$ that minimizes $J$, we compute the gradient of $J$ with respect to $\\delta \\mathbf{x}$ and set it to zero:\n$$\n\\nabla_{\\delta\\mathbf{x}} J(\\delta \\mathbf{x}) = \\mathbf{B}^{-1} \\delta \\mathbf{x} - \\mathbf{K}^T \\mathbf{R}^{-1} (d - \\mathbf{K}\\delta \\mathbf{x}) = \\mathbf{0}\n$$\nRearranging the terms to solve for $\\delta \\mathbf{x}$:\n$$\n\\mathbf{B}^{-1} \\delta \\mathbf{x} + \\mathbf{K}^T \\mathbf{R}^{-1} \\mathbf{K}\\delta \\mathbf{x} = \\mathbf{K}^T \\mathbf{R}^{-1} d\n$$\n$$\n(\\mathbf{B}^{-1} + \\mathbf{K}^T \\mathbf{R}^{-1} \\mathbf{K}) \\delta \\mathbf{x} = \\mathbf{K}^T \\mathbf{R}^{-1} d\n$$\nThis leads to the analysis-space solution for the increment:\n$$\n\\delta \\mathbf{x} = (\\mathbf{B}^{-1} + \\mathbf{K}^T \\mathbf{R}^{-1} \\mathbf{K})^{-1} \\mathbf{K}^T \\mathbf{R}^{-1} d\n$$\nAn equivalent and often more computationally convenient form, known as the observation-space solution, can be obtained by applying the Sherman-Morrison-Woodbury formula. This gives:\n$$\n\\delta \\mathbf{x} = \\mathbf{B} \\mathbf{K}^T (\\mathbf{R} + \\mathbf{K} \\mathbf{B} \\mathbf{K}^T)^{-1} d\n$$\nThis form is particularly advantageous here as it requires the inversion of the scalar quantity $\\mathbf{R} + \\mathbf{K} \\mathbf{B} \\mathbf{K}^T$ instead of the $2 \\times 2$ matrix $(\\mathbf{B}^{-1} + \\mathbf{K}^T \\mathbf{R}^{-1} \\mathbf{K})$.\n\nWe now substitute the given values:\n$$\n\\mathbf{B} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad \\mathbf{R} = 2, \\quad \\mathbf{K} = \\begin{pmatrix} 1 & 2 \\end{pmatrix}, \\quad d = 3.\n$$\nFirst, we compute the term $\\mathbf{K} \\mathbf{B} \\mathbf{K}^T$:\n$$\n\\mathbf{K}^T = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\n$$\n$$\n\\mathbf{K} \\mathbf{B} = \\begin{pmatrix} 1 & 2 \\end{pmatrix} \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} (1)(2) + (2)(0) & (1)(0) + (2)(1) \\end{pmatrix} = \\begin{pmatrix} 2 & 2 \\end{pmatrix}\n$$\n$$\n\\mathbf{K} \\mathbf{B} \\mathbf{K}^T = \\begin{pmatrix} 2 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = (2)(1) + (2)(2) = 2 + 4 = 6\n$$\nNext, we compute the scalar to be inverted:\n$$\n\\mathbf{R} + \\mathbf{K} \\mathbf{B} \\mathbf{K}^T = 2 + 6 = 8\n$$\nIts inverse is simply $(\\mathbf{R} + \\mathbf{K} \\mathbf{B} \\mathbf{K}^T)^{-1} = 8^{-1} = \\frac{1}{8}$.\nWe also need the term $\\mathbf{B} \\mathbf{K}^T$:\n$$\n\\mathbf{B} \\mathbf{K}^T = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} (2)(1) + (0)(2) \\\\ (0)(1) + (1)(2) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\n$$\nNow we assemble the expression for $\\delta \\mathbf{x}$:\n$$\n\\delta \\mathbf{x} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} \\left(\\frac{1}{8}\\right) (3) = \\frac{3}{8} \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{8} \\\\ \\frac{6}{8} \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{4} \\\\ \\frac{3}{4} \\end{pmatrix}\n$$\nSo the components of the analysis increment are $\\delta x_1 = \\frac{3}{4}$ and $\\delta x_2 = \\frac{3}{4}$.\n\nNext, we derive and compute the analysis residual, $r_a$. The analysis residual is defined as the observation minus the model equivalent at the analysis state, $r_a = y - H(\\mathbf{x_a})$.\nUsing the linear approximation around $\\mathbf{x_b}$:\n$$\nr_a = y - H(\\mathbf{x_b} + \\delta\\mathbf{x}) \\approx y - (H(\\mathbf{x_b}) + \\mathbf{K}\\delta\\mathbf{x})\n$$\n$$\nr_a = (y - H(\\mathbf{x_b})) - \\mathbf{K}\\delta\\mathbf{x} = d - \\mathbf{K}\\delta\\mathbf{x}\n$$\nUsing the computed value of $\\delta \\mathbf{x}$:\n$$\nr_a = 3 - \\begin{pmatrix} 1 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{3}{4} \\\\ \\frac{3}{4} \\end{pmatrix} = 3 - \\left( (1)\\left(\\frac{3}{4}\\right) + (2)\\left(\\frac{3}{4}\\right) \\right)\n$$\n$$\nr_a = 3 - \\left( \\frac{3}{4} + \\frac{6}{4} \\right) = 3 - \\frac{9}{4} = \\frac{12}{4} - \\frac{9}{4} = \\frac{3}{4}\n$$\nThe analysis residual is $r_a = \\frac{3}{4}$.\n\nThe final answer requires the two components of $\\delta \\mathbf{x}$ and the residual $r_a$ in a single row matrix. These values are $\\delta x_1 = \\frac{3}{4}$, $\\delta x_2 = \\frac{3}{4}$, and $r_a = \\frac{3}{4}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{4} & \\frac{3}{4} & \\frac{3}{4} \\end{pmatrix}}\n$$"
        }
    ]
}