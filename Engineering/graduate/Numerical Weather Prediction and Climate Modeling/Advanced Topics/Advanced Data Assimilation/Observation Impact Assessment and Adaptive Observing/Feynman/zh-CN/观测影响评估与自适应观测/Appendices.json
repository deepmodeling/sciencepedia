{
    "hands_on_practices": [
        {
            "introduction": "在数据同化中，准确设定观测误差是至关重要的一步。总观测误差不仅包括仪器噪声，还包括代表性误差，后者源于点测量与模式网格平均值之间的尺度不匹配。本练习  将通过一个简化的思想实验，带你定量地分析忽略代表性误差会如何导致对观测影响的过度自信，并使用信号自由度（DFS）作为评估指标。",
            "id": "4071079",
            "problem": "考虑一个用于数值天气预报系统中单个大气网格单元的一维线性高斯数据同化情景。设真实状态为标量温度异常 $x$（单位为开尔文），其先验（背景）估计为 $x_b$，背景误差协方差为 $B = \\mathbb{E}\\big[(x - x_b)^2\\big]$。一个原位温度计在一个代表未分辨的次网格变率的位置上测量了瞬时点温度 $y$。观测算子为 $H = 1$，它将网格单元平均异常映射到观测异常。\n\n假设总观测误差是两个独立分量之和：方差为 $\\sigma_{o}^{2}$ 的仪器噪声，以及由未分辨的次网格变率和点测量与网格单元平均值之间的不匹配所引起的、方差为 $\\sigma_{\\mathrm{rep}}^{2}$ 的代表性误差。因此，物理上正确的观测误差方差是 $R_{\\mathrm{true}} = \\sigma_{o}^{2} + \\sigma_{\\mathrm{rep}}^{2}$。\n\n一位分析员错误地忽略了代表性误差，并使用 $R_{\\mathrm{wrong}} = \\sigma_{o}^{2}$ 来同化观测。假设使用线性贝叶斯更新（等同于卡尔曼滤波更新）进行分析。\n\n从线性高斯假设下的分析更新定义，以及观测的信号自由度（DFS）定义为分析观测对输入观测的敏感度的迹出发，推导出用 $B$、$H$ 和 $R$ 表示的 DFS 表达式。然后，使用 $R_{\\mathrm{true}}$ 和 $R_{\\mathrm{wrong}}$ 对以下参数值计算 DFS：\n- $B = 1.0 \\ \\mathrm{K}^{2}$，\n- $\\sigma_{o}^{2} = 0.1 \\ \\mathrm{K}^{2}$，\n- $\\sigma_{\\mathrm{rep}}^{2} = 0.9 \\ \\mathrm{K}^{2}$，\n- $H = 1$。\n\n最后，计算因忽略代表性误差而引起的 DFS 偏差，定义为 $\\mathrm{bias} = \\mathrm{DFS}(R_{\\mathrm{wrong}}) - \\mathrm{DFS}(R_{\\mathrm{true}})$，并给出结果。\n\n将最终偏差表示为一个无量纲数，并将答案四舍五入到四位有效数字。",
            "solution": "问题陈述已经过验证，被认为是自洽的、有科学依据且适定的。获得唯一解所需的所有数据和定义均已提供，并且该场景是数据同化领域中一个标准且重要的问题。\n\n第一步是推导信号自由度（DFS）的通用表达式。由线性贝叶斯更新（或卡尔曼滤波更新）产生的分析状态 $x_a$ 由下式给出：\n$$x_a = x_b + K(y - Hx_b)$$\n其中 $x_b$ 是背景状态， $y$ 是观测， $H$ 是观测算子， $K$ 是卡尔曼增益。卡尔曼增益表示为：\n$$K = B H^T (H B H^T + R)^{-1}$$\n此处，$B$ 是背景误差协方差，$R$ 是观测误差协方差。\n\n问题将 DFS 定义为分析观测 $y_a$ 对输入观测 $y$ 的敏感度的迹。分析观测是分析状态投影回观测空间的结果：\n$$y_a = H x_a$$\n代入 $x_a$ 的表达式：\n$$y_a = H(x_b + K(y - Hx_b)) = Hx_b + HK y - H K H x_b$$\n为求得 $y_a$ 对 $y$ 的敏感度，我们计算其导数，并将 $x_b$、$B$、$R$ 和 $H$ 视为与观测 $y$ 无关：\n$$\\frac{\\partial y_a}{\\partial y} = H K$$\nDFS 是该敏感度矩阵的迹：\n$$\\mathrm{DFS} = \\mathrm{tr}(HK)$$\n对于本问题中提出的一维标量情况，所有量（$x, x_b, y, B, R, H$）都是标量。转置运算变得无足轻重（$H^T = H$），矩阵求逆变为标量取倒数，标量的迹就是其自身。$K$ 和 DFS 的表达式简化为：\n$$K = B H (H B H + R)^{-1} = \\frac{BH}{H^2 B + R}$$\n$$\\mathrm{DFS} = HK = H \\left( \\frac{BH}{H^2 B + R} \\right) = \\frac{H^2 B}{H^2 B + R}$$\n这 就是在该标量情景下所要求的 DFS 通用表达式。\n\n接下来，我们对两个指定的观测误差方差 $R_{\\mathrm{true}}$ 和 $R_{\\mathrm{wrong}}$ 计算 DFS。给定的参数是：\n- 背景误差方差：$B = 1.0 \\ \\mathrm{K}^{2}$\n- 仪器噪声方差：$\\sigma_{o}^{2} = 0.1 \\ \\mathrm{K}^{2}$\n- 代表性误差方差：$\\sigma_{\\mathrm{rep}}^{2} = 0.9 \\ \\mathrm{K}^{2}$\n- 观测算子：$H = 1$\n\n物理上正确的观测误差方差 $R_{\\mathrm{true}}$ 包含两个误差源：\n$$R_{\\mathrm{true}} = \\sigma_{o}^{2} + \\sigma_{\\mathrm{rep}}^{2} = 0.1 + 0.9 = 1.0 \\ \\mathrm{K}^{2}$$\n分析员使用的不正确的观测误差方差 $R_{\\mathrm{wrong}}$ 忽略了代表性误差：\n$$R_{\\mathrm{wrong}} = \\sigma_{o}^{2} = 0.1 \\ \\mathrm{K}^{2}$$\n\n现在我们使用推导出的公式 $\\mathrm{DFS} = \\frac{H^2 B}{H^2 B + R}$ 计算每种情况下的 DFS。\n\n对于真实误差方差，$\\mathrm{DFS}(R_{\\mathrm{true}})$：\n$$\\mathrm{DFS}(R_{\\mathrm{true}}) = \\frac{1^2 \\cdot 1.0}{1^2 \\cdot 1.0 + R_{\\mathrm{true}}} = \\frac{1.0}{1.0 + 1.0} = \\frac{1.0}{2.0} = 0.5$$\n\n对于不正确误差方差，$\\mathrm{DFS}(R_{\\mathrm{wrong}})$：\n$$\\mathrm{DFS}(R_{\\mathrm{wrong}}) = \\frac{1^2 \\cdot 1.0}{1^2 \\cdot 1.0 + R_{\\mathrm{wrong}}} = \\frac{1.0}{1.0 + 0.1} = \\frac{1.0}{1.1} = \\frac{10}{11}$$\n\n最后，我们计算 DFS 的偏差，定义为 $\\mathrm{bias} = \\mathrm{DFS}(R_{\\mathrm{wrong}}) - \\mathrm{DFS}(R_{\\mathrm{true}})$。\n$$\\mathrm{bias} = \\frac{10}{11} - 0.5 = \\frac{10}{11} - \\frac{1}{2} = \\frac{20 - 11}{22} = \\frac{9}{22}$$\n为了提供最终的数值答案，我们将此分数转换为小数并四舍五入到四位有效数字：\n$$\\frac{9}{22} \\approx 0.40909090...$$\n四舍五入到四位有效数字，偏差为 $0.4091$。这个正偏差表明，忽略代表性误差会导致对观测在分析中影响的显著高估。",
            "answer": "$$\\boxed{0.4091}$$"
        },
        {
            "introduction": "虽然线性假设为观测影响评估提供了基础，但真实的预报模型本质上是非线性的。本实践  旨在探讨强非线性如何打破线性敏感性分析中的简单叠加原理。通过一个精心构建的标量模型，你将证明观测的影响并非总是积极的，其效果会依赖于新息的大小，这为我们提供了超越线性直觉的深刻见解。",
            "id": "4071058",
            "problem": "考虑一个标量预报-分析系统，该系统设计用于研究强非线性下的观测影响预报敏感性 (FSOI) 和自适应观测。设标量状态为 $x \\in \\mathbb{R}$，背景为 $x_b = 0$。单个标量观测 $y \\in \\mathbb{R}$ 通过线性观测算子 $H(x) = x$ 观测该状态，观测误差方差为 $\\sigma_o^2 = 1$。背景误差方差为 $\\sigma_b^2 = 1$，因此通过标准线性化高斯公式在 $x_b$ 处计算的增量三维变分 (3D-Var) 分析更新为\n$$\n\\delta x_a \\equiv x_a - x_b = K \\,\\varepsilon,\n$$\n其中新息为 $\\varepsilon \\equiv y - H(x_b)$，分析增益为 $K \\equiv \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}$。\n\n定义标量非线性预报映射为 $M(x) = x - x^3$，它代表一个简单的饱和增长过程。标量预报检验量为 $z = 1$。定义预报度量\n$$\nJ_f(x) \\equiv \\frac{1}{2}\\,\\big(M(x) - z\\big)^2,\n$$\n这是一个标准的平方误差型目标泛函。在 $x_b$ 处的 FSOI 线性估计是基于一阶变分 $\\delta J_f \\approx \\nabla J_f(x_b) \\,\\delta x_a$，该变分通过切线性/伴随链计算得出。\n\n任务：\n1. 从以上定义和特化到标量情况的多元泰勒展开出发，推导真实预报度量变化 $\\Delta J_f(\\varepsilon) \\equiv J_f(x_a) - J_f(x_b)$ 按新息 $\\varepsilon$ 幂次的三阶展开，表示为\n$$\n\\Delta J_f(\\varepsilon) = A\\,\\varepsilon + B\\,\\varepsilon^2 + C\\,\\varepsilon^3 + \\mathcal{O}(\\varepsilon^4),\n$$\n并用 $K$、$z$ 以及 $M$ 在 $x_b$ 处的导数来确定 $A$、$B$ 和 $C$。\n2. 使用具体值 $\\sigma_b^2 = \\sigma_o^2 = 1$ (因此 $K=\\tfrac{1}{2}$)，$x_b=0$，$M(x)=x - x^3$ 和 $z=1$，计算 $\\Delta J_f(\\varepsilon)$ 的显式三次近似，并解析地证明线性叠加失效，即一般情况下 $\\Delta J_f(\\varepsilon_1 + \\varepsilon_2) \\neq \\Delta J_f(\\varepsilon_1) + \\Delta J_f(\\varepsilon_2)$。\n3. 使用与任务2中相同的参数值，确定使预报度量变化符号改变的最小正新息振幅 $\\varepsilon^{\\star} > 0$，即方程 $\\Delta J_f(\\varepsilon) = 0$ 在 $\\varepsilon=0$ 的平凡根之外的最小正根。请将 $\\varepsilon^{\\star}$ 的最终答案以单个精确的闭式表达式给出。由于要求精确表达式，因此无需四舍五入。新息 $\\varepsilon$ 是无量纲的，因此请将最终结果表示为一个无量纲数。",
            "solution": "问题陈述经评估有效。它以数据同化和预报敏感性原理为科学基础，使用了一个标准的、尽管简化的非线性模型。给定的参数和定义是自洽、一致且适定的，从而能够得到唯一且有意义的解。各项任务是客观的，并且在数学上是严谨的。\n\n我们依次处理这三个任务。\n\n### 任务1：泰勒展开的推导\n真实预报度量变化定义为 $\\Delta J_f(\\varepsilon) \\equiv J_f(x_a) - J_f(x_b)$。分析状态 $x_a$ 由更新公式 $x_a = x_b + \\delta x_a = x_b + K\\varepsilon$ 给出。\n将此代入 $\\Delta J_f(\\varepsilon)$ 的定义中，得到：\n$$\n\\Delta J_f(\\varepsilon) = J_f(x_b + K\\varepsilon) - J_f(x_b)\n$$\n我们寻求此表达式关于新息 $\\varepsilon$ 在 $\\varepsilon = 0$ 附近的幂次的三阶泰勒级数展开。设 $g(\\varepsilon) = J_f(x_b + K\\varepsilon)$。$\\Delta J_f(\\varepsilon) = g(\\varepsilon) - g(0)$ 在 $\\varepsilon=0$ 附近的泰勒展开为：\n$$\n\\Delta J_f(\\varepsilon) = g'(0)\\varepsilon + \\frac{g''(0)}{2!}\\varepsilon^2 + \\frac{g'''(0)}{3!}\\varepsilon^3 + \\mathcal{O}(\\varepsilon^4)\n$$\n系数为 $A = g'(0)$，$B = \\frac{1}{2}g''(0)$ 和 $C = \\frac{1}{6}g'''(0)$。我们使用链式法则计算 $g(\\varepsilon)$ 关于 $\\varepsilon$ 的导数：\n$$\ng'(\\varepsilon) = \\frac{d}{d\\varepsilon} J_f(x_b + K\\varepsilon) = J_f'(x_b + K\\varepsilon) \\cdot K\n$$\n$$\ng''(\\varepsilon) = \\frac{d}{d\\varepsilon} [K J_f'(x_b + K\\varepsilon)] = J_f''(x_b + K\\varepsilon) \\cdot K^2\n$$\n$$\ng'''(\\varepsilon) = \\frac{d}{d\\varepsilon} [K^2 J_f''(x_b + K\\varepsilon)] = J_f'''(x_b + K\\varepsilon) \\cdot K^3\n$$\n在 $\\varepsilon = 0$ 处对这些导数求值（这对应于在 $x=x_b$ 处对 $J_f$ 的导数求值）：\n$$\ng'(0) = K J_f'(x_b)\n$$\n$$\ng''(0) = K^2 J_f''(x_b)\n$$\n$$\ng'''(0) = K^3 J_f'''(x_b)\n$$\n接下来，我们求预报度量 $J_f(x) = \\frac{1}{2}(M(x) - z)^2$ 关于 $x$ 的前三阶导数：\n$$\nJ_f'(x) = \\frac{dJ_f}{dx} = (M(x) - z) M'(x)\n$$\n$$\nJ_f''(x) = \\frac{d^2J_f}{dx^2} = [M'(x)]^2 + (M(x) - z) M''(x)\n$$\n$$\nJ_f'''(x) = \\frac{d^3J_f}{dx^3} = 2M'(x)M''(x) + M''(x)M'(x) + (M(x) - z)M'''(x) = 3M'(x)M''(x) + (M(x) - z)M'''(x)\n$$\n现在，我们可以用 $K$、$z$ 以及 $M(x)$ 在 $x_b$ 处的导数值来表示系数 $A$、$B$ 和 $C$：\n$$\nA = g'(0) = K J_f'(x_b) = K (M(x_b) - z) M'(x_b)\n$$\n$$\nB = \\frac{1}{2}g''(0) = \\frac{1}{2} K^2 J_f''(x_b) = \\frac{1}{2} K^2 \\left( [M'(x_b)]^2 + (M(x_b) - z) M''(x_b) \\right)\n$$\n$$\nC = \\frac{1}{6}g'''(0) = \\frac{1}{6} K^3 J_f'''(x_b) = \\frac{1}{6} K^3 \\left( 3M'(x_b)M''(x_b) + (M(x_b) - z)M'''(x_b) \\right)\n$$\n至此，任务1的推导完成。\n\n### 任务2：具体值与叠加原理的失效\n给定具体值：$\\sigma_b^2 = 1$，$\\sigma_o^2 = 1$，$x_b = 0$，$M(x) = x - x^3$ 和 $z = 1$。\n首先，我们计算 Kalman 增益 $K$：\n$$\nK = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} = \\frac{1}{1 + 1} = \\frac{1}{2}\n$$\n接下来，我们计算 $M(x)$ 的导数并在 $x_b = 0$ 处求值：\n$M(x) = x - x^3 \\implies M(0) = 0$\n$M'(x) = 1 - 3x^2 \\implies M'(0) = 1$\n$M''(x) = -6x \\implies M''(0) = 0$\n$M'''(x) = -6 \\implies M'''(0) = -6$\n现在我们将这些值代入系数 $A$、$B$ 和 $C$ 的表达式中：\n$$\nA = K (M(0) - z) M'(0) = \\frac{1}{2} (0 - 1) (1) = -\\frac{1}{2}\n$$\n$$\nB = \\frac{1}{2} K^2 \\left( [M'(0)]^2 + (M(0) - z) M''(0) \\right) = \\frac{1}{2} \\left(\\frac{1}{2}\\right)^2 \\left( [1]^2 + (0-1)(0) \\right) = \\frac{1}{2} \\cdot \\frac{1}{4} \\cdot (1) = \\frac{1}{8}\n$$\n$$\nC = \\frac{1}{6} K^3 \\left( 3 M'(0) M''(0) + (M(0) - z) M'''(0) \\right) = \\frac{1}{6} \\left(\\frac{1}{2}\\right)^3 \\left( 3(1)(0) + (0-1)(-6) \\right) = \\frac{1}{6} \\cdot \\frac{1}{8} \\cdot (6) = \\frac{6}{48} = \\frac{1}{8}\n$$\n因此，$\\Delta J_f(\\varepsilon)$ 的显式三次近似为：\n$$\n\\Delta J_f(\\varepsilon) = -\\frac{1}{2}\\varepsilon + \\frac{1}{8}\\varepsilon^2 + \\frac{1}{8}\\varepsilon^3\n$$\n为证明线性叠加失效，我们检验是否 $\\Delta J_f(\\varepsilon_1 + \\varepsilon_2) = \\Delta J_f(\\varepsilon_1) + \\Delta J_f(\\varepsilon_2)$。\n左边：\n$$\n\\Delta J_f(\\varepsilon_1 + \\varepsilon_2) = -\\frac{1}{2}(\\varepsilon_1 + \\varepsilon_2) + \\frac{1}{8}(\\varepsilon_1 + \\varepsilon_2)^2 + \\frac{1}{8}(\\varepsilon_1 + \\varepsilon_2)^3\n$$\n$$\n\\Delta J_f(\\varepsilon_1 + \\varepsilon_2) = -\\frac{1}{2}(\\varepsilon_1 + \\varepsilon_2) + \\frac{1}{8}(\\varepsilon_1^2 + 2\\varepsilon_1\\varepsilon_2 + \\varepsilon_2^2) + \\frac{1}{8}(\\varepsilon_1^3 + 3\\varepsilon_1^2\\varepsilon_2 + 3\\varepsilon_1\\varepsilon_2^2 + \\varepsilon_2^3)\n$$\n右边：\n$$\n\\Delta J_f(\\varepsilon_1) + \\Delta J_f(\\varepsilon_2) = \\left(-\\frac{1}{2}\\varepsilon_1 + \\frac{1}{8}\\varepsilon_1^2 + \\frac{1}{8}\\varepsilon_1^3\\right) + \\left(-\\frac{1}{2}\\varepsilon_2 + \\frac{1}{8}\\varepsilon_2^2 + \\frac{1}{8}\\varepsilon_2^3\\right)\n$$\n左边包含交叉乘积项，例如 $\\frac{2}{8}\\varepsilon_1\\varepsilon_2 = \\frac{1}{4}\\varepsilon_1\\varepsilon_2$，而右边没有。由于系数 $B$ 和 $C$ 非零，函数 $\\Delta J_f(\\varepsilon)$ 包含非线性项（$\\varepsilon^2$, $\\varepsilon^3$）。因此，一般情况下，$\\Delta J_f(\\varepsilon_1 + \\varepsilon_2) \\neq \\Delta J_f(\\varepsilon_1) + \\Delta J_f(\\varepsilon_2)$，线性叠加失效。\n\n### 任务3：$\\Delta J_f(\\varepsilon) = 0$ 的最小正根\n使用在任务2中推导出的三次近似，我们需要找到方程 $\\Delta J_f(\\varepsilon) = 0$ 的最小正根 $\\varepsilon^{\\star} > 0$。\n$$\n-\\frac{1}{2}\\varepsilon + \\frac{1}{8}\\varepsilon^2 + \\frac{1}{8}\\varepsilon^3 = 0\n$$\n为简化起见，我们将整个方程乘以 $8$：\n$$\n\\varepsilon^3 + \\varepsilon^2 - 4\\varepsilon = 0\n$$\n我们可以提出一个因子 $\\varepsilon$：\n$$\n\\varepsilon(\\varepsilon^2 + \\varepsilon - 4) = 0\n$$\n该方程有三个根。一个是平凡根 $\\varepsilon = 0$。另外两个根是二次方程的解：\n$$\n\\varepsilon^2 + \\varepsilon - 4 = 0\n$$\n我们使用二次公式 $\\varepsilon = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ 求解，其中 $a=1$，$b=1$，$c=-4$：\n$$\n\\varepsilon = \\frac{-1 \\pm \\sqrt{1^2 - 4(1)(-4)}}{2(1)} = \\frac{-1 \\pm \\sqrt{1 + 16}}{2} = \\frac{-1 \\pm \\sqrt{17}}{2}\n$$\n两个根是 $\\varepsilon_1 = \\frac{-1 - \\sqrt{17}}{2}$ 和 $\\varepsilon_2 = \\frac{-1 + \\sqrt{17}}{2}$。\n因为 $\\sqrt{17} > \\sqrt{1} = 1$，第一个根 $\\varepsilon_1$ 是负数。第二个根 $\\varepsilon_2$ 是正数。\n因此，使 $\\Delta J_f(\\varepsilon) = 0$ 成立的最小正新息振幅 $\\varepsilon^{\\star}$ 是：\n$$\n\\varepsilon^{\\star} = \\frac{-1 + \\sqrt{17}}{2}\n$$\n这就是所要求的精确闭式表达式。",
            "answer": "$$\\boxed{\\frac{\\sqrt{17}-1}{2}}$$"
        },
        {
            "introduction": "本章的最后一个实践将从评估单个观测转向设计一个最优的观测系统。这是自适应观测的核心挑战：在成本和预算等资源限制下，挑选出最有价值的观测组合。本问题  将指导你将这一挑战形式化为一个混合整数优化问题，并展示它如何在一个简化情景下演变为经典的背包问题，其目标是使用A-最优准则来最小化后验预报误差。",
            "id": "4071080",
            "problem": "数值天气预报（NWP）中的自适应观测旨在根据后勤约束选择信息丰富的测量，以减少预报的不确定性。考虑一个目标设计，旨在通过数据同化（DA）来减小单个无量纲标量预报误差模态 $x$。先验是高斯分布，$x \\sim \\mathcal{N}(0, P_b)$，其中已知的 $P_b > 0$。存在 $m$ 个候选观测，索引为 $i \\in \\{1,\\dots,m\\}$，每个观测测量值为 $y_i = h_i x + \\epsilon_i$，其中 $h_i \\in \\mathbb{R}$ 是已知的线性化观测算子系数，$\\epsilon_i$ 是方差为 $r_i > 0$ 的零均值高斯测量误差。假设 $\\epsilon_i$ 对于不同的 $i$ 是相互独立的。每个候选观测 $i$ 都有一个部署成本 $c_i > 0$，总预算为 $B > 0$。定义二元决策变量 $x_i \\in \\{0,1\\}$，表示是否选择观测 $i$。\n\n从线性高斯数据同化模型出发，并根据 A-最优准则（最小化后验误差协方差的迹）的定义，推导一个混合整数优化公式，其目标是 $x$ 的后验协方差关于选择向量 $(x_1,\\dots,x_m)$ 的 A-最优迹函数，其约束条件强制执行预算和二元决策。清晰地陈述该数学优化问题，包括决策变量、目标函数和约束条件。\n\n然后，对于一个具体数值实例：$m=5$，先验方差 $P_b = 1$，预算 $B = 12$，以及参数\n- 成本：$c_1 = 6$，$c_2 = 5$，$c_3 = 5$，$c_4 = 7$，$c_5 = 2$，\n- 观测算子系数：$h_1 = 0.8$，$h_2 = 0.5$，$h_3 = 1.2$，$h_4 = 0.3$，$h_5 = 0.7$，\n- 误差方差：$r_1 = 0.09$，$r_2 = 0.04$，$r_3 = 0.36$，$r_4 = 0.01$，$r_5 = 0.49$，\n\n确定最优选择，并计算此选择所能达到的最小后验方差（对于标量，该值等于后验协方差的迹）。标量 $x$ 是无量纲的；将最终答案表示为一个无量纲实数。将最终答案四舍五入到四位有效数字。",
            "solution": "该问题在线性高斯数据同化（DA）框架内提出。对于一个标量状态 $x$，其先验为 $x \\sim \\mathcal{N}(0, P_b)$，测量值为 $y_i = h_i x + \\epsilon_i$，其中独立的 $\\epsilon_i \\sim \\mathcal{N}(0, r_i)$，则给定一个选定的观测子集，$x$ 的后验分布仍然是高斯分布。线性高斯推断中一个经过充分检验的核心事实是信息（精度）是相加的：后验精度等于先验精度加上每个测量所贡献的信息之和。\n\n我们通过二元变量 $x_i \\in \\{0,1\\}$ 来形式化选择过程。如果选择观测 $i$（$x_i = 1$），其似然将为关于 $x$ 的费雪信息贡献一个与 $h_i^2 / r_i$ 成正比的项。为了证明这一点，我们可以写出在给定所选观测 $\\{i : x_i = 1\\}$ 的情况下的负对数后验（忽略一个加性常数）：\n\n$$\n\\frac{x^2}{2 P_b} + \\sum_{i=1}^{m} x_i \\frac{\\left(y_i - h_i x\\right)^2}{2 r_i}.\n$$\n\n展开求和项并合并关于 $x$ 的项， $x$ 的二次项给出了后验精度：\n\n$$\nP_a^{-1} = P_b^{-1} + \\sum_{i=1}^{m} x_i \\frac{h_i^2}{r_i}.\n$$\n\n因此，后验方差为\n\n$$\nP_a = \\left(P_b^{-1} + \\sum_{i=1}^{m} x_i \\frac{h_i^2}{r_i}\\right)^{-1}.\n$$\n\n对于标量状态，A-最优准则（定义为最小化后验协方差的迹）简化为最小化 $P_a$ 本身。因此，在 A-最优目标下的混合整数优化问题是\n\n$$\n\\min_{x_1,\\dots,x_m} \\;\\; \\left(P_b^{-1} + \\sum_{i=1}^{m} x_i \\frac{h_i^2}{r_i}\\right)^{-1}\n$$\n\n约束条件为\n\n$$\n\\sum_{i=1}^{m} c_i x_i \\leq B, \\quad x_i \\in \\{0,1\\} \\quad \\text{对于所有 } i \\in \\{1,\\dots,m\\}.\n$$\n\n因为函数 $f(s) = \\left(P_b^{-1} + s\\right)^{-1}$ 在 $s \\ge 0$ 时是严格递减的，所以最小化 $P_a$ 等价于最大化总信息贡献\n\n$$\n\\sum_{i=1}^{m} x_i \\frac{h_i^2}{r_i}\n$$\n\n在相同的约束条件下。这表明，在标量情况下，A-最优设计问题简化为一个 0–1 背包问题，其中物品价值为 $w_i = \\frac{h_i^2}{r_i}$，物品重量为 $c_i$。\n\n我们现在求解所提供的数值实例。计算信息贡献 $w_i = \\frac{h_i^2}{r_i}$：\n- 对于 $i=1$：$h_1 = 0.8$, $r_1 = 0.09$，所以 $w_1 = \\frac{(0.8)^2}{0.09} = \\frac{0.64}{0.09} = 7.111\\overline{1}$，即 $w_1 = 7.\\overline{1}$。\n- 对于 $i=2$：$h_2 = 0.5$, $r_2 = 0.04$，所以 $w_2 = \\frac{(0.5)^2}{0.04} = \\frac{0.25}{0.04} = 6.25$。\n- 对于 $i=3$：$h_3 = 1.2$, $r_3 = 0.36$，所以 $w_3 = \\frac{(1.2)^2}{0.36} = \\frac{1.44}{0.36} = 4$。\n- 对于 $i=4$：$h_4 = 0.3$, $r_4 = 0.01$，所以 $w_4 = \\frac{(0.3)^2}{0.01} = \\frac{0.09}{0.01} = 9$。\n- 对于 $i=5$：$h_5 = 0.7$, $r_5 = 0.49$，所以 $w_5 = \\frac{(0.7)^2}{0.49} = \\frac{0.49}{0.49} = 1$。\n\n成本为 $c_1 = 6$, $c_2 = 5$, $c_3 = 5$, $c_4 = 7$, $c_5 = 2$，预算为 $B = 12$。我们寻求在约束 $\\sum_{i=1}^{5} c_i x_i \\le 12$ 和 $x_i \\in \\{0,1\\}$ 下，最大化 $\\sum_{i=1}^{5} x_i w_i$。\n\n我们在预算下枚举可行的高价值组合：\n- 选择 $i=4$ 和 $i=2$：总成本 $7 + 5 = 12$（可行），总价值 $9 + 6.25 = 15.25$。\n- 选择 $i=4$ 和 $i=3$：总成本 $7 + 5 = 12$（可行），总价值 $9 + 4 = 13$。\n- 选择 $i=1$ 和 $i=2$：总成本 $6 + 5 = 11$（可行），总价值 $7.111\\overline{1} + 6.25 = 13.361\\overline{1}$。\n- 选择 $i=2$、$i=3$ 和 $i=5$：总成本 $5 + 5 + 2 = 12$（可行），总价值 $6.25 + 4 + 1 = 11.25$。\n- 其他可行组合，例如 $i=4$ 和 $i=5$（成本 $9$，价值 $10$），$i=1$ 和 $i=3$（成本 $11$，价值 $11.111\\overline{1}$），或者将 $i=5$ 添加到 $i=1$ 和 $i=2$ 或 $i=1$ 和 $i=3$ 的组合中都会超出预算（$13$ 或更高）。\n\n因此，在预算下的最大价值是通过选择 $i=4$ 和 $i=2$ 实现的，其总信息为 $s^{\\star} = 15.25$。当 $P_b = 1$ 时，最优后验方差为\n\n$$\nP_a^{\\star} = \\left(P_b^{-1} + s^{\\star}\\right)^{-1} = \\left(1 + 15.25\\right)^{-1} = \\frac{1}{16.25} = 0.0615384615\\ldots\n$$\n\n四舍五入到四位有效数字，最小后验方差为 $0.06154$（无量纲）。",
            "answer": "$$\\boxed{0.06154}$$"
        }
    ]
}