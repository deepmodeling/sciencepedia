{
    "hands_on_practices": [
        {
            "introduction": "Subseasonal-to-seasonal (S2S) predictability primarily arises from the influence of slowly evolving components of the Earth system, such as sea surface temperatures (SSTs) and soil moisture. A fundamental task in climate science is to design numerical experiments that can isolate and quantify the contribution of each of these sources. This exercise provides a powerful, albeit simplified, theoretical framework for understanding this experimental design, demonstrating how predictability, measured by the Anomaly Correlation Coefficient (ACC), can be derived as a function of the signal strength from a given source versus the background atmospheric noise .",
            "id": "4096547",
            "problem": "Consider a simplified weekly mean near-surface temperature anomaly model appropriate for Subseasonal-to-Seasonal (S2S) prediction in Numerical Weather Prediction (NWP) and climate modeling. The objective is to isolate the impact of Soil Moisture (SM) versus Sea Surface Temperature (SST) on weekly temperature predictability by designing controlled experiments with fixed climatological boundary fields. Let the weekly mean $2$-meter temperature anomaly be denoted by $T$, soil moisture anomaly by $W$, and sea surface temperature anomaly by $S$. Assume that, at weekly lead $1$, the temperature anomaly responds linearly to contemporaneous land and ocean anomalies and to fast atmospheric noise, with controlled initial conditions satisfying $T_0 = 0$ (climatology). The response is described by\n$$\nT_1 = b_w W_0 + b_s S_0 + \\eta_0,\n$$\nwhere $b_w$ and $b_s$ are linear sensitivity coefficients (units of temperature anomaly per unit anomaly of $W$ and $S$, respectively), $W_0$ and $S_0$ are zero-mean random initial anomalies with variances $\\sigma_w^2$ and $\\sigma_s^2$, and $\\eta_0$ is zero-mean fast atmospheric noise with variance $\\sigma_\\eta^2$, independent of $W_0$ and $S_0$. All variances are strictly nonnegative real numbers and $\\sigma_\\eta^2 > 0$ for scientific realism.\n\nDesign two controlled experiments:\n$1.$ Soil-only experiment: fix the SST boundary field to climatology, i.e., set $S_0 = 0$, while allowing $W_0$ to vary according to its distribution. Forecast the weekly mean temperature anomaly using the linear model and controlled initial conditions.\n$2.$ Ocean-only experiment: fix the SM boundary field to climatology, i.e., set $W_0 = 0$, while allowing $S_0$ to vary according to its distribution. Forecast the weekly mean temperature anomaly using the linear model and controlled initial conditions.\n\nDefine the Anomaly Correlation Coefficient (ACC) between the forecast anomaly and the verifying truth anomaly for the weekly mean, which is the Pearson correlation between anomalies computed as the covariance divided by the product of standard deviations. In both experiments, treat the forecast as the deterministic model response to the retained anomaly (SM or SST) under $T_0 = 0$, and treat the verifying truth as the model response including stochastic noise. The ACC is dimensionless.\n\nImplement a program that, given sets of parameters $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta)$, computes for each test case:\n$1.$ The ACC under the soil-only experiment, denoted $\\mathrm{ACC}_{\\text{soil}}$.\n$2.$ The ACC under the ocean-only experiment, denoted $\\mathrm{ACC}_{\\text{ocean}}$.\n\nFor scientific consistency, assume $W_0 \\sim \\mathcal{N}(0,\\sigma_w^2)$, $S_0 \\sim \\mathcal{N}(0,\\sigma_s^2)$, and $\\eta_0 \\sim \\mathcal{N}(0,\\sigma_\\eta^2)$, all mutually independent, and use the standard correlation definition. Although $b_w$ and $b_s$ may implicitly carry physical units via the linear sensitivities, the outputs $\\mathrm{ACC}_{\\text{soil}}$ and $\\mathrm{ACC}_{\\text{ocean}}$ are dimensionless floats. No angles or percentages are involved in the outputs.\n\nUse the following test suite of parameter sets to evaluate the design:\n$1.$ $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta) = (0.6, 1.2, 0.4, 1.0, 1.0)$.\n$2.$ $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta) = (0.0, 1.0, 0.6, 1.2, 1.0)$.\n$3.$ $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta) = (0.5, 1.0, 0.5, 1.0, 3.0)$.\n$4.$ $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta) = (0.2, 1.0, 1.0, 1.5, 0.8)$.\n$5.$ $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta) = (0.5, 1.0, 0.5, 1.0, 1.5)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output two floats in the order $\\mathrm{ACC}_{\\text{soil}}, \\mathrm{ACC}_{\\text{ocean}}$, rounded to three decimal places, concatenated across all test cases so that the final output is of the form $[\\mathrm{ACC}_{\\text{soil},1},\\mathrm{ACC}_{\\text{ocean},1},\\mathrm{ACC}_{\\text{soil},2},\\mathrm{ACC}_{\\text{ocean},2},\\dots]$. All outputs are dimensionless floats.",
            "solution": "The guiding principle is to express weekly mean temperature anomaly predictability as a correlation that arises from linear deterministic signal components and stochastic weather noise, with controlled isolation of Soil Moisture (SM) and Sea Surface Temperature (SST) influences via fixed climatological boundary fields. We begin with a linear response model rooted in the surface energy balance linearization and the well-tested behavior of weekly anomalies, where land and ocean anomalies exert a first-order linear influence on near-surface temperature:\n$$\nT_1 = b_w W_0 + b_s S_0 + \\eta_0,\n$$\nwith $T_0 = 0$ enforced to eliminate atmospheric persistence confounding and to implement controlled initial conditions that focus solely on land and ocean boundary anomaly impacts. Here, $W_0$ and $S_0$ denote zero-mean random initial anomalies with variances $\\sigma_w^2$ and $\\sigma_s^2$, respectively, and $\\eta_0$ denotes zero-mean fast atmospheric noise with variance $\\sigma_\\eta^2$. Assume mutual independence among $W_0$, $S_0$, and $\\eta_0$, which is a standard and tractable idealization for deriving predictability metrics.\n\nWe isolate SM and SST impacts by performing two experiments that fix the other boundary field to climatology (zero anomaly):\n$1.$ Soil-only: set $S_0 = 0$. The verifying truth is\n$$\nT_1^{(\\text{soil})} = b_w W_0 + \\eta_0,\n$$\nand the deterministic forecast based on the controlled initial condition and the linear model is\n$$\nF^{(\\text{soil})} = b_w W_0.\n$$\n$2.$ Ocean-only: set $W_0 = 0$. The verifying truth is\n$$\nT_1^{(\\text{ocean})} = b_s S_0 + \\eta_0,\n$$\nand the deterministic forecast is\n$$\nF^{(\\text{ocean})} = b_s S_0.\n$$\n\nTo quantify predictability, we use the Anomaly Correlation Coefficient (ACC), defined as the Pearson correlation between forecast and verifying truth anomalies. For any pair of random variables $X$ and $Y$ with finite variances, the correlation is\n$$\n\\rho(X,Y) = \\frac{\\mathrm{Cov}(X,Y)}{\\sqrt{\\mathrm{Var}(X)\\,\\mathrm{Var}(Y)}}.\n$$\nThis is a well-tested statistical formula appropriate for evaluating forecast skill as correlation.\n\nWe now compute $\\mathrm{ACC}_{\\text{soil}}$. Under the independence assumptions and zero means:\n$1.$ Compute $\\mathrm{Cov}(F^{(\\text{soil})}, T_1^{(\\text{soil})})$. Since $F^{(\\text{soil})} = b_w W_0$ and $T_1^{(\\text{soil})} = b_w W_0 + \\eta_0$, and $\\eta_0$ is independent of $W_0$ and has zero mean, we have\n$$\n\\mathrm{Cov}(F^{(\\text{soil})}, T_1^{(\\text{soil})}) = \\mathrm{Cov}(b_w W_0, b_w W_0 + \\eta_0) = b_w^2 \\mathrm{Var}(W_0) = b_w^2 \\sigma_w^2.\n$$\n$2.$ Compute $\\mathrm{Var}(F^{(\\text{soil})})$. Because $F^{(\\text{soil})} = b_w W_0$ with $W_0$ zero mean, we obtain\n$$\n\\mathrm{Var}(F^{(\\text{soil})}) = b_w^2 \\mathrm{Var}(W_0) = b_w^2 \\sigma_w^2.\n$$\n$3.$ Compute $\\mathrm{Var}(T_1^{(\\text{soil})})$. Using independence,\n$$\n\\mathrm{Var}(T_1^{(\\text{soil})}) = \\mathrm{Var}(b_w W_0 + \\eta_0) = b_w^2 \\sigma_w^2 + \\sigma_\\eta^2.\n$$\n$4.$ Combine these to get\n$$\n\\mathrm{ACC}_{\\text{soil}} = \\frac{b_w^2 \\sigma_w^2}{\\sqrt{(b_w^2 \\sigma_w^2)\\,(b_w^2 \\sigma_w^2 + \\sigma_\\eta^2)}} = \\sqrt{\\frac{b_w^2 \\sigma_w^2}{b_w^2 \\sigma_w^2 + \\sigma_\\eta^2}}.\n$$\n\nBy symmetry, the ocean-only case yields\n$1.$ $\\mathrm{Cov}(F^{(\\text{ocean})}, T_1^{(\\text{ocean})}) = b_s^2 \\sigma_s^2$,\n$2.$ $\\mathrm{Var}(F^{(\\text{ocean})}) = b_s^2 \\sigma_s^2$,\n$3.$ $\\mathrm{Var}(T_1^{(\\text{ocean})}) = b_s^2 \\sigma_s^2 + \\sigma_\\eta^2$,\nand hence\n$$\n\\mathrm{ACC}_{\\text{ocean}} = \\sqrt{\\frac{b_s^2 \\sigma_s^2}{b_s^2 \\sigma_s^2 + \\sigma_\\eta^2}}.\n$$\n\nThese expressions are dimensionless and reflect the isolation achieved by fixing boundary anomalies to climatology and using controlled initial conditions. They quantify the impact of SM and SST on weekly temperature predictability by directly comparing the signal-to-noise ratio embedded in the forecast-versus-truth correlation for each controlled experiment.\n\nAlgorithmic design for the program:\n$1.$ Encode the test suite as a list of parameter tuples $(b_w, \\sigma_w, b_s, \\sigma_s, \\sigma_\\eta)$.\n$2.$ For each tuple, compute $\\mathrm{ACC}_{\\text{soil}}$ using\n$$\n\\mathrm{ACC}_{\\text{soil}} = \\sqrt{\\frac{b_w^2 \\sigma_w^2}{b_w^2 \\sigma_w^2 + \\sigma_\\eta^2}}.\n$$\n$3.$ Compute $\\mathrm{ACC}_{\\text{ocean}}$ using\n$$\n\\mathrm{ACC}_{\\text{ocean}} = \\sqrt{\\frac{b_s^2 \\sigma_s^2}{b_s^2 \\sigma_s^2 + \\sigma_\\eta^2}}.\n$$\n$4.$ Round each ACC to $3$ decimal places and append them to a single flat list in the order $\\mathrm{ACC}_{\\text{soil}}, \\mathrm{ACC}_{\\text{ocean}}$ for each test case.\n$5.$ Print the final list on a single line, with comma-separated entries enclosed in square brackets, as specified.\n\nScientific realism and edge cases:\n$1.$ If $b_w = 0$ then $\\mathrm{ACC}_{\\text{soil}} = 0$ because the forecast has no signal; similarly, if $b_s = 0$ then $\\mathrm{ACC}_{\\text{ocean}} = 0$.\n$2.$ Larger $\\sigma_\\eta^2$ reduces both ACCs, reflecting greater weather noise that reduces weekly predictability.\n$3.$ Larger $b_w^2 \\sigma_w^2$ or $b_s^2 \\sigma_s^2$ increases ACCs, reflecting stronger land or ocean signals and/or larger initial anomaly variance contributing to forecastable signal.\n\nThe provided test suite covers a general case, a boundary case with no soil coupling, a noise-dominated case, a strong ocean coupling case, and a balanced case with equal sensitivities, ensuring comprehensive verification of the logic under distinct regimes. No physical units are required in the outputs, as ACCs are dimensionless by construction, and all calculations are confined to lead-$1$ weekly predictability under controlled boundary conditions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef acc_linear(b: float, sigma_source: float, sigma_eta: float) -> float:\n    \"\"\"\n    Compute the Anomaly Correlation Coefficient (ACC) for a linear forecast:\n        F = b * X\n        T = b * X + eta\n    where X ~ N(0, sigma_source^2), eta ~ N(0, sigma_eta^2), independent.\n\n    ACC = sqrt( (b^2 * sigma_source^2) / (b^2 * sigma_source^2 + sigma_eta^2) )\n\n    Parameters\n    ----------\n    b : float\n        Linear sensitivity coefficient.\n    sigma_source : float\n        Standard deviation of the source anomaly (soil moisture or SST).\n    sigma_eta : float\n        Standard deviation of the atmospheric noise.\n\n    Returns\n    -------\n    float\n        Dimensionless ACC in [0, 1].\n    \"\"\"\n    signal_var = (b ** 2) * (sigma_source ** 2)\n    total_var = signal_var + (sigma_eta ** 2)\n    # Guard against numerical issues; total_var > 0 by construction in test suite.\n    if total_var <= 0.0:\n        return 0.0\n    return float(np.sqrt(signal_var / total_var))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (b_w, sigma_w, b_s, sigma_s, sigma_eta)\n    test_cases = [\n        (0.6, 1.2, 0.4, 1.0, 1.0),\n        (0.0, 1.0, 0.6, 1.2, 1.0),\n        (0.5, 1.0, 0.5, 1.0, 3.0),\n        (0.2, 1.0, 1.0, 1.5, 0.8),\n        (0.5, 1.0, 0.5, 1.0, 1.5),\n    ]\n\n    results = []\n    for (b_w, sigma_w, b_s, sigma_s, sigma_eta) in test_cases:\n        acc_soil = acc_linear(b_w, sigma_w, sigma_eta)\n        acc_ocean = acc_linear(b_s, sigma_s, sigma_eta)\n        # Round to three decimal places as specified\n        results.append(round(acc_soil, 3))\n        results.append(round(acc_ocean, 3))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After establishing that slow-varying boundary conditions are key sources of predictability, we turn to a concrete example: the Madden-Julian Oscillation (MJO). The MJO is the dominant mode of tropical intraseasonal variability and a primary source of S2S predictability globally. This practice guides you through the core methodology behind the Wheeler-Hendon Real-time Multivariate MJO (RMM) index, a standard tool used by operational centers to monitor the MJO's state . By projecting complex atmospheric data onto principal component space, you will learn to distill the MJO's propagation and strength into a simple phase and amplitude, a crucial skill for S2S forecasting.",
            "id": "4096582",
            "problem": "A forecast center constructs the Real-time Multivariate Madden–Julian Oscillation (RMM) index, following the Wheeler–Hendon methodology, to monitor the Madden–Julian Oscillation (MJO) on the subseasonal-to-seasonal timescale. The inputs are daily fields of bandpass-filtered anomalies of Outgoing Longwave Radiation (OLR), zonal wind at $850$ hPa (denoted $u_{850}$), and zonal wind at $200$ hPa (denoted $u_{200}$). The anomalies are computed by removing the long-term daily climatology and the first few annual harmonics, and then applying a bandpass filter retaining variance between $20$ and $96$ days. The combined state is constructed along the equatorial band by area-weighted concatenation of these three fields, and each field is individually standardized by its climatological spatial standard deviation so that the three components are nondimensional and commensurate.\n\nLet $x(t)$ denote the concatenated, area-weighted vector of the three filtered anomaly fields at time $t$, and let $\\mu$ denote the corresponding climatological mean (zero for anomalies). Let $W$ be the area-weighting operator, $B$ the bandpass filter operator, and $S$ a block-diagonal scaling operator containing the spatial standard deviations for OLR, $u_{850}$, and $u_{200}$ on its diagonal blocks so that $S^{-1}$ produces nondimensional standardized anomalies. Suppose the first two Empirical Orthogonal Function (EOF) patterns $e_{1}$ and $e_{2}$ (columns) have been precomputed from a long historical record using the covariance of $S^{-1} B (x-\\mu)$ with respect to the inner product induced by $W$.\n\nTasks:\n1) Starting from these definitions and linear operators, derive expressions for the two principal components, $PC_{1}(t)$ and $PC_{2}(t)$, as projections of the standardized, filtered anomaly vector onto the EOF patterns. Then, from first principles of representing a two-dimensional oscillatory signal, derive analytic formulas for the instantaneous amplitude $A(t)$ and the instantaneous phase angle $\\phi(t)$ in terms of $PC_{1}(t)$ and $PC_{2}(t)$, where $\\phi(t)$ is defined using the two-argument arctangent and measured in radians.\n\n2) For weekly evaluation, define the weekly mean principal components\n$$\n\\overline{PC}_{i} = \\frac{1}{7} \\sum_{d=1}^{7} PC_{i}(t_{d}), \\quad i \\in \\{1,2\\},\n$$\nfor a given week with days $t_{1},\\dots,t_{7}$. Using linearity and your derivations from part 1), derive formulas for the weekly mean amplitude $A_{\\mathrm{wk}}$ and the weekly mean phase $\\phi_{\\mathrm{wk}}$ in terms of $\\overline{PC}_{1}$ and $\\overline{PC}_{2}$.\n\n3) The following daily principal components have been computed for a particular week by projecting the filtered, standardized fields onto the precomputed EOFs:\n- Day $1$: $PC_{1}(t_{1}) = 1.2$, $PC_{2}(t_{1}) = 0.8$.\n- Day $2$: $PC_{1}(t_{2}) = 1.4$, $PC_{2}(t_{2}) = 0.7$.\n- Day $3$: $PC_{1}(t_{3}) = 1.3$, $PC_{2}(t_{3}) = 0.9$.\n- Day $4$: $PC_{1}(t_{4}) = 1.1$, $PC_{2}(t_{4}) = 0.6$.\n- Day $5$: $PC_{1}(t_{5}) = 1.0$, $PC_{2}(t_{5}) = 0.5$.\n- Day $6$: $PC_{1}(t_{6}) = 0.9$, $PC_{2}(t_{6}) = 0.4$.\n- Day $7$: $PC_{1}(t_{7}) = 1.2$, $PC_{2}(t_{7}) = 0.8$.\n\nCompute the weekly mean amplitude $A_{\\mathrm{wk}}$ implied by these daily principal components. Express the final amplitude as a unitless number and round your answer to four significant figures.",
            "solution": "The problem is addressed in three parts: first, a derivation of the fundamental expressions for principal components, amplitude, and phase; second, an extension of these concepts to weekly mean values; and third, a numerical calculation using provided data.\n\n**Part 1: Derivations for Instantaneous Quantities**\n\nThe problem states that the Empirical Orthogonal Functions (EOFs), denoted $e_{1}$ and $e_{2}$, are derived from the covariance of the standardized, filtered anomaly field. Let the raw state vector be $x(t)$. The anomalies are computed relative to the climatological mean $\\mu$, which is zero for anomaly fields, so we consider $x(t)$. This vector is then processed by a bandpass filter operator $B$ and a standardization operator $S^{-1}$. The resulting state vector, which we shall call $z(t)$, is given by:\n$$\nz(t) = S^{-1} B x(t)\n$$\nThe problem specifies that the EOFs are computed with respect to an inner product induced by an area-weighting operator $W$. This inner product between two state vectors $u$ and $v$ is $\\langle u, v \\rangle_{W} = u^T W v$. The EOF patterns $e_{i}$ are, by construction, orthonormal with respect to this weighted inner product, such that $\\langle e_{i}, e_{j} \\rangle_{W} = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nThe principal component $PC_{i}(t)$ is the projection of the state vector $z(t)$ onto the corresponding EOF pattern $e_{i}$. This projection is computed using the defined weighted inner product:\n$$\nPC_{i}(t) = \\langle z(t), e_{i} \\rangle_{W}\n$$\nSubstituting the expression for $z(t)$, we obtain the formula for the principal components in terms of the initial field $x(t)$ and the operators:\n$$\nPC_{1}(t) = (S^{-1} B x(t))^T W e_{1}\n$$\n$$\nPC_{2}(t) = (S^{-1} B x(t))^T W e_{2}\n$$\nThe pair $(PC_{1}(t), PC_{2}(t))$ represents the state of the system at time $t$ in a two-dimensional phase space spanned by the two leading EOFs. This representation is particularly useful for oscillatory phenomena like the Madden-Julian Oscillation, where the state can be described by an amplitude and a phase.\n\nThe instantaneous amplitude, $A(t)$, is the magnitude of the state vector in this phase space. It is calculated as the Euclidean norm of the vector $(PC_{1}(t), PC_{2}(t))$:\n$$\nA(t) = \\sqrt{PC_{1}(t)^2 + PC_{2}(t)^2}\n$$\nThe instantaneous phase angle, $\\phi(t)$, is the angle of the state vector with respect to the $PC_{1}$ axis. To uniquely determine the angle across all four quadrants, the two-argument arctangent function, often denoted $\\mathrm{atan2}(y, x)$, is used. The phase angle is therefore:\n$$\n\\phi(t) = \\arctan(PC_{2}(t), PC_{1}(t))\n$$\n\n**Part 2: Derivation for Weekly Mean Quantities**\n\nThe problem defines the weekly mean principal components as the arithmetic average of the daily values over a $7$-day period:\n$$\n\\overline{PC}_{i} = \\frac{1}{7} \\sum_{d=1}^{7} PC_{i}(t_{d}), \\quad i \\in \\{1,2\\}\n$$\nThe question asks for the weekly mean amplitude $A_{\\mathrm{wk}}$ and phase $\\phi_{\\mathrm{wk}}$ to be derived in terms of $\\overline{PC}_{1}$ and $\\overline{PC}_{2}$. This implies that we are to find the amplitude and phase of the weekly mean state vector $(\\overline{PC}_{1}, \\overline{PC}_{2})$, not the mean of the daily amplitudes and phases.\n\nThe calculation of the mean principal components is a linear operation. One can see that $\\overline{PC}_{i}$ is the projection of the weekly-mean filtered field onto $e_i$. However, the calculation of amplitude $A(t)$ involves a square root, which is a non-linear function. Consequently, the amplitude of the mean state is not equal to the mean of the daily amplitudes:\n$$\nA_{\\mathrm{wk}} = \\sqrt{\\overline{PC}_{1}^2 + \\overline{PC}_{2}^2} \\neq \\frac{1}{7} \\sum_{d=1}^{7} A(t_d)\n$$\nFollowing the problem's directive, we define the weekly mean amplitude $A_{\\mathrm{wk}}$ and phase $\\phi_{\\mathrm{wk}}$ by applying the same logic from Part 1 to the weekly mean principal components:\n$$\nA_{\\mathrm{wk}} = \\sqrt{\\overline{PC}_{1}^2 + \\overline{PC}_{2}^2}\n$$\n$$\n\\phi_{\\mathrm{wk}} = \\arctan(\\overline{PC}_{2}, \\overline{PC}_{1})\n$$\n\n**Part 3: Numerical Computation**\n\nWe are given the daily principal components for a $7$-day week:\n- Day $1$: $PC_{1}(t_{1}) = 1.2$, $PC_{2}(t_{1}) = 0.8$.\n- Day $2$: $PC_{1}(t_{2}) = 1.4$, $PC_{2}(t_{2}) = 0.7$.\n- Day $3$: $PC_{1}(t_{3}) = 1.3$, $PC_{2}(t_{3}) = 0.9$.\n- Day $4$: $PC_{1}(t_{4}) = 1.1$, $PC_{2}(t_{4}) = 0.6$.\n- Day $5$: $PC_{1}(t_{5}) = 1.0$, $PC_{2}(t_{5}) = 0.5$.\n- Day $6$: $PC_{1}(t_{6}) = 0.9$, $PC_{2}(t_{6}) = 0.4$.\n- Day $7$: $PC_{1}(t_{7}) = 1.2$, $PC_{2}(t_{7}) = 0.8$.\n\nFirst, we compute the weekly mean principal components, $\\overline{PC}_{1}$ and $\\overline{PC}_{2}$.\n\nFor $\\overline{PC}_{1}$:\n$$\n\\overline{PC}_{1} = \\frac{1}{7} (1.2 + 1.4 + 1.3 + 1.1 + 1.0 + 0.9 + 1.2) = \\frac{8.1}{7}\n$$\nFor $\\overline{PC}_{2}$:\n$$\n\\overline{PC}_{2} = \\frac{1}{7} (0.8 + 0.7 + 0.9 + 0.6 + 0.5 + 0.4 + 0.8) = \\frac{4.7}{7}\n$$\nNow, we use these mean values to compute the weekly mean amplitude $A_{\\mathrm{wk}}$ using the formula derived in Part 2:\n$$\nA_{\\mathrm{wk}} = \\sqrt{\\overline{PC}_{1}^2 + \\overline{PC}_{2}^2} = \\sqrt{\\left(\\frac{8.1}{7}\\right)^2 + \\left(\\frac{4.7}{7}\\right)^2}\n$$\n$$\nA_{\\mathrm{wk}} = \\sqrt{\\frac{8.1^2}{7^2} + \\frac{4.7^2}{7^2}} = \\frac{1}{7} \\sqrt{8.1^2 + 4.7^2}\n$$\nWe calculate the values of the squares:\n$$\n8.1^2 = 65.61\n$$\n$$\n4.7^2 = 22.09\n$$\nSubstituting these back into the expression for $A_{\\mathrm{wk}}$:\n$$\nA_{\\mathrm{wk}} = \\frac{1}{7} \\sqrt{65.61 + 22.09} = \\frac{1}{7} \\sqrt{87.7}\n$$\nNow, we compute the numerical value:\n$$\nA_{\\mathrm{wk}} \\approx \\frac{9.364828}{7} \\approx 1.33783259\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nA_{\\mathrm{wk}} \\approx 1.338\n$$",
            "answer": "$$\n\\boxed{1.338}\n$$"
        },
        {
            "introduction": "Even when a forecast model successfully captures signals from sources like the MJO, its raw output often contains systematic biases in mean and variance that degrade its accuracy. Therefore, a crucial step in the S2S prediction workflow is statistical post-processing to calibrate the model output against observations. This hands-on practice introduces you to mean-variance calibration, a common technique to correct for these drifts, and asks you to evaluate its impact using standard verification metrics like Root Mean Square Error (RMSE) and Anomaly Correlation . Mastering this skill is essential for transforming raw model guidance into a more reliable and usable forecast product.",
            "id": "4096533",
            "problem": "A weekly subseasonal-to-seasonal forecast system produces a time series of forecast temperatures for a fixed calendar week across multiple past years (the hindcast period) and a separate time series for a current validation period. Let the hindcast forecasts be a list of real numbers in degrees Celsius and let the hindcast observations be a list of real numbers in degrees Celsius for the same calendar week and years. The validation period consists of a list of real-valued weekly forecasts and a list of real-valued weekly observations for the same calendar week in subsequent years. You are asked to design and implement a program that performs a mean-variance calibration derived from first principles and then evaluates its impact using two metrics: anomaly correlation and root mean square error.\n\nStart from the following fundamental bases:\n- The laws of statistics governing linear transformations and moments: if a random variable $X$ has mean $\\mu_X$ and standard deviation $\\sigma_X$ (population definition), and $Y = aX + b$, then the mean of $Y$ is $a \\mu_X + b$ and the standard deviation of $Y$ is $\\lvert a \\rvert \\sigma_X$.\n- The population mean and population standard deviation for a finite list $\\{x_i\\}_{i=1}^N$ are defined as $\\mu = \\frac{1}{N} \\sum_{i=1}^N x_i$ and $\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}$, respectively.\n- The Root Mean Square Error (RMSE) between two finite lists of equal length $\\{p_i\\}_{i=1}^N$ and $\\{q_i\\}_{i=1}^N$ is defined as $\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (p_i - q_i)^2}$.\n- The anomaly of a value relative to a climatological baseline is its difference from a reference mean. For weekly anomaly verification, use the hindcast observed mean for that calendar week as the climatological baseline.\n- The Pearson correlation coefficient between two finite lists $\\{x_i\\}_{i=1}^N$ and $\\{y_i\\}_{i=1}^N$ is defined as $\\rho = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^N (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^N (y_i - \\bar{y})^2}}$, where $\\bar{x}$ and $\\bar{y}$ are sample means across the $N$ values being correlated. In this problem, apply this to anomalies computed relative to the hindcast observed mean. If there are fewer than $2$ valid pairs or if either anomaly series has zero variance, define the anomaly correlation to be $0$.\n\nYour program must:\n- Estimate the hindcast forecast mean $\\mu_f$ and hindcast forecast standard deviation $\\sigma_f$ using the population definitions from the hindcast forecast list.\n- Estimate the hindcast observed mean $\\mu_o$ and hindcast observed standard deviation $\\sigma_o$ using the population definitions from the hindcast observation list.\n- Derive a linear transformation of the validation forecasts that matches the hindcast observed mean and standard deviation (i.e., yields a corrected forecast series with mean $\\mu_o$ and standard deviation $\\sigma_o$). Implement the resulting correction and use it to produce a corrected validation forecast series. If $\\sigma_f = 0$ (or effectively zero within numerical tolerance), define the corrected forecast to equal $\\mu_o$ for all validation times.\n- Compute the anomaly correlation and RMSE before correction (using the raw validation forecasts) and after correction (using the corrected validation forecasts). For anomalies, subtract $\\mu_o$ from both forecasts and observations. Express RMSE in degrees Celsius. If any validation forecast-observation pair contains a non-finite value, omit that pair from all metric calculations. If there are zero valid pairs, define both metrics as $0$.\n\nUse the following test suite, where all temperatures are in degrees Celsius:\n- Case $1$ (general happy path):\n    - Hindcast forecasts: $[10,12,14,16]$\n    - Hindcast observations: $[11,12,15,17]$\n    - Validation forecasts: $[13,15,17]$\n    - Validation observations: $[12,16,18]$\n- Case $2$ (boundary condition $\\sigma_f = 0$):\n    - Hindcast forecasts: $[14,14,14,14]$\n    - Hindcast observations: $[13,14,15,16]$\n    - Validation forecasts: $[14,14,14]$\n    - Validation observations: $[13,16,15]$\n- Case $3$ (boundary condition $N = 1$ in validation):\n    - Hindcast forecasts: $[8,9,10,11]$\n    - Hindcast observations: $[7,9,11,13]$\n    - Validation forecasts: $[10]$\n    - Validation observations: $[12]$\n- Case $4$ (negative covariance scenario):\n    - Hindcast forecasts: $[20,18,16,14,12]$\n    - Hindcast observations: $[15,16,17,18,19]$\n    - Validation forecasts: $[13,17,15,19]$\n    - Validation observations: $[19,15,17,13]$\n\nFinal output specification:\n- Your program should produce a single line of output containing a comma-separated list of results for the four cases, enclosed in square brackets. Each case’s result must be a list of four floats in the order $[\\text{AC}_{\\text{raw}}, \\text{RMSE}_{\\text{raw}}, \\text{AC}_{\\text{corr}}, \\text{RMSE}_{\\text{corr}}]$, where $\\text{AC}$ is the anomaly correlation (unitless) and $\\text{RMSE}$ is in degrees Celsius. For example, the format is $[[x_{1,1},x_{1,2},x_{1,3},x_{1,4}],[x_{2,1},x_{2,2},x_{2,3},x_{2,4}],[x_{3,1},x_{3,2},x_{3,3},x_{3,4}],[x_{4,1},x_{4,2},x_{4,3},x_{4,4}]]$ with no extra whitespace or text.",
            "solution": "The core of the problem is to implement a statistical calibration scheme and evaluate its performance. The process can be broken down into a sequence of clear, principle-based steps.\n\n**1. Derive the Calibration Transformation**\nLet a raw forecast value be $f_{raw}$. We seek a corrected forecast $f_{corr} = a \\cdot f_{raw} + b$. The goal is to calibrate the forecast distribution to match the observed climatological distribution from the hindcast period. We assume the statistical properties of the forecast system are stationary, meaning the raw validation forecasts have an underlying mean $\\mu_f$ and standard deviation $\\sigma_f$, which we estimate from the hindcast forecast data. The target distribution is that of the hindcast observations, with mean $\\mu_o$ and standard deviation $\\sigma_o$.\n\nUsing the given law for linear transformation of random variables:\n- The mean of the corrected forecast must be $\\mu_o$: $\\mathbb{E}[f_{corr}] = a \\cdot \\mathbb{E}[f_{raw}] + b \\implies \\mu_o = a \\mu_f + b$.\n- The standard deviation of the corrected forecast must be $\\sigma_o$: $\\mathrm{StdDev}[f_{corr}] = |a| \\cdot \\mathrm{StdDev}[f_{raw}] \\implies \\sigma_o = |a| \\sigma_f$.\n\nFrom the standard deviation equation, assuming a positive scaling factor $a$ to preserve the sign of anomalies, we solve for $a$:\n$$ a = \\frac{\\sigma_o}{\\sigma_f} $$\nThis is valid only if $\\sigma_f > 0$. The case where $\\sigma_f = 0$ is handled separately as per the problem statement.\n\nSubstituting $a$ into the mean equation, we solve for the offset $b$:\n$$ b = \\mu_o - a \\mu_f = \\mu_o - \\frac{\\sigma_o}{\\sigma_f} \\mu_f $$\n\nCombining these, the complete linear transformation is:\n$$ f_{corr} = \\left(\\frac{\\sigma_o}{\\sigma_f}\\right) f_{raw} + \\left(\\mu_o - \\frac{\\sigma_o}{\\sigma_f} \\mu_f\\right) $$\nThis can be rearranged into a more intuitive form that shows standardizing and rescaling:\n$$ f_{corr} = \\mu_o + \\frac{\\sigma_o}{\\sigma_f} (f_{raw} - \\mu_f) $$\nThis equation shows that we take the raw forecast's deviation from its own climatological mean ($f_{raw} - \\mu_f$), scale this deviation by the ratio of observed-to-forecast standard deviations, and add it to the observed climatological mean $\\mu_o$.\n\n**2. Algorithmic Implementation Steps**\nFor each test case:\n1.  **Data Preparation**: Convert input lists to NumPy arrays for efficient computation. Filter the validation data (`validation_forecasts`, `validation_observations`) to retain only pairs where both values are finite. If no valid pairs remain, all four output metrics are $0.0$.\n2.  **Hindcast Statistics**: Calculate the population mean and standard deviation for the hindcast forecasts ($\\mu_f, \\sigma_f$) and hindcast observations ($\\mu_o, \\sigma_o$).\n3.  **Raw Metrics Calculation**:\n    *   **RMSE_raw**: Compute the Root Mean Square Error between the (filtered) raw validation forecasts and observations.\n    *   **AC_raw**: Compute the anomalies for raw forecasts and observations by subtracting the climatological mean $\\mu_o$. Then, calculate the Pearson correlation coefficient between these two anomaly series, respecting the edge cases (length $ 2$ or zero variance).\n4.  **Forecast Calibration**:\n    *   Check if $\\sigma_f$ is effectively zero (using a small tolerance). If so, the corrected forecast series is a constant array of value $\\mu_o$.\n    *   Otherwise, apply the derived linear transformation $f_{corr} = \\mu_o + (\\sigma_o/\\sigma_f) \\cdot (f_{raw} - \\mu_f)$ to each element of the raw validation forecast series.\n5.  **Corrected Metrics Calculation**:\n    *   **RMSE_corr**: Compute the RMSE between the new corrected validation forecasts and the observations.\n    *   **AC_corr**: Compute the anomalies for the corrected forecasts by subtracting $\\mu_o$. Calculate the Pearson correlation with the observation anomalies. The same edge cases apply. Note that since the calibration transformation is linear with a positive scaling factor ($a = \\sigma_o/\\sigma_f > 0$), the anomaly correlation is mathematically expected to be identical to the raw AC, unless rounding or edge cases interfere.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n\n    def process_case(h_forecasts, h_observations, v_forecasts, v_observations):\n        \"\"\"\n        Processes a single test case for forecast calibration and verification.\n        \n        Args:\n            h_forecasts (list): Hindcast forecast values.\n            h_observations (list): Hindcast observation values.\n            v_forecasts (list): Validation forecast values.\n            v_observations (list): Validation observation values.\n\n        Returns:\n            list: A list of four floats [AC_raw, RMSE_raw, AC_corr, RMSE_corr].\n        \"\"\"\n        # Convert all inputs to numpy arrays for vectorized operations\n        h_forecasts_np = np.array(h_forecasts, dtype=float)\n        h_observations_np = np.array(h_observations, dtype=float)\n        v_forecasts_np = np.array(v_forecasts, dtype=float)\n        v_observations_np = np.array(v_observations, dtype=float)\n\n        # Filter validation data for finite pairs\n        valid_mask = np.isfinite(v_forecasts_np)  np.isfinite(v_observations_np)\n        valid_v_forecasts = v_forecasts_np[valid_mask]\n        valid_v_observations = v_observations_np[valid_mask]\n\n        # Handle edge case: zero valid pairs\n        if valid_v_forecasts.size == 0:\n            return [0.0, 0.0, 0.0, 0.0]\n\n        # --- Step 1: Calculate Hindcast Statistics ---\n        # Population mean and standard deviation for hindcast period\n        mu_f = np.mean(h_forecasts_np)\n        sigma_f = np.std(h_forecasts_np) # np.std computes population std dev by default\n        mu_o = np.mean(h_observations_np)\n        sigma_o = np.std(h_observations_np)\n\n        # The climatological baseline for anomalies is the hindcast observed mean\n        climatology = mu_o\n\n        # --- Helper function to compute metrics ---\n        def calculate_metrics(forecasts, observations):\n            \"\"\"Computes Anomaly Correlation and RMSE.\"\"\"\n            # RMSE\n            rmse = np.sqrt(np.mean((forecasts - observations)**2))\n            \n            # Anomaly Correlation (AC)\n            # Conditions for AC to be 0\n            if forecasts.size  2:\n                ac = 0.0\n            else:\n                anom_f = forecasts - climatology\n                anom_o = observations - climatology\n                \n                # Check for zero variance in anomaly series\n                if np.isclose(np.var(anom_f), 0) or np.isclose(np.var(anom_o), 0):\n                    ac = 0.0\n                else:\n                    # np.corrcoef returns a 2x2 matrix\n                    ac = np.corrcoef(anom_f, anom_o)[0, 1]\n            return ac, rmse\n\n        # --- Step 2: Calculate Raw Metrics ---\n        ac_raw, rmse_raw = calculate_metrics(valid_v_forecasts, valid_v_observations)\n\n        # --- Step 3: Apply Correction to Validation Forecasts ---\n        # Check for the special case of zero forecast standard deviation\n        if np.isclose(sigma_f, 0):\n            # Corrected forecast is a constant series of the observed mean\n            corrected_v_forecasts = np.full_like(valid_v_forecasts, mu_o)\n        else:\n            # Apply the mean-variance calibration formula\n            # f_corr = mu_o + (sigma_o / sigma_f) * (f_raw - mu_f)\n            corrected_v_forecasts = mu_o + (sigma_o / sigma_f) * (valid_v_forecasts - mu_f)\n\n        # --- Step 4: Calculate Corrected Metrics ---\n        ac_corr, rmse_corr = calculate_metrics(corrected_v_forecasts, valid_v_observations)\n        \n        return [ac_raw, rmse_raw, ac_corr, rmse_corr]\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        {\n            \"h_forecasts\": [10, 12, 14, 16],\n            \"h_observations\": [11, 12, 15, 17],\n            \"v_forecasts\": [13, 15, 17],\n            \"v_observations\": [12, 16, 18],\n        },\n        {\n            \"h_forecasts\": [14, 14, 14, 14],\n            \"h_observations\": [13, 14, 15, 16],\n            \"v_forecasts\": [14, 14, 14],\n            \"v_observations\": [13, 16, 15],\n        },\n        {\n            \"h_forecasts\": [8, 9, 10, 11],\n            \"h_observations\": [7, 9, 11, 13],\n            \"v_forecasts\": [10],\n            \"v_observations\": [12],\n        },\n        {\n            \"h_forecasts\": [20, 18, 16, 14, 12],\n            \"h_observations\": [15, 16, 17, 18, 19],\n            \"v_forecasts\": [13, 17, 15, 19],\n            \"v_observations\": [19, 15, 17, 13],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(**case)\n        results.append(result)\n        \n    # Format the final output string according to the spec (no spaces)\n    case_strings = []\n    for res_list in results:\n        # Format each inner list: [float1,float2,...]\n        inner_str = f\"[{','.join(f'{x:.10g}' for x in res_list)}]\"\n        case_strings.append(inner_str)\n    \n    # Join the case strings and enclose in brackets: [[...],[...]]\n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}