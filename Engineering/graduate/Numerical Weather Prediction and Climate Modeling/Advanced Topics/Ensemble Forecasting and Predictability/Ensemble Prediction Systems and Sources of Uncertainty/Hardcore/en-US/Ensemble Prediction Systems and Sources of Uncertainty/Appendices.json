{
    "hands_on_practices": [
        {
            "introduction": "The chaotic nature of the atmosphere imposes a fundamental limit on weather predictability. This exercise explores the quantitative basis of this limit through the concept of the Lyapunov exponent, $\\lambda$, which characterizes the exponential growth rate of initial errors. By deriving and calculating the error doubling time, you will gain a concrete understanding of how quickly small uncertainties can amplify, a core principle that necessitates the use of ensemble forecasting and informs the practical design of these systems.",
            "id": "4037588",
            "problem": "Consider the design of an Ensemble Prediction System (EPS) used in Numerical Weather Prediction (NWP) to quantify forecast uncertainty through the evolution of small initial perturbations. In a midlatitude baroclinic flow regime, assume that the local growth of small perturbations can be characterized by a largest Lyapunov exponent $\\lambda$ with units $\\mathrm{day}^{-1}$, defined from the tangent-linear dynamics as the instantaneous exponential growth rate of the norm of an infinitesimal perturbation. Starting from the fundamental definition that the largest Lyapunov exponent $\\lambda$ represents the asymptotic rate at which a small perturbation $\\|\\delta \\mathbf{x}(t)\\|$ grows relative to its initial magnitude $\\|\\delta \\mathbf{x}(0)\\|$ under linearized dynamics, derive an analytic expression for the doubling time $t_{d}$ of the perturbation magnitude and then evaluate it for $\\lambda = 0.8\\,\\mathrm{day}^{-1}$. Provide the final result rounded to $4$ significant figures. Express the final time in $\\mathrm{days}$. Briefly discuss, based on your derivation, how this doubling time informs the selection of ensemble lead times and cycling frequency in an EPS for maintaining probabilistic forecast skill in the presence of fast-growing errors.",
            "solution": "The problem is subjected to validation before proceeding.\n\n### Step 1: Extract Givens\n- The system under consideration is an Ensemble Prediction System (EPS) in Numerical Weather Prediction (NWP).\n- The physical context is a midlatitude baroclinic flow regime.\n- The growth of small perturbations is characterized by the largest Lyapunov exponent, $\\lambda$, with units of $\\mathrm{day}^{-1}$.\n- $\\lambda$ is defined as the instantaneous exponential growth rate of the norm of an infinitesimal perturbation, $\\|\\delta \\mathbf{x}(t)\\|$.\n- The mathematical representation of this growth is linked to the asymptotic rate: $\\lambda = \\lim_{t\\to\\infty} \\frac{1}{t} \\ln \\left( \\frac{\\|\\delta \\mathbf{x}(t)\\|}{\\|\\delta \\mathbf{x}(0)\\|} \\right)$.\n- The tasks are:\n    1. Derive an analytic expression for the doubling time $t_{d}$ of the perturbation magnitude.\n    2. Evaluate $t_{d}$ for a given value $\\lambda = 0.8\\,\\mathrm{day}^{-1}$.\n    3. Round the final numerical result to $4$ significant figures.\n    4. Provide a brief discussion on the implications of $t_{d}$ for EPS design.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is firmly rooted in the established principles of chaos theory and predictability as applied to atmospheric science and numerical weather prediction. The concept of the Lyapunov exponent characterizing error growth in dynamical systems is fundamental. The given value for $\\lambda$ is physically realistic for synoptic-scale error growth in the Earth's atmosphere.\n- **Well-Posed:** The problem is clearly stated. It provides a definition for the growth rate and asks for a derivation and calculation based on that definition. The objectives are specific and admit a unique, meaningful solution.\n- **Objective:** The problem uses precise, standard scientific terminology, free from subjective or ambiguous language.\n- **Completeness and Consistency:** The problem provides all necessary information to perform the derivation and calculation. There are no internal contradictions.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is scientifically sound, well-posed, and objective. A complete solution will be provided.\n\n### Solution Derivation\n\nThe problem states that the largest Lyapunov exponent, $\\lambda$, represents the instantaneous exponential growth rate of the norm of an infinitesimal perturbation, $\\|\\delta \\mathbf{x}(t)\\|$. For the early stages of error growth where linear dynamics dominate, this can be modeled by the equation:\n$$\n\\|\\delta \\mathbf{x}(t)\\| = \\|\\delta \\mathbf{x}(0)\\| \\exp(\\lambda t)\n$$\nwhere $\\|\\delta \\mathbf{x}(0)\\|$ is the initial magnitude of the perturbation at time $t=0$, and $\\|\\delta \\mathbf{x}(t)\\|$ is its magnitude at a later time $t$. The parameter $\\lambda$ dictates the rate of this exponential growth.\n\nThe doubling time, denoted as $t_{d}$, is defined as the time required for the perturbation magnitude to become twice its initial value. We can express this condition mathematically as:\n$$\n\\|\\delta \\mathbf{x}(t_{d})\\| = 2 \\|\\delta \\mathbf{x}(0)\\|\n$$\nTo find the expression for $t_{d}$, we substitute this condition into the growth equation:\n$$\n2 \\|\\delta \\mathbf{x}(0)\\| = \\|\\delta \\mathbf{x}(0)\\| \\exp(\\lambda t_{d})\n$$\nAssuming the initial perturbation is non-zero, i.e., $\\|\\delta \\mathbf{x}(0)\\|  0$, we can divide both sides of the equation by $\\|\\delta \\mathbf{x}(0)\\|$:\n$$\n2 = \\exp(\\lambda t_{d})\n$$\nTo solve for $t_{d}$, we take the natural logarithm ($\\ln$) of both sides of the equation:\n$$\n\\ln(2) = \\ln(\\exp(\\lambda t_{d}))\n$$\nUsing the property of logarithms that $\\ln(\\exp(x)) = x$, we get:\n$$\n\\ln(2) = \\lambda t_{d}\n$$\nFinally, we isolate $t_{d}$ to obtain the desired analytic expression for the doubling time:\n$$\nt_{d} = \\frac{\\ln(2)}{\\lambda}\n$$\nThis expression relates the doubling time directly and inversely to the largest Lyapunov exponent.\n\nNext, we evaluate this expression for the given value of $\\lambda = 0.8\\,\\mathrm{day}^{-1}$.\n$$\nt_{d} = \\frac{\\ln(2)}{0.8\\,\\mathrm{day}^{-1}}\n$$\nUsing the numerical value for the natural logarithm of $2$, $\\ln(2) \\approx 0.693147...$, we can calculate $t_{d}$:\n$$\nt_{d} \\approx \\frac{0.693147}{0.8}\\,\\mathrm{days} \\approx 0.8664339...\\,\\mathrm{days}\n$$\nThe problem requires the result to be rounded to $4$ significant figures.\n$$\nt_{d} \\approx 0.8664\\,\\mathrm{days}\n$$\n\n### Discussion\nThe derived doubling time, $t_{d}$, is a fundamental timescale in predictability theory and has direct implications for the design of an Ensemble Prediction System (EPS).\n\n1.  **Ensemble Lead Times:** The value of $t_{d}$ quantifies the rate at which initial uncertainties, represented by the ensemble perturbations, amplify. A short doubling time, such as the calculated $t_d \\approx 0.87$ days, indicates very rapid error growth. This fundamentally limits the \"predictability horizon,\" which is the maximum lead time for which a forecast has skill. After several doubling times (typically $5$ to $10$), the initial small errors grow to saturate the system, meaning the forecast distribution becomes indistinguishable from the climatological distribution. Therefore, a smaller $t_{d}$ necessitates a more conservative expectation for the maximum useful lead time of the EPS. For a system with $t_{d} \\approx 0.87$ days, significant loss of skill is expected beyond about $5$ to $8$ days.\n\n2.  **Cycling Frequency:** An EPS relies on a \"data assimilation cycle\" to generate the initial conditions for the ensemble members. In each cycle, a previous short-range forecast is combined with new observations to produce an updated analysis. The perturbations for the next forecast are then generated around this new analysis. To maintain a skillful ensemble, these perturbations must accurately represent the directions of the fastest-growing errors in the atmosphere's state space. If the cycling frequency is too long compared to $t_{d}$, the linear approximation of error growth breaks down, and the system fails to capture the evolution of these fast-growing instabilities. Consequently, the ensemble spread may not grow at a realistic rate, leading to an under-dispersive (overconfident) and less reliable probabilistic forecast. A short doubling time demands a high cycling frequency (e.g., updates every $6$ hours, which is shorter than $t_d \\approx 21$ hours) to continuously and accurately sample the instabilities responsible for forecast error growth.",
            "answer": "$$\n\\boxed{0.8664}\n$$"
        },
        {
            "introduction": "A central challenge in ensemble forecasting is ensuring that the predicted spread of outcomes is a reliable indicator of the actual forecast uncertainty, which as we have seen, can grow rapidly . This practice introduces the spread-skill relationship, a cornerstone diagnostic for assessing the probabilistic calibration of an Ensemble Prediction System (EPS). By deriving the theoretical model and applying it to sample data, you will learn to diagnose systematic biases like ensemble underdispersion and understand how these diagnostics inform corrective measures like adaptive spread inflation.",
            "id": "4037533",
            "problem": "A global Ensemble Prediction System (EPS) in Numerical Weather Prediction (NWP) produces $K$ forecasts of $2$-meter temperature anomalies. For each forecast case $k \\in \\{1,\\dots,K\\}$, denote the verifying observation by $y_{k}$, the ensemble-mean forecast by $f_{k}$, the forecast error by $e_{k} = y_{k} - f_{k}$, the squared error by $z_{k} = e_{k}^{2}$, and the ensemble variance by $s_{k}^{2}$. Assume the forecasts have been bias-corrected so that $\\mathbb{E}[e_{k} \\mid \\mathcal{I}_{k}] = 0$, where $\\mathcal{I}_{k}$ denotes the information available from the ensemble at lead time for case $k$ (including $s_{k}^{2}$). Use the law of total variance and definitions of conditional variance to derive a regression model that links the conditional expected squared error $\\mathbb{E}[z_{k} \\mid s_{k}^{2}]$ to $s_{k}^{2}$ under scientifically defensible assumptions about unresolved small-scale variability and ensemble reliability.\n\nThen, treating $z_{k}$ as the response and $s_{k}^{2}$ as the predictor in a linear regression with additive error, estimate the slope by Ordinary Least Squares (OLS) using the following sample statistics aggregated over $K = 1000$ cases:\n- The unbiased sample variance of $s_{k}^{2}$ is $\\widehat{\\operatorname{Var}}(s^{2}) = 1.1960$.\n- The unbiased sample covariance between $s_{k}^{2}$ and $z_{k}$ is $\\widehat{\\operatorname{Cov}}(s^{2}, z) = 2.0376$.\n\nState and justify any assumptions you need about the relationship between conditional error variance and ensemble variance to connect the derivation to the regression. Explicitly articulate the implications of the resulting spread-skill slope for probabilistic calibration and the design of adaptive multiplicative spread inflation. Your final computed answer must be the OLS slope for the regression of $z_{k}$ on $s_{k}^{2}$, rounded to four significant figures. The slope is dimensionless; do not include units in your final answer.",
            "solution": "The problem requires the derivation of a regression model for the spread-skill relationship in an ensemble prediction system (EPS), followed by the estimation of the regression slope using provided sample statistics.\n\nFirst, we validate the problem statement.\n**Step 1: Extract Givens**\n- Number of forecast cases: $K = 1000$.\n- Case index: $k \\in \\{1, \\dots, K\\}$.\n- Verifying observation: $y_k$.\n- Ensemble-mean forecast: $f_k$.\n- Forecast error: $e_k = y_k - f_k$.\n- Squared error: $z_k = e_k^2$.\n- Ensemble variance (spread): $s_k^2$.\n- Bias-corrected condition: $\\mathbb{E}[e_k \\mid \\mathcal{I}_k] = 0$, where $\\mathcal{I}_k$ is the information available from the ensemble for case $k$, and $s_k^2 \\in \\mathcal{I}_k$.\n- Sample variance of ensemble variance: $\\widehat{\\operatorname{Var}}(s^2) = 1.1960$.\n- Sample covariance of ensemble variance and squared error: $\\widehat{\\operatorname{Cov}}(s^2, z) = 2.0376$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the domain of numerical weather prediction (NWP) and ensemble forecast verification. The concepts used (ensemble mean, variance, forecast error, spread-skill relationship) are standard in this field. The use of regression analysis to diagnose ensemble performance is a well-established scientific method. The problem is well-posed, providing all necessary information for both the theoretical derivation and the numerical calculation. It is objective and free of ambiguity. Therefore, the problem is deemed valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n**Derivation of the Regression Model**\nThe goal is to derive a model for the conditional expected squared error, $\\mathbb{E}[z_k \\mid s_k^2]$. By definition, $z_k = e_k^2$, so we are seeking to model $\\mathbb{E}[e_k^2 \\mid s_k^2]$.\n\nThe definition of the conditional variance of the error $e_k$ given the ensemble variance $s_k^2$ is:\n$$ \\operatorname{Var}(e_k \\mid s_k^2) = \\mathbb{E}[e_k^2 \\mid s_k^2] - (\\mathbb{E}[e_k \\mid s_k^2])^2 $$\nThe problem states that the forecasts are bias-corrected such that $\\mathbb{E}[e_k \\mid \\mathcal{I}_k] = 0$, where $\\mathcal{I}_k$ represents all information available from the ensemble. Since the ensemble variance $s_k^2$ is part of this information set (i.e., conditioning on $s_k^2$ is conditioning on a subset of $\\mathcal{I}_k$), we can use the law of total expectation (or iterated expectations) to find $\\mathbb{E}[e_k \\mid s_k^2]$:\n$$ \\mathbb{E}[e_k \\mid s_k^2] = \\mathbb{E}[\\mathbb{E}[e_k \\mid \\mathcal{I}_k] \\mid s_k^2] = \\mathbb{E}[0 \\mid s_k^2] = 0 $$\nThis shows that the forecast error is also conditionally unbiased when conditioned only on the ensemble variance. Substituting this result into the conditional variance formula, we get:\n$$ \\operatorname{Var}(e_k \\mid s_k^2) = \\mathbb{E}[e_k^2 \\mid s_k^2] - 0^2 = \\mathbb{E}[e_k^2 \\mid s_k^2] $$\nThus, the conditional expected squared error is equal to the conditional variance of the forecast error:\n$$ \\mathbb{E}[z_k \\mid s_k^2] = \\operatorname{Var}(e_k \\mid s_k^2) $$\nNow, we must establish a relationship between the conditional error variance $\\operatorname{Var}(e_k \\mid s_k^2)$ and the ensemble variance $s_k^2$. The total forecast error arises from multiple sources. A scientifically defensible assumption is to partition the error variance into two components:\n1.  **Resolved uncertainty**: This is the component of forecast uncertainty due to the chaotic nature of the atmosphere that the ensemble is designed to sample. In a perfectly reliable ensemble, the variance of this error component would be equal to the ensemble variance, $s_k^2$. However, real-world ensembles may be over- or under-dispersive. We model this component as being proportional to the ensemble variance, $a \\cdot s_k^2$. The coefficient $a$ measures the reliability of the ensemble spread as a predictor of this flow-dependent uncertainty.\n2.  **Unresolved uncertainty**: This component arises from sources of error not captured by the ensemble perturbations, such as unresolved small-scale atmospheric processes, deficiencies in the model physics, or errors in the boundary conditions. It is a reasonable assumption that the variance of this error component, denoted by $b$, is independent of the synoptic-scale flow regime and thus independent of the ensemble spread $s_k^2$.\n\nAssuming these two sources of variance are additive, we can postulate the following linear model:\n$$ \\operatorname{Var}(e_k \\mid s_k^2) = a \\cdot s_k^2 + b $$\nCombining our results, we arrive at the desired regression model linking the conditional expected squared error to the ensemble variance:\n$$ \\mathbb{E}[z_k \\mid s_k^2] = a \\cdot s_k^2 + b $$\nThis equation has the form of a simple linear regression, where the expected value of the response variable ($z_k$) is a linear function of the predictor variable ($s_k^2$).\n\n**Estimation of the OLS Slope**\nThe problem asks to estimate the slope of the linear regression of $z_k$ (response) on $s_k^2$ (predictor). The regression model is $z_k = a \\cdot s_k^2 + b + \\epsilon_k$, where $\\epsilon_k$ is an error term with $\\mathbb{E}[\\epsilon_k \\mid s_k^2] = 0$.\n\nThe formula for the Ordinary Least Squares (OLS) estimator of the slope, $\\hat{a}$, in a simple linear regression of a response $Y$ on a predictor $X$ is given by the ratio of the sample covariance to the sample variance of the predictor:\n$$ \\hat{a} = \\frac{\\widehat{\\operatorname{Cov}}(X, Y)}{\\widehat{\\operatorname{Var}}(X)} $$\nIn our specific problem, $Y = z_k$ and $X = s_k^2$. The OLS estimator for the slope $a$ is:\n$$ \\hat{a} = \\frac{\\widehat{\\operatorname{Cov}}(s_k^2, z_k)}{\\widehat{\\operatorname{Var}}(s_k^2)} $$\nThe problem provides the necessary unbiased sample statistics:\n- $\\widehat{\\operatorname{Var}}(s^{2}) = 1.1960$\n- $\\widehat{\\operatorname{Cov}}(s^{2}, z) = 2.0376$\n\nSubstituting these values into the formula for the slope:\n$$ \\hat{a} = \\frac{2.0376}{1.1960} \\approx 1.7036789... $$\nRounding to four significant figures as requested, we obtain the estimated slope:\n$$ \\hat{a} \\approx 1.704 $$\n\n**Implications of the Result**\nThe estimated slope, $\\hat{a} \\approx 1.704$, is often referred to as the spread-skill slope.\n- **Probabilistic Calibration**: For a perfectly reliable (or probabilistically calibrated) ensemble, there should be a one-to-one correspondence between the forecast spread and the forecast error variance. In our model, this would correspond to a slope of $a=1$. Our result, $\\hat{a} \\approx 1.704  1$, indicates that the ensemble is **underdispersive**. The actual forecast error variance grows faster than the ensemble variance suggests. This means the ensemble is systematically overconfident: in situations where it predicts high uncertainty (large $s_k^2$), the true uncertainty is even larger than indicated.\n- **Adaptive Multiplicative Spread Inflation**: To correct this underdispersion, a common technique is to inflate the ensemble spread. The fact that the relationship is linear suggests that multiplicative inflation is appropriate. An adaptive scheme would adjust the inflation based on the flow-dependent spread. The estimated slope directly informs this correction. To achieve a calibrated slope of $1$, the predictor variable $s_k^2$ should be scaled by $\\hat{a}$. This is equivalent to inflating the ensemble perturbations (deviations from the ensemble mean) by a factor $\\lambda = \\sqrt{\\hat{a}}$. In this case, the suggested inflation factor is $\\lambda = \\sqrt{1.704} \\approx 1.305$. This implies that inflating the amplitude of ensemble perturbations by approximately $30.5\\%$ would correct the diagnosed underdispersion and improve the ensemble's probabilistic performance.",
            "answer": "$$\\boxed{1.704}$$"
        },
        {
            "introduction": "While assessing ensemble calibration is vital , long-term climate projections introduce more complex sources of uncertainty beyond initial conditions, including future emissions pathways and scientific choices in model structure. The law of total variance provides a powerful framework for partitioning these distinct contributions. This exercise will guide you through applying this statistical tool to a multi-model, multi-scenario ensemble, allowing you to quantify and compare the relative importance of scenario uncertainty versus model structural uncertainty.",
            "id": "4037547",
            "problem": "A climate projection ensemble at horizon year $2100$ is constructed to study uncertainty partitioning in Numerical Weather Prediction (NWP) and climate modeling using an Ensemble Prediction System (EPS). Let $Y$ denote the $20$-year mean global-mean surface air temperature anomaly at year $2100$ relative to a late-twentieth-century baseline, measured in Kelvin. The ensemble is generated by crossing emissions scenarios and model structures and averaging over initial-condition perturbations, so that the conditional expectation $E[Y \\mid S=s, M=m]$ for scenario $S$ and model $M$ is well-defined. Assume the following conditions.\n\n- Scenarios: There are $3$ emissions scenarios, $S \\in \\{s_{1}, s_{2}, s_{3}\\}$, with prior probabilities $p_{s_{1}} = 0.25$, $p_{s_{2}} = 0.50$, and $p_{s_{3}} = 0.25$ at the decision horizon.\n- Model structures: There are $4$ climate models, $M \\in \\{m_{1}, m_{2}, m_{3}, m_{4}\\}$, each assigned equal weight $w_{m} = 0.25$ within any scenario.\n- Conditional means $E[Y \\mid S=s_{i}, M=m_{j}]$ at year $2100$ are given (in Kelvin) by:\n  - For $s_{1}$: $[1.8,\\, 2.1,\\, 2.2,\\, 1.9]$ for $(m_{1}, m_{2}, m_{3}, m_{4})$,\n  - For $s_{2}$: $[2.7,\\, 3.0,\\, 3.2,\\, 3.1]$ for $(m_{1}, m_{2}, m_{3}, m_{4})$,\n  - For $s_{3}$: $[4.1,\\, 4.6,\\, 4.9,\\, 4.4]$ for $(m_{1}, m_{2}, m_{3}, m_{4})$.\n- Within any fixed $(s,m)$, the remaining spread across initial conditions has zero mean and finite variance, but you may ignore this internal variability when computing the requested ratio because the question isolates scenario versus model-structure contributions.\n\nStarting from the law of total variance applied with nested conditioning on scenario and model, define the scenario-induced variance component as the variance across scenarios of the model-averaged conditional mean, and define the model-structure-induced variance component as the scenario-probability-weighted average of the variance across models of the conditional mean. Using the data above, compute the ratio $R$ of the scenario-induced spread to the model-structure-induced spread, where “spread” is defined as the standard deviation (the square root of variance). Express $R$ as a pure number (unitless) and round your answer to four significant figures.",
            "solution": "We formalize the uncertainty partition using the law of total variance from probability theory. Let $Y$ denote the projection, $S$ the scenario, and $M$ the model. The law of total variance states\n$$\n\\mathrm{Var}(Y) \\;=\\; \\mathrm{Var}\\!\\big(E[Y \\mid S]\\big) \\;+\\; E\\!\\big[\\mathrm{Var}(Y \\mid S)\\big].\n$$\nApplying the law again inside the conditional term with conditioning on $M$ yields\n$$\n\\mathrm{Var}(Y \\mid S) \\;=\\; \\mathrm{Var}\\!\\big(E[Y \\mid S, M] \\,\\big|\\, S\\big) \\;+\\; E\\!\\big[\\mathrm{Var}(Y \\mid S, M) \\,\\big|\\, S\\big].\n$$\nCombining these gives a variance decomposition into three nonnegative components,\n$$\n\\mathrm{Var}(Y) \\;=\\; \\underbrace{\\mathrm{Var}\\!\\big(E[Y \\mid S]\\big)}_{\\text{scenario component}} \\;+\\; \\underbrace{E\\!\\big[\\mathrm{Var}\\!\\big(E[Y \\mid S, M] \\,\\big|\\, S\\big)\\big]}_{\\text{model-structure component}} \\;+\\; \\underbrace{E\\!\\big[\\mathrm{Var}(Y \\mid S, M)\\big]}_{\\text{internal component}}.\n$$\nThe problem requests the ratio of spreads (standard deviations) of the first two components. Define\n$$\n\\sigma_{\\text{scen}} \\;=\\; \\sqrt{\\mathrm{Var}\\!\\big(E[Y \\mid S]\\big)}, \\qquad \\sigma_{\\text{model}} \\;=\\; \\sqrt{E\\!\\big[\\mathrm{Var}\\!\\big(E[Y \\mid S, M] \\,\\big|\\, S\\big)\\big]}.\n$$\nThen the requested ratio is $R \\;=\\; \\sigma_{\\text{scen}} / \\sigma_{\\text{model}}$.\n\nWe compute these components from the given conditional means and weights. Let\n$$\n\\mu_{s} \\;=\\; E\\!\\big[Y \\mid S=s\\big] \\;=\\; \\sum_{m} w_{m}\\, \\mu_{s,m}, \\quad \\text{with} \\quad \\mu_{s,m} \\;=\\; E[Y \\mid S=s, M=m],\n$$\nand the grand mean\n$$\n\\mu \\;=\\; E[Y] \\;=\\; \\sum_{s} p_{s}\\, \\mu_{s}.\n$$\n\nStep $1$ (scenario means). Using equal model weights $w_{m}=0.25$:\n- For $s_{1}$: $\\mu_{s_{1}} = 0.25(1.8 + 2.1 + 2.2 + 1.9) = 0.25 \\times 8.0 = 2.0$.\n- For $s_{2}$: $\\mu_{s_{2}} = 0.25(2.7 + 3.0 + 3.2 + 3.1) = 0.25 \\times 12.0 = 3.0$.\n- For $s_{3}$: $\\mu_{s_{3}} = 0.25(4.1 + 4.6 + 4.9 + 4.4) = 0.25 \\times 18.0 = 4.5$.\n\nThe grand mean is\n$$\n\\mu \\;=\\; 0.25 \\times 2.0 \\;+\\; 0.50 \\times 3.0 \\;+\\; 0.25 \\times 4.5 \\;=\\; 0.5 \\;+\\; 1.5 \\;+\\; 1.125 \\;=\\; 3.125.\n$$\n\nStep $2$ (scenario variance component). Using $\\mathrm{Var}(E[Y \\mid S]) = \\sum_{s} p_{s}\\,(\\mu_{s} - \\mu)^{2}$:\n- For $s_{1}$: $(2.0 - 3.125)^{2} = (-1.125)^{2} = 1.265625$, weighted by $0.25$ gives $0.31640625$.\n- For $s_{2}$: $(3.0 - 3.125)^{2} = (-0.125)^{2} = 0.015625$, weighted by $0.50$ gives $0.0078125$.\n- For $s_{3}$: $(4.5 - 3.125)^{2} = (1.375)^{2} = 1.890625$, weighted by $0.25$ gives $0.47265625$.\n\nSumming,\n$$\n\\sigma_{\\text{scen}}^{2} \\;=\\; 0.31640625 \\;+\\; 0.0078125 \\;+\\; 0.47265625 \\;=\\; 0.796875.\n$$\nNoting the exact fractional form, $0.796875 \\,=\\, \\frac{51}{64}$.\n\nStep $3$ (model-structure variance component). For each scenario $s$, compute the variance across models of $\\mu_{s,m}$ with equal weights:\n- For $s_{1}$, deviations from $2.0$ are $[-0.2,\\, 0.1,\\, 0.2,\\, -0.1]$ with squared values $[0.04,\\, 0.01,\\, 0.04,\\, 0.01]$, so\n$$\n\\mathrm{Var}_{M}(\\mu_{s_{1},\\cdot}) \\;=\\; 0.25 \\times (0.04 + 0.01 + 0.04 + 0.01) \\;=\\; 0.25 \\times 0.10 \\;=\\; 0.025 \\;=\\; \\frac{1}{40}.\n$$\n- For $s_{2}$, deviations from $3.0$ are $[-0.3,\\, 0.0,\\, 0.2,\\, 0.1]$ with squared values $[0.09,\\, 0.0,\\, 0.04,\\, 0.01]$, so\n$$\n\\mathrm{Var}_{M}(\\mu_{s_{2},\\cdot}) \\;=\\; 0.25 \\times (0.09 + 0.0 + 0.04 + 0.01) \\;=\\; 0.25 \\times 0.14 \\;=\\; 0.035 \\;=\\; \\frac{7}{200}.\n$$\n- For $s_{3}$, deviations from $4.5$ are $[-0.4,\\, 0.1,\\, 0.4,\\, -0.1]$ with squared values $[0.16,\\, 0.01,\\, 0.16,\\, 0.01]$, so\n$$\n\\mathrm{Var}_{M}(\\mu_{s_{3},\\cdot}) \\;=\\; 0.25 \\times (0.16 + 0.01 + 0.16 + 0.01) \\;=\\; 0.25 \\times 0.34 \\;=\\; 0.085 \\;=\\; \\frac{17}{200}.\n$$\n\nAverage these across scenarios with weights $p_{s}$:\n$$\n\\sigma_{\\text{model}}^{2} \\;=\\; \\sum_{s} p_{s}\\, \\mathrm{Var}_{M}(\\mu_{s,\\cdot}) \\;=\\; 0.25 \\times \\frac{1}{40} \\;+\\; 0.50 \\times \\frac{7}{200} \\;+\\; 0.25 \\times \\frac{17}{200}.\n$$\nConvert to a common denominator of $200$:\n$$\n\\sigma_{\\text{model}}^{2} \\;=\\; \\frac{5}{200} \\times 0.25 \\;+\\; \\frac{7}{200} \\times 0.50 \\;+\\; \\frac{17}{200} \\times 0.25 \\;=\\; \\frac{1.25 + 3.5 + 4.25}{200} \\;=\\; \\frac{9}{200} \\;=\\; 0.045.\n$$\n\nStep $4$ (ratio of spreads). The requested ratio is\n$$\nR \\;=\\; \\frac{\\sigma_{\\text{scen}}}{\\sigma_{\\text{model}}} \\;=\\; \\sqrt{\\frac{\\sigma_{\\text{scen}}^{2}}{\\sigma_{\\text{model}}^{2}}} \\;=\\; \\sqrt{\\frac{\\frac{51}{64}}{\\frac{9}{200}}} \\;=\\; \\sqrt{\\frac{51 \\times 200}{64 \\times 9}} \\;=\\; \\sqrt{\\frac{10200}{576}} \\;=\\; \\sqrt{\\frac{425}{24}}.\n$$\nNumerically, $\\frac{425}{24} \\approx 17.708333\\ldots$, hence\n$$\nR \\;\\approx\\; \\sqrt{17.708333\\ldots} \\;\\approx\\; 4.208127\\ldots\n$$\nRounded to four significant figures, $R \\approx 4.208$. This ratio is unitless, as required, because it is a ratio of standard deviations in the same units.",
            "answer": "$$\\boxed{4.208}$$"
        }
    ]
}