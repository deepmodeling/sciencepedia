{
    "hands_on_practices": [
        {
            "introduction": "An ensemble's ability to reduce forecast error and quantify uncertainty depends on the number of independent pieces of information it contains. In practice, models within an ensemble share components and are driven by similar data, leading to correlated errors. This practice  explores the concept of the effective ensemble size, $N_{\\mathrm{eff}}$, a metric that adjusts the nominal size of the ensemble, $N$, to account for this inter-member correlation. By deriving and applying the formula for $N_{\\mathrm{eff}}$, you will gain a quantitative understanding of how model redundancy can lead to an overestimation of forecast confidence.",
            "id": "4068191",
            "problem": "Consider a Multi-Model Ensemble (MME) used for consensus forecasting in Numerical Weather Prediction (NWP) and climate modeling. Let the ensemble consist of $N$ model forecast anomalies $\\{X_{i}\\}_{i=1}^{N}$ for a fixed lead time and region, where each $X_{i}$ is modeled as a random variable with common mean $E[X_{i}]=\\mu$ and common variance $\\operatorname{Var}(X_{i})=\\sigma^{2}$. Due to shared physics and data assimilation, the members are not independent. Assume an equicorrelation structure, so that for all $i \\neq j$, $\\operatorname{Corr}(X_{i},X_{j})=\\bar{\\rho}$, with $\\bar{\\rho}$ representing the average pairwise correlation across the ensemble. Define the ensemble mean $M=\\frac{1}{N}\\sum_{i=1}^{N}X_{i}$ and the effective ensemble size $N_{\\mathrm{eff}}$ as the unique positive quantity satisfying $\\operatorname{Var}(M)=\\frac{\\sigma^{2}}{N_{\\mathrm{eff}}}$.\n\nStarting from first principles—namely, the linearity of expectation, the bilinearity of covariance, the definition of correlation $\\operatorname{Corr}(X_{i},X_{j})=\\frac{\\operatorname{Cov}(X_{i},X_{j})}{\\sigma^{2}}$, and the variance of a sum—derive a closed-form expression for $N_{\\mathrm{eff}}$ in terms of $N$ and $\\bar{\\rho}$ under the equicorrelation assumption. Then, for $N=10$ and $\\bar{\\rho}=0.5$, compute $N_{\\mathrm{eff}}$. Round your numerical answer to four significant figures. Finally, briefly comment on the consequence this value of $N_{\\mathrm{eff}}$ has for uncertainty estimation when using ensemble spread to quantify the uncertainty of the ensemble mean.",
            "solution": "The problem statement has been validated and is deemed sound, well-posed, and objective. It is a standard problem in the statistical analysis of ensemble forecasts.\n\nThe objective is to derive an expression for the effective ensemble size, $N_{\\mathrm{eff}}$, and compute its value for a specific case. The definition of $N_{\\mathrm{eff}}$ is given by the relation:\n$$\n\\operatorname{Var}(M) = \\frac{\\sigma^{2}}{N_{\\mathrm{eff}}}\n$$\nwhere $M$ is the ensemble mean, and $\\sigma^{2}$ is the common variance of the individual ensemble members. To find $N_{\\mathrm{eff}}$, we must first derive an expression for the variance of the ensemble mean, $\\operatorname{Var}(M)$, from first principles.\n\nThe ensemble mean, $M$, is defined as the arithmetic average of the $N$ ensemble members $\\{X_{i}\\}_{i=1}^{N}$:\n$$\nM = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}\n$$\nUsing the properties of the variance operator, specifically $\\operatorname{Var}(cY) = c^{2}\\operatorname{Var}(Y)$ for a constant $c$ and random variable $Y$, we can write:\n$$\n\\operatorname{Var}(M) = \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N}X_{i}\\right) = \\frac{1}{N^{2}}\\operatorname{Var}\\left(\\sum_{i=1}^{N}X_{i}\\right)\n$$\nThe variance of a sum of random variables is the sum of all elements in their covariance matrix:\n$$\n\\operatorname{Var}\\left(\\sum_{i=1}^{N}X_{i}\\right) = \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\operatorname{Cov}(X_{i}, X_{j})\n$$\nWe can decompose this double summation into two parts: a sum over the diagonal terms where $i=j$, and a sum over the off-diagonal terms where $i \\neq j$.\n$$\n\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\operatorname{Cov}(X_{i}, X_{j}) = \\sum_{i=1}^{N}\\operatorname{Cov}(X_{i}, X_{i}) + \\sum_{i=1}^{N}\\sum_{j \\neq i}\\operatorname{Cov}(X_{i}, X_{j})\n$$\nThe diagonal terms are the variances of the individual members. By definition, $\\operatorname{Cov}(X_{i}, X_{i}) = \\operatorname{Var}(X_{i})$. The problem states that all members have a common variance, $\\operatorname{Var}(X_{i}) = \\sigma^{2}$. Thus, the sum of the diagonal terms is:\n$$\n\\sum_{i=1}^{N}\\operatorname{Var}(X_{i}) = \\sum_{i=1}^{N}\\sigma^{2} = N\\sigma^{2}\n$$\nFor the off-diagonal terms ($i \\neq j$), the covariance is related to the correlation $\\bar{\\rho}$ by the definition $\\operatorname{Corr}(X_{i},X_{j})=\\frac{\\operatorname{Cov}(X_{i},X_{j})}{\\sqrt{\\operatorname{Var}(X_i)\\operatorname{Var}(X_j)}}$. Given the common variance $\\sigma^{2}$ and the equicorrelation assumption $\\operatorname{Corr}(X_{i}, X_{j}) = \\bar{\\rho}$ for $i \\neq j$, we have:\n$$\n\\operatorname{Cov}(X_{i}, X_{j}) = \\bar{\\rho}\\sqrt{\\sigma^{2}\\sigma^{2}} = \\bar{\\rho}\\sigma^{2}\n$$\nThe number of off-diagonal terms in the $N \\times N$ covariance matrix is $N^{2} - N = N(N-1)$. Therefore, the sum of the off-diagonal terms is:\n$$\n\\sum_{i=1}^{N}\\sum_{j \\neq i}\\operatorname{Cov}(X_{i}, X_{j}) = N(N-1)\\bar{\\rho}\\sigma^{2}\n$$\nCombining the diagonal and off-diagonal sums, we obtain the variance of the sum:\n$$\n\\operatorname{Var}\\left(\\sum_{i=1}^{N}X_{i}\\right) = N\\sigma^{2} + N(N-1)\\bar{\\rho}\\sigma^{2} = N\\sigma^{2}\\left[1 + (N-1)\\bar{\\rho}\\right]\n$$\nNow, we substitute this back into the expression for $\\operatorname{Var}(M)$:\n$$\n\\operatorname{Var}(M) = \\frac{1}{N^{2}} \\left( N\\sigma^{2}\\left[1 + (N-1)\\bar{\\rho}\\right] \\right) = \\frac{\\sigma^{2}}{N}\\left[1 + (N-1)\\bar{\\rho}\\right]\n$$\nWe equate this result with the definition of $N_{\\mathrm{eff}}$:\n$$\n\\frac{\\sigma^{2}}{N_{\\mathrm{eff}}} = \\frac{\\sigma^{2}}{N}\\left[1 + (N-1)\\bar{\\rho}\\right]\n$$\nAssuming $\\sigma^{2} > 0$ (as forecast anomalies are not constant), we can cancel $\\sigma^{2}$ from both sides:\n$$\n\\frac{1}{N_{\\mathrm{eff}}} = \\frac{1 + (N-1)\\bar{\\rho}}{N}\n$$\nTaking the reciprocal of both sides yields the closed-form expression for $N_{\\mathrm{eff}}$:\n$$\nN_{\\mathrm{eff}} = \\frac{N}{1 + (N-1)\\bar{\\rho}}\n$$\nThis is the desired analytical expression.\n\nNext, we compute the numerical value for $N=10$ and $\\bar{\\rho}=0.5$:\n$$\nN_{\\mathrm{eff}} = \\frac{10}{1 + (10-1)(0.5)} = \\frac{10}{1 + (9)(0.5)} = \\frac{10}{1 + 4.5} = \\frac{10}{5.5}\n$$\n$$\nN_{\\mathrm{eff}} = \\frac{100}{55} = \\frac{20}{11} \\approx 1.818181...\n$$\nRounding to four significant figures, we get $N_{\\mathrm{eff}} \\approx 1.818$.\n\nFinally, we comment on the consequence of this result for uncertainty estimation. The uncertainty of the ensemble mean forecast is quantified by its standard error, $\\sqrt{\\operatorname{Var}(M)} = \\sigma/\\sqrt{N_{\\mathrm{eff}}}$. If the ensemble members were independent ($\\bar{\\rho}=0$), then $N_{\\mathrm{eff}}$ would equal $N$, and the standard error of the mean would be $\\sigma/\\sqrt{N}$. In our case, with $N=10$ and a positive correlation $\\bar{\\rho}=0.5$, the effective size is $N_{\\mathrm{eff}} \\approx 1.818$. This value is substantially smaller than the actual number of models, $N=10$. This signifies that the $10$ correlated models provide the same amount of information for reducing uncertainty as an ensemble of approximately $2$ truly independent models.\nA common practice is to use the spread of the ensemble (i.e., the sample standard deviation of the members) as a measure of forecast uncertainty. If one naively assumes the members are independent, the uncertainty in the ensemble mean would be estimated as being proportional to $1/\\sqrt{N} = 1/\\sqrt{10}$. However, the true uncertainty is proportional to $1/\\sqrt{N_{\\mathrm{eff}}} = 1/\\sqrt{1.818}$, which is a significantly larger value. Consequently, failing to account for inter-model correlation leads to a substantial underestimation of the true uncertainty of the ensemble mean. The ensemble is overconfident, appearing more skillful than it actually is, because the shared errors and biases among models are not being properly factored into the uncertainty assessment. The concept of $N_{\\mathrm{eff}}$ is therefore critical for correcting this overconfidence and providing a more realistic estimate of forecast skill.",
            "answer": "$$\n\\boxed{1.818}\n$$"
        },
        {
            "introduction": "Combining forecasts from multiple models is a powerful strategy for improving predictive skill, but a simple average is not always the best approach. This practice  introduces the principle of inverse-covariance weighting, which constructs an optimal linear consensus forecast by minimizing its variance. By deriving the weight formula from first principles and applying it to a multi-model scenario, you will see how this method rewards models for both low error and for providing information that is independent of the rest of the ensemble.",
            "id": "4068202",
            "problem": "Consider a three-model consensus forecasting problem in Numerical Weather Prediction (NWP) and climate modeling. Let the scalar quantity of interest be a true state $y$, and suppose three model forecasts $x_{1}$, $x_{2}$, $x_{3}$ aim to estimate $y$ without bias, so that each forecast can be written as $x_{i} = y + \\varepsilon_{i}$ where the error vector $\\varepsilon = (\\varepsilon_{1}, \\varepsilon_{2}, \\varepsilon_{3})^{\\top}$ satisfies $\\mathbb{E}[\\varepsilon] = 0$ and has error covariance matrix $\\Sigma \\in \\mathbb{R}^{3 \\times 3}$. The consensus forecast is a linear combination $\\widehat{y} = w_{1} x_{1} + w_{2} x_{2} + w_{3} x_{3}$ with weights $w = (w_{1}, w_{2}, w_{3})^{\\top}$ constrained by the unbiasedness condition $w_{1} + w_{2} + w_{3} = 1$. Starting from the definitions of unbiasedness and the variance of a linear combination under a known covariance matrix, derive from first principles the weight vector $w^{\\ast}$ that minimizes the forecast variance $\\mathrm{Var}(\\widehat{y})$ subject to the unbiasedness constraint. Then, for the scientifically plausible $3 \\times 3$ symmetric positive definite error covariance matrix\n$$\n\\Sigma = \\begin{pmatrix}\n4 & 2 & 1 \\\\\n2 & 5 & 2 \\\\\n1 & 2 & 3\n\\end{pmatrix},\n$$\ncompute the resulting optimal inverse-covariance consensus weights $w^{\\ast}$, normalized to sum to one. Finally, interpret the weight pattern in light of the variances and covariances in $\\Sigma$. Express the weights as exact fractions (dimensionless). No rounding is required.",
            "solution": "The problem is to find the weight vector $w = (w_1, w_2, w_3)^\\top$ that minimizes the variance of the consensus forecast $\\widehat{y} = w_1 x_1 + w_2 x_2 + w_3 x_3$, subject to the constraint that the forecast is unbiased.\n\nFirst, we formalize the problem. The consensus forecast can be written in vector form as $\\widehat{y} = w^\\top x$, where $x = (x_1, x_2, x_3)^\\top$. The models are given by $x_i = y + \\varepsilon_i$, or in vector form, $x = y \\mathbf{1} + \\varepsilon$, where $\\mathbf{1}$ is a column vector of ones. Substituting this into the expression for $\\widehat{y}$ gives:\n$$\n\\widehat{y} = w^\\top (y \\mathbf{1} + \\varepsilon) = y (w^\\top \\mathbf{1}) + w^\\top \\varepsilon\n$$\nThe problem states the unbiasedness condition is $w_1 + w_2 + w_3 = 1$, which is equivalent to $w^\\top \\mathbf{1} = 1$. Applying this constraint, the consensus forecast simplifies to:\n$$\n\\widehat{y} = y + w^\\top \\varepsilon\n$$\nThe error of the consensus forecast is $\\widehat{y} - y = w^\\top \\varepsilon$. We can now find the variance of $\\widehat{y}$, denoted $\\mathrm{Var}(\\widehat{y})$. The expected value of the consensus forecast is $\\mathbb{E}[\\widehat{y}] = \\mathbb{E}[y + w^\\top \\varepsilon] = y + w^\\top \\mathbb{E}[\\varepsilon]$. Since the model errors are unbiased, $\\mathbb{E}[\\varepsilon] = 0$, so $\\mathbb{E}[\\widehat{y}] = y$.\nThe variance is then:\n$$\n\\mathrm{Var}(\\widehat{y}) = \\mathbb{E}[(\\widehat{y} - \\mathbb{E}[\\widehat{y}])^2] = \\mathbb{E}[(\\widehat{y} - y)^2] = \\mathbb{E}[(w^\\top \\varepsilon)^2]\n$$\nSince $w^\\top \\varepsilon$ is a scalar, its square can be written as $(w^\\top \\varepsilon)(w^\\top \\varepsilon) = (w^\\top \\varepsilon)(\\varepsilon^\\top w) = w^\\top (\\varepsilon \\varepsilon^\\top) w$.\nTaking the expectation, we get:\n$$\n\\mathrm{Var}(\\widehat{y}) = \\mathbb{E}[w^\\top \\varepsilon \\varepsilon^\\top w] = w^\\top \\mathbb{E}[\\varepsilon \\varepsilon^\\top] w\n$$\nBy definition, the error covariance matrix is $\\Sigma = \\mathbb{E}[\\varepsilon \\varepsilon^\\top]$. Therefore, the variance to be minimized is:\n$$\n\\mathrm{Var}(\\widehat{y}) = w^\\top \\Sigma w\n$$\nThe optimization problem is to minimize $f(w) = w^\\top \\Sigma w$ subject to the constraint $g(w) = w^\\top \\mathbf{1} - 1 = 0$. We use the method of Lagrange multipliers. The Lagrangian $\\mathcal{L}$ is:\n$$\n\\mathcal{L}(w, \\lambda) = w^\\top \\Sigma w - \\lambda (w^\\top \\mathbf{1} - 1)\n$$\nTo find the minimum, we set the gradient of $\\mathcal{L}$ with respect to $w$ to zero. Using the matrix derivative rule $\\frac{\\partial}{\\partial w}(w^\\top A w) = 2Aw$ for a symmetric matrix $A$, we have:\n$$\n\\nabla_w \\mathcal{L} = 2 \\Sigma w - \\lambda \\mathbf{1} = 0\n$$\n$$\n2 \\Sigma w = \\lambda \\mathbf{1}\n$$\nSince $\\Sigma$ is a positive definite covariance matrix, it is invertible. We can solve for $w$:\n$$\nw = \\frac{\\lambda}{2} \\Sigma^{-1} \\mathbf{1}\n$$\nThis equation shows that the optimal weights are proportional to the sum of the rows of the inverse covariance matrix. To find the Lagrange multiplier $\\lambda$, we apply the constraint $w^\\top \\mathbf{1} = 1$:\n$$\n\\left( \\frac{\\lambda}{2} \\Sigma^{-1} \\mathbf{1} \\right)^\\top \\mathbf{1} = 1\n$$\n$$\n\\frac{\\lambda}{2} (\\Sigma^{-1} \\mathbf{1})^\\top \\mathbf{1} = 1\n$$\n$$\n\\frac{\\lambda}{2} \\mathbf{1}^\\top (\\Sigma^{-1})^\\top \\mathbf{1} = 1\n$$\nSince $\\Sigma$ is symmetric, its inverse $\\Sigma^{-1}$ is also symmetric, so $(\\Sigma^{-1})^\\top = \\Sigma^{-1}$.\n$$\n\\frac{\\lambda}{2} (\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}) = 1\n$$\nSolving for $\\lambda$:\n$$\n\\lambda = \\frac{2}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}}\n$$\nSubstituting this back into the expression for $w$, we obtain the optimal weight vector $w^\\ast$:\n$$\nw^\\ast = \\frac{1}{2} \\left( \\frac{2}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}} \\right) \\Sigma^{-1} \\mathbf{1} = \\frac{\\Sigma^{-1} \\mathbf{1}}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}}\n$$\nThis is the general formula for the optimal weights. The numerator is the vector of row-sums of the inverse covariance matrix, and the denominator is the sum of all elements of the inverse covariance matrix, which acts as a normalization constant.\n\nNow, we apply this formula to the given covariance matrix:\n$$\n\\Sigma = \\begin{pmatrix} 4 & 2 & 1 \\\\ 2 & 5 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}\n$$\nFirst, we must compute $\\Sigma^{-1}$. The inverse is given by $\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)} \\mathrm{adj}(\\Sigma)$, where $\\mathrm{adj}(\\Sigma)$ is the adjugate matrix of $\\Sigma$.\nThe determinant of $\\Sigma$ is:\n$$\n\\det(\\Sigma) = 4(5 \\cdot 3 - 2 \\cdot 2) - 2(2 \\cdot 3 - 2 \\cdot 1) + 1(2 \\cdot 2 - 5 \\cdot 1)\n$$\n$$\n\\det(\\Sigma) = 4(15 - 4) - 2(6 - 2) + 1(4 - 5) = 4(11) - 2(4) - 1 = 44 - 8 - 1 = 35\n$$\nThe cofactor matrix $C$ is:\n$$\nC_{11} = \\begin{vmatrix} 5 & 2 \\\\ 2 & 3 \\end{vmatrix} = 11, \\quad C_{12} = -\\begin{vmatrix} 2 & 2 \\\\ 1 & 3 \\end{vmatrix} = -4, \\quad C_{13} = \\begin{vmatrix} 2 & 5 \\\\ 1 & 2 \\end{vmatrix} = -1\n$$\n$$\nC_{21} = -\\begin{vmatrix} 2 & 1 \\\\ 2 & 3 \\end{vmatrix} = -4, \\quad C_{22} = \\begin{vmatrix} 4 & 1 \\\\ 1 & 3 \\end{vmatrix} = 11, \\quad C_{23} = -\\begin{vmatrix} 4 & 2 \\\\ 1 & 2 \\end{vmatrix} = -6\n$$\n$$\nC_{31} = \\begin{vmatrix} 2 & 1 \\\\ 5 & 2 \\end{vmatrix} = -1, \\quad C_{32} = -\\begin{vmatrix} 4 & 1 \\\\ 2 & 2 \\end{vmatrix} = -6, \\quad C_{33} = \\begin{vmatrix} 4 & 2 \\\\ 2 & 5 \\end{vmatrix} = 16\n$$\nSo, the cofactor matrix is $C = \\begin{pmatrix} 11 & -4 & -1 \\\\ -4 & 11 & -6 \\\\ -1 & -6 & 16 \\end{pmatrix}$. The adjugate matrix is the transpose of $C$, but since $C$ is symmetric, $\\mathrm{adj}(\\Sigma) = C$.\nThe inverse covariance matrix is:\n$$\n\\Sigma^{-1} = \\frac{1}{35} \\begin{pmatrix} 11 & -4 & -1 \\\\ -4 & 11 & -6 \\\\ -1 & -6 & 16 \\end{pmatrix}\n$$\nNext, we compute the numerator of the weight formula, $\\Sigma^{-1} \\mathbf{1}$:\n$$\n\\Sigma^{-1} \\mathbf{1} = \\frac{1}{35} \\begin{pmatrix} 11 & -4 & -1 \\\\ -4 & 11 & -6 \\\\ -1 & -6 & 16 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{35} \\begin{pmatrix} 11-4-1 \\\\ -4+11-6 \\\\ -1-6+16 \\end{pmatrix} = \\frac{1}{35} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix}\n$$\nThe denominator is $\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}$, which is the sum of the components of the vector we just calculated:\n$$\n\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1} = \\frac{1}{35} (6 + 1 + 9) = \\frac{16}{35}\n$$\nFinally, the optimal weight vector $w^\\ast$ is:\n$$\nw^\\ast = \\frac{\\Sigma^{-1} \\mathbf{1}}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}} = \\frac{\\frac{1}{35} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix}}{\\frac{16}{35}} = \\frac{1}{16} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} 6/16 \\\\ 1/16 \\\\ 9/16 \\end{pmatrix} = \\begin{pmatrix} 3/8 \\\\ 1/16 \\\\ 9/16 \\end{pmatrix}\n$$\nThe optimal weights are $w_1^\\ast = \\frac{3}{8}$, $w_2^\\ast = \\frac{1}{16}$, and $w_3^\\ast = \\frac{9}{16}$.\n\nTo interpret this result, we compare the weights to the properties of the models given by $\\Sigma$. The diagonal elements of $\\Sigma$ are the variances of the individual model errors: $\\sigma_1^2 = 4$, $\\sigma_2^2 = 5$, and $\\sigma_3^2 = 3$. The off-diagonal elements are the covariances.\n\\begin{enumerate}\n    \\item The model with the lowest variance is model 3 ($\\sigma_3^2 = 3$), and it receives the highest weight ($w_3^\\ast = 9/16 = 0.5625$). This is expected, as lower-error models should be trusted more.\n    \\item The model with the highest variance is model 2 ($\\sigma_2^2 = 5$), and it receives the lowest weight ($w_2^\\ast = 1/16 = 0.0625$). This is also expected.\n    \\item The weighting is not simply proportional to the inverse variance. If errors were uncorrelated, the weights would be proportional to $1/\\sigma_i^2$, which would be $1/4:1/5:1/3$ for models $1, 2, 3$. The presence of positive covariances ($ \\Sigma_{12}=2, \\Sigma_{13}=1, \\Sigma_{23}=2 $) penalizes models that are redundant. Model 2, in addition to having the highest variance, is also significantly correlated with the other two models (correlation $\\rho_{23} = \\frac{2}{\\sqrt{5}\\sqrt{3}} \\approx 0.52$ and $\\rho_{12} = \\frac{2}{\\sqrt{4}\\sqrt{5}} \\approx 0.45$). This high redundancy and high error cause its weight to be suppressed dramatically.\n    \\item Model 1 has a lower variance than model 2 ($\\sigma_1^2 = 4$ vs $\\sigma_2^2 = 5$), and it receives a much higher weight ($w_1^\\ast = 3/8 = 0.375$). Its contribution is considered more valuable than that of model 2.\n\\end{enumerate}\nIn summary, the optimal weights reflect a balance between a model's individual skill (inverse variance) and the unique information it provides (low covariance with other models). Model 3 is rewarded for its low error, while model 2 is heavily penalized for its combination of high error and high correlation with the other models.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{8} \\\\ \\frac{1}{16} \\\\ \\frac{9}{16} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The goal of ensemble forecasting is not just to predict an outcome, but to produce a reliable probabilistic distribution of all possible outcomes. To assess this reliability, or \"calibration,\" we can use the Probability Integral Transform (PIT), which transforms observations into a set of values that should be uniformly distributed if the forecast is well-calibrated. This exercise  demonstrates how to apply the Kolmogorov-Smirnov statistical test to a sample of PIT values to quantitatively check for uniformity, providing a rigorous method for verifying the quality of a probabilistic forecast.",
            "id": "4068216",
            "problem": "A weather forecasting center evaluates the calibration of a multi-model ensemble by examining the Probability Integral Transform (PIT) values derived from its predictive cumulative distribution function (CDF). Let the forecast system produce a predictive cumulative distribution function $F$ for a scalar atmospheric variable $Y$, and let $(y_{i})_{i=1}^{n}$ be $n$ verifying observations from an independent test period. The PIT values are defined by $u_{i} = F(y_{i})$ for $i=1,\\dots,n$. Under probabilistic calibration (i.e., the predictive distribution $F$ coincides with the true conditional distribution of $Y$), the PIT values $(u_{i})$ are independent and identically distributed according to the continuous uniform distribution on $[0,1]$. \n\nSuppose $n=10$ and the observed PIT values are $\\{0.05, 0.15, 0.82, 0.91, 0.50, 0.33, 0.48, 0.62, 0.77, 0.88\\}$. Using principles of goodness-of-fit from empirical process theory, construct the one-sample Kolmogorov–Smirnov statistic comparing the empirical distribution function of the PIT values to the uniform CDF on $[0,1]$ as your test statistic. Then, using the asymptotic null distribution of the Kolmogorov–Smirnov statistic, quantify the strength of evidence against the null hypothesis of uniformity and interpret what this implies for the probabilistic calibration of $F$ in this test sample.\n\nReport as your final answer the asymptotic Kolmogorov–Smirnov $p$-value associated with the observed test statistic. Express the final $p$-value as a dimensionless decimal rounded to three significant figures.",
            "solution": "The problem requires us to assess the probabilistic calibration of a weather forecasting ensemble. This is achieved by performing a goodness-of-fit test on a sample of Probability Integral Transform (PIT) values. The null hypothesis, $H_0$, is that the forecast system is perfectly calibrated, which implies that the PIT values are independent and identically distributed (i.i.d.) draws from a continuous uniform distribution on the interval $[0,1]$, denoted as $U(0,1)$. We are asked to use the one-sample Kolmogorov-Smirnov (KS) test for this purpose.\n\nThe given data consists of $n=10$ PIT values: $\\{0.05, 0.15, 0.82, 0.91, 0.50, 0.33, 0.48, 0.62, 0.77, 0.88\\}$.\n\nThe first step in calculating the KS statistic is to order the sample data from smallest to largest. Let the ordered sample be denoted by $u_{(i)}$ for $i=1, \\dots, 10$.\nThe ordered PIT values are:\n$u_{(1)} = 0.05$\n$u_{(2)} = 0.15$\n$u_{(3)} = 0.33$\n$u_{(4)} = 0.48$\n$u_{(5)} = 0.50$\n$u_{(6)} = 0.62$\n$u_{(7)} = 0.77$\n$u_{(8)} = 0.82$\n$u_{(9)} = 0.88$\n$u_{(10)} = 0.91$\n\nThe one-sample Kolmogorov-Smirnov test statistic, $D_n$, is defined as the maximum absolute difference between the empirical distribution function (EDF) of the sample, $F_n(x)$, and the hypothesized cumulative distribution function (CDF), $F(x)$. Under the null hypothesis of uniformity on $[0,1]$, the CDF is $F(x) = x$. The EDF is defined as $F_n(x) = \\frac{1}{n}\\sum_{i=1}^{n} I(u_i \\le x)$, where $I$ is the indicator function. The test statistic is:\n$$D_n = \\sup_{x \\in [0,1]} |F_n(x) - F(x)| = \\sup_{x \\in [0,1]} |F_n(x) - x|$$\n\nThe supremum is guaranteed to be found at one of the observed data points. A computationally convenient formula for $D_n$ using the ordered sample $u_{(i)}$ is:\n$$D_n = \\max \\left( \\max_{i=1,\\dots,n} \\left\\{\\frac{i}{n} - u_{(i)}\\right\\}, \\max_{i=1,\\dots,n} \\left\\{u_{(i)} - \\frac{i-1}{n}\\right\\} \\right)$$\n\nLet's calculate the two components, $D_n^+ = \\max_{i} \\{\\frac{i}{n} - u_{(i)}\\}$ and $D_n^- = \\max_{i} \\{u_{(i)} - \\frac{i-1}{n}\\}$, for our sample with $n=10$.\n\nFor $i=1$: $D_1^+ = \\frac{1}{10} - 0.05 = 0.05$; $D_1^- = 0.05 - \\frac{0}{10} = 0.05$.\nFor $i=2$: $D_2^+ = \\frac{2}{10} - 0.15 = 0.05$; $D_2^- = 0.15 - \\frac{1}{10} = 0.05$.\nFor $i=3$: $D_3^+ = \\frac{3}{10} - 0.33 = -0.03$; $D_3^- = 0.33 - \\frac{2}{10} = 0.13$.\nFor $i=4$: $D_4^+ = \\frac{4}{10} - 0.48 = -0.08$; $D_4^- = 0.48 - \\frac{3}{10} = 0.18$.\nFor $i=5$: $D_5^+ = \\frac{5}{10} - 0.50 = 0.00$; $D_5^- = 0.50 - \\frac{4}{10} = 0.10$.\nFor $i=6$: $D_6^+ = \\frac{6}{10} - 0.62 = -0.02$; $D_6^- = 0.62 - \\frac{5}{10} = 0.12$.\nFor $i=7$: $D_7^+ = \\frac{7}{10} - 0.77 = -0.07$; $D_7^- = 0.77 - \\frac{6}{10} = 0.17$.\nFor $i=8$: $D_8^+ = \\frac{8}{10} - 0.82 = -0.02$; $D_8^- = 0.82 - \\frac{7}{10} = 0.12$.\nFor $i=9$: $D_9^+ = \\frac{9}{10} - 0.88 = 0.02$; $D_9^- = 0.88 - \\frac{8}{10} = 0.08$.\nFor $i=10$: $D_{10}^+ = \\frac{10}{10} - 0.91 = 0.09$; $D_{10}^- = 0.91 - \\frac{9}{10} = 0.01$.\n\nThe maximum of the first set of differences is $D_n^+ = \\max\\{0.05, 0.05, -0.03, -0.08, 0.00, -0.02, -0.07, -0.02, 0.02, 0.09\\} = 0.09$.\nThe maximum of the second set is $D_n^- = \\max\\{0.05, 0.05, 0.13, 0.18, 0.10, 0.12, 0.17, 0.12, 0.08, 0.01\\} = 0.18$.\n\nThe Kolmogorov-Smirnov statistic for our sample is the maximum of these two values:\n$$D_{10} = \\max(D_{10}^+, D_{10}^-) = \\max(0.09, 0.18) = 0.18$$\n\nNext, we must find the $p$-value associated with this statistic using its asymptotic null distribution. The problem instructs us to use this asymptotic approximation, even though the sample size $n=10$ is small, for which the exact distribution would typically be preferred. Under $H_0$, the distribution of the scaled statistic $d = \\sqrt{n}D_n$ converges to the Kolmogorov distribution as $n \\to \\infty$. The $p$-value is the probability of observing a test statistic at least as large as the one computed.\n\nThe value of our scaled statistic is:\n$$d = \\sqrt{10} \\times D_{10} = \\sqrt{10} \\times 0.18 \\approx 3.162277 \\times 0.18 \\approx 0.56921$$\n\nThe $p$-value is given by the survival function of the Kolmogorov distribution, $P(K \\ge x)$, where $K$ is a random variable following this distribution. The survival function can be expressed as an infinite series:\n$$P(K \\ge x) = 2 \\sum_{k=1}^{\\infty} (-1)^{k-1} \\exp(-2k^2x^2)$$\nFor our calculated value $d \\approx 0.56921$, we have $d^2 = (\\sqrt{10} \\times 0.18)^2 = 10 \\times 0.18^2 = 10 \\times 0.0324 = 0.324$.\nSubstituting $x^2 = 0.324$ into the series for the $p$-value:\n$$p\\text{-value} = 2 \\sum_{k=1}^{\\infty} (-1)^{k-1} \\exp(-2k^2 \\times 0.324)$$\n$$p\\text{-value} = 2 \\left( \\exp(-2 \\times 1^2 \\times 0.324) - \\exp(-2 \\times 2^2 \\times 0.324) + \\exp(-2 \\times 3^2 \\times 0.324) - \\dots \\right)$$\n$$p\\text{-value} = 2 \\left( \\exp(-0.648) - \\exp(-2.592) + \\exp(-5.832) - \\dots \\right)$$\n\nThe series converges rapidly. We calculate the first few terms:\n$\\exp(-0.648) \\approx 0.523079$\n$\\exp(-2.592) \\approx 0.074874$\n$\\exp(-5.832) \\approx 0.002932$\nThe fourth term, with $\\exp(-2 \\times 4^2 \\times 0.324) = \\exp(-10.368)$, is approximately $3.15 \\times 10^{-5}$ and can be neglected for the required precision.\n\nSumming the terms inside the parentheses:\n$0.523079 - 0.074874 + 0.002932 \\approx 0.451137$\nMultiplying by $2$:\n$$p\\text{-value} \\approx 2 \\times 0.451137 = 0.902274$$\n\nThis $p$-value represents the probability of observing a deviation from uniformity at least as large as $D_{10} = 0.18$ in a sample of size $10$, assuming the null hypothesis of uniformity is true. A high $p$-value (conventionally, greater than a significance level like $0.05$ or $0.10$) indicates that the observed data is consistent with the null hypothesis.\n\nOur calculated $p$-value of approximately $0.902$ is very large. This means we fail to reject the null hypothesis. There is no statistically significant evidence from this test to conclude that the forecast system's predictive CDF is miscalibrated. The distribution of the observed PIT values is not distinguishably different from a uniform distribution.\n\nThe final answer is the asymptotic $p$-value, rounded to three significant figures.\n$0.902274 \\dots \\to 0.902$.",
            "answer": "$$\\boxed{0.902}$$"
        }
    ]
}