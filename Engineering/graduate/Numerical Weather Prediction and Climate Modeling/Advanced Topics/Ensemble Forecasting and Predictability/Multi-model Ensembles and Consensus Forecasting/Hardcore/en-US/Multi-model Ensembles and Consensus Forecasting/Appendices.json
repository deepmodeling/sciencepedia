{
    "hands_on_practices": [
        {
            "introduction": "A fundamental task in ensemble forecasting is combining multiple model outputs to create a single consensus forecast that is, on average, more accurate than any individual member. This exercise  delves into the foundational method of inverse-covariance weighting. You will derive from first principles the optimal weights that minimize the consensus forecast variance, learning how this technique judiciously balances a model's individual performance with its error correlations, or redundancy, with other ensemble members.",
            "id": "4068202",
            "problem": "Consider a three-model consensus forecasting problem in Numerical Weather Prediction (NWP) and climate modeling. Let the scalar quantity of interest be a true state $y$, and suppose three model forecasts $x_{1}$, $x_{2}$, $x_{3}$ aim to estimate $y$ without bias, so that each forecast can be written as $x_{i} = y + \\varepsilon_{i}$ where the error vector $\\varepsilon = (\\varepsilon_{1}, \\varepsilon_{2}, \\varepsilon_{3})^{\\top}$ satisfies $\\mathbb{E}[\\varepsilon] = 0$ and has error covariance matrix $\\Sigma \\in \\mathbb{R}^{3 \\times 3}$. The consensus forecast is a linear combination $\\widehat{y} = w_{1} x_{1} + w_{2} x_{2} + w_{3} x_{3}$ with weights $w = (w_{1}, w_{2}, w_{3})^{\\top}$ constrained by the unbiasedness condition $w_{1} + w_{2} + w_{3} = 1$. Starting from the definitions of unbiasedness and the variance of a linear combination under a known covariance matrix, derive from first principles the weight vector $w^{\\ast}$ that minimizes the forecast variance $\\mathrm{Var}(\\widehat{y})$ subject to the unbiasedness constraint. Then, for the scientifically plausible $3 \\times 3$ symmetric positive definite error covariance matrix\n$$\n\\Sigma = \\begin{pmatrix}\n4  2  1 \\\\\n2  5  2 \\\\\n1  2  3\n\\end{pmatrix},\n$$\ncompute the resulting optimal inverse-covariance consensus weights $w^{\\ast}$, normalized to sum to one. Finally, interpret the weight pattern in light of the variances and covariances in $\\Sigma$. Express the weights as exact fractions (dimensionless). No rounding is required.",
            "solution": "The problem is to find the weight vector $w = (w_1, w_2, w_3)^\\top$ that minimizes the variance of the consensus forecast $\\widehat{y} = w_1 x_1 + w_2 x_2 + w_3 x_3$, subject to the constraint that the forecast is unbiased.\n\nFirst, we formalize the problem. The consensus forecast can be written in vector form as $\\widehat{y} = w^\\top x$, where $x = (x_1, x_2, x_3)^\\top$. The models are given by $x_i = y + \\varepsilon_i$, or in vector form, $x = y \\mathbf{1} + \\varepsilon$, where $\\mathbf{1}$ is a column vector of ones. Substituting this into the expression for $\\widehat{y}$ gives:\n$$\n\\widehat{y} = w^\\top (y \\mathbf{1} + \\varepsilon) = y (w^\\top \\mathbf{1}) + w^\\top \\varepsilon\n$$\nThe problem states the unbiasedness condition is $w_1 + w_2 + w_3 = 1$, which is equivalent to $w^\\top \\mathbf{1} = 1$. Applying this constraint, the consensus forecast simplifies to:\n$$\n\\widehat{y} = y + w^\\top \\varepsilon\n$$\nThe error of the consensus forecast is $\\widehat{y} - y = w^\\top \\varepsilon$. We can now find the variance of $\\widehat{y}$, denoted $\\mathrm{Var}(\\widehat{y})$. The expected value of the consensus forecast is $\\mathbb{E}[\\widehat{y}] = \\mathbb{E}[y + w^\\top \\varepsilon] = y + w^\\top \\mathbb{E}[\\varepsilon]$. Since the model errors are unbiased, $\\mathbb{E}[\\varepsilon] = 0$, so $\\mathbb{E}[\\widehat{y}] = y$.\nThe variance is then:\n$$\n\\mathrm{Var}(\\widehat{y}) = \\mathbb{E}[(\\widehat{y} - \\mathbb{E}[\\widehat{y}])^2] = \\mathbb{E}[(\\widehat{y} - y)^2] = \\mathbb{E}[(w^\\top \\varepsilon)^2]\n$$\nSince $w^\\top \\varepsilon$ is a scalar, its square can be written as $(w^\\top \\varepsilon)(w^\\top \\varepsilon) = (w^\\top \\varepsilon)(\\varepsilon^\\top w) = w^\\top (\\varepsilon \\varepsilon^\\top) w$.\nTaking the expectation, we get:\n$$\n\\mathrm{Var}(\\widehat{y}) = \\mathbb{E}[w^\\top \\varepsilon \\varepsilon^\\top w] = w^\\top \\mathbb{E}[\\varepsilon \\varepsilon^\\top] w\n$$\nBy definition, the error covariance matrix is $\\Sigma = \\mathbb{E}[\\varepsilon \\varepsilon^\\top]$. Therefore, the variance to be minimized is:\n$$\n\\mathrm{Var}(\\widehat{y}) = w^\\top \\Sigma w\n$$\nThe optimization problem is to minimize $f(w) = w^\\top \\Sigma w$ subject to the constraint $g(w) = w^\\top \\mathbf{1} - 1 = 0$. We use the method of Lagrange multipliers. The Lagrangian $\\mathcal{L}$ is:\n$$\n\\mathcal{L}(w, \\lambda) = w^\\top \\Sigma w - \\lambda (w^\\top \\mathbf{1} - 1)\n$$\nTo find the minimum, we set the gradient of $\\mathcal{L}$ with respect to $w$ to zero. Using the matrix derivative rule $\\frac{\\partial}{\\partial w}(w^\\top A w) = 2Aw$ for a symmetric matrix $A$, we have:\n$$\n\\nabla_w \\mathcal{L} = 2 \\Sigma w - \\lambda \\mathbf{1} = 0\n$$\n$$\n2 \\Sigma w = \\lambda \\mathbf{1}\n$$\nSince $\\Sigma$ is a positive definite covariance matrix, it is invertible. We can solve for $w$:\n$$\nw = \\frac{\\lambda}{2} \\Sigma^{-1} \\mathbf{1}\n$$\nThis equation shows that the optimal weights are proportional to the sum of the rows of the inverse covariance matrix. To find the Lagrange multiplier $\\lambda$, we apply the constraint $w^\\top \\mathbf{1} = 1$:\n$$\n\\left( \\frac{\\lambda}{2} \\Sigma^{-1} \\mathbf{1} \\right)^\\top \\mathbf{1} = 1\n$$\n$$\n\\frac{\\lambda}{2} (\\Sigma^{-1} \\mathbf{1})^\\top \\mathbf{1} = 1\n$$\n$$\n\\frac{\\lambda}{2} \\mathbf{1}^\\top (\\Sigma^{-1})^\\top \\mathbf{1} = 1\n$$\nSince $\\Sigma$ is symmetric, its inverse $\\Sigma^{-1}$ is also symmetric, so $(\\Sigma^{-1})^\\top = \\Sigma^{-1}$.\n$$\n\\frac{\\lambda}{2} (\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}) = 1\n$$\nSolving for $\\lambda$:\n$$\n\\lambda = \\frac{2}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}}\n$$\nSubstituting this back into the expression for $w$, we obtain the optimal weight vector $w^\\ast$:\n$$\nw^\\ast = \\frac{1}{2} \\left( \\frac{2}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}} \\right) \\Sigma^{-1} \\mathbf{1} = \\frac{\\Sigma^{-1} \\mathbf{1}}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}}\n$$\nThis is the general formula for the optimal weights. The numerator is the vector of row-sums of the inverse covariance matrix, and the denominator is the sum of all elements of the inverse covariance matrix, which acts as a normalization constant.\n\nNow, we apply this formula to the given covariance matrix:\n$$\n\\Sigma = \\begin{pmatrix} 4  2  1 \\\\ 2  5  2 \\\\ 1  2  3 \\end{pmatrix}\n$$\nFirst, we must compute $\\Sigma^{-1}$. The inverse is given by $\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)} \\mathrm{adj}(\\Sigma)$, where $\\mathrm{adj}(\\Sigma)$ is the adjugate matrix of $\\Sigma$.\nThe determinant of $\\Sigma$ is:\n$$\n\\det(\\Sigma) = 4(5 \\cdot 3 - 2 \\cdot 2) - 2(2 \\cdot 3 - 2 \\cdot 1) + 1(2 \\cdot 2 - 5 \\cdot 1)\n$$\n$$\n\\det(\\Sigma) = 4(15 - 4) - 2(6 - 2) + 1(4 - 5) = 4(11) - 2(4) - 1 = 44 - 8 - 1 = 35\n$$\nThe cofactor matrix $C$ is:\n$$\nC_{11} = \\begin{vmatrix} 5  2 \\\\ 2  3 \\end{vmatrix} = 11, \\quad C_{12} = -\\begin{vmatrix} 2  2 \\\\ 1  3 \\end{vmatrix} = -4, \\quad C_{13} = \\begin{vmatrix} 2  5 \\\\ 1  2 \\end{vmatrix} = -1\n$$\n$$\nC_{21} = -\\begin{vmatrix} 2  1 \\\\ 2  3 \\end{vmatrix} = -4, \\quad C_{22} = \\begin{vmatrix} 4  1 \\\\ 1  3 \\end{vmatrix} = 11, \\quad C_{23} = -\\begin{vmatrix} 4  2 \\\\ 1  2 \\end{vmatrix} = -6\n$$\n$$\nC_{31} = \\begin{vmatrix} 2  1 \\\\ 5  2 \\end{vmatrix} = -1, \\quad C_{32} = -\\begin{vmatrix} 4  1 \\\\ 2  2 \\end{vmatrix} = -6, \\quad C_{33} = \\begin{vmatrix} 4  2 \\\\ 2  5 \\end{vmatrix} = 16\n$$\nSo, the cofactor matrix is $C = \\begin{pmatrix} 11  -4  -1 \\\\ -4  11  -6 \\\\ -1  -6  16 \\end{pmatrix}$. The adjugate matrix is the transpose of $C$, but since $C$ is symmetric, $\\mathrm{adj}(\\Sigma) = C$.\nThe inverse covariance matrix is:\n$$\n\\Sigma^{-1} = \\frac{1}{35} \\begin{pmatrix} 11  -4  -1 \\\\ -4  11  -6 \\\\ -1  -6  16 \\end{pmatrix}\n$$\nNext, we compute the numerator of the weight formula, $\\Sigma^{-1} \\mathbf{1}$:\n$$\n\\Sigma^{-1} \\mathbf{1} = \\frac{1}{35} \\begin{pmatrix} 11  -4  -1 \\\\ -4  11  -6 \\\\ -1  -6  16 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{35} \\begin{pmatrix} 11-4-1 \\\\ -4+11-6 \\\\ -1-6+16 \\end{pmatrix} = \\frac{1}{35} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix}\n$$\nThe denominator is $\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}$, which is the sum of the components of the vector we just calculated:\n$$\n\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1} = \\frac{1}{35} (6 + 1 + 9) = \\frac{16}{35}\n$$\nFinally, the optimal weight vector $w^\\ast$ is:\n$$\nw^\\ast = \\frac{\\Sigma^{-1} \\mathbf{1}}{\\mathbf{1}^\\top \\Sigma^{-1} \\mathbf{1}} = \\frac{\\frac{1}{35} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix}}{\\frac{16}{35}} = \\frac{1}{16} \\begin{pmatrix} 6 \\\\ 1 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} 6/16 \\\\ 1/16 \\\\ 9/16 \\end{pmatrix} = \\begin{pmatrix} 3/8 \\\\ 1/16 \\\\ 9/16 \\end{pmatrix}\n$$\nThe optimal weights are $w_1^\\ast = \\frac{3}{8}$, $w_2^\\ast = \\frac{1}{16}$, and $w_3^\\ast = \\frac{9}{16}$.\n\nTo interpret this result, we compare the weights to the properties of the models given by $\\Sigma$. The diagonal elements of $\\Sigma$ are the variances of the individual model errors: $\\sigma_1^2 = 4$, $\\sigma_2^2 = 5$, and $\\sigma_3^2 = 3$. The off-diagonal elements are the covariances.\n\\begin{enumerate}\n    \\item The model with the lowest variance is model 3 ($\\sigma_3^2 = 3$), and it receives the highest weight ($w_3^\\ast = 9/16 = 0.5625$). This is expected, as lower-error models should be trusted more.\n    \\item The model with the highest variance is model 2 ($\\sigma_2^2 = 5$), and it receives the lowest weight ($w_2^\\ast = 1/16 = 0.0625$). This is also expected.\n    \\item The weighting is not simply proportional to the inverse variance. If errors were uncorrelated, the weights would be proportional to $1/\\sigma_i^2$, which would be $1/4:1/5:1/3$ for models $1, 2, 3$. The presence of positive covariances ($\\Sigma_{12}=2, \\Sigma_{13}=1, \\Sigma_{23}=2$) penalizes models that are redundant. Model 2, in addition to having the highest variance, is also significantly correlated with the other two models (correlation $\\rho_{23} = \\frac{2}{\\sqrt{5}\\sqrt{3}} \\approx 0.52$ and $\\rho_{12} = \\frac{2}{\\sqrt{4}\\sqrt{5}} \\approx 0.45$). This high redundancy and high error cause its weight to be suppressed dramatically.\n    \\item Model 1 has a lower variance than model 2 ($\\sigma_1^2 = 4$ vs $\\sigma_2^2 = 5$), and it receives a much higher weight ($w_1^\\ast = 3/8 = 0.375$). Its contribution is considered more valuable than that of model 2.\n\\end{enumerate}\nIn summary, the optimal weights reflect a balance between a model's individual skill (inverse variance) and the unique information it provides (low covariance with other models). Model 3 is rewarded for its low error, while model 2 is heavily penalized for its combination of high error and high correlation with the other models.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{8}  \\frac{1}{16}  \\frac{9}{16} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While a single consensus value is useful, modern forecasting demands a full quantification of uncertainty. This practice  moves from a deterministic to a probabilistic framework by introducing Ensemble Model Output Statistics (EMOS), a powerful post-processing technique. By performing a regression on the ensemble's mean and variance, EMOS calibrates the raw output to generate a full predictive probability distribution, correcting for common issues like systematic bias and under- or over-dispersion.",
            "id": "4068179",
            "problem": "Consider a multi-model ensemble forecast for near-surface air temperature at a single station and lead time where the ensemble has $N$ exchangeable members. Let the ensemble sample mean be denoted by $\\bar{y}$ and the unbiased ensemble sample variance be denoted by $s^{2}$. Ensemble Model Output Statistics (EMOS) is a widely used statistical post-processing technique that produces a parametric predictive distribution by calibrating the first two moments of the ensemble through regression on summary statistics of the ensemble. Assume the EMOS predictive distribution for temperature is Gaussian with mean and variance determined by moment calibration driven by $\\bar{y}$ and $s^{2}$ under the following scientifically grounded principles:\n- Bias correction of the ensemble mean is performed by a linear regression of the verifying observation on $\\bar{y}$, reflecting a first-order approximation to the conditional expectation.\n- Dispersion correction is performed by a linear regression of the conditional variance on $s^{2}$ to account for flow-dependent uncertainty while preventing underdispersion or overdispersion through an intercept term.\n\nStarting from these principles, derive the functional forms of the predictive mean and predictive variance in terms of parameters $a$, $b$, $c$, $d$ and the ensemble statistics $\\bar{y}$ and $s^{2}$. Then, for a specific ensemble with $\\bar{y}=12$ and $s^{2}=9$ and EMOS parameters $(a,b,c,d)=(1,0.9,2,0.5)$ estimated from a rolling training window, compute the predictive mean and predictive variance. Express the mean in degrees Celsius and the variance in degrees Celsius squared. Finally, reason about the expected sharpness of the EMOS predictive distribution relative to the raw ensemble spread using the concept of sharpness as concentration of the predictive distribution under fixed calibration, and justify your conclusion qualitatively.\n\nYour final calculated answer should report the predictive mean and predictive variance as a single row matrix. No rounding is required; report exact values.",
            "solution": "The ensemble forecast provides summary statistics $\\bar{y}$ and $s^{2}$ of $N$ exchangeable members, and we seek a calibrated probabilistic forecast. Ensemble Model Output Statistics (EMOS) constructs a predictive distribution by adjusting the ensemble’s first two moments in a way that is consistent with regression-based calibration and proper scoring principles for probabilistic forecasts, such as the Continuous Ranked Probability Score (CRPS), which is strictly proper and encourages both calibration and sharpness.\n\nWe adopt a Gaussian predictive distribution for near-surface air temperature, which is empirically reasonable due to the near-symmetric behavior of temperature at short to medium lead times. The calibration principles are:\n- The conditional mean of the verifying observation given the ensemble, $\\mathbb{E}[Y \\mid \\bar{y}, s^{2}]$, is approximated by a linear function of $\\bar{y}$. This arises as a first-order moment regression, motivated by linear unbiased estimation or the Gauss–Markov framework in the presence of additive biases. Therefore, the predictive mean is taken to be\n$$\n\\mu = a + b\\,\\bar{y},\n$$\nwhere $a$ is an intercept capturing systematic bias and $b$ is a slope capturing multiplicative bias or damping/amplification of the ensemble mean signal.\n- The conditional variance of the verifying observation given the ensemble, $\\operatorname{Var}(Y \\mid \\bar{y}, s^{2})$, is approximated by a linear function of $s^{2}$. This reflects heteroscedasticity: higher raw ensemble spread typically indicates higher forecast uncertainty, while an intercept guards against underdispersion when the raw spread is small. Therefore, the predictive variance is taken to be\n$$\n\\sigma^{2} = c + d\\,s^{2},\n$$\nwhere $c$ is a baseline variance and $d$ scales the contribution of the ensemble spread.\n\nThese affine forms are the canonical EMOS parameterization for Gaussian variables, derived from moment-based regression on ensemble summaries.\n\nWith the given ensemble statistics and EMOS parameters,\n- $\\bar{y} = 12$,\n- $s^{2} = 9$,\n- $(a,b,c,d) = (1,0.9,2,0.5)$,\n\nwe substitute into the derived expressions:\n$$\n\\mu = a + b\\,\\bar{y} = 1 + 0.9 \\times 12 = 1 + 10.8 = 11.8,\n$$\n$$\n\\sigma^{2} = c + d\\,s^{2} = 2 + 0.5 \\times 9 = 2 + 4.5 = 6.5.\n$$\n\nThus, the EMOS predictive distribution is $\\mathcal{N}(\\mu, \\sigma^{2}) = \\mathcal{N}(11.8, 6.5)$, where the mean $\\mu$ is in degrees Celsius and the variance $\\sigma^{2}$ is in degrees Celsius squared.\n\nTo discuss sharpness, we use the concept that, under fixed calibration, sharper predictive distributions concentrate probability mass more tightly around their central tendency, often quantified by reduced variance for Gaussian models. The raw ensemble’s spread proxy is $s^{2} = 9$, while the EMOS predictive variance is $\\sigma^{2} = 6.5$. Since $6.5  9$, the EMOS forecast is sharper than the raw ensemble. The presence of the intercept $c = 2$ prevents the variance from becoming too small, mitigating the risk of underdispersion that would harm calibration. The slope $d = 0.5  1$ reduces the influence of raw spread on the predictive variance, which is consistent with empirical findings that many raw ensembles are overdispersed at some leads, or that optimal CRPS-based calibration may favor a tighter distribution after accounting for biases and flow-dependent uncertainty. Consequently, we expect improved sharpness relative to the raw ensemble while retaining calibration through the baseline variance term.\n\nThe calculated predictive mean and predictive variance are therefore $\\mu = 11.8$ degrees Celsius and $\\sigma^{2} = 6.5$ degrees Celsius squared.",
            "answer": "$$\\boxed{\\begin{pmatrix}11.8  6.5\\end{pmatrix}}$$"
        },
        {
            "introduction": "Producing a probabilistic forecast is only half the battle; we must also rigorously verify its quality. A forecast is \"calibrated\" if its predicted probabilities are statistically reliable. This exercise  introduces a standard diagnostic procedure for this task, using the Probability Integral Transform (PIT) and the Kolmogorov-Smirnov goodness-of-fit test to objectively assess whether a forecast's predictive distributions are consistent with the observed outcomes.",
            "id": "4068216",
            "problem": "A weather forecasting center evaluates the calibration of a multi-model ensemble by examining the Probability Integral Transform (PIT) values derived from its predictive cumulative distribution function (CDF). Let the forecast system produce a predictive cumulative distribution function $F$ for a scalar atmospheric variable $Y$, and let $(y_{i})_{i=1}^{n}$ be $n$ verifying observations from an independent test period. The PIT values are defined by $u_{i} = F(y_{i})$ for $i=1,\\dots,n$. Under probabilistic calibration (i.e., the predictive distribution $F$ coincides with the true conditional distribution of $Y$), the PIT values $(u_{i})$ are independent and identically distributed according to the continuous uniform distribution on $[0,1]$. \n\nSuppose $n=10$ and the observed PIT values are $\\{0.05, 0.15, 0.82, 0.91, 0.50, 0.33, 0.48, 0.62, 0.77, 0.88\\}$. Using principles of goodness-of-fit from empirical process theory, construct the one-sample Kolmogorov–Smirnov statistic comparing the empirical distribution function of the PIT values to the uniform CDF on $[0,1]$ as your test statistic. Then, using the asymptotic null distribution of the Kolmogorov–Smirnov statistic, quantify the strength of evidence against the null hypothesis of uniformity and interpret what this implies for the probabilistic calibration of $F$ in this test sample.\n\nReport as your final answer the asymptotic Kolmogorov–Smirnov $p$-value associated with the observed test statistic. Express the final $p$-value as a dimensionless decimal rounded to three significant figures.",
            "solution": "The problem requires us to assess the probabilistic calibration of a weather forecasting ensemble. This is achieved by performing a goodness-of-fit test on a sample of Probability Integral Transform (PIT) values. The null hypothesis, $H_0$, is that the forecast system is perfectly calibrated, which implies that the PIT values are independent and identically distributed (i.i.d.) draws from a continuous uniform distribution on the interval $[0,1]$, denoted as $U(0,1)$. We are asked to use the one-sample Kolmogorov-Smirnov (KS) test for this purpose.\n\nThe given data consists of $n=10$ PIT values: $\\{0.05, 0.15, 0.82, 0.91, 0.50, 0.33, 0.48, 0.62, 0.77, 0.88\\}$.\n\nThe first step in calculating the KS statistic is to order the sample data from smallest to largest. Let the ordered sample be denoted by $u_{(i)}$ for $i=1, \\dots, 10$.\nThe ordered PIT values are:\n$u_{(1)} = 0.05$\n$u_{(2)} = 0.15$\n$u_{(3)} = 0.33$\n$u_{(4)} = 0.48$\n$u_{(5)} = 0.50$\n$u_{(6)} = 0.62$\n$u_{(7)} = 0.77$\n$u_{(8)} = 0.82$\n$u_{(9)} = 0.88$\n$u_{(10)} = 0.91$\n\nThe one-sample Kolmogorov-Smirnov test statistic, $D_n$, is defined as the maximum absolute difference between the empirical distribution function (EDF) of the sample, $F_n(x)$, and the hypothesized cumulative distribution function (CDF), $F(x)$. Under the null hypothesis of uniformity on $[0,1]$, the CDF is $F(x) = x$. The EDF is defined as $F_n(x) = \\frac{1}{n}\\sum_{i=1}^{n} I(u_i \\le x)$, where $I$ is the indicator function. The test statistic is:\n$$D_n = \\sup_{x \\in [0,1]} |F_n(x) - F(x)| = \\sup_{x \\in [0,1]} |F_n(x) - x|$$\n\nThe supremum is guaranteed to be found at one of the observed data points. A computationally convenient formula for $D_n$ using the ordered sample $u_{(i)}$ is:\n$$D_n = \\max \\left( \\max_{i=1,\\dots,n} \\left\\{\\frac{i}{n} - u_{(i)}\\right\\}, \\max_{i=1,\\dots,n} \\left\\{u_{(i)} - \\frac{i-1}{n}\\right\\} \\right)$$\n\nLet's calculate the two components, $D_n^+ = \\max_{i} \\{\\frac{i}{n} - u_{(i)}\\}$ and $D_n^- = \\max_{i} \\{u_{(i)} - \\frac{i-1}{n}\\}$, for our sample with $n=10$.\n\nFor $i=1$: $D_1^+ = \\frac{1}{10} - 0.05 = 0.05$; $D_1^- = 0.05 - \\frac{0}{10} = 0.05$.\nFor $i=2$: $D_2^+ = \\frac{2}{10} - 0.15 = 0.05$; $D_2^- = 0.15 - \\frac{1}{10} = 0.05$.\nFor $i=3$: $D_3^+ = \\frac{3}{10} - 0.33 = -0.03$; $D_3^- = 0.33 - \\frac{2}{10} = 0.13$.\nFor $i=4$: $D_4^+ = \\frac{4}{10} - 0.48 = -0.08$; $D_4^- = 0.48 - \\frac{3}{10} = 0.18$.\nFor $i=5$: $D_5^+ = \\frac{5}{10} - 0.50 = 0.00$; $D_5^- = 0.50 - \\frac{4}{10} = 0.10$.\nFor $i=6$: $D_6^+ = \\frac{6}{10} - 0.62 = -0.02$; $D_6^- = 0.62 - \\frac{5}{10} = 0.12$.\nFor $i=7$: $D_7^+ = \\frac{7}{10} - 0.77 = -0.07$; $D_7^- = 0.77 - \\frac{6}{10} = 0.17$.\nFor $i=8$: $D_8^+ = \\frac{8}{10} - 0.82 = -0.02$; $D_8^- = 0.82 - \\frac{7}{10} = 0.12$.\nFor $i=9$: $D_9^+ = \\frac{9}{10} - 0.88 = 0.02$; $D_9^- = 0.88 - \\frac{8}{10} = 0.08$.\nFor $i=10$: $D_{10}^+ = \\frac{10}{10} - 0.91 = 0.09$; $D_{10}^- = 0.91 - \\frac{9}{10} = 0.01$.\n\nThe maximum of the first set of differences is $D_n^+ = \\max\\{0.05, 0.05, -0.03, -0.08, 0.00, -0.02, -0.07, -0.02, 0.02, 0.09\\} = 0.09$.\nThe maximum of the second set is $D_n^- = \\max\\{0.05, 0.05, 0.13, 0.18, 0.10, 0.12, 0.17, 0.12, 0.08, 0.01\\} = 0.18$.\n\nThe Kolmogorov-Smirnov statistic for our sample is the maximum of these two values:\n$$D_{10} = \\max(D_{10}^+, D_{10}^-) = \\max(0.09, 0.18) = 0.18$$\n\nNext, we must find the $p$-value associated with this statistic using its asymptotic null distribution. The problem instructs us to use this asymptotic approximation, even though the sample size $n=10$ is small, for which the exact distribution would typically be preferred. Under $H_0$, the distribution of the scaled statistic $d = \\sqrt{n}D_n$ converges to the Kolmogorov distribution as $n \\to \\infty$. The $p$-value is the probability of observing a test statistic at least as large as the one computed.\n\nThe value of our scaled statistic is:\n$$d = \\sqrt{10} \\times D_{10} = \\sqrt{10} \\times 0.18 \\approx 3.162277 \\times 0.18 \\approx 0.56921$$\n\nThe $p$-value is given by the survival function of the Kolmogorov distribution, $P(K \\ge x)$, where $K$ is a random variable following this distribution. The survival function can be expressed as an infinite series:\n$$P(K \\ge x) = 2 \\sum_{k=1}^{\\infty} (-1)^{k-1} \\exp(-2k^2x^2)$$\nFor our calculated value $d \\approx 0.56921$, we have $d^2 = (\\sqrt{10} \\times 0.18)^2 = 10 \\times 0.18^2 = 10 \\times 0.0324 = 0.324$.\nSubstituting $x^2 = 0.324$ into the series for the $p$-value:\n$$p\\text{-value} = 2 \\sum_{k=1}^{\\infty} (-1)^{k-1} \\exp(-2k^2 \\times 0.324)$$\n$$p\\text{-value} = 2 \\left( \\exp(-2 \\times 1^2 \\times 0.324) - \\exp(-2 \\times 2^2 \\times 0.324) + \\exp(-2 \\times 3^2 \\times 0.324) - \\dots \\right)$$\n$$p\\text{-value} = 2 \\left( \\exp(-0.648) - \\exp(-2.592) + \\exp(-5.832) - \\dots \\right)$$\n\nThe series converges rapidly. We calculate the first few terms:\n$\\exp(-0.648) \\approx 0.523079$\n$\\exp(-2.592) \\approx 0.074874$\n$\\exp(-5.832) \\approx 0.002932$\nThe fourth term, with $\\exp(-2 \\times 4^2 \\times 0.324) = \\exp(-10.368)$, is approximately $3.15 \\times 10^{-5}$ and can be neglected for the required precision.\n\nSumming the terms inside the parentheses:\n$0.523079 - 0.074874 + 0.002932 \\approx 0.451137$\nMultiplying by $2$:\n$$p\\text{-value} \\approx 2 \\times 0.451137 = 0.902274$$\n\nThis $p$-value represents the probability of observing a deviation from uniformity at least as large as $D_{10} = 0.18$ in a sample of size $10$, assuming the null hypothesis of uniformity is true. A high $p$-value (conventionally, greater than a significance level like $0.05$ or $0.10$) indicates that the observed data is consistent with the null hypothesis.\n\nOur calculated $p$-value of approximately $0.902$ is very large. This means we fail to reject the null hypothesis. There is no statistically significant evidence from this test to conclude that the forecast system's predictive CDF is miscalibrated. The distribution of the observed PIT values is not distinguishably different from a uniform distribution.\n\nThe final answer is the asymptotic $p$-value, rounded to three significant figures.\n$0.902274 \\dots \\to 0.902$.",
            "answer": "$$\\boxed{0.902}$$"
        }
    ]
}