{
    "hands_on_practices": [
        {
            "introduction": "在不确定性量化中，一个最基础的问题是模型输出对参数变化的敏感程度。本练习通过一个简化的诊断函数，带你实践如何计算局部敏感度，即模型输出关于其参数的梯度。通过这个练习，你将学会如何解释这些敏感度的物理单位及其在参数缩放和模式调优中的实际意义 。",
            "id": "4107171",
            "problem": "一个数值天气预报 (NWP) 模型中的对流参数化方案正在被调整，其使用的是一个简化的、局域无量纲的诊断成本函数 $y(\\theta_{1},\\theta_{2})$，该函数汇总了归一化的平均对流降水偏差和羽流能量学失配。设诊断函数为 $y=\\theta_{1}^{2}+\\theta_{2}$，其中 $(\\theta_{1},\\theta_{2})$ 是无量纲控制参数，通过已知尺度 $(s_{1},s_{2})$ 对物理参数 $(p_{1},p_{2})$ 进行无量纲化得到，即 $\\theta_{i}=p_{i}/s_{i}$，其中 $i\\in\\{1,2\\}$。假设 $y$ 是无量纲且可微的，并且小的扰动通过一阶泰勒线性化来解释，这与不确定性量化和扰动参数集合中的局域方法一致。\n\n从偏导数的基本定义和一阶泰勒线性化出发，计算在 $\\theta=(1,2)$ 处的局域敏感性向量 $\\nabla_{\\theta}y$，并以行向量形式表示。然后，使用链式法则，讨论关于有量纲参数 $(p_{1},p_{2})$ 的敏感性如何依赖于 $(s_{1},s_{2})$，并解释这些有量纲敏感性的单位以及参数缩放对对流方案调整的影响。您必须给出关于 $(\\theta_{1},\\theta_{2})$ 在 $\\theta=(1,2)$ 处求值的局域敏感性向量的数值；无需四舍五入。请使用行矩阵表示您的最终敏感性向量答案。",
            "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，问题设定良好且客观。它在参数敏感性分析的背景下提出了一个清晰、可解的问题，这是数值建模和不确定性量化的一个基本课题。所有必要的定义和数据都已提供，没有内部矛盾或含糊之处。\n\n该问题要求计算一个局域敏感性向量，并随后讨论相关的变量变换。我们从第一部分开始。\n\n诊断成本函数给定为 $y(\\theta_{1}, \\theta_{2}) = \\theta_{1}^{2} + \\theta_{2}$，其中 $\\theta_{1}$ 和 $\\theta_{2}$ 是无量纲控制参数。成本函数 $y$ 对这些参数的局域敏感性由 $y$ 的梯度来量化，记为 $\\nabla_{\\theta}y$。梯度是一个向量，其分量是函数对其每个变量的偏导数。对于一个二元标量函数，它定义为：\n$$\n\\nabla_{\\theta}y = \\begin{pmatrix} \\frac{\\partial y}{\\partial \\theta_{1}} & \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\n问题要求将其表示为行向量，这是标量场梯度的常见表示法。\n\n首先，我们计算 $y$ 对 $\\theta_{1}$ 和 $\\theta_{2}$ 的偏导数：\n关于 $\\theta_{1}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial \\theta_{1}} = \\frac{\\partial}{\\partial \\theta_{1}} (\\theta_{1}^{2} + \\theta_{2}) = 2\\theta_{1}\n$$\n关于 $\\theta_{2}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial \\theta_{2}} = \\frac{\\partial}{\\partial \\theta_{2}} (\\theta_{1}^{2} + \\theta_{2}) = 1\n$$\n因此，作为 $\\theta = (\\theta_{1}, \\theta_{2})$ 的函数的敏感性向量是：\n$$\n\\nabla_{\\theta}y(\\theta_{1}, \\theta_{2}) = \\begin{pmatrix} 2\\theta_{1} & 1 \\end{pmatrix}\n$$\n问题要求在特定点 $\\theta = (1, 2)$ 对此向量求值。我们将 $\\theta_{1} = 1$ 和 $\\theta_{2} = 2$ 代入梯度表达式中：\n$$\n\\nabla_{\\theta}y(1, 2) = \\begin{pmatrix} 2(1) & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\end{pmatrix}\n$$\n这个数值向量表示在指定点，成本函数对无量纲参数扰动的局域敏感性。在此点，$\\theta_{1}$ 的变化对 $y$ 的影响是相同大小的 $\\theta_{2}$ 变化的两倍。这个向量是 $y$ 变化的一阶泰勒线性化，即对于小的扰动 $(\\delta\\theta_{1}, \\delta\\theta_{2})$，$y$ 的变化近似为 $\\delta y \\approx 2\\delta\\theta_{1} + 1\\delta\\theta_{2}$。\n\n接下来，我们处理问题的第二部分：关于无量纲参数 $(\\theta_{1}, \\theta_{2})$ 的敏感性与关于有量纲物理参数 $(p_{1}, p_{2})$ 的敏感性之间的关系。这些参数通过缩放关系 $\\theta_{i} = p_{i}/s_{i}$（$i \\in \\{1, 2\\}$）相关联，其中 $(s_1, s_2)$ 是已知的常数缩放因子。\n\n为了找到 $y$ 对 $(p_{1}, p_{2})$ 的敏感性，我们必须应用多元函数的链式法则。函数 $y$ 是一个复合函数，$y(p_{1}, p_{2}) = y(\\theta_{1}(p_{1}), \\theta_{2}(p_{2}))$。$y$ 对 $p_{1}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{1}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{1}}\n$$\n类似地，$y$ 对 $p_{2}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{2}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{2}}\n$$\n我们计算缩放关系的导数：\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{1}} = \\frac{\\partial}{\\partial p_{1}}\\left(\\frac{p_{1}}{s_{1}}\\right) = \\frac{1}{s_{1}}\n$$\n$$\n\\frac{\\partial \\theta_{2}}{\\partial p_{2}} = \\frac{\\partial}{\\partial p_{2}}\\left(\\frac{p_{2}}{s_{2}}\\right) = \\frac{1}{s_{2}}\n$$\n由于 $\\theta_{1}$ 与 $p_{2}$ 无关，$\\theta_{2}$ 与 $p_{1}$ 无关，我们有：\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{2}} = 0 \\quad \\text{and} \\quad \\frac{\\partial \\theta_{2}}{\\partial p_{1}} = 0\n$$\n将这些代入链式法则的表达式中，得到：\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\left(\\frac{1}{s_{1}}\\right) + \\frac{\\partial y}{\\partial \\theta_{2}} (0) = \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}}\n$$\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} (0) + \\frac{\\partial y}{\\partial \\theta_{2}} \\left(\\frac{1}{s_{2}}\\right) = \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}}\n$$\n因此，关于有量纲参数的敏感性向量 $\\nabla_{p}y$ 是：\n$$\n\\nabla_{p}y = \\begin{pmatrix} \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}} & \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\n\n我们现在解释这个结果的单位和含义。\n令一个量 $q$ 的物理单位表示为 $[q]$。问题陈述 $y$、$\\theta_{1}$ 和 $\\theta_{2}$ 是无量纲的。这意味着 $[y] = 1$ 和 $[\\theta_i] = 1$。因此，敏感性 $\\frac{\\partial y}{\\partial \\theta_i}$ 也是无量纲的，因为 $[\\frac{\\partial y}{\\partial \\theta_i}] = \\frac{[y]}{[\\theta_i]} = \\frac{1}{1} = 1$。\n物理参数 $p_i$ 具有量纲 $[p_i]$。为了使 $\\theta_i = p_i/s_i$ 无量纲，缩放因子 $s_i$ 必须具有与相应物理参数相同的单位，即 $[s_i] = [p_i]$。\n那么，有量纲敏感性 $\\frac{\\partial y}{\\partial p_i}$ 的单位是：\n$$\n\\left[\\frac{\\partial y}{\\partial p_i}\\right] = \\frac{[y]}{[p_i]} = \\frac{1}{[p_i]} = [p_i]^{-1}\n$$\n例如，如果 $p_{1}$ 代表一个对流夹带率，其单位为逆长度 ($m^{-1}$)，那么敏感性 $\\frac{\\partial y}{\\partial p_1}$ 的单位将是长度 ($m$)。这表示夹带率每单位变化所引起的无量纲成本函数的变化。\n\n这对对流方案中的参数调整具有重要意义。关系式 $\\frac{\\partial y}{\\partial p_i} = \\frac{1}{s_i} \\frac{\\partial y}{\\partial \\theta_i}$ 表明，模型的成本函数对有量纲物理参数 $p_i$ 的敏感性与其特征缩放因子 $s_i$ 成反比。\n如果选择一个大的缩放因子 $s_i$，这意味着需要物理参数 $p_i$ 有一个大的绝对变化才能在无量纲参数 $\\theta_i$ 中产生单位变化。因此，大的 $s_i$ 会使成本函数 $y$ 对 $p_i$ 不那么敏感。这会使得参数难以“调整”或约束，因为即使对其值进行大幅调整，也可能只导致由 $y$ 衡量的模型性能发生微小变化。\n相反，如果 $s_i$ 很小，成本函数将对 $p_i$ 高度敏感。对 $p_i$ 的微小调整会被放大，导致 $\\theta_i$ 进而 $y$ 发生大的变化。在调整过程中必须非常小心地处理这类参数，因为其设定上的微小误差可能导致模型性能的大幅下降。\n缩放因子 $(s_1, s_2)$ 的选择是参数估计和不确定性量化中的关键步骤。这些尺度通常是基于物理推理来选择的，以代表参数的特征大小或变化范围。理想情况下，选择它们是为了使无量纲敏感性 $\\frac{\\partial y}{\\partial \\theta_i}$ 具有相似的数量级（例如，一阶数量级），这可以导向一个条件更好的优化问题。这种无量纲化和缩放过程对于理解和比较像对流参数化这样的复杂模型中不同物理过程的相对重要性至关重要。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "超越局部敏感度分析，贝叶斯方法为我们提供了一个在存在不确定性的情况下从数据中学习的完整框架。本练习将引导你应用贝叶斯定理，将关于模型参数的先验知识与一个观测数据相结合，从而推导出更新后的后验分布。你将亲手计算后验均值和方差，并从“精度加权平均”的角度理解为何后验估计会被“收缩”至先验均值，以及不确定性如何通过数据融合得以降低 。",
            "id": "4107138",
            "problem": "考虑在数值天气预报（NWP）和气候模拟中，使用扰动参数集合（PPE；perturbed parameter ensemble）对一个标量不确定参数 $\\theta$ 进行简化校准。假设 $\\theta$ 代表一个次网格过程系数，其在集合中的先验不确定性由高斯先验 $\\theta \\sim \\mathcal{N}(0, 1)$ 描述。您从一次模型-数据比较中获得单个诊断观测值 $y$，其似然为 $y \\mid \\theta \\sim \\mathcal{N}(\\theta, 1)$，反映了方差为 $1$ 的可加观测误差和表示误差。您观测到 $y = 2$。\n\n从贝叶斯定理和高斯密度的定义出发，通过显式地组合先验和似然，并在指数项中进行配方，以闭合形式推导出后验分布 $p(\\theta \\mid y)$。然后，确定后验均值和后验方差，并在此 PPE 背景下，用精度加权平均来解释后验均值相对于观测值 $y$ 是如何收缩的，以及后验方差相对于先验方差为何会减小。\n\n请将后验均值和后验方差的最终数值答案以一个包含两个条目的行矩阵形式给出，按顺序分别为后验均值和后验方差。无需四舍五入。",
            "solution": "该问题要求在给定先验分布和来自似然模型的单个观测值 $y$ 的情况下，推导不确定参数 $\\theta$ 的后验分布。这是贝叶斯定理在共轭先验背景下的一个标准应用。\n\n已知条件如下：\n- $\\theta$ 的先验分布：$\\theta \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$，其中先验均值 $\\mu_p = 0$，先验方差 $\\sigma_p^2 = 1$。\n- 观测值 $y$ 的似然模型：$y \\mid \\theta \\sim \\mathcal{N}(\\theta, \\sigma_l^2)$，其中似然方差 $\\sigma_l^2 = 1$。\n- 具体观测值：$y = 2$。\n\n根据贝叶斯定理，后验概率分布 $p(\\theta \\mid y)$ 正比于似然 $p(y \\mid \\theta)$ 和先验 $p(\\theta)$ 的乘积：\n$$\np(\\theta \\mid y) \\propto p(y \\mid \\theta) \\, p(\\theta)\n$$\n高斯先验的概率密度函数 (PDF) 为：\n$$\np(\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma_p^2}} \\exp\\left( -\\frac{(\\theta - \\mu_p)^2}{2\\sigma_p^2} \\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{\\theta^2}{2} \\right)\n$$\n高斯似然的概率密度函数 (PDF) 为：\n$$\np(y \\mid \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma_l^2}} \\exp\\left( -\\frac{(y - \\theta)^2}{2\\sigma_l^2} \\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(y - \\theta)^2}{2} \\right)\n$$\n将先验与似然相乘，由于我们处理的是比例关系，可以忽略归一化常数 $(2\\pi)^{-1/2}$：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{\\theta^2}{2} \\right) \\exp\\left( -\\frac{(y - \\theta)^2}{2} \\right)\n$$\n我们可以合并指数部分：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\theta^2 + (y - \\theta)^2 \\right] \\right)\n$$\n为了确定后验分布的形式，我们需要分析指数中的表达式。这涉及到展开各项并对 $\\theta$ 进行配方。方括号内的项是：\n$$\n\\theta^2 + (y - \\theta)^2 = \\theta^2 + (y^2 - 2y\\theta + \\theta^2) = 2\\theta^2 - 2y\\theta + y^2\n$$\n现在，我们对涉及 $\\theta$ 的项进行配方：\n$$\n2\\theta^2 - 2y\\theta + y^2 = 2\\left(\\theta^2 - y\\theta\\right) + y^2\n$$\n为了对 $\\theta^2 - y\\theta$ 配方，我们加上并减去 $(y/2)^2$：\n$$\n2\\left( \\left[\\theta^2 - y\\theta + \\left(\\frac{y}{2}\\right)^2\\right] - \\left(\\frac{y}{2}\\right)^2 \\right) + y^2 = 2\\left( \\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{4} \\right) + y^2\n$$\n$$\n= 2\\left(\\theta - \\frac{y}{2}\\right)^2 - 2\\frac{y^2}{4} + y^2 = 2\\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{2} + y^2 = 2\\left(\\theta - \\frac{y}{2}\\right)^2 + \\frac{y^2}{2}\n$$\n将此代回后验 PDF 的表达式中：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ 2\\left(\\theta - \\frac{y}{2}\\right)^2 + \\frac{y^2}{2} \\right] \\right)\n$$\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{4} \\right) = \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 \\right) \\exp\\left( -\\frac{y^2}{4} \\right)\n$$\n由于 $\\exp(-y^2/4)$ 项不依赖于 $\\theta$，因此它是一个关于 $\\theta$ 的常数，可以被吸收到比例常数中。因此，我们有：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 \\right)\n$$\n为了将其与高斯 PDF 的标准形式 $p(x) \\propto \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)$ 匹配，我们重写指数部分：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{\\left(\\theta - \\frac{y}{2}\\right)^2}{2\\left(\\frac{1}{2}\\right)} \\right)\n$$\n这是 $\\theta$ 的高斯分布的核。通过观察，我们可以确定后验均值和方差。后验分布为 $\\theta \\mid y \\sim \\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$，其中：\n- 后验均值：$\\mu_{\\text{post}} = \\frac{y}{2}$\n- 后验方差：$\\sigma_{\\text{post}}^2 = \\frac{1}{2}$\n\n对于给定的观测值 $y=2$，后验均值为：\n$$\n\\mu_{\\text{post}} = \\frac{2}{2} = 1\n$$\n后验方差为 $\\sigma_{\\text{post}}^2 = \\frac{1}{2}$。\n\n用精度加权平均对结果的解释：\n精度定义为方差的倒数，即 $\\tau = 1/\\sigma^2$。它代表了估计的确定性。\n- 先验精度为 $\\tau_p = 1/\\sigma_p^2 = 1/1 = 1$。\n- 数据（似然）精度为 $\\tau_l = 1/\\sigma_l^2 = 1/1 = 1$。\n\n对于高斯-高斯模型，后验均值是先验均值和观测值的精度加权平均：\n$$\n\\mu_{\\text{post}} = \\frac{\\tau_p \\mu_p + \\tau_l y}{\\tau_p + \\tau_l} = \\frac{(1)(0) + (1)(y)}{1 + 1} = \\frac{y}{2}\n$$\n这表明后验均值是先验信念（$\\mu_p=0$）和来自数据的信息（$y$）之间的一种折衷。当 $y=2$ 时，后验均值为 $1$。这个值从观测值 $y=2$ 向先验均值 $\\mu_p=0$“收缩”。由于先验和数据具有相同的精度，后验均值恰好位于它们之间的中点。这种收缩是贝叶斯更新的一个典型特征，它通过将估计值拉向先验信念来对其进行正则化。\n\n后验精度是先验精度和数据精度之和：\n$$\n\\tau_{\\text{post}} = \\tau_p + \\tau_l = 1 + 1 = 2\n$$\n后验方差是后验精度的倒数：\n$$\n\\sigma_{\\text{post}}^2 = \\frac{1}{\\tau_{\\text{post}}} = \\frac{1}{2}\n$$\n后验方差（$\\sigma_{\\text{post}}^2 = 1/2$）小于先验方差（$\\sigma_p^2 = 1$）和似然方差（$\\sigma_l^2 = 1$）。这反映了一个事实：通过结合两个信息源（先验和数据），我们减少了关于参数 $\\theta$ 的不确定性。我们的后验知识比我们最初的信念或仅来自单个观测值的信息更精确。在扰动参数集合（PPE）的背景下，这个过程展示了观测如何约束初始参数集合，从而得到一个更小、更精炼的集合，并因此减少了参数不确定性。\n\n后验均值和后验方差的最终数值答案分别为 $1$ 和 $\\frac{1}{2}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1 & \\frac{1}{2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "在实践中，我们常常需要在计算成本和分析精度之间做出权衡，并选择合适的敏感度分析方法。本练习旨在让你深入理解不同方法之间的差异，通过一个包含参数交互项的模型，精确推导简单的“一次一变”（OAT）方法相对于更全面的“扰动参数集合”（PPE）方法所产生的偏差。这个推导将揭示忽略参数相关性和模型非线性的后果，从而强调了在复杂系统中采用先进 UQ 方法的必要性 。",
            "id": "4107110",
            "problem": "在数值天气预报 (NWP) 和气候模拟中，一种常见的不确定性量化方法是扰动参数集合 (PPE)，其中模型参数被视为随机变量。另一种方法是一次一变 (OAT) 确定性扰动策略，其中每个参数围绕一个基线值进行单独扰动，而其他参数保持不变，所得的局部敏感性被用来近似输出方差。考虑一个简化的PPE，用于气候诊断量 $Y$，其对两个不确定参数 $(\\theta_1,\\theta_2)$ 的依赖关系由一个双线性响应近似：\n$$\nY \\;=\\; f(\\theta_1,\\theta_2) \\;=\\; \\alpha_1 \\,\\theta_1 \\;+\\; \\alpha_2 \\,\\theta_2 \\;+\\; \\beta \\,\\theta_1 \\theta_2,\n$$\n其中 $\\alpha_1$、$\\alpha_2$ 和 $\\beta$ 是由模型的物理过程和数值方法决定的常数。假设 $(\\theta_1,\\theta_2)$ 服从联合高斯分布，其均值为 $(\\mu_1,\\mu_2)$，方差为 $(\\sigma_1^2,\\sigma_2^2)$，相关系数为 $\\rho$。\n\n在OAT确定性扰动设计中，局部线性敏感性在基线 $(\\mu_1,\\mu_2)$ 处进行评估，得到：\n$$\nc_1 \\;=\\; \\left.\\frac{\\partial f}{\\partial \\theta_1}\\right|_{(\\mu_1,\\mu_2)} \\;=\\; \\alpha_1 + \\beta \\mu_2,\n\\qquad\nc_2 \\;=\\; \\left.\\frac{\\partial f}{\\partial \\theta_2}\\right|_{(\\mu_1,\\mu_2)} \\;=\\; \\alpha_2 + \\beta \\mu_1.\n$$\n一个标准的基于OAT的方差估计量会忽略协方差项和曲率项，并使用：\n$$\n\\widehat{\\mathrm{Var}}_{\\mathrm{OAT}} \\;=\\; c_1^2 \\,\\sigma_1^2 \\;+\\; c_2^2 \\,\\sigma_2^2.\n$$\n\n使用随机变量变换的第一性原理和多元正态分布的性质，推导在联合随机扰动集合下精确的输出方差 $\\mathrm{Var}(Y)$，然后计算偏差\n$$\n\\mathrm{Bias} \\;=\\; \\mathrm{Var}(Y) \\;-\\; \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}.\n$$\n将您的最终答案表示为关于 $\\alpha_1$、$\\alpha_2$、$\\beta$、$\\mu_1$、$\\mu_2$、$\\sigma_1$、$\\sigma_2$ 和 $\\rho$ 的单个闭式解析表达式。无需四舍五入。最终表达式中无需报告物理单位。",
            "solution": "问题要求计算一次一变 (OAT) 方差估计量相对于模型输出 $Y$ 的精确方差的偏差。该模型是两个联合高斯随机参数 $\\theta_1$ 和 $\\theta_2$ 的双线性函数。偏差定义为 $\\mathrm{Bias} = \\mathrm{Var}(Y) - \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}$。\n\n首先，我们推导输出的精确方差 $\\mathrm{Var}(Y)$。输出 $Y$ 由下式给出：\n$$\nY = f(\\theta_1, \\theta_2) = \\alpha_1 \\theta_1 + \\alpha_2 \\theta_2 + \\beta \\theta_1 \\theta_2\n$$\n参数 $(\\theta_1, \\theta_2)$ 服从二元正态分布，其均值为 $E[\\theta_1] = \\mu_1$，$E[\\theta_2]=\\mu_2$，方差为 $\\mathrm{Var}(\\theta_1) = \\sigma_1^2$，$\\mathrm{Var}(\\theta_2) = \\sigma_2^2$，相关系数为 $\\mathrm{Corr}(\\theta_1, \\theta_2) = \\rho$。协方差为 $\\mathrm{Cov}(\\theta_1, \\theta_2) = \\rho\\sigma_1\\sigma_2$。\n\n随机变量 $Y$ 的方差由 $\\mathrm{Var}(Y) = E[(Y - E[Y])^2]$ 给出。我们首先计算 $Y$ 的期望值 $E[Y]$。利用期望的线性性质：\n$$\nE[Y] = E[\\alpha_1 \\theta_1 + \\alpha_2 \\theta_2 + \\beta \\theta_1 \\theta_2] = \\alpha_1 E[\\theta_1] + \\alpha_2 E[\\theta_2] + \\beta E[\\theta_1 \\theta_2]\n$$\n项 $E[\\theta_1 \\theta_2]$ 与协方差有关：$\\mathrm{Cov}(\\theta_1, \\theta_2) = E[\\theta_1 \\theta_2] - E[\\theta_1]E[\\theta_2]$。\n因此，$E[\\theta_1 \\theta_2] = \\mathrm{Cov}(\\theta_1, \\theta_2) + E[\\theta_1]E[\\theta_2] = \\rho\\sigma_1\\sigma_2 + \\mu_1\\mu_2$。\n将此代入 $E[Y]$ 的表达式中得到：\n$$\nE[Y] = \\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta(\\mu_1 \\mu_2 + \\rho\\sigma_1\\sigma_2)\n$$\n接下来，我们表示中心化变量 $Y - E[Y]$。我们定义中心化随机变量 $\\delta\\theta_1 = \\theta_1 - \\mu_1$ 和 $\\delta\\theta_2 = \\theta_2 - \\mu_2$。它们的均值为零，$E[\\delta\\theta_1] = E[\\delta\\theta_2] = 0$。它们的二阶矩为：$E[\\delta\\theta_1^2] = \\sigma_1^2$，$E[\\delta\\theta_2^2] = \\sigma_2^2$ 以及 $E[\\delta\\theta_1 \\delta\\theta_2] = \\mathrm{Cov}(\\theta_1, \\theta_2) = \\rho\\sigma_1\\sigma_2$。\n\n我们用这些中心化变量重写 $Y$：\n$$\nY = \\alpha_1(\\mu_1 + \\delta\\theta_1) + \\alpha_2(\\mu_2 + \\delta\\theta_2) + \\beta(\\mu_1 + \\delta\\theta_1)(\\mu_2 + \\delta\\theta_2)\n$$\n$$\nY = \\alpha_1\\mu_1 + \\alpha_1\\delta\\theta_1 + \\alpha_2\\mu_2 + \\alpha_2\\delta\\theta_2 + \\beta(\\mu_1\\mu_2 + \\mu_1\\delta\\theta_2 + \\mu_2\\delta\\theta_1 + \\delta\\theta_1\\delta\\theta_2)\n$$\n减去 $E[Y]$：\n$$\nY - E[Y] = (\\alpha_1\\mu_1 + \\alpha_2\\mu_2 + \\beta\\mu_1\\mu_2) + (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta\\delta\\theta_1\\delta\\theta_2 - E[Y]\n$$\n代入 $E[Y]$ 的表达式给出：\n$$\nY - E[Y] = (\\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta\\mu_1 \\mu_2) + (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta\\delta\\theta_1\\delta\\theta_2 - (\\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta\\mu_1 \\mu_2 + \\beta\\rho\\sigma_1\\sigma_2)\n$$\n$$\nY - E[Y] = (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)\n$$\n使用给定的OAT敏感性定义，$c_1 = \\alpha_1 + \\beta\\mu_2$ 和 $c_2 = \\alpha_2 + \\beta\\mu_1$，我们有：\n$$\nY - E[Y] = c_1\\delta\\theta_1 + c_2\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - E[\\delta\\theta_1\\delta\\theta_2])\n$$\n现在我们计算方差 $\\mathrm{Var}(Y) = E[(Y - E[Y])^2]$：\n$$\n\\mathrm{Var}(Y) = E \\left[ \\left( c_1\\delta\\theta_1 + c_2\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) \\right)^2 \\right]\n$$\n展开平方项：\n$$\n\\mathrm{Var}(Y) = E \\left[ c_1^2\\delta\\theta_1^2 + c_2^2\\delta\\theta_2^2 + \\beta^2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)^2 + 2c_1c_2\\delta\\theta_1\\delta\\theta_2 + 2c_1\\beta\\delta\\theta_1(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) + 2c_2\\beta\\delta\\theta_2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) \\right]\n$$\n根据期望的线性性质，我们可以评估每一项：\n1.  $E[c_1^2\\delta\\theta_1^2] = c_1^2 E[\\delta\\theta_1^2] = c_1^2\\sigma_1^2$。\n2.  $E[c_2^2\\delta\\theta_2^2] = c_2^2 E[\\delta\\theta_2^2] = c_2^2\\sigma_2^2$。\n3.  $E[2c_1c_2\\delta\\theta_1\\delta\\theta_2] = 2c_1c_2 E[\\delta\\theta_1\\delta\\theta_2] = 2c_1c_2\\rho\\sigma_1\\sigma_2$。\n4.  $E[2c_1\\beta\\delta\\theta_1(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)] = 2c_1\\beta(E[\\delta\\theta_1^2\\delta\\theta_2] - \\rho\\sigma_1\\sigma_2 E[\\delta\\theta_1])$。由于 $\\delta\\theta_1$ 和 $\\delta\\theta_2$ 是联合高斯且中心化的，任何奇数阶矩都为零。因此，$E[\\delta\\theta_1]=0$ 且 $E[\\delta\\theta_1^2\\delta\\theta_2]=0$。此项为零。\n5.  类似地，$E[2c_2\\beta\\delta\\theta_2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)] = 2c_2\\beta(E[\\delta\\theta_1\\delta\\theta_2^2] - \\rho\\sigma_1\\sigma_2 E[\\delta\\theta_2]) = 0$。\n6.  最后一项是 $E[\\beta^2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)^2] = \\beta^2 E[(\\delta\\theta_1\\delta\\theta_2 - E[\\delta\\theta_1\\delta\\theta_2])^2] = \\beta^2\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2)$。对于中心化的二元正态变量，其乘积的方差为 $\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2) = (1+\\rho^2)\\sigma_1^2\\sigma_2^2$。这个结果源于 Isserlis 定理，该定理给出 $E[\\delta\\theta_1^2\\delta\\theta_2^2] = E[\\delta\\theta_1^2]E[\\delta\\theta_2^2] + 2(E[\\delta\\theta_1\\delta\\theta_2])^2 = \\sigma_1^2\\sigma_2^2 + 2(\\rho\\sigma_1\\sigma_2)^2 = (1+2\\rho^2)\\sigma_1^2\\sigma_2^2$。那么 $\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2) = E[\\delta\\theta_1^2\\delta\\theta_2^2] - (E[\\delta\\theta_1\\delta\\theta_2])^2 = (1+2\\rho^2)\\sigma_1^2\\sigma_2^2 - (\\rho\\sigma_1\\sigma_2)^2 = (1+\\rho^2)\\sigma_1^2\\sigma_2^2$。因此，此项等于 $\\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2$。\n\n将非零项相加，精确方差为：\n$$\n\\mathrm{Var}(Y) = c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2 + 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n问题将基于OAT的方差估计量指定为：\n$$\n\\widehat{\\mathrm{Var}}_{\\mathrm{OAT}} = c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2\n$$\n偏差是精确方差与估计方差之间的差值：\n$$\n\\mathrm{Bias} = \\mathrm{Var}(Y) - \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}\n$$\n$$\n\\mathrm{Bias} = (c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2 + 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2) - (c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2)\n$$\n$$\n\\mathrm{Bias} = 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n最后，我们将 $c_1$ 和 $c_2$ 的表达式代回，用基本模型参数来表示偏差：\n$$\nc_1 = \\alpha_1 + \\beta\\mu_2\n$$\n$$\nc_2 = \\alpha_2 + \\beta\\mu_1\n$$\n$$\n\\mathrm{Bias} = 2(\\alpha_1 + \\beta\\mu_2)(\\alpha_2 + \\beta\\mu_1)\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n该表达式代表了OAT估计量中两个误差来源：第一项源于忽略了参数效应之间的协方差（当 $\\rho \\neq 0$ 时非零），第二项源于忽略了模型的非线性或曲率（当 $\\beta \\neq 0$ 时非零）。",
            "answer": "$$\n\\boxed{2(\\alpha_1 + \\beta\\mu_2)(\\alpha_2 + \\beta\\mu_1)\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2}\n$$"
        }
    ]
}