{
    "hands_on_practices": [
        {
            "introduction": "The first step in understanding a model's behavior is to assess its local sensitivity: how the output responds to small parameter changes around a baseline value. This exercise builds this foundational skill by asking you to compute the gradient of a simple diagnostic function, which represents the local sensitivity to dimensionless parameters. By then using the chain rule to relate these sensitivities back to their physical, dimensional counterparts, this practice  reveals the critical role that parameter scaling plays in the tuning and analysis of complex schemes in climate and weather models.",
            "id": "4107171",
            "problem": "A convection parameterization in a numerical weather prediction (NWP) model is tuned using a simplified, locally nondimensional diagnostic cost function $y(\\theta_{1},\\theta_{2})$ that aggregates the normalized mean convective precipitation bias and plume energetics mismatch. Let the diagnostic be $y=\\theta_{1}^{2}+\\theta_{2}$, where $(\\theta_{1},\\theta_{2})$ are dimensionless control parameters obtained by nondimensionalizing physical parameters $(p_{1},p_{2})$ via known scales $(s_{1},s_{2})$ as $\\theta_{i}=p_{i}/s_{i}$ for $i\\in\\{1,2\\}$. Assume that $y$ is dimensionless and differentiable, and that small perturbations are interpreted through first-order Taylor linearization consistent with the local approach in uncertainty quantification and perturbed parameter ensembles.\n\nStarting from the fundamental definition of a partial derivative and the first-order Taylor linearization, compute the local sensitivity vector $\\nabla_{\\theta}y$ at $\\theta=(1,2)$, expressed as a row vector. Then, using the chain rule, discuss how the sensitivity with respect to the dimensional parameters $(p_{1},p_{2})$ depends on $(s_{1},s_{2})$, and interpret the units of these dimensional sensitivities as well as the implications of parameter scaling for tuning in a convection scheme. You must give the numerical values for the local sensitivity vector with respect to $(\\theta_{1},\\theta_{2})$ evaluated at $\\theta=(1,2)$; no rounding is required. Express your final sensitivity vector answer using a row matrix.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, and objective. It presents a clear, solvable problem in the context of parameter sensitivity analysis, a fundamental topic in numerical modeling and uncertainty quantification. All necessary definitions and data are provided, and there are no internal contradictions or ambiguities.\n\nThe problem requires the calculation of a local sensitivity vector and a subsequent discussion on a related transformation of variables. We begin with the first part.\n\nThe diagnostic cost function is given as $y(\\theta_{1}, \\theta_{2}) = \\theta_{1}^{2} + \\theta_{2}$, where $\\theta_{1}$ and $\\theta_{2}$ are dimensionless control parameters. The local sensitivity of the cost function $y$ with respect to these parameters is quantified by the gradient of $y$, denoted as $\\nabla_{\\theta}y$. The gradient is a vector whose components are the partial derivatives of the function with respect to each of its variables. For a scalar function of two variables, it is defined as:\n$$\n\\nabla_{\\theta}y = \\begin{pmatrix} \\frac{\\partial y}{\\partial \\theta_{1}} & \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\nThe problem asks for this as a row vector, which is a common convention for the gradient of a scalar field.\n\nFirst, we compute the partial derivatives of $y$ with respect to $\\theta_{1}$ and $\\theta_{2}$:\nThe partial derivative with respect to $\\theta_{1}$ is:\n$$\n\\frac{\\partial y}{\\partial \\theta_{1}} = \\frac{\\partial}{\\partial \\theta_{1}} (\\theta_{1}^{2} + \\theta_{2}) = 2\\theta_{1}\n$$\nThe partial derivative with respect to $\\theta_{2}$ is:\n$$\n\\frac{\\partial y}{\\partial \\theta_{2}} = \\frac{\\partial}{\\partial \\theta_{2}} (\\theta_{1}^{2} + \\theta_{2}) = 1\n$$\nThus, the sensitivity vector as a function of $\\theta = (\\theta_{1}, \\theta_{2})$ is:\n$$\n\\nabla_{\\theta}y(\\theta_{1}, \\theta_{2}) = \\begin{pmatrix} 2\\theta_{1} & 1 \\end{pmatrix}\n$$\nThe problem requires this vector to be evaluated at the specific point $\\theta = (1, 2)$. We substitute $\\theta_{1} = 1$ and $\\theta_{2} = 2$ into the expression for the gradient:\n$$\n\\nabla_{\\theta}y(1, 2) = \\begin{pmatrix} 2(1) & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\end{pmatrix}\n$$\nThis numerical vector represents the local sensitivity of the cost function to perturbations in the dimensionless parameters at the specified point. A change in $\\theta_{1}$ has twice the effect on $y$ as the same magnitude of change in $\\theta_{2}$ at this point. This vector is the first-order Taylor linearization of the change in $y$, i.e., for small perturbations $(\\delta\\theta_{1}, \\delta\\theta_{2})$, the change in $y$ is approximately $\\delta y \\approx 2\\delta\\theta_{1} + 1\\delta\\theta_{2}$.\n\nNext, we address the second part of the problem: the relationship between sensitivities with respect to the dimensionless parameters $(\\theta_{1}, \\theta_{2})$ and the dimensional physical parameters $(p_{1}, p_{2})$. The parameters are related by the scaling relations $\\theta_{i} = p_{i}/s_{i}$ for $i \\in \\{1, 2\\}$, where $(s_1, s_2)$ are known constant scaling factors.\n\nTo find the sensitivity of $y$ with respect to $(p_{1}, p_{2})$, we must apply the chain rule for multivariable functions. The function $y$ is a composition, $y(p_{1}, p_{2}) = y(\\theta_{1}(p_{1}), \\theta_{2}(p_{2}))$. The partial derivative of $y$ with respect to $p_{1}$ is:\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{1}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{1}}\n$$\nSimilarly, the partial derivative of $y$ with respect to $p_{2}$ is:\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{2}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{2}}\n$$\nWe compute the derivatives of the scaling relations:\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{1}} = \\frac{\\partial}{\\partial p_{1}}\\left(\\frac{p_{1}}{s_{1}}\\right) = \\frac{1}{s_{1}}\n$$\n$$\n\\frac{\\partial \\theta_{2}}{\\partial p_{2}} = \\frac{\\partial}{\\partial p_{2}}\\left(\\frac{p_{2}}{s_{2}}\\right) = \\frac{1}{s_{2}}\n$$\nSince $\\theta_{1}$ is independent of $p_{2}$ and $\\theta_{2}$ is independent of $p_{1}$, we have:\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{2}} = 0 \\quad \\text{and} \\quad \\frac{\\partial \\theta_{2}}{\\partial p_{1}} = 0\n$$\nSubstituting these into the chain rule expressions yields:\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\left(\\frac{1}{s_{1}}\\right) + \\frac{\\partial y}{\\partial \\theta_{2}} (0) = \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}}\n$$\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} (0) + \\frac{\\partial y}{\\partial \\theta_{2}} \\left(\\frac{1}{s_{2}}\\right) = \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}}\n$$\nThe sensitivity vector with respect to the dimensional parameters, $\\nabla_{p}y$, is therefore:\n$$\n\\nabla_{p}y = \\begin{pmatrix} \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}} & \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\n\nWe now interpret the units and implications of this result.\nLet the physical units of a quantity $q$ be denoted by $[q]$. The problem states that $y$, $\\theta_{1}$, and $\\theta_{2}$ are dimensionless. This implies $[y] = 1$ and $[\\theta_i] = 1$. The sensitivities $\\frac{\\partial y}{\\partial \\theta_i}$ are therefore also dimensionless, as $[\\frac{\\partial y}{\\partial \\theta_i}] = \\frac{[y]}{[\\theta_i]} = \\frac{1}{1} = 1$.\nThe physical parameters $p_i$ have dimensions, $[p_i]$. For $\\theta_i = p_i/s_i$ to be dimensionless, the scaling factor $s_i$ must have the same units as the corresponding physical parameter, i.e., $[s_i] = [p_i]$.\nThe units of the dimensional sensitivities $\\frac{\\partial y}{\\partial p_i}$ are then:\n$$\n\\left[\\frac{\\partial y}{\\partial p_i}\\right] = \\frac{[y]}{[p_i]} = \\frac{1}{[p_i]} = [p_i]^{-1}\n$$\nFor instance, if $p_{1}$ represents a convective entrainment rate with units of inverse length ($m^{-1}$), then the sensitivity $\\frac{\\partial y}{\\partial p_1}$ would have units of length ($m$). This signifies the change in the dimensionless cost function per unit change in the entrainment rate.\n\nThe implications for parameter tuning in a convection scheme are significant. The relationship $\\frac{\\partial y}{\\partial p_i} = \\frac{1}{s_i} \\frac{\\partial y}{\\partial \\theta_i}$ shows that the sensitivity of the model's cost function to a dimensional physical parameter $p_i$ is inversely proportional to its characteristic scaling factor $s_i$.\nIf a scaling factor $s_i$ is chosen to be large, it implies that a large absolute change in the physical parameter $p_i$ is required to produce a unit change in the dimensionless parameter $\\theta_i$. Consequently, a large $s_i$ makes the cost function $y$ less sensitive to $p_i$. This can make the parameter difficult to \"tune\" or constrain, as even substantial adjustments to its value may result in only minor changes to the model's performance as measured by $y$.\nConversely, if $s_i$ is small, the cost function becomes highly sensitive to $p_i$. Small adjustments to $p_i$ are magnified, leading to large changes in $\\theta_i$ and hence $y$. Such parameters must be handled with great care during tuning, as minor errors in their specification can lead to large degradations in model performance.\nThe choice of scaling factors $(s_1, s_2)$ is a critical step in parameter estimation and uncertainty quantification. These scales are typically chosen based on physical reasoning to represent a characteristic magnitude or range of variation for the parameters. Ideally, they are chosen such that the dimensionless sensitivities $\\frac{\\partial y}{\\partial \\theta_i}$ are of a similar order of magnitude (e.g., of order one), which can lead to a better-conditioned optimization problem. This process of nondimensionalization and scaling is fundamental to understanding and comparing the relative importance of different physical processes within a complex model like a convection parameterization.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "To analyze uncertainty globally, we must sample the parameter space efficiently, which is the purpose of a perturbed parameter ensemble (PPE). This hands-on exercise  walks you through the practical mechanics of creating a Latin Hypercube Sample (LHS), a cornerstone technique for generating space-filling designs. You will follow a concrete algorithm to stratify parameter ranges, generate samples in a normalized space, and map them to their physical values, providing direct experience in constructing the input for a comprehensive global sensitivity or uncertainty propagation study.",
            "id": "4107183",
            "problem": "A perturbed-parameter ensemble for a convection and microphysics scheme is to be constructed using Latin Hypercube Sampling (LHS). Latin Hypercube Sampling (LHS) is defined by stratifying the unit interval $[0,1]$ into $N$ equal-probability strata for each dimension and selecting exactly one sample from each stratum in every dimension, with the cross-dimensional pairing determined by independent permutations so that the resulting joint design has uniform one-dimensional marginals.\n\nConsider a two-parameter design with $N=4$ strata in $[0,1]^2$. The first dimension represents the entrainment rate parameter $\\epsilon$ for a mass-flux convection scheme, which is taken to lie in the physically plausible range $[\\epsilon_{\\min},\\epsilon_{\\max}]=[0.1,1.0]$ in $\\text{km}^{-1}$. The second dimension represents the autoconversion threshold for warm-rain microphysics $q_{\\text{crit}}$, taken to lie in the physically plausible range $[q_{\\min},q_{\\max}]=[5\\times 10^{-4},\\,2\\times 10^{-3}]$ in $\\text{kg}/\\text{kg}$. Use the following construction rules:\n\n- Partition each unit interval into four equal strata $S_i=\\left(\\frac{i-1}{4},\\frac{i}{4}\\right]$ for $i\\in\\{1,2,3,4\\}$ and choose the midpoint of each stratum, i.e., $\\mu_i=\\frac{i-\\frac{1}{2}}{4}$, as the within-stratum representative.\n- Define the permutation for the first dimension (entrainment rate) as $\\pi_{\\epsilon}=(3,1,4,2)$ and for the second dimension (autoconversion threshold) as $\\pi_{q}=(2,4,1,3)$. The $i$th sample’s coordinates in $[0,1]^2$ are $(u_{\\epsilon,i},u_{q,i})=\\left(\\mu_{\\pi_{\\epsilon}(i)},\\,\\mu_{\\pi_{q}(i)}\\right)$ for $i=1,2,3,4$.\n- Map the standardized samples $(u_{\\epsilon,i},u_{q,i})\\in[0,1]^2$ to physical ranges via the linear maps $\\epsilon_i=\\epsilon_{\\min}+u_{\\epsilon,i}\\left(\\epsilon_{\\max}-\\epsilon_{\\min}\\right)$ and $q_{\\text{crit},i}=q_{\\min}+u_{q,i}\\left(q_{\\max}-q_{\\min}\\right)$.\n\nReport the flattened vector of the four mapped pairs in the order $\\left(\\epsilon_1,\\,q_{\\text{crit},1},\\,\\epsilon_2,\\,q_{\\text{crit},2},\\,\\epsilon_3,\\,q_{\\text{crit},3},\\,\\epsilon_4,\\,q_{\\text{crit},4}\\right)$. Round each reported value to four significant figures. Express $\\epsilon$ in $\\text{km}^{-1}$ and $q_{\\text{crit}}$ in $\\text{kg}/\\text{kg}$.",
            "solution": "The problem is first validated against the established criteria.\n\n**Step 1: Extract Givens**\n- **Method**: Latin Hypercube Sampling (LHS).\n- **Dimensions**: $2$.\n- **Number of samples/strata**: $N=4$.\n- **Parameter 1**: Entrainment rate, $\\epsilon$. Range $[\\epsilon_{\\min},\\epsilon_{\\max}]=[0.1,1.0]$ $\\text{km}^{-1}$.\n- **Parameter 2**: Autoconversion threshold, $q_{\\text{crit}}$. Range $[q_{\\min},q_{\\max}]=[5\\times 10^{-4}, 2\\times 10^{-3}]$ $\\text{kg}/\\text{kg}$.\n- **Stratification**: The unit interval is partitioned into four strata $S_i=\\left(\\frac{i-1}{4},\\frac{i}{4}\\right]$ for $i\\in\\{1,2,3,4\\}$.\n- **Representative point**: The midpoint of each stratum, $\\mu_i=\\frac{i-\\frac{1}{2}}{4}$.\n- **Permutations**: $\\pi_{\\epsilon}=(3,1,4,2)$ for the first dimension, and $\\pi_{q}=(2,4,1,3)$ for the second.\n- **Sample Generation**: The $i$-th standardized sample is $(u_{\\epsilon,i},u_{q,i})=\\left(\\mu_{\\pi_{\\epsilon}(i)},\\,\\mu_{\\pi_{q}(i)}\\right)$ for $i=1,2,3,4$.\n- **Mapping to Physical Space**:\n  - $\\epsilon_i=\\epsilon_{\\min}+u_{\\epsilon,i}\\left(\\epsilon_{\\max}-\\epsilon_{\\min}\\right)$\n  - $q_{\\text{crit},i}=q_{\\min}+u_{q,i}\\left(q_{\\max}-q_{\\min}\\right)$\n- **Output**: Flattened vector $\\left(\\epsilon_1,\\,q_{\\text{crit},1},\\,\\epsilon_2,\\,q_{\\text{crit},2},\\,\\epsilon_3,\\,q_{\\text{crit},3},\\,\\epsilon_4,\\,q_{\\text{crit},4}\\right)$, with each value rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It utilizes standard methods (LHS) and established concepts from atmospheric science (entrainment, autoconversion). The parameter ranges are specified as physically plausible. All necessary data, formulae, and constraints are provided, leading to a unique and verifiable solution. There are no contradictions, ambiguities, or factual errors.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A detailed solution will be provided.\n\n**Solution Derivation**\n\nThe solution is derived in three main steps:\n1.  Calculate the representative midpoint for each of the $N=4$ strata in the unit interval.\n2.  Generate the four standardized sample pairs $(u_{\\epsilon,i}, u_{q,i})$ using the given permutations.\n3.  Map these standardized samples to their physical parameter values $(\\epsilon_i, q_{\\text{crit},i})$ and round as required.\n\n**Step 1: Calculate Stratum Midpoints**\nThe representative point for each stratum $S_i$ is its midpoint, given by the formula $\\mu_i=\\frac{i-\\frac{1}{2}}{4}$ for $i \\in \\{1,2,3,4\\}$.\n- For $i=1$: $\\mu_1 = \\frac{1-0.5}{4} = \\frac{0.5}{4} = 0.125$\n- For $i=2$: $\\mu_2 = \\frac{2-0.5}{4} = \\frac{1.5}{4} = 0.375$\n- For $i=3$: $\\mu_3 = \\frac{3-0.5}{4} = \\frac{2.5}{4} = 0.625$\n- For $i=4$: $\\mu_4 = \\frac{4-0.5}{4} = \\frac{3.5}{4} = 0.875$\n\n**Step 2: Generate Standardized Sample Pairs**\nThe standardized coordinates for the $i$-th sample are given by $(u_{\\epsilon,i},u_{q,i})=\\left(\\mu_{\\pi_{\\epsilon}(i)},\\,\\mu_{\\pi_{q}(i)}\\right)$, with permutations $\\pi_{\\epsilon}=(3,1,4,2)$ and $\\pi_{q}=(2,4,1,3)$.\n\n- For sample $i=1$:\n  - $u_{\\epsilon,1} = \\mu_{\\pi_{\\epsilon}(1)} = \\mu_3 = 0.625$\n  - $u_{q,1} = \\mu_{\\pi_{q}(1)} = \\mu_2 = 0.375$\n  - The pair is $(0.625, 0.375)$.\n\n- For sample $i=2$:\n  - $u_{\\epsilon,2} = \\mu_{\\pi_{\\epsilon}(2)} = \\mu_1 = 0.125$\n  - $u_{q,2} = \\mu_{\\pi_{q}(2)} = \\mu_4 = 0.875$\n  - The pair is $(0.125, 0.875)$.\n\n- For sample $i=3$:\n  - $u_{\\epsilon,3} = \\mu_{\\pi_{\\epsilon}(3)} = \\mu_4 = 0.875$\n  - $u_{q,3} = \\mu_{\\pi_{q}(3)} = \\mu_1 = 0.125$\n  - The pair is $(0.875, 0.125)$.\n\n- For sample $i=4$:\n  - $u_{\\epsilon,4} = \\mu_{\\pi_{\\epsilon}(4)} = \\mu_2 = 0.375$\n  - $u_{q,4} = \\mu_{\\pi_{q}(4)} = \\mu_3 = 0.625$\n  - The pair is $(0.375, 0.625)$.\n\n**Step 3: Map to Physical Parameter Values**\nThe standardized values are mapped to the physical ranges using the provided linear transformation.\n\nFor the entrainment rate $\\epsilon$:\nThe range is $[\\epsilon_{\\min}, \\epsilon_{\\max}] = [0.1, 1.0]$, so the range width is $\\epsilon_{\\max}-\\epsilon_{\\min} = 1.0 - 0.1 = 0.9$. The mapping is $\\epsilon_i = 0.1 + u_{\\epsilon,i} \\times 0.9$.\n- $\\epsilon_1 = 0.1 + 0.625 \\times 0.9 = 0.1 + 0.5625 = 0.6625$. Rounded to $4$ s.f., this is $0.6625$.\n- $\\epsilon_2 = 0.1 + 0.125 \\times 0.9 = 0.1 + 0.1125 = 0.2125$. Rounded to $4$ s.f., this is $0.2125$.\n- $\\epsilon_3 = 0.1 + 0.875 \\times 0.9 = 0.1 + 0.7875 = 0.8875$. Rounded to $4$ s.f., this is $0.8875$.\n- $\\epsilon_4 = 0.1 + 0.375 \\times 0.9 = 0.1 + 0.3375 = 0.4375$. Rounded to $4$ s.f., this is $0.4375$.\n\nFor the autoconversion threshold $q_{\\text{crit}}$:\nThe range is $[q_{\\min}, q_{\\max}] = [5 \\times 10^{-4}, 2 \\times 10^{-3}] = [0.0005, 0.002]$. The range width is $q_{\\max}-q_{\\min} = 0.002 - 0.0005 = 0.0015$. The mapping is $q_{\\text{crit},i} = 0.0005 + u_{q,i} \\times 0.0015$.\n- $q_{\\text{crit},1} = 0.0005 + 0.375 \\times 0.0015 = 0.0005 + 0.0005625 = 0.0010625$. Rounded to $4$ s.f., this is $0.001063$.\n- $q_{\\text{crit},2} = 0.0005 + 0.875 \\times 0.0015 = 0.0005 + 0.0013125 = 0.0018125$. Rounded to $4$ s.f., this is $0.001813$.\n- $q_{\\text{crit},3} = 0.0005 + 0.125 \\times 0.0015 = 0.0005 + 0.0001875 = 0.0006875$. This value has exactly $4$ significant figures ($6, 8, 7, 5$), so it remains $0.0006875$.\n- $q_{\\text{crit},4} = 0.0005 + 0.625 \\times 0.0015 = 0.0005 + 0.0009375 = 0.0014375$. Rounded to $4$ s.f., this is $0.001438$.\n\n**Final Result Assembly**\nThe final flattened vector is $\\left(\\epsilon_1,\\,q_{\\text{crit},1},\\,\\epsilon_2,\\,q_{\\text{crit},2},\\,\\epsilon_3,\\,q_{\\text{crit},3},\\,\\epsilon_4,\\,q_{\\text{crit},4}\\right)$.\nSubstituting the rounded values:\n$\\left(0.6625, \\, 0.001063, \\, 0.2125, \\, 0.001813, \\, 0.8875, \\, 0.0006875, \\, 0.4375, \\, 0.001438\\right)$.\nThis vector is presented as a row matrix in the final answer.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6625 & 0.001063 & 0.2125 & 0.001813 & 0.8875 & 0.0006875 & 0.4375 & 0.001438\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "After designing an ensemble, the next task is to use it to determine which parameters have the greatest impact on model output. This practice  takes you from theory to a full computational implementation of the Morris method, an efficient and widely used global sensitivity screening technique. By coding the algorithm to generate randomized trajectories and calculate elementary effects for a simplified convection scheme, you will learn how to sift through a multi-parameter space to identify the most influential drivers of model behavior, a crucial step for focusing UQ and model calibration efforts.",
            "id": "4107140",
            "problem": "You are given a simplified single-column convection scheme with three tunable parameters and tasked to perform a global sensitivity screening using the Elementary Effects method, also known as the Morris method. The context is uncertainty quantification and perturbed parameter ensembles in numerical weather prediction and climate modeling, and the design must be compatible with algorithmic implementation in any modern programming language.\n\nThe convection scheme maps three parameters to a physically plausible convective precipitation rate. Let the three parameters be the entrainment rate $e$ in $\\,\\mathrm{s^{-1}}$, the autoconversion threshold $q_c$ in $\\,\\mathrm{kg\\,kg^{-1}}$, and the closure time scale $\\tau$ in $\\,\\mathrm{s}$. For fixed environmental constants $q_{\\mathrm{env}}$ in $\\,\\mathrm{kg\\,kg^{-1}}$, $t_0$ in $\\,\\mathrm{s}$, $\\alpha$ in $\\,\\mathrm{s}$, $\\beta$ in $\\,\\mathrm{mm\\,hr^{-1}}$, and exponent $\\gamma$ (dimensionless), the scheme’s precipitation rate $R$ in $\\,\\mathrm{mm\\,hr^{-1}}$ is defined by the composition\n$R(e,q_c,\\tau) = \\beta \\left(\\max\\left(q_{\\mathrm{env}}\\exp(-\\alpha e) - q_c, 0\\right)\\right)^{\\gamma}\\left(1 - \\exp\\left(-\\dfrac{t_0}{\\tau}\\right)\\right)$,\nwhere $q_{\\mathrm{env}} = 0.016$, $t_0 = 1800$, $\\alpha = 500$, $\\beta = 1200$, and $\\gamma = 1.2$. The rain rate $R$ must be computed in $\\,\\mathrm{mm\\,hr^{-1}}$. All constants are scientifically plausible for a simplified bulk parameterization and are fixed across all test cases in this problem.\n\nYou must implement the Elementary Effects method in its randomized One-At-a-Time (OAT) trajectory form, starting from the basic definition of finite differences and sensitivity, on a discrete grid in the unit hypercube. The three-dimensional parameter vector is scaled to the unit hypercube using an affine transformation from the given physical bounds. Let the number of levels be $p$ (an integer with $p \\ge 4$) and let the step in the scaled space be a rational increment $\\delta \\in (0,1)$. For each trajectory, construct a sequence of $d+1$ points in the unit hypercube, where $d=3$ is the dimension, by starting from a random grid-aligned base point and applying $d$ single-parameter moves of size $\\delta$ in a random order such that the path remains within the unit hypercube. Map each point to the physical parameter space via linear scaling using the specified bounds, evaluate the model output at each point, and compute $d$ elementary effects via OAT finite differences divided by the step $\\delta$ in the scaled space. Across $r$ trajectories, form the distribution of elementary effects for each parameter.\n\nTo summarize the distribution for screening, aggregate the set of elementary effects for each parameter by computing the mean of the absolute values and the standard deviation. Identify influential parameters for each test case as those whose mean-of-absolute elementary effects is greater than or equal to the median of the three means for that test case. The output for each test case should be the list of zero-based indices of the influential parameters, where index $0$ corresponds to $e$, index $1$ corresponds to $q_c$, and index $2$ corresponds to $\\tau$.\n\nYou must ensure the randomized design is reproducible by using a fixed pseudorandom seed per test case. The program must be self-contained and produce exactly one line of output in the specified format, containing the results for all test cases.\n\nImplement the procedure for the following test suite, which probes different parameter-space regimes and numerical setups:\n- Test case $1$ (general case, broad ranges): bounds $e \\in [1\\times 10^{-4},\\,5\\times 10^{-3}]$, $q_c \\in [5\\times 10^{-4},\\,2\\times 10^{-3}]$, $\\tau \\in [600,\\,3600]$ with $p=8$, $r=20$, and seed $1$.\n- Test case $2$ (boundary case, narrow entrainment): bounds $e \\in [1\\times 10^{-4},\\,3\\times 10^{-4}]$, $q_c \\in [3\\times 10^{-4},\\,3\\times 10^{-3}]$, $\\tau \\in [600,\\,3600]$ with $p=8$, $r=20$, and seed $2$.\n- Test case $3$ (edge case, narrow closure time scale, broader threshold): bounds $e \\in [5\\times 10^{-4},\\,3\\times 10^{-3}]$, $q_c \\in [1\\times 10^{-3},\\,9\\times 10^{-3}]$, $\\tau \\in [1500,\\,1800]$ with $p=6$, $r=12$, and seed $3$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated list of zero-based integers for the influential parameter indices corresponding to the test cases, in the order listed above. For example, the printed line should look like $[ [i_{1,1},i_{1,2}], [i_{2,1},i_{2,2},i_{2,3}], [i_{3,1}] ]$ but with no spaces. Concretely, your program must print exactly one line of the form $[[\\ldots],[\\ldots],[\\ldots]]$ with no spaces anywhere.",
            "solution": "The objective is to conduct a global sensitivity analysis for a simplified atmospheric convection scheme using the Elementary Effects (Morris) method. This method allows for a qualitative screening of the model's parameters to identify those with the most significant influence on the output. The analysis will be performed on three parameters of the convection model for three distinct test cases.\n\nThe convection scheme provides a precipitation rate, $R$, in units of $\\,\\mathrm{mm\\,hr^{-1}}$, as a function of three tunable parameters: the entrainment rate $e$ (in $\\,\\mathrm{s^{-1}}$), the autoconversion threshold $q_c$ (in $\\,\\mathrm{kg\\,kg^{-1}}$), and the closure time scale $\\tau$ (in $\\,\\mathrm{s}$). The model equation is given by:\n$$\nR(e,q_c,\\tau) = \\beta \\left(\\max\\left(q_{\\mathrm{env}}\\exp(-\\alpha e) - q_c, 0\\right)\\right)^{\\gamma}\\left(1 - \\exp\\left(-\\dfrac{t_0}{\\tau}\\right)\\right)\n$$\nThe constants in the model are fixed at scientifically plausible values: $q_{\\mathrm{env}} = 0.016\\,\\mathrm{kg\\,kg^{-1}}$, $t_0 = 1800\\,\\mathrm{s}$, $\\alpha = 500\\,\\mathrm{s}$, $\\beta = 1200\\,\\mathrm{mm\\,hr^{-1}}$, and the exponent $\\gamma = 1.2$ (dimensionless).\n\nThe sensitivity analysis is performed using the randomized One-At-a-Time (OAT) trajectory design of the Elementary Effects method. The methodology involves the following steps:\n\n1.  **Parameter Space Normalization**: The physical parameter space, defined by the lower and upper bounds $[L_i, U_i]$ for each parameter $i$, is affinely scaled to the $d$-dimensional unit hypercube $[0, 1]^d$, where $d=3$ is the number of parameters. A scaled parameter $x_i \\in [0, 1]$ is mapped to its physical value $P_i$ using the transformation:\n    $$\n    P_i = L_i + x_i (U_i - L_i)\n    $$\n\n2.  **Grid Discretization**: The normalized space $[0, 1]^d$ is discretized into a grid. Each axis is divided into $p$ levels, creating a set of grid points $\\{0, \\frac{1}{p-1}, \\frac{2}{p-1}, \\ldots, 1\\}$. The step size for the OAT design is a rational increment $\\delta$. Following standard practice for the Morris method, we define $\\delta = \\frac{p}{2(p-1)}$, which satisfies the problem's constraint $\\delta \\in (0,1)$ and ensures that adding a step of size $\\delta$ to a grid point does not necessarily land on another grid point, promoting better space exploration.\n\n3.  **Trajectory Generation**: The analysis uses $r$ random trajectories, each consisting of $d+1=4$ points in the scaled space. For each trajectory, a reproducible random sequence is ensured by initializing a pseudorandom number generator with a fixed seed specific to each test case.\n    - A base point $x^* \\in [0, 1]^d$ is randomly selected. To ensure the entire trajectory path remains within the unit hypercube, each component $x^*_i$ is chosen randomly from the set of admissible grid levels $\\{0, \\frac{1}{p-1}, \\ldots, 1-\\delta\\}$.\n    - A random permutation of the parameter indices $\\{0, 1, \\ldots, d-1\\}$ is generated. This defines the order in which parameters are perturbed.\n    - A trajectory of $d+1$ points $(x^{(0)}, x^{(1)}, \\ldots, x^{(d)})$ is constructed, starting with $x^{(0)} = x^*$. Subsequent points are generated by sequentially perturbing one parameter at a time by the step $\\delta$. If the permutation of indices is $(\\pi_1, \\pi_2, \\ldots, \\pi_d)$, then the points are:\n    $$\n    x^{(j)} = x^{(j-1)} + \\delta \\cdot \\mathbf{e}_{\\pi_j} \\quad \\text{for } j=1, \\ldots, d\n    $$\n    where $\\mathbf{e}_{\\pi_j}$ is the unit vector along the $\\pi_j$-th axis.\n\n4.  **Elementary Effect Calculation**: For each trajectory, the model output $R$ is evaluated at the physical parameters corresponding to each of the $d+1$ points. The elementary effect ($EE$) for the parameter perturbed at step $j$ (parameter $\\pi_j$) is the finite difference of the model outputs, normalized by the step size $\\delta$:\n    $$\n    EE_{\\pi_j} = \\frac{R(\\text{physical}(x^{(j)})) - R(\\text{physical}(x^{(j-1)}))}{\\delta}\n    $$\n    This yields one elementary effect for each of the $d$ parameters per trajectory.\n\n5.  **Sensitivity Metrics and Screening**: After computing the elementary effects for all $r$ trajectories, the results are aggregated for each parameter $i \\in \\{0, 1, 2\\}$.\n    - The primary sensitivity measure, $\\mu_i^*$, is the mean of the absolute values of the $r$ elementary effects computed for parameter $i$:\n    $$\n    \\mu_i^* = \\frac{1}{r} \\sum_{k=1}^{r} |EE_{i,k}|\n    $$\n    - The standard deviation of the elementary effects, $\\sigma_i$, is also computed to assess non-linear effects or interactions, although it is not used in the final screening criterion for this problem.\n    - A parameter is classified as \"influential\" if its sensitivity measure $\\mu_i^*$ is greater than or equal to the median of the set of all computed means, $\\{\\mu_0^*, \\mu_1^*, \\mu_2^*\\}$.\n\nThis procedure is applied to each of the three test cases specified, using their respective parameter bounds, grid levels ($p$), number of trajectories ($r$), and random seeds. The final output for each case is the list of zero-based indices of the influential parameters.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Elementary Effects (Morris) method for global sensitivity analysis\n    on a simplified convection scheme, as per the problem description.\n    \"\"\"\n\n    # Define the environmental constants for the model.\n    q_env = 0.016\n    t0 = 1800.0\n    alpha = 500.0\n    beta = 1200.0\n    gamma = 1.2\n    \n    # Define the convection model function.\n    def convection_model(params):\n        \"\"\"\n        Computes the precipitation rate R from physical parameters.\n        params: A list or tuple (e, qc, tau).\n        \"\"\"\n        e, qc, tau = params\n        \n        # Protective check for tau > 0 to avoid division by zero.\n        if tau = 0:\n            return 0.0\n\n        q_available = q_env * np.exp(-alpha * e)\n        term1 = np.maximum(q_available - qc, 0)\n        term2 = 1.0 - np.exp(-t0 / tau)\n        \n        R = beta * (term1 ** gamma) * term2\n        return R\n\n    # Define the affine scaling function from unit hypercube to physical space.\n    def scale_to_physical(x_scaled, bounds):\n        \"\"\"\n        Maps a point from the unit hypercube to the physical parameter space.\n        x_scaled: A numpy array of scaled parameters in [0, 1].\n        bounds: A list of (min, max) tuples for each parameter.\n        \"\"\"\n        physical_params = np.zeros_like(x_scaled)\n        for i in range(len(x_scaled)):\n            L_i, U_i = bounds[i]\n            physical_params[i] = L_i + x_scaled[i] * (U_i - L_i)\n        return physical_params\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"bounds\": [(1e-4, 5e-3), (5e-4, 2e-3), (600.0, 3600.0)],\n            \"p\": 8, \"r\": 20, \"seed\": 1\n        },\n        {\n            \"bounds\": [(1e-4, 3e-4), (3e-4, 3e-3), (600.0, 3600.0)],\n            \"p\": 8, \"r\": 20, \"seed\": 2\n        },\n        {\n            \"bounds\": [(5e-4, 3e-3), (1e-3, 9e-3), (1500.0, 1800.0)],\n            \"p\": 6, \"r\": 12, \"seed\": 3\n        }\n    ]\n\n    overall_results = []\n\n    for case in test_cases:\n        bounds, p, r, seed = case[\"bounds\"], case[\"p\"], case[\"r\"], case[\"seed\"]\n        \n        # Set the seed for reproducibility for the current test case.\n        np.random.seed(seed)\n        \n        d = len(bounds)  # Number of parameters\n        delta = p / (2.0 * (p - 1))\n        \n        # Define the grid levels from which base point components are chosen.\n        # The range ensures that a step of size delta remains within [0, 1].\n        grid_step = 1.0 / (p - 1)\n        valid_start_levels = np.arange(0, 1.0 - delta + 1e-9, grid_step)\n\n        # Store elementary effects for each parameter.\n        elementary_effects = {i: [] for i in range(d)}\n\n        for _ in range(r):\n            # 1. Generate a random base point x_star on the grid.\n            x_star = np.array([np.random.choice(valid_start_levels) for _ in range(d)])\n            \n            # 2. Generate a random permutation of parameter indices.\n            perm_indices = np.random.permutation(d)\n            \n            # 3. Construct the trajectory and compute elementary effects.\n            x_current = x_star.copy()\n            y_current = convection_model(scale_to_physical(x_current, bounds))\n            \n            for i in range(d):\n                idx_to_perturb = perm_indices[i]\n                \n                x_next = x_current.copy()\n                x_next[idx_to_perturb] += delta\n                \n                y_next = convection_model(scale_to_physical(x_next, bounds))\n                \n                ee = (y_next - y_current) / delta\n                elementary_effects[idx_to_perturb].append(ee)\n                \n                # Move to the next point in the trajectory.\n                x_current = x_next\n                y_current = y_next\n\n        # 4. Aggregate results to compute mu_star for each parameter.\n        mu_stars = np.zeros(d)\n        for i in range(d):\n            ees_i = np.array(elementary_effects[i])\n            mu_stars[i] = np.mean(np.abs(ees_i))\n        \n        # 5. Identify influential parameters.\n        median_mu_star = np.median(mu_stars)\n        influential_indices = np.where(mu_stars >= median_mu_star)[0].tolist()\n        influential_indices.sort() # Sort for consistent output order.\n        \n        overall_results.append(influential_indices)\n\n    # Final print statement in the exact required format.\n    result_str = \",\".join([f\"[{','.join(map(str, res))}]\" for res in overall_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}