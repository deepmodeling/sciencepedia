## 引言
在现代科学预测领域，尤其是在[数值天气预报](@entry_id:191656)和气候建模中，从“明天是否会下雨？”到“本世纪末全球气温将上升多少？”，我们越来越多地依赖概率来量化未来的不确定性。与给出一个单一数值的确定性预报不同，[概率预报](@entry_id:183505)提供了一个关于所有可能结果的完整分布。然而，如何客观、公正地评估这些[概率预报](@entry_id:183505)的“好”与“坏”？如果一个预报系统声称某事件有70%的概率发生，我们如何验证这一声明的质量，并激励预报者提供其最“诚实”的判断？这正是概率评分规则（Probability Scoring Rules）所要解决的核心问题。

本文旨在为读者提供一个关于概率评分规则的全面而深入的指南。我们将从基本原理出发，逐步深入到实际应用和前沿交叉领域。在“原理与机制”一章中，我们将揭示确保预报诚实性的“固有性”原则，并详细剖析[布莱尔分数](@entry_id:897139)、对数分数和连续分级概率评分（CRPS）等核心工具的内在机制，同时学习如何将预报质量分解为可靠性、分辨力和锐度等多个关键维度。接下来，在“应用与跨学科联系”一章中，我们将跨出理论的范畴，探索这些评分规则在天气预报、气候科学、决策支持、医学AI和机器学习等领域的实际应用，展示它们如何连接预测与行动。最后，“动手实践”部分将提供精选的练习，帮助您将理论知识转化为解决实际问题的能力。

让我们首先进入第一章，深入探索概率评分规则背后的核心原理与精妙机制。

## 原理与机制

在数值天气预报和[气候模型评估](@entry_id:1122469)中，验证概率预报的质量是至关重要的一环。与确定性预报（例如，预测明日最高气温为 $25.1^\circ\text{C}$）不同，[概率预报](@entry_id:183505)提供的是一个关于未来结果可能性的完整分布（例如，明日最高气温有 $0.7$ 的概率超过 $25^\circ\text{C}$）。为了客观地评估这类预报的优劣，我们需要一套严谨的数学工具，这便是**评分规则 (Scoring Rules)** 的用武之地。本章将深入探讨概率评分规则的核心原理与机制，阐明其如何激励预报者提供诚实的预测，并揭示评估预报质量的多个维度。

### 诚实性的基石：固有性评分规则

一个理想的评估体系应当鼓励预报者尽其所能，报告其内心最真实的预测分布。如果一个评分系统使得预报者可以通过策略性地“修饰”或“[对冲](@entry_id:635975)”其预报来获得更高的期望得分，那么这个系统就是有缺陷的。决策理论为我们提供了确保诚实性的关键概念：**固有性 (Propriety)**。

一个评分规则 $S(P, y)$ 是一个函数，它根据预报者发布的预测分布 $P$ 和随后观测到的真实结果 $y$ 来给出一个数值分数。一个理性的预报者会试图选择一个报告的分布 $P$，以期在自己所相信的真实数据生成分布 $Q$ 下，最大化其期望得分。这个期望得分可以表示为 $J(Q, P) = \mathbb{E}_{Y \sim Q}[S(P, Y)]$，其中期望是针对所有可能的结果 $Y$ 基于分布 $Q$ 计算的。

- **固有评分规则 (Proper Scoring Rule)** 规定，当预报者报告其真实 belief $Q$ 时（即 $P=Q$），其期望得分达到最大值。形式化地：$\mathbb{E}_{Y \sim Q}[S(Q, Y)] \ge \mathbb{E}_{Y \sim Q}[S(P, Y)]$ 对所有 $P$ 成立。
- **严格固有评分规则 (Strictly Proper Scoring Rule)** 进一步要求这个最大值是唯一的，即仅当 $P=Q$ 时等号成立。形式化地：$\mathbb{E}_{Y \sim Q}[S(Q, Y)] > \mathbb{E}_{Y \sim Q}[S(P, Y)]$ 对所有 $P \neq Q$ 成立。

严格固有性是评估概率预报的金标准，因为它确保了理性的预报者除了报告其真实所信之外别无更优选择。我们可以引入一个名为**悔值 (Regret)** 或散度的量 $D_S(Q \| P) = J(Q, Q) - J(Q, P)$。严格固有性等价于要求 $D_S(Q \| P) \ge 0$，且仅当 $P=Q$ 时 $D_S(Q \| P) = 0$ 。

#### 经典严格固有评分规则示例

两个最著名且应用广泛的严格固有评分规则是[布莱尔分数](@entry_id:897139)和对数分数。

**[布莱尔分数](@entry_id:897139) (Brier Score)**

对于一个二元事件（例如，某地 24 小时内降水量是否超过阈值），其结果 $y \in \{0, 1\}$，[概率预报](@entry_id:183505)为 $p \in [0, 1]$。[布莱尔分数](@entry_id:897139)的定义为预报概率与结果之间的[均方误差](@entry_id:175403)：
$$
S(p, y) = (p-y)^2
$$
这是一个严格固有评分规则，因为它鼓励预报概率 $p$ 尽可能接近真实的条件概率 $\mathbb{E}[Y|p]$。我们可以分析其惩罚机制。假设一个预报员的预报概率与真实结果的[绝对偏差](@entry_id:265592)为 $d$。

- **误报 (False Alarm)**：事件未发生 ($y=0$)，但预报概率为 $p=d$。此时的惩罚为 $S(d, 0) = (d-0)^2 = d^2$。
- **漏报 (Miss)**：事件发生 ($y=1$)，但预报概率为 $p=1-d$。此时的惩罚为 $S(1-d, 1) = ((1-d)-1)^2 = (-d)^2 = d^2$。

可见，标准的[布莱尔分数](@entry_id:897139)对两种同等偏差的错误给予了对称的惩罚 。然而，在某些应用场景中（如气候风险评估），误报和漏报的后果可能严重不对等。此时，我们可以引入**加权[布莱尔分数](@entry_id:897139)**：
$$
S_w(p, y) = w(y)(p-y)^2
$$
其中 $w(0)=w_0$ 和 $w(1)=w_1$ 是两个正权重。在这种情况下，上述两种错误的惩罚变为 $w_0 d^2$ 和 $w_1 d^2$。其惩罚不[对称因子](@entry_id:274828)，即误报惩罚与漏报惩罚之比，为 $\frac{w_0}{w_1}$。这使得我们可以根据具体决策需求，定制评分规则以反映非对称的损失函数 。

**对数分数 (Logarithmic Score)**

对数分数，或称[似然](@entry_id:167119)分数，是另一个核心的严格固有评分规则，与信息论有着深刻的联系。对于一个[预测分布](@entry_id:165741) $P$（其密度或[质量函数](@entry_id:158970)为 $p(y)$）和结果 $y$，其定义为：
$$
S(P, y) = \ln p(y)
$$
对数分数的严格固有性可以通过其与 **Kullback-Leibler (KL) 散度** 的关系来优雅地证明。当真实分布为 $Q$ 时，报告分布 $P$ 的期望得分为 $J(Q,P) = \mathbb{E}_{Y \sim Q}[\ln p(Y)]$。我们比较真实报告（$P=Q$）与非真实报告（$P \neq Q$）的期望得分差异：
$$
J(Q, P) - J(Q, Q) = \mathbb{E}_{Y \sim Q}[\ln p(Y)] - \mathbb{E}_{Y \sim Q}[\ln q(Y)] = \mathbb{E}_{Y \sim Q}\left[\ln\frac{p(Y)}{q(Y)}\right]
$$
这恰好是负的 KL 散度 $KL(Q \| P) = \mathbb{E}_{Y \sim Q}[\ln(q(Y)/p(Y))]$。根据[吉布斯不等式](@entry_id:273899)，KL 散度总是非负的，即 $KL(Q \| P) \ge 0$，且仅当 $P=Q$ 时等号成立。因此，$J(Q, P) - J(Q, Q) = -KL(Q \| P) \le 0$，这意味着期望得分在 $P=Q$ 时取得唯一最大值。这不仅证明了对数分数的严格固有性，也量化了不诚实报告所导致的期望得分损失，其大小恰为 KL 散度 。

### 分解预报质量：可靠性、分辨力与锐度

一个单一的平均分数值，如平均[布莱尔分数](@entry_id:897139)，虽然有用，但它掩盖了预报质量的多个方面。一个好的概率预报系统应该具备三个关键的美德：**可靠性 (Reliability)**、**分辨力 (Resolution)** 和 **锐度 (Sharpness)** 。

1.  **可靠性 (Reliability)**，也称**校准性 (Calibration)**，指的是预报概率与观测频率之间的[统计一致性](@entry_id:162814)。例如，当系统发布 $0.7$ 的降水概率时，在所有这样的预报日中，降水事件是否真的以接近 $0.7$ 的频率发生？一个完美可靠的预报，其发布的概率可以被直接解读为事件的真实条件频率。

2.  **分辨力 (Resolution)**，或称**判别能力 (Discrimination)**，指的是预报系统区分不同结果的能力。一个具有高分辨力的系统，能够针对将要发生事件的场合发布较高的概率，而针对事件不会发生的场合发布较低的概率。它衡量的是预报值在不同结果下的[条件分布](@entry_id:138367)的差异程度。

3.  **锐度 (Sharpness)** 指的是预测分布的集中程度或“自信度”。这是一个仅与预报本身相关的属性，与真实结果无关。例如，对于二元事件，发布接近 $0$ 或 $1$ 的概率被认为是锐度高的；对于连续变量，一个方差很小的预测分布是锐度高的。锐度本身是可取的，因为它提供了更明确的信息，但前提是必须保持可靠。

### 评估可靠性：从理论到实践

可靠性是概率预报最直观的质量属性。其核心思想是，预报应“言而有信”。

#### 可靠性的理论基础

对于连续变量的概率预报，如温度，其预测由一个[累积分布函数 (CDF)](@entry_id:264700) $F(y)$ 给出。如果预报是可靠的，那么真实的观测值 $Y$ 就应该像是从这个分布 $F$ 中抽取的一个样本。这意味着，对于任意的 $y$ 值，条件概率 $P(Y \le y | F)$ 都应该等于 $F(y)$。

这一性质引出了一个强大的诊断工具：**[概率积分变换](@entry_id:262799) (Probability Integral Transform, PIT)**。如果一个[连续随机变量](@entry_id:166541) $Y$ 的 CDF 是 $F$，那么[随机变量](@entry_id:195330) $U = F(Y)$ 将服从 $[0, 1]$ 上的均匀分布。因此，要检验一个[连续概率](@entry_id:151395)预报系统的可靠性，我们可以计算大量预报-观测对的 PIT 值 $\{U_i = F_i(Y_i)\}$，然后检验这些 PIT 值是否构成一个均匀分布的样本。任何对均匀性的偏离都揭示了某种形式的不可靠性（例如，U型或倒U型的PIT直方图分别表示预报分布过于狭窄或宽泛）。

#### [可靠性图](@entry_id:911296)与[布莱尔分数](@entry_id:897139)分解

对于二元事件预报，评估可靠性的标准工具是**[可靠性图](@entry_id:911296) (Reliability Diagram)**。其构建方法如下：
1.  将所有预报概率 $p_i$ 值域 $[0, 1]$ 划分成 $K$ 个区间（箱子），例如 $[0, 0.1), [0.1, 0.2), \dots$。
2.  对于每个箱子 $k$，计算落入其中的所有预报的平均预报概率 $\bar{p}_k$。
3.  同样对于每个箱子 $k$，计算对应的观测结果的平均值，即观测到的事件频率 $\hat{\pi}_k$。
4.  在坐标系中，以 $\bar{p}_k$ 为横坐标，以 $\hat{\pi}_k$ 为纵坐标，绘制点 $(\bar{p}_k, \hat{\pi}_k)$。

一个完美可靠的预报系统，其所有绘制出的点都应该落在对角线 $y=x$ 上。这些点偏离对角线的程度直观地展示了预报的不可靠性。

这个直观的图形工具与[布莱尔分数](@entry_id:897139)的理论分解有着深刻的联系。[布莱尔分数](@entry_id:897139)可以被精确地分解为可靠性、分辨力和不确定性三个部分。其中，**可靠性项 (REL)** 定义为 $\mathbb{E}[(P - \pi(P))^2]$，其中 $\pi(P) = \mathbb{E}[Y|P]$ 是给定预报 $P$ 时事件发生的真实条件概率。[可靠性图](@entry_id:911296)上计算的经验可靠性度量 $\widehat{REL}_K = \sum_{k=1}^K \frac{n_k}{N}(\bar{p}_k - \hat{\pi}_k)^2$（其中 $n_k$ 是第 $k$ 箱的样本数，N是总样本数），在[样本量](@entry_id:910360)充足且[分箱](@entry_id:264748)足够精细的条件下，是理论可靠性项 $REL$ 的一个[一致估计量](@entry_id:266642) 。

#### 可靠性的[假设检验](@entry_id:142556)

除了图形诊断，我们还可以进行定量的[假设检验](@entry_id:142556)来判断预报是否可靠。一个常用的方法是基于[分箱](@entry_id:264748)的 $\chi^2$ 检验 。其逻辑如下：
在“预报是可靠的”这一[原假设](@entry_id:265441) ($H_0$) 下，对于给定的预报概率 $p_i$，观测值 $Y_i$ 是一个参数为 $p_i$ 的伯努利[随机变量](@entry_id:195330)。考虑第 $k$ 个箱子，其中包含 $n_k$ 个预报。
- **观测到的事件数**为 $s_k = \sum_{i \in k} Y_i$。
- 在 $H_0$ 下，**期望的事件数**为 $m_k = \mathbb{E}[s_k] = \sum_{i \in k} \mathbb{E}[Y_i] = \sum_{i \in k} p_i$。
- 在 $H_0$ 下，**事件数的方差**为 $v_k = \text{Var}(s_k) = \sum_{i \in k} \text{Var}(Y_i) = \sum_{i \in k} p_i(1-p_i)$。

根据[中心极限定理](@entry_id:143108)，当 $n_k$ 较大时，$s_k$ 近似服从正态分布 $\mathcal{N}(m_k, v_k)$。因此，标准化后的变量的平方 $\frac{(s_k - m_k)^2}{v_k}$ 近似服从自由度为 1 的 $\chi^2$ 分布。由于不同箱子中的观测是独立的，我们可以将所有箱子的统计量相加，得到总的检验统计量：
$$
T = \sum_{k=1}^K \frac{(s_k-m_k)^2}{v_k}
$$
在 $H_0$ 下，这个统计量 $T$ 近似服从自由度为 $K$ 的 $\chi^2$ 分布。如果计算出的 $T$ 值过大，我们就有理由拒绝原假设，认为预报是不可靠的。

### 评估分辨力：ROC 曲线

分辨力，或称判别能力，是预报质量的另一个独立维度。它衡量的是预报能否有效地区分“有事件”和“无事件”的情况。评估分辨力的主要工具是 **ROC 曲线 (Receiver Operating Characteristic curve)**。

ROC 曲线是为[二元分类](@entry_id:142257)问题设计的。其构建方式如下：对于一系列[概率预报](@entry_id:183505) $p_i$，我们选择一个阈值 $\tau \in [0, 1]$。当 $p_i \ge \tau$ 时，我们预测事件发生；否则预测不发生。通过从 $1$ 到 $0$ 连续滑动阈值 $\tau$，我们可以计算出每一对相应的**真正率 (True Positive Rate, TPR)** 和 **假正率 (False Positive Rate, FPR)**。

- $TPR(\tau) = P(\text{预报} \ge \tau | \text{事件发生}) = P(p \ge \tau | Y=1)$
- $FPR(\tau) = P(\text{预报} \ge \tau | \text{事件未发生}) = P(p \ge \tau | Y=0)$

以 FPR 为横轴，TPR 为纵轴，绘制出所有 $(\text{FPR}(\tau), \text{TPR}(\tau))$ 点构成的曲线，就是 ROC 曲线 。

ROC 曲线下的面积，即 **[AUC](@entry_id:1121102) (Area Under the Curve)**，是一个总结分辨力好坏的单一指标。AUC 的值在 $0.5$ (无分辨力，相当于随机猜测) 到 $1.0$ (完美分辨力) 之间。

一个至关重要的性质是，ROC 曲线对于预报值的任何严格单调递增变换都是不变的 。例如，如果我们将预报概率 $p$ 替换为 $p^2$ 或者 $\sqrt{p}$，新的 ROC 曲线将与原来完全相同。这是因为如果 $g$ 是一个严格单调递增函数，$p \ge \tau$ 等价于 $g(p) \ge g(\tau)$。这意味着，通过选择新的阈值 $\tau' = g(\tau)$，我们可以得到与原来完全相同的 TPR 和 FPR。

这个性质凸显了 ROC 和 AUC 的一个根本局限性：**它们只衡量分辨力，不衡量可靠性**。一个预报系统可能具有极高的分辨力（AUC接近1），但其概率值可能完全未经校准。

让我们通过一个思想实验来阐明这一点 。假设一个完美的预报系统 $\mathcal{F}_1$ 发布的概率 $p$ 恰好是事件的真实[条件概率](@entry_id:151013)（即 $p$ 是完全校准的）。现在，我们构造另一个预报系统 $\mathcal{F}_2$，它发布的概率是 $q = p^2$。由于 $g(p)=p^2$ 在 $[0, 1]$ 上是严格单调递增的，系统 $\mathcal{F}_2$ 与 $\mathcal{F}_1$ 具有完全相同的 ROC 曲线和 AUC 值，即它们的分辨力完全相同。然而，$\mathcal{F}_2$ 的预报是系统性偏低的（例如，当真实概率为 $0.5$ 时，它预报 $0.25$），因此是不可靠的。如果我们用像[布莱尔分数](@entry_id:897139)这样的严格固有评分规则来评估这两个系统，$\mathcal{F}_1$ 的得分会显著优于 $\mathcal{F}_2$。这个例子雄辩地证明了，依赖 [AUC](@entry_id:1121102) 来评估概率预报是片面的，而固有评分规则则能同时捕捉到可靠性和分辨力的综合表现。

### 连续分级概率评分 (CRPS)

对于连续变量（如温度、风速）的概率预报，[布莱尔分数](@entry_id:897139)不再适用。其在连续变量上的自然推广是 **连续分级概率评分 (Continuous Ranked Probability Score, CRPS)**。对于一个由 CDF $F(x)$ 描述的预测分布和观测值 $y$，CRPS 的定义为：
$$
\mathrm{CRPS}(F,y) = \int_{-\infty}^{\infty} (F(x) - \mathbf{1}\{x \ge y\})^{2} \, dx
$$
其中 $\mathbf{1}\{x \ge y\}$ 是一个[阶跃函数](@entry_id:159192)，代表一个在观测值 $y$ 处退化的确定性预报的 CDF。CRPS 可以被直观地理解为预测 CDF 与代表完美预报的[阶跃函数](@entry_id:159192) CDF 之间的积分平方差。

CRPS 也有一个等价且更具解释性的表达形式：
$$
\mathrm{CRPS}(F,y) = \mathbb{E}[|X - y|] - \frac{1}{2}\mathbb{E}[|X - X'|]
$$
其中 $X$ 和 $X'$ 是从[预测分布](@entry_id:165741) $F$ 中独立抽取的两个随机样本。第一项 $\mathbb{E}[|X - y|]$ 是预测值与观测值之间[绝对误差](@entry_id:139354)的期望，衡量的是**准确度 (Accuracy)**。第二项 $\frac{1}{2}\mathbb{E}[|X - X'|]$ 是[预测分布](@entry_id:165741)中任意两个样本之间绝对差值的期望的一半，衡量的是**锐度 (Sharpness)** 的反面，即预测的**[离散度](@entry_id:168823) (Dispersion)**。CRPS 奖励准确度高（第一项小）和锐度高（第二项小）的预报。

对于由 $m$ 个成员组成的[集合预报](@entry_id:1124525) $\{x_i\}_{i=1}^m$，其经验 CDF 为 $F_m(x) = \frac{1}{m}\sum_i \mathbf{1}\{x_i \le x\}$。利用上述等价形式，可以推导出 CRPS 的一个无积分计算公式 ：
$$
\mathrm{CRPS}(F_m, y) = \frac{1}{m}\sum_{i=1}^m |x_i - y| - \frac{1}{2m^2}\sum_{i=1}^m \sum_{j=1}^m |x_i - x_j|
$$
这个公式在实践中被广泛使用。第一项是集合成员与观测值的平均[绝对误差](@entry_id:139354)，第二项是集合成员内部的平均绝对差，代表了集合的离散度。

CRPS 能够同时惩罚预报的位置误差（偏差）和离散度误差。例如，考虑一个正态分布预报 $X \sim \mathcal{N}(\mu, \sigma^2)$，其 CRPS 可以被分解为依赖于偏差 $|\mu-y|$ 和[离散度](@entry_id:168823) $\sigma$ 的项。在标准正态CDF $\Phi$ 和PDF $\phi$ 下，其精确表达式为 ：
$$
|\mu-y|\left(2\Phi\left(\frac{|\mu-y|}{\sigma}\right) - 1\right) + \sigma\left(2\phi\left(\frac{|\mu-y|}{\sigma}\right) - \frac{1}{\sqrt{\pi}}\right)
$$
这个复杂的表达式清晰地表明，CRPS 是一个关于偏差和标准差的增函数，因此它同时激励预报既要准确又要锐利。

### 可靠性与锐度的权衡

在实践中，可靠性和锐度之间常常存在一种张力。一个预报系统可以很容易地通过发布[气候学](@entry_id:1122484)概率（例如，对所有日子都预报 $0.3$ 的降水概率）来变得完美可靠，但这样的预报毫无锐度和分辨力可言。反之，一个总是预报 $0$ 或 $1$ 的系统具有最高的锐度，但除非它几乎是完美的，否则其可靠性会非常差。

我们可以通过一个简化的理论模型来探索这种权衡 。假设真实事件概率 $\pi$ 是一个[随机变量](@entry_id:195330)，其均值为气候学概率 $q$。一个预报系统通过一个线性模型 $p = q + a(\pi - q)$ 来发布其概率。参数 $a$ 控制了预报的“自信度”：
- $a=1$：完美校准，$p=\pi$。
- $a>1$：过度自信，预报比真实概率更极端。
- $0 \le a  1$：自信不足，预报比真实概率更趋向于气候平均值。
- $a=0$：无锐度，总是预报气候平均值 $q$。

通过分析可以发现，可靠性损失（REL）和锐度（SHP，即 $\text{Var}(p)$）都可以表示为 $a$ 的函数：$\mathrm{REL}(a) = (a-1)^2 \sigma_\pi^2$ 和 $\mathrm{SHP}(a) = a^2 \sigma_\pi^2$ (其中 $\sigma_\pi^2 = \text{Var}(\pi)$)。这表明可靠性损失在 $a=1$ 时达到最小（为零），而锐度随 $|a|$ 的增加而增加。在 $a \ge 0$ 的约束下，$\mathrm{REL}$ 和 $\mathrm{SHP}$ 之间存在一个凸的权衡边界。

在某些决策场景中，用户可能愿意牺牲一些可靠性来换取更高的锐度。我们可以构建一个目标函数来平衡这两者，例如通过最小化 $J(a) = \text{BS}(a) - \lambda \text{Var}(p)$，其中 $\text{BS}$ 是[布莱尔分数](@entry_id:897139)，$\text{Var}(p)$ 是锐度，$\lambda \in (0, 1)$ 是一个权衡系数。通过最小化这个[目标函数](@entry_id:267263)，可以得到最优的自信度参数 $a^\star(\lambda) = \frac{1}{1-\lambda}$。这个结果表明，当决策者对锐度有偏好时（$\lambda  0$），最优的策略是发布一个比完美校准 ($a=1$) 更为自信的预报 ($a^\star  1$) 。这为理解和调整预报系统的行为提供了深刻的理论洞见。

总之，概率评分规则不仅仅是衡量预报好坏的工具，它们是引导和塑造预报系统发展的基本准则。通过理解其内在机制，特别是固有性原理以及可靠性、分辨力和锐度等多维度的质量分解，我们能够更全面、更深刻地评估和改进[数值天气预报](@entry_id:191656)与气候模型。