## 引言
在数值天气预报和气候科学领域，能够准确评估和改进预测模型是推动学科发展的核心。[后报](@entry_id:1126122)（hindcasts）与再预报（reforecasts）——即对过去事件的回顾性预测——构成了这一过程的基石。它们不仅是检验模型优劣的标尺，更是连接模型开发、业务应用和可预报性理论研究的关键桥梁。然而，如何科学地设计和使用这些庞大的历史预测数据集，以提取可靠的信息并避免错误的结论，是研究人员和预报员面临的一大挑战。本文旨在系统性地解决这一问题，为读者提供一个关于后报评估的全面指南。

本文将分为三个核心部分。首先，在“原理与机制”章节中，我们将深入探讨[后报](@entry_id:1126122)与再预报的基本定义、统计[同质性](@entry_id:636502)的重要性，以及它们在诊断系统性误差和量化预测技巧中的核心机制。接着，在“应用与跨学科联系”章节中，我们将展示这些原理如何转化为实际应用，从通过统计后处理提升预报技巧，到设计复杂的模式比较试验，再到将其应用于[气候变化归因](@entry_id:1122438)和能源经济等前沿交叉领域。最后，通过“动手实践”部分，读者将有机会运用所学知识解决具体的评估问题。通过这一结构化的学习路径，本文将引导您掌握后报评估的理论精髓与实践技能，从而更深刻地理解和应用现代地球系统预测。

## 原理与机制

在数值天气预报（NWP）和气候建模领域，对过去的事件进行预测是一项基础性工作。这不仅是为了评估和改进我们的预测系统，也是为了校准实时预报，以提供更可靠的概率信息。这些回顾性预测，通常被称为“[后报](@entry_id:1126122)”（hindcasts）或“再预报”（reforecasts），是连接模型开发、统计后处理和可预报性研究的关键桥梁。本章将深入探讨这些回顾性预测的基本原理、它们在实践中的关键作用，以及在评估过程中遇到的挑战和解决方法。

### 后报与再预报：基础定义与核心作用

首先，我们必须明确两个密切相关但目标不同的概念：**[后报](@entry_id:1126122)（hindcast）** 和 **再预报（reforecast）**。

**[后报](@entry_id:1126122)** 是一个广义术语，指使用数值模型对过去某个日期进行的任何回顾性预测。其最关键的应用之一是评估模型升级的效果。假设一个预报中心开发了一个新版本的模型（记为 $\theta_2$），并希望证明它优于旧版本（$\theta_1$）。为了进行公正的比较，必须遵循“控制变量”原则（ceteris paribus）。这意味着两个模型版本必须在完全相同的初始日期集合 $\mathcal{T}$ 上运行，生成成对的[后报](@entry_id:1126122)。通过比较它们在同一组天气事件上的表现，我们可以将技能得分的差异归因于模型本身的改进，而不是因为某个时期的天气事件本质上比另一个时期更容易预测。如果将一个模型在某个年份的表现与另一个模型在不同年份的表现进行比较，这种评估是存在缺陷的，因为它混淆了模型技能和特定时期大气可预报性的差异 。

相比之下，**再预报** 是一种特殊类型的[后报](@entry_id:1126122)，其设计具有更严格的统计目的。一个再预报数据集是使用一个“冻结”的（即固定不变的）模型配置，针对过去多年的大量历史日期（例如，过去20年中的每周）生成的。这种方法的核心目的是创建一个大规模、**统计[同质性](@entry_id:636502)**（statistically homogeneous）的样本。这种同质性至关重要，因为它使得我们可以可靠地估计模型的**气候态**（即模型对特定日期和预报时效的平均行为）以及其系统性误差的统计特征。这些统计特征是进行[概率校准](@entry_id:636701)和偏差订正的基石。例如，一个业务中心需要校准其次季节（如未来第2周）的降水预报，就需要一个由当前业务模型生成的再预报集。这个数据集使得研究人员能够估计出在特定季节和预报时效下，模型的预报概率与观测事件频率之间的稳定关系，从而建立一个可靠的校准函数  。

### 统计[同质性](@entry_id:636502)的重要性

为何“冻结”模型配置如此关键？因为任何[统计推断](@entry_id:172747)都依赖于样本的稳定性。如果一个“后报”档案库混合了来自不同模型版本、不同时期的预报，那么这个数据集就失去了统计同质性。其中的每一个数据点都来自一个略有不同的概率分布。

在这种情况下，计算整个档案库的平均值来定义“模型气候态”是毫无意义的，因为它混合了所有历史模型的平均偏差，而不能代表当前业务模型的偏差 。同样，试图从这样一个异质数据集中估计极端事件的发生概率也是不可靠的，因为不同模型的尾部行为可能差异巨大。

更微妙的是，模型配置的变更如果与时间演变相关联，会产生虚假的趋势。设想一个场景：一个预报中心在20年的[后报](@entry_id:1126122)档案库中，前12年使用模型版本A，后8年使用了性能更优的版本B。假设版本A的平均技能（以[距平相关系数](@entry_id:1121047)ACC衡量）为 $\mu_A = 0.45$，而版本B为 $\mu_B = 0.60$。如果研究人员忽略了模型版本的变化，直接对这20年的技能得分进行线性回归以寻找“可预报性趋势”，他们会发现一个虚假的上升趋势。这种现象被称为**[遗漏变量偏差](@entry_id:169961)（omitted-variable bias）**。因为模型版本（一个被遗漏的变量）与时间（回归量）是相关的（新版本在[后期](@entry_id:165003)使用），[回归模型](@entry_id:1130806)会错误地将由模型升级带来的技能提升归因于时间的流逝。

在一个具体的例子中 ，对于一个跨越20年、在第13年发生模型版本切换的档案库，如果真实的可预报性没有时间趋势（即真实趋势 $\beta = 0$），仅仅因为 $\mu_A$ 和 $\mu_B$ 的差异，进行简单的线性回归就会得到一个约等于 $0.0108$ 的虚假正斜率。这个偏差的大小可以通过以下公式精确计算：
$$ \text{Bias} = (\mu_B - \mu_A) \frac{\operatorname{Cov}(t, d)}{\operatorname{Var}(t)} $$
其中，$t$ 是时间指数（$1, \dots, 20$），$d(t)$ 是一个[指示变量](@entry_id:266428)，当使用版本B时为1，否则为0。这清晰地表明，只有使用一个冻结的模型配置生成的再预报数据集，才能确保我们估计的统计量和趋势是可信的。

### 应用一：系统性误差的诊断与校准

拥有一个统计同质的再预报数据集后，我们便可以深入剖析模型的“个性”——即其系统性误差，并加以校准。

#### 偏差与离散度误差

**等级[直方图](@entry_id:178776)（Rank Histogram）**，或称塔拉[格兰图](@entry_id:200721)（Talagrand diagram），是诊断[集合预报系统](@entry_id:1124526)性误差的有力工具。其原理是：对于一个完美的[集合预报系统](@entry_id:1124526)，真实的观测值应该与任何一个集合成员在统计上无法区分。因此，将观测值插入到按升序排列的 $m$ 个集合成员中时，它落在 $m+1$ 个可能等级（包括两个极端外部等级）中的任何一个的概率都应该是相等的，即 $1/(m+1)$。一个理想的等级直方图应该是平坦的。

再预报数据集为我们提供了成千上万的案例来构建稳定的等级[直方图](@entry_id:178776)，从而揭示模型的系统性缺陷 ：

*   **U形直方图**：表示观测值过于频繁地落在集合预报范围之外（即等级1和等级 $m+1$ 的频数过高）。这明确地指示了**离散度不足（underdispersion）**，即集合系统的扩展度太小，对预报不确定性的估计过于自信。一个恰当的调整策略是利用再预报数据校准一个统计后处理模型（如集合模式输出统计EMOS），来“膨胀”预报的方差。

*   **驼峰形[直方图](@entry_id:178776)**：表示观测值几乎总是落在集合成员的中间，很少出现在极端等级。这指示了**[离散度](@entry_id:168823)过大（overdispersion）**，即集合系统扩展度太大，过于保守。相应的调整策略则是“收缩”预报的方差。

*   **倾斜的直方图**：如果直方图不对称，例如向左倾斜（低等级的频数更高），意味着观测值系统性地小于大部分集合成员的预报值。对于温度预报而言，这意味着模型存在**正偏差（偏暖）**。纠正方法是利用再预报数据估计一个依赖于预报时效和季节的负偏差订正项，并将其从预报中减去。

值得注意的是，这些缺陷的根源在于模型的物理和动力学特性，仅仅增加集合成员数量 $m$ 并不能解决问题。增加成员数只是从同一个有缺陷的（例如，过窄的）概率分布中抽取更多的样本，而无法改变该分布本身的缺陷 。

#### [次季节到季节](@entry_id:1132614)尺度（S2S）预测中的[模型漂移](@entry_id:916302)

在[S2S预测](@entry_id:1131162)中，一个特殊的系统性误差是**[模型漂移](@entry_id:916302)（model drift）**。它被定义为模型的气候态随预报时效系统性地变化。其物理根源在于，模型从一个接近观测真实状态的初始场开始积分，但由于其自身的动力学和物理过程存在系统性偏差，模型状态会逐渐“漂移”到其自身偏好的、有偏的[平衡态](@entry_id:270364)（即模型[吸引子](@entry_id:270989)）。

这种漂移表现为一种依赖于预报时效的偏差。再预报数据集是量化和校准这种漂移的唯一可靠工具。标准的校准方法  如下：

1.  利用再预报数据集，[计算模型](@entry_id:637456)在每个预报时效 $\ell$ 的气候态 $\bar{f}_{\text{rf}}(\ell)$。
2.  利用历史观测，计算真实的气候态 $\bar{x}_{\text{obs}}(\ell)$。
3.  对于一个实时的原始预报 $f(\ell)$，首先计算其相对于模型自身漂移气候态的**距平**：$a_{\text{mod}}(\ell) = f(\ell) - \bar{f}_{\text{rf}}(\ell)$。这部分被认为是预报的“技巧”所在。
4.  将这个预报距平叠加到观测气候态上，得到最终的校准预报：$y(\ell) = \bar{x}_{\text{obs}}(\ell) + a_{\text{mod}}(\ell) = f(\ell) - \bar{f}_{\text{rf}}(\ell) + \bar{x}_{\text{obs}}(\ell)$。

这个过程有效地用观测的、无偏的气候态替换了模型有偏的、随时间漂移的气候态，从而得到一个在气候意义上无偏的预报。

### 应用二：预测技巧的量化与解释

再预报不仅用于校准，还为量化预测技巧提供了一个稳定的基准。

#### 技巧评分与参考预报

**技巧评分（Skill Score）** 是一个相对度量，它量化了目标预报相对于某个基准参考预报的改进程度。其通用形式为：
$$ SS = 1 - \frac{\text{Score}_{\text{forecast}}}{\text{Score}_{\text{reference}}} $$
其中，$\text{Score}$ 是一个损失函数（如均方误差MSE），分数越低越好。$SS > 0$ 表示预报优于参考， $SS  0$ 表示劣于参考。

选择不同的参考预报，会带来不同的解释 ：

*   **气候态预报**：使用历史平均值作为预报。对于距平预报，气候态预报为0。由于其误差（即气候方差）不随预报时效变化，因此相对于气候态的技巧评分在不同时效间是可比的。它衡量的是预报在多大程度上解释了气候的自然变率。

*   **持续性预报**：使用“昨天”的值来预报“今天”。持续性预报在短时效内非常准确（误差小），但随着时效延长，其误差迅速增大。因此，与持续性预报比较的技巧评分，其值会受到参考预报误差随时间变化的影响，导致不同时效间的技巧评分难以直接比较。例如，一个预报在10天时效上可能比气候态差（$SS_{\text{clim}}  0$），但仍然比持续性预报好（$SS_{\text{pers}}  0$）。

在气候变化的背景下，使用一个固定的、基于过去较早时期（例如1961-1990年）的气候态作为参考是危险的。在全球变暖的今天，这样的气候态本身就存在一个“冷偏差”，这会人为地夸大现代预报系统相对于这个过时气候态的技巧评分 。因此，使用与验证期同步的再预报来定义一个滑动的、与当前气候状态一致的参考气候态，是更科学的做法。

#### [距平相关系数](@entry_id:1121047)（ACC）

对于大尺度场（如500 hPa[位势高度](@entry_id:269053)）的评估，**[距平相关系数](@entry_id:1121047)（Anomaly Correlation Coefficient, ACC）** 是一个核心指标。ACC计算的是**预报距平**与**观测距平**之间的时间或空间相关性。

使用距平至关重要，因为它将预报技巧的评估重点放在了对偏离平均态（即天气系统）的预测上，而不是对基本气候态（如季节循环）的再现上 。一个未经处理的原始预报与观测之间的相关性可能非常高（例如，都正确地预报了夏天热、冬天冷），但这并不代表真正的天气预报技巧。

ACC的计算公式为：
$$ \mathrm{ACC}=\frac{\sum_{i=1}^{n}\left(a_i^{f}-\bar{a}^{f}\right)\left(a_i^{o}-\bar{a}^{o}\right)}{\sqrt{\sum_{i=1}^{n}\left(a_i^{f}-\bar{a}^{f}\right)^{2}} \cdot \sqrt{\sum_{i=1}^{n}\left(a_i^{o}-\bar{a}^{o}\right)^{2}}} $$
其中 $a^f = f - c^f$ 是预报距平（原始预报减去模型气候态），$a^o = o - c^o$ 是观测距平。至关重要的是，预报距平必须是相对于**模型自身的气候态**（$c^f$，从再预报中获得）计算的。这样做的好处是，ACC对模型的平均偏差（即$c^f$与$c^o$的差异）不敏感，从而能够纯粹地衡量模型预报**距平形态**的技巧。模型的平均偏差可以作为另一个指标单独评估。

从信号处理的角度看，ACC可以被理解为可预报信号与总变率（信号加噪声）的比值。在一个简化的信号-[噪声模型](@entry_id:752540)中 ，ACC近似等于：
$$ \mathrm{ACC} \approx \frac{\mathrm{Var}(s)}{\sqrt{\left(\mathrm{Var}(s)+\mathrm{Var}(\epsilon)\right)\left(\mathrm{Var}(s)+\mathrm{Var}(\eta)\right)}} $$
其中 $\mathrm{Var}(s)$ 是可预报信号的方差，$\mathrm{Var}(\epsilon)$ 和 $\mathrm{Var}(\eta)$ 分别是预报和观测中的噪声/[误差方差](@entry_id:636041)。这个形式清晰地表明，ACC衡量的是信号在噪声背景下的强度。

### 高级主题与实践挑战

在后报评估的实践中，还存在一系列更为复杂的问题。

#### "真值"的本质：使用再分析资料进行验证

由于高时空分辨率的全球观测数据稀疏，后报通常是与**再分析资料（reanalysis）** 进行验证。再分析资料本身是通过数据同化系统将所有可用观测融合到一个数值模型中生成的，它提供了时空完整且动力学一致的“最佳”大气状态估计。

然而，这种做法引入了新的复杂性 ：

1.  **验证资料误差的非平稳性**：再分析资料的质量随时间演变。例如，20世纪70年代末卫星数据引入之前和之后，再分析资料的质量有巨大差异。这意味着验证“[真值](@entry_id:636547)”的误差方差是时变的。一个恒定技巧的[后报](@entry_id:1126122)系统，在与质量较差的早期再分析资料比较时，会显得技巧更差，因为测得的[均方误差](@entry_id:175403)（MSE）近似等于真实的预报MSE加上再分析资料的[误差方差](@entry_id:636041)。

2.  **[误差相关性](@entry_id:749076)**：如果生成后报的模型与生成再分析资料的模型相似（例如，使用相同的物理参数化方案），它们的误差可能是相关的。这种正相关会导致一个乐观的评估偏差：由于两者的误差部分抵消，它们会显得比各自与真实状态的符合程度更加一致，从而人为地夸大测得的技巧评分（如ACC）。

尽管存在这些问题，再分析资料仍然是目前进行大尺度后报评估不可或缺的工具。先进的验证方法会尝试估计并校正再分析资料误差的影响，以获得更可靠的技巧评估。

#### [空间验证](@entry_id:1132054)中的“双重惩罚”问题

对于高分辨率的场（特别是降水），传统的逐点比较（pixel-wise verification）会遇到**双重惩罚（double penalty）** 问题。设想一个高分辨率降水预报准确地预测了一个强降水事件的强度和形状，但位置偏移了一个格点。在逐点评估中，这会被记为在观测位置的一次**漏报（miss）** 和在预报位置的一次**错报（false alarm）**，导致诸如威胁评分（Threat Score, TS）等指标急剧下降，甚至为零 。

为了解决这个问题，研究者们发展了**邻域法（neighborhood methods）**。这类方法放宽了对精确位置匹配的要求。例如，**[分数技巧评分](@entry_id:1125282)（Fractions Skill Score, FSS）** 不再比较单个格点，而是比较在一个给定大小的邻域窗口内，事件发生的频率（或分数）。在一个因微小位移而被判为TS=0的案例中，FSS可以通过选择一个足够大的邻域窗口（例如，3x3格点）来识别出预报和观测场在空间结构上的相似性，从而给出一个远高于零的、更符合直觉的评分（例如，$\text{FSS} = 2/3$） 。当邻域窗口扩展到整个区域时，FSS只比较区域总降水量，完全忽略空间位置，此时对于总降水量预测准确的预报，FSS将等于1。

#### 采样不确定性

最后，必须认识到，即使拥有长达20或30年的再预报数据集，我们从中计算出的所有统计量（如气候态、偏差、技巧评分）仍然是**估计值**，并伴随着**采样不确定性**。

这个问题在定义分类预报（如“低于/接近/高于正常”）的阈值时尤为突出 。这些阈值通常被定义为气候态分布的分位数（如33%和66%[分位数](@entry_id:178417)）。然而，用于估计这些[分位数](@entry_id:178417)的样本并非完全独立。在一个集合再预报系统中，同一年份（或同一初始条件）的所有集合成员之间存在相关性（因为它们来自同一个模型积分，仅初始条件有微小扰动）。

这种内部相关性减少了样本的**有效样本量（effective sample size, $n_{\text{eff}}$）**。例如，对于一个有 $K$ 年、每年 $M$ 个成员、成员间[相关系数](@entry_id:147037)为 $\rho_e$ 的再预报集，其[有效样本量](@entry_id:271661)约为：
$$ n_{\text{eff}} \approx \frac{K \cdot M}{1 + (M-1)\rho_e} $$
在一个 $K=20, M=10, \rho_e=0.2$ 的例子中，总[样本量](@entry_id:910360)为200，但[有效样本量](@entry_id:271661)仅为 $200 / (1 + 9 \times 0.2) \approx 71$。这意味着，我们估计的分位数的不确定性（[标准误](@entry_id:635378)）会比我们基于200个[独立样本](@entry_id:177139)所预期的要大得多。在进行任何[统计显著性](@entry_id:147554)检验或构建置信区间时，必须考虑这种由于样本相关性导致的[方差膨胀](@entry_id:756433)效应。这提醒我们，即使在数据丰富的时代，对统计严谨性的追求也至关重要。