{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in understanding the Stochastic Block Model is to solve a simplified problem: if we magically knew the community assignment for every node, how would we estimate the matrix of connection probabilities, $\\boldsymbol{P}$? This foundational exercise  guides you through the derivation of the Maximum Likelihood Estimator (MLE) for these probabilities. This practice reveals an intuitive answer and solidifies the connection between the SBM's parameters and observable network data, such as edge counts between communities.",
            "id": "4283104",
            "problem": "Consider a simple undirected graph without self-loops on $n$ vertices, represented by a symmetric adjacency matrix $A$ with $A_{ii} = 0$ and $A_{ij} \\in \\{0,1\\}$ for $i \\neq j$. Assume the graph is generated by the Stochastic Block Model (SBM) with $K$ communities. The community assignment is given and fixed as $z = (z_{1}, \\dots, z_{n})$, where $z_{i} \\in \\{1, \\dots, K\\}$ denotes the community label of vertex $i$. For any pair of vertices $i \\neq j$, the presence of an edge is an independent Bernoulli event with parameter $P_{z_{i} z_{j}}$, where $P_{ab} \\in (0,1)$ and $P_{ab} = P_{ba}$ for all $a,b \\in \\{1, \\dots, K\\}$.\n\nLet $n_{a} = \\sum_{i=1}^{n} \\mathbf{1}\\{z_{i} = a\\}$ be the size of community $a$. Define, for ordered vertex pairs, the blockwise edge counts\n$$\nm_{ab} = \\sum_{i : z_{i} = a} \\sum_{j : z_{j} = b,\\, j \\neq i} A_{ij},\n$$\nand the number of potential ordered vertex pairs\n$$\nN_{ab} = n_{a} n_{b} - \\delta_{ab} n_{a},\n$$\nwhere $\\delta_{ab}$ is the Kronecker delta. Note that for $a \\neq b$, $N_{ab} = n_{a} n_{b}$, and for $a = b$, $N_{aa} = n_{a}(n_{a} - 1)$.\n\nStarting from the independence of edge indicators across distinct vertex pairs and the Bernoulli sampling mechanism of the Stochastic Block Model, construct the likelihood function of the observed adjacency matrix $A$ given the fixed assignment $z$ and parameters $\\{P_{ab}\\}_{a,b=1}^{K}$, using the ordered-pair counts $m_{ab}$ and $N_{ab}$ defined above. Then, by maximizing the likelihood with respect to $P_{ab}$ under the constraint $P_{ab} \\in (0,1)$ and $P_{ab} = P_{ba}$, derive the closed-form expression for the maximum likelihood estimator of $P_{ab}$ as a function of $m_{ab}$ and $N_{ab}$.\n\nYour final answer must be a single closed-form analytic expression in terms of $m_{ab}$, $n_{a}$, $n_{b}$, and $\\delta_{ab}$, and must not include any units. No numerical rounding is required.",
            "solution": "The problem asks for the maximum likelihood estimator (MLE) of the edge probability parameters $P_{ab}$ in a Stochastic Block Model (SBM) with known community assignments.\n\nThe graph is simple, undirected, and has no self-loops, with $n$ vertices. The adjacency matrix $A$ is symmetric with $A_{ii} = 0$ for all $i$ and $A_{ij} \\in \\{0, 1\\}$ for $i \\neq j$. The community assignment for each vertex $i$ is a fixed, known label $z_i \\in \\{1, \\dots, K\\}$. For any pair of distinct vertices $(i, j)$, an edge $A_{ij}$ exists with a probability that depends on the communities of its endpoints. This is an independent Bernoulli trial:\n$$\nA_{ij} \\sim \\text{Bernoulli}(P_{z_i z_j})\n$$\nThe probability mass function for a single potential edge $(i,j)$ is therefore:\n$$\n\\mathbb{P}(A_{ij} | z_i, z_j, P) = P_{z_i z_j}^{A_{ij}} (1 - P_{z_i z_j})^{1 - A_{ij}}\n$$\nwhere $P$ denotes the matrix of parameters $\\{P_{ab}\\}$. The model for an undirected graph requires symmetry in the connection probabilities, so $P_{ab} = P_{ba}$.\n\nThe likelihood function $\\mathcal{L}(P | A, z)$ is the total probability of observing the given adjacency matrix $A$, given the parameters $P$ and the community structure $z$. Since all potential edges are independent random variables, the likelihood is the product of the probabilities for each unique pair of vertices. For an undirected graph, we consider each pair $(i, j)$ with $i  j$ exactly once.\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le i  j \\le n} \\mathbb{P}(A_{ij} | z_i, z_j, P) = \\prod_{1 \\le i  j \\le n} P_{z_i z_j}^{A_{ij}} (1 - P_{z_i z_j})^{1 - A_{ij}}\n$$\nTo facilitate the calculation, we group the terms in this product according to the community blocks. Let $C_a = \\{i | z_i = a\\}$ be the set of vertices in community $a$. The product can be partitioned into a product over pairs of community blocks $(a, b)$ with $a \\le b$.\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le a \\le b \\le K} \\prod_{\\substack{i \\in C_a, j \\in C_b \\\\ i  j}} P_{ab}^{A_{ij}} (1 - P_{ab})^{1 - A_{ij}}\n$$\nThis can be rewritten as:\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le a \\le b \\le K} P_{ab}^{E_{ab}} (1 - P_{ab})^{M_{ab} - E_{ab}}\n$$\nwhere $E_{ab}$ is the number of observed edges connecting a vertex in community $a$ to a vertex in community $b$, and $M_{ab}$ is the total number of possible edges between these communities (for unordered pairs of vertices).\n\nThe problem provides definitions for blockwise edge counts $m_{ab}$ and potential pairs $N_{ab}$ based on ordered pairs of vertices. We must relate $E_{ab}$ and $M_{ab}$ to these given quantities.\n-   For an intra-community block ($a=b$):\n    $E_{aa}$ is the number of edges within community $a$. The quantity $m_{aa} = \\sum_{i,j \\in C_a, i \\neq j} A_{ij}$ counts every edge twice because $A$ is symmetric ($A_{ij} = A_{ji}$). Thus, $E_{aa} = \\frac{1}{2} m_{aa}$.\n    $M_{aa}$ is the number of possible edges within community $a$, which is the number of pairs of vertices, $\\binom{n_a}{2} = \\frac{n_a(n_a-1)}{2}$. The quantity $N_{aa} = n_a(n_a - 1)$ counts all ordered pairs of distinct vertices. Thus, $M_{aa} = \\frac{1}{2} N_{aa}$.\n\n-   For an inter-community block ($a \\neq b$):\n    $E_{ab}$ is the number of edges between communities $a$ and $b$. The quantity $m_{ab} = \\sum_{i \\in C_a, j \\in C_b} A_{ij}$ sums over all ordered pairs of vertices $(i,j)$ where $i$ is in $C_a$ and $j$ is in $C_b$. This is precisely the number of edges connecting the two communities. So, $E_{ab} = m_{ab}$.\n    $M_{ab}$ is the number of possible edges between communities $a$ and $b$, which is $n_a n_b$. The quantity $N_{ab} = n_a n_b$ counts the ordered pairs and is equal to $M_{ab}$. So, $M_{ab} = N_{ab}$.\n\nSubstituting these relations into the likelihood function:\n$$\n\\mathcal{L}(P) = \\left( \\prod_{a=1}^K P_{aa}^{m_{aa}/2} (1 - P_{aa})^{(N_{aa} - m_{aa})/2} \\right) \\left( \\prod_{1 \\le a  b \\le K} P_{ab}^{m_{ab}} (1 - P_{ab})^{N_{ab} - m_{ab}} \\right)\n$$\nTo find the MLE, we maximize the log-likelihood function, $\\ln \\mathcal{L}(P)$:\n$$\n\\ln \\mathcal{L}(P) = \\sum_{a=1}^K \\frac{1}{2} \\left[ m_{aa}\\ln(P_{aa}) + (N_{aa} - m_{aa})\\ln(1 - P_{aa}) \\right] + \\sum_{1 \\le a  b \\le K} \\left[ m_{ab}\\ln(P_{ab}) + (N_{ab} - m_{ab})\\ln(1 - P_{ab}) \\right]\n$$\nThe parameters $\\{P_{ab} | a \\le b\\}$ are independent in this expression. We can find the maximum by differentiating with respect to each parameter and setting the derivative to zero.\n\nCase 1: Intra-community parameter $P_{cc}$.\n$$\n\\frac{\\partial \\ln \\mathcal{L}}{\\partial P_{cc}} = \\frac{1}{2} \\left[ \\frac{m_{cc}}{P_{cc}} - \\frac{N_{cc} - m_{cc}}{1 - P_{cc}} \\right] = 0\n$$\n$$\n\\frac{m_{cc}}{P_{cc}} = \\frac{N_{cc} - m_{cc}}{1 - P_{cc}} \\implies m_{cc}(1 - P_{cc}) = P_{cc}(N_{cc} - m_{cc}) \\implies m_{cc} = P_{cc} N_{cc}\n$$\n$$\n\\hat{P}_{cc} = \\frac{m_{cc}}{N_{cc}}\n$$\n\nCase 2: Inter-community parameter $P_{cd}$ with $c  d$.\n$$\n\\frac{\\partial \\ln \\mathcal{L}}{\\partial P_{cd}} = \\frac{m_{cd}}{P_{cd}} - \\frac{N_{cd} - m_{cd}}{1 - P_{cd}} = 0\n$$\n$$\n\\frac{m_{cd}}{P_{cd}} = \\frac{N_{cd} - m_{cd}}{1 - P_{cd}} \\implies m_{cd}(1 - P_{cd}) = P_{cd}(N_{cd} - m_{cd}) \\implies m_{cd} = P_{cd} N_{cd}\n$$\n$$\n\\hat{P}_{cd} = \\frac{m_{cd}}{N_{cd}}\n$$\nDue to the symmetry constraint $P_{cd} = P_{dc}$, the estimator for $P_{dc}$ is the same. Note that $m_{cd} = m_{dc}$ and $N_{cd} = N_{dc}$, so the formula is consistent.\n\nCombining both cases, the maximum likelihood estimator for any parameter $P_{ab}$ is given by:\n$$\n\\hat{P}_{ab} = \\frac{m_{ab}}{N_{ab}}\n$$\nThe problem requires the final answer to be expressed in terms of $m_{ab}$, $n_a$, $n_b$, and the Kronecker delta $\\delta_{ab}$. We substitute the given definition of $N_{ab}$:\n$$\nN_{ab} = n_a n_b - \\delta_{ab} n_a =\n\\begin{cases}\nn_a n_b  \\text{if } a \\neq b \\\\\nn_a (n_a - 1)  \\text{if } a = b\n\\end{cases}\n$$\nThis gives the final closed-form expression for the MLE:\n$$\n\\hat{P}_{ab} = \\frac{m_{ab}}{n_a n_b - \\delta_{ab} n_a}\n$$\nThis result is intuitive: the estimated probability of an edge between two blocks is the observed density of edges between them, calculated using directed pair counts. The second-order conditions confirm that this is indeed a maximum as the log-likelihood function is concave with respect to each $P_{ab}$.",
            "answer": "$$\n\\boxed{\\frac{m_{ab}}{n_{a} n_{b} - \\delta_{ab} n_{a}}}\n$$"
        },
        {
            "introduction": "Inference rarely happens with known community labels; they are the very latent variables we wish to find. This practice  dives into the machinery of Bayesian inference by guiding you through the derivation of the update rule for a collapsed Gibbs sampler. By leveraging the properties of conjugate priors to analytically integrate out the model's parameters, you will develop the core equation needed to sample community assignments directly from their posterior distribution, a powerful and widely used technique in computational network science.",
            "id": "4283118",
            "problem": "Consider an undirected, simple network with $n$ nodes represented by a symmetric adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with $A_{ii} = 0$ for all $i$. Each node $i \\in \\{1,\\dots,n\\}$ has a community label $z_i \\in \\{1,\\dots,K\\}$, collected in the vector $z = (z_1,\\dots,z_n)$. The network is generated by a Stochastic Block Model (SBM) with the following hierarchical specification:\n\n1. Community proportions $\\phi = (\\phi_1,\\dots,\\phi_K)$ are drawn from a Dirichlet prior $\\phi \\sim \\text{Dirichlet}(\\alpha_1,\\dots,\\alpha_K)$ with hyperparameters $\\alpha_a  0$ for $a \\in \\{1,\\dots,K\\}$.\n\n2. Conditional on $\\phi$, labels are independent and identically distributed as $z_i \\mid \\phi \\sim \\text{Categorical}(\\phi)$.\n\n3. For each unordered community pair $(a,b)$ with $1 \\leq a \\leq b \\leq K$, the edge probability $\\theta_{ab}$ is drawn independently from a Beta prior $\\theta_{ab} \\sim \\text{Beta}(\\lambda_{ab}^{+}, \\lambda_{ab}^{-})$, where $\\lambda_{ab}^{+}  0$ and $\\lambda_{ab}^{-}  0$ are hyperparameters. For $a \\neq b$, $\\theta_{ab} = \\theta_{ba}$, and for within-community edges, $\\theta_{aa}$ governs edges between two nodes both in community $a$.\n\n4. Conditional on $z$ and $\\{\\theta_{ab}\\}$, edges are independent Bernoulli random variables: for $i  j$, $A_{ij} \\mid z, \\{\\theta_{ab}\\} \\sim \\text{Bernoulli}(\\theta_{z_i z_j})$, with $A_{ji} = A_{ij}$ and $A_{ii} = 0$.\n\nDefine the following counts with node $i$ excluded:\n\n- For each community $b$, let $n_b^{-i} = |\\{j \\neq i : z_j = b\\}|$ denote the number of nodes currently in community $b$ excluding node $i$.\n\n- Let $k_{ib} = \\sum_{j \\neq i,\\, z_j = b} A_{ij}$ denote the number of observed edges from node $i$ to nodes in community $b$.\n\n- For each unordered pair $(a,b)$ with $1 \\leq a \\leq b \\leq K$, let $m_{ab}^{-i}$ denote the number of edges among nodes excluding $i$ whose labels fall in communities $a$ and $b$, respectively; for $a \\neq b$, this is the count of edges with one endpoint in community $a$ and one in community $b$, and for $a=b$, this is the within-community edge count among nodes labeled $a$ excluding node $i$.\n\n- Let $N_{ab}^{-i}$ denote the number of potential unordered node pairs among nodes excluding $i$ for the community pair $(a,b)$; for $a \\neq b$, $N_{ab}^{-i} = n_a^{-i} n_b^{-i}$, and for $a = b$, $N_{aa}^{-i} = \\binom{n_a^{-i}}{2}$. Define the corresponding non-edge counts $s_{ab}^{-i} = N_{ab}^{-i} - m_{ab}^{-i}$.\n\nStarting from the above hierarchical model and using only fundamental probabilistic definitions and well-tested conjugacy relationships, derive the collapsed Gibbs sampling update for a single label $z_i$ by computing the conditional probability $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$, where $z_{-i} = (z_1,\\dots,z_{i-1},z_{i+1},\\dots,z_n)$ denotes the labels of all nodes except $i$. Your derivation must integrate out the community proportions $\\phi$ and all edge probabilities $\\{\\theta_{ab}\\}$, and express the final conditional probability in closed form solely in terms of the local edge counts $\\{k_{ib}\\}$, the exclusion counts $\\{n_b^{-i}\\}$, the pairwise exclusion counts $\\{m_{ab}^{-i}, s_{ab}^{-i}\\}$, and the hyperparameters $\\{\\alpha_a\\}$ and $\\{\\lambda_{ab}^{+}, \\lambda_{ab}^{-}\\}$.\n\nProvide the final expression for $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$ as a single analytic formula. No numerical evaluation is required. If you introduce special functions, define them clearly. Express your final answer as a single closed-form analytic expression. No rounding is required.",
            "solution": "The objective is to derive the collapsed Gibbs sampling update for the community label $z_i$ of a single node $i$. This requires computing the conditional probability $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$ for a proposed community $a \\in \\{1, \\dots, K\\}$, where $z_{-i}$ represents the labels of all other nodes and $A$ is the adjacency matrix. The \"collapsed\" nature of the sampler implies that the model parameters—the community proportions $\\phi$ and the edge probabilities $\\{\\theta_{ab}\\}$—must be integrated out.\n\nBy Bayes' theorem, the desired conditional probability is proportional to the joint probability of the label $z_i=a$ and the observed graph $A$, given the labels of all other nodes $z_{-i}$:\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}, A) \\propto \\mathbb{P}(z_i = a, A \\mid z_{-i})\n$$\nWe can factor the joint probability on the right-hand side as:\n$$\n\\mathbb{P}(z_i = a, A \\mid z_{-i}) = \\mathbb{P}(A \\mid z_i = a, z_{-i}) \\mathbb{P}(z_i = a \\mid z_{-i})\n$$\nThe derivation proceeds by calculating the two terms on the right-hand side, marginalized over the model parameters. Let $\\alpha_0 = \\sum_{c=1}^K \\alpha_c$.\n\nFirst, we derive the prior probability of assigning node $i$ to community $a$, given all other assignments, $\\mathbb{P}(z_i = a \\mid z_{-i})$.\nThe community labels $z$ are generated from a Dirichlet-Multinomial process. The parameters $\\phi$ are drawn from a $\\text{Dirichlet}(\\alpha_1, \\dots, \\alpha_K)$ distribution, and given $\\phi$, the labels are drawn from a $\\text{Categorical}(\\phi)$ distribution. The marginal probability of a set of labels is obtained by integrating out $\\phi$:\n$$\n\\mathbb{P}(z) = \\int \\mathbb{P}(z \\mid \\phi) \\mathbb{P}(\\phi) d\\phi\n$$\nGiven the counts $n_b = |\\{j : z_j = b\\}|$, we have $\\mathbb{P}(z \\mid \\phi) = \\prod_{b=1}^K \\phi_b^{n_b}$ and $\\mathbb{P}(\\phi) \\propto \\prod_{b=1}^K \\phi_b^{\\alpha_b-1}$. The integral is a standard result for the Dirichlet-Multinomial distribution:\n$$\n\\mathbb{P}(z) = \\frac{\\Gamma(\\alpha_0)}{\\Gamma(n + \\alpha_0)} \\prod_{b=1}^K \\frac{\\Gamma(n_b + \\alpha_b)}{\\Gamma(\\alpha_b)}\n$$\nThe conditional probability $\\mathbb{P}(z_i = a \\mid z_{-i})$ is the posterior predictive probability for a new observation, which is given by the ratio $\\frac{\\mathbb{P}(z_i=a, z_{-i})}{\\mathbb{P}(z_{-i})}$. Using the formula above for $\\mathbb{P}(z)$ and noting that for $z=(z_i=a, z_{-i})$, the counts are $n_a = n_a^{-i}+1$ and $n_b = n_b^{-i}$ for $b \\neq a$, and the total number of nodes is $n$. For $z_{-i}$, the counts are $n_b^{-i}$ and the total number of nodes is $n-1$.\nThis yields the well-known result:\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}) = \\frac{n_a^{-i} + \\alpha_a}{\\sum_{c=1}^K (n_c^{-i} + \\alpha_c)} = \\frac{n_a^{-i} + \\alpha_a}{(n-1) + \\alpha_0}\n$$\nSince we are concerned with proportionality, we can write:\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}) \\propto n_a^{-i} + \\alpha_a\n$$\n\nSecond, we derive the likelihood of the graph given the complete label assignment $z = (z_i=a, z_{-i})$, marginalized over the edge probabilities $\\{\\theta_{ab}\\}$.\nThe edges are conditionally independent Bernoulli trials given $z$ and $\\{\\theta_{ab}\\}$. The edge probability $\\theta_{ab}$ for each unordered block $\\{a, b\\}$ is drawn independently from a $\\text{Beta}(\\lambda_{ab}^{+}, \\lambda_{ab}^{-})$ prior. This Beta-Bernoulli structure is conjugate.\nThe marginal likelihood of the graph $A$ given a full labelling $z$ is:\n$$\n\\mathbb{P}(A \\mid z) = \\int \\mathbb{P}(A \\mid z, \\{\\theta_{ab}\\}) \\mathbb{P}(\\{\\theta_{ab}\\}) d\\{\\theta_{ab}\\}\n$$\nDue to independence of priors, this factorizes over the blocks:\n$$\n\\mathbb{P}(A \\mid z) = \\prod_{1 \\le c \\le d \\le K} \\int \\theta_{cd}^{m_{cd}}(1-\\theta_{cd})^{s_{cd}} \\frac{\\theta_{cd}^{\\lambda_{cd}^{+}-1}(1-\\theta_{cd})^{\\lambda_{cd}^{-}-1}}{B(\\lambda_{cd}^{+}, \\lambda_{cd}^{-})} d\\theta_{cd}\n$$\nwhere $m_{cd}$ and $s_{cd}$ are the total counts of edges and non-edges for block $\\{c,d\\}$ in the full graph. The integral evaluates to the ratio of Beta functions:\n$$\n\\mathbb{P}(A \\mid z) = \\prod_{1 \\le c \\le d \\le K} \\frac{B(m_{cd} + \\lambda_{cd}^{+}, s_{cd} + \\lambda_{cd}^{-})}{B(\\lambda_{cd}^{+}, \\lambda_{cd}^{-})}\n$$\nwhere the Beta function is $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$.\n\nTo evaluate the term $\\mathbb{P}(A \\mid z_i = a, z_{-i})$, we can factor the likelihood of the graph $A$ into the likelihood of edges not involving node $i$, $A^{-i}$, and the likelihood of edges incident to node $i$, which we denote $A_{i, \\cdot}$.\n$$\n\\mathbb{P}(A \\mid z_i = a, z_{-i}) = \\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i}) \\mathbb{P}(A^{-i} \\mid z_{-i})\n$$\nThe term $\\mathbb{P}(A^{-i} \\mid z_{-i})$ is constant with respect to the choice of $a$ for $z_i$, so it can be absorbed into the proportionality constant. We are left with the posterior predictive probability of the edges of node $i$.\n$$\n\\mathbb{P}(A \\mid z_i = a, z_{-i}) \\propto \\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i})\n$$\nThe edges from node $i$ to nodes in a specific community $b$ are $n_b^{-i}$ Bernoulli trials with parameter $\\theta_{ab}$. There are $k_{ib}$ observed edges (successes) and $n_b^{-i} - k_{ib}$ non-edges (failures). The posterior for $\\theta_{ab}$ after observing the graph $A^{-i}$ among nodes $z_{-i}$ is $\\text{Beta}(\\theta_{ab} \\mid m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})$.\nThe predictive probability for the edges from $i$ to community $b$ is given by the Beta-Binomial predictive distribution:\n$$\n\\mathbb{P}(\\{A_{ij}\\}_{j: z_j=b} \\mid z_i=a, z_{-i}, A^{-i}) = \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, (n_b^{-i}-k_{ib}) + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\nSince edge probabilities for different blocks are independent, the total predictive likelihood for all edges of node $i$ is the product over all communities $b \\in \\{1, \\dots, K\\}$:\n$$\n\\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i}) = \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\nNote that the counts $m_{ab}^{-i}, s_{ab}^{-i}$ and hyperparameters $\\lambda_{ab}^{\\pm}$ are defined for unordered pairs, so they are symmetric, i.e., $m_{ab}^{-i}=m_{ba}^{-i}$.\n\nCombining the prior and likelihood terms, the unnormalized probability for $z_i=a$ is:\n$$\n\\mathcal{P}(z_i=a) \\propto (n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\nTo obtain the final conditional probability, we normalize over all possible communities $c \\in \\{1, \\dots, K\\}$ for node $i$:\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}, A) = \\frac{\\mathcal{P}(z_i=a)}{\\sum_{c=1}^K \\mathcal{P}(z_i=c)}\n$$\nThis results in the final closed-form expression. The Beta function $B(x,y)$ is a standard special function defined as $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$ for $x > 0, y > 0$.\n\nLet $T_a$ be the unnormalized probability for $z_i = a$:\n$$\nT_a = (n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\nThe final expression is $\\mathbb{P}(z_i=a \\mid z_{-i}, A) = T_a / \\sum_{c=1}^K T_c$.",
            "answer": "$$\n\\boxed{\\frac{(n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}}{\\sum_{c=1}^K \\left( (n_c^{-i} + \\alpha_c) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{cb}^{-i} + \\lambda_{cb}^{+}, n_b^{-i}-k_{ib} + s_{cb}^{-i} + \\lambda_{cb}^{-})}{B(m_{cb}^{-i} + \\lambda_{cb}^{+}, s_{cb}^{-i} + \\lambda_{cb}^{-})} \\right)}}\n$$"
        },
        {
            "introduction": "Theoretical derivations provide insight, but a deep understanding of inference requires seeing how algorithms perform on data, especially under stress. This computational exercise  challenges you to bridge theory and practice by implementing and testing two key algorithms—Spectral Clustering and a Belief Propagation approximation—on SBM graphs subjected to a well-defined adversarial attack. This hands-on experiment offers direct insight into algorithm robustness and failure modes, highlighting the practical challenges of community detection when network data deviates from idealized model assumptions.",
            "id": "4283069",
            "problem": "Consider a symmetric two-community Stochastic Block Model (SBM) on $n$ nodes with equal-sized communities and independent edges. Let the ground-truth community assignment be encoded by a vector $z \\in \\{+1,-1\\}^n$ with exactly $n/2$ entries equal to $+1$ and $n/2$ entries equal to $-1$. Given parameters $p_{\\text{in}} \\in (0,1)$ and $p_{\\text{out}} \\in (0,1)$, an undirected simple graph $A \\in \\{0,1\\}^{n \\times n}$ without self-loops is generated by the following fundamental rule: for each unordered pair $\\{i,j\\}$ with $i \\neq j$, sample $A_{ij} = A_{ji}$ independently with $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$ if $z_i = z_j$ and $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$ if $z_i \\neq z_j$. Define the degree of node $i$ as $d_i = \\sum_{j \\neq i} A_{ij}$.\n\nAn adversary perturbs the graph by flipping the labels of $\\alpha n$ nodes, where $\\alpha \\in [0,0.5]$ is a fraction and $n$ is even. The adversary is adaptive and seeks to degrade community detection. The perturbation is defined purely in terms of the graph and labels as follows:\n\n1. Compute the degrees $d_1,\\dots,d_n$ on the original graph $A$.\n2. Select the set $S$ of $\\alpha n$ nodes with the largest degrees (break ties by increasing node index).\n3. Define the attacked labels $\\tilde{z} \\in \\{+1,-1\\}^n$ by $\\tilde{z}_i = -z_i$ for $i \\in S$ and $\\tilde{z}_i = z_i$ for $i \\notin S$.\n4. Construct the attacked graph $\\tilde{A} \\in \\{0,1\\}^{n \\times n}$ by resampling only the edges incident to attacked nodes while preserving symmetry and leaving unaffected edges unchanged: for each unordered pair $\\{i,j\\}$ with $i \\neq j$,\n   - if $i \\in S$ or $j \\in S$, sample $\\tilde{A}_{ij} = \\tilde{A}_{ji}$ independently with $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$ if $\\tilde{z}_i = \\tilde{z}_j$ and $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$ if $\\tilde{z}_i \\neq \\tilde{z}_j$,\n   - else set $\\tilde{A}_{ij} = A_{ij}$.\n5. All diagonal entries satisfy $\\tilde{A}_{ii} = 0$.\n\nYou will implement two community inference methods that do not use labels, only the attacked graph $\\tilde{A}$ and the known parameters $p_{\\text{in}}$ and $p_{\\text{out}}$:\n\n- Spectral method: classify nodes using the sign of the components of the leading eigenvector of $\\tilde{A}$.\n- Belief Propagation (BP) method via linearization: approximate BP by the Bethe Hessian (BH). Let $D$ be the diagonal degree matrix of $\\tilde{A}$ with $D_{ii} = \\sum_{j \\neq i} \\tilde{A}_{ij}$. Let $\\bar{d} = \\frac{1}{n} \\sum_{i=1}^n D_{ii}$. Define $r = \\sqrt{\\bar{d}}$ and the Bethe Hessian matrix $H(r) = (r^2 - 1) I - r \\tilde{A} + D$, where $I$ is the $n \\times n$ identity matrix. Classify nodes using the sign of the components of the eigenvector of $H(r)$ associated with its smallest eigenvalue.\n\nFor each method, output the misclassification rate relative to the original labels $z$, accounting for the inherent symmetry of two-community assignments. Specifically, if $\\hat{z} \\in \\{+1,-1\\}^n$ are the inferred labels, the misclassification rate is\n$$\\min\\left\\{\\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{\\hat{z}_i \\neq z_i\\}, \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{-\\hat{z}_i \\neq z_i\\}\\right\\}.$$\n\nYour program must:\n\n- Generate the original graph $A$ from an SBM with balanced $z$, perform the adversarial perturbation to obtain $\\tilde{A}$, run both inference methods on $\\tilde{A}$, and compute both misclassification rates with respect to $z$.\n- Use independent randomness for graph generation controlled by the provided seeds.\n- Round each misclassification rate to three decimal places.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order: for each test case, first the spectral method misclassification rate, then the BP (Bethe Hessian) method misclassification rate. For example, an output for two test cases would look like $[\\text{spectral}_1,\\text{bp}_1,\\text{spectral}_2,\\text{bp}_2]$.\n\nTest suite parameter sets to implement (each as a tuple $(n,p_{\\text{in}},p_{\\text{out}},\\alpha,\\text{seed})$):\n\n- $(200, 0.08, 0.02, 0.0, 1)$: happy path, assortative, no attack.\n- $(200, 0.08, 0.02, 0.1, 2)$: assortative, mild attack.\n- $(200, 0.06, 0.04, 0.2, 3)$: assortative, closer to the challenging detection regime, stronger attack.\n- $(200, 0.04, 0.04, 0.2, 4)$: boundary case with $p_{\\text{in}} = p_{\\text{out}}$, no inherent community structure, moderate attack.\n- $(200, 0.02, 0.08, 0.1, 5)$: disassortative structure, mild attack.\n\nYour solution must be purely computational and must not rely on any external labels or training. There are no physical units or angles involved. The expected outputs are floats as specified, and the final output format must strictly follow the single-line list specification above.",
            "solution": "The user-provided problem has been analyzed and validated. It is found to be scientifically grounded, well-posed, objective, and complete. The problem asks for a computational solution involving the generation of graphs from a Stochastic Block Model (SBM), the application of a specified adversarial attack, and the evaluation of two community detection algorithms on the attacked graph. The analysis proceeds as follows.\n\n### Step 1: Initial Setup and Ground Truth Generation\nFor each test case, we are given a set of parameters: the number of nodes $n$, the intra-community edge probability $p_{\\text{in}}$, the inter-community edge probability $p_{\\text{out}}$, the fraction of attacked nodes $\\alpha$, and a random seed for reproducibility.\n\nFirst, we set the random number generator's seed to the provided value. This ensures that the entire process, which involves multiple stochastic steps, is deterministic and reproducible.\n\nNext, we generate the ground-truth community assignment vector $z \\in \\{+1, -1\\}^n$. The problem specifies two equal-sized communities. For a network of $n=200$ nodes, we create a vector $z$ where the first $n/2=100$ entries are $+1$ and the remaining $n/2=100$ entries are $-1$. This vector represents the true, unobserved community structure.\n\n### Step 2: Original Graph Generation ($A$)\nUsing the ground-truth labels $z$, we generate the adjacency matrix $A$ of an undirected simple graph. The matrix $A \\in \\{0, 1\\}^{n \\times n}$ has zeros on its diagonal ($A_{ii}=0$) as there are no self-loops. For each distinct pair of nodes $\\{i, j\\}$ ($i \\neq j$), an edge is created with a probability that depends on their community assignments:\n- If nodes $i$ and $j$ are in the same community ($z_i = z_j$), the edge $A_{ij}$ is drawn from a Bernoulli distribution with parameter $p_{\\text{in}}$, i.e., $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$.\n- If nodes $i$ and $j$ are in different communities ($z_i \\neq z_j$), the edge $A_{ij}$ is drawn from a Bernoulli distribution with parameter $p_{\\text{out}}$, i.e., $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$.\n\nWe construct the symmetric matrix $A$ by iterating through all upper-triangular pairs $(i, j)$ with $i  j$ and setting $A_{ij} = A_{ji}$ based on a single random draw for that pair.\n\n### Step 3: Adversarial Attack\nThe core of the problem involves a specific adversarial attack designed to degrade community detection. This process modifies both the labels and the graph structure.\n\n1.  **Compute Node Degrees**: We first calculate the degree $d_i = \\sum_{j \\neq i} A_{ij}$ for each node $i$ in the original graph $A$.\n2.  **Select Attacked Nodes ($S$)**: We identify the set $S$ of $\\alpha n$ nodes with the highest degrees. To ensure determinism, any ties in degree are broken by selecting the node with the lower index. This is implemented by sorting node indices based on a primary key of descending degree and a secondary key of ascending index.\n3.  **Define Attacked Labels ($\\tilde{z}$)**: A new label vector $\\tilde{z}$ is created. For nodes $i$ in the attacked set $S$, their labels are flipped: $\\tilde{z}_i = -z_i$. For all other nodes $i \\notin S$, the labels remain unchanged: $\\tilde{z}_i = z_i$.\n4.  **Construct Attacked Graph ($\\tilde{A}$)**: A new graph, represented by the adjacency matrix $\\tilde{A}$, is constructed. We start by copying $A$. Then, we resample only the edges incident to the attacked nodes. Specifically, for each pair of nodes $\\{i, j\\}$ where at least one of $i$ or $j$ is in $S$, the corresponding edge $\\tilde{A}_{ij}$ is redrawn from a Bernoulli distribution based on the *attacked* labels $\\tilde{z}$:\n    - If $\\tilde{z}_i = \\tilde{z}_j$, $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$.\n    - If $\\tilde{z}_i \\neq \\tilde{z}_j$, $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$.\n    Edges between pairs of nodes $\\{i, j\\}$ where neither $i$ nor $j$ is in $S$ are left unchanged, i.e., $\\tilde{A}_{ij} = A_{ij}$. The resulting graph $\\tilde{A}$ is symmetric and has a zero diagonal. If $\\alpha=0$, no attack occurs, and $\\tilde{A} = A$.\n\n### Step 4: Community Inference on the Attacked Graph $\\tilde{A}$\nWith the attacked graph $\\tilde{A}$ prepared, we apply two specified community detection algorithms. These algorithms operate solely on $\\tilde{A}$ and the known parameters $p_{\\text{in}}$ and $p_{\\text{out}}$, without access to any version of the labels ($z$ or $\\tilde{z}$).\n\n1.  **Spectral Method**: This method uses the leading eigenvector of the adjacency matrix $\\tilde{A}$. We compute the eigenvalues and eigenvectors of the symmetric matrix $\\tilde{A}$. The leading eigenvector is the one corresponding to the largest (most positive) eigenvalue. The community assignment $\\hat{z}_{\\text{spec}}$ for each node $i$ is determined by the sign of the corresponding component in this eigenvector. If a component is zero, it is arbitrarily assigned to the $+1$ community.\n2.  **Belief Propagation (Bethe Hessian) Method**: This method provides an approximation to Belief Propagation. We construct the Bethe Hessian matrix $H(r)$ for the graph $\\tilde{A}$. The construction requires several intermediate quantities:\n    - The diagonal degree matrix $D$ of $\\tilde{A}$, where $D_{ii} = \\sum_{j \\neq i} \\tilde{A}_{ij}$.\n    - The average degree $\\bar{d} = \\frac{1}{n} \\sum_{i} D_{ii}$.\n    - The parameter $r = \\sqrt{\\bar{d}}$.\n    The Bethe Hessian matrix is then $H(r) = (r^2 - 1)I - r\\tilde{A} + D$, where $I$ is the identity matrix. Community assignment $\\hat{z}_{\\text{BP}}$ is determined by the signs of the components of the eigenvector of $H(r)$ associated with its smallest eigenvalue.\n\n### Step 5: Performance Evaluation\nFor each method, we obtain an inferred label vector $\\hat{z}$. To measure performance, we calculate the misclassification rate relative to the original ground-truth labels $z$. Since the labels $\\{+1, -1\\}$ are interchangeable (a partition $\\{C_1, C_2\\}$ is identical to $\\{C_2, C_1\\}$), we must account for this symmetry. The misclassification rate is therefore defined as:\n$$ \\text{rate} = \\min\\left\\{\\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{\\hat{z}_i \\neq z_i\\}, \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{-\\hat{z}_i \\neq z_i\\}\\right\\} $$\nThis is equivalent to calculating the fraction of mismatched nodes for both possible alignments of the inferred labels with the true labels ($\\hat{z}$ vs $z$ and $-\\hat{z}$ vs $z$) and taking the smaller of the two values.\n\nFinally, the computed misclassification rates for both methods across all test cases are collected, rounded to three decimal places, and formatted into a single output line as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Solves the community detection problem on adversarially attacked SBM graphs.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, p_in, p_out, alpha, seed)\n        (200, 0.08, 0.02, 0.0, 1),\n        (200, 0.08, 0.02, 0.1, 2),\n        (200, 0.06, 0.04, 0.2, 3),\n        (200, 0.04, 0.04, 0.2, 4),\n        (200, 0.02, 0.08, 0.1, 5),\n    ]\n\n    results = []\n    \n    def misclassification_rate(z_hat, z_true):\n        \"\"\"\n        Calculates the misclassification rate, accounting for label swapping symmetry.\n        \"\"\"\n        # Ensure z_hat has no zero entries from np.sign\n        z_hat_clean = z_hat.copy()\n        if 0 in z_hat_clean:\n            z_hat_clean[z_hat_clean == 0] = 1 # Arbitrarily assign 0s to community +1\n        \n        n_nodes = len(z_true)\n        # Calculate error for direct alignment\n        rate1 = np.sum(z_hat_clean != z_true) / n_nodes\n        # Calculate error for flipped alignment\n        rate2 = np.sum(-z_hat_clean != z_true) / n_nodes\n        \n        return min(rate1, rate2)\n\n    for n, p_in, p_out, alpha, seed in test_cases:\n        # 1. Set seed for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 2. Generate ground-truth community assignments z\n        z = np.ones(n, dtype=np.int8)\n        z[n//2:] = -1\n\n        # 3. Generate the original graph A from SBM\n        A = np.zeros((n, n), dtype=np.int8)\n        for i in range(n):\n            for j in range(i + 1, n):\n                prob = p_in if z[i] == z[j] else p_out\n                if rng.random()  prob:\n                    A[i, j] = 1\n                    A[j, i] = 1\n        \n        # 4. Perform the adversarial perturbation\n        num_attacked = int(alpha * n)\n        z_tilde = z.copy()\n        A_tilde = A.copy()\n\n        if num_attacked > 0:\n            # a. Compute degrees on the original graph A\n            degrees = A.sum(axis=1)\n            \n            # b. Select the set S of alpha*n nodes with the largest degrees\n            # Tie-breaking: for equal degrees, prioritize lower index.\n            # np.lexsort sorts by the last key first, so provide (index, -degree).\n            sorted_indices = np.lexsort((np.arange(n), -degrees))\n            S = sorted_indices[:num_attacked]\n            S_set = set(S) # Use a set for efficient lookups\n            \n            # c. Define attacked labels z_tilde\n            z_tilde[S] = -z_tilde[S]\n            \n            # d. Construct attacked graph A_tilde by resampling edges\n            for i in range(n):\n                for j in range(i + 1, n):\n                    if i in S_set or j in S_set:\n                        # This edge is incident to an attacked node, so resample it.\n                        prob_new = p_in if z_tilde[i] == z_tilde[j] else p_out\n                        if rng.random()  prob_new:\n                            A_tilde[i, j] = 1\n                            A_tilde[j, i] = 1\n                        else:\n                            A_tilde[i, j] = 0\n                            A_tilde[j, i] = 0\n\n        # 5. Run inference methods on the attacked graph A_tilde\n        \n        # Spectral method\n        # Eigenvector for the largest eigenvalue of A_tilde\n        # scipy.linalg.eigh returns eigenvalues in ascending order\n        _, vecs_spec = eigh(A_tilde)\n        v_spec = vecs_spec[:, -1] # Last column corresponds to the largest eigenvalue\n        z_hat_spec = np.sign(v_spec)\n        rate_spec = misclassification_rate(z_hat_spec, z)\n        \n        # Belief Propagation (Bethe Hessian) method\n        D_tilde_diag = A_tilde.sum(axis=1)\n        D_tilde = np.diag(D_tilde_diag)\n        d_bar = np.mean(D_tilde_diag)\n        r = np.sqrt(d_bar) if d_bar > 0 else 1.0\n        I = np.identity(n)\n        \n        H_r = (r**2 - 1) * I - r * A_tilde + D_tilde\n        \n        # Eigenvector for the smallest eigenvalue of H(r)\n        _, vecs_bh = eigh(H_r)\n        v_bh = vecs_bh[:, 0] # First column corresponds to the smallest eigenvalue\n        z_hat_bh = np.sign(v_bh)\n        rate_bh = misclassification_rate(z_hat_bh, z)\n        \n        # 6. Store and round results\n        results.append(round(rate_spec, 3))\n        results.append(round(rate_bh, 3))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}