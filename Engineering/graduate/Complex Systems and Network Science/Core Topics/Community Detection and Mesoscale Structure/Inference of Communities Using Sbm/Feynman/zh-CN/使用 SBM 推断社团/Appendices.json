{
    "hands_on_practices": [
        {
            "introduction": "在随机块模型（SBM）的推理任务中，最直接的情形是当社区结构已知时估计模型参数。尽管在现实应用中社区分配通常是未知的，但解决这个“监督”版本的问题是理解更复杂算法（如期望最大化算法）的关键一步。本练习将指导您推导块间连接概率 $P_{ab}$ 的最大似然估计（MLE），揭示最佳参数估计值直观地对应于观测到的块间连边密度。",
            "id": "4283104",
            "problem": "考虑一个有 $n$ 个顶点的简单无向图，无自环，由一个对称邻接矩阵 $A$ 表示，其中 $A_{ii} = 0$ 且对于 $i \\neq j$ 有 $A_{ij} \\in \\{0,1\\}$。假设该图是由随机分块模型（Stochastic Block Model, SBM）生成的，该模型包含 $K$ 个社团。社团分配是给定且固定的，为 $z = (z_{1}, \\dots, z_{n})$，其中 $z_{i} \\in \\{1, \\dots, K\\}$ 表示顶点 $i$ 的社团标签。对于任意一对顶点 $i \\neq j$，边的存在是一个独立的伯努利事件，其参数为 $P_{z_{i} z_{j}}$，其中对于所有 $a,b \\in \\{1, \\dots, K\\}$，都有 $P_{ab} \\in (0,1)$ 且 $P_{ab} = P_{ba}$。\n\n令 $n_{a} = \\sum_{i=1}^{n} \\mathbf{1}\\{z_{i} = a\\}$ 为社团 $a$ 的大小。针对有序顶点对，定义分块边的数量\n$$\nm_{ab} = \\sum_{i : z_{i} = a} \\sum_{j : z_{j} = b,\\, j \\neq i} A_{ij},\n$$\n以及潜在有序顶点对的数量\n$$\nN_{ab} = n_{a} n_{b} - \\delta_{ab} n_{a},\n$$\n其中 $\\delta_{ab}$ 是克罗内克 δ 符号。注意，当 $a \\neq b$ 时，$N_{ab} = n_{a} n_{b}$；当 $a = b$ 时，$N_{aa} = n_{a}(n_{a} - 1)$。\n\n从不同顶点对之间边指示符的独立性以及随机分块模型的伯努利抽样机制出发，使用上面定义的有序对计数 $m_{ab}$ 和 $N_{ab}$，构建在给定固定分配 $z$ 和参数 $\\{P_{ab}\\}_{a,b=1}^{K}$ 的条件下观测到邻接矩阵 $A$ 的似然函数。然后，在 $P_{ab} \\in (0,1)$ 和 $P_{ab} = P_{ba}$ 的约束下，通过最大化关于 $P_{ab}$ 的似然函数，推导出 $P_{ab}$ 的最大似然估计量的闭式表达式，该表达式应表示为 $m_{ab}$ 和 $N_{ab}$ 的函数。\n\n你的最终答案必须是一个以 $m_{ab}$、$n_{a}$、$n_{b}$ 和 $\\delta_{ab}$ 表示的单个闭式解析表达式，且不得包含任何单位。无需进行数值舍入。",
            "solution": "问题要求在已知社团分配的情况下，求解随机分块模型（SBM）中边概率参数 $P_{ab}$ 的最大似然估计（MLE）。\n\n该图是具有 $n$ 个顶点的简单无向图，无自环。邻接矩阵 $A$ 是对称的，对所有 $i$ 都有 $A_{ii} = 0$，且对于 $i \\neq j$ 有 $A_{ij} \\in \\{0, 1\\}$。每个顶点 $i$ 的社团分配是一个固定的、已知的标签 $z_i \\in \\{1, \\dots, K\\}$。对于任意一对不同的顶点 $(i, j)$，边 $A_{ij}$ 是否存在取决于其端点所属的社团，这是一个独立的伯努利试验：\n$$\nA_{ij} \\sim \\text{Bernoulli}(P_{z_i z_j})\n$$\n因此，单个潜在边 $(i,j)$ 的概率质量函数为：\n$$\n\\mathbb{P}(A_{ij} | z_i, z_j, P) = P_{z_i z_j}^{A_{ij}} (1 - P_{z_i z_j})^{1 - A_{ij}}\n$$\n其中 $P$ 表示参数矩阵 $\\{P_{ab}\\}$。无向图模型要求连接概率具有对称性，因此 $P_{ab} = P_{ba}$。\n\n似然函数 $\\mathcal{L}(P | A, z)$ 是在给定参数 $P$ 和社团结构 $z$ 的条件下，观测到给定邻接矩阵 $A$ 的总概率。由于所有潜在的边都是独立的随机变量，似然函数是每个唯一的顶点对的概率之积。对于无向图，我们对每个满足 $i  j$ 的点对 $(i, j)$ 只考虑一次。\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le i  j \\le n} \\mathbb{P}(A_{ij} | z_i, z_j, P) = \\prod_{1 \\le i  j \\le n} P_{z_i z_j}^{A_{ij}} (1 - P_{z_i z_j})^{1 - A_{ij}}\n$$\n为了便于计算，我们根据社团分块将此乘积中的各项分组。令 $C_a = \\{i | z_i = a\\}$ 为社团 $a$ 中的顶点集合。该乘积可以划分为关于社团块对 $(a, b)$（其中 $a \\le b$）的乘积。\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le a \\le b \\le K} \\prod_{\\substack{i \\in C_a, j \\in C_b \\\\ i  j}} P_{ab}^{A_{ij}} (1 - P_{ab})^{1 - A_{ij}}\n$$\n这可以重写为：\n$$\n\\mathcal{L}(P | A, z) = \\prod_{1 \\le a \\le b \\le K} P_{ab}^{E_{ab}} (1 - P_{ab})^{M_{ab} - E_{ab}}\n$$\n其中 $E_{ab}$ 是连接社团 $a$ 中的顶点和社团 $b$ 中的顶点的观测边数，而 $M_{ab}$ 是这些社团之间可能的边总数（对于无序顶点对）。\n\n问题基于有序顶点对给出了分块边数 $m_{ab}$ 和潜在配对数 $N_{ab}$ 的定义。我们必须将 $E_{ab}$ 和 $M_{ab}$ 与这些给定的量联系起来。\n-   对于社团内分块 ($a=b$)：$E_{aa}$ 是社团 $a$ 内部的边数。由于 $A$ 是对称的（$A_{ij} = A_{ji}$），数量 $m_{aa} = \\sum_{i,j \\in C_a, i \\neq j} A_{ij}$ 将每条边计算了两次。因此，$E_{aa} = \\frac{1}{2} m_{aa}$。$M_{aa}$ 是社团 $a$ 内部可能的边数，即顶点对的数量，$\\binom{n_a}{2} = \\frac{n_a(n_a-1)}{2}$。数量 $N_{aa} = n_a(n_a - 1)$ 计算了所有不同的有序顶点对。因此，$M_{aa} = \\frac{1}{2} N_{aa}$。\n\n-   对于社团间分块 ($a \\neq b$)：$E_{ab}$ 是社团 $a$ 和 $b$ 之间的边数。数量 $m_{ab} = \\sum_{i \\in C_a, j \\in C_b} A_{ij}$ 是对所有有序顶点对 $(i,j)$（其中 $i$ 在 $C_a$ 中，$j$ 在 $C_b$ 中）求和。这恰好是连接两个社团的边数。所以，$E_{ab} = m_{ab}$。$M_{ab}$ 是社团 $a$ 和 $b$ 之间可能的边数，即 $n_a n_b$。数量 $N_{ab} = n_a n_b$ 计算了有序对，且等于 $M_{ab}$。所以，$M_{ab} = N_{ab}$。\n\n将这些关系代入似然函数：\n$$\n\\mathcal{L}(P) = \\left( \\prod_{a=1}^K P_{aa}^{m_{aa}/2} (1 - P_{aa})^{(N_{aa} - m_{aa})/2} \\right) \\left( \\prod_{1 \\le a  b \\le K} P_{ab}^{m_{ab}} (1 - P_{ab})^{N_{ab} - m_{ab}} \\right)\n$$\n为了找到最大似然估计，我们最大化对数似然函数 $\\ln \\mathcal{L}(P)$:\n$$\n\\ln \\mathcal{L}(P) = \\sum_{a=1}^K \\frac{1}{2} \\left[ m_{aa}\\ln(P_{aa}) + (N_{aa} - m_{aa})\\ln(1 - P_{aa}) \\right] + \\sum_{1 \\le a  b \\le K} \\left[ m_{ab}\\ln(P_{ab}) + (N_{ab} - m_{ab})\\ln(1 - P_{ab}) \\right]\n$$\n在此表达式中，参数 $\\{P_{ab} | a \\le b\\}$ 是相互独立的。我们可以通过对每个参数求导并令其导数为零来找到最大值。\n\n情况1：社团内参数 $P_{cc}$。\n$$\n\\frac{\\partial \\ln \\mathcal{L}}{\\partial P_{cc}} = \\frac{1}{2} \\left[ \\frac{m_{cc}}{P_{cc}} - \\frac{N_{cc} - m_{cc}}{1 - P_{cc}} \\right] = 0\n$$\n$$\n\\frac{m_{cc}}{P_{cc}} = \\frac{N_{cc} - m_{cc}}{1 - P_{cc}} \\implies m_{cc}(1 - P_{cc}) = P_{cc}(N_{cc} - m_{cc}) \\implies m_{cc} = P_{cc} N_{cc}\n$$\n$$\n\\hat{P}_{cc} = \\frac{m_{cc}}{N_{cc}}\n$$\n\n情况2：社团间参数 $P_{cd}$，其中 $c  d$。\n$$\n\\frac{\\partial \\ln \\mathcal{L}}{\\partial P_{cd}} = \\frac{m_{cd}}{P_{cd}} - \\frac{N_{cd} - m_{cd}}{1 - P_{cd}} = 0\n$$\n$$\n\\frac{m_{cd}}{P_{cd}} = \\frac{N_{cd} - m_{cd}}{1 - P_{cd}} \\implies m_{cd}(1 - P_{cd}) = P_{cd}(N_{cd} - m_{cd}) \\implies m_{cd} = P_{cd} N_{cd}\n$$\n$$\n\\hat{P}_{cd} = \\frac{m_{cd}}{N_{cd}}\n$$\n由于对称性约束 $P_{cd} = P_{dc}$，$P_{dc}$ 的估计量是相同的。注意 $m_{cd} = m_{dc}$ 且 $N_{cd} = N_{dc}$，因此公式是一致的。\n\n结合这两种情况，任何参数 $P_{ab}$ 的最大似然估计由下式给出：\n$$\n\\hat{P}_{ab} = \\frac{m_{ab}}{N_{ab}}\n$$\n问题要求最终答案用 $m_{ab}$、$n_a$、$n_b$ 和克罗内克 δ 符号 $\\delta_{ab}$ 来表示。我们代入 $N_{ab}$ 的给定定义：\n$$\nN_{ab} = n_a n_b - \\delta_{ab} n_a =\n\\begin{cases}\nn_a n_b  \\text{若 } a \\neq b \\\\\nn_a (n_a - 1)  \\text{若 } a = b\n\\end{cases}\n$$\n这就得出了最大似然估计的最终闭式表达式：\n$$\n\\hat{P}_{ab} = \\frac{m_{ab}}{n_a n_b - \\delta_{ab} n_a}\n$$\n这个结果是直观的：两个块之间边的估计概率是它们之间观测到的边密度，该密度是使用有向对计数计算的。二阶条件证实了这确实是一个最大值，因为对数似然函数对于每个 $P_{ab}$ 都是凹函数。",
            "answer": "$$\n\\boxed{\\frac{m_{ab}}{n_{a} n_{b} - \\delta_{ab} n_{a}}}\n$$"
        },
        {
            "introduction": "在更现实的场景中，社区结构和模型参数都是未知的。本练习将引导您进入SBM贝叶斯推理的核心：折叠吉布斯采样（collapsed Gibbs sampling）。通过利用共轭先验（conjugate priors）的优良特性将模型参数（社区比例和连接概率）积分掉，我们可以直接对每个节点的社区归属进行采样，从而有效地探索整个后验分布。",
            "id": "4283118",
            "problem": "考虑一个无向简单网络，该网络有 $n$ 个节点，由一个对称邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示，其中对所有 $i$ 都有 $A_{ii} = 0$。每个节点 $i \\in \\{1,\\dots,n\\}$ 都有一个社群标签 $z_i \\in \\{1,\\dots,K\\}$，这些标签收集在向量 $z = (z_1,\\dots,z_n)$ 中。该网络由一个随机块模型 (SBM) 生成，其分层规范如下：\n\n1. 社群比例 $\\phi = (\\phi_1,\\dots,\\phi_K)$ 从狄利克雷先验 $\\phi \\sim \\text{Dirichlet}(\\alpha_1,\\dots,\\alpha_K)$ 中抽取，其超参数为 $\\alpha_a  0$，其中 $a \\in \\{1,\\dots,K\\}$。\n\n2. 在给定 $\\phi$ 的条件下，标签 $z_i \\mid \\phi \\sim \\text{Categorical}(\\phi)$ 是独立同分布的。\n\n3. 对于每个无序社群对 $(a,b)$（$1 \\leq a \\leq b \\leq K$），边概率 $\\theta_{ab}$ 独立地从贝塔先验 $\\theta_{ab} \\sim \\text{Beta}(\\lambda_{ab}^{+}, \\lambda_{ab}^{-})$ 中抽取，其中 $\\lambda_{ab}^{+}  0$ 和 $\\lambda_{ab}^{-}  0$ 是超参数。对于 $a \\neq b$，$\\theta_{ab} = \\theta_{ba}$；对于社群内部的边，$\\theta_{aa}$ 控制着同在社群 $a$ 中的两个节点之间的边。\n\n4. 在给定 $z$ 和 $\\{\\theta_{ab}\\}$ 的条件下，边是独立的伯努利随机变量：对于 $i  j$，$A_{ij} \\mid z, \\{\\theta_{ab}\\} \\sim \\text{Bernoulli}(\\theta_{z_i z_j})$，其中 $A_{ji} = A_{ij}$ 且 $A_{ii} = 0$。\n\n定义排除节点 $i$ 后的以下计数：\n\n- 对于每个社群 $b$，令 $n_b^{-i} = |\\{j \\neq i : z_j = b\\}|$ 表示当前在社群 $b$ 中除节点 $i$ 之外的节点数。\n\n- 令 $k_{ib} = \\sum_{j \\neq i,\\, z_j = b} A_{ij}$ 表示从节点 $i$ 到社群 $b$ 中节点的观测边数。\n\n- 对于每个无序对 $(a,b)$（$1 \\leq a \\leq b \\leq K$），令 $m_{ab}^{-i}$ 表示在排除节点 $i$ 的节点中，其标签分别属于社群 $a$ 和 $b$ 的节点之间的边数；对于 $a \\neq b$，这是一个端点在社群 $a$、另一个端点在社群 $b$ 的边的计数；对于 $a=b$，这是在标记为 $a$ 的节点中（不包括节点 $i$）的社群内部边计数。\n\n- 令 $N_{ab}^{-i}$ 表示在排除节点 $i$ 的节点中，社群对 $(a,b)$ 的潜在无序节点对的数量；对于 $a \\neq b$，$N_{ab}^{-i} = n_a^{-i} n_b^{-i}$，对于 $a = b$，$N_{aa}^{-i} = \\binom{n_a^{-i}}{2}$。定义相应的非边计数 $s_{ab}^{-i} = N_{ab}^{-i} - m_{ab}^{-i}$。\n\n从上述分层模型出发，仅使用基本的概率定义和经过验证的共轭关系，通过计算条件概率 $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$ 来推导单个标签 $z_i$ 的折叠吉布斯采样更新，其中 $z_{-i} = (z_1,\\dots,z_{i-1},z_{i+1},\\dots,z_n)$ 表示除节点 $i$ 之外所有节点的标签。您的推导必须积分掉社群比例 $\\phi$ 和所有边概率 $\\{\\theta_{ab}\\}$，并仅用局部边计数 $\\{k_{ib}\\}$、排除计数 $\\{n_b^{-i}\\}$、成对排除计数 $\\{m_{ab}^{-i}, s_{ab}^{-i}\\}$ 以及超参数 $\\{\\alpha_a\\}$ 和 $\\{\\lambda_{ab}^{+}, \\lambda_{ab}^{-}\\}$ 来表示最终的闭式条件概率。\n\n请以单一解析公式的形式给出 $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$ 的最终表达式。无需进行数值评估。如果引入特殊函数，请明确定义它们。请用单个闭式解析表达式来表述您的最终答案。无需四舍五入。",
            "solution": "目标是推导单个节点 $i$ 的社群标签 $z_i$ 的折叠吉布斯采样更新。这需要为提议的社群 $a \\in \\{1, \\dots, K\\}$ 计算条件概率 $\\mathbb{P}(z_i = a \\mid z_{-i}, A)$，其中 $z_{-i}$ 代表所有其他节点的标签，$A$ 是邻接矩阵。采样器的“折叠”性质意味着模型参数——社群比例 $\\phi$ 和边概率 $\\{\\theta_{ab}\\}$——必须被积分掉。\n\n根据贝叶斯定理，所求的条件概率与给定所有其他节点的标签 $z_{-i}$ 时，标签 $z_i=a$ 和观测图 $A$ 的联合概率成正比：\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}, A) \\propto \\mathbb{P}(z_i = a, A \\mid z_{-i})\n$$\n我们可以将右侧的联合概率分解为：\n$$\n\\mathbb{P}(z_i = a, A \\mid z_{-i}) = \\mathbb{P}(A \\mid z_i = a, z_{-i}) \\mathbb{P}(z_i = a \\mid z_{-i})\n$$\n推导过程通过计算右侧的两项来进行，并在模型参数上进行边缘化。令 $\\alpha_0 = \\sum_{c=1}^K \\alpha_c$。\n\n首先，我们推导在给定所有其他分配的情况下，将节点 $i$ 分配给社群 $a$ 的先验概率 $\\mathbb{P}(z_i = a \\mid z_{-i})$。\n社群标签 $z$ 由狄利克雷-多项分布过程生成。参数 $\\phi$ 从 $\\text{Dirichlet}(\\alpha_1, \\dots, \\alpha_K)$ 分布中抽取，在给定 $\\phi$ 的情况下，标签从 $\\text{Categorical}(\\phi)$ 分布中抽取。一组标签的边缘概率通过对 $\\phi$ 积分得到：\n$$\n\\mathbb{P}(z) = \\int \\mathbb{P}(z \\mid \\phi) \\mathbb{P}(\\phi) d\\phi\n$$\n给定计数 $n_b = |\\{j : z_j = b\\}|$，我们有 $\\mathbb{P}(z \\mid \\phi) = \\prod_{b=1}^K \\phi_b^{n_b}$ 和 $\\mathbb{P}(\\phi) \\propto \\prod_{b=1}^K \\phi_b^{\\alpha_b-1}$。该积分是狄利克雷-多项分布的一个标准结果：\n$$\n\\mathbb{P}(z) = \\frac{\\Gamma(\\alpha_0)}{\\Gamma(n + \\alpha_0)} \\prod_{b=1}^K \\frac{\\Gamma(n_b + \\alpha_b)}{\\Gamma(\\alpha_b)}\n$$\n条件概率 $\\mathbb{P}(z_i = a \\mid z_{-i})$ 是新观测值的后验预测概率，由比率 $\\frac{\\mathbb{P}(z_i=a, z_{-i})}{\\mathbb{P}(z_{-i})}$ 给出。使用上述 $\\mathbb{P}(z)$ 的公式，并注意对于 $z=(z_i=a, z_{-i})$，计数为 $n_a = n_a^{-i}+1$ 和 $n_b = n_b^{-i}$（对于 $b \\neq a$），总节点数为 $n$。对于 $z_{-i}$，计数为 $n_b^{-i}$，总节点数为 $n-1$。\n这得出了众所周知的结果：\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}) = \\frac{n_a^{-i} + \\alpha_a}{\\sum_{c=1}^K (n_c^{-i} + \\alpha_c)} = \\frac{n_a^{-i} + \\alpha_a}{(n-1) + \\alpha_0}\n$$\n由于我们关心的是比例关系，我们可以写成：\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}) \\propto n_a^{-i} + \\alpha_a\n$$\n\n其次，我们推导在给定完整标签分配 $z = (z_i=a, z_{-i})$ 的情况下，图的似然，并在边概率 $\\{\\theta_{ab}\\}$ 上进行边缘化。\n在给定 $z$ 和 $\\{\\theta_{ab}\\}$ 的条件下，边是条件独立的伯努利试验。每个无序块 $\\{a, b\\}$ 的边概率 $\\theta_{ab}$ 独立地从 $\\text{Beta}(\\lambda_{ab}^{+}, \\lambda_{ab}^{-})$ 先验中抽取。这种贝塔-伯努利结构是共轭的。\n给定一个完整标签 $z$ 时，图 $A$ 的边缘似然为：\n$$\n\\mathbb{P}(A \\mid z) = \\int \\mathbb{P}(A \\mid z, \\{\\theta_{ab}\\}) \\mathbb{P}(\\{\\theta_{ab}\\}) d\\{\\theta_{ab}\\}\n$$\n由于先验的独立性，这可以分解为各个块的乘积：\n$$\n\\mathbb{P}(A \\mid z) = \\prod_{1 \\le c \\le d \\le K} \\int \\theta_{cd}^{m_{cd}}(1-\\theta_{cd})^{s_{cd}} \\frac{\\theta_{cd}^{\\lambda_{cd}^{+}-1}(1-\\theta_{cd})^{\\lambda_{cd}^{-}-1}}{B(\\lambda_{cd}^{+}, \\lambda_{cd}^{-})} d\\theta_{cd}\n$$\n其中 $m_{cd}$ 和 $s_{cd}$ 是完整图中块 $\\{c,d\\}$ 的边和非边的总计数。该积分的计算结果为贝塔函数之比：\n$$\n\\mathbb{P}(A \\mid z) = \\prod_{1 \\le c \\le d \\le K} \\frac{B(m_{cd} + \\lambda_{cd}^{+}, s_{cd} + \\lambda_{cd}^{-})}{B(\\lambda_{cd}^{+}, \\lambda_{cd}^{-})}\n$$\n其中贝塔函数为 $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$。\n\n为了计算项 $\\mathbb{P}(A \\mid z_i = a, z_{-i})$，我们可以将图 $A$ 的似然分解为不涉及节点 $i$ 的边的似然 $A^{-i}$，以及与节点 $i$ 相关联的边的似然，我们将其表示为 $A_{i, \\cdot}$。\n$$\n\\mathbb{P}(A \\mid z_i = a, z_{-i}) = \\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i}) \\mathbb{P}(A^{-i} \\mid z_{-i})\n$$\n项 $\\mathbb{P}(A^{-i} \\mid z_{-i})$ 对于 $z_i$ 的社群选择 $a$ 是一个常数，因此可以被吸收到比例常数中。我们剩下的是节点 $i$ 的边的后验预测概率。\n$$\n\\mathbb{P}(A \\mid z_i = a, z_{-i}) \\propto \\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i})\n$$\n从节点 $i$ 到特定社群 $b$ 中节点的边是 $n_b^{-i}$ 次参数为 $\\theta_{ab}$ 的伯努利试验。有 $k_{ib}$ 条观测到的边（成功）和 $n_b^{-i} - k_{ib}$ 条非边（失败）。在观测到节点 $z_{-i}$ 之间的图 $A^{-i}$ 后，$\\theta_{ab}$ 的后验分布是 $\\text{Beta}(\\theta_{ab} \\mid m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})$。\n从节点 $i$ 到社群 $b$ 的边的预测概率由贝塔-二项预测分布给出：\n$$\n\\mathbb{P}(\\{A_{ij}\\}_{j: z_j=b} \\mid z_i=a, z_{-i}, A^{-i}) = \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, (n_b^{-i}-k_{ib}) + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\n由于不同块的边概率是独立的，节点 $i$ 所有边的总预测似然是所有社群 $b \\in \\{1, \\dots, K\\}$ 上各项的乘积：\n$$\n\\mathbb{P}(A_{i, \\cdot} \\mid z_i=a, z_{-i}, A^{-i}) = \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\n请注意，计数 $m_{ab}^{-i}, s_{ab}^{-i}$ 和超参数 $\\lambda_{ab}^{\\pm}$ 是为无序对定义的，因此它们是对称的，即 $m_{ab}^{-i}=m_{ba}^{-i}$。\n\n结合先验项和似然项，$z_i=a$ 的未归一化概率为：\n$$\n\\mathcal{P}(z_i=a) \\propto (n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\n为了得到最终的条件概率，我们对节点 $i$ 的所有可能社群 $c \\in \\{1, \\dots, K\\}$ 进行归一化：\n$$\n\\mathbb{P}(z_i = a \\mid z_{-i}, A) = \\frac{\\mathcal{P}(z_i=a)}{\\sum_{c=1}^K \\mathcal{P}(z_i=c)}\n$$\n这就得到了最终的闭式表达式。贝塔函数 $B(x,y)$ 是一个标准的特殊函数，定义为 $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$，其中 $x > 0, y > 0$。\n\n令 $T_a$ 为 $z_i = a$ 的未归一化概率：\n$$\nT_a = (n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}\n$$\n最终表达式为 $\\mathbb{P}(z_i=a \\mid z_{-i}, A) = T_a / \\sum_{c=1}^K T_c$。",
            "answer": "$$\n\\boxed{\\frac{(n_a^{-i} + \\alpha_a) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{ab}^{-i} + \\lambda_{ab}^{+}, n_b^{-i}-k_{ib} + s_{ab}^{-i} + \\lambda_{ab}^{-})}{B(m_{ab}^{-i} + \\lambda_{ab}^{+}, s_{ab}^{-i} + \\lambda_{ab}^{-})}}{\\sum_{c=1}^K \\left( (n_c^{-i} + \\alpha_c) \\prod_{b=1}^K \\frac{B(k_{ib} + m_{cb}^{-i} + \\lambda_{cb}^{+}, n_b^{-i}-k_{ib} + s_{cb}^{-i} + \\lambda_{cb}^{-})}{B(m_{cb}^{-i} + \\lambda_{cb}^{+}, s_{cb}^{-i} + \\lambda_{cb}^{-})} \\right)}}\n$$"
        },
        {
            "introduction": "理论的价值最终需要通过实践来检验。最后的这个练习将我们从解析推导带入计算模拟的世界，旨在比较两种流行的社区发现算法——谱聚类（spectral clustering）和基于置信度传播（Belief Propagation）的方法——在面对特定对抗性攻击时的稳健性。通过亲手实现这些算法并评估它们在非理想条件下的表现，您将对不同方法的优势与局限获得具体而深入的理解。",
            "id": "4283069",
            "problem": "考虑一个对称的双社群随机区块模型（SBM），该模型建立在 $n$ 个节点上，社群大小相等，边独立生成。设真实的社群分配由一个向量 $z \\in \\{+1,-1\\}^n$ 编码，其中恰好有 $n/2$ 个条目等于 $+1$， $n/2$ 个条目等于 $-1$。给定参数 $p_{\\text{in}} \\in (0,1)$ 和 $p_{\\text{out}} \\in (0,1)$，一个无向简单图 $A \\in \\{0,1\\}^{n \\times n}$（无自环）通过以下基本规则生成：对于每个 $i \\neq j$ 的无序对 $\\{i,j\\}$，如果 $z_i = z_j$，则独立采样 $A_{ij} = A_{ji}$，其中 $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$；如果 $z_i \\neq z_j$，则 $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$。将节点 $i$ 的度定义为 $d_i = \\sum_{j \\neq i} A_{ij}$。\n\n一个攻击者通过翻转 $\\alpha n$ 个节点的标签来扰动图，其中 $\\alpha \\in [0,0.5]$ 是一个分数，且 $n$ 为偶数。该攻击者是自适应的，旨在降低社群检测的性能。该扰动纯粹根据图和标签定义如下：\n\n1. 在原始图 $A$ 上计算度 $d_1,\\dots,d_n$。\n2. 选择度最大的 $\\alpha n$ 个节点集合 $S$（通过增加节点索引来打破平局）。\n3. 定义受攻击的标签 $\\tilde{z} \\in \\{+1,-1\\}^n$，对于 $i \\in S$，$\\tilde{z}_i = -z_i$；对于 $i \\notin S$，$\\tilde{z}_i = z_i$。\n4. 通过仅重新采样与受攻击节点关联的边来构建受攻击的图 $\\tilde{A} \\in \\{0,1\\}^{n \\times n}$，同时保持对称性并保持未受影响的边不变：对于每个 $i \\neq j$ 的无序对 $\\{i,j\\}$，\n   - 如果 $i \\in S$ 或 $j \\in S$，则根据 $\\tilde{z}_i = \\tilde{z}_j$ 的情况独立采样 $\\tilde{A}_{ij} = \\tilde{A}_{ji}$，其中 $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$；如果 $\\tilde{z}_i \\neq \\tilde{z}_j$，则 $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$，\n   - 否则，设置 $\\tilde{A}_{ij} = A_{ij}$。\n5. 所有对角线元素满足 $\\tilde{A}_{ii} = 0$。\n\n您将实现两种社群推断方法，这些方法不使用标签，仅使用受攻击的图 $\\tilde{A}$ 和已知参数 $p_{\\text{in}}$ 和 $p_{\\text{out}}$：\n\n- 谱方法：使用 $\\tilde{A}$ 的主特征向量分量的符号对节点进行分类。\n- 通过线性化实现的置信传播（BP）方法：通过 Bethe Hessian（BH）矩阵近似 BP。设 $D$ 是 $\\tilde{A}$ 的对角度矩阵，其中 $D_{ii} = \\sum_{j \\neq i} \\tilde{A}_{ij}$。设 $\\bar{d} = \\frac{1}{n} \\sum_{i=1}^n D_{ii}$。定义 $r = \\sqrt{\\bar{d}}$ 和 Bethe Hessian 矩阵 $H(r) = (r^2 - 1) I - r \\tilde{A} + D$，其中 $I$ 是 $n \\times n$ 的单位矩阵。使用与 $H(r)$ 的最小特征值相关联的特征向量的分量符号对节点进行分类。\n\n对于每种方法，输出相对于原始标签 $z$ 的错分率，同时考虑到双社群分配的内在对称性。具体来说，如果 $\\hat{z} \\in \\{+1,-1\\}^n$ 是推断出的标签，则错分率为\n$$\\min\\left\\{\\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{\\hat{z}_i \\neq z_i\\}, \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{-\\hat{z}_i \\neq z_i\\}\\right\\}.$$\n\n您的程序必须：\n\n- 从具有平衡 $z$ 的 SBM 生成原始图 $A$，执行对抗性扰动以获得 $\\tilde{A}$，在 $\\tilde{A}$ 上运行两种推断方法，并计算相对于 $z$ 的两种错分率。\n- 使用由提供的种子控制的独立随机性进行图生成。\n- 将每个错分率四舍五入到三位小数。\n- 生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，其顺序为：对于每个测试用例，首先是谱方法的错分率，然后是 BP（Bethe Hessian）方法的错分率。例如，两个测试用例的输出将类似于 $[\\text{spectral}_1,\\text{bp}_1,\\text{spectral}_2,\\text{bp}_2]$。\n\n需要实现的测试套件参数集（每个参数集为一个元组 $(n,p_{\\text{in}},p_{\\text{out}},\\alpha,\\text{seed})$）：\n\n- $(200, 0.08, 0.02, 0.0, 1)$：理想情况，同配性，无攻击。\n- $(200, 0.08, 0.02, 0.1, 2)$：同配性，轻度攻击。\n- $(200, 0.06, 0.04, 0.2, 3)$：同配性，接近具有挑战性的检测范围，更强的攻击。\n- $(200, 0.04, 0.04, 0.2, 4)$：边界情况，$p_{\\text{in}} = p_{\\text{out}}$，无内在社群结构，中度攻击。\n- $(200, 0.02, 0.08, 0.1, 5)$：异配性结构，轻度攻击。\n\n您的解决方案必须是纯计算性的，不得依赖任何外部标签或训练。不涉及任何物理单位或角度。预期的输出是指定格式的浮点数，最终输出格式必须严格遵循上述单行列表规范。",
            "solution": "用户提供的问题已经过分析和验证。该问题被认为是科学上合理的、适定的、客观的和完整的。问题要求一个计算解决方案，涉及从随机区块模型（SBM）生成图，应用指定的对抗性攻击，以及在受攻击的图上评估两种社群检测算法。分析过程如下。\n\n### 第 1 步：初始设置与真实情况生成\n对于每个测试用例，我们都给定一组参数：节点数 $n$，社群内连边概率 $p_{\\text{in}}$，社群间连边概率 $p_{\\text{out}}$，受攻击节点的分数 $\\alpha$，以及一个用于可复现性的随机种子。\n\n首先，我们将随机数生成器的种子设置为提供的值。这确保了整个涉及多个随机步骤的过程是确定性的和可复现的。\n\n接下来，我们生成真实的社群分配向量 $z \\in \\{+1, -1\\}^n$。问题指定了两个大小相等的社群。对于一个 $n=200$ 个节点的网络，我们创建一个向量 $z$，其中前 $n/2=100$ 个条目为 $+1$，其余 $n/2=100$ 个条目为 $-1$。该向量代表了真实的、未被观测到的社群结构。\n\n### 第 2 步：原始图生成（$A$）\n使用真实的标签 $z$，我们生成一个无向简单图的邻接矩阵 $A$。该矩阵 $A \\in \\{0, 1\\}^{n \\times n}$ 的对角线元素为零（$A_{ii}=0$），因为没有自环。对于每个不同的节点对 $\\{i, j\\}$ ($i \\neq j$)，根据它们的社群分配以一定的概率创建一条边：\n- 如果节点 $i$ 和 $j$ 在同一个社群中（$z_i = z_j$），则边 $A_{ij}$ 从参数为 $p_{\\text{in}}$ 的伯努利分布中抽取，即 $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$。\n- 如果节点 $i$ 和 $j$ 在不同的社群中（$z_i \\neq z_j$），则边 $A_{ij}$ 从参数为 $p_{\\text{out}}$ 的伯努利分布中抽取，即 $A_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$。\n\n我们通过遍历所有上三角对 $(i, j)$（其中 $i  j$）并基于对该对的单次随机抽取设置 $A_{ij} = A_{ji}$ 来构建对称矩阵 $A$。\n\n### 第 3 步：对抗性攻击\n问题的核心涉及一种旨在降低社群检测性能的特定对抗性攻击。此过程会修改标签和图结构。\n\n1.  **计算节点度**：我们首先计算原始图 $A$ 中每个节点 $i$ 的度 $d_i = \\sum_{j \\neq i} A_{ij}$。\n2.  **选择受攻击的节点（$S$）**：我们识别出度最高的 $\\alpha n$ 个节点的集合 $S$。为确保确定性，任何度的平局都通过选择索引较小的节点来打破。这是通过以降序的度为主键、升序的索引为次键对节点索引进行排序来实现的。\n3.  **定义受攻击的标签（$\\tilde{z}$）**：创建一个新的标签向量 $\\tilde{z}$。对于受攻击集合 $S$ 中的节点 $i$，其标签被翻转：$\\tilde{z}_i = -z_i$。对于所有其他节点 $i \\notin S$，标签保持不变：$\\tilde{z}_i = z_i$。\n4.  **构建受攻击的图（$\\tilde{A}$）**：构建一个由邻接矩阵 $\\tilde{A}$ 表示的新图。我们从复制 $A$ 开始。然后，我们只重新采样与受攻击节点关联的边。具体来说，对于每个节点对 $\\{i, j\\}$，其中 $i$ 或 $j$ 中至少有一个在 $S$ 中，相应的边 $\\tilde{A}_{ij}$ 将根据*受攻击的*标签 $\\tilde{z}$ 从伯努利分布中重新抽取：\n    - 如果 $\\tilde{z}_i = \\tilde{z}_j$，则 $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{in}})$。\n    - 如果 $\\tilde{z}_i \\neq \\tilde{z}_j$，则 $\\tilde{A}_{ij} \\sim \\mathrm{Bernoulli}(p_{\\text{out}})$。\n对于节点对 $\\{i, j\\}$，如果 $i$ 和 $j$ 都不在 $S$ 中，它们之间的边保持不变，即 $\\tilde{A}_{ij} = A_{ij}$。最终得到的图 $\\tilde{A}$ 是对称的，并且对角线为零。如果 $\\alpha=0$，则不发生攻击，且 $\\tilde{A} = A$。\n\n### 第 4 步：在受攻击的图 $\\tilde{A}$ 上进行社群推断\n准备好受攻击的图 $\\tilde{A}$ 后，我们应用两种指定的社群检测算法。这些算法仅在 $\\tilde{A}$ 和已知参数 $p_{\\text{in}}$ 和 $p_{\\text{out}}$ 上运行，无法访问任何版本的标签（$z$ 或 $\\tilde{z}$）。\n\n1.  **谱方法**：此方法使用邻接矩阵 $\\tilde{A}$ 的主特征向量。我们计算对称矩阵 $\\tilde{A}$ 的特征值和特征向量。主特征向量是对应于最大（最正）特征值的那个。每个节点 $i$ 的社群分配 $\\hat{z}_{\\text{spec}}$ 由该特征向量中相应分量的符号确定。如果分量为零，则任意将其分配给 $+1$ 社群。\n2.  **置信传播（Bethe Hessian）方法**：此方法提供了对置信传播的一种近似。我们为图 $\\tilde{A}$ 构建 Bethe Hessian 矩阵 $H(r)$。构建过程需要几个中间量：\n    - $\\tilde{A}$ 的对角度矩阵 $D$，其中 $D_{ii} = \\sum_{j \\neq i} \\tilde{A}_{ij}$。\n    - 平均度 $\\bar{d} = \\frac{1}{n} \\sum_{i} D_{ii}$。\n    - 参数 $r = \\sqrt{\\bar{d}}$。\n然后 Bethe Hessian 矩阵为 $H(r) = (r^2 - 1)I - r\\tilde{A} + D$，其中 $I$ 是单位矩阵。社群分配 $\\hat{z}_{\\text{BP}}$ 由与 $H(r)$ 的最小特征值相关联的特征向量的分量符号确定。\n\n### 第 5 步：性能评估\n对于每种方法，我们都获得一个推断出的标签向量 $\\hat{z}$。为了衡量性能，我们计算相对于原始真实标签 $z$ 的错分率。由于标签 $\\{+1, -1\\}$ 是可互换的（一个分区 $\\{C_1, C_2\\}$ 与 $\\{C_2, C_1\\}$ 相同），我们必须考虑这种对称性。因此，错分率定义为：\n$$ \\text{rate} = \\min\\left\\{\\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{\\hat{z}_i \\neq z_i\\}, \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{-\\hat{z}_i \\neq z_i\\}\\right\\} $$\n这等效于计算推断标签与真实标签两种可能对齐方式（$\\hat{z}$ vs $z$ 和 $-\\hat{z}$ vs $z$）下不匹配节点的比例，并取两者中的较小值。\n\n最后，将所有测试用例中两种方法计算出的错分率收集起来，四舍五入到三位小数，并按指定格式化为单行输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Solves the community detection problem on adversarially attacked SBM graphs.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, p_in, p_out, alpha, seed)\n        (200, 0.08, 0.02, 0.0, 1),\n        (200, 0.08, 0.02, 0.1, 2),\n        (200, 0.06, 0.04, 0.2, 3),\n        (200, 0.04, 0.04, 0.2, 4),\n        (200, 0.02, 0.08, 0.1, 5),\n    ]\n\n    results = []\n    \n    def misclassification_rate(z_hat, z_true):\n        \"\"\"\n        Calculates the misclassification rate, accounting for label swapping symmetry.\n        \"\"\"\n        # Ensure z_hat has no zero entries from np.sign\n        z_hat_clean = z_hat.copy()\n        if 0 in z_hat_clean:\n            z_hat_clean[z_hat_clean == 0] = 1 # Arbitrarily assign 0s to community +1\n        \n        n_nodes = len(z_true)\n        # Calculate error for direct alignment\n        rate1 = np.sum(z_hat_clean != z_true) / n_nodes\n        # Calculate error for flipped alignment\n        rate2 = np.sum(-z_hat_clean != z_true) / n_nodes\n        \n        return min(rate1, rate2)\n\n    for n, p_in, p_out, alpha, seed in test_cases:\n        # 1. Set seed for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 2. Generate ground-truth community assignments z\n        z = np.ones(n, dtype=np.int8)\n        z[n//2:] = -1\n\n        # 3. Generate the original graph A from SBM\n        A = np.zeros((n, n), dtype=np.int8)\n        for i in range(n):\n            for j in range(i + 1, n):\n                prob = p_in if z[i] == z[j] else p_out\n                if rng.random()  prob:\n                    A[i, j] = 1\n                    A[j, i] = 1\n        \n        # 4. Perform the adversarial perturbation\n        num_attacked = int(alpha * n)\n        z_tilde = z.copy()\n        A_tilde = A.copy()\n\n        if num_attacked > 0:\n            # a. Compute degrees on the original graph A\n            degrees = A.sum(axis=1)\n            \n            # b. Select the set S of alpha*n nodes with the largest degrees\n            # Tie-breaking: for equal degrees, prioritize lower index.\n            # np.lexsort sorts by the last key first, so provide (index, -degree).\n            sorted_indices = np.lexsort((np.arange(n), -degrees))\n            S = sorted_indices[:num_attacked]\n            S_set = set(S) # Use a set for efficient lookups\n            \n            # c. Define attacked labels z_tilde\n            z_tilde[S] = -z_tilde[S]\n            \n            # d. Construct attacked graph A_tilde by resampling edges\n            for i in range(n):\n                for j in range(i + 1, n):\n                    if i in S_set or j in S_set:\n                        # This edge is incident to an attacked node, so resample it.\n                        prob_new = p_in if z_tilde[i] == z_tilde[j] else p_out\n                        if rng.random()  prob_new:\n                            A_tilde[i, j] = 1\n                            A_tilde[j, i] = 1\n                        else:\n                            A_tilde[i, j] = 0\n                            A_tilde[j, i] = 0\n\n        # 5. Run inference methods on the attacked graph A_tilde\n        \n        # Spectral method\n        # Eigenvector for the largest eigenvalue of A_tilde\n        # scipy.linalg.eigh returns eigenvalues in ascending order\n        _, vecs_spec = eigh(A_tilde)\n        v_spec = vecs_spec[:, -1] # Last column corresponds to the largest eigenvalue\n        z_hat_spec = np.sign(v_spec)\n        rate_spec = misclassification_rate(z_hat_spec, z)\n        \n        # Belief Propagation (Bethe Hessian) method\n        D_tilde_diag = A_tilde.sum(axis=1)\n        D_tilde = np.diag(D_tilde_diag)\n        d_bar = np.mean(D_tilde_diag)\n        r = np.sqrt(d_bar) if d_bar > 0 else 1.0\n        I = np.identity(n)\n        \n        H_r = (r**2 - 1) * I - r * A_tilde + D_tilde\n        \n        # Eigenvector for the smallest eigenvalue of H(r)\n        _, vecs_bh = eigh(H_r)\n        v_bh = vecs_bh[:, 0] # First column corresponds to the smallest eigenvalue\n        z_hat_bh = np.sign(v_bh)\n        rate_bh = misclassification_rate(z_hat_bh, z)\n        \n        # 6. Store and round results\n        results.append(round(rate_spec, 3))\n        results.append(round(rate_bh, 3))\n\n    # Final print statement in the exact required format.\n    # Convert floats to strings, handling cases like 0.0 -> \"0.0\" if needed.\n    # map(str,...) is sufficient for the required output precision.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}