{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the Hyperlink-Induced Topic Search (HITS) algorithm, there's no substitute for working through the mechanics by hand. This exercise takes you through the fundamental iterative process on a small, well-defined network . By manually computing the hub and authority scores and applying the required normalization at each step, you will build a concrete intuition for the mutual reinforcement at the heart of the algorithm.",
            "id": "4281863",
            "problem": "Consider a directed network of $4$ nodes with adjacency matrix $A \\in \\mathbb{R}^{4 \\times 4}$, where $A_{ij} = 1$ if there is a directed edge from node $i$ to node $j$, and $A_{ij} = 0$ otherwise. The network is given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0 & 1 & 1 & 0 \\\\\n0 & 0 & 1 & 1 \\\\\n0 & 1 & 0 & 1 \\\\\n0 & 1 & 0 & 0\n\\end{pmatrix}.\n$$\nIn the Hyperlink-Induced Topic Search (HITS) algorithm, each node is assigned a hub score and an authority score. The fundamental definitions are: an authority score of a node is proportional to the sum of the hub scores of nodes that point to it, and a hub score of a node is proportional to the sum of the authority scores of nodes it points to.\n\nStarting from the initial hub vector $h^{(0)} \\in \\mathbb{R}^{4}$ chosen to be unit length with equal components, that is\n$$\nh^{(0)} \\;=\\; \\frac{1}{\\sqrt{4}} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix},\n$$\nperform exactly $2$ full iterations of the HITS update process as follows. In each full iteration, first compute the authority vector from the hub vector using the proportionality definition, then normalize the authority vector to have Euclidean norm $1$; next compute the hub vector from the authority vector using the proportionality definition, then normalize the hub vector to have Euclidean norm $1$. At each sub-step, explicitly show the unnormalized vector, the normalization factor, and the normalized vector, thereby tracking the evolution of $a$ and $h$.\n\nUsing only the fundamental definitions stated above as the starting point, derive the linear updates needed and carry out the computations with the given $A$ and $h^{(0)}$. At the end of the second authority-update normalization, what is the exact value of the authority score of node $2$, namely $a^{(2)}_{2}$? Provide your answer as a single closed-form expression. Do not round your answer.",
            "solution": "The problem asks for a specific authority score after two full iterations of the Hyperlink-Induced Topic Search (HITS) algorithm on a given network. First, we must formalize the update rules based on the provided definitions.\n\nLet $a = (a_1, a_2, \\dots, a_N)^T$ be the authority vector and $h = (h_1, h_2, \\dots, h_N)^T$ be the hub vector for a network of $N$ nodes. The adjacency matrix is $A$, where $A_{ij}=1$ if a directed edge exists from node $i$ to node $j$.\n\nThe definitions provided are:\n1.  The authority score of a node $j$, $a_j$, is proportional to the sum of the hub scores of nodes that point to it. The nodes $i$ that point to node $j$ are those for which $A_{ij}=1$. Thus,\n    $$a_j \\propto \\sum_{i=1}^N A_{ij} h_i$$\n    This is the $j$-th component of the vector product $A^T h$. So, the unnormalized authority vector, which we denote as $\\tilde{a}$, is given by the update rule:\n    $$\\tilde{a} = A^T h$$\n\n2.  The hub score of a node $i$, $h_i$, is proportional to the sum of the authority scores of nodes it points to. The nodes $j$ that node $i$ points to are those for which $A_{ij}=1$. Thus,\n    $$h_i \\propto \\sum_{j=1}^N A_{ij} a_j$$\n    This is the $i$-th component of the vector product $A a$. So, the unnormalized hub vector, $\\tilde{h}$, is given by the update rule:\n    $$\\tilde{h} = A a$$\n\nA full iteration, updating from step $k$ to $k+1$, consists of an authority update followed by a hub update, with normalization at each stage.\nLet $h^{(k)}$ be the normalized hub vector at step $k$.\n1.  Compute the unnormalized authority vector: $\\tilde{a}^{(k+1)} = A^T h^{(k)}$.\n2.  Normalize to get the authority vector: $a^{(k+1)} = \\frac{\\tilde{a}^{(k+1)}}{\\|\\tilde{a}^{(k+1)}\\|}$, where $\\|\\cdot\\|$ denotes the Euclidean norm.\n3.  Compute the unnormalized hub vector: $\\tilde{h}^{(k+1)} = A a^{(k+1)}$.\n4.  Normalize to get the hub vector: $h^{(k+1)} = \\frac{\\tilde{h}^{(k+1)}}{\\|\\tilde{h}^{(k+1)}\\|}$.\n\nThe problem provides the adjacency matrix for a network of $N=4$ nodes:\n$$A = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 1 & 0 & 0 \\end{pmatrix}$$\nThe transpose of the adjacency matrix is:\n$$A^T = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{pmatrix}$$\nThe initial hub vector is given as:\n$$h^{(0)} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix}$$\n\nWe will now perform two full iterations.\n\n**Iteration 1:**\n\nFirst, we compute the unnormalized authority vector $\\tilde{a}^{(1)}$ using $h^{(0)}$:\n$$\\tilde{a}^{(1)} = A^T h^{(0)} = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1/2 + 1/2 + 1/2 \\\\ 1/2 + 1/2 \\\\ 1/2 + 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 3/2 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\nNext, we normalize $\\tilde{a}^{(1)}$. The normalization factor is its Euclidean norm:\n$$\\|\\tilde{a}^{(1)}\\| = \\sqrt{0^2 + \\left(\\frac{3}{2}\\right)^2 + 1^2 + 1^2} = \\sqrt{\\frac{9}{4} + 1 + 1} = \\sqrt{\\frac{9}{4} + \\frac{8}{4}} = \\sqrt{\\frac{17}{4}} = \\frac{\\sqrt{17}}{2}$$\nThe normalized authority vector $a^{(1)}$ is:\n$$a^{(1)} = \\frac{1}{\\|\\tilde{a}^{(1)}\\|} \\tilde{a}^{(1)} = \\frac{2}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3/2 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 2 \\end{pmatrix}$$\nNow, we compute the unnormalized hub vector $\\tilde{h}^{(1)}$ using $a^{(1)}$:\n$$\\tilde{h}^{(1)} = A a^{(1)} = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 1 & 0 & 0 \\end{pmatrix} \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 3+2 \\\\ 2+2 \\\\ 3+2 \\\\ 3 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix}$$\nFinally for this iteration, we normalize $\\tilde{h}^{(1)}$. The norm is:\n$$\\|\\tilde{h}^{(1)}\\| = \\left\\| \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} \\right\\| = \\frac{1}{\\sqrt{17}} \\sqrt{5^2 + 4^2 + 5^2 + 3^2} = \\frac{1}{\\sqrt{17}} \\sqrt{25 + 16 + 25 + 9} = \\frac{\\sqrt{75}}{\\sqrt{17}} = \\frac{5\\sqrt{3}}{\\sqrt{17}}$$\nThe normalized hub vector $h^{(1)}$ is:\n$$h^{(1)} = \\frac{1}{\\|\\tilde{h}^{(1)}\\|} \\tilde{h}^{(1)} = \\frac{\\sqrt{17}}{5\\sqrt{3}} \\left( \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} \\right) = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix}$$\n\n**Iteration 2:**\n\nWe start the second iteration with $h^{(1)}$ to compute $\\tilde{a}^{(2)}$:\n$$\\tilde{a}^{(2)} = A^T h^{(1)} = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{pmatrix} \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 5+0+5+3 \\\\ 5+4+0+0 \\\\ 0+4+5+0 \\end{pmatrix} = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix}$$\nNext, we normalize $\\tilde{a}^{(2)}$. The normalization factor is:\n$$\\|\\tilde{a}^{(2)}\\| = \\left\\| \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} \\right\\| = \\frac{1}{5\\sqrt{3}} \\sqrt{0^2 + 13^2 + 9^2 + 9^2} = \\frac{1}{5\\sqrt{3}} \\sqrt{169 + 81 + 81} = \\frac{\\sqrt{331}}{5\\sqrt{3}}$$\nThe normalized authority vector $a^{(2)}$ is:\n$$a^{(2)} = \\frac{1}{\\|\\tilde{a}^{(2)}\\|} \\tilde{a}^{(2)} = \\frac{5\\sqrt{3}}{\\sqrt{331}} \\left( \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{331}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 13/\\sqrt{331} \\\\ 9/\\sqrt{331} \\\\ 9/\\sqrt{331} \\end{pmatrix}$$\nThe problem asks for the authority score of node $2$ at the end of the second authority-update normalization, which is the component $a^{(2)}_{2}$. From the vector $a^{(2)}$ we calculated, this value is:\n$$a^{(2)}_{2} = \\frac{13}{\\sqrt{331}}$$\nThe number $331$ is prime, so this expression cannot be simplified further.",
            "answer": "$$\\boxed{\\frac{13}{\\sqrt{331}}}$$"
        },
        {
            "introduction": "Beyond the iterative calculations, the power of HITS lies in its ability to identify network roles based on topology. This problem investigates the algorithm's behavior on a directed star graph, a perfect archetype for a system with a central hub pointing to a set of authorities . By analyzing the principal eigenvectors of the co-reference ($A A^{\\top}$) and co-citation ($A^{\\top} A$) matrices, you will derive the exact hub and authority scores and see how cleanly the algorithm separates these two fundamental roles.",
            "id": "4281856",
            "problem": "Consider a directed star graph $G_n$ with node set $\\{v_0,v_1,\\dots,v_n\\}$, where $v_0$ is the center and for each $i \\in \\{1,\\dots,n\\}$ there is a single directed edge from $v_0$ to $v_i$. There are no other edges. Let $A \\in \\{0,1\\}^{(n+1)\\times(n+1)}$ be the adjacency matrix with the convention that $A_{ij}=1$ if there is a directed edge from node $i$ to node $j$, and $A_{ij}=0$ otherwise.\n\nThe Hyperlink-Induced Topic Search (HITS) framework defines two score vectors: a hub score vector $h$ and an authority score vector $a$. In the canonical linear-algebraic formulation, these arise from the dominant spectral structure of two-step path operators built from $A$; in particular, co-reference and co-citation similarities are captured by $A A^{\\top}$ and $A^{\\top} A$, respectively. In the standard normalization, the hub and authority score vectors are scaled to have unit Euclidean norm, that is, $\\|h\\|_2 = 1$ and $\\|a\\|_2 = 1$.\n\nStarting from the interpretation that $(A A^{\\top})_{ij}$ counts two-step paths $i \\to \\cdot \\to j$ and $(A^{\\top} A)_{ij}$ counts two-step paths $\\cdot \\to i \\leftarrow \\cdot$ (co-citation), derive why the principal eigenvectors of $A A^{\\top}$ and $A^{\\top} A$ encode hub and authority centralities, respectively. Then, for the graph $G_n$ described above:\n- Compute the unit-norm hub score vector $h$ and the unit-norm authority score vector $a$ explicitly in terms of $n$.\n- Explain qualitatively the disparity between the hub and authority roles for the center $v_0$ and a leaf $v_i$.\n\nFinally, let $R(n)$ denote the ratio of the center’s hub score to any leaf’s authority score under the unit-norm normalization, that is, $R(n) = \\frac{h(v_0)}{a(v_i)}$ for any $i \\in \\{1,\\dots,n\\}$. Provide $R(n)$ as a single closed-form analytic expression in terms of $n$. No rounding is required.",
            "solution": "### The HITS Algorithm and its Eigenvector Formulation\n\nThe Hyperlink-Induced Topic Search (HITS) algorithm is based on a mutually reinforcing relationship between two types of nodes in a directed network: hubs and authorities.\nA good authority is a node that is pointed to by many good hubs.\nA good hub is a node that points to many good authorities.\n\nLet the authority score of node $j$ be $a_j$ and the hub score of node $i$ be $h_i$. These scores are defined by the following iterative updates:\n1. The authority score of a node is the sum of the hub scores of the nodes that point to it. Let $A$ be the adjacency matrix where $A_{ij}=1$ if there is an edge from $i$ to $j$. The nodes $k$ that point to node $j$ are those for which an edge $k \\to j$ exists, meaning $A_{kj}=1$. Thus,\n$$a_j \\propto \\sum_k A_{kj} h_k$$\nIn vector form, this is $a \\propto A^{\\top} h$.\n\n2. The hub score of a node is the sum of the authority scores of the nodes it points to.\n$$h_i \\propto \\sum_{j: i \\to j} a_j = \\sum_j A_{ij} a_j$$\nIn vector form, this is $h \\propto A a$.\n\nBy substituting these two relations into each other, we obtain the eigenvector equations:\n$$a \\propto A^{\\top}h \\propto A^{\\top}(Aa) = (A^{\\top}A)a$$\n$$h \\propto Aa \\propto A(A^{\\top}h) = (AA^{\\top})h$$\nThese show that the authority vector $a$ is an eigenvector of the matrix $A^{\\top}A$, and the hub vector $h$ is an eigenvector of the matrix $AA^{\\top}$. To ensure non-negative scores, we select the principal eigenvector, which, by the Perron-Frobenius theorem for non-negative matrices, corresponds to the largest non-negative eigenvalue and has non-negative entries.\n\nThe problem asks for an interpretation based on path counting. Let's analyze the entries of these matrices:\n- The matrix $A^{\\top}A$ is the co-citation matrix. Its $(i,j)$-th entry is $(A^{\\top}A)_{ij} = \\sum_k (A^{\\top})_{ik} A_{kj} = \\sum_k A_{ki} A_{kj}$. This sum counts the number of nodes $k$ that have directed edges to both node $i$ and node $j$ (the pattern $k \\to i$ and $k \\to j$, or $\\cdot \\to i \\leftarrow \\cdot$). Nodes praised by the same sources are considered similar authorities. The principal eigenvector of this matrix thus identifies the most prominent authorities.\n- The matrix $AA^{\\top}$ is the co-reference matrix (or bibliographic coupling matrix). Its $(i,j)$-th entry is $(AA^{\\top})_{ij} = \\sum_k A_{ik} (A^{\\top})_{kj} = \\sum_k A_{ik} A_{jk}$. This sum counts the number of nodes $k$ to which both node $i$ and node $j$ point (the pattern $i \\to k$ and $j \\to k$). Nodes that point to the same targets are considered similar hubs. The principal eigenvector of this matrix identifies the most prominent hubs.\n\n### Matrix Construction for Graph $G_n$\n\nThe graph $G_n$ has $n+1$ nodes, which we label as $\\{0, 1, \\dots, n\\}$, corresponding to $\\{v_0, v_1, \\dots, v_n\\}$. Node $v_0$ is the center. There is a directed edge from $v_0$ to each $v_i$ for $i \\in \\{1, \\dots, n\\}$.\nThe adjacency matrix $A$ is an $(n+1) \\times (n+1)$ matrix. The only non-zero entries are $A_{0i}=1$ for $i \\in \\{1, \\dots, n\\}$.\n$$\nA =\n\\begin{pmatrix}\n0 & 1 & 1 & \\dots & 1 \\\\\n0 & 0 & 0 & \\dots & 0 \\\\\n0 & 0 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\dots & 0\n\\end{pmatrix}\n$$\nThe transpose of $A$, $A^{\\top}$, is:\n$$\nA^{\\top} =\n\\begin{pmatrix}\n0 & 0 & 0 & \\dots & 0 \\\\\n1 & 0 & 0 & \\dots & 0 \\\\\n1 & 0 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & 0 & 0 & \\dots & 0\n\\end{pmatrix}\n$$\n\n### Hub Score Vector Calculation\n\nThe hub scores are given by the principal eigenvector of $AA^{\\top}$.\n$$\nAA^{\\top} =\n\\begin{pmatrix}\n0 & 1 & \\dots & 1 \\\\\n0 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 0 & \\dots & 0 \\\\\n1 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & 0 & \\dots & 0\n\\end{pmatrix}\n$$\nThe only non-zero element is $(AA^{\\top})_{00} = \\sum_{k=1}^{n} 1 \\cdot 1 = n$. All other elements are $0$.\n$$\nAA^{\\top} =\n\\begin{pmatrix}\nn & 0 & 0 & \\dots & 0 \\\\\n0 & 0 & 0 & \\dots & 0 \\\\\n0 & 0 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\dots & 0\n\\end{pmatrix}\n$$\nThis is a diagonal matrix. Its eigenvalues are the diagonal entries: $n$ with multiplicity $1$, and $0$ with multiplicity $n$. The principal eigenvalue is $\\lambda_{hub} = n$. The corresponding eigenvector $h = (h_0, h_1, \\dots, h_n)^{\\top}$ satisfies $(AA^{\\top})h = nh$.\nThis yields the system of equations: $nh_0 = nh_0$, and $0 = nh_i$ for $i \\in \\{1, \\dots, n\\}$.\nThis implies $h_i = 0$ for $i \\ge 1$. The vector $h$ is of the form $(c, 0, \\dots, 0)^{\\top}$ for some constant $c$.\nWe apply the normalization condition $\\|h\\|_2=1$: $\\sqrt{c^2 + 0^2 + \\dots + 0^2} = 1$, which gives $|c|=1$. Choosing the customary non-negative eigenvector, we get $c=1$.\nThe unit-norm hub score vector is $h = (1, 0, \\dots, 0)^{\\top}$.\nSo, $h(v_0) = 1$ and $h(v_i) = 0$ for $i \\in \\{1,\\dots,n\\}$.\n\n### Authority Score Vector Calculation\n\nThe authority scores are given by the principal eigenvector of $A^{\\top}A$.\n$$\nA^{\\top}A =\n\\begin{pmatrix}\n0 & 0 & \\dots & 0 \\\\\n1 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & 0 & \\dots & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 1 & \\dots & 1 \\\\\n0 & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & 0\n\\end{pmatrix}\n$$\nLet's compute the entries $(A^{\\top}A)_{ij} = \\sum_k A_{ki} A_{kj}$.\n- If $i=0$ or $j=0$, the corresponding column in $A$ is all zeros, so $(A^{\\top}A)_{ij}=0$.\n- If $i,j \\in \\{1, \\dots, n\\}$, the only non-zero term in the sum is for $k=0$. Then $(A^{\\top}A)_{ij} = A_{0i} A_{0j} = 1 \\cdot 1 = 1$.\n$$\nA^{\\top}A =\n\\begin{pmatrix}\n0 & 0 & 0 & \\dots & 0 \\\\\n0 & 1 & 1 & \\dots & 1 \\\\\n0 & 1 & 1 & \\dots & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 1 & 1 & \\dots & 1\n\\end{pmatrix}\n$$\nTo find the eigenvalues $\\lambda$ and eigenvectors $a$ of $A^{\\top}A$: $(A^{\\top}A)a = \\lambda a$.\nFor $a = (a_0, a_1, \\dots, a_n)^{\\top}$, this gives:\n$0 = \\lambda a_0$.\nFor $i \\in \\{1, \\dots, n\\}$, $\\sum_{j=1}^{n} a_j = \\lambda a_i$.\nThe principal eigenvalue must be non-zero (since $A^{\\top}A$ is not the zero matrix for $n \\ge 1$), so from the first equation, $a_0 = 0$.\nThe remaining equations imply that $\\lambda a_1 = \\lambda a_2 = \\dots = \\lambda a_n = \\sum_{j=1}^{n} a_j$.\nThis means $a_1=a_2=\\dots=a_n$. Let $a_i=c$ for $i \\in \\{1, \\dots, n\\}$.\nThen the equation becomes $\\lambda c = \\sum_{j=1}^{n} c = nc$. For a non-trivial solution ($c \\ne 0$), we must have $\\lambda = n$.\nThe principal eigenvalue is $\\lambda_{auth} = n$. The corresponding eigenvector is of the form $(0, c, c, \\dots, c)^{\\top}$.\nApplying the normalization $\\|a\\|_2=1$: $\\sqrt{0^2 + nc^2} = 1 \\implies |c|\\sqrt{n} = 1$.\nFor a non-negative eigenvector, we choose $c = 1/\\sqrt{n}$.\nThe unit-norm authority score vector is $a = (0, 1/\\sqrt{n}, \\dots, 1/\\sqrt{n})^{\\top}$.\nSo, $a(v_0) = 0$ and $a(v_i) = 1/\\sqrt{n}$ for $i \\in \\{1,\\dots,n\\}$.\n\n### Qualitative Explanation of Roles\n\nThe calculated scores perfectly reflect the topology of the star graph $G_n$.\n- **Center Node $v_0$**: This node has a maximum hub score of $h(v_0)=1$ and a zero authority score of $a(v_0)=0$. This is because $v_0$ is the source of all links in the network; it acts as a pure \"hub\" by pointing to all other nodes. It receives no incoming links, so it has no \"authority\" status.\n- **Leaf Nodes $v_i$ (for $i \\ge 1$)**: These nodes have zero hub scores, $h(v_i)=0$, and positive, equal authority scores, $a(v_i)=1/\\sqrt{n}$. This is because they do not point to any nodes, hence they are not hubs. However, they all receive a link from the single, maximal hub ($v_0$), making them equally important \"authorities\" in the network. Their authority is distributed equally among them.\n\nThe disparity is maximal: $v_0$ is a pure hub, while the leaves $v_i$ are pure authorities.\n\n### Calculation of the Ratio $R(n)$\n\nThe problem defines the ratio $R(n)$ as $R(n) = \\frac{h(v_0)}{a(v_i)}$ for any $i \\in \\{1,\\dots,n\\}$.\nUsing the scores derived above:\n$h(v_0) = 1$\n$a(v_i) = \\frac{1}{\\sqrt{n}}$\nThe ratio is:\n$$R(n) = \\frac{1}{\\frac{1}{\\sqrt{n}}} = \\sqrt{n}$$\nThis is the closed-form analytic expression for the ratio.",
            "answer": "$$\\boxed{\\sqrt{n}}$$"
        },
        {
            "introduction": "Having explored an idealized star graph, we now turn to another fundamental topology: the directed path or chain. This exercise challenges you to determine the final, converged distribution of hub and authority scores for every node along the chain . Analyzing this structure reveals how HITS scores are influenced by a node's position, particularly demonstrating the unique status of the ultimate source and final sink of the path.",
            "id": "4281874",
            "problem": "Consider the directed path (chain) on $n$ labeled nodes, with arcs $1 \\to 2 \\to 3 \\to \\cdots \\to n$, where $n \\ge 2$. Let $L \\in \\mathbb{R}^{n \\times n}$ be the adjacency matrix defined by $L_{i,i+1} = 1$ for $i \\in \\{1,\\dots,n-1\\}$ and $L_{ij} = 0$ otherwise. In the Hyperlink-Induced Topic Search (HITS) framework, the authority vector $a \\in \\mathbb{R}^{n}$ and the hub vector $h \\in \\mathbb{R}^{n}$ are computed by iterating the linear updates $h \\leftarrow L a$ and $a \\leftarrow L^{\\top} h$, with normalization after each application to enforce unit Euclidean norm. Assume the initialization $a^{(0)} = \\mathbf{1}$ and $h^{(0)} = \\mathbf{1}$, where $\\mathbf{1} \\in \\mathbb{R}^{n}$ denotes the all-ones vector, and at each step the vector is normalized to have $\\ell_{2}$-norm equal to $1$.\n\nStarting from the definitions of hubs and authorities as linear updates induced by $L$ and $L^{\\top}$ and without invoking any pre-packaged formulas, derive the limiting distribution of the $\\ell_{2}$-normalized authority and hub scores along the path as functions of $n$ and the node index $j \\in \\{1,\\dots,n\\}$. Express your final answer using a single closed-form expression for each of the two scores in terms of the Kronecker delta $\\delta_{ij}$, and present them together as a single row vector $\\bigl[a_{j}^{\\star},\\,h_{j}^{\\star}\\bigr]$. No numerical approximation or rounding is required.",
            "solution": "The problem asks for the limiting authority and hub scores for a directed path graph under the Hyperlink-Induced Topic Search (HITS) algorithm. The HITS algorithm is an iterative procedure that can be understood in terms of the power method for finding the principal eigenvectors of two related matrices.\n\nLet $a$ be the authority score vector and $h$ be the hub score vector. The updates are given as $h \\leftarrow L a$ and $a \\leftarrow L^{\\top} h$, followed by normalization at each step. Combining these updates, we see that the authority scores $a$ are computed by iterating the map $a \\mapsto L^{\\top}(La) = (L^{\\top}L)a$. Similarly, one can formulate the hub updates as $h \\mapsto L(L^{\\top}h) = (LL^{\\top})h$. The iterative process with normalization is the power method. Therefore, the limiting normalized authority vector, $a^{\\star}$, is the principal eigenvector of the authority matrix $A = L^{\\top}L$, and the limiting normalized hub vector, $h^{\\star}$, is the principal eigenvector of the hub matrix $H = LL^{\\top}$. The specific limiting vector is determined by the projection of the initial vector onto the eigenspace of the largest eigenvalue.\n\nFirst, we must construct the matrices $L$, $L^{\\top}$, $A$, and $H$. The graph is a directed path $1 \\to 2 \\to \\cdots \\to n$ on $n$ nodes. The adjacency matrix $L \\in \\mathbb{R}^{n \\times n}$ is given by its elements $L_{i,i+1} = 1$ for $i \\in \\{1, \\dots, n-1\\}$, and $L_{ij} = 0$ for all other pairs $(i, j)$. This is a superdiagonal matrix:\n$$\nL = \\begin{pmatrix}\n0 & 1 & 0 & \\cdots & 0 \\\\\n0 & 0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 0 & 1 \\\\\n0 & 0 & \\cdots & 0 & 0\n\\end{pmatrix}\n$$\nIts transpose, $L^{\\top}$, is a subdiagonal matrix:\n$$\nL^{\\top} = \\begin{pmatrix}\n0 & 0 & \\cdots & 0 & 0 \\\\\n1 & 0 & \\cdots & 0 & 0 \\\\\n0 & 1 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 1 & 0\n\\end{pmatrix}\n$$\nNow, we compute the authority matrix $A = L^{\\top}L$:\nThe elements of $A$ are given by $A_{ij} = \\sum_{k=1}^{n} (L^{\\top})_{ik} L_{kj} = \\sum_{k=1}^{n} L_{ki} L_{kj}$. For $A_{ij}$ to be non-zero, there must exist a $k$ such that both $L_{ki}$ and $L_{kj}$ are non-zero. From the definition of $L$, $L_{ki}=1$ implies $k=i-1$, and $L_{kj}=1$ implies $k=j-1$. Thus, we must have $i-1 = j-1$, which means $i=j$. For an element $A_{ii}$ to be non-zero, we need $L_{i-1,i}=1$, which is true for $i \\in \\{2, \\dots, n\\}$. For $i=1$, there is no $k$ such that $L_{k1}=1$, so $A_{11}=0$. The diagonal elements are $A_{ii}=1$ for $i \\in \\{2, \\dots, n\\}$ and $A_{11}=0$. The off-diagonal elements are all zero.\n$$\nA = L^{\\top}L = \\mathrm{diag}(0, 1, 1, \\dots, 1)\n$$\nNext, we compute the hub matrix $H = LL^{\\top}$:\nThe elements of $H$ are $H_{ij} = \\sum_{k=1}^{n} L_{ik} (L^{\\top})_{kj} = \\sum_{k=1}^{n} L_{ik} L_{jk}$. For $H_{ij}$ to be non-zero, there must be a $k$ where $L_{ik}=1$ and $L_{jk}=1$. This implies $k=i+1$ and $k=j+1$, which means $i=j$. For an element $H_{ii}$ to be non-zero, we need $L_{i,i+1}=1$, which holds for $i \\in \\{1, \\dots, n-1\\}$. For $i=n$, there is no $k$ such that $L_{nk}=1$, so $H_{nn}=0$. The diagonal elements are $H_{ii}=1$ for $i \\in \\{1, \\dots, n-1\\}$ and $H_{nn}=0$. The off-diagonal elements are all zero.\n$$\nH = LL^{\\top} = \\mathrm{diag}(1, 1, \\dots, 1, 0)\n$$\nThe eigenvalues of a diagonal matrix are its diagonal entries.\nFor $A=\\mathrm{diag}(0, 1, \\dots, 1)$, the eigenvalues are $\\lambda_1=0$ and $\\lambda_2 = \\dots = \\lambda_n = 1$. The largest eigenvalue is $\\lambda_{\\max}=1$, with multiplicity $n-1$. The eigenspace associated with $\\lambda_{\\max}=1$ is spanned by the standard basis vectors $\\{e_2, e_3, \\dots, e_n\\}$.\nFor $H=\\mathrm{diag}(1, 1, \\dots, 1, 0)$, the eigenvalues are $\\lambda_1 = \\dots = \\lambda_{n-1} = 1$ and $\\lambda_n=0$. The largest eigenvalue is $\\lambda_{\\max}=1$, with multiplicity $n-1$. The eigenspace associated with $\\lambda_{\\max}=1$ is spanned by $\\{e_1, e_2, \\dots, e_{n-1}\\}$.\n\nThe power method, when starting with a vector $v_0$, converges to the projection of $v_0$ onto the eigenspace of the largest eigenvalue, provided this projection is non-zero. The initial vectors are given as $a^{(0)} = \\mathbf{1}$ and $h^{(0)} = \\mathbf{1}$.\nFor the authority vector, the iterative process converges to a vector proportional to the projection of $a^{(0)} = \\mathbf{1}$ onto the eigenspace $\\mathrm{span}\\{e_2, \\dots, e_n\\}$. This projection is $\\sum_{j=2}^{n} e_j = (0, 1, 1, \\dots, 1)^{\\top}$. Alternatively, we can see that after one iteration (un-normalized), we have $a^{(1)} \\propto A a^{(0)} = \\mathrm{diag}(0, 1, \\dots, 1) (1, 1, \\dots, 1)^{\\top} = (0, 1, \\dots, 1)^{\\top}$. Since this vector is already in the eigenspace of $\\lambda=1$, further iterations only scale it by $1$, so the vector direction is fixed. The limiting un-normalized authority vector is $a^{\\star}_{\\text{un-norm}} = (0, 1, 1, \\dots, 1)^{\\top}$.\n\nFor the hub vector, we project $h^{(0)}=\\mathbf{1}$ onto the eigenspace $\\mathrm{span}\\{e_1, \\dots, e_{n-1}\\}$. This projection is $\\sum_{j=1}^{n-1} e_j = (1, 1, \\dots, 1, 0)^{\\top}$. Alternatively, $h^{(1)} \\propto H h^{(0)} = \\mathrm{diag}(1, \\dots, 1, 0) (1, \\dots, 1)^{\\top} = (1, 1, \\dots, 1, 0)^{\\top}$. The limiting un-normalized hub vector is $h^{\\star}_{\\text{un-norm}} = (1, 1, \\dots, 1, 0)^{\\top}$.\n\nThe problem requires the scores to be $\\ell_2$-normalized.\nFor the authority scores:\nThe vector is $(0, 1, \\dots, 1)^{\\top}$. There are $n-1$ entries equal to $1$.\nThe $\\ell_2$-norm is $\\|a^{\\star}_{\\text{un-norm}}\\|_2 = \\sqrt{0^2 + \\sum_{j=2}^{n} 1^2} = \\sqrt{n-1}$.\nThe normalized limiting authority vector is $a^{\\star} = \\frac{1}{\\sqrt{n-1}} (0, 1, 1, \\dots, 1)^{\\top}$.\nThe $j$-th component of this vector is:\n$a_j^{\\star} = \\begin{cases} 0 & \\text{if } j=1 \\\\ \\frac{1}{\\sqrt{n-1}} & \\text{if } j \\in \\{2, \\dots, n\\} \\end{cases}$.\nUsing the Kronecker delta $\\delta_{ij}$, which is $1$ if $i=j$ and $0$ otherwise, we can write this as a single expression:\n$a_j^{\\star} = \\frac{1 - \\delta_{j1}}{\\sqrt{n-1}}$.\n\nFor the hub scores:\nThe vector is $(1, 1, \\dots, 1, 0)^{\\top}$. There are $n-1$ entries equal to $1$.\nThe $\\ell_2$-norm is $\\|h^{\\star}_{\\text{un-norm}}\\|_2 = \\sqrt{\\sum_{j=1}^{n-1} 1^2 + 0^2} = \\sqrt{n-1}$.\nThe normalized limiting hub vector is $h^{\\star} = \\frac{1}{\\sqrt{n-1}} (1, 1, \\dots, 1, 0)^{\\top}$.\nThe $j$-th component of this vector is:\n$h_j^{\\star} = \\begin{cases} \\frac{1}{\\sqrt{n-1}} & \\text{if } j \\in \\{1, \\dots, n-1\\} \\\\ 0 & \\text{if } j=n \\end{cases}$.\nUsing the Kronecker delta, this can be written as:\n$h_j^{\\star} = \\frac{1 - \\delta_{jn}}{\\sqrt{n-1}}$.\n\nThe final answer is the row vector of these two expressions.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{1 - \\delta_{j1}}{\\sqrt{n-1}} & \\frac{1 - \\delta_{jn}}{\\sqrt{n-1}} \\end{pmatrix}\n}\n$$"
        }
    ]
}