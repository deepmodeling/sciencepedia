{
    "hands_on_practices": [
        {
            "introduction": "要真正理解一个算法，最好的方法之一就是亲手执行它。本练习将引导你完成 HITS 更新规则的具体分步演算，将抽象的公式变得具体化。通过这个过程，你将清楚地看到分数是如何在网络中传播和归一化的，从而掌握该算法的核心机制。",
            "id": "4281863",
            "problem": "考虑一个包含 $4$ 个节点的有向网络，其邻接矩阵为 $A \\in \\mathbb{R}^{4 \\times 4}$，其中如果存在从节点 $i$ 到节点 $j$ 的有向边，则 $A_{ij} = 1$，否则 $A_{ij} = 0$。该网络由以下矩阵给出：\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  1  1 \\\\\n0  1  0  1 \\\\\n0  1  0  0\n\\end{pmatrix}.\n$$\n在 HITS (Hyperlink-Induced Topic Search) 算法中，每个节点都被赋予一个 hub 分数和一个 authority 分数。基本定义如下：一个节点的 authority 分数与指向该节点的各节点的 hub 分数之和成正比，而一个节点的 hub 分数与该节点指向的各节点的 authority 分数之和成正比。\n\n从初始 hub 向量 $h^{(0)} \\in \\mathbb{R}^{4}$ 开始，该向量被选为单位长度且各分量相等，即\n$$\nh^{(0)} \\;=\\; \\frac{1}{\\sqrt{4}} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\;=\\; \\begin{pmatrix} \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\end{pmatrix},\n$$\n请执行 HITS 更新过程整整 $2$ 次完整迭代。在每次完整迭代中，首先使用比例性定义根据 hub 向量计算 authority 向量，然后将 authority 向量归一化使其欧几里得范数为 $1$；接下来，使用比例性定义根据 authority 向量计算 hub 向量，然后将 hub 向量归一化使其欧几里得范数为 $1$。在每个子步骤中，明确展示未归一化的向量、归一化因子和归一化的向量，从而追踪 $a$ 和 $h$ 的演变过程。\n\n仅以上述基本定义为出发点，推导出所需的线性更新，并使用给定的 $A$ 和 $h^{(0)}$ 进行计算。在第二次 authority 更新归一化结束时，节点 $2$ 的 authority 分数，即 $a^{(2)}_{2}$ 的精确值是多少？请以单一闭式表达式给出你的答案。不要对答案进行四舍五入。",
            "solution": "该问题要求在给定网络上执行两次 HITS (Hyperlink-Induced Topic Search) 算法的完整迭代后，求一个特定的 authority 分数。首先，我们必须根据所提供的定义将更新规则形式化。\n\n设 $a = (a_1, a_2, \\dots, a_N)^T$ 为 authority 向量，$h = (h_1, h_2, \\dots, h_N)^T$ 为一个包含 $N$ 个节点的网络的 hub 向量。邻接矩阵为 $A$，其中如果存在从节点 $i$ 到节点 $j$ 的有向边，则 $A_{ij}=1$。\n\n提供的定义如下：\n1.  节点 $j$ 的 authority 分数 $a_j$ 与指向它的节点的 hub 分数之和成正比。指向节点 $j$ 的节点 $i$ 是那些满足 $A_{ij}=1$ 的节点。因此，\n    $$a_j \\propto \\sum_{i=1}^N A_{ij} h_i$$\n    这是向量积 $A^T h$ 的第 $j$ 个分量。所以，未归一化的 authority 向量（我们记作 $\\tilde{a}$）由以下更新规则给出：\n    $$\\tilde{a} = A^T h$$\n\n2.  节点 $i$ 的 hub 分数 $h_i$ 与它指向的节点的 authority 分数之和成正比。节点 $i$ 指向的节点 $j$ 是那些满足 $A_{ij}=1$ 的节点。因此，\n    $$h_i \\propto \\sum_{j=1}^N A_{ij} a_j$$\n    这是向量积 $A a$ 的第 $i$ 个分量。所以，未归一化的 hub 向量（我们记作 $\\tilde{h}$）由以下更新规则给出：\n    $$\\tilde{h} = A a$$\n\n一次从步骤 $k$ 更新到 $k+1$ 的完整迭代包括一次 authority 更新，随后是一次 hub 更新，并在每个阶段进行归一化。\n设 $h^{(k)}$ 为步骤 $k$ 的归一化 hub 向量。\n1.  计算未归一化的 authority 向量： $\\tilde{a}^{(k+1)} = A^T h^{(k)}$。\n2.  归一化得到 authority 向量： $a^{(k+1)} = \\frac{\\tilde{a}^{(k+1)}}{\\|\\tilde{a}^{(k+1)}\\|}$，其中 $\\|\\cdot\\|$ 表示欧几里得范数。\n3.  计算未归一化的 hub 向量： $\\tilde{h}^{(k+1)} = A a^{(k+1)}$。\n4.  归一化得到 hub 向量： $h^{(k+1)} = \\frac{\\tilde{h}^{(k+1)}}{\\|\\tilde{h}^{(k+1)}\\|}$。\n\n问题给出了一个包含 $N=4$ 个节点的网络的邻接矩阵：\n$$A = \\begin{pmatrix} 0  1  1  0 \\\\ 0  0  1  1 \\\\ 0  1  0  1 \\\\ 0  1  0  0 \\end{pmatrix}$$\n邻接矩阵的转置是：\n$$A^T = \\begin{pmatrix} 0  0  0  0 \\\\ 1  0  1  1 \\\\ 1  1  0  0 \\\\ 0  1  1  0 \\end{pmatrix}$$\n初始 hub 向量给出如下：\n$$h^{(0)} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix}$$\n\n我们现在将执行两次完整迭代。\n\n**迭代 1：**\n\n首先，我们使用 $h^{(0)}$ 计算未归一化的 authority 向量 $\\tilde{a}^{(1)}$：\n$$\\tilde{a}^{(1)} = A^T h^{(0)} = \\begin{pmatrix} 0  0  0  0 \\\\ 1  0  1  1 \\\\ 1  1  0  0 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1/2 + 1/2 + 1/2 \\\\ 1/2 + 1/2 \\\\ 1/2 + 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 3/2 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\n接下来，我们归一化 $\\tilde{a}^{(1)}$。归一化因子是其欧几里得范数：\n$$\\|\\tilde{a}^{(1)}\\| = \\sqrt{0^2 + \\left(\\frac{3}{2}\\right)^2 + 1^2 + 1^2} = \\sqrt{\\frac{9}{4} + 1 + 1} = \\sqrt{\\frac{9}{4} + \\frac{8}{4}} = \\sqrt{\\frac{17}{4}} = \\frac{\\sqrt{17}}{2}$$\n归一化的 authority 向量 $a^{(1)}$ 是：\n$$a^{(1)} = \\frac{1}{\\|\\tilde{a}^{(1)}\\|} \\tilde{a}^{(1)} = \\frac{2}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3/2 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 2 \\end{pmatrix}$$\n现在，我们使用 $a^{(1)}$ 计算未归一化的 hub 向量 $\\tilde{h}^{(1)}$：\n$$\\tilde{h}^{(1)} = A a^{(1)} = \\begin{pmatrix} 0  1  1  0 \\\\ 0  0  1  1 \\\\ 0  1  0  1 \\\\ 0  1  0  0 \\end{pmatrix} \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 3+2 \\\\ 2+2 \\\\ 3+2 \\\\ 3 \\end{pmatrix} = \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix}$$\n本次迭代的最后一步，我们归一化 $\\tilde{h}^{(1)}$。其范数是：\n$$\\|\\tilde{h}^{(1)}\\| = \\left\\| \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} \\right\\| = \\frac{1}{\\sqrt{17}} \\sqrt{5^2 + 4^2 + 5^2 + 3^2} = \\frac{1}{\\sqrt{17}} \\sqrt{25 + 16 + 25 + 9} = \\frac{\\sqrt{75}}{\\sqrt{17}} = \\frac{5\\sqrt{3}}{\\sqrt{17}}$$\n归一化的 hub 向量 $h^{(1)}$ 是：\n$$h^{(1)} = \\frac{1}{\\|\\tilde{h}^{(1)}\\|} \\tilde{h}^{(1)} = \\frac{\\sqrt{17}}{5\\sqrt{3}} \\left( \\frac{1}{\\sqrt{17}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} \\right) = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix}$$\n\n**迭代 2：**\n\n我们从 $h^{(1)}$ 开始第二次迭代，以计算 $\\tilde{a}^{(2)}$：\n$$\\tilde{a}^{(2)} = A^T h^{(1)} = \\begin{pmatrix} 0  0  0  0 \\\\ 1  0  1  1 \\\\ 1  1  0  0 \\\\ 0  1  1  0 \\end{pmatrix} \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 5 \\\\ 4 \\\\ 5 \\\\ 3 \\end{pmatrix} = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 5+0+5+3 \\\\ 5+4+0+0 \\\\ 0+4+5+0 \\end{pmatrix} = \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix}$$\n接下来，我们归一化 $\\tilde{a}^{(2)}$。归一化因子是：\n$$\\|\\tilde{a}^{(2)}\\| = \\left\\| \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} \\right\\| = \\frac{1}{5\\sqrt{3}} \\sqrt{0^2 + 13^2 + 9^2 + 9^2} = \\frac{1}{5\\sqrt{3}} \\sqrt{169 + 81 + 81} = \\frac{\\sqrt{331}}{5\\sqrt{3}}$$\n归一化的 authority 向量 $a^{(2)}$ 是：\n$$a^{(2)} = \\frac{1}{\\|\\tilde{a}^{(2)}\\|} \\tilde{a}^{(2)} = \\frac{5\\sqrt{3}}{\\sqrt{331}} \\left( \\frac{1}{5\\sqrt{3}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{331}} \\begin{pmatrix} 0 \\\\ 13 \\\\ 9 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 13/\\sqrt{331} \\\\ 9/\\sqrt{331} \\\\ 9/\\sqrt{331} \\end{pmatrix}$$\n问题要求的是第二次 authority 更新归一化结束时节点 $2$ 的 authority 分数，也就是分量 $a^{(2)}_{2}$。从我们计算出的向量 $a^{(2)}$ 中，这个值是：\n$$a^{(2)}_{2} = \\frac{13}{\\sqrt{331}}$$\n数字 $331$ 是一个素数，所以这个表达式不能进一步化简。",
            "answer": "$$\\boxed{\\frac{13}{\\sqrt{331}}}$$"
        },
        {
            "introduction": "在掌握了 HITS 算法的计算机制后，我们可以进一步探索网络拓扑结构如何决定中心性得分。本练习使用“星形图”这一理想化结构，它完美地展示了作为链接分发者的“中心枢纽”（Hub）与作为链接汇集者的“权威”（Authority）之间的概念差异。这是建立关于 HITS 算法直观理解的关键一步。",
            "id": "4281856",
            "problem": "考虑一个有向星形图 $G_n$，其节点集为 $\\{v_0,v_1,\\dots,v_n\\}$，其中 $v_0$ 是中心节点，对于每个 $i \\in \\{1,\\dots,n\\}$，都有一条从 $v_0$ 到 $v_i$ 的有向边。图中没有其他边。设 $A \\in \\{0,1\\}^{(n+1)\\times(n+1)}$ 为邻接矩阵，约定如果存在从节点 $i$ 到节点 $j$ 的有向边，则 $A_{ij}=1$，否则 $A_{ij}=0$。\n\n超链接诱导主题搜索（Hyperlink-Induced Topic Search, HITS）框架定义了两个分数向量：一个hub分数向量 $h$ 和一个authority分数向量 $a$。在规范的线性代数表述中，这些向量源于由 $A$ 构建的两步路径算子的主导谱结构；特别地，共同引用（co-reference）和共同被引（co-citation）的相似性分别由 $A A^{\\top}$ 和 $A^{\\top} A$ 捕获。在标准归一化中，hub和authority分数向量被缩放至单位欧几里得范数，即 $\\|h\\|_2 = 1$ 和 $\\|a\\|_2 = 1$。\n\n从 $(A A^{\\top})_{ij}$ 计数两步路径 $i \\to \\cdot \\to j$ 和 $(A^{\\top} A)_{ij}$ 计数两步路径 $\\cdot \\to i \\leftarrow \\cdot$（共同被引）的解释出发，推导为什么 $A A^{\\top}$ 和 $A^{\\top} A$ 的主特征向量分别编码了hub中心性和authority中心性。然后，对于上述图 $G_n$：\n- 用 $n$ 明确计算单位范数的hub分数向量 $h$ 和单位范数的authority分数向量 $a$。\n- 定性解释中心节点 $v_0$ 和叶节点 $v_i$ 的hub和authority角色之间的差异。\n\n最后，令 $R(n)$ 表示在单位范数归一化下，中心节点的hub分数与任意叶节点的authority分数之比，即 $R(n) = \\frac{h(v_0)}{a(v_i)}$，其中 $i \\in \\{1,\\dots,n\\}$。请提供 $R(n)$ 的单个闭式解析表达式，无需四舍五入。",
            "solution": "### HITS算法及其特征向量公式\n\n超链接诱导主题搜索（HITS）算法基于有向网络中两类节点之间的相互加强关系：hub和authority。\n一个好的authority是被许多好的hub指向的节点。\n一个好的hub是指向许多好的authority的节点。\n\n设节点 $j$ 的authority分数为 $a_j$，节点 $i$ 的hub分数为 $h_i$。这些分数由以下迭代更新定义：\n1. 一个节点的authority分数是所有指向该节点的节点的hub分数之和。\n$$a_j \\propto \\sum_{i: i \\to j} h_i$$\n设 $A$ 为邻接矩阵，其中当存在从 $i$ 到 $j$ 的边时，$A_{ij}=1$。因此，指向节点 $j$ 的节点 $k$ 满足 $A_{kj}=1$。authority分数的更新规则为：\n$$a_j \\propto \\sum_k A_{kj} h_k$$\n用向量形式表示，即 $a \\propto A^{\\top} h$。\n\n2. 一个节点的hub分数是它所指向的所有节点的authority分数之和。\n$$h_i \\propto \\sum_{j: i \\to j} a_j = \\sum_j A_{ij} a_j$$\n用向量形式表示，即 $h \\propto A a$。\n\n将这两个关系相互代入，我们得到特征向量方程：\n$$a \\propto A^{\\top}h \\propto A^{\\top}(Aa) = (A^{\\top}A)a$$\n$$h \\propto Aa \\propto A(A^{\\top}h) = (AA^{\\top})h$$\n这表明authority向量 $a$ 是矩阵 $A^{\\top}A$ 的一个特征向量，而hub向量 $h$ 是矩阵 $AA^{\\top}$ 的一个特征向量。为确保分数为非负，我们选择主特征向量，根据非负矩阵的Perron-Frobenius定理，该向量对应于最大的非负特征值，并且其所有分量均为非负。\n\n问题要求基于路径计数进行解释。让我们分析这些矩阵的元素：\n- 矩阵 $A^{\\top}A$ 是共同被引矩阵。其第 $(i,j)$ 个元素是 $(A^{\\top}A)_{ij} = \\sum_k (A^{\\top})_{ik} A_{kj} = \\sum_k A_{ki} A_{kj}$。这个和计算了同时有有向边指向节点 $i$ 和节点 $j$ 的节点 $k$ 的数量（模式为 $k \\to i$ 和 $k \\to j$，或 $\\cdot \\to i \\leftarrow j$）。被相同来源指向的节点被认为是相似的authority。因此，该矩阵的主特征向量识别了最突出的authority。\n- 矩阵 $AA^{\\top}$ 是共同引用矩阵（或文献耦合矩阵）。其第 $(i,j)$ 个元素是 $(AA^{\\top})_{ij} = \\sum_k A_{ik} (A^{\\top})_{kj} = \\sum_k A_{ik} A_{jk}$。这个和计算了节点 $i$ 和节点 $j$ 同时指向的节点 $k$ 的数量（模式为 $i \\to k$ 和 $j \\to k$）。指向相同目标的节点被认为是相似的hub。该矩阵的主特征向量识别了最突出的hub。\n\n### 图 $G_n$ 的矩阵构造\n\n图 $G_n$ 有 $n+1$ 个节点，我们标记为 $\\{0, 1, \\dots, n\\}$，对应于 $\\{v_0, v_1, \\dots, v_n\\}$。节点 $v_0$ 是中心。对于 $i \\in \\{1, \\dots, n\\}$，有一条从 $v_0$ 到 $v_i$ 的有向边。\n邻接矩阵 $A$ 是一个 $(n+1) \\times (n+1)$ 的矩阵。唯一的非零元素是 $A_{0i}=1$，其中 $i \\in \\{1, \\dots, n\\}$。\n$$\nA =\n\\begin{pmatrix}\n0  1  1  \\dots  1 \\\\\n0  0  0  \\dots  0 \\\\\n0  0  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n0  0  0  \\dots  0\n\\end{pmatrix}\n$$\n$A$ 的转置矩阵 $A^{\\top}$ 是：\n$$\nA^{\\top} =\n\\begin{pmatrix}\n0  0  0  \\dots  0 \\\\\n1  0  0  \\dots  0 \\\\\n1  0  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  0  0  \\dots  0\n\\end{pmatrix}\n$$\n\n### Hub分数向量计算\n\nHub分数由 $AA^{\\top}$ 的主特征向量给出。\n$$\nAA^{\\top} =\n\\begin{pmatrix}\n0  1  \\dots  1 \\\\\n0  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n0  0  \\dots  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  0  \\dots  0 \\\\\n1  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  0  \\dots  0\n\\end{pmatrix}\n$$\n唯一的非零元素是 $(AA^{\\top})_{00} = \\sum_{k=1}^{n} 1 \\cdot 1 = n$。所有其他元素都为 $0$。\n$$\nAA^{\\top} =\n\\begin{pmatrix}\nn  0  0  \\dots  0 \\\\\n0  0  0  \\dots  0 \\\\\n0  0  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n0  0  0  \\dots  0\n\\end{pmatrix}\n$$\n这是一个对角矩阵。其特征值为对角线上的元素：$n$（重数为1）和 $0$（重数为 $n$）。主特征值为 $\\lambda_{hub} = n$。对应的特征向量 $h = (h_0, h_1, \\dots, h_n)^{\\top}$ 满足 $(AA^{\\top})h = nh$。\n这得到方程组：$nh_0 = nh_0$，以及对于 $i \\in \\{1, \\dots, n\\}$，$0 = nh_i$。\n这意味着对于 $i \\ge 1$，$h_i = 0$。向量 $h$ 的形式为 $(c, 0, \\dots, 0)^{\\top}$，其中 $c$ 是某个常数。\n我们应用归一化条件 $\\|h\\|_2=1$：$\\sqrt{c^2 + 0^2 + \\dots + 0^2} = 1$，得到 $|c|=1$。按惯例选择非负特征向量，我们得到 $c=1$。\n单位范数的hub分数向量为 $h = (1, 0, \\dots, 0)^{\\top}$。\n因此，$h(v_0) = 1$，$h(v_i) = 0$（对于 $i \\in \\{1,\\dots,n\\}$）。\n\n### Authority分数向量计算\n\nAuthority分数由 $A^{\\top}A$ 的主特征向量给出。\n$$\nA^{\\top}A =\n\\begin{pmatrix}\n0  0  \\dots  0 \\\\\n1  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  0  \\dots  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  \\dots  1 \\\\\n0  0  \\dots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n0  0  \\dots  0\n\\end{pmatrix}\n$$\n我们计算其元素 $(A^{\\top}A)_{ij} = \\sum_k A_{ki} A_{kj}$。\n- 如果 $i=0$ 或 $j=0$，则 $A$ 中对应的列全为零，所以 $(A^{\\top}A)_{ij}=0$。\n- 如果 $i,j \\in \\{1, \\dots, n\\}$，则和式中唯一的非零项是 $k=0$ 时。此时 $(A^{\\top}A)_{ij} = A_{0i} A_{0j} = 1 \\cdot 1 = 1$。\n$$\nA^{\\top}A =\n\\begin{pmatrix}\n0  0  0  \\dots  0 \\\\\n0  1  1  \\dots  1 \\\\\n0  1  1  \\dots  1 \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n0  1  1  \\dots  1\n\\end{pmatrix}\n$$\n为了找到 $A^{\\top}A$ 的特征值 $\\lambda$ 和特征向量 $a$：$(A^{\\top}A)a = \\lambda a$。\n对于 $a = (a_0, a_1, \\dots, a_n)^{\\top}$，这给出：\n$0 = \\lambda a_0$。\n对于 $i \\in \\{1, \\dots, n\\}$，$\\sum_{j=1}^{n} a_j = \\lambda a_i$。\n由于 $n \\ge 1$ 时 $A^{\\top}A$ 不是零矩阵，主特征值必须非零，因此由第一个方程可知 $a_0 = 0$。\n其余方程意味着 $\\lambda a_1 = \\lambda a_2 = \\dots = \\lambda a_n = \\sum_{j=1}^{n} a_j$。\n这意味着 $a_1=a_2=\\dots=a_n$。令 $a_i=c$（对于 $i \\in \\{1, \\dots, n\\}$）。\n那么方程变为 $\\lambda c = \\sum_{j=1}^{n} c = nc$。对于非平凡解（$c \\ne 0$），必须有 $\\lambda = n$。\n主特征值为 $\\lambda_{auth} = n$。对应的特征向量形式为 $(0, c, c, \\dots, c)^{\\top}$。\n应用归一化条件 $\\|a\\|_2=1$：$\\sqrt{0^2 + nc^2} = 1 \\implies |c|\\sqrt{n} = 1$。\n对于非负特征向量，我们选择 $c = 1/\\sqrt{n}$。\n单位范数的authority分数向量为 $a = (0, 1/\\sqrt{n}, \\dots, 1/\\sqrt{n})^{\\top}$。\n因此，$a(v_0) = 0$，$a(v_i) = 1/\\sqrt{n}$（对于 $i \\in \\{1,\\dots,n\\}$）。\n\n### 角色的定性解释\n\n计算出的分数完美地反映了星形图 $G_n$ 的拓扑结构。\n- **中心节点 $v_0$**：该节点具有最大的hub分数 $h(v_0)=1$ 和零authority分数 $a(v_0)=0$。这是因为 $v_0$ 是网络中所有链接的源头；它通过指向所有其他节点，扮演着纯粹的“hub”角色。它不接收任何入链，因此没有“authority”地位。\n- **叶节点 $v_i$（对于 $i \\ge 1$）**：这些节点具有零hub分数 $h(v_i)=0$ 和相等的正authority分数 $a(v_i)=1/\\sqrt{n}$。这是因为它们不指向任何节点，因此不是hub。然而，它们都接收来自唯一的、最大的hub（$v_0$）的链接，使它们在网络中成为同等重要的“authority”。它们的authority在它们之间被平均分配。\n\n这种差异是极致的：$v_0$ 是一个纯粹的hub，而叶节点 $v_i$ 是纯粹的authority。\n\n### 比率 $R(n)$ 的计算\n\n问题将比率 $R(n)$ 定义为 $R(n) = \\frac{h(v_0)}{a(v_i)}$，其中 $i \\in \\{1,\\dots,n\\}$。\n使用上面推导出的分数：\n$h(v_0) = 1$\n$a(v_i) = \\frac{1}{\\sqrt{n}}$\n该比率为：\n$$R(n) = \\frac{1}{\\frac{1}{\\sqrt{n}}} = \\sqrt{n}$$\n这是该比率的闭式解析表达式。",
            "answer": "$$\\boxed{\\sqrt{n}}$$"
        },
        {
            "introduction": "为了进一步加深理解，我们来分析另一种基本拓扑——有向路径。这个练习将揭示枢纽和权威分数如何沿着一条链进行传播，以及大多数节点如何能同时具备这两种角色。通过展示星形图中的“纯粹”角色是一种理想情况，而真实网络中的节点大多是混合角色，本练习将深化你对 HITS 算法的认识。",
            "id": "4281874",
            "problem": "考虑一个包含 $n$ 个带标签节点的有向路径（链），其弧为 $1 \\to 2 \\to 3 \\to \\cdots \\to n$，其中 $n \\ge 2$。设 $L \\in \\mathbb{R}^{n \\times n}$ 为邻接矩阵，其定义为：当 $i \\in \\{1,\\dots,n-1\\}$ 时，$L_{i,i+1} = 1$，否则 $L_{ij} = 0$。在 HITS (Hyperlink-Induced Topic Search) 框架中，权威向量 $a \\in \\mathbb{R}^{n}$ 和中心向量 $h \\in \\mathbb{R}^{n}$ 通过迭代线性更新 $h \\leftarrow L a$ 和 $a \\leftarrow L^{\\top} h$ 来计算，每次应用后都进行归一化以强制单位欧几里得范数。假设初始化为 $a^{(0)} = \\mathbf{1}$ 和 $h^{(0)} = \\mathbf{1}$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 表示全1向量，并且在每一步中，向量都被归一化以使其 $\\ell_{2}$范数等于1。\n\n从由 $L$ 和 $L^{\\top}$ 导出的中心和权威的线性更新定义出发，且不使用任何现成公式，推导路径上经过 $\\ell_{2}$归一化的权威分数和中心分数的极限分布，将其表示为 $n$ 和节点索引 $j \\in \\{1,\\dots,n\\}$ 的函数。用关于克罗内克δ (Kronecker delta) $\\delta_{ij}$ 的单个闭式表达式来表示这两个分数，并将它们一起呈现为单个行向量 $\\bigl[a_{j}^{\\star},\\,h_{j}^{\\star}\\bigr]$。不需要进行数值近似或四舍五入。",
            "solution": "该问题要求计算在 HITS (Hyperlink-Induced Topic Search) 算法下，有向路径图的极限权威分数和中心分数。HITS 算法是一个迭代过程，可以理解为用于寻找两个相关矩阵主特征向量的幂法。\n\n设 $a$ 为权威向量，$h$ 为中心向量。更新公式为 $h \\leftarrow L a$ 和 $a \\leftarrow L^{\\top} h$，每一步之后都进行归一化。结合这些更新，我们看到权威分数 $a$ 是通过迭代映射 $a \\mapsto L^{\\top}(La) = (L^{\\top}L)a$ 来计算的。类似地，中心向量的更新可以表述为 $h \\mapsto L(L^{\\top}h) = (LL^{\\top})h$。带归一化的迭代过程就是幂法。因此，极限归一化权威向量 $a^{\\star}$ 是权威矩阵 $A = L^{\\top}L$ 的主特征向量，而极限归一化中心向量 $h^{\\star}$ 是中心矩阵 $H = LL^{\\top}$ 的主特征向量。具体的极限向量由初始向量在最大特征值对应的特征空间上的投影决定。\n\n首先，我们必须构造矩阵 $L$、$L^{\\top}$、$A$ 和 $H$。该图是 $n$ 个节点上的有向路径 $1 \\to 2 \\to \\cdots \\to n$。邻接矩阵 $L \\in \\mathbb{R}^{n \\times n}$ 由其元素 $L_{i,i+1} = 1$ (对于 $i \\in \\{1, \\dots, n-1\\}$) 和 $L_{ij} = 0$ (对于所有其他对 $(i, j)$) 给出。这是一个上对角矩阵：\n$$\nL = \\begin{pmatrix}\n0  1  0  \\cdots  0 \\\\\n0  0  1  \\cdots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\ddots  \\vdots \\\\\n0  0  \\cdots  0  1 \\\\\n0  0  \\cdots  0  0\n\\end{pmatrix}\n$$\n其转置 $L^{\\top}$ 是一个下对角矩阵：\n$$\nL^{\\top} = \\begin{pmatrix}\n0  0  \\cdots  0  0 \\\\\n1  0  \\cdots  0  0 \\\\\n0  1  \\cdots  0  0 \\\\\n\\vdots  \\vdots  \\ddots  \\ddots  \\vdots \\\\\n0  0  \\cdots  1  0\n\\end{pmatrix}\n$$\n现在，我们计算权威矩阵 $A = L^{\\top}L$：\n$A$ 的元素由 $A_{ij} = \\sum_{k=1}^{n} (L^{\\top})_{ik} L_{kj} = \\sum_{k=1}^{n} L_{ki} L_{kj}$ 给出。要使 $A_{ij}$ 非零，必须存在一个 $k$ 使得 $L_{ki}$ 和 $L_{kj}$ 都非零。根据 $L$ 的定义，$L_{ki}=1$ 意味着 $k=i-1$，而 $L_{kj}=1$ 意味着 $k=j-1$。因此，我们必须有 $i-1 = j-1$，即 $i=j$。要使元素 $A_{ii}$ 非零，我们需要 $L_{i-1,i}=1$，这对 $i \\in \\{2, \\dots, n\\}$ 成立。对于 $i=1$，不存在 $k$ 使得 $L_{k1}=1$，所以 $A_{11}=0$。对角元素为 $A_{ii}=1$ (对于 $i \\in \\{2, \\dots, n\\}$) 和 $A_{11}=0$。非对角元素全为零。\n$$\nA = L^{\\top}L = \\mathrm{diag}(0, 1, 1, \\dots, 1)\n$$\n接下来，我们计算中心矩阵 $H = LL^{\\top}$：\n$H$ 的元素为 $H_{ij} = \\sum_{k=1}^{n} L_{ik} (L^{\\top})_{kj} = \\sum_{k=1}^{n} L_{ik} L_{jk}$。要使 $H_{ij}$ 非零，必须存在一个 $k$ 使得 $L_{ik}=1$ 和 $L_{jk}=1$。这意味着 $k=i+1$ 和 $k=j+1$，即 $i=j$。要使元素 $H_{ii}$ 非零，我们需要 $L_{i,i+1}=1$，这对 $i \\in \\{1, \\dots, n-1\\}$ 成立。对于 $i=n$，不存在 $k$ 使得 $L_{nk}=1$，所以 $H_{nn}=0$。对角元素为 $H_{ii}=1$ (对于 $i \\in \\{1, \\dots, n-1\\}$) 和 $H_{nn}=0$。非对角元素全为零。\n$$\nH = LL^{\\top} = \\mathrm{diag}(1, 1, \\dots, 1, 0)\n$$\n对角矩阵的特征值是其对角元。\n对于 $A=\\mathrm{diag}(0, 1, \\dots, 1)$，特征值为 $\\lambda_1=0$ 和 $\\lambda_2 = \\dots = \\lambda_n = 1$。最大特征值是 $\\lambda_{\\max}=1$，其重数为 $n-1$。与 $\\lambda_{\\max}=1$ 相关联的特征空间由标准基向量 $\\{e_2, e_3, \\dots, e_n\\}$ 张成。\n对于 $H=\\mathrm{diag}(1, 1, \\dots, 1, 0)$，特征值为 $\\lambda_1 = \\dots = \\lambda_{n-1} = 1$ 和 $\\lambda_n=0$。最大特征值是 $\\lambda_{\\max}=1$，其重数为 $n-1$。与 $\\lambda_{\\max}=1$ 相关联的特征空间由 $\\{e_1, e_2, \\dots, e_{n-1}\\}$ 张成。\n\n幂法从一个向量 $v_0$ 开始，会收敛到 $v_0$ 在最大特征值对应特征空间上的投影，前提是这个投影非零。初始向量给定为 $a^{(0)} = \\mathbf{1}$ 和 $h^{(0)} = \\mathbf{1}$。\n对于权威向量，迭代过程收敛到一个与 $a^{(0)} = \\mathbf{1}$ 在特征空间 $\\mathrm{span}\\{e_2, \\dots, e_n\\}$ 上的投影成比例的向量。这个投影是 $\\sum_{j=2}^{n} e_j = (0, 1, 1, \\dots, 1)^{\\top}$。或者，我们可以看到经过一次迭代（未归一化）后，我们有 $a^{(1)} \\propto A a^{(0)} = \\mathrm{diag}(0, 1, \\dots, 1) (1, 1, \\dots, 1)^{\\top} = (0, 1, \\dots, 1)^{\\top}$。由于这个向量已经在 $\\lambda=1$ 的特征空间中，进一步的迭代只会将其乘以1，因此向量方向是固定的。极限未归一化权威向量是 $a^{\\star}_{\\text{un-norm}} = (0, 1, 1, \\dots, 1)^{\\top}$。\n\n对于中心向量，我们将 $h^{(0)}=\\mathbf{1}$ 投影到特征空间 $\\mathrm{span}\\{e_1, \\dots, e_{n-1}\\}$ 上。这个投影是 $\\sum_{j=1}^{n-1} e_j = (1, 1, \\dots, 1, 0)^{\\top}$。或者，$h^{(1)} \\propto H h^{(0)} = \\mathrm{diag}(1, \\dots, 1, 0) (1, \\dots, 1)^{\\top} = (1, 1, \\dots, 1, 0)^{\\top}$。极限未归一化中心向量是 $h^{\\star}_{\\text{un-norm}} = (1, 1, \\dots, 1, 0)^{\\top}$。\n\n问题要求分数是经过 $\\ell_2$归一化的。\n对于权威分数：\n向量是 $(0, 1, \\dots, 1)^{\\top}$。其中有 $n-1$ 个分量等于1。\n其 $\\ell_2$-范数为 $\\|a^{\\star}_{\\text{un-norm}}\\|_2 = \\sqrt{0^2 + \\sum_{j=2}^{n} 1^2} = \\sqrt{n-1}$。\n归一化后的极限权威向量为 $a^{\\star} = \\frac{1}{\\sqrt{n-1}} (0, 1, 1, \\dots, 1)^{\\top}$。\n该向量的第 $j$ 个分量是：\n$a_j^{\\star} = \\begin{cases} 0  &\\text{若 } j=1 \\\\ \\frac{1}{\\sqrt{n-1}}  &\\text{若 } j \\in \\{2, \\dots, n\\} \\end{cases}$。\n使用克罗内克δ (Kronecker delta) $\\delta_{ij}$（当 $i=j$ 时为1，否则为0），我们可以将其写成一个单一表达式：\n$a_j^{\\star} = \\frac{1 - \\delta_{j1}}{\\sqrt{n-1}}$。\n\n对于中心分数：\n向量是 $(1, 1, \\dots, 1, 0)^{\\top}$。其中有 $n-1$ 个分量等于1。\n其 $\\ell_2$-范数为 $\\|h^{\\star}_{\\text{un-norm}}\\|_2 = \\sqrt{\\sum_{j=1}^{n-1} 1^2 + 0^2} = \\sqrt{n-1}$。\n归一化后的极限中心向量为 $h^{\\star} = \\frac{1}{\\sqrt{n-1}} (1, 1, \\dots, 1, 0)^{\\top}$。\n该向量的第 $j$ 个分量是：\n$h_j^{\\star} = \\begin{cases} \\frac{1}{\\sqrt{n-1}}  &\\text{若 } j \\in \\{1, \\dots, n-1\\} \\\\ 0  &\\text{若 } j=n \\end{cases}$。\n使用克罗内克δ，可以将其写为：\n$h_j^{\\star} = \\frac{1 - \\delta_{jn}}{\\sqrt{n-1}}$。\n\n最终答案是这两个表达式组成的行向量。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{1 - \\delta_{j1}}{\\sqrt{n-1}} & \\frac{1 - \\delta_{jn}}{\\sqrt{n-1}} \\end{pmatrix}\n}\n$$"
        }
    ]
}