{
    "hands_on_practices": [
        {
            "introduction": "PageRank 算法的核心是马尔可夫链的平稳分布。本练习将该模型简化为其最基本的形式，以帮助您巩固这一基础。通过在一个没有“远距传输”的简化场景（即阻尼因子 $\\alpha=1$）中推导一个简单循环图的平稳分布，您将直接处理随机游走的核心数学原理，旨在阐明 PageRank 与马尔可夫链理论之间的基本联系 。",
            "id": "4296056",
            "problem": "考虑一个有 $3$ 个节点（标记为 $1$、$2$ 和 $3$）的有向网络，其邻接矩阵为\n$$\nA \\;=\\; \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n1  0  0\n\\end{pmatrix}.\n$$\n一个随机冲浪者从当前节点出发，以相等的概率沿着出射链接移动，从而产生一个有限状态一阶马尔可夫链 (MC)。令 $P$ 表示相应的列随机转移矩阵，它通过用其源节点的出度对 $A$ 的每一列进行归一化而得到。在没有瞬移（即瞬移参数 $\\alpha = 1$）的 PageRank (PR) 随机冲浪者模型中，平稳分布 $r$ 被定义为在马尔可夫链的动态下保持不变的非负向量，且其各项之和为 $1$。\n\n仅从有向图上的列随机转移矩阵的核心定义、有限马尔可夫链的平稳分布定义以及概率守恒出发，推导出该网络的平稳分布 $r$。请使用 LaTeX $\\texttt{pmatrix}$ 环境将您的最终答案表示为单个行向量。无需四舍五入。",
            "solution": "用户要求我解决一个与 PageRank 算法相关的问题，该问题涉及在给定网络上寻找马尔可夫链的平稳分布。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件**\n\n-   网络：一个有 $3$ 个节点（标记为 $1$、$2$ 和 $3$）的有向网络。\n-   邻接矩阵：\n    $$\n    A \\;=\\; \\begin{pmatrix}\n    0  1  0 \\\\\n    0  0  1 \\\\\n    1  0  0\n    \\end{pmatrix}\n    $$\n-   马尔可夫链模型：一个随机冲浪者从当前节点出发，以相等的概率沿着出射链接移动。这定义了一个有限状态一阶马尔可夫链 (MC)。\n-   转移矩阵 ($P$)：$P$ 是一个列随机转移矩阵，通过用其源节点的出度对 $A$ 的每一列进行归一化而得到。\n-   PageRank 模型：瞬移参数为 $\\alpha = 1$。\n-   平稳分布 ($r$)：$r$ 是一个在马尔可夫链的动态下保持不变的非负向量，即 $Pr=r$。$r$ 的各项之和必须为 $1$，即 $\\sum_i r_i = 1$。\n-   目标：推导出该网络的平穩分布 $r$。\n\n**1.2. 使用提取的已知条件进行验证**\n\n-   **科学依据**：该问题很好地基于线性代数、图论和马尔可夫链的数学理论，这些是 PageRank 算法的基础。所使用的所有概念都是标准的且定义明确。\n-   **适定性**：由邻接矩阵表示的图是强连通的（它形成了一个单一的循环 $1 \\to 3 \\to 2 \\to 1$）。对于一个有限的、不可约的马尔可夫链，保证存在唯一的平稳分布。\n-   **客观性**：该问题以精确、客观的数学语言陈述，没有歧义或主观性陈述。\n-   **完整性和一致性**：该问题提供了所有必要的信息。转移矩阵的构建定义是明确的，并且与列向量表示状态的标准实践一致。条件 $\\alpha=1$ 将 PageRank 模型简化为一个标准的平稳分布问题，这是一致的。\n\n**1.3. 结论**\n\n该问题是有效的，因为它在科学上是合理的、适定的且信息完备。我现在将着手解决。\n\n### 步骤 2：求解推导\n\n该问题要求推导给定网络的平稳分布 $r$。这包括两个主要步骤：首先，从邻接矩阵 $A$ 构建列随机转移矩阵 $P$；其次，求解满足平稳分布性质的向量 $r$。\n\n**2.1. 构建转移矩阵 $P$**\n\n问题指出，转移矩阵 $P$ 是通过用其源节点的出度对邻接矩阵 $A$ 的每一列进行归一化而得到的。这意味着 $A$ 的列对应于源节点，而一个条目 $A_{ij}$ 为 $1$ 表示一个从节点 $j$到节点 $i$ 的有向链接。\n\n节点 $j$ 的出度，记为 $k_j^{\\text{out}}$，是它发出的链接数量。根据 $A$ 的惯例，$k_j^{\\text{out}}$ 是 $A$ 的第 $j$ 列中各项的和。\n$$\nk_j^{\\text{out}} = \\sum_{i=1}^{3} A_{ij}\n$$\n我们来计算每个节点的出度：\n-   对于节点 $1$：$k_1^{\\text{out}} = A_{11} + A_{21} + A_{31} = 0 + 0 + 1 = 1$。\n-   对于节点 $2$：$k_2^{\\text{out}} = A_{12} + A_{22} + A_{32} = 1 + 0 + 0 = 1$。\n-   对于节点 $3$：$k_3^{\\text{out}} = A_{13} + A_{23} + A_{33} = 0 + 1 + 0 = 1$。\n\n从节点 $j$ 转移到节点 $i$ 的概率，记为 $P_{ij}$，由 $A_{ij}$ 除以源节点 $j$ 的出度给出。\n$$\nP_{ij} = \\frac{A_{ij}}{k_j^{\\text{out}}}\n$$\n由于对于所有 $j \\in \\{1, 2, 3\\}$ 都有 $k_j^{\\text{out}} = 1$，所以转移矩阵 $P$与邻接矩阵 $A$ 相同。\n$$\nP \\;=\\; \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n1  0  0\n\\end{pmatrix}\n$$\n该矩阵是列随机的，因为每列的条目之和为 $1$。\n\n**2.2. 求解平穩分布 $r$**\n\n平稳分布 $r = \\begin{pmatrix} r_1 \\\\ r_2 \\\\ r_3 \\end{pmatrix}$ 由两个条件定义：\n1.  不变性：$P r = r$。\n2.  概率守恒：$\\sum_{i=1}^{3} r_i = 1$，其中 $r_i \\ge 0$。\n\n不变性条件 $P r = r$ 是特征值 $\\lambda = 1$ 的特征向量方程。我们可以将其写为 $(P - I)r = 0$，其中 $I$ 是 $3 \\times 3$ 的单位矩阵。\n$$\n\\left( \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n1  0  0\n\\end{pmatrix} - \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} \\right)\n\\begin{pmatrix} r_1 \\\\ r_2 \\\\ r_3 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix}\n-1  1  0 \\\\\n0  -1  1 \\\\\n1  0  -1\n\\end{pmatrix}\n\\begin{pmatrix} r_1 \\\\ r_2 \\\\ r_3 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n这个矩阵方程对应于以下线性方程组：\n1.  $-r_1 + r_2 = 0 \\implies r_1 = r_2$\n2.  $-r_2 + r_3 = 0 \\implies r_2 = r_3$\n3.  $r_1 - r_3 = 0 \\implies r_1 = r_3$\n\n从这个方程组中，我们推断出平稳分布向量的所有分量都相等：\n$$\nr_1 = r_2 = r_3\n$$\n现在，我们应用概率守恒条件：\n$$\nr_1 + r_2 + r_3 = 1\n$$\n将 $r_2=r_1$ 和 $r_3=r_1$ 代入方程，得到：\n$$\nr_1 + r_1 + r_1 = 1\n$$\n$$\n3 r_1 = 1\n$$\n$$\nr_1 = \\frac{1}{3}\n$$\n因此，平稳分布的分量是：\n$$\nr_1 = r_2 = r_3 = \\frac{1}{3}\n$$\n平稳分布向量是 $r = \\begin{pmatrix} 1/3 \\\\ 1/3 \\\\ 1/3 \\end{pmatrix}$。问题要求将最终答案表示为单个行向量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "现实世界的网络充满了复杂性，例如没有出链的“悬挂节点”。一个稳健的排名算法必须能够优雅地处理这些情况。本练习将引导您构建完整的 PageRank 转移矩阵，并特别关注悬挂节点的处理方法，以及引入非均匀的个性化向量 。通过手动执行幂法的前几次迭代，您将亲身体验 PageRank 分数在网络中如何流动，并理解阻尼因子和远距传输机制如何确保算法的收敛性和稳定性。",
            "id": "4296061",
            "problem": "考虑一个有 $n=4$ 个节点（标记为 $\\{1,2,3,4\\}$）的有向网络。节点 $2$ 和 $4$ 是悬挂节点（它们的出度为零）。观察到的超链接如下：节点 $1$ 链接到节点 $2$ 和 $3$，节点 $3$ 链接到节点 $1$。采用节点上的离散时间马尔可夫链的随机冲浪者模型，其中在每一步，冲浪者以概率 $\\alpha \\in (0,1)$ 跟随一个出站超链接，并以概率 $1-\\alpha$ 根据个性化分布 $\\mathbf{v} \\in \\mathbb{R}^{4}$ 进行传送。个性化向量是非均匀的，由 $\\mathbf{v} = \\big(\\frac{1}{2}, \\frac{1}{6}, \\frac{1}{3}, 0\\big)^{\\top}$ 给出，阻尼因子为 $\\alpha = \\frac{17}{20}$。马尔可夫链的转移机制必须根据以下第一性原理构建：\n- 对于任何非悬挂节点 $j$，从节点 $j$ 转移到任何节点 $i$ 的概率与节点 $j$ 的观察到的出站链接成比例，并进行归一化，形成一个总和为 $1$ 的列。\n- 对于任何悬挂节点 $j$，随机转移核的对应列被个性化分布 $\\mathbf{v}$ 替换。\n\n令 $S \\in \\mathbb{R}^{4 \\times 4}$ 表示根据上述规则构建的列随机超链接矩阵。从个性化分布作为初始状态 $x^{(0)} = \\mathbf{v}$ 开始，考虑 PageRank 向量的线性迭代公式 $x^{(k+1)} = \\alpha S x^{(k)} + (1-\\alpha)\\mathbf{v}$。为该网络显式地构建矩阵 $S$，验证其为列随机矩阵，并精确计算前两次迭代 $x^{(1)}$ 和 $x^{(2)}$，结果表示为有理数。给出 $x^{(2)}$ 的第三个分量的精确值，表示为最简分数。不需要四舍五入，也不涉及单位。",
            "solution": "问题陈述经评估有效。它在科学上基于马尔可夫链理论和PageRank算法，问题设定良好，包含所有必要数据和明确的规则，并以客观、正式的语言表述。不存在矛盾、信息缺失或违反科学原理的情况。因此，我们可以进行完整解答。\n\n问题要求构建超链接矩阵 $S$，验证其性质，并计算 PageRank 向量的前两次迭代，最终求出第二次迭代的第三个分量。\n\n首先，我们构建列随机超链接矩阵 $S \\in \\mathbb{R}^{4 \\times 4}$。该网络有 $n=4$ 个节点，标记为 $\\{1,2,3,4\\}$。\n\n- **节点 1** 是非悬挂节点，有指向节点 $2$ 和 $3$ 的出站链接。其出度为 $k_1=2$。$S$ 的第一列表示从节点 $1$ 开始的转移。概率均等地分配给其出站链接。因此，该列的条目为 $S_{21} = \\frac{1}{2}$，$S_{31} = \\frac{1}{2}$，此列中的所有其他条目均为 $0$。\n\n- **节点 2** 是悬挂节点。根据规则，$S$ 的第二列被替换为个性化向量 $\\mathbf{v} = \\left(\\frac{1}{2}, \\frac{1}{6}, \\frac{1}{3}, 0\\right)^{\\top}$。\n\n- **节点 3** 是非悬挂节点，有指向节点 $1$ 的出站链接。其出度为 $k_3=1$。$S$ 的第三列只有一个非零条目，$S_{13} = 1$。\n\n- **节点 4** 是悬挂节点。$S$ 的第四列也被替换为个性化向量 $\\mathbf{v}$。\n\n结合这些列，矩阵 $S$ 构建如下：\n$$S = \\begin{pmatrix} 0  \\frac{1}{2}  1  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{6}  0  \\frac{1}{6} \\\\ \\frac{1}{2}  \\frac{1}{3}  0  \\frac{1}{3} \\\\ 0  0  0  0 \\end{pmatrix}$$\n\n接下来，我们通过检查每列条目之和是否等于 $1$ 来验证 $S$ 是列随机的。\n- 第 1 列：$0 + \\frac{1}{2} + \\frac{1}{2} + 0 = 1$。\n- 第 2 列：$\\frac{1}{2} + \\frac{1}{6} + \\frac{1}{3} + 0 = \\frac{3}{6} + \\frac{1}{6} + \\frac{2}{6} = \\frac{6}{6} = 1$。\n- 第 3 列：$1 + 0 + 0 + 0 = 1$。\n- 第 4 列：$\\frac{1}{2} + \\frac{1}{6} + \\frac{1}{3} + 0 = 1$。\n矩阵 $S$ 被确认为列随机矩阵。\n\nPageRank 迭代公式为 $x^{(k+1)} = \\alpha S x^{(k)} + (1-\\alpha)\\mathbf{v}$。\n给定阻尼因子 $\\alpha = \\frac{17}{20}$，因此 $1-\\alpha = \\frac{3}{20}$。初始状态为 $x^{(0)} = \\mathbf{v} = \\left(\\frac{1}{2}, \\frac{1}{6}, \\frac{1}{3}, 0\\right)^{\\top}$。\n\n我们计算第一次迭代 $x^{(1)}$。首先，我们计算乘积 $S x^{(0)} = S\\mathbf{v}$：\n$$S\\mathbf{v} = \\begin{pmatrix} 0  \\frac{1}{2}  1  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{6}  0  \\frac{1}{6} \\\\ \\frac{1}{2}  \\frac{1}{3}  0  \\frac{1}{3} \\\\ 0  0  0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{6} \\\\ \\frac{1}{3} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0(\\frac{1}{2}) + \\frac{1}{2}(\\frac{1}{6}) + 1(\\frac{1}{3}) + \\frac{1}{2}(0) \\\\ \\frac{1}{2}(\\frac{1}{2}) + \\frac{1}{6}(\\frac{1}{6}) + 0(\\frac{1}{3}) + \\frac{1}{6}(0) \\\\ \\frac{1}{2}(\\frac{1}{2}) + \\frac{1}{3}(\\frac{1}{6}) + 0(\\frac{1}{3}) + \\frac{1}{3}(0) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{12} + \\frac{1}{3} \\\\ \\frac{1}{4} + \\frac{1}{36} \\\\ \\frac{1}{4} + \\frac{1}{18} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{12} \\\\ \\frac{10}{36} \\\\ \\frac{11}{36} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{12} \\\\ \\frac{5}{18} \\\\ \\frac{11}{36} \\\\ 0 \\end{pmatrix}$$\n现在，我们求 $x^{(1)}$：\n$$x^{(1)} = \\alpha S x^{(0)} + (1-\\alpha)\\mathbf{v} = \\frac{17}{20} \\begin{pmatrix} \\frac{5}{12} \\\\ \\frac{5}{18} \\\\ \\frac{11}{36} \\\\ 0 \\end{pmatrix} + \\frac{3}{20} \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{6} \\\\ \\frac{1}{3} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{85}{240} + \\frac{3}{40} \\\\ \\frac{85}{360} + \\frac{3}{120} \\\\ \\frac{187}{720} + \\frac{3}{60} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{85}{240} + \\frac{18}{240} \\\\ \\frac{85}{360} + \\frac{9}{360} \\\\ \\frac{187}{720} + \\frac{36}{720} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{103}{240} \\\\ \\frac{94}{360} \\\\ \\frac{223}{720} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{103}{240} \\\\ \\frac{47}{180} \\\\ \\frac{223}{720} \\\\ 0 \\end{pmatrix}$$\n\n最后，我们计算第二次迭代 $x^{(2)}$ 以求其第三个分量。\n$x^{(2)} = \\alpha S x^{(1)} + (1-\\alpha)\\mathbf{v}$。\n第三个分量是 $x^{(2)}_3 = \\alpha (S x^{(1)})_3 + (1-\\alpha)v_3$。\n首先，我们求乘积 $S x^{(1)}$ 的第三个分量：\n$$(S x^{(1)})_3 = S_{3,:} \\cdot x^{(1)} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{3}  0  \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} \\frac{103}{240} \\\\ \\frac{47}{180} \\\\ \\frac{223}{720} \\\\ 0 \\end{pmatrix} = \\frac{1}{2}\\left(\\frac{103}{240}\\right) + \\frac{1}{3}\\left(\\frac{47}{180}\\right) = \\frac{103}{480} + \\frac{47}{540}$$\n为了将这些分数相加，我们找到一个公分母，$\\text{lcm}(480, 540) = 4320$。\n$$(S x^{(1)})_3 = \\frac{103 \\cdot 9}{4320} + \\frac{47 \\cdot 8}{4320} = \\frac{927 + 376}{4320} = \\frac{1303}{4320}$$\n现在我们可以计算 $x^{(2)}_3$：\n$$x^{(2)}_3 = \\frac{17}{20} \\left( \\frac{1303}{4320} \\right) + \\frac{3}{20} \\left( \\frac{1}{3} \\right) = \\frac{17 \\cdot 1303}{20 \\cdot 4320} + \\frac{1}{20} = \\frac{22151}{86400} + \\frac{1}{20}$$\n为了相加，我们使用公分母 $86400$：\n$$x^{(2)}_3 = \\frac{22151}{86400} + \\frac{4320}{86400} = \\frac{22151 + 4320}{86400} = \\frac{26471}{86400}$$\n分母是 $86400 = 2^7 \\cdot 3^3 \\cdot 5^2$。分子 $26471$ 不能被 $2$、$3$（各位数字之和为 $20$）或 $5$ 整除。因此，该分数是最简形式。\n$x^{(2)}$ 的第三个分量的精确值是 $\\frac{26471}{86400}$。",
            "answer": "$$\\boxed{\\frac{26471}{86400}}$$"
        },
        {
            "introduction": "理论推导和手动计算为我们提供了深刻的见解，但要将 PageRank 应用于实际问题，则必须掌握其计算实现。本练习是一个编程任务，要求您从头开始实现幂法来计算 PageRank 向量，并应用于具有不同拓扑结构（包括含有悬挂节点和社区结构的图）的网络 。通过构建谷歌矩阵、迭代求解分数并经验性地分析收敛速度，您将获得关于网络结构如何影响算法性能的实践技能和直观理解。",
            "id": "4296002",
            "problem": "考虑一个包含 $5$ 个节点的有向网络，以及建模为离散时间马尔可夫链的 PageRank 过程。使用以下基本基础：马尔可夫链由一个列随机转移矩阵定义，其中条目 $P_{ij}$ 表示从节点 $j$ 到节点 $i$ 的转移概率，概率分布向量 $x^{(k)}$ 通过乘法 $x^{(k)} = P \\, x^{(k-1)}$ 演化。在随机冲浪者模型中，在每一步，冲浪者以概率 $\\alpha$ 从当前节点均匀随机地跟随一条出链，并以概率 $1 - \\alpha$ 均匀地传送到任何一个节点。如果一个节点没有出链（即悬挂节点），那么在尝试跟随链接时，冲浪者会在所有节点中进行均匀选择。从均匀分布开始初始化该过程。任务是对此过程计算幂法 (PM) 的几次迭代，并根据连续差分的 $L^1$ 范数的衰减来经验性地估计收敛速率。\n\n通过以下从随机冲浪者模型派生出的程序来构建转移矩阵：\n- 令 $A$ 为邻接矩阵，如果存在从节点 $j$ 到节点 $i$ 的有向边，则其条目 $A_{ij} = 1$，否则 $A_{ij} = 0$。\n- 通过对 $A$ 的每一列进行归一化来形成一个列随机矩阵 $S$；如果列 $j$ 的和为零（节点 $j$ 是悬挂节点），则用所有 $5$ 个节点上的均匀分布替换该列。\n- 通过将 $S$ 与均匀传送相结合来形成随机冲浪者转移矩阵 $G$：$G$ 的每一列分别是 $S$ 的相应列与所有 $5$ 个节点上的均匀分布的凸组合，权重分别为 $\\alpha$ 和 $1 - \\alpha$。\n\n对于下面的每个图，设置 $\\alpha = 0.85$，将 $x^{(0)}$ 初始化为 $5$ 个节点上的均匀分布，并对 $k = 1,2,\\dots,K$（其中 $K = 40$）进行迭代 $x^{(k)} = G \\, x^{(k-1)}$。令 $d^{(k)} = \\lVert x^{(k)} - x^{(k-1)} \\rVert_{1}$ (对于 $k \\geq 1$)。对于 $k \\geq 2$，定义步进衰减比 $r^{(k)} = d^{(k)} / d^{(k-1)}$。将在尾部窗口 $k \\in \\{20,21,\\dots,40\\}$ 上的 $r^{(k)}$ 的中位数作为收敛速率的经验估计。\n\n三个测试图（每个都有 $5$ 个节点）如下：\n- 测试用例 $1$（无悬挂节点，中等密度）：\n  - 有向边：$1 \\to 2$，$1 \\to 3$；$2 \\to 3$，$2 \\to 4$；$3 \\to 1$，$3 \\to 5$；$4 \\to 3$，$4 \\to 5$；$5 \\to 1$，$5 \\to 2$。\n- 测试用例 $2$（一个悬挂节点）：\n  - 有向边：$1 \\to 2$；$2 \\to 3$，$2 \\to 5$；$3 \\to 1$；$4 \\to 3$，$4 \\to 5$；节点 $5$ 没有出边。\n- 测试用例 $3$（两个稀疏互连的社群）：\n  - 有向边：$1 \\to 2$，$1 \\to 3$；$2 \\to 1$；$3 \\to 2$，$3 \\to 4$；$4 \\to 5$；$5 \\to 4$。\n\n您的程序必须：\n- 针对每个测试用例，根据所述规则构建 $S$ 和 $G$。\n- 在 $x^{(0)}$ 为 $5$ 个节点上的均匀分布的情况下，计算 $k = 1,\\dots,40$ 的 $x^{(k)}$。\n- 按规定计算 $d^{(k)}$ 和 $r^{(k)}$。\n- 对于每个测试用例，输出定义为在 $k \\in \\{20,\\dots,40\\}$ 上的 $r^{(k)}$ 中位数的经验收敛速率估计。\n\n最终输出格式：\n- 生成一行，其中包含测试用例 1、2 和 3 的三个估计收敛速率，按此顺序排列，形式为用方括号括起来的逗号分隔列表，每个浮点数四舍五入到六位小数，例如 $\\texttt{[0.731234,0.812345,0.843210]}$。",
            "solution": "该问题提出了一个来自网络科学领域的有效且定义明确的任务，具体涉及 PageRank 算法。它要求对用于计算三个给定网络结构的 PageRank 分数的幂法的收敛速率进行经验性估计。该问题在科学上基于马尔可夫链和线性代数理论，包含了所有必要的数据和定义，并且没有歧义或矛盾。我们将提供一个完整的解决方案。\n\n问题的核心是模拟 PageRank 过程，该过程被建模为在一个包含 $N=5$ 个节点的网络上的离散时间马尔可夫链。系统在步骤 $k$ 的状态是一个概率分布向量 $x^{(k)} \\in \\mathbb{R}^N$，其中第 $i$ 个分量 $x_i^{(k)}$ 是“随机冲浪者”位于节点 $i$ 的概率。该状态的演化由方程 $x^{(k)} = G x^{(k-1)}$ 控制，其中 $G$ 是谷歌矩阵，一个列随机转移矩阵。稳态分布 $x^* = \\lim_{k\\to\\infty} x^{(k)}$ 是 PageRank 向量。\n\n该过程涉及几个步骤：\n1.  为每个图构建邻接矩阵 $A$。\n2.  从 $A$ 构建链接跟随随机矩阵 $S$，并考虑悬挂节点。\n3.  使用阻尼因子 $\\alpha$ 形成谷歌矩阵 $G$。\n4.  迭代应用幂法以找到 PageRank 向量。\n5.  从迭代序列中经验性地估计收敛速率。\n\n让我们详细说明这些步骤。为计算方便，我们将节点从 $0$ 到 $4$ 进行索引，而不是问题中的 $1$ 到 $5$。\n\n**1. 邻接矩阵 $A$**\n邻接矩阵 $A$ 编码了网络的链接结构。根据问题的定义，如果存在从节点 $j$ 到节点 $i$ 的有向边，则条目 $A_{ij}$ 为 $1$，否则为 $0$。因此，$A$ 的每一列 $j$ 代表从节点 $j$ 出发的出链。\n\n**2. 随机矩阵 $S$**\n矩阵 $S$ 模拟了仅跟随链接的冲浪者的转移。它由 $A$ 派生而来。对于每个节点 $j$，我们计算其出度 $d_j^{out} = \\sum_{i=1}^{N} A_{ij}$。这是 $A$ 的第 $j$ 列中元素的总和。\n- 如果 $d_j^{out} > 0$，位于节点 $j$ 的冲浪者会从 $d_j^{out}$ 条出链中均匀随机选择一条。$S$ 的第 $j$ 列，记为 $S_j$，通过对 $A$ 的相应列进行归一化得到：$S_{ij} = A_{ij} / d_j^{out}$。\n- 如果 $d_j^{out} = 0$，则节点 $j$ 是一个“悬挂节点”。问题规定，在这种情况下，冲浪者以均等概率跳转到网络中的任何节点。因此，$S$ 的第 $j$ 列被设置为一个均匀概率向量，即对于所有 $i$，$S_{ij} = 1/N$。\n\n**3. 谷歌矩阵 $G$**\n谷歌矩阵 $G$ 融入了“随机传送”机制，这确保了底层的马尔可夫链是遍历的，因此具有唯一的稳态分布。它被构造为一个凸组合：\n$$G = \\alpha S + (1 - \\alpha) \\frac{1}{N} J$$\n其中 $\\alpha = 0.85$ 是阻尼因子，$S$ 是上一步得到的矩阵，$N=5$ 是节点数，$J$ 是所有元素都为 1 的 $N \\times N$ 矩阵。项 $\\frac{1}{N}J$ 表示向任何节点的均匀传送。$G$ 的每一列都是一个有效的概率分布，使 $G$ 成为列随机矩阵。\n\n**4. 幂法迭代**\nPageRank 向量是 $G$ 的主特征向量（对应于特征值 $\\lambda_1 = 1$）。幂法是一种寻找该特征向量的迭代算法。我们从一个初始概率分布 $x^{(0)}$ 开始，并重复应用转移矩阵：\n$$x^{(k)} = G x^{(k-1)}$$\n问题指定初始状态为均匀分布：对于所有 $i \\in \\{0, 1, 2, 3, 4\\}$，$x_i^{(0)} = 1/N = 1/5$。我们需要执行 $K=40$ 次迭代。\n\n**5. 经验收敛速率估计**\n幂法的理论收敛速率由 $G$ 的第二大特征值的模 $|\\lambda_2|$ 决定。当 $k$ 变大时，误差项由与 $\\lambda_2$ 相关的分量主导，连续迭代之间的距离呈几何级数衰减：\n$$\\lVert x^{(k)} - x^{(k-1)} \\rVert \\propto |\\lambda_2|^k$$\n问题要求对此速率进行经验估计。我们计算连续迭代之间差分的 $L^1$-范数：\n$$d^{(k)} = \\lVert x^{(k)} - x^{(k-1)} \\rVert_{1} = \\sum_{i=0}^{N-1} |x_i^{(k)} - x_i^{(k-1)}| \\quad \\text{for } k \\geq 1$$\n从这个差分序列中，我们计算连续项的比率：\n$$r^{(k)} = \\frac{d^{(k)}}{d^{(k-1)}} \\quad \\text{for } k \\geq 2$$\n对于大的 $k$，该比率 $r^{(k)}$ 应趋近于 $|\\lambda_2|$。为获得稳定估计，我们计算这些比率在迭代的尾部窗口（具体为 $k \\in \\{20, 21, \\dots, 40\\}$）上的中位数。该中位数作为我们对收敛速率的经验估计。\n\n此过程将应用于所提供的三个测试用例中的每一个。\n- **测试用例 1：** 一个没有悬挂节点的连接良好的图。\n- **测试用例 2：** 一个有一个悬挂节点（节点 $5$，或索引 $4$）的图，在构建 $S$ 期间需要特殊处理。\n- **测试用例 3：** 一个具有社群结构的图，已知这可能会减慢收敛速度，导致经验速率更接近 $\\alpha$。\n\n实现将精确遵循这些步骤，以计算每个用例的估计收敛速率。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the empirical convergence rate for the PageRank algorithm on three test graphs.\n    \"\"\"\n\n    # Node count and algorithm parameters\n    N = 5\n    ALPHA = 0.85\n    K = 40\n    \n    # Define the test cases from the problem statement.\n    # Edges are (source, destination) using 1-based indexing as in the problem.\n    test_cases_edges = [\n        # Test case 1 (no dangling nodes, moderately dense)\n        [(1, 2), (1, 3), (2, 3), (2, 4), (3, 1), (3, 5), (4, 3), (4, 5), (5, 1), (5, 2)],\n        # Test case 2 (one dangling node)\n        [(1, 2), (2, 3), (2, 5), (3, 1), (4, 3), (4, 5)], # Node 5 is dangling\n        # Test case 3 (two communities with sparse interconnection)\n        [(1, 2), (1, 3), (2, 1), (3, 2), (3, 4), (4, 5), (5, 4)],\n    ]\n\n    results = []\n    \n    for edges in test_cases_edges:\n        # Step 1: Construct Adjacency Matrix A (using 0-based indexing)\n        # A[i, j] = 1 if there is an edge from j to i\n        A = np.zeros((N, N), dtype=float)\n        for src, dest in edges:\n            A[dest - 1, src - 1] = 1.0\n\n        # Step 2: Construct Stochastic Matrix S\n        S = A.copy()\n        out_degrees = S.sum(axis=0)\n        \n        for j in range(N):\n            if out_degrees[j] > 0:\n                S[:, j] /= out_degrees[j]\n            else: # Dangling node\n                S[:, j] = 1.0 / N\n\n        # Step 3: Construct Google Matrix G\n        J = np.ones((N, N), dtype=float)\n        G = ALPHA * S + (1 - ALPHA) * (1.0 / N) * J\n\n        # Step 4: Power Method Iteration\n        # Initialize x^(0) as the uniform distribution\n        x_prev = np.ones(N) / N\n        \n        # Store L1 norms of differences\n        d_k = []\n        for _ in range(K):\n            x_curr = G @ x_prev\n            # Calculate d^(k) = ||x^(k) - x^(k-1)||_1\n            diff_norm = np.linalg.norm(x_curr - x_prev, ord=1)\n            d_k.append(diff_norm)\n            x_prev = x_curr\n\n        # Step 5: Empirical Convergence Rate Estimation\n        # Calculate ratios r^(k) = d^(k) / d^(k-1)\n        r_k = []\n        # Loop for k from 2 to K (which is index 1 to K-1 of d_k)\n        for i in range(1, len(d_k)):\n            # Avoid division by zero, although not expected for this problem\n            if d_k[i-1] > 1e-15:\n                ratio = d_k[i] / d_k[i-1]\n                r_k.append(ratio)\n            else:\n                # If a difference becomes zero, convergence is perfect (rate 0)\n                r_k.append(0.0)\n\n        # The problem asks for the median of r^(k) for k in {20, ..., 40}.\n        # r_k[i] corresponds to r^(i+2). So k=20 corresponds to index 18.\n        # The tail window is from index 18 (for k=20) to 38 (for k=40).\n        tail_window_start_index = 18\n        tail_ratios = r_k[tail_window_start_index:]\n        \n        convergence_rate = np.median(tail_ratios)\n        results.append(convergence_rate)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}