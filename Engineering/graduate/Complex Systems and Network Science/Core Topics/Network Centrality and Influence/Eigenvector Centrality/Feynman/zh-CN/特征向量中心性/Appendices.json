{
    "hands_on_practices": [
        {
            "introduction": "理论的最佳伴侣是实践。为了将特征向量中心性的抽象定义转化为具体理解，我们从一个基础练习开始。这个练习要求我们为一个简单的四节点路径图计算特征向量中心性，它将引导我们从第一性原理出发，通过构建邻接矩阵和求解核心的特征值方程 $A c = \\lambda c$，来精确地确定网络中每个节点的中心性得分。",
            "id": "1501053",
            "problem": "考虑一个由四个节点组成的小型信息网络，节点标记为 1, 2, 3, 4。该网络中的连接如下：\n- 节点 1 只与节点 2 连接。\n- 节点 2 与节点 1 和节点 3 连接。\n- 节点 3 与节点 2 和节点 4 连接。\n- 节点 4 只与节点 3 连接。\n\n该网络中节点的影响力将通过其特征向量中心性来量化。根据该度量，任何给定节点的中心性与其所连接的所有节点的中心性之和成正比。\n\n令中心性向量表示为 $c = \\begin{pmatrix} c_1  c_2  c_3  c_4 \\end{pmatrix}^T$，其中 $c_i$ 是节点 $i$ 的中心性。求中心性向量 $c$。该向量应被归一化，使其最大分量等于 1。将向量的分量表示为精确的解析表达式。",
            "solution": "设 $A$ 是具有节点 $1$–$4$ 的路径图的邻接矩阵：\n$$\nA=\\begin{pmatrix}\n0  1  0  0\\\\\n1  0  1  0\\\\\n0  1  0  1\\\\\n0  0  1  0\n\\end{pmatrix}.\n$$\n特征向量中心性 $c=\\begin{pmatrix}c_{1}  c_{2}  c_{3}  c_{4}\\end{pmatrix}^{T}$ 满足 $A c=\\lambda c$，其中 $\\lambda$ 是最大特征值，即：\n$$\n\\begin{aligned}\n\\lambda c_{1}=c_{2},\\\\\n\\lambda c_{2}=c_{1}+c_{3},\\\\\n\\lambda c_{3}=c_{2}+c_{4},\\\\\n\\lambda c_{4}=c_{3}.\n\\end{aligned}\n$$\n根据路径的对称性，主特征向量满足 $c_{1}=c_{4}$ 和 $c_{2}=c_{3}$。设 $x=c_{1}=c_{4}$ 且 $y=c_{2}=c_{3}$。方程组简化为\n$$\n\\lambda x=y,\\qquad \\lambda y=x+y.\n$$\n在第二个方程中使用 $x=\\frac{y}{\\lambda}$ 消去 $x$ 得到\n$$\n\\lambda y=\\frac{y}{\\lambda}+y \\;\\;\\Rightarrow\\;\\; \\lambda^{2}=1+\\lambda \\;\\;\\Rightarrow\\;\\; \\lambda^{2}-\\lambda-1=0.\n$$\n因此主特征值为 $\\lambda=\\frac{1+\\sqrt{5}}{2}$。由 $\\lambda x=y$ 我们得到 $x=\\frac{y}{\\lambda}$。因为最大分量是 $y$（因为 $\\lambda1$ 意味着 $y=\\lambda xx$），我们通过设置 $y=1$ 来进行归一化。则\n$$\nx=\\frac{1}{\\lambda}=\\lambda-1=\\frac{\\sqrt{5}-1}{2},\n$$\n这里我们使用 $\\lambda^{2}-\\lambda-1=0$ 来得到 $\\frac{1}{\\lambda}=\\lambda-1$。\n\n因此，归一化后的中心性向量为\n$$\nc=\\begin{pmatrix}\\frac{\\sqrt{5}-1}{2}  1  1  \\frac{\\sqrt{5}-1}{2}\\end{pmatrix}^{T}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\sqrt{5}-1}{2} \\\\ 1 \\\\ 1 \\\\ \\frac{\\sqrt{5}-1}{2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "一个节点的连接数（即度）越多，它就越重要吗？这个练习旨在挑战这种直观但往往不准确的假设。特征向量中心性的精髓在于，一个节点的重要性不仅取决于其连接的数量，更取决于其邻居节点的重要性。通过这个思想实验，你需要在几个选项中识别出一种网络结构，其中度最高的节点并不拥有最高的特征向量中心性，从而深刻理解这两种中心性度量之间的关键差异。",
            "id": "1501057",
            "problem": "在一个由图 $G=(V, E)$ 表示的网络中，一个顶点的重要性可以用多种方式来衡量。一个简单的度量是顶点的**度**，即与其相连的边的数量。一个更微妙的度量是**特征向量中心性**。\n\n对于一个连通的无向图，每个顶点 $v_i \\in V$ 的特征向量中心性 $c_i$ 由该图的邻接矩阵的主特征向量的分量给出。该向量在相差一个缩放因子的情况下是唯一的，并且其所有分量均为正。特征向量中心性的定义性质是，任何顶点的中心性都与其邻居的中心性之和成正比。也就是说，对于某个常数 $\\lambda  0$：\n$$ \\lambda c_i = \\sum_{j \\text{ 是 } i \\text{ 的邻居}} c_j $$\n\n这个性质意味着，如果一个顶点与其他有影响力的顶点相连，那么它本身也是有影响力的。虽然度和特征向量中心性通常是相关的，但它们并不总是等价的。\n\n考虑一个顶点集为 $V = \\{v_1, v_2, v_3, v_4, v_5\\}$ 的图。下列哪个由其边集 $E$ 定义的图，至少存在一个顶点，其度在图中是最大的，但其特征向量中心性不是最大的？\n\nA. $E = \\{(v_1, v_3), (v_1, v_4), (v_1, v_5), (v_2, v_3), (v_2, v_4)\\}$\n\nB. $E = \\{(v_1, v_2), (v_1, v_3), (v_1, v_4), (v_1, v_5)\\}$\n\nC. $E = \\{(v_1, v_2), (v_2, v_3), (v_3, v_4), (v_4, v_5)\\}$\n\nD. $E = \\{(v_1, v_2), (v_2, v_3), (v_3, v_1), (v_3, v_4), (v_4, v_5)\\}",
            "solution": "我们分析每个选项，看是否存在一个顶点，其度在图中是最大的，但其特征向量中心性不是最大的。对于一个邻接矩阵为 $A$ 的连通无向图，特征向量中心性向量 $c$ 满足 $A c = \\lambda c$，其中 $\\lambda  0$ 是主特征值，并且 $c$ 的所有分量都是正的。\n\n选项B：$E = \\{(v_{1},v_{2}),(v_{1},v_{3}),(v_{1},v_{4}),(v_{1},v_{5})\\}$。这是一个以 $v_1$ 为中心的5个顶点的星形图。根据对称性，令 $c_{1}=x$ 且 $c_{2}=c_{3}=c_{4}=c_{5}=y$。特征向量方程为\n$$\n\\lambda x = 4y,\\quad \\lambda y = x.\n$$\n消去 $x$ 得到 $\\lambda^{2} y = 4y$，因此 $\\lambda^{2}=4$，从而 $x=\\lambda y=2yy$。因此，$v_1$ 同时具有最大的度和最大的特征向量中心性。此选项不满足条件。\n\n选项C：$E = \\{(v_{1},v_{2}),(v_{2},v_{3}),(v_{3},v_{4}),(v_{4},v_{5})\\}$。这是路径图 $P_{5}$。根据对称性，令 $c_{1}=c_{5}=a$，$c_{2}=c_{4}=b$，以及 $c_{3}=c$。特征向量方程为\n$$\n\\lambda a = b,\\quad \\lambda b = a + c,\\quad \\lambda c = 2b.\n$$\n由第一个方程可得 $a=b/\\lambda$。代入第二个方程并乘以 $\\lambda$ 得到 $\\lambda^{2} b = b + \\lambda c$。使用第三个方程 $\\lambda c = 2b$，可得 $\\lambda^{2} b = b + 2b = 3b$，因此 $\\lambda^{2}=3$。于是 $c = \\frac{2b}{\\lambda}$ 且 $a=\\frac{b}{\\lambda}$，其中 $\\lambda=\\sqrt{3}$。因为 $1  \\lambda  2$，所以 $c  b  a$。在 $P_5$ 中，最大度为 $2$，由 $v_2, v_3, v_4$ 达到，但只有 $v_3$ 具有最大的特征向量中心性；$v_2$ 和 $v_4$ 的度是最大的，但其特征向量中心性不是最大的。此选项满足条件。\n\n选项A：$E = \\{(v_{1},v_{3}),(v_{1},v_{4}),(v_{1},v_{5}),(v_{2},v_{3}),(v_{2},v_{4})\\}$。这是一个在 $\\{v_{1},v_{3},v_{2},v_{4}\\}$ 上的4-圈，并带有一个连接到 $v_1$ 的叶节点 $v_5$。根据对称性，令 $c_{3}=c_{4}=a$，$c_{5}=b$，$c_{1}=x$，$c_{2}=y$。特征向量方程为\n$$\n\\lambda x = 2a + b,\\quad \\lambda y = 2a,\\quad \\lambda a = x + y,\\quad \\lambda b = x.\n$$\n由最后一个方程可得 $b = \\frac{x}{\\lambda}$。第二个方程给出 $y = \\frac{2a}{\\lambda}$。第三个方程给出 $x = a\\left(\\lambda - \\frac{2}{\\lambda}\\right)$。代入第一个方程得到\n$$\n\\lambda x - \\frac{x}{\\lambda} = 2a \\quad \\Longrightarrow \\quad x = \\frac{2a}{\\lambda - \\frac{1}{\\lambda}}.\n$$\n令两个关于 $x$ 的表达式相等并化简可得\n$$\n\\lambda^{4} - 5\\lambda^{2} + 2 = 0.\n$$\n令 $t=\\lambda^{2}$；则 $t^{2} - 5t + 2 = 0$，所以 $t = \\frac{5 \\pm \\sqrt{17}}{2}$。主特征值满足 $\\lambda^{2} = \\frac{5 + \\sqrt{17}}{2}$，因此 $\\lambda^{2}  4$ 因为\n$$\n\\lambda^{2} - 4 = \\frac{5 + \\sqrt{17} - 8}{2} = \\frac{\\sqrt{17} - 3}{2}  0.\n$$\n现在比较中心性。使用 $x = a\\left(\\lambda - \\frac{2}{\\lambda}\\right)$ 和 $y = \\frac{2a}{\\lambda}$，\n$$\n\\frac{y}{x} = \\frac{\\frac{2}{\\lambda}}{\\lambda - \\frac{2}{\\lambda}} = \\frac{2}{\\lambda^{2} - 2}  1 \\quad \\text{因为} \\quad \\lambda^{2}  4.\n$$\n类似地，\n$$\n\\frac{a}{x} = \\frac{1}{\\lambda - \\frac{2}{\\lambda}} = \\frac{\\lambda}{\\lambda^{2} - 2}  1 \\quad \\text{因为} \\quad \\lambda  2.\n$$\n另外 $b = \\frac{x}{\\lambda}  x$。因此 $x$ 是最大的分量，所以 $v_1$（唯一的最大度顶点）具有最大的特征向量中心性。此选项不满足条件。\n\n选项D：$E = \\{(v_{1},v_{2}),(v_{2},v_{3}),(v_{3},v_{1}),(v_{3},v_{4}),(v_{4},v_{5})\\}$。这是一个在 $\\{v_{1},v_{2},v_{3}\\}$ 上的三角形，并带有一条长度为 2 的路径连接在 $v_3$ 上。根据对称性，令 $c_{1}=c_{2}=x$，$c_{3}=y$，$c_{4}=z$，$c_{5}=w$。特征向量方程为\n$$\n\\lambda x = x + y,\\quad \\lambda y = x + x + z = 2x + z,\\quad \\lambda z = y + w,\\quad \\lambda w = z.\n$$\n由最后一个方程可得 $w = \\frac{z}{\\lambda}$，并且从 $\\lambda x = x + y$ 我们有 $y = (\\lambda - 1) x$。代入 $\\lambda z = y + w$ 得到 $z = \\frac{y}{\\lambda - \\frac{1}{\\lambda}}$。该图严格包含 $K_3$ 作为一个真子图，根据 Perron–Frobenius 单调性，其谱半径 $\\lambda$ 严格大于 $K_3$ 的谱半径 2。因此 $\\lambda  2$，所以 $y = (\\lambda - 1) x  x$。此外，$z = \\frac{y}{\\lambda - \\frac{1}{\\lambda}}  y$ 且 $w = \\frac{z}{\\lambda}  z$。因此，$v_3$ 是唯一具有最大特征向量中心性的顶点，并且也是唯一具有最大度的顶点。此选项不满足条件。\n\n因此，在这些选项中，唯一存在至少一个顶点其度最大但特征向量中心性不最大的图是选项 C。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "在处理真实世界的复杂网络（如社交网络或万维网）时，我们面临着数百万甚至数十亿个节点，直接的分析计算变得不切实际。因此，我们必须转向可扩展的算法。这个高级练习将我们带入分布式计算领域，探索如何在每个节点只拥有局部信息（即只知道其邻居）的情况下，通过本地消息传递来迭代计算整个网络的特征向量中心性。这不仅是一个计算问题，也触及了复杂系统中从局部规则涌现出全局序的核心思想。",
            "id": "4273758",
            "problem": "考虑一个加权无向连通网络 $G = (V, E)$，它有 $|V| = n$ 个节点和一个对称的非负邻接矩阵 $W = [w_{ij}]$，其中 $w_{ij}  0$ 当且仅当 $\\{i,j\\} \\in E$。每个节点 $i$ 知道其关联权重 $\\{w_{ij}\\}_{j \\in \\mathcal{N}(i)}$，并可以在离散时间步 $t = 0, 1, 2, \\dots$ 与邻居 $j \\in \\mathcal{N}(i)$ 交换消息。目标是计算网络的特征向量中心性，即唯一的正中心性向量，其中节点 $i$ 上的项由其邻居的中心性和关联权重确定。设计一个分布式算法，仅使用局部消息传递和重复的邻居加权平均来近似中心性向量，包括一个用于避免平凡发散或坍缩的归一化步骤，以及一个停止准则。在温和的谱隙条件下，并使用严格为正的初始化，正确的算法应收敛到所需的中心性方向。\n\n选择所有正确概述了满足上述约束的此类算法的选项。在每个选项中，“平均一致性 (AC)”子程序指的是一个标准的线性迭代协议，其中节点与邻居重复平均其本地状态，以仅使用局部消息传递来计算初始标量的全局平均值；假设每个节点都知道 $n$ 以便从平均值恢复全局总和。设 $\\varepsilon  0$ 为一个预设的容差。\n\nA. 同步邻居加权和与分布式全局 $2$-范数归一化：\n- 对于所有 $i \\in V$，初始化 $x_i^{(0)}  0$，并设 $t = 0$。\n- 在时间 $t$，每个节点 $i$ 从 $j \\in \\mathcal{N}(i)$ 接收 $x_j^{(t)}$ 并计算邻居加权和 $s_i^{(t)} = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} x_j^{(t)}$。\n- 每个节点以初始标量 $(s_i^{(t)})^2$ 运行平均一致性 (AC) 子程序，以获得平均值 $\\bar{q}^{(t)} = \\frac{1}{n} \\sum_{k=1}^n (s_k^{(t)})^2$。恢复全局总和 $q^{(t)} = n \\bar{q}^{(t)}$，并设置归一化因子 $m^{(t)} = \\sqrt{q^{(t)}}$。\n- 对于所有 $i \\in V$，更新 $x_i^{(t+1)} = \\dfrac{s_i^{(t)}}{m^{(t)}}$。\n- 如果 $\\|x^{(t+1)} - x^{(t)}\\|_2 \\le \\varepsilon$，则停止；否则设置 $t \\leftarrow t + 1$ 并重复。\n\nB. 度归一化的邻居平均，无全局归一化：\n- 初始化 $x_i^{(0)}  0$ 并设 $t = 0$。\n- 在时间 $t$，每个节点 $i$ 更新 $x_i^{(t+1)} = \\dfrac{1}{d_i} \\sum_{j \\in \\mathcal{N}(i)} w_{ij} x_j^{(t)}$，其中 $d_i = \\sum_{j \\in \\mathcal{N}(i)} w_{ij}$。\n- 重复直到 $\\max_{i} |x_i^{(t+1)} - x_i^{(t)}| \\le \\varepsilon$。\n\nC. 带阻尼的邻居加权平均与分布式全局 $2$-范数归一化：\n- 固定一个阻尼参数 $\\alpha \\in (0,1)$，对所有 $i$ 初始化 $x_i^{(0)}  0$，并设 $t = 0$。\n- 在时间 $t$，每个节点 $i$ 计算 $s_i^{(t)} = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} x_j^{(t)}$。\n- 形成带阻尼的更新 $y_i^{(t)} = \\alpha s_i^{(t)} + (1 - \\alpha) x_i^{(t)}$。\n- 以初始标量 $(y_i^{(t)})^2$ 运行平均一致性 (AC) 子程序，以获得 $\\bar{r}^{(t)} = \\frac{1}{n} \\sum_{k=1}^n (y_k^{(t)})^2$，恢复 $r^{(t)} = n \\bar{r}^{(t)}$，并设置 $m^{(t)} = \\sqrt{r^{(t)}}$。\n- 对所有 $i \\in V$ 进行归一化 $x_i^{(t+1)} = \\dfrac{y_i^{(t)}}{m^{(t)}}$。\n- 如果 $\\|x^{(t+1)} - x^{(t)}\\|_2 \\le \\varepsilon$，则停止；否则设置 $t \\leftarrow t + 1$ 并重复。\n\nD. 通过邻居最大值进行局部比例归一化：\n- 初始化 $x_i^{(0)}  0$ 并设 $t = 0$。\n- 在时间 $t$，每个节点 $i$ 计算 $s_i^{(t)} = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} x_j^{(t)}$，然后更新 $x_i^{(t+1)} = \\dfrac{s_i^{(t)}}{\\max\\{s_j^{(t)} : j \\in \\mathcal{N}(i)\\}}$。\n- 重复直到 $\\|x^{(t+1)} - x^{(t)}\\|_2 \\le \\varepsilon$。\n\n假设网络在迭代期间保持静态，每次迭代内的所有消息交换都是可靠和同步的，并且在每个外部迭代中，平均一致性 (AC) 都以足够的精度运行，以使导出的归一化是良定义且在所有节点上一致。选择定义了一个算法的选项，该算法在温和的谱隙条件和严格正的初始化下，仅使用局部消息传递和带有适当归一化的邻居加权平均，收敛到正确的特征向量中心性方向。",
            "solution": "我们从加权、无向、连通、具有非负权重的网络中特征向量中心性的核心定义开始。设 $W \\in \\mathbb{R}^{n \\times n}$ 是对称且逐项非负的。根据佩龙-弗罗贝尼乌斯定理 (Perron–Frobenius theorem)，$W$ 有一个最大特征值 $\\lambda_{1} = \\rho(W)$（谱半径）和一个关联的特征向量 $v_{1} \\in \\mathbb{R}^{n}$，该特征向量可以选择为严格正的。特征向量中心性方向是由 $v_{1}$ 张成的射线，任何对 $v_{1}$ 的正向缩放都代表相同的中心性排名。因此，问题简化为以分布式方式恢复 $v_{1}$ 的方向。\n\n获得 $v_{1}$ 的一个标准原理是幂迭代法：对于一个在 $v_{1}$ 方向上具有非零分量的通用初始向量 $x^{(0)}$，如果 $\\lambda_{1}  |\\lambda_{2}|$（单一主特征值和谱隙），序列\n$$\ny^{(t)} = W x^{(t)}, \\quad x^{(t+1)} = \\frac{y^{(t)}}{\\|y^{(t)}\\|_2}\n$$\n收敛到 $v_{1}/\\|v_{1}\\|_2$。关键的结构特性是与 $W$ 的乘法是可局部化的：第 $i$ 个分量满足\n$$\ny_i^{(t)} = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} x_j^{(t)},\n$$\n因此每个节点 $i$ 只需使用邻居的消息即可计算 $y_i^{(t)}$。归一化因子 $\\|y^{(t)}\\|_2$ 是一个全局量，但它可以通过在标量 $(y_i^{(t)})^2$ 上运行一致性协议，通过局部消息传递来近似，然后将所得平均值乘以 $n$ 来恢复总和 $\\sum_{k=1}^n (y_k^{(t)})^2$（这假设每个节点都知道 $n$）。因此，分布式幂迭代包括用于实现 $W$ 乘法的邻居加权平均，以及随后的分布式归一化，以保持方向并防止发散。在指定的条件下和严格正的初始化下，迭代值保持为正并收敛到特征向量中心性方向。\n\n我们现在分析每个选项。\n\n选项 A (同步邻居加权和与分布式全局 $2$-范数归一化):\n- 更新 $s_i^{(t)} = \\sum_{j} w_{ij} x_j^{(t)}$ 实现了矩阵-向量乘法 $W x^{(t)}$ 的局部分量。\n- 在 $(s_i^{(t)})^2$ 上运行的平均一致性 (AC) 子程序计算了平均值 $\\bar{q}^{(t)} = \\frac{1}{n} \\sum_{k} (s_k^{(t)})^2$。乘以 $n$ 得到 $q^{(t)} = \\sum_{k=1}^n (s_k^{(t)})^2 = \\|s^{(t)}\\|_2^2$。取平方根得到 $m^{(t)} = \\|s^{(t)}\\|_2$。\n- 归一化 $x^{(t+1)} = s^{(t)} / m^{(t)}$ 与归一化幂迭代法相匹配。在佩龙-弗罗贝尼乌斯条件下（$W$ 对称非负，连通网络意味着不可约性），以及一个单一最大特征值 $\\lambda_{1}$ 的情况下，我们有对于任何严格正的 $x^{(0)}$，归一化的迭代值收敛到 $v_{1}/\\|v_{1}\\|_2$。\n- 停止准则 $\\|x^{(t+1)} - x^{(t)}\\|_2 \\le \\varepsilon$ 是标准的。\n结论：正确。这是幂迭代法的一个忠实的分布式实现，使用了邻居加权平均和基于一致性的全局归一化。\n\n选项 B (度归一化的邻居平均，无全局归一化):\n- 更新 $x^{(t+1)} = D^{-1} W x^{(t)}$（其中 $D = \\mathrm{diag}(d_1, \\dots, d_n)$ 且 $d_i = \\sum_{j} w_{ij}$）定义了与行随机矩阵 $P = D^{-1} W$ 的乘法。对于对称的 $W$，$P$ 通常不是对称的，但其最大特征值为 1，对应的特征向量 $u$ 对应于由 $P$ 定义的随机游走的平稳分布（对于无向图，平稳分布与度成正比：$u_i \\propto d_i$）。\n- 如果没有归一化，重复乘以 $P$ 会（在标准的马尔可夫链条件下）收敛到单纯形上的平稳分布（如果初始向量被适当归一化），否则可能会根据缩放情况坍缩到零或在范数上发散。即使进行了归一化，其极限也不是 $W$ 的特征向量中心性，而是 $P$ 的平稳分布。\n- 因此，该过程通常不收敛到 $W$ 的特征向量中心性方向。\n结论：不正确。它计算的是随机游走的平稳测度（或基于度的测度），而不是特征向量中心性。\n\n选项 C (带阻尼的邻居加权平均与分布式全局 $2$-范数归一化):\n- 更新定义了 $y^{(t)} = [(1 - \\alpha) I + \\alpha W] x^{(t)}$。矩阵 $M(\\alpha) = (1 - \\alpha) I + \\alpha W$ 是 $I$ 和 $W$ 的凸组合，因此与 $W$ 具有相同的特征向量，其特征值为 $\\mu_i(\\alpha) = (1 - \\alpha) + \\alpha \\lambda_i$。特别地，主特征向量是 $v_{1}$，与最大特征值 $\\mu_{1}(\\alpha) = (1 - \\alpha) + \\alpha \\lambda_{1}$ 相关联（如果 $\\lambda_{1}$ 是单一且占优的，并且 $\\alpha \\in (0,1)$，则该特征值的幅度仍严格大于其他特征值）。\n- 通过 AC（如选项 A 中）用其全局 $2$-范数对 $y^{(t)}$ 进行归一化，产生了一个针对 $M(\\alpha)$ 的归一化幂迭代，它收敛到 $v_{1}/\\|v_{1}\\|_2$。由于 $v_{1}$ 对于 $W$ 和 $M(\\alpha)$ 是相同的，所以恢复的方向是 $W$ 的特征向量中心性方向。\n- 阻尼可以提高对噪声或数值问题的鲁棒性，同时保持极限方向不变。\n结论：正确。它保留了特征向量方向，并在相同的温和条件下，通过邻居加权平均加上分布式归一化收敛。\n\n选项 D (通过邻居最大值进行局部比例归一化):\n- 所提出的归一化 $x_i^{(t+1)} = s_i^{(t)} / \\max\\{s_j^{(t)} : j \\in \\mathcal{N}(i)\\}$ 使用了一种局部的、邻域范围内的缩放，这种缩放在节点间不一致。这通过引入依赖于局部最大值的异构缩放，破坏了迭代的全局方向，而这些局部最大值不一定与全局范数或任何保持特征向量方向的量成比例。\n- 因此，即使 $s^{(t)}$ 与 $v_{1}$ 对齐，异构的局部归一化也会扭曲分量之间的相对比率，并阻止其收敛到真正的特征向量中心性方向。在这种归一化下，无法保证收敛到所需的中心性向量。\n结论：不正确。局部最大值归一化不是一个一致的全局归一化，也没有实现一个有效的、朝向特征向量中心性的类幂迭代。\n\n结论：选项 A 和 C 正确地概述了分布式算法，这些算法通过一致性协议实现了带有适当全局归一化的重复邻居加权平均，并且（在通常的佩龙-弗罗贝尼乌斯和谱隙条件下，使用严格正的初始化）收敛到特征向量中心性方向。选项 B 和 D 通常不收敛到特征向量中心性。",
            "answer": "$$\\boxed{\\text{AC}}$$"
        }
    ]
}