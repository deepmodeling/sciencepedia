{
    "hands_on_practices": [
        {
            "introduction": "To truly understand random walks, we must begin with the fundamentals of their construction. This first exercise guides you through the process of translating a simple graph structure into a formal Markov chain model. You will build the core components of a random walk—the adjacency matrix $A$, degree matrix $D$, and transition matrix $P$—from scratch for a small but illustrative network. By working through the calculations for a simple path graph, you will gain a concrete understanding of how the stationary distribution reflects the network's topology and why a random walker naturally spends more time in more connected regions .",
            "id": "4299832",
            "problem": "Consider the undirected simple path graph with nodes $1$, $2$, $3$ connected as $1-2-3$. A simple random walk on this graph is a time-homogeneous discrete-time Markov chain (MC) whose states are the nodes, and at each time step the walker at node $i$ moves uniformly at random to one of its neighbors.\n\nUsing only fundamental definitions, do the following:\n\n- Define the adjacency matrix $A$ and the degree matrix $D$ for this graph.\n- Starting from the definition that the transition probability from node $i$ to node $j$ equals $1/k_{i}$ if $j$ is a neighbor of $i$ and equals $0$ otherwise (where $k_{i}$ is the degree of node $i$), derive a compact matrix expression for the transition matrix $P$ in terms of $A$ and $D$, and compute $P$ explicitly for this graph.\n- Verify that $P \\mathbf{1} = \\mathbf{1}$ where $\\mathbf{1}$ is the all-ones vector, thereby showing that each row of $P$ sums to $1$.\n- Using the concept of reversibility and detailed balance for random walks on undirected graphs, derive a stationary distribution $\\pi$ and interpret the difference between the endpoints and the middle node in terms of the transition probabilities and degree heterogeneity.\n- Finally, compute the exact two-step return probability to node $2$, that is, the $(2,2)$ entry of $P^{2}$, and report that single number as your final answer.\n\nAll numerical values must be provided in exact form. The final answer should be the exact value of the two-step return probability to node $2$.",
            "solution": "The problem is well-posed and grounded in the fundamental principles of Markov chains and random walks on graphs. We proceed by following the specified steps.\n\nThe graph is an undirected simple path with nodes labeled $1$, $2$, and $3$, connected as $1-2-3$. The set of nodes is $V = \\{1, 2, 3\\}$ and the set of edges is $E = \\{\\{1, 2\\}, \\{2, 3\\}\\}$.\n\n**Adjacency Matrix $A$ and Degree Matrix $D$**\nThe adjacency matrix $A$ for an undirected graph is a symmetric matrix where the entry $A_{ij}$ is $1$ if there is an edge connecting node $i$ and node $j$, and $0$ otherwise. For a simple graph, the diagonal entries $A_{ii}$ are all $0$.\nFor the given graph, the connections are between node $1$ and $2$, and between node $2$ and $3$. Thus, the adjacency matrix is:\n$$\nA = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe degree of a node $i$, denoted $k_i$, is the number of edges connected to it. It can be calculated from the adjacency matrix as $k_i = \\sum_{j} A_{ij}$.\nThe degrees of the nodes are:\n$k_1 = A_{11} + A_{12} + A_{13} = 0 + 1 + 0 = 1$\n$k_2 = A_{21} + A_{22} + A_{23} = 1 + 0 + 1 = 2$\n$k_3 = A_{31} + A_{32} + A_{33} = 0 + 1 + 0 = 1$\nThe degree matrix $D$ is a diagonal matrix with the degrees of the nodes on its diagonal, i.e., $D_{ii} = k_i$.\n$$\nD = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n\n**Transition Matrix $P$**\nThe transition probability $P_{ij}$ from node $i$ to node $j$ is given as $1/k_i$ if $j$ is a neighbor of $i$, and $0$ otherwise. This can be written in terms of the adjacency matrix as $P_{ij} = A_{ij}/k_i$.\nTo express this in matrix form, we observe that the $i$-th row of the transition matrix $P$ is obtained by dividing the $i$-th row of the adjacency matrix $A$ by the degree $k_i$. This operation corresponds to left-multiplication of $A$ by the inverse of the degree matrix, $D^{-1}$. The inverse $D^{-1}$ is a diagonal matrix with entries $(D^{-1})_{ii} = 1/k_i$.\nThe matrix expression is therefore $P = D^{-1}A$.\nLet's compute $D^{-1}$:\n$$\nD^{-1} = \\begin{pmatrix} 1/1 & 0 & 0 \\\\ 0 & 1/2 & 0 \\\\ 0 & 0 & 1/1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\nNow we compute $P$:\n$$\nP = D^{-1}A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\n\n**Verification that Row Sums are $1$**\nTo show that each row of $P$ sums to $1$, we verify that $P \\mathbf{1} = \\mathbf{1}$, where $\\mathbf{1}$ is the column vector of all ones.\n$$\nP \\mathbf{1} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0\\cdot1 + 1\\cdot1 + 0\\cdot1 \\\\ (1/2)\\cdot1 + 0\\cdot1 + (1/2)\\cdot1 \\\\ 0\\cdot1 + 1\\cdot1 + 0\\cdot1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\mathbf{1}\n$$\nThis confirms that $P$ is a valid stochastic matrix.\n\n**Stationary Distribution $\\pi$**\nFor a random walk on an undirected graph, the process is reversible. The stationary distribution $\\pi$ must satisfy the detailed balance condition: $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs of states $i, j$.\nSubstituting $P_{ij} = A_{ij}/k_i$ and $P_{ji} = A_{ji}/k_j$:\n$$\n\\pi_i \\frac{A_{ij}}{k_i} = \\pi_j \\frac{A_{ji}}{k_j}\n$$\nSince the graph is undirected, $A$ is symmetric, so $A_{ij} = A_{ji}$. If there is an edge between $i$ and $j$ ($A_{ij}=1$), the condition simplifies to $\\pi_i/k_i = \\pi_j/k_j$. Since the graph is connected, this implies that the ratio $\\pi_i/k_i$ is a constant, say $C$, for all nodes $i$. Thus, $\\pi_i = C k_i$. The stationary probability is proportional to the degree of the node.\nTo find the constant $C$, we use the normalization condition $\\sum_i \\pi_i = 1$:\n$$\n\\sum_{i=1}^{3} C k_i = C (k_1 + k_2 + k_3) = 1\n$$\nUsing the degrees we calculated, $k_1=1$, $k_2=2$, $k_3=1$:\n$$\nC(1 + 2 + 1) = C \\cdot 4 = 1 \\implies C = \\frac{1}{4}\n$$\nThe components of the stationary distribution are $\\pi_i = k_i / \\sum_j k_j$.\n$$\n\\pi_1 = \\frac{k_1}{4} = \\frac{1}{4}\n$$\n$$\n\\pi_2 = \\frac{k_2}{4} = \\frac{2}{4} = \\frac{1}{2}\n$$\n$$\n\\pi_3 = \\frac{k_3}{4} = \\frac{1}{4}\n$$\nThe stationary distribution is $\\pi = \\begin{pmatrix} 1/4 & 1/2 & 1/4 \\end{pmatrix}$.\n**Interpretation:** The stationary probability $\\pi_i$ represents the long-term fraction of time the walker spends at node $i$. The result shows the walker spends half its time at the central node $2$ and a quarter of its time at each endpoint ($1$ and $3$). This is a direct consequence of the degree heterogeneity: node $2$ has a degree of $2$, while nodes $1$ and $3$ have degrees of $1$. From the low-degree endpoints, a walker is forced to move to the high-degree center, whereas from the center, the walk can diffuse to either end. This structural feature causes the walker to visit the more connected central node more frequently, leading to a higher stationary probability.\n\n**Two-Step Return Probability to Node $2$**\nThe probability of being at node $j$ after $n$ steps, starting from node $i$, is given by the $(i,j)$ entry of the matrix $P^n$. We need to compute the $(2,2)$ entry of $P^2$, which we denote as $(P^2)_{22}$.\nThis can be computed by considering all possible paths of length $2$ from node $2$ back to node $2$. A path of length $2$ involves an intermediate node $j$. The probability is given by $(P^2)_{22} = \\sum_{j=1}^3 P_{2j}P_{j2}$.\nThe possible paths are:\n1.  $2 \\to 1 \\to 2$: The probability is $P_{21} \\cdot P_{12}$. From matrix $P$, $P_{21} = 1/2$ and $P_{12}=1$. The probability is $(1/2) \\cdot 1 = 1/2$.\n2.  $2 \\to 2 \\to 2$: The probability is $P_{22} \\cdot P_{22}$. Since there are no self-loops, $P_{22}=0$. The probability is $0 \\cdot 0 = 0$.\n3.  $2 \\to 3 \\to 2$: The probability is $P_{23} \\cdot P_{32}$. From matrix $P$, $P_{23} = 1/2$ and $P_{32}=1$. The probability is $(1/2) \\cdot 1 = 1/2$.\nThe total two-step return probability is the sum of probabilities of these mutually exclusive paths:\n$$\n(P^2)_{22} = P_{21}P_{12} + P_{22}P_{22} + P_{23}P_{32} = \\left(\\frac{1}{2}\\right)(1) + (0)(0) + \\left(\\frac{1}{2}\\right)(1) = \\frac{1}{2} + \\frac{1}{2} = 1\n$$\nAlternatively, we can compute the matrix $P^2$:\n$$\nP^2 = P \\cdot P = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 \\\\ 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\\\ 1/2 & 0 & 1/2 \\end{pmatrix}\n$$\nThe $(2,2)$ entry of $P^2$ is $1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Many real-world processes modeled by random walks do not run forever; they terminate upon reaching certain states. This practice explores such scenarios using the framework of absorbing Markov chains, where \"trap\" or \"target\" states end the walk. You will use first-step analysis, a powerful and intuitive technique based on the Markov property, to calculate the probability of reaching a desired target before falling into an undesirable trap. This exercise is crucial for building problem-solving skills applicable to risk analysis, game theory, and diffusion processes where predicting the ultimate fate of a process is the primary goal .",
            "id": "4299835",
            "problem": "Consider a discrete-time random walk on a finite directed network with node set $\\{S, A, B, C, T, U, V\\}$. The node $T$ is a designated target, and $U$ and $V$ are traps (absorbing states). The random walk evolves as a time-homogeneous Markov chain, with transitions determined by the following rules from the transient nodes $S$, $A$, $B$, and $C$:\n- From $S$: move to $A$ with probability $1/2$, to $B$ with probability $1/3$, and to $V$ with probability $1/6$.\n- From $A$: move to $T$ with probability $1/3$, to $B$ with probability $1/3$, and to $U$ with probability $1/3$.\n- From $B$: move to $A$ with probability $1/4$, to $C$ with probability $1/2$, and to $U$ with probability $1/4$.\n- From $C$: move to $T$ with probability $1/2$, to $B$ with probability $1/3$, and to $V$ with probability $1/6$.\n\nThe nodes $T$, $U$, and $V$ are absorbing: once entered, the walk remains there forever.\n\nStarting from $S$, compute the probability that the walk reaches $T$ before ever hitting either $U$ or $V$. Derive your result from first principles using first-step analysis based on the Markov property, and explain how the same quantity can be written using the fundamental matrix of an absorbing Markov chain. Express the final probability as a reduced fraction. No rounding is required.",
            "solution": "The problem asks for the probability that a random walk starting at node $S$ reaches the target node $T$ before being absorbed by the trap nodes $U$ or $V$. This can be formulated as a hitting probability problem on an absorbing Markov chain. The set of transient states is $\\mathcal{T} = \\{S, A, B, C\\}$ and the set of absorbing states is $\\mathcal{A} = \\{T, U, V\\}$.\n\nLet $h_i$ be the probability of reaching the target state $T$ before any other absorbing state ($U$ or $V$), given that the walk starts at node $i \\in \\mathcal{T}$. We are asked to find $h_S$.\n\nBy definition, for the absorbing states, the probabilities are:\n- $h_T = 1$, as the walk has successfully reached the target.\n- $h_U = 0$, as the walk has been trapped and failed to reach the target first.\n- $h_V = 0$, for the same reason.\n\nWe will solve this problem using two methods as requested: first-step analysis and the fundamental matrix approach.\n\n### 1. Derivation using First-Step Analysis\n\nThe first-step analysis is based on the Markov property. The probability of reaching the target from a state $i$ is a weighted average of the probabilities of reaching the target from the states accessible in one step from $i$. The weights are the transition probabilities.\nFor any transient state $i \\in \\mathcal{T}$, the probability $h_i$ is given by the equation:\n$$h_i = \\sum_{j \\in \\mathcal{T} \\cup \\mathcal{A}} P_{ij} h_j$$\nwhere $P_{ij}$ is the probability of transitioning from state $i$ to state $j$.\n\nApplying this principle to each transient state, we obtain a system of linear equations for the unknown probabilities $h_S, h_A, h_B, h_C$.\n\n1.  **Starting from S:** The walk can transition to $A$ (with probability $1/2$), $B$ (with probability $1/3$), or $V$ (with probability $1/6$).\n    $$h_S = P_{SA} h_A + P_{SB} h_B + P_{SV} h_V = \\frac{1}{2} h_A + \\frac{1}{3} h_B + \\frac{1}{6} (0)$$\n    $$h_S = \\frac{1}{2} h_A + \\frac{1}{3} h_B \\quad (1)$$\n\n2.  **Starting from A:** The walk can transition to $T$ (with probability $1/3$), $B$ (with probability $1/3$), or $U$ (with probability $1/3$).\n    $$h_A = P_{AT} h_T + P_{AB} h_B + P_{AU} h_U = \\frac{1}{3} (1) + \\frac{1}{3} h_B + \\frac{1}{3} (0)$$\n    $$h_A = \\frac{1}{3} + \\frac{1}{3} h_B \\quad (2)$$\n\n3.  **Starting from B:** The walk can transition to $A$ (with probability $1/4$), $C$ (with probability $1/2$), or $U$ (with probability $1/4$).\n    $$h_B = P_{BA} h_A + P_{BC} h_C + P_{BU} h_U = \\frac{1}{4} h_A + \\frac{1}{2} h_C + \\frac{1}{4} (0)$$\n    $$h_B = \\frac{1}{4} h_A + \\frac{1}{2} h_C \\quad (3)$$\n\n4.  **Starting from C:** The walk can transition to $T$ (with probability $1/2$), $B$ (with probability $1/3$), or $V$ (with probability $1/6$).\n    $$h_C = P_{CT} h_T + P_{CB} h_B + P_{CV} h_V = \\frac{1}{2} (1) + \\frac{1}{3} h_B + \\frac{1}{6} (0)$$\n    $$h_C = \\frac{1}{2} + \\frac{1}{3} h_B \\quad (4)$$\n\nWe now solve this system of four linear equations. It is most efficient to solve for $h_A, h_B, h_C$ first.\nFrom equation (2), we can express $h_B$ in terms of $h_A$:\n$$3h_A = 1 + h_B \\implies h_B = 3h_A - 1$$\nSubstitute this expression for $h_B$ into equation (4) to find $h_C$ in terms of $h_A$:\n$$h_C = \\frac{1}{2} + \\frac{1}{3} (3h_A - 1) = \\frac{1}{2} + h_A - \\frac{1}{3} = h_A + \\frac{1}{6}$$\nNow, substitute the expressions for $h_B$ and $h_C$ into equation (3):\n$$3h_A - 1 = \\frac{1}{4} h_A + \\frac{1}{2} \\left(h_A + \\frac{1}{6}\\right)$$\n$$3h_A - 1 = \\frac{1}{4} h_A + \\frac{1}{2} h_A + \\frac{1}{12}$$\nTo eliminate fractions, multiply the entire equation by $12$:\n$$12(3h_A - 1) = 12\\left(\\frac{1}{4} h_A\\right) + 12\\left(\\frac{1}{2} h_A\\right) + 12\\left(\\frac{1}{12}\\right)$$\n$$36h_A - 12 = 3h_A + 6h_A + 1$$\n$$36h_A - 12 = 9h_A + 1$$\n$$27h_A = 13 \\implies h_A = \\frac{13}{27}$$\nNow we can back-substitute to find $h_B$:\n$$h_B = 3h_A - 1 = 3\\left(\\frac{13}{27}\\right) - 1 = \\frac{13}{9} - 1 = \\frac{4}{9}$$\nFinally, we compute the desired probability, $h_S$, using equation (1):\n$$h_S = \\frac{1}{2} h_A + \\frac{1}{3} h_B = \\frac{1}{2}\\left(\\frac{13}{27}\\right) + \\frac{1}{3}\\left(\\frac{4}{9}\\right)$$\n$$h_S = \\frac{13}{54} + \\frac{4}{27} = \\frac{13}{54} + \\frac{8}{54} = \\frac{21}{54}$$\nReducing the fraction by dividing the numerator and denominator by their greatest common divisor, which is $3$:\n$$h_S = \\frac{21 \\div 3}{54 \\div 3} = \\frac{7}{18}$$\n\n### 2. Explanation using the Fundamental Matrix\n\nThe theory of absorbing Markov chains provides a matrix formulation for this problem. The transition matrix $P$ can be written in canonical form by ordering the states with transient states first, $\\mathcal{T}=\\{S, A, B, C\\}$, followed by absorbing states, $\\mathcal{A}=\\{T, U, V\\}$.\n$$P = \\begin{pmatrix} Q & R \\\\ 0 & I \\end{pmatrix}$$\nHere, $Q$ is the $4 \\times 4$ submatrix of transition probabilities between transient states, $R$ is the $4 \\times 3$ submatrix of probabilities from transient to absorbing states, $0$ is a $3 \\times 4$ zero matrix, and $I$ is the $3 \\times 3$ identity matrix.\n\nBased on the problem statement, these matrices are:\n$$Q = \\begin{pmatrix} P_{SS} & P_{SA} & P_{SB} & P_{SC} \\\\ P_{AS} & P_{AA} & P_{AB} & P_{AC} \\\\ P_{BS} & P_{BA} & P_{BB} & P_{BC} \\\\ P_{CS} & P_{CA} & P_{CB} & P_{CC} \\end{pmatrix} = \\begin{pmatrix} 0 & 1/2 & 1/3 & 0 \\\\ 0 & 0 & 1/3 & 0 \\\\ 0 & 1/4 & 0 & 1/2 \\\\ 0 & 0 & 1/3 & 0 \\end{pmatrix}$$\n$$R = \\begin{pmatrix} P_{ST} & P_{SU} & P_{SV} \\\\ P_{AT} & P_{AU} & P_{AV} \\\\ P_{BT} & P_{BU} & P_{BV} \\\\ P_{CT} & P_{CU} & P_{CV} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 1/6 \\\\ 1/3 & 1/3 & 0 \\\\ 0 & 1/4 & 0 \\\\ 1/2 & 0 & 1/6 \\end{pmatrix}$$\n\nThe fundamental matrix of the absorbing chain is $N = (I - Q)^{-1}$. The entry $N_{ij}$ represents the expected number of times the process is in transient state $j$, given it starts in transient state $i$.\n\nThe probability of being absorbed in a specific absorbing state $k$, starting from a transient state $i$, is given by the $(i,k)$-th entry of the matrix product $B = NR$. Let $\\mathbf{h} = (h_S, h_A, h_B, h_C)^T$ be the column vector of absorption probabilities into the target state $T$ from each of the transient states. This vector corresponds to the first column of the matrix $B$ (since we ordered $T$ as the first absorbing state). It can be computed as:\n$$\\mathbf{h} = N \\mathbf{r}_T$$\nwhere $\\mathbf{r}_T$ is the first column of the matrix $R$:\n$$\\mathbf{r}_T = (P_{ST}, P_{AT}, P_{BT}, P_{CT})^T = (0, 1/3, 0, 1/2)^T$$\nSubstituting $N = (I-Q)^{-1}$, we get:\n$$\\mathbf{h} = (I-Q)^{-1} \\mathbf{r}_T$$\nMultiplying by $(I-Q)$ from the left gives:\n$$(I-Q)\\mathbf{h} = \\mathbf{r}_T$$\nThis matrix equation is:\n$$\\begin{pmatrix} 1 & -1/2 & -1/3 & 0 \\\\ 0 & 1 & -1/3 & 0 \\\\ 0 & -1/4 & 1 & -1/2 \\\\ 0 & 0 & -1/3 & 1 \\end{pmatrix} \\begin{pmatrix} h_S \\\\ h_A \\\\ h_B \\\\ h_C \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1/3 \\\\ 0 \\\\ 1/2 \\end{pmatrix}$$\nExpanding this matrix equation yields the following system:\n- $h_S - \\frac{1}{2}h_A - \\frac{1}{3}h_B = 0 \\implies h_S = \\frac{1}{2}h_A + \\frac{1}{3}h_B$\n- $h_A - \\frac{1}{3}h_B = 1/3 \\implies h_A = \\frac{1}{3} + \\frac{1}{3}h_B$\n- $-\\frac{1}{4}h_A + h_B - \\frac{1}{2}h_C = 0 \\implies h_B = \\frac{1}{4}h_A + \\frac{1}{2}h_C$\n- $-\\frac{1}{3}h_B + h_C = 1/2 \\implies h_C = \\frac{1}{2} + \\frac{1}{3}h_B$\nThis system is identical to the one derived using first-step analysis. Therefore, the fundamental matrix formalism provides an equivalent, more general framework for calculating the absorption probabilities, leading to the same result. The solution for $h_S$ remains $\\frac{7}{18}$.",
            "answer": "$$\\boxed{\\frac{7}{18}}$$"
        },
        {
            "introduction": "While the simple random walk is a foundational model, it is not always the most efficient tool for exploring a network or sampling its nodes. This computational practice introduces degree-biased random walks, where transitions are weighted by the degree of the destination node, allowing us to engineer walks for specific purposes. You will implement different biasing schemes and analyze their profound impact on both the stationary distribution and the mixing time—a key measure of how quickly a walk converges to its long-term state. This exercise bridges theory with computation, providing hands-on experience in simulating and evaluating algorithms, a vital skill set for modern network science research .",
            "id": "4299848",
            "problem": "Consider an undirected, connected, heterogeneous network given by a simple graph with node set $\\{0,1,2,3,4,5,6,7\\}$ and edge set $\\{(0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(3,4),(5,6),(6,7),(2,6)\\}$. Let $A$ be the adjacency matrix with entries $A_{ij} \\in \\{0,1\\}$ indicating whether there is an edge between nodes $i$ and $j$, and let $k_i = \\sum_{j} A_{ij}$ denote the degree of node $i$.\n\nA discrete-time random walk on this network is a time-homogeneous Markov chain (MC) with transition matrix $P$ whose entries satisfy $P_{ij} \\ge 0$ and $\\sum_{j} P_{ij} = 1$ for all $i$. Consider a family of degree-biased random walks parameterized by a bias exponent $\\beta \\in \\mathbb{R}$, where the transition probability from node $i$ to a neighbor node $j$ is biased according to the neighbor’s degree. Specifically, for a given $\\beta$, define the non-lazy transition matrix $P$ by\n$$\nP_{ij} \\propto A_{ij} \\, k_j^{\\beta} \\quad \\text{for } j \\in \\{ \\text{neighbors of } i \\},\n$$\nwith row normalization so that $\\sum_j P_{ij} = 1$. To ensure aperiodicity, define the lazy transition matrix\n$$\nP^{(\\text{lazy})} = s I + (1-s) P,\n$$\nwhere $I$ is the identity matrix and $s \\in (0,1)$ is a laziness parameter.\n\nThe stationary distribution $\\pi$ is a row vector that satisfies $\\pi P = \\pi$ and $\\sum_i \\pi_i = 1$. For an irreducible and aperiodic chain, the stationary distribution exists and is unique. The total variation distance between two distributions $p$ and $q$ over the node set is defined as\n$$\n\\| p - q \\|_{\\text{TV}} = \\frac{1}{2} \\sum_{i=0}^{7} | p_i - q_i |.\n$$\nFor a given $\\epsilon > 0$, the mixing time is defined as\n$$\n\\tau(\\epsilon) = \\min \\left\\{ t \\in \\mathbb{N} \\, \\bigg| \\, \\max_{i \\in \\{0,\\dots,7\\}} \\left\\| e_i^\\top (P^{(\\text{lazy})})^t - \\pi \\right\\|_{\\text{TV}} \\le \\epsilon \\right\\},\n$$\nwhere $e_i$ is the $i$-th standard basis row vector.\n\nYour task is to implement a complete, runnable program that:\n- Constructs the specified network.\n- For each bias exponent $\\beta$, builds the corresponding degree-biased transition matrix $P$ and its lazy version $P^{(\\text{lazy})}$ using a fixed laziness parameter $s$.\n- Computes the stationary distribution $\\pi$ from first principles, consistent with the above definitions.\n- Computes the mixing time $\\tau(\\epsilon)$ by iterating the distribution from each initial node $i$ under $P^{(\\text{lazy})}$ and evaluating the total variation distance to $\\pi$ at each time $t$ until the threshold is met for all $i$.\n- Compares results for different $\\beta$ as specified in the test suite.\n\nUse the following fixed parameters for the test suite:\n- Bias exponents $\\beta \\in \\{-1, 0, 1\\}$.\n- Laziness parameter $s = 0.1$.\n- Total variation threshold $\\epsilon = 10^{-6}$.\n- Maximum iteration limit $T_{\\max} = 10000$ for mixing time evaluation; if the threshold is not met by $T_{\\max}$, report the mixing time as $-1$.\n\nScientific realism and internal consistency requirements:\n- The network is undirected and connected, ensuring irreducibility.\n- The laziness factor $s = 0.1$ enforces aperiodicity without altering the stationary distribution of the non-lazy chain.\n- The program must compute $\\pi$ and $\\tau(\\epsilon)$ directly from the definitions above; it must not use shortcut formulas absent a derivation.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ \\text{result}_1, \\text{result}_2, \\text{result}_3 ]$).\n- Each $\\text{result}_m$ corresponds to one $\\beta$ in the order $\\beta = -1, 0, 1$, and must be a list containing two elements: the mixing time as an integer and the stationary distribution as a list of eight floating-point numbers ordered by node index $0$ to $7$. For example, $[t, [\\pi_0,\\pi_1,\\dots,\\pi_7]]$.\n- Floating-point numbers should be standard decimal floats; you may round them to a reasonable number of decimal places to ensure readability, but rounding is not a required unit constraint.\n\nYour program must be self-contained, take no input, and run in a standard environment. The final output line must strictly follow the single-line format described above.",
            "solution": "The problem statement has been rigorously validated and is determined to be valid. It is scientifically grounded in the theory of Markov chains and random walks on networks, is mathematically well-posed, and provides a complete and consistent set of definitions and parameters. A unique, stable solution exists and can be computed as specified. We may therefore proceed with the derivation and implementation of the solution.\n\nThe core of the problem is to analyze a family of degree-biased random walks on a given network. The solution involves several computational and theoretical steps: representing the network, constructing the transition matrix for each bias, determining the stationary distribution, and calculating the mixing time.\n\nFirst, we represent the specified network. The graph has a set of $N=8$ nodes, which we label from $0$ to $7$. The edge set is given as $E = \\{(0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(3,4),(5,6),(6,7),(2,6)\\}$. Since the graph is undirected, we construct a symmetric adjacency matrix $A$, an $8 \\times 8$ matrix where $A_{ij} = 1$ if an edge exists between nodes $i$ and $j$, and $A_{ij} = 0$ otherwise. From the adjacency matrix, we compute the degree $k_i$ of each node $i$ by summing the entries of the $i$-th row: $k_i = \\sum_{j=0}^{N-1} A_{ij}$. For the given graph, the degrees are: $k_0 = 5$, $k_1 = 2$, $k_2 = 3$, $k_3 = 2$, $k_4 = 2$, $k_5 = 2$, $k_6 = 3$, and $k_7 = 1$. The total degree is $\\sum_i k_i = 20$.\n\nNext, we construct the non-lazy transition matrix $P$ for a given bias exponent $\\beta$. The transition probability $P_{ij}$ from node $i$ to an adjacent node $j$ is proportional to $k_j^\\beta$. To ensure the rows of $P$ sum to $1$, we normalize them. The explicit formula for the entries of $P$ is:\n$$\nP_{ij} = \\frac{A_{ij} k_j^\\beta}{Z_i}\n$$\nwhere $Z_i$ is the normalization constant for the $i$-th row, given by $Z_i = \\sum_{l=0}^{N-1} A_{il} k_l^\\beta$. Note that if $A_{ij} = 0$, then $P_{ij} = 0$. Since the graph is connected, all nodes have degree $k_i \\ge 1$, so $k_j^\\beta$ is well-defined and positive for any real $\\beta$ and any neighbor $j$.\n\nThe stationary distribution $\\pi$ is a row vector that is invariant under the operation of the transition matrix, satisfying the defining equation $\\pi P = \\pi$, along with the normalization condition $\\sum_i \\pi_i = 1$. This equation signifies that $\\pi$ is a left eigenvector of $P$ with a corresponding eigenvalue of $1$. For a finite, irreducible Markov chain, this eigenvector is unique. Solving for $\\pi$ is equivalent to finding the right eigenvector of the transpose matrix $P^\\top$ for the eigenvalue $1$. We use a standard numerical linear algebra library (`scipy.linalg.eig`) to find the eigenvalues and eigenvectors of $P^\\top$. We identify the eigenvector corresponding to the eigenvalue closest to $1$, take its real part (as the stationary distribution must be real), and normalize it to sum to $1$. This method directly implements the definition from first principles. For the special case of $\\beta=0$ (the simple random walk), the stationary distribution is known to be $\\pi_i = k_i / \\sum_j k_j$, which serves as a useful check for our general method.\n\nTo ensure the Markov chain is aperiodic, a lazy version of the random walk is defined using the transition matrix $P^{(\\text{lazy})} = s I + (1-s) P$, where $I$ is the identity matrix and $s=0.1$ is the laziness parameter. This modification adds a self-loop probability of at least $s > 0$ to each node, guaranteeing aperiodicity. Importantly, the lazy walk does not alter the stationary distribution, as if $\\pi P = \\pi$, then $\\pi P^{(\\text{lazy})} = \\pi(sI + (1-s)P) = s\\pi + (1-s)\\pi P = s\\pi + (1-s)\\pi = \\pi$.\n\nFinally, we compute the mixing time $\\tau(\\epsilon)$. The mixing time is the number of steps required for the random walk to be arbitrarily close to the stationary distribution, regardless of the starting node. The distance between distributions is measured by the total variation distance, $\\| p - q \\|_{\\text{TV}} = \\frac{1}{2} \\sum_i |p_i - q_i|$. The mixing time $\\tau(\\epsilon)$ is defined as the first time step $t$ at which the maximum total variation distance between the distribution at time $t$ and the stationary distribution $\\pi$ is less than or equal to a threshold $\\epsilon=10^{-6}$, for all possible starting nodes.\n$$\n\\tau(\\epsilon) = \\min \\left\\{ t \\in \\mathbb{N} \\, \\bigg| \\, \\max_{i \\in \\{0,\\dots,7\\}} \\left\\| e_i^\\top (P^{(\\text{lazy})})^t - \\pi \\right\\|_{\\text{TV}} \\le \\epsilon \\right\\}\n$$\nwhere $e_i^\\top$ is the distribution concentrated at node $i$. To compute this, we can track the evolution of all $N$ initial distributions simultaneously. We initialize an $N \\times N$ matrix, `p_t_matrix`, as the identity matrix $I$, where each row represents one of the starting distributions $e_i^\\top$. At each time step $t$, we update this matrix via right multiplication with $P^{(\\text{lazy})}$, i.e., `p_t_matrix` becomes `p_t_matrix` $\\times P^{(\\text{lazy})}$. After each update, we calculate the total variation distance of each row to $\\pi$. The maximum of these distances is compared against $\\epsilon$. The first $t$ for which this maximum distance is $\\le \\epsilon$ is the mixing time. If this condition is not met by the maximum iteration limit $T_{\\max}=10000$, we report the mixing time as $-1$.\n\nThe entire process is repeated for each specified bias exponent $\\beta \\in \\{-1, 0, 1\\}$, and the results, consisting of the computed mixing time and stationary distribution for each case, are formatted into a single output line as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eig\n\ndef solve():\n    \"\"\"\n    Solves the random walk problem by constructing the network, computing\n    transition matrices, stationary distributions, and mixing times for\n    different bias exponents.\n    \"\"\"\n    # Define problem constants as specified in the problem statement.\n    N = 8\n    edges = [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (3, 4), (5, 6), (6, 7), (2, 6)]\n    betas_to_test = [-1, 0, 1]\n    s = 0.1\n    epsilon = 1e-6\n    T_max = 10000\n\n    # Build the adjacency matrix A from the edge list.\n    # The graph is undirected, so the matrix is symmetric.\n    A = np.zeros((N, N), dtype=int)\n    for i, j in edges:\n        A[i, j] = 1\n        A[j, i] = 1\n\n    # Calculate the degree k_i for each node i.\n    k = np.sum(A, axis=1)\n\n    # Store results for each beta value.\n    final_results = []\n\n    for beta in betas_to_test:\n        # Step 1: Construct the degree-biased non-lazy transition matrix P.\n        P = np.zeros((N, N), dtype=float)\n        for i in range(N):\n            # Find neighbors of node i\n            neighbors = np.where(A[i] == 1)[0]\n            if len(neighbors) > 0:\n                # Get degrees of neighbors\n                neighbor_degrees = k[neighbors]\n                # Calculate weights k_j^beta for each neighbor j\n                weights = neighbor_degrees.astype(float) ** beta\n                # Normalization constant Z_i\n                Z_i = np.sum(weights)\n                # Assign transition probabilities\n                if Z_i > 0:\n                    P[i, neighbors] = weights / Z_i\n\n        # Step 2: Compute the stationary distribution pi.\n        # pi is the left eigenvector of P for eigenvalue 1.\n        # This is equivalent to the right eigenvector of P.T for eigenvalue 1.\n        eigenvalues, eigenvectors = eig(P.T)\n        \n        # Find the eigenvector corresponding to the eigenvalue closest to 1.\n        idx = np.argmin(np.abs(eigenvalues - 1.0))\n        pi_unnormalized = np.real(eigenvectors[:, idx])\n        \n        # Normalize the eigenvector so its components sum to 1.\n        pi = pi_unnormalized / np.sum(pi_unnormalized)\n\n        # Step 3: Construct the lazy transition matrix P_lazy.\n        # This ensures aperiodicity and guarantees convergence.\n        P_lazy = s * np.eye(N) + (1 - s) * P\n\n        # Step 4: Compute the mixing time tau(epsilon).\n        mixing_time = -1\n        \n        # p_t_matrix stores the probability distributions at time t,\n        # starting from each of the N nodes. Each row is a distribution.\n        # Initially, it's the identity matrix, where row i is e_i^T.\n        p_t_matrix = np.eye(N)\n        \n        for t in range(1, T_max + 1):\n            # Evolve all distributions by one step.\n            p_t_matrix = p_t_matrix @ P_lazy\n            \n            # Calculate the TV distance for each starting distribution to pi.\n            # The formula is 0.5 * sum(|p_i - q_i|).\n            tv_distances = 0.5 * np.sum(np.abs(p_t_matrix - pi), axis=1)\n            \n            # Find the maximum TV distance among all starting nodes.\n            max_tv_dist = np.max(tv_distances)\n            \n            # Check if the convergence criterion is met.\n            if max_tv_dist = epsilon:\n                mixing_time = t\n                break\n        \n        final_results.append([mixing_time, pi.tolist()])\n\n    # Format the final output string as specified in the problem statement.\n    # e.g., [[t1,[pi_list1]],[t2,[pi_list2]],...]\n    result_strings = []\n    for t, pi_list in final_results:\n        # Round floats for readable, standardized output.\n        pi_str = \"[\" + \",\".join(f\"{x:.8f}\" for x in pi_list) + \"]\"\n        result_strings.append(f\"[{t},{pi_str}]\")\n    \n    final_output_string = \"[\" + \",\".join(result_strings) + \"]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}