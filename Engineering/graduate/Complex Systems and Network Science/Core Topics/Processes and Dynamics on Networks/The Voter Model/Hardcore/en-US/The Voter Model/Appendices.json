{
    "hands_on_practices": [
        {
            "introduction": "To truly understand how opinions spread on a network, we must move beyond simple descriptions and build a rigorous mathematical foundation. This practice challenges you to derive the infinitesimal generator of the voter model, a fundamental tool that describes the instantaneous rates of change for any function of the system's state . By starting from the microscopic update rules, you will see precisely how network topology, specifically the degree of each agent, shapes the dynamics at the macroscopic level.",
            "id": "4129354",
            "problem": "Consider a population of $N$ agents connected by a simple undirected network with adjacency matrix $A \\in \\{0,1\\}^{N \\times N}$, where $A_{ij} = A_{ji}$ and $A_{ii} = 0$. Each agent $i \\in \\{1,\\dots,N\\}$ holds a binary opinion $x_i \\in \\{0,1\\}$, so that the system state is $x = (x_1,\\dots,x_N) \\in \\{0,1\\}^{N}$. Suppose interaction events occur along each ordered pair $(i,j)$ with $A_{ij} = 1$ as independent Poisson processes of unit rate. When an event on $(i,j)$ occurs, agent $i$ instantaneously replaces its opinion with agent $j$’s current opinion. This defines a Continuous Time Markov Chain (CTMC) on the state space $\\{0,1\\}^N$.\n\nStarting from foundational principles for Poisson processes and the definition of the generator of a CTMC, do the following:\n\n1. Argue from the superposition property of independent Poisson processes why the total update rate of agent $i$, denoted $\\lambda_i$, equals the sum of rates of all processes impinging on $i$, and thereby depends on the degree heterogeneity of the network through the adjacency matrix $A$.\n\n2. Derive the infinitesimal generator $L$ of the CTMC acting on bounded functions $f:\\{0,1\\}^{N} \\to \\mathbb{R}$ in closed form in terms of $A$ and the update map $x \\mapsto x^{i \\leftarrow j}$, where $x^{i \\leftarrow j}$ denotes the configuration obtained from $x$ by replacing $x_i$ with $x_j$ while leaving all other components unchanged.\n\nYour final answer must be a single closed-form analytical expression for the generator $L$ acting on a function $f$. Do not provide an inequality or a system of equations. No rounding is required. Express your final answer without units.",
            "solution": "The problem statement is a valid exercise in the theory of Continuous Time Markov Chains (CTMCs) applied to a standard model of opinion dynamics. It is scientifically grounded, well-posed, objective, and contains all necessary information for a rigorous derivation.\n\n### Part 1: Derivation of the Total Update Rate $\\lambda_i$\n\nThe model specifies that for each ordered pair of agents $(i,j)$ such that agent $j$ is a neighbor of agent $i$ (i.e., $A_{ij}=1$), there is an independent Poisson process of unit rate, let's call it $\\mathcal{P}_{ij}$. An event in the process $\\mathcal{P}_{ij}$ corresponds to agent $i$ adopting the opinion of agent $j$.\n\nWe are asked to determine the total update rate $\\lambda_i$ for a specific agent $i$. An \"update of agent $i$\" occurs if agent $i$ is the one whose opinion is replaced. This corresponds to the occurrence of an event from any of the processes $\\mathcal{P}_{ij}$ for a fixed $i$ and any $j$ such that $A_{ij}=1$.\n\nLet the set of neighbors of agent $i$ be $\\mathcal{N}_i = \\{j \\in \\{1,\\dots,N\\} \\mid A_{ij}=1\\}$. The events that cause agent $i$ to update its opinion are the events from the set of Poisson processes $\\{\\mathcal{P}_{ij} \\mid j \\in \\mathcal{N}_i\\}$. Each of these processes has a rate of $1$.\n\nA fundamental property of independent Poisson processes is the superposition principle. It states that if we have a collection of independent Poisson processes with rates $r_1, r_2, \\dots, r_m$, their superposition (i.e., the combined stream of events) is also a Poisson process with a total rate $R = \\sum_{k=1}^m r_k$.\n\nIn our case, for a fixed agent $i$, the total process of updates for this agent is the superposition of the independent Poisson processes $\\mathcal{P}_{ij}$ for all $j \\in \\mathcal{N}_i$. The rate of each of these processes is $r_j = 1$. Therefore, the total update rate for agent $i$, denoted $\\lambda_i$, is the sum of the rates of all these impinging processes:\n$$ \\lambda_i = \\sum_{j \\in \\mathcal{N}_i} 1 $$\nThis sum is over all neighbors of $i$. We can express this using the adjacency matrix $A$. The condition $j \\in \\mathcal{N}_i$ is equivalent to $A_{ij}=1$. The rate for the process $\\mathcal{P}_{ij}$ can be written as $1 \\cdot A_{ij}$ (i.e., $1$ if an edge exists, $0$ otherwise). Summing over all possible agents $j$:\n$$ \\lambda_i = \\sum_{j=1}^{N} A_{ij} $$\nThis sum, $\\sum_{j=1}^{N} A_{ij}$, is by definition the degree of node $i$ in the network, commonly denoted $k_i$. Thus, $\\lambda_i=k_i$.\n\nThe update rate of an agent $i$ is therefore equal to its degree. Degree heterogeneity refers to the variation in degrees across the nodes in the network. If the network is not a regular graph, the degrees $k_i$ will differ among agents. Since $\\lambda_i = k_i$, the update rate $\\lambda_i$ is directly and linearly dependent on the degree of the agent. Agents with higher connectivity (hubs) are selected to update their opinions more frequently, demonstrating a direct dependence of the dynamics on the degree heterogeneity of the network.\n\n### Part 2: Derivation of the Infinitesimal Generator $L$\n\nThe infinitesimal generator $L$ of a CTMC describes the instantaneous rate of change of the expected value of a function of the state. It is defined by its action on any bounded function $f: \\{0,1\\}^N \\to \\mathbb{R}$ as:\n$$ (Lf)(x) = \\lim_{dt \\to 0^+} \\frac{\\mathbb{E}[f(X(dt)) \\mid X(0)=x] - f(x)}{dt} $$\nHere, $X(t)$ is the state of the system at time $t$. In a small time interval $dt$, the probability of a specific Poisson process with rate $r$ having an event is $r \\cdot dt + o(dt)$. The probability of two or more events from any of the independent processes is $o(dt)$ and can be neglected in the limit.\n\nThe state of the system can change from $x$ to a new state $y$ only if an update event occurs. The elementary events are the Poisson processes $\\mathcal{P}_{ij}$ for each ordered pair $(i,j)$ with $A_{ij}=1$. Each has a rate of $1$.\n\nConsider the state of the system to be $x$ at time $t=0$. In the interval $(0, dt]$, an event from process $\\mathcal{P}_{ij}$ occurs with probability $1 \\cdot dt$. If this event happens, the system transitions from state $x$ to the state $x^{i \\leftarrow j}$, which is obtained by setting the opinion of agent $i$ to be the opinion of agent $j$, i.e., $(x^{i \\leftarrow j})_k = x_k$ for $k \\neq i$ and $(x^{i \\leftarrow j})_i = x_j$.\n\nThe total rate of any event occurring is $\\Lambda = \\sum_{i=1}^N \\sum_{j=1}^N A_{ij}$. The probability of no event occurring in $(0, dt]$ is $1 - \\Lambda \\cdot dt + o(dt)$.\n\nNow we can write the expected value of $f(X(dt))$:\n$$ \\mathbb{E}[f(X(dt)) \\mid X(0)=x] = f(x) \\cdot \\mathbb{P}(\\text{no event}) + \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} \\left( f(x^{i \\leftarrow j}) \\cdot \\mathbb{P}(\\text{event on }(i,j)) \\right) + o(dt) $$\nSubstituting the probabilities:\n$$ \\mathbb{E}[f(X(dt)) \\mid X(0)=x] = f(x) \\left(1 - \\sum_{i'=1}^{N} \\sum_{j'=1}^{N} A_{i'j'} dt \\right) + \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} (f(x^{i \\leftarrow j}) \\cdot dt) + o(dt) $$\nNote that we must sum over all possible events to calculate the probability of no event.\n\nNow, we compute the numerator of the generator definition:\n$$ \\mathbb{E}[f(X(dt)) \\mid X(0)=x] - f(x) = -f(x) \\left(\\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij}\\right) dt + \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} f(x^{i \\leftarrow j}) dt + o(dt) $$\n$$ = \\left( \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} f(x^{i \\leftarrow j}) - \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} f(x) \\right) dt + o(dt) $$\n$$ = \\left( \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} [f(x^{i \\leftarrow j}) - f(x)] \\right) dt + o(dt) $$\nDividing by $dt$ and taking the limit $dt \\to 0^+$ yields the action of the generator $L$ on the function $f$ at state $x$:\n$$ (Lf)(x) = \\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} [f(x^{i \\leftarrow j}) - f(x)] $$\nThis expression is the closed form for the generator's action. The sum is taken over all ordered pairs $(i,j)$ for which an edge exists in the network. For each such pair, an event causes a potential transition from state $x$ to $x^{i \\leftarrow j}$, and the corresponding term contributes to the rate of change of the expected value of $f$. If $x_i = x_j$, then $x^{i \\leftarrow j} = x$, and the term $[f(x^{i \\leftarrow j}) - f(x)]$ is zero, correctly reflecting that no change in state occurs. The expression is general and holds for any state $x$ and any test function $f$.",
            "answer": "$$\n\\boxed{\\sum_{i=1}^{N} \\sum_{j=1}^{N} A_{ij} [f(x^{i \\leftarrow j}) - f(x)]}\n$$"
        },
        {
            "introduction": "The classic voter model inevitably leads to consensus, but real-world opinion systems are rarely so placid, often being subject to noise, personal conviction, or external influences. This exercise introduces spontaneous opinion flips, a simple yet powerful mechanism that maintains diversity and creates a dynamic statistical equilibrium . You will employ the powerful Kramers-Moyal expansion to derive a Fokker-Planck equation, a cornerstone of statistical physics, to characterize the steady-state fluctuations of the collective opinion.",
            "id": "4129398",
            "problem": "Consider a well-mixed population of $N$ agents, each carrying a binary opinion $s_i(t) \\in \\{-1,+1\\}$. The population evolves under the following continuous-time dynamics, with independent Poisson clocks at each agent:\n- Imitation at rate $\\lambda$: when an agent’s imitation clock rings, it selects a single peer uniformly at random and copies that peer’s opinion.\n- Spontaneous flip at rate $\\eta$: when an agent’s spontaneous clock rings, it flips its opinion from $+1$ to $-1$ or from $-1$ to $+1$.\n\nLet the magnetization be $m(t) = \\frac{1}{N} \\sum_{i=1}^{N} s_i(t)$ and let $k(t)$ denote the number of agents in state $+1$, so that $m(t) = \\frac{2k(t)}{N} - 1$. Starting from the fundamental definition of the Markovian birth–death process for $k(t)$ and using the mean-field limit with $N$ large (fully connected network), derive the effective drift and diffusion of $m(t)$ via the Kramers–Moyal expansion, obtain the associated Fokker–Planck equation (FPE), and infer the steady-state mean magnetization and its variance to leading order in $1/N$. Your derivation should start from the microscopic transition rates and proceed through the coarse-graining to a mesoscopic description that is valid in the vicinity of $m = 0$.\n\nProvide your final answer as a single row matrix whose first entry is the steady-state mean magnetization $\\langle m \\rangle_{\\mathrm{ss}}$ and whose second entry is the steady-state variance $\\mathrm{Var}_{\\mathrm{ss}}(m)$, both expressed symbolically in terms of $N$, $\\lambda$, and $\\eta$.",
            "solution": "The problem asks for the derivation of the steady-state mean and variance of the magnetization in a population of agents undergoing imitation and spontaneous opinion flips. The derivation will proceed from the microscopic dynamics to a macroscopic Fokker-Planck equation (FPE) via a system-size expansion.\n\nFirst, we validate the problem statement.\nThe problem provides a complete description of a stochastic process for opinion dynamics.\n**Givens:**\n- Population size: $N$ agents.\n- Agent state: $s_i(t) \\in \\{-1,+1\\}$.\n- Imitation rate: $\\lambda$.\n- Spontaneous flip rate: $\\eta$.\n- Magnetization: $m(t) = \\frac{1}{N} \\sum_{i=1}^{N} s_i(t)$.\n- Number of agents in state $+1$: $k(t)$.\n- Relation: $m(t) = \\frac{2k(t)}{N} - 1$.\n- Topology: Well-mixed population (mean-field).\n- Limit: Large $N$.\n\n**Validation:**\nThe problem is scientifically grounded, describing a standard model in statistical physics and complex systems (a variant of the voter model). It is well-posed, with all necessary parameters and dynamics defined, leading to a unique statistical steady state for non-zero rates. The language is objective and formal. The problem is self-contained and does not violate any physical or mathematical principles.\n**Verdict:** The problem is valid. We proceed to the solution.\n\nLet $k$ be the number of agents with opinion $s_i=+1$. The number of agents with opinion $s_i=-1$ is $N-k$. The system state is fully described by the integer $k \\in \\{0, 1, ..., N\\}$. This defines a continuous-time Markovian birth-death process on $k$. We need to find the transition rates $T^+(k) = T(k \\to k+1)$ and $T^-(k) = T(k \\to k-1)$.\n\nA transition $k \\to k+1$ occurs when an agent with opinion $-1$ flips to $+1$. This can happen in two ways:\n1.  **Spontaneous flip**: An agent with opinion $-1$ spontaneously flips to $+1$. There are $N-k$ such agents, and each flips with rate $\\eta$. The total rate is $(N-k)\\eta$.\n2.  **Imitation**: An agent with opinion $-1$ imitates an agent with opinion $+1$. There are $N-k$ agents with opinion $-1$. Each attempts imitation at a rate $\\lambda$. When imitating, an agent chooses a single peer uniformly at random from the other $N-1$ agents. The probability of choosing a peer with opinion $+1$ is $\\frac{k}{N-1}$. Thus, the total rate for this process is $(N-k)\\lambda \\frac{k}{N-1}$.\n\nThe total transition rate for $k \\to k+1$ is:\n$$T^+(k) = (N-k)\\eta + \\lambda \\frac{k(N-k)}{N-1}$$\n\nA transition $k \\to k-1$ occurs when an agent with opinion $+1$ flips to $-1$. Similarly, this can happen in two ways:\n1.  **Spontaneous flip**: An agent with opinion $+1$ spontaneously flips to $-1$. There are $k$ such agents, so the total rate is $k\\eta$.\n2.  **Imitation**: An agent with opinion $+1$ imitates an agent with opinion $-1$. The total rate for this process is $k\\lambda \\frac{N-k}{N-1}$.\n\nThe total transition rate for $k \\to k-1$ is:\n$$T^-(k) = k\\eta + \\lambda \\frac{k(N-k)}{N-1}$$\n\nThe evolution of the probability $P(k,t)$ is governed by the Master equation:\n$$\\frac{d P(k,t)}{dt} = T^+(k-1)P(k-1,t) + T^-(k+1)P(k+1,t) - [T^+(k) + T^-(k)]P(k,t)$$\n\nTo derive the Fokker-Planck equation for the magnetization $m$, we perform a Kramers-Moyal expansion. We relate the discrete variable $k$ to the continuous variable $m$:\n$$m = \\frac{2k}{N} - 1 \\implies k = \\frac{N(m+1)}{2}$$\nA change of $\\Delta k = \\pm 1$ corresponds to a change $\\Delta m = \\pm \\frac{2}{N}$. The FPE for the probability density $P(m,t)$ is given by:\n$$\\frac{\\partial P(m,t)}{\\partial t} = -\\frac{\\partial}{\\partial m}[A(m)P(m,t)] + \\frac{1}{2}\\frac{\\partial^2}{\\partial m^2}[B(m)P(m,t)]$$\nwhere $A(m)$ is the drift coefficient and $B(m)$ is the diffusion coefficient. They are defined as the first and second moments of the jump process:\n$$A(m) = \\lim_{\\Delta t \\to 0} \\frac{\\langle \\Delta m \\rangle}{\\Delta t}, \\quad B(m) = \\lim_{\\Delta t \\to 0} \\frac{\\langle (\\Delta m)^2 \\rangle}{\\Delta t}$$\nThe jump moments are calculated from the transition rates:\n$$\\langle \\Delta m \\rangle = \\left(+\\frac{2}{N}\\right) T^+(k)\\Delta t + \\left(-\\frac{2}{N}\\right) T^-(k)\\Delta t = \\frac{2}{N}[T^+(k) - T^-(k)]\\Delta t$$\n$$\\langle (\\Delta m)^2 \\rangle = \\left(+\\frac{2}{N}\\right)^2 T^+(k)\\Delta t + \\left(-\\frac{2}{N}\\right)^2 T^-(k)\\Delta t = \\frac{4}{N^2}[T^+(k) + T^-(k)]\\Delta t$$\nSo the coefficients are:\n$$A(m) = \\frac{2}{N}[T^+(k) - T^-(k)]$$\n$$B(m) = \\frac{4}{N^2}[T^+(k) + T^-(k)]$$\nLet's compute $T^+ - T^-$ and $T^+ + T^-$:\n$$T^+(k) - T^-(k) = \\left((N-k)\\eta + \\lambda \\frac{k(N-k)}{N-1}\\right) - \\left(k\\eta + \\lambda \\frac{k(N-k)}{N-1}\\right) = (N-2k)\\eta$$\nUsing $N-2k = N(1 - 2k/N) = -Nm$, we get:\n$$T^+(k) - T^-(k) = -Nm\\eta$$\nThe drift coefficient is:\n$$A(m) = \\frac{2}{N}(-Nm\\eta) = -2m\\eta$$\nNext, we compute the sum of rates:\n$$T^+(k) + T^-(k) = (N-k)\\eta + k\\eta + 2\\lambda \\frac{k(N-k)}{N-1} = N\\eta + 2\\lambda \\frac{k(N-k)}{N-1}$$\nWe express $k(N-k)$ in terms of $m$:\n$$k(N-k) = \\frac{N(m+1)}{2} \\left(N - \\frac{N(m+1)}{2}\\right) = \\frac{N(m+1)}{2} \\frac{N(1-m)}{2} = \\frac{N^2}{4}(1-m^2)$$\nSo, the sum of rates is:\n$$T^+(k) + T^-(k) = N\\eta + 2\\lambda \\frac{N^2(1-m^2)}{4(N-1)} = N\\eta + \\frac{\\lambda N^2}{2(N-1)}(1-m^2)$$\nThe diffusion coefficient is:\n$$B(m) = \\frac{4}{N^2}\\left[N\\eta + \\frac{\\lambda N^2}{2(N-1)}(1-m^2)\\right] = \\frac{4\\eta}{N} + \\frac{2\\lambda N}{N(N-1)}(1-m^2) = \\frac{4\\eta}{N} + \\frac{2\\lambda}{N-1}(1-m^2)$$\nFor large $N$, we can approximate $N-1 \\approx N$, which is a leading-order approximation in $1/N$:\n$$B(m) \\approx \\frac{4\\eta}{N} + \\frac{2\\lambda}{N}(1-m^2) = \\frac{2}{N}[\\lambda+2\\eta - \\lambda m^2]$$\nThe problem specifies the analysis should be valid \"in the vicinity of $m = 0$\". This suggests that fluctuations around $m=0$ are small, so $m^2$ terms in the diffusion coefficient can be neglected as a higher-order correction. The variance will be $O(1/N)$, so this approximation is self-consistent. We set $m=0$ in $B(m)$:\n$$B(m) \\approx B(0) = \\frac{2(\\lambda+2\\eta)}{N}$$\nThe resulting FPE describes an Ornstein-Uhlenbeck process for $m$:\n$$\\frac{\\partial P(m,t)}{\\partial t} = \\frac{\\partial}{\\partial m}[2m\\eta P(m,t)] + \\frac{\\lambda+2\\eta}{N} \\frac{\\partial^2 P(m,t)}{\\partial m^2}$$\nTo find the steady-state distribution $P_{\\mathrm{ss}}(m)$, we set $\\frac{\\partial P}{\\partial t} = 0$:\n$$\\frac{\\partial}{\\partial m}\\left[2m\\eta P_{\\mathrm{ss}}(m) + \\frac{\\lambda+2\\eta}{N} \\frac{\\partial P_{\\mathrm{ss}}(m)}{\\partial m}\\right] = 0$$\nThis implies the term in brackets, which is the negative of the probability flux, is constant. For a normalizable distribution with reflecting or natural boundaries, this constant must be zero.\n$$2m\\eta P_{\\mathrm{ss}}(m) + \\frac{\\lambda+2\\eta}{N} \\frac{d P_{\\mathrm{ss}}(m)}{d m} = 0$$\n$$\\frac{d P_{\\mathrm{ss}}}{P_{\\mathrm{ss}}} = -\\frac{2N\\eta}{\\lambda+2\\eta} m \\, dm$$\nIntegrating both sides, we obtain:\n$$\\ln P_{\\mathrm{ss}}(m) = -\\frac{N\\eta}{\\lambda+2\\eta} m^2 + \\text{constant}$$\nThis corresponds to a Gaussian distribution:\n$$P_{\\mathrm{ss}}(m) = \\mathcal{N} \\exp\\left(-\\frac{N\\eta}{\\lambda+2\\eta} m^2\\right)$$\nwhere $\\mathcal{N}$ is a normalization constant. A Gaussian distribution of the form $\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$ has mean $\\mu$ and variance $\\sigma^2$. By comparison, we can identify the steady-state mean and variance.\nThe mean is clearly zero as the distribution is symmetric around $m=0$:\n$$\\langle m \\rangle_{\\mathrm{ss}} = 0$$\nThe variance $\\mathrm{Var}_{\\mathrm{ss}}(m) = \\langle m^2 \\rangle_{\\mathrm{ss}} = \\sigma^2$ is found by setting:\n$$\\frac{1}{2\\sigma^2} = \\frac{N\\eta}{\\lambda+2\\eta}$$\n$$\\sigma^2 = \\frac{\\lambda+2\\eta}{2N\\eta}$$\nThus, to leading order in $1/N$, the steady-state variance is:\n$$\\mathrm{Var}_{\\mathrm{ss}}(m) = \\frac{\\lambda+2\\eta}{2N\\eta}$$\nThe final answers are the steady-state mean and variance of the magnetization.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & \\frac{\\lambda + 2\\eta}{2N\\eta}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "This practice takes you to a frontier of complex systems research by exploring the Adaptive Voter Model, where the social network is not static but co-evolves with the agents' opinions. This feedback between opinion and topology can lead to dramatic emergent phenomena, such as the fragmentation of the network into disconnected, echo-chamber-like communities . Your task is to apply mean-field theory at the pair level to predict the critical threshold for this fragmentation, combining analytical skill with computational implementation.",
            "id": "4311561",
            "problem": "Consider the Adaptive Voter Model (AVM) on an undirected, simple, connected, random network with $N$ nodes and mean degree $k$. Each node holds one of two opinions, denoted by $A$ and $B$. At each elementary update, an edge connecting nodes with opposite opinions (an active edge) is selected uniformly at random. With probability $φ \\in [0,1]$, a rewiring event occurs: one endpoint of the selected edge rewires this edge to a uniformly random node that shares its own opinion, preserving the degree sequence and avoiding self-loops and multiple edges. With probability $1-φ$, an adoption event occurs: one endpoint of the selected edge adopts the opinion of the other endpoint. Let $M = Nk/2$ be the number of edges and let $m$ be the number of active edges. Define the active edge density $ρ = m/M$.\n\nStarting from the model definition and assuming random mixing and no degree-opinion correlations beyond pair densities (pair approximation), derive a closed mean-field rate equation for the expected evolution of $ρ$ under the AVM dynamics. Conduct a linear stability and fixed-point analysis of this rate equation to identify the critical rewiring probability $φ_c(k)$ at which the system transitions from a regime with a nonzero stationary density of active edges to a regime where the only stable stationary state has $ρ = 0$ (fragmentation into opinion-homogeneous components). Express $φ_c(k)$ explicitly as a function of $k$ and constants, justified by the pair approximation.\n\nYour program must implement the derived expression for $φ_c(k)$ and evaluate it for the following test suite of mean degree values:\n- $k = 2$ (boundary case for minimal connectivity),\n- $k = 3$ (low connectivity),\n- $k = 4$ (moderate connectivity),\n- $k = 10$ (high connectivity),\n- $k = 100$ (asymptotic regime indicator).\n\nYour program should produce a single line of output containing the results as a comma-separated list of floating-point numbers, rounded to $10$ decimal places, enclosed in square brackets (for example, $[0.1234567890,0.2345678901]$). The output must follow this exact format and contain the computed values of $φ_c(k)$ for the given test suite, in the order listed above. No physical units are involved; all quantities are dimensionless. The final answers must be given as decimal numbers, not fractions.",
            "solution": "The Adaptive Voter Model (AVM) consists of two types of updates applied to edges that connect nodes holding opposite opinions. Let $N$ be the number of nodes, $k$ the mean degree, and $M = Nk/2$ the total number of edges. Define the number of active edges $m$ as those edges connecting opposite opinions and the active edge density $ρ = m/M$.\n\nWe aim to derive a mean-field rate equation for $ρ$ using pair approximation. The fundamental base for this derivation is the definition of the AVM update rules and the assumption of random mixing, which permits closure at the level of pairs by approximating higher-order neighborhood statistics via pair densities.\n\nWe first consider a single elementary event where an active edge is selected uniformly among all active edges. There are two mutually exclusive outcomes:\n\n- Rewiring with probability $φ$,\n- Adoption with probability $1 - φ$.\n\nWe compute the expected change in the number of active edges $m$ under each outcome, then convert it to an expected change in the density $ρ$ by normalizing by $M$ and rescaling time. Since stability and thresholds are invariant under linear time rescaling, we focus on the sign and fixed points of the rate equation rather than its absolute speed.\n\nRewiring step ($φ$): When an active edge is rewired, that edge is removed from the set of active edges and replaced by an edge connecting same-opinion nodes. Under pair approximation and random mixing, the rewired edge becomes inert (connecting same opinions), and no new active edges are created by the rewiring choice. Therefore, the change in the number of active edges is\n$$\n\\Delta m_{\\text{rewire}} = -1.\n$$\n\nAdoption step ($1-φ$): We analyze the expected change in the number of active edges when one endpoint of the selected active edge adopts the opinion of the other endpoint. Consider an active edge $(i,j)$ with $i$ holding opinion $A$ and $j$ holding opinion $B$. Without loss of generality, suppose $i$ adopts $B$. The net change in the number of active edges is determined by the difference between the number of active edges incident to $i$ before and after the flip.\n\nLet $b$ be the number of neighbors of $i$ holding opinion $B$ before the flip, and $a$ be the number of neighbors of $i$ holding opinion $A$ before the flip. Then the degree of $i$ is $a + b = k$. Under random mixing and conditioning on the existence of the selected active edge $(i,j)$, we infer:\n- One neighbor is $j$, with opinion $B$.\n- The other $k-1$ neighbors are independent and each is of opinion $B$ with probability $ρ$ and of opinion $A$ with probability $1-ρ$ in pair approximation.\n\nTherefore, the expected number of $B$ neighbors before the flip is\n$$\n\\mathbb{E}[b] = 1 + (k - 1) ρ,\n$$\nand the expected number of $A$ neighbors before the flip is\n$$\n\\mathbb{E}[a] = (k - 1)(1 - ρ).\n$$\nAfter $i$ flips to opinion $B$, the active edges incident to $i$ are precisely those connecting to neighbors holding opinion $A$, counted by $\\mathbb{E}[a]$. Before the flip, the active edges incident to $i$ are those connecting to neighbors holding opinion $B$, counted by $\\mathbb{E}[b]$. Hence, the expected change in the number of active edges due to a single adoption event is\n$$\n\\Delta m_{\\text{adopt}} = \\mathbb{E}[a] - \\mathbb{E}[b]\n= (k - 1)(1 - ρ) - \\left[ 1 + (k - 1) ρ \\right]\n= (k - 1)(1 - 2ρ) - 1.\n$$\n\nCombining rewiring and adoption outcomes, the expected change in $m$ per elementary event is\n$$\n\\Delta m = φ \\cdot (-1) + (1 - φ) \\cdot \\left[ (k - 1)(1 - 2ρ) - 1 \\right].\n$$\nRescaling time to absorb the constant factor $M$ and working directly with the density $ρ$, we obtain the mean-field rate equation\n$$\n\\frac{dρ}{dτ} = -φ + (1 - φ) \\left[ (k - 1)(1 - 2ρ) - 1 \\right],\n$$\nwhere $τ$ is a rescaled time variable proportional to the number of elementary events.\n\nExpanding the right-hand side to separate constant and linear terms in $ρ$,\n$$\n\\frac{dρ}{dτ} = \\underbrace{\\left[ (k - 2) - φ (k - 1) \\right]}_{\\text{constant term}}\n\\;-\\; \\underbrace{2 (1 - φ) (k - 1)}_{\\text{linear coefficient}} \\; ρ.\n$$\n\nFixed points and stability: The fixed points satisfy\n$$\n\\left[ (k - 2) - φ (k - 1) \\right] - 2 (1 - φ) (k - 1) ρ^* = 0,\n$$\nso\n$$\nρ^* = \\frac{(k - 2) - φ (k - 1)}{2 (1 - φ) (k - 1)}.\n$$\nThe fragmentation threshold occurs when the interior fixed point $ρ^*$ collides with $ρ = 0$, marking the loss of the nonzero active edge density. This happens precisely when the numerator is zero:\n$$\n(k - 2) - φ_c (k - 1) = 0.\n$$\nSolving for $φ_c$ yields\n$$\nφ_c(k) = \\frac{k - 2}{k - 1}.\n$$\n\nInterpretation: For $φ < φ_c(k)$, the constant term in the rate equation is positive, which implies a positive drift away from $ρ = 0$ and a stable interior fixed point $ρ^* > 0$ representing sustained inter-opinion interactions (no fragmentation). For $φ > φ_c(k)$, the constant term is negative, and the only stable fixed point is $ρ = 0$, corresponding to fragmentation into opinion-homogeneous components with no active edges.\n\nProgram specification: The program shall implement the derived expression $φ_c(k) = \\frac{k - 2}{k - 1}$ and compute it for the test suite values $k = 2$, $k = 3$, $k = 4$, $k = 10$, and $k = 100$. The outputs are dimensionless, must be expressed as decimal numbers, and must be printed as a single comma-separated list enclosed in square brackets, with each value rounded to $10$ decimal places, in the exact order of the test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef phi_c(k: int) -> float:\n    \"\"\"\n    Critical rewiring probability phi_c(k) under the pair approximation\n    for the two-state adaptive voter model on a random network\n    with mean degree k: phi_c = (k - 2) / (k - 1).\n    \"\"\"\n    if k <= 1:\n        # Undefined in this approximation; return NaN for completeness.\n        return float('nan')\n    return (k - 2) / (k - 1)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [2, 3, 4, 10, 100]\n\n    results = []\n    for k in test_cases:\n        result = phi_c(k)\n        # Round to 10 decimal places as specified.\n        results.append(f\"{result:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}