{
    "hands_on_practices": [
        {
            "introduction": "这项练习将引导我们探索最简洁却也最优雅的情形：无向图上的随机游走。我们将从第一性原理出发，推导转移矩阵，然后利用强大的“可逆性”概念来求解稳态分布。通过这个实践，你将揭示一个网络科学中的基本关系——节点的长期访问概率与其连接度（即度）之间的深刻联系。",
            "id": "4312660",
            "problem": "考虑一个包含$4$个节点的无向路径图，其顶点集为$\\{1,2,3,4\\}$，边集为$\\{(1,2),(2,3),(3,4)\\}$。该图上的离散时间简单随机游走定义如下：在任意节点$i$，游走者在下一个时间步以均匀随机的方式移动到其一个相邻的邻居。令$P$表示此随机游走的转移概率矩阵，其中条目$P_{ij}$等于从节点$i$一步移动到节点$j$的概率。\n\n仅使用马尔可夫链和无向图上随机游走的基本定义，完成以下任务：\n- 基于图的拓扑结构和简单随机游走规则，从第一性原理推导转移概率矩阵$P$。\n- 使用有限马尔可夫链的平稳分布定义，并援引基于无向边对称性的可逆性考量，显式计算平稳分布$\\pi$。\n\n仅报告平稳分布向量$\\pi$的精确分数形式。不要四舍五入；不需要单位。",
            "solution": "题目要求推导指定路径图上简单随机游走的转移矩阵$P$和平稳分布$\\pi$。推导必须基于第一性原理和可逆性考量。\n\n该图是一个无向路径图，顶点集为$V = \\{1, 2, 3, 4\\}$，边集为$E = \\{(1,2), (2,3), (3,4)\\}$。在此图上的简单随机游走过程为：从当前节点$i$以均匀概率移动到其一个相邻的邻居。\n\n首先，我们推导转移概率矩阵$P$。条目$P_{ij}$表示从节点$i$一步移动到节点$j$的概率。对于无向图上的简单随机游走，如果节点$j$是节点$i$的邻居，则此概率为$P_{ij} = \\frac{1}{d(i)}$，其中$d(i)$是节点$i$的度（其邻居的数量）。如果$j$不是$i$的邻居且$i \\neq j$，则$P_{ij} = 0$。题目暗示游走者总是移动到*邻居*，因此游走动态中没有自环，即对所有$i \\in V$都有$P_{ii}=0$。\n\n我们来计算各顶点的度：\n- 节点$1$：一个邻居($2$)，所以$d(1) = 1$。\n- 节点$2$：两个邻居($1$和$3$)，所以$d(2) = 2$。\n- 节点$3$：两个邻居($2$和$4$)，所以$d(3) = 2$。\n- 节点$4$：一个邻居($3$)，所以$d(4) = 1$。\n\n使用这些度，我们逐行构建转移矩阵$P$：\n- 从节点$1$出发：唯一的邻居是$2$。所以，$P_{12} = \\frac{1}{d(1)} = \\frac{1}{1} = 1$。此行其他概率为$0$。\n- 从节点$2$出发：邻居是$1$和$3$。所以，$P_{21} = \\frac{1}{d(2)} = \\frac{1}{2}$ 和 $P_{23} = \\frac{1}{d(2)} = \\frac{1}{2}$。\n- 从节点$3$出发：邻居是$2$和$4$。所以，$P_{32} = \\frac{1}{d(3)} = \\frac{1}{2}$ 和 $P_{34} = \\frac{1}{d(3)} = \\frac{1}{2}$。\n- 从节点$4$出发：唯一的邻居是$3$。所以，$P_{43} = \\frac{1}{d(4)} = \\frac{1}{1} = 1$。\n\n得到的转移矩阵是：\n$$\nP = \\begin{pmatrix}\n0  1  0  0 \\\\\n\\frac{1}{2}  0  \\frac{1}{2}  0 \\\\\n0  \\frac{1}{2}  0  \\frac{1}{2} \\\\\n0  0  1  0\n\\end{pmatrix}\n$$\n\n接下来，我们计算平稳分布$\\pi = \\begin{pmatrix} \\pi_1  \\pi_2  \\pi_3  \\pi_4 \\end{pmatrix}$。一个分布是平稳的，如果它满足方程$\\pi P = \\pi$，并服从归一化条件$\\sum_{i \\in V} \\pi_i = 1$。对于有限、连通、无向图，保证存在唯一的平稳分布。\n\n题目要求使用可逆性论证。如果细致平衡条件成立，则马尔可夫链对于分布$\\pi$是可逆的：\n$$ \\pi_i P_{ij} = \\pi_j P_{ji} \\quad \\text{for all } i, j \\in V $$\n一个关键定理指出，对于不可约马尔可夫链，任何满足细致平衡的分布都是平稳分布。我们可以通过对细致平衡方程对所有$j$求和来证明这一点：\n$$ \\sum_{j} \\pi_i P_{ij} = \\sum_{j} \\pi_j P_{ji} $$\n$$ \\pi_i \\sum_{j} P_{ij} = \\sum_{j} \\pi_j P_{ji} $$\n由于$P$是随机矩阵，每行之和为$1$，所以$\\sum_{j} P_{ij} = 1$。方程变为：\n$$ \\pi_i = \\sum_{j} \\pi_j P_{ji} = (\\pi P)_i $$\n这就是平稳分布的定义，$\\pi = \\pi P$。因此，如果我们找到一个满足细致平衡且正确归一化的分布，它就是唯一的平稳分布。\n\n对于无向图上的简单随机游走，平稳分布与顶点度之间存在基于边的对称性的基本联系。设$A$为图的邻接矩阵，其中如果$(i,j)$是一条边，则$A_{ij}=1$，否则为$0$。由于图是无向的，$A_{ij}=A_{ji}$。转移概率为$P_{ij} = \\frac{A_{ij}}{d(i)}$。\n\n让我们检验一个与顶点度成正比的分布，$\\pi_i = c \\cdot d(i)$（其中$c$为某个常数），是否满足细致平衡。\n- 左边：$\\pi_i P_{ij} = (c \\cdot d(i)) \\left( \\frac{A_{ij}}{d(i)} \\right) = c \\cdot A_{ij}$。\n- 右边：$\\pi_j P_{ji} = (c \\cdot d(j)) \\left( \\frac{A_{ji}}{d(j)} \\right) = c \\cdot A_{ji}$。\n由于$A_{ij} = A_{ji}$，两边相等：$c \\cdot A_{ij} = c \\cdot A_{ji}$。这在$i$和$j$之间有边($A_{ij}=A_{ji}=1$)和没有边($A_{ij}=A_{ji}=0$)时都成立。因此，任何$\\pi_i$与$d(i)$成正比的分布都满足细致平衡条件。\n\n为了找到具体的平稳分布，我们强制执行归一化条件$\\sum_{i} \\pi_i = 1$。\n$$ \\sum_{i=1}^4 c \\cdot d(i) = 1 \\implies c \\left( \\sum_{i=1}^4 d(i) \\right) = 1 $$\n度的总和为$\\sum d(i) = d(1) + d(2) + d(3) + d(4) = 1 + 2 + 2 + 1 = 6$。\n所以，$c \\cdot 6 = 1$，这给出$c = \\frac{1}{6}$。\n\n因此，平稳分布由$\\pi_i = \\frac{d(i)}{6}$给出。我们可以计算每个分量：\n- $\\pi_1 = \\frac{d(1)}{6} = \\frac{1}{6}$\n- $\\pi_2 = \\frac{d(2)}{6} = \\frac{2}{6} = \\frac{1}{3}$\n- $\\pi_3 = \\frac{d(3)}{6} = \\frac{2}{6} = \\frac{1}{3}$\n- $\\pi_4 = \\frac{d(4)}{6} = \\frac{1}{6}$\n\n平稳分布向量为$\\pi = \\begin{pmatrix} \\frac{1}{6}  \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{6} \\end{pmatrix}$。这个结果是精确的，并且是按要求从第一性原理推导出来的。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{6}  \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{6} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在理解了稳态存在性的基础上，这项练习将深入探讨随机游走“如何”以及“多快”收敛到这个平衡状态。通过对一个小型转移矩阵进行完整的谱分解，我们将观察到特征值和特征向量是如何支配系统动态演化的。这个练习将稳态分布与主特征向量直接联系起来，并利用次级主导特征值来量化收敛到稳态的速率。",
            "id": "4312686",
            "problem": "考虑一个有向网络上的离散时间随机游走 (RW)，该网络有两个节点，标记为 $1$ 和 $2$。在每个时间步，位于节点 $1$ 的游走者确定性地移动到节点 $2$，而位于节点 $2$ 的游走者以 $1/2$ 的概率移动到节点 $1$，并以 $1/2$ 的概率停留在节点 $2$。该随机游走的演化由一个行随机转移矩阵 $P$ 控制，使得概率行向量 $x(t)$ 按 $x(t+1) = x(t) P$ 更新。转移矩阵为\n$$\nP = \\begin{pmatrix}\n0  1 \\\\\n\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}.\n$$\n从复杂系统和网络科学的基础定义出发——具体包括线性算子的特征值和特征向量的定义，平稳分布 $\\pi$ 被刻画为一个满足 $\\pi P = \\pi$ 和 $\\pi \\mathbf{1} = 1$ 的非负行向量（其中 $\\mathbf{1}$ 是全为一的列向量），以及本原（不可约且非周期）随机矩阵幂的渐进行为——推导给定矩阵 $P$ 的以下内容：\n\n- $P$ 的特征值。\n- 与这些特征值对应的 $P$ 的右特征向量的一组基（选择任意方便的非零代表）。\n- 该随机游走的唯一平稳分布 $\\pi$。\n- $P^{t}$ 在 $t \\to \\infty$ 时的渐进形式的闭式表达式，需展示其主导的秩一顶和领先的衰减修正项。\n\n提供精确结果（不要四舍五入）。将最终答案表示为一个包含四个条目的单行矩阵，顺序如下：一对特征值；一个 $2 \\times 2$ 矩阵，其列是对应的右特征向量；一个 $1 \\times 2$ 的行向量表示的平稳分布；以及 $P^{t}$ 的渐进形式，表示为一个秩一极限与一个正比于 $(-\\frac{1}{2})^{t}$ 的项之和的 $2 \\times 2$ 矩阵。",
            "solution": "该问题定义明确，需要应用马尔可夫链理论和线性代数的标准方法。第一步是分析给定转移矩阵 $P$ 的谱性质。\n\n$P$ 的特征值 $\\lambda$ 是特征方程 $\\det(P - \\lambda I) = 0$ 的根，其中 $I$ 是 $2 \\times 2$ 的单位矩阵。\n$$\n\\det \\begin{pmatrix} -\\lambda  1 \\\\ \\frac{1}{2}  \\frac{1}{2} - \\lambda \\end{pmatrix} = (-\\lambda)\\left(\\frac{1}{2} - \\lambda\\right) - (1)\\left(\\frac{1}{2}\\right) = 0\n$$\n这可以简化为二次方程：\n$$\n\\lambda^2 - \\frac{1}{2}\\lambda - \\frac{1}{2} = 0\n$$\n两边乘以 $2$ 以消除分数，得到 $2\\lambda^2 - \\lambda - 1 = 0$。对该二次多项式进行因式分解得到：\n$$\n(2\\lambda + 1)(\\lambda - 1) = 0\n$$\n因此，特征值为 $\\lambda_1 = 1$ 和 $\\lambda_2 = -\\frac{1}{2}$。根据适用于随机矩阵的 Perron-Frobenius 定理，模最大的特征值是 $1$。\n\n接下来，我们求解右特征向量的一组基。对应于特征值 $\\lambda$ 的右特征向量 $\\mathbf{v}$ 满足方程 $(P - \\lambda I)\\mathbf{v} = \\mathbf{0}$。\n对于特征值 $\\lambda_1 = 1$：\n$$\n(P - 1 \\cdot I)\\mathbf{v}_1 = \\begin{pmatrix} -1  1 \\\\ \\frac{1}{2}  -\\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n这得到方程 $-x + y = 0$，即 $x=y$。一个方便的非零特征向量选择是 $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n\n对于特征值 $\\lambda_2 = -\\frac{1}{2}$：\n$$\n\\left(P - \\left(-\\frac{1}{2}\\right)I\\right)\\mathbf{v}_2 = \\left(P + \\frac{1}{2}I\\right)\\mathbf{v}_2 = \\begin{pmatrix} \\frac{1}{2}  1 \\\\ \\frac{1}{2}  1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n这得到方程 $\\frac{1}{2}x + y = 0$，即 $x = -2y$。一个方便的非零特征向量选择是 $\\mathbf{v}_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$。\n因此，右特征向量的一组基由矩阵 $\\begin{pmatrix} \\mathbf{v}_1  \\mathbf{v}_2 \\end{pmatrix} = \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix}$ 的列向量给出。\n\n唯一的平稳分布 $\\pi = \\begin{pmatrix} \\pi_1  \\pi_2 \\end{pmatrix}$ 是 $P$ 对应于特征值 $\\lambda_1 = 1$ 的唯一非负左特征向量，并归一化使其分量之和为 $1$。它满足 $\\pi P = \\pi$ 和 $\\pi_1 + \\pi_2 = 1$。方程 $\\pi P = \\pi$ 为：\n$$\n\\begin{pmatrix} \\pi_1  \\pi_2 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} \\pi_1  \\pi_2 \\end{pmatrix}\n$$\n展开得到方程组 $\\frac{1}{2}\\pi_2 = \\pi_1$ 和 $\\pi_1 + \\frac{1}{2}\\pi_2 = \\pi_2$。两个方程都等价于 $\\pi_2 = 2\\pi_1$。使用归一化条件 $\\pi_1 + \\pi_2 = 1$，我们代入 $\\pi_2$：\n$$\n\\pi_1 + 2\\pi_1 = 1 \\implies 3\\pi_1 = 1 \\implies \\pi_1 = \\frac{1}{3}\n$$\n因此，$\\pi_2 = 2(\\frac{1}{3}) = \\frac{2}{3}$。平稳分布为 $\\pi = \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}$。\n\n最后，为了求 $P^t$ 的渐进形式，我们使用 $P$ 的谱分解。由于给定的矩阵 $P$ 是可对角化的，我们可以将其幂写为 $P^t = \\sum_{i=1}^{2} \\lambda_i^t \\mathbf{v}_i \\mathbf{u}_i$，其中 $\\mathbf{v}_i$ 是右特征向量（作为列向量），$\\mathbf{u}_i$ 是相应的左特征向量（作为行向量），并归一化使得 $\\mathbf{u}_i \\mathbf{v}_j = \\delta_{ij}$。左特征向量可以作为右特征向量矩阵 $V = \\begin{pmatrix} \\mathbf{v}_1  \\mathbf{v}_2 \\end{pmatrix}$ 的逆矩阵的行向量来找到。\n$$\nV = \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix} \\implies V^{-1} = \\frac{1}{(1)(-1)-(2)(1)} \\begin{pmatrix} -1  -2 \\\\ -1  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\\\ \\frac{1}{3}  -\\frac{1}{3} \\end{pmatrix}\n$$\n左特征向量为 $\\mathbf{u}_1 = \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}$（即平稳分布 $\\pi$）和 $\\mathbf{u}_2 = \\begin{pmatrix} \\frac{1}{3}  -\\frac{1}{3} \\end{pmatrix}$。\n\n谱展开中的第一项对应于 $\\lambda_1 = 1$：\n$$\n\\lambda_1^t \\mathbf{v}_1 \\mathbf{u}_1 = 1^t \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\\\ \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}\n$$\n这是主导的秩一顶，即 $P^t$ 在 $t \\to \\infty$ 时的极限。该矩阵的每一行都是平稳分布 $\\pi$。\n\n第二项对应于次主导特征值 $\\lambda_2 = -\\frac{1}{2}$：\n$$\n\\lambda_2^t \\mathbf{v}_2 \\mathbf{u}_2 = \\left(-\\frac{1}{2}\\right)^t \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3}  -\\frac{1}{3} \\end{pmatrix} = \\left(-\\frac{1}{2}\\right)^t \\begin{pmatrix} \\frac{2}{3}  -\\frac{2}{3} \\\\ -\\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}\n$$\n这是领先的衰减修正项，它控制着瞬态行为。\n$P^t$ 的完整闭式表达式是这两项之和：\n$$\nP^t = \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\\\ \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix} + \\left(-\\frac{1}{2}\\right)^t \\begin{pmatrix} \\frac{2}{3}  -\\frac{2}{3} \\\\ -\\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}\n$$\n这个表达式展示了所要求的渐进形式，当 $t \\to \\infty$ 时，修正项衰减至零，收敛到秩一极限。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\begin{pmatrix} 1  -\\frac{1}{2} \\end{pmatrix}  \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix}  \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}  \\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\\\ \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix} + \\left(-\\frac{1}{2}\\right)^{t} \\begin{pmatrix} \\frac{2}{3}  -\\frac{2}{3} \\\\ -\\frac{1}{3}  \\frac{1}{3} \\end{pmatrix} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "从解析解到计算方法，这最后一个实践将我们引向一个真实世界的应用：PageRank算法。你将实现一种迭代方法，来寻找包含“悬挂节点”的图上的稳态分布——这是在真实网络（如万维网）中普遍存在的问题。这项练习展示了如何调整理论框架，以构建用于大规模网络分析的稳健算法。",
            "id": "4312629",
            "problem": "考虑一个有限有向图 $G = (V, E)$，其节点数为 $|V| = n$，由一个邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示，其中当且仅当存在从节点 $i$ 到节点 $j$ 的有向边时，$A_{ij} = 1$，否则 $A_{ij} = 0$。设节点 $i$ 的出度为 $d_i = \\sum_{j=1}^n A_{ij}$。一个出度 $d_i = 0$ 的节点 $i$ 被称为悬挂节点。\n\n我们如下定义带传送的随机游走。在每一步，从当前节点 $i$ 出发：\n- 以概率 $\\alpha \\in [0,1]$，如果 $d_i > 0$，游走会尝试从 $d_i$ 条出边中均匀随机地选择一条进行移动。如果 $d_i = 0$，则该步骤会根据指定的传送分布选择下一个节点。\n- 以概率 $1 - \\alpha$，游走会根据指定的传送分布选择下一个节点。\n\n传送分布由一个个性化向量 $v \\in \\mathbb{R}^n$ 给出，满足对所有 $j$ 都有 $v_j \\ge 0$ 且 $\\sum_{j=1}^n v_j = 1$。\n\n这些规则为该随机游走导出一个行随机转移矩阵 $P_\\alpha \\in \\mathbb{R}^{n \\times n}$。平稳分布 $\\pi \\in \\mathbb{R}^n$ 是一个概率向量，满足 $\\pi = \\pi P_\\alpha$，对所有 $j$ 都有 $\\pi_j \\ge 0$，且 $\\sum_{j=1}^n \\pi_j = 1$。\n\n从马尔可夫链和图上随机游走的基本定义出发，为下面的每个测试用例构建转移矩阵 $P_\\alpha$，并遵循上述规则，特别是在无法进行均匀边选择时，通过使用传送分布来处理悬挂节点。然后，使用一种有理论依据的迭代方法，对平稳分布 $\\pi$ 进行数值计算，该方法在这些动力学下能收敛到唯一的平稳分布。你的计算必须使用一种能确保对所有提供的用例都收敛的方法，并且当连续迭代之间的 $\\ell_1$ 范数差小于 $10^{-12}$ 或达到最大迭代次数 $10^6$ 次时（以先到者为准）终止。不涉及物理量，因此不需要物理单位。所有输出必须以小数形式表示。\n\n测试套件：\n- 用例 1：图 $G_1$，其中 $V = \\{0,1,2,3\\}$，边集 $E = \\{(0,1),(1,2),(2,0)\\}$；节点 $3$ 是悬挂节点。传送向量 $v = [\\,1/4,\\,1/4,\\,1/4,\\,1/4\\,]$。参数 $\\alpha = 0.85$。\n- 用例 2：与用例 1 相同的图 $G_1$ 和向量 $v$，但参数 $\\alpha = 0.0$。\n- 用例 3：与用例 1 相同的图 $G_1$ 和向量 $v$，但参数 $\\alpha = 0.99$。\n- 用例 4：图 $G_2$，其中 $V = \\{0,1,2,3,4\\}$，边集 $E = \\{(0,1),(0,2),(1,2),(2,0),(3,4)\\}$；节点 $4$ 是悬挂节点。传送向量 $v = [\\,0.4,\\,0.2,\\,0.2,\\,0.1,\\,0.1\\,]$。参数 $\\alpha = 0.85$。\n- 用例 5：图 $G_3$，其中 $V = \\{0,1,2\\}$，边集 $E = \\{(0,0),(1,0)\\}$；节点 $2$ 是悬挂节点。传送向量 $v = [\\,1/3,\\,1/3,\\,1/3\\,]$。参数 $\\alpha = 0.75$。\n\n要求：\n- 仅根据上述规则，使用邻接矩阵 $A$、出度 $d_i$、参数 $\\alpha$ 和向量 $v$ 来构建 $P_\\alpha$，并特别注意对于任何出度 $d_i=0$ 的行 $i$，到每个节点 $j$ 的转移概率必须由传送分布定义。\n- 使用基于定义 $\\pi = \\pi P_\\alpha$ 的有数学原理的迭代方法，为每个测试用例数值计算平稳分布 $\\pi$。选择一个基于底层过程而合理的初始化，并确保在每一步进行归一化。\n- 将每个 $\\pi$ 的每个分量四舍五入到 $10$ 位小数。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含所有测试用例的平稳分布，聚合为一个用方括号括起来的逗号分隔列表，其中每个元素是该用例的 $\\pi$ 的四舍五入分量的方括号逗号分隔列表。例如，格式必须类似于 $\\texttt{[[\\pi^{(1)}], [\\pi^{(2)}], \\ldots]}$，不含空格。具体来说，输出必须看起来像 $\\texttt{[[x_{1,1},x_{1,2},\\ldots],[x_{2,1},x_{2,2},\\ldots],\\ldots]}$，其中 $x_{k,\\ell}$ 是四舍五入到 $10$ 位的小数。",
            "solution": "该问题要求我们计算给定有向图上带传送的随机游走的平稳分布。这是网络科学中的一个经典问题，因与 Google 的 PageRank 算法相关而闻名。对于一个具有行随机转移矩阵 $P$ 的马尔可夫链，其平稳分布 $\\pi$ 是一个概率向量，在经过转移后保持不变，满足方程 $\\pi = \\pi P$。\n\n首先，我们必须根据所提供的规则构建转移矩阵 $P_\\alpha$。设图 $G=(V, E)$ 的节点数为 $n$。从节点 $i$ 到节点 $j$ 的转移概率 $P_\\alpha(i, j)$ 由节点 $i$ 的出度 $d_i = \\sum_{k=1}^n A_{ik}$、传送概率 $\\alpha$ 和个性化向量 $v$ 决定。\n\n从节点 $i$ 开始转移的规则是：\n1. 以概率 $\\alpha$，游走者尝试跟随一条出边。\n2. 以概率 $1-\\alpha$，游走者传送到一个新节点，该节点根据分布 $v$ 选择。\n\n我们必须将这形式化为节点 $i$ 的两种情况：\n\n情况 1：节点 $i$ 不是悬挂节点 ($d_i > 0$)。\n从 $i$ 到 $j$ 的转移可以通过两种互斥的方式发生：\n- 通过跟随边（以概率 $\\alpha$）：游走者从 $d_i$ 条出边中均匀选择一条。因此，它以概率 $\\frac{1}{d_i}$ 转移到邻居 $j$（其中 $A_{ij}=1$）。此路径的总概率是 $\\alpha \\frac{A_{ij}}{d_i}$。\n- 通过传送（以概率 $1-\\alpha$）：游走者以概率 $v_j$ 传送到节点 $j$。此路径的总概率是 $(1-\\alpha)v_j$。\n将这些概率相加，得到转移矩阵的条目：\n$$P_\\alpha(i, j) = \\alpha \\frac{A_{ij}}{d_i} + (1-\\alpha)v_j \\quad \\text{对于 } d_i > 0$$\n\n情况 2：节点 $i$ 是悬挂节点 ($d_i = 0$)。\n问题陈述指出，如果尝试从悬挂节点进行游走（以概率 $\\alpha$），则默认进行传送。游走也以概率 $1-\\alpha$ 进行传送。因此，从悬挂节点出发，游走者总是进行传送。\n- 传送到节点 $j$ 的概率是 $v_j$。\n这意味着转移矩阵的第 $i$ 行完全是传送向量 $v$：\n$$P_\\alpha(i, j) = v_j \\quad \\text{对于 } d_i = 0$$\n\n得到的矩阵 $P_\\alpha$ 是行随机的，意味着每行的和为 $1$。这是因为对于 $d_i > 0$，$\\sum_j P_\\alpha(i, j) = \\sum_j (\\alpha \\frac{A_{ij}}{d_i} + (1-\\alpha)v_j) = \\frac{\\alpha}{d_i}\\sum_j A_{ij} + (1-\\alpha)\\sum_j v_j = \\frac{\\alpha}{d_i}d_i + (1-\\alpha) \\cdot 1 = \\alpha + 1 - \\alpha = 1$。对于 $d_i = 0$，$\\sum_j P_\\alpha(i, j) = \\sum_j v_j = 1$。\n\n构建好 $P_\\alpha$ 后，我们需要找到满足 $\\pi = \\pi P_\\alpha$ 的平稳分布 $\\pi$。对于 $\\alpha \\in [0, 1)$ 以及所有分量均为正的个性化向量 $v$（所有测试用例均是如此），该马尔可夫链是遍历的。这保证了唯一平稳分布的存在。\n\n找到此分布的一种有理论依据且标准的迭代方法是**幂迭代法 (Power Iteration Method)**。它利用了这样一个事实：对于一个遍历马尔可夫链，将转移矩阵重复应用于任何初始概率分布，最终都会收敛到唯一的平稳分布。\n迭代过程定义为：\n$$\\pi^{(k+1)} = \\pi^{(k)} P_\\alpha$$\n其中 $\\pi^{(k)}$ 是第 $k$ 次迭代时的分布。\n\n算法如下：\n1.  将 $\\pi^{(0)}$ 初始化为一个概率分布。一个常用且稳健的选择是均匀分布，即对所有 $j=1, \\dots, n$，$\\pi^{(0)}_j = 1/n$。\n2.  迭代计算 $\\pi^{(k+1)} = \\pi^{(k)} P_\\alpha$。由于 $P_\\alpha$ 是行随机的，如果 $\\pi^{(k)}$ 是一个概率分布，那么 $\\pi^{(k+1)}$ 也将是，因此在迭代过程中不需要重新归一化。\n3.  当连续分布之间的变化小于给定容差时，迭代终止。问题指定使用 $\\ell_1$ 范数进行此检查：\n    $$\\|\\pi^{(k+1)} - \\pi^{(k)}\\|_1 = \\sum_{j=1}^n |\\pi^{(k+1)}_j - \\pi^{(k)}_j|  10^{-12}$$\n4.  同时设置了 $10^6$ 次的迭代上限作为保障。\n\n将实施此过程来为每个提供的测试用例求解 $\\pi$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_stationary_distribution(A, v, alpha, tol=1e-12, max_iter=1000000):\n    \"\"\"\n    Computes the stationary distribution of a random walk with teleportation.\n\n    Args:\n        A (np.ndarray): The adjacency matrix of the graph.\n        v (np.ndarray): The teleportation/personalization vector.\n        alpha (float): The probability of following an edge.\n        tol (float): The tolerance for convergence.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        np.ndarray: The stationary distribution vector pi.\n    \"\"\"\n    n = A.shape[0]\n    \n    # 1. Calculate out-degrees\n    d = A.sum(axis=1)\n\n    # 2. Construct the transition matrix P_alpha\n    P_alpha = np.zeros((n, n), dtype=float)\n    \n    # Create the teleportation component, which is broadcastable\n    teleport_matrix = np.tile(v, (n, 1))\n\n    # Create the walk component matrix\n    walk_matrix = np.zeros((n, n), dtype=float)\n    non_dangling_rows = d > 0\n    # Use np.divide to handle division by zero, which results in inf but we zero it out.\n    # A more robust way is to do it only for non-dangling rows.\n    walk_matrix[non_dangling_rows] = A[non_dangling_rows] / d[non_dangling_rows, np.newaxis]\n\n    # Combine components based on dangling/non-dangling rows\n    # For non-dangling rows, use the combined formula\n    P_alpha[non_dangling_rows] = alpha * walk_matrix[non_dangling_rows] + (1 - alpha) * teleport_matrix[non_dangling_rows]\n    \n    # For dangling rows, the row is just the teleportation vector\n    dangling_rows = d == 0\n    P_alpha[dangling_rows] = teleport_matrix[dangling_rows]\n\n    # 3. Perform Power Iteration\n    # Initialize pi as a uniform distribution\n    pi = np.ones(n) / n\n\n    for _ in range(max_iter):\n        pi_next = pi @ P_alpha\n        \n        # Check for convergence using L1 norm\n        if np.sum(np.abs(pi_next - pi))  tol:\n            pi = pi_next\n            break\n        \n        pi = pi_next\n        \n    return pi\n\n\ndef solve():\n    \"\"\"\n    Sets up and solves the test cases, then prints the final formatted output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([[0, 1, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 0]]),\n            np.array([1/4, 1/4, 1/4, 1/4]),\n            0.85\n        ),\n        # Case 2\n        (\n            np.array([[0, 1, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 0]]),\n            np.array([1/4, 1/4, 1/4, 1/4]),\n            0.0\n        ),\n        # Case 3\n        (\n            np.array([[0, 1, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 0]]),\n            np.array([1/4, 1/4, 1/4, 1/4]),\n            0.99\n        ),\n        # Case 4\n        (\n            np.array([[0, 1, 1, 0, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]),\n            np.array([0.4, 0.2, 0.2, 0.1, 0.1]),\n            0.85\n        ),\n        # Case 5\n        (\n            np.array([[1, 0, 0], [1, 0, 0], [0, 0, 0]]),\n            np.array([1/3, 1/3, 1/3]),\n            0.75\n        ),\n    ]\n\n    results_as_strings = []\n    for A, v, alpha in test_cases:\n        pi = compute_stationary_distribution(A, v, alpha)\n        \n        # Format the resulting vector into a string \"[d1,d2,...,dn]\"\n        # with each component rounded to 10 decimal places.\n        result_str = \"[\" + \",\".join([f\"{x:.10f}\" for x in pi]) + \"]\"\n        results_as_strings.append(result_str)\n\n    # Final print statement in the exact required format.\n    # This joins a list of strings like [\"[0.1,0.2]\", \"[0.3,0.4]\"]\n    # into \"[[0.1,0.2],[0.3,0.4]]\"\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        }
    ]
}