{
    "hands_on_practices": [
        {
            "introduction": "We begin by exploring how the model's predictions behave when its parameters—the edge probabilities—are not known precisely. This practice guides you through calculating the best- and worst-case outcomes for cascade size, a concept known as robustness analysis, by leveraging the monotonic nature of the expected spread function. You will also determine which connections in the network have the most impact on the spread by computing the gradient of the expectation, a key aspect of sensitivity analysis .",
            "id": "4309573",
            "problem": "Consider a directed graph with node set $V$ and edge set $E \\subseteq V \\times V$. In the Independent Cascade (IC) model, a seed set $S \\subseteq V$ is initially active at time $t=0$. Each directed edge $(u,v) \\in E$ has an activation probability $p_{uv} \\in [0,1]$. When node $u$ becomes active, it gets exactly one chance to activate node $v$ via edge $(u,v)$, and succeeds with probability $p_{uv}$. All activation events across edges are mutually independent. The process proceeds in discrete time steps until no more activations occur. Let $X(S,\\mathbf{p})$ denote the random final number of active nodes when the activation probabilities are given by the vector $\\mathbf{p} = (p_e)_{e \\in E}$. The quantity of interest is the expected final cascade size $\\mathbb{E}[X(S,\\mathbf{p})]$.\n\nUnder probability uncertainty, each edge $(u,v)$ has an interval $[\\underline{p}_{uv}, \\overline{p}_{uv}]$ with $\\underline{p}_{uv} \\le \\overline{p}_{uv}$, representing lower and upper bounds on the unknown activation probability. The robustness question is to determine the minimum and maximum of $\\mathbb{E}[X(S,\\mathbf{p})]$ over all $\\mathbf{p}$ consistent with these intervals. The sensitivity question asks for the partial derivative vector $\\nabla \\mathbb{E}[X(S,\\mathbf{p})]$ with respect to $\\mathbf{p}$, evaluated at a specified $\\mathbf{p}$ inside the uncertainty intervals.\n\nStarting only from the fundamental definition of the Independent Cascade model, independence of edge activations, and the definition of expectation, write a complete and runnable program that, for each test case specified below, computes:\n- The robust lower bound $L := \\min_{\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]} \\mathbb{E}[X(S,\\mathbf{p})]$.\n- The robust upper bound $U := \\max_{\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]} \\mathbb{E}[X(S,\\mathbf{p})]$.\n- The sensitivity vector $\\left(\\frac{\\partial}{\\partial p_e} \\mathbb{E}[X(S,\\mathbf{p})]\\right)_{e \\in E}$ evaluated at the midpoint probabilities $\\mathbf{p}^{\\mathrm{mid}} := \\frac{1}{2}(\\underline{\\mathbf{p}} + \\overline{\\mathbf{p}})$, where the addition and division are taken componentwise.\n\nAll computations must be exact in the sense of probability, not asymptotic or heuristic, and must be derived from the definitions. For finite graphs, an exact computation may be performed by enumerating all possible live-edge subgraphs, where each edge is independently included with its activation probability and reachability from $S$ determines the final active set. The final expected value is the sum over all live-edge realizations of the reachability size times its probability.\n\nYour program must solve the following test cases. For each test case, the directed edges $E$ are listed in a specified order, and for each edge $e_i$ in that order, the corresponding lower and upper bounds $\\underline{p}_{e_i}$ and $\\overline{p}_{e_i}$ are given. The seed set $S$ is provided as a list of nodes.\n\nTest Suite:\n- Test Case $1$:\n    - Nodes: $V = \\{0,1,2,3,4\\}$, so $|V| = 5$.\n    - Ordered edges: $E = [(0,1),(1,2),(2,3),(1,3),(0,4),(4,3)]$, so $|E| = 6$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.1,\\,0.2,\\,0.25,\\,0.15,\\,0.05,\\,0.3]$ in the same order as $E$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.3,\\,0.5,\\,0.6,\\,0.5,\\,0.2,\\,0.7]$ in the same order as $E$.\n    - Seed set: $S = \\{0\\}$.\n- Test Case $2$:\n    - Nodes: $V = \\{0,1\\}$, so $|V| = 2$.\n    - Ordered edges: $E = [(0,1)]$, so $|E| = 1$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.2]$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.2]$.\n    - Seed set: $S = \\{0\\}$.\n- Test Case $3$:\n    - Nodes: $V = \\{0,1,2,3\\}$, so $|V| = 4$.\n    - Ordered edges: $E = [(0,1),(0,2),(1,3),(2,3)]$, so $|E| = 4$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.1,\\,0.1,\\,0.2,\\,0.2]$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.9,\\,0.8,\\,0.7,\\,0.6]$.\n    - Seed set: $S = \\{0\\}$.\n\nFor each test case, the required outputs are:\n- The robust lower bound $L$ as a real number.\n- The robust upper bound $U$ as a real number.\n- The sensitivity vector at $\\mathbf{p}^{\\mathrm{mid}}$, listed in the same order as $E$, as real numbers.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of real numbers in the following order: first $L$, then $U$, then the components of the sensitivity vector at $\\mathbf{p}^{\\mathrm{mid}}$. For example, a line with three test cases should look like $[[L_1,U_1,d_{1,1},\\dots,d_{1,|E_1|}],[L_2,U_2,d_{2,1},\\dots,d_{2,|E_2|}],[L_3,U_3,d_{3,1},\\dots,d_{3,|E_3|}]]$.\n\nThere are no physical units and no angle units; all outputs are real numbers without units. Express any proportion-related quantities strictly as decimals.\n\nYour program must be self-contained, require no user input, and compute the exact quantities by finite enumeration consistent with the definitions above.",
            "solution": "The problem requires the computation of robust bounds and sensitivities for the expected cascade size in the Independent Cascade (IC) model under probability uncertainty. We begin by formalizing the expected cascade size, $\\mathbb{E}[X(S,\\mathbf{p})]$.\n\nA specific outcome of the stochastic process corresponds to a \"live-edge subgraph\" $G' = (V, E')$, where $E' \\subseteq E$ is the set of edges that successfully activate. Due to the mutual independence of activation events, the probability of realizing a particular live-edge subgraph $G'$ is given by:\n$$\n\\mathbb{P}(G' | \\mathbf{p}) = \\left( \\prod_{e \\in E'} p_e \\right) \\left( \\prod_{e \\in E \\setminus E'} (1 - p_e) \\right)\n$$\nFor a given live-edge subgraph $G'=(V, E')$, the final set of active nodes is the set of all nodes reachable from the initial seed set $S$. Let's denote this set as $R(S, G')$. The size of the cascade is then $|R(S, G')|$.\n\nBy the definition of expectation, the expected cascade size is the sum of the cascade sizes for each possible live-edge subgraph, weighted by their respective probabilities:\n$$\n\\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E' \\subseteq E} |R(S, (V, E'))| \\cdot \\mathbb{P}((V, E') | \\mathbf{p})\n$$\nThis expression is a multi-linear polynomial in the probability variables $\\{p_e\\}_{e\\in E}$. For finite graphs with a small number of edges, this formula allows for an exact computation by enumerating all $2^{|E|}$ subgraphs.\n\n**Robustness Analysis: Lower and Upper Bounds ($L$ and $U$)**\n\nTo determine the minimum and maximum of $\\mathbb{E}[X(S,\\mathbf{p})]$ over the hyperrectangle defined by $\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]$, we first analyze the function's dependence on a single edge probability, $p_k$, for an arbitrary edge $e_k \\in E$. We compute the partial derivative $\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]$.\n\nLet's separate the summation over $E' \\subseteq E$ into two parts: one where $e_k \\in E'$ and one where $e_k \\notin E'$. Any $E' \\subseteq E$ not containing $e_k$ can be written as $E'' \\subseteq E \\setminus \\{e_k\\}$. Any $E' \\subseteq E$ containing $e_k$ can be written as $E'' \\cup \\{e_k\\}$ for some $E'' \\subseteq E \\setminus \\{e_k\\}$. Let $\\mathbb{P}_{\\neg k}(E'')$ denote the probability of the subgraph $(V, E'')$ with edges taken from $E \\setminus \\{e_k\\}$.\n$$\n\\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E''))| (1-p_k) + |R(S, (V, E'' \\cup \\{e_k\\}))| p_k \\right] \\mathbb{P}_{\\neg k}(E'')\n$$\nTaking the partial derivative with respect to $p_k$:\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))| \\right] \\mathbb{P}_{\\neg k}(E'')\n$$\nWhen adding an edge to a graph, the set of reachable nodes from any source can only grow or stay the same. Thus, $|R(S, (V, E'' \\cup \\{e_k\\}))| \\ge |R(S, (V, E''))|$ for any $E''$. Since probabilities $\\mathbb{P}_{\\neg k}(E'')$ are non-negative, each term in the sum is non-negative. Therefore,\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})] \\ge 0\n$$\nThis demonstrates that $\\mathbb{E}[X(S,\\mathbf{p})]$ is a monotonically non-decreasing function of each probability component $p_k$. Consequently, to find the minimum and maximum of the function over the domain $[\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]$, we only need to evaluate it at the corners of this hyperrectangle. The minimum value $L$ is achieved when all probabilities are at their lowest possible values, and the maximum value $U$ is achieved when they are all at their highest.\n$$\nL := \\min_{\\mathbf{p}} \\mathbb{E}[X(S,\\mathbf{p})] = \\mathbb{E}[X(S, \\underline{\\mathbf{p}})]\n$$\n$$\nU := \\max_{\\mathbf{p}} \\mathbb{E}[X(S,\\mathbf{p})] = \\mathbb{E}[X(S, \\overline{\\mathbf{p}})]\n$$\n\n**Sensitivity Analysis: Gradient Vector ($\\nabla \\mathbb{E}$)**\n\nThe sensitivity vector is the gradient $\\nabla \\mathbb{E}[X(S,\\mathbf{p})]$, which consists of the partial derivatives $\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]$ for each edge $e_k \\in E$. The formula derived above for the partial derivative provides a direct method for computation. For each edge $e_k$, we must evaluate:\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]\\bigg|_{\\mathbf{p}=\\mathbf{p}^{\\mathrm{mid}}} = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))| \\right] \\mathbb{P}_{\\neg k}(E'')\\bigg|_{\\mathbf{p}=\\mathbf{p}^{\\mathrm{mid}}}\n$$\nThe term $|R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))|$ represents the marginal increase in the number of activated nodes due to the presence of edge $e_k$, given that the other live edges are exactly the set $E''$.\n\n**Algorithmic Design**\n\nThe computations for $L$, $U$, and the sensitivity vector can be implemented based on these derived formulas.\n\n1.  A function `compute_expected_cascade(graph_params, probabilities)` will implement the primary expectation formula. It iterates through all $2^{|E|}$ subgraphs. For each subgraph $E'$, it calculates its probability $\\mathbb{P}((V,E')|\\mathbf{p})$ and the size of the reachable set $|R(S,(V,E'))|$. The latter is found using a Breadth-First Search (BFS) starting from the seed nodes $S$. The products of size and probability are summed to yield the final expectation.\n2.  The lower bound $L$ is computed by calling this function with the lower-bound probability vector $\\underline{\\mathbf{p}}$.\n3.  The upper bound $U$ is computed by calling this function with the upper-bound probability vector $\\overline{\\mathbf{p}}$.\n4.  A function `compute_gradient(graph_params, probabilities)` will compute the sensitivity vector. It iterates through each edge $e_k \\in E$. For each $e_k$, it iterates through all $2^{|E|-1}$ subgraphs $E''$ of $E \\setminus \\{e_k\\}$. In each inner loop, it calculates the probability of $E''$ using the corresponding components of $\\mathbf{p}^{\\mathrm{mid}}$, and computes the difference in cascade size, $|R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))|$, again using BFS for reachability. These products are summed to find the partial derivative $\\frac{\\partial \\mathbb{E}}{\\partial p_k}$ at $\\mathbf{p}^{\\mathrm{mid}}$.\n\nThis approach, based on enumerating subgraphs, is computationally feasible for the small graph sizes specified in the test cases and provides an exact solution derived from first principles.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main solver function to process all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"num_nodes\": 5,\n            \"edges\": [(0, 1), (1, 2), (2, 3), (1, 3), (0, 4), (4, 3)],\n            \"p_lower\": [0.1, 0.2, 0.25, 0.15, 0.05, 0.3],\n            \"p_upper\": [0.3, 0.5, 0.6, 0.5, 0.2, 0.7],\n            \"seed_set\": {0},\n        },\n        {\n            \"num_nodes\": 2,\n            \"edges\": [(0, 1)],\n            \"p_lower\": [0.2],\n            \"p_upper\": [0.2],\n            \"seed_set\": {0},\n        },\n        {\n            \"num_nodes\": 4,\n            \"edges\": [(0, 1), (0, 2), (1, 3), (2, 3)],\n            \"p_lower\": [0.1, 0.1, 0.2, 0.2],\n            \"p_upper\": [0.9, 0.8, 0.7, 0.6],\n            \"seed_set\": {0},\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = get_results_for_case(case)\n        all_results.append(result)\n\n    # Format the final output string as specified.\n    # e.g., [[L1,U1,d1,...],[L2,U2,d2,...]]\n    output_str = \"[\" + \",\".join(\n        \"[\" + \",\".join(f\"{x:.10f}\" for x in res) + \"]\" for res in all_results\n    ) + \"]\"\n    print(output_str)\n\n\ndef get_results_for_case(case):\n    \"\"\"\n    Computes L, U, and sensitivity for a single test case.\n    \"\"\"\n    num_nodes = case[\"num_nodes\"]\n    edges = case[\"edges\"]\n    p_lower = np.array(case[\"p_lower\"])\n    p_upper = np.array(case[\"p_upper\"])\n    seed_set = case[\"seed_set\"]\n\n    # Calculate L (lower bound)\n    L = compute_expected_cascade(num_nodes, edges, seed_set, p_lower)\n\n    # Calculate U (upper bound)\n    U = compute_expected_cascade(num_nodes, edges, seed_set, p_upper)\n    \n    # Calculate sensitivities at midpoint\n    p_mid = 0.5 * (p_lower + p_upper)\n    sensitivity_vector = compute_gradient(num_nodes, edges, seed_set, p_mid)\n\n    return [L, U] + sensitivity_vector\n\n\ndef bfs(num_nodes, edge_list, start_nodes):\n    \"\"\"\n    Performs a Breadth-First Search to find all reachable nodes.\n    \n    Args:\n        num_nodes (int): Total number of nodes in the graph.\n        edge_list (list): A list of (u, v) tuples representing live edges.\n        start_nodes (set): The set of starting nodes for the search.\n\n    Returns:\n        set: The set of nodes reachable from start_nodes.\n    \"\"\"\n    if not start_nodes:\n        return set()\n\n    adj = [[] for _ in range(num_nodes)]\n    for u, v in edge_list:\n        adj[u].append(v)\n    \n    q = deque(list(start_nodes))\n    visited = set(start_nodes)\n    \n    while q:\n        u = q.popleft()\n        for v in adj[u]:\n            if v not in visited:\n                visited.add(v)\n                q.append(v)\n    return visited\n\ndef compute_expected_cascade(num_nodes, edges, seed_set, probabilities):\n    \"\"\"\n    Computes the expected cascade size by enumerating all live-edge subgraphs.\n    \"\"\"\n    num_edges = len(edges)\n    total_expected_size = 0.0\n\n    # Iterate through all 2^m possible live-edge subgraphs\n    for i in range(1  num_edges):\n        live_edges = []\n        subgraph_prob = 1.0\n        \n        for j in range(num_edges):\n            p_j = probabilities[j]\n            if (i >> j)  1:  # If j-th edge is in the live set\n                live_edges.append(edges[j])\n                subgraph_prob *= p_j\n            else:\n                subgraph_prob *= (1.0 - p_j)\n        \n        # Calculate cascade size for this subgraph\n        reachable_nodes = bfs(num_nodes, live_edges, seed_set)\n        cascade_size = len(reachable_nodes)\n        \n        total_expected_size += cascade_size * subgraph_prob\n        \n    return total_expected_size\n\ndef compute_gradient(num_nodes, edges, seed_set, probabilities):\n    \"\"\"\n    Computes the gradient of the expected cascade size.\n    \"\"\"\n    num_edges = len(edges)\n    gradient = [0.0] * num_edges\n\n    for k in range(num_edges):\n        # Edges excluding e_k\n        other_edges = edges[:k] + edges[k+1:]\n        other_probs = np.concatenate((probabilities[:k], probabilities[k+1:]))\n        num_other_edges = len(other_edges)\n        \n        derivative_k = 0.0\n\n        # Iterate through all subgraphs of E \\ {e_k}\n        for i in range(1  num_other_edges):\n            subgraph_prime = []\n            prob_subgraph_prime = 1.0\n            \n            for j in range(num_other_edges):\n                p_j = other_probs[j]\n                if (i >> j)  1:\n                    subgraph_prime.append(other_edges[j])\n                    prob_subgraph_prime *= p_j\n                else:\n                    prob_subgraph_prime *= (1.0 - p_j)\n\n            # Cascade size without edge e_k\n            size_without_ek = len(bfs(num_nodes, subgraph_prime, seed_set))\n            \n            # Cascade size with edge e_k\n            subgraph_with_ek = subgraph_prime + [edges[k]]\n            size_with_ek = len(bfs(num_nodes, subgraph_with_ek, seed_set))\n            \n            derivative_k += (size_with_ek - size_without_ek) * prob_subgraph_prime\n        \n        gradient[k] = derivative_k\n        \n    return gradient\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Real-world networks often feature multiple competing ideas or products spreading simultaneously, from political campaigns to marketing efforts. This exercise extends the basic Independent Cascade model to a competitive scenario where you will calculate the expected share of the network captured by each contagion. This requires a careful application of the live-edge model and an exact enumeration over the entire probability space to handle tie-breaking rules, reflecting the complexities of competing influence processes .",
            "id": "4309576",
            "problem": "You are given a formal model of competitive diffusion with multiple contagions under the Independent Cascade (IC) framework on a finite directed graph. Consider a directed graph $G=(V,E)$, an integer number of contagions $K \\in \\mathbb{N}$, a priority order on contagions given by the sequence $(1,2,\\dots,K)$ where lower index means higher priority, a seed set $S_k \\subseteq V$ for each contagion $k \\in \\{1,\\dots,K\\}$, and for each contagion $k$ a collection of independent activation probabilities $\\{p_k(u,v)\\}_{(u,v)\\in E}$, where $p_k(u,v) \\in [0,1]$ is the probability that an activation attempt by contagion $k$ along directed edge $(u,v)$ succeeds. All activation events are independent across edges and across contagions.\n\nThe Independent Cascade (IC) process unfolds in discrete time steps as follows: at time $t=0$, each node $v \\in V$ that belongs to at least one seed set is considered active for exactly one contagion, determined by the priority order if needed (that is, if $v \\in S_i \\cap S_j$ with $i \\neq j$, then $v$ is assigned to the contagion with smaller index). At each subsequent integer time $t=1,2,\\dots$, any node that just became active for contagion $k$ at time $t-1$ gets a single chance to activate each of its out-neighbors $w$ that are not yet active for any contagion. An activation attempt of contagion $k$ from $v$ to $w$ along edge $(v,w)$ succeeds with probability $p_k(v,w)$, independently of all other attempts. If, in the same time step, multiple contagions attempt to activate the same node $w$, then the node $w$ becomes active for the contagion with the smallest index among those attempting in that time step. Once a node becomes active for some contagion, it remains active for that contagion and does not change state thereafter.\n\nYour task is to compute, for each of the following test cases, the exact expected number of nodes that end up active for each contagion after the process terminates. The expectation is taken over all sources of randomness specified by the Independent Cascade model. The final values must be computed exactly with respect to the given probabilities, not via Monte Carlo simulation.\n\nFundamental base you may assume: the Independent Cascade model’s definition as above; independence of activation events across edges and contagions; and the well-known equivalence to a live-edge percolation view in which each directed edge $(u,v)$ is independently declared live for contagion $k$ with probability $p_k(u,v)$ and blocked otherwise, and adoption outcomes are determined by reachability in these live-edge subgraphs together with the discrete-time tie-breaking rule as specified.\n\nImplement a program that performs exact enumeration over all live-edge realizations across contagions and computes the expected adoption counts. Use the following test suite.\n\nTest case $1$:\n- Nodes $V=\\{0,1,2\\}$.\n- Directed edges $E=\\{(0,1),(0,2),(2,1)\\}$.\n- Number of contagions $K=2$ with priority order $(1 \\succ 2)$.\n- Seed sets: $S_1=\\{0\\}$, $S_2=\\{2\\}$.\n- Activation probabilities:\n  - For contagion $1$: $p_1(0,1)=0.7$, $p_1(0,2)=0.4$, $p_1(2,1)=0.1$.\n  - For contagion $2$: $p_2(0,1)=0.2$, $p_2(0,2)=0.6$, $p_2(2,1)=0.9$.\n\nTest case $2$:\n- Nodes $V=\\{0,1,2,3\\}$.\n- Directed edges $E=\\{(0,1),(1,2),(0,2),(2,3),(1,3)\\}$.\n- Number of contagions $K=3$ with priority order $(1 \\succ 2 \\succ 3)$.\n- Seed sets: $S_1=\\{0\\}$, $S_2=\\{1\\}$, $S_3=\\{2\\}$.\n- Activation probabilities:\n  - For contagion $1$: $p_1(0,1)=0.9$, $p_1(1,2)=0.0$, $p_1(0,2)=0.5$, $p_1(2,3)=0.6$, $p_1(1,3)=0.7$.\n  - For contagion $2$: $p_2(0,1)=0.0$, $p_2(1,2)=0.8$, $p_2(0,2)=0.0$, $p_2(2,3)=0.6$, $p_2(1,3)=0.4$.\n  - For contagion $3$: $p_3(0,1)=0.0$, $p_3(1,2)=0.0$, $p_3(0,2)=0.0$, $p_3(2,3)=0.9$, $p_3(1,3)=0.0$.\n\nTest case $3$ (edge case):\n- Nodes $V=\\{0,1\\}$.\n- Directed edges $E=\\{(0,1)\\}$.\n- Number of contagions $K=2$ with priority order $(1 \\succ 2)$.\n- Seed sets: $S_1=\\emptyset$, $S_2=\\{0\\}$.\n- Activation probabilities:\n  - For contagion $1$: $p_1(0,1)=0.0$.\n  - For contagion $2$: $p_2(0,1)=1.0$.\n\nOutput requirement:\n- For each test case, compute a list $[\\mathbb{E}[X_1],\\dots,\\mathbb{E}[X_K]]$ where $\\mathbb{E}[X_k]$ is the expected number of nodes finally active for contagion $k$. Each $\\mathbb{E}[X_k]$ must be rounded to exactly $6$ decimal places.\n- Aggregate the results for all test cases in order into a single flat list by concatenation in the order of contagion indices within each test case. That is, produce a single list $[r_{1,1},\\dots,r_{1,K_1},r_{2,1},\\dots,r_{2,K_2},\\dots]$ where $r_{i,k}$ denotes the rounded expected count for contagion $k$ in test case $i$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_{1,1},r_{1,2},r_{2,1}]$). No other text should be printed.\n\nAngle units are not applicable. No physical units are involved. All numerical answers must be reported as decimals rounded to $6$ decimal places as specified.",
            "solution": "The problem asks for the exact expected number of nodes activated by each of several competing contagions spreading on a directed graph. The dynamics follow a competitive Independent Cascade (IC) model with a fixed priority order for tie-breaking. A direct analytical solution is required, not a Monte Carlo simulation.\n\nThe fundamental principle we shall use is the linearity of expectation. The expected number of nodes activated by a contagion $k$, denoted $\\mathbb{E}[X_k]$, is the sum of the probabilities that each node $v$ in the graph is activated by contagion $k$.\n$$\n\\mathbb{E}[X_k] = \\sum_{v \\in V} P(v \\text{ is activated by } k)\n$$\nTherefore, the core of the problem is to compute $P(v \\text{ is activated by } k)$ for every node $v$ and every contagion $k$.\n\nTo compute this probability, we must consider all possible outcomes of the stochastic process. The problem statement provides a crucial hint by mentioning the equivalence of the IC model to a \"live-edge percolation view\". In this framework, for each contagion $k$ and each edge $(u,v) \\in E$, the edge is declared \"live\" for $k$ with probability $p_k(u,v)$ and \"blocked\" otherwise, independently of all other edges and contagions. A specific configuration of all live and blocked edges across all contagions constitutes a single \"possible world\" or realization, $\\omega$. Since all these events are independent, the probability of a specific world $\\omega$ occurring is the product of the probabilities of each individual edge-contagion state:\n$$\nP(\\omega) = \\prod_{k=1}^{K} \\prod_{(u,v) \\in E} P(\\text{state of edge } (u,v) \\text{ for contagion } k \\text{ in } \\omega)\n$$\nwhere $P(\\text{state})$ is $p_k(u,v)$ if the edge is live and $1-p_k(u,v)$ if it is blocked.\n\nThe total expected value can be computed by summing over all possible worlds:\n$$\n\\mathbb{E}[X_k] = \\sum_{\\omega} P(\\omega) \\cdot N_k(\\omega)\n$$\nwhere $N_k(\\omega)$ is the number of nodes activated by contagion $k$ in the specific world $\\omega$. The problem states that we must perform an \"exact enumeration over all live-edge realizations.\" For a graph with $|E|$ edges and $K$ contagions, there are $K \\cdot |E|$ independent binary random events (each edge being live/blocked for each contagion). This results in $2^{K \\cdot |E|}$ distinct possible worlds. For the small graphs provided in the test cases, this number is computationally manageable, allowing for a direct enumeration strategy.\n\nThe algorithm proceeds as follows:\n1.  Initialize the expected counts for each contagion, $\\mathbb{E}[X_k]$, to $0$.\n2.  Iterate through every possible world $\\omega$ from $1$ to $2^{K \\cdot |E|}$.\n3.  For each world $\\omega$:\n    a. Calculate its probability, $P(\\omega)$, by multiplying the probabilities of the corresponding live/blocked edge configurations for each contagion. If $P(\\omega) = 0$, this world contributes nothing and can be skipped.\n    b. Determine the final state of each node for this deterministic world. In a given world, the set of live edges for each contagion is fixed. The outcome is determined by which contagion reaches a node first. The \"time\" to reach a node is the length of the shortest path in the corresponding live-edge graph.\n    c. The detailed procedure for determining node states in world $\\omega$ is:\n        i.   **Initialization ($t=0$):** First, determine the set of initially active nodes. A node $v$ present in one or more seed sets $S_j$ is activated at $t=0$. If it belongs to multiple seed sets, it is assigned to the contagion $k$ with the highest priority (smallest index), i.e., $k = \\min\\{j \\mid v \\in S_j\\}$. Let's denote the set of nodes initially activated by contagion $k$ as $A_k^{(0)}$. These nodes contribute to the count for their respective activating contagions.\n        ii.  **Shortest Path Calculation:** For each contagion $k$, construct its live-edge subgraph $G_k(\\omega)$. Then, compute the shortest path distance, $d_k(v)$, from its initial active set $A_k^{(0)}$ to every other node $v$ in $G_k(\\omega)$. A Breadth-First Search (BFS) is the standard algorithm for this, starting simultaneously from all nodes in $A_k^{(0)}$. If a node $v$ is unreachable, its distance is $d_k(v) = \\infty$. The distance $d_k(v)$ represents the time step at which contagion $k$ first reaches node $v$.\n        iii. **Winner Determination:** For each node $v$ not activated at $t=0$, find its earliest possible activation time, $t_{\\min}(v) = \\min_{k \\in \\{1,\\dots,K\\}} \\{d_k(v)\\}$. If $t_{\\min}(v) = \\infty$, the node is never activated. Otherwise, the node is activated by the contagion $k_{\\text{winner}}$ that has the highest priority among all contagions capable of activating it at $t_{\\min}(v)$. That is, $k_{\\text{winner}} = \\min\\{k \\mid d_k(v) = t_{\\min}(v)\\}$.\n    d.  **Count and Update:** After determining the winning contagion for every node, count the total number of nodes activated by each contagion, $N_k(\\omega)$. Update the total expected counts by adding the contribution from this world: $\\mathbb{E}[X_k] \\mathrel{+}= P(\\omega) \\cdot N_k(\\omega)$.\n4.  After iterating through all possible worlds, the accumulated values are the final exact expected counts. These values are then rounded to $6$ decimal places as required.\n\nThis method provides an exact, deterministic solution by systematically exploring the entire probability space of the diffusion process.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver.\n    \"\"\"\n\n    # Test case 1\n    tc1_nodes = {0, 1, 2}\n    tc1_edges = {(0, 1), (0, 2), (2, 1)}\n    tc1_K = 2\n    tc1_seeds = [{0}, {2}]\n    tc1_probs = [\n        # Probs for Contagion 1\n        {(0, 1): 0.7, (0, 2): 0.4, (2, 1): 0.1},\n        # Probs for Contagion 2\n        {(0, 1): 0.2, (0, 2): 0.6, (2, 1): 0.9}\n    ]\n\n    # Test case 2\n    tc2_nodes = {0, 1, 2, 3}\n    tc2_edges = {(0, 1), (1, 2), (0, 2), (2, 3), (1, 3)}\n    tc2_K = 3\n    tc2_seeds = [{0}, {1}, {2}]\n    tc2_probs = [\n        # Probs for Contagion 1\n        {(0, 1): 0.9, (1, 2): 0.0, (0, 2): 0.5, (2, 3): 0.6, (1, 3): 0.7},\n        # Probs for Contagion 2\n        {(0, 1): 0.0, (1, 2): 0.8, (0, 2): 0.0, (2, 3): 0.6, (1, 3): 0.4},\n        # Probs for Contagion 3\n        {(0, 1): 0.0, (1, 2): 0.0, (0, 2): 0.0, (2, 3): 0.9, (1, 3): 0.0}\n    ]\n\n    # Test case 3\n    tc3_nodes = {0, 1}\n    tc3_edges = {(0, 1)}\n    tc3_K = 2\n    tc3_seeds = [set(), {0}]\n    tc3_probs = [\n        # Probs for Contagion 1\n        {(0, 1): 0.0},\n        # Probs for Contagion 2\n        {(0, 1): 1.0}\n    ]\n\n    test_cases = [\n        (tc1_nodes, tc1_edges, tc1_K, tc1_seeds, tc1_probs),\n        (tc2_nodes, tc2_edges, tc2_K, tc2_seeds, tc2_probs),\n        (tc3_nodes, tc3_edges, tc3_K, tc3_seeds, tc3_probs),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        nodes, edges, K, seed_sets, probabilities = case\n        result = _compute_expectations(nodes, edges, K, seed_sets, probabilities)\n        all_results.extend(result)\n\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef _compute_expectations(nodes, edges, K, seed_sets, probabilities):\n    \"\"\"\n    Computes the exact expected number of active nodes for each contagion.\n    \"\"\"\n    num_nodes = len(nodes)\n    num_edges = len(edges)\n    \n    expected_counts = np.zeros(K)\n    \n    # Use a sorted list of edges for a consistent mapping from bits to edge states.\n    ordered_edges = sorted(list(edges)) \n    \n    num_edge_contagion_pairs = num_edges * K\n    total_worlds = 1  num_edge_contagion_pairs\n\n    for world_id in range(total_worlds):\n        world_prob = 1.0\n        live_graphs = {k: {u: [] for u in nodes} for k in range(1, K + 1)}\n        \n        # 1. Construct the world (live graphs and probability)\n        bit_pos = 0\n        for k in range(1, K + 1):\n            for u, v in ordered_edges:\n                p_live = probabilities[k - 1].get((u, v), 0.0)\n                is_live = (world_id >> bit_pos)  1\n                \n                if is_live:\n                    world_prob *= p_live\n                    live_graphs[k][u].append(v)\n                else:\n                    world_prob *= (1.0 - p_live)\n                bit_pos += 1\n        \n        if world_prob == 0:\n            continue\n\n        # 2. Determine initial active sets at t=0 based on seed sets and priority\n        initial_active_nodes = {}\n        for k in range(1, K + 1):\n            for seed_node in seed_sets[k - 1]:\n                if seed_node not in initial_active_nodes:\n                    initial_active_nodes[seed_node] = k\n        \n        # 3. Compute shortest path distances for each contagion from its initial active set\n        all_distances = {}\n        for k in range(1, K + 1):\n            distances = {node: float('inf') for node in nodes}\n            queue = deque()\n            \n            for node, active_k in initial_active_nodes.items():\n                if active_k == k:\n                    if distances[node] == float('inf'):\n                        distances[node] = 0\n                        queue.append(node)\n            \n            while queue:\n                u = queue.popleft()\n                for v in live_graphs[k].get(u, []):\n                    if distances[v] == float('inf'):\n                        distances[v] = distances[u] + 1\n                        queue.append(v)\n            all_distances[k] = distances\n\n        # 4. Determine final state of each node and count for this world\n        world_counts = np.zeros(K)\n        for node in nodes:\n            # Nodes activated at t=0 (seeds)\n            if node in initial_active_nodes:\n                winner_k = initial_active_nodes[node]\n                world_counts[winner_k - 1] += 1\n                continue\n\n            # For non-seed nodes, find the winning contagion based on minimum time and priority\n            min_dist = float('inf')\n            winner_k = -1\n\n            for k in range(1, K + 1):\n                dist = all_distances[k][node]\n                if dist  min_dist:\n                    min_dist = dist\n                    winner_k = k\n            \n            if winner_k != -1:\n                world_counts[winner_k - 1] += 1\n        \n        # 5. Add this world's weighted contribution to the total expectation\n        expected_counts += world_prob * world_counts\n        \n    return expected_counts\n\nsolve()\n\n```"
        },
        {
            "introduction": "To apply diffusion models in practice, we must first estimate their parameters from observations, which are often incomplete. This final practice addresses this challenge by showing how to infer an unknown activation probability from cascade data where the exact cause of an activation is hidden. You will derive and apply an update step for the Expectation-Maximization (EM) algorithm, a powerful and widely used statistical technique for parameter estimation with latent variables .",
            "id": "4309566",
            "problem": "Consider the Independent Cascade (IC) model on a directed graph with nodes $A$, $B$, and $C$, and directed edges $(A \\rightarrow C)$ and $(B \\rightarrow C)$. In the IC model, each newly activated node gets exactly one chance in the immediately following discrete time step to activate each of its out-neighbors, with independent Bernoulli trials along edges. Let the (unknown) activation probability on edge $(A \\rightarrow C)$ be $p \\in (0,1)$ and the (known) activation probability on edge $(B \\rightarrow C)$ be $q \\in (0,1)$. Suppose that across many cascades, you observe only the activation times of nodes, and you aggregate the data into the following two local configurations at the moment just before any attempts to activate $C$ occur:\n- Type I exposures: only node $A$ is newly active (node $B$ is not newly active), so only $A$ attempts to activate $C$. There are $n_{1}$ such exposures, among which $s_{1}$ result in $C$ becoming active at the next time step.\n- Type II exposures: both $A$ and $B$ are newly active simultaneously, so both attempt to activate $C$ in the next time step. There are $n_{2}$ such exposures, among which $s_{2}$ result in $C$ becoming active at the next time step.\n\nFor Type I exposures, whether $C$ activates is fully informative about the success or failure of $A$'s attempt. For Type II exposures, when $C$ activates, you do not observe which parent’s attempt succeeded (either one or both could have succeeded). Assume all activation attempts are conditionally independent given the edge probabilities and that across cascades these exposure events are independent and identically distributed.\n\nStarting from the IC model definition and the Bernoulli complete-data likelihood for edge $(A \\rightarrow C)$ attempts, and using the principle of Expectation-Maximization (EM) to handle the latent attribution in Type II exposures, derive the one-step M-step update for $p$ from an initial value $p^{(0)}$ by maximizing the expected complete-data log-likelihood. Then, evaluate this update numerically for\n- $n_{1} = 12$, $s_{1} = 5$,\n- $n_{2} = 8$, $s_{2} = 6$,\n- $q = 0.3$,\n- $p^{(0)} = 0.4$.\n\nGive your final numerical answer for $p^{(1)}$ rounded to four significant figures.",
            "solution": "The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. It describes a standard parameter estimation task in the context of the Independent Cascade (IC) model using the Expectation-Maximization (EM) algorithm, a common statistical method for handling latent variables. Therefore, the problem is valid.\n\nThe goal is to estimate the activation probability $p$ for the edge $(A \\rightarrow C)$. We are given two types of observations.\n-   Type I: $n_{1}$ instances where only node $A$ attempts to activate $C$. The number of successful activations is $s_{1}$. These trials directly inform $p$.\n-   Type II: $n_{2}$ instances where both nodes $A$ and $B$ attempt to activate $C$. The number of successful activations of $C$ is $s_{2}$. In these cases, the cause of activation is not observed (it could be $A$, $B$, or both), which introduces a latent variable.\n\nWe use the EM algorithm to find the maximum likelihood estimate for $p$. This iterative algorithm consists of an Expectation (E) step and a Maximization (M) step.\n\nFirst, we define the \"complete data\". The complete data would specify the outcome (success or failure) of every individual activation attempt. For the edge $(A \\rightarrow C)$, there are a total of $n_{1} + n_{2}$ activation attempts. Let us denote the number of successes and failures from $A$ in Type I exposures as $S_{A,1}$ and $F_{A,1}$, and in Type II exposures as $S_{A,2}$ and $F_{A,2}$.\nFrom the problem statement, for Type I exposures, the outcomes are fully observed:\n$S_{A,1} = s_{1}$\n$F_{A,1} = n_{1} - s_{1}$\n\nFor Type II exposures, the outcomes of individual attempts from $A$ are not observed. They are latent variables. The total number of successes from $A$ over all exposures is $S_{A, \\text{total}} = S_{A,1} + S_{A,2} = s_{1} + S_{A,2}$. The total number of failures is $F_{A, \\text{total}} = F_{A,1} + F_{A,2} = (n_{1} - s_{1}) + F_{A,2}$.\n\nThe complete-data log-likelihood for parameter $p$, given the outcomes of all $n_{1} + n_{2}$ attempts from $A$, is that of a Bernoulli process:\n$$ \\mathcal{L}_c(p; S_{A, \\text{total}}, F_{A, \\text{total}}) = \\log \\left( p^{S_{A, \\text{total}}} (1-p)^{F_{A, \\text{total}}} \\right) $$\n$$ \\mathcal{L}_c(p) = (s_{1} + S_{A,2}) \\log(p) + (n_{1} - s_{1} + F_{A,2}) \\log(1-p) $$\nSince $S_{A,2}$ and $F_{A,2}$ are unobserved, we proceed with the EM algorithm.\n\n**E-Step: Expectation**\n\nIn the E-step, we compute the expectation of the complete-data log-likelihood with respect to the posterior distribution of the latent variables, given the observed data and the current estimate of the parameter, $p^{(t)}$. This function is denoted as $Q(p|p^{(t)})$.\n$$ Q(p|p^{(t)}) = E \\left[ \\mathcal{L}_c(p) \\mid \\text{observed data}, p^{(t)} \\right] $$\n$$ Q(p|p^{(t)}) = \\left(s_{1} + E[S_{A,2}]\\right) \\log(p) + \\left(n_{1} - s_{1} + E[F_{A,2}]\\right) \\log(1-p) $$\nThe expectation is conditioned on the observed data ($n_{1}, s_{1}, n_{2}, s_{2}$) and the current parameters ($p^{(t)}, q$). We need to compute $E[S_{A,2}]$ and $E[F_{A,2}]$.\n\nThe $n_{2}$ Type II exposures are divided into two observable outcomes:\n1.  $s_{2}$ cases where node $C$ becomes active.\n2.  $n_{2} - s_{2}$ cases where node $C$ does not become active.\n\nIn the $n_{2} - s_{2}$ cases where $C$ is not activated, it must be that both attempts from $A$ and $B$ failed. Thus, for these cases, the number of successes from $A$ is exactly $0$.\n\nIn the $s_{2}$ cases where $C$ is activated, at least one of the attempts from $A$ or $B$ was successful. The probability of this event, given $p^{(t)}$ and $q$, is $P(C \\text{ active}) = 1 - P(C \\text{ not active}) = 1 - P(A \\text{ fails AND } B \\text{ fails})$. By independence, this is $1 - (1-p^{(t)})(1-q)$.\n\nWe need the expected number of successes from $A$ in one such trial, which is the conditional probability of $A$ succeeding given that $C$ was activated.\n$$ P(A \\text{ succeeds} | C \\text{ active}) = \\frac{P(A \\text{ succeeds AND } C \\text{ active})}{P(C \\text{ active})} $$\nThe event \"$A$ succeeds\" is a subset of the event \"$C$ active\" in this context (since if $A$ succeeds, $C$ definitely activates), so the numerator is simply $P(A \\text{ succeeds}) = p^{(t)}$.\n$$ P(A \\text{ succeeds} | C \\text{ active}) = \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\nThe expected number of successes from $A$ across the $s_{2}$ successful Type II exposures is this probability multiplied by $s_{2}$. Combining with the $n_2-s_2$ failure cases, the total expected number of successes from $A$ in Type II exposures is:\n$$ E[S_{A,2}] = (n_{2}-s_{2}) \\times 0 + s_{2} \\times \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} = s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\nThe total number of attempts from $A$ in Type II exposures is $n_{2}$. The expected number of failures is $E[F_{A,2}] = n_{2} - E[S_{A,2}]$.\n\nThe total expected number of successes for edge $(A \\rightarrow C)$ across all trials is:\n$$ E[S_{A, \\text{total}}] = s_{1} + E[S_{A,2}] = s_{1} + s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\n\n**M-Step: Maximization**\n\nIn the M-step, we find the value of $p$ that maximizes $Q(p|p^{(t)})$. The function $Q$ has the form of a log-likelihood for a Bernoulli random variable with $E[S_{A, \\text{total}}]$ expected successes and $E[F_{A, \\text{total}}]$ expected failures out of a total of $n_{1} + n_{2}$ trials.\nDifferentiating $Q(p|p^{(t)})$ with respect to $p$ and setting to zero gives the standard maximum likelihood estimator:\n$$ p^{(t+1)} = \\frac{\\text{Expected number of successes}}{\\text{Total number of trials}} $$\n$$ p^{(t+1)} = \\frac{E[S_{A, \\text{total}}]}{n_{1} + n_{2}} $$\nSubstituting the expression for $E[S_{A, \\text{total}}]$ gives the M-step update rule:\n$$ p^{(t+1)} = \\frac{1}{n_{1} + n_{2}} \\left( s_{1} + s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} \\right) $$\n\n**Numerical Evaluation**\n\nWe are asked to compute $p^{(1)}$ starting from $p^{(0)}$. The given values are:\n$n_{1} = 12$\n$s_{1} = 5$\n$n_{2} = 8$\n$s_{2} = 6$\n$q = 0.3$\n$p^{(0)} = 0.4$\n\nWe substitute these values into the update equation for $t=0$:\n$$ p^{(1)} = \\frac{1}{12 + 8} \\left( 5 + 6 \\times \\frac{0.4}{1 - (1-0.4)(1-0.3)} \\right) $$\nFirst, we compute the denominator of the inner fraction:\n$$ 1 - (1 - 0.4)(1 - 0.3) = 1 - (0.6)(0.7) = 1 - 0.42 = 0.58 $$\nNow substitute this back into the equation for $p^{(1)}$:\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + 6 \\times \\frac{0.4}{0.58} \\right) $$\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + \\frac{2.4}{0.58} \\right) $$\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + \\frac{240}{58} \\right) = \\frac{1}{20} \\left( 5 + \\frac{120}{29} \\right) $$\nTo combine the terms in the parenthesis, we find a common denominator:\n$$ 5 + \\frac{120}{29} = \\frac{5 \\times 29}{29} + \\frac{120}{29} = \\frac{145 + 120}{29} = \\frac{265}{29} $$\nFinally, we compute $p^{(1)}$:\n$$ p^{(1)} = \\frac{1}{20} \\times \\frac{265}{29} = \\frac{265}{580} $$\nTo simplify the fraction, we can divide the numerator and denominator by $5$:\n$$ p^{(1)} = \\frac{53}{116} $$\nNow we convert this fraction to a decimal value and round to four significant figures:\n$$ p^{(1)} = \\frac{53}{116} \\approx 0.45689655... $$\nRounding to four significant figures, we get $0.4569$.",
            "answer": "$$\\boxed{0.4569}$$"
        }
    ]
}