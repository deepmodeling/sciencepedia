{
    "hands_on_practices": [
        {
            "introduction": "To understand how cooperation can persist in a structured population, we must first analyze the dynamics at the most critical location: the boundary between cooperators and defectors. This exercise focuses on calculating the \"invasion fitness\" of a cooperator at this interface. By working through this calculation, you will derive a fundamental result that quantifies the probability of cooperation spreading into a hostile territory, revealing how this depends on the cost of cooperation and the network's connectivity. ",
            "id": "4274998",
            "problem": "Consider the Prisoner’s Dilemma (PD) in its donation-game parameterization on an infinite, $k$-regular spatial network, where each player interacts pairwise with all $k$ neighbors. In each pairwise interaction, a cooperator pays a cost $c>0$ to confer a benefit $b>c$ to the partner, while a defector pays no cost and confers no benefit. Thus, for any single interaction, the payoffs to the row player are: mutual cooperation yields $R=b-c$, unilateral cooperation against defection yields $S=-c$, unilateral defection against cooperation yields $T=b$, and mutual defection yields $P=0$. The total payoff to a player is the sum of its pairwise payoffs over all $k$ neighbors.\n\nFocus on a straight interface between a semi-infinite defective domain and its complementary cooperative domain. Consider an adjacent pair of boundary nodes, one defector and one cooperator, lying on opposite sides of the interface such that both have exactly $m$ cooperative neighbors and $k-m$ defective neighbors (with $1 \\leq m \\leq k-1$) by regularity of the interface. Strategy updating is asynchronous and follows the Fermi pairwise comparison rule with intensity parameter $\\beta=1$: when the boundary defector compares itself to the boundary cooperator across their shared edge, the defector adopts cooperation with a probability that depends on their payoff difference.\n\nDefine the invasion fitness $\\phi$ of the boundary cooperator as the conditional probability that the boundary defector adopts cooperation in the described comparison event. Compute $\\phi$ as a closed-form expression in terms of $k$ and $c$ only. Express your final answer as a single analytical expression; no rounding is required.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and self-contained. It describes a canonical model from evolutionary game theory on networks. The premises are clear, and the required task is a direct application of the stated principles. The crucial condition that both the boundary cooperator and defector have an identical number of cooperative neighbors, $m$, is a specific theoretical simplification that is not inherently contradictory and leads to a well-defined calculation. The problem is therefore deemed valid and a solution can be derived.\n\nThe problem describes the Prisoner's Dilemma in the donation-game formulation. In a single pairwise interaction, a cooperator pays a cost $c>0$ to provide a benefit $b>c$ to its partner. A defector pays nothing and provides nothing. The payoffs for the row player are given by the matrix:\n$$\n\\begin{pmatrix}\nR & S \\\\\nT & P\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb-c & -c \\\\\nb & 0\n\\end{pmatrix}\n$$\nwhere $R$ is the payoff for mutual cooperation, $S$ for cooperating with a defector, $T$ for defecting against a cooperator, and $P$ for mutual defection. The total payoff for a player on the $k$-regular network is the sum of a player's payoffs from interacting with its $k$ neighbors.\n\nWe are asked to consider a focal cooperator, let's denote it by $C^*$, and an adjacent focal defector, $D^*$. According to the problem statement, both players are situated at the boundary between cooperative and defective domains and have identical neighborhood compositions: each has exactly $m$ cooperative neighbors and $k-m$ defective neighbors, where $1 \\leq m \\leq k-1$.\n\nLet us calculate the total payoff, $\\Pi_C$, for the focal cooperator $C^*$. This player has $m$ neighbors who are cooperators and $k-m$ neighbors who are defectors. The total payoff is the sum of payoffs from these interactions:\n$$\n\\Pi_C = m \\cdot R + (k-m) \\cdot S\n$$\nSubstituting the expressions for $R$ and $S$:\n$$\n\\Pi_C = m(b-c) + (k-m)(-c) = mb - mc - kc + mc\n$$\n$$\n\\Pi_C = mb - kc\n$$\nNext, we calculate the total payoff, $\\Pi_D$, for the focal defector $D^*$. This player also has $m$ cooperative neighbors and $k-m$ defective neighbors. The total payoff is the sum of payoffs from these interactions:\n$$\n\\Pi_D = m \\cdot T + (k-m) \\cdot P\n$$\nSubstituting the expressions for $T$ and $P$:\n$$\n\\Pi_D = m(b) + (k-m)(0)\n$$\n$$\n\\Pi_D = mb\n$$\nThe problem states that strategy updating follows the Fermi pairwise comparison rule. The invasion fitness, $\\phi$, is defined as the conditional probability that the defector $D^*$ adopts the cooperator's strategy when comparing itself with $C^*$. The general form of the Fermi rule for a player $i$ adopting the strategy of a neighbor $j$ is:\n$$\nP(i \\to j) = \\frac{1}{1 + \\exp(-\\beta(\\Pi_j - \\Pi_i))}\n$$\nIn our case, player $i$ is the defector $D^*$, and player $j$ is the cooperator $C^*$. The intensity of selection is given as $\\beta = 1$. Therefore, the probability $\\phi$ is:\n$$\n\\phi = \\frac{1}{1 + \\exp(-1 \\cdot (\\Pi_C - \\Pi_D))} = \\frac{1}{1 + \\exp(-(\\Pi_C - \\Pi_D))}\n$$\nTo compute $\\phi$, we must first find the payoff difference $\\Pi_C - \\Pi_D$:\n$$\n\\Pi_C - \\Pi_D = (mb - kc) - (mb) = -kc\n$$\nSubstituting this difference into the expression for $\\phi$:\n$$\n\\phi = \\frac{1}{1 + \\exp(-(-kc))}\n$$\n$$\n\\phi = \\frac{1}{1 + \\exp(kc)}\n$$\nThis expression for $\\phi$ is in terms of $k$ and $c$ only, as required by the problem statement. The parameters $b$ and $m$ cancel out due to the symmetric neighborhood assumption for the two focal players.",
            "answer": "$$\n\\boxed{\\frac{1}{1 + \\exp(kc)}}\n$$"
        },
        {
            "introduction": "While detailed simulations are powerful, analytical approximations offer general insights into how system-wide behavior depends on parameters. The simplest, mean-field theory, often fails in spatial games because it ignores local correlations. This practice introduces Pair Approximation (PA), a more refined technique that accounts for the fact that neighbors' strategies are not independent. By comparing the PA prediction to the mean-field one, you will gain hands-on experience with a key theoretical tool and see quantitatively how spatial structure can alter the predicted level of cooperation in a population. ",
            "id": "4274916",
            "problem": "Consider a large population structured as a Regular Random Graph (RRG) of degree $k$, in which each node plays a two-strategy, two-player Snowdrift (also called Hawk-Dove) game against each of its neighbors. Let the benefit of cooperation be $b>0$ and the cost of cooperation be $c>0$, with payoff matrix entries defined by the standard Snowdrift parameterization: mutual cooperation yields payoff $R=b-\\frac{c}{2}$ to each cooperator, one-sided cooperation yields payoff $S=b-c$ to the cooperator and $T=b$ to the defector, and mutual defection yields $P=0$ to each. Strategy updating follows pairwise comparison (imitation) under weak selection, where adoption probabilities are monotone in the payoff difference.\n\nUse as a fundamental base the following widely accepted facts:\n- In the well-mixed (Mean Field, MF) limit for two-strategy games under replicator dynamics, an interior steady state $x_{\\mathrm{MF}}$ for the cooperator density $x$ is determined by the equality of expected payoffs of cooperators and defectors, namely $R x + S (1-x) = T x + P (1-x)$.\n- On $k$-regular graphs under weak selection with pairwise comparison (imitation), pair approximation (PA) yields an effective replicator equation on graphs equivalent to the MF replicator with a transformed payoff matrix $\\mathbf{A}'=\\mathbf{A}+\\frac{1}{k}\\left(\\mathbf{A}-\\mathbf{A}^{\\top}\\right)$, where $\\mathbf{A}=\\begin{pmatrix}R & S \\\\ T & P\\end{pmatrix}$ and ${}^{\\top}$ denotes transpose. The interior steady state $x_{\\mathrm{PA}}$ is determined by equality of expected payoffs computed with $\\mathbf{A}'$.\n\nFor a specific graph degree and parameterization, let $k=4$, $b=1$, and $c=0.6$. Derive the MF prediction $x_{\\mathrm{MF}}$ and the PA prediction $x_{\\mathrm{PA}}$, and compute the numerical difference $\\Delta=x_{\\mathrm{PA}}-x_{\\mathrm{MF}}$. Express $\\Delta$ as a unitless decimal and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the difference between the cooperator frequency predicted by Pair Approximation (PA) on a regular random graph and the frequency predicted by Mean-Field (MF) theory for a Snowdrift game. The problem is well-defined and its premises are consistent with standard models in evolutionary game theory.\n\nFirst, we define the payoff matrix $\\mathbf{A}=\\begin{pmatrix} R & S \\\\ T & P \\end{pmatrix}$ using the given parameters $b=1$ and $c=0.6$.\nThe payoff entries are:\n$R = b - \\frac{c}{2} = 1 - \\frac{0.6}{2} = 1 - 0.3 = 0.7$\n$S = b - c = 1 - 0.6 = 0.4$\n$T = b = 1$\n$P = 0$\nThus, the payoff matrix is $\\mathbf{A} = \\begin{pmatrix} 0.7 & 0.4 \\\\ 1 & 0 \\end{pmatrix}$.\nThe condition for a stable mixed strategy equilibrium in the Snowdrift game is $T > R > S > P$, which corresponds to $1 > 0.7 > 0.4 > 0$. This condition is satisfied.\n\nNext, we calculate the Mean-Field (MF) prediction for the cooperator frequency, $x_{\\mathrm{MF}}$. The interior steady state is found where the expected payoff of a cooperator, $E_C$, equals that of a defector, $E_D$. Let $x$ be the frequency of cooperators.\n$$E_C = x R + (1-x) S$$\n$$E_D = x T + (1-x) P$$\nSetting $E_C = E_D$ at $x=x_{\\mathrm{MF}}$:\n$$x_{\\mathrm{MF}} R + (1-x_{\\mathrm{MF}}) S = x_{\\mathrm{MF}} T + (1-x_{\\mathrm{MF}}) P$$\nSolving for $x_{\\mathrm{MF}}$ gives the general formula:\n$$x_{\\mathrm{MF}} = \\frac{P-S}{R-S-T+P}$$\nSubstituting the numerical payoff values:\n$$x_{\\mathrm{MF}} = \\frac{0 - 0.4}{0.7 - 0.4 - 1 + 0} = \\frac{-0.4}{-0.7} = \\frac{4}{7}$$\n\nNow, we calculate the Pair Approximation (PA) prediction, $x_{\\mathrm{PA}}$. According to the problem statement, this is determined by an effective payoff matrix $\\mathbf{A}' = \\mathbf{A} + \\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top})$, with graph degree $k=4$.\nFirst, we find $\\mathbf{A}-\\mathbf{A}^{\\top}$:\n$$\\mathbf{A} - \\mathbf{A}^{\\top} = \\begin{pmatrix} 0.7 & 0.4 \\\\ 1 & 0 \\end{pmatrix} - \\begin{pmatrix} 0.7 & 1 \\\\ 0.4 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -0.6 \\\\ 0.6 & 0 \\end{pmatrix}$$\nThen we compute the correction term for $k=4$:\n$$\\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top}) = \\frac{1}{4} \\begin{pmatrix} 0 & -0.6 \\\\ 0.6 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -0.15 \\\\ 0.15 & 0 \\end{pmatrix}$$\nThe effective payoff matrix $\\mathbf{A}'$ is:\n$$\\mathbf{A}' = \\mathbf{A} + \\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top}) = \\begin{pmatrix} 0.7 & 0.4 \\\\ 1 & 0 \\end{pmatrix} + \\begin{pmatrix} 0 & -0.15 \\\\ 0.15 & 0 \\end{pmatrix} = \\begin{pmatrix} 0.7 & 0.25 \\\\ 1.15 & 0 \\end{pmatrix}$$\nLet the entries of this new matrix be $\\mathbf{A}'=\\begin{pmatrix} R' & S' \\\\ T' & P' \\end{pmatrix}$. So, $R'=0.7$, $S'=0.25$, $T'=1.15$, and $P'=0$.\nThe PA steady state $x_{\\mathrm{PA}}$ is found using the same equilibrium condition form, but with the effective payoffs:\n$$x_{\\mathrm{PA}} = \\frac{P'-S'}{R'-S'-T'+P'}$$\nSubstituting the new payoff values:\n$$x_{\\mathrm{PA}} = \\frac{0 - 0.25}{0.7 - 0.25 - 1.15 + 0} = \\frac{-0.25}{0.45 - 1.15} = \\frac{-0.25}{-0.7} = \\frac{25}{70} = \\frac{5}{14}$$\n\nFinally, we compute the difference $\\Delta = x_{\\mathrm{PA}} - x_{\\mathrm{MF}}$.\n$$\\Delta = \\frac{5}{14} - \\frac{4}{7} = \\frac{5}{14} - \\frac{8}{14} = -\\frac{3}{14}$$\nTo provide the numerical answer, we convert this fraction to a decimal:\n$$\\Delta = -\\frac{3}{14} \\approx -0.2142857...$$\nRounding to four significant figures, we get:\n$$\\Delta \\approx -0.2143$$\nThis negative value indicates that for the Snowdrift game under pairwise comparison updating, the spatial structure captured by pair approximation leads to a lower frequency of cooperators compared to the well-mixed population.",
            "answer": "$$\\boxed{-0.2143}$$"
        },
        {
            "introduction": "Moving from analytical models to direct agent-based simulations requires making choices about how to implement the dynamics. This computational exercise explores one of the most critical and subtle implementation details: the update scheme. By building and comparing simulations with synchronous and asynchronous updates, you will discover firsthand how the timing of strategy adoption can dramatically alter the evolutionary trajectory and the final level of cooperation in the system. ",
            "id": "4274870",
            "problem": "You are asked to design and implement a controlled computational experiment comparing two update schemes—synchronous and asynchronous—for the evolution of cooperation in spatial games on a two-dimensional lattice. The fundamental base consists of the definition of the Prisoner’s Dilemma (PD) and local imitation dynamics in spatial evolutionary game theory. The Prisoner’s Dilemma (PD) is defined by a two-strategy interaction between cooperation $C$ and defection $D$ with payoffs given by the matrix entries $R$ (reward for mutual cooperation), $S$ (sucker’s payoff for cooperating against a defector), $T$ (temptation to defect against a cooperator), and $P$ (punishment for mutual defection), constrained by $T > R > P > S$.\n\nYou will consider a square lattice of size $L \\times L$ with periodic boundary conditions (a torus). Each site $i$ holds a strategy $s_i \\in \\{0,1\\}$, where $1$ denotes cooperation and $0$ denotes defection. Interactions are limited to the von Neumann neighborhood: for a focal site at coordinates $(r,c)$, its neighbors are $(r-1 \\bmod L, c)$, $(r+1 \\bmod L, c)$, $(r, c-1 \\bmod L)$, and $(r, c+1 \\bmod L)$.\n\nThe total payoff $\\pi_i$ to site $i$ is the sum of pairwise payoffs with its four neighbors. The pairwise payoff that site $i$ receives from interacting with neighbor $j$ is\n$$\n\\text{pay}(s_i, s_j) = s_i s_j R + s_i (1 - s_j) S + (1 - s_i) s_j T + (1 - s_i) (1 - s_j) P,\n$$\nand the total payoff for site $i$ is\n$$\n\\pi_i = \\sum_{j \\in \\mathcal{N}(i)} \\text{pay}(s_i, s_j),\n$$\nwhere $\\mathcal{N}(i)$ denotes the set of four neighbors of $i$.\n\nTwo update schemes must be compared under identical initial conditions and parameters:\n\n- Synchronous update: At discrete time $t$, compute $\\pi_i(t)$ for all sites using the current configuration $s(t)$. Then, simultaneously for all sites $i$, update $s_i(t+1)$ by imitating the strategy of the candidate in $\\{i\\} \\cup \\mathcal{N}(i)$ that has the maximal payoff at time $t$. Ties must be broken deterministically by the ordered list of candidates $[i, \\text{up}, \\text{down}, \\text{left}, \\text{right}]$, choosing the earliest in this list among those with maximal payoff.\n\n- Asynchronous update: At discrete time $t$, iterate sites in deterministic row-major order: $(0,0), (0,1), \\dots, (0,L-1), (1,0), \\dots, (L-1,L-1)$. For each focal site $i$, compute the current payoffs $\\pi_k(t)$ for $k \\in \\{i\\} \\cup \\mathcal{N}(i)$ using the present configuration just before updating $i$. Then immediately update $s_i$ by imitating the strategy of the candidate with maximal payoff; ties must be broken using the same deterministic list $[i, \\text{up}, \\text{down}, \\text{left}, \\text{right}]$. Proceed to the next site using the updated configuration. One asynchronous time step completes after all sites have been processed once.\n\nInitial conditions: The initial configuration $s(0)$ is generated by independently setting each site to cooperation ($1$) with probability $f_0$ and defection ($0$) otherwise. Use the specified pseudorandom number generator seeds to ensure identical initial conditions across both update schemes within each test case.\n\nYour task is to implement a program that, for each specified test case, runs both update schemes for a given number of time steps $N_{steps}$, and outputs the absolute difference in the final fraction of cooperators between the synchronous and the asynchronous dynamics:\n$$\n\\Delta = \\left| \\frac{1}{L^2} \\sum_{i=1}^{L^2} s_i^{\\text{sync}}(N_{steps}) - \\frac{1}{L^2} \\sum_{i=1}^{L^2} s_i^{\\text{async}}(N_{steps}) \\right|.\n$$\n\nDesign constraints:\n- All computations must be performed on the lattice with von Neumann neighborhoods and periodic boundary conditions.\n- Imitation is strictly of the single candidate with maximal payoff; no stochastic tie-breaking is permitted.\n- The initial condition must be identical for synchronous and asynchronous runs within each test case, determined by the given seed and $f_0$.\n\nTest suite:\nImplement the following four test cases, each defined by the tuple $(L, N_{steps}, R, S, T, P, f_0, \\text{seed})$:\n1. $(20, 100, 1.0, 0.0, 1.4, 0.0, 0.5, 12345)$: a moderate temptation to defect with balanced initial mix; expected nontrivial dynamics.\n2. $(20, 0, 1.0, 0.0, 1.4, 0.0, 0.5, 54321)$: zero update steps; the difference $\\Delta$ must equal $0$.\n3. $(20, 200, 1.0, 0.0, 1.8, 0.0, 0.8, 98765)$: strong temptation to defect with high initial cooperation; expected erosion of cooperation.\n4. $(25, 150, 1.0, 0.0, 1.1, 0.0, 0.5, 24680)$: weak temptation to defect; expected persistence of cooperative clusters.\n\nOutput specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, where each entry is the value of $\\Delta$ for the corresponding test case (e.g., $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$). Each $\\Delta$ must be a floating-point number.",
            "solution": "The user-provided problem is a well-defined computational experiment in the field of spatial evolutionary game theory. It asks for a comparison of two update schemes, synchronous and asynchronous, for the Prisoner's Dilemma on a two-dimensional lattice. The problem is scientifically grounded, self-contained, and algorithmically specified with sufficient precision for a unique, verifiable solution. All parameters, boundary conditions, update rules, and tie-breaking mechanisms are explicitly defined. Therefore, the problem is deemed valid and a solution is provided below.\n\n### I. Model Formulation and Payoff Structure\n\nThe model is defined on an $L \\times L$ square lattice with periodic boundary conditions, forming a torus topology. Each site $i$ on the lattice is occupied by an agent with a strategy $s_i \\in \\{0, 1\\}$, where $s_i=1$ represents cooperation ($C$) and $s_i=0$ represents defection ($D$). Agents interact with their four immediate neighbors as defined by the von Neumann neighborhood, $\\mathcal{N}(i)$.\n\nThe interaction is governed by the Prisoner's Dilemma, with payoffs for a focal agent given by $R$ for mutual cooperation, $S$ for cooperating while the opponent defects (sucker's payoff), $T$ for defecting while the opponent cooperates (temptation), and $P$ for mutual defection. The defining inequality for the Prisoner's Dilemma is $T > R > P > S$.\n\nThe total payoff $\\pi_i$ for an agent at site $i$ is the sum of payoffs from interactions with its four neighbors:\n$$\n\\pi_i = \\sum_{j \\in \\mathcal{N}(i)} \\text{pay}(s_i, s_j)\n$$\nwhere the pairwise payoff function is defined as:\n$$\n\\text{pay}(s_i, s_j) = s_i s_j R + s_i (1 - s_j) S + (1 - s_i) s_j T + (1 - s_i) (1 - s_j) P\n$$\nThis can be simplified. Let $k_i$ be the number of cooperating neighbors of site $i$. The number of defecting neighbors is then $4 - k_i$.\n- If agent $i$ is a cooperator ($s_i=1$), its total payoff is $\\pi_i = k_i R + (4 - k_i) S$.\n- If agent $i$ is a defector ($s_i=0$), its total payoff is $\\pi_i = k_i T + (4 - k_i) P$.\n\nThis formulation is key to an efficient implementation, as it allows for the calculation of all payoffs across the lattice by first computing a grid of neighbor cooperator counts, $k_i$. This can be achieved through vectorized operations, for instance by shifting the strategy grid in all four directions and summing the results.\n\n### II. Initial Conditions\n\nFor each test case, the simulation begins from an initial strategy configuration $s(0)$ determined by a probability $f_0$ and a specific pseudorandom number generator seed. Each site is independently assigned the cooperation strategy ($s_i=1$) with probability $f_0$. Utilizing a fixed seed ensures that the initial configuration is identical for both the synchronous and asynchronous runs within a given test case, which is a critical requirement for a fair comparison.\n\n### III. Dynamic Update Schemes\n\nThe evolution of strategies is simulated for a total of $N_{steps}$ time steps. At each step, agents update their strategies by imitating the most successful agent in their local environment, which includes the agent itself and its four von Neumann neighbors. The \"most successful\" agent is the one with the highest total payoff. Ties are broken deterministically by selecting the first agent in the ordered list: [self, up, down, left, right].\n\n#### A. Synchronous Update\n\nIn the synchronous scheme, all strategy updates are based on the system's state at the beginning of the time step, $s(t)$, and are applied simultaneously to produce the state at the next time step, $s(t+1)$.\n\nThe algorithm for a single synchronous time step is as follows:\n1.  **Compute Payoffs**: A payoff grid, $\\Pi(t)$, containing $\\pi_i(t)$ for every site $i$, is calculated based on the strategy grid $s(t)$. This is done efficiently using the vectorized approach described in Section I.\n2.  **Identify Winners**: For each site $i$, the payoffs of the five candidates (site $i$ and its four neighbors) are collected from the grid $\\Pi(t)$. The candidate with the maximum payoff is identified. The deterministic tie-breaking rule is applied by checking the candidates in the specified order.\n3.  **Update Strategies**: A new strategy grid, $s(t+1)$, is constructed. For each site $i$, its new strategy, $s_i(t+1)$, is set to the strategy of its winning candidate from step 2, i.e., $s_{\\text{winner}}(t)$.\n4.  **Apply Update**: The entire `current` grid is replaced by the `next` grid.\n\nThis entire process can be heavily vectorized using `numpy`. Payoffs of candidates for all sites can be gathered by rolling the complete payoff grid. The tie-breaking rule is naturally implemented by `numpy.argmax`, which returns the index of the first maximum element found.\n\n#### B. Asynchronous Update\n\nIn the asynchronous scheme, sites are processed sequentially in a deterministic, row-major order. Each update is applied immediately, altering the state of the grid that subsequent agents in the sequence will face within the same time step.\n\nThe algorithm for a single asynchronous time step is as follows:\n1.  **Iterate Sequentially**: The algorithm iterates through each site $i=(r, c)$ from $(0,0)$ to $(L-1, L-1)$.\n2.  **Compute Local Payoffs**: For the current focal site $i$, the payoffs for itself and its four neighbors must be calculated *on-the-fly*. This is because the strategies of neighbors may have already been updated in the current time step. A pre-computed payoff grid from the start of the step cannot be used.\n3.  **Identify Winner and Update**: The winning candidate is determined using the maximum payoff and tie-breaking rule, identical to the synchronous case. The strategy of the focal site, $s_i$, is then *immediately* updated to match the winner's strategy.\n4.  **Proceed**: The algorithm proceeds to the next site in the row-major sequence, which will now \"see\" the updated strategy at site $i$.\n\nOne full time step is completed after all $L^2$ sites have been updated once. This scheme cannot be fully vectorized due to its sequential and state-dependent nature, necessitating an explicit loop over all sites.\n\n### IV. Final Output Calculation\n\nAfter $N_{steps}$ time steps, the final configurations for both simulations, $s^{\\text{sync}}(N_{steps})$ and $s^{\\text{async}}(N_{steps})$, are obtained. The final fraction of cooperators for each scheme is calculated as the mean of the strategy values in the final grid. The output is the absolute difference between these two fractions:\n$$\n\\Delta = \\left| \\frac{1}{L^2} \\sum_{i} s_i^{\\text{sync}}(N_{steps}) - \\frac{1}{L^2} \\sum_{i} s_i^{\\text{async}}(N_{steps}) \\right|\n$$\nThis metric quantifies the divergence in macroscopic outcomes resulting solely from the difference in the update timing protocol.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef create_initial_grid(L, f0, seed):\n    \"\"\"\n    Generates the initial L x L grid of strategies.\n    1 for cooperator, 0 for defector.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    random_grid = rng.random((L, L))\n    # A site is a cooperator (1) if its random value is less than f0.\n    initial_grid = (random_grid  f0).astype(int)\n    return initial_grid\n\ndef calculate_total_payoffs_vectorized(grid, L, R, S, T_pay, P):\n    \"\"\"\n    Calculates total payoffs for all sites on the grid using vectorized operations.\n    \"\"\"\n    # Count cooperating neighbors for each site using periodic boundary conditions.\n    neighbor_coop_count = (\n        np.roll(grid, 1, axis=0) +\n        np.roll(grid, -1, axis=0) +\n        np.roll(grid, 1, axis=1) +\n        np.roll(grid, -1, axis=1)\n    )\n\n    # Payoff for cooperators if they were at a given site: k*R + (4-k)*S\n    payoff_if_C = neighbor_coop_count * R + (4 - neighbor_coop_count) * S\n    # Payoff for defectors if they were at a given site: k*T + (4-k)*P\n    payoff_if_D = neighbor_coop_count * T_pay + (4 - neighbor_coop_count) * P\n\n    # Assign payoffs based on the actual strategy of the site.\n    total_payoffs = np.where(grid == 1, payoff_if_C, payoff_if_D)\n    return total_payoffs\n\ndef run_synchronous(grid_initial, n_steps, L, R, S, T_pay, P):\n    \"\"\"\n    Runs the simulation with synchronous updates for n_steps.\n    \"\"\"\n    if n_steps == 0:\n        return grid_initial.copy()\n\n    current_grid = grid_initial.copy()\n    I, J = np.ogrid[:L, :L]\n\n    for _ in range(n_steps):\n        # 1. Compute all payoffs based on the grid state at the start of the step.\n        payoffs = calculate_total_payoffs_vectorized(current_grid, L, R, S, T_pay, P)\n\n        # 2. Gather payoffs of all candidates (self, up, down, left, right) for each site.\n        candidate_payoffs = np.stack([\n            payoffs,\n            np.roll(payoffs, 1, axis=0),   # Up\n            np.roll(payoffs, -1, axis=0),  # Down\n            np.roll(payoffs, 1, axis=1),   # Left\n            np.roll(payoffs, -1, axis=1)   # Right\n        ], axis=-1)\n\n        # 3. Np.argmax finds the index of the first occurrence of the max value,\n        # which correctly implements the deterministic tie-breaking rule.\n        winner_indices = np.argmax(candidate_payoffs, axis=-1)\n\n        # 4. Gather the strategies of the corresponding candidates.\n        candidate_strategies = np.stack([\n            current_grid,\n            np.roll(current_grid, 1, axis=0),\n            np.roll(current_grid, -1, axis=0),\n            np.roll(current_grid, 1, axis=1),\n            np.roll(current_grid, -1, axis=1)\n        ], axis=-1)\n\n        # 5. Build the next grid by selecting the winner's strategy for each site.\n        next_grid = candidate_strategies[I, J, winner_indices]\n        current_grid = next_grid\n\n    return current_grid\n\ndef run_asynchronous(grid_initial, n_steps, L, R, S, T_pay, P):\n    \"\"\"\n    Runs the simulation with asynchronous updates for n_steps.\n    \"\"\"\n    if n_steps == 0:\n        return grid_initial.copy()\n\n    grid = grid_initial.copy()\n\n    def get_payoff_at(r, c, current_grid):\n        s_focal = current_grid[r, c]\n        r_up, r_down = (r - 1 + L) % L, (r + 1) % L\n        c_left, c_right = (c - 1 + L) % L, (c + 1) % L\n\n        k = (current_grid[r_up, c] + current_grid[r_down, c] +\n             current_grid[r, c_left] + current_grid[r, c_right])\n\n        if s_focal == 1:  # Cooperator\n            return k * R + (4 - k) * S\n        else:  # Defector\n            return k * T_pay + (4 - k) * P\n\n    for _ in range(n_steps):\n        for r in range(L):\n            for c in range(L):\n                r_up, r_down = (r - 1 + L) % L, (r + 1) % L\n                c_left, c_right = (c - 1 + L) % L, (c + 1) % L\n\n                candidate_coords = [\n                    (r, c), (r_up, c), (r_down, c), (r, c_left), (r, c_right)\n                ]\n\n                # Payoffs are computed on-the-fly using the changing grid state.\n                payoffs = [get_payoff_at(cr, cc, grid) for cr, cc in candidate_coords]\n                max_payoff = max(payoffs)\n\n                # Find the first candidate with max payoff to handle ties.\n                winner_index = payoffs.index(max_payoff)\n                winner_coords = candidate_coords[winner_index]\n\n                # Update the focal site's strategy immediately.\n                grid[r, c] = grid[winner_coords]\n\n    return grid\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs simulations, and prints the formatted output.\n    \"\"\"\n    test_cases = [\n        # (L, N_steps, R, S, T, P, f0, seed)\n        (20, 100, 1.0, 0.0, 1.4, 0.0, 0.5, 12345),\n        (20, 0, 1.0, 0.0, 1.4, 0.0, 0.5, 54321),\n        (20, 200, 1.0, 0.0, 1.8, 0.0, 0.8, 98765),\n        (25, 150, 1.0, 0.0, 1.1, 0.0, 0.5, 24680),\n    ]\n\n    results = []\n    for L, T_steps, R, S, T_pay, P, f0, seed in test_cases:\n        initial_grid = create_initial_grid(L, f0, seed)\n\n        final_grid_sync = run_synchronous(initial_grid, T_steps, L, R, S, T_pay, P)\n        final_grid_async = run_asynchronous(initial_grid, T_steps, L, R, S, T_pay, P)\n\n        f_coop_sync = np.mean(final_grid_sync)\n        f_coop_async = np.mean(final_grid_async)\n\n        delta = abs(f_coop_sync - f_coop_async)\n        results.append(delta)\n\n    # The final print statement must produce only the specified output format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}