{
    "hands_on_practices": [
        {
            "introduction": "Before attempting to find a game's equilibrium, a crucial first step is to simplify the strategic landscape. The principle of dominance allows us to do just that: a rational player will never choose a strategy that is consistently outperformed by another, regardless of what their opponents do. This exercise  provides hands-on practice with the powerful technique of Iterated Elimination of Strictly Dominated Strategies (IESDS), a process that can systematically reduce the complexity of a game and, in some cases, reveal a clear solution.",
            "id": "4278059",
            "problem": "Consider a two-player normal-form game that models a single-stage interaction between two nodes in a networked system. The Row player, denoted by $\\mathcal{R}$, has pure strategies $\\{R_{1}, R_{2}, R_{3}\\}$, and the Column player, denoted by $\\mathcal{C}$, has pure strategies $\\{C_{1}, C_{2}, C_{3}\\}$. Let $u_{\\mathcal{R}}$ and $u_{\\mathcal{C}}$ denote the payoffs to $\\mathcal{R}$ and $\\mathcal{C}$, respectively. The game is specified by payoff matrices\n$$A \\;=\\; \\begin{pmatrix}\n0 & 0 & 0 \\\\\n2 & 4 & 1 \\\\\n3 & 3 & 2\n\\end{pmatrix}, \\qquad\nB \\;=\\; \\begin{pmatrix}\n1 & 0 & 2 \\\\\n0 & 2 & 3 \\\\\n1 & 1 & 2\n\\end{pmatrix},$$\nwhere $A_{ij} \\;=\\; u_{\\mathcal{R}}(R_{i}, C_{j})$ and $B_{ij} \\;=\\; u_{\\mathcal{C}}(R_{i}, C_{j})$.\n\nStarting from the foundational definitions of dominance in game theory, do the following:\n\n- Formulate the explicit inequality conditions that define strict dominance of a pure strategy by another pure strategy for a player, and similarly formulate the explicit inequality conditions that define weak dominance. Your inequalities must be stated in full generality in terms of $u_{i}$, a player’s two strategies $s_{i}^{\\prime}$ and $s_{i}$, and the opponent’s strategy $s_{-i}$.\n\n- Apply Iterated Elimination of Strictly Dominated Strategies (IESDS) to the $3 \\times 3$ game given by $A$ and $B$. At each elimination step, justify the elimination by writing the corresponding explicit payoff inequalities across the opponent’s current strategy set. Continue until no further strictly dominated strategies remain.\n\nFinally, report a single number equal to $u_{\\mathcal{R}}(R^{\\star}, C^{\\star})$, the Row player’s payoff at the unique pure-strategy profile $(R^{\\star}, C^{\\star})$ that survives IESDS. The answer must be a single real number. No rounding is required.",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed problem in elementary game theory, with all necessary components defined clearly and without contradiction.\n\nThe first task is to provide the general definitions for strict and weak dominance of pure strategies. Let $i$ be a player, $S_i$ be the set of pure strategies available to player $i$, and $S_{-i}$ be the set of all possible pure strategy profiles of player $i$'s opponents. Let $s_i$ and $s_i'$ be two distinct strategies in $S_i$, and let $s_{-i}$ be a strategy profile in $S_{-i}$. The payoff to player $i$ is denoted by $u_i(s_i, s_{-i})$.\n\nA strategy $s_i' \\in S_i$ is **strictly dominated** by a strategy $s_i \\in S_i$ if for every strategy profile of the opponents $s_{-i} \\in S_{-i}$, playing $s_i$ yields a strictly higher payoff to player $i$ than playing $s_i'$. The condition is formulated as the following inequality:\n$$u_i(s_i, s_{-i}) > u_i(s_i', s_{-i}) \\quad \\forall s_{-i} \\in S_{-i}$$\n\nA strategy $s_i' \\in S_i$ is **weakly dominated** by a strategy $s_i \\in S_i$ if for every strategy profile of the opponents $s_{-i} \\in S_{-i}$, playing $s_i$ yields a payoff at least as high as playing $s_i'$, and for at least one opponent strategy profile $s_{-i}^* \\in S_{-i}$, playing $s_i$ yields a strictly higher payoff. The conditions are formulated as the following pair of inequalities:\n$$u_i(s_i, s_{-i}) \\ge u_i(s_i', s_{-i}) \\quad \\forall s_{-i} \\in S_{-i}$$\n$$\\exists s_{-i}^* \\in S_{-i} \\text{ such that } u_i(s_i, s_{-i}^*) > u_i(s_i', s_{-i}^*)$$\n\nThe second task is to apply the Iterated Elimination of Strictly Dominated Strategies (IESDS) to the given game. The game is defined by the payoff matrices for the Row player ($\\mathcal{R}$) and the Column player ($\\mathcal{C}$):\n$$A \\;=\\; \\begin{pmatrix}\n0 & 0 & 0 \\\\\n2 & 4 & 1 \\\\\n3 & 3 & 2\n\\end{pmatrix}, \\qquad\nB \\;=\\; \\begin{pmatrix}\n1 & 0 & 2 \\\\\n0 & 2 & 3 \\\\\n1 & 1 & 2\n\\end{pmatrix}$$\nThe combined payoff matrix is:\n$$\n\\begin{array}{c|ccc}\n\\mathcal{R} \\backslash \\mathcal{C} & C_1 & C_2 & C_3 \\\\\n\\hline\nR_1 & (0, 1) & (0, 0) & (0, 2) \\\\\nR_2 & (2, 0) & (4, 2) & (1, 3) \\\\\nR_3 & (3, 1) & (3, 1) & (2, 2)\n\\end{array}\n$$\n\n**Step 1: Analyzing Player $\\mathcal{R}$'s Strategies**\n\nWe compare the payoffs for player $\\mathcal{R}$ (the first number in each pair) row by row. The opponent's strategies are $\\{C_1, C_2, C_3\\}$.\nComparing $R_1$ with $R_2$:\n- $u_{\\mathcal{R}}(R_2, C_1) = 2 > 0 = u_{\\mathcal{R}}(R_1, C_1)$\n- $u_{\\mathcal{R}}(R_2, C_2) = 4 > 0 = u_{\\mathcal{R}}(R_1, C_2)$\n- $u_{\\mathcal{R}}(R_2, C_3) = 1 > 0 = u_{\\mathcal{R}}(R_1, C_3)$\nSince $u_{\\mathcal{R}}(R_2, C_j) > u_{\\mathcal{R}}(R_1, C_j)$ for all $j \\in \\{1, 2, 3\\}$, the strategy $R_1$ is strictly dominated by $R_2$.\nSimilarly, comparing $R_1$ with $R_3$:\n- $u_{\\mathcal{R}}(R_3, C_1) = 3 > 0 = u_{\\mathcal{R}}(R_1, C_1)$\n- $u_{\\mathcal{R}}(R_3, C_2) = 3 > 0 = u_{\\mathcal{R}}(R_1, C_2)$\n- $u_{\\mathcal{R}}(R_3, C_3) = 2 > 0 = u_{\\mathcal{R}}(R_1, C_3)$\nStrategy $R_1$ is also strictly dominated by $R_3$.\nComparing $R_2$ with $R_3$: $u_{\\mathcal{R}}(R_2, C_2)=4 > 3=u_{\\mathcal{R}}(R_3, C_2)$ but $u_{\\mathcal{R}}(R_3, C_1)=3 > 2=u_{\\mathcal{R}}(R_2, C_1)$. Neither strictly dominates the other.\nWe eliminate the strictly dominated strategy $R_1$. The game is reduced to:\n$$\n\\begin{array}{c|ccc}\n\\mathcal{R} \\backslash \\mathcal{C} & C_1 & C_2 & C_3 \\\\\n\\hline\nR_2 & (2, 0) & (4, 2) & (1, 3) \\\\\nR_3 & (3, 1) & (3, 1) & (2, 2)\n\\end{array}\n$$\nThe remaining strategies are $S_{\\mathcal{R}}' = \\{R_2, R_3\\}$ and $S_{\\mathcal{C}}' = \\{C_1, C_2, C_3\\}$.\n\n**Step 2: Analyzing Player $\\mathcal{C}$'s Strategies in the Reduced Game**\n\nWe now compare the payoffs for player $\\mathcal{C}$ (the second number in each pair) column by column. The opponent $\\mathcal{R}$'s strategies are now restricted to $\\{R_2, R_3\\}$.\nComparing $C_1$ with $C_3$:\n- $u_{\\mathcal{C}}(R_2, C_3) = 3 > 0 = u_{\\mathcal{C}}(R_2, C_1)$\n- $u_{\\mathcal{C}}(R_3, C_3) = 2 > 1 = u_{\\mathcal{C}}(R_3, C_1)$\nSince $u_{\\mathcal{C}}(R_i, C_3) > u_{\\mathcal{C}}(R_i, C_1)$ for all $R_i \\in \\{R_2, R_3\\}$, the strategy $C_1$ is strictly dominated by $C_3$ in the reduced game.\n\nComparing $C_2$ with $C_3$:\n- $u_{\\mathcal{C}}(R_2, C_3) = 3 > 2 = u_{\\mathcal{C}}(R_2, C_2)$\n- $u_{\\mathcal{C}}(R_3, C_3) = 2 > 1 = u_{\\mathcal{C}}(R_3, C_2)$\nSince $u_{\\mathcal{C}}(R_i, C_3) > u_{\\mathcal{C}}(R_i, C_2)$ for all $R_i \\in \\{R_2, R_3\\}$, the strategy $C_2$ is also strictly dominated by $C_3$ in the reduced game.\n\nWe eliminate the strictly dominated strategies $C_1$ and $C_2$. The game is further reduced to:\n$$\n\\begin{array}{c|c}\n\\mathcal{R} \\backslash \\mathcal{C} & C_3 \\\\\n\\hline\nR_2 & (1, 3) \\\\\nR_3 & (2, 2)\n\\end{array}\n$$\nThe remaining strategies are $S_{\\mathcal{R}}'' = \\{R_2, R_3\\}$ and $S_{\\mathcal{C}}'' = \\{C_3\\}$.\n\n**Step 3: Analyzing Player $\\mathcal{R}$'s Strategies in the New Reduced Game**\n\nWe analyze player $\\mathcal{R}$'s remaining strategies given that player $\\mathcal{C}$ has only one strategy, $C_3$.\nComparing $R_2$ with $R_3$:\n- $u_{\\mathcal{R}}(R_3, C_3) = 2 > 1 = u_{\\mathcal{R}}(R_2, C_3)$\nFor the opponent's entire remaining strategy set $\\{C_3\\}$, $R_3$ yields a strictly higher payoff than $R_2$. Therefore, $R_2$ is strictly dominated by $R_3$.\n\nWe eliminate the strictly dominated strategy $R_2$. This leaves $R_3$ as the only strategy for player $\\mathcal{R}$ and $C_3$ as the only strategy for player $\\mathcal{C}$.\n\nThe unique pure-strategy profile that survives the process of Iterated Elimination of Strictly Dominated Strategies is $(R^{\\star}, C^{\\star}) = (R_3, C_3)$.\n\nFinally, we must report the Row player's payoff at this profile, $u_{\\mathcal{R}}(R^{\\star}, C^{\\star})$. From the original payoff matrix $A$, this corresponds to the element $A_{33}$.\n$$u_{\\mathcal{R}}(R_3, C_3) = A_{33} = 2$$\nThe required value is $2$.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Many strategic interactions lack a stable outcome in pure strategies, leading to endless cycles of best responses. In these cases, stability is found by introducing unpredictability through mixed strategies, where players randomize their actions according to specific probabilities. This practice  challenges you to derive a mixed-strategy Nash Equilibrium from first principles, using the core concept of player indifference, and to explore how this equilibrium behaves within a networked system.",
            "id": "4278052",
            "problem": "Consider a strictly competitive two-player interaction embedded on an undirected, regular network in which each node has degree $d \\in \\mathbb{N}$. On every edge, the incident players simultaneously play a two-action stage game with action set $\\{H, T\\}$. Let Player $1$ (row) have payoff matrix\n$$\n\\begin{pmatrix}\n\\alpha & -\\beta \\\\\n-\\gamma & \\delta\n\\end{pmatrix},\n$$\nwhere $\\alpha, \\beta, \\gamma, \\delta \\in \\mathbb{R}_{>0}$, with rows indexed by Player $1$'s actions $H, T$ and columns indexed by Player $2$'s actions $H, T$. Player $2$ (column) receives the negative of Player $1$'s payoff for each outcome, so the stage game is zero-sum. Each player commits to a single mixed strategy that is played simultaneously against all neighbors; aggregate payoff for each player is the sum of payoffs obtained on its incident edges. \n\nLet $\\sigma_{1} = (p, 1-p)$ denote Player $1$'s mixed strategy over $(H, T)$ and $\\sigma_{2} = (q, 1-q)$ denote Player $2$'s mixed strategy over $(H, T)$. Assume that the network is large enough that strategic interactions are well-approximated by independent random matching along edges and that both players' equilibrium supports are $\\{H, T\\}$.\n\nUsing only the definitions of expected payoff and Nash equilibrium (NE), derive the unique fully mixed-strategy Nash equilibrium $(\\sigma_{1}^{\\ast}, \\sigma_{2}^{\\ast})$ as a closed-form expression in terms of $\\alpha, \\beta, \\gamma, \\delta$ and $d$. Express your final answer as a row matrix containing the two equilibrium probabilities $(p^{\\ast}, q^{\\ast})$ in simplest form. No rounding is required and no units are involved.",
            "solution": "The problem asks for the unique fully mixed-strategy Nash equilibrium (NE) of a two-player, zero-sum game played on the edges of a regular network.\n\nFirst, we must validate the problem statement.\nThe givens are:\n- A two-player, zero-sum stage game with action set $\\{H, T\\}$ for both players.\n- Player 1's payoff matrix: $A = \\begin{pmatrix} \\alpha & -\\beta \\\\ -\\gamma & \\delta \\end{pmatrix}$, where $\\alpha, \\beta, \\gamma, \\delta \\in \\mathbb{R}_{>0}$.\n- Player 2's payoff matrix is $-A$.\n- The game is embedded on an undirected, regular network where each node has degree $d$.\n- Each player (node) commits to a single mixed strategy, played simultaneously against all $d$ neighbors.\n- Player 1's strategy is $\\sigma_1 = (p, 1-p)$ for actions $(H, T)$.\n- Player 2's strategy is $\\sigma_2 = (q, 1-q)$ for actions $(H, T)$.\n- Aggregate payoff is the sum of payoffs from all incident edges.\n- The equilibrium support for both players is $\\{H, T\\}$, implying a fully mixed strategy where $p \\in (0, 1)$ and $q \\in (0, 1)$.\n\nThe problem is scientifically grounded in game theory and its application to networks. It is well-posed, objective, and internally consistent. The structure implies a bipartite network where players of Type 1 (row players) are only connected to players of Type 2 (column players), which is a valid configuration for a regular network (e.g., a cycle graph with an even number of nodes). The core of the problem is to determine if the network structure, specifically the degree $d$, influences the strategic choice of the players.\n\nLet us analyze the payoff structure. Consider a player of Type 1. This player engages in $d$ identical games, one with each of their neighbors, who are all of Type 2. The player must use the same mixed strategy $\\sigma_1 = (p, 1-p)$ in all $d$ games. The neighbors are all assumed to play the same strategy $\\sigma_2 = (q, 1-q)$.\n\nThe expected payoff for Player 1 in a single stage game against Player 2 is given by:\n$$E_1(\\sigma_1, \\sigma_2) = \\sigma_1 A \\sigma_2^T = \\begin{pmatrix} p & 1-p \\end{pmatrix} \\begin{pmatrix} \\alpha & -\\beta \\\\ -\\gamma & \\delta \\end{pmatrix} \\begin{pmatrix} q \\\\ 1-q \\end{pmatrix}$$\nThe aggregate payoff for this Player 1 is the sum of payoffs from the $d$ games. Since each game is identical from a strategic point of view, the aggregate expected payoff $U_1(p, q)$ is simply $d$ times the expected payoff from a single game:\n$$U_1(p, q) = d \\cdot E_1(\\sigma_1, \\sigma_2)$$\nA similar expression holds for Player 2, $U_2(p, q) = d \\cdot E_2(\\sigma_1, \\sigma_2) = -U_1(p, q)$.\n\nWe are seeking a fully mixed-strategy Nash Equilibrium $(\\sigma_1^*, \\sigma_2^*)$, where $p^* \\in (0, 1)$ and $q^* \\in (0, 1)$. A necessary condition for a player to use a mixed strategy is that they must be indifferent between the pure strategies in their support.\n\nFor Player 1 to be indifferent between playing $H$ and $T$, their expected payoff from either choice must be the same, given Player 2 plays their equilibrium strategy $\\sigma_2^* = (q^*, 1-q^*)$. The total expected payoff for Player 1 playing pure strategy $H$ across all $d$ games is $d$ times the expected payoff of playing $H$ in a single game.\nLet $E_1(H, \\sigma_2^*)$ be the expected payoff for Player 1 playing $H$ against $\\sigma_2^*$:\n$$E_1(H, \\sigma_2^*) = \\alpha q^* - \\beta(1-q^*)$$\nLet $E_1(T, \\sigma_2^*)$ be the expected payoff for Player 1 playing $T$ against $\\sigma_2^*$:\n$$E_1(T, \\sigma_2^*) = -\\gamma q^* + \\delta(1-q^*)$$\nThe indifference condition for Player 1 is that the aggregate payoffs are equal: $d \\cdot E_1(H, \\sigma_2^*) = d \\cdot E_1(T, \\sigma_2^*)$. The degree $d$ is a positive integer, so it cancels from the equation, leaving:\n$$E_1(H, \\sigma_2^*) = E_1(T, \\sigma_2^*)$$\n$$\\alpha q^* - \\beta(1-q^*) = -\\gamma q^* + \\delta(1-q^*)$$\n$$\\alpha q^* - \\beta + \\beta q^* = -\\gamma q^* + \\delta - \\delta q^*$$\n$$q^*(\\alpha + \\beta + \\gamma + \\delta) = \\beta + \\delta$$\n$$q^* = \\frac{\\beta + \\delta}{\\alpha + \\beta + \\gamma + \\delta}$$\nThis shows that the equilibrium strategy of Player 2, $q^*$, does not depend on the network degree $d$.\n\nNext, we apply the same logic for Player 2. For Player 2 to be indifferent between playing $H$ and $T$, their expected payoff from either choice must be the same, given Player 1 plays their equilibrium strategy $\\sigma_1^* = (p^*, 1-p^*)$. Player 2's payoff matrix is $-A$.\nLet $E_2(\\sigma_1^*, H)$ be the expected payoff for Player 2 playing $H$ against $\\sigma_1^*$:\n$$E_2(\\sigma_1^*, H) = -\\alpha p^* + \\gamma(1-p^*)$$\nLet $E_2(\\sigma_1^*, T)$ be the expected payoff for Player 2 playing $T$ against $\\sigma_1^*$:\n$$E_2(\\sigma_1^*, T) = \\beta p^* - \\delta(1-p^*)$$\nThe indifference condition for Player 2, after cancellation of the degree $d$, is:\n$$E_2(\\sigma_1^*, H) = E_2(\\sigma_1^*, T)$$\n$$-\\alpha p^* + \\gamma(1-p^*) = \\beta p^* - \\delta(1-p^*)$$\n$$-\\alpha p^* + \\gamma - \\gamma p^* = \\beta p^* - \\delta + \\delta p^*$$\n$$\\gamma + \\delta = p^*(\\alpha + \\beta + \\gamma + \\delta)$$\n$$p^* = \\frac{\\gamma + \\delta}{\\alpha + \\beta + \\gamma + \\delta}$$\nThe equilibrium strategy for Player 1, $p^*$, is also independent of the network degree $d$.\n\nThe problem's constraints are $\\alpha, \\beta, \\gamma, \\delta \\in \\mathbb{R}_{>0}$. This ensures that the denominators $(\\alpha + \\beta + \\gamma + \\delta)$ are strictly positive. The numerators $(\\beta + \\delta)$ and $(\\gamma + \\delta)$ are also strictly positive. Furthermore, it is clear that $0 < p^* < 1$ and $0 < q^* < 1$, which is consistent with the initial assumption of a fully mixed-strategy equilibrium.\n\nThe unique fully mixed-strategy Nash equilibrium is $(\\sigma_1^*, \\sigma_2^*)$ where $\\sigma_1^* = (p^*, 1-p^*)$ and $\\sigma_2^* = (q^*, 1-q^*)$. The equilibrium probabilities are:\n$$p^* = \\frac{\\gamma + \\delta}{\\alpha + \\beta + \\gamma + \\delta}$$\n$$q^* = \\frac{\\beta + \\delta}{\\alpha + \\beta + \\gamma + \\delta}$$\nThe network degree $d$ is irrelevant for determining the equilibrium strategies because it acts as a simple scaling factor on the total payoff, which does not alter the players' strategic considerations under the indifference principle.\nThe final answer is the row matrix $(p^*, q^*)$.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{\\gamma + \\delta}{\\alpha + \\beta + \\gamma + \\delta} & \\frac{\\beta + \\delta}{\\alpha + \\beta + \\gamma + \\delta} \\end{pmatrix} } $$"
        },
        {
            "introduction": "The payoffs in a game are not merely arbitrary numbers; they represent a player's utility or preference for different outcomes. The mathematical form of a player's utility function encodes their attitude towards risk, a factor that can fundamentally alter strategic decisions. This final exercise  moves beyond simple payoff maximization to demonstrate how a player's risk preference—specifically, the difference between a risk-neutral and a risk-averse perspective—changes their best response in a lottery over outcomes, providing a deeper understanding of the behavioral assumptions underpinning game theory.",
            "id": "4278064",
            "problem": "Consider a one-shot, two-player, $2 \\times 2$ normal-form game that models a bilateral interaction embedded in a large networked population. Focus on Player $1$’s decision problem against a single neighbor, where Player $1$ chooses between actions $A$ and $B$, and the neighbor (Player $2$) chooses between actions $L$ and $R$. Player $1$’s realized payoff from the bilateral interaction (before any transformation) is given by the following mapping of pure action profiles to real numbers: $(A,L) \\mapsto 9$, $(A,R) \\mapsto 1$, $(B,L) \\mapsto 4$, $(B,R) \\mapsto 4$. Player $2$’s payoffs are unspecified and irrelevant for this question.\n\nAssume Player $2$ plays a mixed strategy that chooses $L$ with probability $p \\in [0,1]$ and $R$ with probability $1-p$. Player $1$ evaluates lotteries over pure-action payoffs using the following two alternative evaluation rules:\n\n- Baseline rule (scale $u$): maximize expected payoff $\\mathbb{E}[u]$, where $u$ denotes the entries above.\n- Transformed rule (scale $f \\circ u$): first apply the strictly increasing but nonlinear transformation $f(x) = \\sqrt{x}$ to each realized payoff and then maximize $\\mathbb{E}[f(u)]$.\n\nLet $p^{\\star}$ denote the indifference probability under the baseline rule such that Player $1$ is indifferent between $A$ and $B$, and let $\\tilde{p}$ denote the corresponding indifference probability under the transformed rule. These cutoffs determine best responses in mixed environments and, in turn, can alter equilibrium predictions in networked populations when mixed strategies arise endogenously.\n\nTasks:\n\n1. Using only fundamental definitions of expected utility and best response, compute $p^{\\star}$ and $\\tilde{p}$.\n2. Provide a concrete counterexample value $p \\in (0,1)$ for which the baseline best response differs from the transformed best response, and briefly justify why the difference arises in terms of the curvature induced by $f$.\n3. Report the scalar quantity $\\Delta = \\tilde{p} - p^{\\star}$ exactly (no rounding).\n\nAnswer specification: Your final answer must be the exact value of $\\Delta$ as a single real number with no units. Do not round.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective. The problem statement provides a complete description of a one-shot, two-player game with specified actions and payoffs for Player $1$. Player $2$ plays a mixed strategy with a given probability parameter $p$. Two different utility evaluation rules for Player $1$ are defined: one based on raw payoffs and another based on a nonlinear transformation of those payoffs. The tasks are to compute the indifference probabilities under each rule, find a counterexample where best responses differ, and calculate the difference between the indifference probabilities. The problem uses standard concepts from game theory and decision theory (expected utility, mixed strategies, risk aversion via utility functions) and is mathematically well-defined. All necessary data are provided, and there are no contradictions. Therefore, the problem is deemed valid and a solution can be constructed.\n\nThe solution proceeds by addressing the three tasks in order.\n\n### Task 1: Computation of $p^{\\star}$ and $\\tilde{p}$\n\nPlayer $1$ chooses between action $A$ and action $B$. Player $2$ chooses action $L$ with probability $p$ and action $R$ with probability $1-p$.\n\n**1. Baseline Rule and Indifference Probability $p^{\\star}$**\n\nUnder the baseline rule, Player $1$ aims to maximize the expected payoff, $\\mathbb{E}[u]$. The payoffs $u$ are given as $u(A,L) = 9$, $u(A,R) = 1$, $u(B,L) = 4$, and $u(B,R) = 4$.\n\nThe expected payoff for Player $1$ when choosing action $A$ is:\n$$ \\mathbb{E}[u|A] = p \\cdot u(A,L) + (1-p) \\cdot u(A,R) $$\n$$ \\mathbb{E}[u|A] = p \\cdot 9 + (1-p) \\cdot 1 = 9p + 1 - p = 8p + 1 $$\n\nThe expected payoff for Player $1$ when choosing action $B$ is:\n$$ \\mathbb{E}[u|B] = p \\cdot u(B,L) + (1-p) \\cdot u(B,R) $$\n$$ \\mathbb{E}[u|B] = p \\cdot 4 + (1-p) \\cdot 4 = 4p + 4 - 4p = 4 $$\n\nThe indifference probability $p^{\\star}$ is the value of $p$ for which Player $1$ is indifferent between actions $A$ and $B$. This occurs when their expected payoffs are equal:\n$$ \\mathbb{E}[u|A] = \\mathbb{E}[u|B] $$\n$$ 8p^{\\star} + 1 = 4 $$\n$$ 8p^{\\star} = 3 $$\n$$ p^{\\star} = \\frac{3}{8} $$\n\n**2. Transformed Rule and Indifference Probability $\\tilde{p}$**\n\nUnder the transformed rule, Player $1$ first applies the function $f(x) = \\sqrt{x}$ to the payoffs and then maximizes the expected value of the transformed payoffs, $\\mathbb{E}[f(u)]$.\n\nThe transformed payoffs are:\n- $f(u(A,L)) = \\sqrt{9} = 3$\n- $f(u(A,R)) = \\sqrt{1} = 1$\n- $f(u(B,L)) = \\sqrt{4} = 2$\n- $f(u(B,R)) = \\sqrt{4} = 2$\n\nThe expected transformed payoff for Player $1$ when choosing action $A$ is:\n$$ \\mathbb{E}[f(u)|A] = p \\cdot f(u(A,L)) + (1-p) \\cdot f(u(A,R)) $$\n$$ \\mathbb{E}[f(u)|A] = p \\cdot 3 + (1-p) \\cdot 1 = 3p + 1 - p = 2p + 1 $$\n\nThe expected transformed payoff for Player $1$ when choosing action $B$ is:\n$$ \\mathbb{E}[f(u)|B] = p \\cdot f(u(B,L)) + (1-p) \\cdot f(u(B,R)) $$\n$$ \\mathbb{E}[f(u)|B] = p \\cdot 2 + (1-p) \\cdot 2 = 2p + 2 - 2p = 2 $$\n\nThe indifference probability $\\tilde{p}$ is the value of $p$ for which the expected transformed payoffs are equal:\n$$ \\mathbb{E}[f(u)|A] = \\mathbb{E}[f(u)|B] $$\n$$ 2\\tilde{p} + 1 = 2 $$\n$$ 2\\tilde{p} = 1 $$\n$$ \\tilde{p} = \\frac{1}{2} $$\n\n### Task 2: Counterexample and Justification\n\nWe need to find a value of $p \\in (0,1)$ where the best response under the baseline rule differs from the best response under the transformed rule.\n\nFrom the calculations above, the best responses are:\n- **Baseline Rule:**\n  - If $8p+1 > 4$ (i.e., $p > \\frac{3}{8}$), the best response is $A$.\n  - If $8p+1 < 4$ (i.e., $p < \\frac{3}{8}$), the best response is $B$.\n- **Transformed Rule:**\n  - If $2p+1 > 2$ (i.e., $p > \\frac{1}{2}$), the best response is $A$.\n  - If $2p+1 < 2$ (i.e., $p < \\frac{1}{2}$), the best response is $B$.\n\nWe have $p^{\\star} = \\frac{3}{8} = 0.375$ and $\\tilde{p} = \\frac{1}{2} = 0.5$. Any value of $p$ in the interval $(\\frac{3}{8}, \\frac{1}{2})$ will serve as a counterexample. Let's choose $p = \\frac{2}{5} = 0.4$.\n\nFor $p = \\frac{2}{5}$:\n- Under the baseline rule, since $p = \\frac{2}{5} > \\frac{3}{8}$ (because $\\frac{16}{40} > \\frac{15}{40}$), the best response is $A$. We can verify this: $\\mathbb{E}[u|A] = 8(\\frac{2}{5}) + 1 = \\frac{16}{5} + 1 = \\frac{21}{5} = 4.2$, while $\\mathbb{E}[u|B] = 4$. Since $4.2 > 4$, the best response is $A$.\n- Under the transformed rule, since $p = \\frac{2}{5} < \\frac{1}{2}$ (because $\\frac{4}{10} < \\frac{5}{10}$), the best response is $B$. We can verify this: $\\mathbb{E}[f(u)|A] = 2(\\frac{2}{5}) + 1 = \\frac{4}{5} + 1 = \\frac{9}{5} = 1.8$, while $\\mathbb{E}[f(u)|B] = 2$. Since $1.8 < 2$, the best response is $B$.\n\nThus, for $p=\\frac{2}{5}$, the best responses differ.\n\n**Justification:** The difference arises due to the curvature of the utility transformation function $f(x) = \\sqrt{x}$. The second derivative is $f''(x) = -\\frac{1}{4}x^{-3/2}$, which is strictly negative for all $x > 0$. A function with a negative second derivative is strictly concave. In decision theory, a concave utility function represents risk aversion.\n\n- Action $B$ yields a certain payoff of $4$.\n- Action $A$ is a lottery (a risky choice) between a high payoff of $9$ and a low payoff of $1$.\n\nA risk-neutral player (baseline rule) evaluates a lottery by its expected value. A risk-averse player (transformed rule) penalizes risk. The concave function $f(x)$ exhibits diminishing marginal utility; the increase in utility from $4$ to $9$ (which is $f(9)-f(4) = 3-2 = 1$) is smaller than the decrease in utility from $4$ to $1$ (which is $f(4)-f(1)=2-1=1$, but over a smaller payoff interval). More simply, the transformation 'compresses' higher payoffs more than lower payoffs. For the risk-averse player, the 'pain' of the potential low outcome $1$ weighs more heavily relative to the 'gain' of the potential high outcome $9$, making the risky action $A$ less appealing than it is to the risk-neutral player. Consequently, a higher probability $p$ on the favorable outcome $L$ is required to make this risk-averse player indifferent between the risky action $A$ and the safe action $B$. This is why $\\tilde{p} > p^{\\star}$.\n\n### Task 3: Calculation of $\\Delta$\n\nThe scalar quantity $\\Delta$ is the difference between the indifference probabilities.\n$$ \\Delta = \\tilde{p} - p^{\\star} $$\nUsing the values computed in Task 1:\n$$ \\Delta = \\frac{1}{2} - \\frac{3}{8} $$\n$$ \\Delta = \\frac{4}{8} - \\frac{3}{8} $$\n$$ \\Delta = \\frac{1}{8} $$\nAs a decimal, this is $0.125$. The problem requests an exact value, so $\\frac{1}{8}$ is the appropriate form.",
            "answer": "$$\\boxed{\\frac{1}{8}}$$"
        }
    ]
}