{
    "hands_on_practices": [
        {
            "introduction": "无尺度网络的增长通常遵循“富者愈富”的原则，即优先连接机制。本练习提供了一个动手实践的机会，通过计算一个小型增长网络中的连接概率来观察这一原则的实际作用。通过追踪网络在两个连续步骤中的演化，您将对驱动巴拉巴西-阿尔伯特（Barabási-Albert）模型的核心动态过程建立起具体的认识。",
            "id": "1464920",
            "problem": "许多复杂网络（例如蛋白质-蛋白质相互作用（PPI）网络）的生长过程，可以通过“优先连接”机制来建模，著名的 Barabási-Albert 模型就抓住了这一特点。在这个模型中，新节点被添加到现有网络中，并且更倾向于与已经具有大量连接（高度数）的节点形成连接。\n\n考虑一个小型、发展中的PPI网络。最初，该网络由三个蛋白质P1、P2和P3组成的种子构成。相互作用关系为P1仅与P2连接，P3也仅与P2连接，形成一个线性链P1-P2-P3。\n\n现在，两个新蛋白质P4和P5被引入系统，并*依次*整合到网络中。首先加入P4，然后将P5加入到生成的网络中。每个新蛋白质与已存在的一个蛋白质恰好形成一个相互作用（$m=1$）。新蛋白质与现有蛋白质 $i$ 连接的概率与该蛋白质的度 $k_i$（即其已有的相互作用数量）成正比。这个概率可以表示为 $P_i = \\frac{k_i}{\\sum_j k_j}$，其中求和项遍历了当前网络中所有的蛋白质 $j$。\n\n计算在P4和P5都加入网络后，蛋白质P2的最终度数为4的确切概率。请将答案表示为分数。",
            "solution": "最初网络为链P1–P2–P3，其度分别为 $k_{1}=1$，$k_{2}=2$，$k_{3}=1$。总度数为 $\\sum_{j}k_{j}=4$。在 $m=1$ 的优先连接机制下，新节点连接到节点 $i$ 的概率为 $P_{i}=\\frac{k_{i}}{\\sum_{j}k_{j}}$。\n\n对于P4的连接：\n- $P(\\text{P4}\\to\\text{P2})=\\frac{k_{2}}{4}=\\frac{2}{4}=\\frac{1}{2}$。\n\n为了使最终 $\\deg(\\text{P2})=4$，P2必须接收这两个新连接，因为P2的初始度为2，而P4和P5各贡献一条边。因此，所求事件是P4连接到P2，并且随后P5也连接到P2。\n\n假设P4已经连接到P2。在此之后，度数变为 $k_{1}=1$，$k_{2}=3$，$k_{3}=1$，$k_{4}=1$，因此总度数为 $\\sum_{j}k_{j}=6$。接着对于P5的连接：\n- $P(\\text{P5}\\to\\text{P2}\\mid \\text{P4}\\to\\text{P2})=\\frac{k_{2}}{6}=\\frac{3}{6}=\\frac{1}{2}$。\n\n因此，P4和P5都连接到P2，使得最终 $\\deg(\\text{P2})=4$ 的确切概率为\n$$\nP=\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)=\\frac{1}{4}.\n$$\n没有其他连接序列能用仅两条新边将P2的度数从2提高到4，所以这个结果是精确的。",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "除了其生长机制，无尺度网络的一个决定性特征是其独特的弹性和脆弱性。本练习通过应用渗流理论的概念，量化网络在不同类型攻击下的鲁棒性，从而深入探讨这种双重性。通过比较随机故障和蓄意攻击下的渗流阈值，您将分析性地验证一个著名结论：无尺度网络对随机错误具有鲁棒性，但在其核心节点（hub）被攻击时则非常脆弱。",
            "id": "1705397",
            "problem": "复杂网络（例如互联网或生物相互作用网络）在遭受故障时的稳健性，可以通过渗流理论进行研究。考虑一个大型无标度网络，其度分布 $P(k)$ 服从幂律。我们通过将度 $k$ 视为连续变量来为此分布建模，其概率密度函数为 $P(k) = C k^{-\\gamma}$（当 $k_{\\min} \\le k \\le k_{\\max}$ 时），其他情况下 $P(k) = 0$。此处，$C$ 是一个归一化常数。网络参数给定为 $\\gamma = 2.5$，$k_{\\min} = 2$ 以及 $k_{\\max} = 1000$。\n\n我们在两种不同的点渗流场景下分析网络的完整性，其中比例为 $p$ 的节点保持活跃，比例为 $1-p$ 的节点被移除。如果存在一个巨连通分量，则认为网络是功能性的。\n\n1.  **随机故障**：节点被均匀随机地移除。渗流阈值 $p_{c, \\text{rand}}$ 是为了使巨连通分量存在而必须保留的节点的最小比例。对于度分布为 $P(k)$ 的网络，该阈值由公式 $p_{c, \\text{rand}} = \\frac{\\langle k \\rangle}{\\langle k^2 \\rangle - \\langle k \\rangle}$ 给出，其中 $\\langle k^n \\rangle = \\int_{k_{\\min}}^{k_{\\max}} k^n P(k) dk$ 是度分布的 $n$ 阶矩。\n\n2.  **蓄意攻击**：节点以蓄意的方式被移除，从度最高的节点开始，然后是次高的，依此类推。对于我们特定网络模型上的此类攻击，渗流阈值 $p_{c, \\text{targ}}$ 由公式 $p_{c, \\text{targ}} = \\left(\\frac{k_{\\min}}{k_{\\max}}\\right)^{\\frac{\\gamma-2}{\\gamma-1}}$ 给出。\n\n计算比率 $\\frac{p_{c, \\text{rand}}}{p_{c, \\text{targ}}}$ 的数值。将最终答案四舍五入至三位有效数字。",
            "solution": "我们给定一个在 $[k_{\\min},k_{\\max}]$ 上的连续度分布 $P(k)=C k^{-\\gamma}$，其中 $\\gamma=\\frac{5}{2}$，$k_{\\min}=2$，以及 $k_{\\max}=1000$。归一化常数 $C$ 可由下式得出\n$$\n\\int_{k_{\\min}}^{k_{\\max}} C k^{-\\gamma}\\,dk=1 \\;\\;\\Rightarrow\\;\\; C\\frac{k^{1-\\gamma}}{1-\\gamma}\\Big|_{k_{\\min}}^{k_{\\max}}=1,\n$$\n可得\n$$\nC=\\frac{\\gamma-1}{k_{\\min}^{1-\\gamma}-k_{\\max}^{1-\\gamma}}=\\frac{\\frac{3}{2}}{k_{\\min}^{-3/2}-k_{\\max}^{-3/2}}.\n$$\n$n$ 阶矩为\n$$\n\\langle k^{n}\\rangle=\\int_{k_{\\min}}^{k_{\\max}}k^{n}P(k)\\,dk=C\\int_{k_{\\min}}^{k_{\\max}}k^{n-\\gamma}\\,dk=\\frac{C}{n+1-\\gamma}\\left(k_{\\max}^{n+1-\\gamma}-k_{\\min}^{n+1-\\gamma}\\right),\n$$\n在 $n+1\\neq\\gamma$ 时有效。对于 $\\gamma=\\frac{5}{2}$，我们得到\n$$\n\\langle k\\rangle=\\frac{C}{2-\\gamma}\\left(k_{\\max}^{2-\\gamma}-k_{\\min}^{2-\\gamma}\\right)=2C\\left(k_{\\min}^{-1/2}-k_{\\max}^{-1/2}\\right),\n$$\n$$\n\\langle k^{2}\\rangle=\\frac{C}{3-\\gamma}\\left(k_{\\max}^{3-\\gamma}-k_{\\min}^{3-\\gamma}\\right)=2C\\left(k_{\\max}^{1/2}-k_{\\min}^{1/2}\\right).\n$$\n使用 $C=\\frac{3/2}{k_{\\min}^{-3/2}-k_{\\max}^{-3/2}}$，这些简化为\n$$\n\\langle k\\rangle=3\\frac{k_{\\min}^{-1/2}-k_{\\max}^{-1/2}}{k_{\\min}^{-3/2}-k_{\\max}^{-3/2}},\\qquad\n\\langle k^{2}\\rangle=3\\frac{k_{\\max}^{1/2}-k_{\\min}^{1/2}}{k_{\\min}^{-3/2}-k_{\\max}^{-3/2}}.\n$$\n当 $k_{\\min}=2$ 且 $k_{\\max}=1000$ 时，\n$$\nk_{\\min}^{-1/2}=\\frac{1}{\\sqrt{2}},\\quad k_{\\max}^{-1/2}=\\frac{1}{\\sqrt{1000}},\\quad\nk_{\\min}^{-3/2}=\\frac{1}{2\\sqrt{2}},\\quad k_{\\max}^{-3/2}=\\frac{1}{1000\\sqrt{1000}},\n$$\n$$\nk_{\\max}^{1/2}=\\sqrt{1000},\\quad k_{\\min}^{1/2}=\\sqrt{2}.\n$$\n数值计算得出\n$$\n\\langle k\\rangle\\approx 5.732184545,\\qquad \\langle k^{2}\\rangle\\approx 256.351086044.\n$$\n随机故障的渗流阈值为\n$$\np_{c,\\text{rand}}=\\frac{\\langle k\\rangle}{\\langle k^{2}\\rangle-\\langle k\\rangle}\\approx \\frac{5.732184545}{256.351086044-5.732184545}\\approx 0.0228721158.\n$$\n对于蓄意攻击，其阈值为\n$$\np_{c,\\text{targ}}=\\left(\\frac{k_{\\min}}{k_{\\max}}\\right)^{\\frac{\\gamma-2}{\\gamma-1}}=\\left(\\frac{2}{1000}\\right)^{\\frac{1/2}{3/2}}=\\left(\\frac{2}{1000}\\right)^{1/3}=\\frac{1}{10}\\,2^{1/3}\\approx 0.125992105.\n$$\n因此，所求的比率为\n$$\n\\frac{p_{c,\\text{rand}}}{p_{c,\\text{targ}}}\\approx \\frac{0.0228721158}{0.125992105}\\approx 0.181536,\n$$\n四舍五入至三位有效数字为 $0.182$。",
            "answer": "$$\\boxed{0.182}$$"
        },
        {
            "introduction": "理论模型为我们提供了基础，但真实世界的网络科学研究常常涉及构建模型并根据经验数据进行验证。这个高级计算练习将挑战您从理论走向应用，要求您实现三种不同的无尺度网络生成模型。通过比较这些模型再现给定参考网络聚类特性的能力，您将实践计算生物学中的一项核心任务：选择最合适的模型来解释观测到的生物复杂性。",
            "id": "2427984",
            "problem": "给定三种生物相互作用网络的生成机制，这些机制在计算生物学和生物信息学中被广泛用于模拟无标度结构：Barabási-Albert 优先连接机制、Bianconi-Barabási 适应度机制以及复制-分化机制。你的任务是实现这些机制，计算生成网络的聚类谱，并判断哪种机制能最好地复现一个给定的参考网络（作为代谢网络的代理）的聚类谱。你的程序必须是一个完整的、可运行的程序，能够产生所需的输出，且无需外部输入。\n\n基本基础和所需推导：\n- 一个网络表示为一个带有邻接表的简单无向图。对于一个节点 $v$，其度为 $k_v = \\lvert N(v) \\rvert$，其中 $N(v)$ 是其邻居的集合。与 $v$ 相关联的三角形数量为 $t_v$，等于 $v$ 的邻居中相互连接的无序对的数量。节点 $v$ 的局部聚类系数 (LCC) 定义为\n$$\nC_v = \n\\begin{cases}\n\\frac{2 t_v}{k_v(k_v-1)},  & \\text{if } k_v \\ge 2, \\\\\n0, & \\text{if } k_v  2.\n\\end{cases}\n$$\n聚类谱 $C(k)$ 是 $C_v$ 在具有相似度的节点间的按度分解均值。为了使该量在数值上稳定且可在不同模型间比较，定义 $B$ 个对数间隔的度分箱，范围从 $1$ 到 $k_{\\max}$，其中 $k_{\\max}$ 是在参考网络中观察到的最大度。每个度为 $k_v$ 的节点将其 $C_v$ 值贡献给包含 $\\max(1,k_v)$ 的分箱，分箱谱是每个分箱内 $C_v$ 的平均值。如果某个模型在某个分箱中没有节点，则该模型在该分箱的 $C$ 值定义为 $0$。\n- Barabási-Albert 模型通过从一个初始连接核心开始，每次添加一个节点来增长网络，新节点会以与其度成正比的概率连接到现有节点，形成 $m$ 条新边。Bianconi-Barabási 适应度模型对此进行了推广，在每个节点创建时为其分配一个固定的正适应度 $\\eta_i$，并以与 $\\eta_i k_i$ 成正比的概率进行连接。复制-分化模型从一个小的连接种子开始；在每一步中，它均匀随机地选择一个节点 $u$，创建一个新节点 $v$，对于 $u$ 的每个邻居 $w$，以概率 $p$ 独立地将 $v$ 连接到 $w$，并额外以概率 $q$ 连接 $u$ 和 $v$。如果新节点 $v$ 会被隔离，则将其连接到 $u$ 以保持图的简单和连通性。\n- 为了将候选模型与参考网络进行比较，计算它们分箱聚类谱之间的均方误差：\n$$\n\\mathrm{MSE} = \\frac{1}{B} \\sum_{b=1}^{B} \\left( \\widehat{C}_{\\text{cand}}[b] - \\widehat{C}_{\\text{ref}}[b] \\right)^2,\n$$\n其中 $\\widehat{C}[\\cdot]$ 表示分箱谱。对于随机模型，在计算误差之前，需在指定次数的独立重复实验中对分箱谱取平均。\n\n请根据这些定义精确地实现这三个生成器，确保图是简单无向的，并使用从邻居交集导出的三角形计数，根据定义精确计算 $C_v$。\n\n你的程序必须在每个测试用例上评估所有三个模型，计算它们的误差，并使用“最小索引获胜”的平局决胜规则，输出误差最小的模型的索引。使用模型索引映射：$0 \\mapsto$ Barabási-Albert，$1 \\mapsto$ 适应度模型，$2 \\mapsto$ 复制-分化模型。\n\n参考网络在每个测试用例中按程序方式提供，同时提供种子和所有用于可复现性的必要参数。所有随机数生成必须由指定的种子驱动，使用可复现的伪随机数生成器。不涉及角度和物理单位。所有概率必须被视为单位区间内的实数。所有输出必须是整数。\n\n测试套件：\n- 案例 1：\n  - 节点数：$N = 120$。\n  - 分箱数：$B = 6$。\n  - 每个候选模型的重复次数：$R = 6$。\n  - 候选模型基础种子：$5000$。\n  - 参考网络：复制-分化模型，复制保留概率 $p = 0.72$，回连概率 $q = 0.30$，种子 $1337$。\n  - 候选模型参数：\n    - Barabási-Albert：$m = 2$。\n    - 适应度模型：$m = 2$，适应度分布为对数正态分布，在对数空间中 $\\sigma = 1.0$，$\\mu = 0$。\n    - 复制-分化：$p = 0.72$, $q = 0.30$。\n- 案例 2：\n  - 节点数：$N = 150$。\n  - 分箱数：$B = 7$。\n  - 每个候选模型的重复次数：$R = 5$。\n  - 候选模型基础种子：$6000$。\n  - 参考网络：Barabási-Albert 模型，$m = 2$，种子 $2024$。\n  - 候选模型参数：\n    - Barabási-Albert：$m = 2$。\n    - 适应度模型：$m = 2$，适应度分布为帕累托分布，形状参数 $\\alpha = 2.5$，尺度参数为 $1$。\n    - 复制-分化：$p = 0.65$, $q = 0.25$。\n- 案例 3：\n  - 节点数：$N = 200$。\n  - 分箱数：$B = 7$。\n  - 每个候选模型的重复次数：$R = 4$。\n  - 候选模型基础种子：$7000$。\n  - 参考网络：适应度模型，$m = 2$，适应度分布为对数正态分布，$\\sigma = 1.2$，$\\mu = 0$，种子 $7$。\n  - 候选模型参数：\n    - Barabási-Albert：$m = 2$。\n    - 适应度模型：$m = 2$，适应度分布为对数正态分布，$\\sigma = 1.2$，$\\mu = 0$。\n    - 复制-分化：$p = 0.60$, $q = 0.10$。\n\n最终输出格式：\n- 你的程序应产生单行输出，包含一个由逗号分隔的模型索引列表，并用方括号括起来，顺序与测试用例相同，例如，“$[0,1,2]$”。方括号内不允许有空格。\n\n交付成果：\n- 一个单一、完整的程序，运行时，该程序会构建每个指定的参考网络，使用指定的参数和种子评估三个候选模型，计算分箱聚类谱及其均方误差，根据最小误差和指定的平局决胜规则为每个测试用例选择获胜者，并以确切要求的格式打印结果。不应打印任何其他文本。",
            "solution": "该问题是计算网络生物学中一个明确定义的任务，要求实现和比较三种用于无标度网络的经典生成模型：Barabási-Albert ($BA$) 模型、Bianconi-Barabási ($BB$) 适应度模型和复制-分化 ($DD$) 模型。该问题具有科学依据，算法上具体，并且提供了所有用于验证的参数和程序。因此，它被认为是一个有效的问题。\n\n解决方案通过结构化、分步的方式实现指定的组件。对于每个测试用例，主要目标是确定三个候选模型中哪一个能最好地复现程序生成的参考网络的聚类特性。\n\n首先，网络的核心数据结构是邻接表，实现为一个将每个节点索引（从 $0$ 到 $N-1$ 的整数）映射到其邻居集合的字典。这种选择有助于高效的邻居查找和边修改，这对于计算网络属性和增长算法至关重要。通过确保没有自环，并将每条边 $(u,v)$ 对称地添加到节点 $u$ 和节点 $v$ 的邻接表中，来保持图的简单和无向性。\n\n用于比较的主要度量是聚类谱 $C(k)$。这需要计算每个节点 $v$ 的局部聚类系数 (LCC) $C_v$。给定一个度为 $k_v = |N(v)|$ 的节点 $v$，其中 $N(v)$ 是 $v$ 的邻居集合，计算与 $v$ 相关的三角形数量 $t_v$。这是通过遍历 $v$ 的所有唯一的邻居对（例如 $(u,w)$），并检查它们之间是否存在边（即 $u \\in N(w)$）来实现的。然后，LCC 由以下公式给出：\n$$\nC_v = \n\\begin{cases}\n\\frac{2 t_v}{k_v(k_v-1)},   \\text{if } k_v \\ge 2, \\\\\n0,  \\text{if } k_v  2.\n\\end{cases}\n$$\n为了获得聚类谱，节点度被划分到 $B$ 个对数间隔的分箱中。首先，确定参考网络的最大度 $k_{\\max}$。然后使用 `numpy.logspace` 从 $1$ 到 $k_{\\max}$ 定义分箱边界，以创建 $B$ 个连续的区间。对于每个节点 $v$，其度 $k_v$（如果 $k_v=0$ 则为 $1$）被映射到这些分箱之一。给定分箱的谱值 $\\widehat{C}[b]$ 是所有度落入该分箱的节点的 $C_v$ 值的平均值。如果一个分箱为空，其值为 $0$。\n\n三种生成模型实现如下，每种都由一个带种子的伪随机数生成器驱动以保证可复现性：\n\n$1$. **Barabási-Albert (BA) 模型**：网络从一个小的初始核心开始，具体为一个 $m+1$ 个节点的完全图，以确保初始度非零。然后网络通过每次添加一个节点增长到目标大小 $N$。每个新节点与现有节点形成 $m$ 条边，通过优先连接选择。新节点连接到现有节点 $j$ 的概率与该节点的度 $k_j$ 成正比。这是通过从现有总体中以其度为权重，无放回地抽取 $m$ 个不同节点来实现的。\n\n$2$. **Bianconi-Barabási (BB) 适应度模型**：该模型推广了 BA 机制。开始时，为 $N$ 个潜在节点中的每一个分配一个从指定分布（例如，对数正态或帕累托分布）中抽取的适应度值 $\\eta_i$。网络增长过程与 BA 类似，从一个 $m+1$ 个节点的初始完全图开始。然而，新节点连接到现有节点 $j$ 的概率现在与其适应度和度的乘积 $\\eta_j k_j$ 成正比。同样，根据这些加权概率，无放回地选择 $m$ 个不同节点。\n\n$3$. **复制-分化 (DD) 模型**：该模型模拟基因复制和随后的突变。它从一个由两个节点和一条边组成的最小种子网络开始。网络通过迭代地均匀随机选择一个现有节点 $u$ 作为模板来增长。创建一个新节点 $v$，对于 $u$ 的每个邻居 $w$，以概率 $p$ 形成一条边 $(v,w)$。此外，以概率 $q$ 形成一条边 $(u,v)$。一个关键的最后步骤是确保图保持连通：如果新节点 $v$ 在此过程后没有任何连接，则确定性地在 $v$ 和其模板 $u$ 之间创建一条边。\n\n对于每个测试用例，总体流程如下：\n$1$. 使用其指定的模型、参数和种子生成一个参考网络。\n$2$. 确定参考网络的最大度 $k_{\\max}$，并建立 $B$ 个度分箱。\n$3$. 计算参考网络的分箱聚类谱 $\\widehat{C}_{\\text{ref}}$。\n$4$. 对于三个候选模型中的每一个，生成 $R$ 个重复网络。对于每个重复网络，使用从参考网络定义的分箱计算其分箱聚类谱。然后将这些谱在 $R$ 次重复中取平均，以产生一个单一的代表性谱 $\\widehat{C}_{\\text{cand}}$。\n$5$. 每个候选模型的性能通过其平均谱与参考谱之间的均方误差 (MSE) 来量化：\n$$\n\\mathrm{MSE} = \\frac{1}{B} \\sum_{b=1}^{B} \\left( \\widehat{C}_{\\text{cand}}[b] - \\widehat{C}_{\\text{ref}}[b] \\right)^2\n$$\n$6$. MSE 最低的模型被宣布为该测试用例的获胜者。如果出现平局，索引最小的模型（BA 为 $0$，BB 为 $1$，DD 为 $2$）获胜。\n\n整个过程在一个单一的 Python 脚本中自动化。该脚本遍历提供的测试用例，执行模拟和比较，并以所需格式输出最终的获胜模型索引列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import defaultdict\n\ndef _calculate_lcc_and_deg(adj, n_nodes):\n    \"\"\"Calculates degrees and local clustering coefficients for all nodes.\"\"\"\n    degrees = {i: len(adj.get(i, set())) for i in range(n_nodes)}\n    lccs = {}\n    for i in range(n_nodes):\n        k_v = degrees[i]\n        if k_v  2:\n            lccs[i] = 0.0\n            continue\n        \n        neighbors = list(adj.get(i, set()))\n        t_v = 0\n        for idx1 in range(len(neighbors)):\n            for idx2 in range(idx1 + 1, len(neighbors)):\n                u, w = neighbors[idx1], neighbors[idx2]\n                if w in adj.get(u, set()):\n                    t_v += 1\n        \n        lccs[i] = (2 * t_v) / (k_v * (k_v - 1))\n        \n    return degrees, lccs\n\ndef compute_binned_spectrum(adj, n_nodes, B, k_max):\n    \"\"\"Computes the binned clustering spectrum for a given network.\"\"\"\n    if k_max = 1:\n        bin_edges = np.array([1.0, 2.0]) # A single bin for k=1\n        effective_B = 1\n    else:\n        bin_edges = np.logspace(0, np.log10(k_max), B + 1)\n        effective_B = B\n\n    degrees, lccs = _calculate_lcc_and_deg(adj, n_nodes)\n    \n    lcc_sum = np.zeros(effective_B)\n    node_count = np.zeros(effective_B)\n    \n    internal_edges = bin_edges[1:-1]\n\n    for i in range(n_nodes):\n        k = degrees[i]\n        c = lccs[i]\n        \n        k_eff = max(1, k)\n        \n        if k_max = 1:\n            bin_idx = 0\n        else:\n            bin_idx = np.digitize(k_eff, internal_edges)\n        \n        lcc_sum[bin_idx] += c\n        node_count[bin_idx] += 1\n        \n    spectrum = np.zeros(effective_B)\n    non_zero_counts = node_count > 0\n    spectrum[non_zero_counts] = lcc_sum[non_zero_counts] / node_count[non_zero_counts]\n\n    if effective_B  B:\n        # Pad with zeros if fewer bins were used\n        padded_spectrum = np.zeros(B)\n        padded_spectrum[:effective_B] = spectrum\n        return padded_spectrum\n    \n    return spectrum\n\ndef generate_ba(N, m, seed):\n    \"\"\"Generates a Barabási-Albert network.\"\"\"\n    rng = np.random.default_rng(seed)\n    adj = defaultdict(set)\n    m0 = m + 1\n    \n    if N  m0:\n        return adj\n\n    # Initial complete graph K_{m+1}\n    for i in range(m0):\n        for j in range(i + 1, m0):\n            adj[i].add(j)\n            adj[j].add(i)\n\n    degrees = {i: m for i in range(m0)}\n    node_list = list(range(m0))\n    \n    for i in range(m0, N):\n        current_nodes = np.array(node_list)\n        current_degrees = np.array([degrees[node] for node in current_nodes])\n        \n        total_degree = np.sum(current_degrees)\n        if total_degree == 0:\n            targets = rng.choice(current_nodes, size=m, replace=False)\n        else:\n            probs = current_degrees / total_degree\n            targets = rng.choice(current_nodes, size=m, replace=False, p=probs)\n        \n        adj[i] = set(targets)\n        for target in targets:\n            adj[target].add(i)\n        \n        degrees[i] = m\n        for target in targets:\n            degrees[target] += 1\n        node_list.append(i)\n        \n    return adj\n\ndef generate_bb(N, m, fitness, seed):\n    \"\"\"Generates a Bianconi-Barabási fitness network.\"\"\"\n    rng = np.random.default_rng(seed)\n    adj = defaultdict(set)\n    m0 = m + 1\n    \n    if N  m0:\n        return adj\n\n    for i in range(m0):\n        for j in range(i + 1, m0):\n            adj[i].add(j)\n            adj[j].add(i)\n\n    degrees = {i: m for i in range(m0)}\n    node_list = list(range(m0))\n\n    for i in range(m0, N):\n        current_nodes = np.array(node_list)\n        current_degrees = np.array([degrees[node] for node in current_nodes])\n        current_fitness = np.array([fitness[node] for node in current_nodes])\n\n        weights = current_degrees * current_fitness\n        total_weight = np.sum(weights)\n\n        if total_weight == 0:\n            targets = rng.choice(current_nodes, size=m, replace=False)\n        else:\n            probs = weights / total_weight\n            targets = rng.choice(current_nodes, size=m, replace=False, p=probs)\n        \n        adj[i] = set(targets)\n        for target in targets:\n            adj[target].add(i)\n        \n        degrees[i] = m\n        for target in targets:\n            degrees[target] += 1\n        node_list.append(i)\n        \n    return adj\n\ndef generate_dd(N, p, q, seed):\n    \"\"\"Generates a Duplication-Divergence network.\"\"\"\n    rng = np.random.default_rng(seed)\n    adj = defaultdict(set)\n    \n    if N  2:\n        return adj\n    \n    # Initial seed: 2 nodes, 1 edge\n    adj[0].add(1)\n    adj[1].add(0)\n    \n    nodes = [0, 1]\n    for i in range(2, N):\n        template_node = rng.choice(nodes)\n        \n        new_neighbors = set()\n        \n        # Divergence from template's neighbors\n        for neighbor in adj[template_node]:\n            if rng.random()  p:\n                new_neighbors.add(neighbor)\n        \n        # Link-back to template\n        if rng.random()  q:\n            new_neighbors.add(template_node)\n        \n        # Check for isolation\n        if not new_neighbors:\n            adj[i].add(template_node)\n            adj[template_node].add(i)\n        else:\n            adj[i] = new_neighbors\n            for neighbor in new_neighbors:\n                adj[neighbor].add(i)\n        nodes.append(i)\n        \n    return adj\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 120, \"B\": 6, \"R\": 6, \"candidate_base_seed\": 5000,\n            \"ref_model\": \"dd\", \"ref_params\": {\"p\": 0.72, \"q\": 0.30}, \"ref_seed\": 1337,\n            \"cand_params\": [\n                {\"model\": \"ba\", \"m\": 2},\n                {\"model\": \"bb\", \"m\": 2, \"dist\": \"lognormal\", \"dist_params\": {\"mean\": 0, \"sigma\": 1.0}},\n                {\"model\": \"dd\", \"p\": 0.72, \"q\": 0.30},\n            ]\n        },\n        {\n            \"N\": 150, \"B\": 7, \"R\": 5, \"candidate_base_seed\": 6000,\n            \"ref_model\": \"ba\", \"ref_params\": {\"m\": 2}, \"ref_seed\": 2024,\n            \"cand_params\": [\n                {\"model\": \"ba\", \"m\": 2},\n                {\"model\": \"bb\", \"m\": 2, \"dist\": \"pareto\", \"dist_params\": {\"a\": 2.5, \"scale\": 1}},\n                {\"model\": \"dd\", \"p\": 0.65, \"q\": 0.25},\n            ]\n        },\n        {\n            \"N\": 200, \"B\": 7, \"R\": 4, \"candidate_base_seed\": 7000,\n            \"ref_model\": \"bb\", \"ref_params\": {\"m\": 2, \"dist\": \"lognormal\", \"dist_params\": {\"mean\": 0, \"sigma\": 1.2}}, \"ref_seed\": 7,\n            \"cand_params\": [\n                {\"model\": \"ba\", \"m\": 2},\n                {\"model\": \"bb\", \"m\": 2, \"dist\": \"lognormal\", \"dist_params\": {\"mean\": 0, \"sigma\": 1.2}},\n                {\"model\": \"dd\", \"p\": 0.60, \"q\": 0.10},\n            ]\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        N, B, R = case[\"N\"], case[\"B\"], case[\"R\"]\n        \n        # Generate reference network\n        if case[\"ref_model\"] == \"dd\":\n            ref_adj = generate_dd(N, case[\"ref_params\"][\"p\"], case[\"ref_params\"][\"q\"], case[\"ref_seed\"])\n        elif case[\"ref_model\"] == \"ba\":\n            ref_adj = generate_ba(N, case[\"ref_params\"][\"m\"], case[\"ref_seed\"])\n        else: # bb\n            rng_fit = np.random.default_rng(case[\"ref_seed\"])\n            if case[\"ref_params\"][\"dist\"] == \"lognormal\":\n                fitness = rng_fit.lognormal(mean=case[\"ref_params\"][\"dist_params\"][\"mean\"], sigma=case[\"ref_params\"][\"dist_params\"][\"sigma\"], size=N)\n            adj = generate_bb(N, case[\"ref_params\"][\"m\"], fitness, case[\"ref_seed\"])\n            ref_adj = adj\n\n        ref_degrees, _ = _calculate_lcc_and_deg(ref_adj, N)\n        k_max = max(ref_degrees.values()) if ref_degrees else 0\n        ref_spectrum = compute_binned_spectrum(ref_adj, N, B, k_max)\n\n        mse_scores = []\n        for model_idx, params in enumerate(case[\"cand_params\"]):\n            avg_cand_spectrum = np.zeros(B)\n            \n            # Pre-generate fitness values for BB model if needed\n            if params[\"model\"] == \"bb\":\n                rng_fit = np.random.default_rng(case[\"candidate_base_seed\"])\n                if params[\"dist\"] == \"lognormal\":\n                    fitness_vals = rng_fit.lognormal(mean=params[\"dist_params\"][\"mean\"], sigma=params[\"dist_params\"][\"sigma\"], size=N)\n                elif params[\"dist\"] == \"pareto\":\n                    fitness_vals = (rng_fit.pareto(a=params[\"dist_params\"][\"a\"], size=N) + 1) * params[\"dist_params\"][\"scale\"]\n\n            for rep_idx in range(R):\n                seed = case[\"candidate_base_seed\"] + model_idx * R + rep_idx\n                if params[\"model\"] == \"ba\":\n                    cand_adj = generate_ba(N, params[\"m\"], seed)\n                elif params[\"model\"] == \"bb\":\n                    cand_adj = generate_bb(N, params[\"m\"], fitness_vals, seed)\n                else: # dd\n                    cand_adj = generate_dd(N, params[\"p\"], params[\"q\"], seed)\n\n                cand_spectrum = compute_binned_spectrum(cand_adj, N, B, k_max)\n                avg_cand_spectrum += cand_spectrum\n            \n            avg_cand_spectrum /= R\n            \n            mse = np.mean((avg_cand_spectrum - ref_spectrum)**2)\n            mse_scores.append(mse)\n            \n        winner_idx = np.argmin(mse_scores)\n        final_results.append(winner_idx)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}