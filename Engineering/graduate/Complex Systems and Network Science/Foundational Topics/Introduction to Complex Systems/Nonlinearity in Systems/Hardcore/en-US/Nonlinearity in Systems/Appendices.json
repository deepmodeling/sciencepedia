{
    "hands_on_practices": [
        {
            "introduction": "Many nonlinear systems, from magnetic materials to ecological populations, exhibit bistability—the capacity to exist in one of two distinct stable states. This practice explores the phenomenon of hysteresis, where the system's state depends on the history of an external influence. By analyzing a classic bistable potential, you will derive the conditions for equilibrium and stability, and uncover how slow, cyclic forcing can induce abrupt jumps between states, creating a memory loop fundamental to many nonlinear technologies and natural processes .",
            "id": "4293615",
            "problem": "Consider a single-degree-of-freedom overdamped gradient system with state variable $x \\in \\mathbb{R}$ evolving slowly enough that it remains at (or adiabatically tracks) local minima of an effective potential. The intrinsic potential is $V(x)=\\frac{1}{4}x^{4}-\\frac{1}{2}a x^{2}$ with $a0$. A quasi-static external generalized force $F \\in \\mathbb{R}$ couples linearly to $x$, so that the effective potential is $U(x;F)=V(x)-F x$. In the quasi-static limit, equilibria are defined as stationary points of $U$, and local stability is defined by positive curvature of $U$.\n\nUsing only these principles, do the following:\n\n(a) Derive the equilibrium condition for $x$ as a function of $F$ by imposing the stationarity of $U(x;F)$ with respect to $x$. Do not solve the resulting polynomial explicitly; instead, express the implicit relation that $x$ must satisfy.\n\n(b) Determine the local stability criterion for an equilibrium in terms of $x$ and $a$ by examining the curvature of $U(x;F)$.\n\n(c) Identify the condition under which a stable and an unstable equilibrium coalesce and annihilate each other under variation of $F$ (a saddle-node event). Using this condition, derive analytically the magnitude of the critical forcing $F_{c}$ at which this disappearance occurs, in closed form in terms of $a$.\n\n(d) Explain, in words supported by the above derivations, how a slow cyclic sweep of $F$ from a large negative value to a large positive value and back generates a hysteresis loop when tracking $x$ versus $F$. Your explanation should connect the existence of multiple equilibria, their stability, and the saddle-node events.\n\nProvide, as your final answer, the exact analytic expression you obtain for the critical forcing magnitude $F_{c}$. No numerical approximation is required and no units are necessary.",
            "solution": "The effective potential for the system is given by $U(x;F) = V(x) - Fx$, where the intrinsic potential is $V(x) = \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2}$ with the parameter $a > 0$. Therefore, the effective potential is:\n$$\nU(x;F) = \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2} - Fx\n$$\n\n(a) The equilibrium condition is found by identifying the stationary points of the effective potential $U(x;F)$ with respect to the state variable $x$. This is achieved by setting the first derivative of $U$ with respect to $x$ equal to zero.\n$$\n\\frac{\\partial U}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2} - Fx \\right) = x^{3} - ax - F\n$$\nSetting this derivative to zero, $\\frac{\\partial U}{\\partial x} = 0$, yields the implicit relation that defines the equilibrium value(s) of $x$ for a given forcing $F$:\n$$\nx^{3} - ax - F = 0\n$$\nThis equation can be expressed as $F = x^{3} - ax$, which defines the equilibrium manifold in the $(x, F)$ plane.\n\n(b) The local stability of an equilibrium point is determined by the curvature of the potential at that point. A stable equilibrium corresponds to a local minimum of the potential, which requires the second derivative of $U(x;F)$ with respect to $x$ to be positive. We calculate this second derivative:\n$$\n\\frac{\\partial^{2} U}{\\partial x^{2}} = \\frac{\\partial}{\\partial x} (x^{3} - ax - F) = 3x^{2} - a\n$$\nFor an equilibrium to be locally stable, we must have $\\frac{\\partial^{2} U}{\\partial x^{2}} > 0$. This gives the stability criterion:\n$$\n3x^{2} - a > 0\n$$\nThis inequality can be solved for $x$ to determine the regions of stability:\n$$\nx^{2} > \\frac{a}{3} \\quad \\text{or equivalently} \\quad |x| > \\sqrt{\\frac{a}{3}}\n$$\nEquilibria are stable if they are located at positions $x$ that satisfy $|x| > \\sqrt{a/3}$. Conversely, equilibria are unstable if $|x|  \\sqrt{a/3}$, where the curvature is negative.\n\n(c) A saddle-node event occurs when a stable and an unstable equilibrium coalesce and annihilate each other. This happens at the margin of stability, precisely where the curvature of the potential is zero. This corresponds to the condition:\n$$\n\\frac{\\partial^{2} U}{\\partial x^{2}} = 3x^{2} - a = 0\n$$\nSolving for the critical positions $x_{c}$ where this occurs, we find:\n$$\nx_{c}^{2} = \\frac{a}{3} \\implies x_{c} = \\pm \\sqrt{\\frac{a}{3}}\n$$\nThese critical positions are the locations of the saddle-node bifurcations. To find the corresponding critical forcing values, we substitute these $x_{c}$ values back into the equilibrium condition from part (a), $F = x^{3} - ax$.\nFor the critical point $x_{c} = -\\sqrt{\\frac{a}{3}}$:\n$$\nF = \\left(-\\sqrt{\\frac{a}{3}}\\right)^{3} - a\\left(-\\sqrt{\\frac{a}{3}}\\right) = -\\left(\\frac{a}{3}\\right)\\sqrt{\\frac{a}{3}} + a\\sqrt{\\frac{a}{3}} = \\sqrt{\\frac{a}{3}}\\left(a - \\frac{a}{3}\\right) = \\sqrt{\\frac{a}{3}}\\left(\\frac{2a}{3}\\right) = \\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\nFor the critical point $x_{c} = +\\sqrt{\\frac{a}{3}}$:\n$$\nF = \\left(\\sqrt{\\frac{a}{3}}\\right)^{3} - a\\left(\\sqrt{\\frac{a}{3}}\\right) = \\left(\\frac{a}{3}\\right)\\sqrt{\\frac{a}{3}} - a\\sqrt{\\frac{a}{3}} = \\sqrt{\\frac{a}{3}}\\left(\\frac{a}{3} - a\\right) = \\sqrt{\\frac{a}{3}}\\left(-\\frac{2a}{3}\\right) = -\\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\nThe problem asks for the magnitude of the critical forcing, denoted $F_{c}$. This is the absolute value of the forces calculated above:\n$$\nF_{c} = \\left|\\pm\\frac{2a\\sqrt{a}}{3\\sqrt{3}}\\right| = \\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\n\n(d) The existence of multiple equilibria in a specific range of $F$ and their annihilation at critical points gives rise to hysteresis. In the range of forcing $|F|  F_{c}$, there are three equilibrium solutions for $x$: two are stable (outer branches where $|x| > \\sqrt{a/3}$) and one is unstable (middle branch where $|x|  \\sqrt{a/3}$). The system, by assumption, tracks a stable equilibrium (a local minimum of $U$).\n\nLet's trace a slow cyclic sweep of $F$:\n1.  Start at a large negative force, $F \\ll -F_{c}$. There is only one minimum of $U(x;F)$, located at a large negative $x$. The system state is on this lower stable branch.\n2.  Slowly increase $F$. The system state $x$ increases, following this lower stable branch. Even as $F$ enters the bistable region $(-F_{c}, F_{c})$, the system remains on this branch.\n3.  When $F$ reaches the critical value $+F_{c}$, the lower stable equilibrium (at $x_{c} = -\\sqrt{a/3}$) coalesces with the central unstable equilibrium and they both vanish.\n4.  With its local minimum gone, the system must undergo a catastrophic jump to the only remaining stable equilibrium, which is on the upper branch at a positive value of $x$.\n5.  Now, sweep $F$ back down from a large positive value. The system starts on the upper stable branch (large positive $x$).\n6.  As $F$ is decreased, the system tracks this upper branch, with $x$ decreasing.\n7.  When $F$ falls to the other critical value, $-F_{c}$, the upper stable equilibrium (at $x_{c} = +\\sqrt{a/3}$) coalesces with the unstable equilibrium and vanishes.\n8.  The system must then jump down to the only available stable state, which is on the lower branch at a negative $x$.\n\nThe path of $x$ as $F$ is increased is different from the path as $F$ is decreased. This state-dependence on the history of the control parameter $F$ is hysteresis. The plot of $x$ versus $F$ forms a loop, with upward and downward jumps occurring at two different force values, $+F_{c}$ and $-F_{c}$, which are the saddle-node bifurcation points.",
            "answer": "$$\\boxed{\\frac{2a\\sqrt{a}}{3\\sqrt{3}}}$$"
        },
        {
            "introduction": "Linearization is a cornerstone of dynamical systems analysis, but it can be inconclusive for non-hyperbolic equilibria, whose linearized dynamics do not fully capture the behavior of the nonlinear system. This exercise tackles such a case, guiding you to move beyond eigenvalue analysis and apply Lyapunov's direct method. You will derive a conserved energy function for a nonlinear oscillator and use it as a Lyapunov function to rigorously prove stability, illustrating a more powerful and general technique for assessing the behavior of conservative systems .",
            "id": "4293645",
            "problem": "Consider the autonomous, time-invariant, $2$-dimensional ordinary differential equation (ODE) system\n$$\n\\dot{x}_{1}=x_{2},\\qquad \\dot{x}_{2}=-x_{1}-x_{1}^{3},\n$$\nwhich represents the dynamics of a unit-mass particle with generalized coordinate $x_{1}$ and velocity $x_{2}$ subject to a conservative nonlinear restoring force. Your tasks are to assess the predictive power of linearization at the equilibrium $(0,0)$ and to determine whether the linearization yields a correct stability conclusion when compared with the full nonlinear dynamics, explicitly discussing the role of higher-order terms.\n\nYou must proceed from fundamental bases appropriate for complex systems and nonlinear dynamics: the definition of linearization via the Jacobian at an equilibrium, the classification of equilibria via eigenvalues for hyperbolic cases, and the work-energy principle for conservative mechanical systems leading to an energy-like first integral. Do not invoke any specialized theorems beyond these bases.\n\nTasks:\n- Determine the linearization of the system at $(0,0)$ and classify the equilibrium based on the linearized eigenvalues.\n- State what the linearization alone can or cannot conclude about stability in this nonhyperbolic case, justifying your statement from first principles.\n- Derive from first principles a conserved energy function for the full nonlinear system by interpreting the dynamics as those of a conservative mechanical system and by using only the chain rule and the work-energy principle.\n- Use the derived conserved quantity to rigorously assess Lyapunov stability and asymptotic stability of the equilibrium in the full nonlinear system.\n- Explicitly discuss the role of the higher-order term $-x_{1}^{3}$ in shaping the nonlinear stability properties relative to the linearized prediction.\n\nAnswer specification:\n- Your final reported answer must be the explicit analytic expression of a smooth, positive definite Lyapunov function $V(x_{1},x_{2})$ you derive from first principles that certifies Lyapunov stability of $(0,0)$ for the full nonlinear system. Do not include units. No numerical rounding is required. The final answer must be a single closed-form expression.",
            "solution": "The problem requires a stability analysis of the equilibrium point $(0,0)$ for the given $2$-dimensional nonlinear ordinary differential equation (ODE) system:\n$$\n\\dot{x}_{1} = x_{2} \\\\\n\\dot{x}_{2} = -x_{1} - x_{1}^{3}\n$$\nThe analysis must compare the prediction from linearization with a rigorous stability assessment of the full nonlinear system using a derived conserved quantity.\n\nWe begin by representing the system in vector form. Let $\\mathbf{x} = \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix}$. The system dynamics are described by $\\dot{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x})$, where the vector field $\\mathbf{f}$ is given by:\n$$\n\\mathbf{f}(x_{1}, x_{2}) = \\begin{pmatrix} x_{2} \\\\ -x_{1} - x_{1}^{3} \\end{pmatrix}\n$$\nThe equilibrium points are found by setting $\\mathbf{f}(\\mathbf{x}) = \\mathbf{0}$. This yields $x_{2}=0$ and $-x_{1}-x_{1}^{3} = -x_{1}(1+x_{1}^{2}) = 0$. Since $1+x_{1}^{2} > 0$ for all real $x_{1}$, the only real solution is $x_{1}=0$. Thus, the sole equilibrium point is at the origin, $(0,0)$, as stated in the problem.\n\nFirst, we determine the linearization of the system at this equilibrium. The linearization is given by $\\dot{\\mathbf{z}} = J(0,0)\\mathbf{z}$, where $J$ is the Jacobian matrix of $\\mathbf{f}$:\n$$\nJ(x_{1}, x_{2}) = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial x_{1}}  \\frac{\\partial f_{1}}{\\partial x_{2}} \\\\ \\frac{\\partial f_{2}}{\\partial x_{1}}  \\frac{\\partial f_{2}}{\\partial x_{2}} \\end{pmatrix} = \\begin{pmatrix} 0  1 \\\\ -1 - 3x_{1}^{2}  0 \\end{pmatrix}\n$$\nEvaluating the Jacobian at the equilibrium point $(0,0)$:\n$$\nA = J(0,0) = \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}\n$$\nTo classify the equilibrium, we find the eigenvalues of this matrix by solving the characteristic equation $\\det(A - \\lambda I) = 0$:\n$$\n\\det\\begin{pmatrix} -\\lambda  1 \\\\ -1  -\\lambda \\end{pmatrix} = (-\\lambda)(-\\lambda) - (1)(-1) = \\lambda^{2} + 1 = 0\n$$\nThe eigenvalues are $\\lambda_{1,2} = \\pm i$. These are a pair of purely imaginary eigenvalues. An equilibrium is classified as hyperbolic if all eigenvalues of the Jacobian have non-zero real parts. Since the real parts of $\\lambda_{1,2}$ are zero, the equilibrium at $(0,0)$ is non-hyperbolic.\n\nFor a linearized system, purely imaginary eigenvalues correspond to a center, where trajectories are closed orbits (circles or ellipses) around the equilibrium, indicating stability. However, the Hartman-Grobman theorem, which guarantees topological equivalence between a nonlinear system and its linearization near a hyperbolic equilibrium, does not apply here. Consequently, linearization alone is inconclusive. The stability of the full nonlinear system depends on the higher-order terms ($H.O.T.$) in the Taylor expansion of $\\mathbf{f}$, which in this case is the term $-x_{1}^{3}$. The nonlinear system near the origin could exhibit a center, a stable spiral, or an unstable spiral. A definitive conclusion requires a direct analysis of the nonlinear system.\n\nWe now derive a conserved quantity from first principles, as requested. The system can be interpreted as a unit-mass particle ($m=1$) with position $x_{1}$ and velocity $\\dot{x}_{1}=x_{2}$. The equation for acceleration is $\\ddot{x}_{1} = \\dot{x}_{2} = -x_{1} - x_{1}^{3}$. This corresponds to Newton's second law, $m\\ddot{x}_{1} = F(x_{1})$, with a force $F(x_{1}) = -x_{1} - x_{1}^{3}$. Since the force depends only on the position $x_{1}$, it is a conservative force. The work-energy principle states that the total mechanical energy is conserved for such a system. The total energy $E$ is the sum of kinetic energy $T$ and potential energy $U$.\n\nThe kinetic energy for a unit mass is $T = \\frac{1}{2}m v^{2} = \\frac{1}{2}(1)x_{2}^{2} = \\frac{1}{2}x_{2}^{2}$.\nThe potential energy $U(x_{1})$ is related to the conservative force by $F(x_{1}) = -\\frac{dU}{dx_{1}}$. We can find $U(x_{1})$ by integration:\n$$\nU(x_{1}) = -\\int F(x_{1}) \\,dx_{1} = -\\int (-x_{1} - x_{1}^{3}) \\,dx_{1} = \\int (x_{1} + x_{1}^{3}) \\,dx_{1} = \\frac{1}{2}x_{1}^{2} + \\frac{1}{4}x_{1}^{4} + C_{0}\n$$\nChoosing the integration constant $C_{0}=0$ so that the potential is zero at the equilibrium, we get $U(x_{1}) = \\frac{1}{2}x_{1}^{2} + \\frac{1}{4}x_{1}^{4}$.\n\nThe total energy of the system is a candidate for a Lyapunov function, which we denote by $V(x_{1}, x_{2})$:\n$$\nV(x_{1}, x_{2}) = T + U = \\frac{1}{2}x_{2}^{2} + \\frac{1}{2}x_{1}^{2} + \\frac{1}{4}x_{1}^{4}\n$$\nTo verify that this is a conserved quantity for the system, we compute its time derivative along the system's trajectories using the chain rule:\n$$\n\\dot{V} = \\frac{dV}{dt} = \\frac{\\partial V}{\\partial x_{1}}\\dot{x}_{1} + \\frac{\\partial V}{\\partial x_{2}}\\dot{x}_{2}\n$$\nThe partial derivatives are:\n$$\n\\frac{\\partial V}{\\partial x_{1}} = x_{1} + x_{1}^{3} \\\\\n\\frac{\\partial V}{\\partial x_{2}} = x_{2}\n$$\nSubstituting these and the system dynamics ($\\dot{x}_{1}=x_{2}$, $\\dot{x}_{2}=-x_{1}-x_{1}^{3}$) into the expression for $\\dot{V}$:\n$$\n\\dot{V} = (x_{1} + x_{1}^{3})(x_{2}) + (x_{2})(-x_{1} - x_{1}^{3}) = x_{1}x_{2} + x_{1}^{3}x_{2} - x_{1}x_{2} - x_{1}^{3}x_{2} = 0\n$$\nSince $\\dot{V} \\equiv 0$, the function $V(x_{1}, x_{2})$ is a constant of motion, or a first integral. This confirms its role as a conserved energy.\n\nNow, we use this function $V(x_{1}, x_{2})$ to formally assess the stability of the equilibrium $(0,0)$ via Lyapunov's direct method. A function is a Lyapunov function certifying stability if it is positive definite and its time derivative is negative semi-definite in a neighborhood of the equilibrium.\n1.  **Positive Definiteness:**\n    -   At the origin, $V(0,0) = \\frac{1}{2}(0)^{2} + \\frac{1}{4}(0)^{4} + \\frac{1}{2}(0)^{2} = 0$.\n    -   For any point $(x_{1}, x_{2}) \\neq (0,0)$, the terms $\\frac{1}{2}x_{1}^{2}$, $\\frac{1}{4}x_{1}^{4}$, and $\\frac{1}{2}x_{2}^{2}$ are all non-negative. Their sum is zero if and only if all terms are zero, which occurs only at $(x_{1}, x_{2})=(0,0)$. Therefore, $V(x_{1}, x_{2}) > 0$ for all $(x_{1}, x_{2}) \\neq (0,0)$. The function is globally positive definite.\n\n2.  **Time Derivative:**\n    -   We have already shown that $\\dot{V}(x_{1}, x_{2}) = 0$ for all $(x_{1}, x_{2})$. This satisfies the condition of being negative semi-definite ($\\dot{V} \\le 0$).\n\nSince we have found a smooth, positive definite function $V$ whose time derivative along trajectories is identically zero, the equilibrium $(0,0)$ is **Lyapunov stable**. This means trajectories starting sufficiently close to the origin remain in a small neighborhood of the origin for all time. Specifically, they are confined to the level sets of $V(x_{1}, x_{2}) = \\text{constant}$.\n\nFor asymptotic stability, we would require trajectories to approach the origin as $t \\to \\infty$. This is not the case here. Asymptotic stability would require $\\dot{V}$ to be strictly negative away from the origin (or, by LaSalle's Invariance Principle, for the set where $\\dot{V}=0$ to contain no trajectories other than the equilibrium). Here, $\\dot{V}=0$ everywhere, so every trajectory is an invariant set. The system is not asymptotically stable; it exhibits persistent oscillations.\n\nFinally, we discuss the role of the higher-order term, $-x_{1}^{3}$. The linearization captures the force $-x_{1}$, corresponding to a simple harmonic oscillator with potential $U_{lin}(x_{1}) = \\frac{1}{2}x_{1}^{2}$. The higher-order term $-x_{1}^{3}$ is a nonlinear restoring force that adds the term $\\frac{1}{4}x_{1}^{4}$ to the potential energy. Since $x_{1}^{4} > 0$ for $x_{1} \\neq 0$, this term makes the potential well \"steeper\" than the parabolic well of the linearized system. This additional restoring effect, which acts in the same direction as the linear force, reinforces the stability. It ensures the potential energy has a strict and global minimum at $x_{1}=0$. The positive definite nature of the full energy function $V(x_{1}, x_{2})$ holds globally, implying that all trajectories are bounded and are, in fact, closed orbits corresponding to the level sets of $V$. The system possesses a **nonlinear center**. In this specific instance, the prediction of the linearized system (a center) happens to align with the behavior of the full nonlinear system. However, this correctness is not guaranteed in general for non-hyperbolic cases and was only confirmed by constructing the Lyapunov function for the full system. The higher-order term preserves, and in fact strengthens, the stability of the equilibrium.",
            "answer": "$$\\boxed{\\frac{1}{2}x_{1}^{2} + \\frac{1}{2}x_{2}^{2} + \\frac{1}{4}x_{1}^{4}}$$"
        },
        {
            "introduction": "A defining feature of chaos is sensitive dependence on initial conditions, where tiny initial differences between trajectories grow exponentially over time. To move from a qualitative description to a quantitative diagnosis of chaos, we use the largest Lyapunov exponent ($\\lambda$). This practice provides a comprehensive look at this crucial metric, first by guiding you through a first-principles derivation of its formula for one-dimensional maps, and then by having you implement a numerical program to estimate it for the logistic map—a canonical model for the transition to chaos .",
            "id": "4293679",
            "problem": "Consider the one-dimensional iterative map defined by $x_{n+1} = T(x_n)$ on the interval $[0,1]$, where $T$ is continuously differentiable. The largest Lyapunov exponent (LLE) quantifies the average exponential rate of separation of nearby trajectories and is defined fundamentally by the long-time limit\n$$\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\delta x_n|}{|\\delta x_0|},$$\nwhere $\\delta x_n$ is the infinitesimal separation between two trajectories after $n$ iterations, evolved under the linearization induced by $T$.\n\nYour tasks are:\n\n1) Starting from the fundamental definition above and the chain rule for compositions of differentiable functions, derive an expression for the largest Lyapunov exponent of a one-dimensional differentiable map in terms of the long-time average of the logarithm of the absolute value of the derivative of $T$ evaluated along a typical trajectory. State clearly all assumptions you use to justify the derivation.\n\n2) Specialize your result to the logistic map $T(x) = r x (1 - x)$ with parameter $r \\in (0,4]$. Provide the explicit expression for the per-iterate contribution to the finite-time estimator of the largest Lyapunov exponent for this map, expressed as a function of $r$ and the current state $x_n$.\n\n3) Implement a program to estimate the largest Lyapunov exponent numerically using the finite-time estimator\n$$\\hat{\\lambda}_{N,M}(x_0) = \\frac{1}{N} \\sum_{n=1}^{N} \\log \\left| T'(x_{M+n-1}) \\right|,$$\nwhere $M$ is a burn-in (transient) length, $N$ is the number of averaged iterates, $x_0$ is the initial condition, and $\\log$ denotes the natural logarithm. Your implementation must be robust to the nonlinearity-induced singular events that can occur in the logistic map, such as encountering a point where $|T'(x)| = 0$ or rounding into the endpoints of the interval:\n- Before evaluating any logarithm at iteration index $n$, if $|1 - 2 x_{M+n-1}|  \\varepsilon_{\\text{crit}}$ or $x_{M+n-1} \\notin [0,1]$ or $x_{M+n-1}$ lies within $\\varepsilon_{\\text{end}}$ of either endpoint, replace $x_{M+n-1}$ by $x_{M+n-1} + \\operatorname{sign}(0.5 - x_{M+n-1}) \\, \\varepsilon_{\\text{jit}}$ and then clamp it into the closed interval $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$.\n- Use $\\varepsilon_{\\text{crit}} = 10^{-14}$, $\\varepsilon_{\\text{jit}} = 10^{-12}$, and $\\varepsilon_{\\text{end}} = 10^{-15}$.\n- After each map iteration $x \\mapsto T(x)$, clamp the result into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$ to avoid spurious rounding into the endpoints.\n\n4) Use your program to evaluate the estimator for the following test suite. For each case, report a single floating-point value equal to $\\hat{\\lambda}_{N,M}(x_0)$ rounded to $6$ decimal places:\n- Case A (fully developed chaos, typical initial condition): $r = 4.0$, $x_0 = 0.123456789$, $M = 1000$, $N = 200000$.\n- Case B (critical point initial condition requiring regularization): $r = 4.0$, $x_0 = 0.5$, $M = 1000$, $N = 200000$.\n- Case C (periodic window): $r = 3.2$, $x_0 = 0.1$, $M = 1000$, $N = 200000$.\n- Case D (onset of chaos near the Feigenbaum point): $r = 3.569945672$, $x_0 = 0.1$, $M = 2000$, $N = 200000$.\n- Case E (chaotic banded attractor): $r = 3.75$, $x_0 = 0.1$, $M = 1000$, $N = 200000$.\n\nInterpret a positive value of the estimated largest Lyapunov exponent as an indicator of sensitive dependence on initial conditions (chaos) and a negative value as an indicator of asymptotic periodicity. You do not need to output this interpretation; it guides your understanding.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to $6$ decimal places, in the order [Case A, Case B, Case C, Case D, Case E]. For example, a valid output line has the form \"[0.693147,0.693147,-0.000001,0.000000,0.500000]\". Do not print any other text.",
            "solution": "### Task 1: Derivation of the Lyapunov Exponent Expression\n\nThe largest Lyapunov exponent, $\\lambda$, quantifies the average rate of exponential separation of infinitesimally close trajectories. For a one-dimensional map $x_{n+1} = T(x_n)$, the fundamental definition is given as:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\delta x_n|}{|\\delta x_0|}\n$$\nHere, $\\delta x_0$ is the initial infinitesimal separation between two starting points, $x_0$ and $x_0' = x_0 + \\delta x_0$. The separation after $n$ iterations is $\\delta x_n = x_n' - x_n$, where $x_n = T^n(x_0)$ and $x_n' = T^n(x_0')$.\n\nWe proceed with the derivation step-by-step.\nLet the two trajectories be initialized at $x_0$ and $x_0' = x_0 + \\delta x_0$.\nAfter one iteration, their states are $x_1 = T(x_0)$ and $x_1' = T(x_0 + \\delta x_0)$.\nThe separation becomes $\\delta x_1 = x_1' - x_1 = T(x_0 + \\delta x_0) - T(x_0)$.\nSince the initial separation $\\delta x_0$ is infinitesimal and the map $T$ is assumed to be continuously differentiable, we can use a first-order Taylor series expansion for $T(x_0 + \\delta x_0)$ around $x_0$:\n$$\nT(x_0 + \\delta x_0) \\approx T(x_0) + T'(x_0) \\delta x_0\n$$\nwhere $T'(x_0)$ is the derivative of $T$ evaluated at $x_0$.\nSubstituting this into the expression for $\\delta x_1$ yields:\n$$\n\\delta x_1 \\approx (T(x_0) + T'(x_0) \\delta x_0) - T(x_0) = T'(x_0) \\delta x_0\n$$\nThis shows that the initial separation $\\delta x_0$ is stretched or contracted by a factor of $|T'(x_0)|$ after one iteration.\n\nNow, we consider the evolution of the separation over $n$ iterations. After the second iteration, the separation is $\\delta x_2 \\approx T'(x_1) \\delta x_1$. Substituting the expression for $\\delta x_1$, we get:\n$$\n\\delta x_2 \\approx T'(x_1) \\left( T'(x_0) \\delta x_0 \\right) = T'(x_1) T'(x_0) \\delta x_0\n$$\nBy induction, after $n$ iterations, the separation $\\delta x_n$ is related to the initial separation $\\delta x_0$ by:\n$$\n\\delta x_n \\approx \\left( \\prod_{k=0}^{n-1} T'(x_k) \\right) \\delta x_0\n$$\nwhere $x_k = T^k(x_0)$ is the state of the primary trajectory at iteration $k$. The product term is precisely the derivative of the $n$-th iterate of the map, $T^n(x_0)$, by the chain rule: $(T^n)'(x_0) = T'(x_{n-1}) \\cdots T'(x_1) T'(x_0)$.\n\nWe substitute this result into the definition of $\\lambda$:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\left( \\prod_{k=0}^{n-1} T'(x_k) \\right) \\delta x_0|}{|\\delta x_0|}\n$$\nThe term $|\\delta x_0|$ cancels out:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left| \\prod_{k=0}^{n-1} T'(x_k) \\right|\n$$\nUsing the property of logarithms that $\\ln(\\prod a_i) = \\sum \\ln(a_i)$, we arrive at the final expression:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\ln |T'(x_k)|\n$$\nThis expression represents the largest Lyapunov exponent as the long-time average of the logarithm of the absolute value of the map's derivative, evaluated along a trajectory.\n\nThe derivation relies on the following key assumptions:\n1.  **Differentiability**: The map $T(x)$ must be at least continuously differentiable ($C^1$) on its domain, allowing for the use of Taylor series expansion and the chain rule.\n2.  **Infinitesimal Separation**: The entire derivation is based on the linearization of the map's dynamics, which is only valid for infinitesimally small separations. The Lyapunov exponent characterizes the growth rate of such infinitesimal perturbations.\n3.  **Ergodicity**: This is a critical assumption for the practical utility of the derived formula. We assume the system is ergodic on its attractor. This means that for almost all initial conditions $x_0$ within a basin of attraction, the time average along the resulting trajectory is equivalent to the spatial average over the attractor's natural invariant measure. Consequently, the limit exists and is independent of the specific choice of the typical initial condition $x_0$.\n\n### Task 2: Specialization to the Logistic Map\n\nThe logistic map is defined as $T(x) = r x (1 - x)$.\nTo apply the derived formula, we first need to compute its derivative, $T'(x)$:\n$$\nT'(x) = \\frac{d}{dx} \\left( rx - rx^2 \\right) = r - 2rx = r(1-2x)\n$$\nThe per-iterate contribution to the finite-time estimator for the LLE at step $n$ is the term inside the summation, $\\ln|T'(x_n)|$. For the logistic map, this term is explicitely:\n$$\n\\ln|T'(x_n)| = \\ln|r(1-2x_n)|\n$$\n\n### Tasks 3  4: Numerical Estimation and Implementation\n\nThe problem provides a finite-time estimator for the LLE:\n$$\n\\hat{\\lambda}_{N,M}(x_0) = \\frac{1}{N} \\sum_{n=1}^{N} \\log \\left| T'(x_{M+n-1}) \\right|\n$$\nHere, $M$ is the number of \"burn-in\" iterations to let the trajectory settle onto the attractor, and $N$ is the number of subsequent iterations over which the average is computed.\n\nThe numerical implementation follows a precise algorithm to ensure robustness, particularly against singularities. The logistic map's derivative $T'(x) = r(1-2x)$ becomes zero at the critical point $x=0.5$, which would cause the logarithm to diverge to $-\\infty$. The endpoints $x=0$ and $x=1$ can also be problematic.\n\nThe implemented algorithm proceeds as follows:\n1.  Initialize the state $x$ with the initial condition $x_0$.\n2.  Perform the burn-in phase: Iterate the map $M$ times. In each iteration, update the state $x \\leftarrow r x (1 - x)$ and then clamp the result into the interval $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$ to prevent the state from landing exactly on the endpoints due to floating-point rounding.\n3.  Initialize an accumulator, `lyapunov_sum`, to $0.0$.\n4.  Perform the averaging phase for $N$ iterations:\n    a. Let the current state be $x_{current}$. Before using it, check for numerical instability. A state is deemed unstable if it is too close to the critical point $0.5$ (i.e., $|1 - 2x_{current}|  \\varepsilon_{\\text{crit}}$) or if it is at or too close to the interval endpoints.\n    b. If the state is unstable, it is perturbed (replaced) by adding a small jitter $\\pm\\varepsilon_{\\text{jit}}$. The sign of the jitter is chosen to push the state away from the center of the interval. The perturbed state is then clamped into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$. This new, safe state replaces the old one for all subsequent calculations in the current step.\n    c. Calculate the derivative term $\\ln|r(1-2x)|$ using the (potentially perturbed) state and add it to `lyapunov_sum`.\n    d. Iterate the map for the next step, $x \\leftarrow r x (1 - x)$, using the (potentially perturbed) state as input.\n    e. Clamp the result of the map iteration into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$.\n5. After the loop, the LLE estimate is calculated as $\\hat{\\lambda} = \\text{lyapunov\\_sum} / N$.\n6. This procedure is applied to each of the five test cases specified, and the results are rounded to $6$ decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the largest Lyapunov exponent for the logistic map\n    for a suite of test cases and prints the results in the specified format.\n    \"\"\"\n    # Define constants for numerical stability from the problem statement.\n    EPS_CRIT = 1.0e-14\n    EPS_JIT = 1.0e-12\n    EPS_END = 1.0e-15\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (fully developed chaos)\n        {'r': 4.0, 'x0': 0.123456789, 'M': 1000, 'N': 200000},\n        # Case B (critical point initial condition)\n        {'r': 4.0, 'x0': 0.5, 'M': 1000, 'N': 200000},\n        # Case C (periodic window)\n        {'r': 3.2, 'x0': 0.1, 'M': 1000, 'N': 200000},\n        # Case D (onset of chaos)\n        {'r': 3.569945672, 'x0': 0.1, 'M': 2000, 'N': 200000},\n        # Case E (chaotic banded attractor)\n        {'r': 3.75, 'x0': 0.1, 'M': 1000, 'N': 200000},\n    ]\n\n    def calculate_lle(r, x0, M, N):\n        \"\"\"\n        Estimates the Largest Lyapunov Exponent (LLE) for the logistic map.\n\n        Args:\n            r (float): The parameter of the logistic map.\n            x0 (float): The initial condition.\n            M (int): The number of burn-in (transient) iterations.\n            N (int): The number of iterations for averaging.\n\n        Returns:\n            float: The estimated LLE.\n        \"\"\"\n        x = float(x0)\n\n        # Burn-in phase to allow the trajectory to settle on the attractor.\n        # After each map iteration, the state is clamped to avoid rounding\n        # into exact endpoints.\n        for _ in range(M):\n            x = r * x * (1.0 - x)\n            x = max(EPS_END, min(1.0 - EPS_END, x))\n\n        lyapunov_sum = 0.0\n\n        # Averaging phase to compute the LLE.\n        for _ in range(N):\n            # Check for singular or near-singular conditions before evaluation.\n            # This includes being too close to the critical point (x=0.5)\n            # or the interval endpoints.\n            if (abs(1.0 - 2.0 * x)  EPS_CRIT) or \\\n               (x = EPS_END) or (x >= 1.0 - EPS_END):\n                \n                # Perturb the state to avoid singularity.\n                # The sign of the jitter is chosen to push the state away\n                # from the center (0.5).\n                sign_val = np.sign(0.5 - x)\n                if sign_val == 0.0:\n                    sign_val = 1.0  # Handle exact x=0.5 case by picking a direction.\n                \n                x += sign_val * EPS_JIT\n                \n                # Clamp the perturbed state back into the safe interval.\n                x = max(EPS_END, min(1.0 - EPS_END, x))\n\n            # Add the log of the absolute value of the derivative to the sum.\n            # This uses the (potentially perturbed) state x.\n            lyapunov_sum += np.log(abs(r * (1.0 - 2.0 * x)))\n\n            # Iterate the map for the next step using the (potentially perturbed) state.\n            x = r * x * (1.0 - x)\n            \n            # Clamp the result of the map iteration to stay within the safe interval.\n            x = max(EPS_END, min(1.0 - EPS_END, x))\n\n        # The LLE is the average of the logged values.\n        return lyapunov_sum / N\n\n    results = []\n    for case in test_cases:\n        lle = calculate_lle(case['r'], case['x0'], case['M'], case['N'])\n        # Format the result to 6 decimal places as a string.\n        results.append(f\"{lle:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}