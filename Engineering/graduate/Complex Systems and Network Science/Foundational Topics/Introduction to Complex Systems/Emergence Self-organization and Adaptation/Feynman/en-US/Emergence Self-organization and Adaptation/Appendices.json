{
    "hands_on_practices": [
        {
            "introduction": "This first practice delves into the Kuramoto model, a cornerstone for understanding synchronization and a classic example of self-organization. By applying a self-consistent mean-field analysis, you will derive the exact critical coupling strength where a disordered population of oscillators spontaneously develops macroscopic coherence . This exercise is fundamental for building intuition on how local interaction rules can give rise to global, emergent order in a wide array of physical, biological, and social systems.",
            "id": "4274111",
            "problem": "Consider a population of $N$ phase oscillators with natural frequencies $\\{\\omega_i\\}_{i=1}^{N}$ drawn independently from a normalized, unimodal, even probability density function (PDF) $g(\\omega)$ that is continuous at $\\omega=0$ and satisfies $\\int_{-\\infty}^{\\infty} g(\\omega)\\,d\\omega = 1$. The oscillators evolve under all-to-all sinusoidal coupling according to the Kuramoto model\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin\\!\\big(\\theta_j - \\theta_i\\big),\n$$\nwhere $\\theta_i(t)\\in \\mathbb{R}$ is the phase of oscillator $i$ and $K\\ge 0$ is the uniform coupling strength. Define the complex order parameter\n$$\nz(t) \\;=\\; r(t)\\,\\exp\\!\\big(i\\psi(t)\\big) \\;=\\; \\frac{1}{N} \\sum_{j=1}^{N} \\exp\\!\\big(i\\theta_j(t)\\big),\n$$\nwith coherence $r(t)\\in[0,1]$ and mean phase $\\psi(t)\\in\\mathbb{R}$. In the thermodynamic limit $N\\to\\infty$, adopt the continuum description in terms of a phase density $f(\\theta,\\omega,t)$ for oscillators with frequency $\\omega$, satisfying $\\int_{0}^{2\\pi} f(\\theta,\\omega,t)\\,d\\theta = 1$ for each $\\omega$ and evolving under the continuity equation associated with the deterministic velocity field generated by the coupling.\n\nUsing self-consistent mean-field analysis, and starting from the above foundational definitions and laws, derive an explicit closed-form analytic expression for the critical coupling strength $K$ at which the incoherent state with $r=0$ loses stability and a nonzero coherence $r>0$ first emerges continuously. Express your final answer solely in terms of $g(0)$. No numerical approximation or rounding is required, and no physical units should be included in the final expression. Clearly state any regularity assumptions on $g(\\omega)$ that you use in the derivation and justify any limiting procedures involved in the onset analysis.",
            "solution": "The starting point is the Kuramoto model for a population of $N$ oscillators, described by the equations:\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i)\n$$\nThe complex order parameter $z(t) = r(t)e^{i\\psi(t)}$ is defined as $z(t) = \\frac{1}{N} \\sum_{j=1}^{N} e^{i\\theta_j(t)}$. We can rewrite the sine term using this definition.\nThe sum over $j$ is $\\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i) = \\sum_{j=1}^{N} \\text{Im}[e^{i(\\theta_j - \\theta_i)}] = \\text{Im}[e^{-i\\theta_i} \\sum_{j=1}^{N} e^{i\\theta_j}] = \\text{Im}[e^{-i\\theta_i} N z(t)]$.\nSubstituting $z(t) = r(t)e^{i\\psi(t)}$, this becomes $N \\cdot \\text{Im}[e^{-i\\theta_i} r(t)e^{i\\psi(t)}] = N r(t) \\sin(\\psi(t) - \\theta_i)$.\nThe equation of motion for a single oscillator is thus effectively coupled to the mean field represented by $r(t)$ and $\\psi(t)$:\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; K r(t) \\sin(\\psi(t) - \\theta_i)\n$$\nIn the thermodynamic limit $N\\to\\infty$, we describe the system using a probability density function $f(\\theta, \\omega, t)$ for oscillators with natural frequency $\\omega$ to have phase $\\theta$ at time $t$. The dynamics of any oscillator with frequency $\\omega$ is governed by the same mean-field equation:\n$$\n\\frac{d\\theta}{dt} \\;=\\; v(\\theta, \\omega, t) \\;=\\; \\omega \\;+\\; K r(t) \\sin(\\psi(t) - \\theta)\n$$\nThe order parameter is now given by an integral over all frequencies and phases:\n$$\nr(t)e^{i\\psi(t)} \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega, t) e^{i\\theta} d\\theta \\right] d\\omega\n$$\nWe seek a stationary solution where the coherence $r$ is constant and the mean phase $\\psi$ rotates at a constant frequency $\\Omega$, i.e., $\\psi(t) = \\Omega t + \\psi_0$. Due to the rotational symmetry of the system, we can move to a co-rotating frame by defining a new phase variable $\\phi = \\theta - \\psi(t)$. The mean phase in this frame is $0$. Since the given frequency distribution $g(\\omega)$ is even, its mean is already zero, which implies $\\Omega = 0$ for the stationary synchronized state. Thus, we can set $\\psi(t)=0$ and look for a time-independent solution.\n\nThe stationary velocity field is $v(\\theta, \\omega) = \\omega - K r \\sin(\\theta)$. The phase density $f(\\theta, \\omega)$ must satisfy the stationary continuity equation $\\frac{\\partial}{\\partial \\theta}[f \\cdot v] = 0$. This implies $f(\\theta, \\omega) \\cdot (\\omega - Kr\\sin\\theta)$ is a constant with respect to $\\theta$. For the density to be normalizable over the periodic domain $[0, 2\\pi]$, this constant must be zero. This leads to two types of solutions:\n1.  Locked oscillators: For these, $v(\\theta, \\omega) = 0$ at a stable phase $\\theta_s$. This requires $|\\omega| \\le Kr$. The stable fixed point is $\\theta_s = \\arcsin(\\omega / (Kr))$. The density is a delta function: $f(\\theta, \\omega) = \\delta(\\theta - \\arcsin(\\omega/(Kr)))$.\n2.  Drifting oscillators: For these, $|\\omega| > Kr$, the velocity $\\omega - Kr\\sin\\theta$ never becomes zero. The oscillators drift around the circle with a non-uniform speed. Their stationary distribution is $f(\\theta, \\omega) = \\frac{C}{\\omega - Kr\\sin\\theta}$, where $C$ is a normalization constant determined by $\\int_0^{2\\pi} f(\\theta, \\omega)d\\theta=1$. This gives $f(\\theta, \\omega) = \\frac{\\sqrt{\\omega^2 - (Kr)^2}}{2\\pi(\\omega - Kr\\sin\\theta)}$.\n\nThe self-consistency equation for the order parameter $r$ is obtained by substituting these stationary distributions back into the definition of $r$ (with $\\psi=0$, so $z=r$ is real):\n$$\nr \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\nThe integral splits into contributions from the locked ($|\\omega| \\le Kr$) and drifting ($|\\omega|>Kr$) subpopulations.\nWe are interested in the critical coupling strength $K_c$ where the incoherent state ($r=0$) loses stability and a coherent state ($r>0$) emerges continuously. This corresponds to the bifurcation point, which we can find by analyzing the self-consistency equation for arbitrarily small $r > 0$.\n\nFor $r \\to 0^+$, the interval of locked oscillators $[-Kr, Kr]$ becomes infinitesimally small.\nThe contribution from locked oscillators to the order parameter is:\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\left[ \\int_0^{2\\pi} \\delta\\left(\\theta - \\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\cos\\left(\\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) d\\omega = \\int_{-Kr}^{Kr} g(\\omega) \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\nThe contribution from drifting oscillators can be shown to be of order $O(r^3)$ or higher, and is thus negligible compared to the locked oscillators' contribution near the bifurcation point. We make the standard assumption that this contribution vanishes faster than $r$ as $r \\to 0$.\n\nAnalyzing the locked contribution for $r \\to 0^+$: the integration range $[-Kr, Kr]$ is very narrow. As $g(\\omega)$ is continuous at $\\omega=0$ (a given condition), we can approximate $g(\\omega) \\approx g(0)$ over this interval.\n$$\nr \\approx g(0) \\int_{-Kr}^{Kr} \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\nWe perform a change of variables: let $u = \\omega / (Kr)$, so $d\\omega = Kr \\, du$. The integration limits become $-1$ and $1$.\n$$\nr \\approx g(0) (Kr) \\int_{-1}^{1} \\sqrt{1 - u^2} \\, du\n$$\nThe integral $\\int_{-1}^{1} \\sqrt{1 - u^2} \\, du$ represents the area of a semicircle of radius $1$, which is $\\frac{1}{2}\\pi(1)^2 = \\frac{\\pi}{2}$.\nSubstituting this value back:\n$$\nr \\approx g(0) (Kr) \\frac{\\pi}{2}\n$$\nThis equation has two solutions for $r$. One is the trivial incoherent solution, $r=0$. A non-trivial solution for $r>0$ can exist if we can divide both sides by $r$:\n$$\n1 \\approx \\frac{K \\pi g(0)}{2}\n$$\nThis relationship must hold at the critical point $K=K_c$ where the non-zero solution first appears. Thus, we have an exact equality at the bifurcation point:\n$$\n1 = \\frac{K_c \\pi g(0)}{2}\n$$\nSolving for the critical coupling strength $K_c$:\n$$\nK_c = \\frac{2}{\\pi g(0)}\n$$\nThis derivation relies on the assumption that $g(\\omega)$ is continuous at $\\omega=0$, which was provided. The evenness of $g(\\omega)$ ensures the stationary state does not drift, simplifying the analysis. The unimodal property is typical but not strictly necessary for this specific calculation, as long as the distribution is well-behaved at the origin.",
            "answer": "$$\\boxed{\\frac{2}{\\pi g(0)}}$$"
        },
        {
            "introduction": "Our second exercise explores how stable, time-varying patterns can emerge from a previously static state, a process captured by the theory of Hopf bifurcations. You will analyze the canonical normal form of a system near such a bifurcation to determine the properties of the nascent limit cycle oscillation . This practice is key to understanding the origins of rhythmic phenomena, from chemical clocks to population cycles, revealing the mathematical mechanics behind the birth of temporal structure.",
            "id": "4274055",
            "problem": "Consider the planar autonomous dynamical system depending on a scalar control parameter $\\mu$,\n$$\n\\begin{cases}\n\\dot{x} \\,=\\, \\mu x \\,-\\, \\omega_{0} y \\,+\\, \\alpha\\, x\\,(x^{2}+y^{2}) \\,-\\, \\beta\\, y\\,(x^{2}+y^{2}),\\\\[6pt]\n\\dot{y} \\,=\\, \\omega_{0} x \\,+\\, \\mu y \\,+\\, \\beta\\, x\\,(x^{2}+y^{2}) \\,+\\, \\alpha\\, y\\,(x^{2}+y^{2}),\n\\end{cases}\n$$\nwith constants $\\omega_{0} \\,=\\, \\sqrt{5}$, $\\alpha \\,=\\, -\\tfrac{1}{3}$, and $\\beta \\,=\\, \\tfrac{2}{5}$. The origin is an equilibrium for all $\\mu$. This model, which is rotation-equivariant, serves as a minimal normal-form description of emergent oscillations near onset in many self-organizing systems.\n\nUsing only the following foundational bases:\n- the definition of a Hopf bifurcation in terms of the Jacobian eigenvalues crossing the imaginary axis with nonzero speed and nondegeneracy of the first nonlinear terms on the center manifold, and\n- standard coordinate transformations for planar flows (e.g., to complex and polar coordinates),\n\nperform the following tasks:\n- Derive from the Jacobian at the origin the conditions under which a Hopf bifurcation occurs as $\\mu$ varies, and identify the critical parameter value at which the linearization has purely imaginary eigenvalues. Verify the transversality condition.\n- Using center manifold and normal form theory, obtain the leading-order amplitude $r^{\\ast}(\\mu)$ and angular frequency $\\omega(\\mu)$ of the emergent stable limit cycle that arises for small positive $\\mu$.\n\nExpress the final amplitude $r^{\\ast}(\\mu)$ and angular frequency $\\omega(\\mu)$ as closed-form analytic expressions in terms of $\\mu$. No rounding is required. Report both quantities together as your final answer. Do not include units. Angles are assumed to be in radians.",
            "solution": "The analysis proceeds in two parts: first, a linear stability analysis of the origin to identify the Hopf bifurcation, and second, a nonlinear analysis using a coordinate transformation to determine the properties of the emergent limit cycle.\n\n**Linear Stability and Hopf Bifurcation**\nThe Jacobian matrix $J$ of the system is evaluated at the equilibrium point $(0, 0)$. The partial derivatives at the origin are:\n$$\n\\frac{\\partial \\dot{x}}{\\partial x}\\bigg|_{(0,0)} = \\mu, \\quad \\frac{\\partial \\dot{x}}{\\partial y}\\bigg|_{(0,0)} = -\\omega_0\n$$\n$$\n\\frac{\\partial \\dot{y}}{\\partial x}\\bigg|_{(0,0)} = \\omega_0, \\quad \\frac{\\partial \\dot{y}}{\\partial y}\\bigg|_{(0,0)} = \\mu\n$$\nThe Jacobian at the origin is therefore:\n$$\nJ(0,0) = \\begin{pmatrix} \\mu & -\\omega_0 \\\\ \\omega_0 & \\mu \\end{pmatrix}\n$$\nThe eigenvalues $\\lambda$ are found from the characteristic equation $\\det(J(0,0) - \\lambda I) = 0$, which gives $(\\mu - \\lambda)^2 + \\omega_0^2 = 0$. Solving for $\\lambda$ yields a complex conjugate pair:\n$$\n\\lambda = \\mu \\pm i\\omega_0\n$$\nA Hopf bifurcation occurs when the real part of the eigenvalues crosses zero as the parameter $\\mu$ varies. Here, $\\text{Re}(\\lambda) = \\mu$. The critical value is therefore $\\mu_c = 0$, at which point the eigenvalues are purely imaginary, $\\lambda = \\pm i\\omega_0$. Since $\\omega_0 = \\sqrt{5} \\neq 0$, the condition is met. The transversality condition, $\\frac{d}{d\\mu} \\text{Re}(\\lambda(\\mu)) |_{\\mu=\\mu_c} = 1 \\neq 0$, is also satisfied. For $\\mu < 0$, the origin is a stable focus, and for $\\mu > 0$, it becomes an unstable focus, confirming a Hopf bifurcation at $\\mu_c=0$.\n\n**Normal Form Analysis and Limit Cycle Properties**\nTo analyze the nonlinear behavior, we convert the system to polar coordinates using $x = r \\cos(\\theta)$ and $y = r \\sin(\\theta)$. The dynamics of the radius $r$ and angle $\\theta$ are found using $r\\dot{r} = x\\dot{x} + y\\dot{y}$ and $r^2\\dot{\\theta} = x\\dot{y} - y\\dot{x}$.\nSubstituting the system equations:\n$$\nx\\dot{x} + y\\dot{y} = x(\\mu x - \\omega_0 y + \\dots) + y(\\omega_0 x + \\mu y + \\dots) = \\mu(x^2+y^2) + \\alpha(x^2+y^2)^2 = \\mu r^2 + \\alpha r^4\n$$\nDividing by $r$ (for $r \\neq 0$) gives the radial equation:\n$$\n\\dot{r} = \\mu r + \\alpha r^3\n$$\nSimilarly for the angular equation:\n$$\nx\\dot{y} - y\\dot{x} = x(\\omega_0 x + \\mu y + \\dots) - y(\\mu x - \\omega_0 y + \\dots) = \\omega_0(x^2+y^2) + \\beta(x^2+y^2)^2 = \\omega_0 r^2 + \\beta r^4\n$$\nDividing by $r^2$ (for $r \\neq 0$) gives the angular equation:\n$$\n\\dot{\\theta} = \\omega_0 + \\beta r^2\n$$\nA limit cycle corresponds to a non-zero steady-state radius $r^{\\ast}$, found by setting $\\dot{r} = 0$:\n$$\n\\mu r^{\\ast} + \\alpha (r^{\\ast})^3 = 0 \\implies r^{\\ast}(\\mu + \\alpha (r^{\\ast})^2) = 0\n$$\nThe non-trivial solution is $(r^{\\ast})^2 = -\\frac{\\mu}{\\alpha}$. Given $\\alpha = -1/3$, this becomes $(r^{\\ast})^2 = 3\\mu$. A real solution exists for $\\mu > 0$. The amplitude is:\n$$\nr^{\\ast}(\\mu) = \\sqrt{3\\mu}\n$$\nThe bifurcation is supercritical because $\\alpha  0$, meaning the limit cycle is stable for $\\mu > 0$.\nThe angular frequency $\\omega(\\mu)$ on this limit cycle is found by substituting $r=r^{\\ast}$ into the equation for $\\dot{\\theta}$:\n$$\n\\omega(\\mu) = \\omega_0 + \\beta (r^{\\ast})^2 = \\omega_0 + \\beta \\left(-\\frac{\\mu}{\\alpha}\\right) = \\omega_0 - \\frac{\\beta}{\\alpha}\\mu\n$$\nSubstituting the constant values $\\omega_0 = \\sqrt{5}$, $\\alpha = -1/3$, and $\\beta = 2/5$:\n$$\n\\omega(\\mu) = \\sqrt{5} - \\frac{2/5}{-1/3}\\mu = \\sqrt{5} + \\frac{6}{5}\\mu\n$$\nThus, the emergent stable limit cycle has an amplitude $r^{\\ast}(\\mu) = \\sqrt{3\\mu}$ and angular frequency $\\omega(\\mu) = \\sqrt{5} + \\frac{6}{5}\\mu$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{3\\mu}  \\sqrt{5} + \\frac{6}{5}\\mu \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "This final practice transitions from analytical theory to computational methods, addressing a critical question in the study of complex systems: is an observed pattern a genuine signature of self-organization, or could it have arisen by chance? You will implement a rigorous statistical test using a degree-preserving null model to determine if a network's clustering is significantly non-random . Mastering this technique is essential for making data-driven claims about emergent structure in real-world networks.",
            "id": "4274115",
            "problem": "You are given the task of formalizing and testing the claim that an observed macro-pattern in a network requires self-organization rather than arising from random aggregation. Consider an undirected simple graph without self-loops, represented by an adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ that is symmetric with zero diagonal. The nodes are indexed by $\\{0,1,\\dots,n-1\\}$, and edges are unordered pairs $\\{i,j\\}$ for $i \\neq j$. The degree sequence is $k_i = \\sum_{j=0}^{n-1} A_{ij}$.\n\nThe fundamental base of your derivation must employ the following standard definitions:\n- A triangle is a set of three nodes $\\{i,j,\\ell\\}$ with all three edges present among them. The total number of triangles in $A$ is $T = \\frac{1}{6} \\mathrm{tr}(A^3)$.\n- A connected triple (also called a wedge) is a path of length two centered at a node, counted as $\\binom{k_i}{2}$ for node $i$. The total number of connected triples is $W = \\sum_{i=0}^{n-1} \\binom{k_i}{2} = \\frac{1}{2} \\sum_{i=0}^{n-1} k_i (k_i - 1)$.\n- The global clustering coefficient (also called transitivity) is defined as $C = \\frac{3T}{W}$, with the convention that if $W = 0$, then $C = 0$.\n\nTo test whether an observed macro-pattern (here, elevated clustering) requires self-organization, construct a null model that matches only trivial statistics but lacks interaction mechanisms. Use the degree-preserving random edge-swap model (also known as the Maslov–Sneppen rewiring) to sample random graphs uniformly from the space of simple graphs with the same degree sequence as the observed network. This null model preserves the degree sequence and edge count, but erases local interaction structure by repeatedly swapping endpoints of randomly chosen edge pairs while forbidding self-loops and multi-edges.\n\nFor each observed network, estimate the empirical null distribution of $C$ by generating $R$ independent samples from the null model, and compute:\n- The empirical $p$-value $p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$, where $C^{(r)}$ is the clustering coefficient of the $r$-th null sample and $C^{\\mathrm{obs}}$ is the observed clustering coefficient.\n- The standardized effect size $z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$, where $\\mu$ and $\\sigma$ are the mean and standard deviation of the null distribution of $C$. If $\\sigma = 0$, define $z = +\\infty$ if $C^{\\mathrm{obs}}  \\mu$, and $z = -\\infty$ otherwise.\n\nDecision rule: Conclude that the macro-pattern requires self-organization if and only if $p  \\alpha$ and $z \\ge z_{\\mathrm{thr}}$, with $\\alpha = 0.05$ and $z_{\\mathrm{thr}} = 2$.\n\nImplement the following generative procedures for observed networks (all graphs are undirected, simple, and unweighted):\n- Ring-lattice: For parameters $(n,k)$ with $k$ even and $k \\ll n$, connect each node $i$ to its $k/2$ nearest neighbors on either side on the ring, creating edges $(i,(i+d)\\bmod n)$ for $d = 1,2,\\dots,k/2$.\n- Degree-preserving randomization: Starting from the ring-lattice with the same $(n,k)$, perform repeated degree-preserving edge swaps to erase local structure while keeping the degree sequence.\n- Preferential attachment tree: Initialize with a single edge among two nodes. For each new node until there are $n$ nodes, attach it to one existing node chosen with probability proportional to its current degree, producing a tree (Barabási–Albert model with parameter $m=1$).\n- Two-dimensional grid with diagonals: For parameters $(s_x,s_y)$, construct a rectangular lattice of $n = s_x s_y$ nodes with edges between horizontal and vertical neighbors, and add diagonal edges of each cell to create triangles (e.g., add edges from $(x,y)$ to $(x+1,y+1)$ where valid).\n\nYour program must implement:\n- Exact computation of $T$, $W$, and $C$ for any given $A$.\n- Null sampling via degree-preserving edge swaps, starting from the observed $A$. Use $S$ swaps per null sample, with $S$ set proportional to the number of edges $m$ (for example, $S = 10m$).\n- Empirical $p$-value and $z$-score computation and the decision rule specified above.\n\nTest suite. For each of the following parameter sets, construct the corresponding observed network, run the null-model test with $R = 64$ samples, $\\alpha = 0.05$, $z_{\\mathrm{thr}} = 2$, and $S = 10m$ swaps per null sample, and output a boolean indicating whether self-organization is required:\n- Case $1$ (self-organized via local clustering): Ring-lattice with $(n,k) = (60,4)$.\n- Case $2$ (random aggregation with matched degrees): Degree-preserving randomization of the ring-lattice from Case $1$ using $S = 20m$ swaps to produce the observed network.\n- Case $3$ (sparse tree without triadic closure): Preferential attachment tree with $n = 60$, parameter $m = 1$.\n- Case $4$ (locally clustered planar structure): Two-dimensional grid with diagonals for $(s_x,s_y) = (7,7)$, so $n = 49$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Cases $1$ through $4$, for example, $[r_1,r_2,r_3,r_4]$, where each $r_i$ is a boolean computed according to the decision rule.",
            "solution": "The problem requires us to formalize and apply a statistical hypothesis test to determine if an observed network pattern, specifically high clustering, is a result of self-organization or could have arisen from a random process constrained by basic network properties. This is a fundamental question in complex systems, where emergent macro-patterns are often distinguished from trivial aggregation by comparing them against a suitable null model.\n\nThe core of the methodology is a hypothesis test. The null hypothesis, $H_0$, posits that the observed network is a random realization from an ensemble of graphs that only share the same degree sequence as the observed network. The alternative hypothesis, $H_1$, is that the network possesses additional structure—in this case, significantly higher clustering—not explained by the degree sequence alone. Such excess structure is interpreted as a signature of self-organization, i.e., non-random interaction rules.\n\nThe chosen test statistic is the global clustering coefficient, $C$, which quantifies the tendency of nodes to form triangles. It is defined as the ratio of \"closed\" triples (triangles) to all connected triples (wedges).\n- The number of triangles, $T$, is given by $T = \\frac{1}{6} \\mathrm{tr}(A^3)$, where $A$ is the adjacency matrix. The term $A^3_{ii}$ counts the number of paths of length $3$ from node $i$ back to itself. Each triangle involving node $i$ contributes two such paths (one clockwise, one counter-clockwise). Since this is counted for each of the $3$ nodes in a triangle, and the trace sums these counts, we divide by $3 \\times 2 = 6$.\n- The number of connected triples (or wedges), $W$, centered at node $i$ is the number of pairs of edges connected to $i$, which is $\\binom{k_i}{2}$, where $k_i$ is the degree of node $i$. Summing over all nodes gives the total number of wedges: $W = \\sum_{i=0}^{n-1} \\binom{k_i}{2}$.\n- The global clustering coefficient is then $C = \\frac{3T}{W}$. The factor of $3$ normalizes the ratio, as one triangle consists of three closed wedges.\n\nTo test the null hypothesis, we generate a null distribution of the statistic $C$. This is done using the degree-preserving random edge-swap model (Maslov–Sneppen rewiring). This procedure starts with the observed network and repeatedly swaps the endpoints of two randomly chosen edges, say $\\{i, j\\}$ and $\\{u, v\\}$, to form new edges $\\{i, v\\}$ and $\\{u, j\\}$, provided these new edges do not already exist and do not create self-loops. This process randomizes the network's topology while preserving the degree of every node, thereby creating an ensemble of random graphs that match the observed network's degree sequence exactly. This is crucial because many network properties, including clustering, are strongly influenced by the degree sequence. By preserving it, we isolate the effect of higher-order correlations beyond degrees.\n\nFor each of the $R$ random graphs generated by this process, we compute its clustering coefficient $C^{(r)}$. This ensemble of values $\\{C^{(1)}, C^{(2)}, \\dots, C^{(R)}\\}$ constitutes an empirical null distribution. We then compare the observed clustering coefficient, $C^{\\text{obs}}$, to this distribution using two metrics:\n\n1.  **The empirical $p$-value**: $p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$. This measures the probability of observing a clustering coefficient at least as large as $C^{\\text{obs}}$ under the null hypothesis. The `+1` terms are a standard correction to avoid $p=0$ and to account for the observed sample itself. A small $p$-value indicates that the observed clustering is surprisingly high.\n2.  **The standardized effect size ($z$-score)**: $z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$, where $\\mu$ and $\\sigma$ are the mean and standard deviation of the null distribution. The $z$-score measures how many standard deviations the observed value is from the mean of the null distribution. A large positive $z$-score indicates a large effect size.\n\nThe decision rule is to declare the pattern a result of self-organization if it is both statistically significant ($p  \\alpha$) and has a sufficiently large effect size ($z \\ge z_{\\mathrm{thr}}$), with given thresholds $\\alpha=0.05$ and $z_{\\mathrm{thr}}=2$.\n\nA computational framework is implemented to test four distinct network models:\n- **Case 1: Ring-lattice $(n=60, k=4)$**: Each node is connected to its nearest and next-nearest neighbors on a ring. This creates a regular, locally ordered structure. In this k=4 lattice, triangles are common (e.g., the set of nodes $\\{i, i+1, i+2\\}$ forms a triangle). This results in a high $C^{\\text{obs}}$. This structure is not expected in a random graph with the same degrees, so we anticipate rejecting the null hypothesis (Result: `True`).\n- **Case 2: Randomized ring-lattice**: This network is explicitly constructed by taking the ring-lattice from Case 1 and performing a large number of degree-preserving swaps. By construction, it is a sample from the null model ensemble. Therefore, its $C^{\\text{obs}}$ should be typical for the null distribution, leading to a high $p$-value and a $z$-score near $0$. We anticipate failing to reject the null hypothesis (Result: `False`).\n- **Case 3: Preferential attachment tree $(n=60, m=1)$**: This generates a tree structure, which by definition has no cycles and thus no triangles. Therefore, $T^{\\text{obs}}=0$ and $C^{\\text{obs}}=0$. The null model graphs, having the same heterogeneous degree sequence, will almost certainly contain some triangles formed by chance. Thus, $C^{(r)}$ will likely be greater than $C^{\\text{obs}}$ for all null samples, leading to $p \\approx 1$ and a negative $z$-score. We anticipate failing to reject the null hypothesis (Result: `False`).\n- **Case 4: 2D grid with diagonals $((s_x,s_y)=(7,7))$**: This network models a spatially embedded system with local connections. The grid structure with added diagonals creates a high density of triangles. For instance, adding an edge between nodes $(x,y)$ and $(x+1,y+1)$ to a grid cell creates two triangles: $((x,y), (x+1,y), (x+1,y+1))$ and $((x,y), (x,y+1), (x+1,y+1))$. This highly clustered structure is a form of self-organization (based on spatial proximity) and is not expected to arise from a random rewiring process. We anticipate rejecting the null hypothesis (Result: `True`).\n\nThe implementation proceeds by first generating the adjacency matrix for each case. Then, for each matrix, a testing function calculates its observed clustering coefficient $C^{\\text{obs}}$, generates $R=64$ null model samples through rewiring, calculates the null distribution of $C$, and finally computes the $p$-value and $z$-score to apply the decision rule.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the four test cases and print the results.\n    \"\"\"\n    np.random.seed(42)  # For reproducibility\n\n    # Define test case parameters\n    alpha = 0.05\n    z_thr = 2.0\n    R = 64\n    S_multiplier_null = 10\n\n    results = []\n\n    # Case 1: Ring-lattice\n    n1, k1 = 60, 4\n    A1 = generate_ring_lattice(n1, k1)\n    res1 = run_null_model_test(A1, R, alpha, z_thr, S_multiplier_null)\n    results.append(res1)\n\n    # Case 2: Randomized ring-lattice\n    m2 = (n1 * k1) // 2\n    S_randomize = 20 * m2\n    A2 = degree_preserving_swap(A1.copy(), S_randomize)\n    res2 = run_null_model_test(A2, R, alpha, z_thr, S_multiplier_null)\n    results.append(res2)\n\n    # Case 3: Preferential attachment tree\n    n3 = 60\n    A3 = generate_pa_tree(n3)\n    res3 = run_null_model_test(A3, R, alpha, z_thr, S_multiplier_null)\n    results.append(res3)\n\n    # Case 4: 2D grid with diagonals\n    sx4, sy4 = 7, 7\n    A4 = generate_grid_with_diagonals(sx4, sy4)\n    res4 = run_null_model_test(A4, R, alpha, z_thr, S_multiplier_null)\n    results.append(res4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef calculate_c(A):\n    \"\"\"\n    Calculates the global clustering coefficient C for a graph with adjacency matrix A.\n    \"\"\"\n    if A.shape[0]  3:\n        return 0.0\n        \n    # Using np.linalg.matrix_power for A^3\n    A_cubed = np.linalg.matrix_power(A.astype(np.float64), 3)\n    T = np.trace(A_cubed) / 6.0\n    \n    k = A.sum(axis=1)\n    # Filter degrees less than 2, as they don't contribute to wedges\n    k_ge_2 = k[k = 2]\n    W = np.sum(k_ge_2 * (k_ge_2 - 1.0)) / 2.0\n    \n    if W == 0:\n        return 0.0\n    \n    return (3.0 * T) / W\n\ndef degree_preserving_swap(A, num_swaps):\n    \"\"\"\n    Performs degree-preserving random edge swaps (Maslov-Sneppen rewiring).\n    \"\"\"\n    n = A.shape[0]\n    A_rewired = A.copy()\n    \n    # Get edge set for efficient lookups and modification\n    # Use tuples with sorted nodes to have a canonical representation\n    edge_set = {tuple(sorted(edge)) for edge in np.argwhere(np.triu(A_rewired))}\n\n    if not edge_set or len(edge_set)  2:\n        return A_rewired\n\n    edges_list = list(edge_set)\n    m = len(edges_list)\n    \n    swaps_done = 0\n    attempts = 0\n    max_attempts = num_swaps * 10 # To avoid infinite loops in dense graphs\n\n    while swaps_done  num_swaps and attempts  max_attempts:\n        attempts += 1\n        \n        # Choose two distinct edges\n        idx1, idx2 = np.random.choice(m, 2, replace=False)\n        e1 = edges_list[idx1]\n        e2 = edges_list[idx2]\n        \n        i, j = e1\n        u, v = e2\n\n        # Ensure all four nodes are distinct\n        if len({i, j, u, v}) != 4:\n            continue\n\n        # Propose new edges (i,v) and (u,j). Sorting for canonical check.\n        new_e1 = tuple(sorted((i, v)))\n        new_e2 = tuple(sorted((u, j)))\n\n        # Check if new edges would create multi-edges\n        if new_e1 in edge_set or new_e2 in edge_set:\n            continue\n        \n        # Perform the swap\n        # Remove old edges from matrix and set\n        A_rewired[i, j] = A_rewired[j, i] = 0\n        A_rewired[u, v] = A_rewired[v, u] = 0\n        edge_set.remove(e1)\n        edge_set.remove(e2)\n        \n        # Add new edges to matrix and set\n        A_rewired[i, v] = A_rewired[v, i] = 1\n        A_rewired[u, j] = A_rewired[j, u] = 1\n        edge_set.add(new_e1)\n        edge_set.add(new_e2)\n        \n        # Update the list from which we sample\n        edges_list[idx1] = new_e1\n        edges_list[idx2] = new_e2\n\n        swaps_done += 1\n        \n    return A_rewired\n\n\ndef run_null_model_test(A_obs, R, alpha, z_thr, S_multiplier):\n    \"\"\"\n    Runs the null model test and returns the decision.\n    \"\"\"\n    C_obs = calculate_c(A_obs)\n    \n    m = np.sum(np.triu(A_obs))\n    num_swaps = int(S_multiplier * m)\n\n    C_null_dist = []\n    for _ in range(R):\n        A_rewired = degree_preserving_swap(A_obs.copy(), num_swaps)\n        C_null = calculate_c(A_rewired)\n        C_null_dist.append(C_null)\n        \n    C_null_dist = np.array(C_null_dist)\n    \n    # Calculate p-value\n    ge_count = np.sum(C_null_dist = C_obs)\n    p_value = (1.0 + ge_count) / (R + 1.0)\n    \n    # Calculate z-score\n    mu = np.mean(C_null_dist)\n    sigma = np.std(C_null_dist)\n    \n    if sigma == 0:\n        if C_obs  mu:\n            z_score = np.inf\n        else: # Covers C_obs = mu\n            z_score = -np.inf\n    else:\n        z_score = (C_obs - mu) / sigma\n\n    # Decision rule\n    return p_value  alpha and z_score = z_thr\n\n# --- Graph Generation Functions ---\n\ndef generate_ring_lattice(n, k):\n    A = np.zeros((n, n), dtype=int)\n    for i in range(n):\n        for d in range(1, k // 2 + 1):\n            j = (i + d) % n\n            A[i, j] = A[j, i] = 1\n    return A\n\ndef generate_pa_tree(n):\n    A = np.zeros((n, n), dtype=int)\n    if n  2:\n        return A\n    \n    # Initial state: edge between node 0 and 1\n    A[0, 1] = A[1, 0] = 1\n    edge_endpoints = [0, 1]\n    \n    for i in range(2, n):\n        # This samples a node with probability proportional to its degree\n        target_node = np.random.choice(edge_endpoints)\n        A[i, target_node] = A[target_node, i] = 1\n        edge_endpoints.extend([i, target_node])\n        \n    return A\n\ndef generate_grid_with_diagonals(sx, sy):\n    n = sx * sy\n    A = np.zeros((n, n), dtype=int)\n    \n    for y in range(sy):\n        for x in range(sx):\n            i = x + y * sx\n            \n            # Horizontal neighbor\n            if x  sx - 1:\n                j_h = (x + 1) + y * sx\n                A[i, j_h] = A[j_h, i] = 1\n                \n            # Vertical neighbor\n            if y  sy - 1:\n                j_v = x + (y + 1) * sx\n                A[i, j_v] = A[j_v, i] = 1\n            \n            # Diagonal neighbor: (x,y) to (x+1,y+1)\n            if x  sx - 1 and y  sy - 1:\n                j_d = (x + 1) + (y + 1) * sx\n                A[i, j_d] = A[j_d, i] = 1\n                \n    return A\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}