{
    "hands_on_practices": [
        {
            "introduction": "同步现象，从萤火虫的同步闪烁到神经网络的节律性放电，是自然界中自组织的一个典型范例。Kuramoto模型是研究这一现象的基石。该练习  将引导你运用自洽平均场分析，推导出一个由无序振子组成的系统如何通过相互作用自发涌现出宏观同步状态的关键阈值。",
            "id": "4274111",
            "problem": "考虑一个由 $N$ 个相位振子组成的群体，其自然频率 $\\{\\omega_i\\}_{i=1}^{N}$ 独立地从一个归一化的、单峰的、偶概率密度函数 (PDF) $g(\\omega)$ 中抽取，该函数在 $\\omega=0$ 处连续且满足 $\\int_{-\\infty}^{\\infty} g(\\omega)\\,d\\omega = 1$。这些振子在全局正弦耦合下根据Kuramoto模型进行演化\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin\\!\\big(\\theta_j - \\theta_i\\big),\n$$\n其中 $\\theta_i(t)\\in \\mathbb{R}$ 是振子 $i$ 的相位，$K\\ge 0$ 是均匀耦合强度。定义复序参量\n$$\nz(t) \\;=\\; r(t)\\,\\exp\\!\\big(i\\psi(t)\\big) \\;=\\; \\frac{1}{N} \\sum_{j=1}^{N} \\exp\\!\\big(i\\theta_j(t)\\big),\n$$\n其中 $r(t)\\in[0,1]$ 是相干性，$ψ(t)\\in\\mathbb{R}$ 是平均相位。在热力学极限 $N\\to\\infty$ 下，采用连续谱描述，以频率为 $\\omega$ 的振子的相位密度 $f(\\theta,\\omega,t)$ 表示，该密度对每个 $\\omega$ 满足 $\\int_{0}^{2\\pi} f(\\theta,\\omega,t)\\,d\\theta = 1$，并在由耦合产生的确定性速度场相关的连续性方程下演化。\n\n使用自洽平均场分析，并从上述基本定义和定律出发，推导当 $r=0$ 的非相干态失去稳定性且一个非零相干性 $r>0$ 首次连续出现时的临界耦合强度 $K$ 的显式闭式解析表达式。你的最终答案应仅用 $g(0)$ 表示。不需要进行数值近似或舍入，且最终表达式中不应包含任何物理单位。请清楚地说明你在推导中使用的关于 $g(\\omega)$ 的任何正则性假设，并证明在起始分析中涉及的任何极限过程的合理性。",
            "solution": "出发点是描述 $N$ 个振子群体的Kuramoto模型，其方程为：\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i)\n$$\n复序参量 $z(t) = r(t)e^{i\\psi(t)}$ 定义为 $z(t) = \\frac{1}{N} \\sum_{j=1}^{N} e^{i\\theta_j(t)}$。我们可以利用这个定义来重写正弦项。\n对 $j$ 的求和为 $\\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i) = \\sum_{j=1}^{N} \\text{Im}[e^{i(\\theta_j - \\theta_i)}] = \\text{Im}[e^{-i\\theta_i} \\sum_{j=1}^{N} e^{i\\theta_j}] = \\text{Im}[e^{-i\\theta_i} N z(t)]$。\n代入 $z(t) = r(t)e^{i\\psi(t)}$，这变为 $N \\cdot \\text{Im}[e^{-i\\theta_i} r(t)e^{i\\psi(t)}] = N r(t) \\sin(\\psi(t) - \\theta_i)$。\n因此，单个振子的运动方程有效地与由 $r(t)$ 和 $\\psi(t)$ 代表的平均场耦合：\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; K r(t) \\sin(\\psi(t) - \\theta_i)\n$$\n在热力学极限 $N\\to\\infty$下，我们使用概率密度函数 $f(\\theta, \\omega, t)$ 来描述系统，该函数表示自然频率为 $\\omega$ 的振子在时间 $t$ 具有相位 $\\theta$ 的概率。任何频率为 $\\omega$ 的振子的动力学都由相同的平均场方程决定：\n$$\n\\frac{d\\theta}{dt} \\;=\\; v(\\theta, \\omega, t) \\;=\\; \\omega \\;+\\; K r(t) \\sin(\\psi(t) - \\theta)\n$$\n序参量现在由一个对所有频率和相位的积分给出：\n$$\nr(t)e^{i\\psi(t)} \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega, t) e^{i\\theta} d\\theta \\right] d\\omega\n$$\n我们寻找一个定态解，其中相干性 $r$ 是常数，平均相位 $\\psi$ 以恒定频率 $\\Omega$ 旋转，即 $\\psi(t) = \\Omega t + \\psi_0$。由于系统的旋转对称性，我们可以通过定义一个新的相位变量 $\\phi = \\theta - \\psi(t)$ 来移动到一个同转坐标系。在这个坐标系中，平均相位为 0。不失一般性，我们通过对所有 $\\omega_i$ 进行适当平移，假设总平均频率为零。由于给定的频率分布 $g(\\omega)$ 是偶函数，其均值已经为零，这意味着对于定态同步态 $\\Omega = 0$。因此，我们可以设 $\\psi(t)=0$ 并寻找一个不依赖时间的解。\n\n定态速度场为 $v(\\theta, \\omega) = \\omega - K r \\sin(\\theta)$。相位密度 $f(\\theta, \\omega)$ 必须满足定态连续性方程 $\\frac{\\partial}{\\partial \\theta}[f \\cdot v] = 0$。这意味着 $f(\\theta, \\omega) \\cdot (\\omega - Kr\\sin\\theta)$ 关于 $\\theta$ 是一个常数。为了使密度在周期域 $[0, 2\\pi]$ 上可归一化，这个常数必须为零。这导致两种类型的解：\n1.  锁定振子：对于这些振子，$v(\\theta, \\omega) = 0$ 在一个稳定相位 $\\theta_s$ 处。这要求 $|\\omega| \\le Kr$。稳定不动点是 $\\theta_s = \\arcsin(\\omega / (Kr))$。其密度是一个狄拉克δ函数：$f(\\theta, \\omega) = \\delta(\\theta - \\arcsin(\\omega/(Kr)))$。\n2.  漂移振子：对于这些振子，$|\\omega| > Kr$，速度 $\\omega - Kr\\sin\\theta$ 永远不会变为零。这些振子以非均匀的速度绕圆周漂移。它们的定态分布是 $f(\\theta, \\omega) = \\frac{C}{\\omega - Kr\\sin\\theta}$，其中 $C$ 是由 $\\int_0^{2\\pi} f(\\theta, \\omega)d\\theta=1$ 决定的归一化常数。这得到 $f(\\theta, \\omega) = \\frac{\\sqrt{\\omega^2 - (Kr)^2}}{2\\pi(\\omega - Kr\\sin\\theta)}$。\n\n序参量 $r$ 的自洽方程是通过将这些定态分布代回到 $r$ 的定义（其中 $\\psi=0$，所以 $z=r$ 是实数）中得到的：\n$$\nr \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\n该积分分裂为来自锁定 ($|\\omega| \\le Kr$) 和漂移 ($|\\omega|>Kr$) 子群体的贡献。\n我们感兴趣的是临界耦合强度 $K_c$，在该点非相干态（$r=0$）失去稳定性，而相干态（$r>0$）连续出现。这对应于分岔点，我们可以通过分析对于任意小的 $r > 0$ 的自洽方程来找到它。\n\n对于 $r \\to 0^+$，锁定振子的区间 $[-Kr, Kr]$ 变得无穷小。\n锁定振子对序参量的贡献是：\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\left[ \\int_0^{2\\pi} \\delta\\left(\\theta - \\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\cos\\left(\\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) d\\omega = \\int_{-Kr}^{Kr} g(\\omega) \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\n可以证明，漂移振子的贡献是 $O(r^3)$ 或更高阶的，因此在分岔点附近与锁定振子的贡献相比可以忽略不计。我们做出标准假设，即当 $r \\to 0$ 时，这一贡献比 $r$ 更快地消失。\n\n分析 $r \\to 0^+$ 时锁定部分的贡献：积分区间 $[-Kr, Kr]$ 非常窄。由于 $g(\\omega)$ 在 $\\omega=0$ 处连续（给定条件），我们可以将此区间内的 $g(\\omega)$ 近似为 $g(0)$。\n$$\nr \\approx g(0) \\int_{-Kr}^{Kr} \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\n我们进行变量替换：令 $u = \\omega / (Kr)$，则 $d\\omega = Kr \\, du$。积分上下限变为 $-1$ 和 $1$。\n$$\nr \\approx g(0) (Kr) \\int_{-1}^{1} \\sqrt{1 - u^2} \\, du\n$$\n积分 $\\int_{-1}^{1} \\sqrt{1 - u^2} \\, du$ 代表半径为1的半圆面积，即 $\\frac{1}{2}\\pi(1)^2 = \\frac{\\pi}{2}$。\n将这个值代回：\n$$\nr \\approx g(0) (Kr) \\frac{\\pi}{2}\n$$\n这个方程有两个关于 $r$ 的解。一个是平凡的非相干解，$r=0$。如果我们可以用 $r$ 除以方程两边，就可以存在一个 $r>0$ 的非平凡解。\n$$\n1 \\approx \\frac{K \\pi g(0)}{2}\n$$\n这个关系必须在临界点 $K=K_c$ 处成立，即非零解首次出现的地方。因此，我们在分岔点有精确等式：\n$$\n1 = \\frac{K_c \\pi g(0)}{2}\n$$\n解出临界耦合强度 $K_c$：\n$$\nK_c = \\frac{2}{\\pi g(0)}\n$$\n此推导依赖于 $g(\\omega)$ 在 $\\omega=0$ 处连续的假设，这是一个已知条件。$g(\\omega)$ 的偶函数性质确保了定态不发生漂移，从而简化了分析。单峰性质是典型的，但对于此特定计算并非严格必需，只要该分布在原点附近是良态的即可。",
            "answer": "$$\\boxed{\\frac{2}{\\pi g(0)}}$$"
        },
        {
            "introduction": "在生物和社会系统中，适应是塑造行为和策略演化的核心过程。演化博弈论为我们理解这一过程提供了强大的数学框架。通过这个练习 ，你将通过分析复制子动态方程，亲自推导出在一个由竞争策略组成的种群中，一个稳定的混合策略（即演化稳定策略，ESS）是如何作为一种涌现的适应性结果而形成的。",
            "id": "4274006",
            "problem": "考虑一个无限大、充分混合的种群，其个体进行重复的、随机的成对相互作用。这种相互作用由一个对称的 $2\\times 2$ 博弈描述，其支付矩阵为 $A=\\begin{pmatrix}a  b\\\\ c  d\\end{pmatrix}$，其中 $a$、$b$、$c$ 和 $d$ 是实数参数。设种群状态为策略1的频率 $x\\in[0,1]$（以及策略2的频率 $1-x$）。假设适应过程通过演化博弈论中的复制动态进行，其中一个策略频率的增长率与其相对于种群平均支付的支付优势成正比。演化稳定策略（ESS）是一种种群构成 $x^{\\ast}$，使得当几乎所有个体都按照 $x^{\\ast}$ 行动时，任何足够小比例的突变者获得的期望支付都严格较低。\n\n从期望支付和复制动态的定义出发，并且不使用任何现成的公式，完成以下任务：\n\n1. 推导每个策略的期望支付作为 $x$ 的函数，并写出描述 $x(t)$ 的一维复制方程。\n2. 证明混合ESS的内部候选者必须满足等支付条件，并求解内部不动点 $x^{\\ast}$ 的闭式解。\n3. 推导在复制动态下内部不动点的稳定性条件，并将其转化为关于 $(a,b,c,d)$ 的条件。将此与可行性要求 $x^{\\ast}\\in(0,1)$ 相结合，得到存在混合ESS时 $(a,b,c,d)$ 需满足的充要条件。\n\n以 $a$、$b$、$c$ 和 $d$ 的单一闭式解析表达式的形式，报告策略1的混合策略概率 $x^{\\ast}$。如果混合ESS不存在，你的推导过程应清楚说明这一点，但你最终报告的表达式应为假设满足混合ESS可行性和稳定性条件下的闭式解 $x^{\\ast}$。不需要进行数值计算。请给出精确的最终答案（不要四舍五入）。",
            "solution": "本问题要求在复制动态下，为一个对称 $2 \\times 2$ 博弈推导其演化稳定策略（ESS）的混合策略概率 $x^{\\ast}$。我们将首先推导复制方程，然后找到其内部不动点，最后确定该不动点对应于稳定混合ESS的条件。\n\n设两个策略分别用 $1$ 和 $2$ 表示。种群状态由采用策略 $1$ 的个体频率 $x \\in [0,1]$ 给出，因此采用策略 $2$ 的个体频率为 $1-x$。相互作用由对称支付矩阵 $A$ 决定，其中条目 $A_{ij}$ 是采用策略 $i$ 的参与者对抗采用策略 $j$ 的对手时获得的支付。\n$$\nA = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}\n$$\n\n**1. 期望支付与复制方程**\n\n首先，我们确定在状态为 $x$ 的种群中，采用每种纯策略的个体所获得的期望支付。一个采用策略 $1$ 的个体将以概率 $x$ 遇到另一个采用策略 $1$ 的参与者（获得支付 $a$），并以概率 $1-x$ 遇到一个采用策略 $2$ 的参与者（获得支付 $b$）。因此，策略 $1$ 的期望支付，记作 $E_1(x)$，为：\n$$\nE_1(x) = a \\cdot x + b \\cdot (1-x)\n$$\n类似地，策略 $2$ 的期望支付，记作 $E_2(x)$，为：\n$$\nE_2(x) = c \\cdot x + d \\cdot (1-x)\n$$\n整个种群的平均支付 $\\bar{E}(x)$ 是两种策略支付的加权平均：\n$$\n\\bar{E}(x) = x E_1(x) + (1-x) E_2(x)\n$$\n问题陈述了复制动态描述了频率 $x$ 的演化。一个策略频率的增长率与其相对于种群平均支付的支付优势成正比。对于策略 $1$，这可以写成：\n$$\n\\frac{dx}{dt} = kx(E_1(x) - \\bar{E}(x))\n$$\n其中 $k$ 是一个正常数比例常数，通过重标时间，我们可以将其设为 $1$。代入 $\\bar{E}(x)$ 的表达式：\n$$\n\\frac{dx}{dt} = x(E_1(x) - [x E_1(x) + (1-x) E_2(x)])\n$$\n$$\n\\frac{dx}{dt} = x(E_1(x)(1-x) - E_2(x)(1-x))\n$$\n$$\n\\frac{dx}{dt} = x(1-x)(E_1(x) - E_2(x))\n$$\n这是一维复制方程。为了完成其推导，我们代入 $E_1(x)$ 和 $E_2(x)$ 的表达式：\n$$\nE_1(x) - E_2(x) = (ax + b(1-x)) - (cx + d(1-x)) = (a-c)x - (d-b)(1-x) = (a-c)x - (d-b) + (d-b)x\n$$\n$$\nE_1(x) - E_2(x) = (a-c+d-b)x + (b-d)\n$$\n因此，描述频率 $x(t)$ 的复制方程为：\n$$\n\\frac{dx}{dt} = x(1-x)[(a-b-c+d)x + (b-d)]\n$$\n\n**2. 内部不动点与等支付条件**\n\n动态系统的不动点是使得 $\\frac{dx}{dt} = 0$ 的种群状态 $x^{\\ast}$。根据上述方程，不动点可能出现在：\n- $x^{\\ast} = 0$（类型2的纯策略种群）\n- $x^{\\ast} = 1$（类型1的纯策略种群）\n- 一个内部不动点 $x^{\\ast} \\in (0,1)$，此时方括号中的项为零：$(a-b-c+d)x^{\\ast} + (b-d) = 0$。\n\n这最后一个条件等价于 $E_1(x^{\\ast}) - E_2(x^{\\ast}) = 0$，即 $E_1(x^{\\ast}) = E_2(x^{\\ast})$。这就是等支付条件。一个内部混合ESS候选者必须满足此条件。如果支付不相等，例如 $E_1(x^{\\ast}) > E_2(x^{\\ast})$，那么在一个采用混合策略 $x^{\\ast}$ 的种群中，任何个体转而采用纯策略1都会获得更好的结果。该混合策略将不能抵抗个体偏离，而抵抗个体偏离是ESS的一个必要条件。因此，要使一个内部混合策略成为ESS的候选者，两种纯策略必须产生相同的期望支付。\n\n求解等支付条件以得到 $x^{\\ast}$：\n$$\n(a-b-c+d)x^{\\ast} = d-b\n$$\n假设 $a-b-c+d \\neq 0$，我们找到内部不动点：\n$$\nx^{\\ast} = \\frac{d-b}{a-b-c+d}\n$$\n\n**3. 稳定性与可行性条件**\n\n为了使 $x^{\\ast}$ 成为一个稳定的混合ESS，必须满足两组条件：\n1.  **可行性**：$x^{\\ast}$ 必须是一个有效的概率，即 $0  x^{\\ast}  1$。\n2.  **稳定性**：不动点 $x^{\\ast}$ 必须是动态稳定的。对 $x^{\\ast}$ 的小扰动应衰减回 $x^{\\ast}$。\n\n我们首先分析稳定性。动态系统 $\\frac{dx}{dt} = f(x)$ 的一个不动点 $x^{\\ast}$ 是局部稳定的，如果 $f'(x^{\\ast})  0$。设 $f(x) = x(1-x)[(a-b-c+d)x + (b-d)]$。令 $g(x) = (a-b-c+d)x + (b-d)$。则 $f(x) = x(1-x)g(x)$。其导数为 $f'(x) = (1-2x)g(x) + x(1-x)g'(x)$。\n在内部不动点 $x^{\\ast}$ 处，根据定义，$g(x^{\\ast})=0$。所以第一项消失：\n$$\nf'(x^{\\ast}) = x^{\\ast}(1-x^{\\ast})g'(x^{\\ast})\n$$\n$g(x)$ 的导数是 $g'(x) = a-b-c+d$。\n由于 $x^{\\ast} \\in (0,1)$，项 $x^{\\ast}(1-x^{\\ast})$ 是严格为正的。因此，$f'(x^{\\ast})$ 的符号由 $g'(x^{\\ast})$ 的符号决定。稳定性条件 $f'(x^{\\ast})  0$ 因此要求：\n$$\na-b-c+d  0\n$$\n这个条件也等价于静态ESS的第二个要求：均衡策略 $x^{\\ast}$ 对抗任何突变策略所获得的支付，要高于突变策略在被入侵种群中对抗自身所获得的支付。\n\n现在，我们将这个稳定性条件与可行性要求 $0  x^{\\ast}  1$ 结合起来。使用 $x^{\\ast} = \\frac{d-b}{a-b-c+d}$：\n\n-   **条件 $x^{\\ast} > 0$**：\n    我们有 $\\frac{d-b}{a-b-c+d} > 0$。由于稳定性条件要求分母 $(a-b-c+d)$ 为负，要使分数为正，分子 $(d-b)$ 也必须为负。\n    $d-b  0 \\implies b > d$。\n\n-   **条件 $x^{\\ast}  1$**：\n    我们有 $\\frac{d-b}{a-b-c+d}  1$。由于分母为负，两边同乘以它会反转不等号：\n    $d-b > a-b-c+d$\n    $0 > a-c \\implies a  c$。\n\n总结来说，为了存在一个稳定的混合ESS，支付必须满足 $a  c$ 和 $b > d$。这些是鹰鸽博弈（Hawk-Dove game）结构的条件，其中每种纯策略都是对另一种纯策略的最佳应对，这阻止了任何一种策略占据整个种群，从而导致稳定的共存。\n\n问题要求给出 $x^{\\ast}$ 的闭式表达式，我们已经推导出来了。这个表达式在充要条件 $a  c$ 和 $b > d$ 下是有效的。\n\n混合ESS中策略1的概率是：\n$$\nx^{\\ast} = \\frac{d-b}{a-b-c+d}\n$$",
            "answer": "$$\n\\boxed{\\frac{d-b}{a-b-c+d}}\n$$"
        },
        {
            "introduction": "在复杂网络的研究中，一个核心挑战是如何判断观测到的宏观模式（例如社团结构或高聚类特性）是源于有意义的自组织机制，还是仅仅是随机因素的产物。这个计算实践  引入了一种关键的科学方法：零模型检验。你将学习如何通过编程实现一个保留节点度的随机化过程，并将其与观测网络进行统计比较，从而科学地判断网络中是否存在非随机的组织原则。",
            "id": "4274115",
            "problem": "您的任务是形式化并检验一个论断：网络中观察到的宏观模式需要自组织，而非源于随机聚合。考虑一个无向简单图，无自环，由一个对称且对角线为零的邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示。节点索引为 $\\{0,1,\\dots,n-1\\}$，边是 $i \\neq j$ 的无序对 $\\{i,j\\}$。度序列为 $k_i = \\sum_{j=0}^{n-1} A_{ij}$。\n\n您的推导必须基于以下标准定义：\n- 三角形是由三个节点 $\\{i,j,\\ell\\}$ 组成的集合，它们之间所有三条边都存在。$A$ 中的三角形总数为 $T = \\frac{1}{6} \\mathrm{tr}(A^3)$。\n- 一个连通三元组（也称为楔形）是以一个节点为中心、长度为二的路径，对于节点 $i$，其数量为 $\\binom{k_i}{2}$。连通三元组的总数为 $W = \\sum_{i=0}^{n-1} \\binom{k_i}{2} = \\frac{1}{2} \\sum_{i=0}^{n-1} k_i (k_i - 1)$。\n- 全局聚类系数（也称为传递性）定义为 $C = \\frac{3T}{W}$，约定如果 $W = 0$，则 $C = 0$。\n\n为了检验一个观察到的宏观模式（此处为高聚类性）是否需要自组织，构建一个仅匹配平凡统计量但缺乏交互机制的零模型。使用保度随机边交换模型（也称为 Maslov–Sneppen 重连）从与观察网络具有相同度序列的简单图空间中均匀抽样随机图。该零模型保留了度序列和边数，但通过重复交换随机选择的边对的端点来消除局部交互结构，同时禁止自环和多重边。\n\n对于每个观察到的网络，通过从零模型生成 $R$ 个独立样本来估计 $C$ 的经验零分布，并计算：\n- 经验 $p$ 值 $p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$，其中 $C^{(r)}$ 是第 $r$ 个零模型样本的聚类系数，$C^{\\mathrm{obs}}$ 是观察到的聚类系数。\n- 标准化效应大小 $z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$，其中 $\\mu$ 和 $\\sigma$ 分别是 $C$ 的零分布的均值和标准差。如果 $\\sigma = 0$，则当 $C^{\\mathrm{obs}}  \\mu$ 时定义 $z = +\\infty$，否则定义 $z = -\\infty$。\n\n决策规则：当且仅当 $p  \\alpha$ 且 $z \\ge z_{\\mathrm{thr}}$ 时，断定该宏观模式需要自组织，其中 $\\alpha = 0.05$ 且 $z_{\\mathrm{thr}} = 2$。\n\n为观察网络实现以下生成过程（所有图都是无向、简单且无权的）：\n- 环状格：对于参数 $(n,k)$，其中 $k$ 为偶数且 $k \\ll n$，将每个节点 $i$ 与其在环上两侧的 $k/2$ 个最近邻居连接，创建边 $(i,(i+d)\\bmod n)$，其中 $d = 1,2,\\dots,k/2$。\n- 保度随机化：从具有相同 $(n,k)$ 的环状格开始，执行重复的保度边交换，以在保持度序列的同时消除局部结构。\n- 偏好连接树：初始时在两个节点间建立一条边。对于每个新节点，直到总节点数达到 $n$，将其连接到一个现有节点上，该现有节点被选择的概率与其当前度成正比，从而生成一棵树（参数 $m=1$ 的 Barabási–Albert 模型）。\n- 带对角线的二维网格：对于参数 $(s_x,s_y)$，构建一个包含 $n = s_x s_y$ 个节点的矩形格点，节点与其水平和垂直邻居之间有边，并添加每个单元的对角线边以创建三角形（例如，在有效的情况下，添加从 $(x,y)$ 到 $(x+1,y+1)$ 的边）。\n\n您的程序必须实现：\n- 对任何给定的 $A$ 精确计算 $T$、$W$ 和 $C$。\n- 从观察到的 $A$ 开始，通过保度边交换进行零模型抽样。每个零模型样本使用 $S$ 次交换，其中 $S$ 与边数 $m$ 成正比（例如，$S = 10m$）。\n- 经验 p 值和 z 分数的计算以及上述指定的决策规则。\n\n测试套件。对于以下每组参数，构建相应的观察网络，使用 $R = 64$ 个样本、$α = 0.05$、$z_{\\mathrm{thr}} = 2$ 以及每个零模型样本 $S = 10m$ 次交换来运行零模型检验，并输出一个布尔值，指示是否需要自组织：\n- 案例 1（通过局部聚类自组织）：环状格，参数为 $(n,k) = (60,4)$。\n- 案例 2（度匹配的随机聚合）：对案例 1 的环状格进行保度随机化，使用 $S = 20m$ 次交换来生成观察网络。\n- 案例 3（无三元闭包的稀疏树）：偏好连接树，参数为 $n = 60$，$m = 1$。\n- 案例 4（局部聚类的平面结构）：带对角线的二维网格，参数为 $(s_x,s_y) = (7,7)$，因此 $n = 49$。\n\n最终输出格式：您的程序应生成单行输出，其中包含按案例 1 到 4 顺序排列的结果，格式为方括号内的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是根据决策规则计算出的布尔值。",
            "solution": "该问题要求我们形式化并应用一种统计假设检验，以确定观察到的网络模式（特别是高聚类性）是自组织的结果，还是可能由受基本网络属性约束的随机过程产生。这是复杂系统中的一个基本问题，其中涌现的宏观模式通常通过与适当的零模型进行比较，来与平凡的聚合区分开来。\n\n该方法的核心是假设检验。零假设 $H_0$ 假定，观察到的网络是从一个图系综中的随机实现，该系综中的图仅与观察网络共享相同的度序列。备择假设 $H_1$ 认为，网络具有额外的结构——在此案例中是显著更高的聚类性——这不能仅由度序列解释。这种额外的结构被解释为自组织的标志，即非随机的交互规则。\n\n所选的检验统计量是全局聚类系数 $C$，它量化了节点形成三角形的趋势。它被定义为“闭合”三元组（三角形）与所有连通三元组（楔形）的比率。\n- 三角形的数量 $T$ 由 $T = \\frac{1}{6} \\mathrm{tr}(A^3)$ 给出，其中 $A$ 是邻接矩阵。$A^3_{ii}$ 项计算了从节点 $i$ 出发回到自身的长度为 3 的路径数量。每个涉及节点 $i$ 的三角形贡献两条这样的路径（一条顺时针，一条逆时针）。由于这对三角形中的每个节点都计算了一次，并且迹是这些计数的总和，因此我们除以 $3 \\times 2 = 6$。\n- 以节点 $i$ 为中心的连通三元组（或楔形）的数量 $W$，是连接到 $i$ 的边对的数量，即 $\\binom{k_i}{2}$，其中 $k_i$ 是节点 $i$ 的度。对所有节点求和，得到楔形的总数：$W = \\sum_{i=0}^{n-1} \\binom{k_i}{2}$。\n- 全局聚类系数则为 $C = \\frac{3T}{W}$。因子 3 用于归一化该比率，因为一个三角形由三个闭合的楔形组成。\n\n为了检验零假设，我们生成统计量 $C$ 的零分布。这是通过使用保度随机边交换模型（Maslov–Sneppen 重连）完成的。该过程从观察到的网络开始，重复交换两条随机选择的边（例如 $\\{i, j\\}$ 和 $\\{u, v\\}$）的端点，形成新的边 $\\{i, v\\}$ 和 $\\{u, j\\}$，前提是这些新边不存在且不产生自环。这个过程在保持每个节点度数不变的同时，随机化了网络的拓扑结构，从而创建了一个与观察网络的度序列完全匹配的随机图系综。这一点至关重要，因为许多网络属性（包括聚类性）都受到度序列的强烈影响。通过保留度序列，我们分离出了度之外的更高阶相关性的影响。\n\n对于通过此过程生成的 $R$ 个随机图中的每一个，我们计算其聚类系数 $C^{(r)}$。这个值的集合 $\\{C^{(1)}, C^{(2)}, \\dots, C^{(R)}\\}$ 构成了经验零分布。然后，我们使用两个度量将观察到的聚类系数 $C^{\\text{obs}}$ 与此分布进行比较：\n\n1.  **经验 p 值**：$p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$。它衡量了在零假设下观察到至少与 $C^{\\text{obs}}$ 一样大的聚类系数的概率。`+1` 项是一种标准修正，以避免 $p=0$ 并将观察样本本身考虑在内。一个小的 p 值表明观察到的聚类性出奇地高。\n2.  **标准化效应大小（z 分数）**：$z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$，其中 $\\mu$ 和 $\\sigma$ 是零分布的均值和标准差。z 分数衡量观察值与零分布均值相差多少个标准差。一个大的正 z 分数表示效应量很大。\n\n决策规则是，如果一个模式既具有统计显著性（$p  \\alpha$），又具有足够大的效应大小（$z \\ge z_{\\mathrm{thr}}$），则宣布其为自组织的结果，给定阈值为 $\\alpha=0.05$ 和 $z_{\\mathrm{thr}}=2$。\n\n实现了一个计算框架来测试四种不同的网络模型：\n- **案例 1：环状格 $(n=60, k=4)$**：每个节点都连接到它在环上的最近和次近邻居。这创造了一个规则的、局部有序的结构。我们预计相邻的邻居之间会形成三角形（例如，节点 $i$ 与其邻居 $i-1, i-2$ 不形成三角形，但邻居 $i-1, i-2$ 之间是相连的），这导致了较高的 $C^{\\text{obs}}$。这种结构在具有相同度数的随机图中是预料之外的，因此我们预计会拒绝零假设（结果：`True`）。\n- **案例 2：随机化的环状格**：该网络是通过对案例 1 的环状格进行大量保度交换而明确构造的。根据其构造方式，它本身就是零模型系综中的一个样本。因此，其 $C^{\\text{obs}}$ 应该是零分布中的典型值，从而导致较高的 p 值和接近 0 的 z 分数。我们预计无法拒绝零假设（结果：`False`）。\n- **案例 3：偏好连接树 $(n=60, m=1)$**：这会生成一个树形结构，根据定义，它没有环路，因此也没有三角形。所以，$T^{\\text{obs}}=0$ 且 $C^{\\text{obs}}=0$。而具有相同异构度序列的零模型图，几乎肯定会包含一些偶然形成的三角形。因此，对于所有零样本，$C^{(r)}$ 很可能都大于 $C^{\\text{obs}}$，导致 $p \\approx 1$ 和一个负的 z 分数。我们预计无法拒绝零假设（结果：`False`）。\n- **案例 4：带对角线的二维网格 $((s_x,s_y)=(7,7))$**：该网络模拟了一个具有局部连接的空间嵌入系统。带有对角线的网格结构创造了高密度的三角形。例如，在一个网格单元中添加一条连接节点 $(x,y)$ 和 $(x+1,y+1)$ 的边，会产生两个三角形：$((x,y), (x+1,y), (x+1,y+1))$ 和 $((x,y), (x,y+1), (x+1,y+1))$。这种高度聚类的结构是自组织的一种形式（基于空间邻近性），并且不期望从随机重连过程中产生。我们预计会拒绝零假设（结果：`True`）。\n\n该实现首先为每个案例生成邻接矩阵。然后，对于每个矩阵，一个测试函数会计算其观察到的聚类系数 $C^{\\text{obs}}$，通过重连生成 $R=64$ 个零模型样本，计算 $C$ 的零分布，并最终计算 p 值和 z 分数以应用决策规则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the four test cases and print the results.\n    \"\"\"\n    np.random.seed(42)  # For reproducibility\n\n    # Define test case parameters\n    alpha = 0.05\n    z_thr = 2.0\n    R = 64\n    S_multiplier_null = 10\n\n    results = []\n\n    # Case 1: Ring-lattice\n    n1, k1 = 60, 4\n    A1 = generate_ring_lattice(n1, k1)\n    res1 = run_null_model_test(A1, R, alpha, z_thr, S_multiplier_null)\n    results.append(res1)\n\n    # Case 2: Randomized ring-lattice\n    m2 = (n1 * k1) // 2\n    S_randomize = 20 * m2\n    A2 = degree_preserving_swap(A1.copy(), S_randomize)\n    res2 = run_null_model_test(A2, R, alpha, z_thr, S_multiplier_null)\n    results.append(res2)\n\n    # Case 3: Preferential attachment tree\n    n3 = 60\n    A3 = generate_pa_tree(n3)\n    res3 = run_null_model_test(A3, R, alpha, z_thr, S_multiplier_null)\n    results.append(res3)\n\n    # Case 4: 2D grid with diagonals\n    sx4, sy4 = 7, 7\n    A4 = generate_grid_with_diagonals(sx4, sy4)\n    res4 = run_null_model_test(A4, R, alpha, z_thr, S_multiplier_null)\n    results.append(res4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef calculate_c(A):\n    \"\"\"\n    Calculates the global clustering coefficient C for a graph with adjacency matrix A.\n    \"\"\"\n    if A.shape[0]  3:\n        return 0.0\n        \n    # Using np.linalg.matrix_power for A^3\n    A_cubed = np.linalg.matrix_power(A.astype(np.float64), 3)\n    T = np.trace(A_cubed) / 6.0\n    \n    k = A.sum(axis=1)\n    # Filter degrees less than 2, as they don't contribute to wedges\n    k_ge_2 = k[k >= 2]\n    W = np.sum(k_ge_2 * (k_ge_2 - 1.0)) / 2.0\n    \n    if W == 0:\n        return 0.0\n    \n    return (3.0 * T) / W\n\ndef degree_preserving_swap(A, num_swaps):\n    \"\"\"\n    Performs degree-preserving random edge swaps (Maslov-Sneppen rewiring).\n    \"\"\"\n    n = A.shape[0]\n    A_rewired = A.copy()\n    \n    # Get edge set for efficient lookups and modification\n    # Use tuples with sorted nodes to have a canonical representation\n    edge_set = {tuple(sorted(edge)) for edge in np.argwhere(np.triu(A_rewired))}\n\n    if not edge_set or len(edge_set)  2:\n        return A_rewired\n\n    edges_list = list(edge_set)\n    m = len(edges_list)\n    \n    swaps_done = 0\n    attempts = 0\n    max_attempts = num_swaps * 10 # To avoid infinite loops in dense graphs\n\n    while swaps_done  num_swaps and attempts  max_attempts:\n        attempts += 1\n        \n        # Choose two distinct edges\n        idx1, idx2 = np.random.choice(m, 2, replace=False)\n        e1 = edges_list[idx1]\n        e2 = edges_list[idx2]\n        \n        i, j = e1\n        u, v = e2\n\n        # Ensure all four nodes are distinct\n        if len({i, j, u, v}) != 4:\n            continue\n\n        # Propose new edges (i,v) and (u,j). Sorting for canonical check.\n        new_e1 = tuple(sorted((i, v)))\n        new_e2 = tuple(sorted((u, j)))\n\n        # Check if new edges would create multi-edges\n        if new_e1 in edge_set or new_e2 in edge_set:\n            continue\n        \n        # Perform the swap\n        # Remove old edges from matrix and set\n        A_rewired[i, j] = A_rewired[j, i] = 0\n        A_rewired[u, v] = A_rewired[v, u] = 0\n        edge_set.remove(e1)\n        edge_set.remove(e2)\n        \n        # Add new edges to matrix and set\n        A_rewired[i, v] = A_rewired[v, i] = 1\n        A_rewired[u, j] = A_rewired[j, u] = 1\n        edge_set.add(new_e1)\n        edge_set.add(new_e2)\n        \n        # Update the list from which we sample\n        edges_list[idx1] = new_e1\n        edges_list[idx2] = new_e2\n\n        swaps_done += 1\n        \n    return A_rewired\n\n\ndef run_null_model_test(A_obs, R, alpha, z_thr, S_multiplier):\n    \"\"\"\n    Runs the null model test and returns the decision.\n    \"\"\"\n    C_obs = calculate_c(A_obs)\n    \n    m = np.sum(np.triu(A_obs))\n    num_swaps = int(S_multiplier * m)\n\n    C_null_dist = []\n    for _ in range(R):\n        A_rewired = degree_preserving_swap(A_obs.copy(), num_swaps)\n        C_null = calculate_c(A_rewired)\n        C_null_dist.append(C_null)\n        \n    C_null_dist = np.array(C_null_dist)\n    \n    # Calculate p-value\n    ge_count = np.sum(C_null_dist >= C_obs)\n    p_value = (1.0 + ge_count) / (R + 1.0)\n    \n    # Calculate z-score\n    mu = np.mean(C_null_dist)\n    sigma = np.std(C_null_dist)\n    \n    if sigma == 0:\n        if C_obs > mu:\n            z_score = np.inf\n        else: # Covers C_obs = mu\n            z_score = -np.inf\n    else:\n        z_score = (C_obs - mu) / sigma\n\n    # Decision rule\n    return p_value  alpha and z_score >= z_thr\n\n# --- Graph Generation Functions ---\n\ndef generate_ring_lattice(n, k):\n    A = np.zeros((n, n), dtype=int)\n    for i in range(n):\n        for d in range(1, k // 2 + 1):\n            j = (i + d) % n\n            A[i, j] = A[j, i] = 1\n    return A\n\ndef generate_pa_tree(n):\n    A = np.zeros((n, n), dtype=int)\n    if n  2:\n        return A\n    \n    # Initial state: edge between node 0 and 1\n    A[0, 1] = A[1, 0] = 1\n    edge_endpoints = [0, 1]\n    \n    for i in range(2, n):\n        target_node = np.random.choice(edge_endpoints)\n        A[i, target_node] = A[target_node, i] = 1\n        edge_endpoints.extend([i, target_node])\n        \n    return A\n\ndef generate_grid_with_diagonals(sx, sy):\n    n = sx * sy\n    A = np.zeros((n, n), dtype=int)\n    \n    for y in range(sy):\n        for x in range(sx):\n            i = x + y * sx\n            \n            # Horizontal neighbor\n            if x  sx - 1:\n                j_h = (x + 1) + y * sx\n                A[i, j_h] = A[j_h, i] = 1\n                \n            # Vertical neighbor\n            if y  sy - 1:\n                j_v = x + (y + 1) * sx\n                A[i, j_v] = A[j_v, i] = 1\n            \n            # Diagonal neighbor: (x,y) to (x+1,y+1)\n            if x  sx - 1 and y  sy - 1:\n                j_d = (x + 1) + (y + 1) * sx\n                A[i, j_d] = A[j_d, i] = 1\n                \n    return A\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}