{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex simulations, it is essential to grasp the mathematical foundations of agent interactions. This exercise hones your analytical skills by tasking you to derive a key macroscopic property—the expected rate of agent encounters—directly from microscopic rules and system parameters like agent density. By working from the first principles of probability, you will build a crucial intuition for how local behaviors aggregate into predictable global patterns, a cornerstone of agent-based modeling .",
            "id": "4284371",
            "problem": "Consider an agent-based modeling (ABM) setup on a finite two-dimensional toroidal square lattice of side length $L$, so there are $L^{2}$ sites. There are $N$ indistinguishable agents, with density $\\rho$ defined by $\\rho = N/L^{2}$. Time is discrete, and at each time step every agent updates its position synchronously by choosing uniformly at random one of the $9$ sites in its Moore neighborhood (the current site plus its $8$ nearest neighbors) and moving there; choices are independent across agents and time. Multiple occupancy is allowed. Define an encounter during a time step as an unordered pair of distinct agents that occupy the same lattice site after the movement of that time step. Assume the system is in the spatially homogeneous regime in which the marginal distribution of an agent’s position is uniform over sites (which is the stationary distribution for this symmetric random walk on a torus).\n\nStarting only from the core definitions of probability, independence of agent moves, and linearity of expectation, derive the exact closed-form expression for the expected number of encounters per time step across the entire system, expressed as a function of $\\rho$ and $L$. Provide your final result in its simplest analytic form. Do not provide an inequality or an equation to be solved; your final answer must be a single closed-form expression without units.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution without any internal contradictions.\n\nLet $C$ be the random variable representing the total number of encounters per time step across the entire system. An encounter is defined as an unordered pair of distinct agents occupying the same lattice site after the synchronous movement phase. Our goal is to compute the expected value of $C$, denoted as $\\mathbb{E}[C]$.\n\nThe system consists of $N$ agents on a toroidal lattice with $L^2$ sites. The agents are labeled by an index $i \\in \\{1, 2, \\ldots, N\\}$. To calculate the total expected number of encounters, we can use the principle of linearity of expectation. The total number of encounters $C$ is the sum of encounters over all possible distinct pairs of agents. The number of distinct unordered pairs of agents is given by the binomial coefficient $\\binom{N}{2}$.\n\nLet us define an indicator random variable $I_{ij}$ for each unordered pair of distinct agents $(i, j)$, where $1 \\le i  j \\le N$. The variable $I_{ij}$ is defined as:\n$$\nI_{ij} = \\begin{cases} 1  \\text{if agents } i \\text{ and } j \\text{ occupy the same site} \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThe total number of encounters $C$ can then be expressed as the sum of these indicator variables over all distinct pairs:\n$$\nC = \\sum_{1 \\le i  j \\le N} I_{ij}\n$$\nBy the linearity of expectation, the expected total number of encounters is:\n$$\n\\mathbb{E}[C] = \\mathbb{E}\\left[\\sum_{1 \\le i  j \\le N} I_{ij}\\right] = \\sum_{1 \\le i  j \\le N} \\mathbb{E}[I_{ij}]\n$$\nThe expectation of an indicator variable is simply the probability of the event it indicates. Therefore, $\\mathbb{E}[I_{ij}] = P(I_{ij} = 1)$, which is the probability that agents $i$ and $j$ encounter each other.\n\nBecause the agents are indistinguishable and the system dynamics are symmetric for all agents, the probability of an encounter is the same for any pair of distinct agents $(i, j)$. Let $p_{\\text{enc}}$ denote this common probability.\n$$\np_{\\text{enc}} = P(I_{ij} = 1) \\quad \\text{for any } 1 \\le i  j \\le N\n$$\nThe total number of pairs is $\\binom{N}{2} = \\frac{N(N-1)}{2}$. Thus, the expected total number of encounters becomes:\n$$\n\\mathbb{E}[C] = \\binom{N}{2} p_{\\text{enc}} = \\frac{N(N-1)}{2} p_{\\text{enc}}\n$$\nOur next step is to calculate $p_{\\text{enc}}$. Let $X'_k$ denote the random variable for the position of agent $k$ after the movement step. The lattice has $S = L^2$ sites. The problem states that the system is in a spatially homogeneous regime, where the marginal distribution of an agent's position is uniform over the sites. This is the stationary distribution of the random walk. This means that for any agent $k$ and any site $s$, the probability that the agent is at site $s$ after the move is:\n$$\nP(X'_k = s) = \\frac{1}{L^2}\n$$\nAn encounter between agents $i$ and $j$ occurs if $X'_i = X'_j$. To find the probability of this event, we can sum over all possible sites $s$ where they could meet:\n$$\np_{\\text{enc}} = P(X'_i = X'_j) = \\sum_{s=1}^{L^2} P(X'_i = s \\text{ and } X'_j = s)\n$$\nThe problem states that the agents' choices of movement are independent. Consequently, their final positions $X'_i$ and $X'_j$ are independent random variables. Therefore, we can write:\n$$\nP(X'_i = s \\text{ and } X'_j = s) = P(X'_i = s) \\times P(X'_j = s)\n$$\nSubstituting the uniform probability for each agent:\n$$\nP(X'_i = s \\text{ and } X'_j = s) = \\left(\\frac{1}{L^2}\\right) \\times \\left(\\frac{1}{L^2}\\right) = \\frac{1}{L^4}\n$$\nThis probability is the same for any site $s$. Now, we sum over all $L^2$ possible sites:\n$$\np_{\\text{enc}} = \\sum_{s=1}^{L^2} \\frac{1}{L^4} = L^2 \\times \\frac{1}{L^4} = \\frac{1}{L^2}\n$$\nThe specific update rule (Moore neighborhood) is irrelevant for this calculation, as the stationary uniform distribution assumption is given.\n\nNow we substitute this probability back into our expression for the expected number of encounters:\n$$\n\\mathbb{E}[C] = \\frac{N(N-1)}{2} \\times p_{\\text{enc}} = \\frac{N(N-1)}{2L^2}\n$$\nThe final step is to express this result in terms of the agent density $\\rho$ and the lattice side length $L$. The density is defined as $\\rho = N/L^2$. From this, we have $N = \\rho L^2$. Substituting this expression for $N$ into our result for $\\mathbb{E}[C]$:\n$$\n\\mathbb{E}[C] = \\frac{(\\rho L^2)(\\rho L^2 - 1)}{2L^2}\n$$\nThe factor $L^2$ in the numerator and denominator cancels out, leading to the simplified final expression:\n$$\n\\mathbb{E}[C] = \\frac{\\rho(\\rho L^2 - 1)}{2}\n$$\nThis is the exact closed-form expression for the expected number of encounters per time step.",
            "answer": "$$\n\\boxed{\\frac{\\rho(\\rho L^2 - 1)}{2}}\n$$"
        },
        {
            "introduction": "One of the most critical and often subtle design decisions in an ABM is the agent update schedule, which dictates the timing and order of agent actions. This thought experiment provides a clear and tractable example of how this single choice can have profound consequences on system dynamics. By tracing the evolution of a simple two-agent system under both synchronous and sequential updating, you will see firsthand how the same local rules can lead to entirely different emergent outcomes, underscoring the need for careful consideration of model temporality .",
            "id": "4113495",
            "problem": "Consider an Agent-Based Model (ABM) in the domain of complex adaptive systems modeling with two agents labeled $i \\in \\{1,2\\}$ on an undirected network consisting of a single edge connecting the two agents. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. The ABM employs a deterministic threshold decision rule: an agent becomes active at the next time step if and only if the fraction of its neighbors that are active meets or exceeds its threshold. Formally, for any agent $i$, let $N_i$ denote the set of neighbors of $i$, and let $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$ be the fraction of neighbors active at an update reference time $\\tau$. The threshold parameter for agent $i$ is $\\theta_i \\in [0,1]$, and the individual update rule is\n$$\nx_i(\\text{next}) = \n\\begin{cases}\n1,  \\text{if } m_i(\\tau) \\ge \\theta_i, \\\\\n0,  \\text{if } m_i(\\tau)  \\theta_i.\n\\end{cases}\n$$\nTwo update regimes are considered:\n\n- Synchronous update: Both agents compute $m_i(t)$ using the states at time $t$ and simultaneously set $x_i(t+1)$ according to the threshold rule.\n- Sequential update with fixed order $(1,2)$: Agent $1$ updates first using $m_1(t)$ to set $x_1(t+1)$, and then agent $2$ updates using $m_2(t+1)$, where $m_2(t+1)$ is computed from the latest available neighbor state after agent $1$ has updated.\n\nSuppose the initial condition is $x_1(0) = 0$ and $x_2(0) = 1$, and the thresholds are $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. Because the network has a single edge, each agent’s $m_i(\\tau)$ equals the neighbor’s state at the specified reference time. Define the trajectory difference over a finite horizon $T$ as the cumulative Hamming distance between the two regime trajectories,\n$$\nD(T) = \\sum_{t=0}^{T} \\left( \\left| x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t) \\right| + \\left| x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t) \\right| \\right),\n$$\nwhere $x_i^{\\text{sync}}(t)$ and $x_i^{\\text{seq}}(t)$ denote the state of agent $i$ at time $t$ under synchronous and sequential updating, respectively.\n\nCompute $D(T)$ for the horizon $T = 10$. Provide your final answer as a single real number. No rounding instruction is necessary for this problem.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of Agent-Based Models (ABMs) and Complex Adaptive Systems, and contains all necessary information for a unique solution. The validation criteria are met.\n\nThe task is to compute the cumulative Hamming distance, $D(T)$, between the state trajectories of a two-agent system under synchronous and sequential update regimes for a time horizon of $T=10$. We begin by analyzing the agent update rules, then simulate the trajectories for both regimes, and finally compute the required sum.\n\nFirst, we formalize the update rules for agent $i \\in \\{1, 2\\}$ with thresholds $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. The network consists of a single edge connecting the two agents, so the set of neighbors for agent $1$ is $N_1 = \\{2\\}$ and for agent $2$ is $N_2 = \\{1\\}$. The fraction of active neighbors for agent $i$ is $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$. This simplifies to $m_1(\\tau) = x_2(\\tau)$ and $m_2(\\tau) = x_1(\\tau)$.\n\nThe individual update rule is $x_i(\\text{next}) = 1$ if $m_i(\\tau) \\ge \\theta_i$ and $x_i(\\text{next}) = 0$ otherwise. Given the binary state space $x_i \\in \\{0, 1\\}$, the rules for each agent become:\n- For agent $1$: $x_1(\\text{next}) = 1$ if and only if $x_2(\\tau) \\ge \\theta_1 = \\frac{1}{2}$. This means $x_1(\\text{next}) = 1$ only if $x_2(\\tau)=1$. Thus, the rule is $x_1(\\text{next}) = x_2(\\tau)$.\n- For agent $2$: $x_2(\\text{next}) = 1$ if and only if $x_1(\\tau) \\ge \\theta_2 = 1$. This means $x_2(\\text{next}) = 1$ only if $x_1(\\tau)=1$. Thus, the rule is $x_2(\\text{next}) = x_1(\\tau)$.\n\nNow we generate the trajectories for both update regimes starting from the initial condition $(x_1(0), x_2(0)) = (0, 1)$.\n\n**1. Synchronous Update Trajectory**\nUnder synchronous updating, both agents' next states are computed based on the current state of the system at time $t$. The rules are:\n$$\n\\begin{cases}\nx_1^{\\text{sync}}(t+1) = x_2^{\\text{sync}}(t) \\\\\nx_2^{\\text{sync}}(t+1) = x_1^{\\text{sync}}(t)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{sync}}(t), x_2^{\\text{sync}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$: $(x_1(1), x_2(1)) = (x_2(0), x_1(0)) = (1, 0)$\n- $t=2$: $(x_1(2), x_2(2)) = (x_2(1), x_1(1)) = (0, 1)$\n- $t=3$: $(x_1(3), x_2(3)) = (x_2(2), x_1(2)) = (1, 0)$\nThe system oscillates with a period of $2$. The state is $(0, 1)$ for even values of $t$ and $(1, 0)$ for odd values of $t$.\n\n**2. Sequential Update Trajectory (Order 1, 2)**\nUnder sequential updating with order $(1, 2)$, agent $1$ first updates its state for time $t+1$ based on states at time $t$. Then, agent $2$ updates its state for time $t+1$ using the most recent states, which includes the newly updated state of agent $1$.\nThe rules for one time step from $t$ to $t+1$ are:\n$$\n\\begin{cases}\nx_1^{\\text{seq}}(t+1) = x_2^{\\text{seq}}(t) \\\\\nx_2^{\\text{seq}}(t+1) = x_1^{\\text{seq}}(t+1)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(1) = x_2^{\\text{seq}}(0) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(1) = x_1^{\\text{seq}}(1) = 1$.\n  - The state at $t=1$ is $(1, 1)$.\n- $t=2$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(2) = x_2^{\\text{seq}}(1) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(2) = x_1^{\\text{seq}}(2) = 1$.\n  - The state at $t=2$ is $(1, 1)$.\nThe system reaches a fixed point $(1, 1)$ at $t=1$. Therefore, for all $t \\ge 1$, the state is $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t)) = (1, 1)$.\n\n**3. Compute the Trajectory Difference $D(10)$**\nThe trajectory difference is defined as $D(T) = \\sum_{t=0}^{T} d(t)$, where the per-step Hamming distance is $d(t) = |x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t)| + |x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t)|$. We calculate $d(t)$ for each $t$ from $0$ to $10$.\n\n- For $t=0$:\n  - $x^{\\text{sync}}(0) = (0, 1)$ and $x^{\\text{seq}}(0) = (0, 1)$.\n  - $d(0) = |0-0| + |1-1| = 0$.\n\n- For $t \\ge 1$:\n  - The sequential trajectory is fixed: $x^{\\text{seq}}(t) = (1, 1)$.\n  - The synchronous trajectory alternates.\n  - For odd $t \\in \\{1, 3, 5, 7, 9\\}$:\n    - $x^{\\text{sync}}(t) = (1, 0)$.\n    - $d(t) = |1-1| + |0-1| = 0 + 1 = 1$.\n  - For even $t \\in \\{2, 4, 6, 8, 10\\}$:\n    - $x^{\\text{sync}}(t) = (0, 1)$.\n    - $d(t) = |0-1| + |1-1| = 1 + 0 = 1$.\n\nSo, we have $d(0)=0$ and $d(t)=1$ for all $t \\in \\{1, 2, \\dots, 10\\}$.\n\nFinally, we sum these values to find $D(10)$:\n$$\nD(10) = \\sum_{t=0}^{10} d(t) = d(0) + \\sum_{t=1}^{10} d(t)\n$$\n$$\nD(10) = 0 + (d(1) + d(2) + \\dots + d(10))\n$$\n$$\nD(10) = 0 + \\sum_{t=1}^{10} 1 = 10 \\times 1 = 10\n$$\nThe cumulative Hamming distance over the horizon $T=10$ is $10$.",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "Building on the conceptual understanding of update schedules, this hands-on coding challenge moves from theory to practice. You are tasked with implementing a model from scratch to demonstrate how a synchronous update scheme can generate \"spurious\" oscillations—system-level artifacts that may not be present under a more realistic asynchronous schedule. This practice is vital for developing the skills to not only build models but also to critically assess whether their emergent behaviors are genuine phenomena or byproducts of specific implementation choices .",
            "id": "4284430",
            "problem": "You are to construct and analyze a minimal agent-based model that demonstrates how update synchronization can qualitatively change the emergent dynamics, producing spurious oscillations under synchronous updating that vanish under asynchronous updating, even though the local rule is identical. The setting is a one-dimensional ring network in discrete time with binary-state agents. Work from core definitions and formulate your program strictly from first principles, without relying on any pre-built agent-based modeling frameworks.\n\nModel specification:\n\n- Agents and network: There are $n$ agents indexed by $i \\in \\{0,1,\\dots,n-1\\}$ arranged on a ring. Each agent $i$ has two neighbors: $(i-1) \\bmod n$ and $(i+1) \\bmod n$. Each agent $i$ has a binary state $s_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{N}$.\n\n- Local update rule (identical under both modes of updating): For any agent $i$ at time $t$, let $N_i = \\{(i-1) \\bmod n,(i+1) \\bmod n\\}$ be the set of neighbors and define the neighbor sum\n$$\n\\Sigma_i(t) = \\sum_{j \\in N_i} s_j(t).\n$$\nThe local rule produces the next state $s_i(t+1)$ according to the deterministic threshold with tie-flip:\n$$\ns_i(t+1) =\n\\begin{cases}\n1,  \\text{if } \\Sigma_i(t)  1,\\\\\n0,  \\text{if } \\Sigma_i(t)  1,\\\\\n1 - s_i(t),  \\text{if } \\Sigma_i(t) = 1.\n\\end{cases}\n$$\nThus, an agent adopts the strict majority of its two neighbors; in case of a tie, it flips its own state.\n\n- Synchronous versus asynchronous updating:\n  - Synchronous mode: All agents compute $\\Sigma_i(t)$ from the same time-$t$ configuration and update $s_i(t+1)$ simultaneously.\n  - Asynchronous mode: Agents update sequentially within each sweep. A sweep consists of visiting each agent exactly once in a random order and immediately applying the local rule to update its state, so subsequent agents in the same sweep observe the states resulting from prior updates in that sweep. Randomness must be controlled for reproducibility: use the Mersenne Twister pseudo-random generator seeded with $0$ to generate a uniform random permutation of $\\{0,1,\\dots,n-1\\}$ for each sweep. After a sweep with no state changes, the configuration is a fixed point.\n\nDefinitions to be detected by your program:\n\n- Period-$2$ oscillation under synchronous updating: A configuration sequence $\\{s(t)\\}_{t \\ge 0}$ exhibits a period-$2$ oscillation if there exists $t \\ge 2$ such that $s(t) = s(t-2)$ and $s(t) \\ne s(t-1)$.\n- Convergence to a fixed point under asynchronous updating: Starting from the same initial configuration, the asynchronous mode reaches a configuration $s^\\ast$ such that a complete subsequent sweep produces no changes, within a pre-specified maximum number of sweeps.\n\nTask:\n\n1. Implement the agent-based model described above.\n2. For each test case below, starting from the given initial configuration $s(0)$, run the synchronous dynamics for at most $T_{\\text{sync}}$ steps and detect whether a period-$2$ oscillation occurs. Separately, run the asynchronous dynamics for at most $T_{\\text{async}}$ sweeps (each sweep visits all $n$ agents exactly once in a random permutation generated as specified) and detect whether the dynamics converges to a fixed point.\n3. For each test case, output a boolean indicating whether the synchronous dynamics exhibits a period-$2$ oscillation and the asynchronous dynamics converges to a fixed point, both starting from the same initial configuration and using the same local rule.\n\nConstraints and parameters:\n\n- Use $T_{\\text{sync}} = 50$ synchronous steps for period detection.\n- Use $T_{\\text{async}} = 200$ asynchronous sweeps with the random permutation per sweep generated by the Mersenne Twister seeded with $0$ exactly once at the beginning of the run.\n- All numbers and indices are integers; there are no physical units involved.\n\nTest suite:\n\n- Case $1$: $n = 10$, $s(0) = [0,1,0,1,0,1,0,1,0,1]$.\n- Case $2$: $n = 9$, $s(0) = [0,1,0,1,0,1,0,1,0]$.\n- Case $3$: $n = 8$, $s(0) = [0,0,0,0,0,0,0,0]$.\n- Case $4$: $n = 4$, $s(0) = [0,1,0,1]$.\n- Case $5$: $n = 12$, $s(0) = [0,1,0,1,0,1,0,1,0,0,1,0]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true_case_1,true_case_2,true_case_3,true_case_4,true_case_5]\"), where each entry is a boolean corresponding to whether the synchronous dynamics exhibits a period-$2$ oscillation and the asynchronous dynamics converges to a fixed point for the respective test case. The booleans must be printed as \"True\" or \"False\" in the order of the test cases listed above.",
            "solution": "The problem requires the implementation and analysis of a one-dimensional agent-based model with $n$ agents on a ring network. Each agent $i \\in \\{0, 1, \\dots, n-1\\}$ possesses a binary state $s_i(t) \\in \\{0, 1\\}$ at a discrete time step $t \\in \\mathbb{N}$. The state of agent $i$ is updated based on the sum of its two neighbors' states, $\\Sigma_i(t) = s_{(i-1) \\bmod n}(t) + s_{(i+1) \\bmod n}(t)$. The deterministic update rule is a threshold function with a tie-breaking flip, where an agent adopts the strict majority state of its neighbors, or flips its own state in the case of a tie:\n$$\ns_i(t+1) =\n\\begin{cases}\n1,  \\text{if } \\Sigma_i(t) = 2, \\\\\n0,  \\text{if } \\Sigma_i(t) = 0, \\\\\n1 - s_i(t),  \\text{if } \\Sigma_i(t) = 1.\n\\end{cases}\n$$\nWe are tasked to compare the emergent dynamics under two distinct update schemes: synchronous and asynchronous.\n\nFor the synchronous update mode, all $n$ agents compute their next state based on the global configuration at time $t$ and update simultaneously to form the configuration at time $t+1$. We must detect if this process leads to a period-$2$ oscillation within a maximum of $T_{\\text{sync}} = 50$ steps. A period-$2$ oscillation is formally defined as a sequence where, for some time $t \\ge 2$, the system state vector $s(t)$ satisfies the conditions $s(t) = s(t-2)$ and $s(t) \\ne s(t-1)$. Our implementation for this mode iterates through time steps. To detect this behavior, we maintain a history of the two most recent states, $s(t-1)$ and $s(t-2)$. At each step $t$, after computing the new state $s(t)$, we perform the required comparisons.\n\nFor the asynchronous update mode, agents are updated sequentially within a processing cycle called a \"sweep\". Each sweep consists of updating all $n$ agents exactly once, following a random permutation of the agent indices $\\{0, 1, \\dots, n-1\\}$. The state change of an agent is applied immediately, thereby affecting the local neighborhood information used by subsequent agents in the same sweep. For reproducibility, the random permutation for each sweep is generated by a Mersenne Twister pseudo-random number generator, which is seeded once with the value $0$ at the start of the simulation. We must detect if the system converges to a fixed point within a maximum of $T_{\\text{async}} = 200$ sweeps. A fixed point is a configuration that remains unchanged after a complete sweep. Our implementation for this mode creates a copy of the state vector before each sweep and compares it with the state vector after the sweep has concluded. If the two vectors are identical, convergence to a fixed point has occurred.\n\nThe final objective is to solve a set of test cases. For each case, specified by the number of agents $n$ and an initial configuration $s(0)$, we must determine if two conditions are met simultaneously: ($1$) the synchronous dynamics exhibits a period-$2$ oscillation, AND ($2$) the asynchronous dynamics converges to a fixed point. The result for each test case is a single boolean value representing the logical AND of these two outcomes.\n\nThe implementation is written in Python, utilizing the `NumPy` library for efficient handling of agent state vectors and for vectorized state comparisons. The logic is organized into two primary functions, `run_synchronous` and `run_asynchronous`, corresponding to the two update schemes. A main `solve` function coordinates the execution for all provided test cases, calls the simulation functions, aggregates the boolean results, and formats the final output into the specified string format.",
            "answer": "```python\nimport numpy as np\n\ndef run_synchronous(n, s_initial, t_max):\n    \"\"\"\n    Simulates the model with synchronous updates and detects a period-2 oscillation.\n\n    Args:\n        n (int): The number of agents.\n        s_initial (np.ndarray): The initial state vector.\n        t_max (int): The maximum number of steps to simulate.\n\n    Returns:\n        bool: True if a period-2 oscillation is detected, False otherwise.\n    \"\"\"\n    s_curr = s_initial.copy()\n    s_prev = None  # Will store state at t-2\n\n    for t in range(1, t_max + 1):  # t is the current timestep to compute\n        # At the start of this loop, s_curr is the state at t-1\n        s_next = np.empty_like(s_curr)\n        for i in range(n):\n            prev_i = (i - 1 + n) % n\n            next_i = (i + 1) % n\n            neighbor_sum = s_curr[prev_i] + s_curr[next_i]\n\n            if neighbor_sum  1:\n                s_next[i] = 1\n            elif neighbor_sum  1:\n                s_next[i] = 0\n            else:  # neighbor_sum == 1\n                s_next[i] = 1 - s_curr[i]\n\n        # Now s_next is s(t)\n        # Check condition: s(t) == s(t-2) and s(t) != s(t-1)\n        # s_prev is s(t-2), s_curr is s(t-1), s_next is s(t)\n        if s_prev is not None:\n            is_oscillation = (np.array_equal(s_next, s_prev) and\n                              not np.array_equal(s_next, s_curr))\n            if is_oscillation:\n                return True\n\n        # Update states for the next iteration\n        s_prev = s_curr\n        s_curr = s_next\n\n    return False\n\ndef run_asynchronous(n, s_initial, t_max, rng):\n    \"\"\"\n    Simulates the model with asynchronous updates and detects convergence to a fixed point.\n\n    Args:\n        n (int): The number of agents.\n        s_initial (np.ndarray): The initial state vector.\n        t_max (int): The maximum number of sweeps to simulate.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        bool: True if the system converges to a fixed point, False otherwise.\n    \"\"\"\n    s_curr = s_initial.copy()\n\n    for _ in range(t_max):\n        s_before_sweep = s_curr.copy()\n        \n        permutation = rng.permutation(n)\n        \n        for i in permutation:\n            prev_i = (i - 1 + n) % n\n            next_i = (i + 1) % n\n            neighbor_sum = s_curr[prev_i] + s_curr[next_i]\n            \n            if neighbor_sum  1:\n                s_curr[i] = 1\n            elif neighbor_sum  1:\n                s_curr[i] = 0\n            else:  # neighbor_sum == 1\n                s_curr[i] = 1 - s_curr[i]\n        \n        if np.array_equal(s_curr, s_before_sweep):\n            return True\n\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    T_SYNC = 50\n    T_ASYNC = 200\n    RNG_SEED = 0\n\n    rng = np.random.default_rng(RNG_SEED)\n\n    test_cases = [\n        (10, [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]),\n        (9, [0, 1, 0, 1, 0, 1, 0, 1, 0]),\n        (8, [0, 0, 0, 0, 0, 0, 0, 0]),\n        (4, [0, 1, 0, 1]),\n        (12, [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0]),\n    ]\n\n    results = []\n    for n, s0_list in test_cases:\n        s0 = np.array(s0_list, dtype=np.int8)\n        \n        # We need a fresh RNG for each async run to match the problem spec\n        # of seeding once at the beginning of \"the run\" for each test case.\n        # Here we interpret \"the run\" as the combined sync+async test for one case.\n        # But to be safe and ensure test cases are independent, let's re-seed for each.\n        # The prompt says \"seeded with 0 exactly once at the beginning of the run\",\n        # which is slightly ambiguous if it means once for the whole script or once per test case.\n        # The most robust interpretation is that each test case is independent.\n        # However, to strictly follow \"exactly once\", let's use the single RNG object.\n        # This means case 2's permutations depend on how many were drawn for case 1.\n        # The prompt is a little flawed, but we will follow the strictest reading.\n        \n        sync_result = run_synchronous(n, s0, T_SYNC)\n        async_result = run_asynchronous(n, s0, T_ASYNC, rng)\n        \n        final_result = sync_result and async_result\n        results.append(final_result)\n\n    str_results = [str(r) for r in results]\n    print(f\"[{','.join(str_results)}]\")\n\nsolve()\n```"
        }
    ]
}