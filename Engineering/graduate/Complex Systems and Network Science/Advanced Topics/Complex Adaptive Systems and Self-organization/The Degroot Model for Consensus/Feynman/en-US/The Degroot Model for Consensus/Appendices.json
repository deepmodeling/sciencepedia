{
    "hands_on_practices": [
        {
            "introduction": "This first exercise grounds you in the fundamental mechanism of the DeGroot model. By manually calculating the first few time steps for a simple two-agent system, you will gain a concrete understanding of how each agent's opinion evolves as a weighted average of the opinions in the network. This foundational practice is key to visualizing the iterative process of social influence at the heart of consensus dynamics. ",
            "id": "4308894",
            "problem": "Consider a two-agent opinion formation process governed by the DeGroot model for consensus, in which each agent updates its opinion by taking a weighted average of all agents’ previous opinions. The update is represented by multiplying the opinion vector at time $t$ by a nonnegative row-stochastic matrix $W$, where each row sums to $1$ and encodes the weights used by the corresponding agent. Let the weight matrix be\n$$\nW=\\begin{pmatrix}\n0.5  0.5 \\\\\n0.2  0.8\n\\end{pmatrix},\n$$\nand the initial opinion vector be\n$$\nx(0)=\\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix}.\n$$\nStarting from foundational principles—namely, that a row-stochastic matrix produces convex combinations of the previous opinions for each agent—compute the opinion vectors $x(1)$ and $x(2)$ generated by this process. Then, for each entry of $x(1)$ and $x(2)$, interpret it explicitly as a weighted average of the entries of $x(0)$ and $x(1)$, respectively, making clear which weights are applied to which past opinions. Express your final numerical values exactly as rational numbers. Provide your final answer in the form of the single concatenated row vector $\\left(x_{1}(1),\\,x_{2}(1),\\,x_{1}(2),\\,x_{2}(2)\\right)$.",
            "solution": "The DeGroot model describes the evolution of opinions in a network of agents. The state of the system at time step $t$ is given by an opinion vector $x(t)$, where the $i$-th component, $x_i(t)$, represents the opinion of agent $i$. The opinions are updated synchronously according to the linear iteration:\n$$x(t+1) = W x(t)$$\nwhere $W$ is a row-stochastic matrix. The entry $W_{ij}$ of this matrix represents the weight that agent $i$ gives to the opinion of agent $j$ from the previous time step. Since $W$ is row-stochastic, each row sums to $1$, ensuring that each new opinion $x_i(t+1)$ is a convex combination (a weighted average) of the previous opinions $\\{x_j(t)\\}$.\n\nThe given weight matrix is\n$$\nW=\\begin{pmatrix}\n0.5  0.5 \\\\\n0.2  0.8\n\\end{pmatrix}\n$$\nand the initial opinion vector is\n$$\nx(0)=\\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix}.\n$$\nFor calculations involving rational numbers, we convert the decimal entries of $W$ to fractions:\n$$\nW=\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2} \\\\\n\\frac{1}{5}  \\frac{4}{5}\n\\end{pmatrix}\n$$\n\nFirst, we compute the opinion vector at time $t=1$.\n$$\nx(1) = W x(0) = \\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2} \\\\\n\\frac{1}{5}  \\frac{4}{5}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix}\n$$\nThe components of $x(1)$ are calculated as follows:\n$$\nx_1(1) = W_{11}x_1(0) + W_{12}x_2(0) = \\left(\\frac{1}{2}\\right)(1) + \\left(\\frac{1}{2}\\right)(0) = \\frac{1}{2}\n$$\n$$\nx_2(1) = W_{21}x_1(0) + W_{22}x_2(0) = \\left(\\frac{1}{5}\\right)(1) + \\left(\\frac{4}{5}\\right)(0) = \\frac{1}{5}\n$$\nSo, the opinion vector at $t=1$ is $x(1) = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{5} \\end{pmatrix}$.\nInterpreting these results as weighted averages:\n- Agent $1$'s new opinion, $x_1(1)=\\frac{1}{2}$, is a weighted average of the initial opinions, where agent $1$ weights its own initial opinion $x_1(0)=1$ with a weight of $\\frac{1}{2}$ and agent $2$'s initial opinion $x_2(0)=0$ with a weight of $\\frac{1}{2}$.\n- Agent $2$'s new opinion, $x_2(1)=\\frac{1}{5}$, is a weighted average where agent $2$ weights agent $1$'s initial opinion $x_1(0)=1$ with a weight of $\\frac{1}{5}$ and its own initial opinion $x_2(0)=0$ with a weight of $\\frac{4}{5}$.\n\nNext, we compute the opinion vector at time $t=2$.\n$$\nx(2) = W x(1) = \\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2} \\\\\n\\frac{1}{5}  \\frac{4}{5}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{1}{2} \\\\\n\\frac{1}{5}\n\\end{pmatrix}\n$$\nThe components of $x(2)$ are calculated as follows:\n$$\nx_1(2) = W_{11}x_1(1) + W_{12}x_2(1) = \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{5}\\right) = \\frac{1}{4} + \\frac{1}{10} = \\frac{5}{20} + \\frac{2}{20} = \\frac{7}{20}\n$$\n$$\nx_2(2) = W_{21}x_1(1) + W_{22}x_2(1) = \\left(\\frac{1}{5}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{4}{5}\\right)\\left(\\frac{1}{5}\\right) = \\frac{1}{10} + \\frac{4}{25} = \\frac{5}{50} + \\frac{8}{50} = \\frac{13}{50}\n$$\nSo, the opinion vector at $t=2$ is $x(2) = \\begin{pmatrix} \\frac{7}{20} \\\\ \\frac{13}{50} \\end{pmatrix}$.\nInterpreting these results as weighted averages:\n- Agent $1$'s opinion at $t=2$, $x_1(2)=\\frac{7}{20}$, is a weighted average of the opinions at $t=1$, where agent $1$ weights its own previous opinion $x_1(1)=\\frac{1}{2}$ with a weight of $\\frac{1}{2}$ and agent $2$'s previous opinion $x_2(1)=\\frac{1}{5}$ with a weight of $\\frac{1}{2}$.\n- Agent $2$'s opinion at $t=2$, $x_2(2)=\\frac{13}{50}$, is a weighted average of the opinions at $t=1$, where agent $2$ weights agent $1$'s previous opinion $x_1(1)=\\frac{1}{2}$ with a weight of $\\frac{1}{5}$ and its own previous opinion $x_2(1)=\\frac{1}{5}$ with a weight of $\\frac{4}{5}$.\n\nThe problem requests the final answer as the single concatenated row vector $\\left(x_{1}(1),\\,x_{2}(1),\\,x_{1}(2),\\,x_{2}(2)\\right)$. Using the computed values:\n$$\n\\left(\\frac{1}{2}, \\frac{1}{5}, \\frac{7}{20}, \\frac{13}{50}\\right)\n$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{5}  \\frac{7}{20}  \\frac{13}{50}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While iterating the system step-by-step is insightful, we often want to predict the final outcome directly. This practice introduces the powerful concept of the influence vector, $\\pi$, which quantifies the long-term importance of each agent in determining the final consensus. You will learn to calculate this vector as the stationary distribution of the influence matrix and use it to find the system's equilibrium point without simulating the entire process. ",
            "id": "4308906",
            "problem": "Consider a network of $3$ agents interacting under the DeGroot consensus model, with opinions updated by $x(t+1)=W\\,x(t)$ at discrete time $t \\in \\{0,1,2,\\dots\\}$, where $W$ is a row-stochastic influence matrix. Let\n$$\nW=\\begin{pmatrix}\n0.7  0.3  0 \\\\\n0.2  0.5  0.3 \\\\\n0  0.4  0.6\n\\end{pmatrix},\n\\qquad\nx(0)=\\begin{pmatrix}1 \\\\ 2 \\\\ 0\\end{pmatrix}.\n$$\nUsing only the core definitions of row-stochasticity and the Perron–Frobenius theorem for primitive nonnegative matrices, proceed from first principles to determine the unique influence vector $\\pi \\in \\mathbb{R}^3$ with strictly positive entries satisfying $\\pi^{\\top}W=\\pi^{\\top}$ and $\\pi^{\\top}\\mathbf{1}=1$, and then compute the consensus value $c$ attained by the DeGroot dynamics starting from $x(0)$. Explicitly verify the normalization of $\\pi$ as part of your derivation. Provide your final answer as a single row matrix containing the three components of $\\pi$ followed by $c$, in exact form. No rounding is required, and no units are involved.",
            "solution": "The problem requires the determination of the influence vector $\\pi$ and the consensus value $c$ for a DeGroot consensus model defined by the opinion update rule $x(t+1)=W\\,x(t)$. The influence matrix $W$ is given as\n$$\nW=\\begin{pmatrix}\n0.7  0.3  0 \\\\\n0.2  0.5  0.3 \\\\\n0  0.4  0.6\n\\end{pmatrix}\n$$\nand the initial opinion vector is\n$$\nx(0)=\\begin{pmatrix}1 \\\\ 2 \\\\ 0\\end{pmatrix}\n$$\nThe matrix $W$ has non-negative entries, and the sum of the entries in each row is $1$. For example, for the first row, $0.7 + 0.3 + 0 = 1$. This confirms that $W$ is a row-stochastic matrix. Furthermore, while $W$ has zero entries, its square is\n$$\nW^2 = \\begin{pmatrix}\n0.7  0.3  0 \\\\\n0.2  0.5  0.3 \\\\\n0  0.4  0.6\n\\end{pmatrix}\n\\begin{pmatrix}\n0.7  0.3  0 \\\\\n0.2  0.5  0.3 \\\\\n0  0.4  0.6\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.55  0.36  0.09 \\\\\n0.24  0.43  0.33 \\\\\n0.08  0.44  0.48\n\\end{pmatrix}\n$$\nSince all entries of $W^2$ are strictly positive, the matrix $W$ is primitive.\n\nAccording to the Perron–Frobenius theorem for primitive non-negative matrices, such a matrix has a unique largest eigenvalue, which is real and positive. For a row-stochastic matrix, this eigenvalue is $\\lambda_1 = 1$. The theorem also guarantees the existence of a unique left eigenvector $\\pi^{\\top}$ corresponding to $\\lambda_1 = 1$, which can be normalized such that its components are strictly positive and sum to $1$. This vector $\\pi$ is the influence vector, representing the stationary distribution of influence among the agents.\n\nFirst, we find the influence vector $\\pi = \\begin{pmatrix} \\pi_1  \\pi_2  \\pi_3 \\end{pmatrix}^{\\top}$. It must satisfy the eigenvector equation $\\pi^{\\top}W = \\pi^{\\top}$, which is equivalent to $W^{\\top}\\pi = \\pi$, or $(W^{\\top}-I)\\pi = \\mathbf{0}$, where $I$ is the identity matrix and $\\mathbf{0}$ is the zero vector.\n\nThe transpose of $W$ is\n$$\nW^{\\top} = \\begin{pmatrix}\n0.7  0.2  0 \\\\\n0.3  0.5  0.4 \\\\\n0  0.3  0.6\n\\end{pmatrix}\n$$\nThe matrix $(W^{\\top}-I)$ is\n$$\nW^{\\top}-I = \\begin{pmatrix}\n0.7-1  0.2  0 \\\\\n0.3  0.5-1  0.4 \\\\\n0  0.3  0.6-1\n\\end{pmatrix}\n= \\begin{pmatrix}\n-0.3  0.2  0 \\\\\n0.3  -0.5  0.4 \\\\\n0  0.3  -0.4\n\\end{pmatrix}\n$$\nThe system of linear equations $(W^{\\top}-I)\\pi = \\mathbf{0}$ is:\n\\begin{align*}\n-0.3 \\pi_1 + 0.2 \\pi_2 = 0 \\\\\n0.3 \\pi_1 - 0.5 \\pi_2 + 0.4 \\pi_3 = 0 \\\\\n0.3 \\pi_2 - 0.4 \\pi_3 = 0\n\\end{align*}\nFrom the first equation, we get $0.3 \\pi_1 = 0.2 \\pi_2$, which simplifies to $3 \\pi_1 = 2 \\pi_2$, or $\\pi_1 = \\frac{2}{3} \\pi_2$.\nFrom the third equation, we get $0.3 \\pi_2 = 0.4 \\pi_3$, which simplifies to $3 \\pi_2 = 4 \\pi_3$, or $\\pi_3 = \\frac{3}{4} \\pi_2$.\nSubstituting these into the second equation confirms consistency: $0.3(\\frac{2}{3}\\pi_2) - 0.5\\pi_2 + 0.4(\\frac{3}{4}\\pi_2) = 0.2\\pi_2 - 0.5\\pi_2 + 0.3\\pi_2 = 0$.\nThe eigenvector $\\pi$ is thus proportional to the vector $\\begin{pmatrix} \\frac{2}{3}  1  \\frac{3}{4} \\end{pmatrix}^{\\top}$. To work with integers, we can multiply by the least common multiple of the denominators, which is $12$, to get a proportional vector $\\begin{pmatrix} 8  12  9 \\end{pmatrix}^{\\top}$.\n\nNow, we must normalize this vector so that its components sum to $1$, satisfying the condition $\\pi^{\\top}\\mathbf{1} = \\sum_{i=1}^3 \\pi_i = 1$. The sum of the unnormalized components is $8 + 12 + 9 = 29$.\nThus, the influence vector $\\pi$ is:\n$$\n\\pi = \\frac{1}{29}\\begin{pmatrix} 8 \\\\ 12 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} 8/29 \\\\ 12/29 \\\\ 9/29 \\end{pmatrix}\n$$\nExplicitly verifying the normalization as required: $\\pi_1+\\pi_2+\\pi_3 = \\frac{8}{29} + \\frac{12}{29} + \\frac{9}{29} = \\frac{8+12+9}{29} = \\frac{29}{29} = 1$. This is correct.\n\nNext, we compute the consensus value $c$. The dynamics converge to a state where all opinions are equal, i.e., $\\lim_{t\\to\\infty} x(t) = c\\mathbf{1}$.\nLet us consider the quantity $M(t) = \\pi^{\\top}x(t)$. Its evolution in time is\n$$\nM(t+1) = \\pi^{\\top}x(t+1) = \\pi^{\\top}(W x(t)) = (\\pi^{\\top}W)x(t)\n$$\nSince $\\pi^{\\top}$ is the left eigenvector of $W$ with eigenvalue $1$, we have $\\pi^{\\top}W = \\pi^{\\top}$. Therefore,\n$$\nM(t+1) = \\pi^{\\top}x(t) = M(t)\n$$\nThis shows that $M(t)$ is a conserved quantity. The value of $M(t)$ is constant for all $t \\ge 0$.\nThus, $M(\\infty) = M(0)$.\nThe limit value is $M(\\infty) = \\lim_{t\\to\\infty} \\pi^{\\top}x(t) = \\pi^{\\top} (c\\mathbf{1}) = c (\\pi^{\\top}\\mathbf{1}) = c(1) = c$.\nThe initial value is $M(0) = \\pi^{\\top}x(0)$.\nEquating these, we find the consensus value is $c = \\pi^{\\top}x(0)$.\n\nUsing the given initial state $x(0) = \\begin{pmatrix} 1  2  0 \\end{pmatrix}^{\\top}$ and the derived influence vector $\\pi$:\n$$\nc = \\begin{pmatrix} \\frac{8}{29}  \\frac{12}{29}  \\frac{9}{29} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}\n$$\n$$\nc = \\left(\\frac{8}{29}\\right)(1) + \\left(\\frac{12}{29}\\right)(2) + \\left(\\frac{9}{29}\\right)(0) = \\frac{8 + 24 + 0}{29} = \\frac{32}{29}\n$$\nThe consensus value is $c = \\frac{32}{29}$.\n\nThe components of the influence vector are $\\pi_1 = \\frac{8}{29}$, $\\pi_2 = \\frac{12}{29}$, $\\pi_3 = \\frac{9}{29}$, and the consensus value is $c = \\frac{32}{29}$.\nThe final answer is presented as a row matrix containing these four values.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{8}{29}  \\frac{12}{29}  \\frac{9}{29}  \\frac{32}{29} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The structure of the influence network can drastically alter consensus dynamics, sometimes preventing a simple average and instead leading to a dictated outcome. This exercise explores the critical case of an \"absorbing node\"—an agent who is completely stubborn and does not update their opinion. By analyzing the network's connectivity, you will see how such an agent can determine the final opinion of the entire group, offering a key insight into information flow and control in networked systems. ",
            "id": "4308896",
            "problem": "Consider the discrete-time DeGroot opinion dynamics on $n=4$ agents with update $x(t+1)=W x(t)$, where $W$ is a row-stochastic matrix (each row sums to $1$ and entries are nonnegative). The directed confidence graph $G(W)$ has an edge $i \\to j$ if and only if $w_{ij}  0$. Let\n$$\nW \\;=\\; \\begin{pmatrix}\n0.5  0.5  0  0 \\\\\n0.25  0.25  0.5  0 \\\\\n0  0  1  0 \\\\\n0.3  0.2  0.5  0\n\\end{pmatrix},\n$$\nand let the initial opinion vector be\n$$\nx(0) \\;=\\; \\begin{pmatrix} x_1(0) \\\\ x_2(0) \\\\ x_3(0) \\\\ x_4(0) \\end{pmatrix} \\in \\mathbb{R}^4.\n$$\nStarting from the foundational definitions of the DeGroot model and the induced confidence graph $G(W)$, identify the absorbing node in $G(W)$ and derive the limit opinions $x(\\infty) = \\lim_{t\\to\\infty} x(t)$ in closed form for an arbitrary initial condition $x(0)$. Express your final answer as a single row matrix that contains, in order, the index of the absorbing node and the four entries of $x(\\infty)$.",
            "solution": "The DeGroot model describes the evolution of opinions based on the update rule $x(t+1) = W x(t)$. We are asked to find the long-term opinion vector $x(\\infty) = \\lim_{t\\to\\infty} x(t)$ for an arbitrary initial state $x(0)$.\n\nFirst, we analyze the influence matrix $W$ to identify any special agents. An agent $i$ is an **absorbing node** if they are completely stubborn, meaning they only listen to their own opinion. This is reflected in the influence matrix by the $i$-th row being an identity vector, i.e., $W_{ii} = 1$ and $W_{ij} = 0$ for $j \\neq i$.\nLet's inspect the given matrix:\n$$\nW \\;=\\; \\begin{pmatrix}\n0.5  0.5  0  0 \\\\\n0.25  0.25  0.5  0 \\\\\n0  0  1  0 \\\\\n0.3  0.2  0.5  0\n\\end{pmatrix}\n$$\nThe third row is $(0, 0, 1, 0)$, which means $W_{33}=1$. Therefore, agent $3$ is an absorbing node. Its opinion is fixed for all time:\n$$\nx_3(t+1) = \\sum_{j=1}^4 W_{3j}x_j(t) = 1 \\cdot x_3(t) = x_3(t)\n$$\nThis implies $x_3(t) = x_3(0)$ for all $t \\geq 0$. In the limit, $x_3(\\infty) = x_3(0)$.\n\nNext, we must determine the fate of the other agents' opinions. A key result in the study of such systems states that if there is a single absorbing class (in this case, the set containing only node $\\{3\\}$) and every other node has a directed path to this class in the confidence graph $G(W)$, then all opinions will converge to the value held by the agent(s) in that class.\n\nLet's check for paths to node 3 from all other nodes:\n-   **From node 1:** There is no direct edge $1 \\to 3$ (since $W_{13}=0$), but there is a path $1 \\to 2 \\to 3$ because $W_{12}=0.5 > 0$ and $W_{23}=0.5 > 0$. So, node 3 is reachable from node 1.\n-   **From node 2:** There is a direct edge $2 \\to 3$ because $W_{23}=0.5 > 0$. So, node 3 is reachable from node 2.\n-   **From node 4:** There is a direct edge $4 \\to 3$ because $W_{43}=0.5 > 0$. So, node 3 is reachable from node 4.\n\nSince the unique absorbing node $3$ is reachable from every other node, all agents' opinions will eventually converge to the fixed opinion of agent 3.\nTherefore, the limit opinion vector is:\n$$\nx(\\infty) = \\begin{pmatrix} x_1(\\infty) \\\\ x_2(\\infty) \\\\ x_3(\\infty) \\\\ x_4(\\infty) \\end{pmatrix} = \\begin{pmatrix} x_3(0) \\\\ x_3(0) \\\\ x_3(0) \\\\ x_3(0) \\end{pmatrix}\n$$\nWe can verify this by confirming that this vector is a fixed point of the update rule, $x(\\infty) = W x(\\infty)$:\n$$\nW x(\\infty) = \\begin{pmatrix}\n0.5  0.5  0  0 \\\\\n0.25  0.25  0.5  0 \\\\\n0  0  1  0 \\\\\n0.3  0.2  0.5  0\n\\end{pmatrix}\n\\begin{pmatrix} x_3(0) \\\\ x_3(0) \\\\ x_3(0) \\\\ x_3(0) \\end{pmatrix} =\n\\begin{pmatrix} (0.5+0.5)x_3(0) \\\\ (0.25+0.25+0.5)x_3(0) \\\\ (1)x_3(0) \\\\ (0.3+0.2+0.5)x_3(0) \\end{pmatrix} =\n\\begin{pmatrix} 1 \\cdot x_3(0) \\\\ 1 \\cdot x_3(0) \\\\ 1 \\cdot x_3(0) \\\\ 1 \\cdot x_3(0) \\end{pmatrix} = x(\\infty)\n$$\nThe calculation confirms our conclusion.\n\nThe final answer requires the index of the absorbing node (which is $3$) and the four entries of the limit vector $x(\\infty)$.\nThe components are:\n- Index of absorbing node: $3$\n- $x_1(\\infty) = x_3(0)$\n- $x_2(\\infty) = x_3(0)$\n- $x_3(\\infty) = x_3(0)$\n- $x_4(\\infty) = x_3(0)$\n\nThe result is expressed as the single row matrix $\\begin{pmatrix} 3  x_3(0)  x_3(0)  x_3(0)  x_3(0) \\end{pmatrix}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 3  x_3(0)  x_3(0)  x_3(0)  x_3(0) \\end{pmatrix}}\n$$"
        }
    ]
}