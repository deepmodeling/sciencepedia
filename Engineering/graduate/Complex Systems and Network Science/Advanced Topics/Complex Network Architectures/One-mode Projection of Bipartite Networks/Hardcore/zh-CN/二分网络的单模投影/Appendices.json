{
    "hands_on_practices": [
        {
            "introduction": "理解单模投影最直接的方式便是借助线性代数的视角。将一个二分网络的关联矩阵转换为其中一个节点集的加权邻接矩阵，其操作出人意料地简洁。这个练习将探讨使用矩阵乘法进行单模投影的基础计算，特别是格拉姆矩阵（Gram matrices）的构建，即 $W = BB^\\top$ 和 $W' = B^\\top B$。通过完成这个练习 ，你将巩固对投影网络中的边权重和节点强度如何直接关联于原始二分网络的结构与度值的理解。",
            "id": "4294500",
            "problem": "考虑一个具有节点集 $\\mathcal{U}$ 和 $\\mathcal{V}$ 的二分网络，由一个二元关联矩阵 $B \\in \\{0,1\\}^{|\\mathcal{U}| \\times |\\mathcal{V}|}$ 表示，其中当且仅当节点 $u \\in \\mathcal{U}$ 与节点 $v \\in \\mathcal{V}$ 相连时，$B_{uv} = 1$，否则 $B_{uv} = 0$。标准的到 $\\mathcal{U}$ 上的单模投影定义为：节点 $u,u' \\in \\mathcal{U}$ 之间的权重等于它们在 $\\mathcal{V}$ 中共享的共同邻居数量；类似地，到 $\\mathcal{V}$ 上的投影将节点 $v,v' \\in \\mathcal{V}$ 之间的权重赋值为它们在 $\\mathcal{U}$ 中的共同邻居数量。这些权重可以分别由 $B$ 的行向量和列向量的格拉姆矩阵构造。\n\n令\n$$\nB=\\begin{pmatrix}\n1  1  0 \\\\\n0  1  1\n\\end{pmatrix},\n$$\n其中有 $|\\mathcal{U}|=2$ 行和 $|\\mathcal{V}|=3$ 列。\n\n仅使用上述定义和标准的线性代数知识，完成以下任务：\n\n1. 从基本定义出发，推导到 $\\mathcal{U}$ 上的单模投影的加权邻接矩阵 $W$，并对给定的 $B$ 进行显式计算。\n\n2. 从基本定义出发，推导到 $\\mathcal{V}$ 上的单模投影的加权邻接矩阵 $W'$，并对给定的 $B$ 进行显式计算。\n\n3. 令 $k_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$ 和 $k_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 分别表示通过对 $B$ 的行和列求和得到的二分度向量。使用与全1向量 $\\mathbf{1}_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 和 $\\mathbf{1}_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$ 的矩阵-向量乘积来表示 $k_{\\mathcal{U}}$ 和 $k_{\\mathcal{V}}$，并为给定的 $B$ 计算它们。证明 $W$ 的对角线元素等于 $k_{\\mathcal{U}}$ 的元素，$W'$ 的对角线元素等于 $k_{\\mathcal{V}}$ 的元素。\n\n4. 将投影中的加权度（也称为强度）向量定义为 $s_{\\mathcal{U}} = W \\,\\mathbf{1}_{\\mathcal{U}}$ 和 $s_{\\mathcal{V}} = W' \\,\\mathbf{1}_{\\mathcal{V}}$。推导将 $s_{\\mathcal{U}}$ 与 $B$ 和 $k_{\\mathcal{V}}$ 联系起来，以及将 $s_{\\mathcal{V}}$ 与 $B$ 和 $k_{\\mathcal{U}}$ 联系起来的恒等式，并为给定的 $B$ 显式计算这些向量。\n\n作为最终的数值答案，报告标量\n$$\nD \\equiv \\det(W) + \\operatorname{rank}(W').\n$$\n无需四舍五入。只提供 $D$ 的值作为你的最终答案。",
            "solution": "问题陈述已经过验证，被认为是具有科学依据、提法恰当、客观且内部一致的。它提出了一个网络科学中的标准练习，具体涉及二分网络的单模投影，并要求应用线性代数的基本概念。所有定义都清晰明了，所有必要的数据都已提供。因此，我们可以进行完整的解答。\n\n该问题要求对由关联矩阵\n$$\nB=\\begin{pmatrix}\n1  1  0 \\\\\n0  1  1\n\\end{pmatrix}\n$$\n定义的二分网络的单模投影进行相关的推导和计算，其中行对应于节点集 $\\mathcal{U}$ (有 $|\\mathcal{U}|=2$)，列对应于节点集 $\\mathcal{V}$ (有 $|\\mathcal{V}|=3$)。\n\n1. 到 $\\mathcal{U}$ 上的投影的加权邻接矩阵 $W$。\n\n根据定义，两个节点 $u, u' \\in \\mathcal{U}$ 之间的权重 $W_{u,u'}$ 是它们在 $\\mathcal{V}$ 中共享的共同邻居的数量。一个节点 $v \\in \\mathcal{V}$ 是 $u$ 和 $u'$ 的共同邻居，当且仅当存在连接 $u$ 到 $v$ 以及 $u'$ 到 $v$ 的边。用关联矩阵 $B$ 表示，这意味着 $B_{uv}=1$ 且 $B_{u'v}=1$。由于 $B$ 的元素是 0 或 1，如果 $v$ 是一个共同邻居，则乘积 $B_{uv}B_{u'v}$ 为 1，否则为 0。共同邻居的总数是对所有可能的邻居 $v \\in \\mathcal{V}$ 求和：\n$$\nW_{u,u'} = \\sum_{v \\in \\mathcal{V}} B_{uv}B_{u'v}\n$$\n这个表达式是 $B$ 的第 $u$ 个行向量与第 $u'$ 个行向量的点积。设矩阵 $B$ 的维度为 $m \\times n$，其中 $m = |\\mathcal{U}|$ 且 $n = |\\mathcal{V}|$。$B$ 与其转置 $B^T$ 的乘积是一个 $m \\times m$ 矩阵。乘积 $B B^T$ 的第 $(u,u')$ 个元素由下式给出：\n$$\n(B B^T)_{u,u'} = \\sum_{v=1}^{n} B_{uv} (B^T)_{vu'} = \\sum_{v=1}^{n} B_{uv} B_{u'v}\n$$\n这与 $W_{u,u'}$ 的定义相符。因此，到 $\\mathcal{U}$ 上的投影的加权邻接矩阵由 $W = B B^T$ 给出。\n\n对于给定的矩阵 $B$，我们有：\n$$\nB^T = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix}\n$$\n因此，\n$$\nW = B B^T = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(1)(1)+(0)(0)  (1)(0)+(1)(1)+(0)(1) \\\\ (0)(1)+(1)(1)+(1)(0)  (0)(0)+(1)(1)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\n\n2. 到 $\\mathcal{V}$ 上的投影的加权邻接矩阵 $W'$。\n\n类似地，两个节点 $v, v' \\in \\mathcal{V}$ 之间的权重 $W'_{v,v'}$ 是它们在 $\\mathcal{U}$ 中的共同邻居的数量。遵循同样的逻辑，如果 $B_{uv}=1$ 且 $B_{uv'}=1$，则节点 $u \\in \\mathcal{U}$ 是一个共同邻居。共同邻居的总数是：\n$$\nW'_{v,v'} = \\sum_{u \\in \\mathcal{U}} B_{uv}B_{uv'}\n$$\n这个表达式可以被看作是矩阵乘积 $B^T B$ 的一个元素。$B^T$ 的维度是 $n \\times m$，$B$ 的维度是 $m \\times n$，所以 $B^T B$ 是一个 $n \\times n$ 矩阵。$B^T B$ 的第 $(v,v')$ 个元素是：\n$$\n(B^T B)_{v,v'} = \\sum_{u=1}^{m} (B^T)_{vu} B_{uv'} = \\sum_{u=1}^{m} B_{uv} B_{uv'}\n$$\n这与 $W'_{v,v'}$ 的定义相符。因此，到 $\\mathcal{V}$ 上的投影的加权邻接矩阵由 $W' = B^T B$ 给出。\n\n对于给定的矩阵 $B$：\n$$\nW' = B^T B = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0)(0)  (1)(1)+(0)(1)  (1)(0)+(0)(1) \\\\ (1)(1)+(1)(0)  (1)(1)+(1)(1)  (1)(0)+(1)(1) \\\\ (0)(1)+(1)(0)  (0)(1)+(1)(1)  (0)(0)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix}\n$$\n\n3. 二分度向量及其与 $W$ 和 $W'$ 对角线的关系。\n\n节点 $u \\in \\mathcal{U}$ 的二分度，记为 $k_u$，是 $B$ 的第 $u$ 行元素之和。度向量 $k_{\\mathcal{U}}$ 是这些行和的列向量。使用全1向量 $\\mathbf{1}_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$，乘积 $B \\mathbf{1}_{\\mathcal{V}}$ 的第 $u$ 个分量是 $\\sum_{v \\in \\mathcal{V}} B_{uv} \\cdot 1 = k_u$。因此，$k_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}}$。\n节点 $v \\in \\mathcal{V}$ 的二分度，记为 $k_v$，是 $B$ 的第 $v$ 列元素之和。度向量 $k_{\\mathcal{V}}$ 是这些列和的列向量。这等价于对 $B^T$ 的行求和。使用全1向量 $\\mathbf{1}_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$，乘积 $B^T \\mathbf{1}_{\\mathcal{U}}$ 的第 $v$ 个分量是 $\\sum_{u \\in \\mathcal{U}} (B^T)_{vu} \\cdot 1 = \\sum_{u \\in \\mathcal{U}} B_{uv} = k_v$。因此，$k_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}}$。\n\n为给定的 $B$ 计算这些向量：\n$$\n\\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\nk_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+1+0 \\\\ 0+1+1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\n$$\n$$\nk_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+0 \\\\ 1+1 \\\\ 0+1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}\n$$\n\n为证明与对角线的关系，考虑对角线元素 $W_{u,u}$：\n$$\nW_{u,u} = \\sum_{v \\in \\mathcal{V}} B_{uv}B_{uv} = \\sum_{v \\in \\mathcal{V}} (B_{uv})^2\n$$\n由于 $B_{uv} \\in \\{0,1\\}$，我们有 $(B_{uv})^2 = B_{uv}$。因此，\n$$\nW_{u,u} = \\sum_{v \\in \\mathcal{V}} B_{uv} = k_u\n$$\n这表明 $W$ 的对角线元素是度向量 $k_{\\mathcal{U}}$ 的元素。\n对于我们计算出的 $W$，其对角线为 $(2, 2)$，与 $k_{\\mathcal{U}}$ 相符。\n\n类似地，对于对角线元素 $W'_{v,v}$：\n$$\nW'_{v,v} = \\sum_{u \\in \\mathcal{U}} B_{uv}B_{uv} = \\sum_{u \\in \\mathcal{U}} (B_{uv})^2 = \\sum_{u \\in \\mathcal{U}} B_{uv} = k_v\n$$\n这表明 $W'$ 的对角线元素是度向量 $k_{\\mathcal{V}}$ 的元素。\n对于我们计算出的 $W'$，其对角线为 $(1, 2, 1)$，与 $k_{\\mathcal{V}}$ 相符。\n\n4. 投影中的强度向量。\n\n强度向量 $s_{\\mathcal{U}}$ 定义为 $s_{\\mathcal{U}} = W \\mathbf{1}_{\\mathcal{U}}$。代入 $W = B B^T$：\n$$\ns_{\\mathcal{U}} = (B B^T) \\mathbf{1}_{\\mathcal{U}} = B (B^T \\mathbf{1}_{\\mathcal{U}})\n$$\n从第3部分，我们知道 $k_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}}$。因此，我们得到恒等式 $s_{\\mathcal{U}} = B k_{\\mathcal{V}}$。\n\n强度向量 $s_{\\mathcal{V}}$ 定义为 $s_{\\mathcal{V}} = W' \\mathbf{1}_{\\mathcal{V}}$。代入 $W' = B^T B$：\n$$\ns_{\\mathcal{V}} = (B^T B) \\mathbf{1}_{\\mathcal{V}} = B^T (B \\mathbf{1}_{\\mathcal{V}})\n$$\n从第3部分，我们知道 $k_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}}$。因此，我们得到恒等式 $s_{\\mathcal{V}} = B^T k_{\\mathcal{U}}$。\n\n为给定的 $B$ 计算这些向量：\n$$\ns_{\\mathcal{U}} = W \\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2+1 \\\\ 1+2 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}\n$$\n用恒等式验证：\n$s_{\\mathcal{U}} = B k_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+2+0 \\\\ 0+2+1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}$。结果是一致的。\n\n$$\ns_{\\mathcal{V}} = W' \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+1+0 \\\\ 1+2+1 \\\\ 0+1+1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}\n$$\n用恒等式验证：\n$s_{\\mathcal{V}} = B^T k_{\\mathcal{U}} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 2+0 \\\\ 2+2 \\\\ 0+2 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}$。结果是一致的。\n\n最终数值答案。\n需要计算的标量是 $D \\equiv \\det(W) + \\operatorname{rank}(W')$。\n首先，我们计算 $W$ 的行列式：\n$$\nW = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\n$$\n\\det(W) = (2)(2) - (1)(1) = 4 - 1 = 3\n$$\n接下来，我们计算 $W'$ 的秩：\n$$\nW' = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix}\n$$\n线性代数中的一个基本结果表明 $\\operatorname{rank}(A^T A) = \\operatorname{rank}(A)$。因此，$\\operatorname{rank}(W') = \\operatorname{rank}(B^T B) = \\operatorname{rank}(B)$。矩阵 $B$ 是：\n$$\nB = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix}\n$$\n这个矩阵已经是行阶梯形。它有两个非零行，这两个行是线性无关的。因此，$B$ 的秩为2。\n$$\n\\operatorname{rank}(W') = \\operatorname{rank}(B) = 2\n$$\n或者，可以计算 $W'$ 的行列式：\n$$\n\\det(W') = 1 \\begin{vmatrix} 2  1 \\\\ 1  1 \\end{vmatrix} - 1 \\begin{vmatrix} 1  1 \\\\ 0  1 \\end{vmatrix} + 0 = 1(2-1) - 1(1-0) = 1 - 1 = 0\n$$\n由于 $\\det(W')=0$，其秩必须小于3。左上角的 $2 \\times 2$ 子矩阵 $\\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix}$ 的行列式为 $2-1=1 \\neq 0$，所以秩至少为2。因此，$\\operatorname{rank}(W')=2$。\n\n最后，我们计算 $D$：\n$$\nD = \\det(W) + \\operatorname{rank}(W') = 3 + 2 = 5\n$$",
            "answer": "$$\\boxed{5}$$"
        },
        {
            "introduction": "在构建投影网络时，简单地计算共同邻居的数量可能会产生误导，因为度数高的节点偶然共享邻居的可能性更大。为了创建更有意义的投影，我们通常采用标准化的相似度指标。这个练习  要求你推导并比较两种最常见的度量方法：Jaccard 指数和余弦相似度。这种比较将阐明这些度量方法背后不同的假设，并帮助你培养在特定研究问题中选择合适投影方法的批判性思维。",
            "id": "4294525",
            "problem": "考虑一个用户-物品二分网络，由关联矩阵 $B$ 表示，其元素 $B_{i\\alpha} \\in \\{0,1\\}$。如果用户 $i$ 购买了物品 $\\alpha$，则 $B_{i\\alpha} = 1$，否则 $B_{i\\alpha} = 0$。用户 $i$ 的度为 $d_i = \\sum_{\\alpha} B_{i\\alpha}$，用户 $i$ 和 $j$ 之间的共同物品数量为 $c = \\sum_{\\alpha} B_{i\\alpha} B_{j\\alpha}$。在向用户的一模投影中，一种常见的方法是基于用户 $i$ 和 $j$ 的物品邻域重叠来为他们分配一个相似性权重。\n\n仅从这些定义出发，推导用户 $i$ 和 $j$ 之间的余弦相似度和 Jaccard 指数的表达式（用 $d_i$、$d_j$ 和 $c$ 表示），然后针对 $d_i = 8$、$d_j = 10$ 和 $c = 4$ 的情况对这两个指标进行求值。作为对这两种相似性概念的定量比较，请计算此情况下余弦相似度与 Jaccard 指数的比率。请给出最终答案，形式为一个单一、简化的精确表达式，无单位。不要四舍五入。",
            "solution": "问题陈述有效。它具有科学依据，提法明确，并提供了推导和计算所需量所必需的所有信息，前提是假设余弦相似度和 Jaccard 指数采用标准定义，这在此背景下是合理的预期。\n\n该问题要求推导在一个用户-物品二分网络向用户的一模投影中，两个常见的相似性度量：余弦相似度和 Jaccard 指数。这些推导将用给定的量来表示：用户 $i$ 的度 $d_i$；用户 $j$ 的度 $d_j$；以及他们之间的共同物品数量 $c$。\n\n设所有物品的集合由 $\\alpha$ 索引。用户 $i$ 可以由物品空间中的一个向量 $\\mathbf{v}_i$ 表示，其中与物品 $\\alpha$ 对应的分量由关联矩阵的元素 $B_{i\\alpha}$ 给出。因此，$\\mathbf{v}_i = (B_{i1}, B_{i2}, \\dots, B_{iM})$，其中 $M$ 是物品的总数。元素 $B_{i\\alpha}$ 的值为 $1$ 或 $0$。\n\n首先，我们推导余弦相似度的表达式。两个向量 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间的余弦相似度定义为它们之间夹角的余弦值，其计算方法是向量的点积除以它们模长（欧几里得范数或 L2 范数）的乘积。\n$$ \\cos(\\theta)_{ij} = \\frac{\\mathbf{v}_i \\cdot \\mathbf{v}_j}{\\|\\mathbf{v}_i\\| \\|\\mathbf{v}_j\\|} $$\n点积 $\\mathbf{v}_i \\cdot \\mathbf{v}_j$ 的计算如下：\n$$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = \\sum_{\\alpha} B_{i\\alpha} B_{j\\alpha} $$\n乘积 $B_{i\\alpha} B_{j\\alpha}$ 仅在 $B_{i\\alpha}=1$ 且 $B_{j\\alpha}=1$ 时为 $1$，这意味着用户 $i$ 和 $j$ 都购买了物品 $\\alpha$。否则，该乘积为 $0$。因此，对所有 $\\alpha$ 的求和计算了两个用户共有的物品数量。问题陈述将此量定义为 $c$。因此，\n$$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = c $$\n用户向量 $\\mathbf{v}_i$ 的模长由 $\\|\\mathbf{v}_i\\| = \\sqrt{\\sum_{\\alpha} B_{i\\alpha}^2}$ 给出。由于元素 $B_{i\\alpha}$ 是二元的（$0$ 或 $1$），我们有 $B_{i\\alpha}^2 = B_{i\\alpha}$。因此，模长的平方为：\n$$ \\|\\mathbf{v}_i\\|^2 = \\sum_{\\alpha} B_{i\\alpha}^2 = \\sum_{\\alpha} B_{i\\alpha} $$\n这个和是用户 $i$ 购买的物品总数，被定义为用户的度 $d_i$。所以，$\\|\\mathbf{v}_i\\|^2 = d_i$，这意味着 $\\|\\mathbf{v}_i\\| = \\sqrt{d_i}$。\n类似地，对于用户 $j$，我们有 $\\|\\mathbf{v}_j\\| = \\sqrt{d_j}$。\n将这些表达式代回余弦相似度的公式中，得到：\n$$ \\cos(\\theta)_{ij} = \\frac{c}{\\sqrt{d_i d_j}} $$\n\n接下来，我们推导 Jaccard 指数的表达式。两个集合之间的 Jaccard 指数定义为它们交集的大小除以它们并集的大小。设 $S_i$ 是用户 $i$ 购买的物品集合，$S_j$ 是用户 $j$ 的物品集合。\n$$ J_{ij} = \\frac{|S_i \\cap S_j|}{|S_i \\cup S_j|} $$\n交集的大小 $|S_i \\cap S_j|$ 是同时属于两个集合的物品数量。这正是共同物品的数量，定义为 $c$。\n$$ |S_i \\cap S_j| = c $$\n并集的大小 $|S_i \\cup S_j|$ 可以使用容斥原理找到：\n$$ |S_i \\cup S_j| = |S_i| + |S_j| - |S_i \\cap S_j| $$\n集合 $S_i$ 的大小 $|S_i|$ 是用户 $i$ 购买的物品数量，即度 $d_i$。类似地， $|S_j| = d_j$。将这些代入并集的公式中：\n$$ |S_i \\cup S_j| = d_i + d_j - c $$\n因此，Jaccard 指数为：\n$$ J_{ij} = \\frac{c}{d_i + d_j - c} $$\n\n现在，我们对给定情况 $d_i = 8$、$d_j = 10$ 和 $c = 4$ 计算这两个相似性度量。\n余弦相似度为：\n$$ \\cos(\\theta)_{ij} = \\frac{4}{\\sqrt{8 \\times 10}} = \\frac{4}{\\sqrt{80}} = \\frac{4}{\\sqrt{16 \\times 5}} = \\frac{4}{4\\sqrt{5}} = \\frac{1}{\\sqrt{5}} $$\nJaccard 指数为：\n$$ J_{ij} = \\frac{4}{8 + 10 - 4} = \\frac{4}{14} = \\frac{2}{7} $$\n\n最后，我们计算此情况下余弦相似度与 Jaccard 指数的比率。\n$$ \\text{比率} = \\frac{\\cos(\\theta)_{ij}}{J_{ij}} = \\frac{1/\\sqrt{5}}{2/7} = \\frac{1}{\\sqrt{5}} \\times \\frac{7}{2} = \\frac{7}{2\\sqrt{5}} $$\n为了简化这个精确表达式，我们对分母进行有理化：\n$$ \\text{比率} = \\frac{7}{2\\sqrt{5}} \\times \\frac{\\sqrt{5}}{\\sqrt{5}} = \\frac{7\\sqrt{5}}{2 \\times 5} = \\frac{7\\sqrt{5}}{10} $$\n这就是该比率的最终、简化的精确表达式。",
            "answer": "$$\\boxed{\\frac{7\\sqrt{5}}{10}}$$"
        },
        {
            "introduction": "许多现实世界中的网络不仅仅涉及连接的有无，还包含正面或负面的情感，例如“喜欢”和“不喜欢”。单模投影可以被有力地扩展以捕捉这些带符号的互动。这个练习  通过考虑用户评分中的“一致”与“不一致”来对用户相似性进行建模，从而产生一个同时包含正权重和负权重的投影网络。完成这个情景的计算将展示投影框架如何揭示微妙的社会动态，例如联盟（强的正权重）、对立（强的负权重）以及因观点抵消而导致的漠不关心（权重接近于零）。",
            "id": "4294513",
            "problem": "考虑一个二分网络，其包含两个不相交的节点集：四个用户 $U_1, U_2, U_3, U_4$ 和五个物品 $I_1, I_2, I_3, I_4, I_5$。每个用户-物品对 $(U_u, I_i)$ 带有一个符号交互 $r_{u i} \\in \\{-1, 0, +1\\}$，其中 $+1$ 表示喜欢，$-1$ 表示不喜欢，而 $0$ 表示未评价。数据由一个 $4 \\times 5$ 的评分矩阵 $R = \\big(r_{u i}\\big)$ 给出：\n$$\nR \\;=\\;\n\\begin{pmatrix}\n+1  -1  +1  0  -1 \\\\\n+1  +1  -1  +1  0 \\\\\n-1  +1  +1  -1  -1 \\\\\n+1  0  +1  -1  +1\n\\end{pmatrix}.\n$$\n对用户集的单模投影会产生一个加权的用户-用户网络。采用以下原则从基本原理出发构建用户-用户间的边权重：\n- 在无权情况下，两个用户之间的权重等于他们共同连接的共享物品的数量。\n- 对于带符号的评价 $r_{u i} \\in \\{-1, 0, +1\\}$，当两个用户 $U_u$ 和 $U_v$ 对物品 $I_i$ 的评价符号一致时（同为 $+1$ 或同为 $-1$），该物品对他们之间权重的贡献必须为正；当他们评价符号不一致时（一个为 $+1$ 一个为 $-1$），贡献为负；当其中至少一人评价为 $r_{u i} = 0$ 或 $r_{v i} = 0$ 时，贡献为零。\n\n仅从这些原则以及二分邻接和单模投影的核心定义出发，推导用户-用户权重 $w_{u v}$ 关于 $\\{r_{u i}\\}$ 的解析表达式，并用它来计算用户单模投影的完整 $4 \\times 4$ 权重矩阵 $W = \\big(w_{u v}\\big)$。包括与同样贡献规则一致的对角线元素 $w_{u u}$。\n\n使用计算出的 $W$ 矩阵，解释在共同评价的物品中，由于混合符号如何产生抵消效应，并找出至少两对因抵消导致边权重恰好为零的用户对。\n\n最后，报告 $W$ 矩阵中元素 $w_{2 3}$ 的数值。最终数字无需四舍五入。",
            "solution": "用户单模投影的用户-用户权重 $w_{u v}$ 是通过对每个物品 $I_i$ 的贡献求和得出的。设物品 $I_i$ 对用户 $U_u$ 和用户 $U_v$ 之间权重的贡献表示为 $c_i(u, v)$。问题陈述了根据带符号评分 $r_{ui}$ 和 $r_{vi}$ 确定此贡献的原则。\n\n这些原则是：\n1. 如果用户 $U_u$ 和 $U_v$ 对物品 $I_i$ 的评价一致，则贡献 $c_i(u, v)$ 为正。这种情况发生在他们都给出正面评价（$r_{ui}=+1$, $r_{vi}=+1$）或都给出负面评价（$r_{ui}=-1$, $r_{vi}=-1$）时。\n2. 如果用户 $U_u$ 和 $U_v$ 对物品 $I_i$ 的评价不一致，则贡献 $c_i(u, v)$ 为负。这种情况发生在一人给出正面评价而另一人给出负面评价时（$r_{ui}=+1$, $r_{vi}=-1$ 或 $r_{ui}=-1$, $r_{vi}=+1$）。\n3. 如果至少有一个用户没有对该物品进行评分，即 $r_{ui}=0$ 或 $r_{vi}=0$，则贡献 $c_i(u, v)$ 为零。\n\n让我们找一个满足这些条件的简单数学表达式来表示 $c_i(u, v)$。评分的乘积 $r_{ui} r_{vi}$ 直接满足这些要求：\n- 如果 $r_{ui}=+1$ 且 $r_{vi}=+1$，则 $r_{ui} r_{vi} = (+1)(+1) = +1$（正贡献）。\n- 如果 $r_{ui}=-1$ 且 $r_{vi}=-1$，则 $r_{ui} r_{vi} = (-1)(-1) = +1$（正贡献）。\n- 如果 $r_{ui}=+1$ 且 $r_{vi}=-1$，则 $r_{ui} r_{vi} = (+1)(-1) = -1$（负贡献）。\n- 如果 $r_{ui}=-1$ 且 $r_{vi}=+1$，则 $r_{ui} r_{vi} = (-1)(+1) = -1$（负贡献）。\n- 如果 $r_{ui}=0$ 或 $r_{vi}=0$，则 $r_{ui} r_{vi} = 0$（零贡献）。\n\n因此，物品 $I_i$ 贡献的最简单形式化表示是 $c_i(u,v) = r_{ui} r_{vi}$。用户 $U_u$ 和 $U_v$ 之间的总权重 $w_{uv}$ 是这些贡献在所有物品 $i=1, \\dots, 5$ 上的总和：\n$$\nw_{uv} = \\sum_{i=1}^{5} c_i(u,v) = \\sum_{i=1}^{5} r_{ui} r_{vi}\n$$\n这个表达式是评分矩阵 $R$ 的第 $u$ 个行向量与 $R$ 的第 $v$ 个行向量的点积。如果 $R_u$ 表示用户 $U_u$ 的行向量，那么 $w_{uv} = R_u \\cdot R_v$。因此，整个权重矩阵 $W = (w_{uv})$ 可以通过矩阵 $R$ 与其转置 $R^T$ 的乘积来计算：\n$$\nW = R R^T\n$$\n给定的评分矩阵是：\n$$\nR \\;=\\;\n\\begin{pmatrix}\n1  -1  1  0  -1 \\\\\n1  1  -1  1  0 \\\\\n-1  1  1  -1  -1 \\\\\n1  0  1  -1  1\n\\end{pmatrix}\n$$\n其转置矩阵 $R^T$ 是：\n$$\nR^T \\;=\\;\n\\begin{pmatrix}\n1  1  -1  1 \\\\\n-1  1  1  0 \\\\\n1  -1  1  1 \\\\\n0  1  -1  -1 \\\\\n-1  0  -1  1\n\\end{pmatrix}\n$$\n我们现在计算乘积 $W = R R^T$。元素 $w_{uv}$ 是 $R$ 的第 $u$ 行与 $R^T$ 的第 $v$ 列（也就是 $R$ 的第 $v$ 行）的点积。\n\n$w_{11} = (1)(1) + (-1)(-1) + (1)(1) + (0)(0) + (-1)(-1) = 1 + 1 + 1 + 0 + 1 = 4$\n$w_{12} = (1)(1) + (-1)(1) + (1)(-1) + (0)(1) + (-1)(0) = 1 - 1 - 1 + 0 + 0 = -1$\n$w_{13} = (1)(-1) + (-1)(1) + (1)(1) + (0)(-1) + (-1)(-1) = -1 - 1 + 1 + 0 + 1 = 0$\n$w_{14} = (1)(1) + (-1)(0) + (1)(1) + (0)(-1) + (-1)(1) = 1 + 0 + 1 + 0 - 1 = 1$\n\n$w_{21} = w_{12} = -1$\n$w_{22} = (1)(1) + (1)(1) + (-1)(-1) + (1)(1) + (0)(0) = 1 + 1 + 1 + 1 + 0 = 4$\n$w_{23} = (1)(-1) + (1)(1) + (-1)(1) + (1)(-1) + (0)(-1) = -1 + 1 - 1 - 1 + 0 = -2$\n$w_{24} = (1)(1) + (1)(0) + (-1)(1) + (1)(-1) + (0)(1) = 1 + 0 - 1 - 1 + 0 = -1$\n\n$w_{31} = w_{13} = 0$\n$w_{32} = w_{23} = -2$\n$w_{33} = (-1)(-1) + (1)(1) + (1)(1) + (-1)(-1) + (-1)(-1) = 1 + 1 + 1 + 1 + 1 = 5$\n$w_{34} = (-1)(1) + (1)(0) + (1)(1) + (-1)(-1) + (-1)(1) = -1 + 0 + 1 + 1 - 1 = 0$\n\n$w_{41} = w_{14} = 1$\n$w_{42} = w_{24} = -1$\n$w_{43} = w_{34} = 0$\n$w_{44} = (1)(1) + (0)(0) + (1)(1) + (-1)(-1) + (1)(1) = 1 + 0 + 1 + 1 + 1 = 4$\n\n完整的用户-用户权重矩阵 $W$ 是：\n$$\nW \\;=\\;\n\\begin{pmatrix}\n4  -1  0  1 \\\\\n-1  4  -2  -1 \\\\\n0  -2  5  0 \\\\\n1  -1  0  4\n\\end{pmatrix}\n$$\n当用户共同评价了多个物品，并且他们的评分表现出一致和不一致的混合时，就会产生抵消效应。正贡献（来自一致评价，$r_{ui}r_{vi}=+1$）和负贡献（来自不一致评价，$r_{ui}r_{vi}=-1$）的和可能是一个很小的值，甚至恰好为零。\n\n从矩阵 $W$ 中，我们找出两对边权重为零的用户对：$(U_1, U_3)$，其 $w_{13} = 0$；以及 $(U_3, U_4)$，其 $w_{34} = 0$。\n\n让我们来研究用户对 $(U_1, U_3)$ 的抵消情况：\n评分向量为 $R_1 = (1, -1, 1, 0, -1)$ 和 $R_3 = (-1, 1, 1, -1, -1)$。\n各物品的贡献如下：\n- 物品 $I_1$：$r_{11}r_{31} = (1)(-1) = -1$ (不一致)\n- 物品 $I_2$：$r_{12}r_{32} = (-1)(1) = -1$ (不一致)\n- 物品 $I_3$：$r_{13}r_{33} = (1)(1) = +1$ (一致)\n- 物品 $I_4$：$r_{14}r_{34} = (0)(-1) = 0$ (无共同评分)\n- 物品 $I_5$：$r_{15}r_{35} = (-1)(-1) = +1$ (一致)\n总权重为 $w_{13} = -1 - 1 + 1 + 0 + 1 = 0$。两次一致评价和两次不一致评价完全相互抵消。\n\n接下来，我们研究用户对 $(U_3, U_4)$ 的抵消情况：\n评分向量为 $R_3 = (-1, 1, 1, -1, -1)$ 和 $R_4 = (1, 0, 1, -1, 1)$。\n各物品的贡献如下：\n- 物品 $I_1$：$r_{31}r_{41} = (-1)(1) = -1$ (不一致)\n- 物品 $I_2$：$r_{32}r_{42} = (1)(0) = 0$ (无共同评分)\n- 物品 $I_3$：$r_{33}r_{43} = (1)(1) = +1$ (一致)\n- 物品 $I_4$：$r_{34}r_{44} = (-1)(-1) = +1$ (一致)\n- 物品 $I_5$：$r_{35}r_{45} = (-1)(1) = -1$ (不一致)\n总权重为 $w_{34} = -1 + 0 + 1 + 1 - 1 = 0$。同样，两次一致评价和两次不一致评价相互抵消。\n\n对角线元素 $w_{uu}$ 代表用户 $U_u$ 评价过的物品数量，因为 $r_{ui}r_{ui} = r_{ui}^2$，当 $r_{ui} \\in \\{-1,+1\\}$ 时其值为 $1$，当 $r_{ui}=0$ 时其值为 $0$。例如，$w_{33}=5$ 是因为用户 $U_3$ 评价了全部 5 个物品。\n\n最后，问题要求给出元素 $w_{23}$ 的数值。根据我们对矩阵 $W$ 的计算：\n$w_{23} = (1)(-1) + (1)(1) + (-1)(1) + (1)(-1) + (0)(-1) = -1 + 1 - 1 - 1 + 0 = -2$。\n这个负权重表明用户 $U_2$ 和 $U_3$ 在他们共同评价的物品上总体表现为不一致。",
            "answer": "$$\\boxed{-2}$$"
        }
    ]
}