{
    "hands_on_practices": [
        {
            "introduction": "The remarkable effectiveness of hyperbolic geometry in network science stems from its unique spatial properties. This first practice invites you to derive the area of a hyperbolic disk from first principles, revealing how space expands exponentially with radius. Understanding this geometric fact is the first step to appreciating why it serves as a natural container for the hierarchical and scale-free structure of complex networks. ",
            "id": "4282148",
            "problem": "Consider the two-dimensional hyperbolic plane $\\mathbb{H}^{2}$ of constant Gaussian curvature $-1$. In geodesic polar coordinates $(r,\\theta)$ centered at an arbitrary origin, the Riemannian metric takes the form $ds^{2} = dr^{2} + \\sinh^{2}(r)\\,d\\theta^{2}$, where angles are measured in radians. Using only core definitions from Riemannian geometry (in particular, that the area element induced by a metric tensor $g$ is $dA = \\sqrt{\\det g}\\,dr\\,d\\theta$ in coordinates) and the given metric, derive the exact area $A(r)$ of the metric disk of radius $r$ in $\\mathbb{H}^{2}$. Express your final answer as a single closed-form analytic expression in terms of $r$; no rounding is required.\n\nThen, explain from first principles how the radial dependence of the area you derived governs the scaling of available latent space volume in hyperbolic network models with uniform node density, and interpret the consequences of this scaling for emergent network properties such as degree heterogeneity and clustering. Your interpretation should be qualitative but must be grounded in rigorous reasoning based on the geometry and the resulting measure on latent positions. The final answer to submit is only the area expression $A(r)$.",
            "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n**Problem Validation**\n\n**Step 1: Extracted Givens**\n- The space is the two-dimensional hyperbolic plane $\\mathbb{H}^{2}$.\n- The constant Gaussian curvature is $-1$.\n- The coordinates are geodesic polar coordinates $(r,\\theta)$.\n- The Riemannian metric is given as $ds^{2} = dr^{2} + \\sinh^{2}(r)\\,d\\theta^{2}$.\n- Angles are measured in radians.\n- The area element is defined by $dA = \\sqrt{\\det g}\\,dr\\,d\\theta$, where $g$ is the metric tensor.\n- The first task is to derive the exact area $A(r)$ of the metric disk of radius $r$ in $\\mathbb{H}^{2}$.\n- The second task is to explain how the radial dependence of this area governs the scaling of available latent space volume in hyperbolic network models with uniform node density, and to interpret the consequences for emergent network properties, specifically degree heterogeneity and clustering.\n\n**Step 2: Validation of Givens**\nThe problem is scientifically grounded in the established fields of Riemannian geometry and complex network science. The provided metric for the hyperbolic plane in polar coordinates is standard. The definition of the area element is a cornerstone of differential geometry. The application to hyperbolic network models is a current and significant area of research in network science. The problem is well-posed, as all necessary information for the derivation is provided, leading to a unique analytical solution. The language is objective and precise. The problem does not violate any of the invalidity criteria (e.g., it is not scientifically unsound, incomplete, or ambiguous).\n\n**Step 3: Verdict**\nThe problem is deemed **valid**.\n\n**Solution Derivation and Interpretation**\n\n**Part 1: Derivation of the Area of a Hyperbolic Disk**\n\nThe area of a surface in Riemannian geometry is found by integrating the area element over the desired region. The area element $dA$ is derived from the metric tensor $g$. In the given geodesic polar coordinates $(r, \\theta)$, the metric is $ds^{2} = 1 \\cdot dr^{2} + 0 \\cdot dr\\,d\\theta + 0 \\cdot d\\theta\\,dr + \\sinh^{2}(r) \\cdot d\\theta^{2}$.\n\nThe metric tensor $g$ can be written as a matrix with components $g_{ij}$:\n$$g = \\begin{pmatrix} g_{rr}  g_{r\\theta} \\\\ g_{\\theta r}  g_{\\theta\\theta} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  \\sinh^{2}(r) \\end{pmatrix}$$\n\nThe determinant of the metric tensor is:\n$$\\det g = g_{rr}g_{\\theta\\theta} - g_{r\\theta}g_{\\theta r} = (1)(\\sinh^{2}(r)) - (0)(0) = \\sinh^{2}(r)$$\n\nThe area element $dA$ is given by the formula $dA = \\sqrt{\\det g}\\,dr\\,d\\theta$. Substituting the calculated determinant:\n$$dA = \\sqrt{\\sinh^{2}(r)}\\,dr\\,d\\theta$$\nSince the radial coordinate $r$ is non-negative ($r \\ge 0$), the hyperbolic sine function $\\sinh(r)$ is also non-negative. Therefore, we can simplify the square root:\n$$dA = \\sinh(r)\\,dr\\,d\\theta$$\n\nTo find the area $A(r)$ of a metric disk of radius $r$, we must integrate this area element over the region defined by $0 \\le r' \\le r$ and $0 \\le \\theta \\le 2\\pi$. The integral is separable:\n$$A(r) = \\int_{0}^{2\\pi} \\int_{0}^{r} \\sinh(r')\\,dr'\\,d\\theta$$\nWe can evaluate the integrals independently:\n$$A(r) = \\left( \\int_{0}^{2\\pi} d\\theta \\right) \\left( \\int_{0}^{r} \\sinh(r')\\,dr' \\right)$$\nThe integral over the angle $\\theta$ is:\n$$\\int_{0}^{2\\pi} d\\theta = [\\theta]_{0}^{2\\pi} = 2\\pi - 0 = 2\\pi$$\nThe integral over the radius $r'$ is:\n$$\\int_{0}^{r} \\sinh(r')\\,dr' = [\\cosh(r')]_{0}^{r} = \\cosh(r) - \\cosh(0)$$\nSince $\\cosh(0) = 1$, this becomes $\\cosh(r) - 1$.\n\nCombining these results, the area of the hyperbolic disk of radius $r$ is:\n$$A(r) = 2\\pi (\\cosh(r) - 1)$$\n\n**Part 2: Interpretation for Hyperbolic Network Models**\n\nThe derived area formula $A(r) = 2\\pi(\\cosh(r) - 1)$ reveals the fundamental geometric property of hyperbolic space that underpins the structure of networks modeled within it. The key is the asymptotic behavior of the area. For large radii $r$, the hyperbolic cosine function behaves as $\\cosh(r) \\approx \\frac{1}{2}\\exp(r)$. Thus, the area scales exponentially with the radius:\n$$A(r) \\approx \\pi \\exp(r) \\quad \\text{for } r \\gg 1$$\nThis is in stark contrast to Euclidean space, where the area of a disk scales polynomially, $A_{\\text{Euclidean}}(r) = \\pi r^{2}$.\n\nIn hyperbolic network models, nodes are embedded into a latent hyperbolic disk. The assumption of a uniform node density $\\rho$ means the number of nodes $N(r)$ within a radius $r$ is $N(r) = \\rho A(r)$. The number of nodes in an annular ring between $r$ and $r+dr$ is $dN = \\rho \\, dA = \\rho \\cdot 2\\pi \\sinh(r) \\, dr$. Because $\\sinh(r)$ grows exponentially, the radial distribution of nodes is heavily skewed towards the periphery of the disk. The vast majority of nodes reside at large radial coordinates.\n\nThis exponential expansion of space with radius has profound consequences for emergent network properties:\n\n1.  **Degree Heterogeneity:** In many hyperbolic network models, the radial coordinate $r$ of a node is inversely related to its expected degree. Nodes close to the origin (small $r$) are \"central\" and have a high propensity to connect, while nodes at the periphery (large $r$) are less central. A node at a small radius $r_i$ is within a given hyperbolic connection distance of a very large number of other nodes, precisely because the number of available nodes grows exponentially with distance. Conversely, a peripheral node at a large radius $r_j$ is far from most other nodes. This geometric arrangement naturally gives rise to a network structure with a few high-degree \"hubs\" (the nodes near the origin) and a vast number of low-degree nodes (the peripheral nodes). This is the hallmark of degree heterogeneity, often manifesting as a power-law degree distribution characteristic of so-called \"scale-free\" networks.\n\n2.  **Clustering:** Real-world networks exhibit high clustering, meaning that two nodes connected to a common neighbor are themselves likely to be connected. In the hyperbolic model, this property emerges naturally from the geometry. Consider a node $i$ located at a large radius $r_i$. For two other nodes, $j$ and $k$, to be connected to $i$, they must lie within a certain hyperbolic distance of $i$. Due to the negative curvature, this connection region around node $i$ is geometrically constrained. Specifically, to remain close to $i$, nodes $j$ and $k$ must lie within a narrow angular wedge as viewed from the origin. This forces $j$ and $k$ to be close to each other, not just in angular separation but also in hyperbolic distance. Consequently, a connection between $j$ and $k$ becomes highly probable. This mechanism ensures the formation of triangles ($i-j-k$), leading to a high clustering coefficient, in agreement with observations of real complex networks. The space is locally tree-like, but the global embedding structure enforces these correlations.\n\nIn summary, the exponential growth of area with radius is the fundamental geometric principle that allows hyperbolic space to serve as a natural latent geometry for complex networks, simultaneously explaining the ubiquitous features of degree heterogeneity and high clustering.",
            "answer": "$$\\boxed{2\\pi(\\cosh(r) - 1)}$$"
        },
        {
            "introduction": "Building on the insight of exponential space, this exercise provides a direct mathematical link between the geometry of the latent space and the observed structure of the network. You will see how a specific distribution of nodes in the hyperbolic plane, combined with an intuitive relationship between radial position and popularity, directly gives rise to a power-law degree distribution. This derivation is a cornerstone of hyperbolic network models, explaining the ubiquitous emergence of hubs and a heterogeneous degree structure. ",
            "id": "4282214",
            "problem": "Consider a widely used class of hyperbolic random graph models in which nodes are embedded in a disk of constant negative curvature, and each node is assigned a radial coordinate $r \\in [0,R]$ and an angular coordinate $\\theta \\in [0,2\\pi)$. In these models, the expected degree of a node is a monotonically decreasing function of its radial coordinate, reflecting the principle that nodes closer to the disk center are more popular.\n\nAssume the following empirically supported and theoretically consistent ingredients:\n- The distribution of radial coordinates has density $ \\rho(r) = \\alpha \\exp\\!\\big(\\alpha (r - R)\\big) $ for $ r \\in [0,R] $, where $ \\alpha  0 $ and $ R  0 $ are constants determined by network growth and curvature.\n- The expected degree as a function of radial coordinate is $ k(r) = k_{0} \\exp(-\\beta r) $, where $ k_{0}  0 $ and $ \\beta  0 $ are constants depending on connection probability and geometric parameters.\n\nWork in the large-network regime where degree fluctuations around $ k(r) $ are negligible, so that the degree distribution $ P(k) $ arises from the pushforward of $ \\rho(r) $ under the mapping $ r \\mapsto k(r) $. Using conservation of probability and the monotonicity of $ k(r) $, derive the asymptotic tail of $ P(k) $ and show that it follows a power law $ P(k) \\propto k^{-\\gamma} $. Compute the exact closed-form expression for the exponent $ \\gamma $ in terms of $ \\alpha $ and $ \\beta $. Your final answer must be a single analytical expression for $ \\gamma $.\n\nNo numerical approximation is required; provide the exact expression. If you perform any intermediate variable transformations, state them explicitly and justify the steps from first principles of probability (change of variables).",
            "solution": "The problem asks for the exponent $\\gamma$ of the power-law degree distribution $P(k) \\propto k^{-\\gamma}$ in a hyperbolic random graph model. The derivation relies on the principle of conservation of probability under a change of variables, applied to the mapping from the radial coordinate $r$ to the degree $k$.\n\nThe given ingredients are:\n1. The probability density function (PDF) of the radial coordinate $r \\in [0, R]$ is $\\rho(r) = \\alpha \\exp(\\alpha (r - R))$, with $\\alpha  0$ and $R  0$.\n2. The degree $k$ of a node is a deterministic, monotonically decreasing function of its radial coordinate $r$: $k(r) = k_{0} \\exp(-\\beta r)$, with $k_{0}  0$ and $\\beta  0$.\n\nThe degree distribution $P(k)$ can be found from the radial distribution $\\rho(r)$ using the change of variables formula for probability densities. For a monotonic function $k = k(r)$, the conservation of probability implies that the probability mass in an infinitesimal interval $dr$ must equal the probability mass in the corresponding interval $dk$:\n$$\nP(k) |dk| = \\rho(r) |dr|\n$$\nThis can be rearranged to express $P(k)$ in terms of $\\rho(r)$ and the derivative of the transformation:\n$$\nP(k) = \\rho(r(k)) \\left| \\frac{dr}{dk} \\right|\n$$\nHere, $r(k)$ is the inverse function of $k(r)$. The derivation proceeds in three steps:\n1. Find the inverse function $r(k)$.\n2. Calculate the Jacobian of the transformation, which is the absolute value of the derivative, $\\left| \\frac{dr}{dk} \\right|$.\n3. Substitute these components into the change of variables formula to find the functional form of $P(k)$ and identify the exponent $\\gamma$.\n\nStep 1: Find the inverse function $r(k)$.\nWe start with the given relationship between degree and radius:\n$$\nk = k_0 \\exp(-\\beta r)\n$$\nTo solve for $r$, we first divide by $k_0$:\n$$\n\\frac{k}{k_0} = \\exp(-\\beta r)\n$$\nNext, we take the natural logarithm of both sides:\n$$\n\\ln\\left(\\frac{k}{k_0}\\right) = -\\beta r\n$$\nFinally, we isolate $r$ to obtain the inverse function $r(k)$:\n$$\nr(k) = -\\frac{1}{\\beta} \\ln\\left(\\frac{k}{k_0}\\right) = \\frac{1}{\\beta} \\ln\\left(\\frac{k_0}{k}\\right)\n$$\n\nStep 2: Calculate the derivative $\\frac{dr}{dk}$.\nWe differentiate the expression for $r(k)$ with respect to $k$:\n$$\nr(k) = \\frac{1}{\\beta} (\\ln(k_0) - \\ln(k))\n$$\nThe derivative is:\n$$\n\\frac{dr}{dk} = \\frac{d}{dk} \\left[ \\frac{1}{\\beta} (\\ln(k_0) - \\ln(k)) \\right] = \\frac{1}{\\beta} \\left(0 - \\frac{1}{k}\\right) = -\\frac{1}{\\beta k}\n$$\nThe absolute value of the derivative is:\n$$\n\\left| \\frac{dr}{dk} \\right| = \\left| -\\frac{1}{\\beta k} \\right| = \\frac{1}{\\beta k}\n$$\nsince both $\\beta$ and $k$ (degree) are positive quantities.\n\nStep 3: Determine $P(k)$ and the exponent $\\gamma$.\nNow we substitute $r(k)$ and $\\left| \\frac{dr}{dk} \\right|$ into the formula for $P(k)$.\nFirst, we evaluate $\\rho(r)$ at $r=r(k)$:\n$$\n\\rho(r(k)) = \\alpha \\exp\\left(\\alpha (r(k) - R)\\right) = \\alpha \\exp\\left(\\alpha \\left(\\frac{1}{\\beta} \\ln\\left(\\frac{k_0}{k}\\right) - R\\right)\\right)\n$$\nLet's simplify the exponential term:\n$$\n\\exp\\left(\\alpha \\left(\\frac{1}{\\beta} \\ln\\left(\\frac{k_0}{k}\\right) - R\\right)\\right) = \\exp\\left(\\frac{\\alpha}{\\beta} \\ln\\left(\\frac{k_0}{k}\\right) - \\alpha R\\right)\n$$\n$$\n= \\exp(-\\alpha R) \\cdot \\exp\\left(\\ln\\left(\\left(\\frac{k_0}{k}\\right)^{\\alpha/\\beta}\\right)\\right)\n$$\n$$\n= \\exp(-\\alpha R) \\left(\\frac{k_0}{k}\\right)^{\\alpha/\\beta}\n$$\nSo, the expression for $\\rho(r(k))$ becomes:\n$$\n\\rho(r(k)) = \\alpha \\exp(-\\alpha R) \\left(\\frac{k_0}{k}\\right)^{\\alpha/\\beta}\n$$\nNow we assemble $P(k)$:\n$$\nP(k) = \\rho(r(k)) \\left| \\frac{dr}{dk} \\right| = \\left( \\alpha \\exp(-\\alpha R) \\left(\\frac{k_0}{k}\\right)^{\\alpha/\\beta} \\right) \\left( \\frac{1}{\\beta k} \\right)\n$$\nWe can group the terms that are constant with respect to $k$ and the terms that depend on $k$:\n$$\nP(k) = \\left( \\frac{\\alpha \\exp(-\\alpha R) k_0^{\\alpha/\\beta}}{\\beta} \\right) \\left( \\frac{1}{k^{\\alpha/\\beta}} \\right) \\left( \\frac{1}{k} \\right)\n$$\nCombining the terms with $k$:\n$$\nP(k) = \\left( \\frac{\\alpha \\exp(-\\alpha R) k_0^{\\alpha/\\beta}}{\\beta} \\right) k^{-\\frac{\\alpha}{\\beta} - 1}\n$$\n$$\nP(k) = \\left( \\frac{\\alpha \\exp(-\\alpha R) k_0^{\\alpha/\\beta}}{\\beta} \\right) k^{-\\left(1 + \\frac{\\alpha}{\\beta}\\right)}\n$$\nThis expression shows that the degree distribution $P(k)$ follows a power law. By comparing this form to the problem's statement $P(k) \\propto k^{-\\gamma}$, we can identify the exponent $\\gamma$.\n$$\n\\gamma = 1 + \\frac{\\alpha}{\\beta}\n$$\nThis is the exact closed-form expression for the power-law exponent $\\gamma$ in terms of the given parameters $\\alpha$ and $\\beta$.",
            "answer": "$$\\boxed{1 + \\frac{\\alpha}{\\beta}}$$"
        },
        {
            "introduction": "Besides a scale-free degree distribution, real-world networks are characterized by high clusteringâ€”the tendency for friends of a friend to also be friends. This practice explores how this property, known as transitivity, is a natural consequence of hyperbolic geometry. By analyzing a simplified \"hard-threshold\" connection model, you will calculate the local clustering coefficient and find it converges to a high, constant value, a result rooted entirely in the geometric constraints of the embedding. ",
            "id": "4282181",
            "problem": "Consider the canonical soft connection model for hyperbolic random graphs used in the study of complex networks embedded in hyperbolic geometry. Nodes are embedded in the hyperbolic disk of radius $R$ with constant negative curvature $-1$, and each node $i$ has polar coordinates $(r_i,\\theta_i)$, where $r_i\\in[0,R)$ is the radial coordinate and $\\theta_i\\in[0,2\\pi)$ is the angular coordinate in radians. The hyperbolic distance $x_{ij}$ between two nodes $i$ and $j$ satisfies the hyperbolic law of cosines,\n$$\n\\cosh x_{ij} \\;=\\; \\cosh r_i \\cosh r_j \\;-\\; \\sinh r_i \\sinh r_j \\cos\\big(\\Delta\\theta_{ij}\\big),\n$$\nwhere $\\Delta\\theta_{ij}$ is the absolute angular difference between $\\theta_i$ and $\\theta_j$ measured on the circle. Edges are realized independently with probability given by the soft-threshold logistic function\n$$\np_T(x)\\;=\\;\\frac{1}{1+\\exp\\!\\big((x-R)/T\\big)},\n$$\nwhere $T0$ is the temperature parameter controlling the sharpness of the threshold.\n\n(a) Starting from the above definitions, verify rigorously that in the limit $T\\to 0^{+}$ the model reduces to a threshold graph in which an edge between $i$ and $j$ exists if and only if $x_{ij}R$.\n\n(b) Now focus on the conditional ensemble in which all nodes lie on the same geodesic circle at a fixed radial coordinate $r\\in(0,R)$, while their angular coordinates are independently and identically distributed uniformly in $[0,2\\pi)$. In the limit $T\\to 0^{+}$, use the hyperbolic law of cosines to derive the angular threshold $\\theta_c(r,R)\\in(0,\\pi)$ such that an edge between any two nodes at radial coordinate $r$ is present if and only if their angular separation satisfies $|\\Delta\\theta|\\leq \\theta_c(r,R)$. Assume the parameters satisfy\n$$\n0 \\;\\; \\frac{\\cosh R - 1}{2\\sinh^{2} r} \\;\\; 1,\n$$\nso that $\\theta_c(r,R)$ is strictly between $0$ and $\\pi$.\n\n(c) Under the same assumptions and in the limit of a very large network size $N\\to\\infty$, compute the limiting local clustering coefficient of a typical node, defined as the probability that two randomly chosen neighbors of that node (conditional on being neighbors of the node) are themselves connected. Your answer must be a single real number. No rounding is required. All angles are to be treated in radians.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the study of complex networks on hyperbolic spaces. All provided definitions and constraints are consistent and sufficient for a rigorous solution.\n\n(a) Verification of the $T \\to 0^{+}$ limit\n\nThe connection probability between two nodes is given by the logistic function:\n$$p_T(x) = \\frac{1}{1 + \\exp\\left(\\frac{x-R}{T}\\right)}$$\nwhere $x$ is the hyperbolic distance between the nodes, $R$ is the radius of the hyperbolic disk, and $T  0$ is the temperature parameter. We need to analyze the behavior of this function in the limit as $T \\to 0^{+}$.\n\nWe consider two cases for the hyperbolic distance $x_{ij}$ between two nodes $i$ and $j$.\n\nCase 1: $x_{ij}  R$.\nIn this case, the difference $x_{ij} - R$ is negative. As $T \\to 0^{+}$, the argument of the exponential function approaches negative infinity:\n$$\\lim_{T \\to 0^{+}} \\frac{x_{ij}-R}{T} = -\\infty$$\nConsequently, the exponential term approaches zero:\n$$\\lim_{T \\to 0^{+}} \\exp\\left(\\frac{x_{ij}-R}{T}\\right) = 0$$\nThe connection probability thus becomes:\n$$\\lim_{T \\to 0^{+}} p_T(x_{ij}) = \\frac{1}{1 + 0} = 1$$\n\nCase 2: $x_{ij}  R$.\nIn this case, the difference $x_{ij} - R$ is positive. As $T \\to 0^{+}$, the argument of the exponential function approaches positive infinity:\n$$\\lim_{T \\to 0^{+}} \\frac{x_{ij}-R}{T} = +\\infty$$\nConsequently, the exponential term grows infinitely large:\n$$\\lim_{T \\to 0^{+}} \\exp\\left(\\frac{x_{ij}-R}{T}\\right) = \\infty$$\nThe connection probability thus becomes:\n$$\\lim_{T \\to 0^{+}} p_T(x_{ij}) = \\lim_{Z \\to \\infty} \\frac{1}{1 + Z} = 0$$\n\nThe limiting behavior of the connection probability is a step function. The probability is $1$ if the hyperbolic distance $x_{ij}$ is less than the radius $R$, and $0$ if it is greater than $R$. The case $x_{ij} = R$ results in a probability of $p_T(R) = 1/(1+e^0) = 1/2$ for any $T0$, but this is a single point and has measure zero in a continuous distribution of distances. Therefore, in the limit $T \\to 0^{+}$, the model describes a threshold graph where an edge exists between nodes $i$ and $j$ if and only if their hyperbolic distance $x_{ij}$ is less than the threshold $R$.\n\n(b) Derivation of the angular threshold $\\theta_c(r,R)$\n\nIn the limit $T \\to 0^{+}$, an edge exists between two nodes if and only if $x_{ij}  R$. Since the function $\\cosh(x)$ is strictly increasing for $x0$, this condition is equivalent to $\\cosh(x_{ij})  \\cosh(R)$.\n\nAll nodes are located at a fixed radial coordinate $r \\in (0, R)$. Let the angular coordinates of two nodes be $\\theta_i$ and $\\theta_j$. The angular separation is $\\Delta\\theta = \\Delta\\theta_{ij} \\in [0, \\pi]$. The hyperbolic law of cosines for these two nodes is:\n$$\\cosh x_{ij} = \\cosh(r) \\cosh(r) - \\sinh(r) \\sinh(r) \\cos(\\Delta\\theta)$$\n$$\\cosh x_{ij} = \\cosh^{2} r - \\sinh^{2} r \\cos(\\Delta\\theta)$$\nApplying the connection condition $\\cosh(x_{ij})  \\cosh(R)$:\n$$\\cosh^{2} r - \\sinh^{2} r \\cos(\\Delta\\theta)  \\cosh R$$\nWe solve this inequality for $\\cos(\\Delta\\theta)$. Since $r  0$, $\\sinh^{2} r  0$.\n$$-\\sinh^{2} r \\cos(\\Delta\\theta)  \\cosh R - \\cosh^{2} r$$\n$$\\cos(\\Delta\\theta)  \\frac{\\cosh R - \\cosh^{2} r}{-\\sinh^{2} r} = \\frac{\\cosh^{2} r - \\cosh R}{\\sinh^{2} r}$$\nThe function $\\arccos(y)$ is a decreasing function of $y$ on the interval $[-1, 1]$. Therefore, the inequality on $\\cos(\\Delta\\theta)$ translates to an upper bound on $\\Delta\\theta$. An edge exists if the angular separation is smaller than a critical angle $\\theta_c$, which is defined by the equality:\n$$\\cos(\\theta_c) = \\frac{\\cosh^{2} r - \\cosh R}{\\sinh^{2} r}$$\nUsing the identity $\\cosh^2 r = 1 + \\sinh^2 r$, we can rewrite this as:\n$$\\cos(\\theta_c) = \\frac{1 + \\sinh^{2} r - \\cosh R}{\\sinh^{2} r} = 1 - \\frac{\\cosh R - 1}{\\sinh^{2} r}$$\nThe angular threshold $\\theta_c(r, R)$ is therefore:\n$$\\theta_c(r, R) = \\arccos\\left(1 - \\frac{\\cosh R - 1}{\\sinh^{2} r}\\right)$$\nThe problem provides the condition $0  \\frac{\\cosh R - 1}{2\\sinh^{2} r}  1$, which is equivalent to $0  \\frac{\\cosh R - 1}{\\sinh^{2} r}  2$. This ensures that the argument of the $\\arccos$ function, $1 - \\frac{\\cosh R - 1}{\\sinh^{2} r}$, is strictly between $-1$ and $1$, which in turn guarantees that $\\theta_c(r,R)$ is well-defined and lies strictly between $0$ and $\\pi$. The condition for an edge to exist is $|\\Delta\\theta|  \\theta_c$. Following the typical convention for threshold graphs, we define the connection rule as $|\\Delta\\theta| \\leq \\theta_c$.\n\n(c) Computation of the limiting local clustering coefficient\n\nThe local clustering coefficient of a node is defined as the probability that two of its neighbors are themselves connected. We consider a typical node, call it node $0$. Due to the rotational symmetry of the setup, we can place it at angular coordinate $\\theta_0 = 0$ without loss of generality. All nodes have the same radial coordinate $r$.\n\nFrom part (b), a node $j$ with angle $\\theta_j$ is a neighbor of node $0$ if their angular separation on the circle, $\\Delta\\theta_{0j}$, satisfies $\\Delta\\theta_{0j} \\leq \\theta_c$. This means the angle $\\theta_j$ must lie in the interval $[-\\theta_c, \\theta_c]$ (modulo $2\\pi$).\n\nThe node angles are initially independent and identically distributed according to a uniform distribution on $[0, 2\\pi)$. The condition of being a neighbor of node $0$ restricts the angle to a specific interval of length $2\\theta_c$. Therefore, for a node that is a neighbor of node $0$, its angle is uniformly distributed over this connectivity interval.\n\nLet us consider two randomly chosen neighbors of node $0$, say node $1$ and node $2$. Their angular coordinates, $\\theta_1$ and $\\theta_2$, are independent random variables, each drawn from a uniform distribution on the interval $[-\\theta_c, \\theta_c]$.\nSo, $\\theta_1 \\sim U[-\\theta_c, \\theta_c]$ and $\\theta_2 \\sim U[-\\theta_c, \\theta_c]$.\n\nNode $1$ and node $2$ are connected if their angular separation, $|\\theta_1 - \\theta_2|$, is less than or equal to $\\theta_c$. We need to compute the probability $P(|\\theta_1 - \\theta_2| \\leq \\theta_c)$.\n\nThis is a geometric probability problem. The sample space for the pair $(\\theta_1, \\theta_2)$ is a square in the $\\theta_1\\theta_2$-plane defined by $-\\theta_c \\leq \\theta_1 \\leq \\theta_c$ and $-\\theta_c \\leq \\theta_2 \\leq \\theta_c$. The side length of this square is $2\\theta_c$, so its total area is $A_{total} = (2\\theta_c)^2 = 4\\theta_c^2$. The uniform probability distribution over this square means that the desired probability is the ratio of the favorable area to the total area.\n\nThe favorable region is where $|\\theta_1 - \\theta_2| \\leq \\theta_c$, which is equivalent to $-\\theta_c \\leq \\theta_1 - \\theta_2 \\leq \\theta_c$, or $\\theta_1 - \\theta_c \\leq \\theta_2 \\leq \\theta_1 + \\theta_c$. This region is bounded by the lines $\\theta_2 = \\theta_1 - \\theta_c$ and $\\theta_2 = \\theta_1 + \\theta_c$.\n\nThe unfavorable region is where $|\\theta_1 - \\theta_2|  \\theta_c$. This corresponds to two triangular areas at the corners of the square:\n1.  The region $\\theta_2  \\theta_1 + \\theta_c$. This forms a triangle in the top-left corner of the square with vertices at $(-\\theta_c, 0)$, $(0, \\theta_c)$, and $(-\\theta_c, \\theta_c)$. This is a right-angled isosceles triangle with legs of length $\\theta_c$. Its area is $A_1 = \\frac{1}{2} \\times \\theta_c \\times \\theta_c = \\frac{1}{2}\\theta_c^2$.\n2.  The region $\\theta_2  \\theta_1 - \\theta_c$. This forms a triangle in the bottom-right corner of the square with vertices at $(0, -\\theta_c)$, $(\\theta_c, 0)$, and $(\\theta_c, -\\theta_c)$. This is also a right-angled isosceles triangle with legs of length $\\theta_c$. Its area is $A_2 = \\frac{1}{2} \\times \\theta_c \\times \\theta_c = \\frac{1}{2}\\theta_c^2$.\n\nThe total area of the unfavorable region is $A_{unfav} = A_1 + A_2 = \\frac{1}{2}\\theta_c^2 + \\frac{1}{2}\\theta_c^2 = \\theta_c^2$.\nThe area of the favorable region is the total area minus the unfavorable area:\n$$A_{fav} = A_{total} - A_{unfav} = 4\\theta_c^2 - \\theta_c^2 = 3\\theta_c^2$$\nThe probability, which is the limiting local clustering coefficient, is the ratio of the favorable area to the total area:\n$$C = \\frac{A_{fav}}{A_{total}} = \\frac{3\\theta_c^2}{4\\theta_c^2} = \\frac{3}{4}$$\nThe result is a constant, independent of the parameters $r$ and $R$, as long as they satisfy the given constraints.",
            "answer": "$$\\boxed{\\frac{3}{4}}$$"
        }
    ]
}