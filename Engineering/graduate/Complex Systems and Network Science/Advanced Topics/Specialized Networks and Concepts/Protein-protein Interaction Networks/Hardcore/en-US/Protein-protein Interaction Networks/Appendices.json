{
    "hands_on_practices": [
        {
            "introduction": "The simplest, yet often most informative, characteristic of a protein in a network is its degree—the number of partners it interacts with. This exercise grounds this fundamental metric in the context of real-world data generation. By calculating the degree sequence from a network's adjacency matrix and correlating it with hypothetical experimental data, you will explore how measurement bias can arise, a critical consideration for any researcher working with high-throughput biological data. ",
            "id": "4381240",
            "problem": "Consider a curated, undirected, unweighted Protein-Protein Interaction (PPI) network of $8$ proteins labeled $P_1,\\dots,P_8$, represented by the symmetric adjacency matrix $A$ with entries $A_{ij} \\in \\{0,1\\}$ and $A_{ii}=0$:\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 1 & 1 & 1 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0 & 0 & 0 & 1 & 1 \\\\\n0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 1 & 0 & 0 & 0\n\\end{pmatrix}.\n$$\nStarting from standard graph-theoretic definitions appropriate for undirected simple graphs in systems biomedicine, define the node degree $k_i$ in terms of the entries of $A$ and compute the degree sequence $\\big(k_1,\\dots,k_8\\big)$ for this network.\n\nTo study experimental coverage bias in PPI mapping (for example, Affinity Purification followed by Mass Spectrometry (AP-MS) assays), suppose each protein $i$ has a measured coverage factor $c_i$ (dimensionless), reflecting the relative number of independent bait experiments performed for that protein, given by the vector\n$$\n\\mathbf{c}=\\big(1.2,\\ 1.8,\\ 2.2,\\ 1.3,\\ 1.7,\\ 1.4,\\ 0.9,\\ 0.8\\big).\n$$\nUsing the base definition of the Pearson correlation coefficient between two real-valued variables indexed by nodes, compute the correlation between the degree sequence $\\big(k_1,\\dots,k_8\\big)$ and the coverage vector $\\mathbf{c}$. Round the correlation to four significant figures. Explain, from first principles about detection probability and sampling, why higher $c_i$ tends to inflate observed degree in PPI networks and under what experimental conditions the degree–coverage correlation could reflect measurement bias rather than true biological connectivity.\n\nExpress the final answer as a single row matrix containing the degree sequence entries $k_1,\\dots,k_8$ followed by the rounded Pearson correlation coefficient (dimensionless). No units are required in the final answer.",
            "solution": "The problem is scientifically grounded, well-posed, and objective. All provided data and definitions are self-contained and consistent. The adjacency matrix $A$ is properly defined for an undirected, unweighted simple graph, being symmetric with a zero diagonal. The tasks involve standard, well-defined calculations (node degree, Pearson correlation) and a conceptual explanation based on established principles of experimental biology and statistics. Therefore, the problem is deemed valid and a solution will be provided.\n\nFirst, we define and compute the degree sequence for the given Protein-Protein Interaction (PPI) network. The network has $N=8$ proteins, and its topology is described by the $8 \\times 8$ adjacency matrix $A$. For an undirected, unweighted graph, the degree $k_i$ of a node $i$ is the number of edges connected to it. In terms of the adjacency matrix $A$, where $A_{ij}=1$ if an edge exists between nodes $i$ and $j$ and $A_{ij}=0$ otherwise, the degree $k_i$ is the sum of the entries in the $i$-th row (or, due to symmetry, the $i$-th column).\n$$k_i = \\sum_{j=1}^{N} A_{ij}$$\nUsing this definition, we compute the degree for each protein $P_1, \\dots, P_8$ by summing the rows of the given matrix $A$:\n$k_1 = 0+1+1+0+1+0+0+0 = 3$\n$k_2 = 1+0+1+1+0+1+0+0 = 4$\n$k_3 = 1+1+0+0+1+1+1+0 = 5$\n$k_4 = 0+1+0+0+0+1+0+1 = 3$\n$k_5 = 1+0+1+0+0+0+1+1 = 4$\n$k_6 = 0+1+1+1+0+0+0+0 = 3$\n$k_7 = 0+0+1+0+1+0+0+0 = 2$\n$k_8 = 0+0+0+1+1+0+0+0 = 2$\nThe resulting degree sequence is the vector $\\mathbf{k} = \\big(k_1, k_2, k_3, k_4, k_5, k_6, k_7, k_8\\big) = \\big(3, 4, 5, 3, 4, 3, 2, 2\\big)$.\n\nNext, we compute the Pearson correlation coefficient between the degree sequence $\\mathbf{k}$ and the given coverage vector $\\mathbf{c} = \\big(1.2, 1.8, 2.2, 1.3, 1.7, 1.4, 0.9, 0.8\\big)$. The Pearson correlation coefficient $r$ for two sets of $n$ measurements $X = (x_1, \\dots, x_n)$ and $Y = (y_1, \\dots, y_n)$ is defined as:\n$$r_{XY} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\nwhere $\\bar{x}$ and $\\bar{y}$ are the sample means, $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$ and $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$.\nIn our case, $n=8$, $X = \\mathbf{k}$, and $Y = \\mathbf{c}$. We first calculate the means:\n$$\\bar{k} = \\frac{1}{8} \\sum_{i=1}^{8} k_i = \\frac{3+4+5+3+4+3+2+2}{8} = \\frac{26}{8} = 3.25$$\n$$\\bar{c} = \\frac{1}{8} \\sum_{i=1}^{8} c_i = \\frac{1.2+1.8+2.2+1.3+1.7+1.4+0.9+0.8}{8} = \\frac{11.3}{8} = 1.4125$$\nNow we calculate the three required summations:\nThe sum of products of deviations (the numerator's covariance term):\n$$ \\sum_{i=1}^{8} (k_i - \\bar{k})(c_i - \\bar{c}) = (3 - 3.25)(1.2 - 1.4125) + (4 - 3.25)(1.8 - 1.4125) + \\dots + (2 - 3.25)(0.8 - 1.4125) $$\n$$ = (-0.25)(-0.2125) + (0.75)(0.3875) + (1.75)(0.7875) + (-0.25)(-0.1125) + (0.75)(0.2875) + (-0.25)(-0.0125) + (-1.25)(-0.5125) + (-1.25)(-0.6125) $$\n$$ = 0.053125 + 0.290625 + 1.378125 + 0.028125 + 0.215625 + 0.003125 + 0.640625 + 0.765625 = 3.375 $$\nThe sum of squared deviations for $k$:\n$$ \\sum_{i=1}^{8} (k_i - \\bar{k})^2 = (-0.25)^2 + (0.75)^2 + (1.75)^2 + (-0.25)^2 + (0.75)^2 + (-0.25)^2 + (-1.25)^2 + (-1.25)^2 $$\n$$ = 0.0625 + 0.5625 + 3.0625 + 0.0625 + 0.5625 + 0.0625 + 1.5625 + 1.5625 = 7.5 $$\nThe sum of squared deviations for $c$:\n$$ \\sum_{i=1}^{8} (c_i - \\bar{c})^2 = (-0.2125)^2 + (0.3875)^2 + (0.7875)^2 + (-0.1125)^2 + (0.2875)^2 + (-0.0125)^2 + (-0.5125)^2 + (-0.6125)^2 $$\n$$ = 0.04515625 + 0.15015625 + 0.62015625 + 0.01265625 + 0.08265625 + 0.00015625 + 0.26265625 + 0.37515625 = 1.54875 $$\nSubstituting these values into the correlation formula:\n$$r = \\frac{3.375}{\\sqrt{7.5} \\sqrt{1.54875}} = \\frac{3.375}{\\sqrt{11.615625}} \\approx \\frac{3.375}{3.4081703} \\approx 0.990267$$\nRounding to four significant figures, the correlation is $r \\approx 0.9903$.\n\nFinally, we explain why a higher coverage factor $c_i$ tends to inflate the observed degree $k_i$ in PPI networks.\nIn techniques like Affinity Purification-Mass Spectrometry (AP-MS), a specific protein (the \"bait\", $P_i$) is used to pull down its interaction partners (the \"prey\"), which are then identified. The coverage factor $c_i$ is proportional to the number of times $P_i$ has been used as a bait in experiments.\nThe detection of any given protein-protein interaction is a stochastic process. In a single experiment, a true interaction may not be detected due to various factors (e.g., low-affinity binding, low protein expression, technical limitations of mass spectrometry). The probability of detecting a specific true interaction in a single experiment is less than $1$, let's call it $p_{detection}$.\nIf a protein $P_i$ is used as a bait in $M_i$ independent experiments (where $M_i$ is proportional to $c_i$), the probability of *failing* to detect a particular true partner in all $M_i$ experiments is $(1 - p_{detection})^{M_i}$. The probability of successfully detecting that partner at least once is therefore $1 - (1 - p_{detection})^{M_i}$. This detection probability is a monotonically increasing function of $M_i$.\nConsequently, proteins that are used as baits more frequently (higher $c_i$) have a higher chance of their true interaction partners being detected. This systematically inflates their *observed* degree $k_i$ compared to proteins that are studied less frequently. A protein with a low $c_i$ may have a high true degree, but many of its interactions might remain undiscovered, leading to a low observed degree.\nThis correlation between degree and coverage reflects *measurement bias* under the condition that the experimental effort (represented by $\\mathbf{c}$) is not uniformly distributed across all proteins and is not a perfect representation of the proteins' true biological connectivity. If researchers, for instance, choose to study \"popular\" proteins (e.g., those already linked to a disease) more heavily, the vector $\\mathbf{c}$ becomes skewed. The resulting high correlation between observed degree and coverage is then an artifact of this non-uniform sampling. It conflates the true biological signal (if any) with a strong systematic bias, making it impossible to conclude from the observed data alone that proteins with higher coverage are truly more-connected hubs in the biological system. The bias is the portion of the observed correlation induced by the sampling process itself, independent of the underlying biology.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 3 & 4 & 5 & 3 & 4 & 3 & 2 & 2 & 0.9903 \\end{pmatrix} } $$"
        },
        {
            "introduction": "While degree measures local connectivity, other metrics capture a protein's global importance within the network's architecture. Betweenness centrality identifies proteins that act as crucial bridges or bottlenecks by quantifying how often they lie on the shortest communication paths between other proteins. This practice will develop your intuition for network flow by having you calculate this essential metric and analyze the structural consequences of removing a high-centrality node. ",
            "id": "4298718",
            "problem": "Consider a Protein-Protein Interaction Network (PPIN), defined as an undirected, weighted graph where proteins are nodes and interactions are edges with positive weights representing effective path costs inversely related to interaction affinity (lower weight indicates higher affinity). Let the network have nodes $A$, $B$, $C$, $D$, $E$, and $F$. The set of undirected weighted edges is\n$\\{(A,B,1), (A,C,1), (B,C,1), (C,D,1), (D,E,1), (D,F,1), (E,F,1), (A,D,2), (B,D,2), (C,E,2)\\}$,\nwhere each tuple denotes $(\\text{protein}_1,\\ \\text{protein}_2,\\ \\text{weight})$ and all weights are strictly positive. Shortest paths are defined with respect to the sum of weights along a path.\n\nUsing the standard, unnormalized definition of betweenness centrality employed in network science, compute the betweenness centrality of protein $C$, taking shortest paths over unordered pairs of distinct proteins that exclude $C$ as endpoints. In addition, explain—based on first principles of shortest-path structure—how removing protein $C$ affects the flow along shortest paths (i.e., the redundancy and routing of geodesic paths) between the remaining proteins.\n\nReport only the betweenness centrality of protein $C$ as a single reduced fraction with no units. No rounding is required.",
            "solution": "The problem is evaluated as valid. It is scientifically grounded in network theory, well-posed with a complete and consistent definition, and stated objectively. The solution process may proceed.\n\nThe task is twofold: first, to compute the unnormalized betweenness centrality of protein $C$, denoted $B_C$; and second, to explain the structural impact of removing protein $C$ on the shortest paths within the network.\n\n**Part 1: Computation of Betweenness Centrality**\n\nThe betweenness centrality of a node $v$, $B(v)$, is defined as the sum of the fractions of all-pairs shortest paths that pass through $v$. For an undirected graph, the standard formula is:\n$$\nB(v) = \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n$$\nwhere the sum is over all unordered pairs of distinct nodes $\\{s, t\\}$ in the network, not including $v$. Here, $\\sigma_{st}$ is the total number of shortest paths (geodesics) between node $s$ and node $t$, and $\\sigma_{st}(v)$ is the number of those shortest paths that pass through node $v$.\n\nThe set of nodes is $V = \\{A, B, C, D, E, F\\}$. We must calculate $B_C$ by considering all unordered pairs of nodes from the set $V \\setminus \\{C\\} = \\{A, B, D, E, F\\}$. The number of such pairs is $\\binom{5}{2} = 10$. Let us analyze the shortest paths for each pair.\n\nThe network edges and weights are:\n$w(A,B) = 1$, $w(A,C) = 1$, $w(B,C) = 1$, $w(C,D) = 1$, $w(D,E) = 1$, $w(D,F) = 1$, $w(E,F) = 1$, $w(A,D) = 2$, $w(B,D) = 2$, $w(C,E) = 2$.\n\n1.  **Pair $\\{A, B\\}$**: The shortest path is the direct edge $A-B$ with weight $1$. The path $A-C-B$ has weight $1+1=2$. Thus, $\\sigma_{AB} = 1$, and this path does not pass through $C$. The contribution to $B_C$ is $\\frac{0}{1} = 0$.\n\n2.  **Pair $\\{D, E\\}$**: The shortest path is the direct edge $D-E$ with weight $1$. The path $D-F-E$ has weight $1+1=2$. The path $D-C-E$ has weight $1+2=3$. Thus, $\\sigma_{DE} = 1$, and it does not pass through $C$. Contribution is $0$.\n\n3.  **Pair $\\{D, F\\}$**: The shortest path is the direct edge $D-F$ with weight $1$. The path $D-E-F$ has weight $1+1=2$. Thus, $\\sigma_{DF} = 1$, and it does not pass through $C$. Contribution is $0$.\n\n4.  **Pair $\\{E, F\\}$**: The shortest path is the direct edge $E-F$ with weight $1$. The path $E-D-F$ has weight $1+1=2$. Thus, $\\sigma_{EF} = 1$, and it does not pass through $C$. Contribution is $0$.\n\n5.  **Pair $\\{A, D\\}$**:\n    *   Path $A-C-D$: weight $w(A,C) + w(C,D) = 1+1=2$.\n    *   Path $A-D$: weight $w(A,D) = 2$.\n    *   Path $A-B-D$: weight $w(A,B) + w(B,D) = 1+2=3$.\n    There are two shortest paths of length $2$: $A-C-D$ and $A-D$. Thus, $\\sigma_{AD} = 2$. One of these paths, $A-C-D$, passes through $C$, so $\\sigma_{AD}(C) = 1$. The contribution is $\\frac{1}{2}$.\n\n6.  **Pair $\\{B, D\\}$**: By symmetry with pair $\\{A,D\\}$ (nodes $A$ and $B$ are structurally equivalent with respect to the rest of the network), we find two shortest paths of length $2$: $B-C-D$ and $B-D$. Thus, $\\sigma_{BD} = 2$ and $\\sigma_{BD}(C) = 1$. The contribution is $\\frac{1}{2}$.\n\n7.  **Pair $\\{A, E\\}$**:\n    *   Path $A-D-E$: weight $w(A,D) + w(D,E) = 2+1=3$.\n    *   Path $A-C-D-E$: weight $w(A,C) + w(C,D) + w(D,E) = 1+1+1=3$.\n    *   Path $A-C-E$: weight $w(A,C) + w(C,E) = 1+2=3$.\n    *   Path $A-B-D-E$: weight $1+2+1=4$.\n    There are three shortest paths of length $3$. Thus, $\\sigma_{AE} = 3$. Two of these, $A-C-D-E$ and $A-C-E$, pass through $C$. Thus, $\\sigma_{AE}(C) = 2$. The contribution is $\\frac{2}{3}$.\n\n8.  **Pair $\\{B, E\\}$**: By symmetry with pair $\\{A,E\\}$, there are three shortest paths of length $3$: $B-D-E$, $B-C-D-E$, and $B-C-E$. Thus, $\\sigma_{BE} = 3$. Two of these pass through $C$, so $\\sigma_{BE}(C) = 2$. The contribution is $\\frac{2}{3}$.\n\n9.  **Pair $\\{A, F\\}$**:\n    *   Path $A-D-F$: weight $w(A,D) + w(D,F) = 2+1=3$.\n    *   Path $A-C-D-F$: weight $w(A,C) + w(C,D) + w(D,F) = 1+1+1=3$.\n    *   Path $A-C-E-F$: weight $1+2+1=4$.\n    There are two shortest paths of length $3$: $A-D-F$ and $A-C-D-F$. Thus, $\\sigma_{AF} = 2$. One path passes through $C$, so $\\sigma_{AF}(C) = 1$. The contribution is $\\frac{1}{2}$.\n\n10. **Pair $\\{B, F\\}$**: By symmetry with pair $\\{A,F\\}$, there are two shortest paths of length $3$: $B-D-F$ and $B-C-D-F$. Thus, $\\sigma_{BF} = 2$. One path passes through $C$, so $\\sigma_{BF}(C) = 1$. The contribution is $\\frac{1}{2}$.\n\nNow, we sum all non-zero contributions to find $B_C$:\n$$\nB_C = \\sum_{\\{s,t\\} \\subset V \\setminus \\{C\\}} \\frac{\\sigma_{st}(C)}{\\sigma_{st}} = 0 + 0 + 0 + 0 + \\frac{1}{2} + \\frac{1}{2} + \\frac{2}{3} + \\frac{2}{3} + \\frac{1}{2} + \\frac{1}{2}\n$$\n$$\nB_C = 4 \\times \\frac{1}{2} + 2 \\times \\frac{2}{3} = 2 + \\frac{4}{3} = \\frac{6}{3} + \\frac{4}{3} = \\frac{10}{3}\n$$\n\n**Part 2: Effect of Removing Protein C**\n\nRemoving protein $C$ also removes all edges incident to it: $(A,C)$, $(B,C)$, $(C,D)$, and $(C,E)$. This fundamentally alters the network's topology and the available paths for information or signal flow. The analysis must be based on the first principles of shortest-path structure: the set of shortest paths for any given pair of nodes is determined by finding all paths that achieve the minimum possible sum of edge weights. Removing a node eliminates any path that includes it, forcing a re-evaluation of shortest paths among the remaining alternatives.\n\nThe primary effect of removing $C$ is on paths connecting the sub-network involving nodes $\\{A,B\\}$ to the sub-network involving nodes $\\{D,E,F\\}$. For pairs within these sub-networks (e.g., $\\{A,B\\}$ or $\\{D,E\\}$), the shortest paths are unaffected as they do not involve $C$. Let us examine the pairs whose geodesic paths were mediated by $C$:\n\n*   **Pairs $\\{A,D\\}$ and $\\{B,D\\}$**: Before removal, the shortest path length was $2$, and there were two redundant paths (e.g., $A-D$ and $A-C-D$). After removing $C$, the paths $A-C-D$ and $B-C-D$ are eliminated. For both pairs, only a single shortest path remains ($A-D$ and $B-D$, respectively), both still of length $2$. The effect is a **complete loss of redundancy** in the shortest connections between $\\{A,B\\}$ and $D$, without an increase in path length.\n\n*   **Pairs $\\{A,E\\}$, $\\{B,E\\}$, $\\{A,F\\}$, and $\\{B,F\\}$**:\n    *   For $\\{A,E\\}$, removing $C$ eliminates two of the three shortest paths ($A-C-D-E$ and $A-C-E$). The sole remaining shortest path is $A-D-E$, with its length of $3$ becoming the new unique geodesic distance.\n    *   For $\\{A,F\\}$, removing $C$ eliminates one of the two shortest paths ($A-C-D-F$). The sole remaining shortest path is $A-D-F$, with its length of $3$ becoming the new unique geodesic distance.\n    *   The same logic applies symmetrically to pairs $\\{B,E\\}$ and $\\{B,F\\}$.\n\nIn summary, the removal of protein $C$ has the following consequences for shortest-path routing:\n\n1.  **Loss of Redundancy**: For every pair of proteins $(s,t)$ where $s \\in \\{A,B\\}$ and $t \\in \\{D,E,F\\}$, the number of distinct shortest paths, $\\sigma_{st}$, is strictly reduced. This signifies a decrease in the network's robustness. The flow, which was previously distributed across multiple geodesic paths, is now concentrated onto fewer, or in these cases, single routes.\n\n2.  **Increased Centrality of Other Nodes**: The rerouting of flow makes other nodes and edges more critical. Specifically, all shortest paths from $\\{A,B\\}$ to $\\{D,E,F\\}$ must now pass through node $D$ and utilize the edges $(A,D)$ and $(B,D)$. The betweenness centrality of node $D$ and the edge betweenness of $(A,D)$ and $(B,D)$ would increase significantly. Protein $D$ becomes a critical bottleneck or articulation point for communication between these two parts of the network.\n\n3.  **No Increase in Path Distance**: For this specific network configuration, the removal of $C$ does not increase the shortest path *length* for any pair of remaining nodes. This is a crucial observation: protein $C$ provided alternative routes that were exactly as efficient (in terms of path weight) as the best non-$C$ paths. It functioned as a source of parallel, equally optimal pathways rather than as a \"shortcut.\" If the weights had been different (e.g., if $w(C,D)$ were less than $1$), its removal could have increased path distances.\n\nFrom the first principle of shortest-path computation, removing node $C$ prunes the set of candidate paths. For the affected pairs, this pruning removed paths that were members of the set of minimum-weight paths, thereby reducing the size of this set ($\\sigma_{st}$). Since at least one minimum-weight path remained that did not involve $C$, the shortest path distance itself did not change.",
            "answer": "$$\\boxed{\\frac{10}{3}}$$"
        },
        {
            "introduction": "A protein-protein interaction network is a static snapshot of a highly dynamic cellular environment. The edges we draw represent physical interactions that are constantly forming and dissociating according to the principles of chemical kinetics. This exercise moves beyond static topology to model the underlying dynamics of competitive binding, using the law of mass action to determine how multiple proteins compete for a single target, thereby providing a more mechanistic understanding of what an edge in a PPI network truly represents. ",
            "id": "4298682",
            "problem": "Consider a well-mixed solution containing a single target protein $T$ with one binding site and three distinct proteins $P_{1}$, $P_{2}$, and $P_{3}$ that competitively bind to $T$. Binding is mutually exclusive: at most one of $P_{1}$, $P_{2}$, or $P_{3}$ can be bound to $T$ at any time. The reversible reactions are $P_{i} + T \\rightleftharpoons P_{i}T$ for $i \\in \\{1,2,3\\}$, with association rate constants $k_{\\text{on},i}$ and dissociation rate constants $k_{\\text{off},i}$. Let $[P_{i}]$ denote the free concentration of protein $P_{i}$, $[T]$ the free concentration of target $T$, and $[P_{i}T]$ the concentration of the complex.\n\nUsing the law of mass action and mass conservation, perform the following:\n\n1. Write the Ordinary Differential Equations (ODEs) governing the time evolution of $[P_{1}T]$, $[P_{2}T]$, and $[P_{3}T]$, and the algebraic mass-conservation relations linking $[P_{i}]$, $[T]$, and the total concentrations $P_{i}^{\\text{tot}}$ and $T^{\\text{tot}}$.\n\n2. By imposing steady state ($d[P_{i}T]/dt=0$) and assuming the biologically common regime $T^{\\text{tot}} \\ll P_{i}^{\\text{tot}}$ (so that binding to $T$ does not significantly deplete the free pools of $P_{i}$), derive the steady-state fractional occupancies\n$$\nf_{i} \\equiv \\frac{[P_{i}T]}{T^{\\text{tot}}}, \\quad i \\in \\{1,2,3\\}.\n$$\nExpress $f_{i}$ in terms of $k_{\\text{on},i}$, $k_{\\text{off},i}$, and $P_{i}^{\\text{tot}}$.\n\n3. Compute the numerical values of $f_{1}$, $f_{2}$, and $f_{3}$ using the following parameter values: $T^{\\text{tot}} = 5 \\,\\text{nM}$; $P_{1}^{\\text{tot}} = 1.0 \\,\\mu\\text{M}$, $P_{2}^{\\text{tot}} = 0.7 \\,\\mu\\text{M}$, $P_{3}^{\\text{tot}} = 0.4 \\,\\mu\\text{M}$; $k_{\\text{on},1} = 1.5 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1}$, $k_{\\text{off},1} = 0.03 \\, \\text{s}^{-1}$; $k_{\\text{on},2} = 0.9 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1}$, $k_{\\text{off},2} = 0.01 \\, \\text{s}^{-1}$; $k_{\\text{on},3} = 1.2 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1}$, $k_{\\text{off},3} = 0.05 \\, \\text{s}^{-1}$. Round each fractional occupancy to four significant figures. Express the final occupancies as decimals.",
            "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in the principles of chemical kinetics (law of mass action) and mass conservation, is well-posed with sufficient information for a unique solution, and is expressed in objective, unambiguous language. The given parameters are physically realistic and consistent with the stated assumptions. We may therefore proceed with the solution.\n\nThe problem asks for a three-part solution concerning the competitive binding of three proteins, $P_1$, $P_2$, and $P_3$, to a single target protein, $T$.\n\n### Part 1: ODEs and Mass Conservation\n\nThe system involves three reversible reactions, one for each protein $P_i$ binding to the target $T$:\n$$\nP_{i} + T \\underset{k_{\\text{off},i}}{\\stackrel{k_{\\text{on},i}}{\\rightleftharpoons}} P_{i}T, \\quad \\text{for } i \\in \\{1,2,3\\}\n$$\nwhere $k_{\\text{on},i}$ is the association rate constant and $k_{\\text{off},i}$ is the dissociation rate constant for the $i$-th reaction.\n\nAccording to the law of mass action, the rate of formation of the complex $[P_iT]$ is proportional to the product of the concentrations of the free reactants, $k_{\\text{on},i}[P_i][T]$. The rate of dissociation of the complex is proportional to its own concentration, $k_{\\text{off},i}[P_iT]$. The net rate of change of the concentration of each complex, $[P_iT]$, is given by the following Ordinary Differential Equations (ODEs):\n$$\n\\frac{d[P_{1}T]}{dt} = k_{\\text{on},1} [P_{1}] [T] - k_{\\text{off},1} [P_{1}T]\n$$\n$$\n\\frac{d[P_{2}T]}{dt} = k_{\\text{on},2} [P_{2}] [T] - k_{\\text{off},2} [P_{2}T]\n$$\n$$\n\\frac{d[P_{3}T]}{dt} = k_{\\text{on},3} [P_{3}] [T] - k_{\\text{off},3} [P_{3}T]\n$$\n\nThe algebraic mass-conservation relations state that the total concentration of each species is constant. For the target protein $T$, the total concentration, $T^{\\text{tot}}$, is the sum of its free concentration $[T]$ and the concentrations of all its bound forms. Since binding is mutually exclusive, we have:\n$$\nT^{\\text{tot}} = [T] + [P_{1}T] + [P_{2}T] + [P_{3}T]\n$$\nSimilarly, for each of the binding proteins $P_i$, the total concentration, $P_{i}^{\\text{tot}}$, is the sum of its free concentration $[P_i]$ and its concentration in the bound complex:\n$$\nP_{1}^{\\text{tot}} = [P_{1}] + [P_{1}T]\n$$\n$$\nP_{2}^{\\text{tot}} = [P_{2}] + [P_{2}T]\n$$\n$$\nP_{3}^{\\text{tot}} = [P_{3}] + [P_{3}T]\n$$\n\n### Part 2: Steady-State Fractional Occupancies\n\nAt steady state, the concentrations of all species are constant, which means the net rate of change for each complex is zero:\n$$\n\\frac{d[P_{i}T]}{dt} = 0, \\quad \\text{for } i \\in \\{1,2,3\\}\n$$\nApplying this condition to the ODEs from Part 1 gives:\n$$\nk_{\\text{on},i} [P_{i}] [T] - k_{\\text{off},i} [P_{i}T] = 0\n$$\nRearranging this equation, we can express the concentration of the complex $[P_iT]$ in terms of the free concentrations $[P_i]$ and $[T]$:\n$$\n[P_{i}T] = \\frac{k_{\\text{on},i}}{k_{\\text{off},i}} [P_{i}] [T]\n$$\nIt is conventional to define the dissociation constant, $K_{D,i} = \\frac{k_{\\text{off},i}}{k_{\\text{on},i}}$. Using this definition, the equation becomes:\n$$\n[P_{i}T] = \\frac{[P_{i}][T]}{K_{D,i}}\n$$\nWe are given the condition $T^{\\text{tot}} \\ll P_{i}^{\\text{tot}}$. From mass conservation, $[P_i] = P_{i}^{\\text{tot}} - [P_iT]$. Since at most all of $T$ can be bound by $P_i$, we have $[P_iT] \\le T^{\\text{tot}}$. The given condition thus implies $[P_iT] \\ll P_{i}^{\\text{tot}}$, which allows for the approximation that the free concentration of $P_i$ is nearly equal to its total concentration:\n$$\n[P_i] \\approx P_{i}^{\\text{tot}}\n$$\nSubstituting this approximation into the steady-state relation yields:\n$$\n[P_{i}T] \\approx \\frac{P_{i}^{\\text{tot}}[T]}{K_{D,i}}\n$$\nNow, we use the mass conservation equation for the target protein $T$:\n$$\nT^{\\text{tot}} = [T] + \\sum_{j=1}^{3} [P_{j}T]\n$$\nSubstituting our approximate expression for each $[P_jT]$:\n$$\nT^{\\text{tot}} \\approx [T] + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}[T]}{K_{D,j}} = [T] \\left( 1 + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}}{K_{D,j}} \\right)\n$$\nWe can solve for the free target concentration $[T]$:\n$$\n[T] \\approx \\frac{T^{\\text{tot}}}{1 + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}}{K_{D,j}}}\n$$\nThe fractional occupancy for protein $P_i$ is defined as $f_i \\equiv \\frac{[P_iT]}{T^{\\text{tot}}}$. Using our expression for $[P_iT]$:\n$$\nf_i = \\frac{[P_iT]}{T^{\\text{tot}}} \\approx \\frac{1}{T^{\\text{tot}}} \\left( \\frac{P_{i}^{\\text{tot}}[T]}{K_{D,i}} \\right)\n$$\nSubstituting the expression for $[T]$ into this equation:\n$$\nf_i \\approx \\frac{1}{T^{\\text{tot}}} \\frac{P_{i}^{\\text{tot}}}{K_{D,i}} \\left( \\frac{T^{\\text{tot}}}{1 + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}}{K_{D,j}}} \\right) = \\frac{\\frac{P_{i}^{\\text{tot}}}{K_{D,i}}}{1 + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}}{K_{D,j}}}\n$$\nTo express this in terms of the given rate constants, we substitute $K_{D,i} = \\frac{k_{\\text{off},i}}{k_{\\text{on},i}}$:\n$$\nf_i = \\frac{\\frac{P_{i}^{\\text{tot}}}{k_{\\text{off},i}/k_{\\text{on},i}}}{1 + \\sum_{j=1}^{3} \\frac{P_{j}^{\\text{tot}}}{k_{\\text{off},j}/k_{\\text{on},j}}} = \\frac{\\frac{k_{\\text{on},i}P_{i}^{\\text{tot}}}{k_{\\text{off},i}}}{1 + \\sum_{j=1}^{3} \\frac{k_{\\text{on},j}P_{j}^{\\text{tot}}}{k_{\\text{off},j}}}\n$$\nThis is the final expression for the steady-state fractional occupancies.\n\n### Part 3: Numerical Calculation\n\nTo compute the numerical values for $f_1$, $f_2$, and $f_3$, we first evaluate the dimensionless terms $\\frac{k_{\\text{on},i}P_{i}^{\\text{tot}}}{k_{\\text{off},i}}$. We must use consistent units (M, s).\nThe given total protein concentrations are:\n$P_{1}^{\\text{tot}} = 1.0 \\,\\mu\\text{M} = 1.0 \\times 10^{-6} \\,\\text{M}$\n$P_{2}^{\\text{tot}} = 0.7 \\,\\mu\\text{M} = 0.7 \\times 10^{-6} \\,\\text{M}$\n$P_{3}^{\\text{tot}} = 0.4 \\,\\mu\\text{M} = 0.4 \\times 10^{-6} \\,\\text{M}$\n\nLet's compute each term, which we can denote $X_i = \\frac{k_{\\text{on},i}P_{i}^{\\text{tot}}}{k_{\\text{off},i}}$:\nFor $i=1$:\n$$\nX_1 = \\frac{(1.5 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1})(1.0 \\times 10^{-6} \\, \\text{M})}{0.03 \\, \\text{s}^{-1}} = \\frac{1.5}{0.03} = 50\n$$\nFor $i=2$:\n$$\nX_2 = \\frac{(0.9 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1})(0.7 \\times 10^{-6} \\, \\text{M})}{0.01 \\, \\text{s}^{-1}} = \\frac{0.63}{0.01} = 63\n$$\nFor $i=3$:\n$$\nX_3 = \\frac{(1.2 \\times 10^{6} \\, \\text{M}^{-1}\\text{s}^{-1})(0.4 \\times 10^{-6} \\, \\text{M})}{0.05 \\, \\text{s}^{-1}} = \\frac{0.48}{0.05} = 9.6\n$$\nThe common denominator in the expression for $f_i$ is $1 + \\sum_{j=1}^{3} X_j$:\n$$\n1 + X_1 + X_2 + X_3 = 1 + 50 + 63 + 9.6 = 123.6\n$$\nNow we can compute each fractional occupancy $f_i = \\frac{X_i}{1 + X_1 + X_2 + X_3}$:\n$$\nf_1 = \\frac{50}{123.6} \\approx 0.404530744...\n$$\n$$\nf_2 = \\frac{63}{123.6} \\approx 0.509708737...\n$$\n$$\nf_3 = \\frac{9.6}{123.6} \\approx 0.077669902...\n$$\nRounding these results to four significant figures as requested:\n$f_1 \\approx 0.4045$\n$f_2 \\approx 0.5097$\n$f_3 \\approx 0.07767$\n\nThese are the final numerical values for the fractional occupancies.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4045 & 0.5097 & 0.07767\n\\end{pmatrix}\n}\n$$"
        }
    ]
}