{
    "hands_on_practices": [
        {
            "introduction": "The emergence of a giant k-core is a cornerstone of percolation theory. While the giant component ($k=1$) and the 2-core emerge continuously, for $k \\ge 3$ the transition becomes discontinuous, or \"hybrid,\" with the core appearing abruptly at a critical threshold. This practice guides you through the analytical and numerical exploration of this phenomenon on an Erdős–Rényi graph, where you will derive the conditions for the transition and compute the critical point for the 3-core .",
            "id": "4284918",
            "problem": "Consider an Erdős–Rényi (ER) random graph, defined as a graph on $n$ labeled vertices where each pair of vertices is connected by an edge independently with probability $p$, such that the mean degree $c$ equals $c = p(n-1)$ in the sparse limit. The $k$-core of a graph is the maximal subgraph in which every vertex has degree at least $k$. In the large-size limit for ER random graphs, the emergence of a giant $k$-core for $k \\geq 3$ is known to be a hybrid (discontinuous with critical singularity) transition at a threshold mean degree $c^\\star$.\n\nStarting only from foundational facts for ER graphs (Poisson degree distribution of mean $c$ in the sparse limit and independence of edges) and the definition of the $k$-core as the fixed point of iterative pruning (removing vertices of degree less than $k$ until all remaining vertices have degree at least $k$), derive the appropriate self-consistency condition for the survival probability $x$ of a randomly followed half-edge leading to a vertex that remains in the pruned graph, and the corresponding condition for the emergence threshold where the nonzero fixed point $x^\\star$ appears via a double root of the fixed-point equation.\n\nFor the specific case $k = 3$, you must:\n- Use the ER graph assumptions and iterative pruning to obtain the fixed-point function $f(x; c)$ such that the $k$-core corresponds to solutions of $f(x; c) = 0$.\n- Characterize the threshold by the double-root (tangency) conditions $f(x; c) = 0$ and $\\frac{\\partial}{\\partial x} f(x; c) = 0$ at a nonzero $x^\\star$, and reduce these conditions to a single scalar equation in an auxiliary variable that can be solved numerically.\n- Compute numerically:\n  1. The nonzero solution $x^\\star$ at the threshold for $k = 3$.\n  2. The threshold mean degree $c^\\star$.\n  3. The corresponding fraction $S^\\star$ of vertices in the $3$-core at the threshold, expressed as a decimal (not a percentage), using the standard counting argument that the fraction of vertices with residual degree less than $k$ in the pruned graph is the cumulative probability of a Poisson random variable with mean $c x$ up to $k - 1$.\n\nYour program must implement a robust numerical solver starting from first principles and produce the following test suite outputs:\n- Test Case 1 (happy path): Compute the auxiliary variable that solves the reduced scalar equation derived from the double-root conditions using a bracketing interval $[1.0, 3.0]$.\n- Test Case 2: Compute $x^\\star$ from the auxiliary variable obtained in Test Case 1.\n- Test Case 3: Compute $c^\\star$ from the auxiliary variable and $x^\\star$.\n- Test Case 4: Compute $S^\\star$ using $x^\\star$ and $c^\\star$ via the appropriate Poisson cumulative expression for $k = 3$.\n- Test Case 5 (edge condition verification): Verify the double-root conditions at the solution by checking both $f(x^\\star; c^\\star) = 0$ and $\\frac{\\partial}{\\partial x} f(x^\\star; c^\\star) = 0$ within a tolerance of $10^{-12}$, and that the second derivative $\\frac{\\partial^2}{\\partial x^2} f(x^\\star; c^\\star)$ is strictly positive. Output a boolean indicating whether all checks pass.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact order: $[y^\\star, x^\\star, c^\\star, S^\\star, \\text{boolean}]$, where $y^\\star$ is the auxiliary variable introduced in your derivation. No units are involved; express $S^\\star$ as a decimal.",
            "solution": "The problem of determining the onset of a giant $k$-core in an Erdős–Rényi (ER) random graph is a classic problem in network science. We are tasked with deriving the conditions for this transition for the specific case of the $3$-core ($k=3$) and computing the critical parameters. The derivation will start from first principles, namely the properties of ER graphs in the large-size, sparse limit.\n\nIn this limit, an ER graph with $n$ vertices and mean degree $c$ exhibits two key properties:\n$1$. The degree distribution of vertices follows a Poisson distribution with mean $c$: $P(d) = e^{-c} \\frac{c^d}{d!}$.\n$2$. The degrees of different vertices are uncorrelated, and the structure of the graph is locally tree-like.\n\nThe $k$-core is found by iteratively pruning all vertices with a degree less than $k$. The survival of a vertex depends on the survival of its neighbors. This suggests a self-consistent or mean-field approach. Let $x$ be the probability that a vertex reached by following a random edge belongs to the $k$-core. This is the survival probability of a *neighboring* vertex. A non-zero value of $x$ indicates the existence of a macroscopic (giant) $k$-core.\n\nConsider a vertex $v$ reached by following a random edge. Due to the random edge selection, the degree distribution of $v$ is not the standard Poisson distribution for a random vertex. The probability of selecting a vertex of degree $d$ by following a random edge is proportional to $d P(d)$. The distribution of the *residual degree* $d-1$ (the number of other edges of $v$) is then given by $\\frac{d P(d)}{\\langle d \\rangle} = \\frac{d e^{-c} c^d/d!}{c} = e^{-c} \\frac{c^{d-1}}{(d-1)!}$. This is a Poisson distribution with mean $c$.\n\nLet's model the pruning process. Each of the $d-1$ \"other\" neighbors of vertex $v$ survives the pruning process independently with probability $x$. Because the initial distribution of the number of these neighbors is Poisson with mean $c$, the number of *surviving* neighbors follows a \"thinned\" Poisson distribution with mean $c x$.\nFor the vertex $v$ itself to survive and be part of the $k$-core, its degree within the final pruned graph must be at least $k$. We arrived at $v$ via one edge (which we assume is connected to a surviving part of the graph), so $v$ must have at least $k-1$ other neighbors that also survive.\n\nThis leads to the self-consistency equation for $x$. The probability $x$ that vertex $v$ survives is the probability that a Poisson random variable $Z$ with mean $c x$ takes a value of at least $k-1$:\n$$x = P(Z \\ge k-1) = \\sum_{j=k-1}^{\\infty} e^{-cx} \\frac{(cx)^j}{j!} = 1 - \\sum_{j=0}^{k-2} e^{-cx} \\frac{(cx)^j}{j!}$$\nThis equation always has a trivial solution $x=0$, corresponding to the absence of a giant $k$-core. A non-trivial solution $x > 0$ emerges at a critical threshold $c^\\star$.\n\nFor the specific case $k=3$, the self-consistency equation is:\n$$x = 1 - \\sum_{j=0}^{1} e^{-cx} \\frac{(cx)^j}{j!} = 1 - \\left( e^{-cx} \\frac{(cx)^0}{0!} + e^{-cx} \\frac{(cx)^1}{1!} \\right)$$\n$$x = 1 - e^{-cx}(1+cx)$$\nWe define a fixed-point function $f(x; c)$ such that its roots give the solutions for $x$:\n$$f(x; c) = x - 1 + e^{-cx}(1+cx) = 0$$\nThe emergence of a non-trivial solution for $k \\ge 3$ is a discontinuous transition, characterized by a saddle-node bifurcation. This occurs when the line $y=x$ becomes tangent to the curve $g(x) = 1 - e^{-cx}(1+cx)$. This tangency point, $(x^\\star, c^\\star)$, is a double root of the equation $f(x;c)=0$ and must satisfy two simultaneous conditions for $x^\\star > 0$:\n$1$. $f(x^\\star; c^\\star) = 0$\n$2$. $\\frac{\\partial f}{\\partial x}(x^\\star; c^\\star) = 0$\n\nLet's compute the partial derivative with respect to $x$:\n$$\\frac{\\partial f}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( x - 1 + e^{-cx}(1+cx) \\right) = 1 + [(-c)e^{-cx}(1+cx) + e^{-cx}(c)]$$\n$$\\frac{\\partial f}{\\partial x} = 1 -ce^{-cx} - c^2x e^{-cx} + ce^{-cx} = 1 - c^2x e^{-cx}$$\nThe two conditions at the critical point $(x^\\star, c^\\star)$ are:\n$1$. $x^\\star - 1 + e^{-c^\\star x^\\star}(1+c^\\star x^\\star) = 0$\n$2$. $1 - (c^\\star)^2 x^\\star e^{-c^\\star x^\\star} = 0$\n\nTo solve this system, we introduce an auxiliary variable $y = cx$. At the threshold, let $y^\\star = c^\\star x^\\star$.\nFrom condition ($2$):\n$$1 = (c^\\star)^2 x^\\star e^{-c^\\star x^\\star} = c^\\star (c^\\star x^\\star) e^{-c^\\star x^\\star} = c^\\star y^\\star e^{-y^\\star}$$\nThis gives an expression for $c^\\star$:\n$$c^\\star = \\frac{e^{y^\\star}}{y^\\star}$$\nFrom condition ($1$):\n$$1 - x^\\star = e^{-c^\\star x^\\star}(1+c^\\star x^\\star) = e^{-y^\\star}(1+y^\\star)$$\nWe need an expression for $x^\\star$ in terms of $y^\\star$. Using $x^\\star = y^\\star/c^\\star$ and the expression for $c^\\star$:\n$$x^\\star = \\frac{y^\\star}{e^{y^\\star}/y^\\star} = (y^\\star)^2 e^{-y^\\star}$$\nSubstituting this into the rearranged condition ($1$):\n$$1 - (y^\\star)^2 e^{-y^\\star} = e^{-y^\\star}(1+y^\\star)$$\nMultiplying by $e^{y^\\star}$ (since $y^\\star > 0$, $e^{y^\\star} \\neq 0$):\n$$e^{y^\\star} - (y^\\star)^2 = 1+y^\\star$$\nRearranging gives a single scalar equation for $y^\\star$:\n$$e^{y^\\star} - (y^\\star)^2 - y^\\star - 1 = 0$$\nThis equation can be solved numerically for $y^\\star > 0$. The problem specifies a bracketing interval of $[1.0, 3.0]$.\n\nOnce $y^\\star$ is found, we can compute the other critical quantities:\n-   $x^\\star = (y^\\star)^2 e^{-y^\\star}$\n-   $c^\\star = e^{y^\\star} / y^\\star$\n\nFinally, we compute $S^\\star$, the fraction of vertices in the $3$-core at the threshold. A randomly chosen vertex survives if its degree in the pruned graph is at least $k=3$. The degree of a random vertex after each neighbor survives independently with probability $x^\\star$ follows a Poisson distribution with mean $c^\\star x^\\star = y^\\star$. Thus, $S^\\star$ is the probability that a Poisson variable $Z \\sim \\text{Poisson}(y^\\star)$ is at least $3$:\n$$S^\\star = P(Z \\ge 3) = 1 - P(Z \\le 2) = 1 - \\sum_{j=0}^{2} e^{-y^\\star} \\frac{(y^\\star)^j}{j!}$$\n$$S^\\star = 1 - e^{-y^\\star} \\left( 1 + y^\\star + \\frac{(y^\\star)^2}{2} \\right)$$\nFor the transition to be a proper saddle-node bifurcation corresponding to a discontinuous jump, the second derivative of $f(x;c)$ at the critical point must be non-zero.\n$$\\frac{\\partial^2 f}{\\partial x^2} = \\frac{\\partial}{\\partial x} (1 - c^2x e^{-cx}) = -c^2 [e^{-cx} + x(-c)e^{-cx}] = -c^2 e^{-cx}(1-cx)$$\nAt the threshold, this becomes:\n$$\\frac{\\partial^2 f}{\\partial x^2}(x^\\star, c^\\star) = -(c^\\star)^2 e^{-y^\\star}(1-y^\\star)$$\nFor a physically meaningful discontinuous transition starting from $x=0$, we require this second derivative to be positive, which implies $1-y^\\star < 0$, or $y^\\star > 1$. The numerical solution must satisfy this.\n\nThe numerical implementation will solve for $y^\\star$, then calculate $x^\\star$, $c^\\star$, and $S^\\star$ using these derived formulas, and finally verify the double-root conditions and the sign of the second derivative.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Derives and computes the critical parameters for 3-core percolation on an ER graph.\n\n    The problem is solved by first deriving the self-consistency equations for the\n    survival probability of a node in the k-core. For k=3, this leads to a system\n    of two equations for the critical threshold (x*, c*), based on the double-root\n    condition for the emergence of a non-trivial solution.\n\n    f(x; c) = x - 1 + exp(-c*x)*(1 + c*x) = 0\n    df/dx(x; c) = 1 - c**2 * x * exp(-c*x) = 0\n\n    By introducing an auxiliary variable y = c*x, this system is reduced to a\n    single scalar equation for y:\n    g(y) = exp(y) - y**2 - y - 1 = 0\n\n    This script solves for y*, then computes x*, c*, and the 3-core size S* at the\n    threshold. Finally, it verifies that the computed values satisfy the original\n    double-root conditions.\n    \"\"\"\n\n    # --- Test Case 1: Compute the auxiliary variable y* ---\n    # Define the scalar function g(y) = 0 to be solved.\n    def g(y):\n        return np.exp(y) - y**2 - y - 1\n\n    # Solve for y* in the given interval [1.0, 3.0].\n    # There is also a root at y=0 which we are not interested in.\n    try:\n        y_star = brentq(g, 1.0, 3.0, xtol=1e-15, rtol=1e-15)\n    except ValueError:\n        # Handle cases where brentq might fail, although it shouldn't for this function and interval.\n        y_star = None\n    \n    if y_star is None:\n        raise RuntimeError(\"Failed to find root for the auxiliary variable y.\")\n\n    # --- Test Case 2: Compute x* ---\n    # The survival probability x* is given by x* = (y*)**2 * exp(-y*).\n    x_star = y_star**2 * np.exp(-y_star)\n\n    # --- Test Case 3: Compute c* ---\n    # The critical mean degree c* is given by c* = exp(y*) / y*.\n    c_star = np.exp(y_star) / y_star\n\n    # --- Test Case 4: Compute S* ---\n    # The fraction of vertices in the 3-core S* is P(Z >= 3) where Z ~ Poisson(y*).\n    # S* = 1 - exp(-y*) * (1 + y* + (y*)**2 / 2).\n    s_star = 1.0 - np.exp(-y_star) * (1.0 + y_star + y_star**2 / 2.0)\n    \n    # --- Test Case 5: Verify double-root conditions ---\n    tolerance = 1e-12\n    all_checks_passed = False\n\n    # Check 1: f(x*, c*) = 0\n    # f_val = x* - 1 + exp(-c*x)*(1 + c*x) = x* - 1 + exp(-y*)*(1 + y*)\n    f_val = x_star - 1.0 + np.exp(-y_star) * (1.0 + y_star)\n    check1 = abs(f_val) < tolerance\n\n    # Check 2: df/dx(x*, c*) = 0\n    # dfdx_val = 1 - c*^2 * x* * exp(-c*x) = 1 - c* * y* * exp(-y*)\n    # Since c* = exp(y*)/y*, this simplifies to 1 - (exp(y*)/y*) * y* * exp(-y*) = 1 - 1 = 0\n    # We use a numerical check to account for floating point inaccuracies.\n    dfdx_val = 1.0 - c_star**2 * x_star * np.exp(-y_star)\n    check2 = abs(dfdx_val) < tolerance\n\n    # Check 3: d^2f/dx^2(x*,c*) > 0\n    # d2fdx2 = -c*^2 * exp(-y*) * (1-y*)\n    d2fdx2_val = -(c_star**2) * np.exp(-y_star) * (1.0 - y_star)\n    check3 = d2fdx2_val > 0\n\n    all_checks_passed = bool(check1 and check2 and check3)\n    \n    # Assemble the final results\n    results = [y_star, x_star, c_star, s_star, all_checks_passed]\n    \n    # Final print statement in the exact required format.\n    # The format specifier ensures high precision to match the calculations.\n    # Note: A simple `str()` conversion might not provide enough precision.\n    print(f\"[{results[0]:.15f},{results[1]:.15f},{results[2]:.15f},{results[3]:.15f},{str(results[4]).lower()}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A network's resilience is not determined by its degree distribution alone; the way nodes are connected also matters profoundly. This exercise explores the impact of degree-degree correlations by comparing the 3-core in two networks that have identical degree sequences but opposite mixing patterns: one assortative and one disassortative. By applying a cavity method analysis, you will quantify how these higher-order structural features can be the deciding factor in whether a robust core can form at all .",
            "id": "4284879",
            "problem": "Consider an undirected random network generated by the configuration model with degree distribution $P(q)=\\frac{1}{2}\\delta_{q,2}+\\frac{1}{2}\\delta_{q,4}$, so that one half of the nodes have degree $2$ and one half have degree $4$. Two ensembles are defined that share this degree distribution but differ in their degree-degree correlations through the conditional neighbor-degree distribution $P(q' \\mid q)$:\n- Assortative ensemble $\\mathrm{A}$: $P(2 \\mid 2)=1$, $P(4 \\mid 4)=1$, and $P(2 \\mid 4)=P(4 \\mid 2)=0$.\n- Disassortative ensemble $\\mathrm{D}$: $P(4 \\mid 2)=1$, $P(2 \\mid 2)=0$, $P(2 \\mid 4)=\\frac{1}{2}$, and $P(4 \\mid 4)=\\frac{1}{2}$.\n\nThese conditional probabilities satisfy the undirected consistency constraint $q P(q) P(q' \\mid q)=q' P(q') P(q \\mid q')$ for all $q,q' \\in \\{2,4\\}$.\n\nStarting only from the definition of the $k$-core as the maximal induced subgraph in which every node has degree at least $k$, and from the locally tree-like nature of the configuration model (so that messages arriving along different edges can be treated as independent events conditioned on node degrees), analyze the $3$-core ($k=3$) in each ensemble. Define a cavity message along an edge to be positive if the node at the receiving end would remain in the $3$-core when that edge is removed; let $y_q$ denote the probability that such a message sent from a node of degree $q$ is positive in the infinite-size limit, and let $t_q$ denote the probability that a node of degree $q$ belongs to the $3$-core.\n\nDerive the appropriate self-consistency relations for $y_q$ and use them to compute $t_q$ in each ensemble. Then compute the total fraction of nodes in the $3$-core, $S_{\\mathrm{A}}$ and $S_{\\mathrm{D}}$, for ensembles $\\mathrm{A}$ and $\\mathrm{D}$, respectively. Finally, report the reduction\n$$\\Delta S \\equiv S_{\\mathrm{A}}-S_{\\mathrm{D}}.$$\nExpress your final answer as an exact number. No rounding is required.",
            "solution": "The problem asks for an analysis of the $3$-core in two random network ensembles, $\\mathrm{A}$ and $\\mathrm{D}$, which share the same degree distribution $P(q)=\\frac{1}{2}\\delta_{q,2}+\\frac{1}{2}\\delta_{q,4}$ but differ in their degree-degree correlations. The analysis will be performed using a cavity method approach as specified.\n\nThe problem statement has been validated and is deemed valid. It is scientifically grounded in the theory of complex networks, specifically $k$-core percolation. The problem is well-posed, with all necessary information provided and no contradictions. The definitions and goals are stated objectively and unambiguously.\n\nThe $k$-core is the largest induced subgraph where every node has a degree of at least $k$. For this problem, $k=3$. The analysis relies on a message-passing (cavity) method suitable for locally tree-like networks, such as those generated by the configuration model in the infinite-size limit.\n\nLet $y_q$ be the probability that a message sent from a node of degree $q$ is 'positive'. A positive message indicates that the sending node would remain in the $3$-core in a 'cavity' version of the network where the edge along which the message is sent has been removed. A node of original degree $q$ has degree $q-1$ in the cavity graph. For this node to remain in the $3$-core, it must be connected to at least $k=3$ neighbors that also remain in the core. In the message-passing framework, this translates to the node receiving at least $3$ positive messages from its $q-1$ neighbors in the cavity graph.\n\nLet $Y_q$ be the probability that a message received by our degree-$q$ node is positive. This probability depends on the degree distribution of its neighbors, $P(q'|q)$, and the probability $y_{q'}$ that a neighbor of degree $q'$ sends a positive message. So, $Y_q = \\sum_{q'} P(q'|q) y_{q'}$.\n\nThe number of positive messages received by the degree-$q$ node (from its $q-1$ neighbors) follows a binomial distribution, as incoming messages are independent on a tree-like structure. The self-consistency equation for $y_q$ is thus:\n$$y_q = \\sum_{m=k}^{q-1} \\binom{q-1}{m} (Y_q)^m (1-Y_q)^{q-1-m}$$\nFor our problem, $k=3$ and the possible degrees are $q \\in \\{2, 4\\}$.\n\nFor a node of degree $q=2$, it has $q-1=1$ neighbor in the cavity graph. It is impossible for it to receive at least $k=3$ positive messages. Thus, the sum is empty, and\n$$y_2 = 0$$\nThis holds for both ensembles.\n\nFor a node of degree $q=4$, it has $q-1=3$ neighbors in the cavity graph. It must receive at least $3$ positive messages from these $3$ neighbors. This is only possible if all $3$ neighbors send positive messages.\n$$y_4 = \\binom{3}{3} (Y_4)^3 (1-Y_4)^{3-3} = (Y_4)^3$$\nwhere $Y_4 = P(2|4)y_2 + P(4|4)y_4$.\n\nOnce the values for $y_q$ are determined, we can calculate $t_q$, the probability that a randomly chosen node of degree $q$ is in the $3$-core. This node is in the full graph, with $q$ neighbors. It belongs to the $3$-core if it receives at least $3$ positive messages from its $q$ neighbors. The probability that a neighbor sends a positive message is again $Y_q$.\n$$t_q = \\sum_{m=k}^{q} \\binom{q}{m} (Y_q)^m (1-Y_q)^{q-m}$$\nFor $q=2$, the sum is empty, so $t_2=0$.\nFor $q=4$, $t_4 = \\sum_{m=3}^{4} \\binom{4}{m} (Y_4)^m (1-Y_4)^{4-m} = \\binom{4}{3} (Y_4)^3 (1-Y_4) + \\binom{4}{4} (Y_4)^4$.\n\nThe total fraction of nodes in the $3$-core, $S$, is given by $S = \\sum_q P(q)t_q$.\n\n**Analysis of Ensemble A (Assortative)**\nThe conditional probabilities are $P(2|2)=1$, $P(4|4)=1$, and $P(2|4)=P(4|2)=0$.\nAs established, $y_2=0$.\nFor $y_4$, we first calculate $Y_4$:\n$Y_4 = P(2|4)y_2 + P(4|4)y_4 = (0)(0) + (1)y_4 = y_4$.\nThe self-consistency equation for $y_4$ becomes:\n$$y_4 = (y_4)^3 \\implies y_4(y_4^2 - 1) = 0$$\nThe solutions for $y_4$ in the interval $[0,1]$ are $y_4=0$ (trivial core) and $y_4=1$ (non-trivial core). For a network that can support a $k$-core, we take the non-trivial solution, $y_4=1$. A purely 4-regular graph forms a 3-core, so this choice is physically justified.\n\nSo, for ensemble A, we have $y_2=0$ and $y_4=1$.\nNow we compute the probabilities $t_q$.\n$t_2=0$ as nodes of degree $2$ can never be in the $3$-core.\nFor $t_4$, we have $Y_4 = y_4=1$.\n$$t_4 = \\sum_{m=3}^{4} \\binom{4}{m} (1)^m (1-1)^{4-m} = \\binom{4}{3}(1)^3(0)^1 + \\binom{4}{4}(1)^4(0)^0 = 0 + 1 = 1$$\nSo, $t_2=0$ and $t_4=1$. All degree-$4$ nodes are in the $3$-core, and no degree-$2$ nodes are.\nThe total fraction of nodes in the $3$-core for ensemble A is:\n$$S_{\\mathrm{A}} = P(2)t_2 + P(4)t_4 = \\frac{1}{2}(0) + \\frac{1}{2}(1) = \\frac{1}{2}$$\n\n**Analysis of Ensemble D (Disassortative)**\nThe conditional probabilities are $P(4|2)=1$, $P(2|2)=0$, $P(2|4)=\\frac{1}{2}$, and $P(4|4)=\\frac{1}{2}$.\nAgain, $y_2=0$.\nFor $y_4$, we calculate $Y_4$:\n$Y_4 = P(2|4)y_2 + P(4|4)y_4 = \\left(\\frac{1}{2}\\right)(0) + \\left(\\frac{1}{2}\\right)y_4 = \\frac{1}{2}y_4$.\nThe self-consistency equation for $y_4$ is:\n$$y_4 = \\left(\\frac{1}{2}y_4\\right)^3 = \\frac{1}{8}y_4^3 \\implies y_4\\left(1 - \\frac{y_4^2}{8}\\right) = 0$$\nThe solutions are $y_4=0$ and $y_4^2=8$, which gives $y_4 = \\sqrt{8} = 2\\sqrt{2}$. Since $y_4$ is a probability, it must be in $[0,1]$. $2\\sqrt{2} \\approx 2.828 > 1$, so this solution is unphysical. The only valid solution is $y_4=0$.\n\nFor ensemble D, we have $y_2=0$ and $y_4=0$. This implies that no non-trivial $3$-core exists.\nWe compute the probabilities $t_q$.\n$t_2=0$.\nFor $t_4$, we have $Y_4 = \\frac{1}{2}y_4 = 0$.\n$$t_4 = \\sum_{m=3}^{4} \\binom{4}{m} (0)^m (1-0)^{4-m} = 0$$\nSo, $t_2=0$ and $t_4=0$. No nodes are in the $3$-core.\nThe total fraction of nodes in the $3$-core for ensemble D is:\n$$S_{\\mathrm{D}} = P(2)t_2 + P(4)t_4 = \\frac{1}{2}(0) + \\frac{1}{2}(0) = 0$$\n\n**Final Calculation**\nThe problem asks for the reduction $\\Delta S = S_{\\mathrm{A}} - S_{\\mathrm{D}}$.\n$$\\Delta S = \\frac{1}{2} - 0 = \\frac{1}{2}$$\nThis result highlights the strong impact of degree correlations on network robustness. The assortative network maintains a large $3$-core composed of all its degree-$4$ nodes, while the disassortative network's $3$-core collapses completely.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "A key question in network science is whether observed structural properties are statistically significant or simply artifacts of basic constraints like the degree sequence. This computational practice introduces the powerful method of null model testing to answer that question for k-cores. You will implement a degree-preserving randomization algorithm to generate a null distribution and use it to test if a network's k-core is \"structurally reinforced,\" meaning it is significantly larger than expected by chance .",
            "id": "4284882",
            "problem": "Consider a simple undirected network represented by a graph $G = (V, E)$ with $|V| = n$ nodes and $|E| = m$ edges. The degree sequence is the list of degrees $\\{d_1, d_2, \\dots, d_n\\}$, where $d_i$ is the degree of node $i$. The $k$-core of a graph is the maximal induced subgraph in which every node has degree at least $k$, obtained by recursively pruning nodes with degree strictly less than $k$ until no further pruning is possible. The size of the $k$-core, denoted $|V_k(G)|$, is the number of nodes remaining after this pruning process.\n\nYou are tasked with designing a program that performs empirical inference under a degree-preserving null model to test for structural reinforcement of $k$-cores. The null model must preserve the empirical degree sequence exactly and otherwise randomize the network by repeatedly applying degree-preserving double-edge swaps on simple graphs (no self-loops and no multiple edges). A double-edge swap selects two distinct edges $(a,b)$ and $(c,d)$ with four distinct endpoints $\\{a,b,c,d\\}$ and replaces them by either $(a,c)$ and $(b,d)$ or $(a,d)$ and $(b,c)$, provided that the resulting graph remains simple. The double-edge swap must be repeated a fixed number of successful times to induce sufficient randomization. For each randomized sample, compute the $k$-core size $|V_k(\\cdot)|$.\n\nThe statistical test for structural reinforcement should proceed as follows. Let $X_{\\text{obs}}$ denote the observed $k$-core size of the empirical graph $G$. Generate a null ensemble by performing $R$ independent randomizations, each starting from $G$ and applying $S$ successful double-edge swaps. Let $\\{X_1, X_2, \\dots, X_R\\}$ be the resulting $k$-core sizes from the randomized ensemble. Use these samples to compute a standardized test statistic that compares $X_{\\text{obs}}$ against the null expectation. Use a fixed threshold $z^* = 2$ for decision-making. If the standardized test statistic indicates that the observed $k$-core size is substantially larger than the null expectation (exceeding the threshold), classify the case as structurally reinforced; otherwise, do not classify it as reinforced. In cases where the empirical variance of the null ensemble is zero, define the standardized test statistic to be `0` and do not classify as reinforced.\n\nYour program must implement:\n- A procedure to compute the $k$-core size $|V_k(G)|$ using the recursive pruning definition.\n- A procedure to generate degree-preserving randomized samples of $G$ via double-edge swaps, ensuring the graph remains simple at all times.\n- A procedure to compute the null expectation and the standardized test statistic, and to make the reinforcement decision using the threshold $z^* = 2$.\n\nUse the following test suite. Each test case specifies the graph by the node count $n$, the edge set $E$, the core parameter $k$, the number of randomizations $R$, the number of successful swaps per randomization $S$, and the random seed $s$ for reproducibility. Nodes are labeled by integers from $0$ to $n-1$. All numbers must be treated as integers.\n\nTest case $1$ (dense core with periphery):\n- $n = 12$\n- $E$ consists of all pairs among nodes $\\{0,1,2,3,4,5\\}$ forming a clique, plus two edges from each periphery node $\\{6,7,8,9,10,11\\}$ to the clique:\n  - Clique edges: $\\{(0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)\\}$\n  - Periphery attachments: $(6,0),(6,1),(7,2),(7,3),(8,4),(8,5),(9,0),(9,2),(10,1),(10,4),(11,3),(11,5)$\n- $k = 5$\n- $R = 200$\n- $S = 270$\n- $s = 12345$\n\nTest case $2$ (near-regular random-like graph):\n- $n = 12$\n- $E = \\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,5),(1,6),(2,3),(2,7),(3,4),(3,8),(4,5),(4,9),(5,6),(5,10),(6,7),(6,11),(7,8),(7,9),(8,9),(8,10),(9,10),(10,11),(11,0),(11,3)\\}$\n- $k = 4$\n- $R = 200$\n- $S = 250$\n- $s = 2021$\n\nTest case $3$ (star graph boundary case):\n- $n = 12$\n- $E = \\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(0,10),(0,11)\\}$\n- $k = 5$\n- $R = 100$\n- $S = 100$\n- $s = 7$\n\nYour program must produce, for each test case, a list of the form $[\\mu, X_{\\text{obs}}, Z, \\text{reinforced}]$ where:\n- $\\mu$ is the sample mean of $\\{X_1,\\dots,X_R\\}$ expressed as a floating-point number,\n- $X_{\\text{obs}}$ is the empirical $k$-core size expressed as an integer,\n- $Z$ is the standardized test statistic expressed as a floating-point number,\n- $\\text{reinforced}$ is a boolean indicating whether the standardized test statistic exceeds the threshold $z^* = 2$.\n\nFinal output format: Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each item is itself a list in the order above. For example, the output should look like $[[\\mu_1,X_{\\text{obs},1},Z_1,\\text{reinforced}_1],[\\mu_2,X_{\\text{obs},2},Z_2,\\text{reinforced}_2],[\\mu_3,X_{\\text{obs},3},Z_3,\\text{reinforced}_3]]$. No physical units, angle units, or percentages are involved in this problem, so none should be provided.",
            "solution": "The problem is valid. It presents a well-defined task in the field of network science that is scientifically grounded, objective, and internally consistent.\n\n### Step 1: Extract Givens\n\n- **Graph representation**: A simple undirected graph $G = (V, E)$ with $n = |V|$ nodes and $m = |E|$ edges.\n- **Node labels**: Integers from $0$ to $n-1$.\n- **$k$-core definition**: The maximal induced subgraph where every node has a degree of at least $k$. It is obtained by recursively pruning nodes with a degree strictly less than $k$.\n- **$k$-core size**: $|V_k(G)|$, the number of nodes in the $k$-core.\n- **Task**: To perform empirical inference on the structural reinforcement of $k$-cores using a degree-preserving null model.\n- **Null model**: Generated by randomizing the empirical graph $G$ using a fixed number of successful degree-preserving double-edge swaps. The graph must remain simple (no self-loops, no multiple edges).\n- **Double-edge swap**: Select two distinct edges $(a,b)$ and $(c,d)$ with four distinct endpoints $\\{a,b,c,d\\}$. Replace them with either $(a,c)$ and $(b,d)$ or $(a,d)$ and $(b,c)$, contingent on the resulting graph remaining simple.\n- **Randomization procedure**: For each of $R$ independent randomizations, start with the empirical graph $G$ and apply $S$ successful double-edge swaps.\n- **Statistical test**:\n    - $X_{\\text{obs}}$: The observed $k$-core size of the empirical graph $G$.\n    - $\\{X_1, X_2, \\dots, X_R\\}$: A set of $k$-core sizes from the $R$ randomized graphs.\n    - Sample mean of null ensemble: $\\mu = \\frac{1}{R} \\sum_{i=1}^{R} X_i$.\n    - Sample standard deviation of null ensemble: $\\sigma = \\sqrt{\\frac{1}{R} \\sum_{i=1}^{R} (X_i - \\mu)^2}$.\n    - Standardized test statistic: $Z = \\frac{X_{\\text{obs}} - \\mu}{\\sigma}$.\n    - Special condition: If $\\sigma = 0$, then $Z = 0$.\n- **Decision rule**:\n    - Threshold: $z^{\\ast} = 2$.\n    - Classification: If $Z > z^{\\ast}$, the graph is \"structurally reinforced\". Otherwise, it is not.\n- **Test Cases**: Three test cases are provided, each with parameters for graph structure ($n, E$), core analysis ($k$), randomization ($R, S$), and reproducibility ($s$).\n- **Output format**: For each test case, a list $[\\mu, X_{\\text{obs}}, Z, \\text{reinforced}]$. The final program output is a list of these lists.\n\n### Step 2: Validate Using Extracted Givens\n\n- **Scientifically Grounded**: The concepts of $k$-cores, degree-preserving randomization via double-edge swaps (also known as the configuration model switching algorithm), and null model hypothesis testing are fundamental and standard methodologies in network science and complex systems theory. The entire procedure is scientifically valid.\n- **Well-Posed**: The problem is specified with high precision. All necessary inputs ($n, E, k, R, S, s$), algorithms (pruning for $k$-core, double-edge swaps), and statistical procedures (calculation of $Z$, handling of $\\sigma=0$, decision threshold) are explicitly defined. This ensures that a unique, stable, and meaningful computational result exists for each test case given the random seed.\n- **Objective**: The problem is stated in formal, unbiased language. All criteria for analysis and decision-making are quantitative and unambiguous (e.g., $Z > 2$).\n\nThe problem exhibits none of the invalidity flaws:\n1.  **Scientific/Factual Unsoundness**: No violations of scientific or mathematical principles.\n2.  **Non-Formalizable/Irrelevant**: The problem is a formalizable algorithmic task directly relevant to the topic of $k$-core percolation.\n3.  **Incomplete/Contradictory Setup**: All required data and conditions are provided, and they are consistent.\n4.  **Unrealistic/Infeasible**: The parameters for the test cases ($n=12$, moderate $R, S$) are computationally feasible. The graph structures are valid.\n5.  **Ill-Posed/Poorly Structured**: The problem is well-structured and leads to a deterministic outcome for a given seed.\n6.  **Pseudo-Profound/Trivial**: The task requires the implementation and integration of several non-trivial algorithms, making it a substantive problem. The test cases are well-chosen to probe different aspects of the implementation, including boundary conditions (star graph).\n7.  **Outside Scientific Verifiability**: The results are computationally reproducible and verifiable given the specified random seeds.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A solution will be developed and implemented as per the requirements.\n\n### Algorithmic Design and Principles\n\nThe solution is structured as a series of procedures that correspond to the main components of the problem statement.\n\n1.  **`k_core_size(adj, k)`**: This function calculates the size of the $k$-core of a graph represented by an adjacency list `adj` for a given integer $k$. It implements the specified recursive pruning algorithm.\n    - **Principle**: The $k$-core is found by iteratively removing nodes of degree less than $k$. This process must continue until no such nodes remain, as the removal of one node can reduce the degree of its neighbors, potentially causing them to be pruned in a subsequent step.\n    - **Implementation**: We first calculate the initial degrees of all nodes. A queue is initialized with all nodes that have a degree less than $k$. We then process this queue, removing one node at a time. For each removed node, we iterate through its neighbors, decrementing their degrees. If a neighbor's degree drops below $k$, it is added to the queue to be pruned later. We keep track of removed nodes to avoid redundant processing and to calculate the final core size, which is $n$ minus the total count of unique removed nodes.\n\n2.  **`perform_randomization(adj, num_swaps, rng)`**: This function takes a graph, a target number of successful swaps $S$, and a random number generator. It returns a new graph with the same degree sequence.\n    - **Principle**: The double-edge swap is a fundamental operation for generating random graphs with a fixed degree sequence. It locally rewires the network while preserving the degree of every node involved. Repeated application sufficiently randomizes the network structure, breaking down correlations not attributable to the degree sequence itself.\n    - **Implementation**: A copy of the input graph's adjacency list is made. A list of all unique edges is created. The main loop runs until $S$ successful swaps have been performed. In each attempt, two distinct edges, $(a,b)$ and $(c,d)$, are chosen randomly. We verify that the four endpoints are distinct. We then check the validity of the two possible new edge pairs, $(a,c)$ and $(b,d)$, or $(a,d)$ and $(b,c)$. A new pair is valid if it does not introduce multiple edges (i.e., the new edges do not already exist). If at least one valid rewiring exists, one is chosen, the adjacency list and edge list are updated, and the successful swap counter is incremented. A limit on the total number of attempts is included to prevent infinite loops for graphs where no swaps are possible (e.g., a star graph).\n\n3.  **`solve()`**: This is the main driver function that orchestrates the entire analysis for all test cases.\n    - **Principle**: The core of the task is a statistical comparison between an observed metric ($X_{\\text{obs}}$) and a null distribution of that metric generated from an ensemble of randomized graphs. The Z-score quantifies how many standard deviations the observation is from the null model's mean, providing a standardized measure of structural surprise.\n    - **Implementation**: The function iterates through each test case. For each case, it initializes a random number generator with the given seed for reproducibility. It constructs the graph and calculates the observed $k$-core size, $X_{\\text{obs}}$. Then, it enters a loop to generate $R$ randomized graphs. For each iteration, it calls `perform_randomization` on a fresh copy of the original graph and calculates the $k$-core size of the resulting random graph, adding it to a list of null values. After generating the null ensemble, it computes the mean $\\mu$ and standard deviation $\\sigma$. The $Z$-score is calculated as $(X_{\\text{obs}} - \\mu) / \\sigma$, with a specific check to set $Z=0$ if $\\sigma=0$. Finally, the reinforcement decision is made based on whether $Z > 2$. The results $[\\mu, X_{\\text{obs}}, Z, \\text{reinforced}]$ are collected and formatted into the required final output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef k_core_size(adj, k):\n    \"\"\"\n    Computes the size of the k-core of a graph using recursive pruning.\n    \n    Args:\n        adj (list of set): The adjacency list of the graph.\n        k (int): The core parameter.\n        \n    Returns:\n        int: The number of nodes in the k-core.\n    \"\"\"\n    n = len(adj)\n    degrees = np.array([len(neighbors) for neighbors in adj])\n    \n    # Queue for nodes to be pruned\n    prune_queue = [i for i, d in enumerate(degrees) if d < k]\n    head = 0\n    \n    is_pruned = np.zeros(n, dtype=bool)\n    num_pruned = 0\n    \n    while head < len(prune_queue):\n        u = prune_queue[head]\n        head += 1\n        \n        if is_pruned[u]:\n            continue\n            \n        is_pruned[u] = True\n        num_pruned += 1\n        \n        for v in adj[u]:\n            if not is_pruned[v]:\n                degrees[v] -= 1\n                if degrees[v] < k:\n                    prune_queue.append(v)\n                    \n    return n - num_pruned\n\ndef perform_randomization(adj, num_swaps, rng):\n    \"\"\"\n    Generates a degree-preserving randomized graph via double-edge swaps.\n    \n    Args:\n        adj (list of set): The adjacency list of the original graph.\n        num_swaps (int): The number of successful swaps to perform.\n        rng (np.random.Generator): The random number generator.\n        \n    Returns:\n        list of set: The adjacency list of the randomized graph.\n    \"\"\"\n    n = len(adj)\n    rand_adj = [s.copy() for s in adj]\n    \n    edges = []\n    for u in range(n):\n        for v in rand_adj[u]:\n            if u < v:\n                edges.append((u, v))\n                \n    num_edges = len(edges)\n    if num_edges < 2:\n        return rand_adj\n\n    successful_swaps = 0\n    # Add a safety break for non-randomizable graphs\n    max_attempts = 100 * num_swaps if num_swaps > 0 else 1\n    attempts = 0\n\n    while successful_swaps < num_swaps and attempts < max_attempts:\n        attempts += 1\n        \n        if num_edges < 2:\n            break\n\n        idx1, idx2 = rng.choice(num_edges, 2, replace=False)\n        e1, e2 = edges[idx1], edges[idx2]\n        a, b = e1\n        c, d = e2\n        \n        if len({a, b, c, d}) != 4:\n            continue\n            \n        # Rewiring option 1: (a,d) and (b,c)\n        valid1 = (d not in rand_adj[a]) and (c not in rand_adj[b])\n        # Rewiring option 2: (a,c) and (b,d)\n        valid2 = (c not in rand_adj[a]) and (d not in rand_adj[b])\n        \n        chosen_rewiring = None\n        if valid1 and valid2:\n            chosen_rewiring = 1 if rng.random() < 0.5 else 2\n        elif valid1:\n            chosen_rewiring = 1\n        elif valid2:\n            chosen_rewiring = 2\n        \n        if chosen_rewiring:\n            # Remove old edges\n            rand_adj[a].remove(b); rand_adj[b].remove(a)\n            rand_adj[c].remove(d); rand_adj[d].remove(c)\n            \n            if chosen_rewiring == 1: # (a,d) and (b,c)\n                rand_adj[a].add(d); rand_adj[d].add(a)\n                rand_adj[b].add(c); rand_adj[c].add(b)\n                edges[idx1] = tuple(sorted((a,d)))\n                edges[idx2] = tuple(sorted((b,c)))\n            else: # chosen_rewiring == 2, (a,c) and (b,d)\n                rand_adj[a].add(c); rand_adj[c].add(a)\n                rand_adj[b].add(d); rand_adj[d].add(b)\n                edges[idx1] = tuple(sorted((a,c)))\n                edges[idx2] = tuple(sorted((b,d)))\n\n            successful_swaps += 1\n            \n    return rand_adj\n\ndef solve():\n    test_cases = [\n        {\n            \"n\": 12,\n            \"E\": [\n                (0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(1,3),(1,4),(1,5),\n                (2,3),(2,4),(2,5),(3,4),(3,5),(4,5),\n                (6,0),(6,1),(7,2),(7,3),(8,4),(8,5),(9,0),(9,2),\n                (10,1),(10,4),(11,3),(11,5)\n            ],\n            \"k\": 5, \"R\": 200, \"S\": 270, \"s\": 12345\n        },\n        {\n            \"n\": 12,\n            \"E\": [\n                (0,1),(0,2),(0,3),(0,4),(1,2),(1,5),(1,6),(2,3),(2,7),\n                (3,4),(3,8),(4,5),(4,9),(5,6),(5,10),(6,7),(6,11),\n                (7,8),(7,9),(8,9),(8,10),(9,10),(10,11),(11,0),(11,3)\n            ],\n            \"k\": 4, \"R\": 200, \"S\": 250, \"s\": 2021\n        },\n        {\n            \"n\": 12,\n            \"E\": [(0,i) for i in range(1, 12)],\n            \"k\": 5, \"R\": 100, \"S\": 100, \"s\": 7\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n, E, k, R, S, s = case[\"n\"], case[\"E\"], case[\"k\"], case[\"R\"], case[\"S\"], case[\"s\"]\n        \n        rng = np.random.default_rng(s)\n        \n        adj_obs = [set() for _ in range(n)]\n        for u, v in E:\n            adj_obs[u].add(v)\n            adj_obs[v].add(u)\n            \n        X_obs = k_core_size(adj_obs, k)\n        \n        null_core_sizes = []\n        for _ in range(R):\n            adj_random = perform_randomization(adj_obs, S, rng)\n            X_rand = k_core_size(adj_random, k)\n            null_core_sizes.append(X_rand)\n\n        null_dist = np.array(null_core_sizes, dtype=float)\n        mu = np.mean(null_dist)\n        sigma = np.std(null_dist)\n        \n        if sigma == 0.0:\n            Z = 0.0\n        else:\n            Z = (X_obs - mu) / sigma\n            \n        z_star = 2.0\n        reinforced = Z > z_star\n        \n        all_results.append([float(mu), int(X_obs), float(Z), bool(reinforced)])\n\n    # Format the final output string precisely\n    result_strings = []\n    for res in all_results:\n        # Convert boolean to lowercase as per common data exchange formats\n        bool_str = str(res[3]).lower()\n        res_str = f\"[{res[0]},{res[1]},{res[2]},{bool_str}]\"\n        result_strings.append(res_str)\n        \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        }
    ]
}