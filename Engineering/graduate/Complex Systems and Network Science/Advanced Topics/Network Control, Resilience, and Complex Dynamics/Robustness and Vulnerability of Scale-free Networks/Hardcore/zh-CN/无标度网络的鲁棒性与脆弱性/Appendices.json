{
    "hands_on_practices": [
        {
            "introduction": "本练习是理解无标度网络特性的基础。通过从幂律分布的定义出发，我们将推导并计算网络中最大度节点的度量级，以及高度数节点的比例 。这个分析练习旨在帮助你将抽象的数学模型与网络“枢纽”（hubs）存在的具体、可量化的后果联系起来，从而加深对无标度网络异质性的理解。",
            "id": "4301052",
            "problem": "考虑一个简单的无向无标度网络，其中节点度被建模为从支持域为 $[k_{\\min}, \\infty)$、指数为 $\\gamma$ 的连续幂律分布中抽取的独立同分布（IID）样本，其概率密度为 $p(k)$，且该分布是适当归一化的。假设 $\\gamma2$ 且网络规模 $N$ 足够大，以至于极值估计有意义。仅使用以下基本要素：\n- 无标度度分布的定义：其尾部遵循幂律 $k^{-\\gamma}$。\n- 归一化要求 $\\int_{k_{\\min}}^{\\infty} p(k)\\,dk = 1$。\n- 生存（尾）函数 $S(k) = \\int_{k}^{\\infty} p(x)\\,dx$，它给出了度不小于 $k$ 的节点的比例。\n- 独立同分布样本的基本序次统计学推理：在一个大小为 $N$ 的样本中，典型的最大值渐近地是生存概率为 $1/N$ 阶的分位数。\n\n从这些原则出发，推导：\n1. 最大度 $k_{\\max}$ 作为 $N$、$\\gamma$ 和 $k_{\\min}$ 函数的渐近标度表达式。\n2. 度不小于阈值 $K$ 的节点比例的表达式，用 $\\gamma$ 和 $k_{\\min}$ 表示。\n\n然后，对于 $N = 10^{5}$、$\\gamma = 2.5$、$k_{\\min} = 1$ 和 $K = 100$ 进行求值。将您的数值答案四舍五入到四位有效数字。将两个结果都表示为无量纲量。",
            "solution": "该问题陈述经证实具有科学依据、提法恰当、客观且完整。它描述了复杂网络研究中的一个典型问题，基于统计力学和概率论的既定原理。其中一些假设，例如用连续概率分布对离散的节点度进行建模，是适用于大网络规模（$N$）和所要求的渐近分析的标准理论近似。因此，我们可以进行完整的解答。\n\n该问题要求我们推导与无标度网络相关的两个量。问题陈述节点度被建模为从支持域为 $[k_{\\min}, \\infty)$、指数为 $\\gamma$ 的连续幂律概率密度函数（PDF）$p(k)$ 中抽取的独立同分布（IID）随机变量。\n\n首先，我们必须确定归一化概率密度函数 $p(k)$ 的显式形式。问题指明了幂律形式，我们可以写成 $p(k) = Ck^{-\\gamma}$ 对于 $k \\ge k_{\\min}$，其中 $C$ 是归一化常数。$C$ 的值通过强制执行归一化条件 $\\int_{k_{\\min}}^{\\infty} p(k) \\, dk = 1$ 来找到。\n\n$$ \\int_{k_{\\min}}^{\\infty} C k^{-\\gamma} \\, dk = 1 $$\n$$ C \\left[ \\frac{k^{1-\\gamma}}{1-\\gamma} \\right]_{k_{\\min}}^{\\infty} = 1 $$\n鉴于问题指定 $\\gamma > 2$，指数 $1-\\gamma$ 小于 $-1$，这保证了当 $k \\to \\infty$ 时，$k^{1-\\gamma}$ 项收敛于 $0$。因此，积分的计算结果为：\n$$ C \\left( 0 - \\frac{k_{\\min}^{1-\\gamma}}{1-\\gamma} \\right) = C \\frac{k_{\\min}^{1-\\gamma}}{\\gamma-1} = 1 $$\n求解常数 $C$，我们得到：\n$$ C = (\\gamma-1)k_{\\min}^{\\gamma-1} $$\n因此，适当归一化的概率密度函数为：\n$$ p(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} k^{-\\gamma} \\quad \\text{for } k \\ge k_{\\min} $$\n\n接下来，我们处理第二个任务：推导度不小于阈值 $K$ 的节点比例的表达式。这个比例由生存函数 $S(k)$ 给出，该函数也称为互补累积分布函数（CCDF）。生存函数定义为 $S(k) = \\int_{k}^{\\infty} p(x) \\, dx$。我们对任意阈值 $k$ 计算此积分，之后可以将其设为 $K$。\n\n$$ S(k) = \\int_{k}^{\\infty} (\\gamma-1)k_{\\min}^{\\gamma-1} x^{-\\gamma} \\, dx $$\n$$ S(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left[ \\frac{x^{1-\\gamma}}{1-\\gamma} \\right]_{k}^{\\infty} $$\n再次利用条件 $\\gamma > 2$，积分上限处的项消失。\n$$ S(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left( 0 - \\frac{k^{1-\\gamma}}{1-\\gamma} \\right) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left( \\frac{k^{1-\\gamma}}{\\gamma-1} \\right) $$\n$$ S(k) = k_{\\min}^{\\gamma-1} k^{1-\\gamma} = \\left(\\frac{k}{k_{\\min}}\\right)^{1-\\gamma} $$\n$S(k)$ 的这个表达式表示度不小于 $k$ 的节点的比例。对于特定阈值 $K$，该比例为 $S(K) = \\left(\\frac{K}{k_{\\min}}\\right)^{1-\\gamma}$。这就完成了问题第二部分的符号推导。\n\n现在我们处理第一个任务：推导最大度 $k_{\\max}$ 的渐近标度表达式。问题指导我们使用序次统计学推理。对于一个规模为 $N$ 的大网络，典型的最大度 $k_{\\max}$ 是我们期望找到大约一个度等于或大于 $k_{\\max}$ 的节点的值。度不小于 $k_{\\max}$ 的节点的期望数量是总节点数 $N$ 乘以单个节点具有这样度的概率 $S(k_{\\max})$。将此期望值设为 $1$ 提供了控制条件：\n\n$$ N \\cdot S(k_{\\max}) \\approx 1 \\implies S(k_{\\max}) \\approx \\frac{1}{N} $$\n代入我们推导出的生存函数表达式：\n$$ \\left(\\frac{k_{\\max}}{k_{\\min}}\\right)^{1-\\gamma} \\approx \\frac{1}{N} $$\n现在我们求解这个方程以得到 $k_{\\max}$：\n$$ \\frac{k_{\\max}}{k_{\\min}} \\approx \\left(\\frac{1}{N}\\right)^{\\frac{1}{1-\\gamma}} = N^{-\\frac{1}{1-\\gamma}} = N^{\\frac{1}{\\gamma-1}} $$\n$$ k_{\\max} \\approx k_{\\min} N^{\\frac{1}{\\gamma-1}} $$\n这就是所要求的最大度 $k_{\\max}$ 作为 $N$、$\\gamma$ 和 $k_{\\min}$ 函数的渐近标度表达式。这就完成了问题第一部分的符号推导。\n\n最后，我们使用给定值进行数值计算：$N = 10^5$，$\\gamma = 2.5$，$k_{\\min} = 1$ 以及 $K = 100$。\n\n对于最大度 $k_{\\max}$：\n$$ k_{\\max} \\approx k_{\\min} N^{\\frac{1}{\\gamma-1}} = (1) \\left(10^5\\right)^{\\frac{1}{2.5-1}} = \\left(10^5\\right)^{\\frac{1}{1.5}} = \\left(10^5\\right)^{2/3} = 10^{5 \\times \\frac{2}{3}} = 10^{10/3} $$\n$$ k_{\\max} \\approx 2154.43469\\dots $$\n将此结果四舍五入到四位有效数字，得到 $k_{\\max} \\approx 2154$。\n\n对于度不小于 $K = 100$ 的节点比例，我们计算 $S(100)$：\n$$ S(100) = \\left(\\frac{100}{k_{\\min}}\\right)^{1-\\gamma} = \\left(\\frac{100}{1}\\right)^{1-2.5} = 100^{-1.5} = (10^2)^{-1.5} = 10^{-3} $$\n$$ S(100) = 0.001 $$\n这个结果是精确的。为了按要求用四位有效数字表示，我们将其写成科学记数法形式 $1.000 \\times 10^{-3}$。\n\n根据问题陈述的要求，两个结果都是无量纲量。度 $k_{\\max}$ 是一个计数，而 $S(K)$ 是一个比例。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2154  1.000 \\times 10^{-3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在掌握了无标度网络的静态结构特征之后，下一步自然是探究其在压力下的动态行为。本练习通过一个计算模拟，研究当网络中的枢纽节点被移除后，负载如何在剩余节点中重新分配，并引发连锁过载失效 。这项实践将理论与真实世界的现象（如电网崩溃或金融危机）联系起来，直观地揭示了无标度网络“鲁棒但脆弱”原则中的“脆弱”一面。",
            "id": "4301020",
            "problem": "考虑一个有限无向简单图，它代表一个无标度网络，其度分布遵循幂律 $P(k) \\propto k^{-\\gamma}$，指数 $\\gamma = 2.4$。无标度网络是一种其节点度 $k$（即与一个节点相关联的连接数）在 $[k_{\\min}, k_{\\max}]$ 范围内遵循幂律分布的网络。可以通过移除一小部分度最高的节点（中心节点），并观察在负载-容量模型下产生的过载级联，来研究此类网络在蓄意攻击下的鲁棒性。目标是确定级联规模如何依赖于一个容忍参数，并找出能使网络稳定的临界容忍度。\n\n使用以下基础设定：\n- 度分布满足 $P(k) \\propto k^{-\\gamma}$，其中 $\\gamma = 2.4$，并在 $k_{\\min}$ 和 $k_{\\max}$ 处被截断。\n- 节点 $i$ 上的负载 $L_i$ 由其在无向、无权网络中基于最短路径的介数中心性给出，定义为 $L_i = \\sum_{s \\neq i \\neq t} \\frac{\\sigma_{st}(i)}{\\sigma_{st}}$，其中 $\\sigma_{st}$ 是节点 $s$ 和 $t$ 之间的最短路径数量，而 $\\sigma_{st}(i)$ 是这些最短路径中经过节点 $i$ 的数量。\n- 节点 $i$ 的容量 $C_i$ 满足 $C_i = (1 + \\alpha)L_i$，其中 $\\alpha \\geq 0$ 是一个全局容忍参数。\n- 通过移除度最高的一小部分节点（比例为 $f$，即蓄意攻击）来引发过载级联。移除后，在剩余网络上重新计算负载；任何新负载 $L_i^{\\text{new}}$ 超过其容量 $C_i$ 的节点 $i$ 都会发生故障并被移除。此过程重复进行，直到没有新的故障发生。\n- 级联规模定义为除初始移除的节点外，因级联而失效的节点所占的比例（以小数表示）。\n\n你的任务：\n1. 使用配置模型，从一个指数为 $\\gamma = 2.4$、最小度为 $k_{\\min}$、最大度为 $k_{\\max}$、节点数为 $N$ 的截断幂律度序列中生成一个随机的无标度网络。在连续截断分布上使用逆变换采样法生成度序列，然后四舍五入为整数，并通过均匀随机配对“末端”来构建图。移除自环并合并多重边，使最终的图是简单图。所有随机性必须由给定的种子控制。\n2. 使用无向、无权图中最短路径的介数中心性计算所有节点的初始负载 $L_i$。为提高效率，使用基于广度优先搜索 (BFS) 的 Brandes 算法。\n3. 对于移除比例 $f = 0.01$（即度最高的 $1\\%$ 节点），移除度最高的 $r = \\max(1, \\lfloor fN \\rfloor)$ 个节点。对一系列容忍参数 $\\alpha \\in \\{0.0, 0.1, 0.2, \\dots, 1.0\\}$ 模拟过载级联，过程如下：\n   - 使用移除前的负载 $L_i$ 固定容量 $C_i = (1+\\alpha)L_i$。\n   - 移除中心节点后，在剩余网络上重新计算负载。任何负载 $L_i^{\\text{new}} > C_i$ 的节点 $i$ 将会失效并被移除。重复此过程，直到没有新的故障发生。\n   - 记录级联规模，即除初始移除节点外失效的节点所占的比例（以小数形式表示）。\n4. 将稳定的临界容忍度 $\\alpha_c$ 定义为测试集合中使得级联规模小于或等于给定小数阈值 $\\theta$（例如，$\\theta = 0.01$ 意味着最多有 $1\\%$ 的额外故障）的最小 $\\alpha$。如果没有测试的 $\\alpha$ 满足稳定性条件，则返回 $-1.0$。\n\n测试套件：\n对于每个测试用例，仅报告计算出的 $\\alpha_c$（作为浮点数）。使用以下参数集：\n- 测试用例 1 (正常情况): $N=200$, $k_{\\min}=2$, $k_{\\max}=25$, seed $=42$, threshold $\\theta=0.02$。\n- 测试用例 2 (边界条件: 严格稳定): $N=80$, $k_{\\min}=2$, $k_{\\max}=15$, seed $=123$, threshold $\\theta=0.00$。\n- 测试用例 3 (边缘情况: 更高异质性): $N=150$, $k_{\\min}=3$, $k_{\\max}=30$, seed $=7$, threshold $\\theta=0.01$。\n\n最终输出规范：\n你的程序应生成单行输出，其中包含三个结果，格式为方括号内的逗号分隔列表，顺序为 $[\\alpha_c^{(1)}, \\alpha_c^{(2)}, \\alpha_c^{(3)}]$，每个 $\\alpha_c^{(j)}$ 是一个四舍五入到三位小数的浮点数。不应打印任何额外文本。",
            "solution": "其基础是无标度度分布和负载-容量级联模型。一个无标度网络的度分布为 $P(k) \\propto k^{-\\gamma}$，其中 $\\gamma = 2.4$，截断在 $k \\in [k_{\\min}, k_{\\max}]$ 范围内。为了生成度序列，我们使用了对连续截断幂律的逆变换采样法。对于 $\\gamma \\neq 1$，在 $[k_{\\min}, k_{\\max}]$ 上的截断连续幂律的累积分布函数为\n$$\nF(k) = \\frac{k^{1-\\gamma} - k_{\\min}^{1-\\gamma}}{k_{\\max}^{1-\\gamma} - k_{\\min}^{1-\\gamma}}.\n$$\n如果 $u \\sim \\text{Uniform}(0, 1)$，对 $F$ 求逆可得\n$$\nk(u) = \\left(u \\left(k_{\\max}^{1-\\gamma} - k_{\\min}^{1-\\gamma}\\right) + k_{\\min}^{1-\\gamma} \\right)^{\\frac{1}{1-\\gamma}}.\n$$\n我们抽取 $N$ 个样本 $k(u)$，将它们四舍五入为整数，强制 $k \\geq k_{\\min}$ 且 $k \\leq k_{\\max}$，并调整总和的奇偶性以确保度之和为偶数。配置模型通过均匀随机地配对度的“末端”来构建一个随机多重图。为了获得一个适用于最短路径计算的简单图，我们移除自环并合并平行边，最终得到一个用邻接表存储唯一邻居的无向简单图。\n\n负载由无向无权图中的介数中心性定义，它衡量了所有最短路径中经过一个节点的路径所占的比例。Brandes 算法可以高效地计算介数中心性。对于每个源节点 $s$，执行一次广度优先搜索 (BFS) 以获得从 $s$到所有 $v$ 的距离 $d_s(v)$ 和最短路径计数 $\\sigma_s(v)$。维护前驱列表以了解在从 $s$ 出发的最短路径上哪些节点位于 $w$ 之前。然后使用公式\n$$\n\\delta_s(v) = \\sum_{w: v \\in \\text{pred}_s(w)} \\frac{\\sigma_s(v)}{\\sigma_s(w)} \\left(1 + \\delta_s(w)\\right),\n$$\n反向累加依赖性 $\\delta_s(v)$，并更新介数\n$$\nL(v) \\mathrel{+}= \\delta_s(v)\n$$\n（对于 $v \\neq s$）。对于无向图，最后将累加值除以 $2$ 以避免重复计数，从而得到作为负载的 $L(v)$（介数中心性）。\n\n容量模型为 $C_i = (1+\\alpha)L_i$，其中 $L_i$ 是为移除前的图计算的。这种固定容量反映了与初始负载成正比的设计容忍度。为了探查在蓄意攻击下的脆弱性，我们移除度最高的一部分节点，比例为 $f = 0.01$，即 $r = \\max(1, \\lfloor fN \\rfloor)$ 个中心节点。移除后，在剩余图上重新计算负载。任何当前负载 $L_i^{\\text{new}}$ 超过其容量 $C_i$ 的节点 $i$ 都会发生故障并被移除。这个过程是迭代的：在每个移除步骤之后，重新计算负载并应用故障准则，直到没有新的节点发生故障。\n\n级联规模是除初始移除的节点外，因过载而失效的节点所占的比例（一个小数）：如果 $F_{\\text{extra}}$ 是由过载引发的故障计数，则级联规模为 $F_{\\text{extra}}/N$。为了将级联规模映射为 $\\alpha$ 的函数，我们在一个预定义的网格 $\\{0.0, 0.1, \\dots, 1.0\\}$ 上评估 $\\alpha$，为每个 $\\alpha$ 模拟级联并记录级联规模。临界容忍度 $\\alpha_c$ 被定义为此网格上使得级联规模小于或等于每个测试用例指定的阈值 $\\theta$ 的最小 $\\alpha$。如果没有 $\\alpha$ 满足该标准，则将 $\\alpha_c$ 设置为 $-1.0$，以表示在测试范围内未达到稳定性。\n\n算法设计：\n- 度序列：使用逆变换采样以获得与 $\\gamma = 2.4$ 一致的重尾分布，并截断到 $[k_{\\min}, k_{\\max}]$。调整度的总和为偶数。这为配置模型生成了“末端”。\n- 图的构建：随机配对“末端”。丢弃自环并合并多重边以强制实现简单图。将邻接表构建为集合以移除重复项，然后转换为列表以便迭代。\n- 负载计算：使用广度优先搜索 (BFS) 实现 Brandes 算法，并使用一个队列。对于每个活动的源节点 $s$，维护用于存储距离 $d$、最短路径计数 $\\sigma$、前驱列表、一个用于跟踪遍历顺序的栈以及依赖项 $\\delta$ 的数组。在每个源的累加结束后更新介数，并对于无向图将其除以 $2$。\n- 级联模拟：对于网格上的每个 $\\alpha$，根据初始负载计算一次容量。按度移除前 $r$ 个中心节点。在活动的子图上迭代地重新计算负载，并移除负载超过容量的节点，直到收敛。记录级联规模 $F_{\\text{extra}}/N$。\n- 临界容忍度：扫描记录的级联规模，并选择其级联规模 $\\leq \\theta$ 的最小 $\\alpha$。如果没有可接受的值，则输出 $-1.0$。\n- 测试套件覆盖：选择三个案例以探查典型行为（中等网络规模）、严格稳定性要求（仅接受零级联的边界情况）和更高异质性（具有较大 $k_{\\max}$ 的边缘情况）。所有结果都以浮点数形式报告，四舍五入到三位小数，并放在一个列表中。\n\n该方法从无标度网络和介数中心性的核心定义中逻辑推导而来，将经过充分测试的 Brandes 最短路径算法与基于容量的过载规则相结合，并为蓄意移除中心节点下的鲁棒性分析生成可量化的输出。\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef sample_truncated_power_law(N, gamma, k_min, k_max, rng):\n    \"\"\"\n    Sample N degrees from a truncated continuous power-law distribution\n    with exponent gamma over [k_min, k_max], then round to integers and clamp.\n    Ensure the sum of degrees is even.\n    \"\"\"\n    # Inverse CDF sampling for continuous truncated power law\n    # F(k) = (k^(1-gamma) - k_min^(1-gamma)) / (k_max^(1-gamma) - k_min^(1-gamma))\n    # Inversion: k = [u*(k_max^(1-gamma)-k_min^(1-gamma)) + k_min^(1-gamma)]^(1/(1-gamma))\n    a = k_min ** (1.0 - gamma)\n    b = k_max ** (1.0 - gamma)\n    u = rng.random(N)\n    ks = (u * (b - a) + a) ** (1.0 / (1.0 - gamma))\n    # Round and clamp\n    degs = np.clip(np.rint(ks).astype(int), k_min, k_max)\n    # Ensure sum of degrees is even\n    total = degs.sum()\n    if total % 2 != 0:\n        # Adjust one random element within bounds to fix parity\n        idxs = np.where((degs  k_min) | (degs  k_max))[0]\n        if idxs.size == 0:\n            # If all at bounds, flip one element between k_min and k_max\n            # to fix parity; choose a random index and toggle by +1 if possible, else -1\n            i = rng.integers(0, N)\n            if degs[i]  k_max:\n                degs[i] += 1\n            else:\n                degs[i] -= 1\n        else:\n            i = rng.choice(idxs)\n            # Toggle parity by adding 1 (stay within bounds)\n            degs[i] += 1\n    return degs.tolist()\n\ndef configuration_model_simple_graph(degrees, rng):\n    \"\"\"\n    Build a graph from the degree sequence via the configuration model,\n    then remove self-loops and collapse multi-edges to create a simple undirected graph.\n    Returns adjacency lists (list of lists).\n    \"\"\"\n    N = len(degrees)\n    stubs = []\n    for i, k in enumerate(degrees):\n        stubs.extend([i] * k)\n    rng.shuffle(stubs)\n\n    # Pair stubs\n    edges = []\n    # If odd number of stubs, drop the last one\n    pair_count = len(stubs) // 2\n    for p in range(pair_count):\n        u = stubs[2 * p]\n        v = stubs[2 * p + 1]\n        if u != v:\n            edges.append((u, v))\n        # self-loops are ignored here\n\n    # Build adjacency sets to collapse multi-edges\n    adj_sets = [set() for _ in range(N)]\n    for u, v in edges:\n        if u == v:\n            continue\n        adj_sets[u].add(v)\n        adj_sets[v].add(u)\n\n    # Convert to lists\n    adj = [list(neigh) for neigh in adj_sets]\n    return adj\n\ndef betweenness_centrality_undirected(adj, active_mask):\n    \"\"\"\n    Compute betweenness centrality for an undirected, unweighted graph\n    using Brandes algorithm. Nodes not active (active_mask[i] == False)\n    are considered removed; paths cannot go through them or start from them.\n    \"\"\"\n    N = len(adj)\n    BC = [0.0] * N\n    for s in range(N):\n        if not active_mask[s]:\n            continue\n        # Initialization\n        stack = []\n        pred = [[] for _ in range(N)]\n        sigma = [0] * N  # number of shortest paths from s\n        dist = [-1] * N  # distance from s\n        sigma[s] = 1\n        dist[s] = 0\n        Q = deque([s])\n        # BFS\n        while Q:\n            v = Q.popleft()\n            stack.append(v)\n            for w in adj[v]:\n                if not active_mask[w]:\n                    continue\n                if dist[w]  0:\n                    dist[w] = dist[v] + 1\n                    Q.append(w)\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    pred[w].append(v)\n        # Accumulation\n        delta = [0.0] * N\n        while stack:\n            w = stack.pop()\n            # Avoid division by zero if sigma[w] == 0 (disconnected)\n            sw = sigma[w]\n            if sw  0:\n                coef = 1.0 + delta[w]\n                for v in pred[w]:\n                    delta[v] += (sigma[v] / sw) * coef\n            if w != s:\n                BC[w] += delta[w]\n    # For undirected graphs, divide by 2 to correct double-counting\n    for i in range(N):\n        BC[i] *= 0.5\n    return BC\n\ndef degrees_from_adj(adj):\n    return [len(neigh) for neigh in adj]\n\ndef simulate_cascade(adj, initial_loads, alpha, removal_fraction=0.01):\n    \"\"\"\n    Simulate the overload cascade after removing the top hubs by degree.\n    initial_loads: betweenness centrality on the full pre-removal graph.\n    alpha: tolerance parameter; capacity C_i = (1 + alpha) * initial_loads[i].\n    removal_fraction: fraction of top-degree nodes to remove initially.\n    Returns cascade size (fraction of extra failures beyond initial removal).\n    \"\"\"\n    N = len(adj)\n    capacities = [ (1.0 + alpha) * L for L in initial_loads ]\n    degs = degrees_from_adj(adj)\n    r = max(1, int(np.floor(removal_fraction * N)))\n    # Get indices sorted by degree descending\n    hub_order = sorted(range(N), key=lambda i: degs[i], reverse=True)\n    initial_fail = set(hub_order[:r])\n\n    active = [True] * N\n    for i in initial_fail:\n        active[i] = False\n\n    extra_failed_count = 0\n\n    while True:\n        # Compute loads on the current active subgraph\n        loads_new = betweenness_centrality_undirected(adj, active)\n        # Identify overloads\n        to_fail = []\n        for i in range(N):\n            if not active[i]:\n                continue\n            if loads_new[i]  capacities[i] + 1e-12:\n                to_fail.append(i)\n        if not to_fail:\n            break\n        for i in to_fail:\n            active[i] = False\n        extra_failed_count += len(to_fail)\n\n    cascade_fraction = extra_failed_count / N\n    return cascade_fraction\n\ndef compute_alpha_c(adj, alpha_values, threshold, removal_fraction=0.01):\n    \"\"\"\n    Compute initial loads and evaluate cascade across alpha_values.\n    Return the smallest alpha whose cascade size = threshold.\n    If none, return -1.0.\n    \"\"\"\n    N = len(adj)\n    active_full = [True] * N\n    initial_loads = betweenness_centrality_undirected(adj, active_full)\n\n    alpha_c = None\n    for alpha in alpha_values:\n        size = simulate_cascade(adj, initial_loads, alpha, removal_fraction=removal_fraction)\n        if size = threshold:\n            alpha_c = alpha\n            break\n    if alpha_c is None:\n        return -1.0\n    return alpha_c\n\ndef build_scale_free_graph(N, gamma, k_min, k_max, seed):\n    rng = np.random.default_rng(seed)\n    degrees = sample_truncated_power_law(N, gamma, k_min, k_max, rng)\n    adj = configuration_model_simple_graph(degrees, rng)\n    return adj\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (N, k_min, k_max, seed, threshold)\n    test_cases = [\n        (200, 2, 25, 42, 0.02),   # Test Case 1: happy path\n        (80,  2, 15, 123, 0.00),  # Test Case 2: boundary strict stability\n        (150, 3, 30, 7,  0.01),   # Test Case 3: edge case higher heterogeneity\n    ]\n\n    gamma = 2.4\n    alpha_values = [round(0.1 * i, 1) for i in range(11)]  # 0.0 to 1.0 inclusive\n\n    results = []\n    for N, k_min, k_max, seed, theta in test_cases:\n        adj = build_scale_free_graph(N, gamma, k_min, k_max, seed)\n        alpha_c = compute_alpha_c(adj, alpha_values, threshold=theta, removal_fraction=0.01)\n        # Round to three decimals\n        results.append(f\"{alpha_c:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```",
            "answer": "[占位符：最终答案需通过运行解决方案中的代码生成]"
        },
        {
            "introduction": "本练习将网络脆弱性分析提升到一个新的层次，要求你从攻击者的角度思考，解决一个约束优化问题。你需要在固定的成本预算内，设计出最优的节点移除方案，以最大程度地破坏网络的连通性 。通过解决这个组合优化问题，你将学会如何量化网络的结构弱点，并理解在资源有限的情况下制定最高效攻击策略的复杂性。",
            "id": "4301055",
            "problem": "考虑一个大小为 $n=\\lvert V\\rvert$ 的无向简单图 $G=(V,E)$，由一个邻接矩阵 $A\\in\\{0,1\\}^{n\\times n}$ 表示，其中当且仅当节点 $i$ 和节点 $j$ 之间存在一条边时，$A_{ij}=1$，并且对所有 $i$，$A_{ii}=0$。节点 $i$ 的度为 $k_i=\\sum_{j=0}^{n-1}A_{ij}$。该网络被认为是“无标度”的，因为其度分布是重尾的，并且对于某个 $\\gamma2$，近似遵循幂律 $P(k)\\propto k^{-\\gamma}$，尽管对于有限的 $n$，不要求严格遵守。\n\n定义在移除节点 $R\\subseteq V$ 后，图的巨连通分量 (GC) 大小 $S(G,R)$ 为在 $V\\setminus R$ 上的导出子图的最大连通分量中的节点数。我们考虑一个节点移除成本模型，其中移除节点 $i$ 的成本为 $c_i=\\alpha\\cdot\\max(1,k_i)^{\\beta}$，其中 $\\alpha0$ 且指数 $\\beta$ 为实数。给定一个固定预算 $B0$，脆弱性评估问题被构建为以下约束优化问题：\n$$\n\\text{最小化 }S(G,R)\\quad\\text{约束条件为}\\quad \\sum_{i\\in R}c_i\\le B,\\quad R\\subseteq V.\n$$\n在所有最小化集合 $R$ 中，若有多个集合达到相同的最小 $S(G,R)$，则选择总成本最小的那个；若仍有平局，则在节点按其索引排序时选择字典序最小的 $R$。\n\n对于所提供的测试套件，此问题必须精确求解。程序中使用的节点索引必须是 $0,1,2,\\dots,n-1$。\n\n您的任务是编写一个完整、可运行的程序，该程序为每个测试用例计算在给定预算和成本参数下的最优移除集合 $R^\\star$ 和相应的最小 GC 大小 $S^\\star=S(G,R^\\star)$。每个测试用例的最终输出必须是列表 $[S^\\star,R^\\star]$，其中 $R^\\star$ 是一个排序后的节点索引列表。\n\n测试套件如下（每个邻接矩阵 $A$ 都是对称的，对角线为零，并以行主序的列表的列表形式给出）：\n\n- 测试用例 1（线性成本下针对单个中心节点的通用情况）：\n    - $A$ 是一个 $12\\times 12$ 的矩阵，用于一个按如下方式构建的重尾网络。节点 $0$ 连接到节点 $1,2,3,4,5,6,7,8,9$。额外的边有 $(1,2)$, $(3,4)$, $(5,6)$, $(7,8)$, $(9,10)$, $(10,11)$。所有未指明的节点对之间没有边。\n    - 参数：$\\alpha=1$, $\\beta=1$, $B=9$。\n\n- 测试用例 2（二次成本使得移除中心节点代价过高）：\n    - $A$ 与测试用例 1 相同。\n    - 参数：$\\alpha=1$, $\\beta=2$, $B=16$。\n\n- 测试用例 3（两个中心节点和次线性成本）：\n    - $A$ 是一个 $14\\times 14$ 的矩阵，按如下方式构建。节点 $0$ 连接到节点 $1,2,3,4,5,6,7,8$。节点 $5$ 连接到节点 $0,8,9,10,11,12,13$。额外的边有 $(1,2)$, $(3,4)$, $(6,7)$, $(8,9)$, $(10,11)$, $(12,13)$。所有未指明的节点对之间没有边。\n    - 参数：$\\alpha=1$, $\\beta=0.5$, $B=10$。\n\n- 测试用例 4（零预算的边界条件）：\n    - $A$ 与测试用例 3 相同。\n    - 参数：$\\alpha=1$, $\\beta=1$, $B=0$。\n\n- 测试用例 5（固定成本在充足预算下允许完全拆除网络）：\n    - $A$ 与测试用例 1 相同。\n    - 参数：$\\alpha=1$, $\\beta=0$, $B=12$。\n\n对于所有测试用例，节点移除成本必须根据图 $G$ 的原始度 $k_i$ 计算（即，成本不会随着节点的移除而改变）。巨连通分量 (GC) 的大小必须在移除节点后，针对剩余节点上的导出子图进行计算。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应上述顺序的一个测试用例，并且是列表 $[S^\\star,R^\\star]$。例如，输出格式必须遵循模式 $[[S_1,[\\dots]],[S_2,[\\dots]],\\dots]$，逗号或括号之间没有空格。此问题不涉及物理单位。角度不适用。百分比不适用。",
            "solution": "所呈现的问题是一个关注网络脆弱性的约束组合优化任务。我们需要从给定图 $G=(V,E)$ 中找出一个最优节点集 $R^\\star$ 以进行移除，从而最小化剩余最大连通分量（即巨连通分量，GC）的大小。$R^\\star$ 的选择受到总成本预算 $B$ 的约束，其中移除每个节点 $i$ 的成本是其度 $k_i$ 的函数，由 $c_i = \\alpha \\cdot \\max(1,k_i)^{\\beta}$ 给出。问题还规定了一个两级平局打破规则：在达到最小 GC 大小的集合中，选择总成本最小的那个，然后选择字典序最小的那个。\n\n首先，有必要对问题陈述进行验证。\n该问题在图论和网络科学领域内是定义明确的。所有数学实体（$G$、$A$、$k_i$、$S(G,R)$、$c_i$、$B$、$\\alpha$、$\\beta$）都得到了清晰且形式化的定义。优化目标是明确的，显式的平局打破规则确保了任何给定实例都存在唯一解。测试套件中提供的图规模（$n=12$ 和 $n=14$）很小。约束条件虽然具体,但在数学上是合理的,不包含内部矛盾。移除节点可以使网络破碎化这一前提是鲁棒性研究中的一个基本概念。成本函数是一个有效的推广，允许线性（$\\beta=1$）、超线性（$\\beta1$）和次线性（$\\beta1$）成本，这些都是常见的模型。值得注意的是，一般性问题陈述指定 $B0$，而测试用例 4 使用 $B=0$；这是文本中的一个微小不精确之处，但它代表了一个有效且重要的边界条件，而不是一个缺陷。该问题具有科学依据、良定且客观。因此，它被认为是有效的。\n\n任务是找到精确的最优解。鉴于节点集 $V$ 的规模很小（$n \\le 14$），对所有可能的移除集 $R \\subseteq V$ 进行穷举搜索在计算上是可行的。$V$ 的子集总数为 $2^n$。对于 $n=14$，这是 $2^{14} = 16384$ 个子集，现代计算机可以在合理的时间内完全评估这个数量的候选集。这种暴力方法保证能根据指定标准找到全局最优解。\n\n对于每个测试用例，算法流程如下：\n$1$. **初始化**：构建图 $G$ 的邻接矩阵 $A$。计算所有节点 $i \\in V$ 的初始度 $k_i$（即 $A$ 的行和，$k_i = \\sum_{j} A_{ij}$）。然后使用给定公式 $c_i = \\alpha \\cdot \\max(1, k_i)^\\beta$ 计算每个节点的移除成本 $c_i$。找到的最佳解初始化为“无操作”场景，即移除集为空：$R^\\star = \\emptyset$。相应的巨连通分量大小 $S^\\star$ 是原始图 $G$ 的最大连通分量的大小，成本为 $0$。\n\n$2$. **穷举搜索**：算法遍历顶点集 $V$ 的每一个可能的非空子集 $R$。一种常见的实现方式是让一个整数计数器从 $1$ 循环到 $2^n - 1$，其中计数器的二进制表示作为位掩码，指示哪些节点在集合 $R$ 中。\n\n$3$. **候选集评估**：对于每个候选集 $R$：\n    a. 计算总成本 $\\sum_{i \\in R} c_i$。\n    b. 将此成本与预算 $B$ 进行比较。如果成本超过 $B$，则集合 $R$ 无效并被丢弃。\n    c. 如果 $R$ 在预算内，则考虑在剩余节点 $V' = V \\setminus R$ 上的导出子图。计算该子图的巨连通分量大小 $S(G,R)$。这可以通过使用广度优先搜索（BFS）或深度优先搜索（DFS）来找到所有连通分量及其大小来高效完成，或者可以利用库函数，如 `scipy.sparse.csgraph.connected_components`。\n    \n$4$. **最优解更新**：使用指定的多级目标函数，将当前候选解 $(S(G,R), \\sum_{i \\in R} c_i, R)$ 与迄今为止的最佳解 $(S^\\star, \\text{Cost}^\\star, R^\\star)$进行比较：\n    a. 如果 $S(G,R)  S^\\star$，则当前解严格更优。更新最佳解：$(S^\\star, \\text{Cost}^\\star, R^\\star) \\leftarrow (S(G,R), \\sum_{i \\in R} c_i, R)$。\n    b. 如果 $S(G,R) = S^\\star$，则应用第一条平局打破规则：如果 $\\sum_{i \\in R} c_i  \\text{Cost}^\\star$，则当前解因其成本较低而更优。更新最佳解。\n    c. 如果 $S(G,R) = S^\\star$ 且 $\\sum_{i \\in R} c_i = \\text{Cost}^\\star$，则应用第二条平局打破规则：将集合 $R$ 与 $R^\\star$ 进行字典序比较。如果 $R$ 更小，则它成为新的最佳解。为使此比较正确，集合内的节点索引必须是有序的。\n\n在评估完所有 $2^n$ 个子集后，存储的 $(S^\\star, R^\\star)$ 即为该测试用例的保证最优解。对测试套件中的所有测试用例重复此过程。\n```python\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom scipy.sparse import csr_matrix\n\ndef solve():\n    \"\"\"\n    Solves the network vulnerability optimization problem for a suite of test cases.\n    \"\"\"\n\n    def build_adjacency_matrix(n, edges):\n        \"\"\"Helper function to generate an adjacency matrix from an edge list.\"\"\"\n        adj = np.zeros((n, n), dtype=int)\n        for u, v in edges:\n            adj[u, v] = 1\n            adj[v, u] = 1\n        return adj\n\n    def get_test_cases():\n        \"\"\"Defines the graph structures and parameters for all test cases.\"\"\"\n        # Graph for Test Cases 1, 2, 5 (n=12)\n        n1 = 12\n        edges1 = []\n        for i in range(1, 10):\n            edges1.append((0, i))\n        edges1.extend([(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (10, 11)])\n        A1 = build_adjacency_matrix(n1, edges1)\n\n        # Graph for Test Cases 3, 4 (n=14)\n        n2 = 14\n        edges2 = []\n        for i in range(1, 9):\n            edges2.append((0, i))\n        for i in [0, 8, 9, 10, 11, 12, 13]:\n            edges2.append((5, i))\n        edges2.extend([(1, 2), (3, 4), (6, 7), (8, 9), (10, 11), (12, 13)])\n        A2 = build_adjacency_matrix(n2, edges2)\n        \n        test_cases_data = [\n            (A1, 1.0, 1.0, 9.0),   # Test Case 1\n            (A1, 1.0, 2.0, 16.0),  # Test Case 2\n            (A2, 1.0, 0.5, 10.0),  # Test Case 3\n            (A2, 1.0, 1.0, 0.0),   # Test Case 4\n            (A1, 1.0, 0.0, 12.0),  # Test Case 5\n        ]\n        return test_cases_data\n\n    def get_gc_size(adj_matrix, remaining_nodes_indices):\n        \"\"\"Calculates the size of the Giant Component in the induced subgraph.\"\"\"\n        if not remaining_nodes_indices:\n            return 0\n        \n        # Create the induced subgraph by selecting rows and columns.\n        sub_adj = adj_matrix[np.ix_(remaining_nodes_indices, remaining_nodes_indices)]\n        \n        # Use scipy's connected_components for efficiency.\n        # A sparse matrix is required for this function.\n        sub_adj_sparse = csr_matrix(sub_adj)\n        n_components, labels = connected_components(csgraph=sub_adj_sparse, directed=False)\n        \n        if n_components == 0:\n            return 0\n            \n        component_sizes = np.bincount(labels)\n        return np.max(component_sizes)\n\n    def solve_single_case(A, alpha, beta, B):\n        \"\"\"Performs an exhaustive search to find the optimal removal set for one case.\"\"\"\n        n = A.shape[0]\n        \n        # 1. Pre-computation: Calculate degrees and costs from the original graph.\n        degrees = A.sum(axis=1)\n        costs = alpha * np.power(np.maximum(1, degrees), beta)\n        \n        # 2. Initialization: Start with the \"do nothing\" case (R = empty set).\n        all_nodes = list(range(n))\n        best_S = get_gc_size(A, all_nodes)\n        best_cost = 0.0\n        best_R = []\n        \n        # 3. Exhaustive Search: Iterate through all 2^n possible subsets of nodes.\n        # The loop starts from 1 to skip the already-handled empty set.\n        for i in range(1, 1  n):\n            R = []\n            current_cost = 0.0\n            \n            # Construct the removal set R and its cost from the bitmask i.\n            for j in range(n):\n                if (i  j)  1:\n                    R.append(j)\n                    current_cost += costs[j]\n            \n            # 4. Evaluation: Check budget and compute GC size.\n            if current_cost  B:\n                continue\n                \n            remaining_nodes = [node for node in all_nodes if node not in R]\n            current_S = get_gc_size(A, remaining_nodes)\n            \n            # 5. Update: Apply the multi-criteria optimization rules.\n            if current_S  best_S:\n                best_S = current_S\n                best_cost = current_cost\n                best_R = R\n            elif current_S == best_S:\n                if current_cost  best_cost:\n                    best_cost = current_cost\n                    best_R = R\n                elif current_cost == best_cost:\n                    # R is naturally sorted by construction from the bitmask.\n                    # Python's list comparison is lexicographical.\n                    if R  best_R:\n                        best_R = R\n\n        return [best_S, best_R]\n\n    test_cases = get_test_cases()\n    results = []\n    for case in test_cases:\n        A, alpha, beta, B = case\n        result = solve_single_case(A, alpha, beta, B)\n        # Format the result string to remove spaces for exact output matching.\n        results.append(str(result).replace(\" \", \"\"))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```",
            "answer": "[占位符：最终答案需通过运行解决方案中的代码生成]"
        }
    ]
}