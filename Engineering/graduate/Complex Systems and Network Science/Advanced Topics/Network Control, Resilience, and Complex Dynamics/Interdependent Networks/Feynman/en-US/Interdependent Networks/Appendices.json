{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the fragility of interdependent systems, we must first understand the precise mechanics of how failures propagate. This exercise provides a foundational, step-by-step walkthrough of a cascading failure on a small, well-defined pair of networks. By manually tracing how an initial node removal triggers a sequence of connectivity and dependency failures, you will build a concrete intuition for the dynamics that will be modeled more abstractly in later practices .",
            "id": "4266384",
            "problem": "Consider two undirected networks $A$ and $B$ that are interdependent via bidirectional one-to-one dependency pairs. Let the node sets be $A=\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ and $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$. The edge sets are\n$$\nE_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}\n$$\nand\n$$\nE_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}.\n$$\nInterdependence is specified by the bidirectional dependency set\n$$\nD=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\},\n$$\nso that for each $(a_i,b_j)\\in D$ there is a corresponding $(b_j,a_i)\\in D$. The node $b_7$ has no dependency partner and is autonomous.\n\nCascading failure dynamics are defined as follows, starting from an initial removal in network $A$. A node is functional at a given stage if and only if both of the following conditions hold: it belongs to the largest connected component (LCC) of its own network’s currently active subgraph, and, if it has a dependency partner in the other network, that partner is also functional. The process is monotone: once a node becomes nonfunctional, it remains nonfunctional. Define $S_A^{(t)}$ and $S_B^{(t)}$ as the sets of functional nodes in networks $A$ and $B$ after $t$ complete cascade rounds, with $t\\in\\mathbb{N}_0$. Initialization is $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$, where the initial removal set is $R=\\{a_2\\}$. One complete cascade round consists of the following sequence:\n- Compute the LCC of the subgraph induced by $S_A^{(t)}$ in $A$; remove all nodes of $A$ not in this LCC, yielding an intermediate active set $S_{A,\\mathrm{LCC}}^{(t)}$.\n- Propagate dependencies to $B$: remove from $S_B^{(t)}$ any node in $B$ whose dependency partner in $A$ is not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n- Compute the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$ in $B$; remove all nodes of $B$ not in this LCC, yielding $S_B^{(t+1)}$.\n- Propagate dependencies to $A$: remove from $S_{A,\\mathrm{LCC}}^{(t)}$ any node in $A$ whose dependency partner in $B$ is not in $S_B^{(t+1)}$, and then take the LCC of the remaining subgraph in $A$; the result is $S_A^{(t+1)}$.\n\nAssume ties in the size of the largest connected component are broken deterministically by selecting the component whose node labels have the smallest sum under the mappings $a_i\\mapsto i$ and $b_j\\mapsto j$. Perform exactly $2$ complete cascade rounds starting from $R=\\{a_2\\}$ as specified. Report the cardinalities $|S_A^{(2)}|$ and $|S_B^{(2)}|$ as your final answer, formatted as a row matrix. No rounding is required.",
            "solution": "The problem describes a cascading failure process on two interdependent networks, $A$ and $B$. We are asked to simulate this process for two complete rounds and determine the number of surviving nodes in each network.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Network $A$ node set: $A=\\{a_1, a_2, a_3, a_4, a_5, a_6\\}$\n- Network $A$ edge set: $E_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}$\n- Network $B$ node set: $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$\n- Network $B$ edge set: $E_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}$\n- Bidirectional dependency set: $D=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\}$\n- Autonomous node: $b_7$\n- Initial removal set: $R=\\{a_2\\}$\n- Initial functional sets: $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$.\n- Cascade dynamics: A sequence of four operations defines one complete round from time $t$ to $t+1$:\n  1. Find the largest connected component (LCC) of the subgraph induced by $S_A^{(t)}$, yielding $S_{A,\\mathrm{LCC}}^{(t)}$.\n  2. Remove nodes from $S_B^{(t)}$ whose dependency partners are not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n  3. Find the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$, yielding $S_B^{(t+1)}$.\n  4. Remove nodes from $S_{A,\\mathrm{LCC}}^{(t)}$ whose dependency partners are not in $S_B^{(t+1)}$, then find the LCC of the remaining subgraph, yielding $S_A^{(t+1)}$.\n- Tie-breaking rule for LCC: Select the component with the smallest sum of node indices.\n- Task: Report $|S_A^{(2)}|$ and $|S_B^{(2)}|$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, describing a well-known model from network science. It is well-posed, with all components (networks, dependencies, initial conditions, dynamics, and tie-breaking rule) clearly and unambiguously defined, ensuring a unique, deterministic outcome. The problem is objective and formalizable. The setup is complete and consistent, without any contradictions or missing information. It requires a procedural simulation, making it non-trivial.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\nWe will simulate the cascading failure process step-by-step for two rounds.\n\n**Initial State ($t=0$)**\nThe process starts with the removal of node $a_2$ from network $A$.\nThe initial set of functional nodes in network $A$ is $S_A^{(0)} = A \\setminus \\{a_2\\} = \\{a_1, a_3, a_4, a_5, a_6\\}$.\nThe initial set of functional nodes in network $B$ is $S_B^{(0)} = B = \\{b_1, b_2, b_3, b_4, b_5, b_6, b_7\\}$.\n\n**Cascade Round 1 ($t=0 \\to t=1$)**\n1.  **LCC in Network A:** We consider the subgraph of $A$ induced by $S_A^{(0)} = \\{a_1, a_3, a_4, a_5, a_6\\}$. The edges from $E_A$ within this subgraph are $(a_1, a_3)$, $(a_3, a_4)$, and $(a_5, a_6)$. This subgraph has two connected components: $C_{A,1} = \\{a_1, a_3, a_4\\}$ of size $3$ and $C_{A,2} = \\{a_5, a_6\\}$ of size $2$. The largest connected component (LCC) is $C_{A,1}$. Therefore, nodes outside this component fail. The intermediate set of functional nodes in $A$ is $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$.\n\n2.  **Dependency Propagation to Network B:** A node in $B$ fails if its dependency partner in $A$ is no longer functional. The set of all failed nodes in $A$ is now $\\{a_2\\}$ (initial removal) and $\\{a_5, a_6\\}$ (from LCC isolation). Their dependency partners in $B$ are $\\{b_3\\}$, $\\{b_5\\}$, and $\\{b_6\\}$, respectively. We remove these nodes from $S_B^{(0)}$.\n    The intermediate set of functional nodes in $B$ is $S_{B,\\mathrm{dep}}^{(0)} = S_B^{(0)} \\setminus \\{b_3, b_5, b_6\\} = \\{b_1, b_2, b_4, b_7\\}$.\n\n3.  **LCC in Network B:** We find the LCC of the subgraph of $B$ induced by $S_{B,\\mathrm{dep}}^{(0)} = \\{b_1, b_2, b_4, b_7\\}$. The only edge from $E_B$ within this subgraph is $(b_1, b_2)$. This forms three connected components: $C_{B,1}=\\{b_1, b_2\\}$ of size $2$, $C_{B,2}=\\{b_4\\}$ of size $1$, and $C_{B,3}=\\{b_7\\}$ of size $1$. The LCC is $C_{B,1}$. This defines the functional set for the next round: $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with the set $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$ and remove any node whose dependency partner is not in $S_B^{(1)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2$, and $b_2 \\in S_B^{(1)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1$, and $b_1 \\in S_B^{(1)}$. So, $a_3$ is kept.\n    - The partner of $a_4$ is $b_4$, and $b_4 \\notin S_B^{(1)}$. So, $a_4$ fails.\n    The remaining set of nodes is $\\{a_1, a_3\\}$. We must now find the LCC of the subgraph induced by these nodes. Since the edge $(a_1, a_3) \\in E_A$, this subgraph is connected. Thus, its LCC is the set itself.\n    This defines the functional set for the next round: $S_A^{(1)} = \\{a_1, a_3\\}$.\n\nAt the end of round $1$, the functional sets are $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n**Cascade Round 2 ($t=1 \\to t=2$)**\nWe begin with the functional sets $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n1.  **LCC in Network A:** The subgraph induced by $S_A^{(1)}$ is connected due to the edge $(a_1, a_3)$. The LCC is the set itself. So, $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$.\n\n2.  **Dependency Propagation to Network B:** We check the dependency partners of nodes in $S_B^{(1)} = \\{b_1, b_2\\})$.\n    - The partner of $b_1$ is $a_3$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_1$ is kept.\n    - The partner of $b_2$ is $a_1$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_2$ is kept.\n    No nodes fail due to dependency. The intermediate set is $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$.\n\n3.  **LCC in Network B:** The subgraph induced by $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$ is connected due to the edge $(b_1, b_2)$. The LCC is the set itself. Thus, $S_B^{(2)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$ and check dependencies against $S_B^{(2)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2 \\in S_B^{(2)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1 \\in S_B^{(2)}$. So, $a_3$ is kept.\n    No nodes fail due to dependency. The remaining set is $\\{a_1, a_3\\}$. The subgraph induced by this set is connected, so its LCC is the set itself.\n    Thus, $S_A^{(2)} = \\{a_1, a_3\\}$.\n\nAfter two rounds, the system has stabilized with $S_A^{(2)} = S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(2)} = S_B^{(1)} = \\{b_1, b_2\\}$.\nThe cardinalities are $|S_A^{(2)}| = 2$ and $|S_B^{(2)}| = 2$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 & 2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving from a specific simulation to a general, probabilistic viewpoint is a crucial step in network science. This practice challenges you to formalize the interdependence rule into a mathematical expression using the law of total probability. You will derive the survival probability of a node in one network as a function of its dependency probability, $q$, and the functional status of the other network, $x_B$, providing a first look at how analytical models capture the essence of these complex systems .",
            "id": "4266399",
            "problem": "Consider two interdependent networks $A$ and $B$ in the thermodynamic limit of large network size. In the model of partial interdependence, each node in $A$ independently has a dependency on its counterpart in $B$ with probability $q \\in [0,1]$. A node in $A$ that has no dependency on $B$ is not affected by interdependence-induced failures. A node in $A$ that has a dependency on its counterpart in $B$ survives the interdependence-induced failure mechanism if and only if its counterpart in $B$ is functional. Let $x_B \\in [0,1]$ denote the probability that a randomly selected node in $B$ is functional at the cascade steady state. Assume that dependency assignment in $A$ is independent of the survival state of nodes in $B$, and focus exclusively on the interdependence gating effect (ignore $A$'s internal topological or percolation constraints).\n\nUsing the law of total probability and the stated independence, derive the survival probability due solely to interdependence for a randomly chosen node in $A$ as a closed-form analytic expression in terms of $q$ and $x_B$. Provide your final expression as the answer.",
            "solution": "The user wants to solve the problem by following these steps:\n1.  **Validate the problem statement**: The user must check if the problem is scientifically grounded, well-posed, objective, and complete. If not, the user must explain the flaws and terminate.\n2.  **Provide a solution**: If the problem is valid, the user must provide a complete, reasoned solution with all mathematical entities in LaTeX.\n3.  **Format the final answer**: The final answer must be a single number or expression in a `$$\\boxed{...}$$` block, following specific LaTeX formatting rules.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   Networks: Two interdependent networks, $A$ and $B$, in the thermodynamic limit.\n*   Interdependence Model: Partial interdependence, where a node in $A$ depends on its counterpart in $B$ with probability $q \\in [0,1]$.\n*   Survival Condition (No Dependency): A node in $A$ with no dependency on $B$ is not affected by interdependence-induced failures (i.e., it survives this mechanism).\n*   Survival Condition (With Dependency): A node in $A$ with a dependency on its counterpart in $B$ survives the interdependence-induced failure mechanism if and only if its counterpart in $B$ is functional.\n*   State of Network $B$: $x_B \\in [0,1]$ is the probability that a randomly selected node in $B$ is functional.\n*   Independence Assumption: The assignment of dependency in $A$ is independent of the survival state of nodes in $B$.\n*   Scope: Focus exclusively on the interdependence gating effect, ignoring internal network topology.\n*   Objective: Derive the survival probability for a randomly chosen node in $A$ due to interdependence, as a closed-form expression in terms of $q$ and $x_B$, using the law of total probability.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded:** The problem describes a simplified but standard model of cascading failures in interdependent networks, a well-established topic in network science and statistical physics. The concepts of partial interdependence, counterpart dependency, and the thermodynamic limit are standard in this field. The problem is scientifically sound.\n*   **Well-Posed:** The problem is clearly stated. It asks for the derivation of a specific quantity (survival probability) based on a defined set of rules and parameters ($q$, $x_B$). A unique and meaningful solution is derivable from the premises.\n*   **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n*   **Incomplete or Contradictory Setup:** The problem is self-contained. It provides all necessary probabilities ($q$, $x_B$) and logical conditions for survival. The explicit instruction to ignore internal percolation simplifies the setup without creating a contradiction.\n*   **Unrealistic or Infeasible:** The problem is an abstract theoretical model, and within this context, its assumptions are consistent and feasible.\n*   **Ill-Posed or Poorly Structured:** The problem is well-structured, providing a clear path to the solution by specifically requesting the use of the law of total probability.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid as it is scientifically grounded, well-posed, and all necessary information is provided. I will proceed with the solution.\n\n### Solution Derivation\n\nLet $S_A$ denote the event that a randomly selected node in network $A$ survives the interdependence-induced failure mechanism. We wish to find the probability of this event, $P(S_A)$.\n\nLet $D$ be the event that the chosen node in $A$ has a dependency on its counterpart in network $B$. The problem states that this occurs with probability $q$. Therefore, we have:\n$$P(D) = q$$\nThe complementary event, $\\neg D$, is that the node in $A$ does not have a dependency on its counterpart in $B$. The probability of this event is:\n$$P(\\neg D) = 1 - P(D) = 1 - q$$\n\nThe problem directs us to use the law of total probability to find $P(S_A)$. We can partition the calculation of $P(S_A)$ based on whether the node has a dependency or not:\n$$P(S_A) = P(S_A | D) P(D) + P(S_A | \\neg D) P(\\neg D)$$\nHere, $P(S_A | D)$ is the conditional probability of survival given a dependency exists, and $P(S_A | \\neg D)$ is the conditional probability of survival given no dependency exists. We must determine these conditional probabilities based on the rules provided in the problem statement.\n\n1.  **Calculating $P(S_A | \\neg D)$**: This is the probability that a node in $A$ survives, given it does *not* have a dependency on $B$. The problem states: \"A node in $A$ that has no dependency on $B$ is not affected by interdependence-induced failures.\" This means its survival under this specific failure mechanism is certain. Thus, the conditional probability is $1$.\n    $$P(S_A | \\neg D) = 1$$\n\n2.  **Calculating $P(S_A | D)$**: This is the probability that a node in $A$ survives, given it *does* have a dependency on its counterpart in $B$. The problem states: \"A node in $A$ that has a dependency on its counterpart in $B$ survives the interdependence-induced failure mechanism if and only if its counterpart in $B$ is functional.\" Let $S_B$ be the event that the counterpart node in $B$ is functional. The problem gives the probability of this event as $x_B$, so $P(S_B) = x_B$. Because the survival of the node in $A$ is equivalent to the survival of its counterpart in $B$ under this condition, we have $P(S_A | D) = P(S_B)$. Therefore:\n    $$P(S_A | D) = x_B$$\n    The stated independence of dependency assignment and the state of nodes in $B$ validates this direct assignment.\n\nNow, we substitute these conditional probabilities and the event probabilities back into the law of total probability equation:\n$$P(S_A) = (x_B) \\cdot (q) + (1) \\cdot (1 - q)$$\n\nSimplifying this expression gives the final formula for the survival probability of a node in network $A$:\n$$P(S_A) = qx_B + 1 - q$$\nThis can be rearranged to $P(S_A) = 1 - q + qx_B$. This result is the desired closed-form analytic expression in terms of $q$ and $x_B$.",
            "answer": "$$\n\\boxed{1 - q + qx_B}\n$$"
        },
        {
            "introduction": "This capstone practice moves from solving well-defined problems to conducting a full computational experiment, mirroring the work of a network scientist. You will implement a complete simulation of a cascading failure to investigate a critical research question: how does the strategy for forming dependencies affect the overall robustness of the system? By varying a parameter $\\alpha$ that controls degree-correlated linking and measuring its effect on the mutual percolation threshold $p_c$, you will use your model as a tool for scientific inquiry .",
            "id": "4283863",
            "problem": "Consider two interdependent networks $A$ and $B$ of equal size $N$, each generated as an undirected random graph following the Erdős–Rényi (ER) model: every unordered pair of distinct nodes is independently connected with probability $p_{\\text{edge}}$, which yields an expected degree $z \\approx p_{\\text{edge}}(N-1)$. Let $k_A(i)$ denote the degree of node $i$ in network $A$, and $k_B(j)$ denote the degree of node $j$ in network $B$. Define directed interdependence edges across networks (support edges) such that a node in one network requires at least one functional support neighbor in the other network to remain functional.\n\nYou must develop and implement a dependency formation model in which the probability of creating a dependency edge between node $i$ in network $A$ and node $j$ in network $B$ is proportional to $(k_A(i)+1)^\\alpha (k_B(j)+1)^\\alpha$, where $\\alpha \\in \\mathbb{R}$ is a tunable parameter that controls the degree-based bias of interdependence pairing. This offset $(+1)$ ensures that nodes of degree zero are assigned finite weights for all $\\alpha$. The dependency process must be symmetric, meaning both $A \\to B$ and $B \\to A$ dependency edges are constructed independently following the same rule. To maintain finite expected dependency density, construct the dependency edges as follows: for each node $i$ in $A$, draw the number of outgoing dependency edges to $B$ from a Poisson distribution with mean $\\lambda_A(i) = d_{\\text{dep}} \\, \\frac{(k_A(i)+1)^\\alpha}{\\frac{1}{N}\\sum_{u=1}^{N} (k_A(u)+1)^\\alpha}$, and for each such edge select its endpoint $j$ in $B$ with probability proportional to $(k_B(j)+1)^\\alpha$. Perform the analogous construction for each node $j$ in $B$, producing a set of $B \\to A$ dependencies with Poisson mean $\\lambda_B(j) = d_{\\text{dep}} \\, \\frac{(k_B(j)+1)^\\alpha}{\\frac{1}{N}\\sum_{v=1}^{N} (k_B(v)+1)^\\alpha}$ and targets in $A$ chosen with probability proportional to $(k_A(i)+1)^\\alpha$. This factorized sampling yields edge probabilities proportional to $(k_A(i)+1)^\\alpha (k_B(j)+1)^\\alpha$ while controlling the expected number of dependency edges per node via $d_{\\text{dep}}$.\n\nDefine a cascading failure model starting from an initial random damage where a fraction $p \\in [0,1]$ of nodes in each network is retained (functional) and the remaining fraction $1-p$ is removed (non-functional). The cascade proceeds iteratively according to the following two interdependent rules applied to both networks at each iteration:\n1. Connectivity rule: a node can be functional only if it belongs to the largest connected component (the giant component) of its own network considering the nodes currently functional in that network.\n2. Dependency rule: a node in $A$ can be functional only if it has at least one dependency neighbor in $B$ that is currently functional, and vice versa for nodes in $B$ with dependencies to $A$.\n\nStarting from the initially retained sets in $A$ and $B$, alternately enforce the connectivity rule and the dependency rule in both networks until a fixed point is reached or no functional nodes remain. Let $S_A(p)$ and $S_B(p)$ denote the resulting fractions of nodes in $A$ and $B$ that are functional and lie in their respective giant components at the fixed point. Define the mutual percolation threshold $p_c$ for given network and dependency parameters as the infimum of $p$ such that both $S_A(p)$ and $S_B(p)$ are strictly positive in the large-$N$ limit. In finite networks, approximate this by the smallest $p$ for which both $S_A(p)$ and $S_B(p)$ exceed a small threshold $\\tau$.\n\nYour program must:\n- Generate two ER networks $A$ and $B$ with $N$ nodes and expected degree $z_A$ and $z_B$ respectively (implemented via edge probability $p_{\\text{edge},A} = \\frac{z_A}{N-1}$ and $p_{\\text{edge},B} = \\frac{z_B}{N-1}$).\n- Construct symmetric interdependence via the dependency model above with parameter $\\alpha$ and average dependency out-degree target $d_{\\text{dep}}$.\n- For a given $p$, compute the fixed point of the cascade described by the connectivity and dependency rules to obtain $S_A(p)$ and $S_B(p)$.\n- Estimate $p_c$ by binary search over $p \\in [0,1]$ with sufficient resolution, using the finite-size criterion with $\\tau = 0.05$ (that is, declare existence of a mutual giant component if both $S_A(p) \\ge \\tau$ and $S_B(p) \\ge \\tau$ at the fixed point).\n- Use a fixed random seed per test case to ensure reproducibility.\n\nFundamental base assumptions and definitions that may be used include:\n- In ER graphs, for sufficiently large $N$ and expected degree $z$, a giant component emerges when $z > 1$ and occupies a positive fraction of nodes; the largest connected component (giant component) can be found by breadth-first search or depth-first search restricted to currently functional nodes.\n- In interdependent networks with mutual dependencies, enforcing both connectivity and dependency constraints iteratively yields a fixed point representing the mutually functional set.\n\nImplement the above to analyze the effect of $\\alpha$ on the mutual percolation threshold $p_c$ by computing $p_c$ for the following test suite of parameter sets (each specified as a tuple $(N, z_A, z_B, d_{\\text{dep}}, \\alpha, \\text{seed})$):\n- Test case 1 (baseline, \"happy path\"): $(N = 1200, z_A = 3.0, z_B = 3.0, d_{\\text{dep}} = 1.0, \\alpha = 0.0, \\text{seed} = 42)$.\n- Test case 2 (positive degree bias): $(N = 1200, z_A = 3.0, z_B = 3.0, d_{\\text{dep}} = 1.0, \\alpha = 1.0, \\text{seed} = 43)$.\n- Test case 3 (strong positive bias): $(N = 1200, z_A = 3.0, z_B = 3.0, d_{\\text{dep}} = 1.0, \\alpha = 2.0, \\text{seed} = 44)$.\n- Test case 4 (negative degree bias): $(N = 1200, z_A = 3.0, z_B = 3.0, d_{\\text{dep}} = 1.0, \\alpha = -1.0, \\text{seed} = 45)$.\n- Test case 5 (edge case, weaker coupling): $(N = 1200, z_A = 3.0, z_B = 3.0, d_{\\text{dep}} = 0.5, \\alpha = 1.0, \\text{seed} = 46)$.\n\nYour program should produce a single line of output containing the estimated mutual percolation thresholds for the five test cases as a comma-separated list enclosed in square brackets (for example, \"[$p_{c,1},p_{c,2},p_{c,3},p_{c,4},p_{c,5}$]\"), where each $p_{c,i}$ is a floating-point number in decimal form. No other text should be printed.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of complex networks, and provides all necessary information for a computational solution. It describes a simulation of cascading failures on interdependent Erdős-Rényi networks, where the interdependencies are formed based on a degree-correlated attachment rule. The goal is to compute the mutual percolation threshold $p_c$ for several parameter sets. We will proceed with the solution.\n\nThe solution involves several distinct modules:\n$1$. Generation of the intra-network topology for networks $A$ and $B$.\n$2$. Construction of the inter-network dependency links.\n$3$. Simulation of the cascading failure process for a given initial fraction of surviving nodes.\n$4$. A binary search algorithm to identify the critical threshold $p_c$.\n\n**$1$. Intra-network Generation**\nNetworks $A$ and $B$ are generated as Erdős-Rényi (ER) random graphs of size $N$. An ER graph is constructed by considering every possible pair of nodes and connecting them with a fixed probability $p_{\\text{edge}}$. For a network with $N$ nodes and a target average degree $z$, this probability is set to $p_{\\text{edge}} = \\frac{z}{N-1}$. We will represent the networks using adjacency lists, which is efficient for storing sparse graphs and for iterating over the neighbors of a node. For each network, we also compute the degree $k(i)$ for each node $i$, as this is required for constructing the dependency links.\n\n**$2$. Inter-network Dependency Construction**\nThe directed dependency links from network $A$ to $B$ (and symmetrically from $B$ to $A$) are constructed based on a degree-biased rule controlled by the parameter $\\alpha$. The probability of a dependency link between node $i$ in $A$ and node $j$ in $B$ is proportional to $(k_A(i)+1)^\\alpha (k_B(j)+1)^\\alpha$. The problem specifies a concrete generative procedure:\n\nFor the $A \\to B$ dependencies:\nFirst, for each node $i$ in network $A$, we calculate a weight $w_A(i) = (k_A(i)+1)^\\alpha$. Similarly, for each node $j$ in network $B$, its weight is $w_B(j) = (k_B(j)+1)^\\alpha$.\nThe number of dependencies originating from node $i \\in A$, denoted $m_i$, is a random variable drawn from a Poisson distribution with mean $\\lambda_A(i)$. This mean is given by:\n$$ \\lambda_A(i) = d_{\\text{dep}} \\, \\frac{w_A(i)}{\\frac{1}{N}\\sum_{u=1}^{N} w_A(u)} $$\nwhere $d_{\\text{dep}}$ is the target average number of dependency edges per node.\nOnce $m_i$ is determined for node $i$, we select $m_i$ target nodes in network $B$. Each target is chosen independently (with replacement) from the $N$ nodes of $B$, with a probability distribution $P_{\\text{target}}(j)$ proportional to the target node's weight:\n$$ P_{\\text{target}}(j) = \\frac{w_B(j)}{\\sum_{v=1}^{N} w_B(v)} $$\nThis process is repeated for every node in $A$. An identical, independent process is performed to create the $B \\to A$ dependency links, with the roles of $A$ and $B$ reversed. The results are stored in two adjacency lists, one for $A \\to B$ dependencies and one for $B \\to A$.\n\n**$3$. Cascading Failure Simulation**\nGiven an initial fraction $p$ of surviving nodes in each network, a cascading failure is initiated. The state of the system is described by two boolean arrays, `functional_A` and `functional_B`, indicating which nodes are currently operational.\n\n*   **Initial Shock**: For a given $p$, we randomly select a fraction $1-p$ of nodes in network $A$ and, independently, a fraction $1-p$ in network $B$ to be removed. Their status in the respective functional arrays is set to `False`.\n\n*   **Iterative Cascade**: The system then evolves in discrete time steps. In each step, we apply two rules to remove further nodes until a stable state (a fixed point) is reached.\n    $a$. **Dependency Rule**: A node $i$ in network $A$ that is currently functional is marked for removal if it has no dependency links to any currently functional nodes in network $B$. The same rule is applied to nodes in $B$. All such unsupported nodes are removed simultaneously.\n    $b$. **Connectivity Rule**: After applying the dependency rule, we identify for each network ($A$ and $B$) the subgraphs induced by their respective sets of currently functional nodes. Within each subgraph, we find all connected components. Any node not belonging to the largest connected component (LCC, or giant component) of its respective subgraph is marked for removal. These nodes are removed simultaneously.\n\nThese two rules are applied sequentially within an iteration, and the iterations are repeated until an entire iteration passes with no nodes being removed. Since nodes are only ever removed, this process is guaranteed to terminate at a unique fixed point.\n\nTo implement the connectivity rule, we need a function to find the LCC of a graph given a set of active nodes. A Breadth-First Search (BFS) or Depth-First Search (DFS) can be used. We iterate through all active nodes. If an active node has not been visited yet, we start a traversal (e.g., BFS) from it, exploring only along edges that connect to other active nodes. This identifies one connected component. We keep track of the largest component found so far. After checking all active nodes, we obtain the set of nodes belonging to the LCC.\n\n**$4$. Estimation of the Mutual Percolation Threshold $p_c$**\nThe mutual percolation threshold $p_c$ is the critical value of $p$ at which a macroscopic fraction of nodes survives the cascade. For a finite system of size $N$, we approximate this by finding the minimum $p$ for which the final fraction of surviving nodes in the LCC, $S_A(p)$ and $S_B(p)$, are both greater than or equal to a small threshold $\\tau = 0.05$.\n$$ S_A(p) = \\frac{\\text{size of final functional set in A}}{N} $$\n$$ S_B(p) = \\frac{\\text{size of final functional set in B}}{N} $$\nWe are looking for $p_c = \\inf \\{ p \\in [0,1] \\mid S_A(p) \\ge \\tau \\text{ and } S_B(p) \\ge \\tau \\}$.\nThis value is found using a binary search algorithm on the interval $p \\in [0, 1]$. We define a boolean function `check(p)` that runs the full cascading failure simulation for a given $p$ and returns `True` if the survival criterion is met, and `False` otherwise. The binary search proceeds as follows:\n- Initialize search range `p_low` = $0.0$, `p_high` = $1.0$.\n- Repeat for a fixed number of iterations (e.g., $30$, to ensure high precision):\n    - Set `p_mid` = (`p_low` + `p_high`) / $2$.\n    - If `check(p_mid)` is `True`, it means survival is possible at this $p$, so the critical threshold could be lower. We set `p_high` = `p_mid`.\n    - If `check(p_mid)` is `False`, survival is not possible, and a higher initial fraction of nodes is required. We set `p_low` = `p_mid`.\nThe final value of `p_high` is our estimate of $p_c$. This entire procedure is repeated for each of the five test cases provided, using the specified parameters and random seed to ensure reproducibility.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\n# scipy version 1.11.4 does not have a formal dependency on numpy.\n# The code below is pure numpy and standard library to avoid any\n# potential version conflicts, even though scipy is listed as available.\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n\n    test_cases = [\n        # (N, z_A, z_B, d_dep, alpha, seed)\n        (1200, 3.0, 3.0, 1.0, 0.0, 42),\n        (1200, 3.0, 3.0, 1.0, 1.0, 43),\n        (1200, 3.0, 3.0, 1.0, 2.0, 44),\n        (1200, 3.0, 3.0, 1.0, -1.0, 45),\n        (1200, 3.0, 3.0, 0.5, 1.0, 46),\n    ]\n\n    results = []\n    for params in test_cases:\n        N, z_A, z_B, d_dep, alpha, seed = params\n        pc = find_pc(N, z_A, z_B, d_dep, alpha, seed)\n        results.append(f\"{pc:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef generate_er_network(N, z, rng):\n    \"\"\"\n    Generates an Erdős-Rényi (ER) random graph.\n    \"\"\"\n    p_edge = z / (N - 1)\n    adj = [[] for _ in range(N)]\n    degrees = np.zeros(N, dtype=int)\n    for i in range(N):\n        for j in range(i + 1, N):\n            if rng.random()  p_edge:\n                adj[i].append(j)\n                adj[j].append(i)\n                degrees[i] += 1\n                degrees[j] += 1\n    return adj, degrees\n\ndef construct_dependencies(N, degrees_A, degrees_B, alpha, d_dep, rng):\n    \"\"\"\n    Constructs degree-biased dependency links between networks A and B.\n    \"\"\"\n    # Weights for nodes in A and B\n    with np.errstate(divide='ignore'): # Handle k=0, alpha0 case\n        weights_A = (degrees_A + 1)**alpha\n        weights_B = (degrees_B + 1)**alpha\n\n    # Normalize weights to avoid numerical issues\n    mean_weight_A = np.mean(weights_A)\n    mean_weight_B = np.mean(weights_B)\n\n    # Probabilities for choosing targets\n    prob_targets_A = weights_A / np.sum(weights_A)\n    prob_targets_B = weights_B / np.sum(weights_B)\n\n    nodes_A = np.arange(N)\n    nodes_B = np.arange(N)\n    \n    # A -> B dependencies\n    deps_A_to_B = [[] for _ in range(N)]\n    if mean_weight_A > 0:\n        lambda_A = d_dep * weights_A / mean_weight_A\n        num_deps_A = rng.poisson(lambda_A)\n        for i in range(N):\n            if num_deps_A[i] > 0:\n                targets = rng.choice(nodes_B, size=num_deps_A[i], p=prob_targets_B, replace=True)\n                deps_A_to_B[i].extend(targets)\n\n    # B -> A dependencies\n    deps_B_to_A = [[] for _ in range(N)]\n    if mean_weight_B > 0:\n        lambda_B = d_dep * weights_B / mean_weight_B\n        num_deps_B = rng.poisson(lambda_B)\n        for j in range(N):\n            if num_deps_B[j] > 0:\n                targets = rng.choice(nodes_A, size=num_deps_B[j], p=prob_targets_A, replace=True)\n                deps_B_to_A[j].extend(targets)\n\n    return deps_A_to_B, deps_B_to_A\n\ndef find_lcc_mask(N, adj, functional_nodes):\n    \"\"\"\n    Finds the largest connected component (LCC) in the subgraph of functional nodes.\n    Returns a boolean mask of nodes in the LCC.\n    \"\"\"\n    if not np.any(functional_nodes):\n        return np.zeros(N, dtype=bool)\n\n    visited = np.zeros(N, dtype=bool)\n    max_comp_size = 0\n    lcc_nodes_list = []\n\n    potential_starts = np.where(functional_nodes)[0]\n\n    for i in potential_starts:\n        if not visited[i]:\n            current_comp = []\n            q = collections.deque([i])\n            visited[i] = True\n            \n            while q:\n                u = q.popleft()\n                current_comp.append(u)\n                for v in adj[u]:\n                    if functional_nodes[v] and not visited[v]:\n                        visited[v] = True\n                        q.append(v)\n            \n            if len(current_comp) > max_comp_size:\n                max_comp_size = len(current_comp)\n                lcc_nodes_list = current_comp\n\n    lcc_mask = np.zeros(N, dtype=bool)\n    if lcc_nodes_list:\n        lcc_mask[lcc_nodes_list] = True\n    return lcc_mask\n\n\ndef run_cascade(N, adj_A, adj_B, deps_A_to_B, deps_B_to_A, p, rng):\n    \"\"\"\n    Simulates the cascading failure for a given initial survival probability p.\n    \"\"\"\n    num_to_remove = int(np.floor((1 - p) * N))\n\n    # Initial shock\n    nodes_to_remove_A = rng.choice(N, size=num_to_remove, replace=False)\n    nodes_to_remove_B = rng.choice(N, size=num_to_remove, replace=False)\n\n    functional_A = np.ones(N, dtype=bool)\n    functional_B = np.ones(N, dtype=bool)\n    functional_A[nodes_to_remove_A] = False\n    functional_B[nodes_to_remove_B] = False\n\n    while True:\n        num_functional_before = np.sum(functional_A) + np.sum(functional_B)\n\n        # 1. Dependency rule\n        supported_A = np.zeros(N, dtype=bool)\n        for i in range(N):\n            if functional_A[i]:\n                for neighbor in deps_A_to_B[i]:\n                    if functional_B[neighbor]:\n                        supported_A[i] = True\n                        break\n        functional_A = supported_A\n\n        supported_B = np.zeros(N, dtype=bool)\n        for j in range(N):\n            if functional_B[j]:\n                for neighbor in deps_B_to_A[j]:\n                    if functional_A[neighbor]:\n                        supported_B[j] = True\n                        break\n        functional_B = supported_B\n        \n        # 2. Connectivity rule\n        if np.any(functional_A):\n            lcc_A_mask = find_lcc_mask(N, adj_A, functional_A)\n            functional_A = lcc_A_mask\n        \n        if np.any(functional_B):\n            lcc_B_mask = find_lcc_mask(N, adj_B, functional_B)\n            functional_B = lcc_B_mask\n\n        num_functional_after = np.sum(functional_A) + np.sum(functional_B)\n\n        if num_functional_before == num_functional_after:\n            break\n\n    s_A = np.sum(functional_A) / N\n    s_B = np.sum(functional_B) / N\n    \n    return s_A, s_B\n\ndef find_pc(N, z_A, z_B, d_dep, alpha, seed):\n    \"\"\"\n    Finds the mutual percolation threshold pc using binary search.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    tau = 0.05\n    \n    # Generate networks and dependencies once per test case\n    adj_A, degrees_A = generate_er_network(N, z_A, rng)\n    adj_B, degrees_B = generate_er_network(N, z_B, rng)\n    deps_A_to_B, deps_B_to_A = construct_dependencies(N, degrees_A, degrees_B, alpha, d_dep, rng)\n\n    def check(p):\n        s_A, s_B = run_cascade(N, adj_A, adj_B, deps_A_to_B, deps_B_to_A, p, rng)\n        return s_A >= tau and s_B >= tau\n\n    p_low, p_high = 0.0, 1.0\n    \n    # Binary search for pc\n    # 30 iterations give precision of 1/2^30, more than enough.\n    for _ in range(30):\n        p_mid = (p_low + p_high) / 2\n        if check(p_mid):\n            p_high = p_mid  # A solution exists, try smaller p\n        else:\n            p_low = p_mid   # No solution, need larger p\n    \n    return p_high\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}