{
    "hands_on_practices": [
        {
            "introduction": "为了将级联失效的抽象概念与现实世界系统联系起来，我们的第一个实践是模拟电力网络中的失效过程。该练习  使用简化的直流（DC）潮流模型，这是一种在电力系统分析中广泛使用的基本工具。通过实现这个模型，您将亲身体验输电线路的移除如何根据物理定律（如基尔霍夫定律）重新分配功率流，并最终可能导致更大范围的停电。",
            "id": "4266617",
            "problem": "考虑一个由 $N$ 个节点和 $E$ 条无向线路组成的网络，每条线路连接一对节点。该网络使用线性化直流（DC）潮流近似模型进行建模。设净注入功率向量为 $P \\in \\mathbb{R}^N$，其中对于节点 $i$，$P_i$ 为正值时表示发电，为负值时表示负荷。每条线路 $e$ 具有一个正电纳 $b_e$ 和一个热容量限制 $C_e > 0$。DC 模型假定，线路上 $e$ 的有功功率潮流 $f_e$ 与其两端电压相角的差值成正比，并且节点功率平衡由 Kirchhoff 电流定律强制执行。您需要计算潮流，检测过载，按特定规则移除过载线路，并模拟由此产生的连锁故障，直至达到稳定状态。\n\n建模基本原理：\n- Kirchhoff 电流定律：流入节点 $i$ 的潮流代数和等于该节点的净注入功率 $P_i$。\n- 线性化直流潮流关系：对于任意线路 $e = (u,v)$，其有功功率潮流满足 $f_e = b_e \\left(\\theta_u - \\theta_v\\right)$，其中 $\\theta_i$ 是节点 $i$ 的电压相角。\n- 基于关联矩阵的公式：使用一个有向关联矩阵 $A \\in \\mathbb{R}^{E \\times N}$，对于一条从节点 $u$ 指向节点 $v$ 的有向线路 $e=(u,v)$，定义 $A_{e,u} = +1$ 和 $A_{e,v} = -1$（其他位置为零）。Kirchhoff 电流定律可表示为 $A^\\top f = P$，线性化直流关系可表示为 $f = \\operatorname{diag}(b) \\, A \\, \\theta$，这在每个连通分量上，在固定一个参考相角后，导出一个加权拉普拉斯系统 $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$。除非为每个分量固定一个参考（松弛）角，否则加权拉普拉斯矩阵是奇异的。\n\n需要实现的连锁故障流程：\n1. 通过求解每个连通分量上的 $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$ 来计算线路潮流 $f_e$。每个分量中选择索引最小的节点作为平衡节点，并将其相角固定为零。当一个分量只有一个节点时，该分量中没有潮流。\n2. 对每条有效线路 $e$，定义利用率 $r_e = \\left|f_e\\right| / C_e$。\n3. 如果存在任何线路的 $r_e  1$，则精确移除一条线路：$r_e$ 值最大的那条线路。如果多条线路的 $r_e$ 值最大且出现并列，则移除线路索引最小的那条。重新计算连通分量，并从步骤 1 开始重复。\n4. 当所有剩余线路都满足 $r_e \\le 1$ 或没有线路剩下时，终止计算。最终状态被认为是稳定的。\n\n处理孤岛效应：\n- 线路的移除可能会使网络断开成多个连通分量（孤岛）。在每个孤岛中，将该孤岛内索引最小的节点定义为平衡节点。该平衡节点通过固定的参考角隐式地调整其净注入，从而吸收该孤岛内的任何总功率不平衡，这为其他节点的相角提供了一个可解的降阶拉普拉斯系统。这种方法纯属数学处理，并不对平衡节点容量施加约束。\n\n您的程序必须精确实现此连锁故障模拟，并对每个测试用例返回一个三元组 $[k, R, M]$，其中：\n- $k$ 是达到最终稳定状态前移除的线路数量（整数），\n- $R$ 是所有剩余线路的最终最大利用率，定义为 $R = \\max_e r_e$，其中 $r_e = \\left|f_e\\right| / C_e$，表示为一个四舍五入到六位小数的实数，\n- $M$ 是最终网络中的连通分量数量（包括孤立节点）（整数）。\n\n请使用以下参数值的测试套件。在所有情况下，节点由从 0 开始的整数标记，每条线路通过其 $(u,v)$ 端点、电纳 $b_e$ 和容量 $C_e$ 指定，并且 $A$ 的方向定义为从第一个端点 $u$ 指向第二个端点 $v$。\n\n测试用例 1（带弦的环形网络）：\n- $N = 4$\n- 线路：$e_0 = (0,1,b_0=5,C_0=8)$，$e_1 = (1,2,b_1=5,C_1=8)$，$e_2 = (2,3,b_2=5,C_2=8)$，$e_3 = (3,0,b_3=5,C_3=8)$，$e_4 = (1,3,b_4=5,C_4=6)$\n- 净注入功率：$P = [3,-1,-2,0]$\n\n测试用例 2（一个极限紧张的星形网络）：\n- $N = 5$\n- 线路：$e_0 = (0,1,b_0=4,C_0=4)$，$e_1 = (0,2,b_1=4,C_1=4)$，$e_2 = (0,3,b_2=4,C_2=4)$，$e_3 = (0,4,b_3=4,C_3=0.5)$\n- 净注入功率：$P = [4,-1,-1,-1,-1]$\n\n测试用例 3（三角形网络，容量充裕）：\n- $N = 3$\n- 线路：$e_0 = (0,1,b_0=10,C_0=100)$，$e_1 = (1,2,b_1=10,C_1=100)$，$e_2 = (0,2,b_2=10,C_2=100)$\n- 净注入功率：$P = [1,-0.5,-0.5]$\n\n测试用例 4（处于精确极限的链式网络）：\n- $N = 3$\n- 线路：$e_0 = (0,1,b_0=10,C_0=5)$，$e_1 = (1,2,b_1=10,C_1=5)$\n- 净注入功率：$P = [5,0,-5]$\n\n测试用例 5（因过载并列而需打破僵局的链式网络）：\n- $N = 4$\n- 线路：$e_0 = (0,1,b_0=10,C_0=3)$，$e_1 = (1,2,b_1=10,C_1=2)$，$e_2 = (2,3,b_2=10,C_2=100)$\n- 净注入功率：$P = [6,-2,-2,-2]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果是一个子列表 $[k,R,M]$。例如，输出必须类似于 $[[k_1,R_1,M_1],[k_2,R_2,M_2],\\dots]$，其中 $R_i$ 四舍五入到六位小数。",
            "solution": "该问题要求模拟电力网络中的连锁故障，该网络使用线性化直流（DC）潮流近似模型进行建模。模拟过程以离散步骤进行，在每一步中，计算功率潮流，移除最过载的输电线路，这可能导致网络分裂（孤岛化）和潮流的进一步重新分布，直到达到稳定状态。\n\n模拟的核心在于求解网络中每个连通分量的直流潮流方程。其控制方程是一个线性系统，源于 Kirchhoff 电流定律以及一个类似于欧姆定律的有功功率关系式。\n\n设网络有 $N$ 个节点和 $E$ 条线路。我们定义一个有向关联矩阵 $A \\in \\mathbb{R}^{E \\times N}$，其中对于一条从节点 $u$ 指向节点 $v$ 的线路 $e$，$A_{e,u} = 1$ 且 $A_{e,v} = -1$，该行所有其他条目为 0。设 $\\theta \\in \\mathbb{R}^N$ 为节点电压相角向量，$P \\in \\mathbb{R}^N$ 为净注入功率向量，$b \\in \\mathbb{R}^E$ 为线路电纳向量，$f \\in \\mathbb{R}^E$ 为线路上功率潮流向量。\n\n该模型由两个基本关系定义：\n1.  一条线路 $e=(u,v)$ 上的潮流 $f_e$（其电纳为 $b_e$）由 $f_e = b_e(\\theta_u - \\theta_v)$ 给出。用矩阵形式表示为 $f = \\mathrm{diag}(b) A \\theta$。\n2.  流入或流出任何节点的功率潮流之和必须与该节点的净注入功率相平衡。这是 Kirchhoff 电流定律（KCL），表示为 $A^\\top f = P$。\n\n将第一个方程代入第二个方程，得到相角的系统方程：\n$$\nA^\\top \\left( \\mathrm{diag}(b) A \\theta \\right) = P\n$$\n$$\n(A^\\top \\mathrm{diag}(b) A) \\theta = P\n$$\n这通常写作 $L \\theta = P$，其中 $L = A^\\top \\mathrm{diag}(b) A$ 是网络的加权拉普拉斯矩阵。任何图的拉普拉斯矩阵都是奇异的，这反映了一个物理事实：只有相角*差*决定功率潮流，而非其绝对值。为了获得唯一解，我们必须建立一个参考基准。\n\n问题指定了处理这种奇异性和网络潜在分裂的程序：\n1.  **识别连通分量**：使用图遍历算法（如广度优先搜索（BFS）或深度优先搜索（DFS））将网络划分为其连通分量。每个分量被视为一个独立的子问题。\n\n2.  **对每个分量进行求解**：对于每个连通分量 $\\mathcal{C}$（其节点集为 $\\mathcal{V}_\\mathcal{C}$，线路集为 $\\mathcal{E}_\\mathcal{C}$）：\n    - 如果 $|\\mathcal{V}_\\mathcal{C}| \\le 1$，则该分量内没有线路，因此不计算潮流。\n    - 如果 $|\\mathcal{V}_\\mathcal{C}|  1$，必须选择一个参考节点或“平衡”节点 $s$。问题规定选择 $\\mathcal{V}_\\mathcal{C}$ 中索引最小的节点作为平衡节点，并将其相角固定为 $\\theta_s = 0$。\n    - 令 $\\mathcal{V'}_\\mathcal{C} = \\mathcal{V}_\\mathcal{C} \\setminus \\{s\\}$ 为该分量中非平衡节点的集合。我们构建一个降阶线性系统 $L' \\theta' = P'$ 来求解非平衡节点相角 $\\theta'$。\n    - $L'$ 是分量的拉普拉斯矩阵 $L_\\mathcal{C}$ 通过移除对应于平衡节点 $s$ 的行和列得到的子矩阵。对于一个连通分量，这个降阶矩阵 $L'$ 是可逆的。\n    - $P'$ 是功率注入向量 $P$ 中对应于非平衡节点 $\\mathcal{V'}_\\mathcal{C}$ 的子向量。分量内的功率不平衡 $\\sum_{i \\in \\mathcal{V}_\\mathcal{C}} P_i$ 由平衡节点隐式吸收。\n    - 通过求解线性系统找到非平衡节点的相角：$\\theta' = (L')^{-1} P'$。\n    - 在确定了该分量所有节点相角 $\\theta$（包括 $\\theta_s=0$）之后，计算该分量内每条线路 $e=(u,v)$ 上的潮流 $f_e$：$f_e = b_e(\\theta_u - \\theta_v)$。\n\n整个模拟过程在一个循环中进行：\n\n**第一步：初始化**\n- 模拟从完整的线路集合开始。移除的线路数 $k$ 初始化为 $0$。\n\n**第二步：迭代连锁过程**\n模拟进入一个循环，直到没有线路过载为止。\n- **a) 潮流计算**：针对当前的网络拓扑，执行上述流程（分量识别和分量内线性系统求解）来计算所有线路潮流 $f_e$。\n- **b) 过载评估**：对于每条容量为 $C_e$ 的线路 $e$，计算其利用率：$r_e = |f_e| / C_e$。找出最大比率 $r_{\\max} = \\max_e r_e$。如果没有剩余线路，则 $r_{\\max}$ 设为 $0$。\n- **c) 稳定性检查**：如果 $r_{\\max} \\le 1$，网络是稳定的。模拟终止。\n- **d) 线路移除**：如果 $r_{\\max}  1$，网络不稳定。必须移除一条线路。要移除的线路 $e^*$ 是具有最大利用率 $r_{e^*} = r_{\\max}$ 的那条。如果存在并列，则选择原始索引最小的线路。从网络中移除线路 $e^*$，将 $k$ 增加 $1$，然后从第二步 a) 重复循环。\n\n**第三步：最终输出**\n终止时，最终状态由以下特征描述：\n- $k$：连锁故障期间移除的线路总数。\n- $R$：最终的最大利用率 $r_{\\max}$，四舍五入到六位小数。\n- $M$：最终稳定网络中的连通分量数量。\n\n这个综合算法确定性地模拟了指定的连锁故障过程。其实现需要稳健的图算法来寻找连通分量，以及数值线性代数程序来求解矩阵方程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_components(num_nodes, active_lines_indices, lines_def):\n    \"\"\"Finds connected components in the graph using BFS.\"\"\"\n    if num_nodes == 0:\n        return 0, []\n        \n    adj = [[] for _ in range(num_nodes)]\n    for line_idx in active_lines_indices:\n        u, v, _, _, _ = lines_def[line_idx]\n        adj[u].append(v)\n        adj[v].append(u)\n\n    visited = [False] * num_nodes\n    components = []\n    for i in range(num_nodes):\n        if not visited[i]:\n            component_nodes = set()\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head  len(q):\n                u = q[head]\n                head += 1\n                component_nodes.add(u)\n                for v in adj[u]:\n                    if not visited[v]:\n                        visited[v] = True\n                        q.append(v)\n            components.append(sorted(list(component_nodes)))\n    return len(components), components\n\ndef solve_cascade(num_nodes, lines, power_injections):\n    \"\"\"\n    Simulates the cascading failure process.\n    \"\"\"\n    lines_def = [(u, v, b, c, idx) for idx, (u, v, b, c) in enumerate(lines)]\n    active_lines_indices = set(range(len(lines_def)))\n    \n    removed_lines_count = 0\n\n    while True:\n        if not active_lines_indices:\n            num_components, _ = find_components(num_nodes, active_lines_indices, lines_def)\n            return removed_lines_count, 0.0, num_components\n\n        num_components, components = find_components(num_nodes, active_lines_indices, lines_def)\n\n        flows = {}  # Using dict to store flows by line index\n\n        for comp_nodes in components:\n            if len(comp_nodes) = 1:\n                continue\n\n            # Map component-local indices to global node indices\n            node_map = {node_idx: i for i, node_idx in enumerate(comp_nodes)}\n            \n            comp_lines = []\n            for line_idx in active_lines_indices:\n                u, v, _, _, _ = lines_def[line_idx]\n                if u in comp_nodes and v in comp_nodes:\n                    comp_lines.append(line_idx)\n            \n            if not comp_lines:\n                continue\n\n            comp_size = len(comp_nodes)\n            laplacian = np.zeros((comp_size, comp_size))\n\n            # Build weighted Laplacian for the component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                u_comp, v_comp = node_map[u], node_map[v]\n                laplacian[u_comp, u_comp] += b\n                laplacian[v_comp, v_comp] += b\n                laplacian[u_comp, v_comp] -= b\n                laplacian[v_comp, u_comp] -= b\n            \n            # Select slack bus (smallest index in component)\n            slack_node_global = comp_nodes[0]\n            slack_node_comp = node_map[slack_node_global]\n            \n            non_slack_indices_comp = [i for i in range(comp_size) if i != slack_node_comp]\n            non_slack_indices_global = [node for node in comp_nodes if node != slack_node_global]\n            \n            # Reduced system\n            reduced_laplacian = laplacian[np.ix_(non_slack_indices_comp, non_slack_indices_comp)]\n            reduced_p = np.array([power_injections[i] for i in non_slack_indices_global])\n\n            # Solve for non-slack angles\n            try:\n                non_slack_thetas = np.linalg.solve(reduced_laplacian, reduced_p)\n            except np.linalg.LinAlgError:\n                # This can happen if a component is just a line, making L' singular.\n                # It's an issue with how the problem is defined, but we must handle it.\n                # A better approach would be pseudo-inverse, but we stick to the problem.\n                # For safety, use pinv if solve fails.\n                non_slack_thetas = np.linalg.pinv(reduced_laplacian) @ reduced_p\n\n            # Reconstruct full theta vector for the component\n            thetas_comp = np.zeros(comp_size)\n            thetas_comp[non_slack_indices_comp] = non_slack_thetas\n            \n            thetas_global = {comp_nodes[i]: thetas_comp[i] for i in range(comp_size)}\n\n            # Calculate flows for lines in this component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                flow = b * (thetas_global[u] - thetas_global[v])\n                flows[line_idx] = flow\n\n        # Assess overload\n        max_ratio = -1.0\n        line_to_remove = -1\n\n        ratios = []\n        for line_idx in sorted(list(active_lines_indices)):\n            u, v, b, c, _ = lines_def[line_idx]\n            flow_val = flows.get(line_idx, 0.0)\n            ratio = abs(flow_val) / c if c > 0 else float('inf')\n            ratios.append((ratio, line_idx))\n\n        if not ratios:\n            # This case is handled at the loop start, but as a safeguard\n            max_ratio_val = 0.0\n        else:\n            # Sort by ratio (desc), then line index (asc)\n            ratios.sort(key=lambda x: (-x[0], x[1]))\n            max_ratio_val = ratios[0][0]\n            line_to_remove = ratios[0][1]\n\n        if max_ratio_val = 1.0:\n            final_max_ratio = max_ratio_val if ratios else 0.0\n            return removed_lines_count, final_max_ratio, num_components\n        else:\n            active_lines_indices.remove(line_to_remove)\n            removed_lines_count += 1\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 5, 8), (1, 2, 5, 8), (2, 3, 5, 8), (3, 0, 5, 8), (1, 3, 5, 6)],\n            \"P\": [3, -1, -2, 0]\n        },\n        {\n            \"N\": 5,\n            \"lines\": [(0, 1, 4, 4), (0, 2, 4, 4), (0, 3, 4, 4), (0, 4, 4, 0.5)],\n            \"P\": [4, -1, -1, -1, -1]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 100), (1, 2, 10, 100), (0, 2, 10, 100)],\n            \"P\": [1, -0.5, -0.5]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 5), (1, 2, 10, 5)],\n            \"P\": [5, 0, -5]\n        },\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 10, 3), (1, 2, 10, 2), (2, 3, 10, 100)],\n            \"P\": [6, -2, -2, -2]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        k, R, M = solve_cascade(case[\"N\"], case[\"lines\"], case[\"P\"])\n        # Format the result with R rounded to 6 decimal places\n        results.append(f\"[{k},{R:.6f},{M}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在了解了基于物理模型的失效后，我们转向一个更普适的、基于网络拓扑的级联失效模型 。这个练习的核心思想是，节点的负载由其在网络中的中心性（具体为介数中心性）决定，而其容量则与初始负载成正比。通过在一个无标度网络上模拟这个过程，您将探索复杂网络的“鲁棒而脆弱”特性，即网络在随机故障面前表现出弹性，但对特定节点的蓄意攻击却异常敏感。",
            "id": "4266621",
            "problem": "考虑一个简单的无向网络模型，该模型有 $N$ 个节点，其度分布是重尾的，并近似于幂律 $P(k) \\propto k^{-\\gamma}$。我们研究当流量沿最短路径路由时，由负载重分配引起的级联失效。其支配原则如下：所有节点对之间的最短路径路由，由介数中心性定义的节点负载，根据初始负载和非负容忍度参数得出的每个节点的固定容量，以及当当前负载超过固定容量时发生的迭代失效。\n\n定义与基本原理：\n1. 设网络为一个无向简单图 $G = (V,E)$，其中有 $|V| = N$ 个节点，邻接关系 $A_{ij} \\in \\{0,1\\}$ 表示节点 $i$ 和节点 $j$ 之间是否存在链接。设节点 $i$ 的度为 $k_i = \\sum_{j} A_{ij}$。\n2. 假设流量沿最短路径路由。对于每一对不同的无序节点对 $\\{s,t\\}$，考虑从 $s$到 $t$ 的所有最短路径。节点 $v$ 的介数中心性 $B(v)$ 定义为\n$$\nB(v) = \\sum_{\\substack{s,t \\in V \\\\ s \\neq t \\neq v}} \\frac{\\sigma_{st}(v)}{\\sigma_{st}},\n$$\n其中 $\\sigma_{st}$ 是 $s$ 和 $t$ 之间的最短路径数量，而 $\\sigma_{st}(v)$ 是其中经过节点 $v$ 的最短路径数量。此定义适用于无边权重的无向图。\n3. 节点 $i$ 的初始负载 $L_i^{(0)}$ 由其在完整网络 $G$ 上计算的介数中心性定义，即 $L_i^{(0)} = B(i)$。\n4. 每个节点 $i$ 被分配一个与其初始负载成正比的固定容量 $C_i$，带有一个非负的容忍度参数 $\\alpha$，公式为\n$$\nC_i = (1+\\alpha) \\, L_i^{(0)}.\n$$\n5. 通过移除一个代表典型高影响攻击的单一节点来触发级联失效。在此，移除具有最大初始负载 $L_{v^\\star}^{(0)}$ 的节点 $v^\\star$（若负载相同，则按度最大、然后索引最小的顺序选择）。移除后，在每次级联迭代 $t$ 中，通过对剩余节点应用相同的介数中心性定义，在残余图上重新计算负载 $L_i^{(t)}$。在每次迭代中，任何当前负载 $L_i^{(t)}$ 超过其固定容量 $C_i$ 的剩余节点 $i$ 都会失效并从网络中移除。当没有剩余节点过载时，级联停止。\n6. 级联规模 $S(\\alpha)$ 定义为终止时被移除的节点（包括初始攻击的节点）所占的比例，表示为 $[0,1]$ 范围的小数。\n\n目标：\n基于以上原则，实现一个程序，该程序能够：\n- 使用期望度构造生成一个 $P(k) \\propto k^{-\\gamma}$ 的无标度网络，并从 $k_{\\min}$ 和 $k_{\\max}$ 之间的截断幂律分布中采样度 $k_i$。使用 Chung–Lu 期望度模型以概率 $p_{ij} = \\min\\left(1, \\frac{k_i k_j}{\\sum_{\\ell} k_{\\ell}} \\right)$ 为 $i \\neq j$ 独立放置边，从而生成一个无向简单图。该模型必须避免自环和多重边。\n- 使用 Brandes 算法计算无权无向图的节点介数中心性以获得负载。\n- 在固定容量规则 $C_i = (1+\\alpha)L_i^{(0)}$ 下，为每个指定的容忍度 $\\alpha$ 模拟级联失效过程。\n- 返回每个测试的 $\\alpha$ 对应的级联规模 $S(\\alpha)$，并按如下方式识别“鲁棒但脆弱”的体系：如果在一个参数集中，至少 $\\lceil 0.6 m \\rceil$ 个被测试的容忍度值（其中 $m$ 是该集合中 $\\alpha$ 值的数量）产生的级联规模 $\\leq 0.1$，同时在所有被测试的 $\\alpha$ 值中，最大级联规模 $\\geq 0.5$，则将该参数集标记为“鲁棒但脆弱”。\n\n所有计算都是纯组合的且无单位，因为负载和容量是通过路径计数定义的。不涉及角度。所有级联规模均以小数形式返回。不允许使用百分比。\n\n测试套件：\n您的程序必须使用以下参数集测试套件，每个参数集指定为元组 $(N,\\gamma,\\text{seed},\\{ \\alpha \\text{ values} \\})$。必须设置随机种子以确保确定性结果。\n\n- 案例 A (正常路径，中等 $N$ 的重尾分布): $(N=\\;60,\\;\\gamma=\\;2.5,\\;\\text{seed}=\\;12345,\\;\\{\\alpha=\\;0.0,\\;0.1,\\;0.2,\\;0.5\\})$。\n- 案例 B (较轻的尾部，相同的 $N$): $(N=\\;60,\\;\\gamma=\\;3.5,\\;\\text{seed}=\\;54321,\\;\\{\\alpha=\\;0.0,\\;0.1,\\;0.2,\\;0.5\\})$。\n- 案例 C (更重的尾部，较小的 $N$，更宽的容忍度扫描): $(N=\\;40,\\;\\gamma=\\;2.2,\\;\\text{seed}=\\;10101,\\;\\{\\alpha=\\;0.0,\\;0.05,\\;0.1,\\;0.2,\\;0.3,\\;1.0\\})$。\n- 案例 D (边界连通性压力，中等 $N$，宽尾): $(N=\\;50,\\;\\gamma=\\;2.8,\\;\\text{seed}=\\;20202,\\;\\{\\alpha=\\;0.0,\\;0.02,\\;0.05,\\;0.1,\\;0.2\\})$。\n\n对于所有案例，使用 $k_{\\min}=\\;2$ 和 $k_{\\max}=\\;\\left\\lfloor \\frac{N}{2} \\right\\rfloor$。采样必须使用截断到 $[k_{\\min},k_{\\max}]$ 区间的连续幂律的逆累积分布函数，然后四舍五入到界限内的最近整数，并通过在界限内随机调整一个度的值 $\\pm 1$（如有必要）来确保 $\\sum_i k_i$ 为偶数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个列表，每个测试案例对应一个元素。每个测试案例元素本身也是一个列表，按顺序包含指定 $\\alpha$ 值的级联规模，后跟一个布尔型的“鲁棒但脆弱”标志。整个输出不得包含任何空白字符。例如，包含两个案例的一行输出如下所示\n$$\n[ [ s_{A,1}, s_{A,2}, \\dots, r_A ], [ s_{B,1}, s_{B,2}, \\dots, r_B ] ]\n$$\n但没有任何空格。因此，要求的最终输出格式为\n$$\n[[S_A(\\alpha_1),S_A(\\alpha_2),\\dots,\\text{flag}_A],[S_B(\\alpha_1),S_B(\\alpha_2),\\dots,\\text{flag}_B],[S_C(\\alpha_1),\\dots,\\text{flag}_C],[S_D(\\alpha_1),\\dots,\\text{flag}_D]],\n$$\n其中每个 $S(\\alpha_j)$ 是一个小数，每个标志是一个布尔值。\n\n您的程序不得读取任何输入，并且必须按规定在内部生成测试套件。输出必须严格为一行，与上述格式匹配，不得包含任何额外文本。",
            "solution": "用户提供了一份关于无标度网络中级联失效模拟的详细问题陈述。在继续之前，我的首要任务是验证该问题的科学合理性、完整性和清晰度。\n\n### 问题验证\n\n我现在将对所提供的问题陈述进行系统性验证。\n\n#### 步骤 1：提取给定信息\n\n问题提供了以下数据、定义和程序：\n- **网络结构**：一个具有 $N$ 个节点的无向简单图 $G=(V,E)$。度分布被指定为重尾分布，近似于 $P(k) \\propto k^{-\\gamma}$。\n- **网络生成**：\n    - 将使用期望度构造法生成一个无标度网络。\n    - 节点度 $k_i$ 从 $[k_{\\min}, k_{\\max}]$ 上的截断幂律分布中采样。指定的采样方法是对连续分布进行逆变换采样，然后四舍五入到最近的整数，并限制在边界内。\n    - 一项明确要求是通过调整一个随机选择的度来确保度之和 $\\sum_i k_i$ 为偶数。\n    - 将使用 Chung–Lu 模型生成边，对于 $i \\neq j$，边的概率为 $p_{ij} = \\min\\left(1, \\frac{k_i k_j}{\\sum_{\\ell} k_{\\ell}} \\right)$。\n- **负载与容量**：\n    - 节点上的负载由其介数中心性定义，$L_i = B(i)$，为无权无向图计算：$B(v) = \\sum_{s \\neq t \\neq v} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}$，针对不同的无序对 $\\{s,t\\}$。指定使用 Brandes 算法进行此计算。\n    - 节点容量定义为 $C_i = (1+\\alpha) L_i^{(0)}$，其中 $L_i^{(0)}$ 是完整网络上的初始负载，$\\alpha$ 是一个非负容忍度参数。\n- **级联动力学**：\n    - 通过移除具有最高初始负载 $L^{(0)}$ 的节点 $v^\\star$ 来引发级联。平局首先按最高度打破，然后按最低节点索引打破。\n    - 失效过程是迭代的。在每一步中，在剩余网络上重新计算负载。任何当前负载 $L_i^{(t)}$ 超过其固定容量 $C_i$ 的节点 $i$ 都将被移除。\n    - 当某次迭代中没有新的节点失效时，级联停止。\n- **度量指标**：\n    - 主要度量是级联规模 $S(\\alpha)$，定义为被移除的节点总数（包括初始节点）的比例。\n    - 如果满足两个条件，则一个参数集被定义为“鲁棒但脆弱”（RYF）体系：（1）在 $m$ 个被测试的 $\\alpha$ 值中，至少有 $\\lceil 0.6 m \\rceil$ 个值的级联规模 $S(\\alpha) \\leq 0.1$；（2）在所有被测试的 $\\alpha$ 值中，最大级联规模 $\\geq 0.5$。\n- **测试套件**：\n    - 提供了四个具体的测试用例，每个用例都带有参数 $(N, \\gamma, \\text{seed}, \\{\\alpha \\text{ values}\\})$。\n    - 所有用例的固定参数是 $k_{\\min}=2$ 和 $k_{\\max}=\\lfloor N/2 \\rfloor$。\n    - 为了确定性的可复现性，强制要求为每个用例使用随机种子。\n- **输出格式**：一个单行的字符串，表示一个列表的列表，无空格，包含每个测试用例的级联规模和 RYF 布尔标志。\n\n#### 步骤 2：使用提取的给定信息进行验证\n\n- **科学依据**：该问题牢固地植根于复杂系统和网络科学领域。所描述的模型是研究基于负载的级联失效的经典模型，与该领域的开创性工作（例如，Motter  Lai, 2002）紧密相随。所有组成部分——幂律网络、Chung-Lu 模型、作为负载的介数中心性以及迭代失效机制——都是标准且广为接受的概念。该问题没有违反任何科学或数学原理。\n- **适定性**：该问题是极其适定的。为每个测试用例提供特定的随机种子确保了随机网络生成过程是完全确定性和可复现的。由于有明确的平局打破规则，初始攻击是确定性的。级联动力学也是确定性的。因此，每个测试用例都存在唯一、稳定且有意义的解。\n- **客观性**：语言精确、量化，没有主观性。所有术语要么是该领域的标准术语，要么有明确定义。\n- **完整性与一致性**：问题陈述是自洽的。它提供了所有必要的参数、算法（Chung-Lu、Brandes）和定义。度采样和调整过程的描述足够详细，可以明确无误地实现。没有内部矛盾。\n- **可行性**：网络规模（$N \\leq 60$）足够小，使得指定的计算，特别是 Brandes 算法（$O(N \\cdot M)$，其中 $M$ 是边数）的重复应用，在合理的时间范围内是计算可行的。\n\n#### 步骤 3：结论与行动\n\n问题陈述是**有效的**。这是一个结构良好、科学合理且计算上可行的任务，测试了计算网络科学中的基本概念。我现在将着手实现解决方案。\n\n### 解决方案设计\n\n解决方案将使用 Python 实现，严格遵守指定的库（`numpy`，标准库）。整体结构将是一个封装所有逻辑的单一函数 `solve()`。\n\n1.  **主循环**：`solve()` 函数将遍历提供的四个测试用例。对于每个用例，它将调用一个专门的函数来执行完整的模拟。\n\n2.  **网络生成**：将创建一个辅助函数 `_generate_network`。它将接收 $N, \\gamma, k_{\\min}, k_{\\max}$ 和一个 `numpy.random.Generator` 实例作为输入。\n    - **度序列**：它将首先生成一个目标度序列。这涉及对指数为 $-\\gamma$ 的连续截断幂律分布使用逆变换采样方法。逆 CDF 的公式是 $x(u) = \\left[ u(k_{\\max}^{1-\\gamma} - k_{\\min}^{1-\\gamma}) + k_{\\min}^{1-\\gamma} \\right]^{1/(1-\\gamma)}$，其中 $u$ 是一个均匀随机变量。生成的连续样本将被四舍五入到最近的整数，并限制在 $[k_{\\min}, k_{\\max}]$ 内。将检查度之和，如果为奇数，将通过将一个度 $\\pm 1$ 调整来使其为偶数，以确保图的可实现性。\n    - **边生成**：将使用 Chung-Lu 模型填充邻接矩阵。对于每对节点 $(i, j)$ 且 $i",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to solve the cascading failure problem.\n    It encapsulates all logic, including network generation, cascade simulation,\n    and result formatting, as per the problem specification.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (60, 2.5, 12345, [0.0, 0.1, 0.2, 0.5]),\n        (60, 3.5, 54321, [0.0, 0.1, 0.2, 0.5]),\n        (40, 2.2, 10101, [0.0, 0.05, 0.1, 0.2, 0.3, 1.0]),\n        (50, 2.8, 20202, [0.0, 0.02, 0.05, 0.1, 0.2]),\n    ]\n    \n    def _generate_degrees(N, gamma, k_min, k_max, rng):\n        \"\"\"Generates a degree sequence from a truncated power-law distribution.\"\"\"\n        # Using Inverse Transform Sampling for the continuous power-law\n        u = rng.random(N)\n        if gamma == 1.0: # Should not happen with given gammas, but for completeness\n            exp_term = np.exp(u * (np.log(k_max) - np.log(k_min)))\n            continuous_degrees = k_min * exp_term\n        else:\n            g = 1.0 - gamma\n            k_min_g = k_min**g\n            k_max_g = k_max**g\n            continuous_degrees = (u * (k_max_g - k_min_g) + k_min_g)**(1.0/g)\n\n        degrees = np.round(continuous_degrees).astype(int)\n        degrees = np.clip(degrees, k_min, k_max)\n\n        # Ensure sum of degrees is even for graph realizability\n        if np.sum(degrees) % 2 != 0:\n            indices = np.arange(N)\n            rng.shuffle(indices)\n            for i in indices:\n                if degrees[i] + 1 = k_max:\n                    degrees[i] += 1\n                    break\n                elif degrees[i] - 1 >= k_min:\n                    degrees[i] -= 1\n                    break\n        return degrees\n\n    def _generate_network(N, gamma, k_min, k_max, rng):\n        \"\"\"Generates a scale-free network using the Chung-Lu model.\"\"\"\n        degrees = _generate_degrees(N, gamma, k_min, k_max, rng)\n        sum_k = np.sum(degrees)\n        adj_matrix = np.zeros((N, N), dtype=int)\n\n        if sum_k == 0:\n            return adj_matrix, degrees\n\n        for i in range(N):\n            for j in range(i + 1, N):\n                p_ij = min(1.0, (degrees[i] * degrees[j]) / sum_k)\n                if rng.random()  p_ij:\n                    adj_matrix[i, j] = 1\n                    adj_matrix[j, i] = 1\n        \n        # Recalculate degrees from the generated graph, as Chung-Lu model only matches expected degrees.\n        actual_degrees = np.sum(adj_matrix, axis=1)\n        return adj_matrix, actual_degrees\n\n    def _calculate_betweenness(adj_list, active_nodes):\n        \"\"\"Calculates betweenness centrality using Brandes' algorithm for unweighted graphs.\"\"\"\n        nodes_list = list(active_nodes)\n        betweenness = {node: 0.0 for node in nodes_list}\n\n        for s in nodes_list:\n            S = []\n            P = {v: [] for v in nodes_list}\n            sigma = {v: 0.0 for v in nodes_list}; sigma[s] = 1.0\n            d = {v: -1 for v in nodes_list}; d[s] = 0\n            \n            Q = deque([s])\n\n            while Q:\n                v = Q.popleft()\n                S.append(v)\n                for w in adj_list.get(v, []):\n                    if w not in active_nodes:\n                        continue\n                    if d[w]  0:\n                        Q.append(w)\n                        d[w] = d[v] + 1\n                    if d[w] == d[v] + 1:\n                        sigma[w] += sigma[v]\n                        P[w].append(v)\n            \n            delta = {v: 0.0 for v in nodes_list}\n            while S:\n                w = S.pop()\n                for v in P[w]:\n                    if sigma[w] != 0:\n                        delta[v] += (sigma[v] / sigma[w]) * (1.0 + delta[w])\n                if w != s:\n                    betweenness[w] += delta[w]\n        \n        # For undirected graphs, divide by 2\n        for node in betweenness:\n            betweenness[node] /= 2.0\n            \n        return betweenness\n\n    def _run_single_case(case_params):\n        \"\"\"Runs the entire simulation for a single test case.\"\"\"\n        N, gamma, seed, alphas = case_params\n        k_min = 2\n        k_max = N // 2\n        rng = np.random.default_rng(seed)\n\n        adj_matrix, initial_degrees = _generate_network(N, gamma, k_min, k_max, rng)\n        adj_list = {i: list(np.where(adj_matrix[i] == 1)[0]) for i in range(N)}\n        \n        full_node_set = set(range(N))\n        initial_loads = _calculate_betweenness(adj_list, full_node_set)\n\n        # Find the node v* to remove\n        if not initial_loads: # Handle case of empty/edgeless graph\n            v_star = 0\n        else:\n            max_load = -1.0\n            candidates = []\n            for i in range(N):\n                load_i = initial_loads.get(i, 0.0)\n                if load_i > max_load:\n                    max_load = load_i\n                    candidates = [i]\n                elif load_i == max_load:\n                    candidates.append(i)\n            \n            if len(candidates) > 1:\n                max_deg = -1\n                deg_candidates = []\n                for i in candidates:\n                    if initial_degrees[i] > max_deg:\n                        max_deg = initial_degrees[i]\n                        deg_candidates = [i]\n                    elif initial_degrees[i] == max_deg:\n                        deg_candidates.append(i)\n                candidates = deg_candidates\n\n            v_star = min(candidates)\n\n        cascade_sizes = []\n        for alpha in alphas:\n            capacities = {i: (1 + alpha) * initial_loads.get(i, 0.0) for i in range(N)}\n            \n            removed_nodes = {v_star}\n            active_nodes = full_node_set - removed_nodes\n\n            while True:\n                if not active_nodes: break\n                \n                current_loads = _calculate_betweenness(adj_list, active_nodes)\n                newly_failed = set()\n                for i in active_nodes:\n                    load_i = current_loads.get(i, 0.0)\n                    # Node fails if load exceeds capacity. Capacity can be 0.\n                    if load_i > capacities[i]:\n                        newly_failed.add(i)\n                \n                if not newly_failed:\n                    break\n                \n                active_nodes -= newly_failed\n                removed_nodes.update(newly_failed)\n\n            S_alpha = len(removed_nodes) / N\n            cascade_sizes.append(S_alpha)\n\n        # Evaluate robust-yet-fragile condition\n        m = len(alphas)\n        num_robust = sum(1 for s in cascade_sizes if s = 0.1)\n        max_cascade = max(cascade_sizes) if cascade_sizes else 0.0\n        is_ryf = (num_robust >= np.ceil(0.6 * m)) and (max_cascade >= 0.5)\n\n        return cascade_sizes + [is_ryf]\n\n    results = []\n    for case in test_cases:\n        results.append(_run_single_case(case))\n\n    # Final print statement in the exact required format.\n    case_strings = []\n    for res_list in results:\n        str_items = []\n        for item in res_list:\n            if isinstance(item, bool):\n                str_items.append(str(item).lower())\n            else:\n                # Format to a reasonable number of decimal places for consistency\n                str_items.append(f\"{item:.10f}\".rstrip('0').rstrip('.') if '.' in f\"{item:.10f}\" else f\"{item:.0f}\")\n        case_strings.append(f\"[{','.join(str_items)}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们最后的实践将挑战从“分析”转向“优化” 。您不再是分析一个给定初始故障引发的后果，而是需要在一个网络中，通过穷举搜索，找到一个特定规模的初始节点移除集合，以最大化最终的级联失效规模。这个练习不仅能深化您对级联动态的理解，还将引导您思考网络韧性中的组合优化问题，并揭示为何贪心算法在此类问题中可能失效，这与“子模性”这一重要理论概念相关。",
            "id": "4266579",
            "problem": "给定一个有限加权无向网络，由图 $G = (V, E)$ 表示，其中 $|V| = n$。同时给定一个非负基础负载向量 $\\ell \\in \\mathbb{R}_{\\ge 0}^{n}$、一个非负容量向量 $c \\in \\mathbb{R}_{\\ge 0}^{n}$，以及一个非负对称邻接权重矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$，其中对于所有 $i,j \\in V$ 都有 $W_{ij} = W_{ji}$，且对于所有 $i \\in V$ 都有 $W_{ii} = 0$。对于任意节点 $i \\in V$，其邻居节点集合定义为 $N(i) = \\{ j \\in V : W_{ij}  0 \\}$。考虑一个具有以下机制的离散时间负载重分配级联过程：\n\n- 负载以轮次（round）进行演化，并存储于向量 $L \\in \\mathbb{R}_{\\ge 0}^{n}$ 中；初始时 $L = \\ell$。\n- 定向移除策略是一个子集 $S \\subseteq V$，其基数为 $|S| = k$。在第 $t = 0$ 轮，集合 $S$ 中的所有节点都失效（被移除），每个此类节点的当前负载将按边权重比例重新分配给其存活的邻居节点。\n- 更精确地说，当一个节点 $i$ 在一轮开始时失效，计算其存活的邻居节点集合 $N_{\\text{surv}}(i) = \\{ j \\in N(i) : j \\text{ 在该轮开始时未失效} \\}$。令 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。如果 $\\sigma(i)  0$，则每个存活的邻居节点 $j \\in N_{\\text{surv}}(i)$ 在该轮中会收到 $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$ 的额外负载；如果 $\\sigma(i) = 0$，则负载 $L_i$ 被丢弃（丢失）。\n- 在计算完当前轮次中所有失效节点的负载重分配并应用于 $L$ 之后，这些失效节点将被永久移除，不再接收任何负载。如果一个存活节点 $j$ 的负载 $L_j  c_j$，它将在下一轮失效。这种同步更新过程将重复进行，直到没有新的失效发生。\n- 定义级联规模函数 $f(S)$ 为从初始移除集合 $S$ 开始，最终失效的节点总数（包括 $S$ 中的节点）。\n\n目标是构建一个给定基数 $k$ 的最坏情况定向移除策略 $S^{\\star}$，以在所述的负载重分配规则下最大化级联规模 $f(S)$，并使用子模性论证或提供子模性失效的反例来证明您所构建策略的最优性，并解释在此类情况下为何需要通过穷举搜索来获得精确的最优解。\n\n您的程序必须实现上述级联模型，并针对下面的每个测试用例，通过搜索所有大小为 $k$ 的子集 $S \\subseteq V$ 来计算精确的最坏情况移除集合 $S^{\\star}$ 和相应的最大级联规模 $f(S^{\\star})$。当 $f(S)$ 出现平局时，应选择节点索引升序排序后字典序最小的集合 $S$。所有节点索引都是从 0 开始的整数。\n\n所有答案都是纯数学的且无单位。本问题不涉及角度和物理单位。\n\n测试套件规范：\n\n请为以下测试用例提供结果。在每个用例中，网络通过列出非零对称边及其权重，以及基础负载 $\\ell$、容量 $c$ 和移除预算 $k$ 来指定。\n\n- 测试用例 $1$ (顺利路径星形级联):\n  - 节点: $n = 5$，标记为 $0, 1, 2, 3, 4$。\n  - 非零对称边和权重: $(0,1)$ 权重为 $1$，$(0,2)$ 权重为 $1$，$(0,3)$ 权重为 $1$，$(0,4)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.80, 0.31, 0.31, 0.31, 0.31]$。\n  - 容量: $c = [1.20, 0.50, 0.50, 0.50, 0.50]$。\n  - 预算: $k = 1$。\n\n- 测试用例 $2$ (边界情况，无移除):\n  - 节点: $n = 4$，标记为 $0, 1, 2, 3$。\n  - 非零对称边和权重: $(0,1)$ 权重为 $1$，$(1,2)$ 权重为 $1$，$(2,3)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.20, 0.20, 0.20, 0.20]$。\n  - 容量: $c = [0.50, 0.50, 0.50, 0.50]$。\n  - 预算: $k = 0$。\n\n- 测试用例 $3$ (边缘情况协同效应及子模性反例):\n  - 节点: $n = 5$，标记为 $0, 1, 2, 3, 4$。\n  - 非零对称边和权重: $(0,2)$ 权重为 $1$，$(1,2)$ 权重为 $1$，$(2,3)$ 权重为 $1$，$(2,4)$ 权重为 $1$。\n  - 基础负载: $\\ell = [0.50, 0.50, 0.60, 0.40, 0.40]$。\n  - 容量: $c = [0.60, 0.60, 1.20, 0.50, 0.50]$。\n  - 预算: $k = 2$。\n\n要求的最终输出格式：\n\n您的程序应生成单行输出，其中包含三个测试用例的结果，格式为用方括号括起来的逗号分隔列表。每个结果必须是一个双元素列表，包含最大级联规模（一个整数）和对应的字典序最小的最大化集合 $S^{\\star}$（一个整数列表）。例如，输出应类似于 $[[f_1, S_1],[f_2, S_2],[f_3, S_3]]$，其中 $f_i$ 是测试用例 $i$ 的最大级联规模，$S_i$ 是最大化集合。\n\n您的程序不得读取任何输入，并且除了要求的单行输出外，不得打印任何其他文本。",
            "solution": "所提供的问题陈述是网络科学和复杂系统领域中一个有效且定义明确的问题。它涉及通过选择一个最优的初始失效节点集来最大化网络上的级联规模函数。\n\n该问题具有科学依据，是基于负载的级联失效的形式化表示，这一现象在电力网格和金融网络等情境中得到研究。其动力学是确定性的，并以数学精度定义，确保了对于任何初始失效集合 $S$，级联规模函数 $f(S)$ 都是明确定义的。给定有限的节点数 $n$ 和固定的移除预算 $k$，最大化 $f(S)$ 的最优集合 $S^{\\star}$ 保证存在。问题是完整的，提供了所有必要的参数和规则，并且不包含内部矛盾或歧义。对于测试用例中指定的小型网络规模，通过穷举搜索找到精确解的要求在计算上是可行的。\n\n我们将首先形式化级联模型，然后讨论优化方法及其理由，最后概述实现算法。\n\n**1. 级联模型**\n\n在任何离散时间步 $t \\ge 0$，网络的状态可以通过负载向量 $L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$ 和失效节点集合（我们称之为 $\\mathcal{F}^{(t)} \\subseteq V$）来描述。\n\n*   **初始化 ($t=0$):**\n    选择一个节点集合 $S \\subseteq V$（其中 $|S|=k$）进行初始移除。所有失效节点的集合初始化为 $\\mathcal{F}^{(0)} = S$。初始负载向量是基础负载向量 $L = \\ell$。然而，问题规定 $S$ 中的节点是第一批失效并重新分配其负载的节点。我们可以将其建模为一系列轮次。令 $F_0 = S$ 为在第 $0$ 轮失效的节点集合。\n\n*   **级联轮次 ($t=0, 1, 2, \\dots$):**\n    级联过程以同步轮次进行。在每一轮 $t$ 中，都有一组节点 $F_t$ 失效。\n\n    1.  如果 $F_t = \\emptyset$，级联已经终止。过程停止。\n    2.  一个中间负载增量向量 $\\Delta L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$ 被初始化为全零。\n    3.  对于当前轮次中每个正在失效的节点 $i \\in F_t$，其负载 $L_i$ 必须被重新分配。其尚未失效的邻居节点集合为 $N_{\\text{surv}}(i) = N(i) \\setminus \\mathcal{F}_{\\text{total}}$。\n    4.  到这些存活邻居节点的权重总和为 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。\n    5.  如果 $\\sigma(i)  0$，每个存活的邻居节点 $j \\in N_{\\text{surv}}(i)$ 会收到额外的负载。由于节点 $i$ 失效，节点 $j$ 的增量为 $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$。此值被加到 $\\Delta L_j^{(t)}$ 上。如果 $\\sigma(i)=0$，负载 $L_i$ 将丢失。\n    6.  在计算完来自 $F_t$ 中所有节点的负载增量后，同步更新存活节点的负载：对于所有 $j \\notin \\mathcal{F}_{\\text{total}}$，$L_j \\leftarrow L_j + \\Delta L_j^{(t)}$。请注意，失效节点本身的负载不会再被更新。\n    7.  所有失效节点的集合被更新：$\\mathcal{F}_{\\text{total}} \\leftarrow \\mathcal{F}_{\\text{total}} \\cup F_t$。\n    8.  识别出将在下一轮失效的新节点集合 $F_{t+1}$。这些是尚未失效但其新负载超过其容量的节点：\n        $$F_{t+1} = \\{ j \\in V \\setminus \\mathcal{F}_{\\text{total}} : L_j  c_j \\}$$\n    9.  该过程以集合 $F_{t+1}$ 进入第 $t+1$ 轮并重复。\n\n对于一个初始集合 $S$，级联的总规模由函数 $f(S) = |\\mathcal{F}_{\\text{final}}|$ 给出，其中 $\\mathcal{F}_{\\text{final}}$ 是过程终止时的集合 $\\mathcal{F}_{\\text{total}}$。\n\n**2. 优化与论证**\n\n目标是找到一个集合 $S^{\\star}$ 来解决以下优化问题：\n$$ S^{\\star} = \\underset{S \\subseteq V, |S|=k}{\\text{argmax}} \\; f(S) $$\n当出现平局时，通过选择字典序最小的集合 $S$ 来打破。\n\n这是一个组合优化问题。对于许多此类问题，如果目标函数 $f(S)$ 是子模的，一个简单的贪心算法就可以提供一个有性能保证的解。如果一个集合函数 $f$ 表现出“收益递减”的特性，那么它就是子模的。形式上，对于任何集合 $A \\subseteq B \\subseteq V$ 和任何元素 $v \\in V \\setminus B$，必须满足：\n$$ f(A \\cup \\{v\\}) - f(A) \\ge f(B \\cup \\{v\\}) - f(B) $$\n然而，阈值模型中的级联规模函数通常不是子模的。问题陈述正确地暗示了这种可能性。我们可以使用测试用例 3 来证明子模性的失效。\n\n令 $f$ 为测试用例 3 的级联规模函数。\n-   令 $A = \\{0\\}$ 和 $B = \\emptyset$。注意 $B \\subseteq A$。我们来评估添加节点 $\\{1\\}$ 的边际增益。\n-   $f(\\emptyset) = 0$，因为没有节点初始过载。\n-   $f(\\{0\\})$：节点 $0$ 失效。其负载 $L_0=0.5$ 转移给其唯一的邻居节点 $2$。节点 $2$ 的负载变为 $L_2' = 0.6 + 0.5 = 1.1$。这小于其容量 $c_2 = 1.2$。级联停止。因此，$f(\\{0\\}) = 1$。\n-   $f(\\{1\\})$：与节点 $0$ 对称，节点 $1$ 的失效也不会触发级联。因此，$f(\\{1\\}) = 1$。\n-   $f(\\{0, 1\\})$：节点 $0$ 和 $1$ 同时失效。它们都将其负载（$L_0=0.5, L_1=0.5$）重新分配给它们的共同邻居节点 $2$。节点 $2$ 的负载变为 $L_2' = 0.6 + 0.5 + 0.5 = 1.6$。这超过了其容量 $c_2 = 1.2$，因此节点 $2$ 在下一轮失效。当节点 $2$ 失效时，其 $1.6$ 的新负载被重新分配给其存活的邻居节点 $\\{3, 4\\}$，每个节点接收 $0.8$。它们的负载变为 $L_3' = 0.4+0.8=1.2  c_3=0.5$ 和 $L_4' = 0.4+0.8=1.2  c_4=0.5$。它们都失效了。整个网络崩溃。因此，$f(\\{0, 1\\}) = 5$。\n\n现在，我们用 $A = \\{0\\}$ 和 $B = \\emptyset$（因此 $B \\subseteq A$）以及元素 $v = 1$ 来检验子模性不等式。子模性要求 $f(B \\cup \\{v\\}) - f(B) \\ge f(A \\cup \\{v\\}) - f(A)$。\n-   将节点 $1$ 添加到空集 $B$ 的边际增益为：$f(\\{1\\}) - f(\\emptyset) = 1 - 0 = 1$。\n-   将节点 $1$ 添加到集合 $A=\\{0\\}$ 的边际增益为：$f(\\{0,1\\}) - f(\\{0\\}) = 5 - 1 = 4$。\n\n我们得到 $1  4$，这意味着 $f(B \\cup \\{v\\}) - f(B)  f(A \\cup \\{v\\}) - f(A)$。这违反了子模性条件。该函数表现出协同效应，或称为收益递增，即两个节点共同失效的效果大于它们各自效应的总和。由于缺乏子模性，贪心算法不能保证找到最优解。因此，根据问题陈述的要求，必须对所有 $\\binom{n}{k}$ 种可能的初始集合进行穷举搜索，以保证最优性。\n\n**3. 算法方法**\n\n该算法将由一个主循环和一个核心函数组成，主循环负责组织搜索，核心函数则为给定的初始集合模拟级联过程。\n\n1.  **主程序：** 对于每个测试用例 $(n, W, \\ell, c, k)$：\n    a. 初始化 `max_cascade_size = -1` 和 `optimal_set = []`。\n    b. 生成所有大小为 $k$ 的节点唯一子集 $S$。`itertools.combinations` 函数很适合，因为它按字典序生成这些子集。\n    c. 对于每个子集 $S$：\n        i. 调用一个模拟函数 `simulate_cascade(S, n, W, l, c)`，该函数返回最终的级联规模 $f(S)$。\n        ii. 如果返回的规模大于 `max_cascade_size`，则将 `max_cascade_size` 更新为此新规模，并将 `optimal_set` 设置为当前的 $S$。因为我们是按字典序遍历集合，所以第一个达到最大可能规模的集合将是符合平局规则的正确集合。\n    d. 为该测试用例存储最终的 (`max_cascade_size`, `optimal_set`) 对。\n\n2.  **`simulate_cascade(S, n, W, l, c)` 函数：**\n    a. 初始化 `loads = copy(l)`，`total_failed = set(S)`，以及 `newly_failed = set(S)`。\n    b. 进入一个 `while` 循环，只要 `newly_failed` 不为空就继续。\n    c. 在循环内部，令 `failing_this_round = newly_failed`。将 `newly_failed` 重置为空集。\n    d. 初始化 `load_increments = zeros(n)`。\n    e. 对于 `failing_this_round` 中的每个节点 $i$：\n        i. 确定存活邻居节点的集合 $N_{\\text{surv}}(i) = \\{ j \\mid W_{ij}0 \\text{ and } j \\notin \\text{total\\_failed} \\}$。\n        ii. 计算 $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$。\n        iii. 如果 $\\sigma(i)  0$，对于每个 $j \\in N_{\\text{surv}}(i)$，将 $loads[i] \\cdot \\frac{W_{ij}}{\\sigma(i)}$ 加到 `load_increments[j]` 上。\n    f. 遍历完 `failing_this_round` 中的所有节点后，更新主 `loads` 向量：`loads += load_increments`。\n    g. 更新失效节点集合：`total_failed.update(failing_this_round)`。\n    h. 遍历所有节点 $j \\in \\{0, \\dots, n-1\\}$。如果 $j \\notin \\text{total\\_failed}$ 且 $loads[j]  c[j]$，则将 $j$ 添加到 `newly_failed` 集合中。\n    i. 循环继续。\n    j. 循环终止后，返回 `len(total_failed)`。\n\n此设计忠实地实现了指定的模型，并执行了所需的穷举搜索，为每个测试用例找到精确的最优解。",
            "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Solves the cascading failure problem for a set of predefined test cases.\n    It finds the initial removal set of size k that maximizes the total cascade size.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (happy path star cascade)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 1, 1), (0, 2, 1), (0, 3, 1), (0, 4, 1)],\n            \"l\": [0.80, 0.31, 0.31, 0.31, 0.31],\n            \"c\": [1.20, 0.50, 0.50, 0.50, 0.50],\n            \"k\": 1,\n        },\n        # Test Case 2 (boundary, no removals)\n        {\n            \"n\": 4,\n            \"edges\": [(0, 1, 1), (1, 2, 1), (2, 3, 1)],\n            \"l\": [0.20, 0.20, 0.20, 0.20],\n            \"c\": [0.50, 0.50, 0.50, 0.50],\n            \"k\": 0,\n        },\n        # Test Case 3 (edge-case synergy and submodularity counterexample)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 2, 1), (1, 2, 1), (2, 3, 1), (2, 4, 1)],\n            \"l\": [0.50, 0.50, 0.60, 0.40, 0.40],\n            \"c\": [0.60, 0.60, 1.20, 0.50, 0.50],\n            \"k\": 2,\n        },\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        edges = case[\"edges\"]\n        l_vec = np.array(case[\"l\"], dtype=float)\n        c_vec = np.array(case[\"c\"], dtype=float)\n        k = case[\"k\"]\n\n        # Build the weighted adjacency matrix W\n        W = np.zeros((n, n), dtype=float)\n        for i, j, w in edges:\n            W[i, j] = w\n            W[j, i] = w\n\n        max_cascade_size = -1\n        best_s = []\n\n        # Generate all subsets of nodes of size k.\n        # itertools.combinations generates them in lexicographical order.\n        initial_sets = itertools.combinations(range(n), k)\n        \n        for s_tuple in initial_sets:\n            initial_failures = set(s_tuple)\n            \n            # Run the cascade simulation for the current set S\n            loads = np.copy(l_vec)\n            total_failed = set(initial_failures)\n            newly_failed = set(initial_failures)\n\n            while newly_failed:\n                failing_this_round = set(newly_failed)\n                newly_failed = set()\n                \n                # Update total failed set before calculating redistributions\n                # from this round's failures. This is to ensure a node failing\n                # in the same round doesn't receive load from another.\n                current_round_total_failed = total_failed.union(failing_this_round)\n                \n                load_increments = np.zeros(n)\n\n                for i in failing_this_round:\n                    surviving_neighbors = []\n                    weight_sum_surv = 0.0\n                    \n                    # Find surviving neighbors and sum of weights\n                    for j in range(n):\n                        if W[i, j] > 0 and j not in current_round_total_failed:\n                            surviving_neighbors.append(j)\n                            weight_sum_surv += W[i, j]\n\n                    # Redistribute load\n                    if weight_sum_surv > 0:\n                        for j in surviving_neighbors:\n                            load_increments[j] += loads[i] * (W[i, j] / weight_sum_surv)\n                \n                # Synchronous update of loads\n                loads += load_increments\n                \n                # Update total failed set after redistributions are calculated\n                total_failed.update(failing_this_round)\n\n                # Identify nodes failing in the next round\n                for j in range(n):\n                    if j not in total_failed and loads[j] > c_vec[j]:\n                        newly_failed.add(j)\n\n            current_cascade_size = len(total_failed)\n            \n            # Update best result found so far.\n            # Due to lexicographical order of combinations, the first set\n            # that achieves the max size will be the lexicographically smallest.\n            if current_cascade_size > max_cascade_size:\n                max_cascade_size = current_cascade_size\n                best_s = list(s_tuple)\n        \n        # Handle k=0 case which results in no loops\n        if k == 0 and max_cascade_size == -1:\n             max_cascade_size = 0\n             best_s = []\n\n        final_results.append([max_cascade_size, best_s])\n    \n    # Format the final output string exactly as specified.\n    result_str = \",\".join([f\"[{size},{s}]\" for size, s in final_results])\n    print(f\"[{result_str}]\".replace(\" \", \"\"))\n\n\nsolve()\n```"
        }
    ]
}