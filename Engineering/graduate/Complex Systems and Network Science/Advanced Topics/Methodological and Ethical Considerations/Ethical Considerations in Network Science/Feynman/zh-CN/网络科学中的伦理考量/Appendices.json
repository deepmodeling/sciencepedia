{
    "hands_on_practices": [
        {
            "introduction": "网络数据因其描述了人与人之间的关系而具有内在的敏感性。本地化差分隐私 (Local Differential Privacy, LDP) 提供了一个严格的数学框架，用于在数据收集之前保护个人隐私。本练习 () 通过推导一个常用机制的核心隐私参数 $\\epsilon$，提供了一个基础的计算实践，帮助你理解隐私保障与数据扰动之间的权衡。",
            "id": "4274556",
            "problem": "一个包含 $n$ 个节点的无向简单图由一个对称邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示，其中对所有 $i$ 都有 $A_{ii} = 0$。每个非对角线元素 $A_{ij}$（其中 $i \\neq j$）编码了一种可能敏感的二元关系。为了保护个体关系的机密性，以符合网络科学中的隐私伦理标准，研究人员对每个非对角线元素独立应用以下随机响应机制：对于给定的输入比特 $x \\in \\{0,1\\}$，发布的比特 $y$ 以 $1 - \\pi$ 的概率等于 $x$，以 $\\pi$ 的概率等于 $1 - x$，其中 $0  \\pi \\leq \\tfrac{1}{2}$ 是一个适用于所有元素的固定翻转概率。\n\n使用局部差分隐私（LDP）的定义，该定义要求对于任意两个输入比特 $x, x' \\in \\{0,1\\}$ 和任意输出 $y \\in \\{0,1\\}$，机制 $\\mathcal{M}$ 满足 $\\Pr[\\mathcal{M}(x) = y] \\leq \\exp(\\epsilon)\\,\\Pr[\\mathcal{M}(x') = y]$，请确定最小的 $\\epsilon$（作为 $\\pi$ 的函数），该 $\\epsilon$ 证明此随机响应机制对于单个邻接元素是 $\\epsilon$-LDP。请用关于 $\\pi$ 的闭式解析表达式表示您的最终答案。无需进行数值舍入。",
            "solution": "该问题要求我们为给定的随机响应机制确定最小隐私参数 $\\epsilon$，以使该机制满足 $\\epsilon$-局部差分隐私（LDP）的定义。\n\n该机制 $\\mathcal{M}$ 接受单个二进制输入 $x \\in \\{0, 1\\}$，代表一个敏感关系的存在与否，并产生一个二进制输出 $y \\in \\{0, 1\\}$。其概率映射由翻转概率 $\\pi$ 定义，其中 $0  \\pi \\leq \\frac{1}{2}$。\n\n给定输入 $x$，输出 $y$ 的概率如下：\n- 输出与输入相同的概率（无翻转）为 $\\Pr[y = x] = 1 - \\pi$。\n- 输出与输入不同的概率（有翻转）为 $\\Pr[y = 1 - x] = \\pi$。\n\n我们可以明确地写出四个条件概率：\n1.  对于输入 $x=0$：\n    $\\Pr[\\mathcal{M}(0) = 0] = 1 - \\pi$\n    $\\Pr[\\mathcal{M}(0) = 1] = \\pi$\n2.  对于输入 $x=1$：\n    $\\Pr[\\mathcal{M}(1) = 0] = \\pi$\n    $\\Pr[\\mathcal{M}(1) = 1] = 1 - \\pi$\n\n如所提供的 $\\epsilon$-LDP 定义所述，对于任意两个输入 $x, x' \\in \\{0,1\\}$ 和任意可能的输出 $y \\in \\{0,1\\}$，必须满足以下不等式：\n$$\n\\Pr[\\mathcal{M}(x) = y] \\leq \\exp(\\epsilon)\\,\\Pr[\\mathcal{M}(x') = y]\n$$\n为了找到满足此条件的最小 $\\epsilon$，我们必须在所有可能的不同输入 $x, x'$ 和所有可能输出 $y$ 的组合中，找到比值 $\\frac{\\Pr[\\mathcal{M}(x) = y]}{\\Pr[\\mathcal{M}(x') = y]}$ 的最大可能值。由于输入域是二进制的，我们不妨设 $x=0$ 和 $x'=1$。最小的 $\\epsilon$ 必须满足：\n$$\n\\exp(\\epsilon) \\geq \\max_{y \\in \\{0,1\\}} \\left( \\max \\left( \\frac{\\Pr[\\mathcal{M}(0) = y]}{\\Pr[\\mathcal{M}(1) = y]}, \\frac{\\Pr[\\mathcal{M}(1) = y]}{\\Pr[\\mathcal{M}(0) = y]} \\right) \\right)\n$$\n让我们为每个可能的输出 $y$ 计算这些比值。\n\n情况 1：输出 $y = 0$。\n两个比值为：\n$$\n\\frac{\\Pr[\\mathcal{M}(0) = 0]}{\\Pr[\\mathcal{M}(1) = 0]} = \\frac{1 - \\pi}{\\pi}\n$$\n$$\n\\frac{\\Pr[\\mathcal{M}(1) = 0]}{\\Pr[\\mathcal{M}(0) = 0]} = \\frac{\\pi}{1 - \\pi}\n$$\n\n情况 2：输出 $y = 1$。\n两个比值为：\n$$\n\\frac{\\Pr[\\mathcal{M}(0) = 1]}{\\Pr[\\mathcal{M}(1) = 1]} = \\frac{\\pi}{1 - \\pi}\n$$\n$$\n\\frac{\\Pr[\\mathcal{M}(1) = 1]}{\\Pr[\\mathcal{M}(0) = 1]} = \\frac{1 - \\pi}{\\pi}\n$$\n因此，所有需要考虑的可能比值的集合是 $\\left\\{ \\frac{1-\\pi}{\\pi}, \\frac{\\pi}{1-\\pi} \\right\\}$。为了在所有情况下都满足 LDP 条件，$\\exp(\\epsilon)$ 必须大于或等于这些比值的最大值：\n$$\n\\exp(\\epsilon) \\geq \\max\\left(\\frac{1 - \\pi}{\\pi}, \\frac{\\pi}{1 - \\pi}\\right)\n$$\n我们已知约束条件 $0  \\pi \\leq \\frac{1}{2}$。\n如果 $\\pi = \\frac{1}{2}$，那么 $1 - \\pi = \\frac{1}{2}$，两个比值都等于 $1$。\n如果 $0  \\pi  \\frac{1}{2}$，那么 $1 - \\pi > \\pi$。用 $\\pi$（为正数）和 $1-\\pi$（也为正数）相除，我们得到：\n$$\n\\frac{1 - \\pi}{\\pi} > 1 \\quad \\text{and} \\quad \\frac{\\pi}{1 - \\pi}  1\n$$\n因此，在整个范围 $0  \\pi \\leq \\frac{1}{2}$ 内，这两个比值的最大值是 $\\frac{1 - \\pi}{\\pi}$。\n\n关于 $\\epsilon$ 的条件简化为：\n$$\n\\exp(\\epsilon) \\geq \\frac{1 - \\pi}{\\pi}\n$$\n为了找到保证此不等式成立的 $\\epsilon$ 的最小值，我们取等式：\n$$\n\\exp(\\epsilon) = \\frac{1 - \\pi}{\\pi}\n$$\n对两边取自然对数求解 $\\epsilon$，我们得到最小的 $\\epsilon$ 作为 $\\pi$ 的函数：\n$$\n\\epsilon = \\ln\\left(\\frac{1 - \\pi}{\\pi}\\right)\n$$\n该表达式为给定的随机响应机制提供了最紧的隐私边界。",
            "answer": "$$\\boxed{\\ln\\left(\\frac{1 - \\pi}{\\pi}\\right)}$$"
        },
        {
            "introduction": "从数据隐私转向分析的严谨性。网络上的因果推断因“溢出效应”而异常困难，即一个个体的处理可能影响另一个体的结果。本练习 () 提出了一个假设性的公共卫生运动场景，以说明忽略这些网络效应（违反稳定单元处理值假设 SUTVA）如何导致系统性的偏误结果——这在评估政策干预时是一个关键的伦理问题。通过解析地推导偏差，可以揭示这种分析失败的内在机制。",
            "id": "4274559",
            "problem": "一个公共卫生部门在一个由 $N$ 个个体组成的大型无向社交网络上部署了一项由同伴主导的信息宣传活动。该网络由一个对称邻接矩阵 $A \\in \\{0,1\\}^{N \\times N}$ 表示，其对角线元素为零，并且所有个体 $i$ 的度 $k_{i} = \\sum_{j=1}^{N} A_{ij} \\geq 1$。在时间 $t=0$ 时，每个个体 $i$ 以概率 $p \\in (0,1)$ 被独立地指派为同伴教育者，从而对所有 $i$ 独立地生成初始分配 $Z_{i} \\sim \\text{Bernoulli}(p)$。该部门计划评估成为同伴教育者对在时间 $t=1$ 时测量的某一结果的影响。\n\n然而，由于处理接受中的传染效应，稳定单元处理值假设（SUTVA）被违反了：最初未被指派的个体如果接触到最初被指派的邻居，到 $t=1$ 时可能会成为活跃的同伴教育者。具体来说，在时间 $t=1$ 时的最终接受情况 $T_{i} \\in \\{0,1\\}$ 遵循以下规律：\n$$\nT_{i} =\n\\begin{cases}\n1,  \\text{如果 } Z_{i} = 1,\\\\\n\\text{Bernoulli}\\!\\left(q \\cdot E_{i}\\right),  \\text{如果 } Z_{i} = 0,\n\\end{cases}\n$$\n其中 $q \\in [0,1]$ 是一个传染参数，$E_{i}$ 是接触到最初被指派邻居的暴露程度，定义为\n$$\nE_{i} \\equiv \\frac{1}{k_{i}} \\sum_{j=1}^{N} A_{ij} Z_{j}.\n$$\n假设 $q \\cdot E_{i} \\leq 1$ 几乎必然成立。\n\n在时间 $t=1$ 时的结果遵循一个没有结果溢出效应的直接效应模型：\n$$\nY_{i} = Y_{i}(0) + \\alpha \\, T_{i},\n$$\n其中 $Y_{i}(0)$ 是基线结果，$\\alpha \\in \\mathbb{R}$ 是在时间 $t=1$ 时成为活跃同伴教育者的直接效应，并且 $\\{Y_{i}(0)\\}_{i=1}^{N}$ 与 $\\{Z_{i}\\}_{i=1}^{N}$ 以及网络 $A$ 均值独立。评估分析师未意识到传染效应，使用了按初始分配计算的朴素均值差：\n$$\n\\widehat{\\tau}_{\\text{naive}} \\equiv \\frac{1}{N p} \\sum_{i=1}^{N} Z_{i} Y_{i} \\;-\\; \\frac{1}{N (1-p)} \\sum_{i=1}^{N} (1 - Z_{i}) Y_{i}.\n$$\n\n从上述结构和概率定义以及全期望定律出发，推导 $\\widehat{\\tau}_{\\text{naive}}$ 对于 $\\alpha$ 的偏差，其定义为\n$$\n\\text{Bias} \\equiv \\mathbb{E}\\!\\left[ \\widehat{\\tau}_{\\text{naive}} \\,\\middle|\\, A \\right] - \\alpha,\n$$\n并以 $\\alpha$、$q$ 和分配概率 $p$ 的闭合形式函数表示。明确展示该偏差如何依赖于接触最初被指派邻居的暴露程度。请以单一解析表达式的形式提供最终答案。不需要进行数值近似。如果引入任何辅助暴露量，请明确定义它，并在最终表达式中用 $p$ 将其消去。",
            "solution": "目标是推导朴素均值差估计量 $\\widehat{\\tau}_{\\text{naive}}$ 对直接效应参数 $\\alpha$ 的偏差。偏差定义为 $\\text{Bias} \\equiv \\mathbb{E}\\!\\left[ \\widehat{\\tau}_{\\text{naive}} \\,\\middle|\\, A \\right] - \\alpha$。给定的估计量为：\n$$\n\\widehat{\\tau}_{\\text{naive}} \\equiv \\frac{1}{N p} \\sum_{i=1}^{N} Z_{i} Y_{i} \\;-\\; \\frac{1}{N (1-p)} \\sum_{i=1}^{N} (1 - Z_{i}) Y_{i}\n$$\n我们首先计算在给定邻接矩阵 $A$ 的条件下 $\\widehat{\\tau}_{\\text{naive}}$ 的条件期望。期望是针对随机初始分配 $\\{Z_i\\}_{i=1}^N$ 的分布计算的。根据期望的线性性质：\n$$\n\\mathbb{E}\\!\\left[ \\widehat{\\tau}_{\\text{naive}} \\,\\middle|\\, A \\right] = \\frac{1}{N p} \\sum_{i=1}^{N} \\mathbb{E}[Z_{i} Y_{i} | A] - \\frac{1}{N (1-p)} \\sum_{i=1}^{N} \\mathbb{E}[(1 - Z_{i}) Y_{i} | A]\n$$\n我们来分析这两个期望项，$\\mathbb{E}[Z_i Y_i | A]$ 和 $\\mathbb{E}[(1 - Z_i) Y_i | A]$，对于任意个体 $i$。我们代入结果模型 $Y_i = Y_i(0) + \\alpha T_i$。\n\n首先，考虑初始分配为 $Z_i=1$ 的组的项：\n$$\n\\mathbb{E}[Z_i Y_i | A] = \\mathbb{E}[Z_i (Y_i(0) + \\alpha T_i) | A] = \\mathbb{E}[Z_i Y_i(0) | A] + \\alpha \\mathbb{E}[Z_i T_i | A]\n$$\n根据假设，$Y_i(0)$ 与分配向量 $Z$ 和网络 $A$ 均值独立。令 $\\mu_{i0} \\equiv \\mathbb{E}[Y_i(0)]$。由于 $Z_i$ 是参数为 $p$ 的伯努利随机变量，且独立于 $Y_i(0)$ 和 $A$，我们有 $\\mathbb{E}[Z_i Y_i(0) | A] = \\mathbb{E}[Z_i | A]\\mathbb{E}[Y_i(0)|A] = p \\mu_{i0}$。\n对于项 $\\mathbb{E}[Z_i T_i | A]$，我们使用 $T_i$ 的定义。如果 $Z_i=1$，那么 $T_i=1$。如果 $Z_i=0$，则项 $Z_i T_i$ 为 $0$。因此，乘积 $Z_i T_i$ 就等于 $Z_i$。\n$$\n\\mathbb{E}[Z_i T_i | A] = \\mathbb{E}[Z_i | A] = p\n$$\n综合这些结果，第一部分的期望值为：\n$$\n\\mathbb{E}[Z_i Y_i | A] = p \\mu_{i0} + \\alpha p\n$$\n\n接下来，考虑没有初始分配的组，即 $Z_i=0$ 的项：\n$$\n\\mathbb{E}[(1-Z_i) Y_i | A] = \\mathbb{E}[(1 - Z_i) (Y_i(0) + \\alpha T_i) | A] = \\mathbb{E}[(1-Z_i) Y_i(0) | A] + \\alpha \\mathbb{E}[(1 - Z_i) T_i | A]\n$$\n类似地，$\\mathbb{E}[(1-Z_i) Y_i(0) | A] = \\mathbb{E}[1-Z_i | A] \\mathbb{E}[Y_i(0)|A] = (1-p) \\mu_{i0}$。\n关键项是 $\\mathbb{E}[(1-Z_i) T_i | A]$，它捕捉了传染效应。乘积 $(1-Z_i)T_i$ 仅在 $Z_i=0$ 时非零，在这种情况下 $T_i \\sim \\text{Bernoulli}(q E_i)$。我们使用全期望定律，以整个分配向量 $Z = (Z_1, \\dots, Z_N)$ 为条件：\n$$\n\\mathbb{E}[(1-Z_i)T_i | A] = \\mathbb{E}_Z \\big[ \\mathbb{E}[(1-Z_i)T_i | Z, A] \\big| A \\big]\n$$\n给定 $Z$，如果 $Z_i=1$，则 $(1-Z_i)T_i=0$。如果 $Z_i=0$，则 $\\mathbb{E}[T_i | Z, A] = q E_i$。所以，$\\mathbb{E}[(1-Z_i)T_i | Z, A] = (1-Z_i) q E_i$。现在我们对 $Z$ 取期望：\n$$\n\\mathbb{E}[(1-Z_i)T_i | A] = \\mathbb{E}[(1-Z_i) q E_i | A] = q \\, \\mathbb{E}\\left[(1-Z_i) \\frac{1}{k_i} \\sum_{j=1}^N A_{ij} Z_j \\;\\middle|\\; A \\right]\n$$\n根据期望的线性性质：\n$$\n\\mathbb{E}[(1-Z_i)T_i | A] = \\frac{q}{k_i} \\sum_{j=1}^N A_{ij} \\mathbb{E}[(1-Z_i)Z_j | A]\n$$\n由于初始分配 $\\{Z_k\\}$ 是独立的，对 $j \\neq i$，$\\mathbb{E}[(1-Z_i)Z_j | A] = \\mathbb{E}[1-Z_i|A]\\mathbb{E}[Z_j|A] = (1-p)p$。对 $j=i$，$\\mathbb{E}[(1-Z_i)Z_i | A] = 0$。由于 $A$ 的对角线元素为零（$A_{ii}=0$），和式仅对 $j \\neq i$ 求和：\n$$\n\\mathbb{E}[(1-Z_i)T_i | A] = \\frac{q}{k_i} \\sum_{j \\neq i} A_{ij} (1-p)p = \\frac{q p(1-p)}{k_i} \\sum_{j \\neq i} A_{ij}\n$$\n已知 $\\sum_{j \\neq i} A_{ij} = k_i$，这可以简化为：\n$$\n\\mathbb{E}[(1-Z_i)T_i | A] = \\frac{q p(1-p)}{k_i} k_i = q p (1-p)\n$$\n这明确地表明偏差与暴露有关，因为该项表示一个节点在控制组（$Z_i=0$）中但由于暴露而变为被处理（$T_i=1$）的概率。结果与具体节点 $i$ 无关。\n第二部分的期望值为：\n$$\n\\mathbb{E}[(1-Z_i) Y_i | A] = (1-p)\\mu_{i0} + \\alpha q p (1-p)\n$$\n\n现在我们将这些结果代回到 $\\mathbb{E}[\\widehat{\\tau}_{\\text{naive}}|A]$ 的表达式中。\n$$\n\\mathbb{E}\\!\\left[ \\widehat{\\tau}_{\\text{naive}} \\,\\middle|\\, A \\right] = \\frac{1}{N p} \\sum_{i=1}^{N} (p \\mu_{i0} + \\alpha p) - \\frac{1}{N (1-p)} \\sum_{i=1}^{N} ((1-p)\\mu_{i0} + \\alpha q p (1-p))\n$$\n提出不依赖于 $i$ 的项：\n$$\n= \\frac{N(p \\bar{\\mu}_{0} + \\alpha p)}{N p} - \\frac{N((1-p)\\bar{\\mu}_{0} + \\alpha q p (1-p))}{N (1-p)}\n$$\n其中 $\\bar{\\mu}_0 = \\frac{1}{N} \\sum_{i=1}^N \\mu_{i0}$ 是平均基线结果。\n$$\n= (\\bar{\\mu}_{0} + \\alpha) - (\\bar{\\mu}_{0} + \\alpha q p) = \\alpha - \\alpha q p = \\alpha(1-qp)\n$$\n这个表达式表明了估计量的期望值是如何被削弱的。偏差是由传染效应直接引起的，这使得控制组（$Z_i=0$）的测量结果高于其基线潜在结果。对于一个控制单元，这种传染的概率 $\\mathbb{E}[T_i|Z_i=0,A]$ 是 $q \\mathbb{E}[E_i|Z_i=0,A]$。一个控制单元的预期暴露程度 $\\mathbb{E}[E_i|Z_i=0,A] = \\mathbb{E}[\\frac{1}{k_i}\\sum_j A_{ij}Z_j|Z_i=0,A] = \\frac{1}{k_i}\\sum_{j\\neq i}A_{ij}\\mathbb{E}[Z_j|A] = \\frac{p}{k_i} k_i = p$。因此，平均传染概率是 $qp$。\n\n最后，我们计算偏差：\n$$\n\\text{Bias} = \\mathbb{E}\\!\\left[ \\widehat{\\tau}_{\\text{naive}} \\,\\middle|\\, A \\right] - \\alpha = \\alpha(1-qp) - \\alpha = \\alpha - \\alpha q p - \\alpha = - \\alpha q p\n$$\n偏差是直接效应大小 $\\alpha$、传染参数 $q$ 和初始分配概率 $p$ 的乘积。项 $p$ 表示任何节点的邻域对初始同伴教育者的预期暴露比例。",
            "answer": "$$\n\\boxed{-\\alpha q p}\n$$"
        },
        {
            "introduction": "最后，我们将探讨在网络数据上应用机器学习所面临的伦理挑战。在有偏见的数据上训练的算法不仅会重现这些偏见，甚至可能将其放大。本练习 () 在一个同质性网络中模拟了一个链接预测任务，展示了一个看似中立的技术选择——均匀负采样——如何系统性地导致少数群体代表性不足并产生不公平的结果。此练习还包括设计一种纠正措施，从而实现从诊断到解决方案的跨越。",
            "id": "4274574",
            "problem": "考虑一个简单的无向网络，其中有两个受保护群体，群体 $A$（含 $n_A$ 个节点）和群体 $B$（含 $n_B$ 个节点）。假设其生成过程存在同质性：同一群体中两个节点之间存在边的概率为 $p_W$，而不同群体中两个节点之间存在边的概率为 $p_B$，其中 $0  p_B  p_W  1$。设潜在的群体内节点对总数为 $N_W = \\binom{n_A}{2} + \\binom{n_B}{2}$，潜在的跨群体节点对总数为 $N_B = n_A n_B$。链接预测训练集的构建方式如下：所有观察到的边都用作正样本，而负样本则从所有非边的集合中均匀随机抽取（不按节点对类型分层）。\n\n定义偏见放大因子 $\\mathcal{A}$ 为负样本中跨群体节点对的份额与正样本中跨群体节点对的份额之比。请从网络建模和抽样的第一性原理出发，推导 $\\mathcal{A}$ 的一个关于 $n_A$、$n_B$、$p_W$ 和 $p_B$ 的闭式表达式。\n\n此外，请提出一种修正的负采样方案，该方案在期望上能消除这种放大效应（即实现 $\\mathcal{A} = 1$），具体说明如何选择群体内非边与跨群体非边的相对选择概率，从而使负类样本的构成在节点对类型上与正类样本相匹配。\n\n将您的最终答案表示为放大因子 $\\mathcal{A}$ 的闭式解析表达式。无需四舍五入。",
            "solution": "问题要求推导偏见放大因子 $\\mathcal{A}$，并为具有同质性结构的网络提出一种修正的负采样方案。分析将从所提供的生成模型的第一性原理出发。所有计算都将基于该模型生成的图分布的期望值。\n\n设节点集为 $V$，划分为大小为 $n_A = |V_A|$ 和 $n_B = |V_B|$ 的两个群体 $V_A$ 和 $V_B$。该网络是随机分块模型的一个实例。\n\n潜在的群体内节点对总数为 $N_W = \\binom{n_A}{2} + \\binom{n_B}{2}$。任何此类节点对存在边的概率为 $p_W$。\n潜在的跨群体节点对总数为 $N_B = n_A n_B$。任何此类节点对存在边的概率为 $p_B$。问题陈述 $0  p_B  p_W  1$。\n\n首先，我们计算每种类型节点对的期望边数（正样本）。\n群体内边的期望数量 $L_W$ 是潜在节点对数乘以成边概率：\n$$L_W = N_W p_W = \\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) p_W$$\n类似地，跨群体边的期望数量 $L_B$ 是：\n$$L_B = N_B p_B = (n_A n_B) p_B$$\n正样本（边）的期望总数是 $L_{pos} = L_W + L_B$。\n\n正样本中跨群体节点对的份额，我们记为 $S_{pos, B}$，是跨群体边的期望数量与总期望边数的比值：\n$$S_{pos, B} = \\frac{L_B}{L_{pos}} = \\frac{L_B}{L_W + L_B} = \\frac{n_A n_B p_B}{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) p_W + n_A n_B p_B}$$\n\n接下来，我们计算每种类型节点对的期望非边数。这些构成了抽取负样本的样本池。\n群体内节点对之间非边的概率是 $1-p_W$。群体内非边的期望数量 $U_W$ 是：\n$$U_W = N_W (1 - p_W) = \\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) (1 - p_W)$$\n跨群体节点对之间非边的概率是 $1-p_B$。跨群体非边的期望数量 $U_B$ 是：\n$$U_B = N_B (1 - p_B) = n_A n_B (1 - p_B)$$\n非边的期望总数是 $U_{tot} = U_W + U_B$。\n\n问题陈述负样本是从所有非边的集合中均匀随机抽取的。因此，一个抽取的负样本是跨群体节点对的概率，是跨群体非边数与总非边数的比值。负样本中跨群体节点对的份额 $S_{neg, B}$ 是：\n$$S_{neg, B} = \\frac{U_B}{U_{tot}} = \\frac{U_B}{U_W + U_B} = \\frac{n_A n_B (1 - p_B)}{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) (1 - p_W) + n_A n_B (1 - p_B)}$$\n\n偏见放大因子 $\\mathcal{A}$ 定义为这些份额的比值：\n$$\\mathcal{A} = \\frac{S_{neg, B}}{S_{pos, B}} = \\frac{\\frac{U_B}{U_W + U_B}}{\\frac{L_B}{L_W + L_B}}$$\n代入表达式以便更直接地计算：\n$$\\mathcal{A} = \\frac{U_B}{L_B} \\cdot \\frac{L_W + L_B}{U_W + U_B}$$\n现在，我们代入 $L_W, L_B, U_W, U_B$ 的公式：\n$$\\mathcal{A} = \\frac{N_B (1 - p_B)}{N_B p_B} \\cdot \\frac{N_W p_W + N_B p_B}{N_W (1 - p_W) + N_B (1 - p_B)}$$\n第一个分数中的 $N_B$ 项相互抵消：\n$$\\mathcal{A} = \\frac{1 - p_B}{p_B} \\cdot \\frac{N_W p_W + N_B p_B}{N_W (1 - p_W) + N_B (1 - p_B)}$$\n代入 $N_W$ 和 $N_B$ 的定义，得到 $\\mathcal{A}$ 的最终闭式表达式：\n$$\\mathcal{A} = \\frac{1 - p_B}{p_B} \\cdot \\frac{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) p_W + n_A n_B p_B}{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) (1 - p_W) + n_A n_B (1 - p_B)}$$\n条件 $p_W > p_B$ 意味着 $p_W(1-p_B) > p_B(1-p_W)$，这保证了 $\\mathcal{A} > 1$，从而证实了偏见的放大。\n\n对于问题的第二部分，我们必须提出一种修正的负采样方案以实现 $\\mathcal{A} = 1$。这要求抽取的负样本集中跨群体节点对的份额与正样本集中它们的份额相等。设新的负样本中跨群体节点对的份额为 $S'_{neg, B}$。我们需要 $S'_{neg, B} = S_{pos, B}$。\n\n为实现此目的，我们可以使用分层抽样方法，根据非边是群体内还是跨群体的，以不同的概率进行抽样。设 $w_W$ 和 $w_B$ 分别为抽样单个群体内非边和单个跨群体非边的相对选择概率（或权重）。\n\n所选跨群体非边的期望“权重”将与 $w_B U_B$ 成正比，而群体内非边的期望“权重”将与 $w_W U_W$ 成正比。修正后负样本中跨群体节点对的份额是：\n$$S'_{neg, B} = \\frac{w_B U_B}{w_W U_W + w_B U_B}$$\n我们将此值设为与正类中的份额 $S_{pos, B} = \\frac{L_B}{L_W + L_B}$ 相等：\n$$\\frac{w_B U_B}{w_W U_W + w_B U_B} = \\frac{L_B}{L_W + L_B}$$\n如果各分量的比率匹配，则此等式成立：\n$$\\frac{w_B U_B}{w_W U_W} = \\frac{L_B}{L_W}$$\n我们求解相对选择概率之比 $\\frac{w_B}{w_W}$：\n$$\\frac{w_B}{w_W} = \\frac{L_B}{L_W} \\cdot \\frac{U_W}{U_B} = \\frac{N_B p_B}{N_W p_W} \\cdot \\frac{N_W(1 - p_W)}{N_B(1 - p_B)}$$\n$N_W$ 和 $N_B$ 项相互抵消，从而得到所需概率比的简单表达式：\n$$\\frac{w_B}{w_W} = \\frac{p_B(1 - p_W)}{p_W(1 - p_B)}$$\n因此，为了消除偏见放大（即实现 $\\mathcal{A} = 1$），抽样跨群体非边的概率必须是抽样群体内非边概率的 $\\frac{p_B(1 - p_W)}{p_W(1 - p_B)}$ 倍。由于 $p_W > p_B$，这个比率小于1，这意味着相对于从所有非边中进行均匀选择，修正方案必须对跨群体非边进行降采样。",
            "answer": "$$\n\\boxed{\\frac{1-p_B}{p_B} \\frac{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) p_W + n_A n_B p_B}{\\left(\\binom{n_A}{2} + \\binom{n_B}{2}\\right) (1-p_W) + n_A n_B (1-p_B)}}\n$$"
        }
    ]
}