{
    "hands_on_practices": [
        {
            "introduction": "在量化隐私之前，我们必须精确定义什么使两个网络数据集“邻近”。这个基础练习要求您根据边级别和节点级别的隐私定义，从第一性原理出发，枚举给定网络的所有可能的邻近图。通过这个练习，您将对数据集的“邻域”有一个具体的理解，而这是敏感度分析的基础。",
            "id": "4272484",
            "problem": "考虑一个在网络数据差分隐私 (DP) 背景下的简单无向标记图数据集。设数据全集为一个固定的标记节点集 $U = \\{1,2,\\dots,10\\}$，其大小为 $m=10$。发布的数据集是一个图 $G=(V,E)$，其中 $V = \\{1,2,3,4,5,6\\} \\subset U$，边集为 $E = \\{(1,2),(1,3),(2,3),(3,4),(4,5),(5,6)\\}$，其中每条边 $(i,j)$ 表示不同节点 $i$ 和 $j$ 之间的一条无向连接，不允许自环或多重边。\n\n使用网络数据中差分隐私的标准邻接关系：\n- 边级邻接：在同一固定顶点集 $V$ 上的两个图，如果它们的边集仅在一个无序节点对上不同（即，添加或删除了一条边），则它们是邻接的。\n- 点级邻接：在 $U$ 的顶点子集上的两个图，如果它们因包含或排除 $U$ 中的一个节点以及与该节点相关的所有边而不同，则它们是邻接的。具体来说，移除一个现有节点 $v \\in V$ 会删除 $v$ 以及所有与 $w \\in V$ 相连的边 $(v,w)$。添加一个节点 $u \\in U \\setminus V$ 会引入 $u$ 以及连接 $u$ 到当前节点集 $V$ 的任意子集的边；$V$ 中节点之间的边保持不变。\n\n仅从这些定义出发，根据第一性原理推导出一个完整的枚举论证，说明在每种邻接概念下，有多少个不同的数据集（图）与 $G$ 邻接。您必须将节点视为由 $U$ 标记，并且必须假设在所有邻接数据集中，图都保持为简单无向图。请分别提供在边级邻接和点级邻接下与 $G$ 邻接的图的数量的最终计数，结果为精确整数。无需四舍五入。您的最终答案应表示为一行中的两个数字，顺序为：边级计数，点级计数。",
            "solution": "问题陈述已经过分析，被认为是有效的。它在科学上植根于网络数据的差分隐私理论，提供了一个自洽且一致的设定，使用了精确无歧义的语言，并且问题提取得当，允许一个唯一且有意义的解。我们可以开始推导。\n\n问题要求我们确定在两种不同的邻接概念（边级和点级）下，与给定图 $G=(V,E)$ 邻接的不同图的数量。给定图的顶点集为 $V = \\{1,2,3,4,5,6\\}$，边集为 $E = \\{(1,2),(1,3),(2,3),(3,4),(4,5),(5,6)\\}$。顶点集的大小为 $|V|=6$，边的数量为 $|E|=6$。节点的全集为 $U = \\{1,2,\\dots,10\\}$，其大小为 $|U|=10$。\n\n**1. 边级邻接**\n\n边级邻接的定义指出，如果两个图位于同一固定顶点集 $V$ 上，并且它们的边集恰好相差一条边，则它们是邻接的。因此，一个邻接图 $G'$ 可以通过以下两种互斥的方式之一从 $G$ 形成：\n- 通过添加一条 $G$ 中不存在的边。\n- 通过删除一条 $G$ 中存在的边。\n\n顶点集 $V$ 是固定的，其大小为 $|V|=6$。在一个具有 $n=|V|$ 个标记顶点的简单图中，可能的无向边的总数由二项式系数 $\\binom{n}{2}$ 给出。\n对于 $G$，顶点集 $V$ 上可能的边的总数为：\n$$ \\binom{|V|}{2} = \\binom{6}{2} = \\frac{6 \\times 5}{2} = 15 $$\n图 $G$ 有 $|E|=6$ 条边。\n\n通过**加边**形成的邻接图的数量等于 $G$ 中不存在的边的数量。这是可能的边的总数减去现有边的数量。\n$$ \\text{加边数量} = \\binom{6}{2} - |E| = 15 - 6 = 9 $$\n这 $9$ 种添加中的每一种都会产生一个与 $G$ 邻接的唯一图。\n\n通过**删边**形成的邻接图的数量等于 $G$ 中现有边的数量。\n$$ \\text{删边数量} = |E| = 6 $$\n这 $6$ 种删除中的每一种都会产生一个与 $G$ 邻接的唯一图。\n\n由于加边和删边的操作产生不相交的图集，因此在边级定义下与 $G$ 邻接的图的总数是这两个计数的总和。\n$$ N_{\\text{edge}} = (\\binom{6}{2} - |E|) + |E| = 9 + 6 = 15 $$\n因此，在边级邻接下，有 $15$ 个与 $G$ 邻接的不同图。\n\n**2. 点级邻接**\n\n点级邻接的定义指出，如果两个图因包含或排除来自全集 $U$ 的一个节点及其所有关联边而不同，则它们是邻接的。我们从图 $G=(V,E)$ 开始，其中 $V \\subset U$。一个邻接图 $G'$ 可以通过以下两种互斥的方式之一形成：\n- 通过删除一个节点 $v \\in V$ 及其所有关联边。\n- 通过添加一个节点 $u \\in U \\setminus V$ 以及一组连接 $u$ 到 $V$ 中节点某个子集的边。\n\n初始顶点集的大小为 $|V|=6$。节点全集的大小为 $|U|=10$。\n\n通过**删点**形成的邻接图的数量等于 $V$ 中可以被移除的节点的数量。\n$$ \\text{可移除节点数} = |V| = 6 $$\n移除任何节点 $v \\in V$ 都会产生一个顶点集为 $V \\setminus \\{v\\}$、大小为 $5$ 的新图。由于移除不同的节点会产生具有不同顶点集的图，因此这 $6$ 个结果图中的每一个都是唯一的。\n\n通过**加点**形成的邻接图的数量取决于全集 $U$ 中不在 $V$ 中的可用节点。可用节点集为 $U \\setminus V = \\{7,8,9,10\\}$。\n$$ \\text{可添加节点数} = |U \\setminus V| = |U| - |V| = 10 - 6 = 4 $$\n根据定义，当添加一个节点 $u \\in U \\setminus V$ 时，它可以通过新的边连接到 $V$ 中现有节点的任意子集。$V$ 中的节点集大小为 $|V|=6$。$V$ 的子集数量为 $2^{|V|}$。\n$$ \\text{一个新节点的可能边连接数} = 2^{|V|} = 2^6 = 64 $$\n对于我们可以选择添加的 4 个节点中的每一个，都有 64 种可能的方式将其连接到 $V$ 中的节点。每个添加的节点和一组新边的组合都形成一个不同的邻接图。通过添加节点 $u_1$ 形成的图与通过添加不同节点 $u_2$ 形成的图是不同的，因为它们的顶点集 $V \\cup \\{u_1\\}$ 和 $V \\cup \\{u_2\\}$ 是不同的。\n因此，通过加点形成的邻接图总数是可添加节点数与连接模式数的乘积。\n$$ \\text{加点数量} = |U \\setminus V| \\times 2^{|V|} = 4 \\times 2^6 = 4 \\times 64 = 256 $$\n\n通过删点形成的图有 $|V|-1 = 5$ 个顶点，而通过加点形成的图有 $|V|+1 = 7$ 个顶点。由于它们的顶点数不同，这两组邻接图是不相交的。因此，在点级定义下与 $G$ 邻接的图的总数是删除和添加计数之和。\n$$ N_{\\text{node}} = |V| + (|U| - |V|) \\times 2^{|V|} = 6 + (10 - 6) \\times 2^6 = 6 + 4 \\times 64 = 6 + 256 = 262 $$\n因此，在点级邻接下，有 $262$ 个与 $G$ 邻接的不同图。\n\n最终计数为，边级邻接是 $15$，点级邻接是 $262$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 15 & 262 \\end{pmatrix}}$$"
        },
        {
            "introduction": "拉普拉斯机制通过添加与查询的全局敏感度成比例的噪声来提供隐私。本练习将这一核心概念应用于一个常见的网络统计量——三角形计数。通过计算该查询的敏感度并应用该机制，您将获得在私有化图度量以及推理噪声结果属性的全过程中的实践经验。",
            "id": "4272501",
            "problem": "考虑一个简单、无向、无权图 $G$，其顶点集为带标签的顶点 $V=\\{1,2,3,4,5\\}$，边集为\n$$\nE=\\{(1,2),(2,3),(3,1),(3,4),(4,5),(5,3),(2,4)\\}.\n$$\n令 $T$ 表示 $G$ 中不同三角形的数量，其中三角形是指由三个不同顶点组成的3-环。现需在边级差分隐私 (DP) 下发布三角形计数，其中如果两个图恰好相差一条边，则它们是相邻的。该过程使用拉普拉斯机制，隐私参数为 $\\epsilon=\\ln(2)$。\n\n从边级差分隐私的定义和函数全局敏感度的概念出发，确定由拉普拉斯机制产生的带噪声的三角形计数 $Z$ 为非负的精确概率。假设拉普拉斯机制添加一个噪声变量 $X$，该变量从均值为零、尺度参数经选择以满足参数为 $\\epsilon$ 的边级差分隐私的拉普拉斯分布中抽取，并且该机制发布 $Z=T+X$。\n\n请以单个实数的形式给出你的最终概率。无需四舍五入。",
            "solution": "用户提供了一个需要解决的问题。首先，我将根据指定的标准验证问题陈述。\n\n### 步骤1：提取已知条件\n- 图 $G$：一个简单、无向、无权图。\n- 顶点集 $V$：$V=\\{1,2,3,4,5\\}$，因此顶点数为 $n=5$。\n- 边集 $E$：$E=\\{(1,2),(2,3),(3,1),(3,4),(4,5),(5,3),(2,4)\\}$.\n- 查询函数 $f(G)=T$：$T$ 是 $G$ 中不同三角形（3-环）的数量。\n- 隐私模型：边级差分隐私 (DP)，其中邻接性定义为恰好相差一条边。\n- 隐私参数 $\\epsilon$：$\\epsilon=\\ln(2)$。\n- 机制：拉普拉斯机制，它添加从零均值拉普拉斯分布中抽取的噪声 $X$。\n- 带噪声的输出 $Z$：$Z=T+X$。\n- 目标：确定精确概率 $P(Z \\ge 0)$。\n\n### 步骤2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n\n- **科学性：** 该问题使用了图论（简单图、三角形）和计算机科学（差分隐私、拉普拉斯机制、全局敏感度）中的标准、成熟的概念。所有概念在数学上都是严谨的，在科学上也是合理的。\n- **良态性：** 图被明确定义，查询是清晰的（计算三角形），隐私机制的参数也已指定。问题要求一个唯一可确定的概率。顶点数固定为 $n=5$，这对于确定全局敏感度至关重要。\n- **客观性：** 问题以精确、正式的语言陈述。没有主观或模糊的术语。\n- **完整性：** 提供了所有必要的信息。图的结构、查询、隐私定义和机制参数都已给出。\n- **一致性：** 所提供的信息内部一致。具有给定顶点集和边集的简单无向图是一个有效的数学对象。\n\n### 步骤3：结论和行动\n问题是**有效的**。这是一个将差分隐私原理应用于基于图的查询的标准练习。我将继续提供完整解答。\n\n### 解题过程\n\n解题过程分为四个步骤：\n1.  计算图 $G$ 中三角形的真实数量 $T$。\n2.  确定三角形计数函数在边级差分隐私下的全局敏感度。\n3.  根据敏感度和隐私参数 $\\epsilon$ 定义用于噪声的具体拉普拉斯分布。\n4.  计算带噪声的计数为非负的概率。\n\n**步骤1：计算真实的三角形数量 $T$**\n图 $G$ 的顶点集为 $V=\\{1,2,3,4,5\\}$，无向边集为 $E=\\{\\{1,2\\}, \\{2,3\\}, \\{1,3\\}, \\{3,4\\}, \\{4,5\\}, \\{3,5\\}, \\{2,4\\}\\}$。一个三角形是由三个顶点 $\\{u,v,w\\}$ 组成的集合，使得边 $\\{u,v\\}, \\{v,w\\}, \\{w,u\\}$ 都在 $E$ 中。我们找出所有这样的集合：\n- 三角形1：顶点 $\\{1,2,3\\}$。边 $\\{1,2\\}\\in E$、$\\{2,3\\}\\in E$ 和 $\\{1,3\\}\\in E$ 都存在。这构成一个三角形。\n- 三角形2：顶点 $\\{2,3,4\\}$。边 $\\{2,3\\}\\in E$、$\\{3,4\\}\\in E$ 和 $\\{2,4\\}\\in E$ 都存在。这构成一个三角形。\n- 三角形3：顶点 $\\{3,4,5\\}$。边 $\\{3,4\\}\\in E$、$\\{4,5\\}\\in E$ 和 $\\{3,5\\}\\in E$ 都存在。这构成一个三角形。\n\n通过检查，没有其他三个顶点的组合能构成三角形。例如，对于 $\\{1,3,4\\}$，缺少边 $\\{1,4\\}$。\n因此，三角形的真实数量是 $T=3$。\n\n**步骤2：确定全局敏感度 $GS_f$**\n查询是三角形计数函数 $f(G)=T$。隐私模型是边级差分隐私，因此如果两个图 $G_1$ 和 $G_2$ 相差一条边，则它们是相邻的。函数 $f$ 的全局敏感度，记为 $GS_f$，定义为在所有相邻图对上 $f$ 的最大可能变化：\n$$GS_f = \\max_{G_1, G_2 \\text{ adjacent}} |f(G_1) - f(G_2)|$$\n我们来考虑向图中添加一条边 $\\{u,v\\}$ 的影响。只有当新三角形包含新边 $\\{u,v\\}$ 时，才会形成新的三角形。对于每个同时是 $u$ 和 $v$ 的共同邻居的现有顶点 $w$，都会形成一个新的三角形 $\\{u,v,w\\}$。因此，三角形数量的变化等于 $u$ 和 $v$ 的共同邻居的数量。\n\n为了找到全局敏感度，我们必须在任何具有 $n=5$ 个顶点的图上，找出任意两个顶点 $u$ 和 $v$ 的最大可能共同邻居数。对于两个不相邻的顶点 $u$ 和 $v$，它们可以拥有的最大共同邻居数是图中所有其他顶点的数量，即 $n-2$。在我们的例子中，$n=5$，所以最大变化是 $5-2=3$。一个实现这个最大值的示例图是：顶点 $u$ 和 $v$ 不相连，但它们都与所有其他 $3$ 个顶点相连。添加边 $\\{u,v\\}$ 将恰好创建 $3$ 个新三角形。\n移除一条边是相反的操作，其最大影响也是 $n-2$。因此，在具有 $n=5$ 个顶点的图上，三角形计数函数的全局敏感度为：\n$$GS_f = n-2 = 5-2=3$$\n\n**步骤3：定义拉普拉斯分布**\n拉普拉斯机制向真实计数 $T$ 添加来自拉普拉斯分布 $X \\sim \\text{Lap}(0, b)$ 的噪声。为了满足 $\\epsilon$-差分隐私，尺度参数 $b$ 被设置为 $b = GS_f / \\epsilon$。\n给定 $\\epsilon = \\ln(2)$ 和 $GS_f = 3$，尺度参数为：\n$$b = \\frac{GS_f}{\\epsilon} = \\frac{3}{\\ln(2)}$$\n$X$ 的概率密度函数 (PDF) 是 $p(x) = \\frac{1}{2b} \\exp\\left(-\\frac{|x|}{b}\\right)$。\n\n**步骤4：计算所需概率**\n带噪声的计数是 $Z = T+X$。我们需要计算概率 $P(Z \\ge 0)$。\n代入我们找到的值：\n$$P(Z \\ge 0) = P(3 + X \\ge 0) = P(X \\ge -3)$$\n这个概率可以通过将PDF从 $-3$ 积分到 $\\infty$ 来计算，或者更简单地使用累积分布函数 (CDF) 来计算。$P(X \\ge -3) = 1 - P(X  -3)$。由于拉普拉斯分布是连续的，这等于 $1 - P(X \\le -3)$。\n\n对于 $x \\le 0$，拉普拉斯分布 $\\text{Lap}(0, b)$ 的累积分布函数 (CDF) 由下式给出：\n$$F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} \\frac{1}{2b} \\exp\\left(\\frac{t}{b}\\right) dt = \\frac{1}{2b} \\left[ b \\exp\\left(\\frac{t}{b}\\right) \\right]_{-\\infty}^{x} = \\frac{1}{2}\\exp\\left(\\frac{x}{b}\\right)$$\n我们需要计算当 $x=-3$ 时的值：\n$$P(X \\le -3) = F_X(-3) = \\frac{1}{2}\\exp\\left(\\frac{-3}{b}\\right)$$\n现在，我们代入 $b = \\frac{3}{\\ln(2)}$ 的值：\n$$\\frac{-3}{b} = \\frac{-3}{3/\\ln(2)} = -\\ln(2)$$\n将此结果代回CDF表达式：\n$$P(X \\le -3) = \\frac{1}{2} \\exp(-\\ln(2)) = \\frac{1}{2} \\cdot \\frac{1}{\\exp(\\ln(2))} = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}$$\n最后，我们寻求的概率是：\n$$P(Z \\ge 0) = P(X \\ge -3) = 1 - P(X \\le -3) = 1 - \\frac{1}{4} = \\frac{3}{4}$$\n这对应于数值 $0.75$。",
            "answer": "$$\\boxed{\\frac{3}{4}}$$"
        },
        {
            "introduction": "差分隐私机制产生的噪声输出往往缺乏有效数据的结构特性，例如，一个带噪的度序列可能不是可图化的。本练习探讨了后处理这一关键属性，它允许我们在不违反隐私保证的情况下修正这些输出以恢复其有效性。您将分析不同的策略，以理解如何在实际的数据合成流程中正确应用这一强大原则。",
            "id": "4272470",
            "problem": "考虑一个具有 $n$ 个顶点和度序列 $d(G) \\in \\mathbb{Z}_{\\ge 0}^{n}$ 的无向简单图。设 $\\mathcal{M}$ 是一个机制，它在输入一个图 $G$ 时，输出一个带噪声的度向量 $\\tilde{d} \\in \\mathbb{R}^{n}$，并且在边级邻接性（如果两个图因添加或删除一条边而不同，则它们是邻接的）方面是 $(\\varepsilon,\\delta)$-差分隐私的。如果存在一个具有 $n$ 个顶点且度序列等于 $x$ 的简单无向图，则称序列 $x \\in \\mathbb{Z}_{\\ge 0}^{n}$ 是可图化的。Havel–Hakimi 过程接受一个非递增序列，并重复移除最大项，然后从接下来的最大项中各减去 $1$，如果出现负数则宣告失败；Havel–Hakimi 定理指出，一个序列是可图化的当且仅当该过程成功并在全零序列处终止。\n\n您希望定义一个投影算子，将 $\\tilde{d}$ 映射到一个在指定距离下尽可能接近的可图化度序列，然后使用 Havel–Hakimi 过程来生成一个具有该度序列的简单图。目标是确保从 $\\tilde{d}$ 到最终图的整个映射通过应用后处理属性来保持 $(\\varepsilon,\\delta)$-差分隐私。后处理属性指出，如果一个随机算法是 $(\\varepsilon,\\delta)$-差分隐私的，那么其输出的任何（可能是随机的）函数，只要不额外访问私有数据，也是 $(\\varepsilon,\\delta)$-差分隐私的。\n\n以下哪个提议既正确地定义了这样一个到最近的可图化序列的投影，又正确地证明了为什么将其与 $\\mathcal{M}$ 组合能保持 $(\\varepsilon,\\delta)$-差分隐私？\n\nA. 将 $\\Pi(\\tilde{d})$ 定义为\n$$\n\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{1}\n$$\n的唯一元素，其中 $\\mathcal{G}_{n}$ 是所有长度为 $n$ 的非递增可图化序列的集合，并使用确定性的字典序决断规则来确保唯一性。然后通过在 $\\Pi(\\tilde{d})$ 上运行 Havel–Hakimi 构造来输出一个度序列为 $\\Pi(\\tilde{d})$ 的简单图 $H$。因为 $\\Pi$ 和 Havel–Hakimi 都只是 $\\tilde{d}$ 的确定性函数，所以根据后处理不变性，组合 $G \\mapsto \\mathcal{M}(G) \\mapsto \\Pi(\\tilde{d}) \\mapsto H$ 是 $(\\varepsilon,\\delta)$-差分隐私的。\n\nB. 在排序后直接对 $\\tilde{d}$ 运行 Havel–Hakimi 过程，并在此过程中将任何负的中间减法结果替换为 $0$，从而生成一个度序列。仅当映射在 $\\ell_{1}$ 中是 $1$-Lipschitz 的，该过程才能保持隐私，而 Havel–Hakimi 过程不满足此条件，因此为了维持 $(\\varepsilon,\\delta)$-差分隐私，必须在投影后添加一轮新的独立噪声。\n\nC. 将投影 $\\Pi_{2}(\\tilde{d})$ 定义为一个 $\\ell_{2}$ 最近的可图化序列，即\n$$\n\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{2},\n$$\n然后应用 Havel–Hakimi 来生成一个图。这会产生 Havel–Hakimi 意义上的最近可图化序列，因为该过程等价于度空间上的 $\\ell_{2}$ 投影，并且只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私才能得到保护。\n\nD. 通过先从 $\\mathcal{M}(G)$ 计算 $\\tilde{d}$，然后使用来自原始私有图 $G$ 的旁路信息来打破平局，以偏向更接近 $d(G)$ 的序列，从而定义 $\\Pi(\\tilde{d}; G)$，以最小化对真实度序列的期望失真。这种构造保持了 $(\\varepsilon,\\delta)$-差分隐私，因为后处理属性允许在释放 $\\tilde{d}$ 后进行任意依赖于数据的精化。\n\nE. 通过将 $\\tilde{d}$ 裁剪并排序到 $[0,n]$ 区间内，四舍五入到最近的整数，如果和为奇数，则将最小的项加 $1$ 来定义 $\\Pi(\\tilde{d})$；然后从该 $\\ell_{1}$ 距离下的所有可图化序列中均匀随机选择一个，并应用 Havel–Hakimi。仅当决断平局的随机性独立于 $\\tilde{d}$ 时，这种组合才能保持 $(\\varepsilon,\\delta)$-差分隐私；否则后处理不变性可能失效。",
            "solution": "这是一个关于差分隐私在网络数据分析中应用的问题。问题的核心在于理解差分隐私的后处理属性，并将其正确应用于一个多阶段数据分析流程。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n*   **输入数据：** 一个具有 $n$ 个顶点的无向简单图 $G$。\n*   **真实查询结果：** 图的度序列，$d(G) \\in \\mathbb{Z}_{\\ge 0}^{n}$。\n*   **隐私机制：** 一个机制 $\\mathcal{M}$，它以 $G$ 为输入并输出一个带噪声的度向量 $\\tilde{d} \\in \\mathbb{R}^{n}$。\n*   **隐私保证：** 机制 $\\mathcal{M}$ 在边级邻接性方面是 $(\\varepsilon,\\delta)$-差分隐私的。\n*   **邻接定义：** 如果两个图因添加或删除一条边而不同，则它们是邻接的。\n*   **关键定义：**\n    *   如果一个序列 $x \\in \\mathbb{Z}_{\\ge 0}^{n}$ 是某个具有 $n$ 个顶点的简单无向图的度序列，则称其为“可图化的”。\n    *   “Havel–Hakimi 过程”是一种用于测试非递增序列是否可图化的算法。“Havel–Hakimi 定理”指出该过程是一个充分必要测试。一个构造性版本可以从一个可图化序列生成一个图。\n*   **目标：** 定义一个从噪声向量 $\\tilde{d}$ 到简单图 $H$ 的映射，使得 $H$ 具有一个可图化的度序列，并且整个过程（从 $G$ 到 $H$）保持 $(\\varepsilon,\\delta)$-差分隐私。\n*   **隐私保护方法：** 组合映射的隐私性必须通过“后处理属性”来证明。\n*   **后处理属性：** 如果一个随机算法是 $(\\varepsilon,\\delta)$-差分隐私的，那么其输出的任何（可能是随机的）函数，只要不额外访问私有数据，也是 $(\\varepsilon,\\delta)$-差分隐私的。\n\n**步骤2：使用已知条件进行验证**\n\n*   **科学基础：** 该问题牢固地植根于图论（度序列、可图化序列、Havel–Hakimi 定理）和差分隐私理论（边级隐私、后处理属性）中的既定概念。将带噪声的、非可图化的度序列变为可图化的任务是隐私图分析中的一个标准问题。\n*   **适定性：** 问题是适定的。它提出了一个明确的目标和一组候选解决方案（选项 A-E）。任务是评估每个候选方案所提议的程序及其理由的正确性，这是一个概念性问题的标准格式。\n*   **客观性：** 问题陈述使用精确、客观和形式化的数学语言编写。没有主观或含糊的术语。\n*   **缺陷核对清单：**\n    1.  **科学/事实不健全：** 否。所有概念都是标准的并且陈述正确。\n    2.  **不可形式化/不相关：** 否。问题是形式化的，并且与指定主题直接相关。\n    3.  **设置不完整/矛盾：** 否。提供了评估选项所需的所有必要定义和约束。\n    4.  **不切实际/不可行：** 否。该设置描述了隐私数据分析中的一个标准理论问题。\n    5.  **不适定/结构不良：** 否。通过根据所提供的定义分析选项，可以确定唯一的正确答案。\n    6.  **故作高深/琐碎：** 否。该问题需要仔细理解后处理属性，这是差分隐私中一个微妙但基本的概念。\n    7.  **超出科学可验证性：** 否。每个选项的正确性都可以根据差分隐私和图论的数学定义进行严格验证。\n\n**步骤3：结论与行动**\n\n问题陈述有效。我将继续进行解答。\n\n### 求解推导\n\n要应用的核心原则是差分隐私的**后处理属性**。设私有输入为图 $G$。机制 $\\mathcal{M}$ 计算 $\\tilde{d} = \\mathcal{M}(G)$，并且此计算是 $(\\varepsilon,\\delta)$-差分隐私的。目标是对输出 $\\tilde{d}$ 应用某个函数或一系列函数（我们将复合函数称为 $f$）以获得最终的图 $H$。整个过程是 $H = f(\\mathcal{M}(G))$。后处理属性保证 $H$ 也是一个 $(\\varepsilon,\\delta)$-差分隐私的输出，前提是函数 $f$ 不依赖于私有输入 $G$。函数 $f$ 可以是确定性的或随机的，它可以依赖于任何公共信息，但它访问敏感信息的唯一途径是通过已经隐私化的输出 $\\tilde{d}$。\n\n提议的流程是 $\\tilde{d} \\xrightarrow{\\Pi} x \\xrightarrow{\\text{Havel-Hakimi}} H$，其中 $x$ 是一个可图化的度序列。因此，复合函数是 $f(\\tilde{d}) = \\text{Havel-Hakimi}(\\Pi(\\tilde{d}))$。为了使这是一个有效的后处理链，投影 $\\Pi$ 和 Havel-Hakimi 构造都不能使用原始图 $G$。\n\n让我们基于这个原则评估每个选项。\n\n**A. 将 $\\Pi(\\tilde{d})$ 定义为 $\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{1}$ 的唯一元素，其中 $\\mathcal{G}_{n}$ 是所有长度为 $n$ 的非递增可图化序列的集合，并使用确定性的字典序决断规则来确保唯一性。然后通过在 $\\Pi(\\tilde{d})$ 上运行 Havel–Hakimi 构造来输出一个度序列为 $\\Pi(\\tilde{d})$ 的简单图 $H$。因为 $\\Pi$ 和 Havel–Hakimi 都只是 $\\tilde{d}$ 的确定性函数，所以根据后处理不变性，组合 $G \\mapsto \\mathcal{M}(G) \\mapsto \\Pi(\\tilde{d}) \\mapsto H$ 是 $(\\varepsilon,\\delta)$-差分隐私的。**\n\n*   **分析：** 该提议定义了一个两步的后处理函数。\n    1.  投影 $\\Pi$：此函数接受 $\\tilde{d}$ 并在集合 $\\mathcal{G}_n$ 中根据 $\\ell_1$ 范数找到最近的可图化序列。集合 $\\mathcal{G}_n$ 仅依赖于 $n$，这是公共信息。优化问题的目标函数 $\\|x - \\tilde{d}\\|_1$ 仅依赖于输入 $\\tilde{d}$。确定性的决断规则确保了对于任何给定的 $\\tilde{d}$，函数 $\\Pi(\\tilde{d})$ 都是唯一确定的。因此，$\\Pi$ 是 $\\tilde{d}$ 的一个确定性函数，不使用私有图 $G$。\n    2.  Havel-Hakimi 构造：此算法接受一个可图化的度序列并构造一个相应的图。它是一个确定性算法，仅对其输入——可图化序列 $\\Pi(\\tilde{d})$ 进行操作。它不需要访问 $G$。\n*   **理由：** 理由是，由于这两个步骤都只是 $\\tilde{d}$ 的函数，它们的组合也只是 $\\tilde{d}$ 的函数。这是正确的。将一个独立于私有数据的函数应用于一个 $(\\varepsilon,\\delta)$-DP 输出，会得到一个同样满足 $(\\varepsilon,\\delta)$-DP 的输出。这是对后处理属性的直接和正确的应用。\n*   **结论：** **正确**。\n\n**B. 在排序后直接对 $\\tilde{d}$ 运行 Havel–Hakimi 过程，并在此过程中将任何负的中间减法结果替换为 $0$，从而生成一个度序列。仅当映射在 $\\ell_{1}$ 中是 $1$-Lipschitz 的，该过程才能保持隐私，而 Havel–Hakimi 过程不满足此条件，因此为了维持 $(\\varepsilon,\\delta)$-差分隐私，必须在投影后添加一轮新的独立噪声。**\n\n*   **分析：** 该选项提出了一个程序化的投影。所提供的理由完全是错误的。后处理属性并*不*要求后处理函数是 Lipschitz 的或具有任何特定的敏感度。敏感度和 Lipschitz 属性与设计隐私机制（$\\mathcal{M}$）有关，而与后处理其输出无关。“仅当映射是 1-Lipschitz 时才保持隐私”的说法是错误的。此外，“添加一轮新的独立噪声”的建议是不必要的，且会适得其反。隐私保证已经由 $\\mathcal{M}$ 确保；添加更多噪声只会降低结果的效用，而不会带来隐私增益。\n*   **结论：** **不正确**。\n\n**C. 将投影 $\\Pi_{2}(\\tilde{d})$ 定义为一个 $\\ell_{2}$ 最近的可图化序列，即 $\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{2}$，然后应用 Havel–Hakimi 来生成一个图。这会产生 Havel–Hakimi 意义上的最近可图化序列，因为该过程等价于度空间上的 $\\ell_{2}$ 投影，并且只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私才能得到保护。**\n\n*   **分析：** 该选项的理由有两个主要缺陷。\n    1.  “只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私才能得到保护”：这是错误的。后处理属性的成立与投影步骤中使用的度量（$\\ell_1$、$\\ell_2$ 或其他）无关，只要投影函数不访问私有数据 $G$。范数的选择影响效用（哪个序列被认为是“最近的”），而非隐私。\n    2.  “Havel–Hakimi ... 等价于度空间上的 $\\ell_{2}$ 投影”：这在事实上是不正确的。Havel-Hakimi 过程是用于测试可图性的组合算法。它不是执行 $\\ell_2$ 投影的优化过程。\n*   **结论：** **不正确**。\n\n**D. 通过先从 $\\mathcal{M}(G)$ 计算 $\\tilde{d}$，然后使用来自原始私有图 $G$ 的旁路信息来打破平局，以偏向更接近 $d(G)$ 的序列，从而定义 $\\Pi(\\tilde{d}; G)$，以最小化对真实度序列的期望失真。这种构造保持了 $(\\varepsilon,\\delta)$-差分隐私，因为后处理属性允许在释放 $\\tilde{d}$ 后进行任意依赖于数据的精化。**\n\n*   **分析：** 该提议明确定义了投影函数 $\\Pi$ 依赖于私有数据 $G$，记为 $\\Pi(\\tilde{d}; G)$。这直接且根本地违反了后处理属性的条件。一个使用原始私有数据的函数不是后处理步骤；它是对私有数据的新计算。这样的复合算法不能保证是 $(\\varepsilon,\\delta)$-DP，并且需要单独进行完整的隐私分析（很可能会失败）。后处理“允许任意依赖于数据的精化”的理由与该属性的定义直接矛盾，该属性要求独立于私有数据。\n*   **结论：** **不正确**。\n\n**E. 通过将 $\\tilde{d}$ 裁剪并排序到 $[0,n]$ 区间内，四舍五入到最近的整数，如果和为奇数，则将最小的项加 $1$ 来定义 $\\Pi(\\tilde{d})$；然后从该 $\\ell_{1}$ 距离下的所有可图化序列中均匀随机选择一个，并应用 Havel–Hakimi。仅当决断平局的随机性独立于 $\\tilde{d}$ 时，这种组合才能保持 $(\\varepsilon,\\delta)$-差分隐私；否则后处理不变性可能失效。**\n\n*   **分析：** 该选项提出了一个随机化的后处理过程。一个随机化的后处理步骤是允许的。然而，其理由包含一个关键错误。它声称隐私被保留“仅当决断平局的随机性独立于 $\\tilde{d}$ 时”。这是错误的。一个随机化的后处理函数 $f(\\tilde{d}, r)$，其中 $r$ 是随机源，仍然保持隐私。随机性 $r$ 必须独立于私有数据 $G$，但 $r$ 的分布依赖于 $\\tilde{d}$ 是完全可以接受的。例如，可以使用 $\\tilde{d}$ 的哈希值来为一个伪随机数生成器提供种子。这不违反后处理属性。只有当随机性依赖于 $G$ 时，该属性才会失效。该选项中陈述的条件是不必要的限制并且不正确。\n*   **结论：** **不正确**。\n\n总之，只有选项 A 正确描述了一个有效的后处理流程，并基于差分隐私的后处理属性给出了正确的理由。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}