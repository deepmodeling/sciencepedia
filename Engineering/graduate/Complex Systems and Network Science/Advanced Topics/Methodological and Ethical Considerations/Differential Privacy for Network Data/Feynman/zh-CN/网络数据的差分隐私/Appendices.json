{
    "hands_on_practices": [
        {
            "introduction": "在网络数据上应用差分隐私的第一步，是精确定义何为“邻近”数据集。与传统表格数据不同，网络的邻近关系有多种定义，最常见的包括边隐私和节点隐私。本练习将通过一个具体的图例，让你亲手实践这两种邻近关系的定义，从而对不同隐私模型下邻近图的数量规模建立起直观的认识。",
            "id": "4272484",
            "problem": "在网络数据的差分隐私 (DP) 背景下，考虑一个简单的无向标记图数据集。设数据全集为一个固定的标记节点集 $U = \\{1,2,\\dots,10\\}$，其大小为 $m=10$。发布的数据集是一个图 $G=(V,E)$，其中 $V = \\{1,2,3,4,5,6\\} \\subset U$，边集为 $E = \\{(1,2),(1,3),(2,3),(3,4),(4,5),(5,6)\\}$。每条边 $(i,j)$ 表示不同节点 $i$ 和 $j$ 之间的一条无向连接，不允许自环或多重边。\n\n在网络数据中使用 DP 的标准邻接关系：\n- 边级邻接：在同一固定顶点集 $V$ 上的两个图，如果它们的边集仅在一个无序节点对上不同（即添加或删除一条边），则它们是邻接的。\n- 节点级邻接：在 $U$ 的顶点子集上的两个图，如果它们因从 $U$ 中包含或排除恰好一个节点及其所有关联边而不同，则它们是邻接的。具体来说，移除一个现有节点 $v \\in V$ 会删除 $v$ 以及所有与 $w \\in V$ 的边 $(v,w)$。添加一个节点 $u \\in U \\setminus V$ 会引入 $u$ 及其关联边，这些边将 $u$ 连接到当前节点集 $V$ 的任意子集；$V$ 中节点之间的边保持不变。\n\n仅从这些定义出发，根据第一性原理推导出一个完全枚举的论证，说明在每种邻接概念下，有多少个不同的数据集（图）与 $G$ 邻接。您必须将节点视为由 $U$ 标记，并且必须假设在所有邻接数据集中，图都保持为简单无向图。分别提供在边级邻接和节点级邻接下与 $G$ 邻接的图的数量的最终计数，结果为精确整数。无需四舍五入。您的最终答案应表示为单行中的两个数字，顺序为：边级计数，节点级计数。",
            "solution": "问题陈述已经过分析，被认为是有效的。它在科学上基于网络数据的差分隐私理论，提供了一个自洽且一致的设定，使用了精确无歧义的语言，并且问题提取得当，允许一个唯一且有意义的解。我们可以继续进行推导。\n\n问题要求我们确定在两种不同的邻接概念（边级和节点级）下，与给定图 $G=(V,E)$ 邻接的不同图的数量。给定图的顶点集为 $V = \\{1,2,3,4,5,6\\}$，边集为 $E = \\{(1,2),(1,3),(2,3),(3,4),(4,5),(5,6)\\}$。顶点集的大小为 $|V|=6$，边的数量为 $|E|=6$。节点全集为 $U = \\{1,2,\\dots,10\\}$，大小为 $|U|=10$。\n\n**1. 边级邻接**\n\n边级邻接的定义指出，如果两个图位于同一固定顶点集 $V$ 上，并且它们的边集恰好相差一条边，则它们是邻接的。因此，一个邻接图 $G'$ 可以通过以下两种互斥方式之一从 $G$ 形成：\n- 通过添加一条 $G$ 中不存在的边。\n- 通过删除一条 $G$ 中存在的边。\n\n顶点集 $V$ 是固定的，大小为 $|V|=6$。在一个具有 $n=|V|$ 个标记顶点的简单图中，可能存在的无向边的总数由二项式系数 $\\binom{n}{2}$ 给出。\n对于 $G$，顶点集 $V$ 上可能存在的边的总数为：\n$$ \\binom{|V|}{2} = \\binom{6}{2} = \\frac{6 \\times 5}{2} = 15 $$\n图 $G$ 有 $|E|=6$ 条边。\n\n通过**加边**形成的邻接图的数量等于 $G$ 中不存在的边的数量。这是可能存在的总边数减去现有边数。\n$$ \\text{加边数量} = \\binom{6}{2} - |E| = 15 - 6 = 9 $$\n这 $9$ 种加边操作中的每一种都会产生一个与 $G$ 邻接的唯一图。\n\n通过**删边**形成的邻接图的数量等于 $G$ 中现有边的数量。\n$$ \\text{删边数量} = |E| = 6 $$\n这 $6$ 种删边操作中的每一种都会产生一个与 $G$ 邻接的唯一图。\n\n由于加边和删边操作产生不同的图集，因此在边级定义下，与 $G$ 邻接的图的总数是这两个计数的和。\n$$ N_{\\text{edge}} = (\\binom{6}{2} - |E|) + |E| = 9 + 6 = 15 $$\n因此，在边级邻接下，有 $15$ 个不同的图与 $G$ 邻接。\n\n**2. 节点级邻接**\n\n节点级邻接的定义指出，如果两个图因从全集 $U$ 中包含或排除恰好一个节点及其所有关联边而不同，则它们是邻接的。我们从图 $G=(V,E)$ 开始，其中 $V \\subset U$。一个邻接图 $G'$ 可以通过以下两种互斥方式之一形成：\n- 通过删除一个节点 $v \\in V$ 及其所有关联边。\n- 通过添加一个节点 $u \\in U \\setminus V$ 以及一组将 $u$ 连接到 $V$ 中节点某个子集的边。\n\n初始顶点集的大小为 $|V|=6$。节点全集的大小为 $|U|=10$。\n\n通过**删点**形成的邻接图的数量等于 $V$ 中可以被移除的节点数。\n$$ \\text{可移除节点数} = |V| = 6 $$\n移除任何节点 $v \\in V$ 都会得到一个顶点集为 $V \\setminus \\{v\\}$、大小为 $5$ 的新图。由于移除不同的节点会产生具有不同顶点集的图，因此这 $6$ 个结果图都是唯一的。\n\n通过**加点**形成的邻接图的数量取决于全集 $U$ 中不在 $V$ 里的可用节点。可用节点集为 $U \\setminus V = \\{7,8,9,10\\}$。\n$$ \\text{可添加节点数} = |U \\setminus V| = |U| - |V| = 10 - 6 = 4 $$\n根据定义，当添加一个节点 $u \\in U \\setminus V$ 时，它可以通过新边连接到 $V$ 中现有节点的任意子集。$V$ 中的节点集大小为 $|V|=6$。$V$ 的子集数量为 $2^{|V|}$。\n$$ \\text{一个新节点的可能边连接数} = 2^{|V|} = 2^6 = 64 $$\n对于我们可以选择添加的 $4$ 个节点中的每一个，都有 $64$ 种可能的方式将其连接到 $V$ 中的节点。每个添加的节点和一组新边的组合都形成一个不同的邻接图。通过添加节点 $u_1$ 产生的图与通过添加不同节点 $u_2$ 产生的图是不同的，因为它们的顶点集 $V \\cup \\{u_1\\}$ 和 $V \\cup \\{u_2\\}$ 是不同的。\n因此，通过加点形成的邻接图总数是可添加节点数与连接模式数的乘积。\n$$ \\text{加点数量} = |U \\setminus V| \\times 2^{|V|} = 4 \\times 2^6 = 4 \\times 64 = 256 $$\n\n通过删点形成的图有 $|V|-1 = 5$ 个顶点，而通过加点形成的图有 $|V|+1 = 7$ 个顶点。由于它们的顶点数不同，这两组邻接图是不相交的。因此，在节点级定义下，与 $G$ 邻接的图的总数是删除和添加计数的总和。\n$$ N_{\\text{node}} = |V| + (|U| - |V|) \\times 2^{|V|} = 6 + (10 - 6) \\times 2^6 = 6 + 4 \\times 64 = 6 + 256 = 262 $$\n因此，在节点级邻接下，有 $262$ 个不同的图与 $G$ 邻接。\n\n最终计数为：边级邻接有 $15$ 个，节点级邻接有 $262$ 个。",
            "answer": "$$\\boxed{\\begin{pmatrix} 15  262 \\end{pmatrix}}$$"
        },
        {
            "introduction": "拉普拉斯机制是实现差分隐私的核心工具之一，其关键在于计算查询函数的“全局敏感度”。本练习旨在将理论付诸实践，要求你为一个常见的图查询（三角形计数）计算全局敏感度，并应用拉普拉斯机制添加噪声。通过这个过程，你将掌握如何为特定图查询设计和分析一个基本的差分隐私算法。",
            "id": "4272501",
            "problem": "考虑一个简单的、无向的、无权重的图 $G$，其顶点集为带标签的 $V=\\{1,2,3,4,5\\}$，边集为\n$$\nE=\\{\\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{2,4\\}, \\{3,4\\}, \\{3,5\\}, \\{4,5\\}\\}.\n$$\n令 $T$ 表示图 $G$ 中不同三角形的数量，其中三角形是指由三个不同顶点组成的 $3$-环。您希望在边级差分隐私（DP）下发布三角形计数，其中如果两个图恰好相差一条边，则它们是邻接的。使用拉普拉斯机制，隐私参数为 $\\epsilon=\\ln(2)$。\n\n从边级 DP 的定义和函数全局敏感度的概念出发，确定由拉普拉斯机制产生的带噪声的三角形计数 $Z$ 为非负的精确概率。假设拉普拉斯机制添加一个噪声变量 $X$，该变量从均值为零、尺度参数选择为满足边级 DP（参数为 $\\epsilon$）的拉普拉斯分布中抽取，并且该机制发布 $Z=T+X$。\n\n请将最终概率以单个实数形式给出。无需四舍五入。",
            "solution": "用户提供了一个需要解决的问题。首先，我将根据指定标准验证问题陈述。\n\n### 步骤 1：提取已知信息\n- 图 $G$：一个简单的、无向的、无权重的图。\n- 顶点集 $V$：$V=\\{1,2,3,4,5\\}$，因此顶点数为 $n=5$。\n- 边集 $E$：$E=\\{\\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{2,4\\}, \\{3,4\\}, \\{3,5\\}, \\{4,5\\}\\}$。\n- 查询函数 $f(G)=T$：$T$ 是图 $G$ 中不同三角形（3-环）的数量。\n- 隐私模型：边级差分隐私（DP），其中邻接性定义为恰好相差一条边。\n- 隐私参数 $\\epsilon$：$\\epsilon=\\ln(2)$。\n- 机制：拉普拉斯机制，它添加一个从均值为零的拉普拉斯分布中抽取的噪声 $X$。\n- 带噪声的输出 $Z$：$Z=T+X$。\n- 目标：确定精确概率 $P(Z \\ge 0)$。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据验证标准对问题进行评估。\n\n- **科学性：** 该问题使用了图论（简单图、三角形）和计算机科学（差分隐私、拉普拉斯机制、全局敏感度）中的标准、成熟概念。所有概念在数学上都是严谨的，在科学上是合理的。\n- **适定性：** 图被明确定义，查询清晰（计算三角形数量），隐私机制的参数也已指定。问题要求一个唯一可确定的概率。顶点数固定为 $n=5$，这对于确定全局敏感度至关重要。\n- **客观性：** 问题以精确、正式的语言陈述。没有主观或模糊的术语。\n- **完整性：** 所有必要信息都已提供。图的结构、查询、隐私定义和机制参数都已给出。\n- **一致性：** 所提供的信息内部一致。一个具有给定顶点集和边集的简单无向图是一个有效的数学对象。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。这是一个将差分隐私原理应用于基于图的查询的标准练习。我将继续提供完整解答。\n\n### 解答\n\n解答过程分为四个步骤：\n1.  计算图 $G$ 中三角形的真实数量 $T$。\n2.  确定边级 DP 下三角形计数函数的全局敏感度。\n3.  根据敏感度和隐私参数 $\\epsilon$ 定义用于噪声的特定拉普拉斯分布。\n4.  计算带噪声的计数为非负的概率。\n\n**步骤 1：计算真实的三角形数量 $T$**\n图 $G$ 的顶点集为 $V=\\{1,2,3,4,5\\}$，无向边集为 $E=\\{\\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{2,4\\}, \\{3,4\\}, \\{3,5\\}, \\{4,5\\}\\}$。三角形是由三个顶点 $\\{u,v,w\\}$ 组成的集合，使得边 $\\{u,v\\}, \\{v,w\\}, \\{w,u\\}$ 都在 $E$ 中。我们找出所有这样的集合：\n- 三角形 1：顶点 $\\{1,2,3\\}$。边 $\\{1,2\\}\\in E$、$\\{2,3\\}\\in E$ 和 $\\{1,3\\}\\in E$ 均存在。这构成一个三角形。\n- 三角形 2：顶点 $\\{2,3,4\\}$。边 $\\{2,3\\}\\in E$、$\\{3,4\\}\\in E$ 和 $\\{2,4\\}\\in E$ 均存在。这构成一个三角形。\n- 三角形 3：顶点 $\\{3,4,5\\}$。边 $\\{3,4\\}\\in E$、$\\{4,5\\}\\in E$ 和 $\\{3,5\\}\\in E$ 均存在。这构成一个三角形。\n\n经检查，没有其他三个顶点的组合能构成三角形。例如，对于 $\\{1,3,4\\}$，缺少边 $\\{1,4\\}$。\n因此，三角形的真实数量为 $T=3$。\n\n**步骤 2：确定全局敏感度 $GS_f$**\n查询是三角形计数函数 $f(G)=T$。隐私模型是边级 DP，因此如果两个图 $G_1$ 和 $G_2$ 相差一条边，则它们是邻接的。$f$ 的全局敏感度（记为 $GS_f$）定义为在所有邻接图对上 $f$ 的最大可能变化：\n$$GS_f = \\max_{G_1, G_2 \\text{ adjacent}} |f(G_1) - f(G_2)|$$\n让我们考虑向图中添加一条边 $\\{u,v\\}$ 的影响。只有当新三角形包含新边 $\\{u,v\\}$ 时，才会形成新三角形。对于每个同时是 $u$ 和 $v$ 的公共邻居的现有顶点 $w$，都会形成一个新三角形 $\\{u,v,w\\}$。因此，三角形数量的变化等于 $u$ 和 $v$ 的公共邻居的数量。\n\n为了找到全局敏感度，我们必须在任何包含 $n=5$ 个顶点的图中，找出任意两个顶点 $u$ 和 $v$ 可能的最大公共邻居数。对于两个不邻接的顶点 $u$ 和 $v$，它们可以拥有的最大公共邻居数是图中所有其他顶点的数量，即 $n-2$。在我们的例子中，$n=5$，因此最大变化是 $5-2=3$。一个实现此最大值的示例图可以是：顶点 $u$ 和 $v$ 未连接，但它们都与所有其他 $3$ 个顶点相连。添加边 $\\{u,v\\}$ 将恰好创建 $3$ 个新三角形。\n移除一条边是相反的操作，其最大影响同样是 $n-2$。因此，在具有 $n=5$ 个顶点的图上，三角形计数函数的全局敏感度为：\n$$GS_f = n-2 = 5-2=3$$\n\n**步骤 3：定义拉普拉斯分布**\n拉普拉斯机制将来自拉普拉斯分布 $X \\sim \\text{Lap}(0, b)$ 的噪声 $X$ 添加到真实计数 $T$ 中。为了满足 $\\epsilon$-差分隐私，尺度参数 $b$ 设置为 $b = GS_f / \\epsilon$。\n给定 $\\epsilon = \\ln(2)$ 和 $GS_f = 3$，尺度参数为：\n$$b = \\frac{GS_f}{\\epsilon} = \\frac{3}{\\ln(2)}$$\n$X$ 的概率密度函数（PDF）为 $p(x) = \\frac{1}{2b} \\exp\\left(-\\frac{|x|}{b}\\right)$。\n\n**步骤 4：计算所需概率**\n带噪声的计数为 $Z = T+X$。我们需要计算概率 $P(Z \\ge 0)$。\n代入我们找到的值：\n$$P(Z \\ge 0) = P(3 + X \\ge 0) = P(X \\ge -3)$$\n这个概率可以通过将 PDF 从 $-3$ 积分到 $\\infty$ 来计算，或者更简单地使用累积分布函数（CDF）。$P(X \\ge -3) = 1 - P(X  -3)$。由于拉普拉斯分布是连续的，这等于 $1 - P(X \\le -3)$。\n\n对于 $x \\le 0$，拉普拉斯分布 $\\text{Lap}(0, b)$ 的 CDF 由下式给出：\n$$F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} \\frac{1}{2b} \\exp\\left(\\frac{t}{b}\\right) dt = \\frac{1}{2b} \\left[ b \\exp\\left(\\frac{t}{b}\\right) \\right]_{-\\infty}^{x} = \\frac{1}{2}\\exp\\left(\\frac{x}{b}\\right)$$\n我们需要在 $x=-3$ 处计算这个值：\n$$P(X \\le -3) = F_X(-3) = \\frac{1}{2}\\exp\\left(\\frac{-3}{b}\\right)$$\n现在，我们代入 $b = \\frac{3}{\\ln(2)}$ 的值：\n$$\\frac{-3}{b} = \\frac{-3}{3/\\ln(2)} = -\\ln(2)$$\n将此结果代回 CDF 表达式中：\n$$P(X \\le -3) = \\frac{1}{2} \\exp(-\\ln(2)) = \\frac{1}{2} \\cdot \\frac{1}{\\exp(\\ln(2))} = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}$$\n最后，我们寻求的概率是：\n$$P(Z \\ge 0) = P(X \\ge -3) = 1 - P(X \\le -3) = 1 - \\frac{1}{4} = \\frac{3}{4}$$\n这对应于数值 $0.75$。",
            "answer": "$$\\boxed{\\frac{3}{4}}$$"
        },
        {
            "introduction": "差分隐私机制产生的原始含噪输出往往不直接可用，例如，一个含噪的度序列可能不对应任何有效的简单图。差分隐私的“后处理”性质是一个强大的特性，它允许我们在不破坏隐私保证的前提下“修正”这些输出。本练习将挑战你识别一个正确的后处理流程，该流程能从一个含噪的度序列中构造出一个有效的图，从而巩固你对后处理性质成立条件的理解。",
            "id": "4272470",
            "problem": "考虑一个具有 $n$ 个顶点的无向简单图，其度序列为 $d(G) \\in \\mathbb{Z}_{\\ge 0}^{n}$。设 $\\mathcal{M}$ 是一个机制，输入一个图 $G$，输出一个带噪声的度向量 $\\tilde{d} \\in \\mathbb{R}^{n}$，并且该机制在边级别邻接关系下是 $(\\varepsilon,\\delta)$-差分隐私的（如果两个图仅相差一条边的添加或移除，则它们是邻接的）。如果存在一个具有 $n$ 个顶点的简单无向图，其度序列等于 $x$，则称序列 $x \\in \\mathbb{Z}_{\\ge 0}^{n}$ 是可图化的。Havel–Hakimi 过程接受一个非增序列，并重复地移除最大的项，然后从接下来最大的几项中各减去 $1$；如果出现负数，则宣告失败。Havel–Hakimi 定理指出，一个序列是可图化的，当且仅当该过程成功并在全零序列处终止。\n\n您希望定义一个投影算子，将 $\\tilde{d}$ 映射到一个在指定距离下尽可能接近的可图化度序列，然后使用 Havel–Hakimi 算法来生成一个具有该度序列的简单图。目标是利用后处理性质，确保从 $\\tilde{d}$ 到最终图的整个映射保持 $(\\varepsilon,\\delta)$-差分隐私性。后处理性质指出，如果一个随机算法是 $(\\varepsilon,\\delta)$-差分隐私的，那么对其输出进行的不需要额外访问私有数据的任何（可能是随机的）函数也同样是 $(\\varepsilon,\\delta)$-差分隐私的。\n\n以下哪个提议既正确定义了到最近可图化序列的投影，又正确地解释了为什么将其与 $\\mathcal{M}$ 组合能保持 $(\\varepsilon,\\delta)$-差分隐私性？\n\nA. 将 $\\Pi(\\tilde{d})$ 定义为\n$$\n\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{1}\n$$\n的唯一元素，其中 $\\mathcal{G}_{n}$ 是所有长度为 $n$ 的非增可图化序列的集合，并使用确定性的字典序破除平局规则以确保唯一性。然后通过在 $\\Pi(\\tilde{d})$ 上运行 Havel–Hakimi 构建过程，输出一个度序列为 $\\Pi(\\tilde{d})$ 的简单图 $H$。因为 $\\Pi$ 和 Havel–Hakimi 都是仅依赖于 $\\tilde{d}$ 的确定性函数，所以根据后处理不变性，组合映射 $G \\mapsto \\mathcal{M}(G) \\mapsto \\Pi(\\tilde{d}) \\mapsto H$ 是 $(\\varepsilon,\\delta)$-差分隐私的。\n\nB. 在对 $\\tilde{d}$ 排序后直接运行 Havel–Hakimi 过程，并在此过程中将任何负的中间减法结果替换为 $0$，从而生成一个度序列。这种方法仅在映射在 $\\ell_{1}$ 范数下是 $1$-Lipschitz 的情况下才能保持隐私性，而 Havel–Hakimi 过程不满足此条件，因此为了维持 $(\\varepsilon,\\delta)$-差分隐私性，必须在投影后添加一轮新的独立噪声。\n\nC. 将投影 $\\Pi_{2}(\\tilde{d})$ 定义为 $\\ell_{2}$ 范数下最近的可图化序列，即\n$$\n\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{2},\n$$\n然后应用 Havel–Hakimi 过程来生成一个图。这在 Havel–Hakimi 的意义上产生了最近的可图化序列，因为该过程等价于度空间上的 $\\ell_{2}$ 投影，并且只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私性才能得到保护。\n\nD. 通过首先从 $\\mathcal{M}(G)$ 计算 $\\tilde{d}$，然后使用来自原始私有数据 $G$ 的旁路信息来打破平局，倾向于选择更接近 $d(G)$ 的序列，从而最小化与真实度序列的期望失真，来定义 $\\Pi(\\tilde{d}; G)$。这种构造保持了 $(\\varepsilon,\\delta)$-差分隐私性，因为后处理性质允许在发布 $\\tilde{d}$ 后进行任意依赖于数据的精化。\n\nE. 通过将 $\\tilde{d}$ 裁剪并排序到 $[0,n]$ 区间内，四舍五入到最近的整数，如果和为奇数，则将最小的项加 $1$，来定义 $\\Pi(\\tilde{d})$；然后从该 $\\ell_{1}$ 距离下的所有可图化序列中均匀随机地选择一个，并应用 Havel–Hakimi。这种组合仅在用于打破平局的随机性独立于 $\\tilde{d}$ 时才能保持 $(\\varepsilon,\\delta)$-差分隐私性；否则后处理不变性可能会失效。",
            "solution": "这是一个关于差分隐私在网络数据分析中应用的问题。问题的核心在于理解差分隐私的后处理性质，并将其正确应用于多阶段数据分析流程中。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n*   **输入数据：** 一个具有 $n$ 个顶点的无向简单图 $G$。\n*   **真实查询结果：** 图的度序列 $d(G) \\in \\mathbb{Z}_{\\ge 0}^{n}$。\n*   **隐私机制：** 一个机制 $\\mathcal{M}$，输入为 $G$，输出为带噪声的度向量 $\\tilde{d} \\in \\mathbb{R}^{n}$。\n*   **隐私保证：** 机制 $\\mathcal{M}$ 在边级别邻接关系下是 $(\\varepsilon,\\delta)$-差分隐私的。\n*   **邻接定义：** 如果两个图仅相差一条边的添加或移除，则它们是邻接的。\n*   **关键定义：**\n    *   如果一个序列 $x \\in \\mathbb{Z}_{\\ge 0}^{n}$ 是某个具有 $n$ 个顶点的简单无向图的度序列，则称其为“可图化的”。\n    *   “Havel–Hakimi 过程”是一种用于测试非增序列是否可图化的算法。“Havel–Hakimi 定理”指出该过程是一个充分必要测试。一个构造性版本可以从一个可图化序列生成一个图。\n*   **目标：** 定义一个从带噪声的向量 $\\tilde{d}$到简单图 $H$ 的映射，使得 $H$ 具有一个可图化的度序列，并且整个过程（从 $G$到 $H$）保持 $(\\varepsilon,\\delta)$-差分隐私。\n*   **隐私保护方法：** 组合映射的隐私性必须通过“后处理性质”来证明。\n*   **后处理性质：** 如果一个随机算法是 $(\\varepsilon,\\delta)$-差分隐私的，那么对其输出进行的任何（可能是随机的）不需额外访问私有数据的函数也同样是 $(\\varepsilon,\\delta)$-差分隐私的。\n\n**步骤2：使用提取的已知条件进行验证**\n\n*   **科学基础：** 该问题牢固地建立在图论（度序列、可图化序列、Havel–Hakimi 定理）和差分隐私理论（边级别隐私、后处理性质）的既定概念之上。将一个带噪声的、非可图化的度序列变为可图化序列是私有图分析中的一个标准问题。\n*   **良定性：** 问题是良定的。它提出了一个明确的目标和一组候选解决方案（选项 A-E）。任务是评估每个候选方案所提议的程序及其理由的正确性，这是一个概念性问题的标准格式。\n*   **客观性：** 问题陈述以精确、客观、形式化的数学语言编写。没有主观或模糊的术语。\n*   **缺陷清单：**\n    1.  **科学/事实不健全：** 否。所有概念都是标准的并且陈述正确。\n    2.  **非形式化/不相关：** 否。该问题是形式化的，并与指定主题直接相关。\n    3.  **不完整/矛盾的设定：** 否。提供了评估选项所需的所有必要定义和约束。\n    4.  **不切实际/不可行：** 否。该设定描述了私有数据分析中的一个标准理论问题。\n    5.  **不当提问/结构不良：** 否。可以通过根据所提供的定义分析选项来确定唯一的正确答案。\n    6.  **故作高深/琐碎：** 否。该问题需要对后处理性质有仔细的理解，这是差分隐私中一个微妙但基本的概念。\n    7.  **超出科学可验证性范围：** 否。每个选项的正确性都可以基于差分隐私和图论的数学定义进行严格验证。\n\n**步骤3：结论与行动**\n\n问题陈述有效。我将继续进行解答。\n\n### 解题推导\n\n需要应用的核心原则是差分隐私的**后处理性质**。设私有输入为图 $G$。机制 $\\mathcal{M}$ 计算 $\\tilde{d} = \\mathcal{M}(G)$，并且这个计算是 $(\\varepsilon,\\delta)$-差分隐私的。目标是对输出 $\\tilde{d}$ 应用某个函数或一系列函数（我们称其复合函数为 $f$），以获得最终的图 $H$。整个过程是 $H = f(\\mathcal{M}(G))$。后处理性质保证，只要函数 $f$ 不依赖于私有输入 $G$，那么 $H$ 也是一个 $(\\varepsilon,\\delta)$-差分隐私的输出。函数 $f$ 可以是确定性的或随机性的，它可以依赖于任何公开信息，但它访问敏感信息的唯一途径是通过已经隐私化的输出 $\\tilde{d}$。\n\n提议的流程是 $\\tilde{d} \\xrightarrow{\\Pi} x \\xrightarrow{\\text{Havel-Hakimi}} H$，其中 $x$ 是一个可图化的度序列。因此，复合函数是 $f(\\tilde{d}) = \\text{Havel-Hakimi}(\\Pi(\\tilde{d}))$。要使其成为一个有效的后处理链，投影 $\\Pi$ 和 Havel-Hakimi 构建过程都不能使用原始图 $G$。\n\n让我们根据这个原则评估每个选项。\n\n**A. 将 $\\Pi(\\tilde{d})$ 定义为 $\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{1}$ 的唯一元素，其中 $\\mathcal{G}_{n}$ 是所有长度为 $n$ 的非增可图化序列的集合，并使用确定性的字典序破除平局规则以确保唯一性。然后通过在 $\\Pi(\\tilde{d})$ 上运行 Havel–Hakimi 构建过程，输出一个度序列为 $\\Pi(\\tilde{d})$ 的简单图 $H$。因为 $\\Pi$ 和 Havel–Hakimi 都是仅依赖于 $\\tilde{d}$ 的确定性函数，所以根据后处理不变性，组合映射 $G \\mapsto \\mathcal{M}(G) \\mapsto \\Pi(\\tilde{d}) \\mapsto H$ 是 $(\\varepsilon,\\delta)$-差分隐私的。**\n\n*   **分析：** 这个提议定义了一个两步的后处理函数。\n    1.  投影 $\\Pi$：此函数接收 $\\tilde{d}$ 并在集合 $\\mathcal{G}_n$ 中找到 $\\ell_1$ 范数下最近的可图化序列。集合 $\\mathcal{G}_n$ 仅依赖于 $n$，而 $n$ 是公开信息。优化问题的目标函数 $\\|x - \\tilde{d}\\|_1$ 仅依赖于输入 $\\tilde{d}$。确定性的破除平局规则确保了对于任何给定的 $\\tilde{d}$，函数 $\\Pi(\\tilde{d})$ 都是唯一定义的。因此，$\\Pi$ 是一个仅依赖于 $\\tilde{d}$ 的确定性函数，不使用私有图 $G$。\n    2.  Havel-Hakimi 构建过程：该算法接收一个可图化的度序列并构建一个相应的图。它是一个确定性算法，仅对其输入（即可图化序列 $\\Pi(\\tilde{d})$）进行操作。它不需要访问 $G$。\n*   **理由：** 理由是，由于这两个步骤都是仅依赖于 $\\tilde{d}$ 的函数，它们的组合也同样仅依赖于 $\\tilde{d}$。这是正确的。对一个 $(\\varepsilon,\\delta)$-DP 输出应用一个独立于私有数据的函数，会得到一个同样满足 $(\\varepsilon,\\delta)$-DP 的输出。这是对后处理性质的直接且正确的应用。\n*   **结论：** **正确**。\n\n**B. 在对 $\\tilde{d}$ 排序后直接运行 Havel–Hakimi 过程，并在此过程中将任何负的中间减法结果替换为 $0$，从而生成一个度序列。这种方法仅在映射在 $\\ell_{1}$ 范数下是 $1$-Lipschitz 的情况下才能保持隐私性，而 Havel–Hakimi 过程不满足此条件，因此为了维持 $(\\varepsilon,\\delta)$-差分隐私性，必须在投影后添加一轮新的独立噪声。**\n\n*   **分析：** 这个选项提出了一个过程化的投影。其提供的理由完全是谬误的。后处理性质并*不*要求后处理函数是 Lipschitz 的或具有任何特定的敏感度。敏感度和 Lipschitz 性质与设计隐私机制（$\\mathcal{M}$）相关，而与后处理其输出无关。声称隐私性“仅在映射是 1-Lipschitz 的情况下”才能保持是错误的。此外，建议“添加一轮新的独立噪声”是不必要的，并且会适得其反。隐私保证已由 $\\mathcal{M}$ 提供；添加更多噪声只会降低结果的效用，而不会带来任何隐私增益。\n*   **结论：** **不正确**。\n\n**C. 将投影 $\\Pi_{2}(\\tilde{d})$ 定义为 $\\ell_{2}$ 范数下最近的可图化序列，即 $\\underset{x \\in \\mathcal{G}_{n}}{\\arg\\min}\\, \\|x - \\tilde{d}\\|_{2}$，然后应用 Havel–Hakimi 过程来生成一个图。这在 Havel–Hakimi 的意义上产生了最近的可图化序列，因为该过程等价于度空间上的 $\\ell_{2}$ 投影，并且只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私性才能得到保护。**\n\n*   **分析：** 这个选项的理由有两个主要缺陷。\n    1.  “只有当投影使用的度量与原始查询的敏感度范数匹配时，隐私性才能得到保护”：这是错误的。后处理性质的成立与投影步骤中使用的度量（$\\ell_1$、$\\ell_2$ 或其他）无关，只要投影函数不访问私有数据 $G$。范数的选择影响效用（哪个序列被认为是“最近的”），而不影响隐私性。\n    2.  “Havel–Hakimi ... 等价于度空间上的 $\\ell_{2}$ 投影”：这在事实上是错误的。Havel-Hakimi 过程是一个用于测试可图性的组合算法。它不是一个执行 $\\ell_2$ 投影的优化过程。\n*   **结论：** **不正确**。\n\n**D. 通过首先从 $\\mathcal{M}(G)$ 计算 $\\tilde{d}$，然后使用来自原始私有数据 $G$ 的旁路信息来打破平局，倾向于选择更接近 $d(G)$ 的序列，从而最小化与真实度序列的期望失真，来定义 $\\Pi(\\tilde{d}; G)$。这种构造保持了 $(\\varepsilon,\\delta)$-差分隐私性，因为后处理性质允许在发布 $\\tilde{d}$ 后进行任意依赖于数据的精化。**\n\n*   **分析：** 这个提议明确地将投影函数 $\\Pi$ 定义为依赖于私有数据 $G$，记为 $\\Pi(\\tilde{d}; G)$。这直接且根本地违反了后处理性质的条件。使用原始私有数据的函数不是一个后处理步骤；它是一个对私有数据的新计算。这样的复合算法不能保证是 $(\\varepsilon,\\delta)$-DP 的，并且需要一个独立的、完整的隐私分析（而且很可能会失败）。其理由中“后处理性质允许任意依赖于数据的精化”是对该性质定义的直接否定，该性质要求独立于私有数据。\n*   **结论：** **不正确**。\n\n**E. 通过将 $\\tilde{d}$ 裁剪并排序到 $[0,n]$ 区间内，四舍五入到最近的整数，如果和为奇数，则将最小的项加 $1$，来定义 $\\Pi(\\tilde{d})$；然后从该 $\\ell_{1}$ 距离下的所有可图化序列中均匀随机地选择一个，并应用 Havel–Hakimi。这种组合仅在用于打破平局的随机性独立于 $\\tilde{d}$ 时才能保持 $(\\varepsilon,\\delta)$-差分隐私性；否则后处理不变性可能会失效。**\n\n*   **分析：** 这个选项提出了一个随机化的后处理过程。随机化的后处理步骤是允许的。然而，其理由包含一个关键错误。它声称隐私性“仅在用于打破平局的随机性独立于 $\\tilde{d}$ 时”才能保持。这是错误的。一个随机化的后处理函数 $f(\\tilde{d}, r)$（其中 $r$ 是随机性来源）仍然保持隐私性。随机性 $r$ 必须独立于私有数据 $G$，但 $r$ 的分布依赖于 $\\tilde{d}$ 是完全可以接受的。例如，可以使用 $\\tilde{d}$ 的哈希值来为一个伪随机数生成器提供种子。这并不违反后处理性质。只有当随机性依赖于 $G$ 时，该性质才会失效。该选项中陈述的条件是不必要的限制并且是错误的。\n*   **结论：** **不正确**。\n\n综上所述，只有选项 A 正确地描述了一个有效的后处理流程，并基于差分隐私的后处理性质给出了正确的解释。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}