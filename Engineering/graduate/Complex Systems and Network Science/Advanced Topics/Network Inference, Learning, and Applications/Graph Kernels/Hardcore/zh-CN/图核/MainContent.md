## 引言
在网络科学、机器学习和众多科学领域中，图结构数据无处不在，从社交网络到分子结构，再到大[脑连接组](@entry_id:1121840)。然而，如何将这些复杂的非欧几里得数据有效地与[支持向量机](@entry_id:172128)（SVM）等强大的传统[机器学习算法](@entry_id:751585)相结合，一直是一个核心挑战。图核（Graph Kernels）方法正是为了解决这一知识鸿沟而生，它通过精巧的数学设计，构建了一座连接图结构世界与高维特征空间的桥梁，使得我们能够量化和比较图之间的结构相似性。

本文将系统性地引导您深入图核的世界。在第一部分“原理与机制”中，我们将剖析图核背后的数学基础，探讨其设计原则以及包括[随机游走核](@entry_id:1130563)、[最短路径](@entry_id:157568)核和[Weisfeiler-Lehman核](@entry_id:1134116)在内的关键方法。接着，在第二部分“应用与交叉学科联系”中，我们将展示这些理论如何在[化学信息学](@entry_id:902457)、[计算生物学](@entry_id:146988)和神经科学等前沿领域中解决实际问题，从[分子性质预测](@entry_id:169815)到大[脑网络分析](@entry_id:1121851)。最后，通过第三部分“动手实践”，您将有机会亲手实现和计算几种核心的图核，将理论知识转化为实践技能。通过这三个层层递进的章节，您将全面掌握图核的核心思想、应用范式及其在现代数据科学中的重要地位。

## 原理与机制

继前一章对图核及其在网络科学和复杂系统中应用的介绍之后，本章将深入探讨其核心的数学原理与工作机制。我们将从[核函数](@entry_id:145324)的基本定义出发，系统性地阐述图核的设计原则，特别是同构[不变性](@entry_id:140168)与表达能力之间的权衡。此外，我们还将介绍几种主流的图核族，包括[随机游走核](@entry_id:1130563)、[最短路径](@entry_id:157568)核和Weisfeiler-Lehman子树核，并最终讨论图核的普适性及其理论局限。

### 图核的基本原理

从数学角度看，图[核方法](@entry_id:276706)旨在将图这一非欧几里得数据结构嵌入到一个高维的[特征空间](@entry_id:638014)（通常是希尔伯特空间）中，以便应用标准的机器学习算法。实现这一点的核心工具便是[核函数](@entry_id:145324)。

#### Gram 矩阵与正定性

一个定义在图集合 $\mathcal{G}$ 上的函数 $k: \mathcal{G} \times \mathcal{G} \to \mathbb{R}$ 要成为一个有效的**[核函数](@entry_id:145324) (kernel)**，必须满足两个基本条件：对称性和正半定性。

1.  **对称性 (Symmetry)**：对于任意两个图 $G, H \in \mathcal{G}$，必须有 $k(G, H) = k(H, G)$。这确保了图之间的相似度度量是无方向的。

2.  **正半定性 (Positive Semidefiniteness, PSD)**：对于任意一个有限的图样本 $\{G_1, G_2, \dots, G_n\} \subset \mathcal{G}$，由该样本生成的 **Gram 矩阵 (Gram matrix)** $K$ 必须是正半定的。Gram 矩阵是一个 $n \times n$ 的[实对称矩阵](@entry_id:192806)，其元素定义为 $K_{ij} = k(G_i, G_j)$。

一个矩阵 $K$ 是正半定的，等价于以下任一条件成立：
-   对于任意非[零向量](@entry_id:156189) $c \in \mathbb{R}^n$，二次型 $c^\top K c \ge 0$。
-   矩阵 $K$ 的所有特征值均非负（即 $\ge 0$）。

在某些情况下，我们会要求更强的条件，即**严格[正定性](@entry_id:149643) (Strictly Positive Definite, PD)**。一个核函数是严格正定的，如果对于任意一组*两两互不相同*的图 $\{G_1, \dots, G_n\}$，其 Gram 矩阵是严格正定的。这意味着对于所有非[零向量](@entry_id:156189) $c \in \mathbb{R}^n$，二次型 $c^\top K c > 0$，或者等价地，矩阵 $K$ 的所有特征值都严格大于 $0$。

需要注意的是，严格正定性的定义要求样本中的图是两两互不相同的。如果样本中存在重复的图，例如 $G_i = G_j$ 且 $i \neq j$，那么 Gram 矩阵的第 $i$ 行和第 $j$ 行将完全相同。这样的矩阵是奇异的（行列式为零），必然包含至少一个零特征值，因此不可能是严格正定的 。这个特性表明，一个严格正定的[核函数](@entry_id:145324)必须为任意两个不同的输入图赋予不同的特征表示，从而使得 Gram 矩阵在面对非重复输入时保持满秩。

#### 特征映射表示与理论保障

正半定性的核心意义在于它保证了“[核技巧](@entry_id:144768)”的成立。一个函数 $k(G, H)$ 是正半定的，当且仅当存在一个[希尔伯特空间](@entry_id:261193) $\mathcal{H}$ 和一个从图到该空间的**特征映射 (feature map)** $\phi: \mathcal{G} \to \mathcal{H}$，使得核函数可以表示为[特征向量](@entry_id:151813)之间的[内积](@entry_id:750660)：
$$
k(G, H) = \langle \phi(G), \phi(H) \rangle_{\mathcal{H}}
$$
这种表示将对图的复杂比较操作，转化为了对高维[特征向量](@entry_id:151813)的简单[内积](@entry_id:750660)运算。这正是[支持向量机](@entry_id:172128)等[核方法](@entry_id:276706)能够在复杂结构数据上工作的理论基石。

在此，我们必须区分两个重要的基础定理：Moore-Aronszajn 定理和 Mercer 定理。
-   **Moore-Aronszajn 定理**是[核方法](@entry_id:276706)最根本的理论保障。它指出，对于**任何**非[空集](@entry_id:261946)合（无论其是否具有拓扑结构）上的任何一个对称、正半定函数 $k$，都存在一个**唯一**的[再生核希尔伯特空间](@entry_id:633928) (Reproducing Kernel Hilbert Space, RKHS)，而 $k$ 就是这个空间的[再生核](@entry_id:262515)。这一定理的普适性极强，它不要求定义域是[紧集](@entry_id:147575)，也不要求核函数是连续的。

-   **Mercer 定理**则更为严格。它通常应用于一个**紧致**[度量空间](@entry_id:138860)上的**连续**核函数。该定理不仅保证了 RKHS 的存在，还给出了核函数关于其[积分算子](@entry_id:262332)特征函数的谱展开式。

对于图核而言，图的集合 $\mathcal{G}$ 通常是一个离散且无限的集合，它在[离散拓扑](@entry_id:152622)下并非[紧集](@entry_id:147575)。因此，大多数实用的图核（如基于[子图计数](@entry_id:1132589)的核）并不满足 Mercer 定理的严格前提条件。然而，只要这些核函数被构造成对称和正半定的（例如，通过显式或隐式地定义一个特征映射并计算[内积](@entry_id:750660)），Moore-Aronszajn 定理就保证了它们是有效的核函数，并存在一个对应的 RKHS 。这解释了为何我们能在没有 Mercer 定理谱展开的情况下，依然可以放心地在图数据上使用这些[核方法](@entry_id:276706)。

### 不变性与表达能力的权衡

在许多应用场景中，图的节点标签（例如，节点索引 $1, 2, \dots, n$）是任意分配的，真正重要的是图的拓扑结构本身。这就引出了图核设计中的一个核心概念：同构[不变性](@entry_id:140168)。

#### 同构[不变性原理](@entry_id:199405)

两个图 $G$ 和 $H$ 如果结构上完全相同，仅仅是节点标签不同，我们称它们是**同构 (isomorphic)** 的，记为 $G \cong H$。从代数上看，这意味着存在一个[置换矩阵](@entry_id:136841) $P$，使得它们的[邻接矩阵](@entry_id:151010)满足 $A_H = P^\top A_G P$。

一个图的属性如果是**同构不变量 (isomorphism invariant)**，意味着该属性的值不依赖于具体的节点标签，对于所有同构的图都是相同的。例如，节点的数量、边的数量、度数分布以及连通性都是同构不变量。

对于处理非标记图或结构相似性比较的任务，一个设计良好的图核必须是同构不变的。也就是说，如果 $G \cong G'$ 且 $H \cong H'$，那么[核函数](@entry_id:145324)的值必须保持不变：
$$
k(G, H) = k(G', H')
$$
这个性质保证了核函数度量的是图的内在结构相似性，而不是任意标签选择的巧合。从数学上讲，这意味着核函数 $k$ 实际上是定义在图的[同构类](@entry_id:147854)（即无标签图）上的函数 。

#### 构造[不变性](@entry_id:140168)[核函数](@entry_id:145324)

实现同构不变性的最直接方法是，确保用于定义核函数的特征映射 $\phi$ 本身就是同构不变量，即如果 $G \cong H$，则 $\phi(G) = \phi(H)$。一旦特征映射具备不变性，通过[内积](@entry_id:750660) $k(G, H) = \langle \phi(G), \phi(H) \rangle$ 定义的[核函数](@entry_id:145324)自然也是不变的。

以下是一些构造不变特征的常见策略 ：
1.  **基于谱的特征**：图的[邻接矩阵](@entry_id:151010)或拉普拉斯矩阵的特征值（构成图的谱）是同构不变量。因为[相似矩阵](@entry_id:155833)（如 $A_G$ 和 $P^{-1}A_G P$）具有相同的特征值。因此，可以将排序后的特征值向量作为图的特征表示 $\phi(G)$。

2.  **基于模式计数的特征**：[计算图](@entry_id:636350)中特定子结构（如[图元](@entry_id:1125733) graphlets、路径、树等）出现的次数。由于同构映射保持邻接关系，这些子结构的数量也是同构不变量。

3.  **聚合局部特征**：这是一种非常强大的通用方法。首先为每个节点计算一个描述其局部邻域结构的特征。然后，将一个图中所有节点的局部特征收集到一个**多重集 (multiset)** 中。由于同构只是对节点进行了置换，这个局部特征的多重集对于同构图来说是不变的。最后，通过对多重集中的元素进行求和、构造[直方图](@entry_id:178776)等与顺序无关的聚合操作，可以得到整个图的同构不变[特征向量](@entry_id:151813)。

然而，不变性并非没有代价。一个高度不变的特征（例如，仅使用图的度数分布）可能无法区分许多结构迥异的[非同构图](@entry_id:274028)，这限制了其**表达能力 (expressivity)**。例如，任何两个具有相同节点数和相同度的[正则图](@entry_id:265877)（例如 $K_{3,3}$ 和三角棱柱图 $C_3 \square K_2$）都具有完全相同的度数分布，基于度数分布的核函数无法将它们区分开。为了提高表达能力，我们需要引入更精细的结构特征，如三角密度或其他高阶子图的计数。通过将度数分布特征与三角密度特征结合，我们就能区分 $K_{3,3}$（无三角形）和 $C_3 \square K_2$（有三角形），从而获得一个表达能力更强的核函数 。这种在保证不变性的前提下，追求更高[表达能力](@entry_id:149863)的设计思路，是图核研究的核心挑战之一。

### 一个通用框架：R-卷积核

许多图核的设计可以被统一在一个名为 **R-卷积核 (R-convolution kernel)** 的通用框架下。这个由 David Haussler 提出的框架为在组合对象（如序列、树和图）上构建[核函数](@entry_id:145324)提供了一个系统性的方法。

R-卷积框架包含三个核心要素 ：
1.  **分解 (Decomposition)**：定义一个关系 $R$，将每个复合对象 $x$ 分解为其组成部分的集合（或多重集）$R(x)$。对于图而言，这些“部分”可以是节点、边、路径、游走、子树等。

2.  **基核 (Base Kernel)**：在这些基本组成部分上定义一个或多个[核函数](@entry_id:145324) $k_{\text{part}}$。例如，如果部分是带标签的节点，基核可以比较它们的标签。这些基核必须是正半定的。

3.  **卷积 (Convolution)**：通过对所有可能的“部分”对之间的相似度进行求和，来定义复合对象 $x$ 和 $x'$ 之间的[核函数](@entry_id:145324)。最常见的形式是：
    $$
    k(x, x') = \sum_{p \in R(x)} \sum_{p' \in R(x')} k_{\text{part}}(p, p')
    $$
如果基核 $k_{\text{part}}$ 是正半定的，那么通过这种方式构造的 R-卷积核 $k$ 也保证是正半定的。这是因为如果 $k_{\text{part}}(p, p') = \langle \phi_{\text{part}}(p), \phi_{\text{part}}(p') \rangle$，那么 R-卷积核的特征映射可以被定义为 $\Phi(x) = \sum_{p \in R(x)} \phi_{\text{part}}(p)$，核函数值即为 $\langle \Phi(x), \Phi(x') \rangle$。

R-卷积框架的强大之处在于其模块化。通过改变分解方式 $R$ 和基核 $k_{\text{part}}$，我们可以派生出各种不同类型的图核，下一节将要介绍的多种[核函数](@entry_id:145324)都可以被看作是 R-卷积思想的具体实例。

### 主要的图核函数族

基于上述原理，研究者们开发了多种图核，它们从不同角度捕捉图的结构信息。

#### [随机游走核](@entry_id:1130563)

[随机游走核](@entry_id:1130563) (Random Walk Kernels) 的核心思想是：如果两个图具有相似的游走模式，那么它们就是相似的。这类[核函数](@entry_id:145324)通过统计两个图中共有的同步游走数量来衡量它们的相似性。

实现这一思想的关键是**图的[直积](@entry_id:143046) (direct product graph)**，记为 $G \times H$。给定两个图 $G=(V_G, E_G)$ 和 $H=(V_H, E_H)$，它们的[直积](@entry_id:143046)图的顶点集是 $V_G \times V_H$。在[直积](@entry_id:143046)图中，从顶点 $(u,x)$到 $(v,y)$ 存在一条边，当且仅当在 $G$ 中存在边 $(u,v)$ 并且在 $H$ 中存在边 $(x,y)$。这恰好模拟了在两个图上同时进行一步游走的过程 。

一个重要的代数性质是，[直积](@entry_id:143046)图 $G \times H$ 的[邻接矩阵](@entry_id:151010) $A_{G \times H}$ 等于图 $G$ 和 $H$ 的[邻接矩阵](@entry_id:151010)的**[克罗内克积](@entry_id:182766) (Kronecker product)**：
$$
A_{G \times H} = A_G \otimes A_H
$$
根据图论和线性代数的基本知识，矩阵 $(A_{G \times H})^t$ 的 $(i,j)$ 元等于在[直积](@entry_id:143046)图中从顶点 $i$ 到顶点 $j$ 的长度为 $t$ 的游走数量。因此，统计两个图中共有的、长度为 $t$ 的匹配游走数量，等价于计算 $(A_G \otimes A_H)^t$ 的某种形式的和。

**[几何随机游走](@entry_id:145665)核 (Geometric Random Walk Kernel)** 通过对所有长度的游走进行加权求和来定义，其中较长的游走被一个衰减因子 $\lambda$ 指数级地惩罚：
$$
k_{\text{RW}}(G, H) = \sum_{t=0}^{\infty} \lambda^t (\text{total walks of length } t)
$$
更正式地，给定初始和终止顶点分布 $\mathbf{s}$ 和 $\mathbf{t}$，[核函数](@entry_id:145324)可以写成一个矩阵[几何级数](@entry_id:158490) ：
$$
k_{\text{RW}}(G,H;\lambda,\mathbf{s},\mathbf{t}) = \sum_{t=0}^{\infty} \lambda^t \, \mathbf{s}^\top (A_G \otimes A_H)^t \mathbf{t}
$$
这个[级数收敛](@entry_id:142638)当且仅当 $\lambda (A_G \otimes A_H)$ 的[谱半径](@entry_id:138984)小于1。利用谱半径的性质 $\rho(A \otimes B) = \rho(A)\rho(B)$，[收敛条件](@entry_id:166121)为：
$$
|\lambda|  \frac{1}{\rho(A_G)\rho(A_H)}
$$
在[收敛条件](@entry_id:166121)下，该[核函数](@entry_id:145324)有一个等价的[封闭形式](@entry_id:272960)，即[矩阵的逆](@entry_id:140380)：
$$
k_{\text{RW}}(G,H;\lambda,\mathbf{s},\mathbf{t}) = \mathbf{s}^\top (I - \lambda (A_G \otimes A_H))^{-1} \mathbf{t}
$$
[随机游走核](@entry_id:1130563)是 R-卷积框架的一个典型例子，其中图被分解为游走，基核则比较两条游走是否完全相同。

#### 最短路径核

另一族重要的图核是基于**[最短路径](@entry_id:157568) (Shortest-Path Kernels)** 的。其直观思想是，如果两个图中所有节点对之间的[最短路径长度](@entry_id:902643)的分布相似，那么这两个图就相似。

与[随机游走核](@entry_id:1130563)不同，[最短路径](@entry_id:157568)核的第一步是计算每个图中所有节点对 $(u,v)$ 之间的[最短路径长度](@entry_id:902643) $d_G(u,v)$。这通常通过 Floyd-Warshall 或多次运行 Breadth-First Search (BFS) 算法来完成。得到最短路径矩阵后，有多种方法可以构建[核函数](@entry_id:145324) ：

1.  **直接求和核**：这是最通用的形式，它聚合了所有节点对之间的路径长度比较。给定一个在路径长度上定义的正半定基核 $\kappa: \mathbb{R}_{\ge 0} \times \mathbb{R}_{\ge 0} \to \mathbb{R}_{\ge 0}$（例如[高斯核](@entry_id:1125533)），最短路径核可以定义为：
    $$
    K(G,H) = \sum_{(u,v) \in V_G \times V_G} \sum_{(x,y) \in V_H \times V_H} \kappa(d_G(u,v), d_H(x,y))
    $$
    该构造保证是正半定的，因为它符合 R-卷积框架，其中图被分解为所有节点对，而“部分”就是它们之间的[最短路径长度](@entry_id:902643)。

2.  **最短路径直方图核**：这是一种更简单的实现。我们首先为每个图构建一个[最短路径长度](@entry_id:902643)的[直方图](@entry_id:178776)（或[经验分布](@entry_id:274074)）。然后，将这两个直方图向量的[内积](@entry_id:750660)作为核函数的值。这等价于在上述直接求和核中选择一个仅当两个路径长度完全相等时才为1的基核 $\kappa(\ell, \ell') = \mathbf{1}[\ell=\ell']$。

3.  **核均值嵌入 (Kernel Mean Embedding)**：这是一种更先进的统计方法。首先，将每个图的[最短路径长度](@entry_id:902643)[经验分布](@entry_id:274074) $P_G$ 通过一个基核 $\kappa$ 嵌入到其 RKHS 中，得到一个称为“核均值”的单一[特征向量](@entry_id:151813) $\mu_{P_G}$。然后，可以在这些均值嵌入向量上应用另一个核函数（如[高斯核](@entry_id:1125533)）来比较两个图的分布。这种方法能够捕捉分布的更高阶矩，通常具有更强的表达能力。

#### Weisfeiler-Lehman (WL) 子树核

Weisfeiler-Lehman (WL) 子树核是目前[表达能力](@entry_id:149863)最强、应用最广泛的图核之一。它与[图同构](@entry_id:143072)测试中的 **Weisfeiler-Lehman 检验 (1-WL test)** 紧密相关。

1-WL 检验是一个迭代的节点颜色（或标签）细化算法。在第0步，所有节点被赋予相同的初始颜色。在后续的每一步 $t+1$，每个节点 $v$ 的新颜色 $\ell_{t+1}(v)$ 由其当前颜色 $\ell_t(v)$ 和其邻居节点的颜色**多重集** $\{\!\{\ell_t(u) : u \in N(v)\}\!\}$ 唯一确定（通常通过一个[哈希函数](@entry_id:636237)）。这个过程本质上是在为每个节点构建一个以其为根、高度为 $t$ 的“[计算树](@entry_id:267610)”的编码，这个编码捕捉了其局部邻域的结构。

**WL 子树核**正是利用了这个[颜色细化](@entry_id:1122664)过程。它的[特征向量](@entry_id:151813) $\phi_{\text{WL},h}(G)$ 记录了在运行 $h$ 轮 1-WL 检验后，图 $G$ 中每种颜色在每一轮出现的次数。核函数值就是两个图的这种颜色计数向量的[内积](@entry_id:750660)。

WL 核的强大之处在于其特征与 1-WL 检验的表达能力直接挂钩。然而，这也正是其局限所在。WL 子树核的表达能力**完全等同于** 1-WL 检验，它无法区分任何 1-WL 检验无法区分的图 。这意味着：
-   如果两个[非同构图](@entry_id:274028)对于 1-WL 检验是不可区分的，那么对于任意迭代次数 $h$，它们的 WL 子树核[特征向量](@entry_id:151813)都是完全相同的 。
-   一个著名的反例是，任何两个具有相同参数 $(n, k, \lambda, \mu)$ 的非同构**[强正则图](@entry_id:269473) (strongly regular graphs)**，例如 Shrikhande 图和 $4 \times 4$ 棋盘的马走日图，都无法被 1-WL 检验区分。因此，WL 子树核也无法区分它们。
-   另一个简单的例子是，任何两个具有相同节点数和相同度的[正则图](@entry_id:265877)（例如，6个顶点的环图 $C_6$ 和两个分离的三角形 $K_3 \cup K_3$），在 1-WL 检验的每一步都会产生完全相同的颜色分布，因此 WL 核也无法区分它们。

尽[管存](@entry_id:1127299)在这些理论限制，1-WL 检验在实践中对大多数图都非常有效，这也使得 WL 子树核成为一个在性能和[计算效率](@entry_id:270255)之间取得良好平衡的强大工具。

### 普适性及其局限

在[核方法](@entry_id:276706)的理论中，一个理想的核函数应该具有**普适性 (universality)**。一个在图空间 $\mathcal{G}$ 上定义的[核函数](@entry_id:145324) $k$ 被认为是普适的，如果其对应的 RKHS $\mathcal{H}_k$ 在所有定义在 $\mathcal{G}$ 上的[连续函数空间](@entry_id:150395) $C_0(\mathcal{G})$ 中是稠密的（在最高范数意义下）。通俗地说，一个普适核足够强大，原则上可以学习任意复杂的图到实数的映射。

普适性的一个关键必要条件是[核函数](@entry_id:145324)必须是**特征性的 (characteristic)**，即特征映射 $\phi: G \mapsto k(\cdot, G)$ 必须是[单射](@entry_id:183792)的。这意味着对于任意两个不同的图 $G \neq H$，它们的特征表示必须不同，$\phi(G) \neq \phi(H)$。

然而，绝大多数在实践中使用的图核，包括前面讨论的[随机游走核](@entry_id:1130563)、最短路径核和 WL 子树核，都**不是普适的**。其根本原因在于，它们所依赖的特征映射通常是基于有限数量的、离散的[结构不变量](@entry_id:145830)（如特定长度的游走、特定大小的子图、或 1-WL 颜色）来构建的。这些特征映射往往是**非[单射](@entry_id:183792)**的，即存在非同构的图，它们会被映射到完全相同的[特征向量](@entry_id:151813)。例如，我们已经看到 WL 核无法区分某些[强正则图](@entry_id:269473)。

当 $\phi(G) = \phi(H)$ 对 $G \neq H$ 成立时，RKHS 中的任何函数 $f \in \mathcal{H}_k$ 都必然满足 $f(G) = f(H)$。这意味着该函数空间中的所有函数都无法将 $G$ 和 $H$ 分开。因此，这个[函数空间](@entry_id:143478)不可能是稠密的，[核函数](@entry_id:145324)也就不具备普适性 。

尽管缺乏理论上的普适性，这些实用的图核在各种特定任务中依然表现出色。这表明，对于许多现实世界的问题，捕捉与任务相关的特定[结构不变量](@entry_id:145830)，往往比追求理论上的完备[表达能力](@entry_id:149863)更为重要和有效。对图核的选择和设计，始终是在计算可行性、不变性要求和任务所需的[表达能力](@entry_id:149863)之间进行权衡的过程。