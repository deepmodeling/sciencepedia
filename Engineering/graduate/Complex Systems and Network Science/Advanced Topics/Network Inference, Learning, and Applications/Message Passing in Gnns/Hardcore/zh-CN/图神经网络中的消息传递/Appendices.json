{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握消息传递，我们从一个基础练习开始。这个问题将消息传递过程分解为其基本组成部分——消息函数、聚合和更新——并应用于一个简单的路径图。通过手动计算一个节点的更新状态，你将对核心的GNN更新机制有一个具体、分步的理解。",
            "id": "4287364",
            "problem": "考虑一个包含 $3$ 个节点的路径图，其顶点集为 $\\{1,2,3\\}$，无向边为 $\\{(1,2),(2,3)\\}$，每条边的权重均为单位1。图中没有自环。每个节点 $v$ 拥有一个标量特征 $h_{v}^{(0)} \\in \\mathbb{R}$。应用图神经网络 (GNN) 的单个消息传递层，其含义如下：消息从邻居节点 $u \\in \\mathcal{N}(v)$ 沿边发送到节点 $v$，由一个置换不变算子进行聚合，然后用于更新节点 $v$ 的状态。邻居集合 $\\mathcal{N}(v)$ 是 $v$ 的开邻域。消息函数定义为 $\\psi(h_{v}^{(t)},h_{u}^{(t)},e_{uv}) = h_{u}^{(t)}$，聚合算子为求和 $\\square = \\sum$，节点更新函数为 $\\phi(h_{v}^{(t)},m_{v}) = \\sigma\\!\\left(\\alpha\\,h_{v}^{(t)} + \\beta\\,m_{v}\\right)$，其中 $\\alpha \\in \\mathbb{R}$ 和 $\\beta \\in \\mathbb{R}$ 是固定参数，$\\sigma:\\mathbb{R}\\to\\mathbb{R}$ 是一个固定的非线性激活函数。仅使用这些规范以及图上消息传递的核心定义（即对邻居节点信息进行聚合，然后进行局部更新），推导节点 $2$ 更新后的状态 $h_{2}^{(1)}$ 关于 $\\alpha$、$\\beta$、$\\sigma$、$h_{1}^{(0)}$、$h_{2}^{(0)}$ 和 $h_{3}^{(0)}$ 的闭式表达式。将最终答案表示为单个简化的解析表达式。无需四舍五入，不涉及物理单位。",
            "solution": "问题陈述形式有效、科学上合理且定义明确。得到唯一解所需的所有要素均已提供。我们开始推导。\n\n在图神经网络 (GNN) 层中更新节点特征向量的过程由一个消息传递机制定义。对于任何节点 $v$，其在第 $t$ 层的特征向量 $h_v^{(t)}$ 通过一个三步过程（消息创建、消息聚合和节点更新）更新为第 $t+1$ 层的 $h_v^{(t+1)}$。\n\n该更新的一般形式可写为：\n$$h_{v}^{(t+1)} = \\phi\\left(h_{v}^{(t)}, m_{v}^{(t+1)}\\right)$$\n其中 $m_{v}^{(t+1)}$ 是从节点 $v$ 的邻域聚合而来的消息，计算方式如下：\n$$m_{v}^{(t+1)} = \\square_{u \\in \\mathcal{N}(v)} \\psi\\left(h_{v}^{(t)}, h_{u}^{(t)}, e_{uv}\\right)$$\n\n问题为该框架的各个组成部分提供了具体定义：\n1.  消息函数 $\\psi$ 由 $\\psi(h_{v}^{(t)}, h_{u}^{(t)}, e_{uv}) = h_{u}^{(t)}$ 给出。这意味着从邻居节点 $u$ 发送到节点 $v$ 的消息就是邻居节点 $u$ 在第 $t$ 层的特征向量。\n2.  聚合算子 $\\square$ 是求和算子 $\\sum$。\n3.  节点更新函数 $\\phi$ 由 $\\phi(h_{v}^{(t)}, m_{v}) = \\sigma(\\alpha h_{v}^{(t)} + \\beta m_{v})$ 给出，其中 $\\alpha$ 和 $\\beta$ 是标量参数，$\\sigma$ 是一个非线性激活函数。\n\n首先，让我们构建聚合消息 $m_{v}^{(t+1)}$ 的具体公式。将给定的消息函数和聚合算子代入通用公式，我们得到：\n$$m_{v}^{(t+1)} = \\sum_{u \\in \\mathcal{N}(v)} h_{u}^{(t)}$$\n这意味着节点 $v$ 的聚合消息是其邻居节点特征向量的总和。\n\n接下来，我们将此聚合消息代入节点更新函数，以获得任意节点 $v$ 的完整更新规则：\n$$h_{v}^{(t+1)} = \\sigma\\left(\\alpha h_{v}^{(t)} + \\beta \\left(\\sum_{u \\in \\mathcal{N}(v)} h_{u}^{(t)}\\right)\\right)$$\n\n问题要求在经过一层消息传递后，节点 $v=2$ 更新后的状态 $h_{2}^{(1)}$。这对应于从第 $t=0$ 层的初始特征更新到第 $t+1=1$ 层的新特征。对 $v=2$ 和 $t=0$ 应用更新规则：\n$$h_{2}^{(1)} = \\sigma\\left(\\alpha h_{2}^{(0)} + \\beta \\left(\\sum_{u \\in \\mathcal{N}(2)} h_{u}^{(0)}\\right)\\right)$$\n\n最后一步是确定节点 $2$ 的邻域 $\\mathcal{N}(2)$。该图是一个顶点集为 $\\{1, 2, 3\\}$、边集为 $\\{(1,2), (2,3)\\}$ 的路径图。一个节点的邻居是指通过边直接与其相连的节点。对于节点 $2$，其边为 $(1,2)$ 和 $(2,3)$。因此，节点 $2$ 的开邻域是 $\\mathcal{N}(2) = \\{1, 3\\}$。\n\n现在我们可以计算节点 $2$ 邻居特征的总和：\n$$\\sum_{u \\in \\mathcal{N}(2)} h_{u}^{(0)} = h_{1}^{(0)} + h_{3}^{(0)}$$\n\n将此和代入 $h_{2}^{(1)}$ 的表达式，我们得到最终的闭式表达式：\n$$h_{2}^{(1)} = \\sigma\\left(\\alpha h_{2}^{(0)} + \\beta (h_{1}^{(0)} + h_{3}^{(0)})\\right)$$\n该表达式根据 GNN 层的参数以及节点 2 自身及其邻居的初始特征，给出了节点 2 更新后的特征，符合题目要求。",
            "answer": "$$\\boxed{\\sigma(\\alpha h_{2}^{(0)} + \\beta (h_{1}^{(0)} + h_{3}^{(0)}))}$$"
        },
        {
            "introduction": "虽然消息传递GNN功能强大，但其本身也存在固有的局限性。本练习通过量化信息流如何被图的“瓶颈”所阻碍，来阐述“过度挤压”（over-squashing）这一关键问题。通过计算在切断一个桥接边后节点状态的变化，你将对图结构如何限制GNN的表达能力有一个定量的认识。",
            "id": "4287359",
            "problem": "考虑一个连通无向图，其节点标记为 $1,2,3,4,5,6$，边集为 $\\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$。边 $(3,4)$ 是一个桥，如果移除它，图会断开为两个连通分量 $\\{1,2,3\\}$ 和 $\\{4,5,6\\}$。设 $\\mathbf{A}$ 是该图的邻接矩阵，$\\tilde{\\mathbf{A}} = \\mathbf{A} + \\mathbf{I}$ 是带自环的邻接矩阵。设 $\\tilde{\\mathbf{D}}$ 是 $\\tilde{\\mathbf{A}}$ 的对角度矩阵，并定义对称归一化算子 $\\mathbf{S} = \\tilde{\\mathbf{D}}^{-1/2} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-1/2}$。\n\n一个两层图卷积网络 (GCN) 由逐层传播规则 $\\mathbf{H}^{(l+1)} = \\sigma\\!\\left(\\mathbf{S}\\,\\mathbf{H}^{(l)}\\,\\mathbf{W}^{(l)}\\right)$ 定义，其中 $\\sigma$ 是激活函数，$\\mathbf{W}^{(l)}$ 是可训练的权重矩阵，$\\mathbf{H}^{(0)} = \\mathbf{X}$ 是输入特征矩阵。考虑标量节点特征，其中 $\\mathbf{X} \\in \\mathbb{R}^{6 \\times 1}$，并取 $\\sigma$ 为恒等函数，$\\mathbf{W}^{(0)} = [1]$ 和 $\\mathbf{W}^{(1)} = [1]$。输入特征指定为 $x_1 = 1$、$x_2 = 1$、$x_3 = 1$ 以及 $x_4 = x_5 = x_6 = 0$。\n\n在这些条件下，在原始图（即桥边 $(3,4)$ 存在的情况下）上计算得到的节点 $5$ 的两层输出为 $h^{(2)}_5$。现在考虑移除桥边 $(3,4)$ 得到的修改后的图；将相应的算子记为 $\\mathbf{S}'$，节点 $5$ 的两层输出记为 $h'^{(2)}_5$。\n\n从消息传递和归一化邻接的核心定义出发，推导出两层输出，并计算因移除桥边而引起的变化，定义为 $\\Delta = h^{(2)}_5 - h'^{(2)}_5$。请以精确形式给出 $\\Delta$ 的解析值。然后，解释这个计算如何定量地反映图上消息传递中的过度挤压（over-squashing）和瓶颈敏感性（bottleneck sensitivity）的概念。\n\n你的最终答案必须是 $\\Delta$ 的单个精确值，不带单位。无需四舍五入。使用数学符号表示所有中间推导过程。",
            "solution": "该问题要求计算当从一个路径图中移除一个桥边时，节点 $5$ 上的两层图卷积网络 (GCN) 输出的变化。这个变化量记为 $\\Delta$，将通过先确定原始图的输出 $h^{(2)}_5$，再确定修改后图的输出 $h'^{(2)}_5$ 来计算。最后，我们将在 GNN 中的消息传递、瓶颈和过度挤压的背景下分析此结果。\n\nGCN 的传播规则为 $\\mathbf{H}^{(l+1)} = \\sigma\\!\\left(\\mathbf{S}\\,\\mathbf{H}^{(l)}\\,\\mathbf{W}^{(l)}\\right)$。当激活函数 $\\sigma$ 为恒等函数，权重 $\\mathbf{W}^{(0)} = [1]$ 和 $\\mathbf{W}^{(1)} = [1]$ 时，该规则简化为 $\\mathbf{H}^{(l+1)} = \\mathbf{S}\\,\\mathbf{H}^{(l)}$。对于一个两层网络，最终输出为 $\\mathbf{H}^{(2)} = \\mathbf{S}\\,\\mathbf{H}^{(1)} = \\mathbf{S}(\\mathbf{S}\\,\\mathbf{H}^{(0)}) = \\mathbf{S}^2\\,\\mathbf{H}^{(0)}$，其中 $\\mathbf{H}^{(0)} = \\mathbf{X}$ 是输入特征矩阵。\n\n**第一部分：原始图分析**\n\n首先，我们为原始图定义矩阵，其节点为 $V=\\{1,2,3,4,5,6\\}$，边集为 $E = \\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$。\n\n邻接矩阵 $\\mathbf{A}$ 为：\n$$ \\mathbf{A} = \\begin{pmatrix} 0  1  0  0  0  0 \\\\ 1  0  1  0  0  0 \\\\ 0  1  0  1  0  0 \\\\ 0  0  1  0  1  0 \\\\ 0  0  0  1  0  1 \\\\ 0  0  0  0  1  0 \\end{pmatrix} $$\n带自环的邻接矩阵 $\\tilde{\\mathbf{A}} = \\mathbf{A} + \\mathbf{I}$ 为：\n$$ \\tilde{\\mathbf{A}} = \\begin{pmatrix} 1  1  0  0  0  0 \\\\ 1  1  1  0  0  0 \\\\ 0  1  1  1  0  0 \\\\ 0  0  1  1  1  0 \\\\ 0  0  0  1  1  1 \\\\ 0  0  0  0  1  1 \\end{pmatrix} $$\n度矩阵 $\\tilde{\\mathbf{D}}$ 包含由 $\\tilde{\\mathbf{A}}$ 表示的图中节点的度（即 $\\tilde{d}_i = 1 + \\deg(i)$）。对角线元素为 $\\tilde{d}_1=2, \\tilde{d}_2=3, \\tilde{d}_3=3, \\tilde{d}_4=3, \\tilde{d}_5=3, \\tilde{d}_6=2$。\n$$ \\tilde{\\mathbf{D}} = \\mathrm{diag}(2, 3, 3, 3, 3, 2) $$\n对称归一化算子 $\\mathbf{S} = \\tilde{\\mathbf{D}}^{-1/2} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-1/2}$ 的元素为 $S_{ij} = \\frac{\\tilde{A}_{ij}}{\\sqrt{\\tilde{d}_i \\tilde{d}_j}}$。\n$$ \\mathbf{S} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{\\sqrt{6}}  0  0  0  0 \\\\ \\frac{1}{\\sqrt{6}}  \\frac{1}{3}  \\frac{1}{3}  0  0  0 \\\\ 0  \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3}  0  0 \\\\ 0  0  \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3}  0 \\\\ 0  0  0  \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{\\sqrt{6}} \\\\ 0  0  0  0  \\frac{1}{\\sqrt{6}}  \\frac{1}{2} \\end{pmatrix} $$\n输入特征向量为 $\\mathbf{H}^{(0)} = [1, 1, 1, 0, 0, 0]^T$。\n\n我们需要计算 $h^{(2)}_5$，它是 $\\mathbf{H}^{(2)} = \\mathbf{S}^2 \\mathbf{H}^{(0)}$ 的第五个元素。让我们逐步计算。\n首先，$\\mathbf{H}^{(1)} = \\mathbf{S} \\mathbf{H}^{(0)}$。第 $i$ 个元素是 $h^{(1)}_i = \\sum_{j} S_{ij} h^{(0)}_j$。\n$$ h^{(1)}_4 = S_{4,1}x_1 + S_{4,2}x_2 + S_{4,3}x_3 + S_{4,4}x_4 + S_{4,5}x_5 + S_{4,6}x_6 = 0 \\cdot 1 + 0 \\cdot 1 + \\frac{1}{3} \\cdot 1 + \\frac{1}{3} \\cdot 0 + \\frac{1}{3} \\cdot 0 + 0 \\cdot 0 = \\frac{1}{3} $$\n$$ h^{(1)}_5 = S_{5,3}x_3 + S_{5,4}x_4 + S_{5,5}x_5 + S_{5,6}x_6 = 0 \\cdot 1 + \\frac{1}{3} \\cdot 0 + \\frac{1}{3} \\cdot 0 + \\frac{1}{\\sqrt{6}} \\cdot 0 = 0 $$\n$$ h^{(1)}_6 = S_{6,5}x_5 + S_{6,6}x_6 = \\frac{1}{\\sqrt{6}} \\cdot 0 + \\frac{1}{2} \\cdot 0 = 0 $$\n现在，我们计算 $\\mathbf{H}^{(2)} = \\mathbf{S} \\mathbf{H}^{(1)}$。我们只需要第五个元素 $h^{(2)}_5$。\n$$ h^{(2)}_5 = S_{5,4}h^{(1)}_4 + S_{5,5}h^{(1)}_5 + S_{5,6}h^{(1)}_6 = \\frac{1}{3} \\cdot h^{(1)}_4 + \\frac{1}{3} \\cdot h^{(1)}_5 + \\frac{1}{\\sqrt{6}} \\cdot h^{(1)}_6 $$\n代入 $\\mathbf{H}^{(1)}$ 的值：\n$$ h^{(2)}_5 = \\frac{1}{3} \\cdot \\frac{1}{3} + \\frac{1}{3} \\cdot 0 + \\frac{1}{\\sqrt{6}} \\cdot 0 = \\frac{1}{9} $$\n\n**第二部分：修改后图的分析**\n\n接下来，我们考虑移除了桥边 $(3,4)$ 的图。该图现在断开为两个连通分量：$\\{1,2,3\\}$ 和 $\\{4,5,6\\}$。\n\n新的邻接矩阵 $\\mathbf{A}'$ 及其带自环的版本 $\\tilde{\\mathbf{A}}'$ 是块对角矩阵：\n$$ \\tilde{\\mathbf{A}}' = \\begin{pmatrix} 1  1  0  0  0  0 \\\\ 1  1  1  0  0  0 \\\\ 0  1  1  0  0  0 \\\\ 0  0  0  1  1  0 \\\\ 0  0  0  1  1  1 \\\\ 0  0  0  0  1  1 \\end{pmatrix} $$\n新的度是 $\\tilde{d}'_1=2, \\tilde{d}'_2=3, \\tilde{d}'_3=2$ 和 $\\tilde{d}'_4=2, \\tilde{d}'_5=3, \\tilde{d}'_6=2$。\n新的度矩阵是 $\\tilde{\\mathbf{D}}' = \\mathrm{diag}(2, 3, 2, 2, 3, 2)$。\n新的归一化算子 $\\mathbf{S}'$ 也是块对角的，反映了这两个连通分量。当 $i \\in \\{1,2,3\\}$ 且 $j \\in \\{4,5,6\\}$（或反之）时，没有非零元素 $S'_{ij}$。\n\n输出为 $\\mathbf{H}'^{(2)} = (\\mathbf{S}')^2 \\mathbf{H}^{(0)}$。由于 $\\mathbf{S}'$ 的块对角结构，消息传递被限制在每个连通分量内部。$\\{4,5,6\\}$ 中的节点只能从 $\\{4,5,6\\}$ 中的其他节点聚合信息。\n这个分量的输入特征是 $x_4=0, x_5=0, x_6=0$。\n在第一层，对于任意节点 $i \\in \\{4,5,6\\}$，输出是：\n$$ h'^{(1)}_i = \\sum_{j \\in \\{4,5,6\\}} S'_{ij} x_j = \\sum_{j \\in \\{4,5,6\\}} S'_{ij} \\cdot 0 = 0 $$\n由于该分量中所有第一层的输出都为零，因此第二层的输出也必须为零：\n$$ h'^{(2)}_i = \\sum_{j \\in \\{4,5,6\\}} S'_{ij} h'^{(1)}_j = \\sum_{j \\in \\{4,5,6\\}} S'_{ij} \\cdot 0 = 0 $$\n因此，修改后图中节点 $5$ 的输出是 $h'^{(2)}_5 = 0$。\n\n**第三部分：变化量的计算**\n\n变化量 $\\Delta$ 是两个输出之间的差值：\n$$ \\Delta = h^{(2)}_5 - h'^{(2)}_5 = \\frac{1}{9} - 0 = \\frac{1}{9} $$\n\n**第四部分：概念性解释**\n\n这个计算为 GNN 如何处理跨图瓶颈的信息流提供了定量的见解。\n1.  **消息传递和感受野**：GCN 通过聚合其局部邻域的消息来更新节点的特征向量。经过 $L$ 层后，一个节点的表示会受到距离 $L$ 以内的所有节点的初始特征的影响，即其 $L$-跳感受野。在我们的 $L=2$ 问题中，输出 $h^{(2)}_5$ 是距离节点 $5$ 最多 2 跳的节点的初始特征的函数。\n\n2.  **瓶颈敏感性**：在原始图中，从节点 $3$ 到节点 $5$ 的路径是 $3-4-5$，长度为 $2$。因此，初始特征 $x_3$ 可以影响最终的表示 $h^{(2)}_5$。边 $(3,4)$ 充当结构性**瓶颈**；它是信息从子图 $\\{1,2,3\\}$ 传播到子图 $\\{4,5,6\\}$ 的唯一路径。我们的计算表明，$x_3=1$ 的影响通过这个瓶颈传播到节点 $5$，导致 $h^{(2)}_5 = 1/9$。这个值 $\\Delta = 1/9$ 精确地量化了来自第一个连通分量的信号在经过两次聚合步骤后到达节点 5 的强度。\n\n3.  **过度挤压 (Over-squashing)**：**过度挤压** (over-squashing) 这个术语描述了这样一个问题：当信息经过许多层（长距离）传递时，它可能会被指数级稀释或“挤压”，尤其是在被迫通过狭窄瓶颈时。从节点 $u$ 传递到 $v$ 的消息被一个归一化常数缩放，这里是 $1/\\sqrt{\\tilde{d}_u \\tilde{d}_v}$。在我们的例子中，来自 $x_3$ 的信号首先被 $1/\\sqrt{\\tilde{d}_4 \\tilde{d}_3} = 1/3$ 缩放，以贡献给 $h^{(1)}_4$。节点 $4$ 上的这个中间信号随后被传递到节点 $5$，并被 $1/\\sqrt{\\tilde{d}_5 \\tilde{d}_4} = 1/3$ 缩放。这两跳的总衰减给出了 $1/9$ 的因子，这是信号在穿过路径 $3-4-5$ 时被“挤压”程度的直接度量。\n\n通过移除桥 $(3,4)$，我们切断了唯一的通信链路。因此，节点 $5$ 的感受野缩小到只包含其自身连通分量 $\\{4,5,6\\}$ 内的节点。由于该分量中的初始特征全为零，$h'^{(2)}_5$ 变为零。变化量 $\\Delta=1/9$ 代表了来自图另一侧信息流的完全丢失，凸显了 GCN 对图的连通性和瓶颈严重程度的严重依赖。这是过度挤压的最极端形式，即由于路径断开，消息被挤压为零。",
            "answer": "$$\\boxed{\\frac{1}{9}}$$"
        }
    ]
}