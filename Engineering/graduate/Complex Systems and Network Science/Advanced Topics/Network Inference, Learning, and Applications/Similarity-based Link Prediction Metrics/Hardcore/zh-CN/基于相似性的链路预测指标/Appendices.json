{
    "hands_on_practices": [
        {
            "introduction": "为了有效地使用任何链接预测指标，我们必须首先了解其在简单、无结构环境中的行为。这个练习要求你在经典的 Erdős–Rényi 随机图模型中分析共同邻居 (Common Neighbors, CN) 分数。通过推导其期望值和方差，你将建立一个基准，理解在没有任何特定网络结构的情况下，该指标的预期表现。",
            "id": "4302811",
            "problem": "考虑一个顶点集为 $V=\\{1,2,\\dots,n\\}$ 的简单无向 Erdős–Rényi 随机图 $G(n,p)$，其中每对无序的不同顶点以概率 $p \\in (0,1)$ 独立地形成一条边。对于两个不同的顶点 $u,v \\in V$，其公共邻居相似性分数 $s_{\\mathrm{CN}}(u,v)$ 定义为 $V \\setminus \\{u,v\\}$ 中与 $u$ 和 $v$ 都相邻的顶点数量，即\n$$\ns_{\\mathrm{CN}}(u,v) \\equiv \\sum_{w \\in V \\setminus \\{u,v\\}} \\mathbf{1}\\{(u,w) \\in E \\text{ and } (v,w) \\in E\\},\n$$\n其中 $E$ 是边集，$\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。\n\n固定两个不同的顶点 $u$ 和 $v$，并以 $(u,v)$ 不是一条边为条件事件。仅从 Erdős–Rényi 模型的独立性结构和上述 $s_{\\mathrm{CN}}(u,v)$ 的定义出发，推导条件期望 $\\mathbb{E}[s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E]$ 和条件方差 $\\operatorname{Var}(s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E)$ 关于 $n$ 和 $p$ 的闭式表达式。\n\n请用关于 $n$ 和 $p$ 的解析表达式表示你的最终答案。不需要进行数值近似或舍入。",
            "solution": "该问题要求计算在一个 Erdős–Rényi 随机图 $G(n,p)$ 中，两个不同顶点 $u$ 和 $v$ 之间的公共邻居相似性分数的条件期望 $\\mathbb{E}[s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E]$ 和条件方差 $\\operatorname{Var}(s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E]$。\n\n图 $G(n,p)$ 的顶点集为 $V = \\{1, 2, \\dots, n\\}$。边集 $E$ 是通过以概率 $p$ 独立地包含 $\\binom{n}{2}$ 条可能边中的每一条而形成的。我们用 $X_{ij}$ 表示顶点 $i$ 和 $j$ 之间存在边的指示随机变量。即，如果 $(i,j) \\in E$，则 $X_{ij} = 1$，否则 $X_{ij}=0$。变量集合 $\\{X_{ij} \\mid 1 \\le i  j \\le n\\}$ 是一组独立同分布的伯努利随机变量，其成功概率为 $p$。\n\n对于两个不同的顶点 $u,v \\in V$，公共邻居分数 $s_{\\mathrm{CN}}(u,v)$ 定义为与 $u$ 和 $v$ 都相邻的其他顶点的数量。形式上，\n$$\ns_{\\mathrm{CN}}(u,v) = \\sum_{w \\in V \\setminus \\{u,v\\}} \\mathbf{1}\\{(u,w) \\in E \\text{ and } (v,w) \\in E\\}\n$$\n对于每个顶点 $w \\in V \\setminus \\{u,v\\}$，我们定义一个指示变量 $Z_w$：\n$$\nZ_w = \\mathbf{1}\\{(u,w) \\in E \\text{ and } (v,w) \\in E\\} = X_{uw} X_{vw}\n$$\n于是，公共邻居分数可以写成这 $n-2$ 个指示变量的和：\n$$\ns_{\\mathrm{CN}}(u,v) = \\sum_{w \\in V \\setminus \\{u,v\\}} Z_w\n$$\n我们需要计算 $s_{\\mathrm{CN}}(u,v)$ 在事件 $A \\equiv \\{(u,v) \\notin E\\}$ 条件下的期望和方差。该事件对应于 $X_{uv} = 0$。\n\n关键的洞察在于分析随机依赖结构。随机变量 $s_{\\mathrm{CN}}(u,v)$ 是随机变量集合 $\\{Z_w \\mid w \\in V \\setminus \\{u,v\\}\\}$ 的函数。每个 $Z_w$ 又是边指示变量 $X_{uw}$ 和 $X_{vw}$ 的函数。因此，$s_{\\mathrm{CN}}(u,v)$ 完全由随机变量集合 $\\{X_{uw}, X_{vw} \\mid w \\in V \\setminus \\{u,v\\}\\}$ 决定。\n\n条件事件 $A$ 由单个不同的随机变量 $X_{uv}$ 的状态决定。\n在 Erdős–Rényi 模型中，所有边指示变量 $X_{ij}$ 都是相互独立的。决定 $s_{\\mathrm{CN}}(u,v)$ 的变量的边索引集合是 $\\{\\{u,w\\}, \\{v,w\\} \\mid w \\in V \\setminus \\{u,v\\}\\}$。条件事件的边索引是 $\\{u,v\\}$。由于 $w$ 与 $u$ 和 $v$ 都不同，所以点对 $\\{u,v\\}$ 与任何形如 $\\{u,w\\}$ 或 $\\{v,w\\}$ 的点对都不同。因此，随机变量 $X_{uv}$ 与整个随机变量集合 $\\{X_{uw}, X_{vw} \\mid w \\in V \\setminus \\{u,v\\}\\}$ 是独立的。\n\n因为 $s_{\\mathrm{CN}}(u,v)$ 是一个随机变量集合的函数，而这个集合与 $X_{uv}$ 随机独立，所以随机变量 $s_{\\mathrm{CN}}(u,v)$ 本身也与 $X_{uv}$ 独立。这意味着 $s_{\\mathrm{CN}}(u,v)$ 也与事件 $A = \\{X_{uv}=0\\}$ 独立。\n\n对于任何随机变量 $Y$ 和一个与它随机独立的事件 $B$，给定 $B$ 的条件下 $Y$ 的条件期望和条件方差等于其无条件对应值：$\\mathbb{E}[Y \\mid B] = \\mathbb{E}[Y]$ 和 $\\operatorname{Var}(Y \\mid B) = \\operatorname{Var}(Y)$。\n应用此原理，我们得出结论：\n$$\n\\mathbb{E}[s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E] = \\mathbb{E}[s_{\\mathrm{CN}}(u,v)]\n$$\n$$\n\\operatorname{Var}(s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E) = \\operatorname{Var}(s_{\\mathrm{CN}}(u,v))\n$$\n现在问题简化为计算无条件期望和方差。\n\n**1. $s_{\\mathrm{CN}}(u,v)$ 的期望**\n根据期望的线性性质，\n$$\n\\mathbb{E}[s_{\\mathrm{CN}}(u,v)] = \\mathbb{E}\\left[\\sum_{w \\in V \\setminus \\{u,v\\}} Z_w\\right] = \\sum_{w \\in V \\setminus \\{u,v\\}} \\mathbb{E}[Z_w]\n$$\n指示变量 $Z_w$ 的期望是 $Z_w=1$ 的概率：\n$$\n\\mathbb{E}[Z_w] = P(Z_w = 1) = P((u,w) \\in E \\text{ and } (v,w) \\in E)\n$$\n由于在 $G(n,p)$ 模型中，边 $(u,w)$ 和 $(v,w)$ 的存在是独立事件，我们有：\n$$\n\\mathbb{E}[Z_w] = P((u,w) \\in E) \\cdot P((v,w) \\in E) = p \\cdot p = p^2\n$$\n因此，每个 $Z_w$ 都是参数为 $p^2$ 的伯努利随机变量。期望的求和中包含 $n-2$ 个相同的项：\n$$\n\\mathbb{E}[s_{\\mathrm{CN}}(u,v)] = \\sum_{w \\in V \\setminus \\{u,v\\}} p^2 = (n-2)p^2\n$$\n\n**2. $s_{\\mathrm{CN}}(u,v)$ 的方差**\n随机变量之和的方差是它们协方差的和：\n$$\n\\operatorname{Var}(s_{\\mathrm{CN}}(u,v)) = \\operatorname{Var}\\left(\\sum_{w \\in V \\setminus \\{u,v\\}} Z_w\\right) = \\sum_{w_1, w_2 \\in V \\setminus \\{u,v\\}} \\operatorname{Cov}(Z_{w_1}, Z_{w_2})\n$$\n我们来分析两个不同的顶点 $w_1, w_2 \\in V \\setminus \\{u,v\\}$ 的协方差项 $\\operatorname{Cov}(Z_{w_1}, Z_{w_2})$。随机变量 $Z_{w_1}$ 依赖于边 $(u,w_1)$ 和 $(v,w_1)$。随机变量 $Z_{w_2}$ 依赖于边 $(u,w_2)$ 和 $(v,w_2)$。由于 $u,v,w_1,w_2$ 是四个不同的顶点，边集 $\\{(u,w_1), (v,w_1)\\}$ 与 $\\{(u,w_2), (v,w_2)\\}$ 不相交。由于在 $G(n,p)$ 中所有边都是独立形成的，所以当 $w_1 \\neq w_2$ 时，随机变量 $Z_{w_1}$ 和 $Z_{w_2}$ 是独立的。\n独立随机变量的协方差为零，因此对于 $w_1 \\neq w_2$，有 $\\operatorname{Cov}(Z_{w_1}, Z_{w_2})=0$。\n这将方差的计算简化为各个方差之和：\n$$\n\\operatorname{Var}(s_{\\mathrm{CN}}(u,v)) = \\sum_{w \\in V \\setminus \\{u,v\\}} \\operatorname{Var}(Z_w)\n$$\n由于 $Z_w \\sim \\operatorname{Bernoulli}(p^2)$，其方差为：\n$$\n\\operatorname{Var}(Z_w) = p^2(1-p^2)\n$$\n总方差是 $n-2$ 个相同方差项的和：\n$$\n\\operatorname{Var}(s_{\\mathrm{CN}}(u,v)) = \\sum_{w \\in V \\setminus \\{u,v\\}} p^2(1-p^2) = (n-2)p^2(1-p^2)\n$$\n综合这些结果，我们得到最终的条件期望和条件方差。\n条件期望为 $\\mathbb{E}[s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E] = (n-2)p^2$。\n条件方差为 $\\operatorname{Var}(s_{\\mathrm{CN}}(u,v) \\mid (u,v) \\notin E) = (n-2)p^2(1-p^2)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} (n-2)p^2  (n-2)p^2(1-p^2) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "虽然共同邻居分数很直观，但在度分布极不均匀的网络中，它可能会产生误导。这个思想实验将你置于一个对抗性场景中，以揭示 CN 指标在面对人为抬高连接度的中心节点时的脆弱性。通过将其预测结果与 Adamic-Adar 和 Resource Allocation 指数进行比较，你将亲身体会到为什么降低高连接度节点的贡献对于鲁棒的链接预测至关重要。",
            "id": "4302824",
            "problem": "考虑一个表示推荐网络的无向简单图 $G=(V,E)$。一个目标顶点 $x \\in V$ 的邻居为 $\\{h,a,b\\}$，我们的目标是使用基于相似度的链接预测指标来为从 $x$ 到非邻居顶点的潜在链接进行评分。一个攻击者通过连接 $m=50$ 个仅与 $h$ 相连的虚假顶点 $\\{f_1,\\dots,f_{50}\\}$，构建了一个度被人为夸大的枢纽节点 $h$。邻域集合如下：\n- $\\Gamma(x)=\\{h,a,b\\}$,\n- $\\Gamma(h)=\\{x\\}\\cup\\{f_1,\\dots,f_{50}\\}$,\n- $\\Gamma(a)=\\{x,u,v\\}$,\n- $\\Gamma(b)=\\{x,u,w\\}$,\n- $\\Gamma(u)=\\{a,b\\}$,\n- $\\Gamma(v)=\\{a\\}$,\n- $\\Gamma(w)=\\{b\\}$,\n- $\\Gamma(f_i)=\\{h\\}$ for all $i\\in\\{1,\\dots,50\\}$.\n\n需要评分的候选非边是 $(x,u)$、$(x,v)$、$(x,w)$ 以及对于任何 $i\\in\\{1,\\dots,50\\}$ 的 $(x,f_i)$。从无向图中度（degree）和共同邻居（common neighbors）的核心定义，以及标准的基于相似度的链接预测指标——共同邻居（Common Neighbors, CN）、Adamic-Adar（AA）和资源分配（Resource Allocation, RA）出发，判断哪个陈述最能描述这些候选非边分数的相对排序，并解释 CN 对抗性枢纽节点的易受攻击性以及 AA 和 RA 提供的缓解作用。假设对数为自然对数，并允许平局。\n\nA. 在 $CN$ 指标下，对于任何 $i$，有 $s_{CN}(x,u)s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。在 Adamic-Adar (AA) 和资源分配 (RA) 指标下，有 $s_{AA}(x,u)s_{AA}(x,v)=s_{AA}(x,w)s_{AA}(x,f_i)$ 和 $s_{RA}(x,u)s_{RA}(x,v)=s_{RA}(x,w)s_{RA}(x,f_i)$，因为枢纽节点被夸大的度降低了其贡献权重。因此，对抗性枢纽节点通过 $\\{f_i\\}$ 给 CN 指标带来了大量平局，但 AA 和 RA 降低了这种易受攻击性。即使 $h$ 的关联边中缺少了 10%，在 AA 和 RA 指标下的这种定性排序也保持不变。\n\nB. 在 $CN$ 指标下，$s_{CN}(x,f_i)s_{CN}(x,u)$，因为枢纽节点的度更高。在 $AA$ 指标下，夸大 $k_h$ 会进一步增加 $s_{AA}(x,f_i)$，而在 $RA$ 指标下，枢纽节点的贡献为零，所以 $s_{RA}(x,f_i)=0$。\n\nC. 在 $CN$ 指标下，$s_{CN}(x,u)=s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。在 $AA$ 指标下，$s_{AA}(x,f_i)s_{AA}(x,v)$，因为 $1/\\log k_h$ 随着 $k_h$ 的增长而增长。在 $RA$ 指标下，分数与共同邻居的度无关。\n\nD. 在 $CN$ 指标下，$s_{CN}(x,u)=s_{CN}(x,v)s_{CN}(x,w)=s_{CN}(x,f_i)$。在 $AA$ 和 $RA$ 指标下，由于公平性考虑和缺失数据，有 $s_{AA}(x,f_i)=s_{AA}(x,v)$ 和 $s_{RA}(x,f_i)=s_{RA}(x,v)$，因此对抗性枢纽节点不影响相对排序。",
            "solution": "问题陈述的严格验证如下。\n\n### 步骤 1：提取已知条件\n-   该图是一个无向简单图 $G=(V,E)$。\n-   考虑一个目标顶点 $x \\in V$。\n-   一个对抗性枢纽节点 $h$ 的度通过添加 $m=50$ 个仅与 $h$ 相连的虚假顶点 $\\{f_1,\\dots,f_{50}\\}$ 而被人为夸大。\n-   邻域集合已给出：\n    -   $\\Gamma(x)=\\{h,a,b\\}$\n    -   $\\Gamma(h)=\\{x\\}\\cup\\{f_1,\\dots,f_{50}\\}$\n    -   $\\Gamma(a)=\\{x,u,v\\}$\n    -   $\\Gamma(b)=\\{x,u,w\\}$\n    -   $\\Gamma(u)=\\{a,b\\}$\n    -   $\\Gamma(v)=\\{a\\}$\n    -   $\\Gamma(w)=\\{b\\}$\n    -   $\\Gamma(f_i)=\\{h\\}$ for all $i\\in\\{1,\\dots,50\\}$\n-   需要评分的候选非边：$(x,u)$、$(x,v)$、$(x,w)$ 以及对于任何 $i\\in\\{1,\\dots,50\\}$ 的 $(x,f_i)$。\n-   使用的指标：共同邻居 (Common Neighbors, CN)、Adamic-Adar (AA) 和资源分配 (Resource Allocation, RA)。\n-   假设：对数为自然对数，并允许平局。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题使用了图论和网络科学中标准的、定义明确的概念，包括邻域、度，以及链接预测指标 CN、AA 和 RA。对抗性场景是网络算法鲁棒性研究中一个公认的研究课题。该问题具有科学合理性。\n2.  **适定性**：图结构通过邻域集合得到了明确和完整的定义。候选链接的集合也已明确指定。评分函数是标准的。这使得可以计算出一组唯一的得分，从而得到一个确定的排序。该问题是适定的。\n3.  **客观性**：该问题使用精确的数学符号和客观的语言陈述，没有歧义或主观论断。\n4.  **完整性与一致性**：邻域的定义对于无向图是一致的。对于每一条边 $(y,z)$，$y$ 都在 $\\Gamma(z)$ 中，并且 $z$ 都在 $\\Gamma(y)$ 中。例如，$a \\in \\Gamma(x)$ 且 $x \\in \\Gamma(a)$；$h \\in \\Gamma(f_i)$ 且 $f_i \\in \\Gamma(h)$。所有给出的定义都是相互一致的。该问题是完整且自洽的。\n5.  **现实性与可行性**：该场景虽然是一个简化模型，但代表了对推荐系统的一种现实的对抗性攻击类型。所有计算都是可行的。\n6.  **其他缺陷**：该问题并非无关紧要、同义反复或不适定。它需要直接应用和比较标准指标。\n\n### 步骤 3：结论与行动\n问题陈述是有效的。可以推导出严谨的解答。\n\n### 解题推导\n\n首先，我们为一对未连接的顶点 $(X,Y)$ 定义三个基于相似度的链接预测指标：\n1.  **共同邻居 (CN)**：分数是 $X$ 和 $Y$ 共享的邻居数量。\n    $$s_{CN}(X,Y) = |\\Gamma(X) \\cap \\Gamma(Y)|$$\n2.  **Adamic-Adar (AA)**：该指标通过为度较低的共同邻居分配更高的权重来改进 CN。\n    $$s_{AA}(X,Y) = \\sum_{z \\in \\Gamma(X) \\cap \\Gamma(Y)} \\frac{1}{\\log k_z}$$\n    其中 $k_z = |\\Gamma(z)|$ 是顶点 $z$ 的度。\n3.  **资源分配 (RA)**：与 AA 类似，该指标对高度数的共同邻居进行惩罚。\n    $$s_{RA}(X,Y) = \\sum_{z \\in \\Gamma(X) \\cap \\Gamma(Y)} \\frac{1}{k_z}$$\n\n接下来，我们根据给定的邻域集合计算所有相关顶点的度 ($k_z$)：\n-   $k_x = |\\Gamma(x)| = |\\{h,a,b\\}| = 3$\n-   $k_h = |\\Gamma(h)| = |\\{x\\} \\cup \\{f_1, \\dots, f_{50}\\}| = 1 + 50 = 51$\n-   $k_a = |\\Gamma(a)| = |\\{x,u,v\\}| = 3$\n-   $k_b = |\\Gamma(b)| = |\\{x,u,w\\}| = 3$\n-   $k_u = |\\Gamma(u)| = |\\{a,b\\}| = 2$\n-   $k_v = |\\Gamma(v)| = |\\{a\\}| = 1$\n-   $k_w = |\\Gamma(w)| = |\\{b\\}| = 1$\n-   $k_{f_i} = |\\Gamma(f_i)| = |\\{h\\}| = 1$\n\n现在，对于每个候选非边，我们确定共同邻居的集合：\n-   对于 $(x,u)$: $\\Gamma(x) \\cap \\Gamma(u) = \\{h,a,b\\} \\cap \\{a,b\\} = \\{a,b\\}$\n-   对于 $(x,v)$: $\\Gamma(x) \\cap \\Gamma(v) = \\{h,a,b\\} \\cap \\{a\\} = \\{a\\}$\n-   对于 $(x,w)$: $\\Gamma(x) \\cap \\Gamma(w) = \\{h,a,b\\} \\cap \\{b\\} = \\{b\\}$\n-   对于 $(x,f_i)$: $\\Gamma(x) \\cap \\Gamma(f_i) = \\{h,a,b\\} \\cap \\{h\\} = \\{h\\}$\n\n有了这些，我们就可以计算分数了。\n\n**共同邻居 (CN) 分数：**\n-   $s_{CN}(x,u) = |\\{a,b\\}| = 2$\n-   $s_{CN}(x,v) = |\\{a\\}| = 1$\n-   $s_{CN}(x,w) = |\\{b\\}| = 1$\n-   $s_{CN}(x,f_i) = |\\{h\\}| = 1$\n排序为 $s_{CN}(x,u)  s_{CN}(x,v) = s_{CN}(x,w) = s_{CN}(x,f_i)$。\n这个结果展示了 CN 指标的易受攻击性。与任何一个虚假叶节点 $(x, f_i)$ 的链接，其得分与更“自然”的潜在链接 $(x,v)$ 和 $(x,w)$ 一样高，仅仅因为它们都与 $x$ 有一个共同邻居。该指标未能区分共同邻居的质量。\n\n**Adamic-Adar (AA) 分数：**\n-   $s_{AA}(x,u) = \\frac{1}{\\log k_a} + \\frac{1}{\\log k_b} = \\frac{1}{\\log 3} + \\frac{1}{\\log 3} = \\frac{2}{\\log 3}$\n-   $s_{AA}(x,v) = \\frac{1}{\\log k_a} = \\frac{1}{\\log 3}$\n-   $s_{AA}(x,w) = \\frac{1}{\\log k_b} = \\frac{1}{\\log 3}$\n-   $s_{AA}(x,f_i) = \\frac{1}{\\log k_h} = \\frac{1}{\\log 51}$\n为了比较这些值，我们注意到自然对数函数 $\\log(z)$ 在 $z1$ 时是单调递增的。因此，$51  3 \\implies \\log 51  \\log 3$。这反过来意味着 $\\frac{1}{\\log 51}  \\frac{1}{\\log 3}$。\n排序为 $\\frac{2}{\\log 3}  \\frac{1}{\\log 3}  \\frac{1}{\\log 51}$，即：\n$s_{AA}(x,u)  s_{AA}(x,v) = s_{AA}(x,w)  s_{AA}(x,f_i)$。\n\n**资源分配 (RA) 分数：**\n-   $s_{RA}(x,u) = \\frac{1}{k_a} + \\frac{1}{k_b} = \\frac{1}{3} + \\frac{1}{3} = \\frac{2}{3}$\n-   $s_{RA}(x,v) = \\frac{1}{k_a} = \\frac{1}{3}$\n-   $s_{RA}(x,w) = \\frac{1}{k_b} = \\frac{1}{3}$\n-   $s_{RA}(x,f_i) = \\frac{1}{k_h} = \\frac{1}{51}$\n因为 $51  3$，所以 $\\frac{1}{51}  \\frac{1}{3}$。\n排序为 $\\frac{2}{3}  \\frac{1}{3}  \\frac{1}{51}$，即：\n$s_{RA}(x,u)  s_{RA}(x,v) = s_{RA}(x,w)  s_{RA}(x,f_i)$。\n\nAA 和 RA 都通过大幅降低高度枢纽节点 $h$ 的贡献权重，成功地缓解了对抗性攻击，导致涉及虚假节点的链接 $(x,f_i)$ 得分非常低。\n\n### 逐项分析\n\n**A. 在 $CN$ 指标下，对于任何 $i$，有 $s_{CN}(x,u)s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。在 Adamic-Adar (AA) 和资源分配 (RA) 指标下，有 $s_{AA}(x,u)s_{AA}(x,v)=s_{AA}(x,w)s_{AA}(x,f_i)$ 和 $s_{RA}(x,u)s_{RA}(x,v)=s_{RA}(x,w)s_{RA}(x,f_i)$，因为枢纽节点被夸大的度降低了其贡献权重。因此，对抗性枢纽节点通过 $\\{f_i\\}$ 给 CN 指标带来了大量平局，但 AA 和 RA 降低了这种易受攻击性。即使 $h$ 的关联边中缺少了 10%，在 AA 和 RA 指标下的这种定性排序也保持不变。**\n\n-   关于 CN 的陈述是 $s_{CN}(x,u)  s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。我们的计算得出 $2  1=1=1$，这是正确的。\n-   关于 AA 的陈述是 $s_{AA}(x,u)s_{AA}(x,v)=s_{AA}(x,w)s_{AA}(x,f_i)$。我们的计算得出 $\\frac{2}{\\log 3}  \\frac{1}{\\log 3}  \\frac{1}{\\log 51}$，这是正确的。\n-   关于 RA 的陈述是 $s_{RA}(x,u)s_{RA}(x,v)=s_{RA}(x,w)s_{RA}(x,f_i)$。我们的计算得出 $\\frac{2}{3}  \\frac{1}{3}  \\frac{1}{51}$，这是正确的。\n-   对于 AA 和 RA 来说，枢纽节点被夸大的度降低了其贡献权重的推理是正确的。\n-   关于 CN 的易受攻击性以及 AA/RA 的缓解作用的解释也是正确的。\n-   关于稳定性的最后论断：如果 $h$ 的 10% 边缺失，其度将变为 $k'_h$。例如，移除 5 条到虚假节点的边将导致 $k'_h = 51 - 5 = 46$。只要 $k'_h  k_a = 3$ 且 $k'_h  k_b = 3$，AA ($s(x,v)  s(x,f_i)$ 因为 $\\frac{1}{\\log 3}  \\frac{1}{\\log 46}$) 和 RA ($s(x,v)  s(x,f_i)$ 因为 $\\frac{1}{3}  \\frac{1}{46}$) 的定性排序将保持不变。将 $k_h$ 减少 10% 仍然使其远大于 3。因此，这个论断也是正确的。\n-   **结论：正确。**\n\n**B. 在 $CN$ 指标下，$s_{CN}(x,f_i)s_{CN}(x,u)$，因为枢纽节点的度更高。在 $AA$ 指标下，夸大 $k_h$ 会进一步增加 $s_{AA}(x,f_i)$，而在 $RA$ 指标下，枢纽节点的贡献为零，所以 $s_{RA}(x,f_i)=0$。**\n\n-   第一个论断是 $s_{CN}(x,f_i)s_{CN}(x,u)$。我们的计算是 $1  2$，这是错误的。理由“因为枢纽节点的度更高”与 CN 分数无关。\n-   第二个论断是夸大 $k_h$ 会增加 $s_{AA}(x,f_i) = \\frac{1}{\\log k_h}$。随着 $k_h$ 增加，$\\log k_h$ 增加，其倒数 $\\frac{1}{\\log k_h}$ 会*减小*。这个论断是错误的。\n-   第三个论断是 $s_{RA}(x,f_i)=0$。我们的计算是 $s_{RA}(x,f_i) = \\frac{1}{k_h} = \\frac{1}{51} \\neq 0$。这个论断是错误的。\n-   **结论：不正确。**\n\n**C. 在 $CN$ 指标下，$s_{CN}(x,u)=s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。在 $AA$ 指标下，$s_{AA}(x,f_i)s_{AA}(x,v)$，因为 $1/\\log k_h$ 随着 $k_h$ 的增长而增长。在 $RA$ 指标下，分数与共同邻居的度无关。**\n\n-   第一个论断是 $s_{CN}(x,u)=s_{CN}(x,v)=s_{CN}(x,w)=s_{CN}(x,f_i)$。我们的计算得出 $2=1=1=1$，这是错误的。\n-   第二个论断是 $s_{AA}(x,f_i)s_{AA}(x,v)$。我们的计算得出 $\\frac{1}{\\log 51}  \\frac{1}{\\log 3}$，这是错误的。理由“$1/\\log k_h$ 随着 $k_h$ 增长而增长”也是错误的。\n-   第三个论断是 RA 分数与共同邻居的度无关。RA 的公式是 $\\sum \\frac{1}{k_z}$，它明确地依赖于共同邻居的度 $k_z$。这个论断是错误的。\n-   **结论：不正确。**\n\n**D. 在 $CN$ 指标下，$s_{CN}(x,u)=s_{CN}(x,v)s_{CN}(x,w)=s_{CN}(x,f_i)$。在 $AA$ 和 $RA$ 指标下，由于公平性考虑和缺失数据，有 $s_{AA}(x,f_i)=s_{AA}(x,v)$ 和 $s_{RA}(x,f_i)=s_{RA}(x,v)$，因此对抗性枢纽节点不影响相对排序。**\n\n-   第一个论断是 $s_{CN}(x,u)=s_{CN}(x,v)s_{CN}(x,w)=s_{CN}(x,f_i)$。我们的计算表明 $s_{CN}(x,u)=2$ 且 $s_{CN}(x,v)=1$。等式 $2=1$ 是错误的。\n-   第二个论断是 $s_{AA}(x,f_i)=s_{AA}(x,v)$。我们的计算得出 $\\frac{1}{\\log 51} = \\frac{1}{\\log 3}$，这是错误的。\n-   第三个论断是 $s_{RA}(x,f_i)=s_{RA}(x,v)$。我们的计算得出 $\\frac{1}{51} = \\frac{1}{3}$，这是错误的。理由“由于公平性考虑和缺失数据”是毫无根据的，并且与指标定义无关。\n-   **结论：不正确。**\n\n基于严谨的推导和逐项分析，只有选项 A 是正确的。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "一个理论上完美的指标，只有当它能够在大规模真实网络上被高效计算时才具有实用价值。这个练习深入探讨了基于相似性的链接预测中至关重要的算法复杂度问题。你将通过分析和比较两种不同方法——直接邻接表求交集和稀疏矩阵乘法——来计算所有节点对的共同邻居分数，从而揭示可扩展网络分析中涉及的权衡。",
            "id": "4302829",
            "problem": "考虑一个包含 $n$ 个节点和 $m$ 条边的无向简单图，该图以邻接表和稀疏邻接矩阵两种形式表示。对于节点对 $(i,j)$，其共同邻居（CN）相似度定义为同时与 $i$ 和 $j$ 相邻的节点集合的基数。假设所有邻接表都已排序存储，并且每个列表的交集计算都使用双指针扫描方法，该方法比较元素直到两个列表都遍历完毕。考虑通过求节点 $i$ 和 $j$ 的邻接表交集，来计算所有满足 $1 \\leq i  j \\leq n$ 的无序节点对 $(i,j)$ 的CN值的任务。\n\n另外，考虑通过计算稀疏邻接矩阵的平方来计算所有节点对的CN值，即使用基于压缩稀疏行（CSR）和压缩稀疏列（CSC）数据结构实现的标准的稀疏通用矩阵-矩阵乘法（SpGEMM）方法，计算邻接矩阵与自身的乘积。在该方法中，乘积矩阵的每一行是通过对其邻居节点的邻接行求和形成的，合并它们的稀疏索引列表以累积计数；假设采用单位工作模型，其中每次访问和合并一个邻接条目就算作一次基本操作，并且与列表合并相比，哈希或去重成本可以忽略不计。\n\n设图的度序列为 $(d_{1}, d_{2}, \\dots, d_{n})$，且 $\\sum_{i=1}^{n} d_{i} = 2m$。在上述假设下，从基本原理出发，推导这两种方法的总基本操作计数的表达式。然后，给出通过邻接表交集计算所有节点对CN的成本与通过SpGEMM计算成本之比的主阶解析表达式，该表达式仅用 $n$、$m$ 和 $\\sum_{i=1}^{n} d_{i}^{2}$ 表示。你的最终答案必须是一个没有单位的单一闭式解析表达式。不需要进行数值近似或四舍五入。",
            "solution": "我们首先精确地重述定义和建模假设。对于一个包含 $n$ 个节点和 $m$ 条边的无向简单图，节点 $i$ 和 $j$ 之间的共同邻居（CN）相似度是指同时与 $i$ 和 $j$ 相邻的节点数量。等价地，它是节点 $i$ 和 $j$ 的邻接表交集的基数。邻接表是排序的，交集计算使用双指针扫描，该扫描在两个列表中移动指针并比较条目，直到其中一个列表遍历完毕；在这种扫描中执行的比较次数与两个列表的长度之和成正比。\n\n我们分析两种计算所有满足 $1 \\leq i  j \\leq n$ 的无序节点对 $(i,j)$ 的CN值的方法。\n\n方法1：所有节点对的邻接表交集。对于每个无序对 $(i,j)$，我们计算节点 $i$ 和 $j$ 的邻接表的交集。如果节点 $i$ 的度为 $d_i$，节点 $j$ 的度为 $d_j$，那么双指针交集操作执行的比较次数的量级为 $d_i + d_j$。因此，对所有节点对的总基本操作计数 $T_{\\text{intersect}}$ 为\n$$\nT_{\\text{intersect}} = \\sum_{1 \\leq i  j \\leq n} (d_i + d_j).\n$$\n我们来简化这个求和式。观察到，在双重求和中，每个 $d_i$ 对于包含节点 $i$ 的每一个节点对都出现一次，而每个节点恰好参与 $n-1$ 个无序对。因此，\n$$\n\\sum_{1 \\leq i  j \\leq n} (d_i + d_j)\n= \\sum_{i=1}^{n} d_i \\cdot (n-1).\n$$\n因为 $\\sum_{i=1}^{n} d_i = 2m$，我们得到\n$$\nT_{\\text{intersect}} = (n-1) \\sum_{i=1}^{n} d_i = 2m(n-1).\n$$\n\n方法2：使用稀疏通用矩阵-矩阵乘法（SpGEMM）计算邻接矩阵的平方。设 $A$ 为 $n \\times n$ 的稀疏邻接矩阵。节点对 $(i,j)$ 的CN值等于 $A^{2}$ 的 $(i,j)$ 项，因为\n$$\n\\left(A^{2}\\right)_{ij} = \\sum_{k=1}^{n} A_{ik} A_{kj},\n$$\n且当且仅当节点 $k$ 同时与 $i$ 和 $j$ 相邻时，$A_{ik} A_{kj} = 1$，这贡献了一个共同邻居。在标准的基于CSR/CSC的SpGEMM中，$A^{2}$ 的第 $i$ 行是通过对节点 $i$ 的所有邻居的邻接行求和而形成的。对于每个邻居 $k \\in \\Gamma(i)$，我们将对应于 $k$ 的稀疏行（其长度为 $d_k$）合并到第 $i$ 行的累加器中。在单位工作模型下，即每次合并中访问一个邻接条目就算作一次基本操作，形成第 $i$ 行的成本为\n$$\n\\sum_{k \\in \\Gamma(i)} d_k.\n$$\n因此，对所有行的总基本操作计数 $T_{\\text{spgemm}}$ 为\n$$\nT_{\\text{spgemm}} = \\sum_{i=1}^{n} \\sum_{k \\in \\Gamma(i)} d_k.\n$$\n我们可以重写这个双重求和，通过认识到每个邻居关系 $(i,k)$ 对每个 $i \\in \\Gamma(k)$ 贡献一次 $d_k$，并且 $k$ 的邻居数量为 $d_k$。因此，\n$$\nT_{\\text{spgemm}} = \\sum_{k=1}^{n} d_k \\cdot d_k = \\sum_{i=1}^{n} d_i^2.\n$$\n\n现在我们通过计算两种方法的总基本操作计数的比率来比较它们。使用上面推导出的表达式，\n$$\n\\frac{T_{\\text{intersect}}}{T_{\\text{spgemm}}}\n= \\frac{2m(n-1)}{\\sum_{i=1}^{n} d_i^2}.\n$$\n在所述假设下，这个比率是主阶解析表达式。它完全由 $n$、$m$ 和 $\\sum_{i=1}^{n} d_i^2$ 表示，符合要求。对于较大的 $n$，可以将 $(n-1)$ 渐近地视为等同于 $n$，但精确表达式仍然是 $\\frac{2m(n-1)}{\\sum_{i=1}^{n} d_i^2}$。\n\n因此，所求的比率为\n$$\n\\frac{2 m (n-1)}{\\sum_{i=1}^{n} d_i^2}.\n$$",
            "answer": "$$\\boxed{\\frac{2 m (n-1)}{\\sum_{i=1}^{n} d_i^{2}}}$$"
        }
    ]
}