{
    "hands_on_practices": [
        {
            "introduction": "将网络嵌入问题概念化的最直接方法之一，是将其视为一个矩阵分解任务。本练习将指导您使用奇异值分解（SVD）这一线性代数中的基本工具，为有向网络的节点生成源嵌入和目标嵌入。通过计算重构误差，您将亲身体验低秩近似如何捕捉网络的连接模式，从而加深对嵌入作为一种压缩表示的理解。",
            "id": "4290602",
            "problem": "考虑一个有向网络，它有 $n$ 个节点，由一个实数邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 表示，其中 $A_{ij} \\geq 0$ 编码了从节点 $i$ 到节点 $j$ 的有向边的存在和强度。网络嵌入旨在将每个节点 $i$ 表示为一个源向量 $x_i \\in \\mathbb{R}^d$ 和一个目标向量 $y_i \\in \\mathbb{R}^d$，使得有向边 $\\{i \\rightarrow j\\}$ 的交互分数能通过内积 $x_i^\\top y_j$ 来近似。对于给定的维度 $d$，重构的邻接矩阵为 $\\hat{A} = X Y^\\top$，其中 $X \\in \\mathbb{R}^{n \\times d}$ 按行堆叠源向量，$Y \\in \\mathbb{R}^{n \\times d}$ 按行堆叠目标向量。\n\n从线性代数和矩阵分解的基本定义开始。一个实数矩阵 $A$ 的奇异值分解（SVD）存在，并写作 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是一个对角矩阵，其对角线上的非负奇异值按非递增顺序排列。最佳的秩-$k$ 近似（在最小化误差的弗罗贝尼乌斯范数的意义上）可以通过将 SVD 截断为前 $k$ 个最大的奇异值及相关的奇异向量来获得。\n\n你的任务是：\n- 通过使用从 $A$ 的截断 SVD 推导出的有原则的因式分解方法，为每个节点构建维度为 $d = 2$ 的源嵌入和目标嵌入。使用这种构造方法来形成 $X \\in \\mathbb{R}^{n \\times 2}$ 和 $Y \\in \\mathbb{R}^{n \\times 2}$，然后计算秩为2的重构矩阵 $\\hat{A} = X Y^\\top$。\n- 将观察到的边集定义为 $\\mathcal{E}_{\\mathrm{obs}} = \\{(i,j) \\mid A_{ij} > 0\\}$。计算在观察到的边上的均方重构误差，其公式为\n$$\\mathrm{MSE}_{\\mathrm{obs}} = \\begin{cases}\n\\frac{1}{|\\mathcal{E}_{\\mathrm{obs}}|} \\sum_{(i,j) \\in \\mathcal{E}_{\\mathrm{obs}}} \\left(A_{ij} - \\hat{A}_{ij}\\right)^2,  &\\text{若 } |\\mathcal{E}_{\\mathrm{obs}}| > 0, \\\\\n0,  &\\text{若 } |\\mathcal{E}_{\\mathrm{obs}}| = 0.\n\\end{cases}$$\n不应对 $\\hat{A}$ 进行任何裁剪或后处理；直接根据重构值计算误差。\n\n实现一个程序，对以下邻接矩阵测试集执行此计算，每个矩阵都指定为列表的列表。在每种情况下，令 $n$ 等于矩阵的行数（和列数）：\n1. 有向4-环 ($n = 4$)：权重为1的边 $\\{1 \\rightarrow 2, 2 \\rightarrow 3, 3 \\rightarrow 4, 4 \\rightarrow 1\\}$，表示为\n$A^{(1)} = \\begin{bmatrix}\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{bmatrix}.$\n2. 小型双向核心 ($n = 3$)：权重为1的边 $\\{1 \\leftrightarrow 2\\}$ 和 $\\{2 \\leftrightarrow 3\\}$，表示为\n$A^{(2)} = \\begin{bmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  0\n\\end{bmatrix}.$\n3. 空图 ($n = 3$)：没有边，表示为\n$A^{(3)} = \\begin{bmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{bmatrix}.$\n4. 无自环的完全有向图 ($n = 3$)：所有非对角线元素都为1，表示为\n$A^{(4)} = \\begin{bmatrix}\n0  1  1 \\\\\n1  0  1 \\\\\n1  1  0\n\\end{bmatrix}.$\n5. 加权有向网络 ($n = 4$)：非对称权重，表示为\n$A^{(5)} = \\begin{bmatrix}\n0  2.0  0  1.5 \\\\\n0  0  0  0 \\\\\n0.5  0  0  1.0 \\\\\n0  0.25  1.0  0\n\\end{bmatrix}.$\n\n你的程序必须：\n- 对于测试集中的每个 $A^{(t)}$，使用截断 SVD 到维度 $d = 2$ 来计算 $X$ 和 $Y$，并如上所述重构 $\\hat{A}$。\n- 为每个测试用例计算 $\\mathrm{MSE}_{\\mathrm{obs}}$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试集的顺序排列结果：$[r^{(1)}, r^{(2)}, r^{(3)}, r^{(4)}, r^{(5)}]$，其中每个 $r^{(t)}$ 是为测试用例 $t$ 计算出的 $\\mathrm{MSE}_{\\mathrm{obs}}$，格式为浮点数。\n\n不涉及物理单位。不涉及角度。不涉及百分比。输出格式必须严格遵循规范。程序必须完全独立，除了最后一行输出外，不得读取输入或写入任何其他内容。",
            "solution": "该问题要求我们使用一种基于奇异值分解（SVD）的方法来计算网络嵌入，并评估其重构误差。核心任务是为有向网络的节点找到一个低维表示，这可以被构建为一个低秩矩阵分解问题。\n\n### 1. 原理：通过 SVD 进行低秩近似\n\n一个包含 $n$ 个节点的有向网络由其邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 给出，其中 $A_{ij} \\geq 0$ 表示从节点 $i$ 到节点 $j$ 的边的权重。目标是找到两组低维向量，即源向量 $\\{x_i\\}_{i=1}^n$ 和目标向量 $\\{y_i\\}_{i=1}^n$，其中 $x_i, y_i \\in \\mathbb{R}^d$，使得它们的内积 $x_i^\\top y_j$ 能够近似原始边的权重 $A_{ij}$。\n\n这可以用矩阵形式表示。令 $X \\in \\mathbb{R}^{n \\times d}$ 为其行是源向量 $x_i^\\top$ 的矩阵，令 $Y \\in \\mathbb{R}^{n \\times d}$ 为其行是目标向量 $y_i^\\top$ 的矩阵。重构的邻接矩阵 $\\hat{A}$ 则由下式给出：\n$$ \\hat{A} = X Y^\\top $$\n根据构造，$\\hat{A}$ 的秩最多为 $d$。因此，问题就变成了找到 $A$ 的最佳秩-$d$ 近似。\n\n$A$ 矩阵的奇异值分解（SVD）为这项任务提供了理论基础。任何实数矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 都有一个 SVD，形式如下：\n$$ A = U \\Sigma V^\\top $$\n其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵 ($U^\\top U = I$, $V^\\top V = I$)，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是一个对角矩阵，包含奇异值 $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_n \\geq 0$。$U$ 的列是左奇异向量，$V$ 的列是右奇异向量。\n\n根据 Eckart-Young-Mirsky 定理，$A$ 的最佳秩-$d$ 近似（在最小化差值 $A - \\hat{A}$ 的弗罗贝尼乌斯范数的意义上）是通过截断 SVD 获得的。这通过只保留前 $d$ 个最大的奇异值及其对应的奇异向量来实现：\n$$ \\hat{A}_d = U_d \\Sigma_d V_d^\\top $$\n这里，$U_d \\in \\mathbb{R}^{n \\times d}$ 包含 $U$ 的前 $d$ 列，$\\Sigma_d \\in \\mathbb{R}^{d \\times d}$ 是一个对角矩阵，其对角线元素为前 $d$ 个奇异值 $\\{\\sigma_1, \\dots, \\sigma_d\\}$，$V_d \\in \\mathbb{R}^{n \\times d}$ 包含 $V$ 的前 $d$ 列。\n\n### 2. 从截断 SVD 构建嵌入\n\n问题指定嵌入的维度为 $d=2$，因此我们需要构建秩为2的近似 $\\hat{A}_2 = U_2 \\Sigma_2 V_2^\\top$。为了满足嵌入结构 $\\hat{A} = XY^\\top$，我们必须根据 SVD 的组件来定义 $X$ 和 $Y$。如题目所要求的“有原则的因式分解”，是指一种有充分理由支持的分解方法。一种标准且平衡的选择是将奇异值的“能量”分配给源嵌入和目标嵌入。我们将 $\\Sigma_d^{1/2}$ 定义为对角线元素为 $\\sqrt{\\sigma_i}$（其中 $i=1, \\dots, d$）的对角矩阵。然后我们可以设定：\n$$ X = U_d \\Sigma_d^{1/2} $$\n$$ Y = V_d \\Sigma_d^{1/2} $$\n通过这种选择，重构结果确实是最佳的秩-$d$ 近似：\n$$ XY^\\top = (U_d \\Sigma_d^{1/2}) (V_d \\Sigma_d^{1/2})^\\top = U_d \\Sigma_d^{1/2} (\\Sigma_d^{1/2})^\\top V_d^\\top = U_d \\Sigma_d V_d^\\top = \\hat{A}_d $$\n对于本问题，当 $d=2$ 时，我们将使用 $X = U_2 \\Sigma_2^{1/2}$ 和 $Y = V_2 \\Sigma_2^{1/2}$。\n\n需要注意的是，如果存在重复的奇异值（例如 $\\sigma_d = \\sigma_{d+1}$），则奇异向量不是唯一的，因此最佳秩-$d$ 近似也不是唯一的。几个测试用例（$A^{(1)}$、$A^{(2)}$、$A^{(4)}$）都表现出此特性。在这种情况下，一个确定性的 SVD 数值算法会为奇异向量选择一个特定的有效基，从而得出一个具体的、可计算复现的结果。我们的解决方案依赖于这个确定性的结果。\n\n### 3. 误差计算\n\n重构的质量通过在观察到的边集 $\\mathcal{E}_{\\mathrm{obs}} = \\{(i,j) \\mid A_{ij} > 0\\}$ 上的均方误差来衡量。公式为：\n$$ \\mathrm{MSE}_{\\mathrm{obs}} = \\begin{cases} \\frac{1}{|\\mathcal{E}_{\\mathrm{obs}}|} \\sum_{(i,j) \\in \\mathcal{E}_{\\mathrm{obs}}} \\left(A_{ij} - \\hat{A}_{ij}\\right)^2,  &\\text{若 } |\\mathcal{E}_{\\mathrm{obs}}| > 0 \\\\ 0,  &\\text{若 } |\\mathcal{E}_{\\mathrm{obs}}| = 0 \\end{cases} $$\n该指标侧重于评估嵌入模型在多大程度上复现了网络中实际存在的连接。\n\n### 4. 实现算法\n\n对于每个给定的邻接矩阵 $A^{(t)}$：\n1.  将输入的列表的列表转换为一个 NumPy 数组 $A$。\n2.  通过创建一个布尔掩码（其中 $A > 0$）来识别观察到的边。计算观察到的边的数量 $|\\mathcal{E}_{\\mathrm{obs}}|$。\n3.  如果 $|\\mathcal{E}_{\\mathrm{obs}}| = 0$（如空图情况 $A^{(3)}$），则结果为 $0.0$。\n4.  否则，计算 $A$ 的 SVD：$u, s, vh = \\text{svd}(A)$，其中 $s$ 包含奇异值，$vh$ 是 $V^\\top$。\n5.  设置嵌入维度 $d=2$。\n6.  形成截断的 SVD 组件：\n    -   $U_2$ 由 $u$ 的前2列组成。\n    -   $\\Sigma_2^{1/2}$ 由 $s$ 中前2个奇异值的平方根形成。\n    -   $V_2$ 由 $vh^\\top$ 的前2列组成。\n7.  构建嵌入矩阵 $X \\in \\mathbb{R}^{n \\times 2}$ 和 $Y \\in \\mathbb{R}^{n \\times 2}$：\n    -   $X = U_2 \\Sigma_2^{1/2}$\n    -   $Y = V_2 \\Sigma_2^{1/2}$\n8.  计算秩为2的重构矩阵 $\\hat{A} = XY^\\top$。\n9.  仅对观察到的边 $(i,j) \\in \\mathcal{E}_{\\mathrm{obs}}$ 计算平方误差 $(A_{ij} - \\hat{A}_{ij})^2$。\n10. 计算这些平方误差的均值以获得 $\\mathrm{MSE}_{\\mathrm{obs}}$。\n11. 存储该值并对所有测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes network embeddings using truncated SVD and calculates the \n    mean squared reconstruction error on observed edges.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Directed 4-cycle\n        [[0, 1, 0, 0],\n         [0, 0, 1, 0],\n         [0, 0, 0, 1],\n         [1, 0, 0, 0]],\n        \n        # 2. Small bidirectional core\n        [[0, 1, 0],\n         [1, 0, 1],\n         [0, 1, 0]],\n        \n        # 3. Empty graph\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n        \n        # 4. Complete directed graph without self-loops\n        [[0, 1, 1],\n         [1, 0, 1],\n         [1, 1, 0]],\n        \n        # 5. Weighted directed network\n        [[0, 2.0, 0, 1.5],\n         [0, 0, 0, 0],\n         [0.5, 0, 0, 1.0],\n         [0, 0.25, 1.0, 0]]\n    ]\n\n    results = []\n    d = 2 # Embedding dimension\n\n    for case_matrix in test_cases:\n        A = np.array(case_matrix, dtype=float)\n        \n        # Define the observed edge set as a boolean mask.\n        obs_mask = A > 0\n        num_obs_edges = np.sum(obs_mask)\n\n        # Handle the case of no observed edges.\n        if num_obs_edges == 0:\n            results.append(0.0)\n            continue\n            \n        # SVD is only needed if there are edges to reconstruct.\n        # Compute the SVD of the adjacency matrix.\n        # u: left-singular vectors, s: singular values, vh: right-singular vectors (transposed)\n        u, s, vh = np.linalg.svd(A)\n\n        # Truncate to dimension d.\n        # Pad singular values with zeros if rank(A)  d\n        s_d = np.zeros(d)\n        num_singular_values = len(s)\n        if num_singular_values > 0:\n            len_to_copy = min(d, num_singular_values)\n            s_d[:len_to_copy] = s[:len_to_copy]\n        \n        U_d = u[:, :d]\n        Vh_d = vh[:d, :]\n        V_d = Vh_d.T\n\n        # Construct embeddings X and Y based on the principled factorization.\n        s_d_sqrt = np.sqrt(s_d)\n        \n        # Broadcasting s_d_sqrt to the columns of U_d and V_d\n        X = U_d * s_d_sqrt \n        Y = V_d * s_d_sqrt\n        \n        # Compute the rank-d reconstructed adjacency matrix.\n        A_hat = X @ Y.T\n\n        # Calculate the mean squared error on observed edges.\n        squared_errors = (A[obs_mask] - A_hat[obs_mask])**2\n        mse_obs = np.mean(squared_errors)\n        \n        results.append(mse_obs)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "生成网络嵌入只是工作的一部分，评估其质量同样至关重要。本练习将介绍三种用于评估嵌入保真度的标准指标：应力（Stress）、相对失真（Relative Distortion）和链接预测的AUC。通过对给定的不同嵌入进行量化评估，您将学会如何衡量一个嵌入在保持全局结构（如长程距离）与局部结构（如直接邻居）之间的权衡，这是理解和选择合适嵌入方法的关键技能。",
            "id": "4290685",
            "problem": "给定同一个无向、无权图的两个低维嵌入。您的任务是计算三个指标，以评估每个嵌入在多大程度上保留了图的结构，然后在提供的测试套件上汇总结果。对于一个具有 $|V| = n$ 个节点和嵌入坐标 $\\{x_i \\in \\mathbb{R}^2\\}_{i=0}^{n-1}$ 的图 $G = (V, E)$，这三个指标定义如下：\n\n1. 图论最短路径距离：对于节点 $i, j \\in V$，令 $d_G(i,j)$ 表示 $G$ 中 $i$ 和 $j$ 之间最短路径的长度（跳数）。对于 $i = j$，定义 $d_G(i,i) = 0$。\n2. 嵌入中的欧几里得距离：对于节点 $i, j \\in V$，令 $d_E(i,j) = \\lVert x_i - x_j \\rVert_2$。\n3. 嵌入的应力（全局失真）：\n   $$S = \\sum_{0 \\le i  j \\le n-1} \\left( d_E(i,j) - d_G(i,j) \\right)^2.$$\n4. 相对失真（在所有图距离非零的节点对上的归一化绝对误差）：\n   $$R = \\frac{1}{|\\{(i,j) \\mid 0 \\le i  j \\le n-1, d_G(i,j)  0\\}|} \\sum_{\\substack{0 \\le i  j \\le n-1 \\\\ d_G(i,j)  0}} \\frac{\\left| d_E(i,j) - d_G(i,j) \\right|}{d_G(i,j)}.$$\n5. 链接预测的受试者工作特征曲线下面积（AUC）：将存在的边视为正例，不存在的边视为负例。使用得分 $s(i,j) = -d_E(i,j)$，这样较小的欧几里得距离意味着存在边的可能性更高。AUC 定义为随机选择的正例对的得分高于随机选择的负例对的得分的概率，平局的贡献为一半：\n   $$\\mathrm{AUC} = \\Pr\\left( s(i,j)  s(u,v) \\right) + \\frac{1}{2} \\Pr\\left( s(i,j) = s(u,v) \\right),$$\n   其中 $(i,j) \\in E$，$i  j$，并且 $(u,v)$ 是任何满足 $u  v$ 和 $(u,v) \\notin E$ 的无序对。\n\n您必须实现一个程序，为同一个图的两个嵌入中的每一个计算 $S$、$R$ 和 $\\mathrm{AUC}$，并对包含三个图的测试套件进行计算。所有距离都是无量纲的。用于坐标构建的角度必须以弧度为单位。最终输出必须是浮点数。AUC 中的平局必须通过在浮点数比较中使用一个小的容差进行精确相等性处理。\n\n使用的基本基础和定义：\n- 图 $G = (V,E)$ 是无向、无权且有限的。最短路径距离 $d_G(i,j)$ 通过广度优先搜索定义，并计算离散的跳数。\n- 欧几里得距离 $d_E(i,j)$ 是在 $\\mathbb{R}^2$ 中使用标准二范数计算的。\n- 应力 $S$ 和相对失真 $R$ 是对所有无序节点对的聚合，通过 $R$ 的条件 $d_G(i,j)  0$ 来禁止除以零。\n- 链接预测 AUC 是使用由 $s(i,j) = -d_E(i,j)$ 导出的排名来计算的。\n\n测试套件：\n- 测试用例 1（6 个节点的环形图）：\n  - 节点：$\\{0,1,2,3,4,5\\}$。\n  - 边：$(0,1)$, $(1,2)$, $(2,3)$, $(3,4)$, $(4,5)$, $(5,0)$。\n  - 嵌入 A（正六边形，半径为 1）：对于每个节点索引 $k \\in \\{0,1,2,3,4,5\\}$，\n    $$x_k = \\left( \\cos\\left( \\frac{2\\pi k}{6} \\right), \\sin\\left( \\frac{2\\pi k}{6} \\right) \\right).$$\n  - 嵌入 B（在一条线上等距分布）：对于每个节点索引 $k \\in \\{0,1,2,3,4,5\\}$，\n    $$x_k = (k, 0).$$\n- 测试用例 2（5 个节点的星形图）：\n  - 节点：$\\{0,1,2,3,4\\}$。\n  - 边：$(0,1)$, $(0,2)$, $(0,3)$, $(0,4)$。\n  - 嵌入 A（中心在原点，叶节点在单位圆坐标轴点上）：\n    $$x_0 = (0,0), \\quad x_1 = (1,0), \\quad x_2 = (0,1), \\quad x_3 = (-1,0), \\quad x_4 = (0,-1).$$\n  - 嵌入 B（方向相同，半径为 0.3）：\n    $$x_0 = (0,0), \\quad x_1 = (0.3,0), \\quad x_2 = (0,0.3), \\quad x_3 = (-0.3,0), \\quad x_4 = (0,-0.3).$$\n- 测试用例 3（4 个节点的路径图）：\n  - 节点：$\\{0,1,2,3\\}$。\n  - 边：$(0,1)$, $(1,2)$, $(2,3)$。\n  - 嵌入 A（在一条线上单位间距）：\n    $$x_k = (k,0), \\quad k \\in \\{0,1,2,3\\}.$$\n  - 嵌入 B（在一条线上双倍间距）：\n    $$x_k = (2k,0), \\quad k \\in \\{0,1,2,3\\}.$$\n\n程序要求：\n- 通过对每个源节点进行广度优先搜索来计算 $d_G(i,j)$。\n- 通过所提供嵌入的欧几里得距离来计算 $d_E(i,j)$。\n- 按照上述定义计算 $S$、$R$ 和 $\\mathrm{AUC}$。\n- 对于 AUC，将满足 $|s(i,j) - s(u,v)| \\le \\varepsilon$ 的平局视为精确平局，其中 $\\varepsilon = 10^{-12}$。\n- 输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按 $[S_A, R_A, \\mathrm{AUC}_A, S_B, R_B, \\mathrm{AUC}_B]$ 的顺序输出六个浮点数，其中 A 和 B 表示两种嵌入。将所有三个测试用例的结果连接成一个扁平列表。每个浮点数必须四舍五入到 6 位小数。\n\n科学真实性和解释要求：\n- 环形图测试了在全局保留测地环距离与线性排序之间的权衡。星形图测试了中心-叶节点距离的局部保真度与叶节点的相对位置。路径图测试了 AUC 在单调变换下的尺度不变性，及其与应力和相对失真的区别。\n- 不涉及物理单位；所有距离都是无量纲的。角度以弧度为单位。\n\n您的程序必须实现这些计算，并以所描述的精确格式生成最终输出行。",
            "solution": "问题陈述已经过严格验证，并被确定为有效。它具有科学依据，问题提出得当，并且没有矛盾或含糊之处。该问题是网络科学领域中一个明确定义的计算任务，具体涉及网络嵌入的评估。因此，我们可以着手解决。\n\n任务是为三种不同图的两种不同嵌入计算三个质量指标——应力（$S$）、相对失真（$R$）和链接预测的曲线下面积（$\\mathrm{AUC}$）。该解决方案将构建为一个算法，系统地处理每个测试用例。对于每个图及其两种嵌入中的每一种，该算法将执行一系列步骤来计算所需的指标。\n\n首先，我们必须计算构成所有指标基础的两个距离矩阵：图论最短路径距离矩阵 $d_G$ 和嵌入空间中的欧几里得距离矩阵 $d_E$。\n\n**1. 图论距离（$d_G$）的计算**\n\n对于一个给定的具有 $n=|V|$ 个节点的图 $G=(V,E)$，距离 $d_G(i,j)$ 是节点 $i$ 和 $j$ 之间最短路径上的边数。由于图是无权的，可以通过从每个节点开始执行广度优先搜索（BFS）算法来高效地为所有节点对计算这个距离。一个更稳健和高效的方法是构建一个 $n \\times n$ 的邻接矩阵 $A$，其中如果 $(i,j) \\in E$ 则 $A_{ij}=1$，否则 $A_{ij}=0$。然后可以将 `scipy.sparse.csgraph.shortest_path` 函数应用于此矩阵，并使用 `unweighted=True` 和 `directed=False` 选项，以产生完整的 $n \\times n$ 最短路径距离矩阵，我们将其表示为 $d_G$。对于任何节点 $i$，$d_G(i, i) = 0$。\n\n**2. 欧几里得距离（$d_E$）的计算**\n\n对于一个给定的嵌入，提供了一组坐标 $\\{x_k \\in \\mathbb{R}^2\\}_{k=0}^{n-1}$。节点 $i$ 和 $j$ 的嵌入之间的欧几里得距离 $d_E(i,j)$ 由 $L_2$-范数定义：\n$$d_E(i,j) = \\lVert x_i - x_j \\rVert_2 = \\sqrt{(x_{i,1} - x_{j,1})^2 + (x_{i,2} - x_{j,2})^2}.$$\n对所有对 $(i,j)$ 执行此计算，以生成一个 $n \\times n$ 的欧几里得距离矩阵 $d_E$。这可以通过使用 `numpy` 中的向量化操作来高效实现，即计算所有坐标向量之间的成对差异。\n\n**3. 评估指标的计算**\n\n有了距离矩阵 $d_G$ 和 $d_E$ 后，我们就可以计算这三个指标。\n\n**应力（$S$）**：应力是所有唯一节点对的欧几里得距离与图论距离之差的平方和。\n$$S = \\sum_{0 \\le i  j \\le n-1} \\left( d_E(i,j) - d_G(i,j) \\right)^2.$$\n计算方法是取矩阵 $(d_E - d_G)$ 的上三角部分（不包括对角线），将每个元素平方，然后求和。\n\n**相对失真（$R$）**：相对失真是两种距离之差的绝对值（由图论距离归一化）的平均值。求和仅在图论距离非零的节点对上进行，以避免除以零。\n$$R = \\frac{1}{|\\{(i,j) \\mid 0 \\le i  j \\le n-1, d_G(i,j)  0\\}|} \\sum_{\\substack{0 \\le i  j \\le n-1 \\\\ d_G(i,j)  0}} \\frac{\\left| d_E(i,j) - d_G(i,j) \\right|}{d_G(i,j)}.$$\n实现方式是遍历唯一的节点对 $(i,j)$，对于每个满足 $d_G(i,j)  0$ 的对，我们计算该项并将其加到一个运行总和中。然后将最终总和除以这类对的数量。\n\n**链接预测 AUC（$\\mathrm{AUC}$）**：该指标评估嵌入区分由边连接的节点对（正例）和未连接的节点对（负例）的能力。为每对节点分配一个得分 $s(i,j) = -d_E(i,j)$，这反映了较小的欧几里得距离意味着存在边的可能性更高的假设。$\\mathrm{AUC}$ 是随机选择的正例对得分高于随机选择的负例对得分的概率。\n为了计算它，我们首先将所有满足 $ij$ 的节点对分为正例（存在边）和负例（不存在边）。然后，我们比较每个正例得分与每个负例得分。我们计算正例得分严格大于负例得分的次数，以及它们近似相等的次数（在 $\\varepsilon = 10^{-12}$ 的容差内）。$\\mathrm{AUC}$ 的计算公式为：\n$$\\mathrm{AUC} = \\frac{(\\text{正例得分更高的次数}) + 0.5 \\times (\\text{得分相等的次数})}{(\\text{正例总数}) \\times (\\text{负例总数})}.$$\n如果不存在正例或负例，$\\mathrm{AUC}$ 通常定义为 $0.5$，表示随机猜测的性能。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import csgraph\n\ndef solve():\n    \"\"\"\n    Computes and prints the embedding evaluation metrics for the given test suite.\n    \"\"\"\n    \n    # Test cases defined as (num_nodes, edges, embedding_A_def, embedding_B_def)\n    # where embedding_def is a lambda function that returns coordinates.\n    test_cases = [\n        (\n            6, # n_nodes\n            [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 0)], # edges\n            lambda: np.array([(np.cos(2 * np.pi * k / 6), np.sin(2 * np.pi * k / 6)) for k in range(6)]), # emb_A\n            lambda: np.array([(float(k), 0.0) for k in range(6)]) # emb_B\n        ),\n        (\n            5, # n_nodes\n            [(0, 1), (0, 2), (0, 3), (0, 4)], # edges\n            lambda: np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [-1.0, 0.0], [0.0, -1.0]]), # emb_A\n            lambda: np.array([[0.0, 0.0], [0.3, 0.0], [0.0, 0.3], [-0.3, 0.0], [0.0, -0.3]]) # emb_B\n        ),\n        (\n            4, # n_nodes\n            [(0, 1), (1, 2), (2, 3)], # edges\n            lambda: np.array([(float(k), 0.0) for k in range(4)]), # emb_A\n            lambda: np.array([(2.0 * k, 0.0) for k in range(4)]) # emb_B\n        )\n    ]\n\n    all_results = []\n    \n    # Epsilon for AUC tie handling\n    epsilon = 1e-12\n\n    for n_nodes, edges, emb_A_func, emb_B_func in test_cases:\n        # 1. Compute graph-theoretic distance matrix d_G\n        adj_matrix = np.zeros((n_nodes, n_nodes))\n        for i, j in edges:\n            adj_matrix[i, j] = adj_matrix[j, i] = 1\n        \n        d_G = csgraph.shortest_path(csgraph=adj_matrix, directed=False, unweighted=True)\n        # Ensure diagonal is zero, although shortest_path should handle this\n        np.fill_diagonal(d_G, 0)\n        \n        # Get upper triangle indices for pair-wise calculations\n        triu_indices = np.triu_indices(n_nodes, k=1)\n\n        for emb_func in [emb_A_func, emb_B_func]:\n            coords = emb_func()\n            \n            # 2. Compute Euclidean distance matrix d_E\n            # Using broadcasting for efficiency: diffs[i, j, k] = coords[i, k] - coords[j, k]\n            diffs = coords[:, np.newaxis, :] - coords[np.newaxis, :, :]\n            d_E = np.sqrt(np.sum(diffs**2, axis=-1))\n\n            d_G_flat = d_G[triu_indices]\n            d_E_flat = d_E[triu_indices]\n\n            # 3. Compute Stress (S)\n            stress = np.sum((d_E_flat - d_G_flat)**2)\n\n            # 4. Compute Relative Distortion (R)\n            nonzero_graph_dist_mask = d_G_flat > 0\n            if np.any(nonzero_graph_dist_mask):\n                relative_errors = np.abs(d_E_flat[nonzero_graph_dist_mask] - d_G_flat[nonzero_graph_dist_mask]) / d_G_flat[nonzero_graph_dist_mask]\n                relative_distortion = np.mean(relative_errors)\n            else:\n                relative_distortion = 0.0\n\n            # 5. Compute Link Prediction AUC\n            pos_scores = []\n            neg_scores = []\n            for i in range(n_nodes):\n                for j in range(i + 1, n_nodes):\n                    score = -d_E[i, j]\n                    if adj_matrix[i, j] == 1:\n                        pos_scores.append(score)\n                    else:\n                        neg_scores.append(score)\n\n            if not pos_scores or not neg_scores:\n                auc = 0.5  # Default if no positives or no negatives\n            else:\n                n_greater = 0\n                n_equal = 0\n                for p_score in pos_scores:\n                    for n_score in neg_scores:\n                        if p_score > n_score + epsilon:\n                            n_greater += 1\n                        elif abs(p_score - n_score) = epsilon:\n                            n_equal += 1\n                \n                total_comparisons = len(pos_scores) * len(neg_scores)\n                auc = (n_greater + 0.5 * n_equal) / total_comparisons\n\n            all_results.extend([stress, relative_distortion, auc])\n\n    # Final print statement in the exact required format.\n    # Each float is rounded to 6 decimal places.\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}