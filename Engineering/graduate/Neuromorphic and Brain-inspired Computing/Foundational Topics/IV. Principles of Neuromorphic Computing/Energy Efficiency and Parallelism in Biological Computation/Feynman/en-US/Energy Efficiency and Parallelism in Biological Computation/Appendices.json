{
    "hands_on_practices": [
        {
            "introduction": "The brain is an incredibly energy-efficient computer, but even it must obey the fundamental laws of physics. This exercise explores the ultimate thermodynamic limit of computation by focusing on a simple, yet profound operation: erasing one bit of information. By applying the Second Law of Thermodynamics and the statistical definition of entropy, you will derive Landauer's principle, which establishes the minimum heat that must be dissipated to reset a bit . This foundational practice reveals the deep connection between information, entropy, and energy, providing a theoretical baseline against which all computational systems, biological or artificial, can be measured.",
            "id": "4042953",
            "problem": "Consider a nanoscale bistable molecular switch in a neuronal microdomain that encodes one logical bit. The switch is in contact with a large cytosolic environment modeled as an isothermal heat bath at temperature $T$, and the two logical states are encoded by two metastable macrostates with equal prior probabilities and negligible energy difference. A logical erasure operation deterministically resets the switch to one standard state regardless of its initial state. Starting only from the Second Law of Thermodynamics in the Clausius form and the statistical definition of entropy, derive an analytic expression for the minimum average heat that must be dissipated into the environment by such an erasure when the control protocol is quasistatic. Clearly articulate each physical assumption used in the derivation. Then evaluate the derived expression for $T=310\\,\\text{K}$ (typical mammalian physiological temperature). Use $k_{\\mathrm{B}}=1.380\\,649\\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}$ and round your final numerical answer to four significant figures. Express the final energy in $\\text{J}$.",
            "solution": "The problem statement has been analyzed and is deemed valid. It is a well-posed problem in statistical thermodynamics applied to the physics of information, commonly known as Landauer's principle. The problem provides a clear objective, sufficient data, and is grounded in established scientific principles.\n\nThe task is to derive the minimum average heat dissipated during the erasure of one bit of information. This corresponds to a thermodynamically reversible, quasistatic process. We begin with the statistical definition of entropy and the Second Law of Thermodynamics.\n\nLet the system be the bistable molecular switch, which can exist in two logical states, '0' and '1'. The environment is a heat bath at a constant temperature $T$.\n\nFirst, we define the initial state of the system before erasure. The problem states that the two logical states have equal prior probabilities. Let $p_0$ and $p_1$ be the probabilities of the switch being in state '0' and state '1', respectively.\n$$ p_0 = \\frac{1}{2}, \\quad p_1 = \\frac{1}{2} $$\nThe statistical entropy of the system, according to the Boltzmann-Gibbs formula, is given by $S = -k_{\\mathrm{B}} \\sum_i p_i \\ln(p_i)$, where $k_{\\mathrm{B}}$ is the Boltzmann constant and the sum is over all accessible microstates. The initial entropy, $S_{initial}$, is therefore:\n$$ S_{initial} = -k_{\\mathrm{B}} \\left( p_0 \\ln(p_0) + p_1 \\ln(p_1) \\right) $$\n$$ S_{initial} = -k_{\\mathrm{B}} \\left( \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) + \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) \\right) = -k_{\\mathrm{B}} \\ln\\left(\\frac{1}{2}\\right) = k_{\\mathrm{B}} \\ln(2) $$\nThis initial state represents maximum uncertainty for a binary system.\n\nNext, we define the final state after the erasure operation. The erasure deterministically resets the switch to a single standard state, say state '0', regardless of its initial state. The probabilities for the final state are:\n$$ p'_0 = 1, \\quad p'_1 = 0 $$\nThe final entropy of the system, $S_{final}$, is:\n$$ S_{final} = -k_{\\mathrm{B}} \\left( p'_0 \\ln(p'_0) + p'_1 \\ln(p'_1) \\right) $$\nUsing the fact that $\\lim_{x\\to 0} x \\ln(x) = 0$, we have:\n$$ S_{final} = -k_{\\mathrm{B}} \\left( 1 \\ln(1) + 0 \\right) = 0 $$\nThis final state represents complete certainty.\n\nThe change in the entropy of the system (the switch) is:\n$$ \\Delta S_{system} = S_{final} - S_{initial} = 0 - k_{\\mathrm{B}} \\ln(2) = -k_{\\mathrm{B}} \\ln(2) $$\nThe entropy of the system decreases because information has been erased, reducing the phase space volume accessible to the system from two states to one.\n\nAccording to the Second Law of Thermodynamics, the total change in entropy of the universe (system + environment) must be greater than or equal to zero for any process:\n$$ \\Delta S_{total} = \\Delta S_{system} + \\Delta S_{environment} \\ge 0 $$\nTo find the minimum heat dissipated, we consider the limiting case of a thermodynamically reversible (quasistatic) process, for which the total entropy change is zero:\n$$ \\Delta S_{total} = \\Delta S_{system} + \\Delta S_{environment} = 0 $$\nThis implies that the change in the entropy of the environment must compensate for the change in the entropy of the system:\n$$ \\Delta S_{environment} = - \\Delta S_{system} = -(-k_{\\mathrm{B}} \\ln(2)) = k_{\\mathrm{B}} \\ln(2) $$\nThe environment is an isothermal heat bath at temperature $T$. From the Clausius form of the Second Law, the change in entropy of the heat bath is related to the heat $Q$ it absorbs by $\\Delta S_{environment} = \\frac{Q}{T}$. Here, $Q$ is the heat dissipated from the switch into the environment. The minimum heat dissipated, $Q_{min}$, corresponds to the reversible process.\n$$ \\Delta S_{environment} = \\frac{Q_{min}}{T} $$\nEquating the two expressions for $\\Delta S_{environment}$:\n$$ \\frac{Q_{min}}{T} = k_{\\mathrm{B}} \\ln(2) $$\nSolving for $Q_{min}$, we obtain the analytic expression for the minimum average heat dissipated:\n$$ Q_{min} = k_{\\mathrm{B}} T \\ln(2) $$\nThis result is known as the Landauer limit. The problem also states that the energy difference between the two states is negligible. This is an important assumption, as it implies the change in the system's internal energy $\\Delta U_{system}$ is zero. From the First Law of Thermodynamics, $\\Delta U_{system} = Q_{in} + W_{on}$, where $Q_{in}$ is heat transferred to the system and $W_{on}$ is work done on the system. With $\\Delta U_{system} = 0$, we have $W_{on} = -Q_{in} = Q_{out}$, where $Q_{out}$ is the heat dissipated to the environment. The work done on the system to compress its phase space is entirely converted into dissipated heat.\n\nThe key physical assumptions used in this derivation are:\n1. The system's entropy is described by the statistical (Gibbs) entropy formula.\n2. The erasure process is performed quasistatically, corresponding to a thermodynamically reversible transformation, which yields the minimum possible heat dissipation.\n3. The environment acts as an ideal isothermal heat bath at a constant temperature $T$.\n4. The two logical states of the switch are initially equally probable, representing one bit of information.\n5. The energy difference between the two logical states is negligible ($\\Delta U_{system}=0$).\n\nWe now evaluate this expression for the given values:\n$T = 310\\,\\text{K}$\n$k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}$\n\n$$ Q_{min} = (1.380649 \\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}) \\times (310\\,\\text{K}) \\times \\ln(2) $$\n$$ Q_{min} \\approx (4.2799119 \\times 10^{-21}\\,\\text{J}) \\times (0.69314718...) $$\n$$ Q_{min} \\approx 2.966531 \\times 10^{-21}\\,\\text{J} $$\nRounding the result to four significant figures, as requested:\n$$ Q_{min} \\approx 2.967 \\times 10^{-21}\\,\\text{J} $$",
            "answer": "$$\\boxed{2.967 \\times 10^{-21}}$$"
        },
        {
            "introduction": "Moving from abstract principles to biological reality, we now examine the metabolic engine of a single neuron. The constant activity of ion pumps, fueled by adenosine triphosphate (ATP), constitutes a major part of the brain's energy budget. This practice connects the microscopic world of molecular reactions to the macroscopic world of thermodynamics by asking you to calculate the rate of heat production from ATP hydrolysis in a neuron . By applying the First Law of Thermodynamics, you will quantify a neuron's thermal footprint, grounding the concept of energy consumption in the primary currency of cellular metabolism.",
            "id": "4042918",
            "problem": "A cortical pyramidal neuron at temperature $T$ and approximately constant ambient pressure $p$ operates in steady state while engaging in massively parallel ionic signaling, where numerous adenosine triphosphate (ATP) hydrolysis events support ion pumping and synaptic transmission. From the First Law of Thermodynamics for an open, reactive system and the definition of enthalpy, at constant pressure the enthalpy change associated with a chemical reaction equals the heat exchanged with the environment, up to non-pressure–volume work. In a neuron, mechanical pressure–volume work is negligible and any non-pressure–volume work performed by adenosine triphosphate hydrolysis (e.g., moving ions across membranes) ultimately dissipates as heat in steady state. Hence, the rate of heat release from ATP turnover equals the rate at which reaction enthalpy is produced.\n\nAssume the neuron hydrolyzes ATP to adenosine diphosphate (ADP) and inorganic phosphate with a total consumption rate $\\nu_{\\text{ATP}}$ (molecules per second), and the molar enthalpy change of ATP hydrolysis under cytosolic conditions is $\\Delta H_{\\text{ATP}}$ (joules per mole), with $\\Delta H_{\\text{ATP}} &lt; 0$ for an exothermic reaction. Derive, from first principles, an expression for the rate of heat production $\\dot{Q}$ in terms of $\\nu_{\\text{ATP}}$, $\\Delta H_{\\text{ATP}}$, and the Avogadro constant $N_{\\mathrm{A}}$, and then compute its numerical value for the following measured parameters:\n$$\\nu_{\\text{ATP}} = 1.2 \\times 10^{9} \\ \\text{s}^{-1}, \\quad \\Delta H_{\\text{ATP}} = -25 \\times 10^{3} \\ \\text{J mol}^{-1}, \\quad N_{\\mathrm{A}} = 6.02214076 \\times 10^{23} \\ \\text{mol}^{-1}.$$\nExpress the final result as the positive rate of heat release to the environment in watts (W). Round your answer to three significant figures.",
            "solution": "The problem asks for a derivation of the rate of heat production, $\\dot{Q}$, by a neuron due to ATP hydrolysis, and for the calculation of its numerical value given a set of parameters.\n\nThe problem statement has been validated and is found to be scientifically grounded, well-posed, and objective. It is based on fundamental principles of thermodynamics as applied to cellular bioenergetics. The assumptions provided—steady state, negligible pressure-volume work, and the ultimate dissipation of all non-PV work as heat—are standard and appropriate for modeling the energy budget of a neuron. All necessary variables and constants are provided, and their values are physically realistic. The problem is therefore deemed valid and a solution will be constructed.\n\nAccording to the First Law of Thermodynamics, for a process occurring at constant pressure, the change in enthalpy, $\\Delta H$, is equal to the heat exchanged with the surroundings, $q_p$, plus any non-pressure-volume work, $w_{\\text{non-PV}}$, done by the system.\n$$ \\Delta H = q_p + w_{\\text{non-PV}} $$\nIn the context of the neuron, the problem specifies that in the steady state, any non-pressure-volume work performed by ATP hydrolysis (such as ion transport) ultimately dissipates as heat. This means that the work energy is returned to the system as thermal energy and then released to the environment. Consequently, the total rate of heat release to the environment, $\\dot{Q}$, must equal the rate at which enthalpy is changed by the chemical reaction of ATP hydrolysis.\n\nLet's define the quantities involved:\n- $\\nu_{\\text{ATP}}$ is the rate of ATP consumption in molecules per unit time, with units of $\\text{s}^{-1}$.\n- $\\Delta H_{\\text{ATP}}$ is the molar enthalpy change of ATP hydrolysis, with units of $\\text{J mol}^{-1}$. This value is negative for an exothermic reaction, indicating release of energy from the chemical bonds.\n- $N_{\\mathrm{A}}$ is the Avogadro constant, the number of constituent particles (molecules, in this case) per mole, with units of $\\text{mol}^{-1}$.\n\nFirst, we convert the molecular consumption rate, $\\nu_{\\text{ATP}}$, into a molar consumption rate, which we can denote as $\\dot{n}_{\\text{ATP}}$. This is achieved by dividing the number of molecules consumed per second by the number of molecules in a mole:\n$$ \\dot{n}_{\\text{ATP}} = \\frac{\\nu_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\nThe units of this expression are $(\\text{s}^{-1}) / (\\text{mol}^{-1}) = \\text{mol s}^{-1}$, which is the correct unit for a molar rate.\n\nThe total rate of enthalpy change for the system is the product of the molar rate of reaction and the molar enthalpy change of the reaction:\n$$ \\text{Rate of Enthalpy Change} = \\dot{n}_{\\text{ATP}} \\cdot \\Delta H_{\\text{ATP}} = \\frac{\\nu_{\\text{ATP}} \\Delta H_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\nThe units of this expression are $(\\text{mol s}^{-1}) \\cdot (\\text{J mol}^{-1}) = \\text{J s}^{-1}$. A rate of energy change of a joule per second is a watt ($1 \\ \\text{W} = 1 \\ \\text{J s}^{-1}$).\n\nThe problem asks for the rate of heat production, $\\dot{Q}$, defined as the positive rate of heat released *to* the environment. Since $\\Delta H_{\\text{ATP}} < 0$ for this exothermic reaction, the rate of enthalpy change of the system is negative, signifying an energy decrease within the system. This decrease in the system's enthalpy corresponds to an equivalent amount of heat released to the surroundings. Therefore, the rate of heat release is the negative of the rate of the system's enthalpy change:\n$$ \\dot{Q} = -(\\text{Rate of Enthalpy Change}) $$\nSubstituting the expression derived above, we obtain the final symbolic expression for the rate of heat production:\n$$ \\dot{Q} = -\\frac{\\nu_{\\text{ATP}} \\Delta H_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\n\nNow, we can compute the numerical value using the provided parameters:\n$$ \\nu_{\\text{ATP}} = 1.2 \\times 10^{9} \\ \\text{s}^{-1} $$\n$$ \\Delta H_{\\text{ATP}} = -25 \\times 10^{3} \\ \\text{J mol}^{-1} $$\n$$ N_{\\mathrm{A}} = 6.02214076 \\times 10^{23} \\ \\text{mol}^{-1} $$\n\nSubstituting these values into the derived expression for $\\dot{Q}$:\n$$ \\dot{Q} = -\\frac{(1.2 \\times 10^{9} \\ \\text{s}^{-1}) \\times (-25 \\times 10^{3} \\ \\text{J mol}^{-1})}{6.02214076 \\times 10^{23} \\ \\text{mol}^{-1}} $$\nThe two negative signs cancel, resulting in a positive value for heat release, as expected.\n$$ \\dot{Q} = \\frac{(1.2 \\times 25) \\times (10^{9} \\times 10^{3})}{6.02214076 \\times 10^{23}} \\ \\text{J s}^{-1} $$\n$$ \\dot{Q} = \\frac{30 \\times 10^{12}}{6.02214076 \\times 10^{23}} \\ \\text{W} $$\n$$ \\dot{Q} = \\frac{3.0 \\times 10^{13}}{6.02214076 \\times 10^{23}} \\ \\text{W} $$\n$$ \\dot{Q} \\approx 0.4981596 \\times 10^{-10} \\ \\text{W} $$\nTo express this in standard scientific notation, we adjust the decimal point:\n$$ \\dot{Q} \\approx 4.981596 \\times 10^{-11} \\ \\text{W} $$\nThe problem requires the answer to be rounded to three significant figures. The first three significant figures are $4$, $9$, and $8$. The fourth significant figure is $1$, which is less than $5$, so we round down (i.e., we truncate).\n$$ \\dot{Q} \\approx 4.98 \\times 10^{-11} \\ \\text{W} $$\nThis is the rate of heat release from the single neuron under the specified conditions.",
            "answer": "$$\\boxed{4.98 \\times 10^{-11}}$$"
        },
        {
            "introduction": "Energy in the brain is not spent without purpose; it is invested to achieve computational goals like speed and precision. This exercise delves into the crucial trade-off between energy expenditure and informational fidelity in a neural code. You will analyze a model where a neuron improves the precision of its spike timing—and thus the information it transmits—by increasing its density of ion channels, an investment that carries a metabolic cost . This practice challenges you to quantify the \"return on investment\" by calculating the marginal gain in mutual information per joule, providing a concrete example of the optimization problems the nervous system constantly solves.",
            "id": "4042888",
            "problem": "A single-compartment neuron uses a spike-timing code within a fixed window to represent a scalar stimulus. Let the intended spike time be a random variable $X$ uniformly distributed on the interval $[0, T]$, with $T = 20\\,\\mathrm{ms}$. Due to stochastic ion-channel gating, the observed spike time is $Y = X + N$, where $N$ is independent, additive, zero-mean Gaussian timing noise with variance $\\sigma^{2}(N)$ that depends on the total number of statistically independent effective ion channels $N$. Assume that averaging over independent channels reduces timing variability according to $\\sigma(N) = \\sigma_{\\mathrm{ref}}\\sqrt{N_{\\mathrm{ref}}/N}$, where $\\sigma_{\\mathrm{ref}} = 0.8\\,\\mathrm{ms}$ at $N_{\\mathrm{ref}} = 5.0 \\times 10^{5}$. The energy per spike is modeled as $E(N) = E_{0} + \\epsilon_{c} N$, with $E_{0} = 2.0 \\times 10^{-10}\\,\\mathrm{J}$ and $\\epsilon_{c} = 2.0 \\times 10^{-16}\\,\\mathrm{J}$.\n\nYou may assume that boundary effects from the finite coding window are negligible (i.e., $\\sigma(N) \\ll T$) and that the mutual information between $X$ and $Y$ for this additive noise model is well approximated by the standard additive white Gaussian noise expression in terms of the signal-to-noise ratio defined by $\\mathrm{SNR} = \\mathrm{Var}(X)/\\mathrm{Var}(N)$, with $\\mathrm{Var}(X) = T^{2}/12$ and $\\mathrm{Var}(N) = \\sigma^{2}(N)$.\n\nConsider increasing channel density from $N_{0} = 5.0 \\times 10^{5}$ to $2N_{0}$. Compute the marginal information gain per added Joule,\n$$\n\\eta \\equiv \\frac{I(2N_{0}) - I(N_{0})}{E(2N_{0}) - E(N_{0})},\n$$\nwhere $I(N)$ is the mutual information in bits per spike under the above approximation. Express your final answer in $\\mathrm{bits}/\\mathrm{J}$ and round to four significant figures.",
            "solution": "The problem as stated is scientifically sound, internally consistent, and well-posed. All required parameters and models are provided, and the assumptions are clearly stated and physically plausible within the context of the problem. Therefore, the problem is deemed valid and a full solution can be constructed.\n\nThe objective is to compute the marginal information gain per added Joule, $\\eta$, defined as:\n$$\n\\eta \\equiv \\frac{I(2N_{0}) - I(N_{0})}{E(2N_{0}) - E(N_{0})}\n$$\nWe will compute the denominator (change in energy) and the numerator (change in information) separately.\n\nFirst, we calculate the change in energy, $\\Delta E = E(2N_{0}) - E(N_{0})$. The energy per spike is given by the model $E(N) = E_{0} + \\epsilon_{c} N$.\nThe energy at the initial channel density $N_0$ is $E(N_{0}) = E_{0} + \\epsilon_{c} N_{0}$.\nThe energy at the doubled channel density $2N_0$ is $E(2N_{0}) = E_{0} + \\epsilon_{c} (2N_{0})$.\nThe change in energy is therefore:\n$$\n\\Delta E = E(2N_{0}) - E(N_{0}) = (E_{0} + 2\\epsilon_{c}N_{0}) - (E_{0} + \\epsilon_{c}N_{0}) = \\epsilon_{c}N_{0}\n$$\nSubstituting the given values $N_{0} = 5.0 \\times 10^{5}$ and $\\epsilon_{c} = 2.0 \\times 10^{-16}\\,\\mathrm{J}$:\n$$\n\\Delta E = (2.0 \\times 10^{-16}\\,\\mathrm{J}) \\times (5.0 \\times 10^{5}) = 10.0 \\times 10^{-11}\\,\\mathrm{J} = 1.0 \\times 10^{-10}\\,\\mathrm{J}\n$$\n\nNext, we calculate the change in mutual information, $\\Delta I = I(2N_{0}) - I(N_{0})$. The problem specifies using the approximation for an additive white Gaussian noise channel, where the mutual information $I(N)$ in bits is given by:\n$$\nI(N) = \\frac{1}{2}\\log_{2}(1 + \\mathrm{SNR}(N))\n$$\nThe signal-to-noise ratio, $\\mathrm{SNR}(N)$, is defined as the ratio of signal variance to noise variance:\n$$\n\\mathrm{SNR}(N) = \\frac{\\mathrm{Var}(X)}{\\mathrm{Var}(N)} = \\frac{\\mathrm{Var}(X)}{\\sigma^{2}(N)}\n$$\nThe signal $X$ is uniformly distributed on $[0, T]$, so its variance is $\\mathrm{Var}(X) = \\frac{(T-0)^{2}}{12} = \\frac{T^{2}}{12}$.\nThe noise standard deviation $\\sigma(N)$ is given by $\\sigma(N) = \\sigma_{\\mathrm{ref}}\\sqrt{N_{\\mathrm{ref}}/N}$. The noise variance is $\\sigma^{2}(N) = \\sigma_{\\mathrm{ref}}^{2} \\frac{N_{\\mathrm{ref}}}{N}$.\n\nWe first evaluate the SNR at the initial channel density $N_{0}$. Given that $N_{0} = N_{\\mathrm{ref}} = 5.0 \\times 10^{5}$:\n$$\n\\sigma^{2}(N_{0}) = \\sigma_{\\mathrm{ref}}^{2} \\frac{N_{\\mathrm{ref}}}{N_{0}} = \\sigma_{\\mathrm{ref}}^{2}\n$$\nSo, the initial SNR, which we denote as $\\mathrm{SNR}_{0}$, is:\n$$\n\\mathrm{SNR}_{0} = \\mathrm{SNR}(N_{0}) = \\frac{T^{2}/12}{\\sigma_{\\mathrm{ref}}^{2}} = \\frac{T^{2}}{12\\sigma_{\\mathrm{ref}}^{2}}\n$$\nNow, we evaluate the SNR at the doubled channel density, $2N_{0}$. The noise variance is:\n$$\n\\sigma^{2}(2N_{0}) = \\sigma_{\\mathrm{ref}}^{2} \\frac{N_{\\mathrm{ref}}}{2N_{0}} = \\sigma_{\\mathrm{ref}}^{2} \\frac{1}{2} = \\frac{\\sigma^{2}(N_{0})}{2}\n$$\nThus, the new SNR is:\n$$\n\\mathrm{SNR}(2N_{0}) = \\frac{\\mathrm{Var}(X)}{\\sigma^{2}(2N_{0})} = \\frac{\\mathrm{Var}(X)}{\\sigma^{2}(N_{0})/2} = 2 \\frac{\\mathrm{Var}(X)}{\\sigma^{2}(N_{0})} = 2\\mathrm{SNR}_{0}\n$$\nThe change in mutual information is:\n$$\n\\Delta I = I(2N_{0}) - I(N_{0}) = \\frac{1}{2}\\log_{2}(1 + \\mathrm{SNR}(2N_{0})) - \\frac{1}{2}\\log_{2}(1 + \\mathrm{SNR}(N_{0}))\n$$\n$$\n\\Delta I = \\frac{1}{2}\\left[\\log_{2}(1 + 2\\mathrm{SNR}_{0}) - \\log_{2}(1 + \\mathrm{SNR}_{0})\\right] = \\frac{1}{2}\\log_{2}\\left(\\frac{1 + 2\\mathrm{SNR}_{0}}{1 + \\mathrm{SNR}_{0}}\\right)\n$$\nNow we can compute the numerical value of $\\mathrm{SNR}_{0}$. We have $T = 20\\,\\mathrm{ms} = 2.0 \\times 10^{-2}\\,\\mathrm{s}$ and $\\sigma_{\\mathrm{ref}} = 0.8\\,\\mathrm{ms} = 8.0 \\times 10^{-4}\\,\\mathrm{s}$.\n$$\n\\mathrm{SNR}_{0} = \\frac{(2.0 \\times 10^{-2}\\,\\mathrm{s})^{2}}{12 \\times (8.0 \\times 10^{-4}\\,\\mathrm{s})^{2}} = \\frac{4.0 \\times 10^{-4}}{12 \\times 64 \\times 10^{-8}} = \\frac{4.0 \\times 10^{4}}{12 \\times 64} = \\frac{10000}{192} = \\frac{625}{12}\n$$\nSubstituting this into the expression for $\\Delta I$:\n$$\n\\Delta I = \\frac{1}{2}\\log_{2}\\left(\\frac{1 + 2 \\times \\frac{625}{12}}{1 + \\frac{625}{12}}\\right) = \\frac{1}{2}\\log_{2}\\left(\\frac{1 + \\frac{625}{6}}{1 + \\frac{625}{12}}\\right) = \\frac{1}{2}\\log_{2}\\left(\\frac{\\frac{6+625}{6}}{\\frac{12+625}{12}}\\right) = \\frac{1}{2}\\log_{2}\\left(\\frac{\\frac{631}{6}}{\\frac{637}{12}}\\right)\n$$\n$$\n\\Delta I = \\frac{1}{2}\\log_{2}\\left(\\frac{631}{6} \\times \\frac{12}{637}\\right) = \\frac{1}{2}\\log_{2}\\left(\\frac{2 \\times 631}{637}\\right) = \\frac{1}{2}\\log_{2}\\left(\\frac{1262}{637}\\right)\n$$\nUsing the change of base formula $\\log_{2}(x) = \\frac{\\ln(x)}{\\ln(2)}$:\n$$\n\\Delta I = \\frac{1}{2} \\frac{\\ln(1262/637)}{\\ln(2)} \\approx \\frac{1}{2} \\frac{\\ln(1.98116)}{0.69315} \\approx \\frac{0.68368}{2 \\times 0.69315} \\approx 0.49317\\,\\mathrm{bits}\n$$\nFinally, we compute $\\eta$ by dividing $\\Delta I$ by $\\Delta E$:\n$$\n\\eta = \\frac{\\Delta I}{\\Delta E} \\approx \\frac{0.49317\\,\\mathrm{bits}}{1.0 \\times 10^{-10}\\,\\mathrm{J}} = 4.9317 \\times 10^{9}\\,\\mathrm{bits}/\\mathrm{J}\n$$\nRounding to four significant figures, the result is $4.932 \\times 10^{9}\\,\\mathrm{bits}/\\mathrm{J}$.",
            "answer": "$$\\boxed{4.932 \\times 10^{9}}$$"
        }
    ]
}