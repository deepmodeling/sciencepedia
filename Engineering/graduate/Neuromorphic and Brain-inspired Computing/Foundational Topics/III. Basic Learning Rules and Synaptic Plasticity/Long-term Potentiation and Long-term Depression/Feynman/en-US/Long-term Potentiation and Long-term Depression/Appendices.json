{
    "hands_on_practices": [
        {
            "introduction": "Understanding synaptic plasticity often begins with population-level measurements, such as the field Excitatory Postsynaptic Potential (fEPSP) slope, a common proxy for synaptic strength in brain slice experiments. This exercise challenges you to synthesize multiple, co-occurring plasticity phenomena—homosynaptic potentiation, heterosynaptic depression, and global homeostatic scaling—into a single quantitative prediction. By calculating the final fEPSP slope after these changes , you will practice modeling how a neural population's response integrates distinct forms of plasticity, bridging the gap between cellular rules and observable network-level data.",
            "id": "4050517",
            "problem": "A neuromorphic hippocampal slice model records a Field Excitatory Postsynaptic Potential (fEPSP) slope as a linear readout of aggregate synaptic currents from two independent afferent pathways, denoted pathway $\\mathrm{A}$ and pathway $\\mathrm{B}$. The system uses a linear summation principle: the baseline fEPSP slope $S_0$ is the sum of the baseline contributions from each pathway. The baseline fractional contributions are $w_{\\mathrm{A}}$ and $w_{\\mathrm{B}}$, which satisfy $w_{\\mathrm{A}} + w_{\\mathrm{B}} = 1$. Long-Term Potentiation (LTP) and Long-Term Depression (LTD) are modeled as multiplicative changes in synaptic efficacy for each pathway, and global homeostatic scaling is modeled as a multiplicative factor applied uniformly to all synapses.\n\nTheta-Burst Stimulation (TBS) is delivered, after which pathway $\\mathrm{A}$ exhibits sustained LTP of $+40\\%$ and pathway $\\mathrm{B}$ exhibits heterosynaptic LTD of $-15\\%$. A slow homeostatic response reduces overall excitatory gain by $5\\%$ (i.e., a multiplicative factor less than one). The following parameters are measured:\n- Baseline fEPSP slope $S_0 = 0.95$ mV/ms,\n- Baseline fractional contributions $w_{\\mathrm{A}} = 0.60$ and $w_{\\mathrm{B}} = 0.40$,\n- Pathway $\\mathrm{A}$ potentiation percentage $+40\\%$,\n- Pathway $\\mathrm{B}$ depression percentage $-15\\%$,\n- Global homeostatic multiplicative factor $c = 0.95$.\n\nAssuming linear superposition of pathway contributions and multiplicative expression of Long-Term Potentiation (LTP), Long-Term Depression (LTD), and homeostatic scaling, compute the expected post-TBS fEPSP slope $S_{\\mathrm{TBS}}$. Round your final numeric answer to four significant figures and express your answer in mV/ms.",
            "solution": "The field Excitatory Postsynaptic Potential (fEPSP) slope is proportional to the time derivative of the extracellular potential generated by the sum of transmembrane synaptic currents from a population of neurons. Under the linear superposition principle for independent sources, the baseline fEPSP slope $S_0$ can be decomposed into pathway-specific contributions\n$$\nS_0 = S_{0,\\mathrm{A}} + S_{0,\\mathrm{B}},\n$$\nwhere $S_{0,\\mathrm{A}} = w_{\\mathrm{A}} S_0$ and $S_{0,\\mathrm{B}} = w_{\\mathrm{B}} S_0$ with $w_{\\mathrm{A}} + w_{\\mathrm{B}} = 1$. Long-Term Potentiation (LTP) and Long-Term Depression (LTD) are experimentally well-characterized as multiplicative changes in synaptic efficacy at the population level. Therefore, after Theta-Burst Stimulation (TBS), the pathway-specific post-TBS slopes are\n$$\nS_{\\mathrm{A}} = S_{0,\\mathrm{A}} \\left(1 + p_{\\mathrm{A}}\\right) c, \\quad S_{\\mathrm{B}} = S_{0,\\mathrm{B}} \\left(1 - d_{\\mathrm{B}}\\right) c,\n$$\nwhere $p_{\\mathrm{A}}$ is the fractional potentiation of pathway $\\mathrm{A}$, $d_{\\mathrm{B}}$ is the fractional depression of pathway $\\mathrm{B}$, and $c$ is the global homeostatic multiplicative factor applied uniformly.\n\nThe total expected post-TBS fEPSP slope $S_{\\mathrm{TBS}}$ follows from linearity:\n$$\nS_{\\mathrm{TBS}} = S_{\\mathrm{A}} + S_{\\mathrm{B}} = c \\left[ S_{0,\\mathrm{A}} \\left(1 + p_{\\mathrm{A}}\\right) + S_{0,\\mathrm{B}} \\left(1 - d_{\\mathrm{B}}\\right) \\right].\n$$\nSubstituting $S_{0,\\mathrm{A}} = w_{\\mathrm{A}} S_0$ and $S_{0,\\mathrm{B}} = w_{\\mathrm{B}} S_0$ gives\n$$\nS_{\\mathrm{TBS}} = c S_0 \\left[ w_{\\mathrm{A}} \\left(1 + p_{\\mathrm{A}}\\right) + w_{\\mathrm{B}} \\left(1 - d_{\\mathrm{B}}\\right) \\right].\n$$\n\nNow substitute the given values:\n- $S_0 = 0.95$,\n- $w_{\\mathrm{A}} = 0.60$,\n- $w_{\\mathrm{B}} = 0.40$,\n- $p_{\\mathrm{A}} = 0.40$,\n- $d_{\\mathrm{B}} = 0.15$,\n- $c = 0.95$.\n\nCompute the bracketed term:\n$$\nw_{\\mathrm{A}} \\left(1 + p_{\\mathrm{A}}\\right) + w_{\\mathrm{B}} \\left(1 - d_{\\mathrm{B}}\\right)\n= 0.60 \\times 1.40 + 0.40 \\times 0.85\n= 0.84 + 0.34\n= 1.18.\n$$\nApply the homeostatic factor $c$:\n$$\nc \\left( \\cdots \\right) = 0.95 \\times 1.18 = 1.121.\n$$\nMultiply by the baseline slope $S_0$:\n$$\nS_{\\mathrm{TBS}} = 0.95 \\times 1.121 = 1.06495.\n$$\n\nRounding to four significant figures as required gives $1.065$. The requested unit is mV/ms, so the final reported value is $1.065$ mV/ms.",
            "answer": "$$\\boxed{1.065}$$"
        },
        {
            "introduction": "After observing long-term plasticity, a crucial follow-up question is determining its physical locus: does the change reside in the presynaptic terminal (e.g., changes in release probability $p$ or vesicle pool size $N$) or the postsynaptic membrane (e.g., changes in quantal size $q$)? This problem introduces the paired-pulse ratio (PPR), a classic experimental tool used to dissect these possibilities. By deriving how PPR is affected by presynaptic versus postsynaptic parameters , you will gain insight into how short-term dynamics can be cleverly leveraged to diagnose the expression mechanism of long-term synaptic changes.",
            "id": "4050543",
            "problem": "A neuromorphic synapse circuit is designed to emulate cortical excitatory synapses with stochastic vesicle release and short-term dynamics. The measurable excitatory postsynaptic current amplitude is modeled by quantal analysis as $A = nq$, where $n$ is the number of vesicles released, $q$ is the postsynaptic quantal size (per-vesicle postsynaptic efficacy), and $n$ is drawn from a binomial distribution with parameters $(N, p)$, where $N$ is the number of release-ready sites in the readily releasable pool (RRP) and $p$ is the vesicle release probability per site. The paired-pulse protocol delivers two presynaptic spikes separated by a fixed interval $\\Delta t$ that is short compared to the vesicle replenishment time constant, so replenishment between pulses is negligible. Residual calcium enhances release probability on the second pulse by a fixed facilitation factor independent of small changes in baseline $p$, so $p$ on the second pulse satisfies $p_{2} = p (1 + \\alpha)$ with $\\alpha > 0$ constant at the chosen $\\Delta t$. The postsynaptic response is linear over the operating range (no saturation or desensitization on the timescale of $\\Delta t$). The paired-pulse ratio (PPR) is defined as $\\mathrm{PPR} = \\frac{\\mathbb{E}[A_{2}]}{\\mathbb{E}[A_{1}]}$, where $\\mathbb{E}[A_{1}]$ and $\\mathbb{E}[A_{2}]$ are the expected amplitudes of the first and second responses, respectively.\n\nStarting from these definitions and assumptions, analyze how presynaptic changes in release probability $p$ and vesicle pool size $N$ compare to postsynaptic changes in quantal size $q$ in shaping $\\mathrm{PPR}$, and use this to infer which patterns of long-term potentiation (LTP) and long-term depression (LTD) are presynaptic or postsynaptic in expression.\n\nWhich of the following statements are necessarily true under the stated model and assumptions?\n\nA. With negligible replenishment and fixed facilitation at the paired-pulse interval, an increase in presynaptic release probability $p$ necessarily reduces the paired-pulse ratio, whereas changes in readily releasable pool size $N$ or quantal size $q$ do not alter the paired-pulse ratio.\n\nB. Increasing $N$ at fixed $p$ increases the paired-pulse ratio because more vesicles remain for the second pulse; therefore a measured increase in paired-pulse ratio during Long-Term Potentiation (LTP) indicates presynaptic growth of the vesicle pool.\n\nC. Purely postsynaptic Long-Term Potentiation (LTP) that increases $q$ reduces the paired-pulse ratio, because the second response is more susceptible to receptor saturation than the first at the same quantal size.\n\nD. Presynaptic Long-Term Depression (LTD) that reduces $p$ increases the paired-pulse ratio by reducing depletion during the first pulse, even if $N$ is unchanged.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n-   Model for excitatory postsynaptic current amplitude: $A = nq$.\n-   $n$: number of vesicles released, drawn from a binomial distribution $B(N, p)$.\n-   $q$: postsynaptic quantal size (per-vesicle postsynaptic efficacy).\n-   $N$: number of release-ready sites in the readily releasable pool (RRP).\n-   $p$: vesicle release probability per site for the first pulse.\n-   Protocol: Paired-pulse with two presynaptic spikes separated by interval $\\Delta t$.\n-   Assumption: Replenishment between pulses is negligible.\n-   Model for facilitation: The release probability for the second pulse, $p_2$, is given by $p_{2} = p (1 + \\alpha)$ where $\\alpha > 0$ is a constant.\n-   Assumption: The postsynaptic response is linear (no saturation or desensitization).\n-   Definition of Paired-Pulse Ratio (PPR): $\\mathrm{PPR} = \\frac{\\mathbb{E}[A_{2}]}{\\mathbb{E}[A_{1}]}$, where $\\mathbb{E}[A_{1}]$ and $\\mathbb{E}[A_{2}]$ are the expected amplitudes of the first and second responses.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a simplified but standard biophysical model of short-term synaptic plasticity.\n-   **Scientifically Grounded:** The model is based on the quantal hypothesis of neurotransmitter release ($A=nq$), binomial statistics for release, and the concepts of readily releasable pool ($N$), release probability ($p$), short-term facilitation ($\\alpha > 0$), and short-term depression (via vesicle depletion). These are cornerstone principles in synaptic physiology and computational neuroscience. The model is a well-established simplification.\n-   **Well-Posed:** The problem provides sufficient definitions and assumptions to derive a unique mathematical expression for the Paired-Pulse Ratio (PPR) in terms of the model parameters. The question asks for an analysis based on this derivation, which is a well-defined task.\n-   **Objective:** The language is quantitative and precise. All terms are defined within the model.\n\nLet's check for internal consistency. The model includes both facilitation (increase in $p$) and depression (depletion of $N$). These are not contradictory; their interplay is central to short-term plasticity. The assumption of \"negligible replenishment\" implies that the number of release-ready sites for the second pulse is reduced by the number of vesicles released on the first pulse. This is a key constraint that must be used in the derivation. The assumption of \"linear postsynaptic response\" simplifies the problem by allowing the expected amplitude to be the product of the expected number of vesicles and the quantal size, and it makes the quantal size $q$ a simple scaling factor. All components are self-consistent.\n\n### Step 3: Verdict and Action\nThe problem statement is scientifically sound, well-posed, objective, and internally consistent. It is a valid problem. We may proceed to the solution.\n\n### Derivation of the Paired-Pulse Ratio (PPR)\n\nFor the first presynaptic pulse, the number of released vesicles, $n_1$, follows a binomial distribution with parameters $N$ and $p$.\n$$n_1 \\sim B(N, p)$$\nThe expected number of vesicles released is the mean of this distribution:\n$$\\mathbb{E}[n_1] = Np$$\nThe expected amplitude of the first postsynaptic response, $\\mathbb{E}[A_1]$, is:\n$$\\mathbb{E}[A_1] = \\mathbb{E}[n_1 q] = q \\mathbb{E}[n_1] = qNp$$\n\nFor the second presynaptic pulse, two effects are at play:\n1.  **Depletion:** Since replenishment is negligible, the number of release-ready sites available for the second pulse is reduced by the number of sites that released a vesicle during the first pulse. If $n_1$ vesicles were released, the number of available sites becomes $N - n_1$.\n2.  **Facilitation:** The release probability for each of the remaining sites is increased to $p_2 = p(1+\\alpha)$.\n\nThe number of vesicles released on the second pulse, $n_2$, conditioned on the outcome of the first pulse ($n_1$), follows a binomial distribution with parameters $(N - n_1, p_2)$.\n$$n_2 | n_1 \\sim B(N - n_1, p_2)$$\nThe expected value of $n_2$ conditioned on $n_1$ is:\n$$\\mathbb{E}[n_2 | n_1] = (N - n_1) p_2$$\nTo find the unconditional expectation $\\mathbb{E}[n_2]$, we use the law of total expectation: $\\mathbb{E}[n_2] = \\mathbb{E}[\\mathbb{E}[n_2|n_1]]$.\n$$\\mathbb{E}[n_2] = \\mathbb{E}[(N - n_1)p_2] = p_2 \\mathbb{E}[N - n_1] = p_2 (N - \\mathbb{E}[n_1])$$\nSubstituting $\\mathbb{E}[n_1] = Np$:\n$$\\mathbb{E}[n_2] = p_2 (N - Np) = p_2 N(1-p)$$\nNow, substituting $p_2 = p(1+\\alpha)$:\n$$\\mathbb{E}[n_2] = p(1+\\alpha)N(1-p)$$\nThe expected amplitude of the second postsynaptic response, $\\mathbb{E}[A_2]$, is:\n$$\\mathbb{E}[A_2] = \\mathbb{E}[n_2 q] = q \\mathbb{E}[n_2] = q N p (1+\\alpha)(1-p)$$\n\nFinally, we compute the Paired-Pulse Ratio (PPR) using its definition:\n$$\\mathrm{PPR} = \\frac{\\mathbb{E}[A_2]}{\\mathbb{E}[A_1]} = \\frac{q N p (1+\\alpha)(1-p)}{q N p}$$\nAssuming $q, N, p$ are all non-zero, we can cancel terms to obtain the final expression for PPR:\n$$\\mathrm{PPR} = (1+\\alpha)(1-p)$$\nThis expression reveals how PPR depends on the presynaptic parameters $p$ and $\\alpha$, and importantly, how it is independent of the presynaptic parameter $N$ and the postsynaptic parameter $q$.\n\n### Evaluation of Options\n\n**A. With negligible replenishment and fixed facilitation at the paired-pulse interval, an increase in presynaptic release probability $p$ necessarily reduces the paired-pulse ratio, whereas changes in readily releasable pool size $N$ or quantal size $q$ do not alter the paired-pulse ratio.**\n\n-   **Effect of $p$:** We examine the derivative of PPR with respect to $p$: $\\frac{\\partial(\\mathrm{PPR})}{\\partial p} = \\frac{\\partial}{\\partial p}[(1+\\alpha)(1-p)] = -(1+\\alpha)$. Since the problem states $\\alpha > 0$, the derivative is always negative. Therefore, an increase in $p$ necessarily reduces PPR.\n-   **Effect of $N$:** The derived expression $\\mathrm{PPR} = (1+\\alpha)(1-p)$ is independent of $N$. Therefore, changes in $N$ do not alter the PPR.\n-   **Effect of $q$:** The derived expression for PPR is also independent of $q$. Therefore, changes in $q$ do not alter the PPR.\n-   This statement is entirely consistent with our derivation.\n-   Verdict: **Correct**.\n\n**B. Increasing $N$ at fixed $p$ increases the paired-pulse ratio because more vesicles remain for the second pulse; therefore a measured increase in paired-pulse ratio during Long-Term Potentiation (LTP) indicates presynaptic growth of the vesicle pool.**\n\n-   The first part of the statement claims that increasing $N$ increases the PPR. Our derivation shows $\\mathrm{PPR} = (1+\\alpha)(1-p)$, which is independent of $N$. While increasing $N$ increases the absolute expected number of vesicles for both pulses, it does not change their ratio. So, this claim is false.\n-   The conclusion that an increased PPR indicates a growth in $N$ is based on this false premise. In our model, an increase in PPR is caused by a *decrease* in $p$. An increase in $N$ causes LTP (i.e., increases $\\mathbb{E}[A_1] = qNp$) but leaves PPR unchanged.\n-   Verdict: **Incorrect**.\n\n**C. Purely postsynaptic Long-Term Potentiation (LTP) that increases $q$ reduces the paired-pulse ratio, because the second response is more susceptible to receptor saturation than the first at the same quantal size.**\n\n-   The reasoning provided (\"because the second response is more susceptible to receptor saturation\") directly contradicts a key assumption given in the problem statement: \"The postsynaptic response is linear over the operating range (no saturation or desensitization on the timescale of $\\Delta t$)\".\n-   Within the stated model, a purely postsynaptic LTP corresponds to an increase in $q$. Our derivation shows that PPR is independent of $q$. Thus, a change in $q$ does not alter PPR. The statement's claim that it reduces the PPR is false under the given assumptions.\n-   Verdict: **Incorrect**.\n\n**D. Presynaptic Long-Term Depression (LTD) that reduces $p$ increases the paired-pulse ratio by reducing depletion during the first pulse, even if $N$ is unchanged.**\n\n-   This statement concerns presynaptic LTD expressed as a reduction in $p$.\n-   We analyze the effect of decreasing $p$ on $\\mathrm{PPR} = (1+\\alpha)(1-p)$. As established in the analysis of option A, PPR is inversely related to $p$. Therefore, a reduction in $p$ will cause an increase in PPR.\n-   The provided reasoning is \"by reducing depletion during the first pulse\". Depletion is the consumption of vesicles from the RRP. The expected number of vesicles released in the first pulse is $\\mathbb{E}[n_1] = Np$. A smaller $p$ leads to a smaller expected release, hence less depletion. The PPR formula shows that the ratio depends on the fraction of the pool *not* depleted, which is $(1-p)$. A smaller $p$ makes this factor larger, thereby increasing PPR. The reasoning is biophysically and mathematically sound.\n-   The condition \"even if $N$ is unchanged\" is consistent with analyzing a change solely in $p$.\n-   Verdict: **Correct**.",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "This final practice moves from the 'how' and 'where' of plasticity to the 'why'—its functional role in adaptation and learning. You will implement the Bienenstock-Cooper-Munro (BCM) learning rule, a foundational model of metaplasticity that ensures synaptic changes are both competitive and stable by allowing the modification threshold $\\theta_M$ to slide. By simulating a neuron's response to a dynamically changing input , you will observe firsthand how the BCM rule enables a neuron's receptive field to track shifts in input statistics, providing a concrete example of how plasticity mechanisms support adaptive behavior in neural systems.",
            "id": "4050530",
            "problem": "A single rate neuron receives a deterministic, time-varying two-dimensional input that captures drifting input statistics. The neuron has a receptive field represented by a weight vector $\\mathbf{w}(t) \\in \\mathbb{R}^2$ and produces an instantaneous scalar output $y(t) = \\mathbf{w}(t)^\\top \\mathbf{x}(t)$. Synaptic plasticity follows the Bienenstock–Cooper–Munro (BCM) rule with metaplasticity via a sliding modification threshold. The metaplasticity threshold $\\theta_M(t)$ tracks a running average of the squared output. The system is governed by the following ordinary differential equations that define the learning dynamics:\n- Output: $y(t) = \\mathbf{w}(t)^\\top \\mathbf{x}(t)$.\n- Metaplastic threshold dynamics: $\\dfrac{d \\theta_M}{dt} = \\dfrac{1}{\\tau}\\left(y(t)^2 - \\theta_M(t)\\right)$, where $\\tau  0$ is the metaplasticity time constant.\n- Synaptic plasticity: $\\dfrac{d \\mathbf{w}}{dt} = \\eta \\, y(t)\\, \\mathbf{x}(t)\\,\\big(y(t) - \\theta_M(t)\\big) - \\lambda \\, \\mathbf{w}(t)$, where $\\eta  0$ is a learning rate and $\\lambda  0$ is a small homeostatic decay.\n\nThe input is the deterministic mean of a drifting stimulus distribution, chosen to be a constant-magnitude vector rotating at angular velocity $\\omega$ (radians per second). Specifically, $\\mathbf{x}(t) = \\boldsymbol{\\mu}(t)$ with\n$$\n\\boldsymbol{\\mu}(t) = m \\begin{bmatrix} \\cos(\\omega t) \\\\ \\sin(\\omega t) \\end{bmatrix},\n$$\nwhere $m  0$ is the input magnitude. The receptive field orientation is defined as the polar angle of the weight vector, $\\phi_w(t) = \\mathrm{atan2}(w_2(t), w_1(t))$ in radians, and the input orientation is $\\phi_\\mu(t) = \\mathrm{atan2}(\\mu_2(t), \\mu_1(t)) = \\omega t$ in radians. Define the instantaneous signed angular offset $\\Delta(t)$ in degrees as the principal value difference:\n$$\n\\Delta(t) = \\mathrm{wrap}_{(-180,180]}\\left( \\dfrac{180}{\\pi}\\left(\\phi_w(t) - \\phi_\\mu(t)\\right) \\right),\n$$\nwhere $\\mathrm{wrap}_{(-180,180]}(\\cdot)$ maps any real angle in degrees to its equivalent in the interval $(-180, 180]$ by adding or subtracting integer multiples of $360$. The quantity $\\Delta(t)$ quantifies the shift between the neuron's receptive field and the current input orientation due to metaplasticity under the BCM rule.\n\nStarting from initial conditions $\\mathbf{w}(0) = \\begin{bmatrix} w_0 \\\\ 0 \\end{bmatrix}$ and $\\theta_M(0) = \\theta_0$, integrate the system over a finite horizon $t \\in [0, T]$ with a fixed-step explicit scheme appropriate for first-order ordinary differential equations. Use the following fixed constants throughout:\n- Input magnitude $m = 1.0$.\n- Learning rate $\\eta = 0.02$.\n- Weight decay $\\lambda = 0.01$.\n- Initial weight component $w_0 = 0.1$.\n- Initial threshold $\\theta_0 = 0.1$.\n- Total simulation time $T = 200.0$ seconds.\n- Integration time step $\\Delta t = 0.001$ seconds.\n- Time-averaging window $W = 20.0$ seconds.\n\nFor each parameter set, compute the time-average of the signed angular offset over the final window $[T - W, T]$:\n$$\n\\overline{\\Delta} = \\dfrac{1}{N_W} \\sum_{k = N - N_W}^{N - 1} \\Delta(k \\,\\Delta t),\n$$\nwhere $N = \\lfloor T / \\Delta t \\rfloor$ and $N_W = \\lfloor W / \\Delta t \\rfloor$. Report $\\overline{\\Delta}$ in degrees.\n\nYour program must implement the dynamics and output the average offset $\\overline{\\Delta}$ for each of the following test cases, which vary the drift rate $\\omega$ and metaplasticity time constant $\\tau$:\n- Test case $1$: $\\omega = 0.0$, $\\tau = 10.0$.\n- Test case $2$: $\\omega = 0.05$, $\\tau = 10.0$.\n- Test case $3$: $\\omega = 0.05$, $\\tau = 200.0$.\n- Test case $4$: $\\omega = 0.2$, $\\tau = 10.0$.\n- Test case $5$: $\\omega = 1.0$, $\\tau = 100.0$.\n\nAngle unit specification: all angles used for averaging and output must be in degrees. The final answers must be floats rounded to three decimal places.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the $\\overline{\\Delta}$ for the corresponding test case, rounded to three decimal places.",
            "solution": "The problem has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a standard model from computational neuroscience, specifically the Bienenstock–Cooper–Munro (BCM) learning rule with metaplasticity, applied to a neuron tracking a rotating input stimulus. All parameters, equations, and initial conditions are provided, forming a complete and solvable problem.\n\nThe core of the problem is to solve a system of coupled first-order ordinary differential equations (ODEs) that describe the temporal evolution of the neuron's synaptic weight vector $\\mathbf{w}(t)$ and its metaplastic modification threshold $\\theta_M(t)$. The system is given by:\n$$\n\\dfrac{d \\theta_M}{dt} = \\dfrac{1}{\\tau}\\left(y(t)^2 - \\theta_M(t)\\right)\n$$\n$$\n\\dfrac{d \\mathbf{w}}{dt} = \\eta \\, y(t)\\, \\mathbf{x}(t)\\,\\big(y(t) - \\theta_M(t)\\big) - \\lambda \\, \\mathbf{w}(t)\n$$\nwhere the neuron's output is $y(t) = \\mathbf{w}(t)^\\top \\mathbf{x}(t)$, and the input is a deterministically rotating vector $\\mathbf{x}(t) = \\boldsymbol{\\mu}(t) = m [\\cos(\\omega t), \\sin(\\omega t)]^\\top$.\n\nWe will solve this system numerically over the time interval $t \\in [0, T]$ using the Forward Euler method, which is a simple and appropriate fixed-step explicit scheme, given the small integration time step $\\Delta t = 0.001$ s.\n\nLet $k$ be the discrete time index, such that $t_k = k \\Delta t$. The state of the system at time $t_k$ is described by the weight vector $\\mathbf{w}_k = \\mathbf{w}(t_k)$ and the threshold $\\theta_{M,k} = \\theta_M(t_k)$. The initial conditions are $\\mathbf{w}_0 = [w_0, 0]^\\top$ and $\\theta_{M,0} = \\theta_0$.\n\nThe integration proceeds iteratively. At each step $k$, we first compute the input vector and the neuron's output:\n$$\n\\mathbf{x}_k = m \\begin{bmatrix} \\cos(\\omega t_k) \\\\ \\sin(\\omega t_k) \\end{bmatrix}\n$$\n$$\ny_k = \\mathbf{w}_k^\\top \\mathbf{x}_k\n$$\nThen, we evaluate the derivatives (the right-hand sides of the ODEs) at time $t_k$:\n$$\n\\left(\\dfrac{d \\mathbf{w}}{dt}\\right)_k = \\eta \\, y_k\\, \\mathbf{x}_k\\,\\big(y_k - \\theta_{M,k}\\big) - \\lambda \\, \\mathbf{w}_k\n$$\n$$\n\\left(\\dfrac{d \\theta_M}{dt}\\right)_k = \\dfrac{1}{\\tau}\\left(y_k^2 - \\theta_{M,k}\\right)\n$$\nUsing these derivatives, we update the state variables to find their values at the next time step, $t_{k+1} = (k+1)\\Delta t$:\n$$\n\\mathbf{w}_{k+1} = \\mathbf{w}_k + \\Delta t \\cdot \\left(\\dfrac{d \\mathbf{w}}{dt}\\right)_k\n$$\n$$\n\\theta_{M,k+1} = \\theta_{M,k} + \\Delta t \\cdot \\left(\\dfrac{d \\theta_M}{dt}\\right)_k\n$$\nThis process is repeated for $k = 0, 1, \\dots, N-1$, where $N = \\lfloor T / \\Delta t \\rfloor$ is the total number of simulation steps.\n\nConcurrently with the integration, we calculate the instantaneous signed angular offset $\\Delta(t_k)$ at each step. This requires finding the orientation of the weight vector, $\\phi_{w,k}$, and the orientation of the input vector, $\\phi_{\\mu,k}$:\n$$\n\\phi_{w,k} = \\mathrm{atan2}(w_{2,k}, w_{1,k})\n$$\n$$\n\\phi_{\\mu,k} = \\omega t_k\n$$\nwhere $w_{1,k}$ and $w_{2,k}$ are the components of $\\mathbf{w}_k$. The angular difference is then converted to degrees and wrapped to the interval $(-180^\\circ, 180^\\circ]$ as specified:\n$$\n\\Delta_k = \\Delta(t_k) = \\mathrm{wrap}_{(-180,180]}\\left( \\dfrac{180}{\\pi}\\left(\\phi_{w,k} - \\phi_{\\mu,k}\\right) \\right)\n$$\nThe history of $\\Delta_k$ values is stored for the entire simulation.\n\nFinally, after the simulation completes, we compute the time-average of the signed angular offset, $\\overline{\\Delta}$, over the final time window of duration $W$. The number of steps in this window is $N_W = \\lfloor W / \\Delta t \\rfloor$. The average is calculated over the last $N_W$ values of the stored offsets:\n$$\n\\overline{\\Delta} = \\dfrac{1}{N_W} \\sum_{k = N - N_W}^{N-1} \\Delta_k\n$$\nThis entire procedure is performed for each of the five test cases, which differ in their values for the input's angular velocity $\\omega$ and the metaplasticity time constant $\\tau$. The resulting average offset $\\overline{\\Delta}$ for each case is then reported.",
            "answer": "```python\nimport numpy as np\n\n# from scipy import ... # Scipy is available but not used in this solution.\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print the results.\n    \"\"\"\n\n    # --- Fixed constants from the problem statement ---\n    m = 1.0         # Input magnitude\n    eta = 0.02      # Learning rate\n    lambda_ = 0.01  # Weight decay (using lambda_ to avoid keyword conflict)\n    w0 = 0.1        # Initial weight component\n    theta0 = 0.1    # Initial threshold\n    T = 200.0       # Total simulation time in seconds\n    dt = 0.001      # Integration time step in seconds\n    W = 20.0        # Time-averaging window in seconds\n\n    # --- Test cases ---\n    # Each tuple is (omega, tau)\n    test_cases = [\n        (0.0, 10.0),\n        (0.05, 10.0),\n        (0.05, 200.0),\n        (0.2, 10.0),\n        (1.0, 100.0),\n    ]\n\n    results = []\n    for omega, tau in test_cases:\n        avg_delta = run_simulation(omega, tau, m, eta, lambda_, w0, theta0, T, dt, W)\n        results.append(avg_delta)\n\n    # Format the results to three decimal places\n    formatted_results = [f\"{res:.3f}\" for res in results]\n\n    # Print the final output in the required format\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef wrap_angle(angle_deg):\n    \"\"\"\n    Wraps an angle in degrees to the interval (-180, 180].\n\n    Args:\n        angle_deg (float): The angle in degrees.\n\n    Returns:\n        float: The wrapped angle in degrees.\n    \"\"\"\n    # This formula correctly implements the wrap to (-180, 180]\n    return angle_deg - 360.0 * np.ceil((angle_deg - 180.0) / 360.0)\n\ndef run_simulation(omega, tau, m, eta, lambda_, w0, theta0, T, dt, W):\n    \"\"\"\n    Integrates the neuron's dynamics and computes the average angular offset.\n    \n    Args:\n        omega (float): Input angular velocity (rad/s).\n        tau (float): Metaplasticity time constant (s).\n        All other parameters are the fixed constants.\n\n    Returns:\n        float: The time-averaged signed angular offset in degrees.\n    \"\"\"\n    # --- Simulation setup ---\n    n_steps = int(np.floor(T / dt))\n    n_window = int(np.floor(W / dt))\n\n    # --- Initialization ---\n    w = np.array([w0, 0.0])\n    theta_m = theta0\n    delta_history = np.zeros(n_steps)\n\n    # --- Integration loop ---\n    for k in range(n_steps):\n        t = k * dt\n\n        # 1. Calculate angular offset at current time t\n        phi_w = np.arctan2(w[1], w[0])\n        phi_mu = omega * t\n        diff_deg = np.rad2deg(phi_w - phi_mu)\n        delta_k = wrap_angle(diff_deg)\n        delta_history[k] = delta_k\n\n        # 2. Calculate intermediates for state update\n        x = m * np.array([np.cos(omega * t), np.sin(omega * t)])\n        y = np.dot(w, x)\n\n        # 3. Calculate derivatives at time t\n        dw_dt = eta * y * x * (y - theta_m) - lambda_ * w\n        dtheta_m_dt = (1.0 / tau) * (y**2 - theta_m)\n\n        # 4. Update state variables using Forward Euler method\n        w = w + dw_dt * dt\n        theta_m = theta_m + dtheta_m_dt * dt\n\n    # --- Post-processing: Calculate average over the final window ---\n    final_deltas = delta_history[-n_window:]\n    avg_delta = np.mean(final_deltas)\n\n    return avg_delta\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}