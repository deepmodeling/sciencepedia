{
    "hands_on_practices": [
        {
            "introduction": "将理论上的神经网络模型部署到具体的神经形态硬件上，首要任务是进行资源评估和映射。这个练习将指导你分析一个典型的脉冲神经网络层，并根据 SpiNNaker、Loihi、TrueNorth 和 BrainScaleS 等不同平台的硬件限制（如每核心的神经元和突触数量），从第一性原理出发计算承载该网络层所需的最小核心数。通过这个实践，你将掌握将网络结构与硬件资源进行匹配的基本技能，这是设计和扩展神经形态计算应用的基础。",
            "id": "4049234",
            "problem": "考虑一个脉冲神经网络中的单前馈层，该层必须映射到四个大规模神经形态平台之一：SpiNNaker (Spiking Neural Network Architecture)、Intel Loihi、IBM TrueNorth 和 BrainScaleS。该层包含 $N$ 个突触后神经元，每个神经元的扇入为 $k$，连接来自前一个神经元群。假设采用以下科学映射模型：每个突触连接消耗一个单位的突触内存；在任何单个核心内部，突触前轴突流可以被该核心上放置的所有神经元共享；该层的突触内存不存在跨核心共享；并且该层中的所有神经元都是同质的，需要相同的扇入 $k$。\n\n每个平台在核心级别上强制执行资源限制：\n- SpiNNaker：单个核心最多可承载 $n_{\\max}^{\\text{Spi}} = 200$ 个神经元和最多 $s_{\\max}^{\\text{Spi}} = 2.0 \\times 10^{5}$ 个突触。\n- Loihi：单个核心最多可承载 $n_{\\max}^{\\text{Loi}} = 1024$ 个神经元和最多 $s_{\\max}^{\\text{Loi}} = 3.0 \\times 10^{5}$ 个突触。\n- TrueNorth：单个核心最多可承载 $n_{\\max}^{\\text{TN}} = 256$ 个神经元、最多 $s_{\\max}^{\\text{TN}} = 256^{2}$ 个突触，以及最多 $a_{\\max}^{\\text{TN}} = 256$ 个不同的突触前轴突流。对于此平台，扇入不得超过突触前轴突容量，即每核心该层所需的独立输入流数量不能超过 $a_{\\max}^{\\text{TN}}$。\n- BrainScaleS：单个核心最多可承载 $n_{\\max}^{\\text{BSS}} = 512$ 个神经元和最多 $s_{\\max}^{\\text{BSS}} = 1.5 \\times 10^{5}$ 个突触。\n\n假设 $N = 5000$ 且 $k = 180$。在所述模型和限制条件下，从第一性原理推导在每个平台上承载整个层所需的最小核心数，同时考虑神经元容量和突触容量的约束，并对 IBM TrueNorth 的情况验证其突触前轴突约束。以 $\\left(\\text{SpiNNaker}, \\text{Loihi}, \\text{TrueNorth}, \\text{BrainScaleS}\\right)$ 的顺序，将您的最终答案表示为单行矩阵。除了最小资源分配中固有的向上取整和向下取整操作所导致的精确计数外，不需要其他舍入。",
            "solution": "目标是找出在四个不同的神经形态平台上，承载一个包含 $N$ 个神经元、每个神经元扇入为 $k$ 的神经层所需的最小核心数 $C$。该层中的神经元总数为 $N = 5000$，扇入为 $k = 180$。该层中的突触连接总数为 $N \\times k = 5000 \\times 180 = 9.0 \\times 10^5$。\n\n为求得最小核心数，我们首先必须确定可以放置在每个平台单个核心上的该层的最大神经元数量 $n_{\\text{per\\_core}}$。这个数量受到平台特定的每核心神经元和突触数量的约束。设 $n$ 为单个核心上的神经元数量。约束条件如下：\n$1$. 神经元容量：神经元数量 $n$ 不能超过每核心的最大神经元数 $n_{\\max}$。\n$$n \\le n_{\\max}$$\n$2$. 突触容量：$n$ 个神经元所需的突触总数为 $n \\times k$，因为每个神经元有 $k$ 个输入突触。这个数量不能超过每核心的最大突触数 $s_{\\max}$。\n$$n \\times k \\le s_{\\max} \\implies n \\le \\frac{s_{\\max}}{k}$$\n由于 $n$ 必须是整数，突触约束意味着 $n \\le \\lfloor \\frac{s_{\\max}}{k} \\rfloor$。\n\n可以放置在单个核心上的最大神经元数 $n_{\\text{per\\_core}}$ 是同时满足两个约束条件的最大整数 $n$。\n$$n_{\\text{per\\_core}} = \\min(n_{\\max}, \\lfloor \\frac{s_{\\max}}{k} \\rfloor)$$\n一旦确定了 $n_{\\text{per\\_core}}$，承载所有 $N$ 个神经元所需的最小核心数 $C$ 是神经元总数除以每核心最大神经元数，并向上取整。这通过向上取整函数计算。\n$$C = \\lceil \\frac{N}{n_{\\text{per\\_core}}} \\rceil$$\n现在，我们使用给定的值 $N=5000$ 和 $k=180$ 将此框架应用于每个平台。\n\n$1$. SpiNNaker:\n核心限制为 $n_{\\max}^{\\text{Spi}} = 200$ 个神经元和 $s_{\\max}^{\\text{Spi}} = 2.0 \\times 10^{5}$ 个突触。\n基于突触容量的最大神经元数为：\n$$n \\le \\lfloor \\frac{s_{\\max}^{\\text{Spi}}}{k} \\rfloor = \\lfloor \\frac{2.0 \\times 10^5}{180} \\rfloor = \\lfloor 1111.11\\dots \\rfloor = 1111$$\n限制因素是神经元容量。因此，每核心的最大神经元数为：\n$$n_{\\text{per\\_core}}^{\\text{Spi}} = \\min(200, 1111) = 200$$\nSpiNNaker 所需的最小核心数为：\n$$C_{\\text{Spi}} = \\lceil \\frac{N}{n_{\\text{per\\_core}}^{\\text{Spi}}} \\rceil = \\lceil \\frac{5000}{200} \\rceil = \\lceil 25 \\rceil = 25$$\n\n$2$. Loihi:\n核心限制为 $n_{\\max}^{\\text{Loi}} = 1024$ 个神经元和 $s_{\\max}^{\\text{Loi}} = 3.0 \\times 10^{5}$ 个突触。\n基于突触容量的最大神经元数为：\n$$n \\le \\lfloor \\frac{s_{\\max}^{\\text{Loi}}}{k} \\rfloor = \\lfloor \\frac{3.0 \\times 10^5}{180} \\rfloor = \\lfloor 1666.66\\dots \\rfloor = 1666$$\n限制因素是神经元容量。因此，每核心的最大神经元数为：\n$$n_{\\text{per\\_core}}^{\\text{Loi}} = \\min(1024, 1666) = 1024$$\nLoihi 所需的最小核心数为：\n$$C_{\\text{Loi}} = \\lceil \\frac{N}{n_{\\text{per\\_core}}^{\\text{Loi}}} \\rceil = \\lceil \\frac{5000}{1024} \\rceil = \\lceil 4.8828\\dots \\rceil = 5$$\n\n$3$. TrueNorth:\n核心限制为 $n_{\\max}^{\\text{TN}} = 256$ 个神经元、$s_{\\max}^{\\text{TN}} = 256^2 = 65536$ 个突触，以及 $a_{\\max}^{\\text{TN}} = 256$ 个不同的突触前轴突流。\n首先，我们验证轴突约束。问题陈述中说明，突触前轴突流在核心上的神经元之间共享。扇入 $k$ 代表所需的独立突触前输入数量。我们必须检查是否 $k \\le a_{\\max}^{\\text{TN}}$。\n$$180 \\le 256$$\n轴突约束得到满足。我们可以继续计算。\n基于突触容量的最大神经元数为：\n$$n \\le \\lfloor \\frac{s_{\\max}^{\\text{TN}}}{k} \\rfloor = \\lfloor \\frac{65536}{180} \\rfloor = \\lfloor 364.08\\dots \\rfloor = 364$$\n限制因素是神经元容量。因此，每核心的最大神经元数为：\n$$n_{\\text{per\\_core}}^{\\text{TN}} = \\min(256, 364) = 256$$\nTrueNorth 所需的最小核心数为：\n$$C_{\\text{TN}} = \\lceil \\frac{N}{n_{\\text{per\\_core}}^{\\text{TN}}} \\rceil = \\lceil \\frac{5000}{256} \\rceil = \\lceil 19.53125 \\rceil = 20$$\n\n$4$. BrainScaleS:\n核心限制为 $n_{\\max}^{\\text{BSS}} = 512$ 个神经元和 $s_{\\max}^{\\text{BSS}} = 1.5 \\times 10^{5}$ 个突触。\n基于突触容量的最大神经元数为：\n$$n \\le \\lfloor \\frac{s_{\\max}^{\\text{BSS}}}{k} \\rfloor = \\lfloor \\frac{1.5 \\times 10^5}{180} \\rfloor = \\lfloor 833.33\\dots \\rfloor = 833$$\n限制因素是神经元容量。因此，每核心的最大神经元数为：\n$$n_{\\text{per\\_core}}^{\\text{BSS}} = \\min(512, 833) = 512$$\nBrainScaleS 所需的最小核心数为：\n$$C_{\\text{BSS}} = \\lceil \\frac{N}{n_{\\text{per\\_core}}^{\\text{BSS}}} \\rceil = \\lceil \\frac{5000}{512} \\rceil = \\lceil 9.765625 \\rceil = 10$$\n\n各平台所需的最小核心数分别为：SpiNNaker 25个，Loihi 5个，TrueNorth 20个，BrainScaleS 10个。最终答案以指定顺序的单行矩阵形式表示。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 25 & 5 & 20 & 10 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "对于由多个芯片组成的大规模神经形态系统，计算性能不仅取决于单个核心的处理能力，更关键地取决于芯片间的通信效率。天真地将神经元簇映射到物理芯片上可能会导致通信瓶颈，从而严重影响系统性能。本练习旨在解决这一关键问题，要求你设计一种拓扑感知的映射策略，通过将通信频繁的神经元簇放置在物理上相邻的芯片上，来最小化片间通信的平均跳数。这个练习将帮助你理解并量化智能映射策略相对于基线映射所带来的性能提升，这是实现可扩展性的核心技术。",
            "id": "4049231",
            "problem": "您将处理一个大规模神经形态架构中通信的简化抽象，例如部署在多芯片平台上的脉冲神经网络（SNN）系统，这些平台包括可扩展神经网络处理器（SpiNNaker）、英特尔的 Loihi 神经形态研究芯片（Loihi）、国际商业机器公司的 TrueNorth 架构（TrueNorth）以及海德堡大学的 BrainScaleS 系统（BrainScaleS）。每个芯片通过一个片上网络（NoC）连接，该网络可以理想化为一个网格拓扑。我们将通信建模为一个无向加权图，并使用 NoC 中的路由器遍历次数（跳数）来衡量芯片间的通信成本。您的任务是构建一个能够最小化芯片间流量的拓扑感知神经元簇到芯片的映射，然后量化相对于朴素基线映射的平均跳数减少量。\n\n基本依据和定义：\n\n- 设有 $N$ 个神经元簇，标记为 $\\{0,1,\\dots,N-1\\}$，以及 $N$ 个芯片，标记为 $\\{0,1,\\dots,N-1\\}$，排列在一个二维网格上。芯片 $j$ 的整数坐标为 $(x_j,y_j)$。\n- 通信需求由一个对称非负矩阵 $W \\in \\mathbb{R}^{N \\times N}$ 给出，其中 $W_{uv}$ 是簇 $u$ 和簇 $v$ 之间每单位时间的预期簇间脉冲流量（对于 $u \\neq v$），且 $W_{uu} = 0$。\n- 芯片 $j$ 和芯片 $k$ 之间的跳数距离建模为曼哈顿距离 $d_{jk} = |x_j - x_k| + |y_j - y_k|$，它计算了在网状 NoC 中沿轴对齐链路的路由器遍历次数。\n- 一个映射 $\\pi: \\{0,\\dots,N-1\\} \\to \\{0,\\dots,N-1\\}$ 将每个簇索引 $u$ 分配给一个芯片索引 $\\pi(u)$。由 $\\pi$ 导出的加权平均跳数是\n$$\nH(\\pi) = \\frac{\\sum_{0 \\le u  v \\le N-1} W_{uv}\\, d_{\\pi(u),\\pi(v)}}{\\sum_{0 \\le u  v \\le N-1} W_{uv}}.\n$$\n- 基线映射 $\\pi_0$ 是恒等映射 $\\pi_0(u) = u$，它将簇 $u$ 分配给芯片 $u$，其中芯片按每个测试用例指定的行主序排列。\n- 您的任务是找到最优映射 $\\pi^\\star$ 以最小化 $H(\\pi)$，并计算平均跳数减少量 $\\Delta = H(\\pi_0) - H(\\pi^\\star)$。对每个测试用例计算此值，并将结果四舍五入到小数点后四位。",
            "solution": "用户的问题要求计算通过最优拓扑感知映射（将神经元簇映射到芯片）相较于朴素基线映射所实现的平均通信成本减少量 $\\Delta$。这个问题可以形式化为二次分配问题（QAP）的一个实例。虽然一般性的 QAP 是 NP-难问题，但在所提供的测试用例中，簇的数量 $N$ 很小（$N \\le 8$），这允许通过对所有可能的映射进行穷举搜索来找到最优解。\n\n首先，我们将问题的组成部分形式化。给定 $N$ 个神经元簇和 $N$ 个芯片。芯片的位置以坐标 $(x_j, y_j)$ 的形式提供，由此我们可以预先计算一个距离矩阵 $D \\in \\mathbb{R}^{N \\times N}$。条目 $D_{jk}$ 是芯片 $j$ 和芯片 $k$ 之间的曼哈顿距离 $d_{jk} = |x_j - x_k| + |y_j - y_k|$。我们还得到了一个对称的通信需求矩阵 $W \\in \\mathbb{R}^{N \\times N}$，其中 $W_{uv}$ 表示簇 $u$ 和簇 $v$ 之间的流量。\n\n映射是一个从簇集合 $\\{0, 1, \\dots, N-1\\}$ 到芯片集合 $\\{0, 1, \\dots, N-1\\}$ 的双射 $\\pi$。目标是找到一个映射 $\\pi^\\star$，以最小化加权平均跳数，定义为：\n$$\nH(\\pi) = \\frac{\\sum_{0 \\le u  v \\le N-1} W_{uv}\\, d_{\\pi(u),\\pi(v)}}{\\sum_{0 \\le u  v \\le N-1} W_{uv}}\n$$\n设分子为总成本函数 $C(\\pi) = \\sum_{0 \\le u  v \\le N-1} W_{uv}\\, d_{\\pi(u),\\pi(v)}$，分母为总通信权重 $S_W = \\sum_{0 \\le u  v \\le N-1} W_{uv}$。由于对于给定的矩阵 $W$，$S_W$ 是一个常数，因此最小化平均跳数 $H(\\pi)$ 等同于最小化总成本 $C(\\pi)$。\n\n解决策略包括对每个测试用例执行以下步骤：\n1. **构建距离矩阵 $D$**：使用提供的芯片坐标，计算所有芯片对 $(j, k)$ 之间的曼哈顿距离 $d_{jk}$。该矩阵是对称的，对角线为零。\n2. **计算总权重 $S_W$**：对通信矩阵 $W$ 的严格上三角部分求和以得到 $S_W$。如果 $S_W=0$，则跳数未定义，但可视为 $0$，导致 $\\Delta=0$。对于所有提供的测试用例，$S_W  0$。\n3. **计算基线成本**：基线映射是恒等排列 $\\pi_0(u) = u$。相应的总成本计算为 $C(\\pi_0) = \\sum_{0 \\le u  v \\le N-1} W_{uv} d_{uv}$。\n4. **寻找最优成本**：对 $\\{0, 1, \\dots, N-1\\}$ 的所有 $N!$ 个排列进行穷举搜索。对于每个排列 $\\pi$，我们计算其总成本 $C(\\pi)$。在所有排列中找到的最小成本被指定为 $C(\\pi^\\star) = \\min_{\\pi} C(\\pi)$。\n5. **计算减少量 $\\Delta$**：平均跳数的减少量是基线平均跳数与最优平均跳数之差：\n$$\n\\Delta = H(\\pi_0) - H(\\pi^\\star) = \\frac{C(\\pi_0)}{S_W} - \\frac{C(\\pi^\\star)}{S_W} = \\frac{C(\\pi_0) - C(\\pi^\\star)}{S_W}\n$$\n每个测试用例的最终结果四舍五入到小数点后恰好 4 位。\n\n该实现封装了这一逻辑。一个主函数通过调用一个核心计算例程来处理每个测试用例。该例程使用 `itertools.permutations` 来生成所有可能的映射 $\\pi$，并系统地找到最小化总成本 $C(\\pi)$ 的映射，从而确保最终计算出的减少量 $\\Delta$ 的正确性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import...\nfrom itertools import permutations\n\ndef solve():\n    \"\"\"\n    Solves the topology-aware mapping problem for all test cases.\n    \"\"\"\n\n    def create_w_case3(N):\n        \"\"\"Creates the communication matrix W for Test Case 3.\"\"\"\n        W = np.zeros((N, N))\n        edges = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n        weight = 20.0\n        for u, v in edges:\n            W[u, v] = W[v, u] = weight\n        return W\n\n    def create_w_case4(N):\n        \"\"\"Creates the communication matrix W for Test Case 4.\"\"\"\n        W = np.zeros((N, N))\n        weight = 10.0\n        for v in range(1, N):\n            W[0, v] = W[v, 0] = weight\n        return W\n\n    test_cases = [\n        {\n            \"N\": 4,\n            \"coords\": np.array([[0, 0], [1, 0], [0, 1], [1, 1]]),\n            \"W\": np.array([\n                [0, 1, 1, 12],\n                [1, 0, 12, 1],\n                [1, 12, 0, 1],\n                [12, 1, 1, 0]\n            ], dtype=float)\n        },\n        {\n            \"N\": 4,\n            \"coords\": np.array([[0, 0], [1, 0], [0, 1], [1, 1]]),\n            \"W\": np.array([\n                [0, 5, 5, 5],\n                [5, 0, 5, 5],\n                [5, 5, 0, 5],\n                [5, 5, 5, 0]\n            ], dtype=float)\n        },\n        {\n            \"N\": 6,\n            \"coords\": np.array([[0, 0], [1, 0], [2, 0], [0, 1], [1, 1], [2, 1]]),\n            \"W\": create_w_case3(6)\n        },\n        {\n            \"N\": 8,\n            \"coords\": np.array([[0, 0], [1, 0], [2, 0], [3, 0], [0, 1], [1, 1], [2, 1], [3, 1]]),\n            \"W\": create_w_case4(8)\n        }\n    ]\n\n    def calculate_delta(N, coords, W):\n        \"\"\"\n        Calculates the reduction in average hop count for a single test case.\n        \"\"\"\n        # Step 1: Construct the distance matrix D using Manhattan distance\n        D = np.zeros((N, N))\n        for j in range(N):\n            for k in range(j + 1, N):\n                dist = np.sum(np.abs(coords[j] - coords[k]))\n                D[j, k] = D[k, j] = dist\n\n        # Step 2: Sum the upper triangle of W to find the total weight S_W\n        upper_tri_indices = np.triu_indices(N, k=1)\n        total_weight = np.sum(W[upper_tri_indices])\n\n        if total_weight == 0:\n            return 0.0\n\n        # Helper function to compute the cost numerator for a given mapping pi\n        def calculate_cost_numerator(pi):\n            cost_num = 0.0\n            for u, v in zip(upper_tri_indices[0], upper_tri_indices[1]):\n                chip_u, chip_v = pi[u], pi[v]\n                cost_num += W[u, v] * D[chip_u, chip_v]\n            return cost_num\n\n        # Step 3: Calculate baseline cost\n        pi_0 = tuple(range(N))\n        cost_base = calculate_cost_numerator(pi_0)\n\n        # Step 4: Find the optimal cost by exhaustive search\n        min_cost = float('inf')\n        for pi in permutations(range(N)):\n            current_cost = calculate_cost_numerator(pi)\n            if current_cost  min_cost:\n                min_cost = current_cost\n        \n        cost_opt = min_cost\n\n        # Step 5: Compute the reduction Delta\n        delta = (cost_base - cost_opt) / total_weight\n        return delta\n\n    results = []\n    for case in test_cases:\n        delta = calculate_delta(case[\"N\"], case[\"coords\"], case[\"W\"])\n        results.append(f\"{delta:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "能效是神经形态计算相较于传统计算的核心优势之一。为了准确评估和比较不同架构的能效，我们需要一个统一且有物理意义的度量标准。这个练习将带你从功率（能量的时间变化率）和脉冲发放率（脉冲计数的时间变化率）的基本定义出发，推导出评估神经形态系统能效的关键指标——平均每脉冲能量。你将运用此公式，基于给定的稳态功率和脉冲发放率数据，计算并比较 SpiNNaker、Loihi、TrueNorth 和 BrainScaleS 四个平台的能效，从而深入理解它们在实际工作负载下的能量消耗特性。",
            "id": "4049260",
            "problem": "考虑一个脉冲神经网络，其所有神经元的总输出脉冲率稳定在 $r=10^{6}\\,\\text{s}^{-1}$。该网络在四个大规模神经拟态平台上执行：脉冲神经网络架构 (SpiNNaker)、英特尔Loihi神经拟态研究芯片 (Loihi)、IBM TrueNorth神经拟态专用集成电路 (TrueNorth) 以及海德堡BrainScaleS加速混合信号神经拟态系统 (BrainScaleS)。对于此工作负载，由脉冲处理引起的动态功率（即，不包括平台特定的空闲或基线功率）经测量为 $P_{\\text{SpiNNaker}}=2.4\\,\\text{W}$，$P_{\\text{Loihi}}=0.06\\,\\text{W}$，$P_{\\text{TrueNorth}}=0.02\\,\\text{W}$ 以及 $P_{\\text{BrainScaleS}}=0.15\\,\\text{W}$。\n\n仅从功率是能量传输的时间速率和脉冲率是脉冲计数的时间速率这两个基本定义出发，推导以稳态功率和稳态脉冲率表示的平均每脉冲能量的表达式。然后，使用推导出的表达式和给定值，计算每个平台的平均每脉冲能量。将每脉冲能量以 $\\text{J}/\\text{spike}$ 为单位表示，并将每个值四舍五入到三位有效数字。将您的四个数值结果按 $(\\text{SpiNNaker},\\,\\text{Loihi},\\,\\text{TrueNorth},\\,\\text{BrainScaleS})$ 的顺序以单行矩阵的形式呈现。",
            "solution": "瞬时功率的基本定义是 $P(t)=\\frac{dE(t)}{dt}$，其中 $E(t)$ 是到时间 $t$ 为止消耗的累积能量。在稳态操作下，我们假设功率是时不变的，因此在感兴趣的时间区间内 $P(t)=P$ 是一个常数。脉冲率定义为 $r(t)=\\frac{dN(t)}{dt}$，其中 $N(t)$ 是到时间 $t$ 为止的累积脉冲计数。在稳态操作下，脉冲率也是时不变的，因此 $r(t)=r$ 是一个常数。\n\n平均每脉冲能量，记为 $E_{\\text{spike}}$，是指平均单个脉冲所关联的能量。形式上，考虑无穷小能量增量与无穷小脉冲计数增量之比，\n$$\nE_{\\text{spike}}=\\frac{dE}{dN}.\n$$\n根据关于时间的链式法则，\n$$\n\\frac{dE}{dN}=\\frac{\\frac{dE}{dt}}{\\frac{dN}{dt}}=\\frac{P}{r}.\n$$\n因此，在稳态功率 $P$ 和稳态脉冲率 $r$ 下，平均每脉冲能量为\n$$\nE_{\\text{spike}}=\\frac{P}{r}.\n$$\n\n我们现在将此表达式应用于每个平台，使用 $r=10^{6}\\,\\text{s}^{-1}$ 和给定的动态功率。对于 SpiNNaker，\n$$\nE_{\\text{spike,SpiNNaker}}=\\frac{P_{\\text{SpiNNaker}}}{r}=\\frac{2.4\\,\\text{W}}{10^{6}\\,\\text{s}^{-1}}=2.4\\times 10^{-6}\\,\\text{J}/\\text{spike}.\n$$\n对于 Loihi，\n$$\nE_{\\text{spike,Loihi}}=\\frac{P_{\\text{Loihi}}}{r}=\\frac{0.06\\,\\text{W}}{10^{6}\\,\\text{s}^{-1}}=6.0\\times 10^{-8}\\,\\text{J}/\\text{spike}.\n$$\n对于 TrueNorth，\n$$\nE_{\\text{spike,TrueNorth}}=\\frac{P_{\\text{TrueNorth}}}{r}=\\frac{0.02\\,\\text{W}}{10^{6}\\,\\text{s}^{-1}}=2.0\\times 10^{-8}\\,\\text{J}/\\text{spike}.\n$$\n对于 BrainScaleS，\n$$\nE_{\\text{spike,BrainScaleS}}=\\frac{P_{\\text{BrainScaleS}}}{r}=\\frac{0.15\\,\\text{W}}{10^{6}\\,\\text{s}^{-1}}=1.5\\times 10^{-7}\\,\\text{J}/\\text{spike}.\n$$\n\n将每个值四舍五入到三位有效数字，保留显示的形式：$2.40\\times 10^{-6}\\,\\text{J}/\\text{spike}$，$6.00\\times 10^{-8}\\,\\text{J}/\\text{spike}$，$2.00\\times 10^{-8}\\,\\text{J}/\\text{spike}$ 以及 $1.50\\times 10^{-7}\\,\\text{J}/\\text{spike}$。所要求的结果是按 $(\\text{SpiNNaker},\\,\\text{Loihi},\\,\\text{TrueNorth},\\,\\text{BrainScaleS})$ 顺序排列的行矩阵。",
            "answer": "$$\\boxed{\\begin{pmatrix}2.40 \\times 10^{-6}  6.00 \\times 10^{-8}  2.00 \\times 10^{-8}  1.50 \\times 10^{-7}\\end{pmatrix}}$$"
        }
    ]
}