{
    "hands_on_practices": [
        {
            "introduction": "训练脉冲神经网络（SNN）因其脉冲生成的不可微特性而带来独特的挑战。本练习深入探讨了代理梯度法，这是一项关键技术，它使得在SNN中进行基于梯度的优化成为可能 。通过完成该推导和数值示例，您将具体理解学习信号在神经形态硬件上是如何计算的。",
            "id": "4045055",
            "problem": "一个参与联邦学习（Federated Learning, FL）的神经形态边缘客户端在本地训练一个渗漏整合发放（Leaky Integrate-and-Fire, LIF）神经元，并仅通过联邦平均（Federated Averaging, FedAvg）通信权重更新。该神经元在单个离散时间步内接收一个突触前事件，并使用代理梯度以实现基于梯度的学习。神经元的膜电位遵循连续时间LIF动力学：$$\\tau_{m} \\frac{dV(t)}{dt} = -\\left(V(t) - V_{\\mathrm{rest}}\\right) + R I(t),$$ 其中 $\\tau_{m}$ 是膜时间常数，$V_{\\mathrm{rest}}$ 是静息电位，$R$ 是膜电阻，$I(t)$ 是突触输入电流。使用步长为 $\\Delta t$ 的前向欧拉法，任何复位前的单步更新为：$$V_{1} = \\alpha V_{0} + w x_{1}, \\quad \\text{其中} \\quad \\alpha = \\exp\\!\\left(-\\frac{\\Delta t}{\\tau_{m}}\\right),$$ $w$ 是突触权重，$x_{1}$ 是该时间步内的突触前输入幅度。如果神经元的复位前膜电位超过阈值，它会发放一个脉冲，这由亥维赛函数（Heaviside function）建模：$$s_{1} = H\\!\\left(V_{1} - v_{\\mathrm{th}}\\right),$$ 其中 $v_{\\mathrm{th}}$ 是阈值。此客户端上单个步长样本的本地训练损失为：$$L = \\frac{1}{2}\\left(s_{1} - y\\right)^{2},$$ 目标为 $y \\in \\{0,1\\}$。为了实现可微性，在反向传播中，亥维赛函数被一个尺度为 $a > 0$ 的逻辑斯蒂代理函数替代：$$\\tilde{H}(u) = \\sigma\\!\\left(\\frac{u}{a}\\right), \\quad \\sigma(z) = \\frac{1}{1 + \\exp(-z)},$$ 因此用于反向传播的代理导数为：$$\\rho(u) = \\frac{d}{du}\\tilde{H}(u) = \\frac{1}{a}\\,\\sigma\\!\\left(\\frac{u}{a}\\right)\\left[1 - \\sigma\\!\\left(\\frac{u}{a}\\right)\\right].$$\n\n仅从这些定义和链式法则出发，推导梯度 $\\frac{\\partial L}{\\partial w}$ 关于 $x_{1}$、$y$、$v_{\\mathrm{th}}$、$V_{1}$ 和 $a$ 的解析表达式。然后，对于此客户端上的一个单脉冲案例，其参数为：$$\\tau_{m} = 20\\,\\mathrm{ms}, \\quad \\Delta t = 1\\,\\mathrm{ms}, \\quad V_{0} = 0, \\quad v_{\\mathrm{th}} = 1.0, \\quad w = 0.8, \\quad x_{1} = 1.5, \\quad y = 0, \\quad a = 0.5,$$ 使用代理梯度和上述单步前向动力学计算 $\\frac{\\partial L}{\\partial w}$ 的数值。将最终数值答案四舍五入到四位有效数字，并以无量纲数表示。",
            "solution": "问题要求分为两部分：首先，使用代理梯度法推导损失函数相对于突触权重 $\\frac{\\partial L}{\\partial w}$ 的解析表达式；其次，为一组特定参数计算该梯度的数值。\n\n对问题陈述的验证证实了其科学依据充分、定义明确，并包含继续进行所需的所有必要信息。该问题描述了使用代理梯度训练脉冲神经网络（SNN）的标准场景，这是神经形态计算中一种有效且成熟的技术。\n\n**第1部分：梯度 $\\frac{\\partial L}{\\partial w}$ 的解析推导**\n\n本地损失函数 $L$ 定义为：\n$$L = \\frac{1}{2}(s_1 - y)^2$$\n其中 $s_1$ 是神经元的输出脉冲，$y$ 是目标标签，$w$ 是突触权重，$x_1$ 是输入。输出脉冲 $s_1$ 是膜电位 $V_1$ 的函数，而 $V_1$ 又是权重 $w$ 的函数。具体来说：\n$$s_1 = H(V_1 - v_{\\mathrm{th}})$$\n$$V_1 = \\alpha V_0 + w x_1$$\n这里，$H$ 是亥维赛阶跃函数，$v_{\\mathrm{th}}$ 是发放阈值，$V_0$ 是初始电位，$\\alpha$ 是膜电位衰减因子。\n\n我们希望计算梯度 $\\frac{\\partial L}{\\partial w}$。根据微分的链式法则，我们可以将此梯度表示为三个偏导数的乘积：\n$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial s_1} \\frac{\\partial s_1}{\\partial V_1} \\frac{\\partial V_1}{\\partial w}$$\n\n让我们分别计算每一项。\n\n1.  **损失相对于输出脉冲的导数，$\\frac{\\partial L}{\\partial s_1}$**：\n    根据 $L$ 的定义，我们有：\n    $$\\frac{\\partial L}{\\partial s_1} = \\frac{\\partial}{\\partial s_1} \\left[ \\frac{1}{2}(s_1 - y)^2 \\right] = 2 \\cdot \\frac{1}{2}(s_1 - y) = s_1 - y$$\n\n2.  **膜电位相对于权重的导数，$\\frac{\\partial V_1}{\\partial w}$**：\n    根据 $V_1$ 的单步更新方程，我们有：\n    $$\\frac{\\partial V_1}{\\partial w} = \\frac{\\partial}{\\partial w} (\\alpha V_0 + w x_1)$$\n    由于 $\\alpha$、$V_0$ 和 $x_1$ 都不是 $w$ 的函数，因此可以简化为：\n    $$\\frac{\\partial V_1}{\\partial w} = x_1$$\n\n3.  **输出脉冲相对于膜电位的导数，$\\frac{\\partial s_1}{\\partial V_1}$**：\n    前向传播的输出由 $s_1 = H(V_1 - v_{\\mathrm{th}})$ 给出。亥维赛函数的导数是狄拉克δ函数，它几乎处处为零，并且在原点处无定义。这给基于梯度的优化带来了问题。代理梯度法通过在反向传播中用一个连续、性质良好的代理函数 $\\rho(u)$ 替换 $H(u)$ 的不可微导数来解决这个问题。问题将此代理导数定义为：\n    $$\\rho(u) = \\frac{1}{a} \\sigma\\left(\\frac{u}{a}\\right) \\left[1 - \\sigma\\left(\\frac{u}{a}\\right)\\right]$$\n    其中 $u = V_1 - v_{\\mathrm{th}}$。因此，为了反向传播，我们进行替换：\n    $$\\frac{\\partial s_1}{\\partial V_1} \\approx \\rho(V_1 - v_{\\mathrm{th}})$$\n\n将这三项结合起来，我们得到损失相对于权重的梯度表达式：\n$$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\cdot \\rho(V_1 - v_{\\mathrm{th}}) \\cdot x_1$$\n代入 $\\rho(u)$ 的定义，我们得到完整的解析表达式：\n$$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\left( \\frac{1}{a} \\sigma\\left(\\frac{V_1 - v_{\\mathrm{th}}}{a}\\right) \\left[1 - \\sigma\\left(\\frac{V_1 - v_{\\mathrm{th}}}{a}\\right)\\right] \\right) x_1$$\n这里，$s_1$ 是在前向传播过程中计算的值，即 $s_1 = H(V_1 - v_{\\mathrm{th}})$。该表达式按要求用 $x_1$、$y$、$v_{\\mathrm{th}}$、$V_1$ 和 $a$ 表示，其中 $s_1$ 由 $V_1$ 和 $v_{\\mathrm{th}}$ 决定。\n\n**第2部分：梯度的数值计算**\n\n给定以下参数：\n$\\tau_{m} = 20\\,\\mathrm{ms}$，$\\Delta t = 1\\,\\mathrm{ms}$，$V_{0} = 0$，$v_{\\mathrm{th}} = 1.0$，$w = 0.8$，$x_{1} = 1.5$，$y = 0$，$a = 0.5$。\n\n计算按步骤进行，遵循前向和反向传播的逻辑。\n\n1.  **计算膜电位 $V_1$（前向传播）**：\n    首先，我们确定衰减因子 $\\alpha$：\n    $$\\alpha = \\exp\\left(-\\frac{\\Delta t}{\\tau_{m}}\\right) = \\exp\\left(-\\frac{1\\,\\mathrm{ms}}{20\\,\\mathrm{ms}}\\right) = \\exp(-0.05)$$\n    现在，我们计算复位前的膜电位 $V_1$：\n    $$V_1 = \\alpha V_0 + w x_1 = \\exp(-0.05) \\cdot 0 + (0.8)(1.5) = 1.2$$\n\n2.  **计算输出脉冲 $s_1$（前向传播）**：\n    输出脉冲通过比较 $V_1$ 和阈值 $v_{\\mathrm{th}}$ 来确定：\n    $$s_1 = H(V_1 - v_{\\mathrm{th}}) = H(1.2 - 1.0) = H(0.2)$$\n    由于参数为正，亥维赛函数的值为 $1$：\n    $$s_1 = 1$$\n\n3.  **计算梯度分量（反向传播）**：\n    我们现在使用推导出的 $\\frac{\\partial L}{\\partial w}$ 公式：\n    $$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\cdot \\rho(V_1 - v_{\\mathrm{th}}) \\cdot x_1$$\n    -   误差项为 $(s_1 - y) = 1 - 0 = 1$。\n    -   输入项为 $x_1 = 1.5$。\n    -   代理梯度项为 $\\rho(V_1 - v_{\\mathrm{th}}) = \\rho(0.2)$。我们来计算这个值。\n        sigmoid 函数的参数是 $u/a = (V_1 - v_{\\mathrm{th}})/a = 0.2 / 0.5 = 0.4$。\n        sigmoid 函数的值为：\n        $$\\sigma(0.4) = \\frac{1}{1 + \\exp(-0.4)} \\approx \\frac{1}{1 + 0.670320046} \\approx \\frac{1}{1.670320046} \\approx 0.59868766$$\n        现在我们可以计算代理导数 $\\rho(0.2)$ 的值：\n        $$\\rho(0.2) = \\frac{1}{a} \\sigma(0.4) [1 - \\sigma(0.4)] = \\frac{1}{0.5} (0.59868766) [1 - 0.59868766]$$\n        $$\\rho(0.2) = 2 \\cdot (0.59868766) \\cdot (0.40131234) \\approx 0.4805084$$\n\n4.  **组合以求得最终梯度**：\n    $$\\frac{\\partial L}{\\partial w} = (1) \\cdot (0.4805084) \\cdot (1.5) = 0.7207626$$\n\n5.  **四舍五入到四位有效数字**：\n    计算值为 $0.7207626$。四舍五入到四位有效数字得到 $0.7208$。",
            "answer": "$$\n\\boxed{0.7208}\n$$"
        },
        {
            "introduction": "联邦学习的核心在于聚合过程，即中央服务器智能地合并来自多个客户端的模型更新。本练习专注于推导联邦平均（Federated Averaging）等算法中使用的基础加权方案，以确保全局更新能够正确地代表集体的知识 。理解这一原则对于构建有效且理论上合理的联邦系统至关重要，尤其是在客户端数据分布不均的情况下。",
            "id": "4045019",
            "problem": "考虑一个由$K$个神经形态边缘客户端组成的同步联邦学习系统，每个客户端都运行一个使用代理梯度随机梯度下降训练的脉冲神经网络。客户端 $k \\in \\{1,\\dots,K\\}$ 持有大小为 $n_k$ 的本地数据集 $\\mathcal{D}_k$，且满足 $\\sum_{k=1}^{K} n_k = N$。假设以下基本条件成立：\n- 各客户端的数据是独立同分布 (IID) 的：每个 $\\mathcal{D}_k$ 由从相同的数据-标签对 $(\\mathbf{x}, y)$ 分布中抽取的 $n_k$ 个独立样本组成。\n- 单样本脉冲损失 $\\ell(w; \\mathbf{x}, y)$ 在经过代理松弛后对 $w$ 是可微的，并且在神经形态硬件上计算的代理梯度估计器 $\\widehat{\\nabla}\\ell(w; \\mathbf{x}, y)$ 是无偏的，即 $\\mathbb{E}[\\widehat{\\nabla}\\ell(w; \\mathbf{x}, y)] = \\nabla \\ell(w; \\mathbf{x}, y)$，其中期望是针对数据采样和硬件引入的随机性（例如，量化和事件噪声）计算的。\n- 在给定的一个轮次中，每个客户端计算其本地经验梯度为 $g_k(w) = \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z)$，其中 $z = (\\mathbf{x}, y)$。\n\n在数据集并集 $\\mathcal{D} = \\bigcup_{k=1}^{K} \\mathcal{D}_k$ 上的中心化经验风险为 $L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\ell(w; z)$，其相应的中心化经验梯度为 $\\nabla L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla \\ell(w; z)$。\n\n参数服务器使用权重 $p_k \\ge 0$（满足 $\\sum_{k=1}^{K} p_k = 1$）将客户端梯度聚合成一个单一的更新方向，生成聚合梯度 $g_{\\mathrm{agg}}(w) = \\sum_{k=1}^{K} p_k \\, g_k(w)$ 和全局更新 $w^{+} = w - \\eta \\, g_{\\mathrm{agg}}(w)$，其中 $\\eta > 0$ 是一个公共学习率。\n\n仅根据上述定义以及独立同分布和无偏性假设，确定权重 $p_k$ 作为数据集大小 $n_k$ 的函数，使得聚合梯度的期望等于中心化经验梯度，即 $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$。然后通过显式推导验证该等式。\n\n请以关于 $\\{n_k\\}_{k=1}^{K}$ 的单一闭式解析表达式形式提供您的最终答案，无需四舍五入，也无单位。最终答案中请勿包含任何中间步骤。",
            "solution": "该问题陈述已经过验证，被认为是有效的。它具有科学依据、问题适定、客观且内部一致。它提出了联邦学习领域中的一个标准理论问题，具体涉及推导聚合权重，以确保聚合梯度是中心化经验梯度的无偏估计量。\n\n目标是找到对于 $k \\in \\{1, \\dots, K\\}$ 的权重系数 $p_k$，使其满足条件 $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$。期望 $\\mathbb{E}[\\cdot]$ 是针对代理梯度估计器中由硬件引入的随机性计算的。对于此期望，数据集 $\\{\\mathcal{D}_k\\}_{k=1}^{K}$ 被视为固定的。\n\n我们首先展开目标等式的左侧 (LHS)，即期望聚合梯度 $\\mathbb{E}[g_{\\mathrm{agg}}(w)]$。根据聚合梯度 $g_{\\mathrm{agg}}(w) = \\sum_{k=1}^{K} p_k \\, g_k(w)$ 的定义和期望算子的线性性质，我们有：\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\mathbb{E}\\left[ \\sum_{k=1}^{K} p_k \\, g_k(w) \\right] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}[g_k(w)]\n$$\n接下来，我们代入本地经验梯度 $g_k(w) = \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z)$ 的定义：\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}\\left[ \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z) \\right]\n$$\n根据期望的线性性质，我们可以将期望算子移入对本地数据集 $\\mathcal{D}_k$ 的求和中：\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)]\n$$\n问题陈述指出，对于任意给定的数据样本 $z = (\\mathbf{x}, y)$，代理梯度估计器是无偏的，即 $\\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)] = \\nabla \\ell(w; z)$。应用此假设，我们得到：\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} \\frac{p_k}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)\n$$\n现在，我们分析目标等式的右侧 (RHS)，即中心化经验梯度 $\\nabla L_N(w)$。根据其定义，$\\nabla L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla \\ell(w; z)$。总数据集 $\\mathcal{D}$ 是本地数据集的并集，即 $\\mathcal{D} = \\bigcup_{k=1}^{K} \\mathcal{D}_k$。假设本地数据集是不相交的，我们可以将对 $\\mathcal{D}$ 的求和重写为对各本地数据集的求和：\n$$\n\\nabla L_N(w) = \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla \\ell(w; z)\n$$\n为了满足问题的要求，我们将推导出的 LHS 表达式与 RHS 相等：\n$$\n\\sum_{k=1}^{K} \\frac{p_k}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) = \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla \\ell(w; z)\n$$\n这个方程可以重新整理成一个单一的求和式：\n$$\n\\sum_{k=1}^{K} \\left( \\frac{p_k}{n_k} - \\frac{1}{N} \\right) \\left( \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) \\right) = 0\n$$\n该等式必须对任意本地数据集集合 $\\{\\mathcal{D}_k\\}$ 和任意模型参数 $w$ 成立。代表本地梯度和的向量 $\\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)$ 可以是线性无关的。为了在如此一般的条件下使总和为零向量，每个向量项的标量系数必须为零。因此，对于每个客户端 $k \\in \\{1, \\dots, K\\}$，我们必须有：\n$$\n\\frac{p_k}{n_k} - \\frac{1}{N} = 0\n$$\n解出 $p_k$ 可得：\n$$\np_k = \\frac{n_k}{N}\n$$\n问题定义了 $N = \\sum_{j=1}^{K} n_j$。因此，权重与本地数据集的大小成正比。我们验证这些权重是否满足约束条件 $\\sum_{k=1}^{K} p_k = 1$：\n$$\n\\sum_{k=1}^{K} p_k = \\sum_{k=1}^{K} \\frac{n_k}{N} = \\frac{1}{N} \\sum_{k=1}^{K} n_k = \\frac{N}{N} = 1\n$$\n该约束得到满足。由于 $n_k \\ge 0$（数据集大小）且 $N > 0$，条件 $p_k \\ge 0$ 也被满足。值得注意的是，虽然给出了独立同分布 (IID) 的数据假设，但要建立期望聚合梯度和中心化经验梯度之间的这一特定等式，该假设并非必需。然而，IID 属性对于确保中心化经验梯度本身是真实全局总体梯度的无偏估计至关重要。\n\n最后，我们执行问题所要求的显式验证。我们将 $p_k = n_k/N$ 代回期望聚合梯度的表达式中：\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}[g_k(w)] = \\sum_{k=1}^{K} \\frac{n_k}{N} \\, \\mathbb{E}\\left[ \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z) \\right]\n$$\n$$\n= \\sum_{k=1}^{K} \\frac{n_k}{N} \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)] = \\sum_{k=1}^{K} \\frac{1}{N} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)\n$$\n$$\n= \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla\\ell(w; z) = \\nabla L_N(w)\n$$\n该验证确认，当选择 $p_k = n_k/N$ 时，等式 $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$ 成立。因此，解为 $p_k = \\frac{n_k}{\\sum_{j=1}^{K} n_j}$。",
            "answer": "$$\\boxed{\\frac{n_k}{\\sum_{j=1}^{K} n_j}}$$"
        },
        {
            "introduction": "在资源受限的神经形态设备上部署联邦学习，需要对能源消耗进行精细管理。本练习引入了一个现实的优化问题，旨在捕捉设备本地计算与网络通信之间的基本权衡 。通过求解最优的本地训练轮数和通信回合数，您将学会如何设计高能效的联邦学习系统，以便在给定的预算内最大化学习性能。",
            "id": "4044985",
            "problem": "考虑一个在神经形态边缘硬件上使用脉冲神经网络（SNN）实现的跨设备联邦学习（FL）系统。系统共有 $R$ 个通信轮次；在每个轮次中，一个代表性客户端在单次传达其模型更新之前，会执行 $E$ 个本地轮次的训练。假设客户端之间存在对称性，因此对单个客户端的分析就足够了。\n\n硬件能耗模型：\n- 每个本地轮次处理 $n$ 个样本，每个样本平均产生 $s$ 个突触事件。每个突触事件的能量是 $e_s$ 焦耳，因此每个本地轮次的计算能耗为 $c \\equiv e_s \\, n \\, s$。\n- 在每个通信轮次中，客户端总共发送和接收 $L$ 位，每比特的通信能耗是 $e_c$ 焦耳，因此每轮通信的通信能耗为 $d \\equiv e_c \\, L$。\n\n能量预算：\n- 在整个训练过程中，单个客户端的总能耗为 $R \\big(E c + d\\big)$，该值不得超过一个固定的预算 $B$，即 $R \\big(E c + d\\big) \\le B$。\n\n学习理论目标：\n- 对于客户端间数据异构的随机优化问题，在标准的平滑性和有界方差假设下，经过 $R$ 个通信轮次（每轮次包含 $E$ 个本地轮次）后，期望最优性差距的一个常用上界具有以下形式\n$$\n\\Delta(E,R) \\le \\frac{\\alpha}{R E} + \\beta E,\n$$\n其中 $\\alpha > 0$ 聚合了平滑度、步长和梯度噪声常数，而 $\\beta > 0$ 聚合了由多个本地步骤引起的客户端漂移和异构性常数。\n\n构建并求解以下约束优化问题，以确定能在能量预算约束下最小化该上界的实值正数对 $(E^{\\star}, R^{\\star})$：\n$$\n\\min_{E > 0, \\, R > 0} \\; \\frac{\\alpha}{R E} + \\beta E \\quad \\text{约束条件为} \\quad R \\big(E c + d\\big) \\le B.\n$$\n请用 $\\alpha$、$\\beta$、$B$、$c$ 和 $d$ 将 $E^{\\star}$ 和 $R^{\\star}$ 的最终答案表示为精确的闭式符号表达式（并回想 $c \\equiv e_s n s$，$d \\equiv e_c L$）。无需进行数值评估。请按 $(E^{\\star}, R^{\\star})$ 的顺序以数对形式提供您的答案。由于答案是符号形式，因此无需四舍五入。最终表达式中不应包含任何单位（如果有）。",
            "solution": "所述问题是有效的。这是一个适定的约束优化问题，其基础是联邦学习和能耗分析的既有模型。所有术语都得到了明确定义，不存在科学或逻辑上的矛盾。\n\n该优化问题旨在寻找能解出以下问题的正实数对 $(E^{\\star}, R^{\\star})$：\n$$\n\\min_{E > 0, \\, R > 0} \\; f(E,R) = \\frac{\\alpha}{R E} + \\beta E\n$$\n约束条件为：\n$$\ng(E,R) = R \\big(E c + d\\big) \\le B\n$$\n所有参数 $\\alpha$、$\\beta$、$B$、$c$ 和 $d$ 均为给定的正常数。\n\n首先，我们分析问题的结构。目标函数 $f(E,R)$ 由两项组成。对于任何固定的 $E > 0$ 值，函数 $f(E,R)$ 是一个关于 $R$ 的严格递减函数，因为当 $R$ 增加时，项 $\\frac{\\alpha}{RE}$ 减小，而项 $\\beta E$ 保持不变。\n\n这一观察意味着，为了最小化 $f(E,R)$，我们应使 $R$ 在约束允许的范围内尽可能大。如果存在一个最优解 $(E, R)$ 使得约束不处于活动状态，即 $R(Ec+d)  B$，我们总可以将 $R$ 增加到一个新值 $R' = \\frac{B}{Ec+d}$。这个 $R'$ 会大于 $R$，使约束以等式形式满足，并会产生一个更小的目标函数值，即 $f(E, R')  f(E, R)$。因此，任何最优解 $(E^{\\star}, R^{\\star})$ 都必须位于可行集的边界上，这意味着能量约束必须是活动的（饱和的）。\n$$\nR^{\\star} \\big(E^{\\star} c + d\\big) = B\n$$\n这使我们可以用一个变量来表示另一个变量。我们可以将 $R$ 写成 $E$ 的函数：\n$$\nR(E) = \\frac{B}{E c + d}\n$$\n现在，我们可以将这个 $R$ 的表达式代入目标函数，从而将这个双变量的约束优化问题转化为一个单变量 $E$ 的无约束优化问题。\n设新的目标函数为 $h(E) = f(E, R(E))$：\n$$\nh(E) = \\frac{\\alpha}{R(E) E} + \\beta E = \\frac{\\alpha}{\\left(\\frac{B}{Ec + d}\\right) E} + \\beta E\n$$\n化简 $h(E)$ 的表达式：\n$$\nh(E) = \\frac{\\alpha (Ec + d)}{B E} + \\beta E = \\frac{\\alpha Ec}{B E} + \\frac{\\alpha d}{B E} + \\beta E\n$$\n$$\nh(E) = \\frac{\\alpha c}{B} + \\frac{\\alpha d}{B E} + \\beta E\n$$\n为了找到最小化 $h(E)$ 的 $E$ 值，我们计算它关于 $E$ 的导数，并将其设为零。项 $\\frac{\\alpha c}{B}$ 是一个常数，因此它不影响最小值的位置。\n$$\n\\frac{dh}{dE} = \\frac{d}{dE} \\left( \\frac{\\alpha c}{B} + \\frac{\\alpha d}{B} E^{-1} + \\beta E \\right) = -\\frac{\\alpha d}{B} E^{-2} + \\beta\n$$\n将导数设为零，以求得最优值 $E^{\\star}$：\n$$\n-\\frac{\\alpha d}{B (E^{\\star})^2} + \\beta = 0\n$$\n$$\n\\beta = \\frac{\\alpha d}{B (E^{\\star})^2}\n$$\n重新整理以求解 $(E^{\\star})^2$：\n$$\n(E^{\\star})^2 = \\frac{\\alpha d}{\\beta B}\n$$\n由于 $E$ 必须为正，我们取正平方根：\n$$\nE^{\\star} = \\sqrt{\\frac{\\alpha d}{\\beta B}}\n$$\n为了确认这个临界点对应一个最小值，我们检查 $h(E)$ 的二阶导数：\n$$\n\\frac{d^2h}{dE^2} = \\frac{d}{dE} \\left( -\\frac{\\alpha d}{B} E^{-2} + \\beta \\right) = -(-2)\\frac{\\alpha d}{B} E^{-3} = \\frac{2 \\alpha d}{B E^3}\n$$\n鉴于 $\\alpha  0$、$d  0$、$B  0$，并且我们处于 $E  0$ 的定义域内，二阶导数 $\\frac{d^2h}{dE^2}$ 总是正的。这证实了函数 $h(E)$ 对于 $E  0$ 是严格凸的，因此 $E^{\\star}$ 是唯一的全局最小值。\n\n最后，我们通过将 $E^{\\star}$ 代回从活动约束中导出的表达式来找到相应的最优值 $R^{\\star}$：\n$$\nR^{\\star} = \\frac{B}{E^{\\star} c + d}\n$$\n$$\nR^{\\star} = \\frac{B}{c \\sqrt{\\frac{\\alpha d}{\\beta B}} + d}\n$$\n数对 $(E^{\\star}, R^{\\star})$ 代表了在给定能量预算下最小化收敛上界的本地轮次和通信轮次的最佳分配。这些表达式是根据问题的基本参数提供的。\n解对为：\n$$\nE^{\\star} = \\sqrt{\\frac{\\alpha d}{\\beta B}}\n$$\n$$\nR^{\\star} = \\frac{B}{d + c \\sqrt{\\frac{\\alpha d}{\\beta B}}}\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{\\frac{\\alpha d}{\\beta B}}  \\frac{B}{d + c \\sqrt{\\frac{\\alpha d}{\\beta B}}} \\end{pmatrix}}\n$$"
        }
    ]
}