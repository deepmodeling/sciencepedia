{
    "hands_on_practices": [
        {
            "introduction": "To understand how federated learning operates on neuromorphic hardware, we must first master the dynamics of its fundamental processing unit: the artificial neuron. This exercise guides you through deriving the behavior of a Leaky Integrate-and-Fire (LIF) neuron from first principles, connecting the physical model of a simple circuit to the mathematical equations that govern spike timing. Mastering this foundational model is the first step toward building and training complex spiking neural networks. ",
            "id": "4045046",
            "problem": "In a cross-silo federated learning setting, each client deploys a neuromorphic core implementing a single current-based Leaky Integrate-and-Fire (LIF) neuron to encode a local scalar signal as a first-spike latency that will be aggregated server-side. The neuron dynamics are realized by a leaky resistor-capacitor membrane following Kirchhoff’s current law, and are modeled continuously by the ordinary differential equation derived from the resistor-capacitor circuit: the membrane capacitance current plus the leak current equals the injected synaptic current. Let the membrane potential be $V(t)$, the resting potential be $V_{rest}$, the leak resistance be $R$, the membrane time constant be $\\tau_m$, and the constant input current be $I(t)=I_0$ for $t \\ge 0$. The neuron obeys the current-based LIF dynamics with instantaneous reset and hard threshold: when $V(t)$ reaches the threshold $V_{th}$ from below, the neuron emits a spike and $V(t)$ is instantaneously reset to $V_{reset}$. At the beginning of the encoding window, the neuron is assumed to be at the reset potential, i.e., $V(0)=V_{reset}$.\n\nStarting from the resistor-capacitor circuit law and using only first principles (Kirchhoff’s current law and the definition $\\tau_m = R C_m$ for membrane capacitance $C_m$), derive the membrane potential trajectory $V(t)$ for $t \\in [0,t_{sp})$ under the constant input $I(t)=I_0$, where $t_{sp}$ is the first threshold crossing time. Then, solve analytically for the first spike time $t_{sp}$ in terms of the given parameters by enforcing $V(t_{sp})=V_{th}$. Assume $R I_0 > V_{th}-V_{rest}$ and $V_{reset} < V_{th}$ so that a spike occurs in finite time. Express $t_{sp}$ in seconds. Provide your final answer as a single row matrix containing the closed-form expression $V(t)$ and the closed-form expression for $t_{sp}$ in terms of $(\\tau_m, V_{rest}, V_{th}, V_{reset}, R, I_0)$ and the variable $t$. No numerical substitution is required, and no rounding is needed.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in established circuit theory and computational neuroscience, well-posed with sufficient and consistent information, and objectively stated.\n\nThe problem requires the derivation of the membrane potential $V(t)$ for a current-based Leaky Integrate-and-Fire (LIF) neuron and the time of the first spike, $t_{sp}$. The derivation begins from first principles, specifically Kirchhoff's current law applied to a resistor-capacitor (RC) circuit.\n\nThe model consists of a membrane capacitance $C_m$ in parallel with a leak resistance $R$. The total current injected into the neuron, $I(t)$, splits into two paths: the current through the capacitor, $I_C$, and the current through the resistor, $I_R$.\n\nAccording to Kirchhoff's current law, the sum of currents leaving a node must equal the current entering it:\n$$I(t) = I_C(t) + I_R(t)$$\nThe current through the capacitor is given by $I_C(t) = C_m \\frac{dV(t)}{dt}$, where $V(t)$ is the membrane potential. The current through the leak resistance is given by Ohm's law, $I_R(t) = \\frac{V(t) - V_{rest}}{R}$, where $V_{rest}$ is the resting potential across the membrane.\n\nSubstituting these expressions into Kirchhoff's law, we obtain the governing ordinary differential equation (ODE) for the membrane potential:\n$$I(t) = C_m \\frac{dV(t)}{dt} + \\frac{V(t) - V_{rest}}{R}$$\nFor $t \\ge 0$, the input current is a constant, $I(t) = I_0$. The equation becomes:\n$$I_0 = C_m \\frac{dV(t)}{dt} + \\frac{V(t) - V_{rest}}{R}$$\nTo solve this ODE, we rearrange it into a standard linear first-order form. Multiplying the entire equation by $R$ gives:\n$$R I_0 = R C_m \\frac{dV(t)}{dt} + V(t) - V_{rest}$$\nUsing the given definition of the membrane time constant, $\\tau_m = R C_m$, we substitute it into the equation:\n$$\\tau_m \\frac{dV(t)}{dt} + V(t) = V_{rest} + R I_0$$\nThis is a non-homogeneous linear first-order ODE. The general solution can be found by various methods. Let's define the steady-state potential $V_{\\infty} = V_{rest} + R I_0$, which is the potential reached as $t \\to \\infty$ if no spike threshold existed. The ODE can be written as:\n$$\\tau_m \\frac{dV(t)}{dt} = -(V(t) - V_{\\infty})$$\nThe general solution to this equation is of the form:\n$$V(t) = V_{\\infty} + K \\exp\\left(-\\frac{t}{\\tau_m}\\right)$$\nwhere $K$ is a constant of integration determined by the initial conditions. The problem states that the neuron is at its reset potential at time $t=0$, so the initial condition is $V(0) = V_{reset}$. Applying this condition:\n$$V(0) = V_{reset} = V_{\\infty} + K \\exp(0) = V_{\\infty} + K$$\nSolving for $K$:\n$$K = V_{reset} - V_{\\infty} = V_{reset} - (V_{rest} + R I_0)$$\nSubstituting $K$ and $V_{\\infty}$ back into the general solution for $V(t)$, we obtain the specific trajectory for the membrane potential for $t \\in [0, t_{sp})$:\n$$V(t) = (V_{rest} + R I_0) + (V_{reset} - V_{rest} - R I_0) \\exp\\left(-\\frac{t}{\\tau_m}\\right)$$\nThis is the first part of the required answer.\n\nNext, we solve for the time of the first spike, $t_{sp}$. A spike is generated when the membrane potential $V(t)$ reaches the threshold potential $V_{th}$. Thus, we set $V(t_{sp}) = V_{th}$ and solve for $t_{sp}$:\n$$V_{th} = (V_{rest} + R I_0) + (V_{reset} - V_{rest} - R I_0) \\exp\\left(-\\frac{t_{sp}}{\\tau_m}\\right)$$\nWe rearrange the equation to isolate the exponential term:\n$$V_{th} - V_{rest} - R I_0 = (V_{reset} - V_{rest} - R I_0) \\exp\\left(-\\frac{t_{sp}}{\\tau_m}\\right)$$\n$$\\exp\\left(-\\frac{t_{sp}}{\\tau_m}\\right) = \\frac{V_{th} - V_{rest} - R I_0}{V_{reset} - V_{rest} - R I_0}$$\nTo solve for $t_{sp}$, we take the natural logarithm of both sides:\n$$-\\frac{t_{sp}}{\\tau_m} = \\ln\\left(\\frac{V_{th} - V_{rest} - R I_0}{V_{reset} - V_{rest} - R I_0}\\right)$$\nFinally, solving for $t_{sp}$:\n$$t_{sp} = -\\tau_m \\ln\\left(\\frac{V_{th} - V_{rest} - R I_0}{V_{reset} - V_{rest} - R I_0}\\right)$$\nUsing the logarithmic identity $-\\ln(a/b) = \\ln(b/a)$, we can write the expression in a form that avoids the leading negative sign:\n$$t_{sp} = \\tau_m \\ln\\left(\\frac{V_{reset} - V_{rest} - R I_0}{V_{th} - V_{rest} - R I_0}\\right)$$\nThe problem provides the constraints $R I_0 > V_{th} - V_{rest}$ and $V_{reset} < V_{th}$. The first constraint implies $V_{rest} + R I_0 > V_{th}$, ensuring the steady-state potential is above the threshold, which guarantees a spike. This also means the denominator $V_{th} - V_{rest} - R I_0$ is negative. Since $V_{reset} < V_{th} < V_{rest} + R I_0$, the numerator $V_{reset} - V_{rest} - R I_0$ is also negative. The argument of the logarithm is therefore positive. The second constraint $V_{reset} < V_{th}$ ensures the argument of the logarithm is greater than $1$, yielding a positive spike time $t_{sp} > 0$. This completes the derivation for the first spike time.\n\nThe two derived expressions are the complete solution to the problem.",
            "answer": "$$\\boxed{\\begin{pmatrix} V_{rest} + R I_0 + (V_{reset} - V_{rest} - R I_0) \\exp\\left(-\\frac{t}{\\tau_m}\\right) & \\tau_m \\ln\\left(\\frac{V_{reset} - V_{rest} - R I_0}{V_{th} - V_{rest} - R I_0}\\right) \\end{pmatrix}}$$"
        },
        {
            "introduction": "A model is only as powerful as its ability to learn from data. Since the spiking output of a neuron is non-differentiable, standard backpropagation fails, posing a significant challenge for training. This practice introduces the surrogate gradient method, an elegant and powerful technique that makes gradient-based optimization possible for spiking neural networks. By working through this derivation, you will gain hands-on experience with the core mechanism enabling learning on neuromorphic hardware. ",
            "id": "4045055",
            "problem": "A neuromorphic edge client participating in Federated Learning (FL) trains a single Leaky Integrate-and-Fire (LIF) neuron locally and communicates only weight updates via Federated Averaging (FedAvg). The neuron receives a single presynaptic event over one discrete time step and uses a surrogate gradient to enable gradient-based learning. The neuron’s membrane potential obeys the continuous-time LIF dynamics $$\\tau_{m} \\frac{dV(t)}{dt} = -\\left(V(t) - V_{\\mathrm{rest}}\\right) + R I(t),$$ where $\\tau_{m}$ is the membrane time constant, $V_{\\mathrm{rest}}$ is the resting potential, $R$ is the membrane resistance, and $I(t)$ is the synaptic input current. Using forward Euler with step size $\\Delta t$, the one-step update before any reset is $$V_{1} = \\alpha V_{0} + w x_{1}, \\quad \\text{where} \\quad \\alpha = \\exp\\!\\left(-\\frac{\\Delta t}{\\tau_{m}}\\right),$$ $w$ is the synaptic weight, and $x_{1}$ is the presynaptic input amplitude over the step. The neuron emits a spike if its pre-reset membrane potential crosses threshold, modeled by the Heaviside function $$s_{1} = H\\!\\left(V_{1} - v_{\\mathrm{th}}\\right),$$ where $v_{\\mathrm{th}}$ is the threshold. The local training loss on this client for the single-step sample is $$L = \\frac{1}{2}\\left(s_{1} - y\\right)^{2},$$ with target $y \\in \\{0,1\\}$. To enable differentiability, the Heaviside function is replaced in the backward pass by a logistic surrogate with scale $a > 0$, $$\\tilde{H}(u) = \\sigma\\!\\left(\\frac{u}{a}\\right), \\quad \\sigma(z) = \\frac{1}{1 + \\exp(-z)},$$ so that the surrogate derivative used for backpropagation is $$\\rho(u) = \\frac{d}{du}\\tilde{H}(u) = \\frac{1}{a}\\,\\sigma\\!\\left(\\frac{u}{a}\\right)\\left[1 - \\sigma\\!\\left(\\frac{u}{a}\\right)\\right].$$\n\nStarting only from these definitions and the chain rule, derive an analytic expression for the gradient $\\frac{\\partial L}{\\partial w}$ in terms of $x_{1}$, $y$, $v_{\\mathrm{th}}$, $V_{1}$, and $a$. Then, for a single-spike case on this client with parameters $$\\tau_{m} = 20\\,\\mathrm{ms}, \\quad \\Delta t = 1\\,\\mathrm{ms}, \\quad V_{0} = 0, \\quad v_{\\mathrm{th}} = 1.0, \\quad w = 0.8, \\quad x_{1} = 1.5, \\quad y = 0, \\quad a = 0.5,$$ compute the numerical value of $\\frac{\\partial L}{\\partial w}$ using the surrogate gradient and the one-step forward dynamics above. Round your final numerical answer to four significant figures and express it as a dimensionless number.",
            "solution": "The problem asks for two parts: first, to derive an analytic expression for the gradient of the loss function with respect to a synaptic weight, $\\frac{\\partial L}{\\partial w}$, using the surrogate gradient method; and second, to compute the numerical value of this gradient for a specific set of parameters.\n\nThe validation of the problem statement confirms that it is scientifically grounded, well-posed, and contains all necessary information to proceed. The problem describes a standard scenario in training Spiking Neural Networks (SNNs) with surrogate gradients, a valid and established technique in neuromorphic computing.\n\n**Part 1: Analytical Derivation of the Gradient $\\frac{\\partial L}{\\partial w}$**\n\nThe local loss function $L$ is defined as:\n$$L = \\frac{1}{2}(s_1 - y)^2$$\nwhere $s_1$ is the neuron's output spike, $y$ is the target label, $w$ is the synaptic weight, and $x_1$ is the input. The output spike $s_1$ is a function of the membrane potential $V_1$, which in turn is a function of the weight $w$. Specifically:\n$$s_1 = H(V_1 - v_{\\mathrm{th}})$$\n$$V_1 = \\alpha V_0 + w x_1$$\nHere, $H$ is the Heaviside step function, $v_{\\mathrm{th}}$ is the firing threshold, $V_0$ is the initial potential, and $\\alpha$ is the membrane potential decay factor.\n\nWe seek to compute the gradient $\\frac{\\partial L}{\\partial w}$. Using the chain rule for differentiation, we can express this gradient as a product of three partial derivatives:\n$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial s_1} \\frac{\\partial s_1}{\\partial V_1} \\frac{\\partial V_1}{\\partial w}$$\n\nLet us compute each term individually.\n\n1.  **Derivative of the loss with respect to the output spike, $\\frac{\\partial L}{\\partial s_1}$**:\n    From the definition of $L$, we have:\n    $$\\frac{\\partial L}{\\partial s_1} = \\frac{\\partial}{\\partial s_1} \\left[ \\frac{1}{2}(s_1 - y)^2 \\right] = 2 \\cdot \\frac{1}{2}(s_1 - y) = s_1 - y$$\n\n2.  **Derivative of the membrane potential with respect to the weight, $\\frac{\\partial V_1}{\\partial w}$**:\n    From the one-step update equation for $V_1$, we have:\n    $$\\frac{\\partial V_1}{\\partial w} = \\frac{\\partial}{\\partial w} (\\alpha V_0 + w x_1)$$\n    Since $\\alpha$, $V_0$, and $x_1$ are not functions of $w$, this simplifies to:\n    $$\\frac{\\partial V_1}{\\partial w} = x_1$$\n\n3.  **Derivative of the output spike with respect to the membrane potential, $\\frac{\\partial s_1}{\\partial V_1}$**:\n    The forward-pass output is given by $s_1 = H(V_1 - v_{\\mathrm{th}})$. The derivative of the Heaviside function is the Dirac delta function, which is zero almost everywhere and undefined at the origin. This poses a problem for gradient-based optimization. The surrogate gradient method addresses this by replacing the non-differentiable derivative of $H(u)$ in the backward pass with a continuous, well-behaved surrogate function, $\\rho(u)$. The problem defines this surrogate derivative as:\n    $$\\rho(u) = \\frac{1}{a} \\sigma\\left(\\frac{u}{a}\\right) \\left[1 - \\sigma\\left(\\frac{u}{a}\\right)\\right]$$\n    where $u = V_1 - v_{\\mathrm{th}}$. Therefore, for the purpose of backpropagation, we make the substitution:\n    $$\\frac{\\partial s_1}{\\partial V_1} \\approx \\rho(V_1 - v_{\\mathrm{th}})$$\n\nCombining these three terms, we obtain the expression for the gradient of the loss with respect to the weight:\n$$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\cdot \\rho(V_1 - v_{\\mathrm{th}}) \\cdot x_1$$\nSubstituting the definition of $\\rho(u)$, we get the full analytical expression:\n$$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\left( \\frac{1}{a} \\sigma\\left(\\frac{V_1 - v_{\\mathrm{th}}}{a}\\right) \\left[1 - \\sigma\\left(\\frac{V_1 - v_{\\mathrm{th}}}{a}\\right)\\right] \\right) x_1$$\nHere, $s_1$ is the value computed during the forward pass, i.e., $s_1 = H(V_1 - v_{\\mathrm{th}})$. The expression is in terms of $x_1$, $y$, $v_{\\mathrm{th}}$, $V_1$, and $a$ as required, with the understanding that $s_1$ is determined by $V_1$ and $v_{\\mathrm{th}}$.\n\n**Part 2: Numerical Computation of the Gradient**\n\nWe are given the following parameters:\n$\\tau_{m} = 20\\,\\mathrm{ms}$, $\\Delta t = 1\\,\\mathrm{ms}$, $V_{0} = 0$, $v_{\\mathrm{th}} = 1.0$, $w = 0.8$, $x_{1} = 1.5$, $y = 0$, $a = 0.5$.\n\nThe computation proceeds in steps, following the logic of the forward and backward passes.\n\n1.  **Calculate the membrane potential $V_1$ (Forward Pass)**:\n    First, we determine the decay factor $\\alpha$:\n    $$\\alpha = \\exp\\left(-\\frac{\\Delta t}{\\tau_{m}}\\right) = \\exp\\left(-\\frac{1\\,\\mathrm{ms}}{20\\,\\mathrm{ms}}\\right) = \\exp(-0.05)$$\n    Now, we compute the pre-reset membrane potential $V_1$:\n    $$V_1 = \\alpha V_0 + w x_1 = \\exp(-0.05) \\cdot 0 + (0.8)(1.5) = 1.2$$\n\n2.  **Calculate the output spike $s_1$ (Forward Pass)**:\n    The output spike is determined by comparing $V_1$ to the threshold $v_{\\mathrm{th}}$:\n    $$s_1 = H(V_1 - v_{\\mathrm{th}}) = H(1.2 - 1.0) = H(0.2)$$\n    Since the argument is positive, the Heaviside function evaluates to $1$:\n    $$s_1 = 1$$\n\n3.  **Calculate the gradient components (Backward Pass)**:\n    We now use the derived formula for $\\frac{\\partial L}{\\partial w}$:\n    $$\\frac{\\partial L}{\\partial w} = (s_1 - y) \\cdot \\rho(V_1 - v_{\\mathrm{th}}) \\cdot x_1$$\n    -   The error term is $(s_1 - y) = 1 - 0 = 1$.\n    -   The input term is $x_1 = 1.5$.\n    -   The surrogate gradient term is $\\rho(V_1 - v_{\\mathrm{th}}) = \\rho(0.2)$. Let's compute this.\n        The argument of the sigmoid function is $u/a = (V_1 - v_{\\mathrm{th}})/a = 0.2 / 0.5 = 0.4$.\n        The value of the sigmoid function is:\n        $$\\sigma(0.4) = \\frac{1}{1 + \\exp(-0.4)} \\approx \\frac{1}{1 + 0.670320046} \\approx \\frac{1}{1.670320046} \\approx 0.59868766$$\n        Now we can compute the value of the surrogate derivative $\\rho(0.2)$:\n        $$\\rho(0.2) = \\frac{1}{a} \\sigma(0.4) [1 - \\sigma(0.4)] = \\frac{1}{0.5} (0.59868766) [1 - 0.59868766]$$\n        $$\\rho(0.2) = 2 \\cdot (0.59868766) \\cdot (0.40131234) \\approx 0.4805084$$\n\n4.  **Combine to find the final gradient**:\n    $$\\frac{\\partial L}{\\partial w} = (1) \\cdot (0.4805084) \\cdot (1.5) = 0.7207626$$\n\n5.  **Round to four significant figures**:\n    The computed value is $0.7207626$. Rounding to four significant figures gives $0.7208$.",
            "answer": "$$\n\\boxed{0.7208}\n$$"
        },
        {
            "introduction": "Having established how a single neuromorphic client can learn, we now address how multiple clients can collaborate effectively without sharing their private data. This exercise explores the mathematical foundation of the Federated Averaging (FedAvg) algorithm, the most common aggregation strategy in federated learning. You will derive the principled way to weight and combine client contributions to ensure the collective update faithfully approximates the gradient that would be computed in a centralized setting. ",
            "id": "4045019",
            "problem": "Consider a synchronous federated learning system composed of $K$ neuromorphic edge clients, each running a spiking neural network trained with surrogate-gradient stochastic gradient descent. Client $k \\in \\{1,\\dots,K\\}$ holds a local dataset $\\mathcal{D}_k$ of size $n_k$, with $\\sum_{k=1}^{K} n_k = N$. Assume the following foundational conditions hold:\n- The data across clients are independent and identically distributed (IID): each $\\mathcal{D}_k$ consists of $n_k$ independent samples drawn from the same distribution over data-label pairs $(\\mathbf{x}, y)$.\n- The per-sample spiking loss $\\ell(w; \\mathbf{x}, y)$ is differentiable in $w$ after surrogate relaxation, and the surrogate gradient estimator $\\widehat{\\nabla}\\ell(w; \\mathbf{x}, y)$ computed on neuromorphic hardware is unbiased in the sense that $\\mathbb{E}[\\widehat{\\nabla}\\ell(w; \\mathbf{x}, y)] = \\nabla \\ell(w; \\mathbf{x}, y)$, where the expectation is with respect to both data sampling and hardware-induced randomness (e.g., quantization and event noise).\n- At a given round, each client computes its local empirical gradient as $g_k(w) = \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z)$, where $z = (\\mathbf{x}, y)$.\n\nThe centralized empirical risk over the union $\\mathcal{D} = \\bigcup_{k=1}^{K} \\mathcal{D}_k$ is $L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\ell(w; z)$, with corresponding centralized empirical gradient $\\nabla L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla \\ell(w; z)$.\n\nA parameter server aggregates the client gradients into a single update direction using weights $p_k \\ge 0$ with $\\sum_{k=1}^{K} p_k = 1$, producing the aggregated gradient $g_{\\mathrm{agg}}(w) = \\sum_{k=1}^{K} p_k \\, g_k(w)$ and the global update $w^{+} = w - \\eta \\, g_{\\mathrm{agg}}(w)$ with a common learning rate $\\eta > 0$.\n\nStarting only from the definitions above and the IID and unbiasedness assumptions, determine the weights $p_k$ as a function of the dataset sizes $n_k$ so that the aggregated gradient equals the centralized empirical gradient in expectation, that is, $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$. Then verify this equality by explicit derivation.\n\nProvide your final answer as a single closed-form analytic expression for $p_k$ in terms of $\\{n_k\\}_{k=1}^{K}$, with no rounding required and no units. Do not provide any intermediate steps in the final answer.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard theoretical problem in the field of federated learning, specifically concerning the derivation of aggregation weights that ensure the aggregated gradient is an unbiased estimator of the centralized empirical gradient.\n\nThe objective is to find the weighting coefficients $p_k$ for $k \\in \\{1, \\dots, K\\}$ that satisfy the condition $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$. The expectation $\\mathbb{E}[\\cdot]$ is taken with respect to the hardware-induced randomness in the surrogate gradient estimators. The datasets $\\{\\mathcal{D}_k\\}_{k=1}^{K}$ are considered fixed for this expectation.\n\nWe begin by expanding the left-hand side (LHS) of the target equality, which is the expected aggregated gradient $\\mathbb{E}[g_{\\mathrm{agg}}(w)]$.\nUsing the definition of the aggregated gradient $g_{\\mathrm{agg}}(w) = \\sum_{k=1}^{K} p_k \\, g_k(w)$ and the linearity of the expectation operator, we have:\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\mathbb{E}\\left[ \\sum_{k=1}^{K} p_k \\, g_k(w) \\right] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}[g_k(w)]\n$$\nNext, we substitute the definition of the local empirical gradient, $g_k(w) = \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z)$:\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}\\left[ \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z) \\right]\n$$\nBy linearity of expectation, we can move the operator inside the sum over the local dataset $\\mathcal{D}_k$:\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)]\n$$\nThe problem states that the surrogate gradient estimator is unbiased for any given data sample $z = (\\mathbf{x}, y)$, such that $\\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)] = \\nabla \\ell(w; z)$. Applying this assumption, we obtain:\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} \\frac{p_k}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)\n$$\nNow, we analyze the right-hand side (RHS) of the target equality, the centralized empirical gradient $\\nabla L_N(w)$. By its definition, $\\nabla L_N(w) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla \\ell(w; z)$. The total dataset $\\mathcal{D}$ is the union of the local datasets, $\\mathcal{D} = \\bigcup_{k=1}^{K} \\mathcal{D}_k$. Assuming the local datasets are disjoint, we can rewrite the sum over $\\mathcal{D}$ as a sum over the local datasets:\n$$\n\\nabla L_N(w) = \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla \\ell(w; z)\n$$\nTo satisfy the problem's requirement, we equate the derived expression for the LHS with the RHS:\n$$\n\\sum_{k=1}^{K} \\frac{p_k}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) = \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla \\ell(w; z)\n$$\nThis equation can be rearranged into a single summation:\n$$\n\\sum_{k=1}^{K} \\left( \\frac{p_k}{n_k} - \\frac{1}{N} \\right) \\left( \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) \\right) = 0\n$$\nThis equality must hold for any set of local datasets $\\{\\mathcal{D}_k\\}$ and any model parameters $w$. The vectors representing the local gradient sums, $\\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)$, can be linearly independent. For the total sum to be the zero vector under such general conditions, the scalar coefficient of each vector term must be zero. Therefore, for each client $k \\in \\{1, \\dots, K\\}$, we must have:\n$$\n\\frac{p_k}{n_k} - \\frac{1}{N} = 0\n$$\nSolving for $p_k$ yields:\n$$\np_k = \\frac{n_k}{N}\n$$\nThe problem defines $N = \\sum_{j=1}^{K} n_j$. Hence, the weights are proportional to the size of the local datasets. We verify that these weights satisfy the constraint $\\sum_{k=1}^{K} p_k = 1$:\n$$\n\\sum_{k=1}^{K} p_k = \\sum_{k=1}^{K} \\frac{n_k}{N} = \\frac{1}{N} \\sum_{k=1}^{K} n_k = \\frac{N}{N} = 1\n$$\nThe constraint is satisfied. Since $n_k \\ge 0$ (a dataset size) and $N > 0$, the condition $p_k \\ge 0$ is also met. It is noteworthy that the IID data assumption, while given, is not necessary to establish this specific equality between the expected aggregated gradient and the centralized empirical gradient. The IID property is, however, crucial for ensuring that this centralized empirical gradient is itself an unbiased estimate of the true global population gradient.\n\nFinally, we perform the explicit verification required by the problem. We substitute $p_k = n_k/N$ back into the expression for the expected aggregated gradient:\n$$\n\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\sum_{k=1}^{K} p_k \\, \\mathbb{E}[g_k(w)] = \\sum_{k=1}^{K} \\frac{n_k}{N} \\, \\mathbb{E}\\left[ \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\widehat{\\nabla}\\ell(w; z) \\right]\n$$\n$$\n= \\sum_{k=1}^{K} \\frac{n_k}{N} \\frac{1}{n_k} \\sum_{z \\in \\mathcal{D}_k} \\mathbb{E}[\\widehat{\\nabla}\\ell(w; z)] = \\sum_{k=1}^{K} \\frac{1}{N} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z)\n$$\n$$\n= \\frac{1}{N} \\sum_{k=1}^{K} \\sum_{z \\in \\mathcal{D}_k} \\nabla\\ell(w; z) = \\frac{1}{N} \\sum_{z \\in \\mathcal{D}} \\nabla\\ell(w; z) = \\nabla L_N(w)\n$$\nThe verification confirms that with the choice $p_k = n_k/N$, the equality $\\mathbb{E}[g_{\\mathrm{agg}}(w)] = \\nabla L_N(w)$ holds. The solution is thus $p_k = \\frac{n_k}{\\sum_{j=1}^{K} n_j}$.",
            "answer": "$$\\boxed{\\frac{n_k}{\\sum_{j=1}^{K} n_j}}$$"
        }
    ]
}