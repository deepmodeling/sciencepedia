{
    "hands_on_practices": [
        {
            "introduction": "To perform probabilistic inference, a neural sampler must navigate a state space according to a target probability distribution. This exercise  explores how a core component of many sampling algorithms, the Metropolis-Hastings acceptance rule, can be physically realized. By connecting the abstract mathematical probability to the spiking rate of a neuron, you will derive the parameters needed for a neural circuit to correctly implement the detailed balance condition, the fundamental principle ensuring the sampler converges to the desired distribution.",
            "id": "4052517",
            "problem": "Consider a neuromorphic spiking network implementing Markov Chain Monte Carlo (MCMC) sampling via the Metropolis–Hastings (MH) algorithm to approximate a posterior distribution over binary latent states. The target distribution over a state vector $\\mathbf{s} = (s_1, s_2)$ with $s_i \\in \\{0,1\\}$ is defined by an energy-based model with log-probability proportional to $-\\!U(\\mathbf{s})$, where the energy function is\n$$\nU(\\mathbf{s}) = \\theta_1 s_1 + \\theta_2 s_2 + W s_1 s_2.\n$$\nAssume the circuit targets the stationary distribution $\\pi(\\mathbf{s}) \\propto \\exp\\!\\big(-U(\\mathbf{s})\\big)$.\n\nProposals are generated by uniformly selecting one coordinate $i \\in \\{1,2\\}$ and stochastically setting $s_i$ according to a biased local rule: when coordinate $i$ is selected, the circuit proposes $s_i' = 1$ with probability $p_i$, and $s_i' = 0$ with probability $1 - p_i$, independent of the current $s_i$. This results in an asymmetric proposal distribution $q(\\mathbf{s}' \\mid \\mathbf{s})$.\n\nTo ensure the chain has $\\pi(\\mathbf{s})$ as its stationary distribution, the acceptance mechanism must satisfy detailed balance with respect to $\\pi(\\mathbf{s})$. The acceptance event on each proposal is mediated by an “accept” neuron that emits spikes according to a homogeneous Poisson process with rate $\\lambda$ during a fixed decision window of length $T$, and the proposal is accepted if and only if at least one accept spike occurs in the window. For a homogeneous Poisson process, the probability of at least one spike in a window of duration $T$ is $1 - \\exp(-\\lambda T)$.\n\nStarting from the definition of detailed balance for a time-homogeneous Markov chain with transition kernel $P(\\mathbf{s} \\to \\mathbf{s}')$, derive the acceptance probability $\\alpha(\\mathbf{s} \\to \\mathbf{s}')$ required for MH sampling with the given asymmetric proposal $q(\\mathbf{s}' \\mid \\mathbf{s})$, and then equate it to the neural acceptance probability $1 - \\exp(-\\lambda T)$ to determine the rate $\\lambda$ needed to implement the correct acceptance probability.\n\nFinally, evaluate $\\lambda$ numerically for the following specific transition and parameters:\n- Current state $\\mathbf{x} = (1,0)$ and proposed state $\\mathbf{x}' = (1,1)$,\n- Energy parameters $\\theta_1 = 0.7$, $\\theta_2 = -0.3$, $W = 1.1$,\n- Proposal bias $p_1 = 0.5$, $p_2 = 0.8$,\n- Decision window $T = 20\\,\\text{ms}$.\n\nRound your final numerical value for $\\lambda$ to four significant figures and express it in Hertz (Hz). Your final answer must be a single real number.",
            "solution": "The problem requires the derivation of the firing rate $\\lambda$ of an \"accept\" neuron that correctly implements the Metropolis-Hastings (MH) acceptance probability for a specific state transition in a binary network.\n\nFirst, we establish the theoretical foundation for the MH algorithm. A Markov chain with transition probabilities $P(\\mathbf{s} \\to \\mathbf{s}')$ has a stationary distribution $\\pi(\\mathbf{s})$ if the detailed balance condition is met:\n$$\n\\pi(\\mathbf{s}) P(\\mathbf{s} \\to \\mathbf{s}') = \\pi(\\mathbf{s}') P(\\mathbf{s}' \\to \\mathbf{s})\n$$\nIn the MH algorithm, the transition is a two-step process: a proposal of a new state $\\mathbf{s}'$ from the current state $\\mathbf{s}$ according to a proposal distribution $q(\\mathbf{s}' | \\mathbf{s})$, followed by an acceptance of this proposal with probability $\\alpha(\\mathbf{s} \\to \\mathbf{s}')$. Thus, the overall transition probability is $P(\\mathbf{s} \\to \\mathbf{s}') = q(\\mathbf{s}' | \\mathbf{s}) \\alpha(\\mathbf{s} \\to \\mathbf{s}')$ for $\\mathbf{s}' \\neq \\mathbf{s}$.\n\nSubstituting this into the detailed balance equation yields:\n$$\n\\pi(\\mathbf{s}) q(\\mathbf{s}' | \\mathbf{s}) \\alpha(\\mathbf{s} \\to \\mathbf{s}') = \\pi(\\mathbf{s}') q(\\mathbf{s} | \\mathbf{s}') \\alpha(\\mathbf{s}' \\to \\mathbf{s})\n$$\nRearranging for the ratio of acceptance probabilities gives:\n$$\n\\frac{\\alpha(\\mathbf{s} \\to \\mathbf{s}')}{\\alpha(\\mathbf{s}' \\to \\mathbf{s})} = \\frac{\\pi(\\mathbf{s}') q(\\mathbf{s} | \\mathbf{s}')}{\\pi(\\mathbf{s}) q(\\mathbf{s}' | \\mathbf{s})}\n$$\nThe standard Metropolis-Hastings choice for the acceptance probability, which satisfies this relation, is:\n$$\n\\alpha(\\mathbf{s} \\to \\mathbf{s}') = \\min\\left(1, \\frac{\\pi(\\mathbf{s}') q(\\mathbf{s} | \\mathbf{s}')}{\\pi(\\mathbf{s}) q(\\mathbf{s}' | \\mathbf{s})}\\right)\n$$\nThe problem states that the target stationary distribution $\\pi(\\mathbf{s})$ is proportional to $\\exp(-U(\\mathbf{s}))$, where $U(\\mathbf{s})$ is the energy of the state $\\mathbf{s}$. The ratio of probabilities of the target distribution is therefore:\n$$\n\\frac{\\pi(\\mathbf{s}')}{\\pi(\\mathbf{s})} = \\frac{\\exp(-U(\\mathbf{s}'))}{\\exp(-U(\\mathbf{s}))} = \\exp\\big(-(U(\\mathbf{s}') - U(\\mathbf{s}))\\big) = \\exp(-\\Delta U)\n$$\nwhere $\\Delta U = U(\\mathbf{s}') - U(\\mathbf{s})$. The acceptance probability can then be written as:\n$$\n\\alpha(\\mathbf{s} \\to \\mathbf{s}') = \\min\\left(1, \\exp(-\\Delta U) \\frac{q(\\mathbf{s} | \\mathbf{s}')}{q(\\mathbf{s}' | \\mathbf{s})}\\right)\n$$\nNext, we must determine the ratio of the proposal probabilities for the specific transition from state $\\mathbf{x} = (1,0)$ to $\\mathbf{x}' = (1,1)$. The proposal mechanism involves two steps: first, uniformly selecting a coordinate $i \\in \\{1,2\\}$ with probability $1/2$; second, proposing a new value for $s_i$ based on a biased rule ($s_i'=1$ with probability $p_i$, $s_i'=0$ with probability $1-p_i$).\n\nThe transition is from $\\mathbf{s} = \\mathbf{x} = (1,0)$ to $\\mathbf{s}' = \\mathbf{x}' = (1,1)$. These states differ only in the second coordinate ($i=2$).\nFor the forward proposal $q(\\mathbf{x}'|\\mathbf{x})$, coordinate $i=2$ must be selected (probability $1/2$), and the new state for this coordinate must be proposed as $s_2' = 1$ (probability $p_2$). Therefore:\n$$\nq(\\mathbf{x}'|\\mathbf{x}) = q((1,1)|(1,0)) = \\frac{1}{2} \\times p_2\n$$\nFor the reverse proposal $q(\\mathbf{x}|\\mathbf{x}')$, starting from $\\mathbf{x}'=(1,1)$ to get to $\\mathbf{x}=(1,0)$, coordinate $i=2$ must be selected again (probability $1/2$), and the new state must be proposed as $s_2 = 0$ (probability $1-p_2$). Therefore:\n$$\nq(\\mathbf{x}|\\mathbf{x}') = q((1,0)|(1,1)) = \\frac{1}{2} \\times (1-p_2)\n$$\nThe ratio of the proposal probabilities is:\n$$\n\\frac{q(\\mathbf{x}|\\mathbf{x}')}{q(\\mathbf{x}'|\\mathbf{x})} = \\frac{\\frac{1}{2}(1-p_2)}{\\frac{1}{2}p_2} = \\frac{1-p_2}{p_2}\n$$\nNow we compute the change in energy, $\\Delta U = U(\\mathbf{x}') - U(\\mathbf{x})$. The energy function is $U(\\mathbf{s}) = \\theta_1 s_1 + \\theta_2 s_2 + W s_1 s_2$.\nFor the current state $\\mathbf{x}=(1,0)$:\n$$\nU(\\mathbf{x}) = U(1,0) = \\theta_1(1) + \\theta_2(0) + W(1)(0) = \\theta_1\n$$\nFor the proposed state $\\mathbf{x}'=(1,1)$:\n$$\nU(\\mathbf{x}') = U(1,1) = \\theta_1(1) + \\theta_2(1) + W(1)(1) = \\theta_1 + \\theta_2 + W\n$$\nThe change in energy is:\n$$\n\\Delta U = U(\\mathbf{x}') - U(\\mathbf{x}) = (\\theta_1 + \\theta_2 + W) - \\theta_1 = \\theta_2 + W\n$$\nSubstituting these results into the acceptance probability formula:\n$$\n\\alpha(\\mathbf{x} \\to \\mathbf{x}') = \\min\\left(1, \\exp(-(\\theta_2 + W)) \\frac{1-p_2}{p_2}\\right)\n$$\nThe problem states that the neural implementation of acceptance is based on a Poisson process, where the probability of acceptance is the probability of at least one spike in a time window $T$, given by $1 - \\exp(-\\lambda T)$. To ensure detailed balance, this neural acceptance probability must equal the derived MH acceptance probability:\n$$\n1 - \\exp(-\\lambda T) = \\alpha(\\mathbf{x} \\to \\mathbf{x}')\n$$\nSolving for $\\lambda$:\n$$\n\\exp(-\\lambda T) = 1 - \\alpha(\\mathbf{x} \\to \\mathbf{x}')\n$$\n$$\n-\\lambda T = \\ln\\big(1 - \\alpha(\\mathbf{x} \\to \\mathbf{x}')\\big)\n$$\n$$\n\\lambda = -\\frac{1}{T} \\ln\\big(1 - \\alpha(\\mathbf{x} \\to \\mathbf{x}')\\big)\n$$\nSubstituting the expression for $\\alpha(\\mathbf{x} \\to \\mathbf{x}')$:\n$$\n\\lambda = -\\frac{1}{T} \\ln\\left(1 - \\min\\left(1, \\exp(-(\\theta_2 + W)) \\frac{1-p_2}{p_2}\\right)\\right)\n$$\nWe can now evaluate this expression numerically with the given parameters: $\\theta_2 = -0.3$, $W = 1.1$, $p_2 = 0.8$, and $T = 20\\,\\text{ms} = 20 \\times 10^{-3}\\,\\text{s}$.\nFirst, calculate the argument of the $\\min$ function:\n$$\n\\exp(-(\\theta_2 + W)) \\frac{1-p_2}{p_2} = \\exp(-(-0.3 + 1.1)) \\frac{1-0.8}{0.8} = \\exp(-0.8) \\frac{0.2}{0.8} = 0.25\\exp(-0.8)\n$$\nNumerically, $\\exp(-0.8) \\approx 0.449329$. So the term is approximately $0.25 \\times 0.449329 = 0.11233225$. Since this is less than $1$, the $\\min$ function returns this value.\nThus, the acceptance probability is $\\alpha(\\mathbf{x} \\to \\mathbf{x}')=0.25\\exp(-0.8)$.\nNow we can calculate $\\lambda$:\n$$\n\\lambda = -\\frac{1}{20 \\times 10^{-3}} \\ln\\big(1 - 0.25\\exp(-0.8)\\big)\n$$\n$$\n\\lambda = -50 \\ln\\big(1 - 0.25\\exp(-0.8)\\big)\n$$\n$$\n\\lambda \\approx -50 \\ln(1 - 0.11233225) = -50 \\ln(0.88766775)\n$$\n$$\n\\lambda \\approx -50 \\times (-0.119159) \\approx 5.95795 \\, \\text{Hz}\n$$\nRounding to four significant figures, we get $\\lambda = 5.958\\,\\text{Hz}$.",
            "answer": "$$\\boxed{5.958}$$"
        },
        {
            "introduction": "Theoretical models provide a blueprint for neural samplers, but physical hardware is subject to imperfections, noise, and drift. This practical exercise  tackles the essential task of calibrating a real-world binary sampler whose response deviates from the ideal logistic function. You will use empirical spike-count data and linear regression in the logit domain to estimate the hardware's unknown gain and offset, a critical step in bridging the gap between theory and practice in neuromorphic engineering.",
            "id": "4052528",
            "problem": "You are given a binary spiking neural sampler on neuromorphic hardware that, over a fixed observation window, emits a spike with probability modeled by a logistic function of an input field. In an ideal logistic binary sampler, the spike probability as a function of the scalar field $h$ is $p^{\\ast}(h) = \\sigma(h)$, where $\\sigma(u) = 1/(1 + e^{-u})$ is the logistic function. On real hardware, unknown gain and offset distortions occur, so the sampler effectively implements $p(h) = \\sigma(\\alpha h + \\gamma)$, where $\\alpha$ and $\\gamma$ are unknown real numbers that may drift with time or configuration. The goal is to calibrate the sampler by estimating $(\\alpha, \\gamma)$ from measured training responses, and then validate the calibrated model on held-out tests by quantifying its divergence from the ideal sampler.\n\nFundamental base:\n- A binary random variable $x \\in \\{0,1\\}$ with spike probability $p$ follows a Bernoulli distribution $\\mathsf{Bernoulli}(p)$.\n- The logistic link defines $\\sigma(u) = 1/(1+e^{-u})$ for any real $u$.\n- The log-odds (logit) function is $\\operatorname{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$ for any $p \\in (0,1)$.\n- The Kullback–Leibler divergence (KLD) from $\\mathsf{Bernoulli}(p)$ to $\\mathsf{Bernoulli}(q)$ is $\\mathrm{KL}(p \\Vert q) = p \\ln\\left(\\frac{p}{q}\\right) + (1-p)\\ln\\left(\\frac{1-p}{1-q}\\right)$.\n\nCalibration problem:\n- You will be given training measurements consisting of a small set of fields $h_i$ and, for each $h_i$, the number of observed spikes $k_i$ out of $n_i$ trials. Using Laplace smoothing with parameter $\\delta$ to avoid degenerate probabilities near $0$ and $1$, define the empirical probability estimate $\\hat{p}_i = \\frac{k_i + \\delta}{n_i + 2\\delta}$. Assume the hardware obeys the logistic model $p(h) = \\sigma(\\alpha h + \\gamma)$. In the logit domain, this implies $\\operatorname{logit}(\\hat{p}_i) \\approx \\alpha h_i + \\gamma$ plus sampling noise. Estimate $(\\alpha, \\gamma)$ by linear least squares on the training data in the logit domain.\n\nValidation problem:\n- Given held-out test fields $h_j$ and measured spike counts $k_j$ out of $n_j$ trials (with the same smoothing), compute two validation metrics:\n  1. The mean Kullback–Leibler divergence between the ideal target probabilities $p^{\\ast}(h_j) = \\sigma(h_j)$ and the calibrated model’s predicted probabilities $q(h_j) = \\sigma(\\alpha h_j + \\gamma)$:\n  $$\\overline{\\mathrm{KL}} = \\frac{1}{m}\\sum_{j=1}^{m}\\left[p^{\\ast}(h_j)\\ln\\left(\\frac{p^{\\ast}(h_j)}{q(h_j)}\\right) + (1-p^{\\ast}(h_j))\\ln\\left(\\frac{1-p^{\\ast}(h_j)}{1-q(h_j)}\\right)\\right],$$\n  where $m$ is the number of test fields.\n  2. The maximum absolute logit residual on test measurements, defined as:\n  $$R_{\\max} = \\max_{j}\\left|\\operatorname{logit}\\!\\left(\\frac{k_j+\\delta}{n_j+2\\delta}\\right) - (\\alpha h_j + \\gamma)\\right|.$$\n\nYour task is to write a complete, runnable program that performs calibration and validation for each of the provided test cases. The program must:\n- Implement logistic $\\sigma(u)$, logit, Laplace smoothing, and linear least squares in the logit domain.\n- For each test case, estimate $(\\alpha, \\gamma)$ on the training set, compute $\\overline{\\mathrm{KL}}$ on the test set using the calibrated model versus the ideal target, and compute $R_{\\max}$ using measured test counts.\n- Decide pass/fail for each case by checking whether $\\overline{\\mathrm{KL}}$ is less than or equal to a case-specific tolerance $\\tau$.\n\nTest suite:\n- Three test cases are provided. Each case supplies $h_{\\text{train}}$, $k_{\\text{train}}$, $n_{\\text{train}}$, $h_{\\text{test}}$, $k_{\\text{test}}$, $n_{\\text{test}}$, and a tolerance $\\tau$, with smoothing parameter $\\delta = 1$ to be used in all cases. All $h$ values are in pure real numbers (no physical units). The test suite covers a typical well-conditioned scenario, a saturation boundary case, and a drift/noise case.\n\nCase A (well-conditioned):\n- $h_{\\text{train}} = [-2.0, 0.0, 2.0]$\n- $n_{\\text{train}} = [1000, 1000, 1000]$\n- $k_{\\text{train}} = [154, 525, 870]$\n- $h_{\\text{test}} = [-3.0, -1.0, 1.0, 3.0]$\n- $n_{\\text{test}} = [1000, 1000, 1000, 1000]$\n- $k_{\\text{test}} = [69, 310, 731, 943]$\n- $\\tau = 0.01$\n\nCase B (saturation boundary):\n- $h_{\\text{train}} = [-1.0, 0.0, 1.0]$\n- $n_{\\text{train}} = [200, 200, 200]$\n- $k_{\\text{train}} = [4, 100, 196]$\n- $h_{\\text{test}} = [-2.0, -0.5, 0.5, 2.0]$\n- $n_{\\text{test}} = [200, 200, 200, 200]$\n- $k_{\\text{test}} = [0, 24, 176, 200]$\n- $\\tau = 0.05$\n\nCase C (drift/noise case):\n- $h_{\\text{train}} = [-1.0, 0.0, 1.0]$\n- $n_{\\text{train}} = [500, 500, 500]$\n- $k_{\\text{train}} = [99, 225, 366]$\n- $h_{\\text{test}} = [-1.0, 0.0, 1.0, 2.0]$\n- $n_{\\text{test}} = [500, 500, 500, 500]$\n- $k_{\\text{test}} = [60, 189, 366, 462]$\n- $\\tau = 0.03$\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the three cases as a comma-separated list enclosed in square brackets, where each case’s result is itself a list of four values $[\\alpha, \\gamma, \\overline{\\mathrm{KL}}, \\text{pass}]$. For example: $[[\\alpha_1,\\gamma_1,\\mathrm{KL}_1,\\text{True}],[\\alpha_2,\\gamma_2,\\mathrm{KL}_2,\\text{False}],[\\alpha_3,\\gamma_3,\\mathrm{KL}_3,\\text{True}]]$. The numeric results should be standard decimal floats, and the pass/fail should be boolean values. Angles do not appear in this problem, and there are no physical units.",
            "solution": "The problem requires the calibration and validation of a binary spiking neural sampler. The process involves estimating the parameters of a distorted logistic response model and then quantifying the model's deviation from an ideal sampler. The solution proceeds in three stages: first, defining the necessary mathematical functions and models; second, specifying the calibration procedure to estimate the unknown hardware parameters; and third, detailing the validation metrics used to assess the calibrated model.\n\nFirst, we define the core components of the model. The sampler's spike probability is modeled by the logistic function, $\\sigma(u) = (1 + e^{-u})^{-1}$. The ideal sampler has a spike probability $p^{\\ast}(h) = \\sigma(h)$, where $h$ is the input field. The hardware implementation is distorted, with a response $p(h) = \\sigma(\\alpha h + \\gamma)$, where $\\alpha$ and $\\gamma$ are unknown gain and offset parameters, respectively. The analysis is performed in the log-odds (logit) domain, using the function $\\operatorname{logit}(p) = \\ln(p/(1-p))$, which is the inverse of the logistic function. This transformation is key, as it linearizes the response model: $\\operatorname{logit}(p(h)) = \\alpha h + \\gamma$.\n\nSpike count data from $n_i$ trials for a given field $h_i$ results in $k_i$ spikes. The empirical probability of a spike is estimated as $\\hat{p}_i$. To handle cases where $k_i=0$ or $k_i=n_i$, which would lead to undefined logit values, we use Laplace smoothing. With a smoothing parameter $\\delta$, the smoothed empirical probability is given by:\n$$ \\hat{p}_i = \\frac{k_i + \\delta}{n_i + 2\\delta} $$\nFor this problem, $\\delta=1$ is specified. This ensures that $\\hat{p}_i \\in (0, 1)$.\n\nThe second stage is calibration, where we estimate $(\\alpha, \\gamma)$ using a set of training data $\\{ (h_i, k_i, n_i) \\}_{i=1}^N$. We transform the empirical probabilities to the logit domain, creating a set of data points $(h_i, y_i)$ where $y_i = \\operatorname{logit}(\\hat{p}_i)$. Based on our linearized model, we expect the relationship $y_i \\approx \\alpha h_i + \\gamma$. We can find the best-fit parameters $(\\alpha, \\gamma)$ by minimizing the sum of squared errors, $S(\\alpha, \\gamma) = \\sum_{i=1}^N (y_i - (\\alpha h_i + \\gamma))^2$. This is a standard linear least-squares regression problem. We seek to find a vector of parameters $\\mathbf{x} = [\\alpha, \\gamma]^T$ that best solves the system of linear equations $\\mathbf{A}\\mathbf{x} \\approx \\mathbf{y}$, where:\n$$ \\mathbf{A} = \\begin{pmatrix} h_1 & 1 \\\\ h_2 & 1 \\\\ \\vdots & \\vdots \\\\ h_N & 1 \\end{pmatrix}, \\quad \\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{pmatrix} $$\nThe least-squares solution is given by the normal equations, $\\mathbf{x} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{y}$. This provides the estimates for the hardware parameters $(\\hat{\\alpha}, \\hat{\\gamma})$. For brevity, we will refer to these estimates as $(\\alpha, \\gamma)$.\n\nThe third stage is validation. Using the estimated parameters $(\\alpha, \\gamma)$ and a held-out test dataset $\\{ (h_j, k_j, n_j) \\}_{j=1}^m$, we compute two metrics.\n\nThe first metric is the mean Kullback–Leibler (KL) divergence, $\\overline{\\mathrm{KL}}$. This measures the average information loss when using the calibrated model, $q(h_j) = \\sigma(\\alpha h_j + \\gamma)$, to approximate the ideal model, $p^{\\ast}(h_j) = \\sigma(h_j)$. A single spike event is a Bernoulli trial, and the KL divergence from a $\\mathsf{Bernoulli}(p)$ distribution to a $\\mathsf{Bernoulli}(q)$ distribution is $\\mathrm{KL}(p \\Vert q) = p \\ln(p/q) + (1-p)\\ln((1-p)/(1-q))$. The mean KL divergence over the $m$ test fields is:\n$$ \\overline{\\mathrm{KL}} = \\frac{1}{m}\\sum_{j=1}^{m} \\mathrm{KL}(p^{\\ast}(h_j) \\Vert q(h_j)) = \\frac{1}{m}\\sum_{j=1}^{m} \\left[ p^{\\ast}(h_j)\\ln\\left(\\frac{p^{\\ast}(h_j)}{q(h_j)}\\right) + (1-p^{\\ast}(h_j))\\ln\\left(\\frac{1-p^{\\ast}(h_j)}{1-q(h_j)}\\right) \\right] $$\nThe sampler's performance for a given test case is deemed acceptable if this $\\overline{\\mathrm{KL}}$ value is less than or equal to a specified tolerance, $\\tau$.\n\nThe second metric, the maximum absolute logit residual $R_{\\max}$, quantifies the goodness-of-fit of the calibrated linear model to the empirical test data. It is the largest deviation between the model's prediction in the logit domain and the logit of the measured test probabilities:\n$$ R_{\\max} = \\max_{j}\\left|\\operatorname{logit}\\!\\left(\\frac{k_j+\\delta}{n_j+2\\delta}\\right) - (\\alpha h_j + \\gamma)\\right| $$\nWhile this metric provides valuable diagnostic information about model-data mismatch, it is not used for the pass/fail criterion in this problem.\n\nThe implementation will proceed by defining functions for $\\sigma(u)$, $\\operatorname{logit}(p)$, Laplace smoothing, and KL divergence. For each test case, it will:\n$1$. Take the training data $(h_{\\text{train}}, k_{\\text{train}}, n_{\\text{train}})$ and $\\delta=1$.\n$2$. Compute smoothed probabilities $\\hat{p}_i$ and their logit transforms $y_i$.\n$3$. Perform linear least-squares regression of $y_i$ on $h_i$ to find $(\\alpha, \\gamma)$.\n$4$. Take the test data $(h_{\\text{test}}, k_{\\text{test}}, n_{\\text{test}})$ and the estimated $(\\alpha, \\gamma)$.\n$5$. Compute the ideal probabilities $p^{\\ast}(h_j)$ and calibrated model probabilities $q(h_j)$.\n$6$. Calculate the mean KL divergence $\\overline{\\mathrm{KL}}$ by averaging $\\mathrm{KL}(p^{\\ast}(h_j) \\Vert q(h_j))$ over all test points.\n$7$. Compare $\\overline{\\mathrm{KL}}$ with the case-specific tolerance $\\tau$ to determine the pass/fail status.\n$8$. Assemble the results $[\\alpha, \\gamma, \\overline{\\mathrm{KL}}, \\text{pass}]$ for each case and format them into the specified final output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs calibration and validation for a binary spiking neural sampler\n    across multiple test cases as specified in the problem statement.\n    \"\"\"\n    delta = 1.0\n\n    test_cases = [\n        {\n            \"name\": \"Case A (well-conditioned)\",\n            \"h_train\": np.array([-2.0, 0.0, 2.0]),\n            \"n_train\": np.array([1000, 1000, 1000]),\n            \"k_train\": np.array([154, 525, 870]),\n            \"h_test\": np.array([-3.0, -1.0, 1.0, 3.0]),\n            \"n_test\": np.array([1000, 1000, 1000, 1000]),\n            \"k_test\": np.array([69, 310, 731, 943]),\n            \"tau\": 0.01\n        },\n        {\n            \"name\": \"Case B (saturation boundary)\",\n            \"h_train\": np.array([-1.0, 0.0, 1.0]),\n            \"n_train\": np.array([200, 200, 200]),\n            \"k_train\": np.array([4, 100, 196]),\n            \"h_test\": np.array([-2.0, -0.5, 0.5, 2.0]),\n            \"n_test\": np.array([200, 200, 200, 200]),\n            \"k_test\": np.array([0, 24, 176, 200]),\n            \"tau\": 0.05\n        },\n        {\n            \"name\": \"Case C (drift/noise case)\",\n            \"h_train\": np.array([-1.0, 0.0, 1.0]),\n            \"n_train\": np.array([500, 500, 500]),\n            \"k_train\": np.array([99, 225, 366]),\n            \"h_test\": np.array([-1.0, 0.0, 1.0, 2.0]),\n            \"n_test\": np.array([500, 500, 500, 500]),\n            \"k_test\": np.array([60, 189, 366, 462]),\n            \"tau\": 0.03\n        }\n    ]\n\n    def sigma(u):\n        \"\"\"Logistic function.\"\"\"\n        return 1.0 / (1.0 + np.exp(-u))\n\n    def logit(p):\n        \"\"\"Logit function.\"\"\"\n        # Add small epsilon to avoid log(0) if p is exactly 0 or 1,\n        # though Laplace smoothing should prevent this.\n        p = np.clip(p, 1e-15, 1 - 1e-15)\n        return np.log(p / (1.0 - p))\n\n    def laplace_smooth(k, n, delta_val):\n        \"\"\"Empirical probability with Laplace smoothing.\"\"\"\n        return (k + delta_val) / (n + 2.0 * delta_val)\n    \n    def kl_divergence_bernoulli(p, q):\n        \"\"\"KL divergence between two Bernoulli distributions.\"\"\"\n        # Clip probabilities to avoid log(0)\n        p = np.clip(p, 1e-15, 1 - 1e-15)\n        q = np.clip(q, 1e-15, 1 - 1e-15)\n        return p * np.log(p / q) + (1.0 - p) * np.log((1.0 - p) / (1.0 - q))\n\n    all_results = []\n\n    for case in test_cases:\n        # --- Calibration Step ---\n        # 1. Calculate smoothed empirical probabilities\n        p_hat_train = laplace_smooth(case[\"k_train\"], case[\"n_train\"], delta)\n\n        # 2. Transform to logit domain\n        y_train = logit(p_hat_train)\n        \n        # 3. Perform linear least squares to find alpha and gamma\n        # We are fitting y = alpha * h + gamma\n        A = np.vstack([case[\"h_train\"], np.ones_like(case[\"h_train\"])]).T\n        solution, _, _, _ = np.linalg.lstsq(A, y_train, rcond=None)\n        alpha, gamma = solution[0], solution[1]\n\n        # --- Validation Step ---\n        h_test = case[\"h_test\"]\n        \n        # 1. Calculate Mean KL Divergence\n        p_star = sigma(h_test)  # Ideal probabilities\n        q_calibrated = sigma(alpha * h_test + gamma) # Calibrated model probabilities\n        \n        kl_divs = kl_divergence_bernoulli(p_star, q_calibrated)\n        mean_kl = np.mean(kl_divs)\n\n        # 2. (Optional, for completeness) Calculate Max Absolute Logit Residual\n        p_hat_test = laplace_smooth(case[\"k_test\"], case[\"n_test\"], delta)\n        logit_p_test = logit(p_hat_test)\n        model_logit_preds = alpha * h_test + gamma\n        r_max = np.max(np.abs(logit_p_test - model_logit_preds))\n\n        # 3. Pass/Fail decision\n        passed = mean_kl <= case[\"tau\"]\n        \n        all_results.append([alpha, gamma, mean_kl, passed])\n\n    # --- Final Output Formatting ---\n    # Manually format the string to avoid spaces after commas\n    case_strings = []\n    for result in all_results:\n        # str(boolean) gives 'True' or 'False' as required\n        case_str = f\"[{result[0]},{result[1]},{result[2]},{result[3]}]\"\n        case_strings.append(case_str)\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The output of a neural sampler is a sequence of states, from which we estimate properties of the target distribution. However, successive samples are often not independent, and their variance can be scaled by a \"neural temperature\" parameter, both of which affect the reliability of our estimates. This problem  guides you through a rigorous statistical analysis to quantify the bias and variance of mean and variance estimators, providing deep insight into how temporal correlations and hardware characteristics impact the quality of probabilistic inference.",
            "id": "4052509",
            "problem": "Consider a scalar latent variable $x$ represented by a neuromorphic neural sampler whose discrete-time dynamics are a first-order autoregressive process (AR(1)): $$x_{t+1} = \\mu + \\rho\\left(x_t - \\mu\\right) + \\varepsilon_t,$$ where $t \\in \\{0,1,2,\\ldots\\}$, $|\\rho| < 1$, and the innovation $\\varepsilon_t$ is independent and identically distributed (i.i.d.) Gaussian with zero mean and variance chosen such that the stationary variance of $x_t$ is $$\\gamma_0 = \\sigma^2 T,$$ where $\\mu$ is the target mean, $\\sigma^2$ is the target variance, and $T$ is the neural temperature parameter that scales the stationary variance of the sampler relative to the target distribution. This AR(1) process is strictly stationary with autocovariance function $$\\gamma_k = \\operatorname{Cov}(x_t, x_{t+k}) = \\gamma_0 \\rho^k.$$ You observe $n$ consecutive samples $\\{x_1, x_2, \\ldots, x_n\\}$ from the stationary process and estimate the mean and variance using the usual estimators $$\\hat{m} = \\frac{1}{n}\\sum_{t=1}^n x_t, \\quad \\hat{s}^2 = \\frac{1}{n-1}\\sum_{t=1}^n \\left(x_t - \\hat{m}\\right)^2.$$ Starting from first principles—namely the definitions of expectation, variance, covariance, and stationarity—derive expressions for the following quantities in terms of $n$, $\\mu$, $\\sigma^2$, $T$, and $\\rho$, without assuming independence between samples:\n\n1. The bias of the sample mean estimator, defined as $$\\operatorname{Bias}(\\hat{m}) = \\mathbb{E}[\\hat{m}] - \\mu.$$\n\n2. The variance of the sample mean estimator, defined as $$\\operatorname{Var}(\\hat{m}) = \\mathbb{E}\\left[(\\hat{m} - \\mathbb{E}[\\hat{m}])^2\\right].$$\n\n3. The expected value of the sample variance estimator, defined as $$\\mathbb{E}[\\hat{s}^2].$$\n\nThen, interpret the sample variance as a naive estimator of the target variance $\\sigma^2$ that ignores neural temperature ($T$) and temporal correlation ($\\rho$). Using your derived expressions, compute the bias of this naive variance estimator, $$\\operatorname{Bias}_{\\text{naive}} = \\mathbb{E}[\\hat{s}^2] - \\sigma^2.$$\n\nYour program must implement your derived formulas to compute the following three outputs per test case:\n\n- The bias of the sample mean estimator $\\operatorname{Bias}(\\hat{m})$.\n- The bias of the naive variance estimator $\\operatorname{Bias}_{\\text{naive}}$.\n- The variance of the sample mean estimator $\\operatorname{Var}(\\hat{m})$.\n\nNo physical units are involved. Angles are not involved. Express all outputs as real numbers (floats). Use the following test suite, where each tuple is $(n, \\mu, \\sigma, T, \\rho)$:\n\n- Test case A (independence, happy path): $(1000, 0.0, 1.0, 1.0, 0.0)$.\n- Test case B (strong positive correlation, large $n$): $(1000, 0.0, 2.0, 1.0, 0.95)$.\n- Test case C (negative correlation, moderate $n$): $(200, 1.0, 1.5, 1.0, -0.5)$.\n- Test case D (temperature mismatch, moderate correlation): $(500, 0.5, 1.0, 1.5, 0.7)$.\n- Test case E (small sample, high correlation): $(20, -1.0, 1.0, 1.0, 0.9)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output the three floats in the order specified above and concatenate all test case outputs into a single flat list. For example, the output format should be $$\\texttt{[b\\_A^{(m)},b\\_A^{(v)},v\\_A^{(m)},b\\_B^{(m)},b\\_B^{(v)},v\\_B^{(m)},\\ldots]}$$ where $b^{(m)}$ is the bias of the mean, $b^{(v)}$ is the bias of the naive variance estimator, and $v^{(m)}$ is the variance of the sample mean.",
            "solution": "The user-provided problem is subjected to a rigorous validation procedure.\n\n### Step 1: Extract Givens\n- **Process Dynamics**: A first-order autoregressive process, AR($1$), is defined as `$x_{t+1} = \\mu + \\rho(x_t - \\mu) + \\varepsilon_t$`.\n- **Parameters and Conditions**:\n    - Time index: `$t \\in \\{0,1,2,\\ldots\\}`.\n    - Autoregressive coefficient: `$|\\rho| < 1$`.\n    - Innovation term: `$\\varepsilon_t$` is i.i.d. Gaussian with `$\\mathbb{E}[\\varepsilon_t] = 0$`.\n    - Target mean: `$\\mu$`.\n    - Target variance: `$\\sigma^2$`.\n    - Neural temperature: `$T$`.\n- **Stationary Properties**:\n    - The process `$x_t$` is strictly stationary.\n    - Stationary mean: `$\\mathbb{E}[x_t] = \\mu$`.\n    - Stationary variance: `$\\gamma_0 = \\operatorname{Var}(x_t) = \\sigma^2 T$`.\n    - Autocovariance function: `$\\gamma_k = \\operatorname{Cov}(x_t, x_{t+k}) = \\gamma_0 \\rho^k` for `$k \\ge 0$`. By extension, `$\\operatorname{Cov}(x_i, x_j) = \\gamma_0 \\rho^{|i-j|}$`.\n- **Observations**: `$n$` consecutive samples `$\\{x_1, x_2, \\ldots, x_n\\}$`.\n- **Estimators**:\n    - Sample mean: `$\\hat{m} = \\frac{1}{n}\\sum_{t=1}^n x_t$`.\n    - Sample variance: `$\\hat{s}^2 = \\frac{1}{n-1}\\sum_{t=1}^n (x_t - \\hat{m})^2$`.\n- **Quantities to Derive**:\n    1. Bias of the sample mean: `$\\operatorname{Bias}(\\hat{m}) = \\mathbb{E}[\\hat{m}] - \\mu$`.\n    2. Variance of the sample mean: `$\\operatorname{Var}(\\hat{m}) = \\mathbb{E}[(\\hat{m} - \\mathbb{E}[\\hat{m}])^2]$`.\n    3. Expected value of the sample variance: `$\\mathbb{E}[\\hat{s}^2]$`.\n    4. Bias of the naive variance estimator: `$\\operatorname{Bias}_{\\text{naive}} = \\mathbb{E}[\\hat{s}^2] - \\sigma^2$`.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the theory of stochastic processes and statistical estimation. The AR($1$) process is a canonical model in time series analysis, and its application to neural sampling is a recognized paradigm in neuromorphic computing. All definitions are standard and correct.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary parameters and definitions to derive the requested quantities. The derivations are standard exercises in mathematical statistics, and unique, stable solutions exist.\n- **Objectivity**: The language is formal, precise, and devoid of subjective claims.\n- **Flaw Checklist**:\n    1. **Scientific/Factual Unsoundness**: None. The model and its properties are consistent with established theory. The condition `$|\\rho| < 1$` correctly ensures stationarity.\n    2. **Non-Formalizable/Irrelevant**: None. The problem is a formal mathematical task directly relevant to characterizing the statistical properties of a neural sampler.\n    3. **Incomplete/Contradictory Setup**: None. All required information is provided and is internally consistent.\n    4. **Unrealistic/Infeasible**: None. The model parameters and test cases are physically and numerically reasonable.\n    5. **Ill-Posed/Poorly Structured**: None. The objectives are clearly stated and lead to unique, verifiable results.\n    6. **Pseudo-Profound/Trivial**: None. While the bias of the mean is a simple result, the variance of the mean and a-fortiori the expectation of the sample variance for a correlated process require non-trivial derivations.\n    7. **Outside Scientific Verifiability**: None. The derivations are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is **VALID**. It is a well-defined, scientifically sound problem in statistical analysis. A full, reasoned solution will be provided.\n\n---\n\n### Derivations from First Principles\n\nThe derivations will proceed for each of the requested quantities, based on the fundamental definitions of expectation, variance, and covariance, and the properties of the stationary AR($1$) process. The stationary mean is `$\\mathbb{E}[x_t] = \\mu$` and the autocovariance is `$\\operatorname{Cov}(x_i, x_j) = \\gamma_0 \\rho^{|i-j|}$`, where `$\\gamma_0 = \\sigma^2 T$`.\n\n**1. Bias of the Sample Mean Estimator, `$\\operatorname{Bias}(\\hat{m})$`**\n\nThe bias is defined as `$\\operatorname{Bias}(\\hat{m}) = \\mathbb{E}[\\hat{m}] - \\mu$`. We first compute the expected value of the sample mean, `$\\hat{m}$`.\n\nBy the linearity of the expectation operator:\n$$\n\\mathbb{E}[\\hat{m}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{t=1}^n x_t\\right] = \\frac{1}{n}\\sum_{t=1}^n \\mathbb{E}[x_t]\n$$\nSince the process is stationary, `$\\mathbb{E}[x_t] = \\mu$` for all `$t$`.\n$$\n\\mathbb{E}[\\hat{m}] = \\frac{1}{n}\\sum_{t=1}^n \\mu = \\frac{1}{n}(n\\mu) = \\mu\n$$\nTherefore, the bias of the sample mean is:\n$$\n\\operatorname{Bias}(\\hat{m}) = \\mu - \\mu = 0\n$$\nThe sample mean `$\\hat{m}$` is an unbiased estimator of the process mean `$\\mu$`, irrespective of the temporal correlation `$\\rho$` or neural temperature `$T$`.\n\n**2. Variance of the Sample Mean Estimator, `$\\operatorname{Var}(\\hat{m})$`**\n\nThe variance of `$\\hat{m}$` is defined as `$\\operatorname{Var}(\\hat{m}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{t=1}^n x_t\\right)$`.\n\nUsing the properties of variance for a sum of correlated random variables:\n$$\n\\operatorname{Var}(\\hat{m}) = \\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{t=1}^n x_t\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\operatorname{Cov}(x_i, x_j)\n$$\nSubstituting the autocovariance function `$\\operatorname{Cov}(x_i, x_j) = \\gamma_0 \\rho^{|i-j|}$`:\n$$\n\\operatorname{Var}(\\hat{m}) = \\frac{\\gamma_0}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\rho^{|i-j|}\n$$\nThe double summation is a standard result for a Toeplitz matrix, which simplifies to:\n$$\n\\sum_{i=1}^n \\sum_{j=1}^n \\rho^{|i-j|} = n \\frac{1+\\rho}{1-\\rho} - \\frac{2\\rho(1-\\rho^n)}{(1-\\rho)^2}\n$$\nSubstituting this back into the expression for `$\\operatorname{Var}(\\hat{m})$` gives:\n$$\n\\operatorname{Var}(\\hat{m}) = \\frac{\\gamma_0}{n^2} \\left[ n \\frac{1+\\rho}{1-\\rho} - \\frac{2\\rho(1-\\rho^n)}{(1-\\rho)^2} \\right]\n$$\nFactoring out `$n$` and substituting `$\\gamma_0 = \\sigma^2 T$`, we obtain the final formula:\n$$\n\\operatorname{Var}(\\hat{m}) = \\frac{\\sigma^2 T}{n} \\left[ \\frac{1+\\rho}{1-\\rho} - \\frac{2\\rho(1-\\rho^n)}{n(1-\\rho)^2} \\right]\n$$\nNote that in the case of independent samples (`$\\rho=0$`), this formula correctly reduces to `$\\operatorname{Var}(\\hat{m}) = \\frac{\\sigma^2 T}{n} [1 - 0] = \\frac{\\gamma_0}{n}$`.\n\n**3. Expected Value of the Sample Variance Estimator, `$\\mathbb{E}[\\hat{s}^2]$`**\n\nWe begin with the definition of `$\\hat{s}^2$` and use a common identity:\n$$\n\\hat{s}^2 = \\frac{1}{n-1}\\sum_{t=1}^n (x_t - \\hat{m})^2 = \\frac{1}{n-1} \\left( \\sum_{t=1}^n x_t^2 - n\\hat{m}^2 \\right)\n$$\nBy the linearity of expectation:\n$$\n\\mathbb{E}[\\hat{s}^2] = \\frac{1}{n-1} \\left( \\sum_{t=1}^n \\mathbb{E}[x_t^2] - n\\mathbb{E}[\\hat{m}^2] \\right)\n$$\nWe evaluate the two expectations.\nFirst, from the definition of variance, `$\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$`:\n`$\\mathbb{E}[x_t^2] = \\operatorname{Var}(x_t) + (\\mathbb{E}[x_t])^2 = \\gamma_0 + \\mu^2$`.\n`$\\mathbb{E}[\\hat{m}^2] = \\operatorname{Var}(\\hat{m}) + (\\mathbb{E}[\\hat{m}])^2 = \\operatorname{Var}(\\hat{m}) + \\mu^2$`.\n\nSubstituting these into the expression for `$\\mathbb{E}[\\hat{s}^2]$`:\n$$\n\\mathbb{E}[\\hat{s}^2] = \\frac{1}{n-1} \\left( \\sum_{t=1}^n (\\gamma_0 + \\mu^2) - n(\\operatorname{Var}(\\hat{m}) + \\mu^2) \\right)\n$$\n$$\n= \\frac{1}{n-1} \\left( n(\\gamma_0 + \\mu^2) - n\\operatorname{Var}(\\hat{m}) - n\\mu^2 \\right)\n$$\n$$\n= \\frac{1}{n-1} \\left( n\\gamma_0 + n\\mu^2 - n\\operatorname{Var}(\\hat{m}) - n\\mu^2 \\right)\n$$\n$$\n= \\frac{n}{n-1} \\left( \\gamma_0 - \\operatorname{Var}(\\hat{m}) \\right)\n$$\nThis elegant result connects the expected sample variance to the true process variance `$\\gamma_0$` and the variance of the sample mean `$\\operatorname{Var}(\\hat{m})$`. Using `$\\gamma_0 = \\sigma^2 T$` and the previously derived formula for `$\\operatorname{Var}(\\hat{m})$`, this quantity is fully determined. For i.i.d. samples, `$\\operatorname{Var}(\\hat{m}) = \\gamma_0/n$`, and `$\\mathbb{E}[\\hat{s}^2] = \\frac{n}{n-1}(\\gamma_0 - \\gamma_0/n) = \\frac{n}{n-1}(\\frac{n-1}{n}\\gamma_0) = \\gamma_0$`, confirming that `$\\hat{s}^2$` is an unbiased estimator of the process variance in the i.i.d. case.\n\n**4. Bias of the Naive Variance Estimator, `$\\operatorname{Bias}_{\\text{naive}}$`**\n\nThe problem defines a naive estimator of the target variance `$\\sigma^2$` as being the sample variance `$\\hat{s}^2$`, which ignores the effects of neural temperature `$T$` and temporal correlation `$\\rho$`. The bias of this naive estimator is:\n$$\n\\operatorname{Bias}_{\\text{naive}} = \\mathbb{E}[\\hat{s}^2] - \\sigma^2\n$$\nSubstituting our result for `$\\mathbb{E}[\\hat{s}^2]$`:\n$$\n\\operatorname{Bias}_{\\text{naive}} = \\frac{n}{n-1} \\left( \\gamma_0 - \\operatorname{Var}(\\hat{m}) \\right) - \\sigma^2\n$$\nSubstituting `$\\gamma_0 = \\sigma^2 T$`:\n$$\n\\operatorname{Bias}_{\\text{naive}} = \\frac{n}{n-1} \\left( \\sigma^2 T - \\operatorname{Var}(\\hat{m}) \\right) - \\sigma^2\n$$\nThis bias has two sources. The first is the temperature mismatch, which contributes a term related to `$\\sigma^2(T-1)$`. The second is the temporal correlation, which enters through the `$\\operatorname{Var}(\\hat{m})$` term. For positive `$\\rho$`, `$\\operatorname{Var}(\\hat{m})`` is larger than in the i.i.d. case, which reduces `$\\mathbb{E}[\\hat{s}^2]$` and thus contributes a negative component to the bias. The opposite is true for negative `$\\rho$`.\n\nThese derived formulae will now be implemented.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes statistical properties of estimators for an AR(1) process\n    based on derived analytical formulas.\n    \"\"\"\n    # Test suite: (n, mu, sigma, T, rho)\n    test_cases = [\n        (1000, 0.0, 1.0, 1.0, 0.0),    # A: independence, happy path\n        (1000, 0.0, 2.0, 1.0, 0.95),   # B: strong positive correlation, large n\n        (200, 1.0, 1.5, 1.0, -0.5),   # C: negative correlation, moderate n\n        (500, 0.5, 1.0, 1.5, 0.7),    # D: temperature mismatch, moderate correlation\n        (20, -1.0, 1.0, 1.0, 0.9),    # E: small sample, high correlation\n    ]\n\n    results = []\n    for case in test_cases:\n        n, mu, sigma, T, rho = case\n        \n        sigma_sq = sigma**2\n        gamma_0 = sigma_sq * T\n\n        # 1. Bias of the sample mean estimator\n        # As derived, E[m_hat] = mu, so the bias is always 0.\n        bias_m = 0.0\n\n        # 2. Variance of the sample mean estimator\n        if n <= 0:\n            # Not applicable, but handle for robustness\n            var_m = np.nan\n        elif rho == 0.0:\n            # i.i.d. case\n            var_m = gamma_0 / n\n        else:\n            # Correlated case, |rho| < 1\n            if abs(rho) >= 1:\n                # Should not happen based on problem constraints\n                var_m = np.inf\n            else:\n                one_minus_rho = 1.0 - rho\n                # Var(m_hat) = (gamma_0 / n) * [ (1+rho)/(1-rho) - (2*rho*(1-rho^n))/(n*(1-rho)^2) ]\n                term1 = (1.0 + rho) / one_minus_rho\n                term2 = (2.0 * rho * (1.0 - np.power(rho, n))) / (n * np.power(one_minus_rho, 2))\n                var_m = (gamma_0 / n) * (term1 - term2)\n\n        # 3. Expected value of the sample variance estimator\n        if n <= 1:\n            # Bessel's correction undefined, but handle for robustness\n            E_s_sq = np.nan\n        else:\n            # E[s^2] = (n / (n-1)) * (gamma_0 - Var(m_hat))\n            E_s_sq = (n / (n - 1.0)) * (gamma_0 - var_m)\n\n        # 4. Bias of the naive variance estimator\n        # Bias_naive = E[s^2] - sigma^2\n        bias_v_naive = E_s_sq - sigma_sq\n\n        # Append results in the specified order\n        results.append(bias_m)\n        results.append(bias_v_naive)\n        results.append(var_m)\n\n    # Format the final output as a single-line string\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}