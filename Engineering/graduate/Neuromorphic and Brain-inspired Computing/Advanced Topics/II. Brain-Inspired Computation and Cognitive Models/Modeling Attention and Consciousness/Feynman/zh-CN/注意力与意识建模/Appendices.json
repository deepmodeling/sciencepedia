{
    "hands_on_practices": [
        {
            "introduction": "注意力的一项核心计算功能是优化大脑对外部世界的推断。本练习将注意力置于贝叶斯推断的框架下，其中注意力通过提高感官测量的精度（方差的倒数）来增强证据的质量，从而形成更确定的后验信念。通过这个练习，你将推导注意力如何量化地减少关于潜在状态的不确定性，这是理解全局工作空间等意识模型的关键一步。",
            "id": "4051876",
            "problem": "一个神经形态观测器对单个潜标量状态 $x$ 执行贝叶斯推断，该状态 $x$ 代表了一个假定的注意力和意识的全局工作空间模型中的瞬时激活水平。该观测器具有一个高斯先验 $p(x) = \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$，反映了皮层活动的缓慢动力学和稳态约束。一个感官测量值 $y$ 由线性高斯观测模型 $y = x + \\eta$ 生成，其中测量噪声 $\\eta \\sim \\mathcal{N}(0, \\sigma_{y}^{2})$ 源于随机脉冲发放和突触传递的可变性。\n\n假设注意力通过一个乘法因子 $k \\geq 1$ 来调节测量精度，这与神经形态电路中的增益控制和随机共振机制一致，因此在注意力作用下，测量噪声方差变为 $\\sigma_{y}^{2}/k$。定义先验精度 $\\tau_{0} = 1/\\sigma_{0}^{2}$ 和基线（注意力前）测量精度 $\\tau_{y} = 1/\\sigma_{y}^{2}$。\n\n仅从贝叶斯定理和高斯分布的概率密度函数出发，推导后验精度作为 $k$ 的函数，并随后推导在注意力作用下给定 $y$ 时 $x$ 的后验方差 $V(k)$。将您的最终答案表示为 $V(k)$ 关于 $\\tau_{0}$、$\\tau_{y}$ 和 $k$ 的单个闭式解析表达式。不需要进行数值计算，最终表达式也不需要单位。",
            "solution": "本问题要求在注意力调节因子 $k$ 的作用下，推导给定感官测量值 $y$ 时潜状态 $x$ 的后验方差，记为 $V(k)$。推导必须从贝叶斯定理和高斯概率密度函数（PDF）的第一性原理出发。\n\n首先，我们确定先验分布和似然分布。\n\n潜状态 $x$ 的先验分布被给定为高斯分布：\n$$p(x) = \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$$\n该分布的概率密度函数正比于：\n$$p(x) \\propto \\exp\\left(-\\frac{(x - \\mu_{0})^{2}}{2\\sigma_{0}^{2}}\\right)$$\n\n感官测量值 $y$ 由线性高斯观测模型 $y = x + \\eta$ 生成。测量噪声 $\\eta$ 是一个高斯随机变量。在注意力调节下，噪声分布由 $\\eta \\sim \\mathcal{N}(0, \\sigma_{y}^{2}/k)$ 给出。根据观测模型，对于给定的状态 $x$，测量值 $y$ 服从以 $x$ 为中心、方差为 $\\sigma_{y}^{2}/k$ 的高斯分布。这定义了似然函数 $p(y|x)$：\n$$p(y|x) = \\mathcal{N}(x, \\sigma_{y}^{2}/k)$$\n对于固定的测量值 $y$，作为 $x$ 的函数，似然函数是：\n$$p(y|x) \\propto \\exp\\left(-\\frac{(y - x)^{2}}{2(\\sigma_{y}^{2}/k)}\\right) = \\exp\\left(-\\frac{k(x - y)^{2}}{2\\sigma_{y}^{2}}\\right)$$\n\n根据贝叶斯定理，给定 $y$ 时 $x$ 的后验概率分布 $p(x|y)$ 正比于似然函数和先验概率的乘积：\n$$p(x|y) \\propto p(y|x) p(x)$$\n代入先验和似然的表达式：\n$$p(x|y) \\propto \\exp\\left(-\\frac{k(x - y)^{2}}{2\\sigma_{y}^{2}}\\right) \\exp\\left(-\\frac{(x - \\mu_{0})^{2}}{2\\sigma_{0}^{2}}\\right)$$\n我们可以合并指数部分：\n$$p(x|y) \\propto \\exp\\left( -\\left[ \\frac{k(x - y)^{2}}{2\\sigma_{y}^{2}} + \\frac{(x - \\mu_{0})^{2}}{2\\sigma_{0}^{2}} \\right] \\right)$$\n\n问题将精度定义为方差的倒数。先验精度为 $\\tau_{0} = 1/\\sigma_{0}^{2}$，基线测量精度为 $\\tau_{y} = 1/\\sigma_{y}^{2}$。我们可以将注意力下的有效测量精度定义为 $\\tau_{y,k} = 1/(\\sigma_{y}^{2}/k) = k/\\sigma_{y}^{2} = k\\tau_{y}$。\n\n将这些精度项代入后验分布的指数中：\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ k\\tau_{y}(x - y)^{2} + \\tau_{0}(x - \\mu_{0})^{2} \\right] \\right)$$\n两个高斯分布的乘积是另一个高斯分布。因此，后验分布 $p(x|y)$ 是一个高斯分布，我们可以将其表示为 $\\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^{2})$。该后验分布的概率密度函数正比于：\n$$p(x|y) \\propto \\exp\\left(-\\frac{(x - \\mu_{\\text{post}})^{2}}{2\\sigma_{\\text{post}}^{2}}\\right) = \\exp\\left(-\\frac{1}{2}\\tau_{\\text{post}}(x - \\mu_{\\text{post}})^{2}\\right)$$\n其中 $\\tau_{\\text{post}} = 1/\\sigma_{\\text{post}}^{2}$ 是后验精度。\n\n为了找到后验方差（或精度），我们可以分析我们推导的后验表达式指数中关于 $x$ 的二次项。让我们展开指数括号内的项：\n$$k\\tau_{y}(x^{2} - 2xy + y^{2}) + \\tau_{0}(x^{2} - 2x\\mu_{0} + \\mu_{0}^{2})$$\n收集包含 $x^{2}$ 的项：\n$$(k\\tau_{y} + \\tau_{0})x^{2} - 2(k\\tau_{y}y + \\tau_{0}\\mu_{0})x + (\\text{terms independent of } x)$$\n高斯概率密度函数指数部分关于其精度 $\\tau_{\\text{post}}$ 的一般形式是 $-\\frac{1}{2}(\\tau_{\\text{post}}x^2 - 2\\tau_{\\text{post}}\\mu_{\\text{post}}x + \\dots)$。通过将我们推导的后验中 $x^{2}$ 项的系数与此一般形式进行比较，我们可以确定后验精度。\n指数中 $x^2$ 的系数是 $-\\frac{1}{2}(k\\tau_{y} + \\tau_{0})$。通过比较，这必须等于 $-\\frac{1}{2}\\tau_{\\text{post}}$。\n因此，后验精度作为注意力增益 $k$ 的函数是：\n$$\\tau_{\\text{post}}(k) = \\tau_{0} + k\\tau_{y}$$\n这个结果阐明了高斯变量贝叶斯融合的一个基本原则：后验精度是先验精度和似然精度之和。\n\n问题要求的是后验方差 $V(k)$。方差是精度的倒数：\n$$V(k) = \\sigma_{\\text{post}}^{2}(k) = \\frac{1}{\\tau_{\\text{post}}(k)}$$\n代入 $\\tau_{\\text{post}}(k)$ 的表达式：\n$$V(k) = \\frac{1}{\\tau_{0} + k\\tau_{y}}$$\n这就是后验方差 $V(k)$ 关于先验精度 $\\tau_{0}$、基线测量精度 $\\tau_{y}$ 和注意力调节因子 $k$ 的最终闭式解析表达式。",
            "answer": "$$\\boxed{\\frac{1}{\\tau_{0} + k\\tau_{y}}}$$"
        },
        {
            "introduction": "在贝叶斯框架下提高测量精度的一种直接方法是放大相关信号。本练习探讨了这种信号放大的直接后果，即对信噪比（SNR）——一个衡量信号质量的基本指标——的影响。通过分析一个将注意力建模为对信号路径施加乘性增益的简化模型，你将从第一性原理出发，量化注意力带来的性能提升。",
            "id": "4051873",
            "problem": "一个神经拟态注意模块对特定的特征通道施加乘法增益，以优先处理与任务相关的输入。考虑一个单通道线性读出模型，其建模如下。设潜在的与刺激对齐的信号为一个零均值、二阶平稳过程，其功率为 $P_{s} = \\mathbb{E}[s^{2}(t)]$，且独立于噪声。该注意机制仅对信号路径施加一个静态的、非负的增益 $g \\geq 0$，产生输出\n$$\ny_{g}(t) = g\\,s(t) + n(t),\n$$\n其中 $n(t)$ 是加性高斯白噪声（AWGN），其均值为零，方差为 $\\sigma^{2}$，独立于 $s(t)$，且不受增益调制。基线（无注意）条件对应于 $g=1$。\n\n使用信噪比（SNR）的标准定义，即输出端信号功率与噪声功率之比，从第一性原理推导出一个精确的、封闭形式的信噪比改善因子 $R(g)$ 的表达式，其定义为\n$$\nR(g) \\triangleq \\frac{\\mathrm{SNR}_{\\text{with gain } g}}{\\mathrm{SNR}_{\\text{baseline}}},\n$$\n该表达式仅用 $g$ 表示。然后，确定使信噪比相对于基线严格改善的最小增益阈值 $g_{\\text{th}}$。\n\n将你的最终答案表示为单行矩阵 $\\begin{pmatrix} R(g) & g_{\\text{th}} \\end{pmatrix}$。最终表达式不需要数值近似，也不需要单位。",
            "solution": "本任务要求推导信噪比（SNR）改善因子 $R(g)$，以及信噪比得到严格改善时的最小增益阈值 $g_{\\text{th}}$。我们从问题陈述中给出的第一性原理开始。\n\n神经拟态注意模块的输出由以下线性模型给出：\n$$y_{g}(t) = g\\,s(t) + n(t)$$\n其中 $s(t)$ 是与刺激对齐的信号，$n(t)$ 是加性噪声，$g$ 是仅施加于信号路径的乘法增益。增益是非负的，即 $g \\geq 0$。\n\n问题指明，信噪比定义为输出端信号功率与噪声功率之比。\n首先，我们确定输出端的信号分量和噪声分量。根据模型的结构，信号分量是 $g\\,s(t)$，噪声分量是 $n(t)$。\n\n输出端信号分量的功率，我们记为 $P_{\\text{signal}, g}$，是其平方的期望值。由于 $g$ 是一个确定性常数：\n$$P_{\\text{signal}, g} = \\mathbb{E}\\left[ (g\\,s(t))^{2} \\right] = \\mathbb{E}\\left[ g^{2}s^{2}(t) \\right] = g^{2}\\mathbb{E}\\left[ s^{2}(t) \\right]$$\n问题陈述中指出，潜在信号 $s(t)$ 是一个零均值过程，其功率为 $P_{s} = \\mathbb{E}[s^{2}(t)]$。将此代入我们的表达式中，得到：\n$$P_{\\text{signal}, g} = g^{2}P_{s}$$\n\n输出端噪声分量的功率 $P_{\\text{noise}, g}$ 是加性噪声过程 $n(t)$ 的功率。问题陈述中指出，$n(t)$ 是加性高斯白噪声（AWGN），其均值为零，方差为 $\\sigma^{2}$。一个零均值过程的功率等于其方差。因此：\n$$P_{\\text{noise}, g} = \\mathbb{E}\\left[ n^{2}(t) \\right] = \\sigma^{2}$$\n如题目所述，噪声功率不受增益 $g$ 的调制。\n\n现在，我们可以将给定增益 $g$ 下的信噪比（记为 $\\mathrm{SNR}_{\\text{with gain } g}$）表示为输出端信号功率与噪声功率之比：\n$$\\mathrm{SNR}_{\\text{with gain } g} = \\frac{P_{\\text{signal}, g}}{P_{\\text{noise}, g}} = \\frac{g^{2}P_{s}}{\\sigma^{2}}$$\n\n接下来，我们确定基线信噪比。基线条件定义为增益 $g=1$ 的情况。将 $g=1$ 代入通用信噪比表达式，得到基线信噪比 $\\mathrm{SNR}_{\\text{baseline}}$：\n$$\\mathrm{SNR}_{\\text{baseline}} = \\frac{1^{2}P_{s}}{\\sigma^{2}} = \\frac{P_{s}}{\\sigma^{2}}$$\n\n信噪比改善因子 $R(g)$ 定义为带增益 $g$ 的信噪比与基线信噪比之比：\n$$R(g) \\triangleq \\frac{\\mathrm{SNR}_{\\text{with gain } g}}{\\mathrm{SNR}_{\\text{baseline}}}$$\n代入上面推导出的表达式：\n$$R(g) = \\frac{\\frac{g^{2}P_{s}}{\\sigma^{2}}}{\\frac{P_{s}}{\\sigma^{2}}}$$\n假设信号功率 $P_{s}$ 和噪声功率 $\\sigma^{2}$ 均大于零（这对于有意义的信噪比计算是隐含的），我们可以消去项 $\\frac{P_{s}}{\\sigma^{2}}$：\n$$R(g) = g^{2}$$\n这就是所要求的、仅用 $g$ 表示的信噪比改善因子的封闭形式表达式。\n\n对于问题的第二部分，我们必须找到使信噪比相对于基线严格改善的最小增益阈值 $g_{\\text{th}}$。当带增益 $g$ 的信噪比严格大于基线信噪比时，即出现严格改善，这等价于条件 $R(g) > 1$。\n使用我们推导出的 $R(g)$ 表达式，我们得到不等式：\n$$g^{2} > 1$$\n我们已知增益 $g$ 是一个非负值，即 $g \\geq 0$。在约束条件 $g \\geq 0$ 下，不等式 $g^{2} > 1$ 的解是：\n$$g > 1$$\n问题要求的是最小增益阈值 $g_{\\text{th}}$，即严格改善区域的边界点。对于任何严格大于此阈值的增益 $g$，信噪比都必须改善。条件 $g>1$ 意味着该阈值为：\n$$g_{\\text{th}} = 1$$\n在 $g=1$ 时，$R(1)=1$，表示与基线相比没有变化。对于任何 $g>1$，$R(g)>1$，表示严格改善。对于任何 $0 \\leq g  1$，$R(g)1$，表示性能下降。因此，阈值是 $g_{\\text{th}}=1$。\n\n最终答案要求将 $R(g)$ 和 $g_{\\text{th}}$ 表示为单个行矩阵。\n两个结果是 $R(g) = g^{2}$ 和 $g_{\\text{th}} = 1$。\n该行矩阵为 $\\begin{pmatrix} g^{2}  1 \\end{pmatrix}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} g^{2}  1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在掌握了注意力在单一通道上的作用机制后，我们将视野拓宽至系统级的资源管理。由于认知资源是有限的，大脑必须在多个并发任务之间有效地分配注意力。本练习将注意力建模为一种可分割的资源，你需要解决一个优化问题，以在总时间预算的约束下最大化总信息增益，这体现了对注意力执行控制的计算经济学视角。",
            "id": "4051839",
            "problem": "考虑一个神经形态多传感器系统，该系统执行 $m$ 个并发感知任务，任务由 $j \\in \\{1,\\dots,m\\}$ 索引。每个任务都涉及从相应的测量流 $Z_{j}$ 中推断一个潜变量 $X_{j}$。假设为任务 $j$ 分配注意力时间 $t_{j} \\ge 0$ 所带来的期望信息增益，由期望互信息 $\\mathbb{E}[I(X_{j};Z_{j}\\,|\\,t_{j})]$ 来量化，其中 $I(X;Z)$ 表示香农信息论意义上的互信息。假设在给定其注意力分配的情况下，各任务是条件独立的，因此总期望信息增益在任务间是可加的。\n\n作为一个资源受限的类脑模型，假设由于噪声和冗余，每个流的编码保真度随着额外注意力时间的增加而表现出收益递减的特性，并且在感兴趣的工作点附近，期望信息增益可以由一个在 $t_{j}=0$ 附近进行泰勒展开得到的二阶凹模型来近似：\n$$\n\\mathbb{E}[I(X_{j};Z_{j}\\,|\\,t_{j})] \\approx \\beta_{j}\\,t_{j} - \\frac{1}{2}\\alpha_{j}\\,t_{j}^{2},\n$$\n其中 $\\beta_{j}  0$ 是在 $t_{j}=0$ 处的一阶边际信息增益，而 $\\alpha_{j}  0$ 是捕捉收益递减特性的曲率。设总注意力时间预算为 $T  0$，并有硬约束 $\\sum_{j=1}^{m} t_{j} = T$ 以及对所有 $j$ 都有 $t_{j} \\ge 0$。\n\n建立并求解分配注意力时间 $\\{t_{j}\\}_{j=1}^{m}$ 的优化问题，以最大化总期望信息增益\n$$\n\\sum_{j=1}^{m}\\left(\\beta_{j}\\,t_{j} - \\frac{1}{2}\\alpha_{j}\\,t_{j}^{2}\\right)\n$$\n约束条件为 $\\sum_{j=1}^{m} t_{j} = T$ 和 $t_{j} \\ge 0$。假设时间预算 $T$ 满足\n$$\n\\sum_{j=1}^{m}\\frac{\\beta_{j}}{\\alpha_{j}} - \\left(\\min_{1\\le j \\le m}\\beta_{j}\\right)\\sum_{j=1}^{m}\\frac{1}{\\alpha_{j}}  T  \\sum_{j=1}^{m}\\frac{\\beta_{j}}{\\alpha_{j}},\n$$\n这确保了一个内点最优解，其中对所有 $j$ 都有 $t_{j}^{\\star}  0$。\n\n推导出最优分配策略，并将其表示为向量 $\\big(t_{1}^{\\star},\\dots,t_{m}^{\\star}\\big)$ 的单个闭式解析表达式，该表达式应明确地用 $\\{\\alpha_{j}\\}$、$\\{\\beta_{j}\\}$ 和 $T$ 来表示。最终答案必须是单个闭式解析表达式。无需进行四舍五入。",
            "solution": "该问题要求找到注意力时间 $\\{t_{j}\\}_{j=1}^{m}$ 的最优分配，以最大化一个总效用函数，该函数是 $m$ 个并发任务的期望信息增益之和。这是一个经典的资源分配问题，可以使用约束优化方法来解决。\n\n优化问题是：\n$$\n\\text{最大化} \\quad F(t_1, \\dots, t_m) = \\sum_{j=1}^{m}\\left(\\beta_{j}\\,t_{j} - \\frac{1}{2}\\alpha_{j}\\,t_{j}^{2}\\right)\n$$\n$$\n\\text{约束条件为} \\quad \\sum_{j=1}^{m} t_{j} = T \\quad \\text{且} \\quad t_j \\ge 0 \\quad \\text{对于 } j=1, \\dots, m.\n$$\n我们构建拉格朗日函数。由于问题中关于 $T$ 的条件确保了一个内点最优解（即对所有 $j$ 都有 $t_j^\\star > 0$），我们可以忽略非负约束 $t_j \\ge 0$（因为它们在最优点处不是活跃的），而只处理等式约束：\n$$\n\\mathcal{L}(t_1, \\dots, t_m, \\lambda) = \\sum_{j=1}^{m}\\left(\\beta_{j}\\,t_{j} - \\frac{1}{2}\\alpha_{j}\\,t_{j}^{2}\\right) - \\lambda\\left(\\sum_{j=1}^{m} t_{j} - T\\right)\n$$\n其中 $\\lambda$ 是与总时间预算约束相关的拉格朗日乘子。为了找到驻点，我们对 $\\mathcal{L}$ 关于每个 $t_{j}$ 求偏导数，并将其设为零：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial t_{j}} = \\beta_{j} - \\alpha_{j} t_{j} - \\lambda = 0\n$$\n这个等式必须对所有的 $j \\in \\{1, \\dots, m\\}$ 成立。从此方程中，我们可以用尚待确定的乘子 $\\lambda$ 来表示每个任务的最优时间 $t_{j}^{\\star}$：\n$$\nt_{j}^{\\star} = \\frac{\\beta_{j} - \\lambda}{\\alpha_{j}}\n$$\n这个方程有一个清晰的解释：最优分配使得所有任务的边际信息增益 $\\frac{\\partial}{\\partial t_j} \\mathbb{E}[I] = \\beta_j - \\alpha_j t_j$ 相等。这个在最优点处的共同边际增益等于拉格朗日乘子 $\\lambda$，它扮演着注意力时间的“影子价格”的角色。\n\n为了求出 $\\lambda$ 的值，我们将 $t_{j}^{\\star}$ 的表达式代入预算约束 $\\sum_{j=1}^{m} t_{j}^{\\star} = T$ 中：\n$$\n\\sum_{j=1}^{m} \\frac{\\beta_{j} - \\lambda}{\\alpha_{j}} = T\n$$\n我们可以对这个方程求解 $\\lambda$：\n$$\n\\sum_{j=1}^{m} \\frac{\\beta_{j}}{\\alpha_{j}} - \\lambda \\sum_{j=1}^{m} \\frac{1}{\\alpha_{j}} = T\n$$\n$$\n\\lambda \\sum_{j=1}^{m} \\frac{1}{\\alpha_{j}} = \\sum_{j=1}^{m} \\frac{\\beta_{j}}{\\alpha_{j}} - T\n$$\n$$\n\\lambda = \\frac{\\sum_{k=1}^{m} \\frac{\\beta_{k}}{\\alpha_{k}} - T}{\\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}}}\n$$\n这里，我们在求和中使用索引 $k$ 以避免与 $t_j^\\star$ 的特定索引 $j$ 混淆。\n\n最后，我们将 $\\lambda$ 的表达式代回到 $t_{j}^{\\star}$ 的方程中：\n$$\nt_{j}^{\\star} = \\frac{1}{\\alpha_j} \\left( \\beta_{j} - \\lambda \\right) = \\frac{1}{\\alpha_j} \\left( \\beta_{j} - \\frac{\\sum_{k=1}^{m} \\frac{\\beta_{k}}{\\alpha_{k}} - T}{\\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}}} \\right)\n$$\n为了将其呈现为单个合并的表达式，我们可以在括号内找到一个公分母：\n$$\nt_{j}^{\\star} = \\frac{1}{\\alpha_j} \\left( \\frac{\\beta_{j} \\left(\\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}}\\right) - \\left(\\sum_{k=1}^{m} \\frac{\\beta_{k}}{\\alpha_{k}} - T\\right)}{\\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}}} \\right)\n$$\n这可以化简为任务 $j$ 的最优时间分配的最终闭式表达式：\n$$\nt_{j}^{\\star} = \\frac{ T + \\beta_{j} \\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}} - \\sum_{k=1}^{m} \\frac{\\beta_{k}}{\\alpha_{k}} }{ \\alpha_{j} \\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}} }\n$$\n这个单一表达式为任何任务 $j \\in \\{1,\\dots,m\\}$ 提供了最优分配 $t_j^\\star$，从而定义了完整的 Optimal 分配向量 $\\big(t_{1}^{\\star},\\dots,t_{m}^{\\star}\\big)$。",
            "answer": "$$\n\\boxed{\nt_{j}^{\\star} = \\frac{T + \\beta_{j} \\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}} - \\sum_{k=1}^{m} \\frac{\\beta_{k}}{\\alpha_{k}}}{\\alpha_{j} \\sum_{k=1}^{m} \\frac{1}{\\alpha_{k}}}\n}\n$$"
        }
    ]
}