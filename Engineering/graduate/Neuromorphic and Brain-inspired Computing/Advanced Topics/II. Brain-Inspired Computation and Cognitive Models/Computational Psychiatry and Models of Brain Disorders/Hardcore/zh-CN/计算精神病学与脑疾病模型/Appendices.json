{
    "hands_on_practices": [
        {
            "introduction": "计算精神病学的研究通常始于构建简化的数学模型，以形式化地表达生物过程与精神症状之间的假说。本练习将探索由内部振荡器控制的昼夜节律与情绪波动之间的关系，并运用泰勒级数展开这一基本数学工具来分析振荡器相位的微小变化对情绪严重程度的影响。通过这项练习 ，您可以掌握将临床假说转化为可操作的数学形式，并使用微积分来预测干预效果的核心技能。",
            "id": "4039927",
            "problem": "一个旨在模拟视交叉上核（SCN）的神经形态昼夜节律模块被建模为单相振荡器，其可观测状态（昼夜节律觉醒的代理指标）由 $s(t) = A \\cos(\\omega t + \\phi)$ 给出，其中 $A$ 是振幅，$\\omega$ 是角频率，$t$ 是从当地午夜开始测量的时间，$\\phi$ 是相位。在一个关于心境障碍严重程度的计算精神病学模型中，瞬时心境症状严重程度 $M(t)$ 在基线工作点附近通过仿射读出近似为 $M(t) \\approx M_{0} + \\alpha s(t)$，其中 $\\alpha$ 是将昼夜节律觉醒转换为严重程度单位的增益，$M_{0}$ 是一个基线项。系统在每天的固定测量时间 $t_{m}$ 被探测。\n\n一种基于光的授时因子（zeitgeber）干预在振荡器中引起一个小的相移 $\\Delta \\phi$，使得干预后状态变为 $s_{\\text{post}}(t) = A \\cos(\\omega t + \\phi_{0} + \\Delta \\phi)$，其中 $\\phi_{0}$ 是干预前的基线相位。假设 $\\Delta \\phi$ 足够小，使得在 $\\Delta \\phi = 0$ 附近的一阶近似有效。\n\n仅从关于谐振子和一阶泰勒展开的公认事实出发，推导在测量时间 $t_{m}$ 心境严重程度的线性化变化，定义为 $\\Delta M = M_{\\text{post}}(t_{m}) - M_{\\text{pre}}(t_{m})$，并用给定参数表示。然后，使用以下科学上合理的参数评估 $\\Delta M$：振幅 $A = 0.7$，增益 $\\alpha = 4.3$，角频率 $\\omega = \\frac{2\\pi}{24}$（弧度/小时），测量时间 $t_{m} = 8$（当地午夜后的小时数），基线相位 $\\phi_{0} = -\\frac{\\pi}{6}$（弧度），以及相移 $\\Delta \\phi = 0.27$（弧度）。将最终的 $\\Delta M$ 表示为一个无量纲量，并将您的答案四舍五入到四位有效数字。",
            "solution": "问题要求推导由昼夜节律振荡器模型中的小相移 $\\Delta \\phi$ 引起的心境严重程度的线性化变化 $\\Delta M$，然后用一组给定的参数来评估这个变化。\n\n首先，我们确定问题陈述中提供的定义。昼夜节律振荡器的状态由一个谐波函数给出：\n$$s(t) = A \\cos(\\omega t + \\phi)$$\n其中 $A$ 是振幅，$\\omega$ 是角频率，$t$ 是时间，$\\phi$ 是相位。\n\n瞬时心境症状严重程度 $M(t)$ 由振荡器状态的仿射变换给出：\n$$M(t) = M_{0} + \\alpha s(t)$$\n其中 $M_{0}$ 是基线严重程度，$\\alpha$ 是增益因子。\n\n测量在每天的固定时间 $t_{m}$ 进行。此时的干预前心境严重程度 $M_{\\text{pre}}(t_{m})$ 基于初始相位 $\\phi_{0}$。\n干预前状态为 $s_{\\text{pre}}(t) = A \\cos(\\omega t + \\phi_{0})$。\n因此，在测量时间的干预前心境严重程度为：\n$$M_{\\text{pre}}(t_{m}) = M_{0} + \\alpha s_{\\text{pre}}(t_{m}) = M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0})$$\n\n基于光的干预引起一个小的相移 $\\Delta \\phi$。干预后状态为 $s_{\\text{post}}(t) = A \\cos(\\omega t + \\phi_{0} + \\Delta \\phi)$。\n在测量时间的干预后心境严重程度为：\n$$M_{\\text{post}}(t_{m}) = M_{0} + \\alpha s_{\\text{post}}(t_{m}) = M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi)$$\n\n心境严重程度的变化 $\\Delta M$ 是在测量时间 $t_{m}$ 的干预后和干预前心境严重程度之间的差值：\n$$\\Delta M = M_{\\text{post}}(t_{m}) - M_{\\text{pre}}(t_{m})$$\n代入 $M_{\\text{post}}$ 和 $M_{\\text{pre}}$ 的表达式：\n$$\\Delta M = \\left( M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) \\right) - \\left( M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n基线项 $M_{0}$ 被消去：\n$$\\Delta M = \\alpha A \\left( \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) - \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n\n问题指出 $\\Delta \\phi$ 很小，这保证了可以在 $\\Delta \\phi = 0$ 附近进行一阶泰勒展开。我们定义一个函数 $f(\\delta) = \\cos(C + \\delta)$，其中 $C = \\omega t_{m} + \\phi_{0}$ 是一个恒定的相角，$\\delta$ 是对应于 $\\Delta \\phi$ 的小扰动。$f(\\delta)$ 在 $\\delta = 0$ 附近的一阶泰勒展开为：\n$$f(\\delta) \\approx f(0) + f'(0) \\delta$$\n该函数及其导数为：\n$$f(\\delta) = \\cos(C + \\delta) \\implies f(0) = \\cos(C)$$\n$$f'(\\delta) = -\\sin(C + \\delta) \\implies f'(0) = -\\sin(C)$$\n因此，近似值为：\n$$\\cos(C + \\delta) \\approx \\cos(C) - \\delta \\sin(C)$$\n代入 $C = \\omega t_{m} + \\phi_{0}$ 和 $\\delta = \\Delta \\phi$，我们得到：\n$$\\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) \\approx \\cos(\\omega t_{m} + \\phi_{0}) - \\Delta \\phi \\sin(\\omega t_{m} + \\phi_{0})$$\n\n现在，我们将这个线性化的表达式代回 $\\Delta M$ 的方程中：\n$$\\Delta M \\approx \\alpha A \\left( \\left( \\cos(\\omega t_{m} + \\phi_{0}) - \\Delta \\phi \\sin(\\omega t_{m} + \\phi_{0}) \\right) - \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n项 $\\cos(\\omega t_{m} + \\phi_{0})$ 被消去，得到心境严重程度线性化变化的最终表达式：\n$$\\Delta M = - \\alpha A \\sin(\\omega t_{m} + \\phi_{0}) \\Delta \\phi$$\n这完成了问题的推导部分。\n\n接下来，我们使用给定的参数评估 $\\Delta M$：\n$A = 0.7$\n$\\alpha = 4.3$\n$\\omega = \\frac{2\\pi}{24} = \\frac{\\pi}{12}$ 弧度/小时\n$t_{m} = 8$ 小时\n$\\phi_{0} = -\\frac{\\pi}{6}$ 弧度\n$\\Delta \\phi = 0.27$ 弧度\n\n首先，我们计算正弦函数的总相位角 $\\omega t_{m} + \\phi_{0}$：\n$$\\omega t_{m} + \\phi_{0} = \\left(\\frac{\\pi}{12} \\text{ rad/hr}\\right) \\times (8 \\text{ hr}) + \\left(-\\frac{\\pi}{6} \\text{ rad}\\right)$$\n$$\\omega t_{m} + \\phi_{0} = \\frac{8\\pi}{12} - \\frac{\\pi}{6} = \\frac{2\\pi}{3} - \\frac{\\pi}{6}$$\n为了进行减法，我们找到一个公分母：\n$$\\omega t_{m} + \\phi_{0} = \\frac{4\\pi}{6} - \\frac{\\pi}{6} = \\frac{3\\pi}{6} = \\frac{\\pi}{2} \\text{ 弧度}$$\n\n现在，我们计算这个角度的正弦值：\n$$\\sin(\\omega t_{m} + \\phi_{0}) = \\sin\\left(\\frac{\\pi}{2}\\right) = 1$$\n\n最后，我们将所有数值代入 $\\Delta M$ 的表达式中：\n$$\\Delta M = - \\alpha A \\sin(\\omega t_{m} + \\phi_{0}) \\Delta \\phi$$\n$$\\Delta M = - (4.3) \\times (0.7) \\times (1) \\times (0.27)$$\n$$\\Delta M = - (3.01) \\times (0.27)$$\n$$\\Delta M = -0.8127$$\n问题指定答案应四舍五入到四位有效数字。计算出的值 $-0.8127$ 已经有四位有效数字。如题目所要求，该量是无量纲的，前提是心境严重程度标尺本身是一个无量纲分数。",
            "answer": "$$\\boxed{-0.8127}$$"
        },
        {
            "introduction": "许多关于幻觉等精神病性症状的理论都是在“贝叶斯大脑”假说的框架下提出的，该假说认为知觉是一个贝叶斯推理过程。本练习旨在探索当大脑对内部预测（先验信念）的权重超过对外部感觉证据的权重时，知觉如何出错。您将模拟一个没有真实刺激存在的场景，并量化先验精度和感觉精度之间的不平衡如何导致错误的知觉 ，从而具体理解先验信念等抽象概念如何通过计算来解释精神病的核心症状。",
            "id": "4039878",
            "problem": "考虑一个单一的潜在连续原因 $x \\in \\mathbb{R}$，代表刺激强度。在贝叶斯感知的预测编码观点中，一个智能体维持着一个关于 $x$ 的高斯先验，即 $x \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$，并接收一个从高斯似然 $y \\sim \\mathcal{N}(x, \\sigma^2)$ 生成的感官观测值 $y \\in \\mathbb{R}$。感官精度定义为 $\\pi_s = 1/\\sigma^2$，先验精度定义为 $\\pi_0 = 1/\\sigma_0^2$。该智能体在正态-正态共轭模型下应用贝叶斯法则，将关于 $x$ 的先验更新为后验，并使用后验均值作为 $x$ 的点估计。然后，该智能体通过将后验均值与决策阈值 $\\tau$ 进行比较，来做出关于是否存在刺激的二元检测决策：如果后验均值 $>$ $\\tau$，则检测到；否则，不检测。\n\n您的任务是构建一个模拟，在该模拟中，真实刺激不存在（即，在所有试验中，潜变量 $x$ 的真实值均为 $0$），并量化在感官精度和先验精度的不同组合下的假阳性检测率（虚警率）。模拟应按以下方式进行：\n- 对于每组参数，从刺激缺失生成模型 $y \\sim \\mathcal{N}(0, \\sigma^2)$ 中抽取 $N$ 个独立的观测值 $y$。\n- 对于每个观测值，使用贝叶斯法则在正态-正态模型下计算后验均值。\n- 应用带有阈值 $\\tau$ 的检测决策规则。\n- 将虚警率报告为尽管刺激不存在但仍发生检测的试验所占的比例。\n- 为了可复现性，使用等于 $42$ 的固定随机种子。\n- 将每个虚警率表示为介于 $0$ 和 $1$ 之间的小数，并四舍五入到 $4$ 位小数。\n\n该模拟必须从第一性原理出发实现正态-正态共轭模型的贝叶斯更新。除了由指定的高斯先验和高斯似然所蕴含的规范贝叶斯更新之外，不得假设任何启发式加权方案。\n\n测试套件：\n为以下每组参数 $(\\sigma^2, \\sigma_0^2, \\mu_0, \\tau, N)$ 计算虚警率：\n1. $(1.0, 1.0, 0.5, 0.2, 100000)$：一个一般情况，具有中等感官精度和中等先验精度，以及一个正的先验均值。\n2. $(25.0, 0.04, 1.0, 0.2, 100000)$：低感官精度与高先验精度相结合，并具有一个强正先验均值。\n3. $(0.01, 10.0, 1.0, 0.2, 100000)$：高感官精度与低先验精度相结合，并具有一个正的先验均值。\n4. $(1.0, 1.0, 0.5, 1.0, 100000)$：一个保守的决策阈值，具有中等的感官和先验精度。\n5. $(1.0, 1.0, 0.5, -0.1, 100000)$：一个宽松的决策阈值，具有中等的感官和先验精度。\n6. $(25.0, 0.04, 0.0, 0.2, 100000)$：低感官精度与高先验精度相结合，但具有一个中性的先验均值。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序与上述测试套件相同。例如，$[\\text{result1},\\text{result2},\\dots]$，其中每个条目都是按规定四舍五入到 $4$ 位小数的虚警率。",
            "solution": "该问题要求模拟一个贝叶斯感知模型，以确定在不同参数条件下的假阳性检测率（虚警率）。该模型基于正态-正态共轭框架，这是贝叶斯统计学的一个基石。解决方案首先推导后验信念的解析形式，然后利用此结果构建数值模拟。\n\n一个理性智能体旨在推断潜在的刺激強度 $x \\in \\mathbb{R}$。该智能体关于 $x$ 的先验信念由一个均值为 $\\mu_0$、方差为 $\\sigma_0^2$ 的高斯分布描述：\n$$p(x) = \\mathcal{N}(x | \\mu_0, \\sigma_0^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp\\left(-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}\\right)$$\n在接收到感官观测值 $y \\in \\mathbb{R}$后，智能体会更新其信念。观测值 $y$ 被假定是从一个以真实潜在原因 $x$ 为中心、方差为 $\\sigma^2$ 的高斯似然函数生成的：\n$$p(y|x) = \\mathcal{N}(y | x, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-x)^2}{2\\sigma^2}\\right)$$\n智能体使用贝叶斯法则将先验信念与感官证据相结合，形成关于 $x$ 的后验信念：\n$$p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$$\n其中 $p(y) = \\int p(y|x)p(x) dx$ 是边际似然或证据。由于我们处理的是共轭分布（高斯先验和高斯似然），后验也将是一个高斯分布，$p(x|y) = \\mathcal{N}(x | \\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$。这个后验分布的参数可以通过检查乘积 $p(y|x)p(x)$ 的指数中的项来推导：\n$$p(x|y) \\propto \\exp\\left(-\\frac{(y-x)^2}{2\\sigma^2}\\right) \\exp\\left(-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}\\right)$$\n$$= \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(x-y)^2}{\\sigma^2} + \\frac{(x-\\mu_0)^2}{\\sigma_0^2} \\right] \\right)$$\n展开指数中关于 $x$ 的二次项：\n$$-\\frac{1}{2} \\left[ \\frac{x^2 - 2xy + y^2}{\\sigma^2} + \\frac{x^2 - 2x\\mu_0 + \\mu_0^2}{\\sigma_0^2} \\right]$$\n$$= -\\frac{1}{2} \\left[ \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\sigma_0^2}\\right)x^2 - 2\\left(\\frac{y}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right)x + \\text{constants} \\right]$$\n通过对 $x$ 配方，我们可以确定后验精度 $\\pi_{\\text{post}} = 1/\\sigma_{\\text{post}}^2$ 和后验均值 $\\mu_{\\text{post}}$。后验精度是似然精度 $\\pi_s = 1/\\sigma^2$ 和先验精度 $\\pi_0 = 1/\\sigma_0^2$ 的和：\n$$\\frac{1}{\\sigma_{\\text{post}}^2} = \\frac{1}{\\sigma^2} + \\frac{1}{\\sigma_0^2}$$\n后验均值 $\\mu_{\\text{post}}$ 是感官观测值 $y$（作为数据驱动的均值）和先验均值 $\\mu_0$ 的精度加权平均值：\n$$\\mu_{\\text{post}} = \\sigma_{\\text{post}}^2 \\left(\\frac{y}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right) = \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\sigma_0^2}\\right)^{-1} \\left(\\frac{y}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right)$$\n简化此表达式可得到后验均值的公式，该公式用作智能体对刺激强度的点估计：\n$$\\mu_{\\text{post}} = \\frac{\\sigma_0^2 y + \\sigma^2 \\mu_0}{\\sigma^2 + \\sigma_0^2}$$\n问题定义了一个模拟，其中真实刺激始终不存在，即真实值为 $x=0$。在每次试验中，从 $x=0$ 的似然模型中生成一个感官观测值 $y$：\n$$y \\sim \\mathcal{N}(0, \\sigma^2)$$\n对于每个这样的观测值 $y$，智能体计算后验均值 $\\mu_{\\text{post}}$。如果该估计值超过决策阈值 $\\tau$，则触发一次检测：\n$$\\text{Detect if } \\mu_{\\text{post}} > \\tau$$\n由于刺激实际上不存在（$x=0$），任何检测都是虚警。虚警率是 $\\mu_{\\text{post}} > \\tau$ 的试验所占的比例。\n\n对于每组参数 $(\\sigma^2, \\sigma_0^2, \\mu_0, \\tau, N)$，模拟算法如下：\n1.  为了可复现性，使用固定的种子 $42$ 初始化一个伪随机数生成器。\n2.  通过从分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽样，生成一个包含 $N$ 个独立感官观测值的向量 $\\{y_i\\}_{i=1}^N$。用于采样的标准差是 $\\sigma = \\sqrt{\\sigma^2}$。\n3.  对于每个观测值 $y_i$，使用推导出的公式计算相应的后验均值 $\\mu_{\\text{post},i}$：\n    $$\\mu_{\\text{post},i} = \\frac{\\sigma_0^2 y_i + \\sigma^2 \\mu_0}{\\sigma^2 + \\sigma_0^2}$$\n    使用向量化操作可以高效地对所有 $N$ 个观测值执行此计算。\n4.  计算满足检测条件的试验次数：$C = \\sum_{i=1}^N \\mathbb{I}(\\mu_{\\text{post},i} > \\tau)$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n5.  虚警率计算为虚警次数与总试验次数的比率：$\\text{FAR} = C/N$。\n6.  按要求将结果四舍入到 $4$ 位小数。\n\n对问题陈述中提供的所有测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates a Bayesian perception model to calculate false alarm rates\n    under different parameter sets.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (sigma_sq, sigma0_sq, mu0, tau, N)\n    test_cases = [\n        (1.0, 1.0, 0.5, 0.2, 100000),\n        (25.0, 0.04, 1.0, 0.2, 100000),\n        (0.01, 10.0, 1.0, 0.2, 100000),\n        (1.0, 1.0, 0.5, 1.0, 100000),\n        (1.0, 1.0, 0.5, -0.1, 100000),\n        (25.0, 0.04, 0.0, 0.2, 100000)\n    ]\n\n    results = []\n    \n    # Set the fixed random seed for reproducibility.\n    seed = 42\n    rng = np.random.default_rng(seed)\n\n    for case in test_cases:\n        sigma_sq, sigma0_sq, mu0, tau, N = case\n\n        # Step 1: Draw N independent observations from the absence generative model.\n        # The model is y ~ N(0, sigma_sq).\n        # np.random.normal takes standard deviation (sigma), not variance (sigma_sq).\n        sigma = np.sqrt(sigma_sq)\n        y_obs = rng.normal(loc=0, scale=sigma, size=N)\n\n        # Step 2: Compute the posterior mean for each observation.\n        # This is the implementation of the formula derived from first principles:\n        # mu_post = (sigma0_sq * y + sigma_sq * mu0) / (sigma_sq + sigma0_sq)\n        numerator = sigma0_sq * y_obs + sigma_sq * mu0\n        denominator = sigma_sq + sigma0_sq\n        mu_post = numerator / denominator\n\n        # Step 3: Apply the detection decision rule and count false alarms.\n        # A false alarm occurs if the posterior mean > tau, as the true stimulus is absent.\n        false_alarms = np.sum(mu_post > tau)\n\n        # Step 4: Calculate the false alarm rate.\n        false_alarm_rate = false_alarms / N\n\n        # Round the result to 4 decimal places as specified.\n        rounded_rate = round(false_alarm_rate, 4)\n        results.append(rounded_rate)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "计算精神病学的一个关键环节不仅是构建模型，更是严格地比较相互竞争的模型，以确定哪一个能更好地解释观察到的患者数据。这项高级练习将指导您构建一个完整的贝叶斯模型比较流程，用以在两种不同的决策强化学习模型之间进行裁决。通过计算每个模型的贝叶斯模型证据并最终得出贝叶斯因子这一原则性模型选择指标，您将掌握一种强大且广泛应用的定量假说检验方法 ，从而超越单一模型的模拟，转向评估不同科学理论的相对优劣。",
            "id": "4039932",
            "problem": "要求您为神经形态和类脑计算领域设计并实现一个完整的、自包含的计算精神病学模型比较流程。目标是使用贝叶斯模型证据和计算贝叶斯因子，来判别两种关于患者决策的竞争性机制解释。您的程序必须是模型比较的一个完整的、可运行的实现，并按照下文指定的方式产生单行输出。\n\n将对两种机制解释进行比较：\n\n- 机制解释 $\\mathcal{M}_1$ (非对称学习率)：一种神经形态强化学习策略，对正预测误差和负预测误差使用不同的学习率，以捕捉常见于心境障碍中的负性偏见。学习率为 $(\\alpha_{+}, \\alpha_{-}) \\in [0,1]^2$。每个动作的潜在价值使用标准的时间差分规则进行更新，选择概率由神经形态价值单元上的 softmax 策略决定。\n\n- 机制解释 $\\mathcal{M}_2$ (多巴胺能奖励衰减)：一种神经形态强化学习策略，具有单一学习率 $\\alpha \\in [0,1]$ 和一个奖励衰减参数 $\\lambda \\in [0,1]$，该参数在更新价值前对接收到的奖励进行缩放。这捕捉了类似快感缺乏的机制，即奖励被感知为不那么显著。\n\n使用的基础理论和定义：\n\n- 贝叶斯模型比较基于概率论和贝叶斯定理。对于任何具有参数 $\\theta$ 和数据 $D$ 的模型 $\\mathcal{M}$，贝叶斯定理表述为 $p(\\theta \\mid D, \\mathcal{M}) \\propto p(D \\mid \\theta, \\mathcal{M}) p(\\theta \\mid \\mathcal{M})$。贝叶斯模型证据（也称为边际似然）定义为\n$$p(D \\mid \\mathcal{M}) = \\int p(D \\mid \\theta, \\mathcal{M}) \\, p(\\theta \\mid \\mathcal{M}) \\, d\\theta.$$\n比较 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的贝叶斯因子定义为\n$$\\mathrm{BF}_{1,2} = \\frac{p(D \\mid \\mathcal{M}_1)}{p(D \\mid \\mathcal{M}_2)}.$$\n\n- 神经形态强化学习策略使用 softmax 决策规则。对于当前价值估计为 $(Q_0, Q_1)$ 和逆温度 $\\kappa > 0$ 的两个动作，在时间 $t$ 选择动作 $c_t \\in \\{0,1\\}$ 的概率为\n$$p(c_t \\mid Q_t, \\kappa) = \\frac{\\exp(\\kappa Q_{t, c_t})}{\\exp(\\kappa Q_{t, 0}) + \\exp(\\kappa Q_{t, 1})}.$$\n在观察到奖励 $r_t \\in [0,1]$ 后，所选动作的价值更新取决于具体的机制解释：\n- 对于 $\\mathcal{M}_1$：定义预测误差 $\\delta_t = r_t - Q_{t, c_t}$。如果 $\\delta_t \\ge 0$，则使用 $\\alpha_{+}$，否则使用 $\\alpha_{-}$，更新规则为\n$$Q_{t+1, c_t} = Q_{t, c_t} + \\alpha_{\\pm} \\, \\delta_t,$$\n未选择动作的价值保持不变，$Q_{t+1, \\text{other}} = Q_{t, \\text{other}}$。\n- 对于 $\\mathcal{M}_2$：计算衰减后的奖励 $r'_t = \\lambda \\, r_t$。然后预测误差为 $\\delta_t = r'_t - Q_{t, c_t}$，更新规则为\n$$Q_{t+1, c_t} = Q_{t, c_t} + \\alpha \\, \\delta_t,$$\n其中 $Q_{t+1, \\text{other}} = Q_{t, \\text{other}}$。\n\n- 初始价值为 $Q_{0,0} = 0$ 和 $Q_{0,1} = 0$。所有情况和模型中的逆温度固定为 $\\kappa = 5.0$（无量纲）。以上所有量均为无量纲；无需物理单位。\n\n- 先验：对于 $\\mathcal{M}_1$，对学习率使用独立的 Beta 先验：\n$$\\alpha_{+} \\sim \\mathrm{Beta}(2,2), \\quad \\alpha_{-} \\sim \\mathrm{Beta}(2,2).$$\n对于 $\\mathcal{M}_2$，使用独立的 Beta 先验\n$$\\alpha \\sim \\mathrm{Beta}(2,2), \\quad \\lambda \\sim \\mathrm{Beta}(3,2).$$\n对于 $x \\in (0,1)$ 和形状参数 $(a,b)$，Beta 密度为\n$$f(x \\mid a,b) = \\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)},$$\n其中 $B(a,b)$ 是 Beta 函数。\n\n对于数据集 $D=\\{(c_t, r_t)\\}_{t=1}^T$ 的似然构建：\n\n- 对于给定模型的任意参数 $\\theta$，似然 $p(D \\mid \\theta, \\mathcal{M})$ 是各试验中选择概率的乘积，这些选择概率是基于当前价值和 softmax 规则给出的，\n$$p(D \\mid \\theta, \\mathcal{M}) = \\prod_{t=1}^T p(c_t \\mid Q_t(\\theta), \\kappa),$$\n其中 $Q_t(\\theta)$ 根据模型的更新规则和观察到的奖励 $r_t$ 进行演化。\n\n数值评估要求：\n\n- 通过在参数域上进行数值积分来计算每个模型的贝叶斯模型证据 $p(D \\mid \\mathcal{M})$，使用在区间 $[\\epsilon, 1-\\epsilon]$ 上每个参数维度 $N = 101$ 个点的均匀网格，其中 $\\epsilon = 10^{-6}$。离散近似为\n$$p(D \\mid \\mathcal{M}) \\approx \\sum_{i} \\sum_{j} \\cdots \\left( p(D \\mid \\theta_{i,j,\\ldots}, \\mathcal{M}) \\, p(\\theta_{i,j,\\ldots} \\mid \\mathcal{M}) \\right) \\prod_{d} \\Delta_d,$$\n其中 $\\Delta_d$ 是维度 $d$ 的网格步长。为了数值稳定性，请使用 log-sum-exp 算子在对数域中进行求和计算。\n\n测试套件：\n\n为以下三个数据集提供结果（每个数据集都是 $T=8$ 次试验的序列）。每个数据集包含选择和奖励：\n- 案例 1 (混合奖励和选择)：选择 $[0,0,1,1,0,1,0,1]$，奖励 $[1,0,1,0,1,1,0,0]$。\n- 案例 2 (边界情况，零奖励)：选择 $[0,1,0,1,0,1,0,1]$，奖励 $[0,0,0,0,0,0,0,0]$。\n- 案例 3 (对某一动作的奖励一致，且主要选择该动作)：选择 $[0,0,0,0,1,0,0,0]$，奖励 $[1,1,1,1,0,1,1,1]$。\n\n您的程序必须：\n- 实现所述的两种机制解释。\n- 对于每个数据集，通过基于网格的数值积分（$N=101$ 和 $\\epsilon = 10^{-6}$）计算 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的贝叶斯模型证据。\n- 为每个数据集计算贝叶斯因子 $\\mathrm{BF}_{1,2}$。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含三个测试案例的贝叶斯因子，形式为用方括号括起来的逗号分隔列表。每个贝叶斯因子必须是浮点数，四舍五入到六位小数，并按案例 1、2、3 的顺序列出，例如 $[bf_1,bf_2,bf_3]$，其中每个 $bf_i$ 是一个四舍五入到六位小数的十进制数。",
            "solution": "目标是执行两种强化学习机制模型（指定为 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$）的贝叶斯模型比较，这两种模型代表了关于决策功能障碍的竞争性假设。比较通过贝叶斯因子 $\\mathrm{BF}_{1,2}$ 来裁定，它量化了给定数据集 $D$ 支持 $\\mathcal{M}_1$ 相对于 $\\mathcal{M}_2$ 的证据。\n\n贝叶斯模型比较的核心是贝叶斯因子，定义为模型证据（或边际似然）的比率：\n$$\n\\mathrm{BF}_{1,2} = \\frac{p(D \\mid \\mathcal{M}_1)}{p(D \\mid \\mathcal{M}_2)}\n$$\n这需要计算每个模型的模型证据 $p(D \\mid \\mathcal{M})$。证据是通过将数据的似然 $p(D \\mid \\theta, \\mathcal{M})$ 在整个参数空间 $\\theta$ 上进行积分得到的，并由参数的先验概率 $p(\\theta \\mid \\mathcal{M})$ 加权：\n$$\np(D \\mid \\mathcal{M}) = \\int p(D \\mid \\theta, \\mathcal{M}) \\, p(\\theta \\mid \\mathcal{M}) \\, d\\theta\n$$\n对于本问题，被积函数的两个组成部分——似然和先验——都有明确的定义。\n\n似然函数 $p(D \\mid \\theta, \\mathcal{M})$ 源于智能体的决策过程。对于一个包含一系列选择 $c_t$ 和奖励 $r_t$ 的数据集 $D = \\{(c_t, r_t)\\}_{t=1}^T$，总似然是每个单独选择概率的乘积，这些概率以截至该时间点的动作和奖励历史为条件。这个历史被封装在学习到的动作价值估计 $Q_t$ 中。\n$$\np(D \\mid \\theta, \\mathcal{M}) = \\prod_{t=1}^T p(c_t \\mid Q_t(\\theta), \\kappa)\n$$\n计算这个似然需要对给定的一组参数 $\\theta$，逐个试验地模拟智能体的学习过程。该过程如下：\n1.  将动作价值初始化为零：$Q_{0,0} = 0.0$ 和 $Q_{0,1} = 0.0$。\n2.  对于从 $1$ 到 $T$ 的每个试验 $t$：\n    a. 使用 softmax 函数计算智能体做出观察到的选择 $c_t$ 的概率，逆温度固定为 $\\kappa = 5.0$：\n    $$p(c_t \\mid Q_t, \\kappa) = \\frac{\\exp(\\kappa Q_{t, c_t})}{\\exp(\\kappa Q_{t, 0}) + \\exp(\\kappa Q_{t, 1})}$$\n    b. 根据特定模型 $\\mathcal{M}_1$ 或 $\\mathcal{M}_2$ 的规则更新所选动作的价值 $Q_{t, c_t}$。未选择动作的价值保持不变。\n\n两种模型在价值更新机制上有所不同：\n- **模型 $\\mathcal{M}_1$ (非对称学习率)：** 该模型的参数为 $\\theta_1 = (\\alpha_+, \\alpha_-)$。预测误差是 $\\delta_t = r_t - Q_{t,c_t}$。更新规则为 $Q_{t+1, c_t} = Q_{t, c_t} + \\alpha_{\\pm} \\delta_t$，其中如果 $\\delta_t \\ge 0$ 则使用 $\\alpha_+$，如果 $\\delta_t  0$ 则使用 $\\alpha_-$。\n- **模型 $\\mathcal{M}_2$ (奖励衰减)：** 该模型的参数为 $\\theta_2 = (\\alpha, \\lambda)$。奖励首先被衰减，$r'_t = \\lambda r_t$。然后预测误差为 $\\delta_t = r'_t - Q_{t,c_t}$，更新规则为 $Q_{t+1, c_t} = Q_{t, c_t} + \\alpha \\delta_t$。\n\n为保证数值稳定性，所有似然计算都在对数域中执行。对于给定的 $\\theta$，总对数似然是每个选择的对数概率之和：$\\mathcal{L}(\\theta) = \\sum_{t=1}^T \\log p(c_t \\mid Q_t(\\theta), \\kappa)$。\n\n先验分布 $p(\\theta \\mid \\mathcal{M})$ 编码了我们在观察数据之前对参数的信念。问题为所有参数指定了 Beta 分布：\n- 对于 $\\mathcal{M}_1$：$\\alpha_+ \\sim \\mathrm{Beta}(2,2)$ 和 $\\alpha_- \\sim \\mathrm{Beta}(2,2)$。联合先验为 $p(\\theta_1 \\mid \\mathcal{M}_1) = p(\\alpha_+ \\mid a=2, b=2) p(\\alpha_- \\mid a=2, b=2)$。\n- 对于 $\\mathcal{M}_2$：$\\alpha \\sim \\mathrm{Beta}(2,2)$ 和 $\\lambda \\sim \\mathrm{Beta}(3,2)$。联合先验为 $p(\\theta_2 \\mid \\mathcal{M}_2) = p(\\alpha \\mid a=2, b=2) p(\\lambda \\mid a=3, b=2)$。\n\n模型证据的积分是解析上难解的，因此我们采用数值积分。每个模型的二维参数空间被离散化为一个 $N \\times N$ 的均匀网格，其中 $N=101$。每个参数的网格范围为 $[\\epsilon, 1-\\epsilon]$，其中 $\\epsilon = 10^{-6}$。积分通过对所有网格点 $(\\theta_{ij})$ 的求和来近似：\n$$p(D \\mid \\mathcal{M}) \\approx \\sum_{i=1}^N \\sum_{j=1}^N p(D \\mid \\theta_{ij}, \\mathcal{M}) p(\\theta_{ij} \\mid \\mathcal{M}) \\Delta^2$$\n其中 $\\Delta = (1 - 2\\epsilon) / (N-1)$ 是网格间距。为避免下溢和其他数值问题，此和在对数域中计算。对数证据为：\n$$\n\\log p(D \\mid \\mathcal{M}) \\approx \\log \\left( \\sum_{i,j} \\exp(\\mathcal{L}(\\theta_{ij}) + \\log p(\\theta_{ij} \\mid \\mathcal{M})) \\right) + 2\\log(\\Delta)\n$$\n求和项使用 log-sum-exp 算法计算，该算法提供了数值稳定性。\n\n算法实现遵循了这一原则性设计。一个主函数遍历所提供的三个数据集。对于每个数据集，它为两个模型中的每一个调用一个专门的函数 `calculate_log_evidence`。此函数构建参数网格，并为网格上的每个点计算对数先验（使用 `scipy.stats.beta.logpdf`）和对数似然。对数似然函数本身模拟了智能体的逐次试验行为。得到的对数后验项（对数似然加对数先验）使用 `scipy.special.logsumexp` 进行聚合，以计算对数证据。最后，从对数证据计算贝叶斯因子：$\\mathrm{BF}_{1,2} = \\exp(\\log p(D \\mid \\mathcal{M}_1) - \\log p(D \\mid \\mathcal{M}_2))$。然后将每个案例的结果按要求进行四舍五入和格式化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta\nfrom scipy.special import logsumexp\n\ndef calculate_log_likelihood_m1(data, params, kappa):\n    \"\"\"\n    Calculates the total log-likelihood for Model 1 (asymmetric learning rates).\n    \n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        params (tuple): A tuple of (alpha_pos, alpha_neg).\n        kappa (float): The inverse temperature parameter.\n\n    Returns:\n        float: The total log-likelihood of the data given the parameters.\n    \"\"\"\n    alpha_pos, alpha_neg = params\n    choices, rewards = data\n    \n    Q = np.array([0.0, 0.0])\n    total_log_likelihood = 0.0\n\n    for t in range(len(choices)):\n        c_t, r_t = choices[t], rewards[t]\n        \n        # Calculate log-probability of the choice\n        kappa_Q = kappa * Q\n        log_softmax_den = logsumexp(kappa_Q)\n        log_prob_choice = kappa_Q[c_t] - log_softmax_den\n        total_log_likelihood += log_prob_choice\n        \n        # Update Q-value based on M1's rule\n        delta = r_t - Q[c_t]\n        alpha = alpha_pos if delta = 0.0 else alpha_neg\n        Q[c_t] += alpha * delta\n        \n    return total_log_likelihood\n\ndef calculate_log_likelihood_m2(data, params, kappa):\n    \"\"\"\n    Calculates the total log-likelihood for Model 2 (reward attenuation).\n\n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        params (tuple): A tuple of (alpha, lambda).\n        kappa (float): The inverse temperature parameter.\n\n    Returns:\n        float: The total log-likelihood of the data given the parameters.\n    \"\"\"\n    alpha, lam = params\n    choices, rewards = data\n    \n    Q = np.array([0.0, 0.0])\n    total_log_likelihood = 0.0\n\n    for t in range(len(choices)):\n        c_t, r_t = choices[t], rewards[t]\n        \n        # Calculate log-probability of the choice\n        kappa_Q = kappa * Q\n        log_softmax_den = logsumexp(kappa_Q)\n        log_prob_choice = kappa_Q[c_t] - log_softmax_den\n        total_log_likelihood += log_prob_choice\n        \n        # Update Q-value based on M2's rule\n        r_prime = lam * r_t\n        delta = r_prime - Q[c_t]\n        Q[c_t] += alpha * delta\n        \n    return total_log_likelihood\n\ndef compute_log_evidence(data, priors_ab, likelihood_func, n_grid, epsilon, kappa):\n    \"\"\"\n    Computes the log model evidence via grid-based numerical integration.\n\n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        priors_ab (list): A list of [a,b] for the Beta priors of the two parameters.\n        likelihood_func (function): The function to compute log-likelihood.\n        n_grid (int): The number of points on the grid for each parameter.\n        epsilon (float): The small offset for the grid boundaries.\n        kappa (float): The inverse temperature.\n\n    Returns:\n        float: The log model evidence.\n    \"\"\"\n    grid_points = np.linspace(epsilon, 1.0 - epsilon, n_grid)\n    delta = (1.0 - 2.0 * epsilon) / (n_grid - 1.0)\n    log_delta = np.log(delta)\n\n    priors = [(priors_ab[0][0], priors_ab[0][1]), (priors_ab[1][0], priors_ab[1][1])]\n    \n    log_prior1_vals = beta.logpdf(grid_points, priors[0][0], priors[0][1])\n    log_prior2_vals = beta.logpdf(grid_points, priors[1][0], priors[1][1])\n    \n    # Using a meshgrid is more efficient than nested Python loops\n    p1_grid, p2_grid = np.meshgrid(grid_points, grid_points, indexing='ij')\n\n    log_prior_grid = log_prior1_vals[:, np.newaxis] + log_prior2_vals[np.newaxis, :]\n    \n    # Vectorize the likelihood calculation over the grid\n    # This involves a Python loop, but it's cleaner than passing the whole grid\n    # to the likelihood function, which is stateful (trial-by-trial).\n    log_likelihood_grid = np.zeros_like(p1_grid)\n    for i in range(n_grid):\n        for j in range(n_grid):\n            params = (p1_grid[i, j], p2_grid[i, j])\n            log_likelihood_grid[i, j] = likelihood_func(data, params, kappa)\n\n    log_posterior_terms = log_likelihood_grid + log_prior_grid\n    \n    # Sum over the 2D grid and add the log of the volume element (Delta^2)\n    log_sum_evidence = logsumexp(log_posterior_terms)\n    log_evidence = log_sum_evidence + 2.0 * log_delta\n    \n    return log_evidence\n\ndef solve():\n    \"\"\"\n    Main function to run the model comparison pipeline for the test cases.\n    \"\"\"\n    KAPPA = 5.0\n    N_GRID = 101\n    EPSILON = 1e-6\n\n    test_cases = [\n        # Case 1: mixed rewards and choices\n        ((0,0,1,1,0,1,0,1), (1,0,1,0,1,1,0,0)),\n        # Case 2: boundary, zero rewards\n        ((0,1,0,1,0,1,0,1), (0,0,0,0,0,0,0,0)),\n        # Case 3: consistent reward on one action\n        ((0,0,0,0,1,0,0,0), (1,1,1,1,0,1,1,1)),\n    ]\n\n    priors_m1 = [[2.0, 2.0], [2.0, 2.0]] # (alpha+, alpha-)\n    priors_m2 = [[2.0, 2.0], [3.0, 2.0]] # (alpha, lambda)\n\n    results = []\n    for data in test_cases:\n        # Pre-process data for convenience\n        choices, rewards = np.array(data[0]), np.array(data[1])\n        formatted_data = (choices, rewards)\n\n        # Compute log evidence for Model 1\n        log_evidence_m1 = compute_log_evidence(\n            formatted_data, priors_m1, calculate_log_likelihood_m1,\n            N_GRID, EPSILON, KAPPA\n        )\n\n        # Compute log evidence for Model 2\n        log_evidence_m2 = compute_log_evidence(\n            formatted_data, priors_m2, calculate_log_likelihood_m2,\n            N_GRID, EPSILON, KAPPA\n        )\n        \n        # Compute Bayes Factor BF_{1,2}\n        log_bf_12 = log_evidence_m1 - log_evidence_m2\n        bf_12 = np.exp(log_bf_12)\n        \n        results.append(f\"{bf_12:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}