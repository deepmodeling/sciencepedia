{
    "hands_on_practices": [
        {
            "introduction": "要构建脉冲卷积神经网络，我们首先需要为神经元之间的通信方式建模。本练习将回归基础，探究 alpha 函数，这是一个用于描述单个脉冲产生的突触后电流的经典模型。通过分析其关键特性，我们将在生物物理现实与网络中使用的抽象突触权重之间建立联系 。",
            "id": "4060537",
            "problem": "考虑一个脉冲卷积神经网络 (SCNN) 内的单个突触连接，其中在时间 $t=0$ 处的突触前脉冲会引起一个用于时域卷积的突触后电流核。该突触后电流由一个 $\\alpha$-函数 建模，该函数源于 2 个时间常数为 $\\tau>0$ 的相同一阶突触滤波器的级联，其表达式为\n$$\n\\alpha(t) \\;=\\; A \\,\\frac{t}{\\tau}\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\,H(t),\n$$\n其中 $A>0$ 是一个幅度缩放常数，$H(t)$ 是 Heaviside 阶跃函数（当 $t<0$ 时，$H(t)=0$；当 $t\\ge 0$ 时，$H(t)=1$）。在此设置中，突触效能或权重 $w$ 操作性地定义为由单个脉冲引起的总电荷转移量，即 $w = \\int_{0}^{\\infty} \\alpha(t)\\,dt$。\n\n从峰值时间和总电荷转移量的定义出发，并仅使用基础微积分和线性时不变系统原理，完成以下任务：\n- 确定当 $t\\ge 0$ 时 $\\alpha(t)$ 的峰值时间 $t_{\\mathrm{peak}}$。\n- 确定峰值幅度 $\\alpha(t_{\\mathrm{peak}})$。\n- 计算积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$，并使用操作性定义 $w = \\int_{0}^{\\infty} \\alpha(t)\\,dt$ 来用 $w$ 和 $\\tau$ 表示幅度缩放常数 $A$，然后完全用 $w$ 和 $\\tau$ 表示 $\\alpha(t_{\\mathrm{peak}})$。\n\n将你的最终答案表示为一个单行矩阵，其中依次包含 $t_{\\mathrm{peak}}$、$\\alpha(t_{\\mathrm{peak}})$ 和 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$ 的表达式。不需要数值近似。最终答案中不要包含单位。",
            "solution": "我们已知突触后电流核为 $\\alpha$-函数：\n$$\n\\alpha(t) \\;=\\; A \\,\\frac{t}{\\tau}\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\,H(t)\n$$\n参数为 $A > 0$ 和 $\\tau > 0$。对于 $t \\ge 0$，$H(t)=1$，因此函数简化为：\n$$\n\\alpha(t) \\;=\\; \\frac{A}{\\tau}\\,t\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\n$$\n突触权重 $w$ 定义为总电荷转移量：\n$$\nw = \\int_{0}^{\\infty} \\alpha(t)\\,dt\n$$\n\n首先，我们通过求 $\\alpha(t)$ 在 $t \\ge 0$ 上的最大值来确定峰值时间 $t_{\\mathrm{peak}}$。这发生在 $\\alpha(t)$ 对 $t$ 的一阶导数为零的位置。我们使用微分乘法法则 $\\frac{d}{dt}(uv) = u'v + uv'$，其中 $u=t$ 且 $v=\\exp(-t/\\tau)$。\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\frac{d}{dt} \\left[ t \\exp\\left(-\\frac{t}{\\tau}\\right) \\right] = \\frac{A}{\\tau} \\left[ \\frac{d(t)}{dt} \\exp\\left(-\\frac{t}{\\tau}\\right) + t \\frac{d}{dt}\\left(\\exp\\left(-\\frac{t}{\\tau}\\right)\\right) \\right]\n$$\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\left[ (1) \\exp\\left(-\\frac{t}{\\tau}\\right) + t \\left(-\\frac{1}{\\tau}\\right)\\exp\\left(-\\frac{t}{\\tau}\\right) \\right]\n$$\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\exp\\left(-\\frac{t}{\\tau}\\right) \\left( 1 - \\frac{t}{\\tau} \\right)\n$$\n将导数设为 $0$ 以找到临界点：\n$$\n\\frac{A}{\\tau} \\exp\\left(-\\frac{t}{\\tau}\\right) \\left( 1 - \\frac{t}{\\tau} \\right) = 0\n$$\n因为 $A > 0$、$\\tau > 0$，并且对于有限的 $t$，$\\exp(-t/\\tau)$ 总是正的，所以该方程仅在括号中的项为零时成立：\n$$\n1 - \\frac{t}{\\tau} = 0 \\quad \\implies \\quad t = \\tau\n$$\n为了确认这是一个最大值，我们可以检查二阶导数，但从函数的行为（$\\alpha(0)=0$ 且当 $t \\to \\infty$ 时 $\\alpha(t) \\to 0$）可以清楚地看出，这个对于 $t>0$ 的单临界点必定是全局最大值。\n因此，峰值时间为：\n$$\nt_{\\mathrm{peak}} = \\tau\n$$\n\n接下来，我们通过将 $t_{\\mathrm{peak}} = \\tau$ 代入 $\\alpha(t)$ 的表达式来确定峰值幅度 $\\alpha(t_{\\mathrm{peak}})$：\n$$\n\\alpha(t_{\\mathrm{peak}}) = \\alpha(\\tau) = \\frac{A}{\\tau} (\\tau) \\exp\\left(-\\frac{\\tau}{\\tau}\\right) = A \\cdot 1 \\cdot \\exp(-1) = \\frac{A}{e}\n$$\n\n现在，我们计算积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$，它定义了突触权重 $w$。\n$$\nw = \\int_{0}^{\\infty} \\frac{A}{\\tau} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = \\frac{A}{\\tau} \\int_{0}^{\\infty} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt\n$$\n我们使用分部积分法 $\\int u \\,dv = uv - \\int v \\,du$。令：\n- $u = t \\implies du = dt$\n- $dv = \\exp(-t/\\tau) dt \\implies v = -\\tau \\exp(-t/\\tau)$\n\n$$\n\\int t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = t \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) - \\int \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) dt\n$$\n$$\n= -t\\tau \\exp\\left(-\\frac{t}{\\tau}\\right) + \\tau \\int \\exp\\left(-\\frac{t}{\\tau}\\right) dt\n$$\n$$\n= -t\\tau \\exp\\left(-\\frac{t}{\\tau}\\right) + \\tau \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) = -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2)\n$$\n现在我们应用从 $0$ 到 $\\infty$ 的定积分限：\n$$\n\\int_{0}^{\\infty} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = \\left[ -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2) \\right]_{0}^{\\infty}\n$$\n在上限 $t \\to \\infty$ 处求值：$\\lim_{t\\to\\infty} \\left[ -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2) \\right] = 0$，因为指数衰减到零的速度比多项式增长快。\n在下限 $t=0$ 处求值：$-\\exp(0)(0 \\cdot \\tau + \\tau^2) = -1(0 + \\tau^2) = -\\tau^2$。\n该定积分的值为 $(0) - (-\\tau^2) = \\tau^2$。\n\n将此结果代回 $w$ 的表达式中：\n$$\nw = \\frac{A}{\\tau} (\\tau^2) = A\\tau\n$$\n所以，积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$ 的值是 $A\\tau$。根据问题的定义，这个值用 $w$ 表示。\n\n使用关系式 $w = A\\tau$，我们用 $w$ 和 $\\tau$ 来表示幅度缩放常数 $A$：\n$$\nA = \\frac{w}{\\tau}\n$$\n\n最后，我们用 $w$ 和 $\\tau$ 表示峰值幅度 $\\alpha(t_{\\mathrm{peak}})$。我们之前得到 $\\alpha(t_{\\mathrm{peak}}) = A/e$。代入 $A$ 的表达式：\n$$\n\\alpha(t_{\\mathrm{peak}}) = \\frac{1}{e} \\left(\\frac{w}{\\tau}\\right) = \\frac{w}{e\\tau}\n$$\n\n需要报告的三个量是 $t_{\\mathrm{peak}}$、用 $w$ 和 $\\tau$ 表示的 $\\alpha(t_{\\mathrm{peak}})$，以及计算出的积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$。问题将此积分定义为 $w$，因此这就是它的计算符号值。\n结果是：\n- $t_{\\mathrm{peak}} = \\tau$\n- $\\alpha(t_{\\mathrm{peak}}) = \\frac{w}{e\\tau}$\n- $\\int_{0}^{\\infty} \\alpha(t) \\,dt = w$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\tau & \\frac{w}{e\\tau} & w \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在理解了突触后响应之后，我们现在将视角扩展到整个网络层。脉冲卷积神经网络的一个关键优势在于其计算效率，这种效率源于其只在“事件”（即脉冲）发生时才进行信息处理。本练习要求您通过推导脉冲卷积的计算成本，来量化这一优势，从而为 SCNN 的高效率提供坚实的理论基础 。",
            "id": "4060527",
            "problem": "考虑一个尺寸为 $H \\times W$ 的二维脉冲输入图，其上正好有 $S$ 个非零脉冲事件，位于规则网格的整数坐标 $\\{(i_{\\ell}, j_{\\ell})\\}_{\\ell=1}^{S}$ 上。一个单输入、单输出通道、卷积核支持大小为 $k \\times k$、步长为 $s$ 的二维跨步卷积以事件驱动（分散）的方式实现：对于每个位于位置 $(i, j)$ 且值 $x[i,j] \\neq 0$ 的输入脉冲事件，其贡献仅传播给那些在该跨步卷积下感受野包含 $(i,j)$ 的输出神经元。假设有足够的零填充以实现标准的“相同”卷积形状，并忽略边界截断，从而使得 $\\{0,1,\\dots,k-1\\}$ 内的任何卷积核偏移都是允许的。同时假设，在每个维度上，脉冲位置在模 $s$ 的步长余数类上均匀分布，并且在此计数步骤中没有阈值化或非线性操作。\n\n仅从离散二维跨步卷积的定义和所述的事件驱动分散规则出发，推导每个输入脉冲事件的以下期望数量：\n1) 突触事件计算（即，与卷积核权重实际执行的乘法累加运算），以及\n2) 不同的输出事件候选（即，从输入事件接收到非零贡献的不同输出晶格位置）。\n\n将两个答案表示为仅取决于 $k$ 和 $s$ 的闭式解析表达式。将最终结果以一个两元素行向量的形式报告，其中第一个元素是每个输入事件的期望突触事件计算次数，第二个元素是每个输入事件的期望输出事件候选数量。不需要进行数值舍入，也不适用任何物理单位。",
            "solution": "设输入网格由 $(i,j)$ 索引，输出网格由 $(p,q)$ 索引。在一个核大小为 $k \\times k$、步长为 $s$ 的二维卷积中，位于 $(p,q)$ 的输出神经元的感受野覆盖了输入的一个 $k \\times k$ 区域。假设在一个已适当处理填充的坐标系中，该区域的左上角位于输入坐标 $(s \\cdot p, s \\cdot q)$。因此，输出神经元 $(p,q)$ 的感受野覆盖了输入坐标 $(i', j')$，其中：\n$$s \\cdot p \\leq i' \\leq s \\cdot p + k - 1$$\n$$s \\cdot q \\leq j' \\leq s \\cdot q + k - 1$$\n\n问题描述了一种基于分散的实现。对于位于 $(i,j)$ 的单个输入脉冲，我们必须确定所有受影响的输出神经元 $(p,q)$。当且仅当输入位置 $(i,j)$ 落在输出神经元 $(p,q)$ 的感受野内时，才会发生这种情况。将上述不等式中的 $(i', j')$ 设为 $(i, j)$，我们得到：\n$$s \\cdot p \\leq i \\leq s \\cdot p + k - 1$$\n$$s \\cdot q \\leq j \\leq s \\cdot q + k - 1$$\n\n为了找到受影响的整数输出坐标 $(p,q)$ 的范围，我们重排这些不等式：\n对于第一维：\n$$i - (k - 1) \\leq s \\cdot p \\leq i$$\n$$\\frac{i - k + 1}{s} \\leq p \\leq \\frac{i}{s}$$\n由于 $p$ 必须是整数， $p$ 的可能值范围由下式给出：\n$$p \\in \\left[ \\lceil \\frac{i - k + 1}{s} \\rceil, \\lfloor \\frac{i}{s} \\rfloor \\right]$$\n类似地，对于第二维：\n$$q \\in \\left[ \\lceil \\frac{j - k + 1}{s} \\rceil, \\lfloor \\frac{j}{s} \\rfloor \\right]$$\n\n受到位置 $(i,j)$ 的脉冲影响的不同输出神经元的数量是满足这些条件的整数对 $(p,q)$ 的总数。设 $N_p(i)$ 为 $p$ 的可能整数值的数量，$N_q(j)$ 为 $q$ 的可能整数值的数量。受影响的输出神经元总数为 $N_{out}(i,j) = N_p(i) \\cdot N_q(j)$。\n\n我们要计算的两个量——“不同的输出事件候选”和“突触事件计算”——都等于受影响的输出神经元的数量 $N_{out}(i,j)$。我们的任务是求 $N_{out}(i,j)$ 的期望值。由于 $i$ 和 $j$ 的位置分布是独立的，乘积的期望等于期望的乘积：\n$$E[N_{out}(i,j)] = E[N_p(i)] \\cdot E[N_q(j)]$$\n\n让我们计算 $E[N_p(i)]$。区间 $[\\alpha, \\beta]$ 中的整数个数为 $\\lfloor\\beta\\rfloor - \\lceil\\alpha\\rceil + 1$。\n$$N_p(i) = \\left\\lfloor \\frac{i}{s} \\right\\rfloor - \\left\\lceil \\frac{i - k + 1}{s} \\right\\rceil + 1$$\n设 $i = z_i s + r_i$，其中 $r_i = i \\pmod s$ 在 $\\{0, 1, \\dots, s-1\\}$ 上均匀分布。\n$$N_p(i) = \\left\\lfloor \\frac{z_i s + r_i}{s} \\right\\rfloor - \\left\\lceil \\frac{z_i s + r_i - k + 1}{s} \\right\\rceil + 1$$\n$$N_p(i) = z_i - \\left( z_i + \\left\\lceil \\frac{r_i - k + 1}{s} \\right\\rceil \\right) + 1 = 1 - \\left\\lceil \\frac{r_i - k + 1}{s} \\right\\rceil$$\n$N_p(i)$ 仅取决于 $r_i$。期望值 $E[N_p]$ 是通过对 $r_i$ 的所有可能值取平均来计算的：\n$$E[N_p] = \\frac{1}{s} \\sum_{r_i=0}^{s-1} N_p(r_i) = \\frac{1}{s} \\sum_{r_i=0}^{s-1} \\left( 1 - \\left\\lceil \\frac{r_i - k + 1}{s} \\right\\rceil \\right)$$\n利用 $\\sum_{j=0}^{n-1} \\lceil x + j/n \\rceil = \\lceil nx \\rceil$ 的一个变体，或者通过直接求和，可以证明 $\\sum_{r=0}^{s-1} \\lceil \\frac{r+C}{s} \\rceil = C$。令 $C = -k+1$ 且 $r=r_i$。和变为 $\\sum_{r_i=0}^{s-1} \\lceil \\frac{r_i - k + 1}{s} \\rceil = -k+1+s$。\n一个更直接的方法是计算 $N_p(r_i)$ 的和。使用恒等式 $\\lceil x \\rceil = -\\lfloor -x \\rfloor$：\n$$E[N_p] = \\frac{1}{s} \\sum_{r_i=0}^{s-1} \\left( 1 + \\left\\lfloor \\frac{k - 1 - r_i}{s} \\right\\rfloor \\right) = \\frac{1}{s} \\left( s + \\sum_{r_i=0}^{s-1} \\left\\lfloor \\frac{k - 1 - r_i}{s} \\right\\rfloor \\right)$$\n令 $A = k-1$。和 $\\sum_{r=0}^{s-1} \\lfloor \\frac{A - r}{s} \\rfloor$ 可以被计算为 $A - s + 1$。代入 $A=k-1$，和为 $(k-1) - s + 1 = k-s$。\n将其代回 $E[N_p]$ 的表达式中：\n$$E[N_p] = \\frac{1}{s} (s + k - s) = \\frac{k}{s}$$\n根据对称性，第二维的计算是相同的：$E[N_q] = \\frac{k}{s}$。\n最后，受影响的输出神经元的期望数量为：\n$$E[N_{out}] = E[N_p] \\cdot E[N_q] = \\frac{k}{s} \\cdot \\frac{k}{s} = \\frac{k^2}{s^2}$$\n因此，所要求的两个量都等于 $\\frac{k^2}{s^2}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{k^2}{s^2} & \\frac{k^2}{s^2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "一个 SCNN 的强大程度取决于我们训练它的能力。最后的这个练习将聚焦于 SNN 学习中的核心挑战：脉冲的不可微特性。通过运用时间反向传播（BPTT）算法和“替代梯度”，您将推导出卷积权重的基本更新法则，从而深入了解驱动现代 SCNN 学习的核心引擎 。",
            "id": "4060550",
            "problem": "考虑一个在离散时间下运行的单输出通道的脉冲卷积神经网络（SCNN）层。该层通过将输入脉冲序列与空间核进行卷积来计算突触前电流，然后通过泄漏积分更新神经元膜电位。形式上，对于由整数 $(i,j)$ 索引的空间坐标、时间索引 $t \\in \\{1,\\dots,T\\}$ 以及由 $c$ 索引的输入通道，定义如下：\n- 在时间 $t$ 和位置 $(i,j)$ 的突触前电流为\n$$\na_{t}(i,j) = \\sum_{u} \\sum_{v} \\sum_{c} w_{u,v,c} \\, x_{t}(i+u, j+v, c),\n$$\n其中 $x_{t}(p,q,c) \\in \\{0,1\\}$ 表示在时间 $t$、空间位置 $(p,q)$ 和通道 $c$ 的二元输入脉冲，而 $w_{u,v,c}$ 是共享的卷积核参数。\n- 膜电位为无重置的线性泄漏积分，\n$$\nm_{t}(i,j) = \\alpha \\, m_{t-1}(i,j) + a_{t}(i,j),\n$$\n其中泄漏系数为 $0 \\leq \\alpha < 1$，并给定初始条件 $m_{0}(i,j)$。\n- 脉冲输出通过硬阈值确定，\n$$\ns_{t}(i,j) = H\\big(m_{t}(i,j) - \\theta\\big),\n$$\n其中 $H(\\cdot)$ 是赫维赛德阶跃函数（Heaviside step function），$\\theta$ 是脉冲发放阈值。\n\n假设总损失 $L$ 是脉冲输出 $\\{s_{t}(i,j)\\}_{t,i,j}$ 的一个可微泛函，并且通过时间反向传播（BPTT）的执行方式是：用一个平滑的替代导数 $\\sigma'\\!\\big(u\\big)$ 替代赫维赛德函数的不可微导数，并在阈值化的膜电位处求值，即在任何出现 $\\frac{\\partial s_{t}(i,j)}{\\partial m_{t}(i,j)}$ 的地方使用 $\\sigma'\\!\\big(m_{t}(i,j)-\\theta\\big)$。\n\n从离散时间卷积、线性泄漏积分、链式求导法则以及按时间展开的 BPTT 的核心定义出发，推导出一个关于梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 的闭式解析表达式，该表达式需要显式地对时间和空间进行求和。你的最终表达式必须用泄漏系数 $\\alpha$、替代导数 $\\sigma'(\\cdot)$、阈值 $\\theta$、膜电位 $m_{t}(i,j)$、输入脉冲 $x_{t}(\\cdot)$ 以及偏导数 $\\frac{\\partial L}{\\partial s_{t}(i,j)}$ 来表示。请将答案表示为单个解析表达式。不需要进行数值近似。",
            "solution": "总梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 可以通过链式法则表示为：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\frac{\\partial L}{\\partial a_{t}(i,j)} \\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}}\n$$\n其中求和遍及所有时间步和空间位置。\n\n首先，计算突触前电流 $a_{t}(i,j)$ 相对于权重 $w_{u,v,c}$ 的偏导数。从卷积的定义可知：\n$$\n\\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}} = x_{t}(i+u, j+v, c)\n$$\n\n其次，我们确定损失相对于突触前电流的梯度 $\\frac{\\partial L}{\\partial a_{t}(i,j)}$。电流 $a_{t}(i,j)$ 仅通过膜电位 $m_{t}(i,j)$ 影响损失。由于 $m_{t}(i,j) = \\alpha \\, m_{t-1}(i,j) + a_{t}(i,j)$，我们有 $\\frac{\\partial m_{t}(i,j)}{\\partial a_{t}(i,j)} = 1$。因此：\n$$\n\\frac{\\partial L}{\\partial a_{t}(i,j)} = \\frac{\\partial L}{\\partial m_{t}(i,j)} \\frac{\\partial m_{t}(i,j)}{\\partial a_{t}(i,j)} = \\frac{\\partial L}{\\partial m_{t}(i,j)}\n$$\n我们将反向传播到膜电位的误差信号定义为 $\\delta_t^m(i,j) \\equiv \\frac{\\partial L}{\\partial m_t(i,j)}$。\n\n膜电位 $m_t(i,j)$ 通过两条路径影响总损失 $L$：1) 直接通过同一时间步的输出脉冲 $s_t(i,j)$；2) 间接通过对下一时间步的膜电位 $m_{t+1}(i,j)$ 的贡献。这给出了以下反向递推关系：\n$$\n\\delta_t^m(i,j) = \\frac{\\partial L}{\\partial s_t(i,j)} \\frac{\\partial s_t(i,j)}{\\partial m_t(i,j)} + \\frac{\\partial L}{\\partial m_{t+1}(i,j)} \\frac{\\partial m_{t+1}(i,j)}{\\partial m_t(i,j)}\n$$\n根据问题陈述，我们使用替代导数 $\\frac{\\partial s_t(i,j)}{\\partial m_t(i,j)} = \\sigma'(m_t(i,j) - \\theta)$，并且从膜电位更新规则可知 $\\frac{\\partial m_{t+1}(i,j)}{\\partial m_t(i,j)} = \\alpha$。代入后得到：\n$$\n\\delta_t^m(i,j) = \\frac{\\partial L}{\\partial s_t(i,j)} \\sigma'(m_t(i,j) - \\theta) + \\alpha \\, \\delta_{t+1}^m(i,j)\n$$\n该递推关系的边界条件为 $\\delta_{T+1}^m(i,j) = 0$。从 $t=T$ 反向展开此递推关系，可得其闭式解：\n$$\n\\delta_t^m(i,j) = \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta)\n$$\n这个表达式表示在位置 $(i,j)$ 和时间 $t$ 的总误差信号，它是从所有未来时间步 $k \\ge t$ 累积而来，并以泄漏率 $\\alpha$ 进行时间折扣。\n\n最后，我们将各部分组合起来得到总梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 的最终表达式：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\delta_t^m(i,j) \\, x_t(i+u, j+v, c)\n$$\n代入 $\\delta_t^m(i,j)$ 的闭式表达式，得到：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\left( \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta) \\right) x_t(i+u, j+v, c)\n$$\n这个表达式将（反向传播的）误差信号与（正向传播的）输入脉冲在时空上关联起来，这构成了权重更新的基础，类似于一种三因子学习规则。",
            "answer": "$$\n\\boxed{\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\left( \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta) \\right) x_t(i+u, j+v, c)}\n$$"
        }
    ]
}