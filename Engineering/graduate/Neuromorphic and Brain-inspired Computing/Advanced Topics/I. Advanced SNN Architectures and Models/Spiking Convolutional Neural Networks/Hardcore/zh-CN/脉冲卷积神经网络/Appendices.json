{
    "hands_on_practices": [
        {
            "introduction": "脉冲神经网络（SCNN）的核心是突触，它负责在神经元之间传递信号。突触后电流并非瞬时产生，而是具有一个时间动态过程，通常可以用 $\\alpha$ 函数等模型来描述，其传递的总电荷量定义了突触的有效强度或“权重”。这项练习  提供了分析这一基本突触模型的实践机会。通过推导其关键特性，您将具体理解突触时间常数、峰值响应与整体突触权重之间的关系。",
            "id": "4060537",
            "problem": "考虑一个脉冲卷积神经网络 (SCNN) 内的单个突触连接，其中在时间 $t=0$ 的一个突触前脉冲引起一个用于时域卷积的突触后电流核。突触后电流由一个 $\\alpha$-函数建模，该函数由2个时间常数为 $\\tau0$ 的相同一阶突触滤波器级联产生，其表达式为\n$$\n\\alpha(t) \\;=\\; A \\,\\frac{t}{\\tau}\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\,H(t),\n$$\n其中 $A0$ 是一个幅度缩放常数，而 $H(t)$ 是 Heaviside 阶跃函数（当 $t  0$ 时 $H(t)=0$，当 $t\\ge 0$ 时 $H(t)=1$）。在此设置中，突触效能或权重 $w$ 在操作上定义为由单个脉冲引起的总电荷转移量，即 $w = \\int_{0}^{\\infty} \\alpha(t)\\,dt$。\n\n从峰值时间和总电荷转移量的定义出发，并仅使用基本微积分和线性时不变系统原理，完成以下任务：\n- 确定当 $t\\ge 0$ 时 $\\alpha(t)$ 的峰值时间 $t_{\\mathrm{peak}}$。\n- 确定峰值幅度 $\\alpha(t_{\\mathrm{peak}})$。\n- 计算积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$，并使用操作性定义 $w = \\int_{0}^{\\infty} \\alpha(t)\\,dt$ 来将幅度缩放常数 $A$ 表示为 $w$ 和 $\\tau$ 的函数，然后将 $\\alpha(t_{\\mathrm{peak}})$ 完全表示为 $w$ 和 $\\tau$ 的函数。\n\n将你的最终答案表示为一个单行矩阵，按顺序包含 $t_{\\mathrm{peak}}$、$\\alpha(t_{\\mathrm{peak}})$ 和 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$ 的表达式。不需要进行数值近似。最终答案中不要包含单位。",
            "solution": "该问题陈述经评估有效，因为它以计算神经科学和线性系统理论的标准原理为科学基础，是适定的，具有唯一且可推导的解，并使用客观、无歧义的数学语言进行表述。所有必要的数据和定义均已提供，且不存在内部矛盾。\n\n给定突触后电流核为 $\\alpha$-函数：\n$$\n\\alpha(t) \\;=\\; A \\,\\frac{t}{\\tau}\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\,H(t)\n$$\n参数为 $A > 0$ 和 $\\tau > 0$。当 $t \\ge 0$ 时，$H(t)=1$，因此函数简化为：\n$$\n\\alpha(t) \\;=\\; \\frac{A}{\\tau}\\,t\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\n$$\n突触权重 $w$ 定义为总电荷转移量：\n$$\nw = \\int_{0}^{\\infty} \\alpha(t)\\,dt\n$$\n\n首先，我们通过找到 $t \\ge 0$ 时 $\\alpha(t)$ 的最大值来确定峰值时间 $t_{\\mathrm{peak}}$。这发生在 $\\alpha(t)$ 关于 $t$ 的一阶导数为零的地方。我们使用乘法法则求导 $\\frac{d}{dt}(uv) = u'v + uv'$，其中 $u=t$ 且 $v=\\exp(-t/\\tau)$。\n\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\frac{d}{dt} \\left[ t \\exp\\left(-\\frac{t}{\\tau}\\right) \\right] = \\frac{A}{\\tau} \\left[ \\frac{d(t)}{dt} \\exp\\left(-\\frac{t}{\\tau}\\right) + t \\frac{d}{dt}\\left(\\exp\\left(-\\frac{t}{\\tau}\\right)\\right) \\right]\n$$\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\left[ (1) \\exp\\left(-\\frac{t}{\\tau}\\right) + t \\left(-\\frac{1}{\\tau}\\right)\\exp\\left(-\\frac{t}{\\tau}\\right) \\right]\n$$\n$$\n\\frac{d\\alpha}{dt} = \\frac{A}{\\tau} \\exp\\left(-\\frac{t}{\\tau}\\right) \\left( 1 - \\frac{t}{\\tau} \\right)\n$$\n将导数设为 $0$ 以找到临界点：\n$$\n\\frac{A}{\\tau} \\exp\\left(-\\frac{t}{\\tau}\\right) \\left( 1 - \\frac{t}{\\tau} \\right) = 0\n$$\n因为 $A > 0$、$\\tau > 0$，并且 $\\exp(-t/\\tau)$ 对于有限的 $t$ 总是正的，所以只有当括号中的项为零时，该方程才成立：\n$$\n1 - \\frac{t}{\\tau} = 0 \\quad \\implies \\quad t = \\tau\n$$\n为了确认这是一个最大值，我们可以检查二阶导数，但从函数的行为（$\\alpha(0)=0$ 且当 $t \\to \\infty$ 时 $\\alpha(t) \\to 0$）可以清楚地看出，这个对于 $t>0$ 的唯一临界点必定是全局最大值。\n因此，峰值时间为：\n$$\nt_{\\mathrm{peak}} = \\tau\n$$\n\n接下来，我们通过将 $t_{\\mathrm{peak}} = \\tau$ 代入 $\\alpha(t)$ 的表达式中来确定峰值幅度 $\\alpha(t_{\\mathrm{peak}})$：\n$$\n\\alpha(t_{\\mathrm{peak}}) = \\alpha(\\tau) = \\frac{A}{\\tau} (\\tau) \\exp\\left(-\\frac{\\tau}{\\tau}\\right) = A \\cdot 1 \\cdot \\exp(-1) = \\frac{A}{e}\n$$\n\n现在，我们计算积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$，它定义了突触权重 $w$。\n$$\nw = \\int_{0}^{\\infty} \\frac{A}{\\tau} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = \\frac{A}{\\tau} \\int_{0}^{\\infty} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt\n$$\n我们使用分部积分法 $\\int u \\,dv = uv - \\int v \\,du$。设：\n- $u = t \\implies du = dt$\n- $dv = \\exp(-t/\\tau) dt \\implies v = -\\tau \\exp(-t/\\tau)$\n\n$$\n\\int t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = t \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) - \\int \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) dt\n$$\n$$\n= -t\\tau \\exp\\left(-\\frac{t}{\\tau}\\right) + \\tau \\int \\exp\\left(-\\frac{t}{\\tau}\\right) dt\n$$\n$$\n= -t\\tau \\exp\\left(-\\frac{t}{\\tau}\\right) + \\tau \\left(-\\tau \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) = -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2)\n$$\n现在我们应用从 $0$ 到 $\\infty$ 的定积分上下限：\n$$\n\\int_{0}^{\\infty} t \\exp\\left(-\\frac{t}{\\tau}\\right) dt = \\left[ -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2) \\right]_{0}^{\\infty}\n$$\n计算上限 $t \\to \\infty$：$\\lim_{t\\to\\infty} \\left[ -\\exp\\left(-\\frac{t}{\\tau}\\right)(t\\tau + \\tau^2) \\right] = 0$，因为指数衰减到零的速度快于多项式增长。\n计算下限 $t=0$：$-\\exp(0)(0 \\cdot \\tau + \\tau^2) = -1(0 + \\tau^2) = -\\tau^2$。\n定积分的值是 $(0) - (-\\tau^2) = \\tau^2$。\n\n将此结果代回 $w$ 的表达式中：\n$$\nw = \\frac{A}{\\tau} (\\tau^2) = A\\tau\n$$\n所以，积分 $\\int_{0}^{\\infty} \\alpha(t)\\,dt$ 的值是 $A\\tau$。根据问题的定义，这个值用 $w$ 表示。\n\n使用关系式 $w = A\\tau$，我们将幅度缩放常数 $A$ 表示为 $w$ 和 $\\tau$ 的函数：\n$$\nA = \\frac{w}{\\tau}\n$$\n\n最后，我们将峰值幅度 $\\alpha(t_{\\mathrm{peak}})$ 表示为 $w$ 和 $\\tau$ 的函数。我们之前得到 $\\alpha(t_{\\mathrm{peak}}) = A/e$。代入 $A$ 的表达式：\n$$\n\\alpha(t_{\\mathrm{peak}}) = \\frac{1}{e} \\left(\\frac{w}{\\tau}\\right) = \\frac{w}{e\\tau}\n$$\n\n需要报告的三个量是 $t_{\\mathrm{peak}}$、用 $w$ 和 $\\tau$ 表示的 $\\alpha(t_{\\mathrm{peak}})$，以及计算出的积分 $\\int_{0}^{\\infty} \\alpha(t) \\,dt$。问题将此积分定义为 $w$，因此 $w$ 就是其计算出的符号值。\n结果是：\n- $t_{\\mathrm{peak}} = \\tau$\n- $\\alpha(t_{\\mathrm{peak}}) = \\frac{w}{e\\tau}$\n- $\\int_{0}^{\\infty} \\alpha(t) \\,dt = w$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\tau  \\frac{w}{e\\tau}  w \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "脉冲神经网络不仅能通过脉冲发放率编码信息，还能利用脉冲的精确时间进行编码。延迟编码是一种高效的时间编码策略，其中更强的刺激会引发更早的脉冲。然而，生物和电子系统都存在固有的噪声，这可能会破坏时间信息的准确性。这项练习  要求您量化这种编码方案的可靠性。通过计算在存在高斯噪声的情况下正确排序的概率，您将深入理解刺激差异、噪声水平和时间编码鲁棒性之间的权衡。",
            "id": "4060526",
            "problem": "考虑一个脉冲卷积神经网络（SCNN）的单层，该网络层通过严格单调的延迟编码将标量输入编码为首次脉冲延迟。对于任意实值输入 $x$，其确定性延迟为 $t(x) = t_0 - k x$，其中 $k  0$，观测到的脉冲时间建模为 $T(x) = t(x) + \\varepsilon$，其中 $\\varepsilon$ 是均值为零、方差为 $\\sigma^2$ 的高斯噪声，即 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。假设所有噪声项在不同神经元和试验中是独立的。\n\n将两个输入 $x_1$ 和 $x_2$ 同时呈现给两个具有相同参数 $\\{t_0, k, \\sigma\\}$ 的不同神经元。定义排序决策规则如下：首先发放脉冲的神经元代表较大的输入值（在没有噪声的情况下，这与 $k0$ 时 $t(x)$ 的单调性是一致的）。在高斯抖动模型下，排序可能会因噪声而翻转。\n\n从第一性原理出发——即延迟编码的单调性和独立高斯随机变量的基本性质——推导两个输入 $x_1$ 和 $x_2$ 被其观测到的首次脉冲时间正确排序的概率。请用标准正态累积分布函数 $\\Phi(\\cdot)$，将你的最终答案表示为包含 $k$、$\\sigma$、$x_1$ 和 $x_2$ 的单个闭式解析表达式。不需要进行数值近似或四舍五入。",
            "solution": "该问题要求推导两个输入 $x_1$ 和 $x_2$ 被两个神经元的首次脉冲延迟正确排序的概率。该问题在计算神经科学的脉冲神经元模型背景下有明确的定义和科学依据。\n\n首先，我们将给定的信息形式化。我们有两个神经元，神经元1和神经元2，分别接收输入 $x_1$ 和 $x_2$。这些神经元的脉冲时间，记作 $T_1$ 和 $T_2$，被建模为随机变量。\n\n输入 $x$ 的延迟的确定性部分由函数 $t(x) = t_0 - kx$ 给出，其中 $t_0$ 和 $k$ 是常数且 $k > 0$。观测到的脉冲时间 $T(x)$ 是这个确定性延迟和一个随机噪声项 $\\varepsilon$ 的和，即 $T(x) = t(x) + \\varepsilon$。噪声 $\\varepsilon$ 是一个均值为零、方差为 $\\sigma^2$ 的高斯随机变量，记作 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n对于两个输入 $x_1$ 和 $x_2$，观测到的脉冲时间为：\n$$T_1 = t(x_1) + \\varepsilon_1 = (t_0 - kx_1) + \\varepsilon_1$$\n$$T_2 = t(x_2) + \\varepsilon_2 = (t_0 - kx_2) + \\varepsilon_2$$\n其中 $\\varepsilon_1$ 和 $\\varepsilon_2$ 是来自 $\\mathcal{N}(0, \\sigma^2)$ 分布的独立同分布随机变量。\n\n排序决策规则指出，首先发放脉冲的神经元代表较大的输入值。延迟编码 $t(x) = t_0 - kx$ 是严格递减的，因为 $k>0$。这意味着在没有噪声的情况下，较大的输入 $x$ 会导致较小（更早）的脉冲时间 $t(x)$。因此，如果接收客观上较大输入值的神经元在接收较小输入值的神经元之前发放脉冲，则发生“正确”排序。\n\n我们必须考虑 $x_1$ 和 $x_2$ 之间关系的两种情况。\n\n情况1：假设 $x_1 > x_2$。\n根据规则，正确的排序意味着接收较大输入 $x_1$ 的神经元1必须首先发放脉冲。该事件的条件是 $T_1  T_2$。我们需要计算这个事件的概率，$P(T_1  T_2)$。\n\n让我们代入 $T_1$ 和 $T_2$ 的表达式：\n$$P( (t_0 - kx_1) + \\varepsilon_1  (t_0 - kx_2) + \\varepsilon_2 )$$\n常数 $t_0$ 在不等式两边被消去：\n$$P( -kx_1 + \\varepsilon_1  -kx_2 + \\varepsilon_2 )$$\n重新整理各项，将随机变量分离到一边：\n$$P( \\varepsilon_2 - \\varepsilon_1 > -kx_1 + kx_2 )$$\n$$P( \\varepsilon_2 - \\varepsilon_1 > k(x_2 - x_1) )$$\n\n我们定义一个新的随机变量 $Y = \\varepsilon_2 - \\varepsilon_1$。由于 $\\varepsilon_1$ 和 $\\varepsilon_2$ 是独立的高斯随机变量，它们的差 $Y$ 也是一个高斯随机变量。\n$Y$ 的均值为：\n$$E[Y] = E[\\varepsilon_2 - \\varepsilon_1] = E[\\varepsilon_2] - E[\\varepsilon_1] = 0 - 0 = 0$$\n$Y$ 的方差，由于 $\\varepsilon_1$ 和 $\\varepsilon_2$ 的独立性，为：\n$$\\text{Var}(Y) = \\text{Var}(\\varepsilon_2 - \\varepsilon_1) = \\text{Var}(\\varepsilon_2) + \\text{Var}(-\\varepsilon_1) = \\text{Var}(\\varepsilon_2) + (-1)^2 \\text{Var}(\\varepsilon_1) = \\sigma^2 + \\sigma^2 = 2\\sigma^2$$\n所以，随机变量 $Y$ 服从正态分布 $Y \\sim \\mathcal{N}(0, 2\\sigma^2)$。$Y$ 的标准差是 $\\sigma_Y = \\sqrt{2\\sigma^2} = \\sigma\\sqrt{2}$。\n\n我们想要计算的概率是 $P(Y > k(x_2 - x_1))$。为了使用标准正态累积分布函数（CDF）$\\Phi(\\cdot)$ 来表示这个概率，我们必须对变量 $Y$ 进行标准化。一个标准正态变量 $Z \\sim \\mathcal{N}(0, 1)$ 与 $Y$ 的关系是 $Z = \\frac{Y - E[Y]}{\\sigma_Y} = \\frac{Y}{\\sigma\\sqrt{2}}$。\n\n我们可以用 $Z$ 重写这个不等式：\n$$P\\left( \\frac{Y}{\\sigma\\sqrt{2}} > \\frac{k(x_2 - x_1)}{\\sigma\\sqrt{2}} \\right) = P\\left( Z > \\frac{k(x_2 - x_1)}{\\sigma\\sqrt{2}} \\right)$$\n标准正态CDF定义为 $\\Phi(z) = P(Z \\le z)$。使用属性 $P(Z > a) = 1 - P(Z \\le a) = 1 - \\Phi(a)$，以及标准正态分布的对称属性 $1 - \\Phi(a) = \\Phi(-a)$，我们得到：\n$$P(\\text{correct}) = \\Phi\\left( -\\frac{k(x_2 - x_1)}{\\sigma\\sqrt{2}} \\right) = \\Phi\\left( \\frac{k(x_1 - x_2)}{\\sigma\\sqrt{2}} \\right)$$\n\n情况2：假设 $x_2 > x_1$。\n在这种情况下，正确的排序意味着接收较大输入 $x_2$ 的神经元2必须首先发放脉冲。条件是 $T_2  T_1$。\n$$P( (t_0 - kx_2) + \\varepsilon_2  (t_0 - kx_1) + \\varepsilon_1 )$$\n$$P( -kx_2 + \\varepsilon_2  -kx_1 + \\varepsilon_1 )$$\n$$P( \\varepsilon_1 - \\varepsilon_2 > -kx_2 + kx_1 )$$\n$$P( \\varepsilon_1 - \\varepsilon_2 > k(x_1 - x_2) )$$\n我们定义一个新变量 $Y' = \\varepsilon_1 - \\varepsilon_2$。与 $Y$ 类似，$Y' \\sim \\mathcal{N}(0, 2\\sigma^2)$。概率是 $P(Y' > k(x_1 - x_2))$。将其标准化得到：\n$$P\\left( Z > \\frac{k(x_1 - x_2)}{\\sigma\\sqrt{2}} \\right) = \\Phi\\left( -\\frac{k(x_1 - x_2)}{\\sigma\\sqrt{2}} \\right) = \\Phi\\left( \\frac{k(x_2 - x_1)}{\\sigma\\sqrt{2}} \\right)$$\n\n现在，我们将两种情况合并为一个表达式。\n如果 $x_1 > x_2$，概率是 $\\Phi\\left( \\frac{k(x_1 - x_2)}{\\sigma\\sqrt{2}} \\right)$。此处，$x_1 - x_2 > 0$。\n如果 $x_2 > x_1$，概率是 $\\Phi\\left( \\frac{k(x_2 - x_1)}{\\sigma\\sqrt{2}} \\right)$。此处，$x_2 - x_1 > 0$。\n\n在这两种情况下，$\\Phi$ 的参数都是 $\\frac{k \\times (\\text{较大输入} - \\text{较小输入})}{\\sigma\\sqrt{2}}$。这可以用绝对值函数紧凑地表示，因为如果 $x_1 > x_2$，则 $|x_1 - x_2|$ 等于 $(x_1 - x_2)$；如果 $x_2 > x_1$，则等于 $(x_2 - x_1)$。\n因此，对于任意两个输入 $x_1$ 和 $x_2$，正确排序的一般概率是：\n$$P(\\text{correct}) = \\Phi\\left( \\frac{k|x_1 - x_2|}{\\sigma\\sqrt{2}} \\right)$$\n该表达式对所有 $x_1, x_2 \\in \\mathbb{R}$ 都成立。如果 $x_1 = x_2$，参数变为 $0$，且 $P(\\text{correct}) = \\Phi(0) = 1/2$，这是符合预期的，因为当输入相同时，排序完全由偶然机会决定。",
            "answer": "$$\n\\boxed{\\Phi\\left(\\frac{k|x_1 - x_2|}{\\sigma\\sqrt{2}}\\right)}\n$$"
        },
        {
            "introduction": "为了像训练传统深度神经网络一样训练脉冲神经网络，我们需要一种计算梯度的有效方法。脉冲事件的不可微性是一个主要挑战，通常通过在反向传播过程中使用“代理梯度”来解决。此外，脉冲神经网络的时间动态特性要求我们应用时间反向传播（BPTT）算法。这项练习  将引导您完成一个脉冲卷积层学习规则的核心推导过程。掌握这一推导对于理解和开发现代脉冲神经网络的训练算法至关重要。",
            "id": "4060550",
            "problem": "考虑一个在离散时间下运行的单输出通道脉冲卷积神经网络 (SCNN) 层。该层通过将输入脉冲序列与一个空间核进行卷积来计算突触前电流，然后通过漏电积分来更新神经元的膜电位。形式上，对于由整数 $(i,j)$ 索引的空间坐标、时间索引 $t \\in \\{1,\\dots,T\\}$ 以及由 $c$ 索引的输入通道，定义如下：\n- 在时间 $t$ 和位置 $(i,j)$ 的突触前电流为\n$$\na_{t}(i,j) = \\sum_{u} \\sum_{v} \\sum_{c} w_{u,v,c} \\, x_{t}(i+u, j+v, c),\n$$\n其中 $x_{t}(p,q,c) \\in \\{0,1\\}$ 表示在时间 $t$、空间位置 $(p,q)$ 和通道 $c$ 的二元输入脉冲，而 $w_{u,v,c}$ 是共享的卷积核参数。\n- 膜电位，作为一种无重置的线性漏电积分，\n$$\nm_{t}(i,j) = \\alpha \\, m_{t-1}(i,j) + a_{t}(i,j),\n$$\n其中漏电系数 $0 \\leq \\alpha  1$，并给定初始条件 $m_{0}(i,j)$。\n- 通过硬阈值产生的脉冲输出，\n$$\ns_{t}(i,j) = H\\big(m_{t}(i,j) - \\theta\\big),\n$$\n其中 $H(\\cdot)$ 是亥维赛阶跃函数，$\\theta$ 是发放阈值。\n\n假设总损失 $L$ 是关于脉冲输出 $\\{s_{t}(i,j)\\}_{t,i,j}$ 的一个可微泛函，并且通过时间反向传播 (BPTT) 的执行方式是：将亥维赛函数的不可微导数替换为一个平滑的代理导数 $\\sigma'\\!\\big(u\\big)$，该代理导数在经过阈值处理的膜电位处求值，即在任何出现 $\\frac{\\partial s_{t}(i,j)}{\\partial m_{t}(i,j)}$ 的地方使用 $\\sigma'\\!\\big(m_{t}(i,j)-\\theta\\big)$。\n\n从离散时间卷积、线性漏电积分、微分链式法则以及按时间展开的 BPTT 的核心定义出发，推导梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 的闭式解析表达式，该表达式需要显式地对时间和空间进行求和。你的最终表达式必须用漏电系数 $\\alpha$、代理导数 $\\sigma'(\\cdot)$、阈值 $\\theta$、膜电位 $m_{t}(i,j)$、输入脉冲 $x_{t}(\\cdot)$ 以及偏导数 $\\frac{\\partial L}{\\partial s_{t}(i,j)}$ 来表示。将答案表示为单个解析表达式。不需要进行数值近似。",
            "solution": "目标是推导总损失 $L$ 相对于卷积核权重 $w_{u,v,c}$ 的梯度的闭式解析表达式。这需要在按时间展开的脉冲卷积神经网络 (SCNN) 层的计算图中应用微分链式法则，这个过程被称为随时间反向传播 (BPTT)。\n\n让我们首先将总梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 表示为它通过其直接影响的所有中间变量对损失 $L$ 产生影响的总和。权重 $w_{u,v,c}$ 在每个时间步 $t$ 和每个空间位置 $(i,j)$ 都直接对突触前电流 $a_{t}(i,j)$ 有贡献。使用链式法则，我们可以写出：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\frac{\\partial L}{\\partial a_{t}(i,j)} \\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}}\n$$\n求和遍及从 $1$ 到 $T$ 的所有时间步 $t$ 以及应用了核的输出图的所有空间位置 $(i,j)$。\n\n我们的推导过程分为三个主要部分：\n1.  计算偏导数 $\\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}}$。\n2.  通过追踪其在网络动态中的影响，找到项 $\\frac{\\partial L}{\\partial a_{t}(i,j)}$ 的表达式。\n3.  结合这些结果以形成最终表达式。\n\n首先，我们计算突触前电流 $a_{t}(i,j)$ 相对于权重 $w_{u,v,c}$ 的偏导数。$a_{t}(i,j)$ 的定义如下：\n$$\na_{t}(i,j) = \\sum_{u'} \\sum_{v'} \\sum_{c'} w_{u',v',c'} \\, x_{t}(i+u', j+v', c')\n$$\n对特定权重 $w_{u,v,c}$ 求导，只有当索引 $(u',v',c')$ 与 $(u,v,c)$ 匹配时，才会产生非零项。因此，我们有：\n$$\n\\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}} = x_{t}(i+u, j+v, c)\n$$\n该项表示与权重 $w_{u,v,c}$ 相乘以贡献于电流 $a_{t}(i,j)$ 的输入脉冲。\n\n其次，我们确定损失相对于突触前电流的梯度，即 $\\frac{\\partial L}{\\partial a_{t}(i,j)}$。电流 $a_{t}(i,j)$ 仅通过其对膜电位 $m_{t}(i,j)$ 的影响来影响损失 $L$，正如漏电积分方程所定义：\n$$\nm_{t}(i,j) = \\alpha \\, m_{t-1}(i,j) + a_{t}(i,j)\n$$\n再次应用链式法则：\n$$\n\\frac{\\partial L}{\\partial a_{t}(i,j)} = \\frac{\\partial L}{\\partial m_{t}(i,j)} \\frac{\\partial m_{t}(i,j)}{\\partial a_{t}(i,j)}\n$$\n从膜电位方程可知，$\\frac{\\partial m_{t}(i,j)}{\\partial a_{t}(i,j)} = 1$。因此：\n$$\n\\frac{\\partial L}{\\partial a_{t}(i,j)} = \\frac{\\partial L}{\\partial m_{t}(i,j)}\n$$\n让我们将在时间 $t$ 和位置 $(i,j)$ 反向传播到膜电位的误差信号定义为 $\\delta_t^m(i,j) \\equiv \\frac{\\partial L}{\\partial m_t(i,j)}$。\n\n问题的核心是找到 $\\delta_t^m(i,j)$ 的表达式。膜电位 $m_t(i,j)$ 在按时间展开的图中通过两条路径影响总损失 $L$：\n1.  直接地，通过决定同一时间步的输出脉冲 $s_t(i,j)$。\n2.  间接地，通过贡献于下一个时间步的膜电位 $m_{t+1}(i,j)$。\n\n总梯度 $\\delta_t^m(i,j)$ 是来自这两条路径的梯度之和：\n$$\n\\delta_t^m(i,j) = \\frac{\\partial L}{\\partial s_t(i,j)} \\frac{\\partial s_t(i,j)}{\\partial m_t(i,j)} + \\frac{\\partial L}{\\partial m_{t+1}(i,j)} \\frac{\\partial m_{t+1}(i,j)}{\\partial m_t(i,j)}\n$$\n我们使用所提供的定义来计算这些偏导数：\n- 问题指定对亥维赛脉冲函数使用代理导数 $\\sigma'(\\cdot)$：$\\frac{\\partial s_t(i,j)}{\\partial m_t(i,j)} = \\sigma'(m_t(i,j) - \\theta)$。\n- 从膜电位更新规则 $m_{t+1}(i,j) = \\alpha \\, m_t(i,j) + a_{t+1}(i,j)$，我们得到 $\\frac{\\partial m_{t+1}(i,j)}{\\partial m_t(i,j)} = \\alpha$。\n\n将这些代入 $\\delta_t^m(i,j)$ 的方程，得到一个反向递推关系：\n$$\n\\delta_t^m(i,j) = \\frac{\\partial L}{\\partial s_t(i,j)} \\sigma'(m_t(i,j) - \\theta) + \\alpha \\, \\delta_{t+1}^m(i,j)\n$$\n这个关系对 $t \\in \\{1, \\dots, T-1\\}$ 成立。在最后一个时间步 $t=T$，$m_T(i,j)$ 对未来的电位没有影响，所以第二项为零（或者，形式上，$\\delta_{T+1}^m(i,j) = 0$）。边界条件是：\n$$\n\\delta_T^m(i,j) = \\frac{\\partial L}{\\partial s_T(i,j)} \\sigma'(m_T(i,j) - \\theta)\n$$\n这个线性递推关系可以通过将其从 $t=T$ 反向展开到 $t$ 来求解：\n\\begin{align*}\n\\delta_{T-1}^m(i,j) = \\left(\\frac{\\partial L}{\\partial s_{T-1}(i,j)}\\sigma'(m_{T-1}(i,j) - \\theta)\\right) + \\alpha \\left(\\frac{\\partial L}{\\partial s_T(i,j)}\\sigma'(m_T(i,j) - \\theta)\\right) \\\\\n\\delta_{T-2}^m(i,j) = \\left(\\frac{\\partial L}{\\partial s_{T-2}(i,j)}\\sigma'(m_{T-2}(i,j) - \\theta)\\right) + \\alpha \\delta_{T-1}^m(i,j) \\\\\n\\end{align*}\n通用的闭式解是未来误差注入项的总和，这些误差项通过漏电因子 $\\alpha$ 的幂进行折扣：\n$$\n\\delta_t^m(i,j) = \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta)\n$$\n\n最后，我们组装梯度 $\\frac{\\partial L}{\\partial w_{u,v,c}}$ 的完整表达式。我们将推导出的 $\\frac{\\partial a_{t}(i,j)}{\\partial w_{u,v,c}}$ 和 $\\frac{\\partial L}{\\partial a_{t}(i,j)} = \\delta_t^m(i,j)$ 的表达式代入我们最初的公式中：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\delta_t^m(i,j) \\, x_t(i+u, j+v, c)\n$$\n代入 $\\delta_t^m(i,j)$ 的闭式表达式，得到最终的解析结果：\n$$\n\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\left( \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta) \\right) x_t(i+u, j+v, c)\n$$\n该表达式表示一种时空相关性。括号中的项是在位置 $(i,j)$ 和时间 $t$ 的总误差信号，它是从所有未来时间步 $k \\ge t$ 累积而来，并以衰减率 $\\alpha$ 随时间反向传播。然后，外层求和将此误差与每个通过权重 $w_{u,v,c}$ 对其产生贡献的输入脉冲 $x_t(i+u, j+v, c)$ 相关联，从而计算出该权重对损失的总贡献。",
            "answer": "$$\n\\boxed{\\frac{\\partial L}{\\partial w_{u,v,c}} = \\sum_{t=1}^{T} \\sum_{i} \\sum_{j} \\left( \\sum_{k=t}^{T} \\alpha^{k-t} \\frac{\\partial L}{\\partial s_k(i,j)} \\sigma'(m_k(i,j) - \\theta) \\right) x_{t}(i+u, j+v, c)}\n$$"
        }
    ]
}