{
    "hands_on_practices": [
        {
            "introduction": "The first practical challenge in studying neuronal avalanches is to objectively identify them from raw spike recordings. This exercise introduces a standard, data-driven methodology that defines avalanches by coarse-graining time according to the system's intrinsic dynamics . By implementing this detection algorithm, you will gain hands-on experience in transforming a continuous stream of spike data into the discrete events that form the basis of avalanche analysis.",
            "id": "4041876",
            "problem": "Consider a discrete-time spike raster represented as a binary matrix $R \\in \\{0,1\\}^{N \\times T}$, where $N$ is the number of channels and $T$ is the number of time steps. Each entry $R_{n,t} = 1$ indicates a spike on channel $n$ at time index $t$, and $R_{n,t} = 0$ indicates no spike. Assume a base time step of $\\Delta t = 1$ arbitrary time unit.\n\nStarting from fundamental definitions and well-tested observational methodology in neuronal avalanche analysis, implement the following precise avalanche detection rule based on binning with the Mean Inter-Event Interval (MEI):\n\n- Define the sequence of event times $\\{t_i\\}$ by collecting all time indices $t$ such that $R_{n,t} = 1$ for any channel $n$, with multiplicity for coincident spikes on different channels at the same time index. Sort $\\{t_i\\}$ in non-decreasing order.\n- Define the inter-event intervals $\\Delta_i = t_{i+1} - t_{i}$ for all indices $i$ such that $i+1$ exists in the sequence. Define the Mean Inter-Event Interval (MEI) as $\\bar{\\Delta} = \\frac{1}{M-1} \\sum_{i=1}^{M-1} \\Delta_i$, where $M$ is the total number of events in $\\{t_i\\}$. If $M  2$, define $\\bar{\\Delta} := 1$ by convention.\n- Define the integer bin width $w$ by nearest-integer rounding of $\\bar{\\Delta}$, i.e., $w := \\max\\left(1, \\operatorname{round}(\\bar{\\Delta})\\right)$, with ties at halves rounded up to the next integer.\n- Partition the time axis into contiguous, non-overlapping bins $B_k$ of width $w$ starting at time index $t = 0$, such that $B_k$ contains time indices $t$ satisfying $kw \\le t \\le \\min((k+1)w - 1, T-1)$ for $k = 0, 1, \\dots, K-1$ and $K = \\left\\lceil \\frac{T}{w} \\right\\rceil$.\n- Define the bin activity $a_k = \\sum_{n=1}^{N} \\sum_{t \\in B_k} R_{n,t}$, and call $B_k$ \"active\" if $a_k > 0$ and \"silent\" otherwise.\n- Define an avalanche as any maximal contiguous sequence of active bins that is bounded on both sides by silent bins. Treat the boundaries $k = -1$ and $k = K$ as silent. The avalanche size $s$ is the total number of spikes within the bins of this sequence, i.e., the sum of $a_k$ over the bins in the sequence.\n\nYour task is to implement a program that, for each test case below, computes the distribution of avalanche sizes. The distribution must be reported as a list $[c_1, c_2, \\dots, c_{s_{\\max}}]$, where $c_s$ is the count of avalanches of size $s$ and $s_{\\max}$ is the largest avalanche size observed in the test case. If no avalanches are detected, return the empty list $[]$. The program must strictly follow the detection rule above.\n\nTest Suite (each raster is specified as lists of rows, each row is a list of $T$ entries with values in $\\{0,1\\}$):\n\n- Test case $1$ (general multi-channel case). Parameters: $N = 3$, $T = 18$. Raster $R$:\n  - Channel $0$: $[0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0]$\n  - Channel $1$: $[0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0]$\n  - Channel $2$: $[0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0]$\n- Test case $2$ (boundary case with no spikes). Parameters: $N = 2$, $T = 10$. Raster $R$:\n  - Channel $0$: $[0,0,0,0,0,0,0,0,0,0]$\n  - Channel $1$: $[0,0,0,0,0,0,0,0,0,0]$\n- Test case $3$ (all-time active single channel, smallest MEI). Parameters: $N = 1$, $T = 8$. Raster $R$:\n  - Channel $0$: $[1,1,1,1,1,1,1,1]$\n- Test case $4$ (non-integer MEI requiring rounding). Parameters: $N = 2$, $T = 12$. Raster $R$:\n  - Channel $0$: $[0,1,0,0,1,0,0,1,0,0,0,0]$\n  - Channel $1$: $[0,0,1,0,0,1,0,0,0,1,0,0]$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to the distribution list for one test case, in the order listed above. For example, the format is $[[\\dots],[\\dots],[\\dots],[\\dots]]$ with no spaces between commas. The final output values must be lists of integers, and empty lists are permitted.",
            "solution": "The problem statement is a well-defined and scientifically grounded procedure for neuronal avalanche detection in a discrete spike raster, $R \\in \\{0,1\\}^{N \\times T}$. The methodology is based on standard observational techniques used in computational neuroscience to study criticality in neural systems. All parameters and rules are specified unambiguously. Therefore, the problem is valid.\n\nThe core principle of avalanche analysis is to identify causally connected clusters of neural activity. A neuronal avalanche is conceptualized as a cascade of spiking activity that propagates through a network. The method prescribed here uses the Mean Inter-Event Interval (MEI) to define a characteristic timescale for the system's dynamics. This timescale, denoted $\\bar{\\Delta}$, represents the average duration between consecutive spikes across all channels. By partitioning the time axis into bins of a width $w$ derived from $\\bar{\\Delta}$, we can coarse-grain the spike train. Bins with any number of spikes are deemed \"active,\" while bins with zero spikes are \"silent.\" An avalanche is then defined as a contiguous sequence of active bins, temporally bounded by silent bins. This operational definition serves to group temporally clustered spikes into cohesive events, separated by periods of quiescence longer than the characteristic timescale. The size of an avalanche, $s$, is the total number of spikes it contains, which is a primary measure of its magnitude.\n\nThe solution proceeds by meticulously implementing the specified algorithmic steps for each test case.\n\n**Step 1: Extract Event Times and Calculate Mean Inter-Event Interval (MEI)**\n\nFirst, we compile a sequence of event times, $\\{t_i\\}$, which consists of the time indices of every single spike in the raster $R$. If multiple channels spike at the same time index $t$, the index $t$ is included in the sequence once for each spike. The sequence is then sorted in non-decreasing order. Let $M$ be the total number of spikes (the length of $\\{t_i\\}$).\n\nThe inter-event intervals are $\\Delta_i = t_{i+1} - t_i$. The MEI, $\\bar{\\Delta}$, is their average.\n$$ \\bar{\\Delta} = \\frac{1}{M-1} \\sum_{i=1}^{M-1} \\Delta_i = \\frac{1}{M-1} \\sum_{i=1}^{M-1} (t_{i+1} - t_i) $$\nThis sum is a telescoping series, which simplifies to:\n$$ \\bar{\\Delta} = \\frac{t_M - t_1}{M-1} $$\nwhere $t_1$ and $t_M$ are the times of the first and last spikes in the sorted sequence, respectively. If $M  2$, we use the convention $\\bar{\\Delta} := 1$.\n\n**Step 2: Determine Bin Width**\n\nThe integer bin width, $w$, is determined by rounding the MEI to the nearest integer, with the constraint that $w \\ge 1$. The problem specifies that ties at halves (e.g., $2.5$) are rounded up to the next integer. This corresponds to the operation $w := \\max\\left(1, \\lfloor \\bar{\\Delta} + 0.5 \\rfloor\\right)$.\n\n**Step 3: Bin the Spike Data and Compute Activity**\n\nThe total duration $T$ is partitioned into $K = \\lceil T/w \\rceil$ contiguous bins. The activity $a_k$ for each bin $B_k$ (where $k \\in \\{0, 1, \\dots, K-1\\}$) is the total count of spikes with time indices $t$ such that $kw \\le t  (k+1)w$. A bin is \"active\" if $a_k > 0$ and \"silent\" if $a_k = 0$.\n\n**Step 4: Identify Avalanches and Their Sizes**\n\nAn avalanche is a maximal, contiguous sequence of active bins. We identify these sequences by scanning through the bin activities $\\{a_k\\}_{k=0}^{K-1}$. A new avalanche begins upon encountering an active bin after a silent one (the implicit boundary at $k=-1$ is considered silent). The avalanche continues as long as subsequent bins are active. It terminates when a silent bin is encountered. The size, $s$, of the avalanche is the sum of the activities $a_k$ of all bins within that sequence.\n\n**Step 5: Compute Avalanche Size Distribution**\n\nAfter identifying all avalanches and calculating their sizes, we compile the results into a frequency distribution. For each test case, we compute a list $[c_1, c_2, \\dots, c_{s_{\\max}}]$, where $c_s$ is the number of observed avalanches of size $s$, and $s_{\\max}$ is the maximum avalanche size found. If no avalanches are detected, the result is an empty list.\n\nWe now apply this procedure to each test case.\n\n**Test Case 1: $N=3, T=18$**\n- **Event Times:** Spikes occur at times (with multiplicity): $[1, 1, 2, 5, 6, 7, 13, 13, 13, 15]$. Total spikes $M=10$.\n- **MEI:** $\\bar{\\Delta} = \\frac{t_{10} - t_1}{10-1} = \\frac{15 - 1}{9} = \\frac{14}{9} \\approx 1.556$.\n- **Bin Width:** $w = \\max(1, \\lfloor 1.556 + 0.5 \\rfloor) = \\max(1, \\lfloor 2.056 \\rfloor) = 2$.\n- **Binning ($w=2, T=18, K=9$):**\n  - Total activity per time step: $S_t = [0, 2, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0]$.\n  - Bin activities $a_k$: $[2, 1, 1, 2, 0, 0, 3, 1, 0]$.\n- **Avalanches:**\n  - Bins $0-3$ are active: size $s_1 = 2+1+1+2 = 6$.\n  - Bins $4,5$ are silent.\n  - Bins $6-7$ are active: size $s_2 = 3+1 = 4$.\n  - Bin $8$ is silent.\n  - Avalanche sizes are $[6, 4]$.\n- **Distribution:** $s_{\\max}=6$. There is one avalanche of size $4$ and one of size $6$. The distribution is $[c_1, \\dots, c_6] = [0, 0, 0, 1, 0, 1]$.\n\n**Test Case 2: $N=2, T=10$**\n- **Event Times:** No spikes. $M=0$.\n- **MEI:** By convention, for $M2$, $\\bar{\\Delta}=1$.\n- **Bin Width:** $w = \\max(1, \\lfloor 1 + 0.5 \\rfloor) = 1$.\n- **Binning ($w=1$):** All bin activities are $0$.\n- **Avalanches:** No active bins, hence no avalanches.\n- **Distribution:** The result is an empty list $[]$.\n\n**Test Case 3: $N=1, T=8$**\n- **Event Times:** Spikes at every time step: $[0, 1, 2, 3, 4, 5, 6, 7]$. $M=8$.\n- **MEI:** $\\bar{\\Delta} = \\frac{7 - 0}{8-1} = \\frac{7}{7} = 1$.\n- **Bin Width:** $w = \\max(1, \\lfloor 1 + 0.5 \\rfloor) = 1$.\n- **Binning ($w=1$):** All $8$ bins are active with activity $a_k=1$.\n- **Avalanches:** A single avalanche spans all bins. Its size is $s = 8 \\times 1 = 8$.\n- **Distribution:** $s_{\\max}=8$. One avalanche of size $8$. The distribution is $[0, 0, 0, 0, 0, 0, 0, 1]$.\n\n**Test Case 4: $N=2, T=12$**\n- **Event Times:** Spikes at $[1, 2, 4, 5, 7, 9]$. $M=6$.\n- **MEI:** $\\bar{\\Delta} = \\frac{9 - 1}{6-1} = \\frac{8}{5} = 1.6$.\n- **Bin Width:** $w = \\max(1, \\lfloor 1.6 + 0.5 \\rfloor) = \\max(1, \\lfloor 2.1 \\rfloor) = 2$.\n- **Binning ($w=2, T=12, K=6$):**\n  - Total activity per time step: $S_t = [0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0]$.\n  - Bin activities $a_k$: $[1, 1, 2, 1, 1, 0]$.\n- **Avalanches:** Bins $0-4$ are active, followed by a silent bin. One avalanche of size $s = 1+1+2+1+1 = 6$.\n- **Distribution:** $s_{\\max}=6$. One avalanche of size $6$. The distribution is $[0, 0, 0, 0, 0, 1]$.",
            "answer": "```python\nimport numpy as np\n\ndef compute_avalanche_distribution(R_list):\n    \"\"\"\n    Computes the distribution of avalanche sizes for a given spike raster.\n\n    Args:\n        R_list (list of lists): The spike raster as a list of lists.\n\n    Returns:\n        list: The avalanche size distribution [c_1, ..., c_s_max], or [] if no avalanches.\n    \"\"\"\n    R = np.array(R_list, dtype=np.int8)\n    N, T = R.shape\n\n    # Step 1: Extract Event Times\n    # Find all (row, col) indices where a spike occurred.\n    spike_indices = np.where(R == 1)\n    # The event times are the column indices (t) of these spikes.\n    event_times = np.sort(spike_indices[1])\n    \n    M = len(event_times)\n\n    # Step 2: Calculate Mean Inter-Event Interval (MEI)\n    if M  2:\n        mei = 1.0\n    else:\n        # MEI = (last_spike_time - first_spike_time) / (M - 1)\n        mei = (event_times[-1] - event_times[0]) / (M - 1)\n\n    # Step 3: Determine Bin Width (w)\n    # round(x) with ties at halves rounded up is floor(x + 0.5)\n    w = int(np.floor(mei + 0.5))\n    w = max(1, w)\n\n    # Step 4: Bin the Spike Data and Compute Activity\n    # Get total number of spikes at each time step\n    total_spikes_per_t = R.sum(axis=0)\n    \n    num_bins = (T + w - 1) // w\n    bin_activity = np.zeros(num_bins, dtype=int)\n    \n    for k in range(num_bins):\n        start_t = k * w\n        # Python slice end is exclusive, handles final bin correctly\n        end_t = (k + 1) * w\n        bin_activity[k] = np.sum(total_spikes_per_t[start_t:end_t])\n\n    # Step 5: Identify Avalanches and Their Sizes\n    avalanche_sizes = []\n    current_size = 0\n    is_in_avalanche = False\n    \n    for activity in bin_activity:\n        if activity  0:\n            current_size += activity\n            is_in_avalanche = True\n        else:\n            if is_in_avalanche:\n                avalanche_sizes.append(current_size)\n                current_size = 0\n                is_in_avalanche = False\n                \n    # If the last bin was part of an avalanche, it needs to be recorded\n    if is_in_avalanche:\n        avalanche_sizes.append(current_size)\n        \n    # Step 6: Compute Avalanche Size Distribution\n    if not avalanche_sizes:\n        return []\n        \n    s_max = max(avalanche_sizes)\n    distribution = [0] * s_max\n    for s in avalanche_sizes:\n        # Sizes are 1-indexed, list is 0-indexed\n        distribution[s - 1] += 1\n        \n    return distribution\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        [[0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0],\n         [0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0],\n         [0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0]],\n        # Test case 2\n        [[0,0,0,0,0,0,0,0,0,0],\n         [0,0,0,0,0,0,0,0,0,0]],\n        # Test case 3\n        [[1,1,1,1,1,1,1,1]],\n        # Test case 4\n        [[0,1,0,0,1,0,0,1,0,0,0,0],\n         [0,0,1,0,0,1,0,0,0,1,0,0]]\n    ]\n    \n    results = []\n    for R_list in test_cases:\n        dist = compute_avalanche_distribution(R_list)\n        results.append(dist)\n        \n    # Format the output string precisely as specified: [[...],[...]] with no spaces\n    formatted_results = []\n    for res_list in results:\n        # Convert each integer list to a string like '[c1,c2,...]'\n        formatted_list = f\"[{','.join(map(str, res_list))}]\"\n        formatted_results.append(formatted_list)\n    \n    # Join the formatted list strings into the final output format\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "With a method to detect avalanches, the next step is to quantify the underlying dynamics. The branching ratio, $\\sigma$, is the critical parameter that determines whether activity dies out, persists, or explodes. This practice focuses on the crucial task of estimating $\\sigma$ and its uncertainty from finite experimental data . You will apply the powerful technique of Maximum Likelihood Estimation to bridge the gap between abstract theory and concrete measurement.",
            "id": "4041799",
            "problem": "A neuromorphic microcircuit is probed for near-critical avalanche dynamics by injecting independent perturbations and counting immediate offspring activations at the next discrete time step. Let the branching ratio be defined as the expected number of offspring per active parent at one step, denoted by $\\sigma = \\mathbb{E}[K]$, where $K$ is the offspring count produced by a single perturbation. You conduct $N=400$ independent perturbations and observe a total of $S=360$ offspring across all perturbations. The network architecture imposes at most $M=200$ potential postsynaptic partners per perturbation. Assume the following two generative models for the offspring counts per perturbation:\n- Poisson model: $K \\sim \\mathrm{Poisson}(\\sigma)$, independent across perturbations.\n- Binomial model: $K \\sim \\mathrm{Binomial}(M,p)$, independent across perturbations, with $\\sigma = M p$ by definition of the branching ratio.\n\nStarting only from the definitions of expectation, independence, and likelihood, and invoking the asymptotic normality guaranteed by the Central Limit Theorem (CLT) and Fisher Information, do the following:\n1. Derive the maximum likelihood estimator $\\hat{\\sigma}$ for both the Poisson and Binomial models in terms of the observed data $(N,S,M)$.\n2. Derive a two-sided confidence interval for $\\sigma$ at confidence level $0.95$ for each model using asymptotic theory. For the Binomial model, propagate uncertainty from $p$ to $\\sigma$ via the Delta Method.\n3. Evaluate both confidence intervals numerically for the given data and report the results.\n\nExpress the final answer as a single row matrix containing six entries in the following order: $\\hat{\\sigma}_{\\mathrm{Pois}}$, lower bound (Poisson), upper bound (Poisson), $\\hat{\\sigma}_{\\mathrm{Bin}}$, lower bound (Binomial), upper bound (Binomial). Round all six entries to four significant figures. The branching ratio is dimensionless; do not include units in your final boxed answer.",
            "solution": "The quantity of interest is the branching ratio $\\sigma = \\mathbb{E}[K]$, where $K$ is the number of offspring produced by a single perturbation at the next time step. We have $N$ independent and identically distributed offspring counts $\\{K_{i}\\}_{i=1}^{N}$, and the observed total $S = \\sum_{i=1}^{N} K_{i}$.\n\nPoisson model:\n1. Model specification and maximum likelihood estimator (MLE). Under the Poisson model, $K_{i} \\sim \\mathrm{Poisson}(\\sigma)$ independently. The likelihood is\n$$\nL(\\sigma; K_{1},\\dots,K_{N}) = \\prod_{i=1}^{N} \\frac{\\exp(-\\sigma)\\sigma^{K_{i}}}{K_{i}!}.\n$$\nThe log-likelihood is\n$$\n\\ell(\\sigma) = \\sum_{i=1}^{N} \\left( -\\sigma + K_{i}\\ln(\\sigma) - \\ln(K_{i}!) \\right) = -N\\sigma + \\left(\\sum_{i=1}^{N} K_{i}\\right)\\ln(\\sigma) + \\mathrm{const}.\n$$\nDifferentiating and setting to zero,\n$$\n\\frac{\\partial \\ell}{\\partial \\sigma} = -N + \\frac{S}{\\sigma} = 0 \\quad \\Rightarrow \\quad \\hat{\\sigma}_{\\mathrm{Pois}} = \\frac{S}{N}.\n$$\n2. Asymptotic variance and confidence interval. The Fisher Information for one observation is $I_{1}(\\sigma) = \\frac{1}{\\sigma}$, so for $N$ independent observations $I_{N}(\\sigma) = \\frac{N}{\\sigma}$. The asymptotic distribution of the MLE is\n$$\n\\hat{\\sigma}_{\\mathrm{Pois}} \\approx \\mathcal{N}\\left( \\sigma, \\frac{\\sigma}{N} \\right).\n$$\nReplacing $\\sigma$ by $\\hat{\\sigma}_{\\mathrm{Pois}}$ in the variance (plug-in principle), an approximate two-sided confidence interval at confidence level $0.95$ uses the Gaussian quantile $z_{0.975}$,\n$$\n\\mathrm{CI}_{\\mathrm{Pois}}: \\quad \\hat{\\sigma}_{\\mathrm{Pois}} \\pm z_{0.975} \\sqrt{\\frac{\\hat{\\sigma}_{\\mathrm{Pois}}}{N}}.\n$$\n\nBinomial model:\n1. Model specification and MLE. Under the Binomial model, $K_{i} \\sim \\mathrm{Binomial}(M,p)$ independently, with $\\sigma = M p$. The likelihood for the $N$ observations factorizes, and equivalently, the aggregated count $S$ is distributed as $S \\sim \\mathrm{Binomial}(NM, p)$ under independence of trials. The log-likelihood in terms of $p$ (up to constants) is\n$$\n\\ell(p) = S \\ln(p) + (NM - S)\\ln(1-p) + \\mathrm{const}.\n$$\nDifferentiating and setting to zero,\n$$\n\\frac{\\partial \\ell}{\\partial p} = \\frac{S}{p} - \\frac{NM - S}{1-p} = 0 \\quad \\Rightarrow \\quad \\hat{p} = \\frac{S}{NM}.\n$$\nTherefore,\n$$\n\\hat{\\sigma}_{\\mathrm{Bin}} = M \\hat{p} = \\frac{S}{N}.\n$$\n2. Asymptotic variance and confidence interval via Delta Method. The Fisher Information for $p$ with $NM$ trials is $I(p) = \\frac{NM}{p(1-p)}$, so\n$$\n\\hat{p} \\approx \\mathcal{N}\\left( p, \\frac{p(1-p)}{NM} \\right).\n$$\nDefine $g(p) = M p = \\sigma$, with derivative $g'(p) = M$. By the Delta Method,\n$$\n\\hat{\\sigma}_{\\mathrm{Bin}} \\approx \\mathcal{N}\\left( \\sigma, M^{2}\\frac{p(1-p)}{NM} \\right) = \\mathcal{N}\\left( \\sigma, \\frac{M p(1-p)}{N} \\right).\n$$\nUsing $\\sigma = M p$, we can rewrite the variance as\n$$\n\\mathrm{Var}(\\hat{\\sigma}_{\\mathrm{Bin}}) \\approx \\frac{\\sigma\\left(1 - \\frac{\\sigma}{M}\\right)}{N}.\n$$\nReplacing unknown parameters by their MLEs yields the approximate two-sided confidence interval at confidence level $0.95$,\n$$\n\\mathrm{CI}_{\\mathrm{Bin}}: \\quad \\hat{\\sigma}_{\\mathrm{Bin}} \\pm z_{0.975} \\sqrt{ \\frac{\\hat{\\sigma}_{\\mathrm{Bin}}\\left(1 - \\frac{\\hat{\\sigma}_{\\mathrm{Bin}}}{M}\\right)}{N} }.\n$$\n\nNumerical evaluation:\nGiven $N=400$, $S=360$, and $M=200$,\n$$\n\\hat{\\sigma}_{\\mathrm{Pois}} = \\hat{\\sigma}_{\\mathrm{Bin}} = \\frac{S}{N} = \\frac{360}{400} = 0.9.\n$$\nTake $z_{0.975} \\approx 1.96$. For the Poisson model,\n$$\n\\mathrm{SE}_{\\mathrm{Pois}} = \\sqrt{\\frac{\\hat{\\sigma}_{\\mathrm{Pois}}}{N}} = \\sqrt{\\frac{0.9}{400}} = \\sqrt{0.00225} \\approx 0.0474341649,\n$$\nso the margin is\n$$\n1.96 \\times 0.0474341649 \\approx 0.0929709632,\n$$\nyielding\n$$\n\\text{lower}_{\\mathrm{Pois}} \\approx 0.9 - 0.0929709632 = 0.8070290368, \\quad \\text{upper}_{\\mathrm{Pois}} \\approx 0.9 + 0.0929709632 = 0.9929709632.\n$$\nFor the Binomial model,\n$$\n\\mathrm{SE}_{\\mathrm{Bin}} = \\sqrt{ \\frac{\\hat{\\sigma}_{\\mathrm{Bin}}\\left(1 - \\frac{\\hat{\\sigma}_{\\mathrm{Bin}}}{M}\\right)}{N} } = \\sqrt{ \\frac{0.9\\left(1 - \\frac{0.9}{200}\\right)}{400} } = \\sqrt{ \\frac{0.9 \\times 0.9955}{400} } = \\sqrt{0.002239875} \\approx 0.047327105,\n$$\nso the margin is\n$$\n1.96 \\times 0.047327105 \\approx 0.092761126,\n$$\nyielding\n$$\n\\text{lower}_{\\mathrm{Bin}} \\approx 0.9 - 0.092761126 = 0.807238874, \\quad \\text{upper}_{\\mathrm{Bin}} \\approx 0.9 + 0.092761126 = 0.992761126.\n$$\nRounding each entry to four significant figures gives\n$$\n\\hat{\\sigma}_{\\mathrm{Pois}} = 0.9000, \\quad \\text{lower}_{\\mathrm{Pois}} = 0.8070, \\quad \\text{upper}_{\\mathrm{Pois}} = 0.9930,\n$$\nand\n$$\n\\hat{\\sigma}_{\\mathrm{Bin}} = 0.9000, \\quad \\text{lower}_{\\mathrm{Bin}} = 0.8072, \\quad \\text{upper}_{\\mathrm{Bin}} = 0.9928.\n$$\nAs requested, the final answer is reported as a single row matrix in the order specified.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.9000  0.8070  0.9930  0.9000  0.8072  0.9928\\end{pmatrix}}$$"
        },
        {
            "introduction": "After estimating the branching ratio $\\sigma$, we need a theoretical framework to interpret its meaning. The Galton-Watson branching process provides a simple yet profoundly insightful model for the propagation of activity in a network. This exercise asks you to derive the fundamental relationship between $\\sigma$ and the expected avalanche size . This derivation will make the concept of criticality concrete, showing precisely how and why system-wide cascades become possible as $\\sigma$ approaches the critical value of 1.",
            "id": "4041825",
            "problem": "Consider a neuronal avalanche as a cascade initiated by a single active neuron in a large, sparse network. Model the cascade as a Galton–Watson branching process, in which each active neuron independently activates a random number of downstream neurons in the next time step. Assume the offspring count is Poisson distributed with mean branching ratio $\\sigma$, that is, the number of downstream activations $K$ per active neuron satisfies $K \\sim \\text{Poisson}(\\sigma)$, with independence across neurons and time steps. Let the avalanche size $S$ be defined as the total number of activated neurons in the cascade including the initiator. Using only the foundational properties of the Galton–Watson process, namely independence of sub-branches and linearity of expectation, derive an exact closed-form expression for the expected avalanche size $\\mathbb{E}[S]$ as a function of $\\sigma$ in the subcritical regime $\\sigma \\in (0,1)$. Then, evaluate this expected size at $\\sigma = 0.95$, and explain mathematically how $\\mathbb{E}[S]$ diverges as $\\sigma \\to 1^{-}$. Express the numerical evaluation for $\\sigma = 0.95$ in scientific notation with four significant figures, and provide the final numerical answer without units.",
            "solution": "The user wants a solution to a problem about neuronal avalanches. I will first validate the problem statement.\n\n### Step 1: Extract Givens\n-   **Model**: Neuronal avalanche as a Galton–Watson branching process.\n-   **Initiation**: Cascade starts with a single active neuron.\n-   **Network**: Large, sparse.\n-   **Offspring Distribution**: The number of downstream activations $K$ per active neuron is Poisson distributed with mean branching ratio $\\sigma$, i.e., $K \\sim \\text{Poisson}(\\sigma)$.\n-   **Independence**: Offspring counts are independent across neurons and time steps.\n-   **Definition**: Avalanche size $S$ is the total number of activated neurons in the cascade, including the initiator.\n-   **Constraint**: Use only foundational properties: independence of sub-branches and linearity of expectation.\n-   **Regime**: Subcritical, $\\sigma \\in (0,1)$.\n-   **Tasks**:\n    1.  Derive an exact closed-form expression for the expected avalanche size $\\mathbb{E}[S]$ as a function of $\\sigma$.\n    2.  Evaluate $\\mathbb{E}[S]$ at $\\sigma = 0.95$.\n    3.  Explain mathematically how $\\mathbb{E}[S]$ diverges as $\\sigma \\to 1^{-}$.\n-   **Formatting**: Express the numerical evaluation for $\\sigma = 0.95$ in scientific notation with four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is well-grounded. The Galton–Watson process is a standard mathematical framework for modeling branching phenomena, and its application to neuronal avalanches is a cornerstone of theoretical neuroscience and complexity science. The Poisson distribution is a common and appropriate choice for an offspring distribution in this context.\n2.  **Well-Posed**: The problem is well-posed. It asks for a standard result in the theory of branching processes ($\\mathbb{E}[S]$ for a subcritical process), for which a unique and meaningful solution exists.\n3.  **Objective**: The language is precise, quantitative, and free of subjective or ambiguous terminology.\n4.  **Completeness and Consistency**: The problem provides all necessary information (model type, offspring distribution, definition of size, parameter regime) and contains no internal contradictions.\n5.  **Feasibility**: The conditions are standard for this type of model and do not involve any physical or mathematical impossibilities.\n6.  **Triviality**: The problem is not trivial; it requires a specific, non-obvious line of reasoning based on recursive decomposition and the law of total expectation to arrive at the solution.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe problem asks for the derivation of the expected avalanche size, $\\mathbb{E}[S]$, in a Galton-Watson branching process. The process starts with a single initiator at generation $g=0$. Let $S$ be the total size of the avalanche. This initiator activates $K$ neurons in the next generation, where $K$ is a random variable following a Poisson distribution with mean $\\sigma$, i.e., $K \\sim \\text{Poisson}(\\sigma)$.\n\nThe total avalanche size $S$ can be expressed as the sum of the initiator ($1$ neuron) and the sizes of the sub-avalanches started by each of its $K$ direct offspring. Let $S_i$ be the total size of the sub-avalanche initiated by the $i$-th offspring, for $i=1, 2, \\dots, K$.\nWe can write a recursive expression for the random variable $S$:\n$$S = 1 + \\sum_{i=1}^{K} S_i$$\nIf $K=0$, the sum is empty and its value is $0$, so $S=1$. This is correct, as an avalanche with no offspring has a total size of $1$ (the initiator itself).\n\nAccording to the properties of the Galton-Watson process, each sub-avalanche starting from an offspring is an independent process that is statistically identical to the original process. Therefore, each random variable $S_i$ has the same probability distribution as $S$, and consequently, the same expectation: $\\mathbb{E}[S_i] = \\mathbb{E}[S]$.\n\nWe want to find $\\mathbb{E}[S]$. We take the expectation of the recursive equation for $S$:\n$$\\mathbb{E}[S] = \\mathbb{E}\\left[1 + \\sum_{i=1}^{K} S_i\\right]$$\nUsing the linearity of expectation, we get:\n$$\\mathbb{E}[S] = \\mathbb{E}[1] + \\mathbb{E}\\left[\\sum_{i=1}^{K} S_i\\right] = 1 + \\mathbb{E}\\left[\\sum_{i=1}^{K} S_i\\right]$$\nThe term $\\mathbb{E}\\left[\\sum_{i=1}^{K} S_i\\right]$ is the expectation of a sum of a random number of random variables. To evaluate this, we use the law of total expectation (also known as Wald's identity in this context), conditioning on the number of offspring, $K$:\n$$\\mathbb{E}\\left[\\sum_{i=1}^{K} S_i\\right] = \\mathbb{E}\\left[\\mathbb{E}\\left[\\sum_{i=1}^{K} S_i \\Bigg| K\\right]\\right]$$\nLet's first evaluate the inner expectation, conditioned on $K=k$ for some integer $k \\ge 0$:\n$$\\mathbb{E}\\left[\\sum_{i=1}^{k} S_i \\Bigg| K=k\\right]$$\nSince the sizes of the sub-avalanches $S_i$ are independent of the number of offspring $K$, and they are independent and identically distributed, the conditional expectation is:\n$$\\sum_{i=1}^{k} \\mathbb{E}[S_i] = \\sum_{i=1}^{k} \\mathbb{E}[S] = k \\mathbb{E}[S]$$\nSo, we have $\\mathbb{E}\\left[\\sum_{i=1}^{K} S_i \\Bigg| K\\right] = K \\mathbb{E}[S]$. Now we substitute this back into the law of total expectation:\n$$\\mathbb{E}\\left[\\sum_{i=1}^{K} S_i\\right] = \\mathbb{E}[K \\mathbb{E}[S]]$$\nSince $\\mathbb{E}[S]$ is a constant (the value we are trying to determine), we can factor it out of the expectation:\n$$\\mathbb{E}[K \\mathbb{E}[S]] = \\mathbb{E}[S] \\mathbb{E}[K]$$\nThe problem states that $K$ follows a Poisson distribution with mean $\\sigma$. Thus, $\\mathbb{E}[K] = \\sigma$.\nSubstituting this result back into our main equation for $\\mathbb{E}[S]$:\n$$\\mathbb{E}[S] = 1 + \\sigma \\mathbb{E}[S]$$\nWe can now solve for $\\mathbb{E}[S]$. This derivation is valid only if $\\mathbb{E}[S]$ is finite, which is true in the subcritical regime $\\sigma  1$.\n$$\\mathbb{E}[S] - \\sigma \\mathbb{E}[S] = 1$$\n$$\\mathbb{E}[S] (1 - \\sigma) = 1$$\nThis yields the closed-form expression for the expected avalanche size in the subcritical regime $\\sigma \\in (0,1)$:\n$$\\mathbb{E}[S] = \\frac{1}{1 - \\sigma}$$\nNext, we evaluate this expression for $\\sigma = 0.95$:\n$$\\mathbb{E}[S] = \\frac{1}{1 - 0.95} = \\frac{1}{0.05} = 20$$\nExpressed in scientific notation with four significant figures, this is $2.000 \\times 10^1$.\n\nFinally, we explain the divergence as $\\sigma \\to 1^{-}$. The expression for the expected size is $\\mathbb{E}[S] = \\frac{1}{1 - \\sigma}$. To analyze the behavior as the branching ratio $\\sigma$ approaches the critical value of $1$ from below, we take the limit:\n$$\\lim_{\\sigma \\to 1^{-}} \\mathbb{E}[S] = \\lim_{\\sigma \\to 1^{-}} \\frac{1}{1 - \\sigma}$$\nAs $\\sigma$ approaches $1$ from values less than $1$, the denominator $(1 - \\sigma)$ approaches $0$ from the positive side. Therefore, the fraction diverges to positive infinity:\n$$\\lim_{\\sigma \\to 1^{-}} \\mathbb{E}[S] = +\\infty$$\nThis mathematical divergence signifies a phase transition. The value $\\sigma = 1$ is the critical point of the system. For $\\sigma  1$ (subcritical), avalanches are guaranteed to terminate and have a finite expected size. At $\\sigma = 1$ (critical), the expected size of an avalanche becomes infinite. This does not imply that every avalanche is infinitely large; rather, the probability distribution of avalanche sizes develops a \"heavy tail\" (specifically, a power-law distribution), allowing for system-spanning cascades to occur with sufficient probability to make the average size diverge. This state of criticality is a key concept in understanding complex systems, as it allows for information propagation across all scales. For $\\sigma  1$ (supercritical), the probability of extinction is less than $1$, and an avalanche can grow exponentially, leading to an infinite expected size.",
            "answer": "$$\\boxed{2.000 \\times 10^{1}}$$"
        }
    ]
}