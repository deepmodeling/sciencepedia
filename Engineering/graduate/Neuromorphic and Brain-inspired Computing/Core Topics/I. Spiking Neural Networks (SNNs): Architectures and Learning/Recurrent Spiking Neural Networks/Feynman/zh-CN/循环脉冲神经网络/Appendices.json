{
    "hands_on_practices": [
        {
            "introduction": "精确的动力学仿真是研究脉冲神经网络的基础。本练习将引导你推导并比较两种常用的神经元模型离散时间更新方法：精确积分法和前向欧拉法。通过分析这两种方法在强突触电导影响下的稳定性，你将深入理解数值积分方法在SNN仿真中的重要性及选择时的权衡考量 。",
            "id": "4056993",
            "problem": "考虑一个单室漏电积分-发放神经元，其具有基于电导的突触输入，并嵌入在一个循环脉冲神经网络（SNN；Spiking Neural Network）中。该神经元的膜电容为 $C$，漏电导为 $g_L$，漏反转电位为 $E_L$。一个单一的有效突触电导 $g(t)$ 将膜电位驱动向突触反转电位 $E_{\\mathrm{rev}}$。该突触电导根据时间常数为 $\\tau_s$ 的一阶衰减进行演化，并在突触前脉冲到达时（由离散时间 $t$ 的离散脉冲指示符 $s_t \\in \\{0,1\\}$ 表示）接收与突触权重 $w$ 成正比的脉冲式增量。膜电压表示为 $V(t)$。假设为了进行稳定性分析，脉冲生成和重置被禁用（即，系统在没有阈值或重置的阈下状态下进行分析）。\n\n从第一性原理和经过充分检验的事实出发：\n- 膜遵循电流平衡方程 $C \\frac{dV}{dt} = -g_L \\left(V - E_L\\right) - g(t)\\left(V - E_{\\mathrm{rev}}\\right) + I_{\\mathrm{ext}}$，其中 $I_{\\mathrm{ext}}$ 是外部注入电流。\n- 突触电导在脉冲之间遵循一阶衰减。\n- 使用大小为 $\\Delta t > 0$ 的离散时间步，并假设采用一种算子分裂格式，其中在更新 $V(t)$ 时，将 $g(t)$ 在每个时间步内视为分段常数。\n\n任务：\n1. 推导一个用于突触电导的闭式离散时间更新公式，该公式能捕捉在一个时间步 $\\Delta t$ 内的指数衰减以及由 $s_t$ 引起的瞬时增量。用 $g_t$、$\\Delta t$、$\\tau_s$、$w$ 和 $s_t$ 表示 $g_{t+1}$。\n2. 在假设 $g(t)$ 在电压更新期间被冻结在 $g_t$ 的条件下，推导膜电压在 $\\Delta t$ 内的精确离散时间更新。用 $V_t$、$g_t$、$g_L$、$E_L$、$E_{\\mathrm{rev}}$、$I_{\\mathrm{ext}}$、$C$ 和 $\\Delta t$ 表示 $V_{t+1}$。您的推导应从线性常微分方程开始，并使用精确积分，而不引入未从所述基础推导出的辅助快捷公式。\n3. 推导与相同连续时间方程对应的 $V_{t+1}$ 的显式前向欧拉更新。从前向欧拉方法作为导数的一阶离散化的定义出发，给出所得到的离散时间映射。\n4. 分析在大突触电导 $g_t$ 下电压更新的稳定性。对于精确更新，确定对于任何 $g_t \\ge 0$ 和 $\\Delta t > 0$，该映射是否是收缩的。对于前向欧拉更新，推导一个关于 $\\Delta t$、$C$、$g_L$ 和 $g_t$ 的条件，在该条件下，映射是稳定的，即 $V_t$ 的小扰动会随着迭代而衰减。给出保证在给定 $C$、$g_L$ 和 $g_t$ 下稳定性的 $\\Delta t$ 的显式上界。\n5. 实现一个程序，为下面的每个测试案例计算：\n   - 突触电导 $g_{t+1}$，单位为西门子（$\\mathrm{S}$）。\n   - 精确电压更新 $V_{t+1}^{\\mathrm{exact}}$，单位为伏特（$\\mathrm{V}$）。\n   - 前向欧拉电压更新 $V_{t+1}^{\\mathrm{Euler}}$，单位为伏特（$\\mathrm{V}$）。\n   - 一个布尔值 $s_{\\mathrm{exact}}$，指示对于给定参数，精确更新是否是收缩的（稳定的）。\n   - 一个布尔值 $s_{\\mathrm{Euler}}$，指示根据您推导的条件，对于给定参数，前向欧拉更新是否是稳定的。\n   - 前向欧拉的最大稳定步长 $\\Delta t_{\\max}^{\\mathrm{Euler}}$，单位为秒（$\\mathrm{s}$），表示为一个非负实数。\n\n电压以伏特（$\\mathrm{V}$）表示，电导以西门子（$\\mathrm{S}$）表示，电容以法拉（$\\mathrm{F}$）表示，时间以秒（$\\mathrm{s}$）表示，电流以安培（$\\mathrm{A}$）表示。所有输出必须是实数或布尔值；不要使用百分号。\n\n测试套件：\n- 案例 A (标称兴奋性输入，稳定的前向欧拉): $\\Delta t = 10^{-4}\\,\\mathrm{s}$, $\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$, $g_L = 10\\times 10^{-9}\\,\\mathrm{S}$, $C = 200\\times 10^{-12}\\,\\mathrm{F}$, $E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$, $E_{\\mathrm{rev}} = 0\\,\\mathrm{V}$, $I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$, $w = 5\\times 10^{-9}\\,\\mathrm{S}$, $s_t = 1$, $g_t = 30\\times 10^{-9}\\,\\mathrm{S}$, $V_t = -7.0\\times 10^{-2}\\,\\mathrm{V}$。\n- 案例 B (大突触电导，不稳定的前向欧拉): $\\Delta t = 5\\times 10^{-4}\\,\\mathrm{s}$, $\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$, $g_L = 10\\times 10^{-9}\\,\\mathrm{S}$, $C = 200\\times 10^{-12}\\,\\mathrm{F}$, $E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$, $E_{\\mathrm{rev}} = 0\\,\\mathrm{V}$, $I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$, $w = 5\\times 10^{-9}\\,\\mathrm{S}$, $s_t = 0$, $g_t = 2\\times 10^{-6}\\,\\mathrm{S}$, $V_t = -7.0\\times 10^{-2}\\,\\mathrm{V}$。\n- 案例 C (零突触电导下前向欧拉稳定性的边界条件): $\\Delta t = \\frac{2C}{g_L}\\,\\mathrm{s}$, $\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$, $g_L = 10\\times 10^{-9}\\,\\mathrm{S}$, $C = 200\\times 10^{-12}\\,\\mathrm{F}$, $E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$, $E_{\\mathrm{rev}} = -8.0\\times 10^{-2}\\,\\mathrm{V}$, $I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$, $w = 5\\times 10^{-9}\\,\\mathrm{S}$, $s_t = 0$, $g_t = 0\\,\\mathrm{S}$, $V_t = -6.5\\times 10^{-2}\\,\\mathrm{V}$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔的结果列表。对于每个测试案例，按任务 5 中指定的顺序附加六个量。因此，最终输出应为一个长度为 $18$ 的扁平列表，依次包含案例 A 的六个结果，然后是案例 B 的六个结果，最后是案例 C 的六个结果。例如，输出必须看起来像 $[x_1,x_2,x_3,x_4,x_5,x_6,x_7,\\ldots,x_{18}]$，其中每个 $x_i$ 是一个布尔值或一个以 SI 单位表示的实数。",
            "solution": "该问题陈述科学基础扎实、提法恰当、客观且自洽。它提出了一个标准的阈下漏电积分-发放神经元模型，该模型具有基于电导的突触，并要求进行关于其离散时间模拟和数值稳定性的特定、可形式化的推导和计算。所提供的参数在物理上是现实的，各项任务在逻辑上是一致的。该问题被认为是有效的。\n\n在此，我们从第一性原理推导所要求的更新方程和稳定性条件。\n\n### 任务 1：突触电导更新\n\n突触电导 $g(t)$ 的动力学在脉冲之间由一阶衰减控制。相应的常微分方程（ODE）是：\n$$\n\\frac{dg}{dt} = -\\frac{g}{\\tau_s}\n$$\n其中 $\\tau_s$ 是突触时间常数。为了找到 $g$ 在一个离散时间步 $\\Delta t$ 内的演化，我们对这个 ODE 从时间 $t$ 到 $t+\\Delta t$ 进行积分。分离变量，我们得到：\n$$\n\\int_{g_t}^{g(t+\\Delta t)} \\frac{dg}{g} = -\\frac{1}{\\tau_s} \\int_{t}^{t+\\Delta t} dt'\n$$\n$$\n\\ln(g(t+\\Delta t)) - \\ln(g_t) = -\\frac{\\Delta t}{\\tau_s}\n$$\n$$\n\\ln\\left(\\frac{g(t+\\Delta t)}{g_t}\\right) = -\\frac{\\Delta t}{\\tau_s}\n$$\n对两边取指数，得到更新的衰减部分：\n$$\ng(t+\\Delta t) = g_t e^{-\\Delta t/\\tau_s}\n$$\n问题陈述指出，在时间 $t$ 有一个突触前脉冲到达时（由 $s_t=1$ 指示），会有一个大小为 $w$ 的脉冲式增量。这个增量被加到衰减后的电导上，以获得下一个时间步 $g_{t+1}$ 的值。因此，突触电导 $g_t$ 的完整离散时间更新方程是：\n$$\ng_{t+1} = g_t e^{-\\Delta t/\\tau_s} + w s_t\n$$\n\n### 任务 2：精确膜电压更新\n\n膜电位 $V(t)$ 由电流平衡方程控制：\n$$\nC \\frac{dV}{dt} = -g_L (V - E_L) - g(t)(V - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\n$$\n根据算子分裂格式，我们假设突触电导 $g(t)$ 在区间 $[t, t+\\Delta t]$ 内保持为其值 $g_t$ 不变。电压的 ODE 成为一个线性一阶方程：\n$$\nC \\frac{dV}{dt} = -g_L (V - E_L) - g_t(V - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\n$$\n我们重新排列各项，将 $V$ 的倍数归类：\n$$\nC \\frac{dV}{dt} = -g_L V + g_L E_L - g_t V + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}\n$$\n$$\nC \\frac{dV}{dt} = -(g_L + g_t)V + (g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}})\n$$\n我们定义总有效电导 $G_{\\mathrm{tot}} = g_L + g_t$ 和总输入电流项 $I_{\\mathrm{eff}} = g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}$。方程简化为：\n$$\n\\frac{dV}{dt} = -\\frac{G_{\\mathrm{tot}}}{C}V + \\frac{I_{\\mathrm{eff}}}{C}\n$$\n这是一个形式为 $\\frac{dV}{dt} = aV+b$ 的标准线性 ODE。让我们重写它以突出稳态电压 $V_{\\infty}$ 和有效时间常数 $\\tau_{\\mathrm{eff}}$：\n$$\n\\frac{dV}{dt} = -\\frac{g_L+g_t}{C} \\left( V - \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} \\right)\n$$\n这里，有效时间常数为 $\\tau_{\\mathrm{eff}} = \\frac{C}{g_L+g_t}$，稳态电压为 $V_{\\infty} = \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t}$。该 ODE 为 $\\frac{dV}{dt} = -\\frac{1}{\\tau_{\\mathrm{eff}}}(V - V_{\\infty})$。\n此 ODE 在初始条件 $V(t) = V_t$ 下的精确解为：\n$$\nV(t') = V_{\\infty} + (V_t - V_{\\infty}) e^{-(t'-t)/\\tau_{\\mathrm{eff}}}\n$$\n为了找到下一个时间步的电压，我们在 $t' = t+\\Delta t$ 处计算此表达式：\n$$\nV_{t+1} = V_{\\infty} + (V_t - V_{\\infty}) e^{-\\Delta t/\\tau_{\\mathrm{eff}}}\n$$\n将 $V_{\\infty}$ 和 $\\tau_{\\mathrm{eff}}$ 的定义代回，我们得到电压的精确离散时间更新规则：\n$$\nV_{t+1} = \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} + \\left( V_t - \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} \\right) \\exp\\left(-\\frac{(g_L+g_t)\\Delta t}{C}\\right)\n$$\n只要 $g_L+g_t \\neq 0$，此更新就是有效的。在问题中，$g_L > 0$，所以这个条件总是满足的。\n\n### 任务 3：前向欧拉电压更新\n\n前向欧拉方法使用离散更新 $y_{t+1} = y_t + \\Delta t \\cdot f(y_t, t)$ 来近似求解 ODE $\\frac{dy}{dt} = f(y,t)$。对于我们的电压方程，函数 $f(V_t, t)$ 是：\n$$\nf(V_t, t) = \\frac{dV}{dt}\\bigg|_{V=V_t} = \\frac{1}{C}\\left(-g_L(V_t - E_L) - g_t(V_t - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\\right)\n$$\n应用前向欧拉公式，我们得到：\n$$\nV_{t+1}^{\\mathrm{Euler}} = V_t + \\Delta t \\cdot \\frac{1}{C}\\left(-g_L(V_t - E_L) - g_t(V_t - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\\right)\n$$\n这是膜电压的显式前向欧拉更新。\n\n### 任务 4：稳定性分析\n\n形式为 $x_{k+1} = A x_k + B$ 的离散时间线性映射是稳定的，如果小扰动会衰减，这要求乘子 $A$ 的大小严格小于 $1$，即 $|A|<1$。这种映射被称为压缩映射。\n\n**精确更新的稳定性：**\n精确更新规则可以写成 $V_{t+1} = A_{\\mathrm{exact}}V_t + B_{\\mathrm{exact}}$ 的形式，其中乘子是：\n$$\nA_{\\mathrm{exact}} = \\exp\\left(-\\frac{(g_L+g_t)\\Delta t}{C}\\right)\n$$\n根据问题陈述和典型的物理约束，我们有 $C > 0$, $\\Delta t > 0$, $g_L > 0$, and $g_t \\ge 0$。因此，总电导 $g_L+g_t$ 严格为正。指数的参数 $-\\frac{(g_L+g_t)\\Delta t}{C}$ 总是一个有限的、严格为负的数。对于任何严格为负的参数 $x < 0$，其指数 $e^x$ 满足 $0 < e^x < 1$。因此，我们有：\n$$\n0 < A_{\\mathrm{exact}} < 1\n$$\n由于对于所有有效的参数集都有 $|A_{\\mathrm{exact}}| < 1$，所以精确积分方案总是收缩的，因此是无条件稳定的。\n\n**前向欧拉更新的稳定性：**\n前向欧拉更新可以重新整理成 $V_{t+1}^{\\mathrm{Euler}} = A_{\\mathrm{Euler}}V_t + B_{\\mathrm{Euler}}$ 的形式。首先，我们分离出乘以 $V_t$ 的项：\n$$\nV_{t+1}^{\\mathrm{Euler}} = V_t - \\frac{\\Delta t}{C}(g_L+g_t)V_t + \\frac{\\Delta t}{C}(g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}})\n$$\n乘子是：\n$$\nA_{\\mathrm{Euler}} = 1 - \\frac{(g_L+g_t)\\Delta t}{C}\n$$\n为了稳定性，我们要求 $|A_{\\mathrm{Euler}}| < 1$，这转化为两个不等式：\n$$\n-1 < 1 - \\frac{(g_L+g_t)\\Delta t}{C} \\quad \\text{和} \\quad 1 - \\frac{(g_L+g_t)\\Delta t}{C} < 1\n$$\n第二个不等式，$-\\frac{(g_L+g_t)\\Delta t}{C} < 0$，总是成立的，因为 $g_L+g_t > 0$, $\\Delta t > 0$, 和 $C>0$。\n第一个不等式给出了稳定性条件：\n$$\n-2 < -\\frac{(g_L+g_t)\\Delta t}{C}\n$$\n$$\n2 > \\frac{(g_L+g_t)\\Delta t}{C}\n$$\n$$\n\\Delta t < \\frac{2C}{g_L+g_t}\n$$\n这是在给定 $C$、$g_L$ 和 $g_t$ 的情况下，前向欧拉方案稳定的时间步 $\\Delta t$ 的条件。稳定性的 $\\Delta t$ 的显式上界是：\n$$\n\\Delta t_{\\max}^{\\mathrm{Euler}} = \\frac{2C}{g_L+g_t}\n$$\n如果 $\\Delta t < \\Delta t_{\\max}^{\\mathrm{Euler}}$，前向欧拉更新是稳定的。当 $\\Delta t = \\Delta t_{\\max}^{\\mathrm{Euler}}$ 时，乘子 $A_{\\mathrm{Euler}}$ 变为 $-1$，导致临界稳定（振荡），此时扰动不衰减。\n\n### 任务 5：实现\n\n以下程序实现了所推导的公式，用以计算每个测试案例所需的六个量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes dynamics and stability for a leaky integrate-and-fire neuron model.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Nominal excitatory input, stable Forward Euler\n        {\n            \"delta_t\": 1e-4, \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": 0.0, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 1, \"g_t\": 30e-9, \"V_t\": -7.0e-2\n        },\n        # Case B: Large synaptic conductance, Forward Euler unstable\n        {\n            \"delta_t\": 5e-4, \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": 0.0, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 0, \"g_t\": 2e-6, \"V_t\": -7.0e-2\n        },\n        # Case C: Boundary condition for Forward Euler stability\n        {\n            # delta_t is calculated from other params for this case\n            \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": -8.0e-2, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 0, \"g_t\": 0.0, \"V_t\": -6.5e-2\n        }\n    ]\n    # Special calculation for case C delta_t\n    test_cases[2][\"delta_t\"] = 2 * test_cases[2][\"C\"] / test_cases[2][\"g_L\"]\n\n    results = []\n    for params in test_cases:\n        delta_t = params[\"delta_t\"]\n        tau_s = params[\"tau_s\"]\n        g_L = params[\"g_L\"]\n        C = params[\"C\"]\n        E_L = params[\"E_L\"]\n        E_rev = params[\"E_rev\"]\n        I_ext = params[\"I_ext\"]\n        w = params[\"w\"]\n        s_t = params[\"s_t\"]\n        g_t = params[\"g_t\"]\n        V_t = params[\"V_t\"]\n\n        # 1. Synaptic conductance g_{t+1}\n        g_tp1 = g_t * np.exp(-delta_t / tau_s) + w * s_t\n\n        # 2. Exact voltage update V_{t+1}^{exact}\n        G_tot = g_L + g_t\n        if G_tot > 0:\n            V_inf = (g_L * E_L + g_t * E_rev + I_ext) / G_tot\n            tau_eff = C / G_tot\n            V_tp1_exact = V_inf + (V_t - V_inf) * np.exp(-delta_t / tau_eff)\n        else: # Should not happen with g_L > 0\n            V_tp1_exact = V_t + (I_ext / C) * delta_t\n\n        # 3. Forward Euler voltage update V_{t+1}^{Euler}\n        dVdt_term = -g_L * (V_t - E_L) - g_t * (V_t - E_rev) + I_ext\n        V_tp1_euler = V_t + (delta_t / C) * dVdt_term\n\n        # 4. Stability of exact update (s_exact)\n        # As derived, it is unconditionally stable for g_L > 0, C > 0, delta_t > 0\n        # The multiplier is strictly between 0 and 1, so it is contractive.\n        s_exact = True\n\n        # 5. Stability of Forward Euler update (s_Euler) and max step size\n        # Must compute dt_max first to determine s_Euler\n        if G_tot > 0:\n            dt_max_euler = 2 * C / G_tot\n        else: # Unconditionally stable\n            dt_max_euler = float('inf')\n        \n        # Stability requires strict inequality\n        s_euler = delta_t  dt_max_euler\n        \n        # The order for results is specified in the problem\n        results.append(g_tp1)\n        results.append(V_tp1_exact)\n        results.append(V_tp1_euler)\n        results.append(s_exact)\n        results.append(s_euler)\n        results.append(dt_max_euler)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "由于脉冲函数的不可微性，训练循环脉冲神经网络极具挑战。本练习将介绍一种核心技术——直通估计器（Straight-Through Estimator, STE），它通过定义代理梯度来解决此问题。通过定量分析和比较使用及未使用STE时的梯度流，你将亲身体验并理解该技术如何有效缓解循环网络中的梯度消失问题 。",
            "id": "4056952",
            "problem": "考虑一个单神经元循环脉冲神经网络（SNN），其离散时间下的膜电位由以下泄漏递推关系决定\n$$\nV_{t+1} = \\alpha V_t + w_r\\, s(V_t) + b,\n$$\n其中 $t = 0,1,\\dots,T-1$，初始电位为 $V_0$。这里 $s(V)$ 是由 Heaviside 阶跃函数 $H(\\cdot)$ 给出的二元脉冲函数，即 $s(V) = H(V - V_{th})$，其中 $V_{th}$ 是脉冲阈值。常数包括泄漏因子 $\\alpha \\in (0,1)$、循环权重 $w_r \\in \\mathbb{R}$ 和偏置 $b \\in \\mathbb{R}$。我们考虑使用时间反向传播（BPTT）来分析梯度消失问题。\n\n为脉冲函数的导数引入一个直通估计器（STE），使得\n$$\n\\frac{\\partial s}{\\partial V}(V) \\approx g(V) = \\begin{cases}\n1,  \\text{if } |V - V_{th}| \\le \\delta,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n其中窗口半宽 $\\delta  0$。这个替代导数仅在膜电位处于阈值附近的一个小窗口内时才对可学习性进行建模。为了分析梯度在时间上的流动，考虑在时间 $t$ 的雅可比因子\n$$\nJ_t = \\frac{\\partial V_{t+1}}{\\partial V_t}.\n$$\n仅使用基本原理，特别是微积分中的链式法则和递推定义，来构建一个显式计算方法，用于计算梯度在时间上传播的幅度，\n$$\nG = \\left|\\frac{\\partial V_T}{\\partial V_0}\\right|.\n$$\n同时，计算在不使用替代梯度时（即 $\\partial s/\\partial V \\equiv 0$）获得的基线幅度 $G_0$。最后，报告比率\n$$\nR = \\frac{G}{G_0},\n$$\n该比率量化了 STE 在 $T$ 个时间步上对梯度消失的影响。\n\n你的程序必须：\n- 完全按照规定实现 $V_t$ 的前向动态。\n- 实现具有上述定义的指示器窗口的替代导数 $g(V)$。\n- 使用上述定义从第一性原理计算 $J_t$，然后通过链式法则将 $|J_t|$ 在时间上相乘来计算 $G$，并与无 STE 的设置一致地计算 $G_0$。\n- 为每个测试用例返回比率 $R$。\n\n除了指定的内容外，你不得引入任何额外的动态（例如，硬重置或软重置项）。\n\n测试套件：\n为以下五个参数集 $(T,\\alpha,w_r,b,V_{th},\\delta,V_0)$ 提供结果：\n\n1. 具有阈值穿越和正循环反馈的一般情况（理想路径）：\n   - $T = 60$, $\\alpha = 0.9$, $w_r = 0.4$, $b = 0.12$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n2. 窗口停用（STE 中性的边界情况）：\n   - $T = 60$, $\\alpha = 0.9$, $w_r = 0.4$, $b = 0.12$, $V_{th} = 1.0$, $\\delta = 0.0$, $V_0 = 0.0$。\n\n3. 大时间范围下的强梯度消失基线（边缘情况）：\n   - $T = 100$, $\\alpha = 0.5$, $w_r = 0.8$, $b = 0.8$, $V_{th} = 1.0$, $\\delta = 0.02$, $V_0 = 0.0$。\n\n4. 负循环权重（不利影响情况）：\n   - $T = 80$, $\\alpha = 0.9$, $w_r = -0.7$, $b = 0.15$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n5. 无循环反馈（对照情况）：\n   - $T = 120$, $\\alpha = 0.99$, $w_r = 0.0$, $b = 0.0105$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[result1,result2,result3]”）。每个结果必须是相应测试用例的浮点数 $R$，顺序与上面列出的一致。不应打印任何其他文本。",
            "solution": "经评估，用户提供的问题是有效的。它在科学上基于计算神经科学和机器学习的原理，问题阐述清晰，具有明确且唯一的可解结构，并且其数学公式是客观的。我们将提供完整的解决方案。\n\n该问题要求对直通估计器（STE）在单神经元循环脉冲神经网络（SNN）中对梯度传播的影响进行定量分析。分析的核心是计算使用 STE 时的梯度幅度与不使用 STE 时的基线梯度幅度之比 $R$。\n\n首先，我们对问题的各个组成部分进行形式化。神经元的膜电位 $V_t$ 根据离散时间递推关系演化：\n$$\nV_{t+1} = \\alpha V_t + w_r s(V_t) + b\n$$\n其中 $t \\in \\{0, 1, \\dots, T-1\\}$ 是时间步，$\\alpha \\in (0,1)$ 是泄漏因子，$w_r$ 是循环突触权重，$b$ 是恒定的偏置电流。脉冲行为由函数 $s(V_t)$ 控制，该函数使用 Heaviside 阶跃函数 $H(\\cdot)$ 定义如下：\n$$\ns(V_t) = H(V_t - V_{th}) = \\begin{cases}\n1,  \\text{if } V_t \\ge V_{th} \\\\\n0,  \\text{if } V_t  V_{th}\n\\end{cases}\n$$\n这里，$V_{th}$ 是固定的脉冲阈值。\n\n为了使用基于梯度的方法训练这样的网络，我们需要通过时间反向传播梯度（BPTT）。我们感兴趣的量是最终状态 $V_T$ 相对于初始状态 $V_0$ 的梯度，即 $\\frac{\\partial V_T}{\\partial V_0}$。使用链式法则，该梯度表示为雅可比因子的乘积：\n$$\n\\frac{\\partial V_T}{\\partial V_0} = \\frac{\\partial V_T}{\\partial V_{T-1}} \\frac{\\partial V_{T-1}}{\\partial V_{T-2}} \\cdots \\frac{\\partial V_1}{\\partial V_0} = \\prod_{t=0}^{T-1} \\frac{\\partial V_{t+1}}{\\partial V_t}\n$$\n我们将时间 $t$ 的雅可比因子定义为 $J_t = \\frac{\\partial V_{t+1}}{\\partial V_t}$。我们可以通过对递推关系关于 $V_t$ 求导来计算它：\n$$\nJ_t = \\frac{\\partial}{\\partial V_t} (\\alpha V_t + w_r s(V_t) + b) = \\alpha + w_r \\frac{\\partial s(V_t)}{\\partial V_t}\n$$\nHeaviside 阶跃函数的导数 $\\frac{\\partial s(V_t)}{\\partial V_t}$，在除了阈值之外的所有地方都为零，而在阈值处是未定义的（在数学上是一个狄拉克δ函数）。在实际的 BPTT 实现中，这个导数被视为零，这会阻碍学习。直通估计器（STE）是一种通过用替代函数替换导数来克服此问题的技术。问题指定了以下替代导数 $g(V)$：\n$$\ng(V) = \\frac{\\partial s}{\\partial V}(V) \\approx \\begin{cases}\n1,  \\text{if } |V - V_{th}| \\le \\delta \\\\\n0,  \\text{otherwise}\n\\end{cases}\n$$\n其中 $\\delta  0$ 定义了阈值 $V_{th}$ 周围的一个小窗口。将 $g(V_t)$ 替换 $\\frac{\\partial s(V_t)}{\\partial V_t}$，雅可比因子变为：\n$$\nJ_t = \\alpha + w_r g(V_t)\n$$\n通过 $T$ 个时间步传播的总梯度幅度，我们记为 $G$，是这些雅可比因子乘积的绝对值：\n$$\nG = \\left| \\prod_{t=0}^{T-1} J_t \\right| = \\prod_{t=0}^{T-1} |J_t| = \\prod_{t=0}^{T-1} |\\alpha + w_r g(V_t)|\n$$\n要计算 $G$，我们必须首先执行一次前向传播，以模拟 $V_t$ 在 $t \\in [0, T]$ 上的轨迹。然后，对于每个时间步 $t \\in [0, T-1]$，我们评估 $g(V_t)$ 并计算乘积中的相应项。\n\n接下来，我们必须计算基线梯度幅度 $G_0$。这被定义为不使用替代梯度的情况，明确表述为 $\\frac{\\partial s}{\\partial V} \\equiv 0$。这意味着对于基线情况，对所有 $t$ 都有 $g(V_t) = 0$。雅可比因子 $J_{0,t}$ 简化为：\n$$\nJ_{0,t} = \\alpha + w_r \\cdot 0 = \\alpha\n$$\n那么，基线梯度幅度 $G_0$ 为：\n$$\nG_0 = \\prod_{t=0}^{T-1} |\\alpha| = |\\alpha|^T\n$$\n由于问题陈述 $\\alpha \\in (0,1)$，我们有 $G_0 = \\alpha^T$。该项随 $T$ 指数衰减，代表了循环网络中典型的梯度消失问题。\n\n最后，问题要求计算比率 $R = \\frac{G}{G_0}$，它量化了 STE 对梯度流的影响：\n$$\nR = \\frac{\\prod_{t=0}^{T-1} |\\alpha + w_r g(V_t)|}{\\alpha^T}\n$$\n与基线衰减相比，该比率衡量了 STE 对梯度流是放大（$|J_t|  \\alpha$）还是衰减（$|J_t|  \\alpha$）了多少倍。计算过程如下：\n1. 对于给定的参数集 $(T, \\alpha, w_r, b, V_{th}, \\delta, V_0)$，模拟神经元从 $t=0$ 到 $T-1$ 的动态，以获得完整的膜电位轨迹 $\\{V_0, V_1, \\dots, V_T\\}$。\n2. 通过从 $t=0$ 到 $T-1$ 迭代，在每一步评估 $g(V_t)$，计算 $J_t = \\alpha + w_r g(V_t)$，并将累积的乘积乘以 $|J_t|$ 来计算 $G$。\n3. 计算 $G_0 = \\alpha^T$。\n4. 计算比率 $R = G / G_0$。\n对每个提供的测试用例都执行此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ratio of gradient magnitudes for a single-neuron SNN\n    with and without a Straight-Through Estimator (STE).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, alpha, w_r, b, V_th, delta, V_0)\n        (60, 0.9, 0.4, 0.12, 1.0, 0.05, 0.0),      # Case 1: General case\n        (60, 0.9, 0.4, 0.12, 1.0, 0.0, 0.0),       # Case 2: Window deactivated\n        (100, 0.5, 0.8, 0.8, 1.0, 0.02, 0.0),     # Case 3: Strong vanishing baseline\n        (80, 0.9, -0.7, 0.15, 1.0, 0.05, 0.0),     # Case 4: Negative recurrent weight\n        (120, 0.99, 0.0, 0.0105, 1.0, 0.05, 0.0)  # Case 5: No recurrent feedback\n    ]\n\n    results = []\n    for case in test_cases:\n        T, alpha, w_r, b, V_th, delta, V_0 = case\n\n        # Step 1: Forward pass to compute the membrane potential trajectory V_t.\n        # V is a numpy array of size T+1 to store V_0 to V_T.\n        V = np.zeros(T + 1)\n        V[0] = V_0\n\n        for t in range(T):\n            # The spike function s(V) is the Heaviside step function H(V - V_th).\n            # H(x) is 1 if x >= 0, and 0 otherwise.\n            spike = 1.0 if V[t] >= V_th else 0.0\n            \n            # Apply the leaky recurrence relation.\n            V[t+1] = alpha * V[t] + w_r * spike + b\n\n        # Step 2: Compute G, the gradient magnitude with the STE.\n        # This requires a \"backward\" pass over the V trajectory.\n        G = 1.0\n        for t in range(T):\n            # The surrogate derivative g(V).\n            # g(V) is 1 if |V - V_th| = delta, and 0 otherwise.\n            surrogate_grad = 1.0 if np.abs(V[t] - V_th) = delta else 0.0\n\n            # The Jacobian factor J_t.\n            J_t = alpha + w_r * surrogate_grad\n\n            # The total gradient magnitude is the product of the absolute values.\n            G *= np.abs(J_t)\n\n        # Step 3: Compute G_0, the baseline gradient magnitude.\n        # This corresponds to the case where the derivative of s(V) is always zero.\n        # G_0 = alpha^T.\n        G_0 = alpha ** T\n\n        # Step 4: Compute the ratio R = G / G_0.\n        # We check for G_0 being zero, although alpha in (0,1) prevents this.\n        if G_0 == 0.0:\n            # This case is not expected with the problem constraints.\n            R = float('inf') if G > 0 else 1.0\n        else:\n            R = G / G_0\n\n        results.append(R)\n\n    # Final print statement in the exact required format.\n    # We format the floats to ensure consistent and clean output.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "循环网络的计算能力往往源于其丰富的内部动力学。本练习将带你进入储层计算（Reservoir Computing）的领域，这是一种有效利用网络内在动力学的计算范式。你将通过仿真来探究一个关键的网络结构属性——连接稀疏度——如何影响网络为不同输入信号生成可区分状态表征的能力，这是模式识别任务的基石 。",
            "id": "4056967",
            "problem": "考虑一个由漏积分-发放（Leaky Integrate-and-Fire, LIF）神经元建模的循环脉冲神经网络（Spiking Neural Network, SNN）储层。目标是分析循环储层中的连接稀疏性如何影响由输入引起的状态轨迹的可分离性。可分离性将通过对应于不同输入刺激的轨迹向量之间的成对欧几里得距离来量化。该分析必须比较不同连接密度下的这些成对距离。\n\n基本原理：\n- 通过微分方程定义LIF神经元的膜电位动力学：$$\\tau_m \\frac{dV_i(t)}{dt} = -\\left(V_i(t) - V_{\\text{rest}}\\right) + R_m I_i(t),$$ 其中 $V_i(t)$ 是神经元 $i$ 的膜电位，$I_i(t)$ 是流入神经元 $i$ 的总突触电流，$\\tau_m$ 是膜时间常数，$R_m$ 是膜电阻，$V_{\\text{rest}}$ 是静息电位。当 $V_i(t)$ 超过阈值 $V_{\\text{thr}}$ 时，会发放一个脉冲，之后 $V_i(t)$ 被重置为 $V_{\\text{reset}}$ 并在此值上维持一个不应期。\n- 使用指数衰减的突触后电流（Post-Synaptic Current, PSC）对突触电流进行建模：$$\\tau_s \\frac{dI_i(t)}{dt} = -I_i(t) + \\sum_{j=1}^{N} W_{ij} s_j(t) + w_{\\text{in}} x_i(t),$$ 其中 $\\tau_s$ 是突触时间常数，$W_{ij}$ 是从神经元 $j$ 到神经元 $i$ 的循环权重，$s_j(t)$ 是神经元 $j$ 的脉冲序列，$x_i(t)$ 是到神经元 $i$ 的外部输入脉冲序列，$w_{\\text{in}}$ 是前馈输入权重。外部输入脉冲序列 $x_i(t)$ 由具有指定速率（单位为赫兹）的独立泊松过程生成。\n- 为了构建一个能捕捉动力学的轨迹表示，定义一个滤波后的脉冲状态：$$\\tau_f \\frac{dy_i(t)}{dt} = -y_i(t) + s_i(t),$$ 其中 $y_i(t)$ 是神经元 $i$ 的低通滤波脉冲序列，$\\tau_f$ 是滤波时间常数。对于一个输入刺激，储层轨迹向量是 $y_i(t)$ 在所有神经元和时间步上展开得到的向量。\n\n储层构建与连接稀疏性：\n- 储层有 $N$ 个LIF神经元。根据戴尔定律（Dale’s law），每个突触前神经元 $j$ 要么是兴奋性的，要么是抑制性的，其符号固定。循环连接是随机的，连接密度为 $d \\in [0,1]$，它定义了对于 $i \\neq j$ 的连接 $W_{ij}$ 存在的概率。存在的连接的量值是正的，从指数分布中抽取，然后根据突触前神经元的类型赋予符号。禁止自连接，即 $W_{ii} = 0$。\n- 为了使不同密度 $d$ 之间的比较有意义，当 $d  0$ 时，将权重量值按与 $\\sqrt{N d}$ 成反比的因子进行缩放，以便在 $d$ 变化时，总传入方差大致保持受控。\n\n离散时间仿真：\n- 使用步长为 $\\Delta t$ 的时间离散化。膜电位和电流的更新通过欧拉积分进行。脉冲状态 $s_i(t)$ 在每个时间步长上是二元的（$0$ 或 $1$）。外部输入脉冲序列 $x_i(t)$ 对每个神经元使用伯努利过程独立生成，其成功概率为 $p = r \\Delta t$，其中 $r$ 是以赫兹为单位的输入速率，$\\Delta t$ 以秒为单位。\n\n轨迹可分离性：\n- 对于每个连接密度 $d$，使用具有不同泊松速率的多个输入刺激来仿真储层。对于每个刺激，通过将滤波后的脉冲状态 $y_i(t)$ 在所有神经元和时间步上展开来获得轨迹向量。计算对应于不同刺激的轨迹向量之间的成对欧几里得距离。密度 $d$ 的可分离性分数定义为这些成对距离的平均值。\n\n物理单位与数值：\n- 时间 $\\Delta t$ 为 $1$ 毫秒（$\\Delta t = 1$ ms），总仿真时长为 $T = 500$ 毫秒（$T = 500$ ms），角度不适用。电位单位为毫伏（mV），但输出关注的是轨迹向量之间的无量纲距离。\n- 膜参数：$\\tau_m = 20$ ms, $V_{\\text{rest}} = -65$ mV, $V_{\\text{thr}} = -50$ mV, $V_{\\text{reset}} = -65$ mV, 不应期 $= 2$ ms, 以及 $R_m = 1$（无量纲尺度）。\n- 突触和滤波参数：$\\tau_s = 5$ ms, $\\tau_f = 20$ ms, $w_{\\text{in}} = 1.0$（无量纲尺度）。\n- 储层大小：$N = 100$，兴奋性神经元比例 $p_{\\text{exc}} = 0.8$，因此抑制性神经元数量为 $N_{\\text{inh}} = N (1 - p_{\\text{exc}})$。\n- 指数分布的权重量值基础尺度：$b = 0.2$（无量纲），当 $d  0$ 时按 $1/\\sqrt{N d}$ 缩放；当 $d = 0$ 时，设 $W_{ij} = 0$。\n\n输入刺激：\n- 使用输入速率 $r \\in \\{5, 20, 50, 80\\}$ 赫兹。\n\n测试集：\n- 待测试的连接密度 $d$：$\\{0.0, 0.05, 0.2, 0.5, 1.0\\}$。\n- 对于上述集合中的每个 $d$，使用 $\\{5, 20, 50, 80\\}$ 赫兹中的所有输入速率仿真储层，并计算所有不同刺激对之间的平均成对欧几里得距离。\n\n算法任务：\n- 实现上述离散时间LIF储层动力学和轨迹处理。\n- 对于测试集中的每个 $d$，输出可分离性分数（一个浮点数）：四个刺激的轨迹向量之间的平均成对欧几里得距离。\n- 必须通过固定的随机种子来控制随机性，以使结果具有确定性。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按指定顺序排列的连接密度的可分离性分数，形式为逗号分隔的列表，并用方括号括起来，例如 $$[s_{d_1}, s_{d_2}, \\dots, s_{d_5}]$$ 其中每个 $s_{d_k}$ 是测试集中第 $k$ 个密度的平均成对距离。",
            "solution": "该问题要求分析循环脉冲神经网络（SNN）储层的连接稀疏性如何影响其对不同输入刺激响应的可分离性。该SNN由漏积分-发放（LIF）神经元组成。该分析将通过在不同连接密度下仿真网络动力学并量化所得状态空间轨迹的可分离性来执行。\n\n首先，我们基于所提供的连续时间微分方程，形式化离散时间仿真模型。仿真以 $\\Delta t = 1$ ms 的离散时间步进行。我们按照指定使用前向欧拉方法进行积分。\n\n神经元 $i$ 在时间步 $t+1$ 的膜电位 $V_i$ 是基于其在时间步 $t$ 的值和突触电流 $I_i$ 来更新的。提供的方程为 $\\tau_m \\frac{dV_i}{dt} = -(V_i - V_{\\text{rest}}) + R_m I_i$。当 $R_m=1$ 时，其离散形式为：\n$$V_i[t+1] = V_i[t] + \\frac{\\Delta t}{\\tau_m} \\left( -(V_i[t] - V_{\\text{rest}}) + I_i[t] \\right)$$\n可以重排为：\n$$V_i[t+1] = V_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_m}\\right) + \\frac{\\Delta t}{\\tau_m} \\left( V_{\\text{rest}} + I_i[t] \\right)$$\n\n突触电流 $I_i$ 由储层内部的循环脉冲和外部输入脉冲驱动。其控制方程为 $\\tau_s \\frac{dI_i}{dt} = -I_i + \\sum_{j=1}^{N} W_{ij} s_j(t) + w_{\\text{in}} x_i(t)$。其欧拉离散化形式为：\n$$I_i[t+1] = I_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_s}\\right) + \\frac{\\Delta t}{\\tau_s} \\left( \\sum_{j=1}^{N} W_{ij} s_j[t] + w_{\\text{in}} x_i[t] \\right)$$\n此处，$s_j[t]$ 是一个二元变量，如果神经元 $j$ 在时间步 $t$ 发放脉冲，则为 $1$，否则为 $0$。类似地，$x_i[t]$ 是在时间步 $t$ 输入到神经元 $i$ 的二元外部脉冲。\n\n如果神经元 $i$ 的膜电位 $V_i[t]$ 在时间步 $t$ 超过阈值 $V_{\\text{thr}}$，它就会发放一个脉冲。发放脉冲后，其电位被重置为 $V_{\\text{reset}}$，神经元进入一个为期 $2$ 毫秒（$2$ 个时间步）的不应期，在此期间其电位被钳制在 $V_{\\text{reset}}$。\n\n状态空间轨迹由脉冲序列的低通滤波版本 $y_i(t)$ 构建。动力学方程 $\\tau_f \\frac{dy_i}{dt} = -y_i + s_i(t)$ 被离散化为：\n$$y_i[t+1] = y_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_f}\\right) + \\frac{\\Delta t}{\\tau_f} s_i[t]$$\n\n算法流程如下：\n\n1.  **初始化**：我们设置一个全局随机种子以保证可复现性。所有时间常数（$\\tau_m$, $\\tau_s$, $\\tau_f$）都转换为时间步数（例如，$\\tau_m / \\Delta t = 20 \\text{ ms} / 1 \\text{ ms} = 20$）。预先生成四种不同的外部输入脉冲序列，分别对应于 $r \\in \\{5, 20, 50, 80\\}$ Hz 的每个速率。每个序列是一个 $N \\times T$ 的矩阵，其中每个条目是成功概率为 $p = r \\Delta t$ 的独立伯努利试验。预先生成这些输入可以确保在每种连接密度下都使用同一组刺激来测试储层，从而提供一个受控的比较。\n\n2.  **储层构建**：对于每个连接密度 $d \\in \\{0.0, 0.05, 0.2, 0.5, 1.0\\}$，我们构建一个相应的 $N \\times N$（其中 $N=100$）的循环权重矩阵 $W$。\n    -   分配神经元类型：$80\\%$ 兴奋性（$N_{\\text{exc}}=80$）和 $20\\%$ 抑制性（$N_{\\text{inh}}=20$）。\n    -   从神经元 $j$到 $i$ 的连接以概率 $d$ 存在。禁止自连接（$W_{ii}$）。\n    -   如果 $d0$，存在的权重量值从一个尺度参数为 $b=0.2$ 的指数分布中抽取。\n    -   权重 $W_{ij}$ 的符号由突触前神经元 $j$ 决定：如果 $j$ 是兴奋性的，则为正；如果是抑制性的，则为负（戴尔定律）。\n    -   为了在不同密度下保持网络稳定性，权重量值按 $1 / \\sqrt{Nd}$ 进行缩放。对于 $d=0$，所有权重 $W_{ij}$ 均设为 $0$。\n\n3.  **网络仿真**：对于给定的密度 $d$ 及其关联的权重矩阵 $W$，仿真 SNN 对四个预先生成的输入刺激中每一个的响应，时长为 $T=500$ ms（$500$ 步）。\n    -   在每个时间步 $t$，仿真因果进行：\n        a.  根据电流 $I_i[t]$ 更新非不应期神经元的电位 $V_i[t]$。\n        b.  电位超过 $V_{\\text{thr}}$ 的神经元被标记为发放脉冲，其脉冲变量 $s_i[t]$ 设为 $1$。\n        c.  发放脉冲的神经元电位被重置为 $V_{\\text{reset}}$，并启动其不应期计数器。\n        d.  使用脉冲向量 $s[t]$ 和外部输入向量 $x[t]$ 更新突触电流 $I_i[t+1]$ 和滤波状态 $y_i[t+1]$。\n    -   存储所有神经元和所有时间步的滤波状态向量 $y_i[t]$ 的历史记录。\n\n4.  **可分离性计算**：在固定密度 $d$ 下，为所有四个输入速率仿真网络后，我们得到四个轨迹矩阵。每个矩阵被展开成一个大小为 $N \\times T = 100 \\times 500 = 50000$ 的单向量。\n    -   这四个轨迹向量的可分离性通过它们之间的成对欧几里得距离来量化。共有 $\\binom{4}{2}=6$ 个唯一的对。\n    -   密度 $d$ 的可分离性分数是这六个欧几里得距离的算术平均值。\n\n对测试集中的每个密度重复此过程。最终输出是可分离性分数的列表，每个密度对应一个分数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Solves the recurrent SNN trajectory separability problem.\n    \"\"\"\n    # Use a fixed seed for reproducibility as required.\n    SEED = 0\n    rng = np.random.default_rng(SEED)\n\n    # Physical units and numerical values\n    DT_MS = 1.0\n    T_MS = 500.0\n    TAU_M_MS = 20.0\n    V_REST = -65.0\n    V_THR = -50.0\n    V_RESET = -65.0\n    REFRACTORY_PERIOD_MS = 2.0\n    R_M = 1.0  # Assumed dimensionless as per problem, folded into I\n    TAU_S_MS = 5.0\n    TAU_F_MS = 20.0\n    W_IN = 1.0\n    N = 100\n    P_EXC = 0.8\n    N_EXC = int(N * P_EXC)\n    WEIGHT_SCALE_BASE = 0.2\n\n    # Simulation parameters in terms of time steps\n    T_STEPS = int(T_MS / DT_MS)\n    REFRACTORY_STEPS = int(REFRACTORY_PERIOD_MS / DT_MS)\n    \n    # Pre-calculated Euler update coefficients\n    ALPHA_M = DT_MS / TAU_M_MS\n    ALPHA_S = DT_MS / TAU_S_MS\n    ALPHA_F = DT_MS / TAU_F_MS\n\n    # Test suite\n    densities_to_test = [0.0, 0.05, 0.2, 0.5, 1.0]\n    input_rates_hz = [5.0, 20.0, 50.0, 80.0]\n\n    # Pre-generate input spike trains for all stimuli to ensure fair comparison across densities\n    input_trains = []\n    dt_s = DT_MS / 1000.0\n    for r in input_rates_hz:\n        p = r * dt_s\n        train = rng.binomial(1, p, size=(T_STEPS, N)).astype(np.float64)\n        input_trains.append(train)\n\n    # Define neuron types for Dale's Law\n    neuron_signs = np.ones(N, dtype=np.float64)\n    neuron_signs[N_EXC:] = -1.0\n\n    separability_scores = []\n\n    for d in densities_to_test:\n        # 1. Reservoir construction\n        W = np.zeros((N, N), dtype=np.float64)\n        if d > 0:\n            # Create connectivity mask\n            mask = rng.random(size=(N, N))  d\n            np.fill_diagonal(mask, False)\n            \n            # Generate weights from exponential distribution\n            W_mag = rng.exponential(scale=WEIGHT_SCALE_BASE, size=(N, N))\n            \n            # Apply Dale's law and scaling\n            scaling_factor = 1.0 / np.sqrt(N * d)\n            W = mask * W_mag * scaling_factor * neuron_signs.reshape(1, -1)\n\n        trajectories = []\n        for x_train in input_trains:\n            # 2. Simulation for one stimulus\n            v = np.full(N, V_REST, dtype=np.float64)\n            i_syn = np.zeros(N, dtype=np.float64)\n            y_filtered = np.zeros(N, dtype=np.float64)\n            ref_counters = np.zeros(N, dtype=np.int32)\n            \n            y_history = np.zeros((T_STEPS, N), dtype=np.float64)\n\n            for t in range(T_STEPS):\n                is_refractory = ref_counters > 0\n                \n                # Update membrane potential for non-refractory neurons\n                dv = ALPHA_M * (-(v - V_REST) + R_M * i_syn)\n                v[~is_refractory] += dv[~is_refractory]\n                \n                # Decrement refractory counters and clamp potential\n                v[is_refractory] = V_RESET\n                ref_counters[is_refractory] -= 1\n\n                # Detect spikes\n                spiked = (v >= V_THR)  (~is_refractory)\n                s_t = spiked.astype(np.float64)\n                \n                # Reset potential and set refractory period for spiking neurons\n                v[spiked] = V_RESET\n                ref_counters[spiked] = REFRACTORY_STEPS\n                \n                # Update synaptic current\n                recurrent_input = W @ s_t\n                external_input = W_IN * x_train[t, :]\n                total_input = recurrent_input + external_input\n                di_syn = ALPHA_S * (-i_syn + total_input)\n                i_syn += di_syn\n                \n                # Update filtered spike state\n                dy_filtered = ALPHA_F * (-y_filtered + s_t)\n                y_filtered += dy_filtered\n                \n                y_history[t, :] = y_filtered\n\n            # Flatten trajectory and store\n            trajectories.append(y_history.flatten())\n\n        # 3. Trajectory separability calculation for the current density\n        if len(trajectories) > 1:\n            distances = pdist(np.array(trajectories), 'euclidean')\n            mean_distance = np.mean(distances)\n        else:\n            mean_distance = 0.0 # Should not happen with >1 stimuli rates\n            \n        separability_scores.append(mean_distance)\n\n    # Final output format\n    print(f\"[{','.join(map(str, separability_scores))}]\")\n\nsolve()\n```"
        }
    ]
}