{
    "hands_on_practices": [
        {
            "introduction": "精确地模拟神经元动力学是研究循环脉冲神经网络的基石。本练习将带领您为一个基于电导的LIF神经元推导并实现两种离散时间更新方案：精确积分法和前向欧拉法。通过比较这两种方法并分析它们的数值稳定性，您将掌握实现任何脉冲神经网络模型的核心技能，并深刻理解在仿真中确保结果有效性的重要性。",
            "id": "4056993",
            "problem": "考虑一个单室漏电积分发放神经元，其具有基于电导的突触输入，并嵌入在一个循环脉冲神经网络（SNN; Spiking Neural Network）中。该神经元具有膜电容 $C$ 和漏电导 $g_L$，其漏泄反转电位为 $E_L$。一个单一的有效突触电导 $g(t)$ 将膜电位驱动至突触反转电位 $E_{\\mathrm{rev}}$。突触电导根据时间常数为 $\\tau_s$ 的一阶衰减进行演化，并在离散时间 $t$ 接收到由离散脉冲指示器 $s_t \\in \\{0,1\\}$ 表示的突触前脉冲时，获得与突触权重 $w$ 成正比的脉冲式增量。膜电位记为 $V(t)$。为进行稳定性分析，假设脉冲生成和重置功能被禁用（即，在没有阈值或重置的情况下，在阈下状态对系统进行分析）。\n\n从第一性原理和经过充分检验的事实出发：\n- 膜遵循电流平衡方程 $C \\frac{dV}{dt} = -g_L \\left(V - E_L\\right) - g(t)\\left(V - E_{\\mathrm{rev}}\\right) + I_{\\mathrm{ext}}$，其中 $I_{\\mathrm{ext}}$ 是外部注入电流。\n- 突触电导在脉冲之间遵循一阶衰减。\n- 使用大小为 $\\Delta t  0$ 的离散时间步长，并假设采用算子分裂法，在更新 $V(t)$ 时，将 $g(t)$ 在每个时间步长内视为分段常数。\n\n任务：\n1. 推导突触电导的闭式离散时间更新公式，该公式能捕捉在一个时间步长 $\\Delta t$ 内的指数衰减以及由 $s_t$ 引起的瞬时增量。将 $g_{t+1}$ 表示为 $g_t$、$\\Delta t$、$\\tau_s$、 $w$ 和 $s_t$ 的函数。\n2. 在电压更新期间 $g(t)$ 冻结在 $g_t$ 的假设下，推导膜电位在 $\\Delta t$ 上的精确离散时间更新公式。将 $V_{t+1}$ 表示为 $V_t$、$g_t$、$g_L$、$E_L$、$E_{\\mathrm{rev}}$、$I_{\\mathrm{ext}}$、$C$ 和 $\\Delta t$ 的函数。您的推导应从线性常微分方程开始，并使用精确积分，不得引入未从所述基础推导出的辅助简化公式。\n3. 推导与同一连续时间方程对应的 $V_{t+1}$ 的显式前向欧拉更新公式。从前向欧拉法作为导数的一阶离散化的定义出发，给出最终的离散时间映射。\n4. 在大突触电导 $g_t$ 的条件下，分析电压更新的稳定性。对于精确更新，确定对于任何 $g_t \\ge 0$ 和 $\\Delta t  0$，该映射是否是压缩的。对于前向欧拉更新，推导一个关于 $\\Delta t$、$C$、$g_L$ 和 $g_t$ 的条件，在该条件下，映射是稳定的，即 $V_t$ 中的小扰动会随迭代而衰减。为给定的 $C$、$g_L$ 和 $g_t$，提供保证稳定性的 $\\Delta t$ 的显式上界。\n5. 实现一个程序，为下面的每个测试用例计算：\n   - 突触电导 $g_{t+1}$，单位为西门子（$\\mathrm{S}$）。\n   - 精确电压更新 $V_{t+1}^{\\mathrm{exact}}$，单位为伏特（$\\mathrm{V}$）。\n   - 前向欧拉电压更新 $V_{t+1}^{\\mathrm{Euler}}$，单位为伏特（$\\mathrm{V}$）。\n   - 一个布尔值 $s_{\\mathrm{exact}}$，指示在给定参数下精确更新是否是压缩的（稳定的）。\n   - 一个布尔值 $s_{\\mathrm{Euler}}$，指示根据您推导的条件，在给定参数下前向欧拉更新是否稳定。\n   - 前向欧拉法的最大稳定步长 $\\Delta t_{\\max}^{\\mathrm{Euler}}$，单位为秒（$\\mathrm{s}$），表示为一个非负实数。\n\n电压以伏特（$\\mathrm{V}$）表示，电导以西门子（$\\mathrm{S}$）表示，电容以法拉（$\\mathrm{F}$）表示，时间以秒（$\\mathrm{s}$）表示，电流以安培（$\\mathrm{A}$）表示。所有输出必须是实数或布尔值；不要使用百分号。\n\n测试套件：\n- 情况 A（标称兴奋性输入，前向欧拉法稳定）：$\\Delta t = 10^{-4}\\,\\mathrm{s}$，$\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$，$g_L = 10\\times 10^{-9}\\,\\mathrm{S}$，$C = 200\\times 10^{-12}\\,\\mathrm{F}$，$E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$，$E_{\\mathrm{rev}} = 0\\,\\mathrm{V}$，$I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$，$w = 5\\times 10^{-9}\\,\\mathrm{S}$，$s_t = 1$，$g_t = 30\\times 10^{-9}\\,\\mathrm{S}$，$V_t = -7.0\\times 10^{-2}\\,\\mathrm{V}$。\n- 情况 B（大突触电导，前向欧拉法不稳定）：$\\Delta t = 5\\times 10^{-4}\\,\\mathrm{s}$，$\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$，$g_L = 10\\times 10^{-9}\\,\\mathrm{S}$，$C = 200\\times 10^{-12}\\,\\mathrm{F}$，$E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$，$E_{\\mathrm{rev}} = 0\\,\\mathrm{V}$，$I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$，$w = 5\\times 10^{-9}\\,\\mathrm{S}$，$s_t = 0$，$g_t = 2\\times 10^{-6}\\,\\mathrm{S}$，$V_t = -7.0\\times 10^{-2}\\,\\mathrm{V}$。\n- 情况 C（零突触电导下前向欧拉法稳定性的边界条件）：$\\Delta t = \\frac{2C}{g_L}\\,\\mathrm{s}$，$\\tau_s = 5\\times 10^{-3}\\,\\mathrm{s}$，$g_L = 10\\times 10^{-9}\\,\\mathrm{S}$，$C = 200\\times 10^{-12}\\,\\mathrm{F}$，$E_L = -6.5\\times 10^{-2}\\,\\mathrm{V}$，$E_{\\mathrm{rev}} = -8.0\\times 10^{-2}\\,\\mathrm{V}$，$I_{\\mathrm{ext}} = 0\\,\\mathrm{A}$，$w = 5\\times 10^{-9}\\,\\mathrm{S}$，$s_t = 0$，$g_t = 0\\,\\mathrm{S}$，$V_t = -6.5\\times 10^{-2}\\,\\mathrm{V}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按任务 5 中指定的顺序附加六个量。因此，最终输出应为一个长度为 $18$ 的扁平列表，按顺序包含情况 A 的六个结果，然后是情况 B 的六个结果，最后是情况 C 的六个结果。例如，输出必须看起来像 $[x_1,x_2,x_3,x_4,x_5,x_6,x_7,\\ldots,x_{18}]$，其中每个 $x_i$ 是一个布尔值或一个以适当的国际单位制单位表示的实数。",
            "solution": "问题陈述具有科学依据、适定、客观且自洽。它提出了一个标准的带电导突触的漏电积分发放神经元的阈下模型，并要求进行关于其离散时间模拟和数值稳定性的具体、可形式化的推导和计算。所提供的参数符合物理实际，各项任务在逻辑上是一致的。该问题被认为是有效的。\n\n在此，我们从第一性原理出发，推导所要求的更新方程和稳定性条件。\n\n### 任务 1：突触电导更新\n\n突触电导 $g(t)$ 的动力学由脉冲之间的一阶衰减所控制。相应的常微分方程（ODE）是：\n$$\n\\frac{dg}{dt} = -\\frac{g}{\\tau_s}\n$$\n其中 $\\tau_s$ 是突触时间常数。为了找到 $g$ 在一个离散时间步长 $\\Delta t$ 内的演化，我们将此 ODE 从时间 $t$ 积分到 $t+\\Delta t$。分离变量，我们得到：\n$$\n\\int_{g_t}^{g(t+\\Delta t)} \\frac{dg}{g} = -\\frac{1}{\\tau_s} \\int_{t}^{t+\\Delta t} dt'\n$$\n$$\n\\ln(g(t+\\Delta t)) - \\ln(g_t) = -\\frac{\\Delta t}{\\tau_s}\n$$\n$$\n\\ln\\left(\\frac{g(t+\\Delta t)}{g_t}\\right) = -\\frac{\\Delta t}{\\tau_s}\n$$\n对两边取指数，得到更新的衰减部分：\n$$\ng(t+\\Delta t) = g_t e^{-\\Delta t/\\tau_s}\n$$\n问题陈述指出，在时间 $t$ 突触前脉冲到达时（由 $s_t=1$ 表示），会有一个大小为 $w$ 的脉冲式增量。这个增量被加到衰减后的电导上，以获得下一个时间步的值 $g_{t+1}$。因此，突触电导 $g_t$ 的完整离散时间更新方程是：\n$$\ng_{t+1} = g_t e^{-\\Delta t/\\tau_s} + w s_t\n$$\n\n### 任务 2：精确膜电位更新\n\n膜电位 $V(t)$ 由电流平衡方程控制：\n$$\nC \\frac{dV}{dt} = -g_L (V - E_L) - g(t)(V - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\n$$\n根据算子分裂法，我们假设突触电导 $g(t)$ 在区间 $[t, t+\\Delta t]$ 内保持其值 $g_t$ 不变。电压的 ODE 变为一个线性一阶方程：\n$$\nC \\frac{dV}{dt} = -g_L (V - E_L) - g_t(V - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\n$$\n我们重新排列各项，将 $V$ 的倍数归类：\n$$\nC \\frac{dV}{dt} = -g_L V + g_L E_L - g_t V + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}\n$$\n$$\nC \\frac{dV}{dt} = -(g_L + g_t)V + (g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}})\n$$\n让我们定义总有效电导 $G_{\\mathrm{tot}} = g_L + g_t$ 和总输入电流项 $I_{\\mathrm{eff}} = g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}$。方程简化为：\n$$\n\\frac{dV}{dt} = -\\frac{G_{\\mathrm{tot}}}{C}V + \\frac{I_{\\mathrm{eff}}}{C}\n$$\n这是一个形式为 $\\frac{dV}{dt} = aV+b$ 的标准线性 ODE。我们重写它以突出稳态电压 $V_{\\infty}$ 和有效时间常数 $\\tau_{\\mathrm{eff}}$：\n$$\n\\frac{dV}{dt} = -\\frac{g_L+g_t}{C} \\left( V - \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} \\right)\n$$\n这里，有效时间常数是 $\\tau_{\\mathrm{eff}} = \\frac{C}{g_L+g_t}$，稳态电压是 $V_{\\infty} = \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t}$。ODE 是 $\\frac{dV}{dt} = -\\frac{1}{\\tau_{\\mathrm{eff}}}(V - V_{\\infty})$。\n这个带有初始条件 $V(t) = V_t$ 的 ODE 的精确解是：\n$$\nV(t') = V_{\\infty} + (V_t - V_{\\infty}) e^{-(t'-t)/\\tau_{\\mathrm{eff}}}\n$$\n为了找到下一个时间步的电压，我们计算它在 $t' = t+\\Delta t$ 处的值：\n$$\nV_{t+1} = V_{\\infty} + (V_t - V_{\\infty}) e^{-\\Delta t/\\tau_{\\mathrm{eff}}}\n$$\n将 $V_{\\infty}$ 和 $\\tau_{\\mathrm{eff}}$ 的定义代回，我们得到电压的精确离散时间更新法则：\n$$\nV_{t+1} = \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} + \\left( V_t - \\frac{g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}}}{g_L+g_t} \\right) \\exp\\left(-\\frac{(g_L+g_t)\\Delta t}{C}\\right)\n$$\n此更新在 $g_L+g_t \\neq 0$ 的条件下有效。在问题中，$g_L  0$，所以这个条件总是满足的。\n\n### 任务 3：前向欧拉电压更新\n\n前向欧拉法使用离散更新 $y_{t+1} = y_t + \\Delta t \\cdot f(y_t, t)$ 来近似 ODE $\\frac{dy}{dt} = f(y,t)$ 的解。对于我们的电压方程，函数 $f(V_t, t)$ 是：\n$$\nf(V_t, t) = \\frac{dV}{dt}\\bigg|_{V=V_t} = \\frac{1}{C}\\left(-g_L(V_t - E_L) - g_t(V_t - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\\right)\n$$\n应用前向欧拉公式，我们得到：\n$$\nV_{t+1}^{\\mathrm{Euler}} = V_t + \\Delta t \\cdot \\frac{1}{C}\\left(-g_L(V_t - E_L) - g_t(V_t - E_{\\mathrm{rev}}) + I_{\\mathrm{ext}}\\right)\n$$\n这是膜电位的显式前向欧拉更新。\n\n### 任务 4：稳定性分析\n\n一个形式为 $x_{k+1} = A x_k + B$ 的离散时间线性映射是稳定的，如果小扰动会衰减，这要求乘子 $A$ 的大小严格小于 1，即 $|A|  1$。这样的映射被称为压缩映射。\n\n**精确更新的稳定性：**\n精确更新法则可以写成 $V_{t+1} = A_{\\mathrm{exact}}V_t + B_{\\mathrm{exact}}$ 的形式，其中乘子是：\n$$\nA_{\\mathrm{exact}} = \\exp\\left(-\\frac{(g_L+g_t)\\Delta t}{C}\\right)\n$$\n根据问题陈述和典型的物理约束，我们有 $C > 0$，$\\Delta t > 0$，$g_L > 0$ 和 $g_t \\ge 0$。因此，总电导 $g_L+g_t$ 严格为正。指数的参数 $-\\frac{(g_L+g_t)\\Delta t}{C}$ 总是一个有限的、严格的负数。对于任何严格为负的参数 $x  0$，其指数 $e^x$ 满足 $0  e^x  1$。因此，我们有：\n$$\n0  A_{\\mathrm{exact}}  1\n$$\n由于对于所有有效的参数集都有 $|A_{\\mathrm{exact}}|  1$，所以精确积分方案总是压缩的，因此是无条件稳定的。\n\n**前向欧拉更新的稳定性：**\n前向欧拉更新可以重排为 $V_{t+1}^{\\mathrm{Euler}} = A_{\\mathrm{Euler}}V_t + B_{\\mathrm{Euler}}$ 的形式。首先，我们分离出乘以 $V_t$ 的项：\n$$\nV_{t+1}^{\\mathrm{Euler}} = V_t - \\frac{\\Delta t}{C}(g_L+g_t)V_t + \\frac{\\Delta t}{C}(g_L E_L + g_t E_{\\mathrm{rev}} + I_{\\mathrm{ext}})\n$$\n乘子是：\n$$\nA_{\\mathrm{Euler}} = 1 - \\frac{(g_L+g_t)\\Delta t}{C}\n$$\n为了稳定性，我们需要 $|A_{\\mathrm{Euler}}|  1$，这可以转化为两个不等式：\n$$\n-1  1 - \\frac{(g_L+g_t)\\Delta t}{C} \\quad \\text{和} \\quad 1 - \\frac{(g_L+g_t)\\Delta t}{C}  1\n$$\n第二个不等式，$-\\frac{(g_L+g_t)\\Delta t}{C}  0$，总是成立的，因为 $g_L+g_t > 0$，$\\Delta t > 0$ 并且 $C>0$。\n第一个不等式得出了稳定性条件：\n$$\n-2  -\\frac{(g_L+g_t)\\Delta t}{C}\n$$\n$$\n2 > \\frac{(g_L+g_t)\\Delta t}{C}\n$$\n$$\n\\Delta t  \\frac{2C}{g_L+g_t}\n$$\n这是对于给定的 $C$、$g_L$ 和 $g_t$，前向欧拉方案稳定的时间步长 $\\Delta t$ 的条件。稳定性的 $\\Delta t$ 的显式上界是：\n$$\n\\Delta t_{\\max}^{\\mathrm{Euler}} = \\frac{2C}{g_L+g_t}\n$$\n如果 $\\Delta t  \\Delta t_{\\max}^{\\mathrm{Euler}}$，前向欧拉更新是稳定的。当 $\\Delta t = \\Delta t_{\\max}^{\\mathrm{Euler}}$ 时，乘子 $A_{\\mathrm{Euler}}$ 变为 -1，导致临界稳定（振荡），此时扰动不会衰减。\n\n### 任务 5：实现\n\n下面的程序实现了所推导的公式，用以计算每个测试用例所需的六个量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes dynamics and stability for a leaky integrate-and-fire neuron model.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Nominal excitatory input, stable Forward Euler\n        {\n            \"delta_t\": 1e-4, \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": 0.0, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 1, \"g_t\": 30e-9, \"V_t\": -7.0e-2\n        },\n        # Case B: Large synaptic conductance, Forward Euler unstable\n        {\n            \"delta_t\": 5e-4, \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": 0.0, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 0, \"g_t\": 2e-6, \"V_t\": -7.0e-2\n        },\n        # Case C: Boundary condition for Forward Euler stability\n        {\n            # delta_t is calculated from other params for this case\n            \"tau_s\": 5e-3, \"g_L\": 10e-9, \"C\": 200e-12,\n            \"E_L\": -6.5e-2, \"E_rev\": -8.0e-2, \"I_ext\": 0.0, \"w\": 5e-9,\n            \"s_t\": 0, \"g_t\": 0.0, \"V_t\": -6.5e-2\n        }\n    ]\n    # Special calculation for case C delta_t\n    test_cases[2][\"delta_t\"] = 2 * test_cases[2][\"C\"] / test_cases[2][\"g_L\"]\n\n    results = []\n    for params in test_cases:\n        delta_t = params[\"delta_t\"]\n        tau_s = params[\"tau_s\"]\n        g_L = params[\"g_L\"]\n        C = params[\"C\"]\n        E_L = params[\"E_L\"]\n        E_rev = params[\"E_rev\"]\n        I_ext = params[\"I_ext\"]\n        w = params[\"w\"]\n        s_t = params[\"s_t\"]\n        g_t = params[\"g_t\"]\n        V_t = params[\"V_t\"]\n\n        # 1. Synaptic conductance g_{t+1}\n        g_tp1 = g_t * np.exp(-delta_t / tau_s) + w * s_t\n\n        # 2. Exact voltage update V_{t+1}^{exact}\n        G_tot = g_L + g_t\n        if G_tot > 0:\n            V_inf = (g_L * E_L + g_t * E_rev + I_ext) / G_tot\n            tau_eff = C / G_tot\n            V_tp1_exact = V_inf + (V_t - V_inf) * np.exp(-delta_t / tau_eff)\n        else: # Should not happen with g_L > 0\n            V_tp1_exact = V_t + (I_ext / C) * delta_t\n\n        # 3. Forward Euler voltage update V_{t+1}^{Euler}\n        dVdt_term = -g_L * (V_t - E_L) - g_t * (V_t - E_rev) + I_ext\n        V_tp1_euler = V_t + (delta_t / C) * dVdt_term\n\n        # 4. Stability of exact update (s_exact)\n        # As derived, it is unconditionally stable for g_L > 0, C > 0, delta_t > 0\n        # The multiplier is strictly between 0 and 1, so it is contractive.\n        s_exact = True\n\n        # 5. Stability of Forward Euler update (s_Euler) and max step size\n        # Must compute dt_max first to determine s_Euler\n        if G_tot > 0:\n            dt_max_euler = 2 * C / G_tot\n        else: # Unconditionally stable\n            dt_max_euler = float('inf')\n        \n        # Stability requires strict inequality\n        s_euler = delta_t  dt_max_euler\n        \n        # The order for results is specified in the problem\n        results.append(g_tp1)\n        results.append(V_tp1_exact)\n        results.append(V_tp1_euler)\n        results.append(s_exact)\n        results.append(s_euler)\n        results.append(dt_max_euler)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "由于脉冲发放的非可微特性，训练脉冲神经网络（SNN）极具挑战性。本练习将介绍“直通估计器”（Straight-Through Estimator, STE），这是一种通过创建“代理梯度”来解决此问题的关键技术，从而使得基于梯度的学习方法（如反向传播）得以应用。通过分析STE对梯度在时间上传播的影响，您将理解尽管SNN具有不连续的动力学特性，我们依然能够有效地对其进行训练。",
            "id": "4056952",
            "problem": "考虑一个单神经元循环脉冲神经网络（SNN），其膜电位在离散时间下由以下泄露递推公式决定\n$$\nV_{t+1} = \\alpha V_t + w_r\\, s(V_t) + b,\n$$\n对于 $t = 0,1,\\dots,T-1$，初始电位为 $V_0$。其中 $s(V)$ 是由 Heaviside 阶跃函数 $H(\\cdot)$ 给出的二元脉冲函数，即 $s(V) = H(V - V_{th})$，其中 $V_{th}$ 是脉冲阈值。常数包括泄露因子 $\\alpha \\in (0,1)$、循环权重 $w_r \\in \\mathbb{R}$ 和偏置 $b \\in \\mathbb{R}$。我们考虑使用随时间反向传播（BPTT）来分析梯度消失问题。\n\n为脉冲函数的导数引入一个直通估计器（STE），使得\n$$\n\\frac{\\partial s}{\\partial V}(V) \\approx g(V) = \\begin{cases}\n1,  \\text{if } |V - V_{th}| \\le \\delta,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n窗口半宽为 $\\delta  0$。这个替代导数仅在膜电位处于阈值附近的一个小窗口内时才对可学习性进行建模。为了分析跨时间的梯度流，我们考虑在时间 $t$ 的雅可比因子\n$$\nJ_t = \\frac{\\partial V_{t+1}}{\\partial V_t}.\n$$\n仅使用基本原理，特别是微积分中的链式法则和递推定义，来构建一个显式的计算方法，用于计算随时间传播的梯度大小，\n$$\nG = \\left|\\frac{\\partial V_T}{\\partial V_0}\\right|.\n$$\n同时，计算在不使用替代梯度时（即 $\\partial s/\\partial V \\equiv 0$ 时）获得的基线大小 $G_0$。最后，报告比率\n$$\nR = \\frac{G}{G_0},\n$$\n该比率量化了 STE 在 $T$ 个时间步上对梯度消失的影响。\n\n您的程序必须：\n- 精确地按照规定实现 $V_t$ 的前向动力学。\n- 实现具有上述定义的指示窗的替代导数 $g(V)$。\n- 使用上述定义从基本原理计算 $J_t$，然后通过链式法则将跨时间的 $|J_t|$ 相乘来计算 $G$，并与无 STE 设置一致地计算 $G_0$。\n- 为每个测试用例返回比率 $R$。\n\n您不得引入任何超出规定范围的额外动力学（例如，硬重置或软重置项）。\n\n测试套件：\n提供以下五个参数集 $(T,\\alpha,w_r,b,V_{th},\\delta,V_0)$ 的结果：\n\n1. 具有阈值穿越和正循环反馈的一般情况（理想路径）：\n   - $T = 60$, $\\alpha = 0.9$, $w_r = 0.4$, $b = 0.12$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n2. 窗口未激活（STE 中性的边界情况）：\n   - $T = 60$, $\\alpha = 0.9$, $w_r = 0.4$, $b = 0.12$, $V_{th} = 1.0$, $\\delta = 0.0$, $V_0 = 0.0$。\n\n3. 具有大时间范围的强基线梯度消失（边缘情况）：\n   - $T = 100$, $\\alpha = 0.5$, $w_r = 0.8$, $b = 0.8$, $V_{th} = 1.0$, $\\delta = 0.02$, $V_0 = 0.0$。\n\n4. 负循环权重（不利影响情况）：\n   - $T = 80$, $\\alpha = 0.9$, $w_r = -0.7$, $b = 0.15$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n5. 无循环反馈（对照组）：\n   - $T = 120$, $\\alpha = 0.99$, $w_r = 0.0$, $b = 0.0105$, $V_{th} = 1.0$, $\\delta = 0.05$, $V_0 = 0.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔结果列表（例如，“[result1,result2,result3]”）。每个结果必须是相应测试用例的浮点数 $R$，顺序与上面列出的顺序相同。不应打印任何其他文本。",
            "solution": "经评估，用户提供的问题是有效的。它在科学上基于计算神经科学和机器学习的原理，问题提出得很好，具有清晰且唯一的可解结构，并且其数学表述是客观的。我们将提供完整的解决方案。\n\n该问题要求对直通估计器（STE）在单神经元循环脉冲神经网络（SNN）中对梯度传播的影响进行定量分析。分析的核心是计算使用 STE 时的梯度大小与不使用 STE 时的基线梯度大小之比 $R$。\n\n首先，我们将问题的各个组成部分形式化。神经元的膜电位 $V_t$ 根据以下离散时间递推关系演化：\n$$\nV_{t+1} = \\alpha V_t + w_r s(V_t) + b\n$$\n其中 $t \\in \\{0, 1, \\dots, T-1\\}$ 是时间步，$\\alpha \\in (0,1)$ 是泄露因子，$w_r$ 是循环突触权重，$b$ 是恒定偏置电流。脉冲行为由函数 $s(V_t)$ 控制，该函数使用 Heaviside 阶跃函数 $H(\\cdot)$ 定义如下：\n$$\ns(V_t) = H(V_t - V_{th}) = \\begin{cases}\n1,  \\text{if } V_t \\ge V_{th} \\\\\n0,  \\text{if } V_t  V_{th}\n\\end{cases}\n$$\n这里，$V_{th}$ 是固定的脉冲阈值。\n\n为了使用基于梯度的方法训练这样的网络，我们需要随时间反向传播梯度（BPTT）。我们感兴趣的量是最终状态 $V_T$ 相对于初始状态 $V_0$ 的梯度，即 $\\frac{\\partial V_T}{\\partial V_0}$。使用链式法则，该梯度表示为雅可比因子的乘积：\n$$\n\\frac{\\partial V_T}{\\partial V_0} = \\frac{\\partial V_T}{\\partial V_{T-1}} \\frac{\\partial V_{T-1}}{\\partial V_{T-2}} \\cdots \\frac{\\partial V_1}{\\partial V_0} = \\prod_{t=0}^{T-1} \\frac{\\partial V_{t+1}}{\\partial V_t}\n$$\n我们将时间 $t$ 的雅可比因子定义为 $J_t = \\frac{\\partial V_{t+1}}{\\partial V_t}$。我们可以通过对递推关系关于 $V_t$ 求导来计算它：\n$$\nJ_t = \\frac{\\partial}{\\partial V_t} (\\alpha V_t + w_r s(V_t) + b) = \\alpha + w_r \\frac{\\partial s(V_t)}{\\partial V_t}\n$$\nHeaviside 阶跃函数的导数 $\\frac{\\partial s(V_t)}{\\partial V_t}$ 在除了阈值之外的所有地方都为零，而在阈值处未定义（在数学上是一个狄拉克δ函数）。在实际的 BPTT 实现中，这个导数被视为零，这会阻碍学习。直通估计器（STE）是一种通过用替代函数替换导数来克服此问题的技术。问题指定了以下替代导数 $g(V)$：\n$$\ng(V) = \\frac{\\partial s}{\\partial V}(V) \\approx \\begin{cases}\n1,  \\text{if } |V - V_{th}| \\le \\delta \\\\\n0,  \\text{otherwise}\n\\end{cases}\n$$\n其中 $\\delta > 0$ 定义了围绕阈值 $V_{th}$ 的一个小窗口。用 $g(V_t)$ 替换 $\\frac{\\partial s(V_t)}{\\partial V_t}$，雅可比因子变为：\n$$\nJ_t = \\alpha + w_r g(V_t)\n$$\n通过 $T$ 个时间步传播的总梯度大小（我们表示为 $G$）是这些雅可比因子乘积的绝对值：\n$$\nG = \\left| \\prod_{t=0}^{T-1} J_t \\right| = \\prod_{t=0}^{T-1} |J_t| = \\prod_{t=0}^{T-1} |\\alpha + w_r g(V_t)|\n$$\n为了计算 $G$，我们必须首先执行一次前向传播，以模拟 $V_t$ 在 $t \\in [0, T]$ 上的轨迹。然后，对于每个时间步 $t \\in [0, T-1]$，我们计算 $g(V_t)$ 并计算乘积中的相应项。\n\n接下来，我们必须计算基线梯度大小 $G_0$。这被定义为不使用替代梯度的情况，明确表述为 $\\frac{\\partial s}{\\partial V} \\equiv 0$。这意味着对于基线情况，对所有 $t$ 都有 $g(V_t) = 0$。雅可比因子 $J_{0,t}$ 简化为：\n$$\nJ_{0,t} = \\alpha + w_r \\cdot 0 = \\alpha\n$$\n那么，基线梯度大小 $G_0$ 为：\n$$\nG_0 = \\prod_{t=0}^{T-1} |\\alpha| = |\\alpha|^T\n$$\n由于问题陈述 $\\alpha \\in (0,1)$，我们有 $G_0 = \\alpha^T$。该项随 $T$ 指数衰减，代表了循环网络中典型的梯度消失问题。\n\n最后，问题要求计算比率 $R = \\frac{G}{G_0}$，它量化了 STE 对梯度流的影响：\n$$\nR = \\frac{\\prod_{t=0}^{T-1} |\\alpha + w_r g(V_t)|}{\\alpha^T}\n$$\n这个比率衡量了与基线衰减相比，STE 对梯度流是放大（$|J_t| > \\alpha$）还是衰减（$|J_t|  \\alpha$）了多少倍。计算过程如下：\n1.  对于给定的参数集 $(T, \\alpha, w_r, b, V_{th}, \\delta, V_0)$，模拟神经元从 $t=0$ 到 $T-1$ 的动力学，以获得完整的膜电位轨迹 $\\{V_0, V_1, \\dots, V_T\\}$。\n2.  通过从 $t=0$ 到 $T-1$ 迭代计算 $G$，在每个步骤中计算 $g(V_t)$，计算 $J_t = \\alpha + w_r g(V_t)$，并将累积乘积乘以 $|J_t|$。\n3.  计算 $G_0 = \\alpha^T$。\n4.  计算比率 $R = G / G_0$。\n对每个提供的测试用例都执行此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ratio of gradient magnitudes for a single-neuron SNN\n    with and without a Straight-Through Estimator (STE).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, alpha, w_r, b, V_th, delta, V_0)\n        (60, 0.9, 0.4, 0.12, 1.0, 0.05, 0.0),      # Case 1: General case\n        (60, 0.9, 0.4, 0.12, 1.0, 0.0, 0.0),       # Case 2: Window deactivated\n        (100, 0.5, 0.8, 0.8, 1.0, 0.02, 0.0),     # Case 3: Strong vanishing baseline\n        (80, 0.9, -0.7, 0.15, 1.0, 0.05, 0.0),     # Case 4: Negative recurrent weight\n        (120, 0.99, 0.0, 0.0105, 1.0, 0.05, 0.0)  # Case 5: No recurrent feedback\n    ]\n\n    results = []\n    for case in test_cases:\n        T, alpha, w_r, b, V_th, delta, V_0 = case\n\n        # Step 1: Forward pass to compute the membrane potential trajectory V_t.\n        # V is a numpy array of size T+1 to store V_0 to V_T.\n        V = np.zeros(T + 1)\n        V[0] = V_0\n\n        for t in range(T):\n            # The spike function s(V) is the Heaviside step function H(V - V_th).\n            # H(x) is 1 if x >= 0, and 0 otherwise.\n            spike = 1.0 if V[t] >= V_th else 0.0\n            \n            # Apply the leaky recurrence relation.\n            V[t+1] = alpha * V[t] + w_r * spike + b\n\n        # Step 2: Compute G, the gradient magnitude with the STE.\n        # This requires a \"backward\" pass over the V trajectory.\n        G = 1.0\n        for t in range(T):\n            # The surrogate derivative g(V).\n            # g(V) is 1 if |V - V_th| = delta, and 0 otherwise.\n            surrogate_grad = 1.0 if np.abs(V[t] - V_th) = delta else 0.0\n\n            # The Jacobian factor J_t.\n            J_t = alpha + w_r * surrogate_grad\n\n            # The total gradient magnitude is the product of the absolute values.\n            G *= np.abs(J_t)\n\n        # Step 3: Compute G_0, the baseline gradient magnitude.\n        # This corresponds to the case where the derivative of s(V) is always zero.\n        # G_0 = alpha^T.\n        G_0 = alpha ** T\n\n        # Step 4: Compute the ratio R = G / G_0.\n        # We check for G_0 being zero, although alpha in (0,1) prevents this.\n        if G_0 == 0.0:\n            # This case is not expected with the problem constraints.\n            R = float('inf') if G > 0 else 1.0\n        else:\n            R = G / G_0\n\n        results.append(R)\n\n    # Final print statement in the exact required format.\n    # We format the floats to ensure consistent and clean output.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了单个神经元的仿真与学习后，我们将视野扩展到网络层面的计算。本练习将使用一个由循环连接的脉冲神经元构成的“储备池”网络，来研究网络结构（特别是连接密度）如何影响其对不同输入信号产生可分离表征的能力。这项实践揭示了储备池计算的一个核心原理，并展示了复杂的计算功能是如何从网络动力学特性中涌现的。",
            "id": "4056967",
            "problem": "考虑一个使用漏积分放电 (LIF) 神经元建模的循环脉冲神经网络 (SNN) 储备池。目标是分析循环储备池中的连接稀疏度如何影响输入诱发的状态轨迹的可分性。可分性将通过对应于不同输入刺激的轨迹向量之间的两两欧几里得距离来量化。该分析必须比较在不同连接密度下这些两两之间的距离。\n\n基本原理：\n- 定义 LIF 神经元的膜电位动态由以下微分方程描述：$$\\tau_m \\frac{dV_i(t)}{dt} = -\\left(V_i(t) - V_{\\text{rest}}\\right) + R_m I_i(t),$$ 其中 $V_i(t)$ 是神经元 $i$ 的膜电位，$I_i(t)$ 是流入神经元 $i$ 的总突触电流，$\\tau_m$ 是膜时间常数，$R_m$ 是膜电阻，$V_{\\text{rest}}$ 是静息电位。当 $V_i(t)$ 超过阈值 $V_{\\text{thr}}$ 时，会发出一个脉冲，之后 $V_i(t)$ 被设置为 $V_{\\text{reset}}$ 并在不应期内保持该值。\n- 使用指数衰减的突触后电流 (PSC) 对突触电流进行建模：$$\\tau_s \\frac{dI_i(t)}{dt} = -I_i(t) + \\sum_{j=1}^{N} W_{ij} s_j(t) + w_{\\text{in}} x_i(t),$$ 其中 $\\tau_s$ 是突触时间常数，$W_{ij}$ 是从神经元 $j$ 到神经元 $i$ 的循环权重，$s_j(t)$ 是神经元 $j$ 的脉冲序列，$x_i(t)$ 是到神经元 $i$ 的外部输入脉冲序列，$w_{\\text{in}}$ 是前馈输入权重。外部输入脉冲序列 $x_i(t)$ 由具有指定速率（单位为赫兹）的独立泊松过程生成。\n- 为构建一个能捕捉动态的轨迹表示，定义一个滤波后的脉冲状态：$$\\tau_f \\frac{dy_i(t)}{dt} = -y_i(t) + s_i(t),$$ 其中 $y_i(t)$ 是神经元 $i$ 的低通滤波脉冲序列，$\\tau_f$ 是滤波时间常数。一个输入刺激的储备池轨迹向量是 $y_i(t)$ 在所有神经元和时间步上的展平结果。\n\n储备池构建与连接稀疏度：\n- 储备池有 $N$ 个 LIF 神经元。根据 Dale 法则，每个突触前神经元 $j$ 要么是兴奋性的，要么是抑制性的，其符号是固定的。循环连接是随机的，连接密度为 $d \\in [0,1]$，它定义了对于 $i \\neq j$，连接 $W_{ij}$ 存在的概率。存在的连接的量值为正，从指数分布中抽取，然后由突触前神经元的类型赋予符号。禁止自连接，即 $W_{ii} = 0$。\n- 为了使不同密度 $d$ 之间的比较有意义，当 $d  0$ 时，将权重大小按与 $\\sqrt{N d}$ 成反比的因子进行缩放，这样当 $d$ 变化时，总传入方差能保持近似受控。\n\n离散时间模拟：\n- 使用步长为 $\\Delta t$ 的时间离散化。膜电位和电流的更新通过欧拉积分进行。脉冲状态 $s_i(t)$ 在每个时间步是二元的（$0$ 或 $1$）。外部输入脉冲序列 $x_i(t)$ 对每个神经元使用伯努利过程独立生成，成功概率为 $p = r \\Delta t$，其中 $r$ 是以赫兹为单位的输入速率，$\\Delta t$ 的单位是秒。\n\n轨迹可分性：\n- 对于每个连接密度 $d$，使用具有不同泊松速率的多个输入刺激来模拟储备池。对于每个刺激，通过将所有神经元和时间步上的滤波后脉冲状态 $y_i(t)$ 展平来获得轨迹向量。计算对应于不同刺激的轨迹向量之间的两两欧几里得距离。密度 $d$ 的可分性得分定义为这些两两之间距离的平均值。\n\n物理单位和数值：\n- 时间 $\\Delta t$ 为 $1$ 毫秒（$\\Delta t = 1$ ms），总模拟时长为 $T = 500$ 毫秒（$T = 500$ ms）。电位单位为毫伏（mV），但输出关注的是轨迹向量之间无量纲的距离。\n- 膜参数：$\\tau_m = 20$ ms，$V_{\\text{rest}} = -65$ mV，$V_{\\text{thr}} = -50$ mV，$V_{\\text{reset}} = -65$ mV，不应期 $= 2$ ms，$R_m = 1$（无量纲尺度）。\n- 突触和滤波参数：$\\tau_s = 5$ ms，$\\tau_f = 20$ ms，$w_{\\text{in}} = 1.0$（无量纲尺度）。\n- 储备池大小：$N = 100$，兴奋性神经元比例 $p_{\\text{exc}} = 0.8$，因此抑制性神经元数量为 $N_{\\text{inh}} = N (1 - p_{\\text{exc}})$。\n- 指数分布的权重量值基本尺度：$b = 0.2$（无量纲），当 $d > 0$ 时按 $1/\\sqrt{N d}$ 缩放；当 $d = 0$ 时，设 $W_{ij} = 0$。\n\n输入刺激：\n- 使用输入速率 $r \\in \\{5, 20, 50, 80\\}$ 赫兹。\n\n测试套件：\n- 待测试的连接密度 $d$：$\\{0.0, 0.05, 0.2, 0.5, 1.0\\}$。\n- 对于上述集合中的每个 $d$，使用 $\\{5, 20, 50, 80\\}$ 赫兹中的所有输入速率模拟储备池，并计算所有不同刺激对之间的平均两两欧几里得距离。\n\n算法任务：\n- 实现上述离散时间 LIF 储备池动态和轨迹处理。\n- 对于测试套件中的每个 $d$，输出可分性得分，该得分是一个浮点数：四个刺激的轨迹向量之间的平均两两欧几里得距离。\n- 必须通过固定的随机种子来控制随机性，以使结果是确定性的。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含按指定顺序排列的连接密度的可分性得分，格式为逗号分隔的列表并用方括号括起，例如，$$[s_{d_1}, s_{d_2}, \\dots, s_{d_5}]$$ 其中每个 $s_{d_k}$ 是测试套件中第 $k$ 个密度的平均两两距离。",
            "solution": "该问题要求分析循环脉冲神经网络 (SNN) 储备池的连接稀疏度如何影响其对不同输入刺激响应的可分性。该 SNN 由漏积分放电 (LIF) 神经元组成。分析将通过在各种连接密度下模拟网络动态并量化所得状态空间轨迹的可分性来执行。\n\n首先，我们基于所提供的连续时间微分方程来形式化离散时间模拟模型。模拟以大小为 $\\Delta t = 1$ ms 的离散时间步进行。我们按照指定使用前向欧拉方法进行积分。\n\n神经元 $i$ 在时间步 $t+1$ 的膜电位 $V_i$ 基于其在时间步 $t$ 的值和突触电流 $I_i$ 进行更新。给定的方程为 $\\tau_m \\frac{dV_i}{dt} = -(V_i - V_{\\text{rest}}) + R_m I_i$。当 $R_m=1$ 时，其离散形式为：\n$$V_i[t+1] = V_i[t] + \\frac{\\Delta t}{\\tau_m} \\left( -(V_i[t] - V_{\\text{rest}}) + I_i[t] \\right)$$\n可以重新整理为：\n$$V_i[t+1] = V_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_m}\\right) + \\frac{\\Delta t}{\\tau_m} \\left( V_{\\text{rest}} + I_i[t] \\right)$$\n\n突触电流 $I_i$ 由储备池内部的循环脉冲和外部输入脉冲驱动。控制方程为 $\\tau_s \\frac{dI_i}{dt} = -I_i + \\sum_{j=1}^{N} W_{ij} s_j(t) + w_{\\text{in}} x_i(t)$。其欧拉离散化为：\n$$I_i[t+1] = I_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_s}\\right) + \\frac{\\Delta t}{\\tau_s} \\left( \\sum_{j=1}^{N} W_{ij} s_j[t] + w_{\\text{in}} x_i[t] \\right)$$\n这里，$s_j[t]$ 是一个二元变量，如果神经元 $j$ 在时间步 $t$ 发放脉冲，则为 $1$，否则为 $0$。同样，$x_i[t]$ 是在时间步 $t$ 到神经元 $i$ 的二元外部输入脉冲。\n\n如果神经元 $i$ 在时间步 $t$ 的膜电位 $V_i[t]$ 超过阈值 $V_{\\text{thr}}$，它就会发放一个脉冲。发放脉冲后，其电位被重置为 $V_{\\text{reset}}$，并且神经元进入一个为期 $2$ ms（$2$ 个时间步）的不应期，在此期间其电位被钳制在 $V_{\\text{reset}}$。\n\n状态空间轨迹由脉冲序列的低通滤波版本 $y_i(t)$ 构建。动态 $\\tau_f \\frac{dy_i}{dt} = -y_i + s_i(t)$ 被离散化为：\n$$y_i[t+1] = y_i[t] \\left(1 - \\frac{\\Delta t}{\\tau_f}\\right) + \\frac{\\Delta t}{\\tau_f} s_i[t]$$\n\n算法流程如下：\n\n1.  **初始化**：我们设置一个全局随机种子以确保可复现性。所有时间常数（$\\tau_m$, $\\tau_s$, $\\tau_f$）都转换为时间步数（例如，$\\tau_m / \\Delta t = 20 \\text{ ms} / 1 \\text{ ms} = 20$）。为四种不同的速率 $r \\in \\{5, 20, 50, 80\\}$ Hz 预先生成四个不同的外部输入脉冲序列。每个序列是一个 $N \\times T$ 矩阵，其中每个条目是成功概率为 $p = r \\Delta t$ 的独立伯努利试验的结果。预先生成这些输入可确保在每种连接密度下都使用同一组刺激来测试储备池，从而提供受控的比较。\n\n2.  **储备池构建**：对于每种连接密度 $d \\in \\{0.0, 0.05, 0.2, 0.5, 1.0\\}$，我们构建一个相应的 $N \\times N$ 大小的循环权重矩阵 $W$，其中 $N=100$。\n    -   分配神经元类型：$80\\%$ 兴奋性（$N_{\\text{exc}}=80$）和 $20\\%$ 抑制性（$N_{\\text{inh}}=20$）。\n    -   从神经元 $j$ 到 $i$ 的连接以概率 $d$ 存在。禁止自连接（$W_{ii}$）。\n    -   如果 $d>0$，现有权重的大小从尺度参数为 $b=0.2$ 的指数分布中抽取。\n    -   权重 $W_{ij}$ 的符号由突触前神经元 $j$ 决定：如果 $j$ 是兴奋性的，则为正；如果是抑制性的，则为负（Dale 法则）。\n    -   为了在不同密度下保持网络稳定性，权重大小按 $1 / \\sqrt{Nd}$ 进行缩放。对于 $d=0$，所有权重 $W_{ij}$ 都设置为 $0$。\n\n3.  **网络模拟**：对于给定的密度 $d$ 及其关联的权重矩阵 $W$，模拟 SNN 对四个预先生成的输入刺激中每一个的响应，模拟时长为 $T=500$ ms（$500$ 步）。\n    -   在每个时间步 $t$，模拟按因果关系进行：\n        a.  基于电流 $I_i[t]$ 更新非不应期神经元的电位 $V_i[t]$。\n        b.  电位超过 $V_{\\text{thr}}$ 的神经元被标记为发放脉冲，其脉冲变量 $s_i[t]$ 设置为 $1$。\n        c.  发放脉冲的神经元的电位被重置为 $V_{\\text{reset}}$，并启动其不应期计数器。\n        d.  使用脉冲向量 $s[t]$ 和外部输入向量 $x[t]$ 更新突触电流 $I_i[t+1]$ 和滤波状态 $y_i[t+1]$。\n    -   存储所有神经元和所有时间步的滤波状态向量 $y_i[t]$ 的历史记录。\n\n4.  **可分性计算**：在为固定密度 $d$ 模拟了所有四个输入速率的网络后，我们得到四个轨迹矩阵。每个矩阵被展平为一个大小为 $N \\times T = 100 \\times 500 = 50000$ 的单个向量。\n    -   这四个轨迹向量的可分性通过它们之间的两两欧几里得距离来量化。共有 $\\binom{4}{2}=6$ 个唯一的配对。\n    -   密度 $d$ 的可分性得分是这六个欧几里得距离的算术平均值。\n\n对测试套件中的每个密度重复此过程。最终输出是可分性得分的列表，每个密度对应一个得分。",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Solves the recurrent SNN trajectory separability problem.\n    \"\"\"\n    # Use a fixed seed for reproducibility as required.\n    SEED = 0\n    rng = np.random.default_rng(SEED)\n\n    # Physical units and numerical values\n    DT_MS = 1.0\n    T_MS = 500.0\n    TAU_M_MS = 20.0\n    V_REST = -65.0\n    V_THR = -50.0\n    V_RESET = -65.0\n    REFRACTORY_PERIOD_MS = 2.0\n    R_M = 1.0  # Assumed dimensionless as per problem, folded into I\n    TAU_S_MS = 5.0\n    TAU_F_MS = 20.0\n    W_IN = 1.0\n    N = 100\n    P_EXC = 0.8\n    N_EXC = int(N * P_EXC)\n    WEIGHT_SCALE_BASE = 0.2\n\n    # Simulation parameters in terms of time steps\n    T_STEPS = int(T_MS / DT_MS)\n    REFRACTORY_STEPS = int(REFRACTORY_PERIOD_MS / DT_MS)\n    \n    # Pre-calculated Euler update coefficients\n    ALPHA_M = DT_MS / TAU_M_MS\n    ALPHA_S = DT_MS / TAU_S_MS\n    ALPHA_F = DT_MS / TAU_F_MS\n\n    # Test suite\n    densities_to_test = [0.0, 0.05, 0.2, 0.5, 1.0]\n    input_rates_hz = [5.0, 20.0, 50.0, 80.0]\n\n    # Pre-generate input spike trains for all stimuli to ensure fair comparison across densities\n    input_trains = []\n    dt_s = DT_MS / 1000.0\n    for r in input_rates_hz:\n        p = r * dt_s\n        train = rng.binomial(1, p, size=(T_STEPS, N)).astype(np.float64)\n        input_trains.append(train)\n\n    # Define neuron types for Dale's Law\n    neuron_signs = np.ones(N, dtype=np.float64)\n    neuron_signs[N_EXC:] = -1.0\n\n    separability_scores = []\n\n    for d in densities_to_test:\n        # 1. Reservoir construction\n        W = np.zeros((N, N), dtype=np.float64)\n        if d > 0:\n            # Create connectivity mask\n            mask = rng.random(size=(N, N))  d\n            np.fill_diagonal(mask, False)\n            \n            # Generate weights from exponential distribution\n            W_mag = rng.exponential(scale=WEIGHT_SCALE_BASE, size=(N, N))\n            \n            # Apply Dale's law and scaling\n            scaling_factor = 1.0 / np.sqrt(N * d)\n            W = mask * W_mag * scaling_factor * neuron_signs.reshape(1, -1)\n\n        trajectories = []\n        for x_train in input_trains:\n            # 2. Simulation for one stimulus\n            v = np.full(N, V_REST, dtype=np.float64)\n            i_syn = np.zeros(N, dtype=np.float64)\n            y_filtered = np.zeros(N, dtype=np.float64)\n            ref_counters = np.zeros(N, dtype=np.int32)\n            \n            y_history = np.zeros((T_STEPS, N), dtype=np.float64)\n\n            for t in range(T_STEPS):\n                is_refractory = ref_counters > 0\n                \n                # Update membrane potential for non-refractory neurons\n                dv = ALPHA_M * (-(v - V_REST) + R_M * i_syn)\n                v[~is_refractory] += dv[~is_refractory]\n                \n                # Decrement refractory counters and clamp potential\n                v[is_refractory] = V_RESET\n                ref_counters[is_refractory] -= 1\n\n                # Detect spikes\n                spiked = (v >= V_THR)  (~is_refractory)\n                s_t = spiked.astype(np.float64)\n                \n                # Reset potential and set refractory period for spiking neurons\n                v[spiked] = V_RESET\n                ref_counters[spiked] = REFRACTORY_STEPS\n                \n                # Update synaptic current\n                recurrent_input = W @ s_t\n                external_input = W_IN * x_train[t, :]\n                total_input = recurrent_input + external_input\n                di_syn = ALPHA_S * (-i_syn + total_input)\n                i_syn += di_syn\n                \n                # Update filtered spike state\n                dy_filtered = ALPHA_F * (-y_filtered + s_t)\n                y_filtered += dy_filtered\n                \n                y_history[t, :] = y_filtered\n\n            # Flatten trajectory and store\n            trajectories.append(y_history.flatten())\n\n        # 3. Trajectory separability calculation for the current density\n        if len(trajectories) > 1:\n            distances = pdist(np.array(trajectories), 'euclidean')\n            mean_distance = np.mean(distances)\n        else:\n            mean_distance = 0.0 # Should not happen with >1 stimuli rates\n            \n        separability_scores.append(mean_distance)\n\n    # Final output format\n    print(f\"[{','.join(map(str, separability_scores))}]\")\n\nsolve()\n```"
        }
    ]
}