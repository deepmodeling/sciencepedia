{
    "hands_on_practices": [
        {
            "introduction": "要理解神经拟态系统的性能，我们必须从其基本操作开始。本练习将指导您从第一性原理出发，推导和计算由离散的、事件驱动的突触操作产生的动态能耗。通过将单个突触事件的能量成本与总事件数联系起来，您将深入了解硬件的微观特性（例如，网络连接性，如扇入和扇出）如何直接影响宏观基准指标（例如，总能量和延迟）。这种“自下而上”的方法对于模型设计者和硬件架构师在优化神经拟态系统以实现更高效率时至关重要。",
            "id": "4036973",
            "problem": "一个神经拟态加速器使用事件驱动的突触操作来执行脉冲神经网络 (SNN) 的推理。考虑以下测量设置和假设：\n\n- 每个突触事件产生的动态开关能耗为 $E_{\\text{syn}} = 10\\,\\text{pJ/event}$，该值是在标称电压和温度下通过片上测量确定的。\n- 在一个代表性数据集上，每次推理的平均突触活动为 $5 \\times 10^{6}$ 个事件，该值是在网络收敛后，并使用与精度基准测试相同的输入分布测量得出的。\n- 您可以忽略泄漏（静态）能量、神经元更新能量和通信开销；只考虑由突触事件产生的动态突触能量。\n\n仅从每个离散开关事件的能量和事件计数的概念等基本定义出发，推导每次推理的动态突触能量的表达式，并计算其值。用科学记数法表示最终能量，单位为焦耳，并将答案四舍五入到三位有效数字。\n\n然后，从第一性原理出发，论证在固定的脉冲统计数据下，神经元的扇入和扇出如何决定突触事件计数，以及在保持功能准确性不变的情况下，这如何影响能量和延迟指标。您的讨论应基于定义（例如，事件作为边沿触发的突触操作）和资源约束（例如，持续的突触处理速率），不得引用任何未提供的简化公式。",
            "solution": "该问题被验证为具有科学依据、提法明确且客观。所有必要的数据均已提供，任务是进行计算并基于第一性原理提供概念性论证，这是一个有效的科学问题。所提出的模型是对事件驱动的神经拟态硬件中能耗的标准、简化但物理上合理的表示。\n\n**第1部分：动态突触能量的推导与计算**\n\n问题要求计算每次推理的动态突触能量。规定该能量完全由离散的突触事件产生。计算一组离散、独立过程总能量的基本原理是叠加原理。总能量是每个独立过程能量的总和。\n\n设 $E_{\\text{total}}$ 为每次推理的总动态突触能量。\n设 $N_{\\text{events}}$ 为每次推理的突触事件总数。\n设 $E_{\\text{event}}$ 为单个突触事件所消耗的能量。\n\n假设每个突触事件的能耗相同，则总能量是事件数量与每个事件能量的乘积。\n$$E_{\\text{total}} = N_{\\text{events}} \\times E_{\\text{event}}$$\n\n根据问题陈述，我们已知：\n每次推理的平均突触活动，即事件数量：\n$$N_{\\text{events}} = 5 \\times 10^{6} \\text{ events}$$\n每个突触事件的动态开关能耗：\n$$E_{\\text{event}} = E_{\\text{syn}} = 10 \\text{ pJ/event}$$\n\n我们必须首先将每个事件的能量转换为国际单位制（SI）的基本单位焦耳（$J$）。前缀 'pico' (p) 对应于因子 $10^{-12}$。\n$$E_{\\text{syn}} = 10 \\times 10^{-12} \\frac{\\text{J}}{\\text{event}}$$\n\n现在，我们可以将给定值代入我们推导出的总能量表达式中：\n$$E_{\\text{total}} = (5 \\times 10^{6} \\text{ events}) \\times \\left(10 \\times 10^{-12} \\frac{\\text{J}}{\\text{event}}\\right)$$\n\n进行乘法运算：\n$$E_{\\text{total}} = (5 \\times 10) \\times (10^{6} \\times 10^{-12}) \\text{ J}$$\n$$E_{\\text{total}} = 50 \\times 10^{-6} \\text{ J}$$\n\n为了用标准科学记数法（$a \\times 10^b$，其中 $1 \\le |a|  10$）表示，我们调整尾数和指数：\n$$E_{\\text{total}} = 5.0 \\times 10^{1} \\times 10^{-6} \\text{ J}$$\n$$E_{\\text{total}} = 5.0 \\times 10^{-5} \\text{ J}$$\n\n问题要求答案四舍五入到三位有效数字。\n$$E_{\\text{total}} = 5.00 \\times 10^{-5} \\text{ J}$$\n\n**第2部分：扇入和扇出作用的论证**\n\n我们被要求从第一性原理出发，论证在保持准确性不变的情况下，神经元的扇入和扇出如何影响突触事件计数，并因此影响能量和延迟。\n\n**第一性原理与定义：**\n1.  **脉冲神经网络 (SNN)** 由通过突触连接的神经元组成。\n2.  **脉冲** 是时间上的一个离散事件，代表来自突触前神经元的信号。\n3.  **突触事件** 是由突触前脉冲到达突触时触发的基本操作。此操作涉及检索突触权重并更新突触后神经元的状态。在一次推理过程中，此类事件的总数我们记为突触事件计数 $S$。\n4.  神经元的**扇出** ($N_{\\text{out}}$) 是指它投射到的突触后神经元的数量。它代表由这一个神经元发出的突触数量。\n5.  神经元的**扇入** ($N_{\\text{in}}$) 是指投射到它的突触前神经元的数量。它代表以这一个神经元为目标的突触数量。\n\n**扇出与突触事件计数 ($S$) 的关系：**\n考虑一个索引为 $i$ 的突触前神经元。当神经元 $i$ 产生一个脉冲时，该脉冲会传播到其所有下游目标。根据定义，这些目标的数量就是其扇出 $N_{\\text{out},i}$。因此，来自神经元 $i$ 的一个脉冲会精确地产生 $N_{\\text{out},i}$ 个突触事件。\n\n设 $k_i$ 为在单次推理中神经元 $i$ 发放脉冲的次数。由神经元 $i$ 产生的突触事件总数是 $k_i \\times N_{\\text{out},i}$ 的乘积。\n整个网络的总突触事件计数 $S$ 是网络中所有神经元产生的事件之和：\n$$S = \\sum_{i \\in \\text{neurons}} k_i \\cdot N_{\\text{out},i}$$\n\n问题陈述我们必须考虑“固定的脉冲统计数据”。这是一个关键约束，意味着在所比较的网络中，放电模式以及因此的值集 $\\{k_i\\}$ 保持不变。在此假设下，该方程表明 $S$ 是所有神经元扇出的加权和。如果平均扇出 $\\bar{N}_{\\text{out}}$ 增加，假设脉冲计数的分布保持不变，总突触事件计数 $S$ 将成比例增加。同样的逻辑也适用于扇入，因为网络中所有扇入的总和等于所有扇出的总和（即 $\\sum N_{\\text{in},j} = \\sum N_{\\text{out},i}$），两者都等于突触的总数。因此，对于固定数量的神经元和固定的脉冲统计数据，总突触事件计数 $S$ 与平均网络连接度成正比，而网络连接度由扇入和扇出表征。\n\n**对能量的影响：**\n如第1部分所述，总动态突触能量 ($E_{\\text{total}}$) 与总突触事件计数 ($S$) 成正比：\n$$E_{\\text{total}} = S \\times E_{\\text{syn}}$$\n由于我们已经证明 $S$ 与平均扇入/扇出成正比（在给定约束下），因此可以直接得出总能量也与平均扇入/扇出成正比。连接度更高的网络对于相同数量的神经活动需要更多的突触操作，因此消耗更多的动态能量。\n\n**对延迟的影响：**\n延迟 ($T_{\\text{latency}}$) 是完成推理任务所需的时间。神经拟态加速器处理突触事件的能力是有限的，由其最大持续突触处理速率 $R_{\\text{syn}}$ 定义，单位为每秒突触事件数 (SEPS)。这个速率是一个硬件资源约束。\n因此，处理总共 $S$ 个突触事件所需的最短时间受此速率的限制：\n$$T_{\\text{latency}} \\ge \\frac{S}{R_{\\text{syn}}}$$\n这个下限代表了计算延迟。由于 $S$ 与平均扇入/扇出成正比，因此最小延迟也与平均扇入/扇出成正比：\n$$T_{\\text{latency}} \\propto S \\propto \\text{average fan-in/fan-out}$$\n因此，增加网络连接度（扇入/扇出）会增加总计算工作量 ($S$)，对于具有固定吞吐量 ($R_{\\text{syn}}$) 的处理器而言，这会导致更长的处理时间，即更高的延迟。\n\n**恒定准确性的约束：**\n“在保持功能准确性不变的情况下”这个条件并非微不足道。扇入和扇出是网络拓扑的基本属性。改变它们会改变模型。为了保持准确性，具有不同连接度的网络可能需要重新训练，这反过来又可能改变学习到的脉冲统计数据 $\\{k_i\\}$。因此，“固定的脉冲统计数据”的假设是一个强烈的理想化，用于分离连接度对工作负载的直接影响。在这种理想化情景中，两个具有不同连接度的网络可以通过相同的放电模式达到相同的准确性，那么扇入/扇出较高的网络将固有地具有更高的突触事件计数，从而导致更大的能耗和延迟。",
            "answer": "$$\\boxed{5.00 \\times 10^{-5}}$$"
        },
        {
            "introduction": "在神经拟态计算中，性能评估很少是单一维度的。我们经常面临在速度（低延迟）和能效（低能耗）之间的权衡。本练习将您置于系统评估者的角色，任务是比较多个硬件-软件配置。您将应用一个标准的复合指标——能量延迟乘积（$EDP$），来量化这种权衡，并确定在综合考虑能耗和速度的情况下最优的配置。这个实践过程突出了在复杂的设计空间中做出明智决策的重要性，在这种情况下，没有任何单一指标能完全说明问题。",
            "id": "4036901",
            "problem": "一个神经形态脉冲分类器在五种硬件-软件配置下进行评估，索引为 $i=1,2,3,4,5$。对于每种配置 $i$，在同一测试集上测量了单次推理能耗 $E_i$（单位：焦耳）、单次推理延迟 $L_i$（单位：秒）和 top-$1$ 分类准确率 $A_i$（以小数表示）。在神经形态和类脑计算中，标准的基准测试实践使用结合了能耗和延迟的复合指标来捕捉能耗-时间权衡。使用能量-延迟乘积（EDP）的标准定义，从第一性原理出发为每种配置计算 EDP，并确定使 EDP 最小化的配置索引 $i$。然后，报告该配置对应的准确率 $A_i$。\n\n测量值如下：\n- 配置 $1$：$E_1=3.2\\times10^{-5}$，$L_1=8.0\\times10^{-3}$，$A_1=0.926$。\n- 配置 $2$：$E_2=2.5\\times10^{-5}$，$L_2=1.2\\times10^{-2}$，$A_2=0.913$。\n- 配置 $3$：$E_3=1.8\\times10^{-5}$，$L_3=9.0\\times10^{-3}$，$A_3=0.901$。\n- 配置 $4$：$E_4=1.6\\times10^{-5}$，$L_4=1.7\\times10^{-2}$，$A_4=0.934$。\n- 配置 $5$：$E_5=1.2\\times10^{-5}$，$L_5=1.1\\times10^{-2}$，$A_5=0.889$。\n\n从能耗和延迟的核心定义出发，论证 EDP 的计算方法，并确保单位的科学一致性。将最终答案表示为一个包含两个条目的行矩阵：最小化配置的索引 $i$ 及其准确率 $A_i$。将报告的准确率四舍五入到四位有效数字，并且最终答案中不包含任何物理单位。",
            "solution": "问题陈述已经过验证，并被确定为是合理的。它具有科学依据，问题定义良好，客观，完整，并且不包含内部矛盾或不切实际的数据。该任务是计算机体系结构和神经形态工程领域的一项标准计算。\n\n问题要求计算一个神经形态脉冲分类器在五种不同硬件-软件配置下的能量-延迟乘积（EDP）。目标是找出产生最小 EDP 的配置，并报告其对应的分类准确率。\n\n首先，我们定义所涉及的基本物理量。\n能量，用 $E$ 表示，是系统所做的功或产生的热量。在此背景下，它是神经形态硬件执行单个分类任务（一次推理）所消耗的总能量。其国际单位制（SI）单位是焦耳（$J$）。\n延迟，用 $L$ 表示，是过程开始和完成之间的时间延迟。在这里，它代表执行一次推理所需的时间。其国际单位制（SI）单位是秒（$s$）。\n\n能量-延迟乘积（EDP）是用于评估计算系统效率的品质因数，它捕捉了性能（低延迟）和能耗之间的权衡。较低的 EDP 意味着更高效的设计。从第一性原理出发，给定配置 $i$ 的 EDP 定义为单次操作所消耗的能量与该操作延迟的乘积。\n公式为：\n$$\n\\text{EDP}_i = E_i \\times L_i\n$$\nEDP 的结果单位是焦耳-秒（$J \\cdot s$）。我们现在将计算给定的五种配置中每一种的 EDP。\n\n提供的数据如下：\n- 配置 $1$：$E_1 = 3.2 \\times 10^{-5} \\, J$，$L_1 = 8.0 \\times 10^{-3} \\, s$，$A_1 = 0.926$。\n- 配置 $2$：$E_2 = 2.5 \\times 10^{-5} \\, J$，$L_2 = 1.2 \\times 10^{-2} \\, s$，$A_2 = 0.913$。\n- 配置 $3$：$E_3 = 1.8 \\times 10^{-5} \\, J$，$L_3 = 9.0 \\times 10^{-3} \\, s$，$A_3 = 0.901$。\n- 配置 $4$：$E_4 = 1.6 \\times 10^{-5} \\, J$，$L_4 = 1.7 \\times 10^{-2} \\, s$，$A_4 = 0.934$。\n- 配置 $5$：$E_5 = 1.2 \\times 10^{-5} \\, J$，$L_5 = 1.1 \\times 10^{-2} \\, s$，$A_5 = 0.889$。\n\n每种配置的 EDP 计算如下：\n\n对于配置 $i=1$：\n$$\n\\text{EDP}_1 = E_1 \\times L_1 = (3.2 \\times 10^{-5}) \\times (8.0 \\times 10^{-3}) = 25.6 \\times 10^{-8} = 2.56 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=2$：\n$$\n\\text{EDP}_2 = E_2 \\times L_2 = (2.5 \\times 10^{-5}) \\times (1.2 \\times 10^{-2}) = 3.0 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=3$：\n$$\n\\text{EDP}_3 = E_3 \\times L_3 = (1.8 \\times 10^{-5}) \\times (9.0 \\times 10^{-3}) = 16.2 \\times 10^{-8} = 1.62 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=4$：\n$$\n\\text{EDP}_4 = E_4 \\times L_4 = (1.6 \\times 10^{-5}) \\times (1.7 \\times 10^{-2}) = 2.72 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=5$：\n$$\n\\text{EDP}_5 = E_5 \\times L_5 = (1.2 \\times 10^{-5}) \\times (1.1 \\times 10^{-2}) = 1.32 \\times 10^{-7} \\, J \\cdot s\n$$\n\n为了确定最优配置，我们比较计算出的 EDP 值：\n- $\\text{EDP}_1 = 2.56 \\times 10^{-7}$\n- $\\text{EDP}_2 = 3.00 \\times 10^{-7}$\n- $\\text{EDP}_3 = 1.62 \\times 10^{-7}$\n- $\\text{EDP}_4 = 2.72 \\times 10^{-7}$\n- $\\text{EDP}_5 = 1.32 \\times 10^{-7}$\n\n这些值中的最小值是 $\\text{EDP}_5 = 1.32 \\times 10^{-7} \\, J \\cdot s$。这对应于索引为 $i=5$ 的配置。\n\n问题要求报告使 EDP 最小化的配置索引 $i$ 及其对应的准确率 $A_i$。最小化索引是 $i=5$。此配置的准确率是 $A_5 = 0.889$。问题规定准确率应四舍五入到四位有效数字。因此，$A_5 = 0.8890$。\n\n最终答案包含最小化配置索引 $5$ 及其对应的准确率 $0.8890$。",
            "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n5  0.8890\n\\end{bmatrix}\n}\n$$"
        },
        {
            "introduction": "准确率是评估分类模型的关键指标，但一个单一的数字有时会产生误导，尤其是在处理真实世界中常见的不均衡数据集时。本练习通过一个具有显著类别不平衡的多类别分类任务，对准确率指标进行了深入剖析。您将计算总体准确率和宏平均$F_1$分数，并比较两者，从而揭示为什么仅凭高准确率可能会掩盖模型在少数类别上的严重性能缺陷。这项实践强调了选择能够公正反映所有类别性能的评估指标的重要性，这对于开发在现实应用中稳健可靠的神经拟态系统至关重要。",
            "id": "4036959",
            "problem": "一个部署在神经形态基底上的脉冲神经网络（SNN）在一个类别严重不平衡的多类别分类任务上进行评估。测试集包含 $10{,}000$ 个带标签的样本，分布在 $5$ 个类别中。评估产生了以下混淆矩阵 $C \\in \\mathbb{N}^{5 \\times 5}$，其中行索引表示真实类别，列索引表示预测类别：\n$$\nC \\;=\\; \\begin{pmatrix}\n7400  200  150  150  100 \\\\\n500  150  80  40  30 \\\\\n420  100  120  40  20 \\\\\n200  30  30  25  15 \\\\\n140  20  20  10  10\n\\end{pmatrix}.\n$$\n使用多类别分类的核心定义，计算总体准确率和宏平均 $F_1$ 分数。将每个类别的精确率定义为该类别被正确预测的样本数占所有被预测为该类别的样本数的比例，每个类别的召回率定义为该类别被正确预测的样本数占该类别所有真实样本数的比例，每个类别的 $F_1$ 分数定义为其精确率和召回率的调和平均值。宏平均 $F_1$ 分数是 $5$ 个类别的 $F_1$ 分数的非加权平均值。将这两个指标表示为无单位的小数，并均四舍五入到四位有效数字。此外，根据这些定义的基本原理和所提供的数据，解释为什么在神经形态评估场景中，当存在类别不平衡时，即使每次推理的延迟和能耗看起来可以接受，仅凭总体准确率也可能产生误导。最终的数值答案必须只包含所要求的两个指标。",
            "solution": "该问题要求根据给定的混淆矩阵计算两个分类指标——总体准确率和宏平均 $F_1$ 分数，并解释在类别不平衡的背景下，准确率指标可能产生误导的原因。该问题定义明确且具有科学依据。\n\n首先，我们从提供的混淆矩阵 $C$ 中确定必要的组成部分：\n$$\nC \\;=\\; \\begin{pmatrix}\n7400  200  150  150  100 \\\\\n500  150  80  40  30 \\\\\n420  100  120  40  20 \\\\\n200  30  30  25  15 \\\\\n140  20  20  10  10\n\\end{pmatrix}\n$$\n元素 $C_{ij}$ 表示来自真实类别 $i$ 的样本被预测为类别 $j$ 的数量。样本总数 $N$ 是矩阵中所有元素的总和：\n$N = \\sum_{i=1}^{5} \\sum_{j=1}^{5} C_{ij} = (7400+200+150+150+100) + (500+150+80+40+30) + (420+100+120+40+20) + (200+30+30+25+15) + (140+20+20+10+10) = 8000 + 800 + 700 + 300 + 200 = 10000$。\n这证实了给定的测试集总样本量为 $10,000$。\n\n**计算总体准确率**\n\n总体准确率是正确分类的样本数与总样本数的比率。正确分类的样本对应于混淆矩阵的对角线元素（即 $C$ 的迹）。\n$$\n\\text{Accuracy} = \\frac{\\sum_{i=1}^{5} C_{ii}}{N} = \\frac{\\text{Tr}(C)}{N}\n$$\n对角线元素之和为：\n$$\n\\text{Tr}(C) = 7400 + 150 + 120 + 25 + 10 = 7705\n$$\n因此，总体准确率为：\n$$\n\\text{Accuracy} = \\frac{7705}{10000} = 0.7705\n$$\n这个值已经表示为四位有效数字。\n\n**计算宏平均 $F_1$ 分数**\n\n为了计算宏平均 $F_1$ 分数，我们必须首先计算 $k=5$ 个类别中每个类别的精确率（$P_i$）、召回率（$R_i$）和 $F_1$ 分数（$F_{1,i}$）。\n\n对于每个类别 $i$，我们定义：\n- 真正例（$TP_i$）：$C_{ii}$\n- 假正例（$FP_i$）：$\\sum_{j=1, j\\neq i}^{k} C_{ji}$（第 $i$ 列的总和，不包括对角线元素）\n- 假负例（$FN_i$）：$\\sum_{j=1, j\\neq i}^{k} C_{ij}$（第 $i$ 行的总和，不包括对角线元素）\n\n类别 $i$ 的精确率是 $P_i = \\frac{TP_i}{TP_i + FP_i}$，即对类别 $i$ 的正确预测数除以对类别 $i$ 的总预测数。\n类别 $i$ 的召回率是 $R_i = \\frac{TP_i}{TP_i + FN_i}$，即对类别 $i$ 的正确预测数除以类别 $i$ 中的实际总样本数。\n类别 $i$ 的 $F_1$ 分数是其精确率和召回率的调和平均值：$F_{1,i} = 2 \\frac{P_i R_i}{P_i + R_i}$。\n\n让我们为每个类别计算这些值：\n行和（每个类别的实际总样本数）为：$S_{R,1}=8000$，$S_{R,2}=800$，$S_{R,3}=700$，$S_{R,4}=300$，$S_{R,5}=200$。\n列和（每个类别被预测的总样本数）为：\n$S_{C,1}=7400+500+420+200+140 = 8660$\n$S_{C,2}=200+150+100+30+20 = 500$\n$S_{C,3}=150+80+120+30+20 = 400$\n$S_{C,4}=150+40+40+25+10 = 265$\n$S_{C,5}=100+30+20+15+10 = 175$\n\n- **类别 1:**\n  $TP_1 = 7400$\n  $P_1 = \\frac{7400}{8660} \\approx 0.854503...$\n  $R_1 = \\frac{7400}{8000} = 0.925$\n  $F_{1,1} = 2 \\frac{P_1 R_1}{P_1 + R_1} \\approx 0.888355...$\n\n- **类别 2:**\n  $TP_2 = 150$\n  $P_2 = \\frac{150}{500} = 0.3$\n  $R_2 = \\frac{150}{800} = 0.1875$\n  $F_{1,2} = 2 \\frac{0.3 \\cdot 0.1875}{0.3 + 0.1875} = \\frac{0.1125}{0.4875} \\approx 0.230769...$\n\n- **类别 3:**\n  $TP_3 = 120$\n  $P_3 = \\frac{120}{400} = 0.3$\n  $R_3 = \\frac{120}{700} \\approx 0.171428...$\n  $F_{1,3} = 2 \\frac{P_3 R_3}{P_3 + R_3} \\approx 0.218181...$\n\n- **类别 4:**\n  $TP_4 = 25$\n  $P_4 = \\frac{25}{265} \\approx 0.094339...$\n  $R_4 = \\frac{25}{300} \\approx 0.083333...$\n  $F_{1,4} = 2 \\frac{P_4 R_4}{P_4 + R_4} \\approx 0.088495...$\n\n- **类别 5:**\n  $TP_5 = 10$\n  $P_5 = \\frac{10}{175} \\approx 0.057142...$\n  $R_5 = \\frac{10}{200} = 0.05$\n  $F_{1,5} = 2 \\frac{P_5 R_5}{P_5 + R_5} \\approx 0.053333...$\n\n宏平均 $F_1$ 分数是各类别 $F_1$ 分数的非加权算术平均值：\n$$\nF_{1,\\text{macro}} = \\frac{1}{5} \\sum_{i=1}^{5} F_{1,i}\n$$\n$$\nF_{1,\\text{macro}} \\approx \\frac{1}{5} (0.888355... + 0.230769... + 0.218181... + 0.088495... + 0.053333...)\n$$\n$$\nF_{1,\\text{macro}} \\approx \\frac{1}{5} (1.479135...) \\approx 0.295827...\n$$\n四舍五入到四位有效数字，宏平均 $F_1$ 分数为 $0.2958$。\n\n**关于类别不平衡下准确率产生误导的解释**\n\n计算出的指标呈现出鲜明对比：总体准确率是一个看似合理的 $0.7705$，而宏平均 $F_1$ 分数则是一个非常差的 $0.2958$。这种差异直接源于测试集中严重的类别不平衡以及这些指标的定义。\n\n总样本数为 $10,000$，类别分布分别为类别1到5各有 $8000$、$800$、$700$、$300$ 和 $200$ 个样本。类别 $1$ 占整个数据集的 $80\\%$。\n\n总体准确率是各类别性能的加权平均，其中权重是类别的大小。多数类别的真正例数量很高（$TP_1 = 7400$），在准确率计算的分子（$\\sum TP_i = 7705$）中占主导地位。因此，总体准确率被模型在这个单一、过大的类别上的表现严重扭曲，从而对模型的能力给出了一个具有欺骗性的乐观评价。一个将每个样本都预测为“类别1”的平凡模型仍然可以达到 $8000/10000 = 0.80$ 的准确率，这比SNN的性能还要高，但在实践中毫无用处。\n\n相比之下，宏平均 $F_1$ 分数独立地计算每个类别的 $F_1$ 分数，然后取其非加权平均值。这给予每个类别同等的重要性，无论其流行程度如何。四个少数类别的 $F_1$ 分数（$0.2308$、$0.2182$、$0.0885$、$0.0533$）都极低。这揭示了 SNN 模型几乎没有实际能力来正确识别这些类别的样本。$0.2958$ 的低宏 F1 分数准确地反映了模型在少数类别上的糟糕表现，而总体准确率指标则完全掩盖了这一点。\n\n在神经形态评估中，如果只关注低延迟和每次推理的低能耗等效率指标，并结合高总体准确率，将会产生严重的误导。数据显示，SNN 可能仅仅通过学习一种偏向于多数类别的简单策略来达到其高效率。该模型并没有解决预期的分类问题，而是在解决一个有偏见的、更简单的版本。因此，为了对神经形态系统在不平衡任务上的性能进行科学有效的评估，使用像宏平均 F1 分数这样对少数类别性能敏感的指标至关重要，以确保所报告的效率不是一个功能上无用的模型的副产品。",
            "answer": "$$\n\\boxed{\\begin{bmatrix} 0.7705  0.2958 \\end{bmatrix}}\n$$"
        }
    ]
}