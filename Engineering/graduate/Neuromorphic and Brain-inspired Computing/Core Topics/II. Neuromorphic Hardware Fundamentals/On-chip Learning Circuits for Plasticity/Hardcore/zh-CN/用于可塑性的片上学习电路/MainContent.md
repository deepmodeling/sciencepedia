## 引言
构建能够媲美生物大脑的智能系统，要求计算硬件本身具备学习和[适应环境](@entry_id:156246)变化的能力。将学习机制直接嵌入芯片，即“[片上学习](@entry_id:1129110)”，是神经形态计算领域追求的核心目标，它有望突破传统计算架构的能效瓶颈。然而，在计算神经科学和机器学习中优雅的数学学习模型与它们在充满物理限制和非理想性的硅基板上的高效、稳健实现之间，存在着一条巨大的鸿沟。本文旨在系统地跨越这条鸿沟，为面向可塑性的[片上学习](@entry_id:1129110)电路提供一个全面的视角。

为了实现这一目标，我们将分三个章节展开讨论。首先，在“原理与机制”一章中，我们将深入剖析驱动学习的基本[计算模型](@entry_id:637456)，如赫布理论、脉冲时间依赖可塑性（STDP）和三因子学习规则，并探讨为保证学习过程稳定所必需的竞争与调控机制。接着，在“应用与跨学科连接”一章中，我们将视野扩展到系统层面，探索这些电路如何被协调用于实现先进的机器学习算法，并审视它们在更广阔的神经形态计算版图中所扮演的角色。最后，通过一系列“动手实践”练习，我们旨在将理论知识转化为解决具体工程问题的能力。本文将带领读者踏上一段从抽象理论到物理实现，再到系统应用的旅程，为设计下一代自适应智能硬件奠定坚实的基础。

## 原理与机制

在“导论”中，我们确立了将学习和适应能力直接集成到计算硬件中的重要性。本章将深入探讨这些[片上学习](@entry_id:1129110)电路背后的核心科学原理和关键实现机制。我们将从可塑性的基本[计算模型](@entry_id:637456)出发，逐步深入到确保学习过程稳定性的机制，再到将这些抽象规则转化为物理电路和器件的策略，最后分析在真实硬件中不可避免的挑战和非理想性。通过这种由上至下的方法，我们将为理解、设计和分析能够自主学习的神经形态系统奠定坚实的基础。

### [突触可塑性](@entry_id:137631)的基本模型

在计算神经科学中，突触可塑性——即突触连接强度的活动依赖性变化——被认为是学习和[记忆的细胞基础](@entry_id:176418)。在芯片上，突触权重通常由一个模拟值（如电容器上的电压）或一个数字值（如计数器中的整数）来表示。学习电路的功能就是根据局部可获取的信号（主要是突触前和突触后神经元的活动）来调整这些权重。

#### [赫布学习](@entry_id:156080)：相关性的原理

最著名和最直观的可塑性原理是[赫布理论](@entry_id:156080)，通常被概括为“一起发放的神经元，连接会更强”(cells that fire together, wire together)。这个原理假定，当一个突触前神经元重复或持续地参与驱动一个突触后神经元发放时，该突触的权重会得到加强。

在数学上，这可以被建模为一个由相关性驱动的规则。假设突触前活动由迹线 $x(t)$ 表示，突触后活动由 $y(t)$ 表示，最简单的赫布形式是权重的变化率与这两者活动的乘积成正比：

$$
\dot{w}(t) \propto x(t) y(t)
$$

然而，这种纯粹的赫布规则存在一个根本问题：它本质上是一个正反馈系统，会导致权重的无限制增长，最终使所有权重都饱和在最大值。为了使学习过程稳定，必须引入一个与之抗衡的机制。一个常见的方法是增加一个与当前权重成比例的“遗忘”或“衰减”项。这形成了一个更完整的模型，有时被称为Oja规则的变体 ：

$$
\dot{w}(t) = \eta \Phi(x(t), y(t)) - \lambda w(t)
$$

在这里，$\eta$ 是一个小的学习率，$\Phi(x, y) \approx xy$ 是一个相关性计算器（例如，一个[模拟乘法器](@entry_id:269852)），而 $\lambda > 0$ 是一个泄漏常数。这个衰减项 $-\lambda w(t)$ 确保了权重不会无限增长。在[时间尺度分离](@entry_id:149780)的假设下（即权重变化远慢于神经元活动），我们可以分析系统的平均动态。通过令[平均变化率](@entry_id:193432) $\langle \dot{w} \rangle = 0$，可以找到一个稳定的不动点 $w^\star = \frac{\eta}{\lambda} \langle xy \rangle$。这个不动点是稳定的，因为任何偏离该点的扰动 $\delta w$ 都会被负反馈项 $-\lambda \delta w$ 所抑制。

**脉冲时间依赖可塑性 (Spike-Timing-Dependent Plasticity, STDP)** 是[赫布理论](@entry_id:156080)在脉冲神经元层面的一种更精确、更生物物理的体现。STDP不仅仅关心活动的平均相关性，还关心突触前脉冲和突触后脉冲之间精确的相对时间。在一个典型的STDP规则中，如果突触前脉冲在突触后脉冲之前到达（即 $\Delta t = t_{\text{post}} - t_{\text{pre}} > 0$，一个因果关系），突触权重会增加（长时程增强，LTP）。相反，如果突触前脉冲在突触后脉冲之后到达（$\Delta t  0$，一个非因果关系），权重会减小（[长时程抑制](@entry_id:154883)，LTD）。这种时间上的不对称性使STDP成为一种强大的机制，能够从[脉冲序列](@entry_id:1132157)中提取时序相关性。

#### [稳态可塑性](@entry_id:151193)：调控的原理

与[赫布学习](@entry_id:156080)放大相关性的正反馈特性不同，**[稳态可塑性](@entry_id:151193) (homeostatic plasticity)** 是一种负反馈机制，其主要作用是维持神经元或神经网络的活动在一个稳定的、预设的目标范围内。当一个神经元的平均发放率偏离其目标率时，[稳态机制](@entry_id:141716)会调整其[内在兴奋性](@entry_id:911916)或其突触权重，以将发放率拉回到目标水平。

一个典型的[稳态可塑性](@entry_id:151193)规则可以被实现为一个活动调节规则 。假设存在一个局部生成的目标活动水平 $r^\star$，该规则根据突触后活动 $y(t)$ 与该目标的误差来调整权重：

$$
\dot{w}(t) = \eta x(t) (r^\star - y(t))
$$

这个规则的负反馈特性是显而易见的：如果突触后活动 $y(t)$ 超过了目标 $r^\star$，误差项 $(r^\star - y(t))$ 为负，导致权重 $w$ 减小（因为 $x(t) \ge 0$），从而降低 $y(t)$。反之亦然。这种机制对于防止网络活动因赫布学习而失控至关重要。它确保神经元保持在它们的信息处理动态范围内，既不会永远沉默，也不会饱和到最大发放率。在平均动态下，该规则会调整权重 $w$，使得输出活动 $\langle y \rangle$ 趋近于目标 $r^\star$。一个有趣的结果是，权重会自适应地与输入活动的尺度成反比，即 $w^\star \langle x \rangle \approx r^\star$，这保证了即使输入统计特性发生变化，输出活动也能保持稳定。

#### 三因子学习：结合全局背景

赫布学习和[稳态](@entry_id:139253)学习都是“双因子”规则，因为它们只依赖于突触前和突触后的活动。然而，在更复杂的学习任务中，例如[强化学习](@entry_id:141144)，系统需要将局部突触活动与一个全局的、通常是延迟的、关于任务表现的信号（如奖励或惩罚）联系起来。这就引出了**三因子学习 (three-factor learning)** 的概念。

三因子学习规则的核心思想是，突触权重的变化取决于三个因素：(1) 突触前活动，(2) 突触后活动，以及 (3) 一个全局的、神经调节性的“第三因子”信号 $M(t)$。一个关键的挑战是**时间信用分配 (temporal credit assignment)**：如何将延迟到达的奖励信号 $M(t)$ 正确地分配给早先引起该奖励的突触活动？

解决方案是引入一个名为**[资格迹](@entry_id:1124370) (eligibility trace)** 的中间变量 $e(t)$ 。资格迹是每个突触的局部状态变量，它记录了近期发生的赫布式协同活动（例如，突触前和突触后脉冲的重合），并随着时间缓慢衰减。其动态可以建模为：

$$
\frac{de(t)}{dt} = -\frac{e(t)}{\tau_e} + C(t)
$$

其中，$C(t)$ 代表突触前后的协同活动，$\tau_e$ 是迹的衰减时间常数。[资格迹](@entry_id:1124370)的作用就像一个临时的“标记”，表明该突触最近是活跃的，并且有资格获得信用。当延迟的全局调节信号 $M(t)$ 到达时，权重的更新由[资格迹](@entry_id:1124370)和该信号的乘积决定：

$$
\frac{dw(t)}{dt} \propto e(t) \cdot M(t)
$$

通过这种方式，只有那些在奖励（或惩罚）发生前不久被“标记”的突触才会被修改。为了使这种机制有效，资格迹的衰减时间常数 $\tau_e$ 必须与调节信号的典型延迟相当 。

在硬件实现中，一个实际问题是调节信号 $M(t)$（例如，编码奖励预测误差的信号）通常具有非零的基[线或](@entry_id:170208)平均值。如果直接将 $e(t)$ 与 $M(t)$ 相乘，这个基线会导致一个与任务表现无关的系统性权重漂移，从而破坏学习。因此，一个稳定的三因子学习电路必须在硬件中实现基线减法，以确保只有 $M(t)$ 的波动部分（即信息部分）驱动权重更新。从统计学上讲，当调节信号的均值为零时，期望的权重更新正比于资格迹和调节信号之间的协方差 $E[\Delta w] \propto \text{Cov}(e, M)$，这提供了一个对任务相关信用的无偏估计 。

### 稳定与竞争机制

如前所述，纯粹的赫布学习是不稳定的。即使引入了简单的衰减项，在一个由许多相互连接的神经元组成的网络中，确保稳定学习仍然是一个巨大的挑战。本节探讨了在突触和网络层面用于稳定学习并促进有用表征形成的各种机制。

#### 不稳定学习的挑战

STDP 规则的稳定性是理解更复杂机制动机的一个很好的例子。考虑一个**加性STDP (additive STDP)** 模型，其中每次LTP或LTD的更新量 $\Delta w$ 是一个固定的常数，不依赖于当前权重 $w$。如果一个突触接收到的突触前和突触后脉冲流是独立的泊松过程，那么权重的平均漂移将是一个与 $w$ 无关的常数。如果这个常数非零，权重将线性地漂向一个边界（$w_{\max}$ 或 $w_{\min}$）。即使LTP和LTD的贡献精确平衡（即平均漂移为零），权重也会经历一个无偏的随机游走，最终还是会到达其中一个吸收边界。因此，加性STDP本身无法产生一个稳定的中间权重值 。

#### 突触层面的稳定化

为了解决这种不稳定性，可以在突触层面引入多种机制：

*   **[权重衰减](@entry_id:635934)/泄漏 (Weight Decay/Leak)**：正如在赫布模型中讨论的，一个与 $w$ 成比例的衰减项（$-\lambda w$）可以有效地[稳定权重](@entry_id:894842) 。这是一个简单而强大的耗散机制。

*   **权重依赖性更新 (Weight-Dependent Updates)**：与加性规则不同，**乘性STDP (multiplicative STDP)** 使更新量依赖于当前权重。一个常见的模型是，LTP的大小与权重距离上边界的距离成比例（例如，$\Delta w_{\text{LTP}} \propto (w_{\max} - w)$），而LTD的大小与权重距离下边界的距离成比例（例如，$\Delta w_{\text{LTD}} \propto (w - w_{\min})$）。这种依赖性引入了一个软边界：当权重接近 $w_{\max}$ 时，LTP变得非常小；当权重接近 $w_{\min}$ 时，LTD变得非常小。这种动态会在 $(w_{\min}, w_{\max})$ 内部产生一个稳定的不动点。对于不相关的泊松脉冲流，这个不动点 $w^\star$ 满足 potentiation 和 depression 的贡献平衡，即 $A_+(w_{\max} - w^\star) = A_- w^\star$，其中 $A_+$ 和 $A_-$ 分别是LTP和LTD学习窗口的[有效面积](@entry_id:197911)。这个不动点的位置可以通过调整LTP和LTD的相对强度来控制，并且它是局部稳定的 。

*   **硬边界 (Hard Bounding)**：在数字实现中，稳定性可以通过最简单的方式保证：将权重存储在一个具有固定范围 $[w_{\min}, w_{\max}]$ 的整数寄存器中。任何试图将权重推到边界之外的更新都会被“裁剪”掉。这是一种有效但略显生硬的稳定方法。数字电路也可以实现离散时间的[权重衰减](@entry_id:635934)，例如，在每个时间步将权重乘以一个小于1的因子 $\alpha$ ($w[n+1] \leftarrow \alpha w[n]$) 。

#### 网络层面的稳定化

除了单个突触的稳定性，整个网络的活动稳定性也至关重要。这通常通过作用于整个神经元或神经元群体的全局机制来实现 。

*   **[稳态](@entry_id:139253)发放率控制 (Homeostatic Firing Rate Control)**：如前所述，这是通过[负反馈调节](@entry_id:170011)神经元发放率以匹配目标率的核心机制。它可以调整神经元的[内在兴奋性](@entry_id:911916)（例如，通过改变其发放阈值或偏置电流）或全局性地调整其所有输入突触的强度。

*   **[突触缩放](@entry_id:174471) (Synaptic Scaling)**：这是[稳态可塑性](@entry_id:151193)的一种特殊形式，其中校正信号被用来对一个神经元的所有输入突触权重进行[乘性缩放](@entry_id:197417)，即 $w_i \rightarrow \alpha \cdot w_i$。这种操作的关键特性是它保持了权重之间的**比率** ($(\alpha w_i) / (\alpha w_j) = w_i / w_j$)。由于输入模式的表征信息主要编码在这些相对权重中，[突触缩放](@entry_id:174471)可以在不擦除已学知识的情况下，调节总的突触驱动力，从而控制神经元的活动水平。因此，它主要是一种保持稳定的机制，同时保留了学习到的信息。

*   **权重归一化 (Weight Normalization)**：这是一种强制性的约束，要求一个神经元的所有输入权重向量 $\mathbf{w}$ 的某个范数（例如，[L1范数](@entry_id:143036) $\sum_i |w_i|$ 或 [L2范数](@entry_id:172687) $\sqrt{\sum_i w_i^2}$）保持为一个常数。每次通过赫布学习更新权重后，权重向量会被投影回这个约束曲面。这种归一化不仅能直接防止权重的无限增长，从而保证**稳定性**，还能引入**竞争**。为了让一个权重 $w_k$ 增加，其他权重必须相应减少以满足约束。这种竞争是学习过程的一个重要组成部分，它迫使神经元变得对最显著或最频繁的输入模式具有选择性。因此，权重归一化同时服务于稳定和学习两个目的。

### 片上可塑性电路的实现

将上述计算原理转化为高效、紧凑的硅电路是神经形态工程的核心挑战。这需要创新的电路设计技术和对底层[半导体器件物理](@entry_id:191639)的深刻理解。

#### 实现时间动态：资格迹电路

资格迹是实现三因子学习等时间依赖规则的关键构件。其核心功能是实现一个具有可调时间常数的衰减记忆。

一个直接的模拟实现是使用一个**泄[漏积分器](@entry_id:261862) (leaky integrator)**，它由一个电容器 $C$ 和一个并联的泄漏电导 $G_L$ 组成 。当一个突触前后重合事件发生时，一个固定电荷包 $Q$ 被注入电容器，使其电压（代表资格迹 $e(t)$）瞬时增加 $\Delta e = Q/C$。随后，泄漏电导会使电容器上的电压以指数形式衰减，其时间常数由电路参数决定：$\tau = C / G_L$。这是一个简单而有效的实现，它将资格迹的动态直接映射到基本的电路物理上。为了最大化学习效率，资格迹的时间常数 $\tau$ 应该与调节信号的衰减特性相匹配。例如，如果调节信号的平均波形也是指数衰减的 $r(t) \propto \exp(-\lambda t)$，那么在固定能量约束下，将资格迹的时间常数设置为 $\tau^\star = 1/\lambda$ 可以最大化权重更新的幅度。这本质上是一个**[匹配滤波器](@entry_id:137210) (matched filter)** 的原理。

然而，在[CMOS技术](@entry_id:265278)中实现具有长达数百毫秒时间常数的泄漏电导 $G_L$ 是非常困难的，因为这需要非常大或者非常高阻值的电阻，而这两者在芯片上都占用巨大面积且精度不高。一种更优雅、更高效的解决方案是利用**亚阈值 (subthreshold)** MOSFET的物理特性来构建**对[数域](@entry_id:155558) (log-domain)** 电路 。

在亚阈值区，MOSFET的漏极电流 $I_D$ 与其栅源电压 $V_{GS}$ 呈指数关系：$I_D = I_0 \exp(\kappa V_{GS} / U_T)$，其中 $U_T=kT/q$ 是[热电压](@entry_id:267086)，$\kappa$ 是一个与工艺相关的系数。这意味着电压 $V_{GS}$ 与电流的对数成正比。考虑一个被称为“tau单元”的电路：一个电容器 $C$ 连接到MOSFET的栅极，并由一个恒定的[偏置电流](@entry_id:260952) $I_b$ 对其放电。根据电容方程 $C \frac{dV_{GS}}{dt} = -I_b$，栅极电压 $V_{GS}$ 将随时间线性下降。然而，由于指数关系，这个线性的电压斜坡被晶体管转换成了一个精确的**指数衰减**的输出电流 $I_D(t) = I_D(0) \exp(-t/\tau)$。其时间常数为：

$$
\tau = \frac{C U_T}{\kappa I_b}
$$

这个电路的巨大优势在于，它无需物理电阻即可实现指数衰减。时间常数 $\tau$ 可以通过改变[偏置电流](@entry_id:260952) $I_b$ 进行电子化调谐，这在芯片上既精确又节省面积。这种利用器件内在物理特性的方法是低功耗模拟和神经形态设计的基石。

#### 物理基底：[忆阻器](@entry_id:204379)突触

虽然基于电容器的突触可以实现可塑性，但它们是易失性的，需要持续的刷新来维持权重，这会消耗大量能量。**忆阻器 (memristor)** 或更广泛的电阻式开关存储器，为实现高密度、非易失性的[模拟突触](@entry_id:1120995)提供了一条有前途的途径。

一个忆阻器突触的通用定义是，它的电导 $G$ 是一个内部[状态变量](@entry_id:138790) $x$ 的函数，而这个[状态变量](@entry_id:138790)会根据流过器件的电荷或施加在器件两端的电压历史而改变 。这导致了一种依赖于历史的、非易失的电导行为。几种主流的忆阻器技术包括：

*   **[电阻式随机存取存储器](@entry_id:1130916) (RRAM)**：其开关机制基于在绝缘层中导电细丝的形成（SET，低阻态）和断裂（RESET，[高阻态](@entry_id:163861)）。这一过程由电场驱动的离子（如氧空位或金属阳离子）迁移和电化学[氧化还原反应](@entry_id:141625)控制。RRAM可以提供很大的开关比，但其[更新过程](@entry_id:275714)本质上是随机的，因为细丝的生长和溶解涉及原子尺度的概率性事件。这导致其权重更新表现出[非线性](@entry_id:637147)和随机累积的特性。

*   **[相变存储器 (PCM)](@entry_id:753381)**：其原理是利用[焦耳热](@entry_id:150496)诱导材料（如硫族化合物）在低电阻的晶态和高电阻的非晶态之间转换。通过施加一系列精确控制的脉冲，可以逐步增加材料中的晶化区域比例，从而实现较为平滑、渐进的电导增加（SET过程）。然而，RESET过程（熔化后快速冷却形成[非晶态](@entry_id:204035)）通常更具突[变性](@entry_id:165583)。这种不对称性是PCM作为[模拟突触](@entry_id:1120995)的一个挑战。

*   **铁电场效应晶体管 (FeFET)**：这是一种三端器件，其栅极绝缘层被替换为[铁电材料](@entry_id:273847)。通过施加栅极电压，可以改变铁电层的极化方向。由于[铁电材料](@entry_id:273847)具有[剩余极化](@entry_id:160843)，即使在撤去栅压后，它仍然能在半导体沟道中感应出电荷，从而非易失地调制晶体管的阈值电压和沟道电导。通过施加低于[矫顽场](@entry_id:160296)或持续时间很短的脉冲，可以实现[铁电畴](@entry_id:160657)的部分翻转，从而产生准模拟的、非易失的电导状态。

这些不同的[忆阻器](@entry_id:204379)技术为构建大规模、高密度的[片上学习](@entry_id:1129110)系统提供了物理基础，但它们各自的非理想特性也带来了独特的挑战。

### 系统级挑战与硬件非理想性

从单个电路和器件扩展到包含数千乃至数百万突触的大规模系统时，新的挑战便会出现。这些挑战源于器件间的相互作用以及单个器件固有的不完美性。

#### 无源[交叉阵列](@entry_id:202161)：一把双刃剑

为了实现极高的[突触密度](@entry_id:902498)，一种常见的架构是**无源[交叉阵列](@entry_id:202161) (passive crossbar array)**，其中[忆阻器](@entry_id:204379)突触被放置在交叉的金属导线（字线和位线）的每个交点上。这种结构非常紧凑，但也引入了严重的问题 。

*   **潜行路径 (Sneak Paths)**：由于阵列是无源的（即每个交叉点没有选择晶体管来隔离），当试图对一个选定的器件进行编程或读取时，电流不仅会流过目标器件，还会通过阵列中其他未被选中的器件构成的大量并联“潜行路径”泄漏。这些潜行路径会分流电流，并在具有非[零电阻](@entry_id:145222)的金属线上造成显著的[电压降](@entry_id:263648)（IR drop）。其后果是，施加在目标器件上的实际电压会低于预期值，并且这个实际电压的大小取决于阵列中**所有其他器件**的电导状态。这使得权重更新变得依赖于全局状态和历史，严重破坏了学习规则的精确性。

*   **半选应力 (Half-Select Stress)**：一种常见的编程方案是“V/2方案”：将选定行驱动到 $+V_{\text{prog}}/2$，选定列驱动到 $-V_{\text{prog}}/2$，而所有其他行和列接地。这样，目标器件上的电压为 $V_{\text{prog}}$。然而，所有与选定行或选定列共享的“半选”器件上的电压为 $\pm V_{\text{prog}}/2$。如果编程阈值电压为 $V_{\text{th}}$，为了实现选择性更新，必须满足 $V_{\text{th}}  |V_{\text{prog}}|  2V_{\text{th}}$。这个编程窗口可能非常窄。即使 $|V_{\text{prog}}/2|$ 小于 $V_{\text{th}}$，它也可能非零。在经历数百万次更新操作的在位学习过程中，这些施加在半选器件上的微小电压会累积起来，导致它们权重的非预期漂移，从而污染整个网络的权重表示。

#### 器件不完美性及其对学习的影响

即使可以完美地隔离每个突触，单个器件的物理不完美性仍然会对学习算法的性能产生深远影响。这些影响最好在[随机梯度下降](@entry_id:139134)（SGD）的框架下理解，因为许多[片上学习](@entry_id:1129110)规则都可以被看作是SGD的硬件实现。

*   **更新的[非线性](@entry_id:637147)和不对称性**：理想的SGD更新量应该与梯度成正比。然而，在硬件中，每次脉冲引起的权重变化 $\Delta w$ 往往依赖于当前权重 $w$，这就是**更新[非线性](@entry_id:637147)** 。这种[非线性](@entry_id:637147)（由函数 $\phi(w)$ 建模）相当于一个依赖于状态的[学习率](@entry_id:140210)，它虽然会改变收敛速度，但通常不会改变损失函数最优解的位置。更严重的是**LTP/LTD不对称性**，即相同幅度的LTP和LTD指令[脉冲产生](@entry_id:263613)不同大小的权重变化（$\eta_+ \neq \eta_-$）。在那些期望在最优点处LTP和LTD脉冲概率相等（例如，$p_+ = p_- = 1/2$）的算法中，这种不对称性会导致一个非零的期望漂移 $\mathbb{E}[\Delta w] = \frac{1}{2}(\eta_+ - \eta_-)\phi(w)$。这个漂移会将权重从真正的最优点推开，导致收敛到一个有偏的、次优的解，除非电路或算法层面进行补偿。

*   **噪声与变异性**：模拟电路和器件中存在多种噪声源，它们[共同限制](@entry_id:180776)了更新的精度 。
    *   **失配 (Mismatch)**：这是由于制造过程的微小差异导致的器件参数的静态、器件间的变化。它会在阵列中产生固定的模式噪声，即每个突触都有其自己独特的、偏离标称值的增益或偏移。
    *   **热噪声 (Thermal Noise)**：源于导电通道中载流子的热骚动，是一种宽带[白噪声](@entry_id:145248)。在一个更新操作中，[热噪声](@entry_id:139193)被采样到权重存储电容器上，为单次更新的精度设定了一个基本物理下限。这个[均方根](@entry_id:263605)（RMS）误差的大小约为 $\sqrt{k_B T / C}$，其中 $C$ 是存储电容。对于一个 $1 \text{ pF}$ 的电容在室温下，这个噪声约为 $64 \mu\text{V}$。
    *   **[闪烁噪声](@entry_id:139278) (Flicker Noise, 1/f noise)**：在MOS器件中很普遍，其[功率谱](@entry_id:159996)与频率成反比。由于其[能量集中](@entry_id:203621)在低频，它表现为器件参数（如阈值电压）的缓慢、随机漂移。在多次更新操作的时间尺度上，它会导致权重的相关性漂移。
    *   **[随机电报噪声](@entry_id:269610) (Random Telegraph Noise, RTN)**：在纳米级器件中尤为显著，它是由单个[电荷陷阱](@entry_id:1122309)的俘获/释放过程引起的。这会导致器件参数在几个离散能级之间随机跳变。RTN不仅会导致缓慢的漂移，其大幅度的、离散的跳变还会产生非高斯、[重尾](@entry_id:274276)的误差分布，即“异常值”，这对学习算法的稳定性构成了严重威胁。

总之，从抽象的[学习理论](@entry_id:634752)到功能性的神经形态硬件，需要跨越多个层次的理解：从可塑性的[计算模型](@entry_id:637456)，到稳定网络的整体策略，再到将这些思想转化为具体的电路和器件，并最终应对真实物理系统带来的种种非理想性。只有全面地掌握这些原理和机制，我们才能构建出真正强大和高效的[片上学习](@entry_id:1129110)系统。