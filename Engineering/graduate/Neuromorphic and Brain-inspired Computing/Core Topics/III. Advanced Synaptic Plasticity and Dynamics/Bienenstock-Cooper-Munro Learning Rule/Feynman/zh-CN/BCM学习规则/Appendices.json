{
    "hands_on_practices": [
        {
            "introduction": "我们的第一个练习将BCM学习规则简化为其核心逻辑。通过考虑一个固定的活动阈值，我们可以清楚地看到该规则如何实现长时程增强（LTP）和长时程抑制（LTD），从而在BCM规则与我们所熟悉的海布学习概念之间建立起一座桥梁。这个练习将帮助你确定突触增强和减弱之间的关键转换点。",
            "id": "4037134",
            "problem": "考虑一个单速率神经元，它由一个活动为 $x(t)$ 的突触前通道和一个突触权重 $w(t)$ 驱动。假设一个速率编码的突触后响应 $y(t)$ 与净输入成线性比例关系，即 $y(t)=w(t)\\,x(t)$，并且突触权重被约束在非负象限内，$w(t)\\geq 0$，这在整流神经形态电路中很常见。令 $x(t)\\equiv x0$ 在突触变化的时间尺度上为常数。突触权重的 Bienenstock-Cooper-Munro (BCM) 学习规则由一个活动门控更新定义，其形式为 $\\dot{w}(t)=\\eta\\,x(t)\\,y(t)\\big(y(t)-\\theta\\big)$，其中 $\\eta0$ 是一个学习率常数，$\\theta0$ 是一个固定的、小的阈值参数，其单位与 $y(t)$ 相同。从速率编码、 $w(t)$ 的非负性以及上述 BCM 更新结构的假设出发，推导 $w(t)$ 的自治微分方程，并对其右侧进行符号分析，以确定可塑性从抑制切换到增强的唯一非零临界权重 $w_{\\mathrm{c}}$。利用此符号分析来证明，对于一个固定的较小 $\\theta$，BCM 规则近似于一个带阈值的赫布规则，当突触后活动较低时（即当 $y(t)\\theta$ 时）抑制突触，当 $y(t)\\theta$ 时增强突触。请提供切换权重 $w_{\\mathrm{c}}$ 关于 $x$ 和 $\\theta$ 的闭式解析表达式作为最终答案。不需要数值近似。",
            "solution": "问题给出了突触权重 $w(t)$ 的 Bienenstock-Cooper-Munro (BCM) 学习规则，并要求在特定条件下推导和分析其动力学。我们首先陈述给定的方程和约束条件。\n\n突触后响应 $y(t)$ 与突触前输入 $x(t)$ 和突触权重 $w(t)$ 成线性比例：\n$$y(t) = w(t) x(t)$$\n突触权重被约束为非负：\n$$w(t) \\ge 0$$\n假设突触前输入为常数且为正：\n$$x(t) \\equiv x, \\quad \\text{with } x > 0$$\n在此条件下，突触后响应简化为：\n$$y(t) = w(t) x$$\nBCM 学习规则由下式给出：\n$$\\dot{w}(t) = \\eta \\, x(t) \\, y(t) \\big(y(t) - \\theta\\big)$$\n其中 $\\dot{w}(t)$ 是权重的导数，$\\eta > 0$ 是学习率，$\\theta > 0$ 是一个固定的活动阈值。\n\n第一步是推导 $w(t)$ 的自治微分方程。我们将 $x(t)$ 和 $y(t)$ 的表达式代入 BCM 规则：\n$$\\dot{w}(t) = \\eta \\, x \\, (w(t)x) \\big(w(t)x - \\theta\\big)$$\n通过重新整理各项，我们得到 $w(t)$ 的自治常微分方程（ODE），因为右侧仅依赖于 $w(t)$ 而不显式依赖于时间 $t$：\n$$\\dot{w}(t) = \\eta x^2 w(t) \\big(w(t)x - \\theta\\big)$$\n我们定义右侧函数为 $F(w) = \\eta x^2 w (wx - \\theta)$。$\\dot{w}(t) = F(w(t))$ 的符号决定了突触是经历增强（$\\dot{w} > 0$）还是抑制（$\\dot{w}  0$）。\n\n接下来，我们对 $F(w)$ 进行符号分析。动力学的临界点（或不动点）出现在 $\\dot{w}(t) = 0$ 时，即 $F(w) = 0$。\n$$\\eta x^2 w (wx - \\theta) = 0$$\n因为给定 $\\eta > 0$ 和 $x > 0$，所以项 $\\eta x^2$ 是严格为正的。因此，当 $w=0$ 或 $(wx - \\theta) = 0$ 时，方程成立。\n这给出了两个临界点：\n1. $w_1 = 0$\n2. $wx - \\theta = 0 \\implies w_2 = \\frac{\\theta}{x}$\n\n问题要求找出可塑性从抑制切换到增强的唯一非零临界权重 $w_{\\mathrm{c}}$。这对应于 $w_2$。\n$$w_{\\mathrm{c}} = \\frac{\\theta}{x}$$\n由于 $\\theta > 0$ 且 $x > 0$，所以 $w_{\\mathrm{c}}$ 是一个正权重，这与约束条件 $w(t) \\ge 0$ 一致。\n\n现在我们分析由这些临界点定义的 $w > 0$ 区域内 $\\dot{w}$ 的符号。$\\dot{w} = \\eta x^2 w (wx - \\theta)$ 的符号由项 $(wx - \\theta)$ 的符号决定，因为 $\\eta x^2 > 0$ 且我们考虑的是 $w > 0$。\n\n情况1：抑制（$\\dot{w}  0$）。\n这发生在 $(wx - \\theta)  0$ 时，意味着 $wx  \\theta$。解出 $w$ 得：\n$$w  \\frac{\\theta}{x} \\implies w  w_{\\mathrm{c}}$$\n因此，对于区间 $0  w  w_{\\mathrm{c}}$ 内的任何权重 $w$，突触都会减弱（$\\dot{w}  0$）。\n\n情况2：增强（$\\dot{w} > 0$）。\n这发生在 $(wx - \\theta) > 0$ 时，意味着 $wx > \\theta$。解出 $w$ 得：\n$$w > \\frac{\\theta}{x} \\implies w > w_{\\mathrm{c}}$$\n对于任何权重 $w > w_{\\mathrm{c}}$，突触都会增强（$\\dot{w} > 0$）。\n\n这个符号分析证明了将 BCM 规则解释为带阈值的赫布规则是合理的。突触后活动为 $y = wx$。从抑制切换到增强的条件 $w = w_{\\mathrm{c}} = \\frac{\\theta}{x}$ 等价于突触后活动达到阈值：\n$$y = w_{\\mathrm{c}}x = \\left(\\frac{\\theta}{x}\\right)x = \\theta$$\n因此，BCM 规则实现了以下逻辑：\n- 如果突触后活动较低（$y  \\theta$），突触则被抑制。这对应于长时程抑制（LTD）。\n- 如果突触后活动较高（$y > \\theta$），突触则被增强。这对应于长时程增强（LTP）。\n\n该规则的赫布特性从项 $\\eta x y$ 中对突触前 ($x$) 和突触后 ($y$) 活动的乘法依赖性中可以明显看出。因子 $(y - \\theta)$ 引入了控制可塑性方向的阈值，使其成为一个“带阈值的赫布规则”。临界权重 $w_{\\mathrm{c}}$ 是指在给定输入 $x$ 的情况下，突触后响应 $y$ 等于阈值 $\\theta$ 的特定权重值，它标志着抑制和增强之间的边界。\n\n所要求的最终答案是这个切换权重 $w_{\\mathrm{c}}$ 的闭式解析表达式。根据对自治常微分方程临界点的分析推导得出，该表达式为：\n$$w_{\\mathrm{c}} = \\frac{\\theta}{x}$$",
            "answer": "$$\\boxed{\\frac{\\theta}{x}}$$"
        },
        {
            "introduction": "BCM规则的一个关键创新是其具有稳态调节功能的“滑动”阈值，该机制可以防止突触权重失控增长。本练习将深入探讨该阈值的动态特性，要求你推导出它如何根据神经元近期的活动历史自动进行调整。理解这一机制对于掌握BCM网络如何实现稳定性至关重要。",
            "id": "4037170",
            "problem": "考虑一个遵循 Bienenstock-Cooper-Munro (BCM) 学习规则的单神经元模型，其中滑动阈值根据一阶低通动力学演化。具体而言，令阈值变量 $\\theta(t)$ 服从线性常微分方程 $\\tau_{\\theta} \\dot{\\theta}(t) = y(t)^{2} - \\theta(t)$，其中 $\\tau_{\\theta} > 0$ 是一个恒定的时间尺度，$y(t)$ 是神经元的输出。假设 $y(t)$ 是一个具有有限二阶矩、均值为 $\\mu$、方差为 $\\sigma^{2}$ 的平稳遍历过程。从给定的动力学方程以及平稳性和遍历性的定义出发，完成以下任务：\n- 推导 $\\theta(t)$ 作为 $y(\\cdot)$ 的因果泛函的稳态解，并用此解根据过程 $y(t)^{2}$ 的分布来刻画 $\\theta(t)$ 的稳态分布。\n- 仅使用平稳过程的线性时不变滤波的基本性质和遍历定理，建立稳态期望 $\\mathbb{E}[\\theta]$ 与 $\\mathbb{E}[y^{2}]$ 之间的关系。\n- 将稳态期望 $\\mathbb{E}[\\theta]$ 的最终答案仅用 $\\mu$ 和 $\\sigma^{2}$ 表示。\n\n你的最终答案必须是 $\\mathbb{E}[\\theta]$ 的单个闭式解析表达式。不需要数值近似或四舍五入。",
            "solution": "问题陈述被评估为有效。它在计算神经科学和随机过程领域内提出了一个适定的、有科学依据的问题。所有必要的参数和条件都已提供，不存在矛盾、歧义或事实不准确之处。该问题要求根据既定原理进行标准推导。\n\n按问题陈述的要求，分析分三个阶段进行。\n\n首先，我们推导阈值变量 $\\theta(t)$ 的稳态解。$\\theta(t)$ 的动力学由以下一阶线性常微分方程（ODE）决定：\n$$\\tau_{\\theta} \\dot{\\theta}(t) = y(t)^{2} - \\theta(t)$$\n其中 $\\dot{\\theta}(t)$ 表示 $\\theta$ 关于时间 $t$ 的导数，$\\tau_{\\theta} > 0$ 是一个常数。我们可以将此方程重写为标准形式：\n$$ \\frac{d\\theta}{dt} + \\frac{1}{\\tau_{\\theta}}\\theta(t) = \\frac{1}{\\tau_{\\theta}}y(t)^{2} $$\n这是一个非齐次一阶线性常微分方程。我们可以使用积分因子 $I(t)$ 来求解，其定义为：\n$$ I(t) = \\exp\\left(\\int \\frac{1}{\\tau_{\\theta}} dt\\right) = \\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right) $$\n将常微分方程两边乘以 $I(t)$ 得到：\n$$ \\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right)\\frac{d\\theta}{dt} + \\frac{1}{\\tau_{\\theta}}\\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right)\\theta(t) = \\frac{1}{\\tau_{\\theta}}\\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right)y(t)^{2} $$\n左侧是乘积 $\\theta(t)I(t)$ 的导数：\n$$ \\frac{d}{dt}\\left[\\theta(t)\\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right)\\right] = \\frac{1}{\\tau_{\\theta}}\\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right)y(t)^{2} $$\n对两边从过去的某个时间 $t_0$ 积分到当前时间 $t$：\n$$ \\theta(t)\\exp\\left(\\frac{t}{\\tau_{\\theta}}\\right) - \\theta(t_0)\\exp\\left(\\frac{t_0}{\\tau_{\\theta}}\\right) = \\frac{1}{\\tau_{\\theta}}\\int_{t_0}^{t} \\exp\\left(\\frac{s}{\\tau_{\\theta}}\\right)y(s)^{2} ds $$\n解出 $\\theta(t)$：\n$$ \\theta(t) = \\theta(t_0)\\exp\\left(-\\frac{t-t_0}{\\tau_{\\theta}}\\right) + \\frac{1}{\\tau_{\\theta}}\\int_{t_0}^{t} \\exp\\left(-\\frac{t-s}{\\tau_{\\theta}}\\right)y(s)^{2} ds $$\n稳态解是通过考虑系统从遥远过去的演化得到的，即取极限 $t_0 \\to -\\infty$。由于 $\\tau_{\\theta} > 0$，假设 $\\theta(t_0)$ 是有限的，则包含初始条件 $\\theta(t_0)$ 的第一项会衰减到零。因此，稳态解 $\\theta_{ss}(t)$ 为：\n$$ \\theta_{ss}(t) = \\frac{1}{\\tau_{\\theta}}\\int_{-\\infty}^{t} \\exp\\left(-\\frac{t-s}{\\tau_{\\theta}}\\right)y(s)^{2} ds $$\n这个表达式将 $\\theta(t)$ 表示为过程 $y(\\cdot)$ 的一个因果泛函。具体来说，它表明 $\\theta(t)$ 是一个线性时不变（LTI）滤波器的输出，该滤波器的冲激响应为 $h(\\tau) = \\frac{1}{\\tau_{\\theta}}\\exp(-\\tau/\\tau_{\\theta})$（当 $\\tau \\ge 0$ 时，当 $\\tau  0$ 时 $h(\\tau)=0$），并由输入信号 $y(t)^2$ 驱动。因此，$\\theta(t)$ 的分布就是过程 $y(t)^2$ 过去值的加权移动平均的分布。\n\n第二，我们建立稳态期望 $\\mathbb{E}[\\theta]$ 与 $\\mathbb{E}[y^{2}]$ 之间的关系。由于 $y(t)$ 是一个平稳过程，过程 $y(t)^2$ 也是平稳的。这意味着期望 $\\mathbb{E}[y(s)^2]$ 对所有 $s$ 都是一个常数。我们将此常数值记为 $\\mathbb{E}[y^2]$。对稳态解 $\\theta_{ss}(t)$ 取期望：\n$$ \\mathbb{E}[\\theta_{ss}(t)] = \\mathbb{E}\\left[ \\frac{1}{\\tau_{\\theta}}\\int_{-\\infty}^{t} \\exp\\left(-\\frac{t-s}{\\tau_{\\theta}}\\right)y(s)^{2} ds \\right] $$\n根据期望的线性性质和 Fubini 定理，我们可以交换期望和积分算子：\n$$ \\mathbb{E}[\\theta_{ss}(t)] = \\frac{1}{\\tau_{\\theta}}\\int_{-\\infty}^{t} \\exp\\left(-\\frac{t-s}{\\tau_{\\theta}}\\right)\\mathbb{E}[y(s)^{2}] ds $$\n代入常数期望 $\\mathbb{E}[y^2]$：\n$$ \\mathbb{E}[\\theta_{ss}(t)] = \\mathbb{E}[y^2] \\left( \\frac{1}{\\tau_{\\theta}}\\int_{-\\infty}^{t} \\exp\\left(-\\frac{t-s}{\\tau_{\\theta}}\\right) ds \\right) $$\n我们来计算这个积分。令 $u = t-s$，则 $du = -ds$。积分限变为：当 $s=-\\infty$ 时 $u=\\infty$，当 $s=t$ 时 $u=0$。\n$$ \\frac{1}{\\tau_{\\theta}}\\int_{\\infty}^{0} \\exp\\left(-\\frac{u}{\\tau_{\\theta}}\\right) (-du) = \\frac{1}{\\tau_{\\theta}}\\int_{0}^{\\infty} \\exp\\left(-\\frac{u}{\\tau_{\\theta}}\\right) du = \\left[ -\\exp\\left(-\\frac{u}{\\tau_{\\theta}}\\right) \\right]_{0}^{\\infty} = -0 - (-1) = 1 $$\n滤波器冲激响应的积分为 $1$。在稳态下，$\\theta(t)$ 的统计特性是时不变的，因此我们将其期望记为 $\\mathbb{E}[\\theta]$。于是，我们得到：\n$$ \\mathbb{E}[\\theta] = \\mathbb{E}[y^2] \\cdot 1 = \\mathbb{E}[y^2] $$\n另外，按题目要求，我们可以使用遍历定理。对原始常微分方程在区间 $[0, T]$ 上取时间平均：\n$$ \\frac{1}{T}\\int_{0}^{T} \\tau_{\\theta} \\dot{\\theta}(t) dt = \\frac{1}{T}\\int_{0}^{T} y(t)^2 dt - \\frac{1}{T}\\int_{0}^{T} \\theta(t) dt $$\n$$ \\frac{\\tau_{\\theta}}{T}(\\theta(T) - \\theta(0)) = \\langle y^2 \\rangle_T - \\langle \\theta \\rangle_T $$\n其中 $\\langle \\cdot \\rangle_T$ 表示时间平均。当 $T \\to \\infty$ 时，对于一个 $\\theta(t)$ 有界的稳定系统，项 $\\frac{\\theta(T) - \\theta(0)}{T} \\to 0$。这得到 $\\lim_{T \\to \\infty} \\langle \\theta \\rangle_T = \\lim_{T \\to \\infty} \\langle y^2 \\rangle_T$。由于 $y(t)$ 是遍历的，稳定 LTI 滤波器的输出 $\\theta(t)$ 也是一个遍历过程。根据遍历定理，时间平均收敛于系综平均，因此我们得出结论 $\\mathbb{E}[\\theta] = \\mathbb{E}[y^2]$。\n\n第三，我们将 $\\mathbb{E}[\\theta]$ 用过程 $y(t)$ 的给定均值 $\\mu$ 和方差 $\\sigma^2$ 来表示。方差的定义是：\n$$ \\sigma^2 = \\mathbb{E}[(y(t) - \\mathbb{E}[y(t)])^2] $$\n已知 $\\mathbb{E}[y(t)] = \\mu$：\n$$ \\sigma^2 = \\mathbb{E}[(y - \\mu)^2] = \\mathbb{E}[y^2 - 2\\mu y + \\mu^2] $$\n根据期望的线性性：\n$$ \\sigma^2 = \\mathbb{E}[y^2] - 2\\mu\\mathbb{E}[y] + \\mathbb{E}[\\mu^2] = \\mathbb{E}[y^2] - 2\\mu(\\mu) + \\mu^2 = \\mathbb{E}[y^2] - 2\\mu^2 + \\mu^2 $$\n$$ \\sigma^2 = \\mathbb{E}[y^2] - \\mu^2 $$\n这个关系式为二阶矩 $\\mathbb{E}[y^2]$ 提供了一个表达式：\n$$ \\mathbb{E}[y^2] = \\mu^2 + \\sigma^2 $$\n最后，将此结果代入我们得到的阈值的稳态期望中：\n$$ \\mathbb{E}[\\theta] = \\mu^2 + \\sigma^2 $$\n这就是阈值变量稳态期望的最终表达式，仅用神经元输出的均值和方差表示。",
            "answer": "$$\\boxed{\\mu^{2} + \\sigma^{2}}$$"
        },
        {
            "introduction": "现在，我们将结合前面练习中的概念，观察一种涌现特性：神经元选择性的形成。通过向一个神经元呈现两种相互竞争的输入模式，你将计算预期的突触变化，并预测该神经元将学着偏好哪一种模式。这项练习具体展示了BCM规则在塑造神经表征中的作用。",
            "id": "4037209",
            "problem": "考虑一个单一线性神经元，其突触权重向量为 $w \\in \\mathbb{R}^{2}$，接收突触前输入模式 $x \\in \\mathbb{R}^{2}$。神经元的输出为 $y = w^{\\top} x$。两个不同的固定输入模式 $x^{(1)}$ 和 $x^{(2)}$ 以相等的频率出现，因此输入 $x$ 以各 $1/2$ 的概率从 $\\{x^{(1)}, x^{(2)}\\}$ 中独立抽取。假设突触可塑性遵循 Bienenstock-Cooper-Munro (BCM) 学习规则：突触的变化与突触前活动成正比，乘以一个依赖于突触后活动相对于滑动阈值的修正函数，并且滑动阈值在较慢的时间尺度上平衡到当前输入分布下突触后活动平方的长期平均值。学习率常数为 $1$。\n\n设初始突触权重为 $w = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$，两个输入模式为\n$$\nx^{(1)} = \\begin{pmatrix} 2 \\\\ \\frac{2}{5} \\end{pmatrix}, \\qquad x^{(2)} = \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{10} \\end{pmatrix}.\n$$\n将阈值视为已平衡到使用此 $w$ 和给定输入分布计算出的当前期望平方输出。使用 BCM 框架和等频率输入分布，计算：\n\n1. 在给定的 $w$ 和输入下，期望瞬时权重变化向量 $\\mathbb{E}\\!\\left[\\frac{dw}{dt}\\right]$。\n2. 在 BCM 动态下，神经元将对哪种模式产生选择性，如果对 $x^{(1)}$ 有选择性则编码为 $k = 1$，如果对 $x^{(2)}$ 有选择性则编码为 $k = 2$。\n\n将你的最终答案以单行矩阵 $\\begin{pmatrix} \\Delta w_{1}  \\Delta w_{2}  k \\end{pmatrix}$ 的形式报告，其中包含 $\\mathbb{E}\\!\\left[\\frac{dw}{dt}\\right]$ 的两个分量，后跟 $k$。请提供精确值，不要四舍五入。",
            "solution": "用户要求我解决一个基于 Bienenstock-Cooper-Munro (BCM) 学习规则的问题。\n\n### 步骤 1：提取已知条件\n- 神经元：单一线性神经元。\n- 突触权重向量：$w \\in \\mathbb{R}^{2}$，初始值为 $w = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$。\n- 突触前输入模式：$x \\in \\mathbb{R}^{2}$。\n- 神经元输出：$y = w^{\\top} x$。\n- 输入分布：两个固定模式 $x^{(1)} = \\begin{pmatrix} 2 \\\\ \\frac{2}{5} \\end{pmatrix}$ 和 $x^{(2)} = \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{10} \\end{pmatrix}$，以相等的频率出现，$P(x=x^{(1)}) = P(x=x^{(2)}) = \\frac{1}{2}$。\n- 学习规则：BCM 规则，$\\frac{dw}{dt} \\propto x \\cdot \\phi(y, \\theta_M)$。标准形式为 $\\frac{dw}{dt} = \\eta x y (y - \\theta_M)$。\n- 学习率常数：$\\eta = 1$。\n- 滑动阈值 $\\theta_M$：平衡到突触后活动平方的长期平均值，$\\theta_M = \\mathbb{E}[y^2]$。\n\n### 步骤 2：使用提取的已知条件进行验证\n- 科学依据：该问题描述了 BCM 学习规则的一个典型应用，这是计算神经科学中一个成熟的模型。所有前提都基于该模型的标准公式。\n- 良态问题：该问题提供了计算所要求数量所需的所有必要初始条件、参数和定义。存在唯一解。\n- 客观性：该问题使用精确的数学语言陈述，不包含主观或模糊的术语。\n- 完整性：该问题是自洽的。所有变量和常数都已定义。\n- 一致性：所提供的数据和条件在内部是一致的。\n\n### 步骤 3：结论与行动\n问题有效。我将继续进行解答。\n\n突触权重变化的 BCM 学习规则由以下公式给出：\n$$\n\\frac{dw}{dt} = \\eta y \\phi(y, \\theta_M) x\n$$\n问题描述暗示了标准的修正函数 $\\phi(y, \\theta_M) = y - \\theta_M$，从而得到完整的学习规则：\n$$\n\\frac{dw}{dt} = \\eta y (y - \\theta_M) x\n$$\n问题指出学习率常数为 $\\eta = 1$。滑动阈值 $\\theta_M$ 是突触后活动平方的长期平均值：\n$$\n\\theta_M = \\mathbb{E}[y^2]\n$$\n神经元的输出是 $y = w^{\\top} x$。我们已知初始权重向量为 $w = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$。\n\n首先，我们计算两种输入模式下各自的突触后活动：\n$$\ny^{(1)} = w^{\\top} x^{(1)} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 2 \\\\ \\frac{2}{5} \\end{pmatrix} = \\frac{1}{2}(2) + \\frac{1}{2}\\left(\\frac{2}{5}\\right) = 1 + \\frac{1}{5} = \\frac{6}{5}\n$$\n$$\ny^{(2)} = w^{\\top} x^{(2)} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{10} \\end{pmatrix} = \\frac{1}{2}\\left(\\frac{1}{10}\\right) + \\frac{1}{2}\\left(\\frac{1}{10}\\right) = \\frac{1}{20} + \\frac{1}{20} = \\frac{2}{20} = \\frac{1}{10}\n$$\n\n接下来，我们计算阈值 $\\theta_M$。由于模式以相等的概率 $P(x^{(1)}) = P(x^{(2)}) = \\frac{1}{2}$ 出现，期望值为：\n$$\n\\theta_M = \\mathbb{E}[y^2] = P(x^{(1)}) (y^{(1)})^2 + P(x^{(2)}) (y^{(2)})^2\n$$\n$$\n\\theta_M = \\frac{1}{2} \\left(\\frac{6}{5}\\right)^2 + \\frac{1}{2} \\left(\\frac{1}{10}\\right)^2 = \\frac{1}{2} \\left(\\frac{36}{25}\\right) + \\frac{1}{2} \\left(\\frac{1}{100}\\right) = \\frac{18}{25} + \\frac{1}{200}\n$$\n为了对这些分数求和，我们找到公分母 $200$：\n$$\n\\theta_M = \\frac{18 \\times 8}{25 \\times 8} + \\frac{1}{200} = \\frac{144}{200} + \\frac{1}{200} = \\frac{145}{200} = \\frac{29}{40}\n$$\n\n### 第 1 部分：计算期望瞬时权重变化\n期望权重变化是通过对学习规则在输入分布上取期望来找到的：\n$$\n\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\mathbb{E}\\left[y (y - \\theta_M) x\\right] = \\sum_{i=1}^{2} P(x^{(i)}) y^{(i)} (y^{(i)} - \\theta_M) x^{(i)}\n$$\n$$\n\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\frac{1}{2} y^{(1)} (y^{(1)} - \\theta_M) x^{(1)} + \\frac{1}{2} y^{(2)} (y^{(2)} - \\theta_M) x^{(2)}\n$$\n我们首先计算修正项 $(y - \\theta_M)$：\n$$\ny^{(1)} - \\theta_M = \\frac{6}{5} - \\frac{29}{40} = \\frac{48}{40} - \\frac{29}{40} = \\frac{19}{40}\n$$\n$$\ny^{(2)} - \\theta_M = \\frac{1}{10} - \\frac{29}{40} = \\frac{4}{40} - \\frac{29}{40} = -\\frac{25}{40} = -\\frac{5}{8}\n$$\n现在我们将这些值代入期望权重变化的表达式中：\n$$\n\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\frac{1}{2} \\left(\\frac{6}{5}\\right) \\left(\\frac{19}{40}\\right) x^{(1)} + \\frac{1}{2} \\left(\\frac{1}{10}\\right) \\left(-\\frac{5}{8}\\right) x^{(2)}\n$$\n$$\n\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\left(\\frac{57}{200}\\right) x^{(1)} - \\left(\\frac{5}{160}\\right) x^{(2)} = \\left(\\frac{57}{200}\\right) x^{(1)} - \\left(\\frac{1}{32}\\right) x^{(2)}\n$$\n现在，我们代入输入向量 $x^{(1)}$ 和 $x^{(2)}$：\n$$\n\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\frac{57}{200} \\begin{pmatrix} 2 \\\\ \\frac{2}{5} \\end{pmatrix} - \\frac{1}{32} \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{10} \\end{pmatrix} = \\begin{pmatrix} \\frac{114}{200} \\\\ \\frac{114}{1000} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{320} \\\\ \\frac{1}{320} \\end{pmatrix} = \\begin{pmatrix} \\frac{57}{100} \\\\ \\frac{57}{500} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{320} \\\\ \\frac{1}{320} \\end{pmatrix}\n$$\n我们分别计算每个分量。\n对于第一个分量 $\\Delta w_1$：\n$$\n\\Delta w_1 = \\frac{57}{100} - \\frac{1}{320}\n$$\n$100$ 和 $320$ 的最小公倍数是 $1600$。\n$$\n\\Delta w_1 = \\frac{57 \\times 16}{1600} - \\frac{1 \\times 5}{1600} = \\frac{912 - 5}{1600} = \\frac{907}{1600}\n$$\n对于第二个分量 $\\Delta w_2$：\n$$\n\\Delta w_2 = \\frac{57}{500} - \\frac{1}{320}\n$$\n$500$ 和 $320$ 的最小公倍数是 $8000$。\n$$\n\\Delta w_2 = \\frac{57 \\times 16}{8000} - \\frac{1 \\times 25}{8000} = \\frac{912 - 25}{8000} = \\frac{887}{8000}\n$$\n因此，期望瞬时权重变化向量为 $\\mathbb{E}\\left[\\frac{dw}{dt}\\right] = \\begin{pmatrix} \\frac{907}{1600} \\\\ \\frac{887}{8000} \\end{pmatrix}$。\n\n### 第 2 部分：确定神经元选择性\nBCM 规则在突触后活动高时导致突触增强（LTP），在突触后活动低时导致突触抑制（LTD）。阈值 $\\theta_M$ 分隔了这两种机制。修正项 $y(y - \\theta_M)$ 的符号决定了可塑性的方向。\n对于模式 $x^{(1)}$：\n修正因子为 $y^{(1)}(y^{(1)} - \\theta_M) = \\frac{6}{5}\\left(\\frac{19}{40}\\right) = \\frac{114}{200} = \\frac{57}{100} > 0$。\n正因子意味着当模式 $x^{(1)}$ 出现时，权重向量 $w$ 会向 $x^{(1)}$ 的方向移动，从而增强突触并增加神经元对该模式的响应。这对应于长时程增强（LTP）。\n\n对于模式 $x^{(2)}$：\n修正因子为 $y^{(2)}(y^{(2)} - \\theta_M) = \\frac{1}{10}\\left(-\\frac{5}{8}\\right) = -\\frac{5}{80} = -\\frac{1}{16}  0$。\n负因子意味着当模式 $x^{(2)}$ 出现时，权重向量 $w$ 会向与 $x^{(2)}$ 相反的方向移动，从而削弱突触并减少神经元对该模式的响应。这对应于长时程抑制（LTD）。\n\n由于动力学增强了对 $x^{(1)}$ 的响应并抑制了对 $x^{(2)}$ 的响应，神经元将变得对模式 $x^{(1)}$ 具有选择性。根据问题的编码方式，这对应于 $k=1$。\n\n最终答案需要期望权重变化向量的两个分量 $\\Delta w_1$ 和 $\\Delta w_2$，以及选择性指示符 $k$。\n$\\Delta w_1 = \\frac{907}{1600}$\n$\\Delta w_2 = \\frac{887}{8000}$\n$k = 1$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{907}{1600}  \\frac{887}{8000}  1 \\end{pmatrix}}\n$$"
        }
    ]
}