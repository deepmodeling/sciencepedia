{
    "hands_on_practices": [
        {
            "introduction": "Before a Physics-Informed Neural Network (PINN) can be effectively trained, the underlying physical equations must be cast into a dimensionless form. This practice guides you through the crucial first step of dimensional analysis for a Chemical-Mechanical Planarization (CMP) process, a cornerstone of modern semiconductor fabrication. By applying scaling laws to the Navier-Stokes equations, you will derive the key dimensionless groups that govern the system, a fundamental skill for setting up stable and efficient PINN-based simulations. ",
            "id": "4152003",
            "problem": "A semiconductor fabrication team is using Chemical–Mechanical Planarization (CMP) to achieve planar surfaces in a copper damascene process. The slurry is well-approximated as a Newtonian, incompressible fluid with density $\\rho$ and dynamic viscosity $\\mu$, confined between a polishing pad and the wafer by a uniform gap of thickness $h$. A generative process–layout co-synthesis engine proposes a repetitive feature pattern on the wafer with characteristic lateral length scale $\\ell$ and fill factor $\\phi$, and the tool kinematics produce a characteristic tangential slip speed $U$ at the pad–wafer interface across a single feature. The team intends to embed a Physics-Informed Neural Network (PINN) into a co-synthesis loop to predict pressure $p$, interfacial shear stress $\\tau$, and material removal rate $R$ given $(\\rho,\\mu,h,\\ell,U,k_{p},\\phi)$, where $k_{p}$ is Preston’s coefficient in the CMP removal relation. \n\nStarting from the incompressible Navier–Stokes equations for a Newtonian fluid and the continuity equation, and taking as the fundamental assumptions that the aspect ratio $\\epsilon=h/\\ell$ is small (lubrication regime), that the interfacial velocity scale is $U$, and that material removal follows Preston’s relation $R=k_{p}\\,p\\,U$, perform a dimensional analysis that is suitable for PINN-compatible nondimensionalization. Your objectives are:\n- Use first-principles scaling to determine the characteristic magnitudes of $p$, $\\tau$, and $R$ in terms of $(\\rho,\\mu,h,\\ell,U,k_{p})$.\n- Construct the minimal set of $3$ dimensionless groups that control the magnitudes of pressure, shear stress, and removal rate under lubrication flow.\n- Identify the leading-order small parameter that quantifies the ratio of inertial to viscous effects in the axial momentum balance and state it as a dimensionless expression in terms of $(\\rho,\\mu,h,\\ell,U)$.\n- Do not assume symmetry beyond the lubrication ordering, and do not invoke empirical hydrodynamic formulas other than Preston’s relation. Explain how the aspect ratio $\\epsilon$ enters the inertial-viscous comparison.\n\nYour final answer must be a single row matrix containing, in order, the $3$ dimensionless groups you defined for pressure, shear, and removal rate, followed by the single dimensionless parameter that justifies neglecting inertia under lubrication ordering. Express the final answer as closed-form analytic expressions. The quantities in your answer must be dimensionless, and no units are required for the final answer.",
            "solution": "We begin with the incompressible Navier–Stokes equations for a Newtonian fluid and the continuity equation. Denote by $x$ the lateral coordinate along the wafer surface and by $z$ the coordinate normal to the wafer. The equations are\n$$\n\\rho \\left( \\frac{\\partial \\mathbf{v}}{\\partial t} + \\mathbf{v}\\cdot\\nabla \\mathbf{v} \\right) = -\\nabla p + \\mu \\nabla^{2} \\mathbf{v}, \\quad \\nabla \\cdot \\mathbf{v} = 0,\n$$\nwhere $\\mathbf{v}=(u,w)$ are the lateral and normal velocity components, respectively.\n\nWe assume steady operation so that $\\partial \\mathbf{v}/\\partial t$ is negligible on the averaging timescale, and we adopt the lubrication regime with aspect ratio $\\epsilon=h/\\ell \\ll 1$, where $h$ is the gap thickness and $\\ell$ is the lateral length scale set by the generative layout synthesis. Let $U$ be the characteristic lateral slip speed at the interface. From continuity in a slender gap, the normal velocity scale is suppressed by the aspect ratio, giving\n$$\nu \\sim U, \\quad w \\sim U \\frac{h}{\\ell} = U \\epsilon.\n$$\n\nWe now scale derivatives according to $x \\sim \\ell$ and $z \\sim h$, so that $\\partial/\\partial x \\sim 1/\\ell$ and $\\partial/\\partial z \\sim 1/h$. Consider the axial ($x$) momentum equation at leading order. The dominant viscous term arises from the second derivative in $z$, while pressure gradients in $x$ balance this viscous stress in lubrication flow:\n$$\n\\text{viscous: } \\mu \\frac{\\partial^{2} u}{\\partial z^{2}} \\sim \\mu \\frac{U}{h^{2}}, \\quad \\text{pressure gradient: } \\frac{\\partial p}{\\partial x} \\sim \\frac{p}{\\ell}.\n$$\nBalancing these gives the characteristic pressure scale\n$$\n\\frac{p}{\\ell} \\sim \\mu \\frac{U}{h^{2}} \\quad \\Rightarrow \\quad p \\sim \\mu U \\frac{\\ell}{h^{2}}.\n$$\nThe interfacial shear stress is set by the viscous gradient at the wall,\n$$\n\\tau \\sim \\mu \\frac{\\partial u}{\\partial z} \\sim \\mu \\frac{U}{h}.\n$$\nFor material removal rate, we adopt Preston’s relation, which is a well-tested empirical law in CMP at the process scale,\n$$\nR = k_{p} \\, p \\, U,\n$$\nso the characteristic removal rate scale is\n$$\nR \\sim k_{p} \\left( \\mu U \\frac{\\ell}{h^{2}} \\right) U = k_{p} \\mu U^{2} \\frac{\\ell}{h^{2}}.\n$$\n\nTo produce PINN-compatible nondimensional variables, we normalize each field by its characteristic scale:\n- Define the dimensionless pressure $p^{\\ast}$ by $p = \\left( \\mu U \\ell / h^{2} \\right) p^{\\ast}$. Equivalently, the controlling dimensionless group for pressure is\n$$\n\\Pi_{p} \\equiv \\frac{p h^{2}}{\\mu U \\ell}.\n$$\n- Define the dimensionless shear $\\tau^{\\ast}$ by $\\tau = \\left( \\mu U / h \\right) \\tau^{\\ast}$. Equivalently, the controlling dimensionless group for shear is\n$$\n\\Pi_{\\tau} \\equiv \\frac{\\tau h}{\\mu U}.\n$$\n- Define the dimensionless removal $R^{\\ast}$ by $R = \\left( k_{p} \\mu U^{2} \\ell / h^{2} \\right) R^{\\ast}$. Equivalently, the controlling dimensionless group for removal is\n$$\n\\Pi_{R} \\equiv \\frac{R h^{2}}{k_{p} \\mu U^{2} \\ell}.\n$$\n\nNext, we justify neglecting inertia by comparing inertial and viscous terms in the axial momentum balance. The convective inertia scales as\n$$\n\\rho \\, u \\frac{\\partial u}{\\partial x} \\sim \\rho \\, U \\frac{U}{\\ell} = \\rho \\frac{U^{2}}{\\ell},\n$$\nwhile the dominant viscous term scales as\n$$\n\\mu \\frac{\\partial^{2} u}{\\partial z^{2}} \\sim \\mu \\frac{U}{h^{2}}.\n$$\nThe ratio of inertial to viscous effects in the axial momentum equation is therefore\n$$\n\\frac{\\text{inertia}}{\\text{viscous}} \\sim \\frac{\\rho \\, U^{2} / \\ell}{\\mu \\, U / h^{2}} = \\frac{\\rho U h^{2}}{\\mu \\ell}.\n$$\nDefine the corresponding dimensionless small parameter\n$$\n\\Pi_{I} \\equiv \\frac{\\rho U h^{2}}{\\mu \\ell}.\n$$\nThis parameter can be written as $\\Pi_{I} = \\left( \\rho U h / \\mu \\right) \\left( h / \\ell \\right)$, which is the product of a Reynolds number based on the gap $h$ and the aspect ratio $\\epsilon$. Because $\\epsilon \\ll 1$, even moderate values of $\\rho U h / \\mu$ lead to $\\Pi_{I} \\ll 1$, which justifies neglecting inertia in lubrication ordering. In the context of a Physics-Informed Neural Network, using the nondimensional variables associated with $\\Pi_{p}$, $\\Pi_{\\tau}$, and $\\Pi_{R}$ ensures balanced residual magnitudes, while $\\Pi_{I}$ quantifies the regime where the PINN should enforce Stokes-lubrication dynamics.\n\nCollecting the results, the minimal set of $3$ controlling dimensionless groups for pressure, shear, and removal rate, together with the single dimensionless parameter for inertia, are\n$$\n\\Pi_{p} = \\frac{p h^{2}}{\\mu U \\ell}, \\quad \\Pi_{\\tau} = \\frac{\\tau h}{\\mu U}, \\quad \\Pi_{R} = \\frac{R h^{2}}{k_{p} \\mu U^{2} \\ell}, \\quad \\Pi_{I} = \\frac{\\rho U h^{2}}{\\mu \\ell}.\n$$\nThese groups arise directly from the well-tested lubrication scaling of the incompressible Navier–Stokes equations and Preston’s relation, and they provide a principled PINN nondimensionalization and a generative process–layout co-synthesis linkage via the appearance of $\\ell$ and $U$ determined by the layout and tool kinematics.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{p h^{2}}{\\mu U \\ell} & \\frac{\\tau h}{\\mu U} & \\frac{R h^{2}}{k_{p} \\mu U^{2} \\ell} & \\frac{\\rho U h^{2}}{\\mu \\ell}\\end{pmatrix}}$$"
        },
        {
            "introduction": "This exercise provides a complete, end-to-end implementation of a generative process-layout co-synthesis loop for a simplified 1D Chemical-Mechanical Planarization (CMP) model. You will develop code to optimize a layout density profile to achieve maximum post-process uniformity, a key objective in manufacturing. Furthermore, you will construct and train a simple PINN-based linear surrogate model to approximate the process physics, offering a tangible example of how PINNs serve as differentiable surrogates within a holistic optimization framework. ",
            "id": "4151984",
            "problem": "You are tasked with constructing a self-contained program that models one-dimensional Chemical Mechanical Planarization (CMP) mechanics and evaluates Physics-Informed Neural Network (PINN) surrogate quality for generative process–layout co-synthesis in semiconductor manufacturing process modeling. Chemical Mechanical Planarization (CMP) removes material from a wafer surface by slurry-driven abrasive action under pad-induced pressure. The Preston removal law states that local removal rate is proportional to local pressure and relative velocity. To obtain a computationally tractable model suitable for surrogate learning and co-synthesis, assume a one-dimensional spatial domain with position $x \\in [0,1]$, time $t \\in [0,T]$, and the film thickness $h(x,t)$ evolving under a linearized elastic foundation model for pad–wafer contact. Specifically, use a time-evolution law derived from Preston's law in the form\n$$\n\\frac{\\partial h(x,t)}{\\partial t} \\;=\\; -\\,c\\,\\left(h(x,t) - z_{\\mathrm{ref}}(x)\\right),\n$$\nwhere $c > 0$ is an effective removal coefficient in $\\mathrm{s}^{-1}$ that consolidates the Preston coefficient, pad pressure sensitivity, and velocity, and $z_{\\mathrm{ref}}(x)$ is the elastic-contact reference height produced by the local pattern density $d(x)$. For generative process–layout co-synthesis, suppose the reference height is an affine function of density,\n$$\nz_{\\mathrm{ref}}(x) \\;=\\; b_0 \\;+\\; b_1\\,d(x),\n$$\nwith $b_0$ and $b_1$ in $\\mathrm{nm}$, and $d(x)$ a dimensionless fraction constrained by $d_{\\min} \\le d(x) \\le d_{\\max}$ and $\\frac{1}{L}\\int_0^1 d(x)\\,dx = d_{\\mathrm{bar}}$, where $L = 1$ is the domain length. The initial thickness is specified by a baseline plus sinusoidal topography,\n$$\nh(x,0) \\;=\\; h_{\\mathrm{base}} \\;+\\; A \\,\\sin\\!\\left( 2\\pi f x \\right),\n$$\nwhere angles are in radians, $h_{\\mathrm{base}}$ and $A$ are in $\\mathrm{nm}$, and $f$ is a dimensionless spatial frequency. The CMP target thickness for uniformity assessment is $h_{\\mathrm{target}}$ in $\\mathrm{nm}$.\n\nYour program must perform the following tasks for each test case:\n- Implement generative co-synthesis of the layout density $d(x)$ on a discrete grid of $N$ uniformly spaced points in $[0,1]$ that minimizes the variance of the final thickness $h(x,T)$ subject to the box constraints $d_{\\min} \\le d(x) \\le d_{\\max}$ and the average density constraint $\\frac{1}{N}\\sum_{i=1}^N d_i = d_{\\mathrm{bar}}$, where $d_i$ is the discretized density at grid point $i$. Express all densities as decimals, not percentages. Assume the CMP dynamics above and the given $z_{\\mathrm{ref}}(x)$ model.\n- Construct a Physics-Informed Neural Network (PINN) surrogate for $h(x,t)$ of the form\n$$\nu_{\\theta}(x,t) \\;=\\; A_0 \\;+\\; A_1 t \\;+\\; A_2 \\,\\phi_1(x) \\;+\\; A_3 \\,\\phi_2(x) \\;+\\; A_4\\,\\phi_1(x)\\,t \\;+\\; A_5\\,\\phi_2(x)\\,t,\n$$\nwhere $\\phi_1(x) = \\sin(\\pi x)$ and $\\phi_2(x) = \\sin(2\\pi x)$, and $\\theta = (A_0,\\ldots,A_5)$ are parameters to be fit. Fit $\\theta$ by minimizing the squared Physics-Informed residual at a set of spatio-temporal collocation points $\\{(x_i,t_j)\\}$ together with a squared penalty for the initial condition $u_{\\theta}(x,0) \\approx h(x,0)$ on the same spatial grid. The Physics-Informed residual is\n$$\nr(x,t) \\;=\\; \\frac{\\partial u_{\\theta}}{\\partial t}(x,t) \\;+\\; c \\left( u_{\\theta}(x,t) - z_{\\mathrm{ref}}(x) \\right),\n$$\nand the initial condition penalty enforces $u_{\\theta}(x,0) \\approx h(x,0)$. Use a least-squares fit over a fixed number of collocation points for both residual and initial condition penalty, and report the root-mean-square (RMS) of $r(x,t)$ across the residual collocation points as a dimensionless float. Angles in the sine functions must be interpreted in radians.\n- Compute the final thickness $h(x,T)$ implied by the CMP model on the discrete grid, and report the thickness uniformity as the standard deviation of $h(x,T)$ in nanometers (nm).\n\nTest suite and parameters:\n- Use $N = 64$ grid points for the spatial discretization $x \\in [0,1]$.\n- Use $M_t = 11$ collocation points in time for the Physics-Informed residual, uniformly spaced in $[0,T]$.\n- Use an initial condition penalty weight $w_{\\mathrm{IC}} = 10$.\n\nProvide three test cases:\n1. Happy path case:\n    - $h_{\\mathrm{base}} = 100\\,\\mathrm{nm}$, $A = 10\\,\\mathrm{nm}$, $f = 1$, $T = 10\\,\\mathrm{s}$, $c = 0.3\\,\\mathrm{s}^{-1}$,\n    - $b_0 = 95\\,\\mathrm{nm}$, $b_1 = 5\\,\\mathrm{nm}$,\n    - $d_{\\min} = 0.2$, $d_{\\max} = 0.8$, $d_{\\mathrm{bar}} = 0.5$,\n    - $h_{\\mathrm{target}} = 95\\,\\mathrm{nm}$.\n2. Boundary condition case (uniform initial thickness):\n    - $h_{\\mathrm{base}} = 100\\,\\mathrm{nm}$, $A = 0\\,\\mathrm{nm}$, $f = 1$, $T = 10\\,\\mathrm{s}$, $c = 0.1\\,\\mathrm{s}^{-1}$,\n    - $b_0 = 95\\,\\mathrm{nm}$, $b_1 = 6\\,\\mathrm{nm}$,\n    - $d_{\\min} = 0.2$, $d_{\\max} = 0.8$, $d_{\\mathrm{bar}} = 0.5$,\n    - $h_{\\mathrm{target}} = 95\\,\\mathrm{nm}$.\n3. Edge case (weak polishing and tight density bounds):\n    - $h_{\\mathrm{base}} = 110\\,\\mathrm{nm}$, $A = 20\\,\\mathrm{nm}$, $f = 2$, $T = 5\\,\\mathrm{s}$, $c = 0.01\\,\\mathrm{s}^{-1}$,\n    - $b_0 = 100\\,\\mathrm{nm}$, $b_1 = 10\\,\\mathrm{nm}$,\n    - $d_{\\min} = 0.45$, $d_{\\max} = 0.55$, $d_{\\mathrm{bar}} = 0.5$,\n    - $h_{\\mathrm{target}} = 100\\,\\mathrm{nm}$.\n\nYour program must:\n- Discretize the spatial domain $x \\in [0,1]$ into $N$ uniformly spaced points.\n- Compute the co-synthesized density $d(x)$ that minimizes the variance of $h(x,T)$ subject to the bounds and average constraint; treat densities as decimals.\n- Fit the PINN surrogate parameters by linear least squares on collocation points for the residual and the initial condition penalty, and compute the RMS Physics-Informed residual.\n- Compute the standard deviation of the final thickness $h(x,T)$ as the uniformity metric in $\\mathrm{nm}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain six floats in the following order: for test case $1$, the thickness uniformity in $\\mathrm{nm}$ followed by the RMS Physics-Informed residual; then for test case $2$, the thickness uniformity followed by the RMS Physics-Informed residual; then for test case $3$, the thickness uniformity followed by the RMS Physics-Informed residual. For example: $[u_1,r_1,u_2,r_2,u_3,r_3]$.\n\nAll angles must be in radians. All thickness-related outputs must be expressed in nanometers (nm). All densities must be expressed as decimals (not with a percentage sign). The final output must be a single line in the specified format without any additional text.",
            "solution": "The problem statement is scientifically grounded, well-posed, and provides all necessary information to proceed with a solution. It presents a simplified but coherent model of Chemical Mechanical Planarization (CMP) and a clear set of tasks for co-synthesis and surrogate model evaluation. The problem is deemed valid.\n\nThe solution is approached in three main stages for each test case: (1) generative co-synthesis of the optimal layout density profile $d(x)$; (2) fitting a Physics-Informed Neural Network (PINN) surrogate model and evaluating its quality; and (3) calculating the final post-CMP thickness uniformity.\n\n**1. Generative Layout Co-synthesis**\n\nThe core of the co-synthesis task is to determine the spatial layout density profile $d(x)$ that minimizes thickness variation after a specified CMP duration $T$. The physical process is governed by the linearized CMP model:\n$$\n\\frac{\\partial h(x,t)}{\\partial t} = -c \\left(h(x,t) - z_{\\mathrm{ref}}(x)\\right)\n$$\nwhere $z_{\\mathrm{ref}}(x) = b_0 + b_1 d(x)$. For any fixed position $x$, this is a first-order linear ordinary differential equation in time $t$. Its solution, given the initial condition $h(x,0)$, is:\n$$\nh(x,t) = z_{\\mathrm{ref}}(x) + \\left[h(x,0) - z_{\\mathrm{ref}}(x)\\right]e^{-ct}\n$$\nThe final thickness at time $t=T$ can be rearranged as:\n$$\nh(x,T) = z_{\\mathrm{ref}}(x)\\left(1 - e^{-cT}\\right) + h(x,0)e^{-cT}\n$$\nSubstituting the model for $z_{\\mathrm{ref}}(x)$:\n$$\nh(x,T) = \\left(b_0 + b_1 d(x)\\right)\\left(1 - e^{-cT}\\right) + h(x,0)e^{-cT}\n$$\nTo minimize the variance of the final thickness $h(x,T)$, we aim to make $h(x,T)$ a constant, let's call it $H_{\\mathrm{final}}$, for all $x$. By setting $h(x,T) = H_{\\mathrm{final}}$ and solving for $d(x)$, we find the ideal density profile $d^*(x)$ that would achieve perfect planarization:\n$$\nd^*(x) = \\frac{H_{\\mathrm{final}} - b_0(1-e^{-cT})}{b_1(1-e^{-cT})} - \\frac{e^{-cT}}{b_1(1-e^{-cT})}h(x,0)\n$$\nThis expression can be simplified. The constant $H_{\\mathrm{final}}$ is unknown but is determined by the average density constraint, $\\frac{1}{L}\\int_0^1 d(x) dx = d_{\\mathrm{bar}}$. By integrating the expression for $d^*(x)$ and applying this constraint, we find that the ideal density profile can be expressed relative to the mean values:\n$$\nd^*(x) = d_{\\mathrm{bar}} - K_c \\left(h(x,0) - \\overline{h(0)}\\right), \\quad \\text{where} \\quad K_c = \\frac{e^{-cT}}{b_1(1-e^{-cT})}\n$$\nand $\\overline{h(0)}$ is the spatial average of the initial thickness. This ideal profile $d^*(x)$ must be realized under the physical and design-rule constraints $d_{\\min} \\le d(x) \\le d_{\\max}$ and the average density constraint. The problem thus becomes a constrained optimization problem. The solution is found by first computing the ideal unconstrained profile $d^*(x)$ on the discrete grid $x_i$, and then finding a global offset $\\lambda$ such that the profile $d_i = \\text{clip}(d^*_i + \\lambda, d_{\\min}, d_{\\max})$ satisfies the average constraint $\\frac{1}{N}\\sum_i d_i = d_{\\mathrm{bar}}$. This scalar value $\\lambda$ acts as a Lagrange multiplier and is found numerically using a root-finding algorithm. Once the optimal constrained density $d_i$ is determined, the final thickness profile $h(x_i, T)$ is computed.\n\n**2. Physics-Informed Neural Network (PINN) Surrogate**\n\nThe problem specifies a simple surrogate model, or \"tiny PINN\", which is linear in its parameters $\\theta = (A_0, \\dots, A_5)$:\n$$\nu_{\\theta}(x,t) = A_0 + A_1 t + A_2 \\sin(\\pi x) + A_3 \\sin(2\\pi x) + A_4 t\\sin(\\pi x) + A_5 t\\sin(2\\pi x)\n$$\nThe parameters $\\theta$ are determined by minimizing a loss function comprising two parts: a penalty on the governing equation's residual and a penalty on the initial condition mismatch. The Physics-Informed residual is:\n$$\nr(x,t) = \\frac{\\partial u_{\\theta}}{\\partial t}(x,t) + c \\left( u_{\\theta}(x,t) - z_{\\mathrm{ref}}(x) \\right)\n$$\nThe partial derivative with respect to time is $\\frac{\\partial u_{\\theta}}{\\partial t} = A_1 + A_4 \\sin(\\pi x) + A_5 \\sin(2\\pi x)$.\nThe total loss function to be minimized is the sum of squared errors:\n$$\nL(\\theta) = \\sum_{(x_i,t_j)} \\left[ r(x_i, t_j) \\right]^2 + w_{\\mathrm{IC}} \\sum_{x_i} \\left[ u_{\\theta}(x_i, 0) - h(x_i, 0) \\right]^2\n$$\nwhere the sums are over a grid of collocation points. Since both $r(x,t)$ and $u_{\\theta}(x,0)$ are linear functions of the parameters $\\theta$, this is a linear least-squares problem. We can formulate it as $\\min_{\\theta} ||\\mathbf{A}\\theta - \\mathbf{b}||_2^2$. The system matrix $\\mathbf{A}$ and target vector $\\mathbf{b}$ are constructed by assembling rows corresponding to each term in the loss function. There are $N \\times M_t$ rows for the PDE residual evaluated at the spatio-temporal collocation points and $N$ rows for the weighted initial condition penalty. This system is then solved for $\\theta$ using a standard numerical linear algebra routine.\n\n**3. Evaluation Metrics**\n\nTwo key metrics are computed for each test case:\n1.  **Thickness Uniformity**: This quantifies the success of the co-synthesis. It is calculated as the standard deviation of the final thickness profile, $\\sigma_{h(T)} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (h(x_i, T) - \\overline{h(T)})^2}$, in nanometers. A smaller value indicates better uniformity.\n2.  **PINN Surrogate Quality**: This measures how well the fitted PINN surrogate respects the underlying physics. It is calculated as the Root-Mean-Square (RMS) of the Physics-Informed residual $r(x,t)$ evaluated at the $N \\times M_t$ collocation points using the optimal parameters $\\theta$. A smaller value indicates a better physical fit.\n\nThe following implementation performs these calculations for each of the three test cases provided.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Main function to run the CMP co-synthesis and PINN evaluation for all test cases.\n    \"\"\"\n    \n    # Global parameters\n    N = 64  # Number of spatial grid points\n    M_t = 11  # Number of temporal collocation points\n    w_IC = 10.0  # Initial condition penalty weight\n\n    # Define test cases\n    test_cases = [\n        # Case 1: Happy path\n        {'h_base': 100.0, 'A': 10.0, 'f': 1.0, 'T': 10.0, 'c': 0.3,\n         'b0': 95.0, 'b1': 5.0, 'd_min': 0.2, 'd_max': 0.8, 'd_bar': 0.5},\n        # Case 2: Boundary condition (uniform initial thickness)\n        {'h_base': 100.0, 'A': 0.0, 'f': 1.0, 'T': 10.0, 'c': 0.1,\n         'b0': 95.0, 'b1': 6.0, 'd_min': 0.2, 'd_max': 0.8, 'd_bar': 0.5},\n        # Case 3: Edge case (weak polishing, tight bounds)\n        {'h_base': 110.0, 'A': 20.0, 'f': 2.0, 'T': 5.0, 'c': 0.01,\n         'b0': 100.0, 'b1': 10.0, 'd_min': 0.45, 'd_max': 0.55, 'd_bar': 0.5}\n    ]\n\n    results = []\n    \n    # Spatial grid\n    x = np.linspace(0.0, 1.0, N)\n\n    for case in test_cases:\n        # Unpack parameters\n        h_base, A, f, T, c = case['h_base'], case['A'], case['f'], case['T'], case['c']\n        b0, b1, d_min, d_max, d_bar = case['b0'], case['b1'], case['d_min'], case['d_max'], case['d_bar']\n\n        # --- Part 1: Generative Layout Co-synthesis ---\n\n        # Initial thickness profile\n        h0 = h_base + A * np.sin(2 * np.pi * f * x)\n        \n        # Calculate ideal (unconstrained) density profile d*(x)\n        # Handle the case where c or T are very small, making 1-exp(-cT) close to zero\n        exp_m_ct = np.exp(-c * T)\n        if b1 == 0 or (1 - exp_m_ct) < 1e-9:\n            # If b1 is 0 or polishing effect is negligible, density has no effect.\n            # A uniform density is optimal in this scenario.\n            d_star = np.full(N, d_bar)\n        else:\n            Kc = exp_m_ct / (b1 * (1 - exp_m_ct))\n            h0_bar = np.mean(h0)\n            d_star = d_bar - Kc * (h0 - h0_bar)\n\n        # Function to find the root for lambda (Lagrange multiplier)\n        def density_avg_error(lam):\n            return np.mean(np.clip(d_star + lam, d_min, d_max)) - d_bar\n        \n        # Find lambda to enforce the average density constraint\n        # Bracket for the root finder\n        bracket_low = d_min - np.max(d_star)\n        bracket_high = d_max - np.min(d_star)\n        \n        # It's possible for the function to be flat if d_star is completely out of bounds.\n        # In this case, clipping dominates and lambda has no effect within a range.\n        # root_scalar is robust to this.\n        sol = root_scalar(density_avg_error, bracket=[bracket_low, bracket_high], method='brentq')\n        lambda_opt = sol.root\n        \n        # Optimal constrained density profile\n        d_opt = np.clip(d_star + lambda_opt, d_min, d_max)\n\n        # --- Part 2: Final Thickness and Uniformity Metric ---\n\n        # Calculate final thickness h(x, T) using the optimized density\n        z_ref = b0 + b1 * d_opt\n        hT = z_ref * (1 - exp_m_ct) + h0 * exp_m_ct\n        \n        # Metric 1: Uniformity (standard deviation of final thickness)\n        uniformity = np.std(hT)\n        results.append(uniformity)\n\n        # --- Part 3: PINN Surrogate Fitting and Quality Metric ---\n\n        # Temporal collocation grid\n        t_coll = np.linspace(0.0, T, M_t)\n\n        # Set up the linear least-squares system A*theta = b\n        num_pde_rows = N * M_t\n        num_ic_rows = N\n        num_rows = num_pde_rows + num_ic_rows\n        num_cols = 6  # Number of parameters in theta\n        \n        A_matrix = np.zeros((num_rows, num_cols))\n        b_vector = np.zeros(num_rows)\n        \n        # Basis functions evaluated at spatial points\n        phi1 = np.sin(np.pi * x)\n        phi2 = np.sin(2 * np.pi * x)\n\n        # Populate rows for the PDE residual\n        for i in range(N):\n            for j in range(M_t):\n                row_idx = i * M_t + j\n                tj = t_coll[j]\n                \n                # Coefficients for theta = [A0, A1, A2, A3, A4, A5]\n                A_matrix[row_idx, 0] = c\n                A_matrix[row_idx, 1] = 1.0 + c * tj\n                A_matrix[row_idx, 2] = c * phi1[i]\n                A_matrix[row_idx, 3] = c * phi2[i]\n                A_matrix[row_idx, 4] = phi1[i] * (1.0 + c * tj)\n                A_matrix[row_idx, 5] = phi2[i] * (1.0 + c * tj)\n                \n                b_vector[row_idx] = c * z_ref[i]\n\n        # Populate rows for the initial condition penalty\n        sqrt_w_IC = np.sqrt(w_IC)\n        for i in range(N):\n            row_idx = num_pde_rows + i\n            \n            # Coefficients for u(x,0) = A0 + A2*phi1 + A3*phi2\n            A_matrix[row_idx, 0] = sqrt_w_IC * 1.0\n            A_matrix[row_idx, 2] = sqrt_w_IC * phi1[i]\n            A_matrix[row_idx, 3] = sqrt_w_IC * phi2[i]\n            \n            b_vector[row_idx] = sqrt_w_IC * h0[i]\n            \n        # Solve the linear system for theta\n        theta, _, _, _ = np.linalg.lstsq(A_matrix, b_vector, rcond=None)\n        \n        # Metric 2: RMS of the physics-informed residual\n        # Calculate residuals using only the PDE part of the system\n        pde_residuals = A_matrix[:num_pde_rows, :] @ theta - b_vector[:num_pde_rows]\n        rms_residual = np.sqrt(np.mean(pde_residuals**2))\n        results.append(rms_residual)\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.7f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world manufacturing processes, such as optical lithography, are often governed by long-range physical interactions that pose a significant computational challenge for standard PINNs. This practice tackles this issue head-on by demonstrating how the domain decomposition strategy of Extended PINNs (XPINNs) can be combined with efficient FFT-based convolutions. By implementing this hybrid approach, you will explore the critical trade-off between computational efficiency and model accuracy when dealing with non-local physics. ",
            "id": "4152028",
            "problem": "Consider scalar optical projection lithography modeled in one spatial dimension under the space-invariant incoherent imaging approximation. In this approximation, the aerial image $I(x)$ is the linear convolution of the mask layout $M(x)$ with the intensity point spread function (optical kernel) $K(x)$, i.e., $I(x) = (K * M)(x)$. Assume a normalized spatial coordinate $x \\in [0,1)$, discretized on a uniform grid of $N$ points with spacing $\\Delta x = 1/N$. The long-range optical kernel is modeled by a physically plausible tail that combines exponential and algebraic decay, $$K(x) \\propto \\frac{\\exp(-|x|/\\ell)}{1 + (|x|/a)^2},$$ and is normalized so that the discrete sum of samples equals $1$. The ground-truth aerial image $I_{\\mathrm{true}}$ is defined by the exact linear convolution computed on the full domain via a frequency-domain method. To handle the long-range nature of $K(x)$ efficiently, you are asked to implement an Extended Physics-Informed Neural Network (XPINN) inspired block-FFT method: partition the domain into $S$ equal subdomains and, for each subdomain, compute the convolution on a local window extended by an overlap of $o$ samples on both sides using a Fast Fourier Transform (FFT)-based convolution. Truncate the kernel to radius $R = \\min\\{o, H\\}$, where $H$ is the half-length (in samples) of the full kernel support determined by a threshold $\\tau$ on the kernel amplitude. Assemble the full-domain approximation by retaining only the central (non-overlapped) portion from each subdomain computation.\n\nStart from the following fundamental bases and core definitions, without using any shortcut formulas beyond them:\n- The incoherent imaging approximation $I(x) = (K * M)(x)$ and its discrete form on a uniform grid as a linear convolution.\n- The definition of a Fast Fourier Transform (FFT) convolution as a method to evaluate linear convolution via the Discrete Fourier Transform (DFT), using adequate zero padding for linear (non-circular) convolution.\n- The XPINN (Extended Physics-Informed Neural Network) idea of domain decomposition to reduce the effective receptive field per subproblem, and enforcing physics via the convolutional residual locally on each subdomain window.\n\nYou must design a program that:\n- Constructs a deterministic binary mask layout $M(x)$ on $N$ grid points as $M[n] = 1$ if $\\sin(2\\pi f_0 x_n) + 0.3 \\sin(2\\pi \\cdot 3 f_0 \\, x_n) > 0$ and $M[n] = 0$ otherwise, with $x_n = n/N$ and frequency $f_0$ in cycles per unit length.\n- Builds the kernel $K$ by sampling $K(x) \\propto \\exp(-|x|/\\ell)/(1 + (|x|/a)^2)$ on the discrete grid about $x=0$, truncating to the smallest symmetric support of half-length $H$ (in samples) such that the non-normalized kernel amplitude at $H\\Delta x$ is below a threshold $\\tau$. Normalize $K$ so that the discrete sum equals $1$.\n- Computes the ground-truth image $I_{\\mathrm{true}}$ via FFT-based linear convolution on the full domain (mode “same”).\n- Implements the XPINN-inspired block-FFT approximation $I_{\\mathrm{XPINN}}$ by:\n  - Splitting $M$ into $S$ equal subdomains (assume $S$ divides $N$ exactly), with each subdomain of length $N/S$.\n  - For each subdomain $i$, extracting a window of length $N/S + 2o$ centered on the subdomain (using zero-padding outside $[0,N-1]$ as needed), convolving the windowed mask with the truncated kernel of radius $R = \\min\\{o,H\\}$ via FFT-based linear convolution, and retaining only the central $N/S$ samples (discarding the overlapped margins).\n  - Concatenating the retained central pieces to form $I_{\\mathrm{XPINN}}$ of length $N$.\n- Quantifies the accuracy by the relative discrete $\\ell_2$ error $$\\varepsilon = \\frac{\\|I_{\\mathrm{XPINN}} - I_{\\mathrm{true}}\\|_2}{\\|I_{\\mathrm{true}}\\|_2}.$$\n- Estimates the peak memory trade-off between full-domain FFT convolution and XPINN block-FFT convolution by the following proxy model in bytes. Let $L_{\\mathrm{sig}}$ denote the signal length used in a given FFT convolution, $L_{\\mathrm{ker}}$ the kernel length, and $$P = 2^{\\lceil \\log_2(L_{\\mathrm{sig}} + L_{\\mathrm{ker}} - 1) \\rceil}$$ the FFT length. Approximate the peak memory as\n  $$B(L_{\\mathrm{sig}}, L_{\\mathrm{ker}}) = 8\\,(L_{\\mathrm{sig}} + L_{\\mathrm{ker}}) + 16 \\times 3 P,$$\n  corresponding to storing the real signal and kernel (in $64$-bit floats) and three complex arrays of length $P$ (in $128$-bit complex) for forward transforms and the spectral product. Use this same model for both the full-domain and the block-domain convolutions, with the latter evaluated at the maximum window size $L_{\\mathrm{sig}} = N/S + 2o$ and truncated kernel length $L_{\\mathrm{ker}} = 2\\min\\{o,H\\} + 1$. Report the dimensionless memory ratio\n  $$\\rho = \\frac{B\\big(N,\\; L_{\\mathrm{ker,full}}\\big)}{B\\big(N/S + 2o,\\; 2\\min\\{o,H\\} + 1\\big)},$$\n  where $L_{\\mathrm{ker,full}} = 2H + 1$ is the full kernel length. Note that a larger $\\rho$ indicates the full-domain method uses more peak memory than the block method; $\\rho < 1$ indicates the block method uses more peak memory under this model.\n\nUse the following fixed parameters for all tests:\n- Grid size $N = 4096$.\n- Base frequency $f_0 = 20$.\n- Kernel parameters $\\ell = 0.06$, $a = 0.01$, and truncation threshold $\\tau = 10^{-6}$.\n- Angle is not used in this problem; no angle units are required.\n- No physical unit is requested for the outputs; all reported quantities are dimensionless.\n\nYour program must run the following test suite of $(S,o)$ values, in this exact order:\n- Test $1$: $S = 4$, $o = 64$.\n- Test $2$: $S = 4$, $o = 1400$.\n- Test $3$: $S = 16$, $o = 256$.\n- Test $4$: $S = 8$, $o = 0$.\n\nFor each test $i$, compute the pair $(\\varepsilon_i, \\rho_i)$, where $\\varepsilon_i$ is the relative $\\ell_2$ error and $\\rho_i$ is the memory ratio defined above. The final program output must be a single line containing a comma-separated list of $8$ floating-point numbers enclosed in square brackets, corresponding to the flattened list $[\\varepsilon_1, \\rho_1, \\varepsilon_2, \\rho_2, \\varepsilon_3, \\rho_3, \\varepsilon_4, \\rho_4]$, with each value rounded to exactly $6$ decimal places.",
            "solution": "The user-provided problem has been analyzed and is deemed valid. The problem is scientifically grounded in the principles of Fourier optics and computational physics, is well-posed with a clear and complete set of instructions, and is devoid of any ambiguities or contradictions. We shall proceed with a complete solution.\n\nThe problem asks for an implementation and comparison of two methods for computing the aerial image in optical projection lithography, which is modeled as a linear convolution. The first method is a direct, full-domain convolution using the Fast Fourier Transform (FFT). The second is a domain decomposition method, inspired by Extended Physics-Informed Neural Networks (XPINN), which computes the convolution in smaller, overlapping blocks. The goal is to evaluate the trade-off between accuracy and computational memory for different parameters of the block-based method.\n\nOur procedure is as follows:\n1.  Define the discrete simulation grid and construct the binary mask layout $M(x)$ according to the provided periodic function.\n2.  Construct the discrete optical kernel $K(x)$. This involves determining its effective support half-width, $H$, based on an amplitude threshold $\\tau$, sampling the function on a symmetric grid of $2H+1$ points, and normalizing the result.\n3.  Compute the ground-truth aerial image, $I_{\\mathrm{true}}$, by performing a linear convolution of the full mask $M$ with the full kernel $K$ using an FFT-based method.\n4.  Implement the XPINN-inspired block-FFT method to compute the approximate aerial image, $I_{\\mathrm{XPINN}}$. This involves partitioning the domain, handling overlaps, using a truncated kernel, and assembling the final result.\n5.  For each test case, calculate the relative $\\ell_2$ error, $\\varepsilon$, to quantify accuracy, and a memory consumption ratio, $\\rho$, to quantify the computational trade-off.\n\nLet's begin with the definitions and initial setup. The spatial domain is $x \\in [0,1)$, discretized on a grid of $N=4096$ points, with spacing $\\Delta x = 1/N$. The coordinates are $x_n = n \\Delta x$ for $n = 0, 1, \\ldots, N-1$.\n\nThe mask layout $M[n]$ is a deterministic binary pattern given by:\n$$M[n] = \\begin{cases} 1 & \\text{if } \\sin(2\\pi f_0 x_n) + 0.3 \\sin(2\\pi \\cdot 3 f_0 x_n) > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$$\nwhere the base frequency is $f_0 = 20$.\n\nThe optical kernel is modeled by the function:\n$$K(x) \\propto \\frac{\\exp(-|x|/\\ell)}{1 + (|x|/a)^2}$$\nwith parameters $\\ell = 0.06$ and $a = 0.01$. To create a discrete, finite-support kernel, we first find the smallest integer half-length $H$ such that the unnormalized kernel amplitude at $x = H \\Delta x$ falls below the threshold $\\tau = 10^{-6}$. The discrete kernel $K_{\\mathrm{full}}$ is then created by sampling the function on a symmetric grid of $2H+1$ points, from $x = -H \\Delta x$ to $x = H \\Delta x$. Finally, the sampled values are normalized such that their sum is equal to one:\n$$K_{\\mathrm{full}}[k] = \\frac{K_{\\mathrm{un}}((k-H)\\Delta x)}{\\sum_{j=0}^{2H} K_{\\mathrm{un}}((j-H)\\Delta x)}, \\quad k = 0, \\ldots, 2H$$\nwhere $K_{\\mathrm{un}}(x)$ is the unnormalized kernel function. The length of the full kernel is $L_{\\mathrm{ker,full}} = 2H+1$.\n\nThe ground-truth aerial image is the linear convolution $I_{\\mathrm{true}} = (K_{\\mathrm{full}} * M)[n]$. We compute this using the convolution theorem, which states that a convolution in the spatial domain is equivalent to a multiplication in the frequency domain. An FFT-based algorithm for linear convolution is employed, ensuring sufficient zero-padding to avoid circular convolution artifacts. The output is cropped to length $N$ to match the mask domain size (mode 'same').\n\nThe XPINN-inspired block-FFT approximation, $I_{\\mathrm{XPINN}}$, is computed as follows. The mask $M$ is divided into $S$ equal, non-overlapping subdomains, each of length $N/S$. For each subdomain $i \\in \\{0, \\ldots, S-1\\}$:\n1.  An extended window of the mask is extracted. This window is centered on the subdomain and has a length of $N/S + 2o$, where $o$ is the overlap size in samples. Regions outside the original domain $[0, N-1]$ are padded with zeros.\n2.  The full kernel $K_{\\mathrm{full}}$ is truncated to a radius $R = \\min(o, H)$. This yields a block-specific kernel $K_{\\mathrm{block}}$ of length $2R+1$. This truncation is a key source of approximation error, as it neglects long-range optical interactions that extend beyond the overlap region.\n3.  The extended mask window is convolved with the truncated kernel $K_{\\mathrm{block}}$ using an FFT-based method.\n4.  From the resulting convolved window, only the central portion of length $N/S$, which corresponds to the original subdomain, is retained. The overlapped margins are discarded.\n5.  The final image $I_{\\mathrm{XPINN}}$ is constructed by concatenating the retained central portions from all $S$ subdomains.\n\nThe accuracy of this approximation is measured by the relative discrete $\\ell_2$ error:\n$$\\varepsilon = \\frac{\\|I_{\\mathrm{XPINN}} - I_{\\mathrm{true}}\\|_2}{\\|I_{\\mathrm{true}}\\|_2} = \\sqrt{\\frac{\\sum_{n=0}^{N-1} (I_{\\mathrm{XPINN}}[n] - I_{\\mathrm{true}}[n])^2}{\\sum_{n=0}^{N-1} (I_{\\mathrm{true}}[n])^2}}$$\n\nThe computational memory trade-off is estimated using the provided proxy model for peak memory usage during an FFT-based convolution:\n$$B(L_{\\mathrm{sig}}, L_{\\mathrm{ker}}) = 8\\,(L_{\\mathrm{sig}} + L_{\\mathrm{ker}}) + 16 \\times 3 P$$\nwhere $L_{\\mathrm{sig}}$ is the signal length, $L_{\\mathrm{ker}}$ is the kernel length, and $P = 2^{\\lceil\\log_2(L_{\\mathrm{sig}} + L_{\\mathrm{ker}} - 1)\\rceil}$ is the padded length for the FFT. The memory ratio is then computed as:\n$$\\rho = \\frac{B\\big(N, L_{\\mathrm{ker,full}}\\big)}{B\\big(N/S + 2o, 2\\min\\{o,H\\} + 1\\big)}$$\nA ratio $\\rho > 1$ indicates that the full-domain method is more memory-intensive than the block-based method.\n\nWe will now execute this procedure for the specified test suite of $(S, o)$ values and report the resulting $(\\varepsilon, \\rho)$ pairs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal as sp_signal\n\ndef solve():\n    \"\"\"\n    Solves the optical lithography modeling problem by comparing full-domain\n    convolution with a block-FFT domain decomposition method.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    N = 4096\n    f0 = 20.0\n    ell = 0.06\n    a = 0.01\n    tau = 1e-6\n\n    # Test suite of (S, o) values\n    test_cases = [\n        (4, 64),\n        (4, 1400),\n        (16, 256),\n        (8, 0),\n    ]\n\n    # --- Step 1: Pre-computation of Mask and Kernel ---\n\n    # Define the spatial grid\n    x_grid = np.arange(N) / N\n    dx = 1.0 / N\n\n    # Construct the binary mask layout M\n    mask_signal = np.sin(2 * np.pi * f0 * x_grid) + 0.3 * np.sin(2 * np.pi * 3 * f0 * x_grid)\n    M = (mask_signal > 0).astype(float)\n\n    # Define the unnormalized kernel function\n    def K_unnormalized_func(x_val):\n        return np.exp(-np.abs(x_val) / ell) / (1.0 + (np.abs(x_val) / a)**2)\n\n    # Find the kernel half-length H based on the threshold tau\n    H = 0\n    for h_candidate in range(N):\n        if K_unnormalized_func(h_candidate * dx) < tau:\n            H = h_candidate\n            break\n    else:  # If the loop completes without breaking\n        H = N - 1\n\n    # Construct and normalize the discrete kernel K_full\n    L_ker_full = 2 * H + 1\n    k_indices = np.arange(-H, H + 1)\n    k_x_coords = k_indices * dx\n    K_full = K_unnormalized_func(k_x_coords)\n    K_full /= np.sum(K_full)\n\n    # --- Step 2: Compute Ground-Truth Aerial Image I_true ---\n\n    # Use 'scipy.signal.fftconvolve' for efficient and correct FFT-based convolution\n    I_true = sp_signal.fftconvolve(M, K_full, mode='same')\n\n    # Helper function for the memory proxy model\n    def get_peak_memory(L_sig, L_ker):\n        if L_sig <= 0 or L_ker <= 0:\n            return 0\n        fft_len = L_sig + L_ker - 1\n        if fft_len <= 1:\n          P = 1\n        else:\n          P = 1 << (fft_len - 1).bit_length() # Efficient way to find next power of 2\n        \n        # The formula from the problem statement:\n        # B(L_sig, L_ker) = 8*(L_sig + L_ker) + 16 * 3 * P\n        # 8 bytes for float64, 16 bytes for complex128\n        return 8 * (L_sig + L_ker) + 48 * P\n\n    results = []\n    # --- Step 3: Loop over test cases to compute I_XPINN and metrics ---\n    for S, o in test_cases:\n        # --- Step 3a: Compute I_XPINN using the block-FFT method ---\n        subdomain_len = N // S\n        I_XPINN_parts = []\n\n        for i in range(S):\n            sub_start_idx = i * subdomain_len\n            sub_end_idx = sub_start_idx + subdomain_len\n\n            # Define the extended window for the mask\n            win_start_idx = sub_start_idx - o\n            win_end_idx = sub_end_idx + o\n            win_len = subdomain_len + 2 * o\n            \n            M_window = np.zeros(win_len)\n            \n            # Extract the slice of M for the window, handling domain boundaries\n            src_start_in_M = max(0, win_start_idx)\n            src_end_in_M = min(N, win_end_idx)\n            M_slice = M[src_start_in_M:src_end_in_M]\n\n            # Place the slice into the window, handling padding\n            dst_start_in_win = src_start_in_M - win_start_idx\n            dst_end_in_win = dst_start_in_win + len(M_slice)\n            M_window[dst_start_in_win:dst_end_in_win] = M_slice\n            \n            # Truncate the kernel for the block-based convolution\n            R = min(o, H)\n            K_block = K_full[H - R : H + R + 1]\n            \n            # Convolve the windowed mask with the truncated kernel\n            I_window_convolved = sp_signal.fftconvolve(M_window, K_block, mode='same')\n            \n            # Retain only the central portion corresponding to the non-overlapped subdomain\n            I_subdomain = I_window_convolved[o : o + subdomain_len]\n            I_XPINN_parts.append(I_subdomain)\n\n        I_XPINN = np.concatenate(I_XPINN_parts)\n\n        # --- Step 3b: Calculate accuracy and memory metrics ---\n        \n        # Relative L2 error\n        error_norm = np.linalg.norm(I_XPINN - I_true)\n        true_norm = np.linalg.norm(I_true)\n        epsilon = error_norm / true_norm\n\n        # Memory ratio\n        mem_full = get_peak_memory(N, L_ker_full)\n        \n        L_sig_block = subdomain_len + 2 * o\n        L_ker_block = 2 * min(o, H) + 1\n        mem_block = get_peak_memory(L_sig_block, L_ker_block)\n        \n        rho = mem_full / mem_block if mem_block > 0 else float('inf')\n        \n        results.extend([epsilon, rho])\n    \n    # --- Step 4: Format and print the final output ---\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}