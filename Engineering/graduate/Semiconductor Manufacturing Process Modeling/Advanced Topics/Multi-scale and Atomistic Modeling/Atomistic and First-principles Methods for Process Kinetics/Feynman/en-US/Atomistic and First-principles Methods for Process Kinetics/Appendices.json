{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of reliable first-principles modeling is ensuring that the results are converged with respect to computational parameters. This exercise simulates the process of finding an optimal balance between accuracy and computational cost for a bulk silicon calculation . Using physically-motivated surrogate models for numerical error, you will determine the minimum plane-wave cutoff energy ($E_{\\text{cut}}$) and $k$-point mesh density required to meet specific tolerances on total energy and forces, a critical first step for any predictive simulation of process kinetics.",
            "id": "4109418",
            "problem": "You will design and implement a convergence assessment for bulk silicon based on first-principles modeling proxies, suitable for plane-wave Density Functional Theory (DFT) and Monkhorst-Pack Brillouin-zone integration. The objective is to determine minimal computational settings that meet energy and force tolerances and to propose criteria for transition-state barrier calculations, all within a reproducible surrogate framework.\n\nThe fundamental base is as follows. Plane-wave Density Functional Theory (DFT) relies on the variational principle, where the Kohn-Sham total energy is an upper bound that decreases monotonically with increasing basis completeness. The completeness of a plane-wave basis for pseudopotentials is controlled by the kinetic-energy cutoff $E_{\\text{cut}}$, and systematic error in the total energy and forces decreases with $E_{\\text{cut}}$. Brillouin-zone integration is performed using the Monkhorst-Pack mesh, denoted by an $N \\times N \\times N$ grid, where the integration error decreases with increasing $N$. For a gapped semiconductor such as silicon, the integrand is smooth, and quadrature error decays algebraically with $N$. These principles motivate the following surrogate error models for bulk silicon:\n\n- Total energy per-atom error due to the plane-wave basis: $\\Delta E_{\\text{basis}}(E_{\\text{cut}}) = a_E \\, E_{\\text{cut}}^{-p_E}$ with $a_E = 10$ and $p_E = 1.75$, expressed in electronvolts per atom ($\\text{eV/atom}$).\n- Max force component error due to the plane-wave basis: $\\Delta F_{\\text{basis}}(E_{\\text{cut}}) = a_F \\, E_{\\text{cut}}^{-p_F}$ with $a_F = 3$ and $p_F = 1.2$, expressed in $\\text{eV/\\AA}$.\n- Total energy per-atom error due to $k$-point sampling: $\\Delta E_{k}(N) = b_E \\, N^{-q_E}$ with $b_E = 0.08$ and $q_E = 2$, expressed in $\\text{eV/atom}$.\n- Max force component error due to $k$-point sampling: $\\Delta F_{k}(N) = b_F \\, N^{-q_F}$ with $b_F = 0.06$ and $q_F = 2$, expressed in $\\text{eV/\\AA}$.\n\nAssume the total error combines in quadrature:\n$$\n\\Delta E_{\\text{tot}}(E_{\\text{cut}},N) = \\sqrt{\\Delta E_{\\text{basis}}(E_{\\text{cut}})^2 + \\Delta E_{k}(N)^2},\n\\quad\n\\Delta F_{\\text{tot}}(E_{\\text{cut}},N) = \\sqrt{\\Delta F_{\\text{basis}}(E_{\\text{cut}})^2 + \\Delta F_{k}(N)^2}.\n$$\n\nFor barrier calculations such as a Nudged Elastic Band (NEB) path in a semiconductor process, systematic errors across similar images are correlated. Model the barrier uncertainty for an energy difference between two images with a fixed correlation coefficient $\\rho = 0.8$:\n$$\n\\Delta E_{\\text{barrier}}(E_{\\text{cut}},N) = \\sqrt{2\\,(1-\\rho)} \\, \\Delta E_{\\text{tot}}(E_{\\text{cut}},N).\n$$\n\nLet the computational cost metric to minimize over feasible settings be:\n$$\nC(E_{\\text{cut}},N) = \\gamma \\, E_{\\text{cut}}^{3/2} \\, N^3,\n$$\nwith $\\gamma$ an irrelevant positive constant; you should minimize $E_{\\text{cut}}^{3/2} \\, N^3$ among all pairs $(E_{\\text{cut}},N)$ that satisfy the tolerances.\n\nYour program must search $E_{\\text{cut}}$ over the discrete set $\\{200,225,250,275,300,325,350,375,400,450,500,600,800,1000,1200,1400,1600\\}$ in $\\text{eV}$ and $N$ over $\\{2,3,4,\\dots,20\\}$, and for each test case select the pair $(E_{\\text{cut}},N)$ that:\n- satisfies both $\\Delta E_{\\text{tot}}(E_{\\text{cut}},N) \\le \\varepsilon_E$ and $\\Delta F_{\\text{tot}}(E_{\\text{cut}},N) \\le \\varepsilon_F$, and\n- minimizes $E_{\\text{cut}}^{3/2} \\, N^3$ among all satisfying pairs.\n\nFor barrier criteria, the requirement is $\\Delta E_{\\text{barrier}}(E_{\\text{cut}},N) \\le \\min(\\beta \\, H, \\theta)$, where $H$ is a nominal barrier height, $\\beta$ a fractional tolerance (unitless, to be used as a decimal), and $\\theta$ an absolute tolerance in $\\text{eV}$. Report whether the selected $(E_{\\text{cut}},N)$ also meets this barrier criterion.\n\nUnits:\n- All energies must be handled and reported in electronvolts ($\\text{eV}$), with energy per atom explicitly in $\\text{eV/atom}$ where applicable.\n- All forces must be handled and reported in electronvolts per Angstrom ($\\text{eV/\\AA}$).\n- No angles are involved.\n\nTest suite to cover typical, boundary, and edge scenarios:\n- Case $1$: $\\varepsilon_E = 1.0 \\times 10^{-3}$ $\\text{eV/atom}$, $\\varepsilon_F = 1.0 \\times 10^{-2}$ $\\text{eV/\\AA}$, $H = 0.47$ $\\text{eV}$, $\\beta = 0.05$, $\\theta = 2.0 \\times 10^{-2}$ $\\text{eV}$.\n- Case $2$: $\\varepsilon_E = 5.0 \\times 10^{-4}$ $\\text{eV/atom}$, $\\varepsilon_F = 5.0 \\times 10^{-3}$ $\\text{eV/\\AA}$, $H = 0.80$ $\\text{eV}$, $\\beta = 0.02$, $\\theta = 1.0 \\times 10^{-2}$ $\\text{eV}$.\n- Case $3$: $\\varepsilon_E = 3.0 \\times 10^{-3}$ $\\text{eV/atom}$, $\\varepsilon_F = 3.0 \\times 10^{-2}$ $\\text{eV/\\AA}$, $H = 0.10$ $\\text{eV}$, $\\beta = 0.10$, $\\theta = 5.0 \\times 10^{-2}$ $\\text{eV}$.\n\nProgram requirements:\n- Implement the above surrogate models and selection logic.\n- For each case, output the selected $E_{\\text{cut}}$ (in $\\text{eV}$), $N$, the achieved $\\Delta E_{\\text{tot}}$ (in $\\text{eV/atom}$), the achieved $\\Delta F_{\\text{tot}}$ (in $\\text{eV/\\AA}$), the predicted $\\Delta E_{\\text{barrier}}$ (in $\\text{eV}$), and a boolean indicating whether the barrier criterion is met.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case is represented by a list in the order $[E_{\\text{cut}},N,\\Delta E_{\\text{tot}},\\Delta F_{\\text{tot}},\\Delta E_{\\text{barrier}},\\text{pass}]$. For example, $[[\\dots],[\\dots],[\\dots]]$.\n- Express all floating-point outputs with six digits after the decimal point.\n\nYour solution must be a complete, runnable Python program that implements this logic and produces the specified single-line output.",
            "solution": "The problem presented is a well-posed exercise in computational materials science, specifically in the optimization of first-principles calculation parameters. It is scientifically grounded in the principles of Density Functional Theory (DFT) and is objective and internally consistent. Therefore, we may proceed with a formal solution.\n\nThe objective is to determine the optimal pair of computational parameters, the plane-wave kinetic energy cutoff $E_{\\text{cut}}$ and the Monkhorst-Pack mesh size $N$, that minimizes a defined computational cost metric while satisfying specified precision tolerances for total energy and atomic forces. The problem provides surrogate models that analytically describe the convergence of systematic errors with respect to these parameters.\n\nThe error contributions are defined as follows:\n- The error in total energy per atom due to the finite plane-wave basis set is modeled as a power-law decay with respect to the energy cutoff $E_{\\text{cut}}$:\n$$\n\\Delta E_{\\text{basis}}(E_{\\text{cut}}) = a_E \\, E_{\\text{cut}}^{-p_E}\n$$\nwhere $a_E = 10 \\text{ eV} \\cdot \\text{eV}^{p_E}/\\text{atom}$ and $p_E = 1.75$.\n\n- The error in the maximum force component due to the basis set is similarly modeled:\n$$\n\\Delta F_{\\text{basis}}(E_{\\text{cut}}) = a_F \\, E_{\\text{cut}}^{-p_F}\n$$\nwhere $a_F = 3 \\text{ eV/\\AA} \\cdot \\text{eV}^{p_F}$ and $p_F = 1.2$.\n\n- The error in total energy per atom from the discrete Brillouin zone integration on an $N \\times N \\times N$ Monkhorst-Pack grid is:\n$$\n\\Delta E_{k}(N) = b_E \\, N^{-q_E}\n$$\nwhere $b_E = 0.08 \\text{ eV/atom}$ and $q_E = 2$.\n\n- The error in the maximum force component from $k$-point sampling is:\n$$\n\\Delta F_{k}(N) = b_F \\, N^{-q_F}\n$$\nwhere $b_F = 0.06 \\text{ eV/\\AA}$ and $q_F = 2$.\n\nAssuming the errors from the basis set and $k$-point sampling are independent, the total errors for energy and force are calculated by adding the individual contributions in quadrature:\n$$\n\\Delta E_{\\text{tot}}(E_{\\text{cut}},N) = \\sqrt{\\Delta E_{\\text{basis}}(E_{\\text{cut}})^2 + \\Delta E_{k}(N)^2}\n$$\n$$\n\\Delta F_{\\text{tot}}(E_{\\text{cut}},N) = \\sqrt{\\Delta F_{\\text{basis}}(E_{\\text{cut}})^2 + \\Delta F_{k}(N)^2}\n$$\n\nThe computational cost to be minimized is given by the function:\n$$\nC(E_{\\text{cut}},N) = \\gamma \\, E_{\\text{cut}}^{3/2} \\, N^3\n$$\nwhere $\\gamma$ is a constant of proportionality. Minimizing $C(E_{\\text{cut}},N)$ is equivalent to minimizing the term $E_{\\text{cut}}^{3/2} \\, N^3$.\n\nThe solution methodology involves a systematic search over the prescribed discrete parameter space. The set of possible values for the energy cutoff is $E_{\\text{cut}} \\in \\{200, 225, 250, 275, 300, 325, 350, 375, 400, 450, 500, 600, 800, 1000, 1200, 1400, 1600\\}$ $\\text{eV}$, and for the $k$-point mesh density is $N \\in \\{2, 3, \\dots, 20\\}$.\n\nFor each test case defined by a set of tolerances $(\\varepsilon_E, \\varepsilon_F)$, the algorithm is as follows:\n1.  Initialize a minimum cost variable, $C_{\\min}$, to a value approaching infinity, and an optimal parameter set to a null state.\n2.  Iterate through every possible pair of $(E_{\\text{cut}}, N)$ from their respective search spaces.\n3.  For each pair, calculate the total energy error $\\Delta E_{\\text{tot}}(E_{\\text{cut}}, N)$ and total force error $\\Delta F_{\\text{tot}}(E_{\\text{cut}}, N)$ using the provided models.\n4.  Check if the calculated errors satisfy the given tolerance constraints: $\\Delta E_{\\text{tot}} \\le \\varepsilon_E$ and $\\Delta F_{\\text{tot}} \\le \\varepsilon_F$.\n5.  If the constraints are satisfied, the pair $(E_{\\text{cut}}, N)$ is deemed \"feasible\". Calculate its associated cost proxy, $C_0(E_{\\text{cut}}, N) = E_{\\text{cut}}^{3/2} N^3$.\n6.  If this cost $C_0$ is less than the current minimum cost $C_{\\min}$, update $C_{\\min} = C_0$ and store the current pair $(E_{\\text{cut}}, N)$ and its associated errors $(\\Delta E_{\\text{tot}}, \\Delta F_{\\text{tot}})$ as the new optimum.\n7.  After exhausting the search space, the stored optimal pair $(E_{\\text{cut}}^{\\text{opt}}, N^{\\text{opt}})$ is the solution that meets the criteria at the lowest computational cost.\n\nFinally, for the determined optimal parameters, we assess their suitability for transition-state barrier calculations. The uncertainty in a calculated energy barrier, $\\Delta E_{\\text{barrier}}$, is given by:\n$$\n\\Delta E_{\\text{barrier}}(E_{\\text{cut}},N) = \\sqrt{2(1-\\rho)} \\, \\Delta E_{\\text{tot}}(E_{\\text{cut}},N)\n$$\nwith a specified error correlation coefficient $\\rho = 0.8$. This calculated uncertainty is then compared against a tolerance defined as $\\min(\\beta H, \\theta)$, where $H$ is a nominal barrier height, $\\beta$ is a fractional tolerance, and $\\theta$ is an absolute tolerance in $\\text{eV}$. A boolean value will indicate whether the optimal parameters also satisfy this barrier criterion.\n\nThis structured procedure guarantees finding the most computationally efficient parameters within the provided model and search space that adhere to the required accuracy for both ground-state properties and transition-state energies. The implementation will follow this logic for each test case provided.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for optimal DFT parameters based on surrogate error models.\n    \"\"\"\n\n    # --- Model Parameters ---\n    # Basis set error model: a * E_cut^(-p)\n    a_E = 10.0\n    p_E = 1.75\n    a_F = 3.0\n    p_F = 1.2\n    \n    # k-point sampling error model: b * N^(-q)\n    b_E = 0.08\n    q_E = 2.0\n    b_F = 0.06\n    q_F = 2.0\n    \n    # Barrier uncertainty model\n    rho = 0.8\n    barrier_factor = np.sqrt(2 * (1 - rho))\n\n    # --- Search Space ---\n    e_cut_values = [200, 225, 250, 275, 300, 325, 350, 375, 400, 450, 500, 600, 800, 1000, 1200, 1400, 1600]\n    n_values = list(range(2, 21))\n\n    # --- Test Cases ---\n    test_cases = [\n        # (eps_E, eps_F, H, beta, theta)\n        (1.0e-3, 1.0e-2, 0.47, 0.05, 2.0e-2),\n        (5.0e-4, 5.0e-3, 0.80, 0.02, 1.0e-2),\n        (3.0e-3, 3.0e-2, 0.10, 0.10, 5.0e-2),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        eps_E, eps_F, H, beta, theta = case\n        \n        min_cost = float('inf')\n        optimal_params = None\n\n        for e_cut in e_cut_values:\n            # Pre-calculate basis set errors for this e_cut\n            delta_e_basis = a_E * (e_cut ** -p_E)\n            delta_f_basis = a_F * (e_cut ** -p_F)\n\n            for n_val in n_values:\n                # Calculate k-point errors\n                delta_e_k = b_E * (n_val ** -q_E)\n                delta_f_k = b_F * (n_val ** -q_F)\n\n                # Calculate total errors in quadrature\n                delta_e_tot = np.sqrt(delta_e_basis**2 + delta_e_k**2)\n                delta_f_tot = np.sqrt(delta_f_basis**2 + delta_f_k**2)\n\n                # Check if tolerances are met\n                if delta_e_tot = eps_E and delta_f_tot = eps_F:\n                    # This is a feasible parameter set, calculate its cost\n                    cost = (e_cut ** 1.5) * (n_val ** 3)\n                    \n                    if cost  min_cost:\n                        min_cost = cost\n                        optimal_params = {\n                            \"e_cut\": e_cut,\n                            \"n\": n_val,\n                            \"dE_tot\": delta_e_tot,\n                            \"dF_tot\": delta_f_tot\n                        }\n        \n        # After searching, process the optimal parameters\n        if optimal_params:\n            # Calculate barrier uncertainty for the optimal parameter set\n            delta_e_barrier = barrier_factor * optimal_params[\"dE_tot\"]\n            \n            # Determine if the barrier criterion is met\n            barrier_tolerance = min(beta * H, theta)\n            barrier_pass = delta_e_barrier = barrier_tolerance\n\n            # Format the results for this case into a list\n            case_result_list = [\n                optimal_params[\"e_cut\"],\n                optimal_params[\"n\"],\n                optimal_params[\"dE_tot\"],\n                optimal_params[\"dF_tot\"],\n                delta_e_barrier,\n                barrier_pass,\n            ]\n            \n            # Format the list into the required string representation\n            e_str = str(case_result_list[0])\n            n_str = str(case_result_list[1])\n            de_tot_str = f\"{case_result_list[2]:.6f}\"\n            df_tot_str = f\"{case_result_list[3]:.6f}\"\n            de_barr_str = f\"{case_result_list[4]:.6f}\"\n            pass_str = str(case_result_list[5]).lower() # 'true' or 'false'\n            \n            case_result_string = f\"[{e_str},{n_str},{de_tot_str},{df_tot_str},{de_barr_str},{pass_str}]\"\n            all_results.append(case_result_string)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The kinetic parameters obtained from atomistic calculations, such as activation energies ($E_a$) and attempt frequencies ($\\nu$), are not exact values but estimates with associated uncertainties. To make robust predictions about macroscopic behavior, it is essential to understand how these uncertainties propagate through kinetic models. In this final practice, you will use Monte Carlo sampling to translate the statistical uncertainty in DFT-derived parameters into a credible interval for a key kinetic observable, the diffusion coefficient $D$, effectively bridging the gap between atomistic accuracy and macroscopic process predictions .",
            "id": "4109414",
            "problem": "A common modeling task in semiconductor manufacturing process modeling is to propagate parameter uncertainties estimated from atomistic simulations to mesoscopic observables. Consider a single-mechanism surface or bulk diffusion process whose Kinetic Monte Carlo (KMC) hop rate $k$ obeys the Arrhenius form $k = \\nu \\exp\\!\\left(-\\frac{E_a}{k_B T}\\right)$, where $E_a$ is the activation energy, $\\nu$ is the prefactor (attempt frequency), $k_B$ is the Boltzmann constant, and $T$ is the absolute temperature in kelvin. For a random walk on a lattice with dimension $d$ and hop length $a$, the diffusion coefficient is modeled as $D = \\frac{a^2 k}{2 d}$ in meters squared per second. Suppose Density Functional Theory (DFT) analysis yields uncertain parameter estimates modeled as follows: $E_a$ is normally distributed with mean $\\mu_{E_a}$ and standard deviation $\\sigma_{E_a}$, physically truncated to $E_a \\ge 0$, and $\\ln \\nu$ is normally distributed with mean $\\mu_{\\ln \\nu}$ and standard deviation $\\sigma_{\\ln \\nu}$ (so $\\nu$ is log-normally distributed).\n\nYour task is to implement Monte Carlo sampling to propagate uncertainties from $E_a$ and $\\nu$ into the diffusion coefficient $D$ and report equal-tailed $95\\%$ credible intervals for $D$. Use $k_B = 8.617333262 \\times 10^{-5}$ electronvolt per kelvin, $E_a$ in electronvolt, $T$ in kelvin, $a$ in meters, and $\\nu$ in per second, ensuring $D$ is computed in meters squared per second. For each test case, generate $N$ independent samples $\\{E_a^{(i)}, \\nu^{(i)}\\}_{i=1}^N$ with $E_a^{(i)} \\sim \\mathcal{N}(\\mu_{E_a}, \\sigma_{E_a}^2)$ truncated to $E_a^{(i)} \\ge 0$ and $\\ln \\nu^{(i)} \\sim \\mathcal{N}(\\mu_{\\ln \\nu}, \\sigma_{\\ln \\nu}^2)$, compute $k^{(i)} = \\nu^{(i)} \\exp\\!\\left(-\\frac{E_a^{(i)}}{k_B T}\\right)$ and $D^{(i)} = \\frac{a^2 k^{(i)}}{2 d}$, and then report the lower and upper bounds of the equal-tailed $95\\%$ credible interval for $D$ (the $2.5\\%$ and $97.5\\%$ quantiles of the empirical distribution of $\\{D^{(i)}\\}$). Express each bound in meters squared per second, rounded to three significant figures.\n\nTest suite:\n- Case $1$: $T = 800$ kelvin, $a = 2.5 \\times 10^{-10}$ meters, $d = 2$, $\\mu_{E_a} = 0.45$ electronvolt, $\\sigma_{E_a} = 0.05$ electronvolt, $\\mu_{\\ln \\nu} = \\ln(10^{13})$, $\\sigma_{\\ln \\nu} = 0.4$, $N = 40000$.\n- Case $2$: $T = 300$ kelvin, $a = 2.5 \\times 10^{-10}$ meters, $d = 2$, $\\mu_{E_a} = 0.90$ electronvolt, $\\sigma_{E_a} = 0.10$ electronvolt, $\\mu_{\\ln \\nu} = \\ln(5 \\times 10^{12})$, $\\sigma_{\\ln \\nu} = 0.3$, $N = 60000$.\n- Case $3$: $T = 1000$ kelvin, $a = 2.5 \\times 10^{-10}$ meters, $d = 1$, $\\mu_{E_a} = 0.20$ electronvolt, $\\sigma_{E_a} = 0.02$ electronvolt, $\\mu_{\\ln \\nu} = \\ln(10^{12})$, $\\sigma_{\\ln \\nu} = 0.2$, $N = 50000$.\n- Case $4$: $T = 1200$ kelvin, $a = 5.43 \\times 10^{-10}$ meters, $d = 3$, $\\mu_{E_a} = 3.50$ electronvolt, $\\sigma_{E_a} = 0.30$ electronvolt, $\\mu_{\\ln \\nu} = \\ln(10^{13})$, $\\sigma_{\\ln \\nu} = 0.5$, $N = 80000$.\n- Case $5$: $T = 600$ kelvin, $a = 3.0 \\times 10^{-10}$ meters, $d = 2$, $\\mu_{E_a} = 0.60$ electronvolt, $\\sigma_{E_a} = 0.15$ electronvolt, $\\mu_{\\ln \\nu} = \\ln(2 \\times 10^{13})$, $\\sigma_{\\ln \\nu} = 1.0$, $N = 70000$.\n\nFinal output format:\nYour program should produce a single line of output containing the credible interval bounds for all test cases as a comma-separated list of lists, where each inner list contains two floats corresponding to the lower and upper bounds of the $95\\%$ credible interval for $D$ in meters squared per second, rounded to three significant figures, enclosed in square brackets (e.g., $[[\\text{lower}_1,\\text{upper}_1],[\\text{lower}_2,\\text{upper}_2],\\dots]$).",
            "solution": "The starting point is the Arrhenius description of thermally activated kinetics, which is derived from Transition State Theory (TST) under the assumption of a quasi-equilibrium between reactants and the activated complex. In TST, the rate constant for overcoming an energy barrier $E_a$ scales with an attempt frequency $\\nu$ that accounts for vibrational dynamics about the initial state and an exponential Boltzmann factor that penalizes barrier crossing. Specifically, the Kinetic Monte Carlo (KMC) hop rate is modeled as $k = \\nu \\exp\\!\\left(-\\frac{E_a}{k_B T}\\right)$, where $k_B$ is the Boltzmann constant and $T$ is the absolute temperature. This model is well-tested for atomistic processes such as adatom diffusion on surfaces and point defect migration in bulk crystals.\n\nFor a lattice random walk with hop length $a$ in $d$ dimensions, the mean-squared displacement grows linearly in time according to $\\langle r^2(t) \\rangle = 2 d D t$ by definition of the diffusion coefficient $D$. For a sequence of Poissonian hops with rate $k$, each hop displaces a walker by length $a$, yielding the effective diffusion coefficient $D = \\frac{a^2 k}{2 d}$, which arises by equating the rate of growth in mean-squared displacement, $\\frac{d}{dt}\\langle r^2\\rangle = a^2 k$, with the Einstein relation $\\frac{d}{dt}\\langle r^2\\rangle = 2 d D$.\n\nUncertainties in parameters derived from Density Functional Theory (DFT) are modeled as probability distributions. It is standard to model the activation energy $E_a$ as a normal random variable reflecting fitting and methodological uncertainties; however, the physical constraint demands $E_a \\ge 0$, which we enforce via truncation. The prefactor $\\nu$ reflects vibrational frequencies and entropy factors and is typically modeled as log-normal, hence $\\ln \\nu$ is normally distributed. Let $E_a \\sim \\mathcal{N}(\\mu_{E_a}, \\sigma_{E_a}^2)$ truncated to $E_a \\ge 0$, and $\\ln \\nu \\sim \\mathcal{N}(\\mu_{\\ln \\nu}, \\sigma_{\\ln \\nu}^2)$, independent.\n\nTo propagate these uncertainties to $D$, we use Monte Carlo sampling:\n- Sample $N$ independent pairs $\\left(E_a^{(i)}, \\ln \\nu^{(i)}\\right)$ from their respective normal distributions; enforce $E_a^{(i)} \\ge 0$ by truncation, and transform $\\nu^{(i)} = \\exp\\!\\left(\\ln \\nu^{(i)}\\right)$.\n- Compute the hop rate $k^{(i)} = \\nu^{(i)} \\exp\\!\\left(-\\frac{E_a^{(i)}}{k_B T}\\right)$.\n- Compute $D^{(i)} = \\frac{a^2 k^{(i)}}{2 d}$ in meters squared per second, given $a$ in meters and $T$ in kelvin. Use $k_B = 8.617333262 \\times 10^{-5}$ electronvolt per kelvin so that $E_a$ in electronvolt is consistent with $k_B T$ in electronvolt.\n- The empirical distribution of $\\{D^{(i)}\\}_{i=1}^N$ approximates the posterior predictive distribution of $D$ given the parameter uncertainties. The equal-tailed $95\\%$ credible interval is given by the $2.5\\%$ and $97.5\\%$ empirical quantiles: $q_{0.025}$ and $q_{0.975}$.\n- Round each bound to three significant figures to produce the final numeric results in meters squared per second.\n\nAlgorithmic design:\n- Use a fixed random seed to ensure reproducibility.\n- Generate $E_a$ samples via a normal distribution and truncate by replacing negative samples with $0$, which is acceptable given that the left tail probability is small for realistic $\\mu_{E_a} \\gg 0$ and enforces the physical constraint.\n- Generate $\\ln \\nu$ samples via a normal distribution and exponentiate to obtain $\\nu$ samples.\n- Compute $k$ and then $D$ vectorized using numerical arrays for efficiency.\n- Compute empirical quantiles using a deterministic quantile function.\n- Implement numeric rounding to three significant figures for floats by scaling with a power of $10$. Specifically, for $x > 0$, define $e = \\lfloor \\log_{10}(x) \\rfloor, s = 10^{e - s_f + 1}$ with $s_f = 3$, then return $\\operatorname{round}(x/s) \\cdot s$; for $x = 0$, return $0$. This ensures three significant figures while preserving the float type.\n- Apply the procedure to each of the test cases provided, with their specified parameters ($T$, $a$, $d$, $\\mu_{E_a}$, $\\sigma_{E_a}$, $\\mu_{\\ln \\nu}$, $\\sigma_{\\ln \\nu}$, $N$).\n\nThe final output is a single line containing a list of pairs $[\\text{lower}, \\text{upper}]$ for each test case, i.e., $[[q_{0.025}^{(1)}, q_{0.975}^{(1)}],[q_{0.025}^{(2)}, q_{0.975}^{(2)}],\\dots]$, with each bound rounded to three significant figures and expressed in meters squared per second, as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef round_sig(x: float, sig: int = 3) - float:\n    \"\"\"\n    Round a positive float to 'sig' significant figures while returning a float.\n    For x == 0, returns 0.0.\n    \"\"\"\n    if x == 0.0 or not np.isfinite(x):\n        # For infinite or NaN, return as-is (though such values should not occur here).\n        return float(x)\n    ax = abs(x)\n    if ax == 0.0:\n        return 0.0\n    e = int(np.floor(np.log10(ax)))\n    scale = 10.0 ** (e - sig + 1)\n    rounded = round(ax / scale) * scale\n    return np.copysign(rounded, x)\n\ndef credible_interval_D(T, a, d, mu_Ea, sigma_Ea, mu_ln_nu, sigma_ln_nu, N, rng):\n    \"\"\"\n    Compute equal-tailed 95% credible interval for diffusion coefficient D given parameters.\n    Units:\n      - T in K\n      - a in m\n      - d dimensionless\n      - mu_Ea, sigma_Ea in eV\n      - mu_ln_nu, sigma_ln_nu dimensionless (natural log of s^-1)\n      - N number of samples\n    Returns (lower, upper) in m^2/s as floats (rounded to 3 significant figures).\n    \"\"\"\n    # Boltzmann constant in eV/K\n    kB_eV_per_K = 8.617333262e-5\n\n    # Sample Ea from Normal and truncate at 0 (physical constraint Ea = 0)\n    Ea_samples = rng.normal(loc=mu_Ea, scale=sigma_Ea, size=N)\n    Ea_samples = np.maximum(Ea_samples, 0.0)\n\n    # Sample ln(nu) from Normal, then exponentiate to get nu (log-normal)\n    ln_nu_samples = rng.normal(loc=mu_ln_nu, scale=sigma_ln_nu, size=N)\n    nu_samples = np.exp(ln_nu_samples)\n\n    # Compute hop rates: k = nu * exp(-Ea / (kB * T))\n    beta = 1.0 / (kB_eV_per_K * T)  # 1 / (eV)\n    # Guard against overflow/underflow: exponent argument is negative, safe for realistic values.\n    k_samples = nu_samples * np.exp(-Ea_samples * beta)\n\n    # Diffusion coefficient: D = a^2 * k / (2 * d)\n    D_samples = (a * a) * k_samples / (2.0 * d)\n\n    # Compute equal-tailed 95% credible interval\n    lower, upper = np.quantile(D_samples, [0.025, 0.975], method=\"linear\")\n\n    # Round to three significant figures\n    lower_rounded = round_sig(float(lower), sig=3)\n    upper_rounded = round_sig(float(upper), sig=3)\n\n    return lower_rounded, upper_rounded\n\ndef solve():\n    # Fixed random seed for reproducibility\n    rng = np.random.default_rng(seed=42)\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (T [K], a [m], d, mu_Ea [eV], sigma_Ea [eV], mu_ln_nu, sigma_ln_nu, N)\n    test_cases = [\n        (800.0, 2.5e-10, 2, 0.45, 0.05, np.log(1.0e13), 0.4, 40000),\n        (300.0, 2.5e-10, 2, 0.90, 0.10, np.log(5.0e12), 0.3, 60000),\n        (1000.0, 2.5e-10, 1, 0.20, 0.02, np.log(1.0e12), 0.2, 50000),\n        (1200.0, 5.43e-10, 3, 3.50, 0.30, np.log(1.0e13), 0.5, 80000),\n        (600.0, 3.0e-10, 2, 0.60, 0.15, np.log(2.0e13), 1.0, 70000),\n    ]\n\n    results = []\n    for case in test_cases:\n        T, a, d, mu_Ea, sigma_Ea, mu_ln_nu, sigma_ln_nu, N = case\n        lower, upper = credible_interval_D(T, a, d, mu_Ea, sigma_Ea, mu_ln_nu, sigma_ln_nu, N, rng)\n        results.append([lower, upper])\n\n    # Final print statement in the exact required format.\n    # Produce a single line of output with the nested list of credible intervals.\n    # Ensure plain representation of floats.\n    print(f\"[{','.join('[' + ','.join(map(str, pair)) + ']' for pair in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}