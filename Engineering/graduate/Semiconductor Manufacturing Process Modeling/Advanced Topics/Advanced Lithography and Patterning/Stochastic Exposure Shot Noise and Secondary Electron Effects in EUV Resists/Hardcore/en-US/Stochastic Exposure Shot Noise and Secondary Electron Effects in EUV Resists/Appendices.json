{
    "hands_on_practices": [
        {
            "introduction": "This exercise provides a foundational understanding of how stochastic effects originate in EUV lithography. We will derive an analytical expression for Line-Edge Roughness (LER) starting from the fundamental principle that photon arrivals are a random Poisson process. By modeling the effects of secondary electrons as a spatial blur, you will see precisely how fundamental parameters like exposure dose ($D$) and blur width ($\\sigma$) directly influence this critical source of nanopatterning variability . This first-principles approach is essential for building intuition about the sources of noise in semiconductor manufacturing.",
            "id": "4167966",
            "problem": "An Extreme Ultraviolet (EUV) lithography line-edge can be modeled in one spatial dimension, with the mask transmitting for $x0$ and blocking for $x0$. Absorbed photon arrivals in the resist are a spatial Poisson process with mean linear intensity $D$ (photons per unit length) over the transmitting region. Each absorbed photon deposits energy that subsequently produces a latent image via a blur kernel that represents the Point Spread Function (PSF), including secondary electron transport. Assume the PSF is Gaussian and normalized in one dimension: $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)$, where $\\sigma$ is the standard deviation characterizing the effective blur due to the PSF, including secondary electrons.\n\nLet the latent dose (energy density) profile be $A(x)$, and let the final resist response $R(A)$ be a monotone differentiable transfer function mapping dose $A$ to a measurable output that defines the printed edge by the threshold crossing $R(x) = R_{\\mathrm{th}}$ at $x = x_{\\mathrm{t}}$. Define the edge slope $S$ as the magnitude of the spatial derivative of the mean response at the threshold location, $S \\equiv \\left|\\frac{d\\,\\mathbb{E}[R(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right|$. Shot noise in photon counts produces stochastic fluctuations in $A(x)$ and, via $R(A)$, in the threshold crossing location. Starting from first principles of Poisson shot noise and linear systems, derive an analytic expression for the Line Edge Roughness (LER) standard deviation $\\sigma_{\\mathrm{LER}}$ caused purely by shot noise, expressed explicitly in terms of the dose $D$, the PSF width $\\sigma$, and the edge slope. Evaluate the expression for the case of a symmetric step edge with threshold at the half-level of the mean latent dose, i.e., $x_{\\mathrm{t}} = 0$ where $\\mathbb{E}[A(0)] = \\frac{D}{2}$.\n\nYour final result must be a single closed-form expression for $\\sigma_{\\mathrm{LER}}$ showing its dependence on $D$ and $\\sigma$. Provide the expression, and do not include any numerical approximation. If you need to reference the edge slope, you must eliminate explicit dependence on the resist transfer function $R(A)$ by appropriately combining it with the latent dose slope in your derivation. No rounding is required. Do not include physical units in the final expression; however, treat $D$ as a photon count per unit length and $\\sigma$ as a length scale so that the dimensional consistency is clear.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   **System Geometry**: A one-dimensional system with a mask transmitting for $x > 0$ and blocking for $x  0$.\n-   **Photon Arrival Process**: A spatial Poisson process with mean linear intensity $D$ (photons per unit length) in the transmitting region ($x > 0$).\n-   **Point Spread Function (PSF)**: A normalized one-dimensional Gaussian, $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)$, where $\\sigma$ is the standard deviation characterizing the effective blur.\n-   **Latent Dose Profile**: $A(x)$, the energy density profile resulting from absorbed photons convolved with the PSF.\n-   **Resist Response**: A monotone differentiable transfer function $R(A)$.\n-   **Edge Definition**: The printed edge is at position $x_{\\mathrm{t}}$ where the response crosses a threshold, $R(x) = R_{\\mathrm{th}}$.\n-   **Edge Slope Definition**: $S \\equiv \\left|\\frac{d\\,\\mathbb{E}[R(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right|$, where $\\mathbb{E}[\\cdot]$ denotes the expectation value.\n-   **Stochastic Fluctuation Source**: Shot noise in photon counts.\n-   **Objective**: Derive an analytic expression for the Line Edge Roughness (LER) standard deviation, $\\sigma_{\\mathrm{LER}}$, due to shot noise.\n-   **Evaluation Condition**: The edge is symmetric, with the threshold at the half-level of the mean latent dose, which occurs at $x_{\\mathrm{t}} = 0$. It is given that $\\mathbb{E}[A(0)] = \\frac{D}{2}$.\n-   **Final Expression Requirements**: $\\sigma_{\\mathrm{LER}}$ must be expressed explicitly in terms of dose $D$ and PSF width $\\sigma$, eliminating dependence on the resist transfer function $R(A)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective. It employs a standard and widely accepted model for stochastic effects in lithography (Poisson shot noise, Gaussian PSF). The components of the model are clearly defined, and the objective is a specific analytical derivation. The problem is self-contained and free of contradictions or ambiguities. The simplifications (1D model, perfect step mask) are standard for analytical tractability and do not render the problem scientifically unsound or unrealistic in a theoretical context. Therefore, the problem is deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe latent dose profile $A(x)$ is the cumulative effect of all absorbed photons. Since photon arrivals are a Poisson point process, $A(x)$ can be modeled as a shot noise process. Let the locations of the absorbed photons be $\\{z_i\\}$. As photons are only transmitted for $x > 0$, the $z_i$ are distributed in $(0, \\infty)$ with a constant rate $D$. The dose at position $x$ is the sum of the contributions from each photon, where each contribution is described by the PSF $g(x)$:\n$$A(x) = \\sum_i g(x - z_i)$$\nThis is a linear shot noise process. The statistical properties of $A(x)$ are described by Campbell's theorems.\n\nThe Line Edge Roughness, $\\sigma_{\\mathrm{LER}}$, is the standard deviation of the edge position $x_t$. The edge position is defined by a threshold crossing. While the problem defines it in terms of a generic resist response $R(A)$, it asks to eliminate this dependence. We can accomplish this by working directly with the latent dose $A(x)$. The edge is at a position $x_E$ where the dose $A(x_E)$ crosses a threshold $A_{\\mathrm{th}}$. Due to the stochastic nature of $A(x)$, the position $x_E$ is a random variable. We linearize the process around the mean edge position $x_{\\mathrm{t}}$.\n\nThe actual dose profile is $A(x) = \\mathbb{E}[A(x)] + \\delta A(x)$, where $\\delta A(x)$ is the zero-mean fluctuation. The edge position is found where $A(x_E) = A_{\\mathrm{th}}$. Let $x_E = x_{\\mathrm{t}} + \\delta x$, where $x_{\\mathrm{t}}$ is the mean edge position defined by $\\mathbb{E}[A(x_{\\mathrm{t}})] = A_{\\mathrm{th}}$.\n$$A(x_{\\mathrm{t}} + \\delta x) = \\mathbb{E}[A(x_{\\mathrm{t}} + \\delta x)] + \\delta A(x_{\\mathrm{t}} + \\delta x) = A_{\\mathrm{th}}$$\nExpanding $\\mathbb{E}[A(x_{\\mathrm{t}} + \\delta x)]$ in a Taylor series around $x_{\\mathrm{t}}$ to first order:\n$$\\mathbb{E}[A(x_{\\mathrm{t}})] + \\delta x \\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=x_{\\mathrm{t}}} + \\delta A(x_{\\mathrm{t}} + \\delta x) \\approx A_{\\mathrm{th}}$$\nSince $\\mathbb{E}[A(x_{\\mathrm{t}})] = A_{\\mathrm{th}}$ and for small fluctuations $\\delta A(x_{\\mathrm{t}} + \\delta x) \\approx \\delta A(x_{\\mathrm{t}})$, we get:\n$$\\delta x \\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=x_{\\mathrm{t}}} \\approx -\\delta A(x_{\\mathrm{t}})$$\nThe fluctuation in the edge position, $\\delta x$, is related to the dose fluctuation at the mean edge position. The variance of the edge position, $\\sigma_{\\mathrm{LER}}^2$, is therefore:\n$$\\sigma_{\\mathrm{LER}}^2 = \\mathbb{E}[(\\delta x)^2] \\approx \\frac{\\mathbb{E}[(\\delta A(x_{\\mathrm{t}}))^2]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right)^2} = \\frac{\\mathrm{Var}[A(x_{\\mathrm{t}})]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right)^2}$$\nTo find $\\sigma_{\\mathrm{LER}}$, we must calculate the dose variance (the numerator) and the squared slope of the mean dose profile (the denominator) at the edge location $x_{\\mathrm{t}} = 0$.\n\n1.  **Mean Dose Profile $\\mathbb{E}[A(x)]$ and its Slope**:\n    According to Campbell's first theorem, the mean of the shot noise process is the convolution of the input rate function with the impulse response (PSF). The input rate is $\\lambda(z) = D$ for $z>0$ and $0$ otherwise.\n    $$\\mathbb{E}[A(x)] = \\int_{-\\infty}^{\\infty} \\lambda(z) g(x-z) \\,dz = D \\int_{0}^{\\infty} g(x-z) \\,dz$$\n    Let $u = x-z$, so $dz = -du$. The limits change from $z \\in [0, \\infty)$ to $u \\in (x, -\\infty)$.\n    $$\\mathbb{E}[A(x)] = D \\int_{x}^{-\\infty} g(u) (-du) = D \\int_{-\\infty}^{x} g(u) \\,du$$\n    This is $D$ times the cumulative distribution function (CDF) of the Gaussian PSF. Let $\\Phi(\\xi) = \\int_{-\\infty}^{\\xi} \\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} dt$ be the standard normal CDF. Then,\n    $$\\mathbb{E}[A(x)] = D \\cdot \\Phi\\left(\\frac{x}{\\sigma}\\right)$$\n    The slope of the mean dose profile is its derivative with respect to $x$:\n    $$\\frac{d\\mathbb{E}[A(x)]}{dx} = D \\frac{d}{dx} \\Phi\\left(\\frac{x}{\\sigma}\\right) = D \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) = D \\cdot g(x)$$\n    At the specified edge location $x_{\\mathrm{t}} = 0$, the slope is:\n    $$\\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=0} = D \\cdot g(0) = D \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma} = \\frac{D}{\\sigma\\sqrt{2\\pi}}$$\n\n2.  **Dose Variance $\\mathrm{Var}[A(x)]$**:\n    According to Campbell's second theorem, the variance of the shot noise process is given by the integral of the input rate function multiplied by the square of the PSF:\n    $$\\mathrm{Var}[A(x)] = \\int_{-\\infty}^{\\infty} \\lambda(z) [g(x-z)]^2 \\,dz = D \\int_{0}^{\\infty} [g(x-z)]^2 \\,dz$$\n    The square of the PSF is:\n    $$[g(x-z)]^2 = \\left(\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-z)^2}{2\\sigma^2}\\right)\\right)^2 = \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{(x-z)^2}{\\sigma^2}\\right)$$\n    We need to evaluate the variance at $x_{\\mathrm{t}} = 0$:\n    $$\\mathrm{Var}[A(0)] = D \\int_{0}^{\\infty} \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz = \\frac{D}{2\\pi\\sigma^2} \\int_{0}^{\\infty} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz$$\n    This is a standard Gaussian integral. Using the result $\\int_{0}^{\\infty} e^{-ay^2} dy = \\frac{1}{2}\\sqrt{\\frac{\\pi}{a}}$, with $a=1/\\sigma^2$:\n    $$\\int_{0}^{\\infty} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz = \\frac{1}{2}\\sqrt{\\pi\\sigma^2} = \\frac{\\sigma\\sqrt{\\pi}}{2}$$\n    Substituting this back into the expression for variance:\n    $$\\mathrm{Var}[A(0)] = \\frac{D}{2\\pi\\sigma^2} \\cdot \\frac{\\sigma\\sqrt{\\pi}}{2} = \\frac{D}{4\\sigma\\sqrt{\\pi}}$$\n\n3.  **Line Edge Roughness $\\sigma_{\\mathrm{LER}}$**:\n    Now we assemble the expression for $\\sigma_{\\mathrm{LER}}^2$:\n    $$\\sigma_{\\mathrm{LER}}^2 = \\frac{\\mathrm{Var}[A(0)]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=0}\\right)^2} = \\frac{\\frac{D}{4\\sigma\\sqrt{\\pi}}}{\\left(\\frac{D}{\\sigma\\sqrt{2\\pi}}\\right)^2} = \\frac{\\frac{D}{4\\sigma\\sqrt{\\pi}}}{\\frac{D^2}{2\\pi\\sigma^2}}$$\n    Simplifying the expression:\n    $$\\sigma_{\\mathrm{LER}}^2 = \\frac{D}{4\\sigma\\sqrt{\\pi}} \\cdot \\frac{2\\pi\\sigma^2}{D^2} = \\frac{2\\pi\\sigma^2 D}{4\\sqrt{\\pi}\\sigma D^2} = \\frac{\\sqrt{\\pi}\\sigma}{2D}$$\n    Finally, the standard deviation of the LER is the square root of this variance:\n    $$\\sigma_{\\mathrm{LER}} = \\sqrt{\\frac{\\sqrt{\\pi}\\sigma}{2D}}$$\n    This expression gives the LER in terms of the dose $D$ and the PSF blur $\\sigma$, as required. The dimensional consistency is $[L] = \\sqrt{\\frac{[L]}{[L^{-1}]}} = \\sqrt{[L^2]}$, which is correct. The result shows the classic shot noise behavior where LER is inversely proportional to the square root of the dose ($1/\\sqrt{D}$) and increases with the square root of the blur ($\\sqrt{\\sigma}$).",
            "answer": "$$\n\\boxed{\\sqrt{\\frac{\\sqrt{\\pi}\\sigma}{2D}}}\n$$"
        },
        {
            "introduction": "A theoretical model is only as good as its ability to describe reality. This practice bridges the gap between theory and experiment by introducing a powerful technique for parameter estimation: Bayesian inference. You will use a physically-motivated model of the LER Power Spectral Density (PSD) and fit it to measured data to extract key unknown parameters, such as the secondary electron mean free path ($\\lambda$) and the acid quantum yield ($\\phi$) . This exercise demonstrates how to systematically learn from data to make your models quantitative and predictive.",
            "id": "4167988",
            "problem": "You are modeling stochastic exposure in Extreme Ultraviolet (EUV) lithography for chemically amplified resists, where Line-Edge Roughness (LER) arises from photon shot noise and Secondary Electron (SE) transport. Assume the following physically motivated base:\n\n- Photon arrivals are a Poisson process with white noise spectral density proportional to the mean absorbed photon rate.\n- Acid generation is proportional to absorbed photons with acid quantum yield $\\phi$ (acids per absorbed photon), so the input white noise level scales linearly with $\\phi$.\n- SE transport acts as a linear, shift-invariant blur along the line edge through an exponential kernel $g(x) = \\frac{1}{2\\lambda}\\exp(-|x|/\\lambda)$ with SE mean free path $\\lambda$ (one-dimensional effective kernel along the edge). Its Fourier transform magnitude is $|G(k)| = \\frac{1}{1+(k\\lambda)^2}$, hence the power transfer is $|G(k)|^2 = \\frac{1}{(1+(k\\lambda)^2)^2}$.\n- The measured LER Power Spectral Density (PSD) along the line edge at spatial frequency $k$ is modeled as\n$$\nS_{\\text{model}}(k;\\lambda,\\phi) = S_0\\,\\phi\\,|G(k;\\lambda)|^2 + N_0 = S_0\\,\\phi\\,\\frac{1}{\\left(1+(k\\lambda)^2\\right)^2} + N_0,\n$$\nwhere $S_0$ is a known proportionality constant from exposure and absorption conditions and $N_0$ is a known additive instrument noise floor.\n\nYou are given a measured LER PSD data set at discrete spatial frequencies. Assume independent Gaussian measurement errors at each frequency with known standard deviation $\\sigma$, and independent log-normal priors for $\\lambda$ and $\\phi$ with specified hyperparameters. Use Bayesian inference to derive the unnormalized posterior for $(\\lambda, \\phi)$ and evaluate its natural logarithm at a set of test parameter points.\n\nAll symbols and units:\n- $\\lambda$: SE mean free path along the edge, in nanometers (nm). Convert to micrometers (µm) via $\\lambda_{\\mu\\mathrm{m}} = \\lambda_{\\mathrm{nm}}/1000$ when used with $k$ below.\n- $\\phi$: acid quantum yield (dimensionless, acids per absorbed photon).\n- $k$: spatial frequency in inverse micrometers ($\\mu\\mathrm{m}^{-1}$).\n- $S_{\\text{meas}}(k)$: measured PSD values in arbitrary PSD units.\n- $S_0 = 2.0\\times 10^{-4}$, $N_0 = 1.0\\times 10^{-7}$, $\\sigma = 5.0\\times 10^{-5}$ (all in consistent PSD units).\n- Prior for $\\lambda$ (in nm): $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$.\n- Prior for $\\phi$: $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$.\n\nData provided:\n- Frequencies (in $\\mu\\mathrm{m}^{-1}$): $k = [0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0]$.\n- Measured PSD $S_{\\text{meas}}(k)$ at these $k$:\n$[0.001499992,\\ 0.001499668,\\ 0.001498375,\\ 0.001493201,\\ 0.001474330,\\ 0.001395289,\\ 0.001139412,\\ 0.000593658,\\ 0.000277216,\\ 0.000132955]$.\n\nTask:\n1. Starting only from the fundamental bases above (Poisson shot noise, linear shift-invariant blur, and the given exponential kernel), derive the unnormalized posterior density $p(\\lambda,\\phi \\mid \\text{data})$ up to a normalization constant. Explicitly write the expression for the natural logarithm of the unnormalized posterior, $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$, showing its dependence on $(\\lambda,\\phi)$.\n2. Implement a program that evaluates $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ at the following test cases, where $\\lambda$ is in nanometers and $\\phi$ is dimensionless:\n   - Case $1$: $(\\lambda,\\phi)=(12.0, 7.5)$.\n   - Case $2$: $(\\lambda,\\phi)=(4.0, 7.5)$.\n   - Case $3$: $(\\lambda,\\phi)=(20.0, 7.5)$.\n   - Case $4$: $(\\lambda,\\phi)=(12.0, 4.0)$.\n   - Case $5$: $(\\lambda,\\phi)=(12.0, 12.0)$.\n   - Case $6$: $(\\lambda,\\phi)=(3.0, 20.0)$.\n\nAssumptions for the likelihood:\n- For each frequency $k_i$, the measurement model is $S_{\\text{meas}}(k_i) = S_{\\text{model}}(k_i; \\lambda,\\phi) + \\varepsilon_i$ with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ independently, with $\\sigma = 5.0\\times 10^{-5}$.\n\nAssumptions for the priors:\n- $p(\\lambda) \\propto \\frac{1}{\\lambda} \\exp\\!\\left(-\\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}\\right)$ for $\\lambda > 0$, where $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$.\n- $p(\\phi) \\propto \\frac{1}{\\phi} \\exp\\!\\left(-\\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2}\\right)$ for $\\phi > 0$, where $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"), where each \"result\" is the value of $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ for the corresponding test case, expressed as a floating-point number. Ensure that all computations convert $\\lambda$ from nanometers to micrometers before evaluating $|G(k;\\lambda)|^2$ so that the units of $k$ and $\\lambda$ are consistent. No user input is required; constants and data are as specified above. The outputs are unitless real numbers.",
            "solution": "We begin with the stochastic exposure framework: absorbed photons follow a Poisson process. For a Poisson process with mean rate, the fluctuations are white in the spatial frequency domain, and the power spectral density (PSD) of the fluctuations is flat and proportional to the mean. Acid generation is proportional to absorbed photons with acid quantum yield $\\phi$, so the input fluctuation PSD for the acid generation field scales linearly with $\\phi$.\n\nSecondary electron (SE) transport is modeled as a linear, shift-invariant blur along the edge given by the exponential kernel\n$$\ng(x) = \\frac{1}{2\\lambda}\\exp\\!\\left(-\\frac{|x|}{\\lambda}\\right),\n$$\nwhere $\\lambda$ is the mean free path. This kernel is normalized, i.e., $\\int_{-\\infty}^{\\infty} g(x)\\,dx = 1$. Its Fourier transform magnitude is well known:\n$$\n|G(k)| = \\frac{1}{1+(k\\lambda)^2},\n$$\nso that the power transfer function is\n$$\n|G(k)|^2 = \\frac{1}{\\left(1+(k\\lambda)^2\\right)^2}.\n$$\nBecause a linear, shift-invariant system scales the input PSD by the squared magnitude of its transfer function, the predicted LER PSD at spatial frequency $k$ is\n$$\nS_{\\text{model}}(k;\\lambda,\\phi) = S_0\\,\\phi\\,|G(k;\\lambda)|^2 + N_0 = S_0\\,\\phi\\,\\frac{1}{\\left(1+(k\\lambda)^2\\right)^2} + N_0,\n$$\nwhere $S_0$ aggregates proportionality factors from dose and absorption, and $N_0$ is an additive noise floor.\n\nWe are given discrete measurements $\\{(k_i, S_{\\text{meas}}(k_i))\\}_{i=1}^{n}$ with independent Gaussian errors:\n$$\nS_{\\text{meas}}(k_i) = S_{\\text{model}}(k_i;\\lambda,\\phi) + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\\quad i=1,\\dots,n,\n$$\nwith known $\\sigma$. The likelihood is therefore\n$$\np(\\text{data}\\mid \\lambda,\\phi) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma}\n\\exp\\!\\left( -\\frac{\\left(S_{\\text{meas}}(k_i) - S_{\\text{model}}(k_i;\\lambda,\\phi)\\right)^2}{2\\sigma^2} \\right).\n$$\n\nFor the priors, we use independent log-normal distributions:\n- For $\\lambda$ (in nanometers), $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$. The corresponding density is\n$$\np(\\lambda) = \\frac{1}{\\lambda\\,\\sigma_\\lambda\\sqrt{2\\pi}} \\exp\\!\\left( -\\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2} \\right), \\quad \\lambda > 0.\n$$\n- For $\\phi$, $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$:\n$$\np(\\phi) = \\frac{1}{\\phi\\,\\sigma_\\phi\\sqrt{2\\pi}} \\exp\\!\\left( -\\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2} \\right), \\quad \\phi > 0.\n$$\n\nBy Bayes’ theorem, the posterior is\n$$\np(\\lambda,\\phi \\mid \\text{data}) \\propto p(\\text{data} \\mid \\lambda,\\phi)\\, p(\\lambda)\\, p(\\phi).\n$$\nThe phrase “up to a normalization constant” means we may drop any factors that are constant with respect to $(\\lambda,\\phi)$. Taking natural logarithms, the unnormalized log-posterior is\n$$\n\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data}) =\n-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n} \\left(S_{\\text{meas}}(k_i) - S_{\\text{model}}(k_i;\\lambda,\\phi)\\right)^2\n-\\log \\lambda - \\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}\n-\\log \\phi - \\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2},\n$$\nwith $S_{\\text{model}}(k_i;\\lambda,\\phi) = S_0\\,\\phi\\,\\left(1 + \\left(k_i \\lambda_{\\mu\\mathrm{m}}\\right)^2\\right)^{-2} + N_0$, and $\\lambda_{\\mu\\mathrm{m}} = \\lambda_{\\mathrm{nm}}/1000$ to ensure unit consistency since $k_i$ is in $\\mu\\mathrm{m}^{-1}$.\n\nConstants and data given:\n- $S_0 = 2.0\\times 10^{-4}$, $N_0 = 1.0\\times 10^{-7}$, $\\sigma = 5.0\\times 10^{-5}$.\n- $\\mu_\\lambda = \\ln(10)$, $\\sigma_\\lambda = \\ln(1.5)$, $\\mu_\\phi = \\ln(8)$, $\\sigma_\\phi = \\ln(1.4)$.\n- $k = [0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0]$.\n- $S_{\\text{meas}}(k) = [0.001499992,\\ 0.001499668,\\ 0.001498375,\\ 0.001493201,\\ 0.001474330,\\ 0.001395289,\\ 0.001139412,\\ 0.000593658,\\ 0.000277216,\\ 0.000132955]$.\n\nAlgorithm to evaluate $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ for any $(\\lambda,\\phi)$ with $\\lambda0$, $\\phi0$:\n1. Convert $\\lambda$ from nanometers to micrometers: $\\lambda_{\\mu\\mathrm{m}} \\leftarrow \\lambda/1000$.\n2. For each $k_i$, compute $Q_i = \\left(1 + (k_i \\lambda_{\\mu\\mathrm{m}})^2\\right)^{-2}$.\n3. Compute $S_{\\text{model},i} = S_0\\,\\phi\\,Q_i + N_0$.\n4. Compute the residuals $r_i = S_{\\text{meas}}(k_i) - S_{\\text{model},i}$ and the log-likelihood term $-\\frac{1}{2\\sigma^2}\\sum_i r_i^2$.\n5. Compute the log-prior terms $-\\log \\lambda - \\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}$ and $-\\log \\phi - \\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2}$.\n6. Sum the terms to obtain $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$.\n7. Repeat for the specified test cases.\n\nThe program implements precisely these steps and outputs a single line containing the list of unnormalized log-posterior values for the six test cases, in the order specified. All computations are unit-consistent by converting $\\lambda$ from nanometers to micrometers before evaluating the transfer function.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef unnormalized_log_posterior(lam_nm, phi, k_vals, S_meas, S0, N0, sigma, mu_lam, sig_lam, mu_phi, sig_phi):\n    \"\"\"\n    Compute the unnormalized log-posterior log \\tilde{p}(lam, phi | data)\n    for given lambda (in nm) and phi, given data and hyperparameters.\n    \"\"\"\n    # Enforce positivity; return -inf for invalid parameter values\n    if lam_nm = 0.0 or phi = 0.0:\n        return float(\"-inf\")\n\n    # Convert lambda from nm to um to match k units (um^-1)\n    lam_um = lam_nm / 1000.0\n\n    # Power transfer function |G(k)|^2 for exponential kernel g(x) = (1/(2*lambda)) exp(-|x|/lambda)\n    # |G(k)| = 1 / (1 + (k*lambda)^2), so |G(k)|^2 = 1 / (1 + (k*lambda)^2)^2\n    Q = 1.0 / (1.0 + (k_vals * lam_um) ** 2.0) ** 2.0\n\n    # Model PSD at each frequency\n    S_model = S0 * phi * Q + N0\n\n    # Gaussian likelihood (up to an additive constant): -0.5 * sum((residual/sigma)^2)\n    residuals = S_meas - S_model\n    log_like = -0.5 * np.sum((residuals / sigma) ** 2.0)\n\n    # Log-normal priors (up to additive constants): -ln(x) - (ln x - mu)^2 / (2 sigma^2)\n    log_lam = np.log(lam_nm)\n    log_phi = np.log(phi)\n\n    log_prior_lam = -log_lam - ((log_lam - mu_lam) ** 2.0) / (2.0 * (sig_lam ** 2.0))\n    log_prior_phi = -log_phi - ((log_phi - mu_phi) ** 2.0) / (2.0 * (sig_phi ** 2.0))\n\n    # Unnormalized log-posterior\n    return log_like + log_prior_lam + log_prior_phi\n\ndef solve():\n    # Constants and data from the problem statement\n    S0 = 2.0e-4\n    N0 = 1.0e-7\n    sigma = 5.0e-5\n\n    # Log-normal prior hyperparameters\n    mu_lam = np.log(10.0)          # for lambda in nm\n    sig_lam = np.log(1.5)\n    mu_phi = np.log(8.0)\n    sig_phi = np.log(1.4)\n\n    # Frequencies k in um^-1\n    k_vals = np.array([0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0], dtype=float)\n\n    # Measured PSD values S_meas(k)\n    S_meas = np.array([\n        0.001499992,\n        0.001499668,\n        0.001498375,\n        0.001493201,\n        0.001474330,\n        0.001395289,\n        0.001139412,\n        0.000593658,\n        0.000277216,\n        0.000132955\n    ], dtype=float)\n\n    # Define the test cases: (lambda_nm, phi)\n    test_cases = [\n        (12.0, 7.5),   # Case 1: near a plausible true value\n        (4.0, 7.5),    # Case 2: smaller lambda\n        (20.0, 7.5),   # Case 3: larger lambda\n        (12.0, 4.0),   # Case 4: smaller phi\n        (12.0, 12.0),  # Case 5: larger phi\n        (3.0, 20.0),   # Case 6: very small lambda, very large phi (edge)\n    ]\n\n    results = []\n    for lam_nm, phi in test_cases:\n        lp = unnormalized_log_posterior(\n            lam_nm, phi,\n            k_vals, S_meas,\n            S0, N0, sigma,\n            mu_lam, sig_lam, mu_phi, sig_phi\n        )\n        results.append(lp)\n\n    # Final print statement in the exact required format.\n    # Format floats with sufficient precision for reproducibility.\n    print(f\"[{','.join(f'{val:.6f}' for val in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After learning how to calibrate models with data, an advanced modeler asks: \"What are the most informative experiments I can run?\" This exercise introduces the concept of D-optimal experimental design, a systematic method for selecting experimental conditions that maximize the information gained about model parameters. You will use the Fisher Information Matrix to determine the optimal combination of exposure dose and post-exposure bake (PEB) time to most precisely estimate the parameters of a stochastic resist model . Mastering this skill allows you to design efficient experiments that save time and resources while yielding the most valuable data.",
            "id": "4167999",
            "problem": "You are tasked with constructing, from first principles, a local $D$-optimal experimental design for Extreme Ultraviolet (EUV) photoresist characterization under stochastic exposure. Consider a resist model in which absorbed photons arrive as a Poisson process, generate acid via secondary electrons, and the acid subsequently diffuses during Post-Exposure Bake (PEB). The experiments vary exposure dose and PEB time.\n\nStart from the following foundational base:\n- Photon absorption and acid generation are stochastic, and the count of acid molecules in a fixed detection zone after PEB is modeled as a Poisson random variable. For a Poisson random variable, the likelihood is determined by its mean and the Fisher information matrix is defined by the expectation of the negative Hessian of the log-likelihood.\n- Secondary electrons produce a localized cluster of acid around each absorption site with a characteristic length scale, and diffusion during PEB broadens that cluster approximately as a Gaussian kernel whose variance increases with time. For a Gaussian distribution in two dimensions centered in a circular detection window of radius, the fraction captured inside the window is determined by the cumulative probability mass within the radius.\n\nDefine the unknown parameter vector as $\\boldsymbol{\\theta} = (\\lambda,\\phi,\\ell_{a})$, where:\n- $\\lambda$ is the proportionality between dose and the expected number of absorption events in the detection zone.\n- $\\phi$ is the mean acid yield per absorption event (reflecting secondary electron amplification).\n- $\\ell_{a}$ is the effective initial acid cluster characteristic length (pre-PEB), in nanometers.\n\nFor an experiment with exposure dose $D$ (in $\\mathrm{mJ}/\\mathrm{cm}^{2}$) and PEB time $t$ (in $\\mathrm{s}$), the expected acid count in a circular detection window of radius $r_{0}$ (in $\\mathrm{nm}$) is modeled as:\n- The post-PEB spatial spread standard deviation $\\sigma(t,\\ell_{a})$ scales as $\\sigma(t,\\ell_{a}) = \\ell_{a}\\sqrt{1 + t/t_{0}}$, where $t_{0}$ (in $\\mathrm{s}$) sets the PEB time scale.\n- Assuming a two-dimensional Gaussian profile, the fraction $F$ of acid within radius $r_{0}$ is $F = 1 - \\exp\\!\\left(-r_{0}^{2}/(2\\sigma^{2})\\right)$.\n- The Poisson mean for the acid count is $\\mu(D,t;\\boldsymbol{\\theta}) = \\lambda\\,\\phi\\,D\\,F(t;\\ell_{a})$.\n\nUnder the Poisson assumption, the Fisher information contribution from a single experiment at condition $(D,t)$ depends on the gradient of $\\mu(D,t;\\boldsymbol{\\theta})$ with respect to the parameters and inversely on $\\mu(D,t;\\boldsymbol{\\theta})$. The total Fisher information matrix for a set of experiments is the sum of the contributions over all selected conditions. A local $D$-optimal design maximizes the determinant of this Fisher information matrix at a nominal parameter value $\\boldsymbol{\\theta}_{0}$.\n\nYour task is to write a complete program that:\n- Accepts no input and uses the three test cases specified below.\n- For each test case, constructs all experimental condition pairs $(D,t)$ from the provided candidate sets and selects, with replacement, a fixed number $N$ of experiments that maximizes the determinant of the Fisher information matrix evaluated at the given nominal parameter $\\boldsymbol{\\theta}_{0}$. Use the Poisson model and the Gaussian capture fraction described above to formulate $\\mu(D,t;\\boldsymbol{\\theta})$ and its gradient.\n- Treat extremely small $\\mu$ values robustly by applying a nonzero lower bound $\\varepsilon$ inside the Fisher information expression to avoid division by zero or ill-conditioning. You must implement this regularization using $\\mu_{\\mathrm{eff}} = \\max(\\mu,\\varepsilon)$ with a small positive $\\varepsilon$.\n\nTest suite and constants:\n- Test case $1$ (general, happy path):\n    - Dose candidates $D \\in \\{\\,5,\\,10,\\,20,\\,40\\,\\}$ in $\\mathrm{mJ}/\\mathrm{cm}^{2}$.\n    - PEB time candidates $t \\in \\{\\,0,\\,10,\\,30,\\,60\\,\\}$ in $\\mathrm{s}$.\n    - Detection radius $r_{0} = 20\\,\\mathrm{nm}$.\n    - PEB time scale $t_{0} = 30\\,\\mathrm{s}$.\n    - Number of experiments $N = 3$.\n    - Nominal parameters $\\boldsymbol{\\theta}_{0} = (\\lambda,\\phi,\\ell_{a}) = (0.8,\\,50,\\,8\\,\\mathrm{nm})$.\n    - Regularization $\\varepsilon = 10^{-12}$.\n- Test case $2$ (moderate dose/time, different scale):\n    - Dose candidates $D \\in \\{\\,1,\\,2,\\,4,\\,8\\,\\}$ in $\\mathrm{mJ}/\\mathrm{cm}^{2}$.\n    - PEB time candidates $t \\in \\{\\,0,\\,5,\\,15\\,\\}$ in $\\mathrm{s}$.\n    - Detection radius $r_{0} = 15\\,\\mathrm{nm}$.\n    - PEB time scale $t_{0} = 20\\,\\mathrm{s}$.\n    - Number of experiments $N = 4$.\n    - Nominal parameters $\\boldsymbol{\\theta}_{0} = (1.2,\\,20,\\,5\\,\\mathrm{nm})$.\n    - Regularization $\\varepsilon = 10^{-12}$.\n- Test case $3$ (edge case with near-zero dose):\n    - Dose candidates $D \\in \\{\\,0.1,\\,0.5,\\,1.0\\,\\}$ in $\\mathrm{mJ}/\\mathrm{cm}^{2}$.\n    - PEB time candidates $t \\in \\{\\,0,\\,2\\,\\}$ in $\\mathrm{s}$.\n    - Detection radius $r_{0} = 10\\,\\mathrm{nm}$.\n    - PEB time scale $t_{0} = 10\\,\\mathrm{s}$.\n    - Number of experiments $N = 2$.\n    - Nominal parameters $\\boldsymbol{\\theta}_{0} = (0.3,\\,5,\\,3\\,\\mathrm{nm})$.\n    - Regularization $\\varepsilon = 10^{-12}$.\n\nAngle units do not apply. Physical units apply to $D$ and $t$, so ensure the selected condition sets are expressed in $\\mathrm{mJ}/\\mathrm{cm}^{2}$ for dose and $\\mathrm{s}$ for time.\n\nOutput specification:\n- For each test case, return a flat list whose first element is the maximal determinant of the Fisher information matrix (a float), followed by the selected condition set encoded as alternating dose and time values in the units specified above, in the order the experiments are chosen (floats).\n- Your program should produce a single line of output containing the results from all test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a list, for example: $[\\,[\\text{det}_{1},D_{1,1},t_{1,1},\\dots],\\,[\\text{det}_{2},D_{2,1},t_{2,1},\\dots],\\,[\\text{det}_{3},D_{3,1},t_{3,1},\\dots]\\,]$.",
            "solution": "The problem is valid. It presents a well-posed, scientifically grounded task in the field of semiconductor process modeling and statistical experimental design. All necessary parameters, models, and constants are provided, and there are no internal contradictions or violations of physical principles.\n\nThe objective is to determine a locally $D$-optimal experimental design for estimating the parameters $\\boldsymbol{\\theta} = (\\lambda, \\phi, \\ell_{a})$ of a stochastic photoresist model. A $D$-optimal design maximizes the determinant of the Fisher Information Matrix (FIM), which corresponds to minimizing the volume of the joint confidence ellipsoid of the parameter estimates. The design is \"local\" because the FIM is evaluated at a nominal parameter value $\\boldsymbol{\\theta}_{0}$.\n\nThe experimental conditions are exposure dose $D$ and Post-Exposure Bake (PEB) time $t$. The observable is the number of acid molecules in a detection zone, which is modeled as a Poisson random variable with a mean count $\\mu(D,t;\\boldsymbol{\\theta})$.\n\nFirst, we define the model for the mean acid count $\\mu$. The number of absorption events is proportional to dose $D$ via parameter $\\lambda$. Each event yields on average $\\phi$ acid molecules. These molecules subsequently diffuse. The expected count in a circular detection window of radius $r_{0}$ is thus:\n$$ \\mu(D,t;\\boldsymbol{\\theta}) = \\lambda\\,\\phi\\,D\\,F(t;\\ell_{a}) $$\nHere, $F(t;\\ell_{a})$ is the fraction of acid captured within the window. This fraction depends on the spatial spread of the acid, modeled by a standard deviation $\\sigma$. The initial spread is given by $\\ell_{a}$, and it increases with PEB time $t$ according to:\n$$ \\sigma(t,\\ell_{a}) = \\ell_{a}\\sqrt{1 + t/t_{0}} $$\nwhere $t_{0}$ is a characteristic time scale. Assuming a two-dimensional Gaussian profile for the acid distribution, the capture fraction $F$ is given by the cumulative distribution function integrated over the circular window:\n$$ F = 1 - \\exp\\left(-\\frac{r_{0}^{2}}{2\\sigma^{2}}\\right) $$\n\nFor a Poisson-distributed observation with mean $\\mu$, the FIM for a single experiment with respect to the parameter vector $\\boldsymbol{\\theta}$ is a $3 \\times 3$ matrix given by:\n$$ \\mathcal{I}(\\boldsymbol{\\theta}) = \\frac{1}{\\mu(\\boldsymbol{\\theta})} (\\nabla_{\\boldsymbol{\\theta}}\\mu) (\\nabla_{\\boldsymbol{\\theta}}\\mu)^T $$\nwhere $\\nabla_{\\boldsymbol{\\theta}}\\mu$ is the gradient of the mean $\\mu$ with respect to the parameters $\\lambda$, $\\phi$, and $\\ell_{a}$. A regularization is applied to prevent division by zero for small $\\mu$, using $\\mu_{\\mathrm{eff}} = \\max(\\mu, \\varepsilon)$, where $\\varepsilon$ is a small positive constant. The FIM for a single experiment is therefore $\\mathcal{I}(D, t) = \\frac{1}{\\mu_{\\mathrm{eff}}} (\\nabla_{\\boldsymbol{\\theta}}\\mu) (\\nabla_{\\boldsymbol{\\theta}}\\mu)^T$.\n\nThe components of the gradient vector $\\nabla_{\\boldsymbol{\\theta}}\\mu$ are calculated by taking partial derivatives of $\\mu$ with respect to each parameter, evaluated at the nominal point $\\boldsymbol{\\theta}_{0}=(\\lambda_{0}, \\phi_{0}, \\ell_{a,0})$:\n$1$. Derivative with respect to $\\lambda$:\n$$ \\frac{\\partial \\mu}{\\partial \\lambda} = \\phi D F(t;\\ell_{a}) $$\n$2$. Derivative with respect to $\\phi$:\n$$ \\frac{\\partial \\mu}{\\partial \\phi} = \\lambda D F(t;\\ell_{a}) $$\n$3$. Derivative with respect to $\\ell_{a}$:\n$$ \\frac{\\partial \\mu}{\\partial \\ell_{a}} = \\lambda \\phi D \\frac{\\partial F}{\\partial \\ell_{a}} $$\nUsing the chain rule, $\\frac{\\partial F}{\\partial \\ell_{a}}$ is found to be:\n$$ \\frac{\\partial F}{\\partial \\ell_{a}} = \\frac{\\partial F}{\\partial \\sigma} \\frac{\\partial \\sigma}{\\partial \\ell_{a}} = \\left( \\exp\\left(-\\frac{r_{0}^{2}}{2\\sigma^{2}}\\right) \\cdot \\frac{r_{0}^{2}}{\\sigma^{3}} \\right) \\cdot \\left( \\sqrt{1 + t/t_{0}} \\right) = (1-F) \\frac{r_{0}^{2}}{\\sigma^{3}} \\frac{\\sigma}{\\ell_{a}} = (1-F)\\frac{r_{0}^{2}}{\\sigma^{2}\\ell_{a}} $$\nSubstituting this back, the third gradient component is:\n$$ \\frac{\\partial \\mu}{\\partial \\ell_{a}} = \\lambda \\phi D (1-F) \\frac{r_{0}^{2}}{\\sigma^{2}\\ell_{a}} $$\n\nThe total FIM for a design consisting of $N$ experiments, $\\{(D_{k}, t_{k})\\}_{k=1}^{N}$, is the sum of the individual FIMs:\n$$ \\mathcal{I}_{\\text{total}} = \\sum_{k=1}^{N} \\mathcal{I}(D_{k}, t_{k}) $$\nThe goal is to choose the set of $N$ experiments from the candidate pool that maximizes $\\det(\\mathcal{I}_{\\text{total}})$.\n\nThe algorithmic approach is as follows:\n$1$. Construct a set of all possible experimental conditions $(D, t)$ by taking the Cartesian product of the candidate dose and time values.\n$2$. For each unique condition $(D, t)$ in this set, calculate its corresponding $3 \\times 3$ FIM contribution, $\\mathcal{I}(D, t)$, using the formulas above evaluated at $\\boldsymbol{\\theta}_{0}$.\n$3$. The problem involves selecting $N$ experiments with replacement. This is a combinatorial problem. We generate all unique multisets of size $N$ from the set of pre-computed FIMs. This is equivalent to finding all combinations with replacement of $N$ indices corresponding to the experimental conditions.\n$4$. For each multiset, sum the $N$ FIM contributions to get a total FIM, $\\mathcal{I}_{\\text{total}}$.\n$5$. Compute the determinant of this total FIM, $\\det(\\mathcal{I}_{\\text{total}})$.\n$6$. The optimal design is the multiset of experiments that yields the maximum determinant. The final output consists of this maximum determinant value and the list of the $N$ chosen $(D, t)$ pairs.\n\nThis exhaustive search is computationally feasible for the problem sizes specified in the test cases and guarantees finding the globally $D$-optimal design within the given discrete set of experimental conditions.",
            "answer": "```python\nimport numpy as np\nfrom itertools import product, combinations_with_replacement\n\ndef solve():\n    \"\"\"\n    Constructs a local D-optimal experimental design for EUV photoresist characterization.\n    \"\"\"\n    test_cases = [\n        {\n            \"D_candidates\": [5.0, 10.0, 20.0, 40.0],\n            \"t_candidates\": [0.0, 10.0, 30.0, 60.0],\n            \"r0\": 20.0,\n            \"t0\": 30.0,\n            \"N\": 3,\n            \"theta0\": (0.8, 50.0, 8.0),\n            \"epsilon\": 1e-12\n        },\n        {\n            \"D_candidates\": [1.0, 2.0, 4.0, 8.0],\n            \"t_candidates\": [0.0, 5.0, 15.0],\n            \"r0\": 15.0,\n            \"t0\": 20.0,\n            \"N\": 4,\n            \"theta0\": (1.2, 20.0, 5.0),\n            \"epsilon\": 1e-12\n        },\n        {\n            \"D_candidates\": [0.1, 0.5, 1.0],\n            \"t_candidates\": [0.0, 2.0],\n            \"r0\": 10.0,\n            \"t0\": 10.0,\n            \"N\": 2,\n            \"theta0\": (0.3, 5.0, 3.0),\n            \"epsilon\": 1e-12\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        D_candidates = case[\"D_candidates\"]\n        t_candidates = case[\"t_candidates\"]\n        r0 = case[\"r0\"]\n        t0 = case[\"t0\"]\n        N = case[\"N\"]\n        theta0 = case[\"theta0\"]\n        epsilon = case[\"epsilon\"]\n        \n        lambda0, phi0, la0 = theta0\n\n        all_conditions = list(product(D_candidates, t_candidates))\n        num_conditions = len(all_conditions)\n        \n        # Pre-calculate FIM for each possible condition\n        fims = []\n        for D, t in all_conditions:\n            if la0 == 0.0:\n                fims.append(np.zeros((3, 3)))\n                continue\n\n            sigma_sq = la0**2 * (1.0 + t / t0)\n            \n            if sigma_sq == 0.0:\n                 fims.append(np.zeros((3, 3)))\n                 continue\n            \n            # Fraction F of acid captured\n            F = 1.0 - np.exp(-r0**2 / (2.0 * sigma_sq))\n            \n            # Mean acid count mu\n            mu = lambda0 * phi0 * D * F\n            mu_eff = max(mu, epsilon)\n            \n            # Gradient of mu w.r.t. theta = (lambda, phi, la)\n            grad_mu = np.zeros(3, dtype=np.float64)\n            grad_mu[0] = phi0 * D * F  # d(mu)/d(lambda)\n            grad_mu[1] = lambda0 * D * F  # d(mu)/d(phi)\n            \n            # d(mu)/d(la) = lambda0 * phi0 * D * (1-F) * r0^2 / (sigma^2 * la0)\n            dmu_dla = lambda0 * phi0 * D * (1.0 - F) * (r0**2) / (sigma_sq * la0)\n            grad_mu[2] = dmu_dla\n\n            # FIM for one experiment\n            fim = np.outer(grad_mu, grad_mu) / mu_eff\n            fims.append(fim)\n\n        max_det = -1.0\n        best_combo_indices = None\n\n        # Iterate through all combinations of N experiments with replacement\n        indices = range(num_conditions)\n        for combo in combinations_with_replacement(indices, N):\n            total_fim = np.zeros((3, 3), dtype=np.float64)\n            for index in combo:\n                total_fim += fims[index]\n            \n            current_det = np.linalg.det(total_fim)\n            \n            if current_det  max_det:\n                max_det = current_det\n                best_combo_indices = combo\n\n        # Format the result for this test case\n        result_list = [max_det]\n        for index in best_combo_indices:\n            D, t = all_conditions[index]\n            result_list.extend([float(D), float(t)])\n        \n        final_results.append(result_list)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}