{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering the impact of stochasticity in EUV lithography is to understand its theoretical roots. This practice guides you through a foundational, first-principles derivation of how the randomness of photon arrivals—photon shot noise—directly translates into Line-Edge Roughness (LER), a critical performance metric in semiconductor manufacturing. By connecting the dose ($D$) and the secondary electron blur ($\\sigma$) to the final LER through a simplified model, you will build a concrete intuition for the fundamental trade-offs at play .",
            "id": "4167966",
            "problem": "An Extreme Ultraviolet (EUV) lithography line-edge can be modeled in one spatial dimension, with the mask transmitting for $x>0$ and blocking for $x<0$. Absorbed photon arrivals in the resist are a spatial Poisson process with mean linear intensity $D$ (photons per unit length) over the transmitting region. Each absorbed photon deposits energy that subsequently produces a latent image via a blur kernel that represents the Point Spread Function (PSF), including secondary electron transport. Assume the PSF is Gaussian and normalized in one dimension: $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)$, where $\\sigma$ is the standard deviation characterizing the effective blur due to the PSF, including secondary electrons.\n\nLet the latent dose (energy density) profile be $A(x)$, and let the final resist response $R(A)$ be a monotone differentiable transfer function mapping dose $A$ to a measurable output that defines the printed edge by the threshold crossing $R(x) = R_{\\mathrm{th}}$ at $x = x_{\\mathrm{t}}$. Define the edge slope $S$ as the magnitude of the spatial derivative of the mean response at the threshold location, $S \\equiv \\left|\\frac{d\\,\\mathbb{E}[R(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right|$. Shot noise in photon counts produces stochastic fluctuations in $A(x)$ and, via $R(A)$, in the threshold crossing location. Starting from first principles of Poisson shot noise and linear systems, derive an analytic expression for the Line Edge Roughness (LER) standard deviation $\\sigma_{\\mathrm{LER}}$ caused purely by shot noise, expressed explicitly in terms of the dose $D$, the PSF width $\\sigma$, and the edge slope. Evaluate the expression for the case of a symmetric step edge with threshold at the half-level of the mean latent dose, i.e., $x_{\\mathrm{t}} = 0$ where $\\mathbb{E}[A(0)] = \\frac{D}{2}$.\n\nYour final result must be a single closed-form expression for $\\sigma_{\\mathrm{LER}}$ showing its dependence on $D$ and $\\sigma$. Provide the expression, and do not include any numerical approximation. If you need to reference the edge slope, you must eliminate explicit dependence on the resist transfer function $R(A)$ by appropriately combining it with the latent dose slope in your derivation. No rounding is required. Do not include physical units in the final expression; however, treat $D$ as a photon count per unit length and $\\sigma$ as a length scale so that the dimensional consistency is clear.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   **System Geometry**: A one-dimensional system with a mask transmitting for $x > 0$ and blocking for $x < 0$.\n-   **Photon Arrival Process**: A spatial Poisson process with mean linear intensity $D$ (photons per unit length) in the transmitting region ($x > 0$).\n-   **Point Spread Function (PSF)**: A normalized one-dimensional Gaussian, $g(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)$, where $\\sigma$ is the standard deviation characterizing the effective blur.\n-   **Latent Dose Profile**: $A(x)$, the energy density profile resulting from absorbed photons convolved with the PSF.\n-   **Resist Response**: A monotone differentiable transfer function $R(A)$.\n-   **Edge Definition**: The printed edge is at position $x_{\\mathrm{t}}$ where the response crosses a threshold, $R(x) = R_{\\mathrm{th}}$.\n-   **Edge Slope Definition**: $S \\equiv \\left|\\frac{d\\,\\mathbb{E}[R(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right|$, where $\\mathbb{E}[\\cdot]$ denotes the expectation value.\n-   **Stochastic Fluctuation Source**: Shot noise in photon counts.\n-   **Objective**: Derive an analytic expression for the Line Edge Roughness (LER) standard deviation, $\\sigma_{\\mathrm{LER}}$, due to shot noise.\n-   **Evaluation Condition**: The edge is symmetric, with the threshold at the half-level of the mean latent dose, which occurs at $x_{\\mathrm{t}} = 0$. It is given that $\\mathbb{E}[A(0)] = \\frac{D}{2}$.\n-   **Final Expression Requirements**: $\\sigma_{\\mathrm{LER}}$ must be expressed explicitly in terms of dose $D$ and PSF width $\\sigma$, eliminating dependence on the resist transfer function $R(A)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective. It employs a standard and widely accepted model for stochastic effects in lithography (Poisson shot noise, Gaussian PSF). The components of the model are clearly defined, and the objective is a specific analytical derivation. The problem is self-contained and free of contradictions or ambiguities. The simplifications (1D model, perfect step mask) are standard for analytical tractability and do not render the problem scientifically unsound or unrealistic in a theoretical context. Therefore, the problem is deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe latent dose profile $A(x)$ is the cumulative effect of all absorbed photons. Since photon arrivals are a Poisson point process, $A(x)$ can be modeled as a shot noise process. Let the locations of the absorbed photons be $\\{z_i\\}$. As photons are only transmitted for $x > 0$, the $z_i$ are distributed in $(0, \\infty)$ with a constant rate $D$. The dose at position $x$ is the sum of the contributions from each photon, where each contribution is described by the PSF $g(x)$:\n$$A(x) = \\sum_i g(x - z_i)$$\nThis is a linear shot noise process. The statistical properties of $A(x)$ are described by Campbell's theorems.\n\nThe Line Edge Roughness, $\\sigma_{\\mathrm{LER}}$, is the standard deviation of the edge position $x_t$. The edge position is defined by a threshold crossing. While the problem defines it in terms of a generic resist response $R(A)$, it asks to eliminate this dependence. We can accomplish this by working directly with the latent dose $A(x)$. The edge is at a position $x_E$ where the dose $A(x_E)$ crosses a threshold $A_{\\mathrm{th}}$. Due to the stochastic nature of $A(x)$, the position $x_E$ is a random variable. We linearize the process around the mean edge position $x_{\\mathrm{t}}$.\n\nThe actual dose profile is $A(x) = \\mathbb{E}[A(x)] + \\delta A(x)$, where $\\delta A(x)$ is the zero-mean fluctuation. The edge position is found where $A(x_E) = A_{\\mathrm{th}}$. Let $x_E = x_{\\mathrm{t}} + \\delta x$, where $x_{\\mathrm{t}}$ is the mean edge position defined by $\\mathbb{E}[A(x_{\\mathrm{t}})] = A_{\\mathrm{th}}$.\n$$A(x_{\\mathrm{t}} + \\delta x) = \\mathbb{E}[A(x_{\\mathrm{t}} + \\delta x)] + \\delta A(x_{\\mathrm{t}} + \\delta x) = A_{\\mathrm{th}}$$\nExpanding $\\mathbb{E}[A(x_{\\mathrm{t}} + \\delta x)]$ in a Taylor series around $x_{\\mathrm{t}}$ to first order:\n$$\\mathbb{E}[A(x_{\\mathrm{t}})] + \\delta x \\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=x_{\\mathrm{t}}} + \\delta A(x_{\\mathrm{t}} + \\delta x) \\approx A_{\\mathrm{th}}$$\nSince $\\mathbb{E}[A(x_{\\mathrm{t}})] = A_{\\mathrm{th}}$ and for small fluctuations $\\delta A(x_{\\mathrm{t}} + \\delta x) \\approx \\delta A(x_{\\mathrm{t}})$, we get:\n$$\\delta x \\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=x_{\\mathrm{t}}} \\approx -\\delta A(x_{\\mathrm{t}})$$\nThe fluctuation in the edge position, $\\delta x$, is related to the dose fluctuation at the mean edge position. The variance of the edge position, $\\sigma_{\\mathrm{LER}}^2$, is therefore:\n$$\\sigma_{\\mathrm{LER}}^2 = \\mathbb{E}[(\\delta x)^2] \\approx \\frac{\\mathbb{E}[(\\delta A(x_{\\mathrm{t}}))^2]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right)^2} = \\frac{\\mathrm{Var}[A(x_{\\mathrm{t}})]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=x_{\\mathrm{t}}}\\right)^2}$$\nTo find $\\sigma_{\\mathrm{LER}}$, we must calculate the dose variance (the numerator) and the squared slope of the mean dose profile (the denominator) at the edge location $x_{\\mathrm{t}} = 0$.\n\n1.  **Mean Dose Profile $\\mathbb{E}[A(x)]$ and its Slope**:\n    According to Campbell's first theorem, the mean of the shot noise process is the convolution of the input rate function with the impulse response (PSF). The input rate is $\\lambda(z) = D$ for $z>0$ and $0$ otherwise.\n    $$\\mathbb{E}[A(x)] = \\int_{-\\infty}^{\\infty} \\lambda(z) g(x-z) \\,dz = D \\int_{0}^{\\infty} g(x-z) \\,dz$$\n    Let $u = x-z$, so $dz = -du$. The limits change from $z \\in [0, \\infty)$ to $u \\in (x, -\\infty)$.\n    $$\\mathbb{E}[A(x)] = D \\int_{x}^{-\\infty} g(u) (-du) = D \\int_{-\\infty}^{x} g(u) \\,du$$\n    This is $D$ times the cumulative distribution function (CDF) of the Gaussian PSF. Let $\\Phi(\\xi) = \\int_{-\\infty}^{\\xi} \\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} dt$ be the standard normal CDF. Then,\n    $$\\mathbb{E}[A(x)] = D \\cdot \\Phi\\left(\\frac{x}{\\sigma}\\right)$$\n    The slope of the mean dose profile is its derivative with respect to $x$:\n    $$\\frac{d\\mathbb{E}[A(x)]}{dx} = D \\frac{d}{dx} \\Phi\\left(\\frac{x}{\\sigma}\\right) = D \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) = D \\cdot g(x)$$\n    At the specified edge location $x_{\\mathrm{t}} = 0$, the slope is:\n    $$\\frac{d\\mathbb{E}[A(x)]}{dx}\\bigg|_{x=0} = D \\cdot g(0) = D \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma} = \\frac{D}{\\sigma\\sqrt{2\\pi}}$$\n\n2.  **Dose Variance $\\mathrm{Var}[A(x)]$**:\n    According to Campbell's second theorem, the variance of the shot noise process is given by the integral of the input rate function multiplied by the square of the PSF:\n    $$\\mathrm{Var}[A(x)] = \\int_{-\\infty}^{\\infty} \\lambda(z) [g(x-z)]^2 \\,dz = D \\int_{0}^{\\infty} [g(x-z)]^2 \\,dz$$\n    The square of the PSF is:\n    $$[g(x-z)]^2 = \\left(\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-z)^2}{2\\sigma^2}\\right)\\right)^2 = \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{(x-z)^2}{\\sigma^2}\\right)$$\n    We need to evaluate the variance at $x_{\\mathrm{t}} = 0$:\n    $$\\mathrm{Var}[A(0)] = D \\int_{0}^{\\infty} \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz = \\frac{D}{2\\pi\\sigma^2} \\int_{0}^{\\infty} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz$$\n    This is a standard Gaussian integral. Using the result $\\int_{0}^{\\infty} e^{-ay^2} dy = \\frac{1}{2}\\sqrt{\\frac{\\pi}{a}}$, with $a=1/\\sigma^2$:\n    $$\\int_{0}^{\\infty} \\exp\\left(-\\frac{z^2}{\\sigma^2}\\right) \\,dz = \\frac{1}{2}\\sqrt{\\pi\\sigma^2} = \\frac{\\sigma\\sqrt{\\pi}}{2}$$\n    Substituting this back into the expression for variance:\n    $$\\mathrm{Var}[A(0)] = \\frac{D}{2\\pi\\sigma^2} \\cdot \\frac{\\sigma\\sqrt{\\pi}}{2} = \\frac{D}{4\\sigma\\sqrt{\\pi}}$$\n\n3.  **Line Edge Roughness $\\sigma_{\\mathrm{LER}}$**:\n    Now we assemble the expression for $\\sigma_{\\mathrm{LER}}^2$:\n    $$\\sigma_{\\mathrm{LER}}^2 = \\frac{\\mathrm{Var}[A(0)]}{\\left(\\frac{d\\mathbb{E}[A(x)]}{dx}\\big|_{x=0}\\right)^2} = \\frac{\\frac{D}{4\\sigma\\sqrt{\\pi}}}{\\left(\\frac{D}{\\sigma\\sqrt{2\\pi}}\\right)^2} = \\frac{\\frac{D}{4\\sigma\\sqrt{\\pi}}}{\\frac{D^2}{2\\pi\\sigma^2}}$$\n    Simplifying the expression:\n    $$\\sigma_{\\mathrm{LER}}^2 = \\frac{D}{4\\sigma\\sqrt{\\pi}} \\cdot \\frac{2\\pi\\sigma^2}{D^2} = \\frac{2\\pi\\sigma^2 D}{4\\sqrt{\\pi}\\sigma D^2} = \\frac{\\sqrt{\\pi}\\sigma}{2D}$$\n    Finally, the standard deviation of the LER is the square root of this variance:\n    $$\\sigma_{\\mathrm{LER}} = \\sqrt{\\frac{\\sqrt{\\pi}\\sigma}{2D}}$$\n    This expression gives the LER in terms of the dose $D$ and the PSF blur $\\sigma$, as required. The dimensional consistency is $[L] = \\sqrt{\\frac{[L]}{[L^{-1}]}} = \\sqrt{[L^2]}$, which is correct. The result shows the classic shot noise behavior where LER is inversely proportional to the square root of the dose ($1/\\sqrt{D}$) and increases with the square root of the blur ($\\sqrt{\\sigma}$).",
            "answer": "$$\n\\boxed{\\sqrt{\\frac{\\sqrt{\\pi}\\sigma}{2D}}}\n$$"
        },
        {
            "introduction": "Theoretical models are powerful, but their practical value hinges on our ability to connect them to experimental reality by estimating their parameters from measured data. This exercise bridges that gap by introducing a Bayesian inference framework to estimate key physical parameters—the secondary electron mean free path ($\\lambda$) and acid quantum yield ($\\phi$)—from a simulated Power Spectral Density (PSD) of the line edge . Working through this problem provides hands-on experience with modern data analysis techniques, which are essential for model validation, calibration, and gaining deeper physical insight from experimental observations.",
            "id": "4167988",
            "problem": "You are modeling stochastic exposure in Extreme Ultraviolet (EUV) lithography for chemically amplified resists, where Line-Edge Roughness (LER) arises from photon shot noise and Secondary Electron (SE) transport. Assume the following physically motivated base:\n\n- Photon arrivals are a Poisson process with white noise spectral density proportional to the mean absorbed photon rate.\n- Acid generation is proportional to absorbed photons with acid quantum yield $\\phi$ (acids per absorbed photon), so the input white noise level scales linearly with $\\phi$.\n- SE transport acts as a linear, shift-invariant blur along the line edge through an exponential kernel $g(x) = \\frac{1}{2\\lambda}\\exp(-|x|/\\lambda)$ with SE mean free path $\\lambda$ (one-dimensional effective kernel along the edge). Its Fourier transform magnitude is $|G(k)| = \\frac{1}{1+(k\\lambda)^2}$, hence the power transfer is $|G(k)|^2 = \\frac{1}{(1+(k\\lambda)^2)^2}$.\n- The measured LER Power Spectral Density (PSD) along the line edge at spatial frequency $k$ is modeled as\n$$\nS_{\\text{model}}(k;\\lambda,\\phi) = S_0\\,\\phi\\,|G(k;\\lambda)|^2 + N_0 = S_0\\,\\phi\\,\\frac{1}{\\left(1+(k\\lambda)^2\\right)^2} + N_0,\n$$\nwhere $S_0$ is a known proportionality constant from exposure and absorption conditions and $N_0$ is a known additive instrument noise floor.\n\nYou are given a measured LER PSD data set at discrete spatial frequencies. Assume independent Gaussian measurement errors at each frequency with known standard deviation $\\sigma$, and independent log-normal priors for $\\lambda$ and $\\phi$ with specified hyperparameters. Use Bayesian inference to derive the unnormalized posterior for $(\\lambda, \\phi)$ and evaluate its natural logarithm at a set of test parameter points.\n\nAll symbols and units:\n- $\\lambda$: SE mean free path along the edge, in nanometers (nm). Convert to micrometers (µm) via $\\lambda_{\\mu\\mathrm{m}} = \\lambda_{\\mathrm{nm}}/1000$ when used with $k$ below.\n- $\\phi$: acid quantum yield (dimensionless, acids per absorbed photon).\n- $k$: spatial frequency in inverse micrometers ($\\mu\\mathrm{m}^{-1}$).\n- $S_{\\text{meas}}(k)$: measured PSD values in arbitrary PSD units.\n- $S_0 = 2.0 \\times 10^{-4}$, $N_0 = 1.0 \\times 10^{-7}$, $\\sigma = 5.0 \\times 10^{-5}$ (all in consistent PSD units).\n- Prior for $\\lambda$ (in nm): $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$.\n- Prior for $\\phi$: $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$.\n\nData provided:\n- Frequencies (in $\\mu\\mathrm{m}^{-1}$): $k = [0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0]$.\n- Measured PSD $S_{\\text{meas}}(k)$ at these $k$:\n$[0.001499992,\\ 0.001499668,\\ 0.001498375,\\ 0.001493201,\\ 0.001474330,\\ 0.001395289,\\ 0.001139412,\\ 0.000593658,\\ 0.000277216,\\ 0.000132955]$.\n\nTask:\n1. Starting only from the fundamental bases above (Poisson shot noise, linear shift-invariant blur, and the given exponential kernel), derive the unnormalized posterior density $p(\\lambda,\\phi \\mid \\text{data})$ up to a normalization constant. Explicitly write the expression for the natural logarithm of the unnormalized posterior, $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$, showing its dependence on $(\\lambda,\\phi)$.\n2. Implement a program that evaluates $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ at the following test cases, where $\\lambda$ is in nanometers and $\\phi$ is dimensionless:\n   - Case $1$: $(\\lambda,\\phi)=(12.0, 7.5)$.\n   - Case $2$: $(\\lambda,\\phi)=(4.0, 7.5)$.\n   - Case $3$: $(\\lambda,\\phi)=(20.0, 7.5)$.\n   - Case $4$: $(\\lambda,\\phi)=(12.0, 4.0)$.\n   - Case $5$: $(\\lambda,\\phi)=(12.0, 12.0)$.\n   - Case $6$: $(\\lambda,\\phi)=(3.0, 20.0)$.\n\nAssumptions for the likelihood:\n- For each frequency $k_i$, the measurement model is $S_{\\text{meas}}(k_i) = S_{\\text{model}}(k_i; \\lambda,\\phi) + \\varepsilon_i$ with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ independently, with $\\sigma = 5.0 \\times 10^{-5}$.\n\nAssumptions for the priors:\n- $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$, so $p(\\lambda) \\propto \\frac{1}{\\lambda} \\exp\\!\\left(-\\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}\\right)$ for $\\lambda > 0$.\n- $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$, so $p(\\phi) \\propto \\frac{1}{\\phi} \\exp\\!\\left(-\\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2}\\right)$ for $\\phi > 0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"), where each \"result\" is the value of $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ for the corresponding test case, expressed as a floating-point number. Ensure that all computations convert $\\lambda$ from nanometers to micrometers before evaluating $|G(k;\\lambda)|^2$ so that the units of $k$ and $\\lambda$ are consistent. No user input is required; constants and data are as specified above. The outputs are unitless real numbers.",
            "solution": "We begin with the stochastic exposure framework: absorbed photons follow a Poisson process. For a Poisson process with mean rate, the fluctuations are white in the spatial frequency domain, and the power spectral density (PSD) of the fluctuations is flat and proportional to the mean. Acid generation is proportional to absorbed photons with acid quantum yield $\\phi$, so the input fluctuation PSD for the acid generation field scales linearly with $\\phi$.\n\nSecondary electron (SE) transport is modeled as a linear, shift-invariant blur along the edge given by the exponential kernel\n$$\ng(x) = \\frac{1}{2\\lambda}\\exp\\!\\left(-\\frac{|x|}{\\lambda}\\right),\n$$\nwhere $\\lambda$ is the mean free path. This kernel is normalized, i.e., $\\int_{-\\infty}^{\\infty} g(x)\\,dx = 1$. Its Fourier transform magnitude is well known:\n$$\n|G(k)| = \\frac{1}{1+(k\\lambda)^2},\n$$\nso that the power transfer function is\n$$\n|G(k)|^2 = \\frac{1}{\\left(1+(k\\lambda)^2\\right)^2}.\n$$\nBecause a linear, shift-invariant system scales the input PSD by the squared magnitude of its transfer function, the predicted LER PSD at spatial frequency $k$ is\n$$\nS_{\\text{model}}(k;\\lambda,\\phi) = S_0\\,\\phi\\,|G(k;\\lambda)|^2 + N_0 = S_0\\,\\phi\\,\\frac{1}{\\left(1+(k\\lambda)^2\\right)^2} + N_0,\n$$\nwhere $S_0$ aggregates proportionality factors from dose and absorption, and $N_0$ is an additive noise floor.\n\nWe are given discrete measurements $\\{(k_i, S_{\\text{meas}}(k_i))\\}_{i=1}^{n}$ with independent Gaussian errors:\n$$\nS_{\\text{meas}}(k_i) = S_{\\text{model}}(k_i;\\lambda,\\phi) + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\\quad i=1,\\dots,n,\n$$\nwith known $\\sigma$. The likelihood is therefore\n$$\np(\\text{data}\\mid \\lambda,\\phi) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma}\n\\exp\\!\\left( -\\frac{\\left(S_{\\text{meas}}(k_i) - S_{\\text{model}}(k_i;\\lambda,\\phi)\\right)^2}{2\\sigma^2} \\right).\n$$\n\nFor the priors, we use independent log-normal distributions:\n- For $\\lambda$ (in nanometers), $\\log \\lambda \\sim \\mathcal{N}(\\mu_\\lambda, \\sigma_\\lambda^2)$ with $\\mu_\\lambda = \\ln(10)$ and $\\sigma_\\lambda = \\ln(1.5)$. The corresponding density is\n$$\np(\\lambda) = \\frac{1}{\\lambda\\,\\sigma_\\lambda\\sqrt{2\\pi}} \\exp\\!\\left( -\\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2} \\right), \\quad \\lambda > 0.\n$$\n- For $\\phi$, $\\log \\phi \\sim \\mathcal{N}(\\mu_\\phi, \\sigma_\\phi^2)$ with $\\mu_\\phi = \\ln(8)$ and $\\sigma_\\phi = \\ln(1.4)$:\n$$\np(\\phi) = \\frac{1}{\\phi\\,\\sigma_\\phi\\sqrt{2\\pi}} \\exp\\!\\left( -\\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2} \\right), \\quad \\phi > 0.\n$$\n\nBy Bayes’ theorem, the posterior is\n$$\np(\\lambda,\\phi \\mid \\text{data}) \\propto p(\\text{data} \\mid \\lambda,\\phi)\\, p(\\lambda)\\, p(\\phi).\n$$\nThe phrase “up to a normalization constant” means we may drop any factors that are constant with respect to $(\\lambda,\\phi)$. Taking natural logarithms, the unnormalized log-posterior is\n$$\n\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data}) =\n-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n} \\left(S_{\\text{meas}}(k_i) - S_{\\text{model}}(k_i;\\lambda,\\phi)\\right)^2\n-\\log \\lambda - \\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}\n-\\log \\phi - \\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2},\n$$\nwith $S_{\\text{model}}(k_i;\\lambda,\\phi) = S_0\\,\\phi\\,\\left(1 + \\left(k_i \\lambda_{\\mu\\mathrm{m}}\\right)^2\\right)^{-2} + N_0$, and $\\lambda_{\\mu\\mathrm{m}} = \\lambda_{\\mathrm{nm}}/1000$ to ensure unit consistency since $k_i$ is in $\\mu\\mathrm{m}^{-1}$.\n\nConstants and data given:\n- $S_0 = 2.0\\times 10^{-4}$, $N_0 = 1.0\\times 10^{-7}$, $\\sigma = 5.0\\times 10^{-5}$.\n- $\\mu_\\lambda = \\ln(10)$, $\\sigma_\\lambda = \\ln(1.5)$, $\\mu_\\phi = \\ln(8)$, $\\sigma_\\phi = \\ln(1.4)$.\n- $k = [0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0]$.\n- $S_{\\text{meas}}(k) = [0.001499992,\\ 0.001499668,\\ 0.001498375,\\ 0.001493201,\\ 0.001474330,\\ 0.001395289,\\ 0.001139412,\\ 0.000593658,\\ 0.000277216,\\ 0.000132955]$.\n\nAlgorithm to evaluate $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$ for any $(\\lambda,\\phi)$ with $\\lambda>0$, $\\phi>0$:\n1. Convert $\\lambda$ from nanometers to micrometers: $\\lambda_{\\mu\\mathrm{m}} \\leftarrow \\lambda/1000$.\n2. For each $k_i$, compute $Q_i = \\left(1 + (k_i \\lambda_{\\mu\\mathrm{m}})^2\\right)^{-2}$.\n3. Compute $S_{\\text{model},i} = S_0\\,\\phi\\,Q_i + N_0$.\n4. Compute the residuals $r_i = S_{\\text{meas}}(k_i) - S_{\\text{model},i}$ and the log-likelihood term $-\\frac{1}{2\\sigma^2}\\sum_i r_i^2$.\n5. Compute the log-prior terms $-\\log \\lambda - \\frac{(\\ln \\lambda - \\mu_\\lambda)^2}{2\\sigma_\\lambda^2}$ and $-\\log \\phi - \\frac{(\\ln \\phi - \\mu_\\phi)^2}{2\\sigma_\\phi^2}$.\n6. Sum the terms to obtain $\\log \\tilde{p}(\\lambda,\\phi \\mid \\text{data})$.\n7. Repeat for the specified test cases.\n\nThe program implements precisely these steps and outputs a single line containing the list of unnormalized log-posterior values for the six test cases, in the order specified. All computations are unit-consistent by converting $\\lambda$ from nanometers to micrometers before evaluating the transfer function.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef unnormalized_log_posterior(lam_nm, phi, k_vals, S_meas, S0, N0, sigma, mu_lam, sig_lam, mu_phi, sig_phi):\n    \"\"\"\n    Compute the unnormalized log-posterior log \\tilde{p}(lam, phi | data)\n    for given lambda (in nm) and phi, given data and hyperparameters.\n    \"\"\"\n    # Enforce positivity; return -inf for invalid parameter values\n    if lam_nm <= 0.0 or phi <= 0.0:\n        return float(\"-inf\")\n\n    # Convert lambda from nm to um to match k units (um^-1)\n    lam_um = lam_nm / 1000.0\n\n    # Power transfer function |G(k)|^2 for exponential kernel g(x) = (1/(2*lambda)) exp(-|x|/lambda)\n    # |G(k)| = 1 / (1 + (k*lambda)^2), so |G(k)|^2 = 1 / (1 + (k*lambda)^2)^2\n    Q = 1.0 / (1.0 + (k_vals * lam_um) ** 2.0) ** 2.0\n\n    # Model PSD at each frequency\n    S_model = S0 * phi * Q + N0\n\n    # Gaussian likelihood (up to an additive constant): -0.5 * sum((residual/sigma)^2)\n    residuals = S_meas - S_model\n    log_like = -0.5 * np.sum((residuals / sigma) ** 2.0)\n\n    # Log-normal priors (up to additive constants): -ln(x) - (ln x - mu)^2 / (2 sigma^2)\n    log_lam = np.log(lam_nm)\n    log_phi = np.log(phi)\n\n    log_prior_lam = -log_lam - ((log_lam - mu_lam) ** 2.0) / (2.0 * (sig_lam ** 2.0))\n    log_prior_phi = -log_phi - ((log_phi - mu_phi) ** 2.0) / (2.0 * (sig_phi ** 2.0))\n\n    # Unnormalized log-posterior\n    return log_like + log_prior_lam + log_prior_phi\n\ndef solve():\n    # Constants and data from the problem statement\n    S0 = 2.0e-4\n    N0 = 1.0e-7\n    sigma = 5.0e-5\n\n    # Log-normal prior hyperparameters\n    mu_lam = np.log(10.0)          # for lambda in nm\n    sig_lam = np.log(1.5)\n    mu_phi = np.log(8.0)\n    sig_phi = np.log(1.4)\n\n    # Frequencies k in um^-1\n    k_vals = np.array([0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 96.0, 128.0], dtype=float)\n\n    # Measured PSD values S_meas(k)\n    S_meas = np.array([\n        0.001499992,\n        0.001499668,\n        0.001498375,\n        0.001493201,\n        0.001474330,\n        0.001395289,\n        0.001139412,\n        0.000593658,\n        0.000277216,\n        0.000132955\n    ], dtype=float)\n\n    # Define the test cases: (lambda_nm, phi)\n    test_cases = [\n        (12.0, 7.5),   # Case 1: near a plausible true value\n        (4.0, 7.5),    # Case 2: smaller lambda\n        (20.0, 7.5),   # Case 3: larger lambda\n        (12.0, 4.0),   # Case 4: smaller phi\n        (12.0, 12.0),  # Case 5: larger phi\n        (3.0, 20.0),   # Case 6: very small lambda, very large phi (edge)\n    ]\n\n    results = []\n    for lam_nm, phi in test_cases:\n        lp = unnormalized_log_posterior(\n            lam_nm, phi,\n            k_vals, S_meas,\n            S0, N0, sigma,\n            mu_lam, sig_lam, mu_phi, sig_phi\n        )\n        results.append(lp)\n\n    # Final print statement in the exact required format.\n    # Format floats with sufficient precision for reproducibility.\n    print(f\"[{','.join(f'{val:.6f}' for val in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While analytical models offer invaluable insight, the full complexity of resist chemistry often necessitates direct stochastic simulation. This practice takes you into the computational core of process modeling, challenging you to analyze and compare two fundamental algorithms: the exact Stochastic Simulation Algorithm (SSA) and the approximate $\\tau$-leaping method . By deriving their computational costs and identifying the regimes where approximations are valid, you will develop a crucial understanding of the trade-offs between simulation accuracy and computational performance.",
            "id": "4167990",
            "problem": "Consider a spatially discretized Extreme Ultraviolet (EUV) photoresist model where chemical reactions due to shot noise and secondary electron exposure occur in a voxel grid. Let there be $N_{v}$ voxels, with $R$ reaction channels per voxel, and suppose the per-voxel total propensity scale is $a_{0}$ (units: $\\mathrm{s}^{-1}$). The total number of reaction channels in the system is $M = N_{v} R$, and the total propensity is $A = N_{v} a_{0}$.\n\nYou are asked to derive, from first principles of the Chemical Master Equation and the Stochastic Simulation Algorithm (SSA), the expected computational complexity of the SSA versus the $\\tau$-leaping method for simulating the reaction network over a time horizon $T$ (units: $\\mathrm{s}$). Your derivation must begin from the following bases:\n- The Chemical Master Equation gives that reaction events form a continuous-time Markov process with exponentially distributed inter-event times governed by the total propensity $A$.\n- The Stochastic Simulation Algorithm (SSA) draws one reaction event at a time; the expected number of events over time $T$ is $A T$. A naive reaction selection is linear in $M$, and a binary-tree or alias-augmented selection is logarithmic in $M$.\n- The $\\tau$-leaping method makes a leap of size $\\tau$ assuming propensities change only slightly; accuracy requires both a bounded relative change of propensities and sufficiently many firings per channel to justify Poisson sampling.\n\nAssume a simplified but scientifically consistent resist-chemistry setting:\n- Each voxel’s $R$ reaction propensities are of the same order, so that the typical per-channel propensity scale is $a_{0} / R$.\n- Stoichiometry per reaction consumes at most $\\nu_{\\max}$ molecules of the limiting species, and the minimal population scale per voxel is $X_{\\min}$ (molecules). This abstracts secondary electron spatial spreading, ensuring propensities are Lipschitz with respect to state.\n- A small relative-change budget $\\varepsilon \\in (0,1)$ and a required minimal expected firings per channel $k_{\\min}$ are set to ensure $\\tau$-leaping accuracy.\n- A safety fraction $s \\in (0,1)$ imposes a non-negativity safeguard on expected consumptions within a leap.\n\nStarting from these bases, derive expressions for:\n1. The expected SSA complexity under naive selection and under logarithmic selection in terms of $N_{v}$, $R$, $a_{0}$, and $T$.\n2. A conservative bound for the $\\tau$-leaping step size $\\tau$ using:\n   - A Lipschitz-type bound for the relative propensity change, $L = (\\nu_{\\max} / X_{\\min}) (a_{0} / R)$, leading to $\\tau_{\\text{small}} = \\varepsilon / L$.\n   - A many-firings condition, $\\tau_{\\text{many}} = k_{\\min} / (a_{0} / R)$.\n   - A non-negativity safety condition, $\\tau_{\\text{safe}} = s X_{\\min} R / (\\nu_{\\max} a_{0})$.\n   Define the operative leap size as $\\tau_{\\text{leap}} = \\min\\{\\tau_{\\text{small}}, \\tau_{\\text{many}}, \\tau_{\\text{safe}}\\}$.\n3. The expected $\\tau$-leaping complexity as the number of leaps times the per-leap work, assuming per-leap work scales linearly with $M$ because all $M$ channels are updated with Poisson draws, i.e., $C_{\\tau} = \\lceil T / \\tau_{\\text{leap}} \\rceil \\cdot M$.\n4. A precise accuracy regime criterion for $\\tau$-leaping: show that there exists a $\\tau$ satisfying all constraints simultaneously if and only if $\\tau_{\\text{many}} \\le \\min\\{\\tau_{\\text{small}}, \\tau_{\\text{safe}}\\}$. Return a boolean indicating whether this regime holds.\n\nImplement a program that, given a set of parameter tuples, computes:\n- $C_{\\text{SSA,lin}} = A T \\cdot M$ (naive linear selection).\n- $C_{\\text{SSA,log}} = A T \\cdot \\log_{2}(M)$ (logarithmic selection).\n- $C_{\\tau} = \\lceil T / \\tau_{\\text{leap}} \\rceil \\cdot M$.\n- $\\text{accurate} = \\text{True}$ if $\\tau_{\\text{many}} \\le \\min\\{\\tau_{\\text{small}}, \\tau_{\\text{safe}}\\}$, else $\\text{False}$.\n\nExpress complexity values as floats (unitless operation counts) and the accuracy as a boolean.\n\nUse the following test suite of parameters to exercise different regimes:\n- Case $1$ (happy path with high populations and balanced constraints):\n  - $N_{v} = 4096$, $R = 5$, $a_{0} = 200\\,\\mathrm{s}^{-1}$, $T = 0.05\\,\\mathrm{s}$, $\\varepsilon = 0.05$, $k_{\\min} = 20$, $\\nu_{\\max} = 2$, $X_{\\min} = 10^{4}$, $s = 0.2$.\n- Case $2$ (sparse events, many-firings constraint dominant, accuracy fails):\n  - $N_{v} = 64$, $R = 3$, $a_{0} = 0.3\\,\\mathrm{s}^{-1}$, $T = 1.0\\,\\mathrm{s}$, $\\varepsilon = 0.05$, $k_{\\min} = 20$, $\\nu_{\\max} = 2$, $X_{\\min} = 50$, $s = 0.5$.\n- Case $3$ (boundary where small-change equals many-firings):\n  - $N_{v} = 100$, $R = 4$, $a_{0} = 50\\,\\mathrm{s}^{-1}$, $T = 0.2\\,\\mathrm{s}$, $\\varepsilon = 0.02$, $k_{\\min} = 1$, $\\nu_{\\max} = 2$, $X_{\\min} = 100$, $s = 0.9$.\n- Case $4$ (non-negativity safety constrains $\\tau$ below many-firings threshold, accuracy fails):\n  - $N_{v} = 1000$, $R = 2$, $a_{0} = 20\\,\\mathrm{s}^{-1}$, $T = 0.1\\,\\mathrm{s}$, $\\varepsilon = 0.05$, $k_{\\min} = 10$, $\\nu_{\\max} = 3$, $X_{\\min} = 5$, $s = 0.2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of the form $[C_{\\text{SSA,lin}}, C_{\\text{SSA,log}}, C_{\\tau}, \\text{accurate}]$. For example, the final output format is $[[c_{1,\\text{lin}},c_{1,\\log},c_{1,\\tau},b_{1}],[c_{2,\\text{lin}},c_{2,\\log},c_{2,\\tau},b_{2}],\\ldots]$.",
            "solution": "The problem asks for a derivation of the computational complexity of the Stochastic Simulation Algorithm (SSA) and the $\\tau$-leaping method for a spatially discretized chemical reaction network, and a criterion for the accuracy of $\\tau$-leaping. This derivation is to be based on first principles of the Chemical Master Equation and the provided modeling assumptions for Extreme Ultraviolet (EUV) photoresist chemistry.\n\nThe system is defined by $N_{v}$ voxels, each with $R$ reaction channels. The total number of reaction channels is $M = N_{v} R$. The total propensity, which is the sum of all individual reaction propensities, is given as $A = N_{v} a_{0}$, where $a_{0}$ is the per-voxel total propensity scale in units of $\\mathrm{s}^{-1}$. The simulation is run for a total time $T$.\n\n1. Derivation of SSA Complexity ($C_{\\text{SSA}}$)\n\nThe Chemical Master Equation describes the system as a continuous-time Markov process. The time until the next reaction event is an exponential random variable with rate parameter $A$, the total propensity. The expected number of reaction events over a time horizon $T$ is therefore the total rate multiplied by the time duration, which is $N_{\\text{events}} = A T$.\n\nThe SSA simulates the system by advancing one reaction event at a time. The total computational complexity is the product of the number of events simulated and the computational work required per event. The work per event is dominated by the task of selecting which reaction channel fires.\n\n-   **Naive Linear Selection:** In this approach, for each event, one must iterate through all $M$ reaction channels to select the next reaction. The complexity of this selection step is linear in the number of channels, i.e., $\\mathcal{O}(M)$. Therefore, the total expected complexity, $C_{\\text{SSA,lin}}$, is:\n    $C_{\\text{SSA,lin}} = (\\text{Number of Events}) \\times (\\text{Work per Event}) = (A T) \\cdot M$.\n    Substituting the given definitions $A = N_{v} a_{0}$ and $M = N_{v} R$, we have:\n    $C_{\\text{SSA,lin}} = (N_{v} a_{0} T) (N_{v} R)$.\n\n-   **Logarithmic Selection:** More efficient selection algorithms, such as those based on binary trees (propensity trees) or composition-rejection methods, can select a reaction in time logarithmic with the number of channels. The complexity of this selection step is $\\mathcal{O}(\\log M)$. Therefore, the total expected complexity, $C_{\\text{SSA,log}}$, is:\n    $C_{\\text{SSA,log}} = (\\text{Number of Events}) \\times (\\text{Work per Event}) = (A T) \\cdot \\log_{2}(M)$.\n    Substituting the definitions for $A$ and $M$:\n    $C_{\\text{SSA,log}} = (N_{v} a_{0} T) \\log_{2}(N_{v} R)$.\n\n2. Derivation of the $\\tau$-leaping Step Size ($\\tau_{\\text{leap}}$)\n\nThe $\\tau$-leaping method approximates the dynamics by taking a time step $\\tau$ during which propensities are assumed constant. The number of firings of each reaction channel is then drawn from a Poisson distribution. The size of $\\tau$ is constrained by multiple accuracy and stability requirements.\n\n-   **Relative Propensity Change (Small-Change Condition):** To ensure the propensities do not change significantly during the leap, the relative change in any propensity must be bounded by a small value $\\varepsilon \\in (0,1)$. The problem provides a Lipschitz-type constant for the relative propensity change, $L = (\\nu_{\\max} / X_{\\min}) (a_{0} / R)$, where $\\nu_{\\max}$ is the maximum stoichiometry of a limiting species and $X_{\\min}$ is the minimum population scale. The cumulative relative change over $\\tau$ is approximately $L \\tau$. This leads to the constraint $L \\tau \\le \\varepsilon$, yielding an upper bound on $\\tau$:\n    $\\tau_{\\text{small}} = \\frac{\\varepsilon}{L} = \\frac{\\varepsilon X_{\\min} R}{\\nu_{\\max} a_{0}}$.\n\n-   **Sufficient Firings (Many-Firings Condition):** For the Poisson approximation to be statistically justified, the expected number of firings for a typical channel, $(a_0/R)\\tau$, must be sufficiently large, i.e., greater than a threshold $k_{\\min}$. This imposes a lower bound on $\\tau$: $(a_0/R)\\tau \\ge k_{\\min}$. The problem defines a characteristic time $\\tau_{\\text{many}}$ representing this boundary:\n    $\\tau_{\\text{many}} = \\frac{k_{\\min}}{a_{0} / R} = \\frac{k_{\\min} R}{a_{0}}$.\n\n-   **Non-Negativity Safety Condition:** To prevent species populations from becoming negative, the consumption of any species within a leap must be controlled. The problem specifies a conservative condition where the expected consumption from a single typical channel, which is $(a_{0}/R)\\tau \\cdot \\nu_{\\max}$, must be less than a safety fraction $s$ of the minimum population $X_{\\min}$. This gives the constraint $(a_{0}/R)\\tau \\nu_{\\max} \\le s X_{\\min}$, which yields another upper bound on $\\tau$:\n    $\\tau_{\\text{safe}} = \\frac{s X_{\\min}}{(a_{0}/R) \\nu_{\\max}} = \\frac{s X_{\\min} R}{\\nu_{\\max} a_{0}}$.\n\nThe problem defines the operative leap size, $\\tau_{\\text{leap}}$, as the minimum of these three characteristic times, enforcing all conditions simultaneously in a conservative manner:\n$\\tau_{\\text{leap}} = \\min\\{\\tau_{\\text{small}}, \\tau_{\\text{many}}, \\tau_{\\text{safe}}\\}$.\n\n3. Derivation of $\\tau$-leaping Complexity ($C_{\\tau}$)\n\nThe $\\tau$-leaping simulation advances in discrete steps of size $\\tau_{\\text{leap}}$. The number of steps required to cover the time horizon $T$ is $N_{\\text{leaps}} = T / \\tau_{\\text{leap}}$. Since an integer number of steps must be taken, we use the ceiling function: $N_{\\text{leaps}} = \\lceil T / \\tau_{\\text{leap}} \\rceil$.\n\nAt each leap, the algorithm must update the state by drawing a random number of firings for each of the $M$ reaction channels. This requires work proportional to $M$. The total complexity is the product of the number of leaps and the work per leap:\n$C_{\\tau} = N_{\\text{leaps}} \\cdot (\\text{Work per Leap}) = \\lceil T / \\tau_{\\text{leap}} \\rceil \\cdot M$.\n\n4. Accuracy Regime Criterion\n\nFor the $\\tau$-leaping method to be considered operating in a valid and accurate regime, there must exist a step size $\\tau$ that satisfies all underlying constraints simultaneously. This requires the existence of a $\\tau$ that is:\n-   small enough to satisfy the small-change condition: $\\tau \\le \\tau_{\\text{small}}$\n-   small enough to satisfy the non-negativity condition: $\\tau \\le \\tau_{\\text{safe}}$\n-   large enough to satisfy the many-firings condition: $\\tau \\ge \\tau_{\\text{many}}$\n\nA $\\tau$ satisfying all three conditions can only exist if the lower bound is less than or equal to the upper bound. The combined upper bound from the first two conditions is $\\min\\{\\tau_{\\text{small}}, \\tau_{\\text{safe}}\\}$. Thus, the criterion for a valid $\\tau$ to exist is:\n$\\tau_{\\text{many}} \\le \\min\\{\\tau_{\\text{small}}, \\tau_{\\text{safe}}\\}$.\n\nIf this inequality holds, the method is considered to be in an accurate regime. Otherwise, the constraints are contradictory, and no single $\\tau$ can satisfy the requirements for both statistical validity (many firings) and approximation accuracy (small change and non-negativity). The problem requires returning a boolean value, $\\text{accurate}$, indicating whether this condition is met.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the complexity of SSA and tau-leaping methods for simulating\n    a stochastic chemical reaction network based on provided parameters.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path with high populations and balanced constraints)\n        (4096, 5, 200, 0.05, 0.05, 20, 2, 1e4, 0.2),\n        # Case 2 (sparse events, many-firings constraint dominant, accuracy fails)\n        (64, 3, 0.3, 1.0, 0.05, 20, 2, 50, 0.5),\n        # Case 3 (boundary where small-change equals many-firings)\n        (100, 4, 50, 0.2, 0.02, 1, 2, 100, 0.9),\n        # Case 4 (non-negativity safety constrains tau below many-firings threshold, accuracy fails)\n        (1000, 2, 20, 0.1, 0.05, 10, 3, 5, 0.2),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nv, R, a0, T, eps, k_min, nu_max, X_min, s = case\n\n        # Total number of reaction channels\n        M = float(Nv * R)\n        # Total propensity\n        A = float(Nv * a0)\n\n        # 1. SSA Complexity\n        # Naive linear selection\n        C_SSA_lin = A * T * M\n        # Logarithmic selection\n        C_SSA_log = A * T * np.log2(M) if M > 0 else 0.0\n\n        # 2. Tau-leaping Step Size Calculation\n        per_channel_propensity = a0 / R if R > 0 else float('inf')\n\n        # Small-change condition\n        # The Lipschitz-type bound L is combined directly into the tau_small calculation\n        # L = (nu_max / X_min) * per_channel_propensity\n        # tau_small = eps / L\n        if nu_max * a0 == 0:\n             tau_small = float('inf')\n        else:\n            tau_small = (eps * X_min * R) / (nu_max * a0)\n        \n        # Many-firings condition\n        if a0 == 0:\n            tau_many = float('inf')\n        else:\n            tau_many = (k_min * R) / a0\n        \n        # Non-negativity safety condition\n        if nu_max * a0 == 0:\n            tau_safe = float('inf')\n        else:\n            tau_safe = (s * X_min * R) / (nu_max * a0)\n\n        # Operative leap size\n        tau_leap = min(tau_small, tau_many, tau_safe)\n\n        # 3. Tau-leaping Complexity\n        if tau_leap > 0:\n            C_tau = np.ceil(T / tau_leap) * M\n        else:\n            # If tau_leap is zero, the number of leaps is effectively infinite.\n            # This indicates SSA must be used. Complexity is represented as infinity.\n            C_tau = float('inf')\n\n        # 4. Accuracy Regime Criterion\n        accurate = tau_many <= min(tau_small, tau_safe)\n\n        # Store results for this case\n        results.append([\n            float(C_SSA_lin),\n            float(C_SSA_log),\n            float(C_tau),\n            accurate\n        ])\n\n    # Final print statement in the exact required format.\n    # The format is a string representation of a list of lists.\n    # str(results) produces this format, e.g., \"[[...], [...]]\"\n    # The problem asks for f\"[{','.join(map(str, results))}]\", which also yields the same output.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}