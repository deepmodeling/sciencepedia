{
    "hands_on_practices": [
        {
            "introduction": "The starting point for any accuracy assessment is the calculation of core metrics from an error matrix. This practice provides a direct, hands-on opportunity to compute overall, producer's, and user's accuracies from a basic $2 \\times 2$ matrix . Mastering these fundamental calculations is essential for interpreting the performance of any classification model, providing distinct insights for both the map maker (Producer’s Accuracy) and the map user (User’s Accuracy).",
            "id": "3793901",
            "problem": "A binary land-cover classification derived from satellite imagery has been assessed using a sample-based error matrix whose rows correspond to mapped classes and whose columns correspond to reference (ground truth) classes, consistent with the convention used in this article. Let $n_{ij}$ denote the count of samples whose mapped class is $i$ and reference class is $j$, with $i, j \\in \\{1,2\\}$. The observed counts are $n_{11}=50$, $n_{12}=8$, $n_{21}=10$, and $n_{22}=32$. Assume a simple random sample design so that cell proportions estimated by $n_{ij}$ normalized by the appropriate totals are unbiased for the corresponding probabilities.\n\nUsing only the foundational definitions below, compute the Producer’s Accuracy for class $1$ and class $2$ (Producer’s Accuracy (PA) is the proportion of reference samples of a class that are correctly labeled by the map), the User’s Accuracy for class $1$ and class $2$ (User’s Accuracy (UA) is the proportion of mapped samples of a class that truly belong to that class in reference), and the Overall Accuracy (OA) (Overall Accuracy is the proportion of all samples that are correctly classified). Express each accuracy as a decimal in the interval $[0,1]$, rounded to $4$ significant figures.\n\nReport your final answer as the ordered tuple $\\big(PA_{1},\\,PA_{2},\\,UA_{1},\\,UA_{2},\\,OA\\big)$.",
            "solution": "The problem statement has been validated and is deemed valid. It is a scientifically grounded, well-posed, and objective problem in remote sensing accuracy assessment. All necessary data and definitions are provided, and there are no internal contradictions or ambiguities.\n\nThe problem requires the calculation of several accuracy metrics from a sample-based error matrix for a binary classification. The convention, consistent with this article, is that rows of the error matrix represent mapped classes and columns represent reference classes. The given counts, $n_{ij}$, represent the number of samples with mapped class $i$ and reference class $j$. The provided data are:\n- $n_{11} = 50$ (mapped as class 1, is reference class 1)\n- $n_{12} = 8$ (mapped as class 1, is reference class 2; error of commission for class 1)\n- $n_{21} = 10$ (mapped as class 2, is reference class 1; error of omission for class 1)\n- $n_{22} = 32$ (mapped as class 2, is reference class 2)\n\nThe error matrix $N$ is structured with mapped classes as rows and reference classes as columns:\n$$\nN = \\begin{pmatrix} n_{11}  n_{12} \\\\ n_{21}  n_{22} \\end{pmatrix} = \\begin{pmatrix} 50  8 \\\\ 10  32 \\end{pmatrix}\n$$\n\nTo calculate the required accuracy metrics, we first compute the marginal totals.\nThe row totals, representing the total number of samples mapped to each class, are denoted by $n_{i+}$.\n$$\nn_{1+} = n_{11} + n_{12} = 50 + 8 = 58\n$$\n$$\nn_{2+} = n_{21} + n_{22} = 10 + 32 = 42\n$$\n\nThe column totals, representing the total number of reference samples for each class, are denoted by $n_{+j}$.\n$$\nn_{+1} = n_{11} + n_{21} = 50 + 10 = 60\n$$\n$$\nn_{+2} = n_{12} + n_{22} = 8 + 32 = 40\n$$\n\nThe grand total number of samples, $n$, is the sum of all elements in the matrix:\n$$\nn = n_{11} + n_{12} + n_{21} + n_{22} = 50 + 8 + 10 + 32 = 100\n$$\n\nNow we apply the standard definitions.\n\n**User’s Accuracy (UA)**\nUser’s Accuracy for a mapped class $i$ ($UA_{i}$) is the proportion of samples mapped as class $i$ that are truly class $i$. This is the number of correctly classified samples in a class divided by the total number of samples mapped to that class (the row total).\nThe formula is $UA_{i} = \\frac{n_{ii}}{n_{i+}}$.\n\nFor class $1$:\n$$\nUA_{1} = \\frac{n_{11}}{n_{1+}} = \\frac{50}{58} = \\frac{25}{29} \\approx 0.862068...\n$$\nRounded to $4$ significant figures, $UA_{1} = 0.8621$.\n\nFor class $2$:\n$$\nUA_{2} = \\frac{n_{22}}{n_{2+}} = \\frac{32}{42} = \\frac{16}{21} \\approx 0.761904...\n$$\nRounded to $4$ significant figures, $UA_{2} = 0.7619$.\n\n**Producer’s Accuracy (PA)**\nProducer’s Accuracy for a reference class $j$ ($PA_{j}$) is the proportion of reference samples of that class that are correctly labeled by the map. This is the number of correctly classified samples in a class divided by the total number of reference samples for that class (the column total).\nThe formula is $PA_{j} = \\frac{n_{jj}}{n_{+j}}$.\n\nFor class $1$:\n$$\nPA_{1} = \\frac{n_{11}}{n_{+1}} = \\frac{50}{60} = \\frac{5}{6} \\approx 0.83333...\n$$\nRounded to $4$ significant figures, $PA_{1} = 0.8333$.\n\nFor class $2$:\n$$\nPA_{2} = \\frac{n_{22}}{n_{+2}} = \\frac{32}{40} = \\frac{4}{5} = 0.8\n$$\nExpressed with $4$ significant figures, $PA_{2} = 0.8000$.\n\n**Overall Accuracy (OA)**\nOverall Accuracy is the proportion of all samples that are correctly classified. This is the sum of the diagonal elements (correctly classified samples) divided by the grand total number of samples.\nThe formula is $OA = \\frac{\\sum_{k=1}^{2} n_{kk}}{n}$.\n$$\nOA = \\frac{n_{11} + n_{22}}{n} = \\frac{50 + 32}{100} = \\frac{82}{100} = 0.82\n$$\nExpressed with $4$ significant figures, $OA = 0.8200$.\n\nThe final results are compiled into the required ordered tuple $\\big(PA_{1},\\,PA_{2},\\,UA_{1},\\,UA_{2},\\,OA\\big)$.\n- $PA_{1} = 0.8333$\n- $PA_{2} = 0.8000$\n- $UA_{1} = 0.8621$\n- $UA_{2} = 0.7619$\n- $OA = 0.8200$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.8333  0.8000  0.8621  0.7619  0.8200\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Moving beyond idealized scenarios, real-world accuracy assessments often employ more complex sampling designs like stratified sampling to ensure adequate representation of rare classes. This exercise challenges you to adjust your calculations for a dataset collected via stratified random sampling, highlighting how the sampling protocol directly impacts the estimation of Producer’s Accuracy . By also comparing errors of commission ($1-UA$) and omission ($1-PA$), you will develop a more nuanced understanding of a classifier's specific failure modes.",
            "id": "3793883",
            "problem": "A remote sensing land-cover map with $3$ mapped classes is validated using a stratified random sample allocated by mapped class. Let the mapped classes be indexed by $i \\in \\{1,2,3\\}$ and the reference (field-verified) classes be indexed by $j \\in \\{1,2,3\\}$. The sampling strata are the mapped classes, with known mapped area proportions $W_{1}=0.60$, $W_{2}=0.30$, and $W_{3}=0.10$, which sum to $1$. Within each mapped class $i$, a simple random sample of $n_{i+}$ pixels is taken and labeled against reference data to produce the $3 \\times 3$ sample error matrix $N=[n_{ij}]$ with rows indexed by mapped class and columns indexed by reference class:\n$$\nN \\;=\\;\n\\begin{pmatrix}\n40  8  2 \\\\\n9  18  3 \\\\\n4  4  12\n\\end{pmatrix},\n\\quad\n(n_{1+},n_{2+},n_{3+})=(50,30,20).\n$$\nUsing only foundational definitions of conditional probability and design-based unbiased estimation under stratified sampling by mapped class, do the following:\n- Compute the per-class user’s accuracy (UA), $UA_{i}$, interpreted as $P(\\text{Reference}=i \\mid \\text{Mapped}=i)$, for $i \\in \\{1,2,3\\}$.\n- Compute the per-class producer’s accuracy (PA), $PA_{i}$, interpreted as $P(\\text{Mapped}=i \\mid \\text{Reference}=i)$, for $i \\in \\{1,2,3\\}$, taking into account the unequal mapped area proportions $W_{i}$ implied by the stratified design.\n- For each class $i$, define the commission error as $C_{i}=1-UA_{i}$ and the omission error as $O_{i}=1-PA_{i}$. Let $\\Delta_{i}=C_{i}-O_{i}=PA_{i}-UA_{i}$. A class is said to have misclassification dominated by commission errors if $\\Delta_{i}0$ and by omission errors if $\\Delta_{i}0$.\n\nReport a single scalar: the index $k \\in \\{1,2,3\\}$ of the class with the largest positive value of $\\Delta_{i}$; if no $\\Delta_{i}$ is positive, report $0$. The final answer must be this single index.",
            "solution": "The problem is determined to be valid as it represents a standard, well-posed problem in remote sensing accuracy assessment with a complete and consistent set of givens. We proceed with the solution.\n\nThe analysis hinges on design-based statistical estimation, where the sampling design dictates the form of the estimators. The sampling is stratified by mapped class, with known stratum area proportions $W_i$.\n\nFirst, we compute the estimator for the per-class user’s accuracy, $\\widehat{UA}_i$. User's accuracy for class $i$, denoted $UA_i$, is the conditional probability $P(\\text{Reference}=i \\mid \\text{Mapped}=i)$. Because the sampling is performed independently within each mapped class stratum (the rows of the error matrix), the estimator $\\widehat{UA}_i$ is the proportion of correctly classified pixels within the sample from stratum $i$:\n$$ \\widehat{UA}_i = \\frac{n_{ii}}{n_{i+}} $$\nThe given sample error matrix is $N=[n_{ij}] = \\begin{pmatrix} 40  8  2 \\\\ 9  18  3 \\\\ 4  4  12 \\end{pmatrix}$ with row totals $(n_{1+},n_{2+},n_{3+})=(50,30,20)$.\nFor each class $i \\in \\{1, 2, 3\\}$, we have:\n$$ \\widehat{UA}_1 = \\frac{n_{11}}{n_{1+}} = \\frac{40}{50} = 0.80 $$\n$$ \\widehat{UA}_2 = \\frac{n_{22}}{n_{2+}} = \\frac{18}{30} = 0.60 $$\n$$ \\widehat{UA}_3 = \\frac{n_{33}}{n_{3+}} = \\frac{12}{20} = 0.60 $$\n\nNext, we compute the estimator for the per-class producer’s accuracy, $\\widehat{PA}_i$. Producer's accuracy for class $i$, denoted $PA_i$, is the conditional probability $P(\\text{Mapped}=i \\mid \\text{Reference}=i)$. To estimate this from a sample stratified by mapped class, we must first estimate the true area proportions for each cell $(i,j)$ of the population error matrix. The unbiased estimator for the proportion of the total area belonging to mapped class $i$ and reference class $j$, denoted $\\widehat{A}_{ij}$, is given by weighting the sample proportion from stratum $i$ by that stratum's area proportion $W_i$:\n$$ \\widehat{A}_{ij} = W_i \\frac{n_{ij}}{n_{i+}} $$\nThe estimator for the total proportion of area belonging to reference class $j$, denoted $\\widehat{A}_{+j}$, is the sum of these estimates over all mapped classes (rows):\n$$ \\widehat{A}_{+j} = \\sum_{k=1}^3 \\widehat{A}_{kj} = \\sum_{k=1}^3 W_k \\frac{n_{kj}}{n_{k+}} $$\nThe estimator for producer's accuracy for class $i$ is then the ratio of the estimated area correctly classified as class $i$ to the estimated total area of reference class $i$:\n$$ \\widehat{PA}_i = \\frac{\\widehat{A}_{ii}}{\\widehat{A}_{+i}} = \\frac{W_i \\frac{n_{ii}}{n_{i+}}}{\\sum_{k=1}^3 W_k \\frac{n_{ki}}{n_{k+}}} $$\nThe stratum area proportions are given as $W_1 = 0.60$, $W_2 = 0.30$, and $W_3 = 0.10$.\nWe compute the estimated reference class proportions, $\\widehat{A}_{+i}$:\n$$ \\widehat{A}_{+1} = W_1 \\frac{n_{11}}{n_{1+}} + W_2 \\frac{n_{21}}{n_{2+}} + W_3 \\frac{n_{31}}{n_{3+}} = (0.60)\\frac{40}{50} + (0.30)\\frac{9}{30} + (0.10)\\frac{4}{20} = 0.48 + 0.09 + 0.02 = 0.59 $$\n$$ \\widehat{A}_{+2} = W_1 \\frac{n_{12}}{n_{1+}} + W_2 \\frac{n_{22}}{n_{2+}} + W_3 \\frac{n_{32}}{n_{3+}} = (0.60)\\frac{8}{50} + (0.30)\\frac{18}{30} + (0.10)\\frac{4}{20} = 0.096 + 0.18 + 0.02 = 0.296 $$\n$$ \\widehat{A}_{+3} = W_1 \\frac{n_{13}}{n_{1+}} + W_2 \\frac{n_{23}}{n_{2+}} + W_3 \\frac{n_{33}}{n_{3+}} = (0.60)\\frac{2}{50} + (0.30)\\frac{3}{30} + (0.10)\\frac{12}{20} = 0.024 + 0.03 + 0.06 = 0.114 $$\nNow we compute the producer's accuracy estimates:\n$$ \\widehat{PA}_1 = \\frac{W_1 (n_{11}/n_{1+})}{\\widehat{A}_{+1}} = \\frac{0.60 (40/50)}{0.59} = \\frac{0.48}{0.59} = \\frac{48}{59} $$\n$$ \\widehat{PA}_2 = \\frac{W_2 (n_{22}/n_{2+})}{\\widehat{A}_{+2}} = \\frac{0.30 (18/30)}{0.296} = \\frac{0.18}{0.296} = \\frac{180}{296} = \\frac{45}{74} $$\n$$ \\widehat{PA}_3 = \\frac{W_3 (n_{33}/n_{3+})}{\\widehat{A}_{+3}} = \\frac{0.10 (12/20)}{0.114} = \\frac{0.06}{0.114} = \\frac{60}{114} = \\frac{10}{19} $$\nFinally, we compute the quantity $\\Delta_i = \\widehat{PA}_i - \\widehat{UA}_i$ for each class.\nFor class $1$:\n$$ \\Delta_1 = \\widehat{PA}_1 - \\widehat{UA}_1 = \\frac{48}{59} - 0.80 = \\frac{48}{59} - \\frac{4}{5} = \\frac{48 \\times 5 - 4 \\times 59}{295} = \\frac{240 - 236}{295} = \\frac{4}{295} $$\nSince $\\Delta_1 > 0$, this class's misclassification is dominated by commission errors.\nFor class $2$:\n$$ \\Delta_2 = \\widehat{PA}_2 - \\widehat{UA}_2 = \\frac{45}{74} - 0.60 = \\frac{45}{74} - \\frac{3}{5} = \\frac{45 \\times 5 - 3 \\times 74}{370} = \\frac{225 - 222}{370} = \\frac{3}{370} $$\nSince $\\Delta_2 > 0$, this class's misclassification is also dominated by commission errors.\nFor class $3$:\n$$ \\Delta_3 = \\widehat{PA}_3 - \\widehat{UA}_3 = \\frac{10}{19} - 0.60 = \\frac{10}{19} - \\frac{3}{5} = \\frac{10 \\times 5 - 3 \\times 19}{95} = \\frac{50 - 57}{95} = -\\frac{7}{95} $$\nSince $\\Delta_3  0$, this class's misclassification is dominated by omission errors.\n\nThe problem requires identifying the class index $k$ corresponding to the largest positive value of $\\Delta_i$. We must compare the positive values $\\Delta_1 = \\frac{4}{295}$ and $\\Delta_2 = \\frac{3}{370}$. We can compare the two fractions by cross-multiplication:\n$$ 4 \\times 370 = 1480 $$\n$$ 3 \\times 295 = 885 $$\nSince $1480 > 885$, it follows that $\\frac{4}{295} > \\frac{3}{370}$, and thus $\\Delta_1 > \\Delta_2$.\nThe largest positive value is $\\Delta_1$. The index of this class is $k=1$.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Often, the goal is not just to assess one map, but to determine if a new classification model offers a statistically significant improvement over an existing one. This practice introduces McNemar's test, a powerful statistical tool for comparing the error rates of two paired classifiers evaluated on the same reference data . By focusing on the discordant pairs—cases where one classifier is correct and the other is incorrect—you will learn how to formally test the null hypothesis that both classifiers have the same error rate.",
            "id": "3793840",
            "problem": "A regional floodplain mapping study uses medium-resolution satellite imagery to produce binary maps of inundated versus non-inundated land. Two supervised classifiers, denoted as $A$ and $B$, are trained on identical features and assessed on the same set of $600$ independently collected reference pixels. For each pixel, correctness is recorded for each classifier relative to the field-verified class. The aggregated paired outcomes form a $2 \\times 2$ cross-tabulation of correctness as follows: both $A$ and $B$ correct: $410$ pixels; $A$ correct and $B$ incorrect: $52$ pixels; $A$ incorrect and $B$ correct: $31$ pixels; both incorrect: $107$ pixels.\n\nStarting from the definition of McNemar’s matched-pairs test for paired binary outcomes, consider the null hypothesis that the two classifiers have equal error rates on the population of pixels, so that the probability of a discordant outcome favoring $A$ equals that favoring $B$. Using the fundamental binomial model for the discordant counts under the null and a large-sample normal approximation with a continuity correction, derive the continuity-corrected chi-square test statistic for McNemar’s test in terms of the off-diagonal discordant counts. Then compute its value for the dataset above, where $b$ denotes the number of pixels for which $A$ is correct and $B$ is incorrect, and $c$ denotes the number of pixels for which $A$ is incorrect and $B$ is correct.\n\nExpress your final numeric value for the test statistic rounded to four significant figures. No units are required.",
            "solution": "The problem requires the derivation of the continuity-corrected McNemar's chi-square test statistic and its computation for a given dataset.\n\nFirst, we formalize the problem setup. The comparison between the two classifiers, $A$ and $B$, can be summarized in a $2 \\times 2$ contingency table based on the correctness of their classifications for $N$ paired samples.\n\n| | Classifier B Correct | Classifier B Incorrect |\n| :--- | :---: | :---: |\n| **Classifier A Correct** | $n_{11}$ | $b$ |\n| **Classifier A Incorrect** | $c$ | $n_{00}$ |\n\nFrom the problem statement, we have the following counts:\n- $n_{11}$ (both correct): $410$\n- $b$ (A correct, B incorrect): $52$\n- $c$ (A incorrect, B correct): $31$\n- $n_{00}$ (both incorrect): $107$\n\nThe total number of pixels is $N = n_{11} + b + c + n_{00} = 410 + 52 + 31 + 107 = 600$.\n\nThe null hypothesis, $H_0$, is that the two classifiers have equal error rates. Let $p_{ij}$ be the probability that a randomly selected pixel falls into the cell $(i, j)$ of the table, where $i=1$ if $A$ is correct and $i=0$ if $A$ is incorrect, and similarly for $j$ with respect to $B$. The error rate for classifier $A$ is $P(\\text{A is incorrect}) = p_{01} + p_{00}$. The error rate for classifier $B$ is $P(\\text{B is incorrect}) = p_{10} + p_{00}$.\nThe null hypothesis $H_0: P(\\text{A is incorrect}) = P(\\text{B is incorrect})$ is thus equivalent to $p_{01} + p_{00} = p_{10} + p_{00}$, which simplifies to $p_{10} = p_{01}$.\nThis means that under the null hypothesis, the probability of a discordant outcome where $A$ is correct and $B$ is incorrect is equal to the probability of a discordant outcome where $A$ is incorrect and $B$ is correct.\n\nMcNemar's test focuses only on the discordant pairs, i.e., the cells where the classifiers disagree. The counts for these cells are $b$ and $c$. The total number of discordant pairs is $m = b+c$.\nLet's consider these $m$ discordant pairs as a sequence of Bernoulli trials. For each discordant pair, we can define a \"success\" as the outcome \"A correct, B incorrect\" (count $b$). Under $H_0$, the conditional probability of this outcome, given that a discordance has occurred, is:\n$$ p = P(\\text{A correct, B incorrect} | \\text{disagreement}) = \\frac{p_{10}}{p_{10} + p_{01}} $$\nSince $H_0$ states $p_{10} = p_{01}$, this probability becomes $p = \\frac{p_{10}}{p_{10} + p_{10}} = \\frac{1}{2}$.\nTherefore, under the null hypothesis, the number of observations $b$ follows a binomial distribution with parameters $m = b+c$ and $p = 1/2$, i.e., $b \\sim B(m, 1/2)$.\n\nFor a large number of discordant pairs (typically $m > 20$), this binomial distribution can be approximated by a normal distribution. The mean and variance of this binomial distribution are:\n$$ E[b] = mp = \\frac{m}{2} = \\frac{b+c}{2} $$\n$$ \\text{Var}(b) = mp(1-p) = m\\left(\\frac{1}{2}\\right)\\left(1-\\frac{1}{2}\\right) = \\frac{m}{4} = \\frac{b+c}{4} $$\nA standard normal variable $Z$ can be constructed by standardizing the count $b$:\n$$ Z = \\frac{b - E[b]}{\\sqrt{\\text{Var}(b)}} = \\frac{b - (b+c)/2}{\\sqrt{(b+c)/4}} = \\frac{(b-c)/2}{\\sqrt{b+c}/2} = \\frac{b-c}{\\sqrt{b+c}} $$\nThe square of a standard normal variable follows a chi-square distribution with one degree of freedom, $\\chi^2_1$. Squaring $Z$ gives the uncorrected McNemar test statistic:\n$$ \\chi^2 = Z^2 = \\frac{(b-c)^2}{b+c} $$\nThe problem asks for the continuity-corrected statistic. When approximating a discrete distribution (binomial) with a continuous one (normal), a continuity correction is applied to improve the approximation. This involves subtracting $0.5$ from the absolute difference between the observed value and its mean before standardizing.\nThe continuity-corrected Z-score, $Z_{cc}$, is:\n$$ Z_{cc} = \\frac{|b - E[b]| - 0.5}{\\sqrt{\\text{Var}(b)}} $$\nSubstituting the expressions for the mean and variance:\n$$ Z_{cc} = \\frac{|b - (b+c)/2| - 0.5}{\\sqrt{(b+c)/4}} $$\nThe term in the absolute value is $|b - (b+c)/2| = |(2b-b-c)/2| = |(b-c)/2| = |b-c|/2$.\n$$ Z_{cc} = \\frac{|b-c|/2 - 0.5}{\\sqrt{b+c}/2} = \\frac{(|b-c|-1)/2}{\\sqrt{b+c}/2} = \\frac{|b-c|-1}{\\sqrt{b+c}} $$\nThe continuity-corrected chi-square statistic, $\\chi^2_{cc}$, is the square of $Z_{cc}$:\n$$ \\chi^2_{cc} = (Z_{cc})^2 = \\left( \\frac{|b-c|-1}{\\sqrt{b+c}} \\right)^2 = \\frac{(|b-c|-1)^2}{b+c} $$\nThis is the derived expression for the continuity-corrected McNemar's test statistic.\n\nNow, we compute the value of this statistic for the given data. The discordant counts are $b = 52$ and $c = 31$.\nWe substitute these values into the derived formula:\n$$ \\chi^2_{cc} = \\frac{(|52 - 31| - 1)^2}{52 + 31} $$\nFirst, calculate the terms in the numerator and denominator:\n$$ |52 - 31| = |21| = 21 $$\n$$ 52 + 31 = 83 $$\nNow, substitute these back into the expression:\n$$ \\chi^2_{cc} = \\frac{(21 - 1)^2}{83} = \\frac{20^2}{83} = \\frac{400}{83} $$\nPerforming the division gives:\n$$ \\chi^2_{cc} \\approx 4.8192771084... $$\nThe problem requires the final answer to be rounded to four significant figures.\n$$ \\chi^2_{cc} \\approx 4.819 $$\nThis is the computed value of the test statistic.",
            "answer": "$$\\boxed{4.819}$$"
        }
    ]
}