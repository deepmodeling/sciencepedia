{
    "hands_on_practices": [
        {
            "introduction": "In many environmental applications, spatial data is not purely random but exhibits large-scale trends, or 'drift'. A fundamental task in geostatistics is to identify and remove this deterministic component to properly analyze the underlying stationary random process. This comprehensive exercise guides you through a complete, hands-on workflow that mimics a real-world remote sensing analysis: you will generate synthetic data with a known trend, apply polynomial detrending, and then critically evaluate whether the resulting residual field satisfies the assumptions of intrinsic stationarity using a series of quantitative checks on the empirical variogram. ",
            "id": "3850245",
            "problem": "You are given a synthetic remote sensing scenario in which Land Surface Temperature (LST) at midday, expressed in degrees Celsius, is measured over a two-dimensional region. The measured field is modeled as the sum of a deterministic drift and a zero-mean stationary random component. Your task is to construct a complete workflow that identifies and removes deterministic drift in the data and then validates the intrinsic stationarity of the residuals via empirical variogram properties.\n\nFundamental basis and definitions to be used for derivation:\n- Let $Z(\\mathbf{s})$ denote the observed field at spatial location $\\mathbf{s} \\in \\mathbb{R}^2$. Assume $Z(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})$, where $m(\\mathbf{s})$ is a deterministic drift and $Y(\\mathbf{s})$ is a zero-mean stationary Gaussian random field with covariance that depends only on the separation vector $\\mathbf{h} = \\mathbf{s}_i - \\mathbf{s}_j$ through its Euclidean norm $h = \\|\\mathbf{h}\\|$.\n- Stationarity is characterized by $Y(\\mathbf{s})$ having constant mean $0$ and covariance $C(h)$ that depends only on $h$. Intrinsic stationarity assumes that the mean of increments is $0$ and that the variance of increments depends only on $h$, which leads to a well-defined variogram.\n- The empirical variogram is defined via the Matheron estimator. For bin width partitions of distances, the empirical semivariance at lag bin $k$ is\n$$\n\\hat{\\gamma}(h_k) = \\frac{1}{2 N(h_k)} \\sum_{(i,j) \\in B_k} \\left(Z(\\mathbf{s}_i) - Z(\\mathbf{s}_j)\\right)^2,\n$$\nwhere $B_k$ indexes all pairs whose separation falls into bin $k$, and $N(h_k)$ is the number of such pairs.\n- Use an isotropic exponential covariance for $Y(\\mathbf{s})$:\n$$\nC(h) = \\sigma^2 \\exp\\left( -\\frac{h}{\\phi} \\right),\n$$\nand incorporate independent measurement noise (nugget effect) with variance $\\tau^2$ on the diagonal.\n\nWorkflow requirements:\n1. Deterministic drift removal:\n   - Fit a polynomial trend of order $p \\in \\{0,1,2\\}$ to $Z(\\mathbf{s})$ using ordinary least squares. For $p=0$, use only the intercept; for $p=1$, include intercept, $x$, and $y$; for $p=2$, include intercept, $x$, $y$, $x^2$, $y^2$, and $xy$. Here $\\mathbf{s}=(x,y)$ in kilometers.\n   - Subtract the fitted trend $\\hat{m}(\\mathbf{s})$ from $Z(\\mathbf{s})$ to obtain residuals $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$.\n\n2. Empirical variogram computation:\n   - Compute an isotropic empirical variogram of $R(\\mathbf{s})$ using $K$ equal-width distance bins from $0$ to the maximum pairwise distance. Use $K=12$ bins. Distances are in kilometers; semivariances are in squared degrees Celsius.\n   - For numerical stability, if any bin has $N(h_k) = 0$, treat its semivariance as undefined and exclude it from checks described below.\n\n3. Intrinsic stationarity validation of residuals:\n   - Mean stability: Require the absolute mean of $R(\\mathbf{s})$ to be small relative to its standard deviation:\n     $$\n     \\left| \\overline{R} \\right| \\leq \\alpha \\cdot s_R,\n     $$\n     with $\\alpha = 0.1$, where $s_R$ is the standard deviation of $R(\\mathbf{s})$.\n   - Variogram monotonicity: Compute the fraction $M$ of adjacent valid variogram bins $\\hat{\\gamma}(h_{k+1})$ and $\\hat{\\gamma}(h_k)$ satisfying\n     $$\n     \\hat{\\gamma}(h_{k+1}) \\geq \\hat{\\gamma}(h_k) - \\epsilon,\n     $$\n     where $\\epsilon$ is a tolerance proportional to the estimated sill (take $\\epsilon = 0.05 \\cdot \\max_k \\hat{\\gamma}(h_k)$). Require $M \\geq 0.8$.\n   - Short-lag slope non-negativity: Fit a linear model to the first $L$ valid variogram points (smallest lags), where $L = 4$ or fewer if fewer bins are valid, and require the estimated slope $\\beta$ to satisfy\n     $$\n     \\beta \\geq 0.\n     $$\n   - Spatial mean consistency: Partition the domain into four quadrants by median splits in $x$ and $y$. Let $\\overline{R}_q$ be the mean residual in quadrant $q$. Require\n     $$\n     \\max_{q,q'} \\left| \\overline{R}_q - \\overline{R}_{q'} \\right| \\leq \\gamma \\cdot s_R,\n     $$\n     with $\\gamma = 0.2$.\n\nIf all four conditions are satisfied, declare the residual field intrinsically stationary; otherwise, declare it non-stationary.\n\nPhysical units and numeric precision:\n- Coordinates $x$ and $y$ are in kilometers.\n- Temperature values are in degrees Celsius.\n- Distances in the variogram are in kilometers; semivariances are in squared degrees Celsius.\n- The final outputs are booleans per test case; no unit conversion is required for output.\n\nTest suite and parameter specification:\nYou must implement the workflow for the following $4$ test cases. In each case, generate synthetic data on a specified set of locations, construct drift, generate the stationary Gaussian component, add nugget noise, detrend using the specified polynomial order, compute the empirical variogram, and validate intrinsic stationarity.\n\nFor each test case, the parameters are:\n- Grid specification: number of points in $x$ and $y$, spacing $s$ in kilometers, or a specific sampling configuration.\n- Ground-truth drift order $p_{\\text{true}} \\in \\{0,1,2\\}$ and coefficients (in degrees Celsius per appropriate power of kilometers).\n- Fitted polynomial order $p_{\\text{fit}} \\in \\{0,1,2\\}$ used in detrending.\n- Covariance parameters $\\sigma^2$, $\\phi$ (in kilometers), and nugget variance $\\tau^2$ (in squared degrees Celsius).\n- Random seed for reproducibility.\n\nDefine the four test cases as follows:\n- Case $1$ (happy path, linear drift correctly removed):\n  - Grid: $16 \\times 16$ regular grid, spacing $s = 5$ kilometers.\n  - Ground-truth drift: $p_{\\text{true}} = 1$ with coefficients $c = 20$, $a_x = 0.02$ degrees Celsius per kilometer, $a_y = -0.01$ degrees Celsius per kilometer.\n  - Fit: $p_{\\text{fit}} = 1$.\n  - Covariance: $\\sigma^2 = 2.0$, $\\phi = 20$ kilometers, $\\tau^2 = 0.25$.\n  - Seed: $42$.\n- Case $2$ (quadratic drift correctly removed):\n  - Grid: $15 \\times 15$ regular grid, spacing $s = 5$ kilometers.\n  - Ground-truth drift: $p_{\\text{true}} = 2$ with coefficients $c = 18$, $a_x = 0.01$, $a_y = 0.005$ degrees Celsius per kilometer, $b_{xx} = 0.0002$, $b_{yy} = -0.0001$, $b_{xy} = 0.00015$ degrees Celsius per square kilometer.\n  - Fit: $p_{\\text{fit}} = 2$.\n  - Covariance: $\\sigma^2 = 2.5$, $\\phi = 15$ kilometers, $\\tau^2 = 0.3$.\n  - Seed: $123$.\n- Case $3$ (no drift, unnecessary linear detrend):\n  - Grid: $16 \\times 16$ regular grid, spacing $s = 5$ kilometers.\n  - Ground-truth drift: $p_{\\text{true}} = 0$ with coefficient $c = 22$ degrees Celsius.\n  - Fit: $p_{\\text{fit}} = 1$.\n  - Covariance: $\\sigma^2 = 1.5$, $\\phi = 25$ kilometers, $\\tau^2 = 0.2$.\n  - Seed: $7$.\n- Case $4$ (edge case, mis-specified drift order causing failure):\n  - Grid: $14 \\times 14$ regular grid, spacing $s = 5$ kilometers.\n  - Ground-truth drift: $p_{\\text{true}} = 2$ with coefficients $c = 19$, $a_x = 0.015$, $a_y = -0.008$ degrees Celsius per kilometer, $b_{xx} = 0.0010$, $b_{yy} = -0.0008$, $b_{xy} = 0.0006$ degrees Celsius per square kilometer.\n  - Fit: $p_{\\text{fit}} = 1$.\n  - Covariance: $\\sigma^2 = 0.3$, $\\phi = 15$ kilometers, $\\tau^2 = 0.1$.\n  - Seed: $999$.\n\nNumerical implementation details:\n- Use ordinary least squares for drift fitting.\n- Use $K = 12$ isotropic distance bins for the empirical variogram.\n- For the short-lag slope calculation, use the first $L = 4$ valid bins. If fewer than $4$ bins are valid, use all available valid bins. Use a minimum per-bin pair count threshold of $30$ for inclusion in slope fitting; bins with fewer than $30$ pairs should be excluded from the slope fit.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[result1,result2,result3,result4]\"), where each result is a boolean indicating whether intrinsic stationarity is validated for the corresponding test case under the four criteria defined above. The booleans must appear in the order of the test cases $1$ through $4$.",
            "solution": "The problem requires the development and implementation of a geostatistical workflow to assess the intrinsic stationarity of a residual spatial field. This field is obtained after removing a deterministic polynomial trend from a synthetic dataset analogous to remotely sensed Land Surface Temperature (LST). The validation is based on a set of quantitative checks performed on the residuals and their empirical variogram. The entire procedure will be executed for four distinct test cases, each with specified parameters for data generation and trend removal.\n\nThe foundational model for the observed spatial field $Z(\\mathbf{s})$ at location $\\mathbf{s} \\in \\mathbb{R}^2$ is given by the decomposition:\n$$\nZ(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})\n$$\nHere, $m(\\mathbf{s})$ represents a deterministic, large-scale variation, or drift, and $Y(\\mathbf{s})$ is a zero-mean, second-order stationary stochastic process, which models the spatially correlated random fluctuations. The stationarity of $Y(\\mathbf{s})$ is characterized by an isotropic exponential covariance function:\n$$\nC(h) = \\sigma^2 \\exp\\left( -\\frac{h}{\\phi} \\right)\n$$\nwhere $h = \\|\\mathbf{s}_i - \\mathbf{s}_j\\|$ is the Euclidean distance between two locations, $\\sigma^2$ is the partial sill (variance of the correlated component), and $\\phi$ is the effective range parameter. Additionally, independent measurement noise, known as the nugget effect, contributes a variance of $\\tau^2$ at zero separation. Thus, the total covariance for a set of points $\\{\\mathbf{s}_i\\}_{i=1}^N$ is described by a matrix $K$ with elements $K_{ij} = C(\\|\\mathbf{s}_i - \\mathbf{s}_j\\|)$ for $i \\neq j$ and diagonal elements $K_{ii} = \\sigma^2 + \\tau^2$.\n\nThe workflow proceeds through the following four stages:\n\n**1. Synthetic Data Generation**\nFor each test case, a synthetic dataset is generated. First, a set of spatial coordinates is established based on the specified grid configuration. The deterministic drift component $m(\\mathbf{s})$ is then calculated at each location using the true polynomial order $p_{\\text{true}}$ and its coefficients. A realization of the stationary random field $Y(\\mathbf{s})$ is generated by drawing a sample from a multivariate normal distribution, $\\mathcal{N}(\\mathbf{0}, K)$, where $K$ is the covariance matrix constructed from the given parameters $\\sigma^2$, $\\phi$, and $\\tau^2$. The final observed field is the sum $Z(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})$.\n\n**2. Deterministic Drift Removal**\nA polynomial trend surface $\\hat{m}(\\mathbf{s})$ of a specified order $p_{\\text{fit}} \\in \\{0, 1, 2\\}$ is fitted to the observed data $Z(\\mathbf{s})$ using Ordinary Least Squares (OLS). The design matrix $X$ for the OLS regression is constructed based on the coordinates $\\mathbf{s}=(x,y)$ and the chosen polynomial order. For instance, for $p_{\\text{fit}}=2$, the columns of $X$ correspond to the basis functions $\\{1, x, y, x^2, y^2, xy\\}$. The OLS estimator for the polynomial coefficients, $\\hat{\\beta}$, is found by solving the normal equations, typically via $\\hat{\\beta} = (X^T X)^{-1}X^T Z$. The fitted trend is $\\hat{m}(\\mathbf{s}) = X\\hat{\\beta}$, and the residuals are computed as $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$. These residuals represent the detrended field whose stationarity is to be tested.\n\n**3. Empirical Variogram Computation**\nThe spatial structure of the residuals $R(\\mathbf{s})$ is analyzed by computing the isotropic empirical semivariogram using the Matheron estimator. The range of pairwise distances between all data points is partitioned into $K=12$ equal-width bins. For each bin $k$, the semivariance $\\hat{\\gamma}(h_k)$ is calculated as:\n$$\n\\hat{\\gamma}(h_k) = \\frac{1}{2 N(h_k)} \\sum_{(i,j) \\in B_k} \\left(R(\\mathbf{s}_i) - R(\\mathbf{s}_j)\\right)^2\n$$\nwhere $B_k$ is the set of all point pairs whose separation distance falls into bin $k$, and $N(h_k)$ is the count of such pairs. Bins with $N(h_k) = 0$ are considered invalid.\n\n**4. Intrinsic Stationarity Validation**\nThe residual field $R(\\mathbf{s})$ is declared intrinsically stationary if it satisfies four distinct criteria:\n\n*   **Mean Stability:** The absolute mean of the residuals, $|\\overline{R}|$, must be small relative to their standard deviation, $s_R$. The formal check is $|\\overline{R}| \\leq \\alpha \\cdot s_R$, with the tolerance factor $\\alpha = 0.1$. This ensures that the detrending process has successfully produced a field with a mean that is approximately zero.\n\n*   **Variogram Monotonicity:** A theoretical variogram must be a monotonically non-decreasing function of lag distance $h$. We test this property on the empirical variogram. The fraction $M$ of adjacent valid bins $(\\hat{\\gamma}(h_k), \\hat{\\gamma}(h_{k+1}))$ that satisfy $\\hat{\\gamma}(h_{k+1}) \\geq \\hat{\\gamma}(h_k) - \\epsilon$ must be at least $0.8$. The tolerance $\\epsilon = 0.05 \\cdot \\max_k \\hat{\\gamma}(h_k)$ allows for minor stochastic fluctuations. A failure suggests a significant remaining trend.\n\n*   **Short-Lag Slope Non-Negativity:** The behavior of the variogram near the origin is critical. We fit a linear model to the first $L=4$ valid variogram points (or fewer, if available) that have a robust number of pairs ($N(h_k) \\ge 30$). The estimated slope $\\beta$ of this line must be non-negative ($\\beta \\geq 0$). A negative slope near the origin is inconsistent with standard models of spatial correlation.\n\n*   **Spatial Mean Consistency:** To detect large-scale residual trends, the domain is partitioned into four quadrants using median splits of the coordinates. The means of the residuals within each quadrant, $\\overline{R}_q$, are computed. The maximum absolute difference between any two quadrant means must be small compared to the overall residual standard deviation: $\\max_{q,q'} |\\overline{R}_q - \\overline{R}_{q'}| \\leq \\gamma \\cdot s_R$, with $\\gamma = 0.2$.\n\nA test case is deemed to have passed, indicating the residuals are acceptably stationary, only if all four of these conditions are met. The implementation will systematically apply this entire workflow to each of the four specified test cases.",
            "answer": "```python\nimport numpy as np\n\ndef run_case(grid_spec, p_true, drift_coeffs, p_fit, cov_params, seed):\n    \"\"\"\n    Executes the entire workflow for a single test case.\n    \"\"\"\n    # 1. Generate spatial coordinates\n    rng = np.random.default_rng(seed)\n    nx, ny, s = grid_spec\n    x = np.arange(nx) * s\n    y = np.arange(ny) * s\n    xx, yy = np.meshgrid(x, y)\n    coords = np.vstack([xx.ravel(), yy.ravel()]).T\n    n_points = nx * ny\n    x_coords, y_coords = coords[:, 0], coords[:, 1]\n\n    # 2. Generate true deterministic drift m(s)\n    if p_true == 0:\n        m_true = np.full(n_points, drift_coeffs['c'])\n    elif p_true == 1:\n        m_true = (drift_coeffs['c'] + \n                  drift_coeffs['ax'] * x_coords + \n                  drift_coeffs['ay'] * y_coords)\n    elif p_true == 2:\n        m_true = (drift_coeffs['c'] + \n                  drift_coeffs['ax'] * x_coords + \n                  drift_coeffs['ay'] * y_coords +\n                  drift_coeffs['bxx'] * x_coords**2 + \n                  drift_coeffs['byy'] * y_coords**2 + \n                  drift_coeffs['bxy'] * x_coords * y_coords)\n\n    # 3. Generate stationary random component Y(s)\n    sigma2 = cov_params['sigma2']\n    phi = cov_params['phi']\n    tau2 = cov_params['tau2']\n    \n    dist_matrix = np.sqrt(((coords[:, np.newaxis, :] - coords[np.newaxis, :, :])**2).sum(axis=-1))\n    \n    cov_matrix = sigma2 * np.exp(-dist_matrix / phi)\n    np.fill_diagonal(cov_matrix, sigma2 + tau2)\n    \n    Y = rng.multivariate_normal(np.zeros(n_points), cov_matrix, method='eigh')\n\n    # 4. Form observed field Z(s)\n    Z = m_true + Y\n\n    # 5. Detrending using Ordinary Least Squares (OLS)\n    if p_fit == 0:\n        X = np.ones((n_points, 1))\n    elif p_fit == 1:\n        X = np.vstack([np.ones(n_points), x_coords, y_coords]).T\n    elif p_fit == 2:\n        X = np.vstack([np.ones(n_points), x_coords, y_coords, \n                       x_coords**2, y_coords**2, x_coords * y_coords]).T\n    \n    beta_hat = np.linalg.lstsq(X, Z, rcond=None)[0]\n    m_hat = X @ beta_hat\n    R = Z - m_hat\n\n    # 6. Empirical variogram computation\n    indices_upper = np.triu_indices(n_points, k=1)\n    dist_upper = dist_matrix[indices_upper]\n    \n    sq_diff_matrix = (R[:, np.newaxis] - R[np.newaxis, :])**2\n    sq_diff_upper = sq_diff_matrix[indices_upper]\n\n    K = 12\n    max_dist = dist_upper.max()\n    \n    counts, bin_edges = np.histogram(dist_upper, bins=K, range=(0, max_dist))\n    sum_sq_diff, _ = np.histogram(dist_upper, bins=K, range=(0, max_dist), weights=sq_diff_upper)\n\n    gamma_vals = np.full(K, np.nan)\n    valid_mask = counts > 0\n    gamma_vals[valid_mask] = sum_sq_diff[valid_mask] / (2 * counts[valid_mask])\n    \n    h_bins = (bin_edges[:-1] + bin_edges[1:]) / 2\n\n    # 7. Intrinsic stationarity validation\n    R_std = np.std(R)\n\n    # Check 1: Mean stability\n    check1 = np.abs(np.mean(R)) <= 0.1 * R_std if R_std > 1e-9 else np.abs(np.mean(R)) < 1e-9\n\n    # Check 2: Variogram monotonicity\n    valid_gamma_indices = np.where(valid_mask)[0]\n    check2 = True\n    if len(valid_gamma_indices) > 1:\n        gamma_subset = gamma_vals[valid_gamma_indices]\n        if len(gamma_subset) > 0:\n            epsilon = 0.05 * np.max(gamma_subset)\n            monotonic_pairs = 0\n            total_pairs = len(gamma_subset) - 1\n            for i in range(total_pairs):\n                if gamma_subset[i+1] >= gamma_subset[i] - epsilon:\n                    monotonic_pairs += 1\n            \n            check2 = (monotonic_pairs / total_pairs) >= 0.8\n        else: # No valid gamma points\n            check2 = True\n    \n    # Check 3: Short-lag slope non-negativity\n    slope_valid_mask = counts >= 30\n    slope_indices = np.where(slope_valid_mask)[0]\n    check3 = True\n    if len(slope_indices) > 0:\n        first_L_indices = slope_indices[:4]\n        if len(first_L_indices) >= 2:\n            h_slope = h_bins[first_L_indices]\n            gamma_slope = gamma_vals[first_L_indices]\n            \n            X_slope = np.vstack([h_slope, np.ones(len(h_slope))]).T\n            slope, _ = np.linalg.lstsq(X_slope, gamma_slope, rcond=None)[0]\n            check3 = slope >= 0\n\n    # Check 4: Spatial mean consistency\n    median_x = np.median(x_coords)\n    median_y = np.median(y_coords)\n    \n    q1_mask = (x_coords <= median_x) & (y_coords <= median_y)\n    q2_mask = (x_coords > median_x) & (y_coords <= median_y)\n    q3_mask = (x_coords <= median_x) & (y_coords > median_y)\n    q4_mask = (x_coords > median_x) & (y_coords > median_y)\n    \n    q_means = []\n    masks = [q1_mask, q2_mask, q3_mask, q4_mask]\n    for mask in masks:\n        if np.any(mask):\n            q_means.append(np.mean(R[mask]))\n    \n    check4 = True\n    if len(q_means) > 1 and R_std > 1e-9:\n        max_diff = np.max(q_means) - np.min(q_means)\n        check4 = max_diff <= 0.2 * R_std\n\n    return all([check1, check2, check3, check4])\n\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the validation workflow for each.\n    \"\"\"\n    test_cases = [\n        # Case 1: Happy path, linear drift correctly removed\n        {'grid_spec': (16, 16, 5), 'p_true': 1, \n         'drift_coeffs': {'c': 20, 'ax': 0.02, 'ay': -0.01}, 'p_fit': 1, \n         'cov_params': {'sigma2': 2.0, 'phi': 20, 'tau2': 0.25}, 'seed': 42},\n        \n        # Case 2: Quadratic drift correctly removed\n        {'grid_spec': (15, 15, 5), 'p_true': 2, \n         'drift_coeffs': {'c': 18, 'ax': 0.01, 'ay': 0.005, 'bxx': 0.0002, 'byy': -0.0001, 'bxy': 0.00015}, 'p_fit': 2, \n         'cov_params': {'sigma2': 2.5, 'phi': 15, 'tau2': 0.3}, 'seed': 123},\n        \n        # Case 3: No drift, unnecessary linear detrend\n        {'grid_spec': (16, 16, 5), 'p_true': 0, \n         'drift_coeffs': {'c': 22}, 'p_fit': 1, \n         'cov_params': {'sigma2': 1.5, 'phi': 25, 'tau2': 0.2}, 'seed': 7},\n        \n        # Case 4: Mis-specified drift order causing failure\n        {'grid_spec': (14, 14, 5), 'p_true': 2, \n         'drift_coeffs': {'c': 19, 'ax': 0.015, 'ay': -0.008, 'bxx': 0.0010, 'byy': -0.0008, 'bxy': 0.0006}, 'p_fit': 1,\n         'cov_params': {'sigma2': 0.3, 'phi': 15, 'tau2': 0.1}, 'seed': 999},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_case(**params)\n        results.append(result)\n\n    # Format the final output as a string list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Once an empirical variogram has been computed from data, the next critical step is to fit a continuous, permissible mathematical model to these discrete points. This practice moves from application to theory, asking you to derive the objective function for Weighted Least Squares (WLS) fitting, a statistically robust method. By understanding why we weight certain lag bins more than others—giving more influence to estimates based on more data pairs—you will gain a foundational appreciation for how geostatistical software produces reliable variogram models from noisy empirical estimates. ",
            "id": "3850192",
            "problem": "A remote sensing scientist is modeling spatial autocorrelation in detrended land surface temperature residuals obtained from satellite observations over a large region. Let the residual field be denoted by a second-order stationary and isotropic random field $Z(\\mathbf{s})$ with location $\\mathbf{s} \\in \\mathbb{R}^{2}$. The isotropic semivariogram is defined by $\\gamma(h) = \\frac{1}{2}\\operatorname{Var}\\!\\left[Z(\\mathbf{s}) - Z(\\mathbf{s}+\\mathbf{h})\\right]$ with $h = \\|\\mathbf{h}\\|$. The scientist aggregates observation pairs into $K$ non-overlapping lag bins centered at distances $h_{1},\\ldots,h_{K}$, with bin $k$ containing the set of index pairs $N(h_{k}) = \\{(i,j): \\| \\mathbf{s}_{i} - \\mathbf{s}_{j} \\| \\in \\text{bin around } h_{k} \\}$ and cardinality $|N(h_{k})|$. The unbiased Matheron estimator of the semivariogram in bin $k$ is\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} \\left(Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})\\right)^{2}.\n$$\nSuppose a parametric variogram model $\\gamma(h;\\boldsymbol{\\theta})$ is to be fit to $\\{\\hat{\\gamma}(h_{k})\\}_{k=1}^{K}$ by minimizing a weighted sum of squared residuals, following the principle that if the estimation errors at different lags are heteroscedastic and approximately independent with variances $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$, then optimal weights should be inversely proportional to these variances. Assume further that, for large $|N(h_{k})|$ and weak dependence among distinct pairs within a bin, a Gaussian approximation holds for the distribution of $\\hat{\\gamma}(h_{k})$ and that for a Gaussian random field the variance of a single squared increment $Y_{ij}(h_{k})^{2}$ with $Y_{ij}(h_{k}) = Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})$ and $\\| \\mathbf{s}_{i} - \\mathbf{s}_{j} \\| \\in \\text{bin around } h_{k}$ satisfies $\\operatorname{Var}\\!\\left[Y_{ij}(h_{k})^{2}\\right] = 2\\left(2\\gamma(h_{k})\\right)^{2}$.\n\nStarting from these foundations, derive the explicit Weighted Least Squares (WLS) objective function to estimate $\\boldsymbol{\\theta}$ in terms of $\\gamma(h_{k};\\boldsymbol{\\theta})$, $\\hat{\\gamma}(h_{k})$, and $\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right]$, and justify why weights proportional to $|N(h_{k})|$ or to $1/\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right]$ are theoretically appropriate under the stated assumptions. Provide the objective as a single closed-form summation. Your final answer must be a single closed-form analytic expression. No numerical evaluation is required.",
            "solution": "The objective is to derive the explicit Weighted Least Squares (WLS) objective function, $L(\\boldsymbol{\\theta})$, for estimating the parameters $\\boldsymbol{\\theta}$ of a parametric variogram model $\\gamma(h;\\boldsymbol{\\theta})$. The WLS method is used to fit the model to a set of empirical semivariogram estimates $\\{\\hat{\\gamma}(h_{k})\\}_{k=1}^{K}$.\n\nThe general form of a WLS objective function is a weighted sum of squared differences between observed values and model-predicted values:\n$$\nL(\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} w_{k} \\left[ \\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta}) \\right]^{2}\n$$\nwhere $w_{k}$ are the weights associated with each lag bin $k$.\n\nFor optimal estimation, the weights $w_{k}$ should be inversely proportional to the variance of the estimator $\\hat{\\gamma}(h_{k})$, i.e., $w_{k} \\propto 1/\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$. The core of the derivation is to find an expression for $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$ based on the provided assumptions.\n\nThe Matheron estimator for the semivariogram at lag $h_{k}$ is:\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} \\left(Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})\\right)^{2}\n$$\nLet's denote the squared increment as $Y_{ij}^{2} = (Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j}))^{2}$. The estimator can be written as:\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\n$$\nThe variance of this estimator is:\n$$\n\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right] = \\operatorname{Var}\\!\\left[\\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right] = \\frac{1}{4\\,|N(h_{k})|^{2}} \\operatorname{Var}\\!\\left[\\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right]\n$$\nAssuming weak dependence among distinct pairs allows us to approximate the variance of the sum as the sum of the variances:\n$$\n\\operatorname{Var}\\!\\left[\\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right] \\approx \\sum_{(i,j)\\in N(h_{k})} \\operatorname{Var}\\!\\left[Y_{ij}^{2}\\right]\n$$\nThe problem states that for a Gaussian random field, $\\operatorname{Var}[Y_{ij}^{2}] = 2(2\\gamma(h_{k}))^{2} = 8\\gamma(h_{k})^{2}$. We assume this variance is constant for all pairs within bin $k$. Substituting this into the sum:\n$$\n\\sum_{(i,j)\\in N(h_{k})} \\operatorname{Var}\\!\\left[Y_{ij}^{2}\\right] = |N(h_{k})| \\cdot 8\\gamma(h_{k})^{2}\n$$\nNow, substituting this back into the expression for $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$:\n$$\n\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right] \\approx \\frac{1}{4\\,|N(h_{k})|^{2}} \\left( 8|N(h_{k})|\\gamma(h_{k})^{2} \\right) = \\frac{2\\gamma(h_{k})^{2}}{|N(h_{k})|}\n$$\nThis expression shows that the variance of the empirical semivariogram estimator is inversely proportional to the number of pairs $|N(h_{k})|$ and directly proportional to the square of the true semivariogram value $\\gamma(h_{k})$.\n\nThe optimal weights are the inverse of this variance. During fitting, the unknown true variogram $\\gamma(h_{k})$ is replaced by the model $\\gamma(h_{k};\\boldsymbol{\\theta})$:\n$$\nw_{k} = \\frac{1}{\\operatorname{Var}[\\hat{\\gamma}(h_{k})]} \\approx \\frac{|N(h_{k})|}{2\\gamma(h_{k};\\boldsymbol{\\theta})^{2}}\n$$\nSubstituting these weights into the WLS objective function gives the final expression. This approach is justified because it properly weights each lag bin according to its statistical reliability. When the errors of observations are heteroscedastic (have different variances), WLS gives more importance to the more precise measurements (those with smaller variance), leading to more efficient parameter estimates compared to Ordinary Least Squares (where all weights are equal).\n\nA simpler, common weighting scheme uses only $w_k \\propto |N(h_k)|$. This accounts for the precision difference due to the number of pairs but ignores the dependency on the variogram magnitude. The full WLS is more statistically rigorous.\n\nThe derived objective function is:\n$$\nL(\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\frac{|N(h_{k})|}{2\\gamma(h_{k};\\boldsymbol{\\theta})^{2}} \\left[ \\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta}) \\right]^{2}\n$$\nThis can be rearranged to:\n$$\nL(\\boldsymbol{\\theta}) = \\frac{1}{2} \\sum_{k=1}^{K} |N(h_{k})| \\left[ \\frac{\\hat{\\gamma}(h_{k})}{\\gamma(h_{k};\\boldsymbol{\\theta})} - 1 \\right]^{2}\n$$\nThe problem asks for a single closed-form summation, which is provided in the answer.",
            "answer": "$$\n\\boxed{\\sum_{k=1}^{K} \\frac{|N(h_{k})|}{2[\\gamma(h_{k};\\boldsymbol{\\theta})]^2} \\left(\\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta})\\right)^2}\n$$"
        },
        {
            "introduction": "The binned empirical variogram, while useful, is a summary that can sometimes hide important details about the spatial structure of your data. This diagnostic exercise focuses on the variogram cloud—a raw plot of every pair's squared difference against its separation distance. Learning to interpret the patterns within this cloud is a powerful skill for identifying complex issues like hidden outliers, directional dependencies (anisotropy), and the mixing of different spatial populations, allowing for a more nuanced and accurate modeling approach. ",
            "id": "3850208",
            "problem": "A georeferenced satellite image yields a field of Near-Infrared (NIR) reflectance $Z(\\mathbf{s})$ on a regular lattice of locations $\\{\\mathbf{s}_i\\}_{i=1}^n \\subset \\mathbb{R}^2$. Assume $Z(\\mathbf{s})$ is a realization of a random field and recall the core definitions: second-order stationarity requires a constant mean $m(\\mathbf{s}) \\equiv m$ and a covariance that depends only on the lag vector $\\mathbf{h}$, and the semivariogram is defined at lag $\\mathbf{h}$ by $\\gamma(\\mathbf{h}) = \\tfrac{1}{2}\\,\\mathrm{Var}\\big(Z(\\mathbf{s}) - Z(\\mathbf{s}+\\mathbf{h})\\big)$. A variogram cloud is constructed by computing, for every unordered pair $(i,j)$, the squared difference $d_{ij} = \\big(Z(\\mathbf{s}_i)-Z(\\mathbf{s}_j)\\big)^2$ and associating it with the lag vector $\\mathbf{h}_{ij} = \\mathbf{s}_j - \\mathbf{s}_i$, then plotting $d_{ij}$ against $\\|\\mathbf{h}_{ij}\\|$ and optionally classifying by direction via the azimuth $\\theta_{ij} = \\arg(\\mathbf{h}_{ij})$. In a particular scene, the cloud exhibits the following features:\n- At short lags, specifically for $\\|\\mathbf{h}_{ij}\\| \\le r_0$ for some $r_0 > 0$, there is a wide spread of $d_{ij}$ values, with both very small and very large values coexisting at similar $\\|\\mathbf{h}_{ij}\\|$.\n- Pairs aligned approximately east–west (i.e., $\\theta_{ij} \\approx 0^\\circ$ or $\\theta_{ij} \\approx \\pi$) have systematically larger $d_{ij}$ than pairs aligned north–south (i.e., $\\theta_{ij} \\approx \\tfrac{\\pi}{2}$).\n- Across all lags, a subset of very large $d_{ij}$ values repeatedly involves the same pixel index $k$, i.e., $d_{kj}$ is large for many $j$.\n- The marginal distribution of $Z(\\mathbf{s})$ across the image is bimodal with modes near $0.1$ and $0.4$ reflectance.\n\nStarting from the foundational definitions above and without assuming any specific parametric model, select all statements that correctly describe how to use the variogram cloud to identify nonstationarity, outliers, or multiphase structures in this scene, and propose appropriate diagnostics to confirm these patterns.\n\nA. Use the variogram cloud stratified by azimuth to hypothesize directional dependence. Fit a smooth trend $ \\hat{m}(\\mathbf{s}) $ (e.g., a polynomial or thin-plate spline) to $Z(\\mathbf{s})$, compute residuals $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$, and recompute the variogram cloud for $R(\\mathbf{s})$. If the wedge-like spread at short lags collapses and directional differences diminish, this supports nonstationarity due to a mean trend. Confirm by computing moving-window semivariograms $\\hat{\\gamma}_W(\\mathbf{h}; \\mathbf{s})$ whose estimated nuggets or sills vary over $\\mathbf{s}$.\n\nB. Use the variogram cloud to flag potential outliers: pixels $k$ that produce unusually large $d_{kj}$ across many partners $j$ and across a range of $\\|\\mathbf{h}_{kj}\\|$. Confirm by computing robust, influence-resistant variogram estimators for $Z(\\mathbf{s})$ (e.g., the Cressie–Hawkins estimator) and by evaluating leave-one-out ordinary kriging residuals for $k$; large, studentized residuals across multiple neighborhoods indicate a true outlier rather than a single anomalous pair.\n\nC. Interpret the coexistence of very small and very large $d_{ij}$ at short lags together with the bimodal marginal distribution as evidence of multiphase structure (e.g., distinct land-cover phases). Stratify the variogram cloud by phase labels obtained from unsupervised clustering of $Z(\\mathbf{s})$, and compare within-phase versus between-phase clouds; persistent large $d_{ij}$ for between-phase pairs even at small $\\|\\mathbf{h}_{ij}\\|$ supports multiphase structure. Confirm by computing indicator variograms for a binary phase indicator $Y(\\mathbf{s}) = \\mathbf{1}\\{Z(\\mathbf{s}) \\ge \\tau\\}$, testing whether $\\gamma_Y(\\mathbf{h})$ differs markedly from within-phase semivariograms.\n\nD. Rely on global Moran’s $I$ for isotropic weights to detect anisotropy: compute a single Moran’s $I$ on $Z(\\mathbf{s})$ and, after $z$-score normalization of $Z(\\mathbf{s})$, attribute any deviation of $I$ from zero to directional anisotropy; this alone suffices to confirm the east–west pattern observed in the cloud.\n\nE. Diagnose nonstationarity from the histogram of $Z(\\mathbf{s})$ alone: because the distribution is bimodal with heavy tails, the process is nonstationary; confirm by globally standardizing $Z(\\mathbf{s})$ to zero mean and unit variance and observing that the variogram cloud becomes tight.\n\nF. Compute the correlation between $d_{ij}$ and $\\|\\mathbf{h}_{ij}\\|$ over all pairs; if it is strongly positive, conclude there is a global trend rather than multiphase structure, and no further diagnostics are necessary.\n\nSelect all correct options.",
            "solution": "To solve this problem, we must interpret the four key features observed in the data and the variogram cloud, linking them to underlying geostatistical concepts and appropriate diagnostic procedures.\n\n1.  **Bimodal marginal distribution and short-lag spread:** The bimodal distribution (modes at 0.1 and 0.4) strongly suggests the presence of two distinct data populations, or phases, likely corresponding to different land cover types. The wide spread of squared differences ($d_{ij}$) at short lags is a direct consequence of this. Pairs of nearby points within the same phase will have small $d_{ij}$, while nearby points on opposite sides of a phase boundary will have large $d_{ij}$.\n2.  **Directional differences:** The observation that east-west pairs have systematically larger squared differences than north-south pairs is the classic signature of **anisotropy**. The spatial correlation is stronger (i.e., values are more similar) in the north-south direction than in the east-west direction.\n3.  **Anomalous points:** A single pixel index $k$ being involved in many pairs with large $d_{kj}$ is the tell-tale sign of a potential **outlier**. The value $Z(\\mathbf{s}_k)$ is inconsistent with many of its neighbors, regardless of distance or direction.\n\nBased on these interpretations, let's evaluate each option:\n\n**A. Correct.** A large-scale trend (nonstationarity in the mean) can also cause directional dependencies and an inflated variogram at all lags. The proposed diagnostic—fitting a trend, analyzing the residuals' variogram, and checking for changes—is a standard and valid procedure to test for this. Using moving-window semivariograms is an excellent way to check for second-order nonstationarity (where the covariance structure itself varies spatially).\n\n**B. Correct.** This option correctly identifies the variogram cloud's \"cross\" or \"star\" pattern as an indicator of an outlier. The proposed confirmation steps are robust and methodologically sound. Comparing the standard variogram to a robust estimator (like Cressie-Hawkins) mitigates the outlier's influence, while leave-one-out cross-validation directly tests how well a point is predicted by its neighbors. Large studentized residuals confirm the point's anomalous nature.\n\n**C. Correct.** This option correctly links the bimodal distribution to a multiphase structure. The proposed diagnostic workflow is the correct way to analyze such data. By stratifying the data based on phase (e.g., using a threshold between the modes to create labels) and computing within-phase and between-phase variograms, one can explicitly model this structure. Using an indicator variogram on a binary phase variable is a complementary and powerful technique to model the spatial arrangement of the phases themselves.\n\n**D. Incorrect.** Global Moran's I, when computed with isotropic weights (based only on distance), averages out all directional information. It can detect the presence of spatial autocorrelation but is, by definition, insensitive to anisotropy. To detect directional patterns, one needs directional variograms or anisotropic weighting schemes.\n\n**E. Incorrect.** A bimodal marginal distribution does not inherently mean the process is nonstationary. A stationary process can have a mixture distribution. Furthermore, global standardization is a simple linear rescaling and does not remove a spatial trend or resolve a multiphase structure; the structural features of the variogram cloud would remain, only with rescaled axes.\n\n**F. Incorrect.** A positive correlation between squared differences and distance is characteristic of nearly all spatially autocorrelated data, whether stationary or not. It simply reflects that points farther apart tend to be less similar. This single metric is insufficient to distinguish between different types of spatial structure (trend, stationary process, etc.) and ignoring the other rich details in the variogram cloud is poor practice.\n\nTherefore, options A, B, and C describe correct and appropriate diagnostic procedures.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}