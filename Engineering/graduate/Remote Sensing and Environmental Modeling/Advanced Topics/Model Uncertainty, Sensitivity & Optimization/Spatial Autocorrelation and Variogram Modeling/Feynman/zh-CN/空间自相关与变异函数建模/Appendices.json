{
    "hands_on_practices": [
        {
            "introduction": "在应用地球统计学时，分析通常涉及一个多步骤的工作流程。这个实践旨在引导您完成一个从原始数据处理到模型假设验证的完整且真实的工作流程。其核心原则是将空间场分解为确定性趋势（$m(\\mathbf{s})$）和稳态随机分量（$Y(\\mathbf{s})$），并展示如何估计和移除趋势，然后通过经验变异函数来验证残差是否满足稳态假设。这项练习的价值在于它超越了孤立的计算，教授了如何构建和实施一个完整的分析流程，这是任何从业者的关键技能。",
            "id": "3850245",
            "problem": "给定一个合成的遥感场景，其中，一个二维区域的午间地表温度 (LST) 以摄氏度为单位进行测量。该测量场被建模为一个确定性漂移和一个零均值平稳随机分量之和。您的任务是构建一个完整的工作流，用以识别并移除数据中的确定性漂移，然后通过经验变异函数属性验证残差的内蕴平稳性。\n\n用于推导的基本原理和定义：\n- 令 $Z(\\mathbf{s})$ 表示在空间位置 $\\mathbf{s} \\in \\mathbb{R}^2$ 的观测场。假设 $Z(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})$，其中 $m(\\mathbf{s})$ 是一个确定性漂移，而 $Y(\\mathbf{s})$ 是一个零均值平稳高斯随机场，其协方差仅通过其欧几里得范数 $h = \\|\\mathbf{h}\\|$ 依赖于分离向量 $\\mathbf{h} = \\mathbf{s}_i - \\mathbf{s}_j$。\n- 平稳性由以下特征定义：$Y(\\mathbf{s})$ 具有恒定的均值 $0$ 和仅依赖于 $h$ 的协方差 $C(h)$。内蕴平稳性假设增量的均值为 $0$，且增量的方差仅依赖于 $h$，这使得变异函数有良好定义。\n- 经验变异函数通过 Matheron 估算量定义。对于距离的等宽分组，滞后距分组 $k$ 处的经验半方差为\n$$\n\\hat{\\gamma}(h_k) = \\frac{1}{2 N(h_k)} \\sum_{(i,j) \\in B_k} \\left(Z(\\mathbf{s}_i) - Z(\\mathbf{s}_j)\\right)^2,\n$$\n其中 $B_k$ 索引了所有其分离距离落入分组 $k$ 的点对，而 $N(h_k)$ 是此类点对的数量。\n- 对 $Y(\\mathbf{s})$ 使用各向同性指数协方差：\n$$\nC(h) = \\sigma^2 \\exp\\left( -\\frac{h}{\\phi} \\right),\n$$\n并在对角线上加入方差为 $\\tau^2$ 的独立测量噪声（块金效应）。\n\n工作流要求：\n1. 确定性漂移移除：\n   - 使用普通最小二乘法对 $Z(\\mathbf{s})$ 拟合一个阶数 $p \\in \\{0,1,2\\}$ 的多项式趋势。对于 $p=0$，仅使用截距；对于 $p=1$，包括截距、$x$ 和 $y$；对于 $p=2$，包括截距、$x$、$y$、$x^2$、$y^2$ 和 $xy$。此处 $\\mathbf{s}=(x,y)$ 的单位是公里。\n   - 从 $Z(\\mathbf{s})$ 中减去拟合的趋势 $\\hat{m}(\\mathbf{s})$ 以获得残差 $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$。\n\n2. 经验变异函数计算：\n   - 使用 $K$ 个等宽距离分组，计算 $R(\\mathbf{s})$ 从 $0$ 到最大点对距离的各向同性经验变异函数。使用 $K=12$ 个分组。距离单位为公里；半方差单位为平方摄氏度。\n   - 为保证数值稳定性，如果任何分组的 $N(h_k) = 0$，则将其半方差视为未定义，并从下述检查中排除。\n\n3. 残差的内蕴平稳性验证：\n   - 均值稳定性：要求 $R(\\mathbf{s})$ 的绝对均值相对于其标准差要小：\n     $$\n     \\left| \\overline{R} \\right| \\leq \\alpha \\cdot s_R,\n     $$\n     其中 $\\alpha = 0.1$，$s_R$ 是 $R(\\mathbf{s})$ 的标准差。\n   - 变异函数单调性：计算相邻有效变异函数分组 $\\hat{\\gamma}(h_{k+1})$ 和 $\\hat{\\gamma}(h_k)$ 中满足以下条件的比例 $M$：\n     $$\n     \\hat{\\gamma}(h_{k+1}) \\geq \\hat{\\gamma}(h_k) - \\epsilon,\n     $$\n     其中 $\\epsilon$ 是一个与估计的基台值成比例的容差（取 $\\epsilon = 0.05 \\cdot \\max_k \\hat{\\gamma}(h_k)$）。要求 $M \\geq 0.8$。\n   - 短滞后距斜率非负性：对前 $L$ 个有效的变异函数点（最小滞后距）拟合一个线性模型，其中，如果有效分组少于 $4$ 个，则 $L$ 取实际有效分组数，并要求估计的斜率 $\\beta$ 满足：\n     $$\n     \\beta \\geq 0.\n     $$\n   - 空间均值一致性：通过 $x$ 和 $y$ 的中位数分割，将域划分为四个象限。令 $\\overline{R}_q$ 为象限 $q$ 内的平均残差。要求\n     $$\n     \\max_{q,q'} \\left| \\overline{R}_q - \\overline{R}_{q'} \\right| \\leq \\gamma \\cdot s_R,\n     $$\n     其中 $\\gamma = 0.2$。\n\n如果所有四个条件都满足，则宣布残差场是内蕴平稳的；否则，宣布其为非平稳的。\n\n物理单位和数值精度：\n- 坐标 $x$ 和 $y$ 的单位是公里。\n- 温度值的单位是摄氏度。\n- 变异函数中的距离单位为公里；半方差单位为平方摄氏度。\n- 每个测试用例的最终输出是布尔值；输出不需要单位转换。\n\n测试套件和参数规范：\n您必须为以下 $4$ 个测试用例实现该工作流。在每个案例中，在指定的点集上生成合成数据，构建漂移，生成平稳高斯分量，添加块金噪声，使用指定的多项式阶数进行去趋势，计算经验变异函数，并验证内蕴平稳性。\n\n对于每个测试用例，参数如下：\n- 网格规范：$x$ 和 $y$ 方向上的点数，间距 $s$（单位公里），或特定的采样配置。\n- 真实漂移阶数 $p_{\\text{true}} \\in \\{0,1,2\\}$ 和系数（单位为摄氏度每公里的适当次方）。\n- 去趋势中使用的拟合多项式阶数 $p_{\\text{fit}} \\in \\{0,1,2\\}$。\n- 协方差参数 $\\sigma^2$、$\\phi$（单位为公里）和块金方差 $\\tau^2$（单位为平方摄氏度）。\n- 用于可复现性的随机种子。\n\n定义四个测试用例如下：\n- 案例 1（理想路径，线性漂移被正确移除）：\n  - 网格：$16 \\times 16$ 常规网格，间距 $s = 5$ 公里。\n  - 真实漂移：$p_{\\text{true}} = 1$，系数为 $c = 20$，$a_x = 0.02$ 摄氏度/公里，$a_y = -0.01$ 摄氏度/公里。\n  - 拟合：$p_{\\text{fit}} = 1$。\n  - 协方差：$\\sigma^2 = 2.0$，$\\phi = 20$ 公里，$\\tau^2 = 0.25$。\n  - 种子：$42$。\n- 案例 2（二次漂移被正确移除）：\n  - 网格：$15 \\times 15$ 常规网格，间距 $s = 5$ 公里。\n  - 真实漂移：$p_{\\text{true}} = 2$，系数为 $c = 18$，$a_x = 0.01$，$a_y = 0.005$ 摄氏度/公里，$b_{xx} = 0.0002$，$b_{yy} = -0.0001$，$b_{xy} = 0.00015$ 摄氏度/平方公里。\n  - 拟合：$p_{\\text{fit}} = 2$。\n  - 协方差：$\\sigma^2 = 2.5$，$\\phi = 15$ 公里，$\\tau^2 = 0.3$。\n  - 种子：$123$。\n- 案例 3（无漂移，不必要的线性去趋势）：\n  - 网格：$16 \\times 16$ 常规网格，间距 $s = 5$ 公里。\n  - 真实漂移：$p_{\\text{true}} = 0$，系数为 $c = 22$ 摄氏度。\n  - 拟合：$p_{\\text{fit}} = 1$。\n  - 协方差：$\\sigma^2 = 1.5$，$\\phi = 25$ 公里，$\\tau^2 = 0.2$。\n  - 种子：$7$。\n- 案例 4（边缘案例，漂移阶数指定错误导致失败）：\n  - 网格：$14 \\times 14$ 常规网格，间距 $s = 5$ 公里。\n  - 真实漂移：$p_{\\text{true}} = 2$，系数为 $c = 19$，$a_x = 0.015$，$a_y = -0.008$ 摄氏度/公里，$b_{xx} = 0.0010$，$b_{yy} = -0.0008$，$b_{xy} = 0.0006$ 摄氏度/平方公里。\n  - 拟合：$p_{\\text{fit}} = 1$。\n  - 协方差：$\\sigma^2 = 0.3$，$\\phi = 15$ 公里，$\\tau^2 = 0.1$。\n  - 种子：$999$。\n\n数值实现细节：\n- 使用普通最小二乘法进行漂移拟合。\n- 对经验变异函数使用 $K = 12$ 个各向同性距离分组。\n- 对于短滞后距斜率计算，使用前 $L = 4$ 个有效分组。如果有效分组少于 $4$ 个，则使用所有可用的有效分组。在斜率拟合中，包含的每个分组的最小点对数阈值为 $30$；点对数少于 $30$ 的分组应从斜率拟合中排除。\n\n要求的最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[result1,result2,result3,result4]\"）作为结果，其中每个结果都是一个布尔值，指示相应测试用例是否根据上述四个标准验证为内蕴平稳。布尔值必须按测试用例 1 到 4 的顺序出现。",
            "solution": "该问题要求开发并实现一个地统计工作流，以评估一个残差空间场的内蕴平稳性。该场是在从一个类似于遥感地表温度 (LST) 的合成数据集中移除确定性多项式趋势后获得的。验证基于对残差及其经验变异函数执行的一组定量检查。整个过程将对四个不同的测试用例执行，每个用例都有指定的数据生成和趋势移除参数。\n\n观测空间场 $Z(\\mathbf{s})$ 在位置 $\\mathbf{s} \\in \\mathbb{R}^2$ 的基础模型由以下分解给出：\n$$\nZ(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})\n$$\n这里，$m(\\mathbf{s})$ 代表一个确定性的大尺度变异或漂移，而 $Y(\\mathbf{s})$ 是一个零均值的二阶平稳随机过程，用于模拟空间相关的随机波动。$Y(\\mathbf{s})$ 的平稳性由一个各向同性指数协方差函数来表征：\n$$\nC(h) = \\sigma^2 \\exp\\left( -\\frac{h}{\\phi} \\right)\n$$\n其中 $h = \\|\\mathbf{s}_i - \\mathbf{s}_j\\|$ 是两个位置之间的欧几里得距离，$\\sigma^2$ 是偏基台值（相关分量的方差），$\\phi$ 是有效变程参数。此外，被称为块金效应的独立测量噪声在零分离距离处贡献了方差 $\\tau^2$。因此，一组点 $\\{\\mathbf{s}_i\\}_{i=1}^N$ 的总协方差由一个矩阵 $K$ 描述，其元素为 $K_{ij} = C(\\|\\mathbf{s}_i - \\mathbf{s}_j\\|)$（当 $i \\neq j$ 时），对角线元素为 $K_{ii} = \\sigma^2 + \\tau^2$。\n\n该工作流按以下四个阶段进行：\n\n**1. 合成数据生成**\n对于每个测试用例，都会生成一个合成数据集。首先，根据指定的网格配置建立一组空间坐标。然后，使用真实的\n多项式阶数 $p_{\\text{true}}$ 及其系数在每个位置计算确定性漂移分量 $m(\\mathbf{s})$。通过从多元正态分布 $\\mathcal{N}(\\mathbf{0}, K)$ 中抽取一个样本来生成平稳随机场 $Y(\\mathbf{s})$ 的一个实现，其中 $K$ 是由给定参数 $\\sigma^2$、$\\phi$ 和 $\\tau^2$ 构建的协方差矩阵。最终的观测场是 $Z(\\mathbf{s}) = m(\\mathbf{s}) + Y(\\mathbf{s})$ 之和。\n\n**2. 确定性漂移移除**\n使用普通最小二乘法 (OLS) 将一个指定阶数 $p_{\\text{fit}} \\in \\{0, 1, 2\\}$ 的多项式趋势面 $\\hat{m}(\\mathbf{s})$ 拟合到观测数据 $Z(\\mathbf{s})$。OLS 回归的设计矩阵 $X$ 是根据坐标 $\\mathbf{s}=(x,y)$ 和选择的多项式阶数构建的。例如，对于 $p_{\\text{fit}}=2$， $X$ 的列对应于基函数 $\\{1, x, y, x^2, y^2, xy\\}$。多项式系数的 OLS 估算量 $\\hat{\\beta}$ 通过求解正规方程得到，通常通过 $\\hat{\\beta} = (X^T X)^{-1}X^T Z$ 计算。拟合的趋势是 $\\hat{m}(\\mathbf{s}) = X\\hat{\\beta}$，残差计算为 $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$。这些残差代表了其平稳性待检验的去趋势场。\n\n**3. 经验变异函数计算**\n通过使用 Matheron 估算量计算各向同性经验半变异函数，来分析残差 $R(\\mathbf{s})$ 的空间结构。所有数据点之间的成对距离范围被划分为 $K=12$ 个等宽分组。对于每个分组 $k$，半方差 $\\hat{\\gamma}(h_k)$ 计算如下：\n$$\n\\hat{\\gamma}(h_k) = \\frac{1}{2 N(h_k)} \\sum_{(i,j) \\in B_k} \\left(R(\\mathbf{s}_i) - R(\\mathbf{s}_j)\\right)^2\n$$\n其中 $B_k$ 是所有其分离距离落入分组 $k$ 的点对集合，$N(h_k)$ 是此类点对的计数。$N(h_k) = 0$ 的分组被视为无效。\n\n**4. 内蕴平稳性验证**\n只有在满足四个不同准则的情况下，残差场 $R(\\mathbf{s})$ 才被宣布为内蕴平稳：\n\n*   **均值稳定性：** 残差的绝对均值 $|\\overline{R}|$ 必须相对于其标准差 $s_R$ 较小。形式化检查为 $|\\overline{R}| \\leq \\alpha \\cdot s_R$，容差因子 $\\alpha = 0.1$。这确保了去趋势过程已成功地生成了一个均值近似为零的场。\n\n*   **变异函数单调性：** 理论变异函数必须是滞后距离 $h$ 的单调非递减函数。我们在经验变异函数上测试此属性。满足 $\\hat{\\gamma}(h_{k+1}) \\geq \\hat{\\gamma}(h_k) - \\epsilon$ 的相邻有效分组 $(\\hat{\\gamma}(h_k), \\hat{\\gamma}(h_{k+1}))$ 的比例 $M$ 必须至少为 $0.8$。容差 $\\epsilon = 0.05 \\cdot \\max_k \\hat{\\gamma}(h_k)$ 允许微小的随机波动。若此项不满足，则表明存在显著的残余趋势。\n\n*   **短滞后距斜率非负性：** 变异函数在原点附近的行为至关重要。我们对前 $L=4$ 个具有足够点对数（$N(h_k) \\ge 30$）的有效变异函数点（或在可用点较少时使用所有可用点）拟合一个线性模型。该线的估计斜率 $\\beta$ 必须为非负（$\\beta \\geq 0$）。原点附近的负斜率与标准空间相关模型不符。\n\n*   **空间均值一致性：** 为了检测大尺度的残余趋势，该域通过坐标的中位数分割被划分为四个象限。计算每个象限内的残差均值 $\\overline{R}_q$。任意两个象限均值之间的最大绝对差必须相对于总残差标准差较小：$\\max_{q,q'} |\\overline{R}_q - \\overline{R}_{q'}| \\leq \\gamma \\cdot s_R$，其中 $\\gamma = 0.2$。\n\n仅当所有这四个条件都满足时，一个测试用例才被视为通过，表明残差具有可接受的平稳性。该实现将系统地将这整个工作流应用于四个指定的测试用例中的每一个。",
            "answer": "```python\nimport numpy as np\n\ndef run_case(grid_spec, p_true, drift_coeffs, p_fit, cov_params, seed):\n    \"\"\"\n    Executes the entire workflow for a single test case.\n    \"\"\"\n    # 1. Generate spatial coordinates\n    rng = np.random.default_rng(seed)\n    nx, ny, s = grid_spec\n    x = np.arange(nx) * s\n    y = np.arange(ny) * s\n    xx, yy = np.meshgrid(x, y)\n    coords = np.vstack([xx.ravel(), yy.ravel()]).T\n    n_points = nx * ny\n    x_coords, y_coords = coords[:, 0], coords[:, 1]\n\n    # 2. Generate true deterministic drift m(s)\n    if p_true == 0:\n        m_true = np.full(n_points, drift_coeffs['c'])\n    elif p_true == 1:\n        m_true = (drift_coeffs['c'] + \n                  drift_coeffs['ax'] * x_coords + \n                  drift_coeffs['ay'] * y_coords)\n    elif p_true == 2:\n        m_true = (drift_coeffs['c'] + \n                  drift_coeffs['ax'] * x_coords + \n                  drift_coeffs['ay'] * y_coords +\n                  drift_coeffs['bxx'] * x_coords**2 + \n                  drift_coeffs['byy'] * y_coords**2 + \n                  drift_coeffs['bxy'] * x_coords * y_coords)\n\n    # 3. Generate stationary random component Y(s)\n    sigma2 = cov_params['sigma2']\n    phi = cov_params['phi']\n    tau2 = cov_params['tau2']\n    \n    dist_matrix = np.sqrt(((coords[:, np.newaxis, :] - coords[np.newaxis, :, :])**2).sum(axis=-1))\n    \n    cov_matrix = sigma2 * np.exp(-dist_matrix / phi)\n    np.fill_diagonal(cov_matrix, sigma2 + tau2)\n    \n    Y = rng.multivariate_normal(np.zeros(n_points), cov_matrix, method='eigh')\n\n    # 4. Form observed field Z(s)\n    Z = m_true + Y\n\n    # 5. Detrending using Ordinary Least Squares (OLS)\n    if p_fit == 0:\n        X = np.ones((n_points, 1))\n    elif p_fit == 1:\n        X = np.vstack([np.ones(n_points), x_coords, y_coords]).T\n    elif p_fit == 2:\n        X = np.vstack([np.ones(n_points), x_coords, y_coords, \n                       x_coords**2, y_coords**2, x_coords * y_coords]).T\n    \n    beta_hat = np.linalg.lstsq(X, Z, rcond=None)[0]\n    m_hat = X @ beta_hat\n    R = Z - m_hat\n\n    # 6. Empirical variogram computation\n    indices_upper = np.triu_indices(n_points, k=1)\n    dist_upper = dist_matrix[indices_upper]\n    \n    sq_diff_matrix = (R[:, np.newaxis] - R[np.newaxis, :])**2\n    sq_diff_upper = sq_diff_matrix[indices_upper]\n\n    K = 12\n    max_dist = dist_upper.max()\n    \n    counts, bin_edges = np.histogram(dist_upper, bins=K, range=(0, max_dist))\n    sum_sq_diff, _ = np.histogram(dist_upper, bins=K, range=(0, max_dist), weights=sq_diff_upper)\n\n    gamma_vals = np.full(K, np.nan)\n    valid_mask = counts > 0\n    gamma_vals[valid_mask] = sum_sq_diff[valid_mask] / (2 * counts[valid_mask])\n    \n    h_bins = (bin_edges[:-1] + bin_edges[1:]) / 2\n\n    # 7. Intrinsic stationarity validation\n    R_std = np.std(R)\n\n    # Check 1: Mean stability\n    check1 = np.abs(np.mean(R)) = 0.1 * R_std if R_std > 1e-9 else np.abs(np.mean(R))  1e-9\n\n    # Check 2: Variogram monotonicity\n    valid_gamma_indices = np.where(valid_mask)[0]\n    check2 = True\n    if len(valid_gamma_indices) > 1:\n        gamma_subset = gamma_vals[valid_gamma_indices]\n        if len(gamma_subset) > 0 and not np.all(np.isnan(gamma_subset)):\n            epsilon = 0.05 * np.nanmax(gamma_subset)\n            monotonic_pairs = 0\n            total_pairs = len(gamma_subset) - 1\n            for i in range(total_pairs):\n                if gamma_subset[i+1] >= gamma_subset[i] - epsilon:\n                    monotonic_pairs += 1\n            \n            check2 = (monotonic_pairs / total_pairs) >= 0.8\n        else: # No valid gamma points or all are NaN\n            check2 = True\n    \n    # Check 3: Short-lag slope non-negativity\n    slope_valid_mask = counts >= 30\n    slope_indices = np.where(slope_valid_mask)[0]\n    check3 = True\n    if len(slope_indices) > 0:\n        first_L_indices = slope_indices[:4]\n        if len(first_L_indices) >= 2:\n            h_slope = h_bins[first_L_indices]\n            gamma_slope = gamma_vals[first_L_indices]\n            \n            X_slope = np.vstack([h_slope, np.ones(len(h_slope))]).T\n            slope, _ = np.linalg.lstsq(X_slope, gamma_slope, rcond=None)[0]\n            check3 = slope >= 0\n\n    # Check 4: Spatial mean consistency\n    median_x = np.median(x_coords)\n    median_y = np.median(y_coords)\n    \n    q1_mask = (x_coords = median_x)  (y_coords = median_y)\n    q2_mask = (x_coords > median_x)  (y_coords = median_y)\n    q3_mask = (x_coords = median_x)  (y_coords > median_y)\n    q4_mask = (x_coords > median_x)  (y_coords > median_y)\n    \n    q_means = []\n    masks = [q1_mask, q2_mask, q3_mask, q4_mask]\n    for mask in masks:\n        if np.any(mask):\n            q_means.append(np.mean(R[mask]))\n    \n    check4 = True\n    if len(q_means) > 1 and R_std > 1e-9:\n        max_diff = np.max(q_means) - np.min(q_means)\n        check4 = max_diff = 0.2 * R_std\n\n    return all([check1, check2, check3, check4])\n\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the validation workflow for each.\n    \"\"\"\n    test_cases = [\n        # Case 1: Happy path, linear drift correctly removed\n        {'grid_spec': (16, 16, 5), 'p_true': 1, \n         'drift_coeffs': {'c': 20, 'ax': 0.02, 'ay': -0.01}, 'p_fit': 1, \n         'cov_params': {'sigma2': 2.0, 'phi': 20, 'tau2': 0.25}, 'seed': 42},\n        \n        # Case 2: Quadratic drift correctly removed\n        {'grid_spec': (15, 15, 5), 'p_true': 2, \n         'drift_coeffs': {'c': 18, 'ax': 0.01, 'ay': 0.005, 'bxx': 0.0002, 'byy': -0.0001, 'bxy': 0.00015}, 'p_fit': 2, \n         'cov_params': {'sigma2': 2.5, 'phi': 15, 'tau2': 0.3}, 'seed': 123},\n        \n        # Case 3: No drift, unnecessary linear detrend\n        {'grid_spec': (16, 16, 5), 'p_true': 0, \n         'drift_coeffs': {'c': 22}, 'p_fit': 1, \n         'cov_params': {'sigma2': 1.5, 'phi': 25, 'tau2': 0.2}, 'seed': 7},\n        \n        # Case 4: Mis-specified drift order causing failure\n        {'grid_spec': (14, 14, 5), 'p_true': 2, \n         'drift_coeffs': {'c': 19, 'ax': 0.015, 'ay': -0.008, 'bxx': 0.0010, 'byy': -0.0008, 'bxy': 0.0006}, 'p_fit': 1,\n         'cov_params': {'sigma2': 0.3, 'phi': 15, 'tau2': 0.1}, 'seed': 999},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_case(**params)\n        results.append(result)\n\n    # Format the final output as a string list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在计算出经验变异函数后（如上一个练习所示），下一步是为其拟合一个理论模型。这项实践深入探讨了此拟合过程背后的统计理论。其核心是加权最小二乘法（WLS）的原理，通过从经验变异函数估计量本身的方差推导出权重，来解释为什么WLS在变异函数拟合中优于普通最小二乘法（OLS）。理解这个推导有助于学生领会地球统计学软件为何采用特定的拟合算法，并能更批判性地评估模型拟合结果。",
            "id": "3850192",
            "problem": "一位遥感科学家正在对从大片区域的卫星观测中获得的去趋势后的地表温度残差进行空间自相关建模。设残差场由一个二阶平稳且各向同性的随机场 $Z(\\mathbf{s})$ 表示，其中位置 $\\mathbf{s} \\in \\mathbb{R}^{2}$。各向同性半变异函数定义为 $\\gamma(h) = \\frac{1}{2}\\operatorname{Var}\\!\\left[Z(\\mathbf{s}) - Z(\\mathbf{s}+\\mathbf{h})\\right]$，其中 $h = \\|\\mathbf{h}\\|$。该科学家将观测点对聚合成 $K$ 个不重叠的滞后距分组，这些分组以距离 $h_{1},\\ldots,h_{K}$ 为中心，其中第 $k$ 组包含索引对集合 $N(h_{k}) = \\{(i,j): \\| \\mathbf{s}_{i} - \\mathbf{s}_{j} \\| \\in \\text{bin around } h_{k} \\}$，其基数为 $|N(h_{k})|$。在第 $k$ 组中，半变异函数的 Matheron 无偏估计量为\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} \\left(Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})\\right)^{2}.\n$$\n假设要通过最小化加权残差平方和，将一个参数化变异函数模型 $\\gamma(h;\\boldsymbol{\\theta})$ 拟合到 $\\{\\hat{\\gamma}(h_{k})\\}_{k=1}^{K}$。这遵循一个原则：如果不同滞后距上的估计误差是异方差的且近似独立，其方差为 $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$，那么最优权重应与这些方差成反比。进一步假设，对于大的 $|N(h_{k})|$ 和组内不同点对之间的弱依赖性，$\\hat{\\gamma}(h_{k})$ 的分布满足高斯近似，并且对于高斯随机场，单个增量平方 $Y_{ij}(h_{k})^{2}$ 的方差满足 $\\operatorname{Var}\\!\\left[Y_{ij}(h_{k})^{2}\\right] = 2\\left(2\\gamma(h_{k})\\right)^{2}$，其中 $Y_{ij}(h_{k}) = Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})$ 且 $\\| \\mathbf{s}_{i} - \\mathbf{s}_{j} \\| \\in \\text{bin around } h_{k}$。\n\n从这些基础出发，推导用于估计 $\\boldsymbol{\\theta}$ 的显式加权最小二乘 (WLS) 目标函数，该函数用 $\\gamma(h_{k};\\boldsymbol{\\theta})$、$\\hat{\\gamma}(h_{k})$ 和 $\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right]$ 表示，并论证为何在给定假设下，与 $|N(h_{k})|$ 或 $1/\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right]$ 成正比的权重在理论上是合适的。将目标函数以单个闭式求和的形式给出。您的最终答案必须是单个闭式解析表达式。不需要进行数值计算。",
            "solution": "问题陈述已经过验证，被认为是有效的。它以地质统计学原理为科学基础，是适定的，并且所有术语都有形式化定义。所提供的假设在变异函数建模的背景下是标准的。因此，我们可以开始进行推导。\n\n目标是推导用于估计参数化变异函数模型 $\\gamma(h;\\boldsymbol{\\theta})$ 的参数矢量 $\\boldsymbol{\\theta}$ 的显式加权最小二乘 (WLS) 目标函数，我们称之为 $L(\\boldsymbol{\\theta})$。WLS 方法用于将模型拟合到一组经验半变异函数估计值 $\\{\\hat{\\gamma}(h_{k})\\}_{k=1}^{K}$。\n\nWLS 目标函数的一般形式是观测值与模型预测值之差的平方的加权和：\n$$\nL(\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} w_{k} \\left[ \\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta}) \\right]^{2}\n$$\n其中 $w_{k}$ 是与每个滞后距分组 $k$ 相关联的权重。\n\n问题指出，为了实现最优估计，权重 $w_{k}$ 应与估计量 $\\hat{\\gamma}(h_{k})$ 的方差成反比，即 $w_{k} \\propto 1/\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$。推导的核心是根据所提供的假设找到 $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$ 的表达式。\n\n滞后距 $h_{k}$ 处半变异函数的 Matheron 估计量由下式给出：\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} \\left(Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j})\\right)^{2}\n$$\n让我们将增量的平方表示为 $Y_{ij}^{2} = (Z(\\mathbf{s}_{i}) - Z(\\mathbf{s}_{j}))^{2}$。该估计量可以写成：\n$$\n\\hat{\\gamma}(h_{k}) = \\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\n$$\n我们需要计算这个估计量的方差：\n$$\n\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right] = \\operatorname{Var}\\!\\left[\\frac{1}{2\\,|N(h_{k})|} \\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right]\n$$\n使用属性 $\\operatorname{Var}[cX] = c^{2}\\operatorname{Var}[X]$，我们可以将常数项提出来：\n$$\n\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right] = \\frac{1}{4\\,|N(h_{k})|^{2}} \\operatorname{Var}\\!\\left[\\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right]\n$$\n问题明确了“组内不同点对之间的弱依赖性”这一假设。这使我们可以将和的方差近似为方差的和，就好像对于不同的点对 $(i,j)$，项 $Y_{ij}^{2}$ 是独立的：\n$$\n\\operatorname{Var}\\!\\left[\\sum_{(i,j)\\in N(h_{k})} Y_{ij}^{2}\\right] \\approx \\sum_{(i,j)\\in N(h_{k})} \\operatorname{Var}\\!\\left[Y_{ij}^{2}\\right]\n$$\n问题提供了一条从高斯随机场假设中得出的关键信息：对于相隔距离为 $h_k$ 的点对，单个增量平方 $Y_{ij}^{2}$ 的方差由 $\\operatorname{Var}[Y_{ij}^{2}] = 2(2\\gamma(h_{k}))^{2}$ 给出。我们假设对于第 $k$ 组内的所有点对，此方差是恒定的。\n将此代入求和中：\n$$\n\\sum_{(i,j)\\in N(h_{k})} \\operatorname{Var}\\!\\left[Y_{ij}^{2}\\right] = \\sum_{(i,j)\\in N(h_{k})} 2\\left(2\\gamma(h_{k})\\right)^{2} = |N(h_{k})| \\cdot 2\\left(2\\gamma(h_{k})\\right)^{2} = 8|N(h_{k})|\\gamma(h_{k})^{2}\n$$\n现在，我们将此结果代回到 $\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$ 的表达式中：\n$$\n\\operatorname{Var}\\!\\left[\\hat{\\gamma}(h_{k})\\right] \\approx \\frac{1}{4\\,|N(h_{k})|^{2}} \\left( 8|N(h_{k})|\\gamma(h_{k})^{2} \\right) = \\frac{2\\gamma(h_{k})^{2}}{|N(h_{k})|}\n$$\n这个表达式表明，经验半变异函数估计量的方差与点对数量 $|N(h_{k})|$ 成反比，与真实半变异函数值 $\\gamma(h_{k})$ 的平方成正比。\n\n最优权重是此方差的倒数：$w_{k} = 1 / \\operatorname{Var}[\\hat{\\gamma}(h_{k})]$。在拟合过程中，真实的变异函数 $\\gamma(h_{k})$ 是未知的。标准做法是在方差表达式中用模型变异函数 $\\gamma(h_{k};\\boldsymbol{\\theta})$ 代替 $\\gamma(h_{k})$。这使得权重本身也依赖于待估计的参数 $\\boldsymbol{\\theta}$，这是广义最小二乘法 (GLS) 的一个特点。\n所以，权重为：\n$$\nw_{k} = \\frac{|N(h_{k})|}{2\\gamma(h_{k};\\boldsymbol{\\theta})^{2}}\n$$\n将这些权重代入 WLS 目标函数，得到：\n$$\nL(\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\frac{|N(h_{k})|}{2\\gamma(h_{k};\\boldsymbol{\\theta})^{2}} \\left[ \\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta}) \\right]^{2}\n$$\n这就是要为估计 $\\boldsymbol{\\theta}$ 而最小化的显式 WLS 目标函数。为了找到最小值，常数因子 $1/2$ 可以省略。该表达式也可以重排为：\n$$\nL(\\boldsymbol{\\theta}) = \\frac{1}{2} \\sum_{k=1}^{K} |N(h_{k})| \\left[ \\frac{\\hat{\\gamma}(h_{k})}{\\gamma(h_{k};\\boldsymbol{\\theta})} - 1 \\right]^{2}\n$$\n\n接下来，我们论证这些加权方案的合理性。\n1.  **权重与 $1/\\operatorname{Var}[\\hat{\\gamma}(h_{k})]$ 成正比**：这是 WLS 的核心原则。当观测误差（此处指估计误差 $\\hat{\\gamma}(h_{k}) - \\gamma(h_{k})$）独立但具有不同方差（异方差性）时，WLS 是首选的估计方法。通过用每个残差平方的方差的倒数作为权重，我们给予更精确的测量（方差较小的）更大的重要性，而给予较不精确的测量较小的权重。这个过程产生的估计量 $\\hat{\\boldsymbol{\\theta}}$ 在某一类中是渐近最有效的。推导出的方差表达式 $\\operatorname{Var}[\\hat{\\gamma}(h_k)] \\approx 2\\gamma(h_k)^2/|N(h_k)|$ 表明，经验半变异函数估计确实是异方差的，因为它们的方差取决于点对数量 $|N(h_k)|$ 和半变异函数的大小 $\\gamma(h_k)$，这两者都随滞后距 $h_k$ 变化。\n\n2.  **权重与 $|N(h_{k})|$ 成正比**：这是一种简化的、非迭代的加权方案。它源于最优权重 $w_k \\propto |N(h_{k})|/\\gamma(h_{k};\\boldsymbol{\\theta})^{2}$，但做了一个简化近似，即假设项 $\\gamma(h_{k};\\boldsymbol{\\theta})^{2}$ 在所有滞后距 $k$ 上是恒定的。这种近似忽略了由半变异函数自身值的变化所引起的那部分异方差性。然而，它仍然考虑了由于每个滞后距分组中点对数量 $|N(h_k)|$ 的不同而导致的精度差异，而这通常是方差差异的主要来源。相比普通最小二乘法（所有 $k$ 的 $w_k = 1$），这是一种改进，并且比完全的 WLS 计算上更简单，因为权重不依赖于参数 $\\boldsymbol{\\theta}$。\n\n最终要求的表达式是完整的 WLS 目标函数。",
            "answer": "$$\n\\boxed{\\sum_{k=1}^{K} \\frac{|N(h_{k})|}{2[\\gamma(h_{k};\\boldsymbol{\\theta})]^2} \\left(\\hat{\\gamma}(h_{k}) - \\gamma(h_{k};\\boldsymbol{\\theta})\\right)^2}\n$$"
        },
        {
            "introduction": "接下来，我们将视野从分箱的经验变异函数扩展到构成它的原始数据对，介绍一种强大的诊断工具——变异函数云图。变异函数云图绘制了*每一*对点之间的平方差，其形态可以揭示复杂的空间模式，例如异常值、各向异性（方向性趋势）以及在创建标准经验变异函数的平均过程中可能被掩盖的多个子种群。这项实践旨在提升您的诊断技能，教您如何“阅读”数据中的原始空间结构，以便在投入到一个简化的建模工作流程之前，识别潜在问题或复杂特征。",
            "id": "3850208",
            "problem": "一幅地理配准的卫星图像在规则格网位置 $\\{\\mathbf{s}_i\\}_{i=1}^n \\subset \\mathbb{R}^2$ 上生成了一个近红外（NIR）反射率场 $Z(\\mathbf{s})$。假设 $Z(\\mathbf{s})$ 是一个随机场的实现，并回顾其核心定义：二阶平稳性要求均值 $m(\\mathbf{s}) \\equiv m$ 为常数，且协方差仅依赖于滞后向量 $\\mathbf{h}$；半变异函数在滞后向量 $\\mathbf{h}$ 处的定义为 $\\gamma(\\mathbf{h}) = \\tfrac{1}{2}\\,\\mathrm{Var}\\big(Z(\\mathbf{s}) - Z(\\mathbf{s}+\\mathbf{h})\\big)$。变异函数云图的构建方法是：对于每一个无序对 $(i,j)$，计算其平方差 $d_{ij} = \\big(Z(\\mathbf{s}_i)-Z(\\mathbf{s}_j)\\big)^2$ 并将其与滞后向量 $\\mathbf{h}_{ij} = \\mathbf{s}_j - \\mathbf{s}_i$ 关联，然后绘制 $d_{ij}$ 相对于 $\\|\\mathbf{h}_{ij}\\|$ 的图，并可选择通过方位角 $\\theta_{ij} = \\arg(\\mathbf{h}_{ij})$ 按方向进行分类。在某一特定场景中，该云图表现出以下特征：\n- 在短滞后距处，特别是对于某个 $r_0  0$ 使得 $\\|\\mathbf{h}_{ij}\\| \\le r_0$ 时，$d_{ij}$ 值的分布范围很广，极小值和极大值在相似的 $\\|\\mathbf{h}_{ij}\\|$ 处共存。\n- 大致呈东西向排列的像元对（即 $\\theta_{ij} \\approx 0^\\circ$ 或 $\\theta_{ij} \\approx \\pi$）比呈南北向排列的像元对（即 $\\theta_{ij} \\approx \\tfrac{\\pi}{2}$）具有系统性更大的 $d_{ij}$ 值。\n- 在所有滞后距上，一部分极大的 $d_{ij}$ 值反复涉及同一个像素索引 $k$，即对于许多 $j$，$d_{kj}$ 都很大。\n- 整个图像上 $Z(\\mathbf{s})$ 的边缘分布是双峰的，众数（峰值）在反射率 $0.1$ 和 $0.4$ 附近。\n\n从上述基本定义出发，且不假设任何特定的参数模型，选择所有正确描述如何使用变异函数云图来识别此场景中的非平稳性、异常值或多相结构，并提出适当的诊断方法以确认这些模式的陈述。\n\nA. 使用按方位角分层的变异函数云图来假设方向依赖性。对 $Z(\\mathbf{s})$ 拟合一个平滑趋势 $ \\hat{m}(\\mathbf{s}) $（例如，多项式或薄板样条），计算残差 $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$，并为 $R(\\mathbf{s})$ 重新计算变异函数云图。如果短滞后距处的楔形散布收缩且方向差异减小，则支持存在由均值趋势引起的非平稳性。通过计算移动窗口半变异函数 $\\hat{\\gamma}_W(\\mathbf{h}; \\mathbf{s})$，若其估计的块金值或基台值随 $\\mathbf{s}$ 变化，则可确认空间变化的结构。\n\nB. 使用变异函数云图标记潜在的异常值：即那些在多个配对像元 $j$ 和一定范围的 $\\|\\mathbf{h}_{kj}\\|$ 上产生异常大的 $d_{kj}$ 值的像素 $k$。通过计算 $Z(\\mathbf{s})$ 的稳健、抗影响的变异函数估计量（例如，克雷西-霍金斯估计量）以及评估 $k$ 的留一法普通克里金残差来确认；在多个邻域中出现大的学生化残差表明这是一个真实的异常值，而不仅仅是单个异常对。\n\nC. 将短滞后距处极小和极大 $d_{ij}$ 值的共存现象与双峰边缘分布一起解释为多相结构（例如，不同的土地覆盖相）的证据。通过对 $Z(\\mathbf{s})$ 进行无监督聚类获得的相标签对变异函数云图进行分层，并比较相内云图与相间云图；即使在小的 $\\|\\mathbf{h}_{ij}\\|$ 处，相间像元对持续存在大的 $d_{ij}$ 值也支持多相结构。通过计算二元相指示变量 $Y(\\mathbf{s}) = \\mathbf{1}\\{Z(\\mathbf{s}) \\ge \\tau\\}$ 的指示变异函数来确认，检验 $\\gamma_Y(\\mathbf{h})$ 是否与相内半变异函数有显著差异。\n\nD. 依赖于使用各向同性权重的全局莫兰指数I来检测各向异性：计算 $Z(\\mathbf{s})$ 的单个莫兰指数I，并在对 $Z(\\mathbf{s})$ 进行z-score标准化后，将 I 与零的任何偏离归因于方向各向异性；仅此一项就足以确认在云图中观察到的东西向模式。\n\nE. 仅从 $Z(\\mathbf{s})$ 的直方图诊断非平稳性：因为分布是双峰且具有重尾，所以该过程是非平稳的；通过将 $Z(\\mathbf{s})$ 全局标准化为零均值和单位方差，并观察到变异函数云图变得紧凑来确认。\n\nF. 计算所有像元对的 $d_{ij}$ 和 $\\|\\mathbf{h}_{ij}\\|$ 之间的相关性；如果它呈强正相关，则断定存在全局趋势而非多相结构，并且无需进一步的诊断。\n\n选择所有正确选项。",
            "solution": "问题陈述经过验证。\n\n### 步骤1：提取已知条件\n- **场**：一个近红外（NIR）反射率场 $Z(\\mathbf{s})$，定义在规则格网位置 $\\{\\mathbf{s}_i\\}_{i=1}^n \\subset \\mathbb{R}^2$ 上。\n- **随机模型**：假设 $Z(\\mathbf{s})$ 是一个随机场的实现。\n- **定义**：\n    -   二阶平稳性：要求均值 $m(\\mathbf{s}) \\equiv m$ 为常数，且协方差函数仅依赖于滞后向量 $\\mathbf{h}$。\n    -   半变异函数：$\\gamma(\\mathbf{h}) = \\tfrac{1}{2}\\,\\mathrm{Var}\\big(Z(\\mathbf{s}) - Z(\\mathbf{s}+\\mathbf{h})\\big)$。\n    -   变异函数云图：平方差 $d_{ij} = \\big(Z(\\mathbf{s}_i)-Z(\\mathbf{s}_j)\\big)^2$ 相对于滞后距离 $\\|\\mathbf{h}_{ij}\\|$ 的散点图，其中 $\\mathbf{h}_{ij} = \\mathbf{s}_j - \\mathbf{s}_i$。云图可以按方位角 $\\theta_{ij} = \\arg(\\mathbf{h}_{ij})$ 分类。\n- **从变异函数云图和数据中得到的观察结果**：\n    1.  在短滞后距处，即对于某个 $r_0  0$ 使得 $\\|\\mathbf{h}_{ij}\\| \\le r_0$ 时，$d_{ij}$ 值分布范围广，极小值和极大值共存。\n    2.  东西向排列的像元对（$\\theta_{ij} \\approx 0^\\circ$ 或 $\\theta_{ij} \\approx \\pi$）比南北向排列的像元对（$\\theta_{ij} \\approx \\tfrac{\\pi}{2}$）具有系统性更大的 $d_{ij}$ 值。\n    3.  一部分极大的 $d_{ij}$ 值反复涉及同一个像素索引 $k$。\n    4.  $Z(\\mathbf{s})$ 的边缘分布是双峰的，众数（峰值）在 $0.1$ 和 $0.4$ 附近。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题陈述具有科学依据、提法恰当且客观。它在遥感的有效科学背景下，使用了地统计学中的标准定义和概念，特别是变异函数分析。所提供的观察结果是现实的，并对应于空间数据分析中众所周知的现象：潜在的非平稳性、各向异性、异常值和多相结构。该问题没有违反任何基本原则，不是基于错误的假设，也不包含任何模糊不清或矛盾之处。这是一个结构良好的问题，要求基于所提供的证据评估适当的诊断方法。\n\n### 步骤3：结论与行动\n问题陈述是**有效**的。将提供完整的解答和选项评估。\n\n### 基于原理的推导与选项分析\n问题提出了四个不同的经验观察结果。正确的分析必须在地统计学理论的背景下解释这些观察结果，并提出有效的诊断程序。\n1.  **短滞后距处 $d_{ij}$ 的广泛分布**：这表明即使是位置相近的点也可能有非常不同的值。这可能是由不同数据总体之间的清晰边界（多相结构）或强烈的局部趋势引起的。\n2.  **$d_{ij}$ 的方向差异**：这是各向异性的定义。变异函数不仅是滞后距离 $\\|\\mathbf{h}\\|$ 的函数，也与滞后方向 $\\theta$ 有关。具体来说，南北向的空间连续性大于东西向。\n3.  **特定 $k$ 对应的大 $d_{kj}$ 值**：这是位置 $\\mathbf{s}_k$ 处异常值的经典特征。值 $Z(\\mathbf{s}_k)$ 是异常的，因此它与许多其他点 $Z(\\mathbf{s}_j)$ 的差值很大，而与滞后距无关。\n4.  **双峰边缘分布**：这强烈暗示数据中存在两个不同的子总体或相，例如，两种具有不同平均反射率值（$0.1$ 和 $0.4$）的土地覆盖类型。这一观察结果与观察结果1相关联。\n\n现在我们基于这些解释评估每个选项。\n\n**A. 使用按方位角分层的变异函数云图来假设方向依赖性。对 $Z(\\mathbf{s})$ 拟合一个平滑趋势 $ \\hat{m}(\\mathbf{s}) $（例如，多项式或薄板样条），计算残差 $R(\\mathbf{s}) = Z(\\mathbf{s}) - \\hat{m}(\\mathbf{s})$，并为 $R(\\mathbf{s})$ 重新计算变异函数云图。如果短滞后距处的楔形散布收缩且方向差异减小，则支持存在由均值趋势引起的非平稳性。通过计算移动窗口半变异函数 $\\hat{\\gamma}_W(\\mathbf{h}; \\mathbf{s})$，若其估计的块金值或基台值随 $\\mathbf{s}$ 变化，则可确认空间变化的结构。**\n\n该选项处理了均值非平稳性（趋势）及其与观察到的各向异性（观察2）和短滞后距离散（观察1）的潜在联系。大尺度趋势可能导致表观各向异性以及一个未能达到平稳的变异函数。所提出的诊断方法是地统计学实践的基石：对趋势进行建模，计算残差，并分析残差的变异函数，以判断是否更好地达到了平稳性。这是一个检验趋势假设的有效程序。使用移动窗口半变异函数的建议也是一种有效且强大的方法，用于诊断协方差结构中的非平稳性（二阶非平稳性），即局部空间结构本身在整个域内发生变化。该推理完全合理。\n**结论：正确**\n\n**B. 使用变异函数云图标记潜在的异常值：即那些在多个配对像元 $j$ 和一定范围的 $\\|\\mathbf{h}_{kj}\\|$ 上产生异常大的 $d_{kj}$ 值的像素 $k$。通过计算 $Z(\\mathbf{s})$ 的稳健、抗影响的变异函数估计量（例如，克雷西-霍金斯估计量）以及评估 $k$ 的留一法普通克里金残差来确认；在多个邻域中出现大的学生化残差表明这是一个真实的异常值，而不仅仅是单个异常对。**\n\n该选项直接针对观察结果3。从变异函数云图中的“十字形”或“星形”特征初步识别异常值是正确的。所提出的确认方法是标准且稳健的。经典的马特隆（Matheron）变异函数估计量由于平方项的存在而对异常值敏感。像克雷西-霍金斯估计量这样的稳健估计量被专门设计为对极端值不那么敏感，比较两者是诊断异常值的标准方法。留一交叉验证是另一种强大的工具，它通过将一个点的值与其基于邻居的克里金预测值进行比较，来识别与局部环境不一致的点。使用学生化残差是评估这些偏差统计显著性的正确方法。该选项描述了一种方法上无可挑剔的方法。\n**结论：正确**\n\n**C. 将短滞后距处极小和极大 $d_{ij}$ 值的共存现象与双峰边缘分布一起解释为多相结构（例如，不同的土地覆盖相）的证据。通过对 $Z(\\mathbf{s})$ 进行无监督聚类获得的相标签对变异函数云图进行分层，并比较相内云图与相间云图；即使在小的 $\\|\\mathbf{h}_{ij}\\|$ 处，相间像元对持续存在大的 $d_{ij}$ 值也支持多相结构。通过计算二元相指示变量 $Y(\\mathbf{s}) = \\mathbf{1}\\{Z(\\mathbf{s}) \\ge \\tau\\}$ 的指示变异函数来确认，检验 $\\gamma_Y(\\mathbf{h})$ 是否与相内半变异函数有显著差异。**\n\n该选项正确地将观察结果1（短滞后距离散）和观察结果4（双峰性）与多相结构的假设联系起来。同一相内的点对差异小，而跨越相边界的点对差异大，这解释了离散现象。所提出的分层分析的诊断方法是处理此类数据的正确方式。通过将像素分类到不同的相中（例如，通过在众数0.1和0.4附近进行聚类），然后计算独立的变异函数，可以验证这种结构。使用由众数之间的阈值 $\\tau$ 定义的指示变量 $Y(\\mathbf{s})$ 进行二次确认也是一种标准且强大的技术。指示变异函数 $\\gamma_Y(\\mathbf{h})$ 模拟了相本身的空间排列。该选项提出了一个分析多相系统的精妙且正确的方法。\n**结论：正确**\n\n**D. 依赖于使用各向同性权重的全局莫兰指数I来检测各向异性：计算 $Z(\\mathbf{s})$ 的单个莫兰指数I，并在对 $Z(\\mathbf{s})$ 进行z-score标准化后，将 I 与零的任何偏离归因于方向各向异性；仅此一项就足以确认在云图中观察到的东西向模式。**\n\n该选项不正确。全局莫兰指数I是全局空间自相关的度量，它将空间结构压缩为单个数字。如果用各向同性权重（例如，仅基于距离）计算，它根据定义对方向效应（各向异性）是不敏感的。一个显著的莫兰指数I表明存在空间自相关，但没有提供关于这种自相关在所有方向上是否相同的信息。要检测各向异性，必须使用方向变异函数（如问题陈述中所暗示的）或特定方向的统计量，而不是一个全局的各向同性统计量。将一个非零的 I 归因于各向异性，是对该统计量的根本误解。\n**结论：错误**\n\n**E. 仅从 $Z(\\mathbf{s})$ 的直方图诊断非平稳性：因为分布是双峰且具有重尾，所以该过程是非平稳的；通过将 $Z(\\mathbf{s})$ 全局标准化为零均值和单位方差，并观察到变异函数云图变得紧凑来确认。**\n\n该选项在两点上都是不正确的。首先，双峰边缘分布本身并不意味着非平稳性。一个平稳随机场可以有任意的边缘分布，包括双峰分布。这样的场可以被概念化为另外两个平稳场的平稳混合。其次，所提出的确认方法是无效的。将数据全局标准化为均值为0、方差为1是一种重新缩放数值的线性变换。它不会移除空间趋势，也不会解决多相结构。标准化后数据的变异函数云图在结构上将与原始云图相同，仅仅是在纵轴上按因子 $1/\\sigma_Z^2$ 进行了重新缩放。它不会“变得紧凑”。\n**结论：错误**\n\n**F. 计算所有像元对的 $d_{ij}$ 和 $\\|\\mathbf{h}_{ij}\\|$ 之间的相关性；如果它呈强正相关，则断定存在全局趋势而非多相结构，并且无需进一步的诊断。**\n\n该选项是一种过度简化，并且是不正确的。对于几乎*任何*具有空间自相关的过程，无论是平稳的还是非平稳的，平方差 $d_{ij}$ 和滞后距离 $\\|\\mathbf{h}_{ij}\\|$ 之间都预期存在正相关，因为差异的方差通常随着分离距离的增加而增加，直至达到变程。虽然无界增长可能暗示存在趋势，但简单的正相关不足以区分具有有限基台值的平稳过程和具有趋势的非平稳过程。最重要的是，“无需进一步的诊断”这一结论根本上是不科学的。它忽视了变异函数云图中关于各向异性、异常值和多相结构的丰富信息，而单个相关系数无法捕捉这些信息。\n**结论：错误**",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}