{
    "hands_on_practices": [
        {
            "introduction": "信息泄露是机器学习中一个微妙但关键的陷阱，尤其是在数据预处理阶段。本练习将通过一个动手模拟，展示训练集和验证集之间共享信息（例如用于标准化的均值和标准差）如何违反独立性假设。通过量化由此产生的性能指标（如 $\\mathrm{AUC}$）的乐观偏差，您将深刻理解为什么在建模流程的每个阶段都必须进行严格的数据分离。",
            "id": "3804423",
            "problem": "考虑一个遥感领域的二元分类任务，其中每个像素由一个源自辐射波段的多元特征向量表示，目标是从背景中检测出某个目标类别（例如，特定的土地覆盖类型）。您将研究信息泄露对留出验证性能的影响，重点关注受试者工作特征曲线下面积 (ROC AUC)。此处的泄露发生在验证像素与训练像素共享预处理参数（特征归一化统计量）时，这违反了训练集和验证集之间的独立性假设。\n\n从以下基本原理开始：\n\n- 受试者工作特征曲线下面积 (ROC AUC) 定义为随机选择的正类得分超过随机选择的负类得分的概率。形式上，如果 $S^{+}$ 和 $S^{-}$ 分别是正类和负类像素的随机分类器得分，那么 ROC AUC 为\n$$\\mathrm{AUC} = \\mathbb{P}\\left(S^{+} > S^{-}\\right) + \\frac{1}{2}\\mathbb{P}\\left(S^{+} = S^{-}\\right)。$$\n- 在留出策略中，以数据生成过程为条件，训练数据集和验证数据集必须在统计上是独立的。任何使用验证数据估算并随后在训练或评分过程中应用的预处理参数（例如用于归一化的均值和标准差）都会引入信息泄露，这可能会导致性能评估值出现上偏。\n\n您将模拟两个场景：一个训练场景和一个验证场景。像素由一个参数化高斯模型生成，该模型具有类条件均值和每个场景共享的协方差。设特征维度为 $d = 2$。对于类别标签 $Y \\in \\{0,1\\}$，定义训练场景中的原始特征分布为\n$$X \\mid (Y=1,\\ \\mathrm{train}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{1} + \\boldsymbol{b}_{\\mathrm{train}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{train}}\\right),\\quad X \\mid (Y=0,\\ \\mathrm{train}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{0} + \\boldsymbol{b}_{\\mathrm{train}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{train}}\\right),$$\n而在验证场景中为\n$$X \\mid (Y=1,\\ \\mathrm{val}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{1} + \\boldsymbol{b}_{\\mathrm{val}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{val}}\\right),\\quad X \\mid (Y=0,\\ \\mathrm{val}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{0} + \\boldsymbol{b}_{\\mathrm{val}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{val}}\\right)。$$\n这里 $\\boldsymbol{\\mu}_{1}, \\boldsymbol{\\mu}_{0} \\in \\mathbb{R}^{2}$ 是类别均值，$\\boldsymbol{b}_{\\mathrm{train}}, \\boldsymbol{b}_{\\mathrm{val}} \\in \\mathbb{R}^{2}$ 是场景特定的偏移量，$\\boldsymbol{\\Sigma}_{\\mathrm{train}}, \\boldsymbol{\\Sigma}_{\\mathrm{val}} \\in \\mathbb{R}^{2\\times 2}$ 是场景特定的协方差矩阵，其方差为单位值，相关系数分别为 $\\rho_{\\mathrm{train}}$ 和 $\\rho_{\\mathrm{val}}$。设训练集中各类别的流行率（正类像素的比例）为 $\\pi_{\\mathrm{train}}$，验证集中为 $\\pi_{\\mathrm{val}}$。\n\n预处理包括按特征进行 $z$-score 归一化 $Z = (X - \\boldsymbol{m}) \\oslash \\boldsymbol{s}$，其中 $\\oslash$ 表示逐元素除法，$\\boldsymbol{m}, \\boldsymbol{s} \\in \\mathbb{R}^{2}$ 是从参考池估算的均值和标准差向量。对比两种策略：\n- 无泄露：$\\boldsymbol{m}, \\boldsymbol{s}$ 仅使用训练像素估算，训练集和验证集都使用这些仅限训练集的参数进行归一化。\n- 泄露：$\\boldsymbol{m}, \\boldsymbol{s}$ 使用训练像素和验证像素的并集估算（共享参数），两个集合都使用这些共享参数进行归一化。\n\n分类器使用线性判别分析 (LDA) 在归一化后的训练数据上进行训练，并假设类别协方差相等。对于具有归一化特征向量 $\\boldsymbol{z}$ 的像素，LDA 评分函数为 $S(\\boldsymbol{z}) = \\boldsymbol{w}^{\\top}\\boldsymbol{z}$，其中\n$$\\boldsymbol{w} = \\boldsymbol{\\Sigma}_{\\text{pooled}}^{-1}\\left(\\boldsymbol{\\hat{\\mu}}_{1} - \\boldsymbol{\\hat{\\mu}}_{0}\\right),$$\n$\\boldsymbol{\\hat{\\mu}}_{1}, \\boldsymbol{\\hat{\\mu}}_{0}$ 是归一化训练集中的经验类别均值，$\\boldsymbol{\\Sigma}_{\\text{pooled}}$ 是从归一化训练集估算的池化协方差矩阵。由于 ROC AUC 仅取决于分数的排序，因此可以省略截距。\n\n对于每组参数，使用 $R$ 次独立重复实验进行蒙特卡洛模拟。在每次重复中，根据模型生成 $n_{\\mathrm{train}}$ 个训练像素和 $n_{\\mathrm{val}}$ 个验证像素，在两种策略下应用预处理，在训练数据上训练 LDA，在验证数据上计算 ROC AUC，并记录泄露 AUC 和无泄露 AUC 之间的差异。期望的上偏是这些差异在 $R$ 次重复实验中的经验均值。\n\n您的任务是实现一个程序，对于以下测试套件，输出每种情况下 ROC AUC 的期望上偏：\n\n- 情况 1（中等域偏移，理想路径）：$d=2$，$\\boldsymbol{\\mu}_{1} = [0.5, 0.5]$，$\\boldsymbol{\\mu}_{0} = [-0.5, -0.5]$，$\\rho_{\\mathrm{train}} = 0.3$，$\\rho_{\\mathrm{val}} = 0.3$，$\\boldsymbol{b}_{\\mathrm{train}} = [0.0, 0.0]$，$\\boldsymbol{b}_{\\mathrm{val}} = [1.0, 1.0]$，$\\pi_{\\mathrm{train}} = 0.5$，$\\pi_{\\mathrm{val}} = 0.5$，$n_{\\mathrm{train}} = 600$，$n_{\\mathrm{val}} = 600$，$R = 200$。\n- 情况 2（无域偏移，边界条件）：与情况 1 相同，但 $\\boldsymbol{b}_{\\mathrm{val}} = [0.0, 0.0]$ 且 $\\rho_{\\mathrm{val}} = 0.3$。预计偏差接近 $0$。\n- 情况 3（协方差偏移边缘情况）：与情况 1 相同，但 $\\rho_{\\mathrm{train}} = 0.0$，$\\rho_{\\mathrm{val}} = 0.8$，$n_{\\mathrm{train}} = 400$，$n_{\\mathrm{val}} = 400$，$R = 200$。\n- 情况 4（流行率偏移边缘情况）：与情况 1 相同，但 $\\pi_{\\mathrm{train}} = 0.3$，$\\pi_{\\mathrm{val}} = 0.7$，$n_{\\mathrm{train}} = 600$，$n_{\\mathrm{val}} = 600$，$R = 200$。\n\n所有随机抽样必须使用固定种子以保证可复现性。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_{1},r_{2},r_{3},r_{4}]$）。每个 $r_{i}$ 必须是一个浮点数，表示相应情况下期望的上偏（泄露 AUC 减去无泄露 AUC），并精确到六位小数。此问题不涉及任何物理单位或角度，任何比例或流行率都必须表示为小数。\n\n您的实现必须：\n- 构建 $\\boldsymbol{\\Sigma}_{\\mathrm{train}}$ 和 $\\boldsymbol{\\Sigma}_{\\mathrm{val}}$ 作为 $2\\times 2$ 的协方差矩阵，其方差为单位值，相关系数为指定的 $\\rho$：\n$$\\boldsymbol{\\Sigma}(\\rho) = \\begin{bmatrix}1  \\rho \\\\ \\rho  1\\end{bmatrix}.$$\n- 通过减去经验均值 $\\boldsymbol{m}$ 并除以在指定参考池上计算的经验标准差 $\\boldsymbol{s}$ 来执行按特征归一化，并在 $\\boldsymbol{s}$ 的每个分量上添加一个小的稳定常数以避免除以零。\n- 使用仅从训练数据估算的池化协方差，在归一化后的训练数据上训练线性判别分析 (LDA)。\n- 根据其定义 $\\mathrm{AUC} = \\mathbb{P}\\left(S^{+} > S^{-}\\right) + \\frac{1}{2}\\mathbb{P}\\left(S^{+} = S^{-}\\right)$，通过在排序后的负类分数上进行高效搜索来计数比较，从而在归一化的验证数据上计算 ROC AUC。\n\n您的最终输出必须是单行，格式严格为 $[r_{1},r_{2},r_{3},r_{4}]$，每个 $r_{i}$ 精确到六位小数。",
            "solution": "该问题要求分析一个二元分类任务中留出验证方案的信息泄露，这是一个遥感领域的常见场景。我们需要量化当特征归一化统计量从一个同时包含训练样本和验证样本的数据池中计算时，在 ROC 曲线下面积 (AUC) 中产生的乐观偏差。这种做法违反了用于模型训练和模型评估的数据集之间的独立性原则。该分析将通过蒙特卡洛模拟进行。\n\n总体方法步骤如下：\n1. 对于四个指定的情况中的每一个，我们将执行 $R$ 次独立的模拟重复实验。\n2. 在每次重复实验中，我们生成一个大小为 $n_{\\mathrm{train}}$ 的训练数据集和一个大小为 $n_{\\mathrm{val}}$ 的验证数据集。数据点从类条件多元高斯分布中抽取，参数根据每个场景（训练和验证）的指定进行设置。\n3. 然后我们模拟两种不同的验证工作流程：\n    a. **无泄露工作流程**：特征归一化参数（均值 $\\boldsymbol{m}$ 和标准差 $\\boldsymbol{s}$）仅从训练数据中估算。然后使用这些参数对训练数据和验证数据进行归一化。\n    b. **泄露工作流程**：归一化参数从所有训练数据和验证数据的组合集中估算。然后使用这些共享参数对两个数据集进行归一化。\n4. 对于每个工作流程，在线性判别分析 (LDA) 分类器各自的归一化训练数据上进行训练。\n5. 然后将训练好的分类器应用于相应的归一化验证数据以获得分类分数。通过计算 ROC AUC 来量化性能。\n6. 单次重复实验的偏差是差值：$\\mathrm{AUC}_{\\text{leakage}} - \\mathrm{AUC}_{\\text{no-leakage}}$。\n7. 每个情况的最终结果是期望的上偏，通过对所有 $R$ 次重复实验中的这些差异求平均值来估算。\n\n让我们将关键计算步骤形式化。\n\n**1. 数据生成**\n对于给定的场景（训练或验证），我们生成 $n$ 个样本。正类样本（类别 $Y=1$）的数量为 $n_1 = \\text{round}(n \\cdot \\pi)$，负类样本（类别 $Y=0$）的数量为 $n_0 = n - n_1$。\n每个类别的特征向量从一个 $d=2$ 维的正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ 中抽取。\n- 正类特征：$X_1 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1 + \\boldsymbol{b}, \\boldsymbol{\\Sigma})$\n- 负类特征：$X_0 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0 + \\boldsymbol{b}, \\boldsymbol{\\Sigma})$\n协方差矩阵 $\\boldsymbol{\\Sigma}$ 基于指定的相关系数 $\\rho$ 构建如下：\n$$\n\\boldsymbol{\\Sigma}(\\rho) = \\begin{bmatrix} 1  \\rho \\\\ \\rho  1 \\end{bmatrix}\n$$\n此生成过程对训练集和验证集独立执行，使用它们各自的参数（$\\boldsymbol{b}_{\\mathrm{train}}, \\boldsymbol{\\Sigma}_{\\mathrm{train}}, n_{\\mathrm{train}}, \\pi_{\\mathrm{train}}$ 和 $\\boldsymbol{b}_{\\mathrm{val}}, \\boldsymbol{\\Sigma}_{\\mathrm{val}}, n_{\\mathrm{val}}, \\pi_{\\mathrm{val}}$）。\n\n**2. 特征归一化**\n给定一组原始特征向量 $X$ 和一个参考向量池 $X_{\\text{ref}}$，我们应用按特征的 z-score 归一化。均值向量 $\\boldsymbol{m}$ 和标准差向量 $\\boldsymbol{s}$ 从 $X_{\\text{ref}}$ 计算得出：\n$$\n\\boldsymbol{m} = \\mathbb{E}[X_{\\text{ref}}] \\quad \\quad \\boldsymbol{s} = \\sqrt{\\mathrm{Var}(X_{\\text{ref}})}\n$$\n对于来自 $X$ 的任何样本 $\\boldsymbol{x}$，其归一化特征 $\\boldsymbol{z}$ 为：\n$$\n\\boldsymbol{z} = (\\boldsymbol{x} - \\boldsymbol{m}) \\oslash (\\boldsymbol{s} + \\epsilon)\n$$\n其中 $\\oslash$ 表示逐元素除法，$\\epsilon$ 是一个很小的常数（例如 $10^{-8}$）以防止除以零。\n- 在**无泄露**情况下，$X_{\\text{ref}} = X_{\\mathrm{train}}$。\n- 在**泄露**情况下，$X_{\\text{ref}} = X_{\\mathrm{train}} \\cup X_{\\mathrm{val}}$。\n\n**3. 线性判别分析 (LDA) 训练**\nLDA 分类器学习一个投影向量 $\\boldsymbol{w}$，该向量最大化类别之间的可分性。给定归一化的训练数据 $Z_{\\mathrm{train}}$ 和相应的标签 $y_{\\mathrm{train}}$，我们计算 $\\boldsymbol{w}$ 如下：\n$$\n\\boldsymbol{w} = \\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}}^{-1} (\\boldsymbol{\\hat{\\mu}}_1 - \\boldsymbol{\\hat{\\mu}}_0)\n$$\n这里，$\\boldsymbol{\\hat{\\mu}}_1$ 和 $\\boldsymbol{\\hat{\\mu}}_0$ 分别是训练集中归一化正负样本的经验均值。池化协方差矩阵 $\\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}}$ 是各个类别协方差矩阵的加权平均：\n$$\n\\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}} = \\frac{(n_1 - 1)\\boldsymbol{\\hat{\\Sigma}}_1 + (n_0 - 1)\\boldsymbol{\\hat{\\Sigma}}_0}{n_1 + n_0 - 2}\n$$\n其中 $n_1, n_0$ 是训练集中正负样本的数量，$\\boldsymbol{\\hat{\\Sigma}}_1, \\boldsymbol{\\hat{\\Sigma}}_0$ 是它们各自的样本协方差矩阵。\n\n**4. ROC AUC 计算**\n归一化样本 $\\boldsymbol{z}$ 的分类分数为 $S(\\boldsymbol{z}) = \\boldsymbol{w}^{\\top}\\boldsymbol{z}$。为了在验证集上计算 AUC，我们首先将分数分为来自正样本的分数 $\\{S_i^+\\}$ 和来自负样本的分数 $\\{S_j^-\\}$。AUC 通过其概率定义进行估算：\n$$\n\\mathrm{AUC} = \\frac{1}{N^+ N^-} \\left( \\sum_{i=1}^{N^+} \\sum_{j=1}^{N^-} \\mathbb{I}(S_i^+ > S_j^-) + \\frac{1}{2} \\sum_{i=1}^{N^+} \\sum_{j=1}^{N^-} \\mathbb{I}(S_i^+ = S_j^-) \\right)\n$$\n其中 $N^+$ 和 $N^-$ 是验证集中正负样本的数量，$\\mathbb{I}(\\cdot)$ 是指示函数。计算此和的一种高效方法是，对负样本分数 $\\{S_j^-\\}$进行排序，然后对于每个正样本分数 $S_i^+$，使用二分查找来计算小于或等于它的负样本分数的数量。\n\n模拟将使用 Python 中的 `NumPy` 库实现所有数值计算。固定的随机种子将确保结果的可复现性。最终输出是四个指定实验条件下每个情况的平均偏差，四舍五入到六位小数。在情况 2 中，由于训练和验证数据之间没有域偏移，预期的偏差应接近 $0$，这为实现提供了一个健全性检查。对于存在域偏移（均值、协方差或流行率）的其他情况，验证数据统计信息的泄露到训练流程中预计会人为地减少表观的域偏移，从而导致正偏差，即 $\\mathrm{AUC}_{\\text{leakage}} > \\mathrm{AUC}_{\\text{no-leakage}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # A fixed seed ensures that the random sampling is reproducible.\n    np.random.seed(42)\n\n    # Define the parameter sets for the four test cases.\n    # Each tuple contains: (mu1, mu0, rho_train, rho_val, b_train, b_val, \n    #                       pi_train, pi_val, n_train, n_val, R)\n    test_cases = [\n        # Case 1 (moderate domain shift, happy path)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.5, 0.5, 600, 600, 200),\n        # Case 2 (no domain shift, boundary condition)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([0.0, 0.0]), 0.5, 0.5, 600, 600, 200),\n        # Case 3 (covariance shift edge case)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.0, 0.8, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.5, 0.5, 400, 400, 200),\n        # Case 4 (prevalence shift edge case)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.3, 0.7, 600, 600, 200),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        expected_bias = run_simulation(*case_params)\n        results.append(expected_bias)\n\n    # Format the final output string as specified.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef generate_data(n, pi, mu1, mu0, b, rho):\n    \"\"\"\n    Generates feature data and labels from a 2D Gaussian mixture model.\n    \"\"\"\n    n_pos = int(round(n * pi))\n    n_neg = n - n_pos\n\n    mean_pos = mu1 + b\n    mean_neg = mu0 + b\n    \n    cov_matrix = np.array([[1, rho], [rho, 1]])\n\n    X_pos = np.random.multivariate_normal(mean_pos, cov_matrix, n_pos)\n    X_neg = np.random.multivariate_normal(mean_neg, cov_matrix, n_neg)\n    \n    if n_pos > 0 and n_neg > 0:\n        X = np.vstack((X_pos, X_neg))\n        y = np.hstack((np.ones(n_pos), np.zeros(n_neg)))\n        # Shuffle to mix positive and negative samples\n        perm = np.random.permutation(n)\n        X, y = X[perm], y[perm]\n    elif n_pos > 0:\n        X, y = X_pos, np.ones(n_pos)\n    else: # n_neg > 0\n        X, y = X_neg, np.zeros(n_neg)\n\n    return X, y\n\ndef train_lda(Z_train, y_train):\n    \"\"\"\n    Trains a Linear Discriminant Analysis classifier.\n    \"\"\"\n    Z1 = Z_train[y_train == 1]\n    Z0 = Z_train[y_train == 0]\n\n    n1, n0 = Z1.shape[0], Z0.shape[0]\n\n    if n1  2 or n0  2:\n        # Handle degenerate cases, though unlikely with problem parameters\n        return np.zeros(Z_train.shape[1])\n\n    mu1_hat = np.mean(Z1, axis=0)\n    mu0_hat = np.mean(Z0, axis=0)\n    \n    S1 = np.cov(Z1, rowvar=False, ddof=1)\n    S0 = np.cov(Z0, rowvar=False, ddof=1)\n    \n    # an edge case can cause S1 or S0 to be a scalar 0.0 if there is one sample\n    if S1.ndim == 0: S1 = np.zeros((Z_train.shape[1], Z_train.shape[1]))\n    if S0.ndim == 0: S0 = np.zeros((Z_train.shape[1], Z_train.shape[1]))\n    \n    Sigma_pooled = ((n1 - 1) * S1 + (n0 - 1) * S0) / (n1 + n0 - 2)\n    \n    try:\n        Sigma_pooled_inv = np.linalg.inv(Sigma_pooled)\n    except np.linalg.LinAlgError:\n         Sigma_pooled_inv = np.linalg.pinv(Sigma_pooled)\n\n    w = Sigma_pooled_inv @ (mu1_hat - mu0_hat)\n    return w\n\ndef calculate_auc(scores, y_val):\n    \"\"\"\n    Calculates the ROC AUC from scores and true labels.\n    \"\"\"\n    scores_pos = scores[y_val == 1]\n    scores_neg = scores[y_val == 0]\n    \n    n_pos = len(scores_pos)\n    n_neg = len(scores_neg)\n\n    if n_pos == 0 or n_neg == 0:\n        return 0.5  # Convention for undefined AUC\n\n    # Sort negative scores for efficient comparison\n    scores_neg_sorted = np.sort(scores_neg)\n    \n    # Use searchsorted for vectorized counting of pairs\n    # Number of S_neg  S_pos\n    num_greater = np.sum(np.searchsorted(scores_neg_sorted, scores_pos, side='left'))\n    # Number of S_neg == S_pos\n    num_equal = np.sum(np.searchsorted(scores_neg_sorted, scores_pos, side='right') - \n                       np.searchsorted(scores_neg_sorted, scores_pos, side='left'))\n\n    auc = (num_greater + 0.5 * num_equal) / (n_pos * n_neg)\n    return auc\n\ndef run_simulation(mu1, mu0, rho_train, rho_val, b_train, b_val, \n                   pi_train, pi_val, n_train, n_val, R):\n    \"\"\"\n    Runs one full Monte Carlo simulation for a given set of parameters.\n    \"\"\"\n    auc_diffs = []\n    STABILIZATION_CONST = 1e-8\n    \n    for _ in range(R):\n        # 1. Generate data\n        X_train, y_train = generate_data(n_train, pi_train, mu1, mu0, b_train, rho_train)\n        X_val, y_val = generate_data(n_val, pi_val, mu1, mu0, b_val, rho_val)\n\n        # --- No-leakage workflow ---\n        # 2a. Normalize using training set stats\n        m_train = np.mean(X_train, axis=0)\n        s_train = np.std(X_train, axis=0) + STABILIZATION_CONST\n        Z_train_nl = (X_train - m_train) / s_train\n        Z_val_nl = (X_val - m_train) / s_train\n\n        # 3a. Train LDA on no-leakage normalized data\n        w_nl = train_lda(Z_train_nl, y_train)\n\n        # 4a. Evaluate on no-leakage validation data\n        scores_nl = Z_val_nl @ w_nl\n        auc_nl = calculate_auc(scores_nl, y_val)\n\n        # --- Leakage workflow ---\n        X_all = np.vstack((X_train, X_val))\n        \n        # 2b. Normalize using combined set stats\n        m_all = np.mean(X_all, axis=0)\n        s_all = np.std(X_all, axis=0) + STABILIZATION_CONST\n        Z_train_l = (X_train - m_all) / s_all\n        Z_val_l = (X_val - m_all) / s_all\n\n        # 3b. Train LDA on leakage normalized data\n        w_l = train_lda(Z_train_l, y_train)\n        \n        # 4b. Evaluate on leakage validation data\n        scores_l = Z_val_l @ w_l\n        auc_l = calculate_auc(scores_l, y_val)\n\n        # 5. Record the difference\n        auc_diffs.append(auc_l - auc_nl)\n\n    # 6. Return the expected bias (mean of differences)\n    return np.mean(auc_diffs)\n\nsolve()\n```"
        },
        {
            "introduction": "由于空间自相关，标准交叉验证在处理空间数据时常常失效，这在遥感应用中是一个常见问题。本练习将地统计学中的半变异函数“变程”（即数据点变得大致独立的距离）这一概念，与交叉验证策略的实际设计联系起来。通过推导出一个确定空间区块大小的经验法则，您将学会如何利用数据内在的空间结构来构建更可靠的模型评估框架，从而避免对模型性能作出过于乐观的估计。",
            "id": "3804424",
            "problem": "一个遥感团队正在使用一个定义在 $\\mathbb{R}^{2}$ 上的二阶平稳且各向同性的高斯随机场 $Z(\\mathbf{s})$ 来模拟一个空间分布的环境变量。该随机场具有半变异函数 $\\gamma(h)$、协方差函数 $C(h)$ 和相关函数 $\\rho(h) = C(h)/C(0)$。回想一下恒等式 $\\gamma(h) = C(0) - C(h)$ 对所有 $h \\geq 0$ 成立。该团队用经验基台值 $\\hat{C}(0)$ 估计了经验半变异函数 $\\hat{\\gamma}(h)$，并在容差水平 $\\delta \\in (0,1)$ 下，通过条件 $\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\,\\hat{C}(0)$ 定义了经验有效程长 $\\hat{r}$。\n\n他们计划使用空间分块交叉验证进行模型评估：将研究区域剖分为边长为 $b$ 的不重叠方形块，在每一折中，他们选择一个验证块，并移除该验证块周围宽度为 $b$ 的缓冲区内的所有训练点。在这种设计下，任何验证点与任何保留的训练点之间的最小欧几里得距离至少为 $b$。如果任何验证点与任何保留的训练点之间的最大绝对相关性以 $\\delta$ 为界，则该团队将称训练和验证“近似独立”。\n\n请仅使用上述核心定义以及各向同性二阶平稳场的半变异函数的单调性，推导出一个关于最小块大小 $b^{\\star}$ 的经验法则。该法则需表示为 $\\hat{r}$ 和 $\\delta$ 的闭式函数，并能保证在所述的带缓冲区的分块留出方案下满足近似独立性准则。您的最终答案必须是 $b^{\\star}$ 的单个解析表达式。不需要进行数值四舍五入。",
            "solution": "目标是找到满足“近似独立”准则的最小块大小 $b^{\\star}$。让我们将此准则形式化，并将其与给定定义联系起来。\n\n近似独立准则指出，任何验证点与任何保留的训练点之间的最大绝对相关性最多为 $\\delta$。设 $\\mathbf{s}_v$ 为任意验证点的位置，$\\mathbf{s}_t$ 为任意保留的训练点的位置。它们之间的欧几里得距离为 $h = \\|\\mathbf{s}_v - \\mathbf{s}_t\\|$。在这两个位置上随机场值之间的相关性由相关函数 $\\rho(h)$ 给出。该准则可写为：\n$$\n\\max_{\\mathbf{s}_v, \\mathbf{s}_t} |\\rho(h)| \\le \\delta\n$$\n其中，最大值是在所有可能的验证点 $\\mathbf{s}_v$ 和保留的训练点 $\\mathbf{s}_t$ 对上取。\n\n根据问题描述，带缓冲区的分块留出方案确保了任何此类点对之间的最小距离为 $b$。也就是说，对于任何允许的点对 $(\\mathbf{s}_v, \\mathbf{s}_t)$，它们的距离 $h$ 满足 $h \\ge b$。\n\n对于二阶平稳且各向同性的随机场，半变异函数 $\\gamma(h)$ 是滞后距离 $h \\ge 0$ 的非递减函数。相关函数 $\\rho(h)$ 和半变异函数 $\\gamma(h)$ 之间的关系可以从给定的恒等式 $\\gamma(h) = C(0) - C(h)$ 和定义 $\\rho(h) = C(h)/C(0)$ 推导出来：\n$$\n\\rho(h) = \\frac{C(0) - \\gamma(h)}{C(0)} = 1 - \\frac{\\gamma(h)}{C(0)}\n$$\n由于 $\\gamma(h)$ 是 $h$ 的非递减函数，因此 $\\rho(h)$ 是 $h$ 的非递增函数。对于大多数标准的半变异函数模型，基台值 $C(0)$ 表示最大半方差，所以 $\\gamma(h) \\le C(0)$，这意味着 $\\rho(h) \\ge 0$。在这种情况下，$|\\rho(h)| = \\rho(h)$。$\\rho(h)$ 的非递增性意味着，对于所有距离 $h \\ge b$，$\\rho(h)$ 的最大值将出现在可能的最小距离处，即 $h=b$。\n\n因此，条件 $\\max_{h \\ge b} |\\rho(h)| \\le \\delta$ 简化为确保在距离 $b$ 处的相关性满足界限：\n$$\n|\\rho(b)| \\le \\delta\n$$\n按照标准假设 $\\rho(h) \\ge 0$，该式变为：\n$$\n\\rho(b) \\le \\delta\n$$\n我们现在将 $\\rho(b)$ 用半变异函数表示的表达式代入。问题是根据经验估计值提出的，所以我们将使用 $\\hat{\\gamma}(h)$ 和 $\\hat{C}(0)$。\n$$\n1 - \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)} \\le \\delta\n$$\n重排这个不等式以求解关于 $\\hat{\\gamma}(b)$ 的条件：\n$$\n1 - \\delta \\le \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)}\n$$\n$$\n(1 - \\delta)\\hat{C}(0) \\le \\hat{\\gamma}(b)\n$$\n这是块大小 $b$ 必须满足以确保近似独立的条件。\n\n问题中提供了经验有效程长 $\\hat{r}$ 的定义，即经验半变异函数达到基台值特定比例时的距离：\n$$\n\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\hat{C}(0)\n$$\n将这个定义代入我们的不等式，得到：\n$$\n\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)\n$$\n问题明确允许使用半变异函数的单调性。由于 $\\hat{\\gamma}(h)$ 是 $h$ 的非递减函数，不等式 $\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)$ 直接意味着其自变量之间的关系：\n$$\n\\hat{r} \\le b\n$$\n这表明，为了满足近似独立准则，块边长 $b$ 必须至少与经验有效程长 $\\hat{r}$（在容差 $\\delta$ 下定义）一样大。问题要求的是保证该条件的最小块大小 $b^{\\star}$。这个最小值是：\n$$\nb^{\\star} = \\hat{r}\n$$\n这个结果是 $\\hat{r}$ 的函数，而 $\\hat{r}$ 本身通过其定义隐式地是 $\\delta$ 的函数。这就是所要求的闭式表达式。",
            "answer": "$$\n\\boxed{\\hat{r}}\n$$"
        },
        {
            "introduction": "$K$-折交叉验证会为每一折都生成一个性能分数，简单地取平均值只能得到一个点估计，无法体现模型性能的稳定性和不确定性。本练习将应用经典的统计学理论，特别是学生$t$-分布，来处理这些逐折的误差指标。通过学习为模型的真实平均性能构建置信区间，您将能超越单一的性能数值，对模型的可靠性进行更完整、更严谨的评估。",
            "id": "3804427",
            "problem": "一个遥感团队正在使用一个通过$K$-折交叉验证评估的回归模型，根据多光谱卫星反射率对叶面积指数 (LAI) 进行建模。在每一折 $k \\in \\{1,\\dots,K\\}$ 中，模型在其余的 $K-1$ 折上进行训练，并在留出的第 $k$ 折上进行评估，从而产生一个特定于该折的均方根误差 (RMSE)，记为 $e_{k}$。第 $k$ 折上的 RMSE 定义为 $e_{k} = \\sqrt{\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}} r_{k,i}^{2}}$，其中 $r_{k,i}$ 是第 $k$ 折中测试观测值 $i$ 的预测残差，$n_{k}$ 是第 $k$ 折中测试观测值的数量。假设每折的 RMSE 值 $\\{e_{k}\\}_{k=1}^{K}$ 是来自一个具有有限方差的未知分布的实现，并且各折的设计使得 $e_{k}$ 近似独立同分布。\n\n从 $\\{e_{k}\\}_{k=1}^{K}$ 的样本均值和样本方差的定义出发，并利用当总体方差未知并从样本中估计时会产生学生t分布这一事实，推导交叉验证平均 RMSE 的 $0.95$ 置信区间。明确展示具有 $K-1$ 自由度的 $t$-分布如何被引入推导过程，并陈述该区间有效的假设条件，特别关注在空间结构化的遥感背景下各折的独立性。\n\n然后，对于 $K = 5$ 和以下各折的 RMSE 值，计算该区间（LAI 是无量纲的，因此请用不带单位的小数表示你的答案）：$e_{1} = 0.82$, $e_{2} = 0.79$, $e_{3} = 0.85$, $e_{4} = 0.88$, $e_{5} = 0.81$。使用双侧 $t$-临界值 $t_{0.975,4} = 2.776$。将最终区间端点四舍五入到四位有效数字。",
            "solution": "目标是基于 $K$ 个分折 RMSE 值样本 $\\{e_k\\}_{k=1}^{K}$，推导并计算交叉验证均方根误差 (RMSE) 真均值 $\\mu_e$ 的 $0.95$ 置信区间。\n\n首先，我们推导置信区间的一般公式。设 $\\{e_1, e_2, \\dots, e_K\\}$ 是代表各折 RMSE 值的 $K$ 个独立同分布 (i.i.d.) 随机变量的样本，这些变量来自一个均值为 $\\mu_e$、方差为 $\\sigma_e^2$ 的分布。\n\n样本均值 $\\bar{e}$ 是 $\\mu_e$ 的点估计量：\n$$\n\\bar{e} = \\frac{1}{K} \\sum_{k=1}^{K} e_k\n$$\n由于总体方差 $\\sigma_e^2$ 未知，我们必须从样本中估计它。总体方差的无偏估计量是样本方差 $s_e^2$：\n$$\ns_e^2 = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\bar{e})^2\n$$\n样本标准差为 $s_e = \\sqrt{s_e^2}$。\n\n均值标准误差 (SEM)，即 $\\bar{e}$ 的抽样分布的标准差，由 $s_{\\bar{e}}$ 估计：\n$$\ns_{\\bar{e}} = \\frac{s_e}{\\sqrt{K}}\n$$\n当总体方差未知，并从一个大小为 $K$、来自正态分布的样本中估计时，标准化检验统计量\n$$\nT = \\frac{\\bar{e} - \\mu_e}{s_{\\bar{e}}} = \\frac{\\bar{e} - \\mu_e}{s_e / \\sqrt{K}}\n$$\n服从自由度为 $\\nu = K-1$ 的学生t分布。这是将 $t$-分布引入推导过程的关键步骤。\n\n为了构建一个 $1-\\alpha$ 置信区间，我们从 $t$-分布中找到临界值 $\\pm t_{\\alpha/2, K-1}$，它们界定了分布中心 $1-\\alpha$ 的面积。其概率表述为：\n$$\nP\\left(-t_{\\alpha/2, K-1} \\le \\frac{\\bar{e} - \\mu_e}{s_e / \\sqrt{K}} \\le t_{\\alpha/2, K-1}\\right) = 1-\\alpha\n$$\n我们重新整理不等式以分离出总体均值 $\\mu_e$：\n$$\n-t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le \\bar{e} - \\mu_e \\le t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\n$$\n-\\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le -\\mu_e \\le -\\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\n乘以 $-1$ 会反转不等号：\n$$\n\\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le \\mu_e \\le \\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\n因此，$\\mu_e$ 的 $1-\\alpha$ 置信区间由下式给出：\n$$\n\\left[ \\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}, \\quad \\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\right]\n$$\n这可以紧凑地写为 $\\bar{e} \\pm t_{\\alpha/2, K-1} \\cdot s_{\\bar{e}}$。\n\n该区间的有效性依赖于几个关键假设：\n1.  **正态性**：推导假设从中抽取样本的各折 RMSE 总体 $\\{e_k\\}$ 服从正态分布。对于像 $K=5$ 这样的小样本量，这个假设很重要。已知 $t$-分布对于中度偏离正态性的情况具有稳健性，但如果 $e_k$ 的分布存在强偏度或重尾，则会影响置信水平的准确性。对于更大的 $K$，中心极限定理将确保 $\\bar{e}$ 的抽样分布近似正态，即使 $e_k$ 的基础分布不是正态的。\n2.  **独立性**：推导假设各折的误差 $e_k$ 是独立的。在涉及空间结构化数据的遥感背景下，由于空间自相关，这个假设常常被违反。如果数据点在地理上相近，它们的预测残差可能相关。如果创建折时没有考虑这种空间结构（例如，对像素进行简单随机抽样），那么某一折的测试集可能包含与另一折的训练集中空间上相近的点，这可能导致过于乐观（即更窄）的误差估计。问题陈述“各折的设计使得 $e_{k}$ 近似独立”，这暗示使用了诸如空间分块或缓冲交叉验证之类的方法。这类方法从空间上连续的数据块创建折，确保在任何给定的折迭代中，训练集和测试集在空间上是分离的，从而减少了折之间的依赖性，并使得得到的 $e_k$ 值更加独立。\n3.  **同分布性**：假设 $e_k$ 值是同分布的，意味着每一折都是对整体数据景观的同等代表性样本。这通常通过对目标变量（LAI）或地理分层进行分层抽样来实现，以确保每一折都具有相似的环境条件分布。\n\n现在，我们为给定数据计算 $0.95$ 置信区间。\n折数为 $K=5$。各折的 RMSE 值为 $\\{e_k\\} = \\{0.82, 0.79, 0.85, 0.88, 0.81\\}$。\n\n1.  计算样本均值 $\\bar{e}$：\n    $$\n    \\bar{e} = \\frac{1}{5} (0.82 + 0.79 + 0.85 + 0.88 + 0.81) = \\frac{4.15}{5} = 0.83\n    $$\n\n2.  计算样本方差 $s_e^2$：\n    $$\n    \\sum_{k=1}^{5} (e_k - \\bar{e})^2 = (0.82-0.83)^2 + (0.79-0.83)^2 + (0.85-0.83)^2 + (0.88-0.83)^2 + (0.81-0.83)^2\n    $$\n    $$\n    = (-0.01)^2 + (-0.04)^2 + (0.02)^2 + (0.05)^2 + (-0.02)^2\n    $$\n    $$\n    = 0.0001 + 0.0016 + 0.0004 + 0.0025 + 0.0004 = 0.0050\n    $$\n    $$\n    s_e^2 = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\bar{e})^2 = \\frac{0.0050}{5-1} = \\frac{0.0050}{4} = 0.00125\n    $$\n\n3.  计算样本标准差 $s_e$：\n    $$\n    s_e = \\sqrt{0.00125}\n    $$\n\n4.  计算估计的均值标准误差 $s_{\\bar{e}}$：\n    $$\n    s_{\\bar{e}} = \\frac{s_e}{\\sqrt{K}} = \\frac{\\sqrt{0.00125}}{\\sqrt{5}} = \\sqrt{\\frac{0.00125}{5}} = \\sqrt{0.00025}\n    $$\n    $$\n    s_{\\bar{e}} \\approx 0.015811388...\n    $$\n\n5.  确定临界值。对于 $0.95$ 的置信区间，$\\alpha = 0.05$，因此我们需要对应于双尾概率 $\\alpha/2 = 0.025$ 的临界值。自由度为 $\\nu = K-1 = 4$。问题给出的该值为 $t_{0.975,4} = 2.776$。\n\n6.  计算误差范围 (ME)：\n    $$\n    \\text{ME} = t_{\\alpha/2, K-1} \\cdot s_{\\bar{e}} = 2.776 \\times \\sqrt{0.00025} \\approx 2.776 \\times 0.015811388... \\approx 0.04389439\n    $$\n\n7.  构建置信区间，$\\bar{e} \\pm \\text{ME}$：\n    *   下限：$0.83 - 0.04389439 = 0.78610561$\n    *   上限：$0.83 + 0.04389439 = 0.87389439$\n\n最后，我们按要求将区间端点四舍五入到四位有效数字。\n*   下限四舍五入后：$0.7861$\n*   上限四舍五入后：$0.8739$\n\n交叉验证平均 RMSE 的 $0.95$ 置信区间为 $[0.7861, 0.8739]$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.7861  0.8739 \\end{pmatrix}}\n$$"
        }
    ]
}