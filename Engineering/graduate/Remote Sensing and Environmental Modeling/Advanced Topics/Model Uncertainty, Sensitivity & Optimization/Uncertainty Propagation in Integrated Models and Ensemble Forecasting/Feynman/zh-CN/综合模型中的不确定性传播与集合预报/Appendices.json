{
    "hands_on_practices": [
        {
            "introduction": "误差传播定律是分析不确定性的一个基本工具，尤其是在模型可以通过线性化来近似时。本练习将指导你将该定律应用于一个实际的遥感场景：从一个参数化的双向反射分布函数（BRDF）模型推导出地表反照率的不确定性。通过这个实践，你将掌握如何利用一阶泰勒级数展开，将模型参数及其协方差矩阵中的不确定性传播到最终的物理量中。",
            "id": "3863122",
            "problem": "考虑一个用于均质地表的参数化双向反射分布函数（BRDF），在单个光谱波段上建模为 $r(\\theta_{s}, \\theta_{v}, \\phi) = a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})$，其中 $r$ 是双向反射因子，$\\theta_{s}$ 是太阳天顶角，$\\theta_{v}$ 是观测天顶角，$\\phi$ 是相对方位角。在太阳天顶角 $\\theta_{s}$ 处的方向-半球反射率（黑空反照率）由对观测半球的半球积分定义：$A(\\theta_{s}) = \\int_{\\Omega_{v}} r(\\theta_{s}, \\theta_{v}, \\phi) \\cos(\\theta_{v}) \\, \\mathrm{d}\\Omega_{v}$，其中 $\\mathrm{d}\\Omega_{v} = \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi$，积分域为 $\\theta_{v} \\in [0, \\pi/2]$，$\\phi \\in [0, 2\\pi]$。一次遥感反演得到了参数估计值 $a$、$b$、$c$，其联合不确定度由协方差矩阵 $\\Sigma$ 表征：\n$$\n\\Sigma = \\begin{pmatrix}\n0.0004   0.0001   -0.00005 \\\\\n0.0001   0.0009   0.00002 \\\\\n-0.00005   0.00002   0.00025\n\\end{pmatrix},\n$$\n参数均值为 $a = 0.12$，$b = 0.08$，$c = 0.05$。观测到的太阳天顶角为 $\\theta_{s} = 0.7$，其测量不确定度由标准差 $\\sigma_{\\theta} = 0.02$ 表征。假设参数不确定度与太阳天顶角不确定度在统计上是独立的，并且围绕观测角度应用基于一阶线性化（泰勒级数）的不确定度传播定律。使用这些数据和假设，计算在观测太阳天顶角下黑空反照率 $A(\\theta_{s})$ 的标准不确定度（一个标准差）。所有角度均以弧度为单位，您可以将 $\\pi$ 视为圆周率。将最终的不确定度表示为一个无单位的小数，并将您的答案四舍五入到四位有效数字。",
            "solution": "该问题要求基于其输入变量的不确定度来计算黑空反照率 $A(\\theta_{s})$ 的标准不确定度。反照率是双向反射分布函数（BRDF）参数 $a$、$b$、$c$ 和太阳天顶角 $\\theta_{s}$ 的函数。$A$ 的不确定度将使用不确定度传播定律来确定，问题陈述中要求使用一阶泰勒级数线性化，这为此提供了依据。\n\n首先，我们必须推导黑空反照率 $A(\\theta_{s})$ 的解析表达式。它被定义为方向-半球反射率，由 BRDF 在观测半球上的积分给出：\n$$ A(\\theta_{s}) = \\int_{\\Omega_{v}} r(\\theta_{s}, \\theta_{v}, \\phi) \\cos(\\theta_{v}) \\, \\mathrm{d}\\Omega_{v} $$\n观测方向的微分立体角为 $\\mathrm{d}\\Omega_{v} = \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi$，半球的积分限为 $\\theta_{v} \\in [0, \\pi/2]$ 和 $\\phi \\in [0, 2\\pi]$。给定的 BRDF 模型是 $r(\\theta_{s}, \\theta_{v}, \\phi) = a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})$。\n\n我们将 BRDF 模型代入 $A(\\theta_s)$ 的积分中：\n$$ A(\\theta_{s}) = \\int_{0}^{2\\pi} \\int_{0}^{\\pi/2} (a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})) \\cos(\\theta_{v}) \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi $$\n被积函数不依赖于相对方位角 $\\phi$，因此对 $\\phi$ 从 $0$ 到 $2\\pi$ 的积分会引入一个因子 $2\\pi$：\n$$ A(\\theta_{s}) = 2\\pi \\int_{0}^{\\pi/2} (a \\cos(\\theta_{v}) \\sin(\\theta_{v}) + b \\cos^2(\\theta_{v}) \\sin(\\theta_{v}) + c \\cos(\\theta_{s}) \\cos(\\theta_{v}) \\sin(\\theta_{v})) \\, \\mathrm{d}\\theta_{v} $$\n为了计算关于 $\\theta_v$ 的积分，我们进行换元，令 $u = \\cos(\\theta_v)$，这意味着 $\\mathrm{d}u = -\\sin(\\theta_v) \\mathrm{d}\\theta_v$。积分限也相应变换：当 $\\theta_v=0$ 时，$u=1$；当 $\\theta_v=\\pi/2$ 时，$u=0$。\n$$ A(\\theta_{s}) = 2\\pi \\int_{1}^{0} (a u + b u^2 + c u \\cos(\\theta_{s})) (-\\mathrm{d}u) = 2\\pi \\int_{0}^{1} (a u + b u^2 + c u \\cos(\\theta_{s})) \\, \\mathrm{d}u $$\n进行多项式积分得到：\n$$ A(\\theta_{s}) = 2\\pi \\left[ \\frac{a u^2}{2} + \\frac{b u^3}{3} + \\frac{c u^2}{2} \\cos(\\theta_{s}) \\right]_{0}^{1} $$\n$$ A(\\theta_{s}) = 2\\pi \\left( \\frac{a}{2} + \\frac{b}{3} + \\frac{c}{2} \\cos(\\theta_{s}) \\right) $$\n这简化为反照率的最终解析表达式：\n$$ A(a,b,c,\\theta_s) = \\pi a + \\frac{2\\pi}{3} b + \\pi c \\cos(\\theta_{s}) $$\n\n问题陈述指出参数 $(a,b,c)$ 的不确定度与角度 $\\theta_s$ 的不确定度在统计上是独立的。因此，$A$ 的总方差，记作 $\\sigma_A^2$，是这些独立来源贡献的方差之和：\n$$ \\sigma_A^2 = \\sigma_{A, \\text{params}}^2 + \\sigma_{A, \\theta_s}^2 $$\n第一项 $\\sigma_{A, \\text{params}}^2$ 源于参数不确定度，计算为 $J \\Sigma J^T$，其中 $J$ 是 $A$ 对参数 $(a,b,c)$ 的偏导数构成的雅可比行向量，$\\Sigma$ 是它们给定的协方差矩阵。第二项 $\\sigma_{A, \\theta_s}^2$ 源于角度不确定度，计算为 $(\\frac{\\partial A}{\\partial \\theta_s})^2 \\sigma_{\\theta}^2$，其中 $\\sigma_{\\theta}$ 是 $\\theta_s$ 的标准差。\n\n我们计算 $A(a,b,c,\\theta_s)$ 所需的偏导数：\n$$ \\frac{\\partial A}{\\partial a} = \\pi $$\n$$ \\frac{\\partial A}{\\partial b} = \\frac{2\\pi}{3} $$\n$$ \\frac{\\partial A}{\\partial c} = \\pi \\cos(\\theta_{s}) $$\n$$ \\frac{\\partial A}{\\partial \\theta_{s}} = -\\pi c \\sin(\\theta_{s}) $$\n\n来自参数的方差是：\n$$ \\sigma_{A, \\text{params}}^2 = \\begin{pmatrix} \\frac{\\partial A}{\\partial a}  \\frac{\\partial A}{\\partial b}  \\frac{\\partial A}{\\partial c} \\end{pmatrix} \\Sigma \\begin{pmatrix} \\frac{\\partial A}{\\partial a} \\\\ \\frac{\\partial A}{\\partial b} \\\\ \\frac{\\partial A}{\\partial c} \\end{pmatrix} $$\n我们在给定的值 $\\theta_s = 0.7$ 弧度处计算这些导数。方差表达式可以展开为：\n$$ \\sigma_{A, \\text{params}}^2 = \\left(\\frac{\\partial A}{\\partial a}\\right)^2 \\Sigma_{aa} + \\left(\\frac{\\partial A}{\\partial b}\\right)^2 \\Sigma_{bb} + \\left(\\frac{\\partial A}{\\partial c}\\right)^2 \\Sigma_{cc} + 2\\frac{\\partial A}{\\partial a}\\frac{\\partial A}{\\partial b}\\Sigma_{ab} + 2\\frac{\\partial A}{\\partial a}\\frac{\\partial A}{\\partial c}\\Sigma_{ac} + 2\\frac{\\partial A}{\\partial b}\\frac{\\partial A}{\\partial c}\\Sigma_{bc} $$\n代入导数和 $\\Sigma = \\begin{pmatrix} 0.0004  0.0001  -0.00005 \\\\ 0.0001  0.0009  0.00002 \\\\ -0.00005  0.00002  0.00025 \\end{pmatrix}$ 的分量：\n$$ \\sigma_{A, \\text{params}}^2 = \\pi^2 (0.0004) + \\left(\\frac{2\\pi}{3}\\right)^2 (0.0009) + (\\pi\\cos(0.7))^2 (0.00025) + 2(\\pi)\\left(\\frac{2\\pi}{3}\\right)(0.0001) + 2(\\pi)(\\pi\\cos(0.7))(-0.00005) + 2\\left(\\frac{2\\pi}{3}\\right)(\\pi\\cos(0.7))(0.00002) $$\n$$ \\sigma_{A, \\text{params}}^2 = \\pi^2 \\left[ 0.0004 + \\frac{4}{9}(0.0009) + \\cos^2(0.7)(0.00025) + \\frac{4}{3}(0.0001) - 2\\cos(0.7)(0.00005) + \\frac{4}{3}\\cos(0.7)(0.00002) \\right] $$\n使用 $\\theta_s = 0.7$，我们得到 $\\cos(0.7) \\approx 0.764842$：\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0004 + 0.0004 + (0.58498)(0.00025) + 0.00013333 - (1.52968)(0.00005) + (1.01979)(0.00002) ] $$\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0008 + 0.00014625 + 0.00013333 - 0.00007648 + 0.00002040 ] $$\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0010235 ] \\approx 0.0100998 $$\n\n来自角度不确定度的方差，其中 $c=0.05$ 且 $\\sigma_{\\theta}=0.02$，为：\n$$ \\sigma_{A, \\theta_s}^2 = \\left( \\frac{\\partial A}{\\partial \\theta_s} \\right)^2 \\sigma_{\\theta}^2 = (-\\pi c \\sin(\\theta_s))^2 \\sigma_{\\theta}^2 = \\pi^2 c^2 \\sin^2(\\theta_s) \\sigma_{\\theta}^2 $$\n使用 $\\sin(0.7) \\approx 0.644218$：\n$$ \\sigma_{A, \\theta_s}^2 = \\pi^2 (0.05)^2 \\sin^2(0.7) (0.02)^2 \\approx \\pi^2 (0.0025) (0.644218)^2 (0.0004) $$\n$$ \\sigma_{A, \\theta_s}^2 \\approx \\pi^2 (0.0025) (0.415015) (0.0004) \\approx (9.8696) (4.15015 \\times 10^{-7}) \\approx 0.000004096 $$\n\n总方差是这两个分量的和：\n$$ \\sigma_A^2 = \\sigma_{A, \\text{params}}^2 + \\sigma_{A, \\theta_s}^2 \\approx 0.0100998 + 0.000004096 = 0.0101039 $$\n标准不确定度 $\\sigma_A$ 是总方差的平方根：\n$$ \\sigma_A = \\sqrt{\\sigma_A^2} \\approx \\sqrt{0.0101039} \\approx 0.100518 $$\n按要求将结果四舍五入到四位有效数字，得到 $0.1005$。",
            "answer": "$$\\boxed{0.1005}$$"
        },
        {
            "introduction": "准确地传播不确定性的前提是准确地描述输入不确定性。本练习探讨了这一过程中的一个关键挑战：观测误差相关性，这在集成遥感数据的模型中尤为普遍。你将从第一性原理出发，通过解析推导来量化忽略误差相关性所导致的后果，揭示这种简化假设如何系统性地高估观测信息含量，并最终导致过于自信的（即有偏的）后验估计。",
            "id": "3863088",
            "problem": "一个陆地表面数据同化系统整合了一个热力学陆地表面模型和卫星热红外辐射，以估计一个均质像元上的标量近地表动力学温度 $x$。该综合模型的预报步骤产生一个背景（先验）集合，其均值为 $x_{b}$，方差为 $\\sigma_{b}^{2}$。由于辐射到温度的反演已经完成，观测算子是线性的，$h(x)=x$。在短时间窗口内，对同一像元有两个可用的共轨卫星反演结果 $y_{1}$ 和 $y_{2}$。由于共同的大气校正和共享的正演模型分量，反演误差是相关的。设观测误差向量为 $\\mathbf{\\varepsilon}=\\begin{pmatrix}\\varepsilon_{1}  \\varepsilon_{2}\\end{pmatrix}^{\\top}$，其中 $\\mathbb{E}[\\varepsilon_{i}]=0$，$\\mathrm{Var}(\\varepsilon_{i})=\\sigma_{o}^{2}$，且 $\\mathrm{Corr}(\\varepsilon_{1}, \\varepsilon_{2}) = \\rho$ (其中 $-1  \\rho  1$)。因此，真实的观测误差协方差为 $R_{\\mathrm{true}}=\\sigma_{o}^{2}\\begin{pmatrix}1  \\rho \\\\ \\rho  1\\end{pmatrix}$。\n\n假设为线性高斯数据同化，并通过将贝叶斯法则应用于高斯先验 $x\\sim\\mathcal{N}(x_{b},\\sigma_{b}^{2})$ 和高斯似然 $\\mathbf{y}\\mid x \\sim \\mathcal{N}(H x, R)$ (其中 $H=\\begin{pmatrix}1  1\\end{pmatrix}^{\\top}$)，从第一性原理推导 $x$ 的分析（后验）方差。首先，使用 $R=R_{\\mathrm{true}}$ 求得分析方差 $\\sigma_{a,\\mathrm{true}}^{2}$。然后，在忽略相关性的对角协方差假设下，即 $R_{\\mathrm{diag}}=\\sigma_{o}^{2}I_{2}$，求得分析方差 $\\sigma_{a,\\mathrm{diag}}^{2}$。\n\n利用这些结果，通过比较观测引起的精度增量项，展示忽略误差相关性如何夸大感知到的观测信息含量，并量化由此产生的后验方差偏差。具体来说，请用 $\\sigma_{b}^{2}$、$\\sigma_{o}^{2}$ 和 $\\rho$ 表示后验方差中的乘性偏差因子\n$$B=\\frac{\\sigma_{a,\\mathrm{diag}}^{2}}{\\sigma_{a,\\mathrm{true}}^{2}},$$\n提供一个闭式解析表达式。你的最终答案必须是 $B$ 的一个单一闭式解析表达式。无需四舍五入。因为 $B$ 是无量纲的，所以不要在最终答案中附加单位。",
            "solution": "分析基于线性高斯贝叶斯推断的原理。给定测量值 $\\mathbf{y}$，状态变量 $x$ 的后验概率分布正比于先验分布和似然函数的乘积，$p(x|\\mathbf{y}) \\propto p(\\mathbf{y}|x)p(x)$。由于先验和似然都是高斯分布，后验也是一个高斯分布，$x|\\mathbf{y} \\sim \\mathcal{N}(x_{a}, \\sigma_{a}^{2})$。后验（分析）方差 $\\sigma_{a}^{2}$ 由先验（背景）方差 $\\sigma_{b}^{2}$ 和观测不确定性决定。分析方差的倒数（即分析精度）的通用公式由下式给出：\n$$(\\sigma_{a}^{2})^{-1} = (\\sigma_{b}^{2})^{-1} + H^{\\top} R^{-1} H$$\n其中 $H$ 是观测算子矩阵，$R$ 是观测误差协方差矩阵。我们将对 $R$ 的两种指定情况应用此公式。\n\n首先，我们使用真实的观测误差协方差矩阵 $R_{\\mathrm{true}}$ 推导分析方差 $\\sigma_{a,\\mathrm{true}}^{2}$。\n给定的量为：\n标量状态 $x$ 和两次观测的观测算子矩阵是 $H = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n真实的观测误差协方差矩阵是 $R_{\\mathrm{true}} = \\sigma_{o}^{2}\\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$。\n\n为了计算 $H^{\\top} R_{\\mathrm{true}}^{-1} H$ 项，我们首先需要 $R_{\\mathrm{true}}$ 的逆矩阵。$R_{\\mathrm{true}}$ 的行列式是 $\\det(R_{\\mathrm{true}}) = (\\sigma_{o}^{2})^{2}(1) - (\\rho\\sigma_{o}^{2})^{2} = \\sigma_{o}^{4}(1-\\rho^{2})$。\n逆矩阵为：\n$$R_{\\mathrm{true}}^{-1} = \\frac{1}{\\sigma_{o}^{4}(1-\\rho^{2})} \\begin{pmatrix} \\sigma_{o}^{2}  -\\rho\\sigma_{o}^{2} \\\\ -\\rho\\sigma_{o}^{2}  \\sigma_{o}^{2} \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$$\n现在，我们计算观测引起的精度增量，$H^{\\top} R_{\\mathrm{true}}^{-1} H$：\n$$H^{\\top} R_{\\mathrm{true}}^{-1} H = \\begin{pmatrix} 1  1 \\end{pmatrix} \\left( \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$= \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1-\\rho  1-\\rho \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$= \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} ((1-\\rho) + (1-\\rho)) = \\frac{2(1-\\rho)}{\\sigma_{o}^{2}(1-\\rho)(1+\\rho)} = \\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$$\n分析精度是背景精度与此观测精度增量之和：\n$$(\\sigma_{a,\\mathrm{true}}^{2})^{-1} = \\frac{1}{\\sigma_{b}^{2}} + \\frac{2}{\\sigma_{o}^{2}(1+\\rho)} = \\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}$$\n对此表达式求逆，得到真实的分析方差：\n$$\\sigma_{a,\\mathrm{true}}^{2} = \\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}$$\n\n接下来，我们在观测误差不相关的错误假设下推导分析方差 $\\sigma_{a,\\mathrm{diag}}^{2}$。这对应于使用对角协方差矩阵 $R_{\\mathrm{diag}} = \\sigma_{o}^{2}I_{2}$。\n$$R_{\\mathrm{diag}} = \\sigma_{o}^{2}\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} \\sigma_{o}^{2}  0 \\\\ 0  \\sigma_{o}^{2} \\end{pmatrix}$$\n其逆矩阵很简单：\n$$R_{\\mathrm{diag}}^{-1} = \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$$\n感知到的观测引起的精度增量是：\n$$H^{\\top} R_{\\mathrm{diag}}^{-1} H = \\begin{pmatrix} 1  1 \\end{pmatrix} \\left( \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}}(1+1) = \\frac{2}{\\sigma_{o}^{2}}$$\n将这个感知到的精度增量 $\\frac{2}{\\sigma_{o}^{2}}$ 与真实的精度增量 $\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$ 进行比较，揭示了忽略相关性如何影响感知到的信息含量。如果误差是正相关的（$\\rho > 0$），那么 $1+\\rho > 1$，真实的精度增量 $\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$ 小于感知到的增量 $\\frac{2}{\\sigma_{o}^{2}}$。这意味着忽略正相关会导致对观测所提供信息含量的过高估计或夸大。感知到的信息含量与真实信息含量的比率为 $(\\frac{2}{\\sigma_{o}^{2}}) / (\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}) = 1+\\rho$。\n\n在对角假设下的分析精度是：\n$$(\\sigma_{a,\\mathrm{diag}}^{2})^{-1} = \\frac{1}{\\sigma_{b}^{2}} + \\frac{2}{\\sigma_{o}^{2}} = \\frac{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}{\\sigma_{b}^{2}\\sigma_{o}^{2}}$$\n对此表达式求逆，得到对角假设下的分析方差：\n$$\\sigma_{a,\\mathrm{diag}}^{2} = \\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}}{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}$$\n\n最后，我们通过计算方差的比率来计算乘性偏差因子 $B$：\n$$B = \\frac{\\sigma_{a,\\mathrm{diag}}^{2}}{\\sigma_{a,\\mathrm{true}}^{2}} = \\frac{\\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}}{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}}{\\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}}$$\n我们可以从两个分数的分子中消去公因子 $\\sigma_{b}^{2}\\sigma_{o}^{2}$：\n$$B = \\frac{1/(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})}{(1+\\rho)/(\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2})} = \\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})(1+\\rho)}$$\n这就是乘性偏差因子的最终闭式解析表达式。",
            "answer": "$$\\boxed{\\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})(1+\\rho)}}$$"
        },
        {
            "introduction": "在处理复杂环境系统时，我们通常会使用多个模型来生成预测。本练习将引导你进入集合预报的核心领域，学习如何基于模型在校准期的表现动态地构建一个多模型集合。你将应用基于严格适当评分规则（strictly proper scoring rule）的原则，例如 Bayesian Model Averaging，为每个模型分配合理的权重，从而将多个不完美的预测融合成一个更可靠、更稳健的共识预报。",
            "id": "3863176",
            "problem": "您将获得一组概率模型，这些模型在结合了遥感数据和过程模型的综合建模背景下，为在多个时间点上观测到的某个环境量提供预测分布。这些模型将被组合成一个多模型集成，其权重根据模型的概率技巧评分进行动态调整。您的任务是设计并实现一个程序，该程序针对每个测试用例，使用严格正常评分规则作为技巧度量，通过校准期计算最终的集成权重，然后输出结果权重。所有必需的量都是无量纲的，输出必须是十进制数（而非分数或百分比）。\n\n该集成必须由一个对概率预报而言是严格正常的评分规则来证明其合理性。您必须构建权重，使其与在校准期内最大化该正常评分规则下的预期效用相一致，并假设在每个模型的预测分布条件下，校准观测值是独立的。您的程序必须在不调用任何特定领域捷径的情况下实现这一原则。对于每个测试用例，所得权重必须非负且总和为 $1$。\n\n该集成由多个模型组成，在每个校准时间指数 $t \\in \\{1,\\dots,T\\}$，模型 $i \\in \\{1,\\dots,M\\}$ 会输出一个高斯预测分布，其均值为 $\\mu_{i,t}$，方差为 $\\sigma_{i,t}^{2}$。在时间 $t$ 的观测值为 $y_{t}$。您必须使用适用于连续概率预报的严格正常评分规则，在整个校准期内评估每个模型的技巧。然后，您必须推导一个动态加权方案，该方案在校准期内聚合模型技巧，以生成满足 $\\sum_{i=1}^{M} w_{i} = 1$ 和 $w_{i} \\ge 0$ (对所有 $i$) 的最终权重 $w_{i}$。该推导必须基于严格正常评分规则的第一性原理；该加权方案必须被证明在时间独立性假设下能够实现预期评分规则效用的最大化。\n\n您的程序必须为每个测试用例实现以下步骤：\n- 接受作为输入参数（在程序中硬编码）的校准观测值 $\\{y_{t}\\}_{t=1}^{T}$，以及对于每个模型 $i$，序列 $\\{\\mu_{i,t}\\}_{t=1}^{T}$ 和 $\\{\\sigma_{i,t}\\}_{t=1}^{T}$，其中对所有 $i$ 和 $t$ 都有 $\\sigma_{i,t} > 0$。\n- 使用适用于连续预测密度的严格正常评分规则，计算在整个校准期内每个模型的聚合技巧。\n- 推导并计算最终的集成权重 $\\{w_{i}\\}_{i=1}^{M}$，这些权重应反映基于聚合技巧的动态调整，并确保它们位于概率单纯形上。\n- 按照下文所述的最终输出格式，输出每个测试用例的权重。\n\n测试套件规范：\n- 测试用例 $1$ (正常路径)：$M = 2$， $T = 5$。\n  - 观测值：$y = [0.9, 0.6, -0.2, 0.4, 0.7]$。\n  - 模型 $1$ 均值：$\\mu_{1} = [0.85, 0.62, -0.19, 0.35, 0.75]$。\n  - 模型 $1$ 标准差：$\\sigma_{1} = [0.25, 0.25, 0.30, 0.25, 0.25]$。\n  - 模型 $2$ 均值：$\\mu_{2} = [0.30, 0.10, -0.50, 0.00, 0.20]$。\n  - 模型 $2$ 标准差：$\\sigma_{2} = [0.40, 0.40, 0.50, 0.40, 0.40]$。\n- 测试用例 $2$ (模型间结果相近)：$M = 3$，$T = 4$。\n  - 观测值：$y = [2.0, 2.5, 1.5, 2.2]$。\n  - 模型 $1$ 均值：$\\mu_{1} = [1.9, 2.6, 1.6, 2.1]$。\n  - 模型 $1$ 标准差：$\\sigma_{1} = [0.30, 0.30, 0.30, 0.30]$。\n  - 模型 $2$ 均值：$\\mu_{2} = [2.1, 2.4, 1.4, 2.3]$。\n  - 模型 $2$ 标准差：$\\sigma_{2} = [0.30, 0.30, 0.30, 0.30]$。\n  - 模型 $3$ 均值：$\\mu_{3} = [2.0, 2.5, 1.5, 2.2]$。\n  - 模型 $3$ 标准差：$\\sigma_{3} = [0.35, 0.35, 0.35, 0.35]$。\n- 测试用例 $3$ (存在过分自信且有偏差的模型的边缘案例)：$M = 2$，$T = 5$。\n  - 观测值：$y = [-0.5, -0.4, -0.6, -0.55, -0.45]$。\n  - 模型 $1$ 均值：$\\mu_{1} = [-0.45, -0.38, -0.62, -0.50, -0.47]$。\n  - 模型 $1$ 标准差：$\\sigma_{1} = [0.15, 0.15, 0.15, 0.15, 0.15]$。\n  - 模型 $2$ 均值：$\\mu_{2} = [-0.10, -0.10, -0.10, -0.10, -0.10]$。\n  - 模型 $2$ 标准差：$\\sigma_{2} = [0.05, 0.05, 0.05, 0.05, 0.05]$。\n\n答案规范：\n- 对于每个测试用例，您的程序必须根据上述严格正常评分规则原则计算最终的集成权重 $\\{w_{i}\\}_{i=1}^{M}$，并将其作为十进制数输出。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素是对应一个测试用例的权重列表。例如，输出应类似于 $[[w_{1}^{(1)}, w_{2}^{(1)}], [w_{1}^{(2)}, w_{2}^{(2)}, w_{3}^{(2)}], [w_{1}^{(3)}, w_{2}^{(3)}]]$，不含任何额外文本。每个 $w_{i}^{(j)}$ 必须是 $[0,1]$ 范围内的十进制数，并且每个内部列表中的权重总和必须为 $1$。",
            "solution": "用户希望我解决一个关于为概率预报创建集成权重的问题。\n\n### 第 1 步：提取已知条件\n- **背景**：一个综合建模场景，结合遥感和过程模型来预测一个环境量。\n- **集成结构**：一个具有动态调整权重的多模型集成。\n- **集成组件**：$M$ 个模型，每个模型在 $T$ 个时间点上提供一个预测分布。\n- **预测分布形式**：高斯分布，模型 $i$ 在时间 $t$ 提供均值 $\\mu_{i,t}$ 和方差 $\\sigma_{i,t}^{2}$。（$ \\sigma_{i,t}  0 $）\n- **校准数据**：一组观测值 $\\{y_t\\}_{t=1}^T$。\n- **加权原则**：\n    1.  使用严格正常评分规则对连续概率预报进行技巧评估。\n    2.  权重必须与在校准期内最大化该评分规则下的预期效用相一致。\n    3.  在每个模型的预测分布条件下，校准观测值是独立的。\n    4.  推导必须基于第一性原理。\n- **权重约束**：最终权重 $w_i$ 必须是非负的（$w_i \\ge 0$）且总和为一（$\\sum_{i=1}^M w_i = 1$）。\n- **测试用例 1**：$M=2$, $T=5$。\n    - $y = [0.9, 0.6, -0.2, 0.4, 0.7]$。\n    - $\\mu_1 = [0.85, 0.62, -0.19, 0.35, 0.75]$, $\\sigma_1 = [0.25, 0.25, 0.30, 0.25, 0.25]$。\n    - $\\mu_2 = [0.30, 0.10, -0.50, 0.00, 0.20]$, $\\sigma_2 = [0.40, 0.40, 0.50, 0.40, 0.40]$。\n- **测试用例 2**：$M=3, T=4$。\n    - $y = [2.0, 2.5, 1.5, 2.2]$。\n    - $\\mu_1 = [1.9, 2.6, 1.6, 2.1]$, $\\sigma_1 = [0.30, 0.30, 0.30, 0.30]$。\n    - $\\mu_2 = [2.1, 2.4, 1.4, 2.3]$, $\\sigma_2 = [0.30, 0.30, 0.30, 0.30]$。\n    - $\\mu_3 = [2.0, 2.5, 1.5, 2.2]$, $\\sigma_3 = [0.35, 0.35, 0.35, 0.35]$。\n- **测试用例 3**：$M=2, T=5$。\n    - $y = [-0.5, -0.4, -0.6, -0.55, -0.45]$。\n    - $\\mu_1 = [-0.45, -0.38, -0.62, -0.50, -0.47]$, $\\sigma_1 = [0.15, 0.15, 0.15, 0.15, 0.15]$。\n    - $\\mu_2 = [-0.10, -0.10, -0.10, -0.10, -0.10]$, $\\sigma_2 = [0.05, 0.05, 0.05, 0.05, 0.05]$。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题根据验证标准进行评估：\n- **科学依据**：该问题根植于已建立的概率预报、集成方法和评分规则等统计学领域。使用高斯分布、正常评分规则和贝叶斯模型平均（正如将要展示的，这是所要求的第一性原理方法）是标准且可靠的科学实践。该问题是科学有效的。\n- **适定性**：该问题要求从“第一性原理”推导出一个“与最大化……效用相一致”的权重方案。这强烈指向一个特定且明确的理论框架，即贝叶斯模型平均（BMA）。在此解释下，存在一个唯一且有意义的解。输入对于此目的而言是充分的。该问题是适定的。\n- **客观性**：所有输入都是数值，期望的输出是一组数值权重。语言精确且无主观性。该问题是客观的。\n- **完整性与一致性**：该问题为每个测试用例提供了所有必要的数据（观测值、均值、标准差）。约束条件（$\\sigma_{i,t}  0$，权重在单纯形上）清晰且一致。该问题是完整且一致的。\n- **其他缺陷**：该问题没有表现出任何其他缺陷，如不切实际、结构不良、过于简单或超出科学可验证范围。\n\n### 第 3 步：结论与行动\n该问题被判定为**有效**。将提供解决方案。\n\n### 解决方案推导\n\n该问题要求为 $M$ 个概率模型构建集成权重 $\\{w_i\\}_{i=1}^M$，其依据是它们在 $T$ 个观测值的校准期内的表现。推导必须基于第一性原理，并使用严格正常评分规则。\n\n**1. 评分规则的选择**\n严格正常评分规则确保预报者只有在陈述其真实信念时才能获得唯一最优的评分。对于连续概率预报，例如模型提供的高斯分布 $N(\\mu, \\sigma^2)$，最基础的严格正常评分规则是**对数评分** (LogS)。对数评分即为预报的概率密度函数 (PDF) 在观测结果处的对数值。对于单个预测分布 $P$ 和观测值 $y$，评分为 $S(P, y) = \\log(p(y))$，其中 $p(y)$ 是对应于 $P$ 的 PDF。评分越高越好。\n\n对于一个高斯预报 $p_{i,t} \\sim N(\\mu_{i,t}, \\sigma_{i,t}^2)$，观测值为 $y_t$ 时的对数评分为：\n$$ S(p_{i,t}, y_t) = \\log \\left( \\frac{1}{\\sqrt{2\\pi\\sigma_{i,t}^2}} \\exp\\left(-\\frac{(y_t-\\mu_{i,t})^2}{2\\sigma_{i,t}^2}\\right) \\right) $$\n$$ S(p_{i,t}, y_t) = -\\frac{1}{2}\\log(2\\pi\\sigma_{i,t}^2) - \\frac{(y_t-\\mu_{i,t})^2}{2\\sigma_{i,t}^2} $$\n\n**2. 技巧的聚合**\n问题指出，在给定模型的预报条件下，观测值 $\\{y_t\\}$ 是独立的。这一假设允许我们通过将各个对数评分相加来聚合每个模型在校准期内的技巧。模型 $i$ 的总评分（记为 $S_i$）为：\n$$ S_i = \\sum_{t=1}^{T} S(p_{i,t}, y_t) = \\sum_{t=1}^{T} \\log(p_{i,t}(y_t)) $$\n\n**3. 从第一性原理推导权重**\n从模型表现推导权重的最符合第一性原理的方法是贝叶斯模型平均 (BMA)。在此框架中，权重 $w_i$ 被解释为在给定观测校准数据 $D = \\{y_t\\}_{t=1}^T$ 的条件下，模型 $M_i$ 是“真实”数据生成过程的后验概率。\n\n根据贝叶斯定理，模型 $M_i$ 的后验概率为：\n$$ w_i \\equiv P(M_i | D) = \\frac{P(D | M_i) P(M_i)}{P(D)} = \\frac{P(D | M_i) P(M_i)}{\\sum_{j=1}^{M} P(D | M_j) P(M_j)} $$\n这里，$P(M_i)$ 是模型 $M_i$ 的先验概率，$P(D | M_i)$ 是模型 $M_i$ 的边际似然或“证据”。\n\n- **先验概率 $P(M_i)$**：在没有偏好任何特定模型的先验信息的情况下，我们分配一个无信息的均匀先验：对所有 $i = 1, \\dots, M$，有 $P(M_i) = 1/M$。\n\n- **边际似然 $P(D | M_i)$**：由于假设在模型条件下观测值在时间上是独立的，因此模型 $M_i$ 对应整个数据集的似然是各个似然（密度）的乘积：\n$$ P(D | M_i) = \\prod_{t=1}^{T} p_{i,t}(y_t) $$\n对该表达式取对数，揭示了其与总对数评分 $S_i$ 的直接联系：\n$$ \\log(P(D | M_i)) = \\sum_{t=1}^{T} \\log(p_{i,t}(y_t)) = S_i $$\n因此，边际似然就是总评分的指数：$P(D | M_i) = \\exp(S_i)$。\n\n将这些代回权重公式可得：\n$$ w_i = \\frac{\\exp(S_i) \\cdot (1/M)}{\\sum_{j=1}^{M} \\exp(S_j) \\cdot (1/M)} = \\frac{\\exp(S_i)}{\\sum_{j=1}^{M} \\exp(S_j)} $$\n这是应用于总对数评分向量的 softmax 函数。此推导满足所有问题要求：它基于第一性原理（贝叶斯定理），使用了严格正常评分规则（LogS），并生成了非负且总和为 1 的权重 $w_i$。问题中描述的“动态调整”被隐含地捕捉到，因为这种批处理公式与从均匀先验开始的在线贝叶斯更新得到的结果相同。此方法与寻找最优的 BMA 预测分布相一致，该分布在贝叶斯意义上最大化了预期效用。\n\n**4. 算法实现**\n每个测试用例的算法流程如下：\n1.  对于每个模型 $i \\in \\{1, \\dots, M\\}$，计算总对数评分 $S_i = \\sum_{t=1}^{T} \\left( -\\frac{1}{2}\\log(2\\pi\\sigma_{i,t}^2) - \\frac{(y_t-\\mu_{i,t})^2}{2\\sigma_{i,t}^2} \\right)$。\n2.  总评分 $S_i$ 可能是很大的负数，因此直接计算 $\\exp(S_i)$ 可能会导致数值下溢。为确保稳定性，我们使用 log-sum-exp 技巧。设 $S_{\\max} = \\max_j \\{S_j\\}$。权重计算如下：\n    $$ w_i = \\frac{\\exp(S_i - S_{\\max})}{\\sum_{j=1}^{M} \\exp(S_j - S_{\\max})} $$\n    该计算在数值上是稳定的，并且在数学上与原始公式等价。\n3.  生成的权重向量 $\\{w_i\\}$ 即为该测试用例的最终答案。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ensemble weighting problem for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"y\": np.array([0.9, 0.6, -0.2, 0.4, 0.7]),\n            \"mus\": np.array([\n                [0.85, 0.62, -0.19, 0.35, 0.75],\n                [0.30, 0.10, -0.50, 0.00, 0.20]\n            ]),\n            \"sigmas\": np.array([\n                [0.25, 0.25, 0.30, 0.25, 0.25],\n                [0.40, 0.40, 0.50, 0.40, 0.40]\n            ])\n        },\n        {\n            \"y\": np.array([2.0, 2.5, 1.5, 2.2]),\n            \"mus\": np.array([\n                [1.9, 2.6, 1.6, 2.1],\n                [2.1, 2.4, 1.4, 2.3],\n                [2.0, 2.5, 1.5, 2.2]\n            ]),\n            \"sigmas\": np.array([\n                [0.30, 0.30, 0.30, 0.30],\n                [0.30, 0.30, 0.30, 0.30],\n                [0.35, 0.35, 0.35, 0.35]\n            ])\n        },\n        {\n            \"y\": np.array([-0.5, -0.4, -0.6, -0.55, -0.45]),\n            \"mus\": np.array([\n                [-0.45, -0.38, -0.62, -0.50, -0.47],\n                [-0.10, -0.10, -0.10, -0.10, -0.10]\n            ]),\n            \"sigmas\": np.array([\n                [0.15, 0.15, 0.15, 0.15, 0.15],\n                [0.05, 0.05, 0.05, 0.05, 0.05]\n            ])\n        }\n    ]\n\n    def calculate_weights(y, mus, sigmas):\n        \"\"\"\n        Calculates ensemble weights based on the Bayesian Model Averaging principle\n        using the Logarithmic Score.\n\n        Args:\n            y (np.ndarray): Array of observations, shape (T,).\n            mus (np.ndarray): Array of model means, shape (M, T).\n            sigmas (np.ndarray): Array of model standard deviations, shape (M, T).\n\n        Returns:\n            np.ndarray: Final ensemble weights, shape (M,).\n        \"\"\"\n        # Get number of models M and time points T.\n        M, T = mus.shape\n\n        # Reshape y for broadcasting with (M, T) arrays.\n        y_broadcast = y.reshape(1, T)\n\n        # Calculate variances from standard deviations.\n        variances = sigmas**2\n\n        # Calculate the log-likelihood (Logarithmic Score) for each model at each time point.\n        # This is a fully vectorized operation.\n        # log(p(y)) = -0.5 * log(2*pi*sigma^2) - (y - mu)^2 / (2*sigma^2)\n        log_likelihoods = -0.5 * np.log(2 * np.pi * variances) - \\\n                          (y_broadcast - mus)**2 / (2 * variances)\n\n        # Aggregate the scores for each model by summing over the time dimension (axis=1).\n        aggregate_log_scores = np.sum(log_likelihoods, axis=1)\n\n        # To compute weights via softmax, use the log-sum-exp trick for numerical stability.\n        # Subtract the max log score before exponentiating.\n        max_log_score = np.max(aggregate_log_scores)\n        \n        # Calculate unnormalized weights.\n        unnormalized_weights = np.exp(aggregate_log_scores - max_log_score)\n\n        # Normalize to get the final weights.\n        sum_of_weights = np.sum(unnormalized_weights)\n        weights = unnormalized_weights / sum_of_weights\n        \n        return weights\n\n    results = []\n    for case in test_cases:\n        weights = calculate_weights(case[\"y\"], case[\"mus\"], case[\"sigmas\"])\n        results.append(weights)\n\n    # Format the output string precisely as required, with no spaces inside inner lists.\n    results_str_list = []\n    for res in results:\n        # Convert numpy array elements to string and join with commas.\n        weights_str = \",\".join(map(str, res))\n        # Enclose in brackets to form a list-like string.\n        results_str_list.append(f\"[{weights_str}]\")\n    \n    # Join all test case results with commas and enclose in outer brackets.\n    final_output = f\"[{','.join(results_str_list)}]\"\n    \n    print(final_output)\n\nsolve()\n\n```"
        }
    ]
}