{
    "hands_on_practices": [
        {
            "introduction": "在评估环境模型时，一个最基本的问题是：我们如何量化一个输入特征（如一个光谱波段）对于预测目标（如土地覆盖类型）的重要性？本练习将引导你使用信息论中的一个基本概念——互信息（Mutual Information），来回答这个问题。通过从一个简化的遥感数据集中手动计算互信息，你将掌握一种独立于任何特定模型的、量化特征相关性的基本方法，这是构建可解释AI模型的第一步。",
            "id": "3811303",
            "problem": "一个基于卫星的土地覆盖分类器使用单个离散化的近红外（NIR）光谱带作为特征，该特征被量化为三个区间 $X \\in \\{L, M, H\\}$，分别对应低、中、高反射率。目标土地覆盖类别为 $Y \\in \\{F, W, U\\}$，其中 $F$ 代表森林， $W$ 代表水体， $U$ 代表城市。以下玩具数据集包含 $N = 300$ 个像素，其经验观测到的 $X$ 和 $Y$ 之间的联合计数 $n_{x,y}$ 如下：\n- $n_{L,W} = 80$， $n_{L,F} = 10$， $n_{L,U} = 20$，\n- $n_{M,W} = 18$， $n_{M,F} = 30$， $n_{M,U} = 45$，\n- $n_{H,W} = 2$， $n_{H,F} = 80$， $n_{H,U} = 15$。\n从基础的概率和信息论定义出发（不使用任何预先推导的捷径），使用由上述计数导出的经验联合分布 $p(x,y)$ 及相关的边缘分布 $p(x)$ 和 $p(y)$，推导并计算互信息 $I(X;Y)$。计算时使用自然对数 $\\ln$。将最终数值结果以纳特（nats）为单位表示，并四舍五入至四位有效数字。简要阐述计算出的值对于遥感领域的可解释性人工智能（XAI）特征选择的意义，重点关注 $I(X;Y)$ 如何揭示该近红外波段对于土地覆盖分类的相关性。",
            "solution": "用户希望计算一个特征与一个目标类别之间的互信息，并讨论其意义。\n\n### 问题验证\n\n**第 1 步：提取给定信息**\n\n-   特征集：$X \\in \\{L, M, H\\}$（低、中、高近红外反射率）\n-   目标类别集：$Y \\in \\{F, W, U\\}$（森林、水体、城市）\n-   总样本数：$N = 300$\n-   联合计数 $n_{x,y}$：\n    -   $n_{L,W} = 80$\n    -   $n_{L,F} = 10$\n    -   $n_{L,U} = 20$\n    -   $n_{M,W} = 18$\n    -   $n_{M,F} = 30$\n    -   $n_{M,U} = 45$\n    -   $n_{H,W} = 2$\n    -   $n_{H,F} = 80$\n    -   $n_{H,U} = 15$\n-   任务：使用自然对数 $\\ln$ 计算互信息 $I(X;Y)$。\n-   任务：将数值结果四舍五入到四位有效数字。\n-   任务：阐述该结果对遥感领域可解释性人工智能（XAI）的意义。\n\n**第 2 步：使用提取的给定信息进行验证**\n\n-   **科学依据**：该问题具有科学依据。它将信息论的基本概念（互信息）应用于遥感和机器学习中的一个标准问题（土地覆盖分类的特征相关性分析）。不同土地覆盖具有不同近红外反射率的物理前提是正确的（例如，水吸收近红外，因此反射率低；健康植被强烈反射近红外，因此反射率高）。\n-   **适定性**：该问题是适定的。它为两个变量提供了一套完整的联合计数，这足以确定计算所需的联合概率分布和边缘概率分布。总计数是一致的：$\\sum n_{x,y} = 80+10+20+18+30+45+2+80+15 = 300 = N$。存在唯一的数值解。\n-   **客观性**：该问题使用精确、客观和定量的语言进行陈述。\n\n该问题没有任何科学或事实上的不健全、不完整、矛盾或模糊之处。它代表了应用信息论中的一个标准的、可形式化的练习。\n\n**第 3 步：结论与行动**\n\n该问题是**有效的**。将提供解决方案。\n\n### 解决方案推导\n\n两个离散随机变量 $X$ 和 $Y$ 之间的互信息 $I(X;Y)$ 定义为通过了解一个变量而减少的关于另一个变量的不确定性。其形式化表示为：\n$$I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) \\log \\left( \\frac{p(x,y)}{p(x)p(y)} \\right)$$\n题目指定使用自然对数 $\\ln$，因此结果的单位将是纳特（nats）。\n\n首先，我们必须根据给定的计数计算经验联合概率和边缘概率。像素总数为 $N=300$。\n\n**1. 联合概率 $p(x,y)$**\n联合概率 $p(x,y)$ 是联合计数 $n_{x,y}$ 与总计数 $N$ 的比值。\n$p(x,y) = \\frac{n_{x,y}}{N} = \\frac{n_{x,y}}{300}$\n联合概率矩阵为：\n-   $p(L,W) = \\frac{80}{300}$\n-   $p(L,F) = \\frac{10}{300}$\n-   $p(L,U) = \\frac{20}{300}$\n-   $p(M,W) = \\frac{18}{300}$\n-   $p(M,F) = \\frac{30}{300}$\n-   $p(M,U) = \\frac{45}{300}$\n-   $p(H,W) = \\frac{2}{300}$\n-   $p(H,F) = \\frac{80}{300}$\n-   $p(H,U) = \\frac{15}{300}$\n\n**2. 边缘概率 $p(x)$ 和 $p(y)$**\n边缘概率通过对另一变量的联合概率求和得到。\n$p(x) = \\sum_{y \\in Y} p(x,y)$\n-   $p(L) = p(L,W) + p(L,F) + p(L,U) = \\frac{80+10+20}{300} = \\frac{110}{300}$\n-   $p(M) = p(M,W) + p(M,F) + p(M,U) = \\frac{18+30+45}{300} = \\frac{93}{300}$\n-   $p(H) = p(H,W) + p(H,F) + p(H,U) = \\frac{2+80+15}{300} = \\frac{97}{300}$\n\n$p(y) = \\sum_{x \\in X} p(x,y)$\n-   $p(W) = p(L,W) + p(M,W) + p(H,W) = \\frac{80+18+2}{300} = \\frac{100}{300}$\n-   $p(F) = p(L,F) + p(M,F) + p(H,F) = \\frac{10+30+80}{300} = \\frac{120}{300}$\n-   $p(U) = p(L,U) + p(M,U) + p(H,U) = \\frac{20+45+15}{300} = \\frac{80}{300}$\n\n**3. 计算互信息 $I(X;Y)$**\n现在我们将这些概率代入互信息公式。项 $\\frac{p(x,y)}{p(x)p(y)}$ 可以简化为 $\\frac{n_{x,y}/N}{(n_x/N)(n_y/N)} = \\frac{n_{x,y} N}{n_x n_y}$，其中 $n_x = \\sum_y n_{x,y}$ 且 $n_y = \\sum_x n_{x,y}$。\n$I(X;Y)$ 是 9 个形如 $p(x,y) \\ln \\left(\\frac{p(x,y)}{p(x)p(y)}\\right)$ 的项之和：\n\n$I(X;Y) = $\n$\\frac{80}{300} \\ln\\left(\\frac{80/300}{(110/300)(100/300)}\\right) + \\frac{10}{300} \\ln\\left(\\frac{10/300}{(110/300)(120/300)}\\right) + \\frac{20}{300} \\ln\\left(\\frac{20/300}{(110/300)(80/300)}\\right) +$\n$\\frac{18}{300} \\ln\\left(\\frac{18/300}{(93/300)(100/300)}\\right) + \\frac{30}{300} \\ln\\left(\\frac{30/300}{(93/300)(120/300)}\\right) + \\frac{45}{300} \\ln\\left(\\frac{45/300}{(93/300)(80/300)}\\right) +$\n$\\frac{2}{300} \\ln\\left(\\frac{2/300}{(97/300)(100/300)}\\right) + \\frac{80}{300} \\ln\\left(\\frac{80/300}{(97/300)(120/300)}\\right) + \\frac{15}{300} \\ln\\left(\\frac{15/300}{(97/300)(80/300)}\\right)$\n\n简化对数的参数：\n$I(X;Y) = $\n$\\frac{80}{300} \\ln\\left(\\frac{80 \\cdot 300}{110 \\cdot 100}\\right) + \\frac{10}{300} \\ln\\left(\\frac{10 \\cdot 300}{110 \\cdot 120}\\right) + \\frac{20}{300} \\ln\\left(\\frac{20 \\cdot 300}{110 \\cdot 80}\\right) +$\n$\\frac{18}{300} \\ln\\left(\\frac{18 \\cdot 300}{93 \\cdot 100}\\right) + \\frac{30}{300} \\ln\\left(\\frac{30 \\cdot 300}{93 \\cdot 120}\\right) + \\frac{45}{300} \\ln\\left(\\frac{45 \\cdot 300}{93 \\cdot 80}\\right) +$\n$\\frac{2}{300} \\ln\\left(\\frac{2 \\cdot 300}{97 \\cdot 100}\\right) + \\frac{80}{300} \\ln\\left(\\frac{80 \\cdot 300}{97 \\cdot 120}\\right) + \\frac{15}{300} \\ln\\left(\\frac{15 \\cdot 300}{97 \\cdot 80}\\right)$\n\n进行数值计算：\n$I(X;Y) = \\frac{1}{300} [ 80 \\ln(2.1818...) + 10 \\ln(0.2272...) + 20 \\ln(0.6818...) +$\n$18 \\ln(0.5806...) + 30 \\ln(0.8064...) + 45 \\ln(1.8145...) +$\n$2 \\ln(0.0618...) + 80 \\ln(2.0618...) + 15 \\ln(0.5800...) ]$\n\n$I(X;Y) \\approx \\frac{1}{300} [ 80(0.78013) + 10(-1.48160) + 20(-0.38289) +$\n$18(-0.54363) + 30(-0.21506) + 45(0.59579) +$\n$2(-2.78290) + 80(0.72363) + 15(-0.54472) ]$\n\n$I(X;Y) \\approx \\frac{1}{300} [ 62.410 - 14.816 - 7.658 - 9.785 - 6.452 + 26.811 - 5.566 + 57.890 - 8.171 ]$\n$I(X;Y) \\approx \\frac{94.663}{300} \\approx 0.315543...$\n\n四舍五入到四位有效数字，我们得到 $0.3155$。\n\n**4. 对遥感领域可解释性人工智能（XAI）的启示**\n\n计算出的互信息 $I(X;Y) \\approx 0.3155$ 纳特，是离散化近红外波段（$X$）与土地覆盖类别（$Y$）之间统计依赖性的量化度量。在特征选择的可解释性人工智能（XAI）背景下，该值具有直接而明确的意义：\n\n-   **特征相关性的量化**：互信息为零意味着特征和目标在统计上是独立的，即近红外波段对于区分森林、水体和城市类别没有任何信息。由于 $I(X;Y) > 0$，我们可以用形式化的严谨性说明，近红外波段对于此分类任务是一个相关的特征。\n\n-   **与模型无关的可解释性**：此计算是基于数据分布本身进行的，独立于任何特定的机器学习模型（例如，神经网络、随机森林）。这为特征的效用提供了一个基本的、与模型无关的解释。对于 XAI 而言，这是一个有力的陈述：根据信息论，近红外波段本身就具有信息量，而不仅仅是因为某个复杂的“黑箱”模型碰巧使用了它。\n\n-   **特征选择和排序的基础**：在一个拥有数十或数百个光谱带的真实遥感场景中，可以为每个波段 $X_i$ 计算 $I(X_i; Y)$。这些值将允许对所有可用特征进行有原则的排序。具有较高互信息的波段将被认为更重要。这种排序为特征选择提供了一种简单、透明且合理的方法，这是 XAI 的一个核心目标。例如，如果另一个光谱带的互信息为 $0.1$ 纳特，我们可以客观地指出，这个近红外波段的信息量大约是其三倍。$0.3155$ 纳特这个非零值证实了该近红外波段是纳入预测模型的有价值的候选者。",
            "answer": "$$\\boxed{0.3155}$$"
        },
        {
            "introduction": "在掌握了模型无关的特征评估方法后，我们转向更强大的模型特定解释技术，如SHAP (SHapley Additive exPlanations)。本练习不仅仅是简单地应用SHAP，而是深入探讨一个关键且微妙的细节：背景分布的选择，特别是“干预式”（interventional）与“条件式”（conditional）背景的差异。你将推导并计算这两种假设下的SHAP值，亲身体验在遥感数据中常见的特征相关情况下，这个选择如何深刻地改变归因结果，从而更深入地理解SHAP解释的真正含义。",
            "id": "3811343",
            "problem": "考虑一个遥感领域的线性像素级模型，该模型利用两个Sentinel-2光谱波段来估算一个与植被相关的指数，其中$X_1$是B4波段（红色）的反射率，$X_2$是B8波段（近红外）的反射率，预测由$f(x) = w^{\\top} x + b$给出。解释框架为SHapley Additive exPlanations (SHAP)，它为每个特征分配贡献值，这些贡献值之和等于$f(x) - \\mathbb{E}[f(X)]$，其中期望是针对指定的背景分布计算的。考虑两种背景分布：将输入视为独立的干预背景，以及保留输入间统计依赖结构的条件背景。\n\n假设在温带生物群系的一个植被区有以下科学上合理的设定：\n- 随机向量 $(X_1, X_2)$ 服从二元正态分布，其均值为 $\\mu = (\\mu_1, \\mu_2) = (0.12, 0.35)$，标准差为 $\\sigma_1 = 0.05$ 和 $\\sigma_2 = 0.10$，相关系数为 $\\rho = -0.6$。因此，协方差矩阵为\n$$\n\\Sigma = \\begin{pmatrix}\n\\sigma_1^2  \\rho \\, \\sigma_1 \\sigma_2 \\\\\n\\rho \\, \\sigma_1 \\sigma_2  \\sigma_2^2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.05^2  -0.6 \\cdot 0.05 \\cdot 0.10 \\\\\n-0.6 \\cdot 0.05 \\cdot 0.10  0.10^2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.0025  -0.003 \\\\\n-0.003  0.01\n\\end{pmatrix}.\n$$\n- 关注的实例（单个像素）为 $x = (x_1, x_2) = (0.08, 0.60)$。\n- 线性模型参数为 $w = (w_1, w_2) = (-0.8, 1.0)$ 和 $b = 0.05$。\n\n从第一性原理出发：\n1. 使用合作博弈论中的Shapley值定义和全期望定律，推导在干预背景下的SHAP值 $\\phi_i^{\\mathrm{int}}$ 的闭式表达式，其中 $i \\in \\{1,2\\}$。\n2. 使用Shapley值定义和多元正态分布的条件期望公式，推导在条件背景下的SHAP值 $\\phi_i^{\\mathrm{cond}}$ 的闭式表达式，其中 $i \\in \\{1,2\\}$。\n\n然后，对于指定的参数和实例，计算 $\\phi_1^{\\mathrm{int}}$ 和 $\\phi_1^{\\mathrm{cond}}$ 的数值，并报告比率\n$$\nr \\;=\\; \\frac{\\phi_1^{\\mathrm{cond}}}{\\phi_1^{\\mathrm{int}}}.\n$$\n将 $r$ 的最终结果表示为无单位的实数，并四舍五入至四位有效数字。",
            "solution": "该问题要求针对一个线性模型，在两种不同的背景分布假设（干预型和条件型）下，推导SHAP值的闭式表达式，然后计算特定特征的这两个值的比率。\n\n模型是线性的：$f(x) = w^{\\top}x + b$，其中 $x = (x_1, x_2)$ 且 $w = (w_1, w_2)$。\n在特征集 $N$ 中，特征 $i$ 的SHAP值定义为：\n$$\n\\phi_i(f, x) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! (|N| - |S| - 1)!}{|N|!} [v(S \\cup \\{i\\}) - v(S)]\n$$\n其中 $v(S) = \\mathbb{E}[f(X) | X_S = x_S]$。这是在特征子集 $S$ 中的特征被固定为实例 $x$ 中的值时的期望模型输出。对于本问题，特征集为 $N = \\{1, 2\\}$，所以 $|N|=2$。该公式简化为：\n$$\n\\phi_i(f, x) = \\frac{0! (2-0-1)!}{2!} [v(\\{i\\}) - v(\\emptyset)] + \\frac{1! (2-1-1)!}{2!} [v(N) - v(N \\setminus \\{i\\})]\n$$\n$$\n\\phi_i(f, x) = \\frac{1}{2} [ (v(\\{i\\}) - v(\\emptyset)) + (v(\\{1, 2\\}) - v(\\{j\\})) ] \\quad \\text{for } j \\neq i\n$$\n值函数为：\n$v(\\emptyset) = \\mathbb{E}[f(X)]$。\n$v(\\{1\\}) = \\mathbb{E}[f(X) | X_1=x_1]$。\n$v(\\{2\\}) = \\mathbb{E}[f(X) | X_2=x_2]$。\n$v(\\{1, 2\\}) = \\mathbb{E}[f(X) | X_1=x_1, X_2=x_2] = f(x_1, x_2)$。\n\n这两种背景假设在定义期望 $\\mathbb{E}[\\cdot]$ 的方式上有所不同。\n\n**1. 干预型SHAP值($\\phi_i^{\\mathrm{int}}$)的推导**\n\n在干预背景下，特征被视为独立的。对不在 $S$中的特征求期望时，是基于它们的边际分布。模型为 $f(X) = w_1 X_1 + w_2 X_2 + b$。\n\n$v(\\emptyset) = \\mathbb{E}[f(X)] = w_1 \\mathbb{E}[X_1] + w_2 \\mathbb{E}[X_2] + b = w_1 \\mu_1 + w_2 \\mu_2 + b$。\n$v(\\{1\\}) = \\mathbb{E}[w_1 x_1 + w_2 X_2 + b] = w_1 x_1 + w_2 \\mathbb{E}[X_2] + b = w_1 x_1 + w_2 \\mu_2 + b$。\n$v(\\{2\\}) = \\mathbb{E}[w_1 X_1 + w_2 x_2 + b] = w_1 \\mathbb{E}[X_1] + w_2 x_2 + b = w_1 \\mu_1 + w_2 x_2 + b$。\n$v(\\{1, 2\\}) = f(x) = w_1 x_1 + w_2 x_2 + b$。\n\n特征1的边际贡献为：\n$v(\\{1\\}) - v(\\emptyset) = (w_1 x_1 + w_2 \\mu_2 + b) - (w_1 \\mu_1 + w_2 \\mu_2 + b) = w_1(x_1 - \\mu_1)$。\n$v(\\{1, 2\\}) - v(\\{2\\}) = (w_1 x_1 + w_2 x_2 + b) - (w_1 \\mu_1 + w_2 x_2 + b) = w_1(x_1 - \\mu_1)$。\n\n特征1的干预型SHAP值是这些贡献的平均值：\n$$\n\\phi_1^{\\mathrm{int}} = \\frac{1}{2} [w_1(x_1 - \\mu_1) + w_1(x_1 - \\mu_1)] = w_1(x_1 - \\mu_1)\n$$\n根据对称性，特征 $i$ 的通用闭式表达式为：\n$$\n\\phi_i^{\\mathrm{int}} = w_i(x_i - \\mu_i)\n$$\n\n**2. 条件型SHAP值($\\phi_i^{\\mathrm{cond}}$)的推导**\n\n在条件背景下，期望保留了特征之间的统计依赖性。对不在 $S$ 中的特征求期望时，是基于条件概率分布 $p(X_{N \\setminus S} | X_S = x_S)$。\n对于二元正態分布 $(X_1, X_2)$，条件期望是线性的：\n$\\mathbb{E}[X_2 | X_1=x_1] = \\mu_2 + \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1)$。\n$\\mathbb{E}[X_1 | X_2=x_2] = \\mu_1 + \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)$。\n\n值函数为：\n$v(\\emptyset) = \\mathbb{E}[f(X)] = w_1 \\mu_1 + w_2 \\mu_2 + b$。\n$v(\\{1\\}) = \\mathbb{E}[f(X) | X_1=x_1] = w_1 x_1 + w_2 \\mathbb{E}[X_2 | X_1=x_1] + b = w_1 x_1 + w_2(\\mu_2 + \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1)) + b$。\n$v(\\{2\\}) = \\mathbb{E}[f(X) | X_2=x_2] = w_1 \\mathbb{E}[X_1 | X_2=x_2] + w_2 x_2 + b = w_1(\\mu_1 + \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)) + w_2 x_2 + b$。\n$v(\\{1, 2\\}) = f(x) = w_1 x_1 + w_2 x_2 + b$。\n\n特征1的边际贡献是：\n第一个加入时的贡献（$S=\\emptyset$）：\n$v(\\{1\\}) - v(\\emptyset) = [w_1 x_1 + w_2(\\mu_2 + \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1)) + b] - [w_1 \\mu_1 + w_2 \\mu_2 + b] = w_1(x_1 - \\mu_1) + w_2 \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1)$。\n第二个加入时的贡献（$S=\\{2\\}$）：\n$v(\\{1, 2\\}) - v(\\{2\\}) = [w_1 x_1 + w_2 x_2 + b] - [w_1(\\mu_1 + \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)) + w_2 x_2 + b] = w_1 x_1 - w_1(\\mu_1 + \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)) = w_1(x_1 - \\mu_1) - w_1 \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)$。\n\n特征1的条件型SHAP值是这些贡献的平均值：\n$$\n\\phi_1^{\\mathrm{cond}} = \\frac{1}{2} \\left[ \\left(w_1(x_1 - \\mu_1) + w_2 \\rho \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1)\\right) + \\left(w_1(x_1 - \\mu_1) - w_1 \\rho \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2)\\right) \\right]\n$$\n$$\n\\phi_1^{\\mathrm{cond}} = w_1(x_1 - \\mu_1) + \\frac{\\rho}{2} \\left[ w_2 \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1) - w_1 \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2) \\right]\n$$\n这就是 $\\phi_1^{\\mathrm{cond}}$ 的闭式表达式。对于 $\\phi_2^{\\mathrm{cond}}$ 也可以推导出类似的表达式。\n\n**3. 数值计算**\n\n给定以下参数：\n$w = (w_1, w_2) = (-0.8, 1.0)$\n$x = (x_1, x_2) = (0.08, 0.60)$\n$\\mu = (\\mu_1, \\mu_2) = (0.12, 0.35)$\n$\\sigma_1 = 0.05$, $\\sigma_2 = 0.10$\n$\\rho = -0.6$\n\n首先，计算与均值的差：\n$x_1 - \\mu_1 = 0.08 - 0.12 = -0.04$\n$x_2 - \\mu_2 = 0.60 - 0.35 = 0.25$\n\n接下来，计算 $\\phi_1^{\\mathrm{int}}$：\n$$\n\\phi_1^{\\mathrm{int}} = w_1(x_1 - \\mu_1) = (-0.8)(-0.04) = 0.032\n$$\n\n现在，计算 $\\phi_1^{\\mathrm{cond}}$。第一项就是 $\\phi_1^{\\mathrm{int}}$。第二项，即捕捉了相关性影响的修正项，是：\n$$\n\\text{修正项} = \\frac{\\rho}{2} \\left[ w_2 \\frac{\\sigma_2}{\\sigma_1}(x_1 - \\mu_1) - w_1 \\frac{\\sigma_1}{\\sigma_2}(x_2 - \\mu_2) \\right]\n$$\n我们需要标准差的比率：\n$\\frac{\\sigma_2}{\\sigma_1} = \\frac{0.10}{0.05} = 2$\n$\\frac{\\sigma_1}{\\sigma_2} = \\frac{0.05}{0.10} = 0.5$\n\n将数值代入修正项：\n$$\n\\text{修正项} = \\frac{-0.6}{2} \\left[ (1.0)(2)(-0.04) - (-0.8)(0.5)(0.25) \\right]\n$$\n$$\n= -0.3 \\left[ -0.08 - (-0.4)(0.25) \\right]\n$$\n$$\n= -0.3 \\left[ -0.08 + 0.1 \\right]\n$$\n$$\n= -0.3 [0.02] = -0.006\n$$\n现在，我们求得 $\\phi_1^{\\mathrm{cond}}$：\n$$\n\\phi_1^{\\mathrm{cond}} = \\phi_1^{\\mathrm{int}} + \\text{修正项} = 0.032 - 0.006 = 0.026\n$$\n\n最后，计算比率 $r$：\n$$\nr = \\frac{\\phi_1^{\\mathrm{cond}}}{\\phi_1^{\\mathrm{int}}} = \\frac{0.026}{0.032} = \\frac{26}{32} = \\frac{13}{16} = 0.8125\n$$\n问题要求将结果四舍五入至四位有效数字。结果 $0.8125$ 已经有四位有效数字。",
            "answer": "$$\\boxed{0.8125}$$"
        },
        {
            "introduction": "在深度学习时代，注意力机制（attention mechanisms）的可视化常被直观地当作模型的“解释”，但这是否可靠？本练习将引导你挑战这一普遍看法，通过编程构建一个精巧的反例，来揭示“貌似合理”（plausibility）与“忠实性”（faithfulness）之间的鸿沟。你将设计一个模型，它依赖于虚假的边缘伪影进行预测，而其注意力图却“看似合理地”聚焦于图像中心。通过实施基于扰动的忠实性测试 ，你将学会如何严格验证一个解释方法，而不仅仅是相信其表面上的说服力。",
            "id": "3811355",
            "problem": "在遥感和环境模型的可解释性人工智能（XAI）背景下，您被要求构建并分析一个合成反例，其中视觉上合理的注意力图谱对于分类器的真实预测机制并不忠实。遥感领域的动机源于一个已知的边缘伪影：一个虚假预测性边界，例如传感器边框或拼接缝，它与目标标签相关，但并不反映场景内部的潜在环境现象。目标是推导、实现并测试一个有原则的忠实度准则，以证明视觉上合理的注意力机制的失败。\n\n从以下基本依据和定义开始。对于图像 $x \\in \\mathbb{R}^{H \\times W}$，一个输出为 $f(x) \\in [0,1]$ 的二元分类器 $f$ 由逻辑斯谛函数定义：\n$$\nf(x) \\triangleq \\sigma(z(x)) = \\frac{1}{1 + e^{-z(x)}},\n$$\n其中，对数几率（logit）$z(x)$ 是两个空间特征集的线性函数：一个边界框和一个内部中心圆盘。令 $\\mathcal{B}$ 表示宽度为 $w_{\\mathrm{bord}}$ 的边界像素集（所有与图像边界的最小距离严格小于 $w_{\\mathrm{bord}}$ 的像素），令 $\\mathcal{C}$ 表示以图像中心为圆心、半径为 $r$ 的圆盘内的像素集。对数几率为：\n$$\nz(x) = \\alpha_b \\sum_{(i,j) \\in \\mathcal{B}} x_{ij} + \\alpha_c \\sum_{(i,j) \\in \\mathcal{C}} x_{ij} + \\beta,\n$$\n其参数为 $\\alpha_b \\in \\mathbb{R}$、$\\alpha_c \\in \\mathbb{R}$ 和偏置 $\\beta \\in \\mathbb{R}$。合成数据集由三部分构成：一个恒定强度的背景，一个强度反映了合理环境信号（例如，植被绿度）的中心圆盘，以及一个虚假编码标签的边界框。具体来说：\n- 对于所有 $(i,j) \\notin \\mathcal{C} \\cup \\mathcal{B}$，背景强度设置为 $\\mu_{\\mathrm{bg}}$。\n- 对于 $(i,j) \\in \\mathcal{C}$，中心圆盘强度设置为 $\\mu_{y_{\\mathrm{true}}} + \\varepsilon_{ij}$，其中 $y_{\\mathrm{true}} \\in \\{0,1\\}$ 是潜在的环境标签，$\\mu_{1}  \\mu_{0}$，且 $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立的像素噪声。\n- 对于 $(i,j) \\in \\mathcal{B}$，边界强度设置为 $s \\cdot y_{\\mathrm{spur}}$，其中 $y_{\\mathrm{spur}} \\in \\{0,1\\}$ 是一个虚假预测性标签；对于此反例，我们取 $y_{\\mathrm{spur}} = y_{\\mathrm{true}}$，因此即使边界是非因果的，它在训练期间也是完全可预测的。\n\n定义一个视觉上合理的注意力图谱 $A(x)$，它通过将在图像中点为中心的径向对称高斯函数与相对于背景的局部对比度相结合来突出中心圆盘：\n$$\nG_{ij} = \\exp\\left(-\\frac{(i - i_0)^2 + (j - j_0)^2}{2 \\sigma_g^2}\\right), \\quad S_{ij} = \\left|x_{ij} - \\mu_{\\mathrm{bg}}\\right|, \\quad A_{ij}(x) = \\frac{G_{ij} \\cdot S_{ij}}{\\max_{u,v} (G_{uv} \\cdot S_{uv})},\n$$\n其中 $(i_0,j_0)$ 是图像中心，$\\sigma_g$ 是高斯宽度。在环境成像中，这种注意力图谱在视觉上是合理的，因为它倾向于突出中心现象，但如果分类器 $f$ 依赖于边界，那么它就不一定对 $f$ 忠实。\n\n使用基于删除的忠实度测试。对于一个分数 $\\phi \\in (0,1)$ 和一个中性参考强度 $\\rho$，定义两种扰动：\n1. 注意力删除：将 $A_{ij}(x)$ 中值最高的 $\\phi \\cdot H \\cdot W$ 个像素设置为 $\\rho$，得到 $x^{\\mathrm{att}}$；计算 $\\Delta_{\\mathrm{att}} = f(x) - f(x^{\\mathrm{att}})$。\n2. 边界删除：将所有 $(i,j) \\in \\mathcal{B}$ 设置为 $\\rho$，得到 $x^{\\mathrm{bor}}$；计算 $\\Delta_{\\mathrm{bor}} = f(x) - f(x^{\\mathrm{bor}})$。\n\n将忠实度决策 $F$ 定义为布尔值：\n$$\nF = \\left[\\Delta_{\\mathrm{att}} \\ge \\Delta_{\\mathrm{bor}}\\right],\n$$\n其中 $[\\cdot]$ 表示真值。一个忠实的注意力图谱在删除其所突出特征时，应比删除模型不依赖的特征产生更大的预测下降；在此反例中，我们期望删除虚假预测性边界比删除注意力突出的中心区域更能降低预测值，因此在大多数情况下 $F$ 应为假。\n\n您的程序必须完全按照定义实现合成数据生成器、分类器、注意力图谱和删除测试，并评估以下测试套件。对于每个案例，使用 $y_{\\mathrm{true}} = 1$、 $y_{\\mathrm{spur}} = 1$、$\\mu_{\\mathrm{bg}} = 0.5$ 和 $\\sigma_g = r/2$。在所有案例中，将强度表示为无单位的小数。\n\n测试套件（四个案例）：\n- 案例1：$H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 1.0$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$。\n- 案例2：$H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 0.5$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$。\n- 案例3：$H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 2$, $s = 1.0$, $\\alpha_b = 0.02$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$。\n- 案例4：$H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 0.1$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$。\n\n您的程序应生成单行输出，其中包含四个案例的忠实度决策，格式为方括号括起来的逗号分隔列表，例如 $[F_1,F_2,F_3,F_4]$，其中每个 $F_k$ 是案例 $k$ 的布尔结果。",
            "solution": "用户希望在合成的遥感情境下，为一种可解释性人工智能（XAI）方法评估其忠实度准则。该问题被设计为一个反例，其中视觉上合理的注意力图谱对模型的预测机制并不忠实。该模型是一个二元分类器，它在具有两个不同特征区域（一个中心圆盘和一个边界框）的图像上进行训练。它被明确地构建为仅依赖于边界伪影（该伪影与标签存在虚假相关），而忽略中心区域具有物理意义的信号。\n\n解决方案首先实现问题陈述中定义的所需组件：合成图像生成器、分类器、注意力图谱生成器和忠实度测试。\n\n**1. 预备知识和定义**\n\n给定一个图像 $x \\in \\mathbb{R}^{H \\times W}$。\n分类器由逻辑斯谛函数 $f(x) = \\sigma(z(x)) = (1 + e^{-z(x)})^{-1}$ 定义，其中 $z(x)$ 是对数几率。\n\n图像空间被划分为三组像素索引 $(i,j)$：\n- 边界框 $\\mathcal{B}$，包含与图像边界的最小距离小于 $w_{\\mathrm{bord}}$ 的像素。对于从 $(0,0)$ 到 $(H-1, W-1)$ 的网格，如果 $\\min(i, j, H-1-i, W-1-j)  w_{\\mathrm{bord}}$，则像素 $(i,j)$ 在 $\\mathcal{B}$ 中。\n- 中心圆盘 $\\mathcal{C}$，包含与图像中心 $(i_0, j_0) = (\\frac{H-1}{2}, \\frac{W-1}{2})$ 的距离在半径 $r$ 内的像素。如果 $\\sqrt{(i-i_0)^2 + (j-j_0)^2} \\le r$，则像素 $(i,j)$ 在 $\\mathcal{C}$ 中。\n- 背景，包含所有其他像素。\n\n对数几率 $z(x)$ 是这些区域内像素强度的线性组合：\n$$\nz(x) = \\alpha_b \\sum_{(i,j) \\in \\mathcal{B}} x_{ij} + \\alpha_c \\sum_{(i,j) \\in \\mathcal{C}} x_{ij} + \\beta\n$$\n至关重要的是，对于所有测试案例，中心区域的权重都设置为 $\\alpha_c = 0.0$。这使得分类器 $f(x)$完全依赖于边界像素，并对中心圆盘的内容完全不敏感。\n\n**2. 合成图像生成**\n\n合成图像 $x$ 是基于真实环境标签 $y_{\\mathrm{true}}$ 和虚假标签 $y_{\\mathrm{spur}}$ 生成的。对于此问题，给定 $y_{\\mathrm{spur}} = y_{\\mathrm{true}}$。像素强度 $x_{ij}$ 设置如下：\n- 对于 $(i,j) \\in \\mathcal{B}$（边界）：$x_{ij} = s \\cdot y_{\\mathrm{spur}}$。\n- 对于 $(i,j) \\in \\mathcal{C}$（中心）：$x_{ij} = \\mu_{y_{\\mathrm{true}}} + \\varepsilon_{ij}$，其中 $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ 是高斯噪声。\n- 对于所有其他像素（背景）：$x_{ij} = \\mu_{\\mathrm{bg}}$。\n\n所有测试案例都使用 $y_{\\mathrm{true}}=1$，因此边界强度为 $s$，中心强度约为 $\\mu_1$。\n\n**3. 视觉上合理的注意力图谱**\n\n注意力图谱 $A(x)$ 被定义为视觉上合理，突出中心特征。它结合了一个径向对称的高斯函数 $G$ 和一个局部对比度度量 $S$：\n$$\nG_{ij} = \\exp\\left(-\\frac{(i - i_0)^2 + (j - j_0)^2}{2 \\sigma_g^2}\\right) \\quad \\text{其中 } \\sigma_g = r/2\n$$\n$$\nS_{ij} = \\left|x_{ij} - \\mu_{\\mathrm{bg}}\\right|\n$$\n归一化的注意力图谱为 $A_{ij}(x) = (G_{ij} \\cdot S_{ij}) / \\max_{u,v} (G_{uv} \\cdot S_{uv})$。\n此公式确保了在中心圆盘区域有较高的注意力值，因为在这里 $G_{ij}$ 和 $S_{ij} = |\\mu_1 + \\varepsilon_{ij} - \\mu_{\\mathrm{bg}}|$ 都很大；而在边界处有较低的注意力值，因为 $G_{ij}$ 由于远离中心而非常小。\n\n**4. 使用删除测试进行忠实度评估**\n\n通过比较两种不同的图像扰动对分类器输出的影响来评估注意力图谱 $A(x)$ 的忠实度。使用一个中性参考强度 $\\rho$ 来替换像素。\n\n- **注意力删除**：通过将 $A(x)$ 中注意力值最高的 $\\phi \\cdot H \\cdot W$ 个像素设置为 $\\rho$，创建一个新图像 $x^{\\mathrm{att}}$。分类器输出的变化为 $\\Delta_{\\mathrm{att}} = f(x) - f(x^{\\mathrm{att}})$。由于注意力图谱 $A(x)$ 突出的是中心圆盘且 $\\alpha_c=0$，分类器的对数几率对这些变化是不变的，即 $z(x^{\\mathrm{att}}) = z(x)$。这是因为被删除的像素不在边界集 $\\mathcal{B}$ 中。因此，对于所有测试案例，$\\Delta_{\\mathrm{att}} = 0$。\n\n- **边界删除**：通过将边界集 $\\mathcal{B}$ 中的所有像素设置为 $\\rho$，创建一个新图像 $x^{\\mathrm{bor}}$。输出的变化为 $\\Delta_{\\mathrm{bor}} = f(x) - f(x^{\\mathrm{bor}})$。对数几率从 $z(x) = \\alpha_b \\sum_{\\mathcal{B}} x_{ij} + \\beta$ 变为 $z(x^{\\mathrm{bor}}) = \\alpha_b \\sum_{\\mathcal{B}} \\rho + \\beta$。除非原始边界强度 $s$ 等于 $\\rho$，否则 $\\Delta_{\\mathrm{bor}}$ 将不为零。\n\n忠实度决策 $F$ 是比较 $\\Delta_{\\mathrm{att}} \\ge \\Delta_{\\mathrm{bor}}$ 的真值。代入 $\\Delta_{\\mathrm{att}}=0$，这简化为 $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$。如果删除其突出显示的特征比删除其他特征产生更大或相等的影响，则认为注意力图谱是忠实的。在我们的反例中，我们期望这是假的，从而证明视觉上合理的注意力图谱的失败。\n\n**5. 测试案例分析**\n\n- **案例1**：$s=1.0, \\rho=0.5, \\alpha_b>0$。边界像素值（$1.0$）被替换为更低的值（$0.5$）。这会减小对数几率 $z(x)$，因此 $f(x) > f(x^{\\mathrm{bor}})$ 且 $\\Delta_{\\mathrm{bor}} > 0$。决策 $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$ 的结果为 `False`。\n- **案例2**：$s=0.5, \\rho=0.5$。边界像素值被替换为相同的值。因此，$x = x^{\\mathrm{bor}}$，所以 $\\Delta_{\\mathrm{bor}} = 0$。决策 $F = [0 \\ge 0]$ 的结果为 `True`。\n- **案例3**：$s=1.0, \\rho=0.5, \\alpha_b>0$。与案例1类似，$\\Delta_{\\mathrm{bor}} > 0$。决策 $F$ 的结果为 `False`。\n- **案例4**：$s=0.1, \\rho=0.5, \\alpha_b>0$。边界像素值（$0.1$）被替换为更高的值（$0.5$）。这会增大对数几率 $z(x)$，因此 $f(x)  f(x^{\\mathrm{bor}})$ 且 $\\Delta_{\\mathrm{bor}}  0$。决策 $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$ 的结果为 `True`，因为 $0$ 大于一个负数。\n\n结果证实，忠实度测试正确地识别了模型对边界的依赖性。当移除边界产生显著影响时（$\\Delta_{\\mathrm{bor}} \\ne 0$），视觉上合理的注意力图谱未能通过测试（结果为 `False` 或 `True`，取决于 $\\Delta_{\\mathrm{bor}}$ 的符号），除非在边界强度与替换值相匹配的退化情况下。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a faithfulness criterion for a synthetic XAI counterexample\n    in a remote sensing context.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 1.0, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 2\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 0.5, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 3\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 2, 's': 1.0, 'alpha_b': 0.02, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 4\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 0.1, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n    ]\n\n    # Common parameters across all cases\n    y_true = 1\n    y_spur = 1\n    mu_bg = 0.5\n\n    results = []\n    np.random.seed(0)  # For reproducible noise generation\n\n    for params in test_cases:\n        H, W, r = params['H'], params['W'], params['r']\n        mu_1, sigma = params['mu_1'], params['sigma']\n        w_bord, s = params['w_bord'], params['s']\n        alpha_b, alpha_c, beta = params['alpha_b'], params['alpha_c'], params['beta']\n        phi, rho = params['phi'], params['rho']\n        \n        # --- 1. Define Pixel Sets ---\n        i, j = np.mgrid[0:H, 0:W]\n        i0, j0 = (H - 1) / 2.0, (W - 1) / 2.0\n\n        # Border set B\n        dist_to_boundary = np.minimum.reduce([i, j, H - 1 - i, W - 1 - j])\n        mask_b = dist_to_boundary  w_bord\n\n        # Center disk set C\n        dist_from_center = np.sqrt((i - i0)**2 + (j - j0)**2)\n        mask_c = dist_from_center = r\n\n        # --- 2. Generate Synthetic Image x ---\n        x = np.full((H, W), mu_bg)\n        \n        # Set center disk intensity\n        num_center_pixels = np.sum(mask_c)\n        noise = np.random.normal(0, sigma, size=num_center_pixels)\n        x[mask_c] = mu_1 + noise\n        \n        # Set border intensity\n        x[mask_b] = s * y_spur\n\n        # --- 3. Define Classifier ---\n        def sigmoid(z):\n            return 1.0 / (1.0 + np.exp(-z))\n\n        def predict_proba(image):\n            sum_b = np.sum(image[mask_b])\n            sum_c = np.sum(image[mask_c])\n            z = alpha_b * sum_b + alpha_c * sum_c + beta\n            return sigmoid(z)\n\n        # --- 4. Generate Attention Map A(x) ---\n        sigma_g = r / 2.0\n        G = np.exp(-((i - i0)**2 + (j - j0)**2) / (2 * sigma_g**2))\n        S = np.abs(x - mu_bg)\n        A_unnormalized = G * S\n        A = A_unnormalized / np.max(A_unnormalized)\n\n        # --- 5. Perform Deletion Tests ---\n        f_x = predict_proba(x)\n\n        # Attention deletion\n        x_att = x.copy()\n        num_pixels_to_delete = int(np.round(phi * H * W))\n        flat_indices = np.argpartition(A.flatten(), -num_pixels_to_delete)[-num_pixels_to_delete:]\n        np.put(x_att, flat_indices, rho)\n        f_x_att = predict_proba(x_att)\n        delta_att = f_x - f_x_att\n        \n        # Border deletion\n        x_bor = x.copy()\n        x_bor[mask_b] = rho\n        f_x_bor = predict_proba(x_bor)\n        delta_bor = f_x - f_x_bor\n        \n        # --- 6. Make Faithfulness Decision ---\n        F = delta_att >= delta_bor\n        results.append(F.item())\n\n    # Format output as a list of boolean strings\n    boolean_strings = [str(r) for r in results]\n    print(f\"[{','.join(boolean_strings)}]\")\n\nsolve()\n```"
        }
    ]
}