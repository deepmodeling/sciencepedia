{
    "hands_on_practices": [
        {
            "introduction": "Before building a complex predictive model, a fundamental first step in explanation is to determine which features are informative. Mutual information, a concept from information theory, provides a powerful and model-agnostic way to quantify the statistical dependency between an input feature and the target variable. This exercise will guide you through computing mutual information from a toy dataset, giving you a hands-on feel for how to measure a feature's intrinsic relevance for a classification task in remote sensing.",
            "id": "3811303",
            "problem": "A satellite-based land cover classifier uses a single discretized Near-Infrared (NIR) spectral band as a feature, quantified into three bins $X \\in \\{L, M, H\\}$ corresponding to low, medium, and high reflectance. The target land cover class is $Y \\in \\{F, W, U\\}$ with $F$ for forest, $W$ for water, and $U$ for urban. The following toy dataset comprises $N = 300$ pixels with empirically observed joint counts $n_{x,y}$ between $X$ and $Y$:\n- $n_{L,W} = 80$, $n_{L,F} = 10$, $n_{L,U} = 20$,\n- $n_{M,W} = 18$, $n_{M,F} = 30$, $n_{M,U} = 45$,\n- $n_{H,W} = 2$, $n_{H,F} = 80$, $n_{H,U} = 15$.\nStarting from foundational probability and information-theoretic definitions (without invoking any pre-derived shortcuts), use the empirical joint distribution $p(x,y)$ and the associated marginals $p(x)$ and $p(y)$ induced by the counts above to derive and compute the mutual information $I(X;Y)$ using the natural logarithm $\\ln$. Express your final numerical result in nats, and round your answer to four significant figures. Briefly articulate the implications of the computed value for Explainable Artificial Intelligence (XAI) feature selection in remote sensing, focusing on how $I(X;Y)$ informs the relevance of this NIR band for land cover classification.",
            "solution": "The user wants to compute the mutual information between a feature and a target class and discuss its implications.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   Feature set: $X \\in \\{L, M, H\\}$ (Low, Medium, High NIR reflectance)\n-   Target class set: $Y \\in \\{F, W, U\\}$ (Forest, Water, Urban)\n-   Total number of samples: $N = 300$\n-   Joint counts $n_{x,y}$:\n    -   $n_{L,W} = 80$\n    -   $n_{L,F} = 10$\n    -   $n_{L,U} = 20$\n    -   $n_{M,W} = 18$\n    -   $n_{M,F} = 30$\n    -   $n_{M,U} = 45$\n    -   $n_{H,W} = 2$\n    -   $n_{H,F} = 80$\n    -   $n_{H,U} = 15$\n-   Task: Calculate mutual information $I(X;Y)$ using the natural logarithm $\\ln$.\n-   Task: Round the numerical result to four significant figures.\n-   Task: Articulate the implications of the result for Explainable Artificial Intelligence (XAI) in remote sensing.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientific Grounding**: The problem is scientifically grounded. It applies fundamental concepts from information theory (mutual information) to a standard problem in remote sensing and machine learning (feature relevance analysis for land cover classification). The physical premise that different land covers have different NIR reflectances is correct (e.g., water absorbs NIR, hence low reflectance; healthy vegetation reflects NIR strongly, hence high reflectance).\n-   **Well-Posedness**: The problem is well-posed. It provides a complete set of joint counts for the two variables, which is sufficient to determine the joint and marginal probability distributions required for the calculation. The total count is consistent: $\\sum n_{x,y} = 80+10+20+18+30+45+2+80+15 = 300 = N$. A unique numerical solution exists.\n-   **Objectivity**: The problem is stated using precise, objective, and quantitative language.\n\nThe problem is free of any scientific or factual unsoundness, incompleteness, contradictions, or ambiguity. It represents a standard, formalizable exercise in applied information theory.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\n\nThe mutual information $I(X;Y)$ between two discrete random variables $X$ and $Y$ is defined as the reduction in uncertainty about one variable from knowing the other. It is formally expressed as:\n$$I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) \\log \\left( \\frac{p(x,y)}{p(x)p(y)} \\right)$$\nThe problem specifies the use of the natural logarithm, $\\ln$, so the result will be in units of nats.\n\nFirst, we must compute the empirical joint and marginal probabilities from the given counts. The total number of pixels is $N=300$.\n\n**1. Joint Probabilities $p(x,y)$**\nThe joint probability $p(x,y)$ is the ratio of the joint count $n_{x,y}$ to the total count $N$.\n$p(x,y) = \\frac{n_{x,y}}{N} = \\frac{n_{x,y}}{300}$\nThe matrix of joint probabilities is:\n-   $p(L,W) = \\frac{80}{300}$\n-   $p(L,F) = \\frac{10}{300}$\n-   $p(L,U) = \\frac{20}{300}$\n-   $p(M,W) = \\frac{18}{300}$\n-   $p(M,F) = \\frac{30}{300}$\n-   $p(M,U) = \\frac{45}{300}$\n-   $p(H,W) = \\frac{2}{300}$\n-   $p(H,F) = \\frac{80}{300}$\n-   $p(H,U) = \\frac{15}{300}$\n\n**2. Marginal Probabilities $p(x)$ and $p(y)$**\nThe marginal probabilities are found by summing the joint probabilities over the other variable.\n$p(x) = \\sum_{y \\in Y} p(x,y)$\n-   $p(L) = p(L,W) + p(L,F) + p(L,U) = \\frac{80+10+20}{300} = \\frac{110}{300}$\n-   $p(M) = p(M,W) + p(M,F) + p(M,U) = \\frac{18+30+45}{300} = \\frac{93}{300}$\n-   $p(H) = p(H,W) + p(H,F) + p(H,U) = \\frac{2+80+15}{300} = \\frac{97}{300}$\n\n$p(y) = \\sum_{x \\in X} p(x,y)$\n-   $p(W) = p(L,W) + p(M,W) + p(H,W) = \\frac{80+18+2}{300} = \\frac{100}{300}$\n-   $p(F) = p(L,F) + p(M,F) + p(H,F) = \\frac{10+30+80}{300} = \\frac{120}{300}$\n-   $p(U) = p(L,U) + p(M,U) + p(H,U) = \\frac{20+45+15}{300} = \\frac{80}{300}$\n\n**3. Compute Mutual Information $I(X;Y)$**\nNow we substitute these probabilities into the mutual information formula. The term $\\frac{p(x,y)}{p(x)p(y)}$ simplifies to $\\frac{n_{x,y}/N}{(n_x/N)(n_y/N)} = \\frac{n_{x,y} N}{n_x n_y}$, where $n_x = \\sum_y n_{x,y}$ and $n_y = \\sum_x n_{x,y}$.\n$I(X;Y)$ is the sum of $9$ terms of the form $p(x,y) \\ln \\left(\\frac{p(x,y)}{p(x)p(y)}\\right)$:\n\n$I(X;Y) = $\n$\\frac{80}{300} \\ln\\left(\\frac{80/300}{(110/300)(100/300)}\\right) + \\frac{10}{300} \\ln\\left(\\frac{10/300}{(110/300)(120/300)}\\right) + \\frac{20}{300} \\ln\\left(\\frac{20/300}{(110/300)(80/300)}\\right) +$\n$\\frac{18}{300} \\ln\\left(\\frac{18/300}{(93/300)(100/300)}\\right) + \\frac{30}{300} \\ln\\left(\\frac{30/300}{(93/300)(120/300)}\\right) + \\frac{45}{300} \\ln\\left(\\frac{45/300}{(93/300)(80/300)}\\right) +$\n$\\frac{2}{300} \\ln\\left(\\frac{2/300}{(97/300)(100/300)}\\right) + \\frac{80}{300} \\ln\\left(\\frac{80/300}{(97/300)(120/300)}\\right) + \\frac{15}{300} \\ln\\left(\\frac{15/300}{(97/300)(80/300)}\\right)$\n\nSimplifying the arguments of the logarithms:\n$I(X;Y) = $\n$\\frac{80}{300} \\ln\\left(\\frac{80 \\cdot 300}{110 \\cdot 100}\\right) + \\frac{10}{300} \\ln\\left(\\frac{10 \\cdot 300}{110 \\cdot 120}\\right) + \\frac{20}{300} \\ln\\left(\\frac{20 \\cdot 300}{110 \\cdot 80}\\right) +$\n$\\frac{18}{300} \\ln\\left(\\frac{18 \\cdot 300}{93 \\cdot 100}\\right) + \\frac{30}{300} \\ln\\left(\\frac{30 \\cdot 300}{93 \\cdot 120}\\right) + \\frac{45}{300} \\ln\\left(\\frac{45 \\cdot 300}{93 \\cdot 80}\\right) +$\n$\\frac{2}{300} \\ln\\left(\\frac{2 \\cdot 300}{97 \\cdot 100}\\right) + \\frac{80}{300} \\ln\\left(\\frac{80 \\cdot 300}{97 \\cdot 120}\\right) + \\frac{15}{300} \\ln\\left(\\frac{15 \\cdot 300}{97 \\cdot 80}\\right)$\n\nPerforming the numerical calculations:\n$I(X;Y) = \\frac{1}{300} [ 80 \\ln(2.1818...) + 10 \\ln(0.2272...) + 20 \\ln(0.6818...) +$\n$18 \\ln(0.5806...) + 30 \\ln(0.8064...) + 45 \\ln(1.8145...) +$\n$2 \\ln(0.0618...) + 80 \\ln(2.0618...) + 15 \\ln(0.5800...) ]$\n\n$I(X;Y) \\approx \\frac{1}{300} [ 80(0.78013) + 10(-1.48160) + 20(-0.38289) +$\n$18(-0.54363) + 30(-0.21506) + 45(0.59579) +$\n$2(-2.78290) + 80(0.72363) + 15(-0.54472) ]$\n\n$I(X;Y) \\approx \\frac{1}{300} [ 62.410 - 14.816 - 7.658 - 9.785 - 6.452 + 26.811 - 5.566 + 57.890 - 8.171 ]$\n$I(X;Y) \\approx \\frac{94.663}{300} \\approx 0.315543...$\n\nRounding to four significant figures, we get $0.3155$.\n\n**4. Implications for XAI in Remote Sensing**\n\nThe calculated mutual information, $I(X;Y) \\approx 0.3155$ nats, is a quantitative measure of the statistical dependency between the discretized NIR band ($X$) and the land cover class ($Y$). In the context of Explainable AI (XAI) for feature selection, this value has direct and clear implications:\n\n-   **Quantification of Feature Relevance**: A mutual information of zero would imply that the feature and target are statistically independent, meaning the NIR band offers no information for distinguishing between forest, water, and urban classes. Since $I(X;Y) > 0$, we can state with formal rigor that the NIR band is a relevant feature for this classification task.\n\n-   **Model-Agnostic Explainability**: This calculation is performed on the data distribution itself, independent of any specific machine learning model (e.g., a neural network, a random forest). This provides a fundamental, model-agnostic explanation for the feature's utility. For XAI purposes, this is a powerful statement: the NIR band is inherently informative according to information theory, not just because a complex \"black box\" model happens to use it.\n\n-   **Basis for Feature Selection and Ranking**: In a real-world remote sensing scenario with dozens or hundreds of spectral bands, one could compute $I(X_i; Y)$ for each band $X_i$. These values would allow for a principled ranking of all available features. Bands with higher mutual information would be considered more important. This ranking provides a simple, transparent, and justifiable method for feature selection, a core goal of XAI. For instance, if another spectral band had a mutual information of $0.1$ nats, we could objectively state that this NIR band is approximately three times more informative. The non-zero value of $0.3155$ nats confirms that this NIR band is a valuable candidate for inclusion in a predictive model.",
            "answer": "$$\\boxed{0.3155}$$"
        },
        {
            "introduction": "Shapley values offer a theoretically sound method for attributing a model's prediction to its input features, but their exact calculation is often computationally infeasible for real-world problems. This practice confronts this challenge head-on by exploring the exponential complexity of exact Shapley estimation for high-dimensional remote sensing data. You will then derive the necessary sample size for a Monte Carlo approximation to achieve a desired level of accuracy, a core practical skill for applying these powerful XAI methods.",
            "id": "3811326",
            "problem": "Consider a pixel-wise black-box Environmental Model (EM) used in Remote Sensing (RS) that maps a $d$-dimensional hyperspectral reflectance vector to a scalar output representing an environmental quantity, for example, the probability of deforestation within the pixel. Let the model output be denoted by $f(\\mathbf{x}) \\in [0,1]$ for an input vector $\\mathbf{x} \\in \\mathbb{R}^d$. The interpretability goal is to attribute the prediction of a fixed pixel to its $d$ spectral bands using Explainable Artificial Intelligence (XAI), specifically the Shapley value from cooperative game theory.\n\nDefine the cooperative game value function $v(S)$ for a subset $S \\subseteq \\{1,2,\\dots,d\\}$ as the expected model output when only features in $S$ are revealed and the remaining features are marginalized with respect to a fixed, scientifically selected background distribution of the hyperspectral features for the landscape under study. Precisely, $v(S) = \\mathbb{E}_{\\mathbf{X}_{-S}}[f(\\mathbf{x}_S \\oplus \\mathbf{X}_{-S})]$, where $\\mathbf{x}_S$ denotes the fixed pixel’s values on features in $S$, $\\mathbf{X}_{-S}$ are random features sampled from the background distribution for the remaining coordinates, and $\\oplus$ denotes feature fusion into a full input.\n\nThe Shapley value $\\phi_i$ for feature $i \\in \\{1,2,\\dots,d\\}$ is defined by averaging the marginal contribution of feature $i$ across all subsets $S$ not containing $i$ with appropriate combinatorial weights, equivalently as the expectation of the incremental contribution of $i$ under a uniformly random permutation of the $d$ features. For exact computation across all features, one must evaluate the value function on all coalitions.\n\nTask 1 (computational complexity): Starting from the definition that the Shapley value for each feature aggregates contributions over all coalitions, derive the minimal number of distinct value function evaluations required to compute the exact Shapley values for all $d$ features of a single pixel. Express your answer in terms of $d$ as an integer count of model calls.\n\nTask 2 (sampling scheme with error control): Design a permutation-based Monte Carlo estimator for $\\phi_i$ in which one draws $m$ independent random permutations of $\\{1,2,\\dots,d\\}$, and for each permutation records the marginal contribution of feature $i$ when it is added in the permutation order (with the masked features sampled from the same background distribution used in the definition of $v$). Let the per-sample marginal contribution for feature $i$ be denoted $Y_i^{(t)}$ for $t \\in \\{1,2,\\dots,m\\}$, and the estimator be $\\hat{\\phi}_i = \\frac{1}{m} \\sum_{t=1}^m Y_i^{(t)}$. Suppose the marginal contributions are almost surely bounded in an interval of length $R$, i.e., $Y_i^{(t)} \\in [a,b]$ with $b-a \\le R$ for all $i$ and $t$. For RS probability outputs $f(\\mathbf{x}) \\in [0,1]$, it is physically realistic to take $R=2$ because differences of two values in $[0,1]$ lie in $[-1,1]$, which has length $2$.\n\nUsing only well-tested facts from probability (including Hoeffding’s inequality) and the union bound, derive a sufficient condition on the sample size $m$ (as a function of $d$, $\\epsilon$, $\\delta$, and $R$) that ensures\n$$\n\\mathbb{P}\\Big(\\max_{1 \\le i \\le d} \\big| \\hat{\\phi}_i - \\phi_i \\big| \\le \\epsilon \\Big) \\ge 1 - \\delta,\n$$\nfor any prescribed error tolerance $\\epsilon > 0$ and failure probability $0 < \\delta < 1$. Present $m$ as the smallest integer satisfying your inequality.\n\nProgram specification: Implement a program that, for each test case, computes two outputs:\n- the minimal integer number of distinct value function evaluations required for exact Shapley computation across all $d$ features, and\n- the minimal integer sample size $m$ guaranteeing the above error bound for the sampling scheme.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-element list of integers in the order $[E, M]$, with $E$ denoting the exact evaluation count and $M$ denoting the sample size. For example, $[[E_1,M_1],[E_2,M_2]]$.\n\nUse the following test suite, covering a general case, boundary conditions, and range-bound variability:\n- Case A (general, RS probabilities): $d=5$, $\\epsilon=0.05$, $\\delta=0.05$, $R=2.0$.\n- Case B (boundary in $d$): $d=1$, $\\epsilon=0.05$, $\\delta=0.10$, $R=2.0$.\n- Case C (larger feature set): $d=20$, $\\epsilon=0.02$, $\\delta=0.01$, $R=2.0$.\n- Case D (tighter per-sample range): $d=8$, $\\epsilon=0.02$, $\\delta=0.05$, $R=1.0$.\n\nAll answers must be expressed as integers. The final output format must be a single line string representation of a list of lists as described above.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the fields of explainable artificial intelligence and remote sensing, mathematically well-posed, objective, and contains all necessary information to derive a unique solution for both tasks.\n\nThis solution is presented in two parts, corresponding to the two tasks in the problem statement.\n\nTask 1: Minimal Number of Value Function Evaluations\n\nThe objective is to find the minimal number of distinct evaluations of the value function, $v(S)$, required to compute the exact Shapley values, $\\phi_i$, for all $d$ features of a single data instance.\n\nThe Shapley value for a feature $i$ is defined as a weighted sum of its marginal contributions over all possible coalitions $S$ of features that do not contain $i$:\n$$\n\\phi_i = \\sum_{S \\subseteq \\{1,2,\\dots,d\\} \\setminus \\{i\\}} \\frac{|S|! (d - |S| - 1)!}{d!} \\left[ v(S \\cup \\{i\\}) - v(S) \\right]\n$$\nThis formula explicitly shows that calculating $\\phi_i$ requires the values of the function $v$ for pairs of subsets, namely $S$ and $S \\cup \\{i\\}$. To compute the Shapley values for all features $i \\in \\{1, 2, \\dots, d\\}$, one must be able to compute the marginal contribution of each feature to every possible coalition it could join.\n\nLet $N = \\{1, 2, \\dots, d\\}$ be the set of all features. The domain of the value function $v$ is the power set of $N$, denoted $\\mathcal{P}(N)$, which consists of all possible subsets $S \\subseteq N$. Any given evaluation $v(S)$ contributes to the calculation of $\\phi_i$ for all $i \\in S$ (in the term $v( (S \\setminus \\{i\\}) \\cup \\{i\\} )$) and for all $j \\notin S$ (in the term $v(S)$). Consequently, to compute the exact Shapley values for every feature, the value of $v(S)$ must be known for every subset $S \\in \\mathcal{P}(N)$.\n\nThe number of distinct subsets of a set with $d$ elements is given by the cardinality of its power set, which is $2^d$. This includes the empty set $\\emptyset$ (for which $v(\\emptyset)$ represents the expected model output given no specific feature information, i.e., the baseline) and the full set $N$ (for which $v(N)$ is a single model evaluation on the unaltered input vector, $f(\\mathbf{x})$).\n\nTherefore, the minimal number of distinct value function evaluations, denoted by $E$, required to compute the exact Shapley values for all $d$ features is the total number of subsets of $\\{1, 2, \\dots, d\\}$.\n\n$$\nE = 2^d\n$$\n\nTask 2: Sufficient Sample Size for Monte Carlo Estimation\n\nThe objective is to derive a sufficient condition on the sample size $m$ for a Monte Carlo estimator $\\hat{\\phi}_i$ that guarantees a uniform error bound over all $d$ features. We seek the smallest integer $m$ such that:\n$$\n\\mathbb{P}\\left(\\max_{1 \\le i \\le d} \\left| \\hat{\\phi}_i - \\phi_i \\right| \\le \\epsilon \\right) \\ge 1 - \\delta\n$$\nThis is equivalent to bounding the probability of the complementary event, which constitutes a failure:\n$$\n\\mathbb{P}\\left(\\max_{1 \\le i \\le d} \\left| \\hat{\\phi}_i - \\phi_i \\right| > \\epsilon \\right) \\le \\delta\n$$\nThe event $\\max_{1 \\le i \\le d} |\\hat{\\phi}_i - \\phi_i| > \\epsilon$ is the union of the individual events $\\{|\\hat{\\phi}_i - \\phi_i| > \\epsilon\\}$ for $i=1, \\dots, d$. We can apply the union bound (Boole's inequality):\n$$\n\\mathbb{P}\\left(\\bigcup_{i=1}^d \\left\\{|\\hat{\\phi}_i - \\phi_i| > \\epsilon\\right\\}\\right) \\le \\sum_{i=1}^d \\mathbb{P}\\left(|\\hat{\\phi}_i - \\phi_i| > \\epsilon\\right)\n$$\nThe estimator $\\hat{\\phi}_i = \\frac{1}{m} \\sum_{t=1}^m Y_i^{(t)}$ is the sample mean of $m$ independent and identically distributed random variables $Y_i^{(t)}$, which represent the marginal contribution of feature $i$. By definition, $\\phi_i = \\mathbb{E}[Y_i^{(t)}]$. The problem states that each $Y_i^{(t)}$ is bounded within an interval of length at most $R$.\n\nWe can apply Hoeffding's inequality to bound the probability of the deviation of the sample mean from its expected value for a single feature $i$:\n$$\n\\mathbb{P}\\left(|\\hat{\\phi}_i - \\phi_i| > \\epsilon\\right) \\le 2 \\exp\\left( \\frac{-2m\\epsilon^2}{R^2} \\right)\n$$\nSubstituting this into the union bound inequality gives:\n$$\n\\mathbb{P}\\left(\\max_{1 \\le i \\le d} |\\hat{\\phi}_i - \\phi_i| > \\epsilon\\right) \\le \\sum_{i=1}^d 2 \\exp\\left( \\frac{-2m\\epsilon^2}{R^2} \\right) = 2d \\exp\\left( \\frac{-2m\\epsilon^2}{R^2} \\right)\n$$\nTo satisfy the required confidence level, we set this upper bound to be less than or equal to $\\delta$:\n$$\n2d \\exp\\left( \\frac{-2m\\epsilon^2}{R^2} \\right) \\le \\delta\n$$\nWe now solve this inequality for $m$:\n$$\n\\exp\\left( \\frac{-2m\\epsilon^2}{R^2} \\right) \\le \\frac{\\delta}{2d}\n$$\nTaking the natural logarithm of both sides:\n$$\n\\frac{-2m\\epsilon^2}{R^2} \\le \\ln\\left(\\frac{\\delta}{2d}\\right)\n$$\nMultiplying by $-1$ reverses the inequality sign:\n$$\n\\frac{2m\\epsilon^2}{R^2} \\ge -\\ln\\left(\\frac{\\delta}{2d}\\right) = \\ln\\left(\\left(\\frac{\\delta}{2d}\\right)^{-1}\\right) = \\ln\\left(\\frac{2d}{\\delta}\\right)\n$$\nFinally, isolating $m$ gives the sufficient condition:\n$$\nm \\ge \\frac{R^2}{2\\epsilon^2} \\ln\\left( \\frac{2d}{\\delta} \\right)\n$$\nThe problem asks for the minimal integer sample size, which we denote by $M$. This is found by taking the ceiling of the right-hand side of the inequality.\n\n$$\nM = \\left\\lceil \\frac{R^2}{2\\epsilon^2} \\ln\\left( \\frac{2d}{\\delta} \\right) \\right\\rceil\n$$\nThese formulae for $E$ and $M$ will be implemented to solve the test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the exact evaluation count and Monte Carlo sample size for Shapley value estimation.\n\n    Task 1 (Exact Computation):\n    The exact Shapley values for d features require evaluating the value function v(S) for all\n    possible subsets S of the features. The number of subsets of a set of size d is 2^d.\n    Thus, the minimal number of evaluations is E = 2**d.\n\n    Task 2 (Monte Carlo Sampling):\n    Using Hoeffding's inequality and the union bound, we derived a sufficient sample size m\n    to guarantee that the maximum error across all d features is at most epsilon with probability at least 1-delta.\n    The formula is: m >= (R**2 / (2 * epsilon**2)) * ln(2 * d / delta).\n    The minimal integer sample size M is the ceiling of this value.\n    \"\"\"\n\n    # Test cases defined in the problem statement.\n    # Each case is a tuple: (d, epsilon, delta, R)\n    test_cases = [\n        (5, 0.05, 0.05, 2.0),  # Case A\n        (1, 0.05, 0.10, 2.0),  # Case B\n        (20, 0.02, 0.01, 2.0), # Case C\n        (8, 0.02, 0.05, 1.0)   # Case D\n    ]\n\n    results = []\n    for d, epsilon, delta, R in test_cases:\n        # Task 1: Minimal number of distinct value function evaluations (E).\n        # Python's int can handle arbitrarily large integers, so 2**d is safe.\n        E = 2**d\n\n        # Task 2: Minimal integer sample size (M).\n        # We must ensure that the argument to the logarithm is positive.\n        # Given delta > 0 and d >= 1, (2 * d / delta) is always positive.\n        log_term = np.log(2.0 * d / delta)\n        m_float = (R**2 / (2.0 * epsilon**2)) * log_term\n        \n        # M must be the smallest integer satisfying the condition.\n        M = int(np.ceil(m_float))\n\n        results.append([E, M])\n\n    # The final print statement must produce the single-line format specified.\n    # The str() of a list like [1, 2] is '[1, 2]'. Joining these with commas\n    # and wrapping with brackets gives the required format '[[1, 2],[3, 4]]'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "An explanation that appears intuitive or 'plausible' is not necessarily a 'faithful' representation of the model's internal logic, a critical distinction in XAI. This exercise demonstrates this potential pitfall by having you construct a counterexample where a visually convincing attention map is misleading. By implementing a deletion-based faithfulness test, you will learn how to programmatically verify whether an explanation truly reflects the model's predictive mechanism, a crucial step in avoiding misinterpretation of complex models.",
            "id": "3811355",
            "problem": "You are asked to construct and analyze a synthetic counterexample, in the context of Explainable Artificial Intelligence (XAI) for remote sensing and environmental models, where visually plausible attention maps are not faithful to the true predictive mechanism of a classifier. The remote sensing motivation is a known edge artifact: a spuriously predictive border, such as a sensor frame or stitching seam, that correlates with a target label but does not reflect the underlying environmental phenomenon inside the scene. The goal is to derive, implement, and test a principled faithfulness criterion that demonstrates the failure of visually plausible attention.\n\nStart from the following fundamental bases and definitions. A binary classifier $f$ on an image $x \\in \\mathbb{R}^{H \\times W}$ with output $f(x) \\in [0,1]$ is defined by the logistic function\n$$\nf(x) \\triangleq \\sigma(z(x)) = \\frac{1}{1 + e^{-z(x)}},\n$$\nwhere the logit $z(x)$ is a linear function of two spatial feature sets: a border frame and an interior center disk. Let $\\mathcal{B}$ denote the set of border pixels of width $w_{\\mathrm{bord}}$ (all pixels whose minimum distance to the image boundary is strictly less than $w_{\\mathrm{bord}}$), and let $\\mathcal{C}$ denote the set of pixels inside a disk of radius $r$ centered at the image center. The logit is\n$$\nz(x) = \\alpha_b \\sum_{(i,j) \\in \\mathcal{B}} x_{ij} + \\alpha_c \\sum_{(i,j) \\in \\mathcal{C}} x_{ij} + \\beta,\n$$\nwith parameters $\\alpha_b \\in \\mathbb{R}$, $\\alpha_c \\in \\mathbb{R}$, and bias $\\beta \\in \\mathbb{R}$. The synthetic dataset is generated by composing three parts: a background with constant intensity, a center disk whose intensity reflects a plausible environmental signal (e.g., vegetation greenness), and a border frame that spuriously encodes the label. Precisely:\n- Background intensity is set to $\\mu_{\\mathrm{bg}}$ for all $(i,j) \\notin \\mathcal{C} \\cup \\mathcal{B}$.\n- Center disk intensity for $(i,j) \\in \\mathcal{C}$ is set to $\\mu_{y_{\\mathrm{true}}} + \\varepsilon_{ij}$, where $y_{\\mathrm{true}} \\in \\{0,1\\}$ is the underlying environmental label, $\\mu_{1} > \\mu_{0}$, and $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ is independent pixel noise.\n- Border intensity for $(i,j) \\in \\mathcal{B}$ is set to $s \\cdot y_{\\mathrm{spur}}$, where $y_{\\mathrm{spur}} \\in \\{0,1\\}$ is a spuriously predictive label; for this counterexample, take $y_{\\mathrm{spur}} = y_{\\mathrm{true}}$ so the border is perfectly predictive during training, even though it is non-causal.\n\nDefine a visually plausible attention map $A(x)$ that highlights the center disk by combining a radially symmetric Gaussian centered at the image midpoint with the local contrast relative to the background:\n$$\nG_{ij} = \\exp\\left(-\\frac{(i - i_0)^2 + (j - j_0)^2}{2 \\sigma_g^2}\\right), \\quad S_{ij} = \\left|x_{ij} - \\mu_{\\mathrm{bg}}\\right|, \\quad A_{ij}(x) = \\frac{G_{ij} \\cdot S_{ij}}{\\max_{u,v} (G_{uv} \\cdot S_{uv})},\n$$\nwhere $(i_0,j_0)$ is the image center and $\\sigma_g$ is a Gaussian width. This attention is visually plausible in environmental imaging, as it tends to highlight the central phenomenon, but it is not necessarily faithful to the classifier $f$ if $f$ relies on the border.\n\nUse the deletion-based faithfulness test. For a fraction $\\phi \\in (0,1)$ and a neutral reference intensity $\\rho$, define two perturbations:\n1. Attention deletion: set the top $\\phi \\cdot H \\cdot W$ pixels by $A_{ij}(x)$ to $\\rho$, yielding $x^{\\mathrm{att}}$; compute $\\Delta_{\\mathrm{att}} = f(x) - f(x^{\\mathrm{att}})$.\n2. Border deletion: set all $(i,j) \\in \\mathcal{B}$ to $\\rho$, yielding $x^{\\mathrm{bor}}$; compute $\\Delta_{\\mathrm{bor}} = f(x) - f(x^{\\mathrm{bor}})$.\n\nDefine the faithfulness decision $F$ as the boolean\n$$\nF = \\left[\\Delta_{\\mathrm{att}} \\ge \\Delta_{\\mathrm{bor}}\\right],\n$$\nwhere $[\\cdot]$ denotes the truth value. A faithful attention should produce a larger drop than deleting features that the model does not rely on; in this counterexample, we expect deletion of the spuriously predictive border to reduce the prediction more than deleting the attention-highlighted center, thus $F$ should be false in most cases.\n\nYour program must implement the synthetic generator, classifier, attention, and deletion tests exactly as defined, and evaluate the following test suite. For each case, use $y_{\\mathrm{true}} = 1$, $y_{\\mathrm{spur}} = 1$, $\\mu_{\\mathrm{bg}} = 0.5$, and $\\sigma_g = r/2$. In all cases, express intensities as unitless decimals.\n\nTest Suite (four cases):\n- Case $1$: $H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 1.0$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$.\n- Case $2$: $H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 0.5$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$.\n- Case $3$: $H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 2$, $s = 1.0$, $\\alpha_b = 0.02$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$.\n- Case $4$: $H = 32$, $W = 32$, $r = 8$, $\\mu_{1} = 0.8$, $\\mu_{0} = 0.2$, $\\sigma = 0.01$, $w_{\\mathrm{bord}} = 1$, $s = 0.1$, $\\alpha_b = 0.03$, $\\alpha_c = 0.0$, $\\beta = -1.0$, $\\phi = 0.15$, $\\rho = 0.5$.\n\nYour program should produce a single line of output containing the faithfulness decisions for the four cases as a comma-separated list enclosed in square brackets, e.g., $[F_1,F_2,F_3,F_4]$, where each $F_k$ is the boolean result for case $k$.",
            "solution": "The user wishes to evaluate a faithfulness criterion for an Explainable AI (XAI) method in a synthetic remote sensing context. The problem is designed as a counterexample where a visually plausible attention map is not faithful to the model's predictive mechanism. The model is a binary classifier trained on images with two distinct feature regions: a central disk and a border frame. It is explicitly constructed to rely solely on the border artifact, which is spuriously correlated with the label, while ignoring the physically meaningful signal in the center.\n\nThe solution proceeds by first implementing the required components as defined in the problem statement: the synthetic image generator, the classifier, the attention map generator, and the faithfulness test.\n\n**1. Preliminaries and Definitions**\n\nWe are given an image $x \\in \\mathbb{R}^{H \\times W}$.\nThe classifier is defined by the logistic function $f(x) = \\sigma(z(x)) = (1 + e^{-z(x)})^{-1}$, where $z(x)$ is the logit.\n\nThe image space is partitioned into three sets of pixel indices $(i,j)$:\n- The border frame, $\\mathcal{B}$, contains pixels whose minimum distance to the image boundary is less than $w_{\\mathrm{bord}}$. For a grid from $(0,0)$ to $(H-1, W-1)$, a pixel $(i,j)$ is in $\\mathcal{B}$ if $\\min(i, j, H-1-i, W-1-j) < w_{\\mathrm{bord}}$.\n- The center disk, $\\mathcal{C}$, contains pixels within a radius $r$ of the image center $(i_0, j_0) = (\\frac{H-1}{2}, \\frac{W-1}{2})$. A pixel $(i,j)$ is in $\\mathcal{C}$ if $\\sqrt{(i-i_0)^2 + (j-j_0)^2} \\le r$.\n- The background, which comprises all other pixels.\n\nThe logit $z(x)$ is a linear combination of pixel intensities within these regions:\n$$\nz(x) = \\alpha_b \\sum_{(i,j) \\in \\mathcal{B}} x_{ij} + \\alpha_c \\sum_{(i,j) \\in \\mathcal{C}} x_{ij} + \\beta\n$$\nCrucially, for all test cases, the weight for the center region is set to $\\alpha_c = 0.0$. This makes the classifier $f(x)$ entirely dependent on the border pixels and completely insensitive to the center disk's content.\n\n**2. Synthetic Image Generation**\n\nA synthetic image $x$ is generated based on a true environmental label $y_{\\mathrm{true}}$ and a spurious label $y_{\\mathrm{spur}}$. For this problem, we are given $y_{\\mathrm{spur}} = y_{\\mathrm{true}}$. The pixel intensities $x_{ij}$ are set as follows:\n- For $(i,j) \\in \\mathcal{B}$ (border): $x_{ij} = s \\cdot y_{\\mathrm{spur}}$.\n- For $(i,j) \\in \\mathcal{C}$ (center): $x_{ij} = \\mu_{y_{\\mathrm{true}}} + \\varepsilon_{ij}$, where $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ is Gaussian noise.\n- For all other pixels (background): $x_{ij} = \\mu_{\\mathrm{bg}}$.\n\nAll test cases use $y_{\\mathrm{true}}=1$, so the border intensity is $s$ and the center intensity is approximately $\\mu_1$.\n\n**3. Visually Plausible Attention Map**\n\nAn attention map $A(x)$ is defined to be visually plausible, highlighting the central feature. It combines a radially symmetric Gaussian $G$ with a local contrast measure $S$:\n$$\nG_{ij} = \\exp\\left(-\\frac{(i - i_0)^2 + (j - j_0)^2}{2 \\sigma_g^2}\\right) \\quad \\text{with } \\sigma_g = r/2\n$$\n$$\nS_{ij} = \\left|x_{ij} - \\mu_{\\mathrm{bg}}\\right|\n$$\nThe normalized attention map is $A_{ij}(x) = (G_{ij} \\cdot S_{ij}) / \\max_{u,v} (G_{uv} \\cdot S_{uv})$.\nThis formulation ensures high attention values in the center disk, where both $G_{ij}$ and $S_{ij} = |\\mu_1 + \\varepsilon_{ij} - \\mu_{\\mathrm{bg}}|$ are large, and low values at the border, where $G_{ij}$ is very small due to the distance from the center.\n\n**4. Faithfulness Evaluation using Deletion Tests**\n\nThe faithfulness of the attention map $A(x)$ is evaluated by comparing the effect of two different image perturbations on the classifier's output. A neutral reference intensity $\\rho$ is used to replace pixels.\n\n- **Attention Deletion**: A new image $x^{\\mathrm{att}}$ is created by setting the top $\\phi \\cdot H \\cdot W$ pixels with the highest attention values in $A(x)$ to $\\rho$. The change in the classifier's output is $\\Delta_{\\mathrm{att}} = f(x) - f(x^{\\mathrm{att}})$. Since the attention map $A(x)$ highlights the central disk and $\\alpha_c=0$, the classifier's logit is invariant to these changes, i.e., $z(x^{\\mathrm{att}}) = z(x)$. This is because the deleted pixels are not in the border set $\\mathcal{B}$. Therefore, $\\Delta_{\\mathrm{att}} = 0$ for all test cases.\n\n- **Border Deletion**: A new image $x^{\\mathrm{bor}}$ is created by setting all pixels in the border set $\\mathcal{B}$ to $\\rho$. The change in output is $\\Delta_{\\mathrm{bor}} = f(x) - f(x^{\\mathrm{bor}})$. The logit changes from $z(x) = \\alpha_b \\sum_{\\mathcal{B}} x_{ij} + \\beta$ to $z(x^{\\mathrm{bor}}) = \\alpha_b \\sum_{\\mathcal{B}} \\rho + \\beta$. Unless the original border intensity $s$ equals $\\rho$, $\\Delta_{\\mathrm{bor}}$ will be non-zero.\n\nThe faithfulness decision $F$ is the truth value of the comparison $\\Delta_{\\mathrm{att}} \\ge \\Delta_{\\mathrm{bor}}$. Substituting $\\Delta_{\\mathrm{att}}=0$, this simplifies to $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$. An attention map is considered faithful if deleting its highlighted features has a greater or equal impact than deleting other features. In our counterexample, we expect this to be false, demonstrating the failure of the visually plausible attention map.\n\n**5. Analysis of Test Cases**\n\n- **Case 1**: $s=1.0, \\rho=0.5, \\alpha_b>0$. The border pixel values ($1.0$) are replaced with a lower value ($0.5$). This decreases the logit $z(x)$, so $f(x) > f(x^{\\mathrm{bor}})$ and $\\Delta_{\\mathrm{bor}} > 0$. The decision $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$ is `False`.\n- **Case 2**: $s=0.5, \\rho=0.5$. The border pixel values are replaced with the same value. Thus, $x = x^{\\mathrm{bor}}$, so $\\Delta_{\\mathrm{bor}} = 0$. The decision $F = [0 \\ge 0]$ is `True`.\n- **Case 3**: $s=1.0, \\rho=0.5, \\alpha_b>0$. Similar to Case 1, $\\Delta_{\\mathrm{bor}} > 0$. The decision $F$ is `False`.\n- **Case 4**: $s=0.1, \\rho=0.5, \\alpha_b>0$. The border pixel values ($0.1$) are replaced with a higher value ($0.5$). This increases the logit $z(x)$, so $f(x) < f(x^{\\mathrm{bor}})$ and $\\Delta_{\\mathrm{bor}} < 0$. The decision $F = [0 \\ge \\Delta_{\\mathrm{bor}}]$ is `True`, as $0$ is greater than a negative number.\n\nThe results confirm that the faithfulness test correctly identifies the model's reliance on the border. When removing the border has a significant effect ($\\Delta_{\\mathrm{bor}} \\ne 0$), the visually plausible attention fails the test (results are `False` or `True` depending on the sign of $\\Delta_{\\mathrm{bor}}$), except in the degenerate case where the border intensity matches the replacement value.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a faithfulness criterion for a synthetic XAI counterexample\n    in a remote sensing context.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 1.0, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 2\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 0.5, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 3\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 2, 's': 1.0, 'alpha_b': 0.02, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n        # Case 4\n        {'H': 32, 'W': 32, 'r': 8, 'mu_1': 0.8, 'mu_0': 0.2, 'sigma': 0.01,\n         'w_bord': 1, 's': 0.1, 'alpha_b': 0.03, 'alpha_c': 0.0, 'beta': -1.0,\n         'phi': 0.15, 'rho': 0.5},\n    ]\n\n    # Common parameters across all cases\n    y_true = 1\n    y_spur = 1\n    mu_bg = 0.5\n\n    results = []\n    np.random.seed(0)  # For reproducible noise generation\n\n    for params in test_cases:\n        H, W, r = params['H'], params['W'], params['r']\n        mu_1, sigma = params['mu_1'], params['sigma']\n        w_bord, s = params['w_bord'], params['s']\n        alpha_b, alpha_c, beta = params['alpha_b'], params['alpha_c'], params['beta']\n        phi, rho = params['phi'], params['rho']\n        \n        # --- 1. Define Pixel Sets ---\n        i, j = np.mgrid[0:H, 0:W]\n        i0, j0 = (H - 1) / 2.0, (W - 1) / 2.0\n\n        # Border set B\n        dist_to_boundary = np.minimum.reduce([i, j, H - 1 - i, W - 1 - j])\n        mask_b = dist_to_boundary < w_bord\n\n        # Center disk set C\n        dist_from_center = np.sqrt((i - i0)**2 + (j - j0)**2)\n        mask_c = dist_from_center <= r\n\n        # --- 2. Generate Synthetic Image x ---\n        x = np.full((H, W), mu_bg)\n        \n        # Set center disk intensity\n        num_center_pixels = np.sum(mask_c)\n        noise = np.random.normal(0, sigma, size=num_center_pixels)\n        x[mask_c] = mu_1 + noise\n        \n        # Set border intensity\n        x[mask_b] = s * y_spur\n\n        # --- 3. Define Classifier ---\n        def sigmoid(z):\n            return 1.0 / (1.0 + np.exp(-z))\n\n        def predict_proba(image):\n            sum_b = np.sum(image[mask_b])\n            sum_c = np.sum(image[mask_c])\n            z = alpha_b * sum_b + alpha_c * sum_c + beta\n            return sigmoid(z)\n\n        # --- 4. Generate Attention Map A(x) ---\n        sigma_g = r / 2.0\n        G = np.exp(-((i - i0)**2 + (j - j0)**2) / (2 * sigma_g**2))\n        S = np.abs(x - mu_bg)\n        A_unnormalized = G * S\n        A = A_unnormalized / np.max(A_unnormalized)\n\n        # --- 5. Perform Deletion Tests ---\n        f_x = predict_proba(x)\n\n        # Attention deletion\n        x_att = x.copy()\n        num_pixels_to_delete = int(np.round(phi * H * W))\n        flat_indices = np.argpartition(A.flatten(), -num_pixels_to_delete)[-num_pixels_to_delete:]\n        np.put(x_att, flat_indices, rho)\n        f_x_att = predict_proba(x_att)\n        delta_att = f_x - f_x_att\n        \n        # Border deletion\n        x_bor = x.copy()\n        x_bor[mask_b] = rho\n        f_x_bor = predict_proba(x_bor)\n        delta_bor = f_x - f_x_bor\n        \n        # --- 6. Make Faithfulness Decision ---\n        F = delta_att >= delta_bor\n        results.append(F.item())\n\n    # Format output as a list of boolean strings\n    boolean_strings = [str(r) for r in results]\n    print(f\"[{','.join(boolean_strings)}]\")\n\nsolve()\n```"
        }
    ]
}