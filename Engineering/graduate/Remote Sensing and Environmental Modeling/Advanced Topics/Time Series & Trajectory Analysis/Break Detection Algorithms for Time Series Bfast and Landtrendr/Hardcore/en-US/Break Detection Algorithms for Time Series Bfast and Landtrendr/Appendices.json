{
    "hands_on_practices": [
        {
            "introduction": "At their core, break detection algorithms are sophisticated search procedures built on a simple statistical foundation. This exercise  takes you back to that foundation by asking you to derive the maximum likelihood estimator for a single change-point from first principles. Mastering this derivation provides a deep, transferable understanding of the optimization criteria that power modern algorithms like BFAST and LandTrendr.",
            "id": "3799277",
            "problem": "A remote sensing analyst is studying annual Normalized Difference Vegetation Index (NDVI) for a forested pixel potentially disturbed by a clearing event. The analyst aims to connect the statistical estimator for a single mean break under Gaussian errors to the operational logic used by Breaks For Additive Season and Trend (BFAST) and Landsat-based Detection of Trends in Disturbance and Recovery (LandTrendr). Consider a univariate time series $\\{x_t\\}_{t=1}^{n}$ modeled as\n$$\nx_t =\n\\begin{cases}\n\\mu_1 + \\varepsilon_t,  t \\le \\tau, \\\\\n\\mu_2 + \\varepsilon_t,  t  \\tau,\n\\end{cases}\n$$\nwhere $\\varepsilon_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2)$, the variance $\\sigma^2$ is known, and the change-point index $\\tau$ is an unknown integer satisfying $2 \\le \\tau \\le n-1$. Assume the errors are independent across $t$ and the Gaussian model is correctly specified. Starting from the likelihood for independent Gaussian observations, derive the maximum likelihood estimator for $\\tau$ by profiling out $\\mu_1$ and $\\mu_2$. In your derivation, do not assume any specialized change-point test statistics; begin with the Gaussian likelihood and proceed by first principles. Then, articulate how this estimator generalizes to a single change in slope in a piecewise-linear trend model with a continuity constraint at the break, and briefly relate this generalization to the estimation logic employed in BFAST and LandTrendr.\n\nFinally, apply your derived estimator to the following NDVI time series with $n=12$ annual observations (values are effectively unitless, but bounded between $0$ and $1$):\n$$\nx_1 = 0.75,\\; x_2 = 0.75,\\; x_3 = 0.75,\\; x_4 = 0.75,\\; x_5 = 0.75,\\; x_6 = 0.75,\\; x_7 = 0.55,\\; x_8 = 0.55,\\; x_9 = 0.55,\\; x_{10} = 0.55,\\; x_{11} = 0.55,\\; x_{12} = 0.55.\n$$\nReport the integer index $\\hat{\\tau}$ that maximizes the likelihood criterion you derived. Express the final answer as an integer with no units. No rounding instruction is required because the answer is an integer.",
            "solution": "The foundational base is the Gaussian likelihood for independent observations. Under the model\n$$\nx_t =\n\\begin{cases}\n\\mu_1 + \\varepsilon_t,  t \\le \\tau, \\\\\n\\mu_2 + \\varepsilon_t,  t  \\tau,\n\\end{cases}\n\\quad\\text{with}\\quad \\varepsilon_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2),\n$$\nthe joint likelihood for a candidate change-point $\\tau$ is\n$$\nL(\\mu_1,\\mu_2,\\tau) = \\prod_{t=1}^{\\tau} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x_t - \\mu_1)^2}{2\\sigma^2}\\right) \\cdot \\prod_{t=\\tau+1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x_t - \\mu_2)^2}{2\\sigma^2}\\right).\n$$\nThe log-likelihood is\n$$\n\\ell(\\mu_1,\\mu_2,\\tau) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\left( \\sum_{t=1}^{\\tau} (x_t - \\mu_1)^2 + \\sum_{t=\\tau+1}^{n} (x_t - \\mu_2)^2 \\right).\n$$\nFor a fixed $\\tau$, the maximum likelihood estimators of $\\mu_1$ and $\\mu_2$ are the sample means on their respective segments, obtained by setting partial derivatives to zero:\n$$\n\\hat{\\mu}_1(\\tau) = \\frac{1}{\\tau} \\sum_{t=1}^{\\tau} x_t, \\qquad \\hat{\\mu}_2(\\tau) = \\frac{1}{n-\\tau} \\sum_{t=\\tau+1}^{n} x_t.\n$$\nPlugging these into $\\ell$ yields the profile log-likelihood\n$$\n\\ell_{\\text{prof}}(\\tau) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\left( \\sum_{t=1}^{\\tau} (x_t - \\hat{\\mu}_1(\\tau))^2 + \\sum_{t=\\tau+1}^{n} (x_t - \\hat{\\mu}_2(\\tau))^2 \\right).\n$$\nBecause $-\\frac{n}{2}\\ln(2\\pi\\sigma^2)$ is constant in $\\tau$, maximizing $\\ell_{\\text{prof}}(\\tau)$ is equivalent to minimizing the within-segment sum of squared errors\n$$\n\\text{SSE}(\\tau) = \\sum_{t=1}^{\\tau} (x_t - \\hat{\\mu}_1(\\tau))^2 + \\sum_{t=\\tau+1}^{n} (x_t - \\hat{\\mu}_2(\\tau))^2.\n$$\nIt is often convenient to express $\\text{SSE}(\\tau)$ relative to the single-mean model. Let $\\bar{x} = \\frac{1}{n}\\sum_{t=1}^{n} x_t$ be the overall mean. Then the reduction in sum of squares from splitting at $\\tau$ is\n$$\n\\Delta(\\tau) = \\sum_{t=1}^{n} (x_t - \\bar{x})^2 - \\text{SSE}(\\tau).\n$$\nA standard projection argument in least squares shows\n$$\n\\Delta(\\tau) = \\frac{\\tau(n-\\tau)}{n}\\left(\\hat{\\mu}_1(\\tau) - \\hat{\\mu}_2(\\tau)\\right)^2.\n$$\nTherefore, minimizing $\\text{SSE}(\\tau)$ is equivalent to maximizing $\\Delta(\\tau)$, or equivalently maximizing\n$$\nJ(\\tau) = \\tau(n-\\tau)\\left(\\hat{\\mu}_1(\\tau) - \\hat{\\mu}_2(\\tau)\\right)^2.\n$$\nThe maximum likelihood estimator of the change-point is thus\n$$\n\\hat{\\tau} = \\arg\\max_{2 \\le \\tau \\le n-1} \\; \\tau(n-\\tau)\\left(\\hat{\\mu}_1(\\tau) - \\hat{\\mu}_2(\\tau)\\right)^2.\n$$\n\nExtension to a single change in slope: Consider the piecewise-linear model with a continuity constraint at the break,\n$$\nx_t =\n\\begin{cases}\n\\alpha + \\beta_1 t + \\varepsilon_t,  t \\le \\tau, \\\\\n\\alpha + \\beta_1 \\tau + \\beta_2 (t-\\tau) + \\varepsilon_t,  t  \\tau,\n\\end{cases}\n$$\nwith $\\varepsilon_t \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2)$ and known $\\sigma^2$. For fixed $\\tau$, the parameters $(\\alpha,\\beta_1,\\beta_2)$ enter linearly, so the maximum likelihood estimators are the ordinary least squares solutions to the normal equations based on the design matrix that includes columns for the intercept, $t$, and the segmented regressor $(t-\\tau)_{+}$ where $(t-\\tau)_{+} = \\max\\{0, t-\\tau\\}$. Profiling out $(\\alpha,\\beta_1,\\beta_2)$ yields a profile log-likelihood\n$$\n\\ell_{\\text{prof}}^{\\text{slope}}(\\tau) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\text{SSE}^{\\text{slope}}(\\tau),\n$$\nwhere $\\text{SSE}^{\\text{slope}}(\\tau)$ is the residual sum of squares from the segmented regression fit at $\\tau$. Thus,\n$$\n\\hat{\\tau}_{\\text{slope}} = \\arg\\min_{2 \\le \\tau \\le n-1} \\; \\text{SSE}^{\\text{slope}}(\\tau).\n$$\nThis generalization connects to Breaks For Additive Season and Trend (BFAST) and Landsat-based Detection of Trends in Disturbance and Recovery (LandTrendr) in the following way: BFAST decomposes a time series into trend, seasonal, and remainder components, then tests for structural changes in each component by comparing fits over segments; operationally, this aligns with minimizing segment-wise residual sums of squares over candidate breakpoints in the trend component. LandTrendr fits a sequence of linear segments to spectral indices with unknown breakpoints, selecting the number and locations of breaks to minimize an overall cost based on residual variance and model parsimony. In both, the core estimation logic for a single slope change is consistent with selecting $\\tau$ that optimizes a segmented linear least squares criterion.\n\nApplication to the provided NDVI series: Let $n=12$ and\n$$\nx_1 = 0.75,\\; x_2 = 0.75,\\; x_3 = 0.75,\\; x_4 = 0.75,\\; x_5 = 0.75,\\; x_6 = 0.75,\\; x_7 = 0.55,\\; x_8 = 0.55,\\; x_9 = 0.55,\\; x_{10} = 0.55,\\; x_{11} = 0.55,\\; x_{12} = 0.55.\n$$\nDefine $a = 0.75$ for $t \\le 6$ and $b = 0.55$ for $t  6$. For a given $\\tau$, the segment means are\n$$\n\\hat{\\mu}_1(\\tau) =\n\\begin{cases}\na,  \\tau \\le 6, \\\\\n\\frac{6a + (\\tau - 6)b}{\\tau},  \\tau \\ge 6,\n\\end{cases}\n\\qquad\n\\hat{\\mu}_2(\\tau) =\n\\begin{cases}\n\\frac{(6 - \\tau)a + 6b}{12 - \\tau},  \\tau \\le 6, \\\\\nb,  \\tau \\ge 6.\n\\end{cases}\n$$\nHence, for $\\tau \\le 6$,\n$$\n\\hat{\\mu}_1(\\tau) - \\hat{\\mu}_2(\\tau) = a - \\frac{(6 - \\tau)a + 6b}{12 - \\tau} = \\frac{6(a - b)}{12 - \\tau},\n$$\nand for $\\tau \\ge 6$,\n$$\n\\hat{\\mu}_1(\\tau) - \\hat{\\mu}_2(\\tau) = \\frac{6a + (\\tau - 6)b}{\\tau} - b = \\frac{6(a - b)}{\\tau}.\n$$\nTherefore, the objective $J(\\tau)$ becomes\n$$\nJ(\\tau) =\n\\begin{cases}\n\\tau(12 - \\tau)\\left(\\frac{6(a - b)}{12 - \\tau}\\right)^2 = 36(a - b)^2 \\cdot \\frac{\\tau}{12 - \\tau},  \\tau \\le 6, \\\\\n\\tau(12 - \\tau)\\left(\\frac{6(a - b)}{\\tau}\\right)^2 = 36(a - b)^2 \\cdot \\frac{12 - \\tau}{\\tau},  \\tau \\ge 6.\n\\end{cases}\n$$\nBoth expressions are monotone in $\\tau$ on their respective domains: for $\\tau \\le 6$, $J(\\tau)$ increases with $\\tau$; for $\\tau \\ge 6$, $J(\\tau)$ decreases with $\\tau$. Thus $J(\\tau)$ is maximized at $\\tau = 6$. Since $a - b = 0.20$, one can also compute\n$$\nJ(6) = 6 \\cdot 6 \\cdot (0.20)^2 = 36 \\cdot 0.04 = 1.44,\n$$\nand for any $\\tau \\neq 6$, $J(\\tau)  1.44$ by the monotonicity established above. Hence, the maximum likelihood change-point estimate is\n$$\n\\hat{\\tau} = 6.\n$$",
            "answer": "$$\\boxed{6}$$"
        },
        {
            "introduction": "A detected break is only the beginning of the scientific inquiry; the next step is to quantify and interpret it. This practice  moves from detection to ecological characterization, challenging you to deconstruct an observed change into its underlying components. By isolating the disturbance signal from background trend and seasonality, you will learn to calculate a physically meaningful rate of change and connect it to distinct ecological scenarios.",
            "id": "3799342",
            "problem": "A single pixel's Normalized Burn Ratio (NBR) time series, denoted by $y(t)$, is decomposed additively following the Breaks For Additive Seasonal and Trend (BFAST) framework: $y(t) = \\tau(t) + S(t) + \\varepsilon(t)$, where $\\tau(t)$ is a slowly varying trend, $S(t)$ is a periodic seasonal component, and $\\varepsilon(t)$ is a stochastic residual. Prior to a disturbance, the trend is well-approximated locally by the linear form $\\tau(t) = a + b\\,t$. The seasonal component is modeled by its first harmonic, $S(t) = C \\cos(2\\pi t) + D \\sin(2\\pi t)$, with $t$ measured in years so that the period is $1$ year. A disturbance window $[t_b, t_e]$ is identified by Landsat-based detection of Trends and Disturbance (LandTrendr) as a single monotonic linear segment between vertices at $t_b$ and $t_e$. Within this window, you are provided:\n- Pre-break trend slope $b = 0.005$ (index units per year),\n- Seasonal coefficients $C = 0.10$ and $D = 0.05$,\n- Break time $t_b = 2015.25$ and end time $t_e = 2015.75$,\n- NBR observations $y(t_b) = 0.68$ and $y(t_e) = 0.42$.\n\nStarting from the definitions of additive decomposition, the notion of slope as a difference quotient, and the separation of seasonal variation and baseline trend from structural disturbance, derive an analytic expression for the disturbance rate over $[t_b, t_e]$ as the trend-corrected slope of the de-seasonalized LandTrendr segment. Evaluate this disturbance rate using the provided parameters. Express your final rate in index units per year and round your answer to four significant figures. Finally, explain how the magnitude and sign of this rate connect to ecological interpretations of clearcut versus selective logging, grounding your discussion in the physical meaning of NBR changes and the modeled components $S(t)$ and $\\tau(t)$.",
            "solution": "### Step 1: Extract Givens\n- Additive decomposition model for NBR time series $y(t)$: $y(t) = \\tau(t) + S(t) + \\varepsilon(t)$.\n- Trend component: $\\tau(t) = a + b\\,t$.\n- Seasonal component: $S(t) = C \\cos(2\\pi t) + D \\sin(2\\pi t)$.\n- Time $t$ is measured in years.\n- Disturbance window: $[t_b, t_e]$.\n- Pre-break trend slope: $b = 0.005$ index units per year.\n- Seasonal coefficients: $C = 0.10$, $D = 0.05$.\n- Break time: $t_b = 2015.25$.\n- End time: $t_e = 2015.75$.\n- NBR observations: $y(t_b) = 0.68$, $y(t_e) = 0.42$.\n- The LandTrendr segment is a single monotonic linear segment between vertices at $t_b$ and $t_e$.\n- The quantity to be derived is the \"disturbance rate,\" defined as the trend-corrected slope of the de-seasonalized LandTrendr segment.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, using established models (BFAST, LandTrendr) and indices (NBR) from remote sensing science. The additive decomposition is a standard technique. The provided numerical values are physically realistic for vegetation dynamics. The problem statement is well-posed, as it provides a clear, quantitative definition of the target variable and sufficient data for its calculation. The language is objective and precise. The problem is self-contained and free of contradictions or vagueness. It does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\n\nThe objective is to derive an analytical expression for the disturbance rate, denoted as $R_d$, and then evaluate it. The problem defines $R_d$ as the \"trend-corrected slope of the de-seasonalized LandTrendr segment.\" We will construct this quantity in steps.\n\n1.  **Slope of the LandTrendr Segment:** The observed LandTrendr segment connects the two points $(t_b, y(t_b))$ and $(t_e, y(t_e))$. The total rate of change, or slope, of the observed NBR over this interval is given by the difference quotient:\n    $$m_{obs} = \\frac{y(t_e) - y(t_b)}{t_e - t_b}$$\n    This observed slope aggregates changes from the background trend, seasonality, and the disturbance event itself.\n\n2.  **Slope of the De-seasonalized Segment:** To de-seasonalize the data, we subtract the seasonal component $S(t)$ from the observations $y(t)$. The de-seasonalized data points are $y'(t_b) = y(t_b) - S(t_b)$ and $y'(t_e) = y(t_e) - S(t_e)$. The slope of the de-seasonalized segment, $m_{deseasoned}$, is:\n    $$m_{deseasoned} = \\frac{y'(t_e) - y'(t_b)}{t_e - t_b} = \\frac{[y(t_e) - S(t_e)] - [y(t_b) - S(t_b)]}{t_e - t_b}$$\n    Rearranging the terms, we get:\n    $$m_{deseasoned} = \\frac{y(t_e) - y(t_b) - (S(t_e) - S(t_b))}{t_e - t_b}$$\n    This slope represents the rate of change attributable to all trend-like components, which in this context includes both the slow pre-existing trend and the abrupt change caused by the disturbance. The stochastic term $\\varepsilon(t)$ is ignored, as we are modeling the rate based on the given vertices.\n\n3.  **Trend-Correction and the Disturbance Rate $R_d$:** The de-seasonalized slope, $m_{deseasoned}$, is the combined rate of change of the background trend and the disturbance. The rate of the background trend is given as $b$. Therefore, to isolate the disturbance rate $R_d$, we must subtract the background trend's contribution from the de-seasonalized slope.\n    $$R_d = m_{deseasoned} - b$$\n    Substituting the expression for $m_{deseasoned}$, we arrive at the final analytical expression for the disturbance rate:\n    $$R_d = \\frac{y(t_e) - y(t_b) - (S(t_e) - S(t_b))}{t_e - t_b} - b$$\n    This expression isolates the rate of change due solely to the disturbance, having corrected for both seasonal oscillations and the pre-existing linear trend.\n\n### Numerical Evaluation\n\nWe now substitute the provided values into the derived expression.\nThe given parameters are:\n- $t_b = 2015.25$ yr\n- $t_e = 2015.75$ yr\n- $y(t_b) = 0.68$\n- $y(t_e) = 0.42$\n- $b = 0.005$ yr$^{-1}$\n- $C = 0.10$\n- $D = 0.05$\n\nFirst, we evaluate the seasonal component $S(t) = C \\cos(2\\pi t) + D \\sin(2\\pi t)$ at $t_b$ and $t_e$.\nFor $t_b = 2015.25$:\n$$2\\pi t_b = 2\\pi (2015 + 0.25) = 4030\\pi + \\frac{\\pi}{2}$$\n$$\\cos(2\\pi t_b) = \\cos\\left(4030\\pi + \\frac{\\pi}{2}\\right) = \\cos\\left(\\frac{\\pi}{2}\\right) = 0$$\n$$\\sin(2\\pi t_b) = \\sin\\left(4030\\pi + \\frac{\\pi}{2}\\right) = \\sin\\left(\\frac{\\pi}{2}\\right) = 1$$\nTherefore, $S(t_b) = C(0) + D(1) = D = 0.05$.\n\nFor $t_e = 2015.75$:\n$$2\\pi t_e = 2\\pi (2015 + 0.75) = 4030\\pi + \\frac{3\\pi}{2}$$\n$$\\cos(2\\pi t_e) = \\cos\\left(4030\\pi + \\frac{3\\pi}{2}\\right) = \\cos\\left(\\frac{3\\pi}{2}\\right) = 0$$\n$$\\sin(2\\pi t_e) = \\sin\\left(4030\\pi + \\frac{3\\pi}{2}\\right) = \\sin\\left(\\frac{3\\pi}{2}\\right) = -1$$\nTherefore, $S(t_e) = C(0) + D(-1) = -D = -0.05$.\n\nNow, we can compute the change in the seasonal component:\n$$S(t_e) - S(t_b) = -0.05 - 0.05 = -0.10$$\nThe time interval is:\n$$t_e - t_b = 2015.75 - 2015.25 = 0.50 \\text{ yr}$$\nThe change in observed NBR is:\n$$y(t_e) - y(t_b) = 0.42 - 0.68 = -0.26$$\n\nFinally, we substitute these values into the expression for $R_d$:\n$$R_d = \\frac{-0.26 - (-0.10)}{0.50} - 0.005$$\n$$R_d = \\frac{-0.26 + 0.10}{0.50} - 0.005$$\n$$R_d = \\frac{-0.16}{0.50} - 0.005$$\n$$R_d = -0.32 - 0.005 = -0.325$$\nRounding to four significant figures, the disturbance rate is $-0.3250$ index units per year.\n\n### Ecological Interpretation\n\nThe Normalized Burn Ratio (NBR) is a satellite-derived index sensitive to vegetation health and cover, where high values correspond to healthy, dense vegetation and low values indicate stressed vegetation or bare ground.\nThe calculated disturbance rate, $R_d = -0.3250$ yr$^{-1}$, is negative and has a large magnitude.\n\n-   **Significance of the Sign**: The negative sign indicates a rapid loss of NBR, which is physically associated with vegetation loss or stress. This is the defining characteristic of a disturbance.\n\n-   **Significance of the Magnitude**: The observed NBR dropped by $0.26$ over $0.5$ years. Our analysis partitions this change:\n    -   A drop of $0.10$ was expected due to seasonal senescence (from late spring to late autumn).\n    -   A gain of $b \\times (t_e-t_b) = 0.005 \\times 0.5 = 0.0025$ was expected from the slow, pre-existing positive trend (e.g., forest growth).\n    -   The remaining change, $-0.26 - (-0.10) - 0.0025 = -0.1625$, is attributed to the disturbance event over $0.5$ years. This corresponds to our calculated annual rate $R_d = -0.1625 / 0.5 = -0.325$.\n\n-   **Clearcut vs. Selective Logging**:\n    -   **Selective logging** involves removing a fraction of trees, causing a moderate decrease in NBR as canopy cover is thinned.\n    -   **Clearcutting** involves removing nearly all trees, leading to a drastic replacement of forest canopy with soil and logging debris. This results in a sharp, large-magnitude drop in NBR.\n\nThe calculated disturbance rate is substantial. A total NBR drop from $0.68$ (healthy vegetation) to $0.42$ is a significant decline. The fact that this change, when corrected for seasonal and background trends, still corresponds to a rate of $-0.3250$ yr$^{-1}$ points to a severe, stand-altering event. Such a rapid and large removal of photosynthetically active biomass is far more characteristic of a **clearcut** than a typical selective logging operation. The disturbance magnitude overwhelms both the seasonal cycle and the pre-existing positive growth trend.",
            "answer": "$$ \\boxed{-0.3250} $$"
        },
        {
            "introduction": "Choosing the right tool for a scientific task requires rigorous, unbiased comparison. This final exercise  elevates the focus from using algorithms to validating them, a critical skill for any researcher. You are tasked with designing a robust benchmarking experiment, forcing consideration of everything from data harmonization and fair parameter tuning to the selection of metrics that are meaningful under real-world conditions like data imbalance.",
            "id": "3799336",
            "problem": "A remote sensing team must benchmark Breaks For Additive Season and Trend (BFAST) and Landsat-based Detection of Trends in Disturbance and Recovery (LandTrendr) for detecting disturbances in satellite-derived vegetation time series. Both algorithms segment time series of reflectance-derived indices into piecewise-smooth components and output breakpoints indicating putative disturbances. Assume access to Level-$2$ Landsat surface reflectance over temperate forests, ancillary disturbance perimeters with ignition or harvest dates for a subset of events, and the ability to construct synthetic disturbances by injecting known step changes into real, cloud-free time series. The team must design a fair, statistically valid experiment that isolates algorithmic performance rather than artifacts of preprocessing or parameterization, and must specify evaluation metrics that faithfully quantify detection, timing, and magnitude performance under class imbalance.\n\nFrom first principles in detection theory and time series decomposition, the team recognizes that a univariate index time series $y_t$ can be modeled as $y_t = \\mu_t + s_t + d_t + \\varepsilon_t$, where $\\mu_t$ is a low-frequency trend, $s_t$ is a seasonal component (possibly absent if using annual composites), $d_t$ encodes disturbances as abrupt changes in level or slope, and $\\varepsilon_t$ is noise with spatiotemporal autocorrelation. Ground-truth events are sets of pixels with known disturbance time $t^\\ast$ and, for synthetic cases, known magnitude $\\Delta y$. Any fair comparison must ensure comparable input representations, unbiased hyperparameter tuning, and performance quantification that accounts for uncertainty in event dating and severe class imbalance between disturbed and undisturbed pixels.\n\nWhich experimental design and metric suite best meet these requirements?\n\nA. Build a unified, annual medoid Normalized Burn Ratio (NBR) time series for all pixels to harmonize temporal resolution and reduce seasonality. For synthetic ground truth, inject step changes of known magnitude $\\Delta y$ at known times $t^\\ast$ into real undisturbed annual series by adding a level-shift to all post-$t^\\ast$ observations, preserving empirical noise $\\varepsilon_t$ and autocorrelation. For real ground truth, use independently mapped wildfire and harvest perimeters with ignition or operation dates, and exclude a buffer of $\\pm \\delta t$ around $t^\\ast$ for training to avoid leakage; set $\\delta t$ based on compositing uncertainty. Run both algorithms on the same annual series, disabling the seasonal term in BFAST for annual data. Tune hyperparameters using nested cross-validation with spatially blocked folds to prevent spatial leakage; lock tuned settings before final evaluation. Evaluate event-level detection with a temporal tolerance window $\\pm \\tau$ around $t^\\ast$ and compute precision $=\\frac{TP}{TP+FP}$, recall $=\\frac{TP}{TP+FN}$, and the harmonic mean $F_1$. Quantify breakpoint dating with absolute timing error $\\lvert \\hat{t} - t^\\ast\\rvert$ and latency $\\hat{t}-t^\\ast$, and quantify magnitude error $\\lvert \\widehat{\\Delta y}-\\Delta y\\rvert$ for synthetic cases. Summarize discrimination with Area Under the Precision-Recall Curve (AUPRC) and Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) over algorithm confidence scores, report over- and under-segmentation rates per series, post-fit residual root-mean-square error (RMSE), and computational cost. Use paired statistical tests (for example, McNemar’s test on matched pixel-event outcomes and bootstrap confidence intervals) to assess significance.\n\nB. Generate fully simulated monthly Normalized Difference Vegetation Index (NDVI) series as autoregressive Gaussian noise with occasional step changes; run BFAST on monthly NDVI and LandTrendr on annual NBR to reflect typical use. Tune hyperparameters to maximize overall accuracy on the test set. Evaluate performance by overall accuracy only, counting a break as correct if $\\hat{t}=t^\\ast$ exactly, and ignore timing and magnitude errors because they are secondary to detection.\n\nC. Use real wildfire perimeters and compute annual NBR for LandTrendr and monthly NDVI for BFAST, allowing each algorithm to operate on its customary index and cadence. Evaluate by computing the Pearson correlation between detected break magnitudes and independent burn severity for pixels within perimeters; omit non-disturbed areas to avoid class imbalance. Consider the algorithm with the higher correlation to be superior.\n\nD. Partition each site’s time series into $K$ contiguous temporal folds for cross-validation and tune and test within the same sites by rotating the held-out temporal fold. Keep pixel locations fixed across folds to control for spatial variability. Evaluate using only the $F_1$ score with zero temporal tolerance, declaring a true positive only if $\\hat{t}=t^\\ast$ exactly. To compare segmentations of differing granularity, match segments via unsupervised clustering of segment means before computing $F_1$.\n\nSelect the best option.",
            "solution": "The problem statement is scientifically sound, well-posed, and describes a standard yet complex task in remote sensing time series analysis. It requires the design of a rigorous experimental protocol to compare the performance of two breakpoint detection algorithms, BFAST and LandTrendr. The core requirements for a valid design, as stated, are: $1$) ensuring a fair comparison through harmonized inputs and unbiased parameter tuning; $2$) employing a comprehensive suite of metrics to evaluate detection, timing, and magnitude accuracy; and $3$) correctly accounting for statistical challenges like class imbalance, dating uncertainty, and spatiotemporal autocorrelation. We will evaluate each option against these criteria.\n\n### Option-by-Option Analysis\n\n**A. Build a unified, annual medoid Normalized Burn Ratio (NBR) time series for all pixels to harmonize temporal resolution...**\n\nThis option proposes a meticulously designed experiment that adheres to the highest standards of statistical validation and remote sensing practice.\n1.  **Fair Comparison:** It correctly establishes a fair basis for comparison by using a \"unified, annual medoid Normalized Burn Ratio (NBR) time series for all pixels\". This ensures both algorithms operate on the exact same input data, thus isolating algorithmic performance from artifacts of data preprocessing, index choice, or temporal resolution. It also specifies disabling the seasonal model in BFAST when using annual data, which is the correct procedure to ensure a like-for-like comparison with LandTrendr, which does not model seasonality.\n2.  **Unbiased Hyperparameter Tuning:** The proposal to use \"nested cross-validation with spatially blocked folds\" is the gold standard. Nested cross-validation provides an unbiased estimate of performance on unseen data by separating the hyperparameter tuning process from the final model evaluation. \"Spatially blocked folds\" correctly address the problem of spatiotemporal autocorrelation mentioned in the prompt, preventing overly optimistic results caused by training and testing on spatially adjacent, non-independent pixels. Locking the parameters before final evaluation is a critical step for valid inference.\n3.  **Comprehensive Metrics  Uncertainty:** The evaluation framework is exemplary.\n    *   **Detection:** It accounts for class imbalance by using `precision`, `recall`, the `$F_1$` score, and most importantly, the Area Under the Precision-Recall Curve (`AUPRC`), which is the most informative summary metric for imbalanced detection tasks. It also accounts for uncertainty in event dating by using a \"temporal tolerance window $\\pm \\tau$ around $t^\\ast$\", which is a realistic and necessary accommodation.\n    *   **Timing  Magnitude:** It specifies distinct and appropriate metrics for timing (`absolute timing error $\\lvert \\hat{t} - t^\\ast\\rvert$` and `latency $\\hat{t}-t^\\ast$`) and magnitude (`magnitude error $\\lvert \\widehat{\\Delta y}-\\Delta y\\rvert$`), directly addressing the multi-faceted nature of algorithm performance.\n    *   **Supplementary Metrics:** The inclusion of `over- and under-segmentation rates`, `post-fit residual root-mean-square error (RMSE)`, and `computational cost` provides a holistic and nuanced picture of each algorithm's behavior.\n4.  **Statistical Rigor:** The recommendation to use \"paired statistical tests (for example, McNemar’s test...)\" is correct, as the algorithms are run on the same dataset, making the observations paired and requiring such tests to determine if performance differences are statistically significant. The use of \"bootstrap confidence intervals\" is also a robust method for quantifying uncertainty.\n5.  **Ground Truth:** The use of both real (ancillary perimeters) and synthetic ground truth is a powerful combination, allowing for assessment in realistic noise conditions ($\\varepsilon_t$) with known event parameters ($\\Delta y$, $t^\\ast$).\n\nThis option is a textbook example of a rigorous experimental design.\n\n**Verdict: Correct**\n\n**B. Generate fully simulated monthly Normalized Difference Vegetation Index (NDVI) series as autoregressive Gaussian noise...**\n\nThis option is methodologically flawed in several critical ways.\n1.  **Unfair Comparison:** It proposes running \"BFAST on monthly NDVI and LandTrendr on annual NBR\". This fundamentally violates the principle of a fair comparison. Any observed differences in performance could be attributable to the different temporal frequencies (monthly vs. annual) or the different spectral indices (NDVI vs. NBR), rather than the core algorithms themselves. The experiment would be confounded.\n2.  **Invalid Hyperparameter Tuning:** It suggests to \"Tune hyperparameters to maximize overall accuracy on the test set.\" This is a cardinal sin in machine learning and statistics known as data leakage or snooping. The test set must be held out and used only once for final, unbiased evaluation. Tuning on the test set produces artificially inflated and invalid performance metrics.\n3.  **Inappropriate Metrics:** It relies on \"overall accuracy only,\" which is a notoriously poor and misleading metric for imbalanced datasets, as a trivial classifier that always predicts the majority class (no disturbance) can achieve very high accuracy. Furthermore, demanding an exact match ($\\hat{t}=t^\\ast$) ignores the inherent and acceptable uncertainty in event dating. Ignoring timing and magnitude errors discards crucial information about algorithm performance.\n\n**Verdict: Incorrect**\n\n**C. Use real wildfire perimeters and compute annual NBR for LandTrendr and monthly NDVI for BFAST...**\n\nThis option suffers from flaws similar to option B, with an additional critical error in its evaluation strategy.\n1.  **Unfair Comparison:** As with option B, using different inputs (\"annual NBR for LandTrendr and monthly NDVI for BFAST\") makes it impossible to isolate algorithmic performance. The comparison is confounded from the start.\n2.  **Invalid Evaluation Scope:** The proposal to \"omit non-disturbed areas to avoid class imbalance\" is a catastrophic misunderstanding of the problem. A key function of a disturbance detection algorithm is to *not* produce false alarms on stable land. By excluding non-disturbed areas, the experiment cannot measure the false positive rate ($FP$), making it impossible to calculate precision or any related metric. This tests only one half of the detection problem (sensitivity on disturbed pixels) while completely ignoring specificity.\n3.  **Incomplete Metrics:** Relying solely on the \"Pearson correlation between detected break magnitudes and independent burn severity\" is insufficient. This metric, while potentially useful as a supplement, says nothing about whether an event was detected in the first place (recall), the rate of false alarms (precision), or the accuracy of the detection timing.\n\n**Verdict: Incorrect**\n\n**D. Partition each site’s time series into K contiguous temporal folds for cross-validation...**\n\nThis option proposes a design that is less robust and realistic than option A.\n1.  **Inappropriate Cross-Validation:** While temporal cross-validation is a valid technique in some contexts, it is not the best choice here. The problem statement explicitly notes \"noise with spatiotemporal autocorrelation.\" Temporal folding does not address the spatial component of this autocorrelation. Spatially blocked cross-validation, as proposed in option A, is the correct method to handle spatial dependencies and produce a more realistic estimate of generalization performance to new geographic areas.\n2.  **Unrealistic Evaluation Criteria:** Like option B, it makes the unrealistic demand of \"zero temporal tolerance\" ($\\hat{t}=t^\\ast$), which unfairly penalizes algorithms for small, practically insignificant timing errors.\n3.  **Convoluted  Incomplete Metrics:** Evaluating \"only the $F_1$ score\" is less comprehensive than the suite of metrics in option A. The proposal to \"match segments via unsupervised clustering\" before computing the `$F_1$` score is an ad-hoc, overly complex, and non-standard procedure. Breakpoint detection efficacy is best evaluated by directly comparing detected events to ground-truth events, not by an indirect comparison of segments. This method introduces its own sources of error and ambiguity.\n\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}