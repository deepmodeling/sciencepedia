{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in any quantitative analysis of SAR imagery is to characterize the level of speckle noise. This practice guides you through the process of estimating the Equivalent Number of Looks ($L$), a key measure of speckle intensity, directly from the statistical moments of the image data. By deriving the moment-based estimator and then analyzing how it is biased by non-stationarity and scene texture, you will develop a deeper, more critical understanding of the assumptions underlying speckle models.",
            "id": "3852478",
            "problem": "A two-dimensional intensity image acquired by Synthetic Aperture Radar (SAR) over a nominally homogeneous agricultural field is corrupted by speckle consistent with the multiplicative model. In a rectangular analysis window of size $31 \\times 31$ pixels centered on a portion of the field, the sample mean of the intensity is $\\hat{m} = 0.82$ and the sample variance is $\\hat{v} = 0.21$. Assume multi-look processing under fully developed speckle and that the image values are proportional to radar intensity (not amplitude). Starting from the multiplicative speckle model and the well-established statistical characterization of multi-look SAR intensity for fully developed speckle, derive an estimator for the Equivalent Number of Looks (ENL) solely in terms of the first two moments of the intensity, and then use the provided window statistics to compute a numerical estimate. Round your ENL estimate to four significant figures.\n\nNow suppose that the underlying backscatter field within the same window is not exactly stationary but has a slow linear trend in the mean intensity given by $\\mu(x,y) = \\mu_{0} + g_{x} x + g_{y} y$, where $(x,y)$ are discrete pixel coordinates with the origin at the window center, $x,y \\in \\{-15,-14,\\dots,0,\\dots,14,15\\}$, and the gradients are $g_{x} = 2 \\times 10^{-3}$ and $g_{y} = 2 \\times 10^{-3}$ (intensity per pixel). Using first principles of spatial moment analysis, derive an expression for the additional deterministic variance across the window induced by this trend, and explain how this nonstationarity biases the ENL estimator obtained from the first two moments.\n\nFinally, discuss qualitatively and quantitatively (by deriving a symbolic expression) how random texture in the backscatter, modeled as an independent stationary random field with mean $\\mu_{X}$ and variance $\\sigma_{X}^{2}$, alters the relationship between ENL and the first two moments of the observed intensity under the multiplicative model. You may assume the speckle component has unit mean and variance equal to the reciprocal of the number of looks. You do not need to report any bias expressions in the final boxed answer; only the ENL estimate computed from the provided window statistics should be given, rounded to four significant figures and expressed without units.",
            "solution": "The problem as stated is scientifically grounded, well-posed, internally consistent, and contains sufficient information to derive the requested quantities. The problem uses established models from Synthetic Aperture Radar (SAR) signal processing, namely the multiplicative model for speckle, the Gamma distribution for multi-look intensity, and standard statistical methods for parameter estimation and bias analysis. The parameters provided are physically realistic. Therefore, the problem is valid and a solution can be derived.\n\nThe problem is addressed in three parts: first, deriving and calculating the Equivalent Number of Looks (ENL) for a homogeneous scene; second, analyzing the bias introduced by a deterministic trend in the mean backscatter; and third, analyzing the effect of random texture in the backscatter.\n\n**Part 1: ENL Estimation in a Homogeneous Scene**\n\nThe multiplicative model for speckle in an intensity SAR image is given by:\n$$I = X \\cdot S$$\nwhere $I$ is the measured pixel intensity, $X$ is the true radar backscatter of the scene, and $S$ is the speckle noise. For a nominally homogeneous region, the true backscatter $X$ is assumed to be constant, a value we denote as $\\mu$. Thus, $I = \\mu \\cdot S$.\n\nFor multi-look, fully developed speckle, the noise component $S$ is well-modeled by a Gamma distribution with a probability density function:\n$$p(s) = \\frac{L^L}{\\Gamma(L)} s^{L-1} \\exp(-Ls), \\quad s \\ge 0$$\nwhere $L$ is the Equivalent Number of Looks (ENL). For this distribution to be properly normalized for the multiplicative model, it is standard to set its mean to unity. The moments of this Gamma distribution are:\n$$E[S] = 1$$\n$$Var(S) = \\frac{1}{L}$$\n\nUsing these properties, we can find the first two a-priori moments of the observed intensity $I$:\nThe mean of the observed intensity is:\n$$E[I] = E[\\mu \\cdot S] = \\mu \\cdot E[S] = \\mu \\cdot 1 = \\mu$$\nThe variance of the observed intensity is:\n$$Var(I) = Var(\\mu \\cdot S) = \\mu^2 \\cdot Var(S) = \\frac{\\mu^2}{L}$$\n\nFrom these two relationships, we can derive an expression for $L$. By substituting $\\mu = E[I]$ into the variance equation, we get:\n$$Var(I) = \\frac{(E[I])^2}{L}$$\nRearranging for $L$ yields:\n$$L = \\frac{(E[I])^2}{Var(I)}$$\nThis is a moment-based estimator for the ENL. We can apply this formula to the sample statistics provided from the analysis window. The sample mean $\\hat{m}$ is an estimator for $E[I]$, and the sample variance $\\hat{v}$ is an estimator for $Var(I)$. Therefore, the estimate for the ENL, denoted $\\hat{L}$, is:\n$$\\hat{L} = \\frac{\\hat{m}^2}{\\hat{v}}$$\nThe problem provides the sample statistics from a $31 \\times 31$ pixel window: $\\hat{m} = 0.82$ and $\\hat{v} = 0.21$. Substituting these values into the estimator:\n$$\\hat{L} = \\frac{(0.82)^2}{0.21} = \\frac{0.6724}{0.21} \\approx 3.20190476...$$\nRounding to four significant figures as requested, the estimated ENL is $3.202$.\n\n**Part 2: Bias due to a Non-stationary Mean**\n\nNow, we consider the case where the underlying backscatter is not stationary but exhibits a slow linear trend across the analysis window. The mean intensity is given by $\\mu(x,y) = \\mu_{0} + g_{x} x + g_{y} y$, where $(x,y)$ are the centered pixel coordinates. The observed intensity at each pixel is $I(x,y) = \\mu(x,y) \\cdot S(x,y)$, where $S(x,y)$ is a stationary speckle field with $E[S]=1$ and $Var(S)=1/L$.\n\nThe total measured variance in the window, $\\hat{v}$, now captures variance from two sources: the speckle noise and the deterministic variation of the mean. We can formalize this using the law of total variance. If we consider the pixels in the window as a population, the total variance of $I$ is:\n$$Var(I) = E_{\\text{spatial}}[Var(I|\\mu)] + Var_{\\text{spatial}}(E[I|\\mu])$$\nThe conditional moments at a given location $(x,y)$ are:\n$$E[I|\\mu(x,y)] = E[\\mu(x,y) S] = \\mu(x,y)E[S] = \\mu(x,y)$$\n$$Var(I|\\mu(x,y)] = Var[\\mu(x,y) S] = \\mu(x,y)^2 Var(S) = \\frac{\\mu(x,y)^2}{L}$$\nThe total variance is the spatial average of these quantities over the window. Let $\\langle \\cdot \\rangle$ denote the spatial average operator over all pixels in the window.\n$$Var_{\\text{total}} = \\left\\langle \\frac{\\mu(x,y)^2}{L} \\right\\rangle + Var(\\mu(x,y))$$\nwhere $Var(\\mu(x,y)) = \\langle \\mu(x,y)^2 \\rangle - \\langle \\mu(x,y) \\rangle^2$.\n\nThe \"additional deterministic variance\" is precisely this second term, $Var(\\mu(x,y))$. Let's derive it. The window size is $N \\times N$ with $N=31$. The coordinates run from $-K$ to $K$, where $K=(N-1)/2 = 15$.\nThe spatial mean of $\\mu(x,y)$ is:\n$$\\langle \\mu(x,y) \\rangle = \\frac{1}{N^2} \\sum_{x=-K}^{K} \\sum_{y=-K}^{K} (\\mu_{0} + g_{x} x + g_{y} y)$$\nDue to symmetry, $\\sum_{i=-K}^{K} i = 0$. Thus, $\\langle \\mu(x,y) \\rangle = \\mu_0$. The sample mean $\\hat{m}$ estimates this central value $\\mu_0$.\nThe variance of the mean is:\n$$Var(\\mu) = \\langle (\\mu(x,y) - \\mu_0)^2 \\rangle = \\langle (g_{x} x + g_{y} y)^2 \\rangle = \\langle g_{x}^2 x^2 + g_{y}^2 y^2 + 2g_{x}g_{y}xy \\rangle$$\n$$Var(\\mu) = g_{x}^2 \\langle x^2 \\rangle + g_{y}^2 \\langle y^2 \\rangle + 2g_{x}g_{y} \\langle xy \\rangle$$\nThe average of the cross-term is zero: $\\langle xy \\rangle = (\\frac{1}{N}\\sum_x x)(\\frac{1}{N}\\sum_y y) = 0$.\nThe term $\\langle x^2 \\rangle$ is the spatial average of $x^2$ over the window, which due to separability is just the average over one dimension:\n$$\\langle x^2 \\rangle = \\frac{1}{N} \\sum_{i=-K}^{K} i^2 = \\frac{1}{2K+1} \\left( 2 \\sum_{i=1}^{K} i^2 \\right) = \\frac{2}{2K+1} \\frac{K(K+1)(2K+1)}{6} = \\frac{K(K+1)}{3}$$\nWith $K=15$, $\\langle x^2 \\rangle = \\langle y^2 \\rangle = \\frac{15(16)}{3} = 80$.\nThe additional deterministic variance is therefore:\n$$Var(\\mu) = (g_{x}^2 + g_{y}^2) \\frac{K(K+1)}{3}$$\nWith the given gradients $g_x = g_y = 2 \\times 10^{-3}$, this variance is $((2 \\times 10^{-3})^2 + (2 \\times 10^{-3})^2) \\times 80 = (8 \\times 10^{-6}) \\times 80 = 6.4 \\times 10^{-4}$.\n\nThe simple ENL estimator $\\hat{L} = \\hat{m}^2/\\hat{v}$ uses the total measured variance $\\hat{v}$ in the denominator. This total variance is approximately $\\hat{v} \\approx \\frac{\\mu_0^2}{L} + Var(\\mu)$. The estimator becomes:\n$$\\hat{L}_{\\text{biased}} = \\frac{\\mu_0^2}{\\frac{\\mu_0^2}{L} + Var(\\mu)}$$\nSince $Var(\\mu)  0$, the denominator is larger than $\\mu_0^2/L$. This means $\\hat{L}_{\\text{biased}}  L$. The presence of the deterministic trend adds variance that is not due to speckle. The simple estimator misinterprets this additional variance as more intense speckle noise, leading to an underestimation of the true ENL, $L$.\n\n**Part 3: Effect of Random Texture**\n\nFinally, we consider a scene where the backscatter $X$ is itself a random field, independent of the speckle $S$. We assume $X$ is stationary with mean $\\mu_X$ and variance $\\sigma_X^2$. Speckle $S$ has $E[S]=1$ and $Var(S)=1/L$. The observed intensity is $I = X \\cdot S$.\n\nThe mean of the observed intensity is:\n$$E[I] = E[X \\cdot S] = E[X] E[S] = \\mu_X \\cdot 1 = \\mu_X$$\nTo find the variance, we use the property for the product of two independent random variables $Y$ and $Z$: $Var(YZ) = E[Y^2]E[Z^2] - (E[Y]E[Z])^2$.\nWe have $E[X^2] = Var(X) + (E[X])^2 = \\sigma_X^2 + \\mu_X^2$, and $E[S^2] = Var(S) + (E[S])^2 = 1/L + 1^2 = 1 + 1/L$.\nThus, the second moment of $I$ is:\n$$E[I^2] = E[X^2]E[S^2] = (\\sigma_X^2 + \\mu_X^2)(1+1/L)$$\nThe variance of $I$ is:\n$$Var(I) = E[I^2] - (E[I])^2 = (\\sigma_X^2 + \\mu_X^2)(1+1/L) - \\mu_X^2$$\n$$Var(I) = \\sigma_X^2 + \\frac{\\sigma_X^2}{L} + \\mu_X^2 + \\frac{\\mu_X^2}{L} - \\mu_X^2 = \\frac{\\mu_X^2}{L} + \\sigma_X^2(1 + \\frac{1}{L})$$\nThis expression shows that the total variance is the sum of the pure speckle variance term ($\\mu_X^2/L$) and a term related to the texture variance $\\sigma_X^2$.\n\nA more insightful way to express this relationship is through the squared coefficient of variation, $C^2 = Var/Mean^2$.\nFor the observed intensity $I$: $C_I^2 = \\frac{Var(I)}{(E[I])^2}$.\nFor the texture $X$: $C_X^2 = \\frac{\\sigma_X^2}{\\mu_X^2}$.\nFor the speckle $S$: $C_S^2 = \\frac{Var(S)}{(E[S])^2} = \\frac{1/L}{1^2} = \\frac{1}{L}$.\n\nFrom the expression for $Var(I)$:\n$$C_I^2 = \\frac{\\frac{\\mu_X^2}{L} + \\sigma_X^2(1 + \\frac{1}{L})}{\\mu_X^2} = \\frac{1}{L} + \\frac{\\sigma_X^2}{\\mu_X^2} (1 + \\frac{1}{L}) = C_S^2 + C_X^2(1 + C_S^2) = C_S^2 + C_X^2 + C_S^2 C_X^2$$\nThis can be factored into the well-known form:\n$$1 + C_I^2 = (1 + C_X^2)(1 + C_S^2)$$\nThis equation is the symbolic expression that shows how the observed statistics ($C_I^2$) are altered by the random texture ($C_X^2$) and the speckle ($C_S^2 = 1/L$). If one uses the simple estimator $\\hat{L} = 1/C_I^2$, the result is $\\hat{L} = 1/(C_S^2 + C_X^2 + C_S^2 C_X^2)$, which is clearly not equal to the true ENL, $L=1/C_S^2$. The texture introduces intrinsic variability that, like the deterministic trend, inflates the measured variance and causes the simple ENL estimator to underestimate the true number of looks.",
            "answer": "$$\n\\boxed{3.202}\n$$"
        },
        {
            "introduction": "With a grasp on characterizing noise, we turn to the core challenge of estimating the true radar backscatter, $\\mu$, from a speckle-corrupted measurement. This exercise introduces the elegant framework of Bayesian inference, where prior knowledge about the scene is formally combined with observed data. You will derive the Maximum A Posteriori (MAP) estimator for $\\mu$ using a conjugate prior, revealing how this approach provides a statistically robust estimate that balances measurement with prior belief.",
            "id": "3852511",
            "problem": "A Synthetic Aperture Radar (SAR) multilook intensity measurement is modeled using the standard speckle model for multilook processing: the observed intensity $I$ conditioned on the unknown backscatter (reflectivity) $\\mu$ follows a Gamma distribution with shape parameter $L \\geq 1$ (the number of looks) and scale parameter $\\theta = \\mu/L$, so that $\\mathbb{E}[I \\mid \\mu] = \\mu$. Consider a single pixel measurement $I  0$ in an environmental monitoring application where $\\mu  0$ represents the latent mean backscatter of a homogeneous land cover patch.\n\nStarting from well-tested statistical modeling assumptions for SAR speckle, and without introducing any simplifying shortcuts, formulate the estimation of $\\mu$ as a Bayesian inference problem using the conjugate prior family for $\\mu$ implied by the Gamma likelihood kernel in $\\mu$. Use generic hyperparameters $\\alpha  0$ and $\\beta  0$ to define the prior family on $\\mu$, derive the posterior distribution $p(\\mu \\mid I)$ up to a normalized form, and obtain the maximum a posteriori (MAP) estimator $\\hat{\\mu}_{\\mathrm{MAP}}$ as the mode of the posterior density. Express your final answer as a closed-form analytic expression in terms of $I$, $L$, $\\alpha$, and $\\beta$. No numerical approximation is required, and you should provide the exact expression for $\\hat{\\mu}_{\\mathrm{MAP}}$. Do not include units in your final expression.",
            "solution": "The problem is well-posed, scientifically grounded, and contains sufficient information for a unique solution. It requests the derivation of a Maximum A Posteriori (MAP) estimator for the backscatter parameter $\\mu$ in a Synthetic Aperture Radar (SAR) speckle model. The specified statistical models and the Bayesian inference framework are standard in this domain. Thus, the problem is valid, and a full solution can be derived.\n\nThe problem states that the observed intensity $I$ for a single pixel, conditioned on the true backscatter $\\mu$, follows a Gamma distribution. The shape parameter is the number of looks, $L$, and the scale parameter is $\\theta = \\frac{\\mu}{L}$. The probability density function (PDF) of a Gamma distribution for a variable $x$ with shape parameter $k$ and scale parameter $\\theta$ is given by:\n$$f(x \\mid k, \\theta) = \\frac{x^{k-1} \\exp\\left(-\\frac{x}{\\theta}\\right)}{\\Gamma(k) \\theta^k}$$\nIn our case, the variable is $I$, the shape parameter is $k=L$, and the scale parameter is $\\theta = \\frac{\\mu}{L}$. Substituting these into the PDF gives the likelihood function $p(I \\mid \\mu)$:\n$$p(I \\mid \\mu) = \\frac{I^{L-1} \\exp\\left(-\\frac{I}{\\mu/L}\\right)}{\\Gamma(L) (\\frac{\\mu}{L})^L}$$\nWe can simplify this expression:\n$$p(I \\mid \\mu) = \\frac{I^{L-1} \\exp\\left(-\\frac{IL}{\\mu}\\right)}{\\Gamma(L) \\frac{\\mu^L}{L^L}} = \\frac{L^L I^{L-1}}{\\Gamma(L)} \\mu^{-L} \\exp\\left(-\\frac{IL}{\\mu}\\right)$$\nFor the purpose of Bayesian inference on $\\mu$, we can consider the likelihood function up to a proportionality constant, which means we only need the terms that depend on $\\mu$. This is the likelihood kernel:\n$$p(I \\mid \\mu) \\propto \\mu^{-L} \\exp\\left(-\\frac{IL}{\\mu}\\right)$$\nThe problem requires using the conjugate prior family for $\\mu$. A prior distribution is conjugate to a likelihood function if the resulting posterior distribution is in the same family as the prior. The functional form of the likelihood kernel, $\\mu^{-a} \\exp(-b/\\mu)$, suggests that the conjugate prior is the Inverse Gamma distribution.\n\nThe PDF of an Inverse Gamma distribution for a variable $\\mu$ with shape parameter $\\alpha  0$ and scale parameter $\\beta  0$ is:\n$$p(\\mu \\mid \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\mu^{-(\\alpha+1)} \\exp\\left(-\\frac{\\beta}{\\mu}\\right)$$\nWe define the prior distribution for $\\mu$ to be an Inverse Gamma distribution with the specified generic hyperparameters $\\alpha$ and $\\beta$:\n$$p(\\mu) \\propto \\mu^{-(\\alpha+1)} \\exp\\left(-\\frac{\\beta}{\\mu}\\right)$$\nAccording to Bayes' theorem, the posterior distribution $p(\\mu \\mid I)$ is proportional to the product of the likelihood and the prior:\n$$p(\\mu \\mid I) \\propto p(I \\mid \\mu) p(\\mu)$$\nSubstituting the expressions for the likelihood kernel and the prior:\n$$p(\\mu \\mid I) \\propto \\left( \\mu^{-L} \\exp\\left(-\\frac{IL}{\\mu}\\right) \\right) \\left( \\mu^{-(\\alpha+1)} \\exp\\left(-\\frac{\\beta}{\\mu}\\right) \\right)$$\nCombining the terms involving $\\mu$:\n$$p(\\mu \\mid I) \\propto \\mu^{-L - (\\alpha+1)} \\exp\\left(-\\frac{IL}{\\mu} - \\frac{\\beta}{\\mu}\\right)$$\n$$p(\\mu \\mid I) \\propto \\mu^{-(L+\\alpha+1)} \\exp\\left(-\\frac{IL + \\beta}{\\mu}\\right)$$\nThis resulting posterior kernel is also of the form of an Inverse Gamma distribution. By comparing the posterior kernel $p(\\mu \\mid I) \\propto \\mu^{-(\\alpha_{\\text{post}}+1)} \\exp(-\\frac{\\beta_{\\text{post}}}{\\mu})$ with our result, we can identify the parameters of the posterior distribution:\nThe posterior shape parameter is $\\alpha_{\\text{post}} = L + \\alpha$.\nThe posterior scale parameter is $\\beta_{\\text{post}} = IL + \\beta$.\nThus, the posterior distribution of $\\mu$ given $I$ is an Inverse Gamma distribution:\n$$\\mu \\mid I \\sim \\text{Inv-Gamma}(L+\\alpha, IL+\\beta)$$\nThe Maximum A Posteriori (MAP) estimator, $\\hat{\\mu}_{\\mathrm{MAP}}$, is the mode of the posterior distribution. For an Inverse Gamma distribution with shape $\\alpha'$ and scale $\\beta'$, the mode is given by the expression $\\frac{\\beta'}{\\alpha' + 1}$.\nUsing the posterior parameters $\\alpha_{\\text{post}} = L+\\alpha$ and $\\beta_{\\text{post}} = IL+\\beta$, we find the MAP estimator for $\\mu$:\n$$\\hat{\\mu}_{\\mathrm{MAP}} = \\frac{\\beta_{\\text{post}}}{\\alpha_{\\text{post}} + 1} = \\frac{IL + \\beta}{(L + \\alpha) + 1}$$\n$$\\hat{\\mu}_{\\mathrm{MAP}} = \\frac{IL + \\beta}{L + \\alpha + 1}$$\nThis is the closed-form analytic expression for the MAP estimator in terms of the given quantities $I$, $L$, $\\alpha$, and $\\beta$.\nTo formally verify this is a maximum, we can maximize the log-posterior. The log-posterior is:\n$$\\ln p(\\mu \\mid I) = C - (L+\\alpha+1)\\ln(\\mu) - \\frac{IL+\\beta}{\\mu}$$\nwhere $C$ is a constant. The first derivative with respect to $\\mu$ is:\n$$\\frac{d}{d\\mu} \\ln p(\\mu \\mid I) = -\\frac{L+\\alpha+1}{\\mu} + \\frac{IL+\\beta}{\\mu^2}$$\nSetting the derivative to zero to find the critical point:\n$$-\\frac{L+\\alpha+1}{\\mu} + \\frac{IL+\\beta}{\\mu^2} = 0 \\implies (L+\\alpha+1)\\mu = IL+\\beta \\implies \\mu = \\frac{IL+\\beta}{L+\\alpha+1}$$\nThe second derivative is:\n$$\\frac{d^2}{d\\mu^2} \\ln p(\\mu \\mid I) = \\frac{L+\\alpha+1}{\\mu^2} - \\frac{2(IL+\\beta)}{\\mu^3}$$\nAt the critical point, we substitute $IL+\\beta = (L+\\alpha+1)\\mu$:\n$$\\frac{d^2}{d\\mu^2} \\ln p(\\mu \\mid I) = \\frac{L+\\alpha+1}{\\mu^2} - \\frac{2(L+\\alpha+1)\\mu}{\\mu^3} = -\\frac{L+\\alpha+1}{\\mu^2}$$\nGiven that $L \\geq 1$, $\\alpha  0$, the term $L+\\alpha+1$ is positive. Since $\\mu^2$ is also positive, the second derivative is negative, confirming that the critical point is indeed a maximum.",
            "answer": "$$\\boxed{\\frac{IL + \\beta}{L + \\alpha + 1}}$$"
        },
        {
            "introduction": "This final practice bridges theory and application by tasking you with building a complete, high-performance adaptive speckle filter. You will implement the classic Lee filter, which relies on local image statistics to intelligently adjust its smoothing behavior, and master the use of integral images to compute these statistics with remarkable efficiency. By writing and verifying the code to process synthetic SAR data, you will gain invaluable hands-on experience in developing practical algorithms for large-scale environmental remote sensing.",
            "id": "3852489",
            "problem": "You are asked to design and implement a program that demonstrates how integral images can be used to compute local statistics efficiently for large images in real-time filtering, specifically for Synthetic Aperture Radar (SAR) speckle noise reduction within remote sensing and environmental modeling. The program must generate synthetic SAR intensity data with multiplicative speckle noise, compute local statistics via integral images, and apply an adaptive filter based on these statistics. It must also verify the correctness of the integral-image-based local statistics against a reference method and report quantitative accuracy and denoising performance.\n\nFundamental base:\n- The multiplicative speckle model assumes that observed SAR intensity $I$ is given by $I = X \\cdot N$, where $X$ is the unknown backscatter reflectivity, and $N$ is a unit-mean speckle noise random variable with variance determined by the number of looks $L$.\n- For multi-look intensity SAR data, speckle $N$ is commonly modeled as Gamma-distributed with shape parameter $L$ and scale parameter $1/L$, yielding $\\mathbb{E}[N] = 1$ and $\\operatorname{Var}(N) = 1/L$.\n- An integral image (summed area table) of a two-dimensional array $A \\in \\mathbb{R}^{H \\times W}$ is defined as the cumulative sum\n$$\nS(i,j) = \\sum_{u=0}^{i-1} \\sum_{v=0}^{j-1} A(u,v),\n$$\nusing a convention with zero-padding so that $S$ has shape $(H+1) \\times (W+1)$ and $S(0,\\cdot)=S(\\cdot,0)=0$.\n- The sum of any axis-aligned rectangular window of height $h$ and width $w$ with its top-left corner at $(i,j)$ (zero-indexed), where $0 \\le i \\le H-h$ and $0 \\le j \\le W-w$, is given by the inclusion-exclusion formula\n$$\n\\text{sum}(i,j; h,w) = S(i+h,j+w) - S(i,j+w) - S(i+h,j) + S(i,j).\n$$\n- The local mean and variance inside each window are computed as\n$$\n\\mu(i,j) = \\frac{1}{hw}\\sum_{u=i}^{i+h-1}\\sum_{v=j}^{j+w-1} I(u,v), \\quad\n\\sigma^2(i,j) = \\frac{1}{hw}\\sum_{u=i}^{i+h-1}\\sum_{v=j}^{j+w-1} I(u,v)^2 - \\mu(i,j)^2,\n$$\nwhich can be obtained by using integral images of $I$ and $I^2$.\n\nAdaptive filter:\n- Consider the Lee filter, derived under the multiplicative speckle assumption, which produces a filtered output $F$ by blending the local mean $\\mu$ and the observed center pixel $I_c$ according to\n$$\nF = \\mu + W\\left(I_c - \\mu\\right),\n$$\nwhere\n$$\nW = \\max\\left(0, \\min\\left(1, \\frac{\\sigma^2 - \\sigma_n^2}{\\sigma^2 + \\epsilon}\\right)\\right), \\quad \\sigma_n^2 = \\frac{\\mu^2}{L}.\n$$\nHere, $\\sigma_n^2$ is the noise variance in intensity domain when the mean reflectivity is $\\mu$, and $\\epsilon$ is a small positive constant to avoid division by zero. The filter output for a given window is assigned to the pixel at the window center with indices $(i + \\lfloor h/2 \\rfloor, j + \\lfloor w/2 \\rfloor)$.\n\nYour program must:\n1. Generate synthetic reflectivity fields $X$ of specified sizes, then synthesize observed intensities $I = X \\cdot N$ by drawing speckle $N$ from a Gamma distribution with shape $L$ and scale $1/L$, using the provided random seeds to ensure reproducibility.\n2. Implement integral-image-based computation of local sums of $I$ and $I^2$ and derive corresponding local means and variances on the \"valid\" domain (only positions where the full window fits inside the image), yielding arrays of shape $(H-h+1, W-w+1)$ indexed by $(i,j)$ as the window top-left coordinate.\n3. Implement a reference method to compute the same local sums by two-dimensional convolution using an $h \\times w$ all-ones kernel with \"valid\" mode (no padding), then compute local means and variances from those sums.\n4. Compute the maximum absolute differences between integral-image local means and reference local means, and between integral-image local variances and reference local variances, for each test case. These must be reported as floating-point values.\n5. Apply the Lee filter using the integral-image local statistics. The filtered values must be assigned to the center pixel of each window, which yields a filtered output array of shape $(H-h+1, W-w+1)$. Compute the root mean square error (RMSE) between the filtered output and the ground-truth reflectivity $X$ sampled at the same center pixels. Report the RMSE as a floating-point value for each test case.\n\nTest suite:\nUse the following test cases. In all cases, express intensities and reflectivities as unitless real numbers. No angles appear, and no percentages are required.\n\n- Case $1$ (general case):\n    - Image size: $H=256$, $W=256$.\n    - Window: $h=7$, $w=7$.\n    - Looks: $L=4$.\n    - Seed: $s=12345$.\n    - Reflectivity $X$: a base horizontal gradient plus a central bright block:\n      $X(u,v) = 0.5 + 0.5 \\cdot \\frac{v}{W-1} + B(u,v)$, where $B(u,v)=1.5$ if $H/4 \\le u  3H/4$ and $W/4 \\le v  3W/4$, else $B(u,v)=0$.\n\n- Case $2$ (boundary window size and identity behavior):\n    - Image size: $H=128$, $W=192$.\n    - Window: $h=1$, $w=1$.\n    - Looks: $L=8$.\n    - Seed: $s=23456$.\n    - Reflectivity $X$: sinusoidal texture,\n      $X(u,v) = 1.0 + 0.3 \\sin\\left(2\\pi \\cdot \\frac{4u}{H}\\right)\\sin\\left(2\\pi \\cdot \\frac{6v}{W}\\right)$.\n\n- Case $3$ (high speckle, anisotropic window):\n    - Image size: $H=256$, $W=256$.\n    - Window: $h=11$, $w=5$.\n    - Looks: $L=1$.\n    - Seed: $s=34567$.\n    - Reflectivity $X$: checkerboard of two levels with block size $b=8$:\n      $X(u,v) = 0.75$ if $\\left\\lfloor \\frac{u}{b} \\right\\rfloor + \\left\\lfloor \\frac{v}{b} \\right\\rfloor$ is even, else $X(u,v)=1.25$.\n\n- Case $4$ (large window relative to image):\n    - Image size: $H=64$, $W=64$.\n    - Window: $h=33$, $w=33$.\n    - Looks: $L=16$.\n    - Seed: $s=45678$.\n    - Reflectivity $X$: gentle ramp,\n      $X(u,v) = 0.1 + \\frac{u+v}{H+W}$.\n\nFinal output format:\nYour program should produce a single line of output containing all results aggregated in order per case as a comma-separated list enclosed in square brackets. For each case, output three floating-point values in the order: maximum absolute error of local means, maximum absolute error of local variances, RMSE of the Lee-filtered output versus the ground-truth reflectivity at window centers. Therefore, the overall output must contain $12$ floats for the $4$ cases, for example:\n\"[mean_err_case1,var_err_case1,rmse_case1,mean_err_case2,var_err_case2,rmse_case2,mean_err_case3,var_err_case3,rmse_case3,mean_err_case4,var_err_case4,rmse_case4]\".",
            "solution": "The problem is valid. It is a well-defined computational task in the field of remote sensing and image processing, grounded in established scientific models and algorithms. All necessary parameters and definitions are provided for a unique and verifiable solution. The problem asks for the implementation and verification of an efficient filtering pipeline for Synthetic Aperture Radar (SAR) imagery, which is a standard and relevant topic.\n\nThe solution will be implemented by following the sequence of tasks outlined in the problem statement. First, we will define functions to generate the synthetic ground-truth reflectivity fields ($X$) for each of the four test cases. These functions will be based on the explicit mathematical formulas provided.\n\nSecond, a function will generate the noisy SAR intensity image ($I$) according to the multiplicative model $I = X \\cdot N$. The speckle noise $N$ is drawn from a Gamma distribution with shape parameter $L$ (number of looks) and scale parameter $1/L$. A fixed random seed ensures reproducibility for each case.\n\nThird, we will implement the core of the problem: the computation of local image statistics (mean and variance). Two methods will be implemented:\n1.  An efficient method using integral images (also known as summed-area tables). Two integral images will be computed, one for the intensity image $I$ and another for the squared-intensity image $I^2$. From these, the sum of values and sum of squared values within any rectangular window can be calculated in constant time. The local mean and variance are then derived directly from these sums. The formula for the sum over a window with top-left corner $(i,j)$ and size $h \\times w$ using an integral image $S$ is:\n    $$ \\text{sum}(i,j; h,w) = S(i+h, j+w) - S(i, j+w) - S(i+h, j) + S(i, j) $$\n    The local mean $\\mu(i,j)$ and variance $\\sigma^2(i,j)$ are then:\n    $$ \\mu(i,j) = \\frac{\\text{sum}_I(i,j; h,w)}{hw}, \\quad \\sigma^2(i,j) = \\frac{\\text{sum}_{I^2}(i,j; h,w)}{hw} - \\mu(i,j)^2 $$\n    This will be implemented for all windows in a vectorized manner for efficiency.\n2.  A reference method using two-dimensional convolution. The local sums are computed by convolving the images $I$ and $I^2$ with an $h \\times w$ kernel of all ones, using the 'valid' mode to ensure the output size matches the integral image method. The local mean and variance are then calculated from these sums.\n\nFourth, to verify the correctness of the integral image implementation, the maximum absolute difference between the local means and local variances computed by the two methods will be calculated. These differences are expected to be close to zero, within the limits of floating-point precision.\n\nFifth, the Lee adaptive filter will be applied. The filter estimates the restored pixel value $F$ as a weighted average of the observed center pixel $I_c$ and the local mean $\\mu$, with the weight $W$ depending on the local signal-to-noise ratio. The formulas are:\n$$ F = \\mu + W(I_c - \\mu) $$\n$$ W = \\max\\left(0, \\min\\left(1, \\frac{\\sigma^2 - \\sigma_n^2}{\\sigma^2 + \\epsilon}\\right)\\right) $$\nwhere $\\sigma_n^2 = \\mu^2/L$ is the estimated speckle noise variance and $\\epsilon$ is a small positive constant (we will use $\\epsilon=10^{-8}$) to prevent division by zero. The filtered value for each window is assigned to the pixel at the window's center.\n\nFinally, the performance of the filter will be quantified by computing the Root Mean Square Error (RMSE) between the filtered image $F$ and the corresponding central pixels of the original ground-truth reflectivity image $X$.\n\nThe entire process will be executed for each of the four specified test cases, and the three resulting metrics for each case (mean error, variance error, RMSE) will be collected and formatted into a single output string as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef generate_reflectivity(H, W, params):\n    \"\"\"\n    Generates the ground-truth reflectivity field X for a given case.\n    \"\"\"\n    case_id = params['case_id']\n    vv, uu = np.meshgrid(np.arange(W, dtype=float), np.arange(H, dtype=float))\n\n    if case_id == 1:\n        X = 0.5 + 0.5 * vv / (W - 1)\n        X[H // 4 : 3 * H // 4, W // 4 : 3 * W // 4] += 1.5\n    elif case_id == 2:\n        X = 1.0 + 0.3 * np.sin(2 * np.pi * 4 * uu / H) * np.sin(2 * np.pi * 6 * vv / W)\n    elif case_id == 3:\n        b = params['b']\n        is_even = ((uu // b) + (vv // b)) % 2 == 0\n        X = np.full((H, W), 1.25)\n        X[is_even] = 0.75\n    elif case_id == 4:\n        X = 0.1 + (uu + vv) / (H + W)\n    else:\n        raise ValueError(\"Invalid case_id\")\n    return X\n\ndef generate_sar_intensity(X, L, seed):\n    \"\"\"\n    Generates the noisy SAR intensity image I from X, L, and seed.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # Speckle noise N ~ Gamma(shape=L, scale=1/L)\n    # This gives E[N]=1, Var(N)=1/L\n    noise = rng.gamma(L, 1.0 / L, size=X.shape)\n    I = X * noise\n    return I\n\ndef compute_integral_image(img):\n    \"\"\"\n    Computes the integral image (summed-area table) of a 2D array.\n    \"\"\"\n    # Pad with one row and one column of zeros on top and left\n    padded_img = np.pad(img, ((1, 0), (1, 0)), 'constant', constant_values=0)\n    # Cumulative sum over both axes\n    return padded_img.cumsum(axis=0).cumsum(axis=1)\n\ndef compute_stats_integral_image(I, h, w):\n    \"\"\"\n    Computes local mean and variance using integral images.\n    \"\"\"\n    H, W = I.shape\n    I_sq = I**2\n    \n    # Compute integral images for I and I^2\n    S_I = compute_integral_image(I)\n    S_I2 = compute_integral_image(I_sq)\n\n    # Use array slicing to compute sums over all valid windows\n    # Top-left corner (i,j), bottom-right (i+h, j+w) in S indexing\n    # sum_val = S(i+h,j+w) - S(i,j+w) - S(i+h,j) + S(i,j)\n    sum_I = S_I[h:, w:] - S_I[:-h, w:] - S_I[h:, :-w] + S_I[:-h, :-w]\n    sum_I2 = S_I2[h:, w:] - S_I2[:-h, w:] - S_I2[h:, :-w] + S_I2[:-h, :-w]\n\n    num_pixels = h * w\n    local_mean = sum_I / num_pixels\n    # Var(X) = E[X^2] - (E[X])^2\n    local_var = sum_I2 / num_pixels - local_mean**2\n\n    return local_mean, local_var\n\ndef compute_stats_reference(I, h, w):\n    \"\"\"\n    Computes local mean and variance using 2D convolution.\n    \"\"\"\n    kernel = np.ones((h, w))\n    num_pixels = h * w\n\n    sum_I = convolve2d(I, kernel, mode='valid')\n    sum_I2 = convolve2d(I**2, kernel, mode='valid')\n\n    local_mean = sum_I / num_pixels\n    local_var = sum_I2 / num_pixels - local_mean**2\n    \n    return local_mean, local_var\n\ndef apply_lee_filter(I, local_mean, local_var, L, h, w, epsilon):\n    \"\"\"\n    Applies the Lee adaptive filter.\n    \"\"\"\n    H, W = I.shape\n    h_off, w_off = h // 2, w // 2\n    \n    # Output dimensions\n    H_out, W_out = H - h + 1, W - w + 1\n    \n    # Extract Intensity at center of each window\n    I_c = I[h_off : h_off + H_out, w_off : w_off + W_out]\n\n    # Estimated noise variance\n    noise_var = (local_mean**2) / L\n    \n    # Lee filter weight\n    W_lee = (local_var - noise_var) / (local_var + epsilon)\n    W_lee = np.maximum(0, np.minimum(1, W_lee))\n\n    # Apply filter\n    F = local_mean + W_lee * (I_c - local_mean)\n    \n    return F\n\ndef solve():\n    test_cases = [\n        {'H': 256, 'W': 256, 'h': 7, 'w': 7, 'L': 4, 's': 12345, 'case_id': 1},\n        {'H': 128, 'W': 192, 'h': 1, 'w': 1, 'L': 8, 's': 23456, 'case_id': 2},\n        {'H': 256, 'W': 256, 'h': 11, 'w': 5, 'L': 1, 's': 34567, 'case_id': 3, 'b': 8},\n        {'H': 64, 'W': 64, 'h': 33, 'w': 33, 'L': 16, 's': 45678, 'case_id': 4},\n    ]\n\n    all_results = []\n    epsilon = 1e-8\n\n    for params in test_cases:\n        H, W, h, w, L, s = params['H'], params['W'], params['h'], params['w'], params['L'], params['s']\n\n        # 1. Generate synthetic data\n        X = generate_reflectivity(H, W, params)\n        I = generate_sar_intensity(X, L, s)\n\n        # 2. Compute statistics with integral image method\n        mean_ii, var_ii = compute_stats_integral_image(I, h, w)\n\n        # 3. Compute statistics with reference convolution method\n        mean_ref, var_ref = compute_stats_reference(I, h, w)\n        \n        # 4. Compute maximum absolute errors to verify integral image method\n        mean_err = np.max(np.abs(mean_ii - mean_ref))\n        var_err = np.max(np.abs(var_ii - var_ref))\n\n        # 5. Apply Lee filter and compute RMSE\n        filtered_image = apply_lee_filter(I, mean_ii, var_ii, L, h, w, epsilon)\n        \n        # Extract ground truth at window centers for comparison\n        h_off, w_off = h // 2, w // 2\n        H_out, W_out = H - h + 1, W - w + 1\n        X_center = X[h_off : h_off + H_out, w_off : w_off + W_out]\n        \n        rmse = np.sqrt(np.mean((filtered_image - X_center)**2))\n\n        # Clamp variance error to 0 if it's extremely small due to precision\n        if var_err  1e-15:\n            var_err = 0.0\n\n        all_results.extend([mean_err, var_err, rmse])\n    \n    # Format final output string as specified\n    print(f\"[{','.join(f'{r:.8f}' for r in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}