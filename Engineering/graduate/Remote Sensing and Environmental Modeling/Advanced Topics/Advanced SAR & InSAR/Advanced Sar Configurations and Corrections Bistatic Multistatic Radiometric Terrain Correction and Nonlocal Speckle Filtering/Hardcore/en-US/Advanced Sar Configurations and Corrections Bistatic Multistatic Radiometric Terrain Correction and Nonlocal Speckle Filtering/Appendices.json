{
    "hands_on_practices": [
        {
            "introduction": "Before we can perform quantitative analysis on Synthetic Aperture Radar (SAR) imagery, we must correct for distortions introduced by the viewing geometry and underlying terrain. This exercise () guides you through the implementation of a per-pixel Radiometric Terrain Correction (RTC) factor, a cornerstone of SAR pre-processing. By translating the physical principles of imaging geometry, surface orientation, and antenna patterns into a concrete algorithm, you will gain a foundational understanding of how SAR data is normalized to produce scientifically reliable backscatter measurements.",
            "id": "3795003",
            "problem": "You are given a synthetic setup to implement per-pixel Radiometric Terrain Correction (RTC) for a Synthetic Aperture Radar (SAR) image using a Digital Elevation Model (DEM). The correction must adhere to the following principle-based steps: geolocate the pixel, obtain the local surface normal from the DEM, estimate the local incidence angle, compute the area Jacobian that maps slant-plane sampling to the local ground surface, and apply antenna pattern and range loss corrections to a specified reference. Your program should compute only the RTC multiplicative factor for each specified pixel and produce these as a single, aggregated output line.\n\nUse the following fundamental base:\n- The monostatic radar equation for received power states that $P_r$ is inversely proportional to $R^4$, where $R$ is the slant range, and is directly proportional to the antenna gain $G(\\psi)$ at off-boresight angle $\\psi$ and the backscatter $\\sigma$ of the target: $P_r \\propto \\dfrac{G(\\psi)\\,\\sigma}{R^4}$.\n- The DEM-defined local surface around a point $(x,y)$ is approximated by a plane with gradient $\\left(\\dfrac{\\partial z}{\\partial x}, \\dfrac{\\partial z}{\\partial y}\\right)$ and unit normal $\\mathbf{n}$ given by $\\mathbf{n} = \\dfrac{[-\\partial z/\\partial x,\\,-\\partial z/\\partial y,\\,1]}{\\left\\|[-\\partial z/\\partial x,\\,-\\partial z/\\partial y,\\,1]\\right\\|}$.\n- The local incidence angle $\\theta_{\\text{loc}}$ is defined via the unit look vector $\\mathbf{l}$ pointing from ground to sensor by $\\cos(\\theta_{\\text{loc}}) = \\mathbf{n}\\cdot \\mathbf{l}$.\n- Under the approximation that the SAR slant imaging plane is orthogonal to $\\mathbf{l}$ (small squint, side-looking), the orthogonal projection of a local ground area element $dA_{\\text{surf}}$ onto the slant-perpendicular plane is $dA_{\\perp} = dA_{\\text{surf}}\\,|\\mathbf{n}\\cdot \\mathbf{l}|$, implying the Jacobian from slant-perpendicular area to local surface area is $J = \\dfrac{dA_{\\text{surf}}}{dA_{\\perp}} = \\dfrac{1}{|\\mathbf{n}\\cdot \\mathbf{l}|}$.\n- The azimuth antenna boresight vector $\\mathbf{b}$ is defined as $\\mathbf{b} = \\dfrac{\\mathbf{v}\\times \\mathbf{d}}{\\|\\mathbf{v}\\times \\mathbf{d}\\|}$ where $\\mathbf{v}$ is the platform velocity direction and $\\mathbf{d} = [0,0,-1]$ is the downward direction. The off-boresight angle $\\psi$ is computed using the horizontal projection of $\\mathbf{l}$ by $\\cos(\\psi) = \\left| \\hat{\\mathbf{l}}_{xy}\\cdot \\mathbf{b} \\right|$, where $\\hat{\\mathbf{l}}_{xy}$ is the unit vector of $\\mathbf{l}$ projected onto the horizontal plane.\n- Use a cosine-squared azimuth antenna gain model $G(\\psi) = \\cos^2(\\psi)$.\n\nYour task:\n- For each test case, compute the RTC factor $F$ to map a slant-perpendicular area-referenced pixel value to a local-surface-area-referenced value at a specified reference range and reference gain. Use the dimensionless factor:\n$$F = J \\times \\frac{G_{\\text{ref}}}{G(\\psi)} \\times \\left(\\frac{R}{R_{\\text{ref}}}\\right)^4,$$\nwhere $J = \\dfrac{1}{|\\mathbf{n}\\cdot \\mathbf{l}|}$, $R$ is the slant range in meters, $R_{\\text{ref}}$ is the reference slant range in meters, and $G_{\\text{ref}} = 1$.\n\nImplementation details:\n- Geolocate the pixel by using the provided ground coordinates $\\mathbf{P}$ and sensor coordinates $\\mathbf{S}$, then compute the look vector $\\mathbf{l} = \\dfrac{\\mathbf{S}-\\mathbf{P}}{\\|\\mathbf{S}-\\mathbf{P}\\|}$ and slant range $R = \\|\\mathbf{S}-\\mathbf{P}\\|$ in meters.\n- Compute the local DEM normal $\\mathbf{n}$ from the provided $\\dfrac{\\partial z}{\\partial x}$ and $\\dfrac{\\partial z}{\\partial y}$ at the pixel.\n- Compute $\\theta_{\\text{loc}} = \\arccos(\\mathbf{n}\\cdot \\mathbf{l})$ in radians. Although $\\theta_{\\text{loc}}$ is not directly used in $F$, its estimation is required to validate geometry.\n- Compute the Jacobian $J = \\dfrac{1}{|\\mathbf{n}\\cdot \\mathbf{l}|}$.\n- Compute the azimuth antenna boresight $\\mathbf{b}$ from the platform velocity direction $\\mathbf{v}$ and $\\mathbf{d}=[0,0,-1]$. Then compute the off-boresight angle $\\psi$ using the horizontal projection of $\\mathbf{l}$ and obtain $G(\\psi) = \\cos^2(\\psi)$.\n- Use $G_{\\text{ref}} = 1$ and the provided $R_{\\text{ref}}$ to compute $F$ as above.\n\nUnits and angle requirements:\n- Distances must be in meters. Angles must be in radians.\n\nTest suite:\n- Use the following four test cases, each specified as a tuple $(\\mathbf{S}, \\mathbf{v}, \\mathbf{P}, \\partial z/\\partial x, \\partial z/\\partial y, R_{\\text{ref}})$ where vectors are three-dimensional:\n    1. Case $1$ (happy path, flat terrain, side-looking): $\\mathbf{S} = [0,0,1000]$, $\\mathbf{v} = [1,0,0]$, $\\mathbf{P} = [0,1000,0]$, $\\dfrac{\\partial z}{\\partial x} = 0$, $\\dfrac{\\partial z}{\\partial y} = 0$, $R_{\\text{ref}} = 1500$.\n    2. Case $2$ (moderate slope facing radar, reduced local incidence): $\\mathbf{S} = [0,0,1000]$, $\\mathbf{v} = [1,0,0]$, $\\mathbf{P} = [0,1000,0]$, $\\dfrac{\\partial z}{\\partial x} = 0$, $\\dfrac{\\partial z}{\\partial y} = 0.5773502691896257$, $R_{\\text{ref}} = 1500$.\n    3. Case $3$ (moderate slope away from radar, increased local incidence): $\\mathbf{S} = [0,0,1000]$, $\\mathbf{v} = [1,0,0]$, $\\mathbf{P} = [0,1000,0]$, $\\dfrac{\\partial z}{\\partial x} = 0$, $\\dfrac{\\partial z}{\\partial y} = -0.5773502691896257$, $R_{\\text{ref}} = 1500$.\n    4. Case $4$ (far range, flat terrain, stronger range loss): $\\mathbf{S} = [0,0,1000]$, $\\mathbf{v} = [1,0,0]$, $\\mathbf{P} = [0,3000,0]$, $\\dfrac{\\partial z}{\\partial x} = 0$, $\\dfrac{\\partial z}{\\partial y} = 0$, $R_{\\text{ref}} = 1500$.\n\nFinal output format:\n- Your program should produce a single line of output containing the RTC factors for the four test cases as a comma-separated list enclosed in square brackets. Express each RTC factor as a floating-point number rounded to six decimal places (dimensionless), in the order of the test cases above. For example: \"[$f_1,f_2,f_3,f_4$]\".",
            "solution": "The objective is to compute a multiplicative Radiometric Terrain Correction (RTC) factor, denoted by $F$, for several specified ground pixels. This factor corrects the measured SAR backscatter for geometric and radiometric effects, normalizing it to a standard reference geometry. The factor $F$ converts a pixel value representing backscatter from a slant-perpendicular area to a value representing backscatter from the true local surface area on the ground, referenced to a standard range and antenna gain.\n\nThe RTC factor $F$ is given by the formula:\n$$F = J \\times \\frac{G_{\\text{ref}}}{G(\\psi)} \\times \\left(\\frac{R}{R_{\\text{ref}}}\\right)^4$$\nHere, each component has a distinct physical meaning:\n1.  $J$: The area projection Jacobian, which corrects for the local surface slope.\n2.  $\\frac{G_{\\text{ref}}}{G(\\psi)}$: The antenna pattern correction, which normalizes the gain applied to the target to a reference gain $G_{\\text{ref}}$.\n3.  $\\left(\\frac{R}{R_{\\text{ref}}}\\right)^4$: The range loss correction, which normalizes the signal power spreading loss to a reference slant range $R_{\\text{ref}}$.\n\nWe will now detail the calculation of each term for a general case defined by a sensor position $\\mathbf{S}$, sensor velocity vector $\\mathbf{v}$, ground pixel position $\\mathbf{P}$, local surface gradients $\\frac{\\partial z}{\\partial x}$ and $\\frac{\\partial z}{\\partial y}$, and a reference range $R_{\\text{ref}}$.\n\n**1. Geolocalization and Slant Range**\nFirst, we establish the viewing geometry. The vector from the ground pixel $\\mathbf{P}$ to the sensor $\\mathbf{S}$ is $\\mathbf{S} - \\mathbf{P}$.\nThe slant range, $R$, is the magnitude of this vector:\n$$R = \\|\\mathbf{S} - \\mathbf{P}\\|$$\nThe unit look vector, $\\mathbf{l}$, points from the ground pixel to the sensor:\n$$\\mathbf{l} = \\frac{\\mathbf{S} - \\mathbf{P}}{\\|\\mathbf{S} - \\mathbf{P}\\|}$$\n\n**2. Local Surface Normal and Jacobian**\nThe local ground surface at $\\mathbf{P}$ is modeled as a plane defined by the Digital Elevation Model (DEM) gradients. The vector normal to this plane is derived from the gradient components. An unnormalized normal vector $\\mathbf{n}_{\\text{un}}$ is given by $[-\\frac{\\partial z}{\\partial x}, -\\frac{\\partial z}{\\partial y}, 1]$. Normalizing this vector yields the unit surface normal $\\mathbf{n}$:\n$$\\mathbf{n} = \\frac{[-\\frac{\\partial z}{\\partial x}, -\\frac{\\partial z}{\\partial y}, 1]}{\\sqrt{(\\frac{\\partial z}{\\partial x})^2 + (\\frac{\\partial z}{\\partial y})^2 + 1}}$$\nThe local incidence angle, $\\theta_{\\text{loc}}$, is the angle between the surface normal $\\mathbf{n}$ and the look vector $\\mathbf{l}$. It is found via their dot product: $\\cos(\\theta_{\\text{loc}}) = \\mathbf{n} \\cdot \\mathbf{l}$.\nThe area Jacobian, $J$, accounts for the projection of the local ground surface area onto the plane perpendicular to the look vector (the \"slant-perpendicular plane\"). It is the reciprocal of the absolute value of the cosine of the local incidence angle:\n$$J = \\frac{1}{|\\mathbf{n} \\cdot \\mathbf{l}|}$$\n\n**3. Antenna Gain Correction**\nThe antenna gain $G(\\psi)$ depends on the off-boresight angle $\\psi$. The boresight vector $\\mathbf{b}$ defines the direction of maximum antenna gain, which for a side-looking SAR is perpendicular to the platform's velocity vector $\\mathbf{v}$ and in the horizontal plane. We compute $\\mathbf{b}$ by taking the cross product of $\\mathbf{v}$ and the downward direction vector $\\mathbf{d} = [0, 0, -1]$, and normalizing the result:\n$$\\mathbf{b} = \\frac{\\mathbf{v} \\times \\mathbf{d}}{\\|\\mathbf{v} \\times \\mathbf{d}\\|}$$\nThe off-boresight angle $\\psi$ is the angle between the boresight vector $\\mathbf{b}$ and the horizontal projection of the look vector $\\mathbf{l}$. Let $\\mathbf{l} = [l_x, l_y, l_z]$. Its horizontal projection is $\\mathbf{l}_{xy} = [l_x, l_y, 0]$. The unit vector in this direction is $\\hat{\\mathbf{l}}_{xy} = \\frac{\\mathbf{l}_{xy}}{\\|\\mathbf{l}_{xy}\\|}$. The cosine of the angle $\\psi$ is given by the magnitude of the dot product:\n$$\\cos(\\psi) = |\\hat{\\mathbf{l}}_{xy} \\cdot \\mathbf{b}|$$\nThe problem specifies a cosine-squared antenna gain model, $G(\\psi) = \\cos^2(\\psi)$, and a reference gain $G_{\\text{ref}} = 1$. The correction factor is therefore $\\frac{1}{\\cos^2(\\psi)}$.\n\n**4. Application to Test Cases**\nWe apply this procedure to each test case.\n\n**Case 1:** Flat terrain, side-looking.\n-   Inputs: $\\mathbf{S} = [0,0,1000]$, $\\mathbf{v} = [1,0,0]$, $\\mathbf{P} = [0,1000,0]$, $\\frac{\\partial z}{\\partial x} = 0$, $\\frac{\\partial z}{\\partial y} = 0$, $R_{\\text{ref}} = 1500$.\n-   Geometry: $\\mathbf{S} - \\mathbf{P} = [0, -1000, 1000]$.\n    $R = \\sqrt{0^2 + (-1000)^2 + 1000^2} = 1000\\sqrt{2} \\approx 1414.21$ m.\n    $\\mathbf{l} = [0, -1/\\sqrt{2}, 1/\\sqrt{2}]$.\n-   Jacobian: $\\mathbf{n} = [0,0,1]$.\n    $\\mathbf{n} \\cdot \\mathbf{l} = 1/\\sqrt{2}$.\n    $J = \\frac{1}{|1/\\sqrt{2}|} = \\sqrt{2}$.\n-   Antenna Gain: $\\mathbf{b} = [0,1,0]$. $\\hat{\\mathbf{l}}_{xy} = [0,-1,0]$.\n    $\\cos(\\psi) = |[0,-1,0] \\cdot [0,1,0]| = 1$. $G(\\psi) = 1^2=1$.\n-   RTC Factor: $F_1 = \\sqrt{2} \\times \\frac{1}{1} \\times \\left(\\frac{1000\\sqrt{2}}{1500}\\right)^4 = \\sqrt{2} \\times \\left(\\frac{2\\sqrt{2}}{3}\\right)^4 = \\frac{64\\sqrt{2}}{81} \\approx 1.117320$.\n\n**Case 2:** Slope facing radar (foreshortening).\n-   Inputs: Same as Case 1, but with $\\frac{\\partial z}{\\partial y} = 1/\\sqrt{3}$.\n-   Geometry: $R$ and $\\mathbf{l}$ are unchanged.\n-   Jacobian: $\\mathbf{n}_{\\text{un}} = [0, -1/\\sqrt{3}, 1]$. $\\|\\mathbf{n}_{\\text{un}}\\| = 2/\\sqrt{3}$.\n    $\\mathbf{n} = [0, -1/2, \\sqrt{3}/2]$.\n    $\\mathbf{n} \\cdot \\mathbf{l} = (-1/2)(-1/\\sqrt{2}) + (\\sqrt{3}/2)(1/\\sqrt{2}) = \\frac{1+\\sqrt{3}}{2\\sqrt{2}}$.\n    $J = \\frac{2\\sqrt{2}}{1+\\sqrt{3}}$.\n-   Antenna Gain: Unchanged, $G(\\psi)=1$.\n-   RTC Factor: $F_2 = \\frac{2\\sqrt{2}}{1+\\sqrt{3}} \\times \\left(\\frac{1000\\sqrt{2}}{1500}\\right)^4 = \\frac{128\\sqrt{2}}{81(1+\\sqrt{3})} \\approx 0.818000$. The smaller factor reflects the smaller ground area per projected area (foreshortening).\n\n**Case 3:** Slope away from radar.\n-   Inputs: Same as Case 1, but with $\\frac{\\partial z}{\\partial y} = -1/\\sqrt{3}$.\n-   Geometry: $R$ and $\\mathbf{l}$ are unchanged.\n-   Jacobian: $\\mathbf{n}_{\\text{un}} = [0, 1/\\sqrt{3}, 1]$. $\\|\\mathbf{n}_{\\text{un}}\\| = 2/\\sqrt{3}$.\n    $\\mathbf{n} = [0, 1/2, \\sqrt{3}/2]$.\n    $\\mathbf{n} \\cdot \\mathbf{l} = (1/2)(-1/\\sqrt{2}) + (\\sqrt{3}/2)(1/\\sqrt{2}) = \\frac{\\sqrt{3}-1}{2\\sqrt{2}}$.\n    $J = \\frac{2\\sqrt{2}}{\\sqrt{3}-1}$.\n-   Antenna Gain: Unchanged, $G(\\psi)=1$.\n-   RTC Factor: $F_3 = \\frac{2\\sqrt{2}}{\\sqrt{3}-1} \\times \\left(\\frac{1000\\sqrt{2}}{1500}\\right)^4 = \\frac{128\\sqrt{2}}{81(\\sqrt{3}-1)} \\approx 3.052821$. The larger factor reflects the larger ground area per projected area.\n\n**Case 4:** Far range, flat terrain.\n-   Inputs: Same as Case 1, but with $\\mathbf{P} = [0,3000,0]$.\n-   Geometry: $\\mathbf{S} - \\mathbf{P} = [0, -3000, 1000]$.\n    $R = \\sqrt{(-3000)^2 + 1000^2} = 1000\\sqrt{10} \\approx 3162.28$ m.\n    $\\mathbf{l} = [0, -3/\\sqrt{10}, 1/\\sqrt{10}]$.\n-   Jacobian: $\\mathbf{n} = [0,0,1]$.\n    $\\mathbf{n} \\cdot \\mathbf{l} = 1/\\sqrt{10}$.\n    $J = \\sqrt{10}$.\n-   Antenna Gain: $\\mathbf{b} = [0,1,0]$. $\\hat{\\mathbf{l}}_{xy} = [0,-1,0]$.\n    $\\cos(\\psi) = 1$. $G(\\psi) = 1$.\n-   RTC Factor: $F_4 = \\sqrt{10} \\times \\frac{1}{1} \\times \\left(\\frac{1000\\sqrt{10}}{1500}\\right)^4 = \\sqrt{10} \\times \\left(\\frac{2\\sqrt{10}}{3}\\right)^4 = \\frac{1600\\sqrt{10}}{81} \\approx 62.464744$. The large factor is dominated by the range loss correction term, as $R > R_{\\text{ref}}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Radiometric Terrain Correction (RTC) factor for a set of\n    synthetic SAR imaging scenarios.\n    \"\"\"\n\n    # Test suite:\n    # Each case is a tuple: (S, v, P, dz_dx, dz_dy, R_ref)\n    # S: sensor position [x, y, z] in meters\n    # v: platform velocity vector [vx, vy, vz]\n    # P: ground pixel position [x, y, z] in meters\n    # dz_dx, dz_dy: partial derivatives of the DEM at P\n    # R_ref: reference slant range in meters\n    test_cases = [\n        # Case 1: happy path, flat terrain, side-looking\n        ([0, 0, 1000], [1, 0, 0], [0, 1000, 0], 0, 0, 1500),\n        # Case 2: moderate slope facing radar\n        ([0, 0, 1000], [1, 0, 0], [0, 1000, 0], 0, 0.5773502691896257, 1500),\n        # Case 3: moderate slope away from radar\n        ([0, 0, 1000], [1, 0, 0], [0, 1000, 0], 0, -0.5773502691896257, 1500),\n        # Case 4: far range, flat terrain\n        ([0, 0, 1000], [1, 0, 0], [0, 3000, 0], 0, 0, 1500)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        S_list, v_list, P_list, dz_dx, dz_dy, R_ref = case\n        \n        # Convert lists to numpy arrays for vector operations\n        S = np.array(S_list, dtype=float)\n        v = np.array(v_list, dtype=float)\n        P = np.array(P_list, dtype=float)\n        \n        # Step 1: Geolocate the pixel and compute slant range R and look vector l\n        S_minus_P = S - P\n        R = np.linalg.norm(S_minus_P)\n        l = S_minus_P / R\n        \n        # Step 2: Compute the local surface normal n\n        n_unnormalized = np.array([-dz_dx, -dz_dy, 1.0])\n        n = n_unnormalized / np.linalg.norm(n_unnormalized)\n        \n        # Step 3: Compute the local incidence angle and the area Jacobian J\n        # cos(theta_loc) = n . l\n        # J = 1 / |cos(theta_loc)|\n        n_dot_l = np.dot(n, l)\n        # The problem geometry ensures n_dot_l is not zero.\n        J = 1.0 / abs(n_dot_l)\n        \n        # Step 4: Compute the antenna gain correction\n        # Boresight vector b\n        d = np.array([0.0, 0.0, -1.0])\n        b_unnormalized = np.cross(v, d)\n        # The problem geometry ensures v is not parallel to d.\n        b = b_unnormalized / np.linalg.norm(b_unnormalized)\n        \n        # Off-boresight angle psi\n        l_xy = np.array([l[0], l[1], 0.0])\n        norm_l_xy = np.linalg.norm(l_xy)\n        \n        if norm_l_xy < 1e-9:\n            # Nadir-looking case: psi is undefined or can be taken as pi/2\n            # Here, cos(psi) would be 0, leading to infinite gain correction\n            # This case is not in the test suite\n            cos_psi = 0.0\n        else:\n            l_xy_hat = l_xy / norm_l_xy\n            cos_psi = abs(np.dot(l_xy_hat, b))\n            \n        # Antenna gain G(psi)\n        G_psi = cos_psi**2\n        \n        # Reference gain is 1\n        G_ref = 1.0\n        \n        # Step 5: Compute the final RTC factor F\n        # F = J * (G_ref / G(psi)) * (R / R_ref)^4\n        if G_psi < 1e-9:\n             # Gain is zero, correction factor would be infinite\n             # A practical implementation might cap this or flag the pixel\n             F = np.inf\n        else:\n             F = J * (G_ref / G_psi) * ((R / R_ref)**4)\n        \n        results.append(F)\n\n    # Format the final output as a comma-separated list of floating-point\n    # numbers with six decimal places, enclosed in square brackets.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Once geometric and radiometric effects are corrected, the primary remaining challenge is mitigating speckle noise without sacrificing image resolution. This practice () places you in the role of an algorithm designer tasked with parameterizing a Non-Local Means (NLM) filter, a powerful speckle reduction technique. You will derive a principled rule that adaptively balances the need for noise reduction against the preservation of fine details, linking filter parameters to measurable properties of the scene and the desired level of smoothing.",
            "id": "3795000",
            "problem": "A radiometrically terrain-corrected Synthetic Aperture Radar (SAR) backscatter image is to be despeckled using a Non-Local Means (NLM) filter. The SAR intensity model is multiplicative: the observed intensity $I(\\mathbf{x})$ at location $\\mathbf{x}$ is $I(\\mathbf{x}) = S(\\mathbf{x}) X(\\mathbf{x})$, where $S(\\mathbf{x})$ is the true backscatter and $X(\\mathbf{x})$ is a unit-mean speckle term. For a single-look acquisition, $X(\\mathbf{x})$ is well modeled by a Gamma distribution with shape parameter equal to the Equivalent Number of Looks (ENL) $L = 1$, implying $\\operatorname{Var}(X) = 1/L = 1$. Assume the speckle exhibits spatial correlation with a correlation length $\\ell > 0$ (on the ground-range azimuth plane), meaning samples separated by distances $\\gtrsim \\ell$ can be treated as effectively independent for averaging. The NLM filter averages pixels deemed similar to a reference pixel based on patch comparisons within a search window of radius $R_w$, where similarity is assessed by comparing patches of radius $R_p$ centered on candidate pixels.\n\nDefine the heterogeneity metric $H(\\mathbf{x}) = \\|\\nabla \\log S(\\mathbf{x})\\|$, and consider a fixed similarity tolerance $\\tau > 0$ on the log-backscatter difference used in the NLM distance function. For small neighborhoods, approximate $\\log S(\\mathbf{x} + \\mathbf{r})$ by its first-order Taylor expansion in $\\mathbf{r}$ near $\\mathbf{x}$, and assume that the spatial correlation of speckle is negligible beyond distance $\\ell$, so that the effective variance reduction from averaging $K$ similar, independent samples is approximately a factor of $K$ in ENL. Let the target ENL improvement factor be $G_{\\text{target}} > 1$. You aim to select $R_w$ and $R_p$ to achieve $G_{\\text{target}}$ while limiting resolution loss due to averaging across heterogeneous regions.\n\nFrom first principles, derive a rule-of-thumb that links $R_w$ and $R_p$ to the heterogeneity metric $H$, the similarity tolerance $\\tau$, the speckle correlation length $\\ell$, and the target ENL improvement $G_{\\text{target}}$, balancing ENL improvement with spatial resolution. Then select which of the following rules is most consistent with that derivation:\n\nA. Set $R_p = \\alpha \\,\\dfrac{\\tau}{H}$ with $\\alpha \\in [0.3, 0.5]$, and $R_w = \\dfrac{\\tau}{H}$; additionally enforce the feasibility condition $G_{\\text{target}} \\le \\left(\\dfrac{\\tau}{H \\ell}\\right)^2$, otherwise reduce $G_{\\text{target}}$.\n\nB. Set $R_p = \\alpha \\,\\ell$ with $\\alpha \\in [0.3, 0.5]$, and $R_w = \\ell \\,\\sqrt{G_{\\text{target}}}$, independent of $H$, because speckle dominates the error budget.\n\nC. Set $R_p = \\alpha \\,\\dfrac{\\tau}{H}$ with $\\alpha \\in [0.3, 0.5]$, and $R_w = \\ell \\,\\sqrt{G_{\\text{target}}}$ always, since the window must be large enough to gather the required number of independent samples.\n\nD. Set $R_p = \\alpha \\,\\dfrac{\\tau}{H}$ with $\\alpha \\in [0.3, 0.5]$, and $R_w = \\min\\!\\left(\\dfrac{\\tau}{H}, \\,\\ell \\,\\sqrt{G_{\\text{target}}}\\right)$, so that the window does not exceed the local similarity extent in heterogeneous areas nor exceed what is necessary to reach the target ENL in homogeneous areas.\n\nChoose the option that best follows from a derivation grounded in the multiplicative speckle model, the ENL definition, the spatial correlation length, and the local linearization of $\\log S(\\mathbf{x})$ under a fixed similarity tolerance.",
            "solution": "To solve this problem, we must derive a rule-of-thumb that links the Non-Local Means (NLM) filter parameters, patch radius $R_p$ and search window radius $R_w$, to the properties of the SAR image and the filtering goals. The derivation needs to balance two competing objectives: reducing speckle noise and preserving spatial resolution.\n\nThe SAR intensity model is multiplicative, $I(\\mathbf{x}) = S(\\mathbf{x}) X(\\mathbf{x})$. Working in the logarithmic domain simplifies the problem by converting the multiplicative noise to additive noise:\n$$ \\log I(\\mathbf{x}) = \\log S(\\mathbf{x}) + \\log X(\\mathbf{x}) $$\nThe NLM filter aims to estimate the true log-backscatter, $\\log S(\\mathbf{x})$, by averaging log-intensity values from other pixels $\\mathbf{y}$ that are deemed similar to the target pixel $\\mathbf{x}$.\n\n**1. Constraint from Resolution Preservation and Homogeneity**\nTo avoid blurring and preserve image details, the filter should only average pixels that belong to the same underlying scene component. The problem defines a similarity tolerance $\\tau$ on the log-backscatter difference. This implies that we should only consider pixels $\\mathbf{y}$ in the search window for which $|\\log S(\\mathbf{y}) - \\log S(\\mathbf{x})| \\le \\tau$.\n\nUsing the first-order Taylor approximation for $\\log S(\\mathbf{y})$ around $\\mathbf{x}$ for a displacement $\\mathbf{r} = \\mathbf{y} - \\mathbf{x}$:\n$$ \\log S(\\mathbf{y}) \\approx \\log S(\\mathbf{x}) + \\nabla \\log S(\\mathbf{x}) \\cdot (\\mathbf{y} - \\mathbf{x}) $$\nThe difference is approximately $|\\nabla \\log S(\\mathbf{x}) \\cdot (\\mathbf{y} - \\mathbf{x})|$. Using the Cauchy-Schwarz inequality and the given heterogeneity metric $H(\\mathbf{x}) = \\|\\nabla \\log S(\\mathbf{x})\\|$, we get:\n$$ |\\log S(\\mathbf{y}) - \\log S(\\mathbf{x})| \\le H(\\mathbf{x}) \\, \\|\\mathbf{y} - \\mathbf{x}\\| $$\nTo respect the tolerance $\\tau$, we must have $H(\\mathbf{x}) \\, \\|\\mathbf{y} - \\mathbf{x}\\| \\lesssim \\tau$. This defines a \"region of similarity\" around $\\mathbf{x}$ with a characteristic radius $R_{\\text{sim}} \\approx \\tau / H(\\mathbf{x})$. To preserve resolution, the search window radius $R_w$ must be confined to this region:\n$$ R_w \\le \\frac{\\tau}{H(\\mathbf{x})} $$\nThe patch radius, $R_p$, should also be constrained by heterogeneity. For a patch to be a consistent descriptor of local structure, the signal variation within it should be small, typically a fraction $\\alpha$ of the total tolerance $\\tau$. This gives a rule for the patch radius:\n$$ R_p \\approx \\alpha \\frac{\\tau}{H(\\mathbf{x})}, \\quad \\text{for some } \\alpha < 1 $$\n\n**2. Constraint from Speckle Reduction and ENL Improvement**\nThe second goal is to achieve a target ENL improvement factor of $G_{\\text{target}}$. Since averaging $K$ independent samples yields an ENL of approximately $K$, we need to find and average $K \\approx G_{\\text{target}}$ independent samples.\n\nThe problem states that speckle samples are independent if separated by a distance greater than the correlation length $\\ell$. The number of independent samples available in a 2D search window of radius $R_w$ can be estimated as the ratio of the search area to the area of an \"independence cell\" (approximated as a disk of radius $\\ell$):\n$$ K \\approx \\frac{\\pi R_w^2}{\\pi \\ell^2} = \\left(\\frac{R_w}{\\ell}\\right)^2 $$\nTo achieve the target speckle reduction ($K \\approx G_{\\text{target}}$), the search window must be large enough:\n$$ G_{\\text{target}} \\approx \\left(\\frac{R_w}{\\ell}\\right)^2 \\implies R_w \\approx \\ell \\sqrt{G_{\\text{target}}} $$\n\n**3. Synthesizing the Adaptive Rule for $R_w$**\nWe have two constraints on the search window radius $R_w$: one from resolution preservation ($R_w \\le \\tau/H$) and one from speckle reduction ($R_w \\approx \\ell \\sqrt{G_{\\text{target}}}$). A robust algorithm must respect both. The optimal choice for $R_w$ is therefore the minimum of these two values, ensuring the search is large enough for denoising but not so large that it blurs details:\n$$ R_w = \\min\\left(\\frac{\\tau}{H}, \\ell \\sqrt{G_{\\text{target}}}\\right) $$\nThis rule is adaptive:\n- In **heterogeneous regions** (large $H$), $\\tau/H$ is small and limits $R_w$, prioritizing detail preservation.\n- In **homogeneous regions** (small $H$), $\\tau/H$ is large, and $R_w$ is limited by the need to gather samples for the target ENL, $\\ell \\sqrt{G_{\\text{target}}}$.\n\n**Evaluating the Options:**\n- **Option A** sets $R_w = \\tau/H$, ignoring the ENL requirement for homogeneous areas.\n- **Option B** and **C** set $R_w = \\ell \\sqrt{G_{\\text{target}}}$, ignoring the heterogeneity constraint, which would cause blurring.\n- **Option D** correctly uses the $\\min$ function to synthesize both constraints, matching our derivation. It also correctly sets $R_p = \\alpha \\frac{\\tau}{H}$.\n\nTherefore, option D is the most consistent with a principled derivation.",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "A robust scientific workflow requires not just processing but also rigorous validation. This capstone exercise () introduces a systems-level approach to quality assessment for a full SAR processing chain, including both RTC and speckle filtering. You will implement a sophisticated cross-validation scheme that uses overlapping acquisitions to perform inter-pass calibration and compute a statistical consistency metric, providing a powerful method for verifying the quality and reliability of the final data products.",
            "id": "3795006",
            "problem": "Design and implement a cross-validation algorithm to assess the joint quality of Radiometric Terrain Correction (RTC) and nonlocal speckle filtering using overlapping Synthetic Aperture Radar (SAR) acquisitions. The method must be principled, starting from a fundamental statistical model of coherent imaging and proceeding to a testable repeat-pass consistency metric.\n\nAssume the following fundamental base:\n- In coherent imaging, the multiplicative speckle model holds for backscatter intensity. Let the true terrain backscatter for pixel $p$ be $\\mu_p$ (unitless, linear power). For pass $k$, the RTC-corrected and filtered observation is $Y_{p,k} = \\gamma_k \\mu_p S_{p,k}$, where $\\gamma_k &gt; 0$ is an unknown pass-specific calibration gain (unitless) and $S_{p,k}$ is a multiplicative speckle term with $\\mathbb{E}[S_{p,k}]=1$.\n- Nonlocal filtering increases the effective number of looks. The Equivalent Number of Looks (ENL) for pixel $p$ and pass $k$ is $L_{\\text{eff}}(p,k) \\in \\mathbb{N}$ with variance model $\\operatorname{Var}(S_{p,k}) = 1/L_{\\text{eff}}(p,k)$ and independence across passes and pixels for the purposes of the cross-validation variance calculation.\n- Radiometric Terrain Correction (RTC) removes deterministic geometric modulations so that $Y_{p,k}$ is already in terrain-normalized units. No additional physical units are involved in the metric; all quantities are unitless in linear power.\n\nYou must derive a leave-one-pass-out cross-validation scheme that uses the overlapping area across passes to construct, for each held-out pass $k$, a per-pixel consensus estimate from the remaining passes and a normalized residual whose expectation, under the base model, is anchored by the variance predicted from $L_{\\text{eff}}(p,k)$. The scheme must include an internal pass-gain cross-calibration step to estimate $\\gamma_k$ from the overlaps by weighted least squares. The final repeat-pass consistency metric must be the median of the normalized squared residuals across all pixels and passes. Values near $1$ indicate consistency with the assumed RTC and ENL; values substantially larger than $1$ indicate residual inconsistencies (e.g., RTC errors, calibration biases, or underestimated noise), whereas values substantially smaller than $1$ indicate over-smoothing or overestimated noise.\n\nThe algorithmic steps to implement are:\n1. Initialize $\\gamma_k \\leftarrow 1$ for all passes $k$.\n2. For a fixed number of iterations (use $5$):\n   - For each pass $k$, form the leave-one-pass-out consensus for each pixel $p$:\n     $$\\widehat{\\mu}_{p,-k} = \\frac{\\sum\\limits_{j \\neq k} L_{\\text{eff}}(p,j) \\, \\frac{Y_{p,j}}{\\gamma_j}}{\\sum\\limits_{j \\neq k} L_{\\text{eff}}(p,j)}.$$\n   - Update $\\gamma_k$ by minimizing $\\sum_p L_{\\text{eff}}(p,k)\\left(\\frac{Y_{p,k}}{\\gamma_k} - \\widehat{\\mu}_{p,-k}\\right)^2$ with respect to $\\gamma_k$ (closed form):\n     $$\\gamma_k \\leftarrow \\frac{\\sum\\limits_p L_{\\text{eff}}(p,k)\\, Y_{p,k}\\, \\widehat{\\mu}_{p,-k}}{\\sum\\limits_p L_{\\text{eff}}(p,k)\\, \\widehat{\\mu}_{p,-k}^{2}}.$$\n3. After the last iteration, for each pixel $p$ and pass $k$, recompute $\\widehat{\\mu}_{p,-k}$ as above and form the normalized squared residual using the variance predicted by independence of the held-out observation and the consensus mean:\n   $$q_{p,k} = \\frac{\\left(\\frac{Y_{p,k}}{\\gamma_k} - \\widehat{\\mu}_{p,-k}\\right)^2}{\\widehat{\\mu}_{p,-k}^{2}\\left(\\frac{1}{L_{\\text{eff}}(p,k)} + \\frac{1}{\\sum_{j \\neq k} L_{\\text{eff}}(p,j)}\\right)}.$$\n4. Report the repeat-pass consistency score $M$ as the median of $\\{q_{p,k}\\}$ over all pixels and passes.\n\nImplement the algorithm for the following test suite. For all cases, there are $K=3$ passes and $N=4$ pixels in the overlapping region. All quantities are unitless linear power, and angles are not required. The program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (e.g., $\\left[0.123456,1.234568,2.500000\\right]$).\n\nTest suite definitions:\n- Case $1$ (baseline, correct RTC and ENL):\n  - True backscatter vector $\\mu = [0.8, 1.2, 0.6, 1.5]$.\n  - Multiplicative speckle realizations per pass (deterministic for testing):\n    - Pass $1$: $S_{\\cdot,1} = [0.9, 1.1, 1.05, 0.95]$.\n    - Pass $2$: $S_{\\cdot,2} = [1.05, 0.95, 1.1, 0.9]$.\n    - Pass $3$: $S_{\\cdot,3} = [1.0, 0.9, 0.95, 1.1]$.\n  - Observations: $Y_{p,k} = \\mu_p \\, S_{p,k}$ for all $p,k$.\n  - Effective looks:\n    - Pass $1$: $L_{\\text{eff}}(\\cdot,1) = [3,3,3,3]$.\n    - Pass $2$: $L_{\\text{eff}}(\\cdot,2) = [4,4,4,4]$.\n    - Pass $3$: $L_{\\text{eff}}(\\cdot,3) = [2,2,2,2]$.\n- Case $2$ (pass-$2$ calibration bias before cross-calibration; same speckle as Case $1$):\n  - Observations: $Y_{p,k} = \\gamma_k \\, \\mu_p \\, S_{p,k}$ with $\\gamma = [1.0, 1.1, 1.0]$.\n  - Effective looks identical to Case $1$.\n- Case $3$ (overestimated ENL; same observations as Case $1$):\n  - Observations identical to Case $1$.\n  - Effective looks are doubled relative to Case $1$:\n    - Pass $1$: $L_{\\text{eff}}(\\cdot,1) = [6,6,6,6]$.\n    - Pass $2$: $L_{\\text{eff}}(\\cdot,2) = [8,8,8,8]$.\n    - Pass $3$: $L_{\\text{eff}}(\\cdot,3) = [4,4,4,4]$.\n\nYour program must:\n- Implement the iterative cross-calibration and leave-one-pass-out residual computation described above.\n- Compute the median consistency score $M$ for each case.\n- Output a single line string in the exact format $\\left[\\text{M\\_case1},\\text{M\\_case2},\\text{M\\_case3}\\right]$ with each number rounded to six decimal places. No other text should be printed.",
            "solution": "The problem requires the design and implementation of a leave-one-pass-out cross-validation algorithm to assess the consistency of a stack of overlapping Synthetic Aperture Radar (SAR) acquisitions that have undergone Radiometric Terrain Correction (RTC) and nonlocal speckle filtering. The quality is quantified by a single metric, $M$, which represents the median of normalized squared residuals computed across all pixels and passes.\n\nThe foundation of this method is the multiplicative speckle model for coherent imaging. For a given pixel $p$ and acquisition pass $k$, the observed intensity, $Y_{p,k}$, which has been corrected for geometric and terrain-induced radiometric distortions (RTC) and speckle filtered, is modeled as:\n$$Y_{p,k} = \\gamma_k \\mu_p S_{p,k}$$\nHere, $\\mu_p$ is the true, unknown backscatter coefficient of the terrain at pixel $p$, a unitless quantity in linear power. $\\gamma_k > 0$ is an unknown, unitless, pass-specific calibration gain that accounts for residual radiometric variations between acquisitions. $S_{p,k}$ is the multiplicative speckle contribution, a random variable with mean $\\mathbb{E}[S_{p,k}]=1$. The speckle filtering process increases the Effective Number of Looks (ENL), denoted $L_{\\text{eff}}(p,k)$, which relates to the variance of the speckle term as $\\operatorname{Var}(S_{p,k}) = 1/L_{\\text{eff}}(p,k)$. For the purpose of this analysis, the speckle terms $S_{p,k}$ are assumed to be independent across both pixels and passes.\n\nThe core of the cross-validation scheme is to evaluate the consistency of each pass against a consensus formed by the others. For each pass $k$, which is temporarily held out, we generate a consensus estimate of the true backscatter, $\\widehat{\\mu}_{p,-k}$, for each pixel $p$ using the data from all other passes $j \\neq k$. The gain-corrected observation from pass $j$ is an estimate of the true backscatter: $Y_{p,j}/\\gamma_j = \\mu_p S_{p,j}$. The variance of this estimate is $\\operatorname{Var}(\\mu_p S_{p,j}) = \\mu_p^2 \\operatorname{Var}(S_{p,j}) = \\mu_p^2 / L_{\\text{eff}}(p,j)$. The optimal (minimum variance) linear combination of these independent estimates is an inverse-variance weighted average. The weights are therefore proportional to $L_{\\text{eff}}(p,j)$. This leads to the formula for the leave-one-out consensus estimate:\n$$\\widehat{\\mu}_{p,-k} = \\frac{\\sum\\limits_{j \\neq k} L_{\\text{eff}}(p,j) \\, \\frac{Y_{p,j}}{\\gamma_j}}{\\sum\\limits_{j \\neq k} L_{\\text{eff}}(p,j)}$$\nThe calibration gains $\\gamma_k$ are unknown and must be estimated iteratively. A key step is the update rule for the gains. The specified rule is:\n$$\\gamma_k \\leftarrow \\frac{\\sum\\limits_p L_{\\text{eff}}(p,k)\\, Y_{p,k}\\, \\widehat{\\mu}_{p,-k}}{\\sum\\limits_p L_{\\text{eff}}(p,k)\\, \\widehat{\\mu}_{p,-k}^{2}}$$\nThis formula is the closed-form solution for a weighted least-squares regression of $Y_{p,k}$ on $\\widehat{\\mu}_{p,-k}$ (with weights $L_{\\text{eff}}(p,k)$), a standard and physically sound model for relative radiometric calibration. We implement this explicit formula as defined by the algorithm.\n\nAfter a fixed number of iterations ($5$), the final estimated gains $\\gamma_k$ are used to compute the quality metric. For each pixel $p$ and pass $k$, we form the residual between the gain-corrected observation and the consensus estimate:\n$$R_{p,k} = \\frac{Y_{p,k}}{\\gamma_k} - \\widehat{\\mu}_{p,-k}$$\nUnder the assumption that our model is correct and the gains are accurately estimated, the expectation of this residual is zero. The variance of the residual is calculated based on the independence of the held-out pass and the passes forming the consensus:\n$$\\operatorname{Var}(R_{p,k}) = \\operatorname{Var}\\left(\\frac{Y_{p,k}}{\\gamma_k}\\right) + \\operatorname{Var}(\\widehat{\\mu}_{p,-k})$$\nThe individual variance terms are:\n$$\\operatorname{Var}\\left(\\frac{Y_{p,k}}{\\gamma_k}\\right) = \\operatorname{Var}(\\mu_p S_{p,k}) = \\mu_p^2 \\operatorname{Var}(S_{p,k}) = \\frac{\\mu_p^2}{L_{\\text{eff}}(p,k)}$$\n$$\\operatorname{Var}(\\widehat{\\mu}_{p,-k}) = \\frac{\\mu_p^2}{\\sum_{j \\neq k} L_{\\text{eff}}(p,j)}$$\nCombining these yields the total variance of the residual:\n$$\\operatorname{Var}(R_{p,k}) = \\mu_p^2 \\left( \\frac{1}{L_{\\text{eff}}(p,k)} + \\frac{1}{\\sum_{j \\neq k} L_{\\text{eff}}(p,j)} \\right)$$\nTo form a normalized, unitless quantity, we compute the squared residual normalized by its expected variance. Since the true backscatter $\\mu_p$ is unknown, we substitute its best available estimate, $\\widehat{\\mu}_{p,-k}$. This gives the normalized squared residual, $q_{p,k}$:\n$$q_{p,k} = \\frac{\\left(\\frac{Y_{p,k}}{\\gamma_k} - \\widehat{\\mu}_{p,-k}\\right)^2}{\\widehat{\\mu}_{p,-k}^{2}\\left(\\frac{1}{L_{\\text{eff}}(p,k)} + \\frac{1}{\\sum_{j \\neq k} L_{\\text{eff}}(p,j)}\\right)}$$\nThe expectation of $q_{p,k}$ is approximately $1$ if the data are consistent with the model. The final repeat-pass consistency score, $M$, is the median of the set of all computed $q_{p,k}$ values across all pixels and passes. The median is used for its robustness to outliers.\n\nThe algorithm proceeds as follows:\n1.  Initialize gains $\\gamma_k = 1$ for all passes $k$.\n2.  Iterate $5$ times:\n    a. For each pass $k=1, \\dots, K$, compute the leave-one-out consensus $\\widehat{\\mu}_{p,-k}$ for all pixels $p$ using the current gains $\\gamma_j$ for $j \\neq k$.\n    b. For each pass $k$, update its gain $\\gamma_k$ using the weighted least-squares formula with the newly computed consensus map.\n3.  After iterating, compute the final consensus maps $\\widehat{\\mu}_{p,-k}$ for all $p, k$ using the final gains.\n4.  Compute the normalized squared residuals $q_{p,k}$ for all $p, k$.\n5.  Calculate the final metric $M$ as the median of all $q_{p,k}$ values.\n\nThis procedure is applied to the three test cases provided.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute the consistency score for each.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n\n    # Common parameters\n    mu_true = np.array([0.8, 1.2, 0.6, 1.5])\n    S_pass1 = np.array([0.9, 1.1, 1.05, 0.95])\n    S_pass2 = np.array([1.05, 0.95, 1.1, 0.9])\n    S_pass3 = np.array([1.0, 0.9, 0.95, 1.1])\n    S_matrix = np.vstack([S_pass1, S_pass2, S_pass3])\n    Y_base = mu_true * S_matrix\n\n    L_eff_base = np.array([\n        [3, 3, 3, 3],\n        [4, 4, 4, 4],\n        [2, 2, 2, 2]\n    ], dtype=float)\n\n    test_cases = [\n        {\n            \"name\": \"Case 1: Baseline\",\n            \"Y\": Y_base,\n            \"L_eff\": L_eff_base\n        },\n        {\n            \"name\": \"Case 2: Pass-2 calibration bias\",\n            \"Y\": Y_base * np.array([1.0, 1.1, 1.0])[:, np.newaxis],\n            \"L_eff\": L_eff_base\n        },\n        {\n            \"name\": \"Case 3: Overestimated ENL\",\n            \"Y\": Y_base,\n            \"L_eff\": L_eff_base * 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        m_score = calculate_consistency_score(case[\"Y\"], case[\"L_eff\"])\n        results.append(m_score)\n    \n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\n\ndef calculate_consistency_score(Y, L_eff, num_iterations=5):\n    \"\"\"\n    Implements the cross-validation algorithm for a single test case.\n\n    Args:\n        Y (np.ndarray): KxN array of observed intensities.\n        L_eff (np.ndarray): KxN array of effective number of looks.\n        num_iterations (int): Number of iterations for gain calibration.\n\n    Returns:\n        float: The median consistency score M.\n    \"\"\"\n    K, N = Y.shape\n    gamma = np.ones(K)\n    \n    # --- Step 1 & 2: Iterative Cross-Calibration ---\n    for _ in range(num_iterations):\n        gamma_new = np.copy(gamma)\n        for k in range(K):\n            # Identify passes other than k\n            j_neq_k = np.arange(K) != k\n            \n            # --- Step 2a: Form leave-one-pass-out consensus ---\n            # Corrected Y values for passes j != k\n            Y_corr_neg_k = Y[j_neq_k] / gamma[j_neq_k, np.newaxis]\n            \n            # Numerator for mu_hat: sum(L_eff * Y_corr) over j != k\n            mu_hat_num = np.sum(L_eff[j_neq_k] * Y_corr_neg_k, axis=0)\n            \n            # Denominator for mu_hat: sum(L_eff) over j != k\n            mu_hat_den = np.sum(L_eff[j_neq_k], axis=0)\n            \n            mu_hat_neg_k = mu_hat_num / mu_hat_den\n            \n            # --- Step 2b: Update gamma_k ---\n            # Numerator for gamma_k update\n            gamma_num = np.sum(L_eff[k] * Y[k] * mu_hat_neg_k)\n            \n            # Denominator for gamma_k update\n            gamma_den = np.sum(L_eff[k] * mu_hat_neg_k**2)\n\n            if gamma_den > 0:\n                gamma_new[k] = gamma_num / gamma_den\n        \n        gamma = gamma_new\n\n    # --- Step 3 & 4: Compute Normalized Squared Residuals ---\n    q_values = []\n    for k in range(K):\n        # Identify passes other than k\n        j_neq_k = np.arange(K) != k\n        \n        # Recompute final mu_hat_neg_k with final gamma values\n        Y_corr_neg_k = Y[j_neq_k] / gamma[j_neq_k, np.newaxis]\n        mu_hat_num = np.sum(L_eff[j_neq_k] * Y_corr_neg_k, axis=0)\n        mu_hat_den = np.sum(L_eff[j_neq_k], axis=0)\n        mu_hat_neg_k = mu_hat_num / mu_hat_den\n        \n        # Calibrated observation for pass k\n        Y_cal_k = Y[k] / gamma[k]\n        \n        # Numerator of q_{p,k}\n        q_num = (Y_cal_k - mu_hat_neg_k)**2\n        \n        # Denominator of q_{p,k}\n        var_term1 = 1.0 / L_eff[k]\n        var_term2 = 1.0 / np.sum(L_eff[j_neq_k], axis=0)\n        q_den = mu_hat_neg_k**2 * (var_term1 + var_term2)\n\n        # Handle potential division by zero, though unlikely with problem constraints\n        # A residual of 0/0 is 0. A non-zero residual with 0 variance is infinity.\n        # We replace NaNs with 0 and Infs with a large number, though not expected here.\n        with np.errstate(divide='ignore', invalid='ignore'):\n            q_k = np.divide(q_num, q_den)\n            q_k[np.isnan(q_k)] = 0.0 # Occurs if num and den are both 0.\n\n        q_values.extend(q_k.tolist())\n        \n    # --- Step 5: Report the median consistency score ---\n    return np.median(q_values)\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}