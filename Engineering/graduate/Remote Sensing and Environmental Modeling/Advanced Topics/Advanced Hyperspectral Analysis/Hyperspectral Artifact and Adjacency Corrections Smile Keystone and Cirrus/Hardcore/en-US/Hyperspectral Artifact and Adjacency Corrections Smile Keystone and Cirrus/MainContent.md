## Introduction
Hyperspectral remote sensing provides an unparalleled ability to characterize the Earth's surface by capturing detailed spectral information across hundreds of contiguous bands. This rich data stream is the foundation for [quantitative analysis](@entry_id:149547) in fields from ecology to geology. However, the radiance measured by a sensor is not a pristine reflection of the surface; it is a signal systematically distorted by the instrument's own optical imperfections and profoundly altered by its journey through the atmosphere. Failing to account for these instrumental and environmental artifacts can lead to significant errors and misleading scientific conclusions.

This article addresses this critical knowledge gap by providing a comprehensive examination of the most common and impactful artifacts in hyperspectral data. It unpacks the physical origins of these distortions and details the methodological principles required for their correction, transforming raw data into scientifically robust Analysis-Ready Data (ARD). Across the following chapters, you will gain a deep understanding of these complex phenomena. The first chapter, "Principles and Mechanisms," establishes the fundamental physics of instrumental artifacts like spectral smile and keystone, as well as environmental effects like atmospheric adjacency and cirrus cloud contamination. The subsequent chapter, "Applications and Interdisciplinary Connections," explores how these artifacts impact real-world scientific applications and details the advanced methods used to correct them. Finally, "Hands-On Practices" provides an opportunity to apply these concepts to practical, quantitative problems, solidifying your understanding of how to diagnose and manage these critical data quality issues.

## Principles and Mechanisms

The transformation of at-sensor radiance into scientifically robust data products, such as surface reflectance, requires a profound understanding of the physical processes and instrumental characteristics that shape the measured signal. The radiance measured by a hyperspectral sensor is not a pristine representation of the Earth's surface; it is a signal that has been modulated by the atmosphere and perturbed by the non-ideal behavior of the instrument itself. This chapter delineates the principles and mechanisms of several key artifacts and environmental effects that are ubiquitous in hyperspectral remote sensing: the instrumental artifacts known as **spectral smile** and **keystone**, and the environmental perturbations of **atmospheric adjacency effects** and **thin cirrus cloud contamination**. Understanding these phenomena from first principles is the prerequisite for their correction.

### Instrument-Induced Artifacts: The Spatio-Spectral Mapping

An imaging spectrometer is fundamentally a system that maps a continuous, three-dimensional radiance field, $L(\mathbf{x}, \lambda)$, where $\mathbf{x}$ is the spatial coordinate and $\lambda$ is wavelength, onto a discrete two-dimensional detector array. In a pushbroom scanner, one dimension of the detector captures spatial information across the sensor's field of view (the across-track dimension), while the other dimension captures spectrally dispersed information. The forward motion of the platform builds the second spatial dimension (the along-track dimension). In an ideal instrument, each detector element would correspond to a unique, well-defined ground location and a specific, constant wavelength interval. In reality, [optical aberrations](@entry_id:163452) introduce systematic deviations from this ideal, leading to spatio-spectral coupling artifacts.

#### Spectral Smile: The Field-Angle Dependent Wavelength Shift

The **spectral smile** artifact, also known as "spectral line curvature," is a [systematic variation](@entry_id:1132810) in the center wavelength of a given spectral band as a function of the across-track spatial position. For a detector array, this means that pixels in the same column (which should correspond to the same wavelength) actually sense slightly different center wavelengths depending on their row position.

The physical origin of spectral smile in a grating-based spectrometer can be understood from the fundamental **[grating equation](@entry_id:174509)** . The [grating equation](@entry_id:174509) relates the incident angle $\alpha$, the diffracted angle $\beta$, the wavelength $\lambda$, the groove spacing of the grating $d$, and the [diffraction order](@entry_id:174263) $m$:

$m \lambda = d(\sin\alpha + \sin\beta)$

In a [pushbroom spectrometer](@entry_id:1130316) design, the entrance slit is aligned with the across-track spatial dimension. Light from different points along this slit corresponds to different across-track field angles. A collimator optic directs this light onto the [diffraction grating](@entry_id:178037), and typically, the incidence angle $\alpha$ becomes a function of the across-track field angle. Let's consider a small variation in field angle, $\Delta\theta_y$, which leads to a change in the incidence angle, $\Delta\alpha$. If we analyze the signal at a fixed detector column, this corresponds to a fixed diffracted angle $\beta$ (i.e., $\Delta\beta = 0$). By differentiating the [grating equation](@entry_id:174509), we can find the resulting change in wavelength, $\Delta\lambda$:

$m \Delta\lambda \approx d(\cos\alpha_0 \Delta\alpha)$

This equation demonstrates that a change in the across-track field angle (via $\Delta\alpha$) directly maps to a change in the sensed wavelength $\Delta\lambda$ for a fixed detector column. Alternatively, if we imagine imaging a perfectly [monochromatic light](@entry_id:178750) source ($\Delta\lambda = 0$), the [grating equation](@entry_id:174509) dictates that a change in $\alpha$ due to field angle must be compensated by a change in $\beta$ to hold $\lambda$ constant:

$\Delta\beta \approx -\frac{\cos\alpha_0}{\cos\beta_0} \Delta\alpha$

Since the detector position in the [spectral dimension](@entry_id:189923) corresponds to $\beta$, this means the image of a monochromatic line is not straight but curved on the detector—hence the term "spectral smile." This effect must be distinguished from other sources of spectral variation, such as **temporal drift** of the entire wavelength calibration due to thermal changes, or non-uniform **channel-dependent dispersion** where the spacing between bands varies with wavelength but not with spatial position . Smile is specifically the dependence of wavelength calibration on the across-track field position for a single acquisition.

The impact of uncorrected spectral smile is most severe when analyzing narrow spectral features. The artifact effectively shifts the feature's apparent spectral position differently for each across-track pixel, causing a distortion of the feature's shape and depth in the retrieved data. Consider, for example, the retrieval of surface reflectance $\rho$ within a narrow [atmospheric absorption](@entry_id:1121179) feature, such as the oxygen A-band near $760\,\mathrm{nm}$ . The atmospheric two-way transmittance, $T(\lambda)$, is sharply peaked. An algorithm might retrieve reflectance using the equation $\hat{\rho} = (\pi L) / (E_0 \mu_0 T(\lambda_{\text{nom}}))$, where $L$ is the measured radiance and $T(\lambda_{\text{nom}})$ is the modeled transmittance at the *nominal* band center wavelength. However, due to smile, the actual radiance at an off-nadir pixel is measured at a shifted wavelength, $L \propto \rho T(\lambda_{\text{actual}})$. The retrieved reflectance is therefore biased:

$\hat{\rho} = \rho \frac{T(\lambda_{\text{actual}})}{T(\lambda_{\text{nom}})}$

If the nominal wavelength $\lambda_{\text{nom}}$ is at the center of the absorption line (a minimum of $T(\lambda)$) and the smile shifts $\lambda_{\text{actual}}$ onto the wing of the line where transmittance is higher, then $T(\lambda_{\text{actual}}) > T(\lambda_{\text{nom}})$ and the retrieved reflectance $\hat{\rho}$ will be erroneously high. For a hypothetical case with a smile-induced wavelength shift of $0.15\,\mathrm{nm}$ away from the center of a Gaussian absorption line with a standard deviation of $\sigma=0.20\,\mathrm{nm}$, the bias in retrieved reflectance can be substantial. The absolute reflectance bias, $b = \hat{\rho} - \rho$, can be calculated as :

$b = \rho \frac{d}{1-d} \left[ 1 - \exp\left(-\frac{(\Delta\lambda)^{2}}{2\sigma^{2}}\right) \right]$

For typical parameters ($\rho=0.30$, line relative depth $d=0.30$, $\Delta\lambda=0.15\,\mathrm{nm}$, $\sigma=0.20\,\mathrm{nm}$), this bias evaluates to approximately $b \approx 0.0315$, which is a relative error of over $10\%$.

#### Keystone: The Wavelength-Dependent Spatial Misregistration

The **keystone** artifact is a form of [chromatic aberration](@entry_id:174838) that manifests as a wavelength-dependent spatial misregistration. In simpler terms, for a single nominal ground pixel, different spectral bands are imaged from slightly different ground locations. This is fundamentally a spatial effect, in contrast to the spectral nature of smile. Keystone causes the projected image of the [spectrometer](@entry_id:193181)'s entrance slit to shift or change magnification as a function of wavelength .

Keystone must be distinguished from other spatial artifacts. **Platform motion-induced blur**, for instance, is typically a smear in the along-track direction caused by the sensor's movement during the finite integration time, and it is largely independent of wavelength. Static **[optical distortion](@entry_id:166078)** (like barrel or [pincushion distortion](@entry_id:173180)) is a geometric warping of the image that is typically achromatic, meaning it is the same for all wavelengths. Keystone's defining characteristic is that the spatial shift, let's call it $\mathbf{k}(\lambda)$, is a function of wavelength $\lambda$.

The impact of keystone is most pronounced at the boundaries between areas of high spatial contrast. Consider a pixel located exactly at the edge between two different materials, A and B. The true spectrum for this pixel might be a physical mixture of A and B. However, because of keystone, the measurement at wavelength $\lambda_1$ might be sourced from a location shifted slightly into material A, while the measurement at wavelength $\lambda_2$ might be sourced from a location shifted slightly into material B. The result is an artificially induced, wavelength-dependent spectral mixing that does not represent the true state of the ground pixel.

We can formalize this effect using a first-order spatial Taylor expansion . If the keystone induces a small spatial shift $\mathbf{k}(\lambda)$, the measured reflectance $r_{\text{meas}}$ at pixel location $\mathbf{x}$ is approximately:

$r_{\text{meas}}(\mathbf{x}, \lambda) \approx r_{\text{true}}(\mathbf{x}, \lambda) + \mathbf{k}(\lambda) \cdot \nabla r_{\text{true}}(\mathbf{x}, \lambda)$

The error term, $\delta r(\mathbf{x}, \lambda) = \mathbf{k}(\lambda) \cdot \nabla r_{\text{true}}(\mathbf{x}, \lambda)$, is significant only where the spatial gradient of reflectance, $\nabla r_{\text{true}}$, is large—that is, at edges. This error term introduces a spectrally-varying contamination. This artifactual spectral mixing biases downstream analyses. For example, in **linear [spectral unmixing](@entry_id:189588)**, which assumes that an observed spectrum is a linear combination of pure endmember spectra weighted by wavelength-independent fractional abundances, the spectrally-varying error term violates this core assumption and leads to incorrect abundance estimates. Similarly, **spectral indices**, such as the Normalized Difference Vegetation Index (NDVI), are calculated from ratios of reflectances at different wavelengths. Since the keystone-induced error $\delta r$ is different at each wavelength, it will bias the calculated index value, potentially leading to misclassification of the pixel.

### Environment-Induced Artifacts: The Radiative Transfer Pathway

The atmosphere is not a transparent window. As photons travel from the sun to the surface and from the surface to the sensor, they are absorbed and scattered by gas molecules and aerosols. These processes not only attenuate the signal but also add unwanted radiance, fundamentally altering the information content of the measured spectrum.

#### The Atmospheric Adjacency Effect

When a sensor views a specific ground pixel, the radiance it measures is not solely from that pixel. A portion of the signal consists of photons that were reflected from *neighboring* ground areas, scattered by the atmosphere, and redirected into the sensor's line of sight. This phenomenon is known as the **atmospheric adjacency effect** . It is crucial to distinguish this atmospheric blurring from the optical blurring caused by the instrument's own **Point Spread Function (PSF)**. The [adjacency effect](@entry_id:1120809) is a radiative transfer process with a characteristic spatial scale determined by atmospheric conditions, while the PSF is an instrumental property with a scale related to the pixel size .

The physics of the [adjacency effect](@entry_id:1120809) can be described by an **adjacency kernel**, $w(r, \lambda)$, which represents the contribution of a surrounding annular region at a horizontal distance $r$ to the target pixel's radiance. Under a single-scattering approximation, the shape and scale of this kernel are governed by fundamental atmospheric properties . The radial form of the kernel is approximately proportional to $\exp(-\sigma_{\text{ext}}(\lambda) r)/r$. This form arises from two competing factors: the $1/r$ term represents the [geometric spreading](@entry_id:1125610) of light integrated over an annulus, while the exponential term, $\exp(-\sigma_{\text{ext}}(\lambda) r)$, represents the attenuation of light traveling horizontally through the atmosphere, governed by the Beer-Lambert law with the volume extinction coefficient $\sigma_{\text{ext}}(\lambda)$.

The angular distribution of scattering, described by the **[scattering phase function](@entry_id:1131288)** $P(\theta, \lambda)$, also plays a critical role. For nadir viewing, scattering events at small angles (forward scattering) are most effective at redirecting light from nearby neighbors into the sensor's view. Since aerosol phase functions are strongly peaked in the forward direction, this enhances the contribution from the immediate vicinity.

The characteristic e-folding length scale of the [adjacency effect](@entry_id:1120809), $L_e$, is inversely proportional to the [extinction coefficient](@entry_id:270201): $L_e \approx 1/\sigma_{\text{ext}}(\lambda)$. This means that in very clear conditions with low extinction, the [adjacency effect](@entry_id:1120809) can have a very long range, on the order of kilometers. In hazy or dusty conditions with high extinction, the effect is stronger but more localized, with a length scale of hundreds of meters. In all cases, the [adjacency effect](@entry_id:1120809) acts as a low-pass spatial filter, blurring the scene, reducing the contrast of sharp features, and mixing the spectral signatures of adjacent, dissimilar surfaces.

#### Contamination by Thin Cirrus Clouds

Thin, high-altitude cirrus clouds are a common source of contamination in [optical remote sensing](@entry_id:1129164) data. Being semi-transparent, they do not completely obscure the scene below. Instead, they modify the top-of-atmosphere (TOA) radiance in two primary ways: they introduce an additive path radiance component by scattering incoming solar radiation directly to the sensor, and they introduce a multiplicative attenuation of the signal originating from the surface and lower atmosphere .

A highly effective method for detecting the presence of thin cirrus leverages the strong water vapor absorption band centered around $1.38\,\mathrm{\mu m}$ . The principle is elegantly simple: under typical atmospheric conditions, the high concentration of water vapor in the troposphere makes the atmosphere virtually opaque at this wavelength. The two-way transmittance for a signal traveling from the sun to the surface and back to the sensor is extremely low. Consequently, for a clear-sky scene, the radiance measured by the sensor in this channel is near zero because the surface is completely obscured. However, cirrus clouds reside at high altitudes, typically above the bulk of the atmospheric water vapor. Therefore, sunlight scattered by these clouds can reach the sensor without undergoing the strong absorption of the lower atmosphere. The result is that the presence of even thin cirrus clouds produces a distinct, bright signal in the $1.38\,\mathrm{\mu m}$ channel against a very dark background, enabling robust detection.

The effectiveness of this method is, however, contingent on the atmospheric state. In very dry atmospheres (e.g., over deserts, polar regions) or at high-elevation sites, the total column water vapor can be low enough that the two-way transmittance is no longer negligible . In such cases, a significant portion of the signal may be "leaked" from the surface, especially over bright surfaces like snow or sand. This surface leakage can be mistaken for cirrus, limiting the reliability of the detection method. For instance, in a moist atmosphere with $20\,\mathrm{mm}$ of precipitable water, the two-way surface transmittance might be on the order of $10^{-4}$, rendering the surface invisible. In a dry atmosphere with only $2\,\mathrm{mm}$ of water, the transmittance could increase to over $0.4$, making the reflected surface signal comparable to or even stronger than the signal from thin cirrus.

Instrumental artifacts can further complicate [cirrus detection](@entry_id:1122413). Spectral smile, by shifting the center wavelength of off-nadir pixels, can move the effective bandpass to the wings of the water vapor absorption feature where absorption is weaker. This increases surface leakage at the edges of the swath, potentially creating [false positive](@entry_id:635878) cirrus detections in an across-track pattern .

### Synthesis: A Comprehensive Forward Model

The individual principles and mechanisms described above can be synthesized into a single, comprehensive forward model that describes the radiance measured by a real-world hyperspectral sensor. Such a model is the theoretical foundation for developing correction algorithms, which seek to invert this model to retrieve the true underlying surface properties.

Let us construct the model by starting with the true physical radiance field and sequentially applying the instrumental perturbations . The "true" TOA radiance, $L_{TOA}^{\text{true}}(\mathbf{x}, \lambda)$, at a ground location $\mathbf{x}$ and wavelength $\lambda$, can be written as a superposition of atmospheric and surface contributions:

$L_{TOA}^{\text{true}}(\mathbf{x}, \lambda) = L_{\text{path,clr}}(\mathbf{x}, \lambda) + L_{\text{cirrus}}(\mathbf{x}, \lambda) + T_{\uparrow}(\lambda) L_{\uparrow}(\mathbf{x}, \lambda)$

Here, $L_{\text{path,clr}}$ is the clear-sky path radiance, $L_{\text{cirrus}}$ is the additive cirrus path radiance, and $T_{\uparrow}(\lambda)$ is the upward transmittance that attenuates the upwelling radiance from the surface, $L_{\uparrow}(\mathbf{x}, \lambda)$. This upwelling radiance itself includes the [adjacency effect](@entry_id:1120809), modeled as a spatial convolution of the surface-leaving radiance field, $L_{\text{surf}}$, with the adjacency kernel $w$:

$L_{\uparrow}(\mathbf{x}, \lambda) = L_{\text{surf}}(\mathbf{x}, \lambda) + \alpha(\lambda)\int_{\mathbb{R}^{2}} w(\boldsymbol{\xi}; \lambda) L_{\text{surf}}(\mathbf{x}+\boldsymbol{\xi}, \lambda) \mathrm{d}^{2}\boldsymbol{\xi}$

This represents the "true" radiance field entering the sensor's [aperture](@entry_id:172936). The instrument, however, does not measure this field perfectly. The measured radiance at a nominal coordinate pair $(\mathbf{x}, \lambda)$ is actually the true radiance field sampled at a keystone-shifted spatial location, $\mathbf{x}' = \mathbf{x} + \delta\mathbf{x}(\lambda)$, and a smile-shifted wavelength, $\lambda' = \lambda + \Delta\lambda_{\text{smile}}(\mathbf{x})$. Therefore, the final forward model for the *measured* TOA radiance is:

$L_{TOA}(\mathbf{x}, \lambda) = L_{\text{path,clr}}(\mathbf{x}', \lambda') + L_{\text{cirrus}}(\mathbf{x}', \lambda') + T_{\uparrow}(\lambda') \left[ L_{\text{surf}}(\mathbf{x}', \lambda') + \alpha(\lambda')\int_{\mathbb{R}^{2}} w(\boldsymbol{\xi}; \lambda') L_{\text{surf}}(\mathbf{x}'+\boldsymbol{\xi}, \lambda') \mathrm{d}^{2}\boldsymbol{\xi} \right]$

This comprehensive model elegantly encapsulates how the distinct physical mechanisms—atmospheric scattering and absorption, cirrus contamination, adjacency effects, and instrumental spatio-[spectral distortions](@entry_id:161586)—are interwoven to produce the final measured signal. Deconvolving these effects to isolate the true surface reflectance, $\rho(\mathbf{x}, \lambda)$, is the central challenge of hyperspectral data processing.