{
    "hands_on_practices": [
        {
            "introduction": "The ability of Synthetic Aperture Radar (SAR) to map floods stems from the distinct way radar signals interact with calm water versus land. This exercise explores the fundamental physical principle of backscatter contrast, where water's smooth surface reflects energy away from the sensor, appearing dark, while rougher land scatters energy back. By applying simple but representative scattering models , you will quantify this contrast and see how it is influenced by the sensor's viewing geometry, providing a foundational insight into flood detection with SAR.",
            "id": "3812229",
            "problem": "A multi-temporal Synthetic Aperture Radar (SAR) time series is acquired over a floodplain with varying incidence angles due to orbital geometry. Flood inundation mapping relies on exploiting the contrast in the Normalized Radar Cross Section (NRCS), denoted by $\\sigma^{0}$, between calm open water and adjacent unflooded land. For calm water under near-specular reflection, assume a constant NRCS $\\sigma^{0}_{\\mathrm{w}} = b$ independent of incidence angle. For unflooded land, assume a simple surface scattering model $\\sigma^{0}_{\\mathrm{l}}(\\theta) = a \\cos^{n}(\\theta)$, where $\\theta$ is the local incidence angle, $a$ is a land surface backscatter scale factor, and $n$ is an angular fall-off exponent reflecting surface roughness and structure.\n\nLet $a = 0.2$ (dimensionless, linear power scale), $n = 3$, and $b = 0.005$ (dimensionless, linear power scale). Define the backscatter contrast in decibels (dB) at incidence angle $\\theta$ as the decibel ratio between land and water NRCS,\n$$C(\\theta) \\equiv 10 \\log_{10}\\!\\left(\\frac{\\sigma^{0}_{\\mathrm{l}}(\\theta)}{\\sigma^{0}_{\\mathrm{w}}}\\right).$$\nCompute $C(\\theta)$ at $\\theta = 30^{\\circ}$ and $\\theta = 45^{\\circ}$. Angles are in degrees. Express the final contrasts in decibels and round your answers to four significant figures. Provide the two contrasts as a row matrix.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of radar remote sensing, is well-posed with a complete and consistent set of givens, and uses standard mathematical definitions.\n\nThe backscatter contrast in decibels, $C(\\theta)$, is defined as the decibel ratio between the Normalized Radar Cross Section (NRCS) of unflooded land, $\\sigma^{0}_{\\mathrm{l}}(\\theta)$, and that of calm open water, $\\sigma^{0}_{\\mathrm{w}}$. The definition is given by:\n$$C(\\theta) \\equiv 10 \\log_{10}\\!\\left(\\frac{\\sigma^{0}_{\\mathrm{l}}(\\theta)}{\\sigma^{0}_{\\mathrm{w}}}\\right)$$\nThe problem provides models for the NRCS of both surface types. For calm water, the NRCS is constant:\n$$\\sigma^{0}_{\\mathrm{w}} = b$$\nFor unflooded land, the NRCS follows a simple surface scattering model dependent on the local incidence angle $\\theta$:\n$$\\sigma^{0}_{\\mathrm{l}}(\\theta) = a \\cos^{n}(\\theta)$$\nSubstituting these models into the definition of contrast yields:\n$$C(\\theta) = 10 \\log_{10}\\!\\left(\\frac{a \\cos^{n}(\\theta)}{b}\\right)$$\nWe are given the following parameter values: the land surface backscatter scale factor $a = 0.2$, the angular fall-off exponent $n = 3$, and the water NRCS $b = 0.005$. All parameters are dimensionless linear power scale values. Substituting these into the expression for $C(\\theta)$:\n$$C(\\theta) = 10 \\log_{10}\\!\\left(\\frac{0.2 \\cos^{3}(\\theta)}{0.005}\\right)$$\nThe ratio of the constants $a$ and $b$ can be pre-calculated to simplify the expression:\n$$\\frac{a}{b} = \\frac{0.2}{0.005} = \\frac{2 \\times 10^{-1}}{5 \\times 10^{-3}} = \\frac{2}{5} \\times 10^{2} = 0.4 \\times 100 = 40$$\nThus, the specific expression for the contrast becomes:\n$$C(\\theta) = 10 \\log_{10}\\!\\left(40 \\cos^{3}(\\theta)\\right)$$\nWe are required to compute the contrast for two incidence angles: $\\theta_1 = 30^{\\circ}$ and $\\theta_2 = 45^{\\circ}$.\n\nFirst, let us compute $C(30^{\\circ})$:\nFor $\\theta = 30^{\\circ}$, the cosine is $\\cos(30^{\\circ}) = \\frac{\\sqrt{3}}{2}$.\nThe term $\\cos^{3}(\\theta)$ is then $\\left(\\frac{\\sqrt{3}}{2}\\right)^{3} = \\frac{3\\sqrt{3}}{8}$.\nSubstituting this value into our simplified equation for $C(\\theta)$:\n$$C(30^{\\circ}) = 10 \\log_{10}\\!\\left(40 \\times \\frac{3\\sqrt{3}}{8}\\right) = 10 \\log_{10}(5 \\times 3\\sqrt{3}) = 10 \\log_{10}(15\\sqrt{3})$$\nFor a numerical result, we evaluate the argument of the logarithm: $15\\sqrt{3} \\approx 25.980762$.\n$$C(30^{\\circ}) \\approx 10 \\log_{10}(25.980762) \\approx 10 \\times 1.414663 \\approx 14.14663$$\nRounding to four significant figures, we get:\n$$C(30^{\\circ}) \\approx 14.15$$\n\nNext, let us compute $C(45^{\\circ})$:\nFor $\\theta = 45^{\\circ}$, the cosine is $\\cos(45^{\\circ}) = \\frac{\\sqrt{2}}{2}$.\nThe term $\\cos^{3}(\\theta)$ is then $\\left(\\frac{\\sqrt{2}}{2}\\right)^{3} = \\frac{2\\sqrt{2}}{8} = \\frac{\\sqrt{2}}{4}$.\nSubstituting this value into our equation for $C(\\theta)$:\n$$C(45^{\\circ}) = 10 \\log_{10}\\!\\left(40 \\times \\frac{\\sqrt{2}}{4}\\right) = 10 \\log_{10}(10\\sqrt{2})$$\nFor a numerical result, we evaluate the argument: $10\\sqrt{2} \\approx 14.142136$.\n$$C(45^{\\circ}) \\approx 10 \\log_{10}(14.142136) \\approx 10 \\times 1.150515 \\approx 11.50515$$\nRounding to four significant figures, we get:\n$$C(45^{\\circ}) \\approx 11.51$$\n\nThe final results for the contrast at $\\theta = 30^{\\circ}$ and $\\theta = 45^{\\circ}$ are approximately $14.15$ dB and $11.51$ dB, respectively. These are to be presented as a row matrix.",
            "answer": "$$\\boxed{\\begin{pmatrix} 14.15 & 11.51 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Detecting floods from a time series requires distinguishing an anomalous water-induced signal from natural variability. A powerful approach is to establish a robust statistical baseline of \"normal\" backscatter for each pixel and identify significant deviations from it. In this hands-on coding practice , you will implement an anomaly detection algorithm that uses monthly percentiles to create a seasonal baseline and computes a z-score to flag unusual backscatter drops, mirroring a standard workflow for operational flood mapping.",
            "id": "3812210",
            "problem": "You are given a time series of Synthetic Aperture Radar (SAR) backscatter, denoted by $\\sigma^0$ (sigma-naught), measured in decibels (dB), for a regular grid of pixels. The data span $4$ full years at monthly resolution, for a total of $48$ time steps indexed by $t \\in \\{0,1,\\dots,47\\}$. The calendar month associated with time index $t$ is $m(t) = (t \\bmod 12) + 1$, where $m \\in \\{1,2,\\dots,12\\}$. The goal is to detect flood-induced backscatter drops by deriving per-pixel, per-calendar-month robust baselines from monthly percentiles and computing standardized anomaly scores (z-scores) defined by $z = (\\sigma^0 - \\mu)/\\sigma$.\n\nStart from the following fundamental bases, which you must apply without invoking any shortcut formulas in your reasoning:\n- The definition of percentiles and median as order statistics on a sample.\n- The properties of the normal distribution used to relate interquartile range to standard deviation: for a normally distributed variable, the interquartile range (IQR) is approximately $1.349$ times the standard deviation.\n- The definition of a z-score $z = (\\sigma^0 - \\mu)/\\sigma$.\n\nYou must implement the following procedure to construct the dataset deterministically and then to compute z-scores and flood detections:\n\n1. Grid and time:\n   - Define a grid of size $2 \\times 3$ indexed by $(r,c)$ with $r \\in \\{0,1\\}$ and $c \\in \\{0,1,2\\}$.\n   - Define $48$ monthly time steps indexed by $t \\in \\{0,\\dots,47\\}$ corresponding to $4$ years.\n\n2. Deterministic SAR backscatter generator (in dB):\n   - Define a base backscatter matrix $B$ (in dB):\n     $$\n     B = \\begin{bmatrix}\n     -10.0 & -7.5 & -12.0 \\\\\n     -9.0 & -8.0 & -11.5\n     \\end{bmatrix}.\n     $$\n   - Define a seasonal amplitude factor for each pixel:\n     $$\n     a(r,c) = 1.0 + 0.2\\,r + 0.1\\,c.\n     $$\n   - Define a deterministic monthly seasonal component (in dB) for calendar month $m \\in \\{1,\\dots,12\\}$:\n     $$\n     s(m) = 1.5 \\cos\\!\\left(\\frac{2\\pi (m-1)}{12}\\right).\n     $$\n   - Define a deterministic small “noise” term (in dB) with period $6$ months:\n     $$\n     \\eta(t,r,c) = 0.2 \\sin\\!\\left(\\frac{2\\pi t}{6} + 0.3\\,r + 0.1\\,c\\right).\n     $$\n   - Construct the nominal time series (in dB) for each $t$, $r$, $c$:\n     $$\n     y(t,r,c) = B[r,c] + a(r,c)\\,s(m(t)) + \\eta(t,r,c).\n     $$\n   - Override one pixel to have no variability to create a boundary case: set $y(t,1,2) = B[1,2]$ for all $t$.\n   - Introduce missing data (Not-a-Number) for pixel $(0,2)$ for calendar month $m=5$ (May) in the first three years: set $y(t,0,2) = \\mathrm{NaN}$ for $t \\in \\{4,16,28\\}$.\n   - Impose two flood events as abrupt drops in $\\sigma^0$:\n     - At time $t=39$ (year $4$, month $4$), pixel $(0,1)$ experiences a drop of $6.0$ dB: $y(39,0,1) \\leftarrow y(39,0,1) - 6.0$.\n     - At time $t=40$ (year $4$, month $5$), pixel $(0,2)$ experiences a drop of $5.0$ dB: $y(40,0,2) \\leftarrow y(40,0,2) - 5.0$.\n\n3. Robust monthly baseline per pixel:\n   - For a given pixel $(r,c)$ and a query time $t_\\star$ with calendar month $m_\\star = m(t_\\star)$, form the baseline sample $\\mathcal{S}_{m_\\star}(r,c)$ consisting of all non-missing values $\\{y(t,r,c): m(t)=m_\\star\\}$.\n   - Compute the monthly percentiles $P_{25}$, $P_{50}$, $P_{75}$ of $\\mathcal{S}_{m_\\star}(r,c)$ and define the robust baseline location as $\\mu = P_{50}$ and the robust scale as $\\sigma = \\max\\{(P_{75}-P_{25})/1.349, \\sigma_{\\min}\\}$ with $\\sigma_{\\min} = 0.1$ dB to avoid division by zero.\n   - If the cardinality of $\\mathcal{S}_{m_\\star}(r,c)$ is less than $n_{\\min}=3$, fall back to the all-month sample $\\mathcal{S}_{\\mathrm{all}}(r,c) = \\{y(t,r,c): y(t,r,c)\\ \\text{not missing}\\}$ to compute $P_{25}$, $P_{50}$, $P_{75}$ and then $\\mu$ and $\\sigma$ as above.\n\n4. Z-score and flood detection:\n   - For the query $(r,c,t_\\star)$, compute the z-score\n     $$\n     z = \\frac{y(t_\\star,r,c) - \\mu}{\\sigma}.\n     $$\n   - Classify a flood-induced drop as detected if $z \\leq z_{\\mathrm{th}}$ with $z_{\\mathrm{th}} = -2.0$.\n   - The z-score is dimensionless. You must output z-scores rounded to three decimals.\n\n5. Required output format:\n   - For each test case below, output a list $[z,\\ \\mathrm{detected}]$ where $z$ is the rounded float (three decimals) and $\\mathrm{detected}$ is a boolean.\n   - Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, for example: $[[z_1,\\mathrm{det}_1],[z_2,\\mathrm{det}_2],\\dots]$.\n\nTest suite to cover varied conditions:\n- Case $1$ (happy path, strong drop): $(r,c,t_\\star) = (0,1,39)$.\n- Case $2$ (boundary, near-zero variability baseline): $(r,c,t_\\star) = (1,2,32)$.\n- Case $3$ (edge, missing-month fallback to all-month baseline): $(r,c,t_\\star) = (0,2,40)$.\n- Case $4$ (edge, no drop, normal condition): $(r,c,t_\\star) = (1,0,36)$.\n\nImplement a complete program that:\n- deterministically builds $y(t,r,c)$ as specified above,\n- computes $\\mu$ and $\\sigma$ using monthly percentiles as defined,\n- computes the z-scores and flood detections for all test cases,\n- and prints a single line in the exact required output format with each z-score rounded to three decimals (dimensionless).",
            "solution": "The problem statement is a well-posed and scientifically grounded exercise in time series analysis for remote sensing applications, specifically flood detection using Synthetic Aperture Radar (SAR) data. The procedure is deterministic and all required parameters, formulas, and conditions are explicitly provided. The problem is valid.\n\nThe solution will be developed by systematically following the specified procedure.\n\n### Step 1: Data Generation\nFirst, we construct the $48$-step time series of SAR backscatter, $y(t,r,c)$, for a $2 \\times 3$ grid of pixels. The time series is indexed by $t \\in \\{0, \\dots, 47\\}$, and pixels by $(r,c)$ where $r \\in \\{0,1\\}$ and $c \\in \\{0,1,2\\}$.\n\nThe model for the backscatter $y(t,r,c)$ in decibels (dB) is:\n$$\ny(t,r,c) = B[r,c] + a(r,c)\\,s(m(t)) + \\eta(t,r,c)\n$$\n\nThe components are defined as follows:\n- The base backscatter $B$ is a $2 \\times 3$ matrix:\n$$\nB = \\begin{bmatrix}\n-10.0 & -7.5 & -12.0 \\\\\n-9.0 & -8.0 & -11.5\n\\end{bmatrix}\n$$\n- The seasonal amplitude factor $a(r,c)$ depends on pixel location:\n$$\na(r,c) = 1.0 + 0.2\\,r + 0.1\\,c\n$$\n- The calendar month $m(t)$ is derived from the time index $t$:\n$$\nm(t) = (t \\bmod 12) + 1\n$$\n- The seasonal component $s(m)$ depends on the calendar month $m \\in \\{1, \\dots, 12\\}$:\n$$\ns(m) = 1.5 \\cos\\!\\left(\\frac{2\\pi (m-1)}{12}\\right)\n$$\n- The noise term $\\eta(t,r,c)$ is a small periodic fluctuation:\n$$\n\\eta(t,r,c) = 0.2 \\sin\\!\\left(\\frac{2\\pi t}{6} + 0.3\\,r + 0.1\\,c\\right)\n$$\n\nAfter generating the nominal time series using the above formula, we apply the specified modifications:\n1.  **Constant Pixel**: For pixel $(1,2)$, all values are set to a constant: $y(t,1,2) = B[1,2] = -11.5$ for all $t$.\n2.  **Missing Data**: For pixel $(0,2)$, values for May ($m=5$) in the first three years (corresponding to $t=4, 16, 28$) are set to Not-a-Number (NaN): $y(t,0,2) = \\mathrm{NaN}$ for $t \\in \\{4,16,28\\}$.\n3.  **Flood Events**: Two anomalous drops are introduced:\n    -   Pixel $(0,1)$ at $t=39$: $y(39,0,1) \\leftarrow y(39,0,1) - 6.0$.\n    -   Pixel $(0,2)$ at $t=40$: $y(40,0,2) \\leftarrow y(40,0,2) - 5.0$.\n\n### Step 2: Robust Baseline and Z-Score Calculation\nFor each test case, specified by a query pixel $(r,c)$ and time $t_\\star$, we compute a z-score to quantify the anomaly.\n\n1.  **Identify Sample**: We determine the calendar month $m_\\star = m(t_\\star)$. The primary sample for the baseline, $\\mathcal{S}_{m_\\star}(r,c)$, consists of all a-priori historical and current values for that pixel that fall in the same calendar month: $\\mathcal{S}_{m_\\star}(r,c) = \\{y(t,r,c) : m(t)=m_\\star\\}$. All NaN values are excluded.\n\n2.  **Handle Sparse Data**: We check the number of valid data points in the sample, $|\\mathcal{S}_{m_\\star}(r,c)|$. If this count is less than $n_{\\min}=3$, the sample is too small. In this case, we switch to a fallback sample, $\\mathcal{S}_{\\mathrm{all}}(r,c)$, which consists of all non-missing values for the pixel $(r,c)$ across all $48$ months. Otherwise, we proceed with $\\mathcal{S}_{m_\\star}(r,c)$.\n\n3.  **Compute Robust Statistics**: From the chosen sample (either $\\mathcal{S}_{m_\\star}$ or $\\mathcal{S}_{\\mathrm{all}}$), we compute percentiles to derive robust estimates for location and scale.\n    -   The location parameter (robust mean) is the median: $\\mu = P_{50}$.\n    -   The scale parameter (robust standard deviation) is derived from the interquartile range (IQR), defined as $P_{75} - P_{25}$. Based on the properties of a normal distribution, the standard deviation $\\sigma$ is approximated by $\\mathrm{IQR} / 1.349$. To prevent division by zero or near-zero in cases of low variability, a minimum value $\\sigma_{\\min} = 0.1$ is enforced. Thus,\n    $$\n    \\sigma = \\max\\left(\\frac{P_{75} - P_{25}}{1.349}, \\sigma_{\\min}\\right)\n    $$\n\n4.  **Calculate Z-Score**: The standardized anomaly score (z-score) is calculated as:\n    $$\n    z = \\frac{y(t_\\star,r,c) - \\mu}{\\sigma}\n    $$\n    The value $y(t_\\star,r,c)$ is the (potentially flood-affected) backscatter at the query time.\n\n5.  **Detect Flood**: A flood is detected if the z-score is less than or equal to a threshold $z_{\\mathrm{th}} = -2.0$.\n\n### Step 3: Analysis of Test Cases\nWe apply this procedure to the four specified test cases.\n\n-   **Case 1: $(r,c,t_\\star) = (0,1,39)$**\n    This corresponds to a flood event. The query month is $m(39) = 4$ (April). The baseline sample $\\mathcal{S}_4(0,1)$ will contain four values, one of which is the flood-affected value itself. This will slightly bias the baseline statistics but is compliant with the problem statement. The large drop of $6.0$ dB is expected to produce a strongly negative z-score, leading to a detection.\n\n-   **Case 2: $(r,c,t_\\star) = (1,2,32)$**\n    This pixel's time series is constant at $-11.5$ dB. The query month is $m(32)=9$ (September). The sample $\\mathcal{S}_9(1,2)$ will consist of four identical values of $-11.5$. The percentiles will all be $-11.5$, making $\\mu = -11.5$ and the IQR equal to $0$. The scale $\\sigma$ will thus be clamped to the minimum value, $\\sigma_{\\min}=0.1$. The z-score will be $( -11.5 - (-11.5) ) / 0.1 = 0$, resulting in no detection.\n\n-   **Case 3: $(r,c,t_\\star) = (0,2,40)$**\n    This is the second flood event, for a pixel with missing data. The query month is $m(40)=5$ (May). The monthly sample $\\mathcal{S}_5(0,2)$ contains only one valid point (from year 4), as the values from the first three years are NaN. Since $1 < n_{\\min}=3$, the fallback mechanism is triggered. The baseline statistics ($\\mu$, $\\sigma$) will be computed from the sample of all non-missing data for this pixel, $\\mathcal{S}_{\\mathrm{all}}(0,2)$, which comprises $45$ data points. The z-score will be calculated using this all-month baseline. Despite the drop of $5.0$ dB, the baseline is robust and should still yield a z-score less than $-2.0$.\n\n-   **Case 4: $(r,c,t_\\star) = (1,0,36)$**\n    This is a test under normal, non-flood conditions. The query month is $m(36)=1$ (January). The baseline sample $\\mathcal{S}_1(1,0)$ will contain four values corresponding to the Januarys of the four years. Due to the deterministic nature of the signal generation, the noise component for this pixel and month happens to be identical across all four years, leading to four identical sample values. This results in an IQR of $0$, a scale $\\sigma = 0.1$, and a z-score of $0$, hence no detection.\n\nThe implementation will precisely follow these steps to produce the final numerical results for each case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full procedure for SAR-based flood detection as specified.\n    1. Generates the deterministic time series data.\n    2. Computes robust monthly baselines using percentiles.\n    3. Calculates z-scores for specified test cases.\n    4. Detects floods based on a z-score threshold.\n    \"\"\"\n\n    # 1. Grid and time dimensions\n    n_rows, n_cols = 2, 3\n    n_times = 48\n    t_indices = np.arange(n_times)\n\n    # 2. Deterministic SAR backscatter generator\n    # Initialize the data cube\n    y = np.zeros((n_times, n_rows, n_cols))\n\n    # Base backscatter matrix B\n    B = np.array([\n        [-10.0, -7.5, -12.0],\n        [-9.0, -8.0, -11.5]\n    ])\n\n    # Precompute seasonal component s(m)\n    m_values = np.arange(1, 13)\n    s_m = 1.5 * np.cos(2 * np.pi * (m_values - 1) / 12)\n\n    # Generate nominal time series y(t,r,c)\n    for t in t_indices:\n        m_t = (t % 12) + 1\n        for r in range(n_rows):\n            for c in range(n_cols):\n                a_rc = 1.0 + 0.2 * r + 0.1 * c\n                s_val = s_m[m_t - 1]\n                eta_trc = 0.2 * np.sin(2 * np.pi * t / 6 + 0.3 * r + 0.1 * c)\n                y[t, r, c] = B[r, c] + a_rc * s_val + eta_trc\n\n    # Override one pixel to have no variability\n    y[:, 1, 2] = B[1, 2]\n\n    # Introduce missing data (NaN)\n    y[[4, 16, 28], 0, 2] = np.nan\n\n    # Impose two flood events\n    y[39, 0, 1] -= 6.0\n    y[40, 0, 2] -= 5.0\n\n    # Test suite\n    test_cases = [\n        (0, 1, 39),  # Case 1: Happy path, strong drop\n        (1, 2, 32),  # Case 2: Boundary, near-zero variability baseline\n        (0, 2, 40),  # Case 3: Edge, missing-month fallback\n        (1, 0, 36)   # Case 4: Edge, no drop, normal condition\n    ]\n\n    results = []\n    \n    # Constants for baseline and detection\n    sigma_min = 0.1\n    n_min = 3\n    iqr_to_sigma_factor = 1.349\n    z_th = -2.0\n\n    for r_q, c_q, t_q in test_cases:\n        y_query = y[t_q, r_q, c_q]\n        m_q = (t_q % 12) + 1\n\n        # Form the baseline sample\n        monthly_indices = np.where((t_indices % 12) == (m_q - 1))[0]\n        sample_monthly = y[monthly_indices, r_q, c_q]\n        sample_monthly = sample_monthly[~np.isnan(sample_monthly)] # remove NaNs\n\n        # Check for fallback condition\n        if len(sample_monthly) < n_min:\n            # Fallback to all-month sample\n            sample = y[:, r_q, c_q]\n            sample = sample[~np.isnan(sample)]\n        else:\n            sample = sample_monthly\n            \n        # 3. Robust monthly baseline per pixel\n        if len(sample) == 0:\n             # This should not happen with the given test cases\n             # but is a safeguard for general cases.\n             mu, sigma = np.nan, np.nan\n        else:\n            p25, p50, p75 = np.percentile(sample, [25, 50, 75])\n            mu = p50\n            iqr = p75 - p25\n            sigma = max(iqr / iqr_to_sigma_factor, sigma_min)\n\n        # 4. Z-score and flood detection\n        if np.isnan(y_query) or sigma == 0: # sigma should be floored by sigma_min\n            z = np.nan\n        else:\n            z = (y_query - mu) / sigma\n\n        detected = z <= z_th\n        \n        # Round z-score to three decimals\n        z_rounded = round(z, 3)\n\n        results.append(f\"[{z_rounded},{str(detected).lower()}]\")\n\n    # 5. Required output format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A map of statistically anomalous pixels is not yet a physically realistic flood map, as water in a landscape must form a connected body that respects topography. This final practice addresses the critical step of transforming a raw pixel-based detection into a hydrostatically consistent inundation extent. Using a Digital Elevation Model (DEM) and principles of hydraulic connectivity , you will implement an algorithm to find the minimal water level that connects observed water pixels and delineate the corresponding plausible flooded area, a key skill in generating actionable environmental data.",
            "id": "3812224",
            "problem": "You are given a two-dimensional raster Digital Elevation Model (DEM) with elevations expressed in meters above a fixed vertical datum, and a set of indices representing observed water pixels extracted from a Synthetic Aperture Radar (SAR) time series. Under the quasi-static hydrostatic assumption that flood water seeks a horizontal surface controlled by gravity, a physically plausible inundation extent at a uniform water level is defined as the connected set of DEM cells whose elevations are less than or equal to a candidate water level, and that are topologically reachable from at least one observed water pixel using a specified neighborhood connectivity.\n\nStarting from the following fundamental base:\n- Gravitational potential minimizes when water seeks the lowest available elevation, and under hydrostatic equilibrium the free water surface is horizontal. Thus, a single flood level can be represented by a scalar water surface elevation $h$ in meters, and flooded terrain cells are those with elevation $z \\le h$.\n- Connectivity is determined on a discrete grid from adjacency; for a $4$-neighborhood, each cell is adjacent to its immediate up, down, left, and right neighbors.\n- Topographic plausibility requires hydraulic connectivity; disconnected depressions with $z \\le h$ that are not reachable from observed water cells are excluded from the inundation extent.\n\nDefine the minimal water level $h^{\\star}$ as the smallest scalar $h$ such that all observed water pixels belong to the same connected component within the set $\\{(i,j) \\mid z_{ij} \\le h\\}$ under $4$-neighborhood adjacency. The flood inundation extent at this level is then the set of all DEM cells with $z \\le h^{\\star}$ that are connected to any observed water pixel. The physically consistent flooded area is the count of such cells multiplied by the square of the DEM cell size.\n\nYour task is to write a program that, for each provided test case, computes:\n- The minimal connecting water level $h^{\\star}$ in meters.\n- The hydraulically connected flooded area at level $h^{\\star}$ in square meters, using the provided cell size.\n\nUse exclusively $4$-neighborhood connectivity. Express all water levels in meters and all areas in square meters as floating-point numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-value list $[h^{\\star},A]$ for a test case.\n\nTest suite:\n- Case $1$ (happy path, already connected basin): DEM $Z^{(1)}$ of shape $4 \\times 4$ meters with row-wise elevations\n  row $0$: $6,6,6,6$;\n  row $1$: $6,2,2,6$;\n  row $2$: $6,2,2,6$;\n  row $3$: $6,6,6,6$.\n  Observed water pixels $S^{(1)}$: $(1,1)$ and $(2,2)$ (zero-based row, column indices). DEM cell size $c^{(1)} = 30$ meters.\n- Case $2$ (ridge-controlled connection): DEM $Z^{(2)}$ of shape $5 \\times 5$ meters with row-wise elevations\n  row $0$: $10,10,10,10,10$;\n  row $1$: $10,2,2,7,10$;\n  row $2$: $10,2,2,7,10$;\n  row $3$: $10,7,7,3,10$;\n  row $4$: $10,10,10,10,10$.\n  Observed water pixels $S^{(2)}$: $(1,1)$ and $(3,3)$. DEM cell size $c^{(2)} = 30$ meters.\n- Case $3$ (multiple seeds, saddle connectivity): DEM $Z^{(3)}$ of shape $5 \\times 5$ meters with row-wise elevations\n  row $0$: $9,9,9,9,9$;\n  row $1$: $9,1,5,8,9$;\n  row $2$: $9,5,1,5,9$;\n  row $3$: $9,8,5,1,9$;\n  row $4$: $9,9,9,9,9$.\n  Observed water pixels $S^{(3)}$: $(1,1)$, $(2,2)$, $(3,3)$. DEM cell size $c^{(3)} = 30$ meters.\n- Case $4$ (single seed, trivial connection): DEM $Z^{(4)}$ of shape $3 \\times 3$ meters with row-wise elevations\n  row $0$: $5,4,5$;\n  row $1$: $4,2,4$;\n  row $2$: $5,4,5$.\n  Observed water pixels $S^{(4)}$: $(1,1)$. DEM cell size $c^{(4)} = 30$ meters.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each element formatted as $[h^{\\star},A]$ for the corresponding test case. For example, the output must look like $[[h_{1},A_{1}],[h_{2},A_{2}],[h_{3},A_{3}],[h_{4},A_{4}]]$ where $h_{k}$ are floats in meters and $A_{k}$ are floats in square meters.",
            "solution": "We derive the computation from hydrostatic equilibrium and discrete connectivity. Let $Z \\in \\mathbb{R}^{m \\times n}$ be the DEM elevations in meters, and let $S \\subset \\{0,\\dots,m-1\\} \\times \\{0,\\dots,n-1\\}$ be the set of observed water pixel indices from the Synthetic Aperture Radar (SAR) time series. Under hydrostatic equilibrium, a uniform water surface at elevation $h$ inundates any cell $(i,j)$ whose elevation $z_{ij}$ satisfies $z_{ij} \\le h$. A topographically plausible inundation must also be hydraulically connected to the observed water pixels; in a raster, this means connected via chains of adjacent cells using a prescribed neighborhood. We adopt the $4$-neighborhood: two cells are adjacent if their indices differ by exactly one in either row or column while the other index is equal.\n\nWe seek the minimal water level $h^{\\star}$ such that all observed water pixels fall within a single connected component of the thresholded set\n$$\n\\Omega(h) = \\{(i,j) \\mid z_{ij} \\le h\\}.\n$$\nDefine connectivity as follows: two cells $(i,j)$ and $(p,q)$ are connected in $\\Omega(h)$ if there exists a sequence of indices $(i_{0},j_{0}), (i_{1},j_{1}), \\dots, (i_{K},j_{K})$ with $(i_{0},j_{0}) = (i,j)$, $(i_{K},j_{K}) = (p,q)$, each $(i_{k},j_{k}) \\in \\Omega(h)$, and successive pairs are $4$-neighbors.\n\nThe minimal connecting water level is a bottleneck value tied to the lowest possible saddle elevations that must be exceeded to connect the observed water pixels. A constructive way to obtain $h^{\\star}$ is to progressively \"activate\" DEM cells in order of increasing elevation and to merge adjacent active cells into connected components. This is equivalent to a union-find (disjoint-set) process on the graph of raster cells, ordered by elevation. Formally:\n- Enumerate all cell indices and sort them by elevation $z_{ij}$ in nondecreasing order.\n- Maintain a union-find structure with a parent function $p(u)$ mapping each cell index $u$ (flattened from $(i,j)$) to its component representative, and a rank function to ensure near-logarithmic merging complexity.\n- Maintain an \"active\" indicator $a(u) \\in \\{0,1\\}$ that is $1$ once a cell is considered at the current threshold and $0$ otherwise.\n- Maintain for each component a count $c$ of how many observed seeds in $S$ are currently active in that component.\n\nWe add cells in ascending order of elevation:\n- When a cell $u$ becomes active at its elevation $z(u)$, we set $a(u) \\leftarrow 1$, initialize its component count $c(u)$ to $1$ if $u \\in S$ and $0$ otherwise, and union it with any active $4$-neighbors. When merging two components, we sum their seed counts.\n- After merging for the current activation, we check the seed count $c$ of the new component. The moment we find $c = |S|$, all observed water pixels are active and connected within the thresholded set, so the minimal connecting water level is $h^{\\star} = z(u)$, the elevation at which this condition first occurs. This $h^{\\star}$ is minimal by construction, as we increased $h$ monotonically from the smallest elevation.\n\nHaving determined $h^{\\star}$, the hydraulically plausible inundation extent is the set of cells with $z_{ij} \\le h^{\\star}$ that are connected (via $4$-neighborhood) to at least one seed $(i,j) \\in S$. To compute it:\n- Form the binary mask $M = \\{(i,j) \\mid z_{ij} \\le h^{\\star}\\}$.\n- Perform a breadth-first search (or depth-first search) starting from all seed cells, restricted to moves within $M$, to obtain the union of $4$-connected components that contain seeds. This set is the flooded extent consistent with the observed water pixels and the minimal water level.\n- Compute the flooded area $A$ as $N_{\\text{flood}} \\times c^{2}$, where $N_{\\text{flood}}$ is the count of flooded cells and $c$ is the DEM cell size in meters.\n\nThis procedure is grounded in the physics of hydrostatic equilibrium (water surface is horizontal at elevation $h$) and in the topological constraint that water must be hydraulically connected to observed water pixels. The union-find process guarantees the minimality of $h^{\\star}$ because it realizes the earliest elevation at which all seeds are in a single connected component of $\\Omega(h)$.\n\nApplying this to the test suite:\n- Case $1$: The $2$-meter basin cells form a connected component containing both seeds once all $2$-meter cells are activated, so $h^{\\star} = 2$. The connected flooded extent under $z \\le 2$ includes $4$ cells, yielding area $A = 4 \\times 30^{2} = 3600$ square meters.\n- Case $2$: The left and right basins at $2$ and $3$ meters are separated by a ridge at $7$ meters; activation reaches $h^{\\star} = 7$ when the ridge cells connect the seed-bearing basins. The connected flooded extent under $z \\le 7$ that is reachable from seeds comprises $9$ cells, with area $A = 9 \\times 30^{2} = 8100$ square meters.\n- Case $3$: Three seeds at $1$ meter are connected via $5$-meter saddles. Connectivity is achieved at $h^{\\star} = 5$. The seed-reachable flooded component under $z \\le 5$ has $7$ cells, with area $A = 7 \\times 30^{2} = 6300$ square meters.\n- Case $4$: A single seed at $2$ meters yields $h^{\\star} = 2$, and the flooded component under $z \\le 2$ contains $1$ cell, with area $A = 1 \\times 30^{2} = 900$ square meters.\n\nThe final program implements union-find for the minimal connecting water level and a flood-fill for the hydraulically connected extent, and outputs the list $[[h^{\\star}_{1},A_{1}],[h^{\\star}_{2},A_{2}],[h^{\\star}_{3},A_{3}],[h^{\\star}_{4},A_{4}]]$ in a single line, in meters and square meters respectively.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\nclass UnionFind:\n    def __init__(self, n):\n        self.parent = np.arange(n, dtype=int)\n        self.rank = np.zeros(n, dtype=int)\n        self.seed_count = np.zeros(n, dtype=int)\n        self.active = np.zeros(n, dtype=bool)\n\n    def find(self, x):\n        # Path compression\n        while self.parent[x] != x:\n            self.parent[x] = self.parent[self.parent[x]]\n            x = self.parent[x]\n        return x\n\n    def union(self, x, y):\n        rx = self.find(x)\n        ry = self.find(y)\n        if rx == ry:\n            return rx\n        # Union by rank\n        if self.rank[rx] < self.rank[ry]:\n            self.parent[rx] = ry\n            self.seed_count[ry] += self.seed_count[rx]\n            return ry\n        elif self.rank[rx] > self.rank[ry]:\n            self.parent[ry] = rx\n            self.seed_count[rx] += self.seed_count[ry]\n            return rx\n        else:\n            self.parent[ry] = rx\n            self.rank[rx] += 1\n            self.seed_count[rx] += self.seed_count[ry]\n            return rx\n\ndef minimal_connecting_level_and_extent(dem, seeds, cell_size):\n    \"\"\"\n    dem: 2D numpy array of elevations (meters)\n    seeds: list of (row, col) indices (zero-based)\n    cell_size: float, cell size in meters\n    Returns: (h_star, flooded_area_m2)\n    \"\"\"\n    rows, cols = dem.shape\n    n = rows * cols\n    uf = UnionFind(n)\n\n    # Flatten indices and sort by elevation\n    flat_indices = np.arange(n, dtype=int)\n    flat_elev = dem.ravel()\n    order = np.argsort(flat_elev, kind='mergesort')  # stable sort\n\n    # Seed set\n    seed_set = set([r * cols + c for (r, c) in seeds])\n    total_seeds = len(seed_set)\n\n    # Neighbor offsets for 4-neighborhood\n    nbrs = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    h_star = None\n\n    for idx in order:\n        # Activate cell\n        uf.active[idx] = True\n        uf.parent[idx] = idx  # ensure parent initialized\n        # Initialize seed count for this singleton component\n        uf.seed_count[idx] = 1 if idx in seed_set else 0\n\n        # Row, col\n        r = idx // cols\n        c = idx % cols\n\n        # Union with active neighbors\n        root = uf.find(idx)\n        for dr, dc in nbrs:\n            rr = r + dr\n            cc = c + dc\n            if 0 <= rr < rows and 0 <= cc < cols:\n                nid = rr * cols + cc\n                if uf.active[nid]:\n                    new_root = uf.union(root, nid)\n                    root = new_root\n\n        # After merging, check if all seeds are in this component\n        root = uf.find(idx)\n        if uf.seed_count[root] == total_seeds and total_seeds > 0:\n            h_star = float(flat_elev[idx])\n            break\n\n    # If no seeds, define h_star as NaN and flooded area as 0\n    if total_seeds == 0:\n        return float('nan'), 0.0\n    \n    # If only one seed, h_star is its elevation\n    if total_seeds == 1:\n        r, c = seeds[0]\n        h_star = dem[r,c]\n\n\n    # Flood-fill to compute hydraulically connected extent under z <= h_star\n    mask = dem <= h_star\n    visited = np.zeros_like(mask, dtype=bool)\n    dq = deque()\n\n    # Initialize queue with seed cells (only those under mask should be true at h_star)\n    for (r, c) in seeds:\n        if mask[r, c]:\n            visited[r, c] = True\n            dq.append((r, c))\n\n    while dq:\n        r, c = dq.popleft()\n        for dr, dc in nbrs:\n            rr = r + dr\n            cc = c + dc\n            if 0 <= rr < rows and 0 <= cc < cols:\n                if mask[rr, cc] and not visited[rr, cc]:\n                    visited[rr, cc] = True\n                    dq.append((rr, cc))\n\n    flooded_cells = int(np.sum(visited))\n    flooded_area = float(flooded_cells * (cell_size ** 2))\n    return h_star, flooded_area\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([\n                [6, 6, 6, 6],\n                [6, 2, 2, 6],\n                [6, 2, 2, 6],\n                [6, 6, 6, 6]\n            ], dtype=float),\n            [(1, 1), (2, 2)],\n            30.0\n        ),\n        # Case 2\n        (\n            np.array([\n                [10, 10, 10, 10, 10],\n                [10,  2,  2,  7, 10],\n                [10,  2,  2,  7, 10],\n                [10,  7,  7,  3, 10],\n                [10, 10, 10, 10, 10]\n            ], dtype=float),\n            [(1, 1), (3, 3)],\n            30.0\n        ),\n        # Case 3\n        (\n            np.array([\n                [9, 9, 9, 9, 9],\n                [9, 1, 5, 8, 9],\n                [9, 5, 1, 5, 9],\n                [9, 8, 5, 1, 9],\n                [9, 9, 9, 9, 9]\n            ], dtype=float),\n            [(1, 1), (2, 2), (3, 3)],\n            30.0\n        ),\n        # Case 4\n        (\n            np.array([\n                [5, 4, 5],\n                [4, 2, 4],\n                [5, 4, 5]\n            ], dtype=float),\n            [(1, 1)],\n            30.0\n        )\n    ]\n\n    results = []\n    for dem, seeds, cell_size in test_cases:\n        h_star, area = minimal_connecting_level_and_extent(dem, seeds, cell_size)\n        results.append((h_star, area))\n\n    # Format results as required: [[h1,A1],[h2,A2],...]\n    formatted = \"[\" + \",\".join(f\"[{h},{a}]\" for (h, a) in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        }
    ]
}