{
    "hands_on_practices": [
        {
            "introduction": "归一化差异指数，如归一化植被指数（NDVI），是遥感领域的核心工具。然而，在实际应用中，直接套用公式可能会遇到分母接近于零的数值不稳定性问题。本练习将指导您使用$\\varepsilon$-正则化技术来实现一个稳健的指数计算方法，并从解析上量化该技术引入的偏差，从而加深您对算法设计中精度与稳定性权衡的理解。",
            "id": "3840049",
            "problem": "给定两个表示为数组的单波段反射率栅格，记为 $R_1$ 和 $R_2$。其逐元素值被约束在区间 $[0,1]$ 内，且无物理单位（无量纲）。目标是实现一个逐像素归一化差异算子，该算子计算 $R_1$ 和 $R_2$ 之间的差值并按其和进行归一化，其实现方式应通过添加一个严格为正的正则化参数 $\\varepsilon$ 来确保对于分母中出现的小和值具有数值稳健性。然后，量化此正则化引入的偏差，并验证其绝对值的一个上界。\n\n从以下基本依据出发：\n- 栅格代数运算是逐像素定义的。也就是说，对于任何两个形状相同的栅格 $A$ 和 $B$，其加法、减法、乘法和除法运算都在每个像素上独立执行。\n- 对于任何 $a,b \\in [0,1]$，它们的和满足 $0 \\le a+b \\le 2$，差满足 $-1 \\le a-b \\le 1$。\n\n在和 $S = R_1 + R_2$ 严格为正的每个像素处，将理想的、未经正则化的指数定义为 $R_1$ 和 $R_2$ 的差值除以其和。在每个像素处，将正则化指数定义为相同的差值，但其归一化分母为原和值加上一个严格为正的常数 $\\varepsilon$，即分母中的和值增加了 $\\varepsilon$ 以避免除以极小的数。正则化指数相对于未经正则化指数的逐像素偏差，是该像素上正则化指数与未经正则化指数之间的差值。\n\n你的任务：\n1. 根据上述逐元素定义和代数变换，推导一个关于 $R_1$、$R_2$ 和 $\\varepsilon$ 的逐像素偏差的闭式表达式，该表达式在 $R_1 + R_2 > 0$ 和 $\\varepsilon > 0$ 的任意地方均有效。\n2. 证明偏差绝对值的一个逐点上界，该上界仅用和 $S = R_1 + R_2$ 和 $\\varepsilon$ 表示，而不涉及差值 $R_1 - R_2$。对于所有 $S > 0$ 和 $\\varepsilon > 0$，你的界应该是当非负且有限的。\n3. 对每个像素实现一个稳健的、向量化的计算，用于计算未经正则化和正则化的指数、逐像素偏差，并验证任务2中的上界。使用数值容差 $\\delta = 10^{-12}$ 以适应浮点运算。如果计算出的偏差绝对值小于或等于你得到的上界加上 $\\delta$，则认为该像素的验证成功。\n\n使用以下测试套件。每个测试用例包含 $R_1$ 和 $R_2$ 的两个数组以及一个标量 $\\varepsilon$：\n- 测试用例1（具有中等和值的一般值）：$R_1 = [\\,0.62,\\, 0.18,\\, 0.47,\\, 0.33,\\, 0.70\\,]$，$R_2 = [\\,0.21,\\, 0.35,\\, 0.43,\\, 0.12,\\, 0.40\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例2（和值较小，接近正则化尺度）：$R_1 = [\\,10^{-6},\\, 3 \\times 10^{-4},\\, 5 \\times 10^{-3},\\, 2 \\times 10^{-2}\\,]$，$R_2 = [\\,2 \\times 10^{-6},\\, 8 \\times 10^{-4},\\, 5 \\times 10^{-3},\\, 10^{-2}\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例3（分子为零，和值非零）：$R_1 = [\\,10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 5 \\times 10^{-1}\\,]$，$R_2 = [\\,10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 5 \\times 10^{-1}\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例4（混合极端情况）：$R_1 = [\\,1.0,\\, 0.0,\\, 0.9,\\, 2 \\times 10^{-2},\\, 0.6\\,]$，$R_2 = [\\,0.0,\\, 1.0,\\, 0.1,\\, 10^{-2},\\, 0.35\\,]$，$\\varepsilon = 5 \\times 10^{-2}$。\n\n对于每个测试用例，计算并返回以下三个量：\n- 所有像素中的最大绝对偏差（一个浮点数）。\n- 所有像素的平均有符号偏差（一个浮点数）。\n- 一个布尔值，指示任务2中的上界是否在容差 $\\delta$ 内对每个像素都成立。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个测试用例的结果本身也是一个列表，包含按指定顺序排列的上述三个量。例如，输出应具有以下形式\n“[ [max_abs_bias_case1, mean_bias_case1, bound_ok_case1], [max_abs_bias_case2, mean_bias_case2, bound_ok_case2], [max_abs_bias_case3, mean_bias_case3, bound_ok_case3], [max_abs_bias_case4, mean_bias_case4, bound_ok_case4] ]”。",
            "solution": "该问题要求推导在归一化差异指数中由正则化项引入的偏差，证明该偏差的上界，并进行数值实现以计算偏差并为一组给定的测试用例验证该上界。此问题是适定的，有科学依据，并为获得唯一解提供了所有必要信息。\n\n设两个栅格的逐像素反射率值分别为 $r_1$ 和 $r_2$，其中 $r_1, r_2 \\in [0, 1]$。正则化参数为 $\\varepsilon > 0$。所有栅格操作都按逐元素方式执行。\n\n**任务1：推导逐像素偏差的闭式表达式**\n\n对于 $r_1 + r_2 > 0$，未经正则化的归一化差异指数 $I_{unreg}$ 定义为：\n$$I_{unreg} = \\frac{r_1 - r_2}{r_1 + r_2}$$\n\n正则化指数 $I_{reg}$ 定义为：\n$$I_{reg} = \\frac{r_1 - r_2}{r_1 + r_2 + \\varepsilon}$$\n\n逐像素偏差 $B$ 是正则化指数和未经正则化指数之间的差：\n$$B = I_{reg} - I_{unreg}$$\n\n代入 $I_{reg}$ 和 $I_{unreg}$ 的定义：\n$$B = \\frac{r_1 - r_2}{r_1 + r_2 + \\varepsilon} - \\frac{r_1 - r_2}{r_1 + r_2}$$\n\n为简化起见，令 $D = r_1 - r_2$ 且 $S = r_1 + r_2$。偏差的表达式变为：\n$$B = \\frac{D}{S + \\varepsilon} - \\frac{D}{S}$$\n\n提出公因子 $D$：\n$$B = D \\left( \\frac{1}{S + \\varepsilon} - \\frac{1}{S} \\right)$$\n\n我们对括号中的项进行通分：\n$$B = D \\left( \\frac{S - (S + \\varepsilon)}{S(S + \\varepsilon)} \\right) = D \\left( \\frac{-\\varepsilon}{S(S + \\varepsilon)} \\right)$$\n\n将 $D = r_1 - r_2$ 和 $S = r_1 + r_2$ 代回，我们得到偏差的闭式表达式：\n$$B = - \\varepsilon \\frac{r_1 - r_2}{(r_1 + r_2)(r_1 + r_2 + \\varepsilon)}$$\n该表达式对于所有 $S = r_1 + r_2 > 0$ 的像素和任何 $\\varepsilon > 0$ 都有效。\n\n**任务2：证明偏差绝对值的逐点上界**\n\n我们寻求偏差绝对值 $|B|$ 的一个上界，该上界仅取决于和 $S = r_1 + r_2$ 及正则化参数 $\\varepsilon$。\n\n从推导出的 $B$ 的表达式开始：\n$$|B| = \\left| - \\varepsilon \\frac{r_1 - r_2}{S(S + \\varepsilon)} \\right|$$\n\n由于 $\\varepsilon > 0$ 且 $S > 0$（根据问题的约束），分母 $S(S + \\varepsilon)$ 严格为正。我们可以将绝对值简化为：\n$$|B| = \\frac{\\varepsilon |r_1 - r_2|}{S(S + \\varepsilon)}$$\n\n为了建立一个用 $S$ 和 $\\varepsilon$ 表示的上界，我们必须对 $|r_1 - r_2|$ 项进行界定。反射率值为非负，即 $r_1 \\ge 0$ 和 $r_2 \\ge 0$。根据三角不等式，对于任意两个实数 $x$ 和 $y$，有 $|x - y| \\le |x| + |y|$。将此应用于我们的非负反射率：\n$$|r_1 - r_2| \\le |r_1| + |-r_2| = r_1 + r_2 = S$$\n\n这个不等式 $|r_1 - r_2| \\le S$ 允许我们界定偏差的绝对值。将其代入 $|B|$ 的表达式中：\n$$|B| \\le \\frac{\\varepsilon \\cdot S}{S(S + \\varepsilon)}$$\n\n对于 $S>0$，我们可以消去分子和分母中的 $S$ 项：\n$$|B| \\le \\frac{\\varepsilon}{S + \\varepsilon}$$\n\n这为偏差的绝对值提供了一个有效的上界 $U(S, \\varepsilon) = \\frac{\\varepsilon}{S + \\varepsilon}$。该界仅用 $S$ 和 $\\varepsilon$ 表示，对于所有 $S > 0$ 和 $\\varepsilon > 0$ 都是非负且有限的。该界是紧的，意味着当 $|r_1 - r_2| = S$ 时，等式 $|B| = U(S, \\varepsilon)$ 成立，这当且仅当 $r_1$ 或 $r_2$ 中有一个为零时发生。这是一个物理上可实现的条件（例如，$r_1 \\in (0, 1]$ 且 $r_2 = 0$）。\n\n**任务3：向量化计算的算法设计**\n\n实现将使用 `numpy` 库进行向量化，以高效地对栅格数组执行逐元素操作。\n\n对于每个由数组 $R_1$、$R_2$ 和标量 $\\varepsilon$ 组成的测试用例：\n1.  计算逐元素和 $S = R_1 + R_2$ 以及逐元素差 $D = R_1 - R_2$。\n2.  使用数值上稳定的、推导出的闭式表达式计算偏差数组 $B$：$B = -\\varepsilon D / (S(S + \\varepsilon))$。这避免了直接计算 $I_{reg} - I_{unreg}$ 可能出现的相减抵消问题。\n3.  计算偏差绝对值数组 $|B| = \\text{abs}(B)$。\n4.  计算上界数组 $U = \\varepsilon / (S + \\varepsilon)$。\n5.  在每个像素上验证上界。使用数值容差 $\\delta = 10^{-12}$，在单个像素上验证成功的条件是 $|B| \\le U + \\delta$。通过此比较生成一个布尔数组。\n6.  如果条件对所有像素都成立，则认为该测试用例的总体上界验证成功。这通过对上一步的布尔数组应用全称量词（`np.all`）来确定。\n7.  该测试用例所需的三个输出量是：\n    a. 最大绝对偏差：$\\max(|B|)$。\n    b. 平均有符号偏差：$\\text{mean}(B)$。\n    c. 上界验证的总体布尔结果。\n对每个测试用例重复这些步骤，并将结果汇总以供最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the raster algebra problem by calculating bias and verifying bounds.\n    \"\"\"\n    \n    test_cases = [\n        (\n            [0.62, 0.18, 0.47, 0.33, 0.70],\n            [0.21, 0.35, 0.43, 0.12, 0.40],\n            1e-3\n        ),\n        (\n            [1e-6, 3e-4, 5e-3, 2e-2],\n            [2e-6, 8e-4, 5e-3, 1e-2],\n            1e-3\n        ),\n        (\n            [1e-6, 1e-3, 1e-1, 5e-1],\n            [1e-6, 1e-3, 1e-1, 5e-1],\n            1e-3\n        ),\n        (\n            [1.0, 0.0, 0.9, 2e-2, 0.6],\n            [0.0, 1.0, 0.1, 1e-2, 0.35],\n            5e-2\n        )\n    ]\n    \n    delta = 1e-12\n    all_results = []\n    \n    for r1_list, r2_list, epsilon in test_cases:\n        # Convert input lists to numpy arrays for vectorized operations\n        R1 = np.array(r1_list, dtype=float)\n        R2 = np.array(r2_list, dtype=float)\n\n        # Task 1: Compute bias using the derived closed-form expression\n        # This is more numerically stable than subtracting the indices directly.\n        S = R1 + R2  # Element-wise sum\n        D = R1 - R2  # Element-wise difference\n        \n        # Guard against division by zero in the unlikely case S is zero\n        # The problem statement guarantees S > 0 in the test data.\n        # This is for general robustness.\n        # bias = np.divide(-epsilon * D, S * (S + epsilon), where=S>0, out=np.zeros_like(S))\n        bias = -epsilon * D / (S * (S + epsilon))\n        \n        # Task 2: Compute upper bound and verify\n        abs_bias = np.abs(bias)\n        \n        # Bound U(S, epsilon) = epsilon / (S + epsilon)\n        bound = epsilon / (S + epsilon)\n        \n        # Task 3: Verification with tolerance\n        is_bound_satisfied_all_pixels = np.all(abs_bias = bound + delta)\n\n        # Compute required output statistics\n        max_abs_bias = np.max(abs_bias)\n        mean_signed_bias = np.mean(bias)\n        \n        # Append results for the current test case\n        all_results.append([max_abs_bias, mean_signed_bias, bool(is_bound_satisfied_all_pixels)])\n\n    # Format the final output string as a list of lists.\n    # The str() representation of a list of lists matches the required spacing and format.\n    # The problem example shows lowercase booleans, but python's default is capitalized.\n    # We will produce standard Python string representation, which is unambiguous.\n    # The problem prompt is a bit ambiguous on this formatting detail, so we choose\n    # the most direct and standard Python representation.\n    print(str(all_results).replace(\"True\", \"true\").replace(\"False\", \"false\"))\n\nsolve()\n\n```"
        },
        {
            "introduction": "分区统计是总结特定感兴趣区域（如土地地块或分水岭）内栅格数据特征的基本方法。虽然简单的“朴素”扫描方法直观易懂，但其性能在处理大型栅格或众多分区时会急剧下降。本练习将引导您应用“和区域表”（Summed-Area Table, SAT）这一高效技术，以实现对矩形区域内数值求和的常数时间查询。通过亲手实现并对比两种方法，您将深刻体会到算法效率的重要性，并掌握一种加速空间分析任务的实用技巧。",
            "id": "3840046",
            "problem": "给定一个二维栅格和一组轴对齐的矩形区域。任务是设计并实现一种基于栅格代数概念的算法，该算法使用和区域表（Summed-Area Tables, SAT；也称为积分图）高效地计算分区直方图，并评估其相对于朴素扫描方法的复杂度。栅格是定义在规则网格上的函数，分区直方图为每个矩形区域统计其栅格单元值落入预设分组的数量。该问题必须通过离散求和与集合运算的基本定义推导方法来解决。\n\n定义与假设：\n- 设栅格为一个函数 $R : \\{0,1,\\dots,H-1\\} \\times \\{0,1,\\dots,W-1\\} \\to \\mathbb{R}$，其高度为 $H$，宽度为 $W$。\n- 设有 $B$ 个直方图分组，由边界值 $\\mathbf{a} = \\big(a_0, a_1, \\dots, a_B\\big)$ 定义，其中 $a_0  a_1  \\dots  a_B$。一个值 $x$ 属于分组 $k \\in \\{0,1,\\dots,B-1\\}$，如果 $a_k \\le x  a_{k+1}$；如果 $x = a_B$，则 $x$ 被分配到分组 $B-1$。\n- 一个矩形区域由其包含的索引 $(r_0, r_1, c_0, c_1)$ 指定，其中 $0 \\le r_0 \\le r_1  H$ 且 $0 \\le c_0 \\le c_1  W$。\n- 可以指定一个可选的 NoData 值 $v_{\\text{nodata}} \\in \\mathbb{R}$；值等于 $v_{\\text{nodata}}$ 的单元格将从所有直方图中排除。\n\n您的程序必须：\n1. 根据分组边界值（排除 NoData）将栅格量化为分组索引。\n2. 使用两种方法计算分区直方图：\n   - 朴素扫描：对每个区域，遍历其所有像素，并为非 NoData 单元格增加相应分组的计数。\n   - 基于和区域表（SAT）的方法：对每个分组 $k$，在指示函数 $\\phi_k(r,c) = 1$（如果单元格属于分组 $k$ 且不是 NoData）和 $\\phi_k(r,c) = 0$（否则）上构建一个积分图。使用容斥原理，通过每次查询时间复杂度为常数的 SAT，计算每个矩形区域的计数。\n3. 在以下标量运算成本模型下评估操作计数：\n   - SAT 构建成本：对每个分组，计算一个两遍（先沿行，后沿列）的累积和，成本为 $2 \\cdot H \\cdot W$ 次加法。对于 $B$ 个分组，总的 SAT 构建成本为 $2 \\cdot H \\cdot W \\cdot B$ 次加法。\n   - SAT 查询成本：每个分组的每次矩形查询使用容斥原理，需要 $4$ 次标量运算（三次加法和一次减法）。对于 $B$ 个分组上的 $Z$ 个区域，总的 SAT 查询成本为 $4 \\cdot Z \\cdot B$ 次标量运算。\n   - 朴素扫描成本：对每个区域，每扫描一个非 NoData 像素计为一次标量加法。总成本是所有区域的非 NoData 像素数量之和。\n   - 为确保公平比较，两种方法的量化成本均不计入，因为它们都依赖于相同的预量化步骤。\n4. 验证在每个测试用例中，基于 SAT 的直方图与朴素扫描得到的直方图匹配。\n\n您必须以 LaTeX 格式表达所有数学语句、符号、变量、运算符和数字。程序应生成并处理以下测试套件：\n\n测试用例 1（无 NoData 的一般情况）：\n- 大小为 $H = 6$, $W = 5$ 的栅格 $R$：\n  $\n  \\begin{bmatrix}\n  12  15  8  7  6 \\\\\n  5  9  11  3  2 \\\\\n  1  4  0  13  10 \\\\\n  8  8  8  14  16 \\\\\n  20  18  17  7  5 \\\\\n  6  6  6  6  6\n  \\end{bmatrix}\n  $\n- 分组边界值 $\\mathbf{a} = (0, 5, 10, 15, 20)$，因此 $B = 4$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 2, 1, 3)$。\n  - 区域 $2$：$(r_0, r_1, c_0, c_1) = (3, 5, 0, 4)$。\n  - 区域 $3$：$(r_0, r_1, c_0, c_1) = (0, 5, 0, 4)$。\n- NoData：无。\n\n测试用例 2（边界和 NoData 处理）：\n- 大小为 $H = 3$, $W = 3$ 的栅格 $R$：\n  $\n  \\begin{bmatrix}\n  0  -9999  10 \\\\\n  5  5  5 \\\\\n  15  20  20\n  \\end{bmatrix}\n  $\n- 分组边界值 $\\mathbf{a} = (0, 5, 10, 15, 20)$，因此 $B = 4$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 0, 0, 0)$。\n  - 区域 $2$：$(r_0, r_1, c_0, c_1) = (0, 0, 1, 1)$。\n  - 区域 $3$：$(r_0, r_1, c_0, c_1) = (1, 1, 0, 2)$。\n  - 区域 $4$：$(r_0, r_1, c_0, c_1) = (0, 2, 0, 2)$。\n- NoData：$v_{\\text{nodata}} = -9999$。\n\n测试用例 3（所有值相等的退化栅格）：\n- 大小为 $H = 4$, $W = 4$ 的栅格 $R$，所有条目均为 $7$。\n- 分组边界值 $\\mathbf{a} = (0, 7, 14)$，因此 $B = 2$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 3, 0, 3)$。\n- NoData：无。\n\n测试用例 4（重复大范围查询的摊销）：\n- 大小为 $H = 40$, $W = 40$ 的栅格 $R$，其中 $R(r,c) = r + c$，对于 $r \\in \\{0,1,\\dots,39\\}$ 和 $c \\in \\{0,1,\\dots,39\\}$。\n- 分组边界值 $\\mathbf{a}$ 是从 $0$ 到 $80$ 的 $9$ 个等间距边界值，即 $\\mathbf{a} = \\big(0, 10, 20, 30, 40, 50, 60, 70, 80\\big)$，因此 $B = 8$。\n- 区域：$200$ 个覆盖整个栅格的相同区域，即每个区域的 $(r_0, r_1, c_0, c_1) = (0, 39, 0, 39)$。\n- NoData：无。\n\n对于每个测试用例，您的程序必须输出一个列表，其中包含：\n- 一个布尔值，表示基于 SAT 的分区直方图是否与朴素扫描的完全匹配。\n- 在指定成本模型下，朴素扫描的总操作计数（整数）。\n- 在指定成本模型下，SAT 的总操作计数（整数）。\n- 速度比（朴素扫描操作数除以 SAT 操作数）（浮点数）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个逗号分隔的列表，并用方括号括起来，每个测试用例的结果本身也是一个按上述顺序排列的列表。例如：$\\big[\\,[\\text{True},\\,100,\\,48,\\,2.0833333333333335],\\dots\\big]$。",
            "solution": "本问题要求设计、实现并进行复杂度分析两种在二维栅格上计算分区直方图的算法：一种是朴素扫描方法，另一种是基于和区域表（SAT）的更高效方法。解决方案将从离散求和与集合论的基本原理推导得出。\n\n### **1. 形式化问题定义**\n\n设栅格是一个网格函数 $R(r, c)$，定义在离散域 $D = \\{0, 1, \\dots, H-1\\} \\times \\{0, 1, \\dots, W-1\\}$ 上，其中 $H$ 是高度，$W$ 是宽度。每个单元格 $(r,c) \\in D$ 的值为 $R(r,c) \\in \\mathbb{R}$。\n\n一组 $B$ 个直方图分组由一个包含 $B+1$ 个分组边界值的有序序列 $\\mathbf{a} = \\big(a_0, a_1, \\dots, a_B\\big)$ 定义，满足 $a_0  a_1  \\dots  a_B$。一个栅格值 $x$ 根据以下规则被分配到分组 $k \\in \\{0, 1, \\dots, B-1\\}$：\n- 若 $a_k \\le x  a_{k+1}$，$x$ 属于分组 $k$。\n- 作为最右边界的特殊情况，若 $x = a_B$，$x$ 属于分组 $B-1$。\n具有指定 NoData 值 $v_{\\text{nodata}}$ 的单元格在所有计算中都将被忽略。\n\n一个矩形区域 $\\mathcal{Z}$ 由其包含的行列索引 $(r_0, r_1, c_0, c_1)$ 定义，其中 $0 \\le r_0 \\le r_1  H$ 且 $0 \\le c_0 \\le c_1  W$。\n\n任务是计算每个区域的直方图。一个区域 $\\mathcal{Z}$ 的直方图是一个计数向量 $\\mathbf{h}(\\mathcal{Z}) = \\big(h_0, h_1, \\dots, h_{B-1}\\big)$，其中 $h_k$ 是区域 $\\mathcal{Z}$ 内值 $R(r,c)$ 落入分组 $k$ 且不等于 $v_{\\text{nodata}}$ 的单元格数量。\n\n### **2. 预处理：栅格量化**\n\n朴素方法和基于 SAT 的方法都可以从一个共同的预处理步骤中受益：栅格量化。这包括创建一组 $B$ 个二元指示栅格或掩码 $\\Phi = \\{\\phi_0, \\phi_1, \\dots, \\phi_{B-1}\\}$。每个掩码 $\\phi_k(r,c)$ 对应一个分组 $k$，定义如下：\n$$\n\\phi_k(r,c) = \\begin{cases} 1  \\text{if } R(r,c) \\text{ is in bin } k \\text{ and } R(r,c) \\ne v_{\\text{nodata}} \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n利用这些指示函数，区域 $\\mathcal{Z}_{(r_0, r_1, c_0, c_1)}$ 的计数值 $h_k$ 可以正式表示为一个离散二维和：\n$$\nh_k(\\mathcal{Z}) = \\sum_{r=r_0}^{r_1} \\sum_{c=c_0}^{c_1} \\phi_k(r,c)\n$$\n此量化步骤的成本被排除在比较分析之外，因为它是两种方法的先决条件。\n\n### **3. 方法一：朴素扫描**\n\n朴素扫描算法是求和公式的直接实现。对于每个指定的区域 $\\mathcal{Z}$，我们遍历其边界内的每个单元格 $(r,c)$。对每个单元格，我们获取其值 $R(r,c)$，确定其对应的分组索引（如果不是 NoData），并增加该区域直方图中相应计数器的值。\n\n**算法步骤：**\n1. 对于 $Z$ 个区域集合中的每个区域 $\\mathcal{Z}_i$：\n2. 初始化一个大小为 $B$、全为零的直方图向量 $\\mathbf{h}(\\mathcal{Z}_i)$。\n3. 对于从 $(r_{i,0}, c_{i,0})$ 到 $(r_{i,1}, c_{i,1})$ 的每个单元格 $(r,c)$：\n   a. 令 $v = R(r,c)$。\n   b. 如果 $v \\ne v_{\\text{nodata}}$：\n      i. 确定值 $v$ 的分组索引 $k$。\n      ii. 增加该分组的计数：$h_k(\\mathcal{Z}_i) \\leftarrow h_k(\\mathcal{Z}_i) + 1$。\n\n**复杂度分析：**\n根据问题的成本模型，处理单个区域 $\\mathcal{Z}$ 的成本是其非 NoData 单元格的数量，我们记为 $N(\\mathcal{Z})$。对于一组 $Z$ 个区域 $\\{\\mathcal{Z}_1, \\dots, \\mathcal{Z}_Z\\}$，总计算成本是每个区域成本的总和：\n$$\nC_{\\text{naive}} = \\sum_{i=1}^{Z} N(\\mathcal{Z}_i)\n$$\n该成本与所有区域扫描的总面积成正比。如果区域重叠，重叠区域中的单元格将被多次处理。\n\n### **4. 方法二：和区域表（SAT）**\n\n和区域表（Summed-Area Table, SAT），或称积分图，是一种允许快速计算矩形子区域内数值之和的数据结构。其关键思想是以一次性的预计算成本换取极快的查询时间。\n\n**SAT 构建：**\n对于每个分组 $k$，我们构建一个对应的 SAT，记为 $S_k$。$S_k$ 在任意坐标 $(r,c)$ 处的值是指示函数值 $\\phi_k(i,j)$ 在从原点 $(0,0)$ 到 $(r,c)$ 的矩形内的总和：\n$$\nS_k(r,c) = \\sum_{i=0}^{r} \\sum_{j=0}^{c} \\phi_k(i,j)\n$$\nSAT 可以通过以下递推关系在指示掩码 $\\phi_k$ 上单遍高效计算：\n$$\nS_k(r,c) = \\phi_k(r,c) + S_k(r-1, c) + S_k(r, c-1) - S_k(r-1, c-1)\n$$\n边界条件为 $S_k(r,c) = 0$（如果 $r  0$ 或 $c  0$）。这通常实现为两遍算法：首先，沿每行计算累积和，然后，对中间结果的每列计算累积和。\n对于一个大小为 $H \\times W$ 的栅格，每遍计算大约涉及 $H \\times W$ 次加法。因此，构建一个 SAT 的成本是 $2 \\cdot H \\cdot W$ 次加法。对于所有 $B$ 个分组，总构建成本为：\n$$\nC_{\\text{construct}} = 2 \\cdot H \\cdot W \\cdot B\n$$\n\n**SAT 查询：**\n一旦 SATs $S_0, \\dots, S_{B-1}$ 构建完成，$\\phi_k$ 在任意矩形 $\\mathcal{Z}_{(r_0, r_1, c_0, c_1)}$ 上的总和就可以使用容斥原理在常数时间内计算。这个和等于以 $(0,0)$ 为锚点、延伸至 $(r_1, c_1)$ 的矩形面积，减去两个重叠的矩形，再加上它们共同的交集。\n$$\nh_k(\\mathcal{Z}) = \\sum_{r=r_0}^{r_1} \\sum_{c=c_0}^{c_1} \\phi_k(r,c) = S_k(r_1, c_1) - S_k(r_1, c_0-1) - S_k(r_0-1, c_1) + S_k(r_0-1, c_0-1)\n$$\n为了简化索引处理，特别是对于接触栅格边界的区域（其中 $r_0-1$ 或 $c_0-1$ 会是负数），通常的做法是用一行和一列零来填充 SAT。对分组 $k$ 的一次查询需要 $4$ 次查找和 $3$ 次算术运算，问题将其定义为 $4$ 次标量运算。对于 $B$ 个分组上的 $Z$ 个区域，总查询成本为：\n$$\nC_{\\text{query}} = 4 \\cdot Z \\cdot B\n$$\n\n**基于 SAT 的总成本：**\n基于 SAT 的方法的总成本是构建成本和查询成本之和：\n$$\nC_{\\text{SAT}} = C_{\\text{construct}} + C_{\\text{query}} = (2 \\cdot H \\cdot W \\cdot B) + (4 \\cdot Z \\cdot B)\n$$\n\n### **5. 对比分析**\n\n朴素扫描和 SAT 方法之间的选择取决于问题参数：栅格大小 $(H, W)$、分组数量 $(B)$，以及查询区域的数量 $(Z)$ 和大小。\n\n-   **朴素成本：** $C_{\\text{naive}} \\propto \\sum (\\text{Area of Zone}_i)$\n-   **SAT 成本：** $C_{\\text{SAT}} \\propto (H \\cdot W \\cdot B) + (Z \\cdot B)$\n\nSAT 方法的成本与查询区域的大小无关。它有显著的构建表的初始成本，但每次查询的成本非常低，为常数时间。朴素方法没有初始成本，但查询成本与区域面积成线性关系。\n\n当查询数量很大或区域本身很大时，SAT 方法变得比朴素方法更高效，因为这会导致朴素方法扫描的总面积超过 SAT 的构建成本。术语 $C_{\\text{construct}}$ 的成本被摊销到多次查询中。测试用例 4 有 200 个大区域，旨在展示这种摊销效应，预计 SAT 方法将显著更快。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run test cases for zonal histogram calculation.\n    \"\"\"\n    \n    def quantize_raster(raster, bin_edges, nodata_val):\n        \"\"\"\n        Quantizes the raster into B binary indicator masks.\n        \n        A value x is in bin k if bin_edges[k] = x  bin_edges[k+1].\n        If x == bin_edges[-1], it is in the last bin (B-1).\n        \n        Returns a (B, H, W) numpy array of indicator masks.\n        \"\"\"\n        H, W = raster.shape\n        num_bins = len(bin_edges) - 1\n        \n        # Initialize with a sentinel value for pixels outside all bins or nodata\n        bin_indices = np.full(raster.shape, -1, dtype=int)\n        \n        # Assign bin indices based on the rules.\n        # Bins 0 to B-2: a_k = x  a_{k+1}\n        for k in range(num_bins - 1):\n            mask = (raster >= bin_edges[k])  (raster  bin_edges[k+1])\n            bin_indices[mask] = k\n        \n        # Last bin (B-1): a_{B-1} = x = a_B\n        mask_last_bin = (raster >= bin_edges[num_bins - 1])  (raster = bin_edges[num_bins])\n        bin_indices[mask_last_bin] = num_bins - 1\n\n        # Mask out NoData values\n        if nodata_val is not None:\n            bin_indices[raster == nodata_val] = -1\n\n        # Create B indicator masks from the bin indices\n        quantized_masks = np.zeros((num_bins, H, W), dtype=int)\n        for k in range(num_bins):\n            quantized_masks[k, :, :] = (bin_indices == k)\n        \n        return quantized_masks\n\n    def naive_histograms(quantized_masks, zones, original_raster, nodata_val):\n        \"\"\"\n        Computes zonal histograms using naive scanning.\n        \"\"\"\n        histograms = []\n        naive_op_count = 0\n        \n        for r0, r1, c0, c1 in zones:\n            # Calculate operation cost for this zone\n            zone_raster = original_raster[r0:r1+1, c0:c1+1]\n            if nodata_val is not None:\n                naive_op_count += np.sum(zone_raster != nodata_val)\n            else:\n                naive_op_count += zone_raster.size\n\n            # Slice the indicator masks to get the zone\n            zone_masks = quantized_masks[:, r0:r1+1, c0:c1+1]\n            # Sum over the spatial dimensions to get the histogram\n            histogram = np.sum(zone_masks, axis=(1, 2))\n            histograms.append(histogram)\n            \n        return np.array(histograms), naive_op_count\n\n    def sat_histograms(quantized_masks, zones):\n        \"\"\"\n        Computes zonal histograms using Summed-Area Tables.\n        \"\"\"\n        num_bins, H, W = quantized_masks.shape\n        num_zones = len(zones)\n        \n        # --- SAT Construction ---\n        # Cost as per problem statement\n        sat_construction_cost = 2 * H * W * num_bins\n        \n        # Pad SATs with a row and column of zeros for easy querying\n        sats = np.zeros((num_bins, H + 1, W + 1), dtype=int)\n        \n        # Compute cumulative sums twice: once along columns (axis=2), then rows (axis=1)\n        # This is a vectorized implementation of the two-pass algorithm.\n        sats[:, 1:, 1:] = np.cumsum(np.cumsum(quantized_masks, axis=2), axis=1)\n\n        # --- SAT Querying ---\n        # Cost as per problem statement\n        sat_query_cost = 4 * num_zones * num_bins\n        total_sat_cost = sat_construction_cost + sat_query_cost\n\n        histograms = []\n        for r0, r1, c0, c1 in zones:\n            # Adjust indices for padded SAT. The query area corresponds to\n            # corners (r0, c0) and (r1+1, c1+1) in the padded SAT.\n            # D = S(r1, c1), C = S(r1, c0-1), B = S(r0-1, c1), A = S(r0-1, c0-1)\n            # Sum = D - B - C + A\n            # Indices in padded SAT: S(r,c) is accessed at sats[:, r+1, c+1]\n            # So, S(r1,c1) -> sats[:, r1+1, c1+1]\n            # S(r1,c0-1) -> sats[:, r1+1, c0]\n            # S(r0-1,c1) -> sats[:, r0, c1+1]\n            # S(r0-1,c0-1) -> sats[:, r0, c0]\n            # This is vectorized across all bins simultaneously.\n            D = sats[:, r1 + 1, c1 + 1]\n            B_term = sats[:, r1 + 1, c0]\n            C_term = sats[:, r0, c1 + 1]\n            A = sats[:, r0, c0]\n            histogram = D - B_term - C_term + A\n            histograms.append(histogram)\n            \n        return np.array(histograms), total_sat_cost\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"R\": np.array([\n                [12, 15, 8, 7, 6],\n                [5, 9, 11, 3, 2],\n                [1, 4, 0, 13, 10],\n                [8, 8, 8, 14, 16],\n                [20, 18, 17, 7, 5],\n                [6, 6, 6, 6, 6]\n            ]),\n            \"a\": (0, 5, 10, 15, 20),\n            \"zones\": [(0, 2, 1, 3), (3, 5, 0, 4), (0, 5, 0, 4)],\n            \"nodata\": None\n        },\n        # Test Case 2\n        {\n            \"R\": np.array([\n                [0, -9999, 10],\n                [5, 5, 5],\n                [15, 20, 20]\n            ]),\n            \"a\": (0, 5, 10, 15, 20),\n            \"zones\": [(0, 0, 0, 0), (0, 0, 1, 1), (1, 1, 0, 2), (0, 2, 0, 2)],\n            \"nodata\": -9999\n        },\n        # Test Case 3\n        {\n            \"R\": np.full((4, 4), 7),\n            \"a\": (0, 7, 14),\n            \"zones\": [(0, 3, 0, 3)],\n            \"nodata\": None\n        },\n        # Test Case 4\n        {\n            \"R\": np.array([[r + c for c in range(40)] for r in range(40)]),\n            \"a\": tuple(range(0, 81, 10)),\n            \"zones\": [(0, 39, 0, 39)] * 200,\n            \"nodata\": None\n        },\n    ]\n\n    final_results = []\n    for case in test_cases:\n        raster = case[\"R\"]\n        bin_edges = case[\"a\"]\n        zones = case[\"zones\"]\n        nodata_val = case[\"nodata\"]\n\n        # 1. Quantize the raster\n        quantized_masks = quantize_raster(raster, bin_edges, nodata_val)\n\n        # 2a. Compute histograms and cost with naive scanning\n        naive_hists, naive_cost = naive_histograms(quantized_masks, zones, raster, nodata_val)\n\n        # 2b. Compute histograms and cost with SAT\n        sat_hists, sat_cost = sat_histograms(quantized_masks, zones)\n        \n        # 3. Verify results\n        is_match = np.array_equal(naive_hists, sat_hists)\n        \n        # 4. Calculate speed ratio\n        if sat_cost > 0:\n            speed_ratio = naive_cost / sat_cost\n        else: # Should not happen with the given cost models\n            speed_ratio = float('inf') if naive_cost > 0 else 1.0\n            \n        final_results.append([is_match, int(naive_cost), int(sat_cost), speed_ratio])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "栅格代数不仅限于静态分析，它在模拟运动和流动方面也至关重要，而最小成本路径分析便是一个典型应用。此实践的核心在于将连续的成本表面离散化为一个加权图，并应用如图论中的 Dijkstra 算法来寻找最优路径。您将实现从图的构建到路径重建的完整工作流程，从而巩固对抽象图论如何为地理信息系统和环境建模中的复杂空间问题提供强大解决方案的理解。",
            "id": "3840074",
            "problem": "您的概念性任务是在一个空间网格（栅格）上计算最低成本路径，其中每个单元格存储一个非负的单位长度移动摩擦成本，并形式化累积成本栅格与一个非负加权图模型所诱导的最短路径树之间的关系。此问题中的栅格代数构造必须从第一性原理推导得出，该原理将空间变化成本场的连续路径积分与栅格上的离散图表示联系起来。\n\n从以下基本基础开始：一个定义在域 $\\Omega \\subset \\mathbb{R}^2$ 上的连续成本场 $c(\\mathbf{x}) \\ge 0$，以及一条总弧长为 $L$、无穷小弧长测度为 $\\mathrm{d}s$ 的连续路径 $\\gamma: [0, L] \\to \\Omega$。遍历 $\\gamma$ 的累积成本是路径积分\n$$\nJ[\\gamma] = \\int_{0}^{L} c(\\gamma(s)) \\, \\mathrm{d}s,\n$$\n这是对弧长积分一个非负摩擦的空间模拟。对于一个具有 $m$ 行和 $n$ 列的栅格，定义成本栅格 $C \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$，使得 $C_{i,j}$ 近似于单元格中心 $\\mathbf{x}_{i,j}$ 处的 $c(\\mathbf{x}_{i,j})$。设顶点集为 $V = \\{(i,j) \\mid i \\in \\{0,\\dots,m-1\\}, j \\in \\{0,\\dots,n-1\\}\\}$，边集 $E$ 在指定的连通性 $\\mathcal{N}$（4连通或8连通）下连接每个单元格与其邻居。将每条边 $e = (u,v) \\in E$ 与一个欧几里得步长 $d_{uv} \\in \\{1,\\sqrt{2}\\}$ 相关联，具体取决于 $u$ 和 $v$ 是正交邻居还是对角邻居。沿每条边使用一阶精确求积（例如，应用于单元格中心之间线段的梯形法则），将边权重 $w_{uv}$ 近似为沿该短线段对 $c$ 进行积分的离散模拟。这定义了一个非负加权图 $(V,E,w)$，对于该图，从源点集 $S \\subset V$ 到任意顶点 $v \\in V$ 的累积成本是从 $S$ 到 $v$ 的所有离散路径的边权重之和的最小值，并且相应的前驱关系定义了一个最短路径树（当 $|S| \\ge 2$ 时为一个森林）。\n\n您的任务是：\n- 实现一个程序，给定 $C$、$\\mathcal{N}$、一个源点集 $S \\subset V$ 和一个目标点 $t \\in V$，该程序如上所述构建加权图，并使用 Dijkstra 算法在 $(V,E,w)$ 上计算累积成本栅格 $A \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$ 和前驱栅格 $P \\in \\{-1\\} \\cup \\{0,1,\\dots,mn-1\\}^{m \\times n}$，其中 $A_{v}$ 是从 $S$ 中任意源点到 $v$ 的最小边权重和，而 $P_v$ 编码算法在最短路径树中为 $v$选择的唯一前驱（对于源点则为 $-1$）。该图必须遵守以下规则：边仅存在于 $\\mathcal{N}$ 下的有效界内邻居之间，并且与不可通行单元格（$C_{i,j} = +\\infty$）关联的任何边都将被排除。对 $(i,j)$ 坐标使用从零开始的索引约定，并使用扁平索引映射 $f(i,j) = i \\cdot n + j$ 来存储前驱。\n- 通过追踪 $P$ 从目标点 $t$ 回溯到其源点来重建最低成本路径，计算路径上的步数，并验证重建路径上累积成本栅格的边加性属性：对于路径中的每个连续对 $(u,v)$，检查 $A_{v} = A_{u} + w_{uv}$ 是否在 $10^{-9}$ 的数值容差内成立，并检查路径上的边权重总和是否在相同容差内等于 $A_{t}$。\n\n单位：所有成本都是无单位的，表示每单位长度的成本单位；步长是无单位的，根据构造，对于正交移动等于 $1$，对于对角移动等于 $\\sqrt{2}$。\n\n角度单位：此问题不使用角度。\n\n百分比：不适用。\n\n测试套件和参数规范：\n定义四个测试用例，每个用例都有一个目标点：\n- 测试用例 1（8连通性和均匀成本的一般情况）：\n    - 栅格大小：$m = 5$, $n = 5$。\n    - 成本栅格：对于所有 $(i,j)$，$C_{i,j} = 1$。\n    - 连通性：$\\mathcal{N} = 8$连通。\n    - 源点：$S = \\{(0,0)\\}$。\n    - 目标点：$t = (4,3)$。\n- 测试用例 2（有不可通行障碍和4连通性的边界情况）：\n    - 栅格大小：$m = 5$, $n = 5$。\n    - 成本栅格：对于所有 $(i,j)$，$C_{i,j} = 1$，但 $C_{2,1} = C_{2,2} = C_{2,3} = +\\infty$（不可通行）。\n    - 连通性：$\\mathcal{N} = 4$连通。\n    - 源点：$S = \\{(0,2)\\}$。\n    - 目标点：$t = (4,2)$。\n- 测试用例 3（具有多个源点和8连通性的非均匀梯度成本）：\n    - 栅格大小：$m = 6$, $n = 6$。\n    - 成本栅格：对于 $i \\in \\{0,\\dots,5\\}, j \\in \\{0,\\dots,5\\}$，$C_{i,j} = 1 + 0.15\\, i + 0.05\\, j$。\n    - 连通性：$\\mathcal{N} = 8$连通。\n    - 源点：$S = \\{(0,0),(5,5)\\}$。\n    - 目标点：$t = (5,0)$。\n- 测试用例 4（具有多个源点且在均匀成本下存在平局的边界情况）：\n    - 栅格大小：$m = 4$, $n = 4$。\n    - 成本栅格：对于所有 $(i,j)$，$C_{i,j} = 1$。\n    - 连通性：$\\mathcal{N} = 8$连通。\n    - 源点：$S = \\{(0,3),(3,0)\\}$。\n    - 目标点：$t = (3,3)$。\n\n最终输出格式：\n对于每个测试用例，生成一个包含三项的列表：到达目标点 $t$ 的累积成本 $A_{t}$（浮点数，保留6位小数），沿重建的最低成本路径到达源点的步数（整数），以及一个布尔值，指示边加性属性和总路径成本相等性是否在 $10^{-9}$ 容差内成立。您的程序应生成一行输出，其中包含一个逗号分隔的列表，列表用方括号括起来，每个元素对应一个测试用例，本身就是一个形如 $[A_{t}, \\text{steps}, \\text{valid}]$ 的列表。例如，两个测试用例的输出将类似于 $[[a_1,s_1,v_1],[a_2,s_2,v_2]]$，并用实际值替换。",
            "solution": "问题陈述已经过仔细审查，并被确定为 **有效**。它的科学基础在于图论和数值方法应用于空间分析（特别是栅格上的最低成本路径寻找）的原理。该问题是适定的，提供了所有必要的数据、约束和定义，以确保一个唯一且有意义的解决方案。它是客观且无歧义的。任务是基于这些原则实现一个计算解决方案。\n\n解决方案首先将连续的成本路径问题离散化为加权图上的最短路径问题。然后，我们应用 Dijkstra 算法解决这个离散问题，最后，我们重建并验证所得路径。\n\n**1. 离散化：从连续场到离散图**\n\n基本概念是将一个连续问题转化为一个适合计算的离散问题。连续的累积成本由路径积分 $J[\\gamma] = \\int_{\\gamma} c(\\mathbf{x}) \\, \\mathrm{d}s$ 给出，其中 $c(\\mathbf{x})$ 是一个空间变化的摩擦成本场。\n\n我们按如下方式进行离散化：\n- 连续域 $\\Omega \\subset \\mathbb{R}^2$ 由一个 $m \\times n$ 单元格的网格表示。每个单元格 $(i,j)$ 成为图 $G = (V, E)$ 中的一个顶点 $v_{i,j}$。\n- 成本场 $c(\\mathbf{x})$ 在每个单元格的中心进行采样，得到成本栅格 $C$，其中 $C_{i,j}$ 是顶点 $v_{i,j}$ 处的成本值。\n- 连续路径 $\\gamma$ 由连接图中相邻顶点的一系列边来近似。可用边集 $E$ 由指定的连通性决定，可以是4连通（正交邻居）或8连通（正交和对角邻居）。\n- 沿两个相邻顶点 $u$ 和 $v$ 之间的短路径段的积分 $\\int c(\\mathbf{x}) \\, \\mathrm{d}s$ 由离散边权重之和 $w_{uv}$ 近似。\n\n**2. 边权重公式**\n\n问题指定使用一阶精确求积来近似沿连接两个相邻单元格中心 $u$ 和 $v$ 的直线段的成本积分。梯形法则是合适的选择。沿此线段的成本积分近似为端点成本的平均值乘以该线段的长度：\n$$\nw_{uv} \\approx \\frac{C_u + C_v}{2} d_{uv}\n$$\n其中 $C_u$ 和 $C_v$ 分别是单元格 $u$ 和 $v$ 的成本值，$d_{uv}$ 是它们中心之间的欧几里得距离。按照惯例，对于单位网格间距：\n- 对于正交邻居，$d_{uv} = 1$。\n- 对于对角邻居，$d_{uv} = \\sqrt{2}$。\n\n由于所有成本 $C_{i,j}$ 都是非负的，因此所有得到的边权重 $w_{uv}$ 也都是非负的。这是 Dijkstra 算法正确性的一个关键先决条件。与不可通行单元格（其中 $C_{i,j} = +\\infty$）相连的边被认为具有无限权重，并被有效地从图中排除。\n\n**3. 用于最低成本路径的 Dijkstra 算法**\n\n对于一个所有边权重 $w$ 均为非负的图 $G = (V,E,w)$，Dijkstra 算法能正确地找到从一组源顶点 $S$ 到所有其他可达顶点的具有最小累积成本的路径。\n\n该算法维护三个关键数据结构：\n- 一个累积成本栅格 $A$，其中 $A_v$ 存储从 $S$ 中任意源点到顶点 $v$ 的当前已知最短路径成本。对于所有 $s \\in S$，它被初始化为 $0$，对于所有其他顶点，则初始化为 $+\\infty$。\n- 一个前驱栅格 $P$，其中 $P_v$ 存储在从 $S$ 出发的最短路径上位于 $v$ 之前的顶点的索引。源顶点具有特殊的前驱值 $-1$。为此，我们使用一个扁平索引映射 $f(i,j) = i \\cdot n + j$。\n- 一个优先队列 `pq`，用于存储待访问的顶点，并按其累积成本进行排序。它被初始化为包含所有源顶点。\n\n算法按以下步骤进行：\n1.  如上所述初始化 $A$、$P$ 和 `pq`。\n2.  当优先队列不为空时，提取具有最小累积成本的顶点 $u$。\n3.  对于 $u$ 的每个有效邻居 $v$（由连通性 $\\mathcal{N}$ 和网格边界定义）：\n    a. 计算边权重 $w_{uv} = ((C_u + C_v)/2) \\cdot d_{uv}$。\n    b. 计算通过 $u$ 到达 $v$ 的潜在新成本：$A_u + w_{uv}$。\n    c. 如果这个新成本小于当前成本 $A_v$，则将 $A_v$ 更新为这个更低的新成本，将 $P_v$ 设置为 $u$ 的扁平索引，并将 $v$ 以其新成本添加到优先队列中。\n\n算法终止时，$A$ 包含从源点集 $S$ 到每个其他单元格的最终最低成本值，而 $P$ 则编码了最短路径树（在多个不连通组件或多个源点的情况下为森林）。\n\n**4. 路径重建与验证**\n\n给定计算出的前驱栅格 $P$ 和一个目标顶点 $t$，可以通过从 $t$ 开始并迭代地回溯到其前驱，直到到达一个源顶点（其前驱为 $-1$），来重建最低成本路径。\n\n步数是此重建路径中的边数。\n\n验证涉及两个检查，均在 $10^{-9}$ 的数值容差下进行：\n- **边加性属性**：对于重建路径上的每一对连续顶点 $(u, v)$，其中 $u$ 是 $v$ 的前驱，我们必须验证成本是一致的：$A_v = A_u + w_{uv}$。\n- **总路径成本**：沿整个重建路径的所有边权重 $w_{uv}$ 之和必须等于目标点的最终累积成本 $A_t$。\n\n如果这两个属性对整个路径都成立，则认为该实现是有效的。",
            "answer": "```python\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and orchestrate the solution process.\n    \"\"\"\n\n    def run_least_cost_path(cost_raster, connectivity, sources, target):\n        \"\"\"\n        Computes the least-cost path, reconstructs it, and verifies its properties.\n\n        Args:\n            cost_raster (np.ndarray): The m x n raster of cost values.\n            connectivity (int): The neighborhood connectivity (4 or 8).\n            sources (list of tuples): A list of (row, col) source coordinates.\n            target (tuple): The (row, col) coordinate of the target cell.\n\n        Returns:\n            tuple: A tuple containing:\n                - float: Accumulated cost at the target, rounded.\n                - int: Number of steps in the reconstructed path.\n                - bool: True if the path properties are valid, False otherwise.\n        \"\"\"\n        m, n = cost_raster.shape\n        \n        # Initialize accumulated cost raster A and predecessor raster P\n        costs = np.full((m, n), np.inf, dtype=np.float64)\n        predecessors = np.full((m, n), -1, dtype=np.intp)\n        \n        # Priority queue stores (cost, row, col)\n        pq = []\n\n        for r_s, c_s in sources:\n            if 0 = r_s  m and 0 = c_s  n:\n                costs[r_s, c_s] = 0.0\n                heapq.heappush(pq, (0.0, r_s, c_s))\n\n        # Define neighbor movements and distances\n        if connectivity == 4:\n            neighbors_def = [\n                (0, 1, 1.0), (0, -1, 1.0), (1, 0, 1.0), (-1, 0, 1.0)\n            ]\n        elif connectivity == 8:\n            sqrt2 = np.sqrt(2)\n            neighbors_def = [\n                (0, 1, 1.0), (0, -1, 1.0), (1, 0, 1.0), (-1, 0, 1.0),\n                (1, 1, sqrt2), (1, -1, sqrt2), (-1, 1, sqrt2), (-1, -1, sqrt2)\n            ]\n        else:\n            raise ValueError(\"Connectivity must be 4 or 8.\")\n            \n        # Dijkstra's algorithm\n        while pq:\n            cost, r, c = heapq.heappop(pq)\n            \n            # Skip stale entries\n            if cost > costs[r, c]:\n                continue\n            \n            # Skip impassable cells\n            if np.isinf(cost_raster[r,c]):\n                continue\n\n            for dr, dc, dist in neighbors_def:\n                nr, nc = r + dr, c + dc\n                \n                if 0 = nr  m and 0 = nc  n:\n                    # Skip neighbors that are impassable\n                    if np.isinf(cost_raster[nr, nc]):\n                        continue\n\n                    # Calculate edge weight using trapezoidal rule\n                    edge_weight = (cost_raster[r, c] + cost_raster[nr, nc]) / 2.0 * dist\n                    new_cost = costs[r, c] + edge_weight\n                    \n                    if new_cost  costs[nr, nc]:\n                        costs[nr, nc] = new_cost\n                        predecessors[nr, nc] = r * n + c\n                        heapq.heappush(pq, (new_cost, nr, nc))\n\n        # Path reconstruction and verification\n        target_cost = costs[target]\n        if np.isinf(target_cost):\n            return [np.inf, 0, False]\n\n        path = []\n        curr_r, curr_c = target\n        num_steps = 0\n        \n        if predecessors[curr_r, curr_c] != -1 or (curr_r, curr_c) in sources:\n            while True:\n                path.append((curr_r, curr_c))\n                pred_flat_idx = predecessors[curr_r, curr_c]\n                if pred_flat_idx == -1:\n                    break\n                pred_r, pred_c = divmod(pred_flat_idx, n)\n                curr_r, curr_c = pred_r, pred_c\n                num_steps += 1\n        \n        path.reverse() # Path from source to target\n        \n        # Verification\n        path_is_valid = True\n        total_path_cost_sum = 0.0\n        tolerance = 1e-9\n\n        if num_steps > 0:\n            for i in range(num_steps):\n                u_r, u_c = path[i]\n                v_r, v_c = path[i+1]\n                \n                dr, dc = v_r - u_r, v_c - u_c\n                dist = np.sqrt(dr**2 + dc**2)\n                \n                edge_weight = (cost_raster[u_r, u_c] + cost_raster[v_r, v_c]) / 2.0 * dist\n                total_path_cost_sum += edge_weight\n                \n                # Check edge-additive property\n                if not np.isclose(costs[v_r, v_c], costs[u_r, u_c] + edge_weight, atol=tolerance):\n                    path_is_valid = False\n                    break\n            \n            # Check total path cost property\n            if path_is_valid and not np.isclose(total_path_cost_sum, target_cost, atol=tolerance):\n                path_is_valid = False\n        elif target not in sources:\n             # Target is not a source, but path has 0 steps. This is an invalid state\n             # unless the target is unreachable, which is handled earlier.\n             path_is_valid = False\n\n        return [round(target_cost, 6), num_steps, path_is_valid]\n\n\n    # Test Case 1\n    C1 = np.ones((5, 5), dtype=np.float64)\n    S1 = [(0, 0)]\n    t1 = (4, 3)\n    \n    # Test Case 2\n    C2 = np.ones((5, 5), dtype=np.float64)\n    C2[2, 1] = C2[2, 2] = C2[2, 3] = np.inf\n    S2 = [(0, 2)]\n    t2 = (4, 2)\n    \n    # Test Case 3\n    C3 = np.fromfunction(lambda i, j: 1 + 0.15 * i + 0.05 * j, (6, 6), dtype=np.float64)\n    S3 = [(0, 0), (5, 5)]\n    t3 = (5, 0)\n\n    # Test Case 4\n    C4 = np.ones((4, 4), dtype=np.float64)\n    S4 = [(0, 3), (3, 0)]\n    t4 = (3, 3)\n\n    test_cases = [\n        (C1, 8, S1, t1),\n        (C2, 4, S2, t2),\n        (C3, 8, S3, t3),\n        (C4, 8, S4, t4),\n    ]\n    \n    results = []\n    for C, N_conn, S, t in test_cases:\n        result = run_least_cost_path(C, N_conn, S, t)\n        results.append(result)\n\n    # Convert boolean to string 'True' or 'False' for final printing\n    formatted_results = [f\"[{res[0]}, {res[1]}, {str(res[2])}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}