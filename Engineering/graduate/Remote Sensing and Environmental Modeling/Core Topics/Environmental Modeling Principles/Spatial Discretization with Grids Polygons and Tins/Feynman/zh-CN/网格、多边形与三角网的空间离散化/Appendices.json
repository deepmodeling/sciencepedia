{
    "hands_on_practices": [
        {
            "introduction": "虽然简单网格是基础，但对于大规模数据的查询而言效率低下。本实践介绍四叉树，这是一种分层结构，可通过递归划分空间来显著加快空间搜索和聚合的速度。通过从头开始构建四叉树并实现关键的查询算法，您将在优化环境模型中的栅格数据处理方面获得核心技术的实践经验。",
            "id": "3850584",
            "problem": "给定一个在矩形网格上表示的离散栅格场，要求您构建一个分层四叉树索引方案，用于空间范围查询和多分辨率聚合。目标是精确定义该层级结构，实现相应的数据结构，并从空间离散化和分层分区的基本原理出发，计算经验和理论推导的操作计数，以表征关键操作的复杂度。\n\n从以下核心定义和观察出发：\n- 栅格网格是对一个空间连续场进行采样，形成一个有限的矩形像素集合。设栅格大小为 $N_x \\times N_y$，其整数坐标 $(x,y)$ 满足 $x \\in \\{0,1,\\dots,N_x-1\\}$ 且 $y \\in \\{0,1,\\dots,N_y-1\\}$。\n- 栅格的四叉树是通过在每一层将一个正方形域递归地划分为四个相等的象限来构建的，从而生成一个由轴对齐的正方形单元格组成的树。为了适应任意矩形尺寸，栅格域被嵌入一个边长为 $N_p$ 的正方形中，其中 $N_p$ 是满足 $N_p \\ge \\max(N_x, N_y)$ 的最小二次幂；所有在原始栅格之外的填充单元格都被设置为零。四叉树的高度为 $h = \\log_2(N_p)$。\n- 每个四叉树节点对应一个具有轴对齐边界框 $[x_0,x_1) \\times [y_0,y_1)$ 的正方形单元格，并存储其区域内栅格值的聚合（例如，和）。\n- 对轴对齐矩形 $R = [X_0,X_1) \\times [Y_0,Y_1)$ 的范围查询返回 $R$ 与栅格域交集上所有栅格值的总和。在 $\\ell$ 级别的多分辨率聚合使用不重叠的 $2^\\ell \\times 2^\\ell$ 块来计算所有完全包含在原始栅格内的块的块均值。\n\n基于原理的推导要求：\n- 仅使用上述基本定义和以下经过充分检验的事实：区间和矩形的二进分解，以及对二次幂尺寸使用对数性质。未经推导，不得引入任何快捷公式。\n- 证明任何一维区间最多可以被 $2h+2$ 个与四叉树层级对齐的不相交二进区间覆盖，并利用笛卡尔积推导出二维矩形的界限。\n- 对于多分辨率聚合，从大小为 $2^\\ell \\times 2^\\ell$ 的块的定义和四叉树结构出发进行推理，以建立关于 $N_x$、$N_y$、$h$ 和 $\\ell$ 的操作计数。\n\n实现要求：\n- 在填充后的 $N_p \\times N_p$ 网格上构建一个四叉树，在每个节点中存储总和。\n- 实现一个函数，使用四叉树回答矩形范围和查询，通过递归剪枝完全位于查询矩形内部或外部的节点，并仅在部分重叠时向下递归。计算查询期间访问的四叉树节点数量。\n- 通过基于四叉树的范围查询，计算原始 $N_x \\times N_y$ 栅格内完全包含的每个不重叠的 $2^\\ell \\times 2^\\ell$ 块的均值，从而实现在 $\\ell$ 级别的多分辨率聚合，并记录所有块查询中访问的四叉树节点总数。\n- 使用莫顿码 (Z序) 为叶节点构建一个四叉树索引方案，该莫顿码通过交错 $x$ 和 $y$ 直至 $h$ 位的二进制表示而生成，为每个叶节点产生一个非负整数索引。在每个测试用例中，计算指定单元格的莫顿码。\n\n复杂度推导目标：\n- 使用对 $R$ 的二进分解论证，推导矩形范围查询访问的四叉树节点数的上界，以 $h$ 的函数表示。在程序的输出中，以 $h$ 的显式整数函数形式提供该界限，不使用渐近符号。\n- 通过将完全位于栅格内的块数 $B_x = \\left\\lfloor \\frac{N_x}{2^\\ell} \\right\\rfloor$ 和 $B_y = \\left\\lfloor \\frac{N_y}{2^\\ell} \\right\\rfloor$ 与前一项中的单次查询界限相乘，推导在 $\\ell$ 级别多分辨率聚合中访问的节点总数的上界。\n\n测试套件：\n您的程序必须为以下三个测试用例实现上述功能，并精确计算所要求的输出。所有坐标均为整数像素索引，所有结果均为无量纲数。\n\n- 测试用例 1 (一般情况):\n  - 栅格大小: $N_x = 8$, $N_y = 8$.\n  - 栅格值: $v(x,y) = x + y$.\n  - 范围查询矩形 $R$: $[X_0,X_1) \\times [Y_0,Y_1) = [2,6) \\times [1,7)$.\n  - 多分辨率级别: $\\ell = 2$.\n  - 莫顿码单元格: $(x,y) = (3,5)$.\n\n- 测试用例 2 (边界情况：整个栅格):\n  - 栅格大小: $N_x = 16$, $N_y = 16$.\n  - 栅格值: $v(x,y) = 2y + 3x + 1$.\n  - 范围查询矩形 $R$: $[0,16) \\times [0,16)$.\n  - 多分辨率级别: $\\ell = 4$.\n  - 莫顿码单元格: $(x,y) = (15,15)$.\n\n- 测试用例 3 (边缘情况：非二次幂尺寸，单单元格查询):\n  - 栅格大小: $N_x = 10$, $N_y = 6$.\n  - 栅格值: $v(x,y) = x - y$.\n  - 范围查询矩形 $R$: $[3,4) \\times [3,4)$.\n  - 多分辨率级别: $\\ell = 1$.\n  - 莫顿码单元格: $(x,y) = (9,5)$.\n\n对于每个测试用例，您的程序必须按顺序计算并输出以下七个量：\n1. 在 $R$ 上的范围查询和，为整数。\n2. 范围查询期间访问的四叉树节点数，为整数，当每个节点被测试其与 $R$ 的关系时，该节点被精确计数一次。\n3. 范围查询访问节点的理论上界，表示为 $(2h+2)^2$ 并计算为整数。\n4. 在 $\\ell$ 级别的多分辨率聚合块均值的算术平均值，为浮点数，在所有完全位于原始栅格内的块上计算。\n5. 多分辨率聚合的所有块查询中访问的四叉树节点总数，为整数。\n6. 所有块查询访问的节点总数的理论上界，计算公式为 $B_x \\cdot B_y \\cdot (2h+2)^2$，并计算为整数。\n7. 指定单元格 $(x,y)$ 在填充域中的莫顿码 (Z序索引)，为整数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含所有测试用例的结果，连接成一个扁平的数字列表。具体来说，输出必须是单行，包含一个用方括号括起来的逗号分隔列表，长度为 $21$（每个测试用例七个数字，共三个测试用例），并严格按照上述顺序排列测试用例 $1$、$2$ 和 $3$ 的结果。例如：“[$r_{1,1},r_{1,2},\\dots,r_{1,7},r_{2,1},\\dots,r_{2,7},r_{3,1},\\dots,r_{3,7}$]”。",
            "solution": "该问题要求为离散栅格场制定并实现一个基于四叉树的空间索引方案。这包括四叉树的构建，范围查询和多分辨率聚合算法的实现，以及对这些操作的理论和经验复杂度度量的推导与计算。该解决方案是从空间分区的基本原理发展而来的。\n\n**1. 四叉树数据结构与构建**\n\n四叉树是一种分层数据结构，通过递归地将二维空间细分为四个相等的象限来对其进行分区。对于一个给定大小为 $N_x \\times N_y$ 的栅格，我们首先将其嵌入一个更大的正方形域中，以确保递归分区在所有层级上都有良好定义。\n\n- **填充**：栅格域被嵌入到一个边长为 $N_p$ 的正方形网格中，其中 $N_p$ 是满足 $N_p \\ge \\max(N_x, N_y)$ 的最小二次幂。在填充区域中的单元格，即 $x \\ge N_x$ 或 $y \\ge N_y$ 的地方，被赋值为 $0$。\n- **层级结构**：四叉树的高度 $h$ 由填充后的网格大小决定，即 $h = \\log_2(N_p)$。树的根节点对应于级别 $0$ 的整个 $N_p \\times N_p$ 域。级别为 $k$ (其中 $k \\in \\{0, 1, \\dots, h\\}$) 的节点表示一个边长为 $s_k = N_p / 2^k$ 的正方形单元格。树的叶节点位于级别 $h$，对应于单个的 $1 \\times 1$ 单元格。\n- **节点结构**：四叉树中的每个节点代表一个特定的空间范围，由其轴对齐边界框 $[x_0, x_1) \\times [y_0, y_1)$ 定义。它存储一个聚合值，在本问题中是其边界框内所有栅格值的总和。一个非叶节点有四个子节点，分别对应其西北 (NW)、东北 (NE)、西南 (SW) 和东南 (SE) 四个象限。\n\n四叉树是递归构建的。`build` 过程从覆盖整个 $N_p \\times N_p$ 网格的根节点开始。对于任何给定节点：1. 如果节点的级别是 $h$（叶节点），其和就是它所覆盖的单个栅格单元的值。2. 如果节点的级别小于 $h$，它是一个内部节点。它被细分为四个子节点。对每个子节点递归调用 `build` 过程。然后，父节点中存储的和被计算为其四个子节点和的总和。这种自下而上的聚合确保每个节点都正确存储其对应空间区域的值的总和。\n\n**2. 范围和查询算法与复杂度分析**\n\n范围查询旨在计算指定查询矩形 $R = [X_0, X_1) \\times [Y_0, Y_1)$ 内的栅格值之和。四叉树可以实现高效搜索，避免遍历每个单元格。查询算法从根节点开始递归操作：\n\n对于给定的节点 `n` 和查询矩形 `R`：1. 访问的节点数增加。2. 确定节点边界框 `n.bbox` 和 `R` 之间的空间关系。a. **不相交**：如果 `n.bbox` 和 `R` 不相交，则以 `n` 为根的子树对总和没有贡献。该分支的递归终止，返回 $0$。b. **完全包含**：如果 `n.bbox` 完全包含在 `R` 内，则返回存储在 `n` 中的预计算总和。该分支的递归终止，因为不需要进一步细分。c. **部分重叠**：如果 `n.bbox` 与 `R` 部分重叠，则将查询递归地应用于 `n` 的四个子节点中的每一个。将四个递归调用的结果相加并返回。对于部分重叠的叶节点，返回其值（因为它包含在原始栅格域内）。\n\n该算法的效率源于其能够剪除那些完全位于查询区域内部或外部的大部分树节点。\n\n**复杂度推导：** 范围查询期间访问的节点数取决于查询矩形的大小和位置。可以通过考虑将查询矩形分解为与四叉树节点对应的二进块来推导理论上界。\n\n问题要求将推导基于这样一个事实：在大小为 $2^h$ 的网格上，任何一维区间 $[X_0, X_1)$ 最多可以被 $2h+2$ 个不相交的二进区间所覆盖。级别为 $k$ 的二进区间的形式为 $[j \\cdot 2^{h-k}, (j+1) \\cdot 2^{h-k})$。查询算法有效地找到一组最大的四叉树节点，这些节点的单元格包含在查询矩形内，并且它们的并集覆盖了查询区域内部的大部分。被访问的节点是这些最大的被包含节点，以及那些与查询边界部分重叠的节点。\n\n访问的节点数主要由位于查询区域“边缘”的节点决定。根据问题指定的论证，我们将一维区间 $[X_0, X_1)$ 分解为一组 $N_{decomp,x} \\le 2h+2$ 个二进区间。类似地，一维区间 $[Y_0, Y_1)$ 被分解为 $N_{decomp,y} \\le 2h+2$ 个二进区间。二维查询矩形 $R$ 可以表示为这些一维二进区间的笛卡尔积的并集。每个由此产生的二进矩形都对应于四叉树中的一个节点。此类二进矩形的总数提供了一个必须识别的最大被包含节点数的上界。\n\n因此，访问的节点数 $N_{visited}$ 受每个维度界限的乘积所限制：\n$$N_{visited} \\le N_{decomp,x} \\cdot N_{decomp,y} \\le (2h+2)(2h+2) = (2h+2)^2$$\n这个界限与查询矩形的大小无关，仅取决于树的高度 $h$。\n\n**3. 多分辨率聚合算法与复杂度**\n\n多分辨率聚合涉及在不同空间尺度上汇总栅格数据。在给定的级别 $\\ell$，栅格被划分为一个由大小为 $2^\\ell \\times 2^\\ell$ 的不重叠块组成的网格。对于每个完全包含在原始栅格域 ($N_x \\times N_y$) 内的块，我们计算其均值。\n\n该算法按以下步骤进行：1. 确定沿每个维度的完整块数：$B_x = \\lfloor N_x / 2^\\ell \\rfloor$ 和 $B_y = \\lfloor N_y / 2^\\ell \\rfloor$。2. 遍历每个块索引 $(i, j)$，其中 $i \\in \\{0, \\dots, B_x-1\\}$ 且 $j \\in \\{0, \\dots, B_y-1\\}$。3. 对于每个块，定义其对应的查询矩形 $R_{i,j} = [i \\cdot 2^\\ell, (i+1) \\cdot 2^\\ell) \\times [j \\cdot 2^\\ell, (j+1) \\cdot 2^\\ell)$。4. 使用 $R_{i,j}$ 在四叉树上执行范围和查询以获取块总和。5. 通过将总和除以块面积 $(2^\\ell)^2$ 来计算块均值。6. 最终输出是所有计算出的块均值的算术平均值。在此过程中，会维护一个在所有块查询中访问过的所有四叉树节点的运行总数。\n\n**复杂度推导：** 整个聚合过程访问的节点总数是每个单独块查询访问的节点数之和。我们可以通过将总块数乘以先前推导的单次查询上界来找到一个上界。\n\n- 总块数：$N_{blocks} = B_x \\cdot B_y = \\left\\lfloor \\frac{N_x}{2^\\ell} \\right\\rfloor \\cdot \\left\\lfloor \\frac{N_y}{2^\\ell} \\right\\rfloor$。\n- 单次查询节点访问界限：$(2h+2)^2$。\n\n因此，多分辨率聚合访问的节点总数的理论上界为：\n$$N_{visited, agg} \\le N_{blocks} \\cdot (2h+2)^2 = \\left\\lfloor \\frac{N_x}{2^\\ell} \\right\\rfloor \\cdot \\left\\lfloor \\frac{N_y}{2^\\ell} \\right\\rfloor \\cdot (2h+2)^2$$\n\n**4. 莫顿码 (Z序) 索引**\n\n莫顿码，或称Z序索引，提供了一种从二维坐标到一维索引的映射，该映射能保持空间局部性。它通过交错坐标值的比特位来生成。对于 $N_p \\times N_p$ 网格（其中 $N_p=2^h$）中坐标为 $(x,y)$ 的单元格，使用 $x$ 和 $y$ 的 $h$ 位二进制表示。\n- 设 $x = (x_{h-1}x_{h-2}\\dots x_0)_2$ 和 $y = (y_{h-1}y_{h-2}\\dots y_0)_2$。\n- 莫顿码 $Z(x,y)$ 是一个通过交错这些比特位形成的 $2h$ 位整数，通常从 $y$ 的最高有效位开始：\n$$Z(x,y) = (y_{h-1}x_{h-1}y_{h-2}x_{h-2}\\dots y_0x_0)_2$$\n这种索引方案将二维空间中相近的坐标放置在一维Z序曲线上的邻近位置，这对于线性化四叉树叶节点以实现高效存储和访问非常有用。",
            "answer": "```python\nimport numpy as np\n\ndef morton_code(x, y, h):\n    \"\"\"\n    Computes the Morton code (Z-order index) for a 2D coordinate.\n    \"\"\"\n    m_code = 0\n    for i in range(h):\n        x_bit = (x >> i) & 1\n        y_bit = (y >> i) & 1\n        m_code |= (x_bit << (2 * i))\n        m_code |= (y_bit << (2 * i + 1))\n    return m_code\n\nclass Node:\n    \"\"\"Represents a node in the Quadtree.\"\"\"\n    def __init__(self, bbox, level):\n        self.bbox = bbox  # (x0, x1, y0, y1)\n        self.level = level\n        self.sum = 0\n        self.children = None  # List of 4 children [NW, NE, SW, SE]\n\nclass QuadTree:\n    \"\"\"Represents a Quadtree for a raster grid.\"\"\"\n    def __init__(self, grid, h):\n        self.grid = grid\n        self.h = h\n        self.Np = 2**h\n        self.root = Node(bbox=(0, self.Np, 0, self.Np), level=0)\n        self._build_recursive(self.root)\n\n    def _build_recursive(self, node):\n        \"\"\"Recursively builds the quadtree.\"\"\"\n        x0, x1, y0, y1 = node.bbox\n        \n        if node.level == self.h: # Leaf node\n            if x0 < self.grid.shape[1] and y0 < self.grid.shape[0]:\n                node.sum = self.grid[y0, x0]\n            else: # Pad area\n                node.sum = 0\n            return\n\n        # Internal node\n        node.children = []\n        \n        # Subdivide into 4 quadrants\n        mx, my = x0 + (x1 - x0) // 2, y0 + (y1 - y0) // 2\n        \n        # Children order: NW, NE, SW, SE\n        child_bboxes = [\n            (x0, mx, y0, my),    # NW\n            (mx, x1, y0, my),    # NE\n            (x0, mx, my, y1),    # SW\n            (mx, x1, my, y1),    # SE\n        ]\n        \n        child_sum = 0\n        for i, bbox in enumerate(child_bboxes):\n            child_node = Node(bbox=bbox, level=node.level + 1)\n            self._build_recursive(child_node)\n            node.children.append(child_node)\n            child_sum += child_node.sum\n        \n        node.sum = child_sum\n\n    def query(self, query_rect):\n        \"\"\"Public method to start a range query.\"\"\"\n        counter = {'count': 0}\n        total_sum = self._query_recursive(self.root, query_rect, counter)\n        return total_sum, counter['count']\n\n    def _query_recursive(self, node, query_rect, counter):\n        \"\"\"Recursive helper for range query.\"\"\"\n        counter['count'] += 1\n        \n        x0, x1, y0, y1 = node.bbox\n        X0, X1, Y0, Y1 = query_rect\n        \n        # 1. No intersection\n        if x1 <= X0 or x0 >= X1 or y1 <= Y0 or y0 >= Y1:\n            return 0\n            \n        # 2. Fully contained\n        if x0 >= X0 and x1 <= X1 and y0 >= Y0 and y1 <= Y1:\n            return node.sum\n\n        # 3. Handle leaf node partial overlap\n        if node.level == self.h:\n            return node.sum\n        \n        # 4. Partial overlap on internal node\n        if node.children:\n            current_sum = 0\n            for child in node.children:\n                current_sum += self._query_recursive(child, query_rect, counter)\n            return current_sum\n            \n        return 0\n\ndef solve():\n    test_cases = [\n        {\n            \"Nx\": 8, \"Ny\": 8, \"v_func\": lambda x, y: x + y,\n            \"query_rect\": (2, 6, 1, 7), \"l\": 2, \"morton_cell\": (3, 5)\n        },\n        {\n            \"Nx\": 16, \"Ny\": 16, \"v_func\": lambda x, y: 2*y + 3*x + 1,\n            \"query_rect\": (0, 16, 0, 16), \"l\": 4, \"morton_cell\": (15, 15)\n        },\n        {\n            \"Nx\": 10, \"Ny\": 6, \"v_func\": lambda x, y: x - y,\n            \"query_rect\": (3, 4, 3, 4), \"l\": 1, \"morton_cell\": (9, 5)\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        Nx, Ny = case[\"Nx\"], case[\"Ny\"]\n        v_func = case[\"v_func\"]\n        query_rect = case[\"query_rect\"]\n        l = case[\"l\"]\n        mc_x, mc_y = case[\"morton_cell\"]\n\n        # 1. Setup grid and quadtree parameters\n        Np = 1\n        while Np < max(Nx, Ny):\n            Np *= 2\n        h = int(np.log2(Np))\n\n        # Create padded grid\n        padded_grid = np.zeros((Np, Np), dtype=int)\n        for y in range(Ny):\n            for x in range(Nx):\n                padded_grid[y, x] = v_func(x, y)\n\n        # Build Quadtree\n        q_tree = QuadTree(padded_grid, h)\n        \n        # Item 1 & 2: Range query sum and visited nodes\n        query_sum, query_nodes_visited = q_tree.query(query_rect)\n        results.append(int(query_sum))\n        results.append(int(query_nodes_visited))\n\n        # Item 3: Theoretical bound on query nodes\n        query_bound = (2 * h + 2)**2\n        results.append(int(query_bound))\n        \n        # Item 4 & 5: Multiresolution aggregation\n        block_size = 2**l\n        Bx = Nx // block_size\n        By = Ny // block_size\n        \n        total_agg_nodes = 0\n        block_means = []\n        if Bx > 0 and By > 0:\n            for i in range(Bx):\n                for j in range(By):\n                    block_rect = (i * block_size, (i + 1) * block_size, \n                                  j * block_size, (j + 1) * block_size)\n                    block_sum, nodes_visited = q_tree.query(block_rect)\n                    total_agg_nodes += nodes_visited\n                    block_means.append(block_sum / (block_size**2))\n        \n        avg_of_means = sum(block_means) / len(block_means) if block_means else 0.0\n        results.append(float(avg_of_means))\n        results.append(int(total_agg_nodes))\n        \n        # Item 6: Theoretical bound on aggregation nodes\n        agg_bound = Bx * By * query_bound\n        results.append(int(agg_bound))\n        \n        # Item 7: Morton code\n        mc = morton_code(mc_x, mc_y, h)\n        results.append(int(mc))\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "多边形叠加是地理信息系统中的一项基本操作，但由于数据源之间存在微小的不对齐，常常会产生狭长的“碎片多边形”。这些伪影会扭曲面积计算和拓扑关系，从而影响分析的准确性。本练习要求您实现一个稳健的算法，以自动识别并消除这些伪影，同时保持地图的拓扑一致性，这是处理矢量数据集的关键技能。",
            "id": "3850619",
            "problem": "两个多边形图层之间的平面叠加操作会产生一个线排列，该线排列将平面划分为多个面，这些面的边界由输入多边形的线段组成。在遥感和环境建模中，当将土地覆盖多边形与行政单位相结合时，此类叠加操作很常见。由网格、多边形和不规则三角网（TINs）离散化的图层之间的配准误差通常会产生称为“狭长多边形”（sliver polygons）的窄条伪影。这些伪影的来源可以通过计算几何学的核心定义来理解：当两条长度为 $\\,\\ell\\,$ 的近重合边因一个微小的横向位移 $\\,\\delta\\,$（例如，以 $\\,\\mathrm{m}\\,$ 为单位的地理配准误差）而错开时，叠加操作会引入一个面积约为 $\\,A \\approx \\delta \\,\\ell\\,$ 的面，该面由近乎平行的线段界定。此类面的几何形状通常是高度各向异性的，即一个维度远小于另一个维度。\n\n从多边形面积和周长的基本定义以及平面图的拓扑学出发，推导一个方案，该方案使用阈值来识别和消除狭长多边形，同时保持拓扑一致性。使用不依赖于特定坐标系的形状度量，例如最小宽度 $\\,w_{\\min}\\,$、最大宽度 $\\,w_{\\max}\\,$、面积 $\\,A\\,$ 和各向异性比率 $\\,r = \\dfrac{w_{\\min}}{w_{\\max}}\\,$. 阈值判断谓词必须被设计为仅选择各向异性的面作为狭长多边形，并且消除操作必须将每个选定的面合并到共享其长边的唯一一个相邻邻居中，以使平面分区的欧拉特征数 $\\,\\chi = V - E + F\\,$ 保持不变。假设多边形是轴对齐的，因此叠加产生的面是矩形，并且邻接关系通过共享边（四邻域）来定义。所有长度单位均为 $\\,\\mathrm{m}\\,$，面积单位均为 $\\,\\mathrm{m}^2\\,$。\n\n您的程序必须以纯数学术语实现以下算法任务：\n- 从两个输入图层 $\\,L_1\\,$ 和 $\\,L_2\\,$ 构建叠加分区，每个图层都以一组轴对齐的矩形 $\\,[x_{\\min},y_{\\min},x_{\\max},y_{\\max}]\\,$（单位为 $\\,\\mathrm{m}\\,$）的形式给出。通过计算两个图层中所有矩形边的已排序唯一 $\\,x\\,$ 和 $\\,y\\,$ 坐标来完成此操作，然后枚举由连续的 $\\,x\\,$ 和 $\\,y\\,$ 区间形成的每个单元格。如果一个单元格与 $\\,L_1\\,$ 或 $\\,L_2\\,$ 中的至少一个矩形存在正面积相交，则该单元格属于叠加并集。\n- 对于每个宽度为 $\\,w\\,$、高度为 $\\,h\\,$ 的叠加单元格，定义 $\\,w_{\\min} = \\min(w,h)\\,$、$\\,w_{\\max} = \\max(w,h)\\,$、$\\,r = \\dfrac{w_{\\min}}{w_{\\max}}\\,$ 和 $\\,A = w\\cdot h\\,$。一个单元格是候选狭长多边形的充要条件是 $\\,r \\le \\tau_r\\,$ 且 $\\,(A \\le \\tau_A \\,\\lor\\, w_{\\min} \\le \\tau_w)\\,$，其中 $\\,\\tau_r\\,$ 是无量纲的比率阈值，$\\,\\tau_A\\,$ 是以 $\\,\\mathrm{m}^2\\,$ 为单位的面积阈值，$\\,\\tau_w\\,$ 是以 $\\,\\mathrm{m}\\,$ 为单位的宽度阈值。\n- 通过要求候选狭长多边形沿其长边恰好与一个相邻邻居共享来强制实现拓扑一致性（即，如果 $\\,h \\ge w\\,$，则它在并集中必须有且仅有一个水平邻居；如果 $\\,w > h\\,$，则它在并集中必须有且仅有一个垂直邻居）。通过将此类狭长多边形合并到该唯一邻居中来消除它。证明在此规则下，欧拉特征数的变化量为 $\\,\\Delta \\chi = 0\\,$。\n\n对于下面的每个测试用例，计算该方案将消除多少个叠加单元格。仅报告计数，无需输出任何几何图形。程序必须生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。\n\n使用以下测试套件（坐标单位为 $\\,\\mathrm{m}\\,$，阈值单位为指定单位）：\n\n- 测试用例 $\\,1\\,$（正常情况，错位的条带）：\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0.2,0,10.2,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.5\\,\\mathrm{m}^2\\,$, $\\,\\tau_r = 0.1\\,$, $\\,\\tau_w = 0.25\\,\\mathrm{m}\\,$.\n\n- 测试用例 $\\,2\\,$（面积阈值处于边界条件）：\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0.2,0,10.2,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 1.0\\,\\mathrm{m}^2\\,$, $\\,\\tau_r = 1.0\\,$, $\\,\\tau_w = 0.05\\,\\mathrm{m}\\,$.\n\n- 测试用例 $\\,3\\,$（无错位）：\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0,0,10,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.1\\,\\mathrm{m}^2\\,$, $\\,\\tau_r = 0.1\\,$, $\\,\\tau_w = 0.1\\,\\mathrm{m}\\,$.\n\n- 测试用例 $\\,4\\,$（复杂叠加，双轴均错位且有一个应保留的内部图斑）：\n  - $\\,L_1 = \\{[0,0,10,10]\\}\\,$, $\\,L_2 = \\{[0.1,0.1,10.1,10.1],\\,[2,2,2.3,2.3]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.05\\,\\mathrm{m}^2\\,$, $\\,\\tau_r = 0.2\\,$, $\\,\\tau_w = 0.12\\,\\mathrm{m}\\,$.\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如 $\\,[a,b,c,d]\\,$），其中每个条目是相应测试用例的整数计数。",
            "solution": "该问题要求开发并实现一个方案，用于识别和消除由两个轴对齐矩形图层叠加产生的狭长多边形。消除操作必须在拓扑上保持一致，即平面分区的欧拉特征数保持不变。\n\n### 第 1 步：问题阐述与验证\n该问题是有效的。它在科学上基于计算几何学的原理及其在地理信息科学（GIS）中的应用。问题陈述清晰，提供了精确的算法、无歧义的定义和一套完整的测试数据。语言客观，约束条件可行。\n\n### 第 2 步：算法方案推导\n该过程分为三个主要任务：构建叠加层，基于形状度量识别候选狭长多边形，以及根据拓扑一致性规则消除它们。\n\n#### 2.1. 叠加分区构建\n给定两个图层 $L_1$ 和 $L_2$，每个图层都是一组轴对齐的矩形。通过使用所有矩形边界的唯一 $x$ 和 $y$ 坐标构建一个网格来构造叠加分区。设所有唯一 x 坐标的集合为 $X = \\{x_0, x_1, \\dots, x_{n_x}\\}$，所有唯一 y 坐标的集合为 $Y = \\{y_0, y_1, \\dots, y_{n_y}\\}$，两者均按序排列。这些坐标定义了一个由基本矩形单元格组成的网格。单元格 $C_{ij}$ 由区间 $[x_i, x_{i+1}]$ 和 $[y_j, y_{j+1}]$ 的笛卡尔积定义，其中 $i \\in \\{0, \\dots, n_x-1\\}$ 且 $j \\in \\{0, \\dots, n_y-1\\}$。\n\n如果一个单元格 $C_{ij}$ 与 $L_1 \\cup L_2$ 中的至少一个矩形存在正面积相交，则它被视为叠加并集的一部分。由于网格线由矩形边界本身定义，我们可以通过检查单元格的中心点 $p_{ij} = \\left(\\frac{x_i+x_{i+1}}{2}, \\frac{y_j+y_{j+1}}{2}\\right)$ 是否位于 $L_1 \\cup L_2$ 中的任何矩形 $R$ 内来测试其是否被包含。如果 $x_{\\min} \\le p_x  x_{\\max}$ 且 $y_{\\min} \\le p_y  y_{\\max}$，则点 $(p_x, p_y)$ 在矩形 $[x_{\\min}, y_{\\min}, x_{\\max}, y_{\\max}]$ 内部。\n\n#### 2.2. 狭长多边形识别谓词\n对于叠加并集中的每个单元格 $C_{ij}$，我们计算其几何属性。该单元格的宽度为 $w = x_{i+1} - x_i$，高度为 $h = y_{j+1} - y_j$。形状度量定义如下：\n-   面积：$A = w \\cdot h$\n-   最小宽度：$w_{\\min} = \\min(w, h)$\n-   最大宽度：$w_{\\max} = \\max(w, h)$\n-   各向异性比率：$r = \\frac{w_{\\min}}{w_{\\max}}$（如果 $w_{\\max} > 0$；否则 $r=1$）\n\n如果一个单元格是高度各向异性的，并且面积小或非常薄，则它被识别为**候选狭长多边形**。该谓词正式表述为：\n$$ (\\text{is_candidate}) \\iff (r \\le \\tau_r) \\land (A \\le \\tau_A \\lor w_{\\min} \\le \\tau_w) $$\n其中 $\\tau_r$、$\\tau_A$ 和 $\\tau_w$ 分别是用户定义的各向异性比率、面积和最小宽度的阈值。\n\n#### 2.3. 拓扑一致性与消除\n只有当候选狭长多边形满足严格的拓扑标准时，才能将其消除，以防止地图拓扑的碎片化。规则是，该狭长多边形必须沿其最长维度被“夹”在一个较大的多边形和一个空白区域（或另一个不与之合并的多边形）之间。\n\n设候选狭长多边形为单元格 $C_{ij}$。\n-   如果单元格是垂直拉长的（$h \\ge w$，因此其长边是垂直的），我们检查其水平邻居 $C_{i-1,j}$ 和 $C_{i+1,j}$。当且仅当这两个邻居中**恰好有一个**也位于叠加并集中时，该单元格才被消除。\n-   如果单元格是水平拉长的（$w > h$，因此其长边是水平的），我们检查其垂直邻居 $C_{i,j-1}$ 和 $C_{i,j+1}$。当且仅当这两个邻居中**恰好有一个**也位于叠加并集中时，该单元格才被消除。\n\n此规则确保狭长多边形有一个唯一的、无歧义的合并伙伴。该操作包括消溶狭长多边形与其唯一长边邻居之间的边界。\n\n#### 2.4. 欧拉特征数的不变性\n平面图的欧拉特征数由 $\\chi = V - E + F$ 给出，其中 $V$、$E$ 和 $F$ 分别是顶点、边和面的数量。我们必须证明，消除狭长多边形的过程使 $\\chi$ 保持不变，即 $\\Delta \\chi = 0$。\n\n通过将一个狭长面 $f_s$ 合并到其相邻的面 $f_n$ 中来消除它，在拓扑上等同于**边收缩**操作。共享的边界边（例如 $e_{sn}$）被收缩。在平面图嵌入中，收缩作为面边界一部分的边会产生以下影响：\n1.  两个面 $f_s$ 和 $f_n$ 合并成一个面。这使面数减少一：$\\Delta F = -1$。\n2.  边 $e_{sn}$ 本身被移除。这使边数减少一：$\\Delta E_{edge} = -1$。\n3.  边 $e_{sn}$ 的两个顶点塌缩成一个顶点。这使顶点数减少一：$\\Delta V = -1$。\n4.  如果收缩导致同一对顶点之间出现多条边，它们将被合并。特定的规则（“沿其长边恰好与一个相邻邻居共享”）确保了一种简单的拓扑，其中这并非主要影响，但我们必须考虑塌缩顶点的关联边会发生什么。看待这个问题的最稳健方法是通过边收缩的一般属性。\n\n拓扑图论中的一个基本定理指出，如果嵌入在曲面 $S$ 上的图 $G$ 的一条边 $e$ 被收缩，则新图 $G/e$ 在 $S$ 中存在一个嵌入，并且它们的欧拉特征数是相关的。对于平面图，收缩一条边不会改变曲面的亏格（对于平面是0），并且欧拉特征数得以保留。\n\n让我们通过分步的元素计数来分析这一点。设要移除的边为 $e$。\n- 面的数量减少 1：$\\Delta F = -1$。\n- 边 $e$ 被移除，使边数减少 1：$\\Delta E = -1$。\n- 边 $e$ 的两个顶点也是其他边的一部分。拓扑规则保证它们不是整个地图的边界顶点。当 $e$ 被移除时，这些顶点仍然存在，但它们的连通性发生了变化。如果没有顶点被移除，则 $\\Delta V = 0$。\n从这个角度看，欧拉特征数的变化为 $\\Delta \\chi = \\Delta V - \\Delta E + \\Delta F = 0 - (-1) + (-1) = 0$。\n\n一个更严谨的观点承认，合并操作可能会产生度为 2 的顶点，这些顶点通常随后会被移除以保持拓扑的整洁。如果一个度为 2 的顶点 $v$ 被移除，其两条关联边会合并为一条。这意味着移除一个顶点（$\\Delta V = -1$）也会移除一条边（$\\Delta E = -1$）。由于 $\\Delta V - \\Delta E = (-1) - (-1) = 0$，移除任意数量的度为 2 的顶点都不会改变欧拉特征数。\n\n因此，无论是看作简单的边移除，还是带有清理步骤的完全边收缩，合并操作都保留了欧拉特征数 $\\chi$，从而确保了拓扑一致性。\n\n### 第 3 步：实现与测试用例执行\n上述算法使用 Python 实现，并利用 NumPy 库进行高效的网格管理。代码遍历每个测试用例，构建叠加网格，识别候选狭长多边形，应用拓扑检查，并统计最终被消除的单元格数量。\n\n-   **测试用例 1**：$L_1 = \\{[0,0,10,5]\\}$, $L_2 = \\{[0.2,0,10.2,5]\\}$。阈值：$\\tau_A = 0.5$, $\\tau_r = 0.1$, $\\tau_w = 0.25$。这会产生两个垂直的狭长多边形：`[0, 0.2] x [0, 5]` 和 `[10, 10.2] x [0, 5]`。对于两者，$w=0.2, h=5$，因此 $w_{\\min}=0.2, r=0.04, A=1.0$。谓词 $(r \\le 0.1) \\land (A \\le 0.5 \\lor w_{\\min} \\le 0.25)$ 为真，因为 $0.04 \\le 0.1$ 且 $0.2 \\le 0.25$。两者在其长边（垂直）上都只有一个邻居。两者都被消除。计数：$2$。\n\n-   **测试用例 2**：与案例 1 几何形状相同。阈值：$\\tau_A = 1.0$, $\\tau_r = 1.0$, $\\tau_w = 0.05$。对于狭长多边形，$A=1.0, w_{\\min}=0.2, r=0.04$。谓词 $(r \\le 1.0) \\land (A \\le 1.0 \\lor w_{\\min} \\le 0.05)$ 为真，因为 $0.04 \\le 1.0$ 且 $1.0 \\le 1.0$。两者都被消除。计数：$2$。\n\n-   **测试用例 3**：$L_1 = L_2 = \\{[0,0,10,5]\\}$。没有错位，产生一个单一的叠加单元格 `[0,10] x [0,5]`。这里，$w=10, h=5, w_{\\min}=5, r=0.5$。谓词 $(r \\le 0.1)$ 为假。没有识别出狭长多边形。计数：$0$。\n\n-   **测试用例 4**：复杂叠加。来自小图斑 `[2,2,2.3,2.3]` 的坐标将较大的狭长区域细分。沿边界形成狭长多边形：`x in [0, 0.1]`、`x in [10, 10.1]`、`y in [0, 0.1]` 和 `y in [10, 10.1]`。这些狭长条带中的每一个都被中间坐标分解为 3 个单元格。对于所有这些单元格，最小尺寸为 $w_{\\min}=0.1$。条件 $w_{\\min} \\le \\tau_w$（$0.1 \\le 0.12$）得到满足，因此它们都是候选对象。每一个也都通过了拓扑检查。这导致 $4$ 个条带 $\\times$ 每个条带 $3$ 个单元格 = $12$ 个被消除的单元格。中心图斑 `[2,2,2.3,2.3]` 本身不是狭长多边形（$r=1.0$），被正确保留。计数：$12$。\n\n最终结果被收集并按要求格式化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the sliver polygon elimination problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0.2, 0, 10.2, 5]]),\n            \"thresholds\": {\"tau_A\": 0.5, \"tau_r\": 0.1, \"tau_w\": 0.25},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0.2, 0, 10.2, 5]]),\n            \"thresholds\": {\"tau_A\": 1.0, \"tau_r\": 1.0, \"tau_w\": 0.05},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0, 0, 10, 5]]),\n            \"thresholds\": {\"tau_A\": 0.1, \"tau_r\": 0.1, \"tau_w\": 0.1},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 10]]),\n            \"L2\": np.array([[0.1, 0.1, 10.1, 10.1], [2, 2, 2.3, 2.3]]),\n            \"thresholds\": {\"tau_A\": 0.05, \"tau_r\": 0.2, \"tau_w\": 0.12},\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        L1 = case[\"L1\"]\n        L2 = case[\"L2\"]\n        tau_A = case[\"thresholds\"][\"tau_A\"]\n        tau_r = case[\"thresholds\"][\"tau_r\"]\n        tau_w = case[\"thresholds\"][\"tau_w\"]\n\n        # Step 1: Construct the overlay subdivision grid\n        x_coords = set()\n        y_coords = set()\n        all_rects = np.vstack([L1, L2])\n        for rect in all_rects:\n            x_coords.add(rect[0])\n            x_coords.add(rect[2])\n            y_coords.add(rect[1])\n            y_coords.add(rect[3])\n        \n        sorted_x = sorted(list(x_coords))\n        sorted_y = sorted(list(y_coords))\n\n        map_x = {val: i for i, val in enumerate(sorted_x)}\n        map_y = {val: i for i, val in enumerate(sorted_y)}\n        \n        num_x_cells = len(sorted_x) - 1\n        num_y_cells = len(sorted_y) - 1\n\n        if num_x_cells = 0 or num_y_cells = 0:\n            results.append(0)\n            continue\n\n        is_in_union = np.zeros((num_y_cells, num_x_cells), dtype=bool)\n\n        # Determine which cells are in the union of L1 and L2\n        for j in range(num_y_cells):\n            for i in range(num_x_cells):\n                center_x = (sorted_x[i] + sorted_x[i+1]) / 2.0\n                center_y = (sorted_y[j] + sorted_y[j+1]) / 2.0\n                \n                is_covered = False\n                for rect in all_rects:\n                    if (rect[0] = center_x  rect[2]) and \\\n                       (rect[1] = center_y  rect[3]):\n                        is_covered = True\n                        break\n                if is_covered:\n                    is_in_union[j, i] = True\n\n        eliminated_count = 0\n        # Step 2  3: Identify and eliminate slivers\n        for j in range(num_y_cells):\n            for i in range(num_x_cells):\n                if not is_in_union[j, i]:\n                    continue\n\n                w = sorted_x[i+1] - sorted_x[i]\n                h = sorted_y[j+1] - sorted_y[j]\n\n                # Skip degenerate cells\n                if w == 0 or h == 0:\n                    continue\n                \n                # Calculate shape metrics\n                A = w * h\n                w_min = min(w, h)\n                w_max = max(w, h)\n                r = w_min / w_max if w_max  0 else 1.0\n\n                # Check sliver candidate predicate\n                is_candidate = (r = tau_r) and (A = tau_A or w_min = tau_w)\n\n                if not is_candidate:\n                    continue\n                \n                # Check topological consistency rule\n                is_eliminated = False\n                if h = w: # Long side is vertical or square\n                    left_neighbor_exists = (i  0) and is_in_union[j, i-1]\n                    right_neighbor_exists = (i  num_x_cells - 1) and is_in_union[j, i+1]\n                    if left_neighbor_exists != right_neighbor_exists: # XOR\n                        is_eliminated = True\n                else: # Long side is horizontal\n                    bottom_neighbor_exists = (j  0) and is_in_union[j-1, i]\n                    top_neighbor_exists = (j  num_y_cells - 1) and is_in_union[j+1, i]\n                    if bottom_neighbor_exists != top_neighbor_exists: # XOR\n                        is_eliminated = True\n                \n                if is_eliminated:\n                    eliminated_count += 1\n        \n        results.append(eliminated_count)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "对于有限元法等数值模拟，其所依赖的网格必须是“水密”的二维流形，即没有任何间隙或重叠。本实践将处理修复三角化不规则网络（TIN）的关键任务，通过检测和修复重复顶点和非流形边等常见缺陷来实现。通过实现这一修复流程，您将深入理解高质量网格的构成要素，及其为何对可靠的物理模拟至关重要。",
            "id": "3850657",
            "problem": "给定一个三角化不规则网络（Triangulated Irregular Network, TIN），定义为一个对 $(\\mathcal{V}, \\mathcal{F})$，其中 $\\mathcal{V} = \\{ \\mathbf{v}_i \\in \\mathbb{R}^3 \\mid i = 0,1,\\dots,N-1 \\}$ 是一个有限的顶点坐标集，$\\mathcal{F} = \\{ (i,j,k) \\mid i,j,k \\in \\{0,\\dots,N-1\\}, i \\neq j \\neq k \\}$ 是一个有限的三角面片集，其索引引用 $\\mathcal{V}$ 中的顶点。请开发并实现一种方法，用于检测和修复非流形边和重复顶点，以生成一个适用于有限元方法（Finite Element Method, FEM）分析的水密网格。对于嵌入三维空间中的封闭二维流形表面，水密性定义为：每条无向边都恰好与两个面片相邻，即，若 $E$ 表示由 $\\mathcal{F}$ 导出的无向边集，则对于每条边 $e \\in E$，其边-面关联计数恰好为 $2$。非流形边是任何关联计数大于 $2$ 的边，而边界边是任何关联计数为 $1$ 的边。重复顶点是指坐标在容差 $\\epsilon  0$ 内相等的顶点，重复面片是指具有相同顶点索引集（忽略方向）的面片。所期望的修复后网格 $(\\mathcal{V}', \\mathcal{F}')$ 必须没有重复顶点、没有退化面片（面积为零或具有重复索引的面片）、没有重复面片，并且必须根据边-面关联定义是水密的。\n\n从以下基础出发：\n- 网格的图论关联定义：边是从面片中提取的无序顶点索引对，边-面关联是指包含给定无向边的面片数量。\n- $\\mathbb{R}^3$ 中三角形面积的几何定义：对于具有顶点 $\\mathbf{v}_i, \\mathbf{v}_j, \\mathbf{v}_k \\in \\mathbb{R}^3$ 的三角形 $(i,j,k)$，其面积为 $\\frac{1}{2}\\|\\left(\\mathbf{v}_j - \\mathbf{v}_i\\right) \\times \\left(\\mathbf{v}_k - \\mathbf{v}_i\\right)\\|_2$。\n- 封闭曲面水密性的拓扑概念：每条无向边都恰好与两个三角面片相邻。\n\n您的程序必须对每个测试用例，按原则执行以下任务：\n1. 在指定容差 $\\epsilon$ 内识别并合并重复顶点，生成一个从原始顶点索引到新索引的映射。合并后的顶点簇的代表应在簇内一致地选择（不依赖外部数据）。\n2. 更新面片以引用合并后的顶点索引。\n3. 移除退化面片，即任何具有重复顶点索引或几何面积小于一小阈值 $\\tau$ 的面片。\n4. 通过对其顶点索引进行规范集比较来移除重复面片（在确定重复时忽略面片方向）。\n5. 计算无向边-面关联计数，并确定结果网格是否水密（每条无向边的关联计数必须恰好为 $2$）。\n\n本任务的假设：专注于非流形边计数仅由已闭合表面上的重复顶点和重复面片引起的网格，因此去重和移除退化面片足以恢复水密性。不要创造或添加新的几何体；修复必须严格按照所述的合并顶点和移除面片的方式来完成。\n\n您的程序必须为每个测试用例返回一个包含以下条目的结果列表：\n- 一个布尔值，指示修复后的水密性。\n- 一个整数，指示合并了多少顶点（原始顶点数减去修复后的顶点数）。\n- 一个整数，指示在修复过程中移除了多少面片（原始面片数减去修复后的面片数）。\n- 一个整数，指示最终的顶点数。\n- 一个整数，指示最终的面片数。\n\n最终输出必须将所有测试用例的结果聚合为单行，格式为方括号括起来的逗号分隔列表，其中每个元素是单个测试用例的结果列表。例如，输出应类似于 $[[\\text{case1\\_result}], [\\text{case2\\_result}], [\\text{case3\\_result}]]$，不含任何空格。\n\n使用以下测试套件。对于每个用例，所有坐标都是无量纲的，所有索引都是整数。使用顶点合并容差 $\\epsilon = 10^{-8}$ 和面积阈值 $\\tau = 10^{-16}$：\n- 测试用例 A（正常路径；带有重复项的闭合四面体）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1+10^{-10},0,0)]$，面片 $[(0,1,2),(0,1,3),(0,2,3),(1,2,3),(0,4,2),(1,2,3)]$。\n- 测试用例 B（边界条件；已是干净数据）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1)]$，面片 $[(0,1,2),(0,1,3),(0,2,3),(1,2,3)]$。\n- 测试用例 C（边缘情况；近乎重复的顶点和反转的面片方向）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1),(0,1,10^{-9})]$，面片 $[(0,1,4),(0,1,2),(0,2,3),(1,2,3),(2,1,3),(0,1,3)]$。\n\n您的程序应生成单行输出，其中包含用方括号括起来并以逗号分隔的结果列表，不含空格，格式应为 $[[b_1,m_1,r_1,V_1,F_1],[b_2,m_2,r_2,V_2,F_2],[b_3,m_3,r_3,V_3,F_3]]$，其中 $b_i$ 是布尔值，$m_i,r_i,V_i,F_i$ 是测试用例 $i$ 的整数。",
            "solution": "该问题陈述是计算几何和网格处理领域中一个有效的、适定的问题。它具有科学依据、客观，并包含了进行求解所需的所有必要信息。\n\n目标是实现一个程序来修复三角化不规则网络（TIN），该网络由一个顶点集 $\\mathcal{V}$ 和一个面片集 $\\mathcal{F}$ 表示，以生成一个水密的流形网格。水密网格是指每条边都恰好由两个面片共享的网格。修复过程涉及一系列规范的清理操作：合并重复顶点、重新索引面片以及移除退化和重复的面片。\n\n设初始网格为 $(\\mathcal{V}, \\mathcal{F})$，其中有 $N = |\\mathcal{V}|$ 个顶点和 $M = |\\mathcal{F}|$ 个面片。修复过程按以下步骤进行：\n\n1.  **顶点去重与合并**\n    第一步是识别并合并在给定容差 $\\epsilon  0$ 内几何上重合的顶点。如果顶点 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间的欧几里得距离小于 $\\epsilon$，则它们被视为重复顶点：\n    $$\n    \\|\\mathbf{v}_i - \\mathbf{v}_j\\|_2  \\epsilon\n    $$\n    该关系将顶点集 $\\mathcal{V}$ 划分为若干重复顶点簇。对于每个簇，选择一个单一的代表性顶点。一个用于规范地管理这些簇的稳健方法是使用并查集（Disjoint Set Union, DSU）数据结构。每个顶点索引 $i \\in \\{0, \\dots, N-1\\}$ 最初构成其自己的集合。我们遍历所有顶点对 $(i, j)$（其中 $i  j$）。如果它们对应的顶点是重复的，我们就将它们的集合合并。每个集合的代表被一致地选择，例如，作为集合中索引最小的元素。\n\n    划分后，我们构建一个新的顶点列表 $\\mathcal{V}'$，其中只包含唯一的代表性顶点。然后创建一个映射 $\\phi: \\{0, \\dots, N-1\\} \\to \\{0, \\dots, N'-1\\}$，其中 $N' = |\\mathcal{V}'|$ 是新的顶点数。$\\phi(i)$ 给出原始顶点 $i$ 在 $\\mathcal{V}'$ 中的新索引。合并的顶点数是 $N - N'$。\n\n2.  **面片索引重映射**\n    使用上一步得到的映射 $\\phi$，我们更新面片集 $\\mathcal{F}$。每个原始面片 $f = (i, j, k) \\in \\mathcal{F}$ 被转换为一个新的面片 $f_{\\text{remap}} = (\\phi(i), \\phi(j), \\phi(k))$。这会生成一个新的面片集 $\\mathcal{F}_{\\text{remap}}$。\n\n3.  **退化面片移除**\n    如果一个面片没有形成一个有效的二维三角形，它就被认为是退化的，必须被移除。这在两种情况下发生：\n    a.  **拓扑退化**：面片重映射后的顶点索引不唯一。如果一个面片 $(i', j', k')$ 满足 $i'=j'$ 或 $j'=k'$ 或 $k'=i'$，则它是退化的。这样的面片已坍缩成一条线或一个点。\n    b.  **几何退化**：面片的面积可以忽略不计。具有顶点 $(\\mathbf{v}'_{i'}, \\mathbf{v}'_{j'}, \\mathbf{v}'_{k'})$ 的三角形面积由 $A = \\frac{1}{2} \\|\\left(\\mathbf{v}'_{j'} - \\mathbf{v}'_{i'}\\right) \\times \\left(\\mathbf{v}'_{k'} - \\mathbf{v}'_{i'}\\right)\\|_2$ 给出。如果 $A  \\tau$，其中 $\\tau$ 是一个很小的面积阈值，则移除该面片。\n    所有 $\\mathcal{F}_{\\text{remap}}$ 中非退化的面片构成了集合 $\\mathcal{F}_{\\text{degen}}$。\n\n4.  **重复面片移除**\n    网格中可能包含同一面片的多个实例，可能具有不同的顶点排序（方向）。为了识别这些面片，我们为每个面片定义一个规范表示。对于一个面片 $(i', j', k')$，其规范形式是其索引的排序元组。例如，面片 $(i', j', k')$ 和 $(k', j', i')$ 在方向上不同，但表示相同的几何三角形，因此具有相同的规范形式。我们遍历 $\\mathcal{F}_{\\text{degen}}$，并使用一个集合来追踪已见过的规范形式，丢弃任何其规范形式已出现过的面片。这样就得到了最终修复后的面片集 $\\mathcal{F}'$。移除的面片总数为 $M - |\\mathcal{F}'|$。\n\n5.  **水密性验证**\n    最后一步是验证修复后的网格 $(\\mathcal{V}', \\mathcal{F}')$ 是否水密。根据问题的定义，这意味着网格中的每条无向边都必须恰好与两个面片相邻。一条无向边可以通过其顶点索引的排序对来规范地表示，例如 $(\\min(i,j), \\max(i,j))$。我们通过遍历 $\\mathcal{F}'$ 中的每个面片并提取其三条边，来构建一个所有规范边的频率图（字典或哈希图）。一个面片 $(i,j,k)$ 贡献了边 $(\\min(i,j), \\max(i,j))$、$(\\min(j,k), \\max(j,k))$ 和 $(\\min(k,i), \\max(k,i))$。计数后，我们检查频率图中的每个计数是否都恰好为 $2$。如果此条件成立，则网格是水密的。结果是一个布尔值。如果没有边（即没有面片），则该条件是空真（vacuously true）的。\n\n最后，对于每个测试用例，我们汇编所需的五个度量指标：布尔类型的水密状态、合并的顶点数（$N-N'$）、移除的面片数（$M-|\\mathcal{F}'|$）、最终顶点数（$N'$）和最终面片数（$|\\mathcal{F}'|$）。",
            "answer": "```python\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n\n    def repair_and_analyze_mesh(vertices, faces, epsilon, tau):\n        \"\"\"\n        Performs the full mesh repair and analysis pipeline for a single test case.\n\n        Args:\n            vertices (list of tuples): Original vertex coordinates.\n            faces (list of tuples): Original face vertex indices.\n            epsilon (float): Tolerance for merging vertices.\n            tau (float): Area threshold for removing degenerate faces.\n\n        Returns:\n            list: A list containing [watertight, vertices_merged, faces_removed, final_vertices, final_faces].\n        \"\"\"\n        v_orig = np.array(vertices, dtype=np.float64)\n        n_orig_vertices = v_orig.shape[0]\n        n_orig_faces = len(faces)\n\n        # Step 1: Identify and merge duplicated vertices\n        parent = list(range(n_orig_vertices))\n        def find_set(v):\n            if v == parent[v]:\n                return v\n            parent[v] = find_set(parent[v])\n            return parent[v]\n\n        def unite_sets(a, b):\n            a_root = find_set(a)\n            b_root = find_set(b)\n            if a_root != b_root:\n                # Make the smaller index the parent for consistency\n                if a_root  b_root:\n                    parent[b_root] = a_root\n                else:\n                    parent[a_root] = b_root\n        \n        if n_orig_vertices  1:\n            for i in range(n_orig_vertices):\n                for j in range(i + 1, n_orig_vertices):\n                    dist = np.linalg.norm(v_orig[i] - v_orig[j])\n                    if dist  epsilon:\n                        unite_sets(i, j)\n\n        # Create new vertex list and index mapping\n        old_to_new_map = -np.ones(n_orig_vertices, dtype=int)\n        v_new = []\n        new_idx_counter = 0\n        for i in range(n_orig_vertices):\n            root = find_set(i)\n            if old_to_new_map[root] == -1:\n                old_to_new_map[root] = new_idx_counter\n                v_new.append(v_orig[root])\n                new_idx_counter += 1\n        \n        for i in range(n_orig_vertices):\n            old_to_new_map[i] = old_to_new_map[find_set(i)]\n        \n        v_repaired = np.array(v_new, dtype=np.float64)\n        n_repaired_vertices = v_repaired.shape[0]\n        vertices_merged = n_orig_vertices - n_repaired_vertices\n\n        # Step 2: Update faces to reference merged vertex indices\n        faces_remapped = [tuple(old_to_new_map[i] for i in face) for face in faces]\n\n        # Step 3: Remove degenerate faces\n        faces_non_degenerate = []\n        for face in faces_remapped:\n            # Topological degeneracy\n            if len(set(face))  3:\n                continue\n            \n            # Geometric degeneracy\n            p1, p2, p3 = v_repaired[face[0]], v_repaired[face[1]], v_repaired[face[2]]\n            area = 0.5 * np.linalg.norm(np.cross(p2 - p1, p3 - p1))\n            if area  tau:\n                continue\n            \n            faces_non_degenerate.append(face)\n\n        # Step 4: Remove duplicated faces\n        faces_repaired = []\n        seen_canonical_faces = set()\n        for face in faces_non_degenerate:\n            canonical_face = tuple(sorted(face))\n            if canonical_face not in seen_canonical_faces:\n                seen_canonical_faces.add(canonical_face)\n                faces_repaired.append(face)\n        \n        n_repaired_faces = len(faces_repaired)\n        faces_removed = n_orig_faces - n_repaired_faces\n\n        # Step 5: Compute edge-face incidence and check for watertightness\n        edge_counts = collections.defaultdict(int)\n        for face in faces_repaired:\n            i, j, k = face\n            edges = [tuple(sorted((i, j))), tuple(sorted((j, k))), tuple(sorted((k, i)))]\n            for edge in edges:\n                edge_counts[edge] += 1\n        \n        is_watertight = True\n        if not edge_counts: # Vacuously true if no edges/faces\n            is_watertight = True\n        else:\n            for count in edge_counts.values():\n                if count != 2:\n                    is_watertight = False\n                    break\n        \n        return [is_watertight, vertices_merged, faces_removed, n_repaired_vertices, n_repaired_faces]\n\n    # Test suite from the problem statement\n    epsilon = 1e-8\n    tau = 1e-16\n\n    test_cases = [\n        # Test Case A\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1+1e-10,0,0)],\n            \"faces\": [(0,1,2),(0,1,3),(0,2,3),(1,2,3),(0,4,2),(1,2,3)]\n        },\n        # Test Case B\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1)],\n            \"faces\": [(0,1,2),(0,1,3),(0,2,3),(1,2,3)]\n        },\n        # Test Case C\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1),(0,1,1e-9)],\n            \"faces\": [(0,1,4),(0,1,2),(0,2,3),(1,2,3),(2,1,3),(0,1,3)]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = repair_and_analyze_mesh(case[\"vertices\"], case[\"faces\"], epsilon, tau)\n        results.append(result)\n\n    # Final print statement in the exact required format\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}