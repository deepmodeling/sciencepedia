{
    "hands_on_practices": [
        {
            "introduction": "The power of spectral indices often lies in combining them to isolate specific land cover types. While the Normalized Difference Built-up Index (NDBI) is effective, it can be confused by other features. This practice guides you through the construction of the Index-based Built-up Index (IBI), a composite index designed to overcome this limitation . By synthesizing proxies for built-up areas, vegetation, and water from simulated multispectral data, you will numerically verify how the IBI enhances the built-up signal while actively suppressing other land covers.",
            "id": "3800024",
            "problem": "A multispectral sensor comparable to Landsat 8–9 Operational Land Imager (OLI) records top-of-atmosphere reflectance in green, red, near-infrared, and shortwave-infrared bands, denoted by $G$, $R$, $N$, and $S$, respectively. Consider three spectrally homogeneous pixels representing vegetation, water, and built-up surfaces with the following physically plausible reflectances:\n- Vegetation: $G = 0.09$, $R = 0.04$, $N = 0.52$, $S = 0.19$.\n- Water: $G = 0.03$, $R = 0.01$, $N = 0.01$, $S = 0.005$.\n- Built-up: $G = 0.15$, $R = 0.13$, $N = 0.24$, $S = 0.31$.\n\nAdopt as a fundamental building block the normalized-difference transform of two positive-band reflectances $X$ and $Y$, defined for $X>0$, $Y>0$ by the mapping of radiance ratios to a bounded, polarity-preserving contrast:\n$$\\mathrm{ND}(X,Y) \\equiv \\frac{X - Y}{X + Y}.$$\n\nUse the following widely observed spectral ordering facts as the sole physical priors: relative to other land covers, water is dark in shortwave-infrared and relatively brighter in green; healthy vegetation is dark in red and bright in near-infrared; built-up is relatively bright in shortwave-infrared compared to near-infrared. Using only these priors and the normalized-difference transform, do all of the following:\n\n- Construct a vegetation proxy that reduces soil background via a soil-adjustment parameter $L = 0.5$ in the two-band red–near-infrared formulation.\n- Construct a water proxy using a green–shortwave-infrared normalized difference with polarity such that water yields positive values.\n- Construct a built-up proxy using a shortwave-infrared–near-infrared normalized difference with polarity such that built-up yields positive values.\n- From these three proxies, synthesize a single built-up index that linearly enhances built-up and suppresses vegetation and water by subtracting the arithmetic mean of the vegetation and water proxies from the built-up proxy. Denote this synthesized index by $\\mathrm{IBI}$.\n\nCompute $\\mathrm{IBI}$ for each of the three pixels using the reflectances above, and then quantify the suppression of vegetation and water relative to built-up by the single-number contrast\n$$C \\equiv \\mathrm{IBI}_{\\text{built}} - \\frac{\\mathrm{IBI}_{\\text{veg}} + \\mathrm{IBI}_{\\text{water}}}{2}.$$\n\nReport only the value of $C$, rounded to four significant figures. No units are required because all indices are dimensionless by construction.",
            "solution": "The problem statement has been validated and is determined to be sound. It is scientifically grounded in the principles of remote sensing, well-posed with all necessary data and clear objectives, and expressed in objective, formal language. We may therefore proceed with the solution.\n\nThe problem requires the computation of a contrast metric $C$ based on a synthesized built-up index, $\\mathrm{IBI}$. This involves several steps: constructing three proxy indices for vegetation, water, and built-up land cover; synthesizing the $\\mathrm{IBI}$ from these proxies; calculating the $\\mathrm{IBI}$ for three representative pixels; and finally, computing the contrast $C$.\n\nFirst, we define the three proxy indices based on the problem description and the provided normalized-difference transform, $\\mathrm{ND}(X,Y) \\equiv \\frac{X - Y}{X + Y}$. The sensor bands are Green ($G$), Red ($R$), Near-Infrared ($N$), and Shortwave-Infrared ($S$).\n\n1.  **Vegetation Proxy ($P_V$)**: The problem specifies a \"vegetation proxy that reduces soil background via a soil-adjustment parameter $L = 0.5$ in the two-band red–near-infrared formulation\". This is a precise description of the Soil-Adjusted Vegetation Index (SAVI). The physical prior for vegetation is its high reflectance in the near-infrared ($N$) and low reflectance in the red ($R$). The SAVI formula, which is a modification of the fundamental normalized difference concept, is given by:\n    $$P_V \\equiv \\frac{N - R}{N + R + L} (1 + L)$$\n    With the given soil-adjustment parameter $L = 0.5$, the formula becomes:\n    $$P_V = \\frac{N - R}{N + R + 0.5} (1.5)$$\n\n2.  **Water Proxy ($P_W$)**: This is defined as a \"green–shortwave-infrared normalized difference with polarity such that water yields positive values\". The physical prior for water is that it is relatively brighter in the green ($G$) band and darker in the shortwave-infrared ($S$) band, implying $G > S$. To ensure a positive value for water, the numerator must be $G-S$. Therefore, the water proxy is:\n    $$P_W \\equiv \\mathrm{ND}(G, S) = \\frac{G - S}{G + S}$$\n\n3.  **Built-up Proxy ($P_B$)**: This is defined as a \"shortwave-infrared–near-infrared normalized difference with polarity such that built-up yields positive values\". The physical prior for built-up areas is that they are relatively bright in the shortwave-infrared ($S$) band compared to the near-infrared ($N$) band, implying $S > N$. To ensure a positive value for built-up areas, the numerator must be $S-N$. This corresponds to the standard Normalized Difference Built-up Index (NDBI):\n    $$P_B \\equiv \\mathrm{ND}(S, N) = \\frac{S - N}{S + N}$$\n\nNext, we define the synthesized Index-based Built-up Index ($\\mathrm{IBI}$) as instructed, by subtracting the arithmetic mean of the vegetation and water proxies from the built-up proxy:\n$$\\mathrm{IBI} = P_B - \\frac{P_V + P_W}{2}$$\n\nNow, we compute the values of these indices for each of the three given pixel types:\n- Vegetation (veg): $G = 0.09$, $R = 0.04$, $N = 0.52$, $S = 0.19$.\n- Water (water): $G = 0.03$, $R = 0.01$, $N = 0.01$, $S = 0.005$.\n- Built-up (built): $G = 0.15$, $R = 0.13$, $N = 0.24$, $S = 0.31$.\n\n**For the Vegetation pixel ($\\text{veg}$):**\n$P_{V, \\text{veg}} = \\frac{0.52 - 0.04}{0.52 + 0.04 + 0.5} (1.5) = \\frac{0.48}{1.06} (1.5) = \\frac{0.72}{1.06} = \\frac{36}{53} \\approx 0.679245$\n$P_{W, \\text{veg}} = \\frac{0.09 - 0.19}{0.09 + 0.19} = \\frac{-0.10}{0.28} = -\\frac{5}{14} \\approx -0.357143$\n$P_{B, \\text{veg}} = \\frac{0.19 - 0.52}{0.19 + 0.52} = \\frac{-0.33}{0.71} = -\\frac{33}{71} \\approx -0.464789$\n$\\mathrm{IBI}_{\\text{veg}} = P_{B, \\text{veg}} - \\frac{P_{V, \\text{veg}} + P_{W, \\text{veg}}}{2} \\approx -0.464789 - \\frac{0.679245 + (-0.357143)}{2} = -0.464789 - \\frac{0.322102}{2} = -0.464789 - 0.161051 = -0.625840$\n\n**For the Water pixel ($\\text{water}$):**\n$P_{V, \\text{water}} = \\frac{0.01 - 0.01}{0.01 + 0.01 + 0.5} (1.5) = \\frac{0}{0.52} (1.5) = 0$\n$P_{W, \\text{water}} = \\frac{0.03 - 0.005}{0.03 + 0.005} = \\frac{0.025}{0.035} = \\frac{5}{7} \\approx 0.714286$\n$P_{B, \\text{water}} = \\frac{0.005 - 0.01}{0.005 + 0.01} = \\frac{-0.005}{0.015} = -\\frac{1}{3} \\approx -0.333333$\n$\\mathrm{IBI}_{\\text{water}} = P_{B, \\text{water}} - \\frac{P_{V, \\text{water}} + P_{W, \\text{water}}}{2} \\approx -0.333333 - \\frac{0 + 0.714286}{2} = -0.333333 - 0.357143 = -0.690476$\n\n**For the Built-up pixel ($\\text{built}$):**\n$P_{V, \\text{built}} = \\frac{0.24 - 0.13}{0.24 + 0.13 + 0.5} (1.5) = \\frac{0.11}{0.87} (1.5) = \\frac{0.165}{0.87} = \\frac{11}{58} \\approx 0.189655$\n$P_{W, \\text{built}} = \\frac{0.15 - 0.31}{0.15 + 0.31} = \\frac{-0.16}{0.46} = -\\frac{8}{23} \\approx -0.347826$\n$P_{B, \\text{built}} = \\frac{0.31 - 0.24}{0.31 + 0.24} = \\frac{0.07}{0.55} = \\frac{7}{55} \\approx 0.127273$\n$\\mathrm{IBI}_{\\text{built}} = P_{B, \\text{built}} - \\frac{P_{V, \\text{built}} + P_{W, \\text{built}}}{2} \\approx 0.127273 - \\frac{0.189655 + (-0.347826)}{2} = 0.127273 - \\frac{-0.158171}{2} = 0.127273 - (-0.0790855) = 0.2063585$\n\nFinally, we compute the contrast metric $C$:\n$$C \\equiv \\mathrm{IBI}_{\\text{built}} - \\frac{\\mathrm{IBI}_{\\text{veg}} + \\mathrm{IBI}_{\\text{water}}}{2}$$\nSubstituting the calculated $\\mathrm{IBI}$ values:\n$$C \\approx 0.2063585 - \\frac{-0.625840 + (-0.690476)}{2}$$\n$$C \\approx 0.2063585 - \\frac{-1.316316}{2}$$\n$$C \\approx 0.2063585 - (-0.658158)$$\n$$C \\approx 0.2063585 + 0.658158 = 0.8645165$$\n\nThe problem requires the value of $C$ rounded to four significant figures.\n$$C \\approx 0.8645$$",
            "answer": "$$\\boxed{0.8645}$$"
        },
        {
            "introduction": "Calculating an index value is only the first step; turning that continuous value into a discrete land cover class requires a decision rule. This exercise moves from calculation to classification by demonstrating how to determine an optimal decision threshold . Using the principles of Bayesian decision theory, you will derive a threshold for the NDBI that minimizes expected misclassification risk by incorporating prior probabilities of land cover types, a critical skill for creating accurate maps in real-world scenarios where classes are not equally represented.",
            "id": "3800039",
            "problem": "A remote sensing analyst is designing a binary classifier to separate built-up surfaces from barren land using the Normalized Difference Built-up Index (NDBI), defined in terms of Near-Infrared (NIR) and Shortwave Infrared (SWIR) reflectance as an index-valued statistic. In an arid urban fringe region, exploratory analysis and quality-controlled calibration indicate that the NDBI for pixels belonging to the built-up class and the barren class is well-modeled by one-dimensional Gaussian class-conditional densities with a common variance due to sensor noise and invariant atmospheric conditions within the scene. The Index-based Built-up Index (IBI) is also available but, to ensure comparability with historical baselines, the decision will be made on NDBI alone for this scene.\n\nLet $X$ denote the NDBI value of a randomly selected pixel. The analyst models $X$ under the two classes as follows: built-up class $\\omega_{b}$ with $X \\sim \\mathcal{N}(\\mu_{b}, \\sigma^{2})$ and barren class $\\omega_{r}$ with $X \\sim \\mathcal{N}(\\mu_{r}, \\sigma^{2})$, where the scene-specific estimates are $\\mu_{b} = 0.30$, $\\mu_{r} = 0.05$, and $\\sigma = 0.10$. Environmental modeling for this region indicates unequal prior probabilities for the classes: $\\pi_{b} = P(\\omega_{b}) = 0.40$ and $\\pi_{r} = P(\\omega_{r}) = 0.60$. Assume a $0$-$1$ loss structure (equal misclassification costs), and that the decision rule is of threshold type: declare built-up if $X \\geq \\tau$ and barren otherwise.\n\nStarting from the fundamental Bayes decision principle that minimizes expected misclassification risk, derive the optimal decision rule and compute the Bayesian optimal threshold $\\tau$ that minimizes the expected risk under the stated assumptions. Provide the final numerical value of $\\tau$. Round your final threshold to five significant figures.",
            "solution": "The analyst seeks the optimal decision threshold, $\\tau$, for a binary classification problem. The foundation for this derivation is the Bayes decision rule, which minimizes the total probability of misclassification (also known as the expected risk under a $0$-$1$ loss function). The rule states that for an observed value $x$ of the random variable $X$, we should choose the class with the highest posterior probability.\n\nThe two classes are the built-up class, $\\omega_{b}$, and the barren class, $\\omega_{r}$. The posterior probabilities are given by Bayes' theorem:\n$$\nP(\\omega_{b} | x) = \\frac{p(x | \\omega_{b}) P(\\omega_{b})}{p(x)}\n$$\n$$\nP(\\omega_{r} | x) = \\frac{p(x | \\omega_{r}) P(\\omega_{r})}{p(x)}\n$$\nwhere $p(x | \\omega_{j})$ is the class-conditional probability density function (PDF) for class $\\omega_{j}$, $P(\\omega_{j})$ is the prior probability of class $\\omega_{j}$ (denoted $\\pi_{j}$), and $p(x)$ is the evidence.\n\nThe Bayes decision rule is to classify the pixel as built-up if $P(\\omega_{b} | x) > P(\\omega_{r} | x)$, and as barren if $P(\\omega_{b} | x) < P(\\omega_{r} | x)$. The decision boundary, which defines the threshold $\\tau$, occurs where the posterior probabilities are equal: $P(\\omega_{b} | \\tau) = P(\\omega_{r} | \\tau)$.\n\nThis equality can be expressed as:\n$$\n\\frac{p(\\tau | \\omega_{b}) P(\\omega_{b})}{p(\\tau)} = \\frac{p(\\tau | \\omega_{r}) P(\\omega_{r})}{p(\\tau)}\n$$\nThe evidence term $p(\\tau)$ cancels, simplifying the condition to:\n$$\np(\\tau | \\omega_{b}) P(\\omega_{b}) = p(\\tau | \\omega_{r}) P(\\omega_{r})\n$$\nUsing the given prior probabilities $\\pi_{b}$ and $\\pi_{r}$:\n$$\np(\\tau | \\omega_{b}) \\pi_{b} = p(\\tau | \\omega_{r}) \\pi_{r}\n$$\nThe problem states that the class-conditional PDFs are Gaussian with a common variance $\\sigma^{2}$:\n$$\np(x | \\omega_{b}) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu_{b})^{2}}{2\\sigma^{2}}\\right)\n$$\n$$\np(x | \\omega_{r}) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu_{r})^{2}}{2\\sigma^{2}}\\right)\n$$\nTo solve for $\\tau$, it is more convenient to work with the natural logarithm of the decision boundary equation:\n$$\n\\ln(p(\\tau | \\omega_{b})) + \\ln(\\pi_{b}) = \\ln(p(\\tau | \\omega_{r})) + \\ln(\\pi_{r})\n$$\nSubstituting the expressions for the Gaussian PDFs:\n$$\n\\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right) - \\frac{(\\tau - \\mu_{b})^{2}}{2\\sigma^{2}} + \\ln(\\pi_{b}) = \\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right) - \\frac{(\\tau - \\mu_{r})^{2}}{2\\sigma^{2}} + \\ln(\\pi_{r})\n$$\nThe normalization constant term $\\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right)$ appears on both sides and cancels out:\n$$\n- \\frac{(\\tau - \\mu_{b})^{2}}{2\\sigma^{2}} + \\ln(\\pi_{b}) = - \\frac{(\\tau - \\mu_{r})^{2}}{2\\sigma^{2}} + \\ln(\\pi_{r})\n$$\nRearranging the terms to solve for $\\tau$:\n$$\n\\frac{(\\tau - \\mu_{r})^{2}}{2\\sigma^{2}} - \\frac{(\\tau - \\mu_{b})^{2}}{2\\sigma^{2}} = \\ln(\\pi_{r}) - \\ln(\\pi_{b})\n$$\n$$\n(\\tau - \\mu_{r})^{2} - (\\tau - \\mu_{b})^{2} = 2\\sigma^{2} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nExpanding the squared terms:\n$$\n(\\tau^{2} - 2\\tau\\mu_{r} + \\mu_{r}^{2}) - (\\tau^{2} - 2\\tau\\mu_{b} + \\mu_{b}^{2}) = 2\\sigma^{2} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nThe $\\tau^{2}$ terms cancel:\n$$\n2\\tau\\mu_{b} - 2\\tau\\mu_{r} + \\mu_{r}^{2} - \\mu_{b}^{2} = 2\\sigma^{2} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nIsolating the terms containing $\\tau$:\n$$\n2\\tau(\\mu_{b} - \\mu_{r}) = \\mu_{b}^{2} - \\mu_{r}^{2} + 2\\sigma^{2} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nFactoring the difference of squares $\\mu_{b}^{2} - \\mu_{r}^{2} = (\\mu_{b} - \\mu_{r})(\\mu_{b} + \\mu_{r})$:\n$$\n2\\tau(\\mu_{b} - \\mu_{r}) = (\\mu_{b} - \\mu_{r})(\\mu_{b} + \\mu_{r}) + 2\\sigma^{2} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nAssuming $\\mu_{b} \\neq \\mu_{r}$, we can divide by $2(\\mu_{b} - \\mu_{r})$:\n$$\n\\tau = \\frac{\\mu_{b} + \\mu_{r}}{2} + \\frac{2\\sigma^{2}}{2(\\mu_{b} - \\mu_{r})} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nThis simplifies to the general formula for the Bayes optimal threshold for two one-dimensional Gaussian classes with equal variance:\n$$\n\\tau = \\frac{\\mu_{b} + \\mu_{r}}{2} + \\frac{\\sigma^{2}}{\\mu_{b} - \\mu_{r}} \\ln\\left(\\frac{\\pi_{r}}{\\pi_{b}}\\right)\n$$\nThe decision rule is to classify a pixel as built-up ($\\omega_{b}$) if its NDBI value $X \\ge \\tau$. From the data, $\\mu_{b} = 0.30 > \\mu_{r} = 0.05$, so higher NDBI values are indeed associated with the built-up class, consistent with the form of the decision rule.\n\nNow, we substitute the given numerical values:\n$\\mu_{b} = 0.30$\n$\\mu_{r} = 0.05$\n$\\sigma = 0.10$, so $\\sigma^{2} = (0.10)^{2} = 0.01$\n$\\pi_{b} = 0.40$\n$\\pi_{r} = 0.60$\n\nPlugging these into the derived formula for $\\tau$:\n$$\n\\tau = \\frac{0.30 + 0.05}{2} + \\frac{0.01}{0.30 - 0.05} \\ln\\left(\\frac{0.60}{0.40}\\right)\n$$\n$$\n\\tau = \\frac{0.35}{2} + \\frac{0.01}{0.25} \\ln(1.5)\n$$\n$$\n\\tau = 0.175 + 0.04 \\ln(1.5)\n$$\nUsing the value $\\ln(1.5) \\approx 0.405465108$:\n$$\n\\tau \\approx 0.175 + 0.04 \\times 0.405465108\n$$\n$$\n\\tau \\approx 0.175 + 0.01621860432\n$$\n$$\n\\tau \\approx 0.19121860432\n$$\nThe problem requires the final threshold to be rounded to five significant figures.\n$$\n\\tau \\approx 0.19122\n$$\nThis threshold represents the NDBI value at which the posterior probabilities of a pixel belonging to the built-up class and the barren class are equal. Values above this threshold have a higher posterior probability of being built-up.",
            "answer": "$$\n\\boxed{0.19122}\n$$"
        },
        {
            "introduction": "The final and most crucial stage of any classification project is to quantitatively assess its performance. A classification map is only as valuable as its known accuracy. This practice closes the remote sensing workflow by tasking you with evaluating a built-up classification derived from an IBI threshold . You will construct a confusion matrix from validation data and compute essential metrics such as overall accuracy, precision, recall, and the $F_1$ score, providing you with the standard toolkit for interpreting and reporting the reliability of your classification results.",
            "id": "3800058",
            "problem": "Consider a supervised binary classification of land cover into built-up versus non-built-up using the Index-Based Built-up Index (IBI), which is computed from multispectral reflectance to enhance the spectral contrast of impervious surfaces relative to vegetation and water. The classification rule is a single-threshold detector: a pixel is labeled as built-up if its IBI value $I$ satisfies $I \\geq \\tau$ and as non-built-up if $I < \\tau$, where $\\tau$ is a fixed threshold determined from independent calibration.\n\nA validation region contains $400$ pixels with ground-truth labels and IBI values. The ground-truth labels are evenly split: $200$ pixels are built-up and $200$ are non-built-up. A threshold of $\\tau = 0.22$ is applied to the IBI values. The validation audit finds the following frequency counts:\n- Among the $200$ ground-truth built-up pixels, $140$ satisfy $I \\geq \\tau$ and $60$ satisfy $I < \\tau$.\n- Among the $200$ ground-truth non-built-up pixels, $20$ satisfy $I \\geq \\tau$ and $180$ satisfy $I < \\tau$.\n\nStarting from the fundamental definition of a confusion matrix for binary detection and the set-membership rule induced by the threshold, construct the confusion matrix and, using first-principles definitions based on counts of correct and incorrect decisions, compute the following four performance metrics for the positive (built-up) class:\n- Overall accuracy,\n- Precision,\n- Recall,\n- $F_{1}$ score.\n\nRound each metric to four significant figures. Express the final answer as a single row matrix in the order listed above, with each entry being the rounded decimal value. No units are required for these metrics.",
            "solution": "The problem requires the construction of a confusion matrix and the calculation of four standard performance metrics for a binary classification task. The validation of the problem statement confirms that it is scientifically grounded, well-posed, objective, and contains all necessary information for a complete solution.\n\nFirst, we establish the components of the confusion matrix based on the problem's definitions. The binary classification involves two classes:\n-   Positive Class: Built-up\n-   Negative Class: Non-built-up\n\nThe classification rule is based on a threshold $\\tau = 0.22$ applied to the IBI value $I$:\n-   A pixel is predicted as \"built-up\" (Predicted Positive) if $I \\geq \\tau$.\n-   A pixel is predicted as \"non-built-up\" (Predicted Negative) if $I < \\tau$.\n\nThe confusion matrix has four components defined as follows:\n-   **True Positives ($TP$)**: The number of pixels that are actually built-up and are correctly classified as built-up.\n-   **False Negatives ($FN$)**: The number of pixels that are actually built-up but are incorrectly classified as non-built-up.\n-   **False Positives ($FP$)**: The number of pixels that are actually non-built-up but are incorrectly classified as built-up.\n-   **True Negatives ($TN$)**: The number of pixels that are actually non-built-up and are correctly classified as non-built-up.\n\nFrom the provided data:\n-   The total number of ground-truth built-up pixels is $200$. Among these, $140$ pixels satisfy $I \\geq \\tau$ and $60$ pixels satisfy $I < \\tau$.\n    -   The $140$ pixels that are actually built-up and are predicted as built-up ($I \\geq \\tau$) correspond to the True Positives. Thus, $TP = 140$.\n    -   The $60$ pixels that are actually built-up but are predicted as non-built-up ($I < \\tau$) correspond to the False Negatives. Thus, $FN = 60$.\n\n-   The total number of ground-truth non-built-up pixels is $200$. Among these, $20$ pixels satisfy $I \\geq \\tau$ and $180$ pixels satisfy $I < \\tau$.\n    -   The $20$ pixels that are actually non-built-up but are predicted as built-up ($I \\geq \\tau$) correspond to the False Positives. Thus, $FP = 20$.\n    -   The $180$ pixels that are actually non-built-up and are predicted as non-built-up ($I < \\tau$) correspond to the True Negatives. Thus, $TN = 180$.\n\nThe total number of pixels in the validation set is $N = TP + TN + FP + FN = 140 + 180 + 20 + 60 = 400$, which matches the given information.\n\nThe confusion matrix can be constructed as:\n$$\n\\begin{array}{cc|cc}\n& & \\text{Predicted Positive} & \\text{Predicted Negative} \\\\\n\\hline\n\\text{Actual Positive} & (TP) & 140 & (FN) \\quad 60 \\\\\n\\text{Actual Negative} & (FP) &  20 & (TN) \\quad 180\n\\end{array}\n$$\n\nNow, we compute the four requested performance metrics using their first-principles definitions based on these counts.\n\n1.  **Overall Accuracy ($A$)**: This is the ratio of the total number of correct classifications to the total number of pixels.\n    $$A = \\frac{TP + TN}{TP + TN + FP + FN}$$\n    Substituting the values:\n    $$A = \\frac{140 + 180}{140 + 180 + 20 + 60} = \\frac{320}{400} = 0.8$$\n    Rounded to four significant figures, this is $0.8000$.\n\n2.  **Precision ($P$)**: Also known as Positive Predictive Value, this is the ratio of true positive classifications to the total number of positive predictions. It measures the accuracy of the positive predictions.\n    $$P = \\frac{TP}{TP + FP}$$\n    Substituting the values:\n    $$P = \\frac{140}{140 + 20} = \\frac{140}{160} = \\frac{7}{8} = 0.875$$\n    Rounded to four significant figures, this is $0.8750$.\n\n3.  **Recall ($R$)**: Also known as Sensitivity or True Positive Rate, this is the ratio of true positive classifications to the total number of actual positives. It measures the ability of the classifier to find all the positive samples.\n    $$R = \\frac{TP}{TP + FN}$$\n    Substituting the values:\n    $$R = \\frac{140}{140 + 60} = \\frac{140}{200} = \\frac{7}{10} = 0.7$$\n    Rounded to four significant figures, this is $0.7000$.\n\n4.  **$F_1$ Score**: This is the harmonic mean of Precision and Recall, providing a single metric that balances both.\n    $$F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} = \\frac{2TP}{2TP + FP + FN}$$\n    Using the second form for direct computation:\n    $$F_1 = \\frac{2 \\cdot 140}{2 \\cdot 140 + 20 + 60} = \\frac{280}{280 + 80} = \\frac{280}{360} = \\frac{28}{36} = \\frac{7}{9}$$\n    Numerically, this is approximately $0.777777...$.\n    Rounded to four significant figures, this is $0.7778$.\n\nThe final results, rounded to four significant figures, are:\n-   Overall accuracy: $0.8000$\n-   Precision: $0.8750$\n-   Recall: $0.7000$\n-   $F_1$ score: $0.7778$\n\nThese values are to be presented in a single row matrix in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.8000 & 0.8750 & 0.7000 & 0.7778 \\end{pmatrix}}$$"
        }
    ]
}