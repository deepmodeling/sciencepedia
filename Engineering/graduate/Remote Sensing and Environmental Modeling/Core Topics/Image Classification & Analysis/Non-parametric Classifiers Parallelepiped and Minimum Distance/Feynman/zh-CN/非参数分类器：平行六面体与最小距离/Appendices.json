{
    "hands_on_practices": [
        {
            "introduction": "本实践探讨了平行六面体分类器的基本行为，特别是在高维特征空间中的表现。通过一个假设场景，我们将推导在特征波段统计独立的前提下，如何计算一个地物类别被分类器接受的联合概率。这项练习旨在揭示“维度灾难”对这类分类器的具体影响：随着光谱波段数量 $d$ 的增加，接受区域的几何体积看似膨胀，但其联合覆盖概率却会急剧下降，这对理解和应用该分类器至关重要 ()。",
            "id": "3830385",
            "problem": "一台多光谱成像仪在大气校正后获取地表反射率的 $d$ 维特征向量 $\\mathbf{X} \\in \\mathbb{R}^{d}$。对于一个地物覆盖类别 $C$，平行六面体分类器定义了一个轴对齐的接受区域 $A = \\prod_{j=1}^{d} I_{j}$，其中每个 $I_{j} \\subset \\mathbb{R}$ 是根据训练数据估计的沿波段 $j$ 的一个闭区间。在基于主成分分析 (PCA) 的线性白化变换之后，假设变换后的类别条件特征在各个波段之间是标准化的且统计独立的。对于类别 $C$，$I_{j}$ 的经验边际覆盖率是 $p_{j} \\in (0,1)$，定义为一个类别为 $C$ 的像素其波段 $j$ 的值落在 $I_{j}$ 内的概率。\n\n仅从积空间上的联合概率的定义、变换后波段的独立性以及 $p_{j}$ 作为边际覆盖率的定义出发，推导平行六面体分类器所接受的类别为 $C$ 的像素的期望比例，将其表示为 $\\{p_{j}\\}_{j=1}^{d}$ 的函数。使用几何测度解释为什么增加 $d$ 会同时增大 $A$ 的绝对体积，却又减少了类别分布下的期望联合覆盖率。简要地将其与最小距离分类器（该分类器将每个像素分配给最近的类别均值，并且不包含拒绝选项）在覆盖率方面的行为进行对比。\n\n然后，对于一个在 $d = 6$ 个白化波段中的植被类别，其经验测量的边际覆盖率如下\n$$\np_{1} = 0.93,\\quad p_{2} = 0.89,\\quad p_{3} = 0.90,\\quad p_{4} = 0.88,\\quad p_{5} = 0.95,\\quad p_{6} = 0.87,\n$$\n计算平行六面体分类器对类别 $C$ 的期望接受概率。将你的最终概率四舍五入到 $4$ 位有效数字，并以小数形式表示。",
            "solution": "该问题要求推导在统计独立特征假设下平行六面体分类器的期望接受概率，解释该分类器在高维空间中的行为，与最小距离分类器进行简要比较，并进行具体的数值计算。该问题是适定的，有科学依据的，并为得出完整解答提供了所有必要信息。\n\n首先，我们推导分类器接受类别为 $C$ 的像素的期望比例的一般表达式。令 $\\mathbf{X} = (X_{1}, X_{2}, \\dots, X_{d})$ 为代表属于类别 $C$ 的像素特征的 $d$ 维随机向量。如果一个像素的特征向量落在接受区域 $A$ 内，平行六面体分类器就接受该像素。区域 $A$ 定义为 $d$ 个闭区间的笛卡尔积，$A = \\prod_{j=1}^{d} I_{j}$，其中 $I_{j}$ 是第 $j$ 个波段的接受区间。\n\n一个像素被接受，当且仅当其在所有波段 $j = 1, \\dots, d$ 上的特征值 $X_{j}$ 都落在区间 $I_{j}$ 内。被接受像素的期望比例是此联合事件的概率，我们记为 $P_{\\text{accept}}$。\n$$\nP_{\\text{accept}} = P(\\mathbf{X} \\in A) = P(X_{1} \\in I_{1} \\text{ and } X_{2} \\in I_{2} \\text{ and } \\dots \\text{ and } X_{d} \\in I_{d})\n$$\n问题陈述指明，在白化变换之后，类别条件特征在各个波段之间是统计独立的。一组事件统计独立的定义是，它们联合发生的概率是它们各自概率的乘积。因此，我们可以写出：\n$$\nP_{\\text{accept}} = P(X_{1} \\in I_{1}) \\times P(X_{2} \\in I_{2}) \\times \\dots \\times P(X_{d} \\in I_{d})\n$$\n问题将经验边际覆盖率 $p_{j}$ 定义为一个类别为 $C$ 的像素其波段 $j$ 的值落在区间 $I_{j}$ 内的概率。即，$p_{j} = P(X_{j} \\in I_{j})$。将此定义代入 $P_{\\text{accept}}$ 的表达式中，我们得到期望的结果：\n$$\nP_{\\text{accept}} = \\prod_{j=1}^{d} p_{j}\n$$\n该表达式给出了类别 $C$ 的期望接受概率，作为边际覆盖率 $\\{p_{j}\\}_{j=1}^{d}$ 的函数。\n\n接下来，我们讨论这个表面上的悖论：为何增加维度 $d$ 会增大接受区域 $A$ 的体积，却同时减少了期望的联合覆盖率 $P_{\\text{accept}}$。\n轴对齐的平行六面体 $A$ 的几何测度（或体积）是其定义区间长度的乘积：\n$$\n\\text{Vol}(A) = \\prod_{j=1}^{d} \\text{Length}(I_{j})\n$$\n为了使特征标准化，其分布通常具有有限的标准差，例如 $\\sigma_{j}=1$。要实现高的边际覆盖率 $p_{j}$（例如，$p_{j} = 0.95$），区间 $I_{j}$ 必须跨越一个相当大的范围。例如，如果白化后的特征服从标准正态分布，一个捕获 $p_{j}=0.95$ 概率质量的区间长度必须约为 $3.92$。由于这个长度大于 $1$，体积 $\\text{Vol}(A)$ 将随着维度 $d$ 的增加而呈指数级增长，即 $(\\text{长度})^{d}$。这导致接受区域的绝对体积迅速膨胀。\n相反，联合覆盖率（或接受概率）是 $P_{\\text{accept}} = \\prod_{j=1}^{d} p_{j}$。由于每个 $p_{j}$ 都是一个概率，所以必有 $p_{j} \\in (0, 1)$。多个小于 $1$ 的数相乘会得到一个更小的数。为简单起见，如果我们假设所有边际覆盖率都等于一个常数 $p  1$，那么 $P_{\\text{accept}} = p^{d}$。随着 $d$ 的增加，这个值会指数级地趋近于 $0$。这种现象是“维度灾难”的一种表现：尽管超矩形区域 $A$ 在特征空间中包含很大的体积，但这个体积大部分是“空的”角落空间，其中概率密度小到可以忽略不计。类别分布的实际概率质量变得越来越集中在一个难以用超矩形近似的区域，并且要求一个样本在所有维度上同时都是“典型的”，这个条件变得极其严格。\n\n现在，我们简要对比平行六面体分类器与最小距离分类器的行为。最小距离分类器将整个特征空间 $\\mathbb{R}^{d}$ 划分为多个决策区域，每个类别一个。具体来说，每个点 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 都被分配给其均值向量 $\\boldsymbol{\\mu}_{k}$ 与 $\\mathbf{x}$ 最近的类别 $C_{k}$。这意味着没有“拒绝”选项；每个像素都会被分类。因此，所有类别的总覆盖率为 $100 \\%$。相比之下，平行六面体分类器为每个类别定义了明确的、有界的接受区域。任何落在所有已定义的平行六面体之外的像素都将被拒绝或不被分类。因此，其总覆盖率通常远低于 $100 \\%$。虽然最小距离分类器也受维度灾难的影响（高维空间中的距离可能变得意义不大），但它在覆盖率方面的行为有着根本的不同，因为它强制对特征空间进行完全的划分（镶嵌）。\n\n最后，我们计算给定植被类别的期望接受概率。维度是 $d=6$，边际覆盖率如下：\n$p_{1} = 0.93$\n$p_{2} = 0.89$\n$p_{3} = 0.90$\n$p_{4} = 0.88$\n$p_{5} = 0.95$\n$p_{6} = 0.87$\n\n使用推导出的公式，期望接受概率是这些值的乘积：\n$$\nP_{\\text{accept}} = p_{1} \\times p_{2} \\times p_{3} \\times p_{4} \\times p_{5} \\times p_{6}\n$$\n$$\nP_{\\text{accept}} = 0.93 \\times 0.89 \\times 0.90 \\times 0.88 \\times 0.95 \\times 0.87\n$$\n计算这个乘积得到：\n$$\nP_{\\text{accept}} \\approx 0.5418024876\n$$\n问题要求将此值四舍五入到 $4$ 位有效数字。前四位有效数字是 $5$、$4$、$1$ 和 $8$。第五位数字是 $0$，因此我们向下舍入。\n$$\nP_{\\text{accept}} \\approx 0.5418\n$$\n这表明，即使在每个波段都有很高的边际覆盖率（都接近 $0.90$），一个像素同时满足所有标准的概率也下降到了仅略高于 $0.54$。",
            "answer": "$$\n\\boxed{0.5418}\n$$"
        },
        {
            "introduction": "转换到最小距离分类器，本实践探讨了其理论基础，并将其与最优的贝叶斯决策理论联系起来。我们将推导在特定假设下（类别条件分布为具有相同球形协方差的高斯分布），最小距离分类器的决策边界在何种条件下能够近似于贝叶斯最优边界。通过这项练习，学生可以深入理解一个简单的非参数方法背后的理论依据，并量化其作为最优分类器近似的有效性范围，这对于在实际应用中做出明智的方法选择至关重要 ()。",
            "id": "3830408",
            "problem": "一位多光谱遥感分析师正在使用一个两阶段非参数程序对两种土地覆盖类别进行分类：先使用平行六面体拒绝器，然后使用最小均值距离规则。设图像特征向量为 $x \\in \\mathbb{R}^{p}$，并假设类条件分布为多元正态分布，其均值为 $\\mu_{1}, \\mu_{2} \\in \\mathbb{R}^{p}$，并具有一个共同的球形协方差 $\\sigma^{2} I_{p}$，其中 $I_{p}$ 是 $p \\times p$ 的单位矩阵，且 $\\sigma^{2}  0$。先验概率为 $\\pi_{1}$ 和 $\\pi_{2}$，满足 $\\pi_{1} + \\pi_{2} = 1$ 且 $\\pi_{1}, \\pi_{2} \\in (0,1)$。平行六面体拒绝器使用的各波段区间足够宽，以至于在连接 $\\mu_{1}$ 和 $\\mu_{2}$ 的线段上，它不会截断感兴趣的决策边界区域。最小均值距离规则将 $x$ 分配给其均值在欧几里得距离上最近的类别。\n\n仅从贝叶斯决策理论和高斯似然出发，推导这两类的贝叶斯决策边界，并表示该贝叶斯边界与连接 $\\mu_{1}$ 和 $\\mu_{2}$ 的线段的垂直平分线之间的有符号偏移量，该偏移量是沿着 $\\mu_{1} - \\mu_{2}$ 方向的单位向量测量的。设 $D = \\|\\mu_{1} - \\mu_{2}\\|_{2}$ 表示均值间距，并设 $\\alpha \\in (0,1)$ 为指定的容差。施加一个要求，即该偏移量的绝对值不超过均值间距一半的 $\\alpha$ 倍，从而使得最小均值距离决策边界在该轴上以指定的容差近似贝叶斯边界。在此要求下，确定最大允许先验几率因子\n$$\n\\kappa_{\\max} = \\max\\!\\left\\{\\frac{\\pi_{1}}{\\pi_{2}}, \\frac{\\pi_{2}}{\\pi_{1}}\\right\\}\n$$\n的闭式符号表达式，该表达式以 $\\sigma^{2}$、$D$ 和 $\\alpha$ 表示。最终答案必须是关于 $\\kappa_{\\max}$ 的这个单一表达式。请将最终答案表示为无量纲的解析表达式。无需四舍五入。",
            "solution": "目标是，在贝叶斯最优决策边界与最小均值距离决策边界之间的偏差存在约束的条件下，求出最大允许先验几率因子 $\\kappa_{\\max}$。推导从具有高斯分布的两类的贝叶斯决策理论开始。\n\n贝叶斯决策规则规定，将特征向量 $x \\in \\mathbb{R}^{p}$ 分配给使后验概率 $P(\\omega_i | x)$ 最大化的类别 $\\omega_i$。决策边界是后验概率相等的点集，这等价于条件 $\\pi_1 p(x|\\omega_1) = \\pi_2 p(x|\\omega_2)$，其中 $\\pi_i$ 是类别 $\\omega_i$ 的先验概率，$p(x|\\omega_i)$ 是类条件概率密度函数（似然）。\n\n对决策边界条件取自然对数，得到：\n$$\n\\ln(\\pi_1) + \\ln(p(x|\\omega_1)) = \\ln(\\pi_2) + \\ln(p(x|\\omega_2))\n$$\n似然函数为多元正态分布 $N(\\mu_i, \\sigma^2 I_p)$，因此类别 $\\omega_i$ 的概率密度为：\n$$\np(x|\\omega_i) = \\frac{1}{(2\\pi \\sigma^2)^{p/2}} \\exp\\left(-\\frac{1}{2\\sigma^2}\\|x-\\mu_i\\|_2^2\\right)\n$$\n相应的对数似然为：\n$$\n\\ln(p(x|\\omega_i)) = -\\frac{p}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\|x-\\mu_i\\|_2^2\n$$\n将此代入边界方程：\n$$\n\\ln(\\pi_1) - \\frac{p}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\|x-\\mu_1\\|_2^2 = \\ln(\\pi_2) - \\frac{p}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\|x-\\mu_2\\|_2^2\n$$\n常数项 $-\\frac{p}{2}\\ln(2\\pi\\sigma^2)$ 被消去。重新整理剩余项，得到：\n$$\n\\|x-\\mu_2\\|_2^2 - \\|x-\\mu_1\\|_2^2 = 2\\sigma^2(\\ln(\\pi_2) - \\ln(\\pi_1))\n$$\n展开平方范数 $(x^T x - 2x^T\\mu_i + \\mu_i^T\\mu_i)$：\n$$\n(x^T x - 2x^T\\mu_2 + \\mu_2^T\\mu_2) - (x^T x - 2x^T\\mu_1 + \\mu_1^T\\mu_1) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$x^T x$ 项被消去，留下一个超平面的方程：\n$$\n2x^T(\\mu_1 - \\mu_2) - (\\mu_1^T\\mu_1 - \\mu_2^T\\mu_2) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$$\n2x^T(\\mu_1 - \\mu_2) = \\|\\mu_1\\|_2^2 - \\|\\mu_2\\|_2^2 + 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n这是贝叶斯最优决策边界的方程。\n\n最小均值距离决策边界由条件 $\\|x-\\mu_1\\|_2 = \\|x-\\mu_2\\|_2$（或 $\\|x-\\mu_1\\|_2^2 = \\|x-\\mu_2\\|_2^2$）定义。这对应于一般贝叶斯边界方程右侧为零的情况，这种情况在先验概率相等时发生。该边界的方程为：\n$$\n2x^T(\\mu_1 - \\mu_2) = \\|\\mu_1\\|_2^2 - \\|\\mu_2\\|_2^2\n$$\n这是连接 $\\mu_1$ 和 $\\mu_2$ 的线段的垂直平分线的方程。\n\n两个边界都是具有相同法向量 $(\\mu_1 - \\mu_2)$ 的超平面。这两个平行超平面之间的有符号偏移量 $d$（沿单位法向量 $u = \\frac{\\mu_1 - \\mu_2}{\\|\\mu_1 - \\mu_2\\|_2}$ 测量）可以通过考虑贝叶斯边界上的一个点 $x_B$ 和最小距离边界上的一个点 $x_{MD}$ 来求得。向量 $x_B - x_{MD}$ 可写为 $d \\cdot u$。\n从贝叶斯边界方程中减去最小距离边界方程，得到：\n$$\n2x_B^T(\\mu_1 - \\mu_2) - 2x_{MD}^T(\\mu_1 - \\mu_2) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$$\n2(x_B - x_{MD})^T(\\mu_1 - \\mu_2) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n代入 $x_B - x_{MD} = d \\cdot u = d \\frac{\\mu_1 - \\mu_2}{D}$，其中 $D = \\|\\mu_1 - \\mu_2\\|_2$：\n$$\n2\\left(d \\frac{\\mu_1 - \\mu_2}{D}\\right)^T(\\mu_1 - \\mu_2) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$$\n\\frac{2d}{D} (\\mu_1 - \\mu_2)^T(\\mu_1 - \\mu_2) = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$$\n\\frac{2d}{D} \\|\\mu_1 - \\mu_2\\|_2^2 = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n$$\n\\frac{2dD^2}{D} = 2\\sigma^2\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n解出有符号偏移量 $d$：\n$$\nd = \\frac{\\sigma^2}{D}\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\n$$\n问题要求该偏移量的绝对值不超过均值间距一半的 $\\alpha$ 倍：\n$$\n|d| \\le \\alpha \\frac{D}{2}\n$$\n代入 $d$ 的表达式：\n$$\n\\left|\\frac{\\sigma^2}{D}\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\\right| \\le \\frac{\\alpha D}{2}\n$$\n由于 $\\sigma^2  0$ 且 $D  0$，我们可以写成：\n$$\n\\frac{\\sigma^2}{D}\\left|\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\\right| \\le \\frac{\\alpha D}{2}\n$$\n分离对数项：\n$$\n\\left|\\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right)\\right| \\le \\frac{\\alpha D^2}{2\\sigma^2}\n$$\n这等价于不等式：\n$$\n-\\frac{\\alpha D^2}{2\\sigma^2} \\le \\ln\\left(\\frac{\\pi_2}{\\pi_1}\\right) \\le \\frac{\\alpha D^2}{2\\sigma^2}\n$$\n对所有部分取指数，得到几率比 $\\frac{\\pi_2}{\\pi_1}$ 的范围：\n$$\n\\exp\\left(-\\frac{\\alpha D^2}{2\\sigma^2}\\right) \\le \\frac{\\pi_2}{\\pi_1} \\le \\exp\\left(\\frac{\\alpha D^2}{2\\sigma^2}\\right)\n$$\n待确定的量是 $\\kappa_{\\max} = \\max\\{\\frac{\\pi_1}{\\pi_2}, \\frac{\\pi_2}{\\pi_1}\\}$。\n如果 $\\frac{\\pi_2}{\\pi_1} \\ge 1$，则 $\\kappa = \\frac{\\pi_2}{\\pi_1}$。该不等式提供了上界 $\\kappa \\le \\exp\\left(\\frac{\\alpha D^2}{2\\sigma^2}\\right)$。\n如果 $\\frac{\\pi_2}{\\pi_1}  1$，则 $\\frac{\\pi_1}{\\pi_2}  1$，所以 $\\kappa = \\frac{\\pi_1}{\\pi_2}$。根据不等式的左侧，有 $\\frac{\\pi_2}{\\pi_1} \\ge \\exp\\left(-\\frac{\\alpha D^2}{2\\sigma^2}\\right)$。取倒数会反转不等号：$\\frac{\\pi_1}{\\pi_2} \\le \\frac{1}{\\exp\\left(-\\frac{\\alpha D^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{\\alpha D^2}{2\\sigma^2}\\right)$。所以，$\\kappa \\le \\exp\\left(\\frac{\\alpha D^2}{2\\sigma^2}\\right)$。\n在这两种情况下，$\\kappa$ 的最大允许值是相同的。因此，\n$$\n\\kappa_{\\max} = \\exp\\left(\\frac{\\alpha D^2}{2\\sigma^2}\\right)\n$$",
            "answer": "$$\n\\boxed{\\exp\\left(\\frac{\\alpha D^{2}}{2\\sigma^{2}}\\right)}\n$$"
        }
    ]
}