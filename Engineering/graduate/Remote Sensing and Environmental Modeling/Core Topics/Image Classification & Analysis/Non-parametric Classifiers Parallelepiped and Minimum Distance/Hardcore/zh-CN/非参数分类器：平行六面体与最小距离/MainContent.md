## 引言
在遥感与[环境建模](@entry_id:1124562)领域，监督分类是信息提取的核心任务，其目标是根据地物的光谱等特征将其归入预定义的类别。许多强大的分类算法，如高斯[最大似然](@entry_id:146147)法，依赖于对数据分布的特定[参数化](@entry_id:265163)假设。然而，当地物的真实光谱特征未知、复杂或不符合标准分布时，这些[参数化](@entry_id:265163)方法的性能会大打折扣，从而产生模型失配问题。

为了应对这一挑战，非[参数化](@entry_id:265163)分类器提供了一种更灵活、更稳健的替代方案。这类方法不预设数据概率分布的具体形式，而是直接从训练样本的经验属性（如均值、最大/最小值）出发构建决策规则。这使得它们能够适应各种复杂的数据分布，尤其是在先验知识有限的情况下。本文聚焦于两种最经典、最直观的非[参数化](@entry_id:265163)方法：平行六面体分类器和[最小距离分类器](@entry_id:1127934)。

通过本文的学习，您将获得对这两种基础算法的深刻理解。在“原理与机制”一章中，我们将深入剖析它们的核心算法、几何解释、理论假设以及各自的优缺点，并探讨[维度灾难](@entry_id:143920)等关键挑战。接下来的“应用与跨学科联系”一章，将视野扩展到实际应用，讨论如何通过物理校正、特征工程、空间后处理等手段，将这些简单的模型应用于解决复杂的遥感问题。最后，通过“动手实践”部分，您将有机会通过具体问题加深对理论知识的理解，并探索这些分类器在计算性能和[统计稳健性](@entry_id:165428)方面的实际表现。

## 原理与机制

在遥感[图像分析](@entry_id:914766)和环境建模中，监督分类的目标是为特征空间中的每一个数据点（例如，一个像素的[反射率](@entry_id:172768)向量）分配一个预定义的类别标签。根据[贝叶斯决策理论](@entry_id:909090)，在损失函数对称（例如[0-1损失](@entry_id:173640)）的情况下，最优的决策规则是将数据点 $\mathbf{x}$ 分配给后验概率 $P(\omega_j|\mathbf{x})$ 最大的类别 $\omega_j$。通过贝叶斯公式，$P(\omega_j|\mathbf{x}) \propto p(\mathbf{x}|\omega_j)P(\omega_j)$，其中 $p(\mathbf{x}|\omega_j)$ 是类[条件概率密度函数](@entry_id:190422)（PDF），$P(\omega_j)$ 是类别[先验概率](@entry_id:275634)。

[参数化](@entry_id:265163)分类器，如高斯最大似然法，假设 $p(\mathbf{x}|\omega_j)$ 服从一个特定的[参数化](@entry_id:265163)分布（例如，[多元正态分布](@entry_id:175229)），并通过训练数据估计其参数（如[均值向量](@entry_id:266544)和[协方差矩阵](@entry_id:139155)）。这种方法的效率很高，前提是其分布假设与数据的真实分布相符。然而，在许多实际应用中，地物类别的光谱分布是未知的、复杂的，或明显不符合高斯分布。

在这种情况下，**非[参数化](@entry_id:265163)分类器 (non-parametric classifiers)** 提供了一种更稳健的替代方案。这类分类器不预设 $p(\mathbf{x}|\omega_j)$ 的具体函数形式，而是直接根据训练样本的经验属性构建决策规则 。它们通过操作经验性的[数据摘要](@entry_id:748219)（如均值、最小值和最大值）来避免对分布的假设，因此其决策规则中不嵌入[参数化](@entry_id:265163)的[似然函数](@entry_id:921601)。这使得它们能够应用于非高斯或异方差的类条件密度，尽管相对于一个被正确定指定的[参数化](@entry_id:265163)[贝叶斯分类器](@entry_id:180656)，它们的性能可能是次优的 。本章将深入探讨两种经典的非[参数化](@entry_id:265163)分类器：[最小距离分类器](@entry_id:1127934)和平行六面体分类器。

### [最小距离分类器](@entry_id:1127934)

[最小距离分类器](@entry_id:1127934)，或称最近[质心](@entry_id:138352)分类器，是最直观、最简单的分类方法之一。其核心思想是，每个类别都可以由一个单一的**原型 (prototype)** 或**[质心](@entry_id:138352) (centroid)** 来代表，这个[质心](@entry_id:138352)通常是该类别所有训练样本的[算术平均值](@entry_id:165355)。

#### 核心机制与几何解释

给定一组类别 $\omega_k$（$k=1, \dots, K$），我们首先为每个类别计算其[质心](@entry_id:138352)，即训练样本的[均值向量](@entry_id:266544) $\boldsymbol{\mu}_k$。当一个新的、未标记的数据点 $\mathbf{x}$ 出现时，[最小距离分类器](@entry_id:1127934)会计算 $\mathbf{x}$ 到每一个类别[质心](@entry_id:138352) $\boldsymbol{\mu}_k$ 的距离，并将其分配给距离最近的那个类别。如果使用[欧几里得距离](@entry_id:143990)，决策规则可以形式化为：

$$
k^* = \arg\min_{k \in \{1, \dots, K\}} \|\mathbf{x} - \boldsymbol{\mu}_k\|_2
$$

其中 $\|\cdot\|_2$ 表示[欧几里得范数](@entry_id:172687)。在实践中，为了简化计算，通常使用平方欧几里得距离 $\|\mathbf{x} - \boldsymbol{\mu}_k\|_2^2$ 进行比较。由于平方运算是单调递增的，这不会改变最终的[分类结果](@entry_id:924005) 。

为了更具体地理解这个过程，考虑一个三波段遥感数据[分类问题](@entry_id:637153)，其中有三个地物类别：水体、植被和土壤。假设通过训练数据估计得到的类别[质心](@entry_id:138352)（单位为无量纲[反射率](@entry_id:172768)）如下：
- 水体: $\boldsymbol{\mu}_{\mathrm{W}} = (0.05, 0.04, 0.08)$
- 植被: $\boldsymbol{\mu}_{\mathrm{V}} = (0.04, 0.06, 0.42)$
- 土壤: $\boldsymbol{\mu}_{\mathrm{S}} = (0.10, 0.12, 0.20)$

现在，我们有一个待分类的像素，其[反射率](@entry_id:172768)向量为 $\mathbf{x} = (0.07, 0.09, 0.22)$。我们可以计算 $\mathbf{x}$ 到每个[质心](@entry_id:138352)的平方欧几里得距离：
- $d^2(\mathbf{x}, \boldsymbol{\mu}_{\mathrm{W}}) = (0.07-0.05)^2 + (0.09-0.04)^2 + (0.22-0.08)^2 = 0.0225$
- $d^2(\mathbf{x}, \boldsymbol{\mu}_{\mathrm{V}}) = (0.07-0.04)^2 + (0.09-0.06)^2 + (0.22-0.42)^2 = 0.0418$
- $d^2(\mathbf{x}, \boldsymbol{\mu}_{\mathrm{S}}) = (0.07-0.10)^2 + (0.09-0.12)^2 + (0.22-0.20)^2 = 0.0022$

由于 $\mathbf{x}$ 到土壤[质心](@entry_id:138352)的距离最小（$0.0022$），该像素将被分类为土壤 。

从几何角度看，[最小距离分类器](@entry_id:1127934)在特征空间中构建了非常独特的决策区域。任意两个类别（例如 $\omega_i$ 和 $\omega_j$）之间的**决策边界 (decision boundary)** 是[特征空间](@entry_id:638014)中所有与这两个类别[质心](@entry_id:138352) $\boldsymbol{\mu}_i$ 和 $\boldsymbol{\mu}_j$ 等距的点的集合。该边界的方程为 $\|\mathbf{x} - \boldsymbol{\mu}_i\|_2 = \|\mathbf{x} - \boldsymbol{\mu}_j\|_2$，展开后可以简化为一个关于 $\mathbf{x}$ 的线性方程：

$$
\mathbf{x}^{\top}(\boldsymbol{\mu}_i - \boldsymbol{\mu}_j) = \frac{1}{2}\left(\|\boldsymbol{\mu}_i\|_{2}^{2} - \|\boldsymbol{\mu}_j\|_{2}^{2}\right)
$$

这个方程定义了一个**[超平面](@entry_id:268044) (hyperplane)**，它是连接两个[质心](@entry_id:138352) $\boldsymbol{\mu}_i$ 和 $\boldsymbol{\mu}_j$ 的线段的垂直平分面。所有这些成对的超平面将整个特征空间 $\mathbb{R}^d$ 划分为 $K$ 个[凸多面体](@entry_id:170947)区域。每个区域包含了所有离其内部[质心](@entry_id:138352)最近的点。这种空间划分被称为**[沃罗诺伊图](@entry_id:263046) (Voronoi tessellation)**。因此，[最小距离分类器](@entry_id:1127934)的决策区域构成了一个[沃罗诺伊图](@entry_id:263046)，其中每个类别对应一个[凸多面体](@entry_id:170947)单元。这个划分是完备的，即空间中的每个点都会被分配到一个类别，不存在未分类的间隙 。

#### 理论联系与适用性

尽管[最小距离分类器](@entry_id:1127934)在其应用中是非[参数化](@entry_id:265163)的（因为它不直接估计PDF），但它与[贝叶斯决策理论](@entry_id:909090)有着深刻的联系。可以证明，在满足以下三个高度限制性的**[参数化](@entry_id:265163)假设**时，[最小距离分类器](@entry_id:1127934)等价于最优[贝叶斯分类器](@entry_id:180656)：
1.  所有类别的类[条件概率密度函数](@entry_id:190422) $p(\mathbf{x}|\omega_k)$ 都是多元高斯分布。
2.  所有类别具有相同的先验概率，即 $\pi_k$ 为常数。
3.  所有类别具有相同且各向同性（球形）的[协方差矩阵](@entry_id:139155)，即 $\boldsymbol{\Sigma}_k = \sigma^2 \mathbf{I}$，其中 $\mathbf{I}$ 是[单位矩阵](@entry_id:156724) 。

这个理论联系揭示了[最小距离分类器](@entry_id:1127934)的内在假设和局限性。它隐式地假设所有类别的数据簇在特征空间中都是大致**球形 (spherical)** 且大小相近的。当这个假设成立时（例如，用于分类方差相似且波段间相关性弱的紧凑类别，如“明亮的城市表面”），[最小距离分类器](@entry_id:1127934)表现良好 。

然而，它的一个主要缺点是对特征的尺度非常敏感。欧几里得距离的计算会赋予具有较大数值范围或较高方差的波段更大的权重。因此，在使用[最小距离分类器](@entry_id:1127934)之前，对数据进行[标准化](@entry_id:637219)（例如，将每个波段缩放到零均值和单位方差）是至关重要的预处理步骤 。此外，如果类别的数据簇是拉长的（即波段间存在强相关性），或者是大小差异很大的非球形簇，[最小距离分类器](@entry_id:1127934)的线性[决策边界](@entry_id:146073)将无法很好地拟[合数](@entry_id:263553)据，导致分类精度下降。

### 平行六面体分类器

平行六面体分类器是另一种简单而快速的非[参数化](@entry_id:265163)方法，它不使用点状的原型，而是为每个类别定义一个多维的“盒子”或**超矩形 (hyperrectangle)** 作为其接纳区域。

#### 核心机制与几何解释

该分类器的核心机制是为每个类别 $\omega_k$ 和每个特征维度（即光谱波段）$j$ 定义一个[上界](@entry_id:274738) $u_{kj}$ 和一个下界 $l_{kj}$。一个待分类的像素 $\mathbf{x}$ 被判定为属于类别 $\omega_k$，当且仅当它的每个分量 $x_j$ 都落在对应类别的所有波段界限之内，即：

$$
l_{kj} \le x_j \le u_{kj} \quad \text{for all } j \in \{1, \dots, d\}
$$

这些界限通常直接从训练数据中凭经验确定。最直接的非[参数化](@entry_id:265163)方法是为每个类别和每个波段，将下界和上界分别设置为训练样本中的最小值和最大值 。这种方法直接估计了该类别在每个维度上的经验支撑集，而无需任何关于[概率密度函数](@entry_id:140610)形式的假设。

从几何上看，这个决策规则为每个类别定义了一个与坐标轴对齐的超矩形（在二维空间中是矩形，三维空间中是长方体），在遥感文献中通常称为**平行六面体 (parallelepiped)**。这个接纳区域 $\mathcal{B}_k$ 是所有满足上述条件的点的集合，可以表示为一维[闭区间](@entry_id:136474)的[笛卡尔积](@entry_id:154642)：

$$
\mathcal{B}_k = \prod_{j=1}^{d}[l_{kj}, u_{kj}]
$$

每个这样的超矩形本身都是一个**[凸集](@entry_id:155617) (convex set)** 。

#### 关键挑战：间隙与重叠

与将整个空间完全划分的[最小距离分类器](@entry_id:1127934)不同，平行六面体分类器的决策区域既不是**[互斥](@entry_id:752349)的 (mutually exclusive)** 也不是**详尽的 (exhaustive)**。这导致了两个核心挑战：

1.  **重叠 (Overlap)**：不同类别的训练数据范围在某些波段上可能会重叠，导致它们的“盒子”在特征空间中相交。落入这个重叠区域的像素将同时满足多个类别的接纳标准，从而产生**分类模糊性 (ambiguity)**。
2.  **间隙 (Gaps)**：所有类别的“盒子”的并集通常不会覆盖整个[特征空间](@entry_id:638014)。落在所有盒子之外的像素将不会被分配任何类别，成为**未分类 (unclassified)** 像素。

这两个问题是平行六面体分类器的标志性弱点 。然而，“间隙”的存在有时也被视为一个有用的特性。当我们需要一个保守的分类策略，宁愿对没有把握的像素放弃分类，也不愿错误地将其分配给某个类别时，这种固有的“拒绝选项”就变得很有价值 。

#### 高级主题：解决分类模糊性

虽然分类模糊性是一个问题，但我们可以通过更高级的决策理论来系统地解决它。当一个像素 $\mathbf{x}$ 落入多个类别（例如，类别集合 $\mathcal{S}(\mathbf{x})$）的重叠区域时，我们可以引入一个基于风险最小化的决策规则 。

一个严谨的方法是，在与平行六面体模型兼容的非[参数化](@entry_id:265163)框架下，为每个类别 $\omega_n$ 估计其[后验概率](@entry_id:153467) $P(\omega_n|\mathbf{x})$。最自然且一致的假设是，在每个类别的接纳区域 $\mathcal{B}_n$ 内部，其类[条件概率密度](@entry_id:265457)是均匀的，而在区域外部则为零。这意味着 $p(\mathbf{x}|\omega_n)$ 与 $\mathcal{B}_n$ 的体积 $V_n$ 的倒数成正比，即 $p(\mathbf{x}|\omega_n) \propto 1/V_n$。

结合先验概率 $\pi_n$，我们可以得到在重叠区域中每个候选类别的后验概率。在对称[0-1损失函数](@entry_id:173640)下，风险最小化等价于选择后验概率最大的类别（MAP法则）。这导出了一个非常简洁的决策规则：对于一个模糊的像素，将其分配给**先验概率密度 ($\pi_n / V_n$)** 最大的那个类别。

$$
k^* = \arg\max_{n \in \mathcal{S}(\mathbf{x})} \frac{\pi_n}{V_n}
$$

这个规则直观地告诉我们，应该选择那个将其先验概率“更集中地”分布在更小空间区域内的类别。此外，我们还可以设置一个风险阈值来实现一个明确的拒绝选项：只有当最优选择的预期风险低于某个阈值 $\tau$ 时才接受分类，否则拒绝 。

### 对比分析与高级应用

#### 分类器选择与模型失配

平行六面体和[最小距离分类器](@entry_id:1127934)各自适用于不同类型的类别分布。选择哪种分类器取决于我们对地物光谱特性的先验知识 。

- **平行六面体分类器**非常适合于那些其[光谱特征](@entry_id:1132105)在物理上被各波段独立限制的类别。例如，“深水体”在近红外和短波红外波段由于水的强烈吸收而具有明确的低[反射率](@entry_id:172768)上限，且波段间相关性弱。对这类目标使用平行六面体分类器，其轴对齐的盒子是一个合理的几何模型。
- **[最小距离分类器](@entry_id:1127934)**则适用于那些数据簇紧凑且大致呈球形的类别，例如具有中等方差和弱波段间相关性的“明亮城市表面”。当需要对整个图像进行无遗漏的分类时，它的完备性划分是一个优势。

然而，这两种简单的分类器都难以有效处理**波段间存在强相关性**的类别。例如，“健康植被”的[光谱特征](@entry_id:1132105)在近红外和短波红外波段之间通常表现出强烈的正相关性，使其数据簇在特征空间中形成一个倾斜的、拉长的椭球体。无论是轴对齐的盒子还是基于[欧几里得距离](@entry_id:143990)的球形区域，都无法很好地拟合这种形状，从而导致大量的错分或漏分。

#### 处理相关性：[主成分分析](@entry_id:145395)的作用

平行六面体分类器的一个主要弱点是它无法处理波段间的相关性，因为它对每个波段独立进行阈值判断，这使得它对特征轴的旋转非常敏感 。幸运的是，我们可以通过[数据预处理](@entry_id:197920)来克服这个限制。

一个标准的技术是首先对数据应用**主成分分析 (Principal Component Analysis, PCA)**。PCA是一种特征变换，它将原始坐标系旋转，使得新的坐标轴（主成分）与数据方差最大的方向对齐。对于一个具有强相关性的类别（如植被），第一个主成分通常会与数据簇的拉长方向对齐。在这个新的、旋转后的坐标系中，数据变得不相关。

此时，在PCA变换后的空间中定义一个轴对齐的平行六面体，就能够非常有效地框定原本倾斜的数据簇。这个在PCA空间中的轴对齐盒子，对应于原始空间中一个**倾斜的盒子**，它能更好地拟合相关数据的几何形状 。

这种方法不仅在几何上更优越，而且可以显著提高分类性能。例如，对于一个具有相关系数 $\rho$ 的二维类别，其在原始坐标系中的平行六面体接纳区域面积为 $A_{orig}$。在PCA空间中定义一个尺寸相当的平行六面体，其在原始空间中的对应面积会减小为 $A_{PCA} = A_{orig}\sqrt{1-\rho^2}$。这意味着当 $\rho \neq 0$ 时，接纳区域的面积变小了。在一个均匀分布的背景噪声下，更小的接纳区域意味着更低的**虚警概率 (false acceptance probability)** 。

#### 偏差-方差权衡与[维度灾难](@entry_id:143920)

非[参数化](@entry_id:265163)分类器的选择也涉及到机器学习中一个核心的权衡：**偏差-方差权衡 (bias-variance tradeoff)** 。
- **高偏差 (High Bias)**：最小距离和和行六面体分类器都属于简单模型。它们对类别分布的几何形状做了很强的（通常是错误的）假设（球形或轴对齐的盒子），这种系统性的模型失配是“偏差”的来源。
- **低方差 (Low Variance)**：由于模型简单，需要估计的参数很少（[质心](@entry_id:138352)或边界），因此它们的决策边界对于训练数据的微小扰动不敏感。这使得它们在训练样本有限（例如 $n_k$ 与维度 $d$ 相当）或数据存在[重尾](@entry_id:274276)噪声时表现得比较**稳健 (robust)**。

相比之下，一个复杂的[参数化](@entry_id:265163)模型（如具有完整[协方差矩阵](@entry_id:139155)的高斯分类器）偏差较低（如果模型假设正确），但方差很高，因为它需要估计大量的参数。当训练样本不足时，这些参数的估计会非常不稳定，导致分类性能急剧下降。

然而，当处理高维数据（如高光谱图像）时，这些简单的非[参数化](@entry_id:265163)方法也会面临所谓的**维度灾难 (curse of dimensionality)** 。
- 对于**平行六面体分类器**，随着维度 $d$ 的增加，一个数据点同时满足所有 $d$ 个波段区间的概率会呈指数级下降（例如 $\alpha^d$）。为了维持一个恒定的接纳率，必须放宽每个波段的阈值，但这会导致接纳区域的体积呈爆炸式增长，从而极大地增加了错误地将背景像素纳入的概率。
- 对于**[最小距离分类器](@entry_id:1127934)**，随着维度 $d$ 的增加，来自少数信息波段的“信号”（即类别均值之间的差异）会被大量非信息波段累积的“噪声”（即数据自身方差和[质心估计](@entry_id:905018)误差）所淹没。结果是，任何一个数据点到所有不同类别[质心](@entry_id:138352)的距离都变得几乎相等。决策的[信噪比](@entry_id:271861)会随着 $d$ 的增加而衰减（大约按 $1/\sqrt{d}$ 的速率），分类器的性能最终会趋向于随机猜测。

因此，尽管非[参数化](@entry_id:265163)分类器在低维空间中具有简单和稳健的优点，但在高维空间中，必须谨慎使用它们，并通常需要结合[特征选择](@entry_id:177971)或维度约减技术（如PCA）来应对维度灾难带来的挑战。