{
    "hands_on_practices": [
        {
            "introduction": "原始的卫星传感器数据，即大气层顶（Top-of-Atmosphere, TOA）辐射率，会受到大气散射和吸收的显著影响。为了进行准确的地物分类，我们必须首先将其转换为地表反射率，这才是地表真实的物理属性。本练习将指导你使用一种常见且高效的方法——预计算的查找表（Look-Up Table, LUT）——来进行大气校正，从而将辐射传输理论与实际应用联系起来。",
            "id": "3860408",
            "problem": "给定一个简化的、物理上一致的大气校正设置，用于无源光学遥感中的单个光谱波段。目标是为一个已知大气层顶 (TOA) 辐亮度 $L_\\lambda^{TOA}$ 的像素计算波长 $\\lambda$ 处的双向反射因子 $\\rho_\\lambda$，这需要通过从查找表 (LUT) 中插值总大气透过率 $T_\\lambda$ 来实现，然后通过偏导数 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 来量化 $\\rho_\\lambda$ 对气溶胶光学厚度的局部敏感度。插值必须在气溶胶光学厚度 $\\tau_a$、水汽柱含量 $w$ 和太阳天顶角 $\\theta_s$ 上进行三线性插值。\n\n基本原理：\n- 在朗伯近似下，双向反射因子 $\\rho_\\lambda$ 由辐亮度与辐照度之间的关系定义：\n$$\n\\rho_\\lambda \\equiv \\frac{\\pi\\,L_\\lambda}{E_\\lambda^{d}},\n$$\n其中 $L_\\lambda$ 是离开地表的辐亮度，$E_\\lambda^{d}$ 是地表的下行辐照度。\n- 对于在平面平行大气中、单次散射且路径辐亮度可忽略不计的近似下的TOA测量，$L_\\lambda^{TOA}$ 会被上行透过率衰减，而地表辐照度则被下行透过率衰减。记下行和上行透过率的乘积为 $T_\\lambda$，并将地外太阳辐照度 $E_{0,\\lambda}$ 作为大气层顶的辐照度，我们使用经过充分检验的关系式 $E_\\lambda^{d} = E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda$，并在所述近似下将 $L_\\lambda^{TOA}$ 视为地表出射辐亮度乘以向上透过率的代理。这样得到工作公式：\n$$\n\\rho_\\lambda = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda}.\n$$\n\n用于LUT合成的大气透过率模型：\n- 总透过率 $T_\\lambda$ 通过比尔-朗伯定律和斜路径大气质量来建模。设 $m_s \\equiv \\sec\\theta_s$ 为太阳大气质量，$m_v \\equiv \\sec\\theta_v$ 为传感器视场大气质量。考虑天底观测，即 $\\theta_v = 0^\\circ$，因此 $m_v = 1$。则\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left(-m_s\\left(\\alpha_\\lambda\\,\\tau_a + k_{\\lambda,d}\\,w + \\tau_{R,\\lambda,d}\\right) - m_v\\left(\\beta_\\lambda\\,\\tau_a + k_{\\lambda,u}\\,w + \\tau_{R,\\lambda,u}\\right)\\right),\n$$\n其中 $\\alpha_\\lambda$、$\\beta_\\lambda$ 分别代表下行和上行路径的气溶胶消光权重，$k_{\\lambda,d}$ 和 $k_{\\lambda,u}$ 代表下行和上行路径的有效水汽消光系数，$\\tau_{R,\\lambda,d}$ 和 $\\tau_{R,\\lambda,u}$ 分别代表下行和上行路径的瑞利光学厚度贡献。\n\n给定波段用于LUT合成的常数：\n- $\\alpha_\\lambda = 0.3$, $\\beta_\\lambda = 0.15$,\n- $k_{\\lambda,d} = 0.004$, $k_{\\lambda,u} = 0.002$,\n- $\\tau_{R,\\lambda,d} = 0.02$, $\\tau_{R,\\lambda,u} = 0.01$,\n- $\\theta_v = 0^\\circ$ 因此 $m_v = 1$。\n\n定义LUT的网格：\n- 气溶胶光学厚度网格（无量纲）：$\\tau_a \\in \\{\\,0.0,\\,0.2,\\,0.5,\\,1.0\\,\\}$，\n- 水汽柱含量网格（单位：厘米可降水量）：$w \\in \\{\\,0.5,\\,1.5,\\,3.0,\\,5.0\\,\\}$，\n- 太阳天顶角网格（单位：度）：$\\theta_s \\in \\{\\,0,\\,30,\\,60,\\,75\\,\\}$。\n\n地外太阳辐照度：\n- 使用 $E_{0,\\lambda} = 1850$，单位为 W·m$^{-2}$·µm$^{-1}$。\n\n单位和角度约定：\n- 辐亮度 $L_\\lambda^{TOA}$ 必须以 W·m$^{-2}$·sr$^{-1}$·µm$^{-1}$ 为单位提供。\n- 水汽柱含量 $w$ 必须以厘米可降水量为单位提供。\n- 气溶胶光学厚度 $\\tau_a$ 是无量纲的。\n- 太阳天顶角 $\\theta_s$ 必须以度为单位指定；内部计算三角函数时需要转换为弧度。\n- 反射率 $\\rho_\\lambda$ 是无量纲的。\n- 敏感度 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 是无量纲的，单位为每单位气溶胶光学厚度。\n- 输入时所有角度均以度表示；在内部计算 $\\cos\\theta_s$ 和 $\\sec\\theta_s$ 时使用弧度。\n\n敏感度定义：\n- 使用链式法则，在给定状态 $(\\tau_a, w, \\theta_s)$ 下的敏感度为\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = -\\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s}\\,\\frac{1}{T_\\lambda(\\tau_a,w,\\theta_s)^2}\\,\\frac{\\partial T_\\lambda}{\\partial \\tau_a},\n$$\n其中 $\\partial T_\\lambda/\\partial \\tau_a$ 的获取必须与LUT插值方法一致。为确保对LUT构造的通用性，通过对插值函数 $T_\\lambda(\\tau_a,w,\\theta_s)$ 应用有限差分来数值计算 $\\partial T_\\lambda/\\partial \\tau_a$，在 $\\tau_a$ 轴上使用一个小的步长 $\\delta\\tau_a$：\n- 如果 $\\tau_a$ 严格位于查找表域内部，使用步长为 $\\delta\\tau_a$ 的中心差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{2\\,\\delta\\tau_a}.\n$$\n- 如果 $\\tau_a$ 位于下边界，使用前向差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a,w,\\theta_s)}{\\delta\\tau_a}.\n$$\n- 如果 $\\tau_a$ 位于上边界，使用后向差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{\\delta\\tau_a}.\n$$\n选择 $\\delta\\tau_a = 10^{-3}$。\n\n算法要求：\n- 使用提供的常数和比尔-朗伯表达式，在指定的网格上计算 $T_\\lambda(\\tau_a,w,\\theta_s)$ 来合成LUT。在规则网格上使用三线性插值法对任意 $(\\tau_a,w,\\theta_s)$ 处的 $T_\\lambda$ 进行插值。\n- 对于每个测试案例，使用插值得到的 $T_\\lambda$ 计算 $\\rho_\\lambda$，并如上所述，通过对插值得到的 $T_\\lambda$ 应用关于 $\\tau_a$ 的有限差分来计算 $\\partial \\rho_\\lambda / \\partial \\tau_a$。\n\n测试套件：\n提供以下五个测试案例的结果，每个案例以元组 $(L_\\lambda^{TOA}, \\tau_a, w, \\theta_s)$ 的形式给出，单位和约定如前所述：\n- 案例 1：$(80.0,\\;0.3,\\;2.0,\\;40)$，\n- 案例 2：$(50.0,\\;0.0,\\;1.0,\\;0)$，\n- 案例 3：$(30.0,\\;1.0,\\;5.0,\\;75)$，\n- 案例 4：$(60.0,\\;0.5,\\;4.0,\\;60)$，\n- 案例 5：$(70.0,\\;0.2,\\;1.5,\\;30)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个列表的列表形式的结果，其中每个内部列表包含两个浮点数 $[\\rho_\\lambda,\\;\\partial \\rho_\\lambda/\\partial \\tau_a]$，对应一个测试案例，顺序与上面指定的一致。例如，输出应具有以下形式：\n$$\n\\big[\\, [\\rho_1,\\,d\\rho_1],\\;[\\rho_2,\\,d\\rho_2],\\;[\\rho_3,\\,d\\rho_3],\\;[\\rho_4,\\,d\\rho_4],\\;[\\rho_5,\\,d\\rho_5]\\,\\big],\n$$\n其中符号条目将被数值替换。",
            "solution": "该问题要求针对一组给定的大气和观测条件，计算地表双向反射因子 $\\rho_\\lambda$ 及其对气溶胶光学厚度的敏感度 $\\partial \\rho_\\lambda / \\partial \\tau_a$。该方法基于一个简化的大气辐射传输模型，其中总大气透过率 $T_\\lambda$ 被预先计算并存储在查找表 (LUT) 中。然后，该LUT用于对任意条件下的 $T_\\lambda$ 进行快速插值，并从中推导出 $\\rho_\\lambda$ 及其导数。整个过程概述如下。\n\n**步骤 1：透过率查找表 (LUT) 的合成**\n\n该方法的基础是准确高效地计算总大气透过率 $T_\\lambda$。问题提供了一个基于物理的比尔-朗伯定律的 $T_\\lambda$ 模型，该定律描述了光在穿过介质时的衰减。总透过率由太阳到地表路径和地表到传感器路径的透过率乘积给出。它是三个变量的函数：气溶胶光学厚度 ($\\tau_a$)、水汽柱含量 ($w$) 和太阳天顶角 ($\\theta_s$)。\n\n该模型表示为：\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left(-m_s\\left(\\alpha_\\lambda\\,\\tau_a + k_{\\lambda,d}\\,w + \\tau_{R,\\lambda,d}\\right) - m_v\\left(\\beta_\\lambda\\,\\tau_a + k_{\\lambda,u}\\,w + \\tau_{R,\\lambda,u}\\right)\\right)\n$$\n其中 $m_s = \\sec\\theta_s$ 是太阳大气质量，$m_v = \\sec\\theta_v$ 是传感器视场大气质量。问题指定了天底观测传感器，此时 $\\theta_v = 0^\\circ$，因此 $m_v = 1$。给定的光谱波段 $\\lambda$ 的常数如下：$\\alpha_\\lambda = 0.3$，$\\beta_\\lambda = 0.15$，$k_{\\lambda,d} = 0.004$，$k_{\\lambda,u} = 0.002$，$\\tau_{R,\\lambda,d} = 0.02$，以及 $\\tau_{R,\\lambda,u} = 0.01$。\n\n代入这些值，需要使用的特定透过率函数为：\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left( - \\frac{1}{\\cos\\theta_s} \\left(0.3\\,\\tau_a + 0.004\\,w + 0.02\\right) - \\left(0.15\\,\\tau_a + 0.002\\,w + 0.01\\right) \\right)\n$$\n必须注意的是，三角函数 $\\cos\\theta_s$ 的计算必须使用弧度制的 $\\theta_s$。\n\nLUT是通过在三维网格的每个节点上计算该 $T_\\lambda$ 函数来构建的。网格轴由给定的值集定义：\n- 气溶胶光学厚度：$\\tau_a \\in \\{\\,0.0,\\,0.2,\\,0.5,\\,1.0\\,\\}$\n- 水汽柱含量：$w \\in \\{\\,0.5,\\,1.5,\\,3.0,\\,5.0\\,\\}$\n- 太阳天顶角：$\\theta_s \\in \\{\\,0,\\,30,\\,60,\\,75\\,\\}$ 度\n\n这将生成一个 $4 \\times 4 \\times 4$ 的LUT，用于存储 $T_\\lambda$ 的值。\n\n**步骤 2：透过率 $T_\\lambda$ 的三线性插值**\n\n对于一个具有任意参数 $(\\tau_{a,q}, w_q, \\theta_{s,q})$ 的测试案例，相应的透过率 $T_\\lambda$ 必须从LUT中的离散值进行插值。指定的方法是三线性插值。此方法将查询点视为位于一个由最近的8个网格点定义的直线网格单元（长方体）内。插值结果是这8个角点值的加权平均，权重由该点在长方体内的相对位置决定。\n\n设查询点为 $(x_q, y_q, z_q)$，其周围的网格单元由角点 $(x_i, y_j, z_k)$ 和 $(x_{i+1}, y_{j+1}, z_{k+1})$ 定义。首先，我们确定查询点沿每个轴的分数距离：\n$$\nd_x = \\frac{x_q - x_i}{x_{i+1} - x_i}, \\quad d_y = \\frac{y_q - y_j}{y_{j+1} - y_j}, \\quad d_z = \\frac{z_q - z_k}{z_{k+1} - z_k}\n$$\n然后通过一系列线性插值找到查询点的值 $V$。例如，可以先在 $y-z$ 平面内单元格底部的四个角点沿 $x$ 轴进行插值，然后将这四个结果沿 $y$ 轴插值得到两个值，最后将这两个值沿 $z$ 轴进行插值。在计算上，即使网格间距不均匀（如此处的情况），这也可以通过支持在规则网格上进行多变量插值的库来高效处理。\n\n**步骤 3：地表反射率 $\\rho_\\lambda$ 的计算**\n\n一旦获得插值后的透过率 $T_\\lambda(\\tau_{a,q}, w_q, \\theta_{s,q})$，就可以使用提供的简化辐射传输方程计算地表反射率 $\\rho_\\lambda$：\n$$\n\\rho_\\lambda = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda}\n$$\n这里，$L_\\lambda^{TOA}$ 是给定像素的实测大气层顶辐亮度，$E_{0,\\lambda}$ 是地外太阳辐照度，给定值为 $1850$ W·m$^{-2}$·µm$^{-1}$。同前，计算余弦函数时 $\\theta_s$ 必须是弧度。\n\n**步骤 4：反射率敏感度 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 的计算**\n\n最后一步是量化所计算的反射率对气溶胶光学厚度变化的局部敏感度。这由偏导数 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 给出。对 $\\rho_\\lambda$ 的表达式应用链式法则：\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = \\frac{\\partial}{\\partial \\tau_a} \\left( \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s} \\cdot T_\\lambda^{-1} \\right) = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s} \\left( -T_\\lambda^{-2} \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\right)\n$$\n通过代入 $\\rho_\\lambda$ 的定义，可以更简洁地表示为：\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = -\\frac{\\rho_\\lambda}{T_\\lambda} \\frac{\\partial T_\\lambda}{\\partial \\tau_a}\n$$\n透过率的导数 $\\partial T_\\lambda / \\partial \\tau_a$ 是通过对*插值后*的透过率函数应用有限差分格式来数值计算的。格式的选择取决于查询点 $\\tau_{a,q}$ 相对于 $\\tau_a$ 网格边界 $[0.0, 1.0]$ 的位置。使用一个小的扰动 $\\delta\\tau_a = 10^{-3}$。\n\n- 如果 $\\tau_{a,q}$ 是一个内部点 ($0.0  \\tau_{a,q}  1.0$)，使用二阶精度的中心差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{2\\,\\delta\\tau_a}\n    $$\n- 如果 $\\tau_{a,q}$ 位于下边界 ($\\tau_{a,q} = 0.0$)，需要使用一阶前向差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a,w,\\theta_s)}{\\delta\\tau_a}\n    $$\n- 如果 $\\tau_{a,q}$ 位于上边界 ($\\tau_{a,q} = 1.0$)，使用一阶后向差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{\\delta\\tau_a}\n    $$\n这些公式中每一次对 $T_\\lambda$ 的求值都是通过步骤2中建立的三线性插值函数完成的。确定了 $\\partial T_\\lambda / \\partial \\tau_a$ 后，便可轻易计算出最终的敏感度 $\\partial \\rho_\\lambda / \\partial \\tau_a$。这便完成了整个规定的算法。",
            "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import RegularGridInterpolator\n\ndef solve():\n    \"\"\"\n    Computes surface reflectance and its sensitivity to aerosol optical thickness\n    using a LUT-based atmospheric correction approach.\n    \"\"\"\n\n    # --- Problem Constants ---\n    # Atmospheric model parameters\n    ALPHA_LAMBDA = 0.3\n    BETA_LAMBDA = 0.15\n    K_LAMBDA_D = 0.004\n    K_LAMBDA_U = 0.002\n    TAU_R_LAMBDA_D = 0.02\n    TAU_R_LAMBDA_U = 0.01\n\n    # View geometry\n    THETA_V_DEG = 0.0\n    M_V = 1.0 / np.cos(np.deg2rad(THETA_V_DEG)) # sec(theta_v)\n\n    # Solar irradiance\n    E0_LAMBDA = 1850.0\n\n    # Finite difference step for sensitivity\n    DELTA_TAU_A = 1e-3\n\n    # --- LUT Grid Definition ---\n    TAU_A_GRID = np.array([0.0, 0.2, 0.5, 1.0])\n    W_GRID = np.array([0.5, 1.5, 3.0, 5.0])\n    THETA_S_GRID = np.array([0.0, 30.0, 60.0, 75.0])\n    GRIDS = (TAU_A_GRID, W_GRID, THETA_S_GRID)\n    \n    # --- Test Cases ---\n    test_cases = [\n        # (L_toa, tau_a, w, theta_s)\n        (80.0, 0.3, 2.0, 40.0),\n        (50.0, 0.0, 1.0, 0.0),\n        (30.0, 1.0, 5.0, 75.0),\n        (60.0, 0.5, 4.0, 60.0),\n        (70.0, 0.2, 1.5, 30.0),\n    ]\n\n    def transmittance_model(tau_a, w, theta_s_deg):\n        \"\"\"\n        Calculates atmospheric transmittance based on the provided model.\n        \"\"\"\n        # Convert solar zenith angle to radians for trig functions\n        theta_s_rad = np.deg2rad(theta_s_deg)\n        # Handle the case theta_s = 90 deg, though not in grid\n        cos_theta_s = np.cos(theta_s_rad)\n        if np.isclose(cos_theta_s, 0):\n            # Physical limit, transmittance is zero\n            return 0.0\n        m_s = 1.0 / cos_theta_s  # sec(theta_s)\n        \n        downwelling_exponent = m_s * (ALPHA_LAMBDA * tau_a + K_LAMBDA_D * w + TAU_R_LAMBDA_D)\n        upwelling_exponent = M_V * (BETA_LAMBDA * tau_a + K_LAMBDA_U * w + TAU_R_LAMBDA_U)\n        \n        total_exponent = downwelling_exponent + upwelling_exponent\n        \n        return np.exp(-total_exponent)\n\n    def synthesize_lut(grids):\n        \"\"\"\n        Generates the 3D LUT for transmittance.\n        \"\"\"\n        tau_grid, w_grid, theta_grid = grids\n        lut = np.zeros((len(tau_grid), len(w_grid), len(theta_grid)))\n        \n        for i, tau_a in enumerate(tau_grid):\n            for j, w in enumerate(w_grid):\n                for k, theta_s in enumerate(theta_grid):\n                    lut[i, j, k] = transmittance_model(tau_a, w, theta_s)\n        return lut\n\n    # --- Main Calculation ---\n    \n    # 1. Synthesize the LUT\n    lut_values = synthesize_lut(GRIDS)\n    \n    # 2. Create the trilinear interpolator object\n    interpolator_T = RegularGridInterpolator(GRIDS, lut_values, method='linear')\n\n    results = []\n    for case in test_cases:\n        l_toa, tau_a, w, theta_s = case\n        \n        # 3. Interpolate transmittance T_lambda for the given point\n        query_point = np.array([tau_a, w, theta_s])\n        T_lambda = interpolator_T(query_point)[0]\n\n        # 4. Calculate surface reflectance rho_lambda\n        cos_theta_s = np.cos(np.deg2rad(theta_s))\n        rho_lambda = (np.pi * l_toa) / (E0_LAMBDA * cos_theta_s * T_lambda)\n        \n        # 5. Calculate sensitivity d(rho)/d(tau_a) via numerical derivative of T_lambda\n        if tau_a == TAU_A_GRID[0]:\n            # Forward difference at lower boundary\n            T_plus = interpolator_T([tau_a + DELTA_TAU_A, w, theta_s])[0]\n            T_center = T_lambda\n            dT_dtau = (T_plus - T_center) / DELTA_TAU_A\n        elif tau_a == TAU_A_GRID[-1]:\n            # Backward difference at upper boundary\n            T_minus = interpolator_T([tau_a - DELTA_TAU_A, w, theta_s])[0]\n            T_center = T_lambda\n            dT_dtau = (T_center - T_minus) / DELTA_TAU_A\n        else:\n            # Centered difference for interior points\n            T_plus = interpolator_T([tau_a + DELTA_TAU_A, w, theta_s])[0]\n            T_minus = interpolator_T([tau_a - DELTA_TAU_A, w, theta_s])[0]\n            dT_dtau = (T_plus - T_minus) / (2 * DELTA_TAU_A)\n            \n        drho_dtau = - (rho_lambda / T_lambda) * dT_dtau\n        \n        results.append([rho_lambda, drho_dtau])\n        \n    # --- Final Output ---\n    # Convert list of lists to the required string format\n    # The default string representation of a list of lists matches the desired output format\n    print(str(results).replace(\" \", \"\"))\n\n# We call the main function to execute the logic.\n# The problem template had this structure, but we will call it directly\n# for cleaner scoping according to standard Python practices. The solve()\n# function encapsulates all logic and can be called from the global scope.\n# After further checks, the requested output format is `[[v1,v2],[v3,v4]...]` without spaces\n# `str(results).replace(\" \", \"\")` achieves this robustly.\nsolve()\n```"
        },
        {
            "introduction": "在生成了多种光谱和纹理特征之后，我们常常会面临“维度灾难”的问题。主成分分析（Principal Component Analysis, PCA）是一种强大的技术，它可以在保留大部分数据方差的同时减少特征数量。本练习不仅涉及应用PCA，更重要的是，它要求你批判性地评估降维对类别可分性的影响，从而学会在模型复杂性与分类性能之间做出权衡。",
            "id": "3860432",
            "problem": "您将获得带标签的特征矩阵，这些矩阵代表用于土地覆盖图像分类的遥感观测数据。您的任务是使用主成分分析 (PCA) 实现图像分类工作流中的降维和重构阶段，然后量化因降维导致的类别可分性信息损失。您的推导和算法必须基于以下基本定义和广为接受的公式。\n\n基本原理：\n- 主成分分析 (PCA)：给定一个标准化的数据矩阵 $Z \\in \\mathbb{R}^{n \\times d}$，其中包含 $n$ 个样本和 $d$ 个特征，样本协方差矩阵为 $$C = \\frac{1}{n-1} Z^\\top Z.$$ PCA 寻找 $C$ 的标准正交特征向量及其对应的特征值。如果 $C P = P \\Lambda$，其中 $P \\in \\mathbb{R}^{d \\times d}$ 的列是特征向量，$\\Lambda \\in \\mathbb{R}^{d \\times d}$ 是对角矩阵且对角线元素为非负特征值，那么第 $i$ 个主成分的解释方差是 $\\Lambda$ 的第 $i$ 个对角元素。前 $k$ 个主成分的累计解释方差率为 $$r_k = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{d} \\lambda_i},$$ 其中特征值按非递增顺序排序，$\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$。\n- 从顶部主成分重构：设 $P_k \\in \\mathbb{R}^{d \\times k}$ 是由前 $k$ 个特征向量组成的矩阵。投影分数为 $$T_k = Z P_k,$$ 在标准化空间中的秩为 $k$ 的重构为 $$\\hat{Z} = T_k P_k^\\top.$$ 如果 $k = 0$，则定义 $P_0$ 为空矩阵，$\\hat{Z}$ 为形状为 $n \\times d$ 的零矩阵。\n- Fisher 类散度比用于度量可分性：给定类别标签 $y \\in \\{0, 1, \\dots\\}$，定义总体均值 $$\\mu = \\frac{1}{n} \\sum_{i=1}^n z_i,$$ 以及每个类别 $c$ 的均值 $$\\mu_c = \\frac{1}{n_c} \\sum_{i \\in \\mathcal{I}_c} z_i,$$ 其中 $\\mathcal{I}_c$ 是类别 $c$ 中样本的索引集，$n_c = |\\mathcal{I}_c|$。定义类内散度迹 $$\\mathrm{tr}(S_W) = \\sum_{c} \\sum_{i \\in \\mathcal{I}_c} \\| z_i - \\mu_c \\|_2^2,$$ 和类间散度迹 $$\\mathrm{tr}(S_B) = \\sum_{c} n_c \\| \\mu_c - \\mu \\|_2^2.$$ Fisher 可分性判据为 $$J = \\frac{\\mathrm{tr}(S_B)}{\\mathrm{tr}(S_W)}.$$ 如果 $\\mathrm{tr}(S_W) = 0$，为避免除以零，定义 $J = 0$。\n- 因重构导致的信息损失：对于原始标准化特征 $Z$ 和重构后的标准化特征 $\\hat{Z}$，将信息损失定义为 $J$ 的相对下降值：$$L = \\begin{cases} \\max\\left(0, \\dfrac{J(Z) - J(\\hat{Z})}{J(Z)} \\right),  \\text{if } J(Z)  0, \\\\ 0,  \\text{if } J(Z) = 0. \\end{cases}$$\n\n需要实现的工作流：\n1. 标准化输入矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 的每个特征，以获得均值为零、每个特征的无偏标准差为一的矩阵 $Z$。使用分母为 $(n-1)$ 的样本标准差（即无偏估计量）进行缩放；如果某个特征的标准差为零，则用 1 代替除数以避免除以零。\n2. 计算 $C$，对 $C$ 进行特征分解，按特征值的非递增顺序对特征对进行排序，并计算累计解释方差率 $r_k$。\n3. 给定一个目标方差分数 $t \\in [0, 1]$（以小数形式表示），选择最小的整数 $k \\in \\{0,1,\\dots,d\\}$ 使得 $r_k \\ge t$（使用 $10^{-12}$ 的数值容差来处理浮点数舍入问题）。如果 $t=0$，则令 $k=0$。\n4. 从前 $k$ 个主成分重构 $\\hat{Z}$，计算 $J(Z)$ 和 $J(\\hat{Z})$，然后计算 $L$。\n\n测试套件：\n对于每个测试用例，您将获得 $(X, y, t)$，其中 $X$ 是特征矩阵，$y$ 是类别标签，$t$ 是以小数表示的目标方差分数。\n\n- 测试用例 1（常规路径，中高方差目标）：\n  - $X_1 = \\begin{bmatrix}\n  $0.12$  $0.38$  $0.50$ \\\\\n  $0.10$  $0.35$  $0.48$ \\\\\n  $0.15$  $0.40$  $0.52$ \\\\\n  $0.30$  $0.55$  $0.60$ \\\\\n  $0.28$  $0.50$  $0.58$ \\\\\n  $0.32$  $0.57$  $0.62$\n  \\end{bmatrix}$，\n  $y_1 = [$0$, $0$, $0$, $1$, $1$, $1$],\n  $t_1 = $0.90$。\n- 测试用例 2（边界情况，全方差目标）：\n  - $X_2 = \\begin{bmatrix}\n  $0.05$  $0.20$ \\\\\n  $0.07$  $0.22$ \\\\\n  $0.50$  $0.45$ \\\\\n  $0.48$  $0.40$ \\\\\n  $0.52$  $0.47$\n  \\end{bmatrix}$，\n  $y_2 = [$0$, $0$, $1$, $1$, $1$],\n  $t_2 = $1.00$。\n- 测试用例 3（边缘情况，零方差目标）：\n  - $X_3 = \\begin{bmatrix}\n  $0.20$  $0.30$  $0.25$  $0.35$ \\\\\n  $0.22$  $0.32$  $0.27$  $0.36$ \\\\\n  $0.18$  $0.28$  $0.24$  $0.33$ \\\\\n  $0.21$  $0.31$  $0.26$  $0.34$ \\\\\n  $0.60$  $0.70$  $0.65$  $0.75$ \\\\\n  $0.62$  $0.68$  $0.64$  $0.74$ \\\\\n  $0.58$  $0.72$  $0.66$  $0.76$ \\\\\n  $0.61$  $0.69$  $0.63$  $0.73$\n  \\end{bmatrix}$，\n  $y_3 = [$0$, $0$, $0$, $0$, $1$, $1$, $1$, $1$],\n  $t_3 = $0.00$。\n- 测试用例 4（共线性情况，低方差分数目标）：\n  - $X_4 = \\begin{bmatrix}\n  $0.10$  $0.20$  $0.30$ \\\\\n  $0.11$  $0.19$  $0.30$ \\\\\n  $0.09$  $0.21$  $0.30$ \\\\\n  $0.40$  $0.50$  $0.90$ \\\\\n  $0.39$  $0.49$  $0.88$ \\\\\n  $0.41$  $0.51$  $0.92$\n  \\end{bmatrix}$，\n  $y_4 = [$0$, $0$, $0$, $1$, $1$, $1$],\n  $t_4 = $0.50$。\n\n计算与输出要求：\n- 对于每个测试用例 $(X, y, t)$，将 $X$ 标准化为 $Z$，计算满足 $r_k \\ge t$ 的最小 $k$，从前 $k$ 个主成分重构 $\\hat{Z}$，计算 $J(Z)$、$J(\\hat{Z})$ 和 $L$。\n- 将所有目标分数表示为小数。本问题不涉及物理单位或角度。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，聚合为一个列表的列表，每个内部列表为 $[k, r_k, J(Z), J(\\hat{Z}), L]$，其中浮点值四舍五入到六位小数，$k$ 为整数。最终输出行必须严格遵循以下格式：\n\"[ [k1,r1,J1,Jhat1,L1],[k2,r2,J2,Jhat2,L2],[k3,r3,J3,Jhat3,L3],[k4,r4,J4,Jhat4,L4] ]\" 使用逗号分隔值，且无额外文本。",
            "solution": "该问题要求针对带标签的特征矩阵，使用主成分分析 (PCA) 实现一个特定的降维工作流，并随后评估关于类别可分性的信息损失。解决方案是通过系统地应用所提供的数据标准化、PCA、数据重构和 Fisher 类可分性判据的定义来推导的。\n\n对于每个测试用例 $(X, y, t)$ 的总体流程如下：\n\n1.  **数据标准化**：初始步骤是将原始特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 转换为标准化矩阵 $Z \\in \\mathbb{R}^{n \\times d}$，其中 $n$ 是样本数，$d$ 是特征数。$Z$ 的每个特征（列）必须具有零均值和为一的无偏样本标准差。对于每个特征 $j \\in \\{1, \\dots, d\\}$，从 $X$ 的相应列 $X_j$ 计算均值 $\\mu_j$ 和无偏样本标准差 $\\sigma_j$：\n    $$ \\mu_j = \\frac{1}{n} \\sum_{i=1}^{n} X_{ij} $$\n    $$ \\sigma_j = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (X_{ij} - \\mu_j)^2} $$\n    然后，标准化特征 $Z_{ij}$ 计算如下：\n    $$ Z_{ij} = \\frac{X_{ij} - \\mu_j}{\\sigma_j} $$\n    根据规定，如果任何 $\\sigma_j = 0$，则用 1 替换以防止除以零。\n\n2.  **主成分分析 (PCA)**：对标准化数据 $Z$ 执行 PCA。计算样本协方差矩阵 $C \\in \\mathbb{R}^{d \\times d}$：\n    $$ C = \\frac{1}{n-1} Z^\\top Z $$\n    接下来，对对称矩阵 $C$ 进行特征分解，以找到其特征值 $\\lambda_i$ 和对应的特征向量 $p_i$。\n    $$ C p_i = \\lambda_i p_i $$\n    特征向量构成矩阵 $P$ 的列。特征对 $(\\lambda_i, p_i)$ 进行排序，使特征值按非递增顺序排列：$\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$。\n\n3.  **成分选择**：要保留的主成分数量 $k$ 由给定的目标方差分数 $t \\in [0, 1]$ 确定。我们计算前 $m$ 个成分的累计解释方差率：\n    $$ r_m = \\frac{\\sum_{i=1}^{m} \\lambda_i}{\\sum_{i=1}^{d} \\lambda_i} $$\n    所选的成分数量 $k$ 是 $\\{0, 1, \\dots, d\\}$ 中满足 $r_k \\ge t$ 的最小整数。对于特殊情况 $t=0$，我们设置 $k=0$。比较 $r_k \\ge t$ 时使用 $10^{-12}$ 的数值容差以考虑浮点计算的不精确性。\n\n4.  **数据重构**：将原始标准化数据 $Z$ 投影到 $k$ 维主子空间上，然后再重构回原始的 $d$ 维空间。设 $P_k \\in \\mathbb{R}^{d \\times k}$ 是其列为前 $k$ 个主特征向量的矩阵。\n    投影分数计算如下：\n    $$ T_k = Z P_k $$\n    然后，重构的标准化数据矩阵 $\\hat{Z}$ 为：\n    $$ \\hat{Z} = T_k P_k^\\top $$\n    如果 $k=0$，重构矩阵 $\\hat{Z}$ 是与 $Z$ 维度相同的零矩阵。\n\n5.  **可分性评估**：使用 Fisher 类可分性判据 $J$ 来量化特征空间中类别的分离程度。对原始标准化数据 $Z$ 和重构数据 $\\hat{Z}$ 都计算此值。\n    该判据是类间散度迹与类内散度迹的比值：\n    $$ J = \\frac{\\mathrm{tr}(S_B)}{\\mathrm{tr}(S_W)} $$\n    迹的计算方式如下：\n    $$ \\mathrm{tr}(S_B) = \\sum_{c} n_c \\| \\mu_c - \\mu \\|_2^2 $$\n    $$ \\mathrm{tr}(S_W) = \\sum_{c} \\sum_{i \\in \\mathcal{I}_c} \\| z_i - \\mu_c \\|_2^2 $$\n    其中 $\\mu$ 是数据的总体均值，$\\mu_c$ 是类别 $c$ 中数据点的均值，$n_c$ 是类别 $c$ 中的样本数量，$\\mathcal{I}_c$ 是类别 $c$ 中样本的索引集。如果 $\\mathrm{tr}(S_W)=0$，则定义 $J$ 为 0。\n\n6.  **信息损失量化**：最后，因降维导致的信息损失 $L$ 被量化为 Fisher 可分性判据 $J$ 的相对下降值。\n    $$ L = \\begin{cases} \\max\\left(0, \\dfrac{J(Z) - J(\\hat{Z})}{J(Z)} \\right),  \\text{if } J(Z) > 0 \\\\ 0,  \\text{if } J(Z) = 0 \\end{cases} $$\n    该值表示在 PCA 重构过程中损失的类别可分性信息的分数。\n\n实现将对问题陈述中提供的每个测试用例应用这六个步骤，并按规定格式化最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing the PCA workflow and calculating\n    the information loss for class separability for each test case.\n    \"\"\"\n    \n    # Test cases defined in the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [0.12, 0.38, 0.50],\n                [0.10, 0.35, 0.48],\n                [0.15, 0.40, 0.52],\n                [0.30, 0.55, 0.60],\n                [0.28, 0.50, 0.58],\n                [0.32, 0.57, 0.62]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1]),\n            0.90\n        ),\n        (\n            np.array([\n                [0.05, 0.20],\n                [0.07, 0.22],\n                [0.50, 0.45],\n                [0.48, 0.40],\n                [0.52, 0.47]\n            ]),\n            np.array([0, 0, 1, 1, 1]),\n            1.00\n        ),\n        (\n            np.array([\n                [0.20, 0.30, 0.25, 0.35],\n                [0.22, 0.32, 0.27, 0.36],\n                [0.18, 0.28, 0.24, 0.33],\n                [0.21, 0.31, 0.26, 0.34],\n                [0.60, 0.70, 0.65, 0.75],\n                [0.62, 0.68, 0.64, 0.74],\n                [0.58, 0.72, 0.66, 0.76],\n                [0.61, 0.69, 0.63, 0.73]\n            ]),\n            np.array([0, 0, 0, 0, 1, 1, 1, 1]),\n            0.00\n        ),\n        (\n            np.array([\n                [0.10, 0.20, 0.30],\n                [0.11, 0.19, 0.30],\n                [0.09, 0.21, 0.30],\n                [0.40, 0.50, 0.90],\n                [0.39, 0.49, 0.88],\n                [0.41, 0.51, 0.92]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1]),\n            0.50\n        )\n    ]\n\n    def compute_j_criterion(data, labels):\n        \"\"\"Computes Fisher's class separability criterion J.\"\"\"\n        n_samples = data.shape[0]\n        if n_samples == 0:\n            return 0.0\n\n        overall_mean = np.mean(data, axis=0)\n        classes = np.unique(labels)\n        \n        tr_S_W = 0.0\n        tr_S_B = 0.0\n\n        for c in classes:\n            class_samples = data[labels == c]\n            n_c = class_samples.shape[0]\n            if n_c == 0:\n                continue\n            \n            class_mean = np.mean(class_samples, axis=0)\n            \n            tr_S_B += n_c * np.sum((class_mean - overall_mean)**2)\n            tr_S_W += np.sum((class_samples - class_mean)**2)\n\n        if tr_S_W  1e-12: # As per problem, if tr(S_W)=0, J=0\n            return 0.0\n        \n        return tr_S_B / tr_S_W\n\n    results = []\n    \n    for X, y, t in test_cases:\n        # Step 1: Standardize the feature matrix\n        n, d = X.shape\n        mean_X = np.mean(X, axis=0)\n        std_X = np.std(X, axis=0, ddof=1)\n        std_X[std_X == 0] = 1.0  # Avoid division by zero\n        Z = (X - mean_X) / std_X\n\n        # Step 2: Perform PCA\n        C = (1 / (n - 1)) * (Z.T @ Z)\n        eigenvalues, eigenvectors = np.linalg.eigh(C)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        sort_indices = np.argsort(eigenvalues)[::-1]\n        sorted_eigenvalues = eigenvalues[sort_indices]\n        sorted_eigenvectors = eigenvectors[:, sort_indices]\n\n        # Step 3: Determine the number of components k\n        total_variance = np.sum(sorted_eigenvalues)\n        if total_variance  1e-12:\n            cumulative_ratios = np.zeros(d)\n        else:\n            cumulative_ratios = np.cumsum(sorted_eigenvalues) / total_variance\n\n        # Select smallest k such that r_k >= t, using a tolerance\n        # and handling the t=0 case.\n        if t  1e-12:\n            k = 0\n        else:\n            k_indices = np.where(cumulative_ratios >= t - 1e-12)[0]\n            if len(k_indices) == 0:\n                k = d  # Take all components if t=1 but ratio is slightly less\n            else:\n                k = k_indices[0] + 1\n        \n        r_k = 0.0 if k == 0 else cumulative_ratios[k - 1]\n\n        # Step 4: Reconstruct the data\n        if k == 0:\n            hat_Z = np.zeros_like(Z)\n        else:\n            P_k = sorted_eigenvectors[:, :k]\n            T_k = Z @ P_k\n            hat_Z = T_k @ P_k.T\n\n        # Step 5: Compute J for original and reconstructed data\n        J_Z = compute_j_criterion(Z, y)\n        J_hat_Z = compute_j_criterion(hat_Z, y)\n\n        # Step 6: Compute the information loss L\n        if J_Z > 1e-12:\n            L = max(0.0, (J_Z - J_hat_Z) / J_Z)\n        else:\n            L = 0.0\n\n        results.append([k, r_k, J_Z, J_hat_Z, L])\n    \n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        k, r_val, j_z, j_hat, l_val = res\n        # Format floats to 6 decimal places, k is an integer\n        formatted_str = f\"[{k},{r_val:.6f},{j_z:.6f},{j_hat:.6f},{l_val:.6f}]\"\n        formatted_results.append(formatted_str)\n        \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "任何分类工作流的最后一步都是评估其精度。然而，简单的总体精度可能会产生误导，尤其是在土地覆盖制图中常见的数据不平衡情况下。本练习挑战你超越基本指标，去计算如平衡精度（Balanced Accuracy）、$F_1$分数（$F_1$-Score）和马修斯相关系数（Matthews Correlation Coefficient, MCC）等更为稳健的性能度量，从而更深刻地理解分类器在多数类和少数类上的真实表现。",
            "id": "3860465",
            "problem": "使用多光谱卫星数据对一沿海湿地复合体进行了有监督的土地覆盖分类。工作流程包括辐射定标、大气校正和正射校正，然后是对光谱和纹理描述符进行特征工程：归一化植被指数(NDVI)、归一化差异水体指数(NDWI)、修正归一化差异水体指数(MNDWI)、缨帽变换湿度分量和灰度共生矩阵(GLCM)纹理度量。一个分类器在这些特征上进行了训练，并在一个包含$12{,}000$个像素的分层验证样本上进行了评估，其中有$800$个参考湿地像素（正类）和$11{,}200$个参考非湿地像素（负类）。得到的混淆矩阵（行是参考标签，列是分类器预测）如下：\n$$\n\\begin{array}{c|cc}\n  \\text{预测为湿地}  \\text{预测为非湿地} \\\\\n\\hline\n\\text{参考为湿地}  480  320 \\\\\n\\text{参考为非湿地}  1200  10000\n\\end{array}\n$$\n仅从列联表计数的核心定义以及统计分类中使用的相关率（例如，敏感度、特异度、精确率、召回率）出发，推导并计算平衡准确率、F1分数和马修斯相关系数(MCC)。根据它们的数学构造，简要解释在类别不平衡时，这些指标中哪一个最适合总结性能。将每个指标表示为精确的解析形式（如果可以精确化简，则使用分数或根式），并以单行矩阵的形式提供最终答案，该矩阵按顺序包含平衡准确率、F1分数和MCC。不包括单位。不要四舍五入。",
            "solution": "该问题被验证为具有科学依据、问题明确、客观且自洽。所提供的信息足以且一致地推导出所需的分类性能指标。\n\n首先，我们必须定义混淆矩阵的组成部分。设“湿地”类为正类，“非湿地”类为负类。矩阵条目如下：\n-   真正例 ($TP$): 参考为湿地，预测为湿地。$TP = 480$。\n-   假负例 ($FN$): 参考为湿地，预测为非湿地。$FN = 320$。\n-   假正例 ($FP$): 参考为非湿地，预测为湿地。$FP = 1200$。\n-   真负例 ($TN$): 参考为非湿地，预测为非湿地。$TN = 10000$。\n\n实际正类实例（参考为湿地）的总数是 $P = TP + FN = 480 + 320 = 800$。\n实际负类实例（参考为非湿地）的总数是 $N = FP + TN = 1200 + 10000 = 11200$。\n总样本量是 $P + N = 800 + 11200 = 12000$。这些值与问题陈述相符。\n\n现在我们推导并计算所需的指标。\n\n**1. 平衡准确率 ($BA$)**\n平衡准确率定义为敏感度和特异度的算术平均值。\n\n敏感度，也称为真正例率 ($TPR$) 或召回率，是实际正例中被正确识别的比例。\n$$TPR = \\frac{TP}{TP + FN}$$\n代入给定值：\n$$TPR = \\frac{480}{480 + 320} = \\frac{480}{800} = \\frac{48}{80} = \\frac{3}{5}$$\n\n特异度，也称为真负例率 ($TNR$)，是实际负例中被正确识别的比例。\n$$TNR = \\frac{TN}{TN + FP}$$\n代入给定值：\n$$TNR = \\frac{10000}{10000 + 1200} = \\frac{10000}{11200} = \\frac{100}{112} = \\frac{25}{28}$$\n\n那么平衡准确率为：\n$$BA = \\frac{TPR + TNR}{2}$$\n$$BA = \\frac{\\frac{3}{5} + \\frac{25}{28}}{2} = \\frac{\\frac{3 \\times 28 + 25 \\times 5}{5 \\times 28}}{2} = \\frac{\\frac{84 + 125}{140}}{2} = \\frac{\\frac{209}{140}}{2} = \\frac{209}{280}$$\n\n**2. F1分数 ($F_1$)**\n$F_1$分数是精确率和召回率（敏感度）的调和平均数。\n\n精确率，也称为阳性预测值 ($PPV$)，是预测为正例中实际为正例的比例。\n$$PPV = \\frac{TP}{TP + FP}$$\n代入给定值：\n$$PPV = \\frac{480}{480 + 1200} = \\frac{480}{1680} = \\frac{48}{168} = \\frac{2}{7}$$\n\n召回率与敏感度相同，我们已经计算出 $TPR = \\frac{3}{5}$。\n\n$F_1$分数的定义为：\n$$F_1 = 2 \\times \\frac{PPV \\times TPR}{PPV + TPR}$$\n$$F_1 = 2 \\times \\frac{\\frac{2}{7} \\times \\frac{3}{5}}{\\frac{2}{7} + \\frac{3}{5}} = 2 \\times \\frac{\\frac{6}{35}}{\\frac{10+21}{35}} = 2 \\times \\frac{\\frac{6}{35}}{\\frac{31}{35}} = 2 \\times \\frac{6}{31} = \\frac{12}{31}$$\n\n或者，使用直接公式：\n$$F_1 = \\frac{2TP}{2TP + FP + FN} = \\frac{2 \\times 480}{2 \\times 480 + 1200 + 320} = \\frac{960}{960 + 1520} = \\frac{960}{2480} = \\frac{96}{248} = \\frac{12}{31}$$\n\n**3. 马修斯相关系数 ($MCC$)**\n$MCC$是观测分类和预测二元分类之间的相关系数。其定义为：\n$$MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n\n分子是：\n$TP \\times TN - FP \\times FN = (480 \\times 10000) - (1200 \\times 320) = 4800000 - 384000 = 4416000$\n\n分母平方根中的各项是：\n-   $TP+FP = 480 + 1200 = 1680$ (预测为正例)\n-   $TP+FN = 480 + 320 = 800$ (实际为正例)\n-   $TN+FP = 10000 + 1200 = 11200$ (实际为负例)\n-   $TN+FN = 10000 + 320 = 10320$ (预测为负例)\n\n分母是：\n$$\\sqrt{1680 \\times 800 \\times 11200 \\times 10320}$$\n为简化计算，我们注意到所有混淆矩阵计数都是 $80$ 的倍数：\n$TP = 6 \\times 80$, $FN = 4 \\times 80$, $FP = 15 \\times 80$, $TN = 125 \\times 80$。\n设 $k=80$。则 $TP = 6k, FN = 4k, FP = 15k, TN = 125k$。\n\n$MCC$ 公式可以重写为：\n$$MCC = \\frac{(6k)(125k) - (15k)(4k)}{\\sqrt{((6+15)k)((6+4)k)((125+15)k)((125+4)k)}}$$\n$$MCC = \\frac{750k^2 - 60k^2}{\\sqrt{(21k)(10k)(140k)(129k)}} = \\frac{690k^2}{k^2\\sqrt{21 \\times 10 \\times 140 \\times 129}}$$\n$$MCC = \\frac{690}{\\sqrt{21 \\times 10 \\times (14 \\times 10) \\times 129}} = \\frac{690}{10\\sqrt{21 \\times 14 \\times 129}} = \\frac{69}{\\sqrt{(3 \\times 7) \\times (2 \\times 7) \\times (3 \\times 43)}}$$\n$$MCC = \\frac{69}{\\sqrt{2 \\times 3^2 \\times 7^2 \\times 43}} = \\frac{69}{3 \\times 7 \\sqrt{2 \\times 43}} = \\frac{23}{7\\sqrt{86}}$$\n\n**不平衡类别指标的解释**\n该问题显示出显著的类别不平衡（$800$ 对 $11{,}200$）。在这种情况下，一些指标可能会产生误导。例如，简单准确率为 $\\frac{480+10000}{12000} \\approx 0.87$，这看起来很高，但主要反映了分类器在占主导地位的非湿地类别上的成功。\n\n-   **平衡准确率 ($BA$)**: 从其数学构造 $BA = \\frac{1}{2}(TPR + TNR)$ 来看，它是各类准确率的平均值。它对少数类（$TPR$）和多数类（$TNR$）的性能给予相同的权重。这使其成为不平衡数据集上性能的稳健指标，因为它不会因多数负类的高准确率而被夸大。\n\n-   **F1分数 ($F_1$)**: 作为精确率和召回率（$TPR$）的调和平均数，$F_1$ 分数旨在总结正类的性能。其公式 $F_1 = \\frac{2TP}{2TP + FP + FN}$ 不包括真负例（$TN$）的数量。虽然当正类是主要关注点时它很有用，但它完全忽略了正确分类的负类实例的数量，这意味着它不能捕捉分类器在两个类别上的全部性能情况。\n\n-   **马修斯相关系数 ($MCC$)**: $MCC$的公式 $MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$ 是这三者中唯一一个使用混淆矩阵所有四个值构建的。它是真实类别和预测类别之间的相关系数，得分范围从-1到+1。它是一个对称指标，意味着如果正负类互换，其值不会改变。由于它使用了所有四个计数，它被广泛认为是一个信息量大且平衡的单分总结，即使在类别大小差异很大的情况下也能提供可靠的质量度量。\n\n基于对其数学构造的分析，**马修斯相关系数(MCC)** 是总结不平衡类别性能最合适的指标，因为它将分类的所有方面（真正例、假正例、真负例和假负例）合成为一个单一、平衡且稳健的值。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{209}{280}  \\frac{12}{31}  \\frac{23}{7\\sqrt{86}} \\end{pmatrix}}$$"
        }
    ]
}