{
    "hands_on_practices": [
        {
            "introduction": "高光谱影像提供了丰富的光谱信息，但也带来了“维度灾难”和数据冗余问题。主成分分析（PCA）是一种经典且有效的方法，可将高维相关的数据转换到一个新的正交特征空间，并通过保留解释大部分方差的主成分来实现降维。本练习将引导你通过编程实践，掌握从协方差矩阵的特征值中确定数据内在维度的核心技能，这是许多高光谱分析工作流中的基础步骤 。",
            "id": "3852805",
            "problem": "考虑一个高光谱数据立方体，表示为一个包含 $p$ 个空间样本（像素）和 $n$ 个光谱波段的二维测量矩阵，记为 $X \\in \\mathbb{R}^{p \\times n}$。在高光谱成像（HSI）中，$X$ 的每一列对应一个光谱波段，每一行对应一个空间观测。主成分分析（PCA）是遥感和环境建模中广泛使用的光谱降维策略，其目标是将数据投影到一个低维子空间中，该子空间由与中心化数据的协方差矩阵相关的一组正交特征向量张成。\n\n从以下基本前提开始：\n- 中心化数据矩阵为 $X_c = X - \\mathbf{1}\\mu^\\top$，其中 $\\mu \\in \\mathbb{R}^{n}$ 是波段均值向量，$\\mathbf{1} \\in \\mathbb{R}^{p}$ 是全为1的向量。\n- 样本协方差矩阵为 $S = \\frac{1}{p-1} X_c^\\top X_c \\in \\mathbb{R}^{n \\times n}$。\n- 协方差矩阵 $S$ 是对称半正定矩阵，可进行特征分解 $S = V \\Lambda V^\\top$，其中 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n)$ 包含非负特征值。\n- 第 $i$ 个主成分的解释方差比为 $r_i = \\lambda_i \\big/ \\sum_{j=1}^{n} \\lambda_j$，前 $k$ 个成分的累积解释方差为 $R_k = \\sum_{i=1}^{k} r_i$。\n\n您的任务是为一个具有 $n = 200$ 个波段的高光谱立方体构建一个基于 PCA 的光谱降维方法，通过选择前 $k$ 个特征向量，使得累积解释方差 $R_k$ 至少为 $0.95$。您必须直接从一个给定的特征值向量中计算出最小整数 $k$，而不假设任何预先的排序或归一化。\n\n设计一个程序，对于一组给定的 $n = 200$ 的特征值序列，计算出使每个序列的 $R_k \\ge 0.95$ 的最小 $k$ 值。该程序必须：\n- 在计算累积解释方差之前，按非递增顺序对特征值进行排序。\n- 稳健地处理零特征值和相等特征值。\n- 如果特征值之和为 $0$，则返回 $k = 0$。\n\n使用以下特征值序列测试套件（每个序列长度为 $n = 200$）：\n- 测试用例 A（指数光谱能量衰减）：$\\lambda_i = \\exp\\!\\big(-\\alpha (i-1)\\big)$，其中 $\\alpha = 0.1$，$i = 1,\\dots,200$。\n- 测试用例 B（平坦谱）：$\\lambda_i = 1$，$i = 1,\\dots,200$。\n- 测试用例 C（秩亏，有 $50$ 个非零分量）：当 $i \\le 50$ 时 $\\lambda_i = 1$，当 $i > 50$ 时 $\\lambda_i = 0$。\n- 测试用例 D（尖峰谱，前 $5$ 个主导分量）：$\\lambda_1 = 500$，$\\lambda_2 = 400$，$\\lambda_3 = 300$，$\\lambda_4 = 200$，$\\lambda_5 = 100$，当 $i \\ge 6$ 时 $\\lambda_i = 0.1$。\n- 测试用例 E（在 $k = 95$ 处达到精确阈值）：当 $i \\le 100$ 时 $\\lambda_i = 1$，当 $i > 100$ 时 $\\lambda_i = 0$。\n- 测试用例 F（未排序输入）：与测试用例 A 相同，但随机排列，即输入特征值顺序是任意的。\n\n对于每个测试用例，答案必须是计算出的最小整数 $k$。此计算不涉及物理单位，也不使用角度。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表（例如，$[result_1,result_2,\\dots]$）。输出必须按 A, B, C, D, E, F 的顺序汇总测试用例的整数 $k$。",
            "solution": "该问题要求设计一种算法，以确定达到至少 $0.95$ 的累积解释方差所需的主成分最小数量，记为 $k$。输入是来自一个具有 $n=200$ 个波段的高光谱数据立方体的光谱协方差矩阵的特征值序列。\n\n主成分分析（PCA）用于降维的核心原理是将数据投影到一个能捕获最大可能方差的低维子空间上。该子空间由数据协方差矩阵 $S$ 的特征向量张成。每个特征向量（主成分）捕获的方差由其对应的特征值 $\\lambda_i$ 给出。数据集中的总方差是协方差矩阵的迹，等价于其所有特征值之和，即 $T = \\operatorname{Tr}(S) = \\sum_{j=1}^{n} \\lambda_j$。\n\n为了用有限的 $k$ 个分量捕获最大方差，必须选择与 $k$ 个最大特征值相关联的特征向量。因此，任何此类过程的第一步都必须是按非递增顺序对给定的特征值进行排序。设排序后的特征值序列为 $\\lambda'_1 \\ge \\lambda'_2 \\ge \\dots \\ge \\lambda'_n \\ge 0$。\n\n在这个排序列表中，第 $i$ 个主成分的解释方差比为 $r'_i = \\lambda'_i / T$。前 $k$ 个分量的累积解释方差是它们各自比率的总和：\n$$R_k = \\sum_{i=1}^{k} r'_i = \\frac{\\sum_{i=1}^{k} \\lambda'_i}{\\sum_{j=1}^{n} \\lambda'_j}$$\n\n目标是找到满足 $R_k \\ge \\tau$ 的最小整数 $k \\ge 0$，其中指定的阈值为 $\\tau = 0.95$。\n\n计算这个最小 $k$ 值的算法如下：\n\n1.  **接收输入**：输入是一个包含 $n$ 个非负特征值的序列 $(\\lambda_1, \\lambda_2, \\dots, \\lambda_n)$。\n\n2.  **计算总方差**：计算所有特征值的和，$T = \\sum_{j=1}^{n} \\lambda_j$。\n\n3.  **处理零方差边界情况**：如果 $T = 0$，则出现一个特殊情况。这意味着所有特征值都为 $0$，表明数据中没有方差（所有空间样本都相同）。在这种情况下，不需要任何分量来解释方差。根据问题规范，所需分量的最小数量为 $k=0$。\n\n4.  **对特征值排序**：如果 $T > 0$，则按非递增（降序）顺序对输入特征值进行排序，得到序列 $\\lambda'_1, \\lambda'_2, \\dots, \\lambda'_n$。这一步至关重要，因为它确保了我们在逐个添加分量时，总是包含解释剩余方差最大的那个分量。这种贪心方法保证了累积方差增长得最快，从而确保了 $k$ 的最小性。\n\n5.  **迭代和累加**：初始化累积方差和 $C = 0$ 以及分量计数器 $k=0$。遍历排序后的特征值 $\\lambda'_i$（$i = 1, 2, \\dots, n$）：\n    a. 增加分量计数器：$k \\leftarrow k + 1$。\n    b. 将当前特征值加到累积和中：$C \\leftarrow C + \\lambda'_i$。\n    c. 检查是否达到累积方差阈值：$C \\ge \\tau \\times T$。在本问题中，$\\tau = 0.95$。\n    d. 如果条件满足，当前的 $k$ 值就是所需的最小分量数。算法终止并返回该 $k$ 值。\n\n这个迭代过程保证能找到最小的 $k$。例如，如果条件在步骤 $k=k^*$ 时首次满足，我们知道它在步骤 $k=k^*-1$ 时未被满足，因此 $k^*$ 是最小的。由于 $\\sum_{i=1}^{n} \\lambda'_i = T$，假设 $T>0$，则在 $k=n$ 时条件总会被满足（因为 $T \\ge 0.95 \\times T$）。\n\n应用于 $n=200$ 和 $\\tau=0.95$ 的测试用例：\n\n-   **测试用例 A (指数衰减)**：特征值 $\\lambda_i = \\exp(-0.1(i-1))$ 已经排好序。算法将对它们求和，直到累积和达到总和的 $95\\%$。这需要进行数值计算。\n-   **测试用例 B (平坦谱)**：所有 $\\lambda_i = 1$。总方差为 $T = 200 \\times 1 = 200$。目标方差为 $0.95 \\times 200 = 190$。由于每个分量向总和中增加 $1$，我们需要恰好 $190$ 个分量。因此，$k=190$。\n-   **测试用例 C (秩亏)**：有 $50$ 个特征值为 $1$，其余为 $0$。总方差 $T = 50 \\times 1 = 50$。目标方差为 $0.95 \\times 50 = 47.5$。排序后，前 $50$ 个特征值为 $1$。为了超过 $47.5$ 的和，我们需要对其中 $48$ 个特征值求和。因此，$k=48$。\n-   **测试用例 D (尖峰谱)**：必须首先对特征值进行排序。较大的值（$500, 400, 300, 200, 100$）会排在前面。总方差为 $T = (500+400+300+200+100) + (195 \\times 0.1) = 1500 + 19.5 = 1519.5$。目标方差为 $0.95 \\times 1519.5 = 1443.525$。\n    -   $k=1: C_1 = 500$\n    -   $k=2: C_2 = 900$\n    -   $k=3: C_3 = 1200$\n    -   $k=4: C_4 = 1400$ ($ 1443.525$)\n    -   $k=5: C_5 = 1500$ ($\\ge 1443.525$)\n    因此，最小分量数为 $k=5$。\n-   **测试用例 E (精确阈值)**：有 $100$ 个特征值为 $1$，其余为 $0$。总方差 $T = 100 \\times 1 = 100$。目标方差为 $0.95 \\times 100 = 95$。我们需要对 $95$ 个单位特征值求和以精确达到目标。因此，$k=95$。\n-   **测试用例 F (未排序)**：特征值是测试用例 A 的一个随机排列。算法中的排序步骤使得计算与测试用例 A 的计算完全相同，因此 $k$ 的结果将是相同的。\n\n实现将精确遵循此逻辑，确保对各种特征值分布的鲁棒性，并遵守所有指定的约束。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_k(eigenvalues: np.ndarray, threshold: float = 0.95) - int:\n    \"\"\"\n    Computes the minimal number of principal components (k) to explain a\n    given cumulative variance threshold.\n\n    Args:\n        eigenvalues: A numpy array of eigenvalues.\n        threshold: The cumulative explained variance ratio to achieve.\n\n    Returns:\n        The minimal integer k.\n    \"\"\"\n    # Calculate total variance\n    total_variance = np.sum(eigenvalues)\n\n    # Handle the edge case where there is no variance in the data.\n    if total_variance == 0:\n        return 0\n\n    # Sort eigenvalues in nonincreasing (descending) order\n    sorted_eigenvalues = np.sort(eigenvalues)[::-1]\n\n    # Calculate the target variance to be explained\n    target_variance = threshold * total_variance\n\n    # Iterate to find the minimal k\n    cumulative_variance = 0.0\n    k = 0\n    for eig_val in sorted_eigenvalues:\n        cumulative_variance += eig_val\n        k += 1\n        if cumulative_variance = target_variance:\n            return k\n    \n    # This part should theoretically not be reached if total_variance  0,\n    # as the loop will always return a k = n.\n    return len(eigenvalues)\n\ndef solve():\n    \"\"\"\n    Defines, runs, and formats the output for all test cases.\n    \"\"\"\n    n = 200\n    \n    # Test case A (exponential spectral energy decay)\n    alpha_A = 0.1\n    i_A = np.arange(n)\n    eig_A = np.exp(-alpha_A * i_A)\n\n    # Test case B (flat spectrum)\n    eig_B = np.ones(n)\n\n    # Test case C (rank-deficient with 50 nonzero components)\n    eig_C = np.zeros(n)\n    eig_C[:50] = 1.0\n\n    # Test case D (spiked spectrum with top 5 dominant components)\n    eig_D = np.full(n, 0.1)\n    eig_D[0] = 500.0\n    eig_D[1] = 400.0\n    eig_D[2] = 300.0\n    eig_D[3] = 200.0\n    eig_D[4] = 100.0\n    \n    # Test case E (exact threshold at k = 95)\n    eig_E = np.zeros(n)\n    eig_E[:100] = 1.0\n\n    # Test case F (unsorted input, same as A but permuted)\n    # Use a fixed seed for reproducibility of the permutation\n    rng = np.random.default_rng(seed=42)\n    eig_F = rng.permutation(eig_A)\n\n    test_cases = [\n        eig_A,\n        eig_B,\n        eig_C,\n        eig_D,\n        eig_E,\n        eig_F,\n    ]\n\n    results = []\n    for case_eigenvalues in test_cases:\n        k = compute_k(case_eigenvalues)\n        results.append(k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "仅依赖光谱信息的逐像素分类器往往会产生“椒盐”噪声，因为它们忽略了像素之间的空间关系。马尔可夫随机场（MRF）通过引入空间先验，构建了一个上下文分类器，该分类器倾向于生成空间上更平滑、更真实的分类结果。本练习通过手动执行一步α-扩展（alpha-expansion）算法，让你具体理解如何利用空间上下文信息来修正初始分类，并最小化一个全局能量函数 。",
            "id": "3852860",
            "problem": "一个多光谱遥感分类器提供了一个跨越植被-裸土过渡区的六个相邻像素一维样带的逐像素后验类概率。设两个类别为植被 ($V$) 和裸土 ($B$)。类别平滑度的空间先验被建模为一个带有Potts模型惩罚项的成对马尔可夫随机场 (MRF)。对于一个在链式图（邻居结构为相邻像素）上的标记 $l = (l_{1},\\dots,l_{6})$，其总的最大后验 (MAP) 能量为\n$$\nE(l) \\;=\\; \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_{i})\\Big) \\;+\\; \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_{i}\\neq l_{j}\\},\n$$\n其中 $p_{i}(c)$ 是像素 $i$ 处类别 $c\\in\\{V,B\\}$ 的后验概率，$\\mathcal{N}$ 包含相邻索引对 $\\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数，$\\lambda$ 是一个非负标量。\n\n给定由光谱分类器产生的以下后验概率：\n- 像素 1：$p_{1}(V)=0.65$， $p_{1}(B)=0.35$。\n- 像素 2：$p_{2}(V)=0.60$， $p_{2}(B)=0.40$。\n- 像素 3：$p_{3}(V)=0.45$， $p_{3}(B)=0.55$。\n- 像素 4：$p_{4}(V)=0.40$， $p_{4}(B)=0.60$。\n- 像素 5：$p_{5}(V)=0.70$， $p_{5}(B)=0.30$。\n- 像素 6：$p_{6}(V)=0.66$， $p_{6}(B)=0.34$。\n\nPotts模型权重为 $\\lambda=0.40$。初始标记 $l^{(0)}$ 是逐像素分类（每个像素处 $p_{i}(c)$ 的argmax）。\n\n从 $l^{(0)}$ 开始，执行一次 $\\alpha=V$（植被）的$\\alpha$-扩展移动。由于Potts项是一个度量，该问题可以通过一次图割精确求解。计算这次单独的$\\alpha$-扩展移动后标记的能量 $E(l^{(1)})$。使用自然对数 $\\ln$。将你的最终答案表示为一个无单位的实数，并四舍五入到四位有效数字。",
            "solution": "用户希望我使用$\\alpha$-扩展算法解决一个马尔可夫随机场 (MRF) 上的最大后验 (MAP) 估计问题。\n\n### 步骤 1: 提取已知条件\n-   **类别**：植被 ($V$) 和裸土 ($B$)。\n-   **像素**：一个包含6个像素的一维样带，索引为 $i=1, \\dots, 6$。\n-   **能量函数**：一个标记 $l = (l_1, \\dots, l_6)$ 的最大后验 (MAP) 能量由以下公式给出\n    $$\n    E(l) \\;=\\; \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_{i})\\Big) \\;+\\; \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_{i}\\neq l_{j}\\},\n    $$\n    其中 $p_i(c)$ 是像素 $i$ 处类别 $c$ 的后验概率，$\\mathcal{N} = \\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$ 是相邻像素对的集合，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n-   **Potts模型权重**：$\\lambda = 0.40$。\n-   **后验概率**：\n    -   $p_1(V)=0.65$, $p_1(B)=0.35$。\n    -   $p_2(V)=0.60$, $p_2(B)=0.40$。\n    -   $p_3(V)=0.45$, $p_3(B)=0.55$。\n    -   $p_4(V)=0.40$, $p_4(B)=0.60$。\n    -   $p_5(V)=0.70$, $p_5(B)=0.30$。\n    -   $p_6(V)=0.66$, $p_6(B)=0.34$。\n-   **初始条件**：初始标记 $l^{(0)}$ 是逐像素分类，即对每个像素 $i$，$l_i^{(0)} = \\arg\\max_{c \\in \\{V, B\\}} p_i(c)$。\n-   **任务**：从 $l^{(0)}$ 开始，执行一次 $\\alpha=V$ 的$\\alpha$-扩展移动，得到新的标记 $l^{(1)}$。然后，计算能量 $E(l^{(1)})$ 并将结果四舍五入到四位有效数字。\n\n### 步骤 2: 使用提取的已知条件进行验证\n该问题具有科学依据。它描述了马尔可夫随机场与Potts模型先验在图像分类中的标准应用，这是遥感、计算机视觉及相关领域中一项成熟的技术。能量函数是MAP估计的常见形式。$\\alpha$-扩展算法是一种标准的、可证明正确的方法，用于在平滑项是度量（Potts模型即是）时最小化此类能量函数。该问题是适定的，提供了所有必要的数据和参数。定义清晰明确。该问题是客观且可形式化的。\n\n### 步骤 3: 结论与行动\n问题有效。我现在将进行求解。\n\n### 详细解法\n\n解题过程分为四个步骤：\n1.  确定初始标记 $l^{(0)}$。\n2.  为 $\\alpha=V$ 的$\\alpha$-扩展移动构建能量最小化问题。\n3.  求解最小化问题以找到新的标记 $l^{(1)}$。\n4.  计算最终能量 $E(l^{(1)})$。\n\n**1. 确定初始标记 $l^{(0)}$**\n\n初始标记 $l^{(0)}$ 是通过为每个像素选择具有最高后验概率的类别来获得的。\n\n-   像素 1：$p_{1}(V) = 0.65  p_{1}(B)=0.35 \\implies l_{1}^{(0)} = V$。\n-   像素 2：$p_{2}(V) = 0.60  p_{2}(B)=0.40 \\implies l_{2}^{(0)} = V$。\n-   像素 3：$p_{3}(B) = 0.55  p_{3}(V)=0.45 \\implies l_{3}^{(0)} = B$。\n-   像素 4：$p_{4}(B) = 0.60  p_{4}(V)=0.40 \\implies l_{4}^{(0)} = B$。\n-   像素 5：$p_{5}(V) = 0.70  p_{5}(B)=0.30 \\implies l_{5}^{(0)} = V$。\n-   像素 6：$p_{6}(V) = 0.66  p_{6}(B)=0.34 \\implies l_{6}^{(0)} = V$。\n\n因此，初始标记为 $l^{(0)} = (V, V, B, B, V, V)$。\n\n**2. 构建$\\alpha$-扩展问题**\n\n我们执行一次 $\\alpha=V$ 的$\\alpha$-扩展移动。这意味着我们寻求一个新的标记 $l^{(1)}$ 来最小化能量 $E(l)$，其约束条件是对于每个像素 $i$，其新标记 $l_i^{(1)}$ 可以是其当前标记 $l_i^{(0)}$ 或扩展标记 $\\alpha=V$。\n\n对于像素 $i \\in \\{1, 2, 5, 6\\}$，初始标记为 $l_i^{(0)} = V$。由于 $\\alpha=V$，唯一可能的新标记也是 $V$。因此，它们的标记是固定的：$l_1^{(1)}=V$, $l_2^{(1)}=V$, $l_5^{(1)}=V$, $l_6^{(1)}=V$。\n\n对于像素 $i \\in \\{3, 4\\}$，初始标记为 $l_i^{(0)} = B$。新标记 $l_i^{(1)}$ 可以是 $B$ 或 $V$。我们必须找到像素3和4的标记组合，以最小化总能量。\n\n对于一个新的标记 $l^{(1)} = (V, V, l_3, l_4, V, V)$，其中 $l_3, l_4 \\in \\{B, V\\}$，其总能量为：\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_i^{(1)})\\Big) + \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_i^{(1)} \\neq l_j^{(1)}\\}\n$$\n能量可以分解为一个常数部分和一个依赖于 $l_3$ 和 $l_4$ 选择的可变部分。\n常数部分由仅涉及像素1、2、5、6的项组成。我们必须最小化的可变部分是：\n$$\nE_{\\text{sub}}(l_3, l_4) = \\big(-\\ln p_3(l_3)\\big) + \\big(-\\ln p_4(l_4)\\big) + \\lambda \\Big( \\mathbf{1}\\{l_2^{(1)}\\neq l_3\\} + \\mathbf{1}\\{l_3\\neq l_4\\} + \\mathbf{1}\\{l_4\\neq l_5^{(1)}\\} \\Big)\n$$\n代入 $l_2^{(1)}=V$ 和 $l_5^{(1)}=V$，我们得到：\n$$\nE_{\\text{sub}}(l_3, l_4) = -\\ln p_3(l_3) - \\ln p_4(l_4) + \\lambda \\Big( \\mathbf{1}\\{V\\neq l_3\\} + \\mathbf{1}\\{l_3\\neq l_4\\} + \\mathbf{1}\\{l_4\\neq V\\} \\Big)\n$$\n\n**3. 求解最小化问题**\n\n我们对 $(l_3, l_4)$ 的四种可能组合计算 $E_{\\text{sub}}(l_3, l_4)$。我们使用给定的概率和 $\\lambda = 0.40$。数据项为：\n-   $-\\ln p_3(B) = -\\ln(0.55) \\approx 0.5978$\n-   $-\\ln p_3(V) = -\\ln(0.45) \\approx 0.7985$\n-   $-\\ln p_4(B) = -\\ln(0.60) \\approx 0.5108$\n-   $-\\ln p_4(V) = -\\ln(0.40) \\approx 0.9163$\n\n-   **情况 1：** $(l_3, l_4) = (B, B)$\n    $E_{\\text{sub}}(B, B) = -\\ln(0.55) - \\ln(0.60) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq B\\} + \\mathbf{1}\\{B\\neq V\\})$\n    $E_{\\text{sub}}(B, B) = 0.5978 + 0.5108 + 0.40 \\cdot (1 + 0 + 1) = 1.1086 + 0.8 = 1.9086$\n\n-   **情况 2：** $(l_3, l_4) = (B, V)$\n    $E_{\\text{sub}}(B, V) = -\\ln(0.55) - \\ln(0.40) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq V\\} + \\mathbf{1}\\{V\\neq V\\})$\n    $E_{\\text{sub}}(B, V) = 0.5978 + 0.9163 + 0.40 \\cdot (1 + 1 + 0) = 1.5141 + 0.8 = 2.3141$\n\n-   **情况 3：** $(l_3, l_4) = (V, B)$\n    $E_{\\text{sub}}(V, B) = -\\ln(0.45) - \\ln(0.60) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq V\\})$\n    $E_{\\text{sub}}(V, B) = 0.7985 + 0.5108 + 0.40 \\cdot (0 + 1 + 1) = 1.3093 + 0.8 = 2.1093$\n\n-   **情况 4：** $(l_3, l_4) = (V, V)$\n    $E_{\\text{sub}}(V, V) = -\\ln(0.45) - \\ln(0.40) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq V\\})$\n    $E_{\\text{sub}}(V, V) = 0.7985 + 0.9163 + 0.40 \\cdot (0 + 0 + 0) = 1.7148$\n\n比较这四个值，最小能量为 $1.7148$，对应于情况 $(l_3, l_4) = (V, V)$。\n因此，$\\alpha$-扩展移动将像素3和4的标记更改为 $V$。得到的标记是 $l^{(1)} = (V, V, V, V, V, V)$。\n\n**4. 计算最终能量 $E(l^{(1)})$**\n\n我们现在计算最优标记 $l^{(1)} = (V, V, V, V, V, V)$ 的总能量。\n由于所有标记都相同，能量计算得以简化，平滑项为零。\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(V)\\Big) + \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{V\\neq V\\}\n$$\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(V)\\Big) + 0\n$$\n$$\nE(l^{(1)}) = \\big(-\\ln p_1(V)\\big) + \\big(-\\ln p_2(V)\\big) + \\big(-\\ln p_3(V)\\big) + \\big(-\\ln p_4(V)\\big) + \\big(-\\ln p_5(V)\\big) + \\big(-\\ln p_6(V)\\big)\n$$\n代入给定的概率：\n$$\nE(l^{(1)}) = \\big(-\\ln(0.65)\\big) + \\big(-\\ln(0.60)\\big) + \\big(-\\ln(0.45)\\big) + \\big(-\\ln(0.40)\\big) + \\big(-\\ln(0.70)\\big) + \\big(-\\ln(0.66)\\big)\n$$\n使用自然对数：\n$$\nE(l^{(1)}) \\approx 0.43078 + 0.51083 + 0.79851 + 0.91629 + 0.35667 + 0.41551\n$$\n$$\nE(l^{(1)}) \\approx 3.42859\n$$\n将结果四舍五入到四位有效数字，我们得到 $3.429$。",
            "answer": "$$\\boxed{3.429}$$"
        },
        {
            "introduction": "生成分类图后，使用独立的验证数据对其精度进行定量评估是至关重要的一步。混淆矩阵是计算大多数精度指标的基础，而不同的指标，如总体精度、各类别的F1分数和科恩的$\\kappa$系数，为我们提供了评估分类器性能和错误类型的不同视角。本练习旨在培养计算和解读一套标准精度指标的基本技能，从而能够对分类结果进行细致而稳健的评估 。",
            "id": "3852862",
            "problem": "一个用于多光谱卫星图像的土地覆盖分类器结合了光谱特征（例如，短波红外、近红外和红光波段的反射率）和空间上下文特征（例如，在移动窗口上计算的局部纹理统计数据）。该分类器用于绘制四个类别：水体（$W$）、森林（$F$）、城市（$U$）和农业（$A$）。通过在 $4$ 个生态区域进行分层随机抽样，收集了一个包含 $N = 713$ 个像素的独立验证样本，其地面真值通过高分辨率航空影像解译获得。以下汇总结果总结了分类器为每个地面真值类别生成的预测标签，其中的计数是具有指定参考标签和预测标签的验证像素数量：\n\n- 地面真值 $W$：预测为 $W = 140$，$F = 3$，$U = 2$，$A = 5$（行和 $= 150$）。\n- 地面真值 $F$：预测为 $W = 6$，$F = 180$，$U = 12$，$A = 22$（行和 $= 220$）。\n- 地面真值 $U$：预测为 $W = 1$，$F = 15$，$U = 110$，$A = 14$（行和 $= 140$）。\n- 地面真值 $A$：预测为 $W = 2$，$F = 18$，$U = 13$，$A = 170$（行和 $= 203$）。\n\n假设抽样对于测绘区域是设计无偏的，并且验证像素是从潜在的土地覆盖分布中独立抽取的。此外，现场记录表明，误差在农业山谷（$A$ 和 $F$ 之间的混淆）和混合的城市边缘区域（$U$ 和 $F$ 之间的混淆）表现出空间聚类，而 $W$ 在光谱上相对独特，但偶尔在海岸线附近会被混淆。\n\n从分类评估中列联表和事件概率的基本定义出发，执行以下操作：\n\n1. 构建类别顺序为 $[W, F, U, A]$ 的 $4 \\times 4$ 混淆矩阵，并计算行和与列和。\n2. 推导并计算总体精度，即正确分类的比例。\n3. 对于每个类别 $c \\in \\{W, F, U, A\\}$，基于一对余的视角定义真正例、假正例和假负例，并使用精确率和召回率的定义推导逐类的 F1 分数。\n4. 使用在给定观测边际值的情况下独立标注的期望一致性定义，推导并计算科恩的 $\\kappa$ 系数。\n\n简要解释总体精度、各类别 F1 分数和科恩的 $\\kappa$ 系数如何差异化地反映环境地图中观测到的误差结构和类别流行度，尤其是在空间聚类错分的情况下。\n\n仅报告科恩的 $\\kappa$ 系数作为最终数值答案。将报告的 $\\kappa$ 值四舍五入至四位有效数字，并以小数形式表示。",
            "solution": "问题陈述提供了土地覆盖制图任务的分类结果摘要，并要求使用标准统计指标进行定量评估。该问题具有科学依据、提法明确、客观且内部一致。验证像素总数 $N = 713$ 与提供的地面真值行计数之和（$150 + 220 + 140 + 203 = 713$）相符。尽管有关于空间误差聚类的定性说明，但假设独立抽取的指令允许标准统计指标的应用。因此，该问题是有效的，并且可以推导出解决方案。\n\n**1. 混淆矩阵及边际值**\n\n混淆矩阵（表示为 $C$）是一个方阵，其中元素 $C_{ij}$ 是已知属于类别 $i$（地面真值）但被预测为类别 $j$ 的观测数量。类别排序为 $[W, F, U, A]$。行代表地面真值标签，列代表预测标签。\n\n使用给定数据构建 $4 \\times 4$ 混淆矩阵：\n$$\nC =\n\\begin{pmatrix}\n140   3   2   5 \\\\\n6   180   12   22 \\\\\n1   15   110   14 \\\\\n2   18   13   170\n\\end{pmatrix}\n$$\n\n行边际（代表每个地面真值类别的总像素数）如下：\n- $N_{W, \\text{true}} = 140 + 3 + 2 + 5 = 150$\n- $N_{F, \\text{true}} = 6 + 180 + 12 + 22 = 220$\n- $N_{U, \\text{true}} = 1 + 15 + 110 + 14 = 140$\n- $N_{A, \\text{true}} = 2 + 18 + 13 + 170 = 203$\n样本总数为 $N = \\sum_{i} N_{i, \\text{true}} = 150 + 220 + 140 + 203 = 713$。\n\n列边际（代表每个类别预测的总像素数）通过对 $C$ 的列求和计算得出：\n- $N_{W, \\text{pred}} = 140 + 6 + 1 + 2 = 149$\n- $N_{F, \\text{pred}} = 3 + 180 + 15 + 18 = 216$\n- $N_{U, \\text{pred}} = 2 + 12 + 110 + 13 = 137$\n- $N_{A, \\text{pred}} = 5 + 22 + 14 + 170 = 211$\n列边际之和也等于样本总数：$149 + 216 + 137 + 211 = 713$。\n\n**2. 总体精度**\n\n总体精度（$OA$）是正确分类的验证像素所占的比例。它通过将正确分类的数量（混淆矩阵的对角线元素）相加，然后除以总像素数 $N$ 得出。\n$$\nOA = \\frac{\\sum_{i=1}^{k} C_{ii}}{N}\n$$\n其中 $k=4$ 是类别数。\n正确分类的像素数是 $C$ 的对角线元素之和：\n$$\n\\sum_{i=1}^{4} C_{ii} = 140 + 180 + 110 + 170 = 600\n$$\n因此，总体精度为：\n$$\nOA = \\frac{600}{713} \\approx 0.8415\n$$\n\n**3. 逐类 F1 分数**\n\n对于每个类别 $i$，我们采用一对余的视角来定义真正例（$TP_i$）、假正例（$FP_i$）和假负例（$FN_i$）。\n- $TP_i$：类别 $i$ 的像素被正确分类为类别 $i$。$TP_i = C_{ii}$。\n- $FP_i$：其他类别的像素被错误分类为类别 $i$。$FP_i = (\\sum_{j=1}^{k} C_{ji}) - C_{ii} = N_{i, \\text{pred}} - C_{ii}$。\n- $FN_i$：类别 $i$ 的像素被错误分类为其他类别。$FN_i = (\\sum_{j=1}^{k} C_{ij}) - C_{ii} = N_{i, \\text{true}} - C_{ii}$。\n\n由此，我们推导出精确率（$P_i$）和召回率（$R_i$）：\n- 精确率（$P_i$）：预测为类别 $i$ 的像素实际上是类别 $i$ 的概率。$P_i = \\frac{TP_i}{TP_i + FP_i} = \\frac{C_{ii}}{N_{i, \\text{pred}}}$。\n- 召回率（$R_i$）：类别 $i$ 的像素被正确识别的概率。$R_i = \\frac{TP_i}{TP_i + FN_i} = \\frac{C_{ii}}{N_{i, \\text{true}}}$。\n\nF1 分数是精确率和召回率的调和平均数，提供了一个平衡两者的单一指标：\n$$\nF1_i = 2 \\cdot \\frac{P_i \\cdot R_i}{P_i + R_i}\n$$\n每个类别的计算如下：\n- **水体 (W)**: $TP_W=140, FP_W=9, FN_W=10$.\n  $P_W = \\frac{140}{149}$, $R_W = \\frac{140}{150}$.\n  $F1_W = 2 \\cdot \\frac{\\frac{140}{149} \\cdot \\frac{140}{150}}{\\frac{140}{149} + \\frac{140}{150}} \\approx 0.9364$\n- **森林 (F)**: $TP_F=180, FP_F=36, FN_F=40$.\n  $P_F = \\frac{180}{216}$, $R_F = \\frac{180}{220}$.\n  $F1_F = 2 \\cdot \\frac{\\frac{180}{216} \\cdot \\frac{180}{220}}{\\frac{180}{216} + \\frac{180}{220}} \\approx 0.8257$\n- **城市 (U)**: $TP_U=110, FP_U=27, FN_U=30$.\n  $P_U = \\frac{110}{137}$, $R_U = \\frac{110}{140}$.\n  $F1_U = 2 \\cdot \\frac{\\frac{110}{137} \\cdot \\frac{110}{140}}{\\frac{110}{137} + \\frac{110}{140}} \\approx 0.7942$\n- **农业 (A)**: $TP_A=170, FP_A=41, FN_A=33$.\n  $P_A = \\frac{170}{211}$, $R_A = \\frac{170}{203}$.\n  $F1_A = 2 \\cdot \\frac{\\frac{170}{211} \\cdot \\frac{170}{203}}{\\frac{170}{211} + \\frac{170}{203}} \\approx 0.8212$\n\n**4. 科恩的 Kappa 系数（$\\kappa$）**\n\n科恩的 $\\kappa$ 系数衡量预测标签与真实标签之间的一致性，并对偶然预期的一致性进行了校正。其定义为：\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e}\n$$\n此处，$p_o$ 是观测到的一致性概率，即总体精度：\n$$\np_o = OA = \\frac{600}{713}\n$$\n$p_e$ 是偶然一致性的假设概率。它是根据行和列的边际值计算的。对于每个类别 $i$，一个随机像素属于类别 $i$ 的概率是 $\\frac{N_{i, \\text{true}}}{N}$，一个随机像素被分类为类别 $i$ 的概率是 $\\frac{N_{i, \\text{pred}}}{N}$。这两者对类别 $i$ 偶然达成一致的概率是它们的乘积。对所有类别求和得到 $p_e$：\n$$\np_e = \\sum_{i=1}^{k} \\frac{N_{i, \\text{true}}}{N} \\cdot \\frac{N_{i, \\text{pred}}}{N} = \\frac{1}{N^2} \\sum_{i=1}^{k} (N_{i, \\text{true}} \\cdot N_{i, \\text{pred}})\n$$\n使用先前计算的边际值（$N=713$）：\n$N_{W, \\text{true}} = 150, N_{F, \\text{true}} = 220, N_{U, \\text{true}} = 140, N_{A, \\text{true}} = 203$.\n$N_{W, \\text{pred}} = 149, N_{F, \\text{pred}} = 216, N_{U, \\text{pred}} = 137, N_{A, \\text{pred}} = 211$.\n\n边际值的乘积之和为：\n$$\n\\sum (\\text{marginals}) = (150 \\times 149) + (220 \\times 216) + (140 \\times 137) + (203 \\times 211)\n$$\n$$\n\\sum (\\text{marginals}) = 22350 + 47520 + 19180 + 42833 = 131883\n$$\n现在，我们计算 $p_e$：\n$$\np_e = \\frac{131883}{713^2} = \\frac{131883}{508369}\n$$\n现在我们可以使用 $p_o$ 和 $p_e$ 的分数形式来精确计算 $\\kappa$：\n$$\np_o \\approx 0.84151473 \\quad \\text{and} \\quad p_e \\approx 0.25942475\n$$\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e} = \\frac{0.84151473 - 0.25942475}{1 - 0.25942475} = \\frac{0.58208998}{0.74057525} \\approx 0.785994\n$$\n四舍五入到四位有效数字，科恩的 $\\kappa$ 系数为 $0.7860$。\n\n**解释**\n\n- **总体精度 ($OA \\approx 0.84$)**：该指标表明分类器性能水平较高，约有 $84\\%$ 的地景被正确绘制。然而，$OA$ 会受类别流行度的影响，并且不能揭示误差的性质。\n- **F1 分数**：这些针对特定类别的分数揭示了性能差异。水体的高 F1 分数（$F1_W \\approx 0.94$）证实了其光谱独特的现场记录。森林（$F1_F \\approx 0.83$）、城市（$F1_U \\approx 0.79$）和农业（$F1_A \\approx 0.82$）的较低分数凸显了分类挑战。这些较低的分数是这些类别之间较高混淆率的直接结果，这证实了关于农业山谷（$A-F$）和城市边缘（$U-F$）误差的现场记录。混淆矩阵显示了 $F \\rightarrow A$（$22$）、$A \\rightarrow F$（$18$）、$U \\rightarrow F$（$15$）和 $F \\rightarrow U$（$12$）的显著误差计数。\n- **科恩的 $\\kappa$ 系数（$\\kappa \\approx 0.786$）**：该值代表了实质性或极好的一致性水平。它通过考虑在给定观测类别频率（边际值）的情况下纯粹由偶然性预期的一致性，从而对 $OA$ 进行了改进。在这种情况下，由于各类别相对平衡，$\\kappa$ 值与 $OA$ 并无巨大差异，但它仍然是衡量分类器性能的一个更稳健的指标。关于*空间聚类*错分的说明意味着验证样本并非真正独立，这违反了 $\\kappa$ 标准显著性检验的一项核心假设。尽管在问题明确的独立性假设下，$\\kappa$ 本身的计算在算术上是正确的，但严谨的分析需要使用空间统计学来解释这种自相关，这可能导致该指标的置信区间更宽。本质上，$\\kappa$ 量化了超出偶然性的分类器表现，而 F1 分数则诊断出该表现在哪些方面存在不足，定性的现场记录则表明这些缺点呈现出空间模式而非随机模式。",
            "answer": "$$\\boxed{0.7860}$$"
        }
    ]
}