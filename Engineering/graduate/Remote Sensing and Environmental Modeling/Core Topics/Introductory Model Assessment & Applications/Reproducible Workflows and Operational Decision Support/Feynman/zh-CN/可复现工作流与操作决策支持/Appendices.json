{
    "hands_on_practices": [
        {
            "introduction": "许多环境模型依赖于引入随机性的蒙特卡洛方法，这给可复现性带来了挑战，尤其是在并行计算环境中。本练习将演示一项关键技术——基于计数器的随机数生成——以确保并行模拟产生与计算环境无关的、位对位相同的结果。掌握这项技术是进行可靠调试、验证和获得可信科学结论的基石。",
            "id": "3841901",
            "problem": "您将执行一项关于气溶胶光学厚度（AOD）的遥感不确定性传播任务，AOD是一个无量纲量。在此任务中，您需要使用蒙特卡洛采样来估计在模型和测量不确定性下AOD的期望值和变异性，同时确保在分布式计算环境下结果的可复现性。您的目标是设计一个程序，通过精心管理随机种子和流分区，来演示并验证在不同工作节点分区方案下的可复现性。\n\n基本原理：蒙特卡洛积分通过对独立随机变量进行采样来估计函数在不确定性下的期望值。具体而言，设 $A$ 表示气溶胶光学厚度，其反演模型为 $A = c \\left(\\bar{A} + \\epsilon \\right)$，其中 $\\bar{A}$ 是一个基线估计值，$\\epsilon$ 是一个代表传感器和模型噪声的加性误差项，$c$ 是一个乘性定标因子。假设 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $c = \\exp\\left(\\mu_c + \\sigma_c Z\\right)$，其中 $Z \\sim \\mathcal{N}(0, 1)$，$\\mathcal{N}(0, \\sigma^2)$ 表示均值为 $0$、方差为 $\\sigma^2$ 的正态分布，$\\exp(\\cdot)$ 表示指数函数。对于 $N$ 个样本，$A$ 的期望值的蒙特卡洛估计量为 $\\hat{\\mathbb{E}}[A] = \\frac{1}{N}\\sum_{i=1}^{N} A_i$，其中每个 $A_i$ 是由对 $\\epsilon$ 和 $c$ 的独立抽取构建的。\n\n可复现的工作流要求随机变量的生成方式不依赖于工作节点的数量或其调度。形式上，设 $s$ 为一个基础种子，样本索引为 $i$ 的随机变量的生成过程是一个关于 $(s, i)$ 和一个抽取索引 $d$ 的确定性函数。抽取索引 $d$唯一地标识了生成的随机变量（例如，为 $\\epsilon$ 和 $c$ 各分配一个抽取索引）。这种方法被称为基于计数器的随机变量生成，它为每个 $(s, i, d)$ 到 $(0,1)$ 区间内的伪随机值生成一个固定的映射，然后可以将这些值转换为所需的分布。跨工作节点的流分区必须设计为每个工作节点计算 $i$ 的不相交子集，同时保持从 $(s, i, d)$ 到随机变量的映射关系。在此设计下，聚合结果与工作节点的数量及其分配方式无关，从而实现可复现性。\n\n您的程序必须：\n- 实现一个蒙特卡洛模拟器，用于计算 $A_i = c_i \\left(\\bar{A} + \\epsilon_i\\right)$，其中 $i = 0, 1, \\ldots, N-1$。该模拟器使用一个确定性的、基于计数器的伪随机映射，将 $(s, i, d)$ 映射到 $(0,1)$ 区间内的独立均匀分布随机数，然后将这些数转换为 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ 和 $c_i = \\exp\\left(\\mu_c + \\sigma_c Z_i\\right)$（其中 $Z_i \\sim \\mathcal{N}(0, 1)$）。使用从均匀分布到正态分布变量的数值稳定变换。\n- 实现两种执行模式：\n  1. 集中式单流：按顺序计算所有 $A_i$，其中 $i = 0, 1, \\ldots, N-1$。\n  2. 分布式多工作节点：使用指定的分区方案，将索引集 $\\{0,\\ldots,N-1\\}$ 划分到 $W$ 个工作节点上，在每个工作节点中计算 $A_i$，然后将结果聚合成一个按 $i$ 排序的数组。\n- 通过逐元素比较集中式和分布式数组是否相等来验证可复现性，为每个测试用例得出一个布尔值。对于一个测试用例，当且仅当集中式和分布式数组（按 $i$ 排序）完全相同时，布尔结果为真。\n\n物理单位：气溶胶光学厚度是无量纲的。仅返回无量纲量。如果在变换中出现角度，必须以弧度为单位。\n\n测试套件与参数：\n对于每个测试用例，参数以 $(N, \\bar{A}, \\sigma, \\mu_c, \\sigma_c, s, W, \\text{partitioning})$ 的形式提供，其中 $N$ 是蒙特卡洛样本数，$\\bar{A}$ 是基线AOD，$\\sigma$ 是噪声标准差，$\\mu_c$ 和 $\\sigma_c$ 是定标因子的对数正态分布参数，$s$ 是基础种子（一个整数），$W$ 是工作节点数量，$\\text{partitioning}$ 描述了工作节点的分配方案。\n\n使用以下测试用例：\n- 测试用例 1：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 4, \\text{partitioning} = \\text{contiguous blocks})$。每个工作节点 $w$ 接收一个大小近似相等的连续索引块。\n- 测试用例 2：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 1, \\text{partitioning} = \\text{single worker})$。所有索引分配给一个工作节点。\n- 测试用例 3：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 7, \\text{partitioning} = \\text{round-robin})$。工作节点 $w$ 接收满足 $i \\bmod W = w$ 的索引 $i$。\n- 测试用例 4：$(N = 1, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 3, \\text{partitioning} = \\text{contiguous blocks})$。$N$ 取最小值的边界情况。\n- 测试用例 5：$(N = 5{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 123456789, W = 8, \\text{partitioning} = \\text{round-robin})$。使用不同的种子和工作节点数量。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，并用方括号括起来，例如 $[r_1, r_2, r_3, r_4, r_5]$，其中每个 $r_k$ 是一个布尔值，表示测试用例 $k$ 的集中式和分布式数组是否完全相同。",
            "solution": "我们从支配蒙特卡洛方法和可复现计算的基本原理入手。一个随机变量期望值的蒙特卡洛估计量是由独立随机样本构建的。给定AOD模型 $A = c \\left(\\bar{A} + \\epsilon \\right)$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $c = \\exp\\left(\\mu_c + \\sigma_c Z\\right)$, $Z \\sim \\mathcal{N}(0, 1)$，我们模拟 $N$ 个独立样本来近似 $\\mathbb{E}[A]$ 和其他统计量。\n\n为确保跨分布式工作节点的可复现性，我们要求随机变量的生成是一个关于基础种子和唯一标识每次随机抽取的索引的确定性函数。这可以通过一个基于计数器的设计来实现：定义一个函数 $U: \\mathbb{Z} \\times \\mathbb{Z} \\times \\mathbb{Z} \\rightarrow (0,1)$, $U(s, i, d)$，它接受一个基础种子 $s$、一个样本索引 $i$和一个抽取索引 $d$（例如，对于Box–Muller变换中使用的两个均匀分布变量，可使用 $d = 0$ 和 $d = 1$），并通过一个确定性映射（例如对 $(s, i, d)$ 进行加密哈希）返回一个在 $(0,1)$ 区间内的伪随机均匀分布值。对于固定的 $s$，此映射关于 $(i, d)$ 是单射的，并且产生固定的输出，与工作节点数量或调度无关。然后，从均匀分布到所需分布的变换过程是确定性的。\n\n具体来说，为了从均匀分布变量获得标准正态分布变量，我们使用源于基础概率论的Box–Muller变换：给定两个独立的 $U_1, U_2 \\sim \\text{Uniform}(0,1)$，定义\n$$\nZ = \\sqrt{-2 \\ln U_1} \\cos(2 \\pi U_2),\n$$\n这会产生 $Z \\sim \\mathcal{N}(0,1)$。为避免 $U_1 = 0$ 或 $U_1 = 1$ 的边界问题，我们将哈希输出映射到严格在 $(0,1)$ 区间内的值，例如通过将整数表示缩放到 $(0,1)$ 并加上一个微小的偏移量。使用两对 $(U_1, U_2)$ 和 $(U_3, U_4)$ 可以产生两个独立标准正态变量，我们将它们转换为 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$（即 $\\epsilon = \\sigma Z_{\\epsilon}$）和对数正态定标因子 $c = \\exp\\left(\\mu_c + \\sigma_c Z_c\\right)$。\n\n可复现性证明简述：在集中式模式中，对于每个索引 $i \\in \\{0, \\ldots, N-1\\}$，模拟器使用对应于所需随机变量的固定 $d$ 值的抽取 $U(s, i, d)$ 来计算 $A_i$。在分布式模式中，相同的索引集被划分到 $W$ 个工作节点上（无论是通过连续块还是轮询方式），但每个工作节点仍然使用相同的确定性函数 $U(s, i, d)$ 来计算 $A_i$，并将结果放置在全局位置 $i$。因为 $U$ 仅依赖于 $(s, i, d)$ 而不依赖于工作节点标识符或调度，所以分布式模式生成的序列 $\\{A_i\\}$ 在按 $i$ 聚合后与集中式模式生成的序列完全相同。因此，无论 $W$ 或分区方案如何，逐元素相等性都成立，这 dimostrates 了随机种子管理和流分区如何确保可复现性。\n\n算法步骤：\n1. 定义一个确定性函数，通过哈希将 $(s, i, d)$ 映射到一个 $64$ 位整数，然后再映射到 $(0,1)$ 区间内一个严格有界的均匀分布值，以避免 $0$ 和 $1$。\n2. 实现Box–Muller变换，使用两个独立的均匀分布变量生成一个标准正态变量 $Z_{\\epsilon}$ 用于 $\\epsilon$，并使用另外一个独立标准正态变量 $Z_c$ 用于定标因子 $c$。\n3. 在集中式模式中，为所有 $i$ 计算 $A_i = c_i \\left(\\bar{A} + \\epsilon_i \\right)$，以生成一个按 $i$ 排序的数组。\n4. 使用指定方案为分布式模式划分索引，为每个分配的 $i$ 使用相同的映射 $U(s, i, d)$ 计算 $A_i$，并将结果聚合成一个按 $i$ 排序的数组。\n5. 逐元素比较两个数组是否相等，为每个测试用例生成一个布尔值。\n\n边界情况与数值考量：\n- 当 $N = 1$ 时，该方法仍然有效，因为映射对任何索引集都是明确定义的。\n- 均匀分布的映射必须避开精确的 $0$ 或 $1$，以确保Box–Muller变换中的对数和三角函数有定义；映射到 $(0,1)$ 并加上一个微小偏移量可以确保数值稳定性。\n- 因为在两种模式下，每个 $i$ 对应的 $A_i$ 计算方式完全相同，所以相等性是精确的，而不仅仅是在某个容差范围内。\n\n最终程序实现了上述设计，执行测试套件，并打印一个用方括号括起来的、逗号分隔的布尔值列表，以表明每个测试用例的可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport hashlib\nfrom typing import List, Tuple, Dict\n\n# Deterministic mapping from (seed, sample_id, draw_index) to a uniform in (0,1).\ndef _hash_to_uint64(seed: int, sample_id: int, draw_index: int) -> int:\n    # Use SHA-256 for a deterministic hash, and extract 64 bits.\n    # Encode the tuple as ASCII to ensure reproducibility across platforms.\n    msg = f\"{seed}:{sample_id}:{draw_index}\".encode(\"utf-8\")\n    digest = hashlib.sha256(msg).digest()\n    # Take the first 8 bytes as a big-endian unsigned integer.\n    return int.from_bytes(digest[:8], byteorder=\"big\", signed=False)\n\ndef _uniform01(seed: int, sample_id: int, draw_index: int) -> float:\n    # Map uint64 in [0, 2**64 - 1] to a float strictly in (0, 1).\n    u64 = _hash_to_uint64(seed, sample_id, draw_index)\n    # Add 1 and divide by (2**64 + 2) to avoid exact 0 and 1.\n    return (u64 + 1) / (2**64 + 2)\n\ndef _standard_normal_box_muller(u1: float, u2: float) -> float:\n    # Box-Muller transform: Z = sqrt(-2 ln u1) * cos(2 pi u2)\n    r = np.sqrt(-2.0 * np.log(u1))\n    theta = 2.0 * np.pi * u2\n    return r * np.cos(theta)\n\ndef _sample_AOD_for_index(\n    i: int,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) -> float:\n    # Generate two independent standard normals:\n    # For epsilon: use draw indices 0 and 1\n    u1_eps = _uniform01(seed, i, 0)\n    u2_eps = _uniform01(seed, i, 1)\n    z_eps = _standard_normal_box_muller(u1_eps, u2_eps)\n    epsilon = sigma * z_eps\n\n    # For calibration factor c: use draw indices 2 and 3\n    u1_c = _uniform01(seed, i, 2)\n    u2_c = _uniform01(seed, i, 3)\n    z_c = _standard_normal_box_muller(u1_c, u2_c)\n    c = np.exp(mu_c + sigma_c * z_c)\n\n    # AOD sample\n    return c * (A_bar + epsilon)\n\ndef centralized_simulation(\n    N: int,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) -> np.ndarray:\n    # Compute A_i for i in [0, N)\n    out = np.empty(N, dtype=np.float64)\n    for i in range(N):\n        out[i] = _sample_AOD_for_index(i, seed, A_bar, sigma, mu_c, sigma_c)\n    return out\n\ndef partition_indices(N: int, W: int, scheme: str) -> List[List[int]]:\n    # Returns a list of lists; each inner list contains indices assigned to one worker.\n    if W == 0:\n        raise ValueError(\"Number of workers must be positive.\")\n    partitions: List[List[int]] = [[] for _ in range(W)]\n    if scheme == \"contiguous\":\n        # Split into contiguous blocks as evenly as possible.\n        # Compute sizes using floor division and remainder distribution.\n        base = N // W\n        rem = N % W\n        start = 0\n        for w in range(W):\n            size = base + (1 if w  rem else 0)\n            end = start + size\n            partitions[w] = list(range(start, end))\n            start = end\n    elif scheme == \"roundrobin\":\n        for i in range(N):\n            partitions[i % W].append(i)\n    else:\n        raise ValueError(f\"Unknown partitioning scheme: {scheme}\")\n    return partitions\n\ndef distributed_simulation(\n    N: int,\n    W: int,\n    scheme: str,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) - np.ndarray:\n    # Partition indices according to scheme, compute on each worker, and aggregate.\n    partitions = partition_indices(N, W, scheme)\n    out = np.empty(N, dtype=np.float64)\n    for worker_indices in partitions:\n        for i in worker_indices:\n            out[i] = _sample_AOD_for_index(i, seed, A_bar, sigma, mu_c, sigma_c)\n    return out\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (N, A_bar, sigma, mu_c, sigma_c, seed, W, partitioning)\n    test_cases: List[Tuple[int, float, float, float, float, int, int, str]] = [\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 4, \"contiguous\"),\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 1, \"contiguous\"),\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 7, \"roundrobin\"),\n        (1,     0.5, 0.05, 0.0, 0.1, 987654321, 3, \"contiguous\"),\n        (5000,  0.5, 0.05, 0.0, 0.1, 123456789, 8, \"roundrobin\"),\n    ]\n\n    results: List[bool] = []\n    for case in test_cases:\n        N, A_bar, sigma, mu_c, sigma_c, seed, W, scheme_name = case\n        # Map scheme_name to internal\n        scheme = \"contiguous\" if scheme_name == \"contiguous blocks\" else scheme_name\n        # Centralized\n        central = centralized_simulation(N, seed, A_bar, sigma, mu_c, sigma_c)\n        # Distributed\n        distributed = distributed_simulation(N, W, scheme, seed, A_bar, sigma, mu_c, sigma_c)\n        # Reproducibility check: exact element-wise equality\n        results.append(np.array_equal(central, distributed))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Adjust names in test cases to match internal scheme keys\n# The problem statement used natural language names; map them here.\ndef _normalize_partition_name(name: str) - str:\n    if name == \"contiguous blocks\" or name == \"contiguous\":\n        return \"contiguous\"\n    elif name == \"round-robin\" or name == \"roundrobin\":\n        return \"roundrobin\"\n    else:\n        return name\n\n# Override solve to normalize names before using\ndef solve():\n    test_cases_raw: List[Dict] = [\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 4, \"partitioning\": \"contiguous blocks\"},\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 1, \"partitioning\": \"single worker\"},\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 7, \"partitioning\": \"round-robin\"},\n        {\"N\": 1,     \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 3, \"partitioning\": \"contiguous blocks\"},\n        {\"N\": 5000,  \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 123456789, \"W\": 8, \"partitioning\": \"round-robin\"},\n    ]\n\n    # Normalize partitioning descriptors\n    for tc in test_cases_raw:\n        part = tc[\"partitioning\"]\n        if part == \"single worker\":\n            tc[\"partitioning\"] = \"contiguous\"\n        elif part == \"round-robin\":\n            tc[\"partitioning\"] = \"roundrobin\"\n        elif part == \"contiguous blocks\":\n            tc[\"partitioning\"] = \"contiguous\"\n\n    results: List[bool] = []\n    for tc in test_cases_raw:\n        central = centralized_simulation(tc[\"N\"], tc[\"seed\"], tc[\"A_bar\"], tc[\"sigma\"], tc[\"mu_c\"], tc[\"sigma_c\"])\n        distributed = distributed_simulation(tc[\"N\"], tc[\"W\"], tc[\"partitioning\"], tc[\"seed\"], tc[\"A_bar\"], tc[\"sigma\"], tc[\"mu_c\"], tc[\"sigma_c\"])\n        results.append(np.array_equal(central, distributed))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "拥有了确保随机和确定性计算均可复现的工具后，我们便可以将这些原则应用于实际的业务决策支持中。本练习将指导您建立一个严谨的统计框架，用于比较两个NDVI产品，这是评估不同遥感产品一致性的关键技能。您将学习如何应用等效性检验（TOST）和基于误差预算的容差，为“两个数据集是否足够相似”这一问题提供一个量化且可复现的答案。",
            "id": "3841832",
            "problem": "一个环境监测中心必须根据两个归一化植被指数 (NDVI) 产品之间的一致性来做出业务决策，这些产品是针对相同的地理足迹和时间窗口计算的，但使用了不同的软件栈。归一化植被指数 (NDVI) 是一个无量纲量，其值界于 $-1$ 和 $+1$ 之间。目标是设计并实现一个严谨、可复现的工作流，用于判断这两个 NDVI 产品是否在由明确的误差预算和统计等效性准则定义的容差范围内是可复现的。\n\n构建一个基于第一性原理的决策程序，该程序需同时强制执行以下两个条件。\n\n1. 平均偏差的统计等效性：使用双单侧检验 (TOST) 来判断逐像素差异均值的等效性。令 $d_i = a_i - b_i$ 表示每个像素的差异，其中 $a_i$ 和 $b_i$ 分别是产品 $\\mathcal{A}$ 和产品 $\\mathcal{B}$ 中对应像素的 NDVI 值，其中 $i = 1, \\dots, n$。令每个案例的决策显著性水平为 $\\alpha$。均值的等效性界限为 $\\epsilon_{\\mu}$，该值必须根据下文的容差预算和一个指定的策略因子推导得出。当且仅当均值差异的 $100 \\cdot (1 - 2\\alpha)$% 置信区间完全位于区间 $\\left[-\\epsilon_{\\mu}, \\epsilon_{\\mu}\\right]$ 内时，检验必须判定为等效。\n\n2. 空间一致性的业务容差：令 $\\epsilon$ 为根据下文误差预算推导出的总体逐像素绝对差异容差。定义 $p$ 为满足 $|d_i| \\le \\epsilon$ 的像素比例。当且仅当 $p$ 的单侧 $1 - \\alpha$ 置信下界（使用 Clopper–Pearson 方法精确计算）至少达到目标比例 $p_0$ 时，才要求业务可复现性，其中 $p_0$ 由策略设定。\n\n容差定义与误差预算：逐像素容差 $\\epsilon$ 必须通过对独立的、特征明确的不确定性来源进行方和根 (RSS) 组合来计算，这与独立随机误差的传播方式一致。对于以下三个贡献源，$\\epsilon$ 定义为\n$$\n\\epsilon = \\sqrt{\\epsilon_{\\text{inst}}^2 + \\epsilon_{\\text{atm}}^2 + \\epsilon_{\\text{proc}}^2},\n$$\n其中 $\\epsilon_{\\text{inst}}$ 是由仪器辐射不确定度映射到 NDVI 的贡献，$\\epsilon_{\\text{atm}}$ 是由残余大气校正不确定度映射到 NDVI 的贡献，$\\epsilon_{\\text{proc}}$ 是由地理定位、重采样和插值不匹配映射到 NDVI 的贡献。均值等效性界限为 $\\epsilon_{\\mu} = \\lambda \\, \\epsilon$，其中 $\\lambda \\in (0, 1]$ 是一个指定的策略因子。\n\n您的程序必须为以下测试套件实现上述决策程序。对于每个测试案例，使用给定的公式确定性地构建产品 $\\mathcal{A}$ 和 $\\mathcal{B}$，然后以布尔值的形式决定其可复现性。由于 NDVI 是无量纲的，因此不需要物理单位。三角函数中出现的角度以弧度为单位。\n\n在所有测试案例中，使用 $\\alpha = 0.05$ 和 $\\lambda = 0.8$。\n\n- 案例 1（常规“理想路径”）：令 $n = 200$。对于 $i = 0, 1, \\dots, n-1$，\n  $$\n  a_i = 0.6 + 0.2 \\sin\\left(\\frac{2\\pi i}{n}\\right) - 0.1 \\sin\\left(\\frac{4\\pi i}{n}\\right),\n  $$\n  $$\n  b_i = a_i + 0.005 + 0.01 \\cos\\left(\\frac{2\\pi i}{n}\\right).\n  $$\n  误差预算分量为 $\\epsilon_{\\text{inst}} = 0.020$，$\\epsilon_{\\text{atm}} = 0.015$，$\\epsilon_{\\text{proc}} = 0.010$。业务比例目标为 $p_0 = 0.90$。\n\n- 案例 2（严格容差，应失败）：令 $n = 200$。对于 $i = 0, 1, \\dots, n-1$，\n  $$\n  a_i = 0.5 + 0.25 \\sin\\left(\\frac{2\\pi i}{n}\\right),\n  $$\n  $$\n  b_i = a_i + 0.040 + 0.020 \\sin\\left(\\frac{6\\pi i}{n}\\right).\n  $$\n  误差预算分量为 $\\epsilon_{\\text{inst}} = 0.010$，$\\epsilon_{\\text{atm}} = 0.005$，$\\epsilon_{\\text{proc}} = 0.005$。业务比例目标为 $p_0 = 0.95$。\n\n- 案例 3（小样本量，应通过）：令 $n = 12$。对于 $i = 0, 1, \\dots, n-1$，\n  $$\n  a_i = 0.4 + 0.1 \\sin\\left(\\frac{2\\pi i}{n}\\right),\n  $$\n  $$\n  b_i = a_i + 0.002 + 0.003 \\sin\\left(\\frac{4\\pi i}{n}\\right).\n  $$\n  误差预算分量为 $\\epsilon_{\\text{inst}} = 0.020$，$\\epsilon_{\\text{atm}} = 0.008$，$\\epsilon_{\\text{proc}} = 0.005$。业务比例目标为 $p_0 = 0.85$。\n\n- 案例 4（临界系统性偏差）：令 $n = 300$。对于 $i = 0, 1, \\dots, n-1$，\n  $$\n  a_i = 0.55 + 0.15 \\sin\\left(\\frac{2\\pi i}{n}\\right) - 0.05 \\cos\\left(\\frac{8\\pi i}{n}\\right),\n  $$\n  $$\n  b_i = a_i + 0.020.\n  $$\n  误差预算分量为 $\\epsilon_{\\text{inst}} = 0.010$，$\\epsilon_{\\text{atm}} = 0.015$，$\\epsilon_{\\text{proc}} = 0.010$。业务比例目标为 $p_0 = 0.95$。\n\n决策与输出规范：对每个案例，返回一个布尔值。当且仅当上述条件 1 和条件 2 同时满足时，该值为真。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1, result_2, result_3, result_4]$），其中每个 $result_k$ 对应于上述列表中相应测试案例的结果（$True$ 或 $False$）。不应打印任何其他文本。",
            "solution": "该问题要求设计并实现一个可复现的决策工作流，以评估两个被指定为 $\\mathcal{A}$ 和 $\\mathcal{B}$ 的归一化植被指数 (NDVI) 产品的可复现性。可复现性是通过同时满足两个不同的统计准则来确定的：一个涉及产品间的平均偏差，另一个涉及逐像素差异的空间一致性。整个程序在指定的显著性水平 $\\alpha$ 下执行。\n\n设两个 NDVI 产品由 $n$ 个对应像素的像素值数组 $\\{a_i\\}_{i=1}^n$ 和 $\\{b_i\\}_{i=1}^n$ 表示。逐像素差异定义为 $d_i = a_i - b_i$。\n\n决策程序的核心是一个由两部分组成的假设检验。判定为可复现要求两个条件都得到满足。\n\n**条件 1：平均偏差的统计等效性**\n\n此条件评估两个产品之间的平均差异是否小到可以忽略不计。我们使用双单侧检验 (TOST) 程序进行等效性检验。这两个检验的原假设是真实均值差异 $\\mu_d$ 位于等效性界限 $[-\\epsilon_{\\mu}, \\epsilon_{\\mu}]$ 之外。我们检验 $H_{0,1}: \\mu_d \\ge \\epsilon_{\\mu}$ 和 $H_{0,2}: \\mu_d \\le -\\epsilon_{\\mu}$。如果 $\\mu_d$ 的 $100 \\cdot (1 - 2\\alpha)\\%$ 置信区间完全包含在区间 $[-\\epsilon_{\\mu}, \\epsilon_{\\mu}]$ 内，我们就可以判定为等效（即拒绝两个原假设）。\n\n均值的等效性界限 $\\epsilon_{\\mu}$ 是从总逐像素容差 $\\epsilon$ 和一个策略因子 $\\lambda \\in (0, 1]$ 推导出来的。总容差 $\\epsilon$ 是通过使用方和根 (RSS) 方法组合独立的误差源——仪器（$\\epsilon_{\\text{inst}}$）、大气（$\\epsilon_{\\text{atm}}$）和处理（$\\epsilon_{\\text{proc}}$）——来计算的，这是传播独立随机误差的标准方法：\n$$\n\\epsilon = \\sqrt{\\epsilon_{\\text{inst}}^2 + \\epsilon_{\\text{atm}}^2 + \\epsilon_{\\text{proc}}^2}\n$$\n然后，均值等效性界限是该总容差的一部分：\n$$\n\\epsilon_{\\mu} = \\lambda \\, \\epsilon\n$$\n令 $\\bar{d}$ 为差异 $d_i$ 的样本均值，令 $s_d$ 为样本标准差。对于样本量 $n  1$，均值的标准误差为 $SE = s_d / \\sqrt{n}$。$\\mu_d$ 的 $100 \\cdot (1 - 2\\alpha)\\%$ 置信区间由下式给出：\n$$\nCI_{1-2\\alpha} = \\left[ \\bar{d} - t_{1-\\alpha, n-1} \\frac{s_d}{\\sqrt{n}}, \\bar{d} + t_{1-\\alpha, n-1} \\frac{s_d}{\\sqrt{n}} \\right]\n$$\n其中 $t_{1-\\alpha, n-1}$ 是自由度为 $n-1$ 的学生t分布的临界值，该值被超出的概率为 $\\alpha$。当且仅当满足以下条件时，等效性条件成立：\n$$\n\\left( \\bar{d} + t_{1-\\alpha, n-1} \\frac{s_d}{\\sqrt{n}} \\right)  \\epsilon_{\\mu} \\quad \\text{AND} \\quad \\left( \\bar{d} - t_{1-\\alpha, n-1} \\frac{s_d}{\\sqrt{n}} \\right)  -\\epsilon_{\\mu}\n$$\n如果 $s_d = 0$，置信区间将收缩为点估计 $[\\bar{d}, \\bar{d}]$，检验将根据该点是否落在 $(-\\epsilon_{\\mu}, \\epsilon_{\\mu})$ 内来正确判断等效性。\n\n**条件 2：空间一致性的业务容差**\n\n此条件确保足够大比例的单个像素在总体容差 $\\epsilon$ 内达成一致。令 $p$ 为总体中绝对差异在容差范围内（即 $|d_i| \\le \\epsilon$）的像素的真实比例。我们从 $n$ 个像素的样本中估计这个比例。令 $k$ 为样本中满足 $|d_i| \\le \\epsilon$ 的像素数量。样本比例为 $\\hat{p} = k/n$。\n\n为了考虑抽样不确定性，决策不基于点估计 $\\hat{p}$，而是基于真实比例 $p$ 的一个保守置信下界。我们计算 $p$ 的单侧 $1-\\alpha$ 置信下界，记为 $p_{\\text{lower}}$。问题指定使用精确的 Clopper-Pearson 方法。该方法将下界 $p_{\\text{lower}}$ 定义为这样一个 $p$ 值：在 $n$ 次试验中观测到 $k$ 次或更多次“成功”（像素在容差内）的概率等于 $\\alpha$。该界限使用贝塔分布的分位数函数（逆累积分布函数）计算：\n$$\np_{\\text{lower}} = \\text{Beta.ppf}(\\alpha; k, n - k + 1)\n$$\n其中 $\\text{Beta.ppf}(\\cdot; a, b)$ 是形状参数为 $a$ 和 $b$ 的贝塔分布的分位数函数。如果 $k=0$，会出现一个特殊情况，此时下界被正确定义为 $p_{\\text{lower}} = 0$。\n\n当且仅当该下界达到或超过预定义的策略目标比例 $p_0$ 时，满足业务可复现性的条件：\n$$\np_{\\text{lower}} \\ge p_0\n$$\n\n**最终决策**\n对每个测试案例，当且仅当条件1和条件2都满足时，确认可复现性（结果为 `True`）。若任一条件不满足，则结果为 `False`。实施时将为每个测试案例计算必要的量，并应用这两个决策规则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to execute the decision procedure for all test cases.\n    \"\"\"\n\n    def evaluate_replicability(\n        a_vals, b_vals, n, eps_inst, eps_atm, eps_proc, p0, alpha, lambda_val\n    ):\n        \"\"\"\n        Evaluates replicability for a single test case based on the two conditions.\n\n        Args:\n            a_vals (np.ndarray): NDVI values for product A.\n            b_vals (np.ndarray): NDVI values for product B.\n            n (int): Number of pixels.\n            eps_inst (float): Instrument error component.\n            eps_atm (float): Atmospheric error component.\n            eps_proc (float): Processing error component.\n            p0 (float): Target fraction for spatial agreement.\n            alpha (float): Significance level.\n            lambda_val (float): Policy factor for mean equivalence margin.\n\n        Returns:\n            bool: True if both conditions are met, False otherwise.\n        \"\"\"\n        # Calculate per-pixel differences\n        d = a_vals - b_vals\n\n        # --- Condition 1: Statistical equivalence of mean bias (TOST) ---\n\n        # Calculate total tolerance and mean equivalence margin\n        epsilon = np.sqrt(eps_inst**2 + eps_atm**2 + eps_proc**2)\n        epsilon_mu = lambda_val * epsilon\n\n        # Calculate sample statistics for the differences\n        d_mean = np.mean(d)\n        d_std = np.std(d, ddof=1)\n        \n        # Handle the case of n=1\n        if n = 1:\n            cond1_passed = False\n        # Handle the case where all differences are identical (std dev is 0)\n        elif d_std == 0.0:\n            ci_lower = d_mean\n            ci_upper = d_mean\n            cond1_passed = (ci_lower > -epsilon_mu) and (ci_upper  epsilon_mu)\n        else:\n            # Calculate standard error and critical t-value\n            se_mean = d_std / np.sqrt(n)\n            t_crit = stats.t.ppf(1 - alpha, df=n - 1)\n            \n            # Calculate the 100*(1-2*alpha)% confidence interval\n            ci_half_width = t_crit * se_mean\n            ci_lower = d_mean - ci_half_width\n            ci_upper = d_mean + ci_half_width\n            \n            # Check if CI is within the equivalence margin\n            cond1_passed = (ci_lower > -epsilon_mu) and (ci_upper  epsilon_mu)\n\n        # --- Condition 2: Operational tolerance on spatial agreement ---\n\n        # Count pixels within the absolute difference tolerance epsilon\n        k = np.sum(np.abs(d) = epsilon)\n\n        # Calculate the one-sided 1-alpha Clopper-Pearson lower bound for the proportion p\n        if k == 0:\n            p_lower = 0.0\n        else:\n            p_lower = stats.beta.ppf(alpha, k, n - k + 1)\n        \n        # Check if the lower bound meets the target fraction p0\n        cond2_passed = (p_lower >= p0)\n\n        # Final decision: replicable only if both conditions pass\n        return cond1_passed and cond2_passed\n\n    # Global parameters for all cases\n    ALPHA = 0.05\n    LAMBDA = 0.8\n\n    # Define test cases\n    test_cases = [\n        {\n            \"n\": 200, \"p0\": 0.90, \"eps_inst\": 0.020, \"eps_atm\": 0.015, \"eps_proc\": 0.010,\n            \"a_func\": lambda i, n: 0.6 + 0.2 * np.sin(2 * np.pi * i / n) - 0.1 * np.sin(4 * np.pi * i / n),\n            \"b_func\": lambda a_i, i, n: a_i + 0.005 + 0.01 * np.cos(2 * np.pi * i / n),\n        },\n        {\n            \"n\": 200, \"p0\": 0.95, \"eps_inst\": 0.010, \"eps_atm\": 0.005, \"eps_proc\": 0.005,\n            \"a_func\": lambda i, n: 0.5 + 0.25 * np.sin(2 * np.pi * i / n),\n            \"b_func\": lambda a_i, i, n: a_i + 0.040 + 0.020 * np.sin(6 * np.pi * i / n),\n        },\n        {\n            \"n\": 12, \"p0\": 0.85, \"eps_inst\": 0.020, \"eps_atm\": 0.008, \"eps_proc\": 0.005,\n            \"a_func\": lambda i, n: 0.4 + 0.1 * np.sin(2 * np.pi * i / n),\n            \"b_func\": lambda a_i, i, n: a_i + 0.002 + 0.003 * np.sin(4 * np.pi * i / n),\n        },\n        {\n            \"n\": 300, \"p0\": 0.95, \"eps_inst\": 0.010, \"eps_atm\": 0.015, \"eps_proc\": 0.010,\n            \"a_func\": lambda i, n: 0.55 + 0.15 * np.sin(2 * np.pi * i / n) - 0.05 * np.cos(8 * np.pi * i / n),\n            \"b_func\": lambda a_i, i, n: a_i + 0.020,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        n = case[\"n\"]\n        i_vals = np.arange(n)\n        a_vals = case[\"a_func\"](i_vals, n)\n        b_vals = case[\"b_func\"](a_vals, i_vals, n)\n        \n        result = evaluate_replicability(\n            a_vals, b_vals, n, case[\"eps_inst\"], case[\"eps_atm\"], \n            case[\"eps_proc\"], case[\"p0\"], ALPHA, LAMBDA\n        )\n        results.append(result)\n\n    # Print final results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了随机模拟的可复现性后，我们转向另一个微妙但同样关键的挑战：并行硬件（如GPU）上的浮点运算。本练习将揭示计算机数学的非结合性如何导致理论上确定性的计算在实践中产生不可复现的结果，并教授强制实现位对位确定性的方法。对于任务关键型的业务工作流来说，确保数值计算的确定性至关重要。",
            "id": "3841888",
            "problem": "您正在为一个用于业务决策支持流程的卫星图像应用设计一个确定性的图形处理单元 (GPU) 卷积工作流。目标是在确保多次运行之间按位可复现性的同时，量化强制执行确定性所带来的性能权衡。您的推理必须基于以下基本事实和定义：\n\n- 将尺寸为 $H \\times W$ 的图像 $I$ 与尺寸为 $K_h \\times K_w$ 的核 $K$ 进行有效模式 (valid mode) 的离散二维卷积，会产生一个尺寸为 $(H - K_h + 1) \\times (W - K_w + 1)$ 的输出 $O$，其定义为\n$$\nO[y,x] = \\sum_{i=0}^{K_h-1} \\sum_{j=0}^{K_w-1} I[y+i, x+j] \\cdot K[i,j].\n$$\n\n- 在电气与电子工程师协会 (Institute of Electrical and Electronics Engineers, IEEE) $754$ 算术中，浮点加法不满足结合律。对于实数 $a$、$b$ 和 $c$，当使用有限精度计算时，通常有 $(a+b)+c \\neq a+(b+c)$。因此，求和的顺序以及在并行硬件上调度部分和的方式会引发不同的舍入序列和结果。\n\n- 并行归约中的确定性是通过固定加法顺序和归约树形状来强制执行的。当输入顺序固定时，成对（平衡）求和会产生一个确定性的和，并且与纯粹从左到右的累加相比，减少了舍入误差的增长。\n\n- Kahan 补偿求和会累积一个运行中的补偿项，以校正丢失的低位比特。对于一个包含 $K$ 个项且机器 epsilon 为 $\\varepsilon$ 的序列，朴素求和的误差以 $\\mathcal{O}(K \\varepsilon)$ 的量级增长，而 Kahan 求和则会显著减少误差，在实践中对于良态和，误差通常接近 $\\mathcal{O}(\\varepsilon)$。\n\n为了在没有实际 GPU 代码的情况下模拟 GPU 调度效应，请在合成图像上实现三种卷积模式：\n\n- 模式 A（非确定性浮点）：对于每个输出像素，计算 $K = K_h \\cdot K_w$ 个乘积，但在每次运行和每个像素的求和过程中使用一个新的随机排列。使用 $32$ 位浮点数进行累加。在多个独立的种子上重复此过程，以模拟不同的线程块调度和归约顺序。这捕捉了非确定性的舍入。\n\n- 模式 B（确定性成对浮点）：对于每个输出像素，使用一个完全确定性的成对归约树，按 $(i,j)$ 的固定字典序累加 $K$ 个乘积，使用 $32$ 位浮点数。\n\n- 模式 C（确定性 Kahan 浮点）：对于每个输出像素，使用 Kahan 补偿求和，以相同的固定顺序序列进行累加，使用 $64$ 位浮点数。\n\n待卷积的合成数据：\n\n- 图像 $I$：对于整数坐标 $0 \\le y  H$，$0 \\le x  W$，定义\n$$\nI[y,x] = \\operatorname{float32}\\left(0.5 + 0.5 \\tanh\\left(0.25 \\sin(0.11 y + 0.07 x) + 0.75 \\cos(0.03 y^2 + 0.05 x)\\right)\\right).\n$$\n\n- 核 $K$：一个二维高斯函数，标准差 $\\sigma = \\max(K_h, K_w)/3$，在 $K_h \\times K_w$ 网格上采样，中心位于 $\\left(\\frac{K_h-1}{2}, \\frac{K_w-1}{2}\\right)$，并归一化使其和为 $1$。模式 A 和模式 B 使用 $32$ 位浮点数，模式 C 使用 $64$ 位浮点数。\n\n确定性性能模型：\n\n- 令 $K = K_h \\cdot K_w$。使用一个简单的加法模型和操作权重 $c_{\\text{mul}}$、$c_{\\text{add}}$ 以及同步屏障成本 $c_{\\text{bar}}$ 来计算每个输出像素的成本。假设乘法和加法的成本分别为 $c_{\\text{mul}}$ 和 $c_{\\text{add}}$，并且平衡树需要 $\\lceil \\log_2 K \\rceil$ 个同步阶段，每个阶段的屏障成本为 $c_{\\text{bar}}$。在成本计算中，将减法视为加法。\n\n- 基准非确定性成本（朴素累加）：\n$$\nC_{\\text{base}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}}.\n$$\n\n- 确定性成对成本：\n$$\nC_{\\text{tree}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}}.\n$$\n\n- 确定性 Kahan 成本：\n$$\nC_{\\text{Kahan}} = K \\cdot c_{\\text{mul}} + 4K \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}},\n$$\n这反映了 Kahan 对每个项使用 $4$ 个类似加/减法的操作。\n\n对于每个测试用例，计算以下量：\n\n- $D_{\\text{ND}}$：在提供的种子上，所有非确定性输出对之间的最大绝对差。\n\n- $D_{\\text{ND-DET}}$：第一个非确定性输出（使用第一个种子）与确定性成对输出之间的最大绝对差。\n\n- $D_{\\text{DET-Kahan}}$：确定性成对输出与确定性 Kahan 输出之间的最大绝对差。\n\n- $S_{\\text{tree}} = C_{\\text{tree}} / C_{\\text{base}}$ 和 $S_{\\text{Kahan}} = C_{\\text{Kahan}} / C_{\\text{base}}$，相对于基准的预测性能下降率。\n\n- $R_{\\text{det}}$：一个布尔值，指示运行确定性成对计算两次是否产生按位相同的数组。\n\n- $H_{\\text{out}}$ 和 $W_{\\text{out}}$：输出维度。\n\n舍入和输出要求：\n\n- 将所有浮点结果 $D_{\\text{ND}}$、$D_{\\text{ND-DET}}$、$D_{\\text{DET-Kahan}}$、$S_{\\text{tree}}$ 和 $S_{\\text{Kahan}}$ 四舍五入到 $8$ 位小数。布尔值和整数输出不进行舍入。\n\n- 使用有效卷积（无填充，单位步长）。三角函数中的角度以弧度为单位。\n\n测试套件：\n\n为以下参数集提供结果。在每种情况下，按规定顺序使用给定的种子列表运行模式 A。\n\n- 情况 1：$H = 64$，$W = 64$，$K_h = 5$，$K_w = 5$，种子 $[101, 202, 303]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 8.0$。\n\n- 情况 2：$H = 8$，$W = 8$，$K_h = 3$，$K_w = 3$，种子 $[7, 11, 13]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 4.0$。\n\n- 情况 3：$H = 63$，$W = 57$，$K_h = 7$，$K_w = 7$，种子 $[42, 99, 123]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 16.0$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表。每个测试用例贡献一个内部列表，其条目严格按此顺序排列：\n$[D_{\\text{ND}}, D_{\\text{ND-DET}}, D_{\\text{DET-Kahan}}, S_{\\text{tree}}, S_{\\text{Kahan}}, R_{\\text{det}}, H_{\\text{out}}, W_{\\text{out}}]$。\n例如：\n\"[[d1,d2,d3,s1,s2,True,h,w],[...],[...]]\"。",
            "solution": "我们从核心定义和事实出发：离散卷积和电气与电子工程师协会 (IEEE) $754$ 中的浮点算术属性。有效模式的二维卷积将每个输出 $O[y,x]$ 计算为乘积的有限和\n$$\nO[y,x] = \\sum_{i=0}^{K_h-1} \\sum_{j=0}^{K_w-1} I[y+i, x+j] \\cdot K[i,j],\n$$\n其中有 $K = K_h \\cdot K_w$ 个被加数。当 $I$ 和 $K$ 是浮点数时，每个被加数都可以表示为一个浮点数。\n\n非结合性：在有限精度下，浮点加法既不完全满足结合律也不完全满足分配律。在 IEEE $754$ 的“舍入到最近偶数”模式下，对于表示为 $32$ 位或 $64$ 位浮点数的实数 $a$、$b$ 和 $c$，由于每次加法都会发生舍入，可能会有 $(a+b)+c \\neq a+(b+c)$。在图形处理单元 (GPU) 上的并行归约中，硬件或运行时可能会以每次运行都不同的顺序来调度部分和的计算与合并，特别是在使用原子操作或无约束的块调度时。这会导致非确定性的舍入序列，因此即使每次运行的输入完全相同，最终的位模式也可能不同。\n\n通过构造实现确定性：为确保按位可复现性，需要固定归约的输入顺序和归约树的形状，以便在每个层级，相同的数对都以相同的顺序相加。给定相同的输入，固定的成对方案会产生相同的结果。通过使用补偿求和（如 Kahan 算法）可以在数值上进一步提高可复现性，该算法通过跟踪一个补偿项 $c$ 来控制误差传播，该补偿项存储因舍入而丢失的低位比特。\n\n算法设计：\n\n- 数据生成。合成图像由以下公式确定性地定义：\n$$\nI[y,x] = \\operatorname{float32}\\left(0.5 + 0.5 \\tanh\\left(0.25 \\sin(0.11 y + 0.07 x) + 0.75 \\cos(0.03 y^2 + 0.05 x)\\right)\\right),\n$$\n其中 $y$ 和 $x$ 为整数，确保值在 $(0,1)$ 范围内。核是一个归一化的高斯函数：\n$$\nG[i,j] = \\exp\\left(-\\frac{(i-c_y)^2 + (j-c_x)^2}{2\\sigma^2}\\right), \\quad \\sigma = \\frac{\\max(K_h,K_w)}{3}, \\quad (c_y,c_x) = \\left(\\frac{K_h-1}{2}, \\frac{K_w-1}{2}\\right),\n$$\n然后以适当的精度计算 $K = G / \\sum_{i,j} G[i,j]$。\n\n- 模式 A（非确定性浮点）。对于每个输出坐标 $(y,x)$，按照字典索引顺序 $(i,j)$ 构建一个长度为 $K$ 的项列表：\n$$\nt_{i,j} = I[y+i,x+j] \\cdot K[i,j].\n$$\n然后，对于每个 $(y,x)$ 和每次运行，使用一个新的随机排列来打乱这个列表。使用 $32$ 位浮点数以简单的左折叠方式进行累加。在指定的种子上重复此过程，以模拟不同的块调度和归约顺序。不同的排列会改变舍入操作的顺序，从而可能改变每个输出元素的最终结果。\n\n- 模式 B（确定性成对浮点）。使用相同的字典序项顺序，但通过一个固定的成对（平衡）树进行求和。在每个层级，按从左到右的顺序将相邻的对相加，当长度为奇数时，将最后一个单独的项带到下一级，直到只剩下一个值。所有算术运算均使用 $32$ 位浮点数。这会在多次运行中产生相同的结果，因为顺序和树结构都是固定的。\n\n- 模式 C（确定性 Kahan 浮点）。使用相同的字典序，但使用 Kahan 补偿求和以 $64$ 位浮点数进行累加。Kahan 算法维护一个运行总和 $s$ 和一个补偿项 $c$，每个项 $\\tau$ 按以下方式更新：\n$$\ny = \\tau - c,\\quad t = s + y,\\quad c = (t - s) - y,\\quad s = t,\n$$\n这有效地重新注入了丢失的低位比特。结果是确定性的，并且通常更接近精确算术。\n\n性能模型推导：\n\n令 $K = K_h \\cdot K_w$。我们计算每个输出像素的操作数：\n\n- 乘法：总是 $K$ 次。\n\n- 加法。基准（模式 A）在左折叠中使用 $K-1$ 次加法。成对求和（模式 B）也使用 $K-1$ 次加法，但额外产生 $\\lceil \\log_2 K \\rceil$ 个同步阶段，以便在并行中执行平衡树归约。Kahan（模式 C）对每个项使用 $4$ 个类似加/减法的操作（一次加法和三次减法），近似为 $4K$ 次加法类操作，加上当映射到每个通道的序贯补偿并行树时相同的同步阶段。\n\n使用操作权重 $c_{\\text{mul}}$、$c_{\\text{add}}$ 和 $c_{\\text{bar}}$，我们得到\n$$\nC_{\\text{base}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}},\n$$\n$$\nC_{\\text{tree}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}},\n$$\n$$\nC_{\\text{Kahan}} = K \\cdot c_{\\text{mul}} + 4K \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}}.\n$$\n相对于基准的性能下降率为\n$$\nS_{\\text{tree}} = \\frac{C_{\\text{tree}}}{C_{\\text{base}}}, \\quad S_{\\text{Kahan}} = \\frac{C_{\\text{Kahan}}}{C_{\\text{base}}}.\n$$\n\n计算输出：\n\n对于每个测试用例，我们计算：\n\n- $D_{\\text{ND}} = \\max\\limits_{r \\neq s} \\|O^{(r)} - O^{(s)}\\|_{\\infty}$，其中 $r$ 和 $s$ 是在指定种子上的模式 A 的运行，$\\|\\cdot\\|_{\\infty}$ 是元素级的最大绝对差。\n\n- $D_{\\text{ND-DET}} = \\|O^{(r_0)} - O^{\\text{det}}\\|_{\\infty}$，表示第一次非确定性运行（种子顺序中的第一个元素）和确定性成对输出之间的差异。\n\n- $D_{\\text{DET-Kahan}} = \\|O^{\\text{det}} - O^{\\text{Kahan}}\\|_{\\infty}$，表示 $32$ 位确定性成对输出和 $64$ 位确定性 Kahan 输出之间的差异。\n\n- $S_{\\text{tree}}$ 和 $S_{\\text{Kahan}}$ 根据上述公式计算。\n\n- $R_{\\text{det}}$ 通过运行模式 B 两次并检查数组是否按位完全相等来计算。因为模式 B 固定了顺序和归约形状并使用相同的精度，所以多次运行的输出是相同的，因此 $R_{\\text{det}}$ 的值为 True。\n\n- $H_{\\text{out}} = H - K_h + 1$ 和 $W_{\\text{out}} = W - K_w + 1$。\n\n实现说明：\n\n- 为正确模拟累加过程中的 $32$ 位舍入行为，确保累加器变量是 $32$ 位浮点数，以便每次加法都舍入到 $32$ 位精度。\n\n- 模式 A 的随机排列应为每个输出元素和每次运行生成，以模拟不同的调度和归约顺序。\n\n- 按要求将浮点输出舍入到 $8$ 位小数。\n\n边界情况：\n\n- 小核如 $K_h = 3$, $K_w = 3$ 产生 $K = 9$，此时由非结合性引起的差异可能很小，但在 $32$ 位算术中通常仍然非零。\n\n- 奇数维度和更大的核（例如 $K_h = 7$, $K_w = 7$）为每个输出产生更多的被加数，因此通常会放大非确定性差异以及 Kahan 求和的精度优势。\n\n程序实现了所有三种模式，使用指定的种子和权重运行三个测试用例，计算每个用例所需的八个输出，将浮点结果舍入到 $8$ 位小数，并按规定的确切顺序列出每个用例的结果列表，打印为单行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_image(H, W):\n    # Deterministic synthetic image in float32, values in (0,1)\n    y = np.arange(H, dtype=np.float64).reshape(H, 1)\n    x = np.arange(W, dtype=np.float64).reshape(1, W)\n    expr = 0.25 * np.sin(0.11 * y + 0.07 * x) + 0.75 * np.cos(0.03 * (y ** 2) + 0.05 * x)\n    img = 0.5 + 0.5 * np.tanh(expr)\n    return img.astype(np.float32)\n\ndef gaussian_kernel(Kh, Kw, dtype=np.float32):\n    cy = (Kh - 1) / 2.0\n    cx = (Kw - 1) / 2.0\n    sigma = max(Kh, Kw) / 3.0\n    y = np.arange(Kh, dtype=np.float64).reshape(Kh, 1)\n    x = np.arange(Kw, dtype=np.float64).reshape(1, Kw)\n    gy = (y - cy) ** 2\n    gx = (x - cx) ** 2\n    G = np.exp(-(gy + gx) / (2.0 * sigma * sigma))\n    G = G / np.sum(G)\n    return G.astype(dtype)\n\ndef terms_lexicographic(image, kernel, y, x):\n    Kh, Kw = kernel.shape\n    # Produce list of terms in lexicographic (i,j) order\n    terms = []\n    for i in range(Kh):\n        for j in range(Kw):\n            terms.append(image[y + i, x + j] * kernel[i, j])\n    return terms\n\ndef sum_nondet_f32(terms, rng):\n    # Shuffle order and accumulate in float32 left fold\n    idx = rng.permutation(len(terms))\n    s = np.float32(0.0)\n    for k in idx:\n        s = np.float32(s + np.float32(terms[k]))\n    return s\n\ndef sum_pairwise_f32(terms):\n    # Deterministic pairwise reduction in float32\n    # Copy to a float32 list\n    arr = [np.float32(t) for t in terms]\n    n = len(arr)\n    if n == 0:\n        return np.float32(0.0)\n    while len(arr) > 1:\n        new_arr = []\n        m = len(arr)\n        i = 0\n        while i + 1  m:\n            new_arr.append(np.float32(arr[i] + arr[i + 1]))\n            i += 2\n        if i  m:\n            # carry last\n            new_arr.append(arr[i])\n        arr = new_arr\n    return np.float32(arr[0])\n\ndef sum_kahan_f64(terms):\n    # Kahan compensated summation in float64\n    s = np.float64(0.0)\n    c = np.float64(0.0)\n    for t in terms:\n        tau = np.float64(t)\n        y = tau - c\n        tsum = s + y\n        c = (tsum - s) - y\n        s = tsum\n    return s\n\ndef conv2d_valid_nondet_f32(image, kernel, seed):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float32)\n    rng = np.random.default_rng(seed)\n    # Compute per output pixel\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_nondet_f32(terms, rng)\n    return out\n\ndef conv2d_valid_det_pairwise_f32(image, kernel):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float32)\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_pairwise_f32(terms)\n    return out\n\ndef conv2d_valid_det_kahan_f64(image, kernel):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float64)\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_kahan_f64(terms)\n    return out\n\ndef max_abs_diff(a, b):\n    return float(np.max(np.abs(a.astype(np.float64) - b.astype(np.float64))))\n\ndef predicted_slowdowns(Kh, Kw, c_mul, c_add, c_bar):\n    K = Kh * Kw\n    C_base = K * c_mul + (K - 1) * c_add\n    C_tree = K * c_mul + (K - 1) * c_add + (int(np.ceil(np.log2(K))) * c_bar)\n    C_kahan = K * c_mul + (4 * K) * c_add + (int(np.ceil(np.log2(K))) * c_bar)\n    return C_tree / C_base, C_kahan / C_base\n\ndef round8(x):\n    return float(np.round(x, 8))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (H, W, Kh, Kw, seeds_list, c_mul, c_add, c_bar)\n    test_cases = [\n        (64, 64, 5, 5, [101, 202, 303], 1.0, 1.0, 8.0),\n        (8, 8, 3, 3, [7, 11, 13], 1.0, 1.0, 4.0),\n        (63, 57, 7, 7, [42, 99, 123], 1.0, 1.0, 16.0),\n    ]\n\n    results = []\n    for H, W, Kh, Kw, seeds, c_mul, c_add, c_bar in test_cases:\n        # Generate data\n        img32 = generate_image(H, W)\n        ker32 = gaussian_kernel(Kh, Kw, dtype=np.float32)\n        # Non-deterministic runs\n        nd_runs = []\n        for sd in seeds:\n            nd_out = conv2d_valid_nondet_f32(img32, ker32, sd)\n            nd_runs.append(nd_out)\n        # Deterministic pairwise float32\n        det32_first = conv2d_valid_det_pairwise_f32(img32, ker32)\n        # Deterministic Kahan float64\n        img64 = img32.astype(np.float64)\n        ker64 = gaussian_kernel(Kh, Kw, dtype=np.float64)\n        det64_kahan = conv2d_valid_det_kahan_f64(img64, ker64)\n        # Differences\n        # D_ND: max difference across all pairs of nd_runs\n        D_ND = 0.0\n        for i in range(len(nd_runs)):\n            for j in range(i + 1, len(nd_runs)):\n                D_ND = max(D_ND, max_abs_diff(nd_runs[i], nd_runs[j]))\n        # D_ND-DET: first non-deterministic vs deterministic pairwise\n        D_ND_DET = max_abs_diff(nd_runs[0], det32_first)\n        # D_DET-Kahan: deterministic pairwise float32 vs Kahan float64\n        # Convert det32 to float64 for difference\n        D_DET_KAHAN = max_abs_diff(det32_first.astype(np.float64), det64_kahan)\n        # Predicted slowdowns\n        S_tree, S_kahan = predicted_slowdowns(Kh, Kw, c_mul, c_add, c_bar)\n        # Reproducibility check for deterministic pairwise\n        det32_second = conv2d_valid_det_pairwise_f32(img32, ker32)\n        R_det = bool(np.array_equal(det32_first, det32_second))\n        # Output size\n        Ho = H - Kh + 1\n        Wo = W - Kw + 1\n        # Round floating outputs to 8 decimal places\n        res = [\n            round8(D_ND),\n            round8(D_ND_DET),\n            round8(D_DET_KAHAN),\n            round8(S_tree),\n            round8(S_kahan),\n            R_det,\n            int(Ho),\n            int(Wo),\n        ]\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    # Ensure single-line JSON-like list.\n    # Convert booleans and numbers to their string representations.\n    def fmt_elem(e):\n        if isinstance(e, float):\n            # Format with up to 8 decimal places, strip trailing zeros\n            s = f\"{e:.8f}\".rstrip(\"0\").rstrip(\".\")\n            if s == \"\":\n                s = \"0\"\n            return s\n        elif isinstance(e, bool):\n            return \"True\" if e else \"False\"\n        else:\n            return str(e)\n\n    inner_strs = []\n    for res in results:\n        inner = \",\".join(fmt_elem(e) for e in res)\n        inner_strs.append(f\"[{inner}]\")\n    print(f\"[{','.join(inner_strs)}]\")\n\nsolve()\n```"
        }
    ]
}