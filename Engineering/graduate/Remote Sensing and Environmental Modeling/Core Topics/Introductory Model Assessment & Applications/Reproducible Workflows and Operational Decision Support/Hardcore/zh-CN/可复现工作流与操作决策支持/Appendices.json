{
    "hands_on_practices": [
        {
            "introduction": "在高性能计算中，尤其是在使用 GPU 进行并行处理时，一个根本性的可复现性挑战源于浮点数运算的非结合律。这个练习将模拟在卫星图像上进行卷积运算时遇到的这一问题。通过比较非确定性的随机求和、确定性的成对求和以及高精度的 Kahan 补偿求和这三种策略，你将亲身体验如何强制实现逐位可复现性，并量化其在性能和精度上的权衡。",
            "id": "3841832",
            "problem": "您正在为一个用于业务决策支持流程中的卫星影像设计的确定性图形处理单元 (GPU) 卷积工作流。其目标是确保跨次运行的按位可复现性，同时量化强制实现确定性所带来的性能权衡。您必须基于以下基本事实和定义进行推理：\n\n- 在 valid 模式下，一个大小为 $H \\times W$ 的图像 $I$ 与一个大小为 $K_h \\times K_w$ 的卷积核 $K$ 的离散二维卷积，会产生一个大小为 $(H - K_h + 1) \\times (W - K_w + 1)$ 的输出 $O$，其定义为\n$$\nO[y,x] = \\sum_{i=0}^{K_h-1} \\sum_{j=0}^{K_w-1} I[y+i, x+j] \\cdot K[i,j].\n$$\n\n- 在电气与电子工程师协会 (IEEE) $754$ 算术中，浮点加法不满足结合律。对于实数 $a$、$b$ 和 $c$，当以有限精度计算时，通常有 $(a+b)+c \\neq a+(b+c)$。因此，在并行硬件上，求和的顺序以及部分和的调度会引起不同的舍入序列和结果。\n\n- 并行规约中的确定性是通过固定加法顺序和规约树形状来强制执行的。当输入顺序固定时，成对（平衡）求和会产生一个确定性的和，并且与纯粹从左到右的累加相比，它减少了舍入误差的增长。\n\n- Kahan 补偿求和算法会累加一个运行中的补偿项，以校正丢失的低位比特。对于一个包含 $K$ 个项、机器 ε 为 $\\varepsilon$ 的序列，朴素求和的误差增长量级为 $\\mathcal{O}(K \\varepsilon)$，而 Kahan 求和则会显著减小误差，在实践中对于良态求和，误差通常接近 $\\mathcal{O}(\\varepsilon)$。\n\n为了在没有实际 GPU 代码的情况下模拟 GPU 调度效应，请在合成图像上实现三种卷积模式：\n\n- 模式 A（非确定性浮点数）：对于每个输出像素，计算 $K = K_h \\cdot K_w$ 个乘积，但在每次运行和每个像素的求和中使用一个新的随机排列。使用 32 位浮点数进行累加。在多个独立的种子上重复此过程，以模拟不同的线程块调度和规约顺序。这捕捉了非确定性的舍入行为。\n\n- 模式 B（确定性成对浮点数）：对于每个输出像素，使用一个完全确定的成对规约树，在 32 位浮点数下，按照 $(i,j)$ 的固定字典序累加 $K$ 个乘积。\n\n- 模式 C（确定性 Kahan 浮点数）：对于每个输出像素，使用 64 位浮点数下的 Kahan 补偿求和，累加顺序固定的相同序列。\n\n用于卷积的合成数据：\n\n- 图像 $I$：对于整数坐标 $0 \\le y  H$，$0 \\le x  W$，定义\n$$\nI[y,x] = \\operatorname{float32}\\left(0.5 + 0.5 \\tanh\\left(0.25 \\sin(0.11 y + 0.07 x) + 0.75 \\cos(0.03 y^2 + 0.05 x)\\right)\\right).\n$$\n\n- 卷积核 $K$：一个二维高斯函数，标准差为 $\\sigma = \\max(K_h, K_w)/3$，在 $K_h \\times K_w$ 网格上采样，中心点位于 $\\left(\\frac{K_h-1}{2}, \\frac{K_w-1}{2}\\right)$，并归一化使其总和为 $1$。模式 A 和模式 B 使用 32 位浮点数，模式 C 使用 64 位浮点数。\n\n确定性性能模型：\n\n- 令 $K = K_h \\cdot K_w$。使用一个简单的加法模型来计算每个输出像素的成本，其中操作权重为 $c_{\\text{mul}}$、$c_{\\text{add}}$，同步屏障成本为 $c_{\\text{bar}}$。假设乘法和加法的成本分别为 $c_{\\text{mul}}$ 和 $c_{\\text{add}}$，且平衡树需要 $\\lceil \\log_2 K \\rceil$ 个同步阶段，每个阶段的屏障成本为 $c_{\\text{bar}}$。为计算成本，将减法视为加法。\n\n- 基线非确定性成本（朴素累加）：\n$$\nC_{\\text{base}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}}.\n$$\n\n- 确定性成对求和成本：\n$$\nC_{\\text{tree}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}}.\n$$\n\n- 确定性 Kahan 求和成本：\n$$\nC_{\\text{Kahan}} = K \\cdot c_{\\text{mul}} + 4K \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}},\n$$\n这反映了 Kahan 算法每个项使用 4 个类似加/减法的操作。\n\n对于每个测试用例，计算以下量：\n\n- $D_{\\text{ND}}$：在使用所提供种子的所有非确定性输出对之间的最大绝对差值。\n\n- $D_{\\text{ND-DET}}$：第一个非确定性输出（使用第一个种子）与确定性成对求和输出之间的最大绝对差值。\n\n- $D_{\\text{DET-Kahan}}$：确定性成对求和输出与确定性 Kahan 求和输出之间的最大绝对差值。\n\n- $S_{\\text{tree}} = C_{\\text{tree}} / C_{\\text{base}}$ 和 $S_{\\text{Kahan}} = C_{\\text{Kahan}} / C_{\\text{base}}$，相对于基线的预测性能下降比率。\n\n- $R_{\\text{det}}$：一个布尔值，指示运行两次确定性成对求和计算是否产生按位相同的数组。\n\n- $H_{\\text{out}}$ 和 $W_{\\text{out}}$：输出维度。\n\n舍入和输出要求：\n\n- 将所有浮点结果 $D_{\\text{ND}}$、$D_{\\text{ND-DET}}$、$D_{\\text{DET-Kahan}}$、$S_{\\text{tree}}$ 和 $S_{\\text{Kahan}}$ 四舍五入到 8 位小数。布尔值和整数输出不进行舍入。\n\n- 使用 valid 卷积（无填充，步长为 1）。三角函数中的角度以弧度为单位。\n\n测试套件：\n\n为以下参数集提供结果。在每种情况下，按所述顺序使用给定的种子列表运行模式 A。\n\n- 情况 1：$H = 64$，$W = 64$，$K_h = 5$，$K_w = 5$，种子 $[101, 202, 303]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 8.0$。\n\n- 情况 2：$H = 8$，$W = 8$，$K_h = 3$，$K_w = 3$，种子 $[7, 11, 13]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 4.0$。\n\n- 情况 3：$H = 63$，$W = 57$，$K_h = 7$，$K_w = 7$，种子 $[42, 99, 123]$，$c_{\\text{mul}} = 1.0$，$c_{\\text{add}} = 1.0$，$c_{\\text{bar}} = 16.0$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例贡献一个内部列表，其条目严格遵循以下顺序：\n$[D_{\\text{ND}}, D_{\\text{ND-DET}}, D_{\\text{DET-Kahan}}, S_{\\text{tree}}, S_{\\text{Kahan}}, R_{\\text{det}}, H_{\\text{out}}, W_{\\text{out}}]$。\n例如：\n\"[[d1,d2,d3,s1,s2,True,h,w],[...],[...]]\"。",
            "solution": "我们从核心定义和事实开始：离散卷积和电气与电子工程师协会 (IEEE) $754$ 中的浮点算术属性。一个 'valid' 模式的二维卷积将每个输出 $O[y,x]$ 计算为有限个乘积之和\n$$\nO[y,x] = \\sum_{i=0}^{K_h-1} \\sum_{j=0}^{K_w-1} I[y+i, x+j] \\cdot K[i,j],\n$$\n其中有 $K = K_h \\cdot K_w$ 个被加数。当 $I$ 和 $K$ 是浮点数时，每个被加数都可以表示为浮点数。\n\n非结合性：在有限精度下，浮点加法既不完全满足结合律，也不完全满足分配律。在 IEEE $754$ 的“向最近偶数舍入”模式下，对于表示为 32 位或 64 位浮点数的实数 $a$、$b$ 和 $c$，由于每次加法都会进行舍入，可能会出现 $(a+b)+c \\neq a+(b+c)$ 的情况。在图形处理单元 (GPU) 上的并行规约中，硬件或运行时可能会以每次运行都不同的顺序来调度部分和的计算与合并，特别是在使用原子操作或无约束的块调度时。这会导致非确定性的舍入序列，因此即使每次运行的输入完全相同，最终的位模式也可能不同。\n\n通过构造实现确定性：为确保按位可复现性，需要固定规约的输入顺序和规约树的形状，以便在每个层级，相同的数对都以相同的顺序相加。给定相同的输入，固定的成对求和方案会产生相同的结果。通过使用像 Kahan 算法这样的补偿求和，可以在数值上进一步提高可复现性。该算法通过跟踪一个补偿项 $c$ 来控制误差传播，该补偿项存储因舍入而丢失的低位比特。\n\n算法设计：\n\n- 数据生成。合成图像由以下公式确定性地定义\n$$\nI[y,x] = \\operatorname{float32}\\left(0.5 + 0.5 \\tanh\\left(0.25 \\sin(0.11 y + 0.07 x) + 0.75 \\cos(0.03 y^2 + 0.05 x)\\right)\\right),\n$$\n对于整数 $y$ 和 $x$，确保值在 $(0,1)$ 范围内。卷积核是一个归一化的高斯函数：\n$$\nG[i,j] = \\exp\\left(-\\frac{(i-c_y)^2 + (j-c_x)^2}{2\\sigma^2}\\right), \\quad \\sigma = \\frac{\\max(K_h,K_w)}{3}, \\quad (c_y,c_x) = \\left(\\frac{K_h-1}{2}, \\frac{K_w-1}{2}\\right),\n$$\n然后以适当的精度计算 $K = G / \\sum_{i,j} G[i,j]$。\n\n- 模式 A（非确定性浮点数）。对于每个输出坐标 $(y,x)$，按字典索引顺序 $(i,j)$ 构建长度为 $K$ 的项列表：\n$$\nt_{i,j} = I[y+i,x+j] \\cdot K[i,j].\n$$\n然后，在每次运行和每个 $(y,x)$ 坐标处，用一个新的随机排列打乱此列表。使用 32 位浮点数以简单的左折叠方式进行累加。在指定的种子上重复此过程，以模拟不同的块调度和规约顺序。不同的排列会改变舍入操作的序列，可能导致每个输出元素的最终结果发生变化。\n\n- 模式 B（确定性成对浮点数）。使用相同的字典序项顺序，但通过一个固定的成对（平衡）树进行求和。在每个层级，按从左到右的顺序将相邻的对相加，当长度为奇数时，将最后一个单独的项带到下一级，直到只剩一个值。所有算术运算均使用 32 位浮点数。由于顺序和树结构都是固定的，因此每次运行都会产生相同的结果。\n\n- 模式 C（确定性 Kahan 浮点数）。使用相同的字典序，但使用 64 位浮点数通过 Kahan 补偿求和进行累加。Kahan 算法维护一个运行总和 $s$ 和一个补偿项 $c$，每个项 $\\tau$ 都按如下方式更新\n$$\ny = \\tau - c,\\quad t = s + y,\\quad c = (t - s) - y,\\quad s = t,\n$$\n这有效地重新注入了丢失的低位比特。结果是确定性的，并且通常更接近精确算术。\n\n性能模型推导：\n\n令 $K = K_h \\cdot K_w$。我们计算每个输出像素的操作数：\n\n- 乘法：始终为 $K$ 次。\n\n- 加法。基线（模式 A）在左折叠中使用 $K-1$ 次加法。成对求和（模式 B）也使用 $K-1$ 次加法，但额外需要 $\\lceil \\log_2 K \\rceil$ 个同步阶段来并行执行平衡树规约。Kahan（模式 C）每个项使用 4 个类似加/减法的操作（一个加法和三个减法），近似为 $4K$ 个加法类操作，当映射到每个通道的序贯补偿并行树时，也需要相同的同步阶段。\n\n使用操作权重 $c_{\\text{mul}}$、$c_{\\text{add}}$ 和 $c_{\\text{bar}}$，我们得到\n$$\nC_{\\text{base}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}},\n$$\n$$\nC_{\\text{tree}} = K \\cdot c_{\\text{mul}} + (K - 1) \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}},\n$$\n$$\nC_{\\text{Kahan}} = K \\cdot c_{\\text{mul}} + 4K \\cdot c_{\\text{add}} + \\lceil \\log_2 K \\rceil \\cdot c_{\\text{bar}}.\n$$\n相对于基线的性能下降比率为\n$$\nS_{\\text{tree}} = \\frac{C_{\\text{tree}}}{C_{\\text{base}}}, \\quad S_{\\text{Kahan}} = \\frac{C_{\\text{Kahan}}}{C_{\\text{base}}}.\n$$\n\n计算输出：\n\n对于每个测试用例，我们计算：\n\n- $D_{\\text{ND}} = \\max\\limits_{r \\neq s} \\|O^{(r)} - O^{(s)}\\|_{\\infty}$，在指定种子下，对模式 A 的运行 $r$ 和 $s$ 进行计算，其中 $\\|\\cdot\\|_{\\infty}$ 是逐元素的最大绝对差值。\n\n- $D_{\\text{ND-DET}} = \\|O^{(r_0)} - O^{\\text{det}}\\|_{\\infty}$，即第一次非确定性运行（种子顺序中的第一个元素）与确定性成对求和输出之间的差值。\n\n- $D_{\\text{DET-Kahan}} = \\|O^{\\text{det}} - O^{\\text{Kahan}}\\|_{\\infty}$，即 32 位确定性成对求和输出与 64 位确定性 Kahan 求和输出之间的差值。\n\n- $S_{\\text{tree}}$ 和 $S_{\\text{Kahan}}$ 根据上述公式计算。\n\n- 通过运行模式 B 两次并通过数组级比较检查精确的按位相等性来计算 $R_{\\text{det}}$。因为模式 B 固定了顺序和规约形状，并使用相同的精度，所以各次运行的输出是相同的，因此 $R_{\\text{det}}$ 的值为 True。\n\n- $H_{\\text{out}} = H - K_h + 1$ 且 $W_{\\text{out}} = W - K_w + 1$。\n\n实现说明：\n\n- 为了正确模拟累加中的 32 位舍入行为，确保累加器变量是 32 位浮点数，以便每次加法都舍入到 32 位精度。\n\n- 模式 A 的随机排列应为每个输出元素和每次运行生成，以模拟不同的调度和规约顺序。\n\n- 按要求将浮点输出四舍五入到 8 位小数。\n\n边界情况：\n\n- 小卷积核（例如 $K_h = 3, K_w = 3$）产生 $K = 9$，其中由于非结合性引起的差异可能很小，但在 32 位算术中通常仍不为零。\n\n- 奇数维度和更大的卷积核（例如 $K_h = 7, K_w = 7$）会为每个输出产生更多的被加数，因此通常会放大非确定性差异和 Kahan 求和的精度优势。\n\n程序实现了所有三种模式，使用指定的种子和权重运行三个测试用例，为每个用例计算八个所需的输出，将浮点结果四舍五入到 8 位小数，并以规定的确切顺序，将每个用例的结果列表组成的列表打印成单行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_image(H, W):\n    # Deterministic synthetic image in float32, values in (0,1)\n    y = np.arange(H, dtype=np.float64).reshape(H, 1)\n    x = np.arange(W, dtype=np.float64).reshape(1, W)\n    expr = 0.25 * np.sin(0.11 * y + 0.07 * x) + 0.75 * np.cos(0.03 * (y ** 2) + 0.05 * x)\n    img = 0.5 + 0.5 * np.tanh(expr)\n    return img.astype(np.float32)\n\ndef gaussian_kernel(Kh, Kw, dtype=np.float32):\n    cy = (Kh - 1) / 2.0\n    cx = (Kw - 1) / 2.0\n    sigma = max(Kh, Kw) / 3.0\n    y = np.arange(Kh, dtype=np.float64).reshape(Kh, 1)\n    x = np.arange(Kw, dtype=np.float64).reshape(1, Kw)\n    gy = (y - cy) ** 2\n    gx = (x - cx) ** 2\n    G = np.exp(-(gy + gx) / (2.0 * sigma * sigma))\n    G = G / np.sum(G)\n    return G.astype(dtype)\n\ndef terms_lexicographic(image, kernel, y, x):\n    Kh, Kw = kernel.shape\n    # Produce list of terms in lexicographic (i,j) order\n    terms = []\n    for i in range(Kh):\n        for j in range(Kw):\n            terms.append(image[y + i, x + j] * kernel[i, j])\n    return terms\n\ndef sum_nondet_f32(terms, rng):\n    # Shuffle order and accumulate in float32 left fold\n    idx = rng.permutation(len(terms))\n    s = np.float32(0.0)\n    for k in idx:\n        s = np.float32(s + np.float32(terms[k]))\n    return s\n\ndef sum_pairwise_f32(terms):\n    # Deterministic pairwise reduction in float32\n    # Copy to a float32 list\n    arr = [np.float32(t) for t in terms]\n    n = len(arr)\n    if n == 0:\n        return np.float32(0.0)\n    while len(arr) > 1:\n        new_arr = []\n        m = len(arr)\n        i = 0\n        while i + 1  m:\n            new_arr.append(np.float32(arr[i] + arr[i + 1]))\n            i += 2\n        if i  m:\n            # carry last\n            new_arr.append(arr[i])\n        arr = new_arr\n    return np.float32(arr[0])\n\ndef sum_kahan_f64(terms):\n    # Kahan compensated summation in float64\n    s = np.float64(0.0)\n    c = np.float64(0.0)\n    for t in terms:\n        tau = np.float64(t)\n        y = tau - c\n        tsum = s + y\n        c = (tsum - s) - y\n        s = tsum\n    return s\n\ndef conv2d_valid_nondet_f32(image, kernel, seed):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float32)\n    rng = np.random.default_rng(seed)\n    # Compute per output pixel\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_nondet_f32(terms, rng)\n    return out\n\ndef conv2d_valid_det_pairwise_f32(image, kernel):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float32)\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_pairwise_f32(terms)\n    return out\n\ndef conv2d_valid_det_kahan_f64(image, kernel):\n    H, W = image.shape\n    Kh, Kw = kernel.shape\n    Ho = H - Kh + 1\n    Wo = W - Kw + 1\n    out = np.empty((Ho, Wo), dtype=np.float64)\n    for y in range(Ho):\n        for x in range(Wo):\n            terms = terms_lexicographic(image, kernel, y, x)\n            out[y, x] = sum_kahan_f64(terms)\n    return out\n\ndef max_abs_diff(a, b):\n    return float(np.max(np.abs(a.astype(np.float64) - b.astype(np.float64))))\n\ndef predicted_slowdowns(Kh, Kw, c_mul, c_add, c_bar):\n    K = Kh * Kw\n    C_base = K * c_mul + (K - 1) * c_add\n    C_tree = K * c_mul + (K - 1) * c_add + (int(np.ceil(np.log2(K))) * c_bar)\n    C_kahan = K * c_mul + (4 * K) * c_add + (int(np.ceil(np.log2(K))) * c_bar)\n    return C_tree / C_base, C_kahan / C_base\n\ndef round8(x):\n    return float(np.round(x, 8))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (H, W, Kh, Kw, seeds_list, c_mul, c_add, c_bar)\n    test_cases = [\n        (64, 64, 5, 5, [101, 202, 303], 1.0, 1.0, 8.0),\n        (8, 8, 3, 3, [7, 11, 13], 1.0, 1.0, 4.0),\n        (63, 57, 7, 7, [42, 99, 123], 1.0, 1.0, 16.0),\n    ]\n\n    results = []\n    for H, W, Kh, Kw, seeds, c_mul, c_add, c_bar in test_cases:\n        # Generate data\n        img32 = generate_image(H, W)\n        ker32 = gaussian_kernel(Kh, Kw, dtype=np.float32)\n        # Non-deterministic runs\n        nd_runs = []\n        for sd in seeds:\n            nd_out = conv2d_valid_nondet_f32(img32, ker32, sd)\n            nd_runs.append(nd_out)\n        # Deterministic pairwise float32\n        det32_first = conv2d_valid_det_pairwise_f32(img32, ker32)\n        # Deterministic Kahan float64\n        img64 = img32.astype(np.float64)\n        ker64 = gaussian_kernel(Kh, Kw, dtype=np.float64)\n        det64_kahan = conv2d_valid_det_kahan_f64(img64, ker64)\n        # Differences\n        # D_ND: max difference across all pairs of nd_runs\n        D_ND = 0.0\n        for i in range(len(nd_runs)):\n            for j in range(i + 1, len(nd_runs)):\n                D_ND = max(D_ND, max_abs_diff(nd_runs[i], nd_runs[j]))\n        # D_ND-DET: first non-deterministic vs deterministic pairwise\n        D_ND_DET = max_abs_diff(nd_runs[0], det32_first)\n        # D_DET-Kahan: deterministic pairwise float32 vs Kahan float64\n        # Convert det32 to float64 for difference\n        D_DET_KAHAN = max_abs_diff(det32_first.astype(np.float64), det64_kahan)\n        # Predicted slowdowns\n        S_tree, S_kahan = predicted_slowdowns(Kh, Kw, c_mul, c_add, c_bar)\n        # Reproducibility check for deterministic pairwise\n        det32_second = conv2d_valid_det_pairwise_f32(img32, ker32)\n        R_det = bool(np.array_equal(det32_first, det32_second))\n        # Output size\n        Ho = H - Kh + 1\n        Wo = W - Kw + 1\n        # Round floating outputs to 8 decimal places\n        res = [\n            round8(D_ND),\n            round8(D_ND_DET),\n            round8(D_DET_KAHAN),\n            round8(S_tree),\n            round8(S_kahan),\n            R_det,\n            int(Ho),\n            int(Wo),\n        ]\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    # Ensure single-line JSON-like list.\n    # Convert booleans and numbers to their string representations.\n    def fmt_elem(e):\n        if isinstance(e, float):\n            # Format with up to 8 decimal places, strip trailing zeros\n            s = f\"{e:.8f}\".rstrip(\"0\").rstrip(\".\")\n            if s == \"\":\n                s = \"0\"\n            return s\n        elif isinstance(e, bool):\n            return \"True\" if e else \"False\"\n        else:\n            return str(e)\n\n    inner_strs = []\n    for res in results:\n        inner = \",\".join(fmt_elem(e) for e in res)\n        inner_strs.append(f\"[{inner}]\")\n    print(f\"[{','.join(inner_strs)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在解决了数值精度问题之后，可复现工作流中的另一个常见障碍是管理随机过程。当蒙特卡洛等随机模拟任务被分发到多个并行工作器上时，如果对随机数生成器（RNG）的使用不加设计，结果将依赖于工作器的数量和调度，从而变得不可复现。本练习将指导你实现一种基于计数器的 RNG 策略，它能确保无论计算任务如何分配，最终的随机模拟结果都是逐位一致的，从而验证了在分布式系统中实现随机性可复现的核心原则。",
            "id": "3841901",
            "problem": "您将执行一项针对气溶胶光学厚度 (AOD) 的遥感不确定性传播任务，AOD 是一个无量纲量。在此任务中，使用蒙特卡洛采样来估计模型和测量不确定性下 AOD 的期望值和变异性，同时确保在分布式计算下结果的可复现性。您的目标是设计一个程序，通过精心管理随机种子和流分区，来展示并验证在不同工作节点分区方案下的可复现性。\n\n基本原理：蒙特卡洛积分通过对独立随机变量进行采样来估计不确定性下函数的期望。具体来说，令 $A$ 表示气溶胶光学厚度，反演模型为 $A = c \\left(\\bar{A} + \\epsilon \\right)$，其中 $\\bar{A}$ 是基线估计值，$\\epsilon$ 是代表传感器和模型噪声的加性误差项，而 $c$ 是一个乘性校准因子。假设 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $c = \\exp\\left(\\mu_c + \\sigma_c Z\\right)$，其中 $Z \\sim \\mathcal{N}(0, 1)$。这里 $\\mathcal{N}(0, \\sigma^2)$ 表示均值为 $0$、方差为 $\\sigma^2$ 的正态分布，$\\exp(\\cdot)$ 表示指数函数。使用 $N$ 个样本，$A$ 的期望的蒙特卡洛估计量为 $\\hat{\\mathbb{E}}[A] = \\frac{1}{N}\\sum_{i=1}^{N} A_i$，其中每个 $A_i$ 都是由独立抽取的 $\\epsilon$ 和 $c$ 构建的。\n\n可复现的工作流要求随机变量的生成方式不依赖于工作节点的数量或其调度。形式上，令 $s$ 为一个基础种子，令样本索引 $i$ 的随机变量生成过程是一个关于 $(s, i)$ 和抽取索引 $d$ 的确定性函数，其中 $d$ 唯一标识生成的随机变量（例如，为 $\\epsilon$ 和 $c$ 各进行一次抽取）。这种方法被称为基于计数器的随机变量生成，它产生一个从 $(s, i, d)$ 到 $(0,1)$ 区间内伪随机值的固定映射，然后可以将其转换为所需的分布。跨工作节点的流分区必须设计为每个工作节点计算 $i$ 的不相交子集，同时保留从 $(s, i, d)$ 到随机变量的映射。在这种设计下，聚合结果对于工作节点的数量及其分配是不变的，从而实现可复现性。\n\n您的程序必须：\n- 实现一个蒙特卡洛模拟器，对 $i = 0, 1, \\ldots, N-1$ 计算 $A_i = c_i \\left(\\bar{A} + \\epsilon_i\\right)$。此过程使用一个从 $(s, i, d)$ 到 $(0,1)$ 区间内独立均匀分布随机数的确定性、基于计数器的伪随机映射，并将这些数转换为 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ 和 $c_i = \\exp\\left(\\mu_c + \\sigma_c Z_i\\right)$（其中 $Z_i \\sim \\mathcal{N}(0, 1)$）。使用从均匀分布到正态分布变量的数值稳定变换。\n- 实现两种执行模式：\n  1. 中心化单流：对 $i = 0, 1, \\ldots, N-1$ 顺序计算所有 $A_i$。\n  2. 分布式多工作节点：使用指定的分区方案，将索引集 $\\{0,\\ldots,N-1\\}$ 分配给 $W$ 个工作节点，在每个工作节点中计算 $A_i$，然后将结果聚合到一个按 $i$ 排序的数组中。\n- 通过逐元素比较中心化和分布式数组是否相等来验证可复现性，为每个测试用例生成一个布尔值。当且仅当中心化和分布式数组（按 $i$ 排序）完全相同时，该测试用例的布尔结果为真。\n\n物理单位：气溶胶光学厚度是无量纲的。仅返回无量纲量。如果在变换中出现任何角度，必须以弧度为单位。\n\n测试套件和参数：\n对于每个测试用例，参数以 $(N, \\bar{A}, \\sigma, \\mu_c, \\sigma_c, s, W, \\text{partitioning})$ 的形式提供，其中 $N$ 是蒙特卡洛样本数量，$\\bar{A}$ 是基线 AOD，$\\sigma$ 是噪声标准差，$\\mu_c$ 和 $\\sigma_c$ 是校准因子的对数正态参数，$s$ 是基础种子（一个整数），$W$ 是工作节点数量，$\\text{partitioning}$ 描述了工作节点分配方案。\n\n使用以下测试用例：\n- 测试用例 1：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 4, \\text{partitioning} = \\text{contiguous blocks})$。每个工作节点 $w$ 接收一个大小近似相等的连续索引块。\n- 测试用例 2：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 1, \\text{partitioning} = \\text{single worker})$。所有索引分配给一个工作节点。\n- 测试用例 3：$(N = 10{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 7, \\text{partitioning} = \\text{round-robin})$。工作节点 $w$ 接收满足 $i \\bmod W = w$ 的索引 $i$。\n- 测试用例 4：$(N = 1, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 987654321, W = 3, \\text{partitioning} = \\text{contiguous blocks})$。$N$ 取最小值的边界情况。\n- 测试用例 5：$(N = 5{,}000, \\bar{A} = 0.5, \\sigma = 0.05, \\mu_c = 0, \\sigma_c = 0.1, s = 123456789, W = 8, \\text{partitioning} = \\text{round-robin})$。不同的种子和工作节点数量。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[r_1, r_2, r_3, r_4, r_5]$，其中每个 $r_k$ 是一个布尔值，表示测试用例 $k$ 的中心化数组和分布式数组是否完全相同。",
            "solution": "我们从支配蒙特卡洛方法和可复现计算的基本原理出发。随机变量期望的蒙特卡洛估计量由独立随机样本构建。给定 AOD 模型 $A = c \\left(\\bar{A} + \\epsilon \\right)$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $c = \\exp\\left(\\mu_c + \\sigma_c Z\\right)$，$Z \\sim \\mathcal{N}(0, 1)$，我们模拟 $N$ 个独立样本来近似 $\\mathbb{E}[A]$ 及其他统计量。\n\n为确保在分布式工作节点间的可复现性，我们要求随机变量的生成是一个关于基础种子和唯一标识每次随机抽取的索引的确定性函数。这可以通过基于计数器的设计来实现：定义一个函数 $U: \\mathbb{Z} \\times \\mathbb{Z} \\times \\mathbb{Z} \\rightarrow (0,1)$，$U(s, i, d)$，它接收一个基础种子 $s$、一个样本索引 $i$ 和一个抽取索引 $d$（例如，在 Box–Muller 变换中使用的两个均匀分布变量对应 $d=0$ 和 $d=1$），并通过一个确定性映射（例如对 $(s, i, d)$ 进行加密哈希）返回一个在 $(0,1)$ 区间内的伪随机均匀分布值。对于固定的 $s$，此映射相对于 $(i, d)$ 是单射的，并且产生不依赖于工作节点数量或调度的固定输出。然后，从均匀分布到所需分布的转换便以确定性的方式进行。\n\n具体而言，为了从均匀分布变量获得标准正态变量，我们使用 Box–Muller 变换，该变换源于基础概率论：给定两个独立的 $U_1, U_2 \\sim \\text{Uniform}(0,1)$，定义\n$$\nZ = \\sqrt{-2 \\ln U_1} \\cos(2 \\pi U_2),\n$$\n这会得到 $Z \\sim \\mathcal{N}(0,1)$。为避免 $U_1 = 0$ 或 $U_1 = 1$ 时的边界问题，我们将哈希输出映射到严格在 $(0,1)$ 区间内的值，例如通过将整数表示加上一个小的偏移量再缩放到 $(0,1)$ 区间。使用两对 $(U_1, U_2)$ 和 $(U_3, U_4)$ 可以得到两个独立的标准正态变量，我们将它们转换为 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$（即 $\\epsilon = \\sigma Z_{\\epsilon}$）和对数正态校准 $c = \\exp\\left(\\mu_c + \\sigma_c Z_c\\right)$。\n\n可复现性证明梗概：在中心化模式下，对于每个索引 $i \\in \\{0, \\ldots, N-1\\}$，模拟器使用对应所需随机变量的固定 $d$ 值的抽取 $U(s, i, d)$ 来计算 $A_i$。在分布式模式下，同一组索引被划分给 $W$ 个工作节点（无论是通过连续块还是轮询方式），但每个工作节点仍然使用相同的确定性函数 $U(s, i, d)$ 来计算 $A_i$，并将结果放置在全局位置 $i$ 上。由于 $U$ 仅依赖于 $(s, i, d)$ 而不依赖于工作节点标识符或调度，因此分布式模式生成的序列 $\\{A_i\\}$ 在按 $i$ 聚合后与中心化模式生成的序列完全相同。因此，无论 $W$ 或分区方案如何，逐元素相等都成立，这证明了随机种子管理和流分区如何确保可复现性。\n\n算法步骤：\n1. 定义一个确定性函数，通过哈希将 $(s, i, d)$ 映射到一个 64 位整数，然后再映射到具有严格边界的 $(0,1)$ 区间内的均匀分布值，以避免 $0$ 和 $1$。\n2. 使用两个独立的均匀分布变量实现 Box–Muller 变换，为 $\\epsilon$ 生成一个标准正态变量 $Z_{\\epsilon}$，为校准因子 $c$ 生成另一个独立的标准正态变量 $Z_c$。\n3. 在中心化模式下为所有 $i$ 计算 $A_i = c_i \\left(\\bar{A} + \\epsilon_i \\right)$，以生成一个按 $i$ 排序的数组。\n4. 对于分布式模式，使用指定方案对索引进行分区，为每个分配的 $i$ 使用相同的映射 $U(s, i, d)$ 计算 $A_i$，并将结果聚合到一个按 $i$ 排序的数组中。\n5. 逐元素比较这两个数组是否相等，为每个测试用例生成一个布尔值。\n\n边界情况和数值考虑：\n- 当 $N=1$ 时，该方法仍然有效，因为映射对任何索引集都有良好定义。\n- 均匀分布映射必须避免精确的 $0$ 或 $1$，以确保 Box–Muller 变换中的对数和三角函数有良好定义；通过一个小的偏移量映射到 $(0,1)$ 区间可确保数值稳定性。\n- 因为在两种模式下，对于每个 $i$，$A_i$ 的计算方式完全相同，所以相等是精确的，而不仅仅是在容差范围内。\n\n最终程序实现了上述设计，执行测试套件，并打印一个用方括号括起来的、逗号分隔的布尔值列表，以表明每个测试用例的可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport hashlib\nfrom typing import List, Tuple, Dict\n\n# Deterministic mapping from (seed, sample_id, draw_index) to a uniform in (0,1).\ndef _hash_to_uint64(seed: int, sample_id: int, draw_index: int) - int:\n    # Use SHA-256 for a deterministic hash, and extract 64 bits.\n    # Encode the tuple as ASCII to ensure reproducibility across platforms.\n    msg = f\"{seed}:{sample_id}:{draw_index}\".encode(\"utf-8\")\n    digest = hashlib.sha256(msg).digest()\n    # Take the first 8 bytes as a big-endian unsigned integer.\n    return int.from_bytes(digest[:8], byteorder=\"big\", signed=False)\n\ndef _uniform01(seed: int, sample_id: int, draw_index: int) - float:\n    # Map uint64 in [0, 2**64 - 1] to a float strictly in (0, 1).\n    u64 = _hash_to_uint64(seed, sample_id, draw_index)\n    # Add 1 and divide by (2**64 + 2) to avoid exact 0 and 1.\n    return (u64 + 1) / (2**64 + 2)\n\ndef _standard_normal_box_muller(u1: float, u2: float) - float:\n    # Box-Muller transform: Z = sqrt(-2 ln u1) * cos(2 pi u2)\n    r = np.sqrt(-2.0 * np.log(u1))\n    theta = 2.0 * np.pi * u2\n    return r * np.cos(theta)\n\ndef _sample_AOD_for_index(\n    i: int,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) - float:\n    # Generate two independent standard normals:\n    # For epsilon: use draw indices 0 and 1\n    u1_eps = _uniform01(seed, i, 0)\n    u2_eps = _uniform01(seed, i, 1)\n    z_eps = _standard_normal_box_muller(u1_eps, u2_eps)\n    epsilon = sigma * z_eps\n\n    # For calibration factor c: use draw indices 2 and 3\n    u1_c = _uniform01(seed, i, 2)\n    u2_c = _uniform01(seed, i, 3)\n    z_c = _standard_normal_box_muller(u1_c, u2_c)\n    c = np.exp(mu_c + sigma_c * z_c)\n\n    # AOD sample\n    return c * (A_bar + epsilon)\n\ndef centralized_simulation(\n    N: int,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) - np.ndarray:\n    # Compute A_i for i in [0, N)\n    out = np.empty(N, dtype=np.float64)\n    for i in range(N):\n        out[i] = _sample_AOD_for_index(i, seed, A_bar, sigma, mu_c, sigma_c)\n    return out\n\ndef partition_indices(N: int, W: int, scheme: str) - List[List[int]]:\n    # Returns a list of lists; each inner list contains indices assigned to one worker.\n    if W == 0:\n        raise ValueError(\"Number of workers must be positive.\")\n    partitions: List[List[int]] = [[] for _ in range(W)]\n    if scheme == \"contiguous\":\n        # Split into contiguous blocks as evenly as possible.\n        # Compute sizes using floor division and remainder distribution.\n        base = N // W\n        rem = N % W\n        start = 0\n        for w in range(W):\n            size = base + (1 if w  rem else 0)\n            end = start + size\n            partitions[w] = list(range(start, end))\n            start = end\n    elif scheme == \"roundrobin\":\n        for i in range(N):\n            partitions[i % W].append(i)\n    else:\n        raise ValueError(f\"Unknown partitioning scheme: {scheme}\")\n    return partitions\n\ndef distributed_simulation(\n    N: int,\n    W: int,\n    scheme: str,\n    seed: int,\n    A_bar: float,\n    sigma: float,\n    mu_c: float,\n    sigma_c: float\n) - np.ndarray:\n    # Partition indices according to scheme, compute on each worker, and aggregate.\n    partitions = partition_indices(N, W, scheme)\n    out = np.empty(N, dtype=np.float64)\n    for worker_indices in partitions:\n        for i in worker_indices:\n            out[i] = _sample_AOD_for_index(i, seed, A_bar, sigma, mu_c, sigma_c)\n    return out\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (N, A_bar, sigma, mu_c, sigma_c, seed, W, partitioning)\n    test_cases: List[Tuple[int, float, float, float, float, int, int, str]] = [\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 4, \"contiguous\"),\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 1, \"contiguous\"),\n        (10000, 0.5, 0.05, 0.0, 0.1, 987654321, 7, \"roundrobin\"),\n        (1,     0.5, 0.05, 0.0, 0.1, 987654321, 3, \"contiguous\"),\n        (5000,  0.5, 0.05, 0.0, 0.1, 123456789, 8, \"roundrobin\"),\n    ]\n\n    results: List[bool] = []\n    for case in test_cases:\n        N, A_bar, sigma, mu_c, sigma_c, seed, W, scheme_name = case\n        # Map scheme_name to internal\n        scheme = \"contiguous\" if scheme_name == \"contiguous blocks\" else scheme_name\n        # Centralized\n        central = centralized_simulation(N, seed, A_bar, sigma, mu_c, sigma_c)\n        # Distributed\n        distributed = distributed_simulation(N, W, scheme, seed, A_bar, sigma, mu_c, sigma_c)\n        # Reproducibility check: exact element-wise equality\n        results.append(np.array_equal(central, distributed))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Adjust names in test cases to match internal scheme keys\n# The problem statement used natural language names; map them here.\ndef _normalize_partition_name(name: str) - str:\n    if name == \"contiguous blocks\" or name == \"contiguous\":\n        return \"contiguous\"\n    elif name == \"round-robin\" or name == \"roundrobin\":\n        return \"roundrobin\"\n    else:\n        return name\n\n# Override solve to normalize names before using\ndef solve():\n    test_cases_raw: List[Dict] = [\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 4, \"partitioning\": \"contiguous blocks\"},\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 1, \"partitioning\": \"single worker\"},\n        {\"N\": 10000, \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 7, \"partitioning\": \"round-robin\"},\n        {\"N\": 1,     \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 987654321, \"W\": 3, \"partitioning\": \"contiguous blocks\"},\n        {\"N\": 5000,  \"A_bar\": 0.5, \"sigma\": 0.05, \"mu_c\": 0.0, \"sigma_c\": 0.1, \"seed\": 123456789, \"W\": 8, \"partitioning\": \"round-robin\"},\n    ]\n\n    # Normalize partitioning descriptors\n    for tc in test_cases_raw:\n        part = tc[\"partitioning\"]\n        if part == \"single worker\":\n            tc[\"partitioning\"] = \"contiguous\"\n        elif part == \"round-robin\":\n            tc[\"partitioning\"] = \"roundrobin\"\n        elif part == \"contiguous blocks\":\n            tc[\"partitioning\"] = \"contiguous\"\n\n    results: List[bool] = []\n    for tc in test_cases_raw:\n        central = centralized_simulation(tc[\"N\"], tc[\"seed\"], tc[\"A_bar\"], tc[\"sigma\"], tc[\"mu_c\"], tc[\"sigma_c\"])\n        distributed = distributed_simulation(tc[\"N\"], tc[\"W\"], tc[\"partitioning\"], tc[\"seed\"], tc[\"A_bar\"], tc[\"sigma\"], tc[\"mu_c\"], tc[\"sigma_c\"])\n        results.append(np.array_equal(central, distributed))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "将可复现性的概念扩展到复杂的、长期运行的系统层面，我们面临着状态管理和中断恢复的挑战。环境模型通常需要运行很长时间，使其容易受到硬件故障或系统中断的影响。本练习要求你为一个简化的气候模型设计并实现一个检查点-恢复工作流，通过精确地保存和恢复模型的完整状态——包括物理变量、随机数生成器内部状态和外部环境配置——来保证模拟在中断后能精确恢复，并产生与不间断运行完全相同的结果。",
            "id": "3841878",
            "problem": "您的任务是为遥感和环境建模中用于业务决策支持的长期运行气候模型设计并实现一个可复现的检查点设置和恢复工作流。该工作流必须保证精确恢复，包括相同的随机行为和依赖于环境的强迫，当从任何有效检查点恢复时，都能产生按位相同的输出。您还必须实现一个严格的等效性验证程序。您的程序的最终输出必须是单行文本，按照指定格式汇总预定义测试套件的结果。\n\n从以下基本基础开始：\n\n- 一个离散时间、有限维、随机动力系统根据一个规则演化，该规则是其当前状态和强迫的函数。对于整数时间 $t$ 的系统状态 $S_t \\in \\mathbb{R}^{m \\times n}$，存在一个确定性更新函数 $F$ 和一个随机创新过程 $\\varepsilon_t$，使得\n$$\nS_{t+1} = F(S_t, t, \\Theta, E) + \\varepsilon_t,\n$$\n其中 $\\Theta$ 表示模型参数， $E$ 表示环境配置。\n\n- 随机数生成器（RNG）是一个确定性状态机。给定 RNG 的内部状态 $R_t$，下一个输出 $\\xi_t$ 和下一个状态 $R_{t+1}$ 满足\n$$\n(\\xi_t, R_{t+1}) = \\Psi(R_t),\n$$\n对于一个确定性转换 $\\Psi$。因此，如果在任何检查点时间 $t$ 精确地恢复了 RNG 状态 $R_t$，并且此后向 RNG 发出相同的请求序列，则随机实现 $\\{\\varepsilon_{t}, \\varepsilon_{t+1}, \\dots\\}$ 将被精确地复现。\n\n- 在具有周期性边界条件的二维网格上的离散拉普拉斯算子定义为\n$$\n(\\Delta S)_{i,j} = -4 S_{i,j} + S_{i-1,j} + S_{i+1,j} + S_{i,j-1} + S_{i,j+1},\n$$\n其中索引根据网格维度取模。\n\n您的气候模型规定如下：\n\n- 设模型网格大小为 $m \\times n$，状态 $S_t$ 表示以开尔文（K）为单位的地表气温。模型根据以下公式演化\n$$\nS_{t+1} = S_t + \\Delta t \\left( \\kappa \\, \\Delta S_t + \\alpha \\, \\mathcal{F}(t, E) \\right) + \\beta \\, \\eta_t,\n$$\n其中 $\\Delta t$ 是时间步长， $\\kappa$ 是扩散系数， $\\alpha$ 是确定性强迫系数， $\\beta$ 缩放随机创新，而 $\\eta_t$ 是一个零均值高斯随机场。确定性强迫 $\\mathcal{F}(t, E)$ 定义为\n$$\n\\mathcal{F}(t, E) = A(E) \\sin\\left( \\frac{2\\pi t}{T_{\\text{season}}} \\right) P,\n$$\n其中 $A(E)$ 是一个依赖于环境的振幅， $T_{\\text{season}}$ 是以步长为单位的季节周期，而 $P$ 是一个所有条目都等于 $1$ 的固定空间模式。\n\n- 环境 $E$ 包含一个场景键，有两个有效值：$E.\\text{SCENARIO} \\in \\{\\text{\"A\"}, \\text{\"B\"}\\}$。振幅映射为 $A(\\text{\"A\"}) = 0.5$ 和 $A(\\text{\"B\"}) = 0.8$（单位均为开尔文/步）。季节周期为 $T_{\\text{season}} = 24$ 步。\n\n- 随机创新 $\\eta_t$ 在每个步骤和网格单元上独立抽取，服从 $\\eta_t \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma = 1$（单位为开尔文）。所有加法和乘法都以双精度进行。\n\n在时间 $t = k$ 的检查点必须包含：\n\n- 精确的模型状态 $S_k$。\n- 精确的 RNG 内部状态 $R_k$。\n- 环境快照 $E_k$。\n- 时间索引 $k$。\n- 整个运行过程中使用的不可变模型参数 $\\Theta$。\n\n从检查点恢复时，必须设置 $(S_k, R_k, E_k)$ 并继续时间循环 $t = k, k+1, \\dots, N-1$，生成一个最终状态 $S_N$，该状态与使用相同的初始条件、RNG 种子、参数和环境不间断运行模型 $N$ 步所获得的状态按位相同。\n\n等效性验证必须包括：\n\n- 最终状态 $S_N^{\\text{full}}$ 和 $S_N^{\\text{resumed}}$ 的按位相等性检查，\n$$\n\\text{equal} = \\left( S_N^{\\text{full}} \\equiv S_N^{\\text{resumed}} \\right),\n$$\n其中 $\\equiv$ 表示二进制表示中的逐元素精确相等。\n- 基于范数的诊断，例如差值的无穷范数，\n$$\n\\| S_N^{\\text{full}} - S_N^{\\text{resumed}} \\|_\\infty,\n$$\n当恢复正确时，该值必须精确为 $0$。\n\n您的实现必须遵守以下约束：\n\n- 使用单个 RNG，并确保所有随机抽样完全来源于它，其内部状态在检查点被捕获和恢复。\n- 对拉普拉斯算子使用周期性边界条件。\n- 所有计算均使用双精度浮点算术。\n- 将环境 $E$ 视为确定性模型配置的一部分；精确恢复必须恢复在检查点拍摄的环境快照，并将其用于所有后续步骤。\n\n测试套件：\n\n实现您的程序以运行以下四个测试用例。在每个用例中，生成一个布尔值，指示是否达到精确等效。\n\n- 用例 1（正常路径）：$m = 8$, $n = 8$, $N = 50$, $k = 20$, 种子 $= 12345$, $E.\\text{SCENARIO} = \\text{\"A\"}$。执行带环境恢复的检查点-恢复。预期输出为一个布尔值。\n- 用例 2（边界：立即恢复）：$m = 8$, $n = 8$, $N = 50$, $k = 0$, 种子 $= 54321$, $E.\\text{SCENARIO} = \\text{\"A\"}$。执行带环境恢复的检查点-恢复。预期输出为一个布尔值。\n- 用例 3（边界：最后一步检查点）：$m = 8$, $n = 8$, $N = 50$, $k = 50$, 种子 $= 11111$, $E.\\text{SCENARIO} = \\text{\"A\"}$。执行带环境恢复的检查点-恢复。预期输出为一个布尔值。\n- 用例 4（边缘：检查点后环境漂移）：$m = 8$, $n = 8$, $N = 50$, $k = 25$, 种子 $= 22222$, 初始 $E.\\text{SCENARIO} = \\text{\"A\"}$，但在检查点后环境被更改为 $E.\\text{SCENARIO} = \\text{\"B\"}$，并且不从检查点快照恢复。执行不带环境恢复的检查点-恢复，以演示不等式的检测。预期输出为一个布尔值。\n\n所有用例的模型参数均相同：$\\Delta t = 0.1$, $\\kappa = 0.2$, $\\alpha = 1.0$, $\\beta = 0.05$, $\\sigma = 1.0$, $T_{\\text{season}} = 24$, 基础温度 $T_0 = 288.0$ K，以及初始条件\n$$\nS_0 = T_0 \\mathbf{1} + 0.01 \\cdot \\zeta,\n$$\n其中 $\\zeta$ 是由同一 RNG 生成的独立标准正态场。\n\n输出规格：\n\n- 您的程序应生成单行输出，其中包含测试套件的四个布尔值，按顺序排列，形式为用方括号括起来的逗号分隔列表（例如，$[\\text{True},\\text{True},\\text{True},\\text{False}]$）。不应打印任何其他文本。",
            "solution": "该问题要求为随机气候模型设计并实现一个可复现的检查点设置和恢复工作流。核心挑战是确保从时间 $t=k$ 的检查点恢复的模拟所产生的最终状态 $S_N$ 与不间断模拟的最终状态按位相同。这对于可验证和可复现的科学研究是一个关键要求，特别是在需要暂停和恢复长期运行模型的业务环境中。\n\n该解决方案基于这样一个原则：确定性的计算机模拟，即使是模拟随机过程的模拟，其本质上也是一个确定性状态机。如果模拟的整个状态被完美地捕获和恢复，那么可复现性就得到了保证。\n\n**1. 状态定义与封装**\n\n在任何整数时间步 $t$，模拟的完整状态由几个部分组成：\n-   模型状态变量，$S_t \\in \\mathbb{R}^{m \\times n}$，即地表气温网格。\n-   随机数生成器（RNG）的内部状态，记为 $R_t$。由于 RNG 是一个确定性算法，恢复其状态 $R_t$ 可以确保后续的伪随机数序列与原始序列完全相同。\n-   环境配置，$E_t$。在此问题中，这是影响确定性强迫的场景键，$E.\\text{SCENARIO}$。\n-   当前时间索引，$t$。\n-   不可变模型参数，$\\Theta = \\{\\Delta t, \\kappa, \\alpha, \\beta, \\sigma, T_{\\text{season}}, T_0 \\}$。虽然不可变，但它们是模拟定义的一部分。\n\n在时间 $t=k$ 的检查点是一个包含 $\\{S_k, R_k, E_k, k\\}$ 的快照。为实现精确恢复，必须在继续模拟之前恢复所有这些组件。\n\n**2. 模拟引擎**\n\n模型根据离散时间方程演化：\n$$\nS_{t+1} = S_t + \\Delta t \\left( \\kappa \\, \\Delta S_t + \\alpha \\, \\mathcal{F}(t, E) \\right) + \\beta \\, \\eta_t\n$$\n实现了一个 `update_step` 函数来将状态从 $S_t$推进到 $S_{t+1}$。\n\n-   **离散拉普拉斯算子（$\\Delta S_t$）**：使用 `numpy.roll` 计算带周期性边界条件的拉普拉斯算子，以提高效率和清晰度。对于状态网格 $S$，操作为：\n    $$\n    (\\Delta S)_{i,j} = S_{i-1,j} + S_{i+1,j} + S_{i,j-1} + S_{i,j+1} - 4 S_{i,j}\n    $$\n    这是通过沿其轴移动数组 $S$ 来实现的。\n\n-   **确定性强迫（$\\mathcal{F}(t, E)$）**：强迫项计算如下：\n    $$\n    \\mathcal{F}(t, E) = A(E) \\sin\\left( \\frac{2\\pi t}{T_{\\text{season}}} \\right) P\n    $$\n    其中振幅 $A(E)$ 取决于当前环境 $E$。对于 $E.\\text{SCENARIO} = \\text{\"A\"}$，$A=0.5$；对于 $E.\\text{SCENARIO} = \\text{\"B\"}$，$A=0.8$。空间模式 $P$ 是一个全为1的矩阵。\n\n-   **随机创新（$\\eta_t$）**：随机场 $\\eta_t$ 在每个步骤通过从高斯分布 $\\mathcal{N}(0, \\sigma^2)$（其中 $\\sigma=1$）中抽取 $m \\times n$ 个值来生成。此操作必须使用模拟的单个、有状态的 RNG 实例，以确保抽样序列是可复现的。\n\n**3. 检查点设置与恢复工作流**\n\n为验证工作流，我们对每个测试用例采用双重运行策略：\n\n-   **完整运行**：模拟在 $t=0$ 时用给定的 `seed` 和环境 $E_0$ 进行初始化。它不间断地运行 $N$ 步，从 $t=0$ 到 $t=N-1$，产生最终状态 $S_N^{\\text{full}}$。RNG 在开始时只播种一次，其状态在整个模拟过程中演变。\n\n-   **恢复运行**：\n    1.  **运行至检查点**：用相同的种子和 $E_0$ 初始化一个独立的模拟。它从 $t=0$ 运行到 $t=k-1$。\n    2.  **创建检查点**：在步骤 $t=k$，更新状态之前，保存完整的模拟状态。这包括模型网格 $S_k$ 的副本、RNG 的内部状态（通过 `rng.bit_generator.state` 获取）、时间索引 $k$ 以及环境配置 $E_k$ 的副本。\n    3.  **模拟环境漂移（针对用例 4）**：为测试鲁棒性，可以在保存检查点后更改“实时”环境状态。\n    4.  **从检查点恢复**：加载已保存的检查点。模型网格 $S$ 设置为 $S_k$。一个新的 RNG 实例的内部状态被保存的状态 $R_k$ 覆盖。环境 $E$ 恢复到 $E_k$（除非像用例 4 中那样有意省略）。\n    5.  **运行至完成**：模拟使用恢复的状态从 $t=k$ 继续运行到 $t=N-1$。这将产生最终状态 $S_N^{\\text{resumed}}$。\n\n**4. 等效性验证**\n\n验证的核心是两次运行最终状态的按位比较：\n$$\n\\text{equal} = \\left( S_N^{\\text{full}} \\equiv S_N^{\\text{resumed}} \\right)\n$$\n这通过 `numpy.array_equal` 实现，当且仅当两个数组具有相同的形状和元素时，它返回 `True`，对于浮点数而言，这意味着它们是逐位相等的。`True` 的结果证实了检查点-恢复过程是完美的。无穷范数 $\\|S_N^{\\text{full}} - S_N^{\\text{resumed}}\\|_\\infty$ 必须精确为 $0$。\n\n**5. 测试用例分析**\n\n-   **用例 1 ($k=20$)**：标准场景，验证工作流在模拟中途设置检查点时能正常工作。\n-   **用例 2 ($k=0$)**：一个边界情况，检查点在初始步骤设置。‘恢复’的运行实际上是从初始状态开始，测试检查点逻辑是否能正确处理此边缘情况。\n-   **用例 3 ($k=50=N$)**：另一个边界情况，检查点在最后一步设置。恢复的运行没有步骤可执行，因此验证将完整运行的最终状态与检查点中保存的状态进行比较。\n-   **用例 4（环境漂移）**：这是一个阴性对照。在创建检查点后，环境被更改，并且关键的是，在恢复期间*不*恢复检查点中的环境。模拟在更改后的环境下继续进行，导致不同的强迫项。这将导致恢复的模拟偏离完整运行，从而正确地产生不等式（`False`），证明验证可以检测到状态恢复中的失败。\n\n此测试套件的成功执行有力地证明了所设计的工作流在指定条件下保证了可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport copy\nfrom typing import Dict, Any, Tuple, Optional\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the climate model checkpointing workflow.\n    \"\"\"\n\n    def update_step(\n        S: np.ndarray,\n        t: int,\n        env: Dict[str, Any],\n        rng: np.random.Generator,\n        params: Dict[str, Any],\n        amplitude_map: Dict[str, float]\n    ) - np.ndarray:\n        \"\"\"\n        Advances the model state by one time step.\n        \"\"\"\n        m, n = S.shape\n\n        # Laplacian with periodic boundary conditions\n        lap_S = (np.roll(S, 1, axis=0) + np.roll(S, -1, axis=0) +\n                 np.roll(S, 1, axis=1) + np.roll(S, -1, axis=1) - 4 * S)\n\n        # Deterministic forcing term\n        A = amplitude_map[env['SCENARIO']]\n        P = np.ones_like(S)\n        F_t_E = A * np.sin(2 * np.pi * t / params['T_season']) * P\n\n        # Stochastic innovation\n        eta_t = rng.normal(loc=0.0, scale=params['sigma'], size=(m, n))\n\n        # Full update equation\n        S_next = S + params['dt'] * (params['kappa'] * lap_S + params['alpha'] * F_t_E) + params['beta'] * eta_t\n        \n        return S_next\n\n    def run_simulation(\n        start_time: int,\n        end_time: int,\n        initial_S: np.ndarray,\n        rng: np.random.Generator,\n        env: Dict[str, Any],\n        params: Dict[str, Any],\n        amplitude_map: Dict[str, float]\n    ) - np.ndarray:\n        \"\"\"\n        Runs the simulation for a given time interval.\n        \"\"\"\n        S = initial_S.copy()\n        for t in range(start_time, end_time):\n            S = update_step(S, t, env, rng, params, amplitude_map)\n        return S\n\n    def run_test_case(\n        m: int,\n        n: int,\n        N: int,\n        k: int,\n        seed: int,\n        initial_scenario: str,\n        restore_env: bool,\n        drift_scenario: Optional[str]\n    ) - bool:\n        \"\"\"\n        Executes a single test case with a full run and a resumed run, then validates equivalence.\n        \"\"\"\n        # Define model parameters\n        params = {\n            'dt': 0.1, 'kappa': 0.2, 'alpha': 1.0, 'beta': 0.05,\n            'sigma': 1.0, 'T_season': 24, 'T0': 288.0\n        }\n        amplitude_map = {'A': 0.5, 'B': 0.8}\n\n        # --- Full Run ---\n        rng_full = np.random.default_rng(seed)\n        zeta_full = rng_full.normal(size=(m, n))\n        S0_full = params['T0'] + 0.01 * zeta_full\n        env_full = {'SCENARIO': initial_scenario}\n        S_N_full = run_simulation(0, N, S0_full, rng_full, env_full, params, amplitude_map)\n\n        # --- Resumed Run ---\n        # Part 1: Run up to checkpoint k\n        rng_resume = np.random.default_rng(seed)\n        zeta_resume = rng_resume.normal(size=(m, n))\n        S0_resume = params['T0'] + 0.01 * zeta_resume\n        env_live = {'SCENARIO': initial_scenario}\n        \n        S_at_k = run_simulation(0, k, S0_resume, rng_resume, env_live, params, amplitude_map)\n\n        # Part 2: Save checkpoint at t=k\n        checkpoint = {\n            'S': S_at_k.copy(),\n            'rng_state': copy.deepcopy(rng_resume.bit_generator.state),\n            't': k,\n            'env': copy.deepcopy(env_live)\n        }\n\n        # Part 3: Simulate environment drift after checkpoint (for Case 4)\n        if drift_scenario:\n            env_live['SCENARIO'] = drift_scenario\n            \n        # Part 4: Resume from checkpoint\n        S_from_cp = checkpoint['S']\n        t_from_cp = checkpoint['t']\n        \n        rng_from_cp = np.random.default_rng()\n        rng_from_cp.bit_generator.state = checkpoint['rng_state']\n        \n        if restore_env:\n            env_from_cp = checkpoint['env']\n        else:\n            env_from_cp = env_live # Use the potentially drifted live environment\n\n        # Part 5: Run from k to N\n        S_N_resumed = run_simulation(t_from_cp, N, S_from_cp, rng_from_cp, env_from_cp, params, amplitude_map)\n\n        # --- Validation ---\n        return np.array_equal(S_N_full, S_N_resumed)\n\n    # Test suite definition\n    test_cases = [\n        # Case 1: Happy path\n        {'m': 8, 'n': 8, 'N': 50, 'k': 20, 'seed': 12345, 'initial_scenario': 'A', 'restore_env': True, 'drift_scenario': None},\n        # Case 2: Boundary - immediate resume\n        {'m': 8, 'n': 8, 'N': 50, 'k': 0, 'seed': 54321, 'initial_scenario': 'A', 'restore_env': True, 'drift_scenario': None},\n        # Case 3: Boundary - final-step checkpoint\n        {'m': 8, 'n': 8, 'N': 50, 'k': 50, 'seed': 11111, 'initial_scenario': 'A', 'restore_env': True, 'drift_scenario': None},\n        # Case 4: Edge - environment drift detected\n        {'m': 8, 'n': 8, 'N': 50, 'k': 25, 'seed': 22222, 'initial_scenario': 'A', 'restore_env': False, 'drift_scenario': 'B'},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}