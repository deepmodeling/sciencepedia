{
    "hands_on_practices": [
        {
            "introduction": "遥感传感器的原始输出是无单位的数字计数值（Digital Numbers, DN），而不是具有物理意义的单位，如辐射亮度。这个练习将指导你如何使用在实验室中测定的定标方程，将这些原始计数值转换为星上光谱辐射亮度。你将接触到现实世界中常见的非线性效应，并学习如何通过数学方法确保定标在整个动态范围内是物理上合理的（即单调性）。",
            "id": "3823020",
            "problem": "一台卫星成像光谱仪产生原始数字计数 $D$，通过一个将 $D$ 与 $L$ 联系起来的仪器传递函数 $f$，将其转换为传感器端光谱辐亮度 $L$。对于平滑的 $f$，在 $D=0$ 处的二阶泰勒展开提供了一个可行的定标模型，其主要项是偏移量 $o = f(0)$、线性增益 $g = f'(0)$ 和二次非线性系数 $\\alpha = \\frac{1}{2} f''(0)$，从而得出一个包含微小非线性的定标映射。在实验室表征中，估计了以下参数：线性增益 $g = 2.4 \\times 10^{-5}$ 瓦特每平方米每球面度每计数，偏移量 $o = 1.2 \\times 10^{-3}$ 瓦特每平方米每球面度，以及二次系数 $\\alpha = -1.1 \\times 10^{-10}$ 瓦特每平方米每球面度每计数平方。考虑一个像素，其原始计数为 $D = 38500$，传感器动态范围定义在 $D \\in [0, D_{\\max}]$ 上，其中 $D_{\\max} = 65535$。从二阶泰勒展开模型和可微映射的单调性定义出发，推导校准后的传感器端辐亮度 $L(D)$ 以及定标映射在 $[0, D_{\\max}]$ 上单调递增的条件。计算给定 $D$ 值的校准辐亮度，然后计算最小斜率 $m = \\min_{D \\in [0, D_{\\max}]} \\frac{dL}{dD}$ 以评估是否保持了单调性。将 $m$ 的值作为最终答案，单位为瓦特每平方米每球面度每计数。将您的最终答案四舍五入到四位有效数字。将 $L$ 以瓦特每平方米每球面度表示，将 $m$ 以瓦特每平方米每球面度每计数表示。",
            "solution": "题目提供了一个二阶泰勒展开作为卫星传感器定标的模型。传感器端光谱辐亮度 $L$ 通过函数 $L = f(D)$ 与原始数字计数 $D$ 相关。该模型是此函数在 $D=0$ 附近的近似：\n$$L(D) \\approx f(0) + f'(0)D + \\frac{f''(0)}{2!}D^2$$\n题目根据物理参数定义了系数：偏移量 $o = f(0)$，线性增益 $g = f'(0)$，以及二次非线性系数 $\\alpha = \\frac{1}{2}f''(0)$。将这些定义代入展开式，得到明确的定标模型：\n$$L(D) = o + gD + \\alpha D^2$$\n这就是所要求的校准后的传感器端辐亮度 $L(D)$ 的表达式。\n\n接下来，我们推导定标映射单调递增的条件。一个可微函数在一个区间上是单调递增的，如果它的一阶导数在该区间内处处非负。我们关心的定义域是传感器的动态范围，即 $D \\in [0, D_{\\max}]$。我们计算 $L(D)$ 关于 $D$ 的一阶导数：\n$$\\frac{dL}{dD} = \\frac{d}{dD}(o + gD + \\alpha D^2) = g + 2\\alpha D$$\n单调性的条件是对于所有 $D \\in [0, D_{\\max}]$，都有 $\\frac{dL}{dD} \\ge 0$。导数是 $D$ 的线性函数，斜率为 $2\\alpha$。给定的 $\\alpha$ 值为 $-1.1 \\times 10^{-10}$ 瓦特每平方米每球面度每计数平方，这是一个负值。因此，函数 $\\frac{dL}{dD}$ 是 $D$ 的递减函数。对于闭区间上的递减函数，其最小值在区间的右端点达到。因此，条件 $\\frac{dL}{dD} \\ge 0$ 在整个区间上成立的充要条件是它在 $D = D_{\\max}$ 处成立。因此，定标映射在 $[0, D_{\\max}]$ 上单调递增的条件是：\n$$g + 2\\alpha D_{\\max} \\ge 0$$\n现在，我们计算原始计数 $D = 38500$ 的像素的校准辐亮度。给定的参数是：\n$o = 1.2 \\times 10^{-3}$ W m$^{-2}$ sr$^{-1}$\n$g = 2.4 \\times 10^{-5}$ W m$^{-2}$ sr$^{-1}$ count$^{-1}$\n$\\alpha = -1.1 \\times 10^{-10}$ W m$^{-2}$ sr$^{-1}$ count$^{-2}$\n将这些值和 $D = 38500$ 代入定标方程：\n$$L(38500) = (1.2 \\times 10^{-3}) + (2.4 \\times 10^{-5})(38500) + (-1.1 \\times 10^{-10})(38500)^2$$\n我们计算各项：\n$$(2.4 \\times 10^{-5})(38500) = 0.924$$\n$$(-1.1 \\times 10^{-10})(38500)^2 = (-1.1 \\times 10^{-10})(1482250000) \\approx -0.1630475$$\n$$L(38500) \\approx 1.2 \\times 10^{-3} + 0.924 - 0.1630475 = 0.0012 + 0.924 - 0.1630475 = 0.7621525$$\n所以，校准后的辐亮度约为 $0.7621525$ W m$^{-2}$ sr$^{-1}$。\n\n最后，题目要求我们计算最小斜率 $m = \\min_{D \\in [0, D_{\\max}]} \\frac{dL}{dD}$。根据单调性分析，由于 $\\alpha  0$，斜率 $\\frac{dL}{dD} = g + 2\\alpha D$ 是 $D$ 的递减函数。因此，其在区间 $[0, D_{\\max}]$ 上的最小值在 $D = D_{\\max}$ 处取得。\n$$m = g + 2\\alpha D_{\\max}$$\n我们代入给定值，其中 $D_{\\max} = 65535$：\n$$m = (2.4 \\times 10^{-5}) + 2(-1.1 \\times 10^{-10})(65535)$$\n$$m = 2.4 \\times 10^{-5} - (2.2 \\times 10^{-10})(65535)$$\n$$m = 2.4 \\times 10^{-5} - 0.0000144177$$\n$$m = 2.4 \\times 10^{-5} - 1.44177 \\times 10^{-5}$$\n$$m = (2.4 - 1.44177) \\times 10^{-5}$$\n$$m = 0.95823 \\times 10^{-5} = 9.5823 \\times 10^{-6}$$\n$m$ 的单位是 W m$^{-2}$ sr$^{-1}$ count$^{-1}$。题目要求最终答案四舍五入到四位有效数字。\n$$m \\approx 9.582 \\times 10^{-6}$$\n由于 $m > 0$，单调性条件在传感器的整个动态范围内确实得到满足。",
            "answer": "$$\\boxed{9.582 \\times 10^{-6}}$$"
        },
        {
            "introduction": "在完成仪器定标或建立模型后，我们必须对照可信的参考数据来验证其结果的准确性。本练习将介绍三个基本的验证指标——均方根误差（Root Mean Square Error, RMSE）、偏差（bias）和决定系数（$R^2$），并演示如何计算它们。更重要的是，它通过一个具体案例揭示了为什么仅依赖像 $R^2$ 这样的单一指标是不够的，以及偏差和 RMSE 如何共同提供对模型精度的更完整评估 。",
            "id": "3823042",
            "problem": "对一个测量大气层顶光谱辐射亮度的星载成像光谱仪通道进行实验室辐射定标。一个参考系统在六个工作点提供可溯源的辐射亮度值，光谱仪提供定标后的输出，并与参考值进行比较。配对数据如下（辐射亮度单位为 W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$）：\n\n- 数据对 1：参考辐射亮度 $L_{\\text{ref}} = 5.00$，定标后测量值 $L_{\\text{cal}} = 5.40$。\n- 数据对 2：参考辐射亮度 $L_{\\text{ref}} = 6.00$，定标后测量值 $L_{\\text{cal}} = 6.23$。\n- 数据对 3：参考辐射亮度 $L_{\\text{ref}} = 7.50$，定标后测量值 $L_{\\text{cal}} = 7.75$。\n- 数据对 4：参考辐射亮度 $L_{\\text{ref}} = 9.00$，定标后测量值 $L_{\\text{cal}} = 9.14$。\n- 数据对 5：参考辐射亮度 $L_{\\text{ref}} = 10.50$，定标后测量值 $L_{\\text{cal}} = 10.73$。\n- 数据对 6：参考辐射亮度 $L_{\\text{ref}} = 12.00$，定标后测量值 $L_{\\text{cal}} = 12.15$。\n\n使用定标和验证中采用的标准定义，计算参考辐射亮度与定标后辐射亮度之间的均方根误差 (RMSE)、定义为差值 $L_{\\text{cal}} - L_{\\text{ref}}$ 均值的加性偏差，以及决定系数 ($R^2$)。然后，解读高 $R^2$ 值是否必然保证良好的定标质量，并根据计算出的指标简要证明您的结论。\n\n将所有三个指标四舍五入至四位有效数字。以 W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$ 为单位表示 RMSE 和偏差；以无单位小数表示 $R^2$。您的最终答案必须按 RMSE、偏差、$R^2$ 的顺序列出这三个值。",
            "solution": "该问题要求根据给定的一组配对数据计算三个统计指标——均方根误差 (RMSE)、加性偏差和决定系数 ($R^2$)，并随后对这些指标进行解读。\n\n令参考辐射亮度值为集合 $\\{x_i\\}$，定标后测量值为集合 $\\{y_i\\}$，其中 $i$ 的范围从 1 到 $n$。数据对的数量为 $n=6$。辐射亮度的单位是 W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$。\n\n给定的数据为：\n$x = \\{5.00, 6.00, 7.50, 9.00, 10.50, 12.00\\}$\n$y = \\{5.40, 6.23, 7.75, 9.14, 10.73, 12.15\\}$\n\n首先，我们计算每对数据点的差值（误差），$d_i = y_i - x_i$：\n$d_1 = 5.40 - 5.00 = 0.40$\n$d_2 = 6.23 - 6.00 = 0.23$\n$d_3 = 7.75 - 7.50 = 0.25$\n$d_4 = 9.14 - 9.00 = 0.14$\n$d_5 = 10.73 - 10.50 = 0.23$\n$d_6 = 12.15 - 12.00 = 0.15$\n\n问题将加性偏差定义为这些差值的平均值。其公式为：\n$$ \\text{Bias} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - x_i) = \\frac{1}{n} \\sum_{i=1}^{n} d_i $$\n代入数值：\n$$ \\text{Bias} = \\frac{1}{6} (0.40 + 0.23 + 0.25 + 0.14 + 0.23 + 0.15) = \\frac{1.40}{6} \\approx 0.23333... $$\n四舍五入至四位有效数字，偏差为 $0.2333$ W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$。\n\n接下来，我们计算均方根误差 (RMSE)。RMSE 的公式为：\n$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - x_i)^2} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} d_i^2} $$\n我们首先计算差值的平方，$d_i^2$：\n$d_1^2 = (0.40)^2 = 0.1600$\n$d_2^2 = (0.23)^2 = 0.0529$\n$d_3^2 = (0.25)^2 = 0.0625$\n$d_4^2 = (0.14)^2 = 0.0196$\n$d_5^2 = (0.23)^2 = 0.0529$\n$d_6^2 = (0.15)^2 = 0.0225$\n差值平方和为：\n$$ \\sum_{i=1}^{n} d_i^2 = 0.1600 + 0.0529 + 0.0625 + 0.0196 + 0.0529 + 0.0225 = 0.3704 $$\n现在我们可以计算 RMSE：\n$$ \\text{RMSE} = \\sqrt{\\frac{0.3704}{6}} = \\sqrt{0.0617333...} \\approx 0.2484619... $$\n四舍五入至四位有效数字，RMSE 为 $0.2485$ W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$。\n\n最后，我们计算决定系数 $R^2$。它是 $x$ 和 $y$ 之间皮尔逊相关系数的平方。其公式为：\n$$ R^2 = \\left( \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}} \\right)^2 = \\frac{SS_{xy}^2}{SS_{xx} SS_{yy}} $$\n其中 $SS$ 表示平方和。我们首先计算平均值 $\\bar{x}$ 和 $\\bar{y}$：\n$$ \\sum_{i=1}^{n} x_i = 5.00 + 6.00 + 7.50 + 9.00 + 10.50 + 12.00 = 50.00 \\implies \\bar{x} = \\frac{50.00}{6} $$\n$$ \\sum_{i=1}^{n} y_i = 5.40 + 6.23 + 7.75 + 9.14 + 10.73 + 12.15 = 51.40 \\implies \\bar{y} = \\frac{51.40}{6} $$\n接下来，我们使用计算公式计算平方和 $SS_{xx}$、$SS_{yy}$ 以及交叉乘积和 $SS_{xy}$：\n$SS_{xx} = \\sum x_i^2 - \\frac{(\\sum x_i)^2}{n}$\n$SS_{yy} = \\sum y_i^2 - \\frac{(\\sum y_i)^2}{n}$\n$SS_{xy} = \\sum x_i y_i - \\frac{(\\sum x_i)(\\sum y_i)}{n}$\n\n$$ \\sum x_i^2 = 5^2 + 6^2 + 7.5^2 + 9^2 + 10.5^2 + 12^2 = 25+36+56.25+81+110.25+144 = 452.5 $$\n$$ \\sum y_i^2 = 5.4^2 + 6.23^2 + 7.75^2 + 9.14^2 + 10.73^2 + 12.15^2 = 29.16+38.8129+60.0625+83.5396+115.1329+147.6225 = 474.3304 $$\n$$ \\sum x_i y_i = (5)(5.4)+(6)(6.23)+(7.5)(7.75)+(9)(9.14)+(10.5)(10.73)+(12)(12.15) = 27+37.38+58.125+82.26+112.665+145.8 = 463.23 $$\n\n现在，代入平方和公式：\n$$ SS_{xx} = 452.5 - \\frac{50^2}{6} = 452.5 - 416.666... = 35.833... $$\n$$ SS_{yy} = 474.3304 - \\frac{51.4^2}{6} = 474.3304 - 440.3266... = 34.00373... $$\n$$ SS_{xy} = 463.23 - \\frac{(50)(51.4)}{6} = 463.23 - 428.333... = 34.8966... $$\n\n最后，我们计算 $R^2$：\n$$ R^2 = \\frac{(34.8966...)^2}{(35.833...)(34.00373...)} = \\frac{1217.777...}{1218.463...} \\approx 0.999436... $$\n四舍五入至四位有效数字，$R^2$ 为 $0.9994$。\n\n解读：\n高 $R^2$ 值不一定保证良好的定标质量。决定系数 $R^2$ 衡量的是因变量方差中可由自变量预测的比例。在此背景下，$R^2$ 值为 $0.9994$ 表明定标后测量值 ($L_{\\text{cal}}$) 与参考辐射亮度 ($L_{\\text{ref}}$) 之间存在极强的线性关系。这意味着传感器的响应是高度线性和可预测的。\n\n然而，$R^2$ 对加性偏差和乘性偏差不敏感。良好的定标质量既要求高精密度（低随机误差），也要求高准确度（低系统误差）。我们计算出的 $0.2333$ W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$ 的偏差揭示了一个系统误差：定标后的测量值平均高于真实的参考值。$0.2485$ W m$^{-2}$ sr$^{-1}$ $\\mu$m$^{-1}$ 的 RMSE 量化了总误差，该总误差主要由这个系统偏差主导。虽然关系是线性的（高 $R^2$），但数据点并不落在理想的 $1:1$ 线上，而是落在一条有正截距的线上。因此，尽管 $R^2$ 值极好，但定标并不完美，并表现出明显的准确度问题（一个正偏差），需要进行校正。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2485  0.2333  0.9994 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "“定标”也常常指建立从传感器数据（如归一化植被指数 NDVI）估算生物物理变量（如叶面积指数 LAI）的经验模型。这个编程练习将通过一个模拟实验，让你直观地理解模型构建中的一个核心概念：过拟合。通过比较一个简单模型和一个复杂模型的表现，你将亲眼看到一个模型如何在训练数据上表现完美，但在应用于新数据时却表现不佳——这是过拟合的典型特征 。",
            "id": "3822987",
            "problem": "考虑一个遥感和环境建模中的定标与验证练习，该练习专注于从一个辐射植被指数代理来估算叶面积指数 (LAI)，LAI 定义为单位地表面积上的单侧叶面积。归一化植被指数 (NDVI) 定义为 $NDVI = \\frac{R_{\\text{NIR}} - R_{\\text{RED}}}{R_{\\text{NIR}} + R_{\\text{RED}}}$，其中 $R_{\\text{NIR}}$ 和 $R_{\\text{RED}}$ 分别是近红外和红光波段的反射率。假设 NDVI (记为 $x$) 和 LAI (记为 $y$) 之间的真实关系遵循类似比尔-朗伯定律的饱和规律：$y = -\\frac{1}{\\kappa} \\ln(1 - x)$，其中 $\\kappa = 0.6$，适用于 $x \\in [0.1, 0.9]$。观测是有噪声的：测得的 LAI 为 $y_{\\text{obs}} = y + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 是独立同分布的高斯噪声。定标指的是使用一个定标数据集 $\\{(x_i, y_{\\text{obs},i})\\}_{i=1}^{n_{\\text{train}}}$ 来拟合模型，而验证指的是在一个样本外数据集 $\\{(x_j^{\\text{val}}, y_{\\text{obs},j}^{\\text{val}})\\}_{j=1}^{n_{\\text{val}}}$ 上评估预测性能，该数据集独立地从相同的生成过程中抽取。\n\n设均方根误差 (RMSE) 定义为 $RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$，其中 $n$ 是样本大小，$y_i$ 是观测到的 LAI 值，$\\hat{y}_i$ 是模型预测值。虽然 LAI 是一个无量纲比率，其单位表示为 $m^2/m^2$，但 RMSE 具有相同的单位 $m^2/m^2$，并被视为一个无量纲量。\n\n您的任务是实现一个程序，对下面给出的每个测试用例执行以下步骤：\n- 通过在 $[0.1, 0.9]$ 上均匀采样 $x$ 并根据真实关系和标准差为 $\\sigma$ 的加性高斯噪声导出 $y_{\\text{obs}}$，来生成定标和验证数据集。\n- 在定标数据集上拟合两个定标器：\n  1. 一个低复杂度的 $d$ 次多项式回归器，通过对一个缩放后的预测变量 $t = 2 \\frac{x - \\min(x_{\\text{train}})}{\\max(x_{\\text{train}}) - \\min(x_{\\text{train}})} - 1$ 进行最小二乘法，将 NDVI 映射到 LAI。该缩放方法使用定标集的参数，并一致地应用于定标集和验证集。\n  2. 一个高灵活度的 $1$-最近邻回归器 (非参数)，它通过返回欧氏距离中最近的定标 $x$ 所对应的 $y_{\\text{obs}}$ 值来对每个输入进行预测 $\\hat{y}$。\n- 计算两个定标器的样本内 (定标) RMSE 和样本外 (验证) RMSE。\n- 当且仅当高灵活度定标器的定标 RMSE 严格低于多项式定标器，并且其验证 RMSE 严格高于多项式定标器时，声明检测到过拟合；为每个测试用例输出一个布尔值，指示此条件是否成立。\n\n使用以下参数元组 $(n_{\\text{train}}, n_{\\text{val}}, \\sigma, d, \\text{seed})$ 的测试套件：\n- 案例 1：$(40, 1000, 0.3, 2, 1)$\n- 案例 2：$(400, 1000, 0.2, 3, 2)$\n- 案例 3：$(15, 1000, 0.5, 1, 3)$\n- 案例 4：$(2000, 500, 0.0, 3, 4)$\n\n这些案例旨在覆盖：\n- 一个具有中等噪声和较小定标样本量的通用情况 (案例 1)。\n- 一个具有较大定标样本量和中等噪声的情况 (案例 2)。\n- 一个具有极小定标样本量和高噪声的重要边缘情况 (案例 3)。\n- 一个没有噪声和极大定标样本量的边界情况 (案例 4)，在此情况下，高灵活度模型不一定会降低验证性能。\n\n您的程序应生成一行输出，其中包含四个测试用例的布尔结果，格式为方括号括起来的逗号分隔列表，例如“[True,False,True,False]”。不允许有任何中间输出或文本。所有涉及 RMSE 的计算都必须遵循 LAI 的单位 $m^2/m^2$ (无量纲比率)，但最终要打印的答案是布尔值，而非物理量。",
            "solution": "该问题已经过验证，并被确定为模型定标与验证方面一个适定且有科学依据的练习。我们将提供完整的解决方案。\n\n任务是确定在比较两种用于从归一化植被指数 (NDVI) 代理估算叶面积指数 (LAI) 的不同回归模型时，是否检测到过拟合。过拟合是统计建模中的一个关键概念，描述的是模型与其训练数据拟合得过于紧密，捕获了随机噪声而非潜在关系，从而无法泛化到新的、未见过的数据上的情况。该问题通过比较一个低复杂度模型 (多项式回归) 与一个高灵活度模型 (1-最近邻回归) 来定义一个检测过拟合的精确条件。\n\n对于每个测试用例，总体流程包括四个主要步骤：\n1.  基于定义的真实物理关系和加性噪声模型，随机生成定标 (训练) 和验证数据集。\n2.  使用训练数据对多项式回归器和 1-最近邻回归器进行定标。\n3.  使用均方根误差 (RMSE) 指标，在训练数据 (样本内) 和验证数据 (样本外) 上评估两个模型。\n4.  应用指定的过拟合逻辑条件。\n\n设 NDVI 值为 $x$，LAI 值为 $y$。真实关系由类似比尔-朗伯定律的规律给出：\n$$y(x) = -\\frac{1}{\\kappa} \\ln(1 - x)$$\n其中 $\\kappa = 0.6$。观测到的 LAI，$y_{\\text{obs}}$，包含加性高斯噪声：\n$$y_{\\text{obs}} = y(x) + \\epsilon, \\quad \\text{where} \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$$\n训练集和验证集的输入数据 $x$ 均从均匀分布 $x \\sim \\mathcal{U}(0.1, 0.9)$ 中抽取。为每个测试用例提供了一个特定的随机种子，以确保生成数据集的可复现性。\n\n性能指标是均方根误差 (RMSE)，定义为：\n$$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{obs},i} - \\hat{y}_i)^2}$$\n其中 $y_{\\text{obs},i}$ 是观测值，$\\hat{y}_i$ 是模型对 $n$ 个样本的预测值。\n\n**定标器 1：低复杂度多项式回归器**\n\n该模型使用一个 $d$ 次多项式来近似真实的 LAI-NDVI 关系。为增强拟合过程中的数值稳定性，预测变量 $x$ 首先被缩放到区间 $[-1, 1]$。该缩放基于训练数据 $x_{\\text{train}}$ 的最小值和最大值：\n$$t = 2 \\frac{x - \\min(x_{\\text{train}})}{\\max(x_{\\text{train}}) - \\min(x_{\\text{train}})} - 1$$\n此变换一致地应用于训练集和验证集，使用的缩放参数仅从训练集导出。模型形式如下：\n$$\\hat{y}_{\\text{poly}}(t) = \\sum_{k=0}^{d} c_k t^k$$\n系数 $\\{c_k\\}_{k=0}^d$ 通过求解一个线性最小二乘问题来确定，该问题最小化了所有训练点 $i=1, \\dots, n_{\\text{train}}$ 的模型预测值 $\\hat{y}_{\\text{poly}}(t_i)$ 与观测训练值 $y_{\\text{obs},i}$ 之间的平方差之和。这是拟合参数模型的标准流程，通过 `numpy.polyfit` 实现。该模型具有由次数 $d$ 决定的固定复杂度。它往往具有较高的偏差 (因为多项式是对数函数的拙劣近似) 但较低的方差，因为它平滑了数据中的局部噪声。\n\n**定标器 2：高灵活度 1-最近邻 (1-NN) 回归器**\n\n这是一个非参数模型，意味着其复杂度能适应数据。预测规则很简单：对于任何给定的输入值 $x_{\\text{new}}$，模型在训练集中找到单个最近的点 $x_j$ (依据欧氏距离 $|x_{\\text{new}} - x_j|$)，并返回其对应的观测 LAI 值 $y_{\\text{obs},j}$ 作为预测值。\n$$\\hat{y}_{\\text{1-NN}}(x_{\\text{new}}) = y_{\\text{obs},j} \\quad \\text{where} \\quad j = \\arg\\min_{k \\in \\{1,\\dots,n_{\\text{train}}\\}} |x_{\\text{new}} - x_k|$$\n此规则的一个关键后果是其在训练数据本身上的性能。对于任何给定的训练点 $x_i$，其最近的训练点就是 $x_i$ 本身。因此，样本内预测 $\\hat{y}_{\\text{1-NN}}(x_i)$ 就是 $y_{\\text{obs},i}$。这导致训练 RMSE 恰好为 $0$：\n$$RMSE_{\\text{1-NN, train}} = \\sqrt{\\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (y_{\\text{obs},i} - y_{\\text{obs},i})^2} = 0$$\n这种对训练数据 (包括其噪声成分) 的完美拟合，是高灵活度模型的一个标志。为所有验证点寻找最近邻的算法通过使用 `scipy.spatial.cKDTree` 中的 k-d 树数据结构来高效实现。\n\n**过拟合检测**\n\n该问题将过拟合定义为两个条件的合取：\n1.  高灵活度模型的定标 (训练) RMSE 严格低于多项式模型：$RMSE_{\\text{1-NN, train}}  RMSE_{\\text{poly, train}}$。\n2.  高灵活度模型的验证 RMSE 严格高于多项式模型：$RMSE_{\\text{1-NN, val}} > RMSE_{\\text{poly, val}}$。\n\n鉴于 $RMSE_{\\text{1-NN, train}} = 0$，并且多项式模型不会完美拟合含噪声的数据 (或在无噪声情况下拟合真实的非多项式函数)，其训练 RMSE 将严格为正，$RMSE_{\\text{poly, train}} > 0$。因此，第一个条件总是满足的。过拟合的检验实际上简化为检查 1-NN 模型在验证数据上的表现是否比多项式模型差，即 $RMSE_{\\text{1-NN, val}} > RMSE_{\\text{poly, val}}$。这个逻辑直接反映了偏差-方差权衡：当 1-NN 模型的高方差 (源于对噪声的拟合) 导致的验证误差大于多项式模型的误差 (该误差是其偏差（源于错误的函数形式）和较低方差（源于平滑）的组合) 时，就发生了过拟合。\n\n提供的代码为四个测试用例中的每一个都实现了这整个过程，计算相关的 RMSE 值并应用过拟合条件以产生最终的布尔结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef solve():\n    \"\"\"\n    Solves the model validation problem for a series of test cases.\n    For each case, it generates synthetic remote sensing data, fits two models\n    (polynomial and 1-nearest neighbor), calculates their performance, and\n    determines if overfitting has occurred based on a specified criterion.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n_train, n_val, sigma, d, seed)\n        (40, 1000, 0.3, 2, 1),\n        (400, 1000, 0.2, 3, 2),\n        (15, 1000, 0.5, 1, 3),\n        (2000, 500, 0.0, 3, 4)\n    ]\n\n    results = []\n    \n    KAPPA = 0.6\n    \n    def y_true_func(x):\n        \"\"\"Calculates the true LAI from NDVI based on the Beer-Lambert-like law.\"\"\"\n        return -1/KAPPA * np.log(1 - x)\n\n    def rmse(y_observed, y_predicted):\n        \"\"\"Calculates the Root Mean Squared Error.\"\"\"\n        return np.sqrt(np.mean((y_observed - y_predicted)**2))\n\n    for n_train, n_val, sigma, d, seed in test_cases:\n        # Set up the random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Generate calibration (training) data\n        x_train = rng.uniform(0.1, 0.9, size=n_train)\n        y_true_train = y_true_func(x_train)\n        noise_train = rng.normal(0, sigma, size=n_train)\n        y_obs_train = y_true_train + noise_train\n        \n        # Generate validation data\n        x_val = rng.uniform(0.1, 0.9, size=n_val)\n        y_true_val = y_true_func(x_val)\n        noise_val = rng.normal(0, sigma, size=n_val)\n        y_obs_val = y_true_val + noise_val\n        \n        # --- Calibrator 1: Polynomial Regressor ---\n        \n        # Calculate scaling parameters from the training set.\n        min_x_train = np.min(x_train)\n        max_x_train = np.max(x_train)\n        \n        # Scale both training and validation predictors using training set parameters.\n        # This avoids data leakage from the validation set into the training process.\n        # A small epsilon is added for numerical stability in the unlikely event max=min.\n        denominator = max_x_train - min_x_train\n        if denominator == 0:\n            denominator = 1e-9 # Prevent division by zero, though unlikely for n_train > 1\n\n        t_train = 2 * (x_train - min_x_train) / denominator - 1\n        t_val = 2 * (x_val - min_x_train) / denominator - 1\n\n        # Fit the polynomial model using least squares.\n        poly_coeffs = np.polyfit(t_train, y_obs_train, d)\n        poly_model = np.poly1d(poly_coeffs)\n\n        # Predict LAI for both sets.\n        y_pred_poly_train = poly_model(t_train)\n        y_pred_poly_val = poly_model(t_val)\n        \n        # Calculate RMSE for the polynomial model.\n        rmse_poly_train = rmse(y_obs_train, y_pred_poly_train)\n        rmse_poly_val = rmse(y_obs_val, y_pred_poly_val)\n\n        # --- Calibrator 2: 1-Nearest Neighbor Regressor ---\n        \n        # The in-sample RMSE for a 1-NN regressor is 0 by definition, as each\n        # training point is its own nearest neighbor.\n        rmse_1nn_train = 0.0\n        \n        # Build a k-d tree for efficient nearest neighbor search.\n        # Reshape x_train to be a 2D array of shape (n_samples, n_features).\n        x_train_reshaped = x_train.reshape(-1, 1)\n        x_val_reshaped = x_val.reshape(-1, 1)\n        \n        tree = cKDTree(x_train_reshaped)\n        \n        # Query the tree to find the index of the nearest neighbor for each validation point.\n        _, indices = tree.query(x_val_reshaped, k=1)\n        \n        # The prediction is the observed y-value of the nearest neighbor.\n        y_pred_1nn_val = y_obs_train[indices]\n        \n        # Calculate validation RMSE for the 1-NN model.\n        rmse_1nn_val = rmse(y_obs_val, y_pred_1nn_val)\n        \n        # --- Overfitting Detection ---\n        \n        # Overfitting is detected if the flexible model (1-NN) fits the training\n        # data better but generalizes to validation data worse than the simple model.\n        is_overfitting = (rmse_1nn_train  rmse_poly_train) and \\\n                         (rmse_1nn_val > rmse_poly_val)\n        \n        results.append(is_overfitting)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}