{
    "hands_on_practices": [
        {
            "introduction": "此练习将介绍“面片检验”（patch test），这是计算力学中一个基础的验证工具。在将任何数值格式应用于复杂问题之前，我们必须确保它能够精确地重现简单的已知解。对于梯度重构，最基本的检验是看它能否完美地恢复仿射场（affine field）的恒定梯度。此练习不仅能验证您的程序实现，还将引入“秩亏”（rank deficiency）这一关键概念，当邻近点分布不充分，无法唯一定义梯度时，就会出现此现象。",
            "id": "3972768",
            "problem": "您的任务是在航空航天计算流体动力学（Aerospace CFD）的背景下，为仿射标量场设计并实现一个最小二乘梯度重构的网格片检验。其目标是验证当几何采样足够丰富时，该重构方法能否在以单元为中心的网格片上精确再现仿射场的梯度，并诊断因秩亏或实现错误导致的失败。该检验必须完全以纯数学术语构建和执行，不涉及任何物理单位。\n\n背景与基本原理：在 $d$ 维空间中，仿射标量场定义为 $u(\\mathbf{x}) = \\alpha + \\mathbf{g}^{\\top} \\mathbf{x}$，其中 $\\alpha \\in \\mathbb{R}$ 和 $\\mathbf{g} \\in \\mathbb{R}^{d}$ 是常系数，$\\mathbf{x} \\in \\mathbb{R}^{d}$ 表示空间坐标。对于一个中心点 $\\mathbf{x}_{0}$，精确的仿射关系意味着对于任何相邻点 $\\mathbf{x}_{j}$，都有 $u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0}) = \\mathbf{g}^{\\top} (\\mathbf{x}_{j} - \\mathbf{x}_{0})$。在一个相邻点数量多于未知梯度分量数量的通用网格片上，可以通过最小化差值与其线性预测值之间的加权残差平方和来确定 $\\mathbf{g}$，从而在满秩采样下确保无偏重构。\n\n任务：编写一个完整的程序，对下述每个测试用例执行以下步骤：\n1. 根据给定的仿射场和几何形状，构造设计偏移量 $\\Delta \\mathbf{x}_{j} = \\mathbf{x}_{j} - \\mathbf{x}_{0}$ 和响应差值 $\\Delta u_{j} = u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0})$。\n2. 建立并求解加权最小二乘问题，即使用数值稳定的线性代数方法，在 $\\mathbf{g} \\in \\mathbb{R}^{d}$ 上最小化目标函数 $\\sum_{j=1}^{m} w_{j} \\left(\\mathbf{g}^{\\top} \\Delta \\mathbf{x}_{j} - \\Delta u_{j}\\right)^{2}$。不要预先假设任何专用公式；该方法必须源于最小二乘最小化原理。\n3. 使用奇异值分解和相对容差 $r_{\\mathrm{tol}} = 10^{-12}$ 来确定加权设计矩阵的数值秩。如果数值秩严格小于 $d$，则宣布该系统对于此测试用例是秩亏的。\n4. 计算重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 与真实梯度 $\\mathbf{g}_{\\mathrm{true}}$ 之间的欧几里得误差范数 $\\lVert \\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}} \\rVert_{2}$。\n5. 生成单行输出，按下面指定的格式汇总所有测试用例的结果。\n\n科学真实性要求：对于一个精确的仿射场和一个满列秩的网格片，重构在精确算术下必须产生零误差，在浮点运算下必须产生一个由舍入误差界定的接近零的误差。未能达到接近零的误差表明存在秩亏或实现缺陷。\n\n本问题不涉及角度单位。不涉及任何物理单位；所有量均为无量纲。\n\n测试套件：实现以下五个测试用例。在每个用例中，$d$ 表示空间维度，$\\mathbf{x}_{0}$ 是中心点，列出了相邻点的坐标，提供了仿射场系数 $(\\alpha, \\mathbf{g}_{\\mathrm{true}})$ 以使得 $u(\\mathbf{x}) = \\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}$，并指定了正权重 $w_{j}$。所有点和系数都是精确的实数。\n\n- 用例 1（正常路径，二维，均匀权重）：$d = 2$，$\\mathbf{x}_{0} = (0, 0)$，相邻点 $\\{(1, 0), (0, 1), (-1, 0), (0, -1), (1, 1)\\}$，仿射场系数 $\\alpha = 2$，$\\mathbf{g}_{\\mathrm{true}} = (3, -4)$，所有 $j$ 的权重 $w_{j} = 1$。\n- 用例 2（秩亏几何，二维，共线相邻点）：$d = 2$，$\\mathbf{x}_{0} = (0, 0)$，相邻点 $\\{(1, 0), (2, 0), (-1, 0)\\}$，仿射场系数 $\\alpha = 2$，$\\mathbf{g}_{\\mathrm{true}} = (3, -4)$，所有 $j$ 的权重 $w_{j} = 1$。\n- 用例 3（正常路径，三维，均匀权重）：$d = 3$，$\\mathbf{x}_{0} = (0, 0, 0)$，相邻点 $\\{(1, 0, 0), (0, 1, 0), (0, 0, 1), (-1, 1, 1)\\}$，仿射场系数 $\\alpha = -1$，$\\mathbf{g}_{\\mathrm{true}} = (0.5, 1.5, -2)$，所有 $j$ 的权重 $w_{j} = 1$。\n- 用例 4（近奇异几何，二维，均匀权重）：$d = 2$，$\\mathbf{x}_{0} = (0, 0)$，相邻点 $\\{(1, 0), (2, 10^{-8}), (-1, -10^{-8})\\}$，仿射场系数 $\\alpha = 2$，$\\mathbf{g}_{\\mathrm{true}} = (3, -4)$，所有 $j$ 的权重 $w_{j} = 1$。\n- 用例 5（正常路径，二维，非均匀正权重）：$d = 2$，$\\mathbf{x}_{0} = (0, 0)$，相邻点 $\\{(1, 0), (0, 1), (-1, 0), (0, -1), (1, 1)\\}$，仿射场系数 $\\alpha = 2$，$\\mathbf{g}_{\\mathrm{true}} = (3, -4)$，权重 $(1, 2, 3, 4, 5)$ 与相邻点顺序匹配。\n\n数值秩检测：令 $\\sigma_{\\max}$ 和 $\\sigma_{\\min}$ 分别表示加权设计矩阵的最大和最小奇异值。将数值秩计算为满足 $\\sigma \\ge r_{\\mathrm{tol}} \\, \\sigma_{\\max}$（其中 $r_{\\mathrm{tol}} = 10^{-12}$）的奇异值 $\\sigma$ 的数量。如果该数值秩小于 $d$，则宣布为秩亏。\n\n最终输出规范：对于从 1 到 5 的每个测试用例，按顺序将两项内容附加到输出列表中：首先是浮点误差范数 $\\lVert \\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}} \\rVert_{2}$，然后是一个指示是否秩亏的布尔值（使用语言原生的布尔值表示真和假）。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[e_{1},b_{1},e_{2},b_{2},\\dots,e_{5},b_{5}]$，其中 $e_{k}$ 是一个浮点值，$b_{k}$ 是一个布尔值。不允许有其他输出。",
            "solution": "该问题是为最小二乘梯度重构算法创建一个网格片检验。这涉及到验证对于一个给定的仿射标量场，只要采样点的几何排列是充分的，该算法就能精确地重构场的梯度。任务要求从第一性原理推导解决方案，进行数值实现，并诊断秩亏的情况。\n\n在 $d$ 维空间 $\\mathbb{R}^d$ 中，一个仿射标量场由以下函数给出：\n$$\nu(\\mathbf{x}) = \\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}\n$$\n其中 $\\alpha \\in \\mathbb{R}$ 是一个标量偏移，$\\mathbf{g}_{\\mathrm{true}} \\in \\mathbb{R}^d$ 是恒定的真实梯度向量，$\\mathbf{x} \\in \\mathbb{R}^d$ 是位置向量。\n\n对于一个中心点 $\\mathbf{x}_{0}$ 和一组 $m$ 个相邻点 $\\{\\mathbf{x}_{j}\\}_{j=1}^{m}$，标量场值的差异与位置差异呈线性关系：\n$$\n\\Delta u_{j} = u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0}) = (\\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}_{j}) - (\\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}_{0}) = \\mathbf{g}_{\\mathrm{true}}^{\\top} (\\mathbf{x}_{j} - \\mathbf{x}_{0})\n$$\n令 $\\Delta \\mathbf{x}_{j} = \\mathbf{x}_{j} - \\mathbf{x}_{0}$。该关系式为 $\\Delta u_{j} = \\mathbf{g}_{\\mathrm{true}}^{\\top} \\Delta \\mathbf{x}_{j}$。\n\n目标是仅使用已知的 $\\Delta u_{j}$ 和 $\\Delta \\mathbf{x}_{j}$ 值来重构梯度的近似值 $\\mathbf{g}_{\\mathrm{rec}}$。这被构建为一个加权最小二乘问题，我们寻求向量 $\\mathbf{g}$ 来最小化加权残差平方和：\n$$\nJ(\\mathbf{g}) = \\sum_{j=1}^{m} w_{j} \\left( (\\Delta \\mathbf{x}_{j})^{\\top} \\mathbf{g} - \\Delta u_{j} \\right)^{2}\n$$\n这里，$w_{j} > 0$ 是为每个相邻点 $j$ 给定的权重。\n\n为了解决这个最小化问题，我们首先用矩阵表示法来表达它。设 $A$ 为 $m \\times d$ 的设计矩阵，其中第 $j$ 行为 $(\\Delta \\mathbf{x}_{j})^{\\top}$。设 $\\mathbf{b}$ 为 $m \\times 1$ 的响应向量，其中第 $j$ 个元素为 $\\Delta u_{j}$。对于所有相邻点的方程组理想情况下是 $A\\mathbf{g} = \\mathbf{b}$。目标函数可以写成加权残差向量的平方范数。设 $W$ 是一个 $m \\times m$ 的对角矩阵，其对角线元素为 $W_{jj} = \\sqrt{w_j}$。目标函数是：\n$$\nJ(\\mathbf{g}) = \\| W(A\\mathbf{g} - \\mathbf{b}) \\|_2^2\n$$\n令 $\\tilde{A} = WA$ 和 $\\tilde{\\mathbf{b}} = W\\mathbf{b}$。问题就变为最小化 $J(\\mathbf{g}) = \\| \\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}} \\|_2^2$。\n我们展开平方范数：\n$$\nJ(\\mathbf{g}) = (\\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}})^{\\top}(\\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}}) = \\mathbf{g}^{\\top}\\tilde{A}^{\\top}\\tilde{A}\\mathbf{g} - 2\\mathbf{g}^{\\top}\\tilde{A}^{\\top}\\tilde{\\mathbf{b}} + \\tilde{\\mathbf{b}}^{\\top}\\tilde{\\mathbf{b}}\n$$\n为了找到最小值，我们对 $J(\\mathbf{g})$ 关于 $\\mathbf{g}$ 求梯度，并令其为零向量：\n$$\n\\nabla_{\\mathbf{g}} J(\\mathbf{g}) = 2\\tilde{A}^{\\top}\\tilde{A}\\mathbf{g} - 2\\tilde{A}^{\\top}\\tilde{\\mathbf{b}} = \\mathbf{0}\n$$\n这就得到了加权最小二乘问题的正规方程：\n$$\n(\\tilde{A}^{\\top}\\tilde{A})\\mathbf{g} = \\tilde{A}^{\\top}\\tilde{\\mathbf{b}}\n$$\n如果矩阵 $\\tilde{A}^{\\top}\\tilde{A}$ 是可逆的（即，如果 $\\tilde{A}$ 具有满列秩），则重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 存在唯一解。由于 $W$ 是可逆的，$\\tilde{A} = WA$ 的秩与 $A$ 的秩相同。因此，当且仅当位移向量集 $\\{\\Delta \\mathbf{x}_{j}\\}$ 能张成 $\\mathbb{R}^d$ 时，存在唯一解。\n\n如果 $\\tilde{A}$ 是病态的，直接求解正规方程可能数值不稳定。一种更鲁棒的方法是使用加权设计矩阵 $\\tilde{A}$ 的奇异值分解 (SVD)。设 $\\tilde{A}$ 的 SVD 为 $\\tilde{A} = U\\Sigma V^{\\top}$，其中 $U$ 是一个 $m \\times m$ 的正交矩阵，$\\Sigma$ 是一个包含奇异值 $\\sigma_i$ 的 $m \\times d$ 对角矩阵，而 $V$ 是一个 $d \\times d$ 的正交矩阵。最小二乘解由下式给出：\n$$\n\\mathbf{g}_{\\mathrm{rec}} = V \\Sigma^{+} U^{\\top} \\tilde{\\mathbf{b}}\n$$\n其中 $\\Sigma^{+}$ 是 $\\Sigma$ 的 Moore-Penrose 伪逆。这种方法即使对于病态或秩亏系统也是数值稳定的。\n\n$\\tilde{A}$ 的数值秩由其奇异值确定。给定相对容差 $r_{\\mathrm{tol}} = 10^{-12}$，秩是满足 $\\sigma_i \\geq r_{\\mathrm{tol}} \\sigma_{\\max}$ 的奇异值 $\\sigma_i$ 的数量，其中 $\\sigma_{\\max}$ 是最大奇异值。如果此数值秩小于空间维度 $d$，则系统被判定为秩亏。对于此类系统，几何采样不足以唯一确定梯度的所有分量。\n\n实现将通过迭代五个测试用例来进行。对每个用例：\n1. 构造位移向量 $\\Delta \\mathbf{x}_{j}$ 和标量差 $\\Delta u_j = \\mathbf{g}_{\\mathrm{true}}^{\\top} \\Delta \\mathbf{x}_j$。\n2. 形成设计矩阵 $A$、响应向量 $\\mathbf{b}$ 和加权矩阵 $W$。\n3. 计算加权矩阵 $\\tilde{A} = WA$ 和向量 $\\tilde{\\mathbf{b}} = W\\mathbf{b}$。\n4. 计算 $\\tilde{A}$ 的 SVD 以确定其奇异值和数值秩。如果秩小于 $d$，则设置一个布尔标志。\n5. 使用一个内部采用 SVD 的稳定最小二乘求解器，通过求解 $\\tilde{A}\\mathbf{g} = \\tilde{\\mathbf{b}}$ 来找到 $\\mathbf{g}_{\\mathrm{rec}}$。\n6. 计算欧几里得误差范数 $\\|\\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}}\\|_2$。\n\n对于满秩的测试用例，由于响应数据 $\\Delta u_j$ 是从仿射场精确推导的，重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 应该在浮点精度范围内等于 $\\mathbf{g}_{\\mathrm{true}}$。对于秩亏情况，重构将无法恢复 $\\mathbf{g}_{\\mathrm{true}}$，导致非零误差。对于近奇异情况，系统技术上是满秩的，但数值舍入误差可能会被放大，导致一个虽小但非零的重构误差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to execute the least-squares gradient reconstruction patch test\n    for all specified test cases.\n    \"\"\"\n    # Define the test cases as a list of dictionaries.\n    test_cases = [\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [0., 1.], [-1., 0.], [0., -1.], [1., 1.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [2., 0.], [-1., 0.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1.])\n        },\n        {\n            \"d\": 3, \"x0\": np.array([0., 0., 0.]),\n            \"neighbors\": np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.], [-1., 1., 1.]]),\n            \"alpha\": -1., \"g_true\": np.array([0.5, 1.5, -2.]),\n            \"weights\": np.array([1., 1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [2., 1e-8], [-1., -1e-8]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [0., 1.], [-1., 0.], [0., -1.], [1., 1.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 2., 3., 4., 5.])\n        }\n    ]\n\n    r_tol = 1e-12\n    results = []\n\n    for case in test_cases:\n        d = case[\"d\"]\n        x0 = case[\"x0\"]\n        neighbors = case[\"neighbors\"]\n        g_true = case[\"g_true\"]\n        weights = case[\"weights\"]\n        # alpha is not needed for gradient reconstruction, as it cancels out.\n        # u(x) = alpha + g_true.T @ x\n\n        # 1. Construct design offsets and response differences.\n        # delta_x_j = x_j - x_0\n        # A is the design matrix, with rows being delta_x_j.T\n        A = neighbors - x0\n        \n        # delta_u_j = u(x_j) - u(x_0) = g_true.T @ (x_j - x_0)\n        # b is the response vector with elements delta_u_j\n        b = A @ g_true\n\n        # 2. Formulate the weighted least-squares problem.\n        # Create diagonal weight matrix W with sqrt(w_j) on diagonal\n        W = np.diag(np.sqrt(weights))\n        \n        # Weighted design matrix and response vector\n        A_tilde = W @ A\n        b_tilde = W @ b\n\n        # 3. Determine the numerical rank of the weighted design matrix.\n        # Compute singular values of A_tilde\n        try:\n            singular_values = np.linalg.svd(A_tilde, compute_uv=False)\n            s_max = singular_values[0] if len(singular_values) > 0 else 0\n            \n            # Compute numerical rank based on the tolerance\n            numerical_rank = np.sum(singular_values >= r_tol * s_max)\n            is_rank_deficient = numerical_rank  d\n        except np.linalg.LinAlgError:\n            # In an empty or otherwise invalid case\n            numerical_rank = 0\n            is_rank_deficient = True\n            \n        # 4. Solve for the reconstructed gradient and compute the error.\n        # Use a numerically stable least-squares solver\n        g_rec, _, _, _ = np.linalg.lstsq(A_tilde, b_tilde, rcond=None)\n        \n        # Compute the Euclidean error norm\n        error_norm = np.linalg.norm(g_rec - g_true)\n        \n        # 5. Append results for this case to the list.\n        results.append(error_norm)\n        results.append(is_rank_deficient)\n\n    # Final print statement in the exact required format.\n    # str(True) -> 'True', str(False) -> 'False'\n    # The problem asks for \"language-native boolean values\", which these are.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在使用简单的仿射场验证了您的程序实现之后，下一步是在一个更真实的非线性函数上评估其精度。此练习使用“制造解法”（method of manufactured solutions），即利用一个已知的平滑函数来量化重构误差。您将探索加权最小二乘法的精度如何受两个关键因素影响：邻近单元的几何排列（即模板）和加权函数的选择。这将为您提供关于在真实CFD模拟中网格质量和数值参数如何影响求解的实用见解。",
            "id": "3972721",
            "problem": "考虑一个典型的航空航天计算流体动力学（CFD）中的二维、以单元为中心的有限体积重构问题，其目标是使用相邻单元的值来估计给定单元中心的平滑标量场的梯度。设该标量场由一个足够光滑的构造解定义，其精确梯度可以解析计算。估算必须从第一性原理出发，使用以下基本事实：梯度的定义，即光滑函数 Taylor 展开中的线性项；以及来自微积分和线性代数的最小二乘法原理，该原理通过最小化加权残差平方和来拟合参数。\n\n设构造解为标量场，由下式给出\n$$\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta x y,$$\n常数设置为 $\\,\\alpha = 1.6\\,$, $\\,\\beta = 0.5\\,$, $\\,\\gamma = 0.9\\,$, $\\,\\delta = 0.3\\,$. 重构点（单元中心）位于 $(x_0,y_0)$，其中 $\\,x_0 = 0.27\\,$ 且 $\\,y_0 = -0.19\\,$. 设 $\\,h = 0.05\\,$ 为特征邻居偏移尺度。所有量均为无量纲，不涉及物理单位。角度必须以弧度解释。\n\n为了估计点 $(x_0,y_0)$ 处的梯度，通过一个以 $(x_0,y_0)$ 为中心的线性函数来近似 $\\,\\phi\\,$ 的局部行为，并通过在给定的邻居偏移模板上最小化加权残差平方和来确定梯度向量 $\\,\\nabla \\phi(x_0,y_0)\\,$。对于每个邻居偏移 $\\,(d_{x,i}, d_{y,i})\\,$，邻居坐标为 $\\,(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$，对应的标量值为 $\\,\\phi(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$。对于一个候选梯度 $\\,\\mathbf{g} = (g_x,g_y)\\,$，其残差是 $\\,\\phi(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$ 与线性预测 $\\,\\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i}\\,$ 之间的差值。$\\,\\mathbf{g}\\,$ 的加权最小二乘估计被定义为残差平方和的最小化子，其中每个邻居都被赋予了权重 $\\,w_i \\ge 0\\,$。您必须通用地处理此问题，除了给定的偏移和权重外，不假设任何特殊结构。\n\n您必须在使用相同构造解的情况下，比较不同模板和权重下最小二乘梯度的估计误差。误差必须量化为数值梯度与在 $(x_0,y_0)$ 处的精确解析梯度之差的欧几里得范数，即\n$$E = \\left\\| \\nabla \\phi_{\\text{numerical}}(x_0,y_0) - \\nabla \\phi_{\\text{exact}}(x_0,y_0) \\right\\|_2.$$\n\n使用以下三个邻居偏移模板，它们代表了实践中遇到的不同几何构型：\n\n模板 $\\,\\mathcal{S}_1\\,$（八个邻居组成的近似各向同性环）：\n$$\\{(h,0),(-h,0),(0,h),(0,-h),(h,h),(-h,h),(h,-h),(-h,-h)\\}.$$\n\n模板 $\\,\\mathcal{S}_2\\,$（强 $\\,x\\,$ 偏置，带轻微 $\\,y\\,$ 抖动以避免精确共线性，八个邻居）：\n$$\\{(-3h,0.002h),(-2h,-0.002h),(-h,0.001h),(h,-0.001h),(2h,0.002h),(3h,-0.002h),(-0.5h,0.0015h),(0.5h,-0.0015h)\\}.$$\n\n模板 $\\,\\mathcal{S}_3\\,$（沿斜向的近似共线邻居，带小角度扰动，八个邻居）：\n设 $\\,\\theta = \\pi/6\\,$ 且扰动 $\\,\\{\\varepsilon_k\\} = \\{0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004\\}\\,$。设半径 $\\,\\{r_k\\} = \\{h,1.25h,1.5h,1.75h,2h,2.25h,2.5h,2.75h\\}\\,$。偏移量定义为\n$$d_{x,k} = r_k \\cos(\\theta + \\varepsilon_k), \\quad d_{y,k} = r_k \\sin(\\theta + \\varepsilon_k), \\quad k = 1,\\dots,8.$$\n\n对于每个模板，使用以下三种作用于残差的权重策略中的每一种来计算最小二乘梯度：\n\n权重 $\\,\\mathcal{W}_1\\,$（均匀权重）：对所有邻居 $\\,w_i = 1\\,$。\n\n权重 $\\,\\mathcal{W}_2\\,$（距离倒数权重）：$\\,w_i = 1 / \\sqrt{d_{x,i}^2 + d_{y,i}^2}\\,$。\n\n权重 $\\,\\mathcal{W}_3\\,$（距离平方倒数权重）：$\\,w_i = 1 / (d_{x,i}^2 + d_{y,i}^2)\\,$。\n\n对于每个模板-权重对，通过加权最小二乘重构评估数值梯度，并计算如上定义的误差 $\\,E\\,$。构造解在中心点的精确梯度必须从 $\\,\\phi\\,$ 的定义中解析地计算。\n\n测试套件和答案规格：\n对三个模板 $\\,\\mathcal{S}_1\\,$, $\\,\\mathcal{S}_2\\,$, $\\,\\mathcal{S}_3\\,$ 和三种权重策略 $\\,\\mathcal{W}_1\\,$, $\\,\\mathcal{W}_2\\,$, $\\,\\mathcal{W}_3\\,$ 进行计算，产生 $\\,9\\,$ 个误差值。您的程序应生成单行输出，其中包含一个逗号分隔的列表形式的结果，结果用方括号括起来，并按模板分组。每个内部列表对应一个模板，并且必须按 $\\,\\mathcal{W}_1\\,$, $\\,\\mathcal{W}_2\\,$, $\\,\\mathcal{W}_3\\,$ 的顺序包含这三种权重的三个误差值。最终输出格式必须是\n$$[\\,[E_{1,1},E_{1,2},E_{1,3}],\\,[E_{2,1},E_{2,2},E_{2,3}],\\,[E_{3,1},E_{3,2},E_{3,3}]\\,],$$\n其中 $\\,E_{s,w}\\,$ 表示模板 $\\,s\\,$ 和权重 $\\,w\\,$ 的误差。不应打印任何附加文本。",
            "solution": "用户提供了一个需要验证的问题陈述。\n\n### 第一步：提取已知条件\n- **标量场：** $\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta x y$\n- **常数：** $\\alpha = 1.6$, $\\beta = 0.5$, $\\gamma = 0.9$, $\\delta = 0.3$。\n- **重构点：** $(x_0,y_0) = (0.27, -0.19)$。\n- **特征尺度：** $h = 0.05$。\n- **目标：** 使用加权最小二乘法估计梯度 $\\nabla \\phi(x_0,y_0)$。\n- **近似：** 线性函数 $\\phi(x_0 + d_{x,i}, y_0 + d_{y,i}) \\approx \\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i}$。\n- **残差：** $R_i = \\phi(x_0 + d_{x,i}, y_0 + d_{y,i}) - (\\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i})$。\n- **最小化目标：** 加权残差平方和 $\\sum_i w_i R_i^2$。\n- **误差度量：** 欧几里得范数 $E = \\left\\| \\nabla \\phi_{\\text{numerical}}(x_0,y_0) - \\nabla \\phi_{\\text{exact}}(x_0,y_0) \\right\\|_2$。\n- **模板：**\n    - $\\mathcal{S}_1$: $\\{(h,0),(-h,0),(0,h),(0,-h),(h,h),(-h,h),(h,-h),(-h,-h)\\}$.\n    - $\\mathcal{S}_2$: $\\{(-3h,0.002h),(-2h,-0.002h),(-h,0.001h),(h,-0.001h),(2h,0.002h),(3h,-0.002h),(-0.5h,0.0015h),(0.5h,-0.0015h)\\}$.\n    - $\\mathcal{S}_3$: 偏移量 $(d_{x,k}, d_{y,k})$ 由 $d_{x,k} = r_k \\cos(\\theta + \\varepsilon_k), d_{y,k} = r_k \\sin(\\theta + \\varepsilon_k)$ 定义，其中 $k = 1,\\dots,8$, $\\theta = \\pi/6$, 半径 $\\{r_k\\} = h \\cdot \\{1,1.25,1.5,1.75,2,2.25,2.5,2.75\\}$, 扰动 $\\{\\varepsilon_k\\} = \\{0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004\\}$。\n- **权重策略：**\n    - $\\mathcal{W}_1$: $w_i = 1$。\n    - $\\mathcal{W}_2$: $w_i = 1 / \\sqrt{d_{x,i}^2 + d_{y,i}^2}$。\n    - $\\mathcal{W}_3$: $w_i = 1 / (d_{x,i}^2 + d_{y,i}^2)$。\n- **要求输出：** 对应于每个模板-权重对的一个 $3 \\times 3$ 的误差值集合，格式为列表的列表。\n\n### 第二步：使用提取的已知条件进行验证\n该问题具有科学依据，是计算科学与工程中应用的一种标准数值方法（最小二乘梯度重构），尤其是在用于CFD的有限体积法中。问题是适定的；给定的模板旨在避免会导致所得线性系统奇异的共线性问题，从而确保存在唯一解。问题是客观的，所有术语、常数和步骤都经过数学上明确的定义。问题是自包含的，提供了所有必要信息。问题并非无足轻重，因为它需要推导和实现一个著名的数值算法，并理解模板几何形状和权重如何影响精度。问题可通过直接计算进行验证。\n\n### 第三步：结论与行动\n问题有效。将提供详细的解决方案。\n\n---\n\n该问题要求根据标量场在一组邻近位置的值，来估计该场在单元中心点 $(x_0, y_0)$ 的梯度 $\\nabla\\phi$。这是有限体积法中的一个经典重构问题。所选的方法是最小二乘法原理，该方法旨在找到能够在线性意义上最佳拟合来自邻居数据的梯度分量。\n\n设 $(x_0, y_0)$ 处的未知梯度向量表示为 $\\mathbf{g} = (g_x, g_y)$。根据 Taylor 定理，对于一个光滑函数 $\\phi(x,y)$，其在邻近点 $(x_i, y_i)$ 的值可以通过在 $(x_0, y_0)$ 附近进行线性展开来近似：\n$$ \\phi(x_i, y_i) \\approx \\phi(x_0, y_0) + \\left. \\frac{\\partial\\phi}{\\partial x} \\right|_{(x_0,y_0)} (x_i - x_0) + \\left. \\frac{\\partial\\phi}{\\partial y} \\right|_{(x_0,y_0)} (y_i - y_0) $$\n设 $\\mathbf{d}_i = (d_{x,i}, d_{y,i}) = (x_i-x_0, y_i-y_0)$ 为从中心点到第 $i$ 个邻居的偏移向量。使用未知梯度 $\\mathbf{g}$，该近似可以写为：\n$$ \\phi(x_i, y_i) \\approx \\phi(x_0, y_0) + g_x d_{x,i} + g_y d_{y,i} $$\n令 $\\Delta\\phi_i = \\phi(x_i, y_i) - \\phi(x_0, y_0)$，则线性模型为 $\\Delta\\phi_i \\approx g_x d_{x,i} + g_y d_{y,i}$。对于给定的候选梯度 $\\mathbf{g}$，第 $i$ 个邻居的残差或误差为：\n$$ R_i(\\mathbf{g}) = \\Delta\\phi_i - (g_x d_{x,i} + g_y d_{y,i}) $$\n加权最小二乘法旨在找到梯度 $\\mathbf{g}$，以最小化模板中所有 $N$ 个邻居的加权残差平方和：\n$$ J(\\mathbf{g}) = J(g_x, g_y) = \\sum_{i=1}^{N} w_i R_i^2 = \\sum_{i=1}^{N} w_i \\left( \\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i} \\right)^2 $$\n为了找到最小值，我们求 $J$ 关于 $g_x$ 和 $g_y$ 的偏导数并令其为零。\n$$ \\frac{\\partial J}{\\partial g_x} = \\sum_{i=1}^{N} 2 w_i (\\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i})(-d_{x,i}) = 0 $$\n$$ \\frac{\\partial J}{\\partial g_y} = \\sum_{i=1}^{N} 2 w_i (\\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i})(-d_{y,i}) = 0 $$\n重新整理这两个方程，我们得到一个二元线性方程组，称为正规方程：\n$$ \\left( \\sum_{i=1}^{N} w_i d_{x,i}^2 \\right) g_x + \\left( \\sum_{i=1}^{N} w_i d_{x,i} d_{y,i} \\right) g_y = \\sum_{i=1}^{N} w_i \\Delta\\phi_i d_{x,i} $$\n$$ \\left( \\sum_{i=1}^{N} w_i d_{x,i} d_{y,i} \\right) g_x + \\left( \\sum_{i=1}^{N} w_i d_{y,i}^2 \\right) g_y = \\sum_{i=1}^{N} w_i \\Delta\\phi_i d_{y,i} $$\n该系统可以写成矩阵形式 $A\\mathbf{g} = \\mathbf{b}$，其中 $\\mathbf{g} = \\begin{pmatrix} g_x \\\\ g_y \\end{pmatrix}$，并且\n$$ A = \\begin{pmatrix} \\sum w_i d_{x,i}^2  \\sum w_i d_{x,i} d_{y,i} \\\\ \\sum w_i d_{x,i} d_{y,i}  \\sum w_i d_{y,i}^2 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} \\sum w_i \\Delta\\phi_i d_{x,i} \\\\ \\sum w_i \\Delta\\phi_i d_{y,i} \\end{pmatrix} $$\n矩阵 $A$ 是一个对称的 $2 \\times 2$ 矩阵。只要邻居点不都共线，$A$ 就是可逆的，梯度的最小二乘估计由 $\\mathbf{g}_{\\text{numerical}} = A^{-1}\\mathbf{b}$ 给出。\n\n为了评估此数值梯度的准确性，我们将其与从构造解 $\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta xy$ 推导出的精确梯度进行比较。精确的偏导数为：\n$$ \\frac{\\partial \\phi}{\\partial x} = \\alpha \\cos(\\alpha x) + \\delta y $$\n$$ \\frac{\\partial \\phi}{\\partial y} = -\\beta\\gamma \\sin(\\gamma y) + \\delta x $$\n我们使用指定的常数 $\\alpha = 1.6$, $\\beta = 0.5$, $\\gamma = 0.9$, $\\delta = 0.3$ 在中心点 $(x_0, y_0) = (0.27, -0.19)$ 处计算这些表达式，以获得 $\\nabla\\phi_{\\text{exact}}(x_0, y_0)$。\n\n对于 $9$ 个测试用例（3个模板 $\\times$ 3个权重）中的每一个，其步骤如下：\n1.  为给定的模板定义邻居偏移向量集合 $\\{ \\mathbf{d}_i \\}$。\n2.  计算中心点的标量值 $\\phi_0 = \\phi(x_0, y_0)$。\n3.  对于每个邻居 $i$，计算其坐标 $(x_i, y_i) = (x_0+d_{x,i}, y_0+d_{y,i})$ 和标量值 $\\phi_i = \\phi(x_i, y_i)$，然后求出 $\\Delta\\phi_i = \\phi_i - \\phi_0$。\n4.  根据指定的权重策略确定权重集合 $\\{ w_i \\}$。\n5.  通过对所有邻居求和来构造矩阵 $A$ 和向量 $\\mathbf{b}$ 的元素。\n6.  求解线性系统 $A\\mathbf{g} = \\mathbf{b}$ 以找到数值梯度 $\\mathbf{g}_{\\text{numerical}}$。\n7.  使用差值的欧几里得范数计算误差 $E$：$E = \\left\\| \\mathbf{g}_{\\text{numerical}} - \\nabla\\phi_{\\text{exact}}(x_0, y_0) \\right\\|_2$。\n\n对每个模板和权重的组合实施此系统性过程，以生成所需的误差值集合。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the least-squares gradient estimation error for a manufactured solution\n    across different stencils and weighting strategies.\n    \"\"\"\n    # Define constants and problem parameters\n    alpha = 1.6\n    beta = 0.5\n    gamma = 0.9\n    delta = 0.3\n    x0, y0 = 0.27, -0.19\n    h = 0.05\n\n    def phi(x, y):\n        \"\"\"The manufactured scalar field solution.\"\"\"\n        return np.sin(alpha * x) + beta * np.cos(gamma * y) + delta * x * y\n\n    def grad_phi_exact(x, y):\n        \"\"\"The exact analytical gradient of the scalar field.\"\"\"\n        gx = alpha * np.cos(alpha * x) + delta * y\n        gy = -beta * gamma * np.sin(gamma * y) + delta * x\n        return np.array([gx, gy])\n\n    def define_stencils(h_val):\n        \"\"\"Defines the three neighbor offset stencils.\"\"\"\n        # Stencil S1: Isotropic ring\n        s1 = np.array([\n            [h_val, 0], [-h_val, 0], [0, h_val], [0, -h_val],\n            [h_val, h_val], [-h_val, h_val], [h_val, -h_val], [-h_val, -h_val]\n        ])\n\n        # Stencil S2: Strongly x-biased\n        s2 = h_val * np.array([\n            [-3.0, 0.002], [-2.0, -0.002], [-1.0, 0.001],\n            [1.0, -0.001], [2.0, 0.002], [3.0, -0.002],\n            [-0.5, 0.0015], [0.5, -0.0015]\n        ])\n\n        # Stencil S3: Nearly collinear along an oblique direction\n        theta = np.pi / 6.0\n        epsilons = np.array([0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004])\n        radii = h_val * np.array([1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75])\n        angles = theta + epsilons\n        dx_s3 = radii * np.cos(angles)\n        dy_s3 = radii * np.sin(angles)\n        s3 = np.column_stack((dx_s3, dy_s3))\n        \n        return [s1, s2, s3]\n\n    def get_weights(offsets, strategy_id):\n        \"\"\"Computes weights based on the specified strategy.\"\"\"\n        if strategy_id == 1:  # W1: Uniform\n            return np.ones(len(offsets))\n        \n        distances_sq = np.sum(offsets**2, axis=1)\n        \n        if strategy_id == 2:  # W2: Inverse-distance\n            return 1.0 / np.sqrt(distances_sq)\n        elif strategy_id == 3:  # W3: Inverse-square-distance\n            return 1.0 / distances_sq\n        else:\n            raise ValueError(\"Invalid weighting strategy ID.\")\n\n    def compute_gradient_lsq(offsets, weights, phi_0):\n        \"\"\"\n        Computes the numerical gradient using weighted least squares.\n        \n        Args:\n            offsets (np.ndarray): Array of neighbor offset vectors.\n            weights (np.ndarray): Array of weights for each neighbor.\n            phi_0 (float): Scalar value at the central point (x0, y0).\n\n        Returns:\n            np.ndarray: The computed numerical gradient vector [gx, gy].\n        \"\"\"\n        neighbor_coords = np.array([x0, y0]) + offsets\n        phi_neighbors = phi(neighbor_coords[:, 0], neighbor_coords[:, 1])\n        delta_phi = phi_neighbors - phi_0\n        \n        dx = offsets[:, 0]\n        dy = offsets[:, 1]\n        \n        # Assemble the normal equation matrix A\n        A11 = np.sum(weights * dx**2)\n        A12 = np.sum(weights * dx * dy)\n        A22 = np.sum(weights * dy**2)\n        A = np.array([[A11, A12], [A12, A22]])\n        \n        # Assemble the right-hand side vector b\n        b1 = np.sum(weights * delta_phi * dx)\n        b2 = np.sum(weights * delta_phi * dy)\n        b = np.array([b1, b2])\n\n        # Solve the linear system A*g = b for the gradient g\n        grad_num = np.linalg.solve(A, b)\n        \n        return grad_num\n\n    # Main execution logic\n    stencils = define_stencils(h)\n    exact_grad = grad_phi_exact(x0, y0)\n    phi0_val = phi(x0, y0)\n    \n    all_errors = []\n    \n    for stencil in stencils:\n        stencil_errors = []\n        for weight_strategy_id in [1, 2, 3]:\n            # Calculate weights for the current strategy\n            current_weights = get_weights(stencil, weight_strategy_id)\n            \n            # Compute numerical gradient\n            numerical_grad = compute_gradient_lsq(stencil, current_weights, phi0_val)\n            \n            # Compute and store the error\n            error = np.linalg.norm(numerical_grad - exact_grad)\n            stencil_errors.append(error)\n        \n        all_errors.append(stencil_errors)\n\n    # Format the final output string as specified\n    inner_strings = [f\"[{','.join(f'{err:.16e}' for err in sublist)}]\" for sublist in all_errors]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在实际的CFD应用中，网格通常是不均匀的，尤其是在边界附近。靠近壁面时，邻近单元的模板会变成单侧的，这可能导致最小二乘问题的系统变得病态甚至奇异。此练习将从数值实现转向一个更具针对性的解析研究，您将通过推导系统矩阵的奇异值来量化这种病态性。随后，您将看到通过增加额外的“第二环”邻居来增强模板，如何显著提高重构的数值稳定性。",
            "id": "3972774",
            "problem": "在外部空气动力学计算中，采用二维单元中心有限体积法来重构 $y=0$ 处平面无滑移壁面附近的标量场梯度。该重构使用非加权最小二乘法(LS)，基于线性近似 $\\,\\phi_{j}-\\phi_{0}\\approx \\nabla \\phi \\cdot \\boldsymbol{r}_{j}\\,$，其中 $\\boldsymbol{r}_{j}=(x_{j},y_{j})$ 是从目标单元中心到相邻单元中心的位移向量。LS设计矩阵 $\\boldsymbol{A}\\in \\mathbb{R}^{N\\times 2}$ 的行是 $\\boldsymbol{r}_{j}^{\\top}$，重构的条件状况（及其对边界引起的秩亏的敏感性）由 $\\boldsymbol{A}$ 的最小奇异值来衡量。奇异值定义为 $\\boldsymbol{A}^{\\top}\\boldsymbol{A}$ 的特征值的非负平方根。\n\n考虑一个邻近边界的单元，其中心位于原点 $\\boldsymbol{0}=(0,0)$。由于壁面的存在，第一环相邻单元的中心主要分布在切向方向。用以下第一环相邻位移的集合来对此进行建模：\n- $\\boldsymbol{r}_{1}=(-h,0)$，\n- $\\boldsymbol{r}_{2}=(h,0)$，\n- $\\boldsymbol{r}_{3}=(-2h,0)$，\n- $\\boldsymbol{r}_{4}=(2h,0)$，\n- $\\boldsymbol{r}_{5}=(0,\\varepsilon h)$，\n\n其中 $h>0$ 是一个特征网格间距，$0  \\varepsilon \\ll 1$ 代表第一环模板在壁面法向上的微弱延伸范围。为缓解病态问题，使用更深入内部区域的第二环相邻点来增强模板：\n- $\\boldsymbol{r}_{6}=(-h,h)$，\n- $\\boldsymbol{r}_{7}=(h,h)$。\n\n从非加权最小二乘法 (LS) 的定义以及 LS 设计矩阵 $\\boldsymbol{A}$ 的奇异值是 $\\boldsymbol{A}^{\\top}\\boldsymbol{A}$ 的特征值的平方根这一定义出发，推导仅使用第一环模板和使用包含第二环相邻点的增强模板时的最小奇异值。将改进因子定义为比率\n$$\\rho \\equiv \\frac{\\sigma_{\\min}^{\\text{aug}}}{\\sigma_{\\min}^{\\text{base}}},$$\n其中 $\\sigma_{\\min}^{\\text{base}}$ 和 $\\sigma_{\\min}^{\\text{aug}}$ 分别表示增强前和增强后的最小奇异值。\n\n计算当 $\\varepsilon=0.1$ 时 $\\rho$ 的值，并将您的答案四舍五入至四位有效数字。提供一个无单位的 $\\rho$ 数值。",
            "solution": "问题要求计算改进因子 $\\rho$，该因子与最小二乘 (LS) 梯度重构模板的条件数有关。条件数由 LS 设计矩阵 $\\boldsymbol{A}$ 的最小奇异值 $\\sigma_{\\min}$ 来衡量。$\\boldsymbol{A}$ 的奇异值定义为矩阵 $\\boldsymbol{A}^{\\top}\\boldsymbol{A}$ 的特征值的非负平方根。LS 设计矩阵 $\\boldsymbol{A}$ 是通过将从目标单元中心到其相邻点的位移向量 $\\boldsymbol{r}_j = (x_j, y_j)$ 作为行向量堆叠而成的，即 $\\boldsymbol{A}$ 的第 $j$ 行为 $\\boldsymbol{r}_j^{\\top}$。矩阵 $\\boldsymbol{A}^{\\top}\\boldsymbol{A}$ 可以表示为位移向量外积的和：\n$$ \\boldsymbol{A}^{\\top}\\boldsymbol{A} = \\sum_{j=1}^{N} \\boldsymbol{r}_j \\boldsymbol{r}_j^{\\top} = \\sum_{j=1}^{N} \\begin{pmatrix} x_j \\\\ y_j \\end{pmatrix} \\begin{pmatrix} x_j  y_j \\end{pmatrix} = \\begin{pmatrix} \\sum_{j=1}^{N} x_j^2  \\sum_{j=1}^{N} x_j y_j \\\\ \\sum_{j=1}^{N} x_j y_j  \\sum_{j=1}^{N} y_j^2 \\end{pmatrix} $$\n我们将首先分析基础情况（仅有第一环相邻点），然后分析增强情况（有第一和第二环相邻点）。\n\n首先，考虑基础模板，它由 $N=5$ 个相邻点组成。位移向量如下：\n$\\boldsymbol{r}_{1}=(-h,0)$, $\\boldsymbol{r}_{2}=(h,0)$, $\\boldsymbol{r}_{3}=(-2h,0)$, $\\boldsymbol{r}_{4}=(2h,0)$, and $\\boldsymbol{r}_{5}=(0,\\varepsilon h)$。\n基础情况的设计矩阵 $\\boldsymbol{A}_{\\text{base}}$ 是一个 $5 \\times 2$ 的矩阵：\n$$ \\boldsymbol{A}_{\\text{base}} = \\begin{pmatrix} -h  0 \\\\ h  0 \\\\ -2h  0 \\\\ 2h  0 \\\\ 0  \\varepsilon h \\end{pmatrix} $$\n我们通过计算向量各分量的平方和与乘积和来计算矩阵 $\\boldsymbol{A}_{\\text{base}}^{\\top}\\boldsymbol{A}_{\\text{base}}$：\n$$ \\sum_{j=1}^{5} x_j^2 = (-h)^2 + (h)^2 + (-2h)^2 + (2h)^2 + (0)^2 = h^2 + h^2 + 4h^2 + 4h^2 = 10h^2 $$\n$$ \\sum_{j=1}^{5} y_j^2 = (0)^2 + (0)^2 + (0)^2 + (0)^2 + (\\varepsilon h)^2 = \\varepsilon^2 h^2 $$\n$$ \\sum_{j=1}^{5} x_j y_j = (-h)(0) + (h)(0) + (-2h)(0) + (2h)(0) + (0)(\\varepsilon h) = 0 $$\n因此，该矩阵为：\n$$ \\boldsymbol{A}_{\\text{base}}^{\\top}\\boldsymbol{A}_{\\text{base}} = \\begin{pmatrix} 10h^2  0 \\\\ 0  \\varepsilon^2 h^2 \\end{pmatrix} $$\n由于这是一个对角矩阵，其特征值就是其对角线元素：$\\lambda_1 = 10h^2$ 和 $\\lambda_2 = \\varepsilon^2 h^2$。奇异值是这些特征值的平方根：$\\sigma_1 = \\sqrt{10}h$ 和 $\\sigma_2 = \\varepsilon h$（因为 $h>0$ 且 $\\varepsilon>0$）。鉴于 $0  \\varepsilon \\ll 1$，显然有 $\\varepsilon  \\sqrt{10}$。因此，基础情况的最小奇异值是：\n$$ \\sigma_{\\min}^{\\text{base}} = \\varepsilon h $$\n\n接下来，考虑增强模板，它在基础模板的基础上增加了两个第二环相邻点 $\\boldsymbol{r}_{6}=(-h,h)$ 和 $\\boldsymbol{r}_{7}=(h,h)$，总计 $N=7$ 个相邻点。我们为矩阵 $\\boldsymbol{A}_{\\text{aug}}^{\\top}\\boldsymbol{A}_{\\text{aug}}$ 计算新的求和项。\n$$ \\sum_{j=1}^{7} x_j^2 = \\left( \\sum_{j=1}^{5} x_j^2 \\right) + x_6^2 + x_7^2 = 10h^2 + (-h)^2 + (h)^2 = 10h^2 + h^2 + h^2 = 12h^2 $$\n$$ \\sum_{j=1}^{7} y_j^2 = \\left( \\sum_{j=1}^{5} y_j^2 \\right) + y_6^2 + y_7^2 = \\varepsilon^2 h^2 + (h)^2 + (h)^2 = \\varepsilon^2 h^2 + 2h^2 = (2+\\varepsilon^2)h^2 $$\n$$ \\sum_{j=1}^{7} x_j y_j = \\left( \\sum_{j=1}^{5} x_j y_j \\right) + x_6 y_6 + x_7 y_7 = 0 + (-h)(h) + (h)(h) = 0 - h^2 + h^2 = 0 $$\n增强情况的矩阵是：\n$$ \\boldsymbol{A}_{\\text{aug}}^{\\top}\\boldsymbol{A}_{\\text{aug}} = \\begin{pmatrix} 12h^2  0 \\\\ 0  (2+\\varepsilon^2)h^2 \\end{pmatrix} $$\n这同样是一个对角矩阵，其特征值为 $\\lambda_1^{\\text{aug}} = 12h^2$ 和 $\\lambda_2^{\\text{aug}} = (2+\\varepsilon^2)h^2$。对应的奇异值为 $\\sigma_1^{\\text{aug}} = \\sqrt{12}h = 2\\sqrt{3}h$ 和 $\\sigma_2^{\\text{aug}} = \\sqrt{2+\\varepsilon^2}h$。为了找到最小奇异值，我们比较 $12$ 和 $2+\\varepsilon^2$。由于 $\\varepsilon \\ll 1$，$\\varepsilon^2$ 非常小，因此 $2+\\varepsilon^2$ 接近 2。由于 $2  12$，较小的特征值是 $(2+\\varepsilon^2)h^2$。增强情况的最小奇异值是：\n$$ \\sigma_{\\min}^{\\text{aug}} = \\sqrt{2+\\varepsilon^2}h $$\n\n改进因子 $\\rho$ 定义为最小奇异值的比率。\n$$ \\rho = \\frac{\\sigma_{\\min}^{\\text{aug}}}{\\sigma_{\\min}^{\\text{base}}} = \\frac{\\sqrt{2+\\varepsilon^2}h}{\\varepsilon h} = \\frac{\\sqrt{2+\\varepsilon^2}}{\\varepsilon} $$\n题目要求我们计算当 $\\varepsilon=0.1$ 时的值。\n$$ \\rho = \\frac{\\sqrt{2+(0.1)^2}}{0.1} = \\frac{\\sqrt{2+0.01}}{0.1} = \\frac{\\sqrt{2.01}}{0.1} $$\n现在，我们计算数值：\n$$ \\sqrt{2.01} \\approx 1.4177446878... $$\n$$ \\rho \\approx \\frac{1.4177446878}{0.1} = 14.177446878 $$\n将结果四舍五入到四位有效数字，得到 $14.18$。",
            "answer": "$$\n\\boxed{14.18}\n$$"
        }
    ]
}