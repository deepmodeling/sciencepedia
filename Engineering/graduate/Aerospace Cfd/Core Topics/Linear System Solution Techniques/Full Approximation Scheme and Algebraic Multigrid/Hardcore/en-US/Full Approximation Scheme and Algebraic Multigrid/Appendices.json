{
    "hands_on_practices": [
        {
            "introduction": "Local Fourier Analysis (LFA) is an indispensable tool for understanding and designing efficient multigrid smoothers. This first practice provides a foundational exercise in applying LFA to the Red-Black Gauss-Seidel (RBGS) method for the isotropic Poisson problem, a cornerstone of many CFD solvers. By deriving the smoothing factor, you will quantify the smoother's ability to attenuate high-frequency error components, which is the essential role of relaxation in any multigrid cycle. ",
            "id": "3961529",
            "problem": "Consider the pressure Poisson subproblem that arises in projection methods for incompressible flow within aerospace computational fluid dynamics (CFD). On a uniform two-dimensional Cartesian mesh with grid spacing $h$, discretize the negative Laplacian using the standard five-point stencil to obtain a linear system $A_h u = b$ with $$\\left(A_h u\\right)_{i,j} = \\frac{1}{h^2}\\left(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\\right).$$ In an Algebraic Multigrid (AMG) framework embedded within the Full Approximation Scheme (FAS) for nonlinear problems, Red–Black Gauss–Seidel (RBGS) is used as a pre-relaxation smoother. Assume periodic boundary conditions and analyze the RBGS error-propagation by Local Fourier Analysis (LFA), where error modes are taken as complex exponentials $e_{i,j} = \\exp\\!\\left(\\mathrm{i}\\left(\\theta_x i + \\theta_y j\\right)\\right)$ with $\\theta_x,\\theta_y \\in [-\\pi,\\pi]$ (angles in radians).\n\nDefine one RBGS sweep as an update of all red points followed by an update of all black points, with each point update using the $4$-point neighbor average implied by the discrete operator. Let the smoothing factor $\\mu$ be the supremum (over the set of high-frequency Fourier modes) of the magnitude of the error-amplification factor associated with one full RBGS sweep. Take the coarse grid to have spacing $2h$, and define the high-frequency set as the complement of the low-frequency set $[-\\pi/2,\\pi/2]^2$ in $[-\\pi,\\pi]^2$.\n\nStarting from the discrete operator and the definition of RBGS, use Local Fourier Analysis to derive the symbol of the RBGS error-propagation operator and compute the exact value of the smoothing factor $\\mu$ as the supremum of the magnitude of the error-amplification factor over the high-frequency set. Interpret the result in terms of attenuation of high-frequency error modes in the AMG-FAS context. The final answer must be the value of $\\mu$ (dimensionless). No rounding is required.",
            "solution": "The user wants to find the smoothing factor of Red-Black Gauss-Seidel for the 2D Poisson equation using Local Fourier Analysis.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process.\n\n**1.1. Extract Givens:**\n- **Equation**: Pressure Poisson subproblem.\n- **Operator**: Discrete negative Laplacian on a uniform 2D grid with spacing $h$, given by the five-point stencil:\n$$ (A_h u)_{i,j} = \\frac{1}{h^2}(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}) $$\n- **Smoother**: Red-Black Gauss-Seidel (RBGS), defined as an update of all red points (where $i+j$ is even) followed by an update of all black points (where $i+j$ is odd).\n- **Analysis Method**: Local Fourier Analysis (LFA).\n- **Boundary Conditions**: Periodic.\n- **Error Modes**: $e_{i,j} = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$ with $\\theta_x, \\theta_y \\in [-\\pi, \\pi]$.\n- **Coarsening**: Standard coarsening from grid spacing $h$ to $2h$.\n- **Frequency Sets**:\n    - Low-frequency set $\\Omega_L = [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n    - High-frequency set $\\Omega_H = [-\\pi, \\pi]^2 \\setminus [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n- **Target Quantity**: The smoothing factor $\\mu = \\sup_{\\theta \\in \\Omega_H} |g(\\theta)|$, where $g(\\theta)$ is the error-amplification factor for one full RBGS sweep.\n\n**1.2. Validate Using Extracted Givens:**\n- **Scientifically Grounded**: The problem is a cornerstone of classical multigrid theory. The 5-point Laplacian, Red-Black Gauss-Seidel, and Local Fourier Analysis are all standard, well-established concepts in numerical analysis for partial differential equations. The application context (aerospace CFD) is appropriate. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The problem is precisely defined. It requests the derivation of a specific quantity ($\\mu$) using a standard analytical technique (LFA) under clear definitions and constraints. A unique, meaningful solution exists.\n- **Objective**: The problem is stated in precise, formal, and unbiased language.\n\n**1.3. Verdict and Action:**\nThe problem is deemed **valid**. The solution process will now proceed.\n\n### Step 2: Derivation of the RBGS Amplification Factor\n\nWe analyze the propagation of a Fourier error mode through one full RBGS sweep. For the homogeneous error equation $A_h e = 0$, the update at a grid point $(i,j)$ is an averaging of its neighbors:\n$$ e_{i,j}^{\\text{new}} = \\frac{1}{4} (e_{i-1,j} + e_{i+1,j} + e_{i,j-1} + e_{i,j+1}) $$\nThe values on the right-hand side depend on whether they have already been updated in the current sweep.\n\nA single Fourier mode $e_{i,j} = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$ is not an eigenfunction of the RBGS operator. The red-black ordering couples the mode $\\theta = (\\theta_x, \\theta_y)$ with the mode $\\theta' = (\\theta_x+\\pi, \\theta_y+\\pi)$. Therefore, the error is represented as a linear combination of these two modes:\n$$ e_{i,j} = v_1 \\exp(\\mathrm{i} \\theta \\cdot \\mathbf{x}_{i,j}) + v_2 \\exp(\\mathrm{i} \\theta' \\cdot \\mathbf{x}_{i,j}) $$\nwhere $\\mathbf{x}_{i,j}=(i,j)$. The LFA analysis consists of finding the $2 \\times 2$ amplification matrix $G(\\theta)$ that maps the vector of amplitudes $v = [v_1, v_2]^T$ to $v' = G(\\theta) v$ after one full sweep. The error-amplification factor for the mode $\\theta$ is the spectral radius of $G(\\theta)$.\n\nA full RBGS sweep consists of a red pass ($S_R$) followed by a black pass ($S_B$).\nLet $J_h$ be the point-Jacobi iteration operator, which updates a point using the average of its four neighbors, all taken from the previous iteration level. The symbol of $J_h$ is:\n$$ \\tilde{J_h}(\\theta) = \\frac{1}{4} (\\exp(\\mathrm{i}\\theta_x) + \\exp(-\\mathrm{i}\\theta_x) + \\exp(\\mathrm{i}\\theta_y) + \\exp(-\\mathrm{i}\\theta_y)) = \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) $$\nLet $\\rho(\\theta) = \\tilde{J_h}(\\theta)$. Note that $\\rho(\\theta') = \\rho(\\theta_x+\\pi, \\theta_y+\\pi) = \\frac{1}{2}(-\\cos\\theta_x - \\cos\\theta_y) = -\\rho(\\theta)$.\nThe symbol of the Jacobi operator acting on the two-mode vector space is a diagonal matrix:\n$$ \\tilde{J}(\\theta) = \\begin{pmatrix} \\rho(\\theta) & 0 \\\\ 0 & \\rho(\\theta') \\end{pmatrix} = \\begin{pmatrix} \\rho(\\theta) & 0 \\\\ 0 & -\\rho(\\theta) \\end{pmatrix} $$\nThe red and black passes can be described using projection operators $P_R$ and $P_B$. Their symbols are $\\tilde{P}_R = \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}$ and $\\tilde{P}_B = \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$.\n\nThe red pass updates red points using old values (which live on black points) and leaves black points unchanged: $e^{k+1/2} = P_R (J_h e^k) + P_B e^k$. The symbol is $\\tilde{S}_R = \\tilde{P}_R \\tilde{J} + \\tilde{P}_B$.\n$$ \\tilde{S}_R = \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\rho & 0 \\\\ 0 & -\\rho \\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 1+\\rho & -1-\\rho \\\\ -1+\\rho & 1-\\rho \\end{pmatrix} $$\nThe black pass updates black points using the newly computed red values: $e^{k+1} = P_B (J_h e^{k+1/2}) + P_R e^{k+1/2}$. The symbol is $\\tilde{S}_B = \\tilde{P}_B \\tilde{J} + \\tilde{P}_R$.\n$$ \\tilde{S}_B = \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix} \\begin{pmatrix} \\rho & 0 \\\\ 0 & -\\rho \\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 1+\\rho & 1+\\rho \\\\ 1-\\rho & 1-\\rho \\end{pmatrix} $$\nThe amplification matrix for the full sweep is $G(\\theta) = \\tilde{S}_B \\tilde{S}_R$:\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} 1+\\rho & 1+\\rho \\\\ 1-\\rho & 1-\\rho \\end{pmatrix} \\begin{pmatrix} 1+\\rho & -(1+\\rho) \\\\ \\rho-1 & 1-\\rho \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)^2+(1+\\rho)(\\rho-1) & -(1+\\rho)^2+(1+\\rho)(1-\\rho) \\\\ (1-\\rho)(1+\\rho)+(1-\\rho)(\\rho-1) & -(1-\\rho)(1+\\rho)+(1-\\rho)^2 \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)(1+\\rho+\\rho-1) & (1+\\rho)(-1-\\rho+1-\\rho) \\\\ (1-\\rho)(1+\\rho+\\rho-1) & (1-\\rho)(-1-\\rho+1-\\rho) \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)(2\\rho) & (1+\\rho)(-2\\rho) \\\\ (1-\\rho)(2\\rho) & (1-\\rho)(-2\\rho) \\end{pmatrix} = \\begin{pmatrix} \\frac{\\rho(1+\\rho)}{2} & -\\frac{\\rho(1+\\rho)}{2} \\\\ \\frac{\\rho(1-\\rho)}{2} & -\\frac{\\rho(1-\\rho)}{2} \\end{pmatrix} $$\nThe eigenvalues $\\lambda$ of $G(\\theta)$ are found from the characteristic equation $\\lambda^2 - \\text{Tr}(G)\\lambda + \\det(G) = 0$.\nThe trace is $\\text{Tr}(G) = \\frac{\\rho(1+\\rho)}{2} - \\frac{\\rho(1-\\rho)}{2} = \\frac{\\rho}{2}(1+\\rho-1+\\rho) = \\rho^2$.\nThe determinant is $\\det(G) = -\\frac{\\rho^2(1+\\rho)(1-\\rho)}{4} + \\frac{\\rho^2(1+\\rho)(1-\\rho)}{4} = 0$.\nThe characteristic equation is $\\lambda^2 - \\rho^2 \\lambda = 0$, which gives eigenvalues $\\lambda_1 = 0$ and $\\lambda_2 = \\rho^2$.\n\nThe error-amplification factor $g(\\theta)$ is the spectral radius of $G(\\theta)$:\n$$ g(\\theta) = \\max(|\\lambda_1|, |\\lambda_2|) = |\\rho(\\theta)|^2 = \\left[ \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) \\right]^2 $$\n\n### Step 3: Computation of the Smoothing Factor $\\mu$\n\nThe smoothing factor $\\mu$ is the supremum of the amplification factor over the set of high-frequency modes $\\Omega_H = [-\\pi, \\pi]^2 \\setminus [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n$$ \\mu = \\sup_{(\\theta_x, \\theta_y) \\in \\Omega_H} \\left[ \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) \\right]^2 $$\nLet $X = \\cos\\theta_x$ and $Y = \\cos\\theta_y$. The domain for $(\\theta_x, \\theta_y)$ is $[-\\pi, \\pi]^2$, which maps to $(X,Y) \\in [-1, 1]^2$. The low-frequency domain $\\Omega_L$ corresponds to $\\theta_x, \\theta_y \\in [-\\pi/2, \\pi/2]$, which maps to a domain where $X, Y \\in [0, 1]$. The high-frequency domain $\\Omega_H$ corresponds to the domain for $(X,Y)$ being $[-1, 1]^2 \\setminus [0, 1]^2$. This means that at least one of $X$ or $Y$ must be in the range $[-1, 0)$.\n\nWe need to find the supremum of the function $f(X,Y) = \\frac{1}{4}(X+Y)^2$ on the domain $D' = ([-1,1]\\times[-1,1]) \\setminus [0,1]^2$.\nThe function $(X+Y)^2$ is non-negative and its value is determined by the magnitude of the sum $X+Y$. We need to find the maximum possible value of $|X+Y|$ on $D'$.\nThe domain $D'$ can be written as the union of three disjoint sets:\n1. $X \\in [-1, 0)$ and $Y \\in [-1, 0)$\n2. $X \\in [-1, 0)$ and $Y \\in [0, 1]$\n3. $X \\in [0, 1]$ and $Y \\in [-1, 0)$\n\nIn case 1, where both $X$ and $Y$ are negative, the sum $X+Y$ is in the range $(-2, 0)$. The maximum value of $|X+Y|$ is approached as $X\\to -1$ and $Y\\to -1$, where $|X+Y| \\to 2$.\nIn cases 2 and 3, one variable is non-positive and the other is non-negative. The sum $X+Y$ is in the range $[-1, 1]$. The maximum value of $|X+Y|$ is $1$.\n\nComparing the cases, the supremum of $|X+Y|$ over the entire domain $D'$ is $2$. This supremum is attained at the point $(X,Y) = (-1, -1)$. This point corresponds to Fourier modes where $\\cos\\theta_x = -1$ and $\\cos\\theta_y = -1$, for instance, $(\\theta_x, \\theta_y) = (\\pi, \\pi)$. This mode is in the high-frequency set $\\Omega_H$ since $|\\pi| = \\pi > \\pi/2$.\n\nAt this point, the amplification factor is:\n$$ g(\\pi, \\pi) = \\left[ \\frac{1}{2}(\\cos\\pi + \\cos\\pi) \\right]^2 = \\left[ \\frac{1}{2}(-1 - 1) \\right]^2 = (-1)^2 = 1 $$\nThus, the supremum of the amplification factor over the high-frequency domain is $1$.\n\n$$ \\mu = 1 $$\n\n### Step 4: Interpretation\n\nThe calculated smoothing factor is $\\mu=1$. A value of $1$ indicates that there is at least one high-frequency error mode that is not damped at all by the smoother. In this case, it is the highest frequency mode, $(\\theta_x, \\theta_y) = (\\pi, \\pi)$, which corresponds to the checkerboard pattern $e_{i,j} = C(-1)^{i+j}$.\n\nAt first glance, this result seems to suggest that RBGS is a poor smoother. However, its effectiveness is understood in the context of the entire multigrid cycle. The problematic high-frequency mode $(\\pi, \\pi)$ is a special case because it is an alias of the zero-frequency mode $(0,0)$ on the coarse grid (with spacing $2h$). That is, sampling the fine-grid checkerboard mode only on coarse-grid points yields a constant value.\nThe coarse-grid correction step of the multigrid algorithm is specifically designed to eliminate low-frequency errors, which includes the constant mode $(0,0)$. Therefore, the error component that the RBGS smoother fails to damp is effectively handled by the coarse-grid correction.\n\nFor all other high-frequency modes (those not aliasing to the zero-frequency mode), the RBGS amplification factor is strictly less than $1$. For instance, for modes on the boundary of the high-frequency domain, like $(\\pi/2, 0)$, the factor is $g(\\pi/2, 0) = [\\frac{1}{2}(0+1)]^2 = 1/4$. For a mode like $(\\pi, 2\\pi/3)$, the factor is $g(\\pi, 2\\pi/3) = [\\frac{1}{2}(-1 - 1/2)]^2 = 9/16$. The ability of RBGS to effectively damp this broad range of high-frequency modes, combined with its computational efficiency and parallelizability, makes it an excellent and widely-used smoother in practice, despite its theoretical smoothing factor being unity. The single undamped mode is not a bottleneck for the overall multigrid convergence.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Real-world aerospace problems, particularly those involving boundary layers or stretched meshes, often feature strong anisotropy that renders simple point-wise smoothers ineffective. This exercise extends the LFA technique to analyze a line Gauss-Seidel smoother, a standard remedy for anisotropic diffusion. By calculating the smoothing factor for an operator with strong directional coupling, you will see firsthand why tailoring the relaxation strategy to the operator's algebraic properties is critical for robust multigrid performance. ",
            "id": "3961623",
            "problem": "Consider the anisotropic diffusion operator that arises from implicit treatment of viscous terms in Reynolds-Averaged Navier–Stokes equations near a wall, modeled as $$-\\nabla \\cdot \\left( D \\nabla u \\right) = f,$$ on a uniform Cartesian grid with spacing $h$ in both directions, where the constant diffusion tensor is $$D = \\operatorname{diag}(1,\\epsilon), \\quad 0 < \\epsilon \\ll 1.$$ Using second-order central differences, the resulting linear system is symmetric positive definite with a standard five-point stencil. In Full Approximation Scheme (FAS) multigrid within Algebraic Multigrid (AMG), smoothing is achieved by relaxation; here, consider line Gauss–Seidel relaxation along grid-aligned $x$-lines defined as follows: within each fixed $j$-row (an $x$-line), solve the tridiagonal $x$-coupling exactly; across lines in the $y$-direction, apply lexicographic forward substitution (lower-triangular coupling in $y$ treated implicitly, upper-triangular coupling treated explicitly).\n\nPerform a Local Fourier Analysis (LFA) of this line Gauss–Seidel smoother. Let the discrete operator be denoted by $A$ and the line Gauss–Seidel error-propagation operator by $S_{\\mathrm{lineGS}}$. For Fourier modes $$e_{i,j}(\\theta_x,\\theta_y) = \\exp\\!\\left( \\mathrm{i} \\left( \\theta_x i + \\theta_y j \\right) \\right),$$ derive the symbol of $S_{\\mathrm{lineGS}}$, and define the high-frequency set $$\\mathcal{H} = \\left\\{ (\\theta_x,\\theta_y) \\in [-\\pi,\\pi]^2 \\, \\big| \\, |\\theta_x| \\in \\left[ \\frac{\\pi}{2}, \\pi \\right] \\text{ or } |\\theta_y| \\in \\left[ \\frac{\\pi}{2}, \\pi \\right] \\right\\}.$$ Compute the high-frequency smoothing factor $$\\mu_{\\mathrm{lineGS}}(\\epsilon) = \\sup_{(\\theta_x,\\theta_y) \\in \\mathcal{H}} \\left| \\widehat{S}_{\\mathrm{lineGS}}(\\theta_x,\\theta_y;\\epsilon) \\right|,$$ and provide it as a single, simplified closed-form analytic expression. No numerical rounding is required, and no physical units are to be reported in the final answer.",
            "solution": "The problem requires performing a Local Fourier Analysis (LFA) for a line Gauss-Seidel smoother applied to an anisotropic diffusion problem. The goal is to derive the high-frequency smoothing factor, $\\mu_{\\mathrm{lineGS}}(\\epsilon)$.\n\nFirst, we establish the discrete operator. The anisotropic diffusion equation is given by\n$$-\\nabla \\cdot \\left( D \\nabla u \\right) = f,$$\nwith the diffusion tensor $D = \\operatorname{diag}(1,\\epsilon)$. This expands to\n$$-\\frac{\\partial^2 u}{\\partial x^2} - \\epsilon \\frac{\\partial^2 u}{\\partial y^2} = f.$$\nDiscretizing this equation on a uniform Cartesian grid with spacing $h$ using second-order central differences yields the five-point stencil for the discrete operator $A$ at a grid point $(i,j)$:\n$$ (A u)_{i,j} = \\frac{1}{h^2} \\left[ (2+2\\epsilon)u_{i,j} - u_{i+1,j} - u_{i-1,j} - \\epsilon(u_{i,j+1} + u_{i,j-1}) \\right]. $$\nTo perform LFA, we analyze how the operator acts on a Fourier mode $e_{i,j}(\\theta_x,\\theta_y) = \\exp(\\mathrm{i} (\\theta_x i + \\theta_y j))$. The symbol of the operator $A$, denoted $\\widehat{A}(\\theta_x, \\theta_y)$, is the corresponding eigenvalue. Ignoring the scaling factor $1/h^2$, which will cancel out in the analysis of the smoother, we have:\n$$ \\widehat{A}(\\theta_x, \\theta_y) = (2+2\\epsilon) - e^{\\mathrm{i}\\theta_x} - e^{-\\mathrm{i}\\theta_x} - \\epsilon(e^{\\mathrm{i}\\theta_y} + e^{-\\mathrm{i}\\theta_y}) $$\n$$ \\widehat{A}(\\theta_x, \\theta_y) = (2+2\\epsilon) - 2\\cos(\\theta_x) - 2\\epsilon\\cos(\\theta_y) $$\n$$ \\widehat{A}(\\theta_x, \\theta_y) = 2(1-\\cos(\\theta_x)) + 2\\epsilon(1-\\cos(\\theta_y)) = 4\\sin^2\\left(\\frac{\\theta_x}{2}\\right) + 4\\epsilon\\sin^2\\left(\\frac{\\theta_y}{2}\\right). $$\n\nNext, we analyze the line Gauss-Seidel smoother. The relaxation is performed along $x$-lines (fixed $j$) with a lexicographic forward sweep in the $y$-direction. For an error vector $e^k = u - u^k$ at iteration $k$, the error at the next iteration, $e^{k+1}$, is governed by the homogeneous form of the update rule. The update for the line at index $j$ uses the newest available values from line $j-1$ and old values from line $j+1$:\n$$ (2+2\\epsilon)e_{i,j}^{k+1} - e_{i+1,j}^{k+1} - e_{i-1,j}^{k+1} - \\epsilon e_{i,j-1}^{k+1} = \\epsilon e_{i,j+1}^k. $$\nWe seek the amplification factor $\\lambda(\\theta_x, \\theta_y) = \\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, \\theta_y)$ such that $e^{k+1} = \\lambda e^k$ for a given Fourier mode. Substituting $e_{i,j}^k = \\exp(\\mathrm{i} (\\theta_x i + \\theta_y j))$ and $e_{i,j}^{k+1} = \\lambda \\exp(\\mathrm{i} (\\theta_x i + \\theta_y j))$ into the error propagation equation, we get:\n$$ \\lambda \\left[ (2+2\\epsilon) - e^{\\mathrm{i}\\theta_x} - e^{-\\mathrm{i}\\theta_x} - \\epsilon e^{-\\mathrm{i}\\theta_y} \\right] = \\epsilon e^{\\mathrm{i}\\theta_y}. $$\nSolving for the symbol $\\lambda = \\widehat{S}_{\\mathrm{lineGS}}$:\n$$ \\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, \\theta_y) = \\frac{\\epsilon e^{\\mathrm{i}\\theta_y}}{(2+2\\epsilon) - 2\\cos(\\theta_x) - \\epsilon e^{-\\mathrm{i}\\theta_y}}. $$\nThe smoothing factor is the supremum of the magnitude of this symbol over the high-frequency domain $\\mathcal{H}$. Let us compute the squared magnitude:\n$$ |\\widehat{S}_{\\mathrm{lineGS}}|^2 = \\frac{|\\epsilon e^{\\mathrm{i}\\theta_y}|^2}{|(2+2\\epsilon - 2\\cos(\\theta_x)) - \\epsilon \\cos(\\theta_y) + \\mathrm{i}\\epsilon \\sin(\\theta_y)|^2} $$\nLet $C_x = 2(1-\\cos(\\theta_x)) = 4\\sin^2(\\theta_x/2)$. The denominator's squared magnitude is:\n$$ \\left( (C_x + 2\\epsilon) - \\epsilon\\cos(\\theta_y) \\right)^2 + (\\epsilon\\sin(\\theta_y))^2 = (C_x + 2\\epsilon)^2 - 2\\epsilon(C_x + 2\\epsilon)\\cos(\\theta_y) + \\epsilon^2\\cos^2(\\theta_y) + \\epsilon^2\\sin^2(\\theta_y) $$\n$$ = (C_x + 2\\epsilon)^2 - 2\\epsilon(C_x + 2\\epsilon)\\cos(\\theta_y) + \\epsilon^2. $$\nSo,\n$$ |\\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, \\theta_y)|^2 = \\frac{\\epsilon^2}{(C_x + 2\\epsilon)^2 - 2\\epsilon(C_x + 2\\epsilon)\\cos(\\theta_y) + \\epsilon^2}. $$\nWe must find the supremum of $|\\widehat{S}_{\\mathrm{lineGS}}|$ over the high-frequency set $\\mathcal{H} = \\{ (\\theta_x,\\theta_y) \\in [-\\pi,\\pi]^2 \\, | \\, |\\theta_x| \\in [\\frac{\\pi}{2}, \\pi] \\text{ or } |\\theta_y| \\in [\\frac{\\pi}{2}, \\pi] \\}$. We analyze this set in two overlapping parts.\n\nCase 1: $|\\theta_x| \\in [\\frac{\\pi}{2}, \\pi]$.\nFor a fixed $\\theta_x$, to maximize $|\\widehat{S}_{\\mathrm{lineGS}}|$, we must minimize the denominator. The denominator is minimized when $\\cos(\\theta_y)$ is maximized, i.e., $\\cos(\\theta_y)=1$ at $\\theta_y=0$. The point $(\\theta_x, 0)$ is in $\\mathcal{H}$ for $|\\theta_x| \\ge \\frac{\\pi}{2}$. At $\\theta_y=0$:\n$$ |\\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, 0)|^2 = \\frac{\\epsilon^2}{(C_x + 2\\epsilon)^2 - 2\\epsilon(C_x + 2\\epsilon) + \\epsilon^2} = \\frac{\\epsilon^2}{((C_x + 2\\epsilon) - \\epsilon)^2} = \\frac{\\epsilon^2}{(C_x+\\epsilon)^2}. $$\nThus, $|\\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, 0)| = \\frac{\\epsilon}{C_x+\\epsilon} = \\frac{\\epsilon}{2(1-\\cos(\\theta_x))+\\epsilon}$. To maximize this quantity for $|\\theta_x| \\in [\\frac{\\pi}{2}, \\pi]$, we must minimize the term $1-\\cos(\\theta_x)$. In this interval for $\\theta_x$, $\\cos(\\theta_x)$ ranges from $0$ to $-1$. The minimum of $1-\\cos(\\theta_x)$ occurs at $\\theta_x = \\pm\\frac{\\pi}{2}$, where $\\cos(\\theta_x)=0$.\nThe maximum value for this case is at $(\\theta_x, \\theta_y) = (\\pm\\frac{\\pi}{2}, 0)$:\n$$ \\sup_{|\\theta_x|\\ge\\pi/2} |\\widehat{S}_{\\mathrm{lineGS}}(\\theta_x, 0)| = \\frac{\\epsilon}{2(1-0)+\\epsilon} = \\frac{\\epsilon}{2+\\epsilon}. $$\n\nCase 2: $|\\theta_y| \\in [\\frac{\\pi}{2}, \\pi]$.\nFor a fixed $\\theta_y$ in this range, we have $\\cos(\\theta_y) \\le 0$. To maximize $|\\widehat{S}_{\\mathrm{lineGS}}|$, we must minimize the denominator term $(C_x + 2\\epsilon)^2 - 2\\epsilon(C_x + 2\\epsilon)\\cos(\\theta_y) + \\epsilon^2$. As a function of $C_x \\ge 0$, the derivative of the denominator is $2(C_x+2\\epsilon) - 2\\epsilon\\cos(\\theta_y) > 0$. Thus, the denominator is minimized when $C_x$ is minimized. This occurs at $C_x = 2(1-\\cos(\\theta_x)) = 0$, which means $\\theta_x=0$. The point $(0, \\theta_y)$ is in $\\mathcal{H}$ for $|\\theta_y| \\ge \\frac{\\pi}{2}$.\nAt $\\theta_x=0$, we have $C_x=0$. The squared magnitude becomes:\n$$ |\\widehat{S}_{\\mathrm{lineGS}}(0, \\theta_y)|^2 = \\frac{\\epsilon^2}{(2\\epsilon)^2 - 2\\epsilon(2\\epsilon)\\cos(\\theta_y) + \\epsilon^2} = \\frac{\\epsilon^2}{4\\epsilon^2 - 4\\epsilon^2\\cos(\\theta_y) + \\epsilon^2} = \\frac{\\epsilon^2}{\\epsilon^2(5 - 4\\cos(\\theta_y))}. $$\nSo, $|\\widehat{S}_{\\mathrm{lineGS}}(0, \\theta_y)| = \\frac{1}{\\sqrt{5 - 4\\cos(\\theta_y)}}$. To maximize this for $|\\theta_y| \\in [\\frac{\\pi}{2}, \\pi]$, we must minimize the denominator $\\sqrt{5 - 4\\cos(\\theta_y)}$. This occurs when $\\cos(\\theta_y)$ is maximized. In the interval $|\\theta_y| \\in [\\frac{\\pi}{2}, \\pi]$, the maximum value of $\\cos(\\theta_y)$ is $0$, which occurs at $\\theta_y = \\pm\\frac{\\pi}{2}$.\nThe maximum value for this case is at $(\\theta_x, \\theta_y) = (0, \\pm\\frac{\\pi}{2})$:\n$$ \\sup_{|\\theta_y|\\ge\\pi/2} |\\widehat{S}_{\\mathrm{lineGS}}(0, \\theta_y)| = \\frac{1}{\\sqrt{5 - 4(0)}} = \\frac{1}{\\sqrt{5}}. $$\n\nThe overall high-frequency smoothing factor $\\mu_{\\mathrm{lineGS}}(\\epsilon)$ is the supremum over the entire set $\\mathcal{H}$, which is the maximum of the results from the two cases:\n$$ \\mu_{\\mathrm{lineGS}}(\\epsilon) = \\max\\left( \\frac{\\epsilon}{2+\\epsilon}, \\frac{1}{\\sqrt{5}} \\right). $$\nThe problem specifies that $0  \\epsilon \\ll 1$. We must compare the two values under this condition. Let's find when they are equal:\n$$ \\frac{\\epsilon}{2+\\epsilon} = \\frac{1}{\\sqrt{5}} \\implies \\sqrt{5}\\epsilon = 2+\\epsilon \\implies (\\sqrt{5}-1)\\epsilon = 2 \\implies \\epsilon = \\frac{2}{\\sqrt{5}-1} = \\frac{\\sqrt{5}+1}{2} \\approx 1.618. $$\nSince $\\epsilon \\ll 1$, we are in the regime where $\\epsilon  (\\sqrt{5}+1)/2$. In this regime, the function $\\frac{x}{2+x}$ is smaller than $\\frac{1}{\\sqrt{5}}$. For instance, as $\\epsilon \\to 0$, $\\frac{\\epsilon}{2+\\epsilon} \\to 0$, whereas $\\frac{1}{\\sqrt{5}} \\approx 0.4472$ is a constant.\nTherefore, for the specified condition $\\epsilon \\ll 1$, the maximum is always given by the second term.\n$$ \\mu_{\\mathrm{lineGS}}(\\epsilon) = \\frac{1}{\\sqrt{5}}. $$\nThis value is independent of $\\epsilon$, which signifies that the line Gauss-Seidel smoother is robust for this type of anisotropy. The most persistent high-frequency mode is $(\\theta_x, \\theta_y) = (0, \\pm\\pi/2)$, i.e., a mode that is smooth in the direction of strong coupling (and line relaxation) but oscillatory in the direction of weak coupling.",
            "answer": "$$\\boxed{\\frac{1}{\\sqrt{5}}}$$"
        },
        {
            "introduction": "An effective multigrid cycle requires not only a good smoother but also coarse-grid correction operators that can accurately represent and correct algebraically smooth error. This practice shifts focus from the smoother to the inter-grid transfer operators, which are the heart of Algebraic Multigrid. By constructing a simple but highly anisotropic system and applying a naive, geometry-based coarsening strategy, you will calculate the resulting two-grid convergence factor and demonstrate why this approach fails, revealing the fundamental principle that AMG interpolation must be based on the algebraic 'strength of connection' to be effective. ",
            "id": "3961548",
            "problem": "Consider a linear subproblem arising in an implicit compressible flow solver where an anisotropic diffusion operator models wall-normal thermal conduction in a high-Reynolds-number boundary layer. On the unit square with homogeneous Dirichlet boundary conditions, discretize the anisotropic operator $-\\partial_{x}(\\alpha\\,\\partial_{x} u)-\\partial_{y}(\\beta\\,\\partial_{y} u)$ on a uniform fine grid with $N_{x}=N_{y}=2$ interior points, so $h_{x}=h_{y}=1/3$. Let $\\alpha=1$ and $\\beta=\\varepsilon$ with $\\varepsilon=10^{-6}$. Use the standard five-point finite-difference stencil to assemble the $4\\times 4$ fine-grid matrix $A$ ordering unknowns as $(i,j)=(1,1),(2,1),(1,2),(2,2)$.\n\nApply Algebraic Multigrid (AMG) using the Galerkin definition of the coarse operator, $A_{c}=R\\,A\\,P$. Construct a naive coarsening that aggregates all four fine-grid unknowns into a single coarse unknown, with restriction and prolongation that ignore anisotropy: define restriction as the simple average $R=\\frac{1}{4}\\,[\\,1\\;\\;1\\;\\;1\\;\\;1\\,]$ and prolongation as piecewise-constant interpolation $P=[\\,1\\;\\;1\\;\\;1\\;\\;1\\,]^{\\top}$. Consider a two-grid cycle with zero smoothing steps, i.e., only one coarse-grid correction is applied to the fine-grid error.\n\nStarting from first principles of the finite-difference discretization and the Galerkin coarse-grid construction, derive the resulting two-grid error-propagation operator for this setup and determine its spectral radius. Express the final spectral radius as a dimensionless number and round your answer to four significant figures.",
            "solution": "The user has asked for the derivation of the spectral radius of a two-grid error-propagation operator for a specific anisotropic diffusion problem.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n- **Operator:** $-\\partial_{x}(\\alpha\\,\\partial_{x} u)-\\partial_{y}(\\beta\\,\\partial_{y} u)$\n- **Domain:** Unit square $[0,1] \\times [0,1]$\n- **Boundary Conditions:** Homogeneous Dirichlet ($u=0$ on the boundary).\n- **Discretization:** Uniform fine grid, standard five-point finite-difference stencil.\n- **Grid Size:** $N_{x}=2$ and $N_{y}=2$ interior points.\n- **Grid Spacing:** $h_{x} = h_{y} = h = 1/3$.\n- **Anisotropy Parameters:** $\\alpha = 1$, $\\beta = \\varepsilon = 10^{-6}$.\n- **Unknown Ordering:** The $4$ unknowns are ordered as $(i,j)=(1,1),(2,1),(1,2),(2,2)$.\n- **AMG Setup:**\n  - **Coarsening:** All four fine-grid unknowns aggregated into a single coarse unknown.\n  - **Restriction Operator ($R$):** $R = \\frac{1}{4}\\begin{pmatrix} 1  1  1  1 \\end{pmatrix}$.\n  - **Prolongation Operator ($P$):** $P = \\begin{pmatrix} 1  1  1  1 \\end{pmatrix}^{\\top}$.\n  - **Coarse Operator Definition:** Galerkin operator, $A_{c} = R\\,A\\,P$.\n- **Two-Grid Cycle:** Zero pre- and post-smoothing steps.\n- **Task:** Derive the two-grid error-propagation operator and determine its spectral radius, rounded to four significant figures.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded:** The problem is a standard exercise in the field of numerical analysis, specifically concerning multigrid methods for solving partial differential equations. The setup is based on established principles of finite-difference methods and algebraic multigrid.\n- **Well-Posed:** The problem is clearly defined with all necessary components (PDE, domain, boundary conditions, discretization, multigrid operators) specified. It leads to a unique, determinable result.\n- **Objective:** The language is precise and mathematical. All terms are standard in the field.\n\n**3. Verdict and Action:**\nThe problem is deemed **valid**. It is a well-posed, scientifically sound problem in numerical analysis. The solution process can proceed.\n\n### Step 2: Derivation and Solution\n\n**1. Discretization and Fine-Grid Operator ($A$)**\n\nThe given anisotropic diffusion operator is $L(u) = -\\alpha \\frac{\\partial^2 u}{\\partial x^2} - \\beta \\frac{\\partial^2 u}{\\partial y^2}$. Using a central finite-difference scheme on a uniform grid with spacing $h = h_x = h_y$, the operator at an interior grid point $(x_i, y_j)$ is approximated as:\n$$\nL_h u_{ij} = -\\alpha \\frac{u_{i+1,j} - 2u_{ij} + u_{i-1,j}}{h^2} - \\beta \\frac{u_{i,j+1} - 2u_{ij} + u_{i,j-1}}{h^2}\n$$\nRearranging terms, we get the stencil equation:\n$$\n(L_h u)_{ij} = \\frac{1}{h^2} \\left[ (2\\alpha + 2\\beta)u_{ij} - \\alpha u_{i-1,j} - \\alpha u_{i+1,j} - \\beta u_{i,j-1} - \\beta u_{i,j+1} \\right]\n$$\nThe problem specifies $N_x=N_y=2$ interior points, so $h=1/3$. The interior points are $(1/3, 1/3)$, $(2/3, 1/3)$, $(1/3, 2/3)$, and $(2/3, 2/3)$. The unknowns are ordered as $u_1 = u_{11}$, $u_2 = u_{21}$, $u_3 = u_{12}$, $u_4 = u_{22}$. We apply the stencil equation at each of the four points, incorporating the homogeneous Dirichlet boundary conditions ($u_{0j}=u_{3j}=u_{i0}=u_{i3}=0$ for $i,j \\in \\{1,2\\}$).\n\n- For $u_1 = u_{11}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{11} - \\alpha u_{21} - \\beta u_{12} ]$\n- For $u_2 = u_{21}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{21} - \\alpha u_{11} - \\beta u_{22} ]$\n- For $u_3 = u_{12}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{12} - \\alpha u_{22} - \\beta u_{11} ]$\n- For $u_4 = u_{22}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{22} - \\alpha u_{12} - \\beta u_{21} ]$\n\nThese equations form the linear system $A\\mathbf{u}=\\mathbf{f}$. The fine-grid matrix $A$ is:\n$$\nA = \\frac{1}{h^2}\n\\begin{pmatrix}\n2\\alpha+2\\beta  -\\alpha  -\\beta  0 \\\\\n-\\alpha  2\\alpha+2\\beta  0  -\\beta \\\\\n-\\beta  0  2\\alpha+2\\beta  -\\alpha \\\\\n0  -\\beta  -\\alpha  2\\alpha+2\\beta\n\\end{pmatrix}\n$$\n\n**2. Coarse-Grid Operator ($A_c$)**\n\nThe coarse-grid operator is constructed using the Galerkin formula $A_c = R A P$. The given restriction and prolongation operators are:\n$$\nR = \\frac{1}{4}\\begin{pmatrix} 1  1  1  1 \\end{pmatrix}, \\quad P = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\nFirst, we compute the product $AP$:\n$$\nAP = \\frac{1}{h^2}\n\\begin{pmatrix}\n2\\alpha+2\\beta  -\\alpha  -\\beta  0 \\\\\n-\\alpha  2\\alpha+2\\beta  0  -\\beta \\\\\n-\\beta  0  2\\alpha+2\\beta  -\\alpha \\\\\n0  -\\beta  -\\alpha  2\\alpha+2\\beta\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n= \\frac{1}{h^2}\n\\begin{pmatrix}\n\\alpha+\\beta \\\\ \\alpha+\\beta \\\\ \\alpha+\\beta \\\\ \\alpha+\\beta\n\\end{pmatrix}\n= \\frac{\\alpha+\\beta}{h^2}\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\nNow, we pre-multiply by $R$:\n$$\nA_c = R (AP) = \\frac{1}{4}\\begin{pmatrix} 1  1  1  1 \\end{pmatrix} \\left( \\frac{\\alpha+\\beta}{h^2} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{\\alpha+\\beta}{4h^2} (1+1+1+1) = \\frac{\\alpha+\\beta}{h^2}\n$$\n$A_c$ is a scalar (a $1 \\times 1$ matrix), and its inverse is $A_c^{-1} = \\frac{h^2}{\\alpha+\\beta}$.\n\n**3. Two-Grid Error-Propagation Operator ($M_{TG}$)**\n\nA two-grid cycle with zero pre- and post-smoothing steps consists only of the coarse-grid correction. The error $e_{k}$ is transformed to $e_{k+1}$ according to the relation $e_{k+1} = (I - P A_c^{-1} R A) e_k$. The error-propagation operator is therefore:\n$$\nM_{TG} = I - P A_c^{-1} R A\n$$\nLet's compute the coarse-grid correction part, $K = P A_c^{-1} R A$.\nFirst, we form the product $P A_c^{-1} R$:\n$$\nP A_c^{-1} R = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\left( \\frac{h^2}{\\alpha+\\beta} \\right) \\frac{1}{4}\\begin{pmatrix} 1  1  1  1 \\end{pmatrix} = \\frac{h^2}{4(\\alpha+\\beta)}\n\\begin{pmatrix}\n1  1  1  1 \\\\\n1  1  1  1 \\\\\n1  1  1  1 \\\\\n1  1  1  1\n\\end{pmatrix}\n$$\nLet $J$ be the $4 \\times 4$ matrix of all ones. Then $P A_c^{-1} R = \\frac{h^2}{4(\\alpha+\\beta)} J$.\nNow, we compute $K = (P A_c^{-1} R) A$:\n$$\nK = \\frac{h^2}{4(\\alpha+\\beta)} J A\n$$\nThe product $JA$ is a matrix where each row is the sum of all rows of $A$. Summing the columns of $A$ gives the elements of this row vector:\n$$\n\\sum_{i} A_{i1} = \\frac{1}{h^2}( (2\\alpha+2\\beta) - \\alpha - \\beta ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i2} = \\frac{1}{h^2}( -\\alpha + (2\\alpha+2\\beta) - \\beta ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i3} = \\frac{1}{h^2}( -\\beta + (2\\alpha+2\\beta) - \\alpha ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i4} = \\frac{1}{h^2}( -\\beta - \\alpha + (2\\alpha+2\\beta) ) = \\frac{\\alpha+\\beta}{h^2}\n$$\nSo, $JA = \\frac{\\alpha+\\beta}{h^2} J$.\nSubstituting this back into the expression for $K$:\n$$\nK = \\frac{h^2}{4(\\alpha+\\beta)} \\left( \\frac{\\alpha+\\beta}{h^2} J \\right) = \\frac{1}{4} J = \\frac{1}{4}\n\\begin{pmatrix}\n1  1  1  1 \\\\\n1  1  1  1 \\\\\n1  1  1  1 \\\\\n1  1  1  1\n\\end{pmatrix}\n$$\nThe error-propagation operator is:\n$$\nM_{TG} = I - K = I - \\frac{1}{4}J =\n\\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix}\n- \\frac{1}{4}\n\\begin{pmatrix} 1  1  1  1 \\\\ 1  1  1  1 \\\\ 1  1  1  1 \\\\ 1  1  1  1 \\end{pmatrix}\n= \\frac{1}{4}\n\\begin{pmatrix} 3  -1  -1  -1 \\\\ -1  3  -1  -1 \\\\ -1  -1  3  -1 \\\\ -1  -1  -1  3 \\end{pmatrix}\n$$\nNotably, the operator $M_{TG}$ is independent of the parameters $\\alpha$, $\\beta$, and $h$. This is a consequence of the chosen naive restriction and prolongation operators, which are aligned with the constant vector, an eigenvector of the discrete operator $A$.\n\n**4. Spectral Radius of $M_{TG}$**\n\nThe spectral radius $\\rho(M_{TG})$ is the maximum of the absolute values of the eigenvalues of $M_{TG}$. The eigenvalues of $M_{TG} = I - \\frac{1}{4}J$ can be found from the eigenvalues of $J$.\nThe matrix $J$ has rank $1$. Its characteristic polynomial is $\\det(J - \\lambda I)$. The vector $\\mathbf{1} = \\begin{pmatrix} 1  1  1  1 \\end{pmatrix}^{\\top}$ is an eigenvector, since $J\\mathbf{1} = 4\\mathbf{1}$. Thus, one eigenvalue of $J$ is $\\lambda_1 = 4$. Since $\\mathrm{rank}(J) = 1$, the null space of $J$ has dimension $4-1=3$. This means the eigenvalue $\\lambda=0$ has a multiplicity of $3$. The eigenvalues of $J$ are $\\{4, 0, 0, 0\\}$.\n\nThe eigenvalues of $M_{TG}$, denoted $\\mu$, are related to the eigenvalues of $J$ by $\\mu = 1 - \\frac{1}{4}\\lambda$.\n- For $\\lambda=4$: $\\mu = 1 - \\frac{1}{4}(4) = 0$.\n- For $\\lambda=0$: $\\mu = 1 - \\frac{1}{4}(0) = 1$. This eigenvalue has multiplicity $3$.\n\nThe eigenvalues of $M_{TG}$ are $\\{1, 1, 1, 0\\}$.\nThe spectral radius is the maximum of the absolute values of these eigenvalues:\n$$\n\\rho(M_{TG}) = \\max\\{|1|, |0|\\} = 1\n$$\nThis result indicates that the two-grid method with this specific setup does not converge, as error components in the space corresponding to the eigenvalue $1$ are not attenuated. This is a classic example of why AMG operators must be chosen carefully to match the properties (e.g., anisotropy) of the system matrix $A$.\n\nRounding the spectral radius to four significant figures gives $1.000$.",
            "answer": "$$\\boxed{1.000}$$"
        }
    ]
}