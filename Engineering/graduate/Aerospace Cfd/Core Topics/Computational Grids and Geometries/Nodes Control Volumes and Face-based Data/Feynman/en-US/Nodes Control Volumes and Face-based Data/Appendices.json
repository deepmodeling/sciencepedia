{
    "hands_on_practices": [
        {
            "introduction": "The core of the finite volume method is the summation of fluxes across the faces of a control volume. This first practice  breaks this process down to its most fundamental component: calculating the mass flux through a single triangular face. By working through this exercise, you will apply vector algebra to determine a face's area and orientation, and then use this geometric information to compute the physical transport of mass, a cornerstone of any CFD simulation.",
            "id": "3980526",
            "problem": "A single triangular face in three-dimensional space is shared by two control volumes in a finite volume discretization used in Computational Fluid Dynamics (CFD). The face is defined by its ordered vertices (owner-side convention) in meters:\n- $P_1 = (0.2,\\, 0.1,\\, 0.0)$,\n- $P_2 = (1.1,\\, 0.2,\\, 0.3)$,\n- $P_3 = (0.4,\\, 1.0,\\, 0.1)$.\n\nThe centroids of the adjacent control volumes (left/owner and right/neighbor) are:\n- $C_L = (0.5,\\, 0.5,\\, -0.1)$,\n- $C_R = (0.6,\\, 0.4,\\, 0.6)$.\n\nAssume a uniform density and velocity field:\n- $\\rho = 0.8\\,\\mathrm{kg/m^3}$,\n- $\\boldsymbol{u} = (12,\\,-3,\\,25)\\,\\mathrm{m/s}$.\n\nUsing only fundamental geometric facts and the definition of flux in the finite volume method, complete the following:\n1. Compute the face area magnitude $A_f$, the unit normal $\\boldsymbol{n}_f$ induced by the given vertex ordering, and the face centroid $\\boldsymbol{C}_f$.\n2. Verify orientation consistency with the owner-to-neighbor convention by evaluating the sign of $\\left(\\boldsymbol{A}_f \\cdot \\boldsymbol{d}\\right)$, where $\\boldsymbol{A}_f = A_f \\boldsymbol{n}_f$ and $\\boldsymbol{d} = C_R - C_L$. State whether the stored orientation is consistent.\n3. Using the orientation-consistent face area vector on the owner side, compute the advective mass flux through the face, $\\Phi_m = \\rho\\,\\boldsymbol{u}\\cdot\\boldsymbol{A}_f$.\n\nProvide only the final value of the mass flux as your answer. Express the final mass flux in $\\mathrm{kg/s}$ and round your answer to four significant figures.",
            "solution": "The problem statement is a well-posed exercise in vector algebra applied to the fundamental principles of the finite volume method in Computational Fluid Dynamics. It is scientifically grounded, free of contradictions, and contains all necessary data for a unique solution. Therefore, the problem is valid.\n\nThe task is to compute the advective mass flux $\\Phi_m$ through a triangular face. The mass flux is given by the formula $\\Phi_m = \\rho\\,\\boldsymbol{u}\\cdot\\boldsymbol{A}_f$, where $\\rho$ is the fluid density, $\\boldsymbol{u}$ is the velocity vector, and $\\boldsymbol{A}_f$ is the orientation-consistent face area vector.\n\nThe given data are:\n- Vertices: $P_1 = (0.2,\\, 0.1,\\, 0.0)$, $P_2 = (1.1,\\, 0.2,\\, 0.3)$, $P_3 = (0.4,\\, 1.0,\\, 0.1)$. All coordinates are in meters.\n- Control volume centroids: $C_L = (0.5,\\, 0.5,\\, -0.1)$ (owner) and $C_R = (0.6,\\, 0.4,\\, 0.6)$ (neighbor).\n- Fluid properties: $\\rho = 0.8\\,\\mathrm{kg/m^3}$ and $\\boldsymbol{u} = (12,\\,-3,\\,25)\\,\\mathrm{m/s}$.\n\nFirst, we compute the face area vector, $\\boldsymbol{A}_f$, based on the provided vertex ordering. The vector's direction is normal to the face, determined by the right-hand rule applied to the ordered vertices, and its magnitude is the area of the triangle. We define two edge vectors originating from vertex $P_1$:\n$$ \\boldsymbol{v}_1 = P_2 - P_1 = (1.1 - 0.2,\\, 0.2 - 0.1,\\, 0.3 - 0.0) = (0.9,\\, 0.1,\\, 0.3) $$\n$$ \\boldsymbol{v}_2 = P_3 - P_1 = (0.4 - 0.2,\\, 1.0 - 0.1,\\, 0.1 - 0.0) = (0.2,\\, 0.9,\\, 0.1) $$\n\nThe area vector is given by half the cross product of these two edge vectors:\n$$ \\boldsymbol{A}_f = \\frac{1}{2} (\\boldsymbol{v}_1 \\times \\boldsymbol{v}_2) = \\frac{1}{2} \\begin{vmatrix} \\boldsymbol{i} & \\boldsymbol{j} & \\boldsymbol{k} \\\\ 0.9 & 0.1 & 0.3 \\\\ 0.2 & 0.9 & 0.1 \\end{vmatrix} $$\n$$ \\boldsymbol{A}_f = \\frac{1}{2} \\left[ (0.1 \\cdot 0.1 - 0.3 \\cdot 0.9)\\boldsymbol{i} - (0.9 \\cdot 0.1 - 0.3 \\cdot 0.2)\\boldsymbol{j} + (0.9 \\cdot 0.9 - 0.1 \\cdot 0.2)\\boldsymbol{k} \\right] $$\n$$ \\boldsymbol{A}_f = \\frac{1}{2} \\left[ (0.01 - 0.27)\\boldsymbol{i} - (0.09 - 0.06)\\boldsymbol{j} + (0.81 - 0.02)\\boldsymbol{k} \\right] $$\n$$ \\boldsymbol{A}_f = \\frac{1}{2} (-0.26\\boldsymbol{i} - 0.03\\boldsymbol{j} + 0.79\\boldsymbol{k}) $$\n$$ \\boldsymbol{A}_f = (-0.13,\\, -0.015,\\, 0.395)\\,\\mathrm{m}^2 $$\n\nNext, we must verify that the direction of $\\boldsymbol{A}_f$ is consistent with the owner-to-neighbor ($L \\to R$) convention prescribed in finite volume methods. This is done by checking the sign of the dot product of $\\boldsymbol{A}_f$ and the vector $\\boldsymbol{d}$ connecting the owner-cell centroid $C_L$ to the neighbor-cell centroid $C_R$.\n$$ \\boldsymbol{d} = C_R - C_L = (0.6 - 0.5,\\, 0.4 - 0.5,\\, 0.6 - (-0.1)) = (0.1,\\, -0.1,\\, 0.7) $$\n\nWe compute the dot product:\n$$ \\boldsymbol{A}_f \\cdot \\boldsymbol{d} = (-0.13)(0.1) + (-0.015)(-0.1) + (0.395)(0.7) $$\n$$ \\boldsymbol{A}_f \\cdot \\boldsymbol{d} = -0.013 + 0.0015 + 0.2765 = 0.265 $$\nSince $\\boldsymbol{A}_f \\cdot \\boldsymbol{d} > 0$, the normal vector defined by the vertex ordering points from the owner cell to the neighbor cell. The stored orientation is therefore consistent. The orientation-consistent face area vector to be used for the flux calculation from the owner side is $\\boldsymbol{A}_f$ itself.\n\nFinally, we compute the advective mass flux $\\Phi_m$ using the given uniform density $\\rho$ and velocity field $\\boldsymbol{u}$:\n$$ \\Phi_m = \\rho (\\boldsymbol{u} \\cdot \\boldsymbol{A}_f) $$\nWe are given $\\rho = 0.8\\,\\mathrm{kg/m^3}$ and $\\boldsymbol{u} = (12,\\, -3,\\, 25)\\,\\mathrm{m/s}$. First, we calculate the volumetric flux, which is the dot product $\\boldsymbol{u} \\cdot \\boldsymbol{A}_f$:\n$$ \\boldsymbol{u} \\cdot \\boldsymbol{A}_f = (12,\\, -3,\\, 25) \\cdot (-0.13,\\, -0.015,\\, 0.395) $$\n$$ \\boldsymbol{u} \\cdot \\boldsymbol{A}_f = 12(-0.13) + (-3)(-0.015) + 25(0.395) $$\n$$ \\boldsymbol{u} \\cdot \\boldsymbol{A}_f = -1.56 + 0.045 + 9.875 = 8.36\\,\\mathrm{m^3/s} $$\n\nNow, we multiply by the density to obtain the mass flux:\n$$ \\Phi_m = 0.8\\,\\mathrm{kg/m^3} \\times 8.36\\,\\mathrm{m^3/s} = 6.688\\,\\mathrm{kg/s} $$\n\nThe problem requires the final answer to be rounded to four significant figures. The calculated value $6.688$ already has four significant figures.",
            "answer": "$$\\boxed{6.688}$$"
        },
        {
            "introduction": "While simple flux calculations are illustrative, real-world CFD applications on unstructured meshes introduce geometric complexities that can degrade accuracy. This exercise  delves into the critical issue of non-orthogonality, where the face normal vector is not aligned with the vector connecting adjacent cell centroids. You will derive and apply a correction term for the diffusive flux, providing a hands-on understanding of how modern solvers maintain accuracy on imperfect grids.",
            "id": "3980499",
            "problem": "Consider a face-based diffusion discretization in a cell-centered finite volume method for Computational Fluid Dynamics (CFD). Let two adjacent control volumes with centroids at positions $\\boldsymbol{x}_P$ and $\\boldsymbol{x}_N$ share a common planar face of area vector $\\boldsymbol{S}_f$. The scalar field $\\phi(\\boldsymbol{x})$ is transported by diffusion with a constant, nondimensional diffusion coefficient $\\Gamma$, and is assumed to vary linearly in space so that $\\nabla \\phi$ is constant. The face-based diffusive contribution is obtained from the integral form of conservation and the divergence theorem as a sum over faces of $-\\Gamma\\,\\boldsymbol{S}_f \\cdot \\nabla \\phi$ evaluated at the face. The commonly used orthogonal (center-to-center) approximation replaces the face-normal gradient by the directional derivative along the straight line connecting centroids, introducing an error when $\\boldsymbol{S}_f$ is not parallel to the centroid-to-centroid vector.\n\nStarting from the divergence theorem, the definition of the gradient, and the directional derivative along a unit direction, derive the non-orthogonality-induced face error as the difference between the exact face contribution and the orthogonal center-to-center approximation by projecting onto the centroid-connecting direction. Then, propose a non-orthogonal correction term that must be added to the orthogonal approximation to recover the exact face contribution for a linear field, expressed in terms of a decomposition of $\\boldsymbol{S}_f \\cdot \\nabla \\phi$ into an orthogonal and a non-orthogonal part.\n\nFinally, evaluate numerically the non-orthogonal correction contribution to the diffusive flux through the face for the following nondimensional data:\n- $\\boldsymbol{x}_P = (0,\\,0,\\,0)$,\n- $\\boldsymbol{x}_N = (1,\\,0.2,\\,0)$,\n- $\\boldsymbol{S}_f = (0.24,\\,0.18,\\,0)$,\n- $\\nabla \\phi = (2.5,\\,-0.7,\\,1.2)$,\n- $\\Gamma = 2$.\n\nAll quantities are nondimensional. Round your final answer (the value of the non-orthogonal correction contribution to the face diffusive flux) to four significant figures. Express the final answer as a pure number without any unit.",
            "solution": "The problem asks for the derivation of the non-orthogonal correction for a face-based diffusive flux calculation in a finite volume method and its numerical evaluation for a given set of data. The analysis assumes a linear scalar field $\\phi(\\boldsymbol{x})$, which implies its gradient $\\nabla\\phi$ is a constant vector.\n\nLet us begin with the integral form of the conservation equation for a scalar quantity $\\phi$ over a control volume $V$, in the absence of sources and convection:\n$$ \\frac{\\partial}{\\partial t} \\int_V \\phi \\,dV + \\int_V \\nabla \\cdot \\boldsymbol{J} \\,dV = 0 $$\nwhere $\\boldsymbol{J}$ is the diffusive flux vector, defined by Fick's law as $\\boldsymbol{J} = -\\Gamma\\nabla\\phi$, with $\\Gamma$ being the constant diffusion coefficient.\n\nApplying the divergence theorem to the second term transforms the volume integral into a sum of integrals over the faces $f$ enclosing the control volume:\n$$ \\int_V \\nabla \\cdot \\boldsymbol{J} \\,dV = \\sum_f \\int_f \\boldsymbol{J} \\cdot d\\boldsymbol{S} $$\nFor a planar face with area vector $\\boldsymbol{S}_f$ and assuming the flux vector $\\boldsymbol{J}$ is uniform over the face (which is true since $\\nabla\\phi$ is constant), the integral simplifies to a dot product:\n$$ \\int_f \\boldsymbol{J} \\cdot d\\boldsymbol{S} = \\boldsymbol{J} \\cdot \\boldsymbol{S}_f = (-\\Gamma\\nabla\\phi) \\cdot \\boldsymbol{S}_f = -\\Gamma(\\boldsymbol{S}_f \\cdot \\nabla\\phi) $$\nThis term, $F_f = -\\Gamma(\\boldsymbol{S}_f \\cdot \\nabla\\phi)$, represents the exact diffusive flux through the face $f$. The core of the discretization problem lies in approximating the term $\\boldsymbol{S}_f \\cdot \\nabla\\phi$.\n\nIn a cell-centered finite volume method, the primary variables are stored at the centroids of the control volumes, here denoted by $\\boldsymbol{x}_P$ and $\\boldsymbol{x}_N$ for two adjacent cells. The geometric vector connecting the centroids is $\\boldsymbol{d} = \\boldsymbol{x}_N - \\boldsymbol{x}_P$.\n\nThe orthogonal approximation for the flux is based on the gradient component along the centroid-to-centroid vector $\\boldsymbol{d}$. For a linear field, the difference $\\phi_N - \\phi_P$ is exactly related to the gradient by $\\phi_N - \\phi_P = \\nabla\\phi \\cdot (\\boldsymbol{x}_N - \\boldsymbol{x}_P) = \\nabla\\phi \\cdot \\boldsymbol{d}$. The simplest approximations for the flux are constructed using only this cell-to-cell difference, which implicitly relies on the gradient component along $\\boldsymbol{d}$.\n\nMesh non-orthogonality arises when the face area vector $\\boldsymbol{S}_f$ is not parallel to the centroid vector $\\boldsymbol{d}$. To systematically account for this, the vector $\\boldsymbol{S}_f$ is decomposed into two components: one parallel to $\\boldsymbol{d}$ and one perpendicular to $\\boldsymbol{d}$. Let $\\boldsymbol{e}_d = \\boldsymbol{d}/|\\boldsymbol{d}|$ be the unit vector along the centroid-connecting line.\nThe parallel component, which we will call the \"orthogonal\" part of the area vector, is the projection of $\\boldsymbol{S}_f$ onto $\\boldsymbol{d}$:\n$$ \\boldsymbol{S}_{f, \\parallel} = (\\boldsymbol{S}_f \\cdot \\boldsymbol{e}_d) \\boldsymbol{e}_d = \\frac{(\\boldsymbol{S}_f \\cdot \\boldsymbol{d})}{|\\boldsymbol{d}|^2}\\boldsymbol{d} $$\nThe perpendicular component, which we will call the \"non-orthogonal\" part, is the remainder:\n$$ \\boldsymbol{S}_{f, \\perp} = \\boldsymbol{S}_f - \\boldsymbol{S}_{f, \\parallel} $$\nBy construction, $\\boldsymbol{S}_{f, \\perp} \\cdot \\boldsymbol{d} = 0$.\n\nUsing this decomposition, the exact term $\\boldsymbol{S}_f \\cdot \\nabla\\phi$ can be split into two parts:\n$$ \\boldsymbol{S}_f \\cdot \\nabla\\phi = (\\boldsymbol{S}_{f, \\parallel} + \\boldsymbol{S}_{f, \\perp}) \\cdot \\nabla\\phi = \\underbrace{\\boldsymbol{S}_{f, \\parallel} \\cdot \\nabla\\phi}_{\\text{Orthogonal part}} + \\underbrace{\\boldsymbol{S}_{f, \\perp} \\cdot \\nabla\\phi}_{\\text{Non-orthogonal part}} $$\nThe orthogonal approximation for the face flux term considers only the first part, as it can be directly related to the cell-center values $\\phi_P$ and $\\phi_N$:\n$$ (\\boldsymbol{S}_f \\cdot \\nabla\\phi)_{\\text{orth approx}} = \\boldsymbol{S}_{f, \\parallel} \\cdot \\nabla\\phi = \\frac{(\\boldsymbol{S}_f \\cdot \\boldsymbol{d})}{|\\boldsymbol{d}|^2}(\\boldsymbol{d} \\cdot \\nabla\\phi) = \\frac{(\\boldsymbol{S}_f \\cdot \\boldsymbol{d})}{|\\boldsymbol{d}|^2}(\\phi_N - \\phi_P) $$\nThe non-orthogonality-induced face error is the difference between the exact term and this orthogonal approximation:\n$$ \\text{Error} = (\\boldsymbol{S}_f \\cdot \\nabla\\phi) - (\\boldsymbol{S}_f \\cdot \\nabla\\phi)_{\\text{orth approx}} = \\boldsymbol{S}_{f, \\perp} \\cdot \\nabla\\phi $$\nConsequently, to recover the exact face contribution for a linear field, a non-orthogonal correction term equal to this error must be added to the orthogonal approximation. The proposed non-orthogonal correction term is thus $C_{\\text{non-orth}} = \\boldsymbol{S}_{f, \\perp} \\cdot \\nabla\\phi$.\n\nThe total diffusive flux through the face is then given by:\n$$ F_f = -\\Gamma [(\\boldsymbol{S}_f \\cdot \\nabla\\phi)_{\\text{orth approx}} + C_{\\text{non-orth}}] $$\nThe contribution to the diffusive flux from the non-orthogonal correction is $-\\Gamma C_{\\text{non-orth}} = -\\Gamma(\\boldsymbol{S}_{f, \\perp} \\cdot \\nabla\\phi)$. We are asked to evaluate this quantity numerically.\n\nThe given nondimensional data are:\n- $\\boldsymbol{x}_P = (0,\\,0,\\,0)$\n- $\\boldsymbol{x}_N = (1,\\,0.2,\\,0)$\n- $\\boldsymbol{S}_f = (0.24,\\,0.18,\\,0)$\n- $\\nabla \\phi = (2.5,\\,-0.7,\\,1.2)$\n- $\\Gamma = 2$\n\nFirst, we calculate the geometric vectors needed.\nThe centroid-to-centroid vector is:\n$$ \\boldsymbol{d} = \\boldsymbol{x}_N - \\boldsymbol{x}_P = (1,\\,0.2,\\,0) - (0,\\,0,\\,0) = (1,\\,0.2,\\,0) $$\nThe squared magnitude of $\\boldsymbol{d}$ is:\n$$ |\\boldsymbol{d}|^2 = 1^2 + 0.2^2 + 0^2 = 1 + 0.04 = 1.04 $$\nNext, we calculate the dot product of the face area vector and the centroid vector:\n$$ \\boldsymbol{S}_f \\cdot \\boldsymbol{d} = (0.24)(1) + (0.18)(0.2) + (0)(0) = 0.24 + 0.036 = 0.276 $$\nNow, we find the non-orthogonal component of the area vector, $\\boldsymbol{S}_{f, \\perp}$:\n$$ \\boldsymbol{S}_{f, \\perp} = \\boldsymbol{S}_f - \\frac{\\boldsymbol{S}_f \\cdot \\boldsymbol{d}}{|\\boldsymbol{d}|^2}\\boldsymbol{d} $$\n$$ \\boldsymbol{S}_{f, \\perp} = (0.24,\\,0.18,\\,0) - \\frac{0.276}{1.04}(1,\\,0.2,\\,0) $$\nThe scalar fraction is $\\frac{0.276}{1.04} = \\frac{276}{1040} = \\frac{69}{260}$.\n$$ \\boldsymbol{S}_{f, \\perp} = (0.24,\\,0.18,\\,0) - (\\frac{69}{260}, \\frac{69}{260} \\times 0.2, 0) = (0.24 - \\frac{69}{260}, 0.18 - \\frac{13.8}{260}, 0) $$\nCalculating the components:\n$x$-component: $0.24 - \\frac{69}{260} = \\frac{6}{25} - \\frac{69}{260} = \\frac{6 \\times 52 - 69 \\times 5}{1300} = \\frac{312 - 345}{1300} = -\\frac{33}{1300}$.\n$y$-component: $0.18 - \\frac{13.8}{260} = \\frac{18}{100} - \\frac{13.8}{260} = \\frac{9}{50} - \\frac{69}{1300} = \\frac{9 \\times 26 - 69}{1300} = \\frac{234 - 69}{1300} = \\frac{165}{1300}$.\nSo, the non-orthogonal vector component is:\n$$ \\boldsymbol{S}_{f, \\perp} = \\left(-\\frac{33}{1300}, \\frac{165}{1300}, 0\\right) $$\nThe non-orthogonal correction term, $C_{\\text{non-orth}}$, is the dot product of this vector with the gradient $\\nabla\\phi$:\n$$ C_{\\text{non-orth}} = \\boldsymbol{S}_{f, \\perp} \\cdot \\nabla\\phi = \\left(-\\frac{33}{1300}\\right)(2.5) + \\left(\\frac{165}{1300}\\right)(-0.7) + (0)(1.2) $$\n$$ C_{\\text{non-orth}} = \\frac{(-33)(2.5) + (165)(-0.7)}{1300} = \\frac{-82.5 - 115.5}{1300} = \\frac{-198}{1300} = -\\frac{99}{650} $$\nFinally, the non-orthogonal correction contribution to the diffusive flux through the face is:\n$$ \\text{Flux Correction} = -\\Gamma C_{\\text{non-orth}} = -2 \\times \\left(-\\frac{99}{650}\\right) = \\frac{198}{650} = \\frac{99}{325} $$\nTo provide the numerical answer, we evaluate this fraction:\n$$ \\frac{99}{325} \\approx 0.30461538... $$\nRounding to four significant figures, the result is $0.3046$.",
            "answer": "$$\\boxed{0.3046}$$"
        },
        {
            "introduction": "Accurate flux calculations, especially for diffusive terms and higher-order convective schemes, require precise knowledge of flow variable gradients at cell faces or nodes. This practice  guides you through implementing a widely-used technique for gradient reconstruction: the least-squares method. You will investigate how weighting strategies, such as inverse-distance weighting, enhance the robustness and accuracy of the gradient calculation on the irregular and skewed meshes common in aerospace applications.",
            "id": "3980510",
            "problem": "In two-dimensional Computational Fluid Dynamics (CFD), specifically within the Finite Volume Method (FVM), it is common to reconstruct gradients at a node from surrounding control-volume centers and face-based data. Consider a scalar field $\\phi(x,y)$ defined smoothly in a neighborhood of a node located at position $\\boldsymbol{x}_0 = (x_0,y_0)$. The goal is to compute the gradient vector $\\nabla \\phi(\\boldsymbol{x}_0)$ from $N$ neighboring samples $\\{\\phi_i\\}$ located at positions $\\boldsymbol{x}_i = (x_i,y_i)$ surrounding $\\boldsymbol{x}_0$, where some of these positions may correspond to neighboring cell centers and others to face centroids.\n\nStarting from the Taylor expansion of $\\phi$ about $\\boldsymbol{x}_0$ and denoting $\\boldsymbol{r}_i = \\boldsymbol{x}_i - \\boldsymbol{x}_0$, define the least-squares gradient at the node as the minimizer $\\boldsymbol{g}$ of the quadratic misfit\n$$\nJ(\\boldsymbol{g}) = \\sum_{i=1}^{N} w_i \\left(\\phi_i - \\phi_0 - \\boldsymbol{g} \\cdot \\boldsymbol{r}_i \\right)^2,\n$$\nwhere $\\phi_0 = \\phi(\\boldsymbol{x}_0)$ and $w_i$ are nonnegative weights. Two cases must be implemented:\n- Unweighted least squares: $w_i = 1$ for all $i$.\n- Inverse-distance weighted least squares: $w_i = \\frac{1}{\\lVert \\boldsymbol{r}_i \\rVert}$ for all $i$, where $\\lVert \\cdot \\rVert$ denotes the Euclidean norm.\n\nUse the following scalar field, which represents a generic smooth field composed of a linear term and weak curvature, ensuring a nontrivial test:\n$$\n\\phi(x,y) = 3 x - 2 y + \\tfrac{1}{2} x^2 + \\tfrac{1}{4} x y.\n$$\nThe exact gradient at any point $(x,y)$ is\n$$\n\\nabla \\phi(x,y) = \\left( 3 + x + \\tfrac{1}{4} y,\\; -2 + \\tfrac{1}{4} x \\right).\n$$\n\nYour program must, for each test case below, compute the unweighted and inverse-distance weighted least-squares gradient approximations at the specified node, and report the relative Euclidean error of each with respect to the exact gradient, defined as\n$$\n\\varepsilon = \\frac{\\lVert \\boldsymbol{g}_{\\text{approx}} - \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}{\\lVert \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}.\n$$\n\nIf noise is present in a test, it is added to the neighbor scalar values $\\phi_i$ but not to $\\phi_0$. Angles are not used. No physical units are required. All outputs are dimensionless.\n\nImplement the algorithm in a single program that evaluates the following test suite of neighbor positions. In each case, the node position $\\boldsymbol{x}_0$ and neighbor set $\\{\\boldsymbol{x}_i\\}_{i=1}^N$ are specified:\n\n- Test case $1$ (isotropic neighbors around $\\boldsymbol{x}_0$ representing a well-shaped mesh with both cell centers and face midpoints):\n  - Node: $\\boldsymbol{x}_0 = (0, 0)$.\n  - Neighbors:\n    - $(1, 0)$, $(-1, 0)$, $(0, 1)$, $(0, -1)$,\n    - $(0.7, 0.7)$, $(-0.7, 0.7)$, $(0.7, -0.7)$, $(-0.7, -0.7)$.\n  - Noise: none.\n\n- Test case $2$ (highly anisotropic cluster near $\\boldsymbol{x}_0$ with a distant outlier simulating a skewed control-volume adjacency with an outlying face center):\n  - Node: $\\boldsymbol{x}_0 = (0, 0)$.\n  - Neighbors:\n    - $(0.05, -0.01)$, $(0.10, 0.00)$, $(0.15, 0.01)$, $(0.20, -0.02)$, $(5.0, 3.0)$.\n  - Noise: none.\n\n- Test case $3$ (irregular neighbors with small measurement noise on $\\phi_i$):\n  - Node: $\\boldsymbol{x}_0 = (0, 0)$.\n  - Neighbors:\n    - $(0.2, 0.3)$, $(-0.25, 0.1)$, $(0.4, -0.35)$, $(-0.6, -0.2)$, $(1.2, 0.8)$, $(-1.0, 0.9)$.\n  - Additive noise on neighbor values $\\phi_i$ (in the same order as neighbors): $[5 \\times 10^{-4},\\; -4 \\times 10^{-4},\\; 3 \\times 10^{-4},\\; -2 \\times 10^{-4},\\; 1 \\times 10^{-4},\\; -1 \\times 10^{-4}]$.\n  - No noise on $\\phi_0$.\n\n- Test case $4$ (skewed neighbors around $\\boldsymbol{x}_0$ away from the origin, combining near-collinear cell centers and a few off-axis face points):\n  - Node: $\\boldsymbol{x}_0 = (1.0, -0.5)$.\n  - Neighbors:\n    - $(1.05, -0.49)$, $(1.10, -0.51)$, $(1.15, -0.48)$, $(1.20, -0.52)$, $(1.02, -0.30)$, $(0.90, -0.70)$.\n  - Noise: none.\n\nFor each test case, compute:\n- The unweighted relative error $\\varepsilon_{\\text{unw}}$.\n- The inverse-distance weighted relative error $\\varepsilon_{\\text{w}}$ with $w_i = 1 / \\lVert \\boldsymbol{r}_i \\rVert$.\n- A boolean flag indicating whether the inverse-distance weighting improved the result, i.e., whether $\\varepsilon_{\\text{w}} < \\varepsilon_{\\text{unw}}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- Each test case contributes a three-element list of the form $[\\varepsilon_{\\text{unw}}, \\varepsilon_{\\text{w}}, \\text{better}]$, where $\\text{better}$ is a boolean indicating whether the weighted error is strictly smaller than the unweighted error.\n- The two error values for each test must be rounded to $8$ decimal places.\n- Example format: $[[0.00123456,0.00098765,\\text{True}],\\ldots]$.\n\nThe program must be self-contained and require no input. It must compute all neighbor values $\\phi_i$ from the given $\\phi(x,y)$ and apply noise where specified. The computation should be entirely in floating-point arithmetic with no unit conversions required. The goal is to demonstrate, through these test cases, how inverse-distance weighting confers robustness on irregular meshes by reducing the influence of distant or poorly distributed neighbors in the least-squares gradient reconstruction at a node.",
            "solution": "We start from the Taylor expansion of a smooth scalar field $\\phi$ about a point $\\boldsymbol{x}_0 = (x_0,y_0)$, evaluated at neighboring positions $\\boldsymbol{x}_i = (x_i,y_i)$:\n$$\n\\phi(\\boldsymbol{x}_i) = \\phi(\\boldsymbol{x}_0) + \\nabla \\phi(\\boldsymbol{x}_0) \\cdot \\boldsymbol{r}_i + \\mathcal{O}(\\lVert \\boldsymbol{r}_i \\rVert^2),\n$$\nwhere $\\boldsymbol{r}_i = \\boldsymbol{x}_i - \\boldsymbol{x}_0$. If we let $\\boldsymbol{g}$ denote an approximation to $\\nabla \\phi(\\boldsymbol{x}_0)$ and define the residuals\n$$\n\\delta_i(\\boldsymbol{g}) = \\phi_i - \\phi_0 - \\boldsymbol{g} \\cdot \\boldsymbol{r}_i,\n$$\nthen a least-squares estimate seeks $\\boldsymbol{g}$ minimizing the sum of squares of $\\delta_i$. To incorporate geometric information, we introduce nonnegative weights $w_i$ and minimize\n$$\nJ(\\boldsymbol{g}) = \\sum_{i=1}^{N} w_i \\, \\delta_i(\\boldsymbol{g})^2.\n$$\nLet $A \\in \\mathbb{R}^{N \\times 2}$ be the design matrix with $i$th row $A_i = \\boldsymbol{r}_i^\\top$, and let $b \\in \\mathbb{R}^{N}$ be the vector with entries $b_i = \\phi_i - \\phi_0$. Let $W = \\mathrm{diag}(w_1,\\ldots,w_N)$. Then\n$$\nJ(\\boldsymbol{g}) = \\lVert W^{1/2}(A \\boldsymbol{g} - b) \\rVert_2^2.\n$$\nThe first-order optimality condition yields the weighted normal equations\n$$\n(A^\\top W A)\\, \\boldsymbol{g} = A^\\top W b.\n$$\nWhen $A^\\top W A$ is nonsingular, the solution is\n$$\n\\boldsymbol{g} = (A^\\top W A)^{-1} A^\\top W b.\n$$\nNumerically, it is advantageous to avoid explicitly forming the inverse. One can instead solve the least-squares problem by forming $\\tilde{A} = W^{1/2} A$ and $\\tilde{b} = W^{1/2} b$, and then using a robust least-squares solver (for example, a QR-based method). In practice, with the given small sizes, the function $\\texttt{numpy.linalg.lstsq}$ computes a stable solution for $\\min_{\\boldsymbol{g}} \\lVert \\tilde{A} \\boldsymbol{g} - \\tilde{b} \\rVert_2$.\n\nChoice of weights:\n- Unweighted: $w_i = 1$ emphasizes all neighbors equally.\n- Inverse-distance: $w_i = 1 / \\lVert \\boldsymbol{r}_i \\rVert$ downweights distant neighbors. This improves robustness on irregular meshes because the truncation error from neglected higher-order Taylor terms grows with $\\lVert \\boldsymbol{r}_i \\rVert^2$, and geometric anisotropy or outliers can bias the fit unless distant samples are downweighted.\n\nWe test with the scalar field\n$$\n\\phi(x,y) = 3 x - 2 y + \\tfrac{1}{2} x^2 + \\tfrac{1}{4} x y,\n$$\nwhose gradient is\n$$\n\\nabla \\phi(x,y) = \\left( 3 + x + \\tfrac{1}{4} y,\\; -2 + \\tfrac{1}{4} x \\right).\n$$\nAt each node $\\boldsymbol{x}_0$, we compute $\\phi_0 = \\phi(\\boldsymbol{x}_0)$, then assemble neighbor values $\\phi_i = \\phi(\\boldsymbol{x}_i)$, optionally adding specified noise. We then construct $A$ and $b$, solve for $\\boldsymbol{g}$ in both unweighted and weighted cases, and compute the relative Euclidean errors\n$$\n\\varepsilon_{\\text{unw}} = \\frac{\\lVert \\boldsymbol{g}_{\\text{unw}} - \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}{\\lVert \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}, \\quad\n\\varepsilon_{\\text{w}} = \\frac{\\lVert \\boldsymbol{g}_{\\text{w}} - \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}{\\lVert \\nabla \\phi(\\boldsymbol{x}_0) \\rVert_2}.\n$$\n\nAlgorithmic steps for each test case:\n- Step $1$: Compute $\\phi_0 = \\phi(\\boldsymbol{x}_0)$ and $\\phi_i = \\phi(\\boldsymbol{x}_i)$; add noise to $\\phi_i$ if specified, leaving $\\phi_0$ noise-free.\n- Step $2$: Form $A$ with rows $\\boldsymbol{r}_i^\\top = (\\Delta x_i,\\Delta y_i)$ where $\\Delta x_i = x_i - x_0$ and $\\Delta y_i = y_i - y_0$, and $b$ with entries $\\phi_i - \\phi_0$.\n- Step $3$: For unweighted least squares, set $w_i = 1$, $\\tilde{A} = A$, $\\tilde{b} = b$; compute $\\boldsymbol{g}_{\\text{unw}}$ by solving $\\min \\lVert \\tilde{A} \\boldsymbol{g} - \\tilde{b} \\rVert_2$.\n- Step $4$: For inverse-distance weights, set $w_i = 1/\\lVert \\boldsymbol{r}_i \\rVert$, define $\\tilde{A}_i = \\sqrt{w_i} A_i$ and $\\tilde{b}_i = \\sqrt{w_i} b_i$, then compute $\\boldsymbol{g}_{\\text{w}}$ similarly.\n- Step $5$: Evaluate the exact gradient $\\nabla \\phi(\\boldsymbol{x}_0)$ and compute $\\varepsilon_{\\text{unw}}$ and $\\varepsilon_{\\text{w}}$.\n- Step $6$: Determine the boolean $\\text{better}$ indicating whether $\\varepsilon_{\\text{w}} < \\varepsilon_{\\text{unw}}$.\n- Step $7$: Round $\\varepsilon_{\\text{unw}}$ and $\\varepsilon_{\\text{w}}$ to $8$ decimal places and collect the triple $[\\varepsilon_{\\text{unw}}, \\varepsilon_{\\text{w}}, \\text{better}]$.\n\nInterpretation of test cases:\n- Test $1$ features nearly isotropic coverage, so both methods should perform well; inverse-distance weighting may confer little advantage in this well-conditioned case.\n- Test $2$ includes a distant outlier; unweighted least squares can be biased by the outlier because higher-order terms in $\\phi$ grow with distance, whereas inverse-distance weighting suppresses the outlierâ€™s influence, improving robustness.\n- Test $3$ introduces small measurement noise; inverse-distance weighting reduces the impact of noisy distant samples relative to close neighbors, potentially improving the estimate.\n- Test $4$ presents a skewed neighbor set at a nonorigin node; the geometry can be near-degenerate without sufficient angular spread, and downweighting more distant or less informative directions can help stabilize the reconstruction.\n\nThe program implements these steps directly, using $\\texttt{numpy.linalg.lstsq}$ on the weighted system for numerical stability. The final printed line is a list of per-test triples $[\\varepsilon_{\\text{unw}}, \\varepsilon_{\\text{w}}, \\text{better}]$ with errors rounded to $8$ decimal places, demonstrating the effect of inverse-distance weighting on irregular meshes.",
            "answer": "```python\nimport numpy as np\n\ndef phi(x, y):\n    # phi(x,y) = 3x - 2y + 0.5 x^2 + 0.25 x y\n    return 3.0 * x - 2.0 * y + 0.5 * x * x + 0.25 * x * y\n\ndef grad_phi_exact(x, y):\n    # grad phi = [3 + x + 0.25 y, -2 + 0.25 x]\n    return np.array([3.0 + x + 0.25 * y, -2.0 + 0.25 * x], dtype=float)\n\ndef ls_gradient(x0, neighbors, phi_values, weighted):\n    \"\"\"\n    Compute least-squares gradient at node x0 from neighbor coordinates and phi values.\n    Parameters:\n        x0: (2,) ndarray\n        neighbors: (N,2) ndarray of neighbor coords\n        phi_values: (N,) ndarray of phi at neighbors (possibly noisy)\n        weighted: bool, if True use inverse-distance weights\n    Returns:\n        g: (2,) ndarray gradient\n    \"\"\"\n    x0 = np.asarray(x0, dtype=float)\n    X = np.asarray(neighbors, dtype=float)\n    r = X - x0[None, :]\n    N = r.shape[0]\n    A = r  # N x 2\n    phi0 = phi(x0[0], x0[1])\n    b = phi_values - phi0  # N\n    if weighted:\n        # Inverse-distance weights\n        d = np.linalg.norm(r, axis=1)\n        # All distances are nonzero per problem setup.\n        w = 1.0 / d\n        sqrtw = np.sqrt(w)\n        Aw = A * sqrtw[:, None]\n        bw = b * sqrtw\n        g, _, _, _ = np.linalg.lstsq(Aw, bw, rcond=None)\n    else:\n        g, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n    return g\n\ndef relative_error(g, g_exact):\n    return np.linalg.norm(g - g_exact) / np.linalg.norm(g_exact)\n\ndef solve():\n    # Define test cases according to the problem statement.\n    test_cases = []\n\n    # Test case 1\n    x0_1 = np.array([0.0, 0.0], dtype=float)\n    neighbors_1 = np.array([\n        [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0],\n        [0.7, 0.7], [-0.7, 0.7], [0.7, -0.7], [-0.7, -0.7]\n    ], dtype=float)\n    noise_1 = None\n    test_cases.append((x0_1, neighbors_1, noise_1))\n\n    # Test case 2\n    x0_2 = np.array([0.0, 0.0], dtype=float)\n    neighbors_2 = np.array([\n        [0.05, -0.01], [0.10, 0.00], [0.15, 0.01], [0.20, -0.02], [5.0, 3.0]\n    ], dtype=float)\n    noise_2 = None\n    test_cases.append((x0_2, neighbors_2, noise_2))\n\n    # Test case 3\n    x0_3 = np.array([0.0, 0.0], dtype=float)\n    neighbors_3 = np.array([\n        [0.2, 0.3], [-0.25, 0.1], [0.4, -0.35], [-0.6, -0.2], [1.2, 0.8], [-1.0, 0.9]\n    ], dtype=float)\n    noise_3 = np.array([5e-4, -4e-4, 3e-4, -2e-4, 1e-4, -1e-4], dtype=float)\n    test_cases.append((x0_3, neighbors_3, noise_3))\n\n    # Test case 4\n    x0_4 = np.array([1.0, -0.5], dtype=float)\n    neighbors_4 = np.array([\n        [1.05, -0.49], [1.10, -0.51], [1.15, -0.48], [1.20, -0.52],\n        [1.02, -0.30], [0.90, -0.70]\n    ], dtype=float)\n    noise_4 = None\n    test_cases.append((x0_4, neighbors_4, noise_4))\n\n    results = []\n    for x0, Xnbr, noise in test_cases:\n        # Compute phi at neighbors and apply noise if given\n        phi_vals = np.array([phi(x, y) for x, y in Xnbr], dtype=float)\n        if noise is not None:\n            phi_vals = phi_vals + noise\n        # Exact gradient at node\n        g_exact = grad_phi_exact(x0[0], x0[1])\n        # Unweighted gradient\n        g_unw = ls_gradient(x0, Xnbr, phi_vals, weighted=False)\n        # Weighted gradient\n        g_w = ls_gradient(x0, Xnbr, phi_vals, weighted=True)\n        # Relative errors\n        e_unw = relative_error(g_unw, g_exact)\n        e_w = relative_error(g_w, g_exact)\n        # Round to 8 decimals\n        e_unw_r = float(f\"{e_unw:.8f}\")\n        e_w_r = float(f\"{e_w:.8f}\")\n        better = e_w  e_unw\n        results.append([e_unw_r, e_w_r, better])\n\n    # Final print statement in the exact required format.\n    print(f\"{results}\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}