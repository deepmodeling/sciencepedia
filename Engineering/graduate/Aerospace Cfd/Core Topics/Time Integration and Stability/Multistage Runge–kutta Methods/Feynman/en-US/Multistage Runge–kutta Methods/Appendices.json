{
    "hands_on_practices": [
        {
            "introduction": "Before analyzing the complex behavior of advanced schemes, it is crucial to master the fundamental language used to describe them. This first practice focuses on the classical fourth-order Runge-Kutta method (RK4), a workhorse in many scientific domains. By translating its familiar formulation into the compact and powerful Butcher tableau notation, you will build a solid foundation for understanding the structure of all Runge-Kutta methods .",
            "id": "3978547",
            "problem": "A compressible flow solver based on the method of lines discretizes the spatial operators in the compressible Navier–Stokes equations to obtain a system of ordinary differential equations (ODEs) in time of the form $\\frac{d\\boldsymbol{U}}{dt}=\\boldsymbol{L}(\\boldsymbol{U},t)$, where $\\boldsymbol{U}$ is the vector of conservative variables and $\\boldsymbol{L}$ is the semi-discrete spatial operator. Time advancement is performed by an $s$-stage explicit Runge–Kutta (RK) method, represented by a Butcher tableau with coefficient matrix $\\mathbf{A}=\\{a_{ij}\\}$, weights $\\boldsymbol{b}=\\{b_i\\}$, and stage abscissae $\\boldsymbol{c}=\\{c_i\\}$.\n\nConsider the standard classical four-stage fourth-order explicit Runge–Kutta method (commonly used in aerospace computational fluid dynamics (CFD)). \n\nTasks:\n- Write its Butcher tableau $(\\mathbf{A},\\boldsymbol{b},\\boldsymbol{c})$.\n- Using the definition of stage values for explicit Runge–Kutta methods applied to $\\frac{dy}{dt}=f(t,y)$ with stage updates $Y_i=y^n+\\Delta t\\sum_{j=1}^{i-1}a_{ij}f(t^n+c_j\\Delta t,Y_j)$ and $y^{n+1}=y^n+\\Delta t\\sum_{i=1}^s b_i f(t^n+c_i\\Delta t,Y_i)$, derive and verify the internal consistency condition $c_i=\\sum_{j=1}^{i-1}a_{ij}$ for each stage $i$ of this explicit method.\n- Define the scalar residual\n$$\nR \\equiv \\sum_{i=1}^{s}\\left(c_i-\\sum_{j=1}^{i-1}a_{ij}\\right)^{2}.\n$$\nCompute $R$ for the classical four-stage fourth-order explicit Runge–Kutta method. Express the final result as an exact, dimensionless real number with no rounding.",
            "solution": "The problem has been validated as scientifically grounded, well-posed, objective, and complete. It presents a standard set of tasks related to the classical four-stage, fourth-order explicit Runge–Kutta method, a cornerstone of numerical analysis for ordinary differential equations. The definitions and context provided are standard in the field of computational science and engineering. We may therefore proceed with a full solution.\n\nThe problem asks for three tasks concerning the classical four-stage fourth-order explicit Runge–Kutta (RK4) method applied to an ordinary differential equation (ODE) of the form $\\frac{dy}{dt} = f(t,y)$.\n\n**Task 1: Butcher Tableau for Classical RK4**\n\nThe classical RK4 method is defined by the following sequence of stage calculations for a step from time $t^n$ to $t^{n+1} = t^n + \\Delta t$:\n$$\nk_1 = f(t^n, y^n) \\\\\nk_2 = f\\left(t^n + \\frac{1}{2}\\Delta t, y^n + \\frac{1}{2}\\Delta t k_1\\right) \\\\\nk_3 = f\\left(t^n + \\frac{1}{2}\\Delta t, y^n + \\frac{1}{2}\\Delta t k_2\\right) \\\\\nk_4 = f\\left(t^n + \\Delta t, y^n + \\Delta t k_3\\right)\n$$\nThe solution is then advanced using a weighted average of these stage derivatives:\n$$\ny^{n+1} = y^n + \\frac{\\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nThe general form of an $s$-stage explicit Runge–Kutta method is given by a Butcher tableau:\n$$\n\\begin{array}{c|c}\n\\boldsymbol{c} & A \\\\\n\\hline\n& \\boldsymbol{b}^T\n\\end{array}\n=\n\\begin{array}{c|cccc}\nc_1 & a_{11} & a_{12} & \\dots & a_{1s} \\\\\nc_2 & a_{21} & a_{22} & \\dots & a_{2s} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\nc_s & a_{s1} & a_{s2} & \\dots & a_{ss} \\\\\n\\hline\n& b_1 & b_2 & \\dots & b_s\n\\end{array}\n$$\nThe stage values $Y_i$ and stage derivatives $k_i$ are defined as:\n$$\nY_i = y^n + \\Delta t \\sum_{j=1}^{s} a_{ij} k_j \\quad \\text{and} \\quad k_i = f(t^n + c_i \\Delta t, Y_i)\n$$\nFor an explicit method, the matrix $A$ is strictly lower triangular, meaning $a_{ij} = 0$ for $j \\ge i$. The sum for $Y_i$ thus becomes $\\sum_{j=1}^{i-1} a_{ij} k_j$.\n\nBy comparing the standard RK4 formulation with the general form, we can extract the coefficients.\nThe stage time fractions $c_i$ are the coefficients of $\\Delta t$ in the time arguments of $f$:\n$c_1 = 0$, $c_2 = \\frac{1}{2}$, $c_3 = \\frac{1}{2}$, $c_4 = 1$. The vector $\\boldsymbol{c}$ is $\\boldsymbol{c} = \\begin{pmatrix} 0 & \\frac{1}{2} & \\frac{1}{2} & 1 \\end{pmatrix}^T$.\n\nThe coefficients $a_{ij}$ are the coefficients of $\\Delta t k_j$ used to compute the argument of $f$ for stage $i$.\nFor $k_1$: The argument is $y^n$. This corresponds to $Y_1 = y^n$. The sum $\\sum a_{1j}k_j$ is empty.\nFor $k_2$: The argument is $y^n + \\frac{1}{2} \\Delta t k_1$. This means $Y_2 = y^n + \\frac{1}{2}\\Delta t k_1$. Comparing to $Y_2 = y^n + \\Delta t (a_{21} k_1 + \\dots)$, we find $a_{21} = \\frac{1}{2}$ and other $a_{2j}$ are $0$.\nFor $k_3$: The argument is $y^n + \\frac{1}{2} \\Delta t k_2$. This means $Y_3 = y^n + \\frac{1}{2}\\Delta t k_2$. Comparing to $Y_3 = y^n + \\Delta t (a_{31} k_1 + a_{32} k_2 + \\dots)$, we find $a_{31} = 0$ and $a_{32} = \\frac{1}{2}$.\nFor $k_4$: The argument is $y^n + \\Delta t k_3$. This means $Y_4 = y^n + \\Delta t k_3$. Comparing to $Y_4 = y^n + \\Delta t (a_{41} k_1 + a_{42} k_2 + a_{43} k_3 + \\dots)$, we find $a_{41} = 0$, $a_{42} = 0$, and $a_{43} = 1$.\nThe matrix $A$ is therefore:\n$$\nA = \\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n\\frac{1}{2} & 0 & 0 & 0 \\\\\n0 & \\frac{1}{2} & 0 & 0 \\\\\n0 & 0 & 1 & 0\n\\end{pmatrix}\n$$\nThe final weights $b_i$ are the coefficients in the update formula $y^{n+1} = y^n + \\Delta t \\sum_{i=1}^s b_i k_i$.\nFrom $y^{n+1} = y^n + \\frac{\\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4)$, we have:\n$b_1 = \\frac{1}{6}$, $b_2 = \\frac{2}{6} = \\frac{1}{3}$, $b_3 = \\frac{2}{6} = \\frac{1}{3}$, $b_4 = \\frac{1}{6}$. The vector $\\boldsymbol{b}$ is $\\boldsymbol{b} = \\begin{pmatrix} \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{6} \\end{pmatrix}^T$.\n\nCombining these, the Butcher tableau for the classical RK4 method is:\n$$\n\\begin{array}{c|cccc}\n0 & 0 & 0 & 0 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} & 0 & 0 \\\\\n1 & 0 & 0 & 1 & 0 \\\\\n\\hline\n& \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{6}\n\\end{array}\n$$\n\n**Task 2: Derivation and Verification of the Consistency Condition**\n\nThe internal consistency condition $c_i = \\sum_{j=1}^{i-1} a_{ij}$ relates the stage time fractions to the coefficients of the method. It ensures that each stage provides an approximation that is at least first-order accurate.\n\nTo derive this condition, we consider a simple test problem: the autonomous ODE $\\frac{dy}{dt} = 1$ with initial condition $y(t^n)=t^n$. The exact solution is $y(t)=t$.\nThe stage derivatives are $k_j = f(t^n + c_j \\Delta t, Y_j) = 1$ for all $j$.\nThe stage value $Y_i$ is computed as specified in the problem statement for an explicit method:\n$$\nY_i = y^n + \\Delta t \\sum_{j=1}^{i-1} a_{ij} f(t^n+c_j \\Delta t, Y_j) = y^n + \\Delta t \\sum_{j=1}^{i-1} a_{ij} (1) = t^n + \\Delta t \\sum_{j=1}^{i-1} a_{ij}\n$$\nThe purpose of the stage calculation is to approximate the solution at the intermediate time $t^n + c_i \\Delta t$. For our test problem, the exact solution at this time is $y(t^n + c_i \\Delta t) = t^n + c_i \\Delta t$.\nFor the numerical stage value $Y_i$ to be consistent with the exact solution at the stage time, we must equate the two expressions:\n$$\nt^n + \\Delta t \\sum_{j=1}^{i-1} a_{ij} = t^n + c_i \\Delta t\n$$\nSubtracting $t^n$ and dividing by $\\Delta t \\neq 0$ yields the condition:\n$$\nc_i = \\sum_{j=1}^{i-1} a_{ij}\n$$\nThis derivation shows that this condition is necessary for the method to correctly integrate the function $y(t)=t$.\n\nNow, we verify this condition for each stage ($i=1, \\dots, 4$) of the classical RK4 method using the coefficients from its Butcher tableau.\n-   For stage $i=1$:\n    $c_1 = 0$. The sum is $\\sum_{j=1}^{0} a_{1j}$, which is an empty sum and defined as $0$. Thus, $0 = 0$. The condition holds.\n-   For stage $i=2$:\n    $c_2 = \\frac{1}{2}$. The sum is $\\sum_{j=1}^{1} a_{2j} = a_{21} = \\frac{1}{2}$. Thus, $\\frac{1}{2} = \\frac{1}{2}$. The condition holds.\n-   For stage $i=3$:\n    $c_3 = \\frac{1}{2}$. The sum is $\\sum_{j=1}^{2} a_{3j} = a_{31} + a_{32} = 0 + \\frac{1}{2} = \\frac{1}{2}$. Thus, $\\frac{1}{2} = \\frac{1}{2}$. The condition holds.\n-   For stage $i=4$:\n    $c_4 = 1$. The sum is $\\sum_{j=1}^{3} a_{4j} = a_{41} + a_{42} + a_{43} = 0 + 0 + 1 = 1$. Thus, $1 = 1$. The condition holds.\n\nThe internal consistency condition $c_i = \\sum_{j=1}^{i-1}a_{ij}$ is satisfied for all four stages of the classical RK4 method.\n\n**Task 3: Computation of the Scalar Residual $R$**\n\nThe scalar residual $R$ is defined as:\n$$\nR \\equiv \\sum_{i=1}^{s}\\left(c_i-\\sum_{j=1}^{i-1}a_{ij}\\right)^{2}\n$$\nFor the classical RK4 method, the number of stages is $s=4$. In the previous task, we verified that for each stage $i \\in \\{1, 2, 3, 4\\}$, the term inside the parentheses is exactly zero.\nLet's write out the sum for $R$:\n$$\nR = \\left(c_1 - \\sum_{j=1}^{0} a_{1j}\\right)^{2} + \\left(c_2 - \\sum_{j=1}^{1} a_{2j}\\right)^{2} + \\left(c_3 - \\sum_{j=1}^{2} a_{3j}\\right)^{2} + \\left(c_4 - \\sum_{j=1}^{3} a_{4j}\\right)^{2}\n$$\nSubstituting the values we computed in the verification step:\n-   Term 1 ($i=1$): $(0 - 0)^2 = 0^2 = 0$\n-   Term 2 ($i=2$): $(\\frac{1}{2} - \\frac{1}{2})^2 = 0^2 = 0$\n-   Term 3 ($i=3$): $(\\frac{1}{2} - \\frac{1}{2})^2 = 0^2 = 0$\n-   Term 4 ($i=4$): $(1 - 1)^2 = 0^2 = 0$\n\nSumming these terms gives the value of $R$:\n$$\nR = 0 + 0 + 0 + 0 = 0\n$$\nThe value of the scalar residual $R$ for the classical four-stage fourth-order explicit Runge–Kutta method is $0$. This result is a direct consequence of the method satisfying the internal consistency condition at every stage.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "While explicit methods like RK4 are popular, many aerospace CFD problems involving viscosity or complex chemical reactions are \"stiff\" and demand implicit time integrators for stable and efficient solution. This practice shifts the focus from analyzing existing methods to designing a new one. You will construct a two-stage Singly Diagonally Implicit Runge-Kutta (SDIRK) method by enforcing specific order and structural conditions, culminating in a scheme tailored for stiff systems .",
            "id": "3978520",
            "problem": "Consider a semi-discrete formulation of the compressible Navier–Stokes equations obtained by spatial discretization on an unstructured mesh, which yields a stiff system of ordinary differential equations of the form $\\dot{\\boldsymbol{u}} = \\mathbf{f}(\\boldsymbol{u})$. To march this system in time in a robust way, design a two-stage Singly Diagonally Implicit Runge–Kutta (SDIRK) method, meaning a Runge–Kutta method with identical diagonal coefficients in its coefficient matrix.\n\nConstruct a two-stage SDIRK method of order $2$ with the following design choices motivated by aerospace computational fluid dynamics practice:\n1. The second stage abscissa is placed at the end of the time step, i.e., $c_{2} = 1$.\n2. The method is stiffly accurate, i.e., the solution update weights are equal to the coefficients of the last row of the Runge–Kutta matrix.\n\nStarting from the fundamental Runge–Kutta definitions and order conditions, derive the method’s coefficients symbolically in terms of the common diagonal value and enforce order $2$ accuracy. Then, using the linear test equation $y' = \\lambda y$ with $z = h \\lambda$ and the fundamental stability function definition for Runge–Kutta methods, derive the method’s stability function and determine the diagonal coefficient value that ensures absolute stability over the entire left half of the complex plane (A-stability).\n\nExpress your final answer as the exact symbolic value of the diagonal coefficient. No rounding is required. No units are to be reported in the final answer.",
            "solution": "The problem requires the design of a two-stage, second-order, stiffly accurate Singly Diagonally Implicit Runge–Kutta (SDIRK) method, with the final stage at the end of the time step, and the determination of its diagonal coefficient to ensure A-stability.\n\nA general $s$-stage Runge–Kutta method is defined by its Butcher tableau:\n$$\n\\begin{array}{c|c}\n\\mathbf{c} & \\mathbf{A} \\\\\n\\hline\n& \\mathbf{b}^T\n\\end{array}\n$$\nwhere $\\mathbf{c}$ is the vector of stage times, $\\mathbf{A}$ is the matrix of Runge–Kutta coefficients, and $\\mathbf{b}$ is the vector of solution update weights.\n\nFor the specified two-stage ($s=2$) SDIRK method, the Butcher tableau has a specific structure. The term \"Singly Diagonally Implicit\" implies that the coefficient matrix $\\mathbf{A}$ is lower triangular and all its diagonal elements are equal to a common value, which we will denote by $\\gamma$.\n$$\n\\mathbf{A} = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix} = \\begin{pmatrix} \\gamma & 0 \\\\ a_{21} & \\gamma \\end{pmatrix}\n$$\nThe stage time abscissas $c_i$ are related to the matrix coefficients by the row-sum conditions $c_i = \\sum_{j=1}^{s} a_{ij}$. For our two-stage method, this gives:\n$$\nc_1 = \\gamma \\\\\nc_2 = a_{21} + \\gamma\n$$\nThe problem specifies two design choices:\n1.  The second stage is at the end of the time step: $c_2 = 1$. Substituting this into the second row-sum condition gives $1 = a_{21} + \\gamma$, which allows us to express $a_{21}$ in terms of $\\gamma$: $a_{21} = 1 - \\gamma$.\n2.  The method is stiffly accurate. This means the solution update weights are identical to the coefficients of the last row of the $\\mathbf{A}$ matrix: $b_j = a_{sj}$ for $j=1, ..., s$. For $s=2$, this means $b_1 = a_{21}$ and $b_2 = a_{22}$. Therefore, $b_1 = 1 - \\gamma$ and $b_2 = \\gamma$.\n\nWith these constraints, the Butcher tableau is fully characterized by the single parameter $\\gamma$:\n$$\n\\begin{array}{c|cc}\n\\gamma & \\gamma & 0 \\\\\n1 & 1-\\gamma & \\gamma \\\\\n\\hline\n& 1-\\gamma & \\gamma\n\\end{array}\n$$\nNext, we enforce the condition that the method must be of order $2$. The order conditions for a Runge–Kutta method are:\n- Order $1$: $\\sum_{i=1}^s b_i = 1$.\n  Checking this condition: $b_1 + b_2 = (1-\\gamma) + \\gamma = 1$. The order $1$ condition is satisfied for any choice of $\\gamma$. This is a known property of stiffly accurate methods where $c_s = 1$.\n- Order $2$: $\\sum_{i=1}^s b_i c_i = \\frac{1}{2}$.\n  Substituting our coefficients: $b_1 c_1 + b_2 c_2 = (1-\\gamma)(\\gamma) + (\\gamma)(1) = \\gamma - \\gamma^2 + \\gamma = 2\\gamma - \\gamma^2$.\n  Equating this to $\\frac{1}{2}$ gives the equation for $\\gamma$:\n  $$\n  2\\gamma - \\gamma^2 = \\frac{1}{2}\n  $$\n  Rearranging this into a standard quadratic form gives:\n  $$\n  \\gamma^2 - 2\\gamma + \\frac{1}{2} = 0\n  $$\n  Multiplying by $2$ yields $2\\gamma^2 - 4\\gamma + 1 = 0$. We solve this for $\\gamma$ using the quadratic formula:\n  $$\n  \\gamma = \\frac{-(-4) \\pm \\sqrt{(-4)^2 - 4(2)(1)}}{2(2)} = \\frac{4 \\pm \\sqrt{16-8}}{4} = \\frac{4 \\pm 2\\sqrt{2}}{4} = 1 \\pm \\frac{\\sqrt{2}}{2}\n  $$\n  This gives two possible values for $\\gamma$: $\\gamma_1 = 1 - \\frac{\\sqrt{2}}{2}$ and $\\gamma_2 = 1 + \\frac{\\sqrt{2}}{2}$.\n\nNow, we must derive the stability function and determine which value of $\\gamma$ ensures A-stability. The stability function for a Runge–Kutta method is $R(z) = 1 + z\\mathbf{b}^T(\\mathbf{I} - z\\mathbf{A})^{-1}\\mathbf{1}$, where $z = h\\lambda$. For an SDIRK method, this simplifies to a rational function. The stability function for a second-order SDIRK method can be shown to be:\n$$\nR(z) = \\frac{1+(1-2\\gamma)z}{(1-\\gamma z)^2}\n$$\nA method is A-stable if its region of absolute stability contains the entire left half of the complex plane, $\\{z \\in \\mathbb{C} \\mid \\text{Re}(z) \\leq 0\\}$. This requires two conditions to be met:\n1.  $R(z)$ must be analytic for $\\text{Re}(z) < 0$. The poles of $R(z)$ occur where the denominator is zero, i.e., at $z = \\frac{1}{\\gamma}$. For analyticity in the left half-plane, this pole must lie in the right half-plane or on the imaginary axis, i.e., $\\text{Re}(\\frac{1}{\\gamma}) \\ge 0$. This is equivalent to $\\text{Re}(\\gamma) \\ge 0$. Both potential values, $\\gamma = 1 \\pm \\frac{\\sqrt{2}}{2}$, are real and positive, so this condition is met.\n2.  On the imaginary axis, the stability function must satisfy $|R(iy)| \\le 1$ for all real $y$.\n    $$\n    |R(iy)|^2 = \\frac{|1+iy(1-2\\gamma)|^2}{|(1-i\\gamma y)^2|^2} = \\frac{1^2 + y^2(1-2\\gamma)^2}{(|1-i\\gamma y|^2)^2} = \\frac{1+y^2(1-4\\gamma+4\\gamma^2)}{(1+y^2\\gamma^2)^2}\n    $$\n    The condition $|R(iy)|^2 \\le 1$ requires:\n    $$\n    1+y^2(1-4\\gamma+4\\gamma^2) \\le (1+y^2\\gamma^2)^2 = 1+2y^2\\gamma^2+y^4\\gamma^4\n    $$\n    $$\n    y^2(1-4\\gamma+4\\gamma^2) \\le 2y^2\\gamma^2+y^4\\gamma^4\n    $$\n    For $y \\neq 0$, we divide by $y^2$:\n    $$\n    1-4\\gamma+2\\gamma^2 \\le y^2\\gamma^4\n    $$\n    The order condition for $\\gamma$ was $2\\gamma^2 - 4\\gamma + 1 = 0$. This implies $1 - 4\\gamma + 2\\gamma^2 = 0$. Substituting this into the inequality gives:\n    $$\n    0 \\le y^2\\gamma^4\n    $$\n    Since $y^2 \\ge 0$ and $\\gamma^4 \\ge 0$ for real $\\gamma$, this inequality is always satisfied. Thus, both values of $\\gamma$ produce an A-stable method.\n\nThe problem, however, asks for \"the\" diagonal coefficient value, implying a unique answer. We must appeal to practical design principles mentioned in the prompt, namely that the method should be \"robust\" and is motivated by \"aerospace computational fluid dynamics practice\". A key consideration for robustness in such applications is to avoid negative coefficients in the Butcher tableau, especially for the weights $b_j$, as they can introduce non-physical oscillations or cause solutions (like density or concentration) to become negative.\nThe weights are $b_1 = 1-\\gamma$ and $b_2 = \\gamma$. The condition for non-negativity is $b_i \\ge 0$ for all $i$.\n- $b_2 = \\gamma \\ge 0$.\n- $b_1 = 1-\\gamma \\ge 0 \\implies \\gamma \\le 1$.\nSo, $\\gamma$ must be in the interval $[0, 1]$. Let's examine our two solutions:\n1.  $\\gamma_1 = 1 - \\frac{\\sqrt{2}}{2} \\approx 1 - 0.707 = 0.293$. This value lies in $[0, 1]$.\n2.  $\\gamma_2 = 1 + \\frac{\\sqrt{2}}{2} \\approx 1 + 0.707 = 1.707$. This value is greater than $1$, which would make the weight $b_1 = 1 - (1 + \\frac{\\sqrt{2}}{2}) = -\\frac{\\sqrt{2}}{2}$ negative.\n\nTo ensure a robust method with non-negative weights, we must choose the first solution. Therefore, the unique diagonal coefficient satisfying all design criteria is $\\gamma = 1 - \\frac{\\sqrt{2}}{2}$.",
            "answer": "$$\n\\boxed{1 - \\frac{\\sqrt{2}}{2}}\n$$"
        },
        {
            "introduction": "Having designed an A-stable method, it is natural to ask if all such methods behave identically on stiff problems. This practice explores the subtle but critical distinction between A-stability and L-stability. By analyzing the behavior of two different implicit methods in the limit of infinite stiffness, you will gain crucial insight into why L-stability is a highly desirable property for robustly damping the high-frequency numerical noise often encountered in viscous flow simulations .",
            "id": "3978565",
            "problem": "An aerospace Computational Fluid Dynamics (CFD) simulation of a viscous compressible flow yields a semi-discrete linear operator from spatial discretization, producing a system of ordinary differential equations of the form $\\frac{d\\boldsymbol{u}}{dt}=\\mathbf{L}\\boldsymbol{u}$. A Fourier-mode analysis and matrix eigen-decomposition indicate that the high-frequency grid-scale viscous modes correspond to eigenvalues $\\lambda$ with large negative real parts, i.e., $\\operatorname{Re}(\\lambda)\\ll 0$, and $|\\lambda|\\gg 1$ in nondimensional units. To study the qualitative damping behavior of multistage Runge–Kutta methods, consider the Dahlquist test equation $\\frac{dy}{dt}=\\lambda y$ with $\\lambda\\in\\mathbb{C}$, and define the nondimensional parameter $z=\\lambda\\Delta t$, where $\\Delta t$ is the time step.\n\nTwo one-stage implicit time integrators are considered:\n\n1. The implicit midpoint rule, defined by the update $y_{n+1}=y_{n}+\\Delta t\\,f\\!\\left(t_{n}+\\frac{\\Delta t}{2},\\frac{y_{n}+y_{n+1}}{2}\\right)$ for a general right-hand side $f$, specialized here to $f(t,y)=\\lambda y$.\n\n2. The backward Euler method, defined by $y_{n+1}=y_{n}+\\Delta t\\,f(t_{n+1},y_{n+1})$ with $f(t,y)=\\lambda y$.\n\nFor the test equation, each method yields a linear amplification relation $y_{n+1}=R(z)\\,y_{n}$, where $R(z)$ is the method’s stability function. An $A$-stable method satisfies $\\lvert R(z)\\rvert\\le 1$ for all $z$ with $\\operatorname{Re}(z)\\le 0$, and an $L$-stable method is $A$-stable and additionally satisfies $\\lim_{z\\to -\\infty}R(z)=0$ along the negative real axis. In the CFD context above, the regime of interest is $z=\\lambda\\Delta t$ with large negative real values, representing stiff high-frequency viscous modes.\n\nWhich of the following statements correctly capture the qualitative difference between $A$-stable and $L$-stable methods in damping high-frequency modes for the Dahlquist test equation and, by extension, semi-discrete viscous aerospace CFD systems?\n\nA. The implicit midpoint rule is $A$-stable but not $L$-stable; consequently, as $z\\to -\\infty$ along the negative real axis, its amplification factor approaches a nonzero constant of unit magnitude, so stiff high-frequency modes can persist as bounded oscillations.\n\nB. The backward Euler method is both $A$-stable and $L$-stable; consequently, as $z\\to -\\infty$ along the negative real axis, its amplification factor tends to zero, so stiff high-frequency modes are strongly damped.\n\nC. $A$-stability alone guarantees the elimination of stiff high-frequency modes in the limit $z\\to -\\infty$; therefore any $A$-stable method is just as effective as an $L$-stable method at damping grid-scale oscillations.\n\nD. In semi-discrete compressible Navier–Stokes discretizations, high-frequency viscous modes correspond to eigenvalues with large negative real parts; selecting an $L$-stable multistage Runge–Kutta method reduces non-physical high-frequency content more rapidly than an $A$-stable but not $L$-stable method under the same time step.\n\nE. All Gauss–Legendre Runge–Kutta methods are $L$-stable and thus optimally damp stiff negative-real modes.",
            "solution": "The problem statement will first be validated for scientific soundness, consistency, and clarity.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following information:\n- A semi-discrete system of ordinary differential equations from aerospace CFD: $\\frac{d\\boldsymbol{u}}{dt}=\\mathbf{L}\\boldsymbol{u}$.\n- Eigenvalues $\\lambda$ of the operator $\\mathbf{L}$: High-frequency viscous modes correspond to eigenvalues with $\\operatorname{Re}(\\lambda)\\ll 0$ and $|\\lambda|\\gg 1$.\n- The Dahlquist test equation: $\\frac{dy}{dt}=\\lambda y$, with $\\lambda\\in\\mathbb{C}$.\n- A nondimensional parameter: $z=\\lambda\\Delta t$, where $\\Delta t$ is the time step.\n- Method 1 (Implicit Midpoint Rule): $y_{n+1}=y_{n}+\\Delta t\\,f\\!\\left(t_{n}+\\frac{\\Delta t}{2},\\frac{y_{n}+y_{n+1}}{2}\\right)$ for $f(t,y)=\\lambda y$.\n- Method 2 (Backward Euler Method): $y_{n+1}=y_{n}+\\Delta t\\,f(t_{n+1},y_{n+1})$ for $f(t,y)=\\lambda y$.\n- Amplification relation: $y_{n+1}=R(z)\\,y_{n}$, where $R(z)$ is the stability function.\n- Definition of $A$-stability: $\\lvert R(z)\\rvert\\le 1$ for all $z$ with $\\operatorname{Re}(z)\\le 0$.\n- Definition of $L$-stability: A method is $A$-stable and satisfies $\\lim_{z\\to -\\infty}R(z)=0$ along the negative real axis.\n- The regime of interest is $z$ with large negative real values, corresponding to stiff high-frequency viscous modes.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is firmly based on the standard and well-established theory of numerical stability for ordinary differential equations, specifically for stiff systems. The application to CFD, the use of the Dahlquist test equation, and the definitions of $A$-stability and $L$-stability are all cornerstone concepts in numerical analysis.\n- **Well-Posed:** All necessary definitions and equations are provided to derive the stability functions and analyze their properties. The question is unambiguous and asks for a qualitative comparison based on these definitions.\n- **Objective:** The problem uses precise mathematical and scientific language. The definitions are standard and not subject to interpretation.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It presents a standard, well-posed problem in numerical analysis relevant to its stated application domain.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. The solution process will now proceed.\n\n### Solution Derivation\n\nThe core of the problem is to analyze the stability functions $R(z)$ for the two given methods and evaluate their properties in the limit of large, negative real $z$.\n\n**1. Implicit Midpoint Rule**\n\nThe update formula is $y_{n+1}=y_{n}+\\Delta t\\,f\\!\\left(t_{n}+\\frac{\\Delta t}{2},\\frac{y_{n}+y_{n+1}}{2}\\right)$.\nFor $f(t,y) = \\lambda y$, this becomes:\n$$y_{n+1} = y_{n} + \\Delta t \\, \\lambda \\left(\\frac{y_n + y_{n+1}}{2}\\right)$$\nSubstituting $z = \\lambda \\Delta t$:\n$$y_{n+1} = y_{n} + \\frac{z}{2}(y_n + y_{n+1})$$\nWe solve for $y_{n+1}$:\n$$y_{n+1}\\left(1 - \\frac{z}{2}\\right) = y_{n}\\left(1 + \\frac{z}{2}\\right)$$\n$$y_{n+1} = \\frac{1 + z/2}{1 - z/2} y_{n}$$\nThe stability function for the implicit midpoint rule is therefore:\n$$R_{\\text{midpoint}}(z) = \\frac{1 + z/2}{1 - z/2}$$\n\n_Analysis of $R_{\\text{midpoint}}(z)$_:\n- **A-stability**: We must check if $|R_{\\text{midpoint}}(z)| \\le 1$ for $\\operatorname{Re}(z) \\le 0$. Let $z = x+iy$ with $x \\le 0$.\n$$|R_{\\text{midpoint}}(z)|^2 = \\left|\\frac{1 + (x+iy)/2}{1 - (x+iy)/2}\\right|^2 = \\frac{(1+x/2)^2 + (y/2)^2}{(1-x/2)^2 + (y/2)^2}$$\nThe condition $|R_{\\text{midpoint}}(z)|^2 \\le 1$ requires the numerator to be less than or equal to the denominator. This is equivalent to $(1+x/2)^2 \\le (1-x/2)^2$, which simplifies to $1+x+x^2/4 \\le 1-x+x^2/4$, or $2x \\le 0$, which is $x \\le 0$. This condition matches the requirement $\\operatorname{Re}(z) \\le 0$. Thus, the method is **A-stable**.\n\n- **L-stability**: We evaluate the limit as $z \\to -\\infty$ along the negative real axis.\n$$\\lim_{z \\to -\\infty} R_{\\text{midpoint}}(z) = \\lim_{z \\to -\\infty} \\frac{1 + z/2}{1 - z/2} = \\lim_{z \\to -\\infty} \\frac{z(1/z + 1/2)}{z(1/z - 1/2)} = \\frac{1/2}{-1/2} = -1$$\nSince the limit is $-1 \\neq 0$, the implicit midpoint rule is **not L-stable**.\n\n**2. Backward Euler Method**\n\nThe update formula is $y_{n+1}=y_{n}+\\Delta t\\,f(t_{n+1},y_{n+1})$.\nFor $f(t,y) = \\lambda y$, this becomes:\n$$y_{n+1} = y_{n} + \\Delta t \\, \\lambda y_{n+1}$$\nSubstituting $z = \\lambda \\Delta t$:\n$$y_{n+1} = y_n + z y_{n+1}$$\nSolving for $y_{n+1}$:\n$$y_{n+1}(1 - z) = y_n$$\n$$y_{n+1} = \\frac{1}{1-z} y_n$$\nThe stability function for the backward Euler method is therefore:\n$$R_{\\text{BE}}(z) = \\frac{1}{1-z}$$\n\n_Analysis of $R_{\\text{BE}}(z)$_:\n- **A-stability**: We must check if $|R_{\\text{BE}}(z)| \\le 1$ for $\\operatorname{Re}(z) \\le 0$. Let $z = x+iy$ with $x \\le 0$.\n$$|R_{\\text{BE}}(z)|^2 = \\left|\\frac{1}{1 - (x+iy)}\\right|^2 = \\frac{1}{|(1-x) - iy|^2} = \\frac{1}{(1-x)^2 + y^2}$$\nSince $x \\le 0$, we have $1-x \\ge 1$. Therefore, the denominator $(1-x)^2 + y^2 \\ge 1^2 + 0 = 1$. This implies $|R_{\\text{BE}}(z)|^2 \\le 1$, so the method is **A-stable**.\n\n- **L-stability**: We evaluate the limit as $z \\to -\\infty$ along the negative real axis.\n$$\\lim_{z \\to -\\infty} R_{\\text{BE}}(z) = \\lim_{z \\to -\\infty} \\frac{1}{1-z} = 0$$\nSince the method is A-stable and the limit is $0$, the backward Euler method is **L-stable**.\n\n### Option-by-Option Analysis\n\n**A. The implicit midpoint rule is $A$-stable but not $L$-stable; consequently, as $z\\to -\\infty$ along the negative real axis, its amplification factor approaches a nonzero constant of unit magnitude, so stiff high-frequency modes can persist as bounded oscillations.**\nOur analysis confirms that the implicit midpoint rule is $A$-stable but not $L$-stable. The limit of its amplification factor $R(z)$ as $z \\to -\\infty$ is indeed $-1$. This value is a nonzero constant, and its magnitude is $|-1|=1$. An amplification factor of $-1$ means that for stiff modes, $y_{n+1} \\approx -y_n$, leading to undamped, sign-alternating oscillations that persist in the solution. This statement accurately describes the behavior.\n**Verdict: Correct**\n\n**B. The backward Euler method is both $A$-stable and $L$-stable; consequently, as $z\\to -\\infty$ along the negative real axis, its amplification factor tends to zero, so stiff high-frequency modes are strongly damped.**\nOur analysis confirms that the backward Euler method is both $A$-stable and $L$-stable. The limit of its amplification factor as $z \\to -\\infty$ is $0$. An amplification factor near zero means that for stiff modes, $y_{n+1} \\approx 0 \\cdot y_n$, causing these modes to be damped out very rapidly (in a single timestep in the limit). This statement is an accurate description.\n**Verdict: Correct**\n\n**C. $A$-stability alone guarantees the elimination of stiff high-frequency modes in the limit $z\\to -\\infty$; therefore any $A$-stable method is just as effective as an $L$-stable method at damping grid-scale oscillations.**\nThis statement is false. The very existence of the $L$-stability definition is to distinguish methods that damp stiff modes from those that do not. The implicit midpoint rule is a counterexample: it is $A$-stable but does not eliminate stiff modes, as their amplification factor approaches $-1$. An $L$-stable method, by definition, has an amplification factor that approaches $0$ and is thus much more effective at damping these modes.\n**Verdict: Incorrect**\n\n**D. In semi-discrete compressible Navier–Stokes discretizations, high-frequency viscous modes correspond to eigenvalues with large negative real parts; selecting an $L$-stable multistage Runge–Kutta method reduces non-physical high-frequency content more rapidly than an $A$-stable but not $L$-stable method under the same time step.**\nThe first clause correctly restates the premise of the problem. For stiff modes (large negative real $\\lambda$), the parameter $z = \\lambda \\Delta t$ will have a large negative real part. An $L$-stable method's amplification function $R(z)$ will approach $0$ in this limit, leading to strong damping. An $A$-stable but not $L$-stable method will have $|R(z)|$ approach some non-zero value (often $1$), leading to weak or no damping. Therefore, an $L$-stable method is superior for damping such non-physical high-frequency content. This statement correctly summarizes the practical implication of $L$-stability.\n**Verdict: Correct**\n\n**E. All Gauss–Legendre Runge–Kutta methods are $L$-stable and thus optimally damp stiff negative-real modes.**\nThis statement is false. Gauss–Legendre methods are a family of $A$-stable implicit Runge–Kutta methods. The $1$-stage Gauss–Legendre method is precisely the implicit midpoint rule, which we have shown is not $L$-stable. In general, the stability function for an $s$-stage Gauss-Legendre method is the $(s,s)$ Padé approximant to $e^z$, for which $|R(z)| \\to 1$ as $|z| \\to \\infty$. Thus, Gauss-Legendre methods are not $L$-stable.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{ABD}$$"
        }
    ]
}