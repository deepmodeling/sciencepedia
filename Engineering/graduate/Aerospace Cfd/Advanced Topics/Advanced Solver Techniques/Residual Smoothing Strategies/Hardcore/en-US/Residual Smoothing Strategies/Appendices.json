{
    "hands_on_practices": [
        {
            "introduction": "Before implementing any numerical technique, it is essential to understand its fundamental principles and potential pitfalls. This exercise contrasts two possible approaches to smoothing in an iterative solver: smoothing the solution variables directly versus smoothing the calculated residual. By working through a simple but illustrative linear system, you will discover why applying a filter to the solution can alter the final converged result, whereas residual smoothing correctly preserves the true solution of the underlying equations .",
            "id": "3990444",
            "problem": "Consider a steady linear discrete system arising from a one-dimensional second-order elliptic operator in Computational Fluid Dynamics (CFD), written as $A u = f$ with\n$$\nA = \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}, \\qquad f = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\nLet the residual at iteration $k$ be $r^{(k)} = f - A u^{(k)}$. Define a simple averaging filter $S$ acting on two-component vectors by\n$$\nS = \\begin{pmatrix} \\tfrac{1}{2}  \\tfrac{1}{2} \\\\ \\tfrac{1}{2}  \\tfrac{1}{2} \\end{pmatrix},\n$$\nwhich replaces both components by their arithmetic mean. Consider explicit Richardson iteration with relaxation parameter $\\omega \\neq 0$, and two distinct smoothing strategies used in steady iteration:\n\n- Strategy $\\mathrm{V}$ (solution-variable smoothing): $u^{(k+1)} = S\\big(u^{(k)} + \\omega (f - A u^{(k)})\\big)$,\n- Strategy $\\mathrm{R}$ (residual smoothing): $u^{(k+1)} = u^{(k)} + \\omega S\\big(f - A u^{(k)}\\big)$.\n\nStarting from the fundamental definitions of residual and fixed point, and without appealing to any unstated properties of $A$ or $S$, derive the fixed-point conditions for both strategies. Then, compute the exact solution $u^{\\star}$ to $A u = f$, determine the fixed point $u_{\\mathrm{V}}^{\\star}$ of Strategy $\\mathrm{V}$, and verify that $u^{\\star}$ is a fixed point of Strategy $\\mathrm{R}$. Finally, compute the Euclidean norm $\\|u_{\\mathrm{V}}^{\\star} - u^{\\star}\\|_{2}$ and provide its exact value. Express the final answer in exact form with no rounding and no units.",
            "solution": "The problem statement is first validated to ensure it is scientifically sound, self-contained, and well-posed.\n\n**Step 1: Extract Givens**\n- The linear system is $A u = f$.\n- Matrix $A$:\n$$\nA = \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}\n$$\n- Vector $f$:\n$$\nf = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n- Residual definition: $r^{(k)} = f - A u^{(k)}$.\n- Smoothing filter $S$:\n$$\nS = \\begin{pmatrix} \\tfrac{1}{2}  \\tfrac{1}{2} \\\\ \\tfrac{1}{2}  \\tfrac{1}{2} \\end{pmatrix}\n$$\n- Relaxation parameter: $\\omega \\neq 0$.\n- Strategy V (solution-variable smoothing): $u^{(k+1)} = S\\big(u^{(k)} + \\omega (f - A u^{(k)})\\big)$.\n- Strategy R (residual smoothing): $u^{(k+1)} = u^{(k)} + \\omega S\\big(f - A u^{(k)}\\big)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a well-defined exercise in numerical linear algebra, specifically concerning iterative methods for solving linear systems of equations. Such systems commonly arise from the discretization of partial differential equations in CFD and other fields. The matrices $A$ and $S$ are explicitly given and well-behaved. The iterative schemes are standard forms, and the tasks are direct applications of the definitions. The matrix $A$ represents a discrete one-dimensional Laplacian, a fundamental elliptic operator. The smoother $S$ is a simple averaging filter.\nThe problem is scientifically grounded, objective, and self-contained. It contains no contradictions, ambiguities, or factual unsoundness. A unique solution for all requested quantities can be determined.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be provided.\n\n**Derivation of Fixed-Point Conditions**\nA fixed point $u^{\\star}$ of any iterative scheme $u^{(k+1)} = G(u^{(k)})$ must satisfy the condition $u^{\\star} = G(u^{\\star})$.\n\nFor Strategy V, the iteration is $u^{(k+1)} = S\\big(u^{(k)} + \\omega (f - A u^{(k)})\\big)$. The fixed-point condition is thus:\n$$\nu_{\\mathrm{V}}^{\\star} = S\\big(u_{\\mathrm{V}}^{\\star} + \\omega (f - A u_{\\mathrm{V}}^{\\star})\\big)\n$$\nThis is the fixed-point condition for Strategy V. It can be written as a linear system for $u_{\\mathrm{V}}^{\\star}$: $\\big(I - S(I - \\omega A)\\big)u_{\\mathrm{V}}^{\\star} = \\omega S f$, where $I$ is the identity matrix.\n\nFor Strategy R, the iteration is $u^{(k+1)} = u^{(k)} + \\omega S\\big(f - A u^{(k)}\\big)$. The fixed-point condition is:\n$$\nu_{\\mathrm{R}}^{\\star} = u_{\\mathrm{R}}^{\\star} + \\omega S\\big(f - A u_{\\mathrm{R}}^{\\star}\\big)\n$$\nSubtracting $u_{\\mathrm{R}}^{\\star}$ from both sides gives:\n$$\n0 = \\omega S\\big(f - A u_{\\mathrm{R}}^{\\star}\\big)\n$$\nSince the problem states $\\omega \\neq 0$, we can divide by $\\omega$ to obtain the fixed-point condition for Strategy R:\n$$\nS\\big(f - A u_{\\mathrm{R}}^{\\star}\\big) = 0\n$$\nThis condition means that the smoothed residual at the fixed point must be zero.\n\n**Computation of the Exact Solution $u^{\\star}$**\nThe exact solution $u^{\\star}$ satisfies the linear system $A u^{\\star} = f$. We can find $u^{\\star}$ by computing the inverse of $A$. The determinant of $A$ is $\\det(A) = (2)(2) - (-1)(-1) = 4 - 1 = 3$. The inverse is:\n$$\nA^{-1} = \\frac{1}{\\det(A)} \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\nThe solution $u^{\\star}$ is then calculated as:\n$$\nu^{\\star} = A^{-1}f = \\frac{1}{3} \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} (2)(1) + (1)(0) \\\\ (1)(1) + (2)(0) \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{1}{3} \\end{pmatrix}\n$$\n\n**Determination of the Fixed Point $u_{\\mathrm{V}}^{\\star}$ of Strategy V**\nThe fixed-point equation for Strategy V is $u_{\\mathrm{V}}^{\\star} = S\\big(u_{\\mathrm{V}}^{\\star} + \\omega(f - A u_{\\mathrm{V}}^{\\star})\\big)$. The matrix $S$ maps any vector to a vector whose components are equal (the average of the input components). Therefore, the output of the right-hand side, and thus $u_{\\mathrm{V}}^{\\star}$ itself, must have equal components. Let $u_{\\mathrm{V}}^{\\star} = \\begin{pmatrix} c \\\\ c \\end{pmatrix}$ for some scalar $c$.\nWe substitute this form into the fixed-point equation. First, we compute the term inside the parentheses:\n$$\nu_{\\mathrm{V}}^{\\star} + \\omega(f - A u_{\\mathrm{V}}^{\\star}) = \\begin{pmatrix} c \\\\ c \\end{pmatrix} + \\omega \\left( \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} c \\\\ c \\end{pmatrix} \\right)\n$$\n$$\n= \\begin{pmatrix} c \\\\ c \\end{pmatrix} + \\omega \\left( \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 2c-c \\\\ -c+2c \\end{pmatrix} \\right) = \\begin{pmatrix} c \\\\ c \\end{pmatrix} + \\omega \\begin{pmatrix} 1-c \\\\ -c \\end{pmatrix} = \\begin{pmatrix} c + \\omega(1-c) \\\\ c - \\omega c \\end{pmatrix}\n$$\nNow, apply the smoothing operator $S$:\n$$\nS \\begin{pmatrix} c + \\omega - \\omega c \\\\ c - \\omega c \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} c + \\omega - \\omega c \\\\ c - \\omega c \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} (c + \\omega - \\omega c) + (c - \\omega c) \\\\ (c + \\omega - \\omega c) + (c - \\omega c) \\end{pmatrix} = \\begin{pmatrix} c + \\frac{\\omega}{2} - \\omega c \\\\ c + \\frac{\\omega}{2} - \\omega c \\end{pmatrix}\n$$\nFor this to be a fixed point, the result must be equal to $u_{\\mathrm{V}}^{\\star} = \\begin{pmatrix} c \\\\ c \\end{pmatrix}$. Thus, we must have:\n$$\nc = c + \\frac{\\omega}{2} - \\omega c\n$$\n$$\n0 = \\frac{\\omega}{2} - \\omega c = \\omega \\left( \\frac{1}{2} - c \\right)\n$$\nSince $\\omega \\neq 0$, it follows that $\\frac{1}{2} - c = 0$, which gives $c = \\frac{1}{2}$.\nTherefore, the fixed point for Strategy V is:\n$$\nu_{\\mathrm{V}}^{\\star} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}\n$$\nThis demonstrates that the fixed point for solution-variable smoothing is different from the true solution $u^{\\star}$.\n\n**Verification that $u^{\\star}$ is a Fixed Point of Strategy R**\nThe fixed-point condition for Strategy R is $S(f - A u_{\\mathrm{R}}^{\\star}) = 0$. We must verify if $u^{\\star} = \\begin{pmatrix} 2/3 \\\\ 1/3 \\end{pmatrix}$ satisfies this condition.\nWe substitute $u_{\\mathrm{R}}^{\\star} = u^{\\star}$ into the condition:\n$$\nS(f - A u^{\\star})\n$$\nBy definition, $u^{\\star}$ is the solution to $A u = f$, so $A u^{\\star} = f$. This implies that the residual is the zero vector: $f - A u^{\\star} = 0$.\nThe expression becomes:\n$$\nS(0) = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThe condition $0=0$ is satisfied. Thus, the exact solution $u^{\\star}$ is indeed a fixed point of Strategy R.\n\n**Computation of the Euclidean Norm of the Difference**\nFinally, we compute the Euclidean norm of the difference between the fixed point of Strategy V and the exact solution, $\\|u_{\\mathrm{V}}^{\\star} - u^{\\star}\\|_{2}$.\nThe difference vector is:\n$$\nu_{\\mathrm{V}}^{\\star} - u^{\\star} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} - \\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{6} - \\frac{4}{6} \\\\ \\frac{3}{6} - \\frac{2}{6} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{6} \\\\ \\frac{1}{6} \\end{pmatrix}\n$$\nThe Euclidean norm is calculated as $\\sqrt{v_1^2 + v_2^2}$:\n$$\n\\|u_{\\mathrm{V}}^{\\star} - u^{\\star}\\|_{2} = \\sqrt{\\left(-\\frac{1}{6}\\right)^2 + \\left(\\frac{1}{6}\\right)^2} = \\sqrt{\\frac{1}{36} + \\frac{1}{36}} = \\sqrt{\\frac{2}{36}} = \\sqrt{\\frac{1}{18}}\n$$\nSimplifying the result:\n$$\n\\sqrt{\\frac{1}{18}} = \\frac{1}{\\sqrt{18}} = \\frac{1}{\\sqrt{9 \\times 2}} = \\frac{1}{3\\sqrt{2}} = \\frac{1}{3\\sqrt{2}} \\cdot \\frac{\\sqrt{2}}{\\sqrt{2}} = \\frac{\\sqrt{2}}{6}\n$$\nThe exact value of the norm is $\\frac{\\sqrt{2}}{6}$.",
            "answer": "$$\n\\boxed{\\frac{\\sqrt{2}}{6}}\n$$"
        },
        {
            "introduction": "Moving from theory to practice, this problem demonstrates how to apply residual smoothing in a more realistic setting. Aerospace applications often involve complex geometries discretized with unstructured meshes. This exercise provides a concrete, hands-on calculation of a smoothed residual on a sample unstructured mesh patch, showing how geometric factors like face areas and centroid distances are used to construct the smoothing weights .",
            "id": "3990443",
            "problem": "In steady-state explicit Computational Fluid Dynamics (CFD) for compressible flow in aerospace applications, residual smoothing is used to accelerate convergence without violating conservation. Consider a two-dimensional unstructured finite-volume patch consisting of a central control volume indexed by $i$ and four face-sharing neighbors indexed by $j \\in \\{1,2,3,4\\}$. Let the residual associated with the conservation equations in control volume $i$ be $r_{i}$ and the neighbor residuals be $r_{j}$. A smoothing operator must be constructed from first principles such that it is consistent with discrete diffusion derived from fluxes computed via Fick's law, preserves any constant residual field, and uses positive, normalized geometric weights built from face areas and neighbor distances.\n\nStarting from the requirement that the smoothing be a local discrete diffusion step consistent with face-based fluxes proportional to face area and the gradient approximated over inter-centroid distance, construct a smoothing operator for $r_{i}$ using weights of the form $w_{ij} = s_{ij} / S_{i}$ with $s_{ij} \\propto A_{ij} / d_{ij}$, where $A_{ij}$ is the shared face area between control volumes $i$ and $j$ and $d_{ij}$ is the distance between their centroids, and $S_{i} = \\sum_{k \\in N(i)} s_{ik}$. The operator must preserve constant residual fields and ensure positivity and normalization of weights.\n\nFor the specific patch, the geometric data and residuals are:\n- $A_{i1} = 0.8$, $d_{i1} = 0.4$, $r_{1} = 0.012$.\n- $A_{i2} = 0.6$, $d_{i2} = 0.3$, $r_{2} = 0.020$.\n- $A_{i3} = 1.2$, $d_{i3} = 0.6$, $r_{3} = 0.018$.\n- $A_{i4} = 0.9$, $d_{i4} = 0.3$, $r_{4} = 0.010$.\n- Central residual $r_{i} = 0.015$.\n\nUse a dimensionless smoothing coefficient $\\alpha$ with $0  \\alpha  1$, specifically $\\alpha = 0.35$. Compute the smoothed residual in cell $i$ produced by a convex combination of $r_{i}$ and the normalized neighbor average constructed from the weights $w_{ij}$ built from $s_{ij} = A_{ij}/d_{ij}$. Verify that the weights satisfy the normalization requirement. Express your final answer as a dimensionless number and round your answer to four significant figures.",
            "solution": "The problem presents a valid and well-posed scenario in computational fluid dynamics, specifically concerning the application of a residual smoothing technique to accelerate convergence in an explicit numerical scheme. The task is to compute the smoothed residual for a central control volume given its own residual, the residuals of its neighbors, and the geometric properties of the computational mesh patch.\n\nThe process of residual smoothing can be formulated as a discrete diffusion process. The smoothed residual, which we shall denote as $\\bar{r}_{i}$ for the central control volume $i$, is an updated value based on the original residual $r_{i}$ and a weighted average of the residuals from its neighboring control volumes $j \\in N(i)$. The problem specifies that the smoothed residual is a convex combination of $r_{i}$ and the normalized neighbor average. This is expressed as:\n$$ \\bar{r}_{i} = (1 - \\alpha) r_{i} + \\alpha \\sum_{j \\in N(i)} w_{ij} r_{j} $$\nwhere $\\alpha$ is a dimensionless smoothing coefficient, and $w_{ij}$ are the normalized weights. This formulation ensures that if the residual field is constant (i.e., $r_{j} = r_{i}$ for all neighbors $j$), then $\\bar{r}_{i} = r_{i}$, a key property for any such operator.\n\nThe weights $w_{ij}$ must be constructed from the geometric data provided. The problem specifies that the unnormalized weights, $s_{ij}$, are given by the ratio of the shared face area $A_{ij}$ to the distance between the cell centroids $d_{ij}$:\n$$ s_{ij} = \\frac{A_{ij}}{d_{ij}} $$\nThese unnormalized weights are consistent with a discrete diffusion flux, where the \"diffusivity\" is proportional to the geometric conductance between cells.\n\nThe normalized weights $w_{ij}$ are then computed by dividing each $s_{ij}$ by the sum of all unnormalized weights for the neighbors of cell $i$:\n$$ w_{ij} = \\frac{s_{ij}}{S_{i}}, \\quad \\text{where} \\quad S_{i} = \\sum_{k \\in N(i)} s_{ik} $$\nBy this construction, the weights are guaranteed to be positive (since $A_{ij} > 0$ and $d_{ij} > 0$) and normalized, such that $\\sum_{j \\in N(i)} w_{ij} = 1$.\n\nWe are given the following data for the central cell $i$ and its four neighbors $j \\in \\{1, 2, 3, 4\\}$:\n- Central residual: $r_{i} = 0.015$\n- Smoothing coefficient: $\\alpha = 0.35$\n- Neighbor data:\n  - $A_{i1} = 0.8$, $d_{i1} = 0.4$, $r_{1} = 0.012$\n  - $A_{i2} = 0.6$, $d_{i2} = 0.3$, $r_{2} = 0.020$\n  - $A_{i3} = 1.2$, $d_{i3} = 0.6$, $r_{3} = 0.018$\n  - $A_{i4} = 0.9$, $d_{i4} = 0.3$, $r_{4} = 0.010$\n\nFirst, we compute the unnormalized weights $s_{ij}$:\n$$ s_{i1} = \\frac{A_{i1}}{d_{i1}} = \\frac{0.8}{0.4} = 2.0 $$\n$$ s_{i2} = \\frac{A_{i2}}{d_{i2}} = \\frac{0.6}{0.3} = 2.0 $$\n$$ s_{i3} = \\frac{A_{i3}}{d_{i3}} = \\frac{1.2}{0.6} = 2.0 $$\n$$ s_{i4} = \\frac{A_{i4}}{d_{i4}} = \\frac{0.9}{0.3} = 3.0 $$\n\nNext, we calculate the normalization factor $S_{i}$:\n$$ S_{i} = s_{i1} + s_{i2} + s_{i3} + s_{i4} = 2.0 + 2.0 + 2.0 + 3.0 = 9.0 $$\n\nNow, we compute the normalized weights $w_{ij}$:\n$$ w_{i1} = \\frac{s_{i1}}{S_{i}} = \\frac{2.0}{9.0} = \\frac{2}{9} $$\n$$ w_{i2} = \\frac{s_{i2}}{S_{i}} = \\frac{2.0}{9.0} = \\frac{2}{9} $$\n$$ w_{i3} = \\frac{s_{i3}}{S_{i}} = \\frac{2.0}{9.0} = \\frac{2}{9} $$\n$$ w_{i4} = \\frac{s_{i4}}{S_{i}} = \\frac{3.0}{9.0} = \\frac{3}{9} = \\frac{1}{3} $$\n\nAs required, we verify that the weights are normalized:\n$$ \\sum_{j=1}^{4} w_{ij} = w_{i1} + w_{i2} + w_{i3} + w_{i4} = \\frac{2}{9} + \\frac{2}{9} + \\frac{2}{9} + \\frac{3}{9} = \\frac{2+2+2+3}{9} = \\frac{9}{9} = 1 $$\nThe normalization requirement is satisfied.\n\nNext, we calculate the normalized neighbor average of the residuals, which we denote as $\\langle r \\rangle_{N(i)}$:\n$$ \\langle r \\rangle_{N(i)} = \\sum_{j=1}^{4} w_{ij} r_{j} = w_{i1}r_{1} + w_{i2}r_{2} + w_{i3}r_{3} + w_{i4}r_{4} $$\n$$ \\langle r \\rangle_{N(i)} = \\left(\\frac{2}{9}\\right)(0.012) + \\left(\\frac{2}{9}\\right)(0.020) + \\left(\\frac{2}{9}\\right)(0.018) + \\left(\\frac{3}{9}\\right)(0.010) $$\n$$ \\langle r \\rangle_{N(i)} = \\frac{1}{9} \\left( 2 \\cdot 0.012 + 2 \\cdot 0.020 + 2 \\cdot 0.018 + 3 \\cdot 0.010 \\right) $$\n$$ \\langle r \\rangle_{N(i)} = \\frac{1}{9} \\left( 0.024 + 0.040 + 0.036 + 0.030 \\right) $$\n$$ \\langle r \\rangle_{N(i)} = \\frac{1}{9} (0.130) $$\n\nFinally, we compute the smoothed residual $\\bar{r}_{i}$ using the convex combination:\n$$ \\bar{r}_{i} = (1 - \\alpha) r_{i} + \\alpha \\langle r \\rangle_{N(i)} $$\nSubstituting the given values $\\alpha = 0.35$ and $r_{i} = 0.015$:\n$$ \\bar{r}_{i} = (1 - 0.35)(0.015) + (0.35)\\left(\\frac{0.130}{9}\\right) $$\n$$ \\bar{r}_{i} = (0.65)(0.015) + \\frac{0.0455}{9} $$\n$$ \\bar{r}_{i} = 0.00975 + 0.0050555... $$\n$$ \\bar{r}_{i} = 0.01480555... $$\n\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures are $1$, $4$, $8$, $0$. The fifth digit is $5$, which requires rounding up the fourth digit.\n$$ \\bar{r}_{i} \\approx 0.01481 $$",
            "answer": "$$\n\\boxed{0.01481}\n$$"
        },
        {
            "introduction": "The effectiveness of residual smoothing hinges on the proper choice of the smoothing parameter, $\\alpha$. This exercise delves into the theoretical analysis required to optimize this parameter for maximum performance. Using discrete Fourier analysis, you will determine the optimal value of $\\alpha$ that most effectively damps the high-frequency error modes responsible for slowing down convergence, providing insight into the design of efficient and robust CFD solvers .",
            "id": "3990483",
            "problem": "In many aerospace computational fluid dynamics applications, explicit pseudo-time-stepping for the compressible Navierâ€“Stokes equations is accelerated by residual smoothing, in which the residual field is filtered by a linear operator to damp grid-scale oscillations. Consider a one-dimensional uniform mesh with periodic boundary conditions and grid spacing $h$, and a Poisson-like residual operator obtained from the standard second-order central-difference discrete Laplacian. Let $A$ denote the linear operator with action on a grid function $u_i$ defined by\n$$\n(Au)_i = \\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2}.\n$$\nA single step of weighted Jacobi residual smoothing with parameter $\\alpha$ maps a residual $r$ to\n$$\nr^{+} = r - \\alpha D^{-1} A r,\n$$\nwhere $D$ is the diagonal of $A$. Define the smoothing factor for high-frequency modes as the worst-case amplification factor over all discrete Fourier modes with wavenumber $\\theta$ in the high-frequency set $\\mathcal{H} = \\{\\theta \\in [\\pi/2,\\pi]\\}$ under this mapping.\n\nStarting from the fundamental properties of $A$, the structure of $D$, and the discrete Fourier mode analysis on a uniform periodic grid, derive the per-mode amplification factor and hence the smoothing factor as a function of $\\alpha$. Then determine the value of $\\alpha$ that minimizes the high-frequency smoothing factor and the corresponding minimized smoothing factor. Express your final answer as a row matrix containing, in this order, the minimized smoothing factor and the optimal $\\alpha$; use exact values with no rounding. The quantities are dimensionless. That is, report\n$$\n\\begin{pmatrix}\n\\mu_{\\min}  \\alpha_{\\mathrm{opt}}\n\\end{pmatrix}.\n$$",
            "solution": "The problem statement is a valid exercise in the numerical analysis of iterative methods for linear systems, specifically the application of Fourier analysis to determine the optimal relaxation parameter for a Jacobi-type smoothing scheme. All elements are well-defined, scientifically sound, and the problem is self-contained. I will now proceed with the solution.\n\nThe problem asks for the derivation of an optimal smoothing parameter for a weighted Jacobi residual smoothing method. The process involves four main steps:\n1.  Characterizing the discrete operator $A$ using Fourier analysis.\n2.  Deriving the per-mode amplification factor of the smoothing operator.\n3.  Determining the smoothing factor by maximizing the amplification factor over the high-frequency modes.\n4.  Minimizing this smoothing factor with respect to the parameter $\\alpha$ to find the optimal value $\\alpha_{\\mathrm{opt}}$ and the corresponding minimum smoothing factor $\\mu_{\\min}$.\n\n**Step 1: Fourier Analysis of the Operator $A$**\n\nWe analyze the action of the discrete operator $A$ on a generic discrete Fourier mode. On a uniform one-dimensional grid with spacing $h$ and periodic boundary conditions, a Fourier mode with discrete wavenumber $\\theta \\in [-\\pi, \\pi]$ is represented by the grid function $u_j = \\exp(ij\\theta)$, where $j$ is the grid index and $i$ here is the imaginary unit.\n\nThe action of $A$ on this mode $u_j$ is given by:\n$$\n(Au)_j = \\frac{-u_{j-1} + 2u_j - u_{j+1}}{h^2} = \\frac{-\\exp(i(j-1)\\theta) + 2\\exp(ij\\theta) - \\exp(i(j+1)\\theta)}{h^2}\n$$\nFactoring out the term $\\exp(ij\\theta)$:\n$$\n(Au)_j = \\frac{\\exp(ij\\theta)}{h^2} \\left[ -\\exp(-i\\theta) + 2 - \\exp(i\\theta) \\right]\n$$\nUsing Euler's identity, $\\exp(i\\theta) + \\exp(-i\\theta) = 2\\cos(\\theta)$, we can simplify the expression in the brackets:\n$$\n(Au)_j = \\frac{\\exp(ij\\theta)}{h^2} \\left[ 2 - 2\\cos(\\theta) \\right]\n$$\nThis shows that the Fourier mode $u_j = \\exp(ij\\theta)$ is an eigenvector of the operator $A$. The corresponding eigenvalue, which depends on the wavenumber $\\theta$, is:\n$$\n\\lambda_A(\\theta) = \\frac{2(1 - \\cos(\\theta))}{h^2}\n$$\nUsing the half-angle trigonometric identity $1 - \\cos(\\theta) = 2\\sin^2(\\theta/2)$, the eigenvalue can be written as:\n$$\n\\lambda_A(\\theta) = \\frac{4\\sin^2(\\theta/2)}{h^2}\n$$\n\n**Step 2: Deriving the Amplification Factor**\n\nThe residual smoothing update is given by $r^{+} = r - \\alpha D^{-1} A r$. This can be written as $r^{+} = (I - \\alpha D^{-1} A) r$, where $I$ is the identity operator. The operator $S(\\alpha) = I - \\alpha D^{-1} A$ is the amplification operator, and its eigenvalues are the amplification factors for the corresponding modes.\n\nFirst, we determine the operator $D$, which is the diagonal of $A$. From the definition $(Au)_i = \\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2}$, the coefficient of $u_i$ is $2/h^2$. Thus, $D$ is a diagonal matrix with all diagonal entries equal to $2/h^2$. We can write this as $D = \\frac{2}{h^2} I$.\nThe inverse of $D$ is $D^{-1} = \\frac{h^2}{2} I$.\n\nNow, we can find the eigenvalues of the operator $D^{-1}A$. Since $D^{-1}$ is a scalar multiple of the identity, the eigenvectors of $D^{-1}A$ are the same as the eigenvectors of $A$, and the eigenvalues are scaled accordingly:\n$$\n\\lambda_{D^{-1}A}(\\theta) = \\frac{h^2}{2} \\lambda_A(\\theta) = \\frac{h^2}{2} \\left( \\frac{4\\sin^2(\\theta/2)}{h^2} \\right) = 2\\sin^2(\\theta/2)\n$$\nThe amplification factor for the mode with wavenumber $\\theta$, denoted by $g(\\theta, \\alpha)$, is the eigenvalue of the amplification operator $S(\\alpha)$:\n$$\ng(\\theta, \\alpha) = 1 - \\alpha \\lambda_{D^{-1}A}(\\theta) = 1 - 2\\alpha\\sin^2(\\theta/2)\n$$\n\n**Step 3: Determining the Smoothing Factor**\n\nThe smoothing factor, $\\mu(\\alpha)$, is defined as the worst-case (maximum magnitude) amplification factor over the set of high-frequency modes, $\\mathcal{H} = \\{\\theta \\in [\\pi/2, \\pi]\\}$.\n$$\n\\mu(\\alpha) = \\max_{\\theta \\in \\mathcal{H}} |g(\\theta, \\alpha)| = \\max_{\\theta \\in [\\pi/2, \\pi]} |1 - 2\\alpha\\sin^2(\\theta/2)|\n$$\nTo find this maximum, we analyze the behavior of the term $x = \\sin^2(\\theta/2)$ as $\\theta$ varies in the interval $[\\pi/2, \\pi]$.\nAs $\\theta$ goes from $\\pi/2$ to $\\pi$, the argument $\\theta/2$ goes from $\\pi/4$ to $\\pi/2$.\nThe function $\\sin(\\phi)$ is monotonically increasing on this interval, so $\\sin(\\theta/2)$ ranges from $\\sin(\\pi/4) = \\frac{\\sqrt{2}}{2}$ to $\\sin(\\pi/2) = 1$.\nConsequently, $x = \\sin^2(\\theta/2)$ ranges over the interval $[(\\frac{\\sqrt{2}}{2})^2, 1^2] = [1/2, 1]$.\n\nLet $f(x) = 1 - 2\\alpha x$. We need to find $\\max_{x \\in [1/2, 1]} |f(x)|$. Since $f(x)$ is a linear function of $x$, its absolute value over a closed interval will attain its maximum at one of the endpoints of the interval.\nThe values at the endpoints $x=1/2$ and $x=1$ are:\n$$\nf(1/2) = 1 - 2\\alpha(1/2) = 1 - \\alpha\n$$\n$$\nf(1) = 1 - 2\\alpha(1) = 1 - 2\\alpha\n$$\nTherefore, the smoothing factor is the maximum of the absolute values of these two quantities:\n$$\n\\mu(\\alpha) = \\max \\left\\{ |1 - \\alpha|, |1 - 2\\alpha| \\right\\}\n$$\n\n**Step 4: Minimizing the Smoothing Factor**\n\nWe now seek to find the value of $\\alpha$, denoted $\\alpha_{\\mathrm{opt}}$, that minimizes $\\mu(\\alpha)$. This is a classic min-max problem. The minimum of the function $\\mu(\\alpha)$ will occur at a point where the two arguments of the `max` function are equal in magnitude, as this represents the \"valley\" in the upper envelope of the two functions $|1-\\alpha|$ and $|1-2\\alpha|$.\nWe set their magnitudes equal:\n$$\n|1 - \\alpha| = |1 - 2\\alpha|\n$$\nThis equation leads to two possibilities:\n1.  $1 - \\alpha = 1 - 2\\alpha \\implies \\alpha = 0$. In this case, $\\mu(0) = \\max\\{|1|, |1|\\} = 1$, which corresponds to no smoothing and is clearly not a minimum.\n2.  $1 - \\alpha = -(1 - 2\\alpha) \\implies 1 - \\alpha = 2\\alpha - 1$. Solving for $\\alpha$:\n    $$\n    2 = 3\\alpha \\implies \\alpha = \\frac{2}{3}\n    $$\nThis value, $\\alpha_{\\mathrm{opt}} = 2/3$, is the candidate for the optimal parameter. To confirm it gives a minimum, we can analyze the behavior of $\\mu(\\alpha)$. The function $\\mu(\\alpha)$ is the upper envelope of two V-shaped functions, one centered at $\\alpha=1$ and the other at $\\alpha=1/2$. The minimum of this upper envelope occurs at their intersection point $\\alpha=2/3$. For $\\alpha  2/3$, $\\mu(\\alpha)$ is decreasing, and for $\\alpha  2/3$, it is increasing.\n\nThe minimized smoothing factor, $\\mu_{\\min}$, is the value of $\\mu(\\alpha)$ at $\\alpha_{\\mathrm{opt}} = 2/3$:\n$$\n\\mu_{\\min} = \\mu(2/3) = \\max \\left\\{ \\left|1 - \\frac{2}{3}\\right|, \\left|1 - 2\\left(\\frac{2}{3}\\right)\\right| \\right\\}\n$$\n$$\n\\mu_{\\min} = \\max \\left\\{ \\left|\\frac{1}{3}\\right|, \\left|1 - \\frac{4}{3}\\right| \\right\\} = \\max \\left\\{ \\frac{1}{3}, \\left|-\\frac{1}{3}\\right| \\right\\} = \\frac{1}{3}\n$$\nSo, the optimal parameter is $\\alpha_{\\mathrm{opt}} = 2/3$, and the corresponding minimized smoothing factor is $\\mu_{\\min} = 1/3$.\n\nThe final answer is to be reported as a row matrix containing $\\mu_{\\min}$ and $\\alpha_{\\mathrm{opt}}$ in that order.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}}\n$$"
        }
    ]
}