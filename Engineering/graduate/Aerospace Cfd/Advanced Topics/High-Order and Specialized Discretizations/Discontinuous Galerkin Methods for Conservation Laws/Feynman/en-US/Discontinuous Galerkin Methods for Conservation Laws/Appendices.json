{
    "hands_on_practices": [
        {
            "introduction": "The Discontinuous Galerkin method builds its discrete system by evaluating integrals over element interiors and faces. This first practice focuses on a fundamental operation: the numerical evaluation of face integrals. By working through the mapping from a physical element face to a standard reference interval, you will derive the transformation for quadrature weights and determine the necessary quadrature order for exact integration, a critical step for preserving the accuracy of the overall scheme. ",
            "id": "3954969",
            "problem": "Consider a two-dimensional scalar conservation law suitable for aerospace Computational Fluid Dynamics (CFD),\n$$\\partial_{t} u + \\nabla \\cdot (\\boldsymbol{a}\\,u) = 0,$$\nwhere $\\boldsymbol{a}$ is a constant advection velocity and $u$ is approximated within each element by polynomials of degree $p$ in a Discontinuous Galerkin (DG) method. Focus on the numerical flux integral along a straight face $\\mathcal{F}$ of a triangular element, where the face connects the physical points $\\boldsymbol{r}_{0} = (x_{0}, y_{0}) = \\left(\\frac{1}{3}, -2\\right)$ and $\\boldsymbol{r}_{1} = (x_{1}, y_{1}) = \\left(5, \\frac{1}{2}\\right)$. The face integral is evaluated by mapping the standard Gauss–Legendre quadrature on the reference interval $\\hat{s} \\in [-1,1]$ with nodes $\\hat{s}_{i}$ and weights $w_{i}$, $i = 1, \\dots, n$, to the physical face $\\mathcal{F}$. Assume an affine isoparametric mapping of the face from the reference interval to the physical segment connecting $\\boldsymbol{r}_{0}$ and $\\boldsymbol{r}_{1}$. \n\nStarting from fundamental change-of-variables for line integrals and well-tested properties of Gauss–Legendre quadrature, derive the mapped physical face quadrature weights $w_{i}^{\\text{phys}}$ in terms of the reference weights $w_{i}$ and the given endpoints. Then, using the fact that the DG face integrand for constant-coefficient advection with a linear numerical flux is a polynomial in the face parameter whose degree does not exceed $2p$, determine the minimal number $n$ of Gauss–Legendre points required to integrate exactly all polynomials of degree up to $2p$ on the face.\n\nProvide your final answer as a two-entry row matrix, with the first entry equal to the analytical expression for $w_{i}^{\\text{phys}}$ and the second entry equal to the minimal $n$ expressed in terms of $p$. No rounding is required. Express the final answer with exact forms and without units.",
            "solution": "The problem is well-posed and scientifically grounded, containing all necessary information for a rigorous derivation. We shall proceed by first deriving the physical quadrature weights and then determining the minimum number of quadrature points.\n\n### Part 1: Derivation of the Physical Quadrature Weights\n\nA line integral of a function $f(\\boldsymbol{r})$ over the physical face $\\mathcal{F}$ is given by $\\int_{\\mathcal{F}} f(\\boldsymbol{r}) \\, dS$, where $dS$ is the infinitesimal arc length element. The problem specifies an affine mapping from the reference interval $\\hat{s} \\in [-1, 1]$ to the physical face $\\mathcal{F}$, which is the line segment connecting $\\boldsymbol{r}_{0}$ and $\\boldsymbol{r}_{1}$.\n\nAn affine mapping $\\boldsymbol{r}(\\hat{s})$ that maps $\\hat{s}=-1$ to $\\boldsymbol{r}_{0}$ and $\\hat{s}=1$ to $\\boldsymbol{r}_{1}$ can be written using linear Lagrange interpolating polynomials on the interval $[-1, 1]$:\n$$ \\boldsymbol{r}(\\hat{s}) = \\left(\\frac{1-\\hat{s}}{2}\\right) \\boldsymbol{r}_{0} + \\left(\\frac{1+\\hat{s}}{2}\\right) \\boldsymbol{r}_{1} $$\nTo transform the integral from the physical domain to the reference domain, we need the Jacobian of this transformation, which is the magnitude of the derivative of $\\boldsymbol{r}(\\hat{s})$ with respect to $\\hat{s}$.\n$$ \\frac{d\\boldsymbol{r}}{d\\hat{s}} = \\frac{d}{d\\hat{s}} \\left[ \\left(\\frac{1-\\hat{s}}{2}\\right) \\boldsymbol{r}_{0} + \\left(\\frac{1+\\hat{s}}{2}\\right) \\boldsymbol{r}_{1} \\right] = -\\frac{1}{2}\\boldsymbol{r}_{0} + \\frac{1}{2}\\boldsymbol{r}_{1} = \\frac{\\boldsymbol{r}_{1} - \\boldsymbol{r}_{0}}{2} $$\nThe Jacobian, $J$, is the norm of this vector:\n$$ J = \\left\\| \\frac{d\\boldsymbol{r}}{d\\hat{s}} \\right\\| = \\left\\| \\frac{\\boldsymbol{r}_{1} - \\boldsymbol{r}_{0}}{2} \\right\\| = \\frac{\\|\\boldsymbol{r}_{1} - \\boldsymbol{r}_{0}\\|}{2} $$\nThe term $\\|\\boldsymbol{r}_{1} - \\boldsymbol{r}_{0}\\|$ is the length of the face $\\mathcal{F}$, let us call it $L_{\\mathcal{F}}$. Since $\\boldsymbol{r}_{0}$ and $\\boldsymbol{r}_{1}$ are constant vectors, the Jacobian $J$ is a constant value equal to half the length of the physical face.\n\nThe change of variables for the integral is $dS = J \\, d\\hat{s} = \\frac{L_{\\mathcal{F}}}{2} d\\hat{s}$. Thus, the integral transforms as:\n$$ \\int_{\\mathcal{F}} f(\\boldsymbol{r}) \\, dS = \\int_{-1}^{1} f(\\boldsymbol{r}(\\hat{s})) J \\, d\\hat{s} = \\frac{L_{\\mathcal{F}}}{2} \\int_{-1}^{1} f(\\boldsymbol{r}(\\hat{s})) \\, d\\hat{s} $$\nThe problem states that the integral is evaluated using an $n$-point Gauss-Legendre quadrature on the reference interval, which approximates the integral as:\n$$ \\int_{-1}^{1} g(\\hat{s}) \\, d\\hat{s} \\approx \\sum_{i=1}^{n} g(\\hat{s}_{i}) w_{i} $$\nwhere $\\hat{s}_{i}$ are the quadrature nodes and $w_{i}$ are the reference weights.\n\nApplying this quadrature rule to our transformed integral, we get:\n$$ \\int_{\\mathcal{F}} f(\\boldsymbol{r}) \\, dS \\approx \\frac{L_{\\mathcal{F}}}{2} \\sum_{i=1}^{n} f(\\boldsymbol{r}(\\hat{s}_{i})) w_{i} $$\nThe physical quadrature rule takes the form $\\sum_{i=1}^{n} f(\\boldsymbol{r}_{i}^{\\text{phys}}) w_{i}^{\\text{phys}}$, where $\\boldsymbol{r}_{i}^{\\text{phys}} = \\boldsymbol{r}(\\hat{s}_{i})$ are the physical quadrature points.\nBy comparing the two forms, we can identify the physical quadrature weights $w_{i}^{\\text{phys}}$ as:\n$$ w_{i}^{\\text{phys}} = \\frac{L_{\\mathcal{F}}}{2} w_{i} = \\frac{\\|\\boldsymbol{r}_{1} - \\boldsymbol{r}_{0}\\|}{2} w_{i} $$\nWe are given the endpoints $\\boldsymbol{r}_{0} = (x_0, y_0) = \\left(\\frac{1}{3}, -2\\right)$ and $\\boldsymbol{r}_{1} = (x_1, y_1) = \\left(5, \\frac{1}{2}\\right)$. We must compute the length $L_{\\mathcal{F}}$:\n$$ L_{\\mathcal{F}} = \\sqrt{(x_{1} - x_{0})^{2} + (y_{1} - y_{0})^{2}} $$\nSubstituting the given values:\n$$ x_{1} - x_{0} = 5 - \\frac{1}{3} = \\frac{15 - 1}{3} = \\frac{14}{3} $$\n$$ y_{1} - y_{0} = \\frac{1}{2} - (-2) = \\frac{1}{2} + 2 = \\frac{5}{2} $$\nNow, we compute the square of the length:\n$$ L_{\\mathcal{F}}^{2} = \\left(\\frac{14}{3}\\right)^{2} + \\left(\\frac{5}{2}\\right)^{2} = \\frac{196}{9} + \\frac{25}{4} = \\frac{196 \\cdot 4 + 25 \\cdot 9}{36} = \\frac{784 + 225}{36} = \\frac{1009}{36} $$\nThe length is thus $L_{\\mathcal{F}} = \\sqrt{\\frac{1009}{36}} = \\frac{\\sqrt{1009}}{6}$.\nThe factor multiplying the reference weights is $\\frac{L_{\\mathcal{F}}}{2}$:\n$$ \\frac{L_{\\mathcal{F}}}{2} = \\frac{1}{2} \\cdot \\frac{\\sqrt{1009}}{6} = \\frac{\\sqrt{1009}}{12} $$\nTherefore, the physical quadrature weights are given by the analytical expression:\n$$ w_{i}^{\\text{phys}} = \\frac{\\sqrt{1009}}{12} w_{i} $$\n\n### Part 2: Determination of the Minimal Number of Quadrature Points\n\nThe problem states that the integrand on the face is a polynomial in the face parameter $\\hat{s}$ of degree at most $2p$. Let this integrand be denoted $P(\\hat{s})$, so that $\\text{deg}(P) \\le 2p$.\nA key property of the $n$-point Gauss-Legendre quadrature rule is that it integrates any polynomial of degree up to $2n-1$ exactly.\nTo ensure that our face integral is computed exactly, the order of the quadrature rule must be sufficient to handle a polynomial of degree $2p$. This requires the condition:\n$$ 2n - 1 \\ge 2p $$\nWe are asked to find the minimal integer number of points $n$ that satisfies this condition. Solving the inequality for $n$:\n$$ 2n \\ge 2p + 1 $$\n$$ n \\ge p + \\frac{1}{2} $$\nSince the number of quadrature points $n$ must be an integer, we must take the smallest integer value of $n$ that satisfies this inequality. This is given by the ceiling function:\n$$ n = \\lceil p + \\frac{1}{2} \\rceil $$\nGiven that $p$ (the polynomial degree of the basis functions) is a non-negative integer, $p + \\frac{1}{2}$ will never be an integer. The smallest integer greater than $p + \\frac{1}{2}$ is $p+1$.\nThus, the minimal number of Gauss-Legendre points required is:\n$$ n = p+1 $$\nWith $n=p+1$ points, the quadrature rule is exact for polynomials of degree up to $2(p+1)-1 = 2p+1$, which certainly includes all polynomials of degree up to $2p$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\sqrt{1009}}{12} w_{i} & p+1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving from face integrals to volume integrals, we now examine the mass matrix, which arises from the time derivative term in the conservation law. In practical aerospace applications, meshes must conform to curved boundaries, requiring the use of curved elements. This exercise explores how an isoparametric mapping from a simple reference element to a curved physical element affects the local mass matrix, connecting element geometry directly to the matrix's condition number and, consequently, to the stability and efficiency of the numerical solution. ",
            "id": "3954996",
            "problem": "Consider a scalar conservation law in one spatial dimension, given by $\\partial_{t} u(x,t) + \\partial_{x} f(u(x,t)) = 0$, discretized by the Discontinuous Galerkin (DG) method within Computational Fluid Dynamics (CFD). On a single physical element $K$ corresponding to a curved mesh segment designed to model near-wall stretching in aerospace flows, assume an isoparametric quadratic mapping from a reference element $\\hat{K} = [-1,1]$ with coordinate $\\xi$ to the physical element with coordinate $x$, defined by\n$$\nx(\\xi) = x_{c} + \\frac{h}{2}\\left(\\xi + \\frac{s}{2}\\left(\\xi^{2} - 1\\right)\\right),\n$$\nwhere $x_{c}$ is the element center, $h > 0$ is a characteristic element size, and $s \\in \\mathbb{R}$ is a dimensionless shape parameter that controls the stretching; the mapping is required to be nondegenerate and orientation-preserving, so $\\frac{dx}{d\\xi} > 0$ for all $\\xi \\in [-1,1]$.\n\nDenote by $\\{ \\phi_{0}, \\phi_{1} \\}$ the modal basis consisting of the first two Legendre polynomials on $[-1,1]$, specifically $\\phi_{0}(\\xi) = 1$ and $\\phi_{1}(\\xi) = \\xi$. The local mass matrix on $K$ arises in the DG semi-discrete weak form from the $L^{2}$ inner product weighted by the Jacobian of the mapping, namely\n$$\nM_{ij} = \\int_{-1}^{1} \\phi_{i}(\\xi)\\,\\phi_{j}(\\xi)\\,J(\\xi)\\,d\\xi, \\quad J(\\xi) := \\frac{dx}{d\\xi}.\n$$\n\nStarting from the definition of the scalar conservation law and the DG weak form on the physical element, carry out the reference-to-physical-element change of variables and explicitly compute the entries of the local $2 \\times 2$ mass matrix for the above mapping and basis. Then, determine the eigenvalues of this symmetric positive definite matrix and derive its spectral condition number, defined as the ratio of the largest eigenvalue to the smallest eigenvalue, as an explicit function of the shape parameter $s$ and the size $h$. Your final answer must be a single closed-form analytic expression in $s$ only (units are not required). Assume the nondegeneracy condition holds throughout the element and restrict $s$ such that $J(\\xi) > 0$ for all $\\xi \\in [-1,1]$.",
            "solution": "The problem requires the computation of the local $2 \\times 2$ mass matrix $M$ for a specific quadratic mapping, and then to find its spectral condition number as a function of the shape parameter $s$.\n\nFirst, we must find the Jacobian of the mapping $J(\\xi) = \\frac{dx}{d\\xi}$. The mapping is given by:\n$$ x(\\xi) = x_{c} + \\frac{h}{2}\\left(\\xi + \\frac{s}{2}\\left(\\xi^{2} - 1\\right)\\right) $$\nDifferentiating with respect to $\\xi$:\n$$ J(\\xi) = \\frac{dx}{d\\xi} = \\frac{h}{2}\\left(1 + \\frac{s}{2}(2\\xi)\\right) = \\frac{h}{2}(1 + s\\xi) $$\nThe problem states that the mapping is nondegenerate, which means $J(\\xi) > 0$ for all $\\xi \\in [-1, 1]$. This implies $1+s\\xi > 0$ on the interval, which constrains the shape parameter to $|s|  1$.\n\nThe mass matrix entries are defined by $M_{ij} = \\int_{-1}^{1} \\phi_{i}(\\xi)\\,\\phi_{j}(\\xi)\\,J(\\xi)\\,d\\xi$ for the basis functions $\\phi_{0}(\\xi) = 1$ and $\\phi_{1}(\\xi) = \\xi$. We compute the entries of the symmetric matrix $M$:\n\n**Entry $M_{00}$:**\n$$ M_{00} = \\int_{-1}^{1} \\phi_{0}(\\xi)\\phi_{0}(\\xi)J(\\xi)d\\xi = \\int_{-1}^{1} (1)(1) \\frac{h}{2}(1 + s\\xi) d\\xi $$\n$$ M_{00} = \\frac{h}{2} \\left[ \\xi + \\frac{s\\xi^2}{2} \\right]_{-1}^{1} = \\frac{h}{2} \\left( \\left(1 + \\frac{s}{2}\\right) - \\left(-1 + \\frac{s}{2}\\right) \\right) = \\frac{h}{2}(2) = h $$\n\n**Entry $M_{01} = M_{10}$:**\n$$ M_{01} = \\int_{-1}^{1} \\phi_{0}(\\xi)\\phi_{1}(\\xi)J(\\xi)d\\xi = \\int_{-1}^{1} (1)(\\xi) \\frac{h}{2}(1 + s\\xi) d\\xi $$\n$$ M_{01} = \\frac{h}{2} \\int_{-1}^{1} (\\xi + s\\xi^2) d\\xi = \\frac{h}{2} \\left[ \\frac{\\xi^2}{2} + \\frac{s\\xi^3}{3} \\right]_{-1}^{1} = \\frac{h}{2} \\left( \\left(\\frac{1}{2} + \\frac{s}{3}\\right) - \\left(\\frac{1}{2} - \\frac{s}{3}\\right) \\right) = \\frac{h}{2}\\left(\\frac{2s}{3}\\right) = \\frac{hs}{3} $$\n\n**Entry $M_{11}$:**\n$$ M_{11} = \\int_{-1}^{1} \\phi_{1}(\\xi)\\phi_{1}(\\xi)J(\\xi)d\\xi = \\int_{-1}^{1} (\\xi)(\\xi) \\frac{h}{2}(1 + s\\xi) d\\xi $$\n$$ M_{11} = \\frac{h}{2} \\int_{-1}^{1} (\\xi^2 + s\\xi^3) d\\xi = \\frac{h}{2} \\left[ \\frac{\\xi^3}{3} + \\frac{s\\xi^4}{4} \\right]_{-1}^{1} = \\frac{h}{2} \\left( \\left(\\frac{1}{3} + \\frac{s}{4}\\right) - \\left(-\\frac{1}{3} + \\frac{s}{4}\\right) \\right) = \\frac{h}{2}\\left(\\frac{2}{3}\\right) = \\frac{h}{3} $$\n\nThe resulting local mass matrix is:\n$$ M = \\begin{pmatrix} h  \\frac{hs}{3} \\\\ \\frac{hs}{3}  \\frac{h}{3} \\end{pmatrix} = h \\begin{pmatrix} 1  \\frac{s}{3} \\\\ \\frac{s}{3}  \\frac{1}{3} \\end{pmatrix} $$\nNext, we find the eigenvalues $\\lambda$ of this matrix. The characteristic equation is $\\det\\left(M - \\lambda I\\right) = 0$.\n$$ \\det \\begin{pmatrix} h-\\lambda  \\frac{hs}{3} \\\\ \\frac{hs}{3}  \\frac{h}{3}-\\lambda \\end{pmatrix} = 0 $$\n$$ (h-\\lambda)(\\frac{h}{3}-\\lambda) - \\left(\\frac{hs}{3}\\right)^2 = 0 $$\n$$ \\lambda^2 - \\frac{4h}{3}\\lambda + \\frac{h^2}{3} - \\frac{h^2s^2}{9} = 0 $$\nUsing the quadratic formula for $\\lambda$:\n$$ \\lambda = \\frac{-\\left(-\\frac{4h}{3}\\right) \\pm \\sqrt{\\left(-\\frac{4h}{3}\\right)^2 - 4(1)\\left(\\frac{h^2}{3} - \\frac{h^2s^2}{9}\\right)}}{2} = \\frac{\\frac{4h}{3} \\pm \\sqrt{\\frac{16h^2}{9} - \\frac{4h^2}{3} + \\frac{4h^2s^2}{9}}}{2} $$\n$$ \\lambda = \\frac{\\frac{4h}{3} \\pm \\sqrt{\\frac{16h^2 - 12h^2 + 4h^2s^2}{9}}}{2} = \\frac{\\frac{4h}{3} \\pm \\sqrt{\\frac{4h^2(1 + s^2)}{9}}}{2} = \\frac{\\frac{4h}{3} \\pm \\frac{2h}{3}\\sqrt{1 + s^2}}{2} = \\frac{h}{3}(2 \\pm \\sqrt{1 + s^2}) $$\nThe eigenvalues of the mass matrix $M$ are:\n$$ \\lambda_{\\max} = \\frac{h}{3}(2 + \\sqrt{1 + s^2}) \\quad \\text{and} \\quad \\lambda_{\\min} = \\frac{h}{3}(2 - \\sqrt{1 + s^2}) $$\nThe condition number $\\kappa(M)$ is the ratio of the largest to the smallest eigenvalue:\n$$ \\kappa(M) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{\\frac{h}{3}(2 + \\sqrt{1 + s^2})}{\\frac{h}{3}(2 - \\sqrt{1 + s^2})} = \\frac{2 + \\sqrt{1 + s^2}}{2 - \\sqrt{1 + s^2}} $$\nThis expression depends only on the shape parameter $s$, as required.",
            "answer": "$$\n\\boxed{\\frac{2 + \\sqrt{1+s^{2}}}{2 - \\sqrt{1+s^{2}}}}\n$$"
        },
        {
            "introduction": "While the core DG formulation is highly accurate for smooth solutions, it notoriously produces spurious oscillations near discontinuities like shock waves. To create a robust method for aerospace applications, we must introduce slope limiters. This comprehensive practice guides you through the derivation of a `minmod`-type limiter from the fundamental principle of preventing new extrema, its numerical application, and a critical analysis of its impact on accuracy—revealing the essential compromise between maintaining high-order accuracy and ensuring non-oscillatory shock capturing. ",
            "id": "3954984",
            "problem": "Consider the one-dimensional scalar conservation law $u_{t} + f(u)_{x} = 0$ posed on a uniform mesh with cells $I_{i} = [x_{i-1/2}, x_{i+1/2}]$ of width $\\Delta x$. In a piecewise-linear Discontinuous Galerkin (DG) method, the cellwise approximation is $u_{h}|_{I_{i}}(x) = \\bar{u}_{i} + \\sigma_{i} (x - x_{i})$, where $\\bar{u}_{i}$ is the cell average and $\\sigma_{i}$ is the slope coefficient. To prevent spurious oscillations near steep gradients, slope limiting is introduced with the aim of preserving the Total Variation Diminishing (TVD) property at the discrete level under monotone numerical fluxes.\n\nStarting from the definition of total variation in terms of the sequence of cell averages and the requirement that the interface values $u_{i}^{-} = \\bar{u}_{i} - \\frac{1}{2}\\sigma_{i}\\Delta x$ and $u_{i}^{+} = \\bar{u}_{i} + \\frac{1}{2}\\sigma_{i}\\Delta x$ do not create new local extrema, derive a limiter that constrains $\\sigma_{i}$ by comparing it to one-sided discrete gradients computed from neighboring cell averages. Show that this construction leads to a minmod-type limiter for the slope coefficient in one dimension, and express the final limited slope $\\sigma_{i}^{\\text{lim}}$ in terms of the unlimited slope $\\sigma_{i}^{(0)}$, the local one-sided differences, and a parameter $\\theta \\in [1,2]$ that relaxes the bound. Your derivation must begin from the TVD principle and the monotonicity of interface values and proceed to a closed-form expression for $\\sigma_{i}^{\\text{lim}}$.\n\nThen, on a uniform mesh with $\\Delta x = 0.4$ expressed in meters, consider the cell $I_{i}$ with data $\\bar{u}_{i-1} = 1.2$, $\\bar{u}_{i} = 1.0$, $\\bar{u}_{i+1} = 0.7$, and unlimited slope $\\sigma_{i}^{(0)} = -0.6$ expressed in inverse meters. Using the derived limiter with $\\theta = 1.5$, compute the limited slope $\\sigma_{i}^{\\text{lim}}$ for this cell. Express the final limited slope in inverse meters and round your answer to four significant figures.\n\nFinally, analyze the accuracy implications of applying this limiter at a smooth extremum versus at a discontinuity. Using a Taylor expansion of a smooth function $u(x)$ around $x_{i}$, determine the signs of the one-sided average differences near a point where $u'(x_{i}) = 0$ and $u''(x_{i}) \\neq 0$, and explain the limiter’s action in this case. Contrast this behavior with the case of a genuine discontinuity where the one-sided differences share the same sign. Your analysis should connect the limiter’s decision (zeroing the slope or retaining a bounded slope) to the local order of accuracy and non-oscillatory behavior.\n\nExpress the final limited slope value in inverse meters. Round your final numerical answer to four significant figures.",
            "solution": "The problem requires a three-part response: the derivation of a minmod-type slope limiter for a piecewise-linear Discontinuous Galerkin (DG) method, a numerical application of this limiter, and an analysis of its accuracy properties. We shall address each part in sequence.\n\n### Part 1: Derivation of the Minmod-Type Limiter\n\nWe consider a one-dimensional scalar conservation law $u_{t} + f(u)_{x} = 0$. The solution domain is discretized into cells $I_{i} = [x_{i-1/2}, x_{i+1/2}]$ of uniform width $\\Delta x = x_{i+1/2} - x_{i-1/2}$. Within each cell $I_i$, the solution is approximated by a linear polynomial:\n$$u_{h}|_{I_{i}}(x) = \\bar{u}_{i} + \\sigma_{i} (x - x_{i})$$\nwhere $x_i = (x_{i-1/2} + x_{i+1/2})/2$ is the cell center, $\\bar{u}_{i}$ is the cell average of the solution in $I_i$, and $\\sigma_{i}$ is the slope of the linear approximation.\n\nThe core principle for ensuring non-oscillatory behavior, particularly for preserving the Total Variation Diminishing (TVD) property, is to prevent the introduction of new local extrema. A sufficient condition for this is that the values of the reconstructed polynomial at the cell boundaries, $u_{i}^{-} = u_{h}(x_{i-1/2})$ and $u_{i}^{+} = u_{h}(x_{i+1/2})$, should not overshoot the cell average values of the adjacent cells.\n\nThe values at the cell boundaries are given by:\n$$u_{i}^{-} = \\bar{u}_{i} + \\sigma_{i} (x_{i-1/2} - x_{i}) = \\bar{u}_{i} - \\frac{1}{2}\\sigma_{i}\\Delta x$$\n$$u_{i}^{+} = \\bar{u}_{i} + \\sigma_{i} (x_{i+1/2} - x_{i}) = \\bar{u}_{i} + \\frac{1}{2}\\sigma_{i}\\Delta x$$\n\nThe non-overshoot conditions are:\n$1$. The value $u_{i}^{-}$ must lie between $\\bar{u}_{i}$ and $\\bar{u}_{i-1}$.\n$2$. The value $u_{i}^{+}$ must lie between $\\bar{u}_{i}$ and $\\bar{u}_{i+1}$.\n\nLet's analyze the first condition for $u_{i}^{-}$.\nIf $\\bar{u}_{i}  \\bar{u}_{i-1}$, we require $\\bar{u}_{i-1} \\le u_{i}^{-} \\le \\bar{u}_{i}$.\nThe right inequality, $\\bar{u}_{i} - \\frac{1}{2}\\sigma_{i}\\Delta x \\le \\bar{u}_{i}$, implies $\\sigma_{i} \\ge 0$.\nThe left inequality, $\\bar{u}_{i-1} \\le \\bar{u}_{i} - \\frac{1}{2}\\sigma_{i}\\Delta x$, implies $\\frac{1}{2}\\sigma_{i}\\Delta x \\le \\bar{u}_{i} - \\bar{u}_{i-1}$, so $\\sigma_{i} \\le \\frac{2(\\bar{u}_{i} - \\bar{u}_{i-1})}{\\Delta x}$.\nThus, for this case, $0 \\le \\sigma_{i} \\le 2\\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x}$.\n\nIf $\\bar{u}_{i}  \\bar{u}_{i-1}$, we require $\\bar{u}_{i} \\le u_{i}^{-} \\le \\bar{u}_{i-1}$.\nThe left inequality implies $\\sigma_{i} \\le 0$. The right inequality implies $\\sigma_{i} \\ge 2\\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x}$.\nThus, for this case, $2\\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x} \\le \\sigma_{i} \\le 0$.\n\nLet's define the backward-difference slope as $\\sigma_{i}^{-} = \\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x}$. The condition on $\\sigma_i$ from the left boundary $x_{i-1/2}$ is that if $\\sigma_i$ and $\\sigma_i^-$ have the same sign, then $|\\sigma_i| \\le 2|\\sigma_i^-|$. If they have opposite signs, the condition is only met if $\\sigma_i=0$.\n\nNow, let's analyze the second condition for $u_{i}^{+}$.\nIf $\\bar{u}_{i}  \\bar{u}_{i+1}$, we require $\\bar{u}_{i} \\le u_{i}^{+} \\le \\bar{u}_{i+1}$. This leads to $0 \\le \\sigma_{i} \\le 2\\frac{\\bar{u}_{i+1} - \\bar{u}_{i}}{\\Delta x}$.\nIf $\\bar{u}_{i}  \\bar{u}_{i+1}$, we require $\\bar{u}_{i+1} \\le u_{i}^{+} \\le \\bar{u}_{i}$. This leads to $2\\frac{\\bar{u}_{i+1} - \\bar{u}_{i}}{\\Delta x} \\le \\sigma_{i} \\le 0$.\n\nLet's define the forward-difference slope as $\\sigma_{i}^{+} = \\frac{\\bar{u}_{i+1} - \\bar{u}_{i}}{\\Delta x}$. The condition on $\\sigma_i$ from the right boundary $x_{i+1/2}$ is that if $\\sigma_i$ and $\\sigma_i^+$ have the same sign, then $|\\sigma_i| \\le 2|\\sigma_i^+|$. If they have opposite signs, the condition is met only if $\\sigma_i = 0$.\n\nTo satisfy both boundary conditions simultaneously, the slope $\\sigma_i$ must adhere to both constraints.\n- If $\\sigma_{i}^{-}$, $\\sigma_{i}^{+}$ and the desired slope $\\sigma_{i}$ all have the same sign, then $|\\sigma_{i}|$ must be bounded by both $2|\\sigma_{i}^{-}|$ and $2|\\sigma_{i}^{+}|$. This means $|\\sigma_{i}| \\le \\min(2|\\sigma_{i}^{-}|, 2|\\sigma_{i}^{+}|)$.\n- If $\\sigma_{i}^{-}$ and $\\sigma_{i}^{+}$ have opposite signs, the solution has a local extremum at cell $I_i$. In this case, the only way to satisfy both sets of constraints is to set $\\sigma_{i} = 0$.\n\nThis leads to a limiting procedure. Given an unlimited slope $\\sigma_{i}^{(0)}$ (e.g., from a higher-order reconstruction or a centered difference), the limited slope $\\sigma_i^{\\text{lim}}$ must satisfy these bounds. The factor of $2$ is the most generous allowable under the no-overshoot principle. This can be relaxed using a parameter $\\theta \\in [1, 2]$, where $\\theta=1$ is more restrictive (often used in finite volume methods) and $\\theta=2$ is the limit for non-overshooting piecewise linear reconstruction. The general bound becomes $|\\sigma_{i}| \\le \\min(\\theta|\\sigma_{i}^{-}|, \\theta|\\sigma_{i}^{+}|)$.\n\nThe `minmod` function is a convenient way to express this logic. The generalized minmod function is defined as:\n$$\\text{minmod}(a_{1}, a_{2}, \\dots, a_{n}) = \n\\begin{cases} \n\\min(a_{1}, a_{2}, \\dots, a_{n})  \\text{if } a_{k}  0 \\text{ for all } k \\\\\n\\max(a_{1}, a_{2}, \\dots, a_{n})  \\text{if } a_{k}  0 \\text{ for all } k \\\\\n0  \\text{otherwise}\n\\end{cases}$$\nThis function returns the argument with the minimum absolute value if all arguments have the same sign, and $0$ otherwise.\n\nUsing this function, the limited slope $\\sigma_i^{\\text{lim}}$ can be constructed by forcing the unlimited a priori slope $\\sigma_i^{(0)}$ to conform to the derived bounds.  The final limited slope is given by:\n$$\\sigma_{i}^{\\text{lim}} = \\text{minmod}(\\sigma_{i}^{(0)}, \\theta \\sigma_{i}^{-}, \\theta \\sigma_{i}^{+})$$\nThis expression elegantly enforces the desired properties: if $\\sigma_i^{(0)}$, $\\sigma_i^{-}$, and $\\sigma_i^{+}$ do not all share the same sign (indicating an extremum or oscillation), the slope is flattened to zero. Otherwise, the slope $\\sigma_i^{(0)}$ is chosen only if its magnitude is smaller than the bounds given by $\\theta|\\sigma_i^{-}|$ and $\\theta|\\sigma_i^{+}|$; otherwise, it is \"limited\" to the bound with the smaller magnitude.\n\n### Part 2: Numerical Calculation\n\nWe are given the following data on a uniform mesh:\n- Cell width: $\\Delta x = 0.4$ meters\n- Cell averages: $\\bar{u}_{i-1} = 1.2$, $\\bar{u}_{i} = 1.0$, $\\bar{u}_{i+1} = 0.7$\n- Unlimited slope in cell $I_i$: $\\sigma_{i}^{(0)} = -0.6$ inverse meters\n- Limiter parameter: $\\theta = 1.5$\n\nFirst, we compute the one-sided discrete gradient slopes, $\\sigma_i^{-}$ and $\\sigma_i^{+}$:\n$$\\sigma_{i}^{-} = \\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x} = \\frac{1.0 - 1.2}{0.4} = \\frac{-0.2}{0.4} = -0.5 \\, \\text{m}^{-1}$$\n$$\\sigma_{i}^{+} = \\frac{\\bar{u}_{i+1} - \\bar{u}_{i}}{\\Delta x} = \\frac{0.7 - 1.0}{0.4} = \\frac{-0.3}{0.4} = -0.75 \\, \\text{m}^{-1}$$\n\nNext, we calculate the bounded slope terms using the parameter $\\theta$:\n$$\\theta \\sigma_{i}^{-} = 1.5 \\times (-0.5) = -0.75 \\, \\text{m}^{-1}$$\n$$\\theta \\sigma_{i}^{+} = 1.5 \\times (-0.75) = -1.125 \\, \\text{m}^{-1}$$\n\nNow, we apply the `minmod` function to the three arguments: $\\sigma_{i}^{(0)}$, $\\theta \\sigma_{i}^{-}$, and $\\theta \\sigma_{i}^{+}$.\nThe arguments are: $-0.6$, $-0.75$, and $-1.125$.\nAll three arguments are negative. Therefore, the `minmod` function returns the maximum of these values (i.e., the one with the smallest absolute value).\n$$\\sigma_{i}^{\\text{lim}} = \\text{minmod}(-0.6, -0.75, -1.125) = \\max(-0.6, -0.75, -1.125) = -0.6 \\, \\text{m}^{-1}$$\nThe unlimited slope $\\sigma_i^{(0)}$ is already within the bounds set by the limiter, so it is not modified. Rounding to four significant figures, the limited slope is $-0.6000 \\, \\text{m}^{-1}$.\n\n### Part 3: Accuracy Analysis\n\nWe analyze the limiter's behavior in two distinct scenarios: a smooth extremum and a discontinuity.\n\n**Case 1: Smooth Extremum**\nConsider a smooth function $u(x)$ that has a local maximum at $x = x_i$. This implies $u'(x_i) = 0$ and $u''(x_i)  0$. The cell averages $\\bar{u}_k$ are second-order approximations to the point values $u(x_k)$, specifically $\\bar{u}_k = u(x_k) + O(\\Delta x^2)$. More precisely, for a quadratic profile, $\\bar{u}_k = u(x_k) + \\frac{u''(x_k)}{24}\\Delta x^2$.\nLet's analyze the signs of the differences of cell averages. Near a smooth maximum at $x_i$, the function values are increasing for $xx_i$ and decreasing for $xx_i$. This pattern is inherited by the cell averages: $\\bar{u}_{i-1}  \\bar{u}_i$ and $\\bar{u}_{i+1}  \\bar{u}_i$.\nTherefore, the signs of the one-sided differences are:\n- $\\bar{u}_{i} - \\bar{u}_{i-1}  0 \\implies \\sigma_{i}^{-} = \\frac{\\bar{u}_{i} - \\bar{u}_{i-1}}{\\Delta x}  0$\n- $\\bar{u}_{i+1} - \\bar{u}_{i}  0 \\implies \\sigma_{i}^{+} = \\frac{\\bar{u}_{i+1} - \\bar{u}_{i}}{\\Delta x}  0$\n\nSince $\\sigma_{i}^{-}$ and $\\sigma_{i}^{+}$ have opposite signs, the `minmod` function will return zero, regardless of the value of the unlimited slope $\\sigma_i^{(0)}$:\n$$\\sigma_{i}^{\\text{lim}} = \\text{minmod}(\\sigma_{i}^{(0)}, \\theta \\sigma_{i}^{-}, \\theta \\sigma_{i}^{+}) = 0$$\nThis action, known as \"extremum clipping,\" forces the reconstruction in the cell containing the extremum to be piecewise constant ($u_h(x) = \\bar{u}_i$). While this successfully prevents spurious oscillations, it locally degrades the accuracy of the scheme from second-order ($O(\\Delta x^2)$) to first-order ($O(\\Delta x)$). This is a classic drawback of TVD-based limiters.\n\n**Case 2: Discontinuity**\nConsider a monotonic profile with a steep gradient or discontinuity, such as a shock wave, where the solution decreases sharply. In this scenario, it is likely that the cell averages are also monotonic, for instance $\\bar{u}_{i-1}  \\bar{u}_{i}  \\bar{u}_{i+1}$ (as in our numerical example).\nThe signs of the one-sided differences are:\n- $\\bar{u}_{i} - \\bar{u}_{i-1}  0 \\implies \\sigma_{i}^{-}  0$\n- $\\bar{u}_{i+1} - \\bar{u}_{i}  0 \\implies \\sigma_{i}^{+}  0$\n\nIn this case, both $\\sigma_{i}^{-}$ and $\\sigma_{i}^{+}$ are negative. If the unlimited slope $\\sigma_{i}^{(0)}$ also correctly reflects the decreasing trend (i.e., $\\sigma_{i}^{(0)}  0$), then all three arguments to the `minmod` function are negative. The function will return a non-zero value:\n$$\\sigma_{i}^{\\text{lim}} = \\max(\\sigma_{i}^{(0)}, \\theta \\sigma_{i}^{-}, \\theta \\sigma_{i}^{+})$$\nThe limiter preserves a non-zero, negative slope, allowing the reconstruction to represent the steep gradient. The magnitude of the slope is bounded by the local differences, which prevents the linear reconstruction from over- or undershooting the neighboring cell average values, thereby suppressing numerical oscillations (Gibbs phenomenon).\n\n**Contrast and Conclusion**\nThe limiter intelligently distinguishes between a smooth extremum and a discontinuity based on the local monotonicity of the cell-averaged data.\n- At a **smooth extremum**, the change in sign of the local gradients ($\\sigma_i^-$ vs. $\\sigma_i^+$) triggers the limiter to set the slope to zero. This enforces non-oscillatory behavior at the cost of reducing the local order of accuracy.\n- At a **discontinuity** within a monotonic region, the consistent sign of the local gradients allows the limiter to retain a non-zero slope. This slope is bounded to be just steep enough to capture the sharp feature without introducing spurious wiggles. Here, the goal is not formal Taylor-series accuracy but robust, non-oscillatory resolution, which the limiter achieves.",
            "answer": "$$\\boxed{-0.6000}$$"
        }
    ]
}