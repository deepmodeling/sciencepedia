{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of developing reliable adjoint solvers is the rigorous verification of the computed gradients. The discrete adjoint method provides the exact analytical gradient of a discrete functional with respect to its parameters. This exercise  provides hands-on practice with the essential \"gradient check,\" where the analytically derived adjoint gradient is compared against a finite-difference approximation. By implementing this for a canonical 1D convection-diffusion problem, you will build foundational skills in deriving, implementing, and validating a discrete adjoint solver.",
            "id": "3950976",
            "problem": "Consider a one-dimensional, steady, dimensionless convection-diffusion model frequently used in Computational Fluid Dynamics (CFD), derived from conservation of a transported scalar. On the domain $x \\in [0,1]$ with uniform mesh of $N$ points, Dirichlet boundary conditions $U(0)=0$ and $U(1)=0$, and interior nodes indexed by $i=1,\\dots,N-2$, let the discrete residual at each interior node be\n$$\nR_i(U,p) = \\Gamma \\frac{U_{i-1} - 2 U_i + U_{i+1}}{\\Delta x^2} - a \\frac{U_i - U_{i-1}}{\\Delta x} - s_i(p),\n$$\nwhere $U_i$ denotes the discrete state at node $i$, $\\Delta x = \\frac{1}{N-1}$, $a \\ge 0$ is a dimensionless convection strength, $\\Gamma > 0$ is a dimensionless diffusion coefficient, and $s_i(p)$ is a dimensionless source term that depends on a scalar design parameter $p$. Assume $s_i(p) = p f_i$ with $f_i = \\sin(\\pi x_i)$ and $x_i = i \\Delta x$. The discrete state $U$ is defined implicitly by the steady residual equation $R(U,p)=0$, which for this linear model can be written as $A U = s(p)$ with the tridiagonal matrix $A$ independent of $p$ given by\n$$\nA_{i,i} = -\\frac{2\\Gamma}{\\Delta x^2} - \\frac{a}{\\Delta x}, \\quad A_{i,i-1} = \\frac{\\Gamma}{\\Delta x^2} + \\frac{a}{\\Delta x}, \\quad A_{i,i+1} = \\frac{\\Gamma}{\\Delta x^2},\n$$\nfor all valid indices where boundary values are zero and therefore contribute no additional source terms. Consider the cost functional\n$$\nJ(U,p) = \\frac{1}{2}\\,\\Delta x \\sum_{i=1}^{N-2} \\left(U_i - U_i^\\star\\right)^2 + \\beta\\, p,\n$$\nwhere $U_i^\\star = \\sin(2\\pi x_i)$ is a prescribed, dimensionless target field and $\\beta$ is a dimensionless scalar weight. Angles in all trigonometric functions are measured in radians.\n\nTask: Starting from the discrete residual definition and the chain rule applied to the implicit state $U(p)$, derive the discrete adjoint equation and the gradient formula\n$$\n\\frac{dJ}{dp} = J_p^T - \\lambda^T R_p,\n$$\nwhere $\\lambda$ is the adjoint variable defined by a linear system that you must obtain, $J_p$ is the partial derivative of $J$ with respect to $p$ at fixed $U$, and $R_p$ is the partial derivative of $R$ with respect to $p$ at fixed $U$. Then implement a program that:\n- Constructs the matrix $A$, solves for the state $U$ via $A U = s(p)$, computes the adjoint variable $\\lambda$ from the appropriate linear system, and evaluates the discrete-adjoint gradient $\\frac{dJ}{dp}$.\n- Computes a finite-difference estimate of $\\frac{dJ}{dp}$ using a symmetric difference with a small step $h$,\n$$\n\\left.\\frac{dJ}{dp}\\right|_{\\text{FD}} \\approx \\frac{J(U(p+h),p+h) - J(U(p-h),p-h)}{2h}.\n$$\n- Returns, for each test case, the absolute difference between the discrete-adjoint gradient and the finite-difference gradient, as a floating-point number.\n\nAll quantities are dimensionless. You must use angles in radians for all trigonometric evaluations. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots]$).\n\nUse the following test suite with parameter tuples $(N,a,\\Gamma,p,\\beta)$:\n- Case $1$: $(N,a,\\Gamma,p,\\beta) = (50, 1.0, 0.1, 0.5, 0.3)$.\n- Case $2$: $(N,a,\\Gamma,p,\\beta) = (20, 0.0, 0.5, 1.0, 0.0)$.\n- Case $3$: $(N,a,\\Gamma,p,\\beta) = (200, 5.0, 10^{-3}, 0.1, 1.0)$.\n- Case $4$: $(N,a,\\Gamma,p,\\beta) = (5, 0.2, 0.05, 0.8, 0.2)$.\n\nYour output must be a single list $[d_1,d_2,d_3,d_4]$ where $d_k$ is the absolute difference between the discrete-adjoint gradient and the finite-difference gradient for case $k$, expressed as floating-point numbers.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It presents a standard problem in CFD-based optimization using the discrete adjoint method. All necessary data and definitions are provided.\n\n### Derivation of the Discrete Adjoint Gradient\n\nThe objective is to compute the total derivative of the cost functional $J(U,p)$ with respect to the design parameter $p$. The state vector $U$ is an implicit function of $p$, defined by the steady-state residual equation $R(U(p), p) = 0$.\n\nThe cost functional is given by:\n$$\nJ(U,p) = \\frac{1}{2}\\,\\Delta x \\sum_{i=1}^{N-2} \\left(U_i - U_i^\\star\\right)^2 + \\beta\\, p\n$$\nThe discrete residual equation for each interior node $i \\in \\{1, \\dots, N-2\\}$ is:\n$$\nR_i(U,p) = \\left( \\frac{\\Gamma}{\\Delta x^2} + \\frac{a}{\\Delta x} \\right) U_{i-1} + \\left( -\\frac{2\\Gamma}{\\Delta x^2} - \\frac{a}{\\Delta x} \\right) U_i + \\left( \\frac{\\Gamma}{\\Delta x^2} \\right) U_{i+1} - p f_i = 0\n$$\nwhere $f_i = \\sin(\\pi x_i)$. This can be written in matrix form as $R(U, p) = A U - s(p) = 0$, where $A$ is the system matrix, and $s(p)$ is the source vector with components $s_i(p) = p f_i$.\n\n**1. Total Derivative using the Chain Rule**\n\nApplying the chain rule to $J(U(p), p)$, we obtain the total derivative with respect to $p$:\n$$\n\\frac{dJ}{dp} = \\frac{\\partial J}{\\partial p} + \\left(\\nabla_U J\\right)^T \\frac{dU}{dp}\n$$\nHere, $\\frac{\\partial J}{\\partial p}$ is the partial derivative of $J$ with respect to $p$ holding $U$ constant, $\\nabla_U J$ is the gradient of $J$ with respect to the state vector $U$ (a column vector of partial derivatives $\\frac{\\partial J}{\\partial U_i}$), and $\\frac{dU}{dp}$ is the state sensitivity vector, whose components are $\\frac{dU_i}{dp}$.\n\n**2. State Sensitivity Derivation**\n\nThe state sensitivity vector $\\frac{dU}{dp}$ is found by differentiating the state equation $R(U(p), p) = 0$ with respect to $p$:\n$$\n\\frac{dR}{dp} = \\frac{\\partial R}{\\partial U} \\frac{dU}{dp} + \\frac{\\partial R}{\\partial p} = 0\n$$\nwhere $\\frac{\\partial R}{\\partial U}$ is the Jacobian matrix of the residual vector $R$ with respect to the state vector $U$, and $\\frac{\\partial R}{\\partial p}$ is the partial derivative of $R$ with respect to $p$.\nRearranging for the state sensitivity gives:\n$$\n\\frac{dU}{dp} = - \\left( \\frac{\\partial R}{\\partial U} \\right)^{-1} \\frac{\\partial R}{\\partial p}\n$$\nDirect computation of $\\frac{dU}{dp}$ requires solving a linear system for each component of the sensitivity vector, which is computationally expensive. The adjoint method circumvents this.\n\n**3. The Adjoint Method**\n\nSubstituting the expression for the sensitivity into the total derivative of $J$:\n$$\n\\frac{dJ}{dp} = \\frac{\\partial J}{\\partial p} - \\left(\\nabla_U J\\right)^T \\left( \\frac{\\partial R}{\\partial U} \\right)^{-1} \\frac{\\partial R}{\\partial p}\n$$\nTo avoid the matrix inverse, we define the discrete adjoint vector $\\lambda$ (a column vector) by grouping the terms that multiply $\\frac{\\partial R}{\\partial p}$:\n$$\n\\lambda^T = \\left(\\nabla_U J\\right)^T \\left( \\frac{\\partial R}{\\partial U} \\right)^{-1}\n$$\nTo solve for $\\lambda$ without computing an inverse, we right-multiply by $\\frac{\\partial R}{\\partial U}$ and take the transpose:\n$$\n\\left( \\frac{\\partial R}{\\partial U} \\right)^T \\lambda = \\nabla_U J\n$$\nThis is the **discrete adjoint equation**, which is a single linear system for the adjoint vector $\\lambda$.\n\nWith $\\lambda$ defined as such, the total derivative of the cost functional simplifies to:\n$$\n\\frac{dJ}{dp} = \\frac{\\partial J}{\\partial p} - \\lambda^T \\frac{\\partial R}{\\partial p}\n$$\nThis is the desired gradient formula. Using the notation $J_p = \\frac{\\partial J}{\\partial p}$ and $R_p = \\frac{\\partial R}{\\partial p}$, this is $\\frac{dJ}{dp} = J_p - \\lambda^T R_p$. Since $p$ is a scalar, $J_p$ is also a scalar, so $J_p^T=J_p$.\n\n**4. Application to the Specific Problem**\n\nWe now compute the necessary partial derivatives for the given problem.\n-   **Residual Jacobian:** From $R(U, p) = A U - s(p)$, the partial derivative with respect to $U$ is simply the matrix $A$.\n    $$\n    \\frac{\\partial R}{\\partial U} = A\n    $$\n-   **Residual Derivative w.r.t. Parameter:** The residual vector is $R(U,p) = AU - p f$. Its partial derivative with respect to $p$ is:\n    $$\n    \\frac{\\partial R}{\\partial p} = -f\n    $$\n    where $f$ is the vector with components $f_i = \\sin(\\pi x_i)$.\n-   **Functional Gradient w.r.t. State:** The functional is $J = \\frac{1}{2}\\,\\Delta x \\sum_{k=1}^{N-2} \\left(U_k - U_k^\\star\\right)^2 + \\beta\\, p$. Its partial derivative with respect to $U_i$ is:\n    $$\n    (\\nabla_U J)_i = \\frac{\\partial J}{\\partial U_i} = \\Delta x \\left(U_i - U_i^\\star\\right)\n    $$\n-   **Functional Derivative w.r.t. Parameter:** The partial derivative of $J$ with respect to $p$ is:\n    $$\n    \\frac{\\partial J}{\\partial p} = \\beta\n    $$\n\n**5. Final Adjoint System and Gradient**\n\nSubstituting these specific terms into the general adjoint framework yields:\n-   **Primal (State) Equation:** $A U = s(p)$, where $s_i(p) = p f_i$.\n-   **Adjoint Equation:**\n    $$\n    A^T \\lambda = \\nabla_U J, \\quad \\text{where } (\\nabla_U J)_i = \\Delta x (U_i - U_i^\\star)\n    $$\n-   **Gradient Formula:**\n    $$\n    \\frac{dJ}{dp} = \\beta - \\lambda^T (-f) = \\beta + \\lambda^T f = \\beta + \\sum_{i=1}^{N-2} \\lambda_i f_i\n    $$\n\n**6. Numerical Procedure**\n\nThe algorithm to compute the discrete-adjoint gradient is:\n1.  For given parameters $(N, a, \\Gamma, p, \\beta)$, construct the $(N-2) \\times (N-2)$ matrix $A$ and the source vector $s(p)$.\n2.  Solve the primal linear system $A U = s(p)$ for the state vector $U$.\n3.  Construct the right-hand side of the adjoint system, $\\nabla_U J$, using the computed state $U$.\n4.  Solve the adjoint linear system $A^T \\lambda = \\nabla_U J$ for the adjoint vector $\\lambda$.\n5.  Compute the gradient using the formula $\\frac{dJ}{dp} = \\beta + \\lambda^T f$.\n\nThis gradient is then compared against a finite-difference approximation for verification:\n$$\n\\left.\\frac{dJ}{dp}\\right|_{\\text{FD}} \\approx \\frac{J(U(p+h),p+h) - J(U(p-h),p-h)}{2h}\n$$\nwhere $h$ is a small perturbation. This requires two additional primal solves to find $U(p+h)$ and $U(p-h)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are permitted\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n    test_cases = [\n        (50, 1.0, 0.1, 0.5, 0.3),   # Case 1\n        (20, 0.0, 0.5, 1.0, 0.0),   # Case 2\n        (200, 5.0, 1e-3, 0.1, 1.0), # Case 3\n        (5, 0.2, 0.05, 0.8, 0.2),   # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        N, a, Gamma, p, beta = case\n        diff = compute_gradient_difference(N, a, Gamma, p, beta)\n        results.append(diff)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_gradient_difference(N, a, Gamma, p, beta, h=1e-7):\n    \"\"\"\n    Computes the absolute difference between the discrete-adjoint gradient and\n    a finite-difference approximation.\n\n    Args:\n        N (int): Number of mesh points.\n        a (float): Dimensionless convection strength.\n        Gamma (float): Dimensionless diffusion coefficient.\n        p (float): Scalar design parameter.\n        beta (float): Scalar weight in the cost functional.\n        h (float): Step size for finite difference.\n\n    Returns:\n        float: The absolute difference between the two gradient calculations.\n    \"\"\"\n    # Grid and problem setup\n    num_interior = N - 2\n    if num_interior = 0:\n        return 0.0\n    \n    dx = 1.0 / (N - 1)\n    x_interior = np.linspace(0, 1, N)[1:-1]\n\n    # Target field and source term structure\n    U_star = np.sin(2 * np.pi * x_interior)\n    f_vec = np.sin(np.pi * x_interior)\n\n    # --- Construct the primal system matrix A ---\n    A = np.zeros((num_interior, num_interior))\n    \n    # Coefficients from discretization\n    c_diff = Gamma / dx**2\n    c_conv = a / dx\n    \n    diag_val = -2.0 * c_diff - c_conv\n    sub_diag_val = c_diff + c_conv\n    sup_diag_val = c_diff\n    \n    np.fill_diagonal(A, diag_val)\n    if num_interior > 1:\n        np.fill_diagonal(A[1:, :], sub_diag_val)\n        np.fill_diagonal(A[:, 1:], sup_diag_val)\n\n    # --- Discrete-Adjoint Gradient Calculation ---\n    \n    # 1. Solve primal system for state U: A U = s(p)\n    s_p = p * f_vec\n    U = np.linalg.solve(A, s_p)\n\n    # 2. Assemble and solve adjoint system for lambda: A^T lambda = dJ/dU\n    grad_J_U = dx * (U - U_star)\n    A_T = A.T\n    lambda_vec = np.linalg.solve(A_T, grad_J_U)\n\n    # 3. Compute adjoint gradient: dJ/dp = beta + lambda^T f\n    grad_adjoint = beta + np.dot(lambda_vec, f_vec)\n    \n    # --- Finite-Difference Gradient Calculation ---\n\n    def compute_J(param_p):\n        \"\"\"Helper to compute cost functional J for a given parameter p.\"\"\"\n        s_vec = param_p * f_vec\n        U_sol = np.linalg.solve(A, s_vec)\n        cost = 0.5 * dx * np.sum((U_sol - U_star)**2) + beta * param_p\n        return cost\n\n    J_plus_h = compute_J(p + h)\n    J_minus_h = compute_J(p - h)\n    \n    grad_fd = (J_plus_h - J_minus_h) / (2.0 * h)\n\n    # Return the absolute difference\n    return abs(grad_adjoint - grad_fd)\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond simple linear systems, real-world CFD applications often involve non-linear and non-differentiable components within the governing equations, such as flux limiters in high-resolution schemes. This exercise  delves into this practical challenge by asking you to derive the discrete adjoint contributions for a MUSCL reconstruction scheme that employs the non-smooth minmod limiter. This practice demonstrates how the discrete adjoint, as a systematic application of the chain rule, navigates these complexities and forces consideration of how to consistently handle the \"kinks\" where the derivative is formally undefined.",
            "id": "3950940",
            "problem": "Consider the one-dimensional steady linear advection equation with constant speed $a0$ for a scalar state $u(x)$, discretized by a uniform finite-volume mesh. At the cell face $i+\\tfrac{1}{2}$, use a Monotonic Upstream-centered Schemes for Conservation Laws (MUSCL) reconstruction with the minmod flux limiter to define the left-biased state $u_{L,i+\\frac{1}{2}}$ as follows: \n- Define the forward and backward differences $\\Delta^{+} u_{i} \\equiv u_{i+1}-u_{i}$ and $\\Delta^{-} u_{i} \\equiv u_{i}-u_{i-1}$, and the ratio $r_{i} \\equiv \\dfrac{\\Delta^{-} u_{i}}{\\Delta^{+} u_{i}}$ (assume $\\Delta^{+} u_{i} \\neq 0$).\n- Let the minmod limiter be $\\phi_{\\mathrm{mm}}(r) \\equiv \\max\\!\\big(0,\\min(1,r)\\big)$.\n- The MUSCL left state is $u_{L,i+\\frac{1}{2}} \\equiv u_{i} + \\tfrac{1}{2}\\,\\phi_{\\mathrm{mm}}(r_{i})\\,\\Delta^{+} u_{i}$.\n- The upwind numerical flux at the face is $F_{i+\\frac{1}{2}} \\equiv a\\,u_{L,i+\\frac{1}{2}}$.\n\nLet the objective be a linear functional of this face flux, $J \\equiv \\alpha\\,F_{i+\\frac{1}{2}}$, where $\\alpha$ is a given scalar weight. In the discrete adjoint sense, the contribution of this face to the local adjoint right-hand side is governed by the gradient $\\nabla_{\\mathbf{u}} J$ with respect to the triplet of conservative cell values $\\mathbf{u} \\equiv (u_{i-1},u_{i},u_{i+1})$ participating in the reconstruction stencil.\n\nTasks:\n1) Starting from the above definitions and the chain rule, and assuming $0r_{i}1$ so that the active branch of the minmod limiter is $\\phi_{\\mathrm{mm}}(r_{i})=r_{i}$, derive the closed-form expression for the discrete adjoint contributions $\\left(\\dfrac{\\partial J}{\\partial u_{i-1}},\\dfrac{\\partial J}{\\partial u_{i}},\\dfrac{\\partial J}{\\partial u_{i+1}}\\right)$ in terms of $a$ and $\\alpha$ only (no dependence on the local state remains in this branch).\n2) Evaluate these contributions numerically for $a=2$, $\\alpha=1$, and the consistent local state $(u_{i-1},u_{i},u_{i+1})=(1,2,5)$, which indeed satisfies $0r_{i}1$.\n3) Briefly discuss, in words, how the non-smooth kinks of $\\phi_{\\mathrm{mm}}(r)$ at $r=0$ and $r=1$ impact the existence and uniqueness of the discrete adjoint, and indicate a consistent choice one may adopt at these kinks to maintain an implementable discrete adjoint.\n\nProvide the final numerical contributions from part 2 as a single row matrix representing $\\left(\\dfrac{\\partial J}{\\partial u_{i-1}},\\dfrac{\\partial J}{\\partial u_{i}},\\dfrac{\\partial J}{\\partial u_{i+1}}\\right)$. No units are required. No rounding is necessary.",
            "solution": "The problem asks for the derivation and evaluation of discrete adjoint contributions for a specific objective function related to a MUSCL-reconstructed flux in a finite-volume scheme. It also requires a discussion on the implications of non-differentiable limiter functions.\n\nFirst, the problem must be validated.\n\n### Step 1: Extract Givens\n- Equation: One-dimensional steady linear advection with constant speed $a0$.\n- Discretization: Uniform finite-volume mesh.\n- State variables: Cell-average values $u_{i-1}$, $u_{i}$, $u_{i+1}$.\n- Definitions:\n  - Forward difference: $\\Delta^{+} u_{i} \\equiv u_{i+1}-u_{i}$\n  - Backward difference: $\\Delta^{-} u_{i} \\equiv u_{i}-u_{i-1}$\n  - Ratio of gradients: $r_{i} \\equiv \\dfrac{\\Delta^{-} u_{i}}{\\Delta^{+} u_{i}}$, assuming $\\Delta^{+} u_{i} \\neq 0$.\n  - Minmod flux limiter function: $\\phi_{\\mathrm{mm}}(r) \\equiv \\max\\!\\big(0,\\min(1,r)\\big)$.\n  - Reconstructed left state: $u_{L,i+\\frac{1}{2}} \\equiv u_{i} + \\tfrac{1}{2}\\,\\phi_{\\mathrm{mm}}(r_{i})\\,\\Delta^{+} u_{i}$.\n  - Upwind numerical flux: $F_{i+\\frac{1}{2}} \\equiv a\\,u_{L,i+\\frac{1}{2}}$.\n- Objective functional: $J \\equiv \\alpha\\,F_{i+\\frac{1}{2}}$, where $\\alpha$ is a scalar weight.\n- Target gradient: $\\nabla_{\\mathbf{u}} J = \\left(\\dfrac{\\partial J}{\\partial u_{i-1}},\\dfrac{\\partial J}{\\partial u_{i}},\\dfrac{\\partial J}{\\partial u_{i+1}}\\right)$, where $\\mathbf{u} \\equiv (u_{i-1},u_{i},u_{i+1})$.\n- Condition for Task 1: Assume $0  r_{i}  1$, which implies $\\phi_{\\mathrm{mm}}(r_{i}) = r_{i}$.\n- Data for Task 2: $a=2$, $\\alpha=1$, and local state $(u_{i-1},u_{i},u_{i+1})=(1,2,5)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, describing a standard MUSCL scheme and the associated discrete adjoint calculation, which are core topics in advanced computational fluid dynamics (CFD) and numerical optimization. The problem is well-posed, providing all necessary definitions. The data provided for Task 2 is consistent with the assumption for Task 1:\nGiven $(u_{i-1},u_{i},u_{i+1})=(1,2,5)$:\n$\\Delta^{+} u_{i} = u_{i+1} - u_{i} = 5 - 2 = 3$.\n$\\Delta^{-} u_{i} = u_{i} - u_{i-1} = 2 - 1 = 1$.\nThe ratio is $r_{i} = \\dfrac{\\Delta^{-} u_{i}}{\\Delta^{+} u_{i}} = \\dfrac{1}{3}$.\nSince $0  \\frac{1}{3}  1$, the provided state correctly falls within the specified active branch of the minmod limiter. The problem is objective, complete, and mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n---\n\n### Task 1: Derivation of the Adjoint Contributions\n\nThe objective function $J$ is defined as a sequence of nested functions of the state variables $\\mathbf{u} = (u_{i-1}, u_{i}, u_{i+1})$.\n$$J = \\alpha F_{i+\\frac{1}{2}} = \\alpha \\left( a u_{L,i+\\frac{1}{2}} \\right)$$\nSubstituting the definition of the reconstructed state $u_{L,i+\\frac{1}{2}}$:\n$$J = \\alpha a \\left( u_{i} + \\frac{1}{2} \\phi_{\\mathrm{mm}}(r_i) \\Delta^{+} u_i \\right)$$\nThe problem specifies that we are in the branch where $0  r_i  1$. In this range, the minmod function simplifies to $\\phi_{\\mathrm{mm}}(r_i) = r_i$. The expression for $J$ becomes:\n$$J = \\alpha a \\left( u_{i} + \\frac{1}{2} r_i \\Delta^{+} u_i \\right)$$\nNow, we substitute the definitions for $r_i$ and $\\Delta^{+} u_i$:\n$$r_i = \\frac{\\Delta^{-} u_i}{\\Delta^{+} u_i} = \\frac{u_i - u_{i-1}}{u_{i+1} - u_i}$$\n$$\\Delta^{+} u_i = u_{i+1} - u_i$$\nThe term $\\frac{1}{2} r_i \\Delta^{+} u_i$ can be greatly simplified:\n$$\\frac{1}{2} r_i \\Delta^{+} u_i = \\frac{1}{2} \\left( \\frac{u_i - u_{i-1}}{u_{i+1} - u_i} \\right) (u_{i+1} - u_i) = \\frac{1}{2} (u_i - u_{i-1})$$\nIt is crucial to note that this simplification holds because the problem states $\\Delta^{+} u_i \\neq 0$.\nSubstituting this simplified term back into the expression for $J$:\n$$J = \\alpha a \\left( u_i + \\frac{1}{2} (u_i - u_{i-1}) \\right)$$\nCombining terms involving $u_i$:\n$$J = \\alpha a \\left( \\frac{3}{2} u_i - \\frac{1}{2} u_{i-1} \\right)$$\nThis is the closed-form expression for the objective function $J$ in the specified branch. As predicted, it only depends on $u_{i-1}$ and $u_i$. Now we compute the partial derivatives with respect to each component of $\\mathbf{u}$:\n\n1.  Derivative with respect to $u_{i-1}$:\n    $$\\frac{\\partial J}{\\partial u_{i-1}} = \\frac{\\partial}{\\partial u_{i-1}} \\left[ \\alpha a \\left( \\frac{3}{2} u_i - \\frac{1}{2} u_{i-1} \\right) \\right] = -\\frac{1}{2} \\alpha a$$\n\n2.  Derivative with respect to $u_{i}$:\n    $$\\frac{\\partial J}{\\partial u_{i}} = \\frac{\\partial}{\\partial u_{i}} \\left[ \\alpha a \\left( \\frac{3}{2} u_i - \\frac{1}{2} u_{i-1} \\right) \\right] = \\frac{3}{2} \\alpha a$$\n\n3.  Derivative with respect to $u_{i+1}$:\n    $$\\frac{\\partial J}{\\partial u_{i+1}} = \\frac{\\partial}{\\partial u_{i+1}} \\left[ \\alpha a \\left( \\frac{3}{2} u_i - \\frac{1}{2} u_{i-1} \\right) \\right] = 0$$\n\nThe resulting vector of adjoint contributions is $\\left(-\\frac{1}{2} \\alpha a, \\frac{3}{2} \\alpha a, 0\\right)$. These expressions depend only on the constants $a$ and $\\alpha$, as required.\n\n### Task 2: Numerical Evaluation\n\nWe evaluate the expressions derived in Task 1 using the provided numerical values: $a=2$ and $\\alpha=1$. The state values $(u_{i-1},u_{i},u_{i+1})=(1,2,5)$ were used to confirm that we are in the correct branch of the limiter, but they do not appear in the final expressions for the derivatives in this particular branch.\n\n- $\\dfrac{\\partial J}{\\partial u_{i-1}} = -\\dfrac{1}{2} \\alpha a = -\\dfrac{1}{2} (1)(2) = -1$\n- $\\dfrac{\\partial J}{\\partial u_{i}} = \\dfrac{3}{2} \\alpha a = \\dfrac{3}{2} (1)(2) = 3$\n- $\\dfrac{\\partial J}{\\partial u_{i+1}} = 0$\n\nThe numerical contributions are therefore $(-1, 3, 0)$.\n\n### Task 3: Discussion on Non-Smooth Kinks\n\nThe minmod limiter function $\\phi_{\\mathrm{mm}}(r) = \\max(0, \\min(1, r))$ is continuous but not continuously differentiable. It has non-differentiable points, or \"kinks,\" at $r=0$ and $r=1$. The derivative, $\\phi'_{\\mathrm{mm}}(r)$, is piecewise constant:\n$$ \\phi'_{\\mathrm{mm}}(r) = \\begin{cases} 0  \\text{if } r  0 \\\\ 1  \\text{if } 0  r  1 \\\\ 0  \\text{if } r  1 \\end{cases} $$\nAt $r=0$ and $r=1$, the derivative is formally undefined.\n\nThe objective function $J$ depends on the state variables $\\mathbf{u}$ through $\\phi_{\\mathrm{mm}}(r_i(\\mathbf{u}))$. By the chain rule, a non-differentiability in $\\phi_{\\mathrm{mm}}$ at a specific value of $r$ translates to a non-differentiability in $J$ with respect to $\\mathbf{u}$ for any state $\\mathbf{u}$ that produces that value of $r_i$. The discrete adjoint is the gradient $\\nabla_{\\mathbf{u}} J$. If this gradient is not defined, the discrete adjoint does not exist in the classical sense, or at least is not unique.\n\nThis non-uniqueness poses a problem for gradient-based algorithms which require a single well-defined gradient vector at every point. To resolve this, one turns to the concept of subgradients from convex analysis. At a non-differentiable point, the subgradient is a set of values that characterize the local behavior of the function. For $\\phi_{\\mathrm{mm}}$, the subgradient at $r=0$ is the interval $[0,1]$, and at $r=1$ it is also the interval $[0,1]$ (as it is the convex hull of the left and right derivatives).\n\nFor a practical and implementable discrete adjoint method, a single value must be chosen from the subgradient set at each kink. This choice, while arbitrary, must be made consistently. Common choices include:\n1.  Using one of the one-sided derivatives (e.g., setting $\\phi'_{\\mathrm{mm}}(0)=0$ from the left, or $\\phi'_{\\mathrm{mm}}(0)=1$ from the right).\n2.  Using the average of the one-sided derivatives (e.g., $\\phi'_{\\mathrm{mm}}(0) = \\frac{0+1}{2} = \\frac{1}{2}$).\n\nA typical and easily implementable choice is to define the derivative to be equal to one of its one-sided limits, for example by defining $\\phi'_{\\mathrm{mm}}(r) = 1$ for $r \\in [0, 1)$ and $\\phi'_{\\mathrm{mm}}(r) = 0$ otherwise. This ensures a unique value for the generalized derivative is always available, allowing the chain rule to be applied everywhere and yielding a uniquely defined (though technically a subgradient-based) adjoint vector across the entire state space.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-1  3  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Non-differentiability is not only found in the state equations but also frequently appears in the objective functions of engineering design problems, such as those involving $\\max$ operators or absolute values. Such non-smoothness violates the assumptions of classical differentiability, requiring a more nuanced approach using concepts like subgradients or regularization. This exercise  will test your theoretical understanding of these issues, asking you to analyze the mathematical consequences of non-smooth objectives and the properties of their smooth approximations, which restore differentiability at the cost of a small, controllable bias.",
            "id": "3950965",
            "problem": "Consider a steady state Computational Fluid Dynamics (CFD) simulation in which the flow variables are collected in a state vector $\\mathbf{w}$ that satisfies a governing Partial Differential Equation (PDE) residual $\\mathbf{R}(\\mathbf{w}, \\mathbf{p}) = \\mathbf{0}$ for design variables $\\mathbf{p}$. A scalar objective functional is given by\n$$\nJ(\\mathbf{w}) = \\int_{\\Omega} \\Phi\\!\\left(q(\\mathbf{w}(\\mathbf{x}))\\right) \\,\\mathrm{d}\\mathbf{x},\n$$\nwhere $\\Omega$ is the spatial domain, $q(\\mathbf{w})$ is a smooth scalar field of the flow variables, and $\\Phi$ contains nonsmooth operators such as the absolute value $|\\,\\cdot\\,|$ or the maximum $\\max(0, \\cdot)$. In adjoint-based sensitivity analysis, one seeks $\\mathrm{d}J/\\mathrm{d}\\mathbf{p}$ either by the continuous adjoint (derived from the Gateaux/Fréchet derivative of the Lagrangian built from $\\mathbf{R}$ and $J$) or by the discrete adjoint (obtained by differentiating the discretized residual and objective, often via Automatic Differentiation (AD)). \n\nTo enable differentiability, consider the regularizations\n$$\n\\phi_{\\epsilon}(x) = \\sqrt{\\epsilon^{2} + x^{2}}, \\quad \\psi_{\\epsilon}(x) = \\frac{1}{2}\\left(x + \\sqrt{\\epsilon^{2} + x^{2}}\\right),\n$$\nwhich approximate $\\Phi(x) = |x|$ and $\\Phi(x) = \\max(0,x)$, respectively, with a smoothing parameter $\\epsilon  0$. Let $J_{\\epsilon}(\\mathbf{w})$ denote the objective in which $\\Phi$ is replaced by its corresponding regularization. \n\nWhich of the following statements are correct in the context of continuous and discrete adjoint formulations for $\\mathbf{R}(\\mathbf{w}, \\mathbf{p}) = \\mathbf{0}$ with the above objectives?\n\nA. The mapping $x \\mapsto |x|$ is not Fréchet differentiable at $x = 0$. When $\\Phi(x) = |x|$ or $\\Phi(x) = \\max(0,x)$ is used in $J(\\mathbf{w})$, the functional derivative with respect to $q(\\mathbf{w})$ is set-valued on the locus $\\{\\mathbf{x} : q(\\mathbf{w}(\\mathbf{x})) = 0\\}$, and a unique continuous adjoint cannot be defined there without additional regularization or selection of a subgradient.\n\nB. For $\\phi_{\\epsilon}(x) = \\sqrt{\\epsilon^{2} + x^{2}}$, one has $\\mathrm{d}\\phi_{\\epsilon}/\\mathrm{d}x = x/\\sqrt{\\epsilon^{2} + x^{2}}$. As $\\epsilon \\to 0$, this derivative converges pointwise to $\\operatorname{sign}(x)$ for $x \\neq 0$, and for $x \\neq 0$ the gradient bias obeys\n$$\n\\left|\\frac{x}{\\sqrt{\\epsilon^{2} + x^{2}}} - \\operatorname{sign}(x)\\right| \\le \\frac{\\epsilon^{2}}{|x|^{2}}.\n$$\n\nC. For $\\psi_{\\epsilon}(x) = \\frac{1}{2}\\left(x + \\sqrt{\\epsilon^{2} + x^{2}}\\right)$ approximating $\\max(0,x)$, the function bias obeys $0 \\le \\psi_{\\epsilon}(x) - \\max(0,x) \\le \\epsilon/2$ for all $x \\in \\mathbb{R}$. Moreover, the adjoint-computed gradient $\\nabla_{\\mathbf{w}} J_{\\epsilon}$ converges almost everywhere, as $\\epsilon \\to 0$, to a subgradient of $J$ with $\\Phi(x) = \\max(0,x)$.\n\nD. In a finite-volume CFD solver with flux limiters, nondifferentiability of limiter functions makes the adjoint always undefined. Smoothing the objective $J$ alone cannot recover a valid gradient; the continuous adjoint requires both the residual and the objective to be twice continuously differentiable in all arguments.\n\nE. The bias introduced by $\\phi_{\\epsilon}$ in approximating $|x|$ is unbounded as $\\epsilon \\to 0$, and $\\mathrm{d}\\phi_{\\epsilon}/\\mathrm{d}x = \\operatorname{sign}(x)$ for every $\\epsilon  0$, so the regularization does not alter adjoint gradients.\n\nF. In the discrete adjoint, applying reverse-mode AD to code containing $\\max$ or $|\\,\\cdot\\,|$ always yields a derivative equal to a valid subgradient for all inputs, so optimization convergence guarantees are unaffected even without any smoothing.\n\nSelect all correct options and justify your choices from first principles of adjoint-based sensitivity analysis and differentiability of the objective.",
            "solution": "The user has requested a critical validation of the problem statement, followed by a derivation of the solution and evaluation of the given options.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n\n- **Governing Equation:** A steady-state CFD problem is governed by $\\mathbf{R}(\\mathbf{w}, \\mathbf{p}) = \\mathbf{0}$, where $\\mathbf{w}$ is the state vector and $\\mathbf{p}$ are the design variables.\n- **Objective Functional:** A scalar objective is defined as $J(\\mathbf{w}) = \\int_{\\Omega} \\Phi\\!\\left(q(\\mathbf{w}(\\mathbf{x}))\\right) \\,\\mathrm{d}\\mathbf{x}$.\n- **Components:** $\\Omega$ is the spatial domain, $q(\\mathbf{w})$ is a smooth scalar field, and $\\Phi$ is a function containing nonsmooth operators like absolute value $|\\,\\cdot\\,|$ or maximum $\\max(0, \\cdot)$.\n- **Adjoint Methods:** The sensitivity $\\mathrm{d}J/\\mathrm{d}\\mathbf{p}$ is sought via continuous or discrete adjoint methods.\n- **Regularization:** To handle non-differentiability, the following smooth approximations are introduced with a parameter $\\epsilon  0$:\n    - For $\\Phi(x) = |x|$, the regularization is $\\phi_{\\epsilon}(x) = \\sqrt{\\epsilon^{2} + x^{2}}$.\n    - For $\\Phi(x) = \\max(0,x)$, the regularization is $\\psi_{\\epsilon}(x) = \\frac{1}{2}\\left(x + \\sqrt{\\epsilon^{2} + x^{2}}\\right)$.\n- **Regularized Objective:** $J_{\\epsilon}(\\mathbf{w})$ is the objective functional where $\\Phi$ is replaced by its respective regularization $\\phi_{\\epsilon}$ or $\\psi_{\\epsilon}$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientific Grounding:** The problem is firmly grounded in the field of computational fluid dynamics, specifically in the area of PDE-constrained optimization and adjoint-based sensitivity analysis. The challenges posed by nonsmooth objective functionals are a well-documented and critical topic in modern optimization. The concepts of Fréchet differentiability, subgradients, continuous and discrete adjoints, and regularization techniques are standard in applied mathematics and computational science. The problem setup is scientifically and mathematically sound.\n- **Well-Posedness:** The problem asks for the evaluation of several statements based on the provided theoretical framework. This is a well-posed task, as each statement can be rigorously analyzed and judged as correct or incorrect based on principles of functional analysis and optimization theory.\n- **Objectivity:** The problem is stated using precise, standard mathematical and engineering terminology. There is no ambiguity or subjectivity.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is scientifically sound, well-posed, objective, and self-contained. It is **VALID**. The solution process will now proceed with an analysis of each option.\n\n**Option-by-Option Analysis**\n\n**Analysis of A**\n\nThe statement posits that $x \\mapsto |x|$ is not Fréchet differentiable at $x=0$, leading to a set-valued functional derivative for $J(\\mathbf{w})$ on the set where $q(\\mathbf{w}(\\mathbf{x}))=0$, thus preventing the definition of a unique continuous adjoint without further measures.\n\nA function $f: X \\to Y$ between two normed vector spaces is Fréchet differentiable at $x_0 \\in X$ if there exists a continuous linear operator $A: X \\to Y$ such that $\\lim_{\\|h\\|\\to 0} \\frac{\\|f(x_0+h) - f(x_0) - Ah\\|_Y}{\\|h\\|_X} = 0$. For $f(x)=|x|$ on $\\mathbb{R}$, this simplifies to finding a number $f'(0)$ such that $\\lim_{h\\to 0} \\frac{||h| - f'(0)h|}{|h|} = 0$.\nFor $h0$, we need $\\lim_{h\\to 0^+} \\frac{|h - f'(0)h|}{h} = |1-f'(0)|=0$, implying $f'(0)=1$.\nFor $h0$, we need $\\lim_{h\\to 0^-} \\frac{|-h - f'(0)h|}{-h} = |1+f'(0)|=0$, implying $f'(0)=-1$.\nThese conditions are contradictory, so no such derivative exists. The function is not Fréchet differentiable at $x=0$. The same holds for $\\max(0,x)$.\n\nThe continuous adjoint equation for an adjoint state $\\boldsymbol{\\lambda}$ is formally derived from the Lagrangian $\\mathcal{L}(\\mathbf{w}, \\boldsymbol{\\lambda}, \\mathbf{p}) = J(\\mathbf{w}) + \\int_\\Omega \\boldsymbol{\\lambda}^T \\mathbf{R} \\,\\mathrm{d}\\mathbf{x}$. The optimality condition $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} \\cdot \\delta \\mathbf{w} = 0$ for all admissible variations $\\delta \\mathbf{w}$ yields the adjoint equation. This involves the derivative of $J$ with respect to $\\mathbf{w}$. The Gateaux derivative of $J$ in direction $\\delta q$ is $\\int_\\Omega \\Phi'(q(\\mathbf{x})) \\delta q(\\mathbf{x}) \\,\\mathrm{d}\\mathbf{x}$. At any point $\\mathbf{x}$ where $q(\\mathbf{w}(\\mathbf{x})) = 0$, the derivative $\\Phi'(0)$ is undefined for $\\Phi(x)=|x|$ or $\\Phi(x)=\\max(0,x)$. The derivative is replaced by the subdifferential, which is a set of values (a subgradient). For $|x|$ at $x=0$, this is the interval $[-1, 1]$. For $\\max(0,x)$ at $x=0$, it is $[0, 1]$. Consequently, the source term for the continuous adjoint equation, which depends on this derivative, is not uniquely defined on the locus of points where $q=0$. To proceed, one must either regularize (smooth) the functional, as proposed in the problem, or make a specific choice of a subgradient from the set. The statement is entirely correct.\n\n**Verdict for A:** Correct.\n\n**Analysis of B**\n\nThe statement analyzes the derivative and gradient bias of the regularization $\\phi_{\\epsilon}(x) = \\sqrt{\\epsilon^{2} + x^{2}}$.\n\nThe derivative is $\\frac{\\mathrm{d}\\phi_{\\epsilon}}{\\mathrm{d}x} = \\frac{1}{2\\sqrt{\\epsilon^2+x^2}} (2x) = \\frac{x}{\\sqrt{\\epsilon^2+x^2}}$. This is correct.\n\nAs $\\epsilon \\to 0$, for $x \\neq 0$, the derivative $\\frac{x}{\\sqrt{\\epsilon^2+x^2}} \\to \\frac{x}{\\sqrt{x^2}} = \\frac{x}{|x|} = \\operatorname{sign}(x)$. This is correct.\n\nNow, we verify the bias bound for $x \\neq 0$: $\\left|\\frac{x}{\\sqrt{\\epsilon^{2} + x^{2}}} - \\operatorname{sign}(x)\\right| \\le \\frac{\\epsilon^{2}}{|x|^{2}}$.\nLet's consider $x  0$, where $\\operatorname{sign}(x) = 1$. The expression is $1 - \\frac{x}{\\sqrt{\\epsilon^{2} + x^{2}}}$.\n$$\n1 - \\frac{x}{\\sqrt{\\epsilon^{2} + x^{2}}} = \\frac{\\sqrt{\\epsilon^{2} + x^{2}} - x}{\\sqrt{\\epsilon^{2} + x^{2}}} = \\frac{(\\sqrt{\\epsilon^{2} + x^{2}} - x)(\\sqrt{\\epsilon^{2} + x^{2}} + x)}{\\sqrt{\\epsilon^{2} + x^{2}}(\\sqrt{\\epsilon^{2} + x^{2}} + x)} = \\frac{\\epsilon^2 + x^2 - x^2}{\\sqrt{\\epsilon^{2} + x^{2}}(\\sqrt{\\epsilon^{2} + x^{2}} + x)} = \\frac{\\epsilon^2}{\\epsilon^2+x^2 + x\\sqrt{\\epsilon^2+x^2}}\n$$\nWe want to show that $\\frac{\\epsilon^2}{\\epsilon^2+x^2 + x\\sqrt{\\epsilon^2+x^2}} \\le \\frac{\\epsilon^2}{x^2}$. Since $\\epsilon^2  0$, this is equivalent to $x^2 \\le \\epsilon^2+x^2 + x\\sqrt{\\epsilon^2+x^2}$, which simplifies to $0 \\le \\epsilon^2 + x\\sqrt{\\epsilon^2+x^2}$. This inequality is true for all $x0$. A similar argument holds for $x0$, where we analyze $|\\frac{x}{\\sqrt{\\epsilon^2+x^2}} - (-1)|$. The absolute value of the bias is $\\frac{\\epsilon^2}{\\epsilon^2+x^2 + |x|\\sqrt{\\epsilon^2+x^2}}$. The inequality becomes $|x|^2 \\le \\epsilon^2+x^2 + |x|\\sqrt{\\epsilon^2+x^2}$, which is $0 \\le \\epsilon^2 + |x|\\sqrt{\\epsilon^2+x^2}$. This is true for all $x \\neq 0$. The bound is correct.\n\n**Verdict for B:** Correct.\n\n**Analysis of C**\n\nThis statement analyzes the function bias and gradient convergence for $\\psi_{\\epsilon}(x) = \\frac{1}{2}\\left(x + \\sqrt{\\epsilon^{2} + x^{2}}\\right)$.\n\nFirst, we check the function bias: $0 \\le \\psi_{\\epsilon}(x) - \\max(0,x) \\le \\epsilon/2$.\n- Case $x \\ge 0$: We need to verify $0 \\le \\frac{1}{2}(x+\\sqrt{\\epsilon^2+x^2}) - x \\le \\epsilon/2$, which is $0 \\le \\frac{1}{2}(\\sqrt{\\epsilon^2+x^2} - x) \\le \\epsilon/2$. This is equivalent to $x \\le \\sqrt{\\epsilon^2+x^2} \\le x+\\epsilon$. Squaring these positive quantities gives $x^2 \\le \\epsilon^2+x^2$ (true) and $\\epsilon^2+x^2 \\le x^2+2x\\epsilon+\\epsilon^2$ (true for $x\\ge0, \\epsilon0$).\n- Case $x  0$: We need to verify $0 \\le \\frac{1}{2}(x+\\sqrt{\\epsilon^2+x^2}) - 0 \\le \\epsilon/2$. Let $x=-y$ for $y0$. This is $0 \\le \\frac{1}{2}(-y+\\sqrt{\\epsilon^2+y^2}) \\le \\epsilon/2$, which is equivalent to $y \\le \\sqrt{\\epsilon^2+y^2} \\le y+\\epsilon$. This is the same set of inequalities as for $x\\ge0$ (with $y$ instead of $x$), so it is also true.\nThe bias bound is correct.\n\nSecond, we analyze the convergence of the gradient. The source term for the adjoint equation depends on the derivative of the objective, which in turn depends on $\\psi_{\\epsilon}'(q)$.\n$\\psi_{\\epsilon}'(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{1}{2}\\left(x + \\sqrt{\\epsilon^{2} + x^{2}}\\right) = \\frac{1}{2}\\left(1 + \\frac{x}{\\sqrt{\\epsilon^2+x^2}}\\right)$.\nAs $\\epsilon \\to 0$:\n- If $x  0$, $\\psi_{\\epsilon}'(x) \\to \\frac{1}{2}(1+1) = 1$.\n- If $x  0$, $\\psi_{\\epsilon}'(x) \\to \\frac{1}{2}(1-1) = 0$.\n- If $x = 0$, $\\psi_{\\epsilon}'(0) = \\frac{1}{2}(1+0) = 1/2$.\nThe subdifferential of $\\max(0,x)$ is $\\{1\\}$ for $x0$, $\\{0\\}$ for $x0$, and the interval $[0,1]$ for $x=0$. The limit of $\\psi_{\\epsilon}'(x)$ as $\\epsilon \\to 0$ corresponds to a specific selection from this subdifferential at every point $x$. The set of points where $q(\\mathbf{w}(\\mathbf{x})) = 0$ is typically a lower-dimensional manifold (e.g., a surface in a 3D domain) and thus has measure zero. Therefore, the gradient of the regularized functional, $\\nabla_{\\mathbf{w}} J_{\\epsilon}$, converges almost everywhere to a valid subgradient of the original functional $J$. This means the resulting adjoint sensitivity converges to a valid subgradient-based sensitivity. The statement is correct.\n\n**Verdict for C:** Correct.\n\n**Analysis of D**\n\nThe statement claims that nondifferentiable flux limiters make the adjoint \"always undefined\" and that smoothing the objective is insufficient, requiring the continuous adjoint to have $C^2$ regularity.\n\nNondifferentiability of flux limiters is a property of the *discretized* residual operator. It poses a problem for the *discrete* adjoint, which requires differentiating the computer code for the residual. It does not affect the *continuous* adjoint, which is derived from the continuous PDE *before* discretization. The statement conflates these two concepts.\n\nThe claim that smoothing $J$ is insufficient if $\\mathbf{R}$ is nonsmooth is correct; the adjoint equation requires differentiability of $\\mathbf{R}$ with respect to $\\mathbf{w}$.\n\nHowever, the final claim that the \"continuous adjoint requires both the residual and the objective to be twice continuously differentiable ($C^2$) in all arguments\" is false. The derivation of the first-order adjoint equations and the corresponding sensitivity formula requires the operators to be Fréchet differentiable, which corresponds to $C^1$ (once continuously differentiable) regularity. $C^2$ regularity is only necessary for second-order methods (computing Hessians). Since this part of the statement is incorrect, the entire statement is flawed.\n\n**Verdict for D:** Incorrect.\n\n**Analysis of E**\n\nThe statement makes two claims about the regularization $\\phi_{\\epsilon}(x) = \\sqrt{\\epsilon^2+x^2}$.\n\nFirst, \"The bias introduced by $\\phi_{\\epsilon}$ in approximating $|x|$ is unbounded as $\\epsilon \\to 0$.\"\nThe bias is $\\phi_{\\epsilon}(x) - |x| = \\sqrt{\\epsilon^2+x^2} - |x|$. For any fixed $x$, this bias approaches $0$ as $\\epsilon \\to 0$. The maximum bias, which occurs at $x=0$, is $\\epsilon$. This also tends to $0$. The claim that the bias is \"unbounded\" is false.\n\nSecond, \"$\\mathrm{d}\\phi_{\\epsilon}/\\mathrm{d}x = \\operatorname{sign}(x)$ for every $\\epsilon  0$.\"\nAs shown in the analysis of B, $\\mathrm{d}\\phi_{\\epsilon}/\\mathrm{d}x = \\frac{x}{\\sqrt{\\epsilon^2+x^2}}$. This expression is only equal to $\\operatorname{sign}(x)$ in the limit $\\epsilon \\to 0$ (for $x \\neq 0$). For any $\\epsilon  0$, it is a smooth function, not the discontinuous $\\operatorname{sign}(x)$ function. This claim is false.\n\nThe conclusion, \"so the regularization does not alter adjoint gradients,\" is based on these false premises and is itself false. The very purpose of regularization is to alter the function and its gradient into a smooth approximation.\n\n**Verdict for E:** Incorrect.\n\n**Analysis of F**\n\nThe statement addresses the use of Automatic Differentiation (AD) on nonsmooth code and its implications for optimization.\n\nThe first part, \"applying reverse-mode AD to code containing $\\max$ or $|\\,\\cdot\\,|$ always yields a derivative equal to a valid subgradient for all inputs,\" is generally true for well-designed AD tools. These tools implement rules to handle branch points; for instance, at $x=0$, the AD-computed derivative of $|x|$ might be $0$, which is a valid element of the subdifferential $[-1,1]$. So, an AD tool provides *a* selection from the subdifferential.\n\nThe second part, \"so optimization convergence guarantees are unaffected even without any smoothing,\" is decidedly false. Standard optimization algorithms used in CFD (e.g., quasi-Newton methods like L-BFGS, or steepest descent) are designed for smooth functions. Their convergence proofs and performance guarantees rely on properties like the existence of a unique gradient and the validity of Taylor expansions. When these algorithms are fed subgradients instead of true gradients, they can fail. The subgradient does not guarantee a descent direction, and the optimizer may stall or oscillate near the nondifferentiable points. Convergence for nonsmooth optimization requires specialized algorithms (e.g., subgradient methods, bundle methods), which have different, and typically weaker, convergence guarantees (e.g., slower rates, convergence of a subsequence) than their smooth counterparts. Claiming convergence guarantees are \"unaffected\" is a significant error.\n\n**Verdict for F:** Incorrect.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}