{
    "hands_on_practices": [
        {
            "introduction": "This exercise builds the concept of Physical Unclonable Function (PUF) reliability from the ground up. By deriving the distribution of bit-flip errors from first principles, you will develop a foundational understanding of the binomial error model, which is essential for quantifying the stability of any PUF response. ",
            "id": "4235123",
            "problem": "A Physical Unclonable Function (PUF) is deployed for device identity within a Digital Twin (DT) of a Cyber-Physical System (CPS). Upon enrollment, the device’s PUF response is recorded as a reference string of length $n$ bits. On subsequent readouts, environmental noise causes each bit to independently flip relative to the enrolled bit with probability $p$, where $0 \\leq p \\leq 1$. Let the error vector be $E \\in \\{0,1\\}^{n}$, where $E_{i} = 1$ indicates a flip in bit $i$ and $E_{i} = 0$ indicates no flip. The Hamming weight of the error vector is defined as $H = \\sum_{i=1}^{n} E_{i}$, which counts the number of flipped bits.\n\nStarting only from the following foundational bases:\n- the definition of independent Bernoulli random variables,\n- the multiplication rule for independent events,\n- and combinatorial counting of outcomes,\n\nderive the probability mass function of $H$ by explicitly computing the distribution of the Hamming weight of errors. Then, define the reliability of the $n$-bit response, denoted $\\mathcal{R}(n,p)$, as the probability that a subsequent readout exactly matches the enrolled reference (that is, $H = 0$). Compute $\\mathcal{R}(n,p)$ as a closed-form analytic expression in $n$ and $p$.\n\nYour final answer must be a single closed-form expression. No numerical rounding is required, and no physical units apply to this probability.",
            "solution": "The problem statement is scientifically grounded, self-contained, and well-posed. It presents a standard model of bit-flip errors in a digital system, which can be analyzed using fundamental principles of probability theory. All variables and conditions are clearly defined, leading to a unique and meaningful solution. The problem is therefore deemed valid.\n\nWe are tasked with two objectives: first, to derive the probability mass function (PMF) of the Hamming weight of errors, $H$, and second, to compute the reliability, $\\mathcal{R}(n,p)$, defined as the probability of zero errors. The derivation must be constructed from first principles as specified.\n\nLet us model the state of each bit in the PUF response. For each bit $i \\in \\{1, 2, \\dots, n\\}$, there is an associated error variable $E_i$. The problem states that each bit flips independently with probability $p$. We can therefore define $E_i$ as a random variable such that $E_i=1$ if bit $i$ flips, and $E_i=0$ if bit $i$ does not flip.\n\nBased on the problem description, each $E_i$ is an independent Bernoulli random variable. The probability mass function for each $E_i$ is:\n$$ P(E_i = 1) = p $$\n$$ P(E_i = 0) = 1 - p $$\n\nThe Hamming weight of the error vector, $H$, is defined as the total number of flipped bits:\n$$ H = \\sum_{i=1}^{n} E_i $$\nWe seek to find the PMF of $H$, which is the probability $P(H=k)$ for any integer $k$ such that $0 \\le k \\le n$. The event $H=k$ corresponds to observing exactly $k$ bit flips and $n-k$ non-flips among the $n$ bits.\n\nLet us consider a specific sequence of errors that results in a Hamming weight of $k$. For instance, consider the sequence where the first $k$ bits flip and the remaining $n-k$ bits do not. The error vector would be $(\\underbrace{1, 1, \\dots, 1}_{k \\text{ times}}, \\underbrace{0, 0, \\dots, 0}_{n-k \\text{ times}})$. Since the bit flips are independent events, we can use the multiplication rule for independent events to find the probability of this specific sequence occurring:\n$$ P(E_1=1, \\dots, E_k=1, E_{k+1}=0, \\dots, E_n=0) = \\left( \\prod_{i=1}^{k} P(E_i=1) \\right) \\left( \\prod_{j=k+1}^{n} P(E_j=0) \\right) $$\nSubstituting the probabilities for the Bernoulli trials, we get:\n$$ p^k (1-p)^{n-k} $$\nThe probability of any other specific sequence of $k$ flips and $n-k$ non-flips is identical, as the multiplication is commutative.\n\nNext, we must use combinatorial counting to determine the total number of distinct sequences that result in a Hamming weight of $k$. This is equivalent to counting the number of ways to choose $k$ positions for the flips to occur out of a total of $n$ available bit positions. This quantity is given by the binomial coefficient, denoted $\\binom{n}{k}$:\n$$ \\binom{n}{k} = \\frac{n!}{k!(n-k)!} $$\n\nThe total probability of observing exactly $k$ flips, $P(H=k)$, is the sum of the probabilities of all such distinct sequences. Since each sequence has the same probability $p^k(1-p)^{n-k}$, we can multiply this probability by the number of such sequences:\n$$ P(H=k) = \\binom{n}{k} p^k (1-p)^{n-k} $$\nThis is the probability mass function for a binomial distribution, describing the random variable $H \\sim \\text{Binomial}(n,p)$. This completes the first part of the derivation.\n\nThe second part of the task is to compute the reliability, $\\mathcal{R}(n,p)$, which is defined as the probability that a readout exactly matches the enrolled reference. This corresponds to the case of zero bit flips, i.e., $H=0$. We can compute this by setting $k=0$ in the PMF derived above:\n$$ \\mathcal{R}(n,p) = P(H=0) $$\n$$ \\mathcal{R}(n,p) = \\binom{n}{0} p^0 (1-p)^{n-0} $$\nWe now evaluate each term in this expression.\nThe binomial coefficient for $k=0$ is:\n$$ \\binom{n}{0} = \\frac{n!}{0!(n-0)!} = \\frac{n!}{1 \\cdot n!} = 1 $$\nwhere we use the definition $0!=1$.\nThe term $p^0$ is:\n$$ p^0 = 1 $$\n(This holds for any $p \\in [0,1]$, including the edge cases).\nThe final term is:\n$$ (1-p)^{n-0} = (1-p)^n $$\nCombining these results, we obtain the closed-form analytic expression for the reliability:\n$$ \\mathcal{R}(n,p) = 1 \\cdot 1 \\cdot (1-p)^n = (1-p)^n $$\nThis expression gives the probability that an $n$-bit response is read out without any errors, given an independent bit-flip probability of $p$.",
            "answer": "$$\\boxed{(1-p)^n}$$"
        },
        {
            "introduction": "Building on the abstract error probability, this problem delves into the physical origins of PUF instability. You will model how environmental factors like temperature and voltage influence a PUF's behavior, deriving the bit-flip probability as a function of these variables. This practice is key to creating digital twins that can predict and simulate PUF performance under real-world conditions. ",
            "id": "4235130",
            "problem": "A Physical Unclonable Function (PUF) for device identity in a cyber-physical system is mirrored in its digital twin to assess environmental robustness. Each response bit in the twin is abstracted as passing through a Binary Symmetric Channel (BSC) with crossover probability $p(T,V)$ that depends on temperature $T$ and supply voltage $V$. The bit is generated by comparing two path delays; at a nominal enrollment environment $(T_0,V_0)$ the signed delay difference is $\\Delta_0$, and the enrolled bit is $1$ if $\\Delta_0>0$ and $0$ if $\\Delta_0<0$. Assume $\\Delta_0>0$.\n\nUnder operation at $(T,V)$, the deterministic drift of the delay difference is modeled linearly as $\\Delta_{\\mathrm{s}}(T,V)=\\Delta_0+k_T\\,(T-T_0)+k_V\\,(V-V_0)$, where $k_T$ and $k_V$ are constant sensitivities. Let the residual additive noise $N$ (aggregating fast thermal and supply jitter) be independent and identically distributed with a zero-mean logistic distribution of scale $s>0$ and probability density function\n$$\nf_N(n)=\\frac{1}{s}\\,\\frac{\\exp\\!\\left(-\\frac{n}{s}\\right)}{\\left(1+\\exp\\!\\left(-\\frac{n}{s}\\right)\\right)^{2}}.\n$$\nIn the BSC abstraction, the enrolled bit flips at $(T,V)$ if $\\Delta_{\\mathrm{s}}(T,V)+N<0$. Starting only from the given definitions and distribution, derive a closed-form analytic expression for the crossover probability $p(T,V)$ under this logistic sensitivity model. Your final answer must be a single analytic expression for $p(T,V)$ with no units. Do not provide intermediate formulas in the final answer box.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extracted Givens**\n- **System**: A Physical Unclonable Function (PUF) whose response bit is modeled as passing through a Binary Symmetric Channel (BSC) with crossover probability $p(T,V)$.\n- **Dependencies**: The probability $p(T,V)$ depends on temperature $T$ and supply voltage $V$.\n- **Enrollment**: At nominal conditions $(T_0, V_0)$, the signed delay difference is $\\Delta_0$. The enrolled bit is $1$ if $\\Delta_0 > 0$ and $0$ if $\\Delta_0 < 0$.\n- **Problem Condition**: We are given $\\Delta_0 > 0$.\n- **Operational Model**: The deterministic part of the delay difference at $(T,V)$ is $\\Delta_{\\mathrm{s}}(T,V) = \\Delta_0 + k_T(T - T_0) + k_V(V - V_0)$, with $k_T$ and $k_V$ being constant sensitivities.\n- **Noise**: A residual additive noise $N$ is present. $N$ is a random variable that is independent and identically distributed.\n- **Noise Distribution**: $N$ follows a zero-mean logistic distribution with scale $s > 0$.\n- **Noise PDF**: The probability density function of $N$ is $f_N(n) = \\frac{1}{s}\\,\\frac{\\exp(-n/s)}{(1+\\exp(-n/s))^{2}}$.\n- **Bit Flip Condition**: The enrolled bit flips at $(T,V)$ if the total observed delay difference, $\\Delta_{\\mathrm{s}}(T,V) + N$, is less than $0$.\n- **Objective**: Derive a closed-form analytic expression for the crossover probability $p(T,V)$.\n\n**Step 2: Validation**\nThe problem is examined against the specified criteria.\n- **Scientific Grounding**: The problem uses a standard engineering model for analyzing the reliability of PUFs. The use of a linear drift model, additive noise, and a specific probability distribution (logistic) are all standard and valid techniques in signal processing and hardware security analysis. The problem is scientifically sound.\n- **Well-Posedness**: The problem is clearly stated. It asks for the derivation of a probability based on a fully specified model. All necessary components—the deterministic signal model, the noise distribution, and the event condition—are provided. A unique, meaningful solution can be derived.\n- **Objectivity**: The problem is stated in precise, formal language, free of ambiguity or subjective claims.\n\nThe problem is found to be free of any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It is a valid, well-posed problem.\n\n**Step 3: Solution Derivation**\nThe crossover probability, $p(T,V)$, is the probability that the PUF response bit flips under the operational environment $(T,V)$.\n\nAccording to the problem statement, the enrolled bit is determined at $(T_0, V_0)$ by the sign of $\\Delta_0$. We are given that $\\Delta_0 > 0$, which means the enrolled bit is $1$.\n\nA bit flip, or crossover, occurs if the observed bit at $(T,V)$ is $0$. The observed bit is $0$ if the total delay difference, which is the sum of the deterministic drift $\\Delta_{\\mathrm{s}}(T,V)$ and the random noise $N$, is negative.\n\nTherefore, the crossover probability $p(T,V)$ is the probability of this event occurring:\n$$\np(T,V) = P(\\Delta_{\\mathrm{s}}(T,V) + N  0)\n$$\nThis inequality can be rearranged to isolate the random variable $N$:\n$$\np(T,V) = P(N  -\\Delta_{\\mathrm{s}}(T,V))\n$$\nThis probability is, by definition, the value of the cumulative distribution function (CDF) of the noise $N$, which we denote as $F_N(n)$, evaluated at the point $n = -\\Delta_{\\mathrm{s}}(T,V)$.\n$$\np(T,V) = F_N(-\\Delta_{\\mathrm{s}}(T,V))\n$$\nThe CDF $F_N(x)$ is found by integrating the given probability density function (PDF) $f_N(n)$ from $-\\infty$ to $x$:\n$$\nF_N(x) = \\int_{-\\infty}^{x} f_N(n) \\, dn = \\int_{-\\infty}^{x} \\frac{1}{s}\\,\\frac{\\exp(-n/s)}{(1+\\exp(-n/s))^{2}} \\, dn\n$$\nTo solve this integral, we can use a substitution. Let $u = 1 + \\exp(-n/s)$. Then $du = -\\frac{1}{s} \\exp(-n/s) \\, dn$. The integral becomes:\n$$\nF_N(x) = \\int_{n=-\\infty}^{n=x} \\frac{-1}{u^2} \\, du = \\left[ \\frac{1}{u} \\right]_{n=-\\infty}^{n=x} = \\left[ \\frac{1}{1 + \\exp(-n/s)} \\right]_{-\\infty}^{x}\n$$\nEvaluating the limits:\nAs $n \\to x$, the expression is $\\frac{1}{1 + \\exp(-x/s)}$.\nAs $n \\to -\\infty$, $\\exp(-n/s) \\to \\infty$, so the expression $\\frac{1}{1 + \\exp(-n/s)} \\to 0$.\nThus, the CDF of the zero-mean logistic distribution is:\n$$\nF_N(x) = \\frac{1}{1 + \\exp(-x/s)}\n$$\nThis is the standard logistic function.\n\nNow, we can find the crossover probability $p(T,V)$ by substituting $x = -\\Delta_{\\mathrm{s}}(T,V)$ into the CDF expression:\n$$\np(T,V) = F_N(-\\Delta_{\\mathrm{s}}(T,V)) = \\frac{1}{1 + \\exp\\left(-\\frac{-\\Delta_{\\mathrm{s}}(T,V)}{s}\\right)} = \\frac{1}{1 + \\exp\\left(\\frac{\\Delta_{\\mathrm{s}}(T,V)}{s}\\right)}\n$$\nFinally, we substitute the given linear model for the deterministic drift $\\Delta_{\\mathrm{s}}(T,V)$:\n$$\n\\Delta_{\\mathrm{s}}(T,V) = \\Delta_0 + k_T(T - T_0) + k_V(V - V_0)\n$$\nThis yields the final closed-form expression for the crossover probability $p(T,V)$:\n$$\np(T,V) = \\frac{1}{1 + \\exp\\left(\\frac{\\Delta_0 + k_T(T - T_0) + k_V(V - V_0)}{s}\\right)}\n$$\nThis expression represents the probability of a bit flip from $1$ to $0$ as a function of environmental parameters $T$ and $V$, based on the provided physical model.",
            "answer": "$$\n\\boxed{\\frac{1}{1 + \\exp\\left(\\frac{\\Delta_0 + k_T(T - T_0) + k_V(V - V_0)}{s}\\right)}}\n$$"
        },
        {
            "introduction": "A raw PUF response is inherently noisy; to be useful for identity, it must be stabilized. This exercise simulates a core engineering task: designing a system with an Error-Correcting Code (ECC) to ensure robust key reconstruction. You will apply statistical approximations to determine the necessary error-correction capability and explore the fundamental trade-off between reliability and the final key length. ",
            "id": "4235125",
            "problem": "A Physical Unclonable Function (PUF) in a Cyber-Physical System (CPS) is used to bind a device identity to its Digital Twin. The PUF produces a raw binary response that is enrolled once and then reconstructed on-demand. Each response bit flips independently relative to the enrolled reference with Bit Error Rate (BER) $p$. To make the reconstructed key robust across operating conditions, the system uses a binary primitive narrow-sense Bose–Chaudhuri–Hocquenghem (BCH) code as an Error-Correcting Code (ECC) over the PUF response. A reconstruction attempt fails if the number of bit errors in the noisy response exceeds the ECC’s error-correction capability.\n\nConsider a design in which the raw response length is fixed to $n = 511$ bits, so that the BCH code length equals the response length, with $n = 2^{m} - 1$ and integer $m$. The reconstructed key is the BCH code’s dimension $k$ (in bits). The design must ensure that the probability of a reconstruction failure per attempt is at most the desired key failure rate $\\delta$.\n\nAssume the following:\n- The bit-flip process is independent and identically distributed with BER $p = 0.02$.\n- The target key failure rate is $\\delta = 10^{-6}$.\n- The failure event is defined by a binomial model on the number of bit errors over $n$ trials.\n- The BCH family is restricted to primitive narrow-sense binary codes with length $n = 511$.\n\nSelect the error-correction capability $t$ so that the failure probability is at most $\\delta$, and then select the corresponding BCH parameters $[n, k, t]$ consistent with this choice. Compute the maximum reconstructed key length $k$ achievable under these constraints. Express the final key length in bits. If any intermediate approximation is required, justify it from first principles and use a statistically sound approximation method. No external data sources are available. The final answer must be a single number.",
            "solution": "The problem is well-defined and requires the application of standard engineering principles from statistics and coding theory. All provided data is necessary and consistent.\n\nThe first step is to determine the minimum error-correction capability, denoted by $t$, required to meet the specified key failure rate. The number of bit errors, $X$, in a raw response of length $n$ follows a binomial distribution, $X \\sim \\mathcal{B}(n, p)$, with parameters $n=511$ and $p=0.02$.\n\nA reconstruction failure occurs if the number of errors $X$ exceeds the code's capability $t$. The probability of this event must be at most $\\delta = 10^{-6}$. The mathematical constraint is:\n$$P(X  t) \\le \\delta$$\n\nThe exact calculation of this binomial tail probability is computationally intensive. We can use an approximation. First, we compute the mean $\\mu$ and variance $\\sigma^2$ of the binomial distribution:\n$$\\mu = np = 511 \\times 0.02 = 10.22$$\n$$\\sigma^2 = np(1-p) = 511 \\times 0.02 \\times (1 - 0.02) = 10.22 \\times 0.98 = 10.0156$$\nThe standard deviation is $\\sigma = \\sqrt{10.0156} \\approx 3.1647$.\n\nSince $n=511$ is large, and both $np = 10.22  5$ and $n(1-p) = 500.78  5$ are satisfied, the binomial distribution can be accurately approximated by a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ according to the De Moivre-Laplace theorem.\n\nTo improve the accuracy of the approximation for a discrete distribution with a continuous one, we apply a continuity correction. The event $X  t$ for the discrete variable $X$ corresponds to the event $Y  t + 0.5$ for the continuous approximating variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$. The constraint becomes:\n$$P(Y  t + 0.5) \\le \\delta$$\n\nWe standardize this by converting to the standard normal variable $Z = \\frac{Y - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1)$:\n$$P\\left(Z  \\frac{(t + 0.5) - \\mu}{\\sigma}\\right) \\le \\delta$$\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution. The inequality can be written as:\n$$1 - \\Phi\\left(\\frac{t + 0.5 - \\mu}{\\sigma}\\right) \\le \\delta$$\n$$\\Phi\\left(\\frac{t + 0.5 - \\mu}{\\sigma}\\right) \\ge 1 - \\delta$$\nSubstituting $\\delta = 10^{-6}$, we need to find the quantile $z_{\\delta}$ such that $\\Phi(z_{\\delta}) \\ge 1 - 10^{-6} = 0.999999$. Without access to statistical tables, we must rely on known values from probability theory. The one-tailed probability of $10^{-6}$ corresponds to a z-score of approximately $z_{\\delta} \\approx 4.753$.\n\nNow we can solve for $t$:\n$$\\frac{t + 0.5 - \\mu}{\\sigma} \\ge z_{\\delta}$$\n$$t \\ge \\mu - 0.5 + z_{\\delta}\\sigma$$\nSubstituting the numerical values:\n$$t \\ge 10.22 - 0.5 + (4.753)(3.1647)$$\n$$t \\ge 9.72 + 15.0423$$\n$$t \\ge 24.7623$$\nSince $t$ must be an integer representing the number of correctable errors, we must select the smallest integer satisfying this condition, which is $t=25$.\n\nThe next step is to determine the maximum key length $k$ for a primitive narrow-sense binary BCH code with parameters $[n, k, t]$. The code length is given as $n=511$. For BCH codes, the length is of the form $n = 2^m - 1$ for some integer $m$.\n$$511 = 2^m - 1 \\implies 512 = 2^m \\implies m=9$$\nThe dimension $k$ of a BCH code designed to correct $t$ errors is related to $n$ and $m$ by the BCH bound on the number of parity-check bits, $n-k$. The number of parity bits required is at most $mt$. To maximize the information length $k$, we use the standard construction where this bound is an equality:\n$$k = n - mt$$\nSubstituting the determined values $n=511$, $m=9$, and $t=25$:\n$$k = 511 - 9 \\times 25$$\n$$k = 511 - 225$$\n$$k = 286$$\nThus, the maximum reconstructed key length achievable under the given constraints is $286$ bits. This corresponds to the BCH code $[511, 286, 25]$.",
            "answer": "$$\\boxed{286}$$"
        }
    ]
}