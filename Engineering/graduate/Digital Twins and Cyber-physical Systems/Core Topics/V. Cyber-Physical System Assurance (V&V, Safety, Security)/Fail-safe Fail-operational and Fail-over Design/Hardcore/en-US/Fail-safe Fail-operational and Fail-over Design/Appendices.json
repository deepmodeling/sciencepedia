{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of fail-operational design is the use of redundancy, where backup components stand ready to take over for failed ones. While intuitively robust, a critical engineering task is to quantify the precise benefit of such an architecture. This practice guides you through a foundational method for this analysis by modeling a redundant system with repair capabilities as a Continuous-Time Markov Chain (CTMC) . By solving for the steady-state probabilities of the system, you will derive the system's availability, a key metric that captures the long-term probability of the system being operational.",
            "id": "4221276",
            "problem": "A cyber-physical system employs a fail-operational, fail-over architecture with two identical computing units in parallel redundancy. The Digital Twin (DT) of the system monitors unit health and orchestrates immediate repair actions upon failure. Each physical unit fails independently, and each failed unit is repaired independently, with both failure and repair processes modeled as memoryless. Specifically, assume the following modeling assumptions grounded in standard reliability and stochastic process theory:\n\n- Each unit fails according to an independent Poisson process with rate $\\lambda$, leading to exponentially distributed times to failure with parameter $\\lambda$.\n- Each failed unit is restored by an independent repair channel with rate $\\mu$, leading to exponentially distributed times to repair with parameter $\\mu$, and repairs begin immediately upon failure notification by the Digital Twin. If $k$ units are failed, the total repair completion rate is $k \\mu$.\n- The system is operational (available) if at least one unit is functioning, conforming to fail-operational design; it is unavailable only when both units are failed.\n\nModel the system as a continuous-time Markov chain (CTMC), where the state $i \\in \\{0,1,2\\}$ denotes the number of functioning units. Transitions occur via single-unit failure or single-unit repair events, consistent with the memoryless assumptions and independent channels. Derive, from first principles of CTMC stationary analysis and without invoking any pre-packaged reliability shortcuts, the steady-state availability, defined as the stationary probability that the system is operational, i.e., the stationary probability of being in states $i=1$ or $i=2$.\n\nExpress your final answer as a single closed-form analytic expression in terms of $\\lambda$ and $\\mu$. No numerical approximation or rounding is required.",
            "solution": "The problem is valid. The system can be modeled as a continuous-time Markov chain (CTMC) with the state space $S = \\{0, 1, 2\\}$, where the state $i$ represents the number of functioning units. The problem specifies that unit failures and repairs are independent, memoryless processes, which justifies the use of exponential distributions and a CTMC model. This corresponds to a classic birth-death process.\n\nLet $\\pi_i$ be the steady-state probability of the system being in state $i$. We first determine the transition rates between the states based on the provided information.\n\n1.  **State 2: Both units are functioning.**\n    The only possible transition is a failure of one of the two units. Since each unit fails with rate $\\lambda$ and the failures are independent, the total rate of leaving state $2$ is $2\\lambda$. This transition leads to state $1$.\n    Transition: $2 \\to 1$ with rate $q_{2,1} = 2\\lambda$.\n\n2.  **State 1: One unit is functioning, one has failed.**\n    From this state, two transitions are possible:\n    a. The remaining functioning unit fails. This occurs with rate $\\lambda$. The transition is $1 \\to 0$.\n    b. The failed unit is repaired. The problem states that if $k$ units are failed, the total repair completion rate is $k\\mu$. Here, one unit is failed ($k=1$), so the repair rate is $\\mu$. The transition is $1 \\to 2$.\n    The total rate of leaving state $1$ is $(\\lambda + \\mu)$.\n    Transitions: $1 \\to 0$ with rate $q_{1,0} = \\lambda$, and $1 \\to 2$ with rate $q_{1,2} = \\mu$.\n\n3.  **State 0: Both units have failed.**\n    The only possible transition is a repair of one of the two failed units. Two units are failed ($k=2$), so the total repair rate is $2\\mu$. A single repair event moves the system to state $1$.\n    Transition: $0 \\to 1$ with rate $q_{0,1} = 2\\mu$.\n\nThe state transition diagram for this birth-death process is:\n$$\n\\text{State } 2 \\underset{\\mu}{\\stackrel{2\\lambda}{\\rightleftarrows}} \\text{State } 1 \\underset{2\\mu}{\\stackrel{\\lambda}{\\rightleftarrows}} \\text{State } 0\n$$\n\nTo find the steady-state probabilities $\\{\\pi_0, \\pi_1, \\pi_2\\}$, we write the balance equations. For a birth-death process, it is sufficient to use the detailed balance equations, which state that in steady state, the rate of flow from state $i$ to $i-1$ equals the rate of flow from state $i-1$ to $i$.\n\nBalance between states $2$ and $1$:\n$$\n\\pi_2 q_{2,1} = \\pi_1 q_{1,2} \\implies \\pi_2 (2\\lambda) = \\pi_1 \\mu\n$$\nFrom this, we can express $\\pi_2$ in terms of $\\pi_1$:\n$$\n\\pi_2 = \\frac{\\mu}{2\\lambda} \\pi_1\n$$\n\nBalance between states $1$ and $0$:\n$$\n\\pi_1 q_{1,0} = \\pi_0 q_{0,1} \\implies \\pi_1 \\lambda = \\pi_0 (2\\mu)\n$$\nFrom this, we can express $\\pi_0$ in terms of $\\pi_1$:\n$$\n\\pi_0 = \\frac{\\lambda}{2\\mu} \\pi_1\n$$\n\nThe sum of all steady-state probabilities must be equal to $1$:\n$$\n\\pi_0 + \\pi_1 + \\pi_2 = 1\n$$\nSubstitute the expressions for $\\pi_0$ and $\\pi_2$ in terms of $\\pi_1$ into the normalization equation:\n$$\n\\frac{\\lambda}{2\\mu} \\pi_1 + \\pi_1 + \\frac{\\mu}{2\\lambda} \\pi_1 = 1\n$$\nFactor out $\\pi_1$:\n$$\n\\pi_1 \\left( \\frac{\\lambda}{2\\mu} + 1 + \\frac{\\mu}{2\\lambda} \\right) = 1\n$$\nTo solve for $\\pi_1$, we find a common denominator for the terms in the parenthesis, which is $2\\lambda\\mu$:\n$$\n\\pi_1 \\left( \\frac{\\lambda^2}{2\\lambda\\mu} + \\frac{2\\lambda\\mu}{2\\lambda\\mu} + \\frac{\\mu^2}{2\\lambda\\mu} \\right) = 1\n$$\nCombine the terms in the numerator:\n$$\n\\pi_1 \\left( \\frac{\\lambda^2 + 2\\lambda\\mu + \\mu^2}{2\\lambda\\mu} \\right) = 1\n$$\nThe numerator is the expansion of $(\\lambda + \\mu)^2$:\n$$\n\\pi_1 \\left( \\frac{(\\lambda + \\mu)^2}{2\\lambda\\mu} \\right) = 1\n$$\nSolving for $\\pi_1$:\n$$\n\\pi_1 = \\frac{2\\lambda\\mu}{(\\lambda + \\mu)^2}\n$$\nNow we can find $\\pi_0$ and $\\pi_2$:\n$$\n\\pi_0 = \\frac{\\lambda}{2\\mu} \\pi_1 = \\frac{\\lambda}{2\\mu} \\left( \\frac{2\\lambda\\mu}{(\\lambda + \\mu)^2} \\right) = \\frac{\\lambda^2}{(\\lambda + \\mu)^2}\n$$\n$$\n\\pi_2 = \\frac{\\mu}{2\\lambda} \\pi_1 = \\frac{\\mu}{2\\lambda} \\left( \\frac{2\\lambda\\mu}{(\\lambda + \\mu)^2} \\right) = \\frac{\\mu^2}{(\\lambda + \\mu)^2}\n$$\n\nThe problem defines the steady-state availability, $A$, as the stationary probability that the system is operational. The system is operational in states $1$ and $2$. Therefore, the availability is the sum of the probabilities of being in these states:\n$$\nA = \\pi_1 + \\pi_2\n$$\nAlternatively, and more simply, availability is the complement of unavailability. The system is unavailable only in state $0$.\n$$\nA = 1 - \\pi_0\n$$\nUsing the expression for $\\pi_0$:\n$$\nA = 1 - \\frac{\\lambda^2}{(\\lambda + \\mu)^2}\n$$\nTo write this as a single closed-form expression, we combine the terms:\n$$\nA = \\frac{(\\lambda + \\mu)^2 - \\lambda^2}{(\\lambda + \\mu)^2} = \\frac{(\\lambda^2 + 2\\lambda\\mu + \\mu^2) - \\lambda^2}{(\\lambda + \\mu)^2}\n$$\n$$\nA = \\frac{2\\lambda\\mu + \\mu^2}{(\\lambda + \\mu)^2}\n$$\nThis can also be written as $\\frac{\\mu(2\\lambda + \\mu)}{(\\lambda + \\mu)^2}$. The derived expression provides the steady-state availability solely in terms of the failure rate $\\lambda$ and repair rate $\\mu$.",
            "answer": "$$\n\\boxed{\\frac{2\\lambda\\mu + \\mu^2}{(\\lambda + \\mu)^2}}\n$$"
        },
        {
            "introduction": "Effective fail-safe and fail-over strategies depend on the ability to first detect that an anomaly has occurred. This crucial function is often performed by a Digital Twin, which compares the physical system's behavior to the predictions of a mathematical model. In this exercise, you will explore this concept by working with a Luenberger observer, a classic tool for state estimation and anomaly detection . You will derive the residual signal—the difference between measurement and prediction—and then tackle the statistical challenge of setting a detection threshold that provides a desired trade-off between sensitivity and the risk of false alarms.",
            "id": "4221228",
            "problem": "A Digital Twin (DT) supervising a Cyber-Physical System (CPS) uses a state observer to support fail-safe and fail-operational behavior by detecting sensor or model anomalies and triggering a fail-over controller when necessary. Consider a discrete-time linear time-invariant plant with dynamics\n$$\nx_{k+1} = A x_{k} + B u_{k}, \\quad y_{k} = C x_{k} + w_{k},\n$$\nwhere $x_{k} \\in \\mathbb{R}^{n}$ is the state, $u_{k} \\in \\mathbb{R}^{m}$ is the input, $y_{k} \\in \\mathbb{R}^{p}$ is the measurement, and $w_{k} \\sim \\mathcal{N}(0,\\sigma^{2} I_{p})$ is independent and identically distributed zero-mean Gaussian measurement noise with variance $\\sigma^{2}$ per output channel. There is no process noise. The DT implements a Luenberger observer\n$$\n\\hat{x}_{k+1} = A \\hat{x}_{k} + B u_{k} + L \\left( y_{k} - C \\hat{x}_{k} \\right),\n$$\nwith observer gain $L \\in \\mathbb{R}^{n \\times p}$ chosen such that the matrix $A - L C$ is Schur (all eigenvalues strictly inside the unit circle).\n\nIn fault-free operation, the DT computes a residual for anomaly detection,\n$$\nr_{k} = y_{k} - C \\hat{x}_{k},\n$$\nand triggers a fail-safe transition to a fail-over controller whenever the two-sided test $|r_{k}| > \\gamma$ holds, to maintain fail-operational continuity. Here $|r_{k}|$ denotes the Euclidean norm if $p > 1$ and the absolute value if $p = 1$. Assume a single-output sensor channel ($p = 1$) and that the observer has reached steady state with negligible estimation error contribution to the residual variance compared to measurement noise, so that under fault-free operation $r_{k}$ is approximately distributed as $\\mathcal{N}(0,\\sigma^{2})$.\n\nStarting from first principles of linear observers and Gaussian tail probabilities, derive the residual generator $r_{k}$ using the given Luenberger observer and compute the closed-form detection threshold $\\gamma$ that achieves a specified False Alarm Rate (FAR) $\\alpha \\in (0,1)$ for the two-sided test. The FAR is defined as the probability, under fault-free operation, that the detector incorrectly triggers (i.e., the probability that $|r_{k}| > \\gamma$ when no fault is present). Express your final threshold $\\gamma$ as a function of $\\alpha$ and $\\sigma$, using only standard special functions from probability theory, and provide it as a single analytic expression. No numerical rounding is required and no physical units are associated with $\\gamma$ in this setting. Clearly state any distributional functions you use in your reasoning.",
            "solution": "The task is twofold: first, to derive the residual generator $r_{k}$, and second, to compute the detection threshold $\\gamma$ as a function of the false alarm rate $\\alpha$ and the noise standard deviation $\\sigma$.\n\nFirst, let us analyze the dynamics of the system and the observer. The estimation error is defined as $e_{k} = x_{k} - \\hat{x}_{k}$. We can derive its dynamics by subtracting the observer equation from the plant state equation.\n$$\ne_{k+1} = x_{k+1} - \\hat{x}_{k+1}\n$$\nSubstituting the given equations for $x_{k+1}$ and $\\hat{x}_{k+1}$:\n$$\ne_{k+1} = (A x_{k} + B u_{k}) - \\left( A \\hat{x}_{k} + B u_{k} + L(y_{k} - C \\hat{x}_{k}) \\right)\n$$\nThe terms $B u_{k}$ cancel out. We group terms with $A$ and $L$:\n$$\ne_{k+1} = A (x_{k} - \\hat{x}_{k}) - L(y_{k} - C \\hat{x}_{k})\n$$\nNow, substitute $y_{k} = C x_{k} + w_{k}$ into the equation:\n$$\ne_{k+1} = A e_{k} - L( (C x_{k} + w_{k}) - C \\hat{x}_{k} )\n$$\n$$\ne_{k+1} = A e_{k} - L( C(x_{k} - \\hat{x}_{k}) + w_{k} )\n$$\n$$\ne_{k+1} = A e_{k} - L(C e_{k} + w_{k})\n$$\nThis gives the autonomous error dynamics, driven by the measurement noise $w_k$:\n$$\ne_{k+1} = (A - L C)e_{k} - L w_{k}\n$$\nThe problem states that the observer gain $L$ is chosen such that the matrix $A - L C$ is Schur, meaning all its eigenvalues have a magnitude less than $1$. This condition guarantees that the error dynamics are stable. In the absence of noise ($w_k = 0$), the error $e_k$ would converge to $0$. With persistent noise, the error converges to a stationary random process.\n\nNext, we derive the expression for the residual $r_{k}$. The residual is defined as $r_{k} = y_{k} - C \\hat{x}_{k}$. We substitute the measurement equation $y_{k} = C x_{k} + w_{k}$:\n$$\nr_{k} = (C x_{k} + w_{k}) - C \\hat{x}_{k}\n$$\n$$\nr_{k} = C (x_{k} - \\hat{x}_{k}) + w_{k}\n$$\n$$\nr_{k} = C e_{k} + w_{k}\n$$\nThis expression shows that the residual is the sum of the projected estimation error and the measurement noise. Under fault-free operation, the problem makes a key simplifying assumption: \"the observer has reached steady state with negligible estimation error contribution to the residual variance compared to measurement noise\". This means that the term $C e_k$ is considered small enough that its statistical contribution to $r_k$ can be ignored in comparison to $w_k$. Mathematically, this implies the approximation $r_{k} \\approx w_{k}$.\n\nGiven that the measurement noise $w_{k} \\in \\mathbb{R}^{p}$ is distributed as $w_{k} \\sim \\mathcal{N}(0, \\sigma^{2} I_{p})$ and we are considering a single-output channel ($p=1$), the noise $w_k$ is a scalar random variable with distribution $w_{k} \\sim \\mathcal{N}(0, \\sigma^{2})$. Consequently, under the problem's stated assumptions for fault-free steady-state operation, the residual $r_k$ is also a scalar random variable with the same distribution:\n$$\nr_{k} \\sim \\mathcal{N}(0, \\sigma^{2})\n$$\nThis completes the first part of the task, establishing the statistical properties of the residual generator.\n\nNow, we proceed to the second part: computing the detection threshold $\\gamma$. The False Alarm Rate (FAR), denoted by $\\alpha$, is the probability of the detector triggering when no fault is present. The trigger condition is $|r_k| > \\gamma$. Therefore, the FAR is defined as:\n$$\n\\alpha = P(|r_{k}| > \\gamma)\n$$\nSince $r_k$ is a scalar ($p=1$), this is equivalent to:\n$$\n\\alpha = P(r_{k} > \\gamma \\text{ or } r_{k} < -\\gamma)\n$$\nThe events $r_{k} > \\gamma$ and $r_{k} < -\\gamma$ are mutually exclusive, so we can write the probability as the sum:\n$$\n\\alpha = P(r_{k} > \\gamma) + P(r_{k} < -\\gamma)\n$$\nThe normal distribution $\\mathcal{N}(0, \\sigma^{2})$ is symmetric about its mean of $0$. This symmetry implies that $P(r_{k} < -\\gamma) = P(r_{k} > \\gamma)$. Substituting this into the equation for $\\alpha$:\n$$\n\\alpha = 2 P(r_{k} > \\gamma)\n$$\nThis gives us the probability of a one-sided tail:\n$$\nP(r_{k} > \\gamma) = \\frac{\\alpha}{2}\n$$\nTo evaluate this probability, we standardize the random variable $r_k$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$, defined by $Z = \\frac{r_k - 0}{\\sigma} = \\frac{r_k}{\\sigma}$. The inequality $r_k > \\gamma$ is equivalent to $Z \\sigma > \\gamma$, or $Z > \\frac{\\gamma}{\\sigma}$. The probability becomes:\n$$\nP\\left(Z > \\frac{\\gamma}{\\sigma}\\right) = \\frac{\\alpha}{2}\n$$\nLet $\\Phi(z)$ denote the cumulative distribution function (CDF) of the standard normal distribution, defined as $\\Phi(z) = P(Z \\le z)$. The tail probability is related to the CDF by $P(Z > z) = 1 - P(Z \\le z) = 1 - \\Phi(z)$. Applying this to our equation:\n$$\n1 - \\Phi\\left(\\frac{\\gamma}{\\sigma}\\right) = \\frac{\\alpha}{2}\n$$\nSolving for the CDF term, we get:\n$$\n\\Phi\\left(\\frac{\\gamma}{\\sigma}\\right) = 1 - \\frac{\\alpha}{2}\n$$\nTo isolate $\\gamma$, we must apply the inverse of the standard normal CDF. This inverse function is known as the quantile function, or probit function, and is denoted by $\\Phi^{-1}(q)$, where $q \\in (0, 1)$. Applying $\\Phi^{-1}$ to both sides of the equation yields:\n$$\n\\frac{\\gamma}{\\sigma} = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)\n$$\nFinally, solving for the threshold $\\gamma$ gives the desired closed-form expression as a function of $\\sigma$ and $\\alpha$:\n$$\n\\gamma = \\sigma \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)\n$$\nThis expression provides the value of the threshold $\\gamma$ that guarantees a specific false alarm rate $\\alpha$ for the two-sided test, based on a residual signal whose fault-free behavior is modeled as a zero-mean Gaussian process with variance $\\sigma^2$. The function $\\Phi^{-1}$ is a standard special function in probability theory.",
            "answer": "$$\n\\boxed{\\sigma \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)}\n$$"
        },
        {
            "introduction": "Beyond reacting to failures, advanced safety-critical systems can proactively ensure that they never enter an unsafe state. This practice introduces you to a powerful, modern control technique for achieving this: Control Barrier Functions (CBFs). A CBF defines a 'safe' region of the state space and is used to synthesize a controller that renders this region forward-invariant, meaning the system can never leave it . You will derive the safety condition from first principles and design a minimally invasive controller that enforces safety while minimally deviating from a desired performance objective, clearly distinguishing between fail-operational and fail-safe responses.",
            "id": "4221269",
            "problem": "Consider a control-affine scalar cyber-physical system that represents a safety-critical actuator channel monitored by its Digital Twin. The continuous-time plant dynamics are modeled as $\\dot{x} = u$, where $x \\in \\mathbb{R}$ is a dimensionless state and $u \\in \\mathbb{R}$ is a dimensionless control input. The safety requirement is encoded by the safe set $\\mathcal{C} = \\{ x \\in \\mathbb{R} \\mid h(x) \\ge 0 \\}$, where the barrier function is $h(x) = x - x_{\\min}$ with $x_{\\min} \\in \\mathbb{R}$ a fixed threshold. The actuator has hard bounds $u \\in [u_{\\min}, u_{\\max}]$, with $u_{\\min} < u_{\\max}$, and the Digital Twin provides a desired input $u_{\\mathrm{des}}$ to meet nominal performance. All quantities are dimensionless.\n\nYou are to derive from first principles a sufficient forward-invariance condition for $\\mathcal{C}$ based on the time derivative of $h(x)$ and a strictly increasing, continuous, zero-at-zero function $\\alpha(\\cdot)$ (a class-$\\mathcal{K}$ function). Then, using this condition, you are to synthesize a minimally invasive controller that deviates as little as possible from $u_{\\mathrm{des}}$ while ensuring safety (when physically realizable), and to specify a fail-over policy when the safety constraint is infeasible due to actuator saturation.\n\nTasks:\n\n1. Starting from the definitions of the safe set $\\mathcal{C}$, forward invariance (if $x(0) \\in \\mathcal{C}$ then $x(t) \\in \\mathcal{C}$ for all $t \\ge 0$), and the scalar system $\\dot{x} = u$ with $h(x) = x - x_{\\min}$, derive a sufficient condition involving $\\dot{h}(x)$ and $\\alpha(h(x))$ that guarantees forward invariance of $\\mathcal{C}$. Your derivation must use only fundamental dynamical systems facts such as the chain rule, comparison arguments, and properties of class-$\\mathcal{K}$ functions. Do not assume the final inequality form beforehand; derive it explicitly from these bases.\n\n2. Using the condition derived in Task $1$, pose a convex optimization problem of the form \"minimize the squared deviation from $u_{\\mathrm{des}}$ subject to the safety condition and actuator bounds.\" Specialize this optimization to the scalar case and provide the analytic solution based on projection onto the feasible set. Clearly explain how the solution yields a minimally invasive controller when the safety constraint is feasible (fail-operational), and specify a fail-over policy when it is infeasible due to actuator saturations (fail-safe).\n\n3. Implement a complete program that:\n   - Uses the class-$\\mathcal{K}$ function $\\alpha(s) = k s$, with $k > 0$.\n   - For each test case below, computes the control $u^\\star$ that minimizes the squared deviation from $u_{\\mathrm{des}}$ while enforcing the derived safety condition and actuator bounds. If the safety constraint is infeasible, the program must apply a fail-over control that maximizes the instantaneous increase of $h(x)$ under the actuator bounds (fail-safe), and must report that the safety constraint is not satisfied.\n   - For each test case, outputs a pair consisting of the chosen control $u^\\star$ (a float) and a boolean indicating whether the safety condition is satisfied.\n\nUse the following fixed parameters and test suite (all quantities are dimensionless):\n- $k = 0.5$,\n- $x_{\\min} = 1.0$,\n- $u_{\\min} = -2.0$,\n- $u_{\\max} = 2.0$.\n\nTest cases $(x, u_{\\mathrm{des}})$:\n- Case A: $x = 1.5$, $u_{\\mathrm{des}} = 0.0$.\n- Case B: $x = 1.0$, $u_{\\mathrm{des}} = 0.0$.\n- Case C: $x = 0.8$, $u_{\\mathrm{des}} = 0.0$.\n- Case D: $x = -4.0$, $u_{\\mathrm{des}} = 0.0$.\n- Case E: $x = 3.0$, $u_{\\mathrm{des}} = -3.0$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a two-element list of the form $[u^\\star,\\mathrm{flag}]$, with $u^\\star$ a float and $\\mathrm{flag}$ a boolean. For example: $[[u_1,\\mathrm{flag}_1],[u_2,\\mathrm{flag}_2],\\dots]$.\n\nYour solution must be scientifically realistic and derived from the stated bases. The final program must be complete and runnable with no external inputs.",
            "solution": "### Task 1: Derivation of the Sufficient Forward-Invariance Condition\n\nThe objective is to ensure the forward invariance of the safe set $\\mathcal{C} = \\{ x \\in \\mathbb{R} \\mid h(x) \\ge 0 \\}$, where $h(x) = x - x_{\\min}$. Forward invariance means that if an initial state $x(0)$ is in $\\mathcal{C}$, then the state trajectory $x(t)$ remains in $\\mathcal{C}$ for all future times $t \\ge 0$. This is equivalent to requiring that if $h(x(0)) \\ge 0$, then $h(x(t)) \\ge 0$ for all $t \\ge 0$.\n\nWe seek a sufficient condition on the control input $u$ that guarantees this property. We propose the following condition, which is the standard definition of a (zeroing) control barrier function inequality:\n$$ \\dot{h}(x(t)) \\ge -\\alpha(h(x(t))) $$\nwhere $\\alpha(\\cdot)$ is a strictly increasing, continuous function with $\\alpha(0) = 0$ (a class-$\\mathcal{K}$ function).\n\nTo prove that this condition is sufficient for forward invariance, let $y(t) = h(x(t))$. The condition on the trajectory becomes $\\dot{y}(t) \\ge -\\alpha(y(t))$. We analyze this differential inequality using a comparison argument.\n\nConsider the initial value problem for an auxiliary scalar variable $z(t)$:\n$$ \\dot{z}(t) = -\\alpha(z(t)), \\quad z(0) = y(0) = h(x(0)) $$\nSince $\\alpha(\\cdot)$ is a class-$\\mathcal{K}$ function, $\\alpha(s) > 0$ for $s > 0$ and $\\alpha(0) = 0$. This implies that if $z(t) > 0$, then $\\dot{z}(t) < 0$, causing $z(t)$ to decrease. If $z(t) = 0$, then $\\dot{z}(t) = -\\alpha(0) = 0$, which means $z=0$ is an equilibrium point. Therefore, if the initial condition is non-negative, $z(0) \\ge 0$, the solution $z(t)$ will remain non-negative for all $t \\ge 0$.\n\nBy the Comparison Lemma for differential inequalities, since $\\dot{y}(t) \\ge -\\alpha(y(t))$, $\\dot{z}(t) = -\\alpha(z(t))$, and $y(0) = z(0)$, it follows that $y(t) \\ge z(t)$ for all $t \\ge 0$.\n\nCombining these facts, if we start with a safe initial condition $x(0) \\in \\mathcal{C}$, then $h(x(0)) \\ge 0$. This implies $y(0) \\ge 0$, and thus $z(0) \\ge 0$. From the properties of the auxiliary system, we have $z(t) \\ge 0$ for all $t \\ge 0$. The comparison lemma then yields:\n$$ h(x(t)) = y(t) \\ge z(t) \\ge 0 \\quad \\forall t \\ge 0 $$\nThis confirms that $x(t)$ remains in the safe set $\\mathcal{C}$, proving the forward invariance of $\\mathcal{C}$ under the condition $\\dot{h}(x) \\ge -\\alpha(h(x))$.\n\nNow, we specialize this condition for the given system. The time derivative of $h(x)$ is found using the chain rule:\n$$ \\dot{h}(x) = \\frac{\\partial h}{\\partial x} \\dot{x} $$\nFor the given barrier function $h(x) = x - x_{\\min}$, the partial derivative is:\n$$ \\frac{\\partial h}{\\partial x} = \\frac{\\partial}{\\partial x}(x - x_{\\min}) = 1 $$\nSubstituting this and the system dynamics $\\dot{x} = u$ into the expression for $\\dot{h}(x)$ gives:\n$$ \\dot{h}(x) = (1) \\cdot u = u $$\nThe sufficient forward-invariance condition thus becomes a direct constraint on the control input $u$:\n$$ u \\ge -\\alpha(h(x)) $$\nor, substituting the definition of $h(x)$:\n$$ u \\ge -\\alpha(x - x_{\\min}) $$\n\n### Task 2: Minimally Invasive Controller and Fail-Over Policy\n\nThe goal is to synthesize a controller that selects an input $u^\\star$ that is as close as possible to a desired input $u_{\\mathrm{des}}$ while satisfying the derived safety condition and the physical actuator constraints $u \\in [u_{\\min}, u_{\\max}]$. This can be formulated as a convex optimization problem, specifically a Quadratic Program (QP):\n$$\n\\begin{aligned}\n& u^\\star = \\underset{u \\in \\mathbb{R}}{\\text{argmin}} && \\frac{1}{2}(u - u_{\\mathrm{des}})^2 \\\\\n& \\text{subject to} && u \\ge -\\alpha(x - x_{\\min}) \\\\\n& && u \\ge u_{\\min} \\\\\n& && u \\le u_{\\max}\n\\end{aligned}\n$$\nThe factor of $\\frac{1}{2}$ is conventional and does not change the solution. The three linear inequality constraints define a feasible set for the control input $u$. This set is the interval $[L, U]$, where:\n$$ L = \\max(u_{\\min}, -\\alpha(x - x_{\\min})) $$\n$$ U = u_{\\max} $$\n\nA feasible solution exists if and only if the feasible set is non-empty, which requires $L \\le U$. Since $u_{\\min} < u_{\\max}$ is given, the feasibility check simplifies to the condition $-\\alpha(x - x_{\\min}) \\le u_{\\max}$.\n\n**Fail-Operational (Feasible) Case:**\nIf $-\\alpha(x - x_{\\min}) \\le u_{\\max}$, the set of admissible controls is non-empty. The optimization problem reduces to finding the point within the closed interval $[L, U]$ that is closest to $u_{\\mathrm{des}}$. The analytic solution to this problem is the projection of $u_{\\mathrm{des}}$ onto the interval $[L, U]$:\n$$ u^\\star = \\text{proj}_{[L, U]}(u_{\\mathrm{des}}) = \\min(U, \\max(L, u_{\\mathrm{des}})) $$\nSubstituting the definitions of $L$ and $U$:\n$$ u^\\star = \\min(u_{\\max}, \\max(u_{\\min}, -\\alpha(x - x_{\\min}), u_{\\mathrm{des}})) $$\nThis controller is \"minimally invasive\" as it equals $u_{\\mathrm{des}}$ if the desired input already satisfies all constraints. Otherwise, it deviates from $u_{\\mathrm{des}}$ only by the minimum amount required to satisfy the most restrictive active constraint (either the safety condition or an actuator limit).\n\n**Fail-Safe (Infeasible) Case:**\nIf $-\\alpha(x - x_{\\min}) > u_{\\max}$, the safety requirement demands a control input that is larger than the maximum possible actuator output. The feasible set is empty, and no control input can guarantee safety. This is a fail-safe condition. The problem specifies a fail-over policy: select the control that \"maximizes the instantaneous increase of $h(x)$\". Since $\\dot{h}(x) = u$, we must choose the control $u \\in [u_{\\min}, u_{\\max}]$ that maximizes $u$. This control is:\n$$ u^\\star = u_{\\max} $$\nThis action represents the system's best effort to move towards the safe set, even though the safety condition is technically violated at this instant. When this occurs, a flag must indicate that the safety constraint is not satisfied.\n\n### Task 3: Implementation Logic\n\nThe algorithm for computing the control input $u^\\star$ and the safety flag implements the logic from Task 2 using the specified class-$\\mathcal{K}$ function $\\alpha(s) = ks$.\n\nFor a given state $x$ and desired control $u_{\\mathrm{des}}$, along with parameters $k$, $x_{\\min}$, $u_{\\min}$, and $u_{\\max}$:\n1.  Calculate the safety-enforcing lower bound on the control, which we denote $u_{\\text{safe-min}}$:\n    $$ u_{\\text{safe-min}} = -k(x - x_{\\min}) $$\n2.  Check for feasibility. The safety constraint is feasible if it can be satisfied by at least one control input within the actuator's capabilities, which means $u_{\\text{safe-min}} \\le u_{\\max}$.\n    -   **If $u_{\\text{safe-min}} > u_{\\max}$ (Infeasible/Fail-Safe):** Safety cannot be guaranteed.\n        -   The chosen control is the fail-over control: $u^\\star = u_{\\max}$.\n        -   The safety condition is not met, so the flag is `False`.\n    -   **If $u_{\\text{safe-min}} \\le u_{\\max}$ (Feasible/Fail-Operational):** Safety can be guaranteed.\n        -   The lower bound for the control is the more restrictive of the actuator limit and the safety constraint: $L = \\max(u_{\\min}, u_{\\text{safe-min}})$.\n        -   The upper bound is $U = u_{\\max}$.\n        -   The optimal control $u^\\star$ is the projection of $u_{\\mathrm{des}}$ onto the interval $[L, U]$. This can be computed as $u^\\star = \\min(U, \\max(L, u_{\\mathrm{des}}))$, which is equivalent to $u^\\star = \\min(u_{\\max}, \\max(u_{\\mathrm{des}}, u_{\\min}, u_{\\text{safe-min}}))$.\n        -   The safety condition is met, so the flag is `True`.\nThis logic is implemented for each test case provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are used.\n\ndef solve():\n    \"\"\"\n    Computes a minimally invasive safe controller for a set of test cases.\n    \"\"\"\n    # Define fixed parameters from the problem statement.\n    k = 0.5\n    x_min = 1.0\n    u_min = -2.0\n    u_max = 2.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.5, 0.0),   # Case A\n        (1.0, 0.0),   # Case B\n        (0.8, 0.0),   # Case C\n        (-4.0, 0.0),  # Case D\n        (3.0, -3.0),  # Case E\n    ]\n\n    results = []\n    for x, u_des in test_cases:\n        # Task 1 & 2: Calculate the safety constraint.\n        # The barrier function is h(x) = x - x_min.\n        # The class-K function is alpha(s) = k*s.\n        # The safety condition is u >= -alpha(h(x)), which means u >= -k*(x - x_min).\n        h_x = x - x_min\n        \n        # This is the minimum control value required to satisfy the CBF inequality.\n        u_safe_min = -k * h_x\n\n        # Task 2: Check for feasibility and apply fail-over policy if needed.\n        # The safety constraint is feasible if u_safe_min <= u_max.\n        if u_safe_min > u_max:\n            # Infeasible case (Fail-Safe): The safety constraint cannot be satisfied.\n            # Apply fail-over policy: use the control that maximizes dh/dt = u.\n            u_star = u_max\n            is_safe = False\n        else:\n            # Feasible case (Fail-Operational): Synthesize the minimally invasive controller.\n            # The control must be in the interval [L, U], where:\n            # L = max(u_min, u_safe_min)\n            # U = u_max\n            # The solution u_star is the projection of u_des onto [L, U].\n            \n            # Using base Python min/max for clarity. This is equivalent to np.clip.\n            # Combine all lower bounds.\n            lower_bound = max(u_min, u_safe_min)\n            \n            # Project u_des onto the feasible interval [lower_bound, u_max].\n            # 1. Clamp u_des from below.\n            u_clamped_low = max(u_des, lower_bound)\n            # 2. Clamp the result from above.\n            u_star = min(u_clamped_low, u_max)\n            \n            is_safe = True\n\n        results.append([u_star, is_safe])\n\n    # Final print statement in the exact required format.\n    # The str() of a list like [1.0, True] is '[1.0, True]', which matches\n    # the required sub-format [u_star, flag].\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}