{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of automated verification is reachability analysis: the process of systematically exploring all states a system can enter. For systems with vast state spaces, symbolic model checking offers a powerful solution by representing sets of states and transitions implicitly, often using Binary Decision Diagrams (BDDs). This exercise provides hands-on practice with the fundamental algorithm of symbolic forward reachability, asking you to determine how many iterative steps are needed to compute the complete set of reachable states for a simple controller. By working through this problem, you will gain a concrete understanding of how the algorithm converges to a fixed point, connecting the abstract concept of fixed-point iteration to the structural properties of the system's state-space graph .",
            "id": "4231024",
            "problem": "Consider a digital twin of a discrete two-mode controller supervising a cyber-physical plant. The state of the controller-plant system is modeled by two variables: a mode bit $m \\in \\{0,1\\}$ and an integer plant state $x \\in \\{0,1,2,3,4,5\\}$. The controller operates in two modes with the following dynamics, producing a deterministic transition system over the finite state space $\\{0,1\\} \\times \\{0,1,2,3,4,5\\}$:\n\n- If $m=0$ and $x5$, the next state is $(m',x')=(0,x+1)$.\n- If $m=0$ and $x=5$, the next state is $(m',x')=(1,5)$.\n- If $m=1$ and $x0$, the next state is $(m',x')=(1,x-1)$.\n- If $m=1$ and $x=0$, the next state is $(m',x')=(0,0)$.\n\nThe initial state is $(m,x)=(0,0)$. A Binary Decision Diagram (BDD) is used to symbolically encode the characteristic function of the initial set and the transition relation over current-state variables $(m,x)$ and next-state variables $(m',x')$, employing existential quantification over current-state variables to compute one-step forward images.\n\nStarting only from the fundamental principles of symbolic reachability in finite-state model checking and lattice-theoretic fixed points, reason about the monotone least fixed point that captures all states reachable from $(0,0)$ under the given transition system. Let the transition depth $D$ be defined as the length of the longest shortest path from $(0,0)$ to any state reachable under the transition relation. Derive the number of BDD-based image iterations required until the least fixed point is detected by the standard reachability iteration (starting from the initial set and repeatedly taking the union with the one-step forward image) and express the final answer as a single integer. No rounding is required, and no units are to be reported in the answer.",
            "solution": "The problem asks for the number of iterations required for a standard symbolic reachability algorithm to compute the set of all reachable states of a given finite-state transition system. The algorithm terminates when it detects a fixed point.\n\nLet the state space of the system be $S = \\{0,1\\} \\times \\{0,1,2,3,4,5\\}$. The state is a pair $(m,x)$ where $m \\in \\{0,1\\}$ is the mode and $x \\in \\{0,1,2,3,4,5\\}$ is the plant state. The total number of states is $2 \\times 6 = 12$. The system is deterministic, with the transition relation $T \\subseteq S \\times S$ defined by the four rules provided. Let $(m', x')$ be the unique successor of $(m, x)$, denoted by $(m,x) \\to (m',x')$.\nThe initial state is $(0,0)$. The set of initial states is $I = \\{(0,0)\\}$.\n\nThe set of all reachable states, $R_{all}$, is the least fixed point of the operator $F(Y) = I \\cup \\text{Image}(Y)$, where $Y \\subseteq S$ and $\\text{Image}(Y) = \\{s' \\in S \\mid \\exists s \\in Y, (s,s') \\in T\\}$. The standard iterative algorithm to compute this least fixed point starts with a set of states and repeatedly adds the image of that set. The process is defined as follows:\nLet $S_0 = I$ be the set of states after $0$ iterations.\nFor $k \\ge 1$, the set of states after $k$ iterations is given by the recurrence relation:\n$$S_k = S_{k-1} \\cup \\text{Image}(S_{k-1})$$\nThe algorithm terminates when a fixed point is reached, i.e., when $S_k = S_{k-1}$ for some $k$. The problem asks for this value of $k$, which is the number of iterations required to detect the completion of the reachability set.\n\nLet us establish the meaning of the set $S_k$. By induction, $S_k$ is the set of all states reachable from the initial set $I$ in at most $k$ steps. Let $\\text{dist}(s_0, s)$ be the length of the shortest path from a state $s_0$ to a state $s$. Then, $S_k = \\{s \\in S \\mid \\text{dist}((0,0), s) \\le k\\}$.\n\nThe algorithm terminates at iteration $k$ if $S_k = S_{k-1}$. This is equivalent to the condition $\\{s \\in S \\mid \\text{dist}((0,0), s) \\le k\\} = \\{s \\in S \\mid \\text{dist}((0,0), s) \\le k-1\\}$. This equality holds if and only if there are no states $s$ for which $\\text{dist}((0,0), s) = k$. This implies that all reachable states are reachable in at most $k-1$ steps.\n\nLet $D$ be the transition depth as defined in the problem: the length of the longest shortest path from the initial state $(0,0)$ to any reachable state.\n$$D = \\max_{s \\in R_{all}} \\text{dist}((0,0), s)$$\nThis means there exists at least one state $s_{max}$ such that $\\text{dist}((0,0), s_{max}) = D$, and for all other reachable states $s'$, $\\text{dist}((0,0), s') \\le D$.\nAccording to our definition of $S_k$, the state $s_{max}$ will first appear in the set $S_D$, since $\\text{dist}((0,0), s_{max}) = D$. It will not be in $S_{D-1}$. Therefore, $S_D \\neq S_{D-1}$, meaning the algorithm does not terminate at or before iteration $D$.\n\nAt iteration $D$, the set computed is $S_D = \\{s \\in S \\mid \\text{dist}((0,0), s) \\le D\\}$. By definition of $D$, this set contains all reachable states, so $S_D = R_{all}$.\nNow consider the next iteration, $k=D+1$:\n$$S_{D+1} = S_D \\cup \\text{Image}(S_D)$$\nSince $S_D = R_{all}$, the set of all reachable states, any state in $\\text{Image}(S_D)$ is a successor of a reachable state and is therefore itself a reachable state. This implies $\\text{Image}(S_D) \\subseteq R_{all} = S_D$.\nConsequently, $S_{D+1} = S_D \\cup \\text{Image}(S_D) = S_D$.\nThe condition for termination, $S_k = S_{k-1}$, is met for the first time at $k=D+1$. Thus, the number of required iterations is $D+1$.\n\nThe task reduces to finding the value of $D$. We must trace the paths from the initial state $(0,0)$ to determine the shortest-path distance to all other reachable states.\nThe transitions are:\n1.  $(0,x) \\to (0,x+1)$ for $x \\in \\{0,1,2,3,4\\}$\n2.  $(0,5) \\to (1,5)$\n3.  $(1,x) \\to (1,x-1)$ for $x \\in \\{1,2,3,4,5\\}$\n4.  $(1,0) \\to (0,0)$\n\nLet's compute the shortest-path distances, $\\text{dist}((0,0), (m,x))$, starting from $\\text{dist}((0,0),(0,0))=0$:\n- The path starting from $(0,0)$ using rule 1:\n$(0,0) \\to (0,1) \\to (0,2) \\to (0,3) \\to (0,4) \\to (0,5)$.\nThis gives the distances:\n$\\text{dist}((0,0),(0,1)) = 1$\n$\\text{dist}((0,0),(0,2)) = 2$\n$\\text{dist}((0,0),(0,3)) = 3$\n$\\text{dist}((0,0),(0,4)) = 4$\n$\\text{dist}((0,0),(0,5)) = 5$\n\n- From $(0,5)$, the next state is $(1,5)$ (rule 2). The distance is:\n$\\text{dist}((0,0),(1,5)) = \\text{dist}((0,0),(0,5)) + 1 = 5+1 = 6$.\n\n- From $(1,5)$, the path continues using rule 3:\n$(1,5) \\to (1,4) \\to (1,3) \\to (1,2) \\to (1,1) \\to (1,0)$.\nThis gives the distances:\n$\\text{dist}((0,0),(1,4)) = \\text{dist}((0,0),(1,5)) + 1 = 6+1 = 7$\n$\\text{dist}((0,0),(1,3)) = \\text{dist}((0,0),(1,4)) + 1 = 7+1 = 8$\n$\\text{dist}((0,0),(1,2)) = \\text{dist}((0,0),(1,3)) + 1 = 8+1 = 9$\n$\\text{dist}((0,0),(1,1)) = \\text{dist}((0,0),(1,2)) + 1 = 9+1 = 10$\n$\\text{dist}((0,0),(1,0)) = \\text{dist}((0,0),(1,1)) + 1 = 10+1 = 11$\n\n- From $(1,0)$, the next state is $(0,0)$ (rule 4), which closes a cycle. The transition graph consists of a single cycle of length $12$ that includes all states in $S$.\n\nThe set of shortest-path distances from $(0,0)$ to all reachable states (which is the entire state space $S$) is $\\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\\}$.\nThe maximum value in this set is the transition depth $D$:\n$$D = \\max\\{0, 1, \\dots, 11\\} = 11$$\nThe state furthest from the origin is $(1,0)$, with a shortest-path distance of $11$.\n\nThe number of iterations required to detect the fixed point is $D+1$.\nNumber of iterations = $11+1 = 12$.\n\nAt iteration $11$, the set $S_{11}$ will be computed, which contains all $12$ states for the first time. The check $S_{11} \\stackrel{?}{=} S_{10}$ fails because state $(1,0)$ is new.\nAt iteration $12$, the set $S_{12}$ is computed as $S_{11} \\cup \\text{Image}(S_{11})$. Since $S_{11}$ is the full set of reachable states, $\\text{Image}(S_{11}) \\subseteq S_{11}$, and thus $S_{12} = S_{11}$. The check $S_{12} \\stackrel{?}{=} S_{11}$ succeeds, and the algorithm terminates. The total number of iterations performed is $12$.",
            "answer": "$$\\boxed{12}$$"
        },
        {
            "introduction": "Many cyber-physical systems exhibit probabilistic behavior due to uncertain environments, random failures, or randomized algorithms. In these cases, verification shifts from asking whether a bad state is reachable to quantifying the probability of such an event. This practice problem delves into the core of probabilistic model checking for Discrete-Time Markov Chains (DTMCs). You will first derive the system of linear equations for computing reachability probabilities from first principles and then apply this theory to calculate the probability of a safety-critical event in a hypothetical controller. This exercise is essential for understanding how to reason quantitatively about system reliability and safety under uncertainty .",
            "id": "4231030",
            "problem": "Consider a Discrete-Time Markov Chain (DTMC) modeling the discrete event abstraction of a digital twin for a safety controller in a cyber-physical system (CPS), with a finite state space $S$, a transition probability matrix $P$ that is row-stochastic, and a designated set of target states $T \\subseteq S$ representing safe shutdown states. Let $F$ denote the temporal operator “eventually,” and define the reachability probability $P(s \\models F\\,T)$ as the probability that, starting from state $s \\in S$, the DTMC visits any state in $T$ at some finite time. Using only the Kolmogorov axioms of probability, the Markov property, and the Chapman–Kolmogorov equation, derive the system of linear equations satisfied by the function $x : S \\to [0,1]$ with $x(s) = P(s \\models F\\,T)$.\n\nProve that the standard value iteration sequence on a finite DTMC for reachability probabilities converges pointwise to $x$, where the sequence $(v^{(k)})_{k \\in \\mathbb{N}}$ is defined by $v^{(0)}(s) = 1$ for $s \\in T$ and $v^{(0)}(s) = 0$ for $s \\notin T$, and for $k \\geq 0$,\n$$\nv^{(k+1)}(s) =\n\\begin{cases}\n1,  s \\in T, \\\\\n\\sum\\limits_{s' \\in S} P(s,s')\\,v^{(k)}(s'),  s \\notin T.\n\\end{cases}\n$$\n\nThen, apply the derived equations to the specific DTMC with state space $S = \\{s_0,s_1,s_2,s_3,s_4\\}$, target set $T = \\{s_3\\}$, and transition probability matrix $P$ (rows are ordered $s_0,s_1,s_2,s_3,s_4$; columns are ordered $s_0,s_1,s_2,s_3,s_4$):\n$$\nP =\n\\begin{pmatrix}\n0  0.6  0.4  0  0 \\\\\n0.3  0  0  0.5  0.2 \\\\\n0  0  0.2  0.4  0.4 \\\\\n0  0  0  1  0 \\\\\n0  0  0  0  1\n\\end{pmatrix}.\n$$\nCompute the value of $P(s_0 \\models F\\,T)$ and express your final numerical answer as a real number. Round your answer to six significant figures. No units are required.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the theory of Markov chains, well-posed, objective, and internally consistent. We proceed with the solution, which is divided into three parts as requested.\n\n### Part 1: Derivation of the System of Linear Equations\n\nLet the given Discrete-Time Markov Chain (DTMC) have a finite state space $S$, a transition probability matrix $P$, and a target set of states $T \\subseteq S$. We are asked to derive the system of linear equations for the reachability probability function $x: S \\to [0,1]$, where $x(s) = P(s \\models F\\,T)$ is the probability that a path starting from state $s$ eventually visits a state in $T$.\n\nLet $\\omega = (\\omega_0, \\omega_1, \\omega_2, \\dots)$ be a path (a sequence of states) in the DTMC. The event \"$s \\models F\\,T$\" corresponds to the set of paths starting with $\\omega_0=s$ for which there exists a finite time step $k \\ge 0$ such that $\\omega_k \\in T$.\n\nWe determine $x(s)$ by conditioning on the state $s$:\n\nCase 1: $s \\in T$.\nIf the starting state $s$ is already in the target set $T$, the condition of reaching $T$ is satisfied at time $k=0$. Therefore, the probability of the event is $1$.\n$$x(s) = 1, \\quad \\text{for } s \\in T$$\n\nCase 2: $s \\notin T$.\nIf the starting state $s$ is not in $T$, the path must take at least one step. We can apply the law of total probability by conditioning on the outcome of the first step, $\\omega_1$. Let $s'$ be the state after one step, i.e., $\\omega_1=s'$.\n$$x(s) = P(\\text{eventually reach } T \\mid \\omega_0=s)$$\nBy the law of total probability:\n$$x(s) = \\sum_{s' \\in S} P(\\text{eventually reach } T \\mid \\omega_1=s', \\omega_0=s) \\cdot P(\\omega_1=s' \\mid \\omega_0=s)$$\nThe term $P(\\omega_1=s' \\mid \\omega_0=s)$ is the transition probability from $s$ to $s'$, denoted by $P(s,s')$.\nThe term $P(\\text{eventually reach } T \\mid \\omega_1=s', \\omega_0=s)$ is the probability of eventually reaching $T$ given that the path starts at $s$ and moves to $s'$ in the first step. By the Markov property, the future evolution of the process from state $s'$ is independent of its past (i.e., how it reached $s'$). Therefore, this conditional probability is simply the probability of eventually reaching $T$ starting from state $s'$.\n$$P(\\text{eventually reach } T \\mid \\omega_1=s', \\omega_0=s) = P(\\text{eventually reach } T \\mid \\omega_0=s') = x(s')$$\nSubstituting these into the equation for $x(s)$:\n$$x(s) = \\sum_{s' \\in S} P(s,s') x(s'), \\quad \\text{for } s \\notin T$$\n\nCombining both cases, the reachability probabilities $\\{x(s)\\}_{s \\in S}$ satisfy the following system of linear equations:\n$$\nx(s) =\n\\begin{cases}\n1,  \\text{if } s \\in T, \\\\\n\\sum\\limits_{s' \\in S} P(s,s')\\,x(s'),  \\text{if } s \\notin T.\n\\end{cases}\n$$\nThis system has a unique solution for the minimal non-negative probabilities, which are the reachability probabilities.\n\n### Part 2: Proof of Convergence for Value Iteration\n\nWe are asked to prove that the sequence $(v^{(k)})_{k \\in \\mathbb{N}}$, defined by $v^{(0)}(s) = \\mathbf{1}_{T}(s)$ (the indicator function for set $T$) and the recurrence\n$$\nv^{(k+1)}(s) =\n\\begin{cases}\n1,  s \\in T, \\\\\n\\sum\\limits_{s' \\in S} P(s,s')\\,v^{(k)}(s'),  s \\notin T,\n\\end{cases}\n$$\nconverges pointwise to $x(s) = P(s \\models F\\,T)$.\n\nLet us establish the probabilistic meaning of $v^{(k)}(s)$. We claim that $v^{(k)}(s)$ is the probability of reaching a state in $T$ in at most $k$ steps, starting from state $s$. We prove this by induction on $k$.\n\nBase case ($k=0$):\n$v^{(0)}(s)$ is defined as $1$ if $s \\in T$ and $0$ if $s \\notin T$. This is precisely the probability of reaching $T$ in $0$ steps (i.e., starting in $T$). The claim holds for $k=0$.\n\nInductive step:\nAssume that for some $k \\ge 0$, $v^{(k)}(s)$ is the probability of reaching $T$ in at most $k$ steps for all $s \\in S$. Let's compute the probability of reaching $T$ in at most $k+1$ steps.\nIf $s \\in T$, the probability of reaching $T$ in at most $k+1$ steps is $1$. The recurrence gives $v^{(k+1)}(s) = 1$ for $s \\in T$, which matches.\nIf $s \\notin T$, to reach $T$ in at most $k+1$ steps, the process must transition to some state $s' \\in S$ in the first step, and from $s'$ it must reach $T$ in the remaining $k$ steps. By the law of total probability and the Markov property:\n$$P(\\text{reach } T \\text{ in } \\le k+1 \\text{ steps} \\mid \\omega_0=s) = \\sum_{s' \\in S} P(\\omega_1=s' \\mid \\omega_0=s) \\cdot P(\\text{reach } T \\text{ in } \\le k \\text{ steps} \\mid \\omega_0=s')$$\nUsing the inductive hypothesis, $P(\\text{reach } T \\text{ in } \\le k \\text{ steps} \\mid \\omega_0=s') = v^{(k)}(s')$.\nTherefore, for $s \\notin T$:\n$$P(\\text{reach } T \\text{ in } \\le k+1 \\text{ steps} \\mid \\omega_0=s) = \\sum_{s' \\in S} P(s,s') v^{(k)}(s')$$\nThis matches the recurrence relation for $v^{(k+1)}(s)$. The induction is complete.\n\nNow, let $E_k$ be the event that a path starting from $s$ reaches $T$ in at most $k$ steps. From our proof, $P(E_k) = v^{(k)}(s)$.\nThe sequence of events $(E_k)_{k \\in \\mathbb{N}}$ is non-decreasing, i.e., $E_k \\subseteq E_{k+1}$ for all $k \\ge 0$, because if a path reaches $T$ within $k$ steps, it certainly reaches it within $k+1$ steps.\nThe event that a path from $s$ eventually reaches $T$, which we may denote as $E$, is the union of all $E_k$:\n$$E = \\bigcup_{k=0}^{\\infty} E_k$$\nBy the continuity of probability measures (a consequence of the Kolmogorov axioms), for a non-decreasing sequence of events, the probability of the union is the limit of the probabilities:\n$$P(E) = P\\left(\\bigcup_{k=0}^{\\infty} E_k\\right) = \\lim_{k \\to \\infty} P(E_k)$$\nBy definition, $x(s) = P(E)$, and we have shown $v^{(k)}(s) = P(E_k)$. Therefore:\n$$x(s) = \\lim_{k \\to \\infty} v^{(k)}(s)$$\nThis proves that the value iteration sequence converges pointwise to the reachability probability $x(s)$ for all $s \\in S$.\n\n### Part 3: Application to a Specific DTMC\n\nWe are given $S = \\{s_0, s_1, s_2, s_3, s_4\\}$, $T = \\{s_3\\}$, and the transition matrix\n$$\nP =\n\\begin{pmatrix}\n0  0.6  0.4  0  0 \\\\\n0.3  0  0  0.5  0.2 \\\\\n0  0  0.2  0.4  0.4 \\\\\n0  0  0  1  0 \\\\\n0  0  0  0  1\n\\end{pmatrix}.\n$$\nWe want to compute $x_0 = P(s_0 \\models F\\,\\{s_3\\})$. Let $x_i = x(s_i)$. From Part 1, we have the system of equations.\n\nFor $s_3 \\in T$:\n$x_3 = 1$\n\nNote that $s_4$ is an absorbing state since $P(s_4, s_4)=1$. Since $s_4 \\notin T$, any path that reaches $s_4$ will be trapped there and will never reach $T$. Therefore, the probability of reaching $T$ from $s_4$ is $0$.\n$x_4 = 0$.\nThis can also be formally derived from the value iteration: $v^{(0)}(s_4)=0$, and $v^{(k+1)}(s_4) = P(s_4, s_4)v^{(k)}(s_4) = 1 \\cdot v^{(k)}(s_4)$, so by induction $v^{(k)}(s_4)=0$ for all $k$, and the limit is $x_4=0$.\n\nFor the remaining states $s_0, s_1, s_2 \\notin T$, we have:\n$x_0 = P(s_0,s_0)x_0 + P(s_0,s_1)x_1 + P(s_0,s_2)x_2 + P(s_0,s_3)x_3 + P(s_0,s_4)x_4$\n$x_0 = 0 \\cdot x_0 + 0.6 \\cdot x_1 + 0.4 \\cdot x_2 + 0 \\cdot x_3 + 0 \\cdot x_4 \\implies x_0 = 0.6 x_1 + 0.4 x_2$\n\n$x_1 = P(s_1,s_0)x_0 + P(s_1,s_1)x_1 + P(s_1,s_2)x_2 + P(s_1,s_3)x_3 + P(s_1,s_4)x_4$\n$x_1 = 0.3 \\cdot x_0 + 0 \\cdot x_1 + 0 \\cdot x_2 + 0.5 \\cdot x_3 + 0.2 \\cdot x_4 \\implies x_1 = 0.3 x_0 + 0.5 x_3 + 0.2 x_4$\n\n$x_2 = P(s_2,s_0)x_0 + P(s_2,s_1)x_1 + P(s_2,s_2)x_2 + P(s_2,s_3)x_3 + P(s_2,s_4)x_4$\n$x_2 = 0 \\cdot x_0 + 0 \\cdot x_1 + 0.2 \\cdot x_2 + 0.4 \\cdot x_3 + 0.4 \\cdot x_4 \\implies x_2 = 0.2 x_2 + 0.4 x_3 + 0.4 x_4$\n\nNow we substitute the known values $x_3=1$ and $x_4=0$ into this system.\nThe equation for $x_2$ becomes:\n$x_2 = 0.2 x_2 + 0.4(1) + 0.4(0)$\n$x_2 - 0.2 x_2 = 0.4$\n$0.8 x_2 = 0.4$\n$x_2 = \\frac{0.4}{0.8} = 0.5$\n\nThe equation for $x_1$ becomes:\n$x_1 = 0.3 x_0 + 0.5(1) + 0.2(0)$\n$x_1 = 0.3 x_0 + 0.5$\n\nFinally, substitute the expressions for $x_1$ and $x_2$ into the equation for $x_0$:\n$x_0 = 0.6 x_1 + 0.4 x_2$\n$x_0 = 0.6 (0.3 x_0 + 0.5) + 0.4 (0.5)$\n$x_0 = 0.18 x_0 + 0.3 + 0.2$\n$x_0 = 0.18 x_0 + 0.5$\n$x_0 - 0.18 x_0 = 0.5$\n$0.82 x_0 = 0.5$\n$x_0 = \\frac{0.5}{0.82} = \\frac{50}{82} = \\frac{25}{41}$\n\nTo provide the numerical answer, we compute the value and round to six significant figures:\n$x_0 = \\frac{25}{41} \\approx 0.60975609756...$\nRounding to six significant figures gives $0.609756$.",
            "answer": "$$\n\\boxed{0.609756}\n$$"
        },
        {
            "introduction": "Verifying systems with continuous dynamics, such as those found in robotics and control systems, presents a unique challenge because their state spaces are infinite. A powerful technique to address this is over-approximate reachability, where we compute geometric sets that are guaranteed to contain all possible system trajectories. This hands-on practice introduces you to this method using zonotopes, a class of convex sets well-suited for linear systems. You will compute the reachable set for a system with disturbances and use it to rigorously verify a safety property, learning how abstract concepts from convex analysis provide a practical and sound foundation for certifying the safety of continuous systems .",
            "id": "4231096",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) monitors a two-dimensional state $x \\in \\mathbb{R}^{2}$ with discrete-time Linear Time-Invariant (LTI) dynamics\n$$x_{k+1} = A x_{k} + w_{k},$$\nwhere $A \\in \\mathbb{R}^{2 \\times 2}$ and the exogenous disturbance $w_{k}$ lies in a bounded convex uncertainty set $W \\subset \\mathbb{R}^{2}$. The DT uses model checking with over-approximate reachability via convex sets to verify the safety property that an aggregate quantity $n^{\\top} x$ remains below a threshold $h$ at a given horizon. The safety specification is the half-space $\\{x \\in \\mathbb{R}^{2} \\mid n^{\\top} x \\leq h\\}$.\n\nConsider the following scientifically realistic parameterization:\n- The system matrix is $A = \\mathrm{diag}(0.9, 0.8)$.\n- The initial state set $X_{0}$ is a zonotope in center-generator form $Z(c_{0}, G_{0})$ with center $c_{0} = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}$ and generator matrix $G_{0} = \\begin{pmatrix} 0.1  0 \\\\ 0  0.05 \\end{pmatrix}$, meaning $X_{0} = \\{c_{0} + G_{0} \\xi \\mid \\xi \\in [-1,1]^{2}\\}$.\n- The disturbance set $W$ is a zonotope $Z(0, G_{w})$ with generator matrix $G_{w} = \\begin{pmatrix} 0.01  0 \\\\ 0  0.02 \\end{pmatrix}$, i.e., $W = \\{G_{w} \\eta \\mid \\eta \\in [-1,1]^{2}\\}$ and has zero center.\n- The safety half-space is defined by $n = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and threshold $h = 1.2$.\n\nUsing only fundamental definitions from convex analysis and linear systems, perform the following:\n1. Starting from the definition of the reachable set under the given dynamics and the definitions of Minkowski sum and linear image of sets, construct the over-approximate reachable set at horizon $N = 3$ as a zonotope $Z(c, G)$ that contains all true reachable states $x_{3}$ from $X_{0}$ under disturbances in $W$. Express $c$ and the columns of $G$ in terms of $A$, $c_{0}$, $G_{0}$, and $G_{w}$.\n2. Using the definition of the support function $h_{C}(n) = \\sup_{x \\in C} n^{\\top} x$ for a convex set $C$, derive an expression for $h_{Z(c,G)}(n)$ for a zonotope in center-generator form purely from the properties of Minkowski sum and linear maps. Then compute the numerical value of $h_{Z(c,G)}(n)$ for the constructed $Z(c,G)$, with the supplied $n$.\n3. Justify, from first principles, why using the over-approximate reachable zonotope $Z(c,G)$ is sound for safety checking of the half-space $n^{\\top} x \\leq h$. Conclude by computing the safety margin $m = h - h_{Z(c,G)}(n)$ at $N = 3$.\n\nProvide the final answer as the single real number $m$. No rounding is required.",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, and complete. All necessary data and definitions are provided for a unique and meaningful solution. The problem's context is standard in reachability analysis for control systems.\n\nThe solution proceeds in three parts as requested.\n\n### Part 1: Construction of the Over-Approximate Reachable Set\n\nThe state of the system at time step $k+1$ is given by the discrete-time LTI dynamics $x_{k+1} = A x_{k} + w_{k}$. The initial state $x_{0}$ is in a set $X_{0}$, and each disturbance $w_{k}$ is in a set $W$. The true reachable set of states at a future time $N$, denoted $\\mathcal{R}_{N}$, is the set of all possible states $x_{N}$ that can be reached from any initial state $x_{0} \\in X_{0}$ under any valid sequence of disturbances $w_{0}, w_{1}, \\ldots, w_{N-1} \\in W$.\n\nBy unrolling the dynamics for $N=3$:\n$$x_{1} = A x_{0} + w_{0}$$\n$$x_{2} = A x_{1} + w_{1} = A (A x_{0} + w_{0}) + w_{1} = A^{2} x_{0} + A w_{0} + w_{1}$$\n$$x_{3} = A x_{2} + w_{2} = A (A^{2} x_{0} + A w_{0} + w_{1}) + w_{2} = A^{3} x_{0} + A^{2} w_{0} + A w_{1} + w_{2}$$\nThe true reachable set at $N=3$, $\\mathcal{R}_{3}$, is the set of all such points $x_{3}$:\n$$\\mathcal{R}_{3} = \\{ A^{3} x_{0} + A^{2} w_{0} + A w_{1} + w_{2} \\mid x_{0} \\in X_{0}, w_{0} \\in W, w_{1} \\in W, w_{2} \\in W \\}$$\nThis can be expressed using the fundamental definitions of the linear image of a set, $L(C) = \\{Lx \\mid x \\in C\\}$, and the Minkowski sum of sets, $C_{1} \\oplus C_{2} = \\{c_{1} + c_{2} \\mid c_{1} \\in C_{1}, c_{2} \\in C_{2}\\}$.\n$$\\mathcal{R}_{3} = A^{3}(X_{0}) \\oplus A^{2}(W) \\oplus A(W) \\oplus W$$\nTo compute an over-approximation of this set, we use zonotopes, as they are closed under linear maps and Minkowski sums. A zonotope is defined in center-generator form as $Z(c, G) = \\{c + G\\xi \\mid \\xi \\in [-1,1]^{p}\\}$, where $p$ is the number of generators (columns of $G$).\n\nThe key properties are:\n1.  Linear image: $L(Z(c, G)) = Z(Lc, LG)$.\n2.  Minkowski sum: $Z(c_{1}, G_{1}) \\oplus Z(c_{2}, G_{2}) = Z(c_{1} + c_{2}, [G_{1} \\ G_{2}])$, where $[G_{1} \\ G_{2}]$ is the matrix formed by horizontal concatenation of the generator matrices.\n\nThe initial set is $X_{0} = Z(c_{0}, G_{0})$ and the disturbance set is $W = Z(0, G_{w})$. We compute the zonotope over-approximation $X_{3}$ for $\\mathcal{R}_{3}$:\n$$X_{3} = A^{3}(Z(c_{0}, G_{0})) \\oplus A^{2}(Z(0, G_{w})) \\oplus A(Z(0, G_{w})) \\oplus Z(0, G_{w})$$\n$$X_{3} = Z(A^{3}c_{0}, A^{3}G_{0}) \\oplus Z(A^{2}0, A^{2}G_{w}) \\oplus Z(A0, AG_{w}) \\oplus Z(0, G_{w})$$\n$$X_{3} = Z(A^{3}c_{0}, A^{3}G_{0}) \\oplus Z(0, A^{2}G_{w}) \\oplus Z(0, AG_{w}) \\oplus Z(0, G_{w})$$\nSumming these zonotopes gives the final zonotope $X_{3} = Z(c, G)$, where the center $c$ is the sum of the individual centers, and the generator matrix $G$ is the concatenation of the individual generator matrices.\n$$c = A^{3}c_{0} + 0 + 0 + 0 = A^{3}c_{0}$$\n$$G = [A^{3}G_{0} \\ A^{2}G_{w} \\ AG_{w} \\ G_{w}]$$\nThis provides the analytical expression for the center and generators of the over-approximate reachable set $Z(c, G)$ at horizon $N=3$.\n\n### Part 2: Support Function Derivation and Calculation\n\nThe support function of a convex set $C$ for a given direction vector $n$ is defined as $h_{C}(n) = \\sup_{x \\in C} n^{\\top} x$. For a zonotope $Z(c, G) = \\{ c + G\\xi \\mid \\xi \\in [-1,1]^{p} \\}$, any point $x$ can be written as $x = c + \\sum_{i=1}^{p} g_{i} \\xi_{i}$, where $g_{i}$ are the columns of $G$ and $\\xi_{i} \\in [-1,1]$.\n\nThe support function is derived from this definition:\n$$h_{Z(c,G)}(n) = \\sup_{\\xi \\in [-1,1]^{p}} n^{\\top} \\left( c + \\sum_{i=1}^{p} g_{i} \\xi_{i} \\right)$$\n$$h_{Z(c,G)}(n) = \\sup_{\\xi \\in [-1,1]^{p}} \\left( n^{\\top}c + \\sum_{i=1}^{p} (n^{\\top}g_{i})\\xi_{i} \\right)$$\nUsing the linearity of the supremum, we separate the constant term:\n$$h_{Z(c,G)}(n) = n^{\\top}c + \\sup_{\\xi \\in [-1,1]^{p}} \\sum_{i=1}^{p} (n^{\\top}g_{i})\\xi_{i}$$\nThe supremum of the sum is the sum of the suprema, as each term $(n^{\\top}g_{i})\\xi_{i}$ is independent. To maximize each term, we must choose $\\xi_{i} = \\mathrm{sgn}(n^{\\top}g_{i})$. This yields:\n$$\\sup_{\\xi_{i} \\in [-1,1]} (n^{\\top}g_{i})\\xi_{i} = |n^{\\top}g_{i}|$$\nTherefore, the support function of the zonotope is:\n$$h_{Z(c,G)}(n) = n^{\\top}c + \\sum_{i=1}^{p} |n^{\\top}g_{i}|$$\nThis sum can be written compactly using the $L_{1}$-norm as $n^{\\top}c + \\|G^{\\top}n\\|_{1}$.\n\nNow we compute the numerical value for the zonotope $X_{3} = Z(c,G)$ with $N=3$.\nThe given parameters are:\n$$A = \\begin{pmatrix} 0.9  0 \\\\ 0  0.8 \\end{pmatrix}, \\ c_{0} = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}, \\ G_{0} = \\begin{pmatrix} 0.1  0 \\\\ 0  0.05 \\end{pmatrix}, \\ G_{w} = \\begin{pmatrix} 0.01  0 \\\\ 0  0.02 \\end{pmatrix}, \\ n = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\nFirst, we compute the powers of $A$:\n$$A^{2} = \\begin{pmatrix} 0.9^{2}  0 \\\\ 0  0.8^{2} \\end{pmatrix} = \\begin{pmatrix} 0.81  0 \\\\ 0  0.64 \\end{pmatrix}, \\ A^{3} = \\begin{pmatrix} 0.9^{3}  0 \\\\ 0  0.8^{3} \\end{pmatrix} = \\begin{pmatrix} 0.729  0 \\\\ 0  0.512 \\end{pmatrix}$$\nThe center of $X_{3}$ is:\n$$c = A^{3}c_{0} = \\begin{pmatrix} 0.729  0 \\\\ 0  0.512 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} = \\begin{pmatrix} 0.729 \\\\ 0.256 \\end{pmatrix}$$\nThe first term of the support function is $n^{\\top}c$:\n$$n^{\\top}c = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 0.729 \\\\ 0.256 \\end{pmatrix} = 0.729 + 0.256 = 0.985$$\nThe generator matrices are:\n$$A^{3}G_{0} = \\begin{pmatrix} 0.0729  0 \\\\ 0  0.0256 \\end{pmatrix}$$\n$$A^{2}G_{w} = \\begin{pmatrix} 0.0081  0 \\\\ 0  0.0128 \\end{pmatrix}$$\n$$AG_{w} = \\begin{pmatrix} 0.009  0 \\\\ 0  0.016 \\end{pmatrix}$$\n$$G_{w} = \\begin{pmatrix} 0.01  0 \\\\ 0  0.02 \\end{pmatrix}$$\nThe full generator matrix is $G = [A^{3}G_{0}, A^{2}G_{w}, AG_{w}, G_{w}]$, which has $8$ columns (generators). All entries are non-negative.\nThe term $\\sum |n^{\\top}g_{i}|$ is the sum of absolute values of $n^{\\top}g_{i}$ for all generators $g_{i}$. Since $n$ and all generators have non-negative components, $n^{\\top}g_{i} \\geq 0$ for all $i$. Thus, we sum $n^{\\top}g_{i}$ over all generators. This is equivalent to summing all entries in the matrix product $n^{\\top}G$. Alternatively, it is the sum of all elements in the matrix $G$.\nSum of entries in the first component: $0.0729+0+0.0081+0+0.009+0+0.01+0 = 0.1$\nSum of entries in the second component: $0+0.0256+0+0.0128+0+0.016+0+0.02 = 0.0744$\nThe total sum $\\sum |n^{\\top}g_{i}| = 0.1 + 0.0744 = 0.1744$.\nThe support function value is:\n$$h_{X_{3}}(n) = n^{\\top}c + \\sum |n^{\\top}g_{i}| = 0.985 + 0.1744 = 1.1594$$\n\n### Part 3: Justification and Safety Margin Calculation\n\nThe safety property requires that all reachable states $x_{3} \\in \\mathcal{R}_{3}$ satisfy the condition $n^{\\top}x_{3} \\leq h$. This is equivalent to verifying that the maximum value of $n^{\\top}x_{3}$ over the entire set $\\mathcal{R}_{3}$ does not exceed $h$. In terms of the support function, this condition is $h_{\\mathcal{R}_{3}}(n) \\leq h$.\n\nThe reachability analysis produced an over-approximate set $X_{3}$ such that $\\mathcal{R}_{3} \\subseteq X_{3}$. A fundamental property of the supremum operator is that if a set $C_{1}$ is a subset of another set $C_{2}$, then $\\sup_{x \\in C_{1}} f(x) \\leq \\sup_{x \\in C_{2}} f(x)$ for any function $f$. Applying this to the support function, we have:\n$$h_{\\mathcal{R}_{3}}(n) \\leq h_{X_{3}}(n)$$\nTherefore, if we verify the safety property on the over-approximation, i.e., if we show that $h_{X_{3}}(n) \\leq h$, it immediately implies $h_{\\mathcal{R}_{3}}(n) \\leq h$. This guarantees that the true system is safe. This demonstrates that using the over-approximate reachable set for safety verification is a sound (i.e., conservative) method.\n\nThe safety margin at $N=3$ is defined as $m = h - h_{X_{3}}(n)$. With the given threshold $h=1.2$ and the computed support function value $h_{X_{3}}(n) = 1.1594$, the margin is:\n$$m = 1.2 - 1.1594 = 0.0406$$\nSince $m > 0$, the safety property is verified for the horizon $N=3$.",
            "answer": "$$\\boxed{0.0406}$$"
        }
    ]
}