## 应用与跨学科连接

在前几章中，我们已经深入探讨了网络物理系统（CPS）[验证与确认](@entry_id:1133775)（VV）的核心理论与机制。本章旨在将这些理论付诸实践，展示VV如何在现代工程开发流程中扮演关键角色，并如何与其他学科交叉，以应对日益复杂的系统挑战。

我们将首先厘清VV与测试、[运行时监控](@entry_id:1131150)等相关概念在实践中的区别与联系。接着，我们将跟随“[V模型](@entry_id:1133661)”的步伐，考察VV活动如何贯穿于模型在环（MIL）、软件在环（SIL）和[硬件在环](@entry_id:1125914)（HIL）的整个开发生命周期，并探讨[功能样机接口](@entry_id:1125382)（FMI）标准在促进异构系统协同仿真中的作用。

此外，本章还将聚焦于前沿的验证技术，例如如何利用[控制屏障函数](@entry_id:177928)为系统提供数学上可证明的[安全保证](@entry_id:1131169)，以及如何通过“[证伪](@entry_id:260896)”（Falsification）技术主动寻找系统设计的缺陷。我们还将专门讨论当前VV面临的最大挑战之一：为基于学习的组件（LEC）建立信任。最后，我们将探讨VV在满足功能安全标准（如[ISO 26262](@entry_id:1126786)）和构建安全案例（Safety Case）中的核心作用，以及如何综合所有证据来做出最终的系统发布决策。通过这些丰富的案例，读者将深刻理解VV在确保系统安全、满足行业标准和支持最终发布决策中所扮演的不可或缺的角色。

### VV实践中的概念辨析

在工程实践中，验证（Verification）与确认（Validation）虽然紧密相关，但有着明确的分工，正确区分两者是开展有效VV活动的第一步。“我们是否正确地构建了系统？”，即检查系统或其模型是否符合其规格说明和设计要求。而确认则关注“我们是否构建了正确的系统？”，即评估模型或系统在多大程度上能够准确代表其在预期使用环境下的真实世界。

一个典型的例子是汽车制动系统的[数字孪生](@entry_id:171650)（Digital Twin）评估。假设一个数字孪生模型用于预测车辆在特定初始速度和路面条件下的制动距离。验证过程可能包括检查模型中的物理方程是否被正确编码，算法是否按预期实现，以及在理想化（例如，无风阻、恒定[摩擦系数](@entry_id:150354)）条件下，模型的输出是否与解析解一致。与此相对，确认过程则需要将模型的预测结果与真实世界的物理测试数据进行直接比较。例如，通过在试验场进行实车制动测试，测量得到实际的制动距离 $d_{\text{meas}}$，并将其与[数字孪生](@entry_id:171650)预测的距离 $d_{\text{pred}}$ 进行比较。两者之间的差异，可以用一个量化的偏差度量 $\Delta = |d_{\text{pred}} - d_{\text{meas}}|$ 来表示。这个将模型输出与物理世界测量结果进行比较的过程，正是确认的核心所在 。

确认过程的关键在于如何科学地量化模型的保真度（Fidelity），即模型与物理实体之间的“动态一致性”。这需要一套严谨的度量体系，而不仅仅是简单的误差计算。对于一个由[数字孪生](@entry_id:171650)驱动的CPS，其保真度评估可以从多个维度展开：

1.  **时域[能量范数](@entry_id:274966)度量**：在比较[数字孪生](@entry_id:171650)预测的输出信号 $\hat{y}[k]$ 与物理系统测量的信号 $y[k]$ 时，一个基础的度量是计算[误差信号](@entry_id:271594) $e[k] = \hat{y}[k] - y[k]$ 的能量。为了消除信号幅度的影响，通常使用归一化能量度量，如 $J_1 = \|e\|_{2}/\|y\|_{2}$，其中 $\|z\|_{2}$ 是信号的 $L_2$ 范数。在计算前，还需通过互[相关分析](@entry_id:265289)找到最佳的时间延迟 $\tau^\star$ 来对齐两个信号，以避免将模型的固有延迟误判为动态误差。

2.  **频域相[干性](@entry_id:900268)度量**：为了评估模型在不同频率下的响应保真度，可以使用幅值平方[相干函数](@entry_id:181521) $\gamma^2_{y\hat{y}}(\omega) = \frac{|S_{y\hat{y}}(\omega)|^2}{S_{yy}(\omega) S_{\hat{y}\hat{y}}(\omega)}$。该值介于 $0$ 和 $1$ 之间，其中 $S$ 代表信号的[功率谱密度](@entry_id:141002)或[互谱密度](@entry_id:195014)。一个高保真度的模型，在其有效工作频带内，相[干性](@entry_id:900268)应接近 $1$。

3.  **随机[残差分析](@entry_id:191495)**：如果模型中包含了对[测量噪声](@entry_id:275238)的随机模型（例如，[高斯白噪声](@entry_id:749762)），那么在理想状态下，经过状态估计器（如卡尔曼滤波器）处理后的“新息”（innovation），即测量值与预测值之差，其统计特性应与假设的噪声模型一致。通过对[新息序列](@entry_id:181232)进行白度测试（例如，检查其自相关函数是否在非零延迟下接近于零），可以验证模型对随机因素的捕捉是否准确。

4.  **鲁棒增益度量**：可以从输入 $u$ 到误差 $e$ 建立一个偏差动态模型 $G_e$。该模型的 $H_\infty$ 范数，即 $\sup_{\omega} \bar{\sigma}(G_{e}(j\omega))$，量化了在最坏情况下输入信号的能量被放大为误差能量的比例。一个较小的 $H_\infty$ 范数意味着模型对输入的变化具有鲁棒的保真度 。

除了验证与确认的区分，VV活动还存在不同的执行模式，服务于不同的保障目标：

*   **测试（Testing）**：执行有限的一组预设场景，收集经验性的通过/失败结果。测试无法提供系统在所有可能情况下的行为保证，但对于发现常见错误、评估性能和满足覆盖率指标非常有效。
*   **[运行时验证](@entry_id:1131151)（Runtime Verification）**：在系统实际运行时，附加一个“监视器”（Monitor）。该监视器持续观察系统的行为轨迹，并根据已观察到的有限前缀，判断系统是否已经确定性地违反或满足了某个给定的属性。如果当前信息不足以做出判断，监视器会返回“未知”状态。它提供的是针对单次运行的在线判断。
*   **离线验证（Offline Verification）**：通常在系统开发或分析阶段进行，不涉及系统实时运行。这包括对完整的、事后记录的日志进行属性检查，或者更强大地，对系统模型本身进行分析。模型检查（Model Checking）是离线验证的一种，它旨在通过穷举推理来提供一个[数学证明](@entry_id:137161)，证明模型在所有可能的行为下都满足某个属性，或者给出一个明确的反例（Counterexample）。

这些不同模式的VV活动并非相互排斥，而是在一个全面的保障策略中相辅相成。

### 开发生命周期中的VV：从MIL/SIL/HIL到协同仿真

在汽车、航空等行业的复杂CPS开发中，VV活动紧密集成在开发生命周期中，最经典的表示是“[V模型](@entry_id:1133661)”。这个模型强调了从需求定义、系统设计到单元实现，再到集成测试、系统测试和验收测试的对应关系。现代基于模型的设计（Model-Based Design, MBD）流程将这一思想具体化为模型在环（MIL）、软件在环（SIL）和[硬件在环](@entry_id:1125914)（HIL）仿真测试阶段。

*   **模型在环（MIL）**：在此阶段，控制器和被控对象（Plant）都以数学模型的形式存在于仿真环境中（如Simulink）。MIL的主要目标是验证控制算法的逻辑和功能正确性，而不关心其最终的软件或硬件实现细节。
*   **软件在环（SIL）**：在此阶段，控制器模型被自动[代码生成](@entry_id:747434)工具转换为C/C++代码，并被编译成可在开发主机上运行的二[进制](@entry_id:634389)文件。这个编译后的控制器软件与仍然在仿真环境中的被控对象模型进行交互。SIL的关[键价](@entry_id:201326)值在于，它能够暴露由[代码生成](@entry_id:747434)、[编译器优化](@entry_id:747548)、目标语言（如C语言）的数值精度（如单精度浮点数）和运行时库行为引入的系统性缺陷。这些缺陷在纯粹的MIL数学仿真中是无法被发现的。
*   **硬件在环（HIL）**：这是最接近真实物理系统的验证阶段。控制器软件被部署在最终的目标硬件（电子控制单元，ECU）上运行。这个ECU通过真实的I/O接口（如CAN总线、[ADC](@entry_id:200983)/DAC转换器）与一个能够实时模拟被控对象和环境的实时仿真器相连。HIL不仅包含了SIL所能发现的所有软件层面的问题，还能够暴露与目标硬件相关的特定问题，例如处理器时序、缓存行为、[中断延迟](@entry_id:750776)、I/O[量化误差](@entry_id:196306)以及[实时操作系统](@entry_id:754133)（RTOS）的[任务调度](@entry_id:268244)效应等 。

随着CPS变得日益复杂和模块化，系统通常由来自不同供应商、使用不同工具开发的多个子系统集成而成。例如，一个车辆的[数字孪生](@entry_id:171650)可能由一个高精度的发动机模型、一个独立的变速箱模型和一个控制器模型组成。如何让这些异构模型协同工作并进行有效的集成验证，成为一个巨大的挑战。

[功能样机接口](@entry_id:1125382)（Functional Mock-up Interface, FMI）标准正是为解决这一问题而生。FMI定义了一种开放标准，允许不同的仿真工具导出一个称为[功能样机单元](@entry_id:1125384)（Functional Mock-up Unit, FMU）的标准化模型组件。一个主控算法（Master Algorithm）可以加载这些FMUs，并将它们连接起来进行协同仿真。FMI标准主要包含两种模式：

1.  **模型交换（Model Exchange, ME）**：FMU仅暴露其状态方程（如 $\dot{x} = f(x, u, t)$），而不包含自身的数值求解器。主控算法负责收集所有ME-FMUs的方程，构成一个统一的全局[微分方程组](@entry_id:148215)，并使用一个中央求解器进行积分。
2.  **协同仿真（Co-simulation, CS）**：每个FMU都封装了自身的模型和求解器。主控算法负责协调各个FMU的时间推进，在离散的通信点上交换输入和输出数据。每个FMU在两个通信点之间独立进行积分。

在协同仿真中，一个关键的VV任务是检测并正确处理“[代数环](@entry_id:1120933)”（Algebraic Loops）。当[代数环](@entry_id:1120933)发生时，两个或多个FMU的输出在同一时刻相互依赖（即存在直接馈通，Direct Feedthrough），主控算法必须通过迭代计算来求解这个瞬时产生的[代数方程](@entry_id:272665)组，以确保在时间步推进之前，所有接口变量的值是一致和收敛的。对FMI中因果关系（Causality）和变量交换语义的正确理解与实现，是保证协同仿真结果有效性和可信度的基础 。

### 复杂行为的高级验证技术

对于具有复杂动态和严格安全要求的CPS，传统的测试方法往往不足以提供足够的信心。[形式化方法](@entry_id:1125241)（Formal Methods）提供了一套基于数学的技术，能够对系统的某些属性进行严格的证明。

#### 使用屏障函数的安全保证

[控制屏障函数](@entry_id:177928)（Control Barrier Functions, CBF）是一种强大的形式化验证技术，尤其适用于[证明系统](@entry_id:156272)的状态将始终保持在一个“安全集”内（即不变性证明）。我们可以通过一个自动驾驶车辆的自主车道保持[辅助系统](@entry_id:142219)来说明其应用。

假设车辆的侧向动力学被抽象为一个一维状态 $x(t)$，表示车辆中心[线与](@entry_id:177118)车道中心线的横向偏差。系统的动态可以表示为 $\dot{x}(t) = -k x(t) + d(t)$，其中 $-k x(t)$ 代表控制器提供的回正力，$d(t)$ 是有界的未知外部扰动（如侧风、路面倾斜），满足 $|d(t)| \le D$。安全要求是车辆必须始终保持在车道内，即 $|x(t)| \le L$，其中 $L$ 是车道边界。

为了证明这一安全属性，我们可以定义一个屏障函数 $h(x) = L^2 - x^2$。显然，安全集 $\mathcal{S}$ 等价于 $\{x \mid h(x) \ge 0\}$。为了保证从安全集内部出发的[系统轨迹](@entry_id:1132840)永远不会离开该集合（即[前向不变性](@entry_id:170094)），我们需要证明一个条件：在安[全集](@entry_id:264200)内的所有点上，屏障函数的时间导数 $\dot{h}(x)$ 满足 $\dot{h}(x) \ge -\gamma h(x)$，其中 $\gamma$ 是一个正常数。

通过链式法则，我们可以计算出 $\dot{h}(x) = 2kx^2 - 2xd(t)$。为了保证该条件在最坏情况下（即扰动 $d(t)$ 最大程度地试图将车辆推出安[全集](@entry_id:264200)时）仍然成立，我们可以求解出系统能够容忍的最大扰动幅值 $D_{\max}$。通过一系列推导，可以得到 $D_{\max} = L\sqrt{\gamma(2k-\gamma)}$。这个结果表明，只要实际环境中的扰动幅值不超过这个经过[数学证明](@entry_id:137161)的界限，系统就绝对安全。这种基于数字孪生模型的CBF分析，为系统的[安全验证](@entry_id:1131179)提供了强有力的形式化证据 。

#### 证伪：主动寻找反例

与力图[证明系统](@entry_id:156272)“总是安全”的形式化验证相反，证伪（Falsification）的目标是主动且高效地寻找导致系统违反其安全需求的“反例”（Counterexamples）。这在实践中同样具有极高的价值，因为一个具体的反例往往比抽象的证明更能帮助工程师理解和修复设计缺陷。

[证伪](@entry_id:260896)任务可以被巧妙地构建为一个优化问题。这需要我们将系统的需求用一种可量化的语言来描述，例如[信号时序逻辑](@entry_id:1131627)（Signal Temporal Logic, STL）。STL不仅可以表达“是/否”满足，还能计算一个称为“鲁棒性”（Robustness）的实数值 $\rho$。$\rho  0$ 表示[系统轨迹](@entry_id:1132840)满足需求，并且距离违反边界还有一定的裕度；$\rho  0$ 表示轨迹违反了需求；$\rho = 0$ 表示轨迹恰好在需求的边界上。

例如，对于一个“在时间区间 $[0, T]$ 内，输出 $y(t)$ 必须始终小于等于阈值 $\theta$”的需求（记为 $\varphi = \mathbf{G}_{[0,T]} (y(t) \le \theta)$），其鲁棒性可以定义为 $\rho_\varphi = \inf_{t \in [0,T]} (\theta - y(t))$。

证伪的目标就是寻找一个输入信号 $u(t)$，使得系统产生的轨迹对应的鲁棒性 $\rho_\varphi$ 为负数。这自然地导出了一个优化问题：
$$
\min_{u(\cdot)} \rho_\varphi(x(u))
$$
其中 $x(u)$ 是由输入 $u(\cdot)$ 决定的系统状态轨迹。如果能找到一个输入使最小化的鲁棒性值为负，我们就成功找到了一个反例。

由于系统动态（通常是[非线性](@entry_id:637147)的）和STL鲁棒性计算中的 $\min/\inf$ 算子（非光滑、非凸），这个优化问题通常很难求解。现代证伪工具采用两类先进的搜索策略：
1.  **基于梯度的搜索**：对于白盒模型，可以通过平滑化（例如，用softmax代替min）鲁棒性函数，然后利用伴随法（Adjoint Methods）或轨迹[敏感性分析](@entry_id:147555)来计算[目标函数](@entry_id:267263)相对于输入参数的梯度，从而使用梯度下降等方法进行[局部搜索](@entry_id:636449)。
2.  **随机/[启发式搜索](@entry_id:637758)**：对于黑盒模型或梯度难以计算的情况，可以采用无梯度[优化算法](@entry_id:147840)，如[交叉熵方法](@entry_id:748068)（CEM）或[协方差矩阵自适应演化策略](@entry_id:747405)（[CMA-ES](@entry_id:747405)）等。这些方法在输入参数空间中进行智能的[随机采样](@entry_id:175193)，逐步向更有可能产生低鲁棒性值的区域“进化”，直至找到一个反例 。

### 学习型组件（LEC）的VV

将人工智能，特别是基于学习的组件（Learning-Enabled Components, LECs），如深度神经网络，集成到安全关键的CPS中，是当前VV领域最紧迫的挑战之一。与传统控制算法不同，LECs的行为通常是不可解释的“黑箱”，其行为由大量数据训练而来，难以进行形式化分析。

为LECs建立VV策略的第一步是明确保障的**目标类型**。通常，对一个包含LEC的系统的需求可以分为两类：
*   **[功能安全](@entry_id:1125387)属性（Functional Safety Properties）**：这些是必须在所有可接受的操作条件下、对于所有允许的不确定性都必须满足的硬性约束。例如，“车辆与前车的距离永远不得小于安全阈值”或“系统状态必须始终保持在预定义的安[全集](@entry_id:264200) $S$ 内”。这类属性要求普遍性的保证（“for all”），因此是**验证**（Verification）的主要对象，通常需要[形式化方法](@entry_id:1125241)来提供数学证明。
*   **性能目标（Performance Objectives）**：这些是关于系统“做得有多好”的量化目标，通常以统计或平均意义定义。例如，“最小化期望的燃料消耗”或“在典型驾驶场景下，将[跟踪误差](@entry_id:273267)的[均方根值](@entry_id:276804)保持在一定水平以下”。这类目标与系统的预期用途和利益相关者的期望紧密相关，其满足程度通常通过在大量代表性场景中进行测试来评估。因此，性能目标是**确认**（Validation）的主要对象，需要经验证据来支撑 。

即使我们明确了验证目标，如何对一个神经网络控制器进行形式化验证仍然是一个难题。一个有前景的方法是分析其**鲁棒性**。具体而言，我们可以尝试为神经网络的行为建立数学上的界限。例如，通过计算神经网络的**李普希兹常数（Lipschitz Constant）**。

一个函数 $u = \mathrm{NN}(x)$ 的李普希兹常数 $K$ 是一个实数，它满足对于任意两个输入 $x_1$ 和 $x_2$，都有 $|u(x_1) - u(x_2)| \le K \|x_1 - x_2\|$。这个常数 $K$ 量化了函数输出对输入变化的最大敏感度。对于一个由多个线性层（权重矩阵）和[非线性激活函数](@entry_id:635291)（如ReLU, [tanh](@entry_id:636446)）组成的神经网络，其全局李普希兹常数可以通过逐层分析，将每层权重矩阵的[算子范数](@entry_id:752960)和[激活函数](@entry_id:141784)的李普希兹常数（例如，ReLU和[tanh](@entry_id:636446)的李普希兹常数都是1）相乘得到一个上界。

一旦我们为神经网络控制器计算出了一个可靠的李普希兹常数 $K$，我们就能获得一个非常有价值的鲁棒性保证：如果系统的状态估计存在一个有界的误差 $\|x_{\text{真实}} - x_{\text{估计}}\| \le \delta$，那么控制器输出的控制指令偏差也将是有界的，即 $|u(x_{\text{真实}}) - u(x_{\text{估计}})| \le K \delta$。这个有界的控制偏差可以被代入到整个闭环系统的动态分析中，从而使得我们能够像分析传统控制器一样，去验证整个CPS的稳定性和安全性。这种方法为打开神经网络的“黑箱”、提供形式化保证提供了一条可行的路径 。

### VV、合规性与安全案例

在汽车、医疗设备、航空等安全关键领域，VV活动不仅仅是为了提高产品质量，更是为了满足严格的行业法规和标准，并最终构建一个令人信服的论证来[证明系统](@entry_id:156272)的安全性。

#### [功能安全](@entry_id:1125387)标准与合规性

以汽车行业的功能安全标准[ISO 26262](@entry_id:1126786)为例，它为汽车电气/电子系统的整个生命周期（从概念阶段到报废）提供了一个完整的框架。对于软件开发（Part 6），[ISO 26262](@entry_id:1126786)根据风险的严重程度定义了[汽车安全](@entry_id:1121271)完整性等级（ASIL），从A（最低）到D（最高）。对于ASIL C和D等级的软件，标准要求极为严格的VV活动，并需要产出相应的“工作产品”（Work Products）作为证据。

一个符合[ISO 26262](@entry_id:1126786)高ASIL等级要求的软件安全生命周期，其核心VV产出包括：
*   **软件安全需求规范**：从系统级的技术安全需求中派生而来，并被赋予ASIL等级。
*   **软件架构设计**：必须明确组件、接口，并进行“免于干扰”（Freedom from Interference）分析，确保不同ASIL等级的软件组件之间不会产生负面影响。
*   **单元设计与实现**：必须遵循严格的编码规范（如MISRA C），并提供合规性证据。
*   **单元验证与集成测试**：需要达到ASIL等级所要求的结构覆盖率指标（例如，ASIL D要求MC/DC覆盖率）。所有测试结果，包括在[数字孪生](@entry_id:171650)环境中进行的测试，都必须被详细记录，并附上对仿真模型保真度和局限性的说明。
*   **可追溯性矩阵**：必须建立并维护从需求到架构、再到代码、再到测试用例的双向可追溯性，确保每个需求都得到了实现和验证。
*   **工具[置信度](@entry_id:267904)评估**：所有用于开发和验证的软件工具（如编译器、[静态分析](@entry_id:755368)器、[代码生成器](@entry_id:747435)）都必须根据其对安全的影响进行评估和（如果需要）“鉴定”（Qualification）。
*   **软件安全案例**：最终，所有这些证据将被汇总成一份结构化的[安全论证](@entry_id:1131170)，即安全案例，以证明软件已达到可接受的安全水平 。

#### 构建安全案例

安全案例（Safety Case）是一个结构化的、令人信服的论证，由一系列证据支撑，旨在说明一个系统在其预期应用中是可接受地安全的。目标结构符号（Goal Structuring Notation, GSN）是一种广泛用于可视化和组织安全案例论证逻辑的图形化语言。

在一个GSN结构中，顶层目标（Top-level Goal）是最终的安全声明（例如，“UGV的碰撞风险低于法规要求”）。这个目标通过一系列策略（Strategies）被分解为多个子目标（Sub-goals）。每个子目标又可以被进一步分解，直至最底层的目标可以直接由具体的证据——称为“解决方案”（Solutions）——来支持。

VV活动为安全案例提供了最核心的证据基础。例如：
*   一个子目标“控制器在标称环境下能维持安全距离”，其解决方案可以是由数字孪生模型上的**形式化验证报告**（如CBF分析结果）和**模型确认数据**（证明模型与物理世界的一致性）共同构成。通过论证（Justification），可以说明模型上的安全裕度在扣除模型与现实的偏差后，仍然满足要求。
*   另一个子目标“残余风险在可接受范围内”，其解决方案可以由**硬件[故障率](@entry_id:264373)分析报告**、**环境假设被违反的概率评估**等构成。
*   **统计测试证据**（如大规模蒙特卡洛仿真或路测结果）虽然本身可能不足以证明极低概率的安全目标，但可以作为强有力的辅助证据，增加对整个论证的信心 。

#### 定量证据与发布决策

所有VV活动最终都服务于一个根本性的工程决策：“这个系统是否足够安全，可以发布了？”。这需要一个将所有证据综合起来，进行量化评估和决策的框架。

一个先进的方法是结合贝叶斯统计推断和覆盖率度量来指导发布决策。假设安全目标是单次任务的失败概率 $p$ 必须低于 $\lambda^\star = 10^{-4}$。我们可以通过测试来收集证据。
1.  **证据融合与[贝叶斯更新](@entry_id:179010)**：我们可以将在[数字孪生](@entry_id:171650)中进行的大量仿真测试和在真实世界中进行的少量物理测试结合起来。通过一个“保真度因子” $f$ 来折算仿真测试的价值（例如，一次仿真测试等效于 $f$ 次真实测试），得到一个总的“有效测试次数” $n_{\text{eff}}$。基于这些测试结果（例如，观测到0次失败），我们可以使用贝叶斯推断来更新我们对失败概率 $p$ 的认知，得到其后验概率分布 $p \sim \mathrm{Beta}(a_n, b_n)$。
2.  **信心与覆盖率的结合**：有了后验分布，我们可以计算出我们对系统满足安全目标的信心，即 $P(p \le \lambda^\star \mid \text{data})$。然而，这个统计信心必须被我们的“证据完备性”所“折扣”。证据的完备性可以通过一系列覆盖率指标来衡量，例如：操作设计域（ODD）的场景覆盖率 $S$、代码的结构覆盖率 $C$、以及需求到测试的可追溯性 $T$。
3.  **决策阈值**：我们可以定义一个“联合证据充分性指数” $I = P(p \le \lambda^\star \mid \text{data}) \cdot S \cdot C \cdot T$。这个指数同时反映了我们对系统本身安全性的信心和对我们VV过程完备性的信心，可以与从可接受的残余风险 $\mathcal{R}^\star$ 导出的决策阈值 $\theta = 1 - \mathcal{R}^\star$ 进行比较。只有当 $I \ge \theta$ 并且后验分布的某个高可信度上界（如95%[可信区间](@entry_id:176433)[上界](@entry_id:274738)）也满足安全目标时，才做出发布的决定。

这个框架将统计学、[系统工程](@entry_id:180583)和风险管理思想融为一体，为高风险CPS的VV和发布决策提供了一个可操作的、数据驱动的路径 。

总之，从基础的[验证与确认](@entry_id:1133775)区分，到先进的形式化方法和对学习型组件的挑战，再到服务于法规遵从和最终发布决策的结构化论证，VV构成了构建可信CPS的基石。