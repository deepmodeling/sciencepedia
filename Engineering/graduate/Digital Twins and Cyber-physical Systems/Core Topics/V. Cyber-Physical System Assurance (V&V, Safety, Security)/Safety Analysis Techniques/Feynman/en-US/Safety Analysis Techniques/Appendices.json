{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of safety engineering is understanding how component failures combine to cause a system-level hazard. This practice challenges you to perform a qualitative Fault Tree Analysis (FTA) by deriving the Minimal Cut Sets (MCS) and Minimal Path Sets (MPS) for a cyber-physical system. Mastering this skill allows you to identify the specific combinations of events that lead to failure and pinpoint architectural vulnerabilities, a critical first step before any quantitative assessment. ",
            "id": "4242895",
            "problem": "A cyber-physical system with a Digital Twin is used to supervise an autonomous vehicle’s motion planning. The safety case requires demonstrating that the Digital Twin prevents hazardous miscontrol except when multiple barriers fail. Consider the safety analysis using Fault Tree Analysis (FTA), contrasted with other techniques such as Hazard Analysis and Risk Assessment (HARA), Failure Modes and Effects Analysis (FMEA), and Systems-Theoretic Process Analysis (STPA). The top failure event $T$ is “hazardous miscontrol escapes the Digital Twin’s safety envelope.” The fault tree has two levels of $\\land/\\lor$ gates and is defined over the basic failure events $A_{1}$, $A_{2}$, $B_{1}$, $B_{2}$, and $B_{3}$ as follows:\n$$\nT \\equiv (A_{1} \\land A_{2}) \\lor \\big((B_{1} \\lor B_{2}) \\land B_{3}\\big).\n$$\nInterpretation of basic failure events:\n- $A_{1}$: Digital Twin model mismatch not detected.\n- $A_{2}$: Sensor fusion miscalibration.\n- $B_{1}$: Anomaly detector false negative on trajectory instability.\n- $B_{2}$: Runtime monitor threshold mis-set under environmental drift.\n- $B_{3}$: Safety interlock actuator fails to engage.\n\nAll basic events are assumed mutually independent. Their probabilities over the mission interval are:\n- $\\mathbb{P}(A_{1}) = 2.0 \\times 10^{-3}$,\n- $\\mathbb{P}(A_{2}) = 5.0 \\times 10^{-4}$,\n- $\\mathbb{P}(B_{1}) = 1.5 \\times 10^{-3}$,\n- $\\mathbb{P}(B_{2}) = 1.0 \\times 10^{-3}$,\n- $\\mathbb{P}(B_{3}) = 4.0 \\times 10^{-4}$.\n\nTasks:\n- Using first principles of set-theoretic probability and Boolean logic, explain the concepts of minimal cut sets and minimal path sets, and derive them for the given fault tree without introducing any shortcut formulas.\n- Based on your derived minimal cut sets, compute the exact value of $\\mathbb{P}(T)$ using only foundational rules (such as De Morgan’s laws and inclusion–exclusion), maintaining all constants symbolically until the final numerical evaluation.\n- Briefly discuss qualitative vulnerability insights implied by the structure of the minimal cut sets and minimal path sets (no numerical output required for this part).\n\nAnswer specification:\n- Express the final answer as the exact probability of the top failure event $T$ evaluated numerically and rounded to four significant figures.\n- Express the final probability as a decimal fraction using scientific notation $a \\times 10^{b}$ with $1 \\leq |a| < 10$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of Fault Tree Analysis (FTA), a standard safety and reliability engineering methodology. It is well-posed, with a clear logical definition of the top failure event, specified probabilities for all basic events, and a stated assumption of mutual independence. The problem is objective, formally specified, and admits a unique, verifiable solution. We may therefore proceed with the solution.\n\nThe analysis is structured into three parts as requested: derivation of minimal cut sets and minimal path sets, computation of the top event probability, and a qualitative discussion of system vulnerabilities.\n\n### 1. Minimal Cut Sets (MCS) and Minimal Path Sets (MPS)\n\nWe begin with formal definitions based on set theory and Boolean logic. A fault tree represents a logical function $\\phi(x_1, ..., x_n)$ where the output is $1$ (failure) if the top event $T$ occurs, and $0$ (success) otherwise. The inputs $x_i$ represent the state of basic events, where $x_i=1$ if basic event $E_i$ occurs and $x_i=0$ if it does not.\n\nA **cut set** is a set of basic events whose concurrent occurrence causes the top event to occur. A **minimal cut set (MCS)** is a cut set such that, if any basic event is removed from the set, it is no longer a cut set. In Boolean terms, an MCS corresponds to a prime implicant of the structure function $\\phi$, representing a minimal conjunction of basic events that implies the top event.\n\nA **path set** is a set of basic events whose concurrent non-occurrence ensures the top event does not occur. A **minimal path set (MPS)** is a path set such that, if any basic event is removed from the set, it is no longer a path set. In Boolean terms, an MPS corresponds to a prime implicant of the dual (or success) function $\\bar{\\phi}$, representing a minimal conjunction of non-failing components (negated basic events) that implies system success (negation of the top event).\n\nThe given logical structure for the top event $T$ is:\n$$T \\equiv (A_{1} \\land A_{2}) \\lor \\big((B_{1} \\lor B_{2}) \\land B_{3}\\big)$$\n\n**Derivation of Minimal Cut Sets (MCS):**\nTo find the MCS, we expand the Boolean expression into a disjunctive normal form (a sum of products), where each product term represents a cut set. We then eliminate any non-minimal sets.\n\nApplying the distributive law $X \\land (Y \\lor Z) \\equiv (X \\land Y) \\lor (X \\land Z)$ to the second term:\n$$(B_{1} \\lor B_{2}) \\land B_{3} \\equiv (B_{1} \\land B_{3}) \\lor (B_{2} \\land B_{3})$$\nSubstituting this back into the expression for $T$:\n$$T \\equiv (A_{1} \\land A_{2}) \\lor (B_{1} \\land B_{3}) \\lor (B_{2} \\land B_{3})$$\nThis expression is a disjunction of three conjunctions. Each conjunction represents a cut set:\n- Cut Set 1: $\\{A_{1}, A_{2}\\}$\n- Cut Set 2: $\\{B_{1}, B_{3}\\}$\n- Cut Set 3: $\\{B_{2}, B_{3}\\}$\n\nTo confirm they are minimal, we check if any set is a superset of another. No set contains another. For instance, $\\{A_{1}, A_{2}\\}$ is not a superset of $\\{B_{1}, B_{3}\\}$ or $\\{B_{2}, B_{3}\\}$, and vice versa. Each set is also internally minimal, as removing any event from any set would invalidate the corresponding conjunction.\nThus, the minimal cut sets are $\\{A_{1}, A_{2}\\}$, $\\{B_{1}, B_{3}\\}$, and $\\{B_{2}, B_{3}\\}$.\n\n**Derivation of Minimal Path Sets (MPS):**\nTo find the MPS, we first find the Boolean expression for the non-occurrence of $T$, denoted $\\bar{T}$, by applying De Morgan's laws. The MPS correspond to the prime implicants of this new expression. Let $\\bar{E}$ denote the non-occurrence of event $E$.\n$$\\bar{T} \\equiv \\neg T \\equiv \\neg \\Big( (A_{1} \\land A_{2}) \\lor \\big((B_{1} \\lor B_{2}) \\land B_{3}\\big) \\Big)$$\nApplying De Morgan's law $\\neg(X \\lor Y) \\equiv \\neg X \\land \\neg Y$:\n$$\\bar{T} \\equiv \\neg(A_{1} \\land A_{2}) \\land \\neg\\big((B_{1} \\lor B_{2}) \\land B_{3}\\big)$$\nApplying De Morgan's laws again, $\\neg(X \\land Y) \\equiv \\neg X \\lor \\neg Y$ and $\\neg(X \\lor Y) \\equiv \\neg X \\land \\neg Y$:\n$$\\bar{T} \\equiv (\\neg A_{1} \\lor \\neg A_{2}) \\land \\big(\\neg(B_{1} \\lor B_{2}) \\lor \\neg B_{3}\\big)$$\n$$\\bar{T} \\equiv (\\bar{A}_{1} \\lor \\bar{A}_{2}) \\land ((\\bar{B}_{1} \\land \\bar{B}_{2}) \\lor \\bar{B}_{3})$$\nTo obtain a sum-of-products form for $\\bar{T}$, we apply the distributive law $(X \\lor Y) \\land (Z \\lor W) \\equiv (X \\land Z) \\lor (X \\land W) \\lor (Y \\land Z) \\lor (Y \\land W)$:\n$$\\bar{T} \\equiv (\\bar{A}_{1} \\land (\\bar{B}_{1} \\land \\bar{B}_{2})) \\lor (\\bar{A}_{1} \\land \\bar{B}_{3}) \\lor (\\bar{A}_{2} \\land (\\bar{B}_{1} \\land \\bar{B}_{2})) \\lor (\\bar{A}_{2} \\land \\bar{B}_{3})$$\nThis gives the following path sets:\n- Path Set 1: $\\{\\bar{A}_{1}, \\bar{B}_{1}, \\bar{B}_{2}\\}$\n- Path Set 2: $\\{\\bar{A}_{1}, \\bar{B}_{3}\\}$\n- Path Set 3: $\\{\\bar{A}_{2}, \\bar{B}_{1}, \\bar{B}_{2}\\}$\n- Path Set 4: $\\{\\bar{A}_{2}, \\bar{B}_{3}\\}$\nNo set is a superset of another. Therefore, these are the minimal path sets.\n\n### 2. Computation of $\\mathbb{P}(T)$\n\nWe compute the exact probability of the top event, $\\mathbb{P}(T)$, using the principle of inclusion-exclusion and the mutual independence of all basic events. It is most direct to work from the original structure of $T$. Let $I_1 = A_1 \\land A_2$ and $I_2 = (B_1 \\lor B_2) \\land B_3$. Then $T = I_1 \\lor I_2$.\nThe probability of a union is given by:\n$$\\mathbb{P}(T) = \\mathbb{P}(I_1 \\lor I_2) = \\mathbb{P}(I_1) + \\mathbb{P}(I_2) - \\mathbb{P}(I_1 \\land I_2)$$\nThe event $I_1$ depends only on the set of basic events $\\{A_1, A_2\\}$, while $I_2$ depends only on $\\{B_1, B_2, B_3\\}$. Since all basic events are mutually independent, the events $I_1$ and $I_2$ are independent. Therefore, $\\mathbb{P}(I_1 \\land I_2) = \\mathbb{P}(I_1) \\mathbb{P}(I_2)$.\nThe formula simplifies to:\n$$\\mathbb{P}(T) = \\mathbb{P}(I_1) + \\mathbb{P}(I_2) - \\mathbb{P}(I_1)\\mathbb{P}(I_2)$$\nLet us denote the probabilities of the basic events as $p_{A1} = \\mathbb{P}(A_1)$, $p_{A2} = \\mathbb{P}(A_2)$, and so on.\n\nFirst, we calculate $\\mathbb{P}(I_1)$:\n$$\\mathbb{P}(I_1) = \\mathbb{P}(A_1 \\land A_2) = p_{A1} p_{A2} \\quad (\\text{due to independence})$$\nNext, we calculate $\\mathbb{P}(I_2)$:\n$$\\mathbb{P}(I_2) = \\mathbb{P}((B_1 \\lor B_2) \\land B_3)$$\nSince $B_3$ is independent of $B_1$ and $B_2$, it is independent of the event $(B_1 \\lor B_2)$.\n$$\\mathbb{P}(I_2) = \\mathbb{P}(B_1 \\lor B_2) \\mathbb{P}(B_3)$$\nThe probability $\\mathbb{P}(B_1 \\lor B_2)$ is given by the inclusion-exclusion principle:\n$$\\mathbb{P}(B_1 \\lor B_2) = \\mathbb{P}(B_1) + \\mathbb{P}(B_2) - \\mathbb{P}(B_1 \\land B_2) = p_{B1} + p_{B2} - p_{B1}p_{B2}$$\nSubstituting this back, we get:\n$$\\mathbb{P}(I_2) = (p_{B1} + p_{B2} - p_{B1}p_{B2}) p_{B3}$$\nNow, we substitute the numeric values:\n$p_{A1} = 2.0 \\times 10^{-3}$, $p_{A2} = 5.0 \\times 10^{-4}$, $p_{B1} = 1.5 \\times 10^{-3}$, $p_{B2} = 1.0 \\times 10^{-3}$, $p_{B3} = 4.0 \\times 10^{-4}$.\n\nCalculating $\\mathbb{P}(I_1)$:\n$$\\mathbb{P}(I_1) = (2.0 \\times 10^{-3}) \\times (5.0 \\times 10^{-4}) = 10.0 \\times 10^{-7} = 1.0 \\times 10^{-6}$$\nCalculating $\\mathbb{P}(I_2)$:\n$$p_{B1} + p_{B2} = 1.5 \\times 10^{-3} + 1.0 \\times 10^{-3} = 2.5 \\times 10^{-3}$$\n$$p_{B1}p_{B2} = (1.5 \\times 10^{-3}) \\times (1.0 \\times 10^{-3}) = 1.5 \\times 10^{-6}$$\n$$\\mathbb{P}(B_1 \\lor B_2) = 2.5 \\times 10^{-3} - 1.5 \\times 10^{-6} = 0.0025 - 0.0000015 = 0.0024985 = 2.4985 \\times 10^{-3}$$\n$$\\mathbb{P}(I_2) = (2.4985 \\times 10^{-3}) \\times (4.0 \\times 10^{-4}) = 9.994 \\times 10^{-7}$$\nFinally, we calculate $\\mathbb{P}(T)$:\n$$\\mathbb{P}(T) = \\mathbb{P}(I_1) + \\mathbb{P}(I_2) - \\mathbb{P}(I_1)\\mathbb{P}(I_2)$$\n$$\\mathbb{P}(T) = (1.0 \\times 10^{-6}) + (9.994 \\times 10^{-7}) - (1.0 \\times 10^{-6})(9.994 \\times 10^{-7})$$\n$$\\mathbb{P}(T) = 1.0 \\times 10^{-6} + 0.9994 \\times 10^{-6} - 9.994 \\times 10^{-13}$$\n$$\\mathbb{P}(T) = 1.9994 \\times 10^{-6} - 0.0000009994 \\times 10^{-6}$$\n$$\\mathbb{P}(T) = 1.9993990006 \\times 10^{-6}$$\nRounding to four significant figures, we get $1.999 \\times 10^{-6}$.\n\n### 3. Qualitative Vulnerability Insights\n\nThe minimal cut sets (MCS) and minimal path sets (MPS) provide profound insights into the system's vulnerabilities and safety assurance paths without requiring numerical calculation.\n\n- **MCS Insights ($\\{A_{1}, A_{2}\\}$, $\\{B_{1}, B_{3}\\}$, $\\{B_{2}, B_{3}\\}$)**:\n  The MCSs identify the smallest combinations of failures leading to hazardous miscontrol. All MCSs are of order $2$, which means there are no single-point failures for the top event; at least two independent failures are required. This indicates a baseline level of fault tolerance.\n  The event $B_{3}$ (\"Safety interlock actuator fails\") is a critical vulnerability. It is present in two of the three MCSs, making it a common cause of failure across different scenarios. Its failure renders the system vulnerable to a single additional failure in either of the runtime monitoring subsystems ($B_1$ or $B_2$). Consequently, the reliability and integrity of the actuator are paramount for system safety.\n  The system has two distinct macro-vulnerabilities: one related to the Digital Twin's perception and modeling ($A_1, A_2$) and another related to the runtime monitoring and actuation ($B_1, B_2, B_3$).\n\n- **MPS Insights ($\\{\\bar{A}_{1}, \\bar{B}_{3}\\}$, $\\{\\bar{A}_{2}, \\bar{B}_{3}\\}$, $\\{\\bar{A}_{1}, \\bar{B}_{1}, \\bar{B}_{2}\\}$, $\\{\\bar{A}_{2}, \\bar{B}_{1}, \\bar{B}_{2}\\}$)**:\n  The MPSs reveal the minimal conditions for guaranteed safety. The presence of two short path sets of order $2$, $\\{\\bar{A}_{1}, \\bar{B}_{3}\\}$ and $\\{\\bar{A}_{2}, \\bar{B}_{3}\\}$, again emphasizes the importance of component $B_3$. If the safety interlock actuator is guaranteed to work ($\\bar{B}_{3}$), system safety is assured provided at least one of the core Digital Twin functions (model matching or sensor fusion) is also working correctly.\n  Conversely, if component $B_3$ fails, safety is no longer guaranteed by any single component's success. In this case, safety relies on the remaining path structures: safety is maintained only if $(\\bar{A}_1 \\lor \\bar{A}_2)$ AND $(\\bar{B}_1 \\land \\bar{B}_2)$ are true. This means that upon actuator failure, safety depends on BOTH anomaly detectors working correctly in conjunction with at least one primary DT function.\n  Collectively, the MCS and MPS structures unequivocally identify the safety interlock actuator ($B_3$) as the most critical component in this safety architecture.",
            "answer": "$$\n\\boxed{1.999 \\times 10^{-6}}\n$$"
        },
        {
            "introduction": "After identifying failure pathways, the next step is to quantify the likelihood of the top hazardous event. This exercise moves from qualitative to quantitative analysis, tasking you with deriving the failure probability of a simple fault tree gate from the fundamental axioms of probability. This first-principles approach solidifies your understanding of the mathematical underpinnings of FTA and the critical role of independence assumptions in modeling complex cyber-physical systems. ",
            "id": "4242877",
            "problem": "A cyber-physical production cell is supervised by a Digital Twin (DT) that continuously simulates and verifies actuator behaviors against physical measurements. During deceleration of a robotic arm, the system enforces a safety interlock to prevent excessive torque. A Fault Tree Analysis (FTA) is constructed for the top event \"safety interlock fails to engage on a demand.\" Two basic events are identified: $E_1$ is \"physical brake actuator fails on demand\" and $E_2$ is \"DT anomaly detection falsely classifies the state as safe and suppresses interlock.\" Both $E_1$ and $E_2$ are modeled as Bernoulli events per demand with probabilities $p_1$ and $p_2$, respectively. The gate between $\\{E_1, E_2\\}$ and the top event is an OR gate. Engineers have established, via Hazard Analysis and Risk Assessment (HARA), Failure Modes and Effects Analysis (FMEA), and System-Theoretic Process Analysis (STPA), that $E_1$ and $E_2$ have no shared causal mechanisms within the mission timeframe, operate on separated hardware and software stacks, and are conditioned on the same demand without cross-coupling, justifying independence for the per-demand modeling of $E_1$ and $E_2$.\n\nUsing only the Kolmogorov axioms of probability, the set-theoretic correspondence between logical disjunction and event union, the definition of independence, and the law of inclusion-exclusion for two events derived from first principles, derive the closed-form analytic expression for the top event probability $P$ in terms of $p_1$ and $p_2$. Explicitly justify why modeling the OR gate as a union of independent events permits the use of the product term $P(E_1 \\cap E_2) = P(E_1) P(E_2)$ in this cyber-physical context. Express your final answer as a single closed-form analytic expression in terms of $p_1$ and $p_2$. No numerical rounding is required, and no units should be included with your final expression.",
            "solution": "The problem statement is deemed valid. It is scientifically grounded in probability theory and reliability engineering, well-posed with a unique and meaningful solution, and objective in its language. All necessary information is provided, the conditions are consistent, and the problem asks for a formal derivation from first principles, which is a substantive task.\n\nThe objective is to derive the probability, denoted by $P$, of the top event in a Fault Tree Analysis (FTA). This top event, $T$, is the \"safety interlock fails to engage on a demand.\"\n\nThe problem specifies that the top event $T$ is the result of an OR gate connecting two basic events: $E_1$, \"physical brake actuator fails on demand,\" and $E_2$, \"DT anomaly detection falsely classifies the state as safe and suppresses interlock.\" In the set-theoretic framework of probability, a logical OR gate corresponds to the union of events. Therefore, the top event is formally expressed as the union $T = E_1 \\cup E_2$. Our goal is to find its probability, $P = P(T) = P(E_1 \\cup E_2)$.\n\nThe probabilities of the basic events are given as $P(E_1) = p_1$ and $P(E_2) = p_2$.\n\nThe derivation must be founded upon the Kolmogorov axioms of probability. The axiom of finite additivity states that for any two mutually exclusive (disjoint) events $A$ and $B$, where $A \\cap B = \\emptyset$, the probability of their union is the sum of their individual probabilities: $P(A \\cup B) = P(A) + P(B)$.\n\nTo derive the general formula for the probability of a union of two (not necessarily disjoint) events, we employ a partitioning strategy. The event $E_1 \\cup E_2$ can be expressed as the union of two disjoint events: the event $E_1$ and the event that $E_2$ occurs but $E_1$ does not, which is denoted by $E_2 \\setminus E_1$ or, equivalently, $E_2 \\cap E_1^c$.\nThus, we can write the union as $E_1 \\cup E_2 = E_1 \\cup (E_2 \\cap E_1^c)$.\nBecause the sets $E_1$ and $(E_2 \\cap E_1^c)$ are disjoint by construction, we can apply the additivity axiom:\n$$P(E_1 \\cup E_2) = P(E_1) + P(E_2 \\cap E_1^c)$$\nTo find an expression for $P(E_2 \\cap E_1^c)$, we consider the event $E_2$. The event $E_2$ can be partitioned into two disjoint subsets: the part of $E_2$ that is also in $E_1$ (their intersection, $E_1 \\cap E_2$) and the part of $E_2$ that is not in $E_1$ (the set difference, $E_2 \\cap E_1^c$).\nThis partition is $E_2 = (E_1 \\cap E_2) \\cup (E_2 \\cap E_1^c)$.\nApplying the additivity axiom to this disjoint union yields:\n$$P(E_2) = P(E_1 \\cap E_2) + P(E_2 \\cap E_1^c)$$\nBy rearranging this equation, we can express $P(E_2 \\cap E_1^c)$ as:\n$$P(E_2 \\cap E_1^c) = P(E_2) - P(E_1 \\cap E_2)$$\nSubstituting this result back into the expression for $P(E_1 \\cup E_2)$ provides the general law of inclusion-exclusion for two events:\n$$P(E_1 \\cup E_2) = P(E_1) + P(E_2) - P(E_1 \\cap E_2)$$\nThis formula is derived directly from the axioms of probability.\n\nThe next step requires evaluating the intersection term, $P(E_1 \\cap E_2)$. The problem states that events $E_1$ and $E_2$ are independent. By definition, two events are independent if and only if the probability of their joint occurrence (their intersection) is the product of their individual probabilities:\n$$P(E_1 \\cap E_2) = P(E_1) P(E_2)$$\nThe problem requires an explicit justification for this step within the given cyber-physical context. The engineering rationale for assuming independence is provided in the problem statement itself. The events are asserted to be independent because comprehensive safety analyses (HARA, FMEA, STPA) have established that they have \"no shared causal mechanisms.\" Event $E_1$ is a failure of a physical component (the brake actuator), while event $E_2$ is an error in a supervisory software system (the Digital Twin's anomaly detection). The crucial detail is that these systems \"operate on separated hardware and software stacks.\" This physical and logical separation is the formal engineering basis for modeling them as probabilistically independent, as it precludes common-cause failures (e.g., a single power supply fault, a shared network failure, or a single software bug) from affecting both events simultaneously. Thus, the use of the product rule is a well-justified step in this model.\n\nWe now combine these pieces to find the final expression for $P$. Substituting the given probabilities $P(E_1) = p_1$ and $P(E_2) = p_2$, and applying the rule for independence, we get:\n$$P(E_1 \\cap E_2) = p_1 p_2$$\nSubstituting this into the inclusion-exclusion formula:\n$$P = P(E_1 \\cup E_2) = P(E_1) + P(E_2) - P(E_1 \\cap E_2)$$\n$$P = p_1 + p_2 - p_1 p_2$$\nThis is the closed-form analytic expression for the probability of the top event, derived from first principles as required.",
            "answer": "$$\\boxed{p_1 + p_2 - p_1 p_2}$$"
        },
        {
            "introduction": "Ultimately, safety analysis must inform decision-making about where to allocate resources for mitigation. This practice focuses on the critical task of risk prioritization, moving beyond traditional Failure Modes and Effects Analysis (FMEA). You will critically evaluate the classic Risk Priority Number (RPN) and apply a more robust, principled metric using multi-criteria decision analysis, a technique that is essential for leveraging the rich quantitative data provided by Digital Twins. ",
            "id": "4242931",
            "problem": "A cyber-physical system in an automated warehouse uses a Digital Twin to continuously estimate hazard attributes for Failure Modes and Effects Analysis (FMEA). For three representative hazards, the Digital Twin provides the following quantitative estimates: severity as expected consequence magnitude $s_i$ (in consistent units), occurrence probability per operating month $p_i$, and pre-harm detection coverage probability $q_i$; and the engineering team also provides traditional FMEA ordinal ratings $S_i$ (severity class), $O_i$ (occurrence class), and $D_i$ (detection class). The hazards are:\n- Hazard $H_A$: $s_A = 1.5\\times 10^6$, $p_A = 0.0015$, $q_A = 0.3$, $S_A = 9$, $O_A = 3$, $D_A = 7$.\n- Hazard $H_B$: $s_B = 2.0\\times 10^5$, $p_B = 0.0200$, $q_B = 0.7$, $S_B = 5$, $O_B = 6$, $D_B = 4$.\n- Hazard $H_C$: $s_C = 8.0\\times 10^6$, $p_C = 0.0002$, $q_C = 0.1$, $S_C = 10$, $O_C = 2$, $D_C = 8$.\n\nFrom first principles in safety analysis and decision theory, recall that risk prioritization is a ranking problem grounded in monotonic preference with respect to severity and likelihood, and that ordinal classes require transformation to an interval scale before arithmetic operations are meaningful. In the multi-criteria setting, attributes should be normalized to a common scale and combined with weights that reflect stakeholder preferences. Detection should be treated as risk reduction: higher $q_i$ implies lower residual risk.\n\nSelect the option that best satisfies all of the following:\n1) Correctly defines the Risk Priority Number (RPN) used in Failure Modes and Effects Analysis (FMEA), and articulates at least two rigorous limitations of RPN in the context of cyber-physical systems with Digital Twin data.\n2) Proposes a principled alternative prioritization metric using multi-criteria weighting with normalization that respects scale types and the orientation of detection (i.e., higher $q_i$ should decrease risk), and specifies a concrete, reproducible normalization procedure and weight vector.\n3) Applies the proposed metric to $H_A$, $H_B$, and $H_C$ using min-max normalization over the given set and weights $w_S = 0.5$, $w_O = 0.3$, $w_D = 0.2$, yielding an explicit prioritization order among $H_A$, $H_B$, and $H_C$.\n\nOptions:\n\nA) Defines RPN as the product $S\\cdot O\\cdot D$; identifies limitations: multiplication of ordinal classes is not invariant under monotone re-labeling, different hazard profiles can yield identical products, and RPN omits stakeholder weights and cross-hazard normalization; proposes the alternative score $R_i = w_S\\,\\tilde{s}_i + w_O\\,\\tilde{p}_i + w_D\\,\\tilde{u}_i$ with min-max normalization $\\tilde{s}_i = (s_i - s_{\\min})/(s_{\\max} - s_{\\min})$, $\\tilde{p}_i = (p_i - p_{\\min})/(p_{\\max} - p_{\\min})$, and $\\tilde{u}_i = (u_i - u_{\\min})/(u_{\\max} - u_{\\min})$ where $u_i = 1 - q_i$, and weights $w_S = 0.5$, $w_O = 0.3$, $w_D = 0.2$; applies this to the data to obtain the prioritization $H_C \\succ H_B \\succ H_A$.\n\nB) Defines RPN as the sum $S + O + D$; notes that RPN can be “coarse” but claims summation is acceptable on ordinal scales; proposes the alternative score $R_i = w_S\\,S_i + w_O\\,O_i + w_D\\,D_i$ with the same weights but without normalization; applies this to the data to obtain $H_B \\succ H_A \\succ H_C$.\n\nC) Defines RPN as $S\\cdot O\\cdot D$; notes that RPN ignores units and uses arbitrary class boundaries; proposes the alternative score $R_i = s_i \\cdot p_i \\cdot (1 - q_i)$ (expected loss) without any normalization or explicit weights; applies this to the data to obtain $H_A \\succ H_C \\succ H_B$.\n\nD) Defines RPN as $S\\cdot O\\cdot D$; argues that multiplicative aggregation is desirable; proposes a normalized geometric mean $R_i = \\sqrt[3]{\\tilde{s}_i\\,\\tilde{p}_i\\,\\tilde{q}_i}$ with min-max normalization of $s_i$, $p_i$, and $q_i$ (using $\\tilde{q}_i$ increasing in $q_i$); applies this to the data to obtain $H_B \\succ H_A \\succ H_C$.",
            "solution": "The user has provided a problem statement regarding risk prioritization for a cyber-physical system, requiring the evaluation of several options based on three criteria related to Failure Modes and Effects Analysis (FMEA) and multi-criteria decision analysis.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n- **Hazards & Data:**\n  - Hazard $H_A$: $s_A = 1.5\\times 10^6$, $p_A = 0.0015$, $q_A = 0.3$, $S_A = 9$, $O_A = 3$, $D_A = 7$.\n  - Hazard $H_B$: $s_B = 2.0\\times 10^5$, $p_B = 0.0200$, $q_B = 0.7$, $S_B = 5$, $O_B = 6$, $D_B = 4$.\n  - Hazard $H_C$: $s_C = 8.0\\times 10^6$, $p_C = 0.0002$, $q_C = 0.1$, $S_C = 10$, $O_C = 2$, $D_C = 8$.\n- **Variable Definitions:**\n  - $s_i$: quantitative severity (expected consequence magnitude).\n  - $p_i$: quantitative occurrence probability per month.\n  - $q_i$: quantitative pre-harm detection coverage probability.\n  - $S_i$: ordinal severity class.\n  - $O_i$: ordinal occurrence class.\n  - $D_i$: ordinal detection class.\n- **Theoretical Principles:**\n  - Ordinal classes require transformation to an interval scale for arithmetic.\n  - Multi-criteria analysis requires normalization and weighting.\n  - Higher detection probability $q_i$ implies lower risk.\n- **Task Requirements:** Select the option that:\n  1. Correctly defines RPN and lists at least two rigorous limitations.\n  2. Proposes a principled multi-criteria weighted metric with a specific normalization procedure (min-max) and weights.\n  3. Correctly applies this metric with weights $w_S = 0.5$, $w_O = 0.3$, $w_D = 0.2$ to rank the hazards.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the established fields of safety engineering, risk analysis, and multi-criteria decision theory. The concepts of FMEA, RPN, measurement scales (ordinal, ratio), normalization, and weighted sums are standard. The problem is well-posed, providing all necessary data and clear, objective criteria for evaluating the options. It is not incomplete, contradictory, or based on false premises. The scenario of using a Digital Twin to generate quantitative data to improve upon traditional FMEA is a relevant and modern engineering problem.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the solution by evaluating each option against the three specified criteria.\n\n### **Solution Derivation**\n\nThe core of the problem is to identify the option that correctly describes the standard Risk Priority Number (RPN), its flaws, and proposes and applies a methodologically sound alternative based on multi-criteria decision analysis (MCDA).\n\n**Criterion 1: RPN Definition and Limitations**\nThe standard definition of the Risk Priority Number (RPN) in FMEA is the product of the ordinal ratings for Severity ($S$), Occurrence ($O$), and Detection ($D$):\n$$RPN = S \\cdot O \\cdot D$$\nKey limitations of this approach include:\n1.  **Mathematical Incorrectness**: The multiplication of ordinal numbers is not a meaningful mathematical operation. Ordinal scales only define rank order, not magnitude of difference or ratio. The result is not invariant under monotonic rescaling of the $S$, $O$, or $D$ scales.\n2.  **Ambiguity**: Different combinations of $S, O, D$ can produce the same RPN, obscuring the underlying risk profile (e.g., a high-severity, low-probability event may have the same RPN as a low-severity, high-probability event).\n3.  **Implicit Equal Weighting**: RPN gives equal importance to $S$, $O$, and $D$, which may not reflect stakeholder preferences or the true nature of the risk. A proper MCDA framework allows for explicit weighting.\n\n**Criterion 2: Principled Alternative Metric**\nA principled alternative, as outlined in the problem, should use the quantitative data ($s_i$, $p_i$, $q_i$), which are on ratio scales and thus suitable for arithmetic. The metric should follow MCDA principles:\n1.  **Attribute Transformation**: Detection probability ($q_i$) is inversely related to risk. A suitable risk attribute is non-detection probability, $u_i = 1 - q_i$.\n2.  **Normalization**: To combine attributes with different units and scales (like consequence magnitude $s_i$ and probability $p_i$), they must be normalized to a common, dimensionless scale. Min-max normalization is a standard method to scale values to the range $[0, 1]$:\n    $$\\tilde{x}_i = \\frac{x_i - x_{\\min}}{x_{\\max} - x_{\\min}}$$\n3.  **Aggregation**: A weighted linear sum is a common and transparent way to combine the normalized attributes according to specified preferences (weights):\n    $$R_i = w_S\\,\\tilde{s}_i + w_O\\,\\tilde{p}_i + w_D\\,\\tilde{u}_i$$\n    where $w_S, w_O, w_D$ are the weights for severity, occurrence, and non-detection, respectively.\n\n**Criterion 3: Application of the Metric**\nThe proposed metric must be applied to the given data using the specified weights $w_S = 0.5$, $w_O = 0.3$, $w_D = 0.2$.\n\nFirst, we calculate the non-detection probabilities $u_i = 1 - q_i$:\n- $u_A = 1 - 0.3 = 0.7$\n- $u_B = 1 - 0.7 = 0.3$\n- $u_C = 1 - 0.1 = 0.9$\n\nNext, we find the min and max for each attribute to perform normalization:\n- For severity $s_i$: $s_{\\min} = s_B = 2.0\\times 10^5$, $s_{\\max} = s_C = 8.0\\times 10^6$. The range is $7.8\\times 10^6$.\n- For occurrence $p_i$: $p_{\\min} = p_C = 0.0002$, $p_{\\max} = p_B = 0.0200$. The range is $0.0198$.\n- For non-detection $u_i$: $u_{\\min} = u_B = 0.3$, $u_{\\max} = u_C = 0.9$. The range is $0.6$.\n\nNow, we calculate the normalized values ($\\tilde{s}_i, \\tilde{p}_i, \\tilde{u}_i$):\n- $\\tilde{s}_A = \\frac{1.5\\times 10^6 - 2.0\\times 10^5}{8.0\\times 10^6 - 2.0\\times 10^5} = \\frac{1.3\\times 10^6}{7.8\\times 10^6} = \\frac{1}{6}$\n- $\\tilde{s}_B = \\frac{2.0\\times 10^5 - 2.0\\times 10^5}{7.8\\times 10^6} = 0$\n- $\\tilde{s}_C = \\frac{8.0\\times 10^6 - 2.0\\times 10^5}{7.8\\times 10^6} = 1$\n\n- $\\tilde{p}_A = \\frac{0.0015 - 0.0002}{0.0200 - 0.0002} = \\frac{0.0013}{0.0198} \\approx 0.06566$\n- $\\tilde{p}_B = \\frac{0.0200 - 0.0002}{0.0198} = 1$\n- $\\tilde{p}_C = \\frac{0.0002 - 0.0002}{0.0198} = 0$\n\n- $\\tilde{u}_A = \\frac{0.7 - 0.3}{0.9 - 0.3} = \\frac{0.4}{0.6} = \\frac{2}{3}$\n- $\\tilde{u}_B = \\frac{0.3 - 0.3}{0.6} = 0$\n- $\\tilde{u}_C = \\frac{0.9 - 0.3}{0.6} = 1$\n\nFinally, we calculate the risk score $R_i$ for each hazard using $R_i = 0.5\\,\\tilde{s}_i + 0.3\\,\\tilde{p}_i + 0.2\\,\\tilde{u}_i$:\n- $R_A = 0.5 \\left(\\frac{1}{6}\\right) + 0.3 \\left(\\frac{0.0013}{0.0198}\\right) + 0.2 \\left(\\frac{2}{3}\\right) \\approx 0.08333 + 0.3(0.06566) + 0.13333 \\approx 0.08333 + 0.01970 + 0.13333 \\approx 0.2364$\n- $R_B = 0.5(0) + 0.3(1) + 0.2(0) = 0.3$\n- $R_C = 0.5(1) + 0.3(0) + 0.2(1) = 0.5 + 0.2 = 0.7$\n\nComparing the scores: $R_C = 0.7 > R_B = 0.3 > R_A \\approx 0.236$.\nThe prioritization order is $H_C \\succ H_B \\succ H_A$.\n\n### **Option-by-Option Analysis**\n\n**A) Defines RPN as the product $S\\cdot O\\cdot D$; identifies limitations: multiplication of ordinal classes is not invariant under monotone re-labeling, different hazard profiles can yield identical products, and RPN omits stakeholder weights and cross-hazard normalization; proposes the alternative score $R_i = w_S\\,\\tilde{s}_i + w_O\\,\\tilde{p}_i + w_D\\,\\tilde{u}_i$ with min-max normalization $\\tilde{s}_i = (s_i - s_{\\min})/(s_{\\max} - s_{\\min})$, $\\tilde{p}_i = (p_i - p_{\\min})/(p_{\\max} - p_{\\min})$, and $\\tilde{u}_i = (u_i - u_{\\min})/(u_{\\max} - u_{\\min})$ where $u_i = 1 - q_i$, and weights $w_S = 0.5$, $w_O = 0.3$, $w_D = 0.2$; applies this to the data to obtain the prioritization $H_C \\succ H_B \\succ H_A$.**\n- **Criterion 1**: The RPN definition is correct, and the listed limitations are rigorous and accurate. **Correct**.\n- **Criterion 2**: The proposed alternative metric is a weighted linear sum of normalized quantitative variables, correctly transforming detection probability ($q_i$) into a risk-increasing attribute ($u_i=1-q_i$). The normalization and weighting procedures are explicitly and correctly defined. **Correct**.\n- **Criterion 3**: The application yields the prioritization $H_C \\succ H_B \\succ H_A$, which matches our derivation. **Correct**.\nThis option correctly satisfies all three criteria.\n\n**B) Defines RPN as the sum $S + O + D$; notes that RPN can be “coarse” but claims summation is acceptable on ordinal scales; proposes the alternative score $R_i = w_S\\,S_i + w_O\\,O_i + w_D\\,D_i$ with the same weights but without normalization; applies this to the data to obtain $H_B \\succ H_A \\succ H_C$.**\n- **Criterion 1**: The definition of RPN as a sum is incorrect. The claim that summation is acceptable on ordinal scales is mathematically false. **Incorrect**.\n- **Criterion 2**: Proposing a weighted sum of raw ordinal scores is methodologically flawed, violating the principle that arithmetic on ordinal scales is not meaningful and ignoring the superior quantitative data. **Incorrect**.\n- **Criterion 3**: The application is based on a flawed metric. **Incorrect**.\n\n**C) Defines RPN as $S\\cdot O\\cdot D$; notes that RPN ignores units and uses arbitrary class boundaries; proposes the alternative score $R_i = s_i \\cdot p_i \\cdot (1 - q_i)$ (expected loss) without any normalization or explicit weights; applies this to the data to obtain $H_A \\succ H_C \\succ H_B$.**\n- **Criterion 1**: The RPN definition is correct, and the limitations are valid. **Correct**.\n- **Criterion 2**: The proposed metric is the expected loss, which is a valid risk measure. However, it is not a *multi-criteria weighted model with normalization* as specified by the problem's requirements for the alternative metric. It explicitly omits normalization and weights. **Incorrect**.\n- **Criterion 3**: Although the calculation for the proposed expected loss formula is correct ($1575, 1200, 1440 \\rightarrow H_A \\succ H_C \\succ H_B$), the metric itself does not satisfy the problem's constraints. **Incorrect**.\n\n**D) Defines RPN as $S\\cdot O\\cdot D$; argues that multiplicative aggregation is desirable; proposes a normalized geometric mean $R_i = \\sqrt[3]{\\tilde{s}_i\\,\\tilde{p}_i\\,\\tilde{q}_i}$ with min-max normalization of $s_i$, $p_i$, and $q_i$ (using $\\tilde{q}_i$ increasing in $q_i$); applies this to the data to obtain $H_B \\succ H_A \\succ H_C$.**\n- **Criterion 1**: The RPN definition is correct, but the option fails to articulate limitations, instead defending an aspect of the method. **Incorrect**.\n- **Criterion 2**: The proposed metric incorrectly handles detection; by using $\\tilde{q}_i$ (which increases with detection probability $q_i$) in a product, the risk score would incorrectly increase with better detection. It also fails to incorporate the specified weights. **Incorrect**.\n- **Criterion 3**: The application is based on a flawed metric, and the resulting prioritization is wrong. For instance, the normalized values for $H_B$ and $H_C$ include zeros, making their risk scores zero and thus indistinguishable. **Incorrect**.\n\nBased on this analysis, only option A satisfies all requirements laid out in the problem statement.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}