{
    "hands_on_practices": [
        {
            "introduction": "Ensuring the authenticity of components is a critical first line of defense in supply chain security. Since exhaustive testing of every component in a large shipment is often impractical or, in the case of destructive testing, impossible, we must rely on statistical methods. This practice demonstrates how to construct a statistically sound inspection policy based on random sampling, allowing you to guarantee a desired level of confidence in detecting counterfeit-laden lots, even when the exact lot size is unknown .",
            "id": "4248776",
            "problem": "A manufacturer of Cyber-Physical Systems (CPS) components integrates a Digital Twin of its supply chain that recommends a statistically principled incoming inspection policy for counterfeit detection. Each incoming lot has an unknown population size $N$ and an unknown number $M$ of counterfeit units, but operational threat intelligence guarantees that the counterfeit proportion is at least $\\pi \\in (0,1)$, that is $M/N \\ge \\pi$. Inspection uses destructive testing, so units are sampled uniformly at random without replacement and each tested unit is destroyed. The test is assumed to be perfect (no false positives and no false negatives). The goal is to choose a lot-independent sample size $n$ such that, for any lot with counterfeit proportion at least $\\pi$, the probability that at least one counterfeit is detected in the sample is at least $1-\\alpha$, where $\\alpha \\in (0,1)$ is a specified risk tolerance.\n\nStarting only from the definitions of probability, sampling without replacement, and the complement event rule, construct a probabilistic model for the event of “no counterfeit found” under random sampling without replacement, and derive a closed-form sufficient condition on $n$ (independent of $N$) that guarantees the desired detection confidence. Compute the smallest integer $n$ meeting this condition, expressed in closed form as a function of $\\pi$ and $\\alpha$. No numerical substitution is required, and no rounding is needed. The final answer must be a single analytic expression.",
            "solution": "The problem requires the determination of a minimum sample size $n$ for inspecting a lot of components to detect counterfeits with a certain statistical confidence. The derivation must start from first principles.\n\nFirst, we validate the problem statement.\n### Step 1: Extract Givens\n- Lot population size: $N$, unknown.\n- Number of counterfeit units in the lot: $M$, unknown.\n- Minimum counterfeit proportion: $\\frac{M}{N} \\ge \\pi$, where $\\pi \\in (0,1)$.\n- Sampling method: Uniformly at random without replacement.\n- Sample size: $n$, to be determined, must be independent of $N$.\n- Test accuracy: Perfect, meaning no false positives or false negatives.\n- Desired detection probability: The probability of detecting at least one counterfeit must be at least $1-\\alpha$.\n- Risk tolerance: $\\alpha \\in (0,1)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, being a standard application of statistical acceptance sampling based on the hypergeometric distribution. It is well-posed, as the inputs $\\pi$ and $\\alpha$ are sufficient to determine a unique minimum integer sample size $n$ under the specified constraints. The problem statement is objective and uses precise, formal language. It is self-contained, consistent, and free of the flaws listed in the validation criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. We may proceed with the solution.\n\nLet $A$ be the event that at least one counterfeit unit is detected in a sample of size $n$. The problem requires that the probability of this event, $P(A)$, satisfies the condition $P(A) \\ge 1-\\alpha$.\n\nWe use the complement rule, which states that $P(A) = 1 - P(A^c)$, where $A^c$ is the complement event that no counterfeit units are detected in the sample. Substituting this into the inequality gives:\n$$1 - P(A^c) \\ge 1 - \\alpha$$\nSubtracting $1$ from both sides and multiplying by $-1$ (which reverses the inequality) yields the condition on the probability of non-detection:\n$$P(A^c) \\le \\alpha$$\n\nNext, we construct the probabilistic model for the event $A^c$ under sampling without replacement. The total number of ways to choose a sample of size $n$ from a population of $N$ units is given by the binomial coefficient $\\binom{N}{n}$.\nThe number of non-counterfeit units in the lot is $N-M$. The event $A^c$ occurs if and only if all $n$ units in the sample are drawn from these $N-M$ non-counterfeit units. The number of ways to do this is $\\binom{N-M}{n}$.\nThe probability of $A^c$ is the ratio of these two quantities, which is the probability mass function of a hypergeometric distribution:\n$$P(A^c) = \\frac{\\binom{N-M}{n}}{\\binom{N}{n}}$$\nThis model is valid as long as $n \\le N-M$. If $n > N-M$, at least one counterfeit must be sampled, so $P(A^c)=0$, which trivially satisfies $P(A^c) \\le \\alpha$. We thus proceed assuming $n \\le N-M$.\n\nExpanding the binomial coefficients:\n$$P(A^c) = \\frac{\\frac{(N-M)!}{n!(N-M-n)!}}{\\frac{N!}{n!(N-n)!}} = \\frac{(N-M)! (N-n)!}{N! (N-M-n)!}$$\nThis can be written as a product of $n$ terms:\n$$P(A^c) = \\frac{N-M}{N} \\times \\frac{N-M-1}{N-1} \\times \\cdots \\times \\frac{N-M-n+1}{N-n+1} = \\prod_{i=0}^{n-1} \\frac{N-M-i}{N-i}$$\n\nTo find a sample size $n$ that is independent of the unknown population size $N$, we must find an upper bound for $P(A^c)$ that does not depend on $N$. Let's analyze a single term in the product:\n$$\\frac{N-M-i}{N-i} = 1 - \\frac{M}{N-i}$$\nFor any given $i$ in the range $0 \\le i \\le n-1$, we have $N-i \\le N$. Since $M > 0$, this implies $\\frac{1}{N-i} \\ge \\frac{1}{N}$, and thus $\\frac{M}{N-i} \\ge \\frac{M}{N}$.\nTherefore, for each term in the product:\n$$1 - \\frac{M}{N-i} \\le 1 - \\frac{M}{N}$$\nLet $p = M/N$ be the true, unknown proportion of counterfeits in the lot. The inequality becomes:\n$$\\frac{N-M-i}{N-i} \\le 1-p$$\nSince this holds for every term in the product for $P(A^c)$, we can establish an upper bound for $P(A^c)$:\n$$P(A^c) = \\prod_{i=0}^{n-1} \\frac{N-M-i}{N-i} \\le \\prod_{i=0}^{n-1} (1-p) = (1-p)^n$$\nThis inequality shows that the probability of failing to detect a counterfeit is at most the probability that would be calculated for sampling *with* replacement, a result which allows us to remove the dependency on $N$.\n\nThe problem states that operational intelligence guarantees the counterfeit proportion is at least $\\pi$, i.e., $p = M/N \\ge \\pi$.\nSince $p \\ge \\pi$ and both are in $(0,1)$, it follows that $1-p \\le 1-\\pi$. Raising both sides to the power of $n$ (where $n$ is a positive integer) preserves the inequality:\n$$(1-p)^n \\le (1-\\pi)^n$$\n\nCombining our inequalities, we have a complete upper bound for $P(A^c)$ that depends only on the known parameters $\\pi$ and $\\alpha$:\n$$P(A^c) \\le (1-p)^n \\le (1-\\pi)^n$$\nTo guarantee that our desired condition $P(A^c) \\le \\alpha$ is met, it is sufficient to choose a sample size $n$ such that this upper bound is no greater than $\\alpha$:\n$$(1-\\pi)^n \\le \\alpha$$\nThis is the closed-form sufficient condition on $n$ that is independent of $N$.\n\nTo find the smallest integer $n$ that satisfies this condition, we solve the inequality for $n$. Since $\\pi \\in (0,1)$ and $\\alpha \\in (0,1)$, we have $0 < 1-\\pi < 1$ and $0 < \\alpha < 1$. We can take the natural logarithm of both sides:\n$$\\ln((1-\\pi)^n) \\le \\ln(\\alpha)$$\n$$n \\ln(1-\\pi) \\le \\ln(\\alpha)$$\nSince $0 < 1-\\pi < 1$, its logarithm $\\ln(1-\\pi)$ is a negative number. Dividing the inequality by this negative number requires reversing the direction of the inequality sign:\n$$n \\ge \\frac{\\ln(\\alpha)}{\\ln(1-\\pi)}$$\n\nThe problem asks for the smallest integer $n$ that meets this condition. This is given by the ceiling function applied to the right-hand side of the inequality.\n$$n_{\\min} = \\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(1-\\pi)} \\right\\rceil$$\nThis expression provides the smallest integer sample size $n$ that guarantees a detection probability of at least $1-\\alpha$ for any lot with a counterfeit proportion of at least $\\pi$, regardless of the total lot size $N$.",
            "answer": "$$ \\boxed{\\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(1-\\pi)} \\right\\rceil} $$"
        },
        {
            "introduction": "Beyond physical components, the software that powers cyber-physical systems represents a vast and complex attack surface, often composed of numerous third-party dependencies. With limited resources for security audits, a critical task is to allocate your budget effectively to achieve the greatest possible risk reduction. This exercise frames the challenge as a classic resource allocation problem, guiding you through the formulation of a cost-minimal audit strategy that meets a specific security target by prioritizing audits based on their cost-effectiveness .",
            "id": "4248734",
            "problem": "A manufacturer of Cyber-Physical Systems (CPS) operates a Digital Twin that continuously quantifies supply chain security risk across a set of software and hardware dependencies. For each dependency $i \\in \\{1,2,3,4,5,6\\}$, the Digital Twin estimates an expected annual risk contribution $r_i$ (in million United States dollars), and an audit effectiveness $a_i \\in [0,1]$ that represents the fraction of the risk that is removed if the dependency is audited. Auditing dependency $i$ incurs a monetary audit cost $c_i$ (in kilo-United States dollars).\n\nAssume additive expected loss under independence of failure modes across dependencies. If a dependency $i$ is audited, its residual risk contribution becomes $(1 - a_i) r_i$, and if it is not audited, its residual risk remains $r_i$. The total residual expected annual risk across all dependencies must be reduced below a threshold $\\epsilon$ (in million United States dollars).\n\nGiven the following parameters:\n- $r_1 = 2.5$, $r_2 = 1.8$, $r_3 = 3.0$, $r_4 = 0.9$, $r_5 = 2.2$, $r_6 = 1.6$,\n- $a_1 = 0.6$, $a_2 = 0.4$, $a_3 = 0.5$, $a_4 = 0.7$, $a_5 = 0.3$, $a_6 = 0.8$,\n- $c_1 = 120$, $c_2 = 80$, $c_3 = 140$, $c_4 = 60$, $c_5 = 100$, $c_6 = 130$,\n- $\\epsilon = 6.5$,\n\nFormulate from first principles a cost-minimization selection of audits so that the Digital Twin’s modeled residual expected annual risk is strictly less than $\\epsilon$. Treat each audit decision as binary. Compute the minimal total audit cost (in kilo-United States dollars) that achieves the threshold. Express your final answer as an exact integer number of kilo-United States dollars with no rounding. Also identify which dependencies are audited in your reasoning, but report only the minimal total audit cost in your final numeric answer.",
            "solution": "The problem is to determine the minimum total cost of audits required to reduce the total residual expected annual risk to a value strictly less than a given threshold. This is a classic optimization problem that can be modeled as a variation of the 0/1 knapsack problem.\n\nFirst, let us formalize the problem. Let $i \\in \\{1, 2, 3, 4, 5, 6\\}$ be the index for each dependency. We introduce a set of binary decision variables, $x_i$, for each dependency:\n$$\nx_i = \\begin{cases} 1 & \\text{if dependency } i \\text{ is audited} \\\\ 0 & \\text{if dependency } i \\text{ is not audited} \\end{cases}\n$$\nThe total cost of the audits, $C_{total}$, is the sum of the costs of the selected audits. This is the objective function we want to minimize:\n$$\n\\text{Minimize } C_{total} = \\sum_{i=1}^{6} c_i x_i\n$$\nwhere $c_i$ is the cost of auditing dependency $i$.\n\nThe total initial risk, without any audits, is the sum of the individual risk contributions:\n$$\nR_{initial} = \\sum_{i=1}^{6} r_i\n$$\nThe risk contribution of dependency $i$ after a decision is made is $r_i$ if not audited ($x_i=0$) and $(1-a_i)r_i$ if audited ($x_i=1$). This can be written as $r_i - x_i a_i r_i$. The total residual risk, $R_{final}$, is the sum of these contributions over all dependencies:\n$$\nR_{final} = \\sum_{i=1}^{6} (r_i - x_i a_i r_i) = \\left(\\sum_{i=1}^{6} r_i\\right) - \\left(\\sum_{i=1}^{6} x_i a_i r_i\\right) = R_{initial} - \\sum_{i=1}^{6} x_i a_i r_i\n$$\nThe problem states the constraint that the total residual risk must be strictly less than the threshold $\\epsilon$:\n$$\nR_{final} < \\epsilon\n$$\nSubstituting the expression for $R_{final}$:\n$$\nR_{initial} - \\sum_{i=1}^{6} x_i a_i r_i < \\epsilon\n$$\nRearranging this inequality, we find the constraint on the total risk reduction. Let $\\Delta R_{total} = \\sum_{i=1}^{6} x_i a_i r_i$ be the total risk reduction achieved by the selected audits. The constraint is:\n$$\n\\Delta R_{total} > R_{initial} - \\epsilon\n$$\nLet's calculate the numerical values for the initial risk and the required reduction. The risk values $r_i$ and the threshold $\\epsilon$ are in millions of USD.\n$r = [2.5, 1.8, 3.0, 0.9, 2.2, 1.6]$\n$$\nR_{initial} = 2.5 + 1.8 + 3.0 + 0.9 + 2.2 + 1.6 = 12.0 \\text{ million USD}\n$$\nGiven $\\epsilon = 6.5$ million USD, the required total risk reduction is:\n$$\n\\Delta R_{required} > 12.0 - 6.5 = 5.5 \\text{ million USD}\n$$\nThe problem is to choose a set of audits (values of $x_i$) that minimizes the total cost $\\sum c_i x_i$ while satisfying $\\sum x_i a_i r_i > 5.5$. This is a 0/1 knapsack-type problem where we want to select items (audits) to achieve a minimum total \"value\" (risk reduction) for the minimum total \"weight\" (cost).\n\nA common and effective heuristic for such problems is a greedy algorithm based on cost-effectiveness. We define the efficiency, $e_i$, of each audit as the ratio of the risk reduction it provides, $\\Delta r_i = a_i r_i$, to its cost, $c_i$.\n$$\ne_i = \\frac{\\Delta r_i}{c_i} = \\frac{a_i r_i}{c_i}\n$$\nWe will calculate $\\Delta r_i$ (in million USD), $c_i$ (in kilo-USD), and $e_i$ (in units of $1000 \\frac{\\text{USD risk reduction}}{\\text{USD cost}}$) for each dependency.\n\n| Dependency $i$ | $r_i$ (M USD) | $a_i$ | $\\Delta r_i = a_i r_i$ (M USD) | $c_i$ (k USD) | $e_i = \\frac{\\Delta r_i}{c_i}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $1$ | $2.5$ | $0.6$ | $1.50$ | $120$ | $0.01250$ |\n| $2$ | $1.8$ | $0.4$ | $0.72$ | $80$  | $0.00900$ |\n| $3$ | $3.0$ | $0.5$ | $1.50$ | $140$ | $\\approx 0.01071$ |\n| $4$ | $0.9$ | $0.7$ | $0.63$ | $60$  | $0.01050$ |\n| $5$ | $2.2$ | $0.3$ | $0.66$ | $100$ | $0.00660$ |\n| $6$ | $1.6$ | $0.8$ | $1.28$ | $130$ | $\\approx 0.00985$ |\n\nNext, we sort the dependencies in descending order of their efficiency $e_i$:\n$e_1 > e_3 > e_4 > e_6 > e_2 > e_5$.\nThe selection order is therefore: $1, 3, 4, 6, 2, 5$.\n\nWe now apply the greedy algorithm, selecting audits in this order until the cumulative risk reduction exceeds $5.5$ million USD.\n\n1.  **Select audit 1**:\n    *   Cumulative cost: $C = c_1 = 120$.\n    *   Cumulative risk reduction: $\\Delta R = \\Delta r_1 = 1.50$.\n    *   $1.50 \\ngtr 5.5$. We must continue.\n\n2.  **Select audit 3**:\n    *   Cumulative cost: $C = 120 + c_3 = 120 + 140 = 260$.\n    *   Cumulative risk reduction: $\\Delta R = 1.50 + \\Delta r_3 = 1.50 + 1.50 = 3.00$.\n    *   $3.00 \\ngtr 5.5$. We must continue.\n\n3.  **Select audit 4**:\n    *   Cumulative cost: $C = 260 + c_4 = 260 + 60 = 320$.\n    *   Cumulative risk reduction: $\\Delta R = 3.00 + \\Delta r_4 = 3.00 + 0.63 = 3.63$.\n    *   $3.63 \\ngtr 5.5$. We must continue.\n\n4.  **Select audit 6**:\n    *   Cumulative cost: $C = 320 + c_6 = 320 + 130 = 450$.\n    *   Cumulative risk reduction: $\\Delta R = 3.63 + \\Delta r_6 = 3.63 + 1.28 = 4.91$.\n    *   $4.91 \\ngtr 5.5$. We must continue.\n\n5.  **Select audit 2**:\n    *   Cumulative cost: $C = 450 + c_2 = 450 + 80 = 530$.\n    *   Cumulative risk reduction: $\\Delta R = 4.91 + \\Delta r_2 = 4.91 + 0.72 = 5.63$.\n    *   $5.63 > 5.5$. The condition is now satisfied.\n\nThe set of selected audits is $\\{1, 2, 3, 4, 6\\}$. The minimal total audit cost found by this method is $530$ kilo-USD. The total risk reduction achieved is $5.63$ million USD.\nLet's verify the final risk:\n$R_{final} = R_{initial} - \\Delta R_{total} = 12.0 - 5.63 = 6.37$ million USD.\nThe condition $R_{final} < \\epsilon$ is $6.37 < 6.5$, which is true.\n\nWhile the greedy algorithm is a heuristic for the 0/1 knapsack problem and not guaranteed to be optimal in general, we can verify its optimality for this small problem. The sum of all possible risk reductions is $\\sum \\Delta r_i = 6.29$ million USD. If we omit the most efficient audit (audit 1, reduction $1.50$), the maximum possible reduction from the remaining audits is $6.29 - 1.50 = 4.79$ million USD, which is less than the required reduction of $5.5$. Therefore, audit 1 must be part of any valid solution, and thus must be in the optimal solution. A similar analysis shows that audits 3 and 6 are also mandatory. Proceeding with this logic confirms that the greedy selection is indeed optimal for this specific set of parameters.\n\nThe set of dependencies to be audited is $\\{1, 2, 3, 4, 6\\}$. The minimal total audit cost is the sum of their individual costs:\n$$\nC_{minimal} = c_1 + c_2 + c_3 + c_4 + c_6 = 120 + 80 + 140 + 60 + 130 = 530\n$$\nThe cost is in kilo-United States dollars.",
            "answer": "$$\\boxed{530}$$"
        },
        {
            "introduction": "An effective security posture is not just about prevention; it is also about resilience—the ability to recover quickly and predictably from an incident. When a supply chain compromise is detected, the speed of recovery is a paramount concern that directly impacts operational availability and safety. This problem delves into modeling the incident response process, specifically calculating the Mean Time To Recovery (MTTR) by incorporating factors like rollback procedures, the risk of deploying a \"false good\" version, and the latency of detection, providing a quantitative metric to evaluate and improve system resilience .",
            "id": "4248769",
            "problem": "A cyber-physical manufacturing cell operates under a digital twin (DT) that orchestrates incident response for both firmware and software when a supply chain compromise is suspected. The DT maintains an ordered set of prior releases deemed \"known-good\" by Software Bill of Materials (SBOM) attestation, code-signing provenance checks, and hardware root-of-trust validation. However, due to residual supply chain risk (for example, stealthy signing-key compromise or undetected dependency poisoning), some versions that pass pre-deployment verification may still be compromised. The DT can roll back to earlier versions and repeat verification until a truly clean version is deployed.\n\nModel the following response loop, starting at the moment the DT initiates the first rollback, and ending at the first time a clean version is stably deployed (this interval defines the Mean Time To Recovery (MTTR)):\n\n- Each rollback attempt begins with a deterministic verification phase of duration $t$ (including SBOM validation, signature and provenance checks, and compatibility checks). Assume $t$ is measured in hours.\n- Conditional on passing verification, the attempt produces a truly clean deployment with probability $s \\in (0,1)$ and produces a latent false good with probability $1-s$. A false good is a build that passes verification yet remains compromised.\n- Latent compromises are detected post-deployment by continuous runtime attestation and anomaly detection; model the detection latency by an independent exponential random variable $X$ with rate $\\lambda$ (per hour), i.e., $X \\sim \\text{Exp}(\\lambda)$. On detection, the DT immediately initiates another rollback attempt. Assume successive attempts are independent and identically distributed and that detection latencies across false goods are independent and identically distributed, independent of the number of attempts.\n\nUnder these assumptions, define the random variable $\\text{MTTR}$ as the total elapsed time from the start of the first rollback verification until the first clean deployment. Derive a closed-form analytic expression for $\\mathbb{E}[\\text{MTTR}]$ as a function of $s$, $t$, and $\\lambda$. Express the answer in hours. Do not include units inside the final boxed answer.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to derive a unique, meaningful solution. We may proceed with the derivation.\n\nLet the random variable $T$ represent the Mean Time To Recovery ($\\text{MTTR}$), which is the total time from the start of the first rollback attempt until a clean version is stably deployed. We are asked to find the expected value of $T$, denoted as $\\mathbb{E}[T]$.\n\nThe process consists of a sequence of independent and identically distributed rollback attempts. We can find $\\mathbb{E}[T]$ by conditioning on the outcome of the first attempt and applying the law of total expectation.\n\nLet $S_1$ be the event that the first rollback attempt results in a truly clean deployment.\nLet $F_1$ be the event that the first rollback attempt results in a latent false good.\n\nAccording to the problem statement:\n- The probability of success on any given attempt is $P(S_1) = s$.\n- The probability of failure on any given attempt is $P(F_1) = 1-s$.\n\nThe law of total expectation for $T$ is:\n$$\n\\mathbb{E}[T] = \\mathbb{E}[T|S_1] P(S_1) + \\mathbb{E}[T|F_1] P(F_1)\n$$\n\nWe must now determine the conditional expectations $\\mathbb{E}[T|S_1]$ and $\\mathbb{E}[T|F_1]$.\n\n1.  If the first attempt is successful (event $S_1$), the process involves only the fixed verification phase of duration $t$. After this phase, the process terminates. Therefore, the total time elapsed is exactly $t$.\n    $$\n    \\mathbb{E}[T|S_1] = t\n    $$\n\n2.  If the first attempt fails (event $F_1$), the total time is the sum of three components:\n    - The fixed verification time, $t$.\n    - The random detection latency for the latent compromise, $X$, where $X \\sim \\text{Exp}(\\lambda)$.\n    - The expected time to recover from the point after the compromise is detected. When the compromise is detected, the system state is identical to the initial state (i.e., it must initiate a new rollback attempt). Because the attempts are independent and identically distributed, the expected additional time required to recover from this point is, by definition, $\\mathbb{E}[T]$.\n\n    Thus, the conditional expectation given failure is:\n    $$\n    \\mathbb{E}[T|F_1] = t + \\mathbb{E}[X] + \\mathbb{E}[T]\n    $$\n    The expected value of an exponential random variable $X$ with rate $\\lambda$ is $\\mathbb{E}[X] = \\frac{1}{\\lambda}$. Substituting this gives:\n    $$\n    \\mathbb{E}[T|F_1] = t + \\frac{1}{\\lambda} + \\mathbb{E}[T]\n    $$\n\nNow we substitute these components back into the law of total expectation equation:\n$$\n\\mathbb{E}[T] = (t) \\cdot s + \\left(t + \\frac{1}{\\lambda} + \\mathbb{E}[T]\\right) \\cdot (1-s)\n$$\n\nThis is an algebraic equation for $\\mathbb{E}[T]$. We now solve for $\\mathbb{E}[T]$.\n$$\n\\mathbb{E}[T] = st + (1-s)t + \\frac{1-s}{\\lambda} + (1-s)\\mathbb{E}[T]\n$$\nCombine the terms containing $t$:\n$$\n\\mathbb{E}[T] = t(s + 1-s) + \\frac{1-s}{\\lambda} + (1-s)\\mathbb{E}[T]\n$$\n$$\n\\mathbb{E}[T] = t + \\frac{1-s}{\\lambda} + (1-s)\\mathbb{E}[T]\n$$\nIsolate the terms with $\\mathbb{E}[T]$ on one side of the equation:\n$$\n\\mathbb{E}[T] - (1-s)\\mathbb{E}[T] = t + \\frac{1-s}{\\lambda}\n$$\nFactor out $\\mathbb{E}[T]$:\n$$\n\\mathbb{E}[T](1 - (1-s)) = t + \\frac{1-s}{\\lambda}\n$$\n$$\n\\mathbb{E}[T](s) = t + \\frac{1-s}{\\lambda}\n$$\nFinally, divide by $s$ to obtain the closed-form expression for $\\mathbb{E}[\\text{MTTR}] = \\mathbb{E}[T]$:\n$$\n\\mathbb{E}[T] = \\frac{1}{s}\\left(t + \\frac{1-s}{\\lambda}\\right)\n$$\nThis can be written as:\n$$\n\\mathbb{E}[\\text{MTTR}] = \\frac{t}{s} + \\frac{1-s}{s\\lambda}\n$$\nThe parameters $s$, $t$, and $\\lambda$ are given as $s \\in (0,1)$, $t>0$, and $\\lambda>0$, ensuring the denominator is non-zero and the expected value is finite and positive. The expression represents the expected time until recovery, measured in hours, as a function of the verification time, success probability, and detection rate.",
            "answer": "$$\n\\boxed{\\frac{t}{s} + \\frac{1-s}{s\\lambda}}\n$$"
        }
    ]
}