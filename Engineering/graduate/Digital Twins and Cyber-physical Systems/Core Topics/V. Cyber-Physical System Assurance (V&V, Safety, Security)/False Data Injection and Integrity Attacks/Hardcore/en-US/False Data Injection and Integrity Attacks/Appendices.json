{
    "hands_on_practices": [
        {
            "introduction": "Understanding False Data Injection (FDI) attacks begins with the static case. This first exercise challenges you to derive the fundamental condition for a 'stealthy' attack—one that is invisible to standard residual-based detectors in a system using Weighted Least Squares (WLS) estimation. By working through this problem (), you will see how an attacker can craft a malicious data injection vector that precisely manipulates the system's state estimate while remaining perfectly hidden.",
            "id": "4221503",
            "problem": "Consider a Digital Twin (DT) of a Cyber-Physical System (CPS) that performs state estimation using linear Weighted Least Squares (WLS). The measurement model is $y = H x + \\varepsilon$, where $y \\in \\mathbb{R}^{m}$ is the measurement vector, $x \\in \\mathbb{R}^{n}$ is the state vector, $H \\in \\mathbb{R}^{m \\times n}$ is the measurement matrix, and $\\varepsilon \\in \\mathbb{R}^{m}$ is zero-mean measurement noise with covariance $R \\in \\mathbb{R}^{m \\times m}$ that is symmetric positive definite. The DT’s estimator minimizes the quadratic form $(y - H x)^{\\top} R^{-1} (y - H x)$ and uses the same $H$ and $R$ throughout operation. \n\nAn adversary mounts a False Data Injection (FDI) attack by adding an attack vector $a \\in \\mathbb{R}^{m}$ to the measurement, producing $y' = y + a$. The adversary seeks a stealthy attack, meaning the estimator’s residual computed from $y'$ is identical to the residual computed from $y$. Starting from the WLS formulation and the definition of the residual under the $R^{-1}$ inner product, derive the constraint on $a$ that guarantees such stealthiness. Then, under this stealth constraint, argue how an attack can be constructed to shift the estimated state by a chosen vector without altering the residual, and in particular how to shift exactly one component of the state vector by a prescribed amount while leaving all other components unchanged.\n\nNow specialize to the following concrete instance with $m = 5$ and $n = 3$. The measurement matrix $H \\in \\mathbb{R}^{5 \\times 3}$ and the noise covariance $R \\in \\mathbb{R}^{5 \\times 5}$ are\n$$\nH = \\begin{pmatrix}\n1 & 2 & 0 \\\\\n0 & 3 & 1 \\\\\n0 & 0 & 4 \\\\\n5 & 0 & 0 \\\\\n0 & 6 & 7\n\\end{pmatrix}, \\quad\nR = \\operatorname{diag}(1, 2, 3, 4, 5).\n$$\nAssume $H$ has full column rank. The adversary wants to change the DT’s estimate of the second state component $x_{2}$ by a fixed amount $\\Delta = 1$, while keeping all other estimated state components unchanged, and remaining stealthy. Among all stealthy attack vectors that achieve this, determine the minimal $\\ell_{0}$ cardinality of the attack vector $a$, where the $\\ell_{0}$ cardinality $\\|a\\|_{0}$ is defined as the number of nonzero entries of $a$. Express your final answer as a single integer. No rounding is required, and no units are needed.",
            "solution": "The problem requires us to analyze a False Data Injection (FDI) attack on a linear Weighted Least Squares (WLS) state estimator. We must first derive the general condition for a stealthy attack that manipulates the state estimate and then apply this to a specific numerical case to find the minimum sparsity of the required attack vector.\n\nThe WLS state estimate $\\hat{x}$ is the vector that minimizes the objective function $J(x) = (y - Hx)^{\\top} R^{-1} (y - Hx)$. To find the minimum, we set the gradient of $J(x)$ with respect to $x$ to zero.\n$$\n\\frac{dJ(x)}{dx} = -2H^{\\top} R^{-1} (y - Hx) = 0\n$$\nThis leads to the normal equations:\n$$\nH^{\\top} R^{-1} H \\hat{x} = H^{\\top} R^{-1} y\n$$\nThe problem states that the measurement matrix $H \\in \\mathbb{R}^{m \\times n}$ has full column rank (rank $n$) and the noise covariance matrix $R \\in \\mathbb{R}^{m \\times m}$ is symmetric positive definite. Since $R$ is positive definite, its inverse $R^{-1}$ exists and is also positive definite. The matrix $G = H^{\\top} R^{-1} H$, known as the Gramian matrix, is an $n \\times n$ matrix. Because $H$ has full column rank and $R^{-1}$ is positive definite, $G$ is invertible. Therefore, a unique solution for the state estimate $\\hat{x}$ exists:\n$$\n\\hat{x} = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} y\n$$\nAn adversary injects a false data vector $a \\in \\mathbb{R}^{m}$, resulting in a corrupted measurement vector $y' = y + a$. The estimator, being unaware of the attack, computes a new state estimate $\\hat{x}'$ using $y'$:\n$$\n\\hat{x}' = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} y' = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} (y+a)\n$$\n$$\n\\hat{x}' = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} y + (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} a\n$$\nThe change in the state estimate, $\\Delta\\hat{x} = \\hat{x}' - \\hat{x}$, is therefore:\n$$\n\\Delta\\hat{x} = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} a\n$$\nThe problem defines a stealthy attack as one for which the estimator's residual is unchanged. The residual vector corresponding to the original measurement $y$ is $r = y - H\\hat{x}$. The residual for the attacked measurement $y'$ is $r' = y' - H\\hat{x}'$. The stealthiness condition is $r' = r$.\nLet's express $r'$ in terms of $r$ and $a$:\n$$\nr' = y' - H\\hat{x}' = (y+a) - H(\\hat{x}+\\Delta\\hat{x}) = (y - H\\hat{x}) + (a - H\\Delta\\hat{x})\n$$\n$$\nr' = r + a - H(H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} a\n$$\nLet us define the projection-like matrix $\\Pi = H(H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1}$. Then the expression for $r'$ becomes:\n$$\nr' = r + (I - \\Pi)a\n$$\nFor the residual to be unchanged ($r' = r$), we must have $(I - \\Pi)a = 0$. This is the mathematical condition for a perfectly stealthy attack. This equation implies $a = \\Pi a$, which means the attack vector $a$ must lie in the image of the matrix $\\Pi$. The image of $\\Pi$ is the same as the column space of $H$, denoted $\\text{Im}(H)$. Therefore, the condition for a stealthy attack is that the attack vector $a$ must be a linear combination of the columns of $H$. That is, there must exist a vector $c \\in \\mathbb{R}^n$ such that:\n$$\na = Hc\n$$\nNow we can determine the effect of such a stealthy attack on the state estimate. By substituting $a = Hc$ into the expression for $\\Delta\\hat{x}$:\n$$\n\\Delta\\hat{x} = (H^{\\top} R^{-1} H)^{-1} H^{\\top} R^{-1} (Hc) = (H^{\\top} R^{-1} H)^{-1} (H^{\\top} R^{-1} H) c = I_n c = c\n$$\nThis provides a powerful insight: for a stealthy attack of the form $a = Hc$, the resulting shift in the state estimate is precisely the vector $c$. An adversary can therefore engineer a specific, desired change in the state estimate, $\\Delta x_c$, by choosing $c = \\Delta x_c$ and constructing the attack vector as $a = H\\Delta x_c$. This attack is guaranteed to be stealthy.\n\nTo shift exactly one component of the state vector, say the $k$-th component $x_k$, by a prescribed amount $\\Delta$ while leaving all other components unchanged, the desired state shift vector is $\\Delta x_c = \\Delta \\cdot e_k$, where $e_k$ is the $k$-th standard basis vector in $\\mathbb{R}^n$. The required stealthy attack vector is then:\n$$\na = H(\\Delta \\cdot e_k) = \\Delta \\cdot (He_k)\n$$\nThe vector $He_k$ is the $k$-th column of the matrix $H$, which we denote as $h_k$. Thus, the unique stealthy attack vector that accomplishes this specific state modification is $a = \\Delta \\cdot h_k$.\n\nWe now specialize to the given concrete instance. We have $m=5$ and $n=3$, with\n$$\nH = \\begin{pmatrix} 1 & 2 & 0 \\\\ 0 & 3 & 1 \\\\ 0 & 0 & 4 \\\\ 5 & 0 & 0 \\\\ 0 & 6 & 7 \\end{pmatrix}\n$$\nThe adversary's goal is to change the DT's estimate of the second state component $x_2$ by $\\Delta = 1$, while keeping the estimates of $x_1$ and $x_3$ unchanged. This corresponds to the state index $k=2$ and the shift amount $\\Delta=1$. The desired state shift vector is:\n$$\n\\Delta x_c = 1 \\cdot e_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\nBased on our general derivation, there is a unique stealthy attack vector $a$ that achieves this state modification. This vector is given by $a = H\\Delta x_c$.\n$$\na = H e_2 = \\begin{pmatrix} 1 & 2 & 0 \\\\ 0 & 3 & 1 \\\\ 0 & 0 & 4 \\\\ 5 & 0 & 0 \\\\ 0 & 6 & 7 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 0 \\\\ 0 \\\\ 6 \\end{pmatrix}\n$$\nThis vector $a$ is the second column of $H$. Since this is the only vector that satisfies both the stealthiness and state modification objectives, the question \"determine the minimal $\\ell_0$ cardinality\" simply requires us to compute the $\\ell_0$ cardinality of this unique vector. The $\\ell_0$ cardinality, $\\|a\\|_0$, is the number of non-zero entries in the vector $a$.\nThe components of the attack vector are $a_1=2$, $a_2=3$, $a_3=0$, $a_4=0$, and $a_5=6$.\nThe non-zero entries are $a_1$, $a_2$, and $a_5$. Counting these, we find there are $3$ non-zero entries.\nTherefore, the minimal $\\ell_0$ cardinality of the required attack vector is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Real-world cyber-physical systems are dynamic, and so are the most sophisticated attacks against them. This practice moves from the static model to a dynamic system monitored by a Luenberger observer, exploring how an attacker can optimize their strategy over time. In this scenario (), you will determine the maximum possible damage—measured by the final estimation error—that an attacker can inflict given a limited energy budget, revealing how system dynamics can be exploited.",
            "id": "4221472",
            "problem": "Consider a discrete-time linear time-invariant cyber-physical system with a Digital Twin (DT) estimator that monitors the physical process. The plant evolves as $x_{k+1} = A x_{k} + B u_{k}$ and is measured by $y_{k} = C x_{k} + a_{k}$, where $x_{k} \\in \\mathbb{R}^{n}$ is the state, $u_{k} \\in \\mathbb{R}^{m}$ is a known control input, $y_{k} \\in \\mathbb{R}^{p}$ is the measured output, and $a_{k} \\in \\mathbb{R}^{p}$ is an adversarial false data injection signal representing an integrity attack on the sensor measurements. The DT employs a Luenberger observer (LO) with fixed gain $L \\in \\mathbb{R}^{n \\times p}$:\n$$\n\\hat{x}_{k+1} = A \\hat{x}_{k} + B u_{k} + L \\left( y_{k} - C \\hat{x}_{k} \\right),\n$$\nwhere $\\hat{x}_{k} \\in \\mathbb{R}^{n}$ is the state estimate. Define the estimation error as $e_{k} = \\hat{x}_{k} - x_{k}$ and assume the initial alignment $e_{0} = 0$. The attacker seeks to maximize the norm of the estimation error at a given target horizon $N \\in \\mathbb{N}$, subject to an energy budget constraint on the injected signal sequence:\n$$\n\\sum_{k=0}^{N-1} \\| a_{k} \\|_{2}^{2} \\leq E,\n$$\nwith $E > 0$. Assume $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, and $C \\in \\mathbb{R}^{p \\times n}$ are known and that $(A, C)$ is detectable so that the chosen $L$ yields a stable observer error dynamics in nominal operation. Use the fundamental definitions of discrete-time linear systems, Euclidean norm, and the induced operator norm to derive from first principles the exact closed-form expression for the maximum achievable value of $\\| e_{N} \\|_{2}$ under the constraint above. Your answer must be given as a single closed-form analytic expression in terms of $A$, $C$, $L$, $N$, and $E$. No numerical rounding is required and no physical units apply.",
            "solution": "The problem requires the derivation of the maximum achievable estimation error norm $\\| e_{N} \\|_{2}$ at a time horizon $N$ for a discrete-time linear system monitored by a Luenberger observer, under a false data injection attack with a bounded energy budget. The derivation proceeds by first establishing the dynamics of the estimation error, then expressing the error at the horizon $N$ as a linear transformation of the attack sequence, and finally solving the resulting constrained optimization problem.\n\nFirst, we derive the recurrence relation for the estimation error $e_{k} = \\hat{x}_{k} - x_{k}$. The error at step $k+1$ is:\n$$\ne_{k+1} = \\hat{x}_{k+1} - x_{k+1}\n$$\nSubstitute the expressions for $\\hat{x}_{k+1}$ from the Luenberger observer and $x_{k+1}$ from the plant dynamics:\n$$\ne_{k+1} = \\left( A \\hat{x}_{k} + B u_{k} + L ( y_{k} - C \\hat{x}_{k} ) \\right) - \\left( A x_{k} + B u_{k} \\right)\n$$\nThe terms involving $B u_{k}$ cancel out. Rearranging the terms gives:\n$$\ne_{k+1} = A (\\hat{x}_{k} - x_{k}) + L y_{k} - L C \\hat{x}_{k}\n$$\nSubstitute the definition of the error $e_{k} = \\hat{x}_{k} - x_{k}$ and the measurement equation $y_{k} = C x_{k} + a_{k}$:\n$$\ne_{k+1} = A e_{k} + L (C x_{k} + a_{k}) - L C \\hat{x}_{k}\n$$\nDistribute $L$ and rearrange:\n$$\ne_{k+1} = A e_{k} + L C (x_{k} - \\hat{x}_{k}) + L a_{k}\n$$\nRecognizing that $x_{k} - \\hat{x}_{k} = -e_{k}$, we obtain:\n$$\ne_{k+1} = A e_{k} - L C e_{k} + L a_{k}\n$$\nLet us define the observer error dynamics matrix as $A_{cl} = A - L C$. The error dynamics simplify to a linear system driven by the attack signal $a_k$:\n$$\ne_{k+1} = A_{cl} e_{k} + L a_{k}\n$$\nThe problem states that the observer is stable, which implies that the eigenvalues of $A_{cl}$ lie within the open unit disk in the complex plane.\n\nNext, we unroll this recurrence relation from the initial condition $e_0 = 0$ to the target horizon $N$:\nFor $k=0$: $e_1 = A_{cl} e_0 + L a_0 = L a_0$\nFor $k=1$: $e_2 = A_{cl} e_1 + L a_1 = A_{cl} (L a_0) + L a_1$\nFor $k=2$: $e_3 = A_{cl} e_2 + L a_2 = A_{cl} (A_{cl} L a_0 + L a_1) + L a_2 = A_{cl}^2 L a_0 + A_{cl} L a_1 + L a_2$\n\nBy induction, the error at the horizon $N$ is the sum of the effects of all past attack signals:\n$$\ne_{N} = \\sum_{k=0}^{N-1} A_{cl}^{N-1-k} L a_{k}\n$$\nThis expression represents a linear mapping from the sequence of attack vectors $\\{a_0, a_1, \\dots, a_{N-1}\\}$ to the final error vector $e_N$. To facilitate the optimization, we can represent this mapping in matrix form. Let us define a block \"supervector\" for the entire attack sequence:\n$$\n\\mathbf{a} = \\begin{pmatrix} a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_{N-1} \\end{pmatrix} \\in \\mathbb{R}^{Np}\n$$\nand a corresponding block matrix operator $\\mathcal{O} \\in \\mathbb{R}^{n \\times Np}$:\n$$\n\\mathcal{O} = \\begin{pmatrix} A_{cl}^{N-1} L & A_{cl}^{N-2} L & \\cdots & A_{cl}^{0} L \\end{pmatrix}\n$$\nwhere $A_{cl}^0 = I$, the $n \\times n$ identity matrix. With these definitions, the final error $e_N$ can be concisely written as:\n$$\ne_N = \\mathcal{O} \\mathbf{a}\n$$\nThe attacker's energy constraint is $\\sum_{k=0}^{N-1} \\| a_{k} \\|_{2}^{2} \\leq E$. In terms of the supervector $\\mathbf{a}$, this is equivalent to $\\|\\mathbf{a}\\|_{2}^{2} \\leq E$, or $\\|\\mathbf{a}\\|_{2} \\leq \\sqrt{E}$.\n\nThe attacker's objective is to maximize $\\|e_N\\|_2 = \\|\\mathcal{O} \\mathbf{a}\\|_2$ subject to the constraint $\\|\\mathbf{a}\\|_{2} \\leq \\sqrt{E}$. This is a standard problem of finding the maximum output norm of a linear operator given a bounded input norm. The solution is given by the induced $2$-norm (or spectral norm) of the operator $\\mathcal{O}$:\n$$\n\\max_{\\|\\mathbf{a}\\|_{2} \\leq \\sqrt{E}} \\|\\mathcal{O} \\mathbf{a}\\|_{2} = \\left( \\sup_{\\mathbf{a} \\neq 0} \\frac{\\|\\mathcal{O} \\mathbf{a}\\|_{2}}{\\|\\mathbf{a}\\|_{2}} \\right) \\cdot \\sqrt{E} = \\|\\mathcal{O}\\|_{2} \\sqrt{E}\n$$\nThe induced $2$-norm of a matrix is equal to its largest singular value, $\\sigma_{\\max}(\\mathcal{O})$. The singular values of $\\mathcal{O}$ are the square roots of the eigenvalues of the matrix $\\mathcal{O} \\mathcal{O}^T$ or $\\mathcal{O}^T \\mathcal{O}$. It is computationally more convenient to work with the smaller matrix, which is $\\mathcal{O} \\mathcal{O}^T \\in \\mathbb{R}^{n \\times n}$.\n$$\n\\|\\mathcal{O}\\|_{2} = \\sigma_{\\max}(\\mathcal{O}) = \\sqrt{\\lambda_{\\max}(\\mathcal{O} \\mathcal{O}^T)}\n$$\nwhere $\\lambda_{\\max}(\\cdot)$ denotes the maximum eigenvalue of a matrix.\n\nLet's compute the product $\\mathcal{O} \\mathcal{O}^T$:\n$$\n\\mathcal{O} \\mathcal{O}^T = \\begin{pmatrix} A_{cl}^{N-1} L & \\cdots & L \\end{pmatrix} \\begin{pmatrix} (A_{cl}^{N-1} L)^T \\\\ \\vdots \\\\ L^T \\end{pmatrix} = \\sum_{k=0}^{N-1} (A_{cl}^{N-1-k} L) (A_{cl}^{N-1-k} L)^T\n$$\nExpanding the transpose and changing the index of summation by letting $j = N-1-k$ (so as $k$ goes from $0$ to $N-1$, $j$ goes from $N-1$ down to $0$), we get:\n$$\n\\mathcal{O} \\mathcal{O}^T = \\sum_{j=0}^{N-1} A_{cl}^{j} L L^T (A_{cl}^T)^{j}\n$$\nThis matrix is the finite-horizon reachability Gramian for the system $(A_{cl}, L)$ over the time horizon $[0, N-1]$. Let's denote this matrix as $\\mathcal{G}_N$:\n$$\n\\mathcal{G}_N = \\sum_{k=0}^{N-1} (A-LC)^{k} L L^T ((A-LC)^T)^{k}\n$$\nSubstituting this back into our expression for the maximum error norm:\n$$\n\\max \\|e_N\\|_2 = \\|\\mathcal{O}\\|_{2} \\sqrt{E} = \\sqrt{\\lambda_{\\max}(\\mathcal{G}_N)} \\sqrt{E} = \\sqrt{E \\cdot \\lambda_{\\max}(\\mathcal{G}_N)}\n$$\nThis provides the final closed-form expression for the maximum achievable estimation error norm under the given energy constraint on the attack signal. The maximum is achieved when the attacker aligns their attack sequence (reshaped as $\\mathbf{a}$) with the right singular vector of $\\mathcal{O}$ corresponding to $\\sigma_{\\max}(\\mathcal{O})$ and uses the full energy budget $E$.",
            "answer": "$$\n\\boxed{\\sqrt{E \\cdot \\lambda_{\\max}\\left(\\sum_{k=0}^{N-1} (A-LC)^{k} L L^T ((A-LC)^T)^{k}\\right)}}\n$$"
        },
        {
            "introduction": "After learning to think like an attacker, it is crucial to adopt the defender's perspective. This final exercise () tasks you with designing a defense mechanism using statistical principles to detect a structured attack hidden within noisy measurements. You will derive a Generalized Likelihood Ratio Test (GLRT) and analyze its performance by calculating the false alarm rate, providing a hands-on understanding of the trade-offs involved in building robust integrity monitoring systems.",
            "id": "4221476",
            "problem": "A networked Cyber-Physical System (CPS) is monitored by a Digital Twin that provides a physics-consistent predicted measurement vector $\\hat{y} \\in \\mathbb{R}^{m}$ at each sampling instant. The actual measurement vector $y \\in \\mathbb{R}^{m}$ may be corrupted by a False Data Injection (FDI) integrity attack $a \\in \\mathbb{R}^{m}$ and measurement noise $w \\in \\mathbb{R}^{m}$, satisfying the stochastic model\n$$\ny = \\hat{y} + a + w,\n$$\nwhere the noise $w$ is independent and identically distributed Gaussian with $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$, and the attack $a$ is unknown to the defender. Based on the system architecture and historical vulnerability analysis, the attacker’s actuation is known to be confined to a $r$-dimensional subspace $\\mathcal{S} = \\mathrm{col}(U)$ spanned by the columns of a matrix $U \\in \\mathbb{R}^{m \\times r}$, where $U^{\\top} U = I_{r}$ and $r \\leq m$.\n\nConsider the binary hypothesis testing problem\n$$\nH_{0}: a = 0 \\quad \\text{versus} \\quad H_{1}: a \\in \\mathcal{S} \\setminus \\{0\\}.\n$$\nStarting from the definition of the Generalized Likelihood Ratio Test (GLRT), which compares the maximum likelihood under the alternative hypothesis to the likelihood under the null hypothesis, derive the corresponding GLRT decision rule specialized to this Gaussian setting. Your derivation must be based on the Gaussian probability density function and must not assume any pre-derived detection statistic.\n\nLet the GLRT be implemented by thresholding a scalar test statistic $T(y)$ against a threshold $\\gamma > 0$. Compute the exact false alarm rate, defined as the probability of deciding $H_{1}$ under $H_{0}$, as a closed-form analytic expression that depends only on the threshold $\\gamma$ and the subspace dimension $r$. You may use standard special functions in your final expression. No numerical approximation is required. Express your final answer as a single symbolic expression; no units are involved.",
            "solution": "The problem asks for the derivation of a Generalized Likelihood Ratio Test (GLRT) for detecting a structured false data injection attack and for the calculation of the corresponding false alarm rate.\n\nFirst, we derive the GLRT decision rule. The stochastic model for the measurement vector $y \\in \\mathbb{R}^{m}$ is given by\n$$\ny = \\hat{y} + a + w,\n$$\nwhere $\\hat{y}$ is the predicted measurement, $a$ is the attack vector, and $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$ is Gaussian noise. The random component of this model is $w$. We can express $w$ as $w = y - \\hat{y} - a$. The probability density function (PDF) of $y$ given $a$ is therefore\n$$\np(y|a) = \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|y - \\hat{y} - a\\|^2\\right).\n$$\nThe problem is a binary hypothesis test:\n$$\nH_{0}: a = 0 \\quad \\text{versus} \\quad H_{1}: a \\in \\mathcal{S} \\setminus \\{0\\},\n$$\nwhere $\\mathcal{S} = \\mathrm{col}(U)$ is an $r$-dimensional subspace spanned by the columns of $U \\in \\mathbb{R}^{m \\times r}$ with $U^{\\top} U = I_{r}$.\n\nThe GLRT statistic is the ratio of the maximum likelihood under $H_{1}$ to the likelihood under $H_{0}$:\n$$\nL(y) = \\frac{\\sup_{a \\in \\mathcal{S} \\setminus \\{0\\}} p(y|a)}{p(y|H_0)}.\n$$\nUnder the null hypothesis $H_{0}$, the attack $a=0$. The likelihood is\n$$\np(y|H_0) = p(y|a=0) = \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|y - \\hat{y}\\|^2\\right).\n$$\nThere are no unknown parameters under $H_0$, so no maximization is needed.\n\nUnder the alternative hypothesis $H_{1}$, the attack vector $a$ is unknown but lies in the subspace $\\mathcal{S}$. We find the maximum likelihood estimate (MLE) of $a$. Maximizing $p(y|a)$ with respect to $a \\in \\mathcal{S}$ is equivalent to minimizing the squared norm in the exponent:\n$$\n\\hat{a}_{ML} = \\arg\\min_{a \\in \\mathcal{S}} \\|(y - \\hat{y}) - a\\|^2.\n$$\nThis is a standard least-squares problem, where the solution $\\hat{a}_{ML}$ is the orthogonal projection of the residual vector $z = y - \\hat{y}$ onto the subspace $\\mathcal{S}$. The projection matrix onto $\\mathcal{S} = \\mathrm{col}(U)$ is $P_{\\mathcal{S}} = U(U^{\\top}U)^{-1}U^{\\top}$. Given $U^{\\top}U = I_r$, this simplifies to $P_{\\mathcal{S}} = UU^{\\top}$.\nThus, the MLE of $a$ is\n$$\n\\hat{a}_{ML} = P_{\\mathcal{S}} (y - \\hat{y}) = UU^{\\top}(y - \\hat{y}).\n$$\nSince the likelihood function is continuous in $a$ and $\\mathcal{S}$ is a closed set, the supremum over $a \\in \\mathcal{S} \\setminus \\{0\\}$ is the same as the supremum over $a \\in \\mathcal{S}$, unless the maximum uniquely occurs at $a=0$. In that case, the likelihood ratio would be $1$, leading to a decision for $H_0$ for any reasonable threshold, so we can proceed by maximizing over $\\mathcal{S}$.\n\nSubstituting $\\hat{a}_{ML}$ back into the likelihood function gives the maximized likelihood under $H_1$:\n$$\n\\sup_{a \\in \\mathcal{S}} p(y|a) = \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|(y - \\hat{y}) - UU^{\\top}(y - \\hat{y})\\|^2\\right).\n$$\nLet $z = y - \\hat{y}$. The term in the exponent is $\\|(I_m - UU^{\\top})z\\|^2$. The matrix $I_m - UU^{\\top}$ is the projection onto the orthogonal complement of $\\mathcal{S}$. By the Pythagorean theorem for orthogonal projections, $\\|z\\|^2 = \\|P_{\\mathcal{S}}z\\|^2 + \\|(I_m - P_{\\mathcal{S}})z\\|^2 = \\|UU^{\\top}z\\|^2 + \\|(I_m - UU^{\\top})z\\|^2$.\nTherefore, $\\|(I_m - UU^{\\top})z\\|^2 = \\|z\\|^2 - \\|UU^{\\top}z\\|^2$.\n\nThe likelihood ratio $L(y)$ is then\n$$\nL(y) = \\frac{\\exp\\left(-\\frac{1}{2\\sigma^2}(\\|y - \\hat{y}\\|^2 - \\|UU^{\\top}(y - \\hat{y})\\|^2)\\right)}{\\exp\\left(-\\frac{1}{2\\sigma^2} \\|y - \\hat{y}\\|^2\\right)} = \\exp\\left(\\frac{1}{2\\sigma^2} \\|UU^{\\top}(y - \\hat{y})\\|^2\\right).\n$$\nThe GLRT decides $H_1$ if $L(y) > \\gamma_L$ for some threshold $\\gamma_L > 1$. This is equivalent to comparing the log-likelihood ratio to a threshold:\n$$\n\\ln(L(y)) = \\frac{1}{2\\sigma^2} \\|UU^{\\top}(y - \\hat{y})\\|^2 > \\ln(\\gamma_L).\n$$\nA monotonic function of this statistic forms an equivalent test. The problem specifies a test statistic $T(y)$ and threshold $\\gamma$, such that the final false alarm rate depends only on $\\gamma$ and $r$. This implies the nuisance parameter $\\sigma^2$ must be absent from the distribution of $T(y)$ under $H_0$. We therefore define the test statistic $T(y)$ by normalizing the term in the exponent:\n$$\nT(y) = \\frac{1}{\\sigma^2} \\|UU^{\\top}(y - \\hat{y})\\|^2.\n$$\nThe GLRT decision rule is to decide $H_1$ if $T(y) > \\gamma$, where $\\gamma = 2\\ln(\\gamma_L)$.\n\nNext, we compute the false alarm rate, $P_{FA}$. This is the probability of deciding $H_1$ when $H_0$ is true.\n$$\nP_{FA} = P(T(y) > \\gamma | H_0).\n$$\nUnder $H_0$, $a=0$, so $y = \\hat{y} + w$. The test statistic becomes\n$$\nT(y)|_{H_0} = \\frac{1}{\\sigma^2} \\|UU^{\\top}((\\hat{y} + w) - \\hat{y})\\|^2 = \\frac{1}{\\sigma^2} \\|UU^{\\top}w\\|^2.\n$$\nLet $w' = \\frac{1}{\\sigma}w$. Since $w \\sim \\mathcal{N}(0, \\sigma^2 I_m)$, $w'$ is a standard normal random vector, $w' \\sim \\mathcal{N}(0, I_m)$. Substituting $w = \\sigma w'$ into the expression for $T(y)$, we get\n$$\nT(y)|_{H_0} = \\frac{1}{\\sigma^2} \\|UU^{\\top}(\\sigma w')\\|^2 = \\frac{\\sigma^2}{\\sigma^2} \\|UU^{\\top}w'\\|^2 = \\|UU^{\\top}w'\\|^2.\n$$\nThis can be written as a quadratic form $w'^{\\top}(UU^{\\top})^{\\top}(UU^{\\top})w' = w'^{\\top}U(U^{\\top}U)U^{\\top}w' = w'^{\\top}(UU^{\\top})w'$.\nThe statistic is a quadratic form in the standard normal vector $w'$, with the matrix $P_{\\mathcal{S}} = UU^{\\top}$. According to Cochran's theorem (or the general theory of quadratic forms of Gaussian vectors), if $X \\sim \\mathcal{N}(0, I_m)$ and $A$ is an $m \\times m$ symmetric and idempotent matrix with $\\mathrm{rank}(A) = k$, then the random variable $X^{\\top}AX$ follows a chi-squared distribution with $k$ degrees of freedom, $\\chi^2_k$.\n\nThe matrix $P_{\\mathcal{S}} = UU^{\\top}$ is:\n1.  Symmetric: $(UU^{\\top})^{\\top} = (U^{\\top})^{\\top}U^{\\top} = UU^{\\top}$.\n2.  Idempotent: $(UU^{\\top})(UU^{\\top}) = U(U^{\\top}U)U^{\\top} = U I_r U^{\\top} = UU^{\\top}$.\nThe rank of $P_{\\mathcal{S}}$ is $\\mathrm{rank}(UU^{\\top}) = \\mathrm{tr}(UU^{\\top}) = \\mathrm{tr}(U^{\\top}U) = \\mathrm{tr}(I_r) = r$.\n\nTherefore, under $H_0$, the test statistic $T(y)$ follows a chi-squared distribution with $r$ degrees of freedom:\n$$\nT(y)|_{H_0} \\sim \\chi^2_r.\n$$\n The false alarm rate is the probability that this $\\chi^2_r$-distributed random variable exceeds the threshold $\\gamma$:\n$$\nP_{FA} = P(\\chi^2_r > \\gamma).\n$$\nThis is the value of the complementary cumulative distribution function (CCDF), or survival function, of the $\\chi^2_r$ distribution, evaluated at $\\gamma$. The CCDF of a chi-squared random variable is commonly expressed using the regularized upper incomplete gamma function, $Q(s,x)$, defined as:\n$$\nQ(s, x) = \\frac{\\Gamma(s, x)}{\\Gamma(s)} = \\frac{1}{\\Gamma(s)} \\int_x^{\\infty} t^{s-1} e^{-t} dt,\n$$\nwhere $\\Gamma(s)$ is the gamma function and $\\Gamma(s,x)$ is the upper incomplete gamma function.\nFor a $\\chi^2_r$ random variable $X$, the probability $P(X > x_0)$ is given by $Q(\\frac{r}{2}, \\frac{x_0}{2})$.\nIn our case, the degrees of freedom are $r$ and the value $x_0$ is the threshold $\\gamma$. Hence, the false alarm rate is\n$$\nP_{FA} = Q\\left(\\frac{r}{2}, \\frac{\\gamma}{2}\\right).\n$$\nThis expression depends only on the subspace dimension $r$ and the threshold $\\gamma$, as required.",
            "answer": "$$\n\\boxed{Q\\left(\\frac{r}{2}, \\frac{\\gamma}{2}\\right)}\n$$"
        }
    ]
}