{
    "hands_on_practices": [
        {
            "introduction": "在构建任何情境感知系统时，首要步骤是深刻理解其传感器的内在局限性。此练习旨在通过一个假设的传感器模型，量化分析几种基本误差来源——包括偏差（bias）、漂移（drift）、精度（precision）和分辨率（resolution）——如何共同影响最终估计的均方误差（Mean Squared Error）。通过这个实践，您将学会如何从第一性原理出发，推导出不同误差成分对系统整体性能的具体贡献，这对于设计鲁棒的估计算法至关重要。",
            "id": "4210107",
            "problem": "一个信息物理系统 (CPS) 部署了一个上下文传感器来监测一个标量上下文状态 $z$（例如，在数字孪生中编码为标量潜变量的占用水平）。在此设置中，以下基本定义适用于该传感器：准确度是测量值或估计值与真实状态 $z$ 的接近程度；精密度是在不变条件下测量的可复现性，并通过零均值随机波动的方差来量化；偏差是传感器输出与真实状态之间的固定系统性偏移 $b$；漂移是由传感器内部随时间变化引起的缓慢变化的偏差 $d(t)$；分辨率是传感器输出中最小可区分的变化 $q$，导致读数的量化。\n\n在一个以均匀间隔 $\\Delta t$ 采集 $N$ 个样本的短暂估计窗口内，假设真实上下文状态在 $z$ 处保持恒定，且传感器产生如下测量值\n$$\nx_{k} \\;=\\; z \\;+\\; b \\;+\\; d_{k} \\;+\\; \\epsilon_{k} \\;+\\; \\eta_{k}, \\quad k=1,2,\\dots,N,\n$$\n具有以下特征：\n- 偏差 $b$ 是一个常数（未知，但在该窗口内不随时间变化）。\n- 漂移序列 $\\{d_{k}\\}$ 是一个离散时间随机游走，其中 $d_{0}=0$ 且 $d_{k} = \\sum_{m=1}^{k} w_{m}$，$\\{w_{m}\\}$ 是独立的、零均值的高斯增量，其方差为 $\\mathrm{Var}(w_{m}) = D\\,\\Delta t$，其中 $D>0$ 是一个已知的扩散系数。\n- 精密度噪声 $\\{\\epsilon_{k}\\}$ 是独立的、零均值的高斯分布，其方差为 $\\mathrm{Var}(\\epsilon_{k}) = \\sigma_{p}^{2}$。\n- 由分辨率引起的量化噪声 $\\{\\eta_{k}\\}$ 是在 $[-q/2,q/2]$ 上独立同分布的均匀随机变量，且与所有其他项独立。\n\n数字孪生使用的估计量是样本均值，\n$$\n\\hat{z} \\;=\\; \\frac{1}{N}\\sum_{k=1}^{N} x_{k}.\n$$\n\n从均方误差的核心定义和独立随机过程的性质出发，推导均方误差\n$$\nE\\!\\left[(z - \\hat{z})^{2}\\right]\n$$\n的闭式表达式，该表达式应使用 $b$、$D$、$\\Delta t$、$N$、$\\sigma_{p}^{2}$ 和 $q$ 来表示。在你的推导中，请明确指出偏差、漂移、精密度和分辨率各自如何对均方误差做出贡献。无需四舍五入；将你的最终结果表示为单个闭式符号表达式。",
            "solution": "该问题要求推导真实恒定状态 $z$ 的估计量 $\\hat{z}$ 的均方误差 (MSE)。MSE 定义为 $E[(z - \\hat{z})^{2}]$。\n\n估计量是 $N$ 次测量的样本均值：\n$$\n\\hat{z} \\;=\\; \\frac{1}{N}\\sum_{k=1}^{N} x_{k}\n$$\n测量值 $x_k$ 由以下模型给出：\n$$\nx_{k} \\;=\\; z \\;+\\; b \\;+\\; d_{k} \\;+\\; \\epsilon_{k} \\;+\\; \\eta_{k}\n$$\n其中 $z$ 和偏差 $b$ 是常数。\n\n首先，我们表示出估计误差 $z - \\hat{z}$。代入 $\\hat{z}$ 和 $x_k$ 的表达式：\n$$\nz - \\hat{z} \\;=\\; z - \\frac{1}{N}\\sum_{k=1}^{N} (z + b + d_{k} + \\epsilon_{k} + \\eta_{k})\n$$\n通过分配求和符号和因子 $\\frac{1}{N}$：\n$$\nz - \\hat{z} \\;=\\; z - \\left(\\frac{1}{N}\\sum_{k=1}^{N}z + \\frac{1}{N}\\sum_{k=1}^{N}b + \\frac{1}{N}\\sum_{k=1}^{N}d_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right)\n$$\n$$\nz - \\hat{z} \\;=\\; z - \\left(\\frac{N z}{N} + \\frac{N b}{N} + \\frac{1}{N}\\sum_{k=1}^{N}d_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right)\n$$\n$$\nz - \\hat{z} \\;=\\; -b - \\frac{1}{N}\\sum_{k=1}^{N}d_{k} - \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} - \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\n$$\nMSE 通常被分解为估计量的方差和其偏差平方的和。对于参数 $\\theta$ 的估计量 $\\hat{\\theta}$，$\\mathrm{MSE} = \\mathrm{Var}(\\hat{\\theta}) + (\\mathrm{Bias}(\\hat{\\theta}))^2$。这里，误差是 $z-\\hat{z}$。\n$$\nE[(z - \\hat{z})^{2}] \\;=\\; \\mathrm{Var}(z - \\hat{z}) + (E[z - \\hat{z}])^{2}\n$$\n由于 $z$ 是一个非随机常数，$\\mathrm{Var}(z - \\hat{z}) = \\mathrm{Var}(-\\hat{z}) = \\mathrm{Var}(\\hat{z})$。表达式变为：\n$$\nE[(z - \\hat{z})^{2}] \\;=\\; \\mathrm{Var}(\\hat{z}) + (E[z - \\hat{z}])^{2}\n$$\n我们将计算这两个分量。\n\n首先，我们确定偏差的贡献，即 $(E[z - \\hat{z}])^{2}$。\n$$\nE[z - \\hat{z}] = E\\left[-b - \\frac{1}{N}\\sum_{k=1}^{N}d_{k} - \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} - \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right]\n$$\n利用期望算子的线性性质：\n$$\nE[z - \\hat{z}] = -b - \\frac{1}{N}\\sum_{k=1}^{N}E[d_{k}] - \\frac{1}{N}\\sum_{k=1}^{N}E[\\epsilon_{k}] - \\frac{1}{N}\\sum_{k=1}^{N}E[\\eta_{k}]\n$$\n问题陈述指出，漂移增量 $\\{w_{m}\\}$、精密度噪声 $\\{\\epsilon_{k}\\}$ 和量化噪声 $\\{\\eta_{k}\\}$ 都是零均值随机变量。\n- 对于漂移，$d_k = \\sum_{m=1}^{k} w_m$，所以 $E[d_k] = \\sum_{m=1}^{k} E[w_m] = 0$。\n- 对于精密度噪声，$E[\\epsilon_k] = 0$。\n- 对于量化噪声，$\\eta_k \\sim U[-q/2, q/2]$，所以 $E[\\eta_k] = 0$。\n代入这些零期望值：\n$$\nE[z - \\hat{z}] = -b - 0 - 0 - 0 = -b\n$$\n因此，对 MSE 的偏差平方贡献是 $(-b)^{2} = b^{2}$。该项源于传感器的系统偏差 $b$。\n\n接下来，我们计算方差贡献，即 $\\mathrm{Var}(\\hat{z})$。\n$$\n\\hat{z} = z + b + \\frac{1}{N}\\sum_{k=1}^{N}d_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\n$$\n随机变量的方差不受加上常数的影响，所以 $z$ 和 $b$ 没有贡献。\n$$\n\\mathrm{Var}(\\hat{z}) = \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}d_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k} + \\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right)\n$$\n漂移过程、精密度噪声和量化噪声被陈述为相互独立。因此，它们和的方差是它们方差的和：\n$$\n\\mathrm{Var}(\\hat{z}) = \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}d_{k}\\right) + \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k}\\right) + \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right)\n$$\n我们现在计算每个方差分量，它们分别对应于漂移、精密度和分辨率的贡献。\n\n1.  **精密度贡献：** 精密度噪声项 $\\{\\epsilon_{k}\\}$ 是独立同分布的，其方差为 $\\mathrm{Var}(\\epsilon_{k})=\\sigma_{p}^{2}$。\n    $$\n    \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}\\epsilon_{k}\\right) = \\frac{1}{N^2}\\mathrm{Var}\\left(\\sum_{k=1}^{N}\\epsilon_{k}\\right) = \\frac{1}{N^2}\\sum_{k=1}^{N}\\mathrm{Var}(\\epsilon_{k}) = \\frac{1}{N^2}(N\\sigma_{p}^{2}) = \\frac{\\sigma_{p}^{2}}{N}\n    $$\n2.  **分辨率贡献：** 量化噪声项 $\\{\\eta_k\\}$ 是在 $[-q/2, q/2]$ 上的独立同分布 (i.i.d.) 均匀随机变量。均匀分布 $U[a,b]$ 的方差是 $(b-a)^2/12$。\n    $$\n    \\mathrm{Var}(\\eta_k) = \\frac{(q/2 - (-q/2))^2}{12} = \\frac{q^2}{12}\n    $$\n    与精密度噪声项类似：\n    $$\n    \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}\\eta_{k}\\right) = \\frac{1}{N^2}\\sum_{k=1}^{N}\\mathrm{Var}(\\eta_{k}) = \\frac{1}{N^2}\\left(N\\frac{q^2}{12}\\right) = \\frac{q^2}{12N}\n    $$\n3.  **漂移贡献：** 这个计算更为复杂，因为漂移样本 $\\{d_k\\}$ 不是独立的。\n    $$\n    \\mathrm{Var}_{d} = \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{k=1}^{N}d_{k}\\right) = \\frac{1}{N^2}\\mathrm{Var}\\left(\\sum_{k=1}^{N}d_{k}\\right)\n    $$\n    令 $S_d = \\sum_{k=1}^{N}d_{k}$。由于 $E[d_k]=0$，我们有 $E[S_d]=0$。因此，$\\mathrm{Var}(S_d)=E[S_d^{2}]$。\n    $$\n    \\mathrm{Var}(S_d) = E\\left[\\left(\\sum_{i=1}^{N}d_{i}\\right)\\left(\\sum_{j=1}^{N}d_{j}\\right)\\right] = \\sum_{i=1}^{N}\\sum_{j=1}^{N}E[d_{i}d_{j}]\n    $$\n    我们必须评估协方差项 $E[d_i d_j]$。设 $i \\le j$。我们有 $d_i = \\sum_{m=1}^{i}w_m$ 和 $d_j = \\sum_{l=1}^{j}w_l$。增量 $\\{w_m\\}$ 是独立的、零均值的，且方差为 $\\mathrm{Var}(w_m) = D\\Delta t$。这意味着 $E[w_m w_l] = \\delta_{ml} D\\Delta t$，其中 $\\delta_{ml}$ 是克罗内克 δ。\n    $$\n    E[d_{i}d_{j}] = E\\left[\\left(\\sum_{m=1}^{i}w_{m}\\right)\\left(\\sum_{l=1}^{j}w_{l}\\right)\\right] = \\sum_{m=1}^{i}\\sum_{l=1}^{j}E[w_{m}w_{l}] = \\sum_{m=1}^{i}\\sum_{l=1}^{j}\\delta_{ml}D\\Delta t = \\sum_{m=1}^{i} D\\Delta t = i D\\Delta t\n    $$\n    对任意 $i, j$ 进行推广，我们得到 $E[d_i d_j] = \\min(i,j)D\\Delta t$。将此代入方差表达式：\n    $$\n    \\mathrm{Var}(S_d) = \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\min(i,j)D\\Delta t = D\\Delta t \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\min(i,j)\n    $$\n    该双重求和可以计算为 $\\frac{N(N+1)(2N+1)}{6}$。\n    $$\n    \\mathrm{Var}(S_d) = D\\Delta t \\frac{N(N+1)(2N+1)}{6}\n    $$\n    那么，漂移对估计量方差的贡献是：\n    $$\n    \\mathrm{Var}_{d} = \\frac{1}{N^2}\\mathrm{Var}(S_d) = \\frac{D\\Delta t}{N^2}\\frac{N(N+1)(2N+1)}{6} = D\\Delta t \\frac{(N+1)(2N+1)}{6N}\n    $$\n\n最后，我们将所有分量组合起来，得到总均方误差：\n$$\nE[(z - \\hat{z})^{2}] = (E[z - \\hat{z}])^2 + \\mathrm{Var}(\\hat{z}) = b^2 + \\mathrm{Var}_{d} + \\mathrm{Var}_{\\epsilon} + \\mathrm{Var}_{\\eta}\n$$\n$$\nE[(z - \\hat{z})^{2}] = b^2 + D\\Delta t \\frac{(N+1)(2N+1)}{6N} + \\frac{\\sigma_{p}^{2}}{N} + \\frac{q^2}{12N}\n$$\n这个最终表达式是偏差、漂移、精密度和分辨率各自贡献的总和，符合题目要求。",
            "answer": "$$\n\\boxed{b^{2} + D\\Delta t \\frac{(N+1)(2N+1)}{6N} + \\frac{\\sigma_{p}^{2}}{N} + \\frac{q^{2}}{12N}}\n$$"
        },
        {
            "introduction": "获得连续的情境数据流后，下一个挑战是在有限的计算和内存资源下进行有效处理。本练习将指导您设计并实现一种适用于流数据的在线估计算法，该算法能在保证内存使用有界的同时，精确计算带偏差校正的指数加权均值和方差。掌握这种递归更新技术是开发能够在资源受限的边缘设备上运行的实时数字孪生和信息物理系统的关键技能。",
            "id": "4210079",
            "problem": "在一个具有关联数字孪生（Digital Twin）的上下文感知信息物理系统（CPS）中，流式上下文值 $x_t \\in \\mathbb{R}$ 在离散时间 $t = 1, 2, \\dots$ 依次到达。该数字孪生必须在严格的内存限制下，维护推理所需的统计数据。构建一个窗口化与保留策略，该策略需保证内存有界，同时为推理保留以下统计特性：具有指定半衰期的、经指数衰减和偏差校正的均值和方差估计。\n\n使用以下基本定义：\n- 时间 $t$ 的指数衰减权重定义为 $w_i^{(t)} = \\alpha (1 - \\alpha)^{t-i}$，其中 $i \\in \\{1, \\dots, t\\}$，衰减参数为 $\\alpha \\in (0, 1]$。\n- 半衰期 $H$ 与 $\\alpha$ 的关系为 $\\alpha = 1 - 2^{-1/H}$，因此经过 $H$ 个样本后，权重减半。\n- 时间 $t$ 的权重之和为 $S_t = \\sum_{i=1}^t w_i^{(t)} = 1 - (1 - \\alpha)^t$。\n- 时间 $t$ 的偏差校正指数加权均值和二阶矩为\n$$\n\\mu_t = \\frac{1}{S_t} \\sum_{i=1}^t w_i^{(t)} x_i, \\quad q_t = \\frac{1}{S_t} \\sum_{i=1}^t w_i^{(t)} x_i^2,\n$$\n偏差校正指数加权方差为\n$$\nv_t = q_t - \\mu_t^2.\n$$\n\n设计一个保留策略，该策略存储与流长度无关的恒定数量的状态变量。从上述核心定义出发，推导并实现单步递推关系，以便在每个时间点 $t$ 精确地更新所需统计量，且使用的标量数量不超过一个常数。窗口化必须实现指定的半衰期，保留策略必须保证内存有界。您的实现必须计算所有 $t$ 的 $(\\mu_t, v_t)$。\n\n测试套件和答案规范：\n实现程序以运行以下四个测试案例。在所有案例中，输出中不出现任何物理单位或角度；所有值都是无单位的。\n\n- 案例 A（正常路径和适应性检查）：\n  - 半衰期 $H = 20$。\n  - 流长度 $T = 500$。\n  - 上下文流 $x_t$：当 $t \\le 250$ 时，$x_t = 0$，当 $t > 250$ 时，$x_t = 1$（无噪声）。\n  - 对于 $\\mu_t$ 和 $v_t$ 与在每个 $t$ 使用权重 $w_i^{(t)}$ 和 $S_t$ 进行直接有限和计算的结果进行相等性检查时，容差 $\\varepsilon = 10^{-12}$。\n  - 此外，验证阶跃变化后未归一化均值累加器 $M_t = \\sum_{i=1}^t w_i^{(t)} x_i$ 的适应性。设 $t_0 = 250$，目标均值 $m^\\star = 1$，阈值 $\\eta = 10^{-3}$。差值 $|m^\\star - M_{t_0 + k}|$ 必须在满足递推关系所蕴含的几何衰减定律的第一个 $k$ 处降至 $\\eta$ 以下，即\n  $$\n  k_{\\text{pred}} = \\left\\lceil \\frac{\\log\\left(\\eta / |m^\\star - M_{t_0}|\\right)}{\\log(1 - \\alpha)} \\right\\rceil.\n  $$\n  检查观察到的 $k_{\\text{obs}}$ 与 $k_{\\text{pred}}$ 是否在 $\\pm 1$ 的范围内相等。\n  - 内存限制：确认算法在所有时间内最多使用 $3$ 个标量状态变量。\n\n- 案例 B（边界情况：近乎瞬时遗忘）：\n  - 半衰期 $H = 10^{-3}$（因此 $\\alpha \\approx 1$）。\n  - 流长度 $T = 200$。\n  - 上下文流 $x_t$：均值为零、标准差为 $0.1$ 的独立高斯噪声。\n  - 对于 $\\mu_t$ 和 $v_t$ 与直接有限和计算结果的相等性检查，容差 $\\varepsilon = 10^{-12}$。\n  - 内存限制：最多 $3$ 个标量状态变量。\n\n- 案例 C（边界情况：极长半衰期）：\n  - 半衰期 $H = 1000$。\n  - 流长度 $T = 2000$。\n  - 上下文流 $x_t$：$x_t = \\sin\\left(2\\pi t / 50\\right) + \\xi_t$，其中 $\\xi_t$ 是均值为零、标准差为 $0.01$ 的独立高斯噪声。\n  - 对于 $\\mu_t$ 和 $v_t$ 与直接有限和计算结果的相等性检查，容差 $\\varepsilon = 10^{-12}$。\n  - 内存限制：最多 $3$ 个标量状态变量。\n\n- 案例 D（边缘情况：恒定信号）：\n  - 半衰期 $H = 10$。\n  - 流长度 $T = 300$。\n  - 上下文流 $x_t = c$ 对所有 $t$ 成立，其中 $c = 3.14159$。\n  - 对于 $\\mu_t$ 和 $v_t$ 与直接有限和计算结果的相等性检查，容差 $\\varepsilon = 10^{-12}$。\n  - 内存限制：最多 $3$ 个标量状态变量。\n\n对于每个案例，程序必须生成一个布尔结果，指明是否同时满足以下所有标准：\n- 对于所有 $t$，满足 $|\\mu_t^{\\text{alg}} - \\mu_t^{\\text{ref}}| \\le \\varepsilon$ 和 $|v_t^{\\text{alg}} - v_t^{\\text{ref}}| \\le \\varepsilon$，其中 $\\mu_t^{\\text{ref}}$ 和 $v_t^{\\text{ref}}$ 是通过在每个 $t$ 使用 $w_i^{(t)}$ 和 $S_t$ 进行直接有限和计算得出的。\n- 内存限制条件成立。\n- 仅对于案例 A，适应性条件按规定成立。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表（例如，“[true_case_A,true_case_B,true_case_C,true_case_D]”）。每个元素都必须是布尔值。程序必须是完整的，并且不需要任何输入。",
            "solution": "问题陈述已经过严格验证，并被确定为有效。它具有科学依据，定义明确，客观，并包含一套完整且一致的定义和约束。该问题要求推导并实现一个数值精确、常数内存的递归算法，用于从数据流中计算经偏差校正的指数加权统计量。这是信号处理中的一项标准且重要的任务，也是数字孪生和信息物理系统的基本组成部分。\n\n任务的核心是将偏差校正均值和方差的批量定义转换为单步递推形式。提供的定义如下：\n- 指数衰减权重：$w_i^{(t)} = \\alpha (1 - \\alpha)^{t-i}$，其中 $i \\in \\{1, \\dots, t\\}$。\n- 权重之和：$S_t = \\sum_{i=1}^t w_i^{(t)} = 1 - (1 - \\alpha)^t$。\n- 偏差校正均值：$\\mu_t = \\frac{1}{S_t} \\sum_{i=1}^t w_i^{(t)} x_i$。\n- 偏差校正二阶矩：$q_t = \\frac{1}{S_t} \\sum_{i=1}^t w_i^{(t)} x_i^2$。\n- 偏差校正方差：$v_t = q_t - \\mu_t^2$。\n\n为实现常数内存（有界内存）的解决方案，我们必须避免存储数据流的整个历史记录 $\\{x_1, \\dots, x_t\\}$。这需要推导一个更新规则，该规则仅使用新的数据点 $x_t$ 和来自时间 $t-1$ 的固定数量的状态变量来计算时间 $t$ 的统计量。\n\n让我们定义未归一化的指数加权和（或均值累加器）$M_t$ 和未归一化的指数加权平方和 $Q_t$：\n$$\nM_t = \\sum_{i=1}^t w_i^{(t)} x_i = \\sum_{i=1}^t \\alpha (1 - \\alpha)^{t-i} x_i\n$$\n$$\nQ_t = \\sum_{i=1}^t w_i^{(t)} x_i^2 = \\sum_{i=1}^t \\alpha (1 - \\alpha)^{t-i} x_i^2\n$$\n通过这些定义，偏差校正的统计量可以表示为 $\\mu_t = M_t / S_t$ 和 $v_t = (Q_t / S_t) - (M_t / S_t)^2$。现在问题简化为寻找 $M_t$、$Q_t$ 和 $S_t$ 的递归更新。\n\n首先，让我们推导 $M_t$ 的递归关系。我们展开时间 $t$ 的和：\n$$\nM_t = \\alpha (1 - \\alpha)^{t-t} x_t + \\sum_{i=1}^{t-1} \\alpha (1 - \\alpha)^{t-i} x_i\n$$\n$$\nM_t = \\alpha x_t + (1 - \\alpha) \\sum_{i=1}^{t-1} \\alpha (1 - \\alpha)^{(t-1)-i} x_i\n$$\n求和项恰好是 $M_{t-1}$ 的定义。这得出了未归一化均值累加器的单步递推关系：\n$$\nM_t = (1 - \\alpha) M_{t-1} + \\alpha x_t\n$$\n这是指数加权移动平均的经典递推关系。初始条件为 $M_0 = 0$。\n\n未归一化二阶矩累加器 $Q_t$ 的推导遵循完全相同的代数模式。我们将 $x_i$ 替换为 $x_i^2$：\n$$\nQ_t = \\sum_{i=1}^t \\alpha (1 - \\alpha)^{t-i} x_i^2\n$$\n$$\nQ_t = \\alpha x_t^2 + (1 - \\alpha) \\sum_{i=1}^{t-1} \\alpha (1 - \\alpha)^{(t-1)-i} x_i^2\n$$\n识别出求和项为 $Q_{t-1}$，我们得到递推关系：\n$$\nQ_t = (1 - \\alpha) Q_{t-1} + \\alpha x_t^2\n$$\n初始条件为 $Q_0 = 0$。\n\n最后，我们需要偏差校正因子 $S_t$ 的更新。我们可以从其闭式表达式 $S_t = 1 - (1 - \\alpha)^t$ 推导出来：\n$$\nS_t = 1 - (1-\\alpha)(1-\\alpha)^{t-1}\n$$\n因为 $S_{t-1} = 1 - (1-\\alpha)^{t-1}$，所以有 $(1-\\alpha)^{t-1} = 1 - S_{t-1}$。将其代入 $S_t$ 的方程中：\n$$\nS_t = 1 - (1-\\alpha)(1 - S_{t-1}) = 1 - (1 - \\alpha) + (1 - \\alpha) S_{t-1}\n$$\n$$\nS_t = \\alpha + (1 - \\alpha) S_{t-1}\n$$\n初始条件为 $S_0 = 0$。这个递推关系与 $M_t$ 和 $Q_t$ 的形式相同，对应于输入信号恒为 $1$ 的情况。\n\n完整的保留策略和更新算法如下：\n1.  初始化状态变量：$M_0 = 0$，$Q_0 = 0$，$S_0 = 0$。\n2.  在每个时间步 $t=1, 2, \\dots$，当新的上下文值 $x_t$ 到达时：\n    a. 使用来自步骤 $t-1$ 的值更新三个状态变量：\n       $$ M_t \\leftarrow (1-\\alpha) M_{t-1} + \\alpha x_t $$\n       $$ Q_t \\leftarrow (1-\\alpha) Q_{t-1} + \\alpha x_t^2 $$\n       $$ S_t \\leftarrow (1-\\alpha) S_{t-1} + \\alpha $$\n    b. 计算时间 $t$ 的偏差校正统计量：\n       $$ \\mu_t = M_t / S_t $$\n       $$ v_t = (Q_t / S_t) - \\mu_t^2 $$\n\n该算法满足所有设计要求。它由单步递推关系组成。在任何时间 $t$ 所需的状态完全由三元组 $(M_t, Q_t, S_t)$ 捕获，该三元组仅包含三个标量变量。这保证了有界的内存占用，与流长度 $T$ 无关。“窗口化”方面由指数加权方案隐式处理，有效窗口大小由半衰期 $H$ 通过衰减参数 $\\alpha = 1 - 2^{-1/H}$ 确定。“保留策略”是指仅存储和更新三个标量累加器的过程。这个推导出的算法是数值精确的，其提供的结果与直接有限和定义在代数上是等价的，仅受浮点精度限制。实现将使用此算法，并针对所提供的测试案例，通过与直接求和公式的对比来验证其正确性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(H, T, x_stream, epsilon, special_checks=None):\n    \"\"\"\n    Runs a single test case for the recursive statistical algorithm.\n\n    Args:\n        H (float): The half-life for the exponential decay.\n        T (int): The total length of the context stream.\n        x_stream (np.ndarray): The array of context values.\n        epsilon (float): The tolerance for equality checks.\n        special_checks (dict, optional): A dictionary for case-specific checks.\n\n    Returns:\n        bool: True if all checks pass, False otherwise.\n    \"\"\"\n    if H = 0:\n        return False  # Half-life must be positive\n    alpha = 1.0 - 2.0**(-1.0 / H)\n    one_minus_alpha = 1.0 - alpha\n\n    # --- Algorithmic (Recursive) Calculation ---\n    # The state is defined by 3 scalar variables: M_alg, Q_alg, S_alg.\n    # This satisfies the memory bound of at most 3 scalars.\n    M_alg, Q_alg, S_alg = 0.0, 0.0, 0.0\n    alg_results = []\n    for t in range(1, T + 1):\n        x = x_stream[t - 1]\n        \n        M_alg = one_minus_alpha * M_alg + alpha * x\n        Q_alg = one_minus_alpha * Q_alg + alpha * x**2\n        S_alg = one_minus_alpha * S_alg + alpha\n\n        # Avoid division by zero, although S_alg > 0 for t >= 1\n        mu_alg = M_alg / S_alg if S_alg > 0 else 0.0\n        # Ensure variance is non-negative against floating point artifacts\n        v_alg = max(0.0, (Q_alg / S_alg) - mu_alg**2 if S_alg > 0 else 0.0)\n        \n        alg_results.append({'mu': mu_alg, 'v': v_alg, 'M': M_alg})\n\n    # --- Reference (Direct Finite Sum) Calculation  Verification ---\n    for t in range(1, T + 1):\n        # Generate weights w_i^(t) = alpha * (1-alpha)^(t-i) for i=1,...,t\n        powers = np.arange(t - 1, -1, -1, dtype=float)\n        w = alpha * np.power(one_minus_alpha, powers)\n\n        current_x_stream = x_stream[:t]\n\n        S_ref = np.sum(w)\n        \n        # Check against closed-form S_t to ensure w is correct\n        S_ref_closed = 1.0 - one_minus_alpha**t\n        if not np.isclose(S_ref, S_ref_closed):\n             # This would indicate a flaw in the reference calculation itself\n             return False\n\n        if S_ref == 0:\n            mu_ref, v_ref = 0.0, 0.0\n        else:\n            M_ref = np.sum(w * current_x_stream)\n            Q_ref = np.sum(w * (current_x_stream**2))\n            mu_ref = M_ref / S_ref\n            v_ref = (Q_ref / S_ref) - mu_ref**2\n\n        # Comparison\n        mu_alg_t = alg_results[t - 1]['mu']\n        v_alg_t = alg_results[t - 1]['v']\n\n        if not (abs(mu_alg_t - mu_ref) = epsilon and abs(v_alg_t - v_ref) = epsilon):\n            return False  # Verification of mu_t or v_t failed\n\n    # --- Special Case-Specific Checks ---\n    if special_checks:\n        if special_checks['case_name'] == 'A':\n            t0 = special_checks['t0']\n            m_star = special_checks['m_star']\n            eta = special_checks['eta']\n\n            M_t0 = alg_results[t0 - 1]['M']\n            \n            # The denominator approaches 0 if M_t0 is very close to m_star\n            if abs(m_star - M_t0)  1e-15:\n                # If already at the target, k_pred is not well-defined/needed.\n                # However, for this problem, M_t0=0 and m_star=1.\n                pass\n            \n            log_arg_numerator = eta / abs(m_star - M_t0)\n            log_arg_denominator = np.log(one_minus_alpha)\n\n            # Check for domain errors, though not expected with given params\n            if log_arg_numerator = 0 or log_arg_denominator >= 0:\n                return False\n\n            k_pred = int(np.ceil(np.log(log_arg_numerator) / log_arg_denominator))\n\n            # Find observed k\n            k_obs = -1\n            for k_test in range(1, T - t0 + 1):\n                M_t0_plus_k = alg_results[t0 + k_test - 1]['M']\n                if abs(m_star - M_t0_plus_k)  eta:\n                    k_obs = k_test\n                    break\n            \n            if k_obs == -1: # Threshold not reached\n                return False\n                \n            if not(abs(k_obs - k_pred) = 1):\n                return False\n\n    return True # All checks passed for this case\n\ndef solve():\n    # Set a seed for reproducibility of random streams\n    np.random.seed(0)\n\n    # === Case A: Happy path and adaptation check ===\n    T_A = 500\n    x_A = np.zeros(T_A, dtype=float)\n    x_A[250:] = 1.0\n    case_A_params = {\n        'H': 20.0, 'T': T_A, 'x_stream': x_A, 'epsilon': 1e-12,\n        'special_checks': {\n            'case_name': 'A', 't0': 250, 'm_star': 1.0, 'eta': 1e-3\n        }\n    }\n\n    # === Case B: Boundary - near-instantaneous forgetting ===\n    T_B = 200\n    x_B = np.random.normal(loc=0.0, scale=0.1, size=T_B)\n    case_B_params = {'H': 1e-3, 'T': T_B, 'x_stream': x_B, 'epsilon': 1e-12}\n\n    # === Case C: Boundary - extremely long half-life ===\n    T_C = 2000\n    t_C = np.arange(1, T_C + 1, dtype=float)\n    noise_C = np.random.normal(loc=0.0, scale=0.01, size=T_C)\n    x_C = np.sin(2.0 * np.pi * t_C / 50.0) + noise_C\n    case_C_params = {'H': 1000.0, 'T': T_C, 'x_stream': x_C, 'epsilon': 1e-12}\n\n    # === Case D: Edge - constant signal ===\n    T_D = 300\n    x_D = np.full(T_D, 3.14159, dtype=float)\n    case_D_params = {'H': 10.0, 'T': T_D, 'x_stream': x_D, 'epsilon': 1e-12}\n\n    test_cases = [case_A_params, case_B_params, case_C_params, case_D_params]\n    \n    results = []\n    for params in test_cases:\n        passed = run_case(\n            H=params['H'],\n            T=params['T'],\n            x_stream=params['x_stream'],\n            epsilon=params['epsilon'],\n            special_checks=params.get('special_checks')\n        )\n        results.append(str(passed).lower())\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "情境感知的最终目标是驱动更智能、更安全的决策。这个高级练习将理论与实践相结合，探讨了如何在不确定性下制定最优的控制策略。您将基于贝叶斯推断来更新对一个潜在情境变量的认知，并在此基础上，通过求解一个带机会约束的优化问题，来确定一个既能实现预期效用（如节约能源）又能保证安全阈值不被突破的最优决策边界。",
            "id": "4210115",
            "problem": "一个建筑物的供暖、通风和空调 (HVAC) 控制器是一个信息物理系统 (CPS) 的一部分，该系统配备了一个执行上下文感知能源管理的数字孪生 (DT)。在每个决策时刻，DT 对一个潜在的上下文变量 $X$（无量纲）进行建模，该变量表示如果启用节能模式时将剩余的热安全裕度。$X$ 的先验模型是高斯分布，即 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$。一个传感器根据 $Y = X + W$ 提供 $X$ 的带噪测量值 $Y$，其中 $W \\sim \\mathcal{N}(0, \\tau^{2})$ 且独立于 $X$。控制器选择一个动作 $a \\in \\{0,1\\}$，其中 $a=1$ 表示启用节能模式，$a=0$ 表示保持标称运行。\n\n如果在启用节能模式时，实际裕度 $X$ 低于一个固定的风险阈值 $x_{h}$，即当 $a=1$ 且 $X \\leq x_{h}$ 时，就会发生安全风险。控制器必须满足一个基于观测上下文的机会约束：每当它基于 $Y=y$ 启用节能模式时，条件风险概率必须至多为一个预定水平 $\\alpha \\in (0,1)$，即对于每个选择 $a=1$ 的 $y$，必须满足 $$\\mathbb{P}\\!\\left(X \\leq x_{h} \\,\\middle|\\, Y=y\\right) \\leq \\alpha$$。\n\n瞬时损失函数为 $\\ell(a) = c_{1}\\,\\mathbf{1}\\{a=1\\} + c_{0}\\,\\mathbf{1}\\{a=0\\}$，其中常数 $c_1  c_0$，因此启用节能模式会严格减少损失。在作为 $Y$ 的可测函数的上下文感知策略中，考虑形式为 $a(y) = \\mathbf{1}\\{y \\geq t\\}$ 的阈值策略，其中 $t$ 是一个阈值。从条件概率和高斯模型的贝叶斯推断的基本定义出发，推导在满足上述机会约束的条件下最小化期望损失的最优阈值 $t^{\\star}$。请用一个包含 $\\mu$、$\\sigma$、$\\tau$、$x_{h}$ 和 $\\alpha$ 的单一闭式解析表达式给出你的最终结果 $t^{\\star}$。不需要进行数值计算，并且所有变量都是无量纲的。",
            "solution": "数字孪生 (DT) 必须选择一个上下文感知策略，该策略在满足条件风险的机会约束的同时最小化期望损失。由于 $a=1$ 的瞬时损失低于 $a=0$（因为 $c_1  c_0$），最优策略将在满足机会约束的最大可能测量值 $y$ 集合上启用节能模式。在阈值策略 $a(y) = \\mathbf{1}\\{y \\geq t\\}$ 下，这意味着选择最小的阈值 $t$，使得对于所有 $y \\geq t$，机会约束都成立。\n\n我们从基本定义开始。机会约束要求，对于每个选择 $a=1$ 的 $y$，\n$$\n\\mathbb{P}\\!\\left(X \\leq x_{h} \\,\\middle|\\, Y=y\\right) \\leq \\alpha.\n$$\n根据贝叶斯法则和线性高斯测量模型 $Y = X + W$（其中 $W \\sim \\mathcal{N}(0, \\tau^{2})$ 且独立于 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$），后验分布 $X \\mid Y=y$ 是高斯分布。标准的推导方法是使用高斯密度 $p(y \\mid x)$ 和 $p(x)$ 中指数的乘积，并通过对 $x$ 配方来确定后验均值和方差。具体来说，后验分布 $X \\mid Y=y$ 为\n$$\nX \\mid Y=y \\sim \\mathcal{N}\\!\\left(m(y), v\\right),\n$$\n其中\n$$\nm(y) = \\mu + K\\,(y - \\mu), \\quad K = \\frac{\\sigma^{2}}{\\sigma^{2} + \\tau^{2}}, \\quad v = \\frac{\\sigma^{2}\\,\\tau^{2}}{\\sigma^{2} + \\tau^{2}}.\n$$\n因此，条件风险概率为\n$$\n\\mathbb{P}\\!\\left(X \\leq x_{h} \\,\\middle|\\, Y=y\\right) = \\Phi\\!\\left(\\frac{x_{h} - m(y)}{\\sqrt{v}}\\right),\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。机会约束 $\\mathbb{P}(X \\leq x_{h} \\mid Y=y) \\leq \\alpha$ 等价于\n$$\n\\Phi\\!\\left(\\frac{x_{h} - m(y)}{\\sqrt{v}}\\right) \\leq \\alpha,\n$$\n并且由于 $\\Phi$ 是严格递增的，这个不等式等价于\n$$\n\\frac{x_{h} - m(y)}{\\sqrt{v}} \\leq z_{\\alpha},\n$$\n其中 $z_{\\alpha} = \\Phi^{-1}(\\alpha)$ 是标准正态分布的 $\\alpha$-分位数。整理可得\n$$\nm(y) \\geq x_{h} - z_{\\alpha}\\,\\sqrt{v}.\n$$\n因为 $m(y)$ 是一个斜率为 $K \\in (0,1)$ 的仿射、严格递增函数，所以满足机会约束的 $y$ 的集合是一个形如 $[t, \\infty)$ 的区间，其中 $t$ 是使不等式取等的最小 $y$ 值。在阈值 $y=t$ 处强制等式成立，\n$$\nm(t) = \\mu + K\\,(t - \\mu) = x_{h} - z_{\\alpha}\\,\\sqrt{v}.\n$$\n求解 $t$，可得\n$$\nK\\,(t - \\mu) = x_{h} - z_{\\alpha}\\,\\sqrt{v} - \\mu\n\\quad \\Longrightarrow \\quad\nt = \\mu + \\frac{1}{K}\\,\\bigl(x_{h} - z_{\\alpha}\\,\\sqrt{v} - \\mu\\bigr).\n$$\n代入 $K = \\sigma^{2}/(\\sigma^{2} + \\tau^{2})$ 和 $\\sqrt{v} = \\sigma\\,\\tau / \\sqrt{\\sigma^{2} + \\tau^{2}}$，得到\n$$\nt^{\\star} = \\mu + \\frac{\\sigma^{2} + \\tau^{2}}{\\sigma^{2}}\\,\\left(x_{h} - \\mu - z_{\\alpha}\\,\\frac{\\sigma\\,\\tau}{\\sqrt{\\sigma^{2} + \\tau^{2}}}\\right).\n$$\n这个 $t^{\\star}$ 是确保对于所有 $y \\geq t^{\\star}$，条件风险概率至多为 $\\alpha$ 的最小阈值。由于启用节能模式会严格减少损失 ($c_1  c_0$)，在满足机会约束的条件下最小化期望损失的最优策略是：当 $y \\geq t^{\\star}$ 时启用该模式，否则不启用。因此，最优阈值 $t^{\\star}$ 由上述闭式表达式给出。",
            "answer": "$$\\boxed{\\mu + \\frac{\\sigma^{2} + \\tau^{2}}{\\sigma^{2}}\\left(x_{h} - \\mu - \\Phi^{-1}(\\alpha)\\,\\frac{\\sigma\\,\\tau}{\\sqrt{\\sigma^{2} + \\tau^{2}}}\\right)}$$"
        }
    ]
}