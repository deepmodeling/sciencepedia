{
    "hands_on_practices": [
        {
            "introduction": "The numerical stability of a co-simulation is a primary concern, as the coupling of individually stable simulators can surprisingly lead to an unstable overall system. This exercise provides a foundational analysis of this phenomenon by examining a simple, linearly coupled system . By deriving the discrete-time co-simulation update matrix and analyzing its eigenvalues, you will determine the maximum macro-step size $H$ that guarantees stability, providing a crucial skill for designing and debugging co-simulation workflows.",
            "id": "4208719",
            "problem": "A digital twin of a linear resistive-capacitive network is partitioned into two heterogeneous simulators that are co-simulated using a Jacobi scheme with a macro-step size $H$. Subsystem $1$ consists of a capacitor $C_{1}$ to ground and a conductance $G_{1}$ to ground, with boundary node voltage $V_{1}(t)$. Subsystem $2$ consists of a capacitor $C_{2}$ to ground and a conductance $G_{2}$ to ground, with boundary node voltage $V_{2}(t)$. The two subsystems are interconnected by a conductance $G_{c}$ between their boundary nodes, so that the continuous-time nodal dynamics follow Kirchhoff’s Current Law (KCL). Each simulator integrates its subsystem with the neighbor’s boundary voltage held constant over each macro-step due to zero-order hold exchange. Each subsystem advances over the macro-step with explicit Euler.\n\nStarting from KCL and the definition of explicit Euler, construct the discrete-time interconnection map that advances the boundary voltages $\\begin{pmatrix} V_{1}^{n} \\\\ V_{2}^{n} \\end{pmatrix}$ at $t_{n}$ to $\\begin{pmatrix} V_{1}^{n+1} \\\\ V_{2}^{n+1} \\end{pmatrix}$ at $t_{n+1} = t_{n} + H$. Using eigenvalue analysis of this $2 \\times 2$ discrete update, derive the largest macro-step $H_{\\max}$ such that the spectral radius of the update matrix is strictly less than $1$. Express your final answer as a single closed-form analytic expression for $H_{\\max}$ in terms of $C_{1}$, $C_{2}$, $G_{1}$, $G_{2}$, and $G_{c}$. Express $H_{\\max}$ in seconds. Do not include units in the boxed final answer.",
            "solution": "The first step is to establish the continuous-time ordinary differential equations (ODEs) that govern the system dynamics using Kirchhoff’s Current Law (KCL) at the two boundary nodes.\n\nAt node $1$, the sum of currents flowing out of the node must be zero. The current through the capacitor $C_1$ is $C_1 \\frac{dV_1}{dt}$, the current through the conductance $G_1$ to ground is $G_1 V_1$, and the current through the coupling conductance $G_c$ is $G_c(V_1 - V_2)$. Applying KCL at node $1$:\n$$ C_1 \\frac{dV_1}{dt} + G_1 V_1 + G_c (V_1 - V_2) = 0 $$\nRearranging for $\\frac{dV_1}{dt}$:\n$$ \\frac{dV_1}{dt} = - \\frac{G_1 + G_c}{C_1} V_1 + \\frac{G_c}{C_1} V_2 $$\n\nSimilarly, at node $2$, the sum of currents flowing out of the node must be zero. The current through the capacitor $C_2$ is $C_2 \\frac{dV_2}{dt}$, the current through the conductance $G_2$ to ground is $G_2 V_2$, and the current through the coupling conductance $G_c$ is $G_c(V_2 - V_1)$. Applying KCL at node $2$:\n$$ C_2 \\frac{dV_2}{dt} + G_2 V_2 + G_c (V_2 - V_1) = 0 $$\nRearranging for $\\frac{dV_2}{dt}$:\n$$ \\frac{dV_2}{dt} = \\frac{G_c}{C_2} V_1 - \\frac{G_2 + G_c}{C_2} V_2 $$\n\nThe problem specifies a Jacobi co-simulation scheme with a macro-step size $H$. In this scheme, each subsystem is integrated over the interval $[t_n, t_{n+1}]$ using the boundary values from the neighboring subsystem at the beginning of the interval, $t_n$. This is a zero-order hold (ZOH) on the coupling variables. The integrator used within each subsystem is explicit Euler.\n\nFor subsystem $1$, the ODE to be integrated over $[t_n, t_{n+1}]$ treats $V_2$ as a constant equal to $V_2^n = V_2(t_n)$:\n$$ \\frac{dV_1}{dt} = - \\frac{G_1 + G_c}{C_1} V_1 + \\frac{G_c}{C_1} V_2^n $$\nApplying the explicit Euler method, $y_{k+1} = y_k + h f(t_k, y_k)$, with a step size $H = t_{n+1} - t_n$:\n$$ V_1^{n+1} = V_1^n + H \\left( - \\frac{G_1 + G_c}{C_1} V_1^n + \\frac{G_c}{C_1} V_2^n \\right) $$\n$$ V_1^{n+1} = \\left( 1 - H \\frac{G_1 + G_c}{C_1} \\right) V_1^n + \\left( H \\frac{G_c}{C_1} \\right) V_2^n $$\n\nFor subsystem $2$, the ODE to be integrated treats $V_1$ as a constant equal to $V_1^n = V_1(t_n)$:\n$$ \\frac{dV_2}{dt} = \\frac{G_c}{C_2} V_1^n - \\frac{G_2 + G_c}{C_2} V_2 $$\nApplying the explicit Euler method with step size $H$:\n$$ V_2^{n+1} = V_2^n + H \\left( \\frac{G_c}{C_2} V_1^n - \\frac{G_2 + G_c}{C_2} V_2^n \\right) $$\n$$ V_2^{n+1} = \\left( H \\frac{G_c}{C_2} \\right) V_1^n + \\left( 1 - H \\frac{G_2 + G_c}{C_2} \\right) V_2^n $$\n\nThese two discrete-time equations can be written in matrix form, which defines the interconnection map from the state at time $t_n$ to the state at time $t_{n+1}$:\n$$ \\begin{pmatrix} V_1^{n+1} \\\\ V_2^{n+1} \\end{pmatrix} = \\begin{pmatrix} 1 - H \\frac{G_1 + G_c}{C_1}  H \\frac{G_c}{C_1} \\\\ H \\frac{G_c}{C_2}  1 - H \\frac{G_2 + G_c}{C_2} \\end{pmatrix} \\begin{pmatrix} V_1^n \\\\ V_2^n \\end{pmatrix} $$\nLet the update matrix be $M$. The co-simulation is stable if and only if the spectral radius of $M$, $\\rho(M)$, is strictly less than $1$. The spectral radius is the maximum absolute value of the eigenvalues of $M$. Let's find the eigenvalues $\\lambda$ of $M$ by solving the characteristic equation $\\det(M - \\lambda I) = 0$.\nTo simplify the notation, let:\n$a = \\frac{G_1+G_c}{C_1}$, $b = \\frac{G_c}{C_1}$, $c = \\frac{G_c}{C_2}$, $d = \\frac{G_2+G_c}{C_2}$. The matrix $M$ is:\n$$ M = \\begin{pmatrix} 1 - Ha  Hb \\\\ Hc  1 - Hd \\end{pmatrix} $$\nThe characteristic equation is:\n$$ \\det \\begin{pmatrix} 1 - Ha - \\lambda  Hb \\\\ Hc  1 - Hd - \\lambda \\end{pmatrix} = 0 $$\n$$ (1 - Ha - \\lambda)(1 - Hd - \\lambda) - H^2bc = 0 $$\n$$ \\lambda^2 - (2 - H(a+d))\\lambda + (1 - H(a+d) + H^2ad - H^2bc) = 0 $$\nThe solutions for $\\lambda$ are given by the quadratic formula:\n$$ \\lambda = \\frac{2 - H(a+d) \\pm \\sqrt{(2 - H(a+d))^2 - 4(1 - H(a+d) + H^2(ad - bc))}}{2} $$\nThe term under the square root simplifies to:\n$$ (4 - 4H(a+d) + H^2(a+d)^2) - (4 - 4H(a+d) + 4H^2(ad - bc)) = H^2((a+d)^2 - 4ad + 4bc) = H^2((a-d)^2 + 4bc) $$\nSo, the eigenvalues are:\n$$ \\lambda = \\frac{2 - H(a+d) \\pm H\\sqrt{(a-d)^2 + 4bc}}{2} $$\n$$ \\lambda = 1 - \\frac{H}{2}(a+d) \\pm \\frac{H}{2}\\sqrt{(a-d)^2 + 4bc} $$\nSince all physical parameters $C_1, C_2, G_1, G_2, G_c$ are non-negative, the terms $a, b, c, d$ are non-negative. The term under the square root is positive, so the eigenvalues are real. Let $k = \\sqrt{(a-d)^2 + 4bc}$.\nThe two eigenvalues are $\\lambda_1 = 1 - \\frac{H}{2}(a+d-k)$ and $\\lambda_2 = 1 - \\frac{H}{2}(a+d+k)$.\nFor stability, we require $|\\lambda_i|  1$ for $i=1, 2$, which for real eigenvalues means $-1  \\lambda_i  1$.\n\nWe can show that $a+d-k > 0$ because $(a+d)^2 = (a-d)^2+4ad > (a-d)^2+4bc = k^2$ (since $ad>bc$). Thus, $a+d>k$. This implies that for $H>0$, both $\\frac{H}{2}(a+d-k)$ and $\\frac{H}{2}(a+d+k)$ are positive, and thus both eigenvalues are less than $1$. The stability is limited by the lower bound, i.e., $\\lambda_i  -1$.\n\nThe condition for $\\lambda_1$ is:\n$$ 1 - \\frac{H}{2}(a+d-k)  -1 \\implies 2  \\frac{H}{2}(a+d-k) \\implies H  \\frac{4}{a+d-k} $$\nThe condition for $\\lambda_2$ is:\n$$ 1 - \\frac{H}{2}(a+d+k)  -1 \\implies 2  \\frac{H}{2}(a+d+k) \\implies H  \\frac{4}{a+d+k} $$\nSince $k0$, we have $a+d+k  a+d-k$, which implies $\\frac{4}{a+d+k}  \\frac{4}{a+d-k}$. The stability region for $H$ must satisfy both inequalities, so it is constrained by the stricter one. The largest macro-step $H_{\\max}$ is therefore given by the smaller of the two bounds:\n$$ H_{\\max} = \\frac{4}{a+d+k} $$\nSubstituting back the expressions for $a, d,$ and $k$:\n$$ H_{\\max} = \\frac{4}{(a+d) + \\sqrt{(a-d)^2 + 4bc}} $$\n$$ H_{\\max} = \\frac{4}{\\left(\\frac{G_1+G_c}{C_1} + \\frac{G_2+G_c}{C_2}\\right) + \\sqrt{\\left(\\frac{G_1+G_c}{C_1} - \\frac{G_2+G_c}{C_2}\\right)^2 + 4\\left(\\frac{G_c}{C_1}\\right)\\left(\\frac{G_c}{C_2}\\right)}} $$\nThis expression can be written as:\n$$ H_{\\max} = \\frac{4}{\\left(\\frac{G_1+G_c}{C_1} + \\frac{G_2+G_c}{C_2}\\right) + \\sqrt{\\left(\\frac{G_1+G_c}{C_1} - \\frac{G_2+G_c}{C_2}\\right)^2 + \\frac{4G_c^2}{C_1 C_2}}} $$\nThis is the final closed-form expression for the maximum stable macro-step size $H_{\\max}$. The units of $G/C$ are $1/s$, so the expression for $H_{\\max}$ correctly yields units of seconds.",
            "answer": "$$\\boxed{\\frac{4}{\\left(\\frac{G_{1}+G_{c}}{C_{1}} + \\frac{G_{2}+G_{c}}{C_{2}}\\right) + \\sqrt{\\left(\\frac{G_{1}+G_{c}}{C_{1}} - \\frac{G_{2}+G_{c}}{C_{2}}\\right)^{2} + \\frac{4G_{c}^{2}}{C_{1} C_{2}}}}}$$"
        },
        {
            "introduction": "In many real-world systems, subsystems exhibit instantaneous dependencies, creating algebraic loops that must be resolved at each co-simulation step. This practice introduces a powerful and widely-used technique for this challenge: a Newton-Raphson iteration based on interface Jacobians . You will construct the Newton step for a generic coupled system, gaining insight into how to achieve rapid convergence to a consistent interface solution for tightly coupled models.",
            "id": "4208753",
            "problem": "Consider a co-simulation of two heterogeneous simulators, denoted subsystem $\\mathcal{A}$ and subsystem $\\mathcal{B}$, coupled via a direct-feedthrough algebraic loop at each macro-step in a Digital Twin co-simulation framework. At a fixed macro-step $k$, each subsystem provides an instantaneous interface output that depends on the current interface input and its internal macro-step state, modeled as $y_{\\mathcal{A}} = \\phi_{\\mathcal{A}}(u_{\\mathcal{A}}; x_{\\mathcal{A}}(k))$ and $y_{\\mathcal{B}} = \\phi_{\\mathcal{B}}(u_{\\mathcal{B}}; x_{\\mathcal{B}}(k))$, where $x_{\\mathcal{A}}(k)$ and $x_{\\mathcal{B}}(k)$ are fixed parameters for this macro-step. The algebraic loop closure is $u_{\\mathcal{A}} = y_{\\mathcal{B}}$ and $u_{\\mathcal{B}} = y_{\\mathcal{A}}$. Assume $\\phi_{\\mathcal{A}}$ and $\\phi_{\\mathcal{B}}$ are continuously differentiable in their input arguments near the sought consistent solution.\n\nDefine the residual mapping\n$$\nF(y_{\\mathcal{A}}, y_{\\mathcal{B}}) \\;=\\; \\begin{pmatrix}\ny_{\\mathcal{A}} - \\phi_{\\mathcal{A}}(y_{\\mathcal{B}}; x_{\\mathcal{A}}(k)) \\\\\ny_{\\mathcal{B}} - \\phi_{\\mathcal{B}}(y_{\\mathcal{A}}; x_{\\mathcal{B}}(k))\n\\end{pmatrix},\n$$\nand its interface Jacobian\n$$\nJ(y_{\\mathcal{A}}, y_{\\mathcal{B}}) \\;=\\; \\frac{\\partial F}{\\partial (y_{\\mathcal{A}}, y_{\\mathcal{B}})} \\;=\\; \\begin{pmatrix}\n1  -\\dfrac{\\partial \\phi_{\\mathcal{A}}}{\\partial u_{\\mathcal{A}}}(y_{\\mathcal{B}}; x_{\\mathcal{A}}(k)) \\\\\n-\\dfrac{\\partial \\phi_{\\mathcal{B}}}{\\partial u_{\\mathcal{B}}}(y_{\\mathcal{A}}; x_{\\mathcal{B}}(k))  1\n\\end{pmatrix}.\n$$\nConstruct the Newton iteration that uses the interface Jacobian to solve the algebraic loop at each macro-step, by deriving a closed-form analytic expression for the Newton step $\\Delta y = (\\Delta y_{\\mathcal{A}}, \\Delta y_{\\mathcal{B}})$ at a generic iteration $m$, which solves\n$$\nJ(y_{\\mathcal{A}}^{(m)}, y_{\\mathcal{B}}^{(m)}) \\, \\Delta y^{(m)} \\;=\\; -F(y_{\\mathcal{A}}^{(m)}, y_{\\mathcal{B}}^{(m)}).\n$$\nIntroduce the shorthand\n$$\nF_1 \\;=\\; y_{\\mathcal{A}}^{(m)} - \\phi_{\\mathcal{A}}(y_{\\mathcal{B}}^{(m)}; x_{\\mathcal{A}}(k)), \\quad\nF_2 \\;=\\; y_{\\mathcal{B}}^{(m)} - \\phi_{\\mathcal{B}}(y_{\\mathcal{A}}^{(m)}; x_{\\mathcal{B}}(k)),\n$$\n$$\n\\alpha \\;=\\; \\left.\\dfrac{\\partial \\phi_{\\mathcal{A}}}{\\partial u_{\\mathcal{A}}}\\right|_{u_{\\mathcal{A}} = y_{\\mathcal{B}}^{(m)}} \\!, \\quad\n\\beta \\;=\\; \\left.\\dfrac{\\partial \\phi_{\\mathcal{B}}}{\\partial u_{\\mathcal{B}}}\\right|_{u_{\\mathcal{B}} = y_{\\mathcal{A}}^{(m)}}.\n$$\nExpress the Newton step $\\Delta y^{(m)}$ in terms of $F_1$, $F_2$, $\\alpha$, and $\\beta$.\n\nIn addition, from first principles of Newton’s method, state the conditions under which the iteration exhibits local quadratic convergence for this algebraic loop solve in the co-simulation context, considering smoothness and invertibility properties of the interface Jacobian and the proximity of the initial guess to the consistent solution.\n\nProvide the final answer as a single analytic expression for the Newton step vector $\\Delta y^{(m)}$ written as a row matrix in terms of $F_1$, $F_2$, $\\alpha$, and $\\beta$. No numerical approximation or rounding is required, and no physical units apply to this expression.",
            "solution": "The task is to solve the linear system defined by the Newton iteration for the step $\\Delta y^{(m)}$. The system is given by:\n$$\nJ(y_{\\mathcal{A}}^{(m)}, y_{\\mathcal{B}}^{(m)}) \\, \\Delta y^{(m)} \\;=\\; -F(y_{\\mathcal{A}}^{(m)}, y_{\\mathcal{B}}^{(m)})\n$$\nUsing the provided shorthand notations, this system can be written as:\n$$\n\\begin{pmatrix}\n1  -\\alpha \\\\\n-\\beta  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Delta y_{\\mathcal{A}}^{(m)} \\\\\n\\Delta y_{\\mathcal{B}}^{(m)}\n\\end{pmatrix}\n\\;=\\;\n-\n\\begin{pmatrix}\nF_1 \\\\\nF_2\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n-F_1 \\\\\n-F_2\n\\end{pmatrix}\n$$\nTo find the Newton step vector $\\Delta y^{(m)}$, we must solve this $2 \\times 2$ linear system. This is most directly achieved by finding the inverse of the Jacobian matrix $J$. The determinant of $J$ is:\n$$\n\\det(J) = (1)(1) - (-\\alpha)(-\\beta) = 1 - \\alpha\\beta\n$$\nThe inverse of $J$, denoted $J^{-1}$, exists if and only if $\\det(J) \\neq 0$, i.e., $1 - \\alpha\\beta \\neq 0$. Assuming this condition holds, the inverse of a general $2 \\times 2$ matrix $\\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$ is $\\frac{1}{ad-bc}\\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$. Applying this formula to $J$:\n$$\nJ^{-1} = \\frac{1}{1 - \\alpha\\beta}\n\\begin{pmatrix}\n1  \\alpha \\\\\n\\beta  1\n\\end{pmatrix}\n$$\nNow, we can solve for $\\Delta y^{(m)}$:\n$$\n\\Delta y^{(m)} = J^{-1} \\left( -F^{(m)} \\right)\n$$\n$$\n\\begin{pmatrix}\n\\Delta y_{\\mathcal{A}}^{(m)} \\\\\n\\Delta y_{\\mathcal{B}}^{(m)}\n\\end{pmatrix}\n\\;=\\;\n\\frac{1}{1 - \\alpha\\beta}\n\\begin{pmatrix}\n1  \\alpha \\\\\n\\beta  1\n\\end{pmatrix}\n\\begin{pmatrix}\n-F_1 \\\\\n-F_2\n\\end{pmatrix}\n$$\nPerforming the matrix-vector multiplication yields the components of the Newton step:\n$$\n\\Delta y_{\\mathcal{A}}^{(m)} = \\frac{1}{1 - \\alpha\\beta} \\left( (1)(-F_1) + (\\alpha)(-F_2) \\right) = \\frac{-F_1 - \\alpha F_2}{1 - \\alpha\\beta} = -\\frac{F_1 + \\alpha F_2}{1 - \\alpha\\beta}\n$$\n$$\n\\Delta y_{\\mathcal{B}}^{(m)} = \\frac{1}{1 - \\alpha\\beta} \\left( (\\beta)(-F_1) + (1)(-F_2) \\right) = \\frac{-\\beta F_1 - F_2}{1 - \\alpha\\beta} = -\\frac{\\beta F_1 + F_2}{1 - \\alpha\\beta}\n$$\nThus, the Newton step vector is $\\Delta y^{(m)} = (\\Delta y_{\\mathcal{A}}^{(m)}, \\Delta y_{\\mathcal{B}}^{(m)})$.\n\nThe second part of the problem asks for the conditions for local quadratic convergence of the Newton iteration. Let the consistent solution to the algebraic loop be $y^* = (y_{\\mathcal{A}}^*, y_{\\mathcal{B}}^*)$, where $F(y^*) = 0$. The general theory of Newton's method establishes the following conditions for local quadratic convergence to a root $y^*$:\n\n1.  **Sufficient Smoothness:** The function $F$ must be twice continuously differentiable (i.e., belong to class $C^2$) in an open neighborhood of the solution $y^*$. In the context of this problem, the components of $F$ are $F_1 = y_{\\mathcal{A}} - \\phi_{\\mathcal{A}}(y_{\\mathcal{B}})$ and $F_2 = y_{\\mathcal{B}} - \\phi_{\\mathcal{B}}(y_{\\mathcal{A}})$. The first derivatives of $F$ form the Jacobian $J$, which involves the first derivatives of $\\phi_{\\mathcal{A}}$ and $\\phi_{\\mathcal{B}}$. For $F$ to be of class $C^2$, the second derivatives of $F$ must be continuous. This requires that the interface functions $\\phi_{\\mathcal{A}}(u_{\\mathcal{A}})$ and $\\phi_{\\mathcal{B}}(u_{\\mathcal{B}})$ be twice continuously differentiable with respect to their inputs in a neighborhood of the solution.\n\n2.  **Nonsingular Jacobian at the Solution:** The interface Jacobian matrix $J(y)$ must be invertible (nonsingular) at the solution $y^*$. As calculated previously, the determinant is $\\det(J) = 1 - \\alpha\\beta$. At the solution $y^*$, this condition becomes $1 - \\alpha^*\\beta^* \\neq 0$, where $\\alpha^*$ and $\\beta^*$ are the interface gains evaluated at the solution. Physically, this means the product of the direct feedthrough gains of the two subsystems must not equal $1$. A product of $1$ corresponds to an unstable positive feedback loop with unity gain, leading to a singular system.\n\n3.  **Sufficiently Close Initial Guess:** The initial guess for the iteration, $y^{(0)} = (y_{\\mathcal{A}}^{(0)}, y_{\\mathcal{B}}^{(0)})$, must be sufficiently close to the true solution $y^*$. This means $y^{(0)}$ must lie within a specific \"basin of attraction\" around $y^*$ where the convergence properties are guaranteed. The size of this region depends on the properties of $F$ and its derivatives near $y^*$.\n\nIf these three conditions are met, the sequence of iterates $\\{y^{(m)}\\}$ generated by the Newton's method update rule, $y^{(m+1)} = y^{(m)} + \\Delta y^{(m)}$, will converge to the solution $y^*$ at a quadratic rate. This means there exists a constant $C$ such that $\\|y^{(m+1)} - y^*\\| \\le C \\|y^{(m)} - y^*\\|^2$ for all $m$ large enough, where $\\|\\cdot\\|$ is a vector norm.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{F_1 + \\alpha F_2}{1 - \\alpha \\beta}  -\\frac{\\beta F_1 + F_2}{1 - \\alpha \\beta} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "For hybrid systems that combine continuous dynamics with discrete events, a critical challenge is ensuring that no event is missed between communication points. This practice moves beyond simple heuristics and demonstrates a rigorous method for guaranteeing event detection . Using known bounds on system dynamics and the Lipschitz continuity of the event function, you will derive a \"safe\" macro-step size that mathematically precludes the possibility of a missed zero-crossing, a vital technique for building high-integrity digital twins.",
            "id": "4208801",
            "problem": "Consider a co-simulation of heterogeneous systems in a digital twin of a cyber-physical system, where a continuous-time Ordinary Differential Equation (ODE) subsystem and a discrete-event subsystem are coupled via macro-step communication. The continuous-time subsystem is described by the initial value problem $\\dot{x}(t) = f(x(t), u(t), t)$ with state $x(t) \\in \\mathbb{R}^{n}$ and input $u(t)$ held constant over each macro-step. The discrete-event subsystem triggers an event when an event guard function $g(x,t)$ crosses zero, that is, when $g(x(t), t)$ changes sign.\n\nAssume the following fundamental properties hold over a compact, forward-invariant domain for the current macro-step starting at time $t_{k}$:\n- The ODE subsystem provides a uniform bound on the state time-derivative: $\\|\\dot{x}(t)\\| \\leq B_{x}$ for all $t \\in [t_{k}, t_{k} + H]$.\n- The event guard $g(x,t)$ is Lipschitz continuous in the state with constant $L_{x} \\geq 0$ and in time with constant $L_{t} \\geq 0$, so that for all $(x,t)$ and $(y,s)$ in the domain, $|g(x,t) - g(y,s)| \\leq L_{x}\\|x - y\\| + L_{t}|t - s|$.\n- At the communication instant $t_{k}$, the known state $x_{k} := x(t_{k})$ yields a nonzero guard value $g_{k} := g(x_{k}, t_{k}) \\neq 0$.\n\nYou are tasked to determine a safe macro-step size $H$ such that no zero-crossing of $g(x(t), t)$ can be missed within the open interval $(t_{k}, t_{k} + H)$ under these assumptions, when only boundary evaluations of $g$ at macro-step endpoints are used for event detection. Starting from the stated bounds and definitions, derive an analytic expression for the largest threshold on $H$ that guarantees the guard cannot cross zero inside the interval, expressed purely in terms of $g_{k}$, $B_{x}$, $L_{x}$, and $L_{t}$.\n\nProvide the final answer as a single closed-form expression. No numerical evaluation is required.",
            "solution": "The problem requires the derivation of a safe macro-step size, $H$, for a co-simulation framework. Safety, in this context, means guaranteeing that no zero-crossing of an event guard function, $g(x(t), t)$, is missed within the open time interval $(t_{k}, t_{k} + H)$. The state of the system is $x(t)$ and the simulation proceeds in macro-steps starting at time $t_{k}$. We are given the state $x_{k} = x(t_{k})$ and the guard value $g_{k} = g(x_{k}, t_{k})$ at the beginning of the step, with the crucial condition that $g_{k} \\neq 0$.\n\nA zero-crossing is missed if the function $g(x(t), t)$ has a sign at some time $t \\in (t_k, t_k+H)$ that is different from the sign of $g_{k}$. By the Intermediate Value Theorem, a change of sign implies that the function must have passed through zero at some point within the interval. To guarantee that no zero-crossing is missed, we must ensure that the change in the guard function's value, $|g(x(t), t) - g_{k}|$, is strictly less than its initial distance from zero, which is $|g_{k}|$, for all $t$ in the open interval $(t_k, t_k+H)$.\n\nLet us establish an upper bound for the change $|g(x(t), t) - g_{k}|$ for any $t \\in (t_{k}, t_{k} + H)$. We are given that the guard function $g$ is Lipschitz continuous in both its arguments, state $x$ and time $t$, with respective Lipschitz constants $L_{x} \\ge 0$ and $L_{t} \\ge 0$. Applying the definition of Lipschitz continuity between the points $(x(t), t)$ and $(x_k, t_k) = (x(t_k), t_k)$, we have:\n$$|g(x(t), t) - g(x_{k}, t_{k})| \\leq L_{x}\\|x(t) - x_{k}\\| + L_{t}|t - t_{k}|$$\nSince $t  t_{k}$, we can write $|t - t_{k}| = t - t_{k}$. The inequality becomes:\n$$|g(x(t), t) - g_{k}| \\leq L_{x}\\|x(t) - x(t_k)\\| + L_{t}(t - t_{k})$$\n\nNext, we must bound the term $\\|x(t) - x(t_k)\\|$. The state vector $x(t)$ evolves according to the ordinary differential equation $\\dot{x}(t) = f(x(t), u(t), t)$. By the Fundamental Theorem of Calculus, the change in state over the interval $[t_{k}, t]$ is the integral of its derivative:\n$$x(t) - x(t_k) = \\int_{t_{k}}^{t} \\dot{x}(\\tau) d\\tau$$\nTaking the norm and applying the triangle inequality for integrals (also known as the Minkowski integral inequality), we get:\n$$\\|x(t) - x(t_k)\\| = \\left\\| \\int_{t_{k}}^{t} \\dot{x}(\\tau) d\\tau \\right\\| \\leq \\int_{t_{k}}^{t} \\|\\dot{x}(\\tau)\\| d\\tau$$\nWe are provided with a uniform bound on the norm of the state derivative, $\\|\\dot{x}(t)\\| \\leq B_{x}$, for all $t$ in the macro-step interval. Substituting this bound into the integral yields:\n$$\\int_{t_{k}}^{t} \\|\\dot{x}(\\tau)\\| d\\tau \\leq \\int_{t_{k}}^{t} B_{x} d\\tau = B_{x}(t - t_{k})$$\nTherefore, we have established a bound on the state deviation:\n$$\\|x(t) - x(t_k)\\| \\leq B_{x}(t - t_{k})$$\n\nNow we substitute this bound back into the inequality for the change in the guard function:\n$$|g(x(t), t) - g_{k}| \\leq L_{x} (B_{x}(t - t_{k})) + L_{t}(t - t_{k})$$\nFactoring out the term $(t-t_k)$, we obtain a comprehensive bound on the change in $g$:\n$$|g(x(t), t) - g_{k}| \\leq (L_{x}B_{x} + L_{t})(t - t_{k})$$\n\nTo prevent a zero-crossing for $t \\in (t_{k}, t_{k}+H)$, the sign of $g(x(t), t)$ must remain the same as the sign of $g_k$. A sufficient condition to ensure this is to require that the maximum possible change in $g$ over the interval $[t_k, t_k+H]$ is less than or equal to the initial distance to zero, $|g_k|$.\nThis condition is most stringent at the end of the interval, $t = t_k+H$. We require:\n$$(L_{x}B_{x} + L_{t}) H \\leq |g_{k}|$$\n\nThe problem asks for the largest threshold on $H$. From the inequality, we can solve for $H$:\n$$H \\leq \\frac{|g_{k}|}{L_{x}B_{x} + L_{t}}$$\nThis inequality defines the set of all safe step sizes. The largest possible value for $H$ that is guaranteed to be safe is the upper bound of this set. We must consider the case where the denominator $L_{x}B_{x} + L_{t}$ is zero. Given $L_x \\ge 0$, $L_t \\ge 0$, and $B_x \\ge 0$, the denominator is zero only if $L_t=0$ and either $L_x=0$ or $B_x=0$. In this scenario, the guard function's value cannot change over the interval, and since $g_k \\neq 0$, it can never cross zero. The formula correctly reflects this by implying no upper limit on $H$ (division by zero). Assuming the denominator is non-zero, the largest threshold for $H$ is:\n$$H_{\\text{max}} = \\frac{|g_{k}|}{L_{x}B_{x} + L_{t}}$$\nThis expression represents the largest macro-step size that can be taken from time $t_k$ while guaranteeing that no zero-crossing event within the open interval $(t_k, t_k+H)$ goes undetected.\nThe final expression is solely in terms of the required variables $g_k$, $B_x$, $L_x$, and $L_t$.",
            "answer": "$$\\boxed{\\frac{|g_{k}|}{L_{x}B_{x} + L_{t}}}$$"
        }
    ]
}