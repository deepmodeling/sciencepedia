{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a concrete entry point into hybrid modeling. We will consider a familiar physical system—a mass on a spring—where the friction force is unknown and needs to be learned from data. The key challenge is to ensure our data-driven friction model adheres to the second law of thermodynamics by guaranteeing non-negative energy dissipation, a task we accomplish by enforcing non-negativity on the model's parameters. This practice demonstrates a powerful technique for embedding fundamental physical constraints directly into the parameter estimation process. ",
            "id": "4226933",
            "problem": "Consider a single-degree-of-freedom cyber-physical system with a physical plant and its digital twin sharing the hybrid model coupling physics-based structure with data-driven friction. Let the plant be a point mass on a linear spring with unknown speed-dependent damping. The longitudinal motion is described by Newton's second law of motion and Hooke's law. The governing physics is that the sum of forces equals mass times acceleration. Denote position by $x(t)$ in meters, velocity by $v(t)$ in meters per second, acceleration by $a(t)$ in meters per second squared, external actuation force by $u(t)$ in newtons, mass by $m$ in kilograms, linear stiffness by $k$ in newtons per meter, and friction force by $F_{\\mathrm{fric}}(t)$ in newtons. The fundamental equations are: \n$$ m \\, a(t) = u(t) - k \\, x(t) - F_{\\mathrm{fric}}(t). $$\nTo ensure physically consistent non-negative energy dissipation, we represent the friction as a viscous-like term with an effective friction coefficient that depends on the speed magnitude, so that\n$$ F_{\\mathrm{fric}}(t) = c\\big(|v(t)|\\big)\\, v(t), \\quad c\\big(|v(t)|\\big) \\ge 0, $$\nwhich yields an instantaneous power dissipation \n$$ P_{\\mathrm{diss}}(t) = F_{\\mathrm{fric}}(t)\\, v(t) \\ge 0. $$\nWe adopt the following hybrid modeling scheme: the structural model ($m$ and $k$) is known from physics, while the effective friction coefficient $c\\big(|v|\\big)$ is learned from data using a minimal parametric basis that preserves positivity. Specifically, let\n$$ c\\big(|v|\\big) = \\alpha_0 + \\alpha_1 |v|, $$\nwith unknown coefficients $\\alpha_0 \\ge 0$ and $\\alpha_1 \\ge 0$ to be inferred from time-series data and the physics equation. The learning objective is to find $\\alpha_0$ and $\\alpha_1$ that minimize the mismatch between the measured external force $u(t)$ and the force predicted by the hybrid model, under the non-negativity constraints on $\\alpha_0$ and $\\alpha_1$, thereby guaranteeing $P_{\\mathrm{diss}}(t) \\ge 0$. The modeling assumption is scientifically realistic for lubricated contacts in which viscous friction increases with speed.\n\nYour task is to implement a program that:\n- Generates synthetic data $(x(t), v(t), a(t), u(t))$ for specified parameters by exciting the system with a known motion profile, computes the design signals from the physics, and estimates $(\\alpha_0,\\alpha_1)$ using Non-Negative Least Squares (NNLS).\n- Computes the root-mean-square speed \n$$ v_{\\mathrm{rms}} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} v(t_i)^2}, $$\nand reports the scalar effective friction coefficient at this speed,\n$$ c_{\\mathrm{eff}} = \\alpha_0 + \\alpha_1 \\, v_{\\mathrm{rms}}, $$\nexpressed in $\\mathrm{N\\cdot s/m}$.\n- Verifies the positivity of dissipation across the dataset by checking \n$$ P_{\\mathrm{diss}}(t_i) = \\big(\\alpha_0 v(t_i) + \\alpha_1 |v(t_i)| v(t_i)\\big)\\, v(t_i) \\ge 0 $$\nfor all samples $t_i$. The boolean should be true if every sample satisfies the inequality (within floating-point arithmetic, which here is exact due to non-negativity of the coefficients and the quadratic non-negativity), and false otherwise.\n\nThe program should implement the following data generation protocol for each test case:\n- Time samples $t_i = i \\, \\Delta t$ for $i = 0,1,\\dots,N-1$, with specified $N$ and $\\Delta t$ in seconds.\n- Motion profile $x(t) = X_0 \\sin(\\omega t)$, with $X_0$ in meters and angular frequency $\\omega$ in radians per second. Then $v(t) = X_0 \\omega \\cos(\\omega t)$ and $a(t) = -X_0 \\omega^2 \\sin(\\omega t)$.\n- True friction coefficients $(\\alpha_0^{\\mathrm{true}}, \\alpha_1^{\\mathrm{true}})$ produce a friction force $F_{\\mathrm{fric}}^{\\mathrm{true}}(t) = \\alpha_0^{\\mathrm{true}} v(t) + \\alpha_1^{\\mathrm{true}} |v(t)| v(t)$.\n- Measured actuation is $u(t) = m a(t) + k x(t) + F_{\\mathrm{fric}}^{\\mathrm{true}}(t) + \\eta(t)$, with additive zero-mean Gaussian noise $\\eta(t)$ in newtons, generated with a given standard deviation and a fixed random seed per test case for reproducibility.\n\nEstimation protocol:\n- Using the physics equation, rearrange the measurement equation to isolate the friction contribution: \n$$ b(t) = u(t) - m a(t) - k x(t) = \\alpha_0 v(t) + \\alpha_1 |v(t)| v(t). $$\n- Estimate $(\\alpha_0,\\alpha_1)$ from the samples $\\{b(t_i), v(t_i)\\}_{i=1}^N$ by solving the NNLS problem that minimizes the sum of squared residuals subject to $\\alpha_0 \\ge 0$ and $\\alpha_1 \\ge 0$.\n\nUnits and output specification:\n- Mass $m$ in $\\mathrm{kg}$, stiffness $k$ in $\\mathrm{N/m}$, position $x$ in $\\mathrm{m}$, velocity $v$ in $\\mathrm{m/s}$, acceleration $a$ in $\\mathrm{m/s^2}$, force $u$ in $\\mathrm{N}$, friction coefficients $\\alpha_0$ in $\\mathrm{N\\cdot s/m}$ and $\\alpha_1$ in $\\mathrm{N\\cdot s^2/m^2}$, and $c_{\\mathrm{eff}}$ in $\\mathrm{N\\cdot s/m}$. Angles are in radians. No percentages appear in the output.\n- For each test case, the program should output a list $[c_{\\mathrm{eff}}, \\mathrm{flag}]$ where $c_{\\mathrm{eff}}$ is a float in $\\mathrm{N\\cdot s/m}$ and $\\mathrm{flag}$ is a boolean indicating whether $P_{\\mathrm{diss}}(t_i) \\ge 0$ for all samples.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, e.g., $[[c_1,\\mathrm{flag}_1],[c_2,\\mathrm{flag}_2],[c_3,\\mathrm{flag}_3]]$.\n\nTest suite:\n- Case $1$ (happy path): $m = 2.0$, $k = 5.0$, $X_0 = 0.15$, $\\omega = 3.0$, $\\Delta t = 0.01$, $N = 1000$, $\\alpha_0^{\\mathrm{true}} = 0.8$, $\\alpha_1^{\\mathrm{true}} = 0.3$, noise standard deviation $= 0.05$ newtons, random seed $= 42$.\n- Case $2$ (boundary condition: purely viscous): $m = 1.2$, $k = 8.0$, $X_0 = 0.08$, $\\omega = 2.5$, $\\Delta t = 0.01$, $N = 800$, $\\alpha_0^{\\mathrm{true}} = 1.0$, $\\alpha_1^{\\mathrm{true}} = 0.0$, noise standard deviation $= 0.02$ newtons, random seed $= 123$.\n- Case $3$ (edge case: near-zero speeds): $m = 3.5$, $k = 4.0$, $X_0 = 0.02$, $\\omega = 1.5$, $\\Delta t = 0.01$, $N = 600$, $\\alpha_0^{\\mathrm{true}} = 0.5$, $\\alpha_1^{\\mathrm{true}} = 0.1$, noise standard deviation $= 0.01$ newtons, random seed $= 7$.\n\nYour implementation must be deterministic, use the specified seeds, and adhere strictly to the final output format.",
            "solution": "The problem requires the estimation of friction parameters for a single-degree-of-freedom cyber-physical system. The system consists of a physical plant, represented as a point mass $m$ on a linear spring with stiffness $k$, and its digital twin. The solution approach involves a hybrid model that combines a known physics-based structure with a data-driven component for the friction force.\n\nThe governing equation of motion for the mass is derived from Newton's second law:\n$$ m \\, a(t) = u(t) - k \\, x(t) - F_{\\mathrm{fric}}(t) $$\nwhere $x(t)$, $v(t)$, and $a(t)$ are the position, velocity, and acceleration of the mass, respectively. The term $u(t)$ represents an external actuation force, and $F_{\\mathrm{fric}}(t)$ is the friction force.\n\nThe friction is modeled using a hybrid approach. The model structure is physically inspired, ensuring that the instantaneous power dissipated by friction, $P_{\\mathrm{diss}}(t) = F_{\\mathrm{fric}}(t)v(t)$, is always non-negative. This is achieved by defining the friction force as:\n$$ F_{\\mathrm{fric}}(t) = c\\big(|v(t)|\\big)\\, v(t) $$\nwhere the effective friction coefficient $c\\big(|v(t)|\\big)$ is a non-negative function of the speed $|v(t)|$. The data-driven component is the parametric form of this coefficient, which is to be learned from data:\n$$ c\\big(|v(t)|\\big) = \\alpha_0 + \\alpha_1 |v(t)| $$\nThe parameters $\\alpha_0$ and $\\alpha_1$ are unknown and must be estimated. To ensure $P_{\\mathrm{diss}}(t) = (\\alpha_0 + \\alpha_1 |v(t)|)v(t)^2 \\ge 0$, we must enforce the constraints $\\alpha_0 \\ge 0$ and $\\alpha_1 \\ge 0$.\n\nTo estimate $\\alpha_0$ and $\\alpha_1$, we first rearrange the governing equation to isolate the terms containing the unknowns. This establishes a linear relationship between a measurable quantity and the parameters:\n$$ u(t) - m \\, a(t) - k \\, x(t) = \\alpha_0 v(t) + \\alpha_1 |v(t)| v(t) $$\nThis equation forms the basis for a linear regression problem. We define a target variable $b(t) = u(t) - m \\, a(t) - k \\, x(t)$. Given a set of $N$ time-series measurements $(x(t_i), v(t_i), a(t_i), u(t_i))$ for $i=0, \\dots, N-1$, we can construct a system of linear equations:\n$$ \\mathbf{b} \\approx \\mathbf{A} \\boldsymbol{\\alpha} $$\nwhere $\\mathbf{b}$ is a column vector of size $N$ with elements $b(t_i)$, $\\boldsymbol{\\alpha}$ is the column vector of parameters $[\\alpha_0, \\alpha_1]^T$, and $\\mathbf{A}$ is the $N \\times 2$ design matrix whose rows are $[v(t_i), |v(t_i)|v(t_i)]$. The approximation symbol $\\approx$ acknowledges the presence of measurement noise in $u(t)$.\n\nThe estimation task is to find the vector $\\boldsymbol{\\alpha}$ that minimizes the sum of squared residuals, $||\\mathbf{A}\\boldsymbol{\\alpha} - \\mathbf{b}||_2^2$, subject to the physical constraints $\\alpha_0 \\ge 0$ and $\\alpha_1 \\ge 0$. This is a Non-Negative Least Squares (NNLS) problem. It can be solved efficiently using standard optimization routines, such as `scipy.optimize.nnls`.\n\nThe overall algorithm proceeds as follows for each test case:\n1.  **Data Generation**: A synthetic dataset is created.\n    -   A time vector $t$ is generated with $N$ samples and a time step of $\\Delta t$.\n    -   A sinusoidal motion profile $x(t) = X_0 \\sin(\\omega t)$ is prescribed. The velocity $v(t)$ and acceleration $a(t)$ are obtained by analytical differentiation.\n    -   The true friction force $F_{\\mathrm{fric}}^{\\mathrm{true}}(t)$ is calculated using the given true parameters $(\\alpha_0^{\\mathrm{true}}, \\alpha_1^{\\mathrm{true}})$.\n    -   The \"measured\" actuation force $u(t)$ is synthesized by evaluating $m a(t) + k x(t) + F_{\\mathrm{fric}}^{\\mathrm{true}}(t)$ and adding zero-mean Gaussian noise with a specified standard deviation and a fixed random seed for reproducibility.\n\n2.  **Parameter Estimation**:\n    -   The target vector $\\mathbf{b}$ and design matrix $\\mathbf{A}$ are constructed from the generated data $(x, v, a, u)$ and the known system parameters $(m, k)$.\n    -   The NNLS problem is solved to obtain the estimated parameters $\\hat{\\alpha}_0$ and $\\hat{\\alpha}_1$.\n\n3.  **Output Calculation**:\n    -   The root-mean-square speed is calculated over the time series: $v_{\\mathrm{rms}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} v(t_i)^2}$.\n    -   The effective friction coefficient at this speed is computed: $c_{\\mathrm{eff}} = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 v_{\\mathrm{rms}}$.\n    -   The non-negativity of the dissipated power, $P_{\\mathrm{diss}}(t_i) = (\\hat{\\alpha}_0 + \\hat{\\alpha}_1 |v(t_i)|) v(t_i)^2 \\ge 0$, is verified for all time samples. Since NNLS guarantees $\\hat{\\alpha}_0 \\ge 0$ and $\\hat{\\alpha}_1 \\ge 0$, and since $v(t_i)^2 \\ge 0$ and $|v(t_i)| \\ge 0$, this condition is mathematically guaranteed to be satisfied. The boolean flag serves as a confirmation of this theoretical property.\n\n4.  **Formatting**: The final result for each case, a list containing $c_{\\mathrm{eff}}$ and the boolean flag, is formatted into a string. These strings are then aggregated into a final list format as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import nnls\n\ndef solve():\n    \"\"\"\n    Solves the hybrid modeling problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path\n        (2.0, 5.0, 0.15, 3.0, 0.01, 1000, 0.8, 0.3, 0.05, 42),\n        # Case 2: boundary condition (purely viscous)\n        (1.2, 8.0, 0.08, 2.5, 0.01, 800, 1.0, 0.0, 0.02, 123),\n        # Case 3: edge case (near-zero speeds)\n        (3.5, 4.0, 0.02, 1.5, 0.01, 600, 0.5, 0.1, 0.01, 7),\n    ]\n\n    results_list = []\n    \n    for case in test_cases:\n        m, k, X0, omega, dt, N, alpha0_true, alpha1_true, noise_std, seed = case\n\n        # 1. Generate synthetic data\n        # Time vector\n        t = np.arange(N) * dt\n        \n        # Motion profile\n        x = X0 * np.sin(omega * t)\n        v = X0 * omega * np.cos(omega * t)\n        a = -X0 * omega**2 * np.sin(omega * t)\n        \n        # True friction force\n        F_fric_true = alpha0_true * v + alpha1_true * np.abs(v) * v\n        \n        # Generate reproducible noise\n        rng = np.random.default_rng(seed)\n        noise = rng.normal(loc=0.0, scale=noise_std, size=N)\n        \n        # Synthesize measured actuation force\n        u = m * a + k * x + F_fric_true + noise\n\n        # 2. Set up and solve the NNLS problem\n        # Target vector b(t) = u(t) - m*a(t) - k*x(t)\n        b = u - m * a - k * x\n        \n        # Design matrix A(t) = [v(t), |v(t)|v(t)]\n        A = np.vstack([v, np.abs(v) * v]).T\n        \n        # Solve for alpha = [alpha0, alpha1] using Non-Negative Least Squares\n        alpha_est, _ = nnls(A, b)\n        alpha0_est, alpha1_est = alpha_est\n\n        # 3. Calculate specified outputs\n        # Root-mean-square speed\n        v_rms = np.sqrt(np.mean(v**2))\n        \n        # Effective friction coefficient at v_rms\n        c_eff = alpha0_est + alpha1_est * v_rms\n        \n        # Verify positivity of dissipated power\n        # P_diss = (alpha0*v + alpha1*|v|*v)*v = alpha0*v^2 + alpha1*|v|*v^2\n        # Since alpha0_est, alpha1_est from NNLS are >= 0, and v^2, |v| >=0,\n        # P_diss is guaranteed to be non-negative.\n        dissipated_power = (alpha0_est * v + alpha1_est * np.abs(v) * v) * v\n        dissipation_positive_flag = np.all(dissipated_power >= 0.0)\n\n        # Append result for the current case\n        results_list.append([c_eff, dissipation_positive_flag])\n\n    # Final print statement in the exact required format.\n    # The format [[c1,flag1],[c2,flag2]] is achieved by printing the\n    # string representation of the list of lists and removing spaces.\n    print(str(results_list).replace(\" \", \"\"))\n\nsolve()\n\n```"
        },
        {
            "introduction": "When we use highly flexible function approximators like neural networks to represent unknown physics, ensuring they respect known physical laws is critical. This exercise explores two powerful strategies for enforcing Dirichlet boundary conditions in the context of Physics-Informed Neural Networks (PINNs): \"hard\" enforcement through a carefully designed model architecture and \"soft\" enforcement by adding a penalty term to the training loss function. By deriving the gradient for the penalty method, you will gain insight into the optimization dynamics and the fundamental trade-offs between these two common approaches. ",
            "id": "4226906",
            "problem": "A Digital Twin (DT) of a one-dimensional heat-conducting bar, a representative Cyber-Physical System (CPS), models the steady-state temperature field $u(x)$ on the spatial domain $x \\in [0,1]$. The field must satisfy Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 1$, along with a physics residual that is not needed for this question. You are comparing two hybrid modeling strategies that combine physics and data via an Artificial Neural Network (ANN) to represent unknown components of the solution.\n\nStrategy A (hard enforcement via constrained architecture): Use a trial solution of the form $u_{\\mathrm{c}}(x;\\theta) = g(x) + s(x)\\,N(x;\\theta)$, where $g(x)$ is a fixed function that satisfies the boundary conditions, $s(x)$ is a fixed function such that $s(0) = 0$ and $s(1) = 0$, and $N(x;\\theta)$ is an ANN with parameters $\\theta$.\n\nStrategy B (soft enforcement via loss penalties): Use an unconstrained ANN $u_{\\mathrm{u}}(x;\\theta)$ and penalize boundary violations in the loss with a boundary penalty\n$$\nL_{\\mathrm{bc}}(\\theta) = \\lambda \\left[ \\left(u_{\\mathrm{u}}(0;\\theta) - 0\\right)^{2} + \\left(u_{\\mathrm{u}}(1;\\theta) - 1\\right)^{2} \\right],\n$$\nwhere $\\lambda > 0$ is a fixed scalar weight.\n\nFor Strategy A, let $g(x) = x$ and $s(x) = x(1-x)$. For Strategy B, take an explicit unconstrained ANN ansatz $u_{\\mathrm{u}}(x;\\theta) = \\theta_{1}\\,\\tanh\\!\\left(\\theta_{2}\\,x\\right)$ with parameter vector $\\theta = (\\theta_{1},\\theta_{2})$.\n\nTasks:\n- Using fundamental definitions of boundary conditions and the property $s(0)=0$ and $s(1)=0$, explain why Strategy A enforces the boundary conditions for all values of $\\theta$.\n- Starting from the definition of $L_{\\mathrm{bc}}(\\theta)$ and the chain rule for gradients, derive the exact analytic gradient $\\nabla_{\\theta} L_{\\mathrm{bc}}(\\theta)$ for Strategy B with the given ansatz $u_{\\mathrm{u}}(x;\\theta) = \\theta_{1}\\,\\tanh\\!\\left(\\theta_{2}\\,x\\right)$. Express your final answer as a single closed-form row vector in terms of $\\lambda$, $\\theta_{1}$, and $\\theta_{2}$. Do not substitute numerical values.\n- Briefly, based on first principles of constrained optimization and smooth penalty methods, discuss how the optimization landscape differs between Strategies A and B near feasibility.\n\nYour final answer must be the gradient vector for Strategy B in a single closed-form analytic expression. Provide the gradient as a row matrix using the $\\mathrm{pmatrix}$ environment. No rounding is required, and no units are needed.",
            "solution": "The problem as stated is scientifically sound, well-posed, and self-contained. It describes a standard comparison between two common techniques for enforcing boundary conditions in physics-informed machine learning: hard enforcement by architectural construction and soft enforcement via penalty terms in the loss function. All necessary definitions and functions are provided, and the tasks are direct applications of mathematical principles. Therefore, the problem is valid, and a solution can be provided.\n\nThe problem asks for three distinct tasks: an explanation of why Strategy A satisfies the boundary conditions, a derivation of the gradient of the boundary loss for Strategy B, and a brief discussion on the resulting optimization landscapes.\n\nFirst, let us analyze Strategy A, which uses the trial solution $u_{\\mathrm{c}}(x;\\theta) = g(x) + s(x)\\,N(x;\\theta)$. The problem specifies that the function $g(x)$ must satisfy the Dirichlet boundary conditions, and the function $s(x)$ must be zero at the boundaries. The given boundary conditions are $u(0)=0$ and $u(1)=1$.\nFor Strategy A, we are given $g(x)=x$ and $s(x)=x(1-x)$. Let us verify these auxiliary functions meet their requirements.\nFor $g(x)$, we have $g(0)=0$ and $g(1)=1$, so it correctly satisfies the boundary conditions.\nFor $s(x)$, we have $s(0)=0(1-0)=0$ and $s(1)=1(1-1)=0$, so it correctly vanishes at the boundaries.\n\nNow, we evaluate the trial solution $u_{\\mathrm{c}}(x;\\theta)$ at the boundaries $x=0$ and $x=1$:\nAt $x=0$:\n$$u_{\\mathrm{c}}(0;\\theta) = g(0) + s(0)\\,N(0;\\theta)$$\nSubstituting the values $g(0)=0$ and $s(0)=0$:\n$$u_{\\mathrm{c}}(0;\\theta) = 0 + (0) \\cdot N(0;\\theta) = 0$$\nThis result is independent of the value of the neural network output $N(0;\\theta)$ and hence holds for any parameter vector $\\theta$.\n\nAt $x=1$:\n$$u_{\\mathrm{c}}(1;\\theta) = g(1) + s(1)\\,N(1;\\theta)$$\nSubstituting the values $g(1)=1$ and $s(1)=0$:\n$$u_{\\mathrm{c}}(1;\\theta) = 1 + (0) \\cdot N(1;\\theta) = 1$$\nThis result is also independent of the value of $N(1;\\theta)$ and holds for any parameter vector $\\theta$.\nThus, by its very construction, the trial solution $u_{\\mathrm{c}}(x;\\theta)$ in Strategy A rigorously enforces the Dirichlet boundary conditions $u(0)=0$ and $u(1)=1$ for all possible choices of the neural network parameters $\\theta$.\n\nNext, we address Strategy B and derive the gradient of the boundary loss function $L_{\\mathrm{bc}}(\\theta)$. The parameter vector is $\\theta = (\\theta_1, \\theta_2)$. The gradient is a row vector given by $\\nabla_{\\theta} L_{\\mathrm{bc}}(\\theta) = \\begin{pmatrix} \\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_1} & \\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_2} \\end{pmatrix}$.\nThe boundary loss is defined as:\n$$L_{\\mathrm{bc}}(\\theta) = \\lambda \\left[ \\left(u_{\\mathrm{u}}(0;\\theta) - 0\\right)^{2} + \\left(u_{\\mathrm{u}}(1;\\theta) - 1\\right)^{2} \\right]$$\nThe specific ansatz for the unconstrained ANN is $u_{\\mathrm{u}}(x;\\theta) = \\theta_{1}\\,\\tanh(\\theta_{2}\\,x)$.\n\nFirst, let's evaluate the ansatz at the boundaries $x=0$ and $x=1$:\n$$u_{\\mathrm{u}}(0;\\theta) = \\theta_{1}\\,\\tanh(\\theta_{2} \\cdot 0) = \\theta_{1}\\,\\tanh(0) = 0$$\n$$u_{\\mathrm{u}}(1;\\theta) = \\theta_{1}\\,\\tanh(\\theta_{2} \\cdot 1) = \\theta_{1}\\,\\tanh(\\theta_{2})$$\nSubstituting these into the loss function simplifies the expression:\n$$L_{\\mathrm{bc}}(\\theta) = \\lambda \\left[ (0)^{2} + (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)^{2} \\right] = \\lambda (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)^{2}$$\n\nNow, we compute the partial derivatives with respect to $\\theta_1$ and $\\theta_2$ using the chain rule.\nFor $\\theta_1$:\n$$\\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_1} = \\lambda \\cdot 2 (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1) \\cdot \\frac{\\partial}{\\partial \\theta_1}(\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)$$\n$$\\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_1} = 2\\lambda (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1) \\cdot \\tanh(\\theta_{2})$$\n\nFor $\\theta_2$:\n$$\\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_2} = \\lambda \\cdot 2 (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1) \\cdot \\frac{\\partial}{\\partial \\theta_2}(\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)$$\nWe need the derivative of $\\tanh(z)$, which is $\\frac{d}{dz}\\tanh(z) = \\frac{1}{\\cosh^2(z)}$. Applying the chain rule:\n$$\\frac{\\partial}{\\partial \\theta_2}(\\theta_{1}\\,\\tanh(\\theta_{2})) = \\theta_1 \\cdot \\frac{1}{\\cosh^2(\\theta_2)}$$\nSubstituting this back into the partial derivative for $L_{\\mathrm{bc}}$:\n$$\\frac{\\partial L_{\\mathrm{bc}}}{\\partial \\theta_2} = 2\\lambda (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1) \\cdot \\frac{\\theta_1}{\\cosh^2(\\theta_2)}$$\n\nCombining these two components, we obtain the gradient vector $\\nabla_{\\theta} L_{\\mathrm{bc}}(\\theta)$:\n$$\\nabla_{\\theta} L_{\\mathrm{bc}}(\\theta) = \\begin{pmatrix} 2\\lambda (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)\\tanh(\\theta_{2}) & 2\\lambda (\\theta_{1}\\,\\tanh(\\theta_{2}) - 1)\\frac{\\theta_1}{\\cosh^2(\\theta_2)} \\end{pmatrix}$$\n\nFinally, we briefly discuss the difference in optimization landscapes between the two strategies.\nIn Strategy A, the satisfaction of boundary conditions is a hard constraint, enforced architecturally. The entire parameter space for $\\theta$ maps to a function space where all functions are feasible with respect to the boundary conditions. The optimization algorithm, driven by the physics residual loss (not specified, but assumed to exist), searches within this feasible subspace. The landscape is determined solely by the physics loss, and the optimizer is never directed to correct for boundary violations, as none can occur.\n\nIn contrast, Strategy B employs a soft constraint via a penalty method. The parameter space for $\\theta$ maps to a larger function space, most of which is infeasible (i.e., violates the boundary conditions). The boundary loss $L_{\\mathrm{bc}}(\\theta)$ creates a penalty \"well\" or \"valley\" in the total loss landscape. The minimum of this penalty term (at $L_{\\mathrm{bc}}=0$) defines the feasible region in the parameter space. The total loss landscape is a superposition of the physics loss and this penalty term. For any finite penalty weight $\\lambda$, the global minimum of the total loss will likely be a point where the boundary conditions are only approximately satisfied, representing a compromise between satisfying the physics and satisfying the boundaries. Near the feasible region, the gradient of the penalty term, $\\nabla_{\\theta} L_{\\mathrm{bc}}(\\theta)$, dominates the search direction, pulling the parameters towards boundary satisfaction. This can introduce steep gradients and potential numerical stiffness, making the optimization problem more challenging compared to Strategy A, where the search is intrinsically confined to the feasible set.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2\\lambda (\\theta_1 \\tanh(\\theta_2) - 1) \\tanh(\\theta_2) & 2\\lambda (\\theta_1 \\tanh(\\theta_2) - 1) \\frac{\\theta_1}{\\cosh^2(\\theta_2)} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond local constraints like boundary conditions, many physical systems are defined by global conservation laws, which state that a total quantity such as mass or energy is conserved over time. This practice investigates how the mathematical form of a learned correction term dictates whether the resulting hybrid PDE model upholds this fundamental principle. You will implement a finite volume simulation to see firsthand how structuring the correction as a flux divergence ensures conservation, while treating it as a source term breaks this crucial physical property. ",
            "id": "4226924",
            "problem": "Consider a one-dimensional periodic domain of length $L$ discretized into $N_x$ control volumes of width $\\Delta x = L / N_x$. Let $u(x,t)$ denote a scalar field representing a conserved quantity density in a Cyber-Physical System (CPS) digital twin. The physics-based baseline model is a linear advection Partial Differential Equation (PDE) governed by the continuity law, expressed as $\\partial_t u + \\partial_x f_p(u) = 0$ where $f_p(u) = c u$ with constant advection speed $c$. A data-driven learned correction is introduced to improve model fidelity. The hybrid model is either:\n- Conservative correction: there exists a flux function $g(u)$ such that the learned term enters as a divergence, i.e., $\\partial_t u + \\partial_x f_p(u) + \\partial_x g(u) = 0$.\n- Non-conservative correction: the learned term enters as a source $s(u)$, i.e., $\\partial_t u + \\partial_x f_p(u) = s(u)$.\n\nUnder periodic boundary conditions, if the learned correction is conservative (flux form), the spatial integral of $u$ over the domain, $M(t) = \\int_0^L u(x,t) \\, dx$, must remain constant in time. To validate this property in a discrete simulation, we compute the time integral of the absolute deviation of the total mass from its initial value:\n$$\nI = \\int_0^T \\left| M(t) - M(0) \\right| \\, dt.\n$$\nA nearly conservative scheme will produce $I$ close to zero; we compare $I$ to a specified tolerance $\\varepsilon$ to return a boolean verdict. The angle unit for trigonometric functions used in initial conditions must be radians.\n\nDiscrete numerical scheme requirement:\n- Use the Finite Volume Method (FVM) to ensure telescoping flux differences and mass conservation in the absence of sources. For each control volume indexed by $i \\in \\{0,1,\\dots,N_x-1\\}$, update $u_i^n$ to $u_i^{n+1}$ over a time step $\\Delta t$ using face fluxes at $i+1/2$ and $i-1/2$ that sum the physics flux and, when applicable, the learned flux. For linear advection with $c>0$, use an upwind face flux for the physics, and use a centered average for the learned flux to respect conservation. For the non-conservative case, add a source term at cell centers. The discrete scheme must respect the periodic boundary condition. Express all computations without physical units, and use radians for any trigonometric evaluations.\n\nInitial condition:\n- Use $u(x,0) = u_0(x) = a_0 + a_1 \\sin(2 \\pi x / L)$ with specified $a_0$ and $a_1$ values. The integral $M(0)$ equals $a_0 L$ due to the zero-mean sine term.\n\nValidation metric and decision rule:\n- Compute the discrete approximation of $I$ by numerical quadrature over simulation steps:\n$$\nI \\approx \\sum_{n=1}^{N_t} \\Delta t \\, \\left| M^n - M^0 \\right|, \\quad M^n \\approx \\Delta x \\sum_{i=0}^{N_x-1} u_i^n,\n$$\nwhere $N_t$ is the number of time steps.\n- Declare the learned correction conservative if $I \\le \\varepsilon$ and non-conservative otherwise. The program must output a boolean for each test case.\n\nTest suite and parameters:\n- The following tests cover a typical conservative learned correction, a non-conservative source, a zero correction edge case, and a coarse-grid boundary-case scenario. For all cases, use $L = 1$ (dimensionless), $c > 0$, and periodic boundary conditions.\n\n1. Happy path (conservative learned flux):\n    - $N_x = 128$, $L = 1$, $c = 1$, $\\Delta x = L/N_x$, $\\Delta t = 0.5 \\, \\Delta x / c$, $T = 0.5$, $a_0 = 0.7$, $a_1 = 0.3$, learned flux $g(u) = \\alpha u^3$ with $\\alpha = 0.2$, tolerance $\\varepsilon = 10^{-10}$.\n2. Non-conservative source:\n    - $N_x = 128$, $L = 1$, $c = 1$, $\\Delta x = L/N_x$, $\\Delta t = 0.5 \\, \\Delta x / c$, $T = 0.5$, $a_0 = 0.7$, $a_1 = 0.3$, source $s(u) = \\beta u$ with $\\beta = 0.05$, tolerance $\\varepsilon = 10^{-6}$.\n3. Zero learned correction (edge case):\n    - $N_x = 256$, $L = 1$, $c = 1$, $\\Delta x = L/N_x$, $\\Delta t = 0.5 \\, \\Delta x / c$, $T = 0.5$, $a_0 = 0.7$, $a_1 = 0.3$, learned flux $g(u) = \\alpha u^3$ with $\\alpha = 0$, tolerance $\\varepsilon = 10^{-12}$.\n4. Coarse grid near Courant–Friedrichs–Lewy (CFL) limit (boundary case):\n    - $N_x = 8$, $L = 1$, $c = 1$, $\\Delta x = L/N_x$, $\\Delta t = \\Delta x / c$, $T = 0.25$, $a_0 = 0.7$, $a_1 = 0.3$, learned flux $g(u) = \\alpha u^3$ with $\\alpha = 5.0$, tolerance $\\varepsilon = 10^{-8}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the boolean results for the test suite as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True,True]\").",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and complete. It presents a clear task in computational physics related to hybrid modeling, a contemporary topic in the study of Cyber-Physical Systems. The problem is based on the fundamental principle of conservation laws and their numerical solution using the Finite Volume Method (FVM). All parameters and numerical schemes are explicitly defined, allowing for a unique and verifiable solution.\n\nThe core of the problem is to verify the mass conservation property of two types of hybrid models for a scalar field $u(x,t)$. The evolution of $u$ is governed by a Partial Differential Equation (PDE).\nThe general form of the PDE is $\\partial_t u + \\partial_x F(u) = S(u)$, where $F(u)$ is the total flux and $S(u)$ is a source term.\nIn this problem, the total flux is a sum of a physics-based flux $f_p(u) = c u$ and a learned correction flux $g(u)$. The source term is denoted by $s(u)$.\n- A **conservative** model has the correction in flux form: $F(u) = c u + g(u)$ and $S(u)=0$. The PDE is $\\partial_t u + \\partial_x (c u + g(u)) = 0$.\n- A **non-conservative** model has the correction as a source term: $F(u) = c u$ and $S(u) = s(u)$. The PDE is $\\partial_t u + \\partial_x (c u) = s(u)$.\n\nThe principle of mass conservation for a periodic domain of length $L$ states that the total mass $M(t) = \\int_0^L u(x,t) \\, dx$ is constant if the governing equation is conservative. This can be shown by integrating the conservative PDE over the domain:\n$$ \\frac{dM}{dt} = \\frac{d}{dt} \\int_0^L u \\, dx = \\int_0^L \\partial_t u \\, dx = - \\int_0^L \\partial_x F(u) \\, dx $$\nBy the Fundamental Theorem of Calculus, this becomes:\n$$ \\frac{dM}{dt} = - [F(u(L,t)) - F(u(0,t))] $$\nDue to periodic boundary conditions, $u(L,t) = u(0,t)$, and thus $F(u(L,t)) = F(u(0,t))$. This leads to $\\frac{dM}{dt} = 0$, implying $M(t)$ is constant.\nIf a source term $S(u)$ is present, then $\\frac{dM}{dt} = \\int_0^L S(u) \\, dx$, which is generally non-zero, hence mass is not conserved.\n\nWe will implement a Finite Volume Method (FVM) scheme to solve the PDE numerically. For a control volume $i$ of width $\\Delta x$, the semi-discrete FVM form is:\n$$ \\frac{du_i}{dt} = - \\frac{1}{\\Delta x} (F_{i+1/2} - F_{i-1/2}) + S_i $$\nwhere $u_i$ is the cell-average of $u$, $F_{i\\pm1/2}$ are numerical fluxes at the cell faces, and $S_i$ is the cell-averaged source term. Integrating in time with Forward Euler over a step $\\Delta t$:\n$$ u_i^{n+1} = u_i^n - \\frac{\\Delta t}{\\Delta x} (F_{i+1/2}^n - F_{i-1/2}^n) + \\Delta t S_i^n $$\nThe problem specifies the numerical fluxes:\n- Physics flux $f_p(u) = cu$ ($c>0$): upwind scheme, so $f_{p, i+1/2} = f_p(u_i) = c u_i$.\n- Learned flux $g(u)$: centered average, so $g_{i+1/2} = \\frac{g(u_i) + g(u_{i+1})}{2}$.\n- Total flux at face $i+1/2$: $F_{i+1/2} = c u_i + \\frac{g(u_i) + g(u_{i+1})}{2}$.\n- The source term at cell $i$ is $S_i = s(u_i)$.\n\nA key property of FVM for periodic domains is that the discrete total mass $M^n = \\Delta x \\sum_{i=0}^{N_x-1} u_i^n$ is exactly conserved if there is no source term. This is because summing the update equation over all cells $i$ yields a telescoping sum for the flux differences that cancels to zero under periodic boundary conditions: $\\sum_{i=0}^{N_x-1} (F_{i+1/2} - F_{i-1/2}) = 0$. Thus, $\\sum_i u_i^{n+1} = \\sum_i u_i^n$, implying $M^{n+1} = M^n$.\n\nThe validation procedure involves computing the integral $I = \\int_0^T |M(t) - M(0)| \\, dt$, approximated discretely as $I \\approx \\sum_{n=1}^{N_t} \\Delta t |M^n - M^0|$. If the scheme is conservative, $M^n$ should equal $M^0$ up to floating-point precision, making $I$ very close to zero. The model is deemed conservative if $I \\le \\varepsilon$.\n\nThe implementation will proceed by creating a simulation function that takes the parameters for each test case. This function will:\n1. Initialize the grid and the initial condition $u(x,0) = a_0 + a_1 \\sin(2 \\pi x / L)$.\n2. Compute the initial mass $M^0$.\n3. Loop over time steps until the final time $T$ is reached. In each step:\n   a. Compute the numerical fluxes at all cell faces and the source terms at cell centers, handling periodic boundaries using `numpy.roll`.\n   b. Update the solution vector $u$ using the FVM formula.\n   c. Compute the current mass $M^n$ and add $\\Delta t |M^n - M^0|$ to the accumulated integral $I$.\n4. After the loop, compare the final $I$ with the given tolerance $\\varepsilon$ to return a boolean result.\n\nThis procedure will be applied to the four test cases specified. The expected results are `True` for the conservative cases (1, 3, 4) and `False` for the non-conservative case (2), as the numerical conservation property of the FVM scheme is independent of numerical stability issues that might arise in Case 4.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def run_simulation(Nx, L, c, cfl, T, a0, a1, alpha, beta, epsilon):\n        \"\"\"\n        Runs a single simulation case for the hybrid model validation.\n\n        Args:\n            Nx (int): Number of control volumes.\n            L (float): Domain length.\n            c (float): Advection speed.\n            cfl (float): CFL number to determine the time step.\n            T (float): Total simulation time.\n            a0 (float): Constant part of initial condition.\n            a1 (float): Amplitude of sine part of initial condition.\n            alpha (float): Coefficient for the learned conservative flux g(u).\n            beta (float): Coefficient for the learned non-conservative source s(u).\n            epsilon (float): Tolerance for the conservation integral.\n\n        Returns:\n            bool: True if the model is conservative (I <= epsilon), False otherwise.\n        \"\"\"\n        # 1. Setup discretization and grid\n        dx = L / Nx\n        dt = cfl * dx / c\n        \n        # 2. Initialize the solution field u\n        # Cell centers for finite volume method\n        x_centers = (np.arange(Nx) + 0.5) * dx\n        u = a0 + a1 * np.sin(2 * np.pi * x_centers / L)\n        \n        # 3. Define learned correction functions\n        def g(u_vec):\n            if alpha == 0.0:\n                # Return scalar 0.0 to enable broadcasting\n                return 0.0\n            return alpha * u_vec**3\n            \n        def s(u_vec):\n            if beta == 0.0:\n                return 0.0\n            return beta * u_vec\n            \n        # 4. Calculate initial mass and initialize validation integral\n        m0 = np.sum(u) * dx\n        integral_I = 0.0\n        \n        current_time = 0.0\n        \n        # 5. Time-stepping loop\n        while current_time < T:\n            # Use smaller timestep if the default dt overshoots T\n            dt_step = min(dt, T - current_time)\n            \n            # --- FVM Update Step ---\n            # Periodic boundaries are handled implicitly by np.roll.\n            u_prev = np.roll(u, 1) # u at i-1\n            u_next = np.roll(u, -1) # u at i+1\n            \n            # Physics flux (fp): upwind for c > 0\n            # fp at face i+1/2 is c*u_i\n            # fp at face i-1/2 is c*u_{i-1}\n            fp_plus = c * u\n            fp_minus = c * u_prev\n            \n            # Learned flux (g): centered average\n            # g at face i+1/2 is (g(u_i) + g(u_{i+1}))/2\n            # g at face i-1/2 is (g(u_{i-1}) + g(u_i))/2\n            g_vals = g(u)\n            if alpha != 0.0:\n                g_next_vals = np.roll(g_vals, -1)\n                g_prev_vals = np.roll(g_vals, 1)\n                fg_plus = (g_vals + g_next_vals) * 0.5\n                fg_minus = (g_prev_vals + g_vals) * 0.5\n            else:\n                fg_plus = 0.0\n                fg_minus = 0.0\n\n            # Total numerical flux at faces\n            F_plus = fp_plus + fg_plus   # Flux at i+1/2\n            F_minus = fp_minus + fg_minus # Flux at i-1/2\n            \n            # Learned source term (S)\n            S = s(u)\n            \n            # Update solution using Forward Euler FVM scheme\n            u = u - (dt_step / dx) * (F_plus - F_minus) + dt_step * S\n            # --- End of FVM Update Step ---\n            \n            current_time += dt_step\n            \n            # 6. Update the conservation validation integral I\n            m_current = np.sum(u) * dx\n            integral_I += dt_step * np.abs(m_current - m0)\n            \n        # 7. Return the boolean verdict\n        return integral_I <= epsilon\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Happy path (conservative learned flux)\n        {'Nx': 128, 'L': 1.0, 'c': 1.0, 'cfl': 0.5, 'T': 0.5, 'a0': 0.7, 'a1': 0.3, 'alpha': 0.2, 'beta': 0.0, 'epsilon': 1e-10},\n        # 2. Non-conservative source\n        {'Nx': 128, 'L': 1.0, 'c': 1.0, 'cfl': 0.5, 'T': 0.5, 'a0': 0.7, 'a1': 0.3, 'alpha': 0.0, 'beta': 0.05, 'epsilon': 1e-6},\n        # 3. Zero learned correction (edge case)\n        {'Nx': 256, 'L': 1.0, 'c': 1.0, 'cfl': 0.5, 'T': 0.5, 'a0': 0.7, 'a1': 0.3, 'alpha': 0.0, 'beta': 0.0, 'epsilon': 1e-12},\n        # 4. Coarse grid near CFL limit (boundary case)\n        {'Nx': 8, 'L': 1.0, 'c': 1.0, 'cfl': 1.0, 'T': 0.25, 'a0': 0.7, 'a1': 0.3, 'alpha': 5.0, 'beta': 0.0, 'epsilon': 1e-8},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        result = run_simulation(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}