{
    "hands_on_practices": [
        {
            "introduction": "A crucial aspect of statistical modeling is not just proposing estimators, but also rigorously evaluating their performance. This practice introduces the Mean Squared Error ($\\mathrm{MSE}$) as a fundamental metric that decomposes an estimator's total error into its bias and variance. By analyzing a simple biased estimator versus its unbiased counterpart , you will gain a concrete understanding of the celebrated bias-variance tradeoff, a cornerstone concept for developing robust models in the face of uncertainty and model mismatch.",
            "id": "4247291",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) is tasked with estimating a scalar calibration parameter $\\theta$ that affects a measurement channel. The CPS provides $n$ synchronous samples $\\{y_{i}\\}_{i=1}^{n}$ generated according to the data-generating process $y_{i} = \\theta + \\varepsilon_{i}$, where $\\varepsilon_{i}$ are independent, zero-mean disturbances with variance $\\sigma^{2}$, and the DT’s modeling pipeline assumes homoscedasticity and independence across samples.\n\nTo compensate for model mismatch identified in system identification, the DT deploys a biased estimator $\\hat{\\theta}_{b} = \\bar{y} + c$, where $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_{i}$ and $c$ is a known constant offset. The reference unbiased estimator is $\\hat{\\theta}_{u} = \\bar{y}$. Using only core definitions of expectation, variance, bias, and the mean squared error under Euclidean norm squared loss (commonly called $L_{2}$ loss), derive the mean squared error of $\\hat{\\theta}_{b}$ and $\\hat{\\theta}_{u}$, and compute the comparison requested below.\n\nGiven $n = 36$, $\\sigma^{2} = 0.09$, and $c = 0.05$, compute the ratio $\\mathrm{MSE}(\\hat{\\theta}_{b}) / \\mathrm{MSE}(\\hat{\\theta}_{u})$. Express your final answer as a pure number rounded to four significant figures.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- Data-generating process: $y_{i} = \\theta + \\varepsilon_{i}$ for $i=1, \\dots, n$.\n- Disturbances $\\varepsilon_{i}$ are independent and identically distributed (i.i.d.) with $\\mathbb{E}[\\varepsilon_{i}] = 0$ and $\\mathrm{Var}(\\varepsilon_{i}) = \\sigma^{2}$.\n- Number of samples: $n$.\n- Sample mean: $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_{i}$.\n- Unbiased estimator: $\\hat{\\theta}_{u} = \\bar{y}$.\n- Biased estimator: $\\hat{\\theta}_{b} = \\bar{y} + c$, where $c$ is a known constant.\n- Loss function: Mean Squared Error (MSE), defined as $\\mathrm{MSE}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\theta)^2]$.\n- Provided numerical values: $n = 36$, $\\sigma^{2} = 0.09$, $c = 0.05$.\n- Task: Compute the ratio $\\mathrm{MSE}(\\hat{\\theta}_{b}) / \\mathrm{MSE}(\\hat{\\theta}_{u})$ and round the result to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it is based on fundamental principles of statistical estimation theory (bias, variance, mean squared error), which are central to modeling and analysis in cyber-physical systems and digital twins. The problem is well-posed, with all necessary data and definitions provided to arrive at a unique, meaningful solution. The language is objective and formal. The setup is complete and internally consistent. The model is a standard representation of a constant signal corrupted by additive noise, and the numerical values are plausible.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe solution proceeds by first deriving the expressions for the Mean Squared Error (MSE) of the two estimators, $\\hat{\\theta}_{u}$ and $\\hat{\\theta}_{b}$, and then computing their ratio using the provided numerical values. A fundamental property of the MSE is its decomposition into the square of the bias and the variance of the estimator:\n$$\n\\mathrm{MSE}(\\hat{\\theta}) = (\\mathrm{Bias}(\\hat{\\theta}))^2 + \\mathrm{Var}(\\hat{\\theta})\n$$\nwhere the bias is $\\mathrm{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$ and the variance is $\\mathrm{Var}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^2]$.\n\nFirst, we analyze the properties of the sample mean, $\\bar{y}$, which is a component of both estimators.\nThe expectation of the sample mean is:\n$$\n\\mathbb{E}[\\bar{y}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n} y_{i}\\right] = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{E}[y_{i}]\n$$\nGiven $y_i = \\theta + \\varepsilon_i$ and $\\mathbb{E}[\\varepsilon_i] = 0$, the expectation of a single sample is $\\mathbb{E}[y_i] = \\mathbb{E}[\\theta + \\varepsilon_i] = \\theta + \\mathbb{E}[\\varepsilon_i] = \\theta$.\nThus,\n$$\n\\mathbb{E}[\\bar{y}] = \\frac{1}{n}\\sum_{i=1}^{n} \\theta = \\frac{1}{n}(n\\theta) = \\theta\n$$\nThe variance of the sample mean is:\n$$\n\\mathrm{Var}(\\bar{y}) = \\mathrm{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n} y_{i}\\right) = \\frac{1}{n^2}\\mathrm{Var}\\left(\\sum_{i=1}^{n} y_{i}\\right)\n$$\nSince the disturbances $\\varepsilon_i$ are independent, the samples $y_i$ are also independent. Therefore, the variance of the sum is the sum of the variances:\n$$\n\\mathrm{Var}(\\bar{y}) = \\frac{1}{n^2}\\sum_{i=1}^{n}\\mathrm{Var}(y_i)\n$$\nThe variance of a single sample is $\\mathrm{Var}(y_i) = \\mathrm{Var}(\\theta + \\varepsilon_i) = \\mathrm{Var}(\\varepsilon_i) = \\sigma^2$, as $\\theta$ is a constant.\nThus,\n$$\n\\mathrm{Var}(\\bar{y}) = \\frac{1}{n^2}\\sum_{i=1}^{n}\\sigma^2 = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}\n$$\n\nNow, we can compute the MSE for each estimator.\n\nFor the unbiased estimator $\\hat{\\theta}_{u} = \\bar{y}$:\nThe expectation is $\\mathbb{E}[\\hat{\\theta}_{u}] = \\mathbb{E}[\\bar{y}] = \\theta$.\nThe bias is $\\mathrm{Bias}(\\hat{\\theta}_{u}) = \\mathbb{E}[\\hat{\\theta}_{u}] - \\theta = \\theta - \\theta = 0$.\nThe variance is $\\mathrm{Var}(\\hat{\\theta}_{u}) = \\mathrm{Var}(\\bar{y}) = \\frac{\\sigma^2}{n}$.\nThe MSE for the unbiased estimator is:\n$$\n\\mathrm{MSE}(\\hat{\\theta}_{u}) = (\\mathrm{Bias}(\\hat{\\theta}_{u}))^2 + \\mathrm{Var}(\\hat{\\theta}_{u}) = 0^2 + \\frac{\\sigma^2}{n} = \\frac{\\sigma^2}{n}\n$$\n\nFor the biased estimator $\\hat{\\theta}_{b} = \\bar{y} + c$:\nThe expectation is $\\mathbb{E}[\\hat{\\theta}_{b}] = \\mathbb{E}[\\bar{y} + c] = \\mathbb{E}[\\bar{y}] + c = \\theta + c$.\nThe bias is $\\mathrm{Bias}(\\hat{\\theta}_{b}) = \\mathbb{E}[\\hat{\\theta}_{b}] - \\theta = (\\theta + c) - \\theta = c$.\nThe variance is $\\mathrm{Var}(\\hat{\\theta}_{b}) = \\mathrm{Var}(\\bar{y} + c)$. Since $c$ is a constant, it does not affect the variance, so $\\mathrm{Var}(\\hat{\\theta}_{b}) = \\mathrm{Var}(\\bar{y}) = \\frac{\\sigma^2}{n}$.\nThe MSE for the biased estimator is:\n$$\n\\mathrm{MSE}(\\hat{\\theta}_{b}) = (\\mathrm{Bias}(\\hat{\\theta}_{b}))^2 + \\mathrm{Var}(\\hat{\\theta}_{b}) = c^2 + \\frac{\\sigma^2}{n}\n$$\n\nFinally, we compute the required ratio:\n$$\n\\frac{\\mathrm{MSE}(\\hat{\\theta}_{b})}{\\mathrm{MSE}(\\hat{\\theta}_{u})} = \\frac{c^2 + \\frac{\\sigma^2}{n}}{\\frac{\\sigma^2}{n}} = \\frac{c^2}{\\frac{\\sigma^2}{n}} + \\frac{\\frac{\\sigma^2}{n}}{\\frac{\\sigma^2}{n}} = \\frac{nc^2}{\\sigma^2} + 1\n$$\nWe substitute the given numerical values: $n = 36$, $\\sigma^{2} = 0.09$, and $c = 0.05$.\n$$\n\\frac{\\mathrm{MSE}(\\hat{\\theta}_{b})}{\\mathrm{MSE}(\\hat{\\theta}_{u})} = \\frac{36 \\times (0.05)^2}{0.09} + 1\n$$\nFirst, calculate the term in the numerator: $36 \\times (0.05)^2 = 36 \\times 0.0025 = 0.09$.\nNow substitute this back into the expression:\n$$\n\\frac{\\mathrm{MSE}(\\hat{\\theta}_{b})}{\\mathrm{MSE}(\\hat{\\theta}_{u})} = \\frac{0.09}{0.09} + 1 = 1 + 1 = 2\n$$\nThe problem requires the answer to be expressed as a pure number rounded to four significant figures. Since the result is exactly $2$, we write it as $2.000$ to explicitly denote the required precision.",
            "answer": "$$\\boxed{2.000}$$"
        },
        {
            "introduction": "Building on the concept of estimator performance, we now explore how to systematically incorporate prior knowledge into our models using Bayesian methods. This exercise guides you through deriving a Maximum A Posteriori (MAP) estimator, which finds the most probable parameter value by combining evidence from data (the likelihood) with existing beliefs (the prior). You will discover the phenomenon of \"shrinkage\" , where the final estimate is a weighted average of the data-driven result and the prior belief, providing a powerful mechanism for regularizing estimates and improving performance, especially with noisy or limited data.",
            "id": "4247342",
            "problem": "A Cyber-Physical System (CPS) digital twin is used to continuously calibrate a latent operating parameter, the mean vibration amplitude, denoted by $\\mu$, of a rotating component. At calibration cycle $t$, the digital twin collects $n$ sensor observations $\\{y_i\\}_{i=1}^{n}$ subject to additive sensor noise that is modeled as independent and identically distributed Gaussian with known variance $\\sigma^{2}$, so that $y_i \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ for $i=1,\\dots,n$. Prior engineering knowledge from previous operating cycles is represented as a Gaussian prior $\\mu \\sim \\mathcal{N}(\\mu_{0},\\tau^{2})$ with known hyperparameters $\\mu_{0}$ and $\\tau^{2}$.\n\nStarting from first principles of Bayesian inference and the Maximum A Posteriori (MAP) definition, derive the closed-form MAP estimator for $\\mu$ under these assumptions. Your derivation must begin from the definition of the likelihood, the prior, and Bayes’ rule, and proceed by optimizing the posterior density with respect to $\\mu$. In your explanation, articulate the statistical mechanism by which the estimator exhibits shrinkage, including how the estimator balances the sample mean toward the prior mean as a function of $n$, $\\sigma^{2}$, and $\\tau^{2}$, and discuss the limiting behavior when $\\tau^{2} \\to \\infty$ and when $\\tau^{2} \\to 0$.\n\nProvide the final estimator as a single closed-form analytical expression in terms of $n$, $\\sigma^{2}$, $\\tau^{2}$, $\\mu_{0}$, and the sample mean $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$. No numerical rounding is required, and no units are to be included in the final expression.",
            "solution": "The user wants to solve the problem.\nThe problem is valid. I will proceed with the solution.\n\nThe objective is to derive the Maximum A Posteriori (MAP) estimator for the mean vibration amplitude $\\mu$ of a rotating component, given a set of sensor observations and prior knowledge about the parameter.\n\nThe problem provides the following:\n1.  A set of $n$ sensor observations $\\{y_i\\}_{i=1}^{n}$.\n2.  A likelihood model for each observation: $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where the observations are independent and identically distributed (i.i.d.) and the variance $\\sigma^2$ is known.\n3.  A prior distribution for the parameter $\\mu$: $\\mu \\sim \\mathcal{N}(\\mu_0, \\tau^2)$, where the hyperparameters $\\mu_0$ and $\\tau^2$ are known.\n\nThe derivation will proceed from the first principles of Bayesian inference.\n\nAccording to Bayes' rule, the posterior probability density of the parameter $\\mu$ given the data $\\{y_i\\}$ is proportional to the product of the likelihood of the data given the parameter and the prior probability density of the parameter.\n$$\np(\\mu | y_1, \\dots, y_n) \\propto p(y_1, \\dots, y_n | \\mu) \\, p(\\mu)\n$$\nwhere $p(\\mu | y_1, \\dots, y_n)$ is the posterior, $p(y_1, \\dots, y_n | \\mu)$ is the likelihood, and $p(\\mu)$ is the prior.\n\nFirst, we define the likelihood function, $L(\\mu) = p(y_1, \\dots, y_n | \\mu)$. Since the observations $\\{y_i\\}$ are i.i.d., the joint likelihood is the product of the individual probability densities:\n$$\nL(\\mu) = \\prod_{i=1}^{n} p(y_i | \\mu)\n$$\nGiven the Gaussian model $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, the probability density function for a single observation is:\n$$\np(y_i | \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right)\n$$\nThe full likelihood function is therefore:\n$$\nL(\\mu) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 \\right)\n$$\n\nNext, we define the prior distribution for $\\mu$, which is given as $\\mu \\sim \\mathcal{N}(\\mu_0, \\tau^2)$:\n$$\np(\\mu) = \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left( -\\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right)\n$$\n\nNow, we construct the posterior density by multiplying the likelihood and the prior. We can ignore the normalization constants as they do not depend on $\\mu$:\n$$\np(\\mu | \\{y_i\\}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 \\right) \\exp\\left( -\\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right)\n$$\nCombining the exponents, we get:\n$$\np(\\mu | \\{y_i\\}) \\propto \\exp\\left( - \\left[ \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 + \\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right] \\right)\n$$\n\nThe MAP estimator, denoted $\\hat{\\mu}_{\\text{MAP}}$, is the value of $\\mu$ that maximizes this posterior probability density. It is computationally more convenient to maximize the natural logarithm of the posterior, as the logarithm is a monotonic function. Let $\\mathcal{L}(\\mu) = \\ln(p(\\mu | \\{y_i\\}))$.\n$$\n\\mathcal{L}(\\mu) = C - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 - \\frac{(\\mu - \\mu_0)^2}{2\\tau^2}\n$$\nwhere $C$ is a constant term that does not depend on $\\mu$. To find the maximum, we take the derivative of $\\mathcal{L}(\\mu)$ with respect to $\\mu$ and set it to zero:\n$$\n\\frac{d\\mathcal{L}}{d\\mu} = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} 2(y_i - \\mu)(-1) - \\frac{1}{2\\tau^2} 2(\\mu - \\mu_0)(1) = 0\n$$\n$$\n\\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu) - \\frac{1}{\\tau^2}(\\mu - \\mu_0) = 0\n$$\nRecognizing that $\\sum_{i=1}^{n} y_i = n\\bar{y}$, where $\\bar{y}$ is the sample mean, we have:\n$$\n\\frac{1}{\\sigma^2} (n\\bar{y} - n\\mu) - \\frac{1}{\\tau^2}(\\mu - \\mu_0) = 0\n$$\nNow, we solve for $\\mu$:\n$$\n\\frac{n\\bar{y}}{\\sigma^2} - \\frac{n\\mu}{\\sigma^2} - \\frac{\\mu}{\\tau^2} + \\frac{\\mu_0}{\\tau^2} = 0\n$$\n$$\n\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2} = \\mu \\left( \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2} \\right)\n$$\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\mu = \\frac{\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}}\n$$\nTo obtain the expression in the required form, we multiply the numerator and denominator by $\\sigma^2\\tau^2$:\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\n\nThis closed-form solution for $\\hat{\\mu}_{\\text{MAP}}$ can be rewritten as a weighted average of the sample mean $\\bar{y}$ and the prior mean $\\mu_0$:\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\left(\\frac{n\\tau^2}{n\\tau^2 + \\sigma^2}\\right) \\bar{y} + \\left(\\frac{\\sigma^2}{n\\tau^2 + \\sigma^2}\\right) \\mu_0\n$$\n\nThis form clearly illustrates the statistical mechanism of shrinkage. The MAP estimate is a convex combination of the maximum likelihood estimate (which for a Gaussian is the sample mean $\\bar{y}$) and the prior mean $\\mu_0$. The data-driven estimate $\\bar{y}$ is \"shrunk\" toward the prior belief $\\mu_0$. The degree of shrinkage is determined by the weights, which depend on the sample size $n$, the sensor noise variance $\\sigma^2$, and the prior variance $\\tau^2$.\n-   A larger sample size $n$ increases the weight on $\\bar{y}$, meaning the estimate relies more on the data.\n-   A larger sensor noise variance $\\sigma^2$ increases the weight on $\\mu_0$, signifying that noisy data are less trustworthy, so the estimate relies more on the prior.\n-   A larger prior variance $\\tau^2$ (a less certain prior) increases the weight on $\\bar{y}$, as the prior information is considered less reliable.\n\nWe now analyze the limiting behavior of the estimator.\n\nCase 1: Uninformative prior, $\\tau^2 \\to \\infty$. This represents a scenario with very weak prior knowledge.\n$$\n\\lim_{\\tau^2 \\to \\infty} \\hat{\\mu}_{\\text{MAP}} = \\lim_{\\tau^2 \\to \\infty} \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\nDividing the numerator and denominator by $\\tau^2$:\n$$\n\\lim_{\\tau^2 \\to \\infty} \\frac{n\\bar{y} + \\frac{\\sigma^2}{\\tau^2}\\mu_0}{n + \\frac{\\sigma^2}{\\tau^2}} = \\frac{n\\bar{y} + 0}{n + 0} = \\bar{y}\n$$\nIn this limit, the MAP estimator converges to the sample mean $\\bar{y}$, which is the Maximum Likelihood Estimate (MLE). The prior's influence vanishes.\n\nCase 2: Infinitely strong prior, $\\tau^2 \\to 0$. This represents absolute certainty that $\\mu = \\mu_0$.\n$$\n\\lim_{\\tau^2 \\to 0} \\hat{\\mu}_{\\text{MAP}} = \\lim_{\\tau^2 \\to 0} \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\nAs $\\tau^2 \\to 0$, the terms involving $\\tau^2$ vanish:\n$$\n\\lim_{\\tau^2 \\to 0} \\frac{n(0)\\bar{y} + \\sigma^2\\mu_0}{n(0) + \\sigma^2} = \\frac{\\sigma^2\\mu_0}{\\sigma^2} = \\mu_0\n$$\nIn this limit, the MAP estimator discards the data entirely and is fixed at the prior mean $\\mu_0$. The prior belief is so strong that no amount of data can alter it.",
            "answer": "$$\n\\boxed{\\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}}\n$$"
        },
        {
            "introduction": "Many real-world cyber-physical systems are characterized by nonlinear dynamics, where exact analytical solutions for state estimation are intractable. This final practice moves from static parameter estimation to the challenge of tracking a hidden state in a dynamic system using computational methods. You will implement a bootstrap particle filter , a powerful sequential Monte Carlo technique that approximates the evolving state distribution with a cloud of weighted \"particles,\" providing a hands-on foundation for tackling complex, real-world tracking and filtering problems in digital twins.",
            "id": "4247459",
            "problem": "You are given a scalar Cyber-Physical System (CPS) governed by a nonlinear discrete-time state-space model with process and measurement uncertainties. The latent state is denoted by $x_k \\in \\mathbb{R}$ at discrete time index $k \\in \\{0, 1, 2, \\dots\\}$, the process noise by $w_k \\in \\mathbb{R}$, and the measurement noise by $v_k \\in \\mathbb{R}$. The model is\n- State transition: $x_{k+1} = x_k^2 + w_k$,\n- Measurement: $y_k = x_k + v_k$,\nwith independent Gaussian uncertainties $w_k \\sim \\mathcal{N}(0, q)$ and $v_k \\sim \\mathcal{N}(0, r)$, and a Gaussian prior $x_0 \\sim \\mathcal{N}(m_0, P_0)$, where $q > 0$, $r > 0$, $P_0 > 0$.\n\nTask: Implement a bootstrap particle filter that performs sequential Bayesian estimation using $N$ particles with the proposal equal to the state transition density. At each time step $k$, before any resampling, compute the Effective Sample Size (ESS) defined by\n$$\nN_{\\text{eff}}(k) = \\frac{1}{\\sum_{i=1}^{N} \\tilde{w}_{k}^{(i)\\,2}},\n$$\nwhere $\\tilde{w}_{k}^{(i)}$ are the normalized importance weights at time $k$. Use systematic resampling only when the pre-resampling ESS satisfies $N_{\\text{eff}}(k) < N/2$. The particle filtering recursion at time $k$ should be:\n- For $k = 0$: draw $x_0^{(i)} \\sim \\mathcal{N}(m_0, P_0)$, compute weights proportional to the likelihood $p(y_0 \\mid x_0^{(i)})$, normalize the weights, compute $N_{\\text{eff}}(0)$, and if $N_{\\text{eff}}(0) < N/2$ then resample and reset the weights to uniform.\n- For $k \\ge 1$: propagate $x_k^{(i)} = \\left(x_{k-1}^{(i)}\\right)^2 + w_{k-1}^{(i)}$ with $w_{k-1}^{(i)} \\sim \\mathcal{N}(0, q)$, update weights proportional to $p(y_k \\mid x_k^{(i)})$ multiplied by the previous weights, normalize the weights, compute $N_{\\text{eff}}(k)$, and if $N_{\\text{eff}}(k) < N/2$ then resample and reset the weights to uniform.\n\nImplementation constraints and requirements:\n- Use a fixed pseudorandom number generator seed $s = 12345$ for reproducibility. If multiple test cases are evaluated in one program run, use seeds $s, s+1, s+2, \\dots$ for successive cases in the order listed below to ensure deterministic and distinct randomness across test cases.\n- Use numerically stable computations for weights by working in the logarithmic domain to avoid underflow, and normalize via a log-sum-exp stabilization.\n- The output for each test case is a single real number equal to the minimum pre-resampling $N_{\\text{eff}}(k)$ over all time indices $k \\in \\{0, \\dots, T-1\\}$, where $T$ is the length of the measurement sequence in that test case.\n- Express the final numerical answers rounded to exactly $4$ decimal places.\n\nTest suite:\nEvaluate your bootstrap particle filter on the following three test cases. In every case, the measurement sequence length is $T = 6$ with observations $y_0, y_1, y_2, y_3, y_4, y_5$.\n\n- Test case $1$ (happy path):\n  - Number of particles: $N = 5000$.\n  - Process noise variance: $q = 0.05$.\n  - Measurement noise variance: $r = 0.2$.\n  - Prior mean and variance: $m_0 = 0.3$, $P_0 = 0.4$.\n  - Measurements: $y = [0.25, 0.11, 0.15, 0.05, 0.10, 0.18]$.\n\n- Test case $2$ (boundary with small $N$ and higher noise):\n  - Number of particles: $N = 200$.\n  - Process noise variance: $q = 0.2$.\n  - Measurement noise variance: $r = 0.8$.\n  - Prior mean and variance: $m_0 = 0.0$, $P_0 = 1.0$.\n  - Measurements: $y = [0.2, -0.1, 0.0, 0.05, -0.2, 0.1]$.\n\n- Test case $3$ (edge case with strong nonlinearity and low noise):\n  - Number of particles: $N = 3000$.\n  - Process noise variance: $q = 0.01$.\n  - Measurement noise variance: $r = 0.05$.\n  - Prior mean and variance: $m_0 = -1.0$, $P_0 = 0.1$.\n  - Measurements: $y = [-0.90, 0.85, 0.70, 0.55, 0.36, 0.14]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- Specifically, the output must be a single line of the form\n  $$\n  [\\text{res}_1,\\text{res}_2,\\text{res}_3],\n  $$\n  where $\\text{res}_j$ is the minimum pre-resampling effective sample size for test case $j$ rounded to exactly $4$ decimal places (no units).\n\nAngle units and physical units:\n- No angular quantities appear; no angle units are required.\n- The effective sample size is dimensionless; no physical units are required.\n\nYour implementation must be a complete, runnable program that uses only the standard library and the specified numerical libraries, reads no input, and prints exactly one line in the specified format.",
            "solution": "The user has provided a well-defined problem in the domain of statistical estimation for nonlinear dynamical systems. The problem is scientifically grounded, self-contained, and algorithmically specific. It requires the implementation of a bootstrap particle filter, a standard Monte Carlo method for solving state estimation problems. All parameters, system dynamics, and evaluation criteria are provided unambiguously. Therefore, the problem is valid.\n\nThe core of the problem is to perform sequential Bayesian estimation for a scalar state $x_k$ at discrete time $k$, governed by the nonlinear state-space model:\n$$\n\\text{State transition: } x_{k+1} = x_k^2 + w_k, \\quad w_k \\sim \\mathcal{N}(0, q)\n$$\n$$\n\\text{Measurement: } y_k = x_k + v_k, \\quad v_k \\sim \\mathcal{N}(0, r)\n$$\nThe estimation is based on a sequence of measurements $y_0, y_1, \\dots, y_{T-1}$. The particle filter approximates the posterior probability density function $p(x_k | y_{0:k})$ with a set of $N$ weighted samples or \"particles\" $\\{(x_k^{(i)}, \\tilde{w}_k^{(i)})\\}_{i=1}^N$. The solution proceeds by implementing the specified bootstrap particle filter algorithm.\n\nThe bootstrap filter is a specific type of Sequential Importance Resampling (SIR) filter where the proposal distribution for generating particles at the next time step is chosen to be the state transition distribution, $p(x_k | x_{k-1})$. This choice simplifies the weight update equation. The algorithm proceeds recursively as follows:\n\n**Step 1: Initialization ($k=0$)**\nWe begin by drawing $N$ initial particles from the prior distribution of the state. The problem specifies a Gaussian prior $x_0 \\sim \\mathcal{N}(m_0, P_0)$.\n$$\nx_0^{(i)} \\sim \\mathcal{N}(m_0, P_0) \\quad \\text{for } i=1, \\dots, N\n$$\nThe initial weights are uniform, which is equivalent to assuming no prior information before the first measurement. We then incorporate the first measurement, $y_0$, by updating a set of unnormalized weights, $w_0^{(i)}$, to be proportional to the likelihood of observing $y_0$ given the particle's state $x_0^{(i)}$.\n$$\nw_0^{(i)} \\propto p(y_0 | x_0^{(i)})\n$$\nSince the measurement noise $v_0 = y_0 - x_0$ is Gaussian with variance $r$, the likelihood function is the probability density function (PDF) of a Gaussian distribution $\\mathcal{N}(x_0^{(i)}, r)$ evaluated at $y_0$. For numerical stability, we work with log-weights. The unnormalized log-weight is:\n$$\n\\log w_0^{(i)} = \\log p(y_0 | x_0^{(i)}) = -\\frac{1}{2}\\log(2\\pi r) - \\frac{(y_0 - x_0^{(i)})^2}{2r}\n$$\n\n**Step 2: Propagation (for $k \\ge 1$)**\nFor subsequent time steps, we first predict the next state of each particle using the state transition model. This is the \"bootstrap\" step, where we sample from the dynamics. A particle $x_{k-1}^{(i)}$ from the previous step is propagated forward to time $k$:\n$$\nx_k^{(i)} = (x_{k-1}^{(i)})^2 + w_{k-1}^{(i)}, \\quad \\text{where } w_{k-1}^{(i)} \\sim \\mathcal{N}(0, q)\n$$\nThis generates a new set of particles $\\{x_k^{(i)}\\}_{i=1}^N$ that represents an empirical approximation of the predictive density $p(x_k|y_{0:k-1})$.\n\n**Step 3: Weight Update (for $k \\ge 1$)**\nUpon receiving a new measurement $y_k$, the weights are updated to reflect how well each propagated particle $x_k^{(i)}$ agrees with this measurement. The update rule for a general particle filter is $w_k^{(i)} \\propto \\tilde{w}_{k-1}^{(i)} \\frac{p(y_k|x_k^{(i)})p(x_k^{(i)}|x_{k-1}^{(i)})}{q(x_k^{(i)}|x_{k-1}^{(i)})}$, where $\\tilde{w}_{k-1}^{(i)}$ is the normalized weight from the previous step and $q(\\cdot)$ is the proposal distribution. In a bootstrap filter, the proposal is the prior, $q(x_k^{(i)}|x_{k-1}^{(i)}) = p(x_k^{(i)}|x_{k-1}^{(i)})$, so the fraction cancels. The update simplifies to:\n$$\nw_k^{(i)} \\propto \\tilde{w}_{k-1}^{(i)} p(y_k | x_k^{(i)})\n$$\nIn the logarithmic domain, this becomes an additive update:\n$$\n\\log w_k^{(i)} = \\log \\tilde{w}_{k-1}^{(i)} + \\log p(y_k | x_k^{(i)})\n$$\n\n**Step 4: Normalization and Effective Sample Size (ESS) Calculation**\nThe unnormalized log-weights $\\log w_k^{(i)}$ are normalized to yield weights $\\tilde{w}_k^{(i)}$ that sum to $1$. To avoid numerical underflow/overflow, this is done using the log-sum-exp trick:\n$$\nS_k = \\log\\left(\\sum_{i=1}^N \\exp(\\log w_k^{(i)})\\right)\n$$\nThe normalized log-weights are $\\log \\tilde{w}_k^{(i)} = \\log w_k^{(i)} - S_k$, and the normalized weights are $\\tilde{w}_k^{(i)} = \\exp(\\log \\tilde{w}_k^{(i)})$.\n\nBefore any resampling, we compute the Effective Sample Size (ESS) to measure particle degeneracy. A low ESS indicates that a few particles have very high weights, making the approximation of the posterior poor. The formula is:\n$$\nN_{\\text{eff}}(k) = \\frac{1}{\\sum_{i=1}^{N} (\\tilde{w}_{k}^{(i)})^2}\n$$\nThis value is computed and stored for each time step $k \\in \\{0, \\dots, T-1\\}$ to find the minimum as required by the problem.\n\n**Step 5: Resampling**\nIf the particle set is degenerate, as indicated by $N_{\\text{eff}}(k) < N/2$, a resampling step is performed. We will implement systematic resampling, a low-variance method. This step creates a new set of particles by drawing $N$ times from the current particle set $\\{x_k^{(i)}\\}$ with probabilities given by their weights $\\{\\tilde{w}_k^{(i)}\\}$. High-weight particles are likely to be duplicated, while low-weight particles are likely to be eliminated. After resampling, the particles are replaced by the new set, and their weights are reset to be uniform: $\\tilde{w}_k^{(i)} = 1/N$ for all $i$. In the log domain, this means $\\log \\tilde{w}_k^{(i)} = -\\log N$. If no resampling occurs, the normalized weights $\\tilde{w}_k^{(i)}$ (or their logs) are carried forward to the next time step.\n\nThis entire sequence—propagation, weighting, normalization, ESS calculation, and conditional resampling—is repeated for each time step from $k=0$ to $k=T-1$. The final output for each test case is the minimum of the pre-resampling $N_{\\text{eff}}(k)$ values recorded over this interval. The implementation will use a fixed random seed for each test case to ensure reproducibility.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_particle_filter(N, q, r, m0, P0, y_seq, seed):\n    \"\"\"\n    Implements a bootstrap particle filter for a nonlinear state-space model.\n\n    Args:\n        N (int): Number of particles.\n        q (float): Process noise variance.\n        r (float): Measurement noise variance.\n        m0 (float): Prior mean.\n        P0 (float): Prior variance.\n        y_seq (list or np.ndarray): Sequence of measurements.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        float: The minimum pre-resampling effective sample size (ESS).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    T = len(y_seq)\n    \n    # Standard deviations for noise generation\n    std_q = np.sqrt(q)\n    std_r = np.sqrt(r)\n\n    # --- Step 1: Initialization (k=0) ---\n    # Draw initial particles from the prior distribution\n    # These represent the particle set for time k=0, i.e., {x_0^(i)}\n    particles = rng.normal(loc=m0, scale=np.sqrt(P0), size=N)\n    \n    # Initialize log weights to be uniform. These represent log(w_tilde_{-1}),\n    # which are implicitly uniform before the first measurement.\n    log_weights = np.full(N, -np.log(N))\n    \n    all_ess_values = []\n\n    # --- Main Loop (k = 0 to T-1) ---\n    for k in range(T):\n        # At the start of loop k, `particles` holds {x_{k-1}^{(i)}} and `log_weights` holds log(w_tilde_{k-1}).\n        # For k=0, `particles` holds {x_0^{(i)}} and there is no propagation.\n        \n        # --- Step 2: Propagation (for k >= 1) ---\n        if k > 0:\n            process_noise = rng.normal(loc=0.0, scale=std_q, size=N)\n            particles = particles**2 + process_noise\n        \n        # `particles` now holds the set {x_k^(i)}\n\n        # --- Step 3: Weight Update ---\n        # Calculate log-likelihood log p(y_k | x_k^(i))\n        log_likelihood = norm.logpdf(y_seq[k], loc=particles, scale=std_r)\n        \n        # Update log-weights: log(w_k) = log(w_tilde_{k-1}) + log p(y_k | x_k)\n        unnormalized_log_weights = log_weights + log_likelihood\n\n        # --- Step 4: Normalization and ESS Calculation ---\n        # Normalize weights using log-sum-exp trick for numerical stability\n        max_log = np.max(unnormalized_log_weights)\n        if np.isneginf(max_log): # All weights are -inf, numerically unstable\n            # This can happen if all particles are extremely unlikely.\n            # We can reset to uniform weights to recover, but for this problem,\n            # this indicates a serious filter divergence.\n            # To avoid division by zero, we set weights to uniform.\n            normalized_weights = np.full(N, 1.0/N)\n            log_weights = np.log(normalized_weights)\n        else:\n            temp_weights = np.exp(unnormalized_log_weights - max_log)\n            sum_of_weights = np.sum(temp_weights)\n            log_sum = max_log + np.log(sum_of_weights)\n            normalized_weights = temp_weights / sum_of_weights\n            log_weights = unnormalized_log_weights - log_sum\n        \n        # Calculate pre-resampling Effective Sample Size (ESS)\n        ess = 1.0 / np.sum(normalized_weights**2)\n        all_ess_values.append(ess)\n\n        # --- Step 5: Resampling ---\n        if ess < N / 2.0:\n            # Systematic resampling\n            positions = (np.arange(N) + rng.random()) / N\n            cumulative_sum = np.cumsum(normalized_weights)\n            indices = np.searchsorted(cumulative_sum, positions, side='left')\n            \n            # Ensure indices are within bounds (can happen with numerical precision issues)\n            indices = np.clip(indices, 0, N - 1)\n\n            particles = particles[indices]\n            log_weights = np.full(N, -np.log(N)) # Reset weights to uniform\n\n    return min(all_ess_values)\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the particle filter, and print results.\n    \"\"\"\n    base_seed = 12345\n\n    test_cases = [\n        {\n            \"N\": 5000, \"q\": 0.05, \"r\": 0.2, \"m0\": 0.3, \"P0\": 0.4,\n            \"y\": [0.25, 0.11, 0.15, 0.05, 0.10, 0.18]\n        },\n        {\n            \"N\": 200, \"q\": 0.2, \"r\": 0.8, \"m0\": 0.0, \"P0\": 1.0,\n            \"y\": [0.2, -0.1, 0.0, 0.05, -0.2, 0.1]\n        },\n        {\n            \"N\": 3000, \"q\": 0.01, \"r\": 0.05, \"m0\": -1.0, \"P0\": 0.1,\n            \"y\": [-0.90, 0.85, 0.70, 0.55, 0.36, 0.14]\n        }\n    ]\n\n    results = []\n    for i, case in enumerate(test_cases):\n        min_ess = run_particle_filter(\n            N=case[\"N\"],\n            q=case[\"q\"],\n            r=case[\"r\"],\n            m0=case[\"m0\"],\n            P0=case[\"P0\"],\n            y_seq=case[\"y\"],\n            seed=base_seed + i\n        )\n        results.append(f\"{min_ess:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}