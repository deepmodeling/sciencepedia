{
    "hands_on_practices": [
        {
            "introduction": "The controllability of a linearized model is often used as a proxy for the controllability of the underlying nonlinear system. This exercise  provides a crucial counterexample, demonstrating how physical constraints, such as unidirectional actuators, can render a system locally uncontrollable even when its linearization suggests otherwise. By working through this problem, you will develop a deeper appreciation for the limitations of linear analysis and the importance of considering physical realities in cyber-physical systems.",
            "id": "4230034",
            "problem": "A cyber-physical system (CPS) has a digital twin that uses linearization to design controllers for a planar vehicle subject to a unidirectional thrust actuator. The physical plant is modeled by the nonlinear state equations\n$$\n\\dot{x}_{1} = x_{2}, \\qquad\n\\dot{x}_{2} = -\\beta\\, x_{2}\\,|x_{2}| + u,\n$$\nwhere $x_{1}$ is position, $x_{2}$ is velocity, $\\beta  0$ is a known constant representing quadratic drag, and $u$ is the actuator input constrained by a hardware uni-directionality requirement $u \\in [0, u_{\\max}]$ with $u_{\\max}  0$. The digital twin, however, uses the unconstrained linearization around the equilibrium $(x^{\\star},u^{\\star}) = (0,0)$ to assess controllability and design feedback.\n\nStarting only from the definitions of linearization via Jacobians and standard controllability concepts for linear systems, and without invoking any shortcut formulas, do the following:\n\n1. Identify the Jacobian matrices that define the linearization of the nonlinear plant around $(x^{\\star},u^{\\star}) = (0,0)$, obtaining a linear system $\\dot{\\delta x} = A\\,\\delta x + B\\,\\delta u$.\n\n2. For the $2 \\times 2$ pair $(A,B)$, form the controllability matrix with columns $B$ and $AB$, and compute its determinant. This determinant certifies whether the linearized pair is controllable by the usual rank test.\n\n3. Using first principles (variation of constants and sign arguments grounded in the given dynamics and constraints), explain why the nonlinear plant with the unilateral input constraint $u \\in [0,u_{\\max}]$ fails to be locally controllable at $(x^{\\star},u^{\\star}) = (0,0)$, even though the linearized pair $(A,B)$ is controllable in the unconstrained sense. In particular, show that for sufficiently small time horizons, the reachable set from $x^{\\star}$ cannot contain states with $x_{2}  0$.\n\nYour final reported quantity should be the determinant from Part 2. Express the final answer as an exact real number. No rounding is required and no units should be included in the final answer box.",
            "solution": "The problem asks for a three-part analysis of a nonlinear control system: linearization, a controllability test on the linearized system, and an explanation for why the nonlinear system is not locally controllable.\n\nLet the state vector be $x = \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix}$. The nonlinear dynamics are given by $\\dot{x} = f(x, u)$, where the function $f: \\mathbb{R}^2 \\times \\mathbb{R} \\to \\mathbb{R}^2$ is defined as:\n$$\nf(x, u) = \\begin{pmatrix} f_{1}(x, u) \\\\ f_{2}(x, u) \\end{pmatrix} = \\begin{pmatrix} x_{2} \\\\ -\\beta\\, x_{2}\\,|x_{2}| + u \\end{pmatrix}\n$$\nThe system is to be analyzed at the equilibrium point $(x^{\\star}, u^{\\star})$, where $x^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and $u^{\\star} = 0$.\n\n**Part 1: Linearization**\n\nThe linearization of the nonlinear system around the equilibrium point $(x^{\\star}, u^{\\star})$ results in a linear time-invariant system of the form $\\dot{\\delta x} = A\\,\\delta x + B\\,\\delta u$, where $\\delta x = x - x^{\\star}$ and $\\delta u = u - u^{\\star}$. The matrices $A$ and $B$ are the Jacobians of $f$ with respect to $x$ and $u$, evaluated at the equilibrium point.\n\nThe Jacobian matrix $A$ is given by:\n$$\nA = \\frac{\\partial f}{\\partial x}\\bigg|_{(x^{\\star}, u^{\\star})} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial x_{1}}  \\frac{\\partial f_{1}}{\\partial x_{2}} \\\\ \\frac{\\partial f_{2}}{\\partial x_{1}}  \\frac{\\partial f_{2}}{\\partial x_{2}} \\end{pmatrix}\\bigg|_{(x^{\\star}, u^{\\star})}\n$$\nWe compute the partial derivatives:\n$\\frac{\\partial f_{1}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(x_{2}) = 0$\n$\\frac{\\partial f_{1}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(x_{2}) = 1$\n$\\frac{\\partial f_{2}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(-\\beta\\, x_{2}\\,|x_{2}| + u) = 0$\n\nFor the derivative $\\frac{\\partial f_{2}}{\\partial x_{2}}$, we must differentiate the term $-\\beta\\, x_{2}\\,|x_{2}|$. The function $g(x_{2}) = x_{2}\\,|x_{2}|$ is $x_{2}^{2}$ for $x_{2} \\ge 0$ and $-x_{2}^{2}$ for $x_{2}  0$. Its derivative is $\\frac{dg}{dx_{2}} = 2x_{2}$ for $x_{2}  0$ and $\\frac{dg}{dx_{2}} = -2x_{2}$ for $x_{2}  0$. This can be written compactly as $\\frac{d}{dx_{2}}(x_{2}\\,|x_{2}|) = 2|x_{2}|$. At $x_{2}=0$, the derivative is $0$.\nTherefore, $\\frac{\\partial f_{2}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(-\\beta\\, x_{2}\\,|x_{2}| + u) = -2\\beta\\,|x_{2}|$.\n\nEvaluating the Jacobian matrix at the equilibrium state $x^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 0  -2\\beta\\,|x_{2}| \\end{pmatrix}\\bigg|_{x_{2}=0} = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\nThe Jacobian matrix $B$ is given by:\n$$\nB = \\frac{\\partial f}{\\partial u}\\bigg|_{(x^{\\star}, u^{\\star})} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial u} \\\\ \\frac{\\partial f_{2}}{\\partial u} \\end{pmatrix}\\bigg|_{(x^{\\star}, u^{\\star})}\n$$\nWe compute the partial derivatives:\n$\\frac{\\partial f_{1}}{\\partial u} = \\frac{\\partial}{\\partial u}(x_{2}) = 0$\n$\\frac{\\partial f_{2}}{\\partial u} = \\frac{\\partial}{\\partial u}(-\\beta\\, x_{2}\\,|x_{2}| + u) = 1$\nThe resulting matrix $B$ is constant:\n$$\nB = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe linearized system is $\\dot{\\delta x} = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\delta x + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\delta u$.\n\n**Part 2: Controllability of the Linearized System**\n\nThe controllability of the linear pair $(A, B)$ is determined by the rank of the controllability matrix $\\mathcal{C} = [B \\mid AB \\mid \\dots \\mid A^{n-1}B]$. For a $2$-dimensional system ($n=2$), the matrix is $\\mathcal{C} = [B \\mid AB]$.\n\nWe have $A = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$ and $B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nFirst, calculate the product $AB$:\n$$\nAB = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (0)(0) + (1)(1) \\\\ (0)(0) + (0)(1) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nNow, form the controllability matrix $\\mathcal{C}$:\n$$\n\\mathcal{C} = [B \\mid AB] = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}\n$$\nThe determinant of this matrix is:\n$$\n\\det(\\mathcal{C}) = (0)(0) - (1)(1) = -1\n$$\nSince $\\det(\\mathcal{C}) = -1 \\neq 0$, the rank of $\\mathcal{C}$ is $2$, which is equal to the dimension of the state space. Therefore, the linearized system $(A, B)$ is controllable.\n\n**Part 3: Local Uncontrollability of the Nonlinear System**\n\nDespite the controllability of its linearization, the original nonlinear system is not locally controllable at the origin due to the unilateral input constraint $u \\in [0, u_{\\max}]$. Local controllability at an equilibrium point $x^{\\star}$ requires that, for any neighborhood of $x^{\\star}$, the set of states reachable from $x^{\\star}$ in arbitrarily small time contains a neighborhood of $x^{\\star}$. We will show that from the origin $x(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, it is impossible to reach any state with a negative velocity, i.e., $x_{2}  0$.\n\nThe dynamics of the velocity state $x_{2}$ are governed by:\n$$\n\\dot{x}_{2} = -\\beta\\, x_{2}\\,|x_{2}| + u(t)\n$$\nWe start at $x(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, so $x_{2}(0) = 0$. The input is constrained such that $u(t) \\ge 0$ for all $t \\ge 0$.\n\nLet us assume, for the sake of contradiction, that there exists a control input $u(t)$ and a time $T  0$ such that the system reaches a state where $x_{2}(T)  0$. Since the state trajectory $x(t)$ is continuous and $x_{2}(0) = 0$, there must be a first time $t_{0} \\in [0, T)$ where the velocity either becomes negative or is about to. Let $t_{0} = \\inf\\{t  0 \\mid x_{2}(t)  0\\}$. By the continuity of $x_{2}(t)$, we must have $x_{2}(t_{0}) = 0$. For any small $\\epsilon  0$, there exists a time $t' \\in (t_{0}, t_{0}+\\epsilon)$ such that $x_{2}(t')  0$.\n\nNow, let us examine the dynamics for any time $t  t_{0}$ where $x_{2}(t)  0$. In this case, $|x_{2}(t)| = -x_{2}(t)$. The velocity dynamics become:\n$$\n\\dot{x}_{2}(t) = -\\beta\\, x_{2}(t) (-x_{2}(t)) + u(t) = \\beta\\,x_{2}(t)^{2} + u(t)\n$$\nSince $\\beta  0$, the term $\\beta\\,x_{2}(t)^{2}$ is always non-negative. The input constraint specifies that $u(t)$ is also non-negative. Therefore, for any time $t$ where $x_{2}(t)  0$, the time derivative of the velocity must be non-negative:\n$$\n\\dot{x}_{2}(t) \\ge 0\n$$\nThis implies that whenever the velocity $x_{2}$ is negative, it can only be non-decreasing.\n\nLet's return to the time $t_{0}$. We have $x_{2}(t_{0}) = 0$. For times $t$ in an interval $(t_{0}, t_{0}+\\delta)$ immediately following $t_{0}$, we have assumed $x_{2}(t)  0$. However, according to our analysis, $\\dot{x}_{2}(t) \\ge 0$ for all $t$ in this interval. This means that $x_{2}(t)$ is a non-decreasing function on $(t_{0}, t_{0}+\\delta)$. A non-decreasing function starting from $x_{2}(t_{0})=0$ cannot take on negative values for $tt_{0}$. That is, $x_{2}(t) \\ge x_{2}(t_{0}) = 0$ must hold. This creates a direct contradiction with our assumption that $x_{2}(t)  0$ for $t \\in (t_{0}, t_{0}+\\delta)$.\n\nThe assumption that a state with $x_{2}  0$ is reachable must be false. The reachable set from the origin is confined to the half-plane where $x_{2} \\ge 0$. Since any open neighborhood of the origin in $\\mathbb{R}^{2}$ contains points with $x_{2}  0$, the reachable set cannot contain any such neighborhood. Thus, the nonlinear system is not locally controllable at the origin.\n\nThe linearization is misleading because it represents the system's behavior for infinitesimal perturbations $\\delta u$ around $u^{\\star}=0$ that can be both positive and negative. A negative $\\delta u$ (i.e., a negative total input $u$) would be required to generate a negative acceleration $\\dot{x}_{2}$ starting from rest. The physical constraint $u \\ge 0$ prohibits this, a critical detail that the linearization process discards.",
            "answer": "$$\\boxed{-1}$$"
        },
        {
            "introduction": "While linearization provides a powerful simplification, its validity is always local. This practice  moves beyond qualitative warnings by introducing a rigorous method to quantify the \"trust zone\" of a linear approximation. By using bounds on the system's second-order dynamics (the Hessian), you will derive a confidence ellipsoid that guarantees the linearization error remains within a specified tolerance, a key technique for robust and safe system design.",
            "id": "4229982",
            "problem": "A supervisory controller in a Digital Twin (DT)-enabled Cyber-Physical System (CPS) uses a linearized surrogate of a scalar one-step performance map for real-time prediction. Let $h:\\mathbb{R}^{n} \\to \\mathbb{R}$ be twice continuously differentiable on a convex neighborhood $\\mathcal{N}$ of an operating point $z_{0} \\in \\mathcal{N}$. The DT returns, from its statistical estimation pipeline, a symmetric positive definite matrix $\\mathcal{B}_{\\alpha} \\in \\mathbb{R}^{n \\times n}$ such that, with confidence level at least $1-\\alpha$, the Hessian of $h$ satisfies the uniform operator bound\n$$\n-\\mathcal{B}_{\\alpha} \\preceq \\nabla^{2} h(\\zeta) \\preceq \\mathcal{B}_{\\alpha} \\quad \\text{for all } \\zeta \\in \\mathcal{N}.\n$$\nThe controller linearizes $h$ at $z_{0}$ and uses the affine predictor $h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta$ for $\\delta := z - z_{0}$, where $z \\in \\mathcal{N}$. Given a specified absolute error tolerance $\\epsilon  0$, define the “confidence region” in the perturbation space as the set of all $\\delta \\in \\mathbb{R}^{n}$ for which the linearization error satisfies $\\left|h(z_{0}+\\delta) - \\left(h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta\\right)\\right| \\le \\epsilon$ with probability at least $1-\\alpha$.\n\nStarting from the fundamental Taylor expansion with integral remainder and the given uniform bound on the Hessian, derive a closed-form expression, as an explicit ellipsoidal set in $\\mathbb{R}^{n}$ centered at the origin of the $\\delta$-space, for a confidence ellipsoid guaranteed to lie within the confidence region above. Your final expression must be written solely in terms of $\\epsilon$ and $\\mathcal{B}_{\\alpha}$. Provide the ellipsoid as a set in $\\mathbb{R}^{n}$. The final answer must be a single closed-form analytic expression. No numerical rounding is required.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in multivariable calculus and linear algebra, well-posed, objective, and contains sufficient information for a rigorous derivation. No flaws are identified.\n\nThe objective is to find a guaranteed confidence ellipsoid for the perturbation vector $\\delta$ such that the linearization error is bounded by a given tolerance $\\epsilon  0$. The linearization error is defined as the absolute difference between the true function value $h(z_0 + \\delta)$ and its affine approximation at $z_0$, which is $h(z_0) + \\nabla h(z_0)^{\\top} \\delta$.\n\nLet the linearization error be denoted by $E(\\delta)$:\n$$\nE(\\delta) = \\left|h(z_{0}+\\delta) - \\left(h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta\\right)\\right|\n$$\nThe term inside the absolute value is the remainder of the first-order Taylor expansion of $h$ around $z_0$ evaluated at $z_0 + \\delta$. Since $h$ is given to be twice continuously differentiable ($C^2$) on the convex neighborhood $\\mathcal{N}$, we can express this remainder term using Taylor's theorem with the integral form:\n$$\nh(z_{0}+\\delta) - h(z_{0}) - \\nabla h(z_{0})^{\\top} \\delta = \\int_{0}^{1} (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\, dt\n$$\nThe points $z_0+t\\delta$ for $t \\in [0, 1]$ form the line segment connecting $z_0$ and $z_0+\\delta = z$. Since $\\mathcal{N}$ is a convex set and $z_0, z \\in \\mathcal{N}$, this entire line segment lies within $\\mathcal{N}$. Therefore, the Hessian $\\nabla^{2} h(z_{0}+t\\delta)$ is well-defined and the given bound applies for all $t$ in the interval of integration.\n\nThe error is the absolute value of this integral:\n$$\nE(\\delta) = \\left| \\int_{0}^{1} (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\, dt \\right|\n$$\nBy applying the triangle inequality for integrals (or Jensen's inequality), we can move the absolute value inside the integral:\n$$\nE(\\delta) \\le \\int_{0}^{1} \\left| (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\right| \\, dt\n$$\nSince $t \\in [0, 1]$, the term $(1-t)$ is non-negative, so it can be moved outside the absolute value:\n$$\nE(\\delta) \\le \\int_{0}^{1} (1-t) \\left| \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\right| \\, dt\n$$\nThe problem states that the Hessian $\\nabla^{2} h(\\zeta)$ is bounded for all $\\zeta \\in \\mathcal{N}$ by the symmetric positive definite matrix $\\mathcal{B}_{\\alpha}$, with confidence level at least $1-\\alpha$. The bound is given in terms of the Loewner order as:\n$$\n-\\mathcal{B}_{\\alpha} \\preceq \\nabla^{2} h(\\zeta) \\preceq \\mathcal{B}_{\\alpha}\n$$\nFor any vector $\\delta \\in \\mathbb{R}^n$, this operator inequality implies the following inequality for the corresponding quadratic forms:\n$$\n\\delta^{\\top} (-\\mathcal{B}_{\\alpha}) \\delta \\le \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis is equivalent to:\n$$\n-\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis precisely means that the absolute value of the quadratic form involving the Hessian is bounded:\n$$\n\\left| \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\right| \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis bound holds for all $\\zeta \\in \\mathcal{N}$. Since $z_0+t\\delta \\in \\mathcal{N}$ for $t \\in [0,1]$, we can substitute this upper bound into our integral for the error $E(\\delta)$:\n$$\nE(\\delta) \\le \\int_{0}^{1} (1-t) (\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta) \\, dt\n$$\nThe term $\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta$ is a scalar that is constant with respect to the integration variable $t$, so it can be factored out of the integral:\n$$\nE(\\delta) \\le (\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta) \\int_{0}^{1} (1-t) \\, dt\n$$\nEvaluating the elementary integral:\n$$\n\\int_{0}^{1} (1-t) \\, dt = \\left[t - \\frac{t^2}{2}\\right]_{0}^{1} = \\left(1 - \\frac{1}{2}\\right) - (0) = \\frac{1}{2}\n$$\nSubstituting this result back gives a deterministic upper bound on the linearization error:\n$$\nE(\\delta) \\le \\frac{1}{2} \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThe derivation of this inequality is contingent on the Hessian bound, which holds with a confidence of at least $1-\\alpha$. Therefore, this error bound also holds with a confidence of at least $1-\\alpha$.\n\nWe are looking for a region of $\\delta$ where the linearization error is guaranteed to be no more than $\\epsilon$. That is, we require $E(\\delta) \\le \\epsilon$. A sufficient condition to ensure this is to require that our derived upper bound on the error be less than or equal to $\\epsilon$:\n$$\n\\frac{1}{2} \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le \\epsilon\n$$\nThis inequality defines a set of vectors $\\delta$ for which the error tolerance is guaranteed to be met (with the specified confidence). Rearranging the inequality, we get:\n$$\n\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon\n$$\nSince $\\mathcal{B}_{\\alpha}$ is a symmetric positive definite matrix and $2\\epsilon  0$, this inequality defines a closed, solid ellipsoid centered at the origin ($\\delta=0$) in the space $\\mathbb{R}^n$. Any $\\delta$ within this ellipsoid will satisfy the error tolerance condition.\n\nThe final expression for the confidence ellipsoid, as a set in $\\mathbb{R}^n$, is therefore:\n$$\n\\{ \\delta \\in \\mathbb{R}^{n} \\mid \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon \\}\n$$\nThis is the closed-form expression for a confidence ellipsoid guaranteed to lie within the specified confidence region.",
            "answer": "$$\\boxed{\\{ \\delta \\in \\mathbb{R}^{n} \\mid \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon \\}}$$"
        },
        {
            "introduction": "This final practice exercise  integrates the chapter's concepts into a comprehensive, practical application: designing a path-following controller for an autonomous vehicle. You will linearize the vehicle's kinematic model around a reference trajectory, design a discrete-time Linear Quadratic Regulator (LQR), and implement the solution in code, including handling physical actuator constraints. This capstone problem demonstrates the full workflow of model-based control design as it is used in modern cyber-physical systems and digital twins.",
            "id": "4230022",
            "problem": "You are given the continuous-time kinematic bicycle model for a road vehicle as a basis for a digital twin used in cyber-physical systems. The model is described by the fundamental definition of translational and rotational kinematics of a rigid body and assumes negligible tire slip angles for low to moderate speeds. The continuous-time dynamics in the global frame are:\n$$\n\\dot{x} = v \\cos(\\psi), \\quad \\dot{y} = v \\sin(\\psi), \\quad \\dot{\\psi} = \\frac{v}{L} \\tan(\\delta), \\quad \\dot{v} = a,\n$$\nwhere $x$ and $y$ are position in meters, $\\psi$ is the yaw angle in radians, $v$ is the speed in meters per second, $L$ is the wheelbase in meters, $\\delta$ is the front-wheel steering angle in radians, and $a$ is the longitudinal acceleration in meters per second squared. Consider path-following with respect to a nominal reference trajectory parameterized by arc-length with constant curvature $\\kappa$ in inverse meters and constant nominal speed $v_0$ in meters per second. Define the path-frame error state as\n$$\nx = \\begin{bmatrix} e_y \\\\ e_\\psi \\\\ e_v \\end{bmatrix},\n$$\nwhere $e_y$ is the lateral deviation in meters, $e_\\psi$ is the heading error in radians, and $e_v = v - v_0$ is the speed error in meters per second. The nominal steering angle $\\delta_0$ in radians required to follow the path curvature at nominal speed is given implicitly by matching nominal yaw-rate to path curvature, i.e., $\\tan(\\delta_0)/L = \\kappa$. Assume nominal acceleration $a_0 = 0$.\n\nStarting from the fundamental continuous-time model above and the Taylor expansion to first order, perform a local linearization of the error dynamics about the nominal trajectory $(e_y, e_\\psi, e_v) = (0, 0, 0)$ and inputs $(\\delta, a) = (\\delta_0, 0)$. Use the following path-frame approximations valid for small errors:\n$$\n\\dot{e}_y = v \\sin(e_\\psi), \\quad \\dot{e}_\\psi = \\frac{v}{L}\\tan(\\delta) - v \\kappa, \\quad \\dot{e}_v = a,\n$$\nand apply first-order Taylor linearization around the nominal point to obtain a continuous-time linear system of the form\n$$\n\\dot{x} = A x + B u,\n$$\nwhere $u = \\begin{bmatrix} \\delta - \\delta_0 \\\\ a - a_0 \\end{bmatrix} = \\begin{bmatrix} \\delta - \\delta_0 \\\\ a \\end{bmatrix}$. Discretize the linear system using forward Euler (Zero-Order Hold (ZOH) approximation) with sampling interval $\\Delta t$ seconds to obtain\n$$\nx_{k+1} = A_d x_k + B_d u_k.\n$$\nDesign a discrete-time Linear Quadratic Regulator (LQR) by computing the state-feedback gain matrix $K$ that minimizes the infinite-horizon quadratic cost\n$$\nJ = \\sum_{k=0}^{\\infty} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right),\n$$\nfor given positive semidefinite $Q$ and positive definite $R$. Enforce actuator limits by saturating the total physical inputs\n$$\n\\delta_{\\mathrm{phys}} = \\delta_0 + u_\\delta, \\quad a_{\\mathrm{phys}} = a_0 + u_a,\n$$\nsuch that $\\delta_{\\mathrm{phys}} \\in [-\\delta_{\\max}, \\delta_{\\max}]$ and $a_{\\mathrm{phys}} \\in [a_{\\min}, a_{\\max}]$, with angles in radians and accelerations in meters per second squared. The control law is $u = -K x$.\n\nYour task is to implement a program that, for each specified test case, performs the following computations:\n1. Compute the nominal steering angle $\\delta_0 = \\arctan(\\kappa L)$ in radians and test feasibility of the nominal trajectory under steering bounds by checking whether $|\\delta_0| \\le \\delta_{\\max}$; return the corresponding boolean.\n2. Compute the discrete-time linearization matrices $A_d$ and $B_d$ using the above modeling assumptions and $\\Delta t$.\n3. Compute the discrete-time LQR gain $K$ using the provided $Q$ and $R$.\n4. Compute the spectral radius $\\rho(A_d - B_d K)$ of the closed-loop matrix (dimensionless float).\n5. For the given initial error state $x(0)$, compute the unconstrained control $u = -K x(0)$, form the physical input $(\\delta_{\\mathrm{phys}}, a_{\\mathrm{phys}})$ by adding nominal inputs, and then apply saturation to the bounds to obtain the applied inputs. Return the saturated steering angle and acceleration as floats in radians and meters per second squared, respectively.\n\nUse the following test suite. All angles must be in radians, all lengths in meters, all speeds in meters per second, and all accelerations in meters per second squared.\n\nTest cases:\n- Case 1 (moderate curvature, nominal speed):\n  - $L = 2.8$, $v_0 = 15.0$, $\\kappa = 0.02$, $\\Delta t = 0.05$\n  - $\\delta_{\\max} = 0.5$, $a_{\\min} = -3.0$, $a_{\\max} = 3.0$\n  - $Q = \\mathrm{diag}(10.0, 5.0, 1.0)$, $R = \\mathrm{diag}(1.0, 0.5)$\n  - $x(0) = [0.5, 0.1, -1.0]$\n- Case 2 (straight road):\n  - $L = 2.8$, $v_0 = 20.0$, $\\kappa = 0.0$, $\\Delta t = 0.05$\n  - $\\delta_{\\max} = 0.6$, $a_{\\min} = -2.0$, $a_{\\max} = 2.0$\n  - $Q = \\mathrm{diag}(8.0, 4.0, 2.0)$, $R = \\mathrm{diag}(0.8, 0.3)$\n  - $x(0) = [-0.2, -0.05, 0.5]$\n- Case 3 (high curvature near steering limit):\n  - $L = 2.8$, $v_0 = 10.0$, $\\kappa = \\frac{\\tan(0.45)}{2.8}$, $\\Delta t = 0.1$\n  - $\\delta_{\\max} = 0.4$, $a_{\\min} = -1.5$, $a_{\\max} = 1.5$\n  - $Q = \\mathrm{diag}(12.0, 6.0, 1.0)$, $R = \\mathrm{diag}(0.9, 0.4)$\n  - $x(0) = [1.0, 0.2, -2.0]$\n- Case 4 (low-speed boundary):\n  - $L = 2.5$, $v_0 = 0.1$, $\\kappa = 0.05$, $\\Delta t = 0.05$\n  - $\\delta_{\\max} = 0.5$, $a_{\\min} = -1.0$, $a_{\\max} = 1.0$\n  - $Q = \\mathrm{diag}(15.0, 7.0, 1.0)$, $R = \\mathrm{diag}(1.2, 0.6)$\n  - $x(0) = [0.3, 0.15, -0.1]$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test-case result must be a list of the form\n$$\n[\\text{feasible\\_nominal}, \\ \\rho, \\ \\delta_{\\mathrm{applied}}, \\ a_{\\mathrm{applied}}],\n$$\nwhere $\\text{feasible\\_nominal}$ is a boolean, $\\rho$ is a float, $\\delta_{\\mathrm{applied}}$ is a float in radians, and $a_{\\mathrm{applied}}$ is a float in meters per second squared. The final output must be in the format\n$$\n[[\\text{case1\\_result}], [\\text{case2\\_result}], [\\text{case3\\_result}], [\\text{case4\\_result}]].\n$$",
            "solution": "The problem requires the design and analysis of a discrete-time Linear Quadratic Regulator (LQR) for the lateral and longitudinal control of a vehicle. The process involves several standard steps in control systems engineering: modeling, linearization, discretization, controller synthesis, and analysis.\n\n### 1. System Modeling and Linearization\n\nThe state of the system is defined by the error vector $x = [e_y, e_\\psi, e_v]^\\top$, where $e_y$ is the lateral error, $e_\\psi$ is the heading error, and $e_v$ is the velocity error relative to a nominal path. The control input vector is $u = [\\delta_{\\mathrm{dev}}, a_{\\mathrm{dev}}]^\\top$, representing perturbations from the nominal steering angle $\\delta_0$ and nominal acceleration $a_0$. The nominal acceleration is given as $a_0=0$. The nominal steering angle $\\delta_0$ is determined by the path curvature $\\kappa$, wheelbase $L$, and the condition that the vehicle's nominal yaw rate matches the path's curvature rate: $\\dot{\\psi}_0 = v_0 \\kappa$. From the vehicle kinematics, $\\dot{\\psi}_0 = \\frac{v_0}{L}\\tan(\\delta_0)$. Equating these under the assumption $v_0 \\neq 0$ gives $\\frac{\\tan(\\delta_0)}{L} = \\kappa$, which can be solved for the nominal steering angle: $\\delta_0 = \\arctan(\\kappa L)$.\n\nThe problem provides the approximated nonlinear error dynamics:\n$$\n\\begin{align*}\n\\dot{e}_y = (v_0 + e_v) \\sin(e_\\psi) \\\\\n\\dot{e}_\\psi = \\frac{v_0 + e_v}{L}\\tan(\\delta_0 + \\delta_{\\mathrm{dev}}) - (v_0 + e_v)\\kappa \\\\\n\\dot{e}_v = a_0 + a_{\\mathrm{dev}} = a_{\\mathrm{dev}}\n\\end{align*}\n$$\nTo obtain a continuous-time linear state-space model $\\dot{x} = Ax + Bu$, we compute the Jacobian matrices of the dynamics with respect to the state $x$ and input $u$, evaluated at the equilibrium point $(x, u) = (\\mathbf{0}, \\mathbf{0})$.\n\nThe state matrix $A$ is the Jacobian with respect to $x = [e_y, e_\\psi, e_v]^\\top$:\n$$\nA = \\frac{\\partial \\dot{x}}{\\partial x} \\bigg|_{x=\\mathbf{0}, u=\\mathbf{0}} =\n\\begin{bmatrix}\n\\frac{\\partial \\dot{e}_y}{\\partial e_y}  \\frac{\\partial \\dot{e}_y}{\\partial e_\\psi}  \\frac{\\partial \\dot{e}_y}{\\partial e_v} \\\\\n\\frac{\\partial \\dot{e}_\\psi}{\\partial e_y}  \\frac{\\partial \\dot{e}_\\psi}{\\partial e_\\psi}  \\frac{\\partial \\dot{e}_\\psi}{\\partial e_v} \\\\\n\\frac{\\partial \\dot{e}_v}{\\partial e_y}  \\frac{\\partial \\dot{e}_v}{\\partial e_\\psi}  \\frac{\\partial \\dot{e}_v}{\\partial e_v}\n\\end{bmatrix}\n\\bigg|_{x=\\mathbf{0}, u=\\mathbf{0}}\n$$\nThe individual partial derivatives are:\n- $\\frac{\\partial \\dot{e}_y}{\\partial e_y} = 0$\n- $\\frac{\\partial \\dot{e}_y}{\\partial e_\\psi} = (v_0+e_v)\\cos(e_\\psi) \\to v_0$\n- $\\frac{\\partial \\dot{e}_y}{\\partial e_v} = \\sin(e_\\psi) \\to 0$\n- $\\frac{\\partial \\dot{e}_\\psi}{\\partial e_y} = 0$\n- $\\frac{\\partial \\dot{e}_\\psi}{\\partial e_\\psi} = 0$\n- $\\frac{\\partial \\dot{e}_\\psi}{\\partial e_v} = \\frac{1}{L}\\tan(\\delta_0+\\delta_{\\mathrm{dev}}) - \\kappa \\to \\frac{\\tan(\\delta_0)}{L} - \\kappa = 0$\n- $\\frac{\\partial \\dot{e}_v}{\\partial e_y} = \\frac{\\partial \\dot{e}_v}{\\partial e_\\psi} = \\frac{\\partial \\dot{e}_v}{\\partial e_v} = 0$\n\nThis yields the continuous-time state matrix:\n$$\nA = \\begin{bmatrix}\n0  v_0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{bmatrix}\n$$\n\nThe input matrix $B$ is the Jacobian with respect to $u=[\\delta_{\\mathrm{dev}}, a_{\\mathrm{dev}}]^\\top$:\n$$\nB = \\frac{\\partial \\dot{x}}{\\partial u} \\bigg|_{x=\\mathbf{0}, u=\\mathbf{0}} =\n\\begin{bmatrix}\n\\frac{\\partial \\dot{e}_y}{\\partial \\delta_{\\mathrm{dev}}}  \\frac{\\partial \\dot{e}_y}{\\partial a_{\\mathrm{dev}}} \\\\\n\\frac{\\partial \\dot{e}_\\psi}{\\partial \\delta_{\\mathrm{dev}}}  \\frac{\\partial \\dot{e}_\\psi}{\\partial a_{\\mathrm{dev}}} \\\\\n\\frac{\\partial \\dot{e}_v}{\\partial \\delta_{\\mathrm{dev}}}  \\frac{\\partial \\dot{e}_v}{\\partial a_{\\mathrm{dev}}}\n\\end{bmatrix}\n\\bigg|_{x=\\mathbf{0}, u=\\mathbf{0}}\n$$\n- $\\frac{\\partial \\dot{e}_y}{\\partial \\delta_{\\mathrm{dev}}} = 0$ and $\\frac{\\partial \\dot{e}_y}{\\partial a_{\\mathrm{dev}}} = 0$\n- $\\frac{\\partial \\dot{e}_\\psi}{\\partial \\delta_{\\mathrm{dev}}} = \\frac{v_0+e_v}{L}\\sec^2(\\delta_0+\\delta_{\\mathrm{dev}}) \\to \\frac{v_0}{L}\\sec^2(\\delta_0) = \\frac{v_0}{L}(1 + \\tan^2(\\delta_0)) = \\frac{v_0}{L}(1+(\\kappa L)^2)$\n- $\\frac{\\partial \\dot{e}_\\psi}{\\partial a_{\\mathrm{dev}}} = 0$\n- $\\frac{\\partial \\dot{e}_v}{\\partial \\delta_{\\mathrm{dev}}} = 0$ and $\\frac{\\partial \\dot{e}_v}{\\partial a_{\\mathrm{dev}}} = 1$\n\nThis yields the continuous-time input matrix:\n$$\nB = \\begin{bmatrix}\n0  0 \\\\\n\\frac{v_0}{L}(1+(\\kappa L)^2)  0 \\\\\n0  1\n\\end{bmatrix}\n$$\n\n### 2. Discretization\n\nThe continuous-time system is discretized using the forward Euler method with a sampling time $\\Delta t$. This approximates the exact Zero-Order Hold (ZOH) discretization.\n$$\nx_{k+1} = x_k + \\Delta t \\dot{x}_k = (I + \\Delta t A) x_k + (\\Delta t B) u_k\n$$\nThus, the discrete-time matrices $A_d$ and $B_d$ are:\n$$\nA_d = I + \\Delta t A = \\begin{bmatrix} 1  \\Delta t v_0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix}\n$$\n$$\nB_d = \\Delta t B = \\begin{bmatrix}\n0  0 \\\\\n\\frac{\\Delta t v_0}{L}(1+(\\kappa L)^2)  0 \\\\\n0  \\Delta t\n\\end{bmatrix}\n$$\n\n### 3. Discrete-Time LQR Controller Design\n\nThe goal is to find a state-feedback control law $u_k = -K x_k$ that minimizes the infinite-horizon quadratic cost function $J = \\sum_{k=0}^{\\infty} (x_k^\\top Q x_k + u_k^\\top R u_k)$. The optimal gain matrix $K$ is found by first solving the Discrete-time Algebraic Riccati Equation (DARE) for the positive semidefinite matrix $P$:\n$$\nP = A_d^\\top P A_d - (A_d^\\top P B_d)(R + B_d^\\top P B_d)^{-1}(B_d^\\top P A_d) + Q\n$$\nOnce $P$ is found, the optimal gain is computed as:\n$$\nK = (R + B_d^\\top P B_d)^{-1}(B_d^\\top P A_d)\n$$\nThis computation is performed numerically. The closed-loop system dynamics are then $x_{k+1} = (A_d - B_d K) x_k$, and its stability is determined by the spectral radius $\\rho(A_d - B_d K)$, which must be less than $1$.\n\n### 4. Input Saturation\n\nThe calculated control input perturbation $u_k = -K x_k$ is added to the nominal inputs to get the total physical inputs. For the steering angle $\\delta$ and acceleration $a$, these are:\n$$\n\\delta_{\\mathrm{phys}} = \\delta_0 + u_\\delta\n$$\n$$\na_{\\mathrm{phys}} = a_0 + u_a = u_a\n$$\nThese physical inputs are then constrained to their actuator limits $[\\delta_{\\min}, \\delta_{\\max}]$ and $[a_{\\min}, a_{\\max}]$, where $\\delta_{\\min}=-\\delta_{\\max}$. This saturation, or clamping, is applied to the calculated inputs for a given initial state $x(0)$ to find the final applied inputs.\n\nThis complete procedure is implemented for each test case provided. First, the nominal trajectory is checked for feasibility against the steering angle limit. If $|\\delta_0|  \\delta_{\\max}$, the nominal path is not achievable. Then, the matrices and LQR gain are computed, followed by the stability analysis and a sample calculation of the saturated control action for the given initial state.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_discrete_are\n\ndef solve():\n    \"\"\"\n    Solves the vehicle control problem for a series of test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            # Case 1 (moderate curvature, nominal speed)\n            'L': 2.8, 'v0': 15.0, 'kappa': 0.02, 'dt': 0.05,\n            'delta_max': 0.5, 'a_min': -3.0, 'a_max': 3.0,\n            'Q': np.diag([10.0, 5.0, 1.0]), 'R': np.diag([1.0, 0.5]),\n            'x0': [0.5, 0.1, -1.0]\n        },\n        {\n            # Case 2 (straight road)\n            'L': 2.8, 'v0': 20.0, 'kappa': 0.0, 'dt': 0.05,\n            'delta_max': 0.6, 'a_min': -2.0, 'a_max': 2.0,\n            'Q': np.diag([8.0, 4.0, 2.0]), 'R': np.diag([0.8, 0.3]),\n            'x0': [-0.2, -0.05, 0.5]\n        },\n        {\n            # Case 3 (high curvature near steering limit)\n            'L': 2.8, 'v0': 10.0, 'kappa': np.tan(0.45) / 2.8, 'dt': 0.1,\n            'delta_max': 0.4, 'a_min': -1.5, 'a_max': 1.5,\n            'Q': np.diag([12.0, 6.0, 1.0]), 'R': np.diag([0.9, 0.4]),\n            'x0': [1.0, 0.2, -2.0]\n        },\n        {\n            # Case 4 (low-speed boundary)\n            'L': 2.5, 'v0': 0.1, 'kappa': 0.05, 'dt': 0.05,\n            'delta_max': 0.5, 'a_min': -1.0, 'a_max': 1.0,\n            'Q': np.diag([15.0, 7.0, 1.0]), 'R': np.diag([1.2, 0.6]),\n            'x0': [0.3, 0.15, -0.1]\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Extract parameters\n        L, v0, kappa, dt = case['L'], case['v0'], case['kappa'], case['dt']\n        delta_max, a_min, a_max = case['delta_max'], case['a_min'], case['a_max']\n        Q, R, x0 = case['Q'], case['R'], np.array(case['x0'])\n\n        # 1. Compute nominal steering angle and check feasibility\n        delta0 = np.arctan(kappa * L)\n        feasible_nominal = np.abs(delta0) = delta_max\n\n        # 2. Compute continuous and discrete-time linearization matrices\n        # Continuous-time state matrix A\n        A = np.array([\n            [0, v0, 0],\n            [0, 0, 0],\n            [0, 0, 0]\n        ])\n\n        # Continuous-time input matrix B\n        B_21 = (v0 / L) * (1 + (kappa * L)**2)\n        B = np.array([\n            [0, 0],\n            [B_21, 0],\n            [0, 1]\n        ])\n\n        # Discrete-time matrices using Forward Euler\n        Ad = np.eye(3) + dt * A\n        Bd = dt * B\n\n        # 3. Compute discrete-time LQR gain K\n        # Solve the Discrete Algebraic Riccati Equation (DARE) for P\n        P = solve_discrete_are(Ad, Bd, Q, R)\n        \n        # Compute LQR gain K\n        K = np.linalg.inv(R + Bd.T @ P @ Bd) @ (Bd.T @ P @ Ad)\n\n        # 4. Compute spectral radius of the closed-loop matrix\n        A_cl = Ad - Bd @ K\n        eigenvalues = np.linalg.eigvals(A_cl)\n        rho = np.max(np.abs(eigenvalues))\n\n        # 5. Compute saturated control inputs for the given initial state\n        u = -K @ x0  # Unconstrained control input [u_delta, u_a]\n\n        # Form physical inputs by adding nominal values (a0=0)\n        delta_phys = delta0 + u[0]\n        a_phys = u[1]\n\n        # Apply saturation\n        delta_applied = np.clip(delta_phys, -delta_max, delta_max)\n        a_applied = np.clip(a_phys, a_min, a_max)\n\n        # Store results for this case\n        case_result = [feasible_nominal, rho, delta_applied, a_applied]\n        results.append(case_result)\n\n    # Format the final output string\n    # e.g., [[True, 0.98..., 0.12..., -3.0], [True, ...], ...]\n    formatted_results = []\n    for res in results:\n        # Convert boolean to string \"True\"/\"False\" and floats to string\n        s = f\"[{res[0]}, {res[1]}, {res[2]}, {res[3]}]\"\n        formatted_results.append(s)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}