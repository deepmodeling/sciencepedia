{
    "hands_on_practices": [
        {
            "introduction": "Effective shared autonomy often relies on a predictive model of the human operator's behavior. By understanding how a person perceives errors and generates control actions, an autonomous system can provide more intuitive and helpful assistance. This practice guides you through the fundamental process of system identification for a human-in-the-loop system, where you will implement a calibration and validation pipeline to estimate the parameters of a common human control model from simulated data—a core skill for developing adaptive cyber-physical systems. ",
            "id": "4226720",
            "problem": "Consider a human-in-the-loop shared autonomy scenario within a digital twin of a single-degree-of-freedom tracking task. A human operator and an autonomous assistant jointly produce a control action to reduce a scalar tracking error signal. The digital twin provides a synchronized time series of the tracking error and the executed control action. The goal is to calibrate a parametric human control model from data and validate it on a held-out dataset, using only the foundational assumptions and definitions stated below.\n\nFoundational modeling assumptions:\n1) The human produces a control action modeled as a noisy linear feedback on a filtered internal percept of error. The continuous-time internal percept $s(t)$ satisfies the first-order linear differential equation $\\tau \\, \\frac{d s(t)}{d t} + s(t) = e(t)$, where $e(t)$ is the externally measurable tracking error and $\\tau > 0$ is the human time constant. The human control signal is $u_{\\mathrm{h}}(t) = K_{\\mathrm{h}} \\, s(t) + w(t)$, where $K_{\\mathrm{h}}$ is the human feedback gain and $w(t)$ is zero-mean Gaussian white noise with variance $\\sigma^2$.\n2) The autonomy applies a known linear feedback $u_{\\mathrm{a}}(t) = -K_{\\mathrm{a}} \\, e(t)$, where $K_{\\mathrm{a}}$ is known and positive. The executed control command is a convex blend $u(t) = \\alpha \\, u_{\\mathrm{h}}(t) + (1 - \\alpha) \\, u_{\\mathrm{a}}(t)$ with a known blending coefficient $\\alpha \\in (0,1]$.\n3) The digital twin provides discrete-time samples at a fixed sampling period $\\Delta t > 0$. The discrete approximation of the internal percept uses the forward Euler method applied to the continuous-time model, resulting in $s_{k+1} = s_k + \\frac{\\Delta t}{\\tau}\\,(e_k - s_k)$ for sample index $k \\in \\{0,1,\\dots\\}$, with initial condition $s_0 = 0$. All angles used inside trigonometric functions are in radians.\n\nCalibration objective:\nGiven $N$ pairs $(e_k, u_k)$ for $k = 0,1,\\dots,N-1$, along with known $\\Delta t$, $\\alpha$, and $K_{\\mathrm{a}}$, estimate the human parameters $\\tau$, $K_{\\mathrm{h}}$, and $\\sigma^2$ by maximizing the likelihood under a zero-mean independent Gaussian noise model on $u_{\\mathrm{h},k}$. You must treat $\\tau$ as a nonlinear parameter and $K_{\\mathrm{h}}$ as a linear parameter. Use a grid search over $\\tau$ constrained to $\\tau \\in [\\tau_{\\min}, \\tau_{\\max}]$ with a uniform grid, and for each $\\tau$ compute the closed-form least squares estimate of $K_{\\mathrm{h}}$, then compute the maximum likelihood estimate of $\\sigma^2$. Select the $\\tau$ that minimizes the negative log-likelihood.\n\nValidation objective:\nGiven a held-out dataset $(e^{\\mathrm{val}}_k, u^{\\mathrm{val}}_k)$ of length $N_{\\mathrm{val}}$, compute a one-step-ahead prediction $\\hat{u}^{\\mathrm{val}}_k$ by running the same forward Euler recursion with the calibrated $\\hat{\\tau}$ and using $\\hat{K}_{\\mathrm{h}}$ with no noise. Evaluate the normalized root mean square error defined as $\\mathrm{NRMSE} = \\sqrt{\\frac{1}{N_{\\mathrm{val}}} \\sum_{k=0}^{N_{\\mathrm{val}} - 1} \\left(u^{\\mathrm{val}}_k - \\hat{u}^{\\mathrm{val}}_k\\right)^2} \\Big/ \\sqrt{\\frac{1}{N_{\\mathrm{val}}} \\sum_{k=0}^{N_{\\mathrm{val}} - 1} \\left(u^{\\mathrm{val}}_k - \\bar{u}^{\\mathrm{val}}\\right)^2}$, where $\\bar{u}^{\\mathrm{val}}$ is the sample mean of $u^{\\mathrm{val}}_k$. The normalized root mean square error is dimensionless. All time constants must be expressed in seconds.\n\nData generation (to be implemented by your program exactly as specified):\n- For any given $\\Delta t$, $N$, and frequencies $f_1, f_2$ in Hertz, define $t_k = k \\, \\Delta t$ and the excitation error sequence $e_k = \\sin(2\\pi f_1 t_k) + 0.5 \\, \\sin(2\\pi f_2 t_k)$ for $k = 0,1,\\dots,N-1$. The validation error sequence uses the same formula with $f_1^{\\mathrm{val}}$ and $f_2^{\\mathrm{val}}$.\n- The executed command sequence is generated from the human-in-the-loop model: first, recursively compute $s_{k+1} = s_k + \\frac{\\Delta t}{\\tau}\\,(e_k - s_k)$ with $s_0 = 0$; then compute $u_{\\mathrm{h},k} = K_{\\mathrm{h}} \\, s_k + w_k$ with $w_k \\sim \\mathcal{N}(0,\\sigma^2)$; the autonomy command is $u_{\\mathrm{a},k} = -K_{\\mathrm{a}} \\, e_k$; the executed command is $u_k = \\alpha \\, u_{\\mathrm{h},k} + (1 - \\alpha)\\, u_{\\mathrm{a},k}$. The same recursion without noise is used for the validation prediction $\\hat{u}^{\\mathrm{val}}_k$; the measured validation command $u^{\\mathrm{val}}_k$ includes noise drawn as above.\n- Randomness must be reproducible. For each dataset, use an independent fixed seed for a pseudo-random number generator to draw $\\{w_k\\}$.\n\nEstimation method (to be implemented by your program exactly as specified):\n- For a candidate $\\tau$, form the deterministic regressor sequence by running $s_{k+1} = s_k + \\frac{\\Delta t}{\\tau}\\,(e_k - s_k)$ with $s_0 = 0$ and computing $u_{\\mathrm{a},k} = -K_{\\mathrm{a}} e_k$. Define the blended autonomy-compensated response $z_k = u_k - (1 - \\alpha)\\, u_{\\mathrm{a},k}$ and the regressor $\\phi_k = \\alpha \\, s_k$. The least squares estimate of $K_{\\mathrm{h}}$ is $\\hat{K}_{\\mathrm{h}}(\\tau) = \\frac{\\sum_{k=0}^{N-1} \\phi_k z_k}{\\sum_{k=0}^{N-1} \\phi_k^2}$. The residuals are $r_k(\\tau) = z_k - \\phi_k \\, \\hat{K}_{\\mathrm{h}}(\\tau)$, and the maximum likelihood estimate of the noise variance is $\\hat{\\sigma}^2(\\tau) = \\frac{1}{N} \\sum_{k=0}^{N-1} r_k(\\tau)^2$. The negative log-likelihood (up to an additive constant independent of parameters) is $J(\\tau) = \\frac{N}{2} \\log\\left(\\hat{\\sigma}^2(\\tau)\\right)$. Select $\\hat{\\tau}$ that minimizes $J(\\tau)$ over the grid, and set $\\hat{K}_{\\mathrm{h}} = \\hat{K}_{\\mathrm{h}}(\\hat{\\tau})$ and $\\hat{\\sigma}^2 = \\hat{\\sigma}^2(\\hat{\\tau})$.\n\nGrid specification:\n- For each test case, use a uniform grid of $M = 300$ points on $\\tau \\in [\\tau_{\\min}, \\tau_{\\max}]$ where $\\tau_{\\min} = \\max\\{0.55 \\, \\Delta t, 0.02\\}$ and $\\tau_{\\max} = 0.6$. This ensures the forward Euler recursion is stable since $0  \\frac{\\Delta t}{\\tau}  2$.\n\nTest suite:\nImplement three independent calibration-and-validation tasks using the following parameters. All time constants and sampling periods are in seconds; frequencies are in Hertz; gains are dimensionless; noise standard deviations are in the same units as control commands; angles inside trigonometric functions are in radians. For each case, generate both a training dataset and a validation dataset.\n\nCase A:\n- $\\Delta t = 0.02$, $\\alpha = 0.7$, $K_{\\mathrm{a}} = 0.9$, $K_{\\mathrm{h}} = 1.1$, $\\tau = 0.15$, $\\sigma = 0.05$,\n- $N = 1500$, $N_{\\mathrm{val}} = 800$,\n- $f_1 = 0.3$, $f_2 = 0.7$, $f_1^{\\mathrm{val}} = 0.45$, $f_2^{\\mathrm{val}} = 1.1$,\n- training seed $= 12345$, validation seed $= 54321$.\n\nCase B:\n- $\\Delta t = 0.05$, $\\alpha = 0.9$, $K_{\\mathrm{a}} = 1.0$, $K_{\\mathrm{h}} = 0.8$, $\\tau = 0.03$, $\\sigma = 0.02$,\n- $N = 1200$, $N_{\\mathrm{val}} = 600$,\n- $f_1 = 0.2$, $f_2 = 0.5$, $f_1^{\\mathrm{val}} = 0.35$, $f_2^{\\mathrm{val}} = 0.9$,\n- training seed $= 22222$, validation seed $= 33333$.\n\nCase C:\n- $\\Delta t = 0.01$, $\\alpha = 0.6$, $K_{\\mathrm{a}} = 1.2$, $K_{\\mathrm{h}} = 1.8$, $\\tau = 0.25$, $\\sigma = 0.08$,\n- $N = 2000$, $N_{\\mathrm{val}} = 1000$,\n- $f_1 = 0.4$, $f_2 = 0.95$, $f_1^{\\mathrm{val}} = 0.25$, $f_2^{\\mathrm{val}} = 0.6$,\n- training seed $= 44444$, validation seed $= 55555$.\n\nRequired outputs:\n- For each case, compute the calibrated tuple $(\\hat{\\tau}, \\hat{K}_{\\mathrm{h}}, \\hat{\\sigma}^2)$ using the procedure above, and compute the validation $\\mathrm{NRMSE}$ based on the held-out dataset. Report all four values as real numbers in this order.\n- Units: report $\\hat{\\tau}$ in seconds; the other quantities are unit-consistent with the model and dimensionless for $\\hat{K}_{\\mathrm{h}}$ and $\\mathrm{NRMSE}$, while $\\hat{\\sigma}^2$ has the same units squared as the control command.\n- Numerical formatting: round each reported number to six decimal places.\n\nFinal output format:\nYour program should produce a single line of output containing a list of three lists, one per case, where each inner list is $[\\hat{\\tau}, \\hat{K}_{\\mathrm{h}}, \\hat{\\sigma}^2, \\mathrm{NRMSE}]$ with each value rounded to six decimals, and no spaces anywhere in the line. For example: `[[0.123456,1.234567,0.012345,0.345678],[...],[...]]`. The program must not read any input and must not print anything else.",
            "solution": "The problem requires the calibration and validation of a parametric model for a human operator's control actions within a human-in-the-loop shared autonomy system. The task is to estimate the human's perceptual time constant $\\tau$, feedback gain $K_{\\mathrm{h}}$, and noise variance $\\sigma^2$ from a synthetically generated time series of tracking error and control actions, and then to validate the calibrated model on a separate dataset.\n\nThe solution proceeds in three main stages: (1) Data Generation, (2) Model Calibration, and (3) Model Validation.\n\n**1. Data Generation**\n\nThe problem specifies a precise procedure for generating the training and validation datasets.\n- The tracking error signal $e_k$ is a deterministic sum of two sinusoids: $e_k = \\sin(2\\pi f_1 t_k) + 0.5 \\sin(2\\pi f_2 t_k)$ where $t_k = k \\Delta t$.\n- The human operator's internal percept of the error, $s_k$, is modeled as a first-order low-pass filtered version of the error $e_k$. The discrete-time dynamics are given by a forward Euler approximation of the continuous-time model $\\tau \\dot{s} + s = e$:\n$$s_{k+1} = s_k + \\frac{\\Delta t}{\\tau}(e_k - s_k)$$\nwith the initial condition $s_0 = 0$.\n- The human's control action $u_{\\mathrm{h},k}$ is a noisy linear feedback on this internal state:\n$$u_{\\mathrm{h},k} = K_{\\mathrm{h}} s_k + w_k$$\nwhere $w_k$ are independent samples from a zero-mean Gaussian distribution with variance $\\sigma^2$, i.e., $w_k \\sim \\mathcal{N}(0, \\sigma^2)$.\n- The autonomous assistant provides a simple proportional control action $u_{\\mathrm{a},k} = -K_{\\mathrm{a}} e_k$.\n- The final executed control command $u_k$ is a convex combination of the human and autonomous actions, governed by a blending coefficient $\\alpha$:\n$$u_k = \\alpha u_{\\mathrm{h},k} + (1 - \\alpha) u_{\\mathrm{a},k}$$\nThis full generative model is implemented to produce the training pairs $(e_k, u_k)$ and validation pairs $(e^{\\mathrm{val}}_k, u^{\\mathrm{val}}_k)$, using separate pseudo-random number generator seeds for reproducibility.\n\n**2. Model Calibration**\n\nThe calibration objective is to estimate the parameters $(\\tau, K_{\\mathrm{h}}, \\sigma^2)$ from the training data $(e_k, u_k)$ and known system parameters $(\\Delta t, \\alpha, K_{\\mathrm{a}})$. The estimation strategy leverages the structure of the model, which is non-linear in $\\tau$ but linear in $K_{\\mathrm{h}}$. This is a separable non-linear least squares problem.\n\nFirst, we rearrange the shared control equation to isolate the human's contribution. Given $u_k$ and $e_k$, we can compute the autonomy's contribution $u_{\\mathrm{a},k} = -K_{\\mathrm{a}} e_k$. The human's contribution (scaled by $\\alpha$) is then:\n$$\\alpha u_{\\mathrm{h},k} = u_k - (1 - \\alpha) u_{\\mathrm{a},k}$$\nLet us define this observable quantity as $z_k \\equiv u_k - (1-\\alpha)u_{\\mathrm{a},k}$. Substituting the model for $u_{\\mathrm{h},k}$, we obtain the regression equation:\n$$z_k = \\alpha (K_{\\mathrm{h}} s_k + w_k) = K_{\\mathrm{h}} (\\alpha s_k) + \\alpha w_k$$\nThis equation is linear in the parameter $K_{\\mathrm{h}}$ but non-linear in $\\tau$ because $s_k$ is a function of $\\tau$.\n\nThe estimation proceeds with a grid search over the non-linear parameter $\\tau$. For each candidate value $\\tau_{\\mathrm{cand}}$ from a uniform grid on $[\\tau_{\\min}, \\tau_{\\max}]$, we perform the following steps:\n- **Generate the regressor:** The internal state sequence $s_k(\\tau_{\\mathrm{cand}})$ is computed using the forward Euler recursion with the known training error $e_k$ and the candidate value $\\tau_{\\mathrm{cand}}$. The regressor is then $\\phi_k(\\tau_{\\mathrm{cand}}) = \\alpha s_k(\\tau_{\\mathrm{cand}})$.\n- **Estimate $K_{\\mathrm{h}}$:** For a fixed $\\tau$, the model is $z_k = K_{\\mathrm{h}} \\phi_k + \\text{noise}$. The standard linear least-squares estimate for $K_{\\mathrm{h}}$ that minimizes the sum of squared errors is:\n$$\\hat{K}_{\\mathrm{h}}(\\tau_{\\mathrm{cand}}) = \\frac{\\sum_{k=0}^{N-1} \\phi_k z_k}{\\sum_{k=0}^{N-1} \\phi_k^2}$$\n- **Estimate noise variance:** The residuals of this regression are $r_k(\\tau_{\\mathrm{cand}}) = z_k - \\hat{K}_{\\mathrm{h}}(\\tau_{\\mathrm{cand}}) \\phi_k$. The problem defines the maximum likelihood estimate of the \"noise variance\" as the sample variance of these residuals:\n$$\\hat{\\sigma}^2(\\tau_{\\mathrm{cand}}) = \\frac{1}{N} \\sum_{k=0}^{N-1} r_k(\\tau_{\\mathrm{cand}})^2$$\nNote that these residuals $r_k$ are an estimate of the scaled observation noise $\\alpha w_k$, so $\\hat{\\sigma}^2$ as defined is an estimate of $\\alpha^2 \\sigma^2$. We follow this explicit problem definition.\n- **Evaluate cost function:** The optimal $\\tau$ is found by maximizing the profile log-likelihood, which is equivalent to minimizing the negative log-likelihood. Up to an additive constant, the negative log-likelihood is given by:\n$$J(\\tau_{\\mathrm{cand}}) = \\frac{N}{2} \\log\\left(\\hat{\\sigma}^2(\\tau_{\\mathrm{cand}})\\right)$$\nMinimizing $J(\\tau_{\\mathrm{cand}})$ is equivalent to minimizing the residual variance $\\hat{\\sigma}^2(\\tau_{\\mathrm{cand}})$.\n- **Select optimal parameters:** The grid search finds the value $\\hat{\\tau}$ that minimizes $J(\\tau)$. The final estimates are then $\\hat{\\tau}$, and the corresponding $\\hat{K}_{\\mathrm{h}} = \\hat{K}_{\\mathrm{h}}(\\hat{\\tau})$ and $\\hat{\\sigma}^2 = \\hat{\\sigma}^2(\\hat{\\tau})$.\n\n**3. Model Validation**\n\nThe performance of the calibrated model $(\\hat{\\tau}, \\hat{K}_{\\mathrm{h}})$ is assessed on a held-out validation dataset $(e^{\\mathrm{val}}_k, u^{\\mathrm{val}}_k)$. This involves generating one-step-ahead predictions of the control command and comparing them to the measured commands.\n\n- **Prediction:** The predicted control signal, $\\hat{u}^{\\mathrm{val}}_k$, is generated using the calibrated model parameters but without the noise term. For each step $k$:\n    1. The predicted internal state $\\hat{s}^{\\mathrm{val}}_k$ is updated using the validation error $e^{\\mathrm{val}}_k$ and the estimated time constant $\\hat{\\tau}$:\n       $$\\hat{s}^{\\mathrm{val}}_{k+1} = \\hat{s}^{\\mathrm{val}}_k + \\frac{\\Delta t}{\\hat{\\tau}}(e^{\\mathrm{val}}_k - \\hat{s}^{\\mathrm{val}}_k), \\quad \\hat{s}^{\\mathrm{val}}_0=0$$\n    2. The predicted noiseless human command is $\\hat{u}_{\\mathrm{h},k}^{\\mathrm{val}} = \\hat{K}_{\\mathrm{h}} \\hat{s}^{\\mathrm{val}}_k$.\n    3. The final predicted command is blended: $\\hat{u}^{\\mathrm{val}}_k = \\alpha \\hat{u}_{\\mathrm{h},k}^{\\mathrm{val}} + (1 - \\alpha) u_{\\mathrm{a},k}^{\\mathrm{val}}$, where $u_{\\mathrm{a},k}^{\\mathrm{val}} = -K_{\\mathrm{a}} e^{\\mathrm{val}}_k$.\n\n- **Evaluation Metric:** The predictive accuracy is quantified by the Normalized Root Mean Square Error (NRMSE), defined as the Root Mean Square (RMS) of the prediction errors normalized by the standard deviation of the measured validation signal:\n$$\\mathrm{NRMSE} = \\frac{\\sqrt{\\frac{1}{N_{\\mathrm{val}}} \\sum_{k=0}^{N_{\\mathrm{val}} - 1} \\left(u^{\\mathrm{val}}_k - \\hat{u}^{\\mathrm{val}}_k\\right)^2}}{\\sqrt{\\frac{1}{N_{\\mathrm{val}}} \\sum_{k=0}^{N_{\\mathrm{val}} - 1} \\left(u^{\\mathrm{val}}_k - \\bar{u}^{\\mathrm{val}}\\right)^2}}$$\nwhere $\\bar{u}^{\\mathrm{val}}$ is the sample mean of the measured validation signal $u^{\\mathrm{val}}_k$. This metric provides a scale-invariant measure of model fit.\n\nThis entire procedure is implemented for the three specified test cases, adhering strictly to the provided parameters, data generation process, estimation method, and grid specification.",
            "answer": "```python\nimport numpy as np\n\ndef generate_data(dt, alpha, Ka, Kh, tau_true, sigma, freqs, N, seed):\n    \"\"\"\n    Generates synthetic data for the human-in-the-loop tracking task.\n    \"\"\"\n    f1, f2 = freqs\n    rng = np.random.default_rng(seed)\n    \n    t = np.arange(N) * dt\n    e = np.sin(2 * np.pi * f1 * t) + 0.5 * np.sin(2 * np.pi * f2 * t)\n    \n    s = np.zeros(N)\n    u_h = np.zeros(N)\n    u_a = -Ka * e\n    u = np.zeros(N)\n    w = rng.normal(0, sigma, N)\n    \n    for k in range(N - 1):\n        # Calculate controls at step k based on state s[k]\n        u_h[k] = Kh * s[k] + w[k]\n        u[k] = alpha * u_h[k] + (1 - alpha) * u_a[k]\n        \n        # Update state for step k+1 based on error and state at k\n        s[k+1] = s[k] + (dt / tau_true) * (e[k] - s[k])\n        \n    # Final step calculation\n    k = N - 1\n    u_h[k] = Kh * s[k] + w[k]\n    u[k] = alpha * u_h[k] + (1 - alpha) * u_a[k]\n    \n    return e, u\n\ndef calibrate_model(e_train, u_train, dt, alpha, Ka, N, M_grid=300):\n    \"\"\"\n    Calibrates the human model parameters using grid search and least squares.\n    \"\"\"\n    tau_min = max(0.55 * dt, 0.02)\n    tau_max = 0.6\n    tau_grid = np.linspace(tau_min, tau_max, M_grid)\n    \n    best_J = np.inf\n    hat_tau, hat_Kh, hat_sigma_sq = 0.0, 0.0, 0.0\n    \n    u_a_train = -Ka * e_train\n    z_train = u_train - (1 - alpha) * u_a_train\n    \n    for tau_cand in tau_grid:\n        s_cand = np.zeros(N)\n        for k in range(N - 1):\n            s_cand[k+1] = s_cand[k] + (dt / tau_cand) * (e_train[k] - s_cand[k])\n            \n        phi = alpha * s_cand\n        \n        phi_sq_sum = np.dot(phi, phi)\n        if phi_sq_sum  1e-15:\n            continue\n\n        Kh_cand = np.dot(phi, z_train) / phi_sq_sum\n        \n        r = z_train - phi * Kh_cand\n        sigma_sq_cand = np.mean(r**2)\n        \n        if sigma_sq_cand = 1e-15:\n            continue\n            \n        J = N / 2.0 * np.log(sigma_sq_cand)\n        \n        if J  best_J:\n            best_J = J\n            hat_tau = tau_cand\n            hat_Kh = Kh_cand\n            hat_sigma_sq = sigma_sq_cand\n            \n    return hat_tau, hat_Kh, hat_sigma_sq\n\ndef validate_model(e_val, u_val, hat_tau, hat_Kh, dt, alpha, Ka, N_val):\n    \"\"\"\n    Validates the calibrated model and computes NRMSE.\n    \"\"\"\n    s_pred = np.zeros(N_val)\n    u_pred = np.zeros(N_val)\n    u_a_val = -Ka * e_val\n    \n    for k in range(N_val - 1):\n        u_h_pred_k = hat_Kh * s_pred[k]\n        u_pred[k] = alpha * u_h_pred_k + (1 - alpha) * u_a_val[k]\n        s_pred[k+1] = s_pred[k] + (dt / hat_tau) * (e_val[k] - s_pred[k])\n        \n    k = N_val - 1\n    u_h_pred_k = hat_Kh * s_pred[k]\n    u_pred[k] = alpha * u_h_pred_k + (1 - alpha) * u_a_val[k]\n    \n    rmse_num = np.sqrt(np.mean((u_val - u_pred)**2))\n    std_den = np.std(u_val)\n    \n    if std_den  1e-15:\n        return np.inf if rmse_num > 1e-15 else 0.0\n    \n    nrmse = rmse_num / std_den\n    return nrmse\n\ndef solve():\n    \"\"\"\n    Main function to run the calibration and validation for all test cases.\n    \"\"\"\n    # M_grid is the number of points in the tau grid search\n    M_grid = 300\n\n    test_cases = [\n        {\n            # Case A\n            'params': {'dt': 0.02, 'alpha': 0.7, 'Ka': 0.9, 'Kh': 1.1, 'tau': 0.15, 'sigma': 0.05},\n            'data': {'N': 1500, 'N_val': 800, 'f1': 0.3, 'f2': 0.7, 'f1_val': 0.45, 'f2_val': 1.1},\n            'seeds': {'train': 12345, 'val': 54321}\n        },\n        {\n            # Case B\n            'params': {'dt': 0.05, 'alpha': 0.9, 'Ka': 1.0, 'Kh': 0.8, 'tau': 0.03, 'sigma': 0.02},\n            'data': {'N': 1200, 'N_val': 600, 'f1': 0.2, 'f2': 0.5, 'f1_val': 0.35, 'f2_val': 0.9},\n            'seeds': {'train': 22222, 'val': 33333}\n        },\n        {\n            # Case C\n            'params': {'dt': 0.01, 'alpha': 0.6, 'Ka': 1.2, 'Kh': 1.8, 'tau': 0.25, 'sigma': 0.08},\n            'data': {'N': 2000, 'N_val': 1000, 'f1': 0.4, 'f2': 0.95, 'f1_val': 0.25, 'f2_val': 0.6},\n            'seeds': {'train': 44444, 'val': 55555}\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p = case['params']\n        d = case['data']\n        s = case['seeds']\n\n        # 1. Generate training and validation data\n        e_train, u_train = generate_data(p['dt'], p['alpha'], p['Ka'], p['Kh'], p['tau'], p['sigma'], \n                                         (d['f1'], d['f2']), d['N'], s['train'])\n        e_val, u_val = generate_data(p['dt'], p['alpha'], p['Ka'], p['Kh'], p['tau'], p['sigma'], \n                                     (d['f1_val'], d['f2_val']), d['N_val'], s['val'])\n\n        # 2. Calibrate model parameters\n        hat_tau, hat_Kh, hat_sigma_sq = calibrate_model(e_train, u_train, p['dt'], p['alpha'], p['Ka'], d['N'], M_grid)\n\n        # 3. Validate model and compute NRMSE\n        nrmse = validate_model(e_val, u_val, hat_tau, hat_Kh, p['dt'], p['alpha'], p['Ka'], d['N_val'])\n\n        all_results.append([hat_tau, hat_Kh, hat_sigma_sq, nrmse])\n\n    # Format the final output string\n    result_str = \",\".join([f\"[{','.join([f'{v:.6f}' for v in res])}]\" for res in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "At the heart of many shared autonomy systems lies an arbitrator that must intelligently blend inputs from the human and the autonomous controller. This process is not a simple weighted average but an optimization problem that seeks to balance multiple, often competing, objectives like task performance, safety, and agreement with the user's intent. This exercise will have you implement a solution to a constrained multi-objective optimization problem, providing a hands-on understanding of how to formally derive and compute an optimal shared control action. ",
            "id": "4226636",
            "problem": "Consider a shared autonomy controller for a cyber-physical system where a Digital Twin predicts a linearized mapping between a control input and a safety-relevant state. Let the control input be a vector $u \\in \\mathbb{R}^2$. The Digital Twin provides a linear mapping $S \\in \\mathbb{R}^{2 \\times 2}$ and a desired safety reference $s_{\\mathrm{ref}} \\in \\mathbb{R}^2$. The autonomy module proposes $u_{\\mathrm{auto}} \\in \\mathbb{R}^2$, while the human operator proposes $u_{\\mathrm{human}} \\in \\mathbb{R}^2$. A trust parameter $\\tau \\in [0,1]$ modulates the relative weights given to the autonomy module and the human operator. Define the weights $w_{\\mathrm{p}}(\\tau) = \\beta (1 - \\tau)$ and $w_{\\mathrm{h}}(\\tau) = \\beta \\tau$ with $\\beta  0$, and a fixed safety-performance weight $w_{\\mathrm{s}}  0$.\n\nThe multi-objective optimization problem is to find $u^\\star$ minimizing the following cost:\n$$\nJ(u; \\tau) = w_{\\mathrm{s}} \\lVert S u - s_{\\mathrm{ref}} \\rVert_2^2 + w_{\\mathrm{p}}(\\tau) \\lVert u - u_{\\mathrm{auto}} \\rVert_2^2 + w_{\\mathrm{h}}(\\tau) \\lVert u - u_{\\mathrm{human}} \\rVert_2^2\n$$\nsubject to the linear safety constraint\n$$\nc^\\top u \\le d,\n$$\nwhere $c \\in \\mathbb{R}^2$ and $d \\in \\mathbb{R}$.\n\nStarting only from fundamental definitions of convex optimization and the structure of quadratic forms, and without using any pre-derived shortcut formulas, derive the necessary optimality conditions for this problem and implement an algorithm that computes $u^\\star$ for a given parameter set. The derivation must be based on first principles: properties of positive definite quadratic forms, gradients, and the feasibility condition imposed by the linear inequality.\n\nYour program must compute $u^\\star$ for each test case specified below and produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of the output list must itself be a two-element list representing the optimal control $u^\\star$ for the corresponding test case, with each number rounded to six decimal places, for example, $[[u_{1,1},u_{1,2}],[u_{2,1},u_{2,2}],\\ldots]$. No additional text should be printed.\n\nNo physical units are involved; all quantities are dimensionless. Angles are not used. Percentages must not appear; any fractional quantities should be represented as decimals.\n\nTest Suite:\n- Case $1$ (general \"happy path\"): \n  - $S = \\begin{bmatrix} 1.0  0.2 \\\\ 0.1  1.5 \\end{bmatrix}$,\n  - $s_{\\mathrm{ref}} = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$,\n  - $u_{\\mathrm{auto}} = \\begin{bmatrix} 0.5 \\\\ -0.3 \\end{bmatrix}$,\n  - $u_{\\mathrm{human}} = \\begin{bmatrix} 0.0 \\\\ 0.8 \\end{bmatrix}$,\n  - $\\beta = 2.0$,\n  - $w_{\\mathrm{s}} = 1.0$,\n  - $c = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}$,\n  - $d = 1.0$,\n  - $\\tau = 0.5$.\n- Case $2$ (active safety constraint):\n  - Same $S$, $s_{\\mathrm{ref}}$, $u_{\\mathrm{auto}}$, $u_{\\mathrm{human}}$, $\\beta$, $w_{\\mathrm{s}}$, $c$ as in Case $1$,\n  - $d = 0.5$,\n  - $\\tau = 0.5$.\n- Case $3$ (trust boundary at $\\tau = 0$):\n  - Same $S$, $s_{\\mathrm{ref}}$, $u_{\\mathrm{auto}}$, $u_{\\mathrm{human}}$, $\\beta$, $w_{\\mathrm{s}}$, $c$ as in Case $1$,\n  - $d = 0.55$,\n  - $\\tau = 0.0$.\n- Case $4$ (trust boundary at $\\tau = 1$ with feasibility at the constraint boundary):\n  - Same $S$, $s_{\\mathrm{ref}}$, $u_{\\mathrm{auto}}$, $u_{\\mathrm{human}}$, $\\beta$, $w_{\\mathrm{s}}$, $c$ as in Case $1$,\n  - $\\tau = 1.0$,\n  - Set $d$ equal to $c^\\top u_{\\mathrm{uncon}}$, where $u_{\\mathrm{uncon}}$ is the unconstrained minimizer for the given parameters in Case $4$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each case’s $u^\\star$ listed in order of the cases $1$ through $4$, each as a two-element list rounded to six decimal places, for example: $[[x_{1,1},x_{1,2}],[x_{2,1},x_{2,2}],[x_{3,1},x_{3,2}],[x_{4,1},x_{4,2}]]$.",
            "solution": "The problem is to find the optimal control input $u^\\star \\in \\mathbb{R}^2$ that minimizes a quadratic cost function subject to a single linear inequality constraint. This is a classic Quadratic Programming (QP) problem. The solution can be derived from first principles using the Karush-Kuhn-Tucker (KKT) conditions for constrained optimization.\n\nThe optimization problem is stated as:\n$$\n\\min_{u \\in \\mathbb{R}^2} J(u; \\tau) = w_{\\mathrm{s}} \\lVert S u - s_{\\mathrm{ref}} \\rVert_2^2 + w_{\\mathrm{p}}(\\tau) \\lVert u - u_{\\mathrm{auto}} \\rVert_2^2 + w_{\\mathrm{h}}(\\tau) \\lVert u - u_{\\mathrm{human}} \\rVert_2^2\n$$\nsubject to the constraint:\n$$\nc^\\top u \\le d\n$$\n\nFor clarity, we will denote the weights as $w_s$, $w_p$, and $w_h$.\n\n**1. Expansion and Simplification of the Cost Function**\n\nThe cost function $J(u)$ is a sum of squared Euclidean norms. We expand each term to express $J(u)$ in a standard quadratic form. Using the identity $\\lVert x \\rVert_2^2 = x^\\top x$, we have:\n- $w_s \\lVert S u - s_{\\mathrm{ref}} \\rVert_2^2 = w_s (u^\\top S^\\top S u - 2 s_{\\mathrm{ref}}^\\top S u + s_{\\mathrm{ref}}^\\top s_{\\mathrm{ref}})$\n- $w_p \\lVert u - u_{\\mathrm{auto}} \\rVert_2^2 = w_p (u^\\top u - 2 u_{\\mathrm{auto}}^\\top u + u_{\\mathrm{auto}}^\\top u_{\\mathrm{auto}})$\n- $w_h \\lVert u - u_{\\mathrm{human}} \\rVert_2^2 = w_h (u^\\top u - 2 u_{\\mathrm{human}}^\\top u + u_{\\mathrm{human}}^\\top u_{\\mathrm{human}})$\n\nSumming these terms and grouping by powers of $u$, we can write $J(u)$ in the form $J(u) = u^\\top A u - 2 b^\\top u + \\gamma$, where terms not dependent on $u$ are collected in $\\gamma$.\n\nThe quadratic term is $u^\\top (w_s S^\\top S + w_p I + w_h I) u$. The linear term is $-2 (w_s s_{\\mathrm{ref}}^\\top S + w_p u_{\\mathrm{auto}}^\\top + w_h u_{\\mathrm{human}}^\\top) u$.\n\nLet's define the matrix $A \\in \\mathbb{R}^{2 \\times 2}$ and vector $b \\in \\mathbb{R}^2$ as follows:\n$A = w_s S^\\top S + (w_p + w_h)I$\n$b = w_s S^\\top s_{\\mathrm{ref}} + w_p u_{\\mathrm{auto}} + w_h u_{\\mathrm{human}}$\n\nUsing the definitions $w_p(\\tau) = \\beta (1 - \\tau)$ and $w_h(\\tau) = \\beta \\tau$, their sum is $w_p + w_h = \\beta$.\nSo, the expressions become:\n$$\nA = w_s S^\\top S + \\beta I\n$$\n$$\nb = w_s S^\\top s_{\\mathrm{ref}} + \\beta(1-\\tau) u_{\\mathrm{auto}} + \\beta\\tau u_{\\mathrm{human}}\n$$\nThe cost function is now $J(u) = u^\\top A u - 2 b^\\top u + \\text{constant}$.\n\n**2. Convexity and Unconstrained Solution**\n\nTo find the minimum of $J(u)$, we first compute its gradient with respect to $u$:\n$$\n\\nabla_u J(u) = 2 A u - 2 b\n$$\nThe Hessian of the cost function is $\\nabla_u^2 J(u) = 2A = 2(w_s S^\\top S + \\beta I)$. Since $w_s  0$ and $\\beta  0$, and $S^\\top S$ is a positive semi-definite matrix, the Hessian is the sum of a positive semi-definite matrix ($2w_s S^\\top S$) and a positive definite matrix ($2\\beta I$). Therefore, the Hessian is positive definite. This proves that $J(u)$ is a strictly convex function, which guarantees that a unique global minimum exists.\n\nFor the unconstrained problem, the minimum $u_{\\mathrm{uncon}}$ is found by setting the gradient to zero:\n$$\n\\nabla_u J(u_{\\mathrm{uncon}}) = 2 A u_{\\mathrm{uncon}} - 2 b = 0\n$$\n$$\nA u_{\\mathrm{uncon}} = b\n$$\nSince $A$ is positive definite, it is invertible. The unique unconstrained minimizer is:\n$$\nu_{\\mathrm{uncon}} = A^{-1} b\n$$\n\n**3. Karush-Kuhn-Tucker (KKT) Conditions for the Constrained Problem**\n\nFor the constrained problem, we use the KKT conditions. The Lagrangian is:\n$\\mathcal{L}(u, \\lambda) = J(u) + \\lambda(c^\\top u - d)$, where $\\lambda$ is the Lagrange multiplier.\n\nThe KKT conditions for an optimal solution $u^\\star$ and multiplier $\\lambda^\\star$ are:\n1.  **Stationarity:** $\\nabla_u \\mathcal{L}(u^\\star, \\lambda^\\star) = \\nabla_u J(u^\\star) + \\lambda^\\star c = 0$\n2.  **Primal Feasibility:** $c^\\top u^\\star - d \\le 0$\n3.  **Dual Feasibility:** $\\lambda^\\star \\ge 0$\n4.  **Complementary Slackness:** $\\lambda^\\star (c^\\top u^\\star - d) = 0$\n\nFrom the Complementary Slackness condition, we analyze two distinct cases.\n\n**Case I: The constraint is inactive ($c^\\top u^\\star - d  0$).**\nBy complementary slackness, if $c^\\top u^\\star - d  0$, then $\\lambda^\\star$ must be $0$.\nSubstituting $\\lambda^\\star = 0$ into the stationarity condition gives:\n$$\n\\nabla_u J(u^\\star) = 0\n$$\nThis is the same condition as for the unconstrained minimum. Therefore, if the unconstrained solution $u_{\\mathrm{uncon}}$ satisfies the primal feasibility condition, i.e., $c^\\top u_{\\mathrm{uncon}} \\le d$, then it is the optimal solution for the constrained problem:\n$$\nu^\\star = u_{\\mathrm{uncon}} \\quad \\text{if } c^\\top u_{\\mathrm{uncon}} \\le d\n$$\nThis solution fulfills all KKT conditions with $\\lambda^\\star=0$.\n\n**Case II: The constraint is active ($c^\\top u^\\star - d = 0$).**\nThis case occurs when the unconstrained solution is not feasible, i.e., $c^\\top u_{\\mathrm{uncon}}  d$. The optimal solution must therefore lie on the boundary of the feasible region, $c^\\top u^\\star = d$. In this case, the multiplier $\\lambda^\\star$ can be positive.\n\nWe use the stationarity condition to express $u^\\star$ in terms of $\\lambda^\\star$:\n$$\n\\nabla_u J(u^\\star) + \\lambda^\\star c = 0 \\implies 2 A u^\\star - 2 b + \\lambda^\\star c = 0\n$$\n$$\nA u^\\star = b - \\frac{\\lambda^\\star}{2} c \\implies u^\\star = A^{-1}b - \\frac{\\lambda^\\star}{2} A^{-1}c\n$$\nRecognizing $u_{\\mathrm{uncon}} = A^{-1}b$, we have:\n$$\nu^\\star = u_{\\mathrm{uncon}} - \\frac{\\lambda^\\star}{2} A^{-1}c\n$$\nLet's define a new multiplier $\\mu = \\lambda^\\star / 2 \\ge 0$. So, $u^\\star = u_{\\mathrm{uncon}} - \\mu A^{-1}c$.\nTo find $\\mu$, we substitute this expression for $u^\\star$ into the active constraint equation $c^\\top u^\\star = d$:\n$$\nc^\\top (u_{\\mathrm{uncon}} - \\mu A^{-1}c) = d\n$$\n$$\nc^\\top u_{\\mathrm{uncon}} - \\mu (c^\\top A^{-1} c) = d\n$$\nSolving for $\\mu$:\n$$\n\\mu = \\frac{c^\\top u_{\\mathrm{uncon}} - d}{c^\\top A^{-1} c}\n$$\nSince we are in the case where $c^\\top u_{\\mathrm{uncon}}  d$, the numerator is positive. Since $A$ is positive definite, $A^{-1}$ is also positive definite, and thus the denominator $c^\\top A^{-1} c$ is also positive (for $c \\neq 0$). This ensures that $\\mu  0$ (and $\\lambda^\\star0$), satisfying the dual feasibility condition.\n\nThe optimal solution is then found by substituting this $\\mu$ back into the expression for $u^\\star$:\n$$\nu^\\star = u_{\\mathrm{uncon}} - \\left( \\frac{c^\\top u_{\\mathrm{uncon}} - d}{c^\\top A^{-1} c} \\right) A^{-1}c \\quad \\text{if } c^\\top u_{\\mathrm{uncon}}  d\n$$\n\n**Summary of the Algorithm**\nThe computational procedure is as follows:\n1.  Given the problem parameters, assemble the matrix $A = w_s S^\\top S + \\beta I$ and the vector $b = w_s S^\\top s_{\\mathrm{ref}} + \\beta(1-\\tau) u_{\\mathrm{auto}} + \\beta\\tau u_{\\mathrm{human}}$.\n2.  Compute the unconstrained solution $u_{\\mathrm{uncon}} = A^{-1}b$.\n3.  Check if $u_{\\mathrm{uncon}}$ is feasible by evaluating $c^\\top u_{\\mathrm{uncon}}$.\n4.  If $c^\\top u_{\\mathrm{uncon}} \\le d$, the solution is $u^\\star = u_{\\mathrm{uncon}}$.\n5.  If $c^\\top u_{\\mathrm{uncon}}  d$, the solution is found by projecting $u_{\\mathrm{uncon}}$ onto the constraint hyperplane:\n    $u^\\star = u_{\\mathrm{uncon}} - \\mu (A^{-1}c)$, with $\\mu = \\frac{c^\\top u_{\\mathrm{uncon}} - d}{c^\\top A^{-1} c}$.\n\nThis procedure provides the unique, optimal control input $u^\\star$ for all specified cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(S, s_ref, u_auto, u_human, beta, w_s, c, d, tau):\n    \"\"\"\n    Solves the constrained quadratic optimization problem for a single test case\n    based on the KKT-derived algorithm.\n    \"\"\"\n    # 1. Assemble matrices A and b based on the problem derivation.\n    # Note: w_p + w_h = beta.\n    A = w_s * (S.T @ S) + beta * np.identity(2)\n    b = w_s * (S.T @ s_ref) + beta * (1 - tau) * u_auto + beta * tau * u_human\n\n    # 2. Compute the unconstrained minimizer u_uncon = A^-1 * b.\n    try:\n        A_inv = np.linalg.inv(A)\n    except np.linalg.LinAlgError:\n        # A should always be invertible as it is positive definite.\n        # This is a fallback, not expected to be triggered.\n        raise ValueError(\"Matrix A is singular.\")\n        \n    u_uncon = A_inv @ b\n\n    # Special handling for Case 4: d is defined based on the unconstrained solution.\n    if d is None:\n        d = c.T @ u_uncon\n\n    # 3. Check if the unconstrained solution is feasible.\n    if c.T @ u_uncon = d:\n        # Case I: Constraint is inactive or active with lambda=0.\n        # The unconstrained solution is the optimal solution.\n        u_star = u_uncon\n    else:\n        # Case II: Constraint is violated by the unconstrained solution.\n        # The optimal solution lies on the constraint boundary.\n        # We project u_uncon onto the hyperplane c^T u = d in the A-metric.\n        \n        # Calculate the multiplier mu = (c^T u_uncon - d) / (c^T A^-1 c)\n        cT_A_inv_c = c.T @ A_inv @ c\n        mu = (c.T @ u_uncon - d) / cT_A_inv_c\n        \n        # Calculate the constrained solution u* = u_uncon - mu * (A^-1 c)\n        u_star = u_uncon - mu * (A_inv @ c)\n\n    return u_star\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the solver for each,\n    and print the results in the specified format.\n    \"\"\"\n    # Common parameters for all test cases\n    S = np.array([[1.0, 0.2], [0.1, 1.5]])\n    s_ref = np.array([0.0, 1.0])\n    u_auto = np.array([0.5, -0.3])\n    u_human = np.array([0.0, 0.8])\n    beta = 2.0\n    w_s = 1.0\n    c = np.array([1.0, 1.0])\n\n    # Test cases defined by (d, tau)\n    test_cases = [\n        # Case 1: General \"happy path\"\n        {'d': 1.0,  'tau': 0.5},\n        # Case 2: Active safety constraint\n        {'d': 0.5,  'tau': 0.5},\n        # Case 3: Trust boundary at tau = 0\n        {'d': 0.55, 'tau': 0.0},\n        # Case 4: Trust boundary at tau = 1, with d determined by u_uncon\n        {'d': None, 'tau': 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        u_star = solve_case(\n            S, s_ref, u_auto, u_human, beta, w_s, c, case['d'], case['tau']\n        )\n        results.append(u_star)\n\n    # Format the output string as per requirements:\n    # [[u1_1,u1_2],[u2_1,u2_2],...] with 6 decimal places and no spaces.\n    formatted_results = [f\"[{r[0]:.6f},{r[1]:.6f}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A critical challenge in real-world human-in-the-loop systems is that our models of human behavior are inherently uncertain and can be misspecified. To ensure safety, a shared autonomy system must be robust to these imperfections, providing safeguards that prevent catastrophic failures even under worst-case human actions. In this practice, you will design and implement an adaptive safety safeguard that accounts for bounded uncertainty in the human model, using principles of robust control to enforce a probabilistic safety guarantee. ",
            "id": "4226706",
            "problem": "A shared-autonomy controller for a Digital Twin (DT) of a Cyber-Physical System (CPS) must accommodate a human operator whose action model is misspecified. Consider a one-step safety safeguard that blends human intent and robotic override for a discrete-time linear-Gaussian plant. The plant evolves according to the fundamental discrete-time linear dynamics\n$$\nx_{t+1} = a\\,x_t + b\\,u_t + w_t,\n$$\nwhere $x_t$ is the state in meters, $u_t$ is the control input in meters, $a$ and $b$ are known scalars, and $w_t$ is a zero-mean disturbance with variance $\\sigma_w^2$ in square meters. The shared-autonomy blending is\n$$\nu_t = \\alpha\\,h_t + (1-\\alpha)\\,r_t,\n$$\nwhere $h_t$ is the human input and $r_t$ is the robotic override chosen by the safeguard. The blending parameter $\\alpha \\in [0,1]$ is known. The human model is misspecified: a nominal estimate treats $h_t$ as Gaussian with mean $\\mu_h$ and variance $\\sigma_h^2$, but the true mean deviates by an unknown shift $\\delta$ satisfying $|\\delta| \\le \\Delta$. Thus, the human input $h_t$ is modeled as\n$$\nh_t \\sim \\mathcal{N}(\\mu_h + \\delta,\\ \\sigma_h^2),\\quad |\\delta| \\le \\Delta.\n$$\nThe safety requirement is that the next state remains within the symmetric safe set\n$$\n|x_{t+1}| \\le X_{\\max},\n$$\nwith high probability under the worst-case misspecification. Your safeguard must choose a robotic override $r_t$ subject to a saturation constraint\n$$\n|r_t| \\le U_{\\max},\n$$\nto minimize worst-case risk while maintaining the safety chance constraint. For scientific realism, use the following principles as the base: the linearity of the plant and blending, independence and additivity of variances for the sum of independent Gaussian variables, the union bound for two-tail events, and the properties of the Gaussian cumulative distribution function. Do not assume any shortcut formulas beyond these principles.\n\nTasks:\n1. Starting from the given dynamics and blending, and treating $r_t$ as deterministic, derive the distribution of $x_{t+1}$ in terms of $a$, $b$, $\\alpha$, $x_t$, $r_t$, $\\mu_h$, $\\Delta$, $\\sigma_h^2$, and $\\sigma_w^2$. Carefully account for the unknown mean offset $\\delta$ by constructing a worst-case bound over $|\\delta| \\le \\Delta$.\n2. Using only the union bound and properties of the Gaussian distribution, derive a sufficient one-step chance constraint of the form $P(|x_{t+1}| \\le X_{\\max}) \\ge 1 - \\varepsilon$ that can be checked for a given $r_t$. The constraint must be robust to all $|\\delta| \\le \\Delta$ and must not rely on any shortcut formulas beyond the stated principles.\n3. Derive the choice of $r_t$ that minimizes the worst-case absolute mean of $x_{t+1}$ under $|\\delta| \\le \\Delta$, subject to the saturation constraint $|r_t| \\le U_{\\max}$. Explain how your derivation follows from first principles of interval centering and linearity.\n4. Define the minimal achievable upper bound on the violation probability $\\varepsilon_{\\text{bound}}$ for the chosen $r_t$ using the derived sufficient condition, robust to $|\\delta| \\le \\Delta$. If the total variance is zero, define the limit of $\\varepsilon_{\\text{bound}}$ in that degenerate deterministic case.\n\nNumerical units and outputs:\n- State $x_t$ is in meters, control $u_t$ and override $r_t$ are in meters, variances are in square meters, and $X_{\\max}$ is in meters.\n- Angles are not used.\n- Express the final override $r_t$ in meters, and express $\\varepsilon_{\\text{bound}}$ as a decimal fraction.\n\nTest suite:\nImplement a program that, for each of the following test cases, computes the saturated $r_t$ that minimizes the worst-case absolute mean, then computes the robust sufficient upper bound $\\varepsilon_{\\text{bound}}$ on the violation probability, and evaluates the boolean feasibility of the target chance constraint $P(|x_{t+1}| \\le X_{\\max}) \\ge 1 - \\varepsilon_{\\text{target}}$:\n- Case 1 (happy path): $(a,b,\\alpha,x_t,\\mu_h,\\Delta,\\sigma_h,\\sigma_w,X_{\\max},U_{\\max},\\varepsilon_{\\text{target}}) = (0.9, 1.0, 0.7, 2.0, 1.0, 0.3, 0.5, 0.1, 3.0, 2.0, 0.05)$.\n- Case 2 (boundary stress): $(a,b,\\alpha,x_t,\\mu_h,\\Delta,\\sigma_h,\\sigma_w,X_{\\max},U_{\\max},\\varepsilon_{\\text{target}}) = (1.2, 1.0, 0.9, 2.5, 1.5, 0.8, 0.7, 0.2, 3.0, 0.5, 0.02)$.\n- Case 3 (no override possible): $(a,b,\\alpha,x_t,\\mu_h,\\Delta,\\sigma_h,\\sigma_w,X_{\\max},U_{\\max},\\varepsilon_{\\text{target}}) = (0.95, 1.0, 1.0, 0.0, 0.0, 0.5, 0.3, 0.1, 0.4, 1.0, 0.1)$.\n- Case 4 (large actuation room, stable centering): $(a,b,\\alpha,x_t,\\mu_h,\\Delta,\\sigma_h,\\sigma_w,X_{\\max},U_{\\max},\\varepsilon_{\\text{target}}) = (0.5, 2.0, 0.6, -1.0, -0.5, 0.1, 0.2, 0.05, 1.0, 10.0, 0.01)$.\n- Case 5 (deterministic edge): $(a,b,\\alpha,x_t,\\mu_h,\\Delta,\\sigma_h,\\sigma_w,X_{\\max},U_{\\max},\\varepsilon_{\\text{target}}) = (1.0, 1.0, 0.5, 1.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.001)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element must be a list of the form $[r_t,\\ \\text{feasible},\\ \\varepsilon_{\\text{bound}}]$, where $r_t$ is in meters, `feasible` is a boolean, and `eps_bound` is a decimal fraction rounded to six decimal places. For example: `[[2.0, True, 0.014481], [0.5, False, 0.021189], ...]`\non a single line.",
            "solution": "### Principle-Based Derivation\n\n#### Task 1: Distribution of the Next State $x_{t+1}$\n\nThe evolution of the state $x_{t+1}$ is determined by substituting the shared-autonomy control law into the plant dynamics:\n$$\nx_{t+1} = a\\,x_t + b \\left( \\alpha\\,h_t + (1-\\alpha)\\,r_t \\right) + w_t\n$$\nWe can rearrange this expression by grouping deterministic and random terms. At time $t$, the state $x_t$ and the chosen override $r_t$ are known (deterministic). The human input $h_t$ and the process noise $w_t$ are independent random variables.\n$$\nx_{t+1} = \\underbrace{(a\\,x_t + b(1-\\alpha)r_t)}_{\\text{deterministic part}} + \\underbrace{b\\alpha\\,h_t + w_t}_{\\text{random part}}\n$$\nSince $x_{t+1}$ is a linear combination of independent Gaussian random variables ($h_t$ and $w_t$) and deterministic terms, $x_{t+1}$ itself follows a Gaussian distribution, $x_{t+1} \\sim \\mathcal{N}(\\mu_{x_{t+1}}, \\sigma_{x_{t+1}}^2)$.\n\nThe mean of $x_{t+1}$, denoted $\\mu_{x_{t+1}}(\\delta)$, depends on the unknown shift $\\delta$:\n$$\n\\mu_{x_{t+1}}(\\delta) = E[a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\,h_t + w_t]\n$$\nUsing the linearity of expectation and the given means $E[h_t] = \\mu_h + \\delta$ and $E[w_t] = 0$:\n$$\n\\mu_{x_{t+1}}(\\delta) = a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\,E[h_t] + E[w_t] = a\\,x_t + b(1-\\alpha)r_t + b\\alpha(\\mu_h + \\delta)\n$$\nWe define the nominal mean $\\mu_{\\text{nom}}$ as the part of the mean independent of the uncertainty $\\delta$:\n$$\n\\mu_{\\text{nom}}(r_t) = a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\mu_h\n$$\nThus, the mean is $\\mu_{x_{t+1}}(\\delta) = \\mu_{\\text{nom}}(r_t) + b\\alpha\\delta$. Since $|\\delta| \\le \\Delta$, the mean lies within the interval $[\\mu_{\\text{nom}}(r_t) - |b\\alpha|\\Delta, \\mu_{\\text{nom}}(r_t) + |b\\alpha|\\Delta]$.\n\nThe variance of $x_{t+1}$, $\\sigma_{x_{t+1}}^2$, is independent of $\\delta$. Since $h_t$ and $w_t$ are independent:\n$$\n\\sigma_{x_{t+1}}^2 = \\text{Var}(a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\,h_t + w_t) = \\text{Var}(b\\alpha\\,h_t) + \\text{Var}(w_t)\n$$\nUsing the variance property $\\text{Var}(cZ) = c^2\\text{Var}(Z)$ and the given variances $\\text{Var}(h_t) = \\sigma_h^2$ and $\\text{Var}(w_t) = \\sigma_w^2$:\n$$\n\\sigma_{x_{t+1}}^2 = (b\\alpha)^2\\sigma_h^2 + \\sigma_w^2\n$$\nThis total variance is constant for a given set of system parameters.\n\n#### Task 2: Sufficient Chance Constraint Derivation\n\nThe safety requirement is $P(|x_{t+1}| \\le X_{\\max}) \\ge 1 - \\varepsilon$ for all $|\\delta| \\le \\Delta$. This is equivalent to ensuring the violation probability $P(|x_{t+1}| > X_{\\max}) \\le \\varepsilon$ under the worst-case $\\delta$.\n\nWe seek a sufficient condition. Let's represent the next state as $x_{t+1} = \\mu_{x_{t+1}}(\\delta) + \\epsilon_t$, where $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma_{x_{t+1}}^2)$ is a zero-mean Gaussian variable representing the total system noise. The condition $|x_{t+1}| \\le X_{\\max}$ becomes $|\\mu_{x_{t+1}}(\\delta) + \\epsilon_t| \\le X_{\\max}$.\n\nBy the triangle inequality, $|\\mu_{x_{t+1}}(\\delta) + \\epsilon_t| \\le |\\mu_{x_{t+1}}(\\delta)| + |\\epsilon_t|$. Therefore, a sufficient condition for safety is $|\\mu_{x_{t+1}}(\\delta)| + |\\epsilon_t| \\le X_{\\max}$. To make this robust to all $|\\delta| \\le \\Delta$, we must consider the worst-case (largest) value of $|\\mu_{x_{t+1}}(\\delta)|$.\n$$\n\\max_{|\\delta| \\le \\Delta} |\\mu_{x_{t+1}}(\\delta)| = \\max_{|\\delta| \\le \\Delta} |\\mu_{\\text{nom}}(r_t) + b\\alpha\\delta| = |\\mu_{\\text{nom}}(r_t)| + |b\\alpha|\\Delta\n$$\nLet's name this worst-case absolute mean $\\mu_{\\text{wc,abs}}(r_t)$. The sufficient condition becomes $|\\epsilon_t| \\le X_{\\max} - \\mu_{\\text{wc,abs}}(r_t)$.\n\nThe probability of this condition holding is $P(|\\epsilon_t| \\le X_{\\max} - \\mu_{\\text{wc,abs}}(r_t))$. Let $Y(r_t) = X_{\\max} - \\mu_{\\text{wc,abs}}(r_t)$. If $Y(r_t)  0$, the probability is $0$, as $|\\epsilon_t|$ cannot be negative. If $Y(r_t) \\ge 0$, we analyze the probability of violation, which must be less than or equal to $\\varepsilon$:\n$$\nP(|\\epsilon_t| > Y(r_t)) \\le \\varepsilon\n$$\nUsing the union bound, $P(|\\epsilon_t| > Y(r_t)) = P(\\epsilon_t > Y(r_t)) + P(\\epsilon_t  -Y(r_t))$. Since $\\epsilon_t$ is a zero-mean Gaussian variable, these two tail probabilities are equal.\n$$\nP(|\\epsilon_t| > Y(r_t)) = 2 P(\\epsilon_t > Y(r_t)) = 2 P\\left(\\frac{\\epsilon_t}{\\sigma_{x_{t+1}}} > \\frac{Y(r_t)}{\\sigma_{x_{t+1}}}\\right)\n$$\nLet $Z = \\epsilon_t / \\sigma_{x_{t+1}}$ be a standard normal variable, $Z \\sim \\mathcal{N}(0,1)$. The violation probability is $2 P(Z > Y(r_t)/\\sigma_{x_{t+1}})$. Let $\\Phi(\\cdot)$ be the CDF of the standard normal distribution. Then $P(Z>z) = 1 - \\Phi(z)$. The sufficient chance constraint is:\n$$\n2 \\left( 1 - \\Phi\\left( \\frac{X_{\\max} - \\mu_{\\text{wc,abs}}(r_t)}{\\sigma_{x_{t+1}}} \\right) \\right) \\le \\varepsilon\n$$\nThis constraint can be checked for any given $r_t$, provided $X_{\\max} \\ge \\mu_{\\text{wc,abs}}(r_t)$. If $X_{\\max}  \\mu_{\\text{wc,abs}}(r_t)$, the violation probability bound is taken as $1$.\n\n#### Task 3: Optimal Robotic Override $r_t$\n\nThe objective is to choose $r_t$ to minimize the worst-case absolute mean of $x_{t+1}$, subject to $|r_t| \\le U_{\\max}$. The expression to minimize is:\n$$\n\\mu_{\\text{wc,abs}}(r_t) = |\\mu_{\\text{nom}}(r_t)| + |b\\alpha|\\Delta = |a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\mu_h| + |b\\alpha|\\Delta\n$$\nMinimizing this expression with respect to $r_t$ is equivalent to minimizing $|\\mu_{\\text{nom}}(r_t)|$, as the term $|b\\alpha|\\Delta$ is constant with respect to $r_t$. The expression $|\\mu_{\\text{nom}}(r_t)|$ is minimized when its argument is zero, which is the principle of centering the nominal distribution at the origin.\n$$\n\\mu_{\\text{nom}}(r_t) = a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\mu_h = 0\n$$\nSolving for an unconstrained optimal override $r_t^*$:\n$$\nb(1-\\alpha)r_t^* = -(a\\,x_t + b\\alpha\\mu_h) \\implies r_t^* = -\\frac{a\\,x_t + b\\alpha\\mu_h}{b(1-\\alpha)}\n$$\nThis solution is valid if $b(1-\\alpha) \\neq 0$. If $b(1-\\alpha) = 0$ (i.e., $b=0$ or $\\alpha=1$), the robot has no authority to alter the mean, and its choice of $r_t$ is irrelevant to the objective. In this case, a conventional choice is $r_t=0$.\n\nTo satisfy the saturation constraint $|r_t| \\le U_{\\max}$, we project the unconstrained solution $r_t^*$ onto the interval $[-U_{\\max}, U_{\\max}]$. This is a clipping operation:\n$$\nr_{t, \\text{opt}} = \\text{clip}(r_t^*, -U_{\\max}, U_{\\max}) = \\max(-U_{\\max}, \\min(U_{\\max}, r_t^*))\n$$\n\n#### Task 4: Minimal Achievable Violation Probability Bound $\\varepsilon_{\\text{bound}}$\n\nThe minimal achievable upper bound on the violation probability, $\\varepsilon_{\\text{bound}}$, is found by computing the chosen optimal override $r_{t, \\text{opt}}$ from Task 3 and substituting it into the sufficient violation probability formula derived in Task 2.\n\n1.  Compute the optimal saturated override $r_t = r_{t, \\text{opt}}$.\n2.  Calculate the corresponding worst-case absolute mean $\\mu_{\\text{wc,abs}}(r_t) = |a\\,x_t + b(1-\\alpha)r_t + b\\alpha\\mu_h| + |b\\alpha|\\Delta$.\n3.  Calculate the total standard deviation $\\sigma_{\\text{tot}} = \\sqrt{(b\\alpha\\sigma_h)^2 + \\sigma_w^2}$.\n4.  Calculate the bound $\\varepsilon_{\\text{bound}}$ based on two cases:\n    *   **Stochastic Case ($\\sigma_{\\text{tot}} > 0$):**\n        If $X_{\\max}  \\mu_{\\text{wc,abs}}(r_t)$, the violation is certain under this conservative bound, so $\\varepsilon_{\\text{bound}} = 1.0$.\n        Otherwise, $\\varepsilon_{\\text{bound}} = 2 \\left( 1 - \\Phi\\left( \\frac{X_{\\max} - \\mu_{\\text{wc,abs}}(r_t)}{\\sigma_{\\text{tot}}} \\right) \\right)$.\n    *   **Deterministic Case ($\\sigma_{\\text{tot}} = 0$):**\n        The system is deterministic. Violation occurs if and only if the worst-case state $|x_{t+1}|$ exceeds $X_{\\max}$.\n        If $|x_{t+1}|_{\\text{wc}} = \\mu_{\\text{wc,abs}}(r_t) > X_{\\max}$, violation is certain, so $\\varepsilon_{\\text{bound}} = 1.0$.\n        Otherwise, violation is impossible, so $\\varepsilon_{\\text{bound}} = 0.0$.\n\nThis formulation provides a complete method for computing the optimal override and its associated robust safety guarantee.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\n# np.__version__ should be 1.23.5\n# scipy.__version__ should be 1.11.4\n\ndef solve():\n    \"\"\"\n    Solves the shared autonomy safeguard problem for a set of test cases.\n    \"\"\"\n    # Test cases from the problem statement:\n    # (a, b, alpha, xt, mu_h, Delta, sigma_h, sigma_w, X_max, U_max, eps_target)\n    test_cases = [\n        (0.9, 1.0, 0.7, 2.0, 1.0, 0.3, 0.5, 0.1, 3.0, 2.0, 0.05),\n        (1.2, 1.0, 0.9, 2.5, 1.5, 0.8, 0.7, 0.2, 3.0, 0.5, 0.02),\n        (0.95, 1.0, 1.0, 0.0, 0.0, 0.5, 0.3, 0.1, 0.4, 1.0, 0.1),\n        (0.5, 2.0, 0.6, -1.0, -0.5, 0.1, 0.2, 0.05, 1.0, 10.0, 0.01),\n        (1.0, 1.0, 0.5, 1.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.001),\n    ]\n\n    results = []\n    \n    # A small tolerance for floating point comparisons\n    TOLERANCE = 1e-9\n\n    for case in test_cases:\n        a, b, alpha, x_t, mu_h, Delta, sigma_h, sigma_w, X_max, U_max, eps_target = case\n\n        # Task 3: Derive the choice of r_t\n        r_t_opt = 0.0\n        # The term b*(1-alpha) determines the robot's control authority over the mean\n        control_authority = b * (1 - alpha)\n        \n        if abs(control_authority) > TOLERANCE:\n            # Unconstrained optimal r_t to center the nominal mean at zero\n            r_t_unc = -(a * x_t + b * alpha * mu_h) / control_authority\n            # Apply saturation constraint |r_t| = U_max\n            r_t_opt = np.clip(r_t_unc, -U_max, U_max)\n        else:\n            # If control authority is zero (alpha=1 or b=0), the robot cannot influence\n            # the mean. By convention, the override is set to zero.\n            r_t_opt = 0.0\n\n        # Task 4: Define the minimal achievable upper bound on the violation probability\n        \n        # 1. Calculate nominal mean with the chosen r_t\n        mu_nom = a * x_t + b * (1 - alpha) * r_t_opt + b * alpha * mu_h\n        \n        # 2. Calculate worst-case absolute mean, robust to delta\n        mu_wc_abs = abs(mu_nom) + abs(b * alpha) * Delta\n        \n        # 3. Calculate total variance and standard deviation\n        sigma_sq_h = (b * alpha * sigma_h)**2\n        sigma_sq_w = sigma_w**2\n        sigma_tot_sq = sigma_sq_h + sigma_sq_w\n        sigma_tot = np.sqrt(sigma_tot_sq)\n\n        eps_bound = 0.0\n\n        # 4. Calculate the violation probability bound\n        if sigma_tot  TOLERANCE:\n            # Deterministic case\n            if mu_wc_abs > X_max:\n                eps_bound = 1.0\n            else:\n                eps_bound = 0.0\n        else:\n            # Stochastic case\n            safety_margin = X_max - mu_wc_abs\n            if safety_margin  0:\n                # The worst-case mean is already outside the safe set,\n                # making the sufficient condition impossible to meet.\n                eps_bound = 1.0\n            else:\n                # Use survival function (1 - CDF) for numerical stability\n                # P(|err| > Y) = 2 * P(err > Y) = 2 * sf(Y / sigma)\n                z = safety_margin / sigma_tot\n                eps_bound = 2.0 * norm.sf(z)\n\n        # Evaluate feasibility of the target chance constraint\n        feasible = eps_bound = eps_target\n\n        results.append([r_t_opt, feasible, round(eps_bound, 6)])\n\n    # Format the final output as a string representing a list of lists.\n    # The default str() representation of a list is used for formatting.\n    # E.g., `str([-2.0, True, 0.01448])` -> `'[-2.0, True, 0.01448]'`\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}