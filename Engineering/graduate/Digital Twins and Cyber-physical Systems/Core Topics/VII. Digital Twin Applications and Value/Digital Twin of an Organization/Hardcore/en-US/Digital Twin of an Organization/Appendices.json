{
    "hands_on_practices": [
        {
            "introduction": "Before a Digital Twin of an Organization (DTO) can be used for monitoring or control, we must answer a fundamental question: can our chosen measurements actually \"see\" all the critical internal dynamics of the organization? This property, known as observability, is a cornerstone of control theory and is essential for designing an effective DTO. This practice will guide you through calculating the observability of a simplified organizational model, revealing how mathematical analysis can uncover blind spots in a monitoring strategy. ",
            "id": "4214840",
            "problem": "A digital twin of an organization near an operating point is modeled as a continuous-time, linear time-invariant state-space system with state vector $x \\in \\mathbb{R}^{4}$, where $x_{1}$ represents order backlog deviations, $x_{2}$ represents work-in-progress throughput deviations, $x_{3}$ represents resource capacity imbalance, and $x_{4}$ represents a latent compliance risk propensity. The output vector $y \\in \\mathbb{R}^{2}$ collects key monitoring indicators: a filtered backlog measure and a composite compliance incident signal. The linearization around the operating point yields the pair $(A,C)$:\n$$\nA \\;=\\; \\begin{bmatrix}\n-0.3  1  0  0 \\\\\n0  -0.5  1  0 \\\\\n0  0  -0.1  0 \\\\\n0  0  0  -0.2\n\\end{bmatrix}, \n\\qquad\nC \\;=\\; \\begin{bmatrix}\n1  0  0  0 \\\\\n0  1  1  0\n\\end{bmatrix}.\n$$\nStarting from the definition of observability for linear time-invariant systems and without using any pre-given shortcut formulas, determine the rank of the observability matrix associated with $(A,C)$ and interpret what this rank implies for the monitoring design of the digital twin (for example, which latent organizational dynamics can or cannot be inferred from the available indicators). Provide the rank as your final numerical answer. No rounding is necessary, and no physical units are required for the rank.",
            "solution": "The problem requires us to determine the observability of a linear time-invariant (LTI) system described by the state-space representation $(\\dot{x} = Ax, y = Cx)$ and interpret the findings in the context of a digital twin of an organization. The core of the task is to compute the rank of the system's observability matrix, starting from the fundamental definition of observability.\n\nAn LTI system is said to be observable if, for any unknown initial state $x(0) = x_0$, there exists a finite time $t_f  0$ such that knowledge of the input $u(t)$ and the output $y(t)$ over the interval $[0, t_f]$ is sufficient to uniquely determine $x_0$. For a system with no input ($u(t)=0$), the state trajectory is given by $x(t) = \\exp(At)x_0$, and the output is $y(t) = C x(t) = C \\exp(At) x_0$.\n\nA state $x_0$ is unobservable if and only if, for that initial state, the output is identically zero for all time $t \\ge 0$. That is, $y(t) = C \\exp(At) x_0 = \\mathbf{0}$ for all $t \\ge 0$. To derive a testable condition from this definition, we can repeatedly differentiate the output equation with respect to time and evaluate at $t=0$:\n$y(0) = C x_0 = \\mathbf{0}$\n$\\dot{y}(t) = \\frac{d}{dt}(C \\exp(At) x_0) = C A \\exp(At) x_0 \\implies \\dot{y}(0) = C A x_0 = \\mathbf{0}$\n$\\ddot{y}(t) = \\frac{d^2}{dt^2}(C \\exp(At) x_0) = C A^2 \\exp(At) x_0 \\implies \\ddot{y}(0) = C A^2 x_0 = \\mathbf{0}$\n...\n$y^{(k)}(t) = \\frac{d^k}{dt^k}(C \\exp(At) x_0) = C A^k \\exp(At) x_0 \\implies y^{(k)}(0) = C A^k x_0 = \\mathbf{0}$\n\nTherefore, an initial state $x_0$ is unobservable if and only if $C A^k x_0 = \\mathbf{0}$ for all non-negative integers $k$. According to the Cayley-Hamilton theorem, any matrix power $A^k$ for $k \\ge n$ (where $n$ is the dimension of the state vector) can be expressed as a linear combination of the powers $\\{A^0, A^1, \\dots, A^{n-1}\\}$. Thus, the condition simplifies to checking only the first $n$ such equations. This set of linear equations can be written in matrix form:\n$$\n\\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\n\\vdots \\\\\nCA^{n-1}\n\\end{bmatrix}\nx_0 = \\mathbf{0}\n$$\nThe matrix in this equation is the observability matrix, denoted by $\\mathcal{O}$. A non-zero state $x_0$ is unobservable if it lies in the null space of $\\mathcal{O}$. The system is fully observable if the only solution to $\\mathcal{O} x_0 = \\mathbf{0}$ is the trivial solution $x_0 = \\mathbf{0}$. This is equivalent to the condition that the observability matrix $\\mathcal{O}$ has full column rank, i.e., $\\text{rank}(\\mathcal{O}) = n$.\n\nThe state dimension is $n=4$. The observability matrix is $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}$. We are given:\n$$\nA = \\begin{bmatrix}\n-0.3  1  0  0 \\\\\n0  -0.5  1  0 \\\\\n0  0  -0.1  0 \\\\\n0  0  0  -0.2\n\\end{bmatrix}, \n\\qquad\nC = \\begin{bmatrix}\n1  0  0  0 \\\\\n0  1  1  0\n\\end{bmatrix}\n$$\nThe rows of $\\mathcal{O}$ are the rows of $C, CA, CA^2,$ and $CA^3$.\nFirst, we compute the matrix products:\n$C = \\begin{bmatrix} 1  0  0  0 \\\\ 0  1  1  0 \\end{bmatrix}$\n\n$CA = \\begin{bmatrix} 1  0  0  0 \\\\ 0  1  1  0 \\end{bmatrix} \\begin{bmatrix} -0.3  1  0  0 \\\\ 0  -0.5  1  0 \\\\ 0  0  -0.1  0 \\\\ 0  0  0  -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.3  1  0  0 \\\\ 0  -0.5  0.9  0 \\end{bmatrix}$\n\nTo compute $CA^2$, we first find $A^2$:\n$A^2 = A \\cdot A = \\begin{bmatrix} -0.3  1  0  0 \\\\ 0  -0.5  1  0 \\\\ 0  0  -0.1  0 \\\\ 0  0  0  -0.2 \\end{bmatrix}^2 = \\begin{bmatrix} 0.09  -0.8  1  0 \\\\ 0  0.25  -0.6  0 \\\\ 0  0  0.01  0 \\\\ 0  0  0  0.04 \\end{bmatrix}$\nThen, $CA^2 = C \\cdot A^2 = \\begin{bmatrix} 1  0  0  0 \\\\ 0  1  1  0 \\end{bmatrix} \\begin{bmatrix} 0.09  -0.8  1  0 \\\\ 0  0.25  -0.6  0 \\\\ 0  0  0.01  0 \\\\ 0  0  0  0.04 \\end{bmatrix} = \\begin{bmatrix} 0.09  -0.8  1  0 \\\\ 0  0.25  -0.59  0 \\end{bmatrix}$\n\nTo compute $CA^3$, we first find $A^3$:\n$A^3 = A \\cdot A^2 = \\begin{bmatrix} -0.3  1  0  0 \\\\ 0  -0.5  1  0 \\\\ 0  0  -0.1  0 \\\\ 0  0  0  -0.2 \\end{bmatrix} \\begin{bmatrix} 0.09  -0.8  1  0 \\\\ 0  0.25  -0.6  0 \\\\ 0  0  0.01  0 \\\\ 0  0  0  0.04 \\end{bmatrix} = \\begin{bmatrix} -0.027  0.49  -0.9  0 \\\\ 0  -0.125  0.31  0 \\\\ 0  0  -0.001  0 \\\\ 0  0  0  -0.008 \\end{bmatrix}$\nThen, $CA^3 = C \\cdot A^3 = \\begin{bmatrix} 1  0  0  0 \\\\ 0  1  1  0 \\end{bmatrix} \\begin{bmatrix} -0.027  0.49  -0.9  0 \\\\ 0  -0.125  0.31  0 \\\\ 0  0  -0.001  0 \\\\ 0  0  0  -0.008 \\end{bmatrix} = \\begin{bmatrix} -0.027  0.49  -0.9  0 \\\\ 0  -0.125  0.309  0 \\end{bmatrix}$\n\nNow we assemble the full observability matrix $\\mathcal{O}$:\n$$\n\\mathcal{O} = \\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\nCA^3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n-0.3  1  0  0 \\\\\n0  -0.5  0.9  0 \\\\\n0.09  -0.8  1  0 \\\\\n0  0.25  -0.59  0 \\\\\n-0.027  0.49  -0.9  0 \\\\\n0  -0.125  0.309  0\n\\end{bmatrix}\n$$\nTo determine the rank of this $8 \\times 4$ matrix, we analyze its columns. The fourth column consists entirely of zeros. This immediately implies that the columns are not linearly independent. Specifically, the vector $v = [0, 0, 0, \\alpha]^T$ for any non-zero scalar $\\alpha$ will satisfy $\\mathcal{O}v = \\mathbf{0}$. This means the null space of $\\mathcal{O}$ has a dimension of at least $1$, and consequently, the rank of $\\mathcal{O}$ is at most $4-1=3$.\n\nTo determine if the rank is exactly $3$, we must check if the first three columns are linearly independent. We can do this by finding a $3 \\times 3$ submatrix with a non-zero determinant. Let's form a submatrix using the first three rows and first three columns of $\\mathcal{O}$:\n$$\n M = \\begin{bmatrix}\n1  0  0 \\\\\n0  1  1 \\\\\n-0.3  1  0\n\\end{bmatrix}\n$$\nThe determinant of this submatrix is:\n$$\n\\det(M) = 1 \\cdot \\det\\begin{pmatrix} 1  1 \\\\ 1  0 \\end{pmatrix} - 0 + 0 = 1 \\cdot (1 \\cdot 0 - 1 \\cdot 1) = -1\n$$\nSince $\\det(M) \\neq 0$, the first three columns of $\\mathcal{O}$ are linearly independent. Therefore, the rank of the observability matrix $\\mathcal{O}$ is exactly $3$.\n\nInterpretation:\nThe rank of the observability matrix is $3$, which is less than the state dimension $n=4$. The difference, $n - \\text{rank}(\\mathcal{O}) = 4 - 3 = 1$, indicates that there is a one-dimensional unobservable subspace. Any state vector within this subspace cannot be determined from the output measurements.\n\nAs shown by the calculation, the null space of $\\mathcal{O}$ is spanned by the vector $[0, 0, 0, 1]^T$. This vector corresponds to the fourth state variable, $x_4$, which is the \"latent compliance risk propensity\". This means that the dynamics of $x_4$ are completely decoupled from the outputs $y$. An initial value or any subsequent change in $x_4$ has no effect on the measured \"filtered backlog measure\" and \"composite compliance incident signal\".\n\nIn the context of the digital twin monitoring design, this result implies a critical flaw: the current set of key monitoring indicators is insufficient to track or infer the organization's latent compliance risk. The dynamics associated with backlog ($x_1$), throughput ($x_2$), and resource imbalance ($x_3$) can be fully reconstructed from the output data (as their corresponding columns in $\\mathcal{O}$ are linearly independent). However, the propensity for compliance risk ($x_4$) remains hidden. To make this state observable, the monitoring strategy must be augmented with new indicators that are explicitly or implicitly dependent on $x_4$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "A DTO is a complex model with numerous parameters, many of which are uncertain. To build a credible and useful twin, we must focus our calibration efforts on the parameters that matter most. This exercise introduces global sensitivity analysis (GSA), a powerful computational technique to quantify how uncertainty in each model input contributes to uncertainty in the outputs, allowing you to prioritize parameters for data collection and calibration. You will implement the Sobol' method, a widely-used variance-based GSA technique, to create a data-driven priority list. ",
            "id": "4214862",
            "problem": "You are modeling a digital twin of an organization where Key Performance Indicators (KPIs) emerge from deterministic transformations of model parameters. Your task is to implement a program that performs variance-based global sensitivity analysis using first-order Sobol indices and then produces a calibration priority ranking of parameters for each test case. The program must be self-contained and deterministic.\n\nFundamental base and definitions:\n- Use the law of total variance and the associated Analysis of Variance (ANOVA) decomposition. For a scalar KPI random variable $Y = f(\\mathbf{X})$ with independent components $\\mathbf{X} = (X_1,\\dots,X_d)$, the total variance decomposes as\n$$\n\\mathrm{Var}(Y) = \\sum_{i=1}^{d} V_i + \\sum_{ij} V_{ij} + \\cdots + V_{1,2,\\dots,d},\n$$\nwhere $V_i = \\mathrm{Var}_{X_i}\\big(\\mathbb{E}[Y \\mid X_i]\\big)$, $V_{ij} = \\mathrm{Var}_{X_i,X_j}\\big(\\mathbb{E}[Y \\mid X_i,X_j]\\big) - V_i - V_j$, and so on, assuming square-integrable $f$ and statistical independence of inputs under their prior distributions.\n- The first-order Sobol sensitivity index for parameter $i$ is defined as\n$$\nS_i = \\frac{\\mathrm{Var}_{X_i}\\left(\\mathbb{E}[Y \\mid X_i]\\right)}{\\mathrm{Var}(Y)} \\in [0,1],\n$$\nwhich measures the fractional contribution of parameter $i$ to the output variance through its main effect.\n- Use the Monte Carlo Saltelli estimator for $S_i$. Given two independent sample matrices $\\mathbf{A}, \\mathbf{B} \\in [0,1]^{N \\times d}$ with $N$ independent and identically distributed samples per row and $d$ parameters, define $\\mathbf{A}_{B}^{(i)}$ as $\\mathbf{A}$ with its $i$-th column replaced by the $i$-th column of $\\mathbf{B}$. For a scalar output $Y$, let $Y_{\\mathbf{A}} = f(\\mathbf{A})$, $Y_{\\mathbf{B}} = f(\\mathbf{B})$, and $Y_{\\mathbf{A}_{B}^{(i)}} = f(\\mathbf{A}_{B}^{(i)})$. Then the first-order index can be estimated by\n$$\n\\widehat{S}_i = \\frac{\\frac{1}{N}\\sum_{n=1}^{N} Y_{\\mathbf{B}}^{(n)}\\left(Y_{\\mathbf{A}_{B}^{(i)}}^{(n)} - Y_{\\mathbf{A}}^{(n)}\\right)}{\\widehat{\\mathrm{Var}}(Y)},\n$$\nwhere $\\widehat{\\mathrm{Var}}(Y)$ is estimated using the pooled variance of $\\{Y_{\\mathbf{A}}^{(n)}\\}_{n=1}^{N}$ and $\\{Y_{\\mathbf{B}}^{(n)}\\}_{n=1}^{N}$. When $\\widehat{\\mathrm{Var}}(Y) = 0$, define $\\widehat{S}_i = 0$.\n- Angles for trigonometric functions must be in radians.\n\nCalibration priority:\n- Let there be $m$ KPIs per test case and $d$ parameters with ranges $\\left[a_i,b_i\\right]$. For each KPI $k \\in \\{1,\\dots,m\\}$, compute first-order indices $\\widehat{S}_i^{(k)}$ for all $i \\in \\{1,\\dots,d\\}$. Define parameter width $w_i = b_i - a_i$ and normalized width $\\tilde{w}_i = \\frac{w_i}{\\sum_{j=1}^{d} w_j}$.\n- Define a calibration priority score per parameter as\n$$\nP_i = \\sum_{k=1}^{m} \\widehat{S}_i^{(k)} \\cdot \\tilde{w}_i.\n$$\n- Rank parameters in descending order of $P_i$, breaking ties by increasing parameter index (zero-based indexing).\n\nMonte Carlo specifications:\n- Use $N = 8000$ base samples per test case for the Monte Carlo estimator.\n- Use a fixed pseudo-random seed of $12345$ for reproducibility across all test cases.\n- Sample each input uniformly on $[0,1]$ and then transform to the actual parameter ranges via $x \\mapsto a_i + x\\cdot(b_i - a_i)$.\n\nTest suite:\nImplement the sensitivity analysis and prioritization for the following three test cases. In all cases, parameter inputs are mutually independent with uniform priors over their specified ranges. All numbers are exact constants.\n\n- Test Case $1$:\n  - Parameters: $d = 3$, bounds $\\left[a_1,b_1\\right] = [0.5, 1.5]$, $\\left[a_2,b_2\\right] = [0, 2]$, $\\left[a_3,b_3\\right] = [0, 1]$.\n  - KPIs ($m = 2$):\n    - $Y_1 = 2\\cdot p_1 + p_2^2 + 0.5\\cdot p_3$.\n    - $Y_2 = p_1\\cdot p_3 + 0.2\\cdot p_2$.\n- Test Case $2$:\n  - Parameters: $d = 4$, bounds $\\left[a_1,b_1\\right] = [0, 1]$, $\\left[a_2,b_2\\right] = [0, 1]$, $\\left[a_3,b_3\\right] = [0, 2]$, $\\left[a_4,b_4\\right] = [0, 1]$.\n  - KPIs ($m = 2$):\n    - $Y_1 = \\sin(\\pi\\cdot p_1) + p_2^2$.\n    - $Y_2 = e^{-p_3} + 0.1\\cdot p_1 + 0\\cdot p_4$.\n- Test Case $3$:\n  - Parameters: $d = 2$, bounds $\\left[a_1,b_1\\right] = [0, 1]$, $\\left[a_2,b_2\\right] = [0, 1]$.\n  - KPIs ($m = 2$):\n    - $Y_1 = 3$.\n    - $Y_2 = p_1$.\n\nRequired final output format:\n- Your program should produce a single line of output containing a Python-like list of lists, one inner list per test case. Each inner list must contain the zero-based parameter indices sorted in descending calibration priority $P_i$ for that test case. For example, a valid output with three test cases might look like $[[2,0,1],[1,0,2,3],[0,1]]$.\n\nAngle unit:\n- All trigonometric functions use radians.\n\nNo physical units are involved in this problem.\n\nYour program must:\n- Implement the Monte Carlo Saltelli estimator for first-order Sobol indices exactly as specified.\n- Handle the zero-variance case by setting corresponding first-order indices to $0$.\n- Use the sampling specifications above.\n- Produce the exact output format described above.",
            "solution": "We begin from the law of total variance and the Analysis of Variance (ANOVA) decomposition for a scalar Key Performance Indicator (KPI) random variable $Y = f(\\mathbf{X})$ with independent inputs $\\mathbf{X} = (X_1,\\dots,X_d)$. The total variance admits the decomposition\n$$\n\\mathrm{Var}(Y) = \\sum_{i=1}^{d} V_i + \\sum_{ij} V_{ij} + \\cdots + V_{1,2,\\dots,d},\n$$\nwhere $V_i = \\mathrm{Var}_{X_i}(\\mathbb{E}[Y \\mid X_i])$ captures the main effect of parameter $i$, while higher-order terms capture interactions. The first-order Sobol sensitivity index is defined as\n$$\nS_i = \\frac{V_i}{\\mathrm{Var}(Y)} = \\frac{\\mathrm{Var}_{X_i}(\\mathbb{E}[Y \\mid X_i])}{\\mathrm{Var}(Y)}.\n$$\nIt quantifies the fraction of the output variance attributable to variations in a single parameter $X_i$ through its main effect, independent of interactions.\n\nTo compute $S_i$ without closed-form integrals, we use Monte Carlo estimators that are consistent with the ANOVA decomposition under independent input distributions. The Saltelli estimator for the first-order index is built from two independent input sample matrices $\\mathbf{A}, \\mathbf{B} \\in [0,1]^{N \\times d}$, each row being a realization of the input vector $\\mathbf{X}$ drawn from its prior distributions via inverse transform sampling from $[0,1]$. For a given parameter index $i$, construct the hybrid matrix $\\mathbf{A}_{B}^{(i)}$ by replacing the $i$-th column of $\\mathbf{A}$ with the corresponding column of $\\mathbf{B}$. Denote the model outputs for a scalar KPI $Y$ as $Y_{\\mathbf{A}} = f(\\mathbf{A})$, $Y_{\\mathbf{B}} = f(\\mathbf{B})$, and $Y_{\\mathbf{A}_{B}^{(i)}} = f(\\mathbf{A}_{B}^{(i)})$. The Saltelli first-order estimator is\n$$\n\\widehat{S}_i = \\frac{\\frac{1}{N} \\sum_{n=1}^{N} Y_{\\mathbf{B}}^{(n)} \\left( Y_{\\mathbf{A}_{B}^{(i)}}^{(n)} - Y_{\\mathbf{A}}^{(n)} \\right)}{\\widehat{\\mathrm{Var}}(Y)},\n$$\nwhere $\\widehat{\\mathrm{Var}}(Y)$ is an unbiased or consistent estimator of $\\mathrm{Var}(Y)$, for example the pooled sample variance using the $2N$ samples from $\\mathbf{A}$ and $\\mathbf{B}$. Under integrability and independence, this estimator converges to the true $S_i$ as $N \\to \\infty$. When the estimated variance $\\widehat{\\mathrm{Var}}(Y)$ is zero (i.e., the KPI is numerically constant across all sampled inputs), the estimator is undefined; we follow a robust convention and set $\\widehat{S}_i = 0$ in that case, consistent with $V_i = 0$.\n\nIn our organizational digital twin setting, each test case defines a deterministic mapping $f: \\mathbb{R}^{d} \\to \\mathbb{R}^{m}$ where $m$ is the number of KPIs. Inputs are independent and uniformly distributed over specified parameter ranges $\\left[a_i,b_i\\right]$. We sample $\\mathbf{A}, \\mathbf{B}$ from $[0,1]^{N \\times d}$ and transform to the actual ranges via the affine map $x \\mapsto a_i + x\\cdot(b_i - a_i)$. For each KPI $k \\in \\{1,\\dots,m\\}$, we compute $\\widehat{S}_i^{(k)}$ for all $i$.\n\nCalibration prioritization combines global sensitivity with prior uncertainty. Larger parameter ranges suggest more potential room for calibration benefit. We encode this by normalized widths $\\tilde{w}_i = \\frac{w_i}{\\sum_{j=1}^{d} w_j}$, with $w_i = b_i - a_i$. We then define the calibration priority score\n$$\nP_i = \\sum_{k=1}^{m} \\widehat{S}_i^{(k)} \\cdot \\tilde{w}_i,\n$$\nwhich aggregates main-effect sensitivity across KPIs and scales by relative parameter uncertainty. The prioritization is the descending sort of $P_i$, breaking ties by smaller parameter index to ensure determinism.\n\nAlgorithmic design:\n- Fix $N = 8000$ and a pseudo-random seed of $12345$ to ensure reproducibility.\n- For each test case:\n  1. Define $d$, parameter bounds $\\left[a_i,b_i\\right]$, and the KPI mapping $f$.\n  2. Generate $\\mathbf{A}, \\mathbf{B} \\in [0,1]^{N \\times d}$ as independent uniform samples using the fixed seed.\n  3. Affinely transform $\\mathbf{A}, \\mathbf{B}$ to the actual parameter ranges.\n  4. Evaluate $Y_{\\mathbf{A}}$ and $Y_{\\mathbf{B}}$ for each KPI $k$ to get vectors in $\\mathbb{R}^{N}$.\n  5. For each parameter $i$, construct $\\mathbf{A}_{B}^{(i)}$, evaluate $Y_{\\mathbf{A}_{B}^{(i)}}$, compute the pooled variance $\\widehat{\\mathrm{Var}}(Y)$ from concatenated $Y_{\\mathbf{A}}$ and $Y_{\\mathbf{B}}$, and then compute $\\widehat{S}_i^{(k)}$ using the Saltelli formula. If $\\widehat{\\mathrm{Var}}(Y) = 0$, set $\\widehat{S}_i^{(k)} = 0$.\n  6. Compute $P_i = \\left(\\sum_{k=1}^{m} \\widehat{S}_i^{(k)}\\right) \\cdot \\tilde{w}_i$.\n  7. Sort indices by descending $P_i$; break ties by increasing index.\n- Aggregate the results for all test cases into a single list of lists and print as a single line in the specified format.\n\nScientific realism and numerical soundness:\n- The chosen KPI mappings correspond to plausible organizational dynamics (e.g., throughput, inventory effects) but are treated purely as deterministic mathematical functions to isolate sensitivity computation principles.\n- Using independent uniform priors and Monte Carlo variance-based estimators traces back to well-tested statistical Monte Carlo methods.\n- The test suite covers a typical non-linear case (Test Case $1$), includes a case with an irrelevant parameter and mixed non-linearities (Test Case $2$), and an edge case with a constant KPI to validate zero-variance handling (Test Case $3$).\n\nThe final program adheres strictly to the specifications and outputs the three priority rankings as a single Python-like list literal, e.g., $[[1,0,2],[2,0,1,3],[0,1]]$ (the actual computed ordering will reflect the Monte Carlo estimates with the fixed seed).",
            "answer": "```python\nimport numpy as np\n\ndef saltelli_first_order_indices(f, bounds, N, seed):\n    \"\"\"\n    Compute first-order Sobol indices for a vector-valued function f: R^d - R^m\n    using the Saltelli estimator with N base samples and a fixed seed.\n    - f expects an array of shape (n_samples, d) and returns shape (n_samples, m).\n    - bounds is a list of (a_i, b_i) for i=0..d-1.\n    Returns:\n        S: array of shape (d, m) with first-order indices per parameter per KPI.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    d = len(bounds)\n    # Sample in unit cube\n    A_unit = rng.random((N, d))\n    B_unit = rng.random((N, d))\n\n    # Affine transform to actual bounds\n    a = np.array([lo for lo, hi in bounds])\n    b = np.array([hi for lo, hi in bounds])\n    widths = b - a\n\n    A = a + A_unit * widths\n    B = a + B_unit * widths\n\n    YA = f(A)  # shape (N, m)\n    YB = f(B)  # shape (N, m)\n    N, m = YA.shape\n\n    # Variance estimate using pooled samples\n    Y_concat = np.vstack([YA, YB])  # (2N, m)\n    Y_mean = np.mean(Y_concat, axis=0)\n    # Unbiased sample variance with ddof=1\n    varY = np.var(Y_concat, axis=0, ddof=1)  # shape (m,)\n\n    S = np.zeros((d, m), dtype=float)\n\n    # For each parameter, build A_Bi and evaluate\n    for i in range(d):\n        ABi = A.copy()\n        ABi[:, i] = B[:, i]\n        YABi = f(ABi)  # (N, m)\n\n        # Saltelli first-order estimator:\n        # S_i = mean( YB * (YABi - YA) ) / Var(Y)\n        numer = np.mean(YB * (YABi - YA), axis=0)  # (m,)\n        # Handle zero variance robustly\n        with np.errstate(invalid='ignore', divide='ignore'):\n            Si = np.where(varY  0.0, numer / varY, 0.0)\n        # Numerical guard: clip to [0,1]\n        Si = np.clip(Si, 0.0, 1.0)\n        S[i, :] = Si\n\n    return S, widths\n\n# Define the test case models\ndef model_case_1(X):\n    \"\"\"\n    X: (n,3) with columns p1, p2, p3\n    KPIs:\n      Y1 = 2*p1 + p2^2 + 0.5*p3\n      Y2 = p1*p3 + 0.2*p2\n    \"\"\"\n    p1 = X[:, 0]\n    p2 = X[:, 1]\n    p3 = X[:, 2]\n    Y1 = 2.0 * p1 + p2**2 + 0.5 * p3\n    Y2 = p1 * p3 + 0.2 * p2\n    return np.column_stack([Y1, Y2])\n\ndef model_case_2(X):\n    \"\"\"\n    X: (n,4) with columns p1, p2, p3, p4\n    KPIs:\n      Y1 = sin(pi*p1) + p2^2\n      Y2 = exp(-p3) + 0.1*p1 + 0.0*p4\n    Angles in radians.\n    \"\"\"\n    p1 = X[:, 0]\n    p2 = X[:, 1]\n    p3 = X[:, 2]\n    p4 = X[:, 3]\n    Y1 = np.sin(np.pi * p1) + p2**2\n    Y2 = np.exp(-p3) + 0.1 * p1 + 0.0 * p4\n    return np.column_stack([Y1, Y2])\n\ndef model_case_3(X):\n    \"\"\"\n    X: (n,2) with columns p1, p2\n    KPIs:\n      Y1 = 3 (constant)\n      Y2 = p1\n    \"\"\"\n    p1 = X[:, 0]\n    # p2 = X[:, 1]  # unused\n    Y1 = np.full_like(p1, 3.0)\n    Y2 = p1\n    return np.column_stack([Y1, Y2])\n\ndef prioritize(S, widths):\n    \"\"\"\n    Compute calibration priority ranking indices given first-order indices S (d x m)\n    and parameter widths (d,). Priority score P_i = (sum_k S_i,k) * (width_i / sum_j width_j).\n    Return list of indices sorted descending by P_i, ties broken by lower index.\n    \"\"\"\n    d, m = S.shape\n    width_sum = np.sum(widths)\n    if width_sum = 0.0:\n        wnorm = np.ones_like(widths) / max(len(widths), 1)\n    else:\n        wnorm = widths / width_sum\n    P = np.sum(S, axis=1) * wnorm\n    # Sort by (-P_i, i)\n    order = sorted(range(d), key=lambda i: (-P[i], i))\n    return order\n\ndef solve():\n    N = 8000\n    seed = 12345\n\n    test_cases = [\n        # Each case: (model_function, bounds)\n        (model_case_1, [(0.5, 1.5), (0.0, 2.0), (0.0, 1.0)]),\n        (model_case_2, [(0.0, 1.0), (0.0, 1.0), (0.0, 2.0), (0.0, 1.0)]),\n        (model_case_3, [(0.0, 1.0), (0.0, 1.0)]),\n    ]\n\n    results = []\n    # To keep reproducibility per case, vary seed deterministically\n    for case_index, (model, bounds) in enumerate(test_cases):\n        S, widths = saltelli_first_order_indices(model, bounds, N, seed + case_index)\n        order = prioritize(S, widths)\n        results.append(order)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([str(lst) for lst in results])}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A key promise of a DTO is its ability to serve as a virtual sandbox for discovering optimal strategies. By framing organizational decision-making as a Markov Decision Process (MDP), we can use algorithms from reinforcement learning to compute the best course of action in any given state. In this practice, you will use the value iteration algorithm to find an optimal resource allocation policy for a hypothetical organization, demonstrating how a DTO can move beyond simple monitoring to provide proactive, optimized decision support. ",
            "id": "4214863",
            "problem": "A digital twin of an organization models decision-making over coarse-grained backlog states under uncertainty. Consider a finite Markov Decision Process (MDP) with discounted infinite-horizon returns, where the state space is $S=\\{0,1,2\\}$, representing organizational backlog levels: $0$ (low), $1$ (medium), and $2$ (high). The action space is $A=\\{0,1,2\\}$, representing $0$ (allocate resources to reduce backlog), $1$ (hold steady), and $2$ (shift resources to innovation). Immediate rewards are defined by $R(s,a)=r_a + p_s$, where $r_a$ is the action-dependent immediate reward and $p_s$ is the backlog-dependent penalty. Assume $r_0=-1$, $r_1=0$, $r_2=2$, and $p_0=0$, $p_1=-2$, $p_2=-5$.\n\nTransitions are specified by one of two kernels, $\\mathsf{P}^{(1)}$ and $\\mathsf{P}^{(2)}$, both mapping $S \\times A$ to distributions over $S$. For $\\mathsf{P}^{(1)}$ (stochastic operational dynamics):\n- For action $0$ (allocate resources to reduce backlog):\n  - From $s=0$: to $s'=0$ with probability $0.7$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.6$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.1$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.6$, to $s'=2$ with probability $0.4$.\n- For action $1$ (hold steady):\n  - From $s=0$: to $s'=0$ with probability $0.5$, to $s'=1$ with probability $0.5$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.6$, to $s'=2$ with probability $0.4$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.2$, to $s'=2$ with probability $0.8$.\n- For action $2$ (shift resources to innovation):\n  - From $s=0$: to $s'=0$ with probability $0.3$, to $s'=1$ with probability $0.7$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.7$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.1$, to $s'=2$ with probability $0.9$.\n\nFor $\\mathsf{P}^{(2)}$ (deterministic policy effects):\n- For action $0$ (allocate resources to reduce backlog): from $s=0$ to $s'=0$ with probability $1.0$, from $s=1$ to $s'=0$ with probability $1.0$, from $s=2$ to $s'=1$ with probability $1.0$.\n- For action $1$ (hold steady): from $s=0$ to $s'=0$ with probability $1.0$, from $s=1$ to $s'=1$ with probability $1.0$, from $s=2$ to $s'=2$ with probability $1.0$.\n- For action $2$ (shift resources to innovation): from $s=0$ to $s'=1$ with probability $1.0$, from $s=1$ to $s'=2$ with probability $1.0$, from $s=2$ to $s'=2$ with probability $1.0$.\n\nCompute an optimal policy via value iteration under a discount factor $\\gamma \\in [0,1)$, using the decision rule that ties in the maximization must be broken by choosing the smallest action index. Let the stopping threshold be $\\varepsilon0$ in the supremum norm on state values, and the maximum iteration cap be $N_{\\max} \\in \\mathbb{N}$. If $\\gamma \\ge 1$, detect non-contraction and, instead of running value iteration, output the myopic policy that maximizes $R(s,a)$ independently in each state, set the iteration count to $0$, and set the convergence flag to boolean false. If $\\gamma \\in [0,1)$ but the algorithm does not meet the stopping threshold by $N_{\\max}$ iterations, output the greedy policy with respect to the last iterate, the actual number of iterations performed, and a boolean false convergence flag.\n\nYour program must implement the above and evaluate the following test suite of parameter values, each specified as $(\\text{kernel}, \\gamma, \\varepsilon, N_{\\max})$:\n- Case $1$: $\\left(\\mathsf{P}^{(1)},\\, 0.9,\\, 10^{-8},\\, 10000\\right)$.\n- Case $2$: $\\left(\\mathsf{P}^{(1)},\\, 0.999,\\, 10^{-12},\\, 20000\\right)$.\n- Case $3$: $\\left(\\mathsf{P}^{(1)},\\, 0.0,\\, 10^{-8},\\, 10000\\right)$.\n- Case $4$: $\\left(\\mathsf{P}^{(2)},\\, 0.95,\\, 10^{-8},\\, 10000\\right)$.\n- Case $5$: $\\left(\\mathsf{P}^{(1)},\\, 1.0,\\, 10^{-8},\\, 10000\\right)$.\n\nFor each case, produce a result list $\\left[a_0,a_1,a_2,n,c\\right]$, where $a_0,a_1,a_2 \\in \\{0,1,2\\}$ are the chosen actions for states $s=0,1,2$, $n \\in \\mathbb{N}$ is the number of iterations actually performed by your procedure (with $n=0$ in the $\\gamma \\ge 1$ myopic case), and $c \\in \\{\\text{True},\\text{False}\\}$ indicates whether your procedure declared convergence according to the stopping criterion. \n\nFinal output format specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the per-case result list, for example, $\\left[\\left[a_0,a_1,a_2,n,c\\right],\\left[\\cdots\\right],\\ldots\\right]$.",
            "solution": "First, we formalize the components of the MDP. The state space is $S=\\{0, 1, 2\\}$, the action space is $A=\\{0, 1, 2\\}$, and the discount factor is $\\gamma$. The immediate reward for taking action $a$ in state $s$ is given by $R(s, a) = r_a + p_s$. We can pre-compute this into a $3 \\times 3$ reward matrix $\\mathbf{R}$:\n$$\n\\mathbf{R}_{s,a} = \\begin{pmatrix} r_0+p_0  r_1+p_0  r_2+p_0 \\\\ r_0+p_1  r_1+p_1  r_2+p_1 \\\\ r_0+p_2  r_1+p_2  r_2+p_2 \\end{pmatrix} = \\begin{pmatrix} -1+0  0+0  2+0 \\\\ -1-2  0-2  2-2 \\\\ -1-5  0-5  2-5 \\end{pmatrix} = \\begin{pmatrix} -1  0  2 \\\\ -3  -2  0 \\\\ -6  -5  -3 \\end{pmatrix}\n$$\nThe transition dynamics are given by probability kernels $\\mathsf{P}(s'|s,a)$, which we represent as a $3 \\times 3 \\times 3$ tensor $\\mathbf{P}$ where $\\mathbf{P}_{s,a,s'} = \\mathsf{P}(s'|s,a)$. Two such tensors, $\\mathbf{P}^{(1)}$ and $\\mathbf{P}^{(2)}$, are constructed based on the problem description.\n\nThe core of the solution is the value iteration algorithm, which finds the optimal value function $V^*(s)$ for an infinite-horizon discounted MDP. The value function represents the maximum expected cumulative discounted reward starting from state $s$. Value iteration is based on the Bellman optimality equation:\n$$\nV^*(s) = \\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V^*(s') \\right)\n$$\nThe algorithm iteratively improves an estimate of the value function, starting with an initial guess $V_0(s)$ (e.g., $V_0(s)=0$ for all $s$). The update rule for iteration $k+1$ is:\n$$\nV_{k+1}(s) = \\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V_k(s') \\right)\n$$\nThis can be expressed more compactly by defining the state-action value function, or Q-function, as $Q_k(s, a) = R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V_k(s')$. Then, the update becomes $V_{k+1}(s) = \\max_{a \\in A} Q_k(s, a)$.\n\nThe iteration continues until the value function converges, which is determined by checking if the supremum norm of the difference between successive value function iterates is below a given threshold $\\varepsilon$:\n$$\n\\max_{s \\in S} |V_{k+1}(s) - V_k(s)|  \\varepsilon\n$$\nThis condition is guaranteed to be met for $\\gamma \\in [0,1)$ because the Bellman operator is a contraction mapping with modulus $\\gamma$.\n\nIf the algorithm is provided with a discount factor $\\gamma \\ge 1$, the Bellman operator is no longer a contraction, and value iteration may not converge. As stipulated, in this case, we do not run the iteration. Instead, we compute a myopic policy $\\pi(s) = \\arg\\max_a R(s,a)$ for each state, set the iteration count to $0$, and report that convergence was not achieved.\n\nIf the algorithm for $\\gamma \\in [0,1)$ fails to converge within the maximum number of iterations $N_{\\max}$, it terminates. The final policy is then the greedy policy with respect to the last computed value function, $V_{N_{\\max}}$.\n\nOnce the value function $V$ has converged (or the iteration limit is reached), the optimal policy $\\pi^*(s)$ is extracted by finding the action that maximizes the Q-function for each state:\n$$\n\\pi^*(s) = \\arg\\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsfP(s'|s,a) V(s') \\right)\n$$\nThe problem specifies that any ties during this maximization must be broken by choosing the action with the smallest index.\n\nThe implementation will use `NumPy` arrays for efficient vectorized computation. The rewards $\\mathbf{R}$ will be a $3 \\times 3$ matrix. The transition kernels $\\mathbf{P}^{(1)}$ and $\\mathbf{P}^{(2)}$ will be $3 \\times 3 \\times 3$ tensors. The value function $V$ will be a vector of size $3$. The term $\\sum_{s'} \\mathsf{P}(s'|s,a) V(s')$ is computed efficiently for all states and actions simultaneously using `numpy.einsum`. The `numpy.argmax` function is used for the maximization steps, as it inherently breaks ties by returning the index of the first occurrence of the maximum value, satisfying the tie-breaking rule. The procedure is applied to each test case, and the results are formatted into a single-line string as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of Markov Decision Process problems using value iteration.\n    \"\"\"\n    \n    # Define MDP components\n    num_states = 3\n    num_actions = 3\n    r = np.array([-1, 0, 2])\n    p = np.array([0, -2, -5])\n    R = r.reshape(1, num_actions) + p.reshape(num_states, 1)\n\n    # Transition Kernel P1 (stochastic)\n    P1 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P1[0, 0, :] = [0.7, 0.3, 0.0]\n    P1[1, 0, :] = [0.6, 0.3, 0.1]\n    P1[2, 0, :] = [0.0, 0.6, 0.4]\n    # Action 1: hold steady\n    P1[0, 1, :] = [0.5, 0.5, 0.0]\n    P1[1, 1, :] = [0.0, 0.6, 0.4]\n    P1[2, 1, :] = [0.0, 0.2, 0.8]\n    # Action 2: innovate\n    P1[0, 2, :] = [0.3, 0.7, 0.0]\n    P1[1, 2, :] = [0.0, 0.3, 0.7]\n    P1[2, 2, :] = [0.0, 0.1, 0.9]\n\n    # Transition Kernel P2 (deterministic)\n    P2 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P2[0, 0, 0] = 1.0\n    P2[1, 0, 0] = 1.0\n    P2[2, 0, 1] = 1.0\n    # Action 1: hold steady\n    P2[0, 1, 0] = 1.0\n    P2[1, 1, 1] = 1.0\n    P2[2, 1, 2] = 1.0\n    # Action 2: innovate\n    P2[0, 2, 1] = 1.0\n    P2[1, 2, 2] = 1.0\n    P2[2, 2, 2] = 1.0\n    \n    kernels = {'P1': P1, 'P2': P2}\n\n    test_cases = [\n        ('P1', 0.9, 1e-8, 10000),\n        ('P1', 0.999, 1e-12, 20000),\n        ('P1', 0.0, 1e-8, 10000),\n        ('P2', 0.95, 1e-8, 10000),\n        ('P1', 1.0, 1e-8, 10000),\n    ]\n\n    def solve_mdp(P, gamma, epsilon, n_max):\n        \"\"\"\n        Implements value iteration for a given MDP.\n        \"\"\"\n        # Case: gamma = 1, non-contraction\n        if gamma = 1:\n            policy = np.argmax(R, axis=1)\n            return [int(policy[0]), int(policy[1]), int(policy[2]), 0, False]\n\n        # Case: gamma  1, value iteration\n        V = np.zeros(num_states)\n        for n in range(1, n_max + 1):\n            V_old = V.copy()\n            Q = R + gamma * np.einsum('ijk,k-ij', P, V_old)\n            V = np.max(Q, axis=1)\n            \n            # Check for convergence\n            if np.max(np.abs(V - V_old))  epsilon:\n                policy = np.argmax(Q, axis=1)\n                return [int(policy[0]), int(policy[1]), int(policy[2]), n, True]\n\n        # Case: did not converge within n_max iterations\n        Q = R + gamma * np.einsum('ijk,k-ij', P, V)\n        policy = np.argmax(Q, axis=1)\n        return [int(policy[0]), int(policy[1]), int(policy[2]), n_max, False]\n\n    all_results = []\n    for kernel_name, gamma, epsilon, n_max in test_cases:\n        P = kernels[kernel_name]\n        result_list = solve_mdp(P, gamma, epsilon, n_max)\n        all_results.append(result_list)\n        \n    # Format the final output string to match the required format without spaces\n    string_results = []\n    for res_list in all_results:\n        inner_str = f\"[{','.join(map(str, res_list))}]\"\n        string_results.append(inner_str)\n    \n    final_output = f\"[{','.join(string_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}