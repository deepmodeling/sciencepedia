{
    "hands_on_practices": [
        {
            "introduction": "组织数字孪生的一个核心前提是能够准确地反映物理实体的状态。本练习将引导您应用控制理论中的一个基本概念——可观测性（observability），来评估一套给定的关键绩效指标（KPIs）是否足以推断组织内部的关键动态。通过这个实践，您将学会如何从数学上判断监控设计的完备性，并理解哪些潜在的组织状态可能被当前的测量手段所“隐藏”。",
            "id": "4214840",
            "problem": "一个组织在某个工作点附近的数字孪生被建模为一个连续时间线性时不变状态空间系统，其状态向量为 $x \\in \\mathbb{R}^{4}$，其中 $x_{1}$ 表示订单积压偏差，$x_{2}$ 表示在制品吞吐量偏差，$x_{3}$ 表示资源容量不平衡，$x_{4}$ 表示潜在的合规风险倾向。输出向量 $y \\in \\mathbb{R}^{2}$ 收集了关键监控指标：一个经过滤波的积压度量和一个综合合规事件信号。围绕该工作点的线性化得到矩阵对 $(A,C)$：\n$$\nA \\;=\\; \\begin{bmatrix}\n-0.3  & 1  & 0  & 0 \\\\\n0  & -0.5  & 1  & 0 \\\\\n0  & 0  & -0.1  & 0 \\\\\n0  & 0  & 0  & -0.2\n\\end{bmatrix}, \n\\qquad\nC \\;=\\; \\begin{bmatrix}\n1  & 0  & 0  & 0 \\\\\n0  & 1  & 1  & 0\n\\end{bmatrix}.\n$$\n从线性时不变系统的可观测性定义出发，并且不使用任何给定的快捷公式，确定与 $(A,C)$ 相关的可观测性矩阵的秩，并解释该秩对数字孪生的监控设计意味着什么（例如，可以或不可以通过现有指标推断出哪些潜在的组织动态）。将秩作为你的最终数值答案。无需四舍五入，秩也不需要物理单位。",
            "solution": "问题要求我们确定由状态空间表示 $(\\dot{x} = Ax, y = Cx)$ 描述的线性时不变 (LTI) 系统的可观测性，并在组织数字孪生的背景下解释研究结果。任务的核心是从可观测性的基本定义出发，计算系统的可观测性矩阵的秩。\n\n如果对于任何未知的初始状态 $x(0) = x_0$，存在一个有限时间 $t_f > 0$，使得在区间 $[0, t_f]$ 内的输入 $u(t)$ 和输出 $y(t)$ 的知识足以唯一确定 $x_0$，则称该 LTI 系统是可观测的。对于一个无输入的系统 ($u(t)=0$)，其状态轨迹由 $x(t) = \\exp(At)x_0$ 给出，输出为 $y(t) = C x(t) = C \\exp(At) x_0$。\n\n一个状态 $x_0$ 是不可观测的，当且仅当对于该初始状态，在所有时间 $t \\ge 0$ 内输出恒为零。即，对于所有 $t \\ge 0$，$y(t) = C \\exp(At) x_0 = \\mathbf{0}$。为了从这个定义中推导出一个可检验的条件，我们可以对输出方程随时间反复求导，并在 $t=0$ 处求值：\n$y(0) = C x_0 = \\mathbf{0}$\n$\\dot{y}(t) = \\frac{d}{dt}(C \\exp(At) x_0) = C A \\exp(At) x_0 \\implies \\dot{y}(0) = C A x_0 = \\mathbf{0}$\n$\\ddot{y}(t) = \\frac{d^2}{dt^2}(C \\exp(At) x_0) = C A^2 \\exp(At) x_0 \\implies \\ddot{y}(0) = C A^2 x_0 = \\mathbf{0}$\n...\n$y^{(k)}(t) = \\frac{d^k}{dt^k}(C \\exp(At) x_0) = C A^k \\exp(At) x_0 \\implies y^{(k)}(0) = C A^k x_0 = \\mathbf{0}$\n\n因此，一个初始状态 $x_0$ 是不可观测的，当且仅当对于所有非负整数 $k$，都有 $C A^k x_0 = \\mathbf{0}$。根据 Cayley-Hamilton 定理，对于 $k \\ge n$（其中 $n$ 是状态向量的维度），任何矩阵的幂 $A^k$ 都可以表示为幂集 $\\{A^0, A^1, \\dots, A^{n-1}\\}$ 的线性组合。因此，该条件简化为只需检查前 $n$ 个这样的方程。这组线性方程可以写成矩阵形式：\n$$\n\\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\n\\vdots \\\\\nCA^{n-1}\n\\end{bmatrix}\nx_0 = \\mathbf{0}\n$$\n该方程中的矩阵是可观测性矩阵，记为 $\\mathcal{O}$。一个非零状态 $x_0$ 如果位于 $\\mathcal{O}$ 的零空间中，则是不可观测的。如果 $\\mathcal{O} x_0 = \\mathbf{0}$ 的唯一解是平凡解 $x_0 = \\mathbf{0}$，则系统是完全可观测的。这等价于可观测性矩阵 $\\mathcal{O}$ 具有满列秩，即 $\\text{rank}(\\mathcal{O}) = n$。\n\n状态维度为 $n=4$。可观测性矩阵为 $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}$。我们已知：\n$$\nA = \\begin{bmatrix}\n-0.3  & 1  & 0  & 0 \\\\\n0  & -0.5  & 1  & 0 \\\\\n0  & 0  & -0.1  & 0 \\\\\n0  & 0  & 0  & -0.2\n\\end{bmatrix}, \n\\qquad\nC = \\begin{bmatrix}\n1  & 0  & 0  & 0 \\\\\n0  & 1  & 1  & 0\n\\end{bmatrix}\n$$\n$\\mathcal{O}$ 的行是 $C, CA, CA^2,$ 和 $CA^3$ 的行。\n首先，我们计算矩阵乘积：\n$C = \\begin{bmatrix} 1  & 0  & 0  & 0 \\\\ 0  & 1  & 1  & 0 \\end{bmatrix}$\n\n$CA = \\begin{bmatrix} 1  & 0  & 0  & 0 \\\\ 0  & 1  & 1  & 0 \\end{bmatrix} \\begin{bmatrix} -0.3  & 1  & 0  & 0 \\\\ 0  & -0.5  & 1  & 0 \\\\ 0  & 0  & -0.1  & 0 \\\\ 0  & 0  & 0  & -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.3  & 1  & 0  & 0 \\\\ 0  & -0.5  & 0.9  & 0 \\end{bmatrix}$\n\n为了计算 $CA^2$，我们先求 $A^2$：\n$A^2 = A \\cdot A = \\begin{bmatrix} -0.3  & 1  & 0  & 0 \\\\ 0  & -0.5  & 1  & 0 \\\\ 0  & 0  & -0.1  & 0 \\\\ 0  & 0  & 0  & -0.2 \\end{bmatrix}^2 = \\begin{bmatrix} 0.09  & -0.8  & 1  & 0 \\\\ 0  & 0.25  & -0.6  & 0 \\\\ 0  & 0  & 0.01  & 0 \\\\ 0  & 0  & 0  & 0.04 \\end{bmatrix}$\n然后，$CA^2 = C \\cdot A^2 = \\begin{bmatrix} 1  & 0  & 0  & 0 \\\\ 0  & 1  & 1  & 0 \\end{bmatrix} \\begin{bmatrix} 0.09  & -0.8  & 1  & 0 \\\\ 0  & 0.25  & -0.6  & 0 \\\\ 0  & 0  & 0.01  & 0 \\\\ 0  & 0  & 0  & 0.04 \\end{bmatrix} = \\begin{bmatrix} 0.09  & -0.8  & 1  & 0 \\\\ 0  & 0.25  & -0.59  & 0 \\end{bmatrix}$\n\n为了计算 $CA^3$，我们先求 $A^3$：\n$A^3 = A \\cdot A^2 = \\begin{bmatrix} -0.3  & 1  & 0  & 0 \\\\ 0  & -0.5  & 1  & 0 \\\\ 0  & 0  & -0.1  & 0 \\\\ 0  & 0  & 0  & -0.2 \\end{bmatrix} \\begin{bmatrix} 0.09  & -0.8  & 1  & 0 \\\\ 0  & 0.25  & -0.6  & 0 \\\\ 0  & 0  & 0.01  & 0 \\\\ 0  & 0  & 0  & 0.04 \\end{bmatrix} = \\begin{bmatrix} -0.027  & 0.49  & -0.9  & 0 \\\\ 0  & -0.125  & 0.31  & 0 \\\\ 0  & 0  & -0.001  & 0 \\\\ 0  & 0  & 0  & -0.008 \\end{bmatrix}$\n然后，$CA^3 = C \\cdot A^3 = \\begin{bmatrix} 1  & 0  & 0  & 0 \\\\ 0  & 1  & 1  & 0 \\end{bmatrix} \\begin{bmatrix} -0.027  & 0.49  & -0.9  & 0 \\\\ 0  & -0.125  & 0.31  & 0 \\\\ 0  & 0  & -0.001  & 0 \\\\ 0  & 0  & 0  & -0.008 \\end{bmatrix} = \\begin{bmatrix} -0.027  & 0.49  & -0.9  & 0 \\\\ 0  & -0.125  & 0.309  & 0 \\end{bmatrix}$\n\n现在我们组装完整的可观测性矩阵 $\\mathcal{O}$：\n$$\n\\mathcal{O} = \\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\nCA^3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1  & 0  & 0  & 0 \\\\\n0  & 1  & 1  & 0 \\\\\n-0.3  & 1  & 0  & 0 \\\\\n0  & -0.5  & 0.9  & 0 \\\\\n0.09  & -0.8  & 1  & 0 \\\\\n0  & 0.25  & -0.59  & 0 \\\\\n-0.027  & 0.49  & -0.9  & 0 \\\\\n0  & -0.125  & 0.309  & 0\n\\end{bmatrix}\n$$\n为了确定这个 $8 \\times 4$ 矩阵的秩，我们分析它的列。第四列完全由零组成。这立即意味着这些列不是线性无关的。具体来说，对于任何非零标量 $\\alpha$，向量 $v = [0, 0, 0, \\alpha]^T$ 都将满足 $\\mathcal{O}v = \\mathbf{0}$。这意味着 $\\mathcal{O}$ 的零空间维度至少为 $1$，因此 $\\mathcal{O}$ 的秩最多为 $4-1=3$。\n\n为了确定秩是否恰好为 $3$，我们必须检查前三列是否线性无关。我们可以通过找到一个行列式不为零的 $3 \\times 3$ 子矩阵来做到这一点。让我们使用 $\\mathcal{O}$ 的前三行和前三列构成一个子矩阵：\n$$\n M = \\begin{bmatrix}\n1  & 0  & 0 \\\\\n0  & 1  & 1 \\\\\n-0.3  & 1  & 0\n\\end{bmatrix}\n$$\n该子矩阵的行列式为：\n$$\n\\det(M) = 1 \\cdot \\det\\begin{pmatrix} 1  & 1 \\\\ 1  & 0 \\end{pmatrix} - 0 + 0 = 1 \\cdot (1 \\cdot 0 - 1 \\cdot 1) = -1\n$$\n由于 $\\det(M) \\neq 0$，$\\mathcal{O}$ 的前三列是线性无关的。因此，可观测性矩阵 $\\mathcal{O}$ 的秩恰好为 $3$。\n\n解释：\n可观测性矩阵的秩为 $3$，小于状态维度 $n=4$。差值 $n - \\text{rank}(\\mathcal{O}) = 4 - 3 = 1$ 表明存在一个一维的不可观测子空间。该子空间内的任何状态向量都无法通过输出测量来确定。\n\n如计算所示，$\\mathcal{O}$ 的零空间由向量 $[0, 0, 0, 1]^T$ 张成。这个向量对应于第四个状态变量 $x_4$，即“潜在的合规风险倾向”。这意味着 $x_4$ 的动态完全与输出 $y$ 解耦。$x_4$ 的初始值或任何后续变化对测量的“经过滤波的积压度量”和“综合合规事件信号”没有影响。\n\n在数字孪生监控设计的背景下，这个结果意味着一个关键缺陷：当前的关键监控指标集不足以跟踪或推断组织的潜在合规风险。与积压 ($x_1$)、吞吐量 ($x_2$) 和资源不平衡 ($x_3$) 相关的动态可以从输出数据中完全重构（因为它们在 $\\mathcal{O}$ 中对应的列是线性无关的）。然而，合规风险倾向 ($x_4$) 仍然是隐藏的。为了使这个状态可观测，监控策略必须增加新的、明确或隐含地依赖于 $x_4$ 的指标。",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "一个精确的数字孪生模型是有效决策的基础，但这依赖于对模型参数的深刻理解。本练习将带您进入全局敏感性分析（Global Sensitivity Analysis）的领域，特别是使用基于方差的Sobol指数来量化模型参数对输出不确定性的贡献。通过编程实现Saltelli估计器，您将掌握一种识别关键驱动因素的强大技术，从而为模型校准和数据采集工作确定优先级。",
            "id": "4214862",
            "problem": "您正在为一个组织建立数字孪生模型，其中关键绩效指标 (KPI) 是模型参数经过确定性转换后产生的。您的任务是实现一个程序，该程序使用一阶索博尔指数执行基于方差的全局敏感性分析，然后为每个测试用例生成参数的校准优先级排序。该程序必须是自包含且确定性的。\n\n基本原理和定义：\n- 使用全方差定律及相关的方差分析 (ANOVA) 分解。对于一个具有独立分量 $\\mathbf{X} = (X_1,\\dots,X_d)$ 的标量KPI随机变量 $Y = f(\\mathbf{X})$，总方差可分解为\n$$\n\\mathrm{Var}(Y) = \\sum_{i=1}^{d} V_i + \\sum_{i<j} V_{ij} + \\dots + V_{1\\dots d}\n$$\n其中 $V_i = \\mathrm{Var}_{X_i}\\left(\\mathbb{E}_{X_{\\sim i}}[Y|X_i]\\right)$ 是由参数 $X_i$ 的主效应引起的方差。\n- 一阶索博尔指数 $S_i$ 定义为 $S_i = \\frac{V_i}{\\mathrm{Var}(Y)}$。\n\n您的任务是使用 Saltelli 估计器来实现一个计算一阶索博尔指数 $S_i$ 的函数。然后，基于这些指数和参数的不确定性范围，为每个测试用例生成一个校准优先级排序。\n\n**校准优先级**：参数 $X_i$ 的校准优先级分数 $P_i$ 定义为其对所有 $m$ 个 KPI 的总敏感度之和，并根据其不确定性范围的相对宽度进行加权： $P_i = \\left(\\sum_{k=1}^m S_{i,k}\\right) \\frac{w_i}{\\sum_{j=1}^d w_j}$，其中 $w_i = b_i - a_i$ 是参数 $X_i$ 的不确定性区间的宽度。参数按 $P_i$ 降序排序；平局则按参数索引升序解决。\n\n该程序必须应用于三个测试用例，并为每个案例输出参数的优先级排序列表。",
            "solution": "解决方案实现了基于 Saltelli 采样的蒙特卡洛方法来估计一阶索博尔指数。这种方法因其计算效率而备受青睐。\n\n**方法论**：\n1.  **采样**：为 $d$ 个输入参数生成两个独立的 $N \\times d$ 样本矩阵 $\\mathbf{A}$ 和 $\\mathbf{B}$，其中 $N$ 是基本样本量。这些样本在单位超立方体中均匀采样，然后通过仿射变换缩放到其各自的参数边界。\n2.  **模型评估**：对样本矩阵 $\\mathbf{A}$ 和 $\\mathbf{B}$ 评估模型函数 $f$，得到输出 $\\mathbf{y}_A = f(\\mathbf{A})$ 和 $\\mathbf{y}_B = f(\\mathbf{B})$。\n3.  **构造条件样本**：对于每个参数 $X_i$，构造一个新的样本矩阵 $\\mathbf{A}_{B}^{(i)}$，它与 $\\mathbf{A}$ 相同，只是第 $i$ 列被替换为 $\\mathbf{B}$ 的第 $i$ 列。然后评估模型得到 $\\mathbf{y}_{AB}^{(i)} = f(\\mathbf{A}_{B}^{(i)})$。\n4.  **指数估计**：使用以下 Saltelli 估计器计算总方差 $\\mathrm{Var}(Y)$ 和一阶效应 $V_i$：\n    -   $\\mathrm{Var}(Y)$ 使用 $\\mathbf{y}_A$ 和 $\\mathbf{y}_B$ 的合并样本进行估计，以提高准确性。\n    -   $V_i$ 的估计量为 $\\frac{1}{N} \\sum_{j=1}^{N} \\mathbf{y}_{B,j} \\cdot (\\mathbf{y}_{AB,j}^{(i)} - \\mathbf{y}_{A,j})$。\n    -   一阶索博尔指数为 $S_i = V_i / \\mathrm{Var}(Y)$。\n5.  **优先级排序**：根据问题中定义的公式计算每个参数的优先级分数 $P_i$，并据此对参数进行排序。\n\n该方法应用于提供的三个具有不同模型函数和参数边界的测试用例，以确定每个案例中参数的相对重要性。",
            "answer": "```python\nimport numpy as np\n\ndef saltelli_first_order_indices(f, bounds, N, seed):\n    \"\"\"\n    Compute first-order Sobol indices for a vector-valued function f: R^d -> R^m\n    using the Saltelli estimator with N base samples and a fixed seed.\n    - f expects an array of shape (n_samples, d) and returns shape (n_samples, m).\n    - bounds is a list of (a_i, b_i) for i=0..d-1.\n    Returns:\n        S: array of shape (d, m) with first-order indices per parameter per KPI.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    d = len(bounds)\n    # Sample in unit cube\n    A_unit = rng.random((N, d))\n    B_unit = rng.random((N, d))\n\n    # Affine transform to actual bounds\n    a = np.array([lo for lo, hi in bounds])\n    b = np.array([hi for lo, hi in bounds])\n    widths = b - a\n\n    A = a + A_unit * widths\n    B = a + B_unit * widths\n\n    YA = f(A)  # shape (N, m)\n    YB = f(B)  # shape (N, m)\n    N, m = YA.shape\n\n    # Variance estimate using pooled samples\n    Y_concat = np.vstack([YA, YB])  # (2N, m)\n    Y_mean = np.mean(Y_concat, axis=0)\n    # Unbiased sample variance with ddof=1\n    varY = np.var(Y_concat, axis=0, ddof=1)  # shape (m,)\n\n    S = np.zeros((d, m), dtype=float)\n\n    # For each parameter, build A_Bi and evaluate\n    for i in range(d):\n        ABi = A.copy()\n        ABi[:, i] = B[:, i]\n        YABi = f(ABi)  # (N, m)\n\n        # Saltelli first-order estimator:\n        # S_i = mean( YB * (YABi - YA) ) / Var(Y)\n        numer = np.mean(YB * (YABi - YA), axis=0)  # (m,)\n        # Handle zero variance robustly\n        with np.errstate(invalid='ignore', divide='ignore'):\n            Si = np.where(varY > 0.0, numer / varY, 0.0)\n        # Numerical guard: clip to [0,1]\n        Si = np.clip(Si, 0.0, 1.0)\n        S[i, :] = Si\n\n    return S, widths\n\n# Define the test case models\ndef model_case_1(X):\n    \"\"\"\n    X: (n,3) with columns p1, p2, p3\n    KPIs:\n      Y1 = 2*p1 + p2^2 + 0.5*p3\n      Y2 = p1*p3 + 0.2*p2\n    \"\"\"\n    p1 = X[:, 0]\n    p2 = X[:, 1]\n    p3 = X[:, 2]\n    Y1 = 2.0 * p1 + p2**2 + 0.5 * p3\n    Y2 = p1 * p3 + 0.2 * p2\n    return np.column_stack([Y1, Y2])\n\ndef model_case_2(X):\n    \"\"\"\n    X: (n,4) with columns p1, p2, p3, p4\n    KPIs:\n      Y1 = sin(pi*p1) + p2^2\n      Y2 = exp(-p3) + 0.1*p1 + 0.0*p4\n    Angles in radians.\n    \"\"\"\n    p1 = X[:, 0]\n    p2 = X[:, 1]\n    p3 = X[:, 2]\n    p4 = X[:, 3]\n    Y1 = np.sin(np.pi * p1) + p2**2\n    Y2 = np.exp(-p3) + 0.1 * p1 + 0.0 * p4\n    return np.column_stack([Y1, Y2])\n\ndef model_case_3(X):\n    \"\"\"\n    X: (n,2) with columns p1, p2\n    KPIs:\n      Y1 = 3 (constant)\n      Y2 = p1\n    \"\"\"\n    p1 = X[:, 0]\n    # p2 = X[:, 1]  # unused\n    Y1 = np.full_like(p1, 3.0)\n    Y2 = p1\n    return np.column_stack([Y1, Y2])\n\ndef prioritize(S, widths):\n    \"\"\"\n    Compute calibration priority ranking indices given first-order indices S (d x m)\n    and parameter widths (d,). Priority score P_i = (sum_k S_i,k) * (width_i / sum_j width_j).\n    Return list of indices sorted descending by P_i, ties broken by lower index.\n    \"\"\"\n    d, m = S.shape\n    width_sum = np.sum(widths)\n    if width_sum == 0.0:\n        wnorm = np.ones_like(widths) / max(len(widths), 1)\n    else:\n        wnorm = widths / width_sum\n    P = np.sum(S, axis=1) * wnorm\n    # Sort by (-P_i, i)\n    order = sorted(range(d), key=lambda i: (-P[i], i))\n    return order\n\ndef solve():\n    N = 8000\n    seed = 12345\n\n    test_cases = [\n        # Each case: (model_function, bounds)\n        (model_case_1, [(0.5, 1.5), (0.0, 2.0), (0.0, 1.0)]),\n        (model_case_2, [(0.0, 1.0), (0.0, 1.0), (0.0, 2.0), (0.0, 1.0)]),\n        (model_case_3, [(0.0, 1.0), (0.0, 1.0)]),\n    ]\n\n    results = []\n    # To keep reproducibility per case, vary seed deterministically\n    for case_index, (model, bounds) in enumerate(test_cases):\n        S, widths = saltelli_first_order_indices(model, bounds, N, seed + case_index)\n        order = prioritize(S, widths)\n        results.append(order)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([str(lst) for lst in results])}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "组织数字孪生的最终价值体现在其支持或自动化复杂决策的能力上。本练习将一个典型的组织资源分配问题建模为马尔可夫决策过程（Markov Decision Process, MDP），并要求您通过价值迭代算法来求解最优策略。这个实践将让您亲身体验如何在一个不确定的、动态的环境中，利用动态规划来寻找能够最大化长期回报的行动序列，这是构建智能决策支持系统的核心环节。",
            "id": "4214863",
            "problem": "一个组织的数字孪生模型用于在不确定性下对粗粒度的积压状态进行决策建模。考虑一个具有折扣无限期回报的有限马尔可夫决策过程（MDP），其状态空间为 $S=\\{0,1,2\\}$，代表组织的积压水平：$0$（低）、$1$（中）和 $2$（高）。动作空间为 $A=\\{0,1,2\\}$，代表 $0$（分配资源以减少积压）、$1$（保持稳定）和 $2$（将资源转向创新）。即时奖励由 $R(s,a)=r_a + p_s$ 定义，其中 $r_a$ 是与动作相关的即时奖励，$p_s$ 是与积压相关的惩罚。假设 $r_0=-1$、$r_1=0$、$r_2=2$，以及 $p_0=0$、$p_1=-2$、$p_2=-5$。\n\n转移由两个核之一指定，即 $\\mathsf{P}^{(1)}$ 和 $\\mathsf{P}^{(2)}$，两者都将 $S \\times A$ 映射到 $S$ 上的分布。对于 $\\mathsf{P}^{(1)}$（随机运营动态）：\n- 对于动作 $0$（分配资源以减少积压）：\n  - 从 $s=0$：以概率 $0.7$ 转移到 $s'=0$，以概率 $0.3$ 转移到 $s'=1$，以概率 $0.0$ 转移到 $s'=2$。\n  - 从 $s=1$：以概率 $0.6$ 转移到 $s'=0$，以概率 $0.3$ 转移到 $s'=1$，以概率 $0.1$ 转移到 $s'=2$。\n  - 从 $s=2$：以概率 $0.0$ 转移到 $s'=0$，以概率 $0.6$ 转移到 $s'=1$，以概率 $0.4$ 转移到 $s'=2$。\n- 对于动作 $1$（保持稳定）：\n  - 从 $s=0$：以概率 $0.5$ 转移到 $s'=0$，以概率 $0.5$ 转移到 $s'=1$，以概率 $0.0$ 转移到 $s'=2$。\n  - 从 $s=1$：以概率 $0.0$ 转移到 $s'=0$，以概率 $0.6$ 转移到 $s'=1$，以概率 $0.4$ 转移到 $s'=2$。\n  - 从 $s=2$：以概率 $0.0$ 转移到 $s'=0$，以概率 $0.2$ 转移到 $s'=1$，以概率 $0.8$ 转移到 $s'=2$。\n- 对于动作 $2$（将资源转向创新）：\n  - 从 $s=0$：以概率 $0.3$ 转移到 $s'=0$，以概率 $0.7$ 转移到 $s'=1$，以概率 $0.0$ 转移到 $s'=2$。\n  - 从 $s=1$：以概率 $0.0$ 转移到 $s'=0$，以概率 $0.3$ 转移到 $s'=1$，以概率 $0.7$ 转移到 $s'=2$。\n  - 从 $s=2$：以概率 $0.0$ 转移到 $s'=0$，以概率 $0.1$ 转移到 $s'=1$，以概率 $0.9$ 转移到 $s'=2$。\n\n对于 $\\mathsf{P}^{(2)}$（确定性策略效应）：\n- 对于动作 $0$（分配资源以减少积压）：从 $s=0$ 以概率 $1.0$ 转移到 $s'=0$，从 $s=1$ 以概率 $1.0$ 转移到 $s'=0$，从 $s=2$ 以概率 $1.0$ 转移到 $s'=1$。\n- 对于动作 $1$（保持稳定）：从 $s=0$ 以概率 $1.0$ 转移到 $s'=0$，从 $s=1$ 以概率 $1.0$ 转移到 $s'=1$，从 $s=2$ 以概率 $1.0$ 转移到 $s'=2$。\n- 对于动作 $2$（将资源转向创新）：从 $s=0$ 以概率 $1.0$ 转移到 $s'=1$，从 $s=1$ 以概率 $1.0$ 转移到 $s'=2$，从 $s=2$ 以概率 $1.0$ 转移到 $s'=2$。\n\n在折扣因子 $\\gamma \\in [0,1)$ 下，通过价值迭代计算最优策略，决策规则规定最大化过程中的平局必须通过选择最小的动作索引来解决。设状态值上确界范数下的停止阈值为 $\\varepsilon>0$，最大迭代次数上限为 $N_{\\max} \\in \\mathbb{N}$。如果 $\\gamma \\ge 1$，则检测非收缩性，并且不运行价值迭代，而是输出在每个状态下独立最大化 $R(s,a)$ 的短视策略，将迭代次数设为 $0$，并将收敛标志设为布尔值 false。如果 $\\gamma \\in [0,1)$ 但算法在 $N_{\\max}$ 次迭代内未达到停止阈值，则输出相对于最后一次迭代的贪心策略、实际执行的迭代次数以及一个布尔值 false 的收敛标志。\n\n您的程序必须实现上述内容，并评估以下参数值测试套件，每个套件指定为 $(\\text{kernel}, \\gamma, \\varepsilon, N_{\\max})$：\n- 案例 1：$\\left(\\mathsf{P}^{(1)},\\, 0.9,\\, 10^{-8},\\, 10000\\right)$。\n- 案例 2：$\\left(\\mathsf{P}^{(1)},\\, 0.999,\\, 10^{-12},\\, 20000\\right)$。\n- 案例 3：$\\left(\\mathsf{P}^{(1)},\\, 0.0,\\, 10^{-8},\\, 10000\\right)$。\n- 案例 4：$\\left(\\mathsf{P}^{(2)},\\, 0.95,\\, 10^{-8},\\, 10000\\right)$。\n- 案例 5：$\\left(\\mathsf{P}^{(1)},\\, 1.0,\\, 10^{-8},\\, 10000\\right)$。\n\n对于每个案例，生成一个结果列表 $\\left[a_0,a_1,a_2,n,c\\right]$，其中 $a_0,a_1,a_2 \\in \\{0,1,2\\}$ 是为状态 $s=0,1,2$ 选择的动作，$n \\in \\mathbb{N}$ 是您的程序实际执行的迭代次数（在 $\\gamma \\ge 1$ 的短视情况下 $n=0$），$c \\in \\{\\text{True},\\text{False}\\}$ 表示您的程序是否根据停止准则声明收敛。\n\n最终输出格式规范：您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表用方括号括起来，其中每个元素是每个案例的结果列表，例如 $\\left[\\left[a_0,a_1,a_2,n,c\\right],\\left[\\cdots\\right],\\ldots\\right]$。",
            "solution": "该问题要求我们通过价值迭代算法求解一个有限马尔可夫决策过程（MDP）的最优策略。该算法旨在找到一个策略，以最大化从每个状态开始的期望累积折扣奖励。\n\n**1. MDP形式化**\n首先，我们定义MDP的组成部分：\n-   **状态空间** $S = \\{0, 1, 2\\}$\n-   **动作空间** $A = \\{0, 1, 2\\}$\n-   **折扣因子** $\\gamma$\n-   **奖励函数** $R(s, a) = r_a + p_s$。我们可以将其预计算为一个 $3 \\times 3$ 的奖励矩阵 $\\mathbf{R}$：\n   $$ \\mathbf{R} = \\begin{pmatrix} -1 & 0 & 2 \\\\ -3 & -2 & 0 \\\\ -6 & -5 & -3 \\end{pmatrix} $$\n-   **转移概率** $\\mathsf{P}(s'|s,a)$ 由两个核 $\\mathbf{P}^{(1)}$ 和 $\\mathbf{P}^{(2)}$ 中的一个给出，它们是 $3 \\times 3 \\times 3$ 的张量。\n\n**2. 价值迭代算法**\n价值迭代基于贝尔曼最优方程，通过迭代更新价值函数 $V(s)$ 来找到最优值 $V^*(s)$：\n$$ V_{k+1}(s) = \\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V_k(s') \\right) $$\n算法从一个初始价值函数（例如，全零向量）开始。在每次迭代中，我们计算所有状态-动作对的Q值 $Q(s, a) = R(s, a) + \\gamma \\sum_{s'} \\mathsf{P}(s'|s,a) V_k(s')$，然后将新的价值函数更新为 $V_{k+1}(s) = \\max_a Q(s, a)$。\n\n**3. 终止与策略提取**\n迭代持续进行，直到价值函数收敛，即连续两次迭代之间的最大差值小于阈值 $\\varepsilon$：$\\max_s |V_{k+1}(s) - V_k(s)| < \\varepsilon$。\n如果算法在 $N_{\\max}$ 次迭代内未收敛，或者如果折扣因子 $\\gamma \\ge 1$（此时算法不收敛），则遵循问题中指定的特殊规则。\n一旦价值函数收敛到 $V^*$，最优策略 $\\pi^*(s)$ 通过为每个状态选择最大化Q值的动作来提取：\n$$ \\pi^*(s) = \\arg\\max_{a \\in A} Q^*(s, a) $$\n平局根据规则通过选择索引最小的动作来解决。\n\n该程序将为每个测试用例执行此过程，并记录最优策略、迭代次数和收敛状态。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of Markov Decision Process problems using value iteration.\n    \"\"\"\n    \n    # Define MDP components\n    num_states = 3\n    num_actions = 3\n    r = np.array([-1, 0, 2])\n    p = np.array([0, -2, -5])\n    R = r.reshape(1, num_actions) + p.reshape(num_states, 1)\n\n    # Transition Kernel P1 (stochastic)\n    P1 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P1[0, 0, :] = [0.7, 0.3, 0.0]\n    P1[1, 0, :] = [0.6, 0.3, 0.1]\n    P1[2, 0, :] = [0.0, 0.6, 0.4]\n    # Action 1: hold steady\n    P1[0, 1, :] = [0.5, 0.5, 0.0]\n    P1[1, 1, :] = [0.0, 0.6, 0.4]\n    P1[2, 1, :] = [0.0, 0.2, 0.8]\n    # Action 2: innovate\n    P1[0, 2, :] = [0.3, 0.7, 0.0]\n    P1[1, 2, :] = [0.0, 0.3, 0.7]\n    P1[2, 2, :] = [0.0, 0.1, 0.9]\n\n    # Transition Kernel P2 (deterministic)\n    P2 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P2[0, 0, 0] = 1.0\n    P2[1, 0, 0] = 1.0\n    P2[2, 0, 1] = 1.0\n    # Action 1: hold steady\n    P2[0, 1, 0] = 1.0\n    P2[1, 1, 1] = 1.0\n    P2[2, 1, 2] = 1.0\n    # Action 2: innovate\n    P2[0, 2, 1] = 1.0\n    P2[1, 2, 2] = 1.0\n    P2[2, 2, 2] = 1.0\n    \n    kernels = {'P1': P1, 'P2': P2}\n\n    test_cases = [\n        ('P1', 0.9, 1e-8, 10000),\n        ('P1', 0.999, 1e-12, 20000),\n        ('P1', 0.0, 1e-8, 10000),\n        ('P2', 0.95, 1e-8, 10000),\n        ('P1', 1.0, 1e-8, 10000),\n    ]\n\n    def solve_mdp(P, gamma, epsilon, n_max):\n        \"\"\"\n        Implements value iteration for a given MDP.\n        \"\"\"\n        # Case: gamma >= 1, non-contraction\n        if gamma >= 1:\n            policy = np.argmax(R, axis=1)\n            return [int(policy[0]), int(policy[1]), int(policy[2]), 0, False]\n\n        # Case: gamma < 1, value iteration\n        V = np.zeros(num_states)\n        for n in range(1, n_max + 1):\n            V_old = V.copy()\n            Q = R + gamma * np.einsum('ijk,k->ij', P, V_old)\n            V = np.max(Q, axis=1)\n            \n            # Check for convergence\n            if np.max(np.abs(V - V_old)) < epsilon:\n                policy = np.argmax(Q, axis=1)\n                return [int(policy[0]), int(policy[1]), int(policy[2]), n, True]\n\n        # Case: did not converge within n_max iterations\n        Q = R + gamma * np.einsum('ijk,k->ij', P, V)\n        policy = np.argmax(Q, axis=1)\n        return [int(policy[0]), int(policy[1]), int(policy[2]), n_max, False]\n\n    all_results = []\n    for kernel_name, gamma, epsilon, n_max in test_cases:\n        P = kernels[kernel_name]\n        result_list = solve_mdp(P, gamma, epsilon, n_max)\n        all_results.append(result_list)\n        \n    # Format the final output string to match the required format without spaces\n    string_results = []\n    for res_list in all_results:\n        inner_str = f\"[{','.join(map(str, res_list))}]\"\n        string_results.append(inner_str)\n    \n    final_output = f\"[{','.join(string_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}