{
    "hands_on_practices": [
        {
            "introduction": "A primary function of data lineage is to trace a downstream artifact back to its upstream sources. This practice explores the fundamental mathematical condition for perfect traceability: the invertibility of the data transformation. By analyzing a common pipeline involving linear mixing and quantization, you will determine when an upstream state can be uniquely recovered, providing a crucial distinction between lossless operations that preserve lineage and lossy ones that permanently obscure it .",
            "id": "4212505",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) maintains data provenance and lineage by recording how upstream artifacts are transformed into downstream artifacts through a deterministic pipeline. Consider an upstream artifact represented by a state vector $\\mathbf{x} \\in \\mathbb{R}^{3}$ and a downstream artifact $\\mathbf{y} \\in \\mathbb{R}^{3}$ produced by the transformation\n$$\n\\mathbf{y} \\;=\\; T_{\\lambda,\\delta}(\\mathbf{x}) \\;=\\; Q_{\\delta}\\!\\left(A_{\\lambda}\\,\\mathbf{x}\\right),\n$$\nwhere $A_{\\lambda} \\in \\mathbb{R}^{3 \\times 3}$ is a linear inter-sensor mixing operator parameterized by $\\,\\lambda \\in \\mathbb{R}\\,$,\n$$\nA_{\\lambda} \\;=\\;\n\\begin{pmatrix}\n1 & \\lambda & 0 \\\\\n0 & 1 & \\lambda \\\\\n\\lambda & 0 & 1\n\\end{pmatrix},\n$$\nand $Q_{\\delta}:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}$ is a componentwise quantizer with step size $\\,\\delta \\ge 0\\,$, defined by $\\,Q_{\\delta}(\\mathbf{z}) = (q_{\\delta}(z_{1}),q_{\\delta}(z_{2}),q_{\\delta}(z_{3}))\\,$ and $\\,q_{\\delta}(z)$ equal to the nearest multiple of $\\delta$ to $z$ (when $\\delta=0$, take $Q_{0}$ to be the identity map).\n\nGround your reasoning in the core definitions of injectivity, surjectivity, and bijectivity, together with well-tested facts from linear algebra about invertibility of linear operators. Derive conditions on $\\lambda$ and $\\delta$ under which $T_{\\lambda,\\delta}$ is invertible, and construct an explicit inverse that recovers upstream artifacts from downstream artifacts under those conditions. Then, assuming the transformation is invertible, derive a closed-form expression for the second upstream component $x_{2}$ in terms of the observed downstream components $y_{1}, y_{2}, y_{3}$ and $\\lambda$.\n\nFinally, evaluate $x_{2}$ when $\\lambda = \\tfrac{1}{2}$, $\\delta = 0$, and $\\mathbf{y} = (2,\\,3,\\,4)^{\\top}$. Round your numerical answer to four significant figures. Express your final numerical answer without units.",
            "solution": "The problem requires an analysis of the invertibility of a transformation $T_{\\lambda,\\delta}$ that models a process in a Cyber-Physical System. The transformation maps an upstream artifact $\\mathbf{x} \\in \\mathbb{R}^{3}$ to a downstream artifact $\\mathbf{y} \\in \\mathbb{R}^{3}$ according to the equation $\\mathbf{y} = T_{\\lambda,\\delta}(\\mathbf{x})$. The transformation is a composition of two operations: a linear mixing $A_{\\lambda}$ and a component-wise quantization $Q_{\\delta}$. Specifically, $T_{\\lambda,\\delta}(\\mathbf{x}) = Q_{\\delta}(A_{\\lambda}\\,\\mathbf{x})$.\n\nFirst, we must determine the conditions under which the transformation $T_{\\lambda,\\delta}: \\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ is invertible. A function is invertible if and only if it is bijective, meaning it must be both injective (one-to-one) and surjective (onto). The transformation $T_{\\lambda,\\delta}$ is a composition of two functions, $A_{\\lambda}$ and $Q_{\\delta}$. For the composition to be invertible, both constituent functions must be invertible over their respective domains and codomains in the chain of operations.\n\nLet's analyze the quantization operator $Q_{\\delta}$. It is defined component-wise by the function $q_{\\delta}(z)$, which maps a real number $z$ to the nearest multiple of a step size $\\delta \\ge 0$.\nIf $\\delta > 0$, the range of $q_{\\delta}$ is the set of all integer multiples of $\\delta$, i.e., $\\{k\\delta \\mid k \\in \\mathbb{Z}\\}$. This is a discrete, countable set.\n1.  Injectivity: For any $\\delta > 0$, $q_{\\delta}$ is not injective. For example, all values of $z$ in the interval $[-\\frac{\\delta}{2}, \\frac{\\delta}{2})$ are mapped to the same output value, $0$. Since a single output value corresponds to multiple input values, the function is not injective. Consequently, the vector-valued function $Q_{\\delta}$ is not injective for $\\delta > 0$.\n2.  Surjectivity: The codomain of $q_{\\delta}$ as a function from $\\mathbb{R}$ to $\\mathbb{R}$ is $\\mathbb{R}$, but its image (the set of actual output values) is the discrete set $\\{k\\delta \\mid k \\in \\mathbb{Z}\\}$. Since the image is not equal to the codomain, $q_{\\delta}$ is not surjective. Consequently, $Q_{\\delta}$ is not surjective onto $\\mathbb{R}^{3}$.\n\nSince $Q_{\\delta}$ is neither injective nor surjective for any $\\delta > 0$, it is not bijective, and therefore not invertible. This implies that the composite transformation $T_{\\lambda,\\delta}$ cannot be invertible if $\\delta > 0$, as information is irrecoverably lost during the quantization step.\n\nThe problem statement specifies that when $\\delta = 0$, $Q_{0}$ is the identity map. The identity map, $Q_{0}(\\mathbf{z}) = \\mathbf{z}$, is bijective. Thus, a necessary condition for $T_{\\lambda,\\delta}$ to be invertible is $\\delta = 0$.\n\nWith $\\delta = 0$, the transformation simplifies to a purely linear transformation:\n$$ T_{\\lambda,0}(\\mathbf{x}) = A_{\\lambda}\\mathbf{x} $$\nwhere $A_{\\lambda}$ is the matrix:\n$$ A_{\\lambda} \\;=\\; \\begin{pmatrix} 1 & \\lambda & 0 \\\\ 0 & 1 & \\lambda \\\\ \\lambda & 0 & 1 \\end{pmatrix} $$\nA linear transformation represented by a square matrix is invertible if and only if the matrix is invertible. A matrix is invertible if and only if its determinant is non-zero. We calculate the determinant of $A_{\\lambda}$:\n$$ \\det(A_{\\lambda}) = 1 \\begin{vmatrix} 1 & \\lambda \\\\ 0 & 1 \\end{vmatrix} - \\lambda \\begin{vmatrix} 0 & \\lambda \\\\ \\lambda & 1 \\end{vmatrix} + 0 \\begin{vmatrix} 0 & 1 \\\\ \\lambda & 0 \\end{vmatrix} $$\n$$ \\det(A_{\\lambda}) = 1(1 \\cdot 1 - \\lambda \\cdot 0) - \\lambda(0 \\cdot 1 - \\lambda \\cdot \\lambda) + 0 $$\n$$ \\det(A_{\\lambda}) = 1 - \\lambda(-\\lambda^2) = 1 + \\lambda^3 $$\nFor $A_{\\lambda}$ to be invertible, we must have $\\det(A_{\\lambda}) \\neq 0$, which implies $1 + \\lambda^3 \\neq 0$. For real $\\lambda$, this condition is $\\lambda^3 \\neq -1$, which simplifies to $\\lambda \\neq -1$.\n\nCombining our findings, the transformation $T_{\\lambda,\\delta}$ is invertible if and only if $\\delta = 0$ and $\\lambda \\neq -1$.\n\nUnder these conditions, the inverse transformation $T_{\\lambda,0}^{-1}$ is given by $\\mathbf{x} = A_{\\lambda}^{-1}\\mathbf{y}$. We construct the inverse matrix $A_{\\lambda}^{-1}$ using the formula $A_{\\lambda}^{-1} = \\frac{1}{\\det(A_{\\lambda})}\\text{adj}(A_{\\lambda})$, where $\\text{adj}(A_{\\lambda})$ is the adjugate of $A_{\\lambda}$. The adjugate is the transpose of the cofactor matrix.\nThe cofactor matrix $C$ of $A_{\\lambda}$ is:\n$$ C = \\begin{pmatrix} \\begin{vmatrix} 1 & \\lambda \\\\ 0 & 1 \\end{vmatrix} & -\\begin{vmatrix} 0 & \\lambda \\\\ \\lambda & 1 \\end{vmatrix} & \\begin{vmatrix} 0 & 1 \\\\ \\lambda & 0 \\end{vmatrix} \\\\ -\\begin{vmatrix} \\lambda & 0 \\\\ 0 & 1 \\end{vmatrix} & \\begin{vmatrix} 1 & 0 \\\\ \\lambda & 1 \\end{vmatrix} & -\\begin{vmatrix} 1 & \\lambda \\\\ \\lambda & 0 \\end{vmatrix} \\\\ \\begin{vmatrix} \\lambda & 0 \\\\ 1 & \\lambda \\end{vmatrix} & -\\begin{vmatrix} 1 & 0 \\\\ 0 & \\lambda \\end{vmatrix} & \\begin{vmatrix} 1 & \\lambda \\\\ 0 & 1 \\end{vmatrix} \\end{pmatrix} = \\begin{pmatrix} 1 & \\lambda^2 & -\\lambda \\\\ -\\lambda & 1 & \\lambda^2 \\\\ \\lambda^2 & -\\lambda & 1 \\end{pmatrix} $$\nThe adjugate matrix is the transpose of $C$:\n$$ \\text{adj}(A_{\\lambda}) = C^{\\top} = \\begin{pmatrix} 1 & -\\lambda & \\lambda^2 \\\\ \\lambda^2 & 1 & -\\lambda \\\\ -\\lambda & \\lambda^2 & 1 \\end{pmatrix} $$\nThe inverse matrix is therefore:\n$$ A_{\\lambda}^{-1} = \\frac{1}{1+\\lambda^3} \\begin{pmatrix} 1 & -\\lambda & \\lambda^2 \\\\ \\lambda^2 & 1 & -\\lambda \\\\ -\\lambda & \\lambda^2 & 1 \\end{pmatrix} $$\nThe explicit inverse transformation is $T_{\\lambda,0}^{-1}(\\mathbf{y}) = A_{\\lambda}^{-1}\\mathbf{y}$.\n\nNext, we derive the closed-form expression for the second upstream component, $x_2$. We use the relation $\\mathbf{x} = A_{\\lambda}^{-1}\\mathbf{y}$:\n$$ \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\frac{1}{1+\\lambda^3} \\begin{pmatrix} 1 & -\\lambda & \\lambda^2 \\\\ \\lambda^2 & 1 & -\\lambda \\\\ -\\lambda & \\lambda^2 & 1 \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix} $$\nExtracting the expression for $x_2$ from the second row of the matrix-vector product:\n$$ x_2 = \\frac{1}{1+\\lambda^3} (\\lambda^2 y_1 + y_2 - \\lambda y_3) $$\nThis is the required closed-form expression, valid under the assumption of invertibility (i.e., $\\delta = 0$ and $\\lambda \\neq -1$).\n\nFinally, we evaluate $x_2$ for the given values: $\\lambda = \\frac{1}{2}$, $\\delta = 0$, and $\\mathbf{y} = (2, 3, 4)^{\\top}$. The values $\\delta = 0$ and $\\lambda = \\frac{1}{2} \\neq -1$ satisfy the conditions for invertibility. The components of $\\mathbf{y}$ are $y_1=2$, $y_2=3$, and $y_3=4$.\nWe substitute these values into the expression for $x_2$:\nThe denominator is $1 + \\lambda^3 = 1 + (\\frac{1}{2})^3 = 1 + \\frac{1}{8} = \\frac{9}{8}$.\nThe numerator term is $\\lambda^2 y_1 + y_2 - \\lambda y_3$:\n$$ \\left(\\frac{1}{2}\\right)^2 (2) + (3) - \\left(\\frac{1}{2}\\right) (4) = \\left(\\frac{1}{4}\\right)(2) + 3 - 2 = \\frac{1}{2} + 1 = \\frac{3}{2} $$\nNow, we compute $x_2$:\n$$ x_2 = \\frac{3/2}{9/8} = \\frac{3}{2} \\times \\frac{8}{9} = \\frac{24}{18} = \\frac{4}{3} $$\nAs a decimal, $x_2 = 1.3333\\dots$. Rounding to four significant figures gives $1.333$.",
            "answer": "$$\\boxed{1.333}$$"
        },
        {
            "introduction": "In distributed cyber-physical systems, network delays and clock drift often lead to recorded timestamps that violate the true causal order of events. This exercise tackles the critical task of repairing the provenance record to ensure its consistency with physical reality. You will apply the 'happened-before' principle to a provenance graph and calculate the minimal temporal adjustments required to restore a valid causal chain, a core skill for building trustworthy digital twins .",
            "id": "4212529",
            "problem": "A cyber-physical system (CPS) with a digital twin performs a pipeline of data ingestion and actuation. The provenance of computation is represented by a Directed Acyclic Graph (DAG), where each node is an event and each directed edge encodes a data dependency and a minimal physical latency. Fundamental causality in such systems is captured by the happened-before relation (HB), which requires that if an event $j$ depends on event $i$, then the true time of $j$ cannot be earlier than the true time of $i$ plus the minimal latency along the dependency. Formally, if $(i,j)$ is an edge and the minimal latency is $d_{ij}>0$, then the true times $\\tau_{i}$ and $\\tau_{j}$ must satisfy $\\tau_{j} \\ge \\tau_{i} + d_{ij}$. In distributed logging, recorded timestamps $t_{i}$ can violate HB due to network delays and asynchronous clocks. To repair provenance consistency, suppose we constrain adjustments to be nonnegative forward shifts $x_{i} \\ge 0$, forming adjusted times $t'_{i} = t_{i} + x_{i}$ that must satisfy all HB constraints.\n\nConsider the following five events in the provenance DAG $G=(V,E)$ with $V=\\{S,T,C,A,L\\}$ corresponding to sensor sampling ($S$), network transmission to the twin ($T$), twin computation ($C$), actuation command ($A$), and logging/persistence ($L$). The edges and their minimal latencies are:\n- $(S,T)$ with $d_{ST} = 0.002$,\n- $(T,C)$ with $d_{TC} = 0.004$,\n- $(C,A)$ with $d_{CA} = 0.003$,\n- $(C,L)$ with $d_{CL} = 0.001$.\n\nThe recorded timestamps (in seconds) are:\n- $t_{S} = 0.015$,\n- $t_{T} = 0.011$,\n- $t_{C} = 0.020$,\n- $t_{A} = 0.018$,\n- $t_{L} = 0.019$.\n\nThese recorded times violate HB constraints due to out-of-order logging caused by network delays.\n\nStarting from the base principles above, determine the component-wise minimal nonnegative adjustment vector $x = (x_{S}, x_{T}, x_{C}, x_{A}, x_{L})$ such that the adjusted times $t'_{i} = t_{i} + x_{i}$ satisfy $t'_{j} \\ge t'_{i} + d_{ij}$ for all $(i,j) \\in E$, and $x_{i} \\ge 0$ for all $i \\in V$. Express each adjustment in seconds. No rounding is necessary; provide exact decimal values. The final answer must be the row matrix $\\begin{pmatrix} x_{S} & x_{T} & x_{C} & x_{A} & x_{L} \\end{pmatrix}$.",
            "solution": "The problem asks for the component-wise minimal nonnegative adjustment vector $x = (x_S, x_T, x_C, x_A, x_L)$ that makes the recorded timestamps causally consistent. The adjusted times are $t'_i = t_i + x_i$. The causality constraint, or happened-before (HB) relation, for a directed edge $(i, j)$ with minimal latency $d_{ij}$ is $t'_j \\ge t'_i + d_{ij}$.\n\nFirst, we write out the system of inequalities based on the given DAG and latencies:\n1.  For edge $(S, T)$: $t'_T \\ge t'_S + d_{ST}$\n2.  For edge $(T, C)$: $t'_C \\ge t'_T + d_{TC}$\n3.  For edge $(C, A)$: $t'_A \\ge t'_C + d_{CA}$\n4.  For edge $(C, L)$: $t'_L \\ge t'_C + d_{CL}$\n\nWe substitute $t'_i = t_i + x_i$ into these inequalities to express them in terms of the unknown adjustments $x_i$:\n1.  $t_T + x_T \\ge t_S + x_S + d_{ST} \\implies x_T \\ge x_S + (t_S + d_{ST} - t_T)$\n2.  $t_C + x_C \\ge t_T + x_T + d_{TC} \\implies x_C \\ge x_T + (t_T + d_{TC} - t_C)$\n3.  $t_A + x_A \\ge t_C + x_C + d_{CA} \\implies x_A \\ge x_C + (t_C + d_{CA} - t_A)$\n4.  $t_L + x_L \\ge t_C + x_C + d_{CL} \\implies x_L \\ge x_C + (t_C + d_{CL} - t_L)$\n\nWe are also given that the adjustments must be nonnegative: $x_i \\ge 0$ for all $i \\in V$.\n\nOur goal is to find the component-wise minimal solution. This means we must find the smallest possible nonnegative value for each $x_i$ that satisfies all constraints. We can achieve this by processing the nodes in a topological order of the DAG ($S \\to T \\to C \\to \\{A, L\\}$) and, at each step, setting the adjustment to the minimum value allowed by the constraints from its predecessors.\n\n**Step 1: Adjust $x_S$**\nNode $S$ is a source node (no incoming edges), so there are no HB constraints preceding it. To satisfy $x_S \\ge 0$ minimally, we set:\n$x_S = 0$\n\n**Step 2: Adjust $x_T$**\nNode $T$ depends on $S$. The constraint is $x_T \\ge x_S + (t_S + d_{ST} - t_T)$.\nSubstituting the values:\n$x_T \\ge 0 + (0.015 + 0.002 - 0.011) = 0.006$\nThe minimal nonnegative value is $\\max(0, 0.006)$. Thus:\n$x_T = 0.006$\n\n**Step 3: Adjust $x_C$**\nNode $C$ depends on $T$. The constraint is $x_C \\ge x_T + (t_T + d_{TC} - t_C)$.\nSubstituting the values, including the minimal $x_T$ we just found:\n$x_C \\ge 0.006 + (0.011 + 0.004 - 0.020) = 0.006 - 0.005 = 0.001$\nThe minimal nonnegative value is $\\max(0, 0.001)$. Thus:\n$x_C = 0.001$\n\n**Step 4: Adjust $x_A$**\nNode $A$ depends on $C$. The constraint is $x_A \\ge x_C + (t_C + d_{CA} - t_A)$.\nSubstituting the values, including the minimal $x_C$:\n$x_A \\ge 0.001 + (0.020 + 0.003 - 0.018) = 0.001 + 0.005 = 0.006$\nThe minimal nonnegative value is $\\max(0, 0.006)$. Thus:\n$x_A = 0.006$\n\n**Step 5: Adjust $x_L$**\nNode $L$ also depends on $C$. The constraint is $x_L \\ge x_C + (t_C + d_{CL} - t_L)$.\nSubstituting the values, including the minimal $x_C$:\n$x_L \\ge 0.001 + (0.020 + 0.001 - 0.019) = 0.001 + 0.002 = 0.003$\nThe minimal nonnegative value is $\\max(0, 0.003)$. Thus:\n$x_L = 0.003$\n\nThe component-wise minimal nonnegative adjustment vector is therefore:\n$x = (x_S, x_T, x_C, x_A, x_L) = (0, 0.006, 0.001, 0.006, 0.003)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 0.006 & 0.001 & 0.006 & 0.003\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Ensuring the integrity of a provenance record at the scale of a national cyber-physical system presents unique challenges. This practice examines the cryptographic foundation of lineage integrity by analyzing the probability of hash collisions in a provenance ledger. Using an approximation derived from the 'birthday problem,' you will quantify the risk that two distinct artifacts are assigned the same identifier, demonstrating how design choices like hash length have profound implications for the trustworthiness of the entire system .",
            "id": "4212518",
            "problem": "A Digital Twin (DT) provenance ledger for a national-scale Cyber-Physical System (CPS) records immutable lineage artifacts for each sensor event. Each artifact is identified by the truncated output of a cryptographic hash function, modeled as a uniform random mapping into a finite set of size $2^{k}$ with independent draws. For storage efficiency, the system truncates Secure Hash Algorithm 256 (SHA-256) outputs to $k = 64$ bits. During an $8$-hour ingestion window, $200{,}000$ sensors each emit $10$ lineage records per minute, and each record becomes an artifact in the ledger.\n\nStarting only from the definitions of uniform independent sampling into a finite set and the basic rules of probability, derive an approximation for the probability that at least one collision occurs among the $n$ artifacts hashed into $2^{k}$ possible outputs. Then, evaluate this approximation numerically for the described ingestion window. Express the final probability as a decimal and round your answer to four significant figures.\n\nFinally, explain the implication of this probability for lineage integrity in such a DT provenance ledger, under the stated modeling assumptions.",
            "solution": "The problem is well-posed and scientifically grounded. It presents a classic scenario in computer science and cryptography known as the \"birthday problem,\" applied to the context of data provenance in a cyber-physical system. We can proceed with a formal analysis.\n\nFirst, we must determine the total number of artifacts, $n$, that are generated and hashed during the specified time window.\n\nThe given parameters are:\n- Number of sensors, $S = 200{,}000 = 2 \\times 10^5$.\n- Record emission rate per sensor, $R = 10 \\text{ records}/\\text{minute}$.\n- Ingestion window duration, $T = 8 \\text{ hours}$.\n\nTo calculate $n$, we first convert the time duration $T$ into minutes:\n$$T = 8 \\text{ hours} \\times \\frac{60 \\text{ minutes}}{1 \\text{ hour}} = 480 \\text{ minutes}$$\n\nThe total number of artifacts $n$ is the product of the number of sensors, the emission rate, and the time duration in minutes:\n$$n = S \\times R \\times T = (2 \\times 10^5) \\times 10 \\times 480 = 960 \\times 10^6 = 9.6 \\times 10^8$$\n\nThe hash function truncates outputs to $k=64$ bits. The set of possible hash outputs has a size $M$, where:\n$$M = 2^k = 2^{64}$$\n\nThe problem models the hash function as a uniform random mapping with independent draws. This means for each of the $n$ artifacts, the resulting hash is chosen uniformly and independently from the $M$ possible outputs. The total number of possible sequences of $n$ hash values is $M^n$.\n\nWe are asked to find the probability of at least one collision, which we denote as $P_c$. It is more direct to first calculate the probability of the complementary event: no collisions. Let this be $P_{nc}$. Then, $P_c = 1 - P_{nc}$.\n\nFor no collisions to occur, all $n$ hash values must be distinct. The number of ways to choose $n$ distinct hash values from $M$ possibilities without replacement is given by the falling factorial, $P(M, n)$:\n$$P(M, n) = M(M-1)(M-2)\\cdots(M-n+1) = \\frac{M!}{(M-n)!}$$\nThe probability of a specific sequence of $n$ distinct hashes is $1/M^n$. Therefore, the probability of obtaining any sequence with no collisions is:\n$$P_{nc} = \\frac{M(M-1)\\cdots(M-n+1)}{M^n} = \\frac{M}{M} \\cdot \\frac{M-1}{M} \\cdot \\frac{M-2}{M} \\cdots \\frac{M-n+1}{M}$$\nThis can be expressed as a product:\n$$P_{nc} = \\prod_{i=0}^{n-1} \\left(1 - \\frac{i}{M}\\right)$$\n\nFor the large values of $n$ and $M$ in this problem, an exact calculation is infeasible. We must use an approximation, which we derive from fundamental principles as requested. The Taylor series expansion for the exponential function around $x=0$ is $\\exp(x) \\approx 1+x$ for small $x$. This implies that for a small term $\\epsilon_i = i/M$, we can approximate $1-\\epsilon_i \\approx \\exp(-\\epsilon_i)$. This approximation is robust.\n\nApplying this to each term in the product for $P_{nc}$:\n$$P_{nc} \\approx \\prod_{i=0}^{n-1} \\exp\\left(-\\frac{i}{M}\\right) = \\exp\\left(-\\sum_{i=0}^{n-1} \\frac{i}{M}\\right)$$\nThe sum is an arithmetic series: $\\sum_{i=0}^{n-1} i = \\frac{(n-1)n}{2}$. Substituting this into the exponent:\n$$P_{nc} \\approx \\exp\\left(-\\frac{n(n-1)}{2M}\\right)$$\nFor very large $n$, $n(n-1) \\approx n^2$, leading to the common approximation $P_{nc} \\approx \\exp(-n^2/(2M))$. We shall retain the slightly more accurate $n(n-1)$ form.\n\nThe probability of at least one collision, $P_c$, is therefore:\n$$P_c = 1 - P_{nc} \\approx 1 - \\exp\\left(-\\frac{n(n-1)}{2M}\\right)$$\nThis is the desired approximation.\n\nNow, we evaluate this expression numerically with the given values:\n- $n = 9.6 \\times 10^8$\n- $M = 2^{64}$\n\nLet $\\lambda$ be the argument of the exponential function's magnitude:\n$$\\lambda = \\frac{n(n-1)}{2M} = \\frac{(9.6 \\times 10^8)(9.6 \\times 10^8 - 1)}{2 \\times 2^{64}}$$\nSince $n-1$ is negligibly different from $n$ for this calculation, we can approximate $n(n-1) \\approx n^2$:\n$$\\lambda \\approx \\frac{n^2}{2M} = \\frac{(9.6 \\times 10^8)^2}{2 \\times 2^{64}} = \\frac{9.216 \\times 10^{17}}{2^{65}}$$\nTo evaluate this, we use the value $2^{64} \\approx 1.844674 \\times 10^{19}$.\n$$\\lambda \\approx \\frac{9.216 \\times 10^{17}}{2 \\times (1.844674 \\times 10^{19})} = \\frac{9.216 \\times 10^{17}}{3.689348 \\times 10^{19}} \\approx 0.024979$$\nNow we compute the probability of collision:\n$$P_c \\approx 1 - \\exp(-\\lambda) \\approx 1 - \\exp(-0.024979)$$\nUsing a calculator for the exponential term:\n$$\\exp(-0.024979) \\approx 0.975328$$\n$$P_c \\approx 1 - 0.975328 = 0.024672$$\nRounding to four significant figures, we get:\n$$P_c \\approx 0.02467$$\n\nFinally, we explain the implication of this result.\nA collision probability of approximately $2.467\\%$ within a single $8$-hour window is significantly high for a system where lineage integrity is critical. A hash collision means two distinct lineage records are assigned the same unique identifier. This fundamentally breaks the provenance chain, making it impossible to unambiguously trace the history of data. An auditor or an automated analysis tool would be unable to distinguish between the two colliding records, potentially leading to incorrect conclusions about system state, fault propagation, or security events. For a system operating continuously, a collision becomes a near certainty over a matter of days. A probability of no collision over one day (three $8$-hour windows) is $(1-P_c)^3 \\approx (0.97533)^3 \\approx 0.9275$, implying a daily collision risk of over $7\\%$. Over a month ($90$ windows), the probability of avoiding a collision is $(1-P_c)^{90} \\approx 0.103$, meaning an $89.7\\%$ chance of at least one collision. The modeling assumption of a uniform random hash function is optimistic; real-world hash functions can have biases that increase collision probability. Therefore, the calculated risk should be considered a lower bound. The clear implication is that a $64$-bit hash space is inadequate for ensuring lineage integrity at this scale. The system requires a larger hash output, such as $128$ bits or the full $256$ bits of SHA-256, to reduce the collision probability to a cryptographically negligible level.",
            "answer": "$$\\boxed{0.02467}$$"
        }
    ]
}