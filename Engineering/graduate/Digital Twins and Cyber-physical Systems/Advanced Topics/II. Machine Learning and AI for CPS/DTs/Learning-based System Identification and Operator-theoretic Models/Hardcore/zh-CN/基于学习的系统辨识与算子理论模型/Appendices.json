{
    "hands_on_practices": [
        {
            "introduction": "系统辨识中最基本的任务之一是从输入输出数据中估计模型参数。这个练习将引导您完成一个经典的最小二乘法问题，这是学习系统模型的基础。通过最小化预测误差的平方和，我们可以为给定的数据集找到“最佳拟合”的线性模型，这可以看作是学习一个简单的线性算子。",
            "id": "4229220",
            "problem": "一个针对单输入单输出 (SISO) 组件的信息物理系统数字孪生，旨在利用线性模型学习一个静态输入-输出映射。该学习任务被构建为算子理论建模问题，其中输出由作用于一组有限提升特征集上的线性泛函来近似。考虑由 t 索引的离散时间样本的特征映射 $\\phi(u)=[u,\\,1]$ 和参数模型 $y_t=\\theta_1 u_t+\\theta_2$。给定输入-输出数据 $\\{(u_t,y_t)\\}_{t=1}^5$，具体为 $(u_1,y_1)=(-2,-3)$，$(u_2,y_2)=(-1,-1)$，$(u_3,y_3)=(0,0)$，$(u_4,y_4)=(1,3)$ 和 $(u_5,y_5)=(2,6)$。\n\n从最小二乘估计器最小化经验平方误差泛函这一基本原理出发，将辨识问题表述为最小化残差平方和问题，并推导出表征最小值点的条件。然后计算解决该问题的参数估计 $(\\theta_1,\\theta_2)$。如果适用，将最终估计表示为精确的有理数。无需进行四舍五入。最终答案必须是单一的解析表达式。",
            "solution": "问题陈述经核实具有科学依据、是适定的、客观且完整的。它代表了用于线性参数估计的最小二乘法的一个标准应用，这是系统辨识和机器学习中的一个基本任务。\n\n该问题要求确定线性模型 $y_t = \\theta_1 u_t + \\theta_2$ 的参数 $\\theta_1$ 和 $\\theta_2$，使其在最小二乘意义下最佳拟合给定数据。所提供的数据包含 $N=5$ 个输入-输出对 $\\{(u_t, y_t)\\}_{t=1}^5$：\n$(u_1, y_1) = (-2, -3)$\n$(u_2, y_2) = (-1, -1)$\n$(u_3, y_3) = (0, 0)$\n$(u_4, y_4) = (1, 3)$\n$(u_5, y_5) = (2, 6)$\n\n该学习任务被构建为最小化经验平方误差泛函，即残差平方和。每个数据点的残差是观测输出 $y_t$ 与模型预测输出 $\\hat{y}_t = \\theta_1 u_t + \\theta_2$ 之间的差值。因此，待最小化的目标函数是：\n$$ J(\\theta_1, \\theta_2) = \\sum_{t=1}^{5} (y_t - \\hat{y}_t)^2 = \\sum_{t=1}^{5} (y_t - (\\theta_1 u_t + \\theta_2))^2 $$\n\n为了找到最小化此泛函的 $\\theta_1$ 和 $\\theta_2$ 的值，我们必须找到 $J$ 关于参数向量 $\\theta = [\\theta_1, \\theta_2]$ 的梯度为零的点。这需要计算 $J$ 关于 $\\theta_1$ 和 $\\theta_2$ 的偏导数并令其为零。这些是取得最小值的必要条件。\n\n首先，关于 $\\theta_1$ 的偏导数：\n$$ \\frac{\\partial J}{\\partial \\theta_1} = \\frac{\\partial}{\\partial \\theta_1} \\sum_{t=1}^{5} (y_t - \\theta_1 u_t - \\theta_2)^2 = \\sum_{t=1}^{5} 2(y_t - \\theta_1 u_t - \\theta_2)(-u_t) $$\n令其为零：\n$$ \\sum_{t=1}^{5} -2 u_t (y_t - \\theta_1 u_t - \\theta_2) = 0 $$\n$$ \\sum_{t=1}^{5} (u_t y_t - \\theta_1 u_t^2 - \\theta_2 u_t) = 0 $$\n$$ (\\sum_{t=1}^{5} u_t^2) \\theta_1 + (\\sum_{t=1}^{5} u_t) \\theta_2 = \\sum_{t=1}^{5} u_t y_t \\quad (1) $$\n\n接着，关于 $\\theta_2$ 的偏导数：\n$$ \\frac{\\partial J}{\\partial \\theta_2} = \\frac{\\partial}{\\partial \\theta_2} \\sum_{t=1}^{5} (y_t - \\theta_1 u_t - \\theta_2)^2 = \\sum_{t=1}^{5} 2(y_t - \\theta_1 u_t - \\theta_2)(-1) $$\n令其为零：\n$$ \\sum_{t=1}^{5} -2 (y_t - \\theta_1 u_t - \\theta_2) = 0 $$\n$$ \\sum_{t=1}^{5} (y_t - \\theta_1 u_t - \\theta_2) = 0 $$\n$$ (\\sum_{t=1}^{5} u_t) \\theta_1 + (\\sum_{t=1}^{5} 1) \\theta_2 = \\sum_{t=1}^{5} y_t $$\n由于 $\\sum_{t=1}^{5} 1 = N = 5$，我们有：\n$$ (\\sum_{t=1}^{5} u_t) \\theta_1 + 5 \\theta_2 = \\sum_{t=1}^{5} y_t \\quad (2) $$\n\n方程 $(1)$ 和 $(2)$ 是正规方程组。为了解出 $\\theta_1$ 和 $\\theta_2$，我们需要根据给定数据计算各项和：\n- $\\sum_{t=1}^{5} u_t = -2 - 1 + 0 + 1 + 2 = 0$\n- $\\sum_{t=1}^{5} y_t = -3 - 1 + 0 + 3 + 6 = 5$\n- $\\sum_{t=1}^{5} u_t^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 4 + 1 + 0 + 1 + 4 = 10$\n- $\\sum_{t=1}^{5} u_t y_t = (-2)(-3) + (-1)(-1) + (0)(0) + (1)(3) + (2)(6) = 6 + 1 + 0 + 3 + 12 = 22$\n\n将这些值代入正规方程组：\n根据方程 $(1)$:\n$$ (10) \\theta_1 + (0) \\theta_2 = 22 $$\n$$ 10 \\theta_1 = 22 $$\n$$ \\theta_1 = \\frac{22}{10} = \\frac{11}{5} $$\n\n根据方程 $(2)$:\n$$ (0) \\theta_1 + 5 \\theta_2 = 5 $$\n$$ 5 \\theta_2 = 5 $$\n$$ \\theta_2 = 1 $$\n\n因此，最小化残差平方和的参数估计为 $(\\theta_1, \\theta_2) = (\\frac{11}{5}, 1)$。\n线性模型为 $y_t = \\frac{11}{5} u_t + 1$。\n该问题也可以用矩阵形式表示。设特征矩阵为 $X$，输出向量为 $Y$：\n$$ X = \\begin{pmatrix} u_1  1 \\\\ u_2  1 \\\\ u_3  1 \\\\ u_4  1 \\\\ u_5  1 \\end{pmatrix} = \\begin{pmatrix} -2  1 \\\\ -1  1 \\\\ 0  1 \\\\ 1  1 \\\\ 2  1 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ -1 \\\\ 0 \\\\ 3 \\\\ 6 \\end{pmatrix} $$\n正规方程组为 $(X^T X) \\theta = X^T Y$，其中 $\\theta = \\begin{pmatrix} \\theta_1 \\\\ \\theta_2 \\end{pmatrix}$。\n$$ X^T X = \\begin{pmatrix} \\sum u_t^2  \\sum u_t \\\\ \\sum u_t  N \\end{pmatrix} = \\begin{pmatrix} 10  0 \\\\ 0  5 \\end{pmatrix} $$\n$$ X^T Y = \\begin{pmatrix} \\sum u_t y_t \\\\ \\sum y_t \\end{pmatrix} = \\begin{pmatrix} 22 \\\\ 5 \\end{pmatrix} $$\n待解的方程组是：\n$$ \\begin{pmatrix} 10  0 \\\\ 0  5 \\end{pmatrix} \\begin{pmatrix} \\theta_1 \\\\ \\theta_2 \\end{pmatrix} = \\begin{pmatrix} 22 \\\\ 5 \\end{pmatrix} $$\n这得出 $10\\theta_1 = 22$ 和 $5\\theta_2 = 5$，给出相同的解：$\\theta_1 = \\frac{11}{5}$ 和 $\\theta_2 = 1$。\n最终估计按要求表示为精确有理数。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{11}{5}  1 \\end{pmatrix} } $$"
        },
        {
            "introduction": "在处理非线性系统时，直接建模可能非常复杂。Koopman算子理论提供了一个强大的框架，通过将动力学提升到观测函数空间，从而将非线性问题线性化。这个练习演示了如何通过在一个选定的函数基（可观测量）上投影动力学，来构建无限维Koopman算子的有限维矩阵近似，这是将算子理论付诸实践的关键一步。",
            "id": "4229160",
            "problem": "一个标量非线性离散时间信息物理系统的数字孪生使用一个基于 Koopman 算子的算子理论代理模型。考虑由 $f(x)=\\alpha x+\\beta x^{2}$ 定义的映射 $f:\\mathbb{R}\\to\\mathbb{R}$，其中 $\\alpha\\in\\mathbb{R}$ 和 $\\beta\\in\\mathbb{R}$ 是固定参数。Koopman 算子 $\\mathcal{K}$ 作用于一个可观测量 $g:\\mathbb{R}\\to\\mathbb{R}$，其定义为 $(\\mathcal{K}g)(x)=g(f(x))$。为了构建一个有限维代理模型，使用在总多项式次数为 $2$ 处截断的 Carleman 线性化：将注意力限制在字典 $\\Psi(x)=[1,\\,x,\\,x^{2}]^{\\top}$ 上，并将截断算子 $\\mathcal{K}_{2}$ 定义为 $\\mathrm{span}\\{1,x,x^{2}\\}$ 上的唯一线性算子，使得对于每个基可观测量 $g\\in\\{1,x,x^{2}\\}$，其作用 $\\mathcal{K}_{2}g$ 等于复合函数 $g\\circ f$ 再舍去所有次数大于 $2$ 的单项式。\n\n从 Koopman 算子的基本定义和 Carleman 截断原理出发，推导 $\\mathcal{K}_{2}$ 在有序基 $\\{1,x,x^{2}\\}$ 下的矩阵表示，并计算其行列式。请以 $\\alpha$ 和 $\\beta$ 的单个封闭形式解析表达式提供最终答案。不需要进行数值计算或四舍五入，也不涉及物理单位。",
            "solution": "该问题是有效的，因为它在算子理论中有科学依据，是适定的、客观的且自洽的。没有科学或事实上的不健全之处，没有歧义，所要求的任务是所提供定义的直接应用。\n\n目标是求出截断 Koopman 算子 $\\mathcal{K}_{2}$ 关于有序基 $\\{1, x, x^{2}\\}$ 的矩阵表示，然后计算其行列式。设基函数表示为 $\\phi_1(x) = 1$，$\\phi_2(x) = x$ 和 $\\phi_3(x) = x^{2}$。我们称之为 $K_2$ 的矩阵表示是一个 $3 \\times 3$ 矩阵，其第 $j$ 列是变换后的基函数 $\\mathcal{K}_{2}(\\phi_j)$ 关于基 $\\{\\phi_1, \\phi_2, \\phi_3\\}$ 的坐标向量。\n\n步骤如下：对于 $\\{1, x, x^{2}\\}$ 中的每个基函数 $\\phi_j$，我们首先计算完整 Koopman 算子的作用，即 $(\\mathcal{K}\\phi_j)(x) = \\phi_j(f(x))$，其中 $f(x) = \\alpha x + \\beta x^{2}$。然后，我们应用截断规则，即舍去所有 $x$ 的幂次大于 $2$ 的项。得到的多项式是 $\\mathcal{K}_{2}(\\phi_j)$。最后，我们将这个多项式表示为基函数的线性组合，以找到矩阵 $K_2$ 的相应列。\n\n我们来计算 $\\mathcal{K}_{2}$ 对每个基函数的作用。\n\n1.  对第一个基函数 $\\phi_1(x) = 1$ 的作用：\n    Koopman 算子的作用是 $(\\mathcal{K}\\phi_1)(x) = \\phi_1(f(x)) = \\phi_1(\\alpha x + \\beta x^{2}) = 1$。\n    这是一个 $0$ 次多项式，其次数小于或等于 $2$。因此，不需要截断。\n    $$ \\mathcal{K}_{2}(\\phi_1)(x) = 1 $$\n    在基 $\\{\\phi_1, \\phi_2, \\phi_3\\}$ 中表示这个结果：\n    $$ \\mathcal{K}_{2}(\\phi_1)(x) = 1 \\cdot \\phi_1(x) + 0 \\cdot \\phi_2(x) + 0 \\cdot \\phi_3(x) $$\n    坐标向量为 $[1, 0, 0]^{\\top}$。这构成了矩阵 $K_2$ 的第一列。\n\n2.  对第二个基函数 $\\phi_2(x) = x$ 的作用：\n    Koopman 算子的作用是 $(\\mathcal{K}\\phi_2)(x) = \\phi_2(f(x)) = f(x) = \\alpha x + \\beta x^{2}$。\n    这个多项式中的所有项的次数都小于或等于 $2$。不需要截断。\n    $$ \\mathcal{K}_{2}(\\phi_2)(x) = \\alpha x + \\beta x^{2} $$\n    在基 $\\{\\phi_1, \\phi_2, \\phi_3\\}$ 中表示这个结果：\n    $$ \\mathcal{K}_{2}(\\phi_2)(x) = 0 \\cdot \\phi_1(x) + \\alpha \\cdot \\phi_2(x) + \\beta \\cdot \\phi_3(x) $$\n    坐标向量为 $[0, \\alpha, \\beta]^{\\top}$。这构成了矩阵 $K_2$ 的第二列。\n\n3.  对第三个基函数 $\\phi_3(x) = x^{2}$ 的作用：\n    Koopman 算子的作用是 $(\\mathcal{K}\\phi_3)(x) = \\phi_3(f(x)) = (f(x))^{2} = (\\alpha x + \\beta x^{2})^{2}$。\n    我们展开这个表达式：\n    $$ (\\alpha x + \\beta x^{2})^{2} = (\\alpha x)^{2} + 2(\\alpha x)(\\beta x^{2}) + (\\beta x^{2})^{2} = \\alpha^{2}x^{2} + 2\\alpha\\beta x^{3} + \\beta^{2}x^{4} $$\n    现在，我们应用截断规则，舍去所有次数大于 $2$ 的单项式。项 $2\\alpha\\beta x^{3}$ (次数 $3$) 和 $\\beta^{2}x^{4}$ (次数 $4$) 被舍去。\n    截断后的结果是：\n    $$ \\mathcal{K}_{2}(\\phi_3)(x) = \\alpha^{2}x^{2} $$\n    在基 $\\{\\phi_1, \\phi_2, \\phi_3\\}$ 中表示这个结果：\n    $$ \\mathcal{K}_{2}(\\phi_3)(x) = 0 \\cdot \\phi_1(x) + 0 \\cdot \\phi_2(x) + \\alpha^{2} \\cdot \\phi_3(x) $$\n    坐标向量为 $[0, 0, \\alpha^{2}]^{\\top}$。这构成了矩阵 $K_2$ 的第三列。\n\n根据其列向量组装矩阵 $K_2$：\n第一列是 $[1, 0, 0]^{\\top}$。\n第二列是 $[0, \\alpha, \\beta]^{\\top}$。\n第三列是 $[0, 0, \\alpha^{2}]^{\\top}$。\n\n得到的矩阵 $K_2$ 是：\n$$\nK_2 = \\begin{pmatrix}\n1  & 0  & 0 \\\\\n0  & \\alpha  & 0 \\\\\n0  & \\beta  & \\alpha^{2}\n\\end{pmatrix}\n$$\n\n最后一步是计算该矩阵的行列式。矩阵 $K_2$ 是一个下三角矩阵。三角矩阵（无论是上三角还是下三角）的行列式是其对角线元素的乘积。\n$$\n\\det(K_2) = (1) \\cdot (\\alpha) \\cdot (\\alpha^{2})\n$$\n$$\n\\det(K_2) = \\alpha^{3}\n$$\n截断 Koopman 算子 $\\mathcal{K}_{2}$ 的矩阵表示的行列式是 $\\alpha^{3}$。",
            "answer": "$$\\boxed{\\alpha^{3}}$$"
        },
        {
            "introduction": "将理论付诸实践，这个动手编程练习将前两个概念融合到一个现代的、数据驱动的工作流中。我们将学习如何使用延迟嵌入技术从标量时间序列数据中构建一个合适的状态空间，然后应用动态模态分解 (DMD) 来近似Koopman算子并提取系统的基本频率。这个过程是为数字孪生构建基于学习的动力学模型的基石，它展示了如何仅从测量数据中发现隐藏的动力学模式。",
            "id": "4229200",
            "problem": "您的任务是实现一个基于学习的系统辨识工作流，该工作流对一个标量时间序列使用延迟嵌入和算子理论模型。目标是通过对延迟嵌入的汉克尔矩阵（Hankel matrix）进行动态模态分解（Dynamic Mode Decomposition, DMD），重建系统的准周期模态，从而在一个有限维子空间上逼近库普曼算子（Koopman operator）的作用。\n\n该问题的基本基础包括以下核心定义和经过充分检验的事实：\n- 从一个连续时间系统采样的离散时间标量可观测量产生一个时间序列 $x_n = x(t_n)$，其中 $t_n = n \\Delta t$，对于整数 $n \\geq 0$ 和固定的采样周期 $\\Delta t$。\n- 延迟嵌入构建形式为 $\\psi_n = [x_n, x_{n+1}, \\dots, x_{n+m-1}]^\\top$ 的向量，其中 $m$ 是嵌入维度，并将这些向量作为列组织在一个汉克尔矩阵中。\n- 动态模态分解（DMD）通过找到一个线性算子，在通过奇异值截断获得的有限维子空间上，以最小二乘意义上最佳地将嵌入的快照在时间上向前推进，从而逼近库普曼算子的作用。\n\n您的程序必须：\n1. 对于每个测试用例，通过对一组具有指定角频率（单位：弧度/秒）、幅度和指定采样周期 $\\Delta t$ 的正弦波求和进行采样，生成一个包含 $N$ 个时间样本的标量时间序列 $x_n$。角度单位为弧度。如果指定了噪声，则为每个样本添加具有所提供标准差的独立零均值高斯噪声。\n2. 构建延迟嵌入的汉克尔矩阵 $H \\in \\mathbb{R}^{m \\times L}$，其中 $m$ 是嵌入维度，$L = N - m + 1$，其元素定义为 $H_{i,j} = x_{i + j - 1}$，对于 $i = 1, \\dots, m$ 和 $j = 1, \\dots, L$。\n3. 通过取 $H$ 的相邻列来形成两个快照矩阵 $X$ 和 $Y$，即 $X = [h_1, h_2, \\dots, h_{L-1}]$ 和 $Y = [h_2, h_3, \\dots, h_L]$，其中 $h_j$ 表示 $H$ 的第 $j$ 列。\n4. 对 $X$ 执行指定秩为 $r$ 的截断奇异值分解（SVD），以在嵌入子空间上构建一个降阶线性算子，并执行DMD以获得表征准周期模态的特征值。\n5. 根据DMD特征值，通过将特征谱解释为离散时间传播子，并使用采样周期 $\\Delta t$ 将其辐角映射到连续时间角频率，来估计主导模态的角频率（单位：弧度/秒）。确保角度单位是弧度，报告的频率单位是弧度/秒（rad/s）。\n6. 按模态对初始嵌入快照的贡献对模态进行排序，选择前 $k$ 个不同的正角频率（在小容差范围内去重），并按模态贡献的降序报告它们。频率必须四舍五入到三位小数，并以弧度/秒表示。\n\n测试套件由四个测试用例组成，每个用例由参数 $(N, \\Delta t, \\{\\omega_j\\}, \\{a_j\\}, \\sigma, m, r, k)$ 指定，其中：\n- $N$ 是样本数。\n- $\\Delta t$ 是采样周期（秒）。\n- $\\{\\omega_j\\}$ 是正弦波角频率（弧度/秒）。\n- $\\{a_j\\}$ 是对应的幅度（无量纲）。\n- $\\sigma$ 是附加高斯噪声的标准差（无量纲）。\n- $m$ 是嵌入维度。\n- $r$ 是SVD截断秩。\n- $k$ 是要返回的主导频率数量。\n\n使用以下参数集：\n- 情况1：$N = 500$，$\\Delta t = 0.01$ s，$\\{\\omega_1\\} = \\{\\pi\\}$ rad/s，$\\{a_1\\} = \\{1.0\\}$，$\\sigma = 0.0$，$m = 50$，$r = 20$，$k = 1$。\n- 情况2：$N = 800$，$\\Delta t = 0.01$ s，$\\{\\omega_1, \\omega_2\\} = \\{2\\pi \\cdot 0.7, 2\\pi \\cdot 1.2\\}$ rad/s，$\\{a_1, a_2\\} = \\{1.0, 0.5\\}$，$\\sigma = 0.01$，$m = 80$，$r = 40$，$k = 2$。\n- 情况3：$N = 900$，$\\Delta t = 0.01$ s，$\\{\\omega_1, \\omega_2\\} = \\{2\\pi \\cdot 2.0, 2\\pi \\cdot 2.2\\}$ rad/s，$\\{a_1, a_2\\} = \\{1.0, 0.8\\}$，$\\sigma = 0.005$，$m = 100$，$r = 60$，$k = 2$。\n- 情况4：$N = 120$，$\\Delta t = 0.01$ s，$\\{\\omega_1, \\omega_2\\} = \\{2\\pi \\cdot 1.5, 2\\pi \\cdot 3.0\\}$ rad/s，$\\{a_1, a_2\\} = \\{1.0, 0.3\\}$，$\\sigma = 0.02$，$m = 40$，$r = 10$，$k = 2$。\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个项目对应一个测试用例，并且本身是所选的 $k$ 个角频率（单位：弧度/秒）的列表，四舍五入到三位小数。例如，格式必须类似于 $[ [\\omega_{1,1}, \\dots], [\\omega_{2,1}, \\dots], \\dots ]$，不打印任何额外文本。所有角度必须是弧度，所有频率必须以弧度/秒报告。",
            "solution": "用户提供的问题是有效的。它在科学上基于算子理论和系统辨识的原理，并且问题定义良好，具有清晰的、算法上定义的目标和所有测试用例的完整参数集。所概述的程序——使用延迟嵌入形成汉克尔矩阵，然后通过动态模态分解（DMD）来识别潜在频率——是分析动力系统中一种标准且强大的技术。因此，我们可以着手提供一个正式的解决方案。\n\n主要目标是从一个标量时间序列中识别准周期系统的主导角频率。这个过程可以被理解为库普曼算子理论的一个实际应用，我们寻求一个无限维库普曼算子的有限维、数据驱动的近似。\n\n**1. 理论框架：延迟嵌入与库普曼算子**\n\n对于 $n=0, 1, \\dots, N-1$ 和 $t_n = n\\Delta t$ 的离散时间标量时间序列 $x_n = x(t_n)$，通常是更复杂、更高维动力系统的一个观测。根据Takens-Whitney嵌入定理，在某些一般条件下，原始系统的动力学可以在一个“延迟坐标空间”中被忠实地重建。我们在这个空间中构建向量 $\\psi_n = [x_n, x_{n+1}, \\dots, x_{n+m-1}]^\\top \\in \\mathbb{R}^m$，其中 $m$ 是嵌入维度。对于足够大的 $m$，这些延迟向量的轨迹 $\\psi_n \\to \\psi_{n+1}$ 会保留原始系统吸引子的拓扑性质。\n\n库普曼算子 $\\mathcal{K}$ 为非线性动力学提供了一个线性的视角。它作用于系统状态 $z$ 的可观测函数 $g$，将它们在时间上向前演化：$(\\mathcal{K}g)(z_n) = g(z_{n+1})$。对于准周期动力学，$\\mathcal{K}$ 的谱包含单位圆上的特征值 $e^{i\\omega_j \\Delta t}$，其中 $\\omega_j$ 是系统的基频。DMD是一种数值方法，用于寻找 $\\mathcal{K}$ 及其谱的有限维近似。\n\n**2. 算法流程**\n\n实现过程遵循一系列明确定义的步骤，以逼近库普曼算子并提取其谱信息。\n\n**步骤 2a：汉克尔矩阵构造**\n延迟嵌入向量 $\\psi_n$ 被组织成一个大型汉克尔矩阵的列。我们形成矩阵 $H \\in \\mathbb{R}^{m \\times L}$，其中 $L = N - m + 1$。这些列是连续的延迟向量：$h_j = \\psi_{j-1}$，对于 $j=1, \\dots, L$。就原始时间序列 $x_n$（使用0-基索引）而言，矩阵元素为 $H_{ij} = x_{i+j}$（对于0-基矩阵索引 $i, j$）。然后从 $H$ 的相邻列形成两个快照矩阵：\n$$\nX = [h_1, h_2, \\dots, h_{L-1}] \\in \\mathbb{R}^{m \\times (L-1)}\n$$\n$$\nY = [h_2, h_3, \\dots, h_L] \\in \\mathbb{R}^{m \\times (L-1)}\n$$\n根据构造，这些矩阵满足关系 $Y \\approx A X$，其中 $A \\in \\mathbb{R}^{m \\times m}$ 是作用于延迟坐标可观测函数空间的库普曼算子的一个有限维近似。\n\n**步骤 2b：降阶DMD**\n直接计算 $A = YX^\\dagger$（其中 $X^\\dagger$ 是摩尔-彭若斯伪逆）在计算上可能开销很大，并且对噪声敏感。因此，我们将动力学投影到一个能够捕获信号中大部分能量的低维子空间上。该子空间通过 $X$ 的奇异值分解（SVD）来确定：\n$$\nX \\approx U_r \\Sigma_r V_r^*\n$$\n这里，$U_r \\in \\mathbb{R}^{m \\times r}$ 的列是前 $r$ 个本征正交模态（POD modes），$\\Sigma_r \\in \\mathbb{R}^{r \\times r}$ 是前 $r$ 个奇异值的对角矩阵，而 $V_r \\in \\mathbb{R}^{(L-1) \\times r}$ 包含相应的右奇异向量。整数 $r$ 是截断秩。\n\n高维算子 $A$ 被投影到由 $U_r$ 张成的子空间上，产生一个低维算子 $\\tilde{A} \\in \\mathbb{R}^{r \\times r}$：\n$$\n\\tilde{A} = U_r^* A U_r = U_r^* (Y X^\\dagger) U_r = U_r^* Y (V_r \\Sigma_r^{-1} U_r^*) U_r = U_r^* Y V_r \\Sigma_r^{-1}\n$$\n最后一步是因为 $U_r^* U_r = I$。矩阵 $\\tilde{A}$ 捕获了降阶子空间内的动力学。\n\n**步骤 2c：特征值与频率分析**\n$\\tilde{A}$ 的特征谱近似于完整算子 $A$ 的谱。我们求解特征值问题：\n$$\n\\tilde{A} W = W \\Lambda\n$$\n其中 $\\Lambda$ 是特征值 $\\lambda_j$ 的对角矩阵，而 $W$ 的列是相应的特征向量。每个特征值 $\\lambda_j$ 是一个离散时间传播子。它通过 $\\lambda_j = e^{z_j \\Delta t}$ 与连续时间特征值 $z_j = \\gamma_j + i\\omega_j$ 相关联。因此，模态的角频率 $\\omega_j$ 可以提取为：\n$$\n\\omega_j = \\frac{\\text{Im}(\\ln \\lambda_j)}{\\Delta t} = \\frac{\\text{arg}(\\lambda_j)}{\\Delta t}\n$$\n\n**步骤 2d：模态贡献与排序**\n降阶算子的特征向量 $W$ 可用于重建全空间DMD模态，这些模态是库普曼模态的近似。DMD模态的一个常见选择是 $\\Phi = U_r W$。为了确定每个模态对系统观测行为的贡献，我们将初始状态 $\\psi_0 = X[:,0]$ 投影到这个DMD模态基上：\n$$\n\\psi_0 = \\sum_j b_j \\phi_j = \\Phi b\n$$\n模态振幅向量 $b$ 通过最小二乘拟合求得，通常使用伪逆：$b = \\Phi^\\dagger \\psi_0$。$|b_j|$ 的大小代表第 $j$ 个模态对初始状态的贡献。\n\n然后，根据 $|b_j|$ 的降序对模态进行排序。我们选择前 $k$ 个对应于不同正频率的模态，经过一个去重步骤以合并由同一物理模态产生的数值上接近的频率。最终结果是这些主导角频率的列表。为了在有噪声时保证可复现性，伪随机数生成器使用一个固定的种子进行初始化。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the DMD analysis for all specified test cases.\n    \"\"\"\n    # Use a fixed seed for the random number generator to ensure reproducibility.\n    rng = np.random.default_rng(seed=0)\n\n    test_cases = [\n        # Case 1: Single sinusoid, no noise\n        {'N': 500, 'dt': 0.01, 'omegas': [np.pi], 'amps': [1.0], 'sigma': 0.0, 'm': 50, 'r': 20, 'k': 1},\n        # Case 2: Two sinusoids, with noise\n        {'N': 800, 'dt': 0.01, 'omegas': [2*np.pi*0.7, 2*np.pi*1.2], 'amps': [1.0, 0.5], 'sigma': 0.01, 'm': 80, 'r': 40, 'k': 2},\n        # Case 3: Two close sinusoids, with noise\n        {'N': 900, 'dt': 0.01, 'omegas': [2*np.pi*2.0, 2*np.pi*2.2], 'amps': [1.0, 0.8], 'sigma': 0.005, 'm': 100, 'r': 60, 'k': 2},\n        # Case 4: Two sinusoids, short time series, with noise\n        {'N': 120, 'dt': 0.01, 'omegas': [2*np.pi*1.5, 2*np.pi*3.0], 'amps': [1.0, 0.3], 'sigma': 0.02, 'm': 40, 'r': 10, 'k': 2},\n    ]\n\n    all_results = []\n\n    for params in test_cases:\n        # 1. Generate time series\n        t = np.arange(params['N']) * params['dt']\n        x = np.zeros(params['N'])\n        for omega, amp in zip(params['omegas'], params['amps']):\n            x += amp * np.sin(omega * t)\n        \n        if params['sigma'] > 0:\n            x += rng.normal(0, params['sigma'], params['N'])\n\n        # 2. Construct Hankel matrix\n        m = params['m']\n        N = params['N']\n        L = N - m + 1\n        H = np.empty((m, L))\n        for j in range(L):\n            H[:, j] = x[j : j + m]\n\n        # 3. Form snapshot matrices\n        X = H[:, :-1]\n        Y = H[:, 1:]\n\n        # 4. Perform truncated SVD and DMD\n        U, s, Vh = linalg.svd(X, full_matrices=False)\n        \n        r = params['r']\n        Ur = U[:, :r]\n        Sr_inv = np.diag(1.0 / s[:r])\n        Vr = Vh[:r, :].T\n\n        # Build reduced-order operator\n        A_tilde = Ur.T @ Y @ Vr @ Sr_inv\n\n        # 5. Eigendecomposition and frequency extraction\n        Lambda, W = linalg.eig(A_tilde)\n        # Convert discrete-time eigenvalues to continuous-time angular frequencies\n        dmd_omegas = np.angle(Lambda) / params['dt']\n\n        # 6. Rank modes by contribution and select top k\n        # Reconstruct DMD modes\n        Phi = Ur @ W\n        # Project initial state onto DMD modes to get amplitudes\n        x1 = X[:, 0]\n        # Use pseudoinverse for stable computation of mode amplitudes\n        b = linalg.pinv(Phi) @ x1\n        \n        amplitudes = np.abs(b)\n        \n        # Pair frequencies with their amplitudes and sort\n        sorted_indices = np.argsort(amplitudes)[::-1]\n        sorted_omegas = dmd_omegas[sorted_indices]\n\n        # Deduplicate and select top k positive frequencies\n        top_k_omegas = []\n        added_omegas_set = []\n        # Tolerance for considering frequencies as distinct\n        freq_tolerance = 0.1 \n        \n        for omega in sorted_omegas:\n            if len(top_k_omegas) >= params['k']:\n                break\n            # Consider only positive frequencies\n            if omega > 0:\n                is_duplicate = False\n                for added_omega in added_omegas_set:\n                    if abs(omega - added_omega)  freq_tolerance:\n                        is_duplicate = True\n                        break\n                if not is_duplicate:\n                    top_k_omegas.append(omega)\n                    added_omegas_set.append(omega)\n        \n        # Round the final frequencies to three decimal places\n        result = [round(f, 3) for f in top_k_omegas]\n        # The problem asks for decreasing order of modal contribution.\n        # Since we iterate through the sorted list, the order is preserved.\n        all_results.append(result)\n\n    # Format output as a string representation of a list of lists.\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}