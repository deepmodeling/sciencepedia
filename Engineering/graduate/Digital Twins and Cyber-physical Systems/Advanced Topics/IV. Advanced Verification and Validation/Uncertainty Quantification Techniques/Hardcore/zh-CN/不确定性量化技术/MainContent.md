## 引言
[数字孪生](@entry_id:171650)与信息物理系统（CPS）的成功依赖于其核心的[计算模型](@entry_id:637456)，这些模型被用于预测物理资产的行为、诊断故障并指导决策。然而，任何模型都只是现实世界的近似，其预测不可避免地伴随着不确定性。若不对此不确定性进行严谨的量化和管理，模型的预测可能会产生误导，基于这些预测的决策也可能带来巨大的风险。本文旨在系统性地解决这一知识鸿沟，为读者构建一个关于[不确定性量化](@entry_id:138597)（UQ）技术的完整知识体系，使其能够构建和使用更可靠、更值得信赖的[数字孪生](@entry_id:171650)。

在接下来的内容中，读者将踏上一段从理论到实践的旅程。第一章“原理与机制”将奠定坚实的基础，深入剖析不确定性的两种[基本类](@entry_id:158335)型，并介绍作为现代UQ核心的贝叶斯推断框架。第二章“应用与跨学科联系”将展示这些原理如何应用于现实世界中的关键任务，如动态系统的状态估计、模型校准与验证，并探讨UQ在最优设计、[鲁棒控制](@entry_id:260994)乃至公共政策等领域的广泛影响。最后，第三章“动手实践”将通过具体的计算练习，巩固所学知识。为了建立这个强大的框架，我们必须首先深入探讨[不确定性量化](@entry_id:138597)的核心原理和机制。

## 原理与机制

本章旨在系统性阐述数字孪生与信息物理系统中不确定性量化（UQ）的核心原理和关键机制。我们将从不确定性的基本分类出发，深入探讨将不确定性形式化并进行推理的贝叶斯框架，介绍主流的[不确定性传播](@entry_id:146574)与表达技术，并最终将这些技术置于[模型校准](@entry_id:146456)、结构选择和优化决策等高级应用背景下进行审视。本章的目标是为读者构建一个从基本概念到前沿应用的完整知识体系。

### 数字孪生中不确定性的本质

在任何复杂的建模与仿真任务中，不确定性都是一个无法回避的现实。对于数字孪生而言，其预测能力和可靠性直接取决于我们对其不确定性来源的理解和量化。从根本上说，不确定性可分为两大类：**[偶然不确定性](@entry_id:634772)（aleatoric uncertainty）** 和 **认知不确定性（epistemic uncertainty）**。

**[偶然不确定性](@entry_id:634772)**，又称随机不确定性或不可约不确定性，源于系统或测量过程固有的、内在的随机性。即使我们拥有完美的模型和精确的参数知识，这种不确定性依然存在。例如，传感器测量中的热噪声、制造过程中不可控的微小差异、或[流体动力](@entry_id:750449)学中的[湍流](@entry_id:151300)波动，都属于[偶然不确定性](@entry_id:634772)。在数学模型中，它通常由一个[随机变量](@entry_id:195330)来表示，例如一个零均值的噪声项。

**认知不确定性**，又称系统不确定性或可约不确定性，源于我们对系统知识的缺乏。这包括对模型结构的不确定（例如，是否应包含某个物理效应）、对模型参数的不确定（例如，材料的弹性模量或传热系数的精确值）。原则上，通过收集更多的数据、进行更精确的实验或改进模型，认知不确定性是可以被减小甚至消除的。

为了更精确地理解这两种不确定性，我们可以构建一个形式化的概率模型。假设一个[数字孪生](@entry_id:171650)模型用于预测系统的某个输出 $Y$，该输出依赖于一组可控或环境输入 $X$。模型由一个物理方程 $f(X, \theta)$ 描述，其中 $\theta$ 是一组未知的模型参数。传感器的测量过程引入了随机噪声 $\varepsilon$，因此观测值 $Y$ 与模型的关系为：
$$
Y = f(X, \theta) + \varepsilon
$$
我们假定噪声 $\varepsilon$ 的期望为零，即 $\mathbb{E}[\varepsilon \mid X, \theta] = 0$，其方差为 $\operatorname{Var}(\varepsilon \mid X, \theta) = \sigma^2(X)$，表示噪声水平可能随输入 $X$ 变化。在贝叶斯框架下，我们对参数 $\theta$ 的先验知识由一个[先验分布](@entry_id:141376) $p(\theta)$ 描述。在收集了数据集 $\mathcal{D}_n = \{(X_i, Y_i)\}_{i=1}^n$ 后，我们可以通过贝叶斯推断得到参数的[后验分布](@entry_id:145605) $p(\theta \mid \mathcal{D}_n)$。

此时，对于一个新的输入 $X$，我们对预测值 $Y$ 的不确定性可以由其预测方差 $\operatorname{Var}(Y \mid X, \mathcal{D}_n)$ 来量化。根据**[全方差公式](@entry_id:177482)**（Law of Total Variance），我们可以将这个总方差分解为两部分 ：
$$
\operatorname{Var}(Y \mid X, \mathcal{D}_n) = \mathbb{E}_{\theta \mid \mathcal{D}_n}\! \big[ \operatorname{Var}(Y \mid X, \theta) \big] + \operatorname{Var}_{\theta \mid \mathcal{D}_n}\! \big( \mathbb{E}[Y \mid X, \theta] \big)
$$
让我们来解析这个公式的每一项：
1.  内层期望 $\mathbb{E}[Y \mid X, \theta] = \mathbb{E}[f(X, \theta) + \varepsilon \mid X, \theta] = f(X, \theta)$。这是在参数 $\theta$ 已知的情况下，我们对 $Y$ 的最佳[点估计](@entry_id:174544)。
2.  内层方差 $\operatorname{Var}(Y \mid X, \theta) = \operatorname{Var}(f(X, \theta) + \varepsilon \mid X, \theta) = \operatorname{Var}(\varepsilon \mid X, \theta) = \sigma^2(X)$。这是在参数 $\theta$ 已知的情况下，预测中剩余的方差，它完全来自于[固有噪声](@entry_id:261197) $\varepsilon$。

将这两项代入[全方差公式](@entry_id:177482)，我们得到：
$$
\operatorname{Var}(Y \mid X, \mathcal{D}_n) = \underbrace{\mathbb{E}_{\theta \mid \mathcal{D}_n} \! \big[ \sigma^2(X) \big]}_{\text{偶然不确定性}} + \underbrace{\operatorname{Var}_{\theta \mid \mathcal{D}_n} \! \big( f(X, \theta) \big)}_{\text{认知不确定性}}
$$
由于 $\sigma^2(X)$ 不依赖于 $\theta$，第一项简化为 $\sigma^2(X)$。因此，总预测方差被清晰地分解为：
$$
\operatorname{Var}(Y \mid X, \mathcal{D}_n) = \sigma^2(X) + \operatorname{Var}_{\theta \mid \mathcal{D}_n} \! \big( f(X, \theta) \big)
$$
这个分解完美地对应了偶然和认知不确定性的定义：
-   **$\sigma^2(X)$** 是 **[偶然不确定性](@entry_id:634772)** 的量度。它代表了即使我们完全知道了模型参数（即 $\theta$ 是一个确定值），系统输出仍然存在的波动性。只要 $\sigma^2(X) > 0$，这种不确定性就无法通过收集更多同类型的数据来消除。
-   **$\operatorname{Var}_{\theta \mid \mathcal{D}_n} ( f(X, \theta) )$** 是 **认知不确定性** 的量度。它源于我们对参数 $\theta$ 的不确定性，这种不确定性由[后验分布](@entry_id:145605) $p(\theta \mid \mathcal{D}_n)$ 来刻画。随着我们收集更多的数据（即 $n \to \infty$），[后验分布](@entry_id:145605)会越来越集中于真实的参数值 $\theta^\star$。因此，这个方差项会趋近于零。

理解这两种不确定性的区别至关重要，因为它直接关系到我们如何改进数字孪生。如果预测不确定性主要由认知不确定性主导，那么通过模型校准、收集更多数据是有效的策略。反之，如果[偶然不确定性](@entry_id:634772)占主导，那么改进的重点应该放在升级传感器硬件或改造物理系统本身。

### 不确定性量化的贝叶斯框架

[贝叶斯推断](@entry_id:146958)为量化和更新认知不确定性提供了一个严谨且自洽的数学框架。其核心在于利用观测数据，将我们关于未知参数的先验知识更新为后验知识。这个过程依赖于三个基本要素：**先验（prior）**、**[似然](@entry_id:167119)（likelihood）** 和 **后验（posterior）**。

**[似然函数](@entry_id:921601)** $p(Y \mid \theta)$ 是连接数据与模型参数的桥梁 。它描述了在给定一组特定参数 $\theta$ 的条件下，观测到数据集 $Y$ 的概率。它并不是 $\theta$ 的一个概率分布，而是作为 $\theta$ 的函数，衡量了不同参数值与观测数据的“契合程度”。那些能使观测数据出现的可能性更高的参数值，将获得更高的[似然](@entry_id:167119)值。

假设一个信息物理系统的测量过程是离散的，在时刻 $k=1, \dots, N$，我们得到观测值 $y_k$。该观测值由一个与状态相关的函数 $h(x_k(\theta), \theta)$ 和一个加性[高斯噪声](@entry_id:260752) $\varepsilon_k \sim \mathcal{N}(0, R_k(\theta))$ 构成。如果各次测量的噪声是条件独立的，那么整个数据集 $Y = \{y_k\}_{k=1}^N$ 的[联合似然](@entry_id:750952)函数就是各次测量似然的乘积：
$$
p(Y \mid \theta) = \prod_{k=1}^{N} p(y_k \mid \theta) = \prod_{k=1}^{N} \mathcal{N} \! \left( y_k; h(x_k(\theta), \theta), R_k(\theta) \right)
$$
其中 $\mathcal{N}(y; \mu, \Sigma)$ 表示均值为 $\mu$、协方差为 $\Sigma$ 的高斯分布在 $y$ 处的[概率密度](@entry_id:175496)。

**[先验分布](@entry_id:141376)** $p(\theta)$ 则编码了我们在观测任何数据之前关于参数 $\theta$ 的知识或信念。这可能来自于物理学原理、历史数据或专家经验。

**[后验分布](@entry_id:145605)** $p(\theta \mid Y)$ 是[贝叶斯推断](@entry_id:146958)的最终产物，它代表了在观测到数据 $Y$ 之后，我们对参数 $\theta$ 的更新后的知识。根据**贝叶斯定理**，后验分布正比于[似然函数](@entry_id:921601)与先验分布的乘积：
$$
p(\theta \mid Y) \propto p(Y \mid \theta) p(\theta)
$$
这个简单的公式蕴含了深刻的学习机制：后验知识是数据证据（通过[似然函数](@entry_id:921601)体现）和[先验信念](@entry_id:264565)的结合。

#### 实例：共轭高斯模型的[贝叶斯更新](@entry_id:179010)

为了更具体地理解[贝叶斯更新](@entry_id:179010)过程，我们考虑一个简单的校准问题 。假设一个[温度传感](@entry_id:921441)器的静态偏差 $\theta$ 是未知的。我们对其的先验信念是一个高斯分布 $\theta \sim \mathcal{N}(\mu_0, v_0)$。我们进行了一系列独立的校准测量 $y_1, \dots, y_n$，其测量模型为 $y_i \mid \theta \sim \mathcal{N}(\theta, \sigma^2)$，其中噪声方差 $\sigma^2$ 已知。

根据贝叶斯定理，[后验分布](@entry_id:145605) $p(\theta \mid y_{1:n})$ 为：
$$
p(\theta \mid y_{1:n}) \propto \left( \prod_{i=1}^n p(y_i \mid \theta) \right) p(\theta) \propto \exp \! \left( -\frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - \theta)^2 \right) \exp \! \left( -\frac{(\theta - \mu_0)^2}{2v_0} \right)
$$
通过对指数部分关于 $\theta$ 配方，我们可以证明[后验分布](@entry_id:145605)仍然是一个高斯分布 $\mathcal{N}(\mu_n, v_n)$。这个特性被称为**共轭性**，即[似然函数](@entry_id:921601)和[先验分布](@entry_id:141376)的形式使得后验分布与先验分布属于同一分布族。在这种情况下，[后验均值](@entry_id:173826) $\mu_n$ 和后验方差 $v_n$ 有解析解。

特别地，后验均值可以表达为一个非常直观的形式：
$$
\mu_n = \frac{\frac{1}{v_0}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac{1}{v_0} + \frac{n}{\sigma^2}}
$$
其中 $\bar{y} = \frac{1}{n}\sum y_i$ 是样本均值。如果我们定义 **精度（precision）** 为方差的倒数（例如，先验精度 $\tau_0 = 1/v_0$），那么上式可以写成：
$$
\mu_n = \frac{\tau_0 \mu_0 + n\tau_y \bar{y}}{\tau_0 + n\tau_y}
$$
其中 $\tau_y = 1/\sigma^2$ 是单次测量的精度。这个结果优雅地表明，[后验均值](@entry_id:173826)是先验均值和数据样本均值的**精度加权平均**。先验的权重是其自身的精度，而数据的权重是其总精度（$n\tau_y$）。这意味着，信息更精确的来源（无论是先验还是数据）将在决定后验估计时拥有更大的话语权。

例如，假设先验参数为 $\mu_0=0.6$ K, $v_0=0.16$ K$^2$ (即 $\tau_0=6.25$)，传感器噪声标准差为 $\sigma=0.15$ K (即 $\sigma^2 = 0.0225$，$\tau_y \approx 44.44$)。在收集了8个观测值 $\{0.91, 0.65, 0.80, 0.77, 0.58, 0.83, 0.69, 0.74\}$ 后，样本均值为 $\bar{y} \approx 0.74625$。数据的总精度为 $n\tau_y = 8 \times (1/0.0225) \approx 355.56$，远大于先验精度 $6.25$。因此，[后验均值](@entry_id:173826)将非常接近样本均值：
$$
\mu_8 = \frac{6.25 \times 0.6 + 355.56 \times 0.74625}{6.25 + 355.56} \approx 0.7437 \text{ K}
$$
这清晰地展示了数据是如何压倒（update）较弱的先验信念的。

### 不确定性的传播与表达

获得了参数的[后验分布](@entry_id:145605)后，下一个关键步骤是**不确定性传播**：将参数的不确定性通过模型 $f(X, \theta)$ 传递到我们关心的预测量上。这使得我们不仅能给出一个点预测，还能给出一个完整的预测分布或[置信区间](@entry_id:142297)。

#### 基于采样的传播方法：蒙特卡洛

**[蒙特卡洛](@entry_id:144354)（[Monte Carlo](@entry_id:144354), MC）** 方法是最通用、最直观的不确定性传播技术。其基本思想是通过随机抽样来模拟不确定性的影响。假设我们想估计某个模型输出量 $Y=h(X)$ 的期望 $\mu = \mathbb{E}[h(X)]$，其中 $X$ 是一个具有已知分布的随机输入。MC估计器 $\hat{\mu}_n$ 的构造如下：
1.  从 $X$ 的分布中[独立同分布](@entry_id:169067)地抽取 $n$ 个样本 $\{X_i\}_{i=1}^n$。
2.  对每个样本，通过模型计算输出 $h(X_i)$。
3.  计算这些输出的样本均值：$\hat{\mu}_n = \frac{1}{n}\sum_{i=1}^n h(X_i)$。

根据[大数定律](@entry_id:140915)，当 $n \to \infty$ 时，$\hat{\mu}_n$ 会收敛到真实的期望 $\mu$。更重要的是，**[中心极限定理](@entry_id:143108)（Central Limit Theorem）** 告诉我们这个收敛的速度和误差的分布特征 。如果 $h(X)$ 的方差 $\sigma_h^2 = \operatorname{Var}(h(X))$ 是有限的，那么对于足够大的 $n$，$\hat{\mu}_n$ 的分布近似于一个正态分布：
$$
\hat{\mu}_n \approx \mathcal{N} \! \left(\mu, \frac{\sigma_h^2}{n}\right)
$$
或者等价地，[标准化](@entry_id:637219)后的估计误差收敛到一个[标准正态分布](@entry_id:184509)：
$$
\sqrt{n}(\hat{\mu}_n - \mu) \xrightarrow{d} \mathcal{N}(0, \sigma_h^2)
$$
这个强大的结论有几个直接的实践意义：
-   **[收敛速度](@entry_id:636873)**：MC估计的标准差以 $1/\sqrt{n}$ 的速度减小。这意味着要将误差减半，需要的样本量是原来的四倍。
-   **误差条（Error Bars）**：我们可以为我们的估计构造一个近似的置信区间。例如，一个近似的 $95\%$ 置信区间为 $\hat{\mu}_n \pm 1.96 \frac{s_h}{\sqrt{n}}$，其中 $s_h$ 是样本 $\{h(X_i)\}$ 的标准差，用作未知真实标准差 $\sigma_h$ 的估计。
-   **样本量规划**：我们可以预先确定为达到特定精度所需的样本量。如果我们希望[置信区间](@entry_id:142297)的半宽度为 $\varepsilon$，则所需的样本量 $n$ 大约是 $n \approx (z_{1-\alpha/2} \sigma_h / \varepsilon)^2$。在实践中，$\sigma_h$ 通常是未知的，可以通过一次小规模的“试点”仿真来估计它。

#### 高效传播的代理模型

蒙特卡洛方法虽然通用，但当单次[模型评估](@entry_id:164873) $f(x, \theta)$ 非常耗时（例如，一次复杂的[有限元分析](@entry_id:138109)可能需要数小时）时，成千上万次的调用是不可接受的。在这种情况下，我们转向使用**代理模型（surrogate model）**，也称为**仿真器（emulator）**。代理模型是在少量精心挑选的[设计点](@entry_id:748327)上运行昂贵模型后，构建的一个廉价的近似模型。

**多项式混沌展开（Polynomial Chaos Expansions, PCE）** 是一种强大且广泛应用的非侵入式代理建模技术 。其核心思想是将模型输出 $Y$ 表示为关于随机输入 $\xi = (\xi_1, \dots, \xi_d)$ 的一组正交多项式基 $\Psi_\alpha(\xi)$ 的[级数展开](@entry_id:142878)：
$$
Y = \sum_{\alpha \in \mathcal{A}} c_\alpha \Psi_\alpha(\xi)
$$
这里的 $\alpha$ 是一个多重指标，$\{\Psi_\alpha\}$ 是关于输入变量 $\xi$ 的[概率测度](@entry_id:190821) $\mu$ 正交的多项式。正交性意味着 $\mathbb{E}[\Psi_\alpha(\xi) \Psi_\beta(\xi)] = \langle \Psi_\alpha, \Psi_\beta \rangle = 0$ 对所有 $\alpha \neq \beta$ 成立。

**正交性**是PCE的魔力所在。它极大地简化了系数 $c_\alpha$ 的计算。通过利用正交性，我们可以将系数表示为模型输出与相应基函数的投影：
$$
c_\alpha = \frac{\langle Y, \Psi_\alpha \rangle}{\langle \Psi_\alpha, \Psi_\alpha \rangle} = \frac{\mathbb{E}[Y \cdot \Psi_\alpha(\xi)]}{\mathbb{E}[\Psi_\alpha(\xi)^2]}
$$
这些[期望值](@entry_id:150961)通常通过数值积分（如[高斯求积](@entry_id:146011)）或[蒙特卡洛采样](@entry_id:752171)来估计。

如果选择的基是**标准正交（orthonormal）** 的，即 $\mathbb{E}[\Psi_\alpha^2]=1$ 对所有 $\alpha$ 成立，并且 $\Psi_0=1$ 是零阶多项式，那么PCE会带来一个极为有用的性质：**方差分解**。模型输出的均值和方差可以直接从展开系数中读出：
$$
\mathbb{E}[Y] = c_0
$$
$$
\operatorname{Var}[Y] = \sum_{\alpha \in \mathcal{A}\setminus\{0\}} c_\alpha^2
$$
这个公式表明，总方差被分解为与每个（非零阶）基函数相关的方差贡献之和。这为**全局敏感性分析**提供了一条直接路径，因为每个系数 $c_\alpha$ 的平方直接量化了相应基函数 $\Psi_\alpha$ 对总输出方差的贡献。

多项式基的选择取决于输入[随机变量](@entry_id:195330)的分布。例如，对于服从[标准正态分布](@entry_id:184509)的输入 $\xi_i \sim \mathcal{N}(0,1)$，所选用的正交多项式是**概率论中的[埃尔米特多项式](@entry_id:153594)（Probabilists' Hermite polynomials）** $H_n$。对于由独立标准正态输入构成的[张量积](@entry_id:140694)基 $\Psi_\alpha(\xi) = \prod_{i=1}^d H_{\alpha_i}(\xi_i)$，其范数平方为 $\mathbb{E}[\Psi_\alpha(\xi)^2] = \prod_{i=1}^d \alpha_i!$ 。

### 贝叶斯推断与建模中的高级主题

现实世界的[数字孪生](@entry_id:171650)应用往往涉及更复杂的场景，需要更先进的推断技术和建模理念。

#### [近似推断](@entry_id:746496)：[变分推断](@entry_id:634275)

当模型变得复杂时（例如，非共轭的先验与[似然](@entry_id:167119)组合，或参数维度非常高），后验分布 $p(\theta \mid y)$ 往往没有解析形式，并且使用MCMC等[采样方法](@entry_id:141232)进行估计的计算成本可能过高。**[变分推断](@entry_id:634275)（Variational Inference, VI）** 提供了一种替代的、通常更快的[近似推断](@entry_id:746496)方法。

VI的核心思想是将复杂的推断问题转化为一个优化问题 。我们选择一个相对简单的、[参数化](@entry_id:265163)的分布族 $\mathcal{Q}$（例如，所有高斯分布），然后在这个族里寻找一个成员 $q(\theta)$，使其与真实的[后验分布](@entry_id:145605) $p(\theta \mid y)$ 最“接近”。这种“接近”程度通常用**Kullback-Leibler (KL) 散度**来衡量。具体来说，我们旨在最小化 $D_{KL}(q(\theta) \parallel p(\theta \mid y))$。

通过简单的代数推导，可以得到一个基本恒等式：
$$
\log p(y) = \mathcal{L}(q) + D_{KL}(q(\theta) \parallel p(\theta \mid y))
$$
其中 $p(y)$ 是模型的**边际似然**或**证据（evidence）**，而 $\mathcal{L}(q)$ 被称为**[证据下界](@entry_id:634110)（Evidence Lower Bound, ELBO）**，其定义为：
$$
\mathcal{L}(q) = \mathbb{E}_q[\log p(y, \theta)] - \mathbb{E}_q[\log q(\theta)]
$$
由于KL散度总是非负的，ELBO 确实是 $\log p(y)$ 的一个下界。同时，因为 $\log p(y)$ 对于我们的优化变量 $q$ 来说是一个常数，所以最小化KL散度等价于最大化ELBO。

一个常见的简化假设是**平均场（mean-field）**假设，它假定 $q(\theta)$ 可以分解为各参数分量的乘积：$q(\theta) = \prod_i q_i(\theta_i)$。在这种假设下，可以通过一种称为**坐标上升[变分推断](@entry_id:634275)（Coordinate Ascent Variational Inference, CAVI）**的[迭代算法](@entry_id:160288)来优化ELBO。其更新规则为，交替更新每个因子 $q_i(\theta_i)$，使其正比于：
$$
q_i^\star(\theta_i) \propto \exp \! \left( \mathbb{E}_{q_{-i}}[\log p(y, \theta)] \right)
$$
其中 $\mathbb{E}_{q_{-i}}$ 表示对除 $\theta_i$ 外所有其他参数的期望。

需要注意的是，最小化 $D_{KL}(q \parallel p)$ 这种“正向”KL散度具有一种**寻模（mode-seeking）**行为。如果真实后验 $p$ 是多峰的，而我们的近似族 $\mathcal{Q}$（例如高斯分布族）是单峰的，那么优化过程会倾向于让 $q$ 集中在 $p$ 的某一个峰上，而忽略其他峰，并常常低估[后验分布](@entry_id:145605)的方差。

#### 考虑[模型差异](@entry_id:198101)的[贝叶斯校准](@entry_id:746704)

传统的[模型校准](@entry_id:146456)假设，在某个“真实”的参数 $\theta$ 下，计算机模拟器可以完美地复现物理现实。然而，所有模型都是现实的简化。**肯尼迪-奥哈根（Kennedy-O'Hagan, KOH）框架**提供了一个更现实的[贝叶斯校准](@entry_id:746704)方法，它明确地考虑了模型本身的不完美性 。

在该框架下，一次物理观测 $y^{\text{obs}}(x)$ 被分解为三个部分：
$$
y^{\text{obs}}(x) = f(x, \theta) + \delta(x) + \epsilon(x)
$$
其中：
-   $f(x, \theta)$ 是计算机模拟器的输出。在实践中，它本身也可能被一个快速的代理模型（**仿真器**）所替代，这个代理模型自身也带有不确定性（例如，[高斯过程仿真器](@entry_id:1125535)给出的预测均值和方差）。
-   $\delta(x)$ 是**[模型差异](@entry_id:198101)（model discrepancy）**项。这是一个关于输入 $x$ 的函数，代表了即使在最佳参数 $\theta$ 下，模拟器与物理现实之间的系统性偏差。它捕捉了模型结构上的缺陷。
-   $\epsilon(x)$ 是**[测量噪声](@entry_id:275238)**，代表观测过程中的[偶然不确定性](@entry_id:634772)。

这个框架虽然更真实，但也引入了一个严峻的挑战：**[不可辨识性](@entry_id:1128800)（non-identifiability）**。从观测数据中，我们只能得到三项之和的信息。特别是，模型参数 $\theta$ 的效应和[模型差异](@entry_id:198101) $\delta(x)$ 的效应很容易混淆。例如，如果模型在某个区域 $x$ 的预测偏低，数据既可以解释为“参数 $\theta$ 不对”，也可以解释为“参数 $\theta$ 对，但存在一个负的[模型差异](@entry_id:198101) $\delta(x)$”。

为了缓解这种[不可辨识性](@entry_id:1128800)，需要引入额外的结构性假设或先验知识。常用的策略包括：
-   为[模型差异](@entry_id:198101) $\delta(x)$ 赋予一个零均值的先验（例如，一个零均值的[高斯过程](@entry_id:182192)先验），这表达了我们相信模型在平均意义上是无偏的。
-   使用信息丰富的先验知识来约束参数 $\theta$ 的范围。
-   精心设计实验，选择那些对参数 $\theta$ 敏感而对 $\delta(x)$ 相对不敏感的输入点 $x$ 进行测量。

此外，[测量噪声](@entry_id:275238) $\epsilon$ 和模型差异 $\delta$ 之间也可能存在[不可辨识性](@entry_id:1128800)，特别是当差异项包含类似于[白噪声](@entry_id:145248)的高频成分时。如果在同一个输入点 $x$ 进行**[重复测量](@entry_id:896842)**，就可以帮助分离这两种不确定性，因为重复测量值的方差直接估计了纯粹的[测量噪声](@entry_id:275238)方差 $\sigma_\epsilon^2$ 。

#### 动态系统中的不确定性

对于信息物理系统，动态演化是其核心特征。一个典型的[离散时间状态空间](@entry_id:261361)模型可以写成：
$$
x_{t+1} = f(x_t, u_t, \theta) + w_t \quad (\text{过程模型})
$$
$$
y_t = g(x_t) + v_t \quad (\text{测量模型})
$$
其中 $x_t$ 是系统的隐状态， $u_t$ 是控制输入，$\theta$ 是未知参数，$w_t$ 是过程噪声，$v_t$ 是测量噪声。

在这样的动态系统中进行序贯贝叶斯推断（例如，状态滤波或估计），其计算的可行性严重依赖于模型的概率结构 。为了实现高效的递归更新（如[预测-更新循环](@entry_id:269441)），通常需要两个关键的[条件独立性](@entry_id:262650)假设：
1.  **马尔可夫性（Markov Property）**：未来状态 $x_{t+1}$ 只依赖于当前状态 $x_t$ 和当前输入 $u_t$，而与过去的状态历史无关。即 $p(x_{t+1} \mid x_{0:t}, u_{0:t}) = p(x_{t+1} \mid x_t, u_t)$。这个性质直接源于过程模型 $x_{t+1}=f(\dots)+w_t$，前提是[过程噪声](@entry_id:270644)序列 $\{w_t\}$ 是“[白噪声](@entry_id:145248)”，即时间上不相关。
2.  **测量的[条件独立性](@entry_id:262650)**：当前测量 $y_t$ 只依赖于当前状态 $x_t$，而与过去的状态和测量无关。即 $p(y_t \mid x_{0:t}, y_{1:t-1}) = p(y_t \mid x_t)$。这个性质源于测量模型 $y_t=g(x_t)+v_t$，前提是测量噪声序列 $\{v_t\}$ 是[白噪声](@entry_id:145248)，并且与过程噪声 $\{w_t\}$ 相互独立。

满足这些假设的最简单和最常见的模型是假设 $w_t$ 和 $v_t$ 都是[独立同分布](@entry_id:169067)的**[高斯白噪声](@entry_id:749762)**。这种**线性-高斯**假设是卡尔曼滤波器及其各种[非线性](@entry_id:637147)扩展（如[扩展卡尔曼滤波器](@entry_id:199333)EKF、[无迹卡尔曼滤波器](@entry_id:166733)UKF）能够实现高效、[闭合形式](@entry_id:271343)或近似[闭合形式](@entry_id:271343)递归计算的基石。

### [不确定性量化](@entry_id:138597)在决策中的价值

[量化不确定性](@entry_id:272064)的最终目的不是为了不确定性本身，而是为了利用这些信息来做出更明智、更鲁棒的决策。

#### [贝叶斯模型选择](@entry_id:147207)

在构建数字孪生时，我们常常面临**结构不确定性**：应该选择哪种模型结构？例如，一个模型可能基于简化的线性物理定律，而另一个则包含复杂的[非线性](@entry_id:637147)效应。贝叶斯框架提供了一个原则性的方法来比较这些[竞争模型](@entry_id:1122715)，即**[贝叶斯模型选择](@entry_id:147207)**。

其核心工具是**[边际似然](@entry_id:636856)（marginal likelihood）**，也称为**[模型证据](@entry_id:636856)（model evidence）** 。对于一个给定的模型 $M$，其边际似然定义为[似然函数](@entry_id:921601)在整个参数先验分布上的加权平均：
$$
p(y \mid M) = \int p(y \mid \theta, M) p(\theta \mid M) d\theta
$$
这个量代表了模型 $M$ 产生观测数据 $y$ 的总体概率。要比较两个模型 $M_1$ 和 $M_2$，我们计算它们的**贝叶斯因子（Bayes Factor）** $B_{12} = p(y \mid M_1) / p(y \mid M_2)$。如果两个模型的先验概率 $p(M_1)$ 和 $p(M_2)$ 相等，那么贝叶斯因子就等于它们的后验概率之比。

边际似然的美妙之处在于它自动实现了**[奥卡姆剃刀](@entry_id:142853)（Occam's razor）**原理：在拟[合数](@entry_id:263553)据同样好的情况下，更简单的模型更受青睐。一个更复杂的模型（[参数空间](@entry_id:178581)更大或更灵活）虽然可能在某个最优参数点上更好地拟[合数](@entry_id:263553)据（即有更高的似然峰值），但它的先验概率被“稀释”在一个更广阔的[参数空间](@entry_id:178581)中。如果增加的复杂性对于解释数据并非必要，那么模型的大部分[参数空间](@entry_id:178581)都对应着与数据不符的预测，导致其在积分后的[边际似然](@entry_id:636856)值较低。

例如，在一个[线性高斯模型](@entry_id:268963)中，如果我们将参数的先验方差 $\tau^2$ 设得极大（即一个非常弥散的、看似“无信息”的先验），这意味着我们允许参数取很大的值。这会导致预测分布的方差 $\sigma^2 I + \tau^2 XX^\top$ 变得非常大，将总概率质量摊薄在一个巨大的空间中。结果，在任何特定数据点 $y$ 处的概率密度 $p(y \mid M)$ 都会变得非常小，从而惩罚了这种不必要的灵活性 。

#### 降低不确定性的经济价值

将[不确定性量化](@entry_id:138597)与决策理论相结合，可以让我们评估信息本身的经济价值。**样本信息的期望价值（Expected Value of Sample Information, EVSI）** 就是这样一个概念。它衡量的是，在做出决策之前，通过获取额外样本信息所能带来的预期收益（或损失的减少）。

考虑一个简单的控制问题：根据当前状态 $x_t$ 选择一个控制量 $u$，以最小化期望损失 $L = (x_{t+1}-x_{\text{ref}})^2 + \lambda u^2$，其中下一时刻的状态 $x_{t+1} = \theta x_t + u + w$ 依赖于未知参数 $\theta$ 和随机扰动 $w$ 。

EVSI被定义为“在获取样本Y并使用后验知识进行优化”相对于“仅使用先验知识进行优化”所带来的预期风险降低量。通过[决策论](@entry_id:265982)的严谨推导可以证明，EVSI直接与**认知不确定性**的降低量成正比。在这个例子中，EVSI最终可以表示为 $EVSI \propto (s_0^2 - s_1^2)$，其中 $s_0^2$ 是参数 $\theta$ 的先验方差， $s_1^2$ 是其后验方差。

这个结论意义深远：
-   **信息只对减少认知不确定性有价值**。如果系统中没有认知不确定性（即 $s_0^2=0$，参数已知），那么EVSI为零，收集更多数据没有意义。
-   **[偶然不确定性](@entry_id:634772)不贡献于EVSI**。在上述例子中，随机扰动的方差 $\sigma_w^2$（一个纯粹的[偶然不确定性](@entry_id:634772)来源）在EVSI的最终表达式中完全抵消了。这是因为我们计划收集的样本 $Y$ 提供了关于 $\theta$ 的信息，但没有提供关于未来扰动 $w$ 的信息。因此，无论[偶然不确定性](@entry_id:634772)有多大，只要它无法通过样本学习来减少，它就不会影响样本信息的价值。

这一结论为本章开篇关于偶然与认知不确定性的讨论提供了一个强有力的闭环：区分这两种不确定性不仅是一个哲学上的分类，它直接决定了我们在改进数字孪生和指导决策时的策略和资源投入方向。