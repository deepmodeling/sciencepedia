{
    "hands_on_practices": [
        {
            "introduction": "Understanding the quantitative behavior of a system is the core of probabilistic model checking. This first practice provides a comprehensive walkthrough, starting from a fundamental three-state Continuous-Time Markov Chain (CTMC) model of a system with failure pathways. You will derive the time-bounded failure probability as a closed-form function of the system's transition rates, implement this solution, and interpret how these parameters influence system safety, a process known as parametric model checking . This exercise bridges the gap between the theory of stochastic processes and the practical analysis of system reliability.",
            "id": "4248146",
            "problem": "Consider a three-state Continuous-Time Markov Chain (CTMC), defined over the state set $\\{s_0, s_1, s_F\\}$ where $s_F$ is absorbing. The transitions are as follows: from $s_0$ to $s_1$ with rate $a$ (in $s^{-1}$), from $s_0$ to $s_F$ with rate $b$ (in $s^{-1}$), and from $s_1$ to $s_F$ with rate $c$ (in $s^{-1}$). There are no other transitions. The initial state is $s_0$ with probability $1$. Let the generator matrix be $Q$ and the transient state probability row vector be $x(t)$ obeying the Kolmogorov forward equations $dx(t)/dt = x(t) Q$ for $t \\ge 0$. The absorbing state $s_F$ represents failure.\n\nIn Continuous Stochastic Logic (CSL), the bounded until operator expresses time-bounded reachability. The property $\\mathsf{P}=?\\,[\\,\\mathsf{true}\\,\\mathsf{U}^{\\le T}\\,s_F\\,]$ asks for the probability that the process reaches $s_F$ within time bound $T$. For this CTMC, this probability equals the probability mass in $s_F$ at time $T$, denoted $x_F(T)$, when $s_F$ is absorbing.\n\nStarting only from the core definitions of CTMCs and the Kolmogorov forward equations, derive an explicit closed-form expression for $x_F(T)$ as a function of the parameters $a$, $b$, $c$, and the time bound $T$. Your derivation must handle the general case and the degenerate case where $a + b = c$.\n\nThen, implement a program that, given specific parameter sets $(a,b,c,T)$, computes the CSL query value $\\mathsf{P}=?\\,[\\,\\mathsf{true}\\,\\mathsf{U}^{\\le T}\\,s_F\\,]$, which equals $x_F(T)$. Rates $a$, $b$, and $c$ are given in $s^{-1}$, and time $T$ is given in seconds; the computed probability is unitless and must be returned as a decimal number. Use the derived expression to ensure numerical stability near the degenerate case.\n\nFinally, interpret the functional dependence of $x_F(T)$ on the parameters $a$, $b$, and $c$ by reasoning from first principles. Explain qualitatively and quantitatively how changes in each parameter affect the probability of reaching $s_F$ by time $T$.\n\nTest Suite:\nProvide outputs for the following parameter sets, which include a general case, a boundary case, and edge cases:\n1. $(a,b,c,T) = (0.4, 0.3, 0.8, 2.5)$ with $a$ in $s^{-1}$, $b$ in $s^{-1}$, $c$ in $s^{-1}$, and $T$ in seconds.\n2. $(a,b,c,T) = (0.3, 0.2, 0.5, 3.0)$ with $a + b = c$ (degenerate case).\n3. $(a,b,c,T) = (0.2, 0.0, 0.4, 1.75)$ with no direct failure from $s_0$.\n4. $(a,b,c,T) = (0.4, 0.3, 0.5, 0.0)$ with zero time bound.\n5. $(a,b,c,T) = (0.1, 0.2, 0.05, 100.0)$ with a long time bound.\n\nRequired final output format:\nYour program should produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4,result_5]$), where each $result_i$ is the computed decimal probability. The program must not read any input and must print only this single line.",
            "solution": "The user wants me to solve a problem about a Continuous-Time Markov Chain (CTMC).\n\n### Step 1: Problem Validation\n\nThe problem is a well-defined mathematical exercise in the domain of stochastic processes, specifically Continuous-Time Markov Chains (CTMCs) and their analysis using Continuous Stochastic Logic (CSL).\n\n*   **Extraction of Givens**:\n    *   System: A three-state CTMC with states $\\{s_0, s_1, s_F\\}$, where $s_F$ is absorbing.\n    *   Initial condition: The process starts in state $s_0$ at time $t=0$, i.e., $P(X(0)=s_0)=1$.\n    *   Transitions and rates:\n        *   $s_0 \\to s_1$ with rate $a$ ($s^{-1}$).\n        *   $s_0 \\to s_F$ with rate $b$ ($s^{-1}$).\n        *   $s_1 \\to s_F$ with rate $c$ ($s^{-1}$).\n    *   Objective 1: Derive a closed-form expression for $x_F(T)$, the probability of reaching the failure state $s_F$ by time $T$, as a function of $a, b, c, T$. The derivation must handle the general case ($a+b \\neq c$) and the degenerate case ($a+b = c$).\n    *   Objective 2: Implement a program to compute $x_F(T)$ for a given set of test parameters.\n    *   Objective 3: Interpret the functional dependence of $x_F(T)$ on the parameters $a, b, c$.\n\n*   **Validation**:\n    *   The problem is scientifically grounded in the theory of CTMCs and is a standard topic in quantitative verification and performance analysis of systems.\n    *   It is well-posed, with all necessary information provided for a unique solution.\n    *   The language is objective and precise.\n    *   The setup is complete, consistent, and mathematically sound.\n\n*   **Verdict**: The problem is valid.\n\n### Step 2: Derivation of the Closed-Form Expression\n\nWe begin by modeling the system using the Kolmogorov forward equations. Let $x_0(t)$, $x_1(t)$, and $x_F(t)$ be the probabilities of the system being in state $s_0$, $s_1$, and $s_F$ at time $t$, respectively. The state vector is $x(t) = [x_0(t), x_1(t), x_F(t)]$.\n\nThe generator matrix $Q$ for the CTMC, with states ordered $(s_0, s_1, s_F)$, is constructed from the given transition rates. The diagonal elements are the negative sum of the rates of outgoing transitions from each state.\n$$\nQ = \\begin{pmatrix} -(a+b) & a & b \\\\ 0 & -c & c \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nThe Kolmogorov forward equations are given by the matrix-vector differential equation $dx(t)/dt = x(t) Q$. This expands into a system of linear ordinary differential equations (ODEs):\n1.  $\\frac{dx_0(t)}{dt} = -(a+b) x_0(t)$\n2.  $\\frac{dx_1(t)}{dt} = a x_0(t) - c x_1(t)$\n3.  $\\frac{dx_F(t)}{dt} = b x_0(t) + c x_1(t)$\n\nThe initial conditions are given by the starting state $s_0$: $x_0(0)=1$, $x_1(0)=0$, and $x_F(0)=0$.\n\nWe solve this system of ODEs step-by-step.\n\n**Solving for $x_0(t)$:**\nThe first equation is a simple separable first-order ODE.\n$$\n\\frac{dx_0}{x_0} = -(a+b) dt\n$$\nIntegrating both sides and applying the initial condition $x_0(0)=1$ yields:\n$$\nx_0(t) = e^{-(a+b)t}\n$$\n\n**Solving for $x_1(t)$:**\nSubstitute the solution for $x_0(t)$ into the second ODE:\n$$\n\\frac{dx_1(t)}{dt} + c x_1(t) = a e^{-(a+b)t}\n$$\nThis is a first-order linear ODE. We solve it using an integrating factor $I(t) = e^{\\int c dt} = e^{ct}$.\n$$\n\\frac{d}{dt}(x_1(t)e^{ct}) = a e^{ct} e^{-(a+b)t} = a e^{(c - (a+b))t}\n$$\nIntegrating with respect to time from $0$ to $t$:\n$$\nx_1(t)e^{ct} - x_1(0)e^0 = \\int_0^t a e^{(c - (a+b))\\tau} d\\tau\n$$\nSince $x_1(0)=0$, we have $x_1(t)e^{ct} = a \\int_0^t e^{(c - (a+b))\\tau} d\\tau$. We must consider two cases for the integral.\n\n*   **General Case: $a+b \\neq c$**\n    The exponent is non-zero. Let $\\delta = c-(a+b)$.\n    $$\n    x_1(t)e^{ct} = a \\left[ \\frac{1}{\\delta} e^{\\delta \\tau} \\right]_0^t = \\frac{a}{\\delta}(e^{\\delta t} - 1)\n    $$\n    Multiplying by $e^{-ct}$:\n    $$\n    x_1(t) = \\frac{a}{c-(a+b)} (e^{(c-(a+b))t} - 1)e^{-ct} = \\frac{a}{c-(a+b)} (e^{-(a+b)t} - e^{-ct})\n    $$\n\n*   **Degenerate Case: $a+b = c$**\n    The exponent is zero ($e^0 = 1$).\n    $$\n    x_1(t)e^{ct} = a \\int_0^t 1 d\\tau = at\n    $$\n    Multiplying by $e^{-ct}$:\n    $$\n    x_1(t) = at e^{-ct}\n    $$\n    As $a+b=c$, we can also write this as $x_1(t) = at e^{-(a+b)t}$.\n\n**Solving for $x_F(T)$:**\nThe total probability must be conserved: $x_0(t) + x_1(t) + x_F(t) = 1$ for all $t \\ge 0$. Therefore, the probability of being in the failure state at time $T$ is:\n$$\nx_F(T) = 1 - x_0(T) - x_1(T)\n$$\nWe now substitute the expressions for $x_0(T)$ and $x_1(T)$ for each case.\n\n*   **General Case: $a+b \\neq c$**\n    $$\n    x_F(T) = 1 - e^{-(a+b)T} - \\frac{a}{c-(a+b)} (e^{-(a+b)T} - e^{-cT})\n    $$\n    Rearranging the terms to group the exponentials:\n    $$\n    x_F(T) = 1 - \\left(1 + \\frac{a}{c-(a+b)}\\right)e^{-(a+b)T} + \\frac{a}{c-(a+b)}e^{-cT}\n    $$\n    Simplifying the coefficient of the first exponential term:\n    $$\n    1 + \\frac{a}{c-(a+b)} = \\frac{c - a - b + a}{c-(a+b)} = \\frac{c-b}{c-(a+b)}\n    $$\n    This gives the final closed-form expression for the general case:\n    $$\n    x_F(T) = 1 - \\frac{c-b}{c-(a+b)} e^{-(a+b)T} + \\frac{a}{c-(a+b)} e^{-cT}\n    $$\n\n*   **Degenerate Case: $a+b = c$**\n    $$\n    x_F(T) = 1 - x_0(T) - x_1(T) = 1 - e^{-cT} - aT e^{-cT}\n    $$\n    This gives the expression for the degenerate case:\n    $$\n    x_F(T) = 1 - (1+aT)e^{-cT}\n    $$\n\n**Numerical Stability:**\nThe general formula for $x_F(T)$ involves the term $\\delta = c-(a+b)$ in the denominator, which leads to numerical instability when $\\delta \\to 0$. We can verify that the degenerate case formula is the limit of the general case formula as $\\delta \\to 0$ using L'Hôpital's rule or a Taylor series expansion.\nLet $c = a+b+\\delta$. The general formula can be written as:\n$$\nx_F(T) = 1 + \\frac{a e^{-(a+b+\\delta)T} - (a+\\delta) e^{-(a+b)T}}{\\delta}\n$$\nWe examine the limit of the fraction as $\\delta \\to 0$. Using the first-order Taylor expansion for the exponential, $e^{-\\delta T} \\approx 1 - \\delta T$:\n$$\n\\lim_{\\delta \\to 0} \\frac{a e^{-(a+b)T} e^{-\\delta T} - (a+\\delta) e^{-(a+b)T}}{\\delta} = \\lim_{\\delta \\to 0} e^{-(a+b)T} \\frac{a(1-\\delta T) - (a+\\delta)}{\\delta}\n$$\n$$\n= e^{-(a+b)T} \\lim_{\\delta \\to 0} \\frac{a - a\\delta T - a - \\delta}{\\delta} = e^{-(a+b)T} \\lim_{\\delta \\to 0} \\frac{-\\delta(aT+1)}{\\delta} = -(aT+1)e^{-(a+b)T}\n$$\nSubstituting this back, we get $x_F(T) = 1 - (aT+1)e^{-(a+b)T}$. Since $a+b=c$ in this limit, this is exactly the formula for the degenerate case. For implementation, we use the degenerate formula when $|\\delta|$ is below a small threshold (e.g., $10^{-8}$) and the general formula otherwise.\n\n### Step 3: Interpretation of Parameter Dependence\n\nThe quantity $x_F(T)$ represents the cumulative distribution function (CDF) of the time to absorption into the failure state $s_F$. The parameters $a, b, c$ are rates, and their inverse represents a mean time for a corresponding exponential event.\n\n*   **Dependence on $b$ (rate $s_0 \\to s_F$):** An increase in $b$ increases the rate of the direct path to failure from the initial state ($s_0 \\to s_F$). This unequivocally makes failure more likely to occur sooner. Thus, for any time $T>0$, $x_F(T)$ is a strictly increasing function of $b$. The partial derivative $\\partial x_F(T) / \\partial b$ is always positive for $T>0$.\n\n*   **Dependence on $c$ (rate $s_1 \\to s_F$):** An increase in $c$ increases the rate of failure from the intermediate state $s_1$. This speeds up the second step of the two-step failure path ($s_0 \\to s_1 \\to s_F$). If there is any chance of reaching $s_1$ (i.e., if $a>0$), speeding up the exit from $s_1$ to $s_F$ will make the overall failure process faster. Therefore, for any $T>0$ and $a>0$, $x_F(T)$ is a strictly increasing function of $c$. The partial derivative $\\partial x_F(T) / \\partial c$ is positive for $T>0, a>0$.\n\n*   **Dependence on $a$ (rate $s_0 \\to s_1$):** The effect of $a$ is more complex. Increasing $a$ has two competing effects:\n    1.  It increases the total rate of leaving state $s_0$ (which is $a+b$), thereby shortening the time spent in the initial state.\n    2.  It diverts probability mass away from the direct failure path ($s_0 \\to s_F$) towards the two-step path ($s_0 \\to s_1 \\to s_F$).\n    The net effect depends on the \"speed\" of this alternative path, which is governed by rate $c$. If $c$ is very large, the second step $s_1 \\to s_F$ is very fast, so opening this path more (increasing $a$) will likely accelerate overall failure. If $c$ is very small, the state $s_1$ acts as a temporary trap, and diverting probability mass into it can delay the eventual failure compared to the direct path (if $b>0$). Consequently, the dependence of $x_F(T)$ on $a$ is non-monotonic and depends on the relative values of $b$ and $c$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the CTMC problem for the given test suite.\n    \n    The function calculates the probability of reaching the absorbing failure state s_F\n    by time T for a three-state Continuous-Time Markov Chain. It uses a derived\n    closed-form solution that is numerically stabilized for the degenerate case\n    where a + b = c.\n    \"\"\"\n\n    test_cases = [\n        # (a, b, c, T)\n        (0.4, 0.3, 0.8, 2.5),    # General case\n        (0.3, 0.2, 0.5, 3.0),    # Degenerate case (a + b = c)\n        (0.2, 0.0, 0.4, 1.75),   # No direct failure from s0 (b=0)\n        (0.4, 0.3, 0.5, 0.0),    # Zero time bound\n        (0.1, 0.2, 0.05, 100.0)  # Long time bound, T -> infinity\n    ]\n\n    results = []\n    \n    # Threshold for treating the general case as degenerate for numerical stability.\n    epsilon = 1e-9\n\n    for a, b, c, T in test_cases:\n        # T=0 is a trivial boundary case, failure probability is 0.\n        if T == 0.0:\n            results.append(0.0)\n            continue\n            \n        rate_sum = a + b\n        delta = c - rate_sum\n\n        prob = 0.0\n        if abs(delta) < epsilon:\n            # Degenerate case: a + b = c, or numerically very close.\n            # Formula: x_F(T) = 1 - (1 + a*T) * exp(-c*T)\n            # This handles the case where c=0 (and thus a=b=0), resulting in prob=0.\n            prob = 1.0 - (1.0 + a * T) * np.exp(-c * T)\n        else:\n            # General case: a + b != c\n            # Formula: x_F(T) = 1 - (c-b)/(c-(a+b))*exp(-(a+b)T) + a/(c-(a+b))*exp(-c*T)\n            # This handles cases where a=0 or b=0 correctly.\n            term1 = ((c - b) / delta) * np.exp(-rate_sum * T)\n            term2 = (a / delta) * np.exp(-c * T)\n            prob = 1.0 - term1 + term2\n        \n        results.append(prob)\n\n    # Format the final output string as specified.\n    # e.g., [result_1,result_2,result_3,result_4,result_5]\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Formal logics like Continuous Stochastic Logic (CSL) provide a precise language to specify complex system properties, but what do they mean in practice? This exercise focuses on dissecting the semantics of the time-bounded 'until' operator, a key construct for expressing reachability and response properties. By analyzing a simple two-mode system, you will calculate the satisfaction probability directly from the first principles of CTMC behavior—the exponentially distributed holding times—to build a concrete intuition for what the abstract CSL formula represents . This deepens your understanding of how logical specifications map to underlying probabilistic events.",
            "id": "4248168",
            "problem": "A digital twin of a cyber-physical system is abstracted as a two-mode stochastic hybrid model whose mode switching is captured by a Continuous-Time Markov Chain (CTMC). The CTMC has state space $\\{0,1\\}$, with $0$ denoting the nominal operating mode and $1$ denoting a maintenance mode. The infinitesimal generator matrix is\n$$\nQ \\;=\\; \\begin{pmatrix}\n-\\lambda & \\lambda \\\\\n\\mu & -\\mu\n\\end{pmatrix},\n$$\nwith fixed rates $\\lambda > 0$ and $\\mu > 0$. Let atomic proposition $A$ hold exactly in state $0$ and atomic proposition $B$ hold exactly in state $1$. The system starts in state $0$ at time $0$.\n\nConsider the Continuous Stochastic Logic (CSL) time-bounded until formula $\\mathsf{P}_{\\geq p}\\big[A \\ \\mathsf{U}^{\\leq T}\\ B\\big]$ with a fixed horizon $T>0$, interpreted under the standard semantics of CSL on CTMCs: along a path, the formula $A \\ \\mathsf{U}^{\\leq T}\\ B$ holds if there exists a time $t \\in [0,T]$ at which the state satisfies $B$, and for all times $\\tau \\in [0,t)$ the state satisfies $A$.\n\nDefine the minimal probability threshold $p_{\\min}(T)$ as the supremum of all $p \\in [0,1]$ such that the state $0$ satisfies $\\mathsf{P}_{\\geq p}\\big[A \\ \\mathsf{U}^{\\leq T}\\ B\\big]$. In other words, $p_{\\min}(T)$ is the exact probability, starting from state $0$, that the property $A \\ \\mathsf{U}^{\\leq T}\\ B$ is satisfied, and $\\mathsf{P}_{\\geq p}\\big[A \\ \\mathsf{U}^{\\leq T}\\ B\\big]$ holds at state $0$ if and only if $p \\leq p_{\\min}(T)$.\n\nUsing only first principles for CTMCs (exponential holding times, Kolmogorov forward equations) and the formal semantics of the CSL time-bounded until operator, derive a closed-form analytic expression for $p_{\\min}(T)$ in terms of $\\lambda$, $\\mu$, and $T$. Provide your final answer as a single analytic expression. Do not approximate or round your answer.",
            "solution": "The problem requires the derivation of a closed-form analytic expression for $p_{\\min}(T)$.\n\nFirst, we must validate the problem statement.\nThe problem is formulated within the standard mathematical frameworks of Continuous-Time Markov Chains (CTMCs) and Continuous Stochastic Logic (CSL), which are cornerstones of modeling and verification for stochastic systems.\nThe givens are:\n- A CTMC with state space $\\{0, 1\\}$.\n- An infinitesimal generator matrix $Q = \\begin{pmatrix} -\\lambda & \\lambda \\\\ \\mu & -\\mu \\end{pmatrix}$ with rates $\\lambda > 0$, $\\mu > 0$.\n- Atomic propositions $A$ is true in state $0$, $B$ is true in state $1$.\n- Initial condition: the system starts in state $0$ at time $t=0$.\n- The CSL formula of interest is $\\mathsf{P}_{\\geq p}\\big[A \\ \\mathsf{U}^{\\leq T}\\ B\\big]$ for a fixed time horizon $T>0$.\nThe quantity to be derived, $p_{\\min}(T)$, is defined as the exact probability that a path starting from state $0$ satisfies the property $A \\ \\mathsf{U}^{\\leq T}\\ B$.\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information to derive a unique solution. No contradictions or ambiguities are present. The model is a fundamental and widely used representation of a two-state system. Therefore, the problem is valid and we may proceed with the solution.\n\nThe core of the problem is to compute $p_{\\min}(T)$, which represents the probability of the path property $A \\ \\mathsf{U}^{\\leq T}\\ B$ holding, given the system starts in state $0$ at time $t=0$. Let the state of the CTMC at time $\\tau$ be denoted by $X(\\tau)$. The initial state is $X(0) = 0$.\n\nAccording to the provided semantics, the path formula $A \\ \\mathsf{U}^{\\leq T}\\ B$ holds for a path if there exists a time $t \\in [0, T]$ such that the state at time $t$ satisfies $B$, and for all preceding times $\\tau \\in [0, t)$, the state satisfies $A$.\nGiven our specific CTMC:\n- A state satisfies proposition $A$ if and only if the state is $0$.\n- A state satisfies proposition $B$ if and only if the state is $1$.\n\nThus, for a path starting at $X(0)=0$, the formula $A \\ \\mathsf{U}^{\\leq T}\\ B$ holds if there exists a time $t \\in [0,T]$ such that $X(t)=1$, and for all $\\tau \\in [0, t)$, we have $X(\\tau)=0$. This condition describes an event where the first time the system enters state $1$ occurs at or before time $T$.\n\nLet $\\tau_{0 \\to 1}$ be the random variable representing the time of the first passage from state $0$ to state $1$. The probability we seek to compute is precisely $P(\\tau_{0 \\to 1} \\leq T)$.\n\nWe now derive this probability from the first principles of CTMCs. The time a CTMC spends in any given state $i$ before transitioning to another state is called the holding time. This holding time is an exponentially distributed random variable with a rate equal to the total rate of exit from state $i$, which is given by $-Q_{ii}$.\n\nFor our system starting in state $0$, the holding time in state $0$ is an exponential random variable, let's call it $S_0$, with rate $-Q_{00} = -(-\\lambda) = \\lambda$.\nAfter this holding time $S_0$, the process must transition to another state. The transition rate from state $0$ to state $1$ is $Q_{01} = \\lambda$. Since state $1$ is the only other state in the system, any transition from state $0$ must be to state $1$. The probability of transitioning to state $1$ upon leaving state $0$ is $\\frac{Q_{01}}{-Q_{00}} = \\frac{\\lambda}{\\lambda} = 1$.\n\nTherefore, the first passage time from state $0$ to state $1$, $\\tau_{0 \\to 1}$, is identical to the first holding time in state $0$, $S_0$. We have $\\tau_{0 \\to 1} = S_0$, where $S_0 \\sim \\text{Exponential}(\\lambda)$.\n\nThe problem is now reduced to calculating the probability $P(S_0 \\leq T)$. The cumulative distribution function (CDF) for an exponential random variable with rate $\\lambda$ is given by $F(t) = P(S_0 \\leq t) = 1 - \\exp(-\\lambda t)$ for $t \\geq 0$.\n\nEvaluating this CDF at $t=T$, we obtain the desired probability:\n$$p_{\\min}(T) = P(S_0 \\leq T) = 1 - \\exp(-\\lambda T)$$\n\nIt is important to note that the rate $\\mu$, which governs transitions from state $1$ back to state $0$, does not appear in the final expression. This is a direct consequence of the semantics of the CSL \"until\" operator ($\\mathsf{U}$). The property is satisfied as soon as the system reaches a $B$-satisfying state (state $1$) for the first time, provided it has only been in $A$-satisfying states (state $0$) up to that point. The behavior of the system *after* this first arrival at state $1$ is irrelevant to the truth of the formula.\n\nThis result can be rigorously confirmed by solving the system of ordinary differential equations (ODEs) that governs the CSL model checking problem for bounded-until properties. Let $p_i(t)$ be the probability of satisfying $A \\ \\mathsf{U}^{\\leq t}\\ B$ starting from state $i$. We seek $p_0(T)$.\n- For a starting state $i=1$ (which satisfies $B$), the property is met at time $0$, so $p_1(t)=1$ for all $t \\ge 0$.\n- For the starting state $i=0$ (which satisfies $A$ but not $B$), its probability evolves according to the Kolmogorov backward equation:\n$$ \\frac{d p_0(t)}{dt} = \\sum_{j \\in \\{0,1\\}} Q_{0j} p_j(t) = Q_{00} p_0(t) + Q_{01} p_1(t) $$\nSubstituting the known values $Q_{00}=-\\lambda$, $Q_{01}=\\lambda$, and $p_1(t)=1$:\n$$ \\frac{d p_0(t)}{dt} = -\\lambda p_0(t) + \\lambda(1) $$\nThis is a first-order linear ODE: $\\frac{d p_0(t)}{dt} + \\lambda p_0(t) = \\lambda$.\nThe initial condition is $p_0(0)=0$, since the probability of reaching state $1$ within time $0$ from state $0$ is zero.\nThe solution to this initial value problem is $p_0(t) = 1 - \\exp(-\\lambda t)$.\nEvaluating at $t=T$ gives $p_0(T) = 1 - \\exp(-\\lambda T)$, which confirms our result derived from first principles.\n\nThus, the closed-form analytic expression for $p_{\\min}(T)$ is $1 - \\exp(-\\lambda T)$.",
            "answer": "$$\\boxed{1 - \\exp(-\\lambda T)}$$"
        },
        {
            "introduction": "Stochastic hybrid systems couple discrete logic with continuous dynamics that are subject to noise. This practice moves beyond discrete-state models to the analysis of a continuous variable governed by a Stochastic Differential Equation (SDE)—specifically, the Ornstein-Uhlenbeck process, a common model for regulated physical quantities. Your task is to compute the probability that this continuous state will cross a critical safety threshold ('guard') within a given time, a fundamental problem in verifying hybrid systems . This exercise will equip you with the tools to analyze first-passage time properties for SDEs, a cornerstone of probabilistic reachability for continuous dynamics.",
            "id": "4248164",
            "problem": "A cyber-physical system’s digital twin monitors a scalar mode representing a regulated thermal deviation, modeled as an Ornstein–Uhlenbeck stochastic differential equation (SDE) $dx_t = -\\beta (x_t - \\mu)\\,dt + \\sigma\\,dW_t$, where $W_t$ is a standard Wiener process. In this hybrid-system abstraction, a discrete transition (“guard firing”) is triggered when the continuous mode $x_t$ crosses a level $b$, i.e., when $x_t \\geq b$. For probabilistic model checking (PMC), the satisfaction probability of the bounded-time reachability property in Probabilistic Computation Tree Logic (PCTL) is the quantity $\\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} x_s \\geq b\\right)$.\n\nStarting from the fundamental definition of a linear SDE solution and properties of Gaussian processes, do the following:\n- Derive the exact transition density $p(t,x \\mid x_0)$ of $x_t$ for $t>0$ before any guard firing.\n- Compute the probability $\\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} x_s \\geq b\\right)$ for the parameter set\n$$\\beta = 0.5,\\quad \\sigma = 0.8,\\quad \\mu = 5.0,\\quad b = 5.0,\\quad T = 3.0,\\quad x_0 = 1.50504019.$$\nExpress the final probability as a decimal and round your answer to four significant figures.",
            "solution": "The user wants me to solve a problem related to stochastic hybrid systems.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n-   **Model**: An Ornstein–Uhlenbeck stochastic differential equation (SDE): $dx_t = -\\beta (x_t - \\mu)\\,dt + \\sigma\\,dW_t$, where $W_t$ is a standard Wiener process.\n-   **Discrete Transition Condition**: A guard firing occurs when $x_t \\geq b$.\n-   **Quantity to Compute**: The satisfaction probability $\\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} x_s \\geq b\\right)$.\n-   **Tasks**:\n    1.  Derive the exact transition density $p(t,x \\mid x_0)$ of $x_t$ for $t>0$.\n    2.  Compute $\\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} x_s \\geq b\\right)$ for a specific parameter set.\n-   **Parameter Set**:\n    -   $\\beta = 0.5$\n    -   $\\sigma = 0.8$\n    -   $\\mu = 5.0$\n    -   $b = 5.0$\n    -   $T = 3.0$\n    -   $x_0 = 1.50504019$\n-   **Output Format**: The final probability expressed as a decimal, rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Groundedness**: The problem is grounded in the well-established theory of stochastic differential equations, specifically the Ornstein–Uhlenbeck (OU) process, which is a standard model in many STEM fields. The concept of first-passage time probability is a fundamental topic in stochastic processes.\n-   **Well-Posedness**: The problem is well-posed. The derivation of the transition density for a linear SDE like the OU process is a standard procedure. The computation of the first-passage time probability for an OU process is also a solvable, albeit non-trivial, problem with a known analytical solution under the given conditions.\n-   **Objectivity**: The problem is stated in precise, objective mathematical language.\n-   **Completeness and Consistency**: All necessary parameters ($\\beta, \\sigma, \\mu, b, T, x_0$) are provided. There are no contradictions. The problem is self-contained. The special condition $\\mu=b$ simplifies the problem but does not invalidate it.\n-   **Relation to Topic**: The problem is directly relevant to *stochastic hybrid systems and probabilistic model checking*. The OU process represents the continuous dynamics, the guard condition $x_t \\geq b$ represents a discrete transition, and the PCTL reachability probability $\\mathbb{P}(\\lozenge^{\\leq T} (\\text{state} \\geq b))$ is being computed.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with the solution.\n\n---\n\n**Part 1: Derivation of the Transition Density**\n\nThe scalar dynamics are described by the Ornstein–Uhlenbeck SDE:\n$$dx_t = -\\beta (x_t - \\mu)\\,dt + \\sigma\\,dW_t$$\nwith initial condition $x(0) = x_0$. This is a linear SDE. To solve it, we introduce a change of variable, $y_t = x_t - \\mu$. The differential $dy_t$ is simply $dx_t$. Substituting this into the SDE gives:\n$$dy_t = -\\beta y_t\\,dt + \\sigma\\,dW_t$$\nThis is a homogeneous linear SDE. We can solve it using an integrating factor, $f(t) = \\exp(\\beta t)$. Let $Z_t = f(t) y_t = \\exp(\\beta t) y_t$. Using Itô's product rule for $dZ_t$:\n$$dZ_t = (\\frac{\\partial Z_t}{\\partial t}) dt + (\\frac{\\partial Z_t}{\\partial y_t}) dy_t + \\frac{1}{2}(\\frac{\\partial^2 Z_t}{\\partial y_t^2}) (dy_t)^2$$\nSince $Z_t$ is linear in $y_t$, the second-order derivative is zero. The terms are:\n- $\\frac{\\partial Z_t}{\\partial t} = \\beta \\exp(\\beta t) y_t$\n- $\\frac{\\partial Z_t}{\\partial y_t} = \\exp(\\beta t)$\n\n$$dZ_t = \\beta \\exp(\\beta t) y_t\\,dt + \\exp(\\beta t)\\,dy_t$$\nSubstituting $dy_t = -\\beta y_t\\,dt + \\sigma\\,dW_t$:\n$$dZ_t = \\beta \\exp(\\beta t) y_t\\,dt + \\exp(\\beta t)(-\\beta y_t\\,dt + \\sigma\\,dW_t)$$\n$$dZ_t = \\beta \\exp(\\beta t) y_t\\,dt - \\beta \\exp(\\beta t) y_t\\,dt + \\sigma \\exp(\\beta t)\\,dW_t$$\nThe $dt$ terms cancel, leaving:\n$$dZ_t = \\sigma \\exp(\\beta t)\\,dW_t$$\nIntegrating from $s=0$ to $s=t$:\n$$Z_t - Z_0 = \\int_0^t \\sigma \\exp(\\beta s)\\,dW_s$$\nSubstituting back $Z_t = \\exp(\\beta t) y_t$ and $Z_0 = \\exp(0) y_0 = y_0$:\n$$\\exp(\\beta t) y_t - y_0 = \\sigma \\int_0^t \\exp(\\beta s)\\,dW_s$$\n$$y_t = y_0 \\exp(-\\beta t) + \\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s$$\nFinally, substituting back $y_t = x_t - \\mu$ and $y_0 = x_0 - \\mu$:\n$$x_t - \\mu = (x_0 - \\mu) \\exp(-\\beta t) + \\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s$$\n$$x_t = \\mu + (x_0 - \\mu) \\exp(-\\beta t) + \\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s$$\nThis expression shows that $x_t$ is a Gaussian process, as it is a sum of a deterministic term and an Itô integral with a deterministic integrand. The distribution of $x_t$ given $x_0$ is therefore normal, and is fully characterized by its mean and variance.\n\nThe conditional mean is $M(t) = \\mathbb{E}[x_t | x_0]$:\n$$\\mathbb{E}[x_t | x_0] = \\mathbb{E}\\left[\\mu + (x_0 - \\mu) \\exp(-\\beta t) + \\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s\\right]$$\nSince the expectation of the Itô integral is zero,\n$$M(t) = \\mu + (x_0 - \\mu) \\exp(-\\beta t)$$\nThe conditional variance is $V(t) = \\text{Var}(x_t | x_0)$:\n$$V(t) = \\text{Var}\\left(\\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s\\right)$$\nUsing Itô isometry, $\\text{Var}\\left(\\int_0^t f(s)\\,dW_s\\right) = \\int_0^t f(s)^2\\,ds$:\n$$V(t) = \\sigma^2 \\int_0^t \\exp(-2\\beta(t-s))\\,ds = \\sigma^2 \\exp(-2\\beta t) \\int_0^t \\exp(2\\beta s)\\,ds$$\n$$V(t) = \\sigma^2 \\exp(-2\\beta t) \\left[\\frac{\\exp(2\\beta s)}{2\\beta}\\right]_{s=0}^{s=t} = \\sigma^2 \\exp(-2\\beta t) \\frac{\\exp(2\\beta t)-1}{2\\beta}$$\n$$V(t) = \\frac{\\sigma^2}{2\\beta} (1 - \\exp(-2\\beta t))$$\nThus, the process $x_t$ conditional on $x_0$ follows a normal distribution $x_t | x_0 \\sim \\mathcal{N}(M(t), V(t))$. The transition density $p(t, x | x_0)$ is the probability density function of this distribution:\n$$p(t,x | x_0) = \\frac{1}{\\sqrt{2\\pi V(t)}} \\exp\\left(-\\frac{(x - M(t))^2}{2V(t)}\\right)$$\nwhere $M(t) = \\mu + (x_0 - \\mu) \\exp(-\\beta t)$ and $V(t) = \\frac{\\sigma^2}{2\\beta} (1 - \\exp(-2\\beta t))$.\n\n**Part 2: Computation of the Reachability Probability**\n\nWe need to compute $\\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} x_s \\geq b\\right)$ for the given parameters:\n$\\beta = 0.5$, $\\sigma = 0.8$, $\\mu = 5.0$, $b = 5.0$, $T = 3.0$, $x_0 = 1.50504019$.\n\nA key feature of the parameter set is that the mean reversion level $\\mu$ is equal to the barrier level $b$. This simplifies the problem. Let us define a new process $y_t = x_t - b$. Since $b=\\mu$, this is the same as $y_t = x_t - \\mu$. The SDE for $y_t$ is:\n$$dy_t = -\\beta y_t\\,dt + \\sigma\\,dW_t$$\nThe initial condition is $y_0 = x_0 - b = 1.50504019 - 5.0 = -3.49495981$.\nThe reachability condition $x_s \\geq b$ becomes $y_s + b \\geq b$, which simplifies to $y_s \\geq 0$.\nWe must therefore compute the probability that the process $y_t$, starting from $y_0 < 0$, reaches or exceeds the level $0$ in the time interval $[0, T]$:\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq s \\leq T} y_s \\geq 0 \\mid y_0\\right)$$\nThis is a first-passage time problem for the OU process. We can solve it by transforming the OU process into a time-changed Wiener process. From Part 1, the solution for $y_t$ (with $\\mu=0$) is:\n$$y_t = y_0 \\exp(-\\beta t) + \\sigma \\int_0^t \\exp(-\\beta(t-s))\\,dW_s$$\nLet $Z_t = \\exp(\\beta t) y_t$. Then $dZ_t = \\sigma \\exp(\\beta t)\\,dW_t$, and $Z_t = y_0 + \\sigma \\int_0^t \\exp(\\beta s)\\,dW_s$.\nLet $\\tau(t) = \\int_0^t \\exp(2\\beta s)\\,ds = \\frac{\\exp(2\\beta t)-1}{2\\beta}$.\nBy the Dambis-Dubins-Schwarz theorem, the process $B_{\\tau(t)} = \\int_0^t \\exp(\\beta s)\\,dW_s$ is a standard Wiener process.\nSo, $Z_t = y_0 + \\sigma B_{\\tau(t)}$.\nThe original probability is:\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq t \\leq T} \\exp(-\\beta t)Z_t \\geq 0 \\mid y_0\\right)$$\nSince $\\exp(-\\beta t) > 0$ for all $t$, this is equivalent to:\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq t \\leq T} Z_t \\geq 0 \\mid y_0\\right)$$\nSubstituting the expression for $Z_t$:\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq t \\leq T} (y_0 + \\sigma B_{\\tau(t)}) \\geq 0\\right)$$\nThe time change $\\tau(t)$ is a strictly increasing function. As $t$ varies from $0$ to $T$, the new time variable $u = \\tau(t)$ varies from $\\tau(0)=0$ to $S \\equiv \\tau(T) = \\frac{\\exp(2\\beta T)-1}{2\\beta}$. The supremum over the interval $[0,T]$ in $t$ corresponds to a supremum over $[0,S]$ in $u$.\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq u \\leq S} (y_0 + \\sigma B_u) \\geq 0\\right)$$\n$$\\implies P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq u \\leq S} \\sigma B_u \\geq -y_0\\right)$$\nSince $\\sigma>0$, we can divide by it:\n$$P = \\mathbb{P}\\!\\left(\\sup_{0 \\leq u \\leq S} B_u \\geq \\frac{-y_0}{\\sigma}\\right)$$\nLet $a = -y_0/\\sigma$. Since $y_0 < 0$, we have $a > 0$. The problem reduces to finding the probability that a standard Wiener process $B_u$ starting at $0$ reaches level $a>0$ by time $S$. By the reflection principle for Brownian motion, this probability is given by:\n$$P(\\sup_{0 \\leq u \\leq S} B_u \\geq a) = 2 \\mathbb{P}(B_S \\geq a)$$\nThe position of the Wiener process at time $S$, $B_S$, is a normal random variable with mean $0$ and variance $S$, i.e., $B_S \\sim \\mathcal{N}(0,S)$. Let $Z \\sim \\mathcal{N}(0,1)$ be a standard normal variable.\n$$\\mathbb{P}(B_S \\geq a) = \\mathbb{P}\\left(\\frac{B_S}{\\sqrt{S}} \\geq \\frac{a}{\\sqrt{S}}\\right) = \\mathbb{P}\\left(Z \\geq \\frac{a}{\\sqrt{S}}\\right) = 1 - \\Phi\\left(\\frac{a}{\\sqrt{S}}\\right) = \\Phi\\left(-\\frac{a}{\\sqrt{S}}\\right)$$\nwhere $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution.\nThe final probability is:\n$$P = 2 \\Phi\\left(-\\frac{a}{\\sqrt{S}}\\right)$$\nNow we substitute the numerical values:\n- $y_0= -3.49495981$\n- $\\beta = 0.5$\n- $\\sigma = 0.8$\n- $T = 3.0$\n\nCalculate $a$ and $S$:\n$$a = -\\frac{y_0}{\\sigma} = -\\frac{-3.49495981}{0.8} = 4.3686997625$$\n$$S = \\frac{\\exp(2\\beta T) - 1}{2\\beta} = \\frac{\\exp(2 \\times 0.5 \\times 3.0) - 1}{2 \\times 0.5} = \\frac{\\exp(3)-1}{1} = \\exp(3)-1$$\nLet's evaluate the argument of $\\Phi$:\n$$\\frac{a}{\\sqrt{S}} = \\frac{4.3686997625}{\\sqrt{\\exp(3)-1}}$$\nWe note that the value of $x_0$ seems specifically chosen. Let's test the hypothesis that $a/\\sqrt{S} = 1$. This would mean $a^2 = S$.\n$$a^2 = (4.3686997625)^2 \\approx 19.0855369$$\n$$S = \\exp(3) - 1 \\approx 20.0855369 - 1 = 19.0855369$$\nThe values match to high precision. The slight discrepancy arises from the finite precision of the given $x_0$. We conclude that the problem is designed such that $a/\\sqrt{S} = 1$.\nThe argument of the CDF is $-a/\\sqrt{S} = -1$.\nThe probability is:\n$$P = 2 \\Phi(-1)$$\nUsing the symmetry of the normal distribution, $\\Phi(-1) = 1 - \\Phi(1)$. The value of $\\Phi(1)$ is related to the error function, $\\Phi(z) = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)$.\nNumerically, $\\Phi(-1) \\approx 0.15865525$.\n$$P \\approx 2 \\times 0.15865525 = 0.3173105$$\nRounding the result to four significant figures gives $0.3173$.",
            "answer": "$$\\boxed{0.3173}$$"
        }
    ]
}