{
    "hands_on_practices": [
        {
            "introduction": "Before deploying a learning-enabled component in a safety-critical Cyber-Physical System (CPS), we must first quantify its sensitivity to input perturbations. This practice introduces the concept of the Lipschitz constant, a powerful mathematical tool for bounding the output change of a function with respect to its input. You will implement a standard numerical method to compute an upper bound on the global Lipschitz constant for a neural network, which in turn provides a certifiable guarantee of its robustness against adversarial attacks .",
            "id": "4204838",
            "problem": "Consider a learning-enabled controller within a Cyber-Physical System (CPS) that is mirrored by a Digital Twin, where the controller is implemented as a feedforward neural network with fully connected layers and Rectified Linear Unit (ReLU) activations between layers. Robustness of the network to adversarial perturbations is assessed under the $\\ell_2$ norm. You must design a program to compute, for each given network and input, an upper bound on the global Lipschitz constant via spectral norms, and use it to predict whether the classification is certifiably robust at a specified perturbation radius.\n\nFundamental basis and definitions:\n- The induced operator norm of a matrix $A$ under the $\\ell_2$ norm equals its spectral norm, which is the largest singular value.\n- The spectral norm of $A$ is $\\sigma_{\\max}(A) = \\sqrt{\\lambda_{\\max}(A^\\top A)}$, where $\\lambda_{\\max}$ denotes the largest eigenvalue.\n- The Lipschitz constant of an affine layer $x \\mapsto Ax + b$ under the $\\ell_2$ norm is $\\sigma_{\\max}(A)$; the bias $b$ does not affect the Lipschitz constant.\n- The ReLU activation is $x \\mapsto \\max(0, x)$ and has Lipschitz constant $1$ under the $\\ell_2$ norm.\n- For a composition of functions $f = f_n \\circ \\cdots \\circ f_1$, an upper bound on the Lipschitz constant is the product of the individual upper bounds.\n- Let $f(x)$ denote the output logits vector of the network for input $x$. Define the logit margin $m(x)$ as the difference between the largest and second-largest component of $f(x)$. A sufficient condition for certifiable robustness to any $\\ell_2$ perturbation of radius $\\epsilon$ is $\\epsilon  \\frac{m(x)}{L}$, where $L$ is an upper bound on the global Lipschitz constant.\n\nAlgorithmic requirement:\n- Implement power iteration to approximate $\\sigma_{\\max}(A)$ by iterating on $A^\\top A$:\n  - Initialize a nonzero vector $u_0$ in $\\mathbb{R}^d$, where $d$ is the number of columns of $A$, and normalize it to unit norm.\n  - For $k = 0, 1, \\dots$ up to a maximum number of iterations, compute $v_{k+1} = (A^\\top A) u_k$, set $u_{k+1} = v_{k+1} / \\|v_{k+1}\\|_2$, and stop when $\\|u_{k+1} - u_k\\|_2$ is below a tolerance.\n  - Estimate $\\lambda_{\\max} \\approx u^\\top (A^\\top A) u$ and return $\\sigma_{\\max}(A) \\approx \\sqrt{\\lambda_{\\max}}$.\n- Use the product of the layer spectral norms to bound the global Lipschitz constant, treating ReLU layers as having Lipschitz constant $1$.\n- The final layer must be affine (i.e., linear transformation plus bias); do not apply ReLU after the final layer so that outputs are logits.\n- For each test case, compute the list of spectral norms per layer, the global Lipschitz upper bound $L$, the margin $m(x)$, and whether the robustness certificate holds at the specified $\\epsilon$ using the strict inequality $\\epsilon  \\frac{m(x)}{L}$.\n- If $L = 0$, then the network output is constant with respect to the input, and the classification is certifiably robust for any finite $\\epsilon$.\n\nNumerical parameters for power iteration:\n- Maximum iterations: $1000$.\n- Tolerance: $1\\times 10^{-10}$.\n- Initialize $u_0$ by normalizing a vector of ones.\n\nNetworks, inputs, and perturbation radii (all quantities are dimensionless; no physical units are involved):\n\nTest Case $1$ (two-layer network, two-class logits):\n- Layer $1$: weight matrix\n  $$\n  W_1 =\n  \\begin{bmatrix}\n  1.0  0.5 \\\\\n  -0.3  0.8\n  \\end{bmatrix},\n  $$\n  bias $b_1 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}$.\n- Layer $2$: weight matrix\n  $$\n  W_2 =\n  \\begin{bmatrix}\n  0.7  -0.4 \\\\\n  0.3  0.9\n  \\end{bmatrix},\n  $$\n  bias $b_2 = \\begin{bmatrix} 0.05 \\\\ -0.1 \\end{bmatrix}$.\n- Input $x = \\begin{bmatrix} 0.6 \\\\ -1.2 \\end{bmatrix}$.\n- Perturbation radius $\\epsilon = 0.2$.\n\nTest Case $2$ (three-layer network, three-class logits, boundary condition where $\\epsilon$ equals the certified radius):\n- Layer $1$: weight matrix\n  $$\n  W_1 =\n  \\begin{bmatrix}\n  1.2  -0.7  0.3 \\\\\n  0.5  0.9  -1.1 \\\\\n  -0.4  0.2  0.8\n  \\end{bmatrix},\n  $$\n  bias $b_1 = \\begin{bmatrix} 0.1 \\\\ -0.05 \\\\ 0.2 \\end{bmatrix}$.\n- Layer $2$: weight matrix\n  $$\n  W_2 =\n  \\begin{bmatrix}\n  0.6  0.0  -0.3 \\\\\n  0.2  -0.5  1.0 \\\\\n  0.7  0.4  -0.6\n  \\end{bmatrix},\n  $$\n  bias $b_2 = \\begin{bmatrix} 0.0 \\\\ 0.1 \\\\ -0.1 \\end{bmatrix}$.\n- Layer $3$: weight matrix\n  $$\n  W_3 =\n  \\begin{bmatrix}\n  0.9  -0.2  0.5 \\\\\n  -0.3  0.8  0.1 \\\\\n  0.4  0.3  -0.7\n  \\end{bmatrix},\n  $$\n  bias $b_3 = \\begin{bmatrix} 0.05 \\\\ -0.05 \\\\ 0.0 \\end{bmatrix}$.\n- Input $x = \\begin{bmatrix} 0.3 \\\\ -0.8 \\\\ 1.1 \\end{bmatrix}$.\n- Perturbation radius $\\epsilon$ set equal to the certified radius $\\frac{m(x)}{L}$ computed from the network and input.\n\nTest Case $3$ (single-layer network with zero weights to test the $L=0$ edge case, two-class logits):\n- Layer $1$: weight matrix\n  $$\n  W_1 =\n  \\begin{bmatrix}\n  0.0  0.0 \\\\\n  0.0  0.0\n  \\end{bmatrix},\n  $$\n  bias $b_1 = \\begin{bmatrix} 1.0 \\\\ -2.0 \\end{bmatrix}$.\n- Input $x = \\begin{bmatrix} 100.0 \\\\ -50.0 \\end{bmatrix}$.\n- Perturbation radius $\\epsilon = 10.0$.\n\nRequired outputs and format:\n- For each test case, output a list containing:\n  - The list of spectral norms of the weight matrices for each layer in order.\n  - The global Lipschitz upper bound $L$ (the product of the spectral norms).\n  - The margin $m(x)$ (largest logit minus second-largest logit).\n  - The boolean decision of certifiable robustness at the specified $\\epsilon$ under the strict inequality.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, without any whitespace, where each test case result is itself enclosed in square brackets. For example: `[[\\text{sn_list},L,m,\\text{robust}],[\\dots],[\\dots]]`.\n\nYour task:\n- Implement the described computations exactly.\n- Ensure numerical stability in the power iteration with the specified tolerance and maximum iterations.\n- Handle the $L=0$ case according to the definition above.",
            "solution": "The problem is deemed valid. It is scientifically grounded in the principles of numerical linear algebra and the theory of adversarial robustness in neural networks. The problem is well-posed, with all necessary data, definitions, and algorithms explicitly provided. The language is objective and precise, and the setup is self-contained and consistent.\n\nThe task is to compute an upper bound on the $\\ell_2$ Lipschitz constant for several feedforward neural networks and use it to certify their robustness against adversarial perturbations. The solution involves three main components: calculating the spectral norm of layer weight matrices using the power iteration method, computing the network's forward pass to find the output logits and margin, and applying the given robustness certificate.\n\nLet a feedforward neural network be a composition of $n$ functions, $f = f_n \\circ \\dots \\circ f_1$. The network consists of affine transformations and ReLU activations. An affine layer is of the form $f_i(z) = W_i z + b_i$, and a ReLU activation is applied element-wise, $\\text{ReLU}(z)_j = \\max(0, z_j)$. The final layer is affine, producing logits. The problem specifies a network structure of alternating affine transformations and ReLU activations:\n$$ f(x) = f_n \\circ g_{n-1} \\circ \\dots \\circ g_1 \\circ f_1(x) $$\nwhere $f_i(z) = W_i z + b_i$ are affine layers and $g_i(z) = \\text{ReLU}(z)$ are activation functions. The final layer $f_n$ has no subsequent ReLU activation.\n\nThe Lipschitz constant of a function $h$ under the $\\ell_2$ norm, denoted $L(h)$, is the smallest value such that $\\|h(x) - h(y)\\|_2 \\le L(h) \\|x - y\\|_2$ for all $x,y$. An upper bound on the Lipschitz constant of the composite function $f$ can be found by multiplying the Lipschitz constants of its constituent functions:\n$$ L(f) \\le L(f_n) \\cdot L(g_{n-1}) \\cdot \\dots \\cdot L(g_1) \\cdot L(f_1) $$\nThe Lipschitz constant of the affine layer $f_i(z) = W_i z + b_i$ is the spectral norm of the weight matrix, $L(f_i) = \\sigma_{\\max}(W_i)$. The bias $b_i$ does not affect the Lipschitz constant. The ReLU activation has a Lipschitz constant of $L(g_i) = 1$. Therefore, an upper bound on the global Lipschitz constant of the network is the product of the spectral norms of a network's weight matrices:\n$$ L = \\prod_{i=1}^{n} \\sigma_{\\max}(W_i) $$\n\nThe spectral norm $\\sigma_{\\max}(A)$ of a matrix $A$ is its largest singular value, which is the square root of the largest eigenvalue $\\lambda_{\\max}$ of the positive semi-definite matrix $A^\\top A$. We will compute this using the power iteration method as specified.\nThe power iteration algorithm for finding the largest eigenvalue of a matrix $M = A^\\top A$ is as follows:\n1. Initialize a random non-zero vector $u_0$ and normalize it: $u_0 = u_0 / \\|u_0\\|_2$. The problem specifies initializing with a vector of ones.\n2. Iterate for $k = 0, 1, 2, \\dots$ up to a maximum number of iterations:\n   a. Compute the next vector in the sequence: $v_{k+1} = M u_k = (A^\\top A) u_k$.\n   b. Normalize the new vector: $u_{k+1} = v_{k+1} / \\|v_{k+1}\\|_2$.\n   c. Check for convergence: if $\\|u_{k+1} - u_k\\|_2$ is below a tolerance, stop.\n3. Once the iteration converges to the dominant eigenvector $u$, the corresponding eigenvalue $\\lambda_{\\max}$ can be estimated using the Rayleigh quotient: $\\lambda_{\\max} \\approx u^\\top M u$.\n4. The spectral norm is then $\\sigma_{\\max}(A) = \\sqrt{\\lambda_{\\max}}$.\n\nAfter computing the global Lipschitz upper bound $L$, we perform a forward pass of the input $x$ through the network to obtain the output logit vector $f(x)$. The logit margin $m(x)$ is defined as the difference between the largest and the second-largest logit values.\nA sufficient condition for certifiable robustness is that for any perturbation $\\delta$ with $\\|\\delta\\|_2 \\le \\epsilon$, the classification of $x+\\delta$ remains the same as for $x$. This is guaranteed if the perturbation radius $\\epsilon$ satisfies the strict inequality:\n$$ \\epsilon  \\frac{m(x)}{L} $$\nIf $L=0$, the network's output is constant (independent of the input), as all weight matrices have zero spectral norm, implying they are zero matrices. In this case, the classification cannot change, and the network is certifiably robust for any finite $\\epsilon$.\n\nWe now apply this procedure to each test case.\n\n**Test Case 1:**\n- Layers: $f(x) = (W_2 \\cdot \\text{ReLU}(W_1 x + b_1) + b_2)$\n- $W_1 = \\begin{bmatrix} 1.0  0.5 \\\\ -0.3  0.8 \\end{bmatrix}, b_1 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}$\n- $W_2 = \\begin{bmatrix} 0.7  -0.4 \\\\ 0.3  0.9 \\end{bmatrix}, b_2 = \\begin{bmatrix} 0.05 \\\\ -0.1 \\end{bmatrix}$\n- $x = \\begin{bmatrix} 0.6 \\\\ -1.2 \\end{bmatrix}, \\epsilon = 0.2$\n\n1.  **Spectral Norms:**\n    -   For $W_1$: Compute $\\sigma_{\\max}(W_1)$ via power iteration.\n    -   For $W_2$: Compute $\\sigma_{\\max}(W_2)$ via power iteration.\n2.  **Global Lipschitz Bound:** $L = \\sigma_{\\max}(W_1) \\cdot \\sigma_{\\max}(W_2)$.\n3.  **Forward Pass:**\n    -   $z_0 = W_1 x + b_1 = \\begin{bmatrix} 1.0  0.5 \\\\ -0.3  0.8 \\end{bmatrix} \\begin{bmatrix} 0.6 \\\\ -1.2 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix} = \\begin{bmatrix} 0.0 \\\\ -1.14 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix} = \\begin{bmatrix} 0.1 \\\\ -1.34 \\end{bmatrix}$.\n    -   $z_1 = \\text{ReLU}(z_0) = \\begin{bmatrix} \\max(0, 0.1) \\\\ \\max(0, -1.34) \\end{bmatrix} = \\begin{bmatrix} 0.1 \\\\ 0.0 \\end{bmatrix}$.\n    -   $f(x) = W_2 z_1 + b_2 = \\begin{bmatrix} 0.7  -0.4 \\\\ 0.3  0.9 \\end{bmatrix} \\begin{bmatrix} 0.1 \\\\ 0.0 \\end{bmatrix} + \\begin{bmatrix} 0.05 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 0.07 \\\\ 0.03 \\end{bmatrix} + \\begin{bmatrix} 0.05 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 0.12 \\\\ -0.07 \\end{bmatrix}$.\n4.  **Margin:** The logits are $0.12$ and $-0.07$. The margin is $m(x) = 0.12 - (-0.07) = 0.19$.\n5.  **Robustness Check:** Compare $\\epsilon = 0.2$ with $m(x)/L = 0.19 / L$.\n\n**Test Case 2:**\n- Layers: $f(x) = W_3 \\cdot \\text{ReLU}(W_2 \\cdot \\text{ReLU}(W_1 x + b_1) + b_2) + b_3$\n- $W_1, b_1, W_2, b_2, W_3, b_3$ are given $3 \\times 3$ and $3 \\times 1$ matrices.\n- $x = \\begin{bmatrix} 0.3 \\\\ -0.8 \\\\ 1.1 \\end{bmatrix}$.\n\n1.  **Spectral Norms:** Compute $\\sigma_{\\max}(W_1)$, $\\sigma_{\\max}(W_2)$, and $\\sigma_{\\max}(W_3)$ via power iteration.\n2.  **Global Lipschitz Bound:** $L = \\sigma_{\\max}(W_1) \\cdot \\sigma_{\\max}(W_2) \\cdot \\sigma_{\\max}(W_3)$.\n3.  **Forward Pass:** Propagate $x$ through the network to find logits $f(x)$.\n4.  **Margin:** Compute $m(x)$ from the three output logits.\n5.  **Robustness Check:** The problem states to set $\\epsilon = m(x)/L$. The condition for robustness is the strict inequality $\\epsilon  m(x)/L$. Since $\\epsilon$ is set to be equal to the right-hand side, the condition $\\epsilon  \\epsilon$ will be false. The robustness certificate will not hold.\n\n**Test Case 3:**\n- Layers: $f(x) = W_1 x + b_1$\n- $W_1 = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}, b_1 = \\begin{bmatrix} 1.0 \\\\ -2.0 \\end{bmatrix}$\n- $x = \\begin{bmatrix} 100.0 \\\\ -50.0 \\end{bmatrix}, \\epsilon = 10.0$\n\n1.  **Spectral Norm:** The spectral norm of a zero matrix is $0$. So, $\\sigma_{\\max}(W_1) = 0$.\n2.  **Global Lipschitz Bound:** $L = \\sigma_{\\max}(W_1) = 0$.\n3.  **Forward Pass:** $f(x) = W_1 x + b_1 = 0 \\cdot x + b_1 = b_1 = \\begin{bmatrix} 1.0 \\\\ -2.0 \\end{bmatrix}$. The output is constant.\n4.  **Margin:** The logits are $1.0$ and $-2.0$. The margin is $m(x) = 1.0 - (-2.0) = 3.0$.\n5.  **Robustness Check:** The problem states that if $L=0$, the classification is certifiably robust for any finite $\\epsilon$. Since $\\epsilon = 10.0$ is finite, the condition holds. The result is `True`.\n\nThese steps will be implemented in the provided Python code.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of certifying neural network robustness.\n    \"\"\"\n\n    def power_iteration(A, max_iter=1000, tol=1e-10):\n        \"\"\"\n        Computes the spectral norm of a matrix A using power iteration.\n        The spectral norm is the largest singular value, sigma_max(A),\n        which is sqrt(lambda_max(A.T @ A)).\n        \"\"\"\n        if A.shape[1] == 0:\n            return 0.0\n        \n        # Power iteration on A.T @ A to find its largest eigenvalue.\n        M = A.T @ A\n        \n        # Initialize a vector u_0 from a vector of ones, normalized.\n        u = np.ones(M.shape[1])\n        u = u / np.linalg.norm(u)\n\n        for _ in range(max_iter):\n            v = M @ u\n            u_new = v / np.linalg.norm(v)\n\n            if np.linalg.norm(u_new - u)  tol:\n                break\n            \n            u = u_new\n        \n        # Estimate lambda_max using the Rayleigh quotient: u.T @ M @ u\n        # where u is the approximated eigenvector.\n        lambda_max = u.T @ M @ u\n        \n        # The spectral norm is the square root of the largest eigenvalue.\n        # Add a small epsilon to handle potential floating-point inaccuracies\n        # resulting in a tiny negative number.\n        spectral_norm = np.sqrt(max(0, lambda_max))\n        return spectral_norm\n\n    test_cases = [\n        {\n            \"weights\": [\n                np.array([[1.0, 0.5], [-0.3, 0.8]]),\n                np.array([[0.7, -0.4], [0.3, 0.9]])\n            ],\n            \"biases\": [\n                np.array([0.1, -0.2]),\n                np.array([0.05, -0.1])\n            ],\n            \"input\": np.array([0.6, -1.2]),\n            \"epsilon\": 0.2\n        },\n        {\n            \"weights\": [\n                np.array([[1.2, -0.7, 0.3], [0.5, 0.9, -1.1], [-0.4, 0.2, 0.8]]),\n                np.array([[0.6, 0.0, -0.3], [0.2, -0.5, 1.0], [0.7, 0.4, -0.6]]),\n                np.array([[0.9, -0.2, 0.5], [-0.3, 0.8, 0.1], [0.4, 0.3, -0.7]])\n            ],\n            \"biases\": [\n                np.array([0.1, -0.05, 0.2]),\n                np.array([0.0, 0.1, -0.1]),\n                np.array([0.05, -0.05, 0.0])\n            ],\n            \"input\": np.array([0.3, -0.8, 1.1]),\n            \"epsilon\": None  # To be computed\n        },\n        {\n            \"weights\": [\n                np.array([[0.0, 0.0], [0.0, 0.0]])\n            ],\n            \"biases\": [\n                np.array([1.0, -2.0])\n            ],\n            \"input\": np.array([100.0, -50.0]),\n            \"epsilon\": 10.0\n        }\n    ]\n\n    all_results = []\n\n    for i, case in enumerate(test_cases):\n        weights = case[\"weights\"]\n        biases = case[\"biases\"]\n        x = case[\"input\"]\n        epsilon = case[\"epsilon\"]\n\n        # 1. Compute spectral norms and global Lipschitz bound L\n        spectral_norms = [power_iteration(w) for w in weights]\n        lipschitz_bound = np.prod(spectral_norms)\n\n        # 2. Perform the forward pass\n        current_val = x\n        # Hidden layers with ReLU\n        for j in range(len(weights) - 1):\n            current_val = weights[j] @ current_val + biases[j]\n            current_val = np.maximum(0, current_val)\n        # Final affine layer (logits)\n        logits = weights[-1] @ current_val + biases[-1]\n\n        # 3. Compute the margin\n        if len(logits)  2:\n            # Undefined for single-class output\n            margin = float('inf') \n        else:\n            sorted_logits = np.sort(logits)\n            margin = sorted_logits[-1] - sorted_logits[-2]\n\n        # 4. Handle special epsilon for Test Case 2\n        if i == 1: # Test Case 2\n            if lipschitz_bound  0:\n                epsilon = margin / lipschitz_bound\n            else: # Should not happen in this case, but for correctness\n                epsilon = float('inf')\n\n        # 5. Check the robustness certificate\n        if lipschitz_bound == 0:\n            # If L=0, output is constant, robust for any finite epsilon\n            is_robust = True\n        else:\n            # Strict inequality is required\n            is_robust = epsilon  margin / lipschitz_bound\n\n        all_results.append([spectral_norms, lipschitz_bound, margin, is_robust])\n\n    # Format the final output string to match the required format without spaces\n    result_strings = []\n    for sn_list, L, m, robust in all_results:\n        sn_list_str = f\"[{','.join(f'{sn:.15f}' for sn in sn_list)}]\"\n        # Format to remove unnecessary trailing zeros and ensure high precision\n        L_str = f\"{L:.15f}\"\n        m_str = f\"{m:.15f}\"\n        robust_str = str(robust)\n        case_result_str = f\"[{sn_list_str},{L_str},{m_str},{robust_str}]\"\n        result_strings.append(case_result_str)\n\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "A robust controller is necessary but not sufficient for system-wide safety; the true behavior of a CPS emerges from the dynamic interaction between the controller and the physical plant. This exercise moves from analyzing a single component to verifying the entire closed-loop system. You will propagate uncertainty from adversarial sensor inputs through both the neural network policy and the plant dynamics to certify whether a critical safety constraint is met, a technique known as reachability analysis that forms a cornerstone of formal verification for learning-enabled systems .",
            "id": "4204835",
            "problem": "Consider a discrete-time linear time-invariant plant controlled by a learning-enabled policy inside a Digital Twin of a Cyber-Physical System (CPS). The plant state is $x_t \\in \\mathbb{R}^2$, the control input is $u_t \\in \\mathbb{R}$, and the observed measurement is $y_t \\in \\mathbb{R}^2$. The dynamics are\n$$\nx_{t+1} = A x_t + B u_t + w_t,\n$$\nwhere $A \\in \\mathbb{R}^{2 \\times 2}$, $B \\in \\mathbb{R}^{2 \\times 1}$, and $w_t$ is an exogenous disturbance vector. The measurement is corrupted by adversarial sensor noise $\\delta_t$ so that\n$$\ny_t = x_t + \\delta_t.\n$$\nThe control input is generated by a feedforward Artificial Neural Network (ANN) with a single hidden layer and Rectified Linear Unit (ReLU) activation, which maps $y_t$ to $u_t = \\pi(y_t)$. The adversary chooses $\\delta_t$ within an elementwise interval budget and the environment injects $w_t$ within an elementwise interval budget. We seek a certified safety guarantee by over-approximating the reachable sets under these adversarial choices.\n\nFundamental basis:\n- The set-propagation of an affine map $z = W a + b$, where $a$ lies in an elementwise interval $[l,u]$, is bounded by the following monotonicity-based enclosure. Let $W^+ = \\max(W,0)$ and $W^- = \\min(W,0)$ be the elementwise nonnegative and nonpositive parts of $W$. Then the image interval $[l_z, u_z]$ is\n$$\nl_z = W^+ l + W^- u + b, \\quad u_z = W^+ u + W^- l + b.\n$$\n- The ReLU operation $\\mathrm{ReLU}(z) = \\max(0,z)$ is monotone elementwise, so if $z \\in [l,u]$ elementwise, then $\\mathrm{ReLU}(z) \\in [\\max(0,l), \\max(0,u)]$ elementwise.\n- The Minkowski sum of intervals satisfies $[l_1,u_1] + [l_2,u_2] = [l_1 + l_2, u_1 + u_2]$ elementwise.\n\nController architecture and parameters:\n- The hidden layer has $4$ units, with weights $W_1 \\in \\mathbb{R}^{4 \\times 2}$ and bias $b_1 \\in \\mathbb{R}^{4}$ given by\n$$\nW_1 = \\begin{bmatrix}\n1  0\\\\\n-1  0\\\\\n0  1\\\\\n0  -1\n\\end{bmatrix}, \\quad b_1 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}.\n$$\n- The output layer has weights $W_2 \\in \\mathbb{R}^{1 \\times 4}$ and bias $b_2 \\in \\mathbb{R}$ given by\n$$\nW_2 = \\begin{bmatrix} -1  1  -0.5  0.5 \\end{bmatrix}, \\quad b_2 = 0.\n$$\n- The activation is $\\mathrm{ReLU}$ between the layers, so for any input $y \\in \\mathbb{R}^2$,\n$$\nu = \\pi(y) = W_2 \\, \\mathrm{ReLU}(W_1 y + b_1) + b_2.\n$$\nThis network implements a piecewise-linear approximation of $u \\approx -x_1 - 0.5 x_2$.\n\nPlant model:\n- The plant matrices correspond to a discretized double integrator with sampling period $h = 0.1$,\n$$\nA = \\begin{bmatrix}\n1  0.1\\\\\n0  1\n\\end{bmatrix}, \\quad\nB = \\begin{bmatrix}\n0.005\\\\\n0.1\n\\end{bmatrix}.\n$$\n\nAdversarial input and disturbance sets:\n- The adversary can perturb each component of the observation within an elementwise bound $\\varepsilon \\ge 0$, so that $\\delta_t \\in [-\\varepsilon, \\varepsilon]^2$ for all $t$.\n- The disturbance lies in an elementwise interval $w_t \\in [-\\bar{w}, \\bar{w}]^2$ for all $t$, where $\\bar{w} \\ge 0$ is a given scalar bound applied to both state components.\n\nInitial set:\n- The initial states lie in a box $x_0 \\in [\\underline{x}_0, \\overline{x}_0]$ with\n$$\n\\underline{x}_0 = \\begin{bmatrix} 0.045\\\\ -0.005 \\end{bmatrix}, \\quad\n\\overline{x}_0 = \\begin{bmatrix} 0.055\\\\ 0.005 \\end{bmatrix}.\n$$\n\nSafety specification:\n- The safety constraint requires that the position component $x_{t,1}$ satisfy $|x_{t,1}| \\le p_{\\max}$ for all times $t \\in \\{0,1,\\dots,T\\}$, that is, the polyhedral set\n$$\n\\mathcal{S}(p_{\\max}) = \\{ x \\in \\mathbb{R}^2 : C x \\le d \\}, \\quad\nC = \\begin{bmatrix} 1  0\\\\ -1  0 \\end{bmatrix}, \\quad\nd = \\begin{bmatrix} p_{\\max}\\\\ p_{\\max} \\end{bmatrix}.\n$$\n\nCertified safety problem:\n- Using only the fundamental facts stated above and the provided parameters, over-approximate the reachable state intervals $[ \\underline{x}_t, \\overline{x}_t ]$ recursively for $t = 0,1,\\dots,T$ by:\n    - Computing the observation interval $[ \\underline{y}_t, \\overline{y}_t ] = [ \\underline{x}_t - \\varepsilon \\mathbf{1}, \\overline{x}_t + \\varepsilon \\mathbf{1} ]$.\n    - Propagating $[ \\underline{y}_t, \\overline{y}_t ]$ through the ANN using interval bounds to obtain a control interval $[ \\underline{u}_t, \\overline{u}_t ]$.\n    - Propagating $[ \\underline{x}_t, \\overline{x}_t ]$ and $[ \\underline{u}_t, \\overline{u}_t ]$ through the plant dynamics with interval arithmetic and adding the disturbance interval $[-\\bar{w}, \\bar{w}]^2$ to obtain $[ \\underline{x}_{t+1}, \\overline{x}_{t+1} ]$.\n- A test for certified safety holds if and only if, for all $t \\in \\{0,1,\\dots,T\\}$, the worst-case value of each safety inequality is nonpositive, that is, the upper bounds of $C x_t - d$ over the interval $[ \\underline{x}_t, \\overline{x}_t ]$ are elementwise $\\le 0$.\n\nTest suite:\nFor each of the following parameter tuples $(\\varepsilon, p_{\\max}, T, \\bar{w})$, determine a boolean indicating whether the safety constraint is certified to hold for all admissible adversarial sensor noises and disturbances over the entire horizon $t \\in \\{0,1,\\dots,T\\}$.\n- Case $1$: $\\varepsilon = 0.01$, $p_{\\max} = 0.2$, $T = 20$, $\\bar{w} = 0.0005$.\n- Case $2$: $\\varepsilon = 0.05$, $p_{\\max} = 0.08$, $T = 30$, $\\bar{w} = 0.0005$.\n- Case $3$: $\\varepsilon = 0.0$, $p_{\\max} = 0.06$, $T = 10$, $\\bar{w} = 0.0$.\n- Case $4$: $\\varepsilon = 0.02$, $p_{\\max} = 0.1$, $T = 50$, $\\bar{w} = 0.0002$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results for the cases in the order above as a comma-separated list of Python boolean literals enclosed in square brackets, for example, `[True,False,True,True]`.\n- No units are required because all quantities are treated as dimensionless in this problem.",
            "solution": "The user's request is to validate and solve a problem concerning the certified safety of a learning-enabled control system. The process involves iteratively computing over-approximations of reachable state sets for a discrete-time linear system under adversarial sensor attacks and environmental disturbances.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Plant Dynamics**: $x_{t+1} = A x_t + B u_t + w_t$, with state $x_t \\in \\mathbb{R}^2$, control input $u_t \\in \\mathbb{R}$.\n- **Measurement Equation**: $y_t = x_t + \\delta_t$, with measurement $y_t \\in \\mathbb{R}^2$.\n- **Controller**: A feedforward Artificial Neural Network (ANN), $u_t = \\pi(y_t) = W_2 \\, \\mathrm{ReLU}(W_1 y_t + b_1) + b_2$.\n- **Adversarial Sets**:\n    - Sensor noise: $\\delta_t \\in [-\\varepsilon, \\varepsilon]^2$.\n    - Disturbance: $w_t \\in [-\\bar{w}, \\bar{w}]^2$.\n- **Set Propagation Rules (Fundamental Basis)**:\n    - Affine map $z = W a + b$ with $a \\in [l,u]$: $[l_z, u_z] = [W^+ l + W^- u + b, W^+ u + W^- l + b]$, where $W^+ = \\max(W,0)$ and $W^- = \\min(W,0)$.\n    - ReLU activation $\\mathrm{ReLU}(z)$ with $z \\in [l,u]$: $[\\max(0,l), \\max(0,u)]$.\n    - Minkowski sum of intervals: $[l_1,u_1] + [l_2,u_2] = [l_1 + l_2, u_1 + u_2]$.\n- **Controller Parameters**:\n    - $W_1 = \\begin{bmatrix} 1  0\\\\ -1  0\\\\ 0  1\\\\ 0  -1 \\end{bmatrix} \\in \\mathbb{R}^{4 \\times 2}$\n    - $b_1 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^{4}$\n    - $W_2 = \\begin{bmatrix} -1  1  -0.5  0.5 \\end{bmatrix} \\in \\mathbb{R}^{1 \\times 4}$\n    - $b_2 = 0 \\in \\mathbb{R}$\n- **Plant Parameters** (discretized double integrator with $h=0.1$):\n    - $A = \\begin{bmatrix} 1  0.1\\\\ 0  1 \\end{bmatrix} \\in \\mathbb{R}^{2 \\times 2}$\n    - $B = \\begin{bmatrix} 0.005\\\\ 0.1 \\end{bmatrix} \\in \\mathbb{R}^{2 \\times 1}$\n- **Initial State Set**: $x_0 \\in [\\underline{x}_0, \\overline{x}_0]$ where $\\underline{x}_0 = \\begin{bmatrix} 0.045\\\\ -0.005 \\end{bmatrix}$ and $\\overline{x}_0 = \\begin{bmatrix} 0.055\\\\ 0.005 \\end{bmatrix}$.\n- **Safety Specification**: $|x_{t,1}| \\le p_{\\max}$ for all $t \\in \\{0, 1, \\dots, T\\}$, defined by the polyhedron $\\mathcal{S}(p_{\\max}) = \\{ x \\in \\mathbb{R}^2 : C x \\le d \\}$ with $C = \\begin{bmatrix} 1  0\\\\ -1  0 \\end{bmatrix}$ and $d = \\begin{bmatrix} p_{\\max}\\\\ p_{\\max} \\end{bmatrix}$.\n- **Reachability Algorithm**:\n    1.  Compute observation interval: $[ \\underline{y}_t, \\overline{y}_t ] = [ \\underline{x}_t - \\varepsilon \\mathbf{1}, \\overline{x}_t + \\varepsilon \\mathbf{1} ]$.\n    2.  Compute control interval $[\\underline{u}_t, \\overline{u}_t]$ by propagating $[\\underline{y}_t, \\overline{y}_t]$ through the ANN.\n    3.  Compute next state interval $[\\underline{x}_{t+1}, \\overline{x}_{t+1}]$ by propagating $[\\underline{x}_t, \\overline{x}_t]$ and $[\\underline{u}_t, \\overline{u}_t]$ through the dynamics and adding the disturbance interval.\n- **Safety Certification Test**: Certified if for all $t \\in \\{0, 1, \\dots, T\\}$, the upper bound of $C x_t - d$ over the set $[\\underline{x}_t, \\overline{x}_t]$ is elementwise non-positive.\n- **Test Suite**:\n    - Case 1: $(\\varepsilon, p_{\\max}, T, \\bar{w}) = (0.01, 0.2, 20, 0.0005)$\n    - Case 2: $(\\varepsilon, p_{\\max}, T, \\bar{w}) = (0.05, 0.08, 30, 0.0005)$\n    - Case 3: $(\\varepsilon, p_{\\max}, T, \\bar{w}) = (0.0, 0.06, 10, 0.0)$\n    - Case 4: $(\\varepsilon, p_{\\max}, T, \\bar{w}) = (0.02, 0.1, 50, 0.0002)$\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in the field of formal verification and robust control for cyber-physical systems. The models are based on linear systems theory and neural networks, and the method of analysis is interval arithmetic, which is mathematically sound. All parameters, equations, and procedures are specified without ambiguity, contradiction, or missing information. The problem is formalizable and requires non-trivial computation, directly addressing the specified topic.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be provided by implementing the specified reachability algorithm.\n\n### Solution\n\nThe problem requires us to determine the certified safety of a control system by computing interval over-approximations of the reachable state sets. We will implement the specified recursive algorithm. Let the state interval at time $t$ be $[\\underline{x}_t, \\overline{x}_t]$. The goal is to compute the interval for the next state, $[\\underline{x}_{t+1}, \\overline{x}_{t+1}]$, and verify safety at each step.\n\n**1. Safety Verification**\nAt each discrete time step $t \\in \\{0, 1, \\dots, T\\}$, we must verify that the computed state interval $[\\underline{x}_t, \\overline{x}_t]$ is entirely contained within the safe set $\\mathcal{S}(p_{\\max})$. The safety condition is $|x_{t,1}| \\le p_{\\max}$, which translates to two inequalities: $x_{t,1} \\le p_{\\max}$ and $-x_{t,1} \\le p_{\\max}$. To check if these hold for the entire interval, we must check them for the worst-case values. This requires:\n- $\\max(x_{t,1}) = \\overline{x}_{t,1} \\le p_{\\max}$\n- $\\max(-x_{t,1}) = -\\underline{x}_{t,1} \\le p_{\\max}$, which is equivalent to $\\underline{x}_{t,1} \\ge -p_{\\max}$\nIf both conditions are met, the system is safe at time $t$. The overall system is certified safe if this holds for all $t$ from $0$ to $T$.\n\n**2. Reachable Set Propagation (from $t$ to $t+1$)**\n\n**Step 2.1: Observation Interval**\nThe measurement $y_t = x_t + \\delta_t$ is affected by an adversarial sensor attack $\\delta_t \\in [-\\varepsilon, \\varepsilon]^2$. Given the state interval $[\\underline{x}_t, \\overline{x}_t]$, the interval for the observation $y_t$ is found by the Minkowski sum of the state interval and the noise interval $[-\\varepsilon \\mathbf{1}, \\varepsilon \\mathbf{1}]$, where $\\mathbf{1}$ is a vector of ones.\n$$ \\underline{y}_t = \\underline{x}_t - \\varepsilon \\mathbf{1} $$\n$$ \\overline{y}_t = \\overline{x}_t + \\varepsilon \\mathbf{1} $$\n\n**Step 2.2: Control Input Interval**\nThe control input $u_t$ is determined by propagating the observation interval $[\\underline{y}_t, \\overline{y}_t]$ through the neural network controller $u_t = W_2 \\, \\mathrm{ReLU}(W_1 y_t + b_1) + b_2$.\n\n- **First Affine Transformation**: Let $z_{t,1} = W_1 y_t + b_1$. The interval for $z_{t,1}$ is $[\\underline{z}_{t,1}, \\overline{z}_{t,1}]$, computed using the specified monotonicity-based enclosure rule:\n  $$ \\underline{z}_{t,1} = W_1^+ \\underline{y}_t + W_1^- \\overline{y}_t + b_1 $$\n  $$ \\overline{z}_{t,1} = W_1^+ \\overline{y}_t + W_1^- \\underline{y}_t + b_1 $$\n  where $W_1^+ = \\max(W_1, 0)$ and $W_1^- = \\min(W_1, 0)$ are the element-wise positive and negative parts of $W_1$.\n\n- **ReLU Activation**: Let $a_{t,1} = \\mathrm{ReLU}(z_{t,1})$. The interval for the activation output, $[\\underline{a}_{t,1}, \\overline{a}_{t,1}]$, is found by applying ReLU to the bounds of its input interval:\n  $$ \\underline{a}_{t,1} = \\mathrm{ReLU}(\\underline{z}_{t,1}) = \\max(0, \\underline{z}_{t,1}) $$\n  $$ \\overline{a}_{t,1} = \\mathrm{ReLU}(\\overline{z}_{t,1}) = \\max(0, \\overline{z}_{t,1}) $$\n\n- **Second Affine Transformation (Output)**: The final control input is $u_t = W_2 a_{t,1} + b_2$. Its interval $[\\underline{u}_t, \\overline{u}_t]$ is computed similarly:\n  $$ \\underline{u}_t = W_2^+ \\underline{a}_{t,1} + W_2^- \\overline{a}_{t,1} + b_2 $$\n  $$ \\overline{u}_t = W_2^+ \\overline{a}_{t,1} + W_2^- \\underline{a}_{t,1} + b_2 $$\n\n**Step 2.3: Next State Interval**\nThe next state $x_{t+1} = A x_t + B u_t + w_t$ is a sum of three terms, each lying in an interval. The resulting interval for $x_{t+1}$ is the Minkowski sum of the intervals for each term.\n\n- **Interval for $A x_t$**: Using the affine propagation rule with input $x_t \\in [\\underline{x}_t, \\overline{x}_t]$:\n  $$ [\\underline{(Ax_t)}, \\overline{(Ax_t)}] = [A^+ \\underline{x}_t + A^- \\overline{x}_t, A^+ \\overline{x}_t + A^- \\underline{x}_t] $$\n- **Interval for $B u_t$**: Using the affine propagation rule with input $u_t \\in [\\underline{u}_t, \\overline{u}_t]$:\n  $$ [\\underline{(Bu_t)}, \\overline{(Bu_t)}] = [B^+ \\underline{u}_t + B^- \\overline{u}_t, B^+ \\overline{u}_t + B^- \\underline{u}_t] $$\n- **Interval for $w_t$**: This is given as $[-\\bar{w}\\mathbf{1}, \\bar{w}\\mathbf{1}]$.\n\nSumming these interval bounds gives the next state interval $[\\underline{x}_{t+1}, \\overline{x}_{t+1}]$:\n$$ \\underline{x}_{t+1} = (A^+ \\underline{x}_t + A^- \\overline{x}_t) + (B^+ \\underline{u}_t + B^- \\overline{u}_t) - \\bar{w}\\mathbf{1} $$\n$$ \\overline{x}_{t+1} = (A^+ \\overline{x}_t + A^- \\underline{x}_t) + (B^+ \\overline{u}_t + B^- \\underline{u}_t) + \\bar{w}\\mathbf{1} $$\n\nSince all elements of the given matrices $A$ and $B$ are non-negative, $A^+=A$, $A^-=0$, $B^+=B$, and $B^-=0$. The propagation rule simplifies to:\n$$ \\underline{x}_{t+1} = A \\underline{x}_t + B \\underline{u}_t - \\bar{w}\\mathbf{1} $$\n$$ \\overline{x}_{t+1} = A \\overline{x}_t + B \\overline{u}_t + \\bar{w}\\mathbf{1} $$\nThis complete recursive procedure is implemented for each test case to determine its certified safety status.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the certified safety problem for the four test cases specified.\n    \"\"\"\n    test_cases = [\n        # (epsilon, p_max, T, w_bar)\n        (0.01, 0.2, 20, 0.0005),\n        (0.05, 0.08, 30, 0.0005),\n        (0.0, 0.06, 10, 0.0),\n        (0.02, 0.1, 50, 0.0002),\n    ]\n\n    results = []\n    for case in test_cases:\n        is_safe = check_safety_certification(case)\n        results.append(is_safe)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef check_safety_certification(params):\n    \"\"\"\n    Performs reachability analysis for a given set of parameters to certify safety.\n\n    Args:\n        params (tuple): A tuple containing (epsilon, p_max, T, w_bar).\n\n    Returns:\n        bool: True if the system is certified safe, False otherwise.\n    \"\"\"\n    eps, p_max, T, w_bar = params\n\n    # --- System and Controller Parameters ---\n    # Using column vectors (shape N,1) for consistency in matrix operations.\n    \n    # Plant model\n    A = np.array([[1.0, 0.1], [0.0, 1.0]], dtype=float)\n    B = np.array([[0.005], [0.1]], dtype=float)\n\n    # Controller ANN parameters\n    W1 = np.array([[1, 0], [-1, 0], [0, 1], [0, -1]], dtype=float)\n    b1 = np.zeros((4, 1), dtype=float)\n    W2 = np.array([[-1, 1, -0.5, 0.5]], dtype=float)\n    b2 = np.array([[0.0]], dtype=float)\n\n    # Initial state set\n    x0_lower = np.array([[0.045], [-0.005]], dtype=float)\n    x0_upper = np.array([[0.055], [0.005]], dtype=float)\n\n    # Pre-compute positive and negative parts of weight matrices for propagation\n    W1_pos = np.maximum(W1, 0)\n    W1_neg = np.minimum(W1, 0)\n    W2_pos = np.maximum(W2, 0)\n    W2_neg = np.minimum(W2, 0)\n    \n    # Since A and B are non-negative, the general formula simplifies,\n    # but we implement the general form for correctness.\n    A_pos = np.maximum(A, 0)\n    A_neg = np.minimum(A, 0)\n    B_pos = np.maximum(B, 0)\n    B_neg = np.minimum(B, 0)\n\n    # Initialize current state interval\n    x_lower = x0_lower\n    x_upper = x0_upper\n\n    # Constant interval vectors for noise and disturbance\n    eps_vec = np.full((2, 1), eps)\n    w_bar_vec = np.full((2, 1), w_bar)\n\n    # --- Main Reachability Loop ---\n    for t in range(T + 1):\n        # 1. Safety Verification\n        # Check if the current reachable set violates the safety constraints.\n        # Condition: -p_max = x_t,1 = p_max\n        if x_upper[0, 0]  p_max or x_lower[0, 0]  -p_max:\n            return False  # Safety violated\n\n        # If it's the last time step, no need to compute the next state.\n        if t == T:\n            break\n\n        # 2. Reachable Set Propagation\n        \n        # 2.1. Observation Interval Calculation\n        y_lower = x_lower - eps_vec\n        y_upper = x_upper + eps_vec\n\n        # 2.2. Control Input Interval Calculation (propagate through ANN)\n        # First affine layer\n        z1_lower = W1_pos @ y_lower + W1_neg @ y_upper + b1\n        z1_upper = W1_pos @ y_upper + W1_neg @ y_lower + b1\n\n        # ReLU activation\n        a1_lower = np.maximum(0, z1_lower)\n        a1_upper = np.maximum(0, z1_upper)\n\n        # Output layer\n        u_lower = W2_pos @ a1_lower + W2_neg @ a1_upper + b2\n        u_upper = W2_pos @ a1_upper + W2_neg @ a1_lower + b2\n        \n        # 2.3. Next State Interval Calculation\n        # Contribution from Ax_t\n        ax_lower = A_pos @ x_lower + A_neg @ x_upper\n        ax_upper = A_pos @ x_upper + A_neg @ x_lower\n\n        # Contribution from Bu_t\n        bu_lower = B_pos @ u_lower + B_neg @ u_upper\n        bu_upper = B_pos @ u_upper + B_neg @ u_lower\n        \n        # Minkowski sum for the next state interval\n        x_next_lower = ax_lower + bu_lower - w_bar_vec\n        x_next_upper = ax_upper + bu_upper + w_bar_vec\n\n        # Update state for the next iteration\n        x_lower = x_next_lower\n        x_upper = x_next_upper\n\n    # If the loop completes without any safety violations, the property is certified.\n    return True\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "To build resilient systems, we must also understand how an adversary might exploit them. This final practice challenges you to synthesize a complete end-to-end attack, tracing the impact from a subtle manipulation of sensor features to a tangible physical failure. You will craft an optimal adversarial perturbation against a mobile robot's learned obstacle detector and simulate the resulting trajectory, demonstrating how a purely digital attack can induce a violation of a physical safety clearance in a realistic robotics scenario .",
            "id": "4204841",
            "problem": "Consider a discrete-time Cyber-Physical System (CPS) consisting of a mobile robot and a learned obstacle detector. The robot has a planar kinematic model with curvature dynamics and bounded curvature-rate actuation. Let the robot state at time step $t$ be $x_t = [p_{x,t}, p_{y,t}, \\theta_t, \\kappa_t]$, where $p_{x,t}$ and $p_{y,t}$ are position in meters, $\\theta_t$ is heading in radians, and $\\kappa_t$ is curvature in inverse meters. The control input is $u_t = [v, \\Delta \\kappa_t]$, where $v$ is forward speed in meters per second and $\\Delta \\kappa_t$ is the curvature rate increment per time step in inverse meters. The discrete-time update over a time step $\\Delta t$ is\n$$\n\\begin{aligned}\np_{x,t+1} = p_{x,t} + v \\cos(\\theta_t)\\, \\Delta t,\\\\\np_{y,t+1} = p_{y,t} + v \\sin(\\theta_t)\\, \\Delta t,\\\\\n\\theta_{t+1} = \\theta_t + v\\, \\kappa_t\\, \\Delta t,\\\\\n\\kappa_{t+1} = \\kappa_t + \\Delta \\kappa_t,\n\\end{aligned}\n$$\nwith a bounded curvature-rate constraint $|\\Delta \\kappa_t| \\leq \\kappa_{\\mathrm{rate,max}}$.\n\nA learned obstacle detector operates on a two-dimensional feature vector $y_t \\in \\mathbb{R}^2$ constructed from the robot state and a fixed obstacle position $o = [o_x, o_y]$:\n$$\nr_t = \\sqrt{(o_x - p_{x,t})^2 + (o_y - p_{y,t})^2},\\quad\nb_t = \\mathrm{atan2}(o_y - p_{y,t}, o_x - p_{x,t}) - \\theta_t,\n$$\nwhere $r_t$ is the range in meters and $b_t$ is the bearing in radians. The feature vector is $y_t = [\\phi_1(r_t), \\phi_2(b_t)] = [1/r_t, \\cos(b_t)]$, which is dimensionless. The detector is a logistic classifier producing a probability $p_t \\in [0,1]$ via\n$$\np_t = \\sigma(w^\\top y_t + \\beta), \\quad \\text{with} \\quad \\sigma(z) = \\frac{1}{1 + e^{-z}},\n$$\nwhere $w \\in \\mathbb{R}^2$ and $\\beta \\in \\mathbb{R}$ are fixed learned parameters.\n\nA simple avoidance policy uses the detector output at $t=0$ to set the curvature-rate command for all subsequent steps:\n$$\n\\Delta \\kappa_t =\n\\begin{cases}\n-\\kappa_{\\mathrm{rate,max}}\\, \\mathrm{sign}(b_0),  \\text{if } p_0 \\ge \\tau,\\\\\n0,  \\text{if } p_0  \\tau,\n\\end{cases}\n\\quad \\text{for all } t \\in \\{0, 1, \\dots, N-1\\},\n$$\nwhere $\\tau \\in (0,1)$ is a fixed decision threshold, and $\\mathrm{sign}(\\cdot)$ denotes the sign function. This policy attempts to turn away from the obstacle when the detector indicates it is in the path. The minimum clearance relative to the obstacle over the horizon is\n$$\n\\mathrm{clearance}_{\\min} = \\min_{t \\in \\{0,1,\\dots,N\\}} \\sqrt{(o_x - p_{x,t})^2 + (o_y - p_{y,t})^2},\n$$\nand a safety requirement imposes $\\mathrm{clearance}_{\\min} \\ge d_{\\min}$, with $d_{\\min}$ in meters.\n\nAn adversary perturbs the detector input by adding a feature-space perturbation $\\delta \\in \\mathbb{R}^2$ at $t=0$, yielding the attacked feature vector $y_0^{\\mathrm{adv}} = y_0 + \\delta$, with perturbation budget constraint $\\|\\delta\\|_2 \\le \\varepsilon$, where $\\varepsilon$ is dimensionless. The objective of the adversary is to induce a control input sequence that violates the minimum clearance constraint, subject to the bounded curvature-rate constraint, by reducing the detector output below threshold $\\tau$.\n\nStarting from the above fundamentals, implement a program that computes, for each provided test case:\n- an adversarial feature perturbation $\\delta^\\star$ at $t=0$ that minimizes the logistic detector’s decision score under the budget $\\|\\delta\\|_2 \\le \\varepsilon$,\n- the resulting control input determined by the avoidance policy with $y_0^{\\mathrm{adv}}$,\n- the discrete-time trajectory over $N$ steps under the bounded curvature-rate constraint,\n- the minimum clearance, and a boolean indicating violation of the safety requirement, defined as $\\mathrm{clearance}_{\\min}  d_{\\min}$.\n\nUse the following fixed parameters across all test cases:\n- $v = 1.0$ meters per second,\n- $\\Delta t = 0.1$ seconds,\n- $\\kappa_{\\mathrm{rate,max}} = 0.02$ inverse meters per time step,\n- $N = 50$ time steps,\n- $d_{\\min} = 0.5$ meters,\n- $\\tau = 0.5$,\n- $w = [4.0, 6.0]$ (dimensionless),\n- $\\beta = -3.0$ (dimensionless),\n- initial state $x_0 = [0.0, 0.0, 0.0, 0.0]$ (meters, meters, radians, inverse meters).\n\nTest suite of four cases (express all angles in radians and distances in meters):\n1. Case A (happy path): obstacle at $o = [3.0, 0.2]$, attack budget $\\varepsilon = 0.65$.\n2. Case B (boundary budget): obstacle at $o = [3.0, 0.2]$, attack budget $\\varepsilon = 0.55$.\n3. Case C (edge, obstacle behind): obstacle at $o = [-2.0, 0.0]$, attack budget $\\varepsilon = 0.65$.\n4. Case D (edge, obstacle far ahead): obstacle at $o = [10.0, 0.0]$, attack budget $\\varepsilon = 0.65$.\n\nYour program must produce a single line of output containing the boolean violation results for the four cases, as a comma-separated list enclosed in square brackets, for example, \"[True,False,True,False]\". No additional text should be printed. Angles must be computed in radians and all distances must be in meters. The boolean values indicate whether the adversarial perturbation induces a violation ($\\mathrm{clearance}_{\\min}  d_{\\min}$) under the bounded curvature-rate constraint for each case.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It presents a complete and consistent set of definitions, constraints, and parameters for simulating an adversarial attack on a learning-enabled cyber-physical system. The task is to determine if a specific, optimally crafted adversarial perturbation can cause a safety violation for a set of given scenarios. We proceed with a methodical solution.\n\nThe solution process involves four main steps for each test case:\n1.  Compute the optimal adversarial perturbation $\\delta^\\star$.\n2.  Determine the control action based on the perturbed detector output.\n3.  Simulate the robot's trajectory under the determined control action.\n4.  Calculate the minimum clearance to the obstacle and check for a safety violation.\n\nThe fixed parameters for all computations are:\n- Speed $v = 1.0 \\, \\mathrm{m/s}$\n- Time step $\\Delta t = 0.1 \\, \\mathrm{s}$\n- Maximum curvature rate $\\kappa_{\\mathrm{rate,max}} = 0.02 \\, \\mathrm{m}^{-1}/\\mathrm{step}$\n- Simulation horizon $N = 50$ steps\n- Minimum required clearance $d_{\\min} = 0.5 \\, \\mathrm{m}$\n- Detector threshold $\\tau = 0.5$\n- Classifier weights $w = [4.0, 6.0]^\\top$ (dimensionless)\n- Classifier bias $\\beta = -3.0$ (dimensionless)\n- Initial state $x_0 = [p_{x,0}, p_{y,0}, \\theta_0, \\kappa_0] = [0.0, 0.0, 0.0, 0.0]$ in units of (m, m, rad, m⁻¹).\n\n**Step 1: Optimal Adversarial Perturbation**\n\nThe adversary's goal is to minimize the detector's output probability $p_0^{\\mathrm{adv}} = \\sigma(w^\\top y_0^{\\mathrm{adv}} + \\beta)$. The sigmoid function $\\sigma(z)$ is monotonically increasing. Therefore, minimizing $p_0^{\\mathrm{adv}}$ is equivalent to minimizing its argument, the decision score $S_{\\mathrm{adv}} = w^\\top y_0^{\\mathrm{adv}} + \\beta$.\n\nThe attacked feature vector is $y_0^{\\mathrm{adv}} = y_0 + \\delta$. Substituting this into the score gives:\n$$\nS_{\\mathrm{adv}}(\\delta) = w^\\top (y_0 + \\delta) + \\beta = (w^\\top y_0 + \\beta) + w^\\top \\delta\n$$\nThe first part, $(w^\\top y_0 + \\beta)$, is constant for a given scenario. To minimize $S_{\\mathrm{adv}}(\\delta)$, the adversary must minimize the term $w^\\top \\delta$. This is a dot product, which is minimized when the vector $\\delta$ points in the direction opposite to the vector $w$.\n\nThe adversary is constrained by a budget $\\|\\delta\\|_2 \\le \\varepsilon$. To achieve the maximum negative projection onto $w$, the perturbation $\\delta$ must have the maximum possible magnitude, $\\varepsilon$, and be aligned with the direction $-w$. Therefore, the optimal perturbation $\\delta^\\star$ is:\n$$\n\\delta^\\star = -\\varepsilon \\frac{w}{\\|w\\|_2}\n$$\nWith $w = [4.0, 6.0]^\\top$, the L2-norm is $\\|w\\|_2 = \\sqrt{4.0^2 + 6.0^2} = \\sqrt{16.0 + 36.0} = \\sqrt{52.0}$.\nThe optimal perturbation is a function of the attack budget $\\varepsilon$:\n$$\n\\delta^\\star = -\\frac{\\varepsilon}{\\sqrt{52.0}} [4.0, 6.0]^\\top\n$$\n\n**Step 2: Control Policy Decision**\n\nFor each test case, we first compute the initial unperturbed feature vector $y_0$. The initial state is $x_0 = [0,0,0,0]$.\n- The range to the obstacle $o=[o_x, o_y]$ is $r_0 = \\sqrt{(o_x - 0)^2 + (o_y - 0)^2} = \\sqrt{o_x^2 + o_y^2}$.\n- The bearing to the obstacle is $b_0 = \\mathrm{atan2}(o_y - 0, o_x - 0) - 0 = \\mathrm{atan2}(o_y, o_x)$.\n- The feature vector is $y_0 = [1/r_0, \\cos(b_0)]^\\top$.\n\nWe then compute the attacked feature vector $y_0^{\\mathrm{adv}} = y_0 + \\delta^\\star$ and the corresponding decision score $S_{\\mathrm{adv}} = w^\\top y_0^{\\mathrm{adv}} + \\beta$.\n\nThe avoidance policy is:\n$$\n\\Delta \\kappa =\n\\begin{cases}\n-\\kappa_{\\mathrm{rate,max}}\\, \\mathrm{sign}(b_0),  \\text{if } p_0^{\\mathrm{adv}} \\ge \\tau,\\\\\n0,  \\text{if } p_0^{\\mathrm{adv}}  \\tau,\n\\end{cases}\n$$\nwhere $\\Delta\\kappa$ is the constant curvature rate for all time steps $t=0, \\dots, N-1$. Since $\\tau=0.5$, the condition $p_0^{\\mathrm{adv}} \\ge \\tau$ is equivalent to $S_{\\mathrm{adv}} \\ge 0$, and $p_0^{\\mathrm{adv}}  \\tau$ is equivalent to $S_{\\mathrm{adv}}  0$. The adversary's goal is to make $S_{\\mathrm{adv}}  0$, which sets $\\Delta\\kappa=0$ and causes the robot to move straight, potentially into the obstacle.\n\n**Step 3: Trajectory Simulation**\n\nWith the constant curvature rate $\\Delta\\kappa$ determined, we simulate the robot's trajectory for $N=50$ steps. Starting with $x_0$, we iterate from $t=0$ to $N-1$ using the discrete-time dynamics:\n$$\n\\begin{aligned}\n\\kappa_{t+1} = \\kappa_t + \\Delta \\kappa \\\\\n\\theta_{t+1} = \\theta_t + v \\, \\kappa_t \\, \\Delta t \\\\\np_{x,t+1} = p_{x,t} + v \\cos(\\theta_t) \\, \\Delta t \\\\\np_{y,t+1} = p_{y,t} + v \\sin(\\theta_t) \\, \\Delta t\n\\end{aligned}\n$$\nWe store the position $[p_{x,t}, p_{y,t}]$ at each time step $t \\in \\{0, 1, \\dots, N\\}$.\n\n**Step 4: Minimum Clearance and Violation Check**\n\nAfter generating the full trajectory of positions, we compute the Euclidean distance to the obstacle $o$ at each time step:\n$$\nd_t = \\sqrt{(o_x - p_{x,t})^2 + (o_y - p_{y,t})^2} \\quad \\text{for } t \\in \\{0, 1, \\dots, N\\}\n$$\nThe minimum clearance over the horizon is $\\mathrm{clearance}_{\\min} = \\min_{t} d_t$.\nA safety violation occurs if this clearance is less than the required minimum, i.e., if $\\mathrm{clearance}_{\\min}  d_{\\min}$. We compute this boolean value for each test case.\n\nThis complete procedure is implemented for each of the four test cases provided in the problem statement. The final output is a list of these boolean violation indicators.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes adversarial attack outcomes for a CPS robot model.\n    For each test case, it calculates an optimal adversarial perturbation,\n    simulates the robot's trajectory under the attacked control policy,\n    and determines if a safety violation occurs.\n    \"\"\"\n\n    # Fixed parameters from the problem statement\n    v = 1.0  # meters per second\n    dt = 0.1  # seconds\n    kappa_rate_max = 0.02  # inverse meters per time step\n    N = 50  # time steps\n    d_min = 0.5  # meters\n    tau = 0.5  # dimensionless\n    w = np.array([4.0, 6.0])  # dimensionless\n    beta = -3.0  # dimensionless\n    x0 = np.array([0.0, 0.0, 0.0, 0.0])  # m, m, rad, 1/m\n\n    # Test cases: (obstacle_position, attack_budget_epsilon)\n    test_cases = [\n        (np.array([3.0, 0.2]), 0.65),  # Case A\n        (np.array([3.0, 0.2]), 0.55),  # Case B\n        (np.array([-2.0, 0.0]), 0.65),  # Case C\n        (np.array([10.0, 0.0]), 0.65),  # Case D\n    ]\n\n    results = []\n\n    # Calculate optimal perturbation direction\n    norm_w = np.linalg.norm(w)\n    w_dir_inv = -w / norm_w\n\n    for o, epsilon in test_cases:\n        # Step 1: Compute optimal adversarial perturbation delta_star\n        delta_star = epsilon * w_dir_inv\n\n        # Step 2: Determine control action with attacked detector\n        px0, py0, theta0, _ = x0\n        \n        # Calculate initial features\n        r0 = np.linalg.norm(o - x0[:2])\n        # Handle case where r0 is zero to avoid division by zero\n        if r0 == 0:\n            # If robot starts on the obstacle, it's a violation.\n            # However, problem setup ensures r0  0 for all test cases.\n            # We can treat y0 features as infinitely large.\n            # In practice, with this problem's test cases, this won't happen.\n            y0 = np.array([np.inf, 0.0])\n        else:\n            b0 = np.arctan2(o[1] - py0, o[0] - px0) - theta0\n            y0 = np.array([1.0 / r0, np.cos(b0)])\n\n        # Apply attack and get decision score\n        y0_adv = y0 + delta_star\n        score_adv = w @ y0_adv + beta\n        \n        # Decide on control input delta_kappa based on the policy\n        # Condition p_adv = tau is equivalent to score_adv = 0 for tau=0.5\n        delta_kappa = 0.0\n        if score_adv = 0:\n            delta_kappa = -kappa_rate_max * np.sign(b0)\n\n        # Step 3: Simulate the trajectory\n        x = x0.copy()\n        trajectory_positions = [x0[:2]]\n        for _ in range(N):\n            px, py, theta, kappa = x\n            \n            # Update state using discrete-time dynamics\n            kappa_next = kappa + delta_kappa\n            # Note: The model updates theta and position using state from start of timestep\n            theta_next = theta + v * kappa * dt\n            px_next = px + v * np.cos(theta) * dt\n            py_next = py + v * np.sin(theta) * dt\n            \n            x = np.array([px_next, py_next, theta_next, kappa_next])\n            trajectory_positions.append(x[:2])\n            \n        # Step 4: Calculate minimum clearance and check for violation\n        trajectory_positions = np.array(trajectory_positions)\n        distances_to_obstacle = np.linalg.norm(trajectory_positions - o, axis=1)\n        min_clearance = np.min(distances_to_obstacle)\n\n        violation = min_clearance  d_min\n        results.append(violation)\n\n    # Format the final output as a string\n    print(f\"[{','.join(map(str, results))}]\")\n\n\nsolve()\n```"
        }
    ]
}