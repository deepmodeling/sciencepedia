{
    "hands_on_practices": [
        {
            "introduction": "Digital Twins often rely on Luenberger observers to estimate unmeasured states from available sensor data. However, the purpose of an observer can extend beyond simple state tracking. This practice explores how to actively design an observer not just for stability, but also for enhanced Fault Detection and Isolation (FDI) performance. You will apply the advanced technique of eigenstructure assignment  to shape the observer's error dynamics, maximizing the residual's sensitivity to a specific actuator fault while satisfying prescribed stability requirements.",
            "id": "4221840",
            "problem": "A digital twin for a cyber-physical system uses a Luenberger observer to generate residuals for Fault Detection, Isolation, and Diagnosis (FDI). Consider the continuous-time linear time-invariant plant\n$$\n\\dot{x}(t) = A x(t) + B u(t) + B_f f, \\quad y(t) = C x(t),\n$$\nwhere $x(t) \\in \\mathbb{R}^{2}$ is the state, $u(t) \\in \\mathbb{R}$ is a known control input, $f \\in \\mathbb{R}$ is a constant actuator bias fault entering through $B_f$, and $y(t) \\in \\mathbb{R}^{2}$ is the measured output. The plant matrices are\n$$\nA = \\begin{bmatrix} 0 & 1 \\\\ -2 & -1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\quad B_f = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n$$\nThe observer has the standard Luenberger form and uses the residual for detection,\n$$\nr(t) = y(t) - \\hat{y}(t), \\quad \\hat{y}(t) = C \\hat{x}(t),\n$$\nand a scalar residual channel is formed as\n$$\nr_s(t) = w^{\\top} r(t), \\quad w = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}.\n$$\nTo maintain stability via pole placement while enabling sensitivity eigenstructure tuning, design the observer gain $L \\in \\mathbb{R}^{2 \\times 2}$ such that the error dynamics matrix $A - L C$ has the prescribed eigenvalues\n$$\n\\Lambda = \\operatorname{diag}(-1, -3).\n$$\nLet the right-eigenvector matrix of $A - L C$ be\n$$\nV = \\begin{bmatrix} 1 & 1 \\\\ t & 1 \\end{bmatrix},\n$$\nwith columns $v_1 = \\begin{bmatrix} 1 \\\\ t \\end{bmatrix}$ and $v_2 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, where $t \\in \\mathbb{R}$ is a tunable sensitivity eigenstructure parameter. To ensure numerical robustness and avoid excessive noise amplification in the digital twin, impose the conditioning constraint\n$$\n|\\det(V)| \\ge \\delta, \\quad \\delta = 0.5.\n$$\nStarting from the fundamental definitions of the Luenberger observer error dynamics and the steady-state response to a constant fault input, derive the steady-state scalar sensitivity coefficient $s(t)$ mapping the constant actuator bias $f$ to the scalar residual $r_s(t)$, defined by the steady-state relationship $r_s^{\\star} = s(t)\\, f$. Then, subject to the above pole placement and conditioning constraint, determine the maximum attainable magnitude of $s(t)$ over all admissible $t$. Express your final answer as an exact number, with no units and no rounding.",
            "solution": "The solution requires finding the maximum magnitude of the fault sensitivity coefficient $s(t)$ under given constraints. The derivation proceeds as follows.\n\n1.  **Error Dynamics and Residuals**\n    The Luenberger observer is given by $\\dot{\\hat{x}}(t) = A\\hat{x}(t) + Bu(t) + L(y(t)-\\hat{y}(t))$. The estimation error is $e(t) = x(t) - \\hat{x}(t)$. Its dynamics are:\n    $$\n    \\dot{e}(t) = \\dot{x}(t) - \\dot{\\hat{x}}(t) = (Ax + Bu + B_f f) - (A\\hat{x} + Bu + L(Cx - C\\hat{x}))\n    $$\n    $$\n    \\dot{e}(t) = (A - LC)e(t) + B_f f\n    $$\n    For a constant fault $f$, the steady-state error $e_{ss}$ is found by setting $\\dot{e}(t) = 0$:\n    $$\n    e_{ss} = -(A - LC)^{-1} B_f f\n    $$\n    The residual is $r(t) = y(t) - \\hat{y}(t) = C(x(t) - \\hat{x}(t)) = Ce(t)$. Since $C = I$, the residual is $r(t) = e(t)$. The steady-state scalar residual $r_s^{\\star}$ is:\n    $$\n    r_s^{\\star} = w^{\\top} r_{ss} = w^{\\top} e_{ss} = -w^{\\top} (A - LC)^{-1} B_f f\n    $$\n    From the definition $r_s^{\\star} = s(t)f$, the sensitivity coefficient is:\n    $$\n    s(t) = -w^{\\top} (A - LC)^{-1} B_f\n    $$\n\n2.  **Eigenstructure Assignment**\n    The problem specifies the eigenstructure of the error dynamics matrix $A_e = A - LC$. We are given its eigenvalues $\\Lambda$ and eigenvector matrix $V$. From the standard spectral decomposition, we can write $A_e = V \\Lambda V^{-1}$. Therefore, its inverse is:\n    $$\n    A_e^{-1} = (A - LC)^{-1} = (V \\Lambda V^{-1})^{-1} = V \\Lambda^{-1} V^{-1}\n    $$\n    The sensitivity coefficient can now be expressed as:\n    $$\n    s(t) = -w^{\\top} V \\Lambda^{-1} V^{-1} B_f\n    $$\n\n3.  **Calculate Sensitivity $s(t)$**\n    First, we compute the inverse of $V$:\n    $$\n    \\det(V) = \\det\\left(\\begin{bmatrix} 1 & 1 \\\\ t & 1 \\end{bmatrix}\\right) = 1 - t\n    $$\n    $$\n    V^{-1} = \\frac{1}{1 - t} \\begin{bmatrix} 1 & -1 \\\\ -t & 1 \\end{bmatrix}\n    $$\n    Now, we substitute all the given matrices into the expression for $s(t)$:\n    $$\n    w = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad B_f = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad \\Lambda^{-1} = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1/3 \\end{bmatrix}\n    $$\n    Let's compute the terms step-by-step:\n    $$\n    w^{\\top} V = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ t & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\end{bmatrix}\n    $$\n    $$\n    V^{-1} B_f = \\frac{1}{1 - t} \\begin{bmatrix} 1 & -1 \\\\ -t & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\frac{1}{1 - t} \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\n    $$\n    Now, assemble the full expression for $s(t)$:\n    $$\n    s(t) = - \\underbrace{\\begin{bmatrix} 1 & 1 \\end{bmatrix}}_{w^{\\top}V} \\underbrace{\\begin{bmatrix} -1 & 0 \\\\ 0 & -1/3 \\end{bmatrix}}_{\\Lambda^{-1}} \\underbrace{\\left( \\frac{1}{1-t} \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} \\right)}_{V^{-1}B_f}\n    $$\n    $$\n    s(t) = - \\begin{bmatrix} -1 & -1/3 \\end{bmatrix} \\left( \\frac{1}{1-t} \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} \\right) = - \\frac{1}{1-t} \\left( (-1)(-1) + (-1/3)(1) \\right)\n    $$\n    $$\n    s(t) = - \\frac{1}{1-t} \\left( 1 - \\frac{1}{3} \\right) = - \\frac{2/3}{1-t} = \\frac{2}{3(t-1)}\n    $$\n\n4.  **Maximize $|s(t)|$ Under Constraint**\n    The conditioning constraint is $|\\det(V)| \\ge 0.5$. Since $\\det(V) = 1 - t$, the constraint is:\n    $$\n    |1 - t| \\ge 0.5\n    $$\n    This inequality defines the set of admissible values for the parameter $t$. It splits into two cases:\n    -   $1 - t \\ge 0.5 \\implies t \\le 0.5$\n    -   $1 - t \\le -0.5 \\implies t \\ge 1.5$\n    So, the admissible range for $t$ is $(-\\infty, 0.5] \\cup [1.5, \\infty)$.\n\n    We want to maximize the magnitude of the sensitivity:\n    $$\n    |s(t)| = \\left| \\frac{2}{3(t-1)} \\right| = \\frac{2}{3|t-1|}\n    $$\n    To maximize $|s(t)|$, we must minimize its denominator, $3|t-1|$, over the admissible range of $t$.\n    -   For the interval $t \\in (-\\infty, 0.5]$, the value of $|t-1|$ is minimized at the boundary point $t = 0.5$. The minimum value is $|0.5 - 1| = 0.5$.\n    -   For the interval $t \\in [1.5, \\infty)$, the value of $|t-1|$ is minimized at the boundary point $t = 1.5$. The minimum value is $|1.5 - 1| = 0.5$.\n    Both intervals give the same minimum value for $|t-1|$, which is $0.5$.\n\n    Therefore, the maximum attainable magnitude for the sensitivity is:\n    $$\n    \\max |s(t)| = \\frac{2}{3 \\times (\\min |t-1|)} = \\frac{2}{3 \\times 0.5} = \\frac{2}{1.5} = \\frac{4}{3}\n    $$",
            "answer": "$$\n\\boxed{\\frac{4}{3}}\n$$"
        },
        {
            "introduction": "As an alternative to state observers, parity space methods offer a powerful, data-driven approach for generating residuals directly from input-output measurements over a finite time horizon. A key advantage of this technique is its ability to create residuals that are, by construction, decoupled from unknown initial conditions and known control inputs, making them robust diagnostics signals. This exercise  provides a concrete, hands-on application of the parity space framework, guiding you through the entire workflow from building a parity matrix to computing residuals and using geometric fault signatures to isolate a sensor bias from a set of measurement data.",
            "id": "4221798",
            "problem": "A discrete-time linear time-invariant cyber-physical system (CPS) is modeled in state space as $x_{k+1} = A x_{k} + B u_{k}$ and $y_{k} = C x_{k} + f b$, where $x_{k} \\in \\mathbb{R}^{n}$ is the state, $u_{k} \\in \\mathbb{R}^{p}$ is the input, $y_{k} \\in \\mathbb{R}^{m}$ is the sensor output, $f \\in \\mathbb{R}^{m}$ is an unknown constant sensor fault direction that equals a canonical basis vector $e_{i}$ if the $i$-th sensor has a constant bias, and $b \\in \\mathbb{R}$ is the (unknown) bias magnitude. Assume zero input, $u_{k} = 0$, and an unknown initial condition $x_{0}$. The parity-space principle for fault detection, isolation, and diagnosis (FDI) requires a matrix $W$ such that $W \\mathcal{O}_{L} = 0$, where $\\mathcal{O}_{L}$ is the extended observability over a finite horizon of length $L$. Then the parity residual $r = W Y$ is insensitive to $x_{0}$ (and to $u_{k}$ when present) but sensitive to sensor faults, where $Y$ is the stacked output over the horizon.\n\nConsider the system with $n = 1$, $m = 2$, and horizon $L = 2$, with\n$$\nA = [\\,0.6\\,], \\quad B = [\\,1\\,], \\quad C = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}.\n$$\nThe stacked output over two steps is $Y = \\begin{bmatrix} y_{0} \\\\ y_{1} \\end{bmatrix} \\in \\mathbb{R}^{4}$, and the extended observability is\n$$\n\\mathcal{O}_{2} = \\begin{bmatrix} C \\\\ C A \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0.6 \\\\ 1.2 \\end{bmatrix}.\n$$\nAssume exactly one sensor has a constant bias over the horizon. The measured outputs are\n$$\ny_{0} = \\begin{bmatrix} 1.9 \\\\ 3.0 \\end{bmatrix}, \\qquad y_{1} = \\begin{bmatrix} 1.3 \\\\ 1.8 \\end{bmatrix}.\n$$\nTasks:\n1) From first principles, construct a nontrivial parity matrix $W \\in \\mathbb{R}^{q \\times 4}$ with $q = 4 - 1 = 3$ such that $W \\mathcal{O}_{2} = 0$.\n2) Using the definition of parity residuals, compute $r = W Y$.\n3) For isolation, define the fault signature vectors in parity space $s_{i} = W F_{L} e_{i}$, where $F_{L} = \\begin{bmatrix} I_{2} \\\\ I_{2} \\end{bmatrix}$ and $e_{i} \\in \\mathbb{R}^{2}$ is the $i$-th canonical basis vector. Design a decision rule that selects the index $i$ maximizing the normalized correlation\n$$\ng_{i} = \\frac{| \\langle r, s_{i} \\rangle |}{\\lVert r \\rVert \\, \\lVert s_{i} \\rVert},\n$$\nand apply it to the given data.\nProvide as your final answer only the isolated sensor index $i$ as an integer (use $1$-based indexing). No rounding is required and no units are needed.",
            "solution": "The solution is found by following the three tasks outlined in the problem statement.\n\n1.  **Construct the Parity Matrix $W$**\n    The parity matrix $W$ must satisfy $W \\mathcal{O}_{2} = 0$. This means the rows of $W$ must belong to the left null space of $\\mathcal{O}_{2}$. Given $\\mathcal{O}_{2} \\in \\mathbb{R}^{4 \\times 1}$, its left null space has dimension $4 - \\operatorname{rank}(\\mathcal{O}_{2}) = 4 - 1 = 3$. We need to find three linearly independent row vectors $w^T = \\begin{bmatrix} w_1 & w_2 & w_3 & w_4 \\end{bmatrix}$ such that:\n    $$\n    w^T \\mathcal{O}_{2} = w_1(1) + w_2(2) + w_3(0.6) + w_4(1.2) = 0\n    $$\n    A systematic way to construct a basis for this null space is to set one of the free variables to $1$ and the others to $0$. A simple basis is:\n    -   $w_1^T = \\begin{bmatrix} -2 & 1 & 0 & 0 \\end{bmatrix}$\n    -   $w_2^T = \\begin{bmatrix} -0.6 & 0 & 1 & 0 \\end{bmatrix}$\n    -   $w_3^T = \\begin{bmatrix} -1.2 & 0 & 0 & 1 \\end{bmatrix}$\n    Stacking these row vectors gives a valid parity matrix:\n    $$\n    W = \\begin{bmatrix} -2 & 1 & 0 & 0 \\\\ -0.6 & 0 & 1 & 0 \\\\ -1.2 & 0 & 0 & 1 \\end{bmatrix}\n    $$\n\n2.  **Compute the Residual $r$**\n    First, stack the measured outputs into the vector $Y$:\n    $$\n    Y = \\begin{bmatrix} y_0 \\\\ y_1 \\end{bmatrix} = \\begin{bmatrix} 1.9 \\\\ 3.0 \\\\ 1.3 \\\\ 1.8 \\end{bmatrix}\n    $$\n    Next, compute the residual $r = W Y$:\n    $$\n    r = \\begin{bmatrix} -2 & 1 & 0 & 0 \\\\ -0.6 & 0 & 1 & 0 \\\\ -1.2 & 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1.9 \\\\ 3.0 \\\\ 1.3 \\\\ 1.8 \\end{bmatrix} = \\begin{bmatrix} (-2)(1.9) + (1)(3.0) \\\\ (-0.6)(1.9) + (1)(1.3) \\\\ (-1.2)(1.9) + (1)(1.8) \\end{bmatrix} = \\begin{bmatrix} -3.8 + 3.0 \\\\ -1.14 + 1.3 \\\\ -2.28 + 1.8 \\end{bmatrix} = \\begin{bmatrix} -0.8 \\\\ 0.16 \\\\ -0.48 \\end{bmatrix}\n    $$\n\n3.  **Isolate the Fault**\n    The fault signature vectors $s_i$ are computed as $s_i = W F_L e_i$. The matrix $F_L$ stacks identity matrices:\n    $$\n    F_{L} = \\begin{bmatrix} I_{2} \\\\ I_{2} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n    $$\n    -   **For a fault in sensor 1 ($i=1$):** The fault enters along direction $F_L e_1 = \\begin{bmatrix} 1 & 0 & 1 & 0 \\end{bmatrix}^T$.\n        $$\n        s_1 = W (F_L e_1) = \\begin{bmatrix} -2 & 1 & 0 & 0 \\\\ -0.6 & 0 & 1 & 0 \\\\ -1.2 & 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ 0.4 \\\\ -1.2 \\end{bmatrix}\n        $$\n    -   **For a fault in sensor 2 ($i=2$):** The fault enters along direction $F_L e_2 = \\begin{bmatrix} 0 & 1 & 0 & 1 \\end{bmatrix}^T$.\n        $$\n        s_2 = W (F_L e_2) = \\begin{bmatrix} -2 & 1 & 0 & 0 \\\\ -0.6 & 0 & 1 & 0 \\\\ -1.2 & 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}\n        $$\n    The decision rule is to find the fault index $i$ that maximizes the normalized correlation (cosine similarity) $g_i$.\n    Let's check the alignment between the residual $r$ and the signatures $s_1$ and $s_2$.\n    By inspection, we can see if $r$ is a scalar multiple of $s_1$:\n    $$\n    \\frac{r_1}{s_{1,1}} = \\frac{-0.8}{-2} = 0.4, \\quad \\frac{r_2}{s_{1,2}} = \\frac{0.16}{0.4} = 0.4, \\quad \\frac{r_3}{s_{1,3}} = \\frac{-0.48}{-1.2} = 0.4\n    $$\n    Since $r = 0.4 s_1$, the residual vector $r$ is perfectly aligned with the signature vector $s_1$. This means the normalized correlation $g_1$ is exactly $1$.\n    $$\n    g_1 = \\frac{| \\langle r, s_{1} \\rangle |}{\\lVert r \\rVert \\, \\lVert s_{1} \\rVert} = \\frac{| \\langle 0.4s_1, s_{1} \\rangle |}{\\lVert 0.4s_1 \\rVert \\, \\lVert s_{1} \\rVert} = \\frac{0.4 \\lVert s_1 \\rVert^2}{0.4 \\lVert s_1 \\rVert \\lVert s_1 \\rVert} = 1\n    $$\n    Since $r$ is not a scalar multiple of $s_2$, their normalized correlation $g_2$ will be less than $1$.\n    Therefore, the maximum correlation is achieved for $i=1$. The fault is isolated to the first sensor.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "In realistic Cyber-Physical Systems, both process dynamics and measurements are corrupted by noise, making the Kalman filter the standard tool for optimal state estimation. This raises a critical question for FDI design: does an optimal state estimator also serve as an optimal fault detector? This practice  delves into this fundamental trade-off inherent in stochastic FDI. By deriving the steady-state Kalman gain and analyzing its influence on the innovation-based fault signature, you will uncover the subtle conditions under which a filter tuned for optimal estimation performance may inadvertently mask the very fault it is supposed to detect.",
            "id": "4221867",
            "problem": "Consider a discrete-time, scalar Cyber-Physical System (CPS) and its Digital Twin (DT) estimator. The plant evolves according to the linear time-invariant stochastic dynamics\n$$\nx_{k+1} = a\\,x_{k} + w_{k},\n$$\nwith the measurement model\n$$\ny_{k} = x_{k} + v_{k} + f_{k}.\n$$\nAssume the process noise $w_{k}$ and measurement noise $v_{k}$ are mutually independent, zero-mean, white, Gaussian sequences with covariances $\\mathbb{E}[w_{k}^{2}] = Q > 0$ and $\\mathbb{E}[v_{k}^{2}] = R > 0$, respectively. The scalar parameter $a$ satisfies $|a| < 1$. The additive fault $f_{k}$ represents an unknown bias injected into the measurement channel. The Digital Twin employs a steady-state Kalman Filter (KF) with a constant gain $K$ and the predictor-corrector recursion\n$$\n\\hat{x}_{k}^{-} = a\\,\\hat{x}_{k-1}, \\quad r_{k} = y_{k} - \\hat{x}_{k}^{-}, \\quad \\hat{x}_{k} = \\hat{x}_{k}^{-} + K\\,r_{k},\n$$\nwhere $r_{k}$ is the innovation. Define the a priori estimation error $e_{k}^{-} = x_{k} - \\hat{x}_{k}^{-}$ and its covariance $P_{k}^{-} = \\mathbb{E}[(e_{k}^{-})^{2}]$, and the a posteriori estimation error $e_{k} = x_{k} - \\hat{x}_{k}$ with covariance $P_{k} = \\mathbb{E}[e_{k}^{2}]$.\n\nStarting from the foundational definitions above and the least-mean-square optimality principle for linear Gaussian estimation, derive the steady-state Kalman gain $K$ as a closed-form analytic expression in terms of $a$, $Q$, and $R$. Then, using the innovation representation, analyze how $K$ affects fault sensitivity by expressing the innovation covariance $S = \\mathbb{E}[(r_{k} - \\mathbb{E}[r_{k}])^{2}]$ in steady state and discussing the dependence of the normalized fault effect $F/\\sqrt{S}$, where $f_{k} \\equiv F$ is a constant bias, on $K$, $Q$, and $R$.\n\nYour final answer must be the closed-form analytic expression for the steady-state Kalman gain $K$ in terms of $a$, $Q$, and $R$. No numerical evaluation is required.",
            "solution": "The problem requires the derivation of the steady-state Kalman gain $K$ for a scalar system. This is achieved by solving the discrete-time algebraic Riccati equation (DARE) for the steady-state error covariance.\n\nThe standard Kalman filter covariance propagation equations are:\n1.  **Covariance Prediction:** $P_{k}^{-} = a^2 P_{k-1} + Q$\n2.  **Kalman Gain:** $K_{k} = \\frac{P_{k}^{-}}{P_{k}^{-} + R}$\n3.  **Covariance Correction:** $P_{k} = (1 - K_k) P_{k}^{-}$\n\nIn steady state, the covariances are constant: $P_{k}^{-} = P^{-}$ and $P_{k} = P_{k-1} = P$. The equations become:\n1.  $P^{-} = a^2 P + Q$\n2.  $K = \\frac{P^{-}}{P^{-} + R}$\n3.  $P = (1-K)P^{-}$\n\nWe combine these three equations to find an expression for the steady-state gain $K$.\nFrom (2), we can express $P^{-}$ in terms of $K$:\n$$K(P^{-} + R) = P^{-} \\implies KP^{-} + KR = P^{-} \\implies KR = P^{-}(1-K) \\implies P^{-} = \\frac{KR}{1-K}$$\nFrom (3), we express $P$ in terms of $P^{-}$ and $K$:\n$$P = (1-K)P^{-}$$\nSubstitute this expression for $P$ into equation (1):\n$$P^{-} = a^2 (1-K)P^{-} + Q$$\nNow, substitute the expression for $P^{-}$ in terms of $K$ into this equation:\n$$\\frac{KR}{1-K} = a^2 (1-K) \\left(\\frac{KR}{1-K}\\right) + Q$$\n$$\\frac{KR}{1-K} = a^2 KR + Q$$\nTo solve for $K$, we rearrange this into a quadratic equation:\n$$KR = (a^2 KR + Q)(1-K)$$\n$$KR = a^2 KR - a^2 KR K + Q - QK$$\n$$a^2 R K^2 + (KR - a^2 KR + QK) - Q = 0$$\n$$a^2 R K^2 + (R(1-a^2) + Q)K - Q = 0$$\n\nThis is a quadratic equation for $K$ of the form $A_K K^2 + B_K K + C_K = 0$, with:\n-   $A_K = a^2 R$\n-   $B_K = (1-a^2)R + Q$\n-   $C_K = -Q$\n\nUsing the quadratic formula, the solutions for $K$ are:\n$$K = \\frac{-B_K \\pm \\sqrt{B_K^2 - 4A_K C_K}}{2A_K}$$\nSubstituting the coefficients:\n$$K = \\frac{-((1-a^2)R + Q) \\pm \\sqrt{((1-a^2)R + Q)^2 - 4(a^2 R)(-Q)}}{2a^2 R}$$\n$$K = \\frac{-((1-a^2)R + Q) \\pm \\sqrt{((1-a^2)R + Q)^2 + 4a^2 QR}}{2a^2 R}$$\nSince $Q > 0$ and $R > 0$, the Kalman gain $K$ must be a positive value (specifically, $0  K  1$). The term under the square root is strictly greater than $|B_K|$. Therefore, to ensure a positive solution for $K$, we must choose the positive root.\n\nThe final expression for the steady-state Kalman gain is:\n$$K = \\frac{-((1-a^{2})R + Q) + \\sqrt{((1-a^{2})R + Q)^{2} + 4a^{2}QR}}{2a^{2}R}$$\n\nThe fault sensitivity analysis shows that the normalized fault effect is proportional to $\\sqrt{(1-K)/R}$, indicating a trade-off where a higher gain $K$ (optimal for estimation with low measurement noise) reduces fault detectability.",
            "answer": "$$\n\\boxed{\\frac{-((1-a^{2})R + Q) + \\sqrt{((1-a^{2})R + Q)^{2} + 4a^{2}QR}}{2a^{2}R}}\n$$"
        }
    ]
}