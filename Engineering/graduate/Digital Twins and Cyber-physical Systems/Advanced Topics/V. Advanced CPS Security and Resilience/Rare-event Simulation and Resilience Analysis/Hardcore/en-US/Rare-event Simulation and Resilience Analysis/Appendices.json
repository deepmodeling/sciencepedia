{
    "hands_on_practices": [
        {
            "introduction": "A foundational method in resilience analysis is to create a formal probabilistic model of the system, such as a Discrete-Time Markov Chain (DTMC). This exercise  demonstrates how to calculate the exact probability of a rare failure event—modeled as a reach-avoid property—by setting up and solving a system of linear equations derived from the law of total probability. This model-based approach provides a baseline understanding of how system dynamics directly translate into risk probabilities.",
            "id": "4238425",
            "problem": "A digital twin of a microgrid Cyber-Physical System (CPS) is used to evaluate resilience under cascading protection actions and fault propagation. The discrete-event evolution is modeled as a Discrete-Time Markov Chain (DTMC). The states are $\\{s_0, s_1, s_2, s_3, a, b\\}$, where $a$ encodes an unrecoverable unsafe shutdown and $b$ encodes a successful recovery to nominal operation. The system starts in $s_0$. Let $A=\\{a\\}$ and $B=\\{b\\}$. The transition probabilities are as follows (any transition not explicitly listed has probability $0$):\n- From $s_0$: to $s_1$ with probability $\\frac{1}{100}$ and to $s_3$ with probability $\\frac{99}{100}$.\n- From $s_3$: to $b$ with probability $\\frac{9}{10}$ and to $s_1$ with probability $\\frac{1}{10}$.\n- From $s_1$: to $s_2$ with probability $\\frac{1}{10}$ and to $s_3$ with probability $\\frac{9}{10}$.\n- From $s_2$: to $a$ with probability $\\frac{1}{20}$ and to $s_3$ with probability $\\frac{19}{20}$.\n- States $a$ and $b$ are absorbing.\n\nThe rare-event of interest for resilience analysis is “reach $A$ before $B$,” i.e., that the system enters an unsafe shutdown before successful recovery. Using the fundamental definition of reach-avoid probability for Markov processes, and starting only from the Markov property and the law of total probability, do the following:\n1) Construct a probabilistic temporal-logic specification in Probabilistic Computation Tree Logic (PCTL) that encodes “reach $A$ before $B$” from the initial state.\n2) Derive, set up, and solve the minimal nonnegative system of linear equations that gives the probability $p(s)$ of reaching $A$ before $B$ when starting from state $s$, with the Dirichlet boundary conditions $p(a)=1$ and $p(b)=0$. Then compute the value at the initial state $p(s_0)$.\n\nExpress your final numerical answer for $p(s_0)$ as a reduced fraction. Do not use a percentage sign. No rounding is required.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of Markov chains, is well-posed with a unique solvable structure, and is stated using objective, formal language. It is self-contained and free of contradictions.\n\nThe problem requires two tasks: constructing a Probabilistic Computation Tree Logic (PCTL) specification and solving a system of linear equations for a reach-avoid probability.\n\n### Part 1: PCTL Specification\n\nThe event of interest is \"reach set $A$ before set $B$\". In the context of temporal logic, this is a \"reach-avoid\" property. We are given the sets $A = \\{a\\}$ and $B = \\{b\\}$. The property requires that any valid path through the state space must eventually arrive at state $a$, and all states visited along this path prior to reaching $a$ must not be state $b$.\n\nProbabilistic Computation Tree Logic (PCTL) is a logic used to formally specify such properties for probabilistic systems like Markov chains. A PCTL formula specifies a property of paths starting from a certain state. The specific property \"reach $A$ before $B$\" is naturally expressed using the \"until\" operator, denoted by $\\text{U}$.\n\nA path formula $\\phi_1 \\text{ U } \\phi_2$ asserts that there is some future time step where property $\\phi_2$ holds, and at all preceding time steps, property $\\phi_1$ holds.\n\nTo formalize our specific event, we define atomic propositions. Let the proposition $a$ be true if and only if the system is in state $a$, and let the proposition $b$ be true if and only if the system is in state $b$.\nThe condition \"avoiding $B$\" means not being in state $b$, which is expressed by the logical formula $\\neg b$.\nThe condition \"reaching $A$\" means arriving at state $a$, which is expressed by the atomic proposition $a$.\n\nTherefore, the path formula that encodes \"reach $a$ before $b$\" is given by:\n$$ (\\neg b) \\text{ U } a $$\nThis formula specifies that the system must remain in states other than $b$ *until* it finally reaches state $a$. The problem of finding the probability of the rare event from the initial state $s_0$ corresponds to evaluating the PCTL query $P_{=?}[(\\neg b) \\text{ U } a]$ at state $s_0$.\n\n### Part 2: Derivation and Solution of the System of Equations\n\nLet $p(s)$ denote the probability of the event \"reach $A$ before $B$\" starting from state $s$. We need to compute $p(s_0)$. The analysis relies on the law of total probability and the Markov property.\n\nThe boundary conditions are defined on the absorbing sets $A=\\{a\\}$ and $B=\\{b\\}$.\n1. If the system starts in state $a \\in A$, it has already reached $A$ without passing through $B$. Thus, the probability is $1$. So, $p(a) = 1$.\n2. If the system starts in state $b \\in B$, it has failed to reach $A$ before $B$. Thus, the probability is $0$. So, $p(b) = 0$.\nThese are the specified Dirichlet boundary conditions.\n\nFor any non-absorbing (transient) state $s \\notin A \\cup B$, we can express $p(s)$ by conditioning on the state $s'$ at the next time step. Let $T(s, s')$ be the transition probability from state $s$ to $s'$. By the law of total probability:\n$$ p(s) = \\sum_{s'} P(\\text{reach } A \\text{ before } B \\mid \\text{next is } s') \\cdot T(s,s') $$\nDue to the Markov property, the probability of the event from the next state $s'$ is simply $p(s')$. This yields the central set of linear equations:\n$$ p(s) = \\sum_{s'} T(s,s') \\cdot p(s') $$\nLet's denote $p_i = p(s_i)$ for $i \\in \\{0, 1, 2, 3\\}$. We can now write the equations for the transient states $s_0, s_1, s_2, s_3$ using the given transition probabilities.\n\nFor state $s_0$:\n$p_0 = T(s_0, s_1)p(s_1) + T(s_0, s_3)p(s_3) = \\frac{1}{100}p_1 + \\frac{99}{100}p_3$\n\nFor state $s_1$:\n$p_1 = T(s_1, s_2)p(s_2) + T(s_1, s_3)p(s_3) = \\frac{1}{10}p_2 + \\frac{9}{10}p_3$\n\nFor state $s_2$:\n$p_2 = T(s_2, a)p(a) + T(s_2, s_3)p(s_3) = \\frac{1}{20}(1) + \\frac{19}{20}p_3$\n\nFor state $s_3$:\n$p_3 = T(s_3, b)p(b) + T(s_3, s_1)p(s_1) = \\frac{9}{10}(0) + \\frac{1}{10}p_1$\n\nThis constitutes a system of four linear equations for the four unknown probabilities $p_0, p_1, p_2, p_3$:\n1. $p_0 = \\frac{1}{100} p_1 + \\frac{99}{100} p_3$\n2. $p_1 = \\frac{1}{10} p_2 + \\frac{9}{10} p_3$\n3. $p_2 = \\frac{1}{20} + \\frac{19}{20} p_3$\n4. $p_3 = \\frac{1}{10} p_1$\n\nWe solve this system using substitution. From equation (4), we have:\n$$ p_1 = 10 p_3 $$\nSubstitute this expression for $p_1$ into equation (2):\n$$ 10 p_3 = \\frac{1}{10} p_2 + \\frac{9}{10} p_3 $$\nMultiplying by $10$ to clear the denominators:\n$$ 100 p_3 = p_2 + 9 p_3 $$\n$$ p_2 = 100 p_3 - 9 p_3 = 91 p_3 $$\nNow, substitute this expression for $p_2$ into equation (3):\n$$ 91 p_3 = \\frac{1}{20} + \\frac{19}{20} p_3 $$\nMultiplying by $20$:\n$$ 1820 p_3 = 1 + 19 p_3 $$\n$$ 1820 p_3 - 19 p_3 = 1 $$\n$$ 1801 p_3 = 1 $$\n$$ p_3 = \\frac{1}{1801} $$\nNow we can find the value of $p_0$ by back-substituting the expressions for $p_1$ and $p_3$. From equation (1):\n$$ p_0 = \\frac{1}{100} p_1 + \\frac{99}{100} p_3 $$\nSubstitute $p_1 = 10 p_3$:\n$$ p_0 = \\frac{1}{100} (10 p_3) + \\frac{99}{100} p_3 = \\frac{10 p_3 + 99 p_3}{100} = \\frac{109 p_3}{100} $$\nFinally, substitute the value of $p_3$:\n$$ p_0 = \\frac{109}{100} \\left(\\frac{1}{1801}\\right) = \\frac{109}{180100} $$\nThe number $109$ is prime. To check if the fraction can be reduced, we must check if $180100$ is divisible by $109$. Since $180100 = 1801 \\times 100$, we check if $1801$ is divisible by $109$.\n$$ \\frac{1801}{109} = 16.522... $$\n$1801$ is not divisible by $109$. Therefore, the fraction $\\frac{109}{180100}$ is in its simplest form.\n\nThe required value is $p(s_0) = \\frac{109}{180100}$.",
            "answer": "$$\\boxed{\\frac{109}{180100}}$$"
        },
        {
            "introduction": "When a complete system model is unavailable or intractable, we often rely on data from simulations or real-world operations to assess resilience. This practice  introduces a powerful statistical technique from Extreme Value Theory (EVT), using the Generalized Pareto Distribution (GPD) to model the tail of a stress metric's distribution. Mastering this allows you to extrapolate from observed data to estimate extreme quantiles, which correspond to the magnitude of very rare events, and to quantify the uncertainty in your estimate.",
            "id": "4238483",
            "problem": "A digital twin of a Cyber-Physical System (CPS) monitors a dimensionless resilience stress metric $X$ (per-unit, p.u.) at a fixed sampling cadence under stationary conditions. To support rare-event simulation and resilience analysis, a peaks-over-threshold model is adopted. Let the threshold be $u$, and suppose that exceedances $Y = X - u$ conditional on $X > u$ follow the Generalized Pareto Distribution (GPD) with scale parameter $\\sigma > 0$ and shape parameter $\\xi \\in \\mathbb{R}$. For $\\xi \\neq 0$, the GPD cumulative distribution function is\n$$\nH(y) \\;=\\; 1 - \\left(1 + \\frac{\\xi y}{\\sigma}\\right)^{-1/\\xi}, \\quad y \\ge 0,\n$$\nand the corresponding tail probability for $x \\ge u$ satisfies\n$$\nP(X > x) \\;=\\; P(X > u) \\, P(Y > x - u \\mid X > u).\n$$\nA year-long rare-event simulation produced $N$ samples with $k$ exceedances above $u$, yielding the empirical exceedance probability $p_u = P(X > u) \\approx k/N$. A maximum likelihood fit of the GPD to the exceedances produced parameter estimates $\\hat{\\sigma}$ and $\\hat{\\xi}$ and an observed Fisher information matrix $I(\\hat{\\sigma}, \\hat{\\xi})$ for $(\\sigma, \\xi)$ at the maximum likelihood estimate.\n\nGiven the following scientifically plausible quantities, all in per-unit for $X$ and $u$:\n- Threshold $u = 1.05$,\n- Sample size $N = 5.0 \\times 10^{6}$,\n- Number of exceedances $k = 2{,}500$, so $p_u = k/N = 5.0 \\times 10^{-4}$,\n- GPD maximum likelihood estimates $\\hat{\\sigma} = 0.06$ and $\\hat{\\xi} = 0.20$,\n- Observed Fisher information matrix at $(\\hat{\\sigma}, \\hat{\\xi})$ given by\n$$\nI(\\hat{\\sigma}, \\hat{\\xi}) \\;=\\;\n\\begin{pmatrix}\n700{,}000  -3{,}000 \\\\\n-3{,}000  12{,}000\n\\end{pmatrix},\n$$\nand a target extreme tail probability $p = 1.0 \\times 10^{-6}$,\n\nderive from the above base the analytical expression for the extreme quantile $q_p$ defined implicitly by $P(X > q_p) = p$, then compute the maximum likelihood estimate $\\hat{q}_p$ by substituting $(u, p_u, p, \\hat{\\sigma}, \\hat{\\xi})$.\n\nAdditionally, explain how to assess the uncertainty in $q_p$ using the profile likelihood for the scalar parameter of interest $q_p$, including the reparametrization needed to profile out the nuisance parameters and the curvature interpretation of the profile log-likelihood at $\\hat{q}_p$. Using the provided $I(\\hat{\\sigma}, \\hat{\\xi})$, compute the asymptotic standard error of $\\hat{q}_p$ via the curvature of the profile likelihood at the maximum likelihood estimate.\n\nYour final numerical report should be the single value $\\hat{q}_p$. Round your final answer to four significant figures. Express the final quantile in p.u. (per-unit).",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and complete. It is based on established principles of extreme value theory and statistical inference. All necessary data are provided, and there are no internal contradictions. Therefore, the problem is deemed valid and a full solution is presented.\n\nThe solution is structured in two principal parts. First, we derive the analytical expression for the extreme quantile $q_p$ and compute its maximum likelihood estimate, $\\hat{q_p}$. Second, we describe the methodology for uncertainty assessment using profile likelihood and compute the asymptotic standard error of $\\hat{q}_p$ via the Delta method, which is computationally equivalent.\n\n**Part 1: Derivation and Calculation of the Extreme Quantile $\\hat{q}_p$**\n\nThe extreme quantile $q_p$ is defined implicitly by the equation $P(X > q_p) = p$, where $p$ is the target extreme tail probability. The problem provides a model for the tail of the distribution of $X$. For a point $x$ above the threshold $u$, the tail probability is given by:\n$$\nP(X > x) = P(X > u) \\, P(Y > x - u \\mid X > u)\n$$\nHere, $Y = X - u$ represents the exceedance over the threshold $u$. The probability $P(X > u)$ is estimated by $p_u = k/N$. The conditional probability $P(Y > y \\mid X > u)$ corresponds to the survival function of the Generalized Pareto Distribution (GPD), which we denote as $\\bar{H}(y)$. The GPD cumulative distribution function (CDF) for $\\xi \\neq 0$ is given as:\n$$\nH(y) = 1 - \\left(1 + \\frac{\\xi y}{\\sigma}\\right)^{-1/\\xi}\n$$\nThe corresponding survival function is:\n$$\n\\bar{H}(y) = 1 - H(y) = \\left(1 + \\frac{\\xi y}{\\sigma}\\right)^{-1/\\xi}\n$$\nSubstituting these into the tail probability formula for $x = q_p$ and $y = q_p - u$, we get:\n$$\nP(X > q_p) = p_u \\, \\bar{H}(q_p - u)\n$$\n$$\np = p_u \\left(1 + \\frac{\\xi (q_p - u)}{\\sigma}\\right)^{-1/\\xi}\n$$\nWe now solve this equation for $q_p$ to find its analytical expression:\n$$\n\\frac{p}{p_u} = \\left(1 + \\frac{\\xi (q_p - u)}{\\sigma}\\right)^{-1/\\xi}\n$$\nRaise both sides to the power of $-\\xi$:\n$$\n\\left(\\frac{p}{p_u}\\right)^{-\\xi} = 1 + \\frac{\\xi (q_p - u)}{\\sigma}\n$$\nRearrange to isolate the term with $q_p$:\n$$\n\\left(\\frac{p}{p_u}\\right)^{-\\xi} - 1 = \\frac{\\xi (q_p - u)}{\\sigma}\n$$\nFinally, solve for $q_p$:\n$$\nq_p = u + \\frac{\\sigma}{\\xi} \\left[ \\left(\\frac{p}{p_u}\\right)^{-\\xi} - 1 \\right]\n$$\nThis is the required analytical expression for the extreme quantile $q_p$.\n\nTo compute the maximum likelihood estimate $\\hat{q}_p$, we substitute the given values and parameter estimates into this expression:\n$u = 1.05$, $p_u = 5.0 \\times 10^{-4}$, $p = 1.0 \\times 10^{-6}$, $\\hat{\\sigma} = 0.06$, and $\\hat{\\xi} = 0.20$.\n\nThe ratio of probabilities is:\n$$\n\\frac{p}{p_u} = \\frac{1.0 \\times 10^{-6}}{5.0 \\times 10^{-4}} = \\frac{1}{500} = 0.002\n$$\nSubstituting the values into the expression for $\\hat{q}_p$:\n$$\n\\hat{q}_p = 1.05 + \\frac{0.06}{0.20} \\left[ \\left(0.002\\right)^{-0.20} - 1 \\right]\n$$\n$$\n\\hat{q}_p = 1.05 + 0.3 \\left[ \\left(500\\right)^{0.2} - 1 \\right]\n$$\nWe compute the value of $(500)^{0.2}$:\n$$\n(500)^{0.2} = (500)^{1/5} \\approx 3.4657359\n$$\nNow, substitute this value back into the expression for $\\hat{q}_p$:\n$$\n\\hat{q}_p = 1.05 + 0.3 (3.4657359 - 1) = 1.05 + 0.3(2.4657359)\n$$\n$$\n\\hat{q}_p = 1.05 + 0.73972077 = 1.78972077\n$$\nRounding to four significant figures, we get $\\hat{q}_p \\approx 1.790$.\n\n**Part 2: Uncertainty Assessment for $\\hat{q}_p$**\n\nThe uncertainty in the estimate $\\hat{q}_p$ arises from the statistical uncertainty in the maximum likelihood estimates $\\hat{\\sigma}$ and $\\hat{\\xi}$. A standard method to assess this uncertainty is to use the profile likelihood.\n\nThe quantile $q_p$ is a function of the model parameters $(\\sigma, \\xi)$. Our parameter of interest is $\\psi_1 = q_p(\\sigma, \\xi)$, while the other parameter can be considered a nuisance. To use profile likelihood, we reparametrize the model from $(\\sigma, \\xi)$ to a new set of parameters $(\\psi_1, \\psi_2)$, where $\\psi_1=q_p$ and $\\psi_2$ is a nuisance parameter, conveniently chosen as $\\psi_2=\\xi$. We can express $(\\sigma, \\xi)$ in terms of $(q_p, \\xi)$:\n$$\n\\xi = \\psi_2\n$$\n$$\n\\sigma = \\frac{\\xi(q_p - u)}{\\left(p/p_u\\right)^{-\\xi} - 1} = \\frac{\\psi_2(q_p - u)}{\\left(p/p_u\\right)^{-\\psi_2} - 1}\n$$\nThe log-likelihood function, $l(\\sigma, \\xi)$, can be re-expressed as $l^*(q_p, \\xi)$. The profile log-likelihood for $q_p$ is then defined as:\n$$\nl_{\\text{prof}}(q_p) = \\max_{\\xi} l^*(q_p, \\xi)\n$$\nFor each fixed value of $q_p$, we find the value of the nuisance parameter $\\xi$ that maximizes the likelihood. The resulting function $l_{\\text{prof}}(q_p)$ has its maximum at the MLE $\\hat{q}_p$.\nThe curvature of the profile log-likelihood at its peak provides an estimate of the uncertainty. Specifically, the asymptotic variance of $\\hat{q}_p$ is given by the inverse of the negative second derivative of the profile log-likelihood evaluated at $\\hat{q}_p$:\n$$\n\\text{Var}(\\hat{q}_p) \\approx \\left( - \\frac{d^2 l_{\\text{prof}}(q_p)}{dq_p^2} \\Big|_{q_p=\\hat{q}_p} \\right)^{-1}\n$$\nComputationally, this variance is most conveniently calculated using the Delta method, which provides the same asymptotic result. The variance of a function $g(\\theta)$ of a parameter vector $\\theta$ is approximated by $\\text{Var}(g(\\hat{\\theta})) \\approx \\nabla g(\\hat{\\theta})^T \\text{Cov}(\\hat{\\theta}) \\nabla g(\\hat{\\theta})$. Here, $g$ is the function for $q_p$, $\\theta = (\\sigma, \\xi)$, and the covariance matrix $\\text{Cov}(\\hat{\\theta})$ is the inverse of the observed Fisher information matrix, $\\Sigma = I(\\hat{\\sigma}, \\hat{\\xi})^{-1}$.\n\nThe asymptotic standard error of $\\hat{q}_p$ is $\\text{SE}(\\hat{q}_p) = \\sqrt{\\text{Var}(\\hat{q}_p)}$.\n\nWe now compute this standard error.\nFirst, we find the covariance matrix $\\Sigma = I^{-1}$:\n$$\nI = \\begin{pmatrix} 700{,}000  -3{,}000 \\\\ -3{,}000  12{,}000 \\end{pmatrix}\n$$\nThe determinant is $\\det(I) = (700{,}000)(12{,}000) - (-3{,}000)^2 = 8.4 \\times 10^9 - 9 \\times 10^6 = 8.391 \\times 10^9$.\nThe inverse is:\n$$\n\\Sigma = I^{-1} = \\frac{1}{8.391 \\times 10^9} \\begin{pmatrix} 12{,}000  3{,}000 \\\\ 3{,}000  700{,}000 \\end{pmatrix} \\approx \\begin{pmatrix} 1.4301 \\times 10^{-6}  0.3575 \\times 10^{-6} \\\\ 0.3575 \\times 10^{-6}  8.3423 \\times 10^{-5} \\end{pmatrix}\n$$\nSecond, we compute the gradient vector $\\nabla q_p = (\\frac{\\partial q_p}{\\partial \\sigma}, \\frac{\\partial q_p}{\\partial \\xi})^T$ and evaluate it at $(\\hat{\\sigma}, \\hat{\\xi})$.\nLet $A = p/p_u = 0.002$. The partial derivatives are:\n$$\n\\frac{\\partial q_p}{\\partial \\sigma} = \\frac{1}{\\xi} \\left[ A^{-\\xi} - 1 \\right]\n$$\n$$\n\\frac{\\partial q_p}{\\partial \\xi} = \\frac{\\sigma}{\\xi^2} \\left[ 1 - A^{-\\xi} \\right] - \\frac{\\sigma}{\\xi} \\ln(A) A^{-\\xi}\n$$\nEvaluating at $(\\hat{\\sigma}, \\hat{\\xi}) = (0.06, 0.20)$:\n$$\n\\frac{\\partial q_p}{\\partial \\sigma} \\Big|_{MLE} = \\frac{1}{0.20} \\left[ (0.002)^{-0.20} - 1 \\right] = 5(3.4657359 - 1) = 12.32868\n$$\n$$\n\\frac{\\partial q_p}{\\partial \\xi} \\Big|_{MLE} = \\frac{0.06}{0.20^2} \\left[ 1 - (0.002)^{-0.20} \\right] - \\frac{0.06}{0.20} \\ln(0.002) (0.002)^{-0.20}\n$$\n$$\n= 1.5(1 - 3.4657359) - 0.3(-6.214608)(3.4657359)\n$$\n$$\n= 1.5(-2.4657359) + 6.46083 = -3.69860 + 6.46083 = 2.76223\n$$\nThe gradient vector is $\\nabla \\hat{q}_p \\approx (12.32868, 2.76223)^T$.\n\nThird, we compute the variance:\n$$\n\\text{Var}(\\hat{q}_p) \\approx \\begin{pmatrix} 12.32868  2.76223 \\end{pmatrix} \\begin{pmatrix} 1.4301 \\times 10^{-6}  0.3575 \\times 10^{-6} \\\\ 0.3575 \\times 10^{-6}  8.3423 \\times 10^{-5} \\end{pmatrix} \\begin{pmatrix} 12.32868 \\\\ 2.76223 \\end{pmatrix}\n$$\n$\\text{Var}(\\hat{q}_p) \\approx (12.32868)^2(1.4301 \\times 10^{-6}) + (2.76223)^2(8.3423 \\times 10^{-5}) + 2(12.32868)(2.76223)(0.3575 \\times 10^{-6})$\n$\\text{Var}(\\hat{q}_p) \\approx (151.996)(1.4301 \\times 10^{-6}) + (7.6299)(8.3423 \\times 10^{-5}) + (68.125)(0.3575 \\times 10^{-6})$\n$\\text{Var}(\\hat{q}_p) \\approx 2.1737 \\times 10^{-4} + 6.3659 \\times 10^{-4} + 0.2435 \\times 10^{-4}$\n$\\text{Var}(\\hat{q}_p) \\approx 8.7831 \\times 10^{-4}$\n\nFinally, the standard error is:\n$$\n\\text{SE}(\\hat{q}_p) = \\sqrt{8.7831 \\times 10^{-4}} \\approx 0.02963\n$$\nThis value quantifies the uncertainty of the estimate $\\hat{q}_p = 1.790 \\text{ p.u.}$. For example, an approximate $95\\%$ confidence interval would be $\\hat{q}_p \\pm 1.96 \\times \\text{SE}(\\hat{q}_p)$.",
            "answer": "$$\n\\boxed{1.790}\n$$"
        },
        {
            "introduction": "Resilience analysis often involves managing multiple, interacting risks simultaneously to satisfy an overall system safety requirement. This problem  explores how to allocate risk budgets across coupled subsystems using the principle of inclusion-exclusion. By leveraging bounds on the probabilities of joint failures, you will learn to derive a tighter, more efficient allocation than what is possible with a simple union bound, a crucial skill for certifying complex cyber-physical systems.",
            "id": "4238436",
            "problem": "A cyber-physical system (CPS) coordinates three coupled safety mechanisms in a resilient microgrid: voltage protection, frequency regulation, and thermal management. The microgrid’s Digital Twin (DT) runs Rare-Event Simulation using Importance Sampling (IS) to monitor and quantify the probability of safety violations over a $10$-minute operating horizon. Let the safety violation events be denoted by $A_{1}$ (voltage violation), $A_{2}$ (frequency violation), and $A_{3}$ (thermal violation).\n\nTo certify resilience, the operator imposes a joint chance constraint $ \\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\varepsilon $ with target risk budget $ \\varepsilon = 1.0 \\times 10^{-4} $. For simplified policy design, the operator allocates equal marginal risk budgets $ \\mathbb{P}(A_{i}) \\leq \\alpha $ for $ i \\in \\{1,2,3\\} $.\n\nThe DT’s Rare-Event Simulation outputs high-confidence two-sided Confidence Intervals (CI) for the pairwise intersections and a one-sided bound for the triple intersection:\n- Lower confidence bounds $ \\ell_{12} = 6.0 \\times 10^{-6} $, $ \\ell_{13} = 4.0 \\times 10^{-6} $, $ \\ell_{23} = 5.0 \\times 10^{-6} $ on $ \\mathbb{P}(A_{i} \\cap A_{j}) $,\n- An upper confidence bound $ \\tau = 1.0 \\times 10^{-8} $ on $ \\mathbb{P}(A_{1} \\cap A_{2} \\cap A_{3}) $.\n\nStarting from the axioms of probability, apply Boole’s inequality (the union bound) to decompose the joint chance constraint across the three safety constraints, and then design a tighter conservative approximation using the inclusion–exclusion principle (Bonferroni truncation) that leverages the available intersection bounds. Derive, from first principles, the largest equal marginal allocation $ \\alpha $ that guarantees $ \\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\varepsilon $ under the given DT-estimated bounds.\n\nCompute this $ \\alpha $ numerically using the provided values. Express your final answer as a decimal and round to four significant figures.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, objective, and complete. All givens are extracted and examined.\n- Events: $A_{1}$ (voltage violation), $A_{2}$ (frequency violation), $A_{3}$ (thermal violation).\n- Joint chance constraint: $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\varepsilon$.\n- Target risk budget: $\\varepsilon = 1.0 \\times 10^{-4}$.\n- Marginal risk budget constraint: $\\mathbb{P}(A_{i}) \\leq \\alpha$ for $i \\in \\{1,2,3\\}$.\n- Lower confidence bounds for pairwise intersections: $\\mathbb{P}(A_1 \\cap A_2) \\geq \\ell_{12} = 6.0 \\times 10^{-6}$, $\\mathbb{P}(A_1 \\cap A_3) \\geq \\ell_{13} = 4.0 \\times 10^{-6}$, $\\mathbb{P}(A_2 \\cap A_3) \\geq \\ell_{23} = 5.0 \\times 10^{-6}$.\n- Upper confidence bound for the triple intersection: $\\mathbb{P}(A_{1} \\cap A_{2} \\cap A_{3}) \\leq \\tau = 1.0 \\times 10^{-8}$.\n\nThe problem is a standard application of probability theory, specifically the principle of inclusion-exclusion, to the domain of engineering resilience and risk analysis. The terminology is precise, the data is consistent, and the objective is clearly defined. The problem is valid. We may proceed with the solution.\n\nOur objective is to find the largest value of the marginal risk budget, $\\alpha$, that guarantees the satisfaction of the joint chance constraint, $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\varepsilon$, given the constraints on the marginal and intersection probabilities.\n\nThe problem asks us to start from first principles. The probability of the union of three events $A_1$, $A_2$, and $A_3$ is given by the principle of inclusion-exclusion:\n$$\n\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) = \\sum_{i=1}^{3} \\mathbb{P}(A_{i}) - \\sum_{1 \\leq i  j \\leq 3} \\mathbb{P}(A_{i} \\cap A_{j}) + \\mathbb{P}(A_{1} \\cap A_{2} \\cap A_{3})\n$$\nThe problem contrasts Boole's inequality (a simple union bound) with a tighter approximation. Boole's inequality states $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\sum_{i=1}^{3} \\mathbb{P}(A_{i})$. Using the marginal risk budget $\\mathbb{P}(A_i) \\leq \\alpha$, this yields $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq 3\\alpha$. This is a conservative bound that ignores the information about event intersections.\n\nTo derive the requested tighter conservative approximation, we must use all available information to establish the most restrictive upper bound on $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3})$. We bound each term in the inclusion-exclusion formula as follows:\n1.  For the sum of marginal probabilities: The problem states $\\mathbb{P}(A_{i}) \\leq \\alpha$ for $i \\in \\{1,2,3\\}$. Therefore, the sum is bounded above:\n    $$ \\sum_{i=1}^{3} \\mathbb{P}(A_{i}) = \\mathbb{P}(A_{1}) + \\mathbb{P}(A_{2}) + \\mathbb{P}(A_{3}) \\leq \\alpha + \\alpha + \\alpha = 3\\alpha $$\n2.  For the sum of pairwise intersection probabilities: The term in the formula is negative, $- \\sum \\mathbb{P}(A_{i} \\cap A_{j})$. The problem provides lower confidence bounds on these probabilities: $\\mathbb{P}(A_{i} \\cap A_{j}) \\geq \\ell_{ij}$. Multiplying by $-1$ reverses the inequality, yielding an upper bound for the negative term: $-\\mathbb{P}(A_{i} \\cap A_{j}) \\leq -\\ell_{ij}$. Consequently, the sum is bounded above:\n    $$ - \\sum_{1 \\leq i  j \\leq 3} \\mathbb{P}(A_{i} \\cap A_{j}) \\leq -(\\ell_{12} + \\ell_{13} + \\ell_{23}) $$\n3.  For the triple intersection probability: The problem provides a direct upper confidence bound:\n    $$ \\mathbb{P}(A_{1} \\cap A_{2} \\cap A_{3}) \\leq \\tau $$\n\nCombining these individual upper bounds, we can construct a total upper bound for the probability of the union:\n$$\n\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq 3\\alpha - (\\ell_{12} + \\ell_{13} + \\ell_{23}) + \\tau\n$$\nThis is the Bonferroni-type inequality that represents the tighter conservative approximation. To guarantee the joint chance constraint $\\mathbb{P}(A_{1} \\cup A_{2} \\cup A_{3}) \\leq \\varepsilon$, we must ensure that our derived upper bound is itself less than or equal to $\\varepsilon$:\n$$\n3\\alpha - (\\ell_{12} + \\ell_{13} + \\ell_{23}) + \\tau \\leq \\varepsilon\n$$\nWe are asked to find the largest possible value of $\\alpha$ that satisfies this condition. This is achieved when the inequality becomes an equality:\n$$\n3\\alpha - (\\ell_{12} + \\ell_{13} + \\ell_{23}) + \\tau = \\varepsilon\n$$\nSolving for $\\alpha$, we get:\n$$\n3\\alpha = \\varepsilon + \\ell_{12} + \\ell_{13} + \\ell_{23} - \\tau\n$$\n$$\n\\alpha = \\frac{1}{3} (\\varepsilon + \\ell_{12} + \\ell_{13} + \\ell_{23} - \\tau)\n$$\nNow, we substitute the provided numerical values into this expression:\n$\\varepsilon = 1.0 \\times 10^{-4}$\n$\\ell_{12} = 6.0 \\times 10^{-6}$\n$\\ell_{13} = 4.0 \\times 10^{-6}$\n$\\ell_{23} = 5.0 \\times 10^{-6}$\n$\\tau = 1.0 \\times 10^{-8}$\n\nFirst, sum the lower bounds on the pairwise intersections:\n$$\n\\ell_{12} + \\ell_{13} + \\ell_{23} = (6.0 + 4.0 + 5.0) \\times 10^{-6} = 15.0 \\times 10^{-6}\n$$\nNow substitute all values into the expression for $\\alpha$:\n$$\n\\alpha = \\frac{1}{3} (1.0 \\times 10^{-4} + 15.0 \\times 10^{-6} - 1.0 \\times 10^{-8})\n$$\nTo perform the arithmetic, we express all numbers with a common power of $10$, for instance $10^{-8}$:\n$1.0 \\times 10^{-4} = 10000 \\times 10^{-8}$\n$15.0 \\times 10^{-6} = 1500 \\times 10^{-8}$\n$1.0 \\times 10^{-8} = 1 \\times 10^{-8}$\n$$\n\\alpha = \\frac{1}{3} (10000 \\times 10^{-8} + 1500 \\times 10^{-8} - 1 \\times 10^{-8})\n$$\n$$\n\\alpha = \\frac{1}{3} (10000 + 1500 - 1) \\times 10^{-8}\n$$\n$$\n\\alpha = \\frac{11499}{3} \\times 10^{-8}\n$$\n$$\n\\alpha = 3833 \\times 10^{-8}\n$$\nExpressing this in standard scientific notation and rounding to four significant figures as requested:\n$$\n\\alpha = 3.833 \\times 10^{-5}\n$$\nThis is the largest marginal risk budget $\\alpha$ that guarantees the joint chance constraint is met under the conservative bounds provided by the Digital Twin simulation.",
            "answer": "$$ \\boxed{3.833 \\times 10^{-5}} $$"
        }
    ]
}