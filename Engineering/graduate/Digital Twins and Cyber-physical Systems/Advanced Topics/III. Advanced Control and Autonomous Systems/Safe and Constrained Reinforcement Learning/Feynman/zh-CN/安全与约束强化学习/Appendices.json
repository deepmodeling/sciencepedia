{
    "hands_on_practices": [
        {
            "introduction": "在有约束马尔可夫决策过程 (CMDP) 中，评估一个给定策略的安全性是首要任务。这项练习将带你实践安全策略评估的核心过程 。通过应用贝尔曼期望方程，你将为一个在数字孪生模型中运行的控制器计算其预期的累积安全成本，从而深入理解策略、系统动态和安全成本函数之间的相互作用。",
            "id": "4242700",
            "problem": "在一个信息物理系统（CPS）中，一个微电网逆变器的数字孪生被用来评估一个基于学习的控制器的安全性能。该安全信号在强化学习（RL）框架内通过马尔可夫决策过程（MDP）进行建模。该 MDP 有一个有限状态空间 $S = \\{s_{N}, s_{C}, s_{E}\\}$，分别代表运行模式：$s_{N}$ (正常)，$s_{C}$ (拥堵) 和 $s_{E}$ (紧急)。动作空间为 $A = \\{a_{0}, a_{1}\\}$，其中 $a_{0}$ 是保守控制（低驱动压力），$a_{1}$ 是激进控制（高驱动压力）。单步安全成本函数 $c(s,a)$ 编码了风险暴露（无量纲），具体如下：\n- $c(s_{N}, a_{0}) = \\frac{1}{10}$, $c(s_{N}, a_{1}) = \\frac{3}{10}$,\n- $c(s_{C}, a_{0}) = \\frac{2}{5}$, $c(s_{C}, a_{1}) = \\frac{4}{5}$,\n- $c(s_{E}, a_{0}) = 1$, $c(s_{E}, a_{1}) = \\frac{6}{5}$.\n\n受控的转移动态 $P(s' \\mid s, a)$ 为：\n- 从 $s_{N}$ 出发：当动作为 $a_{0}$ 时，$P(s_{N} \\mid s_{N}, a_{0}) = \\frac{4}{5}$，$P(s_{C} \\mid s_{N}, a_{0}) = \\frac{1}{5}$，$P(s_{E} \\mid s_{N}, a_{0}) = 0$；当动作为 $a_{1}$ 时，$P(s_{N} \\mid s_{N}, a_{1}) = \\frac{1}{2}$，$P(s_{C} \\mid s_{N}, a_{1}) = \\frac{1}{2}$，$P(s_{E} \\mid s_{N}, a_{1}) = 0$。\n- 从 $s_{C}$ 出发：当动作为 $a_{0}$ 时，$P(s_{N} \\mid s_{C}, a_{0}) = \\frac{1}{2}$，$P(s_{C} \\mid s_{C}, a_{0}) = \\frac{1}{3}$，$P(s_{E} \\mid s_{C}, a_{0}) = \\frac{1}{6}$；当动作为 $a_{1}$ 时，$P(s_{N} \\mid s_{C}, a_{1}) = \\frac{1}{3}$，$P(s_{C} \\mid s_{C}, a_{1}) = \\frac{1}{3}$，$P(s_{E} \\mid s_{C}, a_{1}) = \\frac{1}{3}$。\n- 从 $s_{E}$ 出发：当动作为 $a_{0}$ 时，$P(s_{N} \\mid s_{E}, a_{0}) = 0$，$P(s_{C} \\mid s_{E}, a_{0}) = \\frac{1}{2}$，$P(s_{E} \\mid s_{E}, a_{0}) = \\frac{1}{2}$；当动作为 $a_{1}$ 时，$P(s_{N} \\mid s_{E}, a_{1}) = 0$，$P(s_{C} \\mid s_{E}, a_{1}) = 0$，$P(s_{E} \\mid s_{E}, a_{1}) = 1$。\n\n控制器遵循一个固定的表格化策略 $\\pi(a \\mid s)$：\n- $\\pi(a_{0} \\mid s_{N}) = \\frac{3}{4}$, $\\pi(a_{1} \\mid s_{N}) = \\frac{1}{4}$,\n- $\\pi(a_{0} \\mid s_{C}) = \\frac{2}{3}$, $\\pi(a_{1} \\mid s_{C}) = \\frac{1}{3}$,\n- $\\pi(a_{0} \\mid s_{E}) = 1$, $\\pi(a_{1} \\mid s_{E}) = 0$.\n\n设折扣因子为 $\\gamma = \\frac{1}{2}$。仅使用马尔可夫决策过程和强化学习中折扣期望回报的基本定义，计算在策略 $\\pi$ 下从状态 $s_{N}$ 开始的期望折扣累积安全成本 $C^{\\pi}(s_{N})$。提供所有中间步骤。将你的最终答案表示为一个无单位的精确分数。安全成本是无量纲的。",
            "solution": "该问题是有效的，因为它在马尔可夫决策过程（MDP）和强化学习（RL）的标准框架内是自洽的、数学上一致且适定的。所有必要的参数——状态、动作、转移概率、成本函数、策略和折扣因子——均已提供并符合其定义。任务是计算给定策略的价值函数，这是一个标准的策略评估问题。\n\n策略 $\\pi$ 的期望折扣累积安全成本，记作 $C^{\\pi}(s)$，表示从一个起始状态 $s$ 开始累积的总期望成本，未来的成本以因子 $\\gamma$ 进行折扣。它由贝尔曼期望方程定义：\n$$C^{\\pi}(s) = \\mathbb{E}_{\\pi} \\left[ \\sum_{t=0}^{\\infty} \\gamma^{t} c(s_t, a_t) \\mid s_0 = s \\right]$$\n对于每个状态 $s \\in S$，这可以递归地表示为：\n$$C^{\\pi}(s) = \\sum_{a \\in A} \\pi(a \\mid s) \\left( c(s, a) + \\gamma \\sum_{s' \\in S} P(s' \\mid s, a) C^{\\pi}(s') \\right)$$\n其中 $S = \\{s_{N}, s_{C}, s_{E}\\}$ 是状态空间，$A = \\{a_0, a_1\\}$ 是动作空间，$c(s, a)$ 是单步成本函数，$P(s' \\mid s, a)$ 是转移概率，$\\pi(a \\mid s)$ 是策略，$\\gamma = \\frac{1}{2}$ 是折扣因子。\n\n为简化贝尔曼方程，我们首先计算策略平均的单步成本 $c^{\\pi}(s)$ 和策略平均的转移概率 $P^{\\pi}(s' \\mid s)$。\n\n对于状态 $s_N$：\n$c^{\\pi}(s_{N}) = \\sum_{a \\in A} \\pi(a \\mid s_{N}) c(s_{N}, a) = \\pi(a_0 \\mid s_{N})c(s_{N}, a_0) + \\pi(a_1 \\mid s_{N})c(s_{N}, a_1) = \\frac{3}{4} \\cdot \\frac{1}{10} + \\frac{1}{4} \\cdot \\frac{3}{10} = \\frac{3}{40} + \\frac{3}{40} = \\frac{6}{40} = \\frac{3}{20}$.\n$P^{\\pi}(s_{N} \\mid s_{N}) = \\sum_{a \\in A} \\pi(a \\mid s_{N}) P(s_{N} \\mid s_{N}, a) = \\frac{3}{4} \\cdot \\frac{4}{5} + \\frac{1}{4} \\cdot \\frac{1}{2} = \\frac{3}{5} + \\frac{1}{8} = \\frac{24+5}{40} = \\frac{29}{40}$.\n$P^{\\pi}(s_{C} \\mid s_{N}) = \\sum_{a \\in A} \\pi(a \\mid s_{N}) P(s_{C} \\mid s_{N}, a) = \\frac{3}{4} \\cdot \\frac{1}{5} + \\frac{1}{4} \\cdot \\frac{1}{2} = \\frac{3}{20} + \\frac{1}{8} = \\frac{6+5}{40} = \\frac{11}{40}$.\n$P^{\\pi}(s_{E} \\mid s_{N}) = \\sum_{a \\in A} \\pi(a \\mid s_{N}) P(s_{E} \\mid s_{N}, a) = \\frac{3}{4} \\cdot 0 + \\frac{1}{4} \\cdot 0 = 0$.\n\n对于状态 $s_C$：\n$c^{\\pi}(s_{C}) = \\sum_{a \\in A} \\pi(a \\mid s_{C}) c(s_{C}, a) = \\frac{2}{3} \\cdot \\frac{2}{5} + \\frac{1}{3} \\cdot \\frac{4}{5} = \\frac{4}{15} + \\frac{4}{15} = \\frac{8}{15}$.\n$P^{\\pi}(s_{N} \\mid s_{C}) = \\sum_{a \\in A} \\pi(a \\mid s_{C}) P(s_{N} \\mid s_{C}, a) = \\frac{2}{3} \\cdot \\frac{1}{2} + \\frac{1}{3} \\cdot \\frac{1}{3} = \\frac{1}{3} + \\frac{1}{9} = \\frac{4}{9}$.\n$P^{\\pi}(s_{C} \\mid s_{C}) = \\sum_{a \\in A} \\pi(a \\mid s_{C}) P(s_{C} \\mid s_{C}, a) = \\frac{2}{3} \\cdot \\frac{1}{3} + \\frac{1}{3} \\cdot \\frac{1}{3} = \\frac{2}{9} + \\frac{1}{9} = \\frac{3}{9} = \\frac{1}{3}$.\n$P^{\\pi}(s_{E} \\mid s_{C}) = \\sum_{a \\in A} \\pi(a \\mid s_{C}) P(s_{E} \\mid s_{C}, a) = \\frac{2}{3} \\cdot \\frac{1}{6} + \\frac{1}{3} \\cdot \\frac{1}{3} = \\frac{1}{9} + \\frac{1}{9} = \\frac{2}{9}$.\n\n对于状态 $s_E$：\n策略是确定性的：$\\pi(a_0 \\mid s_E)=1$, $\\pi(a_1 \\mid s_E)=0$.\n$c^{\\pi}(s_{E}) = 1 \\cdot c(s_{E}, a_0) = 1$.\n$P^{\\pi}(s_{N} \\mid s_{E}) = 1 \\cdot P(s_{N} \\mid s_{E}, a_0) = 0$.\n$P^{\\pi}(s_{C} \\mid s_{E}) = 1 \\cdot P(s_{C} \\mid s_{E}, a_0) = \\frac{1}{2}$.\n$P^{\\pi}(s_{E} \\mid s_{E}) = 1 \\cdot P(s_{E} \\mid s_{E}, a_0) = \\frac{1}{2}$.\n\n现在，策略 $\\pi$ 的贝尔曼期望方程简化为：\n$$C^{\\pi}(s) = c^{\\pi}(s) + \\gamma \\sum_{s' \\in S} P^{\\pi}(s' \\mid s) C^{\\pi}(s')$$\n令 $C_N = C^{\\pi}(s_N)$，$C_C = C^{\\pi}(s_C)$，以及 $C_E = C^{\\pi}(s_E)$。这就定义了一个三元线性方程组：\n\n1. 对于 $s_N$：\n$C_N = c^{\\pi}(s_N) + \\gamma (P^{\\pi}(s_N \\mid s_N) C_N + P^{\\pi}(s_C \\mid s_N) C_C)$\n$C_N = \\frac{3}{20} + \\frac{1}{2} \\left( \\frac{29}{40} C_N + \\frac{11}{40} C_C \\right)$\n$C_N = \\frac{3}{20} + \\frac{29}{80} C_N + \\frac{11}{80} C_C$\n$(1 - \\frac{29}{80}) C_N - \\frac{11}{80} C_C = \\frac{3}{20}$\n$\\frac{51}{80} C_N - \\frac{11}{80} C_C = \\frac{12}{80} \\implies 51 C_N - 11 C_C = 12$ (方程 I)\n\n2. 对于 $s_C$：\n$C_C = c^{\\pi}(s_C) + \\gamma (P^{\\pi}(s_N \\mid s_C) C_N + P^{\\pi}(s_C \\mid s_C) C_C + P^{\\pi}(s_E \\mid s_C) C_E)$\n$C_C = \\frac{8}{15} + \\frac{1}{2} \\left( \\frac{4}{9} C_N + \\frac{1}{3} C_C + \\frac{2}{9} C_E \\right)$\n$C_C = \\frac{8}{15} + \\frac{2}{9} C_N + \\frac{1}{6} C_C + \\frac{1}{9} C_E$\n$(1 - \\frac{1}{6}) C_C - \\frac{2}{9} C_N - \\frac{1}{9} C_E = \\frac{8}{15}$\n$\\frac{5}{6} C_C - \\frac{2}{9} C_N - \\frac{1}{9} C_E = \\frac{8}{15}$\n方程两边同乘以分母的最小公倍数 ($90$)：\n$75 C_C - 20 C_N - 10 C_E = 48 \\implies -20 C_N + 75 C_C - 10 C_E = 48$ (方程 II)\n\n3. 对于 $s_E$：\n$C_E = c^{\\pi}(s_E) + \\gamma (P^{\\pi}(s_C \\mid s_E) C_C + P^{\\pi}(s_E \\mid s_E) C_E)$\n$C_E = 1 + \\frac{1}{2} \\left( \\frac{1}{2} C_C + \\frac{1}{2} C_E \\right)$\n$C_E = 1 + \\frac{1}{4} C_C + \\frac{1}{4} C_E$\n$(1 - \\frac{1}{4}) C_E - \\frac{1}{4} C_C = 1$\n$\\frac{3}{4} C_E - \\frac{1}{4} C_C = 1 \\implies 3 C_E - C_C = 4$ (方程 III)\n\n我们现在求解这个方程组。从方程 III，我们将 $C_C$ 用 $C_E$ 表示：\n$C_C = 3 C_E - 4$\n\n将 $C_C$ 的这个表达式代入方程 I：\n$51 C_N - 11 (3 C_E - 4) = 12$\n$51 C_N - 33 C_E + 44 = 12$\n$51 C_N - 33 C_E = -32$ (方程 IV)\n\n将 $C_C$ 的表达式代入方程 II：\n$-20 C_N + 75 (3 C_E - 4) - 10 C_E = 48$\n$-20 C_N + 225 C_E - 300 - 10 C_E = 48$\n$-20 C_N + 215 C_E = 348$ (方程 V)\n\n现在我们得到一个包含两个变量 $C_N$ 和 $C_E$ 的二元方程组（IV 和 V）。\n从方程 IV，我们可以将 $C_E$ 用 $C_N$ 表示：\n$33 C_E = 51 C_N + 32 \\implies C_E = \\frac{51 C_N + 32}{33}$\n\n将此代入方程 V：\n$-20 C_N + 215 \\left( \\frac{51 C_N + 32}{33} \\right) = 348$\n整个方程乘以 $33$：\n$-20 \\cdot 33 \\cdot C_N + 215 (51 C_N + 32) = 348 \\cdot 33$\n$-660 C_N + (215 \\cdot 51) C_N + (215 \\cdot 32) = 11484$\n$-660 C_N + 10965 C_N + 6880 = 11484$\n$(10965 - 660) C_N = 11484 - 6880$\n$10305 C_N = 4604$\n$C_N = \\frac{4604}{10305}$\n\n题目要求计算 $C^{\\pi}(s_{N})$，即 $C_N$。分数 $\\frac{4604}{10305}$ 是不可约的，因为分子的质因数分解是 $4604 = 2^2 \\cdot 1151$，分母的质因数分解是 $10305 = 3^2 \\cdot 5 \\cdot 229$，它们没有公质因数。",
            "answer": "$$\\boxed{\\frac{4604}{10305}}$$"
        },
        {
            "introduction": "平均成本并不能完全反映安全风险，因为单次灾难性事件的发生可能无法通过大量安全事件来弥补。条件风险价值 (Conditional Value at Risk, CVaR) 是一种关注最坏情况的风险度量。本练习旨在让你通过处理一组从数字孪生仿真中收集的实证成本数据，亲手计算 CVaR，从而掌握量化和管理尾部风险的关键技能 。",
            "id": "4242685",
            "problem": "一个微电网（一类信息物理系统 (CPS)）的数字孪生被用于训练一个强化学习 (RL) 控制器，该控制器调度储能和可控负载。为确保安全，每个回合都被赋予一个无量纲标量成本 $z_i$，该成本汇总了整个回合中的约束违反（例如，逆变器过流和电压偏差）。考虑 $N=20$ 个已完成的训练回合，其经验分布将相等的概率质量 $1/N$ 赋予观察到的成本 $\\{z_i\\}_{i=1}^{N}$：\n$$\\{z_i\\}_{i=1}^{20} = \\{32.5,\\; 45.1,\\; 27.9,\\; 53.4,\\; 39.8,\\; 61.7,\\; 48.2,\\; 55.6,\\; 42.3,\\; 36.9,\\; 67.1,\\; 58.4,\\; 71.6,\\; 62.9,\\; 75.3,\\; 47.7,\\; 83.5,\\; 68.2,\\; 91.4,\\; 86.8\\}.$$\n使用条件风险价值 (CVaR) 的定义，通过找到最小化阈值和相关的尾部期望，为此经验分布计算风险水平 $\\alpha=0.9$ 时的 $\\mathrm{CVaR}_{\\alpha}$。将您的最终答案表示为一个实数（无量纲），并四舍五入到四位有效数字。",
            "solution": "问题要求对给定的 $N=20$ 个成本值 $\\{z_i\\}_{i=1}^{20}$ 的经验分布，计算风险水平 $\\alpha=0.9$ 时的条件风险价值，记为 $\\mathrm{CVaR}_{0.9}$。\n\n首先，我们确定定义。对于代表成本或损失的随机变量 $Z$，风险水平为 $\\alpha$ 时的风险价值 ($\\mathrm{VaR}_{\\alpha}$) 是其分布的 $\\alpha$-分位数。风险水平为 $\\alpha$ 时的条件风险价值 ($\\mathrm{CVaR}_{\\alpha}$) 是在损失大于或等于 $\\mathrm{VaR}_{\\alpha}$ 的条件下，损失的期望值。对于基于有限样本集的离散分布，这简化为分布极端尾部数值的平均值。\n\n问题提供了以下数据：\n- 回合数：$N=20$。\n- 风险水平：$\\alpha=0.9$。\n- 观察到的无量纲成本集合：$\\{z_i\\}_{i=1}^{20} = \\{32.5, 45.1, 27.9, 53.4, 39.8, 61.7, 48.2, 55.6, 42.3, 36.9, 67.1, 58.4, 71.6, 62.9, 75.3, 47.7, 83.5, 68.2, 91.4, 86.8\\}$。\n经验分布为每个观察到的成本 $z_i$ 分配了 $p_i = \\frac{1}{N} = \\frac{1}{20}$ 的概率。\n\n第一步是将观察到的成本按非递减顺序排序，以获得顺序统计量，记为 $z_{(i)}$，其中 $i=1, \\dots, 20$。\n排序后的列表是：\n$z_{(1)} = 27.9$\n$z_{(2)} = 32.5$\n$z_{(3)} = 36.9$\n$z_{(4)} = 39.8$\n$z_{(5)} = 42.3$\n$z_{(6)} = 45.1$\n$z_{(7)} = 47.7$\n$z_{(8)} = 48.2$\n$z_{(9)} = 53.4$\n$z_{(10)} = 55.6$\n$z_{(11)} = 58.4$\n$z_{(12)} = 61.7$\n$z_{(13)} = 62.9$\n$z_{(14)} = 67.1$\n$z_{(15)} = 68.2$\n$z_{(16)} = 71.6$\n$z_{(17)} = 75.3$\n$z_{(18)} = 83.5$\n$z_{(19)} = 86.8$\n$z_{(20)} = 91.4$\n\n问题陈述要求通过找到最小化阈值和相关的尾部期望来计算 $\\mathrm{CVaR}_{\\alpha}$。最小化阈值是风险价值 $\\mathrm{VaR}_{\\alpha}$。对于大小为 $N$ 的样本，样本 $\\mathrm{VaR}_{\\alpha}$ 估计为第 $k$ 个顺序统计量，其中 $k = \\lceil \\alpha N \\rceil$。\n对于 $\\alpha=0.9$ 和 $N=20$，索引 $k$ 为：\n$$k = \\lceil \\alpha N \\rceil = \\lceil 0.9 \\times 20 \\rceil = \\lceil 18 \\rceil = 18$$\n因此，最小化阈值是排序列表中第 $18$ 个值：\n$$\\mathrm{VaR}_{0.9} = z_{(18)} = 83.5$$\n\n现在，我们计算相关的尾部期望，即 $\\mathrm{CVaR}_{0.9}$。$\\mathrm{CVaR}_{\\alpha}$ 是所有满足 $z \\ge \\mathrm{VaR}_{\\alpha}$ 的值 $z$ 的平均值。在来自 $N$ 个样本的经验分布的背景下，这对应于对最差的 $(1-\\alpha)$ 部分结果中的值进行平均。\n尾部的观察数量由下式给出：\n$$M = (1-\\alpha)N = (1-0.9) \\times 20 = 0.1 \\times 20 = 2$$\n由于 $M=2$ 是一个整数，并且 $\\alpha N$ 也是一个整数，$\\mathrm{CVaR}_{0.9}$ 可以被计算为 $M=2$ 个最大观察成本的算术平均值。这些值是 $z_{(19)}$ 和 $z_{(20)}$。\n使用排序后的列表，我们确定这些值：\n$$z_{(19)} = 86.8$$\n$$z_{(20)} = 91.4$$\n$\\mathrm{CVaR}_{0.9}$ 是这两个值的平均值：\n$$\\mathrm{CVaR}_{0.9} = \\frac{z_{(19)} + z_{(20)}}{2} = \\frac{86.8 + 91.4}{2}$$\n进行计算：\n$$\\mathrm{CVaR}_{0.9} = \\frac{178.2}{2} = 89.1$$\n问题要求答案四舍五入到四位有效数字。数字 $89.1$ 有三位有效数字。为了用四位有效数字表示它，我们写作 $89.10$。",
            "answer": "$$\\boxed{89.10}$$"
        },
        {
            "introduction": "评估和度量风险之后，下一步是主动强制执行安全约束，安全滤波器（或称安全护盾）是实现这一目标的常用方法。这项编程练习将指导你构建一个核心组件：一个通过求解二次规划 (Quadratic Program, QP) 将名义动作（可能不安全）投影到安全动作集上的算法，以此实现对智能体行为的最小侵入式修正 。",
            "id": "4242673",
            "problem": "您正在为信息物理系统（Cyber-Physical System, CPS）的数字孪生（Digital Twin, DT）中由强化学习（Reinforcement Learning, RL）生成的动作构建一个安全滤波器。在每个时刻，给定当前状态 $x \\in \\mathbb{R}^n$ 和一个标称动作 $u_0 \\in \\mathbb{R}^p$，安全滤波器必须通过将 $u_0$ 投影到由 DT 指定的可行集上来计算最小侵入性校正。该可行集由形式为 $c(x,u) \\le 0$ 的状态依赖线性安全约束定义，其中 $c(x,u) = G u - (H x + d)$，并且 $G \\in \\mathbb{R}^{m \\times p}$，$H \\in \\mathbb{R}^{m \\times n}$，$d \\in \\mathbb{R}^m$。最小侵入性校正是一个严格凸二次规划（Quadratic Program, QP）问题的解，该问题在满足约束的条件下最小化到 $u_0$ 的欧几里得距离。该投影问题表示为以下优化问题\n$$\n\\min_{u \\in \\mathbb{R}^p} \\ \\|u - u_0\\|_2^2 \\quad \\text{subject to} \\quad G u \\le H x + d.\n$$\n维度 $p$ 为 $p = 2$，约束数量为 $m = 5$。状态维度为 $n = 2$。使用固定的矩阵\n$$\nG = \\begin{bmatrix}\n1  0 \\\\\n0  1 \\\\\n-1  0 \\\\\n0  -1 \\\\\n1  1\n\\end{bmatrix}, \\quad\nH = \\begin{bmatrix}\n-0.5  0.0 \\\\\n0.0  0.0 \\\\\n0.0  0.0 \\\\\n0.0  0.0 \\\\\n-0.2  0.1\n\\end{bmatrix}, \\quad\nd = \\begin{bmatrix}\n1.0 \\\\\n1.0 \\\\\n1.0 \\\\\n1.0 \\\\\n1.2\n\\end{bmatrix}.\n$$\n对于下面测试套件中的每个测试用例，计算求解上述优化问题的投影动作 $u^\\star(x,u_0)$。所有量都是无量纲的，并且必须在 $\\mathbb{R}$ 中处理。\n\n测试套件（每个用例是一个对 $(x,u_0)$）：\n- 用例 1：$x = [0.0, 0.0]$, $u_0 = [0.5, 0.25]$。\n- 用例 2：$x = [0.0, 0.0]$, $u_0 = [2.0, 0.0]$。\n- 用例 3：$x = [0.0, 0.0]$, $u_0 = [2.0, -2.0]$。\n- 用例 4：$x = [0.0, -7.0]$, $u_0 = [0.8, 0.4]$。\n- 用例 5：$x = [0.0, 0.0]$, $u_0 = [1.0, 0.2]$。\n- 用例 6：$x = [2.0, 0.0]$, $u_0 = [0.8, 0.9]$。\n\n您的程序必须：\n- 实现一个数学上可靠的算法，仅使用提供的固定 $G$、$H$ 和 $d$ 来为每个测试用例计算 $u^\\star(x,u_0)$，其中 $h(x) = H x + d$。\n- 确保所有情况下的数值稳定性和理论正确性，包括边界可行（在约束上）和多约束激活场景。\n- 将最终输出生成为单行，其中包含聚合到列表的列表中的结果。每个内部列表必须是相应测试用例的投影动作向量 $u^\\star$，顺序与上面相同。确切的输出格式必须是单行：\n$$\n[\\,[u^\\star_1[0],u^\\star_1[1]],[u^\\star_2[0],u^\\star_2[1]],\\dots,[u^\\star_6[0],u^\\star_6[1]]\\,]\n$$\n不应打印任何附加文本。",
            "solution": "我们从第一性原理推导最小侵入性投影算法。对于给定的标称动作 $u_0 \\in \\mathbb{R}^p$ 和状态 $x \\in \\mathbb{R}^n$，安全集定义为 $m$ 个线性半空间的交集\n$$\n\\mathcal{C}(x) = \\{u \\in \\mathbb{R}^p \\mid G u \\le H x + d\\}.\n$$\n安全滤波器寻求 $u_0$ 到 $\\mathcal{C}(x)$ 上的欧几里得投影，这是严格凸二次规划（Quadratic Program, QP）的唯一解\n$$\n\\min_{u \\in \\mathbb{R}^p} \\ \\|u - u_0\\|_2^2 \\ \\text{ subject to } \\ G u \\le H x + d.\n$$\n该公式源于欧几里得投影到非空闭凸集上的定义：对于任何闭凸集 $\\mathcal{C}(x)$，由于目标函数的严格凸性和 $\\mathcal{C}(x)$ 的凸性，最小化 $\\|u - u_0\\|_2^2$ 的点 $u^\\star \\in \\mathcal{C}(x)$ 存在且唯一。\n\nKarush-Kuhn-Tucker (KKT) 最优性条件为解提供了一个原则性的刻画。为不等式约束 $G u \\le h(x)$ 引入拉格朗日乘子 $\\lambda \\in \\mathbb{R}^m$，其中 $h(x) = H x + d$。拉格朗日函数为\n$$\n\\mathcal{L}(u,\\lambda) = \\tfrac{1}{2}\\|u - u_0\\|_2^2 + \\lambda^\\top(G u - h(x)),\n$$\n其中 $\\lambda \\ge 0$。KKT 条件是：\n1. 稳定性（Stationarity）：$\\nabla_u \\mathcal{L}(u^\\star,\\lambda^\\star) = 0 \\Rightarrow u^\\star - u_0 + G^\\top \\lambda^\\star = 0$，因此 $u^\\star = u_0 - G^\\top \\lambda^\\star$。\n2. 原始可行性（Primal feasibility）：$G u^\\star \\le h(x)$。\n3. 对偶可行性（Dual feasibility）：$\\lambda^\\star \\ge 0$。\n4. 互补松弛性（Complementary slackness）：对于所有 $i \\in \\{1,\\dots,m\\}$，有 $\\lambda_i^\\star \\cdot \\left(G_i u^\\star - h_i(x)\\right) = 0$。\n\n这些条件确立了最优投影点位于从 $u_0$ 出发的仿射位移上，该位移方向由约束法向量张成，其中只有活动约束贡献非零乘子。虽然在活动集已知时可以通过 KKT 直接求解活动集和乘子，但一个不需要活动集先验知识的鲁棒算法更为可取。\n\n我们使用 Dykstra 算法，通过投影到半空间上来设计该算法。Dykstra 算法是一种将点欧几里得投影到闭凸集交集上的原则性方法。每个约束定义了一个闭凸半空间\n$$\n\\mathcal{H}_i(x) = \\{u \\in \\mathbb{R}^p \\mid a_i^\\top u \\le b_i(x)\\},\n$$\n其中 $a_i^\\top$ 是 $G$ 的第 $i$ 行，$b_i(x) = h_i(x)$。任何点 $y \\in \\mathbb{R}^p$ 到单个半空间 $\\mathcal{H}_i(x)$ 上的欧几里得投影由下式给出\n$$\n\\operatorname{proj}_{\\mathcal{H}_i(x)}(y) =\n\\begin{cases}\ny,  \\text{if } a_i^\\top y \\le b_i(x), \\\\\ny - \\dfrac{a_i^\\top y - b_i(x)}{\\|a_i\\|_2^2} \\, a_i,  \\text{if } a_i^\\top y  b_i(x).\n\\end{cases}\n$$\nDykstra 算法通过迭代地循环投影到每个半空间并带有校正项来构造到 $\\mathcal{C}(x) = \\bigcap_{i=1}^m \\mathcal{H}_i(x)$ 上的投影，这些校正项确保收敛到真正的欧几里得投影（而不仅仅是交集中的一个可行点）。具体来说，初始化 $z^{(0)} = u_0$ 和对所有 $i$ 的校正向量 $p_i^{(0)} = 0$。对于 $k = 0,1,2,\\dots$，执行：\n- 对 $i = 1,2,\\dots,m$ 顺序执行：\n  - 设置 $y = z^{(k)} + p_i^{(k)}$。\n  - 计算 $z_i = \\operatorname{proj}_{\\mathcal{H}_i(x)}(y)$。\n  - 更新 $p_i^{(k+1)} = y - z_i$ 并设置 $z^{(k+1)} = z_i$。\n在标准条件下（闭凸集和非空交集），$z^{(k)}$ 收敛到 $u_0$ 在 $\\mathcal{C}(x)$ 上的欧几里得投影 $u^\\star$。该算法基于凸分析和单调算子理论，并避免了脆弱的活动集枚举。\n\n我们现在将此应用于给定的矩阵。约束条件是：\n- 第 1 行：$[1,0] \\cdot u \\le 1.0 - 0.5 x_1$。\n- 第 2 行：$[0,1] \\cdot u \\le 1.0$。\n- 第 3 行：$[-1,0] \\cdot u \\le 1.0$ (等价于 $u_1 \\ge -1.0$)。\n- 第 4 行：$[0,-1] \\cdot u \\le 1.0$ (等价于 $u_2 \\ge -1.0$)。\n- 第 5 行：$[1,1] \\cdot u \\le 1.2 - 0.2 x_1 + 0.1 x_2$。\n\n对于每种情况，计算 $h(x) = H x + d$，然后通过 Dykstra 算法将 $u_0$ 投影到相应半空间的交集上，以获得 $u^\\star(x,u_0)$。\n\n对选定案例的解析验证：\n- 用例 1，其中 $x = [0.0,0.0]$ 且 $u_0 = [0.5,0.25]$：所有约束都被严格满足（$[1,1] \\cdot u_0 = 0.75 \\le 1.2$），因此根据到凸集投影的特性（如果 $u_0 \\in \\mathcal{C}(x)$，其投影就是其自身），有 $u^\\star = u_0$。\n- 用例 2，其中 $x = [0.0,0.0]$ 且 $u_0 = [2.0,0.0]$：违反了 $u_1 \\le 1.0$ 和 $u_1 + u_2 \\le 1.2$；最近的可行点是 $[1.0,0.0]$，它满足所有约束并最小化平方距离 $(2.0-1.0)^2 + (0.0-0.0)^2 = 1.0$（任何对 $u_2$ 的改变都会增加距离）。\n- 用例 3，其中 $x = [0.0,0.0]$ 且 $u_0 = [2.0,-2.0]$：违反了 $u_1 \\le 1.0$ 和 $u_2 \\ge -1.0$；与其他约束一致的最近角落点是 $[1.0,-1.0]$，其平方距离为 $(2.0-1.0)^2 + (-2.0+1.0)^2 = 2.0$。\n- 用例 4，其中 $x = [0.0,-7.0]$ 给出 $h_5(x) = 1.2 + 0.1(-7.0) = 0.5$，而其他 $h_i(x)$ 不变；$u_0 = [0.8,0.4]$ 仅违反了和约束 $u_1 + u_2 \\le 0.5$。到这个半空间的投影会沿着法线 $[1,1]^\\top$ 调整：$u^\\star = u_0 - \\frac{(1,1)\\cdot u_0 - 0.5}{\\|[1,1]\\|_2^2} [1,1] = [0.8,0.4] - \\frac{1.2 - 0.5}{2} [1,1] = [0.45,0.05]$。\n- 用例 5，其中 $x = [0.0,0.0]$ 且 $u_0 = [1.0,0.2]$：恰好位于约束 $u_1 \\le 1.0$ 和 $u_1 + u_2 \\le 1.2$ 上，因此 $u^\\star = u_0$。\n- 用例 6，其中 $x = [2.0,0.0]$ 给出 $h_1(x) = 1.0 - 0.5(2.0) = 0.0$ 和 $h_5(x) = 1.2 - 0.2(2.0) = 0.8$；对于 $u_0 = [0.8,0.9]$，$u_1 \\le 0.0$ 和 $u_1 + u_2 \\le 0.8$ 都被违反。当两个约束都激活时，KKT 活动集解得出 $u^\\star = u_0 - [1,0]^\\top \\lambda_1 - [1,1]^\\top \\lambda_5$ 以及等式 $u_1^\\star = 0.0$ 和 $u_1^\\star + u_2^\\star = 0.8$。求解得到 $\\lambda_5 = 0.1$，$\\lambda_1 = 0.7$ 和 $u^\\star = [0.0,0.8]$。\n\n因此，基于 Dykstra 方法的算法得出了与 KKT 分析一致的正确欧几里得投影。最终程序为所有测试用例计算 $u^\\star(x,u_0)$，并按指定的确切顺序，将它们作为单行的列表的列表打印出来。不涉及物理单位或角度单位；所有量都是无量纲的实数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef project_halfspace(y: np.ndarray, a: np.ndarray, b: float, tol: float = 1e-12) -> np.ndarray:\n    \"\"\"\n    Euclidean projection of y onto the halfspace {u | a^T u = b}.\n    If a^T y = b (within tolerance), return y unchanged.\n    Otherwise, project along the normal vector a.\n    \"\"\"\n    ay = float(np.dot(a, y))\n    if ay = b + tol:\n        return y.copy()\n    norm_a2 = float(np.dot(a, a))\n    if norm_a2 == 0.0:\n        # Degenerate constraint; ignore.\n        return y.copy()\n    t = (ay - b) / norm_a2\n    return y - t * a\n\n\ndef dykstra_projection(u0: np.ndarray, A: np.ndarray, b: np.ndarray,\n                       tol: float = 1e-10, max_iter: int = 10000) -> np.ndarray:\n    \"\"\"\n    Dykstra's algorithm to project u0 onto intersection of halfspaces {u | A u = b}.\n    A: (m, p) matrix, rows are normals a_i^T.\n    b: (m,) vector of halfspace offsets.\n    \"\"\"\n    m, p = A.shape\n    z = u0.copy()\n    corrections = np.zeros((m, p), dtype=float)\n\n    for _ in range(max_iter):\n        z_prev = z.copy()\n        # Cycle through constraints\n        for i in range(m):\n            y = z + corrections[i]\n            z_new = project_halfspace(y, A[i], b[i])\n            corrections[i] = y - z_new\n            z = z_new\n        # Convergence check\n        if np.linalg.norm(z - z_prev) = tol:\n            break\n    return z\n\n\ndef solve():\n    # Fixed matrices G, H, d as specified.\n    G = np.array([\n        [1.0, 0.0],\n        [0.0, 1.0],\n        [-1.0, 0.0],\n        [0.0, -1.0],\n        [1.0, 1.0]\n    ], dtype=float)\n    H = np.array([\n        [-0.5, 0.0],\n        [ 0.0, 0.0],\n        [ 0.0, 0.0],\n        [ 0.0, 0.0],\n        [-0.2, 0.1]\n    ], dtype=float)\n    d = np.array([1.0, 1.0, 1.0, 1.0, 1.2], dtype=float)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (x, u0)\n        (np.array([0.0, 0.0], dtype=float), np.array([0.5, 0.25], dtype=float)),\n        (np.array([0.0, 0.0], dtype=float), np.array([2.0, 0.0], dtype=float)),\n        (np.array([0.0, 0.0], dtype=float), np.array([2.0, -2.0], dtype=float)),\n        (np.array([0.0, -7.0], dtype=float), np.array([0.8, 0.4], dtype=float)),\n        (np.array([0.0, 0.0], dtype=float), np.array([1.0, 0.2], dtype=float)),\n        (np.array([2.0, 0.0], dtype=float), np.array([0.8, 0.9], dtype=float)),\n    ]\n\n    results = []\n    for x, u0 in test_cases:\n        h = H @ x + d\n        u_star = dykstra_projection(u0, G, h, tol=1e-12, max_iter=20000)\n        results.append([float(u_star[0]), float(u_star[1])])\n\n    # Final print statement in the exact required format.\n    # Single line: list of lists of floats.\n    print(f\"[[{results[0][0]},{results[0][1]}],[{results[1][0]},{results[1][1]}],[{results[2][0]},{results[2][1]}],[{results[3][0]},{results[3][1]}],[{results[4][0]},{results[4][1]}],[{results[5][0]},{results[5][1]}]]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}