{
    "hands_on_practices": [
        {
            "introduction": "在任何分布式系统中，网络拓扑都是其核心骨架，其结构特性深刻影响着系统的动态行为。本练习将探讨一个前沿概念：通过引入一个与物理系统耦合的数字孪生（Digital Twin）层来增强网络。通过分析这种增广图的拉普拉斯谱，您将亲手推导孪生层与物理层之间的耦合强度如何改变整个系统的代数连通性等关键指标，从而为设计稳定高效的赛博物理系统奠定理论基础。",
            "id": "4218234",
            "problem": "考虑一个由 $n$ 个物理节点组成的无向、连通的物理网络，该网络被建模为一个信息物理系统（CPS），其图拉普拉斯矩阵 $L \\in \\mathbb{R}^{n \\times n}$ 根据标准的度-邻接定义 $L = D - A$ 构建，其中 $D$ 是度矩阵，$A$ 是邻接矩阵。假设 $L$ 的特征值排序为 $0 = \\lambda_1 \\lt \\lambda_2 \\leq \\cdots \\leq \\lambda_n$。通过为每个物理节点增加一个对应的虚拟孪生节点来扩展物理网络图，从而引入一个数字孪生（DT）层。DT 层完全复制物理网络的层内拓扑结构（即具有相同的邻接关系和权重），并且每个物理节点仅与其对应的孪生节点耦合，耦合强度为一个正常数 $c \\gt 0$。由此得到的 $2n$ 节点增广超拉普拉斯矩阵是一个分块矩阵：\n$$\nL_{\\mathrm{aug}}(c) \\;=\\;\n\\begin{pmatrix}\nL + c I  -\\,c I \\\\\n-\\,c I  L + c I\n\\end{pmatrix}\n\\in \\mathbb{R}^{2n \\times 2n},\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵。从拉普拉斯矩阵的核心定义以及关于对称矩阵特征值和特征向量的基本线性代数知识出发，通过利用 $L$ 的特征向量构造 $L_{\\mathrm{aug}}(c)$ 的特征向量，并刻画它们相关的特征值，推导由此次增广引起的拉普拉斯谱的完全变化。利用你的推导结果，确定最小耦合强度 $c^{\\star}$，使得 $L_{\\mathrm{aug}}(c)$ 的代数连通度（第二小特征值）等于物理网络的代数连通度 $\\lambda_2$。将 $c^{\\star}$ 的最终答案表示为关于 $\\lambda_2$ 的闭式解析表达式。无需四舍五入，不涉及单位。",
            "solution": "该问题是有效的，因为它是适定的，在网络理论和线性代数方面有科学依据，并且包含了获得唯一解所需的所有信息。\n\n令 $L \\in \\mathbb{R}^{n \\times n}$ 为物理网络的拉普拉斯矩阵。根据定义，$L$ 是一个对称半正定矩阵。由于网络是连通的，其最小特征值为 $\\lambda_1 = 0$，重数为一，对应的特征向量是全一向量（在一个缩放因子内）。令 $\\{v_i\\}_{i=1}^n$ 为 $L$ 的一组标准正交特征向量，其对应的特征值为 $0 = \\lambda_1  \\lt \\lambda_2 \\leq \\cdots \\leq \\lambda_n$。物理网络拉普拉斯矩阵的特征值方程为：\n$$\nL v_i = \\lambda_i v_i \\quad \\text{for } i = 1, 2, \\ldots, n\n$$\n物理网络与数字孪生组合系统的增广超拉普拉斯矩阵由以下 $2n \\times 2n$ 的分块矩阵给出：\n$$\nL_{\\mathrm{aug}}(c) =\n\\begin{pmatrix}\nL + c I  -c I \\\\\n-c I  L + c I\n\\end{pmatrix}\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵，$c  0$ 是耦合强度。\n\n我们的第一个目标是确定 $L_{\\mathrm{aug}}(c)$ 的特征值。我们试图从已知的 $L$ 的特征向量构造 $L_{\\mathrm{aug}}(c)$ 的特征向量。让我们假设一个 $L_{\\mathrm{aug}}(c)$ 的候选特征向量，其形式为 $V = \\begin{pmatrix} \\alpha v_i \\\\ \\beta v_i \\end{pmatrix}$，其中 $v_i$ 是 $L$ 对于某个 $i \\in \\{1, \\ldots, n\\}$ 的特征向量，$\\alpha, \\beta$ 是待定的标量系数。\n\n增广系统的特征值方程为 $L_{\\mathrm{aug}}(c) V = \\mu V$，其中 $\\mu$ 是对应于特征向量 $V$ 的特征值。将 $L_{\\mathrm{aug}}(c)$ 的分块矩阵形式和假设的 $V$ 的形式代入，我们得到：\n$$\n\\begin{pmatrix}\nL + c I  -c I \\\\\n-c I  L + c I\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha v_i \\\\\n\\beta v_i\n\\end{pmatrix}\n= \\mu\n\\begin{pmatrix}\n\\alpha v_i \\\\\n\\beta v_i\n\\end{pmatrix}\n$$\n这个矩阵方程可以展开为一个由两个向量方程组成的系统：\n$$\n\\begin{cases}\n(L + cI)(\\alpha v_i) - cI(\\beta v_i) = \\mu (\\alpha v_i) \\\\\n-cI(\\alpha v_i) + (L + cI)(\\beta v_i) = \\mu (\\beta v_i)\n\\end{cases}\n$$\n利用矩阵乘法的线性性质和属性 $L v_i = \\lambda_i v_i$，该系统简化为：\n$$\n\\begin{cases}\n\\alpha L v_i + c \\alpha v_i - c \\beta v_i = \\mu \\alpha v_i \\\\\n-c \\alpha v_i + \\beta L v_i + c \\beta v_i = \\mu \\beta v_i\n\\end{cases}\n\\implies\n\\begin{cases}\n\\alpha \\lambda_i v_i + c \\alpha v_i - c \\beta v_i = \\mu \\alpha v_i \\\\\n-c \\alpha v_i + \\beta \\lambda_i v_i + c \\beta v_i = \\mu \\beta v_i\n\\end{cases}\n$$\n由于 $v_i$ 是一个非零向量（因为它是一个特征向量），我们可以从每个方程中将其作为公因子提取出来：\n$$\n\\begin{cases}\n(\\alpha \\lambda_i + c \\alpha - c \\beta) v_i = (\\mu \\alpha) v_i \\\\\n(-c \\alpha + \\beta \\lambda_i + c \\beta) v_i = (\\mu \\beta) v_i\n\\end{cases}\n$$\n这导出了一个关于系数 $\\alpha$ 和 $\\beta$ 的齐次线性方程组：\n$$\n\\begin{cases}\n(\\lambda_i + c - \\mu) \\alpha - c \\beta = 0 \\\\\n-c \\alpha + (\\lambda_i + c - \\mu) \\beta = 0\n\\end{cases}\n$$\n该系统可以写成矩阵形式：\n$$\n\\begin{pmatrix}\n\\lambda_i + c - \\mu  -c \\\\\n-c  \\lambda_i + c - \\mu\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha \\\\\n\\beta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix}\n$$\n为了使 $(\\alpha, \\beta)$ 存在非平凡解（这是构成非零特征向量 $V$ 所必需的），系数矩阵的行列式必须为零：\n$$\n\\det\n\\begin{pmatrix}\n\\lambda_i + c - \\mu  -c \\\\\n-c  \\lambda_i + c - \\mu\n\\end{pmatrix}\n= 0\n$$\n$$\n(\\lambda_i + c - \\mu)^2 - (-c)^2 = 0\n$$\n$$\n(\\lambda_i + c - \\mu)^2 = c^2\n$$\n对两边开平方根，得到特征值 $\\mu$ 的两种可能性：\n$$\n\\lambda_i + c - \\mu = \\pm c\n$$\n情况1：$\\lambda_i + c - \\mu = c$\n这简化为 $\\mu = \\lambda_i$。这意味着对于 $L$ 的每个特征值 $\\lambda_i$，$L_{\\mathrm{aug}}(c)$ 都有一个与之值相同的特征值。\n\n情况2：$\\lambda_i + c - \\mu = -c$\n这简化为 $\\mu = \\lambda_i + 2c$。这意味着对于 $L$ 的每个特征值 $\\lambda_i$，$L_{\\mathrm{aug}}(c)$ 还有一个等于 $\\lambda_i + 2c$ 的特征值。\n\n因此，$L_{\\mathrm{aug}}(c)$ 的谱是 $L$ 的两个平移版本的谱的并集：\n$$\n\\text{Spec}(L_{\\mathrm{aug}}(c)) = \\{ \\lambda_1, \\lambda_2, \\ldots, \\lambda_n \\} \\cup \\{ \\lambda_1 + 2c, \\lambda_2 + 2c, \\ldots, \\lambda_n + 2c \\}\n$$\n这就完成了问题的第一部分。\n\n第二部分是找到最小耦合强度 $c^{\\star}$，使得 $L_{\\mathrm{aug}}(c)$ 的代数连通度等于物理网络的代数连通度 $\\lambda_2$。代数连通度定义为拉普拉斯矩阵的第二小特征值。\n\n令 $\\mu_k$ 表示 $L_{\\mathrm{aug}}(c)$ 的第 $k$ 小特征值。我们需要找到 $\\mu_2$。物理网络的特征值排序为 $0 = \\lambda_1  \\lt \\lambda_2 \\leq \\cdots \\leq \\lambda_n$。增广系统的特征值按非递减顺序排序，必须从我们推导出的集合中构造。\n最小特征值为 $\\mu_1 = \\lambda_1 = 0$。这证实了 $L_{\\mathrm{aug}}(c)$ 是一个（可能不连通的）图的有效拉普拉斯矩阵。\n第二小特征值 $\\mu_2$ 的候选值是来自完整的 $2n$ 个特征值集合中的最小非零值。这些候选值是：\n\\begin{enumerate}\n    \\item 来自第一个集合的第二小特征值，即 $\\lambda_2$。\n    \\item 来自第二个集合的最小特征值，即 $\\lambda_1 + 2c = 0 + 2c = 2c$。\n\\end{enumerate}\n所有其他特征值，如 $\\lambda_3$、$\\lambda_2 + 2c$ 等，都大于或等于 $\\lambda_2$。并且由于 $c  0$，第二个集合中的所有其他特征值都大于 $2c$。\n因此，增广系统的代数连通度是这两个候选值的最小值：\n$$\n\\mu_2(c) = \\min(\\lambda_2, 2c)\n$$\n题目要求我们找到最小的 $c^{\\star}  0$，使得 $\\mu_2(c^{\\star}) = \\lambda_2$。代入 $\\mu_2(c)$ 的表达式：\n$$\n\\min(\\lambda_2, 2c^{\\star}) = \\lambda_2\n$$\n要使两个正数的最小值等于第一个数，第一个数必须小于或等于第二个数。这意味着条件：\n$$\n\\lambda_2 \\leq 2c^{\\star}\n$$\n对 $c^{\\star}$ 重新整理，我们得到：\n$$\nc^{\\star} \\geq \\frac{\\lambda_2}{2}\n$$\n问题要求的是满足此条件的*最小*耦合强度 $c^{\\star}$。所有有效的 $c$ 值的集合是区间 $[\\frac{\\lambda_2}{2}, \\infty)$。该集合中的最小值在下界处取得。\n因此，最小耦合强度是：\n$$\nc^{\\star} = \\frac{\\lambda_2}{2}\n$$\n由于物理网络是连通的，$\\lambda_2  0$，这确保了 $c^{\\star}  0$，符合问题的约束条件。",
            "answer": "$$\n\\boxed{\\frac{\\lambda_2}{2}}\n$$"
        },
        {
            "introduction": "在掌握了网络结构分析的基础后，下一步自然是设计能够在这一网络上有效运行的控制器。本练习将带您进入多智能体系统中的一个经典场景——编队控制。您将运用图拉普拉斯理论和模态分析方法，为一个具有双积分器动力学的智能体集群设计一个分布式比例-微分（PD）控制器，并通过调节控制器增益来优化编队的收敛性能，直观地体验理论分析与控制实践的紧密联系。",
            "id": "4218264",
            "problem": "一个由$N=4$个相同移动智能体组成的网络化编队，在一个信息物理系统（CPS）的数字孪生（DT）中表示。每个智能体具有单位质量的一维双积分器动力学，由$\\ddot{x}_{i}(t) = u_{i}(t)$给出，其中$x_{i}(t) \\in \\mathbb{R}$是智能体$i$的位置，$u_{i}(t) \\in \\mathbb{R}$是其控制输入。智能体之间通过一个固定的无向环形图（圈）进行交互，相邻智能体之间的权重为单位值：$1-2-3-4-1$。目标编队由每条边$(i,j)$上的恒定期望相对偏移量$d_{ij}$指定，这些偏移量是一致的，并能在全局平移和匀速运动的意义下形成一个唯一的形状。\n\n考虑分布式比例-微分（PD）编队控制律\n$$\nu_{i}(t) \\;=\\; -\\,k_{p}\\sum_{j \\in \\mathcal{N}_{i}} \\left( \\big(x_{i}(t)-x_{j}(t)\\big) - d_{ij} \\right)\\;-\\;k_{v}\\sum_{j \\in \\mathcal{N}_{i}} \\left( \\dot{x}_{i}(t)-\\dot{x}_{j}(t) \\right),\n$$\n其中$\\mathcal{N}_{i}$表示智能体$i$的邻居集合，$k_{p}  0$和$k_{v}  0$是待设计的标量增益。假设数字孪生验证了$k_{p}$已被固定为$k_{p} = 9$（归一化单位）。\n\n从图拉普拉斯矩阵和针对分布式PD耦合的双积分器模态分解的基本定义出发，推导闭环模态动力学以及所有非零拉普拉斯特征值对应的模态衰减率。然后，通过平衡最慢的欠阻尼和最慢的过阻尼模态衰减率，确定$k_{v}$的唯一值，该值可以最大化所有非平凡图模态下编队误差的保证最坏情况指数收敛速率。针对给定的环形图和$k_p$计算此$k_{v}$。\n\n将您的$k_{v}$最终数值四舍五入至四位有效数字。用$\\mathrm{s}^{-1}$单位表示您的答案。",
            "solution": "系统的动力学可以用向量形式表示。令$x(t) = [x_1(t), x_2(t), x_3(t), x_4(t)]^T$为智能体位置向量。系统动力学为$\\ddot{x}(t) = u(t)$，其中$u(t) = [u_1(t), u_2(t), u_3(t), u_4(t)]^T$。\n\n智能体$i$的控制律可以使用图拉普拉斯矩阵$L$来编写。对于一个无向图，量$\\sum_{j \\in \\mathcal{N}_{i}} (y_i - y_j)$是向量$Ly$的第$i$个分量，其中$y$是状态向量。$N=4$的无向环形图的拉普拉斯矩阵是：\n$$\nL = D - A = \\begin{pmatrix} 2  -1  0  -1 \\\\ -1  2  -1  0 \\\\ 0  -1  2  -1 \\\\ -1  0  -1  2 \\end{pmatrix}\n$$\n控制律包含一个与期望偏移量$d_{ij}$相关的常数项。令$b$为一个常数向量，其第$i$个分量为$b_i = \\sum_{j \\in \\mathcal{N}_i} d_{ij}$。向量形式的控制律为：\n$$\nu(t) = -k_p (Lx(t) - b) - k_v L\\dot{x}(t)\n$$\n闭环动力学为$\\ddot{x}(t) = -k_p (Lx(t) - b) - k_v L\\dot{x}(t)$，整理后得到：\n$$\n\\ddot{x}(t) + k_v L\\dot{x}(t) + k_p Lx(t) = k_p b\n$$\n为了分析向编队的收敛性，我们定义一个误差向量。一个静态编队$x^*$是一个平衡状态，其中$\\dot{x}^* = 0$且$\\ddot{x}^*=0$。从动力学可知，这意味着$k_p Lx^* = k_p b$，或$Lx^*=b$。问题陈述指出偏移量$d_{ij}$是一致的，这保证了这样的解$x^*$存在。令误差向量为$e(t) = x(t) - x^*$。那么$\\dot{e}(t) = \\dot{x}(t)$且$\\ddot{e}(t) = \\ddot{x}(t)$。将这些代入动力学方程得到：\n$$\n\\ddot{e}(t) + k_v L\\dot{e}(t) + k_p L(e(t) + x^*) = k_p b\n$$\n使用$Lx^* = b$，我们得到齐次误差动力学方程：\n$$\n\\ddot{e}(t) + k_v L\\dot{e}(t) + k_p Le(t) = 0\n$$\n为了求解这个系统，我们使用拉普拉斯矩阵$L$的谱特性进行模态分解。由于$L$是实对称矩阵，它可以被其特征向量构成的正交矩阵对角化。令$L=V\\Lambda V^T$，其中$\\Lambda = \\mathrm{diag}(\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4)$是特征值对角矩阵，$V$是对应的标准正交特征向量矩阵。\n对于一个$N$节点环形图的循环矩阵，其特征值$\\lambda_k$由$\\lambda_k = 2 - 2\\cos(2\\pi (k-1)/N)$给出，对于$k=1, \\dots, N$。对于$N=4$：\n$\\lambda_1 = 2 - 2\\cos(0) = 0$\n$\\lambda_2 = 2 - 2\\cos(\\pi/2) = 2$\n$\\lambda_3 = 2 - 2\\cos(\\pi) = 4$\n$\\lambda_4 = 2 - 2\\cos(3\\pi/2) = 2$\n排序后的特征值为$0$, $2$, $2$, $4$。不同的非零特征值为$\\lambda_a=2$和$\\lambda_b=4$。\n\n令$e(t) = V\\eta(t)$，其中$\\eta(t)$是模态坐标。代入误差动力学方程并左乘$V^T$：\n$V^T V \\ddot{\\eta}(t) + k_v V^T L V \\dot{\\eta}(t) + k_p V^T L V \\eta(t) = 0$\n$\\ddot{\\eta}(t) + k_v \\Lambda \\dot{\\eta}(t) + k_p \\Lambda \\eta(t) = 0$\n该系统解耦为$N=4$个关于每个模态坐标$\\eta_k$的独立的标量二阶常微分方程：\n$$\n\\ddot{\\eta}_k(t) + k_v \\lambda_k \\dot{\\eta}_k(t) + k_p \\lambda_k \\eta_k(t) = 0, \\quad k=1,2,3,4\n$$\n对应于$\\lambda_1 = 0$的模态给出$\\ddot{\\eta}_1(t) = 0$。这对应于编队质心的无阻尼运动，不影响编队的形状。编队误差的收敛性由与非零特征值相关的模态决定。\n\n对于一个非零特征值$\\lambda_k \\in \\{2, 4\\}$，模态动力学是一个标准的二阶线性时不变（LTI）系统。特征方程为$s^2 + (k_v \\lambda_k)s + (k_p \\lambda_k) = 0$。这对应于一个自然频率为$\\omega_{n,k} = \\sqrt{k_p \\lambda_k}$，阻尼比为$\\zeta_k = \\frac{k_v \\lambda_k}{2\\omega_{n,k}} = \\frac{k_v}{2}\\sqrt{\\frac{\\lambda_k}{k_p}}$的系统。\n\n每个模态的指数收敛速率由其特征方程极点实部的绝对值给出，$\\sigma_k = -\\mathrm{Re}(s_k)$。极点为$s_{1,2} = -\\zeta_k \\omega_{n,k} \\pm \\omega_{n,k}\\sqrt{\\zeta_k^2 - 1}$。\n衰减率$\\sigma_k$取决于阻尼比$\\zeta_k$：\n-   如果模态是欠阻尼的($\\zeta_k  1$)，极点是复数。衰减率为$\\sigma_k = \\zeta_k \\omega_{n,k} = \\frac{k_v \\lambda_k}{2}$。\n-   如果模态是过阻尼的($\\zeta_k > 1$)，极点是实数且不相等。衰减由较慢的极点（更靠近原点）决定，速率为$\\sigma_k = \\zeta_k \\omega_{n,k} - \\omega_{n,k}\\sqrt{\\zeta_k^2 - 1}$。\n\n我们的目标是最大化保证的最坏情况收敛速率，即在所有非平凡模态上的$\\sigma_{\\text{worst}} = \\min_{k} \\sigma_k$。这里，非平凡模态对应于$\\lambda_a=2$和$\\lambda_b=4$。\n给定$k_p=9$：\n对于一个特征值为$\\lambda$的模态，临界阻尼($\\zeta=1$)的条件是$k_v = 2\\sqrt{k_p/\\lambda}$。\n-   对于$\\lambda_a=2$：$\\zeta_a=1$在$k_v = 2\\sqrt{9/2} = 3\\sqrt{2}$。\n-   对于$\\lambda_b=4$：$\\zeta_b=1$在$k_v = 2\\sqrt{9/4} = 3$。\n\n我们来分析衰减率$\\sigma_a(k_v)$和$\\sigma_b(k_v)$：\n-   对于模态$a$，特征值$\\lambda_a=2$：\n    -   如果$k_v  3\\sqrt{2}$ (欠阻尼)，$\\sigma_a(k_v) = \\frac{k_v \\lambda_a}{2} = k_v$。\n    -   如果$k_v \\ge 3\\sqrt{2}$ (过阻尼)，$\\sigma_a(k_v) = \\frac{k_v \\cdot 2}{2} - \\sqrt{(\\frac{k_v \\cdot 2}{2})^2 - 9 \\cdot 2} = k_v - \\sqrt{k_v^2 - 18}$。\n-   对于模态$b$，特征值$\\lambda_b=4$：\n    -   如果$k_v  3$ (欠阻尼)，$\\sigma_b(k_v) = \\frac{k_v \\lambda_b}{2} = 2k_v$。\n    -   如果$k_v \\ge 3$ (过阻尼)，$\\sigma_b(k_v) = \\frac{k_v \\cdot 4}{2} - \\sqrt{(\\frac{k_v \\cdot 4}{2})^2 - 9 \\cdot 4} = 2k_v - \\sqrt{4k_v^2 - 36}$。\n\n我们希望最大化$\\sigma_{\\text{worst}}(k_v) = \\min(\\sigma_a(k_v), \\sigma_b(k_v))$。\n-   对于$0  k_v \\le 3$：两个模态都是欠阻尼的。$\\sigma_a(k_v)=k_v$且$\\sigma_b(k_v)=2k_v$。最小值为$\\sigma_{\\text{worst}}(k_v) = k_v$。该函数随$k_v$递增。\n-   对于$k_v > 3$：模态$b$变为过阻尼，其衰减率$\\sigma_b(k_v)$从其峰值$\\sigma_b(3)=6$开始下降。模态$a$仍然是欠阻尼的，其衰减率$\\sigma_a(k_v)=k_v$继续增加。\n最坏情况速率由较慢的模态决定。对于$k_v \\le 3$，这是模态$a$。当$k_v$增加超过$3$时，$\\sigma_a(k_v)$继续增加而$\\sigma_b(k_v)$减少。最大化这两个函数最小值的最优$k_v$值将出现在它们的衰减率相等的地方，即$\\sigma_a(k_v) = \\sigma_b(k_v)$。这平衡了两个速率。这个交点必须在$3  k_v  3\\sqrt{2}$的区间内，此时模态$a$是欠阻尼的，而模态$b$是过阻尼的。\n我们令衰减率相等：\n$$\n\\sigma_a(k_v) = \\sigma_b(k_v)\n$$\n$$\nk_v = 2k_v - \\sqrt{4k_v^2 - 36}\n$$\n重新整理方程：\n$$\n\\sqrt{4k_v^2 - 36} = k_v\n$$\n两边平方（因为$k_v0$所以有效）：\n$$\n4k_v^2 - 36 = k_v^2\n$$\n$$\n3k_v^2 = 36\n$$\n$$\nk_v^2 = 12\n$$\n$$\nk_v = \\sqrt{12} = 2\\sqrt{3}\n$$\n我们必须验证这个$k_v$值位于假设的区间$3  k_v  3\\sqrt{2}$内。\n$(3)^2 = 9$，$(2\\sqrt{3})^2 = 12$，以及$(3\\sqrt{2})^2 = 18$。因为$9  12  18$，所以我们的假设是正确的。\n因此，最优增益为$k_v = 2\\sqrt{3}$。\n\n问题要求将数值四舍五入到四位有效数字。\n$$\nk_v = 2\\sqrt{3} \\approx 3.4641016...\n$$\n四舍五入到四位有效数字，我们得到$k_v = 3.464$。",
            "answer": "$$\n\\boxed{3.464}\n$$"
        },
        {
            "introduction": "从解析设计走向计算实现，是分布式控制理论应用于实践的关键一步。本练习将引导您解决一个更高级的控制问题——模型预测控制（MPC），其中网络中的多个子系统受到共享资源约束的耦合。您将通过实现交替方向乘子法（ADMM）这一现代分布式优化领域的基石算法，来学习如何将一个复杂的全局优化问题分解为多个可以并行处理的局部子问题，这是开发可扩展、高效的分布式控制系统的一项核心技能。",
            "id": "4218235",
            "problem": "考虑一个由 $N$ 个离散时间线性子系统组成的网络，索引为 $i \\in \\{1,\\dots,N\\}$。每个子系统根据状态方程 $x_{i,t+1} = A_i x_{i,t} + B_i u_{i,t}$ 演化，其中 $t \\in \\{0,1,\\dots,T-1\\}$，$x_{i,t} \\in \\mathbb{R}$ 和 $u_{i,t} \\in \\mathbb{R}$ 是时间 $t$ 的标量状态和控制，$A_i \\in \\mathbb{R}$，$B_i \\in \\mathbb{R}$。设每个子系统 $i$ 的初始状态为 $x_{i,0} \\in \\mathbb{R}$。在长度为 $T$ 的时域上的模型预测控制 (MPC) 目标是二次阶段成本和终端成本之和，由以下经过充分检验的公式给出\n$$\nJ_i(x_{i,0}, u_i) = \\sum_{t=0}^{T-1} \\left( Q_i x_{i,t}^2 + R_i u_{i,t}^2 \\right) + P_i x_{i,T}^2,\n$$\n其中 $Q_i \\ge 0$，$R_i  0$ 和 $P_i \\ge 0$ 是标量成本权重。总目标是 $\\sum_{i=1}^N J_i(x_{i,0}, u_i)$。\n\n在每个时间步 $t$，跨子系统施加了一个耦合资源约束，要求控制之和等于一个给定的资源向量 $r \\in \\mathbb{R}^T$：\n$$\n\\sum_{i=1}^N u_{i,t} = r_t \\quad \\text{for all } t \\in \\{0,1,\\dots,T-1\\}.\n$$\n\n任务是实现一个基于交替方向乘子法 (ADMM) 的分布式优化算法，以求解在这些耦合约束下的凝聚MPC二次规划问题。该算法必须在凝聚控制公式上运行，其中状态变量通过线性动力学被消去，成本则表示为每个子系统控制序列的严格凸二次函数。\n\n您必须从凸优化的Karush-Kuhn-Tucker条件和增广拉格朗日量的定义出发，推导出停止准则，以保证在给定的容差范围内，同时满足原始可行性（局部变量与辅助变量之间的一致性以及耦合约束的满足）和对偶可行性（乘子的稳定性）。该推导必须基于凸性和线性代数的基本事实，并且不得假定使用简便公式。您的实现必须使用这些停止准则来终止迭代：返回一个布尔值，指示是否在最大迭代次数内满足了这些准则。\n\n您的程序应：\n- 为每个子系统 $i$ 构建凝聚二次目标函数，形式如下\n$$\n\\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + c_i,\n$$\n其中 $u_i \\in \\mathbb{R}^T$ 是堆叠的控制序列，在 $R_i  0$ 的条件下 $H_i \\in \\mathbb{R}^{T \\times T}$ 是正定的，$h_i \\in \\mathbb{R}^T$，而 $c_i \\in \\mathbb{R}$ 是一个优化中不需要的常数。\n- 对局部变量 $u_i$、辅助变量 $y_i$（用于强制耦合的副本）和对偶变量 $\\lambda_i$ 实现ADMM迭代，并使用增广拉格朗日惩罚参数 $\\rho  0$。\n- 在每次迭代中，执行：\n  1. 对每个 $i$ 进行局部二次最小化，\n  2. 投影到仿射耦合约束上，\n  3. 更新对偶变量。\n- 评估原始残差范数和对偶残差范数，并应用绝对-相对停止容差来判断收敛。\n- 对于下面套件中的每个测试用例，输出一个布尔值，指示算法是否在最大迭代次数内满足停止准则。\n\n使用以下测试套件，它探查了一个典型情况、收敛缓慢的紧容差、一个边界时域以及一个混合符号资源剖面。所有数字必须与指定完全一致：\n\n- 用例1（理想情况）：\n  - $N = 2$, $T = 8$.\n  - 子系统1：$A_1 = 1.0$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.1$, $P_1 = 2.0$, $x_{1,0} = 0.5$。\n  - 子系统2：$A_2 = 0.9$, $B_2 = 1.1$, $Q_2 = 1.2$, $R_2 = 0.15$, $P_2 = 2.5$, $x_{2,0} = -0.2$。\n  - 资源向量 $r = [0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]$。\n  - ADMM参数 $\\rho = 1.0$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-4}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-3}$。\n  - 最大迭代次数 $K_{\\max} = 1000$。\n- 用例2（紧容差与慢参数）：\n  - $N = 2$, $T = 12$.\n  - 子系统1：$A_1 = 1.0$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.05$, $P_1 = 1.5$, $x_{1,0} = 1.0$。\n  - 子系统2：$A_2 = 0.95$, $B_2 = 1.0$, $Q_2 = 1.0$, $R_2 = 0.05$, $P_2 = 1.5$, $x_{2,0} = -1.0$。\n  - 资源向量 $r = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$。\n  - ADMM参数 $\\rho = 0.01$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-9}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-9}$。\n  - 最大迭代次数 $K_{\\max} = 200$。\n- 用例3（边界时域）：\n  - $N = 2$, $T = 1$.\n  - 子系统1：$A_1 = 1.1$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.2$, $P_1 = 0.0$, $x_{1,0} = 0.1$。\n  - 子系统2：$A_2 = 0.8$, $B_2 = 1.0$, $Q_2 = 1.0$, $R_2 = 0.2$, $P_2 = 0.0$, $x_{2,0} = 0.2$。\n  - 资源向量 $r = [0.0]$。\n  - ADMM参数 $\\rho = 1.0$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-6}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-6}$。\n  - 最大迭代次数 $K_{\\max} = 50$。\n- 用例4（混合符号资源与非对称性）：\n  - $N = 2$, $T = 5$.\n  - 子系统1：$A_1 = 0.95$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.1$, $P_1 = 1.0$, $x_{1,0} = 0.3$。\n  - 子系统2：$A_2 = 1.05$, $B_2 = 0.9$, $Q_2 = 1.0$, $R_2 = 0.12$, $P_2 = 1.0$, $x_{2,0} = -0.3$。\n  - 资源向量 $r = [0.2, 0.0, -0.1, 0.1, 0.0]$。\n  - ADMM参数 $\\rho = 0.5$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-5}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-4}$。\n  - 最大迭代次数 $K_{\\max} = 1000$。\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的、逗号分隔的布尔值列表，按顺序表示用例1到4的收敛成功与否。确切格式为 `[result_1,result_2,result_3,result_4]`。不应打印任何额外文本。",
            "solution": "本任务是使用交替方向乘子法 (ADMM) 解决一个带耦合约束的分布式模型预测控制 (MPC) 问题。这包括三个主要阶段：将MPC问题凝聚为二次规划 (QP)，制定和实现ADMM算法，以及推导并应用适当的停止准则。\n\n### 1. 凝聚MPC问题\n\n第一步是从成本函数 $J_i$ 中消去状态变量 $x_{i,t}$，将其表示为控制序列 $u_i = [u_{i,0}, u_{i,1}, \\dots, u_{i,T-1}]^\\top \\in \\mathbb{R}^T$ 的二次函数。\n\n状态演化方程为 $x_{i,t+1} = A_i x_{i,t} + B_i u_{i,t}$。通过展开这个递归，我们可以将任何状态 $x_{i,k}$ 表示为初始状态 $x_{i,0}$ 和直到时间 $k-1$ 的控制序列的仿射函数：\n$$\nx_{i,k} = A_i^k x_{i,0} + \\sum_{j=0}^{k-1} A_i^{k-1-j} B_i u_{i,j} \\quad \\text{for } k \\in \\{1, \\dots, T\\}.\n$$\n我们可以将被惩罚的状态序列 $\\mathbf{x}_{i,\\text{seq}} = [x_{i,0}, x_{i,1}, \\dots, x_{i,T}]^\\top \\in \\mathbb{R}^{T+1}$ 表示为紧凑的矩阵形式：\n$$\n\\mathbf{x}_{i,\\text{seq}} = \\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x}\n$$\n其中 $\\mathbf{S}_{i,u} \\in \\mathbb{R}^{(T+1) \\times T}$ 和 $\\mathbf{s}_{i,x} \\in \\mathbb{R}^{T+1}$ 按元素定义如下：\n$$\n(\\mathbf{S}_{i,u})_{k,j} = \\begin{cases} A_i^{k-1-j} B_i  \\text{if } j  k \\\\ 0  \\text{otherwise} \\end{cases} \\quad \\text{for } k \\in \\{0, \\dots, T\\}, j \\in \\{0, \\dots, T-1\\}\n$$\n$$\n(\\mathbf{s}_{i,x})_k = A_i^k x_{i,0} \\quad \\text{for } k \\in \\{0, \\dots, T\\}\n$$\n成本函数为：\n$$\nJ_i(x_{i,0}, u_i) = \\sum_{t=0}^{T-1} (Q_i x_{i,t}^2 + R_i u_{i,t}^2) + P_i x_{i,T}^2\n$$\n这可以写成矩阵形式：\n$$\nJ_i(u_i) = \\mathbf{x}_{i,\\text{seq}}^\\top \\mathbf{Q}'_i \\mathbf{x}_{i,\\text{seq}} + u_i^\\top \\mathbf{R}'_i u_i\n$$\n其中 $\\mathbf{Q}'_i = \\text{diag}(Q_i, \\dots, Q_i, P_i) \\in \\mathbb{R}^{(T+1)\\times(T+1)}$ 且 $\\mathbf{R}'_i = \\text{diag}(R_i, \\dots, R_i) \\in \\mathbb{R}^{T\\times T}$。\n\n代入 $\\mathbf{x}_{i,\\text{seq}}$ 的表达式：\n$$\nJ_i(u_i) = (\\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x})^\\top \\mathbf{Q}'_i (\\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x}) + u_i^\\top \\mathbf{R}'_i u_i\n$$\n展开此表达式并按 $u_i$ 的幂次对各项进行分组，得到所需的二次形式 $\\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + c_i$：\n- **二次项**：$u_i^\\top (\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} + \\mathbf{R}'_i) u_i$\n- **线性项**：$2 \\mathbf{s}_{i,x}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} u_i$\n- **常数项**：$\\mathbf{s}_{i,x}^\\top \\mathbf{Q}'_i \\mathbf{s}_{i,x}$\n\n由此，我们确定了Hessian矩阵 $H_i \\in \\mathbb{R}^{T \\times T}$ 和线性系数向量 $h_i \\in \\mathbb{R}^T$：\n$$\nH_i = 2(\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} + \\mathbf{R}'_i)\n$$\n$$\nh_i = 2 \\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{s}_{i,x}\n$$\n由于 $R_i  0$，$\\mathbf{R}'_i$ 是正定的。由于 $Q_i, P_i \\ge 0$，$\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u}$ 是半正定的。因此，$H_i$ 是正定的，从而确保了局部目标函数的严格凸性。\n\n### 2. ADMM公式化\n完整的优化问题是：\n$$\n\\min_{u_1, \\dots, u_N} \\sum_{i=1}^N \\left( \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i \\right) \\quad \\text{s.t.} \\quad \\sum_{i=1}^N u_i = r\n$$\n其中 $r = [r_0, \\dots, r_{T-1}]^\\top$。为了应用ADMM，我们引入辅助变量 $y_i \\in \\mathbb{R}^T$ 并构建一个等价的一致性问题：\n$$\n\\min_{u_i, y_i} \\sum_{i=1}^N f_i(u_i) + g(y) \\quad \\text{s.t.} \\quad u_i = y_i \\; \\forall i\n$$\n这里，$f_i(u_i) = \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i$，而 $g(y)$ 是仿射约束集 $C = \\{(y_1, \\dots, y_N) \\mid \\sum_{i=1}^N y_i = r\\}$ 的指示函数。\n\n该问题的增广拉格朗日量 $\\mathcal{L}_\\rho$（带有对偶变量 $\\lambda_i$）是：\n$$\n\\mathcal{L}_\\rho(u, y, \\lambda) = \\sum_{i=1}^N \\left( f_i(u_i) + \\lambda_i^\\top(u_i - y_i) + \\frac{\\rho}{2} \\|u_i - y_i\\|_2^2 \\right) + g(y)\n$$\nADMM通过交替最小化关于 $u$ 和 $y$ 的 $\\mathcal{L}_\\rho$ ，然后进行对偶变量更新来推进。迭代（在第 $k+1$ 步）如下：\n\n1.  **$u$-最小化**：对于每个子系统 $i$，通过最小化 $\\mathcal{L}_\\rho$ 来求解 $u_i^{k+1}$，这是一个严格凸的二次规划问题：\n    $$\n    u_i^{k+1} = \\arg\\min_{u_i} \\left( \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + (\\lambda_i^k)^\\top u_i + \\frac{\\rho}{2} \\|u_i - y_i^k\\|_2^2 \\right)\n    $$\n    将梯度设为零可得一阶条件 $(H_i + \\rho I)u_i^{k+1} + h_i + \\lambda_i^k - \\rho y_i^k = 0$，从而得到更新公式：\n    $$\n    u_i^{k+1} = (H_i + \\rho I)^{-1} (\\rho y_i^k - h_i - \\lambda_i^k)\n    $$\n    矩阵 $(H_i + \\rho I)$ 只在算法开始时求逆一次。\n\n2.  **$y$-最小化**：对 $y^{k+1} = (y_1^{k+1}, \\dots, y_N^{k+1})$ 的更新涉及在集合 $C$ 上最小化 $\\mathcal{L}_\\rho$。这等价于找到到 $C$ 上的欧几里得投影：\n    $$\n    y^{k+1} = \\arg\\min_{\\sum y_i = r} \\sum_{i=1}^N \\frac{\\rho}{2} \\left\\| y_i - \\left(u_i^{k+1} + \\frac{1}{\\rho}\\lambda_i^k\\right) \\right\\|_2^2\n    $$\n    解是通过求平均得到的。令 $z_i^k = u_i^{k+1} + \\frac{1}{\\rho}\\lambda_i^k$。更新公式是：\n    $$\n    y_i^{k+1} = z_i^k - \\bar{z}^k + \\frac{1}{N}r, \\quad \\text{where} \\quad \\bar{z}^k = \\frac{1}{N}\\sum_{j=1}^N z_j^k\n    $$\n\n3.  **$\\lambda$-更新**：使用标准的梯度上升步骤更新对偶变量：\n    $$\n    \\lambda_i^{k+1} = \\lambda_i^k + \\rho(u_i^{k+1} - y_i^{k+1})\n    $$\n\n### 3. 停止准则的推导\n\n最优性的Karush-Kuhn-Tucker (KKT) 条件是原始可行性、对偶可行性和互补松弛性。对于我们的一致性问题，这些条件转化为：\n1.  **原始可行性**：对所有 $i$ 有 $u_i^* = y_i^*$，并且 $\\sum_i y_i^* = r$。\n2.  **对偶可行性**：拉格朗日量相对于原始变量的梯度必须为零。\n    - $\\nabla_{u_i} \\mathcal{L} = \\nabla f_i(u_i^*) + \\lambda_i^* = 0 \\implies H_i u_i^* + h_i + \\lambda_i^* = 0$。\n    - $\\nabla_{y_i} \\mathcal{L}$ 与 $g$ 的次微分有关，这意味着对所有 $i$，$\\lambda_i^*$ 必须相等。\n\nADMM算法的残差衡量当前迭代离满足这些条件的距离。\n\n- **原始残差**：衡量一致性约束 $u_i = y_i$ 的违反程度。第 $k+1$ 次迭代的原始残差是 $r_p^{k+1} = u^{k+1} - y^{k+1}$。其范数为 $\\|r_p^{k+1}\\|_2 = \\sqrt{\\sum_i \\|u_i^{k+1} - y_i^{k+1}\\|_2^2}$。\n\n- **对偶残差**：衡量平稳性条件的违反程度。从 $u$-更新我们有 $H_i u_i^{k+1} + h_i + \\lambda_i^k + \\rho(u_i^{k+1}-y_i^k)=0$。使用 $\\lambda$-更新来替换 $\\lambda_i^k$，我们得到 $H_i u_i^{k+1} + h_i + \\lambda_i^{k+1} + \\rho(y_i^{k+1}-y_i^k)=0$。对偶可行性条件要求 $H_i u_i^* + h_i + \\lambda_i^* = 0$。在第 $k+1$ 次迭代中阻止此条件满足的项是 $\\rho(y_i^{k+1}-y_i^k)$。这引出了对偶残差的定义 $r_d^{k+1} = \\rho(y^{k+1} - y^k)$。其范数为 $\\|r_d^{k+1}\\|_2 = \\rho \\sqrt{\\sum_i \\|y_i^{k+1} - y_i^k\\|_2^2}$。\n\n当两个残差范数都小于一个阈值时，即宣告收敛。这些阈值 $\\epsilon^{\\text{primal}}$ 和 $\\epsilon^{\\text{dual}}$ 结合了绝对和相对容差，以处理不同规模的问题：\n$$\n\\|r_p^{k+1}\\|_2 \\le \\epsilon^{\\text{primal}} = \\sqrt{NT} \\epsilon_{\\text{abs}} + \\epsilon_{\\text{rel}} \\max\\{\\|u^{k+1}\\|_2, \\|y^{k+1}\\|_2\\}\n$$\n$$\n\\|r_d^{k+1}\\|_2 \\le \\epsilon^{\\text{dual}} = \\sqrt{NT} \\epsilon_{\\text{abs}} + \\epsilon_{\\text{rel}} \\|\\lambda^{k+1}\\|_2\n$$\n其中 $u, y, \\lambda$ 代表所有子系统的堆叠向量，例如 $\\|u\\|_2 = \\sqrt{\\sum_i \\|u_i\\|_2^2}$。项 $\\sqrt{NT}$ 根据问题维度缩放绝对容差。",
            "answer": "```python\nimport numpy as np\n\ndef build_condensed_matrices(T, A, B, Q, R, P, x0):\n    \"\"\"\n    Constructs the matrices H and h for the condensed QP form for one subsystem.\n    \"\"\"\n    # State sequence matrices\n    S_u = np.zeros((T + 1, T))\n    s_x = np.zeros(T + 1)\n    \n    # Populate S_u and s_x based on unrolled dynamics\n    # k is the state index x_k, j is the control index u_j\n    for k in range(T + 1):\n        s_x[k] = (A**k) * x0\n        if k > 0:\n            for j in range(k):\n                # Coefficient of u_j in the expansion of x_k\n                S_u[k, j] = (A**(k - 1 - j)) * B\n\n    # Cost matrices\n    Q_prime = np.diag([Q] * T + [P])\n    R_prime = np.diag([R] * T)\n    \n    # Condensed QP matrices\n    H = 2.0 * (S_u.T @ Q_prime @ S_u + R_prime)\n    h = 2.0 * S_u.T @ Q_prime @ s_x\n    \n    return H, h\n\ndef run_admm_for_case(case_params):\n    \"\"\"\n    Runs the ADMM algorithm for a single test case.\n    \"\"\"\n    N = case_params['N']\n    T = case_params['T']\n    subsystems = case_params['subsystems']\n    r = np.array(case_params['r'], dtype=float)\n    rho = case_params['rho']\n    eps_abs = case_params['eps_abs']\n    eps_rel = case_params['eps_rel']\n    K_max = case_params['K_max']\n\n    # Step 1: Condensation and pre-computation for each subsystem\n    H_list, h_list, P_H_list = [], [], []\n    for params in subsystems:\n        A, B, Q, R, P, x0 = params\n        H, h = build_condensed_matrices(T, float(A), float(B), float(Q), float(R), float(P), float(x0))\n        H_list.append(H)\n        h_list.append(h)\n        # Pre-compute inverse for u-update\n        P_H_list.append(np.linalg.inv(H + rho * np.identity(T)))\n\n    # Step 2: ADMM Initialization\n    u_list = [np.zeros(T) for _ in range(N)]\n    y_list = [np.zeros(T) for _ in range(N)]\n    lambda_list = [np.zeros(T) for _ in range(N)]\n    \n    # Step 3: ADMM Iterations\n    for k in range(K_max):\n        y_list_old = [y.copy() for y in y_list]\n\n        # u-updates (local solves)\n        u_list_new = []\n        for i in range(N):\n            rhs = rho * y_list[i] - h_list[i] - lambda_list[i]\n            u_i_new = P_H_list[i] @ rhs\n            u_list_new.append(u_i_new)\n\n        # y-updates (projection onto consensus set)\n        z_list = [u_list_new[i] + lambda_list[i] / rho for i in range(N)]\n        avg_z = sum(z_list) / N\n        \n        y_list_new = []\n        for i in range(N):\n            y_i_new = z_list[i] - avg_z + r / N\n            y_list_new.append(y_i_new)\n\n        # lambda-updates (dual ascent)\n        lambda_list_new = []\n        for i in range(N):\n            lambda_i_new = lambda_list[i] + rho * (u_list_new[i] - y_list_new[i])\n            lambda_list_new.append(lambda_i_new)\n        \n        # Update state variables for the next iteration\n        u_list, y_list, lambda_list = u_list_new, y_list_new, lambda_list_new\n\n        # Step 4: Check stopping criteria\n        u_stack = np.concatenate(u_list)\n        y_stack = np.concatenate(y_list)\n        lambda_stack = np.concatenate(lambda_list)\n        y_old_stack = np.concatenate(y_list_old)\n\n        # Primal residual norm\n        res_p_norm = np.linalg.norm(u_stack - y_stack)\n        \n        # Dual residual norm\n        res_d_norm = rho * np.linalg.norm(y_stack - y_old_stack)\n\n        # Primal and dual stopping thresholds (tolerances)\n        eps_p = np.sqrt(N * T) * eps_abs + eps_rel * max(np.linalg.norm(u_stack), np.linalg.norm(y_stack))\n        eps_d = np.sqrt(N * T) * eps_abs + eps_rel * np.linalg.norm(lambda_stack)\n\n        if res_p_norm = eps_p and res_d_norm = eps_d:\n            return True\n\n    return False\n\ndef solve():\n    \"\"\"\n    Defines test cases and orchestrates the solution process.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            'N': 2, 'T': 8,\n            'subsystems': [\n                (1.0, 1.0, 1.0, 0.1, 2.0, 0.5),\n                (0.9, 1.1, 1.2, 0.15, 2.5, -0.2)\n            ],\n            'r': [0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05],\n            'rho': 1.0, 'eps_abs': 1e-4, 'eps_rel': 1e-3, 'K_max': 1000\n        },\n        # Case 2 (tight tolerance, slow parameter)\n        {\n            'N': 2, 'T': 12,\n            'subsystems': [\n                (1.0, 1.0, 1.0, 0.05, 1.5, 1.0),\n                (0.95, 1.0, 1.0, 0.05, 1.5, -1.0)\n            ],\n            'r': [0.0] * 12,\n            'rho': 0.01, 'eps_abs': 1e-9, 'eps_rel': 1e-9, 'K_max': 200\n        },\n        # Case 3 (boundary horizon)\n        {\n            'N': 2, 'T': 1,\n            'subsystems': [\n                (1.1, 1.0, 1.0, 0.2, 0.0, 0.1),\n                (0.8, 1.0, 1.0, 0.2, 0.0, 0.2)\n            ],\n            'r': [0.0],\n            'rho': 1.0, 'eps_abs': 1e-6, 'eps_rel': 1e-6, 'K_max': 50\n        },\n        # Case 4 (mixed-sign resource and asymmetry)\n        {\n            'N': 2, 'T': 5,\n            'subsystems': [\n                (0.95, 1.0, 1.0, 0.1, 1.0, 0.3),\n                (1.05, 0.9, 1.0, 0.12, 1.0, -0.3)\n            ],\n            'r': [0.2, 0.0, -0.1, 0.1, 0.0],\n            'rho': 0.5, 'eps_abs': 1e-5, 'eps_rel': 1e-4, 'K_max': 1000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        converged = run_admm_for_case(case)\n        results.append(converged)\n\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}