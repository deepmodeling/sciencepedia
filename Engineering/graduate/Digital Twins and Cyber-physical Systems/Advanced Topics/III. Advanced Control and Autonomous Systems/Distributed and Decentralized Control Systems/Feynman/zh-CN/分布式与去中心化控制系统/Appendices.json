{
    "hands_on_practices": [
        {
            "introduction": "分布式系统的性能在根本上取决于其底层网络拓扑。图拉普拉斯矩阵及其谱（即特征值集合）蕴含了关于系统动态行为（如收敛速度和稳定性）的关键信息。本练习  旨在通过分析为一个物理网络添加数字孪生层如何改变其拉普拉斯谱，提供网络结构分析的实践经验，这对于预测和设计复杂赛博物理系统的动态至关重要。",
            "id": "4218234",
            "problem": "考虑一个由 $n$ 个物理节点组成的无向、连通的设施网络，该网络被建模为一个信息物理系统 (CPS)，其图拉普拉斯矩阵 $L \\in \\mathbb{R}^{n \\times n}$ 由标准度-邻接定义 $L = D - A$ 构建，其中 $D$ 是度矩阵，$A$ 是邻接矩阵。假设 $L$ 的特征值按 $0 = \\lambda_1  \\lambda_2 \\leq \\cdots \\leq \\lambda_n$ 排序。通过为每个设施节点增加一个虚拟孪生节点来增广设施图，从而引入一个数字孪生 (DT) 层。DT 层完全复制了设施的层内拓扑结构（相同的邻接关系和权重），并且每个设施节点仅与其对应的孪生节点耦合，耦合强度为一个正常数 $c > 0$。得到的 $2n$ 节点增广超拉普拉斯矩阵是分块矩阵\n$$\nL_{\\mathrm{aug}}(c) \\;=\\;\n\\begin{pmatrix}\nL + c I   -\\,c I \\\\\n-\\,c I   L + c I\n\\end{pmatrix}\n\\in \\mathbb{R}^{2n \\times 2n},\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵。从拉普拉斯矩阵的核心定义以及关于对称矩阵特征值和特征向量的基本线性代数事实出发，通过利用 $L$ 的特征向量构造 $L_{\\mathrm{aug}}(c)$ 的特征向量，并刻画其相关的特征值，推导出由该增广引起的拉普拉斯谱的全部变化。利用你的推导，确定最小耦合强度 $c^{\\star}$，使得 $L_{\\mathrm{aug}}(c)$ 的代数连通度（第二小特征值）等于设施的代数连通度 $\\lambda_2$。将你对 $c^{\\star}$ 的最终答案表示为一个关于 $\\lambda_2$ 的闭式解析表达式。无需四舍五入，不涉及单位。",
            "solution": "该问题是有效的，因为它提法恰当，在网络理论和线性代数方面有科学依据，并且包含了获得唯一解所需的所有信息。\n\n设 $L \\in \\mathbb{R}^{n \\times n}$ 是设施网络的拉普拉斯矩阵。根据定义，$L$ 是一个对称半正定矩阵。由于网络是连通的，其最小特征值为 $\\lambda_1 = 0$，重数为一，对应的特征向量是全一向量（在相差一个缩放因子的情况下）。设 $\\{v_i\\}_{i=1}^n$ 是 $L$ 的一组标准正交特征向量，其对应的特征值为 $0 = \\lambda_1  \\lambda_2 \\leq \\cdots \\leq \\lambda_n$。设施拉普拉斯矩阵的特征值方程为：\n$$\nL v_i = \\lambda_i v_i \\quad \\text{for } i = 1, 2, \\ldots, n\n$$\n设施与数字孪生组合系统的增广超拉普拉斯矩阵由 $2n \\times 2n$ 的分块矩阵给出：\n$$\nL_{\\mathrm{aug}}(c) =\n\\begin{pmatrix}\nL + c I   -c I \\\\\n-c I   L + c I\n\\end{pmatrix}\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵，$c > 0$ 是耦合强度。\n\n我们的首要目标是确定 $L_{\\mathrm{aug}}(c)$ 的特征值。我们试图从 $L$ 的已知特征向量构造 $L_{\\mathrm{aug}}(c)$ 的特征向量。我们提出一个 $L_{\\mathrm{aug}}(c)$ 的候选特征向量，其形式为 $V = \\begin{pmatrix} \\alpha v_i \\\\ \\beta v_i \\end{pmatrix}$，其中 $v_i$ 是 $L$ 的某个特征向量（对于某个 $i \\in \\{1, \\ldots, n\\}$），而 $\\alpha, \\beta$ 是待确定的标量系数。\n\n增广系统的特征值方程为 $L_{\\mathrm{aug}}(c) V = \\mu V$，其中 $\\mu$ 是对应于特征向量 $V$ 的特征值。代入 $L_{\\mathrm{aug}}(c)$ 的分块矩阵形式和 $V$ 的建议形式，我们得到：\n$$\n\\begin{pmatrix}\nL + c I   -c I \\\\\n-c I   L + c I\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha v_i \\\\\n\\beta v_i\n\\end{pmatrix}\n= \\mu\n\\begin{pmatrix}\n\\alpha v_i \\\\\n\\beta v_i\n\\end{pmatrix}\n$$\n该矩阵方程可以展开为一个包含两个向量方程的系统：\n$$\n\\begin{cases}\n(L + cI)(\\alpha v_i) - cI(\\beta v_i) = \\mu (\\alpha v_i) \\\\\n-cI(\\alpha v_i) + (L + cI)(\\beta v_i) = \\mu (\\beta v_i)\n\\end{cases}\n$$\n利用矩阵乘法的线性性质和 $L v_i = \\lambda_i v_i$ 的属性，该系统简化为：\n$$\n\\begin{cases}\n\\alpha L v_i + c \\alpha v_i - c \\beta v_i = \\mu \\alpha v_i \\\\\n-c \\alpha v_i + \\beta L v_i + c \\beta v_i = \\mu \\beta v_i\n\\end{cases}\n\\implies\n\\begin{cases}\n\\alpha \\lambda_i v_i + c \\alpha v_i - c \\beta v_i = \\mu \\alpha v_i \\\\\n-c \\alpha v_i + \\beta \\lambda_i v_i + c \\beta v_i = \\mu \\beta v_i\n\\end{cases}\n$$\n由于 $v_i$ 是一个非零向量（因为它是一个特征向量），我们可以从每个方程中将其因子提出：\n$$\n\\begin{cases}\n(\\alpha \\lambda_i + c \\alpha - c \\beta) v_i = (\\mu \\alpha) v_i \\\\\n(-c \\alpha + \\beta \\lambda_i + c \\beta) v_i = (\\mu \\beta) v_i\n\\end{cases}\n$$\n这导出了一个关于系数 $\\alpha$ 和 $\\beta$ 的齐次线性方程组：\n$$\n\\begin{cases}\n(\\lambda_i + c - \\mu) \\alpha - c \\beta = 0 \\\\\n-c \\alpha + (\\lambda_i + c - \\mu) \\beta = 0\n\\end{cases}\n$$\n该系统可以写成矩阵形式：\n$$\n\\begin{pmatrix}\n\\lambda_i + c - \\mu   -c \\\\\n-c   \\lambda_i + c - \\mu\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha \\\\\n\\beta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix}\n$$\n为了使 $(\\alpha, \\beta)$ 存在非平凡解（这是构成非零特征向量 $V$ 所必需的），系数矩阵的行列式必须为零：\n$$\n\\det\n\\begin{pmatrix}\n\\lambda_i + c - \\mu   -c \\\\\n-c   \\lambda_i + c - \\mu\n\\end{pmatrix}\n= 0\n$$\n$$\n(\\lambda_i + c - \\mu)^2 - (-c)^2 = 0\n$$\n$$\n(\\lambda_i + c - \\mu)^2 = c^2\n$$\n对两边取平方根，得到特征值 $\\mu$ 的两种可能性：\n$$\n\\lambda_i + c - \\mu = \\pm c\n$$\n情况1：$\\lambda_i + c - \\mu = c$\n这简化为 $\\mu = \\lambda_i$。这意味着对于 $L$ 的每个特征值 $\\lambda_i$，$L_{\\mathrm{aug}}(c)$ 都有一个与之值相同的特征值。\n\n情况2：$\\lambda_i + c - \\mu = -c$\n这简化为 $\\mu = \\lambda_i + 2c$。这意味着对于 $L$ 的每个特征值 $\\lambda_i$，$L_{\\mathrm{aug}}(c)$ 还有一个等于 $\\lambda_i + 2c$ 的特征值。\n\n因此，$L_{\\mathrm{aug}}(c)$ 的谱是 $L$ 的两个移位版本的谱的并集：\n$$\n\\text{Spec}(L_{\\mathrm{aug}}(c)) = \\{ \\lambda_1, \\lambda_2, \\ldots, \\lambda_n \\} \\cup \\{ \\lambda_1 + 2c, \\lambda_2 + 2c, \\ldots, \\lambda_n + 2c \\}\n$$\n这完成了问题的第一部分。\n\n第二部分是找到最小耦合强度 $c^{\\star}$，使得 $L_{\\mathrm{aug}}(c)$ 的代数连通度等于设施的代数连通度 $\\lambda_2$。代数连通度被定义为拉普拉斯矩阵的第二小特征值。\n\n令 $\\mu_k$ 表示 $L_{\\mathrm{aug}}(c)$ 的第 $k$ 小特征值。我们需要找到 $\\mu_2$。设施网络的特征值按 $0 = \\lambda_1  \\lambda_2 \\leq \\cdots \\leq \\lambda_n$ 排序。增广系统的特征值，按非递减顺序排序，必须从我们推导出的集合中构建。\n最小的特征值是 $\\mu_1 = \\lambda_1 = 0$。这证实了 $L_{\\mathrm{aug}}(c)$ 是一个（可能不连通的）图的有效拉普拉斯矩阵。\n第二小特征值 $\\mu_2$ 的候选者是来自全部 $2n$ 个特征值集合中的最小非零值。它们是：\n\\begin{enumerate}\n    \\item 来自第一个集合的第二小特征值，即 $\\lambda_2$。\n    \\item 来自第二个集合的最小特征值，即 $\\lambda_1 + 2c = 0 + 2c = 2c$。\n\\end{enumerate}\n所有其他特征值，如 $\\lambda_3$、$\\lambda_2 + 2c$ 等，都大于或等于 $\\lambda_2$。并且由于 $c > 0$，第二个集合中的所有其他特征值都大于 $2c$。\n因此，增广系统的代数连通度是这两个候选者的最小值：\n$$\n\\mu_2(c) = \\min(\\lambda_2, 2c)\n$$\n题目要求我们找到最小的 $c^{\\star} > 0$，使得 $\\mu_2(c^{\\star}) = \\lambda_2$。代入 $\\mu_2(c)$ 的表达式中：\n$$\n\\min(\\lambda_2, 2c^{\\star}) = \\lambda_2\n$$\n要使两个正数中的最小值等于第一个数，第一个数必须小于或等于第二个数。这意味着以下条件：\n$$\n\\lambda_2 \\leq 2c^{\\star}\n$$\n整理以求解 $c^{\\star}$，我们得到：\n$$\nc^{\\star} \\geq \\frac{\\lambda_2}{2}\n$$\n问题要求满足此条件的*最小*耦合强度 $c^{\\star}$。所有有效 $c$ 值的集合是区间 $[\\frac{\\lambda_2}{2}, \\infty)$。该集合中的最小值在下界处达到。\n因此，最小耦合强度是：\n$$\nc^{\\star} = \\frac{\\lambda_2}{2}\n$$\n由于设施网络是连通的，$\\lambda_2 > 0$，这确保了 $c^{\\star} > 0$，符合题目的约束条件。",
            "answer": "$$\n\\boxed{\\frac{\\lambda_2}{2}}\n$$"
        },
        {
            "introduction": "在理解网络结构的基础上，分布式控制的核心任务是设计局部控制律以实现全局目标，例如一致性或队形控制。本问题  提出了一个经典的多智能体队形控制场景，要求您设计一个比例-微分（PD）控制器。通过这个练习，您将学会如何运用基于图拉普拉斯矩阵的模态分析来整定控制器增益，从而平衡网络不同模态下的性能，以优化系统的整体收敛速度。",
            "id": "4218264",
            "problem": "一个由$N=4$个相同移动智能体组成的网络化编队在一个信息物理系统 (CPS) 的数字孪生 (DT) 中表示。每个智能体具有单位质量的一维双积分器动力学，由$\\ddot{x}_{i}(t) = u_{i}(t)$给出，其中$x_{i}(t) \\in \\mathbb{R}$是智能体$i$的位置，$u_{i}(t) \\in \\mathbb{R}$是其控制输入。这些智能体在一个固定的无向环形图（圈）上相互作用，相邻智能体之间的权重为单位值：$1-2-3-4-1$。目标编队由每条边$(i,j)$上恒定的期望相对偏移量$d_{ij}$指定，这些偏移量是一致的，并能在全局平移和匀速运动的范围内产生唯一的形状。\n\n考虑分布式比例-微分 (PD) 编队控制律\n$$\nu_{i}(t) \\;=\\; -\\,k_{p}\\sum_{j \\in \\mathcal{N}_{i}} \\left( \\big(x_{i}(t)-x_{j}(t)\\big) - d_{ij} \\right)\\;-\\;k_{v}\\sum_{j \\in \\mathcal{N}_{i}} \\left( \\dot{x}_{i}(t)-\\dot{x}_{j}(t) \\right),\n$$\n其中$\\mathcal{N}_{i}$表示智能体$i$的邻居集，$k_{p} > 0$和$k_{v} > 0$是待设计的标量增益。假设数字孪生验证了$k_{p}$已被固定为$k_{p} = 9$（归一化单位）。\n\n从图拉普拉斯矩阵和分布式PD耦合的双积分器模态分解的基本定义出发，推导所有非零拉普拉斯特征值的闭环模态动力学和相应的模态衰减率。然后，通过平衡最慢的欠阻尼和最慢的过阻尼模态衰减率，确定单一的$k_{v}$值，以最大化所有非平凡图模态中编队误差的最差情况下的保证指数收敛速率。为给定的环形图和$k_{p}$计算这个$k_{v}$。\n\n将您最终的$k_{v}$数值四舍五入到四位有效数字。用$\\mathrm{s}^{-1}$表示您的答案。",
            "solution": "系统的动力学可以用向量形式表示。设$x(t) = [x_1(t), x_2(t), x_3(t), x_4(t)]^T$为智能体位置的向量。系统动力学为$\\ddot{x}(t) = u(t)$，其中$u(t) = [u_1(t), u_2(t), u_3(t), u_4(t)]^T$。\n\n智能体$i$的控制律可以用图拉普拉斯矩阵$L$来写。对于无向图，量$\\sum_{j \\in \\mathcal{N}_{i}} (y_i - y_j)$是向量$Ly$的第$i$个分量，其中$y$是状态向量。对于$N=4$的无向环形图，拉普拉斯矩阵为：\n$$\nL = D - A = \\begin{pmatrix} 2  0  0  0 \\\\ 0  2  0  0 \\\\ 0  0  2  0 \\\\ 0  0  0  2 \\end{pmatrix} - \\begin{pmatrix} 0  1  0  1 \\\\ 1  0  1  0 \\\\ 0  1  0  1 \\\\ 1  0  1  0 \\end{pmatrix} = \\begin{pmatrix} 2  -1  0  -1 \\\\ -1  2  -1  0 \\\\ 0  -1  2  -1 \\\\ -1  0  -1  2 \\end{pmatrix}\n$$\n控制律包含一个与期望偏移量$d_{ij}$相关的常数项。设$b$为一个常数向量，其第$i$个分量为$b_i = \\sum_{j \\in \\mathcal{N}_i} d_{ij}$。向量形式的控制律为：\n$$\nu(t) = -k_p (Lx(t) - b) - k_v L\\dot{x}(t)\n$$\n闭环动力学为$\\ddot{x}(t) = -k_p (Lx(t) - b) - k_v L\\dot{x}(t)$，整理后得到：\n$$\n\\ddot{x}(t) + k_v L\\dot{x}(t) + k_p Lx(t) = k_p b\n$$\n为了分析向编队的收敛性，我们定义一个误差向量。静态编队$x^*$是一个平衡状态，其中$\\dot{x}^* = 0$且$\\ddot{x}^*=0$。从动力学方程可知，这意为着$k_p Lx^* = k_p b$，或$Lx^*=b$。问题陈述$d_{ij}$是一致的，这保证了这样的解$x^*$存在。设误差向量为$e(t) = x(t) - x^*$。那么$\\dot{e}(t) = \\dot{x}(t)$和$\\ddot{e}(t) = \\ddot{x}(t)$。将这些代入动力学方程得到：\n$$\n\\ddot{e}(t) + k_v L\\dot{e}(t) + k_p L(e(t) + x^*) = k_p b\n$$\n使用$Lx^* = b$，我们得到齐次误差动力学方程：\n$$\n\\ddot{e}(t) + k_v L\\dot{e}(t) + k_p Le(t) = 0\n$$\n为了解这个系统，我们使用拉普拉斯矩阵$L$的谱特性进行模态分解。由于$L$是实对称的，它可以被其特征向量的正交矩阵对角化。设$L=V\\Lambda V^T$，其中$\\Lambda = \\mathrm{diag}(\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4)$是特征值的对角矩阵，$V$是相应标准正交特征向量的矩阵。\n对于一个$N$节点的环形图，其特征值$\\lambda_k$由$\\lambda_k = 2 - 2\\cos(2\\pi (k-1)/N)$给出，其中$k=1, \\dots, N$。对于$N=4$：\n$\\lambda_1 = 2 - 2\\cos(0) = 0$\n$\\lambda_2 = 2 - 2\\cos(\\pi/2) = 2$\n$\\lambda_3 = 2 - 2\\cos(\\pi) = 4$\n$\\lambda_4 = 2 - 2\\cos(3\\pi/2) = 2$\n排序后的特征值为$0, 2, 2, 4$。非零的不同特征值为$\\lambda_a=2$和$\\lambda_b=4$。\n\n设$e(t) = V\\eta(t)$，其中$\\eta(t)$是模态坐标。代入误差动力学方程并左乘$V^T$：\n$V^T V \\ddot{\\eta}(t) + k_v V^T L V \\dot{\\eta}(t) + k_p V^T L V \\eta(t) = 0$\n$\\ddot{\\eta}(t) + k_v \\Lambda \\dot{\\eta}(t) + k_p \\Lambda \\eta(t) = 0$\n该系统解耦为$N=4$个独立的标量二阶常微分方程，每个模态坐标$\\eta_k$一个：\n$$\n\\ddot{\\eta}_k(t) + k_v \\lambda_k \\dot{\\eta}_k(t) + k_p \\lambda_k \\eta_k(t) = 0, \\quad k=1,2,3,4\n$$\n对于$\\lambda_1 = 0$的模态，我们得到$\\ddot{\\eta}_1(t) = 0$。这对应于编队质心的无阻尼运动，它不影响编队的形状。编队误差的收敛性由与非零特征值相关的模态决定。\n\n对于一个非零特征值$\\lambda_k \\in \\{2, 4\\}$，模态动力学是一个标准的二阶LTI系统。特征方程为$s^2 + (k_v \\lambda_k)s + (k_p \\lambda_k) = 0$。这对应于一个自然频率为$\\omega_{n,k} = \\sqrt{k_p \\lambda_k}$，阻尼比为$\\zeta_k = \\frac{k_v \\lambda_k}{2\\omega_{n,k}} = \\frac{k_v}{2}\\sqrt{\\frac{\\lambda_k}{k_p}}$的系统。\n\n每个模态的指数收敛速率由其特征方程极点的实部大小给出，即$\\sigma_k = -\\mathrm{Re}(s_k)$。极点为$s_{1,2} = -\\zeta_k \\omega_{n,k} \\pm \\omega_{n,k}\\sqrt{\\zeta_k^2 - 1}$。\n衰减率$\\sigma_k$取决于阻尼比$\\zeta_k$：\n-   如果模态是欠阻尼的($\\zeta_k  1$)，极点是复数。衰减率为$\\sigma_k = \\zeta_k \\omega_{n,k} = \\frac{k_v \\lambda_k}{2}$。\n-   如果模态是过阻尼的($\\zeta_k  1$)，极点是实数且不同。衰减由较慢的极点（离原点更近）决定，速率为$\\sigma_k = \\zeta_k \\omega_{n,k} - \\omega_{n,k}\\sqrt{\\zeta_k^2 - 1}$。\n\n我们的目标是最大化保证的最差情况收敛速率，即$\\sigma_{\\text{worst}} = \\min_{k} \\sigma_k$，其中$k$遍历所有非平凡模态。在这里，非平凡模态对应于$\\lambda_a=2$和$\\lambda_b=4$。\n给定$k_p=9$：\n对于一个特征值为$\\lambda$的模态，临界阻尼($\\zeta=1$)的条件是$k_v = 2\\sqrt{k_p/\\lambda}$。\n-   对于$\\lambda_a=2$：在$k_v = 2\\sqrt{9/2} = 3\\sqrt{2}$时，$\\zeta_a=1$。\n-   对于$\\lambda_b=4$：在$k_v = 2\\sqrt{9/4} = 3$时，$\\zeta_b=1$。\n\n我们来分析衰减率$\\sigma_a(k_v)$和$\\sigma_b(k_v)$：\n-   对于特征值为$\\lambda_a=2$的模态$a$：\n    -   如果$k_v  3\\sqrt{2}$ (欠阻尼)，$\\sigma_a(k_v) = \\frac{k_v \\lambda_a}{2} = k_v$。\n    -   如果$k_v \\ge 3\\sqrt{2}$ (过阻尼)，$\\sigma_a(k_v) = \\frac{k_v \\cdot 2}{2} - \\sqrt{(\\frac{k_v \\cdot 2}{2})^2 - 9 \\cdot 2} = k_v - \\sqrt{k_v^2 - 18}$。\n-   对于特征值为$\\lambda_b=4$的模态$b$：\n    -   如果$k_v  3$ (欠阻尼)，$\\sigma_b(k_v) = \\frac{k_v \\lambda_b}{2} = 2k_v$。\n    -   如果$k_v \\ge 3$ (过阻尼)，$\\sigma_b(k_v) = \\frac{k_v \\cdot 4}{2} - \\sqrt{(\\frac{k_v \\cdot 4}{2})^2 - 9 \\cdot 4} = 2k_v - \\sqrt{4k_v^2 - 36}$。\n\n我们希望最大化$\\sigma_{\\text{worst}}(k_v) = \\min(\\sigma_a(k_v), \\sigma_b(k_v))$。\n-   对于$0  k_v \\le 3$：两个模态都是欠阻尼的。$\\sigma_a(k_v)=k_v$和$\\sigma_b(k_v)=2k_v$。最小值为$\\sigma_{\\text{worst}}(k_v) = k_v$。此函数随$k_v$增加而增加。\n-   对于$k_v > 3$：模态$b$变为过阻尼，其衰减率$\\sigma_b(k_v)$从其峰值$\\sigma_b(3)=6$开始减小。模态$a$仍然是欠阻尼的，其衰减率$\\sigma_a(k_v)=k_v$继续增加。\n最差情况的速率由较慢的模态决定。对于$k_v \\le 3$，这是模态$a$。当$k_v$增加超过$3$时，$\\sigma_a(k_v)$继续增加，而$\\sigma_b(k_v)$减小。使这两个函数中的最小值最大化的最佳$k_v$值将出现在它们的衰减率相等时，即$\\sigma_a(k_v) = \\sigma_b(k_v)$。这平衡了速率。这个交点必须发生在$3  k_v  3\\sqrt{2}$的区间内，此时模态$a$是欠阻尼的，模态$b$是过阻尼的。\n我们令衰减率相等：\n$$\n\\sigma_a(k_v) = \\sigma_b(k_v)\n$$\n$$\nk_v = 2k_v - \\sqrt{4k_v^2 - 36}\n$$\n整理方程：\n$$\n\\sqrt{4k_v^2 - 36} = k_v\n$$\n两边平方（因为$k_v > 0$所以有效）：\n$$\n4k_v^2 - 36 = k_v^2\n$$\n$$\n3k_v^2 = 36\n$$\n$$\nk_v^2 = 12\n$$\n$$\nk_v = \\sqrt{12} = 2\\sqrt{3}\n$$\n我们必须验证这个$k_v$值是否在假设的区间$3  k_v  3\\sqrt{2}$内。\n$(3)^2 = 9$，$(2\\sqrt{3})^2 = 12$，以及$(3\\sqrt{2})^2 = 18$。因为$9  12  18$，我们的假设是正确的。\n因此，最优增益为$k_v = 2\\sqrt{3}$。\n\n问题要求一个四舍五入到四位有效数字的数值。\n$$\nk_v = 2\\sqrt{3} \\approx 3.4641016...\n$$\n四舍五入到四位有效数字，我们得到$k_v = 3.464$。单位是$\\mathrm{s}^{-1}$，这是通过对运动方程$\\ddot{\\eta}_k + (k_v \\lambda_k)\\dot{\\eta}_k + \\dots = 0$进行量纲分析确定的，其中速度项$\\dot{\\eta}_k$的系数必须具有$\\mathrm{s}^{-1}$的单位，以使该项具有加速度的单位。",
            "answer": "$$\n\\boxed{3.464}\n$$"
        },
        {
            "introduction": "许多高级分布式控制应用，尤其是在资源分配和预测控制领域，需要以分散的方式解决具有耦合约束的复杂优化问题。本练习  将引导您从理论分析走向代码实现，任务是使用交替方向乘子法（ADMM）开发一个分布式模型预测控制（MPC）算法。这项实践将为您提供在分布式环境中构建和求解约束优化问题的宝贵经验，这对于为大规模赛博物理系统开发可扩展且鲁棒的控制方案至关重要。",
            "id": "4218235",
            "problem": "考虑一个由 $N$ 个离散时间线性子系统组成的网络，子系统索引为 $i \\in \\{1,\\dots,N\\}$。在 $t \\in \\{0,1,\\dots,T-1\\}$ 时，每个子系统根据状态方程 $x_{i,t+1} = A_i x_{i,t} + B_i u_{i,t}$ 演化，其中 $x_{i,t} \\in \\mathbb{R}$ 和 $u_{i,t} \\in \\mathbb{R}$ 分别是时间 $t$ 的标量状态和控制，且 $A_i \\in \\mathbb{R}$，$B_i \\in \\mathbb{R}$。设每个子系统 $i$ 的初始状态为 $x_{i,0} \\in \\mathbb{R}$。在长度为 $T$ 的时域上，模型预测控制 (MPC) 的目标是二次阶段成本和终端成本的总和，由经过充分检验的公式给出：\n$$\nJ_i(x_{i,0}, u_i) = \\sum_{t=0}^{T-1} \\left( Q_i x_{i,t}^2 + R_i u_{i,t}^2 \\right) + P_i x_{i,T}^2,\n$$\n其中 $Q_i \\ge 0$，$R_i  0$ 和 $P_i \\ge 0$ 是标量成本权重。总目标是 $\\sum_{i=1}^N J_i(x_{i,0}, u_i)$。\n\n在每个时间步 $t$，跨子系统施加了一个耦合资源约束，要求控制之和等于一个预设的资源向量 $r \\in \\mathbb{R}^T$：\n$$\n\\sum_{i=1}^N u_{i,t} = r_t \\quad \\text{对所有 } t \\in \\{0,1,\\dots,T-1\\}.\n$$\n\n任务是实现一个基于交替方向乘子法 (ADMM) 的分布式优化算法，以求解在这些耦合约束下的压缩 MPC 二次规划问题。该算法必须在压缩控制公式上运行，其中状态通过线性动力学被消去，成本被表示为每个子系统控制序列的严格凸二次函数。\n\n您必须推导停止准则，以保证在预设的容差范围内，同时满足原始可行性（局部变量与辅助变量之间的一致性以及耦合约束的满足）和对偶可行性（乘子的稳定性）。推导需从凸优化的 Karush-Kuhn-Tucker 条件和增广拉格朗日函数的定义出发。该推导必须基于基本的凸性和线性代数事实，并且不得假定使用简化公式。您的实现必须使用这些停止准则来终止迭代：返回一个布尔值，指示是否在最大迭代次数内满足了这些准则。\n\n您的程序应：\n- 为每个子系统 $i$ 构建形式如下的压缩二次目标：\n$$\n\\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + c_i,\n$$\n其中 $u_i \\in \\mathbb{R}^T$ 是堆叠的控制序列，$H_i \\in \\mathbb{R}^{T \\times T}$ 在 $R_i  0$ 的条件下是正定的，$h_i \\in \\mathbb{R}^T$，而 $c_i \\in \\mathbb{R}$ 是优化不需要的常数。\n- 实现对局部变量 $u_i$、辅助变量 $y_i$（用于强制耦合的副本）和对偶变量 $\\lambda_i$ 的 ADMM 迭代，其中增广拉格朗日惩罚参数为 $\\rho  0$。\n- 在每次迭代中，执行：\n  1. 对每个 $i$ 进行局部二次最小化，\n  2. 到仿射耦合约束上的投影，\n  3. 对偶变量更新。\n- 评估原始残差范数和对偶残差范数，并应用绝对-相对停止容差来判断收敛。\n- 对于下面的测试套件中的每个测试用例，输出一个布尔值，指示算法是否在最大迭代次数内满足了停止准则。\n\n使用以下测试套件，它探查了一个典型案例、收敛缓慢的紧容差案例、一个边界时域案例以及一个混合符号资源配置。所有数值必须与指定值完全一致：\n\n- 案例 1 (正常路径):\n  - $N = 2$, $T = 8$。\n  - 子系统 1: $A_1 = 1.0$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.1$, $P_1 = 2.0$, $x_{1,0} = 0.5$。\n  - 子系统 2: $A_2 = 0.9$, $B_2 = 1.1$, $Q_2 = 1.2$, $R_2 = 0.15$, $P_2 = 2.5$, $x_{2,0} = -0.2$。\n  - 资源向量 $r = [0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]$。\n  - ADMM 参数 $\\rho = 1.0$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-4}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-3}$。\n  - 最大迭代次数 $K_{\\max} = 1000$。\n- 案例 2 (紧容差，慢参数):\n  - $N = 2$, $T = 12$。\n  - 子系统 1: $A_1 = 1.0$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.05$, $P_1 = 1.5$, $x_{1,0} = 1.0$。\n  - 子系统 2: $A_2 = 0.95$, $B_2 = 1.0$, $Q_2 = 1.0$, $R_2 = 0.05$, $P_2 = 1.5$, $x_{2,0} = -1.0$。\n  - 资源向量 $r = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$。\n  - ADMM 参数 $\\rho = 0.01$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-9}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-9}$。\n  - 最大迭代次数 $K_{\\max} = 200$。\n- 案例 3 (边界时域):\n  - $N = 2$, $T = 1$。\n  - 子系统 1: $A_1 = 1.1$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.2$, $P_1 = 0.0$, $x_{1,0} = 0.1$。\n  - 子系统 2: $A_2 = 0.8$, $B_2 = 1.0$, $Q_2 = 1.0$, $R_2 = 0.2$, $P_2 = 0.0$, $x_{2,0} = 0.2$。\n  - 资源向量 $r = [0.0]$。\n  - ADMM 参数 $\\rho = 1.0$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-6}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-6}$。\n  - 最大迭代次数 $K_{\\max} = 50$。\n- 案例 4 (混合符号资源与非对称性):\n  - $N = 2$, $T = 5$。\n  - 子系统 1: $A_1 = 0.95$, $B_1 = 1.0$, $Q_1 = 1.0$, $R_1 = 0.1$, $P_1 = 1.0$, $x_{1,0} = 0.3$。\n  - 子系统 2: $A_2 = 1.05$, $B_2 = 0.9$, $Q_2 = 1.0$, $R_2 = 0.12$, $P_2 = 1.0$, $x_{2,0} = -0.3$。\n  - 资源向量 $r = [0.2, 0.0, -0.1, 0.1, 0.0]$。\n  - ADMM 参数 $\\rho = 0.5$。\n  - 停止容差 $\\epsilon_{\\mathrm{abs}} = 1 \\times 10^{-5}$, $\\epsilon_{\\mathrm{rel}} = 1 \\times 10^{-4}$。\n  - 最大迭代次数 $K_{\\max} = 1000$。\n\n您的程序必须产生一行输出，其中包含一个用方括号括起来的、逗号分隔的布尔值列表，按顺序表示案例 1 到 4 的收敛成功与否。确切格式为 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$。不应打印任何额外文本。",
            "solution": "用户提供了一个有效的问题陈述。任务是使用交替方向乘子法 (ADMM) 解决一个带耦合约束的分布式模型预测控制 (MPC) 问题。这涉及三个主要阶段：将 MPC 问题压缩为二次规划 (QP)，制定并实现 ADMM 算法，以及推导和应用适当的停止准则。\n\n### 问题验证\n对问题陈述的全面审查确认了其有效性。\n- **已知条件**：问题提供了离散时间线性动力学 $x_{i,t+1} = A_i x_{i,t} + B_i u_{i,t}$、带权重 $Q_i, R_i, P_i$ 的二次成本函数 $J_i$、初始状态 $x_{i,0}$、规划时域 $T$ 以及线性耦合约束 $\\sum_{i=1}^N u_{i,t} = r_t$。四个不同测试用例的所有参数均已指定，包括 ADMM 惩罚参数 $\\rho$、收敛容差 $\\epsilon_{\\mathrm{abs}}, \\epsilon_{\\mathrm{rel}}$ 和最大迭代次数 $K_{\\max}$。\n- **科学依据**：该公式是控制理论和优化领域一个标准的、公认的问题，代表了一个受共享资源约束的线性系统网络。ADMM 是解决此类分布式凸优化问题的经典算法。要求从第一性原理推导停止准则，是展示对凸优化理论理解的标准练习。\n- **适定性**：每个子系统的成本函数相对于其控制序列 $u_i$ 是严格凸的，因为权重 $R_i  0$ 确保了二次项带有一个正定矩阵。严格凸函数之和仍是严格凸的。约束集是一个非空仿射子空间。一个严格凸函数在一个非空闭凸集上最小化有唯一最小值。因此，该问题是适定的。\n- **客观性**：问题以精确、无歧义的数学语言陈述，所有必要参数均已定义。任务是客观的，需要一个形式化的、可验证的解决方案。\n\n该问题被认为是**有效的**，可以继续进行求解。\n\n### 1. 压缩 MPC 问题\n\n第一步是从成本函数 $J_i$ 中消去状态变量 $x_{i,t}$，以将其表示为控制序列 $u_i = [u_{i,0}, u_{i,1}, \\dots, u_{i,T-1}]^\\top \\in \\mathbb{R}^T$ 的二次函数。\n\n状态演化方程为 $x_{i,t+1} = A_i x_{i,t} + B_i u_{i,t}$。通过展开此递归，我们可以将任何状态 $x_{i,k}$ 表示为初始状态 $x_{i,0}$ 和直到时间 $k-1$ 的控制序列的仿射函数：\n$$\nx_{i,k} = A_i^k x_{i,0} + \\sum_{j=0}^{k-1} A_i^{k-1-j} B_i u_{i,j} \\quad \\text{对于 } k \\in \\{1, \\dots, T\\}.\n$$\n我们可以将被惩罚的状态序列 $\\mathbf{x}_{i,\\text{seq}} = [x_{i,0}, x_{i,1}, \\dots, x_{i,T}]^\\top \\in \\mathbb{R}^{T+1}$ 表示为紧凑的矩阵形式：\n$$\n\\mathbf{x}_{i,\\text{seq}} = \\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x}\n$$\n其中 $\\mathbf{S}_{i,u} \\in \\mathbb{R}^{(T+1) \\times T}$ 和 $\\mathbf{s}_{i,x} \\in \\mathbb{R}^{T+1}$ 按元素定义如下：\n$$\n(\\mathbf{S}_{i,u})_{k,j} = \\begin{cases} A_i^{k-1-j} B_i  \\text{如果 } j  k \\\\ 0  \\text{否则} \\end{cases} \\quad \\text{对于 } k \\in \\{0, \\dots, T\\}, j \\in \\{0, \\dots, T-1\\}\n$$\n$$\n(\\mathbf{s}_{i,x})_k = A_i^k x_{i,0} \\quad \\text{对于 } k \\in \\{0, \\dots, T\\}\n$$\n成本函数为：\n$$\nJ_i(x_{i,0}, u_i) = \\sum_{t=0}^{T-1} (Q_i x_{i,t}^2 + R_i u_{i,t}^2) + P_i x_{i,T}^2\n$$\n这可以写成矩阵形式：\n$$\nJ_i(u_i) = \\mathbf{x}_{i,\\text{seq}}^\\top \\mathbf{Q}'_i \\mathbf{x}_{i,\\text{seq}} + u_i^\\top \\mathbf{R}'_i u_i\n$$\n其中 $\\mathbf{Q}'_i = \\text{diag}(Q_i, \\dots, Q_i, P_i) \\in \\mathbb{R}^{(T+1)\\times(T+1)}$ 且 $\\mathbf{R}'_i = \\text{diag}(R_i, \\dots, R_i) \\in \\mathbb{R}^{T\\times T}$。\n\n代入 $\\mathbf{x}_{i,\\text{seq}}$ 的表达式：\n$$\nJ_i(u_i) = (\\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x})^\\top \\mathbf{Q}'_i (\\mathbf{S}_{i,u} u_i + \\mathbf{s}_{i,x}) + u_i^\\top \\mathbf{R}'_i u_i\n$$\n展开此表达式并按 $u_i$ 的幂次对各项进行分组，得到所需的二次形式 $\\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + c_i$：\n- **二次项**: $u_i^\\top (\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} + \\mathbf{R}'_i) u_i$\n- **线性项**: $2 \\mathbf{s}_{i,x}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} u_i$\n- **常数项**: $\\mathbf{s}_{i,x}^\\top \\mathbf{Q}'_i \\mathbf{s}_{i,x}$\n\n由此，我们确定了海森矩阵 $H_i \\in \\mathbb{R}^{T \\times T}$ 和线性系数向量 $h_i \\in \\mathbb{R}^T$：\n$$\nH_i = 2(\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u} + \\mathbf{R}'_i)\n$$\n$$\nh_i = 2 \\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{s}_{i,x}\n$$\n由于 $R_i  0$，$\\mathbf{R}'_i$ 是正定的。由于 $Q_i, P_i \\ge 0$，$\\mathbf{S}_{i,u}^\\top \\mathbf{Q}'_i \\mathbf{S}_{i,u}$ 是半正定的。因此，$H_i$ 是正定的，确保了局部目标函数的严格凸性。\n\n### 2. ADMM 公式\n完整的优化问题是：\n$$\n\\min_{u_1, \\dots, u_N} \\sum_{i=1}^N \\left( \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i \\right) \\quad \\text{s.t.} \\quad \\sum_{i=1}^N u_i = r\n$$\n其中 $r = [r_0, \\dots, r_{T-1}]^\\top$。为了应用 ADMM，我们引入辅助变量 $y_i \\in \\mathbb{R}^T$ 并构建一个等价的一致性问题：\n$$\n\\min_{u_i, y_i} \\sum_{i=1}^N f_i(u_i) + g(y) \\quad \\text{s.t.} \\quad u_i = y_i \\; \\forall i\n$$\n这里，$f_i(u_i) = \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i$，而 $g(y)$ 是仿射约束集 $C = \\{(y_1, \\dots, y_N) \\mid \\sum_{i=1}^N y_i = r\\}$ 的指示函数。\n\n该问题的增广拉格朗日函数 $\\mathcal{L}_\\rho$（其中 $\\lambda_i$ 为对偶变量）是：\n$$\n\\mathcal{L}_\\rho(u, y, \\lambda) = \\sum_{i=1}^N \\left( f_i(u_i) + \\lambda_i^\\top(u_i - y_i) + \\frac{\\rho}{2} \\|u_i - y_i\\|_2^2 \\right) + g(y)\n$$\nADMM 通过迭代地最小化 $\\mathcal{L}_\\rho$ 关于 $u$ 和 $y$，然后进行对偶变量更新。迭代（在步骤 $k+1$）如下：\n\n1.  **$u$-最小化**：对于每个子系统 $i$，通过最小化 $\\mathcal{L}_\\rho$ 求解 $u_i^{k+1}$，这是一个严格凸二次规划问题：\n    $$\n    u_i^{k+1} = \\arg\\min_{u_i} \\left( \\frac{1}{2} u_i^\\top H_i u_i + h_i^\\top u_i + (\\lambda_i^k)^\\top u_i + \\frac{\\rho}{2} \\|u_i - y_i^k\\|_2^2 \\right)\n    $$\n    将梯度设置为零可得一阶条件 $(H_i + \\rho I)u_i^{k+1} + h_i + \\lambda_i^k - \\rho y_i^k = 0$，从而得到更新公式：\n    $$\n    u_i^{k+1} = (H_i + \\rho I)^{-1} (\\rho y_i^k - h_i - \\lambda_i^k)\n    $$\n    矩阵 $(H_i + \\rho I)$ 在算法开始时只求逆一次。\n\n2.  **$y$-最小化**：对 $y^{k+1} = (y_1^{k+1}, \\dots, y_N^{k+1})$ 的更新涉及在集合 $C$ 上最小化 $\\mathcal{L}_\\rho$。这等效于找到到 $C$ 上的欧几里得投影：\n    $$\n    y^{k+1} = \\arg\\min_{\\sum y_i = r} \\sum_{i=1}^N \\frac{\\rho}{2} \\left\\| y_i - \\left(u_i^{k+1} + \\frac{1}{\\rho}\\lambda_i^k\\right) \\right\\|_2^2\n    $$\n    解通过求平均值得到。令 $z_i^k = u_i^{k+1} + \\frac{1}{\\rho}\\lambda_i^k$。更新公式为：\n    $$\n    y_i^{k+1} = z_i^k - \\bar{z}^k + \\frac{1}{N}r, \\quad \\text{其中} \\quad \\bar{z}^k = \\frac{1}{N}\\sum_{j=1}^N z_j^k\n    $$\n\n3.  **$\\lambda$-更新**：对偶变量使用标准的梯度上升步骤进行更新：\n    $$\n    \\lambda_i^{k+1} = \\lambda_i^k + \\rho(u_i^{k+1} - y_i^{k+1})\n    $$\n\n### 3. 停止准则的推导\n\n最优性的 Karush-Kuhn-Tucker (KKT) 条件是原始可行性、对偶可行性和互补松弛性。对于我们的一致性问题，这些条件转化为：\n1.  **原始可行性**：对所有 $i$ 有 $u_i^* = y_i^*$，并且 $\\sum_i y_i^* = r$。\n2.  **对偶可行性**：拉格朗日函数关于原始变量的梯度必须为零。\n    - $\\nabla_{u_i} \\mathcal{L} = \\nabla f_i(u_i^*) + \\lambda_i^* = 0 \\implies H_i u_i^* + h_i + \\lambda_i^* = 0$。\n    - $\\nabla_{y_i} \\mathcal{L}$ 与 $g$ 的次微分有关，意味着所有 $i$ 的 $\\lambda_i^*$ 必须相等。\n\nADMM 算法的残差衡量了当前迭代距离满足这些条件的程度。\n\n- **原始残差**：衡量一致性约束 $u_i = y_i$ 的违反程度。在迭代 $k+1$ 时的原始残差是 $r_p^{k+1} = u^{k+1} - y^{k+1}$。其范数为 $\\|r_p^{k+1}\\|_2 = \\sqrt{\\sum_i \\|u_i^{k+1} - y_i^{k+1}\\|_2^2}$。\n\n- **对偶残差**：衡量平稳性条件的违反程度。从 $u$-更新中，我们有 $H_i u_i^{k+1} + h_i + \\lambda_i^k + \\rho(u_i^{k+1}-y_i^k)=0$。使用 $\\lambda$-更新来替换 $\\lambda_i^k$，我们得到 $H_i u_i^{k+1} + h_i + \\lambda_i^{k+1} + \\rho(y_i^{k+1}-y_i^k)=0$。对偶可行性条件要求 $H_i u_i^* + h_i + \\lambda_i^* = 0$。在迭代 $k+1$ 时阻止这一点的项是 $\\rho(y_i^{k+1}-y_i^k)$。这导致了对偶残差的定义 $r_d^{k+1} = \\rho(y^{k+1} - y^k)$。其范数为 $\\|r_d^{k+1}\\|_2 = \\rho \\sqrt{\\sum_i \\|y_i^{k+1} - y_i^k\\|_2^2}$。\n\n当两个残差范数都小于一个阈值时，宣告收敛。这些阈值 $\\epsilon^{\\text{primal}}$ 和 $\\epsilon^{\\text{dual}}$ 结合了绝对和相对容差，以处理不同规模的问题：\n$$\n\\|r_p^{k+1}\\|_2 \\le \\epsilon^{\\text{primal}} = \\sqrt{NT} \\epsilon_{\\text{abs}} + \\epsilon_{\\text{rel}} \\max\\{\\|u^{k+1}\\|_2, \\|y^{k+1}\\|_2\\}\n$$\n$$\n\\|r_d^{k+1}\\|_2 \\le \\epsilon^{\\text{dual}} = \\sqrt{NT} \\epsilon_{\\text{abs}} + \\epsilon_{\\text{rel}} \\|\\lambda^{k+1}\\|_2\n$$\n其中 $u, y, \\lambda$ 代表所有子系统的堆叠向量，例如 $\\|u\\|_2 = \\sqrt{\\sum_i \\|u_i\\|_2^2}$。项 $\\sqrt{NT}$ 根据问题维度缩放绝对容差。",
            "answer": "```python\nimport numpy as np\n\ndef build_condensed_matrices(T, A, B, Q, R, P, x0):\n    \"\"\"\n    Constructs the matrices H and h for the condensed QP form for one subsystem.\n    \"\"\"\n    # State sequence matrices\n    S_u = np.zeros((T + 1, T))\n    s_x = np.zeros(T + 1)\n    \n    # Populate S_u and s_x based on unrolled dynamics\n    # k is the state index x_k, j is the control index u_j\n    for k in range(T + 1):\n        s_x[k] = (A**k) * x0\n        if k > 0:\n            for j in range(k):\n                # Coefficient of u_j in the expansion of x_k\n                if k - 1 - j >= 0:\n                    S_u[k, j] = (A**(k - 1 - j)) * B\n\n    # Cost matrices\n    Q_prime = np.diag([Q] * T + [P])\n    R_prime = np.diag([R] * T)\n    \n    # Condensed QP matrices\n    H = 2.0 * (S_u.T @ Q_prime @ S_u + R_prime)\n    h = 2.0 * S_u.T @ Q_prime @ s_x\n    \n    return H, h\n\ndef run_admm_for_case(case_params):\n    \"\"\"\n    Runs the ADMM algorithm for a single test case.\n    \"\"\"\n    N = case_params['N']\n    T = case_params['T']\n    subsystems = case_params['subsystems']\n    r = np.array(case_params['r'], dtype=float)\n    rho = case_params['rho']\n    eps_abs = case_params['eps_abs']\n    eps_rel = case_params['eps_rel']\n    K_max = case_params['K_max']\n\n    # Step 1: Condensation and pre-computation for each subsystem\n    H_list, h_list, P_H_list = [], [], []\n    for params in subsystems:\n        A, B, Q, R, P, x0 = params\n        H, h = build_condensed_matrices(T, float(A), float(B), float(Q), float(R), float(P), float(x0))\n        H_list.append(H)\n        h_list.append(h)\n        # Pre-compute inverse for u-update\n        P_H_list.append(np.linalg.inv(H + rho * np.identity(T)))\n\n    # Step 2: ADMM Initialization\n    u_list = [np.zeros(T) for _ in range(N)]\n    y_list = [np.zeros(T) for _ in range(N)]\n    lambda_list = [np.zeros(T) for _ in range(N)]\n    \n    # Step 3: ADMM Iterations\n    for k in range(K_max):\n        y_list_old = [y.copy() for y in y_list]\n\n        # u-updates (local solves)\n        u_list_new = []\n        for i in range(N):\n            rhs = rho * y_list[i] - h_list[i] - lambda_list[i]\n            u_i_new = P_H_list[i] @ rhs\n            u_list_new.append(u_i_new)\n\n        # y-updates (projection onto consensus set)\n        z_list = [u_list_new[i] + lambda_list[i] / rho for i in range(N)]\n        avg_z = sum(z_list) / N\n        \n        y_list_new = []\n        for i in range(N):\n            y_i_new = z_list[i] - avg_z + r / N\n            y_list_new.append(y_i_new)\n\n        # lambda-updates (dual ascent)\n        lambda_list_new = []\n        for i in range(N):\n            lambda_i_new = lambda_list[i] + rho * (u_list_new[i] - y_list_new[i])\n            lambda_list_new.append(lambda_i_new)\n        \n        # Update state variables for the next iteration\n        u_list, y_list, lambda_list = u_list_new, y_list_new, lambda_list_new\n\n        # Step 4: Check stopping criteria\n        u_stack = np.concatenate(u_list)\n        y_stack = np.concatenate(y_list)\n        lambda_stack = np.concatenate(lambda_list)\n        y_old_stack = np.concatenate(y_list_old)\n\n        # Primal residual norm\n        res_p_norm = np.linalg.norm(u_stack - y_stack)\n        \n        # Dual residual norm\n        res_d_norm = rho * np.linalg.norm(y_stack - y_old_stack)\n\n        # Primal and dual stopping thresholds (tolerances)\n        eps_p = np.sqrt(N * T) * eps_abs + eps_rel * max(np.linalg.norm(u_stack), np.linalg.norm(y_stack))\n        eps_d = np.sqrt(N * T) * eps_abs + eps_rel * np.linalg.norm(lambda_stack)\n\n        if res_p_norm = eps_p and res_d_norm = eps_d:\n            return True\n\n    return False\n\ndef solve():\n    \"\"\"\n    Defines test cases and orchestrates the solution process.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            'N': 2, 'T': 8,\n            'subsystems': [\n                (1.0, 1.0, 1.0, 0.1, 2.0, 0.5),\n                (0.9, 1.1, 1.2, 0.15, 2.5, -0.2)\n            ],\n            'r': [0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05],\n            'rho': 1.0, 'eps_abs': 1e-4, 'eps_rel': 1e-3, 'K_max': 1000\n        },\n        # Case 2 (tight tolerance, slow parameter)\n        {\n            'N': 2, 'T': 12,\n            'subsystems': [\n                (1.0, 1.0, 1.0, 0.05, 1.5, 1.0),\n                (0.95, 1.0, 1.0, 0.05, 1.5, -1.0)\n            ],\n            'r': [0.0] * 12,\n            'rho': 0.01, 'eps_abs': 1e-9, 'eps_rel': 1e-9, 'K_max': 200\n        },\n        # Case 3 (boundary horizon)\n        {\n            'N': 2, 'T': 1,\n            'subsystems': [\n                (1.1, 1.0, 1.0, 0.2, 0.0, 0.1),\n                (0.8, 1.0, 1.0, 0.2, 0.0, 0.2)\n            ],\n            'r': [0.0],\n            'rho': 1.0, 'eps_abs': 1e-6, 'eps_rel': 1e-6, 'K_max': 50\n        },\n        # Case 4 (mixed-sign resource and asymmetry)\n        {\n            'N': 2, 'T': 5,\n            'subsystems': [\n                (0.95, 1.0, 1.0, 0.1, 1.0, 0.3),\n                (1.05, 0.9, 1.0, 0.12, 1.0, -0.3)\n            ],\n            'r': [0.2, 0.0, -0.1, 0.1, 0.0],\n            'rho': 0.5, 'eps_abs': 1e-5, 'eps_rel': 1e-4, 'K_max': 1000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        converged = run_admm_for_case(case)\n        results.append(converged)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}