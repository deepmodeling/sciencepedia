{
    "hands_on_practices": [
        {
            "introduction": "分布式模型预测控制的核心挑战在于如何协调多个子系统以实现全局目标，同时保持计算的本地化。交替方向乘子法（ADMM）是解决此类耦合优化问题的强大工具。通过本练习 ，您将从第一性原理出发，为典型的DMPC问题推导出ADMM的迭代格式，从而深入理解如何通过引入共识变量和对偶更新来实现分布式计算，这是掌握DMPC算法精髓的关键一步。",
            "id": "4218526",
            "problem": "考虑一个网络化信息物理系统 (CPS)，其数字孪生 (DT) 用于通过分布式模型预测控制 (MPC) 来协调 $N$ 个子系统的控制。在给定的采样时刻，每个子系统 $i \\in \\{1,\\dots,N\\}$ 选择一个局部控制向量 $u^{i} \\in \\mathbb{R}^{n_{i}}$ 以最小化局部二次阶段成本，同时满足一个全局耦合约束。局部成本由 $f_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top} Q_{i} u^{i} + c_{i}^{\\top} u^{i}$ 给出，其中 $Q_{i} \\in \\mathbb{R}^{n_{i} \\times n_{i}}$ 是对称正定的，且 $c_{i} \\in \\mathbb{R}^{n_{i}}$。全局耦合约束源于子系统间的物理资源共享，并被建模为\n$$\n\\sum_{i=1}^{N} H_{i} u^{i} = h,\n$$\n其中，对于每个 $i$，$H_{i} \\in \\mathbb{R}^{m \\times n_{i}}$，而 $h \\in \\mathbb{R}^{m}$ 由 DT 在当前采样时刻给出。假设每个 $H_{i}$ 都是列满秩的。\n\nDT 旨在通过求解以下凸规划问题来计算最优控制：\n$$\n\\min_{\\{u^{i}\\}_{i=1}^{N}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) \\quad \\text{subject to} \\quad \\sum_{i=1}^{N} H_{i} u^{i} = h.\n$$\n为了获得一个能保持局部性的分布式算法，我们引入一个一致性变量 $z := (z^{1},\\dots,z^{N})$，其分量为 $z^{i} \\in \\mathbb{R}^{m}$，同时引入局部一致性约束 $H_{i} u^{i} - z^{i} = 0$ 和全局仿射约束 $\\sum_{i=1}^{N} z^{i} = h$。将问题等价地表述为\n$$\n\\min_{\\{u^{i}\\}, \\{z^{i}\\}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) \\quad \\text{subject to} \\quad H_{i} u^{i} - z^{i} = 0 \\ \\text{for all } i,\n$$\n其中 $I_{\\mathcal{C}}(z)$ 是仿射集 $\\mathcal{C} := \\left\\{ z \\in \\mathbb{R}^{mN} : \\sum_{i=1}^{N} z^{i} = h \\right\\}$ 的指示函数，定义为：如果 $z \\in \\mathcal{C}$，则 $I_{\\mathcal{C}}(z) = 0$，否则 $I_{\\mathcal{C}}(z) = +\\infty$。\n\n从增广拉格朗日方法和交替方向乘子法 (ADMM) 的核心定义出发，为局部控制 $u^{i}$ 和一致性变量分量 $z^{i}$，以及与约束 $H_{i} u^{i} - z^{i} = 0$ 相关的尺度对偶变量 $y^{i} \\in \\mathbb{R}^{m}$，推导出带有惩罚参数 $\\rho > 0$ 的尺度形式 ADMM 迭代。您的推导必须从构建增广拉格朗日量开始，并展示每个分块最小化和对偶上升步是如何从第一性原理得到的。然后，将 $u^{i}$ 的更新针对给定的二次成本进行特化，并提供用 $Q_{i}$、$c_{i}$、$H_{i}$、$h$、$\\rho$ 和先前的迭代量表示的 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$ 的显式闭式更新方程。将您的最终答案表示为三个解析表达式，分别对应于 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$，并且对所有 $i \\in \\{1,\\dots,N\\}$ 有效。\n\n无需进行数值评估，也不应进行任何舍入。使用 $\\LaTeX$ 的 $\\mathrm{pmatrix}$ 环境，将您的最终表达式表示为一个单行矩阵，其条目按 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$ 的更新顺序排列。",
            "solution": "该问题要求为数字孪生和信息物理系统背景下出现的一个分布式优化问题，推导尺度形式的交替方向乘子法 (ADMM) 迭代。我们首先验证问题陈述。\n\n给定的条件是：\n- $N$ 个子系统，由 $i \\in \\{1, \\dots, N\\}$ 索引。\n- 局部控制向量 $u^{i} \\in \\mathbb{R}^{n_{i}}$。\n- 局部成本函数 $f_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top} Q_{i} u^{i} + c_{i}^{\\top} u^{i}$，其中 $Q_{i} \\in \\mathbb{R}^{n_{i} \\times n_{i}}$ 是对称正定的，且 $c_{i} \\in \\mathbb{R}^{n_{i}}$。\n- 一个全局耦合约束 $\\sum_{i=1}^{N} H_{i} u^{i} = h$，其中 $H_{i} \\in \\mathbb{R}^{m \\times n_{i}}$ 具有列满秩，且 $h \\in \\mathbb{R}^{m}$。\n- 等价的、适用于 ADMM 的表述：\n$$ \\min_{\\{u^{i}\\}, \\{z^{i}\\}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) \\quad \\text{subject to} \\quad H_{i} u^{i} - z^{i} = 0 \\ \\text{for all } i, $$\n其中 $z = (z^{1}, \\dots, z^{N})$ 且 $z^{i} \\in \\mathbb{R}^{m}$，$I_{\\mathcal{C}}(z)$ 是仿射集 $\\mathcal{C} := \\left\\{ z \\in \\mathbb{R}^{mN} : \\sum_{i=1}^{N} z^{i} = h \\right\\}$ 的指示函数。\n- ADMM 惩罚参数为 $\\rho > 0$。\n- 尺度对偶变量为 $y^{i} \\in \\mathbb{R}^{m}$。\n\n该问题具有科学依据、是适定的、客观的、完整的且数学上严谨。它是凸优化技术在分布式控制中的一个标准应用，而分布式控制是指定领域的一个核心课题。因此，该问题被认为是有效的。我们继续进行推导。\n\nADMM 算法应用于形式为 $\\min_{x,w} F(x) + G(w)$ subject to $Ax + Bw = c$ 的问题。在我们的案例中，优化变量是局部控制的集合 $u = (u^{1}, \\dots, u^{N})$ 和一致性变量的集合 $z = (z^{1}, \\dots, z^{N})$。目标函数是可分的：$F(u) = \\sum_{i=1}^{N} f_{i}(u^{i})$ 和 $G(z) = I_{\\mathcal{C}}(z)$。约束为 $H_{i}u^{i} - z^{i} = 0$，对所有 $i \\in \\{1, \\dots, N\\}$ 成立。\n\n为该问题构建尺度形式的增广拉格朗日量 $\\mathcal{L}_{\\rho}$。令 $y = (y^{1}, \\dots, y^{N})$ 为尺度对偶变量的堆叠向量。\n$$ \\mathcal{L}_{\\rho}(u, z, y) = \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) + \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| H_{i}u^{i} - z^{i} + y^{i} \\|_{2}^{2} - \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| y^{i} \\|_{2}^{2} $$\n在最小化过程中，涉及 $\\|y^{i}\\|_{2}^{2}$ 的常数项可以被省略。ADMM 算法在每次迭代 $k$ 中通过迭代三个步骤进行：关于 $u$ 的最小化，关于 $z$ 的最小化，以及对偶变量更新。\n\n步骤 1：$u$-更新\n在第 $k+1$ 次迭代中，我们将 $z$ 和 $y$ 固定在第 $k$ 次迭代的值，通过最小化 $\\mathcal{L}_{\\rho}$ 来更新原始变量 $u$：\n$$ u_{k+1} = \\arg\\min_{u} \\mathcal{L}_{\\rho}(u, z_{k}, y_{k}) $$\n由于目标函数和约束的可分结构，这个最小化问题可以分解为 $N$ 个独立的子问题，每个子系统 $i$ 对应一个：\n$$ u^{i}_{k+1} = \\arg\\min_{u^{i}} \\left( f_{i}(u^{i}) + \\frac{\\rho}{2} \\| H_{i}u^{i} - z^{i}_{k} + y^{i}_{k} \\|_{2}^{2} \\right) $$\n代入 $f_{i}(u^{i})$ 的二次形式，该子问题的目标函数是：\n$$ J_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top}Q_{i}u^{i} + c_{i}^{\\top}u^{i} + \\frac{\\rho}{2} (H_{i}u^{i} - z^{i}_{k} + y^{i}_{k})^{\\top}(H_{i}u^{i} - z^{i}_{k} + y^{i}_{k}) $$\n这个函数关于 $u^{i}$ 是严格凸的，因为 $Q_{i}$ 是正定的且 $\\rho > 0$。通过将关于 $u^{i}$ 的梯度设为零，可以找到唯一的最小化子：\n$$ \\nabla_{u^{i}} J_{i}(u^{i}) = Q_{i}u^{i} + c_{i} + \\rho H_{i}^{\\top}(H_{i}u^{i} - z^{i}_{k} + y^{i}_{k}) = 0 $$\n整理各项以求解 $u^{i}$：\n$$ (Q_{i} + \\rho H_{i}^{\\top}H_{i}) u^{i} = \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} $$\n矩阵 $(Q_{i} + \\rho H_{i}^{\\top}H_{i})$ 是可逆的，因为 $Q_{i}$ 是正定的，而 $H_{i}^{\\top}H_{i}$ 是半正定的。因此，我们得到 $u^{i}_{k+1}$ 的闭式更新：\n$$ u^{i}_{k+1} = (Q_{i} + \\rho H_{i}^{\\top}H_{i})^{-1} \\left( \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} \\right) $$\n\n步骤 2：$z$-更新\n接下来，我们将 $u$ 固定在 $u_{k+1}$，将 $y$ 固定在 $y_{k}$，通过最小化 $\\mathcal{L}_{\\rho}$ 来更新一致性变量 $z$：\n$$ z_{k+1} = \\arg\\min_{z} \\mathcal{L}_{\\rho}(u_{k+1}, z, y_{k}) $$\n这个最小化等价于求解：\n$$ \\min_{z} \\left( I_{\\mathcal{C}}(z) + \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| H_{i}u^{i}_{k+1} - z^{i} + y^{i}_{k} \\|_{2}^{2} \\right) $$\n指示函数 $I_{\\mathcal{C}}(z)$ 强制执行约束 $\\sum_{i=1}^{N} z^{i} = h$。该问题可以重写为在仿射集 $\\mathcal{C}$ 上的一个投影问题：\n$$ \\min_{\\{z^{i}\\}} \\sum_{i=1}^{N} \\| z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k}) \\|_{2}^{2} \\quad \\text{subject to} \\quad \\sum_{i=1}^{N} z^{i} = h $$\n我们为这个子问题构建拉格朗日函数，其中乘子为 $\\nu \\in \\mathbb{R}^{m}$：\n$$ \\mathcal{L}_{z}(\\{z^{i}\\}, \\nu) = \\sum_{i=1}^{N} \\| z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k}) \\|_{2}^{2} + 2\\nu^{\\top}\\left(\\sum_{i=1}^{N} z^{i} - h\\right) $$\n对每个 $z^{i}$ 求梯度并令其为零，得到：\n$$ 2(z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k})) + 2\\nu = 0 \\implies z^{i} = (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\nu $$\n为了找到 $\\nu$，我们强制执行约束 $\\sum_{i=1}^{N} z^{i} = h$：\n$$ \\sum_{i=1}^{N} \\left( (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\nu \\right) = h \\implies \\sum_{i=1}^{N} (H_{i}u^{i}_{k+1} + y^{i}_{k}) - N\\nu = h $$\n求解 $\\nu$：\n$$ \\nu = \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right) $$\n将这个 $\\nu$ 的表达式代回到 $z^{i}$ 的方程中，得到 $z^{i}_{k+1}$ 的更新：\n$$ z^{i}_{k+1} = (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right) $$\n\n步骤 3：$y$-更新\n最后，使用对偶上升步来更新尺度对偶变量。对于每个约束 $H_{i}u^{i} - z^{i} = 0$，更新规则是：\n$$ y^{i}_{k+1} = y^{i}_{k} + (H_{i}u^{i}_{k+1} - z^{i}_{k+1}) $$\n这表示在第 $k+1$ 次迭代时，基于局部一致性约束的残差对尺度对偶变量进行的更新。\n\n这三个方程构成了针对给定分布式优化问题的完整 ADMM 迭代集合。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n(Q_{i} + \\rho H_{i}^{\\top}H_{i})^{-1} \\left( \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} \\right) & (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right) & y^{i}_{k} + H_{i}u^{i}_{k+1} - z^{i}_{k+1}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在分布式控制系统中，各智能体基于局部信息进行自利优化，系统整体的行为往往会收敛到一个纳什均衡，而非全局最优解。这种由于缺乏中心协调而导致的系统性能损失，常被称为“无政府代价”。本练习  将引导您为一个具有交叉耦合成本的线性二次型动态博弈计算纳什均衡和中心化最优控制序列，并通过比较两者来量化分布式决策的效率，这对于评估和设计分布式系统至关重要。",
            "id": "4218474",
            "problem": "考虑一个信息物理系统 (CPS) 中的两个智能体，其数字孪生 (DT) 在有限时域上采用分布式模型预测控制 (DMPC)。每个智能体都有一个单输入、单状态的离散时间线性模型，并且它们的成本通过状态交叉耦合。目标是计算开环纳什均衡控制序列，并将其与最小化智能体成本之和的集中式最优解进行比较。\n\n假设对于智能体 $i \\in \\{1,2\\}$：\n- 动态特性由 $x_i(k+1) = a_i x_i(k) + b_i u_i(k)$ 给出，其中 $k \\in \\{0,1,\\dots,N-1\\}$。\n- 初始条件为 $x_i(0) = x_{i0}$。\n- 智能体 $i$ 在时间 $k$ 的阶段成本为 $q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)$，其中 $q_i \\ge 0$，$r_i > 0$ 且 $\\gamma \\in \\mathbb{R}$。\n- 智能体在整个时域内的总成本为 $J_i = \\sum_{k=0}^{N-1} \\left(q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)\\right)$。\n\n我们将通过标准的线性系统堆叠方法，用每个智能体的控制序列来表示其在时域内的状态轨迹。为智能体 $i$ 定义：\n- 堆叠状态向量 $\\mathbf{x}_i = \\begin{bmatrix}x_i(0) & x_i(1) & \\dots & x_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- 堆叠控制向量 $\\mathbf{u}_i = \\begin{bmatrix}u_i(0) & u_i(1) & \\dots & u_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- 堆叠仿射关系 $\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$，其中 $\\boldsymbol{\\alpha}_i \\in \\mathbb{R}^N$ 和 $T_i \\in \\mathbb{R}^{N \\times N}$ 由动态特性确定。具体来说，对于 $k \\in \\{0,1,\\dots,N-1\\}$ 和 $j \\in \\{0,1,\\dots,N-1\\}$，\n$$\n\\left(\\boldsymbol{\\alpha}_i\\right)_k = a_i^k x_{i0}, \\quad\n\\left(T_i\\right)_{k,j} =\n\\begin{cases}\nb_i a_i^{k-1-j}, & \\text{if } j \\le k-1,\\\\\n0, & \\text{if } j \\ge k.\n\\end{cases}\n$$\n\n令 $Q_i = q_i I_N$，$R_i = r_i I_N$ 且 $W = I_N$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。Nash 均衡定义为一对控制序列 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$，使得在给定另一方决策的情况下，每个智能体都最小化其自身成本 $J_i$，这等价于 $J_i$ 相对于 $\\mathbf{u}_i$ 的梯度为零的平稳点条件。集中式最优解定义为成本之和 $J_{\\mathrm{sum}} = J_1 + J_2$ 相对于 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 的最小化解。\n\n您的任务是：\n- 使用上述定义，从第一性原理出发，为 Nash 均衡和集中式最优解构建分块线性系统。\n- 求解这些系统，以获得 Nash 均衡的 $\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star$ 和集中式最优解的 $\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}}$。\n- 为每个测试用例计算比较指标，该指标定义为 Nash 控制序列和集中式控制序列在两个智能体和所有时间步长上的均方根 (RMS) 差异：\n$$\n\\mathrm{RMS} = \\sqrt{\\frac{1}{2N} \\left\\| \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix} - \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix} \\right\\|_2^2 }.\n$$\n\n使用以下参数集测试套件，涵盖典型、边界和边缘情况。为每个用例计算 RMS 差异。无物理单位适用。\n\n- 测试用例 1：$N = 3$, $a_1 = 1.0$, $b_1 = 1.0$, $q_1 = 1.0$, $r_1 = 0.1$, $a_2 = 0.9$, $b_2 = 1.2$, $q_2 = 1.0$, $r_2 = 0.1$, $\\gamma = 0.5$, $x_{10} = 1.0$, $x_{20} = -1.0$.\n- 测试用例 2：$N = 4$, $a_1 = 1.0$, $b_1 = 1.0$, $q_1 = 1.0$, $r_1 = 0.2$, $a_2 = 1.0$, $b_2 = 1.0$, $q_2 = 1.0$, $r_2 = 0.2$, $\\gamma = 0.0$, $x_{10} = 0.5$, $x_{20} = 0.5$.\n- 测试用例 3：$N = 1$, $a_1 = 1.1$, $b_1 = 1.0$, $q_1 = 1.0$, $r_1 = 1.0$, $a_2 = 0.8$, $b_2 = 1.1$, $q_2 = 1.0$, $r_2 = 1.0$, $\\gamma = 0.5$, $x_{10} = 2.0$, $x_{20} = -3.0$.\n- 测试用例 4：$N = 5$, $a_1 = 1.2$, $b_1 = 1.0$, $q_1 = 0.5$, $r_1 = 0.5$, $a_2 = 1.05$, $b_2 = 0.8$, $q_2 = 1.5$, $r_2 = 0.3$, $\\gamma = 0.8$, $x_{10} = 1.0$, $x_{20} = 1.5$.\n\n最终输出格式：您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表（例如，$[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4]$），每个条目是相应测试用例的 RMS 差异。",
            "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n- **系统动态特性**：对于智能体 $i \\in \\{1,2\\}$，其离散时间动态特性为 $x_i(k+1) = a_i x_i(k) + b_i u_i(k)$，时域为 $k \\in \\{0, 1, \\dots, N-1\\}$。\n- **初始条件**：$x_i(0) = x_{i0}$。\n- **阶段成本**：对于智能体 $i$，在时间 $k$ 的成本为 $q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)$，其中 $q_i \\ge 0$，$r_i > 0$，$\\gamma \\in \\mathbb{R}$。\n- **总成本**：$J_i = \\sum_{k=0}^{N-1} \\left(q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)\\right)$。\n- **堆叠向量**：\n    - 状态：$\\mathbf{x}_i = \\begin{bmatrix}x_i(0) & x_i(1) & \\dots & x_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n    - 控制：$\\mathbf{u}_i = \\begin{bmatrix}u_i(0) & u_i(1) & \\dots & u_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- **堆叠仿射关系**：$\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$，其分量定义为：\n    - $\\left(\\boldsymbol{\\alpha}_i\\right)_k = a_i^k x_{i0}$。\n    - $\\left(T_i\\right)_{k,j} = b_i a_i^{k-1-j}$ 若 $j \\le k-1$，否则为 $0$。\n- **成本矩阵**：$Q_i = q_i I_N$，$R_i = r_i I_N$，$W = I_N$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。\n- **目标**：\n    1.  求 Nash 均衡控制序列 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$。\n    2.  求最小化 $J_{\\mathrm{sum}} = J_1 + J_2$ 的集中式最优控制序列 $(\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}})$。\n    3.  计算指标 $\\mathrm{RMS} = \\sqrt{\\frac{1}{2N} \\left\\| \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix} - \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix} \\right\\|_2^2 }$。\n- **测试数据**：提供了四组参数 $\\{N, a_i, b_i, q_i, r_i, \\gamma, x_{i0}\\}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n- **科学基础**：该问题牢固地植根于线性系统理论、最优控制（特别是线性二次调节器理论）和博弈论（Nash 均衡）的既定原则。该设置代表了一个标准的非合作动态博弈。\n- **适定性**：成本函数 $J_i$ 是二次的。条件 $r_i > 0$ 确保了 $J_i$ 相对于 $\\mathbf{u}_i$ 是严格凸的（在保持 $\\mathbf{u}_j$ 固定，$j \\neq i$ 的情况下）。这保证了每个智能体最佳响应的存在性和唯一性，从而保证了唯一的 Nash 均衡。类似地，总成本 $J_{\\mathrm{sum}}$ 在联合控制向量 $(\\mathbf{u}_1, \\mathbf{u}_2)$ 上是严格凸的，从而保证了唯一的集中式最优解。因此，该问题是适定的。\n- **客观性**：问题以精确的数学语言陈述，没有歧义或主观论断。所有术语都经过了形式化定义。\n- 该设置是 **完整且一致的**。解决问题所需的所有参数和定义都已提供。所提供的堆叠系统表示是从标量动态特性标准推導出来的。在问题的抽象背景下，测试用例中的参数在物理上是合理的。\n\n### 步驟 3：結論与行動\n该问题是 **有效的**。这是一个在分布式控制领域中定义明確且可解的問題。我現在将继续进行求解。\n\n## 基于原理的设计\n\n解决方案需要推导和求解两个不同的优化问题：非合作 Nash 博弈和合作（或集中式）社会最优解。两种解都是通过找到相应成本函数的驻点来获得的。\n\n### 1. 向量化成本函数\n首先，我们使用提供的堆叠表示法将总成本 $J_1$ 和 $J_2$ 表示为矩阵向量形式。求和 $\\sum_{k=0}^{N-1} y(k) z(k)$ 等价于点积 $\\mathbf{y}^\\top \\mathbf{z}$。\n智能体 1 和智能体 2 的成本函数为：\n$$\nJ_1(\\mathbf{u}_1, \\mathbf{u}_2) = \\mathbf{x}_1^\\top Q_1 \\mathbf{x}_1 + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n$$\nJ_2(\\mathbf{u}_1, \\mathbf{u}_2) = \\mathbf{x}_2^\\top Q_2 \\mathbf{x}_2 + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + \\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n代入状态-控制关系 $\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$：\n$$\nJ_1(\\mathbf{u}_1, \\mathbf{u}_2) = (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\gamma (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)\n$$\n$$\nJ_2(\\mathbf{u}_1, \\mathbf{u}_2) = (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + \\gamma (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)\n$$\n\n### 2. Nash 均衡解\nNash 均衡 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$ 是一对策略，其中每个智能体的控制输入都是对另一方输入的最佳响应，这意味着任何一方都不能通过单方面改变其策略来降低成本。这可以通过求解耦合的一阶最优性必要条件来找到：\n$$\n\\nabla_{\\mathbf{u}_1} J_1(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star) = \\mathbf{0} \\quad \\text{and} \\quad \\nabla_{\\mathbf{u}_2} J_2(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star) = \\mathbf{0}\n$$\n使用向量微积分的标准法则（例如，对于对称矩阵 $A$，有 $\\nabla_{\\mathbf{z}} (\\mathbf{b}^\\top A \\mathbf{z}) = A^\\top \\mathbf{b}$ 和 $\\nabla_{\\mathbf{z}} (\\mathbf{z}^\\top A \\mathbf{z}) = 2 A \\mathbf{z}$），我们计算梯度。\n\n对于智能体 1：\n$$\n\\nabla_{\\mathbf{u}_1} J_1 = 2 T_1^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + 2 R_1 \\mathbf{u}_1 + \\gamma T_1^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) = \\mathbf{0}\n$$\n整理各项得：\n$$\n2(T_1^\\top Q_1 T_1 + R_1)\\mathbf{u}_1 + \\gamma T_1^\\top W T_2 \\mathbf{u}_2 = -2 T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2\n$$\n\n对于智能体 2：\n$$\n\\nabla_{\\mathbf{u}_2} J_2 = 2 T_2^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + 2 R_2 \\mathbf{u}_2 + \\gamma T_2^\\top W^\\top (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) = \\mathbf{0}\n$$\n整理各项（并使用 $W=W^\\top$ 因为 $W=I_N$）：\n$$\n\\gamma T_2^\\top W T_1 \\mathbf{u}_1 + 2(T_2^\\top Q_2 T_2 + R_2)\\mathbf{u}_2 = -2 T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n$$\n\n这两个方程为串联向量 $\\mathbf{u}_{Nash} = \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix}$ 构成了一个 $2N \\times 2N$ 的分块线性系统：\n$$\n\\underbrace{\n\\begin{bmatrix}\n2(T_1^\\top Q_1 T_1 + R_1) & \\gamma T_1^\\top W T_2 \\\\\n\\gamma T_2^\\top W T_1 & 2(T_2^\\top Q_2 T_2 + R_2)\n\\end{bmatrix}\n}_{M_{Nash}}\n\\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix}\n=\n\\underbrace{\n\\begin{bmatrix}\n-2 T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2 \\\\\n-2 T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n\\end{bmatrix}\n}_{c_{Nash}}\n$$\n\n### 3. 集中式最优解\n集中式最优解 $(\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}})$ 最小化智能体的成本之和 $J_{\\mathrm{sum}} = J_1 + J_2$。这是一个标准的线性二次最优控制问题。\n$$\nJ_{\\mathrm{sum}} = \\mathbf{x}_1^\\top Q_1 \\mathbf{x}_1 + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\mathbf{x}_2^\\top Q_2 \\mathbf{x}_2 + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + 2\\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n最优解由驻点条件 $\\nabla_{\\mathbf{u}} J_{\\mathrm{sum}} = \\mathbf{0}$ 给出，其中 $\\mathbf{u} = \\begin{bmatrix} \\mathbf{u}_1 \\\\ \\mathbf{u}_2 \\end{bmatrix}$。这等价于同时求解 $\\nabla_{\\mathbf{u}_1} J_{\\mathrm{sum}} = \\mathbf{0}$ 和 $\\nabla_{\\mathbf{u}_2} J_{\\mathrm{sum}} = \\mathbf{0}$。\n\n相对于 $\\mathbf{u}_1$ 的梯度：\n$$\n\\nabla_{\\mathbf{u}_1} J_{\\mathrm{sum}} = 2 T_1^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + 2 R_1 \\mathbf{u}_1 + 2\\gamma T_1^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) = \\mathbf{0}\n$$\n除以 2 并整理得：\n$$\n(T_1^\\top Q_1 T_1 + R_1)\\mathbf{u}_1 + \\gamma T_1^\\top W T_2 \\mathbf{u}_2 = - T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2\n$$\n\n相对于 $\\mathbf{u}_2$ 的梯度：\n$$\n\\nabla_{\\mathbf{u}_2} J_{\\mathrm{sum}} = 2 T_2^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + 2 R_2 \\mathbf{u}_2 + 2\\gamma T_2^\\top W^\\top (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) = \\mathbf{0}\n$$\n除以 2 并整理得：\n$$\n\\gamma T_2^\\top W T_1 \\mathbf{u}_1 + (T_2^\\top Q_2 T_2 + R_2)\\mathbf{u}_2 = - T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n$$\n\n这得到了另一个针对 $\\mathbf{u}_{Cent} = \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix}$ 的 $2N \\times 2N$ 分块线性系统：\n$$\n\\underbrace{\n\\begin{bmatrix}\nT_1^\\top Q_1 T_1 + R_1 & \\gamma T_1^\\top W T_2 \\\\\n\\gamma T_2^\\top W T_1 & T_2^\\top Q_2 T_2 + R_2\n\\end{bmatrix}\n}_{M_{Cent}}\n\\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix}\n=\n\\underbrace{\n\\begin{bmatrix}\n-T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2 \\\\\n-T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n\\end{bmatrix}\n}_{c_{Cent}}\n$$\n\n### 4. 计算步骤\n对于每个测试用例，算法如下：\n1.  从给定参数（$a_i, b_i, x_{i0}, N$）构建模型相关的矩阵 $T_1, T_2$ 和向量 $\\boldsymbol{\\alpha}_1, \\boldsymbol{\\alpha}_2$。\n2.  构建成本相关的矩阵 $Q_1, R_1, Q_2, R_2, W$。\n3.  组合分块矩阵 $M_{Nash}$ 和向量 $c_{Nash}$。求解线性系统 $M_{Nash}\\mathbf{u}_{Nash} = c_{Nash}$ 以找到 Nash 均衡控制 $\\mathbf{u}^\\star_1, \\mathbf{u}^\\star_2$。\n4.  组合分块矩阵 $M_{Cent}$ 和向量 $c_{Cent}$。求解线性系统 $M_{Cent}\\mathbf{u}_{Cent} = c_{Cent}$ 以找到集中式最优控制 $\\mathbf{u}^{\\mathrm{c}}_1, \\mathbf{u}^{\\mathrm{c}}_2$。\n5.  使用提供的公式计算 RMS 差异。Nash 情况下的因子 2“放大”了智能体自身成本相对于耦合项的影响，导致 Nash 解偏离社会最优解。这种由 RMS 指标捕捉到的差异通常被称为“无政府代价”(price of anarchy)。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_rms(params):\n    \"\"\"\n    Constructs and solves the Nash and Centralized systems for a given set of parameters.\n    \"\"\"\n    N, a1, b1, q1, r1, a2, b2, q2, r2, gamma, x10, x20 = params\n\n    # 1. Construct model-dependent matrices and vectors\n    # Q, R, W matrices\n    Q1 = q1 * np.identity(N)\n    R1 = r1 * np.identity(N)\n    Q2 = q2 * np.identity(N)\n    R2 = r2 * np.identity(N)\n    W = np.identity(N)\n\n    # alpha vectors\n    k_vals = np.arange(N)\n    alpha1 = (a1 ** k_vals) * x10\n    alpha2 = (a2 ** k_vals) * x20\n\n    # T matrices (lower triangular)\n    T1 = np.zeros((N, N))\n    T2 = np.zeros((N, N))\n    for k in range(1, N):\n        for j in range(k):\n            T1[k, j] = b1 * (a1 ** (k - 1 - j))\n            T2[k, j] = b2 * (a2 ** (k - 1 - j))\n\n    # 2. Solve for Nash Equilibrium\n    # Construct block matrix M_Nash and vector c_Nash\n    H1 = T1.T @ Q1 @ T1 + R1\n    H2 = T2.T @ Q2 @ T2 + R2\n    \n    M_Nash_11 = 2 * H1\n    M_Nash_12 = gamma * T1.T @ W @ T2\n    M_Nash_21 = gamma * T2.T @ W @ T1\n    M_Nash_22 = 2 * H2\n    M_Nash = np.block([[M_Nash_11, M_Nash_12], [M_Nash_21, M_Nash_22]])\n\n    c_Nash_1 = -2 * T1.T @ Q1 @ alpha1 - gamma * T1.T @ W @ alpha2\n    c_Nash_2 = -2 * T2.T @ Q2 @ alpha2 - gamma * T2.T @ W @ alpha1\n    c_Nash = np.concatenate([c_Nash_1, c_Nash_2])\n\n    u_nash = np.linalg.solve(M_Nash, c_Nash)\n    \n    # 3. Solve for Centralized Optimum\n    # Construct block matrix M_Cent and vector c_Cent\n    M_Cent_11 = H1\n    M_Cent_12 = M_Nash_12 # Same off-diagonal blocks\n    M_Cent_21 = M_Nash_21\n    M_Cent_22 = H2\n    M_Cent = np.block([[M_Cent_11, M_Cent_12], [M_Cent_21, M_Cent_22]])\n    \n    c_Cent_1 = -T1.T @ Q1 @ alpha1 - gamma * T1.T @ W @ alpha2\n    c_Cent_2 = -T2.T @ Q2 @ alpha2 - gamma * T2.T @ W @ alpha1\n    c_Cent = np.concatenate([c_Cent_1, c_Cent_2])\n\n    u_cent = np.linalg.solve(M_Cent, c_Cent)\n\n    # 4. Compute RMS difference\n    # The norm squared of the difference vector\n    diff_norm_sq = np.sum((u_nash - u_cent) ** 2)\n    # The RMS value\n    rms = np.sqrt(diff_norm_sq / (2 * N))\n    \n    return rms\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, a1, b1, q1, r1, a2, b2, q2, r2, gamma, x10, x20)\n        (3, 1.0, 1.0, 1.0, 0.1, 0.9, 1.2, 1.0, 0.1, 0.5, 1.0, -1.0),\n        (4, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.2, 0.0, 0.5, 0.5),\n        (1, 1.1, 1.0, 1.0, 1.0, 0.8, 1.1, 1.0, 1.0, 0.5, 2.0, -3.0),\n        (5, 1.2, 1.0, 0.5, 0.5, 1.05, 0.8, 1.5, 0.3, 0.8, 1.0, 1.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_rms(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "将DMPC应用于安全关键型信息物理系统是其最重要的应用方向之一，其核心在于如何保证所有智能体在任何时候都保持在安全集内。本练习  介绍如何使用控制屏障函数（CBF）来形式化地定义和强制执行安全约束。您将通过在一个多智能体系统中实现一个包含对数屏障项的DMPC控制器，来实践如何主动地规划安全轨迹，从而避免智能体穿越预设的安全边界。",
            "id": "4218496",
            "problem": "一个信息物理系统由两个智能体组成，每个智能体被建模为一维离散时间线性动力学系统。每个智能体遵循离散时间积分器的基本更新方程，该方程通过以单位采样时间对连续时间速度控制律进行采样而得出：$$x_i[k+1] = x_i[k] + u_i[k],$$ 其中 $x_i[k] \\in \\mathbb{R}$ 是智能体 $i \\in \\{1,2\\}$ 在离散时间索引 $k$ 处的位置，而 $u_i[k] \\in \\mathbb{R}$ 是控制输入（速度指令）。两个智能体通过分布式模型预测控制（DMPC）进行协调，其中每个智能体 $i$ 使用另一个智能体 $j \\neq i$ 的最新预测轨迹，在长度为 $N$ 的预测时域上求解一个局部优化问题。\n\n安全性通过控制障碍函数（CBF） $h_i(x_i) = x_{b,i} - x_i$ 进行编码，该函数定义了安全集 $$\\mathcal{C}_i = \\{x_i \\in \\mathbb{R} \\mid h_i(x_i) \\ge 0\\} = \\{x_i \\in \\mathbb{R} \\mid x_i \\le x_{b,i}\\}.$$ 每个智能体必须在整个预测时域内保持在其安全集内。为强制执行安全性，在局部优化中为所有 $k$ 加入障碍约束 $h_i(x_i[k]) \\ge \\epsilon$ （其中 $\\epsilon > 0$ 是一个小的裕度，以避免退化的对数障碍项），并在目标函数中添加一个对数障碍项 $-\\mu \\sum_{k=0}^{N-1} \\log(h_i(x_i[k]))$ 以抑制接近边界。\n\n每个智能体 $i$ 都有一个局部阶段成本，该成本编码了参考跟踪、执行器正则化以及相对于另一智能体预测位置的编队保持。对于预测时域长度 $N$、参考值 $x_{\\mathrm{ref},i} \\in \\mathbb{R}$、权重 $q_i > 0$、$r_i > 0$、耦合权重 $c > 0$、期望分离距离 $s \\in \\mathbb{R}$ 和障碍参数 $\\mu > 0$，将智能体 $i$ 的局部成本定义为\n$$J_i = \\sum_{k=0}^{N-1} \\left(q_i \\left(x_i[k] - x_{\\mathrm{ref},i}\\right)^2 + r_i \\, u_i[k]^2 + c \\left(\\left(x_i[k] - x_j[k]\\right) - s\\right)^2 \\right) - \\mu \\sum_{k=0}^{N-1} \\log\\left(x_{b,i} - x_i[k]\\right),$$\n受动力学 $x_i[k+1] = x_i[k] + u_i[k]$、输入边界 $u_{\\min,i} \\le u_i[k] \\le u_{\\max,i}$ 以及对所有 $k \\in \\{0,\\dots,N-1\\}$ 的障碍约束 $x_{b,i} - x_i[k] \\ge \\epsilon$ 的限制。在分布式操作中，$x_j[k]$ 取自前一次DMPC迭代中智能体 $j$ 的最新预测轨迹，并且智能体们在固定迭代次数内交替求解其局部问题。初始的邻居预测轨迹可以是由零输入引起的静态轨迹。\n\n您的任务是实现一个DMPC控制器，该控制器针对每个提供的测试用例，使用上述带有障碍约束的公式计算两个智能体的可行控制序列，执行固定次数的交替局部优化，然后验证计算出的预测轨迹是否对所有 $k \\in \\{1,\\dots,N\\}$ 和 $i \\in \\{1,2\\}$ 满足 $h_i(x_i[k]) \\ge 0$。验证应基于最终DMPC迭代后的预测轨迹。每个测试用例的最终输出是一个布尔值，指示是否两个智能体在整个时域上的所有障碍约束 $h_i(x_i[k]) \\ge 0$ 都得到满足。\n\n不涉及角度，也不需要物理单位；该问题纯粹使用归一化单位。\n\n在一个单一、完整、可运行的程序中实现该算法，并将所有测试用例的汇总结果以逗号分隔列表的形式在一行中输出，并用方括号括起来。\n\n使用以下测试套件：\n\n- 测试用例 1（安全区域内的标称跟踪）：\n    - $N = 5$\n    - 初始状态：$x_1[0] = 0.20$, $x_2[0] = 0.10$\n    - 安全边界：$x_{b,1} = 1.00$, $x_{b,2} = 1.00$\n    - 参考值：$x_{\\mathrm{ref},1} = 0.80$, $x_{\\mathrm{ref},2} = 0.75$\n    - 权重：$q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.1$, $c = 0.5$\n    - 期望分离距离：$s = 0.10$\n    - 障碍参数：$\\mu = 10^{-3}$, $\\epsilon = 10^{-4}$\n    - 输入边界：$u_{\\min,1} = u_{\\min,2} = -0.30$, $u_{\\max,1} = u_{\\max,2} = 0.30$\n    - DMPC迭代次数：$3$\n\n- 测试用例 2（靠近边界的激进参考值，安全关键）：\n    - $N = 6$\n    - 初始状态：$x_1[0] = 0.95$, $x_2[0] = 0.92$\n    - 安全边界：$x_{b,1} = 1.00$, $x_{b,2} = 1.00$\n    - 参考值：$x_{\\mathrm{ref},1} = 1.10$, $x_{\\mathrm{ref},2} = 1.05$\n    - 权重：$q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.1$, $c = 0.5$\n    - 期望分离距离：$s = 0.05$\n    - 障碍参数：$\\mu = 5 \\times 10^{-3}$, $\\epsilon = 10^{-3}$\n    - 输入边界：$u_{\\min,1} = u_{\\min,2} = -0.20$, $u_{\\max,1} = u_{\\max,2} = 0.20$\n    - DMPC迭代次数：$4$\n\n- 测试用例 3（极靠近边界的边缘情况；必要时后退）：\n    - $N = 4$\n    - 初始状态：$x_1[0] = 0.9990$, $x_2[0] = 0.9995$\n    - 安全边界：$x_{b,1} = 1.0000$, $x_{b,2} = 1.0000$\n    - 参考值：$x_{\\mathrm{ref},1} = 1.0000$, $x_{\\mathrm{ref},2} = 1.0000$\n    - 权重：$q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.05$, $c = 0.2$\n    - 期望分离距离：$s = 0.00$\n    - 障碍参数：$\\mu = 10^{-2}$, $\\epsilon = 10^{-4}$\n    - 输入边界：$u_{\\min,1} = u_{\\min,2} = -0.05$, $u_{\\max,1} = u_{\\max,2} = 0.05$\n    - DMPC迭代次数：$5$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3]\"），每个结果都是一个布尔值，指示在相应测试用例中，两个智能体在整个时域内的所有约束 $h_i(x_i[k]) \\ge 0$ 是否都得到满足。",
            "solution": "已对用户提供的问题进行分析，并认定其有效。该问题在科学上基于控制理论的原理，特别是针对带状态约束的线性系统的分布式模型预测控制（DMPC）。该问题是适定的、自洽的，并且提供了数值求解所需的所有必要参数。任务要求实现一个迭代优化算法，为两个耦合的智能体寻找控制序列，并验证所得轨迹的安全性。\n\n### 1. 问题公式化与系统动力学\n\n系统由两个智能体 $i \\in \\{1, 2\\}$ 组成，每个智能体由一个离散时间单积分器模型描述：\n$$x_i[k+1] = x_i[k] + u_i[k]$$\n其中 $x_i[k] \\in \\mathbb{R}$ 是状态（位置），$u_i[k] \\in \\mathbb{R}$ 是在时间步 $k$ 的控制输入。目标是设计一种DMPC策略，其中每个智能体 $i$ 通过求解一个局部的、受约束的优化问题，来计算其在长度为 $N$ 的预测时域上的控制序列 $\\mathbf{u}_i = \\{u_i[0], \\dots, u_i[N-1]\\}$。\n\n### 2. 局部优化问题\n\n对于每个智能体 $i$，优化问题是在满足系统动力学和约束的条件下，最小化一个局部成本函数 $J_i$。决策变量是预测时域内的控制输入 $\\mathbf{u}_i$。状态轨迹 $\\mathbf{x}_i = \\{x_i[0], \\dots, x_i[N]\\}$ 由初始状态 $x_i[0]$ 和控制序列 $\\mathbf{u}_i$ 通过以下关系确定：\n$$x_i[k] = x_i[0] + \\sum_{m=0}^{k-1} u_i[m] \\quad \\text{对于 } k \\in \\{1, \\dots, N\\}$$\n\n智能体 $i$ 的局部成本函数 $J_i$ 如下：\n$$J_i(\\mathbf{u}_i) = \\sum_{k=0}^{N-1} \\left[ q_i (x_i[k] - x_{\\mathrm{ref},i})^2 + r_i u_i[k]^2 + c ((x_i[k] - x_j[k]) - s)^2 \\right] - \\mu \\sum_{k=0}^{N-1} \\log(x_{b,i} - x_i[k])$$\n该成本函数由四个部分组成：\n1.  **参考跟踪**：二次惩罚项 $q_i (x_i[k] - x_{\\mathrm{ref},i})^2$ 驱动智能体的状态朝其参考值 $x_{\\mathrm{ref},i}$ 移动。\n2.  **控制努力正则化**：二次惩罚项 $r_i u_i[k]^2$ 惩罚大的控制动作。\n3.  **编队保持**：二次项 $c ((x_i[k] - x_j[k]) - s)^2$ 惩罚与另一个智能体 $j$ 偏离期望分离距离 $s$ 的行为。在DMPC方案中，另一个智能体的轨迹 $\\mathbf{x}_j$ 被视为基于其最新预测的固定参数。\n4.  **对数障碍**：项 $-\\mu \\sum \\log(h_i(x_i[k]))$，其中 $h_i(x_i) = x_{b,i} - x_i$，为接近安全边界 $x_{b,i}$ 的状态创建巨大惩罚，从而有效地将轨迹保持在安全集的内部。\n\n该优化受以下约束限制，其中输入约束适用于 $k \\in \\{0, \\dots, N-1\\}$，状态约束适用于 $k \\in \\{1, \\dots, N\\}$：\n1.  **输入边界**：$u_{\\min,i} \\le u_i[k] \\le u_{\\max,i}$。这些是关于决策变量的简单箱形约束。\n2.  **状态约束**：$x_i[k] \\le x_{b,i} - \\epsilon$。这强制要求预测的状态轨迹严格保持在安全集内，并带有一个裕度 $\\epsilon > 0$。由于 $x_i[k]$ 是 $\\mathbf{u}_i$ 的线性函数，这些是关于决策变量的线性不等式约束。\n\n成本函数 $J_i$ 是二次项和负对数项的和。由于二次函数是凸的，负对数函数也是凸的，因此目标函数是凸的。约束是线性的。因此，每个局部优化问题都是一个凸规划问题，这保证了数值求解器可以高效地找到唯一的最优解。\n\n### 3. 分布式模型预测控制（DMPC）算法\n\nDMPC方案以迭代方式运行，智能体以交替（Gauss-Seidel）方式求解其局部问题。算法如下：\n\n1.  **初始化**：对于每个智能体 $i$，初始化其预测轨迹。假设采用静态轨迹，即对所有 $k$，有 $u_i[k] = 0$，从而对所有 $k \\in \\{0, \\dots, N\\}$，有 $x_i^{\\text{pred}}[k] = x_i[0]$。\n2.  **迭代优化**：对于固定次数的DMPC迭代：\n    a.  **为智能体1求解**：智能体1求解其局部优化问题，以找到其最优控制序列 $\\mathbf{u}_1^*$。此优化使用智能体2当前的预测轨迹 $\\mathbf{x}_2^{\\text{pred}}$。然后使用 $\\mathbf{u}_1^*$ 更新智能体1的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$。\n    b.  **为智能体2求解**：智能体2求解其局部优化问题，以找到其最优控制序列 $\\mathbf{u}_2^*$。此优化使用智能体1新更新的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$。然后使用 $\\mathbf{u}_2^*$ 更新智能体2的预测轨迹 $\\mathbf{x}_2^{\\text{pred}}$。\n3.  **终止**：在指定的迭代次数后，获得两个智能体的最终预测轨迹。\n\n### 4. 数值实现与安全性验证\n\n数值求解使用 Python 实现，利用 `scipy.optimize.minimize` 函数和 ‘SLSQP’（序列最小二乘规划）方法，该方法非常适合非线性约束优化问题。\n\n-   **目标函数**：定义一个 Python 函数，用于在给定控制向量 $\\mathbf{u}_i$ 的情况下计算 $J_i$。该函数首先计算对应的状态轨迹 $\\mathbf{x}_i$，然后评估成本项的总和。其中包含一个安全措施，如果对数函数的任何参数为非正数，则返回无穷大，以引导求解器避开不可行区域。\n-   **约束**：输入边界直接传递给求解器的 `bounds` 参数。状态约束 $x_i[k] \\le x_{b,i} - \\epsilon$ 被表述为 $\\mathbf{u}_i$ 的函数，并提供给 `constraints` 参数。对于每个 $k \\in \\{1, \\dots, N\\}$，创建一个约束函数 $g_k(\\mathbf{u}_i) = (x_{b,i} - x_i[k]) - \\epsilon \\ge 0$。\n-   **最终验证**：DMPC迭代完成后，根据基本安全条件 $h_i(x_i[k]) \\ge 0$（等效于 $x_i[k] \\le x_{b,i}$）检查最终的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$ 和 $\\mathbf{x}_2^{\\text{pred}}$。此检查对每个智能体 $i$ 以及预测轨迹中的所有步骤 $k \\in \\{1, \\dots, N\\}$ 执行。一个测试用例的最终输出为 `True` 当且仅当该条件对两个智能体在其整个预测轨迹上都成立。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for the DMPC problem.\n    \"\"\"\n    test_cases = [\n        { # Test Case 1\n            \"N\": 5, \"x0\": (0.20, 0.10), \"xb\": (1.00, 1.00),\n            \"xref\": (0.80, 0.75), \"q\": (1.0, 1.0), \"r\": (0.1, 0.1),\n            \"c\": 0.5, \"s\": 0.10, \"mu\": 1e-3, \"epsilon\": 1e-4,\n            \"umin\": (-0.30, -0.30), \"umax\": (0.30, 0.30),\n            \"dmpc_iterations\": 3\n        },\n        { # Test Case 2\n            \"N\": 6, \"x0\": (0.95, 0.92), \"xb\": (1.00, 1.00),\n            \"xref\": (1.10, 1.05), \"q\": (1.0, 1.0), \"r\": (0.1, 0.1),\n            \"c\": 0.5, \"s\": 0.05, \"mu\": 5e-3, \"epsilon\": 1e-3,\n            \"umin\": (-0.20, -0.20), \"umax\": (0.20, 0.20),\n            \"dmpc_iterations\": 4\n        },\n        { # Test Case 3\n            \"N\": 4, \"x0\": (0.9990, 0.9995), \"xb\": (1.0000, 1.0000),\n            \"xref\": (1.0000, 1.0000), \"q\": (1.0, 1.0), \"r\": (0.05, 0.05),\n            \"c\": 0.2, \"s\": 0.00, \"mu\": 1e-2, \"epsilon\": 1e-4,\n            \"umin\": (-0.05, -0.05), \"umax\": (0.05, 0.05),\n            \"dmpc_iterations\": 5\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        is_safe = run_dmpc_for_case(params)\n        results.append(str(is_safe).lower())\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_trajectory(x0, u_vec):\n    \"\"\"\n    Computes the state trajectory from an initial state and control sequence.\n    \"\"\"\n    N = len(u_vec)\n    x_traj = np.zeros(N + 1)\n    x_traj[0] = x0\n    for k in range(N):\n        x_traj[k+1] = x_traj[k] + u_vec[k]\n    return x_traj\n\ndef optimize_agent_trajectory(agent_idx, params, x0, neighbor_traj):\n    \"\"\"\n    Solves the local optimization problem for a single agent.\n    \"\"\"\n    N = params['N']\n    q = params['q'][agent_idx]\n    r = params['r'][agent_idx]\n    c = params['c']\n    s = params['s']\n    mu = params['mu']\n    epsilon = params['epsilon']\n    xb = params['xb'][agent_idx]\n    xref = params['xref'][agent_idx]\n    umin = params['umin'][agent_idx]\n    umax = params['umax'][agent_idx]\n\n    def objective(u_vec):\n        x_traj = compute_trajectory(x0, u_vec)\n        \n        # Barrier term check\n        h_vals = xb - x_traj[:N]\n        if np.any(h_vals = 0):\n            return np.inf\n\n        cost_tracking = q * np.sum((x_traj[:N] - xref)**2)\n        cost_actuation = r * np.sum(u_vec**2)\n        cost_coupling = c * np.sum(((x_traj[:N] - neighbor_traj[:N]) - s)**2)\n        cost_barrier = -mu * np.sum(np.log(h_vals))\n\n        return cost_tracking + cost_actuation + cost_coupling + cost_barrier\n\n    constraints = []\n    # Note: State constraints are for k=0...N-1 in cost, but k=1...N for trajectory evolution.\n    # The problem states \"for all k in {0..N-1}\" for the log barrier and \"for all k in {0..N-1}\" for the barrier constraint.\n    # We apply constraint to trajectory points x_i[k] where k includes time step 0.\n    # However, x_i[0] is fixed. So constraints apply for k=1..N-1 on state, and the log barrier is on x_i[0]...x_i[N-1].\n    # Let's check the problem again.\n    # \"barrier constraint x_b,i - x_i[k] >= epsilon\" for \"all k in {0,..,N-1}\".\n    # Let's implement this strictly. x[0] is initial state, it's a parameter, not a variable. But it's part of the trajectory.\n    # A robust implementation should check if x[0] already violates the constraint.\n    # The optimization variables are u[0]..u[N-1], affecting x[1]..x[N].\n    # So the constraints are on x[1]..x[N]. The log term is on x[0]..x[N-1].\n    # The problem says \"x_b,i - x_i[k] >= epsilon\" for k in 0..N-1. This is a bit ambiguous as x[0] is not a decision variable.\n    # Let's assume the constraints are for k=1...N, as x[0] is fixed. The log barrier applies to x[0]..x[N-1]\n    for k in range(1, N + 1):\n        def constr_func(u_vec, k_val=k):\n            # Sum of controls up to k_val-1 determines x[k_val]\n            x_k = x0 + np.sum(u_vec[:k_val])\n            return xb - x_k - epsilon\n        constraints.append({'type': 'ineq', 'fun': constr_func})\n    \n    bounds = [(umin, umax)] * N\n    u_initial_guess = np.zeros(N)\n\n    result = minimize(objective, u_initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n    return result\n\ndef run_dmpc_for_case(params):\n    \"\"\"\n    Runs the DMPC simulation for a single test case.\n    \"\"\"\n    N = params['N']\n    x1_0, x2_0 = params['x0']\n    xb1, xb2 = params['xb']\n\n    # Initial static trajectories (zero control input)\n    u1_pred = np.zeros(N)\n    u2_pred = np.zeros(N)\n    x1_pred = compute_trajectory(x1_0, u1_pred)\n    x2_pred = compute_trajectory(x2_0, u2_pred)\n    \n    # DMPC iterations\n    for _ in range(params['dmpc_iterations']):\n        # Agent 1 solves its optimization problem\n        res1 = optimize_agent_trajectory(0, params, x1_0, x2_pred)\n        if res1.success:\n            u1_pred = res1.x\n        x1_pred = compute_trajectory(x1_0, u1_pred)\n\n        # Agent 2 solves its optimization problem\n        res2 = optimize_agent_trajectory(1, params, x2_0, x1_pred)\n        if res2.success:\n            u2_pred = res2.x\n        x2_pred = compute_trajectory(x2_0, u2_pred)\n\n    # Final safety verification h_i(x_i[k]) >= 0 for k=1..N\n    # This is equivalent to x_i[k] = x_{b,i}\n    is_safe1 = np.all(x1_pred[1:] = xb1)\n    is_safe2 = np.all(x2_pred[1:] = xb2)\n    \n    return is_safe1 and is_safe2\n\nsolve()\n```"
        }
    ]
}