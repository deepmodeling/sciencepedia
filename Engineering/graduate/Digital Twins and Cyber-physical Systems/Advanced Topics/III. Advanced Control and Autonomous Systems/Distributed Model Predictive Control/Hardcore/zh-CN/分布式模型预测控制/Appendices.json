{
    "hands_on_practices": [
        {
            "introduction": "大规模的MPC问题往往难以集中求解，因此分布式算法至关重要。本练习将指导您从第一性原理出发，为典型的分布式模型预测控制（DMPC）问题推导交替方向乘子法（ADMM）的迭代格式。通过构建增广拉格朗日量并执行分块最小化，您将深入理解如何将一个复杂的全局问题分解为多个可并行处理的局部子问题。",
            "id": "4218526",
            "problem": "考虑一个网络化的信息物理系统 (CPS)，其数字孪生 (DT) 用于通过分布式模型预测控制 (MPC) 协调 $N$ 个子系统的控制。在给定的采样时刻，每个子系统 $i \\in \\{1,\\dots,N\\}$ 选择一个局部控制向量 $u^{i} \\in \\mathbb{R}^{n_{i}}$，以最小化局部二次阶段成本，同时满足一个全局耦合约束。局部成本由 $f_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top} Q_{i} u^{i} + c_{i}^{\\top} u^{i}$ 给出，其中 $Q_{i} \\in \\mathbb{R}^{n_{i} \\times n_{i}}$ 是对称正定的，$c_{i} \\in \\mathbb{R}^{n_{i}}$。全局耦合约束源于子系统间的物理资源共享，并建模为\n$$\n\\sum_{i=1}^{N} H_{i} u^{i} = h,\n$$\n其中，对每个 $i$，$H_{i} \\in \\mathbb{R}^{m \\times n_{i}}$，而 $h \\in \\mathbb{R}^{m}$ 由 DT 在当前采样时刻给出。假设每个 $H_{i}$ 都是满列秩的。\n\nDT 旨在通过求解以下凸规划问题来计算最优控制\n$$\n\\min_{\\{u^{i}\\}_{i=1}^{N}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) \\quad \\text{subject to} \\quad \\sum_{i=1}^{N} H_{i} u^{i} = h.\n$$\n为了获得一个保持局部性的分布式算法，引入一个一致性变量 $z := (z^{1},\\dots,z^{N})$（其分量为 $z^{i} \\in \\mathbb{R}^{m}$），以及局部一致性约束 $H_{i} u^{i} - z^{i} = 0$ 和全局仿射约束 $\\sum_{i=1}^{N} z^{i} = h$。将问题等价地表述为\n$$\n\\min_{\\{u^{i}\\}, \\{z^{i}\\}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) \\quad \\text{subject to} \\quad H_{i} u^{i} - z^{i} = 0 \\ \\text{for all } i,\n$$\n其中 $I_{\\mathcal{C}}(z)$ 是仿射集 $\\mathcal{C} := \\left\\{ z \\in \\mathbb{R}^{mN} : \\sum_{i=1}^{N} z^{i} = h \\right\\}$ 的指示函数，定义为：如果 $z \\in \\mathcal{C}$，则 $I_{\\mathcal{C}}(z) = 0$，否则 $I_{\\mathcal{C}}(z) = +\\infty$。\n\n从增广拉格朗日方法和交替方向乘子法 (ADMM) 的核心定义出发，为局部控制 $u^{i}$ 和一致性变量分量 $z^{i}$，以及与约束 $H_{i} u^{i} - z^{i} = 0$ 相关联的缩放对偶变量 $y^{i} \\in \\mathbb{R}^{m}$，推导带有罚参数 $\\rho  0$ 的缩放形式ADMM迭代。你的推导必须从增广拉格朗日量的构造开始，并展示每个块最小化和对偶上升步是如何从第一性原理得到的。然后，将 $u^{i}$ 的更新具体化到给定的二次成本上，并提供关于 $Q_{i}$、$c_{i}$、$H_{i}$、$h$、$\\rho$ 和先前迭代量的 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$ 的显式闭式更新方程。将你的最终答案表示为三个对应于 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$ 的解析表达式，这些表达式对所有 $i \\in \\{1,\\dots,N\\}$ 都有效。\n\n不需要进行数值计算，也不应进行任何舍入。请使用 $\\LaTeX$ 的 $\\mathrm{pmatrix}$ 环境将你的最终表达式表示为单行矩阵，其条目按 $u^{i}_{k+1}$、$z^{i}_{k+1}$ 和 $y^{i}_{k+1}$ 更新的顺序排列。",
            "solution": "该问题要求推导在数字孪生和信息物理系统背景下出现的分布式优化问题的缩放形式交替方向乘子法（ADMM）迭代。我们首先对问题进行分析。\n\n给定条件如下：\n- $N$ 个子系统，由 $i \\in \\{1, \\dots, N\\}$ 索引。\n- 局部控制向量 $u^{i} \\in \\mathbb{R}^{n_{i}}$。\n- 局部成本函数 $f_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top} Q_{i} u^{i} + c_{i}^{\\top} u^{i}$，其中 $Q_{i} \\in \\mathbb{R}^{n_{i} \\times n_{i}}$ 是对称正定的，$c_{i} \\in \\mathbb{R}^{n_{i}}$。\n- 一个全局耦合约束 $\\sum_{i=1}^{N} H_{i} u^{i} = h$，其中 $H_{i} \\in \\mathbb{R}^{m \\times n_{i}}$ 是满列秩的，$h \\in \\mathbb{R}^{m}$。\n- 等价的适用于 ADMM 的表述：\n$$ \\min_{\\{u^{i}\\}, \\{z^{i}\\}} \\ \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) \\quad \\text{subject to} \\quad H_{i} u^{i} - z^{i} = 0 \\ \\text{for all } i, $$\n其中 $z = (z^{1}, \\dots, z^{N})$ 且 $z^{i} \\in \\mathbb{R}^{m}$，$I_{\\mathcal{C}}(z)$ 是仿射集 $\\mathcal{C} := \\left\\{ z \\in \\mathbb{R}^{mN} : \\sum_{i=1}^{N} z^{i} = h \\right\\}$ 的指示函数。\n- ADMM 的罚参数为 $\\rho  0$。\n- 缩放对偶变量为 $y^{i} \\in \\mathbb{R}^{m}$。\n\n该问题具有科学依据，是适定、客观、完整且数学上严谨的。它是凸优化技术在分布式控制中的一个标准应用，而分布式控制是指定领域的核心课题。因此，该问题是有效的，我们继续进行推导。\n\nADMM 算法应用于形如 $\\min_{x,w} F(x) + G(w)$ 且满足 $Ax + Bw = c$ 的问题。在我们的案例中，优化变量是局部控制 $u = (u^{1}, \\dots, u^{N})$ 和一致性变量 $z = (z^{1}, \\dots, z^{N})$ 的集合。目标函数是可分离的：$F(u) = \\sum_{i=1}^{N} f_{i}(u^{i})$ 和 $G(z) = I_{\\mathcal{C}}(z)$。约束条件为对所有 $i \\in \\{1, \\dots, N\\}$ 都有 $H_{i}u^{i} - z^{i} = 0$。\n\n为该问题构造缩放形式的增广拉格朗日量 $\\mathcal{L}_{\\rho}$。令 $y = (y^{1}, \\dots, y^{N})$ 为缩放对偶变量的堆叠向量。\n$$ \\mathcal{L}_{\\rho}(u, z, y) = \\sum_{i=1}^{N} f_{i}(u^{i}) + I_{\\mathcal{C}}(z) + \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| H_{i}u^{i} - z^{i} + y^{i} \\|_{2}^{2} - \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| y^{i} \\|_{2}^{2} $$\n包含 $\\|y^{i}\\|_{2}^{2}$ 的常数项在最小化过程中可以省略。ADMM 算法在每次迭代 $k$ 中通过迭代三个步骤进行：关于 $u$ 的最小化，关于 $z$ 的最小化，以及对偶变量更新。\n\n步骤1：$u$的更新\n在迭代 $k+1$ 时，我们通过将 $z$ 和 $y$ 固定在它们在迭代 $k$ 时的值来最小化 $\\mathcal{L}_{\\rho}$，从而更新原始变量 $u$：\n$$ u_{k+1} = \\arg\\min_{u} \\mathcal{L}_{\\rho}(u, z_{k}, y_{k}) $$\n由于目标函数和约束的可分离结构，这个最小化问题可以分解为 $N$ 个独立的子问题，每个子系统 $i$ 对应一个：\n$$ u^{i}_{k+1} = \\arg\\min_{u^{i}} \\left( f_{i}(u^{i}) + \\frac{\\rho}{2} \\| H_{i}u^{i} - z^{i}_{k} + y^{i}_{k} \\|_{2}^{2} \\right) $$\n代入 $f_{i}(u^{i})$ 的二次形式，该子问题的目标函数为：\n$$ J_{i}(u^{i}) = \\frac{1}{2}(u^{i})^{\\top}Q_{i}u^{i} + c_{i}^{\\top}u^{i} + \\frac{\\rho}{2} (H_{i}u^{i} - z^{i}_{k} + y^{i}_{k})^{\\top}(H_{i}u^{i} - z^{i}_{k} + y^{i}_{k}) $$\n该函数在 $u^{i}$ 上是严格凸的，因为 $Q_{i}$ 是正定的且 $\\rho  0$。通过将关于 $u^{i}$ 的梯度设为零，可以找到唯一的最小化子：\n$$ \\nabla_{u^{i}} J_{i}(u^{i}) = Q_{i}u^{i} + c_{i} + \\rho H_{i}^{\\top}(H_{i}u^{i} - z^{i}_{k} + y^{i}_{k}) = 0 $$\n整理各项以求解 $u^{i}$：\n$$ (Q_{i} + \\rho H_{i}^{\\top}H_{i}) u^{i} = \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} $$\n矩阵 $(Q_{i} + \\rho H_{i}^{\\top}H_{i})$ 是可逆的，因为 $Q_{i}$ 是正定的，而 $H_{i}^{\\top}H_{i}$ 是半正定的。因此，我们得到 $u^{i}_{k+1}$ 的闭式更新：\n$$ u^{i}_{k+1} = (Q_{i} + \\rho H_{i}^{\\top}H_{i})^{-1} \\left( \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} \\right) $$\n\n步骤2：$z$的更新\n接下来，我们通过将 $u$ 固定为 $u_{k+1}$ 和 $y$ 固定为 $y_{k}$ 来最小化 $\\mathcal{L}_{\\rho}$，从而更新一致性变量 $z$：\n$$ z_{k+1} = \\arg\\min_{z} \\mathcal{L}_{\\rho}(u_{k+1}, z, y_{k}) $$\n这个最小化问题等价于求解：\n$$ \\min_{z} \\left( I_{\\mathcal{C}}(z) + \\sum_{i=1}^{N} \\frac{\\rho}{2} \\| H_{i}u^{i}_{k+1} - z^{i} + y^{i}_{k} \\|_{2}^{2} \\right) $$\n指示函数 $I_{\\mathcal{C}}(z)$ 强制执行约束 $\\sum_{i=1}^{N} z^{i} = h$。该问题可以重写为到仿射集 $\\mathcal{C}$ 上的投影：\n$$ \\min_{\\{z^{i}\\}} \\sum_{i=1}^{N} \\| z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k}) \\|_{2}^{2} \\quad \\text{subject to} \\quad \\sum_{i=1}^{N} z^{i} = h $$\n我们为该子问题构造带乘子 $\\nu \\in \\mathbb{R}^{m}$ 的拉格朗日量：\n$$ \\mathcal{L}_{z}(\\{z^{i}\\}, \\nu) = \\sum_{i=1}^{N} \\| z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k}) \\|_{2}^{2} + 2\\nu^{\\top}\\left(\\sum_{i=1}^{N} z^{i} - h\\right) $$\n对每个 $z^{i}$ 求梯度并将其设为零，得到：\n$$ 2(z^{i} - (H_{i}u^{i}_{k+1} + y^{i}_{k})) + 2\\nu = 0 \\implies z^{i} = (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\nu $$\n为了求得 $\\nu$，我们强制执行约束 $\\sum_{i=1}^{N} z^{i} = h$：\n$$ \\sum_{i=1}^{N} \\left( (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\nu \\right) = h \\implies \\sum_{i=1}^{N} (H_{i}u^{i}_{k+1} + y^{i}_{k}) - N\\nu = h $$\n求解 $\\nu$：\n$$ \\nu = \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right) $$\n将这个 $\\nu$ 的表达式代回 $z^{i}$ 的方程，得到 $z^{i}_{k+1}$ 的更新式：\n$$ z^{i}_{k+1} = (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right) $$\n\n步骤3：$y$的更新\n最后，使用对偶上升步更新缩放对偶变量。对于每个约束 $H_{i}u^{i} - z^{i} = 0$，更新规则是：\n$$ y^{i}_{k+1} = y^{i}_{k} + (H_{i}u^{i}_{k+1} - z^{i}_{k+1}) $$\n这表示基于迭代 $k+1$ 时局部一致性约束的残差来更新缩放对偶变量。\n\n这三个方程构成了给定分布式优化问题的完整ADMM迭代集合。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n(Q_{i} + \\rho H_{i}^{\\top}H_{i})^{-1} \\left( \\rho H_{i}^{\\top}(z^{i}_{k} - y^{i}_{k}) - c_{i} \\right)  (H_{i}u^{i}_{k+1} + y^{i}_{k}) - \\frac{1}{N} \\left( \\sum_{j=1}^{N} (H_{j}u^{j}_{k+1} + y^{j}_{k}) - h \\right)  y^{i}_{k} + H_{i}u^{i}_{k+1} - z^{i}_{k+1}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "分布式控制的一个核心问题是：当各个智能体仅优化自身利益时，系统整体性能会受到多大影响？这个问题引出了“无政府代价”（Price of Anarchy）的概念，即非合作博弈的效率损失。在本练习中，您将通过计算和比较纳什均衡解与集中式最优解，来量化这种性能差异，从而深刻理解可扩展性与全局最优性之间的权衡。",
            "id": "4218474",
            "problem": "考虑一个信息物理系统 (Cyber-Physical System, CPS) 中的两个智能体，其数字孪生 (Digital Twin, DT) 在有限时域上采用分布式模型预测控制 (Distributed Model Predictive Control, DMPC)。每个智能体都有一个单输入、单状态的离散时间线性模型，并且它们的成本通过状态交叉耦合。目标是计算开环纳什均衡控制序列，并将其与最小化智能体成本之和的中心化最优解进行比较。\n\n假设对于智能体 $i \\in \\{1,2\\}$：\n- 动态方程由 $x_i(k+1) = a_i x_i(k) + b_i u_i(k)$ 给出，其中 $k \\in \\{0,1,\\dots,N-1\\}$。\n- 初始条件为 $x_i(0) = x_{i0}$。\n- 智能体 $i$ 在时刻 $k$ 的阶段成本为 $q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)$，其中 $q_i \\ge 0$，$r_i  0$ 且 $\\gamma \\in \\mathbb{R}$。\n- 智能体在整个时域内的总成本为 $J_i = \\sum_{k=0}^{N-1} \\left(q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)\\right)$。\n\n我们将通过标准的线性系统堆叠方法，用每个智能体的控制序列来表示其在时域内的状态轨迹。为智能体 $i$ 定义：\n- 堆叠状态向量 $\\mathbf{x}_i = \\begin{bmatrix}x_i(0)  x_i(1)  \\dots  x_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- 堆叠控制向量 $\\mathbf{u}_i = \\begin{bmatrix}u_i(0)  u_i(1)  \\dots  u_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- 堆叠仿射关系 $\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$，其中 $\\boldsymbol{\\alpha}_i \\in \\mathbb{R}^N$ 和 $T_i \\in \\mathbb{R}^{N \\times N}$ 由动态方程确定。具体来说，对于 $k \\in \\{0,1,\\dots,N-1\\}$ 和 $j \\in \\{0,1,\\dots,N-1\\}$，\n$$\n\\left(\\boldsymbol{\\alpha}_i\\right)_k = a_i^k x_{i0}, \\quad\n\\left(T_i\\right)_{k,j} =\n\\begin{cases}\nb_i a_i^{k-1-j},  \\text{if } j \\le k-1,\\\\\n0,  \\text{if } j \\ge k.\n\\end{cases}\n$$\n\n令 $Q_i = q_i I_N$，$R_i = r_i I_N$ 且 $W = I_N$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。纳什均衡定义为一对控制序列 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$，在此均衡下，每个智能体在给定对方决策的情况下最小化其自身成本 $J_i$，这等价于 $J_i$ 相对于 $\\mathbf{u}_i$ 的梯度为稳态点。中心化最优解定义为成本之和 $J_{\\mathrm{sum}} = J_1 + J_2$ 相对于 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 的最小化器。\n\n你的任务是：\n- 使用上述定义，从第一性原理出发，为纳什均衡和中心化最优解构建分块线性系统。\n- 求解这些系统，以获得纳什均衡的解 $\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star$ 和中心化最优解 $\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}}$。\n- 为每个测试用例计算比较指标，该指标定义为纳什均衡控制序列与中心化最优控制序列在所有智能体和所有时间步上的均方根 (RMS) 差异：\n$$\n\\mathrm{RMS} = \\sqrt{\\frac{1}{2N} \\left\\| \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix} - \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix} \\right\\|_2^2 }.\n$$\n\n使用以下参数集测试套件，涵盖典型、边界和边缘情况。对每种情况，计算 RMS 差异。无物理单位适用。\n\n- 测试用例 1：$N = 3$，$a_1 = 1.0$，$b_1 = 1.0$，$q_1 = 1.0$，$r_1 = 0.1$，$a_2 = 0.9$，$b_2 = 1.2$，$q_2 = 1.0$，$r_2 = 0.1$，$\\gamma = 0.5$，$x_{10} = 1.0$，$x_{20} = -1.0$。\n- 测试用例 2：$N = 4$，$a_1 = 1.0$，$b_1 = 1.0$，$q_1 = 1.0$，$r_1 = 0.2$，$a_2 = 1.0$，$b_2 = 1.0$，$q_2 = 1.0$，$r_2 = 0.2$，$\\gamma = 0.0$，$x_{10} = 0.5$，$x_{20} = 0.5$。\n- 测试用例 3：$N = 1$，$a_1 = 1.1$，$b_1 = 1.0$，$q_1 = 1.0$，$r_1 = 1.0$，$a_2 = 0.8$，$b_2 = 1.1$，$q_2 = 1.0$，$r_2 = 1.0$，$\\gamma = 0.5$，$x_{10} = 2.0$，$x_{20} = -3.0$。\n- 测试用例 4：$N = 5$，$a_1 = 1.2$，$b_1 = 1.0$，$q_1 = 0.5$，$r_1 = 0.5$，$a_2 = 1.05$，$b_2 = 0.8$，$q_2 = 1.5$，$r_2 = 0.3$，$\\gamma = 0.8$，$x_{10} = 1.0$，$x_{20} = 1.5$。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4]$），其中每个条目是相应测试用例的 RMS 差异。",
            "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n- **系统动态**：对于智能体 $i \\in \\{1,2\\}$，离散时间动态为 $x_i(k+1) = a_i x_i(k) + b_i u_i(k)$，时域为 $k \\in \\{0, 1, \\dots, N-1\\}$。\n- **初始条件**：$x_i(0) = x_{i0}$。\n- **阶段成本**：对于智能体 $i$，在时刻 $k$ 的成本为 $q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)$，其中 $q_i \\ge 0$，$r_i  0$，$\\gamma \\in \\mathbb{R}$。\n- **总成本**：$J_i = \\sum_{k=0}^{N-1} \\left(q_i x_i(k)^2 + r_i u_i(k)^2 + \\gamma x_1(k) x_2(k)\\right)$。\n- **堆叠向量**：\n    - 状态：$\\mathbf{x}_i = \\begin{bmatrix}x_i(0)  x_i(1)  \\dots  x_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n    - 控制：$\\mathbf{u}_i = \\begin{bmatrix}u_i(0)  u_i(1)  \\dots  u_i(N-1)\\end{bmatrix}^\\top \\in \\mathbb{R}^N$。\n- **堆叠仿射关系**：$\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$，其分量定义为：\n    - $\\left(\\boldsymbol{\\alpha}_i\\right)_k = a_i^k x_{i0}$。\n    - $\\left(T_i\\right)_{k,j} = b_i a_i^{k-1-j}$ 若 $j \\le k-1$，否则为 $0$。\n- **成本矩阵**：$Q_i = q_i I_N$，$R_i = r_i I_N$ 且 $W = I_N$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。\n- **目标**：\n    1.  求纳什均衡控制序列 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$。\n    2.  求最小化 $J_{\\mathrm{sum}} = J_1 + J_2$ 的中心化最优控制序列 $(\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}})$。\n    3.  计算指标 $\\mathrm{RMS} = \\sqrt{\\frac{1}{2N} \\left\\| \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix} - \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix} \\right\\|_2^2 }$。\n- **测试数据**：提供了四组参数 $\\{N, a_i, b_i, q_i, r_i, \\gamma, x_{i0}\\}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n- **科学依据**：该问题牢固地植根于线性系统理论、最优控制（特别是线性二次调节器理论）和博弈论（纳什均衡）的既定原则。该设置代表了一个标准的非合作动态博弈。\n- **适定性**：成本函数 $J_i$ 是二次的。条件 $r_i  0$ 确保了 $J_i$ 相对于 $\\mathbf{u}_i$（在固定 $\\mathbf{u}_j$, $j \\neq i$ 的情况下）是严格凸的。这保证了每个智能体最佳响应的存在性和唯一性，从而保证了唯一的纳什均衡。类似地，总成本 $J_{\\mathrm{sum}}$ 在联合控制向量 $(\\mathbf{u}_1, \\mathbf{u}_2)$ 上是严格凸的，保证了唯一的中心化最优解。因此，该问题是适定的。\n- **客观性**：问题以精确的数学语言陈述，没有歧义或主观论断。所有术语都有正式定义。\n- 该设置是**完整且一致的**。为解决问题提供了所有必需的参数和定义。所提供的堆叠系统表示是从标量动态方程的标准推导。在问题的抽象背景下，测试用例中的参数是物理上合理的。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。它是一个定义明确且可解的分布式控制问题。我现在将着手进行求解。\n\n## 基于原理的设计\n\n解决方案需要推导和求解两个不同的优化问题：非合作的纳什博弈和合作的（或中心化的）社会最优解。两种解决方案都是通过找到相应成本函数的稳态点来获得的。\n\n### 1. 向量化成本函数\n首先，我们使用提供的堆叠表示法将总成本 $J_1$ 和 $J_2$ 表示为矩阵-向量形式。求和 $\\sum_{k=0}^{N-1} y(k) z(k)$ 等价于点积 $\\mathbf{y}^\\top \\mathbf{z}$。\n智能体 1 和智能体 2 的成本函数为：\n$$\nJ_1(\\mathbf{u}_1, \\mathbf{u}_2) = \\mathbf{x}_1^\\top Q_1 \\mathbf{x}_1 + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n$$\nJ_2(\\mathbf{u}_1, \\mathbf{u}_2) = \\mathbf{x}_2^\\top Q_2 \\mathbf{x}_2 + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + \\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n代入状态-控制关系 $\\mathbf{x}_i = \\boldsymbol{\\alpha}_i + T_i \\mathbf{u}_i$：\n$$\nJ_1(\\mathbf{u}_1, \\mathbf{u}_2) = (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\gamma (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)\n$$\n$$\nJ_2(\\mathbf{u}_1, \\mathbf{u}_2) = (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + \\gamma (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1)^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2)\n$$\n\n### 2. 纳什均衡解\n纳什均衡 $(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star)$是一对策略，其中每个智能体的控制输入都是对另一个智能体策略的最佳响应，意味着任何一方都不能通过单方面改变其策略来降低成本。这可以通过求解耦合的一阶最优性必要条件来找到：\n$$\n\\nabla_{\\mathbf{u}_1} J_1(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star) = \\mathbf{0} \\quad \\text{and} \\quad \\nabla_{\\mathbf{u}_2} J_2(\\mathbf{u}_1^\\star, \\mathbf{u}_2^\\star) = \\mathbf{0}\n$$\n使用向量微积分的标准法则（例如，对于对称矩阵 $A$，有 $\\nabla_{\\mathbf{z}} (\\mathbf{b}^\\top A \\mathbf{z}) = A^\\top \\mathbf{b}$ 和 $\\nabla_{\\mathbf{z}} (\\mathbf{z}^\\top A \\mathbf{z}) = 2 A \\mathbf{z}$），我们计算梯度。\n\n对于智能体 1：\n$$\n\\nabla_{\\mathbf{u}_1} J_1 = 2 T_1^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + 2 R_1 \\mathbf{u}_1 + \\gamma T_1^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) = \\mathbf{0}\n$$\n整理各项得：\n$$\n2(T_1^\\top Q_1 T_1 + R_1)\\mathbf{u}_1 + \\gamma T_1^\\top W T_2 \\mathbf{u}_2 = -2 T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2\n$$\n\n对于智能体 2：\n$$\n\\nabla_{\\mathbf{u}_2} J_2 = 2 T_2^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + 2 R_2 \\mathbf{u}_2 + \\gamma T_2^\\top W^\\top (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) = \\mathbf{0}\n$$\n整理各项（并使用 $W=W^\\top$ 因为 $W=I_N$）：\n$$\n\\gamma T_2^\\top W T_1 \\mathbf{u}_1 + 2(T_2^\\top Q_2 T_2 + R_2)\\mathbf{u}_2 = -2 T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n$$\n\n这两个方程为级联向量 $\\mathbf{u}_{Nash} = \\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix}$ 构成了一个 $2N \\times 2N$ 的分块线性系统：\n$$\n\\underbrace{\n\\begin{bmatrix}\n2(T_1^\\top Q_1 T_1 + R_1)  \\gamma T_1^\\top W T_2 \\\\\n\\gamma T_2^\\top W T_1  2(T_2^\\top Q_2 T_2 + R_2)\n\\end{bmatrix}\n}_{M_{Nash}}\n\\begin{bmatrix} \\mathbf{u}_1^\\star \\\\ \\mathbf{u}_2^\\star \\end{bmatrix}\n=\n\\underbrace{\n\\begin{bmatrix}\n-2 T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2 \\\\\n-2 T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n\\end{bmatrix}\n}_{c_{Nash}}\n$$\n\n### 3. 中心化最优解\n中心化最优解 $(\\mathbf{u}_1^{\\mathrm{c}}, \\mathbf{u}_2^{\\mathrm{c}})$ 最小化了智能体成本之和 $J_{\\mathrm{sum}} = J_1 + J_2$。这是一个标准的线性二次最优控制问题。\n$$\nJ_{\\mathrm{sum}} = \\mathbf{x}_1^\\top Q_1 \\mathbf{x}_1 + \\mathbf{u}_1^\\top R_1 \\mathbf{u}_1 + \\mathbf{x}_2^\\top Q_2 \\mathbf{x}_2 + \\mathbf{u}_2^\\top R_2 \\mathbf{u}_2 + 2\\gamma \\mathbf{x}_1^\\top W \\mathbf{x}_2\n$$\n最优解由稳态条件 $\\nabla_{\\mathbf{u}} J_{\\mathrm{sum}} = \\mathbf{0}$ 给出，其中 $\\mathbf{u} = \\begin{bmatrix} \\mathbf{u}_1 \\\\ \\mathbf{u}_2 \\end{bmatrix}$。这等价于同时求解 $\\nabla_{\\mathbf{u}_1} J_{\\mathrm{sum}} = \\mathbf{0}$ 和 $\\nabla_{\\mathbf{u}_2} J_{\\mathrm{sum}} = \\mathbf{0}$。\n\n关于 $\\mathbf{u}_1$ 的梯度：\n$$\n\\nabla_{\\mathbf{u}_1} J_{\\mathrm{sum}} = 2 T_1^\\top Q_1 (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) + 2 R_1 \\mathbf{u}_1 + 2\\gamma T_1^\\top W (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) = \\mathbf{0}\n$$\n除以 2 并整理得：\n$$\n(T_1^\\top Q_1 T_1 + R_1)\\mathbf{u}_1 + \\gamma T_1^\\top W T_2 \\mathbf{u}_2 = - T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2\n$$\n\n关于 $\\mathbf{u}_2$ 的梯度：\n$$\n\\nabla_{\\mathbf{u}_2} J_{\\mathrm{sum}} = 2 T_2^\\top Q_2 (\\boldsymbol{\\alpha}_2 + T_2 \\mathbf{u}_2) + 2 R_2 \\mathbf{u}_2 + 2\\gamma T_2^\\top W^\\top (\\boldsymbol{\\alpha}_1 + T_1 \\mathbf{u}_1) = \\mathbf{0}\n$$\n除以 2 并整理得：\n$$\n\\gamma T_2^\\top W T_1 \\mathbf{u}_1 + (T_2^\\top Q_2 T_2 + R_2)\\mathbf{u}_2 = - T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n$$\n\n这得到了另一个关于 $\\mathbf{u}_{Cent} = \\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix}$ 的 $2N \\times 2N$ 分块线性系统：\n$$\n\\underbrace{\n\\begin{bmatrix}\nT_1^\\top Q_1 T_1 + R_1  \\gamma T_1^\\top W T_2 \\\\\n\\gamma T_2^\\top W T_1  T_2^\\top Q_2 T_2 + R_2\n\\end{bmatrix}\n}_{M_{Cent}}\n\\begin{bmatrix} \\mathbf{u}_1^{\\mathrm{c}} \\\\ \\mathbf{u}_2^{\\mathrm{c}} \\end{bmatrix}\n=\n\\underbrace{\n\\begin{bmatrix}\n-T_1^\\top Q_1 \\boldsymbol{\\alpha}_1 - \\gamma T_1^\\top W \\boldsymbol{\\alpha}_2 \\\\\n-T_2^\\top Q_2 \\boldsymbol{\\alpha}_2 - \\gamma T_2^\\top W \\boldsymbol{\\alpha}_1\n\\end{bmatrix}\n}_{c_{Cent}}\n$$\n\n### 4. 计算流程\n对于每个测试用例，算法如下：\n1.  根据给定参数（$a_i, b_i, x_{i0}, N$）构建与模型相关的矩阵 $T_1, T_2$ 和向量 $\\boldsymbol{\\alpha}_1, \\boldsymbol{\\alpha}_2$。\n2.  构建与成本相关的矩阵 $Q_1, R_1, Q_2, R_2, W$。\n3.  组装分块矩阵 $M_{Nash}$ 和向量 $c_{Nash}$。求解线性系统 $M_{Nash}\\mathbf{u}_{Nash} = c_{Nash}$ 以找到纳什均衡控制 $\\mathbf{u}^\\star_1, \\mathbf{u}^\\star_2$。\n4.  组装分块矩阵 $M_{Cent}$ 和向量 $c_{Cent}$。求解线性系统 $M_{Cent}\\mathbf{u}_{Cent} = c_{Cent}$ 以找到中心化最优控制 $\\mathbf{u}^{\\mathrm{c}}_1, \\mathbf{u}^{\\mathrm{c}}_2$。\n5.  使用提供的公式计算 RMS 差异。在纳什情况下，对角块中的因子 2 “夸大”了智能体自身成本相对于耦合项的影响，从而使纳什解偏离社会最优解。这种差异由 RMS 指标捕获，通常被称为“无政府代价”(price of anarchy)。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_rms(params):\n    \"\"\"\n    Constructs and solves the Nash and Centralized systems for a given set of parameters.\n    \"\"\"\n    N, a1, b1, q1, r1, a2, b2, q2, r2, gamma, x10, x20 = params\n\n    # 1. Construct model-dependent matrices and vectors\n    # Q, R, W matrices\n    Q1 = q1 * np.identity(N)\n    R1 = r1 * np.identity(N)\n    Q2 = q2 * np.identity(N)\n    R2 = r2 * np.identity(N)\n    W = np.identity(N)\n\n    # alpha vectors\n    k_vals = np.arange(N)\n    alpha1 = (a1 ** k_vals) * x10\n    alpha2 = (a2 ** k_vals) * x20\n\n    # T matrices (lower triangular)\n    T1 = np.zeros((N, N))\n    T2 = np.zeros((N, N))\n    for k in range(1, N):\n        for j in range(k):\n            T1[k, j] = b1 * (a1 ** (k - 1 - j))\n            T2[k, j] = b2 * (a2 ** (k - 1 - j))\n\n    # 2. Solve for Nash Equilibrium\n    # Construct block matrix M_Nash and vector c_Nash\n    H1 = T1.T @ Q1 @ T1 + R1\n    H2 = T2.T @ Q2 @ T2 + R2\n    \n    M_Nash_11 = 2 * H1\n    M_Nash_12 = gamma * T1.T @ W @ T2\n    M_Nash_21 = gamma * T2.T @ W @ T1\n    M_Nash_22 = 2 * H2\n    M_Nash = np.block([[M_Nash_11, M_Nash_12], [M_Nash_21, M_Nash_22]])\n\n    c_Nash_1 = -2 * T1.T @ Q1 @ alpha1 - gamma * T1.T @ W @ alpha2\n    c_Nash_2 = -2 * T2.T @ Q2 @ alpha2 - gamma * T2.T @ W @ alpha1\n    c_Nash = np.concatenate([c_Nash_1, c_Nash_2])\n\n    u_nash = np.linalg.solve(M_Nash, c_Nash)\n    \n    # 3. Solve for Centralized Optimum\n    # Construct block matrix M_Cent and vector c_Cent\n    M_Cent_11 = H1\n    M_Cent_12 = M_Nash_12 # Same off-diagonal blocks\n    M_Cent_21 = M_Nash_21\n    M_Cent_22 = H2\n    M_Cent = np.block([[M_Cent_11, M_Cent_12], [M_Cent_21, M_Cent_22]])\n    \n    c_Cent_1 = -T1.T @ Q1 @ alpha1 - gamma * T1.T @ W @ alpha2\n    c_Cent_2 = -T2.T @ Q2 @ alpha2 - gamma * T2.T @ W @ alpha1\n    c_Cent = np.concatenate([c_Cent_1, c_Cent_2])\n\n    u_cent = np.linalg.solve(M_Cent, c_Cent)\n\n    # 4. Compute RMS difference\n    # The norm squared of the difference vector\n    diff_norm_sq = np.sum((u_nash - u_cent) ** 2)\n    # The RMS value\n    rms = np.sqrt(diff_norm_sq / (2 * N))\n    \n    return rms\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, a1, b1, q1, r1, a2, b2, q2, r2, gamma, x10, x20)\n        (3, 1.0, 1.0, 1.0, 0.1, 0.9, 1.2, 1.0, 0.1, 0.5, 1.0, -1.0),\n        (4, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.2, 0.0, 0.5, 0.5),\n        (1, 1.1, 1.0, 1.0, 1.0, 0.8, 1.1, 1.0, 1.0, 0.5, 2.0, -3.0),\n        (5, 1.2, 1.0, 0.5, 0.5, 1.05, 0.8, 1.5, 0.3, 0.8, 1.0, 1.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_rms(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在许多网络物理系统中，例如自动驾驶车队或机器人协作，确保系统始终处于安全状态是首要任务。本练习介绍了一种强大的技术，即使用控制屏障函数（Control Barrier Functions, CBFs）在分布式模型预测控制中强制执行安全性。您将通过在成本函数中引入对数屏障项来设计一个控制器，使其能够前瞻性地规划安全轨迹，有效防止智能体穿越预定义的安全边界。",
            "id": "4218496",
            "problem": "一个信息物理系统由两个智能体组成，每个智能体被建模为一个一维离散时间线性动力系统。每个智能体遵循离散时间积分器的基本更新方程，该方程通过对单位采样时间的连续时间速度控制律进行采样得出：$$x_i[k+1] = x_i[k] + u_i[k],$$ 其中 $x_i[k] \\in \\mathbb{R}$ 是智能体 $i \\in \\{1,2\\}$ 在离散时间索引 $k$ 处的位置，而 $u_i[k] \\in \\mathbb{R}$ 是控制输入（速度指令）。这两个智能体通过分布式模型预测控制（DMPC）进行协调，其中每个智能体 $i$ 使用另一个智能体 $j \\neq i$ 的最新预测轨迹，在长度为 $N$ 的时域上求解一个局部优化问题。\n\n安全性由一个控制屏障函数 (CBF) $h_i(x_i) = x_{b,i} - x_i$ 来编码，该函数定义了安全集 $$\\mathcal{C}_i = \\{x_i \\in \\mathbb{R} \\mid h_i(x_i) \\ge 0\\} = \\{x_i \\in \\mathbb{R} \\mid x_i \\le x_{b,i}\\}$$。每个智能体必须在整个预测时域内保持在其安全集内。为强制执行安全性，在局部优化中加入屏障约束 $h_i(x_i[k]) \\ge \\epsilon$（其中 $\\epsilon  0$ 是一个小的裕度，以避免退化的对数屏障项），并在目标函数中增加一个对数屏障项 $-\\mu \\sum_{k=0}^{N-1} \\log(h_i(x_i[k]))$，以抑制接近边界的行为。\n\n每个智能体 $i$ 都有一个局部阶段成本，该成本编码了参考跟踪、执行器正则化以及相对于另一个智能体预测位置的编队保持。对于时域长度 $N$、参考值 $x_{\\mathrm{ref},i} \\in \\mathbb{R}$、权重 $q_i  0$、$r_i  0$、耦合权重 $c  0$、期望间距 $s \\in \\mathbb{R}$ 以及屏障参数 $\\mu  0$，为智能体 $i$ 定义局部成本如下：\n$$J_i = \\sum_{k=0}^{N-1} \\left(q_i \\left(x_i[k] - x_{\\mathrm{ref},i}\\right)^2 + r_i \\, u_i[k]^2 + c \\left(\\left(x_i[k] - x_j[k]\\right) - s\\right)^2 \\right) - \\mu \\sum_{k=0}^{N-1} \\log\\left(x_{b,i} - x_i[k]\\right),$$\n该成本受制于动力学方程 $x_i[k+1] = x_i[k] + u_i[k]$、输入边界 $u_{\\min,i} \\le u_i[k] \\le u_{\\max,i}$ 以及屏障约束 $x_{b,i} - x_i[k] \\ge \\epsilon$（对于所有 $k \\in \\{0,\\dots,N-1\\}$）。在分布式操作中，$x_j[k]$ 被视为来自前一次 DMPC 迭代的智能体 $j$ 的最新预测轨迹，并且智能体们以交替方式求解其局部问题，迭代固定的次数。初始的邻居预测轨迹可以是零输入引起的静态轨迹。\n\n您的任务是实现一个 DMPC 控制器，该控制器针对每个提供的测试用例，使用上述带有屏障约束的公式计算两个智能体的可行控制序列，执行固定次数的交替局部优化，然后验证计算出的预测轨迹是否满足 $h_i(x_i[k]) \\ge 0$（对于所有 $k \\in \\{1,\\dots,N\\}$ 和 $i \\in \\{1,2\\}$）。验证应基于最终 DMPC 迭代后的预测轨迹。每个测试用例的最终输出是一个布尔值，表示对于两个智能体，所有屏障约束 $h_i(x_i[k]) \\ge 0$ 是否在整个时域内都得到满足。\n\n问题不涉及角度，也无需物理单位；问题纯粹使用归一化单位。\n\n请在一个完整的、可运行的程序中实现该算法，并将所有测试用例的聚合结果在一行上以方括号括起来的逗号分隔列表形式输出。\n\n使用以下测试套件：\n\n- 测试用例 1 (安全区域内的标称跟踪):\n    - $N = 5$\n    - 初始状态: $x_1[0] = 0.20$, $x_2[0] = 0.10$\n    - 安全边界: $x_{b,1} = 1.00$, $x_{b,2} = 1.00$\n    - 参考值: $x_{\\mathrm{ref},1} = 0.80$, $x_{\\mathrm{ref},2} = 0.75$\n    - 权重: $q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.1$, $c = 0.5$\n    - 期望间距: $s = 0.10$\n    - 屏障参数: $\\mu = 10^{-3}$, $\\epsilon = 10^{-4}$\n    - 输入边界: $u_{\\min,1} = u_{\\min,2} = -0.30$, $u_{\\max,1} = u_{\\max,2} = 0.30$\n    - DMPC 迭代次数: $3$\n\n- 测试用例 2 (接近边界的激进参考值，安全关键):\n    - $N = 6$\n    - 初始状态: $x_1[0] = 0.95$, $x_2[0] = 0.92$\n    - 安全边界: $x_{b,1} = 1.00$, $x_{b,2} = 1.00$\n    - 参考值: $x_{\\mathrm{ref},1} = 1.10$, $x_{\\mathrm{ref},2} = 1.05$\n    - 权重: $q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.1$, $c = 0.5$\n    - 期望间距: $s = 0.05$\n    - 屏障参数: $\\mu = 5 \\times 10^{-3}$, $\\epsilon = 10^{-3}$\n    - 输入边界: $u_{\\min,1} = u_{\\min,2} = -0.20$, $u_{\\max,1} = u_{\\max,2} = 0.20$\n    - DMPC 迭代次数: $4$\n\n- 测试用例 3 (极端接近边界的边缘情况；必要时后退):\n    - $N = 4$\n    - 初始状态: $x_1[0] = 0.9990$, $x_2[0] = 0.9995$\n    - 安全边界: $x_{b,1} = 1.0000$, $x_{b,2} = 1.0000$\n    - 参考值: $x_{\\mathrm{ref},1} = 1.0000$, $x_{\\mathrm{ref},2} = 1.0000$\n    - 权重: $q_1 = q_2 = 1.0$, $r_1 = r_2 = 0.05$, $c = 0.2$\n    - 期望间距: $s = 0.00$\n    - 屏障参数: $\\mu = 10^{-2}$, $\\epsilon = 10^{-4}$\n    - 输入边界: $u_{\\min,1} = u_{\\min,2} = -0.05$, $u_{\\max,1} = u_{\\max,2} = 0.05$\n    - DMPC 迭代次数: $5$\n\n您的程序应生成一行输出，其中包含一个由方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3]\"），其中每个结果是一个布尔值，表示在相应的测试用例中，两个智能体的所有约束 $h_i(x_i[k]) \\ge 0$ 是否在整个时域内都得到满足。",
            "solution": "用户提供的问题已经过分析，被认为是有效的。其科学基础植根于控制理论的原理，特别是针对带状态约束的线性系统的分布式模型预测控制（DMPC）。该问题是适定的、自洽的，并且为数值解提供了所有必要的参数。任务要求实现一个迭代优化算法，为两个耦合的智能体寻找控制序列，并验证所得轨迹的安全性。\n\n### 1. 问题建模与系统动力学\n\n系统由两个智能体 $i \\in \\{1, 2\\}$ 组成，每个智能体由一个离散时间单积分器模型描述：\n$$x_i[k+1] = x_i[k] + u_i[k]$$\n其中 $x_i[k] \\in \\mathbb{R}$ 是状态（位置），$u_i[k] \\in \\mathbb{R}$ 是时间步 $k$ 的控制输入。目标是设计一个 DMPC 策略，其中每个智能体 $i$ 通过求解一个局部的、有约束的优化问题，来计算其在长度为 $N$ 的预测时域上的控制序列 $\\mathbf{u}_i = \\{u_i[0], \\dots, u_i[N-1]\\}$。\n\n### 2. 局部优化问题\n\n对于每个智能体 $i$，优化问题是在满足系统动力学和约束的条件下，最小化一个局部成本函数 $J_i$。决策变量是时域内的控制输入 $\\mathbf{u}_i$。状态轨迹 $\\mathbf{x}_i = \\{x_i[0], \\dots, x_i[N]\\}$ 由初始状态 $x_i[0]$ 和控制序列 $\\mathbf{u}_i$ 通过以下关系确定：\n$$x_i[k] = x_i[0] + \\sum_{m=0}^{k-1} u_i[m] \\quad \\text{for } k \\in \\{1, \\dots, N\\}$$\n\n智能体 $i$ 的局部成本函数 $J_i$ 如下：\n$$J_i(\\mathbf{u}_i) = \\sum_{k=0}^{N-1} \\left[ q_i (x_i[k] - x_{\\mathrm{ref},i})^2 + r_i u_i[k]^2 + c ((x_i[k] - x_j[k]) - s)^2 \\right] - \\mu \\sum_{k=0}^{N-1} \\log(x_{b,i} - x_i[k])$$\n该成本函数包含四个部分：\n1.  **参考跟踪**: 二次惩罚项 $q_i (x_i[k] - x_{\\mathrm{ref},i})^2$ 驱使智能体的状态朝其参考值 $x_{\\mathrm{ref},i}$ 移动。\n2.  **控制能量正则化**: 二次惩罚项 $r_i u_i[k]^2$ 惩罚大的控制动作。\n3.  **编队保持**: 二次项 $c ((x_i[k] - x_j[k]) - s)^2$ 惩罚与另一个智能体 $j$ 的相对位置偏离期望间距 $s$ 的行为。在 DMPC 方案中，另一个智能体的轨迹 $\\mathbf{x}_j$ 基于其最新的预测，被视为一个固定参数。\n4.  **对数屏障**: 项 $-\\mu \\sum \\log(h_i(x_i[k]))$（其中 $h_i(x_i) = x_{b,i} - x_i$）对接近安全边界 $x_{b,i}$ 的状态产生巨大的惩罚，从而有效地将轨迹保持在安全集的内部。\n\n优化受制于以下约束，对于输入为 $k \\in \\{0, \\dots, N-1\\}$，对于状态为 $k \\in \\{1, \\dots, N\\}$：\n1.  **输入边界**: $u_{\\min,i} \\le u_i[k] \\le u_{\\max,i}$。这些是关于决策变量的简单箱形约束。\n2.  **状态约束**: $x_i[k] \\le x_{b,i} - \\epsilon$。这强制要求预测的状态轨迹严格保持在安全集内，并带有一个裕度 $\\epsilon  0$。由于 $x_i[k]$ 是 $\\mathbf{u}_i$ 的线性函数，这些是关于决策变量的线性不等式约束。\n\n成本函数 $J_i$ 是二次项和负对数项的和。由于二次函数是凸的，负对数函数也是凸的，因此目标函数是凸的。约束是线性的。因此，每个局部优化问题都是一个凸规划问题，这保证了数值求解器可以高效地找到唯一的全局最优解。\n\n### 3. 分布式模型预测控制 (DMPC) 算法\n\nDMPC 方案以迭代方式运行，智能体以交替（高斯-赛德尔）方式求解其局部问题。算法如下：\n\n1.  **初始化**: 为每个智能体 $i$ 初始化其预测轨迹。假设采用静态轨迹，即对于所有 $k$，$u_i[k] = 0$，这导致对于所有 $k \\in \\{0, \\dots, N\\}$，$x_i^{\\text{pred}}[k] = x_i[0]$。\n2.  **迭代优化**: 对于固定次数的 DMPC 迭代：\n    a.  **求解智能体 1**: 智能体 1 求解其局部优化问题，以找到其最优控制序列 $\\mathbf{u}_1^*$。此优化使用智能体 2 当前的预测轨迹 $\\mathbf{x}_2^{\\text{pred}}$。然后，使用 $\\mathbf{u}_1^*$ 更新智能体 1 的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$。\n    b.  **求解智能体 2**: 智能体 2 求解其局部优化问题，以找到其最优控制序列 $\\mathbf{u}_2^*$。此优化使用智能体 1 新更新的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$。然后，使用 $\\mathbf{u}_2^*$ 更新智能体 2 的预测轨迹 $\\mathbf{x}_2^{\\text{pred}}$。\n3.  **终止**: 在指定次数的迭代之后，获得两个智能体的最终预测轨迹。\n\n### 4. 数值实现与安全性验证\n\n数值解在 Python 中使用 `scipy.optimize.minimize` 函数和 'SLSQP'（序列最小二乘规划）方法实现，该方法非常适合非线性约束优化问题。\n\n-   **目标函数**: 定义一个 Python 函数，用于在给定控制向量 $\\mathbf{u}_i$ 的情况下计算 $J_i$。该函数首先计算对应的状态轨迹 $\\mathbf{x}_i$，然后评估成本项的总和。其中包含一个保护措施，如果对数的任何参数为非正数，则返回无穷大，以引导求解器避开不可行区域。\n-   **约束**: 输入边界直接传递给求解器的 `bounds` 参数。状态约束 $x_i[k] \\le x_{b,i} - \\epsilon$ 被表述为 $\\mathbf{u}_i$ 的函数，并提供给 `constraints` 参数。对于每个 $k \\in \\{1, \\dots, N\\}$，创建一个约束函数 $g_k(\\mathbf{u}_i) = (x_{b,i} - x_i[k]) - \\epsilon \\ge 0$。\n-   **最终验证**: DMPC 迭代完成后，检查最终的预测轨迹 $\\mathbf{x}_1^{\\text{pred}}$ 和 $\\mathbf{x}_2^{\\text{pred}}$ 是否满足基本安全条件 $h_i(x_i[k]) \\ge 0$，这等同于 $x_i[k] \\le x_{b,i}$。对每个智能体 $i$ 和预测轨迹中的所有步骤 $k \\in \\{1, \\dots, N\\}$ 执行此检查。一个测试用例的最终输出为 `True` 当且仅当此条件对两个智能体的整个预测轨迹都成立。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for the DMPC problem.\n    \"\"\"\n    test_cases = [\n        { # Test Case 1\n            \"N\": 5, \"x0\": (0.20, 0.10), \"xb\": (1.00, 1.00),\n            \"xref\": (0.80, 0.75), \"q\": (1.0, 1.0), \"r\": (0.1, 0.1),\n            \"c\": 0.5, \"s\": 0.10, \"mu\": 1e-3, \"epsilon\": 1e-4,\n            \"umin\": (-0.30, -0.30), \"umax\": (0.30, 0.30),\n            \"dmpc_iterations\": 3\n        },\n        { # Test Case 2\n            \"N\": 6, \"x0\": (0.95, 0.92), \"xb\": (1.00, 1.00),\n            \"xref\": (1.10, 1.05), \"q\": (1.0, 1.0), \"r\": (0.1, 0.1),\n            \"c\": 0.5, \"s\": 0.05, \"mu\": 5e-3, \"epsilon\": 1e-3,\n            \"umin\": (-0.20, -0.20), \"umax\": (0.20, 0.20),\n            \"dmpc_iterations\": 4\n        },\n        { # Test Case 3\n            \"N\": 4, \"x0\": (0.9990, 0.9995), \"xb\": (1.0000, 1.0000),\n            \"xref\": (1.0000, 1.0000), \"q\": (1.0, 1.0), \"r\": (0.05, 0.05),\n            \"c\": 0.2, \"s\": 0.00, \"mu\": 1e-2, \"epsilon\": 1e-4,\n            \"umin\": (-0.05, -0.05), \"umax\": (0.05, 0.05),\n            \"dmpc_iterations\": 5\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        is_safe = run_dmpc_for_case(params)\n        results.append(str(is_safe).lower())\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_trajectory(x0, u_vec):\n    \"\"\"\n    Computes the state trajectory from an initial state and control sequence.\n    \"\"\"\n    N = len(u_vec)\n    x_traj = np.zeros(N + 1)\n    x_traj[0] = x0\n    for k in range(N):\n        x_traj[k+1] = x_traj[k] + u_vec[k]\n    return x_traj\n\ndef optimize_agent_trajectory(agent_idx, params, x0, neighbor_traj):\n    \"\"\"\n    Solves the local optimization problem for a single agent.\n    \"\"\"\n    N = params['N']\n    q = params['q'][agent_idx]\n    r = params['r'][agent_idx]\n    c = params['c']\n    s = params['s']\n    mu = params['mu']\n    epsilon = params['epsilon']\n    xb = params['xb'][agent_idx]\n    xref = params['xref'][agent_idx]\n    umin = params['umin'][agent_idx]\n    umax = params['umax'][agent_idx]\n\n    def objective(u_vec):\n        x_traj = compute_trajectory(x0, u_vec)\n        \n        # Barrier term check\n        h_vals = xb - x_traj[:N]\n        if np.any(h_vals = 0):\n            return np.inf\n\n        cost_tracking = q * np.sum((x_traj[:N] - xref)**2)\n        cost_actuation = r * np.sum(u_vec**2)\n        cost_coupling = c * np.sum(((x_traj[:N] - neighbor_traj[:N]) - s)**2)\n        cost_barrier = -mu * np.sum(np.log(h_vals))\n\n        return cost_tracking + cost_actuation + cost_coupling + cost_barrier\n\n    constraints = []\n    for k in range(1, N + 1):\n        def constr_func(u_vec, k_val=k):\n            x_k = x0 + np.sum(u_vec[:k_val])\n            return xb - x_k - epsilon\n        constraints.append({'type': 'ineq', 'fun': constr_func})\n    \n    bounds = [(umin, umax)] * N\n    u_initial_guess = np.zeros(N)\n\n    result = minimize(objective, u_initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n    return result\n\ndef run_dmpc_for_case(params):\n    \"\"\"\n    Runs the DMPC simulation for a single test case.\n    \"\"\"\n    N = params['N']\n    x1_0, x2_0 = params['x0']\n    xb1, xb2 = params['xb']\n\n    # Initial static trajectories (zero control input)\n    u1_pred = np.zeros(N)\n    u2_pred = np.zeros(N)\n    x1_pred = compute_trajectory(x1_0, u1_pred)\n    x2_pred = compute_trajectory(x2_0, u2_pred)\n    \n    # DMPC iterations\n    for _ in range(params['dmpc_iterations']):\n        # Agent 1 solves its optimization problem\n        res1 = optimize_agent_trajectory(0, params, x1_0, x2_pred)\n        if res1.success:\n            u1_pred = res1.x\n        x1_pred = compute_trajectory(x1_0, u1_pred)\n\n        # Agent 2 solves its optimization problem\n        res2 = optimize_agent_trajectory(1, params, x2_0, x1_pred)\n        if res2.success:\n            u2_pred = res2.x\n        x2_pred = compute_trajectory(x2_0, u2_pred)\n\n    # Final safety verification h_i(x_i[k]) >= 0 for k=1..N\n    # This is equivalent to x_i[k] = x_{b,i}\n    is_safe1 = np.all(x1_pred[1:] = xb1)\n    is_safe2 = np.all(x2_pred[1:] = xb2)\n    \n    return is_safe1 and is_safe2\n\nsolve()\n```"
        }
    ]
}