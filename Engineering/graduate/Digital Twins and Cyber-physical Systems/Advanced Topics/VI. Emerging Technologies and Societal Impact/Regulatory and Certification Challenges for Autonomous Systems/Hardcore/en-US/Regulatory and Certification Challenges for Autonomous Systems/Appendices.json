{
    "hands_on_practices": [
        {
            "introduction": "Certifying an autonomous system often begins with applying established principles of functional safety to its hardware and architecture. This practice  places you in the role of a safety engineer, tasked with quantifying a subsystem's reliability according to the IEC 61508 standard. You will calculate the required diagnostic coverage from a Digital Twin monitor to meet a target Probability of dangerous Failure per Hour ($λ_{\\mathrm{PFH}}$), providing practical insight into how safety cases are built and argued quantitatively.",
            "id": "4239826",
            "problem": "An autonomous braking subsystem within a Cyber-Physical System (CPS) is undergoing certification under the International Electrotechnical Commission standard 61508 (IEC 61508) for continuous mode of operation. The certification target is the Probability of dangerous Failure per Hour (PFH), denoted by $\\lambda_{\\mathrm{PFH}}$, for the hazard path formed by three components in series: a perception sensor ($S$), a controller ($C$), and an actuator ($A$). Each component $i \\in \\{S,C,A\\}$ has a base dangerous failure rate $\\lambda_{D,i}$ and an embedded hardware diagnostic with coverage $c_{h,i}$ implemented on-board. A Digital Twin-based online monitor is added, with a uniform tunable coverage parameter $c_{dt} \\in [0,1]$ applied to all three components, but its effectiveness on component $i$ is limited by an effectiveness coefficient $e_i \\in [0,1]$ that quantifies the fraction of dangerous failure modes in $i$ that are amenable to detection by the Digital Twin’s models and analytics. Assume detection mechanisms (hardware diagnostics and Digital Twin monitor) act independently on each dangerous failure mode, and that upon detection the system transitions immediately to a safe state such that detected dangerous failures do not contribute to $\\lambda_{\\mathrm{PFH}}$. Assume constant failure rates (homogeneous Poisson processes), rare failures, and a series hazard path such that the subsystem-level $\\lambda_{\\mathrm{PFH}}$ is the sum of component-level dangerous undetected failure rates.\n\nThe subsystem data are:\n- Sensor: $\\lambda_{D,S} = 2.0 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,S} = 0.55$, $e_{S} = 0.90$.\n- Controller: $\\lambda_{D,C} = 1.5 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,C} = 0.65$, $e_{C} = 0.50$.\n- Actuator: $\\lambda_{D,A} = 2.5 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,A} = 0.40$, $e_{A} = 0.80$.\n\nThe certification target is $\\lambda_{\\mathrm{PFH,target}} = 2.0 \\times 10^{-6}\\ \\text{h}^{-1}$. Under the modeling assumptions above, compute the minimum Digital Twin coverage $c_{dt}$ required to meet $\\lambda_{\\mathrm{PFH,target}}$. Express your final answer as a unitless fraction and round your answer to four significant figures.",
            "solution": "The user-provided problem is evaluated for validity.\n\n### Step 1: Extract Givens\n- **System Components**: Sensor ($S$), Controller ($C$), Actuator ($A$) in a series hazard path.\n- **Certification Target**: Probability of dangerous Failure per Hour, $\\lambda_{\\mathrm{PFH,target}} = 2.0 \\times 10^{-6}\\ \\text{h}^{-1}$.\n- **Component Data ($i \\in \\{S,C,A\\}$)**:\n  - Base dangerous failure rate: $\\lambda_{D,i}$.\n  - Hardware diagnostic coverage: $c_{h,i}$.\n  - Digital Twin effectiveness coefficient: $e_i$.\n- **Digital Twin (DT) Monitor**:\n  - Uniform tunable coverage: $c_{dt} \\in [0,1]$.\n- **Specific Data Values**:\n  - Sensor ($S$): $\\lambda_{D,S} = 2.0 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,S} = 0.55$, $e_{S} = 0.90$.\n  - Controller ($C$): $\\lambda_{D,C} = 1.5 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,C} = 0.65$, $e_{C} = 0.50$.\n  - Actuator ($A$): $\\lambda_{D,A} = 2.5 \\times 10^{-6}\\ \\text{h}^{-1}$, $c_{h,A} = 0.40$, $e_{A} = 0.80$.\n- **Assumptions**:\n  - Hardware diagnostics and the DT monitor act as independent detection mechanisms.\n  - Detected dangerous failures are safely handled and do not contribute to $\\lambda_{\\mathrm{PFH}}$.\n  - The subsystem $\\lambda_{\\mathrm{PFH}}$ is the sum of component-level dangerous undetected failure rates ($\\lambda_{\\mathrm{DU},i}$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded**: The problem is well-grounded in the principles of reliability engineering and functional safety as defined by standards like IEC 61508. The concepts of dangerous failure rates, diagnostic coverage, and the calculation of PFH for a series system are standard methodologies.\n- **Well-Posed**: The problem provides all necessary data and defines all relationships required to formulate and solve for the unknown variable, $c_{dt}$. A unique solution is expected.\n- **Objective**: The problem is stated using precise, quantitative, and unambiguous language.\n- **Conclusion**: The problem does not exhibit any flaws related to scientific soundness, completeness, consistency, or objectivity. It is a formalizable and relevant problem in the field of cyber-physical systems safety.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\nThe problem requires the calculation of the minimum Digital Twin coverage, $c_{dt}$, needed to achieve a target subsystem Probability of dangerous Failure per Hour, $\\lambda_{\\mathrm{PFH,target}}$.\n\nAccording to the problem statement, the subsystem's $\\lambda_{\\mathrm{PFH}}$ is the sum of the dangerous undetected failure rates, $\\lambda_{\\mathrm{DU},i}$, of its components.\n$$ \\lambda_{\\mathrm{PFH}} = \\sum_{i \\in \\{S,C,A\\}} \\lambda_{\\mathrm{DU},i} $$\nA dangerous failure of a component $i$ contributes to $\\lambda_{\\mathrm{DU},i}$ only if it is not detected by either the on-board hardware diagnostic or the Digital Twin monitor. The problem states that these two detection mechanisms are independent.\n\nFor a given component $i$, the probability that a dangerous failure is *not* detected by the hardware diagnostic is $(1 - c_{h,i})$.\nThe Digital Twin monitor has a coverage parameter $c_{dt}$, but its applicability to component $i$ is limited by an effectiveness coefficient $e_i$. Thus, the effective probability that the DT detects a random dangerous failure on component $i$ is the product $e_i c_{dt}$. Consequently, the probability that a dangerous failure is *not* detected by the DT monitor is $(1 - e_i c_{dt})$.\n\nDue to the independence of the two detection mechanisms, the probability that a dangerous failure is missed by *both* mechanisms is the product of their individual probabilities of non-detection.\n$$ P(\\text{undetected}) = (1 - c_{h,i}) (1 - e_i c_{dt}) $$\nThe dangerous undetected failure rate for component $i$, $\\lambda_{\\mathrm{DU},i}$, is the base dangerous failure rate, $\\lambda_{D,i}$, multiplied by this probability of non-detection.\n$$ \\lambda_{\\mathrm{DU},i} = \\lambda_{D,i} (1 - c_{h,i})(1 - e_i c_{dt}) $$\nThe total system $\\lambda_{\\mathrm{PFH}}$ is the sum over all three components:\n$$ \\lambda_{\\mathrm{PFH}} = \\sum_{i \\in \\{S,C,A\\}} \\lambda_{D,i} (1 - c_{h,i})(1 - e_i c_{dt}) $$\nTo find the minimum required $c_{dt}$, we set $\\lambda_{\\mathrm{PFH}}$ equal to the target value, $\\lambda_{\\mathrm{PFH,target}}$.\n$$ \\lambda_{\\mathrm{PFH,target}} = \\sum_{i \\in \\{S,C,A\\}} \\lambda_{D,i} (1 - c_{h,i})(1 - e_i c_{dt}) $$\nWe can expand and rearrange this equation to solve for $c_{dt}$.\n$$ \\lambda_{\\mathrm{PFH,target}} = \\sum_{i} \\left[ \\lambda_{D,i}(1 - c_{h,i}) - c_{dt} \\cdot e_i \\lambda_{D,i}(1 - c_{h,i}) \\right] $$\n$$ \\lambda_{\\mathrm{PFH,target}} = \\sum_{i} \\lambda_{D,i}(1 - c_{h,i}) - c_{dt} \\sum_{i} e_i \\lambda_{D,i}(1 - c_{h,i}) $$\nRearranging to isolate the term with $c_{dt}$:\n$$ c_{dt} \\sum_{i} e_i \\lambda_{D,i}(1 - c_{h,i}) = \\sum_{i} \\lambda_{D,i}(1 - c_{h,i}) - \\lambda_{\\mathrm{PFH,target}} $$\nFinally, solving for $c_{dt}$:\n$$ c_{dt} = \\frac{\\sum_{i \\in \\{S,C,A\\}} \\lambda_{D,i}(1-c_{h,i}) - \\lambda_{\\mathrm{PFH,target}}}{\\sum_{i \\in \\{S,C,A\\}} e_i \\lambda_{D,i}(1-c_{h,i})} $$\nNow, we substitute the given numerical values. First, we compute the numerator's summation term, which represents the baseline PFH with only hardware diagnostics:\n$$ \\sum_{i} \\lambda_{D,i}(1-c_{h,i}) = \\lambda_{D,S}(1-c_{h,S}) + \\lambda_{D,C}(1-c_{h,C}) + \\lambda_{D,A}(1-c_{h,A}) $$\n$$ = (2.0 \\times 10^{-6})(1 - 0.55) + (1.5 \\times 10^{-6})(1 - 0.65) + (2.5 \\times 10^{-6})(1 - 0.40) $$\n$$ = (2.0 \\times 10^{-6})(0.45) + (1.5 \\times 10^{-6})(0.35) + (2.5 \\times 10^{-6})(0.60) $$\n$$ = (0.90 \\times 10^{-6}) + (0.525 \\times 10^{-6}) + (1.50 \\times 10^{-6}) = 2.925 \\times 10^{-6}\\ \\text{h}^{-1} $$\nThe full numerator is:\n$$ \\text{Numerator} = (2.925 \\times 10^{-6}) - (2.0 \\times 10^{-6}) = 0.925 \\times 10^{-6}\\ \\text{h}^{-1} $$\nNext, we compute the denominator's summation term:\n$$ \\sum_{i} e_i \\lambda_{D,i}(1-c_{h,i}) = e_S \\lambda_{D,S}(1-c_{h,S}) + e_C \\lambda_{D,C}(1-c_{h,C}) + e_A \\lambda_{D,A}(1-c_{h,A}) $$\nUsing the component terms calculated earlier:\n$$ = (0.90)(0.90 \\times 10^{-6}) + (0.50)(0.525 \\times 10^{-6}) + (0.80)(1.50 \\times 10^{-6}) $$\n$$ = (0.81 \\times 10^{-6}) + (0.2625 \\times 10^{-6}) + (1.20 \\times 10^{-6}) = 2.2725 \\times 10^{-6}\\ \\text{h}^{-1} $$\nNow, we calculate $c_{dt}$:\n$$ c_{dt} = \\frac{0.925 \\times 10^{-6}}{2.2725 \\times 10^{-6}} = \\frac{0.925}{2.2725} \\approx 0.4070429... $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ c_{dt} \\approx 0.4070 $$\nThis value is a unitless fraction between $0$ and $1$, consistent with its definition as a coverage parameter.",
            "answer": "$$\n\\boxed{0.4070}\n$$"
        },
        {
            "introduction": "Beyond hardware reliability, the correctness of the software's decision-making logic is paramount for safety. This hands-on exercise  delves into Modified Condition/Decision Coverage (MC/DC), a stringent structural coverage criterion required by standards like DO-178C for the most critical software. By writing a program to assess MC/DC, you will learn from first principles how to verify that each logical condition in your code has been shown to independently influence a decision outcome.",
            "id": "4239822",
            "problem": "You are given the task of quantifying Modified Condition/Decision Coverage (MC/DC) for several Boolean decision logic modules, and of grounding why attaining MC/DC is mandated at the highest safety assurance levels in safety-critical certification schemes for autonomous systems in digital twins and cyber-physical systems. The core is to compute MC/DC from first principles of propositional logic, using only the semantics of Boolean functions.\n\nDefinitions to use as the fundamental base:\n- A decision is a Boolean function $f:\\{0,1\\}^n \\rightarrow \\{0,1\\}$ over $n$ atomic conditions $(C_1,\\dots,C_n)$, where $0$ denotes false and $1$ denotes true.\n- Given a finite test set $T \\subset \\{0,1\\}^n$, Modified Condition/Decision Coverage (MC/DC) holds for a condition $C_i$ if there exist two tests $\\mathbf{x},\\mathbf{y}\\in T$ such that:\n  - $\\mathbf{x}_j=\\mathbf{y}_j$ for all $j\\neq i$, and $\\mathbf{x}_i \\neq \\mathbf{y}_i$ (only $C_i$ differs), and\n  - $f(\\mathbf{x}) \\neq f(\\mathbf{y})$ (the decision outcome changes).\n- The MC/DC coverage for a module with $n$ conditions under $T$ is the fraction $k/n$, where $k$ is the number of conditions that satisfy the above independence criterion using tests in $T$. Express coverage as a decimal in $[0,1]$ without a percentage sign.\n\nDecision modules and required test suites:\n- Module $\\mathcal{M}_1$ has decision $E_1(C_1,C_2,C_3,C_4) = (C_1 \\land C_2) \\lor (C_3 \\land \\lnot C_4)$ with $n=4$. Use the test suite $T_1$ consisting of the following input tuples, each tuple in the order $(C_1,C_2,C_3,C_4)$:\n  - $(0,1,0,1)$,\n  - $(1,1,0,1)$,\n  - $(1,0,0,1)$,\n  - $(0,0,0,0)$,\n  - $(0,0,1,0)$,\n  - $(0,0,1,1)$.\n- Module $\\mathcal{M}_2$ has decision $E_2(C_1,C_2,C_3) = C_1 \\land C_2 \\land C_3$ with $n=3$. Use the test suite $T_2$:\n  - $(1,1,1)$,\n  - $(0,1,1)$,\n  - $(1,0,1)$,\n  - $(1,1,0)$.\n- Module $\\mathcal{M}_3$ has decision $E_3(C_1,C_2,C_3) = C_1 \\lor (C_2 \\land C_3)$ with $n=3$. Use the test suite $T_3$:\n  - $(0,0,0)$,\n  - $(1,0,0)$,\n  - $(0,0,1)$,\n  - $(0,1,1)$.\n- Module $\\mathcal{M}_4$ has decision $E_4(C_1) = \\lnot C_1$ with $n=1$. Use the test suite $T_4$:\n  - $(0)$,\n  - $(1)$.\n\nTasks:\n- Implement a program that, for each module $\\mathcal{M}_i$, computes the MC/DC coverage under its specified test suite $T_i$ using only the above definition. For each module, compute the set of covered conditions and the coverage fraction $k/n$.\n- The result for each module must be a single float equal to the coverage fraction rounded to three decimal places (do not use a percentage sign). The final output should be the list of these floats for the four modules in the order $(\\mathcal{M}_1,\\mathcal{M}_2,\\mathcal{M}_3,\\mathcal{M}_4)$.\n\nJustification to include in your internal reasoning (not produced by the program output):\n- Use the fundamental semantics of Boolean functions and the independence requirement for MC/DC to explain why MC/DC detects masking in compound decisions.\n- Explain, using widely accepted certification practices such as \"DO-$178$C Level A\" and \"ISO $26262$ ASIL D\", why MC/DC is necessary at the highest assurance levels: it provides evidence that each atomic condition can independently affect the decision outcome, which is essential for demonstrating adequate structural coverage in safety-critical autonomy.\n\nTest suite and final output specification:\n- Use exactly the above $T_1,T_2,T_3,T_4$ and decision definitions.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[0.750,1.000,0.667,1.000]\"). Express each coverage as a decimal rounded to three places.\n\nNotes:\n- There are no physical units involved.\n- Angles are not involved.\n- Do not express any value as a percentage.",
            "solution": "The problem requires the calculation of Modified Condition/Decision Coverage (MC/DC) for four distinct Boolean decision logic modules, given their respective decision functions and test suites. The MC/DC coverage is defined as the fraction of conditions for which an independence pair can be found within the provided test set. An independence pair for a condition $C_i$ consists of two test vectors that differ only in the value of $C_i$ and for which the decision outcome is different. The problem is well-posed, scientifically grounded in the principles of software engineering and formal logic, and provides all necessary information for a unique solution.\n\nWe will analyze each module sequentially by first evaluating the decision outcome for every test in the suite, and then systematically searching for an independence pair for each condition.\n\n**Module $\\mathcal{M}_1$**\n\nThe decision function is $E_1(C_1, C_2, C_3, C_4) = (C_1 \\land C_2) \\lor (C_3 \\land \\lnot C_4)$ with $n=4$ conditions.\nThe test suite is $T_1 = \\{(0,1,0,1), (1,1,0,1), (1,0,0,1), (0,0,0,0), (0,0,1,0), (0,0,1,1)\\}$.\n\nFirst, we calculate the outcome of $E_1$ for each test vector in $T_1$:\n- $\\mathbf{t}_1 = (0,1,0,1): E_1(\\mathbf{t}_1) = (0 \\land 1) \\lor (0 \\land \\lnot 1) = 0 \\lor 0 = 0$\n- $\\mathbf{t}_2 = (1,1,0,1): E_1(\\mathbf{t}_2) = (1 \\land 1) \\lor (0 \\land \\lnot 1) = 1 \\lor 0 = 1$\n- $\\mathbf{t}_3 = (1,0,0,1): E_1(\\mathbf{t}_3) = (1 \\land 0) \\lor (0 \\land \\lnot 1) = 0 \\lor 0 = 0$\n- $\\mathbf{t}_4 = (0,0,0,0): E_1(\\mathbf{t}_4) = (0 \\land 0) \\lor (0 \\land \\lnot 0) = 0 \\lor 0 = 0$\n- $\\mathbf{t}_5 = (0,0,1,0): E_1(\\mathbf{t}_5) = (0 \\land 0) \\lor (1 \\land \\lnot 0) = 0 \\lor 1 = 1$\n- $\\mathbf{t}_6 = (0,0,1,1): E_1(\\mathbf{t}_6) = (0 \\land 0) \\lor (1 \\land \\lnot 1) = 0 \\lor 0 = 0$\n\nNext, we check for MC/DC coverage for each condition:\n- **Condition $C_1$**: The test pair $(\\mathbf{t}_1, \\mathbf{t}_2) = ((0,1,0,1), (1,1,0,1))$ differs only in $C_1$. The outcomes are $E_1(\\mathbf{t}_1) = 0$ and $E_1(\\mathbf{t}_2) = 1$, which are different. Thus, $C_1$ is covered.\n- **Condition $C_2$**: The test pair $(\\mathbf{t}_3, \\mathbf{t}_2) = ((1,0,0,1), (1,1,0,1))$ differs only in $C_2$. The outcomes are $E_1(\\mathbf{t}_3) = 0$ and $E_1(\\mathbf{t}_2) = 1$, which are different. Thus, $C_2$ is covered.\n- **Condition $C_3$**: The test pair $(\\mathbf{t}_4, \\mathbf{t}_5) = ((0,0,0,0), (0,0,1,0))$ differs only in $C_3$. The outcomes are $E_1(\\mathbf{t}_4) = 0$ and $E_1(\\mathbf{t}_5) = 1$, which are different. Thus, $C_3$ is covered.\n- **Condition $C_4$**: The test pair $(\\mathbf{t}_5, \\mathbf{t}_6) = ((0,0,1,0), (0,0,1,1))$ differs only in $C_4$. The outcomes are $E_1(\\mathbf{t}_5) = 1$ and $E_1(\\mathbf{t}_6) = 0$, which are different. Thus, $C_4$ is covered.\n\nAll $k=4$ conditions are covered. The MC/DC coverage for $\\mathcal{M}_1$ is $k/n = 4/4 = 1.0$.\n\n**Module $\\mathcal{M}_2$**\n\nThe decision function is $E_2(C_1, C_2, C_3) = C_1 \\land C_2 \\land C_3$ with $n=3$ conditions.\nThe test suite is $T_2 = \\{(1,1,1), (0,1,1), (1,0,1), (1,1,0)\\}$.\n\nOutcomes for $T_2$:\n- $\\mathbf{t}_1 = (1,1,1): E_2(\\mathbf{t}_1) = 1 \\land 1 \\land 1 = 1$\n- $\\mathbf{t}_2 = (0,1,1): E_2(\\mathbf{t}_2) = 0 \\land 1 \\land 1 = 0$\n- $\\mathbf{t}_3 = (1,0,1): E_2(\\mathbf{t}_3) = 1 \\land 0 \\land 1 = 0$\n- $\\mathbf{t}_4 = (1,1,0): E_2(\\mathbf{t}_4) = 1 \\land 1 \\land 0 = 0$\n\nMC/DC coverage check:\n- **Condition $C_1$**: The pair $(\\mathbf{t}_2, \\mathbf{t}_1) = ((0,1,1), (1,1,1))$ differs only in $C_1$. Outcomes are $0$ and $1$. $C_1$ is covered.\n- **Condition $C_2$**: The pair $(\\mathbf{t}_3, \\mathbf{t}_1) = ((1,0,1), (1,1,1))$ differs only in $C_2$. Outcomes are $0$ and $1$. $C_2$ is covered.\n- **Condition $C_3$**: The pair $(\\mathbf{t}_4, \\mathbf{t}_1) = ((1,1,0), (1,1,1))$ differs only in $C_3$. Outcomes are $0$ and $1$. $C_3$ is covered.\n\nAll $k=3$ conditions are covered. The MC/DC coverage for $\\mathcal{M}_2$ is $k/n = 3/3 = 1.0$.\n\n**Module $\\mathcal{M}_3$**\n\nThe decision function is $E_3(C_1, C_2, C_3) = C_1 \\lor (C_2 \\land C_3)$ with $n=3$ conditions.\nThe test suite is $T_3 = \\{(0,0,0), (1,0,0), (0,0,1), (0,1,1)\\}$.\n\nOutcomes for $T_3$:\n- $\\mathbf{t}_1 = (0,0,0): E_3(\\mathbf{t}_1) = 0 \\lor (0 \\land 0) = 0$\n- $\\mathbf{t}_2 = (1,0,0): E_3(\\mathbf{t}_2) = 1 \\lor (0 \\land 0) = 1$\n- $\\mathbf{t}_3 = (0,0,1): E_3(\\mathbf{t}_3) = 0 \\lor (0 \\land 1) = 0$\n- $\\mathbf{t}_4 = (0,1,1): E_3(\\mathbf{t}_4) = 0 \\lor (1 \\land 1) = 1$\n\nMC/DC coverage check:\n- **Condition $C_1$**: The pair $(\\mathbf{t}_1, \\mathbf{t}_2) = ((0,0,0), (1,0,0))$ differs only in $C_1$. Outcomes are $0$ and $1$. $C_1$ is covered.\n- **Condition $C_2$**: The pair $(\\mathbf{t}_3, \\mathbf{t}_4) = ((0,0,1), (0,1,1))$ differs only in $C_2$. The other conditions $(C_1,C_3)$ are fixed at $(0,1)$. The outcomes are $E_3(\\mathbf{t}_3)=0$ and $E_3(\\mathbf{t}_4)=1$. $C_2$ is covered.\n- **Condition $C_3$**: We need a pair that differs only in $C_3$. The only such pair in $T_3$ is $(\\mathbf{t}_1, \\mathbf{t}_3) = ((0,0,0), (0,0,1))$. The outcomes are $E_3(\\mathbf{t}_1) = 0$ and $E_3(\\mathbf{t}_3) = 0$. Since the outcome does not change, this pair does not satisfy the MC/DC criterion. No other pair exists in $T_3$ for $C_3$. Thus, $C_3$ is not covered.\n\nOnly $k=2$ conditions ($C_1, C_2$) are covered. The MC/DC coverage for $\\mathcal{M}_3$ is $k/n = 2/3 \\approx 0.667$.\n\n**Module $\\mathcal{M}_4$**\n\nThe decision function is $E_4(C_1) = \\lnot C_1$ with $n=1$ condition.\nThe test suite is $T_4 = \\{(0), (1)\\}$.\n\nOutcomes for $T_4$:\n- $\\mathbf{t}_1 = (0): E_4(\\mathbf{t}_1) = \\lnot 0 = 1$\n- $\\mathbf{t}_2 = (1): E_4(\\mathbf{t}_2) = \\lnot 1 = 0$\n\nMC/DC coverage check:\n- **Condition $C_1$**: The pair $(\\mathbf{t}_1, \\mathbf{t}_2) = ((0), (1))$ differs only in $C_1$. Outcomes are $1$ and $0$. $C_1$ is covered.\n\nAll $k=1$ conditions are covered. The MC/DC coverage for $\\mathcal{M}_4$ is $k/n = 1/1 = 1.0$.\n\n**Summary of Results**\nThe calculated MC/DC coverage fractions are:\n- $\\mathcal{M}_1$: $1.0$\n- $\\mathcal{M}_2$: $1.0$\n- $\\mathcal{M}_3$: $2/3 \\approx 0.667$\n- $\\mathcal{M}_4$: $1.0$",
            "answer": "[1.000,1.000,0.667,1.000]"
        },
        {
            "introduction": "Autonomous systems that learn from data face a critical challenge: ensuring they remain safe when the operational environment deviates from their training data. This practice  addresses this by tasking you with building a runtime monitor based on statistical hypothesis testing. You will use the Mahalanobis distance to construct a test for distribution shift and compute its false alarm rate, a fundamental skill for maintaining the safety assurance of AI-powered systems in the field.",
            "id": "4239834",
            "problem": "An autonomous system within a Cyber-Physical System (CPS) uses a Digital Twin (DT) to maintain a reference model of its training data distribution. To meet regulatory and certification objectives for safety monitoring, the system must detect statistically significant distribution shifts in its operational data stream with a controlled False Alarm Probability (FAP). Consider the following principle-based detection mechanism grounded in statistical hypothesis testing:\n\n- Let the training distribution be multivariate normal with known mean vector $\\mu \\in \\mathbb{R}^d$ and known positive-definite covariance matrix $\\Sigma \\in \\mathbb{R}^{d \\times d}$.\n- Let the operational data consist of $n$ Independent and Identically Distributed (i.i.d.) samples $\\{x_i\\}_{i=1}^n$, where each $x_i \\in \\mathbb{R}^d$.\n- The null hypothesis $H_0$ asserts that the operational data follow the same distribution as training data, i.e., $x_i \\sim \\mathcal{N}(\\mu, \\Sigma)$ for all $i \\in \\{1,\\dots,n\\}$.\n- Define the aggregated squared Mahalanobis statistic\n$$\nT = \\sum_{i=1}^{n} (x_i - \\mu)^\\top \\Sigma^{-1} (x_i - \\mu).\n$$\n- The decision rule raises an alarm if $T  \\tau$ for a chosen threshold $\\tau \\geq 0$. Under $H_0$, $T$ is distributed as a chi-square with $n d$ degrees of freedom.\n\nTask: Construct a program that, given $(n, d, \\tau)$, computes the false alarm probability $\\alpha$ under $H_0$,\n$$\n\\alpha = \\Pr_{H_0}(T  \\tau),\n$$\nexpressed as a decimal number (not a percentage), for each test case below. No physical units or angle units are involved in this computation. The program must implement the survival function of the chi-square distribution to compute $\\alpha$ exactly under $H_0$, without approximation by simulation.\n\nTest suite:\n- Case $1$ (general happy path): $n = 50$, $d = 2$, $\\tau = 150.0$.\n- Case $2$ (boundary threshold at zero): $n = 1$, $d = 2$, $\\tau = 0.0$.\n- Case $3$ (large-sample regime, threshold at the mean): $n = 1000$, $d = 10$, $\\tau = 10000.0$.\n- Case $4$ (low degrees of freedom, moderate threshold): $n = 5$, $d = 1$, $\\tau = 10.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Each $result_k$ must be a floating-point number equal to the computed $\\alpha$ for Case $k$.",
            "solution": "The problem requires the calculation of the false alarm probability, denoted by $\\alpha$, for a statistical test designed to detect distribution shifts in an autonomous system. The problem statement provides a comprehensive and valid framework based on classical statistical hypothesis testing.\n\nThe validation of the problem is as follows:\n- **Scientific Grounding**: The problem is based on well-established principles of multivariate statistics. The core statement that the test statistic $T$ follows a chi-square distribution under the null hypothesis is correct. If $x_i \\sim \\mathcal{N}(\\mu, \\Sigma)$, then the squared Mahalanobis distance $(x_i - \\mu)^\\top \\Sigma^{-1} (x_i - \\mu)$ follows a chi-square distribution with $d$ degrees of freedom, denoted $\\chi^2_d$. The test statistic $T$ is the sum of $n$ such independent, identically distributed variables. A fundamental property of the chi-square distribution is that the sum of independent chi-square variables is also a chi-square variable, with degrees of freedom equal to the sum of the individual degrees of freedom. Thus, $T = \\sum_{i=1}^{n} (x_i - \\mu)^\\top \\Sigma^{-1} (x_i - \\mu)$ follows a chi-square distribution with $n \\times d$ degrees of freedom, i.e., $T \\sim \\chi^2_{nd}$. The problem formulation is mathematically sound.\n- **Well-Posedness and Completeness**: The problem is well-posed. It provides all necessary inputs ($n, d, \\tau$) for each test case and a clear definition of the quantity to be calculated, $\\alpha$. The relationship between the inputs and the output is a precisely defined statistical function, ensuring a unique and meaningful solution exists.\n- **Objectivity and Clarity**: The problem is stated using precise, objective mathematical language. The context involving Cyber-Physical Systems and Digital Twins serves as a realistic framing for a formal mathematical task.\n\nThe problem is deemed valid, and we may proceed with the solution.\n\nThe task is to compute the false alarm probability $\\alpha$, which is the probability of the test statistic $T$ exceeding a threshold $\\tau$ under the null hypothesis $H_0$. This is formally expressed as:\n$$\n\\alpha = \\Pr_{H_0}(T  \\tau)\n$$\nAs established, under $H_0$, the statistic $T$ is distributed as a chi-square random variable with $k = nd$ degrees of freedom. Therefore, we need to compute:\n$$\n\\alpha = \\Pr(X  \\tau) \\quad \\text{where} \\quad X \\sim \\chi^2_k\n$$\nThis probability corresponds to the survival function (SF) of the chi-square distribution with $k$ degrees of freedom, evaluated at the point $\\tau$. The survival function, often denoted $S(x)$, is the complementary cumulative distribution function (CCDF), defined as $S(x) = 1 - F(x)$, where $F(x)$ is the cumulative distribution function (CDF).\n\nThe computational procedure for each test case $(n, d, \\tau)$ is as follows:\n$1$. Calculate the degrees of freedom for the chi-square distribution: $k = n \\times d$. It is important to note that both $n$ and $d$ must be positive integers, which they are in all provided test cases.\n$2$. Compute $\\alpha$ using the survival function of the $\\chi^2_k$ distribution evaluated at the threshold $\\tau$. This is computationally preferable to $1 - \\text{CDF}(\\tau)$, especially for large values of $\\tau$ where $\\text{CDF}(\\tau)$ is close to $1$, as it avoids potential loss of precision.\n\nWe will apply this procedure to each test case:\n\n- **Case 1**: $n = 50$, $d = 2$, $\\tau = 150.0$.\n  - Degrees of freedom $k = 50 \\times 2 = 100$.\n  - We calculate $\\alpha_1 = \\Pr(\\chi^2_{100}  150.0)$.\n\n- **Case 2**: $n = 1$, $d = 2$, $\\tau = 0.0$.\n  - Degrees of freedom $k = 1 \\times 2 = 2$.\n  - We calculate $\\alpha_2 = \\Pr(\\chi^2_2  0.0)$. The chi-square distribution is defined for non-negative values. As a continuous distribution, the probability of it being strictly greater than $0$ is $1$, since the probability of being exactly $0$ is zero. Thus, $\\alpha_2 = 1.0$.\n\n- **Case 3**: $n = 1000$, $d = 10$, $\\tau = 10000.0$.\n  - Degrees of freedom $k = 1000 \\times 10 = 10000$.\n  - We calculate $\\alpha_3 = \\Pr(\\chi^2_{10000}  10000.0)$. The mean of a $\\chi^2_k$ distribution is $k$. Here, the threshold $\\tau$ is exactly equal to the mean. For large $k$, the $\\chi^2_k$ distribution approaches a normal distribution, becoming more symmetric. The median of a $\\chi^2_k$ distribution is approximately $k - 2/3$. Since the threshold is slightly larger than the median, we expect $\\alpha_3$ to be slightly less than $0.5$.\n\n- **Case 4**: $n = 5$, $d = 1$, $\\tau = 10.0$.\n  - Degrees of freedom $k = 5 \\times 1 = 5$.\n  - We calculate $\\alpha_4 = \\Pr(\\chi^2_5  10.0)$.\n\nThese calculations will be performed using the `scipy.stats.chi2.sf` function, which provides a numerically robust implementation of the chi-square survival function.",
            "answer": "[0.0002704533939375172,1.0,0.5015858042456075,0.07523992215392554]"
        }
    ]
}