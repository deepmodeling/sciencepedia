{
    "hands_on_practices": [
        {
            "introduction": "In safety-critical Cyber-Physical Systems, redundancy is a cornerstone of reliable design. However, the assumption of independent failures can be dangerously optimistic. This exercise  introduces the Beta-factor model to quantify the risk of Common Cause Failures (CCF), where a single event incapacitates multiple redundant components. By calculating the system-level failure probability for a hypothetical medical device, you will gain a crucial, quantitative understanding of how shared vulnerabilities can undermine safety and why this analysis is essential for ethical risk management under principles like As Low As Reasonably Practicable (ALARP).",
            "id": "4220283",
            "problem": "A hospital deploys a Cyber-Physical System (CPS) for closed-loop drug delivery, with a Digital Twin continuously auditing sensor reliability for ethical risk management under the As Low As Reasonably Practicable (ALARP) principle. The CPS uses a dual-redundant sensing architecture where either sensor can provide the necessary measurement. Each sensor has a single-sensor failure probability over the mission time modeled as $p$. Audits of software updates and environmental stressors report the presence of Common Cause Failures (CCF), summarized by a common-cause factor $\\beta$, defined as the fraction of the single-sensor failure probability attributable to mechanisms that simultaneously incapacitate both redundant sensors. The remainder $(1 - \\beta)$ of $p$ is attributed to idiosyncratic, sensor-specific failure mechanisms.\n\nAssume:\n- The two sensors are statistically independent conditional on the absence of common-cause mechanisms.\n- Common-cause mechanisms and idiosyncratic mechanisms are mutually exclusive routes to failure over the mission time.\n- The mission-time failure probability $p$ is small enough that second-order terms can be treated as arising from independent idiosyncratic mechanisms without reweighting the single-sensor marginal beyond the leading-order decomposition described above.\n\nStarting from the law of total probability and the definitions above, derive the mixture expression for the system-level failure probability $P_f$ of the dual-redundant sensor network over the mission time, in terms of $\\beta$ and $p$, emphasizing how the common-cause and independent routes contribute. Then, for $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$, compute the numerical value of $P_f$. Express the final probability as a decimal and round your answer to four significant figures. No units are required.",
            "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, objective, and complete.\n\n### Step 1: Extract Givens\n-   System architecture: Dual-redundant sensing, where either sensor is sufficient for operation. The system fails if and only if both sensors fail.\n-   Single-sensor failure probability: $p$.\n-   Common-cause factor: $\\beta$, defined as the fraction of $p$ attributable to mechanisms that simultaneously incapacitate both sensors.\n-   Idiosyncratic failure contribution: The fraction $(1 - \\beta)$ of $p$ is attributed to sensor-specific failure mechanisms.\n-   Assumption 1: The two sensors are statistically independent conditional on the absence of common-cause mechanisms.\n-   Assumption 2: Common-cause mechanisms and idiosyncratic mechanisms are mutually exclusive routes to failure.\n-   Assumption 3: $p$ is small, allowing second-order terms to be treated as arising from independent mechanisms without further correction.\n-   Numerical values: $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$.\n-   Required output: Derive the expression for the system-level failure probability $P_f$ and compute its numerical value, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is valid. It employs the Beta-factor model, a standard and well-established method in reliability engineering for analyzing Common Cause Failures (CCF) in redundant systems. The context is scientifically appropriate, the terms are precisely defined, and the provided data and assumptions are self-contained and consistent. No scientific, logical, or structural flaws are present.\n\n### Step 3: Derivation and Solution\n\nLet $S_1$ and $S_2$ be the events that sensor $1$ and sensor $2$ fail over the mission time, respectively. The single-sensor failure probability is given as $P(S_1) = P(S_2) = p$. The system is dual-redundant, meaning it fails only if both sensors fail. The system-level failure event is therefore the intersection $S_1 \\cap S_2$, and its probability is $P_f = P(S_1 \\cap S_2)$.\n\nThe problem states that sensor failures can arise from two mutually exclusive routes: common-cause failures (CCF) and idiosyncratic, sensor-specific failures. We can therefore decompose the system failure probability based on these routes.\n\nLet $p_{cc}$ be the portion of the single-sensor failure probability attributable to common causes, and $p_{id}$ be the portion attributable to idiosyncratic causes. According to the problem's definition of $\\beta$:\n-   The probability that a single sensor fails due to a common cause is $p_{cc} = \\beta p$.\n-   The probability that a single sensor fails due to an idiosyncratic cause is $p_{id} = (1 - \\beta)p$.\n\nThe total failure probability of a single sensor is conserved: $p = p_{cc} + p_{id} = \\beta p + (1-\\beta)p$.\n\nThe total system failure probability, $P_f$, is the sum of the probabilities of system failure through the two mutually exclusive routes:\n1.  System failure due to a common-cause event.\n2.  System failure due to the simultaneous occurrence of independent idiosyncratic failures in both sensors.\n\nLet's analyze each route:\n\n**Route 1: Common-Cause Failure (CCF)**\nThe problem defines $\\beta$ with respect to \"mechanisms that simultaneously incapacitate both redundant sensors\". A common-cause failure event, by this definition, compromises the entire redundant pair. The probability of such an event occurring and causing a single sensor to fail is given as $\\beta p$. Since this event incapacitates both sensors, the probability of the system failing due to a common cause is precisely this value.\n$$P_{\\text{system failure | CCF}} = \\beta p$$\n\n**Route 2: Independent Idiosyncratic Failures (IDF)**\nFor the system to fail via this route, both sensors must fail due to their own independent, specific causes. The probability for a single sensor to fail idiosyncratically is $p_{id} = (1-\\beta)p$.\nGiven the assumption that these failures are statistically independent, the probability that *both* sensors fail idiosyncratically is the product of their individual idiosyncratic failure probabilities:\n$$P_{\\text{system failure | IDF}} = P(\\text{S1 fails idio.}) \\times P(\\text{S2 fails idio.})$$\n$$P_{\\text{system failure | IDF}} = p_{id} \\times p_{id} = ((1-\\beta)p)^2 = (1-\\beta)^2 p^2$$\n\nSince these two failure routes are mutually exclusive, the total system-level failure probability $P_f$ is the sum of their probabilities:\n$$P_f = P_{\\text{system failure | CCF}} + P_{\\text{system failure | IDF}}$$\n$$P_f = \\beta p + (1-\\beta)^2 p^2$$\nThis is the derived mixture expression for the system-level failure probability, emphasizing the linear contribution from common-cause failures and the quadratic contribution from independent failures.\n\nNow, we compute the numerical value of $P_f$ for the given parameters: $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$.\n\nFirst, substitute the values into the derived expression:\n$$P_f = (0.30) \\times (1.1 \\times 10^{-4}) + (1 - 0.30)^2 \\times (1.1 \\times 10^{-4})^2$$\n\nCalculate the contribution from each term:\nThe common-cause failure term is:\n$$P_{\\text{CCF}} = 0.30 \\times 1.1 \\times 10^{-4} = 0.33 \\times 10^{-4} = 3.3 \\times 10^{-5}$$\n\nThe independent failure term is:\n$$(1 - 0.30)^2 = (0.70)^2 = 0.49$$\n$$(1.1 \\times 10^{-4})^2 = 1.21 \\times 10^{-8}$$\n$$P_{\\text{IDF}} = 0.49 \\times (1.21 \\times 10^{-8}) = 0.5929 \\times 10^{-8} = 5.929 \\times 10^{-9}$$\n\nSum the two contributions to find the total system failure probability:\n$$P_f = 3.3 \\times 10^{-5} + 5.929 \\times 10^{-9}$$\nTo add these, we can express them with the same power of $10$:\n$$P_f = 3.3 \\times 10^{-5} + 0.005929 \\times 10^{-5}$$\n$$P_f = (3.3 + 0.005929) \\times 10^{-5}$$\n$$P_f = 3.305929 \\times 10^{-5}$$\n\nThe problem requires the final answer to be expressed as a decimal rounded to four significant figures. The number is $3.305929 \\times 10^{-5}$. The first four significant figures are $3$, $3$, $0$, and $5$. The fifth significant digit is $9$, which is $5$ or greater, so we round up the fourth significant digit. The fourth digit, $5$, rounds up to $6$.\nThe rounded value is $3.306 \\times 10^{-5}$.\n\nExpressed as a decimal, this is:\n$$P_f \\approx 0.00003306$$",
            "answer": "$$\\boxed{0.00003306}$$"
        },
        {
            "introduction": "As CPS take on roles in allocating public resources, we must ensure their decisions are equitable and do not perpetuate societal biases. This practice  provides a direct method for auditing algorithmic fairness by applying the disparate impact ratio, a metric adapted from legal frameworks for equal opportunity. You will analyze hypothetical allocation data for a critical energy resilience service to determine if the system's outcomes exhibit bias, connecting abstract ethical principles of fairness to a concrete, data-driven evaluation.",
            "id": "4220340",
            "problem": "A city operates a Cyber-Physical System (CPS) for critical energy resilience that uses a Digital Twin (DT) to allocate real-time battery backup service tokens to households during grid stress events. To evaluate ethical fairness in service allocation, the city applies the disparate impact assessment drawn from the Equal Employment Opportunity Commission (EEOC) four-fifths rule, generalized to non-employment CPS resource provisioning.\n\nData aggregated over a stable operational window show two demographic groups: an unprivileged group $U$ and a privileged group $P$. The CPS processed $N_U$ applications from group $U$ and allocated tokens to $A_U$ applicants; it processed $N_P$ applications from group $P$ and allocated tokens to $A_P$ applicants. Over the period, the counts were $N_U = 950$, $A_U = 171$, $N_P = 800$, and $A_P = 184$.\n\nStarting from the frequentist interpretation of probability, the selection rate for any group is the ratio of allocated outcomes to total applicants. The disparate impact ratio is defined as the unprivileged group’s selection rate divided by the highest selection rate among the compared groups. Using this definition and the four-fifths ($0.8$) rule as the compliance heuristic, compute the disparate impact ratio from the provided counts and determine whether the allocation is compliant with the $0.8$ rule under this data.\n\nExpress your final answer as the disparate impact ratio in decimal form, rounded to four significant figures. Do not include any units. Provide no intermediate quantities in your final answer; only the disparate impact ratio itself should be reported.",
            "solution": "We begin from the frequentist interpretation of probability, where empirical rates are computed as counts of outcomes divided by counts of trials. For any group $G$, the selection rate $r_G$ is defined as the ratio of allocated cases to applicants:\n$$\nr_G = \\frac{A_G}{N_G}.\n$$\nUnder the disparate impact framework, the disparate impact ratio is defined as the unprivileged group’s selection rate divided by the highest selection rate among the compared groups. Let the unprivileged group be $U$ with selection rate $r_U$, and the privileged group be $P$ with selection rate $r_P$. Let\n$$\nr_{\\max} = \\max\\{r_U, r_P\\}.\n$$\nThen the disparate impact ratio $\\rho$ is\n$$\n\\rho = \\frac{r_U}{r_{\\max}}.\n$$\n\nWe first compute the selection rates using the given counts. For the unprivileged group $U$,\n$$\nr_U = \\frac{A_U}{N_U} = \\frac{171}{950}.\n$$\nWe check whether this fraction simplifies to a terminating decimal. Since $950 = 2 \\times 5^{2} \\times 19$, we can directly compute:\n$$\n\\frac{171}{950} = 0.18.\n$$\nFor the privileged group $P$,\n$$\nr_P = \\frac{A_P}{N_P} = \\frac{184}{800}.\n$$\nSince $800 = 2^{5} \\times 5^{2}$, we compute:\n$$\n\\frac{184}{800} = 0.23.\n$$\n\nNow we compute $r_{\\max}$:\n$$\nr_{\\max} = \\max\\{0.18, 0.23\\} = 0.23.\n$$\nTherefore,\n$$\n\\rho = \\frac{r_U}{r_{\\max}} = \\frac{0.18}{0.23}.\n$$\nWe express this ratio as an exact fraction first. Note that $0.18 = \\frac{18}{100}$ and $0.23 = \\frac{23}{100}$, so\n$$\n\\rho = \\frac{\\frac{18}{100}}{\\frac{23}{100}} = \\frac{18}{23}.\n$$\nCompute the decimal expansion:\n$$\n\\frac{18}{23} \\approx 0.7826086956\\ldots\n$$\nRounding $\\rho$ to four significant figures yields:\n$$\n\\rho \\approx 0.7826.\n$$\n\nTo test compliance with the four-fifths rule, compare $\\rho$ with $0.8$:\n$$\n0.7826 < 0.8,\n$$\nwhich indicates non-compliance under the $0.8$ rule for these counts. The problem requests the final answer to be the disparate impact ratio only, rounded to four significant figures. Hence, we report $0.7826$.",
            "answer": "$$\\boxed{0.7826}$$"
        },
        {
            "introduction": "Designing a responsible CPS involves navigating complex trade-offs between performance, safety, and fairness. This hands-on coding exercise  places you in the role of a system designer tasked with evaluating an interpretable, rule-based controller. By simulating the system's behavior for different demographic groups and quantifying its performance using a composite social loss function, you will develop a practical appreciation for the challenges of multi-objective optimization in real-world ethical engineering.",
            "id": "4220301",
            "problem": "You are given a discrete-time, single-input, single-output linear time-invariant plant that models a simplified cyber-physical system. The state evolution is defined by the fundamental state-update equation\n$$\nx_{t+1} = a \\, x_t + b \\, u_t + w_t,\n$$\nwhere $x_t$ is the scalar state at discrete time $t$, $u_t$ is the scalar control input, $a$ and $b$ are constant coefficients, and $w_t$ is a known disturbance sequence. The goal is to track a known reference sequence $\\{r_t\\}_{t=0}^{T-1}$ while respecting safety constraints, using an interpretable rule-based policy. The interpretability stems from a small number of simple, human-understandable rules based on the tracking error and a context variable.\n\nDefine the tracking error as\n$$\ne_t = r_t - x_t.\n$$\nThe controller is a rule-based policy with three regimes, parameterized by thresholds and gains, and augmented by a linear context term. Let $c \\in \\{-1, +1\\}$ denote a binary context indicator for two distinct groups. The policy operates as follows:\n- If $\\lvert e_t \\rvert \\ge \\theta_{\\mathrm{hi}}$, use the high-gain rule $u_t^{\\mathrm{raw}} = k_{\\mathrm{hi}} \\, e_t + b_{\\mathrm{ctx}} \\, c$.\n- Else if $\\lvert e_t \\rvert \\le \\theta_{\\mathrm{lo}}$, use the low-gain rule $u_t^{\\mathrm{raw}} = k_{\\mathrm{lo}} \\, e_t + b_{\\mathrm{ctx}} \\, c$.\n- Else, use the mid-gain rule $u_t^{\\mathrm{raw}} = k_{\\mathrm{mid}} \\, e_t + b_{\\mathrm{ctx}} \\, c$.\n\nTo reflect actuator limitations, the applied control is saturated at a limit $U_{\\mathrm{sat}}$:\n$$\nu_t = \\mathrm{clip}\\left(u_t^{\\mathrm{raw}}, -U_{\\mathrm{sat}}, U_{\\mathrm{sat}}\\right).\n$$\n\nSafety is assessed by two constraints: a state safety bound $\\lvert x_t \\rvert \\le X_{\\max}$ and a control safety bound $\\lvert u_t \\rvert \\le U_{\\mathrm{safe}}$. Note that $U_{\\mathrm{safe}}$ may be less than or equal to $U_{\\mathrm{sat}}$; violating $U_{\\mathrm{safe}}$ incurs a safety violation even if the actuator can physically apply $u_t$ due to $U_{\\mathrm{sat}}$.\n\nYou must evaluate the following performance metrics over a finite horizon of length $T$ for two contexts $c \\in \\{-1, +1\\}$, each simulated with identical plant, reference, and disturbance sequences:\n- Group-specific root-mean-squared error (RMSE):\n$$\n\\mathrm{RMSE}(c) = \\sqrt{\\frac{1}{T} \\sum_{t=0}^{T-1} e_t(c)^2}.\n$$\n- Overall RMSE averaged across the two groups:\n$$\n\\mathrm{RMSE}_{\\mathrm{overall}} = \\frac{1}{2}\\left(\\mathrm{RMSE}(+1) + \\mathrm{RMSE}(-1)\\right).\n$$\n- Fairness disparity as the absolute difference of group RMSEs:\n$$\n\\Delta_{\\mathrm{fair}} = \\left| \\mathrm{RMSE}(+1) - \\mathrm{RMSE}(-1) \\right|.\n$$\n- Safety violation rate as the fraction of time steps across both groups where either the state or the control violates its safety bound:\n$$\n\\rho_{\\mathrm{viol}} = \\frac{1}{2T} \\sum_{c \\in \\{-1,+1\\}} \\sum_{t=0}^{T-1} \\mathbf{1}\\left( \\lvert x_t(c) \\rvert > X_{\\max} \\ \\ \\text{or} \\ \\ \\lvert u_t(c) \\rvert > U_{\\mathrm{safe}} \\right),\n$$\nwhere $\\mathbf{1}(\\cdot)$ is the indicator function.\n\nTo quantify trade-offs among performance, safety, and fairness, define a composite social loss with nonnegative weights $\\alpha, \\beta, \\gamma$:\n$$\nL = \\alpha \\, \\mathrm{RMSE}_{\\mathrm{overall}} + \\beta \\, \\rho_{\\mathrm{viol}} + \\gamma \\, \\Delta_{\\mathrm{fair}}.\n$$\n\nAssume the following base conditions for all simulations:\n- The initial state is $x_0 = 0$.\n- The same reference sequence $\\{r_t\\}$ and disturbance sequence $\\{w_t\\}$ are used for both contexts $c \\in \\{-1, +1\\}$ within a test case.\n- The error $e_t$ at time $t$ is computed using the current state $x_t$, the control $u_t$ is computed from the rules and applied, and then the next state $x_{t+1}$ is computed via the plant equation.\n\nYour task is to implement a program that, for each test case below, simulates the two-group closed loop, computes $\\mathrm{RMSE}_{\\mathrm{overall}}$, $\\rho_{\\mathrm{viol}}$, $\\Delta_{\\mathrm{fair}}$, and $L$, and outputs these values rounded to $6$ decimal places.\n\nTest suite:\n- Case $1$ (happy path with mild context bias and ample safety margins):\n  - Plant: $a = 0.9$, $b = 0.4$, horizon $T = 60$.\n  - Reference: step sequence $r_t = 0$ for $t < 10$, and $r_t = 1.0$ for $t \\ge 10$.\n  - Disturbance: $w_t = 0.02 \\sin\\left( \\frac{2\\pi t}{15} \\right)$ for $t = 0, \\dots, 59$.\n  - Controller thresholds: $\\theta_{\\mathrm{lo}} = 0.05$, $\\theta_{\\mathrm{hi}} = 0.5$.\n  - Gains: $k_{\\mathrm{lo}} = 0.3$, $k_{\\mathrm{mid}} = 0.8$, $k_{\\mathrm{hi}} = 1.2$.\n  - Context bias: $b_{\\mathrm{ctx}} = 0.1$.\n  - Saturation and safety: $U_{\\mathrm{sat}} = 2.0$, $U_{\\mathrm{safe}} = 1.5$, $X_{\\max} = 2.0$.\n  - Weights: $\\alpha = 1.0$, $\\beta = 3.0$, $\\gamma = 2.0$.\n- Case $2$ (tighter safety, more aggressive high-gain, expect constraint pressure):\n  - Plant: $a = 0.9$, $b = 0.4$, horizon $T = 60$.\n  - Reference: step sequence $r_t = 0$ for $t < 10$, and $r_t = 1.0$ for $t \\ge 10$.\n  - Disturbance: $w_t = 0.02 \\sin\\left( \\frac{2\\pi t}{15} \\right)$.\n  - Controller thresholds: $\\theta_{\\mathrm{lo}} = 0.05$, $\\theta_{\\mathrm{hi}} = 0.5$.\n  - Gains: $k_{\\mathrm{lo}} = 0.3$, $k_{\\mathrm{mid}} = 0.8$, $k_{\\mathrm{hi}} = 1.5$.\n  - Context bias: $b_{\\mathrm{ctx}} = 0.15$.\n  - Saturation and safety: $U_{\\mathrm{sat}} = 2.0$, $U_{\\mathrm{safe}} = 0.7$, $X_{\\max} = 1.0$.\n  - Weights: $\\alpha = 1.0$, $\\beta = 3.0$, $\\gamma = 2.0$.\n- Case $3$ (fairness-neutral policy via zero context bias, conservative gains):\n  - Plant: $a = 0.95$, $b = 0.3$, horizon $T = 60$.\n  - Reference: ramped step $r_t = 0$ for $t < 5$, $r_t = 0.5$ for $5 \\le t < 30$, and $r_t = 1.0$ for $t \\ge 30$.\n  - Disturbance: $w_t = 0$ for all $t$.\n  - Controller thresholds: $\\theta_{\\mathrm{lo}} = 0.02$, $\\theta_{\\mathrm{hi}} = 0.3$.\n  - Gains: $k_{\\mathrm{lo}} = 0.2$, $k_{\\mathrm{mid}} = 0.5$, $k_{\\mathrm{hi}} = 0.7$.\n  - Context bias: $b_{\\mathrm{ctx}} = 0.0$.\n  - Saturation and safety: $U_{\\mathrm{sat}} = 1.0$, $U_{\\mathrm{safe}} = 1.0$, $X_{\\max} = 2.0$.\n  - Weights: $\\alpha = 1.0$, $\\beta = 3.0$, $\\gamma = 2.0$.\n- Case $4$ (higher disturbance environment, moderate gains, moderate safety):\n  - Plant: $a = 0.9$, $b = 0.4$, horizon $T = 60$.\n  - Reference: sinusoidal around a setpoint $r_t = 0.8 + 0.2 \\sin\\left( \\frac{2\\pi t}{20} \\right)$.\n  - Disturbance: $w_t = 0.2 \\sin\\left( \\frac{2\\pi t}{10} \\right)$.\n  - Controller thresholds: $\\theta_{\\mathrm{lo}} = 0.05$, $\\theta_{\\mathrm{hi}} = 0.4$.\n  - Gains: $k_{\\mathrm{lo}} = 0.4$, $k_{\\mathrm{mid}} = 0.9$, $k_{\\mathrm{hi}} = 1.1$.\n  - Context bias: $b_{\\mathrm{ctx}} = 0.05$.\n  - Saturation and safety: $U_{\\mathrm{sat}} = 2.0$, $U_{\\mathrm{safe}} = 1.2$, $X_{\\max} = 1.2$.\n  - Weights: $\\alpha = 1.0$, $\\beta = 3.0$, $\\gamma = 2.0$.\n\nYour program should produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets. For each case, return a list with four floats in the order $[\\mathrm{RMSE}_{\\mathrm{overall}}, \\rho_{\\mathrm{viol}}, \\Delta_{\\mathrm{fair}}, L]$, each rounded to $6$ decimal places. Thus the final output should be a list of lists, for example: $[[x_1, y_1, z_1, \\ell_1],[x_2, y_2, z_2, \\ell_2],[x_3, y_3, z_3, \\ell_3],[x_4, y_4, z_4, \\ell_4]]$.",
            "solution": "The problem requires the simulation of a discrete-time, single-input, single-output (SISO) linear time-invariant (LTI) system under a rule-based feedback controller. The simulation is to be performed for two distinct context groups, and several performance, safety, and fairness metrics are to be calculated, culminating in a composite social loss function. The problem is well-posed, scientifically grounded, and contains all necessary information for a unique solution.\n\nFirst, we must formalize the simulation procedure for a single context group, identified by the binary context indicator $c \\in \\{-1, +1\\}$. The system state evolves over a finite time horizon $T$.\n\nThe state of the system at time $t=0, 1, \\dots, T$ is denoted by $x_t$. The initial state is given as $x_0 = 0$. The simulation proceeds iteratively for each time step $t$ from $0$ to $T-1$.\n\nFor each time step $t \\in \\{0, 1, \\dots, T-1\\}$:\n1.  **Compute Tracking Error**: The tracking error $e_t$ is the difference between the reference signal $r_t$ and the current state $x_t$:\n    $$\n    e_t = r_t - x_t\n    $$\n2.  **Apply Rule-Based Control Policy**: A raw control input, $u_t^{\\mathrm{raw}}$, is determined based on the magnitude of the error $e_t$ and the context $c$. The policy is defined by three rules:\n    $$\n    u_t^{\\mathrm{raw}} =\n    \\begin{cases}\n    k_{\\mathrm{hi}} \\, e_t + b_{\\mathrm{ctx}} \\, c & \\text{if } \\lvert e_t \\rvert \\ge \\theta_{\\mathrm{hi}} \\\\\n    k_{\\mathrm{lo}} \\, e_t + b_{\\mathrm{ctx}} \\, c & \\text{if } \\lvert e_t \\rvert \\le \\theta_{\\mathrm{lo}} \\\\\n    k_{\\mathrm{mid}} \\, e_t + b_{\\mathrm{ctx}} \\, c & \\text{otherwise}\n    \\end{cases}\n    $$\n3.  **Apply Actuator Saturation**: The actual control input $u_t$ applied to the plant is the raw input clipped by the actuator's saturation limit, $U_{\\mathrm{sat}}$:\n    $$\n    u_t = \\mathrm{clip}\\left(u_t^{\\mathrm{raw}}, -U_{\\mathrm{sat}}, U_{\\mathrm{sat}}\\right) = \\max(-U_{\\mathrm{sat}}, \\min(u_t^{\\mathrm{raw}}, U_{\\mathrm{sat}}))\n    $$\n4.  **Assess Safety Violations**: At each time step $t$, we check if the state or the control input exceeds their respective safety bounds, $X_{\\max}$ and $U_{\\mathrm{safe}}$. A violation occurs if:\n    $$\n    \\lvert x_t \\rvert > X_{\\max} \\quad \\text{or} \\quad \\lvert u_t \\rvert > U_{\\mathrm{safe}}\n    $$\n    We must count the total number of such time steps.\n\n5.  **Update State**: The state of the system at the next time step, $x_{t+1}$, is calculated using the discrete-time state-update equation, incorporating the applied control $u_t$ and the known disturbance $w_t$:\n    $$\n    x_{t+1} = a \\, x_t + b \\, u_t + w_t\n    $$\n\nThis iterative process is performed for the entire horizon $t=0, \\dots, T-1$, generating trajectories for the state $\\{x_t\\}_{t=0}^{T}$, error $\\{e_t\\}_{t=0}^{T-1}$, and control $\\{u_t\\}_{t=0}^{T-1}$.\n\nThe entire simulation process is executed twice for each test case: once for context $c=+1$ and once for $c=-1$. This yields two sets of trajectories, e.g., $\\{x_t(+1)\\}$ and $\\{x_t(-1)\\}$.\n\nAfter both simulations are complete, we calculate the required metrics:\n\n- **Group-Specific Root-Mean-Squared Error (RMSE)**: For each context $c$, the RMSE is calculated as:\n  $$\n  \\mathrm{RMSE}(c) = \\sqrt{\\frac{1}{T} \\sum_{t=0}^{T-1} e_t(c)^2}\n  $$\n- **Overall RMSE**: This is the average of the two group-specific RMSEs:\n  $$\n  \\mathrm{RMSE}_{\\mathrm{overall}} = \\frac{1}{2}\\left(\\mathrm{RMSE}(+1) + \\mathrm{RMSE}(-1)\\right)\n  $$\n- **Fairness Disparity**: This is the absolute difference between the group-specific RMSEs:\n  $$\n  \\Delta_{\\mathrm{fair}} = \\left| \\mathrm{RMSE}(+1) - \\mathrm{RMSE}(-1) \\right|\n  $$\n- **Safety Violation Rate**: We first count the total number of violations for each group, let's call them $N_{\\mathrm{viol}}(c) = \\sum_{t=0}^{T-1} \\mathbf{1}(\\lvert x_t(c) \\rvert > X_{\\max} \\text{ or } \\lvert u_t(c) \\rvert > U_{\\mathrm{safe}})$. The rate is then the total violations over the total time steps across both groups:\n  $$\n  \\rho_{\\mathrm{viol}} = \\frac{N_{\\mathrm{viol}}(+1) + N_{\\mathrm{viol}}(-1)}{2T}\n  $$\n- **Composite Social Loss**: Finally, the social loss $L$ is a weighted sum of the above metrics:\n  $$\n  L = \\alpha \\, \\mathrm{RMSE}_{\\mathrm{overall}} + \\beta \\, \\rho_{\\mathrm{viol}} + \\gamma \\, \\Delta_{\\mathrm{fair}}\n  $$\n  where $\\alpha$, $\\beta$, and $\\gamma$ are given non-negative weights.\n\nThe implementation will consist of a main function to iterate through the test cases. For each case, it will call a simulation function that internally runs the process for $c=+1$ and $c=-1$, then computes and returns the four final metrics: $\\mathrm{RMSE}_{\\mathrm{overall}}$, $\\rho_{\\mathrm{viol}}$, $\\Delta_{\\mathrm{fair}}$, and $L$. The reference and disturbance sequences, $\\{r_t\\}$ and $\\{w_t\\}$, will be pre-calculated for each test case based on their functional forms.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1\n        {\n            \"a\": 0.9, \"b\": 0.4, \"T\": 60,\n            \"ref_spec\": (\"step\", {\"t_step\": 10, \"v_pre\": 0.0, \"v_post\": 1.0}),\n            \"dist_spec\": (\"sine\", {\"amp\": 0.02, \"period\": 15}),\n            \"theta_lo\": 0.05, \"theta_hi\": 0.5,\n            \"k_lo\": 0.3, \"k_mid\": 0.8, \"k_hi\": 1.2,\n            \"b_ctx\": 0.1,\n            \"U_sat\": 2.0, \"U_safe\": 1.5, \"X_max\": 2.0,\n            \"alpha\": 1.0, \"beta\": 3.0, \"gamma\": 2.0\n        },\n        # Case 2\n        {\n            \"a\": 0.9, \"b\": 0.4, \"T\": 60,\n            \"ref_spec\": (\"step\", {\"t_step\": 10, \"v_pre\": 0.0, \"v_post\": 1.0}),\n            \"dist_spec\": (\"sine\", {\"amp\": 0.02, \"period\": 15}),\n            \"theta_lo\": 0.05, \"theta_hi\": 0.5,\n            \"k_lo\": 0.3, \"k_mid\": 0.8, \"k_hi\": 1.5,\n            \"b_ctx\": 0.15,\n            \"U_sat\": 2.0, \"U_safe\": 0.7, \"X_max\": 1.0,\n            \"alpha\": 1.0, \"beta\": 3.0, \"gamma\": 2.0\n        },\n        # Case 3\n        {\n            \"a\": 0.95, \"b\": 0.3, \"T\": 60,\n            \"ref_spec\": (\"ramped_step\", {\"t1\": 5, \"v1\": 0.0, \"t2\": 30, \"v2\": 0.5, \"v3\": 1.0}),\n            \"dist_spec\": (\"zero\", {}),\n            \"theta_lo\": 0.02, \"theta_hi\": 0.3,\n            \"k_lo\": 0.2, \"k_mid\": 0.5, \"k_hi\": 0.7,\n            \"b_ctx\": 0.0,\n            \"U_sat\": 1.0, \"U_safe\": 1.0, \"X_max\": 2.0,\n            \"alpha\": 1.0, \"beta\": 3.0, \"gamma\": 2.0\n        },\n        # Case 4\n        {\n            \"a\": 0.9, \"b\": 0.4, \"T\": 60,\n            \"ref_spec\": (\"sine_offset\", {\"offset\": 0.8, \"amp\": 0.2, \"period\": 20}),\n            \"dist_spec\": (\"sine\", {\"amp\": 0.2, \"period\": 10}),\n            \"theta_lo\": 0.05, \"theta_hi\": 0.4,\n            \"k_lo\": 0.4, \"k_mid\": 0.9, \"k_hi\": 1.1,\n            \"b_ctx\": 0.05,\n            \"U_sat\": 2.0, \"U_safe\": 1.2, \"X_max\": 1.2,\n            \"alpha\": 1.0, \"beta\": 3.0, \"gamma\": 2.0\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        results.append(evaluate_case(params))\n\n    # Format the final output as a string representing a list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef generate_sequence(T, spec):\n    \"\"\"Generates reference or disturbance sequences.\"\"\"\n    seq_type, params = spec\n    t = np.arange(T)\n    if seq_type == \"step\":\n        seq = np.full(T, params[\"v_pre\"])\n        seq[params[\"t_step\"]:] = params[\"v_post\"]\n    elif seq_type == \"sine\":\n        seq = params[\"amp\"] * np.sin(2 * np.pi * t / params[\"period\"])\n    elif seq_type == \"ramped_step\":\n        seq = np.full(T, params[\"v1\"])\n        seq[params[\"t1\"]:params[\"t2\"]] = params[\"v2\"]\n        seq[params[\"t2\"]:] = params[\"v3\"]\n    elif seq_type == \"sine_offset\":\n        seq = params[\"offset\"] + params[\"amp\"] * np.sin(2 * np.pi * t / params[\"period\"])\n    elif seq_type == \"zero\":\n        seq = np.zeros(T)\n    return seq\n\ndef run_simulation(c, params, r_seq, w_seq):\n    \"\"\"\n    Runs the simulation for a single context group.\n    \n    Returns:\n        tuple: (RMSE for this group, number of violations for this group)\n    \"\"\"\n    T = params[\"T\"]\n    x = np.zeros(T + 1)\n    x[0] = 0.0\n    \n    errors = np.zeros(T)\n    violations = 0\n\n    for t in range(T):\n        # 1. Compute tracking error\n        e_t = r_seq[t] - x[t]\n        errors[t] = e_t\n\n        # 2. Apply rule-based control policy\n        e_abs = abs(e_t)\n        if e_abs >= params[\"theta_hi\"]:\n            k = params[\"k_hi\"]\n        elif e_abs <= params[\"theta_lo\"]:\n            k = params[\"k_lo\"]\n        else:\n            k = params[\"k_mid\"]\n        u_raw = k * e_t + params[\"b_ctx\"] * c\n        \n        # 3. Apply actuator saturation\n        u_t = np.clip(u_raw, -params[\"U_sat\"], params[\"U_sat\"])\n        \n        # 4. Assess safety violations\n        if abs(x[t]) > params[\"X_max\"] or abs(u_t) > params[\"U_safe\"]:\n            violations += 1\n            \n        # 5. Update state\n        x[t+1] = params[\"a\"] * x[t] + params[\"b\"] * u_t + w_seq[t]\n\n    rmse = np.sqrt(np.mean(errors**2))\n    return rmse, violations\n\ndef evaluate_case(params):\n    \"\"\"\n    Evaluates a single test case by running simulations for c = +1 and c = -1.\n    \n    Returns:\n        list: [RMSE_overall, rho_viol, Delta_fair, L] rounded to 6 decimal places.\n    \"\"\"\n    T = params[\"T\"]\n    r_seq = generate_sequence(T, params[\"ref_spec\"])\n    w_seq = generate_sequence(T, params[\"dist_spec\"])\n\n    # Run for context c = +1\n    rmse_p1, viol_p1 = run_simulation(1, params, r_seq, w_seq)\n    \n    # Run for context c = -1\n    rmse_n1, viol_n1 = run_simulation(-1, params, r_seq, w_seq)\n\n    # Calculate metrics\n    rmse_overall = (rmse_p1 + rmse_n1) / 2.0\n    delta_fair = abs(rmse_p1 - rmse_n1)\n    rho_viol = (viol_p1 + viol_n1) / (2.0 * T)\n    \n    # Calculate composite loss\n    loss = (params[\"alpha\"] * rmse_overall + \n            params[\"beta\"] * rho_viol + \n            params[\"gamma\"] * delta_fair)\n\n    return [round(val, 6) for val in [rmse_overall, rho_viol, delta_fair, loss]]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}