{
    "hands_on_practices": [
        {
            "introduction": "Building immersive digital twins of large-scale environments requires managing vast amounts of geometric data. A common optimization is to reduce the numerical precision of vertex coordinates, but this introduces quantization errors. This exercise will guide you through a practical analysis of this trade-off, where you will determine the minimum viewing distance at which these geometric errors become imperceptible on a high-resolution display, directly linking data compression techniques to visual fidelity in the metaverse .",
            "id": "4227321",
            "problem": "An immersive, metaverse-integrated digital twin of a large industrial campus is represented by a triangular mesh whose vertex coordinates in world space are currently stored as $32$-bit binary floating-point numbers. To reduce memory and bandwidth, the system proposes converting these coordinates to $16$-bit half-precision numbers following the Institute of Electrical and Electronics Engineers (IEEE) $754$ half-precision binary interchange format. The campus can be enclosed within an axis-aligned cube centered at the origin with side length $2S$ and half-side $S = 1200$ meters. A user views the scene with a pinhole camera having horizontal Field-of-View (FOV) equal to $90$ degrees and a screen width of $W = 3840$ pixels. Consider worst-case viewing and orientation in which small object-space displacements orthogonal to the viewing direction produce the largest screen-space motion.\n\nStarting from the formal definition of the IEEE $754$ half-precision format and the pinhole camera model, derive a bound on the worst-case object-space vertex displacement magnitude introduced by quantization when converting from $32$-bit floats to $16$-bit half floats. Then, using the perspective projection and a first-order small-displacement approximation, determine the minimum camera distance $D_{\\mathrm{min}}$ such that the induced screen-space error from this worst-case quantization does not exceed $0.25$ pixel. Report only the value of $D_{\\mathrm{min}}$ and express it in meters. Round your answer to three significant figures.",
            "solution": "This problem requires a multi-step analysis combining principles of numerical representation (IEEE $754$ floating-point), geometry, and optics (pinhole camera model). The objective is to find the minimum camera distance $D_{\\mathrm{min}}$ at which the visual artifact caused by coordinate quantization is limited to a specified sub-pixel threshold.\n\nFirst, we determine the worst-case object-space quantization error. The problem states that vertex coordinates are converted from $32$-bit single-precision floats to $16$-bit half-precision floats. The IEEE $754$ half-precision format (binary$16$) consists of $1$ sign bit, $5$ exponent bits (with a bias of $15$), and $10$ mantissa bits. The value of a normalized number is $v = (-1)^{\\text{sign}} \\times 2^{\\text{exponent}-15} \\times (1.\\text{mantissa})_2$.\n\nThe campus is enclosed in a cube with a half-side of $S = 1200$ meters. This means the maximum absolute value of any vertex coordinate component (e.g., $x, y, z$) is $1200$. The quantization error of a floating-point number depends on its magnitude. The worst-case error occurs for the numbers with the largest magnitude. We must therefore analyze the representation of numbers around $1200$.\n\nWe need to find the power-of-two interval that contains $1200$. We have $2^{10} = 1024$ and $2^{11} = 2048$. Thus, any coordinate component with magnitude near $1200$ lies in the interval $[2^{10}, 2^{11})$. For any number $x$ in this interval, the exponent value is $10$.\n\nThe precision of floating-point numbers is determined by the mantissa. The unit in the last place (ulp), which represents the gap between consecutive representable numbers, is given by $\\text{ulp} = 2^{\\text{exponent}} \\times 2^{-\\text{number of mantissa bits}}$. For the half-precision format, this is:\n$$ \\text{ulp} = 2^{10} \\times 2^{-10} = 1 $$\nWhen a $32$-bit float is converted to a $16$-bit float, it is typically rounded to the nearest representable $16$-bit value. The maximum rounding error for a single coordinate component is half the ulp. Let this error be $\\Delta_c$.\n$$ \\Delta_{c, \\text{max}} = \\frac{1}{2} \\text{ulp} = \\frac{1}{2} \\times 1 = 0.5 \\text{ meters} $$\nThe quantization introduces an error in each of the three spatial coordinates $(x, y, z)$. The worst-case vertex displacement occurs when the error is maximal for all three components. The resulting object-space displacement vector is $\\vec{\\delta}_o = (\\Delta_x, \\Delta_y, \\Delta_z)$, where each component has a maximum magnitude of $0.5$. The magnitude of this worst-case displacement vector is:\n$$ \\delta_o = |\\vec{\\delta}_o|_{\\text{max}} = \\sqrt{(\\Delta_{c, \\text{max}})^2 + (\\Delta_{c, \\text{max}})^2 + (\\Delta_{c, \\text{max}})^2} = \\sqrt{3 \\times (0.5)^2} = 0.5 \\sqrt{3} \\text{ meters} $$\n\nNext, we relate this object-space displacement $\\delta_o$ to the perceived screen-space error $\\delta_s$. We use a pinhole camera model. Let the camera be at a distance $D$ from an object vertex. Let the camera's viewing axis be the $Z$-axis. A point $(X, Y, Z)$ in camera space is projected onto an image plane. The problem specifies a horizontal Field-of-View (FOV) of $90$ degrees and a screen width of $W = 3840$ pixels.\n\nFor a pinhole camera, the projected horizontal position on the screen, $x_p$ (in pixels), of a point at a horizontal object-space coordinate $X_o$ and a distance (depth) $D$ from the camera is given by:\n$$ x_p = \\left( \\frac{W}{2} \\right) \\frac{X_o}{D \\tan(\\text{FOV}/2)} $$\nGiven $\\text{FOV} = 90^\\circ$, the half-FOV is $45^\\circ$, and $\\tan(45^\\circ) = 1$. The projection equation simplifies to:\n$$ x_p = \\frac{W X_o}{2 D} $$\nThe problem asks for a first-order approximation of the screen-space error. A small object-space displacement $\\Delta X_o$ results in a screen-space displacement $\\Delta x_p$:\n$$ \\Delta x_p \\approx \\frac{\\partial x_p}{\\partial X_o} \\Delta X_o = \\frac{W}{2 D} \\Delta X_o $$\nThe problem specifies the \"worst-case viewing and orientation\". This occurs when the object-space displacement vector $\\vec{\\delta}_o$ is entirely perpendicular to the camera's viewing axis. In this configuration, the full magnitude of the displacement, $\\delta_o$, contributes to the motion projected onto the screen. Any component of displacement parallel to the viewing axis would result in a second-order change in size (perspective distortion), which is negligible for a small displacement. Thus, we set the effective object-space displacement to $\\delta_o$. The magnitude of the screen-space error, $\\delta_s$, is:\n$$ \\delta_s = \\frac{W \\delta_o}{2 D} $$\nWe are given the constraint that this screen-space error must not exceed $0.25$ pixels:\n$$ \\delta_s \\le 0.25 $$\nSubstituting the expression for $\\delta_s$:\n$$ \\frac{W \\delta_o}{2 D} \\le 0.25 $$\nWe need to find the minimum camera distance $D_{\\mathrm{min}}$ that satisfies this condition. We solve the inequality for $D$:\n$$ D \\ge \\frac{W \\delta_o}{2 \\times 0.25} = \\frac{W \\delta_o}{0.5} = 2 W \\delta_o $$\nThe minimum distance is therefore:\n$$ D_{\\mathrm{min}} = 2 W \\delta_o $$\nNow, we substitute the known values: $W=3840$ and $\\delta_o = 0.5\\sqrt{3}$ meters.\n$$ D_{\\mathrm{min}} = 2 \\times 3840 \\times (0.5 \\sqrt{3}) = 3840 \\sqrt{3} $$\nTo obtain the final numerical answer, we compute this value and round to three significant figures as requested.\n$$ D_{\\mathrm{min}} = 3840 \\times \\sqrt{3} \\approx 3840 \\times 1.73205 \\approx 6651.072 $$\nRounding to three significant figures, we get $6650$ meters. This can be expressed in scientific notation to make the number of significant figures unambiguous.\n$$ D_{\\mathrm{min}} \\approx 6.65 \\times 10^3 \\text{ meters} $$",
            "answer": "$$\n\\boxed{6.65 \\times 10^{3}}\n$$"
        },
        {
            "introduction": "Beyond static geometry, many digital twins incorporate dynamic physical simulations to model behavior like acoustics or fluid dynamics. For a seamless immersive experience, these simulations must run stably in real-time, synchronized with the rendering frame rate. This practice delves into the core of this challenge, asking you to derive the Courant-Friedrichs-Lewy (CFL) stability condition for a wave simulation and translate it into a minimum required frame rate for the VR application .",
            "id": "4227334",
            "problem": "A metaverse-integrated digital twin of an industrial pipeline drives spatialized audio and haptic feedback in Virtual Reality (VR) by simulating one-dimensional acoustic waves along the pipe axis. The acoustic field is modeled by the one-dimensional linear wave equation, where the acoustic pressure field $u(x,t)$ satisfies $\\frac{\\partial^{2} u}{\\partial t^{2}} = c^{2} \\frac{\\partial^{2} u}{\\partial x^{2}}$, with sound speed $c$. The simulation domain has length $L$ and is discretized uniformly into $N$ grid points, so the grid spacing is $\\Delta x = \\frac{L}{N-1}$. The solver uses a fully explicit, second-order accurate, centered finite-difference scheme in time and space. The metaverse rendering engine couples one simulation update per rendered frame, so the simulation time step equals the inter-frame interval, $\\Delta t = \\frac{1}{F}$, where $F$ is the render frame rate.\n\nUsing the wave equation as the fundamental model and performing a discrete stability analysis appropriate for explicit centered schemes (for example, a von Neumann analysis), derive the stability constraint on $\\Delta t$ in terms of $c$ and $\\Delta x$. Then translate this constraint into a requirement on $F$ that guarantees stability when one simulation step is taken per frame. Finally, for the following twin parameters, compute the minimum stable frame rate:\n- Speed of sound $c = 343\\ \\mathrm{m}\\ \\mathrm{s}^{-1}$,\n- Pipeline length $L = 30\\ \\mathrm{m}$,\n- Number of grid points $N = 11$.\n\nExpress your final frame rate in $\\mathrm{s}^{-1}$ and round your answer to four significant figures.",
            "solution": "The problem asks for the minimum stable frame rate for a numerical simulation of the one-dimensional linear wave equation, which is given as:\n$$ \\frac{\\partial^{2} u}{\\partial t^{2}} = c^{2} \\frac{\\partial^{2} u}{\\partial x^{2}} $$\nwhere $u(x,t)$ is the acoustic pressure field, and $c$ is the speed of sound.\n\nThe simulation employs a fully explicit, second-order accurate, centered finite-difference scheme in both time and space. Let the discrete grid be defined by points $(x_j, t_n)$ where $x_j = j \\Delta x$ and $t_n = n \\Delta t$, with $j$ and $n$ being integers. The numerical approximation of $u(x_j, t_n)$ is denoted by $u_j^n$.\n\nThe second partial derivative with respect to time, $\\frac{\\partial^{2} u}{\\partial t^{2}}$, is approximated by the centered difference:\n$$ \\frac{\\partial^{2} u}{\\partial t^{2}} \\approx \\frac{u_j^{n+1} - 2u_j^n + u_j^{n-1}}{(\\Delta t)^2} $$\nSimilarly, the second partial derivative with respect to space, $\\frac{\\partial^{2} u}{\\partial x^{2}}$, is approximated by:\n$$ \\frac{\\partial^{2} u}{\\partial x^{2}} \\approx \\frac{u_{j+1}^n - 2u_j^n + u_{j-1}^n}{(\\Delta x)^2} $$\nSubstituting these approximations into the wave equation gives the discrete finite-difference equation:\n$$ \\frac{u_j^{n+1} - 2u_j^n + u_j^{n-1}}{(\\Delta t)^2} = c^2 \\frac{u_{j+1}^n - 2u_j^n + u_{j-1}^n}{(\\Delta x)^2} $$\nTo find the update rule for $u_j^{n+1}$, we rearrange the terms:\n$$ u_j^{n+1} = 2u_j^n - u_j^{n-1} + \\frac{c^2 (\\Delta t)^2}{(\\Delta x)^2} (u_{j+1}^n - 2u_j^n + u_{j-1}^n) $$\nIt is standard to define the Courant number, $\\sigma$, as the dimensionless ratio:\n$$ \\sigma = \\frac{c \\Delta t}{\\Delta x} $$\nSubstituting $\\sigma$ into the update equation, we get:\n$$ u_j^{n+1} = 2u_j^n - u_j^{n-1} + \\sigma^2 (u_{j+1}^n - 2u_j^n + u_{j-1}^n) $$\n$$ u_j^{n+1} = 2(1 - \\sigma^2)u_j^n + \\sigma^2(u_{j+1}^n + u_{j-1}^n) - u_j^{n-1} $$\nTo determine the stability of this explicit scheme, we perform a von Neumann stability analysis. We consider the evolution of a single Fourier mode of the solution, represented as:\n$$ u_j^n = G^n e^{i k x_j} = G^n e^{i k j \\Delta x} $$\nwhere $k$ is the wavenumber and $G=G(k)$ is the amplification factor per time step. For the scheme to be stable, the magnitude of the amplification factor must not exceed unity for any wavenumber, i.e., $|G| \\leq 1$.\n\nSubstituting the trial solution into the finite-difference equation:\n$$ G^{n+1}e^{ikj\\Delta x} = 2(1 - \\sigma^2)G^n e^{ikj\\Delta x} + \\sigma^2(G^n e^{ik(j+1)\\Delta x} + G^n e^{ik(j-1)\\Delta x}) - G^{n-1}e^{ikj\\Delta x} $$\nDividing through by $G^{n-1}e^{ikj\\Delta x}$ yields a characteristic equation for $G$:\n$$ G^2 = 2(1 - \\sigma^2)G + \\sigma^2(G e^{ik\\Delta x} + G e^{-ik\\Delta x}) - 1 $$\nUsing Euler's formula, $e^{i\\theta} + e^{-i\\theta} = 2\\cos(\\theta)$, the expression simplifies to:\n$$ G^2 = 2G(1 - \\sigma^2) + 2G\\sigma^2 \\cos(k\\Delta x) - 1 $$\n$$ G^2 - 2G(1 - \\sigma^2 + \\sigma^2 \\cos(k\\Delta x)) + 1 = 0 $$\nUsing the half-angle identity $1 - \\cos(\\theta) = 2\\sin^2(\\frac{\\theta}{2})$, this becomes:\n$$ G^2 - 2G\\left(1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right)\\right) + 1 = 0 $$\nThis is a quadratic equation for $G$ of the form $aG^2+bG+c=0$. The roots are stable ($|G| \\leq 1$) if they are complex conjugates on the unit circle or real with magnitude at most $1$. This condition is met if the discriminant of the quadratic equation is non-positive, i.e., $b^2 - 4ac \\leq 0$.\n$$ \\left[-2\\left(1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right)\\right)\\right]^2 - 4(1)(1) \\leq 0 $$\n$$ 4\\left(1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right)\\right)^2 \\leq 4 $$\n$$ \\left(1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right)\\right)^2 \\leq 1 $$\nTaking the square root of both sides gives:\n$$ -1 \\leq 1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right) \\leq 1 $$\nThe right side of the inequality, $1 - 2\\sigma^2 \\sin^2(\\frac{k\\Delta x}{2}) \\leq 1$, simplifies to $-2\\sigma^2 \\sin^2(\\frac{k\\Delta x}{2}) \\leq 0$, which is always true since $\\sigma^2 \\ge 0$ and $\\sin^2(\\cdot) \\ge 0$.\nThe left side provides the actual stability constraint:\n$$ -1 \\leq 1 - 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right) $$\n$$ 2\\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right) \\leq 2 $$\n$$ \\sigma^2 \\sin^2\\left(\\frac{k\\Delta x}{2}\\right) \\leq 1 $$\nThis inequality must hold for all possible wavenumbers $k$. The term $\\sin^2\\left(\\frac{k\\Delta x}{2}\\right)$ has a maximum value of $1$. To ensure stability under the worst-case scenario, we set this term to its maximum:\n$$ \\sigma^2 \\leq 1 \\implies \\sigma \\leq 1 $$\nThis is the renowned Courant-Friedrichs-Lewy (CFL) stability condition for this scheme. Substituting the definition of $\\sigma$:\n$$ \\frac{c \\Delta t}{\\Delta x} \\leq 1 $$\nThe stability constraint on the time step $\\Delta t$ is therefore:\n$$ \\Delta t \\leq \\frac{\\Delta x}{c} $$\nThe problem states that the simulation time step $\\Delta t$ is tied to the render frame rate $F$ by the relation $\\Delta t = \\frac{1}{F}$. Substituting this into the stability constraint:\n$$ \\frac{1}{F} \\leq \\frac{\\Delta x}{c} $$\nSolving for the frame rate $F$, we find the requirement for stability:\n$$ F \\geq \\frac{c}{\\Delta x} $$\nThis means the minimum stable frame rate, $F_{min}$, is:\n$$ F_{min} = \\frac{c}{\\Delta x} $$\nNow, we compute the numerical value for $F_{min}$ using the given parameters. First, we calculate the grid spacing $\\Delta x$:\n- Pipeline length $L = 30\\ \\mathrm{m}$\n- Number of grid points $N = 11$\nThe grid spacing is $\\Delta x = \\frac{L}{N-1}$.\n$$ \\Delta x = \\frac{30\\ \\mathrm{m}}{11 - 1} = \\frac{30\\ \\mathrm{m}}{10} = 3\\ \\mathrm{m} $$\nNext, we use the speed of sound $c = 343\\ \\mathrm{m}\\ \\mathrm{s}^{-1}$ to find the minimum stable frame rate:\n$$ F_{min} = \\frac{343\\ \\mathrm{m}\\ \\mathrm{s}^{-1}}{3\\ \\mathrm{m}} = \\frac{343}{3}\\ \\mathrm{s}^{-1} $$\n$$ F_{min} \\approx 114.333...\\ \\mathrm{s}^{-1} $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ F_{min} = 114.3\\ \\mathrm{s}^{-1} $$",
            "answer": "$$\\boxed{114.3}$$"
        },
        {
            "introduction": "The ultimate test of an immersive digital twin is its responsiveness to human interaction. The motion-to-photon latency—the total delay from user movement to visual update—is a critical performance metric that dictates the sense of presence and prevents user discomfort. In this final practice, you will perform a complete end-to-end latency budget analysis for a VR system interacting with an edge-computed digital twin, learning how to allocate time across sensing, networking, computation, and display stages to meet a strict performance target .",
            "id": "4227342",
            "problem": "A metaverse-integrated Digital Twin (DT) is visualized through a Virtual Reality (VR) headset. The control loop is closed through the VR user’s head motion, which is sensed, transmitted, simulated against the DT at the edge, rendered locally on the headset, and displayed on a sample-and-hold display. The system must meet a motion-to-photon (MTP) latency target strictly below $20\\,\\mathrm{ms}$. By MTP latency we mean the sum of the serial stage delays in the motion-to-photon pipeline. Assume the following scientifically grounded stage models based on core definitions of serial pipeline latency, sampling theory, and network delay composition:\n\n- Sensing: The headset’s inertial measurement unit samples at frequency $f_{s}=500\\,\\mathrm{Hz}$, so the sampling period is $T_{s}=1/f_{s}$. The expected sample-to-use delay is the average phase delay $T_{s}/2$. A sensor fusion pre-processing stage adds a fixed compute delay of $0.8\\,\\mathrm{ms}$.\n- Network uplink: A motion state packet of size $S_{\\mathrm{ul}}=12\\,\\mathrm{kB}$ is transmitted at rate $R_{\\mathrm{ul}}=200\\,\\mathrm{Mbit/s}$. The transmission time is $S_{\\mathrm{ul}}/R_{\\mathrm{ul}}$. The one-way propagation path to the edge is $d=5\\,\\mathrm{km}$ over fiber with propagation speed $v=2.0\\times 10^{8}\\,\\mathrm{m/s}$. The wireless last-hop access adds a fixed $0.6\\,\\mathrm{ms}$, and queuing adds $0.2\\,\\mathrm{ms}$.\n- Edge simulation: If simulation is offloaded, the DT physics and state-estimation compute on the edge require $2.2\\,\\mathrm{ms}$. If computed locally on the headset, this stage would require $7.5\\,\\mathrm{ms}$.\n- Network downlink: The updated state of size $S_{\\mathrm{dl}}=16\\,\\mathrm{kB}$ is transmitted at rate $R_{\\mathrm{dl}}=1.0\\,\\mathrm{Gbit/s}$, contributing $S_{\\mathrm{dl}}/R_{\\mathrm{dl}}$. The same one-way propagation, wireless access, and queuing delays as uplink apply.\n- Rendering: The shaded image is produced locally on the headset GPU, with rendering time $T_{\\mathrm{rend}}$ to be determined.\n- Display: The display refresh is $f_{\\mathrm{disp}}=120\\,\\mathrm{Hz}$. The expected v-sync quantization delay is $1/(2 f_{\\mathrm{disp}})$, and the pixel response time adds $0.8\\,\\mathrm{ms}$.\n\nAssume a serial pipeline where these stages add linearly to form the total MTP latency. Choose to offload only the simulation to the edge (not the rendering), and compute the maximum allowable rendering time $T_{\\mathrm{rend}}$ such that the total motion-to-photon latency is strictly below $20\\,\\mathrm{ms}$. Express your final numerical answer in milliseconds and round your answer to four significant figures.\n\nIn one or two sentences within your derivation, briefly justify which stage benefits most from edge offload in this configuration and why, but note that the graded final answer is only the rendering-time budget.",
            "solution": "The problem is to determine the maximum allowable rendering time, $T_{\\mathrm{rend}}$, such that the total motion-to-photon (MTP) latency, $L_{\\mathrm{MTP}}$, for a metaverse-integrated Digital Twin (DT) system is strictly below $20\\,\\mathrm{ms}$.\n\nThe total MTP latency is the sum of the serial stage delays:\n$$L_{\\mathrm{MTP}} = L_{\\mathrm{sense}} + L_{\\mathrm{uplink}} + L_{\\mathrm{sim}} + L_{\\mathrm{downlink}} + L_{\\mathrm{render}} + L_{\\mathrm{display}}$$\nThe constraint is given as $L_{\\mathrm{MTP}} < 20\\,\\mathrm{ms}$. We will calculate the latency for each stage, converting all time units to milliseconds ($\\mathrm{ms}$).\n\n1.  **Sensing Latency ($L_{\\mathrm{sense}}$)**:\n    The sampling frequency is $f_{s} = 500\\,\\mathrm{Hz}$. The sampling period is $T_{s} = 1/f_{s}$. The average sample-to-use delay is $T_{s}/2$.\n    $$\n    T_{s} = \\frac{1}{500\\,\\mathrm{Hz}} = 0.002\\,\\mathrm{s} = 2\\,\\mathrm{ms}\n    $$\n    The average sampling latency is $\\frac{T_{s}}{2} = \\frac{2\\,\\mathrm{ms}}{2} = 1\\,\\mathrm{ms}$.\n    An additional sensor fusion pre-processing delay is $0.8\\,\\mathrm{ms}$.\n    $$\n    L_{\\mathrm{sense}} = 1\\,\\mathrm{ms} + 0.8\\,\\mathrm{ms} = 1.8\\,\\mathrm{ms}\n    $$\n\n2.  **Network Uplink Latency ($L_{\\mathrm{uplink}}$)**:\n    This consists of transmission time, propagation time, wireless access delay, and queuing delay.\n    Transmission time is $S_{\\mathrm{ul}}/R_{\\mathrm{ul}}$, where $S_{\\mathrm{ul}}=12\\,\\mathrm{kB}$ and $R_{\\mathrm{ul}}=200\\,\\mathrm{Mbit/s}$.\n    $$\n    S_{\\mathrm{ul}} = 12\\,\\mathrm{kB} = 12 \\times 10^{3}\\,\\mathrm{bytes} \\times 8\\,\\frac{\\mathrm{bits}}{\\mathrm{byte}} = 96000\\,\\mathrm{bits}\n    $$\n    $$\n    R_{\\mathrm{ul}} = 200\\,\\mathrm{Mbit/s} = 200 \\times 10^{6}\\,\\mathrm{bits/s}\n    $$\n    $$\n    T_{\\mathrm{tx,ul}} = \\frac{S_{\\mathrm{ul}}}{R_{\\mathrm{ul}}} = \\frac{96000\\,\\mathrm{bits}}{200 \\times 10^{6}\\,\\mathrm{bits/s}} = 0.00048\\,\\mathrm{s} = 0.48\\,\\mathrm{ms}\n    $$\n    Propagation time is $d/v$, where $d=5\\,\\mathrm{km}$ and $v=2.0\\times 10^{8}\\,\\mathrm{m/s}$.\n    $$\n    T_{\\mathrm{prop}} = \\frac{d}{v} = \\frac{5 \\times 10^{3}\\,\\mathrm{m}}{2.0 \\times 10^{8}\\,\\mathrm{m/s}} = 2.5 \\times 10^{-5}\\,\\mathrm{s} = 0.025\\,\\mathrm{ms}\n    $$\n    The fixed delays are $0.6\\,\\mathrm{ms}$ (wireless) and $0.2\\,\\mathrm{ms}$ (queuing).\n    $$\n    L_{\\mathrm{uplink}} = T_{\\mathrm{tx,ul}} + T_{\\mathrm{prop}} + 0.6\\,\\mathrm{ms} + 0.2\\,\\mathrm{ms} = 0.48\\,\\mathrm{ms} + 0.025\\,\\mathrm{ms} + 0.8\\,\\mathrm{ms} = 1.305\\,\\mathrm{ms}\n    $$\n\n3.  **Edge Simulation Latency ($L_{\\mathrm{sim}}$)**:\n    The problem specifies to offload the simulation to the edge.\n    $$\n    L_{\\mathrm{sim}} = 2.2\\,\\mathrm{ms}\n    $$\n\n4.  **Network Downlink Latency ($L_{\\mathrm{downlink}}$)**:\n    Similar to the uplink, this is the sum of transmission, propagation, and fixed delays.\n    Transmission time is $S_{\\mathrm{dl}}/R_{\\mathrm{dl}}$, where $S_{\\mathrm{dl}}=16\\,\\mathrm{kB}$ and $R_{\\mathrm{dl}}=1.0\\,\\mathrm{Gbit/s}$.\n    $$\n    S_{\\mathrm{dl}} = 16\\,\\mathrm{kB} = 16 \\times 10^{3}\\,\\mathrm{bytes} \\times 8\\,\\frac{\\mathrm{bits}}{\\mathrm{byte}} = 128000\\,\\mathrm{bits}\n    $$\n    $$\n    R_{\\mathrm{dl}} = 1.0\\,\\mathrm{Gbit/s} = 1 \\times 10^{9}\\,\\mathrm{bits/s}\n    $$\n    $$\n    T_{\\mathrm{tx,dl}} = \\frac{S_{\\mathrm{dl}}}{R_{\\mathrm{dl}}} = \\frac{128000\\,\\mathrm{bits}}{1 \\times 10^{9}\\,\\mathrm{bits/s}} = 0.000128\\,\\mathrm{s} = 0.128\\,\\mathrm{ms}\n    $$\n    Propagation and fixed delays are the same as for the uplink.\n    $$\n    L_{\\mathrm{downlink}} = T_{\\mathrm{tx,dl}} + T_{\\mathrm{prop}} + 0.6\\,\\mathrm{ms} + 0.2\\,\\mathrm{ms} = 0.128\\,\\mathrm{ms} + 0.025\\,\\mathrm{ms} + 0.8\\,\\mathrm{ms} = 0.953\\,\\mathrm{ms}\n    $$\n\n5.  **Rendering Latency ($L_{\\mathrm{render}}$)**:\n    This is the unknown quantity to be determined.\n    $$\n    L_{\\mathrm{render}} = T_{\\mathrm{rend}}\n    $$\n\n6.  **Display Latency ($L_{\\mathrm{display}}$)**:\n    This is the sum of the v-sync quantization delay and the pixel response time.\n    The v-sync delay is $1/(2 f_{\\mathrm{disp}})$ for $f_{\\mathrm{disp}}=120\\,\\mathrm{Hz}$.\n    $$\n    \\text{V-sync delay} = \\frac{1}{2 \\times 120\\,\\mathrm{Hz}} = \\frac{1}{240}\\,\\mathrm{s} = \\frac{1000}{240}\\,\\mathrm{ms} = \\frac{25}{6}\\,\\mathrm{ms}\n    $$\n    The pixel response time is $0.8\\,\\mathrm{ms}$.\n    $$\n    L_{\\mathrm{display}} = \\left(\\frac{25}{6} + 0.8\\right)\\,\\mathrm{ms}\n    $$\n\nNow, we sum the known latencies and solve for $T_{\\mathrm{rend}}$.\n$$\nL_{\\mathrm{sense}} + L_{\\mathrm{uplink}} + L_{\\mathrm{sim}} + L_{\\mathrm{downlink}} + T_{\\mathrm{rend}} + L_{\\mathrm{display}} < 20\\,\\mathrm{ms}\n$$\n$$\n1.8\\,\\mathrm{ms} + 1.305\\,\\mathrm{ms} + 2.2\\,\\mathrm{ms} + 0.953\\,\\mathrm{ms} + T_{\\mathrm{rend}} + \\left(\\frac{25}{6} + 0.8\\right)\\,\\mathrm{ms} < 20\\,\\mathrm{ms}\n$$\nSumming the known numerical terms:\n$$\n1.8 + 1.305 + 2.2 + 0.953 + 0.8 = 7.058\n$$\nThe inequality becomes:\n$$\n7.058\\,\\mathrm{ms} + \\frac{25}{6}\\,\\mathrm{ms} + T_{\\mathrm{rend}} < 20\\,\\mathrm{ms}\n$$\n$$\n7.058 + 4.1666... + T_{\\mathrm{rend}} < 20\n$$\n$$\n11.224666...\\,\\mathrm{ms} + T_{\\mathrm{rend}} < 20\\,\\mathrm{ms}\n$$\nTo find the maximum allowable rendering time, we solve for $T_{\\mathrm{rend}}$:\n$$\nT_{\\mathrm{rend}} < 20\\,\\mathrm{ms} - 11.224666...\\,\\mathrm{ms}\n$$\n$$\nT_{\\mathrm{rend}} < 8.775333...\\,\\mathrm{ms}\n$$\nThe maximum allowable value is the supremum of this range. In this context, it is the value $20\\,\\mathrm{ms} - (7.058 + \\frac{25}{6})\\,\\mathrm{ms} = \\frac{13163}{1500}\\,\\mathrm{ms} \\approx 8.775333...\\,\\mathrm{ms}$.\n\nThe simulation stage benefits most from the edge offload because its local compute time of $7.5\\,\\mathrm{ms}$ represents the single largest delay in the potential pipeline, and replacing it with the total offload path time ($L_{\\mathrm{uplink}} + L_{\\mathrm{sim}} + L_{\\mathrm{downlink}} = 1.305 + 2.2 + 0.953 = 4.458\\,\\mathrm{ms}$) yields a substantial net latency reduction of $7.5 - 4.458 = 3.042\\,\\mathrm{ms}$.\n\nRounding the maximum allowable rendering time to four significant figures:\n$$\nT_{\\mathrm{rend,max}} \\approx 8.775\\,\\mathrm{ms}\n$$",
            "answer": "$$\n\\boxed{8.775}\n$$"
        }
    ]
}