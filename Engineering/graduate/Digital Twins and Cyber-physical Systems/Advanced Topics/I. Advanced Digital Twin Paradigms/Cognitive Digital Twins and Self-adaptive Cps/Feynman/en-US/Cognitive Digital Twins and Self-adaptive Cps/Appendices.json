{
    "hands_on_practices": [
        {
            "introduction": "A Cognitive Digital Twin's primary function is to maintain an accurate, real-time understanding of its physical counterpart's state. This practice delves into the heart of state estimation by exploring the Kalman Filter, the cornerstone algorithm for fusing model-based predictions with noisy sensor data . By working through the derivation and application of the filter's update step, you will gain insight into how a digital twin can infer latent variables and reduce uncertainty, forming the basis for all subsequent reasoning and control actions.",
            "id": "4208983",
            "problem": "A cognitive digital twin for a self-adaptive Cyber-Physical System (CPS) performs online state estimation of a two-dimensional latent state using a single scalar sensor. The digital twin employs the optimal linear Minimum Mean Square Error estimator derived from the linear-Gaussian Bayesian conditioning principle, commonly instantiated as the Kalman Filter (KF). At time index $k$, the prior belief over the state is Gaussian with mean $\\hat{x}_{k}^{-}$ and covariance $P_{k}^{-}$, and the measurement model is linear with additive Gaussian noise:\n$$\ny_{k} = H x_{k} + v_{k}, \\quad v_{k} \\sim \\mathcal{N}(0, R),\n$$\nwhere $H \\in \\mathbb{R}^{1 \\times 2}$ and $R \\in \\mathbb{R}$.\n\nStarting from the core definitions of linear-Gaussian models and Bayesian conditioning, derive the optimal linear gain $K_{k}$ and the posterior covariance $P_{k}^{+}$ of the state estimate after assimilating $y_{k}$, expressed solely in terms of $H$, $P_{k}^{-}$, and $R$. Then evaluate the posterior covariance numerically for the scientifically plausible parameters\n$$\nP_{k}^{-} = \\begin{bmatrix}2 & 0\\\\ 0 & 1\\end{bmatrix}, \\quad H = \\begin{bmatrix}1 & 0\\end{bmatrix}, \\quad R = 1.\n$$\nProvide the final posterior covariance as an exact matrix with no rounding. No physical units are required for this computation.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of Bayesian state estimation and the Kalman Filter, is mathematically well-posed with all necessary information provided, and is formulated objectively. We will proceed with the derivation and numerical evaluation.\n\nThe goal is to find the optimal linear estimator for the state $x_k \\in \\mathbb{R}^2$ given a prior belief and a linear measurement. The posterior estimate, $\\hat{x}_k^+$, is a linear function of the prior estimate, $\\hat{x}_k^-$, and the new measurement, $y_k$. The update is of the form:\n$$\n\\hat{x}_k^+ = \\hat{x}_k^- + K_k (y_k - \\hat{y}_k^-)\n$$\nwhere $K_k$ is the gain matrix to be determined, and $\\hat{y}_k^-$ is the predicted measurement based on the prior. The predicted measurement is the expectation of $y_k$ given the prior information:\n$$\n\\hat{y}_k^- = E[y_k] = E[H x_k + v_k] = H E[x_k] + E[v_k] = H \\hat{x}_k^- + 0 = H \\hat{x}_k^-\n$$\nThe term $y_k - \\hat{y}_k^-$ is the innovation or measurement residual. The posterior estimate is thus:\n$$\n\\hat{x}_k^+ = \\hat{x}_k^- + K_k (y_k - H \\hat{x}_k^-)\n$$\nThe posterior estimation error is $e_k^+ = x_k - \\hat{x}_k^+$. Substituting the expression for $\\hat{x}_k^+$:\n$$\ne_k^+ = x_k - \\left( \\hat{x}_k^- + K_k (y_k - H \\hat{x}_k^-) \\right)\n$$\nSubstituting the measurement model $y_k = H x_k + v_k$:\n$$\ne_k^+ = (x_k - \\hat{x}_k^-) - K_k ( (H x_k + v_k) - H \\hat{x}_k^- )\n$$\nLet the prior estimation error be $e_k^- = x_k - \\hat{x}_k^-$. This simplifies the expression to:\n$$\ne_k^+ = e_k^- - K_k ( H(x_k - \\hat{x}_k^-) + v_k ) = e_k^- - K_k (H e_k^- + v_k)\n$$\nGrouping terms, we get:\n$$\ne_k^+ = (I - K_k H) e_k^- - K_k v_k\n$$\nThe posterior covariance matrix is defined as $P_k^+ = E[e_k^+ (e_k^+)^\\top]$. We substitute the expression for $e_k^+$:\n$$\nP_k^+ = E \\left[ \\left( (I - K_k H) e_k^- - K_k v_k \\right) \\left( (I - K_k H) e_k^- - K_k v_k \\right)^\\top \\right]\n$$\nExpanding the product:\n$$\nP_k^+ = E \\left[ (I - K_k H) e_k^- (e_k^-)^\\top (I - K_k H)^\\top - (I - K_k H) e_k^- v_k^\\top K_k^\\top - K_k v_k (e_k^-)^\\top (I - K_k H)^\\top + K_k v_k v_k^\\top K_k^\\top \\right]\n$$\nThe prior state error $e_k^-$ and the measurement noise $v_k$ are uncorrelated, so $E[e_k^- v_k^\\top] = 0$ and $E[v_k (e_k^-)^\\top] = 0$. Using the definitions $E[e_k^- (e_k^-)^\\top] = P_k^-$ and $E[v_k v_k^\\top] = R$, the expression simplifies to:\n$$\nP_k^+ = (I - K_k H) P_k^- (I - K_k H)^\\top + K_k R K_k^\\top\n$$\nThis is the Joseph form of the covariance update. To find the optimal gain $K_k$ that minimizes the mean square error (i.e., the trace of $P_k^+$), we differentiate $\\text{tr}(P_k^+)$ with respect to $K_k$ and set the result to zero. First, expand the expression for $P_k^+$:\n$$\nP_k^+ = P_k^- - K_k H P_k^- - P_k^- H^\\top K_k^\\top + K_k H P_k^- H^\\top K_k^\\top + K_k R K_k^\\top\n$$\n$$\nP_k^+ = P_k^- - K_k H P_k^- - P_k^- H^\\top K_k^\\top + K_k (H P_k^- H^\\top + R) K_k^\\top\n$$\nThe trace is a linear operator, so we can take the trace of each term. We then differentiate $\\text{tr}(P_k^+)$ with respect to $K_k$ using standard matrix calculus identities ($\\frac{\\partial}{\\partial X} \\text{tr}(AX) = A^\\top$, $\\frac{\\partial}{\\partial X} \\text{tr}(XA^\\top) = A$, $\\frac{\\partial}{\\partial X} \\text{tr}(XCX^\\top) = 2XC$ for symmetric $C$):\n$$\n\\frac{\\partial}{\\partial K_k} \\text{tr}(P_k^+) = 0 - (H P_k^-)^\\top - (P_k^- H^\\top) + 2 K_k (H P_k^- H^\\top + R)\n$$\nSince $P_k^-$ is symmetric, $(P_k^-)^\\top = P_k^-$.\n$$\n\\frac{\\partial}{\\partial K_k} \\text{tr}(P_k^+) = - (P_k^-)^\\top H^\\top - P_k^- H^\\top + 2 K_k (H P_k^- H^\\top + R) = -2 P_k^- H^\\top + 2 K_k (H P_k^- H^\\top + R)\n$$\nSetting the derivative to zero for optimality:\n$$\n-2 P_k^- H^\\top + 2 K_k (H P_k^- H^\\top + R) = 0\n$$\n$$\nK_k (H P_k^- H^\\top + R) = P_k^- H^\\top\n$$\nSolving for the optimal gain $K_k$:\n$$\nK_k = P_k^- H^\\top (H P_k^- H^\\top + R)^{-1}\n$$\nThis is the optimal Kalman gain. To find the posterior covariance, we can substitute this expression for $K_k$ back into a simplified form of the $P_k^+$ equation. Let's use $P_k^+ = P_k^- - K_k H P_k^- - P_k^- H^\\top K_k^\\top + K_k (H P_k^- H^\\top + R) K_k^\\top$. From the optimality condition, we have $P_k^- H^\\top = K_k (H P_k^- H^\\top + R)$. Substituting this into the third term:\n$$\nP_k^+ = P_k^- - K_k H P_k^- - \\left( K_k (H P_k^- H^\\top + R) \\right)^\\top K_k^\\top + K_k (H P_k^- H^\\top + R) K_k^\\top\n$$\nSince $(AB)^\\top = B^\\top A^\\top$ and $(H P_k^- H^\\top + R)$ is symmetric:\n$$\nP_k^+ = P_k^- - K_k H P_k^- - K_k (H P_k^- H^\\top + R) K_k^\\top + K_k (H P_k^- H^\\top + R) K_k^\\top\n$$\n$$\nP_k^+ = P_k^- - K_k H P_k^- = (I - K_k H) P_k^-\n$$\nThis is the simplest form for the updated posterior covariance. The problem asks for $P_k^+$ solely in terms of $H$, $P_k^-$, and $R$. Substituting the expression for $K_k$:\n$$\nP_{k}^{+} = \\left(I - \\left(P_k^- H^\\top (H P_k^- H^\\top + R)^{-1}\\right) H\\right) P_k^-\n$$\n\nNow, we evaluate this numerically with the given parameters:\n$$\nP_{k}^{-} = \\begin{bmatrix}2 & 0\\\\ 0 & 1\\end{bmatrix}, \\quad H = \\begin{bmatrix}1 & 0\\end{bmatrix}, \\quad R = 1\n$$\nFirst, we compute the innovation covariance, $S_k = H P_k^- H^\\top + R$.\n$$\nH P_k^- = \\begin{bmatrix}1 & 0\\end{bmatrix} \\begin{bmatrix}2 & 0\\\\ 0 & 1\\end{bmatrix} = \\begin{bmatrix}(1)(2)+(0)(0) & (1)(0)+(0)(1)\\end{bmatrix} = \\begin{bmatrix}2 & 0\\end{bmatrix}\n$$\n$$\nH P_k^- H^\\top = \\begin{bmatrix}2 & 0\\end{bmatrix} \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = (2)(1) + (0)(0) = 2\n$$\nSince $R=1$, the innovation covariance is a scalar:\n$$\nS_k = H P_k^- H^\\top + R = 2 + 1 = 3\n$$\nThe inverse is $S_k^{-1} = \\frac{1}{3}$.\n\nNext, we calculate the optimal Kalman gain $K_k = P_k^- H^\\top S_k^{-1}$.\n$$\nP_k^- H^\\top = \\begin{bmatrix}2 & 0\\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}(2)(1)+(0)(0) \\\\ (0)(1)+(1)(0)\\end{bmatrix} = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix}\n$$\n$$\nK_k = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix} \\left(\\frac{1}{3}\\right) = \\begin{bmatrix}2/3 \\\\ 0\\end{bmatrix}\n$$\nFinally, we compute the posterior covariance $P_k^+ = (I - K_k H) P_k^-$.\nFirst, calculate $K_k H$:\n$$\nK_k H = \\begin{bmatrix}2/3 \\\\ 0\\end{bmatrix} \\begin{bmatrix}1 & 0\\end{bmatrix} = \\begin{bmatrix}(2/3)(1) & (2/3)(0) \\\\ (0)(1) & (0)(0)\\end{bmatrix} = \\begin{bmatrix}2/3 & 0 \\\\ 0 & 0\\end{bmatrix}\n$$\nNext, compute $(I - K_k H)$:\n$$\nI - K_k H = \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix} - \\begin{bmatrix}2/3 & 0 \\\\ 0 & 0\\end{bmatrix} = \\begin{bmatrix}1 - 2/3 & 0-0 \\\\ 0-0 & 1-0\\end{bmatrix} = \\begin{bmatrix}1/3 & 0 \\\\ 0 & 1\\end{bmatrix}\n$$\nNow, compute $P_k^+$:\n$$\nP_k^+ = (I - K_k H) P_k^- = \\begin{bmatrix}1/3 & 0 \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix}2 & 0\\\\ 0 & 1\\end{bmatrix} = \\begin{bmatrix}(1/3)(2)+(0)(0) & (1/3)(0)+(0)(1) \\\\ (0)(2)+(1)(0) & (0)(0)+(1)(1)\\end{bmatrix}\n$$\n$$\nP_k^+ = \\begin{bmatrix}2/3 & 0 \\\\ 0 & 1\\end{bmatrix}\n$$\nThe posterior covariance matrix is computed as shown. The uncertainty in the first state component is reduced from $2$ to $2/3$ due to the informative measurement, while the uncertainty in the unobserved second component remains unchanged at $1$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2}{3} & 0 \\\\ 0 & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond simply mirroring the present, a cognitive twin's power lies in its ability to predict the future. This exercise introduces the core concept of prognostics by tasking you with calculating the Remaining Useful Life (RUL) of a component based on a simple, deterministic wear model . Understanding this fundamental calculation is the first step toward mastering the predictive capabilities that allow self-adaptive systems to anticipate failures and trigger proactive maintenance, a key tenet of intelligent industrial systems.",
            "id": "4209017",
            "problem": "A Cognitive Digital Twin (CDT) of a Cyber-Physical System (CPS) monitors a scalar wear state $w_{k}$ sampled at discrete time steps $k \\in \\mathbb{N}_{0}$, with sampling period $\\Delta t = 1$ hour. The CDT uses a deterministic predictive model grounded in the discrete-time integrator form, where the state update is given by the fundamental law of accumulation\n$$\nw_{k+1} = w_{k} + \\alpha,\n$$\nwith constant drift $\\alpha > 0$. Failure of the physical asset is defined by a threshold crossing event $w_{k} \\ge \\theta$, where $\\theta > 0$ is a fixed failure threshold. The Remaining Useful Life (RUL) at time $k$ is defined as the minimal time-to-threshold given the current state, namely the first passage time to the failure set under the predictive model. Assume the initial condition $w_{0} = 0$, constant wear rate $\\alpha = 0.1$ per hour, and failure threshold $\\theta = 10$.\n\nStarting from the fundamental definitions above, derive the RUL at $k=0$ as the first hitting time of the threshold for the deterministic linear wear process, and compute its value. Express the final answer in hours. No rounding is necessary; provide the exact value. Your final answer must be a single real-valued number.",
            "solution": "The problem statement shall first be validated for scientific soundness, consistency, and completeness.\n\n### Step 1: Extract Givens\n- **System**: A Cognitive Digital Twin (CDT) of a Cyber-Physical System (CPS).\n- **State Variable**: Scalar wear state $w_{k}$ at discrete time step $k \\in \\mathbb{N}_{0}$.\n- **Sampling Period**: $\\Delta t = 1$ hour.\n- **Predictive Model (State Update Law)**: $w_{k+1} = w_{k} + \\alpha$. This is described as a \"deterministic predictive model grounded in the discrete-time integrator form\".\n- **Drift Constant**: $\\alpha = 0.1$ per hour. It is given that $\\alpha > 0$.\n- **Initial Condition**: $w_{0} = 0$.\n- **Failure Condition**: $w_{k} \\ge \\theta$.\n- **Failure Threshold**: $\\theta = 10$. It is given that $\\theta > 0$.\n- **Definition of RUL**: The Remaining Useful Life (RUL) at time $k$ is the minimal time-to-threshold, defined as the first passage time to the failure set under the predictive model.\n- **Objective**: Derive the RUL at $k=0$ and compute its value in hours.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The model $w_{k+1} = w_{k} + \\alpha$ represents a linear accumulation process, a fundamental and widely used first-order approximation for wear, degradation, or damage accumulation in engineering systems. The concepts of a state variable, failure threshold, and Remaining Useful Life (RUL) are central to the field of prognostics and health management (PHM), which is integral to the study of digital twins and cyber-physical systems. The problem is scientifically and technically sound.\n2.  **Well-Posed**: The problem provides a deterministic state evolution equation, an initial condition, all necessary parameters ($\\alpha$, $\\theta$), and a clear definition of the quantity to be calculated (RUL at $k=0$). This setup guarantees the existence of a unique and meaningful solution.\n3.  **Objective**: The problem is stated using precise mathematical language and definitions. All terms are either standard in the field or explicitly defined. There are no subjective or opinion-based statements.\n4.  **Completeness and Consistency**: The provided information is self-contained and sufficient to solve the problem. There are no contradictory constraints.\n5.  **No Other Flaws**: The problem is not metaphorical, is directly relevant to the stated topic, is not unrealistic for a model-based problem, is not ill-posed, and is not trivial as it requires the correct application of the definition of RUL in a discrete-time context.\n\n### Step 3: Verdict and Action\nThe problem is valid. The solution process may proceed.\n\n### Solution Derivation\nThe state of the system at time step $k$ is denoted by $w_k$. The evolution of the state is governed by the discrete-time linear model:\n$$\nw_{k+1} = w_{k} + \\alpha\n$$\nThis is a first-order difference equation, which can be solved by recursion. Let's find a closed-form expression for $w_k$ in terms of the initial state $w_0$ and the time step $k$.\nFor $k=1$:\n$$\nw_1 = w_0 + \\alpha\n$$\nFor $k=2$:\n$$\nw_2 = w_1 + \\alpha = (w_0 + \\alpha) + \\alpha = w_0 + 2\\alpha\n$$\nFor $k=3$:\n$$\nw_3 = w_2 + \\alpha = (w_0 + 2\\alpha) + \\alpha = w_0 + 3\\alpha\n$$\nBy induction, the general solution for the state at any time step $k$ is:\n$$\nw_k = w_0 + k\\alpha\n$$\nThe problem defines failure as the event where the wear state $w_k$ reaches or exceeds a fixed threshold $\\theta$. The failure condition is $w_k \\ge \\theta$.\n\nThe Remaining Useful Life (RUL) at a given time step $j$ is the minimal time required for the system to fail, starting from the state $w_j$. Let this time, measured in discrete steps, be $L_j$. The state at time $j+L_j$ will be $w_{j+L_j}$. The RUL $L_j$ is the smallest non-negative integer such that:\n$$\nw_{j+L_j} \\ge \\theta\n$$\nUsing the closed-form solution for the state, we can write $w_{j+L_j}$ as:\n$$\nw_{j+L_j} = w_0 + (j+L_j)\\alpha\n$$\nAlternatively, and more directly, we can express the state evolution starting from $w_j$:\n$$\nw_{j+L_j} = w_j + L_j \\alpha\n$$\nThe condition for failure becomes:\n$$\nw_j + L_j \\alpha \\ge \\theta\n$$\nWe need to solve for the smallest integer $L_j$ that satisfies this inequality.\n$$\nL_j \\alpha \\ge \\theta - w_j\n$$\nSince $\\alpha > 0$, we can divide by $\\alpha$ without changing the inequality direction:\n$$\nL_j \\ge \\frac{\\theta - w_j}{\\alpha}\n$$\nBecause $L_j$ must be an integer representing the number of time steps, the minimal value for $L_j$ is the ceiling of the expression on the right-hand side.\n$$\nL_j = \\left\\lceil \\frac{\\theta - w_j}{\\alpha} \\right\\rceil\n$$\nThe problem asks for the RUL at the initial time, $k=0$. We must therefore calculate $L_0$.\n$$\nL_0 = \\left\\lceil \\frac{\\theta - w_0}{\\alpha} \\right\\rceil\n$$\nWe are given the following values:\n- Initial state: $w_0 = 0$\n- Failure threshold: $\\theta = 10$\n- Wear rate: $\\alpha = 0.1$ per hour\n\nSubstituting these values into the expression for $L_0$:\n$$\nL_0 = \\left\\lceil \\frac{10 - 0}{0.1} \\right\\rceil = \\left\\lceil \\frac{10}{0.1} \\right\\rceil = \\lceil 100 \\rceil\n$$\nSince $100$ is an integer, its ceiling is $100$.\n$$\nL_0 = 100\n$$\nThis value $L_0$ represents the number of time steps until failure. The problem asks for the RUL to be expressed in hours. The physical time is the number of steps multiplied by the sampling period, $\\Delta t$.\n$$\n\\text{RUL}_0 = L_0 \\times \\Delta t\n$$\nWe are given $\\Delta t = 1$ hour.\n$$\n\\text{RUL}_0 = 100 \\times 1 \\text{ hour} = 100 \\text{ hours}\n$$\nThus, the Remaining Useful Life at time $k=0$ is $100$ hours.",
            "answer": "$$\\boxed{100}$$"
        },
        {
            "introduction": "The ultimate goal of a cognitive twin in a self-adaptive system is to translate its knowledge and predictions into optimal actions. This hands-on practice explores Model Predictive Control (MPC), an advanced control strategy that embodies this decision-making process . By solving a finite-horizon optimal control problem, you will see how a CDT can plan a sequence of future inputs to steer the system towards a desired goal, demonstrating the powerful synergy between prediction and control that enables true self-adaptation.",
            "id": "4208970",
            "problem": "A Cognitive Digital Twin (CDT) supervising a self-adaptive Cyber-Physical System (CPS) uses Model Predictive Control (MPC) to compute the control action to be applied at each sampling step. The controlled plant is a scalar discrete-time integrator with dynamics $x_{k+1} = x_k + u_k$. At time $k=0$, the twin solves a finite-horizon, unconstrained MPC problem with horizon length $N=2$ using the quadratic stage cost $(x_k - x^{\\text{ref}})^2$ and control effort cost $u_k^2$, and a quadratic terminal cost $(x_N - x^{\\text{ref}})^2$. Assume $x^{\\text{ref}}=0$, $Q=1$, $R=1$, and terminal weight $Q_f=1$. The initial state is $x_0=2$, and there are no state or input constraints.\n\nStarting from the fundamental discrete-time dynamics $x_{k+1}=x_k+u_k$, the quadratic cost construction for finite-horizon optimal control, and the Bellman principle of optimality, formulate the resulting unconstrained MPC problem and solve it exactly to obtain the optimal first control move $u_0^\\star$ to be applied at $k=0$. Give your answer as an exact simplified rational number with no rounding and no units.",
            "solution": "The problem is valid as it is a well-posed, scientifically-grounded exercise in discrete-time optimal control, a standard topic in engineering and applied mathematics. It provides a complete and consistent set of givens, with no contradictions or ambiguities. We shall proceed with a formal solution.\n\nThe problem is to find the optimal first control action, $u_0^\\star$, for a finite-horizon, unconstrained Model Predictive Control (MPC) problem. The system is a scalar discrete-time integrator with dynamics given by:\n$$x_{k+1} = x_k + u_k$$\nThe optimization is performed over a horizon of length $N=2$. The objective is to minimize a quadratic cost function. The stage cost at step $k$ is $L(x_k, u_k) = (x_k - x^{\\text{ref}})^2 Q + u_k^2 R$, and the terminal cost is $V_f(x_N) = (x_N - x^{\\text{ref}})^2 Q_f$. The total cost to be minimized is:\n$$J = V_f(x_N) + \\sum_{k=0}^{N-1} L(x_k, u_k)$$\nThe given parameters are:\n- Horizon: $N=2$\n- Reference state: $x^{\\text{ref}}=0$\n- State weight: $Q=1$\n- Control weight: $R=1$\n- Terminal weight: $Q_f=1$\n- Initial state: $x_0=2$\n\nSubstituting these values, the cost function becomes:\n$$J(u_0, u_1) = x_2^2 + \\sum_{k=0}^{1} (x_k^2 + u_k^2) = x_2^2 + x_1^2 + u_1^2 + x_0^2 + u_0^2$$\nWe seek to find the control sequence $(u_0^\\star, u_1^\\star)$ that minimizes this cost, subject to the system dynamics. The MPC paradigm dictates that only the first element of this sequence, $u_0^\\star$, is applied to the system.\n\nThe standard method for solving such problems is dynamic programming, which applies the Bellman principle of optimality. We work backward in time from the final step, $k=N=2$.\n\nAt the final time step, $k=2$, the cost-to-go is the terminal cost:\n$$J_2(x_2) = x_2^2 Q_f = 1 \\cdot x_2^2 = x_2^2$$\nThis is a quadratic form $J_2(x_2) = P_2 x_2^2$, where $P_2=1$.\n\nNext, we step back to $k=1$. The optimal cost-to-go from state $x_1$ is given by the Bellman equation:\n$$J_1(x_1) = \\min_{u_1} \\{ L(x_1, u_1) + J_2(x_2) \\}$$\nSubstituting the expressions for the stage cost and the cost-to-go $J_2$, and using the system dynamics $x_2=x_1+u_1$:\n$$J_1(x_1) = \\min_{u_1} \\{ x_1^2 + u_1^2 + (x_1 + u_1)^2 \\}$$\nTo find the control $u_1$ that minimizes this expression, we take the derivative with respect to $u_1$ and set it to zero:\n$$\\frac{\\partial}{\\partial u_1} \\left( x_1^2 + u_1^2 + (x_1 + u_1)^2 \\right) = 2u_1 + 2(x_1 + u_1) = 0$$\n$$2u_1 + 2x_1 + 2u_1 = 0$$\n$$4u_1 = -2x_1$$\n$$u_1^\\star(x_1) = -\\frac{1}{2}x_1$$\nThis is the optimal feedback control law at $k=1$. Substituting this back into the expression for $J_1(x_1)$ gives the optimal cost-to-go from state $x_1$:\n$$J_1(x_1) = x_1^2 + \\left(-\\frac{1}{2}x_1\\right)^2 + \\left(x_1 - \\frac{1}{2}x_1\\right)^2 = x_1^2 + \\frac{1}{4}x_1^2 + \\left(\\frac{1}{2}x_1\\right)^2$$\n$$J_1(x_1) = x_1^2 + \\frac{1}{4}x_1^2 + \\frac{1}{4}x_1^2 = \\left(1 + \\frac{1}{2}\\right)x_1^2 = \\frac{3}{2}x_1^2$$\nThis is a quadratic form $J_1(x_1) = P_1 x_1^2$, where $P_1 = \\frac{3}{2}$.\n\nFinally, we step back to the initial time step, $k=0$. The optimal cost-to-go from the initial state $x_0$ is:\n$$J_0(x_0) = \\min_{u_0} \\{ L(x_0, u_0) + J_1(x_1) \\}$$\nUsing the system dynamics $x_1=x_0+u_0$ and the expression for $J_1(x_1)$:\n$$J_0(x_0) = \\min_{u_0} \\left\\{ x_0^2 + u_0^2 + \\frac{3}{2}(x_0+u_0)^2 \\right\\}$$\nTo find the optimal control $u_0^\\star$, we take the derivative with respect to $u_0$ and set it to zero:\n$$\\frac{\\partial}{\\partial u_0} \\left( x_0^2 + u_0^2 + \\frac{3}{2}(x_0+u_0)^2 \\right) = 2u_0 + \\frac{3}{2} \\cdot 2(x_0+u_0) = 0$$\n$$2u_0 + 3(x_0+u_0) = 0$$\n$$2u_0 + 3x_0 + 3u_0 = 0$$\n$$5u_0 = -3x_0$$\n$$u_0^\\star(x_0) = -\\frac{3}{5}x_0$$\nThis is the optimal feedback control law for the first step. The problem asks for the specific control action to be applied at $k=0$, given the initial state $x_0=2$. We substitute this value into the control law:\n$$u_0^\\star = -\\frac{3}{5} \\cdot 2 = -\\frac{6}{5}$$\nThe optimal first control move is $-\\frac{6}{5}$.",
            "answer": "$$\n\\boxed{-\\frac{6}{5}}\n$$"
        }
    ]
}