{
    "hands_on_practices": [
        {
            "introduction": "Before designing a controller, we must understand the fundamental capabilities of our system model. This practice explores the core concepts of controllability and observability, which determine our ability to influence and monitor a system's internal states. By constructing and analyzing the controllability and observability matrices, you will determine if a state-space realization is \"minimal\"â€”a crucial property for creating efficient and non-redundant models for digital twins, providing a foundational check on the structural properties of a linear system .",
            "id": "4222247",
            "problem": "A digital twin (DT) of a cyber-physical system (CPS) operating a precision nano-positioning stage is modeled, after linearization about a nominal operating point, by a continuous-time, linear time-invariant (LTI) state-space realization with state $x \\in \\mathbb{R}^{2}$, control input $u \\in \\mathbb{R}$, and measured output $y \\in \\mathbb{R}$. The DT uses a minimal realization to reduce computational burden while preserving input-output behavior fidelity. The physics-based linearized model is defined by the matrices $A=\\begin{bmatrix}01\\\\00\\end{bmatrix}$, $B=\\begin{bmatrix}0\\\\1\\end{bmatrix}$, $C=\\begin{bmatrix}10\\end{bmatrix}$, with dynamics $\\dot{x}=Ax+Bu$ and output $y=Cx$.\n\nStarting from the fundamental definitions of reachability (controllability) and distinguishability (observability) for LTI systems, construct:\n- the controllability matrix for the pair $(A,B)$ by assembling columns that span the subspace reachable by applying the input through the dynamics,\n- the observability matrix for the pair $(C,A)$ by assembling rows that span the subspace of state directions that affect the output through the dynamics.\n\nDecide whether this realization is minimal, using the criterion that a realization is minimal if and only if it is both controllable and observable.\n\nReport your final answer as a single row matrix whose three entries are, in order: the controllability matrix, the observability matrix, and a minimality indicator, where the minimality indicator is $1$ if the realization is minimal and $0$ otherwise. No approximation is needed, and no units are required. Express all matrices and numbers in exact form.",
            "solution": "The problem requires an analysis of a given continuous-time, linear time-invariant (LTI) state-space realization to determine if it is minimal. A realization is defined as minimal if and only if it is both controllable (or reachable) and observable (or distinguishable). We will first construct the controllability and observability matrices and then use them to assess these properties.\n\nThe system is described by the state-space equations:\n$$ \\dot{x}(t) = Ax(t) + Bu(t) $$\n$$ y(t) = Cx(t) $$\nwith the state vector $x \\in \\mathbb{R}^{2}$, input $u \\in \\mathbb{R}$, and output $y \\in \\mathbb{R}$. The system matrices are given as:\n$$ A=\\begin{bmatrix}01\\\\00\\end{bmatrix}, \\quad B=\\begin{bmatrix}0\\\\1\\end{bmatrix}, \\quad C=\\begin{bmatrix}10\\end{bmatrix} $$\nThe order of the system is $n=2$, which corresponds to the dimension of the state vector $x$.\n\nFirst, we address the property of controllability. A system is controllable if, for any initial state $x(0)$ and any final state $x(t_f)$, there exists a control input $u(t)$ that can drive the state from $x(0)$ to $x(t_f)$ in a finite time $t_f  0$. For an LTI system, this is equivalent to the condition that the controllability matrix, $\\mathcal{C}$, has full rank. The controllability matrix for a system of order $n$ is defined as:\n$$ \\mathcal{C} = \\begin{bmatrix} B  AB  A^2B  \\dots  A^{n-1}B \\end{bmatrix} $$\nFor this system with $n=2$, the controllability matrix is:\n$$ \\mathcal{C} = \\begin{bmatrix} B  AB \\end{bmatrix} $$\nWe proceed with the calculation of the product $AB$:\n$$ AB = \\begin{bmatrix}01\\\\00\\end{bmatrix} \\begin{bmatrix}0\\\\1\\end{bmatrix} = \\begin{bmatrix}(0)(0)+(1)(1)\\\\(0)(0)+(0)(1)\\end{bmatrix} = \\begin{bmatrix}1\\\\0\\end{bmatrix} $$\nAssembling the controllability matrix $\\mathcal{C}$ by concatenating the columns $B$ and $AB$:\n$$ \\mathcal{C} = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} $$\n\nNext, we address the property of observability. A system is observable if, for any unknown initial state $x(0)$, it is possible to determine this state by observing the system's output $y(t)$ over a finite time interval $t \\in [0, t_f]$ with $t_f  0$. For an LTI system, this is equivalent to the condition that the observability matrix, $\\mathcal{O}$, has full rank. The observability matrix for a system of order $n$ is defined as:\n$$ \\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{n-1} \\end{bmatrix} $$\nFor this system with $n=2$, the observability matrix is:\n$$ \\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix} $$\nWe proceed with the calculation of the product $CA$:\n$$ CA = \\begin{bmatrix}10\\end{bmatrix} \\begin{bmatrix}01\\\\00\\end{bmatrix} = \\begin{bmatrix}(1)(0)+(0)(0)  (1)(1)+(0)(0)\\end{bmatrix} = \\begin{bmatrix}01\\end{bmatrix} $$\nAssembling the observability matrix $\\mathcal{O}$ by stacking the rows $C$ and $CA$:\n$$ \\mathcal{O} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} $$\n\nFinally, we determine if the realization is minimal. This requires checking if the system is both controllable and observable.\nThe system is controllable if and only if the rank of $\\mathcal{C}$ is equal to the system order, $n=2$. The rank can be determined by computing the determinant of $\\mathcal{C}$:\n$$ \\det(\\mathcal{C}) = \\det\\left(\\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}\\right) = (0)(0) - (1)(1) = -1 $$\nSince $\\det(\\mathcal{C}) \\neq 0$, the matrix $\\mathcal{C}$ has full rank, which is $\\text{rank}(\\mathcal{C}) = 2$. Therefore, the system is controllable.\n\nThe system is observable if and only if the rank of $\\mathcal{O}$ is equal to the system order, $n=2$. The rank can be determined by computing the determinant of $\\mathcal{O}$:\n$$ \\det(\\mathcal{O}) = \\det\\left(\\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}\\right) = (1)(1) - (0)(0) = 1 $$\nSince $\\det(\\mathcal{O}) \\neq 0$, the matrix $\\mathcal{O}$ has full rank, which is $\\text{rank}(\\mathcal{O}) = 2$. Therefore, the system is observable.\n\nBecause the state-space realization is both controllable and observable, it is, by definition, a minimal realization. The minimality indicator is therefore $1$.\n\nThe problem requires a single row matrix containing the controllability matrix, the observability matrix, and the minimality indicator in that order. The three entries are:\n1.  Controllability matrix: $\\mathcal{C} = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}$\n2.  Observability matrix: $\\mathcal{O} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$\n3.  Minimality indicator: $1$\nThese are assembled into the final answer format.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}  \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}  1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Control systems can be described in either the time domain using state-space equations or the frequency domain using a transfer function. This practice bridges these two fundamental representations, a critical skill in modern control engineering. Starting from a state-space model, you will derive its equivalent input-output transfer function, solidifying your understanding of how a system's internal dynamics, represented by the state matrix $A$, directly manifest as the poles of its transfer function .",
            "id": "4222269",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) is used to support feedback controller synthesis by providing a linear input-output model derived from a state-space realization. Consider a Single-Input Single-Output (SISO) linear time-invariant (LTI) system with state equations and output equation given by\n$$\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t) + D u(t),$$\nwhere the matrices are\n$$A = \\begin{bmatrix}0  1 \\\\ -2  -3\\end{bmatrix}, \\quad B = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}, \\quad C = \\begin{bmatrix}1  0\\end{bmatrix}, \\quad D = 0.$$\nStarting from the fundamental definition of the transfer function as the ratio of the Laplace transform of the output to the Laplace transform of the input under zero initial conditions, derive the explicit input-output transfer function $$G(s) = \\frac{Y(s)}{U(s)}$$ for this DT model. Then, identify its poles and zeros by appealing to first principles, namely the relationship between poles and the system dynamics, and between zeros and the input-output map.\n\nYou must:\n- Begin from the state and output equations and the definition of the transfer function under zero initial conditions, and use the Laplace transform and algebraic manipulation of the resolvent to obtain the input-output transfer function.\n- Identify the poles as the values of $s$ that render the transfer function unbounded and the zeros as the values of $s$ that render the transfer function equal to zero.\n- Express your final answer as a single row matrix with entries in the following order: the transfer function $G(s)$, each pole listed as separate entries, and the set of finite zeros as a single entry. If there are no finite zeros, denote the set of finite zeros by the empty-set symbol $\\,\\varnothing\\,$.\n- No numerical rounding is required. No physical units are required.",
            "solution": "The problem statement is deemed valid. It is a well-posed, scientifically grounded problem in linear time-invariant (LTI) systems theory, a cornerstone of control engineering and its application to cyber-physical systems and digital twins. All necessary information is provided, the data is consistent, and the objectives are clearly defined.\n\nThe task is to derive the input-output transfer function, $G(s)$, for a given LTI system described in state-space form and then to identify its poles and zeros. The derivation must start from first principles.\n\nThe system is described by the state-space equations:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nwhere $x(t)$ is the state vector, $u(t)$ is the input, and $y(t)$ is the output. The matrices are given as:\n$$\nA = \\begin{bmatrix}0  1 \\\\ -2  -3\\end{bmatrix}, \\quad B = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}, \\quad C = \\begin{bmatrix}1  0\\end{bmatrix}, \\quad D = 0\n$$\n\nThe transfer function $G(s)$ is defined as the ratio of the Laplace transform of the output, $Y(s)$, to the Laplace transform of the input, $U(s)$, assuming zero initial conditions, i.e., $x(0) = 0$.\n$$\nG(s) = \\frac{Y(s)}{U(s)} \\bigg|_{x(0)=0}\n$$\n\nWe begin by applying the Laplace transform to the state and output equations. Let $X(s) = \\mathcal{L}\\{x(t)\\}$, $U(s) = \\mathcal{L}\\{u(t)\\}$, and $Y(s) = \\mathcal{L}\\{y(t)\\}$. The Laplace transform of the state derivative $\\dot{x}(t)$ is $sX(s) - x(0)$. Applying this to the state equation with the zero initial condition $x(0)=0$ yields:\n$$\nsX(s) = AX(s) + BU(s)\n$$\nThe Laplace-transformed output equation is:\n$$\nY(s) = CX(s) + DU(s)\n$$\nNext, we solve the transformed state equation for $X(s)$.\n$$\nsX(s) - AX(s) = BU(s)\n$$\nFactoring out $X(s)$ requires the use of the identity matrix, $I$, of the same dimension as $A$:\n$$\n(sI - A)X(s) = BU(s)\n$$\nTo isolate $X(s)$, we pre-multiply both sides by the inverse of the matrix $(sI - A)$, which is called the resolvent matrix. This is permissible for all values of $s$ for which $(sI - A)$ is invertible, i.e., for which $\\det(sI - A) \\neq 0$.\n$$\nX(s) = (sI - A)^{-1}BU(s)\n$$\nNow, substitute this expression for $X(s)$ into the transformed output equation:\n$$\nY(s) = C\\left((sI - A)^{-1}BU(s)\\right) + DU(s)\n$$\nBy factoring out $U(s)$, we obtain the relationship between $Y(s)$ and $U(s)$:\n$$\nY(s) = \\left[C(sI - A)^{-1}B + D\\right]U(s)\n$$\nFrom the definition of the transfer function, we can now identify $G(s)$:\n$$\nG(s) = C(sI - A)^{-1}B + D\n$$\nNow, we substitute the given matrices into this formula. First, we compute the matrix $(sI - A)$:\n$$\nsI - A = s\\begin{bmatrix}1  0 \\\\ 0  1\\end{bmatrix} - \\begin{bmatrix}0  1 \\\\ -2  -3\\end{bmatrix} = \\begin{bmatrix}s  0 \\\\ 0  s\\end{bmatrix} - \\begin{bmatrix}0  1 \\\\ -2  -3\\end{bmatrix} = \\begin{bmatrix}s  -1 \\\\ 2  s+3\\end{bmatrix}\n$$\nThe inverse of this $2 \\times 2$ matrix is given by the formula $(M)^{-1} = \\frac{1}{\\det(M)}\\text{adj}(M)$. The determinant of $(sI - A)$ is the characteristic polynomial of $A$:\n$$\n\\det(sI - A) = s(s+3) - (-1)(2) = s^2 + 3s + 2\n$$\nThe adjugate matrix is:\n$$\n\\text{adj}(sI - A) = \\begin{bmatrix}s+3  1 \\\\ -2  s\\end{bmatrix}\n$$\nTherefore, the resolvent matrix is:\n$$\n(sI - A)^{-1} = \\frac{1}{s^2 + 3s + 2} \\begin{bmatrix}s+3  1 \\\\ -2  s\\end{bmatrix}\n$$\nNow we compute the full expression for $G(s)$. Since $D=0$, we have $G(s) = C(sI - A)^{-1}B$:\n$$\nG(s) = \\begin{bmatrix}1  0\\end{bmatrix} \\left( \\frac{1}{s^2 + 3s + 2} \\begin{bmatrix}s+3  1 \\\\ -2  s\\end{bmatrix} \\right) \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}\n$$\nWe perform the matrix multiplication, which is associative. Let's first multiply the two matrices on the right:\n$$\n\\begin{bmatrix}s+3  1 \\\\ -2  s\\end{bmatrix} \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}(s+3)(0) + (1)(1) \\\\ (-2)(0) + (s)(1)\\end{bmatrix} = \\begin{bmatrix}1 \\\\ s\\end{bmatrix}\n$$\nNow substitute this back into the expression for $G(s)$:\n$$\nG(s) = \\frac{1}{s^2 + 3s + 2} \\begin{bmatrix}1  0\\end{bmatrix} \\begin{bmatrix}1 \\\\ s\\end{bmatrix}\n$$\n$$\nG(s) = \\frac{1}{s^2 + 3s + 2} ((1)(1) + (0)(s)) = \\frac{1}{s^2 + 3s + 2}\n$$\nThe derived transfer function is $G(s) = \\frac{1}{s^2 + 3s + 2}$.\n\nNext, we identify the poles and zeros.\nPoles are the values of the complex variable $s$ for which the transfer function $G(s)$ becomes unbounded. These correspond to the roots of the denominator polynomial, which is the characteristic polynomial of the system matrix $A$.\n$$\ns^2 + 3s + 2 = 0\n$$\nFactoring the quadratic polynomial gives:\n$$\n(s+1)(s+2) = 0\n$$\nThus, the poles of the system are $s_1 = -1$ and $s_2 = -2$. These values correspond to the natural frequencies (eigenvalues) of the system.\n\nZeros are the values of the complex variable $s$ for which the transfer function $G(s)$ becomes zero. These correspond to the roots of the numerator polynomial.\nThe numerator of $G(s)$ is the constant $1$. The equation for the zeros is:\n$$\n1 = 0\n$$\nThis equation has no solution. Therefore, the system has no finite zeros. The set of finite zeros is the empty set, denoted by $\\varnothing$.\n\nThe final results are the transfer function $G(s) = \\frac{1}{s^2 + 3s + 2}$, the poles at $s=-1$ and $s=-2$, and an empty set of finite zeros.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{s^2 + 3s + 2}  -1  -2  \\varnothing\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Ideal feedforward control aims to perfectly invert the plant dynamics, but this is often impossible in practice due to physical and mathematical constraints. This practice confronts a common and challenging scenario: designing a controller for a non-minimum phase system, characterized by unstable zeros. By analyzing the pitfalls of direct inversion, you will learn to construct a stable and causal approximate inverse that preserves tracking performance at low frequencies while ensuring stability, demonstrating a key engineering trade-off in control design .",
            "id": "4222205",
            "problem": "A digital twin of a Cyber-Physical System (CPS) uses a model-based feedforward pathway to shape the actuator input so that the physical output tracks a reference. Consider a linear time-invariant single-input single-output plant with transfer function $G(s)=\\frac{s-1}{(s+2)(s+3)}$, where $s$ is the Laplace variable. The digital twin seeks a feedforward compensator $F(s)$ such that, over the frequency band where the model is accurate, the product $F(s)G(s)$ approximates unity to achieve tracking.\n\nStarting from fundamental definitions, analyze the feasibility of exact inversion and its implications:\n- Use the definition of Bounded-Input Bounded-Output (BIBO) stability and the relation between pole locations and stability to determine the stability of the exact inverse $G^{-1}(s)$.\n- Use causality requirements for rational transfer functions to determine whether $G^{-1}(s)$ is causal.\n\nThen construct a stable, causal, minimum-phase approximate inverse $F(s)$ that meets the following design constraints without introducing any unstable internal dynamics:\n- All poles of $F(s)$ must lie strictly in the open left half-plane to ensure BIBO stability.\n- $F(s)$ must be proper.\n- The low-frequency tracking condition must hold: $\\lim_{s \\to 0} F(s)G(s)=1$.\n- The dynamic order of $F(s)$ must be the smallest necessary to satisfy the above constraints.\n- Introduce exactly one positive real tuning parameter $\\omega_c0$ that sets the bandwidth of a strictly stable prefilter factor used to achieve properness and attenuate high-frequency amplification, with unity direct-current (DC) gain.\n\nProvide the final closed-form analytic expression for the proposed $F(s)$ in terms of $s$ and $\\omega_c$. No numerical evaluation is required. Express the final answer as a single rational function of $s$ and $\\omega_c$. There are no physical units to report for this expression.",
            "solution": "The problem requires an analysis of a feedforward control strategy for a given linear time-invariant (LTI) plant, followed by the design of a suitable feedforward compensator $F(s)$. The process begins with validating the problem statement.\n\n### Step 1: Extract Givens\n- Plant transfer function: $G(s)=\\frac{s-1}{(s+2)(s+3)}$\n- Goal: Design a feedforward compensator $F(s)$ such that $F(s)G(s)$ approximates unity.\n- Analysis Part 1: Determine the Bounded-Input Bounded-Output (BIBO) stability and causality of the exact inverse $G^{-1}(s)$.\n- Design Constraints for the approximate inverse $F(s)$:\n    1.  All poles of $F(s)$ must lie strictly in the open left half-plane.\n    2.  $F(s)$ must be proper.\n    3.  Low-frequency tracking condition: $\\lim_{s \\to 0} F(s)G(s)=1$.\n    4.  The dynamic order of $F(s)$ must be the smallest necessary.\n    5.  $F(s)$ must include a strictly stable prefilter factor with unity DC gain and a single positive real tuning parameter $\\omega_c  0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of classical control theory, including transfer functions, stability, causality, and feedforward controller design. The plant $G(s)$ has a right-half-plane (RHP) zero, making it non-minimum phase, which is a standard and non-trivial challenge in control systems. The constraints provided for the compensator $F(s)$ are clear, self-contained, consistent, and standard in practical controller design. The problem is well-posed, objective, and its solution is verifiable through mathematical derivation. There are no scientific flaws, ambiguities, or missing information.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\n\n#### Analysis of the Exact Inverse Compensator\n\nFirst, we analyze the properties of an ideal feedforward compensator defined by the exact inverse of the plant, $F(s) = G^{-1}(s)$.\nThe plant transfer function is given by:\n$$G(s) = \\frac{s-1}{(s+2)(s+3)}$$\nThe exact inverse is:\n$$G^{-1}(s) = \\frac{(s+2)(s+3)}{s-1} = \\frac{s^2 + 5s + 6}{s-1}$$\n\n**BIBO Stability:** A rational LTI system is BIBO stable if and only if all its poles have strictly negative real parts (i.e., they lie in the open left half of the complex plane). The poles of $G^{-1}(s)$ are the roots of its denominator polynomial, $s-1=0$. This gives a single pole at $s=1$. Since this pole lies in the right-half plane ($\\text{Re}\\{1\\}  0$), the system $G^{-1}(s)$ is **unstable**.\n\n**Causality:** A rational transfer function is causal if the degree of its numerator polynomial is less than or equal to the degree of its denominator polynomial. Such a system is called proper if the degrees are equal, and strictly proper if the numerator degree is smaller. If the numerator degree is greater than the denominator degree, the system is non-causal (or improper). For $G^{-1}(s)$, the degree of the numerator polynomial ($s^2+5s+6$) is $2$, and the degree of the denominator polynomial ($s-1$) is $1$. Since $2  1$, the system $G^{-1}(s)$ is **non-causal**.\n\nAn unstable and non-causal compensator is not physically realizable. Therefore, an approximate inverse must be constructed.\n\n#### Construction of a Stable, Causal, Approximate Inverse\n\nThe primary difficulty arises from the zero of $G(s)$ at $s=1$, which becomes an unstable pole in $G^{-1}(s)$. This is a non-minimum phase zero. The standard method for inverting such a system is to factor the plant $G(s)$ into a minimum-phase part $G_{mp}(s)$ (containing all poles and LHP zeros) and an all-pass part $G_{ap}(s)$ (containing the RHP zeros).\n\nThe RHP zero is at $s=1$. The corresponding all-pass factor, which has unity magnitude for all frequencies $s=j\\omega$, is constructed by pairing the RHP zero with a stable pole at its reflection across the imaginary axis, $s=-1$:\n$$G_{ap}(s) = \\frac{1-s}{1+s} = -\\frac{s-1}{s+1}$$\nThe minimum-phase part is then found by dividing the original plant by the all-pass factor:\n$$G_{mp}(s) = \\frac{G(s)}{G_{ap}(s)} = \\frac{s-1}{(s+2)(s+3)} \\cdot \\left(-\\frac{s+1}{s-1}\\right) = -\\frac{s+1}{(s+2)(s+3)}$$\nSo, the plant is factored as $G(s) = G_{mp}(s) G_{ap}(s)$.\n\nA practical feedforward controller inverts only the well-behaved minimum-phase part, $G_{mp}(s)$. An initial attempt for the compensator would be $F_{ideal}(s) = G_{mp}^{-1}(s)$:\n$$F_{ideal}(s) = \\left(-\\frac{s+1}{(s+2)(s+3)}\\right)^{-1} = -\\frac{(s+2)(s+3)}{s+1}$$\nThis intermediate form has a stable pole at $s=-1$. However, its numerator degree ($2$) is greater than its denominator degree ($1$), so it is improper and thus non-causal.\n\nTo satisfy the design constraints, we must modify $F_{ideal}(s)$:\n1.  **Properness:** To make the compensator proper, we must add poles to increase the denominator degree until it is at least equal to the numerator degree. $F_{ideal}(s)$ has a relative degree of $-1$ (numerator degree minus denominator degree is $2-1=1$). To achieve a proper transfer function (relative degree $0$), we need to multiply it by a filter with a relative degree of at least $1$. The minimum order to achieve this is a first-order filter.\n2.  **Prefilter and Parameter $\\omega_c$:** Constraint $5$ requires adding a \"strictly stable prefilter factor used to achieve properness\" with \"unity direct-current (DC) gain\" and a tuning parameter $\\omega_c  0$. A first-order low-pass filter of the form $L(s) = \\frac{\\omega_c}{s+\\omega_c}$ satisfies these requirements perfectly.\n    - It is strictly stable since $\\omega_c  0$.\n    - Its DC gain is $L(0) = \\frac{\\omega_c}{0+\\omega_c} = 1$.\n    - Its relative degree is $1$, which is exactly what is needed to make the overall compensator proper.\n    - It introduces the parameter $\\omega_c$ which defines the filter's bandwidth.\n\nThe final form of the compensator $F(s)$ is the product of the inverted minimum-phase part and this low-pass filter:\n$$F(s) = F_{ideal}(s) \\cdot L(s) = \\left(-\\frac{(s+2)(s+3)}{s+1}\\right) \\left(\\frac{\\omega_c}{s+\\omega_c}\\right)$$\nThis compensator $F(s)$ satisfies all constraints:\n- **Stability:** Its poles are at $s=-1$ and $s=-\\omega_c$. Since $\\omega_c  0$, both poles are in the open left half-plane.\n- **Properness:** The numerator degree is $2$ and the denominator degree is $2$. It is proper.\n- **Low-frequency Tracking:** We check the DC gain of the full loop $F(s)G(s)$.\n  $$ \\lim_{s \\to 0} F(s)G(s) = F(0)G(0) $$\n  $$ F(0) = \\left(-\\frac{(0+2)(0+3)}{0+1}\\right) \\left(\\frac{\\omega_c}{0+\\omega_c}\\right) = (-6)(1) = -6 $$\n  $$ G(0) = \\frac{0-1}{(0+2)(0+3)} = -\\frac{1}{6} $$\n  $$ F(0)G(0) = (-6)\\left(-\\frac{1}{6}\\right) = 1 $$\n  The tracking condition is met. This works because $F(s)$ inverts the DC gain of $G_{mp}(s)$ and the filter $L(s)$ has unity DC gain, so $F(0)G_{mp}(0)=1$. The total loop gain at DC is $F(0)G(0) = F(0)G_{mp}(0)G_{ap}(0) = 1 \\cdot G_{ap}(0)$. Since $G_{ap}(0) = \\frac{1-0}{1+0} = 1$, the condition holds.\n- **Minimum Order:** The base part of the compensator, $G_{mp}^{-1}(s)$, already has an order of $1$. To make it proper, we must add a filter of at least order $1$. Thus, the minimum possible order for the final compensator $F(s)$ is $1+1=2$. Our design has an order of $2$.\n\nThe final expression for the compensator is:\n$$F(s) = -\\frac{\\omega_c(s+2)(s+3)}{(s+1)(s+\\omega_c)} = \\frac{-\\omega_c(s^2 + 5s + 6)}{(s+1)(s+\\omega_c)}$$\nThis is the required closed-form analytic expression in terms of $s$ and $\\omega_c$.",
            "answer": "$$\n\\boxed{\\frac{-\\omega_c(s^2 + 5s + 6)}{(s+1)(s+\\omega_c)}}\n$$"
        }
    ]
}