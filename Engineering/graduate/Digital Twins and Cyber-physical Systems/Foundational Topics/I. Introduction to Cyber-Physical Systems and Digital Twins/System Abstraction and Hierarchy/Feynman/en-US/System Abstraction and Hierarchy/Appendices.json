{
    "hands_on_practices": [
        {
            "introduction": "The interface between continuous physical dynamics and discrete digital control is a fundamental site of abstraction in cyber-physical systems. This exercise challenges you to quantify the error introduced by this abstraction by comparing an exact discrete-time model with a computationally simpler one based on the Euler method. Mastering this type of error analysis is essential for guaranteeing the performance and safety of digital controllers and twins. ",
            "id": "4249603",
            "problem": "A scalar continuous-time plant at the physical layer of a cyber-physical system is modeled by the linear time-invariant dynamics $\\dot{x}(t) = a x(t) + b u(t)$, where $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constant parameters. In a hierarchical digital twin abstraction, the plant is interfaced via a sampler and a zero-order hold (ZOH) using a fixed sampling period $h  0$. On each sampling interval $[k h, (k+1) h)$, the input is held constant, $u(t) = u_k$ for $t \\in [k h, (k+1) h)$. \n\nConsider the specific case with $a = -1$, sampling time $h = 0.1$, and input gain $b = 2$. The exact discrete-time abstraction is defined as $x_{k+1} = \\Phi x_k + \\Gamma u_k$, where $\\Phi$ and $\\Gamma$ are determined by first principles from the continuous-time dynamics and the ZOH assumption. An alternative approximate abstraction uses the forward Euler method, $x_{k+1}^{\\mathrm{E}} = x_k + h (a x_k + b u_k)$. \n\nUsing only the definitions of the solution of a linear time-invariant system and the ZOH assumption, derive the exact discrete-time mapping $(\\Phi, \\Gamma)$ and the forward Euler mapping, then quantify the one-step abstraction error over the bounded operating set $\\{(x_k, u_k) : |x_k| \\leq 1, |u_k| \\leq 1\\}$ by computing\n$$\nE^\\star \\triangleq \\sup_{\\substack{|x_k| \\leq 1 \\\\ |u_k| \\leq 1}} \\left| x_{k+1} - x_{k+1}^{\\mathrm{E}} \\right|.\n$$\nReport the value of $E^\\star$ as a single dimensionless number. Round your final answer to six significant figures.",
            "solution": "The problem requires the derivation of two different discrete-time abstractions of a continuous-time system and the quantification of the one-step error between them over a specified operating set.\n\nFirst, we must derive the exact discrete-time model, $x_{k+1} = \\Phi x_k + \\Gamma u_k$. The continuous-time dynamics are given by the linear time-invariant (LTI) ordinary differential equation:\n$$\n\\dot{x}(t) = a x(t) + b u(t)\n$$\nThe solution to this equation, starting from an initial condition $x(t_0)$, is given by the variation of constants formula:\n$$\nx(t) = \\exp(a(t-t_0)) x(t_0) + \\int_{t_0}^{t} \\exp(a(t-\\tau)) b u(\\tau) \\, d\\tau\n$$\nWe are interested in the evolution of the state from time $t_0 = k h$ to $t = (k+1) h$. Let $x_k \\triangleq x(kh)$. The state at the next sampling instant is $x_{k+1} \\triangleq x((k+1)h)$:\n$$\nx_{k+1} = \\exp(a((k+1)h - kh)) x_k + \\int_{kh}^{(k+1)h} \\exp(a((k+1)h - \\tau)) b u(\\tau) \\, d\\tau\n$$\nThe problem states that a Zero-Order Hold (ZOH) is used, meaning the control input is held constant over each sampling interval: $u(\\tau) = u_k$ for $\\tau \\in [kh, (k+1)h)$. Substituting this into the integral and simplifying the exponential term gives:\n$$\nx_{k+1} = \\exp(ah) x_k + b u_k \\int_{kh}^{(k+1)h} \\exp(a((k+1)h - \\tau)) \\, d\\tau\n$$\nTo evaluate the integral, we perform a change of variable. Let $s = (k+1)h - \\tau$. Then $ds = -d\\tau$. The limits of integration change from $\\tau=kh$ to $s=h$, and from $\\tau=(k+1)h$ to $s=0$.\n$$\n\\int_{kh}^{(k+1)h} \\exp(a((k+1)h - \\tau)) \\, d\\tau = \\int_{h}^{0} \\exp(as) (-ds) = \\int_{0}^{h} \\exp(as) \\, ds\n$$\nSince $a = -1 \\neq 0$, the integral evaluates to:\n$$\n\\int_{0}^{h} \\exp(as) \\, ds = \\left[ \\frac{\\exp(as)}{a} \\right]_0^h = \\frac{\\exp(ah) - \\exp(0)}{a} = \\frac{\\exp(ah) - 1}{a}\n$$\nSubstituting this back into the expression for $x_{k+1}$:\n$$\nx_{k+1} = \\exp(ah) x_k + b \\left( \\frac{\\exp(ah) - 1}{a} \\right) u_k\n$$\nBy comparing this to the given form $x_{k+1} = \\Phi x_k + \\Gamma u_k$, we identify the exact discrete-time system matrices:\n$$\n\\Phi = \\exp(ah) \\quad \\text{and} \\quad \\Gamma = \\frac{b}{a}(\\exp(ah) - 1)\n$$\n\nNext, we formulate the approximate abstraction using the forward Euler method. The forward Euler discretization of $\\dot{x} = f(x,u)$ is $x_{k+1} \\approx x_k + h f(x_k, u_k)$. For our system, $f(x,u) = ax+bu$, so the approximation is:\n$$\nx_{k+1}^{\\mathrm{E}} = x_k + h(a x_k + b u_k) = (1+ah)x_k + (bh)u_k\n$$\nThis gives the approximate system matrices $\\Phi^{\\mathrm{E}} = 1+ah$ and $\\Gamma^{\\mathrm{E}} = bh$.\n\nNow, we must quantify the one-step abstraction error, defined as $x_{k+1} - x_{k+1}^{\\mathrm{E}}$.\n$$\nx_{k+1} - x_{k+1}^{\\mathrm{E}} = (\\Phi x_k + \\Gamma u_k) - (\\Phi^{\\mathrm{E}} x_k + \\Gamma^{\\mathrm{E}} u_k)\n$$\n$$\nx_{k+1} - x_{k+1}^{\\mathrm{E}} = (\\Phi - \\Phi^{\\mathrm{E}}) x_k + (\\Gamma - \\Gamma^{\\mathrm{E}}) u_k\n$$\nLet's compute the difference terms:\n$$\n\\Phi - \\Phi^{\\mathrm{E}} = \\exp(ah) - (1+ah)\n$$\n$$\n\\Gamma - \\Gamma^{\\mathrm{E}} = \\frac{b}{a}(\\exp(ah) - 1) - bh = \\frac{b}{a}(\\exp(ah) - 1 - ah)\n$$\nThe error expression becomes:\n$$\nx_{k+1} - x_{k+1}^{\\mathrm{E}} = (\\exp(ah) - 1 - ah) x_k + \\frac{b}{a}(\\exp(ah) - 1 - ah) u_k\n$$\nWe can factor out the common term:\n$$\nx_{k+1} - x_{k+1}^{\\mathrm{E}} = (\\exp(ah) - 1 - ah) \\left( x_k + \\frac{b}{a} u_k \\right)\n$$\nWe are asked to compute $E^\\star$, the supremum of the absolute value of this error over the set $\\{(x_k, u_k) : |x_k| \\leq 1, |u_k| \\leq 1\\}$:\n$$\nE^\\star = \\sup_{\\substack{|x_k| \\leq 1 \\\\ |u_k| \\leq 1}} \\left| (\\exp(ah) - 1 - ah) \\left( x_k + \\frac{b}{a} u_k \\right) \\right|\n$$\nThis can be separated into two parts:\n$$\nE^\\star = \\left| \\exp(ah) - 1 - ah \\right| \\cdot \\sup_{\\substack{|x_k| \\leq 1 \\\\ |u_k| \\leq 1}} \\left| x_k + \\frac{b}{a} u_k \\right|\n$$\nLet's analyze the first term. The function $f(y) = \\exp(y) - 1 - y$ is a convex function with a global minimum at $y=0$, where $f(0)=0$. For any $y \\neq 0$, $f(y)  0$. Since $a \\neq 0$ and $h  0$, $ah \\neq 0$, so $\\exp(ah) - 1 - ah  0$. Thus, the absolute value is redundant.\n\nFor the second term, we need to find the supremum of $|x_k + \\frac{b}{a} u_k|$ for $|x_k| \\leq 1$ and $|u_k| \\leq 1$. By the triangle inequality:\n$$\n\\left| x_k + \\frac{b}{a} u_k \\right| \\leq |x_k| + \\left| \\frac{b}{a} u_k \\right| = |x_k| + \\left| \\frac{b}{a} \\right| |u_k|\n$$\nSince $|x_k| \\leq 1$ and $|u_k| \\leq 1$, the maximum value of the right-hand side is $1 + |b/a|$. This maximum is attainable by choosing $|x_k|=1$, $|u_k|=1$, and ensuring that $x_k$ and $(b/a)u_k$ have the same sign. For example, if $b/a  0$, we can choose $x_k=1$ and $u_k=-1$ to get $|1 - b/a| = 1 - b/a = 1 + |b/a|$. Thus, the supremum is indeed $1 + |b/a|$.\n\nCombining these results, the expression for the maximum error is:\n$$\nE^\\star = (\\exp(ah) - 1 - ah) \\left( 1 + \\left| \\frac{b}{a} \\right| \\right)\n$$\nNow, we substitute the given numerical values: $a=-1$, $b=2$, and $h=0.1$.\n$$\nah = (-1)(0.1) = -0.1\n$$\n$$\n\\frac{b}{a} = \\frac{2}{-1} = -2\n$$\nSubstituting these into the expression for $E^\\star$:\n$$\nE^\\star = (\\exp(-0.1) - 1 - (-0.1)) \\left( 1 + |-2| \\right)\n$$\n$$\nE^\\star = (\\exp(-0.1) - 0.9) (1 + 2)\n$$\n$$\nE^\\star = 3 (\\exp(-0.1) - 0.9)\n$$\nNow we compute the numerical value.\n$$\n\\exp(-0.1) \\approx 0.9048374180\n$$\n$$\nE^\\star \\approx 3 (0.9048374180 - 0.9)\n$$\n$$\nE^\\star \\approx 3 (0.0048374180)\n$$\n$$\nE^\\star \\approx 0.014512254\n$$\nThe problem requires rounding the result to six significant figures. The first six significant digits are $1, 4, 5, 1, 2, 2$. The seventh significant digit is $5$, so we round up the sixth digit.\n$$\nE^\\star \\approx 0.0145123\n$$",
            "answer": "$$\\boxed{0.0145123}$$"
        },
        {
            "introduction": "While many physical systems exhibit nonlinear behavior, their analysis can be prohibitively complex, a challenge often addressed by creating simpler surrogate models. This practice guides you through constructing a piecewise affine abstraction for a nonlinear system and, critically, deriving a rigorous worst-case error bound for your approximation using principles from calculus. This skill is vital for verifying the behavior of simplified models against their more complex, real-world counterparts. ",
            "id": "4249600",
            "problem": "A digital twin of a single-degree-of-freedom mechanical subsystem within a hierarchy of abstractions in Cyber-Physical Systems (CPS) uses a simplified surrogate for fast verification. The physical state variable is denoted by $x$, measured in radians, and the control input by $u$. The nonlinear nominal dynamics are given by $\\dot{x}=\\sin(x)+u$ for $x \\in [-\\pi,\\pi]$. To obtain a hierarchical, piecewise affine abstraction suitable for supervisory tasks, proceed as follows.\n\n1. Partition the domain $[-\\pi,\\pi]$ into three equal-length regions with knots at $x_{0}=-\\pi$, $x_{1}=-\\pi/3$, $x_{2}=\\pi/3$, and $x_{3}=\\pi$. On each region $[x_{k},x_{k+1}]$, define an affine surrogate $\\ell_{k}(x)$ for $\\sin(x)$ by linear interpolation of $\\sin(x)$ at the endpoints $x_{k}$ and $x_{k+1}$, and define the abstracted regional dynamics $\\dot{x}=\\ell_{k}(x)+u$.\n\n2. Using only well-tested interpolation error facts grounded in calculus, derive a uniform worst-case bound $E$ such that $\\sup_{x \\in [-\\pi,\\pi]}|\\sin(x)-\\ell(x)| \\leq E$, where $\\ell(x)$ denotes the piecewise linear interpolant formed by the $\\ell_{k}(x)$ on the three regions. Express the bound in exact closed form. No rounding is required.\n\nProvide as your final answer the exact closed-form expression for the bound $E$ only. All angles are in radians.",
            "solution": "The problem requires the derivation of a uniform worst-case error bound $E$ for the piecewise linear interpolation of the function $f(x) = \\sin(x)$ over the domain $[-\\pi, \\pi]$. The domain is partitioned into three intervals of equal length.\n\nThe fundamental principle governing the error of linear interpolation is a standard result from calculus. For a function $f(x)$ that is twice differentiable, the error $e(x) = f(x) - p_1(x)$, where $p_1(x)$ is the linear polynomial interpolating $f(x)$ at points $a$ and $b$, is given by:\n$$e(x) = \\frac{f''(\\xi)}{2!} (x-a)(x-b)$$\nfor some $\\xi \\in (a, b)$.\n\nTo find a bound on the error over the interval $[a, b]$, we take the absolute value and find its supremum. A standard upper bound is obtained by separating the terms:\n$$\\sup_{x \\in [a,b]} |f(x) - p_1(x)| \\leq \\frac{1}{2} \\left( \\sup_{t \\in [a,b]} |f''(t)| \\right) \\left( \\sup_{x \\in [a,b]} |(x-a)(x-b)| \\right)$$\nThe term $|(x-a)(x-b)|$ reaches its maximum value of $\\frac{(b-a)^2}{4}$ at the midpoint of the interval. Let $h = b-a$ be the length of the interval. The error bound becomes:\n$$\\sup_{x \\in [a,b]} |e(x)| \\leq \\frac{1}{2} \\left( \\sup_{t \\in [a,b]} |f''(t)| \\right) \\left( \\frac{h^2}{4} \\right) = \\frac{h^2}{8} \\sup_{t \\in [a,b]} |f''(t)|$$\nThis is the \"well-tested interpolation error fact\" the problem alludes to.\n\nIn this problem, $f(x) = \\sin(x)$. Its derivatives are $f'(x) = \\cos(x)$ and $f''(x) = -\\sin(x)$. Therefore, $|f''(x)| = |-\\sin(x)| = |\\sin(x)|$.\n\nThe domain $[-\\pi, \\pi]$ is partitioned into three intervals of equal length $h = \\frac{2\\pi}{3}$:\n$I_0 = [-\\pi, -\\frac{\\pi}{3}]$, $I_1 = [-\\frac{\\pi}{3}, \\frac{\\pi}{3}]$, and $I_2 = [\\frac{\\pi}{3}, \\pi]$.\nThe term $\\frac{h^2}{8}$ is constant for all intervals:\n$$\\frac{h^2}{8} = \\frac{1}{8}\\left(\\frac{2\\pi}{3}\\right)^2 = \\frac{1}{8}\\left(\\frac{4\\pi^2}{9}\\right) = \\frac{4\\pi^2}{72} = \\frac{\\pi^2}{18}$$\n\nThe uniform error bound $E$ over the entire domain $[-\\pi, \\pi]$ is the maximum of the error bounds from each sub-interval. Let $E_k$ be the error bound on interval $I_k$.\n$$E_k \\leq \\frac{\\pi^2}{18} \\sup_{t \\in I_k} |\\sin(t)|$$\n\nWe now compute the supremum of $|\\sin(t)|$ for each interval:\n1.  For $I_0 = [-\\pi, -\\frac{\\pi}{3}]$: The maximum value of $|\\sin(t)|$ is $1$ at $t = -\\frac{\\pi}{2}$.\n2.  For $I_1 = [-\\frac{\\pi}{3}, \\frac{\\pi}{3}]$: The maximum value of $|\\sin(t)|$ is $\\sin(\\frac{\\pi}{3}) = \\frac{\\sqrt{3}}{2}$ at the endpoints.\n3.  For $I_2 = [\\frac{\\pi}{3}, \\pi]$: The maximum value of $|\\sin(t)|$ is $1$ at $t=\\frac{\\pi}{2}$.\n\nTo find the uniform worst-case bound $E$, we must take a value that is greater than or equal to the error on all three intervals. We thus take the maximum of the individual bounds:\n$$ E = \\max\\left(\\frac{\\pi^2}{18} \\cdot 1, \\frac{\\pi^2}{18} \\cdot \\frac{\\sqrt{3}}{2}, \\frac{\\pi^2}{18} \\cdot 1\\right) $$\nSince $1 > \\frac{\\sqrt{3}}{2}$, the maximum of the three bounds is $\\frac{\\pi^2}{18}$.\n\nThus, a valid uniform worst-case bound $E$ for the approximation over the entire domain $[-\\pi, \\pi]$ is $\\frac{\\pi^2}{18}$.\n$$ \\sup_{x \\in [-\\pi,\\pi]}|\\sin(x)-\\ell(x)| \\leq \\frac{\\pi^2}{18} $$",
            "answer": "$$\\boxed{\\frac{\\pi^2}{18}}$$"
        },
        {
            "introduction": "Digital twins of large-scale systems can involve models with hundreds or thousands of states, making them unwieldy for analysis and real-time control. This practice introduces balanced truncation, a powerful and systematic method for model order reduction that creates a lower-dimensional abstraction while preserving the most significant input-output behaviors. By following the process from computing system Gramians to verifying the theoretical $H_\\infty$ error bound, you will gain insight into creating efficient and reliable hierarchical system models. ",
            "id": "4249595",
            "problem": "Consider a continuous-time, stable Linear Time-Invariant (LTI) system defined by the state-space equations $ \\dot{x}(t) = A x(t) + B u(t) $ and $ y(t) = C x(t) + D u(t) $, where $ A \\in \\mathbb{R}^{n \\times n}, B \\in \\mathbb{R}^{n \\times m}, C \\in \\mathbb{R}^{p \\times n}, D \\in \\mathbb{R}^{p \\times m} $. The controllability Gramian $ P \\in \\mathbb{R}^{n \\times n} $ and observability Gramian $ Q \\in \\mathbb{R}^{n \\times n} $ are defined for stable systems as the unique positive definite solutions to the continuous-time Lyapunov equations\n$$ A P + P A^\\top + B B^\\top = 0, \\quad A^\\top Q + Q A + C^\\top C = 0. $$\nA balancing transformation is a similarity transformation that maps the system into balanced coordinates such that the transformed controllability and observability Gramians are equal and diagonal, with entries equal to the Hankel singular values. One numerically reliable method constructs lower-triangular Cholesky factors $ S $ and $ R $ such that $ P = S S^\\top $ and $ Q = R R^\\top $, followed by a singular value decomposition of $ R^\\top S = U \\Sigma V^\\top $. The balancing transformation and its inverse are then\n$$ T = S V \\Sigma^{-1/2}, \\quad T^{-1} = \\Sigma^{-1/2} U^\\top R^\\top, $$\nwhich yield the balanced realization\n$$ A_b = T^{-1} A T, \\quad B_b = T^{-1} B, \\quad C_b = C T, \\quad D_b = D. $$\nOrdering the states by descending Hankel singular values $ \\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n $, define the $ r $-state balanced truncation by partitioning\n$$ A_b = \\begin{bmatrix} A_{11}  A_{12} \\\\ A_{21}  A_{22} \\end{bmatrix}, \\quad B_b = \\begin{bmatrix} B_1 \\\\ B_2 \\end{bmatrix}, \\quad C_b = \\begin{bmatrix} C_1  C_2 \\end{bmatrix}, $$\nwhere the partition sizes conform to retaining the first $ r $ states, and then taking the reduced-order model\n$$ A_r = A_{11}, \\quad B_r = B_1, \\quad C_r = C_1, \\quad D_r = D. $$\nThe error system $ E(s) = G(s) - G_r(s) $ is defined as the difference of transfer matrices of the original and reduced models, where\n$$ G(s) = C (s I - A)^{-1} B + D, \\quad G_r(s) = C_r (s I - A_r)^{-1} B_r + D_r. $$\nThe Hardy space ($H_\\infty$) norm of a transfer matrix is $ \\|G\\|_\\infty = \\sup_{\\omega \\in \\mathbb{R}} \\bar{\\sigma}(G(j\\omega)) $, where $ \\bar{\\sigma}(\\cdot) $ denotes the largest singular value. For balanced truncation, the error bound is\n$$ \\|G - G_r\\|_\\infty \\le 2 \\sum_{i=r+1}^{n} \\sigma_i. $$\nYour task is to implement the complete pipeline to:\n- Compute $ P $ and $ Q $ via the Lyapunov equations.\n- Compute the balancing transformation $ T $ and $ T^{-1} $ as defined above.\n- Form the balanced realization and perform a $ r = 2 $ state truncation.\n- Report the reduced matrices $ A_r, B_r, C_r, D_r $.\n- Numerically approximate $ \\|G - G_r\\|_\\infty $ by sampling frequencies $ \\omega $ uniformly in logarithmic scale over an interval specified below, with the angle unit specified explicitly.\n- Verify the error bound $ \\|G - G_r\\|_\\infty \\le 2 \\sum_{i=3}^{n} \\sigma_i $ numerically using the approximation.\n\nFundamental base to use: the definitions of controllability and observability Gramians, the singular value decomposition, and the $ H_\\infty $ norm definition via the supremum over frequency.\n\nNumerical approximation details:\n- Use a frequency grid of $ N = 1000 $ points logarithmically spaced over $ \\omega \\in [10^{-3}, 10^{3}] $ in radians per second.\n- For each $ \\omega $, compute $ G(j\\omega) $ using the definition above and take the largest singular value $ \\bar{\\sigma}(G(j\\omega)) $. For the error system $ E(j\\omega) $, take $ \\bar{\\sigma}(E(j\\omega)) $ similarly.\n- Approximate $ \\|G - G_r\\|_\\infty $ by the maximum over the sampled grid.\n- Use a numerical tolerance of $ 10^{-6} $ when comparing the approximate $ H_\\infty $ error against the theoretical bound.\n\nTest suite:\n- Case 1 (happy path, Single-Input Single-Output (SISO), $ n = 4, m = 1, p = 1 $):\n  $$ A_1 = \\begin{bmatrix}\n  -1.0  0.2  0  0 \\\\\n  -0.1  -2.0  0.1  0 \\\\\n  0  0.05  -3.0  0.2 \\\\\n  0  0  -0.1  -0.5\n  \\end{bmatrix}, \\quad\n  B_1 = \\begin{bmatrix} 1.0 \\\\ 0.5 \\\\ 0.2 \\\\ 0.1 \\end{bmatrix}, \\quad\n  C_1 = \\begin{bmatrix} 0.5  -0.3  0.2  0.1 \\end{bmatrix}, \\quad\n  D_1 = \\begin{bmatrix} 0.0 \\end{bmatrix}. $$\n- Case 2 (edge case with weakly controllable/observable tail states, SISO, $ n = 5, m = 1, p = 1 $):\n  $$ A_2 = \\begin{bmatrix}\n  -0.5  0.05  0  0  0 \\\\\n  0  -1.0  0.02  0  0 \\\\\n  0  0  -2.5  0.03  0 \\\\\n  0  0  0  -5.0  0.01 \\\\\n  0  0  0  0  -8.0\n  \\end{bmatrix}, \\quad\n  B_2 = \\begin{bmatrix} 0.1 \\\\ 1.0 \\\\ 0.01 \\\\ 0.005 \\\\ 0.002 \\end{bmatrix}, \\quad\n  C_2 = \\begin{bmatrix} 0.2  1.0  0.01  0.005  0.002 \\end{bmatrix}, \\quad\n  D_2 = \\begin{bmatrix} 0.0 \\end{bmatrix}. $$\n- Case 3 (Multiple-Input Multiple-Output (MIMO), $ n = 4, m = 2, p = 2 $):\n  $$ A_3 = \\begin{bmatrix}\n  -1.5  0.3  0  0 \\\\\n  0  -0.8  0.25  0 \\\\\n  0  0  -2.0  0.4 \\\\\n  0  0  0  -3.0\n  \\end{bmatrix}, \\quad\n  B_3 = \\begin{bmatrix}\n  1.0  0.0 \\\\\n  0.5  0.2 \\\\\n  0.0  1.0 \\\\\n  0.1  0.0\n  \\end{bmatrix}, \\quad\n  C_3 = \\begin{bmatrix}\n  0.8  0.0  0.1  0.0 \\\\\n  0.0  0.5  0.0  0.2\n  \\end{bmatrix}, \\quad\n  D_3 = \\begin{bmatrix}\n  0.0  0.0 \\\\\n  0.0  0.0\n  \\end{bmatrix}. $$\n\nRequired outputs and format:\n- For each test case, produce the reduced matrices $ A_r, B_r, C_r, D_r $, the theoretical error bound $ 2 \\sum_{i=3}^{n} \\sigma_i $, the numerically approximated $ H_\\infty $ error $ \\|G - G_r\\|_\\infty $, and a boolean indicating whether the bound holds within the specified tolerance.\n- Round all matrix entries and scalar outputs to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). Each result should itself be a list of the form\n$$ [A_r, B_r, C_r, D_r, \\text{bound}, \\text{error}, \\text{flag}] $$\nwhere $ A_r, B_r, C_r, D_r $ are represented as nested lists of floats, \"bound\" and \"error\" are floats, and \"flag\" is a boolean. The angle unit for the frequency sweep must be radians per second.",
            "solution": "The user has provided a well-defined problem in the domain of control theory, specifically concerning model order reduction of linear time-invariant (LTI) systems using the balanced truncation method. The problem is scientifically grounded, internally consistent, and contains all necessary information to proceed with a solution.\n\nThe task is to implement a computational pipeline that, for a given stable LTI system, performs the following steps:\n1.  Computes the controllability and observability Gramians.\n2.  Determines the balancing similarity transformation.\n3.  Calculates the balanced realization of the system.\n4.  Performs model reduction via truncation to a specified order $r=2$.\n5.  Calculates the theoretical $H_\\infty$ error bound.\n6.  Numerically approximates the actual $H_\\infty$ error norm of the difference between the full and reduced-order models.\n7.  Verifies that the numerical error is within the theoretical bound.\n\nThe solution will be implemented by systematically following the procedure described in the problem statement.\n\n### Step 1: Gramian Computation\nFor a stable continuous-time LTI system described by state-space matrices $(A, B, C, D)$, the controllability Gramian $P$ and observability Gramian $Q$ are the unique, symmetric, positive definite solutions to the continuous-time Lyapunov equations:\n$$ A P + P A^\\top + B B^\\top = 0 $$\n$$ A^\\top Q + Q A + C^\\top C = 0 $$\nThese equations can be rearranged into the standard form $M X + X M^\\top = -K$ required by numerical solvers.\nFor the controllability Gramian $P$, we have $M=A$ and $K=BB^\\top$, leading to the equation $A P + P A^\\top = -B B^\\top$.\nFor the observability Gramian $Q$, we have $M=A^\\top$ and $K=C^\\top C$, leading to the equation $A^\\top Q + Q (A^\\top)^\\top = -C^\\top C$.\nWe will use a numerical linear algebra library function, specifically `scipy.linalg.solve_continuous_lyapunov`, to solve for $P$ and $Q$. The stability of the matrix $A$ (all eigenvalues in the open left-half complex plane), which is a given condition for the test cases, ensures that unique positive definite solutions exist.\n\n### Step 2: Balancing Transformation\nThe goal of a balancing transformation is to find a new coordinate system in which the controllability and observability Gramians are equal and diagonal. The diagonal entries are the Hankel singular values, $\\sigma_i$. The procedure is as follows:\n1.  Compute the Cholesky factorizations of the Gramians: $P = S S^\\top$ and $Q = R R^\\top$, where $S$ and $R$ are lower-triangular matrices.\n2.  Compute the singular value decomposition (SVD) of the product $R^\\top S = U \\Sigma V^\\top$. The diagonal matrix $\\Sigma$ contains the Hankel singular values, $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n  0$.\n3.  From the SVD components, a state-space transformation matrix $T$ and its inverse $T^{-1}$ are constructed, which map the original system to the balanced one:\n    $$ T = S V \\Sigma^{-1/2} $$\n    $$ T^{-1} = \\Sigma^{-1/2} U^\\top R^\\top $$\n\n### Step 3: Model Reduction\nUsing the transformation matrix $T$, the original system $(A, B, C, D)$ is transformed into a balanced realization $(A_b, B_b, C_b, D_b)$:\n$$ A_b = T^{-1} A T, \\quad B_b = T^{-1} B, \\quad C_b = C T, \\quad D_b = D $$\nIn this new balanced coordinate system, the states are ordered according to the magnitude of their corresponding Hankel singular values. States associated with small $\\sigma_i$ are weakly controllable and observable and thus contribute least to the input-output behavior.\nModel reduction is achieved by truncating the balanced system, keeping only the first $r$ states. For this problem, $r=2$. The balanced matrices are partitioned as:\n$$ A_b = \\begin{bmatrix} A_{11}  A_{12} \\\\ A_{21}  A_{22} \\end{bmatrix}, \\quad B_b = \\begin{bmatrix} B_1 \\\\ B_2 \\end{bmatrix}, \\quad C_b = \\begin{bmatrix} C_1  C_2 \\end{bmatrix}, $$\nwhere $A_{11}$ is $r \\times r$. The reduced-order model $(A_r, B_r, C_r, D_r)$ is then given by:\n$$ A_r = A_{11}, \\quad B_r = B_1, \\quad C_r = C_1, \\quad D_r = D $$\n\n### Step 4: Error Analysis and Verification\nA key property of balanced truncation is the existence of an a priori error bound. The error, measured by the $H_\\infty$ norm of the difference between the full-order transfer function $G(s)$ and the reduced-order transfer function $G_r(s)$, is bounded by twice the sum of the truncated Hankel singular values:\n$$ \\|G - G_r\\|_\\infty \\le 2 \\sum_{i=r+1}^{n} \\sigma_i $$\nFor this problem, with $r=2$, the bound is $2 \\sum_{i=3}^{n} \\sigma_i$.\n\nThe $H_\\infty$ norm of the error system $E(s) = G(s) - G_r(s)$ is defined as $\\|E\\|_\\infty = \\sup_{\\omega \\in \\mathbb{R}} \\bar{\\sigma}(E(j\\omega))$, where $\\bar{\\sigma}$ is the largest singular value. We will approximate this norm numerically by evaluating $\\bar{\\sigma}(G(j\\omega_k) - G_r(j\\omega_k))$ over a discrete grid of $N=1000$ frequencies $\\omega_k$ logarithmically spaced in the interval $[10^{-3}, 10^3]$ rad/s. The transfer functions are computed from the state-space models:\n$$ G(j\\omega) = C(j\\omega I - A)^{-1}B + D $$\n$$ G_r(j\\omega) = C_r(j\\omega I_r - A_r)^{-1}B_r + D_r $$\nThe maximum value of $\\bar{\\sigma}$ found over the grid serves as the numerical approximation of $\\|G - G_r\\|_\\infty$. Finally, we will verify if this numerically computed error is less than or equal to the theoretical bound, allowing for a numerical tolerance of $10^{-6}$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_continuous_lyapunov\n\ndef solve():\n    \"\"\"\n    Main function to solve the balanced truncation problem for all test cases.\n    \"\"\"\n\n    def process_case(A, B, C, D, r=2, N=1000, omega_range=(1e-3, 1e3), tol=1e-6):\n        \"\"\"\n        Performs balanced truncation and error analysis for a single LTI system.\n        \"\"\"\n        n = A.shape[0]\n\n        # Step 1: Compute Controllability and Observability Gramians\n        # The equation for P is AP + PA' + BB' = 0, or AP + PA' = -BB'\n        # scipy.linalg.solve_continuous_lyapunov solves AX + XA' = Q\n        P = solve_continuous_lyapunov(A, -B @ B.T)\n\n        # The equation for Q is A'Q + QA + C'C = 0, or A'Q + QA = -C'C\n        # We solve it for the system matrix A.T\n        Q = solve_continuous_lyapunov(A.T, -C.T @ C)\n\n        # Step 2: Cholesky factorization of Gramians\n        # P = S S', Q = R R', with S, R lower-triangular\n        try:\n            S = np.linalg.cholesky(P)\n            R = np.linalg.cholesky(Q)\n        except np.linalg.LinAlgError:\n            # This would happen if Gramians are not positive definite\n            return \"Error: Gramians not positive definite.\"\n\n        # Step 3: Singular Value Decomposition to find Hankel singular values\n        # R'S = U * Sigma * V'\n        U, hankel_svs, Vt = np.linalg.svd(R.T @ S)\n\n        # Step 4: Construct the balancing transformation T and its inverse T_inv\n        Sigma_inv_sqrt = np.diag(1.0 / np.sqrt(hankel_svs))\n        V = Vt.T\n        T = S @ V @ Sigma_inv_sqrt\n        T_inv = Sigma_inv_sqrt @ U.T @ R.T\n\n        # Step 5: Transform to balanced realization and truncate\n        A_b = T_inv @ A @ T\n        B_b = T_inv @ B\n        C_b = C @ T\n\n        A_r = A_b[:r, :r]\n        B_r = B_b[:r, :]\n        C_r = C_b[:, :r]\n        D_r = D\n\n        # Step 6: Calculate theoretical error bound\n        error_bound = 2 * np.sum(hankel_svs[r:])\n\n        # Step 7: Numerically approximate the H-infinity norm of the error system\n        # Frequency grid uses radians per second, as specified.\n        omega = np.logspace(np.log10(omega_range[0]), np.log10(omega_range[1]), N)\n        max_sv_error = 0.0\n\n        I_n = np.eye(n)\n        I_r = np.eye(r)\n\n        for w in omega:\n            s_val = 1j * w\n            \n            # Transfer matrix of the full system\n            G_jw = C @ np.linalg.inv(s_val * I_n - A) @ B + D\n            \n            # Transfer matrix of the reduced system\n            Gr_jw = C_r @ np.linalg.inv(s_val * I_r - A_r) @ B_r + D_r\n            \n            # Error system\n            E_jw = G_jw - Gr_jw\n            \n            # Largest singular value of the error matrix\n            sv_E = np.linalg.svd(E_jw, compute_uv=False)\n            current_max_sv = sv_E[0]\n            \n            if current_max_sv > max_sv_error:\n                max_sv_error = current_max_sv\n        \n        h_inf_error = max_sv_error\n\n        # Step 8: Verify the error bound\n        bound_holds = h_inf_error = error_bound + tol\n\n        # Step 9: Format results for output\n        def format_matrix(m):\n            return np.round(m, 6).tolist()\n        \n        def format_scalar(s):\n            return round(s, 6)\n\n        result = [\n            format_matrix(A_r),\n            format_matrix(B_r),\n            format_matrix(C_r),\n            format_matrix(D_r),\n            format_scalar(error_bound),\n            format_scalar(h_inf_error),\n            bound_holds\n        ]\n        return result\n\n    # Test suite with three cases\n    test_cases = [\n        (\n            np.array([[-1.0, 0.2, 0, 0], [-0.1, -2.0, 0.1, 0], [0, 0.05, -3.0, 0.2], [0, 0, -0.1, -0.5]]),\n            np.array([[1.0], [0.5], [0.2], [0.1]]),\n            np.array([[0.5, -0.3, 0.2, 0.1]]),\n            np.array([[0.0]])\n        ),\n        (\n            np.array([[-0.5, 0.05, 0, 0, 0], [0, -1.0, 0.02, 0, 0], [0, 0, -2.5, 0.03, 0], [0, 0, 0, -5.0, 0.01], [0, 0, 0, 0, -8.0]]),\n            np.array([[0.1], [1.0], [0.01], [0.005], [0.002]]),\n            np.array([[0.2, 1.0, 0.01, 0.005, 0.002]]),\n            np.array([[0.0]])\n        ),\n        (\n            np.array([[-1.5, 0.3, 0, 0], [0, -0.8, 0.25, 0], [0, 0, -2.0, 0.4], [0, 0, 0, -3.0]]),\n            np.array([[1.0, 0.0], [0.5, 0.2], [0.0, 1.0], [0.1, 0.0]]),\n            np.array([[0.8, 0.0, 0.1, 0.0], [0.0, 0.5, 0.0, 0.2]]),\n            np.array([[0.0, 0.0], [0.0, 0.0]])\n        )\n    ]\n\n    results = []\n    for A, B, C, D in test_cases:\n        results.append(process_case(A, B, C, D))\n\n    # Print the final result in the requested compact single-line format.\n    # str(results).replace(' ', '') creates a python-literal-like string without spaces.\n    print(str(results).replace(' ', ''))\n\nsolve()\n```"
        }
    ]
}