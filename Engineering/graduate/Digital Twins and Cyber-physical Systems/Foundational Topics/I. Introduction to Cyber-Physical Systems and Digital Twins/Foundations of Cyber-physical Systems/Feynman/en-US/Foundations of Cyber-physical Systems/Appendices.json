{
    "hands_on_practices": [
        {
            "introduction": "Cyber-physical systems often involve multiple processes or agents competing for limited resources, such as processors, communication channels, or physical devices. Uncoordinated resource sharing can lead to concurrency issues like deadlock, where the system grinds to a halt. This exercise introduces Petri nets as a powerful formal method for modeling and analyzing such discrete-event systems. By engaging with this problem, you will learn to identify structural properties like siphons and traps that correspond to deadlock-prone states and design a supervisory controller to provably enforce liveness, a foundational skill for building robust and reliable CPS .",
            "id": "4223669",
            "problem": "Consider a resource-sharing Cyber-Physical System (CPS) modeled by a Petri net (PN) with two reusable resources and a population of tasks whose acquisition order of resources is non-deterministic (free-choice). The PN has the set of places $P = \\{r_{A}, r_{B}, p^{s}, p^{A}, p^{B}, p^{AB}\\}$ and transitions $T = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$. The arcs are defined as follows, using the standard notation where the pre-set of a transition $t$ is $\\bullet t \\subseteq P$ and its post-set is $t \\bullet \\subseteq P$:\n- $t_{A}^{\\text{start}}$: $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$ and $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$,\n- $t_{B}^{\\text{start}}$: $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$ and $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$,\n- $t_{A\\to B}$: $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$ and $t_{A\\to B} \\bullet = \\{p^{AB}\\}$,\n- $t_{B\\to A}$: $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$ and $t_{B\\to A} \\bullet = \\{p^{AB}\\}$,\n- $t^{\\text{rel}}$: $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$ and $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$.\n\nThe initial marking is $M_{0}(r_{A}) = c_{A}$, $M_{0}(r_{B}) = c_{B}$, $M_{0}(p^{s}) = n$, and $M_{0}(p^{A}) = M_{0}(p^{B}) = M_{0}(p^{AB}) = 0$, with $c_{A}, c_{B}, n \\in \\mathbb{N}$ and $c_{A} \\geq 1$, $c_{B} \\geq 1$, $n \\geq 1$. This PN models $n$ task instances cycling through the system, where each instance non-deterministically starts by acquiring either resource $A$ or resource $B$, then acquires the other resource, and finally releases both and returns to ready.\n\nUse the following foundational definitions.\n- A subset of places $S \\subseteq P$ is a siphon if every transition that has an output arc to a place in $S$ also has an input arc from a place in $S$, equivalently $\\bullet S \\subseteq S \\bullet$ where $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$ and $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$.\n- A subset of places $U \\subseteq P$ is a trap if every transition that has an input arc from a place in $U$ also has an output arc to a place in $U$, equivalently $U \\bullet \\subseteq \\bullet U$ where $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$ and $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$.\n- A marking $M$ is live if from $M$ every transition in $T$ can be enabled at least once in some continuation (no deadlock). A classical necessary condition to avoid deadlock is that no siphon becomes unmarked (empty of tokens) along any reachable execution.\n\nTasks:\n1. Identify a siphon $S$ for this PN whose emptiness would result in deadlock. Prove that $S$ is a siphon using the formal definition, and explain informally why its emptiness prevents any transition from returning tokens to $S$.\n2. Identify a trap $U$ for this PN that is initially marked under $M_{0}$, and argue whether $U \\subseteq S$ holds; discuss the implication for deadlock risk under $M_{0}$.\n3. Propose a non-intrusive supervisory control action consistent with digital twin supervisory control: add a single control place $u$ with arcs $\\bullet t_{A}^{\\text{start}} \\gets u$, $\\bullet t_{B}^{\\text{start}} \\gets u$, and $t^{\\text{rel}} \\bullet \\to u$, so that each start transition consumes one token from $u$ and each release transition produces one token to $u$. Let the initial marking of the control place be $M_{0}(u) = K$, with $K \\in \\mathbb{N}$. Derive, from first principles and using place-level token balance, the minimal value of $K$ as a function of $c_{A}$ and $c_{B}$ that guarantees that the siphon identified in Task 1 never becomes unmarked along any reachable execution, thereby enforcing liveness with respect to deadlock due to siphon emptiness. Express your final answer as a single closed-form expression in terms of $c_{A}$ and $c_{B}$ only. No rounding is required.",
            "solution": "The user wants me to analyze a Petri net model of a resource-sharing Cyber-Physical System.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n-   Petri Net (PN) Structure:\n    -   Set of places: $P = \\{r_{A}, r_{B}, p^{s}, p^{A}, p^{B}, p^{AB}\\}$\n    -   Set of transitions: $T = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$\n    -   Arcs (pre-sets $\\bullet t$ and post-sets $t \\bullet$):\n        -   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$, $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$\n        -   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$, $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$\n        -   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$, $t_{A\\to B} \\bullet = \\{p^{AB}\\}$\n        -   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$, $t_{B\\to A} \\bullet = \\{p^{AB}\\}$\n        -   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$, $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$\n-   Initial Marking ($M_{0}$):\n    -   $M_{0}(r_{A}) = c_{A}$\n    -   $M_{0}(r_{B}) = c_{B}$\n    -   $M_{0}(p^{s}) = n$\n    -   $M_{0}(p^{A}) = M_{0}(p^{B}) = M_{0}(p^{AB}) = 0$\n    -   Constraints: $c_{A}, c_{B}, n \\in \\mathbb{N}$ with $c_{A} \\geq 1$, $c_{B} \\geq 1$, $n \\geq 1$.\n-   Definitions:\n    -   Siphon $S \\subseteq P$: $\\bullet S \\subseteq S \\bullet$, where $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$ and $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$.\n    -   Trap $U \\subseteq P$: $U \\bullet \\subseteq \\bullet U$, where $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$ and $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$.\n    -   Liveness: A marking is live if every transition can be eventually enabled.\n-   Tasks:\n    1.  Identify a deadlock-related siphon $S$, prove it is a siphon, and explain the consequence of its emptiness.\n    2.  Identify an initially marked trap $U$, check if $U \\subseteq S$, and discuss implications.\n    3.  Add a control place $u$ with arcs $\\bullet t_{A}^{\\text{start}} \\gets u$, $\\bullet t_{B}^{\\text{start}} \\gets u$, $t^{\\text{rel}} \\bullet \\to u$, and initial marking $M_{0}(u) = K$. Derive the minimal value of $K$ in terms of $c_{A}$ and $c_{B}$ that guarantees the siphon from Task 1 never becomes unmarked.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in Petri net theory, a standard formalism for modeling and analyzing concurrent systems, particularly for resource allocation and deadlock analysis in fields like computer science and cyber-physical systems. The concepts of siphons, traps, liveness, and supervisory control are central to this theory.\n-   **Well-Posed:** The Petri net structure, initial state, and all relevant definitions are provided completely and unambiguously. The tasks are specific, logically connected, and solvable using the provided information and standard Petri net analysis techniques.\n-   **Objective:** The problem is stated using formal mathematical language and established scientific terminology, free of any subjective or ambiguous content.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n**Solution**\n\n**Task 1: Siphon Identification and Proof**\n\nA deadlock in this system corresponds to a state where tasks are waiting for resources that are held by other waiting tasks. This suggests a circular wait, which often relates to an unmarked siphon. A key set of places in this process involves the resources themselves ($r_A, r_B$) and the place where tasks hold both resources ($p^{AB}$) before releasing them. Let us propose the set $S = \\{r_{A}, r_{B}, p^{AB}\\}$ as a candidate siphon.\n\nTo prove that $S$ is a siphon, we must show that $\\bullet S \\subseteq S \\bullet$. We first compute the set of input transitions to $S$, $\\bullet S$, and the set of output transitions from $S$, $S \\bullet$.\n\nThe set of input transitions to $S$, $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$, consists of all transitions that add tokens to any place in $S$.\n-   $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$. $\\{p^{A}\\} \\cap S = \\emptyset$.\n-   $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$. $\\{p^{B}\\} \\cap S = \\emptyset$.\n-   $t_{A\\to B} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in \\bullet S$.\n-   $t_{B\\to A} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in \\bullet S$.\n-   $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$. $\\{r_{A}, r_{B}, p^{s}\\} \\cap S = \\{r_{A}, r_{B}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in \\bullet S$.\nThus, the set of input transitions is $\\bullet S = \\{t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nThe set of output transitions from $S$, $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$, consists of all transitions that consume tokens from any place in $S$.\n-   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$. $\\{p^{s}, r_{A}\\} \\cap S = \\{r_{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in S \\bullet$.\n-   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$. $\\{p^{s}, r_{B}\\} \\cap S = \\{r_{B}\\} \\neq \\emptyset$, so $t_{B}^{\\text{start}} \\in S \\bullet$.\n-   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$. $\\{p^{A}, r_{B}\\} \\cap S = \\{r_{B}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in S \\bullet$.\n-   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$. $\\{p^{B}, r_{A}\\} \\cap S = \\{r_{A}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in S \\bullet$.\n-   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in S \\bullet$.\nThus, the set of output transitions is $S \\bullet = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nComparing the two sets, we see that $\\bullet S = \\{t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$ is a subset of $S \\bullet = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$. Therefore, $\\bullet S \\subseteq S \\bullet$, and $S = \\{r_{A}, r_{B}, p^{AB}\\}$ is a siphon.\n\nIf this siphon $S$ becomes empty (unmarked), it means $M(r_{A})=0$, $M(r_{B})=0$, and $M(p^{AB})=0$. For the siphon to become marked again, at least one of its input transitions, $t \\in \\bullet S$, must fire. The transitions in $\\bullet S$ are $t_{A\\to B}$, $t_{B\\to A}$, and $t^{\\text{rel}}$.\n-   Firing $t_{A\\to B}$ requires a token in $r_{B}$. Since $M(r_{B})=0$, this is not possible.\n-   Firing $t_{B\\to A}$ requires a token in $r_{A}$. Since $M(r_{A})=0$, this is not possible.\n-   Firing $t^{\\text{rel}}$ requires a token in $p^{AB}$. Since $M(p^{AB})=0$, this is not possible.\nSince no input transition to $S$ can fire, an empty siphon $S$ will remain empty forever. In this state, not only these three transitions are disabled but all other transitions are as well: $t_{A}^{\\text{start}}$ requires a token in $r_{A}$ and $t_{B}^{\\text{start}}$ requires a token in $r_{B}$. Thus, the emptiness of $S$ implies a total deadlock of the system.\n\n**Task 2: Trap Identification and Analysis**\n\nA trap is a set of places that, once marked, can never become empty. The P-invariants of the net often correspond to traps. The conservation of resource $A$ is represented by the invariant $M(r_{A}) + M(p^{A}) + M(p^{AB}) = c_{A}$. Let's test the corresponding set of places $U = \\{r_{A}, p^{A}, p^{AB}\\}$ to see if it is a trap.\n\nTo prove that $U$ is a trap, we must show that $U \\bullet \\subseteq \\bullet U$.\nThe set of output transitions from $U$, $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$:\n-   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$. $\\{p^{s}, r_{A}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in U \\bullet$.\n-   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$. Intersection is empty.\n-   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$. $\\{p^{A}, r_{B}\\} \\cap U = \\{p^{A}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in U \\bullet$.\n-   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$. $\\{p^{B}, r_{A}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in U \\bullet$.\n-   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in U \\bullet$.\nThus, $U \\bullet = \\{t_{A}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nThe set of input transitions to $U$, $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$:\n-   $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$. $\\{p^{A}\\} \\cap U = \\{p^{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in \\bullet U$.\n-   $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$. Intersection is empty.\n-   $t_{A\\to B} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in \\bullet U$.\n-   $t_{B\\to A} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in \\bullet U$.\n-   $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$. $\\{r_{A}, r_{B}, p^{s}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in \\bullet U$.\nThus, $\\bullet U = \\{t_{A}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nSince $U \\bullet = \\bullet U$, the condition $U \\bullet \\subseteq \\bullet U$ holds. Therefore, $U = \\{r_{A}, p^{A}, p^{AB}\\}$ is a trap.\nThe initial marking of this trap is $M_{0}(U) = M_{0}(r_{A}) + M_{0}(p^{A}) + M_{0}(p^{AB}) = c_{A} + 0 + 0 = c_{A}$. Since $c_{A} \\geq 1$, the trap $U$ is initially marked.\n\nNow we check if $U \\subseteq S$.\n$U = \\{r_{A}, p^{A}, p^{AB}\\}$\n$S = \\{r_{A}, r_{B}, p^{AB}\\}$\nThe inclusion $U \\subseteq S$ does not hold because $p^{A} \\in U$ but $p^{A} \\notin S$.\n\nA fundamental result in Petri net theory is that a siphon that contains an initially marked trap can never become empty. In our case, the dangerous siphon $S$ does not contain the initially marked trap $U$. This lack of a structural guarantee (an initially marked trap inside the siphon) is precisely why the siphon $S$ *can* become empty, leading to the possibility of deadlock.\n\n**Task 3: Supervisory Control for Liveness**\n\nThe supervisory control action adds a control place $u$ with arcs from $u$ to $t_{A}^{\\text{start}}$ and $t_{B}^{\\text{start}}$, and an arc from $t^{\\text{rel}}$ to $u$. The initial marking is $M_0(u)=K$. This control structure creates a new place invariant. The change in marking for the new place $u$ for each transition is: `[-1, -1, 0, 0, 1]`. The sum of markings for places $p^A$, $p^B$, $p^{AB}$, and $u$ is invariant. Let's verify:\n- For $t_{A}^{\\text{start}}$: $+1$ in $p^A$, $-1$ in $u$. Sum change is $0$.\n- For $t_{B}^{\\text{start}}$: $+1$ in $p^B$, $-1$ in $u$. Sum change is $0$.\n- For $t_{A\\to B}$: $-1$ in $p^A$, $+1$ in $p^{AB}$. Sum change is $0$.\n- For $t_{B\\to A}$: $-1$ in $p^B$, $+1$ in $p^{AB}$. Sum change is $0$.\n- For $t^{\\text{rel}}$: $-1$ in $p^{AB}$, $+1$ in $u$. Sum change is $0$.\n\nThus, for any reachable marking $M$, the following P-invariant holds:\n$M(p^{A}) + M(p^{B}) + M(p^{AB}) + M(u) = \\text{constant}$.\nThe constant is determined by the initial marking $M_0$:\n$M_{0}(p^{A}) + M_{0}(p^{B}) + M_{0}(p^{AB}) + M_{0}(u) = 0 + 0 + 0 + K = K$.\nSo, for any reachable marking $M$: $M(p^{A}) + M(p^{B}) + M(p^{AB}) + M(u) = K$.\n\nThe problem is to find the value of $K$ that guarantees the siphon $S = \\{r_A, r_B, p^{AB}\\}$ never becomes unmarked, i.e., $M(S) = M(r_{A}) + M(r_{B}) + M(p^{AB}) > 0$ for all reachable $M$.\n\nWe use the existing P-invariants of the system:\n1. $M(r_{A}) + M(p^{A}) + M(p^{AB}) = c_{A} \\implies M(r_{A}) = c_{A} - M(p^{A}) - M(p^{AB})$\n2. $M(r_{B}) + M(p^{B}) + M(p^{AB}) = c_{B} \\implies M(r_{B}) = c_{B} - M(p^{B}) - M(p^{AB})$\n\nWe substitute these into the expression for the marking of the siphon $S$:\n$M(S) = (c_{A} - M(p^{A}) - M(p^{AB})) + (c_{B} - M(p^{B}) - M(p^{AB})) + M(p^{AB})$\n$M(S) = c_{A} + c_{B} - (M(p^{A}) + M(p^{B}) + M(p^{AB}))$\n\nLet's denote the number of tasks currently active in the system (i.e., those that have acquired at least one resource) as $N_{\\text{active}}(M) = M(p^{A}) + M(p^{B}) + M(p^{AB})$. The expression for the siphon marking becomes:\n$M(S) = c_{A} + c_{B} - N_{\\text{active}}(M)$.\n\nTo guarantee $M(S) > 0$, we must ensure that $c_{A} + c_{B} - N_{\\text{active}}(M) > 0$ for any reachable marking $M$. This is equivalent to the condition:\n$N_{\\text{active}}(M)  c_{A} + c_{B}$.\n\nThe control place $u$ imposes a constraint on $N_{\\text{active}}$. From the new invariant $N_{\\text{active}}(M) + M(u) = K$, and since the marking of any place must be non-negative ($M(u) \\geq 0$), we have:\n$N_{\\text{active}}(M) \\leq K$.\n\nTo satisfy the liveness condition $N_{\\text{active}}(M)  c_{A} + c_{B}$ for all reachable markings, we must choose $K$ such that the upper bound on $N_{\\text{active}}(M)$ is strictly less than $c_{A} + c_{B}$. Thus, we must set $K  c_{A} + c_{B}$.\n\nThe problem describes a \"non-intrusive\" supervisor and asks for a single value of $K$. In supervisory control theory, a non-intrusive or maximally permissive supervisor is one that restricts the system's behavior as little as possible while enforcing the desired property. The number of concurrent tasks is bounded by $K$. To be as non-intrusive as possible, we should allow the maximum number of tasks consistent with liveness. This corresponds to choosing the largest integer value of $K$ that satisfies the inequality $K  c_{A} + c_{B}$.\n\nThe largest integer $K$ satisfying $K  c_{A} + c_{B}$ is $K = c_{A} + c_{B} - 1$.\nThis choice guarantees that $N_{\\text{active}}(M) \\leq c_{A} + c_{B} - 1$, which ensures $N_{\\text{active}}(M)  c_{A} + c_{B}$. This, in turn, guarantees $M(S) = c_{A} + c_{B} - N_{\\text{active}}(M) \\ge c_{A} + c_{B} - (c_{A} + c_{B} - 1) = 1$. The siphon marking is always at least $1$, so it never becomes empty.\nThis value is also necessary: if $K \\geq c_{A} + c_{B}$, it would be possible (with $n \\geq c_{A} + c_{B}$ tasks) to reach a deadlock state where $N_{\\text{active}}(M) = c_{A} + c_{B}$, resulting in $M(S) = 0$.\n\nTherefore, the required value for $K$ is $c_{A} + c_{B} - 1$.",
            "answer": "$$\n\\boxed{c_{A} + c_{B} - 1}\n$$"
        },
        {
            "introduction": "In many advanced CPS, such as autonomous robots or vehicles, the control system must simultaneously pursue performance objectives (e.g., reaching a target) while adhering to strict safety constraints (e.g., avoiding obstacles or respecting physical limits). This practice delves into a state-of-the-art control synthesis technique that elegantly unifies these competing demands. You will formulate and solve a real-time quadratic program (QP) that synthesizes a control input by minimizing a cost function subject to constraints derived from Control Lyapunov Functions (CLFs) for performance and Control Barrier Functions (CBFs) for safety . This hands-on implementation will provide you with practical insight into ensuring provable safety for continuous dynamical systems.",
            "id": "4223707",
            "problem": "Consider a cyber-physical plant modeled as a single-input single-output continuous-time system with state $x \\in \\mathbb{R}$ and control input $u \\in \\mathbb{R}$, governed by the single-integrator dynamics $\\dot{x} = u$. You are asked to unify a Control Lyapunov Function (CLF) objective with a Control Barrier Function (CBF) constraint via a Quadratic Program (QP) and to analyze feasibility when the CLF objective and the CBF constraint are in conflict, especially in the presence of actuator limits.\n\nStart from the following foundational definitions and laws:\n- The CLF $V(x)$ is a continuously differentiable, positive definite function, with a desired decrease rate quantified by a constant $c  0$. For the single-integrator model, use $V(x) = \\frac{1}{2} x^2$. The CLF condition is expressed in terms of Lie derivatives $L_f V(x)$ and $L_g V(x)$ along the drift $f(x)$ and input vector field $g(x)$. For the single-integrator, the drift is $f(x) = 0$ and the input vector field is $g(x) = 1$, hence $L_f V(x) = 0$ and $L_g V(x) = \\frac{\\partial V}{\\partial x} = x$. To allow regulation to coexist with safety, include a nonnegative slack variable $\\delta \\ge 0$ that relaxes the CLF inequality. The relaxed CLF constraint is\n$$\nx u \\le -\\frac{c}{2} x^2 + \\delta.\n$$\n- The CBF $h(x)$ defines a forward-invariant safe set $\\{x \\mid h(x) \\ge 0\\}$ by enforcing the inequality $\\dot{h}(x) + \\alpha h(x) \\ge 0$ for some $\\alpha  0$ (a class-$\\mathcal{K}$ gain). Use the affine barrier $h(x) = x - x_{\\min}$ where $x_{\\min} \\in \\mathbb{R}$ denotes a safety threshold. For the single-integrator model, this yields\n$$\nu + \\alpha (x - x_{\\min}) \\ge 0,\n$$\nor equivalently\n$$\nu \\ge -\\alpha (x - x_{\\min}).\n$$\n- To encode actuator limits, impose box constraints $u_{\\min} \\le u \\le u_{\\max}$ with given constants $u_{\\min} \\in \\mathbb{R}$ and $u_{\\max} \\in \\mathbb{R}$.\n\nFormulate the following convex Quadratic Program (QP) that unifies the CLF objective with the CBF constraint:\n- Decision variables: $(u, \\delta) \\in \\mathbb{R} \\times \\mathbb{R}$ with $\\delta \\ge 0$.\n- Objective: minimize the quadratic cost\n$$\nJ(u,\\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2,\n$$\nwhere $p  0$ is a penalty weight on the CLF slack.\n- Constraints:\n    1. CLF decrease (relaxed): $x u \\le -\\frac{c}{2} x^2 + \\delta$,\n    2. CBF safety: $u \\ge -\\alpha (x - x_{\\min})$,\n    3. Actuator limits: $u_{\\min} \\le u \\le u_{\\max}$,\n    4. Slack nonnegativity: $\\delta \\ge 0$.\n\nYour program must:\n- Implement from first principles an algorithm to compute the optimal solution $(u^\\star, \\delta^\\star)$ and the optimal cost $J^\\star$ for given parameters $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max})$.\n- Determine feasibility: return a boolean indicating whether there exists any $(u, \\delta)$ satisfying all constraints. Interpret feasibility with respect to the constraints; in particular, the CLF constraint is relaxable via $\\delta \\ge 0$, so infeasibility can only arise from irreconcilable safety and actuator limits.\n\nYou must analyze and encode feasibility conditions when the CLF objective and the CBF constraint are in conflict with actuator limits. Specifically, your solution must reason from the constraints to decide when no admissible control $u$ exists that simultaneously satisfies the CBF inequality and the actuator bounds, regardless of the CLF slack $\\delta$.\n\nTest Suite:\nUse the following parameter sets to exercise different regimes (happy path, boundary, and conflict). Each test case is a tuple $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max})$:\n- Case $1$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,1.0,\\,0.0,\\,1.0,\\,1.0,\\,100.0,\\, -2.0,\\, 2.0\\,)$.\n- Case $2$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,0.0,\\,0.0,\\,1.0,\\,1.0,\\,10.0,\\, -1.0,\\, 1.0\\,)$.\n- Case $3$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,0.1,\\,0.0,\\,50.0,\\,1.0,\\,10.0,\\, -2.0,\\, 2.0\\,)$.\n- Case $4$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\, -1.0,\\, -5.0,\\, 0.5,\\, 1.0,\\, 50.0,\\, -3.0,\\, 3.0\\,)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and must be a list of the form $[\\text{feasible}, u^\\star, \\delta^\\star, J^\\star]$, where $\\text{feasible}$ is a boolean, and $u^\\star$, $\\delta^\\star$, and $J^\\star$ are real numbers. For example, the output must look like\n$[[\\text{True}, u_1, \\delta_1, J_1],[\\text{False}, u_2, \\delta_2, J_2],\\ldots]$\ncomputed for the four specified test cases.",
            "solution": "The problem presented is to find the optimal control input $u$ and Control Lyapunov Function (CLF) relaxation slack $\\delta$ for a single-integrator system, $\\dot{x} = u$. The optimization is formulated as a Quadratic Program (QP) that minimizes a cost function balancing control effort and CLF relaxation, subject to constraints from a relaxed CLF, a Control Barrier Function (CBF), actuator limits, and slack non-negativity.\n\nThe QP is formulated as follows:\n$$ \\min_{u, \\delta} \\quad J(u,\\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2 $$\nsubject to the constraints:\n1.  $x u \\le -\\frac{c}{2} x^2 + \\delta$ (Relaxed CLF condition)\n2.  $u \\ge -\\alpha (x - x_{\\min})$ (CBF condition)\n3.  $u_{\\min} \\le u \\le u_{\\max}$ (Actuator limits)\n4.  $\\delta \\ge 0$ (Slack non-negativity)\n\nHere, $x \\in \\mathbb{R}$ is the state, $u \\in \\mathbb{R}$ is the control input, and $\\delta \\in \\mathbb{R}$ is the slack variable. The parameters $c, p, \\alpha, x_{\\min}, u_{\\min}, u_{\\max}$ are given positive constants or real values.\n\nFirst, we analyze the feasibility of this QP. The CLF constraint, $x u \\le -\\frac{c}{2} x^2 + \\delta$, can be rewritten as $\\delta \\ge x u + \\frac{c}{2} x^2$. Since we also have the constraint $\\delta \\ge 0$, for any given control input $u$, we can always find a feasible $\\delta$ by choosing $\\delta \\ge \\max(0, x u + \\frac{c}{2} x^2)$. This implies that the feasibility of the entire QP depends only on the existence of a control input $u$ that satisfies the remaining constraints. These constraints on $u$ are the CBF condition and the actuator limits:\n$$ u \\ge -\\alpha (x - x_{\\min}) $$\n$$ u_{\\min} \\le u \\le u_{\\max} $$\nFor a feasible $u$ to exist, the intersection of the sets defined by these inequalities must be non-empty. This is true if and only if the overall lower bound on $u$ is less than or equal to the upper bound. Let $u_{cbf} = -\\alpha (x - x_{\\min})$ be the lower bound from the CBF constraint. The combined lower bound on $u$ is $\\max(u_{\\min}, u_{cbf})$. Thus, the feasible set for $u$ is non-empty if and only if:\n$$ \\max(u_{\\min}, -\\alpha (x - x_{\\min})) \\le u_{\\max} $$\nThis is the feasibility condition. If it is not met, no solution exists. We assume that the actuator limits are well-defined, i.e., $u_{\\min} \\le u_{\\max}$. The condition then simplifies to $-\\alpha (x - x_{\\min}) \\le u_{\\max}$.\n\nIf the problem is feasible, we proceed to find the optimal solution $(u^\\star, \\delta^\\star)$. To minimize the objective function $J(u, \\delta)$, which is a sum of squared terms with positive weights ($p>0$), we must choose the smallest permissible value for $\\delta$. As established, the constraints on $\\delta$ are $\\delta \\ge 0$ and $\\delta \\ge x u + \\frac{c}{2} x^2$. Thus, the optimal choice for $\\delta$ for any given $u$ is:\n$$ \\delta(u) = \\max\\left(0, x u + \\frac{c}{2} x^2\\right) $$\nSubstituting this into the objective function transforms the two-variable QP into a one-dimensional optimization problem over $u$:\n$$ \\min_{u \\in [u_{lower}, u_{upper}]} \\quad J(u) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\left( \\max\\left(0, x u + \\frac{c}{2} x^2\\right) \\right)^2 $$\nwhere the feasible interval for $u$ is $[u_{lower}, u_{upper}]$, with $u_{lower} = \\max(u_{\\min}, -\\alpha (x - x_{\\min}))$ and $u_{upper} = u_{\\max}$.\n\nThe objective function $J(u)$ is convex and continuously differentiable. Its unconstrained minimum can be found by setting its derivative to zero. We analyze this by considering two cases based on the sign of $C(u) = x u + \\frac{c}{2} x^2$.\n\nCase 1: $C(u) \\le 0$. Here, $\\delta(u)=0$ and $J(u) = \\frac{1}{2} u^2$. The minimum of this quadratic is at $u=0$. However, the condition $C(0) = \\frac{c}{2}x^2 \\le 0$ holds only if $x=0$, which we handle as a special case.\n\nCase 2: $C(u)  0$. Here, $\\delta(u) = x u + \\frac{c}{2} x^2$ and the objective is $J(u) = \\frac{1}{2} u^2 + \\frac{1}{2} p (x u + \\frac{c}{2} x^2)^2$. The derivative is:\n$$ \\frac{dJ}{du} = u + p \\left(x u + \\frac{c}{2} x^2\\right) x = u(1 + px^2) + \\frac{pcx^3}{2} $$\nSetting $\\frac{dJ}{du} = 0$ yields the unconstrained minimizer:\n$$ u_{unc} = -\\frac{p c x^3}{2(1 + p x^2)} $$\nWe can verify that for $x \\neq 0$, this value of $u_{unc}$ yields $C(u_{unc}) = x u_{unc} + \\frac{c}{2} x^2 = \\frac{c x^2}{2(1 + p x^2)}  0$, confirming that the unconstrained minimum lies in this region.\n\nThe optimal solution $u^\\star$ for the constrained problem is the projection of the unconstrained minimizer $u_{unc}$ onto the feasible interval $[u_{lower}, u_{upper}]$.\n$$ u^\\star = \\max(u_{lower}, \\min(u_{unc}, u_{upper})) $$\n\nSpecial Case: $x = 0$.\nIf $x=0$, the CLF constraint becomes $\\delta \\ge 0$. The CBF constraint is $u \\ge \\alpha x_{\\min}$. The feasible set for $u$ is $u \\in [\\max(u_{\\min}, \\alpha x_{\\min}), u_{\\max}]$. The objective is $J(u, \\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2$. To minimize $J$, we must choose $\\delta^\\star=0$. The optimal control $u^\\star$ is the value in the feasible interval closest to $0$, which is found by projecting $0$ onto the interval.\n\nThe algorithm is as follows:\n1.  Calculate the feasibility bounds: $u_{cbf} = -\\alpha (x - x_{\\min})$, $u_{lower} = \\max(u_{\\min}, u_{cbf})$, and $u_{upper} = u_{\\max}$.\n2.  Check for feasibility: If $u_{lower}  u_{upper}$, the problem is infeasible.\n3.  If feasible:\n    a. If $x=0$:\n       $u^\\star = \\max(u_{lower}, \\min(0, u_{upper}))$.\n       $\\delta^\\star = 0$.\n    b. If $x \\neq 0$:\n       Calculate $u_{unc} = - (p \\cdot c \\cdot x^3) / (2 \\cdot (1 + p \\cdot x^2))$.\n       $u^\\star = \\max(u_{lower}, \\min(u_{unc}, u_{upper}))$.\n       $\\delta^\\star = \\max(0, x \\cdot u^\\star + (c/2) \\cdot x^2)$.\n4.  Calculate the optimal cost $J^\\star = \\frac{1}{2} (u^\\star)^2 + \\frac{1}{2} p (\\delta^\\star)^2$.\n5.  Return the feasibility status and the optimal values $(u^\\star, \\delta^\\star, J^\\star)$.",
            "answer": "```python\nimport numpy as np\n\ndef solve_clf_cbf_qp(x, x_min, alpha, c, p, u_min, u_max):\n    \"\"\"\n    Solves the CLF-CBF-QP for a single-integrator system from first principles.\n\n    Args:\n        x (float): Current state.\n        x_min (float): Safety threshold for the state.\n        alpha (float): CBF class-K gain.\n        c (float): CLF decay rate constant.\n        p (float): Penalty weight on the CLF slack.\n        u_min (float): Minimum control input.\n        u_max (float): Maximum control input.\n\n    Returns:\n        list: A list containing [feasible, u_star, delta_star, J_star].\n              'feasible' is a boolean. For infeasible cases, the other\n              values are np.nan.\n    \"\"\"\n    # 1. Feasibility Analysis\n    # The set of admissible controls for u is constrained by the CBF and actuator limits.\n    # Feasibility requires this set to be non-empty.\n    \n    # Lower bound from CBF: u >= -alpha * (x - x_min)\n    u_cbf = -alpha * (x - x_min)\n\n    # Combined lower bound for u\n    u_lower = max(u_min, u_cbf)\n    u_upper = u_max\n\n    is_feasible = u_lower = u_upper\n\n    if not is_feasible:\n        return [False, np.nan, np.nan, np.nan]\n\n    # 2. Solve for the optimal (u*, delta*)\n    u_star = 0.0\n    delta_star = 0.0\n\n    if x == 0.0:\n        # For x=0, CLF constraint is delta >= 0.\n        # Objective is min 0.5*u^2 + 0.5*p*delta^2.\n        # To minimize, we need delta=0 and u to be as close to 0 as possible.\n        # u_star is the projection of 0 onto the feasible set [u_lower, u_upper].\n        u_star = max(u_lower, min(0.0, u_upper))\n        delta_star = 0.0\n    else:\n        # For x != 0, solve the 1D optimization problem for u.\n        # Unconstrained minimizer of the reduced objective function J(u).\n        numerator = p * c * (x**3)\n        denominator = 2 * (1 + p * (x**2))\n        u_unc = -numerator / denominator\n\n        # The optimal u* is the projection of u_unc onto the feasible interval.\n        u_star = max(u_lower, min(u_unc, u_upper))\n        \n        # The optimal delta* is the smallest value satisfying the constraints.\n        delta_star = max(0.0, x * u_star + (c / 2.0) * (x**2))\n\n    # 3. Calculate the optimal cost\n    J_star = 0.5 * (u_star**2) + 0.5 * p * (delta_star**2)\n\n    return [True, u_star, delta_star, J_star]\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results in the required format.\n    \"\"\"\n    test_cases = [\n        # (x, x_min, alpha, c, p, u_min, u_max)\n        (1.0, 0.0, 1.0, 1.0, 100.0, -2.0, 2.0),\n        (0.0, 0.0, 1.0, 1.0, 10.0, -1.0, 1.0),\n        (0.1, 0.0, 50.0, 1.0, 10.0, -2.0, 2.0),\n        (-1.0, -5.0, 0.5, 1.0, 50.0, -3.0, 3.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = solve_clf_cbf_qp(*params)\n        results.append(result)\n\n    # Format the output string as specified in the problem.\n    # e.g., [[True,-0.495...,0.00495...,0.123...],[True,0.0,0.0,0.0],...]\n    formatted_results = []\n    for res in results:\n        # str() on a boolean gives 'True' or 'False' with correct capitalization.\n        # str() on np.nan gives 'nan'.\n        inner_list_str = f\"[{str(res[0])},{res[1]},{res[2]},{res[3]}]\"\n        formatted_results.append(inner_list_str)\n    \n    # Final output is a comma-separated list of these inner lists, enclosed in brackets.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The defining characteristic of many complex CPS is their hybrid nature, where continuous physical dynamics interact with discrete computational logic. A critical task in their design is formal verification: proving with mathematical certainty that the system will never enter an unsafe region of its state space. This exercise demonstrates how to tackle this challenge by translating a reachability problem for a piecewise-affine (PWA) hybrid system into a Mixed-Integer Linear Program (MILP). By implementing this encoding from first principles, you will explore the power of computational verification methods and gain an appreciation for the fundamental trade-offs between scalability and completeness in the formal analysis of hybrid systems .",
            "id": "4223727",
            "problem": "Consider a discrete-time piecewise-affine hybrid system with a finite set of modes. At each discrete step $k \\in \\{0,1,\\dots,K-1\\}$, exactly one mode is active. Let the continuous state be $x_k \\in \\mathbb{R}^n$. For each mode $q \\in \\{0,1,\\dots,Q-1\\}$, the system enforces a mode-invariant (a linear guard that must hold while the mode is active) and a reset-affine update. Formally, for mode $q$, the invariant is given by the linear inequalities $H_q x_k \\le h_q$ and the reset-affine update is $x_{k+1} = A_q x_k + b_q$. The initial set is given by $E x_0 \\le e$, and the target set is $G x_K \\le g$. All inequalities are interpreted component-wise. Mixed-Integer Linear Programming (MILP) will be used to encode reachability with binary variables indicating which mode is active at each step, using the Big-M formulation to activate or relax constraints.\n\nYour task is to write a complete program that, for each provided test case, constructs the MILP feasibility encoding of reachability using a Big-M formulation and decides whether the target set is reachable in exactly $K$ steps from the initial set. Because only Linear Programming (LP) solvers are available, your program must implement a complete search over mode assignments by enumerating all sequences $(q_0,q_1,\\dots,q_{K-1}) \\in \\{0,\\dots,Q-1\\}^K$, and, for each sequence, transform the MILP to an LP by substituting the binary variables $y_{k,q}$ with their fixed values $y_{k,q} \\in \\{0,1\\}$ according to the chosen mode at each step. The Big-M constraints must be included exactly as they would appear in the MILP so that the effect of the chosen Big-M constant is apparent. The LP should be posed as a feasibility problem with a zero objective. If any sequence yields a feasible LP, then the test case is reachable; otherwise it is not reachable. The final output must aggregate a boolean result for each test case.\n\nFundamental base to use in the derivation:\n- Discrete-time state progression $x_{k+1} = A_q x_k + b_q$ when mode $q$ is active.\n- Mode-invariants $H_q x_k \\le h_q$ must hold when mode $q$ is active.\n- Big-M activation: constraints $C \\le d$ that must hold when $y=1$ are relaxed when $y=0$ by $C \\le d + M(1-y)$. For affine equalities $x_{k+1} = A_q x_k + b_q$, encode with two linear inequalities $x_{k+1} - A_q x_k - b_q \\le M(1 - y_{k,q})$ and $-(x_{k+1} - A_q x_k - b_q) \\le M(1 - y_{k,q})$ applied component-wise. The invariants $H_q x_k \\le h_q$ are encoded as $H_q x_k \\le h_q + M(1 - y_{k,q})$. Big-M must be chosen large enough to truly relax inactive constraints given known variable bounds.\n\nVariables and constraints in the MILP:\n- Continuous variables $x_0, x_1, \\dots, x_K \\in \\mathbb{R}^n$.\n- Binary mode-selection variables $y_{k,q} \\in \\{0,1\\}$ with $\\sum_{q=0}^{Q-1} y_{k,q} = 1$ for each $k$.\n- Initial set constraints $E x_0 \\le e$, target set constraints $G x_K \\le g$.\n- For each step $k$ and mode $q$, mode-invariant constraints $H_q x_k \\le h_q + M(1 - y_{k,q})$.\n- For each step $k$ and mode $q$, dynamics constraints for each dimension $i \\in \\{1,\\dots,n\\}$:\n  $x_{k+1,i} - (A_q x_k)_i - b_{q,i} \\le M(1 - y_{k,q})$ and $-(x_{k+1,i} - (A_q x_k)_i - b_{q,i}) \\le M(1 - y_{k,q})$.\n- Variable bounds must be finite to make Big-M meaningful.\n\nProgram requirements:\n- Implement enumeration of all mode sequences $(q_0,\\dots,q_{K-1})$.\n- For each sequence, fix $y_{k,q}$ and build the LP with the Big-M constraints included for all modes and steps.\n- Solve the LP feasibility using an LP solver and record whether feasible.\n- Report reachability as true if any sequence is feasible for that test case.\n- No physical units are involved.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[True,False,True]\") corresponding to the test cases in order.\n\nTest suite:\nUse the following three test cases, which together probe a general case, a Big-M sensitivity edge case, and an unreachable boundary case.\n\nCommon system components for Test Case $1$ and Test Case $2$:\n- Dimension $n = 2$, number of modes $Q = 2$.\n- Horizon $K = 3$.\n- Mode $0$ (horizontal move):\n  $A_0 = \\begin{bmatrix}1  0 \\\\ 0  1\\end{bmatrix}$,\n  $b_0 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$,\n  invariant $H_0 x \\le h_0$ with\n  $H_0 = \\begin{bmatrix}0  1 \\\\ 0  -1\\end{bmatrix}$,\n  $h_0 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$,\n  which encodes $-1 \\le y \\le 1$.\n- Mode $1$ (vertical move):\n  $A_1 = \\begin{bmatrix}1  0 \\\\ 0  1\\end{bmatrix}$,\n  $b_1 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$,\n  invariant $H_1 x \\le h_1$ with\n  $H_1 = \\begin{bmatrix}1  0 \\\\ -1  0\\end{bmatrix}$,\n  $h_1 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$,\n  which encodes $-1 \\le x \\le 1$.\n- Initial set $E x_0 \\le e$ with\n  $E = \\begin{bmatrix}1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1\\end{bmatrix}$,\n  $e = \\begin{bmatrix}0.5 \\\\ 0.5 \\\\ 0.5 \\\\ 0.5\\end{bmatrix}$,\n  which encodes $x_0 \\in [-0.5,0.5]^2$.\n- Target set $G x_3 \\le g$ with\n  $G = \\begin{bmatrix}-1  -1\\end{bmatrix}$,\n  $g = \\begin{bmatrix}-3\\end{bmatrix}$,\n  which encodes $x_3 + y_3 \\ge 3$.\n- Variable bounds for each component of each $x_k$: lower bound $-10$, upper bound $10$.\n\nTest Case $1$:\n- Big-M constant $M = 100$ (sufficiently large).\nExpected logical behavior: Reachable due to appropriate mode sequencing, and Big-M sufficiently relaxes inactive constraints.\n\nTest Case $2$:\n- Big-M constant $M = 0.2$ (intentionally too small).\nExpected logical behavior: Not reachable under this MILP encoding because inactive-mode constraints are not relaxed enough, generating false infeasibility even though a path exists under correct relaxation.\n\nTest Case $3$:\n- Same modes and invariants as above.\n- Horizon $K = 2$.\n- Big-M constant $M = 100$.\n- Initial set $E x_0 \\le e$ as above.\n- Target set $G x_2 \\le g$ with\n  $G = \\begin{bmatrix}-1  -1\\end{bmatrix}$,\n  $g = \\begin{bmatrix}-4\\end{bmatrix}$,\n  which encodes $x_2 + y_2 \\ge 4$.\n- Variable bounds: lower bound $-10$, upper bound $10$.\nExpected logical behavior: Unreachable because the horizon is insufficient to accumulate the required sum in two steps from the bounded initial set.\n\nYour program must implement the above and produce a single line \"[result1,result2,result3]\" where each result is a boolean for the corresponding test case.",
            "solution": "The problem statement is subjected to validation before a solution is attempted.\n\n**Step 1: Extract Givens**\n\n- **System Type**: Discrete-time piecewise-affine (PWA) hybrid system with a finite set of modes.\n- **State and Time**: Continuous state $x_k \\in \\mathbb{R}^n$ at discrete time step $k \\in \\{0, 1, \\dots, K-1\\}$.\n- **Modes**: $q \\in \\{0, 1, \\dots, Q-1\\}$.\n- **Mode-Specific Definitions (for mode $q$)**:\n    - **Invariant**: $H_q x_k \\le h_q$.\n    - **Dynamics**: $x_{k+1} = A_q x_k + b_q$.\n- **Set Definitions**:\n    - **Initial Set**: $E x_0 \\le e$.\n    - **Target Set**: $G x_K \\le g$.\n- **Methodology**: Reachability analysis using a Mixed-Integer Linear Programming (MILP) formulation, which is then solved by enumerating all mode sequences and solving the corresponding Linear Programming (LP) feasibility problems.\n- **MILP Encoding (Big-M Formulation)**:\n    - **Binary variables**: $y_{k,q} \\in \\{0, 1\\}$, with $\\sum_{q=0}^{Q-1} y_{k,q} = 1$ for each step $k$.\n    - **Invariant Constraints**: $H_q x_k \\le h_q + M(1 - y_{k,q})$.\n    - **Dynamics Constraints**: For each dimension $i \\in \\{1, \\dots, n\\}$,\n        $x_{k+1,i} - (A_q x_k)_i - b_{q,i} \\le M(1 - y_{k,q})$\n        and $-(x_{k+1,i} - (A_q x_k)_i - b_{q,i}) \\le M(1 - y_{k,q})$.\n- **Variable Bounds**: State variables are bounded.\n- **Task**: For each test case, determine if the target set is reachable in $K$ steps by enumerating all $Q^K$ mode sequences, constructing an LP for each, and checking for feasibility.\n\n**Test Case 1  2 Common Data**:\n- $n = 2$, $Q = 2$, $K = 3$.\n- Mode $0$: $A_0 = \\begin{bmatrix}1  0 \\\\ 0  1\\end{bmatrix}$, $b_0 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$, Invariant $H_0 = \\begin{bmatrix}0  1 \\\\ 0  -1\\end{bmatrix}$, $h_0 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$ ($-1 \\le x_{k,2} \\le 1$).\n- Mode $1$: $A_1 = \\begin{bmatrix}1  0 \\\\ 0  1\\end{bmatrix}$, $b_1 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$, Invariant $H_1 = \\begin{bmatrix}1  0 \\\\ -1  0\\end{bmatrix}$, $h_1 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$ ($-1 \\le x_{k,1} \\le 1$).\n- Initial Set: $E = \\begin{bmatrix}1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1\\end{bmatrix}$, $e = \\begin{bmatrix}0.5 \\\\ 0.5 \\\\ 0.5 \\\\ 0.5\\end{bmatrix}$.\n- Target Set: $G = \\begin{bmatrix}-1  -1\\end{bmatrix}$, $g = \\begin{bmatrix}-3\\end{bmatrix}$.\n- Bounds: $[-10, 10]$ for all state components.\n- **Test Case 1 Specific**: $M = 100$.\n- **Test Case 2 Specific**: $M = 0.2$.\n\n**Test Case 3 Data**:\n- $n = 2$, $Q = 2$, $K = 2$, $M = 100$.\n- Modes, invariants, initial set, and bounds are the same as above.\n- Target Set: $G = \\begin{bmatrix}-1  -1\\end{bmatrix}$, $g = \\begin{bmatrix}-4\\end{bmatrix}$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria.\n\n1.  **Scientifically Grounded**: The problem is well-grounded in the field of hybrid systems and control theory, a sub-discipline of cyber-physical systems. The reachability analysis of piecewise-affine systems via MILP is a standard and well-documented technique. The formulation is mathematically rigorous.\n2.  **Well-Posed**: The problem is well-posed. All required parameters, matrices, and constants for each test case are explicitly provided. The objective is clear: determine the boolean reachability. The prescribed method, exhaustive enumeration of mode sequences, guarantees a deterministic outcome (True or False).\n3.  **Objective**: The problem is stated in precise, formal mathematical language, free from subjectivity or ambiguity.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or infeasibility in its premises. It is a standard, non-trivial exercise in computational modeling of hybrid systems.\n\n**Step 3: Verdict and Action**\nThe problem is **VALID**. A solution will be developed.\n\n**Principle-Based Design of the Solution**\n\nThe core of the problem is to determine the reachability of a target set for a discrete-time PWA system. The system's evolution is governed by a sequence of active modes $(q_0, q_1, \\dots, q_{K-1})$. Since an MILP solver is proscribed, the task reduces to an exhaustive search over the space of all possible mode sequences, which has a size of $Q^K$. For each candidate sequence, we must check if there exists a valid state trajectory starting in the initial set and ending in the target set. This check is formulated as a Linear Programming (LP) feasibility problem.\n\nLet a specific mode sequence be denoted by $(\\hat{q}_0, \\hat{q}_1, \\dots, \\hat{q}_{K-1})$. We need to find if there exists a state trajectory $(x_0, x_1, \\dots, x_K)$ that satisfies all constraints for this sequence. The decision variables for the LP are the components of these state vectors, concatenated into a single vector $z \\in \\mathbb{R}^{n(K+1)}$, where $z = [x_0^T, x_1^T, \\dots, x_K^T]^T$.\n\nThe LP is a feasibility problem, so the objective function is null: minimize $c^T z$ with $c = \\mathbf{0}$. The solution lies entirely in the satisfaction of a set of linear inequality constraints, which we formulate in the standard LP form $A_{ub} z \\le b_{ub}$.\n\nThe constraints for a fixed mode sequence are as follows:\n\n1.  **Variable Bounds**: Each component of each state vector $x_k$ must lie within the given bounds. For any $k \\in \\{0, \\dots, K\\}$ and $i \\in \\{1, \\dots, n\\}$, $x_{k,i} \\in [-10, 10]$. These are box constraints on the elements of $z$.\n\n2.  **Initial Set**: The initial state $x_0$ must belong to the initial set, defined by $E x_0 \\le e$. These constraints apply to the first $n$ elements of $z$.\n\n3.  **Target Set**: The final state $x_K$ must belong to the target set, defined by $G x_K \\le g$. These constraints apply to the last $n$ elements of $z$.\n\n4.  **Hybrid Dynamics and Invariants**: At each time step $k \\in \\{0, \\dots, K-1\\}$, the system's evolution is constrained by the dynamics and invariants of *all* possible modes $q \\in \\{0, \\dots, Q-1\\}$, activated or relaxed using the Big-M method. For our fixed sequence, the binary MILP variable $y_{k,q}$ is replaced by a constant: $y_{k,q}=1$ if $q = \\hat{q}_k$ (the active mode at step $k$), and $y_{k,q}=0$ otherwise. Consequently, the term $M(1 - y_{k,q})$ evaluates to $0$ for the active mode and $M$ for all inactive modes.\n\nFor each step $k \\in \\{0, \\dots, K-1\\}$ and each mode $q \\in \\{0, \\dots, Q-1\\}$, we add the following constraints. Let $m_{k,q} = M(1 - \\delta_{q, \\hat{q}_k})$, where $\\delta$ is the Kronecker delta.\n\n-   **Invariant Constraint**: The condition $H_q x_k \\le h_q$ must be enforced for the active mode and relaxed for inactive modes. This is encoded as:\n    $$H_q x_k \\le h_q + m_{k,q} \\cdot \\mathbf{1}$$\n    where $\\mathbf{1}$ is a vector of ones of appropriate dimension. This set of inequalities constrains the block of variables in $z$ corresponding to $x_k$.\n\n-   **Dynamics Constraint**: The affine update $x_{k+1} = A_q x_k + b_q$ is encoded as two inequalities. For the active mode, they enforce equality, and for inactive modes, they are relaxed:\n    $$x_{k+1} - A_q x_k \\le b_q + m_{k,q} \\cdot \\mathbf{1}$$\n    $$-x_{k+1} + A_q x_k \\le -b_q + m_{k,q} \\cdot \\mathbf{1}$$\n    These inequalities couple the variables in $z$ corresponding to $x_k$ and $x_{k+1}$.\n\nThese constraints are systematically assembled into a large matrix $A_{ub}$ and vector $b_{ub}$. We then use an LP solver (`scipy.optimize.linprog`) to check for feasibility. If the solver finds a feasible solution for any of the $Q^K$ mode sequences, we conclude that the target set is reachable and the result for the test case is `True`. If all sequences lead to infeasible LPs, the target is unreachable, and the result is `False`.\n\n**Analysis of Test Cases**:\n- **Test Case 1 ($M=100$)**: The target $x_{3,1} + x_{3,2} \\ge 3$ is reachable. A trajectory starting from $x_0=(0,0)$ with mode sequence $(0,1,0)$ yields $x_1=(1,0)$, $x_2=(1,1)$, and $x_3=(2,1)$, satisfying the target ($2+1=3$). The invariants are satisfied along this path. Since $M=100$ is sufficiently large (greater than the maximum possible violation between mode dynamics, which is $1$), the inactive constraints are properly relaxed. This sequence is expected to yield a feasible LP. Result: `True`.\n\n- **Test Case 2 ($M=0.2$)**: The same trajectory as above is physically possible. However, the MILP encoding with $M=0.2$ will fail. The difference between dynamics, e.g., $(A_0 x_k + b_0) - (A_1 x_k + b_1) = b_0 - b_1 = [1, -1]^T$, has components with magnitude $1$. For an inactive constraint to be relaxed, $M$ must be at least this large. Since $M=0.2  1$, when mode $0$ is active, the relaxed constraint for mode $1$ will be violated, causing the LP to be infeasible regardless of the chosen sequence. Result: `False`.\n\n- **Test Case 3 ($M=100$)**: The horizon is $K=2$. The state update is $x_{k+1} = x_k + v_k$, where $v_k$ is $[1,0]^T$ or $[0,1]^T$. After two steps, $x_2 = x_0 + v_0 + v_1$. The target is $x_{2,1} + x_{2,2} \\ge 4$. The sum is maximized if $x_{2,1}+x_{2,2} = (x_{0,1}+v_{0,1}+v_{1,1}) + (x_{0,2}+v_{0,2}+v_{1,2}) = (x_{0,1}+x_{0,2}) + (v_{0,1}+v_{0,2}) + (v_{1,1}+v_{1,2})$. The sum of components for any $v_k$ is $1$. The maximum initial sum $x_{0,1}+x_{0,2}$ is $0.5+0.5=1$. Thus, the maximum possible sum for $x_2$ is $1 + 1 + 1 = 3$. Reaching a sum of $\\ge 4$ is kinematically impossible. All LPs will be infeasible. Result: `False`.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport itertools\n\ndef solve_case(params):\n    \"\"\"\n    Solves a single reachability test case by enumerating mode sequences.\n\n    For each sequence, it constructs and solves an LP feasibility problem.\n    \"\"\"\n    n = params['n']\n    Q = params['Q']\n    K = params['K']\n    M = params['M']\n    A_modes = params['A_modes']\n    b_modes = params['b_modes']\n    H_modes = params['H_modes']\n    h_modes = params['h_modes']\n    E = params['E']\n    e = params['e']\n    G = params['G']\n    g = params['g']\n    bounds_val = params['bounds']\n\n    # Generate all possible mode sequences of length K\n    mode_sequences = itertools.product(range(Q), repeat=K)\n    \n    # LP decision variables are the concatenated state vectors: z = [x_0, x_1, ..., x_K]\n    num_lp_vars = n * (K + 1)\n    \n    # Objective function is zero for a feasibility problem\n    c = np.zeros(num_lp_vars)\n    \n    # State variable bounds\n    bounds = [bounds_val] * num_lp_vars\n    \n    # Iterate through each possible mode sequence\n    for seq in mode_sequences:\n        A_ub_list = []\n        b_ub_list = []\n        \n        # 1. Initial set constraints: E x_0 = e\n        A_init = np.zeros((E.shape[0], num_lp_vars))\n        A_init[:, :n] = E\n        A_ub_list.append(A_init)\n        b_ub_list.append(e.flatten())\n        \n        # 2. Target set constraints: G x_K = g\n        A_target = np.zeros((G.shape[0], num_lp_vars))\n        A_target[:, n * K : n * (K + 1)] = G\n        A_ub_list.append(A_target)\n        b_ub_list.append(g.flatten())\n\n        # 3. Dynamics and Invariant constraints for each step k and each mode q\n        for k in range(K):\n            for q in range(Q):\n                is_active_mode = (q == seq[k])\n                \n                # The Big-M term is 0 for the active mode, M otherwise\n                m_val = 0.0 if is_active_mode else M\n                \n                # Invariant constraint: H_q x_k = h_q + M * (1-y_kq)\n                H_q, h_q = H_modes[q], h_modes[q]\n                num_inv_const = H_q.shape[0]\n                A_inv = np.zeros((num_inv_const, num_lp_vars))\n                A_inv[:, n * k : n * (k + 1)] = H_q\n                b_inv = h_q.flatten() + m_val\n                A_ub_list.append(A_inv)\n                b_ub_list.append(b_inv)\n                \n                # Dynamics constraints encoded as two inequalities\n                A_q, b_q = A_modes[q], b_modes[q]\n                \n                # Inequality 1: x_{k+1} - A_q x_k = b_q + M * (1-y_kq)\n                A_dyn_1 = np.zeros((n, num_lp_vars))\n                A_dyn_1[:, n * (k + 1) : n * (k + 2)] = np.eye(n)\n                A_dyn_1[:, n * k : n * (k + 1)] = -A_q\n                b_dyn_1 = b_q.flatten() + m_val\n                A_ub_list.append(A_dyn_1)\n                b_ub_list.append(b_dyn_1)\n                \n                # Inequality 2: -x_{k+1} + A_q x_k = -b_q + M * (1-y_kq)\n                A_dyn_2 = np.zeros((n, num_lp_vars))\n                A_dyn_2[:, n * (k + 1) : n * (k + 2)] = -np.eye(n)\n                A_dyn_2[:, n * k : n * (k + 1)] = A_q\n                b_dyn_2 = -b_q.flatten() + m_val\n                A_ub_list.append(A_dyn_2)\n                b_ub_list.append(b_dyn_2)\n\n        # Consolidate all constraints into a single matrix and vector\n        A_ub = np.vstack(A_ub_list)\n        b_ub = np.concatenate(b_ub_list)\n        \n        # Solve the LP feasibility problem\n        # method='highs' is the default and recommended in recent SciPy versions\n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        # A status of 0 indicates an optimal solution was found (i.e., it's feasible)\n        if res.success:\n            return True # Target is reachable\n            \n    # If no feasible sequence was found after checking all\n    return False # Target is not reachable\n\ndef solve():\n    # Common system components\n    n = 2\n    Q = 2\n    \n    A0 = np.array([[1, 0], [0, 1]])\n    b0 = np.array([1, 0])\n    H0 = np.array([[0, 1], [0, -1]])\n    h0 = np.array([1, 1])\n\n    A1 = np.array([[1, 0], [0, 1]])\n    b1 = np.array([0, 1])\n    H1 = np.array([[1, 0], [-1, 0]])\n    h1 = np.array([1, 1])\n    \n    A_modes = [A0, A1]\n    b_modes = [b0, b1]\n    H_modes = [H0, H1]\n    h_modes = [h0, h1]\n\n    E = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\n    e = np.array([0.5, 0.5, 0.5, 0.5])\n    bounds = (-10, 10)\n\n    # Test Case 1: Reachable, sufficient M\n    test_case_1 = {\n        'n': n, 'Q': Q, 'K': 3, 'M': 100.0,\n        'A_modes': A_modes, 'b_modes': b_modes,\n        'H_modes': H_modes, 'h_modes': h_modes,\n        'E': E, 'e': e,\n        'G': np.array([[-1, -1]]), 'g': np.array([-3]),\n        'bounds': bounds\n    }\n\n    # Test Case 2: Unreachable (by encoding), insufficient M\n    test_case_2 = {\n        'n': n, 'Q': Q, 'K': 3, 'M': 0.2,\n        'A_modes': A_modes, 'b_modes': b_modes,\n        'H_modes': H_modes, 'h_modes': h_modes,\n        'E': E, 'e': e,\n        'G': np.array([[-1, -1]]), 'g': np.array([-3]),\n        'bounds': bounds\n    }\n    \n    # Test Case 3: Unreachable (kinematically), sufficient M\n    test_case_3 = {\n        'n': n, 'Q': Q, 'K': 2, 'M': 100.0,\n        'A_modes': A_modes, 'b_modes': b_modes,\n        'H_modes': H_modes, 'h_modes': h_modes,\n        'E': E, 'e': e,\n        'G': np.array([[-1, -1]]), 'g': np.array([-4]),\n        'bounds': bounds\n    }\n\n    test_cases = [test_case_1, test_case_2, test_case_3]\n    \n    results = [solve_case(case) for case in test_cases]\n\n    # Format output as specified: \"[True,False,True]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}