{
    "hands_on_practices": [
        {
            "introduction": "A critical role of an Architecture Description Language (ADL) is to enable the analysis of system behavior before costly implementation. This practice focuses on diagnosing subtle but potentially catastrophic flaws in real-time scheduling, such as priority inversion. By reasoning through the interactions of threads with different priorities and shared resources as specified in an ADL model, you can identify conditions that lead to deadline misses and evaluate standard architectural mitigations to ensure system correctness .",
            "id": "4205715",
            "problem": "An Architecture Description Language (ADL) model, expressed in Architecture Analysis and Design Language (AADL), specifies a cyber-physical system and its Digital Twin that share a single-core processor under a Real-Time Operating System (RTOS) using fixed-priority, fully preemptive scheduling. The ADL declares three threads bound to the same processor and a shared memory component DataBuffer with a mutual-exclusion lock. The ADL sets the lock policy to a first-in-first-out mutex with no priority inheritance by default. The three threads are declared with priorities and timing parameters as follows: ActuatorControl thread ($T_H$) with priority $p_H = 90$, period $T_H = 10$ ms, relative deadline $D_H = 10$ ms, and worst-case execution time $C_H = 2$ ms including a critical section on DataBuffer of duration $1$ ms; SensorFusion thread ($T_M$) with priority $p_M = 60$, period $T_M = 15$ ms, relative deadline $D_M = 15$ ms, and worst-case execution time $C_M = 9$ ms, which does not access DataBuffer; Logger thread ($T_L$) with priority $p_L = 10$, period $T_L = 50$ ms, relative deadline $D_L = 50$ ms, and worst-case execution time $C_L = 5$ ms including a critical section on DataBuffer of duration $3$ ms. The ADL deployment binds the shared DataBuffer and all three threads to the same processor and the same memory with the default mutex policy described above. Releases in the worst-case pattern occur with offsets: $O_L = 0$ ms, $O_H = 1$ ms, $O_M = 1.5$ ms. All execution-time and critical-section durations are feasible and consistent with the hardware.\n\nUsing only fundamental definitions of fixed-priority preemptive scheduling, mutual exclusion, and blocking (no specialized protocol formulas), reason about whether the declared configuration can produce priority inversion for ($T_H$) and whether the inversion can cause a deadline miss for ($T_H$). Then, consider architectural mitigations that the ADL could express (e.g., by property changes or component redesign) to eliminate unbounded inversion while preserving bounded latency. Select all options that correctly identify the condition under which priority inversion occurs in this deployment and propose an effective architectural mitigation that is expressible at the ADL level and correct under the given assumptions.\n\nA. Priority inversion occurs when ($T_L$) holds the DataBuffer mutex, ($T_H$) requests the same mutex and is blocked, and ($T_M$) preempts ($T_L$) before it can release the mutex; a mitigation is to enable priority inheritance on the DataBuffer mutex in the ADL so that when ($T_H$) is blocked, ($T_L$) temporarily executes at priority $p_H$, preventing preemption by ($T_M$) and bounding ($T_H$)’s blocking by the longest lower-priority critical section using the resource.\n\nB. Priority inversion in this deployment can only occur if ($T_M$) also uses DataBuffer; a mitigation is to replace the mutex with a read-write lock, designating ($T_L$) as a writer and ($T_H$) as a reader, which prevents blocking between them.\n\nC. Priority inversion necessarily occurs in any single-core fixed-priority system whenever any lower-priority thread accesses any shared resource; a mitigation is to make all mutexes non-preemptible at the kernel level, which eliminates priority inversion without impacting schedulability of higher-priority threads.\n\nD. Priority inversion occurs because the shared resource is bound via ADL to a non-deterministic bus with variable arbitration, and a mitigation is to migrate ($T_H$) to a higher-priority core where bus access is prioritized, eliminating the blocking.\n\nE. Priority inversion occurs when ($T_L$) holds the DataBuffer mutex, ($T_H$) requests the mutex and is blocked, and ($T_M$)—despite not using DataBuffer—preempts ($T_L$); a mitigation is to redesign DataBuffer as a lock-free Single-Producer Single-Consumer (SPSC) ring buffer with bounded atomic operations and appropriate memory fences, declared in the ADL as a lock-free synchronization kind, under the condition that ($T_L$) is the unique producer and ($T_H$) is the unique consumer and the buffer capacity $N$ is sized to avoid producer-induced blocking.",
            "solution": "The problem statement is a valid exercise in real-time systems analysis. It provides a complete and consistent set of parameters for three threads scheduled on a single-core processor under a fixed-priority preemptive policy, including their timing properties, priorities, and interaction via a shared resource protected by a standard mutex without priority inheritance. The scenario is scientifically grounded in established scheduling theory and is well-posed for analyzing the phenomena of priority inversion and its consequences on system schedulability.\n\nThe central task is to analyze the potential for priority inversion affecting the highest-priority thread, $T_H$, and to evaluate proposed architectural mitigations.\n\n**1. Analysis of Priority Inversion Condition**\n\nPriority inversion occurs when a high-priority thread is forced to wait for a lower-priority thread. The problem becomes severe, leading to \"unbounded\" priority inversion, when the duration of this waiting is not determined solely by the time the lower-priority thread spends in its critical section, but is prolonged by the execution of medium-priority threads.\n\nThe given system is a textbook case for this phenomenon:\n-   $T_H$ has the highest priority ($p_H=90$).\n-   $T_M$ has a medium priority ($p_M=60$).\n-   $T_L$ has the lowest priority ($p_L=10$).\n-   $T_H$ and $T_L$ share a resource, `DataBuffer`, protected by a mutex.\n-   $T_M$ does not use the resource but can preempt $T_L$.\n-   The mutex policy does not include priority inheritance.\n\nA worst-case scenario unfolds as follows:\n1.  The low-priority thread, $T_L$, starts execution and acquires the mutex for `DataBuffer`.\n2.  The high-priority thread, $T_H$, is released. It preempts $T_L$ and begins executing.\n3.  $T_H$ attempts to acquire the mutex for `DataBuffer`, finds it locked by $T_L$, and blocks (is moved from the \"Running\" state to the \"Blocked\" state).\n4.  The scheduler must now run the highest-priority ready thread. Since $T_H$ is blocked, the scheduler considers $T_M$ and $T_L$.\n5.  The medium-priority thread, $T_M$, which is ready to run, has a higher priority than $T_L$ ($p_M > p_L$). Therefore, $T_M$ preempts $T_L$.\n6.  $T_M$ runs. During this entire time, $T_H$ remains blocked, waiting for $T_L$ to release the mutex. However, $T_L$ cannot run to release the mutex because it is being preempted by $T_M$.\n\nThe duration of blocking experienced by $T_H$ is the sum of the remaining critical section time of $T_L$ and the entire execution time of $T_M$. This is the classic unbounded priority inversion problem.\n\n**2. Analysis of Deadline Miss for $T_H$**\n\nWe will construct a timeline based on the worst-case parameters to determine if $T_H$ can miss its deadline.\n-   Offsets: $O_L = 0$ ms, $O_H = 1$ ms, $O_M = 1.5$ ms.\n-   At time $t=0$ ms, $T_L$ is released. Let's assume it starts executing and immediately enters its critical section, which has a worst-case duration of $3$ ms.\n-   At time $t=1$ ms, $T_H$ is released. Since $p_H > p_L$, $T_H$ preempts $T_L$. $T_L$ has executed for $1$ ms inside its critical section.\n-   At time $t=1.5$ ms, $T_M$ is released. However, $T_H$ is still running ($p_H > p_M$), so $T_M$ is placed in the ready queue.\n-   The WCET of $T_H$ is $C_H = 2$ ms, which includes a $1$ ms critical section. Let's assume the worst case for blocking, where $T_H$ executes its non-critical part first. This takes $C_H - (\\text{CS duration}) = 2 - 1 = 1$ ms. So, $T_H$ runs from $t=1$ ms to $t=2$ ms.\n-   At time $t=2$ ms, $T_H$ attempts to lock the mutex. It finds the mutex held by $T_L$ and blocks.\n-   The scheduler now dispatches the highest-priority ready thread. This is $T_M$ (priority $60$), which was released at $t=1.5$ ms.\n-   $T_M$ begins execution at $t=2$ ms. It runs for its full WCET, $C_M=9$ ms.\n-   $T_M$ completes its execution at $t = 2 + 9 = 11$ ms.\n-   At time $t=11$ ms, the highest-priority ready thread is $T_L$ (priority $10$). $T_H$ is still blocked.\n-   $T_L$ resumes execution to complete its critical section. It had already run for $1$ ms, so it needs $3 - 1 = 2$ more ms. It runs from $t=11$ ms to $t=13$ ms.\n-   At time $t=13$ ms, $T_L$ releases the mutex.\n-   Immediately upon the mutex release, $T_H$ becomes unblocked and ready. As it has the highest priority, it preempts $T_L$ and begins executing its critical section.\n-   $T_H$ runs for its critical section duration of $1$ ms, from $t=13$ ms to $t=14$ ms.\n-   At time $t=14$ ms, the first job of $T_H$ completes.\n-   The deadline for this job of $T_H$ is its release time plus its relative deadline: $D_{H,abs} = O_H + D_H = 1 + 10 = 11$ ms.\n-   Since the job finishes at $14$ ms, which is later than its deadline of $11$ ms, the thread $T_H$ misses its deadline.\nThe analysis confirms that the specified configuration can produce priority inversion, and this inversion can directly cause a deadline miss for the high-priority thread.\n\n**3. Evaluation of Options**\n\n**Option A:** Priority inversion occurs when ($T_L$) holds the DataBuffer mutex, ($T_H$) requests the same mutex and is blocked, and ($T_M$) preempts ($T_L$) before it can release the mutex; a mitigation is to enable priority inheritance on the DataBuffer mutex in the ADL so that when ($T_H$) is blocked, ($T_L$) temporarily executes at priority $p_H$, preventing preemption by ($T_M$) and bounding ($T_H$)’s blocking by the longest lower-priority critical section using the resource.\n-   **Analysis**: This option provides a perfectly accurate description of the unbounded priority inversion scenario identified in our analysis. The proposed mitigation, enabling priority inheritance, is the standard solution. When $T_L$ holds the lock and blocks $T_H$, $T_L$ would inherit the priority of $T_H$, becoming $p_L' = p_H = 90$. Consequently, $T_M$ (with $p_M=60$) would not be able to preempt $T_L$. $T_L$ would finish its critical section ($3$ ms max), release the lock, and then $T_H$ could proceed. This bounds the blocking time of $T_H$ to the duration of $T_L$'s critical section ($3$ ms), preventing the deadline miss (new response time would be at most $C_H + \\text{blocking} = 2+3=5$ ms, which is less than $D_H=10$ ms). Such a policy is a standard feature in RTOSes and is configurable in ADLs like AADL.\n-   **Verdict**: **Correct**.\n\n**Option B:** Priority inversion in this deployment can only occur if ($T_M$) also uses DataBuffer; a mitigation is to replace the mutex with a read-write lock, designating ($T_L$) as a writer and ($T_H$) as a reader, which prevents blocking between them.\n-   **Analysis**: The premise is false. The severe priority inversion problem occurs precisely because $T_M$ *does not* use the mutex and is free to preempt $T_L$. The proposed mitigation is also flawed. A read-write lock does not allow a reader ($T_H$) to proceed if a writer ($T_L$) holds the lock. Exclusive access is required for writers. Thus, $T_H$ would still block on $T_L$, and the priority inversion scenario with preemption by $T_M$ would remain unchanged.\n-   **Verdict**: **Incorrect**.\n\n**Option C:** Priority inversion necessarily occurs in any single-core fixed-priority system whenever any lower-priority thread accesses any shared resource; a mitigation is to make all mutexes non-preemptible at the kernel level, which eliminates priority inversion without impacting schedulability of higher-priority threads.\n-   **Analysis**: The initial premise is an overgeneralization. While blocking of a high-priority thread by a low-priority thread is technically a priority inversion, it is not always \"unbounded\" or problematic. The severe case requires the specific three-priority-level interaction. The proposed mitigation, using non-preemptible critical sections, does prevent the inversion scenario. However, the claim that this is achieved \"without impacting schedulability of higher-priority threads\" is false. A non-preemptible section executed by a low-priority thread will block any higher-priority thread from running for its duration, even if the higher-priority thread does not use the shared resource. This introduces a separate form of blocking that can negatively impact schedulability.\n-   **Verdict**: **Incorrect**.\n\n**Option D:** Priority inversion occurs because the shared resource is bound via ADL to a non-deterministic bus with variable arbitration, and a mitigation is to migrate ($T_H$) to a higher-priority core where bus access is prioritized, eliminating the blocking.\n-   **Analysis**: This option introduces facts not in evidence. The problem statement specifies a \"single-core processor\" and attributes the issue to scheduling and locking policies. There is no mention of a bus architecture. The proposed mitigation is impossible as the system only has a single core. The reasoning is entirely disconnected from the provided problem description.\n-   **Verdict**: **Incorrect**.\n\n**Option E:** Priority inversion occurs when ($T_L$) holds the DataBuffer mutex, ($T_H$) requests the mutex and is blocked, and ($T_M$)—despite not using DataBuffer—preempts ($T_L$); a mitigation is to redesign DataBuffer as a lock-free Single-Producer Single-Consumer (SPSC) ring buffer with bounded atomic operations and appropriate memory fences, declared in the ADL as a lock-free synchronization kind, under the condition that ($T_L$) is the unique producer and ($T_H$) is the unique consumer and the buffer capacity $N$ is sized to avoid producer-induced blocking.\n-   **Analysis**: The description of the priority inversion condition is identical to Option A's and is correct. The proposed mitigation involves a fundamental architectural redesign of the shared component to use a lock-free algorithm. An SPSC queue is a classic example of a lock-free data structure that avoids mutexes entirely, thereby eliminating the possibility of blocking due to mutual exclusion and the associated priority inversion. This is a valid and effective advanced mitigation strategy. The option correctly notes the necessary preconditions (single producer/consumer roles) for this specific design pattern. Such an architectural pattern is expressible in an ADL, representing a change in the component's design and synchronization properties.\n-   **Verdict**: **Correct**.",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "Modern cyber-physical systems are rarely monolithic; they exist as product lines with extensive variability in features and capabilities. This exercise challenges you to act as a product line architect, using a feature model and ADL-derived constraints to manage this complexity. Your task is to systematically navigate the design space to count the number of valid system configurations that satisfy a complex web of structural, policy, and quantitative resource constraints .",
            "id": "4205712",
            "problem": "Consider a cyber-physical system digital twin product line whose variability is modeled by a feature diagram. Features are constrained by Architecture Description Language (ADL) properties that impose structural integrity and quantitative resource bounds. The system has uniform processing pipelines: a single compression method and a single encryption method are applied to all chosen sensors. The following definitions, options, and constraints hold.\n\n- Fundamental base:\n  - An Architecture Description Language (ADL) specifies components, connectors, and properties. Structural integrity requires uniform dataflow transformations across sensors and compatibility between choices. Quantitative properties bound end-to-end resource usage.\n  - A feature diagram defines variability as selection among alternatives and options, subject to cross-tree constraints derived from ADL properties.\n  - The bus capacity constraint requires the sum of transmitted data rates to not exceed the chosen bus capacity.\n  - The compute budget constraint requires the total compute cost of compression and encryption to not exceed the chosen compute platform budget.\n\n- Acronyms:\n  - Architecture Description Language (ADL).\n  - Cyber-Physical Systems (CPS).\n  - Controller Area Network (CAN).\n  - Time-Sensitive Networking (TSN).\n  - Advanced Encryption Standard (AES).\n\n- Sensor types and raw data rates:\n  - IMU: $5$ Mbps.\n  - Lidar: $100$ Mbps.\n  - Camera: $200$ Mbps.\n  Each configuration must select exactly two distinct sensors from $\\{\\text{IMU}, \\text{Lidar}, \\text{Camera}\\}$.\n\n- Communication bus alternatives:\n  - CAN: capacity $50$ Mbps.\n  - TSN: capacity $1000$ Mbps.\n\n- Compression method alternatives (applied uniformly to all selected sensors):\n  - None: compression ratio $r=1$, compression cost coefficient $k_{c}=0$ units per Mbps.\n  - LZ4: compression ratio $r=\\frac{3}{5}$, compression cost coefficient $k_{c}=0.2$ units per Mbps.\n  - Zstd: compression ratio $r=\\frac{2}{5}$, compression cost coefficient $k_{c}=0.5$ units per Mbps.\n\n- Encryption method alternatives (applied uniformly to all selected sensors):\n  - None: overhead factor $\\alpha=0$, encryption cost coefficient $k_{e}=0$ units per Mbps.\n  - AES-128: overhead factor $\\alpha=0.1$, encryption cost coefficient $k_{e}=1.0$ units per Mbps.\n  - AES-256: overhead factor $\\alpha=0.2$, encryption cost coefficient $k_{e}=1.5$ units per Mbps.\n\n- Compute platform alternatives and budgets:\n  - CPU only: budget $250$ units.\n  - CPU+GPU: budget $400$ units.\n  - CPU+FPGA: budget $500$ units.\n\n- ADL-derived structural integrity and cross-tree constraints:\n  1. Uniformity: a single compression method and a single encryption method must be selected and applied uniformly to both sensors.\n  2. Camera privacy policy: if any Camera is selected, encryption may not be None (i.e., encryption must be AES-128 or AES-256).\n  3. Compatibility: AES-256 requires TSN as the bus.\n  4. Platform support: on CPU only, Zstd and AES-256 are disallowed.\n  5. Quantitative constraints:\n     - Bus capacity: the sum of transmitted rates $D_{\\text{tx}}$ must satisfy $D_{\\text{tx}} \\leq$ bus capacity.\n     - Compute budget: the total compute cost $K_{\\text{tot}}$ must satisfy $K_{\\text{tot}} \\leq$ the chosen platform budget.\n  The transmitted rate for a single sensor with raw rate $d$ is $d \\cdot r \\cdot (1+\\alpha)$. The total transmitted rate for the two sensors is the sum over the selected pair. The compute cost for a single sensor is $k_{c}\\cdot d + k_{e}\\cdot (r\\cdot d)$, and the total compute cost is the sum over the selected pair.\n\nCompute the number of valid configurations that satisfy all structural integrity and quantitative constraints, where a configuration is a complete selection of:\n- exactly two distinct sensors,\n- one bus,\n- one compression method,\n- one encryption method,\n- one compute platform.\n\nExpress your final answer as an exact integer (unitless). No rounding is required.",
            "solution": "We begin from the ADL principles: components (sensors, bus, processing platform) and connectors (compression and encryption transformations) must satisfy structural uniformity and compatibility. Quantitative properties bound resource usage via bus capacity and compute budgets. A feature diagram provides discrete variability; the valid configurations are those selections that satisfy the ADL-derived constraints.\n\nLet the raw data rates be $d_{\\text{IMU}}=5$, $d_{\\text{Lidar}}=100$, $d_{\\text{Camera}}=200$ (all in Mbps). Exactly two distinct sensors are selected from the set, yielding three possible pairs:\n- Pair $A$: IMU $+$ Lidar, with total raw rate $D_{A}=5+100=105$.\n- Pair $B$: IMU $+$ Camera, with total raw rate $D_{B}=5+200=205$.\n- Pair $C$: Lidar $+$ Camera, with total raw rate $D_{C}=100+200=300$.\n\nUniform compression and encryption imply:\n- Transmitted rate for a single sensor with raw rate $d$ is $d\\cdot r \\cdot (1+\\alpha)$.\n- Total transmitted rate for a pair is $D \\cdot r \\cdot (1+\\alpha)$, where $D$ is the pair’s raw sum.\n- Total compute cost for a pair is $K_{\\text{tot}}=D \\cdot (k_{c} + k_{e} r)$.\n\nCompression options: None ($r=1, k_{c}=0$), LZ4 ($r=\\frac{3}{5}, k_{c}=0.2$), Zstd ($r=\\frac{2}{5}, k_{c}=0.5$). Encryption options: None ($\\alpha=0, k_{e}=0$), AES-128 ($\\alpha=0.1, k_{e}=1.0$), AES-256 ($\\alpha=0.2, k_{e}=1.5$). Bus capacities: CAN $50$ Mbps, TSN $1000$ Mbps. Platform budgets: CPU only $250$, CPU+GPU $400$, CPU+FPGA $500$. Structural constraints: Camera requires encryption $\\neq$ None; AES-256 requires TSN; CPU only disallows Zstd and AES-256.\n\nStep 1: Bus capacity feasibility.\n\nFor each pair $D$ and choice $(r,\\alpha)$, the total transmitted rate is $D_{\\text{tx}}=D \\cdot r \\cdot (1+\\alpha)$. TSN has capacity $1000$ Mbps, so all combinations are feasible on TSN. For CAN with capacity $50$ Mbps, we check feasibility:\n\n- Pair $A$ ($D_{A}=105$):\n  - None compression ($r=1$):\n    - None encryption ($\\alpha=0$): $105 \\cdot 1 \\cdot 1 = 105$ (not feasible).\n    - AES-128 ($\\alpha=0.1$): $105 \\cdot 1 \\cdot 1.1 = 115.5$ (not feasible).\n    - AES-256 ($\\alpha=0.2$): $105 \\cdot 1 \\cdot 1.2 = 126$ (not feasible).\n  - LZ4 ($r=\\frac{3}{5}$):\n    - None: $105 \\cdot \\frac{3}{5} \\cdot 1 = 63$ (not feasible).\n    - AES-128: $105 \\cdot \\frac{3}{5} \\cdot 1.1 = 69.3$ (not feasible).\n    - AES-256: $105 \\cdot \\frac{3}{5} \\cdot 1.2 = 75.6$ (not feasible).\n  - Zstd ($r=\\frac{2}{5}$):\n    - None: $105 \\cdot \\frac{2}{5} \\cdot 1 = 42$ (feasible).\n    - AES-128: $105 \\cdot \\frac{2}{5} \\cdot 1.1 = 46.2$ (feasible).\n    - AES-256: $105 \\cdot \\frac{2}{5} \\cdot 1.2 = 50.4$ (not feasible).\n  Note AES-256 is structurally incompatible with CAN regardless.\n\n- Pair $B$ ($D_{B}=205$, camera present requires encryption):\n  - Zstd ($r=\\frac{2}{5}$), AES-128: $205 \\cdot \\frac{2}{5} \\cdot 1.1 = 90.2$ (not feasible).\n  - Zstd, AES-256: $205 \\cdot \\frac{2}{5} \\cdot 1.2 = 98.4$ (not feasible).\n  - LZ4 ($r=\\frac{3}{5}$), AES-128: $205 \\cdot \\frac{3}{5} \\cdot 1.1 = 135.3$ (not feasible).\n  - LZ4, AES-256: $205 \\cdot \\frac{3}{5} \\cdot 1.2 = 147.6$ (not feasible).\n  - None ($r=1$), AES-128: $205 \\cdot 1 \\cdot 1.1 = 225.5$ (not feasible).\n  - None, AES-256: $205 \\cdot 1 \\cdot 1.2 = 246$ (not feasible).\n  Thus no camera-containing pair is feasible on CAN.\n\n- Pair $C$ ($D_{C}=300$, camera present requires encryption):\n  - Zstd ($r=\\frac{2}{5}$), AES-128: $300 \\cdot \\frac{2}{5} \\cdot 1.1 = 132$ (not feasible).\n  - Zstd, AES-256: $300 \\cdot \\frac{2}{5} \\cdot 1.2 = 144$ (not feasible).\n  - LZ4 ($r=\\frac{3}{5}$), AES-128: $300 \\cdot \\frac{3}{5} \\cdot 1.1 = 198$ (not feasible).\n  - LZ4, AES-256: $300 \\cdot \\frac{3}{5} \\cdot 1.2 = 216$ (not feasible).\n  - None ($r=1$), AES-128: $300 \\cdot 1 \\cdot 1.1 = 330$ (not feasible).\n  - None, AES-256: $300 \\cdot 1 \\cdot 1.2 = 360$ (not feasible).\n  Thus no camera-containing pair is feasible on CAN. The only CAN-feasible cases are Pair $A$ with Zstd and either None or AES-128 (subject to other constraints).\n\nStep 2: Compute budget feasibility.\n\nTotal compute cost for a pair with raw sum $D$ is $K_{\\text{tot}}=D\\cdot(k_{c}+k_{e}r)$.\n\nCompute values for Pair $A$ ($D_{A}=105$):\n- None compression ($r=1$):\n  - None encryption: $105\\cdot(0+0\\cdot 1)=0$.\n  - AES-128: $105\\cdot(0+1\\cdot 1)=105$.\n  - AES-256: $105\\cdot(0+1.5\\cdot 1)=157.5$.\n- LZ4 ($r=\\frac{3}{5}$):\n  - None: $105\\cdot(0.2+0\\cdot \\frac{3}{5})=21$.\n  - AES-128: $105\\cdot(0.2+1\\cdot \\frac{3}{5})=105\\cdot 0.8=84$.\n  - AES-256: $105\\cdot(0.2+1.5\\cdot \\frac{3}{5})=105\\cdot 1.1=115.5$.\n- Zstd ($r=\\frac{2}{5}$):\n  - None: $105\\cdot(0.5+0\\cdot \\frac{2}{5})=52.5$.\n  - AES-128: $105\\cdot(0.5+1\\cdot \\frac{2}{5})=105\\cdot 0.9=94.5$.\n  - AES-256: $105\\cdot(0.5+1.5\\cdot \\frac{2}{5})=105\\cdot 1.1=115.5$.\nAll are $\\leq 250$, $\\leq 400$, and $\\leq 500$, so compute budgets do not bind for Pair $A$.\n\nCompute values for Pair $B$ ($D_{B}=205$):\n- None ($r=1$):\n  - AES-128: $205\\cdot 1=205$.\n  - AES-256: $205\\cdot 1.5=307.5$.\n- LZ4 ($r=\\frac{3}{5}$):\n  - None: $205\\cdot 0.2=41$.\n  - AES-128: $205\\cdot 0.8=164$.\n  - AES-256: $205\\cdot 1.1=225.5$.\n- Zstd ($r=\\frac{2}{5}$):\n  - None: $205\\cdot 0.5=102.5$.\n  - AES-128: $205\\cdot 0.9=184.5$.\n  - AES-256: $205\\cdot 1.1=225.5$.\nAll are $\\leq 400$ and $\\leq 500$. On CPU only ($250$), only None+AES-256 exceeds budget ($307.5$), but CPU only structurally disallows AES-256 and Zstd anyway.\n\nCompute values for Pair $C$ ($D_{C}=300$):\n- None ($r=1$):\n  - AES-128: $300\\cdot 1=300$.\n  - AES-256: $300\\cdot 1.5=450$.\n- LZ4 ($r=\\frac{3}{5}$):\n  - None: $300\\cdot 0.2=60$.\n  - AES-128: $300\\cdot 0.8=240$.\n  - AES-256: $300\\cdot 1.1=330$.\n- Zstd ($r=\\frac{2}{5}$):\n  - None: $300\\cdot 0.5=150$.\n  - AES-128: $300\\cdot 0.9=270$.\n  - AES-256: $300\\cdot 1.1=330$.\nFor CPU only ($250$), None+AES-128 exceeds budget ($300$), and LZ4+AES-256 and Zstd+AES-128 also exceed ($330$, $270$); however, CPU only structurally disallows AES-256 and Zstd. For CPU+GPU ($400$), all are within budget except None+AES-256 ($450$). For CPU+FPGA ($500$), all are within budget.\n\nStep 3: Count valid configurations, respecting all structural constraints.\n\nWe count by bus type and sensor pair.\n\n- CAN:\n  - Pair $A$ feasible only with Zstd and encryption in $\\{\\text{None}, \\text{AES-128}\\}$. AES-256 incompatible with CAN; CPU only disallows Zstd, so only CPU+GPU and CPU+FPGA platforms are allowed.\n    - Encryption choices: $2$ (None, AES-128).\n    - Platforms: $2$ (CPU+GPU, CPU+FPGA).\n    - Total CAN configurations for Pair $A$: $2 \\times 2 = 4$.\n  - Pairs $B$ and $C$ are not feasible on CAN due to capacity.\n  Thus CAN total: $4$.\n\n- TSN:\n  All pairs satisfy capacity. Apply camera encryption requirement, AES-256 compatibility, and platform support.\n\n  - Pair $A$ (no camera requirement):\n    - CPU only: Zstd disallowed, AES-256 disallowed. Compression in $\\{\\text{None}, \\text{LZ4}\\}$, Encryption in $\\{\\text{None}, \\text{AES-128}\\}$. Combinations: $2 \\times 2 = 4$.\n    - CPU+GPU: all $3$ compressions $\\times$ all $3$ encryptions: $3 \\times 3 = 9$.\n    - CPU+FPGA: similarly $9$.\n    - Total for Pair $A$ on TSN: $4 + 9 + 9 = 22$.\n\n  - Pair $B$ (camera present, encryption $\\in \\{\\text{AES-128}, \\text{AES-256}\\}$):\n    - CPU only: Zstd disallowed, AES-256 disallowed. Compression in $\\{\\text{None}, \\text{LZ4}\\}$, encryption $\\{\\text{AES-128}\\}$: $2 \\times 1 = 2$ (budgets satisfied).\n    - CPU+GPU: all $3$ compressions $\\times$ both encryptions: $3 \\times 2 = 6$ (budgets satisfied).\n    - CPU+FPGA: $3 \\times 2 = 6$.\n    - Total for Pair $B$ on TSN: $2 + 6 + 6 = 14$.\n\n  - Pair $C$ (camera present, encryption $\\in \\{\\text{AES-128}, \\text{AES-256}\\}$):\n    - CPU only: Zstd disallowed, AES-256 disallowed; compression $\\{\\text{None}, \\text{LZ4}\\}$ with encryption $\\{\\text{AES-128}\\}$. None+AES-128 exceeds budget ($300>250$), LZ4+AES-128 within budget ($240\\leq 250$). So $1$ valid combination.\n    - CPU+GPU: all $3$ compressions $\\times$ both encryptions $=6$, but None+AES-256 exceeds budget ($450>400$), so $5$ valid.\n    - CPU+FPGA: all $6$ valid (budgets satisfied).\n    - Total for Pair $C$ on TSN: $1 + 5 + 6 = 12$.\n\n  TSN total: $22 + 14 + 12 = 48$.\n\nSumming across bus types, the total number of valid configurations is $4$ (CAN) $+$ $48$ (TSN) $=$ $52$.\n\nTherefore, the number of valid configurations satisfying all ADL-derived structural integrity and quantitative constraints is $52$.",
            "answer": "$$\\boxed{52}$$"
        },
        {
            "introduction": "The ultimate goal of model-based design is often not just to find a valid architecture, but to discover an optimal one. This practice moves from manual analysis to automated design space exploration by framing the architectural design as a constrained optimization problem. You will implement an algorithm to find the optimal allocation of software components to hardware resources that minimizes end-to-end latency while respecting schedulability, memory, and bus capacity constraints specified in the ADL model .",
            "id": "4205704",
            "problem": "Consider an Architecture Description Language (ADL) model of a cyber-physical system consisting of processors, a shared bus, memories, and a linear pipeline of software components. The objective is to determine an allocation of each software component to a processor and to a memory that minimizes the end-to-end latency of one pipeline execution, subject to processor schedulability, memory capacity, and bus capacity constraints. The allocation must be derived from first principles of performance modeling and scheduling theory and implemented as a complete runnable program.\n\nDefinitions and fundamental base:\n- Architecture Description Language (ADL) provides a structural model of components and connectors. We consider sets of processors, a single shared bus, memories, and software components with fixed attributes.\n- Millions of Instructions Per Second (MIPS) is the processor speed metric. If a component requires $w_i$ million instructions and executes on a processor of speed $S_p$ MIPS, then its compute time is $C_{i,p} = \\frac{w_i}{S_p}$ seconds.\n- Megabytes per second (MB/s) is the capacity metric for bus bandwidth and memory throughput. If a component requires $d_i$ megabytes per period for memory access and executes with period $T_i$ seconds, then its memory data rate is $\\frac{d_i}{T_i}$ MB/s.\n- Schedulability under Earliest Deadline First (EDF): For a single processor, a sufficient and necessary schedulability condition is the utilization inequality $\\sum_{i \\in \\mathcal{A}(p)} \\frac{C_{i,p}}{T_i} \\leq 1$, where $\\mathcal{A}(p)$ is the set of components assigned to processor $p$, $C_{i,p}$ is the compute time on that processor, and $T_i$ is the component period.\n- Memory throughput capacity: For each memory $m$ with throughput capacity $W_m$ MB/s, the aggregate assigned data rates must satisfy $\\sum_{i \\in \\mathcal{A}(m)} \\frac{d_i}{T_i} \\leq W_m$.\n- Shared bus capacity: For a single shared bus of bandwidth $R_b$ MB/s and per-transfer arbitration overhead $\\tau_b$ seconds, the sum of rates of all bus-using flows must satisfy $\\sum_{\\text{flows}} \\text{rate} \\leq R_b$. The flows are: (a) remote memory accesses where a component’s assigned memory is not the processor’s local memory, with rate $\\frac{d_i}{T_i}$ for component $i$, and (b) inter-component message flows between adjacent components in the pipeline when they reside on different processors. For a message of size $s_j$ MB between components $j$ and $j+1$, the bus rate contribution is $\\frac{s_j}{\\max(T_j, T_{j+1})}$ MB/s.\n- End-to-end latency model: For a pipeline of $N$ components with assignments $p(i)$ to processors and $m(i)$ to memories, the end-to-end latency $L_{\\text{end}}$ of one execution equals the sum of compute times, memory access times, and inter-component communication latencies:\n  $$L_{\\text{end}} = \\sum_{i=1}^{N} \\left( \\frac{w_i}{S_{p(i)}} + \\left[ \\frac{d_i}{W_{m(i)}} + \\lambda_{m(i)} \\right] + \\Delta^{\\text{mem}}_{i} \\right) + \\sum_{i=1}^{N-1} \\Delta^{\\text{msg}}_{i,i+1},$$\n  where $\\lambda_{m(i)}$ is the base memory latency of memory $m(i)$, and the additional bus terms are\n  $$\\Delta^{\\text{mem}}_{i} = \\begin{cases}\n  \\frac{d_i}{R_b} + \\tau_b  \\text{if } m(i) \\neq L_{p(i)},\\\\\n  0  \\text{otherwise,}\n  \\end{cases} \\quad\n  \\Delta^{\\text{msg}}_{i,i+1} = \\begin{cases}\n  \\frac{s_i}{R_b} + \\tau_b  \\text{if } p(i) \\neq p(i+1),\\\\\n  0  \\text{otherwise,}\n  \\end{cases}$$\n  with $L_{p(i)}$ denoting the local memory identifier of processor $p(i)$.\n\nAllocation decision variables:\n- For each component $i \\in \\{1,\\dots,N\\}$, choose a processor $p(i)$ from the processor set and a memory $m(i)$ from the memory set.\n\nConstraints:\n- Processor schedulability (EDF) for each processor $p$: $$\\sum_{i : p(i) = p} \\frac{\\frac{w_i}{S_p}}{T_i} \\leq 1.$$\n- Memory throughput for each memory $m$: $$\\sum_{i : m(i) = m} \\frac{d_i}{T_i} \\leq W_m.$$\n- Bus capacity: $$\\sum_{i : m(i) \\neq L_{p(i)}} \\frac{d_i}{T_i} + \\sum_{j=1}^{N-1 : p(j) \\neq p(j+1)} \\frac{s_j}{\\max(T_j, T_{j+1})} \\leq R_b.$$\n\nObjective:\n- Minimize $L_{\\text{end}}$ subject to the constraints.\n\nYour task:\n- Implement a complete program that enumerates all allocations and returns the minimal feasible end-to-end latency $L_{\\text{end}}$ for each provided test case. The answer must be expressed in seconds, rounded to $6$ decimal places.\n\nTest suite:\n- All test cases share a pipeline length $N = 3$ with adjacent message sizes $s_1$ and $s_2$ and component memory data per period $d_1$, $d_2$, $d_3$.\n- Test Case $1$ (general case):\n  - Processors: $p_1$ with speed $S_{p_1} = 100$ MIPS and local memory $L_{p_1} = m_1$; $p_2$ with speed $S_{p_2} = 50$ MIPS and local memory $L_{p_2} = m_2$.\n  - Bus: bandwidth $R_b = 100$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 60$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 40$ MB/s and base latency $\\lambda_{m_2} = 0.002$ s.\n  - Components: $(w_1,w_2,w_3) = (2, 1.5, 1)$ million instructions, $(T_1,T_2,T_3) = (0.05, 0.05, 0.05)$ s, $(d_1,d_2,d_3) = (1, 0.5, 0.2)$ MB, and adjacent message sizes $(s_1,s_2) = (2, 1)$ MB.\n- Test Case $2$ (bus-constrained boundary case):\n  - Processors: identical to Test Case $1$.\n  - Bus: bandwidth $R_b = 60$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 60$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 60$ MB/s and base latency $\\lambda_{m_2} = 0.0015$ s.\n  - Components: identical to Test Case $1$.\n- Test Case $3$ (memory-throughput edge case):\n  - Processors: $p_1$ with speed $S_{p_1} = 100$ MIPS and local memory $L_{p_1} = m_1$; $p_2$ with speed $S_{p_2} = 80$ MIPS and local memory $L_{p_2} = m_2$.\n  - Bus: bandwidth $R_b = 200$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 25$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 25$ MB/s and base latency $\\lambda_{m_2} = 0.001$ s.\n  - Components: $(w_1,w_2,w_3) = (2, 1.5, 1)$ million instructions, $(T_1,T_2,T_3) = (0.05, 0.05, 0.05)$ s, $(d_1,d_2,d_3) = (1, 0.5, 0.2)$ MB, and adjacent message sizes $(s_1,s_2) = (2, 1)$ MB.\n\nFinal output format:\n- Your program should produce a single line of output containing the minimal end-to-end latencies for the three test cases, as a comma-separated list enclosed in square brackets (e.g., \"[0.123456,0.234567,0.345678]\"), with each latency in seconds, rounded to $6$ decimal places.",
            "solution": "The problem presented is a constrained combinatorial optimization task. The objective is to find an allocation of software components to hardware resources (processors and memories) in a cyber-physical system, described by an Architecture Description Language (ADL) model, that minimizes the end-to-end latency of a software pipeline. This allocation must satisfy a set of performance and capacity constraints.\n\nThe problem is well-posed and all parameters, constraints, and the objective function are explicitly defined. The proposed solution methodology is based on an exhaustive search of all possible allocations, which is computationally feasible given the small dimensions of the problem instance ($N=3$ components, $2$ processors, $2$ memories).\n\nAn allocation is defined by a pair of assignment vectors, $(\\vec{p}, \\vec{m})$, where for each software component $i \\in \\{1, \\dots, N\\}$, $p(i)$ specifies its assigned processor and $m(i)$ specifies its assigned memory. With $|P|$ processors and $|M|$ memories, there are $(|P| \\cdot |M|)^N$ total possible allocations. For each test case, we have $N=3$, $|P|=2$, and $|M|=2$, resulting in $(2 \\cdot 2)^3 = 64$ unique allocations to evaluate.\n\nThe solution algorithm proceeds as follows:\n1.  Initialize a variable for the minimum latency, $L_{\\text{min}}$, to infinity.\n2.  Iterate through each of the $64$ possible allocations $(\\vec{p}, \\vec{m})$.\n3.  For each allocation, perform a feasibility check by verifying all system constraints. An allocation is deemed feasible only if it satisfies all three of the following conditions:\n\n    a.  **Processor Schedulability Constraint**: For each processor $p$ in the system, the total utilization must not exceed its capacity. The utilization for a set of components $\\mathcal{A}(p)$ assigned to processor $p$ is calculated based on the Earliest Deadline First (EDF) schedulability condition. With component $i$ having workload $w_i$ (million instructions), period $T_i$ (seconds), and processor $p$ having speed $S_p$ (MIPS), the compute time is $C_{i,p} = w_i/S_p$. The constraint is:\n    $$\\sum_{i : p(i)=p} \\frac{C_{i,p}}{T_i} = \\sum_{i : p(i)=p} \\frac{w_i}{S_p \\cdot T_i} \\leq 1$$\n\n    b.  **Memory Throughput Constraint**: For each memory $m$ with throughput capacity $W_m$ (MB/s), the sum of data rates from all components assigned to it must not exceed its capacity. A component $i$ requiring $d_i$ MB of data per period $T_i$ has a data rate of $d_i/T_i$. The constraint is:\n    $$\\sum_{i : m(i)=m} \\frac{d_i}{T_i} \\leq W_m$$\n\n    c.  **Bus Capacity Constraint**: The total bandwidth consumed on the single shared bus must not exceed its capacity $R_b$ (MB/s). Bus traffic originates from two sources: (i) remote memory accesses, when a component's assigned memory $m(i)$ is not the local memory $L_{p(i)}$ of its assigned processor $p(i)$, and (ii) inter-processor communication, when adjacent components in the pipeline are assigned to different processors. The constraint is:\n    $$\\sum_{i : m(i) \\neq L_{p(i)}} \\frac{d_i}{T_i} + \\sum_{j=1}^{N-1 : p(j) \\neq p(j+1)} \\frac{s_j}{\\max(T_j, T_{j+1})} \\leq R_b$$\n    where $s_j$ is the message size between components $j$ and $j+1$.\n\n4.  If an allocation is found to be feasible (i.e., it satisfies all three constraints), its end-to-end latency, $L_{\\text{end}}$, is calculated using the formula provided:\n    $$L_{\\text{end}} = \\sum_{i=1}^{N} \\left( \\frac{w_i}{S_{p(i)}} + \\frac{d_i}{W_{m(i)}} + \\lambda_{m(i)} + \\Delta^{\\text{mem}}_{i} \\right) + \\sum_{i=1}^{N-1} \\Delta^{\\text{msg}}_{i,i+1}$$\n    The terms $\\Delta^{\\text{mem}}_{i}$ and $\\Delta^{\\text{msg}}_{i,i+1}$ represent the additional latency due to bus usage for remote memory access and inter-processor communication, respectively. They are non-zero only if the bus is used:\n    $$\\Delta^{\\text{mem}}_{i} = \\begin{cases} \\frac{d_i}{R_b} + \\tau_b  \\text{if } m(i) \\neq L_{p(i)} \\\\ 0  \\text{otherwise} \\end{cases}$$\n    $$\\Delta^{\\text{msg}}_{i,i+1} = \\begin{cases} \\frac{s_i}{R_b} + \\tau_b  \\text{if } p(i) \\neq p(i+1) \\\\ 0  \\text{otherwise} \\end{cases}$$\n    where $R_b$ is the bus bandwidth and $\\tau_b$ is the bus arbitration overhead.\n\n5.  The calculated $L_{\\text{end}}$ is compared with the current minimum latency, $L_{\\text{min}}$, and $L_{\\text{min}}$ is updated if the new latency is lower: $L_{\\text{min}} = \\min(L_{\\text{min}}, L_{\\text{end}})$.\n\n6.  After evaluating all $64$ allocations, the final value of $L_{\\text{min}}$ represents the minimal feasible end-to-end latency. This entire procedure is applied to each of the three test cases provided. The final result for each case is rounded to $6$ decimal places as required.",
            "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve_case(procs, mems, bus, comps):\n    \"\"\"\n    Solves for the minimum end-to-end latency for a single test case.\n\n    This function enumerates all possible processor and memory allocations\n    for the software components. For each allocation, it checks feasibility\n    against processor, memory, and bus constraints. If feasible, it calculates\n    the end-to-end latency. The minimum latency across all feasible\n    allocations is returned.\n    \"\"\"\n    w, T, d, s = comps['w'], comps['T'], comps['d'], comps['s']\n    N = len(w)\n    num_procs = len(procs)\n    num_mems = len(mems)\n\n    p_indices = range(num_procs)\n    m_indices = range(num_mems)\n\n    # Generate all possible allocations using itertools.product\n    proc_allocations = list(itertools.product(p_indices, repeat=N))\n    mem_allocations = list(itertools.product(m_indices, repeat=N))\n\n    min_latency = float('inf')\n\n    for p_alloc in proc_allocations:\n        for m_alloc in mem_allocations:\n            # 1. Check processor schedulability (EDF utilization)\n            proc_util = [0.0] * num_procs\n            for i in range(N):\n                p_idx = p_alloc[i]\n                proc_util[p_idx] += (w[i] / procs[p_idx]['S']) / T[i]\n            \n            if any(u > 1.0 for u in proc_util):\n                continue\n\n            # 2. Check memory throughput capacity\n            mem_thru = [0.0] * num_mems\n            for i in range(N):\n                m_idx = m_alloc[i]\n                mem_thru[m_idx] += d[i] / T[i]\n\n            if any(mem_thru[j] > mems[j]['W'] for j in range(num_mems)):\n                continue\n\n            # 3. Check shared bus capacity\n            bus_rate = 0.0\n            # a) Remote memory access flows\n            for i in range(N):\n                p_idx = p_alloc[i]\n                m_idx = m_alloc[i]\n                if m_idx != procs[p_idx]['L_mem_idx']:\n                    bus_rate += d[i] / T[i]\n            \n            # b) Inter-component message flows\n            for i in range(N - 1):\n                if p_alloc[i] != p_alloc[i+1]:\n                    bus_rate += s[i] / max(T[i], T[i+1])\n\n            if bus_rate > bus['R_b']:\n                continue\n\n            # If all constraints are met, the allocation is feasible.\n            # Calculate its end-to-end latency.\n            current_latency = 0.0\n            \n            # Sum of component-level latencies\n            for i in range(N):\n                p_idx = p_alloc[i]\n                m_idx = m_alloc[i]\n                \n                # Compute time\n                current_latency += w[i] / procs[p_idx]['S']\n                \n                # Memory access time (base part)\n                current_latency += d[i] / mems[m_idx]['W'] + mems[m_idx]['lambda']\n                \n                # Additional bus latency for remote memory access\n                if m_idx != procs[p_idx]['L_mem_idx']:\n                    current_latency += d[i] / bus['R_b'] + bus['tau_b']\n\n            # Sum of inter-component communication latencies\n            for i in range(N - 1):\n                if p_alloc[i] != p_alloc[i+1]:\n                    current_latency += s[i] / bus['R_b'] + bus['tau_b']\n            \n            min_latency = min(min_latency, current_latency)\n\n    return min_latency\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and generate the final output.\n    \"\"\"\n    # Common component data for all test cases\n    components = {\n        'w': [2.0, 1.5, 1.0],      # million instructions\n        'T': [0.05, 0.05, 0.05],  # seconds\n        'd': [1.0, 0.5, 0.2],    # MB\n        's': [2.0, 1.0]          # MB\n    }\n\n    test_cases = [\n        # Test Case 1: General case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 50.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 100.0, 'tau_b': 0.0005},\n            'mems': [{'W': 60.0, 'lambda': 0.001}, {'W': 40.0, 'lambda': 0.002}]\n        },\n        # Test Case 2: Bus-constrained boundary case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 50.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 60.0, 'tau_b': 0.0005},\n            'mems': [{'W': 60.0, 'lambda': 0.001}, {'W': 60.0, 'lambda': 0.0015}]\n        },\n        # Test Case 3: Memory-throughput edge case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 80.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 200.0, 'tau_b': 0.0005},\n            'mems': [{'W': 25.0, 'lambda': 0.001}, {'W': 25.0, 'lambda': 0.001}]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case['procs'], case['mems'], case['bus'], components)\n        results.append(result)\n\n    # Format the output as specified: list of latencies, 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}