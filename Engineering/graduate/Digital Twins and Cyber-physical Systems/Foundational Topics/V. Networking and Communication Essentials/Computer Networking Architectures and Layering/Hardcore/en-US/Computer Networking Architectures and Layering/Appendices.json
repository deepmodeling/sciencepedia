{
    "hands_on_practices": [
        {
            "introduction": "To design efficient communication for Cyber-Physical Systems, we must first understand the fundamental cost of data transmission. Every piece of application data is wrapped in multiple layers of protocol headers and trailers, creating overhead that consumes bandwidth and processing time. This first exercise  provides a practical scenario to deconstruct a network packet layer by layer, from the application payload down to the physical wire, allowing you to quantify the protocol overhead and calculate the true effective throughput for a real-time telemetry stream.",
            "id": "4209765",
            "problem": "A cyber-physical production system streams state telemetry from its plant to a supervisory digital twin. The telemetry is emitted periodically as a User Datagram Protocol (UDP) datagram with an application payload of $256$ bytes every $2$ milliseconds. The system uses Internet Protocol version $4$ (IPv4) over Ethernet on a local area network with a Maximum Transmission Unit (MTU) of $1500$ bytes. Assume Ethernet Version $2$ framing with no Virtual Local Area Network (VLAN) tags and no IPv4 options. For this environment, use the following well-tested facts:\n- The UDP header is $8$ bytes.\n- The IPv4 header (without options) is $20$ bytes.\n- The Ethernet Media Access Control (MAC) header is $14$ bytes and the Ethernet Frame Check Sequence (FCS) trailer is $4$ bytes.\n- At the physical layer, Ethernet transmits an $8$-byte preamble plus start frame delimiter before each frame and enforces a $12$-byte-time interframe gap after each frame.\n\nStarting from the Open Systems Interconnection (OSI) layering definitions and the stated header sizes, derive the total non-application on-wire overhead per packet and use it to:\n1. Compute the protocol overhead as a decimal fraction $f$ defined by $f = \\dfrac{\\text{non-application bytes per packet}}{\\text{total on-wire bytes per packet}}$, where “non-application bytes” include transport, network, data-link headers and trailer, and the physical-layer preamble and interframe gap.\n2. Compute the effective throughput of application payload delivered to the digital twin in megabits per second (Mb/s), given the $2$ millisecond periodicity.\n\nReport the protocol overhead as a decimal fraction and the effective throughput in Mb/s. Round both quantities to four significant figures. Express the throughput in Mb/s and the overhead as a unitless decimal fraction. Confirm whether fragmentation occurs under the given MTU and incorporate that determination into your derivation without using any shortcut formulas.",
            "solution": "The problem is scientifically grounded, well-posed, and contains sufficient information for a unique solution. We proceed with the derivation.\n\nThe solution requires calculating the total size of the data transmitted on the physical medium for a single application payload and then using this to find the overhead fraction and the effective throughput. We follow the data encapsulation process from the application layer down to the physical layer, consistent with the Open Systems Interconnection (OSI) model.\n\nThe given parameters are:\n- Application payload size, $L_{app} = 256$ bytes.\n- Time period between datagrams, $T = 2$ milliseconds = $2 \\times 10^{-3}$ s.\n- Maximum Transmission Unit, $MTU = 1500$ bytes.\n- User Datagram Protocol (UDP) header size, $H_{UDP} = 8$ bytes.\n- Internet Protocol version $4$ (IPv4) header size, $H_{IPv4} = 20$ bytes.\n- Ethernet Media Access Control (MAC) header size, $H_{Eth} = 14$ bytes.\n- Ethernet Frame Check Sequence (FCS) trailer size, $T_{Eth} = 4$ bytes.\n- Ethernet Preamble + Start Frame Delimiter (SFD) size, $P_{Eth} = 8$ bytes.\n- Ethernet Interframe Gap (IFG) size, $IFG = 12$ byte-times.\n\nFirst, we must determine if IP fragmentation occurs. The $MTU$ defines the maximum size of the payload for a data link layer frame. In this case, it is the maximum size of the IP packet that can be encapsulated within an Ethernet frame.\n\n1.  At the Transport Layer (OSI Layer $4$), the application payload is encapsulated in a UDP datagram. The size of the UDP datagram is the sum of its header and the application payload.\n    $$L_{UDP\\_datagram} = H_{UDP} + L_{app} = 8 \\text{ bytes} + 256 \\text{ bytes} = 264 \\text{ bytes}$$\n\n2.  At the Network Layer (OSI Layer $3$), the UDP datagram becomes the payload for an IPv4 packet. The size of the IPv4 packet is the sum of its header and its payload (the UDP datagram).\n    $$L_{IP\\_packet} = H_{IPv4} + L_{UDP\\_datagram} = 20 \\text{ bytes} + 264 \\text{ bytes} = 284 \\text{ bytes}$$\n\n3.  The $MTU$ for the network is given as $1500$ bytes. We compare the total IP packet size to the $MTU$:\n    $$L_{IP\\_packet} = 284 \\text{ bytes} < 1500 \\text{ bytes} = MTU$$\n    Since the IP packet size is less than the $MTU$, no fragmentation is required. The entire IP packet will be encapsulated in a single Ethernet frame.\n\nNow, we can calculate the total number of bytes transmitted on the wire for each packet. This includes the Ethernet frame itself and the physical layer overheads.\n\n4.  At the Data Link Layer (OSI Layer $2$), the IP packet is encapsulated in an Ethernet frame. The frame consists of a header, the IP packet payload, and a trailer.\n    $$L_{Ethernet\\_frame} = H_{Eth} + L_{IP\\_packet} + T_{Eth} = 14 \\text{ bytes} + 284 \\text{ bytes} + 4 \\text{ bytes} = 302 \\text{ bytes}$$\n\n5.  At the Physical Layer (OSI Layer $1$), additional bytes are added for signaling and timing. These are the preamble with SFD and the interframe gap. The problem asks for the total \"on-wire bytes per packet,\" which represents the total channel resources consumed by the transmission of one packet.\n    $$L_{total} = P_{Eth} + L_{Ethernet\\_frame} + IFG$$\n    $$L_{total} = 8 \\text{ bytes} + 302 \\text{ bytes} + 12 \\text{ byte-times} = 322 \\text{ bytes}$$\n    The $IFG$ is given in \"byte-times,\" which for this calculation is equivalent to bytes in terms of channel occupancy.\n\nWith the total on-wire size established, we can solve for the two required quantities.\n\n**1. Protocol Overhead Fraction ($f$)**\n\nThe protocol overhead fraction $f$ is defined as the ratio of non-application bytes to the total on-wire bytes.\nThe non-application bytes, $L_{non-app}$, are the total bytes minus the original application payload.\n$$L_{non-app} = L_{total} - L_{app} = 322 \\text{ bytes} - 256 \\text{ bytes} = 66 \\text{ bytes}$$\nAlternatively, we can sum the sizes of all protocol headers, trailers, and physical layer overheads:\n$$L_{non-app} = H_{UDP} + H_{IPv4} + H_{Eth} + T_{Eth} + P_{Eth} + IFG$$\n$$L_{non-app} = 8 + 20 + 14 + 4 + 8 + 12 = 66 \\text{ bytes}$$\nThe fraction $f$ is then:\n$$f = \\frac{L_{non-app}}{L_{total}} = \\frac{66}{322} \\approx 0.2049689...$$\nRounding to four significant figures, we get:\n$$f \\approx 0.2050$$\n\n**2. Effective Application Payload Throughput**\n\nThe effective throughput concerns only the application payload data delivered to the digital twin. One payload of $L_{app} = 256$ bytes is delivered every $T = 2$ milliseconds.\n\nFirst, we convert the payload size from bytes to bits:\n$$L_{app, bits} = L_{app} \\times 8 \\frac{\\text{bits}}{\\text{byte}} = 256 \\text{ bytes} \\times 8 \\frac{\\text{bits}}{\\text{byte}} = 2048 \\text{ bits}$$\nThe effective throughput, $R_{eff}$, is the number of application bits transmitted per unit of time.\n$$R_{eff} = \\frac{L_{app, bits}}{T} = \\frac{2048 \\text{ bits}}{2 \\times 10^{-3} \\text{ s}} = 1\\,024\\,000 \\text{ bits/s}$$\nThe problem requires the answer in megabits per second (Mb/s), where $1$ Mb/s = $10^6$ bits/s.\n$$R_{eff} = \\frac{1\\,024\\,000 \\text{ bits/s}}{10^6 \\text{ bits/Mb}} = 1.024 \\text{ Mb/s}$$\nRounding to four significant figures, this becomes:\n$$R_{eff} \\approx 1.0240 \\text{ Mb/s}$$\n\nThe two final results are the protocol overhead fraction $f$ and the effective throughput $R_{eff}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.2050 & 1.0240\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Once a packet is constructed, it must be intelligently guided through an internetwork to its destination. This process, known as routing, relies on hierarchical addressing schemes and a simple but powerful forwarding rule. This practice  challenges you to step into the role of a network router, applying the principles of Classless Inter-Domain Routing (CIDR) and the longest-prefix match (LPM) algorithm to determine packet paths, a core skill for designing and analyzing the behavior of complex industrial networks.",
            "id": "4209772",
            "problem": "In a cyber-physical production plant, a distribution router interconnects three operational technology subnets and two external network segments. The plant’s digital twin replicates the routing behavior at the network layer to evaluate failover policies under the Internet Protocol version 4 (IPv4). Use only the following foundational bases: the definition of Classless Inter-Domain Routing (CIDR) prefixes as bitmasks over $32$-bit IPv4 addresses, the definition of network reachability by prefix membership, and the longest-prefix match (LPM) rule, which forwards based on the matching route with the largest prefix length.\n\nThree plant subnets are locally attached to three distinct router interfaces:\n- Subnet $S_A$: $\\text{10.0.16.0}/21$ on interface $I_A$.\n- Subnet $S_B$: $\\text{10.0.24.0}/21$ on interface $I_B$.\n- Subnet $S_C$: $\\text{10.0.32.0}/20$ on interface $I_C$.\n\nThe router also has the following installed routes and interfaces:\n- Demilitarized Zone (DMZ): $\\text{172.20.0.0}/16$ on interface $I_{\\text{DMZ}}$.\n- Plant summary toward the core: $\\text{10.0.0.0}/8$ on interface $I_{\\text{Core}}$.\n- Default route to the Wide Area Network (WAN): $\\text{0.0.0.0}/0$ on interface $I_{\\text{WAN}}$.\n\nTask 1 (aggregation for export): Using only CIDR principles and bitwise prefix alignment, determine the minimal exact-cover set of aggregated CIDR prefixes that can be formed from the union of $S_A$, $S_B$, and $S_C$ without including any address outside these three subnets. Your answer to this task should logically justify whether and how any of $S_A$, $S_B$, and $S_C$ can be aggregated into supernets while preserving exact coverage.\n\nTask 2 (forwarding by LPM): Consider the following destination addresses to be looked up by the router’s Forwarding Information Base (FIB):\n- $d_1 = \\text{10.0.17.5}$,\n- $d_2 = \\text{10.0.30.1}$,\n- $d_3 = \\text{10.0.200.1}$,\n- $d_4 = \\text{172.20.10.10}$,\n- $d_5 = \\text{10.0.36.9}$,\n- $d_6 = \\text{8.8.8.8}$.\nFor each $d_k$, determine the outgoing interface selected by the router under the LPM rule, given all installed routes listed above.\n\nFinal encoding (single numeric answer): Map the interface selected for each $d_k$ to a code via the function $g$ defined by\n$$\ng(I_A)=2,\\quad g(I_B)=3,\\quad g(I_C)=5,\\quad g(I_{\\text{DMZ}})=7,\\quad g(I_{\\text{Core}})=11,\\quad g(I_{\\text{WAN}})=13.\n$$\nCompute the single scalar\n$$\nK \\;=\\; \\sum_{k=1}^{6} k \\cdot g\\big(\\text{interface selected for } d_k\\big).\n$$\nReport $K$ as a base-$10$ integer with no units. No rounding is required or permitted. The final answer must be this single integer.",
            "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, and objective. It is based on established principles of computer networking, specifically IPv4 addressing, Classless Inter-Domain Routing (CIDR), and the Longest-Prefix Match (LPM) forwarding rule. The provided data is complete, consistent, and allows for a unique, verifiable solution.\n\nThe solution is divided into three parts: first, the analysis of subnet aggregation (Task 1); second, the determination of forwarding paths for given destination addresses (Task 2); and third, the computation of the final scalar value $K$.\n\n### Task 1: CIDR Prefix Aggregation\n\nThe goal is to find the minimal set of CIDR prefixes that provides an exact cover for the union of subnets $S_A$, $S_B$, and $S_C$, without including any extraneous addresses. The subnets are:\n- $S_A$: $\\text{10.0.16.0}/21$\n- $S_B$: $\\text{10.0.24.0}/21$\n- $S_C$: $\\text{10.0.32.0}/20$\n\nTo analyze aggregation possibilities, we must examine the binary representation of the network prefixes, focusing on the third octet where the addresses differ. An IPv4 address is a $32$-bit number. A prefix length of $/n$ means the first $n$ bits are fixed for all addresses in that subnet.\n\n1.  **Analyze $S_A$ and $S_B$:**\n    - Subnet $S_A = \\text{10.0.16.0}/21$. The prefix length of $21$ means the first $21$ bits are fixed. The first two octets ($16$ bits) are `00001010.00000000`. The third octet of the network address is $16 = 00010000_2$. The first $21-16=5$ bits of this octet are part of the prefix: `00010`. The range of addresses for $S_A$ is from $\\text{10.0.16.0}$ to $\\text{10.0.23.255}$.\n    - Subnet $S_B = \\text{10.0.24.0}/21$. The third octet of the network address is $24 = 00011000_2$. The first $5$ bits of this octet are `00011`. The range of addresses for $S_B$ is from $\\text{10.0.24.0}$ to $\\text{10.0.31.255}$.\n\n    The binary prefixes for $S_A$ and $S_B$ up to bit $21$ are:\n    - $S_A$: `00001010.00000000.00010`\n    - $S_B$: `00001010.00000000.00011`\n\n    The first $20$ bits are identical (`00001010.00000000.0001`). The $21^{\\text{st}}$ bit is $0$ for $S_A$ and $1$ for $S_B$. This is the condition for two adjacent $/21$ blocks (or \"buddy blocks\") to be aggregated into a single $/20$ block. The resulting aggregate prefix is formed by taking the common $20$-bit prefix, which corresponds to the network address $\\text{10.0.16.0}$.\n    The aggregated subnet, let's call it $S_{AB}$, is $\\text{10.0.16.0}/20$. This block covers the IP address range from $\\text{10.0.16.0}$ to $\\text{10.0.31.255}$, which is exactly the union of the address ranges of $S_A$ and $S_B$.\n\n2.  **Analyze $S_{AB}$ and $S_C$:**\n    - We now have two blocks: the aggregated block $S_{AB} = \\text{10.0.16.0}/20$ and the original block $S_C = \\text{10.0.32.0}/20$.\n    - The address range for $S_C$ is from $\\text{10.0.32.0}$ to $\\text{10.0.47.255}$.\n    - The total address space to be covered is the union of $S_{AB}$ and $S_C$, which corresponds to the continuous range from $\\text{10.0.16.0}$ to $\\text{10.0.47.255}$.\n\n    To determine if these two $/20$ blocks can be further aggregated into a single block, we examine their binary prefixes.\n    - $S_{AB}$ network address: $\\text{10.0.16.0} \\rightarrow 00001010.00000000.00010000.00000000$\n    - $S_C$ network address: $\\text{10.0.32.0} \\rightarrow 00001010.00000000.00100000.00000000$\n\n    The common prefix is `00001010.00000000.00...`, which is $18$ bits long. A single aggregate would have to be a $/18$ prefix: $\\text{10.0.0.0}/18$. However, this prefix covers the range $\\text{10.0.0.0}$ to $\\text{10.0.63.255}$, which is much larger than the required range and thus not an exact cover.\n\n    Alternatively, a CIDR block must be a power-of-$2$ size and aligned on a boundary of that size. The total range $[\\text{10.0.16.0}, \\text{10.0.47.255}]$ contains $2 \\times 2^{32-20} = 2 \\times 2^{12} = 2^{13}$ addresses, which corresponds to the size of a $/19$ prefix. However, a $/19$ block's starting address must have its last $13$ bits as zero. The starting address $\\text{10.0.16.0}$ has binary representation `00001010.00000000.00010000.00000000`. The last $13$ bits are `10000.00000000`, which are not all zero. Therefore, this range cannot be represented by a single CIDR prefix.\n\n    The minimal set of aggregated prefixes that exactly covers the union of $S_A$, $S_B$, and $S_C$ is $\\{\\text{10.0.16.0}/20, \\text{10.0.32.0}/20\\}$.\n\n### Task 2: Forwarding by Longest-Prefix Match (LPM)\n\nThe router's Forwarding Information Base (FIB) consists of the following routes:\n1.  $\\text{10.0.16.0}/21 \\rightarrow I_A$ (Prefix length $L=21$)\n2.  $\\text{10.0.24.0}/21 \\rightarrow I_B$ (Prefix length $L=21$)\n3.  $\\text{10.0.32.0}/20 \\rightarrow I_C$ (Prefix length $L=20$)\n4.  $\\text{172.20.0.0}/16 \\rightarrow I_{\\text{DMZ}}$ (Prefix length $L=16$)\n5.  $\\text{10.0.0.0}/8 \\rightarrow I_{\\text{Core}}$ (Prefix length $L=8$)\n6.  $\\text{0.0.0.0}/0 \\rightarrow I_{\\text{WAN}}$ (Prefix length $L=0$)\n\nFor each destination address $d_k$, we find all matching prefixes in the FIB and select the one with the largest prefix length ($L$).\n\n-   **For $d_1 = \\text{10.0.17.5}$**:\n    - Matches $\\text{10.0.16.0}/21$ (range $\\text{10.0.16.0} - \\text{10.0.23.255}$), $L=21$.\n    - Matches $\\text{10.0.0.0}/8$ (range $\\text{10.0.0.0} - \\text{10.255.255.255}$), $L=8$.\n    - Matches $\\text{0.0.0.0}/0$ (all addresses), $L=0$.\n    - Longest match is $/21$. Interface is $I_A$.\n\n-   **For $d_2 = \\text{10.0.30.1}$**:\n    - Matches $\\text{10.0.24.0}/21$ (range $\\text{10.0.24.0} - \\text{10.0.31.255}$), $L=21$.\n    - Matches $\\text{10.0.0.0}/8$, $L=8$.\n    - Matches $\\text{0.0.0.0}/0$, $L=0$.\n    - Longest match is $/21$. Interface is $I_B$.\n\n-   **For $d_3 = \\text{10.0.200.1}$**:\n    - Does not match any of the $/21$ or $/20$ prefixes.\n    - Matches $\\text{10.0.0.0}/8$, $L=8$.\n    - Matches $\\text{0.0.0.0}/0$, $L=0$.\n    - Longest match is $/8$. Interface is $I_{\\text{Core}}$.\n\n-   **For $d_4 = \\text{172.20.10.10}$**:\n    - Matches $\\text{172.20.0.0}/16$ (range $\\text{172.20.0.0} - \\text{172.20.255.255}$), $L=16$.\n    - Matches $\\text{0.0.0.0}/0$, $L=0$.\n    - Longest match is $/16$. Interface is $I_{\\text{DMZ}}$.\n\n-   **For $d_5 = \\text{10.0.36.9}$**:\n    - Matches $\\text{10.0.32.0}/20$ (range $\\text{10.0.32.0} - \\text{10.0.47.255}$), $L=20$.\n    - Matches $\\text{10.0.0.0}/8$, $L=8$.\n    - Matches $\\text{0.0.0.0}/0$, $L=0$.\n    - Longest match is $/20$. Interface is $I_C$.\n\n-   **For $d_6 = \\text{8.8.8.8}$**:\n    - Does not match any prefix except the default route.\n    - Matches $\\text{0.0.0.0}/0$, $L=0$.\n    - Longest match (only match) is $/0$. Interface is $I_{\\text{WAN}}$.\n\nSummary of forwarding decisions:\n- $d_1 \\rightarrow I_A$\n- $d_2 \\rightarrow I_B$\n- $d_3 \\rightarrow I_{\\text{Core}}$\n- $d_4 \\rightarrow I_{\\text{DMZ}}$\n- $d_5 \\rightarrow I_C$\n- $d_6 \\rightarrow I_{\\text{WAN}}$\n\n### Final Scalar Calculation\n\nThe mapping from interface to code is given by the function $g$:\n$g(I_A)=2$, $g(I_B)=3$, $g(I_C)=5$, $g(I_{\\text{DMZ}})=7$, $g(I_{\\text{Core}})=11$, $g(I_{\\text{WAN}})=13$.\n\nWe compute the scalar $K$ using the formula:\n$$\nK = \\sum_{k=1}^{6} k \\cdot g\\big(\\text{interface selected for } d_k\\big)\n$$\n\nSubstituting the values from Task 2:\n$$\nK = (1 \\cdot g(I_A)) + (2 \\cdot g(I_B)) + (3 \\cdot g(I_{\\text{Core}})) + (4 \\cdot g(I_{\\text{DMZ}})) + (5 \\cdot g(I_C)) + (6 \\cdot g(I_{\\text{WAN}}))\n$$\n$$\nK = (1 \\cdot 2) + (2 \\cdot 3) + (3 \\cdot 11) + (4 \\cdot 7) + (5 \\cdot 5) + (6 \\cdot 13)\n$$\n$$\nK = 2 + 6 + 33 + 28 + 25 + 78\n$$\n$$\nK = 8 + 33 + 28 + 25 + 78\n$$\n$$\nK = 41 + 28 + 25 + 78\n$$\n$$\nK = 69 + 25 + 78\n$$\n$$\nK = 94 + 78\n$$\n$$\nK = 172\n$$\n\nThe final integer result is $172$.",
            "answer": "$$\\boxed{172}$$"
        },
        {
            "introduction": "For many CPS and Digital Twin applications, 'best-effort' delivery is not enough; performance guarantees for latency and jitter are critical. This final exercise  explores Time-Sensitive Networking (TSN), a key technology for achieving deterministic communication over Ethernet. By comparing a strictly layered architecture with an optimized cross-layer design, you will quantify the significant latency improvements achievable by sharing timing intent between layers, illustrating a powerful principle in engineering high-performance networked systems.",
            "id": "4209727",
            "problem": "A cyber-physical production cell is mirrored by a Digital Twin (DT) service that emits a periodic state-update flow with an end-to-end deadline $D=10$ ms and a source release jitter bound $J=2$ ms. The DT packets traverse two Ethernet switches configured for Time-Sensitive Networking (TSN), specifically the Time-Aware Shaper (TAS), which offers a deterministic periodic transmission opportunity for the update traffic class. Each switch repeats a cycle of duration $T$ during which a gate for the update class is open for a window of width $w$ and closed otherwise. The two switches have independently configured gate schedules (identical period $T$ and window width $w$, but arbitrary phase offsets). The link rate is $R=100$ Mbps on both hops, the payload length is $L=800$ bytes, and the propagation delay per hop is $0.5$ ms.\n\nTwo designs are considered:\n- Strictly layered design: the application, transport, and link/MAC layers each schedule independently at their own layer, without sharing timing intent. Packets are launched at the first-hop TAS as soon as the first-hop gate next opens; their arrival at the second hop is not coordinated with the second hop’s TAS window.\n- Cross-layer design with transmission scheduling hints: the application conveys deadline and timing intent down the stack so the first-hop transmission time is chosen to cause arrival at the second hop within its TAS open window, if feasible, thereby avoiding second-hop gate waiting.\n\nStarting from first principles of deterministic service, model end-to-end latency as the sum of serialization, propagation, processing, and queueing components, and reason about the maximum queueing delay introduced by periodic TAS service at each hop. Use the following base facts:\n- End-to-end latency is the time from packet release to its arrival at the destination.\n- For a server that offers service only in a periodic open window of width $w$ in a cycle of length $T$, the queueing delay experienced by an arrival is the time until the next open window; derive the maximum of this delay over all possible arrival phases in a cycle.\n- In the cross-layer design, assume feasibility of end-to-end alignment when $J \\leq w$ and the sum of serialization and one-hop propagation time is no greater than the second-hop window width. Use these conditions to justify whether second-hop gate waiting can be eliminated.\n\nLet the TAS parameters be $T=5$ ms and $w=2$ ms at both hops. Assume processing time at each device is negligible compared to TAS-induced waiting and can be ignored. Under these assumptions, quantify the latency improvement, defined as the difference in worst-case end-to-end latency between the strictly layered design and the cross-layer design with scheduling hints. Express your final answer in ms and round to four significant figures.",
            "solution": "The problem is first validated to be scientifically grounded, well-posed, objective, and complete. All necessary parameters are provided, and the scenario is a standard, albeit simplified, model used in the analysis of real-time networks, specifically Time-Sensitive Networking (TSN). The principles involved (serialization, propagation, queueing delay) are fundamental to network performance analysis. The problem is therefore deemed valid and a solution can be formulated.\n\nThe core of the problem is to calculate and compare the worst-case end-to-end latency for a data flow under two different networking architectures: a strictly layered design and a cross-layer optimized design.\n\nFirst, we define and quantify the basic components of latency as per the problem description. The total end-to-end latency is the sum of serialization delays, propagation delays, and queueing delays. Processing time is stated to be negligible.\n\nThe packet payload length is given as $L=800$ bytes. We assume this represents the entire Layer-$2$ frame size for a simplified analysis, as TAS operates at the MAC layer (Layer-$2$). The size in bits is $S = L \\times 8 = 800 \\times 8 = 6400$ bits.\nThe link rate is $R = 100$ Mbps, which is $100 \\times 10^6$ bits per second.\nThe serialization delay, $\\tau_{ser}$, is the time to transmit the packet onto a link:\n$$ \\tau_{ser} = \\frac{S}{R} = \\frac{6400 \\text{ bits}}{100 \\times 10^6 \\text{ bits/s}} = 64 \\times 10^{-6} \\text{ s} = 0.064 \\text{ ms} $$\n\nThe propagation delay per hop, $\\tau_{prop}$, is given as $0.5$ ms.\n\nThe path traverses two Ethernet switches, which we denote as SW1 and SW2. A standard model for such a path is Source $\\rightarrow$ SW1 $\\rightarrow$ SW2 $\\rightarrow$ Destination. This path involves two hops where TSN shaping is applied: the egress links of SW1 and SW2. The total latency is the sum of delays across these two hops, starting from the packet's release from the source until its arrival at the destination. We model the end-to-end latency as the sum of delays incurred at each of the two hops. A hop's latency consists of queueing at the switch, serialization at the switch's egress port, and propagation over the link.\n\nThe queueing delay is induced by the Time-Aware Shaper (TAS). As requested, we derive the maximum queueing delay from first principles. A TAS gate for a specific traffic class is open for a duration $w$ within a recurring cycle of period $T$. A packet arriving at the switch can only be transmitted during this open-gate interval. The worst-case scenario for queueing delay occurs when a packet arrives just after the gate has closed. Let the gate be open in the interval $[t_0, t_0+w]$ of a cycle. If a packet arrives at an instant $\\epsilon$ after $t_0+w$, it must wait for the gate to open in the next cycle. The next open interval starts at time $t_0+T$. The waiting time is $(t_0+T) - (t_0+w+\\epsilon) = T-w-\\epsilon$. In the limit as $\\epsilon \\to 0$, the maximum queueing delay, $d_{Q,max}$, is:\n$$ d_{Q,max} = T - w $$\nGiven $T=5$ ms and $w=2$ ms, the maximum queueing delay at a single hop is:\n$$ d_{Q,max} = 5 \\text{ ms} - 2 \\text{ ms} = 3 \\text{ ms} $$\n\nNow, we analyze the worst-case end-to-end latency for the two designs. The end-to-end latency, $W$, is defined as the time from packet release to its arrival at the destination. We model this as the sum of delays over the two hops:\n$W = (\\text{delay at hop 1}) + (\\text{delay at hop 2})$.\nLet's assume the path is Source $\\rightarrow$ SW1 $\\rightarrow$ SW2, and the destination is the egress of SW2. The latency is measured from the packet's availability at SW1's ingress queue (after accounting for release jitter) to its arrival at SW2's egress port. A more comprehensive model for a S$\\rightarrow$S1$\\rightarrow$S2$\\rightarrow$D path is $W = d_{Q1} + \\tau_{ser} + \\tau_{prop} + d_{Q2} + \\tau_{ser} + \\tau_{prop}$. This represents the time from availability at SW1's queue to final arrival at the destination.\n\nCase 1: Strictly Layered Design\nIn this design, there is no coordination between layers or nodes. The packet release from the source is subject to a jitter $J=2$ ms. This jitter, combined with the independent and arbitrary phase offsets of the TAS schedules on SW1 and SW2, means that the arrival of a packet at each switch's queue is uncoordinated with that switch's gate schedule. To calculate the worst-case end-to-end latency, $W_{SL}$, we must assume the worst-case queueing delay occurs at each switch.\n$$ W_{SL} = d_{Q1,max} + \\tau_{ser} + \\tau_{prop} + d_{Q2,max} + \\tau_{ser} + \\tau_{prop} $$\n$$ W_{SL} = 2 \\cdot d_{Q,max} + 2 \\cdot \\tau_{ser} + 2 \\cdot \\tau_{prop} $$\n$$ W_{SL} = 2(T-w) + 2\\tau_{ser} + 2\\tau_{prop} $$\n\nCase 2: Cross-Layer Design with Transmission Scheduling Hints\nIn this design, the application layer provides timing information to the lower layers to intelligently schedule the transmission at SW1. The goal is to time the departure from SW1 so that the packet arrives at SW2 during SW2's open gate window, thus eliminating the queueing delay at the second hop, $d_{Q2}$.\nThe problem provides two conditions for this to be feasible:\n1. $J \\leq w$\n2. $\\tau_{ser} + \\tau_{prop} \\leq w$\n\nLet's verify these conditions with the given parameters:\n1. $J=2$ ms, $w=2$ ms. The condition $2 \\leq 2$ is met.\n2. $\\tau_{ser}=0.064$ ms, $\\tau_{prop}=0.5$ ms. The condition $0.064 + 0.5 \\leq 2$, or $0.564 \\leq 2$, is also met.\nSince both feasibility conditions are satisfied, we can assume that the cross-layer scheduling is effective and \"second-hop gate waiting can be eliminated\". This means the worst-case queueing delay at SW2 is zero: $d_{Q2,max} = 0$.\nHowever, the arrival of the packet at the first switch, SW1, is still subject to the source release jitter and is uncoordinated with SW1's gate schedule. Therefore, we must still consider the worst-case queueing delay at the first hop.\nThe worst-case end-to-end latency for the cross-layer design, $W_{CL}$, is:\n$$ W_{CL} = d_{Q1,max} + \\tau_{ser} + \\tau_{prop} + d_{Q2,max} + \\tau_{ser} + \\tau_{prop} $$\n$$ W_{CL} = (T-w) + 2\\tau_{ser} + 2\\tau_{prop} $$\n\nLatency Improvement\nThe latency improvement, $\\Delta W$, is the difference in worst-case latency between the two designs.\n$$ \\Delta W = W_{SL} - W_{CL} $$\n$$ \\Delta W = (2(T-w) + 2\\tau_{ser} + 2\\tau_{prop}) - ((T-w) + 2\\tau_{ser} + 2\\tau_{prop}) $$\n$$ \\Delta W = (T-w) $$\n\nThe improvement is precisely the maximum queueing delay of one hop, which is eliminated at the second switch by the cross-layer coordination.\n\nFinally, we substitute the numerical values:\n$$ \\Delta W = T - w = 5 \\text{ ms} - 2 \\text{ ms} = 3 \\text{ ms} $$\nThe problem asks for the answer to be rounded to four significant figures. As the result is an integer, we express it as $3.000$.\n\nLet's compute the full latencies for completeness:\n$W_{SL} = 2(3 \\text{ ms}) + 2(0.064 \\text{ ms}) + 2(0.5 \\text{ ms}) = 6 + 0.128 + 1.0 = 7.128$ ms.\n$W_{CL} = 1(3 \\text{ ms}) + 2(0.064 \\text{ ms}) + 2(0.5 \\text{ ms}) = 3 + 0.128 + 1.0 = 4.128$ ms.\n$\\Delta W = 7.128 \\text{ ms} - 4.128 \\text{ ms} = 3.000$ ms.\nThe result is confirmed.",
            "answer": "$$\\boxed{3.000}$$"
        }
    ]
}