{
    "hands_on_practices": [
        {
            "introduction": "Before we can trust a numerical model to simulate complex physics, we must first verify that its fundamental building blocks are sound. This practice guides you through a crucial verification test: confirming that the discrete divergence operator correctly preserves a constant, divergence-free field, a property rooted in the geometric conservation law. By implementing this test for both structured and unstructured grids , you will build confidence in the geometric integrity of the finite volume discretization, a foundational step in model development.",
            "id": "3918705",
            "problem": "You are tasked with designing and implementing a verification test, rooted in first principles, to confirm the exact preservation of a constant divergence-free velocity field under a discrete divergence operator on both structured and unstructured grids commonly used in environmental and earth system modeling. The design must start from the Divergence Theorem and proceed to a discrete, control-volume-based divergence consistent with the Finite Volume Method (FVM). Your program must compute residuals that quantify deviations from zero divergence and aggregate these residuals for several test cases.\n\nFundamental base:\n- The Divergence Theorem (Gauss's theorem) states that for a sufficiently smooth vector field $\\mathbf{u}(\\mathbf{x})$ and a closed control volume $V$ with boundary $\\partial V$ and outward unit normal $\\mathbf{n}$,\n$$\n\\int_V \\nabla \\cdot \\mathbf{u} \\, dV = \\int_{\\partial V} \\mathbf{u} \\cdot \\mathbf{n} \\, dS.\n$$\n- The Finite Volume Method (FVM) discretizes the divergence by approximating the boundary integral as a sum of face fluxes. For a single control volume (cell) $c$ of volume $|V_c|$ with faces indexed by $f$ and areas $|S_f|$, the discrete divergence is derived from the flux balance:\n$$\n\\left(\\nabla \\cdot \\mathbf{u}\\right)_c \\approx \\frac{1}{|V_c|} \\sum_{f \\in \\partial c} \\left( \\mathbf{u}_f \\cdot \\mathbf{n}_f \\right) |S_f|.\n$$\n- A constant velocity field $\\mathbf{u}(\\mathbf{x}) = \\mathbf{u}_0$ has $\\nabla \\cdot \\mathbf{u} = 0$ in the continuous setting, and the exact flux over any closed surface must be zero because the sum of outward area vectors over a closed surface (or the sum of outward normal-length vectors over a closed polygon in two dimensions) vanishes.\n\nYour tasks:\n1. For a structured Cartesian grid in two dimensions, define cells of width $dx$ and height $dy$, with faces aligned to the coordinate axes. Use the FVM control-volume flux balance with the exact geometry of faces to compute the discrete divergence at every cell for a constant velocity $\\mathbf{u}_0 = (u_x, u_y)$, using the outward normal directions on each face. Compute the residual defined as the maximum absolute value of the discrete divergence over all cells. Divergence has units of $\\mathrm{s}^{-1}$ when velocity is in $\\mathrm{m/s}$ and lengths are in $\\mathrm{m}$. Report residuals in $\\mathrm{s}^{-1}$.\n2. For an unstructured polygonal grid in two dimensions, define each cell as a simple polygon by its vertices $(x_i, y_i)$ in $\\mathrm{m}$, ordered to form a closed loop (your program must ensure counterclockwise ordering if needed). Compute the polygon area $|V_c|$ using the shoelace formula and the outward unit normals $\\mathbf{n}_f$ along each edge by rotating the edge vectors by $-90^\\circ$ to obtain outward normals for counterclockwise orientation. Use the FVM flux balance to compute the discrete divergence for a constant velocity $\\mathbf{u}_0 = (u_x, u_y)$ and the corresponding residual as in the structured case. Report residuals in $\\mathrm{s}^{-1}$.\n\nConstraints and expectations:\n- Use only exact geometric quantities for faces and cell volumes; do not introduce numerical quadrature for the flux on faces since $\\mathbf{u}$ is constant.\n- The calculation must be local per cell and must not rely on boundary conditions or ghost cells, as the flux balance is computed on closed control volumes.\n- Residuals should be extremely close to zero, with any nonzero value attributable only to floating-point rounding.\n\nTest suite:\nProvide and compute residuals for the following five test cases. All distances are in $\\mathrm{m}$, velocities in $\\mathrm{m/s}$, and report residuals in $\\mathrm{s}^{-1}$.\n\n- Test case $1$ (structured, general case):\n  - Grid: $N_x = 10$, $N_y = 8$, $dx = 3700$, $dy = 2100$.\n  - Constant velocity: $\\mathbf{u}_0 = (3.2, -5.4)$.\n- Test case $2$ (structured, boundary-sized single cell):\n  - Grid: $N_x = 1$, $N_y = 1$, $dx = 0.001$, $dy = 0.001$.\n  - Constant velocity: $\\mathbf{u}_0 = (123.456, -654.321)$.\n- Test case $3$ (structured, anisotropic cell size with irrational-like components):\n  - Grid: $N_x = 45$, $N_y = 60$, $dx = 1.0$, $dy = 1000.0$.\n  - Constant velocity: $\\mathbf{u}_0 = (1.41421356237, 3.14159265359)$.\n- Test case $4$ (unstructured, triangles):\n  - Polygons (each cell is a triangle with counterclockwise vertices specified in $\\mathrm{m}$):\n    - Triangle $1$: $(0, 0)$, $(2, 0)$, $(0, 1)$.\n    - Triangle $2$: $(1, 1)$, $(3, 1)$, $(2, 3)$.\n    - Triangle $3$: $(5, 0)$, $(6, 2)$, $(4, 2)$.\n  - Constant velocity: $\\mathbf{u}_0 = (1.41421356237, 3.14159265359)$.\n- Test case $5$ (unstructured, highly skewed quadrilaterals to probe numerical robustness):\n  - Polygons (each cell is a quadrilateral with vertices in $\\mathrm{m}$):\n    - Quadrilateral $1$: $(0, 0)$, $(10, 0.1)$, $(10.2, 50)$, $(0, 49.9)$.\n    - Quadrilateral $2$: $(20, 0)$, $(30, 0.05)$, $(30.05, 100)$, $(20, 99.95)$.\n  - Constant velocity: $\\mathbf{u}_0 = (3.2, -5.4)$.\n\nFinal output format:\nYour program should produce a single line of output containing the residuals for the five test cases, in order, as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4,r_5]$, where each $r_i$ is a floating-point number in $\\mathrm{s}^{-1}$ representing the maximum absolute discrete divergence over all cells in that test case. No additional text should be printed.",
            "solution": "The problem is valid. It presents a well-posed, scientifically grounded verification exercise from the field of computational fluid dynamics, specifically concerning the properties of discrete operators on structured and unstructured grids. All necessary data and definitions are provided, and the problem is internally consistent.\n\nThe core of this problem lies in verifying a fundamental property of a Finite Volume Method (FVM) discretization: the exact preservation of a constant, divergence-free velocity field. This is a crucial test for any numerical scheme intended for conservation laws, as it demonstrates that the discrete operator correctly mimics the properties of its continuous counterpart in the simplest non-trivial case.\n\nThe governing principle is the Divergence Theorem, which relates the volume integral of the divergence of a vector field $\\mathbf{u}$ to the flux of that field through the volume's closed boundary $\\partial V$:\n$$\n\\int_V \\nabla \\cdot \\mathbf{u} \\, dV = \\oint_{\\partial V} \\mathbf{u} \\cdot \\mathbf{n} \\, dS\n$$\nHere, $\\mathbf{n}$ is the outward unit normal to the boundary surface element $dS$.\n\nIn the FVM, we consider a single control volume (a cell $c$) and approximate the average divergence over that cell. The integral form is divided by the cell volume $|V_c|$:\n$$\n\\frac{1}{|V_c|} \\int_{V_c} \\nabla \\cdot \\mathbf{u} \\, dV = \\frac{1}{|V_c|} \\oint_{\\partial V_c} \\mathbf{u} \\cdot \\mathbf{n} \\, dS\n$$\nThe left side represents the cell-averaged divergence, $(\\nabla \\cdot \\mathbf{u})_c$. The right side's integral is discretized as a sum of fluxes over the faces $f$ of the cell:\n$$\n(\\nabla \\cdot \\mathbf{u})_c \\approx \\frac{1}{|V_c|} \\sum_{f \\in \\partial c} \\left( \\mathbf{u}_f \\cdot \\mathbf{n}_f \\right) |S_f|\n$$\nwhere $\\mathbf{u}_f$ is the velocity at the face, $\\mathbf{n}_f$ is the outward unit normal to the face, and $|S_f|$ is the face area (or length in 2D).\n\nThe problem specifies a constant velocity field, $\\mathbf{u}(\\mathbf{x}) = \\mathbf{u}_0$. For such a field, the continuous divergence is identically zero: $\\nabla \\cdot \\mathbf{u}_0 = 0$. Since the velocity is constant, the velocity at any face $\\mathbf{u}_f$ is simply $\\mathbf{u}_0$. The discrete divergence formula becomes:\n$$\n(\\nabla \\cdot \\mathbf{u})_c \\approx \\frac{1}{|V_c|} \\sum_{f \\in \\partial c} \\left( \\mathbf{u}_0 \\cdot \\mathbf{n}_f \\right) |S_f| = \\frac{1}{|V_c|} \\mathbf{u}_0 \\cdot \\left( \\sum_{f \\in \\partial c} \\mathbf{n}_f |S_f| \\right)\n$$\nThis equation reveals that the discrete divergence of a constant field is zero if and only if the sum of the outward normal vectors scaled by their face areas is the zero vector. This is a purely geometric property known as the geometric conservation law: for any closed volume, the sum of its outward-pointing face-normal-area vectors must be zero. A valid FVM discretization must satisfy this condition exactly.\n$$\n\\sum_{f \\in \\partial c} \\mathbf{n}_f |S_f| = \\mathbf{0}\n$$\nOur task is to verify this property numerically for both structured and unstructured grids. The computed residual will be the maximum absolute value of the discrete divergence over all cells, which should ideally be zero, with any non-zero value being attributable to floating-point arithmetic error.\n\n**1. Structured Cartesian Grid (2D)**\n\nFor a 2D structured grid, a cell is a rectangle of width $dx$ and height $dy$. Its area is $|V_c| = dx \\cdot dy$. The cell has four faces (East, North, West, South). We define the outward normal-length vectors, which are the product $\\mathbf{n}_f |S_f|$:\n- East face: normal $\\mathbf{n}_e=(1, 0)$, length $|S_e|=dy$. Vector: $(dy, 0)$.\n- North face: normal $\\mathbf{n}_n=(0, 1)$, length $|S_n|=dx$. Vector: $(0, dx)$.\n- West face: normal $\\mathbf{n}_w=(-1, 0)$, length $|S_w|=dy$. Vector: $(-dy, 0)$.\n- South face: normal $\\mathbf{n}_s=(0, -1)$, length $|S_s|=dx$. Vector: $(0, -dx)$.\n\nThe sum of these vectors is:\n$$\n\\sum_{f \\in \\partial c} \\mathbf{n}_f |S_f| = (dy, 0) + (0, dx) + (-dy, 0) + (0, -dx) = (dy - dy, dx - dx) = (0, 0)\n$$\nThe geometric conservation law is satisfied. The total flux is calculated by summing the dot products of the constant velocity $\\mathbf{u}_0 = (u_x, u_y)$ with each normal-length vector:\n$$\n\\text{Flux}_{total} = u_x \\cdot dy + u_y \\cdot dx + u_x \\cdot (-dy) + u_y \\cdot (-dx) = (u_x dy - u_x dy) + (u_y dx - u_y dx) = 0\n$$\nThe discrete divergence is $\\frac{\\text{Flux}_{total}}{|V_c|} = \\frac{0}{dx \\cdot dy} = 0$. This holds for every cell in the grid.\n\n**2. Unstructured Polygonal Grid (2D)**\n\nFor a 2D unstructured grid, a cell is a simple polygon defined by a sequence of $N$ vertices $(x_i, y_i)$ for $i=0, \\dots, N-1$, ordered counter-clockwise (CCW).\nThe cell area $|V_c|$ is calculated using the shoelace formula:\n$$\n|V_c| = \\frac{1}{2} \\sum_{i=0}^{N-1} (x_i y_{i+1} - x_{i+1} y_i)\n$$\nwhere the vertex index $N$ is equivalent to $0$. A positive result confirms CCW ordering.\n\nA face $f_i$ is the edge connecting vertex $i$ to vertex $i+1$. The edge vector is $\\Delta\\mathbf{s}_i = (x_{i+1} - x_i, y_{i+1} - y_i) = (\\Delta x_i, \\Delta y_i)$. For a CCW-ordered polygon, the outward normal-length vector is obtained by rotating the edge vector by $-90^\\circ$:\n$$\n\\mathbf{n}_{f_i} |S_{f_i}| = (\\Delta y_i, -\\Delta x_i)\n$$\nThe sum of these vectors over all faces of the closed polygon is:\n$$\n\\sum_{i=0}^{N-1} (\\Delta y_i, -\\Delta x_i) = \\left( \\sum_{i=0}^{N-1} (y_{i+1} - y_i), -\\sum_{i=0}^{N-1} (x_{i+1} - x_i) \\right)\n$$\nThese are telescoping sums. For a closed polygon where $(x_N, y_N) = (x_0, y_0)$:\n$$\n\\sum_{i=0}^{N-1} (y_{i+1} - y_i) = y_N - y_0 = 0 \\quad \\text{and} \\quad \\sum_{i=0}^{N-1} (x_{i+1} - x_i) = x_N - x_0 = 0\n$$\nThe sum of the normal-length vectors is therefore $(0, 0)$, again satisfying the geometric conservation law. The total flux is calculated by summing the dot products $\\mathbf{u}_0 \\cdot (\\mathbf{n}_{f_i} |S_{f_i}|)$:\n$$\n\\text{Flux}_{total} = \\sum_{i=0}^{N-1} \\mathbf{u}_0 \\cdot (\\Delta y_i, -\\Delta x_i) = \\sum_{i=0}^{N-1} (u_x \\Delta y_i - u_y \\Delta x_i) = u_x \\sum \\Delta y_i - u_y \\sum \\Delta x_i = u_x \\cdot 0 - u_y \\cdot 0 = 0\n$$\nThe discrete divergence for each polygonal cell is $\\frac{\\text{Flux}_{total}}{|V_c|} = 0$. The implementation will calculate this for each specified cell and report the maximum absolute value as the residual.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_structured_residual(dx, dy, u0):\n    \"\"\"\n    Computes the discrete divergence for a single cell in a structured grid.\n    For a constant velocity field on a uniform Cartesian grid, the result\n    is identical for all cells.\n    \n    Args:\n        dx (float): Cell width in meters.\n        dy (float): Cell height in meters.\n        u0 (tuple): Constant velocity vector (ux, uy) in m/s.\n        \n    Returns:\n        float: The absolute value of the discrete divergence in s^-1.\n    \"\"\"\n    ux, uy = u0\n    \n    # Cell area (which is the 2D volume)\n    cell_area = dx * dy\n    if cell_area == 0:\n        return 0.0\n\n    # Fluxes across a cell's four faces (East, North, West, South).\n    # The flux for a face f is (u0 . n_f) * |S_f|, where n_f is the outward\n    # unit normal and |S_f| is the face length. This is equivalent to\n    # u0 . (n_f * |S_f|), where (n_f * |S_f|) is the normal-length vector.\n    # East face: normal-length vector is (dy, 0)\n    # North face: normal-length vector is (0, dx)\n    # West face: normal-length vector is (-dy, 0)\n    # South face: normal-length vector is (0, -dx)\n    \n    flux_east = ux * dy\n    flux_north = uy * dx\n    flux_west = -ux * dy\n    flux_south = -uy * dx\n    \n    # Summing the fluxes. Grouping identical terms to improve numerical stability.\n    total_flux = (flux_east + flux_west) + (flux_north + flux_south)\n    \n    divergence = total_flux / cell_area\n    \n    return abs(divergence)\n\ndef calculate_unstructured_residual(polygons, u0):\n    \"\"\"\n    Computes the maximum absolute discrete divergence over a set of \n    unstructured polygonal cells.\n    \n    Args:\n        polygons (list): A list of numpy arrays, where each array contains the\n                         (x, y) vertices of a cell in meters.\n        u0 (tuple): Constant velocity vector (ux, uy) in m/s.\n        \n    Returns:\n        float: The maximum absolute discrete divergence over all cells in s^-1.\n    \"\"\"\n    ux, uy = u0\n    all_divergences = []\n    \n    for poly_verts in polygons:\n        # Ensure vertices are in counter-clockwise (CCW) order by checking\n        # the sign of the shoelace formula for area.\n        num_verts = len(poly_verts)\n        signed_area = 0.5 * sum(\n            poly_verts[i, 0] * poly_verts[(i + 1) % num_verts, 1] -\n            poly_verts[(i + 1) % num_verts, 0] * poly_verts[i, 1]\n            for i in range(num_verts)\n        )\n        \n        if signed_area < 0:\n            # Reverse vertices if clockwise (CW)\n            poly_verts = np.flip(poly_verts, axis=0)\n            cell_area = -signed_area\n        else:\n            cell_area = signed_area\n\n        if cell_area == 0:\n            all_divergences.append(0.0)\n            continue\n            \n        total_flux = 0.0\n        # Loop over polygon edges (faces) to compute total flux\n        for i in range(num_verts):\n            p1 = poly_verts[i]\n            p2 = poly_verts[(i + 1) % num_verts]\n            \n            # Edge vector (dx, dy)\n            dx = p2[0] - p1[0]\n            dy = p2[1] - p1[1]\n\n            # Outward normal-length vector (dy, -dx) for CCW.\n            # Flux for this edge is u0 . (normal-length vector)\n            flux = ux * dy - uy * dx\n            total_flux += flux\n            \n        divergence = total_flux / cell_area\n        all_divergences.append(divergence)\n        \n    if not all_divergences:\n        return 0.0\n        \n    return np.max(np.abs(all_divergences))\n\ndef solve():\n    \"\"\"\n    Runs the verification tests for both structured and unstructured grids\n    and prints the residuals in the specified format.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (structured)\n        {'type': 'structured', 'params': {'dx': 3700.0, 'dy': 2100.0, 'u0': (3.2, -5.4)}},\n        # Test case 2 (structured)\n        {'type': 'structured', 'params': {'dx': 0.001, 'dy': 0.001, 'u0': (123.456, -654.321)}},\n        # Test case 3 (structured)\n        {'type': 'structured', 'params': {'dx': 1.0, 'dy': 1000.0, 'u0': (1.41421356237, 3.14159265359)}},\n        # Test case 4 (unstructured)\n        {'type': 'unstructured', 'params': {\n            'polygons': [\n                np.array([(0., 0.), (2., 0.), (0., 1.)]),\n                np.array([(1., 1.), (3., 1.), (2., 3.)]),\n                np.array([(5., 0.), (6., 2.), (4., 2.)])\n            ],\n            'u0': (1.41421356237, 3.14159265359)\n        }},\n        # Test case 5 (unstructured)\n        {'type': 'unstructured', 'params': {\n            'polygons': [\n                np.array([(0., 0.), (10., 0.1), (10.2, 50.), (0., 49.9)]),\n                np.array([(20., 0.), (30., 0.05), (30.05, 100.), (20., 99.95)])\n            ],\n            'u0': (3.2, -5.4)\n        }}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'structured':\n            residual = calculate_structured_residual(**case['params'])\n            results.append(residual)\n        elif case['type'] == 'unstructured':\n            residual = calculate_unstructured_residual(**case['params'])\n            results.append(residual)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With the geometric foundations verified, we now turn to performance and accuracy. The choice of grid profoundly impacts the solution of a dynamic simulation, and this practice allows you to quantify that impact directly. You will solve the canonical linear advection equation on both uniform structured and non-uniform unstructured grids, computing a suite of standard error norms like the $L^1$, $L^2$, and $L^{\\infty}$ metrics . This exercise provides direct, hands-on experience with how grid structure influences numerical error in a transport scheme.",
            "id": "3918663",
            "problem": "Consider the one-dimensional linear advection Partial Differential Equation (PDE) $u_t + a u_x = 0$ on the periodic domain $x \\in [0,1)$, where $a \\in \\mathbb{R}$ is a constant advection velocity. Let the initial condition be $u(x,0) = u_0(x)$ with\n$$\nu_0(x) = \\sin(2\\pi x) + 0.25 \\exp\\left(-100 (x-0.5)^2 \\right).\n$$\nThe analytical solution at time $t$ is $u(x,t) = u_0\\big((x - a t) \\bmod 1\\big)$.\n\nYou will assess grid-dependent performance by computing verification metrics on two mesh types:\n- Structured grid: $N$ uniform control volumes with edges at $x_j = j/N$ for $j=0,\\dots,N$.\n- Unstructured grid: $N$ nonuniform control volumes with lengths $\\Delta x_i$ constructed from positive weights $w_i = 1 + \\eta \\xi_i$, where $\\xi_i \\sim \\mathcal{U}[-1,1]$ are independent and identically distributed random variables generated with a specified pseudorandom seed. The cell lengths are $\\Delta x_i = w_i / \\sum_{k=1}^{N} w_k$, and the periodic edges are $x_0 = 0$, $x_i = \\sum_{k=1}^{i} \\Delta x_k$ for $i=1,\\dots,N$, with $x_N = 1$.\n\nDiscretize the PDE using a first-order, finite-volume upwind method on each mesh. Denote cell averages by $U_i^n \\approx \\frac{1}{\\Delta x_i} \\int_{x_{i-1}}^{x_i} u(x,t^n)\\,dx$. For one explicit time step from $t^n$ to $t^{n+1} = t^n + \\Delta t$, the finite-volume update is\n$$\nU_i^{n+1} = U_i^n - \\frac{\\Delta t}{\\Delta x_i} \\left( F_{i+1/2} - F_{i-1/2} \\right),\n$$\nwith numerical flux at face $i+1/2$ given by the upwind choice for constant velocity $a$:\n$$\nF_{i+1/2} =\n\\begin{cases}\na \\, U_i^n, & a \\ge 0, \\\\\na \\, U_{i+1}^n, & a < 0,\n\\end{cases}\n$$\non a periodic mesh with indices taken modulo $N$. Choose the time step $\\Delta t$ by the Courant number $C \\in (0,1]$ as\n$$\n\\Delta t = C \\, \\frac{\\min_i \\Delta x_i}{|a|},\n$$\nfor $a \\ne 0$.\n\nTo compare the discrete solution after one upwind time step to the advected analytic field, use cell averages computed by high-order quadrature. Specifically, for a cell interval $[x_{i-1}, x_i]$ of length $\\Delta x_i$, approximate the cell average of a function $f(x)$ by an at-least eight-point Gauss–Legendre rule:\n$$\n\\frac{1}{\\Delta x_i} \\int_{x_{i-1}}^{x_i} f(x) \\, dx \\approx \\frac{1}{2} \\sum_{q=1}^{m} w_q \\, f\\!\\left( \\frac{x_i - x_{i-1}}{2} \\, \\xi_q + \\frac{x_i + x_{i-1}}{2} \\right),\n$$\nwhere $m \\ge 8$, and $\\{(\\xi_q, w_q)\\}_{q=1}^{m}$ are the Gauss–Legendre nodes and weights on $[-1,1]$. Use this rule both for the initial cell averages $U_i^0$ of $u_0(x)$, and for the exact cell averages at time $\\Delta t$ of the advected field $u_0\\big((x - a \\Delta t) \\bmod 1\\big)$.\n\nFor each mesh, after one time step, define the discrete error $e_i = U_i^{1} - \\bar{u}_i^{\\mathrm{exact}}$, where $\\bar{u}_i^{\\mathrm{exact}}$ is the quadrature-approximated exact cell average at time $\\Delta t$. Compute the following verification metrics:\n- The $L^1$ norm,\n$$\n\\|e\\|_{L^1} \\approx \\sum_{i=1}^{N} |e_i| \\, \\Delta x_i.\n$$\n- The $L^2$ norm,\n$$\n\\|e\\|_{L^2} \\approx \\left( \\sum_{i=1}^{N} e_i^2 \\, \\Delta x_i \\right)^{1/2}.\n$$\n- The $L^{\\infty}$ norm,\n$$\n\\|e\\|_{L^{\\infty}} = \\max_{1 \\le i \\le N} |e_i|.\n$$\n- The energy norm induced by the lumped mass matrix (cell volumes),\n$$\n\\|e\\|_{E} = \\left( e^{\\top} M e \\right)^{1/2}, \\quad M = \\mathrm{diag}(\\Delta x_1,\\dots,\\Delta x_N).\n$$\n\nImplement the above for both the structured and unstructured grids in each test case below, using $m = 8$ Gauss–Legendre points for quadrature. For the unstructured grid, generate $\\xi_i$ by the specified pseudorandom seed, and use $\\eta$ as the irregularity amplitude.\n\nTest suite (each parameter tuple is $(N, a, C, \\eta, \\text{seed})$):\n1. $(100, 1.0, 0.5, 0.3, 42)$\n2. $(20, 1.0, 0.9, 0.5, 123)$\n3. $(8, -1.0, 0.4, 0.8, 7)$\n\nYour program must:\n- Construct the structured and unstructured meshes for each test case as defined.\n- Compute one upwind finite-volume time step from $t=0$ to $t=\\Delta t$ on each mesh.\n- Compute the four error metrics on each mesh using the quadrature-defined cell averages.\n- For each test case, output a list of eight floats in the order\n$$\n[\\|e\\|_{L^1}^{\\mathrm{struct}}, \\|e\\|_{L^2}^{\\mathrm{struct}}, \\|e\\|_{L^{\\infty}}^{\\mathrm{struct}}, \\|e\\|_{E}^{\\mathrm{struct}}, \\|e\\|_{L^1}^{\\mathrm{unstruct}}, \\|e\\|_{L^2}^{\\mathrm{unstruct}}, \\|e\\|_{L^{\\infty}}^{\\mathrm{unstruct}}, \\|e\\|_{E}^{\\mathrm{unstruct}} ].\n$$\n- Aggregate the results for all test cases into a single outer list.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated Python-style list of lists, with each floating-point number rounded to eight decimal places, and no additional text. For example: \"[[0.12345678,0.23456789,0.34567890,0.45678901,0.11111111,0.22222222,0.33333333,0.44444444],[...],[...]]\". Angles and physical units are not required for this problem; all quantities are dimensionless. The output must be exactly one line, with no trailing or leading spaces, and no units.",
            "solution": "The user-provided problem is a well-defined task in the field of numerical analysis for partial differential equations (PDEs). I will first verify its validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n\n- **PDE**: One-dimensional linear advection equation, $u_t + a u_x = 0$, on a periodic domain $x \\in [0,1)$, where $a \\in \\mathbb{R}$ is a constant velocity.\n- **Initial Condition**: $u(x,0) = u_0(x) = \\sin(2\\pi x) + 0.25 \\exp\\left(-100 (x-0.5)^2 \\right)$.\n- **Analytical Solution**: $u(x,t) = u_0\\big((x - a t) \\bmod 1\\big)$.\n- **Grids**: Two types of grids with $N$ cells are defined:\n    1.  **Structured Grid**: Uniform cells with edges at $x_j = j/N$ for $j=0, \\dots, N$. Cell lengths are $\\Delta x_j = 1/N$.\n    2.  **Unstructured Grid**: Nonuniform cells. Generated from weights $w_i = 1 + \\eta \\xi_i$ where $\\xi_i$ are i.i.d. samples from $\\mathcal{U}[-1,1]$ using a given seed. Cell lengths are $\\Delta x_i = w_i / \\sum_{k=1}^{N} w_k$. Edges are $x_0 = 0$, $x_i = \\sum_{k=1}^{i} \\Delta x_k$.\n- **Numerical Discretization**: First-order finite-volume upwind method.\n    - **Update Rule**: $U_i^{n+1} = U_i^n - \\frac{\\Delta t}{\\Delta x_i} \\left( F_{i+1/2} - F_{i-1/2} \\right)$.\n    - **Numerical Flux**: $F_{i+1/2} = a U_i^n$ if $a \\ge 0$, and $F_{i+1/2} = a U_{i+1}^n$ if $a < 0$. Indices are periodic (modulo $N$).\n- **Time Step**: $\\Delta t = C \\frac{\\min_i \\Delta x_i}{|a|}$ for a Courant number $C \\in (0,1]$.\n- **Cell Averages**: Cell averages of any function $f(x)$ on $[x_{i-1}, x_i]$ are to be approximated via an $m$-point Gauss-Legendre quadrature rule with $m \\ge 8$. The formula is given as $\\frac{1}{2} \\sum_{q=1}^{m} w_q f(\\dots)$. This is to be used for the initial condition and the exact solution at time $\\Delta t$.\n- **Error Metrics**:\n    - $L^1$ norm: $\\|e\\|_{L^1} \\approx \\sum_{i=1}^{N} |e_i| \\, \\Delta x_i$.\n    - $L^2$ norm: $\\|e\\|_{L^2} \\approx \\left( \\sum_{i=1}^{N} e_i^2 \\, \\Delta x_i \\right)^{1/2}$.\n    - $L^{\\infty}$ norm: $\\|e\\|_{L^{\\infty}} = \\max_{1 \\le i \\le N} |e_i|$.\n    - Energy norm: $\\|e\\|_{E} = \\left( e^{\\top} M e \\right)^{1/2}$ with $M = \\mathrm{diag}(\\Delta x_1, \\dots, \\Delta x_N)$.\n- **Task**: For each test case, compute one time step and evaluate the four error metrics for both structured and unstructured grids.\n- **Test Suite**: $(N, a, C, \\eta, \\text{seed})$ tuples:\n    1.  $(100, 1.0, 0.5, 0.3, 42)$\n    2.  $(20, 1.0, 0.9, 0.5, 123)$\n    3.  $(8, -1.0, 0.4, 0.8, 7)$\n- **Output Format**: A list of lists, with each inner list containing eight floating-point numbers rounded to eight decimal places, corresponding to the four norms for the structured grid followed by the four for the unstructured grid.\n\n### Step 2: Validate Using Extracted Givens\n\n- **Scientifically Grounded**: The problem is based on the fundamental linear advection equation, a cornerstone of fluid dynamics and transport phenomena. The numerical method (first-order upwind), stability condition (CFL), grid generation procedures, and error analysis are all standard and correct concepts from numerical analysis. All premises are scientifically sound.\n- **Well-Posed**: The problem is well-posed. The PDE with a given smooth initial condition and periodic boundary conditions has a unique, stable analytical solution. The numerical problem is also well-posed; the discretization is standard, and the choice of time step ensures stability. The procedure is deterministic (given the seeds for the random number generator) and will produce a unique result.\n- **Objective**: The problem is stated in precise, objective mathematical language. All terms are defined, and the task is unambiguous.\n- **Completeness and Consistency**: All necessary parameters ($N, a, C, \\eta, \\text{seed}$), functions ($u_0(x)$), and procedures are provided for each test case. There are no contradictions. The definition of the energy norm, $\\|e\\|_{E} = (\\sum e_i^2 \\Delta x_i)^{1/2}$, is identical to the provided discrete $L^2$ norm. This is a redundancy, not a contradiction. It simply means the two computed values will be identical.\n- **Realism and Feasibility**: The problem is a standard academic exercise in numerical methods. All parameters are within reasonable ranges, and the computations are perfectly feasible.\n- **Structure and Triviality**: The problem is well-structured and non-trivial. It requires the correct implementation of grid generation, numerical integration, a PDE solver, and error analysis, testing the understanding of these interconnected concepts.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a clear, self-contained, and scientifically sound exercise in computational science. I will now proceed with the solution.\n\n### Solution Principles and Design\n\nThe solution will be implemented in Python, leveraging the `numpy` library for efficient array operations and `scipy` for specialized scientific functions. The implementation will follow a modular design, breaking down the problem into distinct, manageable components.\n\n1.  **Grid Generation**: Two functions will be created: one for the structured grid, which simply calculates a uniform spacing, and one for the unstructured grid, which uses a random number generator (seeded for reproducibility) to create non-uniform cell widths as specified.\n\n2.  **Function Definitions**: The initial condition $u_0(x)$ and the analytical solution $u(x,t)$ will be defined as Python functions that can operate on `numpy` arrays, allowing for vectorized evaluation.\n\n3.  **High-Order Quadrature**: A a core utility function will compute the cell average of a given function over a specified grid. This function will use the $8$-point Gauss-Legendre quadrature rule. The nodes and weights will be pre-computed using `scipy.special.roots_legendre`. The function will map these nodes to each cell interval and apply the quadrature formula to approximate the integral, then divide by the cell width to get the average.\n\n4.  **Numerical Time Step**: A function will implement a single time step of the first-order upwind finite-volume method. This implementation will be vectorized for efficiency. It will conditionally handle the flux calculation based on the sign of the advection velocity $a$. For $a \\ge 0$, the flux depends on the state in the current cell and the cell to the left (`i` and `i-1`); for $a < 0$, it depends on the current cell and the cell to the right (`i` and `i+1`). The periodic boundary conditions will be handled using `numpy.roll` to circulate the elements of the cell average array.\n\n5.  **Error Calculation**: A function will take a vector of cell-wise errors and the corresponding cell widths to compute the four required norms: $L^1$, $L^2$, $L^{\\infty}$, and the energy norm $E$. As established, the $L^2$ and $E$ norms are mathematically equivalent and will be computed using the same formula.\n\n6.  **Main Loop**: The main function will orchestrate the entire process. It will iterate through the provided test cases. For each case, it will:\n    a.  Execute the comparison for the structured grid: generate the grid, determine $\\Delta t$, compute the initial cell averages `U0_s`, perform the upwind step to get `U1_s`, compute the exact cell averages `U_exact_s` at $t=\\Delta t$, calculate the error `e_s = U1_s - U_exact_s`, and compute the four error metrics.\n    b.  Repeat the process for the unstructured grid, using its specific geometry and a consequently different $\\Delta t$.\n    c.  Collect the eight resulting error metrics in the specified order.\n\n7.  **Output Formatting**: Finally, the collected results from all test cases will be formatted into a single string—a list of lists of floating-point numbers, with each number rounded to eight decimal places—and printed to standard output.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\n# Use a constant for the number of Gauss points as specified.\nNUM_GAUSS_POINTS = 8\n\ndef u0(x: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the initial condition u(x,0). The function is vectorized.\n    \"\"\"\n    return np.sin(2 * np.pi * x) + 0.25 * np.exp(-100 * (x - 0.5)**2)\n\ndef u_analytical(x: np.ndarray, t: float, a: float) -> np.ndarray:\n    \"\"\"\n    Computes the analytical solution u(x,t) for the 1D linear advection equation.\n    \"\"\"\n    # Python's '%' operator correctly handles the periodic domain for (x - a*t).\n    return u0((x - a * t) % 1)\n\ndef generate_structured_grid(N: int) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generates a structured grid with N uniform cells on the domain [0,1).\n    Returns cell edges and cell widths.\n    \"\"\"\n    edges = np.linspace(0, 1, N + 1)\n    delta_x = np.full(N, 1.0 / N)\n    return edges, delta_x\n\ndef generate_unstructured_grid(N: int, eta: float, seed: int) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generates an unstructured grid with N non-uniform cells on [0,1).\n    Returns cell edges and cell widths.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    xi = rng.uniform(-1, 1, N)\n    weights = 1 + eta * xi\n    delta_x = weights / np.sum(weights)\n    edges = np.zeros(N + 1)\n    edges[1:] = np.cumsum(delta_x)\n    return edges, delta_x\n\ndef compute_cell_averages(func: callable, edges: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes cell averages of a function on a grid using Gauss-Legendre quadrature.\n    \"\"\"\n    N = len(edges) - 1\n    averages = np.zeros(N)\n    nodes, weights = roots_legendre(NUM_GAUSS_POINTS)\n    \n    for i in range(N):\n        x_left, x_right = edges[i], edges[i+1]\n        delta_x_i = x_right - x_left\n        x_center = (x_right + x_left) / 2.0\n        \n        # Transform Gauss-Legendre nodes from [-1, 1] to [x_left, x_right]\n        mapped_nodes = x_center + (delta_x_i / 2.0) * nodes\n        \n        # Evaluate function at mapped nodes\n        func_values = func(mapped_nodes)\n        \n        # The cell average is 1/Delta_x * integral(f(x)dx).\n        # The integral is approx. (Delta_x/2) * sum(w_q * f(x_q)).\n        # Thus, the average is approx. (1/2) * sum(w_q * f(x_q)).\n        averages[i] = 0.5 * np.sum(weights * func_values)\n        \n    return averages\n\ndef upwind_step(U0: np.ndarray, delta_x: np.ndarray, dt: float, a: float) -> np.ndarray:\n    \"\"\"\n    Performs one time step of the first-order upwind finite volume scheme.\n    \"\"\"\n    if a >= 0:\n        # Upwind flux from the left. Flux difference is a*(U_i - U_{i-1}).\n        flux_diff = a * (U0 - np.roll(U0, 1))\n    else:  # a  0\n        # Upwind flux from the right. Flux difference is a*(U_{i+1} - U_i).\n        flux_diff = a * (np.roll(U0, -1) - U0)\n        \n    U1 = U0 - (dt / delta_x) * flux_diff\n    return U1\n\ndef compute_error_metrics(error: np.ndarray, delta_x: np.ndarray) - list[float]:\n    \"\"\"\n    Computes the L1, L2, L-infinity, and Energy norms for the error vector.\n    \"\"\"\n    l1_norm = np.sum(np.abs(error) * delta_x)\n    l2_norm = np.sqrt(np.sum(error**2 * delta_x))\n    linf_norm = np.max(np.abs(error))\n    \n    # Per the problem description, the energy norm is mathematically\n    # identical to the discrete L2 norm.\n    energy_norm = l2_norm\n    \n    return [l1_norm, l2_norm, linf_norm, energy_norm]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (100, 1.0, 0.5, 0.3, 42),\n        (20, 1.0, 0.9, 0.5, 123),\n        (8, -1.0, 0.4, 0.8, 7)\n    ]\n\n    all_results = []\n    for params in test_cases:\n        N, a, C, eta, seed = params\n        \n        # --- Structured Grid Calculation ---\n        edges_s, delta_x_s = generate_structured_grid(N)\n        dt_s = C * (1.0 / N) / abs(a)\n        \n        U0_s = compute_cell_averages(u0, edges_s)\n        U1_s = upwind_step(U0_s, delta_x_s, dt_s, a)\n        \n        u_exact_s_func = lambda x: u_analytical(x, dt_s, a)\n        U_exact_s = compute_cell_averages(u_exact_s_func, edges_s)\n        \n        error_s = U1_s - U_exact_s\n        metrics_s = compute_error_metrics(error_s, delta_x_s)\n        \n        # --- Unstructured Grid Calculation ---\n        edges_u, delta_x_u = generate_unstructured_grid(N, eta, seed)\n        dt_u = C * np.min(delta_x_u) / abs(a)\n\n        U0_u = compute_cell_averages(u0, edges_u)\n        U1_u = upwind_step(U0_u, delta_x_u, dt_u, a)\n\n        u_exact_u_func = lambda x: u_analytical(x, dt_u, a)\n        U_exact_u = compute_cell_averages(u_exact_u_func, edges_u)\n        \n        error_u = U1_u - U_exact_u\n        metrics_u = compute_error_metrics(error_u, delta_x_u)\n\n        # Combine results into a single list for the test case\n        all_results.append(metrics_s + metrics_u)\n\n    # Format the final output string as specified\n    formatted_results = []\n    for case_res in all_results:\n        formatted_case = [f\"{x:.8f}\" for x in case_res]\n        formatted_results.append(f\"[{','.join(formatted_case)}]\")\n        \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world earth system models are often complex systems composed of different components running on distinct grid types, such as a structured latitude-longitude grid for the atmosphere and an unstructured grid for the ocean. Transferring data between them without violating physical conservation laws is a critical challenge in model coupling. This exercise  tasks you with implementing a first-order conservative remapping scheme, a cornerstone of interoperable modeling, by calculating geometric overlap areas to ensure quantities are conserved during data transfer.",
            "id": "3918651",
            "problem": "You are given a localized environmental modeling task that requires conservative remapping between a latitude–longitude structured grid and a triangular unstructured mesh. The goal is to derive and implement area-preserving remapping weights by computing polygon intersections between source grid cells and destination triangles. The domain is small enough that a locally planar approximation is justified.\n\nFundamental base and definitions:\n- Let a scalar field be represented as piecewise constant over a set of source cells indexed by $i$, each cell having area $A_i$ and constant value $s_i$. The destination mesh consists of triangular elements indexed by $j$, each triangle having area $A_j$.\n- Conservative remapping requires that the discrete integral of the scalar field be preserved under the mapping, meaning that the total \"mass\" computed from source cells equals the total \"mass\" computed from destination elements, provided the same spatial domain is covered.\n- The remapped value on destination triangle $j$, denoted $v_j$, is defined using overlap areas $A_{ij}$ between source cell $i$ and destination triangle $j$.\n- Areas must be computed in square kilometers, and latitude–longitude angles must be in degrees.\n\nPlanar approximation:\n- Use a locally planar equidistant cylindrical (equirectangular) projection centered at a reference latitude $lat_0$ (in degrees). Let the Earth radius be $R=6371$ kilometers. Convert longitude–latitude $(\\lambda,\\phi)$ in degrees to planar coordinates $(x,y)$ in kilometers by\n$$\nx = R \\cos\\left(\\frac{\\pi}{180} lat_0\\right)\\,\\frac{\\pi}{180}\\,\\lambda, \\quad\ny = R\\,\\frac{\\pi}{180}\\,\\phi.\n$$\n\nConservative remapping principle:\n- Define the remapping weights $w_{ij}$ by\n$$\nw_{ij} = \\frac{A_{ij}}{A_j},\n$$\nwhere $A_{ij}$ is the area of the intersection polygon between source cell $i$ and destination triangle $j$, and $A_j$ is the area of the destination triangle $j$.\n- The remapped destination value is\n$$\nv_j = \\sum_i w_{ij}\\,s_i.\n$$\n- Exact area conservation for first-order conservative remapping follows from\n$$\n\\sum_j v_j A_j = \\sum_j \\left(\\sum_i s_i\\,\\frac{A_{ij}}{A_j}\\right) A_j = \\sum_i s_i \\left(\\sum_j A_{ij}\\right),\n$$\nand when the union of destination polygons exactly covers the union of source cells, one has $\\sum_j A_{ij} = A_i$, giving\n$$\n\\sum_j v_j A_j = \\sum_i s_i A_i.\n$$\n\nAlgorithmic requirements:\n- Implement polygon intersection between a triangle and axis-aligned rectangles via planar clipping. Use Sutherland–Hodgman polygon clipping against the four half-planes of the rectangle. Compute polygon areas using the shoelace formula in planar $(x,y)$ coordinates.\n- Compute $A_{ij}$ by clipping the triangle polygon to source rectangle $i$, converting vertices from degrees to $(x,y)$ using the specified projection, and taking the area of the clipped polygon. Compute $A_j$ as the area of the triangle in the same projection.\n- Compute weights $w_{ij} = A_{ij}/A_j$ for all source cells $i$ and each triangle $j$.\n\nStructured grid specification:\n- Use a $2\\times 2$ latitude–longitude structured grid defined by latitude lines at $\\{34^\\circ, 35^\\circ, 36^\\circ\\}$ and longitude lines at $\\{-120^\\circ, -119^\\circ, -118^\\circ\\}$, forming four rectangular source cells:\n  - Lower-left: $\\lambda \\in [-120^\\circ,-119^\\circ], \\phi \\in [34^\\circ,35^\\circ]$,\n  - Lower-right: $\\lambda \\in [-119^\\circ,-118^\\circ], \\phi \\in [34^\\circ,35^\\circ]$,\n  - Upper-left: $\\lambda \\in [-120^\\circ,-119^\\circ], \\phi \\in [35^\\circ,36^\\circ]$,\n  - Upper-right: $\\lambda \\in [-119^\\circ,-118^\\circ], \\phi \\in [35^\\circ,36^\\circ]$.\n- Use $lat_0 = 35^\\circ$ in the projection.\n\nDestination triangular mesh test suite (angles in degrees):\n- Triangle $T_1$ (fully inside the lower-left cell): vertices at $(-119.8^\\circ, 34.2^\\circ)$, $(-119.6^\\circ, 34.4^\\circ)$, $(-119.7^\\circ, 34.6^\\circ)$.\n- Triangle $T_2$ (straddles the vertical boundary at $\\lambda=-119^\\circ$ within the lower row): vertices at $(-119.2^\\circ, 34.6^\\circ)$, $(-118.9^\\circ, 34.7^\\circ)$, $(-118.95^\\circ, 34.4^\\circ)$.\n- Triangle $T_3$ (with one edge aligned exactly on the boundary $\\lambda=-119^\\circ$): vertices at $(-119.0^\\circ, 34.3^\\circ)$, $(-119.0^\\circ, 34.8^\\circ)$, $(-118.7^\\circ, 34.5^\\circ)$.\n- Triangle $T_4$ (partially outside the structured grid domain): vertices at $(-118.1^\\circ, 35.8^\\circ)$, $(-117.9^\\circ, 36.2^\\circ)$, $(-118.5^\\circ, 36.1^\\circ)$.\n\nRequired outputs per test case:\n- For $T_1$: compute the absolute conservation deviation $\\left|\\sum_i w_{i1} - 1\\right|$ as a float.\n- For $T_2$: compute the list of the two nonzero weights $\\{w_{i2}\\}$ corresponding to the two lower-row cells, sorted in ascending order, as a list of floats.\n- For $T_3$: compute a boolean indicating whether the lower-left cell weight is exactly zero within tolerance $10^{-12}$ (i.e., $w_{LL,3} \\le 10^{-12}$).\n- For $T_4$: compute the coverage fraction $\\sum_i w_{i4}$ across all four source cells as a float (this is less than $1$ because part of $T_4$ lies outside the structured grid domain).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[T_1\\ \\text{result},\\ T_2\\ \\text{result},\\ T_3\\ \\text{result},\\ T_4\\ \\text{result}]$. For example, the printed structure must look like $[x,[a,b],y,z]$ where $x$ and $z$ are floats, $[a,b]$ is a list of two floats, and $y$ is a boolean.\n\nAngle unit specification:\n- All input longitudes and latitudes are in degrees.\n- Areas must be computed and conserved in square kilometers.",
            "solution": "The problem requires the implementation of a first-order conservative remapping scheme between a structured latitude-longitude grid and an unstructured triangular mesh. This is a common task in environmental modeling for transferring data between different model components that use different grid systems. The solution involves geometric calculations in a locally planar projection. The core of the task is to compute the fractional area of each destination triangle that is covered by each source grid cell. These fractions serve as the remapping weights.\n\nThe methodological approach is structured as follows:\n1.  **Coordinate Projection**: Convert all geographic coordinates (latitude, longitude) into a planar Cartesian coordinate system $(x,y)$. This simplifies geometric calculations like area and intersection.\n2.  **Polygon Clipping**: For each pair of a source cell (a rectangle) and a destination element (a triangle), compute their intersection polygon.\n3.  **Area Calculation**: Compute the area of the original destination triangles and their intersection polygons.\n4.  **Weight Calculation**: Compute the remapping weights based on the ratio of intersection area to total triangle area.\n5.  **Test Case Evaluation**: Apply the calculated weights to evaluate the specific metrics required for each test case.\n\n**1. Planar Coordinate System: Equirectangular Projection**\nFor localized domains, a planar approximation is justified. The problem specifies an equidistant cylindrical (equirectangular) projection. Given the Earth's radius $R = 6371$ km and a reference latitude $lat_0 = 35^\\circ$, a point with longitude $\\lambda$ and latitude $\\phi$ (both in degrees) is mapped to planar coordinates $(x,y)$ (in kilometers) by the following transformation:\n$$\nx = R \\cos\\left(\\frac{\\pi}{180} lat_0\\right) \\left(\\frac{\\pi}{180}\\lambda\\right)\n$$\n$$\ny = R \\left(\\frac{\\pi}{180}\\phi\\right)\n$$\nThese equations can be simplified by pre-calculating the scaling factors. Let $\\lambda_{rad} = \\lambda \\cdot \\pi/180$ and $\\phi_{rad} = \\phi \\cdot \\pi/180$ be the angles in radians. The transformation becomes:\n$$\nx = \\left(R \\cos(lat_{0,rad})\\right) \\lambda_{rad}\n$$\n$$\ny = R \\phi_{rad}\n$$\nThis projection maps lines of constant longitude and latitude to straight vertical and horizontal lines, respectively. Consequently, the rectangular source grid cells in $(\\lambda, \\phi)$ space become axis-aligned rectangles in the $(x,y)$ plane.\n\n**2. Core Algorithm: Intersection Area Calculation**\nThe area of intersection $A_{ij}$ between a source cell $i$ (a rectangle) and a destination triangle $j$ is computed by clipping the triangle polygon against the four boundaries of the source cell rectangle.\n\n**2.1. Sutherland–Hodgman Polygon Clipping**\nThe Sutherland–Hodgman algorithm is employed for this task. It clips a subject polygon against a convex clip polygon (in our case, the rectangular source cell) by processing the subject polygon against each edge of the clip polygon sequentially. A source cell defined by longitude range $[\\lambda_{min}, \\lambda_{max}]$ and latitude range $[\\phi_{min}, \\phi_{max}]$ is projected to a rectangle in the $(x,y)$ plane with corners at $(x(\\lambda_{min}), y(\\phi_{min}))$ and $(x(\\lambda_{max}), y(\\phi_{max}))$. This rectangle defines four clip boundaries or half-planes:\n- Left boundary: $x \\ge x_{min}$\n- Right boundary: $x \\le x_{max}$\n- Bottom boundary: $y \\ge y_{min}$\n- Top boundary: $y \\le y_{max}$\n\nThe algorithm proceeds by taking the list of vertices of the destination triangle (in its projected form) and clipping it against the first boundary. The resulting list of vertices, which forms the new clipped polygon, is then fed as input to be clipped against the second boundary, and so on for all four boundaries.\n\nFor a single clip edge (e.g., a vertical line $x = x_{clip}$), the algorithm iterates through the edges of the polygon being clipped. For each edge from vertex $P_1$ to $P_2$:\n- If both $P_1$ and $P_2$ are inside the half-plane, only $P_2$ is added to the output vertex list.\n- If $P_1$ is inside and $P_2$ is outside, the intersection point of the edge with the clip boundary is calculated and added to the output list.\n- If both $P_1$ and $P_2$ are outside, nothing is added.\n- If $P_1$ is outside and $P_2$ is inside, the intersection point and $P_2$ are added to the output list.\n\nAfter clipping against all four boundaries, the final list of vertices defines the intersection polygon. If this list is empty or has fewer than $3$ vertices, the intersection area $A_{ij}$ is $0$.\n\n**2.2. Shoelace Formula for Area**\nThe area of any simple polygon (including the original triangles and the intersection polygons) with vertices $(x_0, y_0), (x_1, y_1), \\dots, (x_{N-1}, y_{N-1})$ listed in counter-clockwise or clockwise order is calculated using the shoelace (or surveyor's) formula:\n$$\nA = \\frac{1}{2} \\left| \\sum_{k=0}^{N-1} (x_k y_{k+1} - x_{k+1} y_k) \\right|\n$$\nwhere $(x_N, y_N)$ is taken to be the same as $(x_0, y_0)$. This formula is applied in the planar $(x,y)$ coordinate system to compute both the total area of the destination triangle, $A_j$, and the area of the intersection polygon, $A_{ij}$.\n\n**3. Derivation of Remapping Weights**\nThe first-order conservative remapping weight $w_{ij}$ is the fraction of destination triangle $j$'s area that lies within source cell $i$. It is defined as:\n$$\nw_{ij} = \\frac{A_{ij}}{A_j}\n$$\nwhere $A_{ij}$ is the intersection area and $A_j$ is the total area of the destination triangle. Per the problem, both areas are computed in the same projected coordinate system to ensure the ratio is dimensionless and correct. The remapped value on triangle $j$ is then a weighted average of the source cell values: $v_j = \\sum_i w_{ij} s_i$.\n\n**4. Application to Test Cases**\nThe defined procedure is applied to each test case:\n- The four source cells are indexed $0$ (Lower-Left), $1$ (Lower-Right), $2$ (Upper-Left), and $3$ (Upper-Right).\n- For each destination triangle $T_j$ ($j=1,2,3,4$):\n    1. The vertices of $T_j$ are projected to the $(x,y)$ plane.\n    2. The total area $A_j$ of the projected triangle is computed.\n    3. A loop runs over the four source cells $i=0,1,2,3$. In each iteration:\n        - The boundaries of cell $i$ are defined in $(\\lambda, \\phi)$ and then projected to form a clipping rectangle in $(x,y)$.\n        - The projected triangle $T_j$ is clipped against this rectangle.\n        - The area $A_{ij}$ of the resulting intersection polygon is computed.\n        - The weight $w_{ij} = A_{ij} / A_j$ is calculated. If $A_j$ is zero (a degenerate triangle), the weight is taken to be zero.\n    4. The set of four weights $\\{w_{0j}, w_{1j}, w_{2j}, w_{3j}\\}$ is used to compute the specific output required for that test case. For instance, for $T_1$, the quantity $|\\sum_i w_{i1} - 1|$ is computed. For $T_3$, the weight $w_{0,3}$ (corresponding to the Lower-Left cell) is checked against the tolerance $10^{-12}$. This systematic process yields the required numerical results.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes conservative remapping weights between a structured grid and a triangular mesh.\n    \"\"\"\n\n    # --- Constants and Definitions ---\n    R_EARTH = 6371.0  # Earth radius in km\n    LAT_0_DEG = 35.0  # Reference latitude in degrees\n    LAT_0_RAD = math.radians(LAT_0_DEG)\n\n    # --- Coordinate Projection ---\n    def project(lon_deg, lat_deg):\n        \"\"\"Converts (lon, lat) in degrees to planar (x, y) in km.\"\"\"\n        lon_rad = math.radians(lon_deg)\n        lat_rad = math.radians(lat_deg)\n        x = R_EARTH * math.cos(LAT_0_RAD) * lon_rad\n        y = R_EARTH * lat_rad\n        return np.array([x, y])\n\n    # --- Geometric Algorithms ---\n    def polygon_area(vertices):\n        \"\"\"Computes polygon area using the shoelace formula.\"\"\"\n        if len(vertices)  3:\n            return 0.0\n        \n        v = np.array(vertices)\n        x = v[:, 0]\n        y = v[:, 1]\n        \n        # Shift vertices for vectorized calculation\n        x_shifted = np.roll(x, -1)\n        y_shifted = np.roll(y, -1)\n        \n        area = 0.5 * np.abs(np.sum(x * y_shifted - x_shifted * y))\n        return area\n\n    def clip_polygon(subject_polygon, clip_bounds):\n        \"\"\"\n        Clips a polygon using the Sutherland-Hodgman algorithm against a rectangular clip_bounds.\n        clip_bounds = (xmin, ymin, xmax, ymax)\n        \"\"\"\n        clipped = list(subject_polygon)\n        \n        # Clip against the 4 edges of the rectangle\n        # 0: left, 1: right, 2: bottom, 3: top\n        for i in range(4):\n            if not clipped:\n                break\n            \n            input_list = clipped\n            clipped = []\n            s = input_list[-1]\n            \n            for j in range(len(input_list)):\n                e = input_list[j]\n                \n                # Check if points are inside the current clip edge\n                s_inside = False\n                e_inside = False\n                if i == 0:  # Left edge: x >= xmin\n                    s_inside = s[0] = clip_bounds[0]\n                    e_inside = e[0] = clip_bounds[0]\n                elif i == 1:  # Right edge: x = xmax\n                    s_inside = s[0] = clip_bounds[2]\n                    e_inside = e[0] = clip_bounds[2]\n                elif i == 2:  # Bottom edge: y >= ymin\n                    s_inside = s[1] = clip_bounds[1]\n                    e_inside = e[1] = clip_bounds[1]\n                elif i == 3:  # Top edge: y = ymax\n                    s_inside = s[1] = clip_bounds[3]\n                    e_inside = e[1] = clip_bounds[3]\n\n                if s_inside and e_inside:\n                    clipped.append(e)\n                elif s_inside and not e_inside:\n                    # Going from inside to outside, add intersection\n                    intersection = _get_intersection(s, e, i, clip_bounds)\n                    clipped.append(intersection)\n                elif not s_inside and e_inside:\n                    # Going from outside to inside, add intersection and end point\n                    intersection = _get_intersection(s, e, i, clip_bounds)\n                    clipped.append(intersection)\n                    clipped.append(e)\n                # If both are outside, do nothing.\n                \n                s = e\n        \n        return clipped\n\n    def _get_intersection(p1, p2, edge_index, clip_bounds):\n        \"\"\"Helper to find intersection of segment p1-p2 with a clip edge.\"\"\"\n        dx, dy = p2[0] - p1[0], p2[1] - p1[1]\n\n        if edge_index == 0:  # Left\n            x_clip = clip_bounds[0]\n            if dx == 0: return np.array([x_clip, p1[1]])\n            t = (x_clip - p1[0]) / dx\n            return np.array([x_clip, p1[1] + t * dy])\n        elif edge_index == 1:  # Right\n            x_clip = clip_bounds[2]\n            if dx == 0: return np.array([x_clip, p1[1]])\n            t = (x_clip - p1[0]) / dx\n            return np.array([x_clip, p1[1] + t * dy])\n        elif edge_index == 2:  # Bottom\n            y_clip = clip_bounds[1]\n            if dy == 0: return np.array([p1[0], y_clip])\n            t = (y_clip - p1[1]) / dy\n            return np.array([p1[0] + t * dx, y_clip])\n        elif edge_index == 3:  # Top\n            y_clip = clip_bounds[3]\n            if dy == 0: return np.array([p1[0], y_clip])\n            t = (y_clip - p1[1]) / dy\n            return np.array([p1[0] + t * dx, y_clip])\n\n    # --- Grid and Mesh Definitions ---\n    source_cells_lonlat = [\n        # (lon_min, lon_max, lat_min, lat_max)\n        (-120.0, -119.0, 34.0, 35.0),  # Lower-Left (LL)\n        (-119.0, -118.0, 34.0, 35.0),  # Lower-Right (LR)\n        (-120.0, -119.0, 35.0, 36.0),  # Upper-Left (UL)\n        (-119.0, -118.0, 35.0, 36.0),  # Upper-Right (UR)\n    ]\n\n    destination_triangles_lonlat = [\n        # T1: Fully inside LL cell\n        [(-119.8, 34.2), (-119.6, 34.4), (-119.7, 34.6)],\n        # T2: Straddles vertical boundary at lambda=-119\n        [(-119.2, 34.6), (-118.9, 34.7), (-118.95, 34.4)],\n        # T3: One edge aligned with boundary lambda=-119\n        [(-119.0, 34.3), (-119.0, 34.8), (-118.7, 34.5)],\n        # T4: Partially outside the domain\n        [(-118.1, 35.8), (-117.9, 36.2), (-118.5, 36.1)],\n    ]\n    \n    source_cells_proj = [\n        (project(b[0], b[2])[0], project(b[0], b[2])[1], \n         project(b[1], b[3])[0], project(b[1], b[3])[1])\n        for b in source_cells_lonlat\n    ]\n\n    all_results = []\n    \n    # --- Main Loop over Test Cases ---\n    for j, tri_lonlat in enumerate(destination_triangles_lonlat):\n        \n        projected_triangle = [project(lon, lat) for lon, lat in tri_lonlat]\n        \n        total_triangle_area = polygon_area(projected_triangle)\n        \n        weights = []\n        for i, cell_bounds_proj in enumerate(source_cells_proj):\n            if total_triangle_area == 0:\n                weights.append(0.0)\n                continue\n\n            intersection_polygon = clip_polygon(projected_triangle, cell_bounds_proj)\n            intersection_area = polygon_area(intersection_polygon)\n            weight = intersection_area / total_triangle_area\n            weights.append(weight)\n\n        # --- Process results for each test case ---\n        if j == 0: # T1: Absolute conservation deviation\n            result = abs(sum(weights) - 1.0)\n            all_results.append(result)\n        \n        elif j == 1: # T2: Two non-zero weights, sorted\n            nonzero_weights = sorted([w for w in weights if w  1e-12])\n            all_results.append(nonzero_weights)\n\n        elif j == 2: # T3: Check if LL cell weight is zero\n            # LL cell is index 0\n            result = weights[0] = 1e-12\n            all_results.append(result)\n\n        elif j == 3: # T4: Coverage fraction\n            result = sum(weights)\n            all_results.append(result)\n\n    # --- Format final output ---\n    formatted_results = []\n    for res in all_results:\n      if isinstance(res, list):\n        # Format list without spaces, e.g., [0.1,0.2]\n        formatted_results.append(f\"[{','.join(map(str, res))}]\")\n      else:\n        formatted_results.append(str(res))\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}