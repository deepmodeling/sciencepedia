{
    "hands_on_practices": [
        {
            "introduction": "在模型选择的实践中，我们需要一个定量的方法来平衡模型的拟合优度和复杂性。赤池信息准则（Akaike Information Criterion, $AIC$）和贝叶斯信息准则（Bayesian Information Criterion, $BIC$）正是为此设计的关键工具。 这个练习将带你进入一个区域碳通量反演的场景，通过亲手计算和比较 $AIC$ 与 $BIC$，你将深刻理解这两个准则如何通过不同的惩罚项来实现奥卡姆剃刀原则，以及它们在特定条件下为何会偏好不同的模型。",
            "id": "3925501",
            "problem": "在一个温带森林的区域碳通量反演中，考虑了地球系统数据同化框架内大气传输部分的两种备选前向模型。模型A假设了一个空间均匀的湍流参数化方案，而模型B引入了一个在较粗网格上解析的空间变化的湍流场。数据包含 $n=500$ 个独立的柱平均二氧化碳浓度日观测值，每个模型都通过最大似然估计(MLE)对相同的数据集进行拟合。设模型A的可识别自由参数数量为 $k=12$，模型B为 $k=20$。最大化对数似然值分别为 $\\ell(\\hat{\\theta}_A)=-1400$ 和 $\\ell(\\hat{\\theta}_B)=-1390$。根据简约性原则（奥卡姆剃刀），使用两种基于经过充分检验的统计理论的标准信息准则来比较模型：赤池信息准则(AIC)和贝叶斯信息准则(BIC)。\n\n从期望信息损失和边际似然的基本定义出发，并使用适当的渐近近似，计算两个模型的AIC和BIC，在BIC的样本量惩罚项中使用自然对数。解释每个准则如何将简约性原则付诸实施，并确定每个准则偏好哪个模型。将AIC值表示为精确整数。将BIC值四舍五入到四位有效数字。以行矩阵 $(\\text{AIC}_A, \\text{BIC}_A, \\text{AIC}_B, \\text{BIC}_B, p_{\\mathrm{AIC}}, p_{\\mathrm{BIC}})$ 的形式给出你的最终答案，其中如果AIC偏好模型A，则 $p_{\\mathrm{AIC}}=0$，如果AIC偏好模型B，则 $p_{\\mathrm{AIC}}=1$；类似地，如果BIC偏好模型A，则 $p_{\\mathrm{BIC}}=0$，如果BIC偏好模型B，则 $p_{\\mathrm{BIC}}=1$。这些准则无需物理单位。",
            "solution": "该问题是有效的，因为它具有科学依据、提法恰当、客观且自洽。它要求将标准的统计模型选择准则（AIC和BIC）应用于环境建模中的一个明确场景，并提供了所有必要的数据。\n\n简约性原则，即奥卡姆剃刀，主张在相互竞争的假设中，应选择假设最少的那个。在统计建模中，这转化为偏好能够充分解释数据的更简单的模型。信息准则提供了一个形式化框架，用于平衡模型的拟合度（模型解释数据的优良程度）与模型的复杂度（参数数量）。\n\n赤池信息准则（AIC）源于信息论。它估计当使用一个给定模型来表示生成数据的过程时所损失的相对信息量。这等同于估计模型与真实数据生成过程之间的期望Kullback-Leibler散度。对于一个给定的模型，有 $k$ 个自由参数，在拟合数据集后得到最大化对数似然值 $\\ell$，其AIC定义为：\n$$\n\\text{AIC} = 2k - 2\\ell\n$$\n较低的AIC值表示模型更好，意味着估计损失的信息更少。$-2\\ell$ 项代表拟合优度，而 $2k$ 项则作为对复杂度的惩罚。简约性是通过对每个额外参数施加一个固定的惩罚来实现的，这迫使更复杂的模型必须达到显著更优的拟合才能被偏好。\n\n贝叶斯信息准则（BIC），也称为施瓦茨准则，源于贝叶斯框架。它是给定模型下数据边际似然函数 $p(\\text{data}|M)$ 的一个（针对大样本的）渐近近似。选择具有最高后验概率的模型（假设各模型具有相等的先验概率）等同于选择具有最低BIC的模型。BIC定义为：\n$$\n\\text{BIC} = k \\ln(n) - 2\\ell\n$$\n此处，$k$ 是参数数量，$\\ell$ 是最大化对数似然值，$n$ 是观测数量。与AIC类似，较低的BIC值更优。BIC的惩罚项 $k \\ln(n)$ 同时取决于参数数量 $k$ 和样本量 $n$。对于任何样本量 $n > e^2 \\approx 7.4$，BIC对每个参数的惩罚 $\\ln(n)$ 都大于AIC的惩罚 $2$。在本问题中，$n=500$，所以 $\\ln(500) \\approx 6.21$。这意味着BIC对模型复杂度施加了比AIC强得多的惩罚，因此更倾向于选择简约模型，尤其是在大数据集的情况下。\n\n我们现在为给定的两个模型计算这些准则。\n\n对于模型A：\n参数数量为 $k_A = 12$。\n最大化对数似然值为 $\\ell(\\hat{\\theta}_A) = -1400$。\n观测数量为 $n = 500$。\n\n模型A的AIC为：\n$$\n\\text{AIC}_A = 2k_A - 2\\ell(\\hat{\\theta}_A) = 2(12) - 2(-1400) = 24 + 2800 = 2824\n$$\n\n模型A的BIC为：\n$$\n\\text{BIC}_A = k_A \\ln(n) - 2\\ell(\\hat{\\theta}_A) = 12 \\ln(500) - 2(-1400) = 12 \\ln(500) + 2800\n$$\n使用值 $\\ln(500) \\approx 6.214608$，我们有：\n$$\n\\text{BIC}_A \\approx 12(6.214608) + 2800 \\approx 74.5753 + 2800 = 2874.5753\n$$\n四舍五入到四位有效数字，我们得到 $\\text{BIC}_A = 2875$。\n\n对于模型B：\n参数数量为 $k_B = 20$。\n最大化对数似然值为 $\\ell(\\hat{\\theta}_B) = -1390$。\n观测数量为 $n = 500$。\n\n模型B的AIC为：\n$$\n\\text{AIC}_B = 2k_B - 2\\ell(\\hat{\\theta}_B) = 2(20) - 2(-1390) = 40 + 2780 = 2820\n$$\n\n模型B的BIC为：\n$$\n\\text{BIC}_B = k_B \\ln(n) - 2\\ell(\\hat{\\theta}_B) = 20 \\ln(500) - 2(-1390) = 20 \\ln(500) + 2780\n$$\n使用 $\\ln(500) \\approx 6.214608$：\n$$\n\\text{BIC}_B \\approx 20(6.214608) + 2780 \\approx 124.2922 + 2780 = 2904.2922\n$$\n四舍五入到四位有效数字，我们得到 $\\text{BIC}_B = 2904$。\n\n比较与模型偏好：\n信息准则值较低的模型更优。\n\nAIC比较：\n$\\text{AIC}_A = 2824$\n$\\text{AIC}_B = 2820$\n由于 $\\text{AIC}_B  \\text{AIC}_A$，赤池信息准则偏好模型B。模型B改进的拟合度（对数似然值增加10）超过了其因8个额外参数而受到的惩罚（$2 \\times 8 = 16$）。AIC的变化量是 $2824 - 2820 = 4$，这对应于对数似然值变化10和参数数量变化8；具体而言，$2(k_A-k_B) - 2(\\ell_A - \\ell_B) = 2(12-20) - 2(-1400 - (-1390)) = 2(-8) - 2(-10) = -16+20=4$。因此，$p_{\\mathrm{AIC}} = 1$。\n\nBIC比较：\n$\\text{BIC}_A \\approx 2875$\n$\\text{BIC}_B \\approx 2904$\n由于 $\\text{BIC}_A  \\text{BIC}_B$，贝叶斯信息准则偏好模型A。在BIC更严格的惩罚下，模型B改进的拟合度不足以证明其增加的复杂度是合理的。8个额外参数的惩罚是 $8 \\ln(500) \\approx 8 \\times 6.21 = 49.68$，这远大于从改进拟合中获得的增益（$2 \\times 10 = 20$）。因此，$p_{\\mathrm{BIC}} = 0$。\n\n最终结果是：$\\text{AIC}_A = 2824$，$\\text{BIC}_A \\approx 2875$，$\\text{AIC}_B = 2820$，$\\text{BIC}_B \\approx 2904$，$p_{\\mathrm{AIC}}=1$，以及 $p_{\\mathrm{BIC}}=0$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2824  2875  2820  2904  1  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "除了基于信息论的方法，贝叶斯推断为模型选择提供了一个强大且自洽的框架。该框架的核心是贝叶斯因子（Bayes factor），它通过比较不同模型的边际似然（marginal likelihood）来量化数据对各个模型的支持程度，并内在地惩罚了不必要的复杂性。 在这个关于气溶胶强迫模型的练习中，你将学习如何根据给定的对数证据（log-evidences）计算贝叶斯因子，并根据其数值大小来解释证据强度，从而体会贝叶斯方法是如何优雅地践行简约原则的。",
            "id": "3925554",
            "problem": "比较了两种候选的基于过程的气溶胶强迫模型，以评估它们解释全球大气层顶辐射不平衡数据集的能力。模型 $M_1$ 是一个从气溶胶光学厚度到有效辐射强迫的简约线性映射，有 $2$ 个参数；而模型 $M_2$ 是一个更复杂的带有 $4$ 个参数的区域切换非线性映射。两种模型都对其参数使用了适当且科学上可辩护的先验，这些先验仅在物理上合理的参数范围内赋予非零质量。数据 $y$ 包含 $1970$–$2020$ 年期间的年平均观测值，每个模型的边际似然 $p(y \\mid M_i)$ 是通过在其参数先验上对似然函数进行积分计算得出的。\n\n给定对数证据 $\\log p(y \\mid M_1) = -520$ 和 $\\log p(y \\mid M_2) = -515$。假设 $M_1$ 和 $M_2$ 的先验几率相等，这与简约原则（奥卡姆剃刀）一致，即除非数据提供足够强的支持来克服边际似然中隐含的复杂性惩罚，否则更倾向于选择更简单的模型。\n\n仅使用这些输入和贝叶斯模型比较的基本原理，计算支持模型 $M_2$ 而非 $M_1$ 的贝叶斯因子，并根据文献中常用的贝叶斯因子定性分类来解释在两种气溶胶强迫模型之间进行选择的证据强度。以标准科学记数法报告贝叶斯因子的数值，并四舍五入到四位有效数字。贝叶斯因子是无量纲的，因此不需要单位。",
            "solution": "首先根据所需标准对问题进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- 模型 $M_1$：简约线性映射，$2$ 个参数。\n- 模型 $M_2$：复杂区域切换非线性映射，$4$ 个参数。\n- 两个模型的先验都是适当的、科学上可辩护的，并且仅在物理上合理的参数范围内有支撑。\n- 数据 $y$：$1970$–$2020$ 年的年平均观测值。\n- $M_1$ 的对数证据：$\\log p(y \\mid M_1) = -520$。\n- $M_2$ 的对数证据：$\\log p(y \\mid M_2) = -515$。\n- 先验几率相等：$p(M_1) / p(M_2) = 1$。\n- 任务是计算支持 $M_2$ 超过 $M_1$ 的贝叶斯因子，解释其证据强度，并以科学记数法报告其数值，保留四位有效数字。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题使用了贝叶斯统计中标准的、成熟的概念，即边际似然（证据）和贝叶斯因子，用于模型比较。其应用背景，即地球系统科学中的气溶胶强迫模型，是STEM研究中一个有效且重要的领域。给定的对数证据值为负且数值很大，这对于包含大量观测值（此处为 $51$ 年）的数据集是符合实际的。\n- **良态问题：** 问题陈述清晰，并提供了计算所要求数量的所有必要信息。目标明确，存在唯一且有意义的解。\n- **客观性：** 问题以精确的技术语言表述，没有主观或基于意见的陈述。\n- **完整性与一致性：** 问题是自洽的。提供的数据（$\\log p(y \\mid M_1)$ 和 $\\log p(y \\mid M_2)$）正是计算贝叶斯因子所需的数据。不存在矛盾之处。\n- **现实性与可行性：** 场景是现实的。在模型选择中，将一个简单模型与一个更复杂的模型进行比较是常见的。更复杂的模型（$M_2$）具有更高的边际似然（对数证据的负值更小），这一事实表明数据支持其额外的复杂性，这是贝叶斯分析中的一个标准结果。\n- **结构与平凡性：** 问题结构良好，考察了贝叶斯模型选择中的一个基本概念。它并非微不足道，因为它需要了解贝叶斯因子的定义及其与对数证据的关系。它也不是伪深刻的。\n\n**步骤3：结论与行动**\n问题是有效的，因为它科学上合理，是良态问题，并且提供了所有必要的信息。将给出解答。\n\n### 解答\n\n贝叶斯模型比较的主要工具是贝叶斯因子。贝叶斯因子 $K_{ij}$ 量化了数据 $y$ 支持模型 $M_i$ 超过模型 $M_j$ 的证据，其定义为它们边际似然（也称为证据）的比值：\n$$\nK_{ij} = \\frac{p(y \\mid M_i)}{p(y \\mid M_j)}\n$$\n在这个问题中，我们需要计算支持模型 $M_2$ 超过模型 $M_1$ 的贝叶斯因子。这对应于 $K_{21}$：\n$$\nK_{21} = \\frac{p(y \\mid M_2)}{p(y \\mid M_1)}\n$$\n问题提供了边际似然的自然对数，即对数证据：\n$$\n\\log p(y \\mid M_1) = -520\n$$\n$$\n\\log p(y \\mid M_2) = -515\n$$\n为了计算 $K_{21}$，首先计算其对数在数值上更稳定。贝叶斯因子的对数是对数证据之差：\n$$\n\\log K_{21} = \\log\\left(\\frac{p(y \\mid M_2)}{p(y \\mid M_1)}\\right) = \\log p(y \\mid M_2) - \\log p(y \\mid M_1)\n$$\n代入给定值：\n$$\n\\log K_{21} = (-515) - (-520) = 5\n$$\n为了求得贝叶斯因子 $K_{21}$，我们对这个结果取指数：\n$$\nK_{21} = \\exp(\\log K_{21}) = \\exp(5)\n$$\n现在，我们计算其数值，并按要求四舍五入到四位有效数字：\n$$\nK_{21} \\approx 148.413159...\n$$\n$$\nK_{21} \\approx 1.484 \\times 10^{2}\n$$\n任务的第二部分是解释这个值。贝叶斯因子使用定性标度来解释，以描述证据的强度。一个常用的标度，例如 Kass and Raftery (1995) 提出的标度，将证据分类如下：\n- $1  K  3$：不值一提（或“坊间证据”）。\n- $3  K  20$：正面（或“实质性”）。\n- $20  K  150$：强。\n- $K > 150$：非常强（或“决定性”）。\n\n我们计算出的值 $K_{21} \\approx 148.4$ 处于“强”证据类别的上限，接近于支持模型 $M_2$ 的“非常强”证据。这意味着在模型 $M_2$ 下观测到数据 $y$ 的可能性大约是在模型 $M_1$ 下的 $148.4$ 倍。\n\n问题陈述 $M_2$ 是一个具有 $4$ 个参数的更复杂的模型，而 $M_1$ 是一个具有 $2$ 个参数的更简单的模型。边际似然 $p(y \\mid M)$ 内在地惩罚复杂性；一个更复杂的模型必须对数据提供显著更好的拟合，以证明其额外参数的合理性。这是对简约原则（奥卡姆剃刀）的贝叶斯量化。在这种情况下，数据提供了强到非常强的证据，克服了这种隐含的惩罚，从而支持更复杂的非线性模型 $M_2$ 而非简约的线性模型 $M_1$。",
            "answer": "$$\\boxed{1.484 \\times 10^{2}}$$"
        },
        {
            "introduction": "任何模型选择准则的可靠性都取决于其所依赖的性能评估的公正性。当地球系统数据（如降水）表现出空间自相关时，标准的交叉验证方法可能会产生误导性的乐观结果，从而错误地偏爱复杂模型。 这个实践探讨了如何通过空间块交叉验证（spatial block cross-validation）来解决这个问题。它揭示了为何标准方法会失效，并阐明了设计一个无偏的验证方案对于实现真正的简约模型选择至关重要。",
            "id": "3925520",
            "problem": "一位水文学家正在使用位于 $s \\in \\mathcal{D} \\subset \\mathbb{R}^2$ 的 $n=500$ 个雨量计，对一个流域的日降水量 $Y(s)$ 进行建模。探索性分析得出的半变异函数与马特恩（Matérn）协方差一致，其相关性随分离距离 $h=\\lVert s-s' \\rVert$ 而衰减，有效范围参数 $a \\approx 50\\,\\mathrm{km}$，因此 $\\mathrm{Corr}(Y(s),Y(s')) \\approx \\rho(h)$ 满足：当 $h \\gtrsim a$ 时 $\\rho(h) \\approx 0$，当 $h \\lesssim a$ 时 $\\rho(h)  0$。考虑了两种候选模型：一个简约模型 $M_S$，它将 $Y(s)$ 对海拔和纬度进行回归，并带有一个平滑的空间趋势；以及一个复杂模型 $M_C$，它增加了 15 个额外的协变量和一个捕捉局部空间依赖性的短程高斯过程随机场。在留一法交叉验证（LOO-CV）下，$M_C$ 的均方根误差（RMSE）低于 $M_S$。然而，在使用直径 $\\geq 60\\,\\mathrm{km}$ 的非重叠块进行空间块交叉验证时，两者的 RMSE 相当。\n\n假设存在以下基础设定。交叉验证的目标是为一个新位置 $s_* \\in \\mathcal{D}$ 估计期望泛化风险 $R=\\mathbb{E}[L(Y(s_*),\\hat{f}(s_*))]$，其中 $L$ 是平方误差损失，$\\hat{f}$ 是从训练数据中获得的拟合预测器。标准的 LOO-CV 隐含地假设被留出的点与用其余数据拟合的预测器之间近似独立。在具有正自相关的空间数据中，当训练数据包含位于被留出位置的范围 $a$ 之内的点时，这种独立性假设可能被违反。\n\n令 $\\hat{Y}_{-i}(s_i)$ 表示由一个对除第 $i$ 个点之外的所有数据进行拟合的模型在 $s_i$ 处做出的预测，令 $B_1,\\dots,B_K$ 是将 $\\mathcal{D}$ 划分为 $K$ 个直径至少为 $60\\,\\mathrm{km}$ 的空间块的划分；令 $\\hat{Y}_{-B}(s)$ 表示由一个在块 $B$ 之外的数据上拟合的模型在位置 $s \\in B$ 处做出的预测。考虑恒等式\n$$\n\\mathbb{E}\\left[(Y(s) - \\hat{Y}(s))^2\\right] = \\mathrm{Var}(Y(s)) + \\mathrm{Var}(\\hat{Y}(s)) - 2\\,\\mathrm{Cov}(Y(s),\\hat{Y}(s)),\n$$\n以及一个事实，即在 LOO-CV 下，当 $\\hat{Y}(s)$ 受到其 $Y$ 值与 $Y(s)$ 相关的邻近点的影响时，$\\mathrm{Cov}(Y(s),\\hat{Y}(s))$ 通常为正。\n\n哪个选项最能解释空间块交叉验证如何为空间自相关的降水模型修正 LOO-CV，以及为何这对于在 $M_S$ 和 $M_C$ 之间的模型选择中评估简约性（奥卡姆剃刀）很重要？\n\nA) 空间块交叉验证会排除整个空间邻域，以便对于任何测试位置 $s \\in B$，训练集都不包含 $s$ 的相关范围 $a$ 内的点。这使得 $\\mathrm{Cov}(Y(s),\\hat{Y}_{-B}(s))$ 趋近于 $0$。相对于 $\\mathrm{Cov}(Y(s_i),\\hat{Y}_{-i}(s_i))0$ 的留一法交叉验证，这会抬高估计的误差，从而为块外泛化风险提供一个偏差更小的估计。结果是，那些利用局部自相关的过度复杂模型显得优势减弱，而简约性原则（当性能相当时选择 $M_S$）与真实的预测任务更加吻合。\n\nB) 空间块交叉验证通过汇集块来增加有效训练样本量，相对于 LOO-CV 降低了 $\\mathrm{Var}(\\hat{Y}_{-B}(s))$；这种方差的减小使得复杂模型比在 LOO-CV 下更有利，因此块交叉验证倾向于选择更复杂的模型，从而与简约性考虑无关。\n\nC) 当模型包含空间随机效应时，空间块交叉验证是不必要的，因为随机场已经考虑了自相关；LOO-CV 中的偏差会消失，简约性评估不受 LOO-CV 和块交叉验证之间选择的影响。\n\nD) 空间块交叉验证通过使训练集和测试集尽可能不相似，故意在估计的预测误差中引入负偏差，从而对简单模型的惩罚多于复杂模型，并鼓励选择 $M_C$，而不管自相关结构如何。\n\n选择唯一的最佳选项。",
            "solution": "评估问题陈述的有效性。\n\n**步骤 1：提取已知条件**\n-   **过程**：对一个流域的日降水量 $Y(s)$ 进行建模。\n-   **数据**：位于 $s \\in \\mathcal{D} \\subset \\mathbb{R}^2$ 的 $n=500$ 个雨量计。\n-   **随机结构**：潜在过程具有与马特恩（Matérn）协方差一致的半变异函数。\n-   **相关性**：相关性 $\\rho(h)$ 取决于分离距离 $h=\\lVert s-s' \\rVert$。\n-   **相关范围**：有效范围为 $a \\approx 50\\,\\mathrm{km}$，其中当 $h \\gtrsim a$ 时 $\\rho(h) \\approx 0$，当 $h \\lesssim a$ 时 $\\rho(h)  0$。\n-   **模型 $M_S$ (简约)**：$Y(s)$ 对海拔和纬度进行回归，并带有一个平滑的空间趋势。\n-   **模型 $M_C$ (复杂)**：与 $M_S$ 相同，但增加了 15 个协变量和一个短程高斯过程随机场。\n-   **LOO-CV 结果**：$M_C$ 的均方根误差（RMSE）低于 $M_S$。\n-   **空间块交叉验证结果**：使用直径 $\\geq 60\\,\\mathrm{km}$ 的非重叠块， $M_S$ 和 $M_C$ 的 RMSE 相当。\n-   **目标**：为一个新位置 $s_*$ 估计期望泛化风险 $R=\\mathbb{E}[L(Y(s_*),\\hat{f}(s_*))]$，损失函数 $L$ 为平方误差损失。\n-   **LOO-CV 问题**：标准的留一法交叉验证（LOO-CV）隐含地假设被留出的观测值与在其余数据上训练的预测器之间近似独立。在存在空间自相关的情况下，此假设被违反。\n-   **符号**：$\\hat{Y}_{-i}(s_i)$ 是使用除点 $i$ 之外的所有数据训练的模型在位置 $s_i$ 处的预测。$B_k$ 是直径 $\\geq 60\\,\\mathrm{km}$ 的空间块。$\\hat{Y}_{-B}(s)$ 是使用块 $B$ 之外的数据训练的模型在 $s \\in B$ 处的预测。\n-   **提供的恒等式**：均方误差由 $\\mathbb{E}\\left[(Y(s) - \\hat{Y}(s))^2\\right] = \\mathrm{Var}(Y(s)) + \\mathrm{Var}(\\hat{Y}(s)) - 2\\,\\mathrm{Cov}(Y(s),\\hat{Y}(s))$ 给出。\n-   **提供的事实**：由于受到邻近相关数据点的影响，在 LOO-CV 下，$\\mathrm{Cov}(Y(s),\\hat{Y}(s))$ 通常为正。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学依据**：该问题在空间统计学及其在环境建模中的应用领域有充分的依据。马特恩协方差、半变异函数、高斯过程、LOO-CV 和空间块交叉验证等概念都是标准概念。对于自相关数据，LOO-CV 的乐观偏差问题是该领域一个有据可查且至关重要的课题。\n-   **良定性**：该问题是良定的。它要求对一个明确定义的统计现象给出最佳的概念性解释，并提供了所有必要的背景和对比性的经验结果来引导推理。\n-   **客观性**：问题使用精确、客观和标准的科学术语陈述。没有主观或含糊的语言。\n-   **完整性与一致性**：问题是自洽且内部一致的。选择大于相关范围（$a \\approx 50\\,\\mathrm{km}$）的块直径（$\\geq 60\\,\\mathrm{km}$）是空间块交叉验证设计中的一个关键且正确的细节。两种交叉验证方法得出的对比结果，正是在所述条件下人们所期望的，从而构成了一个清晰且可解的难题。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。它描述了空间模型验证中的一个经典且重要的问题。解决方案将首先推导原理，然后评估各个选项。\n\n**从原理推导**\n交叉验证的目标是估计在新未见数据上的期望预测误差。对于空间过程，“新数据”通常意味着在不位于任何训练位置紧邻区域的某个位置 $s_*$ 进行预测。交叉验证估计的质量取决于它在多大程度上模拟了这种真实的泛化任务。\n\n对于一个通用预测器 $\\hat{Y}(s)$ 在位置 $s$ 的期望平方预测误差由下式给出：\n$$\n\\mathbb{E}\\left[(Y(s) - \\hat{Y}(s))^2\\right] = \\mathrm{Var}(Y(s)) + \\mathbb{E}\\left[(\\hat{Y}(s) - \\mathbb{E}[\\hat{Y}(s)])^2\\right] + (\\mathbb{E}[\\hat{Y}(s)] - \\mathbb{E}[Y(s)])^2\n$$\n或者，以问题中呈现的略有不同但相关的形式：\n$$\n\\mathbb{E}\\left[(Y(s) - \\hat{Y}(s))^2\\right] = \\mathrm{Var}(Y(s)) + \\mathrm{Var}(\\hat{Y}(s)) - 2\\,\\mathrm{Cov}(Y(s),\\hat{Y}(s))\n$$\n在这个分解中，$\\mathrm{Var}(Y(s))$ 是由于过程的自然变异性而产生的不可约误差。其余项取决于模型和训练数据。\n\n1.  **LOO-CV 分析**：在 LOO-CV 中，我们使用在排除 $(s_i, Y(s_i))$ 的数据集上训练的预测器 $\\hat{Y}_{-i}(s_i)$ 来估计在 $s_i$ 处的误差。由于空间自相关，训练集包含非常接近 $s_i$ 的点 $s_j$（即 $\\lVert s_i - s_j \\rVert \\ll a$）。相应的值 $Y(s_j)$ 与 $Y(s_i)$ 强相关。作为这些训练点的函数，预测器 $\\hat{Y}_{-i}(s_i)$ 与真实值 $Y(s_i)$ 变得相关。这导致一个非零的正协方差项，$\\mathrm{Cov}(Y(s_i), \\hat{Y}_{-i}(s_i))  0$。其后果是，在所有 $i$ 上平均的估计误差是对真实泛化误差的低估，因为项 $-2\\,\\mathrm{Cov}(Y(s_i),\\hat{Y}_{-i}(s_i))$ 人为地减小了总和。这给出了一个过于乐观的性能度量。模型被评估的是其在极短距离内进行插值的能力，而不是外推到新区域的能力。复杂模型 $M_C$ 具有明确的短程随机场，其设计旨在擅长于这种局部插值，因此它从这种偏差中获益不成比例，这解释了它在 LOO-CV 下有更低的 RMSE。\n\n2.  **空间块交叉验证分析**：该方法旨在打破训练集和测试集之间的依赖关系。通过留出整个数据块 $B$，其中块的直径（$\\geq 60\\,\\mathrm{km}$）超过了相关范围（$a \\approx 50\\,\\mathrm{km}$），我们确保对于任何测试点 $s \\in B$，整个训练集都位于其相关邻域之外。因此，预测器 $\\hat{Y}_{-B}(s)$ 是由与真实值 $Y(s)$ 近似不相关的数据构建的。这将协方差项驱动至零：$\\mathrm{Cov}(Y(s), \\hat{Y}_{-B}(s)) \\approx 0$。由此产生的误差估计 $\\mathbb{E}\\left[(Y(s) - \\hat{Y}_{-B}(s))^2\\right] \\approx \\mathrm{Var}(Y(s)) + \\mathrm{Var}(\\hat{Y}_{-B}(s))$，不再因协方差项而产生乐观偏差。它为模型外推到真正新位置的能力提供了一个更现实的评估。\n\n3.  **对简约性的影响**：块交叉验证的结果显示 $M_S$ 和 $M_C$ 的 RMSE 相当。这表明 $M_C$ 的额外复杂性（15个协变量和随机场）对于在新区域进行样本外预测没有显著的好处。它在 LOO-CV 下的明显优势是 flawed 验证过程的人为产物。简约性原则（奥卡姆剃刀）规定，如果两个模型具有相似的预测能力，则应选择较简单的那个。因此，基于空间块交叉验证的无偏评估，简约模型 $M_S$ 是更可取的选择。\n\n**逐项分析**\n\n**A) 空间块交叉验证会排除整个空间邻域，以便对于任何测试位置 $s \\in B$，训练集都不包含 $s$ 的相关范围 $a$ 内的点。这使得 $\\mathrm{Cov}(Y(s),\\hat{Y}_{-B}(s))$ 趋近于 $0$。相对于 $\\mathrm{Cov}(Y(s_i),\\hat{Y}_{-i}(s_i))0$ 的留一法交叉验证，这会抬高估计的误差，从而为块外泛化风险提供一个偏差更小的估计。结果是，那些利用局部自相关的过度复杂模型显得优势减弱，而简约性原则（当性能相当时选择 $M_S$）与真实的预测任务更加吻合。**\n- 该选项正确描述了空间块交叉验证的机制：确保训练集和测试集之间的空间分离。\n- 它正确地指出了其后果：将预测值与真实值之间的协方差 $\\mathrm{Cov}(Y(s),\\hat{Y}_{-B}(s))$ 减小至趋近于零。\n- 它正确地将其与 LOO-CV 进行对比，在 LOO-CV 中协方差为正，导致误差被低估。术语“抬高”正确地描述了块交叉验证的误差估计将比 LOO-CV 的估计更高（不那么乐观）。\n- 它正确地得出结论，这会产生对真实泛化风险的偏差较小的估计。\n- 它正确地解释了对模型选择的影响：像 $M_C$ 这样的复杂模型的人为优势被移除，从而可以根据相当的性能，正确应用简约性原则。\n- **结论：正确。**\n\n**B) 空间块交叉验证通过汇集块来增加有效训练样本量，相对于 LOO-CV 降低了 $\\mathrm{Var}(\\hat{Y}_{-B}(s))$；这种方差的减小使得复杂模型比在 LOO-CV 下更有利，因此块交叉验证倾向于选择更复杂的模型，从而与简约性考虑无关。**\n- 空间块交叉验证增加训练样本量的假设是错误的。对于 K 折块交叉验证，每折的训练集大小是总数据的 $((K-1)/K)$，这小于 LOO-CV 每折中使用的 $n-1$ 个点。\n- 较小的训练样本量通常会导致预测器方差*更高*，而不是更低。因此，$\\mathrm{Var}(\\hat{Y}_{-B}(s))$ 预期会大于或等于 $\\mathrm{Var}(\\hat{Y}_{-i}(s_i))$。\n- 整个推理链都基于不正确的前提。\n- **结论：错误。**\n\n**C) 当模型包含空间随机效应时，空间块交叉验证是不必要的，因为随机场已经考虑了自相关；LOO-CV 中的偏差会消失，简约性评估不受 LOO-CV 和块交叉验证之间选择的影响。**\n- 这是一个严重的误解。模型*考虑*了某个数据特征（如自相关）并不能使*评估方法*免于缺陷。LOO-CV 中的偏差源于数据分割方案允许信息泄漏，而这与模型结构无关。事实上，一个善于捕捉自相关的模型（如 $M_C$）最能利用这种泄漏，从而使偏差变得更糟。\n- 问题陈述中给出的经验结果直接反驳了这一说法：交叉验证方法的选择极大地改变了 $M_S$ 和 $M_C$ 的相对性能。\n- **结论：错误。**\n\n**D) 空间块交叉验证通过使训练集和测试集尽可能不相似，故意在估计的预测误差中引入负偏差，从而对简单模型的惩罚多于复杂模型，并鼓励选择 $M_C$，而不管自相关结构如何。**\n- 空间块交叉验证纠正的是 LOO-CV 的*负*偏差（低估）。它产生一个更高、更现实的误差估计。说它“引入负偏差”是不正确的。\n- 它并不会更多地惩罚简单模型。它惩罚的是那些通过利用 LOO-CV 中的局部信息泄漏来“作弊”的模型。正如问题中所示，失去优势的是复杂模型 $M_C$，而不是简单模型 $M_S$。\n- 它鼓励选择 $M_C$ 的结论与问题中描述的结果相反。\n- **结论：错误。**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}