{
    "hands_on_practices": [
        {
            "introduction": "Before a model can be trusted to simulate the real world (validation), we must first ensure its underlying equations are solved correctly (verification). This exercise provides hands-on practice in code verification, a foundational skill for any computational modeler. You will implement standard numerical schemes for a basic transport equation and then apply a grid refinement study to computationally measure the order of accuracy, $p$, confirming that your code converges at its theoretically expected rate. ",
            "id": "3896009",
            "problem": "You are asked to design and implement a self-contained computational study to verify spatial discretizations for a one-dimensional linear transport equation via grid refinement and Richardson extrapolation, and to compute the observed order of accuracy. Begin from the governing equation and core definitions. Then derive algorithmic steps to compute differences across multiple grids and estimate the convergence rate.\n\nConsider the one-dimensional linear advection (transport) equation with periodic boundary conditions:\n$$\n\\frac{\\partial u}{\\partial t} + c \\frac{\\partial u}{\\partial x} = 0,\n$$\non the spatial domain $[0, L]$ with $L = 1$ (meters), and constant advection velocity $c = 1$ (meters per second). Use an initial condition\n$$\nu(x, 0) = \\sin(2\\pi x) + \\frac{1}{2}\\cos(4\\pi x),\n$$\nwhich is smooth and periodic over $[0, L]$. Evolve the solution to a final time $T = 0.2$ (seconds). The exact solution is given by\n$$\nu_{\\mathrm{exact}}(x, t) = u(x - ct \\bmod L, 0),\n$$\nwhich follows from the invariance of the shape under translation for constant advection.\n\nFrom the fundamental base:\n- Conservation of advected quantity implies discrete flux differences as the driver of temporal changes.\n- The Courant–Friedrichs–Lewy (CFL) condition ensures stability for explicit schemes; use a fixed $ \\mathrm{CFL} $ number with $0 < \\mathrm{CFL} \\le 1$.\n- On a uniform grid with $N$ points, grid spacing $h = L/N$, and time step $\\Delta t$ chosen to satisfy $c \\Delta t / h = \\nu$ (a chosen $ \\mathrm{CFL} $ number), construct consistent finite difference updates.\n\nImplement two spatial schemes:\n1. A first-order upwind scheme for $c > 0$, using forward Euler in time and upwind differences for space.\n2. A second-order Lax–Wendroff scheme, using a two-term Taylor expansion in time and centered differences in space.\n\nDefine a grid refinement study over triplets of grids with sizes $(N_1, N_2, N_3)$ such that the refinement factor $r$ satisfies $N_2 = r N_1$ and $N_3 = r N_2$, where $r$ is an integer. For each scheme, compute numerical solutions $u_{h_1}$, $u_{h_2}$, and $u_{h_3}$ at $t = T$ on these grids. Construct a restriction operator from fine to coarse grids by sampling every $r$-th point so that discrete comparisons occur at shared locations. Use the discrete $L^2$ norm with physical weighting to measure differences; for a grid with spacing $h$, the discrete $L^2$ norm of a vector $v$ is\n$$\n\\| v \\|_{2,h} = \\sqrt{ h \\sum_{i=1}^{N} v_i^2 }.\n$$\n\nUnder asymptotic grid convergence with error scaling $\\| u_h - u_{\\mathrm{exact}} \\|_{2,h} \\approx C h^p$ for some constant $C$ and observed order $p$, Richardson extrapolation yields that the ratio of successive solution differences computed on appropriately restricted grids is directly connected to $p$ via the refinement factor $r$. Use this relationship to derive the observed order $p$ from three grids for each test case, without using the exact solution. All computations must be performed in double precision floats.\n\nUse $L$ in meters, $c$ in meters per second, and $T$ in seconds. No physical quantity in the final answers requires unit reporting since the observed order of accuracy $p$ is dimensionless.\n\nTest Suite:\n- Case $1$: First-order upwind, $(N_1, N_2, N_3) = (64, 128, 256)$, $r = 2$, $L = 1$, $c = 1$, $T = 0.2$, $\\mathrm{CFL} = 0.5$.\n- Case $2$: Second-order Lax–Wendroff, $(N_1, N_2, N_3) = (64, 128, 256)$, $r = 2$, $L = 1$, $c = 1$, $T = 0.2$, $\\mathrm{CFL} = 0.5$.\n- Case $3$: First-order upwind (coarser grids, a boundary case), $(N_1, N_2, N_3) = (16, 32, 64)$, $r = 2$, $L = 1$, $c = 1$, $T = 0.2$, $\\mathrm{CFL} = 0.5$.\n- Case $4$: Second-order Lax–Wendroff (finer grids, approaching asymptotic regime), $(N_1, N_2, N_3) = (128, 256, 512)$, $r = 2$, $L = 1$, $c = 1$, $T = 0.2$, $\\mathrm{CFL} = 0.5$.\n\nYour program must:\n- Discretize the problem according to the specified scheme and parameters.\n- Integrate to time $T$ using the chosen $ \\mathrm{CFL} $ number.\n- For each case, compute the observed order $p$ using Richardson extrapolation from the three solutions on multiple meshes, via differences restricted to a shared grid as described above.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[p_1, p_2, p_3, p_4]$). Each $p_i$ must be a float. No other text must be printed.\n\nThe final output has no physical units because the observed order of accuracy $p$ is dimensionless. Angles, if any, should be in radians, but none are used. Percentages must not be used anywhere; all ratios must be expressed as decimals. The output must be reproducible with no external input or files.",
            "solution": "The objective of this study is to computationally verify the theoretical order of accuracy, $p$, for two distinct finite difference schemes applied to the one-dimensional linear advection equation. This verification is performed via a grid refinement study. The observed order of accuracy is calculated using Richardson extrapolation applied to numerical solutions from a triplet of successively refined grids. This method allows for the estimation of $p$ without requiring access to the exact analytical solution.\n\nThe governing partial differential equation (PDE) is the linear advection equation on a spatial domain $x \\in [0, L]$:\n$$\n\\frac{\\partial u}{\\partial t} + c \\frac{\\partial u}{\\partial x} = 0\n$$\nHere, $u(x, t)$ represents the advected quantity, $c$ is the constant advection velocity, and the system is subject to periodic boundary conditions, $u(0, t) = u(L, t)$. The problem specifies the physical parameters as $L=1$ m, $c=1$ m/s, and a final integration time of $T=0.2$ s. The simulation begins from a smooth, periodic initial condition:\n$$\nu(x, 0) = \\sin(2\\pi x) + \\frac{1}{2}\\cos(4\\pi x)\n$$\nThe spatial domain is discretized into $N$ uniform cells of width $h = L/N$, with grid points located at $x_i = i h$ for $i = 0, 1, \\dots, N-1$. The numerical solution at grid point $i$ and time step $n$ is denoted by $u_i^n$, which approximates the exact solution $u(x_i, n\\Delta t)$. The time step $\\Delta t$ is determined by fixing the Courant–Friedrichs–Lewy (CFL) number, $\\nu = c \\Delta t / h$. For the stability of the explicit schemes employed, it is necessary that $\\nu \\le 1$. In this study, we use a target CFL number $\\nu_{\\text{target}} = 0.5$. The number of time steps is set to $N_t = \\lceil T/( \\nu_{\\text{target}} h / c) \\rceil$, and the time step is then adjusted to $\\Delta t = T/N_t$. This procedure ensures that the final time $T$ is reached precisely and that the effective CFL number $\\nu = c \\Delta t / h \\le \\nu_{\\text{target}}$.\n\nTwo numerical schemes are implemented for the spatial discretization.\n\n**1. First-Order Upwind Scheme:**\nFor a positive advection velocity $c > 0$, the \"upwind\" direction corresponds to the negative $x$-direction. The spatial derivative is approximated using a first-order backward difference:\n$$\n\\left(\\frac{\\partial u}{\\partial x}\\right)_i^n \\approx \\frac{u_i^n - u_{i-1}^n}{h}\n$$\nDiscretizing the PDE using the forward Euler method for the temporal derivative, $\\frac{u_i^{n+1} - u_i^n}{\\Delta t} = -c \\left(\\frac{\\partial u}{\\partial x}\\right)_i^n$, we derive the update formula:\n$$\nu_i^{n+1} = u_i^n - \\frac{c \\Delta t}{h} (u_i^n - u_{i-1}^n) = u_i^n - \\nu (u_i^n - u_{i-1}^n)\n$$\nThe periodic boundary condition implies that for $i=0$, the value $u_{-1}^n$ is taken as $u_{N-1}^n$. This scheme is theoretically first-order accurate in both space and time, so we expect $p \\approx 1$.\n\n**2. Second-Order Lax–Wendroff Scheme:**\nTo achieve second-order accuracy, we begin with a second-order Taylor series expansion in time:\n$$\nu(x, t+\\Delta t) = u(x,t) + \\Delta t \\frac{\\partial u}{\\partial t} + \\frac{(\\Delta t)^2}{2} \\frac{\\partial^2 u}{\\partial t^2} + O((\\Delta t)^3)\n$$\nFrom the governing PDE, we can substitute the time derivatives with spatial derivatives: $\\frac{\\partial u}{\\partial t} = -c \\frac{\\partial u}{\\partial x}$ and, by extension, $\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2 u}{\\partial x^2}$. This transforms the Taylor expansion into:\n$$\nu(x, t+\\Delta t) = u(x,t) - c \\Delta t \\frac{\\partial u}{\\partial x} + \\frac{c^2 (\\Delta t)^2}{2} \\frac{\\partial^2 u}{\\partial x^2} + O((\\Delta t)^3)\n$$\nWe then discretize the spatial derivatives using second-order centered difference approximations:\n$$\n\\left(\\frac{\\partial u}{\\partial x}\\right)_i^n \\approx \\frac{u_{i+1}^n - u_{i-1}^n}{2h} \\quad \\text{and} \\quad \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_i^n \\approx \\frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{h^2}\n$$\nSubstituting these approximations into the expansion and using the definition $\\nu = c \\Delta t/h$, we obtain the Lax-Wendroff update formula:\n$$\nu_i^{n+1} = u_i^n - \\frac{\\nu}{2}(u_{i+1}^n - u_{i-1}^n) + \\frac{\\nu^2}{2}(u_{i+1}^n - 2u_i^n + u_{i-1}^n)\n$$\nThis scheme is second-order accurate in both space and time, and thus we expect $p \\approx 2$.\n\n**Verification via Richardson Extrapolation:**\nTo determine the observed order of accuracy $p$, we assume that the error in a numerical solution $u_h$ on a grid with spacing $h$ behaves asymptotically as $\\| u_h - u_{\\mathrm{exact}} \\|_{2,h} \\approx K h^p$ for some constant $K$.\n\nWe use solutions on three grids of sizes $N_1$, $N_2 = r N_1$, and $N_3 = r N_2 = r^2 N_1$, with corresponding grid spacings $h_1 = L/N_1$, $h_2 = h_1/r$, and $h_3 = h_1/r^2$. Let the numerical solutions on these grids at time $T$ be $u_1$, $u_2$, and $u_3$. To compare them, we restrict the solutions from the finer grids onto the coarsest grid ($N_1$ points) by sampling. Let $f_1 = u_1$, $f_2$ be the solution $u_2$ restricted by taking every $r$-th point, and $f_3$ be the solution $u_3$ restricted by taking every $(r^2)$-th point.\n\nThe error of each solution, evaluated on the common coarse grid, is approximately $f_k(x) - u_{\\mathrm{exact}}(x) \\approx C(x) h_k^p$. The differences between consecutive solutions are then:\n$$\nf_2(x) - f_1(x) \\approx C(x) (h_2^p - h_1^p) = C(x) h_1^p (r^{-p} - 1)\n$$\n$$\nf_3(x) - f_2(x) \\approx C(x) (h_3^p - h_2^p) = C(x) h_2^p (r^{-p} - 1) = C(x) (h_1/r)^p (r^{-p} - 1)\n$$\nWe compute the discrete $L^2$ norm of these difference vectors on the coarse grid, defined as $\\|v\\|_{2,h_1} = \\sqrt{h_1 \\sum_i v_i^2}$. Let $D_{21} = \\|f_2 - f_1\\|_{2,h_1}$ and $D_{32} = \\|f_3 - f_2\\|_{2,h_1}$. The ratio of these norms is:\n$$\n\\frac{D_{21}}{D_{32}} \\approx \\frac{\\|C(x) h_1^p (r^{-p} - 1)\\|_{2,h_1}}{\\|C(x) (h_1/r)^p (r^{-p} - 1)\\|_{2,h_1}} = \\frac{h_1^p}{(h_1/r)^p} = r^p\n$$\nSolving for $p$ yields the formula for the observed order of accuracy:\n$$\np = \\frac{\\log(D_{21} / D_{32})}{\\log(r)}\n$$\nThis algorithm is implemented in double-precision floating-point arithmetic to compute $p$ for each test case specified in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef u_initial(x, L):\n    \"\"\"\n    Computes the initial condition u(x, 0) for the advection equation.\n    \"\"\"\n    return np.sin(2 * np.pi * x / L) + 0.5 * np.cos(4 * np.pi * x / L)\n\ndef upwind_step(u, nu):\n    \"\"\"\n    Performs one time step of the first-order upwind scheme.\n    u_i^{n+1} = u_i^n - nu * (u_i^n - u_{i-1}^n)\n    \"\"\"\n    u_prev = np.roll(u, 1)  # Periodicity handled by np.roll\n    return u - nu * (u - u_prev)\n\ndef lax_wendroff_step(u, nu):\n    \"\"\"\n    Performs one time step of the second-order Lax-Wendroff scheme.\n    u_i^{n+1} = u_i^n - nu/2 * (u_{i+1}^n - u_{i-1}^n) + nu^2/2 * (u_{i+1}^n - 2u_i^n + u_{i-1}^n)\n    \"\"\"\n    u_prev = np.roll(u, 1)   # u_{i-1}\n    u_next = np.roll(u, -1)  # u_{i+1}\n    term1 = -0.5 * nu * (u_next - u_prev)\n    term2 = 0.5 * nu**2 * (u_next - 2 * u + u_prev)\n    return u + term1 + term2\n\ndef solve_pde(N, L, c, T, cfl, scheme_name):\n    \"\"\"\n    Solves the 1D linear advection equation until time T.\n    \n    Returns the numerical solution u at final time T.\n    \"\"\"\n    h = L / N\n    # Ideal dt to match the CFL target\n    dt_ideal = cfl * h / c\n    # Calculate number of steps to reach T, then adjust dt to hit T exactly.\n    n_steps = int(np.ceil(T / dt_ideal))\n    dt = T / n_steps\n    # The effective CFL number nu will be <= the target cfl.\n    nu = c * dt / h\n    \n    # Define the grid, excluding the endpoint L due to periodicity\n    x = np.linspace(0, L, N, endpoint=False)\n    u = u_initial(x, L)\n\n    if scheme_name == 'upwind':\n        step_func = upwind_step\n    elif scheme_name == 'lax_wendroff':\n        step_func = lax_wendroff_step\n    else:\n        raise ValueError(f\"Unknown scheme: {scheme_name}\")\n\n    for _ in range(n_steps):\n        u = step_func(u, nu)\n    \n    return u\n\ndef l2_norm(v, h):\n    \"\"\"\n    Computes the discrete L2 norm: sqrt(h * sum(v_i^2)).\n    \"\"\"\n    return np.sqrt(h * np.sum(v**2))\n\ndef compute_order_of_accuracy(case):\n    \"\"\"\n    Computes the observed order of accuracy p from a grid refinement study.\n    \"\"\"\n    scheme, N_tuple, r, L, c, T, cfl = case\n    N1, N2, N3 = N_tuple\n\n    # 1. Solve the PDE on the three grids\n    u1 = solve_pde(N1, L, c, T, cfl, scheme)\n    u2 = solve_pde(N2, L, c, T, cfl, scheme)\n    u3 = solve_pde(N3, L, c, T, cfl, scheme)\n\n    # 2. Restrict solutions from fine grids to the coarsest grid\n    u2_on_1 = u2[::r]\n    u3_on_1 = u3[::(r*r)]\n    \n    # 3. Compute difference vectors on the coarse grid\n    diff_21 = u2_on_1 - u1\n    diff_32 = u3_on_1 - u2_on_1\n    \n    # 4. Compute L2 norms of the differences using the coarse grid spacing h1\n    h1 = L / N1\n    norm_21 = l2_norm(diff_21, h1)\n    norm_32 = l2_norm(diff_32, h1)\n    \n    # 5. Calculate the observed order of accuracy p\n    # Handle potential for norm_32 being zero to avoid division by zero or log(0)\n    if norm_32 == 0.0:\n        return np.nan  # p is undefined or infinite\n\n    ratio = norm_21 / norm_32\n    \n    # If ratio is non-positive, log is undefined. This can happen if not in\n    # the asymptotic regime or with oscillating convergence.\n    if ratio <= 0:\n        return np.nan\n        \n    p = np.log(ratio) / np.log(r)\n    return p\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: (scheme_name, (N1, N2, N3), refinement_factor r, L, c, T, CFL)\n    test_cases = [\n        ('upwind', (64, 128, 256), 2, 1.0, 1.0, 0.2, 0.5),\n        ('lax_wendroff', (64, 128, 256), 2, 1.0, 1.0, 0.2, 0.5),\n        ('upwind', (16, 32, 64), 2, 1.0, 1.0, 0.2, 0.5),\n        ('lax_wendroff', (128, 256, 512), 2, 1.0, 1.0, 0.2, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        p = compute_order_of_accuracy(case)\n        results.append(p)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "When validating a model against time-series data, a common challenge is the presence of autocorrelation in the model residuals, meaning the error at one time step is not independent of the previous one. This \"memory\" in the error structure can lead to a false sense of confidence in your model's performance. This practice delves into this critical statistical issue by having you derive the concept of an \"effective sample size,\" $n_{\\text{eff}}$, which quantifies how serial correlation inflates the variance of validation metrics and widens their confidence intervals. ",
            "id": "3895941",
            "problem": "A hydrologic model is being validated against observed daily streamflow. Let the residual sequence $\\{e_t\\}_{t=1}^{n}$ denote model-minus-observation differences. A key performance metric is the mean bias, computed as the sample mean $\\bar{e} = \\frac{1}{n}\\sum_{t=1}^{n} e_t$. Suppose the residuals are weakly stationary with zero mean and follow a first-order autoregressive (AR) structure: their lag-$k$ autocorrelation is $\\rho_k$ and satisfies $\\rho_k = \\phi^{k}$ for some $|\\phi|<1$. Assume $n$ is large enough that end effects can be neglected. \n\nStarting from the definitions of variance, covariance, and autocovariance for weakly stationary processes, derive an expression for an effective sample size $n_{\\text{eff}}$ such that $\\operatorname{Var}(\\bar{e}) \\approx \\sigma_{e}^{2}/n_{\\text{eff}}$, where $\\sigma_{e}^{2}$ is the marginal variance of $e_t$. Then consider a two-sided $0.95$ confidence interval (CI) for the mean bias under a normal approximation. Define the multiplicative inflation factor $F$ as the ratio of the CI half-width under autocorrelated residuals to the CI half-width under independent residuals with the same $\\sigma_{e}^{2}$ and $n$. \n\nGiven $n=730$ and $\\hat{\\phi}=0.6$, compute $F$. Round your answer to four significant figures and express it as a pure number (dimensionless).",
            "solution": "The variance of the sample mean $\\bar{e} = \\frac{1}{n}\\sum_{t=1}^{n} e_t$ of a weakly stationary time series with marginal variance $\\sigma_e^2$ and autocorrelation function $\\rho_k$ is given by:\n$$\n\\operatorname{Var}(\\bar{e}) = \\frac{\\sigma_e^2}{n} \\left( 1 + 2\\sum_{k=1}^{n-1} \\left(1-\\frac{k}{n}\\right)\\rho_k \\right)\n$$\nFor a large sample size $n$ and a decaying autocorrelation, this can be approximated as:\n$$\n\\operatorname{Var}(\\bar{e}) \\approx \\frac{\\sigma_e^2}{n} \\left( 1 + 2\\sum_{k=1}^{\\infty} \\rho_k \\right)\n$$\nFor the specified first-order autoregressive (AR(1)) process, $\\rho_k = \\phi^k$. The infinite sum is a geometric series $\\sum_{k=1}^{\\infty} \\phi^k = \\frac{\\phi}{1-\\phi}$ for $|\\phi|<1$. Substituting this into the variance expression yields:\n$$\n\\operatorname{Var}(\\bar{e}) \\approx \\frac{\\sigma_e^2}{n} \\left( 1 + 2\\frac{\\phi}{1-\\phi} \\right) = \\frac{\\sigma_e^2}{n} \\left( \\frac{1-\\phi+2\\phi}{1-\\phi} \\right) = \\frac{\\sigma_e^2}{n} \\left( \\frac{1+\\phi}{1-\\phi} \\right)\n$$\nThe effective sample size $n_{\\text{eff}}$ is defined such that $\\operatorname{Var}(\\bar{e}) = \\sigma_e^2/n_{\\text{eff}}$. Equating the two expressions for the variance gives:\n$$\n\\frac{\\sigma_e^2}{n_{\\text{eff}}} = \\frac{\\sigma_e^2}{n} \\left( \\frac{1+\\phi}{1-\\phi} \\right) \\implies n_{\\text{eff}} = n \\left( \\frac{1-\\phi}{1+\\phi} \\right)\n$$\nThe confidence interval (CI) half-width is proportional to the standard error of the mean, $\\operatorname{SE}(\\bar{e}) = \\sqrt{\\operatorname{Var}(\\bar{e})}$. The inflation factor $F$ is the ratio of the CI half-width for the autocorrelated case to that of the independent case (where $\\phi=0$). This is equivalent to the ratio of the standard errors:\n$$\nF = \\frac{\\operatorname{SE}(\\bar{e})_{\\text{auto}}}{\\operatorname{SE}(\\bar{e})_{\\text{indep}}} = \\frac{\\sqrt{\\frac{\\sigma_e^2}{n} \\left( \\frac{1+\\phi}{1-\\phi} \\right)}}{\\sqrt{\\frac{\\sigma_e^2}{n}}} = \\sqrt{\\frac{1+\\phi}{1-\\phi}}\n$$\nUsing the given value $\\hat{\\phi}=0.6$:\n$$\nF = \\sqrt{\\frac{1+0.6}{1-0.6}} = \\sqrt{\\frac{1.6}{0.4}} = \\sqrt{4} = 2\n$$\nRounding to four significant figures, the result is $2.000$.",
            "answer": "$$\\boxed{2.000}$$"
        },
        {
            "introduction": "Many environmental prediction systems now issue probabilistic forecasts, which require more sophisticated validation tools than simple deterministic metrics like root-mean-square error. This practice introduces a cornerstone of probabilistic forecast verification: the Brier Score and its decomposition. By partitioning the score into components of reliability, resolution, and uncertainty, you will learn to diagnose not just *how* accurate a forecast is, but *why*, distinguishing a model's ability to issue trustworthy probabilities from its capacity to discriminate between different outcomes. ",
            "id": "3896013",
            "problem": "A hydrometeorological prediction system issues daily probabilistic forecasts for the binary event “region-mean precipitation exceeds $20$ millimeters.” Over a season of $N = 750$ forecast–verification pairs, the system’s issued probabilities take on five discrete values and the corresponding observations are summarized by the following forecast bins. For bin $k$ with issued probability $f_k$, let $n_k$ be the number of forecasts in the bin and let $e_k$ be the number of times the event occurred in that bin. The data are:\n- Bin $1$: $f_1 = 0.05$, $n_1 = 120$, $e_1 = 6$.\n- Bin $2$: $f_2 = 0.15$, $n_2 = 150$, $e_2 = 30$.\n- Bin $3$: $f_3 = 0.35$, $n_3 = 200$, $e_3 = 70$.\n- Bin $4$: $f_4 = 0.55$, $n_4 = 180$, $e_4 = 99$.\n- Bin $5$: $f_5 = 0.75$, $n_5 = 100$, $e_5 = 80$.\n\nStarting from the definition of the Brier Score (BS) for a probabilistic forecast of a binary outcome, $BS \\equiv \\frac{1}{N}\\sum_{i=1}^{N} \\left( f_i - Y_i \\right)^2$, where $Y_i \\in \\{0,1\\}$ is the verifying outcome indicator for case $i$ and $f_i \\in [0,1]$ is the issued probability, derive the Murphy decomposition that partitions $BS$ into three interpretable components associated with the binning scheme above. Use only fundamental probabilistic identities such as the law of total expectation and conditional means, and state clearly how each component reflects reliability, resolution, and uncertainty in the forecasts relative to the observed outcomes.\n\nThen, using the five bins provided, compute the sample estimates of the three components. Define the empirical event rate in bin $k$ as $o_k \\equiv \\frac{e_k}{n_k}$ and the overall base rate as $\\bar{o} \\equiv \\frac{1}{N}\\sum_{k=1}^{5} e_k$. Treat each $f_k$ as the mean forecast within its bin. Round each of the three component values to four significant figures and express them as dimensionless numbers. Report your final answer in the order: reliability, resolution, uncertainty.",
            "solution": "The Brier Score (BS) for a probabilistic forecast of a binary event is defined as the mean squared error between the forecast probability and the binary verifying outcome, namely\n$$\nBS \\equiv \\frac{1}{N} \\sum_{i=1}^{N} \\left( f_i - Y_i \\right)^2,\n$$\nwhere $Y_i \\in \\{0,1\\}$ and $f_i \\in [0,1]$. When forecasts are grouped into $K$ bins based on their issued probability $f_k$, the BS can be partitioned using the Murphy decomposition:\n$$\nBS = \\underbrace{\\sum_{k=1}^{K} \\frac{n_k}{N} \\left( f_k - o_k \\right)^2}_{\\text{Reliability}}\n\\;-\\;\n\\underbrace{\\sum_{k=1}^{K} \\frac{n_k}{N} \\left( o_k - \\bar{o} \\right)^2}_{\\text{Resolution}}\n\\;+\\;\n\\underbrace{\\bar{o}(1 - \\bar{o})}_{\\text{Uncertainty}}.\n$$\nHere, $n_k$ is the number of forecasts in bin $k$, $N$ is the total number of forecasts, $o_k$ is the observed frequency of the event in bin $k$ ($o_k = e_k/n_k$), and $\\bar{o}$ is the overall climatological frequency of the event ($\\bar{o} = (\\sum e_k) / N$).\n\nInterpretation:\n- **Reliability** measures the correspondence between forecast probabilities and observed frequencies. A perfectly reliable forecast has $f_k = o_k$ for all bins, making this component zero (a better score).\n- **Resolution** measures the ability of the forecast to separate events from non-events by issuing different probabilities. It is a positive term subtracted from the score, so higher resolution is better.\n- **Uncertainty** depends only on the climatological frequency of the event and represents the inherent difficulty of the forecast problem. It is the score one would obtain by always forecasting the climatological mean $\\bar{o}$.\n\nWe now compute each component using the provided data.\n\n**Step 1: Compute preliminary statistics ($o_k$, $n_k/N$, and $\\bar{o}$)**\nTotal forecasts $N = 120 + 150 + 200 + 180 + 100 = 750$.\nTotal events $\\sum e_k = 6 + 30 + 70 + 99 + 80 = 285$.\nOverall base rate: $\\bar{o} = \\frac{285}{750} = 0.38$.\n\nBin-specific statistics:\n- Bin 1: $f_1 = 0.05$, $n_1/N = 120/750 = 0.16$, $o_1 = 6/120 = 0.05$.\n- Bin 2: $f_2 = 0.15$, $n_2/N = 150/750 = 0.20$, $o_2 = 30/150 = 0.20$.\n- Bin 3: $f_3 = 0.35$, $n_3/N = 200/750 \\approx 0.2667$, $o_3 = 70/200 = 0.35$.\n- Bin 4: $f_4 = 0.55$, $n_4/N = 180/750 = 0.24$, $o_4 = 99/180 = 0.55$.\n- Bin 5: $f_5 = 0.75$, $n_5/N = 100/750 \\approx 0.1333$, $o_5 = 80/100 = 0.80$.\n\n**Step 2: Compute Reliability**\n$$ \\text{Reliability} = \\sum_{k=1}^{5} \\frac{n_k}{N} \\left( f_k - o_k \\right)^2 $$\n- Bin 1: $0.16 \\times (0.05 - 0.05)^2 = 0$.\n- Bin 2: $0.20 \\times (0.15 - 0.20)^2 = 0.20 \\times 0.0025 = 0.0005$.\n- Bin 3: $(200/750) \\times (0.35 - 0.35)^2 = 0$.\n- Bin 4: $0.24 \\times (0.55 - 0.55)^2 = 0$.\n- Bin 5: $(100/750) \\times (0.75 - 0.80)^2 = (2/15) \\times 0.0025 \\approx 0.0003333$.\n$$ \\text{Reliability} = 0.0005 + 0.0003333... = 0.0008333... $$\nTo four significant figures, Reliability is $8.333 \\times 10^{-4}$.\n\n**Step 3: Compute Resolution**\n$$ \\text{Resolution} = \\sum_{k=1}^{5} \\frac{n_k}{N} \\left( o_k - \\bar{o} \\right)^2 $$\n- Bin 1: $0.16 \\times (0.05 - 0.38)^2 = 0.16 \\times (-0.33)^2 = 0.017424$.\n- Bin 2: $0.20 \\times (0.20 - 0.38)^2 = 0.20 \\times (-0.18)^2 = 0.00648$.\n- Bin 3: $(200/750) \\times (0.35 - 0.38)^2 = (4/15) \\times (-0.03)^2 = 0.00024$.\n- Bin 4: $0.24 \\times (0.55 - 0.38)^2 = 0.24 \\times (0.17)^2 = 0.006936$.\n- Bin 5: $(100/750) \\times (0.80 - 0.38)^2 = (2/15) \\times (0.42)^2 = 0.02352$.\n$$ \\text{Resolution} = 0.017424 + 0.00648 + 0.00024 + 0.006936 + 0.02352 = 0.0546 $$\nTo four significant figures, Resolution is $5.460 \\times 10^{-2}$.\n\n**Step 4: Compute Uncertainty**\n$$ \\text{Uncertainty} = \\bar{o} (1 - \\bar{o}) = 0.38 \\times (1 - 0.38) = 0.38 \\times 0.62 = 0.2356 $$\nTo four significant figures, Uncertainty is $2.356 \\times 10^{-1}$.\n\nFinal answer in the order: reliability, resolution, uncertainty.",
            "answer": "$$\\boxed{\\begin{pmatrix}8.333 \\times 10^{-4} & 5.460 \\times 10^{-2} & 2.356 \\times 10^{-1}\\end{pmatrix}}$$"
        }
    ]
}