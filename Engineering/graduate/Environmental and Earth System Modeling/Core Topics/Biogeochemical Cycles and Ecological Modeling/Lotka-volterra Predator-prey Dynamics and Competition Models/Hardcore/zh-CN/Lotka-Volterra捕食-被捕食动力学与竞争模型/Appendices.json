{
    "hands_on_practices": [
        {
            "introduction": "本节的实践练习将从分析模型的基础入手。我们将超越最简单的 Lotka-Volterra 模型，探讨一个更贴近现实的场景，该场景同时包含了猎物种群的逻辑斯谛增长和捕食者种群内的自我调节机制 。通过推导共存平衡点，我们将练习寻找系统稳态的核心分析技能，这是理解任何动力系统长期行为的第一步。",
            "id": "1067561",
            "problem": "Lotka-Volterra模型是数学生物学中的一个基础模型，用于描述捕食者-猎物相互作用的动态过程。一个更符合现实的扩展模型，称为Gause型模型，它引入了猎物的逻辑斯谛增长，并可进一步细化以包含捕食者间的种内竞争。\n\n考虑一个捕食者-猎物系统，其猎物种群为$x(t)$，捕食者种群为$y(t)$，由以下耦合微分方程组控制：\n$$\n\\frac{dx}{dt} = \\alpha x \\left(1 - \\frac{x}{K}\\right) - \\beta xy\n$$\n$$\n\\frac{dy}{dt} = \\delta xy - \\gamma y - \\eta y^2\n$$\n\n这里，所有参数均为正实数：\n- $\\alpha$：猎物的内禀增长率。\n- $K$：在没有捕食者的情况下，猎物的环境承载量。\n- $\\beta$：表示捕食率的参数。\n- $\\delta$：将被捕食的猎物转化为新捕食者的效率。\n- $\\gamma$：捕食者的内禀死亡率。\n- $\\eta$：表示捕食者之间种内竞争强度的参数，使其增长呈逻辑斯谛形式。\n\n该系统存在几个平衡点，在这些点上两个种群的变化率均为零。其中一个点，即“共存平衡点”$(x^*, y^*)$，对应于猎物和捕食者种群均为正值的稳定状态。\n\n推导该共存平衡点下猎物平衡种群$x^*$的表达式。",
            "solution": "1. 在平衡点处，$\\frac{dx}{dt}=0$ 且 $\\frac{dy}{dt}=0$。方程组为\n$$\n\\frac{dx}{dt}=\\alpha x\\Bigl(1-\\frac{x}{K}\\Bigr)-\\beta x y=0,\n\\quad\n\\frac{dy}{dt}=\\delta x y-\\gamma y-\\eta y^2=0.\n$$\n2. 对于 $x^*>0, y^*>0$ 的共存平衡点 $(x^*,y^*)$，消去公因子：\n   由 $\\frac{dx}{dt}=0$ 得：\n   $$\\alpha\\Bigl(1-\\frac{x^*}{K}\\Bigr)-\\beta y^*=0\n   \\;\\implies\\;\n   y^*=\\frac{\\alpha}{\\beta}\\Bigl(1-\\frac{x^*}{K}\\Bigr).$$\n   由 $\\frac{dy}{dt}=0$ 得：\n   $$\\delta x^*-\\gamma-\\eta y^*=0\n   \\;\\implies\\;\n   y^*=\\frac{\\delta x^*-\\gamma}{\\eta}.$$\n3. 令两个关于 $y^*$ 的表达式相等：\n$$\n\\frac{\\alpha}{\\beta}\\Bigl(1-\\frac{x^*}{K}\\Bigr)\n=\\frac{\\delta x^*-\\gamma}{\\eta}.\n$$\n4. 两边乘以 $\\beta\\eta$ 并重新整理：\n$$\n\\alpha\\eta\\Bigl(1-\\frac{x^*}{K}\\Bigr)\n=\\beta(\\delta x^*-\\gamma)\n\\;\\implies\\;\n\\alpha\\eta-\\frac{\\alpha\\eta}{K}x^*\n=\\beta\\delta x^* - \\beta\\gamma\n\\;\\implies\\;\n\\alpha\\eta+\\beta\\gamma\n=x^*\\Bigl(\\frac{\\alpha\\eta}{K}+\\beta\\delta\\Bigr).\n$$\n5. 解出 $x^*$：\n$$\nx^*=\\frac{\\alpha\\eta+\\beta\\gamma}{\\tfrac{\\alpha\\eta}{K}+\\beta\\delta}\n=\\frac{K(\\alpha\\eta+\\beta\\gamma)}{\\alpha\\eta+\\beta\\delta K}.\n$$",
            "answer": "$$\\boxed{\\frac{K(\\alpha\\eta+\\beta\\gamma)}{\\alpha\\eta+\\beta\\delta K}}$$"
        },
        {
            "introduction": "在分析了模型的平衡点之后，下一步自然是模拟其随时间变化的动态行为。然而，这个实践揭示了一个关键挑战：简单的数值方法可能会引入从根本上扭曲模型预测的误差，例如将稳定的循环轨道变为不稳定的螺旋线 。我们将探讨这一现象背后的原因，并将其与更先进的、能够保持系统内在结构的积分方法（如辛积分法）进行对比，这些高级方法对于生态系统的可靠长期模拟至关重要。",
            "id": "3889871",
            "problem": "考虑环境和地球系统建模中的经典洛特卡-沃尔泰拉（Lotka–Volterra）捕食者-被捕食者系统，\n$$\n\\frac{dx}{dt} = a x - b x y,\\qquad \\frac{dy}{dt} = -c y + d x y,\n$$\n其中参数 $a>0$，$b>0$，$c>0$ 和 $d>0$，$x(t)>0$ 表示被捕食者密度，$y(t)>0$ 表示捕食者密度。已知共存平衡点 $(x^\\ast,y^\\ast) = \\left(\\frac{c}{d},\\,\\frac{a}{b}\\right)$ 是一个非线性中心，被一个光滑首次积分 $H(x,y)$ 的闭合水平集所环绕，并且该向量场可以用哈密顿形式写出，其斜对称结构矩阵为 $S(x,y)$，使得对于 $z=(x,y)$，有 $\\dot{z} = S(z)\\nabla H(z)$ 且 $S(z)^\\top = -S(z)$。设 $h>0$ 是一个固定的时间步长。应用于该系统的显式欧拉法为\n$$\nx_{n+1} = x_n + h\\,(a x_n - b x_n y_n),\\qquad y_{n+1} = y_n + h\\,(-c y_n + d x_n y_n),\n$$\n而隐式中点法为\n$$\nx_{n+1} = x_n + h\\left(a \\frac{x_n + x_{n+1}}{2} - b \\frac{x_n + x_{n+1}}{2}\\,\\frac{y_n + y_{n+1}}{2}\\right),\n$$\n$$\ny_{n+1} = y_n + h\\left(-c \\frac{y_n + y_{n+1}}{2} + d \\frac{x_n + x_{n+1}}{2}\\,\\frac{y_n + y_{n+1}}{2}\\right).\n$$\n对于具有斜对称结构 $S(z)$ 的哈密顿系统，一种保能量离散梯度法或平均向量场（AVF）法定义为\n$$\nz_{n+1} = z_n + h\\int_0^1 S\\big(z_n + s(z_{n+1}-z_n)\\big)\\,\\nabla H\\big(z_n + s(z_{n+1}-z_n)\\big)\\,ds,\n$$\n根据其构造，该方法满足 $H(z_{n+1}) = H(z_n)$。\n\n利用在 $(x^\\ast,y^\\ast)$ 附近线性化的第一原理、哈密顿流的性质以及数值积分器的一致性，判断下列哪些陈述是正确的。选择所有适用的选项。\n\nA. 对于足够小的 $h$，显式欧拉法能精确地保持首次积分 $H(x,y)$，并产生围绕 $(x^\\ast,y^\\ast)$ 的数值闭合轨道，而没有长期漂移。\n\nB. 显式欧拉法在 $(x^\\ast,y^\\ast)$ 处的更新的线性化具有形式为 $1 \\pm i h \\omega$（其中 $\\omega>0$）的特征值，其模严格大于 $1$，这意味着存在虚假的向外螺旋线。此外，$H$ 的泰勒展开显示 $H(x_{n+1},y_{n+1}) - H(x_n,y_n)$ 是 $O(h^2)$ 阶的，并且主导项为正，而 AVF/离散梯度法能使 $H$ 精确保持恒定，并将轨迹限制在单个水平集上。\n\nC. 应用于在 $(x^\\ast,y^\\ast)$ 处的线性化系统时，隐式中点法的单步放大矩阵的特征值位于单位圆上，因此避免了振幅的数值增长或衰减；尽管对于非线性的洛特卡-沃尔泰拉系统，它不精确守恒 $H(x,y)$，但其辛结构确保了 $H$ 的误差有界，并且在长时间内没有系统性漂移。\n\nD. 因为对于连续向量场 $f$，有 $\\nabla H(x,y)\\cdot f(x,y) = 0$，所以任何一致的一阶方法，包括显式欧拉法，在长时间积分中都能在 $O(h^2)$ 阶上全局保持 $H$，因此不会引入跨越水平集的长期漂移。\n\nE. 显式欧拉法在 $(x^\\ast,y^\\ast)$ 附近产生的虚假螺旋线完全是由浮点舍入误差引起的；在精确算术下，对于所有 $h$，显式欧拉法都会遵守首次积分并产生闭合的数值轨道。",
            "solution": "该问题要求分析几种数值方法应用于洛特卡-沃尔泰拉捕食者-被捕食者系统时的行为。分析将首先围绕其共存平衡点对系统进行线性化，然后检验每种数值积分器的性质。\n\n洛特卡-沃尔泰拉系统由以下方程给出：\n$$\n\\frac{dx}{dt} = a x - b x y = f(x,y)\n$$\n$$\n\\frac{dy}{dt} = -c y + d x y = g(x,y)\n$$\n参数 $a, b, c, d$ 均为正数。共存平衡点为 $(x^\\ast, y^\\ast) = \\left(\\frac{c}{d}, \\frac{a}{b}\\right)$。\n\n首先，我们围绕该平衡点对系统进行线性化。向量场的雅可比矩阵为：\n$$\nJ(x,y) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} a - by & -bx \\\\ dy & -c + dx \\end{pmatrix}\n$$\n在平衡点 $(x^\\ast, y^\\ast)$ 处计算雅可比矩阵：\n$$\nJ(x^\\ast, y^\\ast) = \\begin{pmatrix} a - b\\left(\\frac{a}{b}\\right) & -b\\left(\\frac{c}{d}\\right) \\\\ d\\left(\\frac{a}{b}\\right) & -c + d\\left(\\frac{c}{d}\\right) \\end{pmatrix} = \\begin{pmatrix} 0 & -\\frac{bc}{d} \\\\ \\frac{ad}{b} & 0 \\end{pmatrix}\n$$\n该矩阵的特征值 $\\lambda$ 满足特征方程 $\\det(J(x^\\ast, y^\\ast) - \\lambda I) = 0$：\n$$\n\\lambda^2 - (0) \\lambda + \\left(\\left(-\\frac{bc}{d}\\right)\\left(-\\frac{ad}{b}\\right)\\right) = 0 \\implies \\lambda^2 + ac = 0\n$$\n特征值为 $\\lambda_{1,2} = \\pm i\\sqrt{ac}$。由于特征值是纯虚数，该平衡点是线性化系统的一个中心，对应于角频率为 $\\omega = \\sqrt{ac}$ 的振荡。这证实了问题陈述中关于连续系统在平衡点周围表现出闭合轨道的说法。\n\n问题陈述该系统拥有一个首次积分 $H(x,y)$，使得沿轨迹 $\\frac{dH}{dt} = 0$。该系统的标准首次积分为 $H(x,y) = dx - c\\ln x + by - a\\ln y$。\n\n现在，我们分析这些数值方法。\n\n**选项 A：对于足够小的 $h$，显式欧拉法能精确地保持首次积分 $H(x,y)$，并产生围绕 $(x^\\ast,y^\\ast)$ 的数值闭合轨道，而没有长期漂移。**\n\n对于一般系统 $\\dot{z} = F(z)$，显式欧拉法的更新公式为 $z_{n+1} = z_n + h F(z_n)$。在不动点 $z^\\ast$ 附近对该更新进行线性化，我们得到 $\\delta z_{n+1} = \\delta z_n + h J(z^\\ast) \\delta z_n = (I + h J) \\delta z_n$。放大矩阵为 $G_{EE} = I + h J$。其特征值 $\\mu$ 决定了稳定性。如果 $\\lambda$ 是 $J$ 的一个特征值，那么 $\\mu = 1 + h\\lambda$ 就是 $G_{EE}$ 的一个特征值。\n使用 $\\lambda = \\pm i\\omega = \\pm i\\sqrt{ac}$，放大矩阵的特征值为：\n$$\n\\mu_{1,2} = 1 \\pm i h \\sqrt{ac}\n$$\n这些特征值的模为：\n$$\n|\\mu| = \\sqrt{1^2 + (h\\sqrt{ac})^2} = \\sqrt{1 + h^2 ac}\n$$\n由于 $a,c,h > 0$，我们有 $|\\mu| > 1$。模大于1的放大因子意味着振荡的振幅在每一步都会增长。数值轨迹将不是闭合轨道，而是一条虚假的向外螺旋线。这代表了向更高能级的长期漂移。该方法不保持 $H(x,y)$，即使是在长时间内也无法近似保持，更不用说精确保持了。\n\n结论：**不正确**。\n\n**选项 B：显式欧拉法在 $(x^\\ast,y^\\ast)$ 处的更新的线性化具有形式为 $1 \\pm i h \\omega$（其中 $\\omega>0$）的特征值，其模严格大于 $1$，这意味着存在虚假的向外螺旋线。此外，$H$ 的泰勒展开显示 $H(x_{n+1},y_{n+1}) - H(x_n,y_n)$ 是 $O(h^2)$ 阶的，并且主导项为正，而 AVF/离散梯度法能使 $H$ 精确保持恒定，并将轨迹限制在单个水平集上。**\n\n该陈述的第一部分证实了我们对选项A的分析：特征值为 $\\mu=1 \\pm ih\\omega$（其中 $\\omega=\\sqrt{ac}>0$），其模 $|\\mu| = \\sqrt{1+h^2ac} > 1$，这导致了虚假的向外螺旋线。这部分是正确的。\n\n对于第二部分，我们来分析显式欧拉法一步中 $H$ 的变化，$z_{n+1} = z_n + h F(z_n)$，其中 $z=(x,y)$。\n将 $H(z_{n+1})$ 在 $z_n$ 处进行泰勒展开，得到：\n$$\nH(z_{n+1}) = H(z_n + h F(z_n)) = H(z_n) + h \\nabla H(z_n) \\cdot F(z_n) + \\frac{h^2}{2} F(z_n)^T (\\nabla^2 H)(z_n) F(z_n) + O(h^3)\n$$\n连续动力学系统保持 $H$，因此 $\\frac{dH}{dt} = \\nabla H \\cdot F = 0$。一阶项消失。每一步 $H$ 的变化为：\n$$\nH(z_{n+1}) - H(z_n) \\approx \\frac{h^2}{2} F(z_n)^T (\\nabla^2 H)(z_n) F(z_n)\n$$\n$H(x,y) = dx - c\\ln x + by - a\\ln y$ 的黑塞矩阵（Hessian matrix）是：\n$$\n\\nabla^2 H(x,y) = \\begin{pmatrix} c/x^2 & 0 \\\\ 0 & a/y^2 \\end{pmatrix}\n$$\n由于 $a,c > 0$ 并且我们考虑的是正象限内的轨迹（$x,y > 0$），黑塞矩阵是正定矩阵。只要 $z_n$ 不是平衡点，向量场 $F(z_n)$ 就非零。因此，对于除平衡点外的任何点，二次型 $F^T (\\nabla^2 H) F$ 都是严格正的。这意味着 $H(z_{n+1}) - H(z_n)$ 是 $O(h^2)$ 阶的，并且主导项为正。$H$ 的这种系统性增加证实了向外螺旋。\n\n最后，问题陈述定义了 AVF/离散梯度方法，并明确指出它“根据构造满足 $H(z_{n+1}) = H(z_n)$”。因此，该方法能精确地保持 $H$ 恒定，并将轨迹限制在 $H$ 的单个水平集上。该陈述的所有部分都是正确的。\n\n结论：**正确**。\n\n**选项 C：应用于在 $(x^\\ast,y^\\ast)$ 处的线性化系统时，隐式中点法的单步放大矩阵的特征值位于单位圆上，因此避免了振幅的数值增长或衰减；尽管对于非线性的洛特卡-沃尔泰拉系统，它不精确守恒 $H(x,y)$，但其辛结构确保了 $H$ 的误差有界，并且在长时间内没有系统性漂移。**\n\n隐式中点法是 $z_{n+1} = z_n + h F\\left(\\frac{z_n+z_{n+1}}{2}\\right)$。在不动点 $z^\\ast$ 附近进行线性化：\n$$\n\\delta z_{n+1} = \\delta z_n + h J(z^\\ast) \\frac{\\delta z_n + \\delta z_{n+1}}{2}\n$$\n整理得到 $\\delta z_{n+1}$：\n$$\n\\left(I - \\frac{h}{2}J\\right) \\delta z_{n+1} = \\left(I + \\frac{h}{2}J\\right) \\delta z_n\n$$\n放大矩阵是 $G_{IM} = \\left(I - \\frac{h}{2}J\\right)^{-1} \\left(I + \\frac{h}{2}J\\right)$。这是 $\\frac{h}{2}J$ 的凯莱变换（Cayley transform）。$G_{IM}$ 的特征值 $\\mu$ 与 $J$ 的特征值 $\\lambda$ 通过 $\\mu = \\frac{1+h\\lambda/2}{1-h\\lambda/2}$ 相关。当 $\\lambda = \\pm i\\omega$ 时：\n$$\n\\mu = \\frac{1 \\pm i h\\omega/2}{1 \\mp i h\\omega/2}\n$$\n模为 $|\\mu| = \\frac{|1 \\pm i h\\omega/2|}{|1 \\mp i h\\omega/2|} = \\frac{\\sqrt{1+(h\\omega/2)^2}}{\\sqrt{1+(h\\omega/2)^2}} = 1$。特征值位于单位圆上，因此线性映射是稳定的，不表现出振幅的增长或衰减。这部分是正确的。\n\n隐式中点法是一种辛积分器（symplectic integrator）。对于一般的哈密顿系统，辛积分器并不精确地守恒哈密顿量 $H$。它们精确地守恒一个附近的“影子哈密顿量” $H_h$。洛特卡-沃尔泰拉系统的哈密顿量不是一个简单的二次型，对于这类哈密顿量，中点法并不精确守恒 $H$。这部分是正确的。\n\n辛方法的主要优点是，因为它守恒一个影子哈密顿量 $H_h$（它接近于 $H$），原始哈密顿量的误差 $H(z_n) - H(z_0)$ 在指数级长的时间内保持有界。这防止了像显式欧拉法这样的非辛方法中出现的系统性能量漂移。这部分也是正确的。\n\n结论：**正确**。\n\n**选项 D：因为对于连续向量场 $f$，有 $\\nabla H(x,y)\\cdot f(x,y) = 0$，所以任何一致的一阶方法，包括显式欧拉法，在长时间积分中都能在 $O(h^2)$ 阶上全局保持 $H$，因此不会引入跨越水平集的长期漂移。**\n\n这个陈述包含错误的推理。性质 $\\nabla H \\cdot f = 0$ 属于连续向量场。数值方法通常不继承这种守恒定律。如选项B的分析所示，显式欧拉法在单步中 $H$ 的变化是 $O(h^2)$，而不是零。这是守恒量的局部误差。在长时间积分 $T = N h$ 后，这些系统性为正的局部误差会累积。在时间 $T$ 之后，$H$ 的全局误差大约是 $N \\times O(h^2) = (T/h) \\times O(h^2) = O(h T)$。因此，全局误差是 $O(h)$ 阶，而不是 $O(h^2)$。这种误差的累积正是导致长期漂移的原因。没有长期漂移的结论是错误的，正如显式欧拉法的向外螺旋所证明的那样。\n\n结论：**不正确**。\n\n**选项 E：显式欧拉法在 $(x^\\ast,y^\\ast)$ 附近产生的虚假螺旋线完全是由浮点舍入误差引起的；在精确算术下，对于所有 $h$，显式欧拉法都会遵守首次积分并产生闭合的数值轨道。**\n\n这个陈述错误地将显式欧拉法的失败归因于浮点舍入误差。我们对放大矩阵特征值的分析（$|\\mu| = \\sqrt{1 + h^2 ac} > 1$）是在精确算术下进行的。这种不稳定性是显式欧拉算法应用于振荡或保守系统时固有的数学性质。即使使用无限精度算术，该方法也会产生螺旋轨迹。舍入误差是任何数值计算中的一个额外误差源，但不是这种特定行为的根本原因。\n\n结论：**不正确**。",
            "answer": "$$\\boxed{BC}$$"
        },
        {
            "introduction": "任何模型的最终检验标准是其描述真实世界观测的能力。这项实践练习将理论与数据联系起来，重点关注“功能性反应”——即捕食者消耗猎物的速率 。您将需要推导并拟合两种相互竞争的功能性反应模型（II型和III型）到实验数据上，并使用统计学方法来判断哪种模型能更好地解释观察到的捕食行为。这个练习模拟了一个完整的建模工作流程，从理论推导到数据驱动的模型选择，是环境建模领域的一项核心技能。",
            "id": "3889896",
            "problem": "考虑一个实验室实验，其中单个捕食者暴露于不同密度的猎物中，并记录单位时间内每个捕食者消耗的猎物数量。在捕食者-猎物理论中，功能性响应量化了单个捕食者的捕食率如何依赖于猎物密度。您的任务是从第一性原理出发，推导、实现并拟合两个相互竞争的功能性响应模型，然后进行模型选择。\n\n从以下基本假设开始：\n\n- 捕食者与猎物之间的相遇是一个泊松过程，其相遇强度与猎物密度成正比。如果猎物密度为 $N$（单位：每个实验区域内的个体数），比例常数为 $a$（相遇系数，单位：每小时），则单位时间内在搜索过程中的期望相遇次数与 $a N$ 成正比。\n- 每捕获一个猎物需要固定的处理时间 $h$（单位：小时/猎物），这构成了一个时间预算约束：处理时间会占用搜索时间。\n- 在第一个模型中，假设在所有密度下搜索速率都与 $N$ 成正比，这与恒定的搜索效率以及没有学习或转换行为相符。\n- 在第二个模型中，假设在低密度下存在一个加速相遇机制，这与学习或转换行为相符，使得有效相遇强度在低 $N$ 值时增长超过线性，但由于处理时间的限制仍会达到饱和。\n\n根据这些假设，为以下两个模型推导期望的单个捕食者捕食率 $r(N)$（单位：猎物/捕食者/小时）作为 $N$、相遇系数 $a$ 和处理时间 $h$ 的函数表达式：\n\n- 模型 $M_2$（作为“II 型”功能性响应的候选模型进行测试）。\n- 模型 $M_3$（作为在低猎物密度下具有加速效应的“III 型”功能性响应的候选模型进行测试）。\n\n假设在不同观测值上，$r(N)$ 的测量误差是独立的、服从高斯分布且方差未知，并使用非线性最小二乘法为每个模型估计参数 $a$ 和 $h$。为了进行模型比较，在高斯误差假设下使用赤池信息准则 (AIC)。设残差平方和为 $\\mathrm{SSR} = \\sum_{i=1}^{n} \\left( r_i - r(N_i; a, h) \\right)^2$，其中 $n$ 是观测次数，$k$ 是自由参数的数量。使用\n$$\n\\mathrm{AIC} = n \\ln\\left(\\frac{\\mathrm{SSR}}{n}\\right) + 2 k,\n$$\n该公式适用于误差方差未知并通过 $\\mathrm{SSR}/n$ 进行隐式估计时的模型比较。选择具有较低 $\\mathrm{AIC}$ 值的模型。\n\n物理单位：猎物密度 $N$ 是一个计数（无量纲），时间单位为小时，捕食率 $r$ 的单位必须是 猎物/捕食者/小时。将每个数据集最终选择的模型报告为一个整数：如果 $M_2$ 的 $\\mathrm{AIC}$ 较低，则输出 $2$；如果 $M_3$ 的 $\\mathrm{AIC}$ 较低，则输出 $3$。\n\n测试套件：将两个模型分别拟合到以下四个数据集。每个数据集提供了猎物密度 $N$ 和观测到的捕食率 $r$（单位：猎物/捕食者/小时）。这些数据在科学上是合理的，并且与假设内部一致。\n\n- 数据集 $1$（中度饱和，无明显的低密度加速效应）：$N = [1,2,4,8,16,32,64]$，$r = [0.49,0.81,1.22,1.64,1.98,2.21,2.35]$。\n- 数据集 $2$（明显的低密度加速效应并伴有饱和）：$N = [1,2,4,8,16,32,64]$，$r = [0.076,0.261,0.675,1.117,1.336,1.404,1.423]$。\n- 数据集 $3$（包含零密度，在低 $N$ 值时有显著的加速效应）：$N = [0,1,2,3,4,5]$，$r = [0.0,0.22,0.49,0.64,0.71,0.75]$。\n- 数据集 $4$（由于处理时间非常短而接近线性区域）：$N = [5,10,20,40]$，$r = [0.25,0.495,0.98,1.92]$。\n\n算法要求：\n\n- 对于每个数据集，使用有界非线性最小二乘算法，通过最小化 $\\mathrm{SSR}$ 来估计两个模型的参数 $(a, h)$，参数边界为 $a \\in (0, 10]$，$h \\in (0, 10]$。\n- 使用科学上合理的初始猜测值；算法应对不同数据集之间的差异具有鲁棒性。\n- 为每个拟合的模型计算 $\\mathrm{AIC}$，并选择 $\\mathrm{AIC}$ 较低的模型。\n\n角度单位不适用。不得使用百分比；所有量都应表示为小数或分数。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须包含四个整数，分别对应上述顺序的每个数据集。例如，如果选择的模型是 $M_3$、$M_3$、$M_2$、$M_2$，则输出应为 $[3,3,2,2]$。您的程序必须且只能打印这一行内容。",
            "solution": "该问题要求解决一个关于捕食者-猎物功能性响应的建模任务。核心是从第一性原理推导两个模型（II型和III型），然后将它们拟合到四个数据集，并使用赤池信息准则（AIC）为每个数据集选择最佳模型。\n\n### 模型推导\n\n两个模型的推导都源于时间预算约束。设捕食者的总可用时间为 $T$，它被划分为搜索时间 $T_s$ 和处理时间 $T_h$：\n$$T = T_s + T_h$$\n\n单位时间内的捕食率定义为 $r(N)$，因此在时间 $T$ 内捕食的猎物总数 $N_e = r(N)T$。总处理时间是捕食的猎物数乘以每个猎物的处理时间 $h$：$T_h = N_e h = r(N)Th$。\n将此代入时间预算方程，解出搜索时间 $T_s$：\n$$T_s = T - T_h = T - r(N)Th = T(1 - r(N)h)$$\n\n捕食的猎物总数 $N_e$ 也是搜索期间相遇的结果。它等于搜索时间 $T_s$ 乘以单位时间内的相遇率，我们记作 $f(N)$：\n$$N_e = f(N) T_s$$\n\n结合以上方程：\n$$r(N)T = f(N) [T(1 - r(N)h)]$$\n消去总时间 $T$ 并解出 $r(N)$：\n$$r(N) = f(N) (1 - r(N)h) \\implies r(N) + r(N)f(N)h = f(N) \\implies r(N) = \\frac{f(N)}{1 + f(N)h}$$\n\n这个通用公式（霍林圆盘方程）是两个模型的基础。模型的区别在于对相遇率函数 $f(N)$ 的假设。\n\n**模型 $M_2$ (II型功能性响应)**\n假设相遇率与猎物密度 $N$ 成正比，比例常数为攻击率 $a$：\n$$f(N) = aN$$\n代入通用公式，得到II型功能性响应：\n$$r(N) = \\frac{aN}{1 + aNh}$$\n该函数随 $N$ 单调递增并饱和，趋向于最大捕食率 $1/h$。\n\n**模型 $M_3$ (III型功能性响应)**\n假设相遇率在低密度下呈加速增长，通常用于模拟捕食者学习或猎物转换。最简单的形式是二次关系：\n$$f(N) = aN^2$$\n代入通用公式，得到S型的III型功能性响应：\n$$r(N) = \\frac{aN^2}{1 + aN^2h}$$\n该函数在低密度时呈S型（sigmoid）增长，然后饱和到同样的最大速率 $1/h$。\n\n### 模型拟合与选择\n对于每个数据集，使用有界非线性最小二乘法估计两个模型的参数 $(a, h)$。优化目标是最小化残差平方和 (SSR)：\n$$\\mathrm{SSR} = \\sum_{i=1}^{n} (r_i - r(N_i; a, h))^2$$\n其中 $(N_i, r_i)$ 是观测数据点，$n$ 是观测次数。优化约束为 $a \\in (0, 10]$ 和 $h \\in (0, 10]$。\n\n拟合后，根据赤池信息准则 (AIC) 对模型进行比较：\n$$\\mathrm{AIC} = n \\ln\\left(\\frac{\\mathrm{SSR}}{n}\\right) + 2k$$\n对于 $M_2$ 和 $M_3$，估计的参数数量均为 $k=2$（即 $a$ 和 $h$）。AIC值较低的模型被认为是更好的选择，因为它在拟合优度和模型复杂度之间取得了更好的平衡。对四个数据集中的每一个都重复此过程，并记录所选的模型（$2$ 代表 $M_2$，$3$ 代表 $M_3$）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\n\n# --- Model Definitions ---\n\ndef model_M2(N, a, h):\n    \"\"\"\n    Type II functional response model.\n    r(N) = a*N / (1 + a*N*h)\n    \"\"\"\n    N = np.asarray(N)\n    # To prevent division by zero or NaN if a=0 or h=0, though bounds should prevent this.\n    denominator = 1.0 + a * N * h\n    return (a * N) / denominator\n\ndef model_M3(N, a, h):\n    \"\"\"\n    Type III functional response model.\n    r(N) = a*N^2 / (1 + a*N^2*h)\n    \"\"\"\n    N = np.asarray(N)\n    N_squared = N**2\n    denominator = 1.0 + a * N_squared * h\n    return (a * N_squared) / denominator\n\n# --- Fitting and Selection ---\n\ndef calculate_ssr(params, model_func, N_data, r_data):\n    \"\"\"Calculates the Sum of Squared Residuals (SSR).\"\"\"\n    a, h = params\n    r_predicted = model_func(N_data, a, h)\n    residuals = r_predicted - r_data\n    return np.sum(residuals**2)\n\ndef fit_and_select_model(N_data, r_data):\n    \"\"\"\n    Fits both M2 and M3 to the data, calculates AIC, and selects the best model.\n    \"\"\"\n    # Convert data to numpy arrays\n    N_data = np.array(N_data, dtype=float)\n    r_data = np.array(r_data, dtype=float)\n\n    # Number of observations\n    n = len(N_data)\n    # Number of parameters\n    k = 2\n\n    # --- Parameter Estimation using Bounded Nonlinear Least Squares ---\n\n    # Common settings for the optimizer\n    # Initial guess for (a, h)\n    p0 = [0.5, 0.5]\n    # Bounds: a in (0, 10], h in (0, 10]. Use small positive for lower bound.\n    bounds = ([1e-9, 1e-9], [10.0, 10.0])\n\n    # Residual functions for least_squares\n    def residuals_M2(params, N, r):\n        return model_M2(N, params[0], params[1]) - r\n\n    def residuals_M3(params, N, r):\n        return model_M3(N, params[0], params[1]) - r\n\n    # Fit Model M2\n    res_M2 = least_squares(residuals_M2, p0, args=(N_data, r_data), bounds=bounds)\n    ssr_M2 = np.sum(res_M2.fun**2)\n\n    # Fit Model M3\n    res_M3 = least_squares(residuals_M3, p0, args=(N_data, r_data), bounds=bounds)\n    ssr_M3 = np.sum(res_M3.fun**2)\n\n    # --- Model Selection using AIC ---\n    # AIC = n * ln(SSR/n) + 2k\n    \n    # Check for SSR=0 to avoid log(0)\n    aic_M2 = np.inf\n    if ssr_M2 > 1e-12: # Use a small tolerance instead of exact zero\n        aic_M2 = n * np.log(ssr_M2 / n) + 2 * k\n    else: # Handle perfect fit case\n        aic_M2 = -np.inf\n\n\n    aic_M3 = np.inf\n    if ssr_M3 > 1e-12:\n        aic_M3 = n * np.log(ssr_M3 / n) + 2 * k\n    else:\n        aic_M3 = -np.inf\n\n    # Select the model with the lower AIC\n    if aic_M2  aic_M3:\n        return 2\n    else:\n        return 3\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset 1\n        {'N': [1, 2, 4, 8, 16, 32, 64], 'r': [0.49, 0.81, 1.22, 1.64, 1.98, 2.21, 2.35]},\n        # Dataset 2\n        {'N': [1, 2, 4, 8, 16, 32, 64], 'r': [0.076, 0.261, 0.675, 1.117, 1.336, 1.404, 1.423]},\n        # Dataset 3\n        {'N': [0, 1, 2, 3, 4, 5], 'r': [0.0, 0.22, 0.49, 0.64, 0.71, 0.75]},\n        # Dataset 4\n        {'N': [5, 10, 20, 40], 'r': [0.25, 0.495, 0.98, 1.92]},\n    ]\n\n    results = []\n    for case in test_cases:\n        N_data = case['N']\n        r_data = case['r']\n        chosen_model = fit_and_select_model(N_data, r_data)\n        results.append(chosen_model)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}