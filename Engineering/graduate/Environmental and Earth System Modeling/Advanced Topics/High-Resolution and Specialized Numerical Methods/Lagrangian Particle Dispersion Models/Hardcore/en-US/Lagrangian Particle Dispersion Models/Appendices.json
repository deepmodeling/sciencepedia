{
    "hands_on_practices": [
        {
            "introduction": "The core purpose of a dispersion model is to link the properties of a turbulent flow to the resulting spread of a tracer. This first practice establishes that fundamental connection in its simplest form. By analyzing the evolution of a tracer puff's statistical moments, you will derive the classic result that its variance grows linearly with time, a relationship directly proportional to the eddy diffusivity $K$ . Understanding this foundational principle is the first step toward building and interpreting any Lagrangian particle model.",
            "id": "3886931",
            "problem": "Consider a passive tracer puff released at time $t=0$ into an unbounded, homogeneous, isotropic, and stationary turbulent flow with zero mean velocity. Assume that on scales of the puff the effect of turbulence on particle motions is well-represented by a Fickian closure with a constant eddy diffusivity $K>0$. Let $c(\\mathbf{x},t)$ denote the tracer concentration field, which evolves according to the conservation of mass and the diffusion of the scalar by the turbulent eddies. The total tracer mass $M$ is finite and conserved, and the initial concentration $c(\\mathbf{x},0)$ has a finite variance along a chosen Cartesian coordinate $x$.\n\nDefine the center of mass along $x$ by $\\mu(t) = M^{-1} \\int_{-\\infty}^{\\infty} x\\, c(x,t)\\, dx$ and the coordinate-wise variance by $\\sigma^{2}(t) = M^{-1} \\int_{-\\infty}^{\\infty} \\left(x - \\mu(t)\\right)^{2} c(x,t)\\, dx$. Introduce a fixed length scale $L>0$ and nondimensional variables $\\Sigma(t) = \\sigma^{2}(t)/L^{2}$ and $\\tau = K t / L^{2}$, with $\\Sigma_{0} = \\Sigma(0)$.\n\nStarting only from:\n- the definition of the Lagrangian velocity $u = d x / d t$ and the assumption of homogeneous, isotropic, stationary turbulence with zero mean velocity,\n- conservation of tracer mass,\n- and the Fickian representation of turbulent mixing by a constant eddy diffusivity,\n\nderive a closed-form expression for the temporal evolution of the nondimensional variance $\\Sigma(\\tau)$ in terms of $\\Sigma_{0}$ and $\\tau$. Present your final answer as a single analytic expression for $\\Sigma(\\tau)$. No numerical evaluation is required, and no units should be included with your final expression.",
            "solution": "The problem requires the derivation of the temporal evolution of the nondimensional variance of a passive tracer puff in a turbulent flow. The derivation must start from the fundamental principles stated in the problem.\n\nFirst, we formalize the governing equation for the tracer concentration field, $c(\\mathbf{x}, t)$. The problem describes the transport using a Fickian closure with a constant eddy diffusivity, $K > 0$, in a flow with zero mean velocity. This is described by the diffusion equation:\n$$\n\\frac{\\partial c}{\\partial t} = K \\nabla^2 c\n$$\nThe problem defines moments with respect to a single Cartesian coordinate, $x$. It is advantageous to work with the concentration integrated over the other two coordinates, $y$ and $z$. Let us define $C(x,t) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} c(x,y,z,t) \\, dy \\, dz$. Integrating the $3$D diffusion equation with respect to $y$ and $z$ yields the $1$D diffusion equation for $C(x,t)$:\n$$\n\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} \\frac{\\partial c}{\\partial t} \\, dy \\, dz = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} K \\left( \\frac{\\partial^2 c}{\\partial x^2} + \\frac{\\partial^2 c}{\\partial y^2} + \\frac{\\partial^2 c}{\\partial z^2} \\right) \\, dy \\, dz\n$$\n$$\n\\frac{\\partial}{\\partial t} C(x,t) = K \\frac{\\partial^2}{\\partial x^2} C(x,t) + K \\int_{-\\infty}^{\\infty} \\left[ \\frac{\\partial c}{\\partial y} \\right]_{y=-\\infty}^{\\infty} dz + K \\int_{-\\infty}^{\\infty} \\left[ \\frac{\\partial c}{\\partial z} \\right]_{z=-\\infty}^{\\infty} dy\n$$\nAssuming the concentration and its gradients vanish at infinity for a finite mass puff, the boundary terms are zero. This leaves us with the 1D diffusion equation:\n$$\n\\frac{\\partial C}{\\partial t} = K \\frac{\\partial^2 C}{\\partial x^2}\n$$\nThe problem statement uses $c(x,t)$ in its definitions of moments, which we identify with this integrated concentration $C(x,t)$. The total mass is $M = \\int_{-\\infty}^{\\infty} C(x,t) \\, dx$. This mass is conserved, as $\\frac{dM}{dt} = \\int_{-\\infty}^{\\infty} \\frac{\\partial C}{\\partial t} \\, dx = K \\int_{-\\infty}^{\\infty} \\frac{\\partial^2 C}{\\partial x^2} \\, dx = K \\left[ \\frac{\\partial C}{\\partial x} \\right]_{-\\infty}^{\\infty} = 0$.\n\nNext, we analyze the evolution of the center of mass along the $x$-axis, $\\mu(t)$, defined as $\\mu(t) = M^{-1} \\int_{-\\infty}^{\\infty} x C(x,t) \\, dx$. We compute its time derivative:\n$$\n\\frac{d\\mu}{dt} = \\frac{1}{M} \\int_{-\\infty}^{\\infty} x \\frac{\\partial C}{\\partial t} \\, dx = \\frac{K}{M} \\int_{-\\infty}^{\\infty} x \\frac{\\partial^2 C}{\\partial x^2} \\, dx\n$$\nUsing integration by parts, with $u=x$ and $dv = (\\partial^2 C/\\partial x^2)dx$:\n$$\n\\int_{-\\infty}^{\\infty} x \\frac{\\partial^2 C}{\\partial x^2} \\, dx = \\left[ x \\frac{\\partial C}{\\partial x} \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} \\frac{\\partial C}{\\partial x} \\, dx\n$$\nThe first term vanishes at infinity. The second term is $\\left[ C(x,t) \\right]_{-\\infty}^{\\infty}$, which also vanishes. Therefore, $\\frac{d\\mu}{dt} = 0$. This implies that the center of mass $\\mu(t)$ is constant. This is consistent with the stated zero mean velocity of the flow. We can choose a coordinate system that moves with the center of mass, such that $\\mu(t) = 0$ for all $t$.\n\nWith $\\mu(t)=0$, the definition of the variance simplifies to $\\sigma^2(t) = M^{-1} \\int_{-\\infty}^{\\infty} x^2 C(x,t) \\, dx$. We now derive the evolution equation for $\\sigma^2(t)$ by differentiating with respect to time $t$:\n$$\n\\frac{d\\sigma^2}{dt} = \\frac{1}{M} \\frac{d}{dt} \\int_{-\\infty}^{\\infty} x^2 C(x,t) \\, dx = \\frac{1}{M} \\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial C}{\\partial t} \\, dx\n$$\nSubstituting the 1D diffusion equation for $\\frac{\\partial C}{\\partial t}$:\n$$\n\\frac{d\\sigma^2}{dt} = \\frac{K}{M} \\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial^2 C}{\\partial x^2} \\, dx\n$$\nWe evaluate the integral using integration by parts twice. First, let $u = x^2$ and $dv = (\\partial^2 C/\\partial x^2)dx$. Then $du = 2x \\, dx$ and $v = \\partial C/\\partial x$.\n$$\n\\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial^2 C}{\\partial x^2} \\, dx = \\left[ x^2 \\frac{\\partial C}{\\partial x} \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} 2x \\frac{\\partial C}{\\partial x} \\, dx\n$$\nThe boundary term is zero. We are left with $-2 \\int_{-\\infty}^{\\infty} x \\frac{\\partial C}{\\partial x} \\, dx$. We apply integration by parts again, with $u=x$ and $dv = (\\partial C/\\partial x)dx$. Then $du=dx$ and $v=C$.\n$$\n-2 \\int_{-\\infty}^{\\infty} x \\frac{\\partial C}{\\partial x} \\, dx = -2 \\left( \\left[ x C \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} C \\, dx \\right)\n$$\nThe boundary term is again zero. The remaining integral is the total mass, $\\int_{-\\infty}^{\\infty} C(x,t) \\, dx = M$.\nSo, the integral becomes $-2(-M) = 2M$.\nSubstituting this back into the equation for the time derivative of the variance:\n$$\n\\frac{d\\sigma^2}{dt} = \\frac{K}{M} (2M) = 2K\n$$\nThis is a simple ordinary differential equation for $\\sigma^2(t)$. Integrating from time $t=0$ to a general time $t$:\n$$\n\\int_{\\sigma^2(0)}^{\\sigma^2(t)} d(\\sigma'^2) = \\int_0^t 2K \\, dt'\n$$\n$$\n\\sigma^2(t) - \\sigma^2(0) = 2Kt\n$$\nThis gives the evolution of the dimensional variance:\n$$\n\\sigma^2(t) = \\sigma^2(0) + 2Kt\n$$\nThe last step is to express this result using the specified nondimensional variables: $\\Sigma(t) = \\sigma^2(t)/L^2$ and $\\tau = Kt/L^2$. The initial nondimensional variance is $\\Sigma_0 = \\sigma^2(0)/L^2$.\nWe divide the equation for $\\sigma^2(t)$ by the constant $L^2$:\n$$\n\\frac{\\sigma^2(t)}{L^2} = \\frac{\\sigma^2(0)}{L^2} + \\frac{2Kt}{L^2}\n$$\nSubstituting the nondimensional definitions, we get:\n$$\n\\Sigma(\\tau) = \\Sigma_0 + 2\\tau\n$$\nThis is the closed-form expression for the temporal evolution of the nondimensional variance.",
            "answer": "$$\\boxed{\\Sigma_{0} + 2\\tau}$$"
        },
        {
            "introduction": "While simple models assume turbulence is uniform, real-world environments like the atmosphere feature complex, spatially varying turbulence. A naive Lagrangian model can cause particles to spuriously accumulate in regions of low diffusivity, a non-physical artifact. This practice tackles that problem head-on by asking you to derive the \"well-mixed condition\" . You will determine the necessary corrective drift term for the particle's stochastic differential equation, ensuring your model behaves physically correctly in a non-uniform flow field.",
            "id": "3886893",
            "problem": "Consider a one-dimensional vertical coordinate $z$ in a Lagrangian particle dispersion model for the atmospheric boundary layer. A passive scalar is represented by an ensemble of particles whose vertical position $Z(t)$ evolves according to an Itō stochastic differential equation (SDE),\n$$\n\\mathrm{d}Z(t) = a(Z(t))\\,\\mathrm{d}t + \\sqrt{2\\,K(Z(t))}\\,\\mathrm{d}W(t),\n$$\nwhere $a(z)$ is the deterministic drift, $K(z)$ is the eddy diffusivity, and $W(t)$ is a standard Wiener process. Let the corresponding Eulerian concentration $C(z,t)$ denote the particle number density. Assume there are no sources or sinks and that the domain is large enough that boundary effects can be neglected in the interior.\n\nStarting from conservation of probability mass and the relationship between the Itō SDE and the Fokker–Planck equation for $C(z,t)$, derive the condition on the drift $a(z)$ required for a stationary, spatially uniform equilibrium concentration $C_{\\infty}(z)=C_{0}$, where $C_{0}$ is a constant. Then, for the specific eddy diffusivity profile $K(z)=K_{0}\\,(1+\\alpha z)$ with $K_{0}>0$ and $\\alpha$ a constant (with dimension of inverse length), compute the explicit expression for $a(z)$ that maintains the uniform equilibrium $C_{\\infty}(z)=C_{0}$.\n\nExpress your final answer as a single closed-form symbolic expression for $a(z)$. The physical unit of the drift $a(z)$ is meters per second, but do not include units in your boxed answer.",
            "solution": "The evolution of the particle number density, or concentration $C(z,t)$, corresponding to the given Itō SDE is described by the Fokker–Planck equation. For a one-dimensional process with drift $a(z)$ and a stochastic term $\\sigma(z) = \\sqrt{2K(z)}$, the Fokker-Planck equation is:\n$$\n\\frac{\\partial C(z,t)}{\\partial t} = -\\frac{\\partial}{\\partial z}\\left[a(z)C(z,t)\\right] + \\frac{1}{2}\\frac{\\partial^2}{\\partial z^2}\\left[\\sigma(z)^2 C(z,t)\\right] = -\\frac{\\partial}{\\partial z}\\left[a(z)C(z,t)\\right] + \\frac{\\partial^2}{\\partial z^2}\\left[K(z)C(z,t)\\right]\n$$\nThis equation can be written in the form of a continuity equation, $\\frac{\\partial C}{\\partial t} = -\\frac{\\partial J}{\\partial z}$, where $J(z,t)$ is the particle flux:\n$$\nJ(z,t) = a(z)C(z,t) - \\frac{\\partial}{\\partial z}\\left[K(z)C(z,t)\\right]\n$$\nThe problem requires a stationary equilibrium solution, which means $\\frac{\\partial C}{\\partial t} = 0$. In this case, the continuity equation reduces to $\\frac{\\partial J}{\\partial z} = 0$, implying that the stationary flux, $J(z)$, must be a constant. Since there are no sources or sinks and the domain is large, the net flux must be zero everywhere to prevent accumulation or depletion. Therefore, we set the constant flux to zero: $J(z) = 0$.\n\nThe condition for stationary equilibrium is thus:\n$$\na(z)C(z) - \\frac{\\partial}{\\partial z}\\left[K(z)C(z)\\right] = 0\n$$\nWe are given that the stationary equilibrium concentration is spatially uniform, i.e., $C(z) = C_{\\infty}(z) = C_{0}$, where $C_{0}$ is a non-zero constant. Substituting this into the zero-flux condition:\n$$\na(z)C_{0} - \\frac{\\mathrm{d}}{\\mathrm{d}z}\\left[K(z)C_{0}\\right] = 0\n$$\nSince $C_{0}$ is a constant, we can factor it out of the derivative and then divide the entire equation by $C_{0}$ (assuming $C_0 \\neq 0$):\n$$\na(z)C_{0} - C_{0}\\frac{\\mathrm{d}K(z)}{\\mathrm{d}z} = 0 \\implies a(z) = \\frac{\\mathrm{d}K(z)}{\\mathrm{d}z}\n$$\nThis result is the general \"well-mixed\" condition. To find the specific drift for the given eddy diffusivity profile $K(z) = K_{0}\\,(1+\\alpha z)$, we compute its derivative:\n$$\n\\frac{\\mathrm{d}K(z)}{\\mathrm{d}z} = \\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ K_{0}\\,(1+\\alpha z) \\right] = K_{0} \\frac{\\mathrm{d}}{\\mathrm{d}z} (1+\\alpha z) = K_{0} (0 + \\alpha) = \\alpha K_{0}\n$$\nTherefore, the required drift is the constant value $a(z) = \\alpha K_{0}$.",
            "answer": "$$\n\\boxed{\\alpha K_{0}}\n$$"
        },
        {
            "introduction": "Lagrangian models excel not only at forward prediction (where will a pollutant go?) but also at inverse problems (where did it come from?). This final practice transitions from model theory to a powerful real-world application: source estimation. You will act as an environmental scientist, using simulated receptor measurements and a model-derived \"footprint\" to infer an unknown emission rate and quantify its uncertainty . This exercise introduces the statistical framework of maximum likelihood estimation, a cornerstone of data assimilation and environmental forensics.",
            "id": "3886854",
            "problem": "Consider a single, steady point emission of a passive tracer with constant emission rate $Q$ (in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$). A Lagrangian Particle Dispersion Model (LPDM) precomputes receptor-specific source-receptor transfer coefficients (footprints) so that the time-averaged concentration at receptor $i$ is linearly related to $Q$ via $y_i = G_i \\, Q + \\epsilon_i$, where $G_i$ (in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$ per $\\mathrm{kg} \\, \\mathrm{s}^{-1}$) is the footprint for receptor $i$ and $\\epsilon_i$ is measurement error. Assume the errors $\\epsilon_i$ are independent Gaussian random variables with zero mean and known standard deviations $\\sigma_i$ (in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$), and measurements $y_i$ are reported in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$. Using the independence and Gaussianity of $\\epsilon_i$ and the linearity of the LPDM mapping $Q \\mapsto y_i$, derive from first principles the maximum likelihood estimator for $Q$ and an uncertainty quantification for that estimate under the same Gaussian assumptions.\n\nYour program must:\n- Implement the derived estimator and the associated uncertainty quantification using the general case of $N$ receptors with possibly heterogeneous $\\sigma_i$.\n- For each test case, return four quantities:\n    1. The point estimate of $Q$ (in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$).\n    2. The posterior standard deviation of $Q$ (in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$) assuming a flat prior, which under Gaussian errors equals the estimator’s standard deviation derived from the likelihood curvature.\n    3. The lower endpoint of a two-sided $0.95$ credible interval for $Q$ (in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$) under the Gaussian posterior.\n    4. The upper endpoint of the same credible interval (in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$).\n- Use the standard normal quantile $z_{0.975}$ to form the two-sided $0.95$ interval.\n- Express all results in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, flattened across test cases in the order described above. For example, for three test cases, the output should be of the form $[q_1,\\mathrm{sd}_1,\\mathrm{low}_1,\\mathrm{high}_1,q_2,\\mathrm{sd}_2,\\mathrm{low}_2,\\mathrm{high}_2,q_3,\\mathrm{sd}_3,\\mathrm{low}_3,\\mathrm{high}_3]$.\n\nTest suite:\n- Case A (happy path, moderate signals and equal uncertainties):\n    - $G = [0.80, 1.10, 0.95]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$ per $\\mathrm{kg} \\, \\mathrm{s}^{-1}$,\n    - $y = [0.88, 1.12, 0.97]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$,\n    - $\\sigma = [0.05, 0.05, 0.05]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$.\n- Case B (boundary-leaning case with very small footprints and equal uncertainties):\n    - $G = [0.010, 0.020, 0.015]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$ per $\\mathrm{kg} \\, \\mathrm{s}^{-1}$,\n    - $y = [0.008, 0.023, 0.012]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$,\n    - $\\sigma = [0.005, 0.005, 0.005]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$.\n- Case C (edge case with heterogeneous uncertainties and one negative measurement due to noise):\n    - $G = [0.30, 0.20, 0.40, 0.50]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$ per $\\mathrm{kg} \\, \\mathrm{s}^{-1}$,\n    - $y = [-0.01, 0.08, 0.15, 0.24]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$,\n    - $\\sigma = [0.05, 0.04, 0.06, 0.05]$ in $\\mathrm{mg} \\, \\mathrm{m}^{-3}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[q_A,\\mathrm{sd}_A,\\mathrm{low}_A,\\mathrm{high}_A,q_B,\\mathrm{sd}_B,\\mathrm{low}_B,\\mathrm{high}_B,q_C,\\mathrm{sd}_C,\\mathrm{low}_C,\\mathrm{high}_C]$, where subscripts indicate the case. All numbers must be in $\\mathrm{kg} \\, \\mathrm{s}^{-1}$.",
            "solution": "The task is to derive the maximum likelihood estimator for the emission rate $Q$ and to quantify its uncertainty, based on a set of $N$ measurements. The model relating a measurement $y_i$ to the emission rate $Q$ is given by the linear equation:\n$$ y_i = G_i Q + \\epsilon_i $$\nwhere $y_i$ is the measured concentration, $G_i$ is the known source-receptor transfer coefficient (footprint), $Q$ is the unknown emission rate, and $\\epsilon_i$ is the measurement error. The problem states that the errors $\\epsilon_i$ are independent, normally distributed random variables with mean $0$ and known standard deviation $\\sigma_i$, i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$. Note that if the $\\sigma_i$ differ, the errors are not identically distributed.\n\nFrom the model, it follows that the measurement $y_i$ is also a Gaussian random variable with mean $G_i Q$ and variance $\\sigma_i^2$:\n$$ y_i \\sim \\mathcal{N}(G_i Q, \\sigma_i^2) $$\nThe probability density function (PDF) of a single observation $y_i$ given $Q$ is:\n$$ p(y_i | Q) = \\frac{1}{\\sqrt{2\\pi\\sigma_i^2}} \\exp\\left(-\\frac{(y_i - G_i Q)^2}{2\\sigma_i^2}\\right) $$\n\n**1. Derivation of the Maximum Likelihood Estimator (MLE)**\n\nThe likelihood function, $L(Q)$, is the joint probability of observing the entire set of measurements $\\{y_i\\}_{i=1}^N$. Since the measurements are independent, the likelihood is the product of the individual PDFs:\n$$ L(Q) = \\prod_{i=1}^{N} p(y_i | Q) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma_i^2}} \\exp\\left(-\\frac{(y_i - G_i Q)^2}{2\\sigma_i^2}\\right) $$\nTo find the value of $Q$ that maximizes $L(Q)$, it is simpler to maximize the log-likelihood function, $\\mathcal{L}(Q) = \\ln(L(Q))$:\n$$ \\mathcal{L}(Q) = \\sum_{i=1}^{N} \\left[ \\ln\\left(\\frac{1}{\\sqrt{2\\pi\\sigma_i^2}}\\right) - \\frac{(y_i - G_i Q)^2}{2\\sigma_i^2} \\right] = C - \\frac{1}{2} \\sum_{i=1}^{N} \\frac{(y_i - G_i Q)^2}{\\sigma_i^2} $$\nwhere $C$ is a constant that does not depend on $Q$. Maximizing $\\mathcal{L}(Q)$ is equivalent to minimizing the weighted sum of squared residuals, where the weights are $w_i = 1/\\sigma_i^2$.\n\nTo find the maximum, we compute the derivative of $\\mathcal{L}(Q)$ with respect to $Q$ and set it to $0$:\n$$ \\frac{d\\mathcal{L}(Q)}{dQ} = \\sum_{i=1}^{N} \\frac{G_i(y_i - G_i Q)}{\\sigma_i^2} $$\nSetting the derivative to zero for the estimator $\\hat{Q}$:\n$$ \\sum_{i=1}^{N} \\frac{G_i y_i}{\\sigma_i^2} = \\hat{Q} \\sum_{i=1}^{N} \\frac{G_i^2}{\\sigma_i^2} $$\nSolving for $\\hat{Q}$ yields the maximum likelihood estimator:\n$$ \\hat{Q} = \\frac{\\sum_{i=1}^{N} (G_i y_i / \\sigma_i^2)}{\\sum_{i=1}^{N} (G_i^2 / \\sigma_i^2)} $$\nThis estimator is a weighted average of the individual estimates $y_i/G_i$, where each estimate is weighted by its precision relative to the model, $(G_i/\\sigma_i)^2$.\n\n**2. Uncertainty Quantification**\n\nAssuming a flat prior for $Q$, the posterior distribution is proportional to the likelihood function, $p(Q|\\{y_i\\}) \\propto L(Q)$. Since the log-likelihood $\\mathcal{L}(Q)$ is a quadratic function of $Q$, the posterior distribution for $Q$ is Gaussian. The mean of this posterior is the MLE, $\\hat{Q}$.\n\nThe variance of the posterior, $\\sigma_Q^2$, can be found from the curvature of the log-likelihood function at its maximum. The variance is the negative reciprocal of the second derivative of the log-likelihood:\n$$ \\sigma_Q^2 = \\left( - \\frac{d^2\\mathcal{L}(Q)}{dQ^2} \\right)^{-1} $$\nThe second derivative is:\n$$ \\frac{d^2\\mathcal{L}(Q)}{dQ^2} = \\frac{d}{dQ} \\left( \\sum_{i=1}^{N} \\frac{G_i y_i}{\\sigma_i^2} - \\sum_{i=1}^{N} \\frac{G_i^2 Q}{\\sigma_i^2} \\right) = - \\sum_{i=1}^{N} \\frac{G_i^2}{\\sigma_i^2} $$\nThe second derivative is negative and constant, confirming that $\\hat{Q}$ is a maximum. The variance is:\n$$ \\sigma_Q^2 = \\left( - \\left( - \\sum_{i=1}^{N} \\frac{G_i^2}{\\sigma_i^2} \\right) \\right)^{-1} = \\left( \\sum_{i=1}^{N} \\frac{G_i^2}{\\sigma_i^2} \\right)^{-1} $$\nThe posterior standard deviation, $\\sigma_Q$, is the square root of the variance:\n$$ \\sigma_Q = \\left( \\sum_{i=1}^{N} \\frac{G_i^2}{\\sigma_i^2} \\right)^{-1/2} $$\n\n**3. Credible Interval**\n\nWith the posterior distribution for $Q$ established as Gaussian, $Q|\\{y_i\\} \\sim \\mathcal{N}(\\hat{Q}, \\sigma_Q^2)$, a two-sided $0.95$ credible interval for $Q$ is constructed as:\n$$ [ \\hat{Q} - z_{0.975} \\cdot \\sigma_Q, \\quad \\hat{Q} + z_{0.975} \\cdot \\sigma_Q ] $$\nwhere $z_{0.975} \\approx 1.95996$ is the $97.5$-th percentile of the standard normal distribution $\\mathcal{N}(0, 1)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Derives the maximum likelihood estimate for a single emission source Q,\n    its uncertainty, and credible interval, based on a linear receptor model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (G_values, y_values, sigma_values)\n    test_cases = [\n        # Case A (happy path, moderate signals and equal uncertainties)\n        ([0.80, 1.10, 0.95], [0.88, 1.12, 0.97], [0.05, 0.05, 0.05]),\n        # Case B (boundary-leaning case with very small footprints and equal uncertainties)\n        ([0.010, 0.020, 0.015], [0.008, 0.023, 0.012], [0.005, 0.005, 0.005]),\n        # Case C (edge case with heterogeneous uncertainties and one negative measurement)\n        ([0.30, 0.20, 0.40, 0.50], [-0.01, 0.08, 0.15, 0.24], [0.05, 0.04, 0.06, 0.05]),\n    ]\n\n    all_results = []\n    \n    # Pre-calculate the standard normal quantile for a two-sided 95% interval.\n    # This corresponds to the 97.5th percentile.\n    z_0975 = norm.ppf(0.975)\n\n    for G_vals, y_vals, sigma_vals in test_cases:\n        # Convert lists to NumPy arrays for vectorized operations.\n        G = np.array(G_vals)\n        y = np.array(y_vals)\n        sigma = np.array(sigma_vals)\n\n        # The weights for the weighted least squares are the inverse variances.\n        weights = 1.0 / sigma**2\n\n        # Calculate the terms for the MLE of Q.\n        # This is equivalent to Q_hat = (G' W y) / (G' W G) in matrix notation,\n        # where W is the weight matrix.\n        numerator = np.sum(weights * G * y)\n        denominator = np.sum(weights * G**2)\n\n        # 1. Point estimate of Q (kg/s)\n        q_hat = numerator / denominator\n\n        # The denominator is also the Fisher Information, or the inverse variance of Q.\n        # 2. Posterior standard deviation of Q (kg/s)\n        var_q = 1.0 / denominator\n        std_q = np.sqrt(var_q)\n\n        # Calculate the half-width of the credible interval.\n        interval_half_width = z_0975 * std_q\n\n        # 3. Lower endpoint of the 95% credible interval for Q (kg/s)\n        q_lower = q_hat - interval_half_width\n        \n        # 4. Upper endpoint of the 95% credible interval for Q (kg/s)\n        q_upper = q_hat + interval_half_width\n        \n        # Append the four required quantities for this case to the final list.\n        all_results.extend([q_hat, std_q, q_lower, q_upper])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}