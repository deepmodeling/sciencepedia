{
    "hands_on_practices": [
        {
            "introduction": "The heart of the Metropolis-Hastings algorithm is its elegant probabilistic rule for deciding whether to accept a proposed move to a new state. This decision ensures that the chain of samples will, in the long run, faithfully represent the complex target distributions often encountered in environmental modeling. This first exercise provides a direct, hands-on calculation of this core mechanism, the acceptance probability, allowing you to see how the relative likelihoods of the current and proposed states govern the sampler's behavior .",
            "id": "1371728",
            "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.",
            "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "While Metropolis-Hastings offers a universally applicable framework, other MCMC algorithms can be far more efficient for models with specific structures. The Gibbs sampler is a powerful alternative that simplifies a high-dimensional problem by sampling each variable or block of variables from its full conditional distribution. This practice focuses on the essential skill required for Gibbs sampling: deriving these conditional distributions, using a linear Gaussian state-space model as a foundational example prevalent in the analysis of environmental time series .",
            "id": "791654",
            "problem": "Consider a linear Gaussian state-space model, also known as a local level model, which is frequently used in time series analysis. The model is defined for time steps $t=1, \\dots, T$.\n\n1.  **Observation Equation:** The observation $y_t$ at time $t$ depends on a latent state $x_t$ according to a normal distribution:\n    $$\n    y_t | x_t, \\sigma^2_y \\sim N(x_t, \\sigma^2_y)\n    $$\n    where $N( \\mu, \\sigma^2)$ denotes a normal distribution with mean $\\mu$ and variance $\\sigma^2_y$.\n\n2.  **State Equation:** The latent state $x_t$ evolves as a random walk, depending on the previous state $x_{t-1}$:\n    $$\n    x_t | x_{t-1}, \\sigma^2_x \\sim N(x_{t-1}, \\sigma^2_x)\n    $$\n\nIn the context of Bayesian inference, particularly when using a Gibbs sampler, one needs to compute the full conditional distribution for each latent state. For an intermediate time step $k$ (where $1  k  T$), the full conditional distribution of the state $x_k$ is the distribution of $x_k$ given all other states $\\mathbf{x}_{-k} = \\{x_t\\}_{t \\neq k}$, all observations $\\mathbf{y} = \\{y_t\\}_{t=1}^T$, and the model's variance parameters.\n\nYou are given that for this model, the full conditional distribution $p(x_k | \\mathbf{x}_{-k}, \\mathbf{y}, \\sigma_y^2, \\sigma_x^2)$ is a normal distribution, which we will denote as $N(\\mu_k^*, (\\sigma_k^*)^2)$. For this problem, assume the observation variance $\\sigma_y^2$ and the state variance $\\sigma_x^2$ are known positive constants.\n\nYour task is to derive an expression for the product of the mean and variance, $\\mu_k^* (\\sigma_k^*)^2$, of this full conditional distribution. The final expression should be in terms of the observation $y_k$, the neighboring latent states $x_{k-1}$ and $x_{k+1}$, and the variances $\\sigma_y^2$ and $\\sigma_x^2$.",
            "solution": "We seek the conditional:\n$$p(x_k\\mid\\mathbf x_{-k},\\mathbf y)\\;\\propto\\;p(y_k\\mid x_k)\\,p(x_k\\mid x_{k-1})\\,p(x_{k+1}\\mid x_k)\\,.$$\nSince each factor is Gaussian, we write the exponent of the unnormalized log-posterior in $x_k$:\n$$-\\tfrac{1}{2}\\Bigl[\\tfrac{1}{\\sigma_y^2}(y_k - x_k)^2+\\tfrac{1}{\\sigma_x^2}(x_k - x_{k-1})^2+\\tfrac{1}{\\sigma_x^2}(x_{k+1}-x_k)^2\\Bigr]\\,.$$\nExpanding and collecting terms in $x_k$ gives:\n$$-\\tfrac{1}{2}\\Bigl[\\bigl(\\tfrac{1}{\\sigma_y^2}+\\tfrac{2}{\\sigma_x^2}\\bigr)x_k^2-2\\bigl(\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}\\bigr)x_k+\\cdots\\Bigr]\\,.$$\nHence the conditional is Gaussian with precision:\n$$\\lambda=\\frac{1}{\\sigma_y^2}+\\frac{2}{\\sigma_x^2},$$\nvariance:\n$$(\\sigma_k^*)^2=\\lambda^{-1},$$\nand mean:\n$$\\mu_k^*=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda}\\,.$$\nTherefore:\n$$\\mu_k^*(\\sigma_k^*)^2=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda^2} = \\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\bigl(\\tfrac{1}{\\sigma_y^2}+\\tfrac{2}{\\sigma_x^2}\\bigr)^2}\\,.$$",
            "answer": "$$\\boxed{\\frac{\\frac{y_k}{\\sigma_y^2}+\\frac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\Bigl(\\frac1{\\sigma_y^2}+\\frac{2}{\\sigma_x^2}\\Bigr)^2}}$$"
        },
        {
            "introduction": "Moving from theoretical exercises to practical application, this final practice guides you through the implementation of a complete, modern MCMC sampler. The efficiency of a Metropolis sampler critically depends on the characteristics of its proposal distribution, and manual tuning can be a significant bottleneck. In this problem, you will build an adaptive algorithm that automatically tunes its proposal step size to achieve a target acceptance rate, a sophisticated technique that produces more robust and efficient samplers for real-world modeling tasks .",
            "id": "2411370",
            "problem": "Implement an adaptive Metropolis random-walk Markov Chain Monte Carlo (MCMC) algorithm that tunes a scalar proposal step size during a burn-in phase to achieve and maintain a target acceptance rate near a specified value. The target density is known only up to a normalization constant. Your implementation must be a complete, runnable program that takes no input and prints the required output. The algorithm must be justified from fundamental principles: (i) the Metropolis-Hastings construction from the detailed balance condition, and (ii) stochastic approximation to solve a root-finding problem for the acceptance rate. The objective is to design the adaptation so that it is confined to burn-in and leaves the stationary distribution unchanged during sampling.\n\nStart from the following fundamental base:\n- The transition kernel of a Markov chain with stationary density $\\pi(\\boldsymbol{x})$ must satisfy detailed balance, that is, for all states $\\boldsymbol{x}$ and $\\boldsymbol{y}$, $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$.\n- In the Metropolis-Hastings construction with proposal density $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$, the acceptance probability must be chosen so that detailed balance holds.\n- In adaptive schemes, parameter updates during burn-in can be posed as a stochastic approximation to solve an equation of the form $\\mathbb{E}[h(\\theta)] = 0$ with a diminishing step size.\n\nYour tasks are:\n1) Derive the Metropolis-Hastings acceptance probability for a symmetric Gaussian random-walk proposal $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ from the detailed balance condition and implement it in your code. You must justify the acceptance formula in your solution, starting from detailed balance, without relying on any unproven shortcut formulas.\n2) Derive and implement a Robbins-Monro-type stochastic approximation that updates the log step size $\\theta = \\log \\sigma$ at iteration $n$ during burn-in according to a diminishing step size sequence. The goal is to drive the expected acceptance probability toward a target value $a^\\star$. Your update must be on the log scale to preserve positivity of $\\sigma$, must use a diminishing gain of the form $\\gamma_n = c/(n+t_0)$ with constants $c > 0$ and $t_0 \\ge 0$, and must be confined strictly to the burn-in phase. Clearly state the reasoning for this choice in your solution.\n3) After burn-in, freeze the tuned $\\sigma$ and generate samples. Compute the empirical acceptance rate over the sampling phase only. All acceptance rates must be reported as decimals in the unit interval.\n\nYou must implement and test your program on the following test suite. Each test specifies a target distribution, dimensionality, initial conditions, and a random seed. For reproducibility, use the specified seeds. The target acceptance rate is $a^\\star = 0.23$ in all cases.\n\n- Test A (one-dimensional standard Gaussian):\n  - Dimension $d = 1$.\n  - Target log-density: $\\log \\pi(x) = -\\tfrac{1}{2} x^2$.\n  - Initial position: $x_0 = 0$.\n  - Initial step size: $\\sigma_0 = 0.001$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 6000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $42$.\n\n- Test B (five-dimensional correlated Gaussian):\n  - Dimension $d = 5$.\n  - Target density: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$ with $\\Sigma_{ij} = \\rho^{|i-j|}$ and $\\rho = 0.8$.\n  - Initial position: $\\boldsymbol{x}_0 = \\boldsymbol{0}$.\n  - Initial step size: $\\sigma_0 = 10$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 8000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $123$.\n\n- Test C (two-dimensional Rosenbrock target with softened curvature):\n  - Dimension $d = 2$.\n  - Define the potential $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$.\n  - Target density: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$.\n  - Initial position: $\\boldsymbol{x}_0 = (0,\\,0)$.\n  - Initial step size: $\\sigma_0 = 1$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 12000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $2024$.\n\nAlgorithmic requirements:\n- Use a Gaussian random-walk proposal $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$ with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n- During burn-in only, update $\\theta_n = \\log \\sigma_n$ at each proposal via a Robbins-Monro step with $\\gamma_n = c/(n + t_0)$ for fixed constants $c$ and $t_0$, using the observed acceptance probability at that step.\n- After burn-in, fix $\\sigma$ and continue sampling without any further adaptation.\n- For stability, you may constrain $\\theta_n$ to a broad interval so that $\\sigma_n$ remains finite.\n\nOutput specification:\n- For each test, compute the empirical acceptance rate over the $N_{\\mathrm{sample}}$ sampling iterations only.\n- Your program must print a single line containing a list with the $3$ acceptance rates in the order A, B, C, each rounded to three decimal places, as decimals (no percentage signs), formatted exactly as: $[\\text{r}_A,\\text{r}_B,\\text{r}_C]$.\n\nNo physical units or angle units are involved in this problem. All numerical answers must be decimals. The output must be deterministic under the given seeds. The final program must be complete and runnable as is, with no input required, and must not access any external resources.",
            "solution": "The task is to implement an adaptive Metropolis random-walk Markov Chain Monte Carlo (MCMC) algorithm. The algorithm must tune its scalar proposal step size, $\\sigma$, during a burn-in phase to achieve a specified target acceptance rate, $a^\\star$. The theoretical foundations for the algorithm—the Metropolis-Hastings acceptance rule and the Robbins-Monro stochastic approximation for adaptation—must be derived from first principles.\n\n### Problem Validation\n\nFirst, we validate the problem statement.\n\n#### Step 1: Extract Givens\n\n- **Fundamental Principles**:\n    - Detailed balance: $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$.\n    - Metropolis-Hastings (M-H) construction: The transition kernel $P(\\boldsymbol{x},\\boldsymbol{y})$ is constructed from a proposal density $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ and an acceptance probability $\\alpha(\\boldsymbol{x},\\boldsymbol{y})$.\n    - Stochastic approximation: Parameter updates follow a scheme to solve $\\mathbb{E}[h(\\theta)] = 0$ with a diminishing step size.\n\n- **Tasks**:\n    1.  Derive the M-H acceptance probability for a symmetric Gaussian random-walk proposal, $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$, from detailed balance.\n    2.  Derive and implement a Robbins-Monro update for the log step size, $\\theta = \\log \\sigma$, to drive the acceptance rate to a target $a^\\star$. The update must use a gain $\\gamma_n = c/(n+t_0)$ and be confined to burn-in.\n    3.  Implement the full algorithm, fix $\\sigma$ after burn-in, and compute the empirical acceptance rate during the sampling phase.\n\n- **Algorithmic Requirements**:\n    - Proposal: Gaussian random-walk $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$ with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n    - Adaptation: Update $\\theta_n = \\log \\sigma_n$ via Robbins-Monro with gain $\\gamma_n = c/(n+t_0)$ during burn-in only.\n    - Sampling: Fix $\\sigma$ after burn-in.\n    - Target acceptance rate: $a^\\star = 0.23$ for all tests.\n\n- **Test Cases**:\n    - **Test A**: $d=1$, log-density $\\log \\pi(x) = -\\tfrac{1}{2} x^2$, $x_0 = 0$, $\\sigma_0 = 0.001$, $N_{\\mathrm{burn}} = 6000$, $N_{\\mathrm{sample}} = 12000$, seed $42$.\n    - **Test B**: $d=5$, $\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$ with $\\Sigma_{ij} = \\rho^{|i-j|}$ and $\\rho = 0.8$, $\\boldsymbol{x}_0 = \\boldsymbol{0}$, $\\sigma_0 = 10$, $N_{\\mathrm{burn}} = 8000$, $N_{\\mathrm{sample}} = 12000$, seed $123$.\n    - **Test C**: $d=2$, $\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$ where $U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$, $\\boldsymbol{x}_0 = (0,0)$, $\\sigma_0 = 1$, $N_{\\mathrm{burn}} = 12000$, $N_{\\mathrm{sample}} = 12000$, seed $2024$.\n\n- **Output Specification**: A single line with a list of three acceptance rates for tests A, B, C, rounded to three decimal places: $[\\text{r}_A,\\text{r}_B,\\text{r}_C]$.\n\n#### Step 2: Validate Using Extracted Givens\n\nThe problem is reviewed against the validation criteria.\n- **Scientifically Grounded**: The problem is based on established, fundamental principles of computational statistics and physics, namely MCMC theory, detailed balance, and stochastic approximation. The target distributions are standard benchmarks in the field. The problem is free from pseudoscience.\n- **Well-Posed**: The objectives are clear, all necessary parameters for each test case (dimensions, target densities, initial conditions, iteration counts, random seeds) are specified. The output format is precisely defined. The problem is deterministic given the seeds. A unique, meaningful solution is expected. The choice of the Robbins-Monro constants $c$ and $t_0$ is left to the implementer, which is a standard design decision, not a flaw.\n- **Objective**: The language is technical, precise, and unambiguous. There are no subjective or opinion-based statements.\n\nThe problem is self-contained, consistent, and scientifically sound. No flaws are identified.\n\n#### Step 3: Verdict and Action\n\nThe problem is valid. We proceed with the solution.\n\n### Derivation and Algorithm Design\n\n#### 1. Metropolis-Hastings Acceptance Probability\n\nThe goal is to construct a Markov chain with a stationary distribution $\\pi(\\boldsymbol{x})$. The transition kernel, $P(\\boldsymbol{x}, \\boldsymbol{y})$, which gives the probability density of moving from state $\\boldsymbol{x}$ to $\\boldsymbol{y}$, must satisfy the detailed balance condition:\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\nIn the Metropolis-Hastings framework, the transition is a two-step process: propose a new state $\\boldsymbol{y}$ from a proposal density $q(\\boldsymbol{y} \\mid \\boldsymbol{x})$, then accept it with probability $\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$. For $\\boldsymbol{x} \\neq \\boldsymbol{y}$, the transition kernel is $P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$. Substituting this into the detailed balance equation gives:\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\nThis implies the following constraint on the ratio of acceptance probabilities:\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\nThe standard Metropolis choice for the acceptance probability, which satisfies this condition, is:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\nThe problem specifies a symmetric Gaussian random-walk proposal: $\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$. The proposal density is:\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\nDue to the term $(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$, the proposal is symmetric, i.e., $q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$. The proposal terms in the acceptance ratio cancel out, yielding the simplified Metropolis acceptance probability:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\nSince the target density $\\pi(\\boldsymbol{x})$ is often known only up to a normalization constant, we compute this ratio using the unnormalized density or, more stably, its logarithm:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\nThis is the formula to be implemented.\n\n#### 2. Adaptive Step Size using Stochastic Approximation\n\nThe goal is to adjust the proposal step size $\\sigma$ such that the expected acceptance rate matches a target value $a^\\star$. Let $\\theta = \\log \\sigma$ be the parameter to be tuned. The update is performed during the burn-in phase. We want to find the root of the function $g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$, where $\\alpha(\\theta)$ is the acceptance probability for a given $\\theta$.\n\nThe Robbins-Monro algorithm is a stochastic root-finding method. For a function $g(\\theta)$, we can find its root using the iterative scheme $\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$, where $g_n$ is a noisy observation of $g$ at step $n$ and $\\{\\gamma_n\\}$ is a sequence of step sizes satisfying $\\sum \\gamma_n = \\infty$ and $\\sum \\gamma_n^2  \\infty$.\n\nIn our case, we observe the acceptance probability $\\alpha_n$ at iteration $n$ and use this as our noisy measurement. The update rule for $\\theta_n = \\log\\sigma_n$ is formulated to guide the observed acceptance rate towards $a^\\star$:\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\nThe sign is positive because if the current acceptance rate $\\alpha_n$ is higher than the target $a^\\star$, we need to increase $\\theta$ (and thus $\\sigma$) to make proposals bolder and decrease the acceptance rate. Conversely, if $\\alpha_n  a^\\star$, we decrease $\\theta$ to make proposals more conservative and increase the acceptance rate.\n\nThe step size sequence (gain) is given as $\\gamma_n = c/(n + t_0)$ for $n \\geq 1$. We will select $c=1.0$ and $t_0=10.0$ as reasonable constants to ensure stability and effective adaptation. Updating on the log scale, $\\theta = \\log\\sigma$, naturally ensures that $\\sigma = \\exp(\\theta)$ remains positive.\n\nThis adaptation scheme makes the Markov chain non-homogeneous. To guarantee that the samples are drawn from the correct stationary distribution $\\pi(\\boldsymbol{x})$, the adaptation must be terminated after the burn-in phase. After $N_{\\mathrm{burn}}$ iterations, the step size $\\sigma$ is frozen at its final adapted value, and the subsequent $N_{\\mathrm{sample}}$ iterations proceed as a standard, homogeneous Metropolis MCMC algorithm. The ergodic theorem for Markov chains then ensures that averages computed from these samples converge to expectations with respect to $\\pi(\\boldsymbol{x})$.\n\n### Implementation Plan\n\nThe algorithm will be implemented in a function that takes the test case parameters. For each iteration from $n=1$ to $N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$:\n1.  Generate a proposal $\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$, with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n2.  Compute $\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$.\n3.  Draw $u \\sim U(0,1)$. If $u  \\alpha$, set $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$ and note an acceptance. Otherwise, set $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$.\n4.  If $n \\le N_{\\mathrm{burn}}$:\n    - Update $\\log \\sigma_n$ using the Robbins-Monro step: $\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$.\n    - For robustness, we will clip $\\log\\sigma$ to a reasonable range, e.g., $[-10, 10]$.\n5.  If $n  N_{\\mathrm{burn}}$:\n    - Keep $\\sigma$ fixed.\n    - Tally acceptances to compute the final empirical acceptance rate over the sampling phase.\n\nThis procedure will be applied to each of the three test cases using the specified parameters and random seeds.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```"
        }
    ]
}