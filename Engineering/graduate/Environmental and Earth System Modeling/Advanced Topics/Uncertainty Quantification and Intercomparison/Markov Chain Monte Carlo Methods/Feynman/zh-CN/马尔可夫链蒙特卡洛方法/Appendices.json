{
    "hands_on_practices": [
        {
            "introduction": "Metropolis-Hastings 接受准则是许多 MCMC 算法的决策核心，它通过一个简单的计算决定是否接受一个新提出的状态，从而引导采样器逼近目标分布。本练习  将让你亲手计算接受概率 $\\alpha$，以此来巩固你对这一基本机制的理解。",
            "id": "1371728",
            "problem": "一位数据科学家正在实施马尔可夫链蒙特卡洛（MCMC）模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用Metropolis算法和对称提议分布 $q(x'|x)$，其中给定当前状态 $x$ 提议新状态 $x'$ 的概率等于给定 $x'$ 提议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态为 $x = 1.5$。然后，算法提议移动到一个新的候选状态 $x' = 2.0$。\n\n计算此特定移动的接受概率。你的答案应该是一个无量纲的实数。将你的最终答案四舍五入到四位有效数字。",
            "solution": "对于从 $x$ 到 $x'$ 的移动，使用对称提议分布 $q(x'|x)=q(x|x')$ 的Metropolis接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 和 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，$\\exp(-0.5)\\approx 0.6065$（四舍五入到四位有效数字）。",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "对于具有特定结构的多参数复杂模型（例如地球系统科学中常见的时间序列状态空间模型），Gibbs 抽样是一种尤为高效的策略。该方法的核心是从每个参数的满条件分布中进行迭代抽样。本练习  要求你为一个潜变量推导其满条件分布，这是在结构化模型中应用 Gibbs 抽样的关键一步。",
            "id": "791654",
            "problem": "考虑一个线性高斯状态空间模型，也称为局部水平模型，它常用于时间序列分析。该模型定义在时间步 $t=1, \\dots, T$ 上。\n\n1.  **观测方程：** 在时间 $t$ 的观测值 $y_t$ 依赖于潜状态 $x_t$，遵循正态分布：\n    $$\n    y_t | x_t, \\sigma^2_y \\sim N(x_t, \\sigma^2_y)\n    $$\n    其中 $N( \\mu, \\sigma^2)$ 表示均值为 $\\mu$、方差为 $\\sigma^2_y$ 的正态分布。\n\n2.  **状态方程：** 潜状态 $x_t$ 作为一个随机游走进行演化，依赖于前一个状态 $x_{t-1}$：\n    $$\n    x_t | x_{t-1}, \\sigma^2_x \\sim N(x_{t-1}, \\sigma^2_x)\n    $$\n\n在贝叶斯推断的背景下，特别是在使用吉布斯采样器时，需要计算每个潜状态的全条件分布。对于一个中间时间步 $k$ (其中 $1  k  T$)，状态 $x_k$ 的全条件分布是在给定所有其他状态 $\\mathbf{x}_{-k} = \\{x_t\\}_{t \\neq k}$、所有观测值 $\\mathbf{y} = \\{y_t\\}_{t=1}^T$ 以及模型的方差参数的条件下 $x_k$ 的分布。\n\n已知对于该模型，全条件分布 $p(x_k | \\mathbf{x}_{-k}, \\mathbf{y}, \\sigma_y^2, \\sigma_x^2)$ 是一个正态分布，我们将其记为 $N(\\mu_k^*, (\\sigma_k^*)^2)$。对于本问题，假设观测方差 $\\sigma_y^2$ 和状态方差 $\\sigma_x^2$ 是已知的正常数。\n\n你的任务是推导该全条件分布的均值与方差的乘积 $\\mu_k^* (\\sigma_k^*)^2$ 的表达式。最终表达式应使用观测值 $y_k$、相邻的潜状态 $x_{k-1}$ 和 $x_{k+1}$ 以及方差 $\\sigma_y^2$ 和 $\\sigma_x^2$ 来表示。",
            "solution": "我们要求解条件分布\n$$p(x_k\\mid\\mathbf x_{-k},\\mathbf y)\\;\\propto\\;p(y_k\\mid x_k)\\,p(x_k\\mid x_{k-1})\\,p(x_{k+1}\\mid x_k)\\,. $$\n由于每个因子都是高斯的，我们写出关于 $x_k$ 的未归一化对数后验的指数部分：\n$$-\\tfrac12\\Bigl[\\tfrac1{\\sigma_y^2}(y_k - x_k)^2+\\tfrac1{\\sigma_x^2}(x_k - x_{k-1})^2+\\tfrac1{\\sigma_x^2}(x_{k+1}-x_k)^2\\Bigr]\\,. $$\n展开并合并关于 $x_k$ 的项，得到\n$$-\\tfrac12\\Bigl[\\bigl(\\tfrac1{\\sigma_y^2}+2\\tfrac1{\\sigma_x^2}\\bigr)x_k^2-2\\bigl(\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}\\bigr)x_k+\\cdots\\Bigr]\\,. $$\n因此，该条件分布是高斯分布，其精度为\n$$\\lambda=\\frac1{\\sigma_y^2}+\\frac{2}{\\sigma_x^2},$$\n方差为\n$$ (\\sigma_k^*)^2=\\lambda^{-1},$$\n均值为\n$$ \\mu_k^*=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda}\\,. $$\n因此\n$$\\mu_k^*(\\sigma_k^*)^2=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda^2}  \n=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\bigl(\\tfrac1{\\sigma_y^2}+\\tfrac{2}{\\sigma_x^2}\\bigr)^2}\\,. $$",
            "answer": "$$\\boxed{\\frac{\\frac{y_k}{\\sigma_y^2}+\\frac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\Bigl(\\frac1{\\sigma_y^2}+\\frac{2}{\\sigma_x^2}\\Bigr)^2}}$$"
        },
        {
            "introduction": "MCMC 方法在实际应用中的一个常见挑战是有效调整其超参数（如提议步长），以确保对目标分布进行高效探索。这项综合性练习  将理论付诸实践，要求你构建一个完整的自适应 MCMC 算法。通过实现一个能够在预烧（burn-in）阶段自动优化其提议步长的采样器，你将掌握设计和实现高效 MCMC 工具的关键工程技能。",
            "id": "2411370",
            "problem": "实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛 (MCMC) 算法，该算法在预烧 (burn-in) 阶段调整一个标量提议步长，以达到并维持一个接近指定值的目标接受率。目标密度函数仅在相差一个归一化常数的情况下是已知的。您的实现必须是一个完整的、可运行的程序，不接受任何输入并打印所需的输出。该算法必须从基本原理上得到论证：(i) 基于细致平衡条件的 Metropolis-Hastings 构建方法，以及 (ii) 用于解决接受率求根问题的随机近似方法。目标是设计一个自适应方案，使其仅限于预烧阶段，并且在采样阶段不改变平稳分布。\n\n从以下基本原理出发：\n- 具有平稳密度 $\\pi(\\boldsymbol{x})$ 的马尔可夫链的转移核必须满足细致平衡条件，即对于所有状态 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$，$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n- 在使用提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 的 Metropolis-Hastings 构建方法中，必须选择接受概率以使细致平衡成立。\n- 在自适应方案中，预烧期间的参数更新可以被看作是使用递减步长来解决形式为 $\\mathbb{E}[h(\\theta)] = 0$ 的方程的随机近似。\n\n您的任务是：\n1) 从细致平衡条件出发，推导对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 的 Metropolis-Hastings 接受概率，并在您的代码中实现它。您必须在解决方案中从细致平衡条件开始论证该接受公式，不得依赖任何未经证明的简化公式。\n2) 推导并实现一个 Robbins-Monro 类型的随机近似算法，该算法在预烧期间根据一个递减的步长序列更新对数步长 $\\theta = \\log \\sigma$。目标是驱动期望接受概率趋向于目标值 $a^\\star$。您的更新必须在对数尺度上进行以保持 $\\sigma$ 的正性，必须使用形式为 $\\gamma_n = c/(n+t_0)$（其中 $c  0$ 和 $t_0 \\ge 0$ 为常数）的递减增益，并且必须严格限制在预烧阶段。在您的解决方案中清楚地说明选择此方法的原因。\n3) 预烧结束后，固定调整好的 $\\sigma$ 并生成样本。仅计算采样阶段的经验接受率。所有接受率必须以单位区间内的小数形式报告。\n\n您必须在以下测试套件上实现并测试您的程序。每个测试都指定了目标分布、维度、初始条件和随机种子。为保证可复现性，请使用指定的种子。所有情况下的目标接受率均为 $a^\\star = 0.23$。\n\n- 测试 A (一维标准高斯分布):\n  - 维度 $d = 1$。\n  - 目标对数密度: $\\log \\pi(x) = -\\tfrac{1}{2} x^2$。\n  - 初始位置: $x_0 = 0$。\n  - 初始步长: $\\sigma_0 = 0.001$。\n  - 预烧迭代次数: $N_{\\mathrm{burn}} = 6000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $42$。\n\n- 测试 B (五维相关高斯分布):\n  - 维度 $d = 5$。\n  - 目标密度: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$。\n  - 初始位置: $\\boldsymbol{x}_0 = \\boldsymbol{0}$。\n  - 初始步长: $\\sigma_0 = 10$。\n  - 预烧迭代次数: $N_{\\mathrm{burn}} = 8000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $123$。\n\n- 测试 C (曲率软化的二维 Rosenbrock 目标):\n  - 维度 $d = 2$。\n  - 定义势能 $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$。\n  - 目标密度: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$。\n  - 初始位置: $\\boldsymbol{x}_0 = (0,\\,0)$。\n  - 初始步长: $\\sigma_0 = 1$。\n  - 预烧迭代次数: $N_{\\mathrm{burn}} = 12000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $2024$。\n\n算法要求:\n- 使用高斯随机游走提议 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n- 仅在预烧期间，通过一个 Robbins-Monro 步骤更新 $\\theta_n = \\log \\sigma_n$，步长为 $\\gamma_n = c/(n + t_0)$（其中 $c$ 和 $t_0$ 为固定常数），使用该步骤观察到的接受概率。\n- 预烧结束后，固定 $\\sigma$ 并继续采样，不再进行任何自适应调整。\n- 为保证稳定性，您可以将 $\\theta_n$ 约束在一个较宽的区间内，以使 $\\sigma_n$ 保持有限。\n\n输出规范:\n- 对于每个测试，仅计算 $N_{\\mathrm{sample}}$ 次采样迭代的经验接受率。\n- 您的程序必须打印一行，其中包含一个列表，列表内有按 A、B、C 顺序排列的 3 个接受率，每个接受率四舍五入到三位小数，以小数形式表示（无百分号），格式必须完全为：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n本问题不涉及物理单位或角度单位。所有数值答案必须是小数。在给定种子的情况下，输出必须是确定性的。最终程序必须是完整的、可直接运行的，无需任何输入，且不得访问任何外部资源。",
            "solution": "任务是实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛 (MCMC) 算法。该算法必须在预烧 (burn-in) 阶段调整其标量提议步长 $\\sigma$，以达到指定的目标接受率 $a^\\star$。该算法的理论基础——Metropolis-Hastings 接受规则和用于自适应的 Robbins-Monro 随机近似——必须从第一性原理推导得出。\n\n### 问题验证\n\n首先，我们验证问题陈述。\n\n#### 第 1 步：提取给定信息\n\n- **基本原理**:\n    - 细致平衡: $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n    - Metropolis-Hastings (M-H) 构建：转移核 $P(\\boldsymbol{x},\\boldsymbol{y})$ 由提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 和接受概率 $\\alpha(\\boldsymbol{x},\\boldsymbol{y})$ 构建。\n    - 随机近似：参数更新遵循一个方案，以递减的步长求解 $\\mathbb{E}[h(\\theta)] = 0$。\n\n- **任务**:\n    1.  从细致平衡条件出发，推导对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 的 M-H 接受概率。\n    2.  推导并实现一个 Robbins-Monro 更新算法，用于更新对数步长 $\\theta = \\log \\sigma$，以将接受率驱动至目标值 $a^\\star$。更新必须使用增益 $\\gamma_n = c/(n+t_0)$，并仅限于预烧阶段。\n    3.  实现完整的算法，在预烧后固定 $\\sigma$，并计算采样阶段的经验接受率。\n\n- **算法要求**:\n    - 提议：高斯随机游走 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n    - 自适应：仅在预烧期间，通过 Robbins-Monro 方法以增益 $\\gamma_n = c/(n+t_0)$ 更新 $\\theta_n = \\log \\sigma_n$。\n    - 采样：预烧后固定 $\\sigma$。\n    - 目标接受率：所有测试均为 $a^\\star = 0.23$。\n\n- **测试用例**:\n    - **测试 A**: $d=1$，对数密度 $\\log \\pi(x) = -\\tfrac{1}{2} x^2$，$x_0 = 0$，$\\sigma_0 = 0.001$，$N_{\\mathrm{burn}} = 6000$，$N_{\\mathrm{sample}} = 12000$，种子 $42$。\n    - **测试 B**: $d=5$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$，$\\boldsymbol{x}_0 = \\boldsymbol{0}$，$\\sigma_0 = 10$，$N_{\\mathrm{burn}} = 8000$，$N_{\\mathrm{sample}} = 12000$，种子 $123$。\n    - **测试 C**: $d=2$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$，其中 $U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$，$\\boldsymbol{x}_0 = (0,0)$，$\\sigma_0 = 1$，$N_{\\mathrm{burn}} = 12000$，$N_{\\mathrm{sample}} = 12000$，种子 $2024$。\n\n- **输出规范**: 一行包含一个列表，其中有三个分别对应测试 A、B、C 的接受率，四舍五入到三位小数：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n#### 第 2 步：使用提取的给定信息进行验证\n\n根据验证标准对问题进行审查。\n- **科学基础**: 该问题基于计算统计和物理学中已确立的基本原理，即 MCMC 理论、细致平衡和随机近似。目标分布是该领域的标准基准。问题不含伪科学。\n- **良构性 (Well-Posed)**: 目标明确，每个测试用例的所有必要参数（维度、目标密度、初始条件、迭代次数、随机种子）都已指定。输出格式定义精确。在给定种子的情况下，问题是确定性的。预期会有一个唯一的、有意义的解。Robbins-Monro 常数 $c$ 和 $t_0$ 的选择留给实现者，这是一个标准的设计决策，而非缺陷。\n- **客观性**: 语言技术性强、精确且无歧义。没有主观或基于意见的陈述。\n\n问题是自洽的、一致的且科学上合理的。没有发现任何缺陷。\n\n#### 第 3 步：结论与行动\n\n问题有效。我们继续进行解答。\n\n### 推导与算法设计\n\n#### 1. Metropolis-Hastings 接受概率\n\n目标是构建一个具有平稳分布 $\\pi(\\boldsymbol{x})$ 的马尔可夫链。转移核 $P(\\boldsymbol{x}, \\boldsymbol{y})$ 给出了从状态 $\\boldsymbol{x}$ 移动到 $\\boldsymbol{y}$ 的概率密度，它必须满足细致平衡条件：\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n在 Metropolis-Hastings 框架中，转移是一个两步过程：从提议密度 $q(\\boldsymbol{y} \\mid \\boldsymbol{x})$ 中提出一个新状态 $\\boldsymbol{y}$，然后以概率 $\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$ 接受它。对于 $\\boldsymbol{x} \\neq \\boldsymbol{y}$，转移核为 $P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$。将其代入细致平衡方程，得到：\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n这意味着接受概率的比率必须满足以下约束：\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\n满足此条件的标准 Metropolis 接受概率选择是：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\n问题指定了一个对称高斯随机游走提议：$\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$。其提议密度为：\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\n由于 $(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$，该提议是对称的，即 $q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$。接受率比值中的提议项被抵消，从而得到简化的 Metropolis 接受概率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\n由于目标密度 $\\pi(\\boldsymbol{x})$ 通常仅在相差一个归一化常数的情况下是已知的，我们使用未归一化的密度或者更稳定地使用其对数来计算此比率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\n这就是需要实现的公式。\n\n#### 2. 使用随机近似的自适应步长\n\n目标是调整提议步长 $\\sigma$，使得期望接受率与目标值 $a^\\star$ 相匹配。设 $\\theta = \\log \\sigma$ 为待调整的参数。更新在预烧阶段进行。我们希望找到函数 $g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$ 的根，其中 $\\alpha(\\theta)$ 是给定 $\\theta$ 时的接受概率。\n\nRobbins-Monro 算法是一种随机求根方法。对于一个函数 $g(\\theta)$，我们可以使用迭代格式 $\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$ 来找到它的根，其中 $g_n$ 是在第 $n$ 步对 $g$ 的带噪声观测，而 $\\{\\gamma_n\\}$ 是一个满足 $\\sum \\gamma_n = \\infty$ 和 $\\sum \\gamma_n^2  \\infty$ 的步长序列。\n\n在我们的情况下，我们观察第 $n$ 次迭代的接受概率 $\\alpha_n$，并将其用作我们的带噪声测量。$\\theta_n = \\log\\sigma_n$ 的更新规则被制定为引导观察到的接受率趋向于 $a^\\star$：\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\n符号为正，是因为如果当前接受率 $\\alpha_n$ 高于目标值 $a^\\star$，我们需要增加 $\\theta$（从而增加 $\\sigma$）以使提议更大胆，从而降低接受率。反之，如果 $\\alpha_n  a^\\star$，我们减小 $\\theta$ 以使提议更保守，从而提高接受率。\n\n步长序列（增益）被给定为 $\\gamma_n = c/(n + t_0)$，其中 $n \\geq 1$。我们将选择 $c=1.0$ 和 $t_0=10.0$ 作为合理的常数，以确保稳定性和有效的自适应。在对数尺度上更新 $\\theta = \\log\\sigma$ 自然地确保了 $\\sigma = \\exp(\\theta)$ 保持为正。\n\n这种自适应方案使得马尔可夫链非齐次。为保证样本是从正确的平稳分布 $\\pi(\\boldsymbol{x})$ 中抽取的，自适应必须在预烧阶段结束后终止。在 $N_{\\mathrm{burn}}$ 次迭代后，步长 $\\sigma$ 被冻结在其最终调整值上，随后的 $N_{\\mathrm{sample}}$ 次迭代则作为标准的齐次 Metropolis MCMC 算法进行。马尔可夫链的遍历定理随后保证了从这些样本计算的平均值会收敛到关于 $\\pi(\\boldsymbol{x})$ 的期望。\n\n### 实现计划\n\n该算法将在一个函数中实现，该函数接受测试用例的参数。对于从 $n=1$ 到 $N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$ 的每次迭代：\n1.  生成一个提议 $\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n2.  计算 $\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$。\n3.  从 $U(0,1)$ 中抽取一个随机数 $u$。如果 $u  \\alpha$，则设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$ 并记录一次接受。否则，设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$。\n4.  如果 $n \\le N_{\\mathrm{burn}}$：\n    - 使用 Robbins-Monro 步骤更新 $\\log \\sigma_n$：$\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$。\n    - 为保证鲁棒性，我们将把 $\\log\\sigma$ 限制在一个合理的范围，例如 $[-10, 10]$。\n5.  如果 $n > N_{\\mathrm{burn}}$：\n    - 保持 $\\sigma$ 固定。\n    - 统计接受次数，以计算采样阶段的最终经验接受率。\n\n该过程将使用指定的参数和随机种子应用于三个测试用例中的每一个。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```"
        }
    ]
}