{
    "hands_on_practices": [
        {
            "introduction": "An Observing System Simulation Experiment's core is the ability to realistically simulate observations from a model's \"Nature Run.\" This practice challenges you to construct a forward operator, the crucial link between the model's continuous reality and the discrete, imperfect data an instrument provides. By modeling the physical characteristics of an ascending Argo float's temperature sensor, you will gain hands-on experience in creating the synthetic data that drives all subsequent OSSE analysis .",
            "id": "3805663",
            "problem": "You are tasked with designing and implementing a forward operator for Observing System Simulation Experiments (OSSEs) in computational oceanography that maps a one-dimensional ocean model state to synthetic observations resembling Argo profiling float temperature measurements. The forward operator must incorporate vertical interpolation from the model grid to continuous depth and account for the instrument’s measurement response characteristics along the ascent trajectory.\n\nBase assumptions and definitions to be used:\n- An Observing System Simulation Experiment (OSSE) represents observations as the output of a forward operator acting on a model state plus potential measurement and representation errors. The forward operator maps state variables to observed quantities in physically consistent ways.\n- An Argo profiling float ascends through the water column at a constant vertical speed and measures in-situ temperature using a first-order sensor with a finite response time. Consequently, the reported temperature at a given depth is not a perfect instantaneous sample but a vertically filtered quantity influenced by the float’s motion and the sensor’s dynamics.\n\nModel state and ocean scenario:\n- Consider a one-dimensional vertical model with depth coordinate $z$ in meters, where $z=0$ corresponds to the sea surface and increasing $z$ corresponds to deeper water.\n- The synthetic “true” ocean temperature profile is defined on a discrete model grid of $z$ values from $z_{\\min} = 0$ to $z_{\\max} = 2000$ with uniform spacing $\\Delta z = 20$ meters. The temperature field is given by\n$$\nT(z) = T_0 - \\Delta T \\cdot \\frac{1}{2}\\left(1 + \\tanh\\left(\\frac{z - z_0}{w}\\right)\\right),\n$$\nwith parameters $T_0 = 20$ (degrees Celsius), $\\Delta T = 16$ (degrees Celsius), $z_0 = 300$ (meters), and $w = 80$ (meters). This represents a realistic thermocline transition from warm surface waters to cooler deep waters.\n\nMeasurement response and forward operator requirements:\n- The forward operator at an observation depth $d$ must be the vertically filtered value of $T(z)$ according to a physically motivated measurement kernel. Two independent physical effects contribute to this kernel:\n  1. A symmetric spatial averaging component, modeled by a Gaussian kernel with standard deviation $\\sigma_g$ (in meters),\n  $$\n  G_\\sigma(z - d) = \\exp\\!\\left(-\\frac{(z - d)^2}{2\\sigma_g^2}\\right).\n  $$\n  2. A one-sided exponential component due to the first-order sensor response with time constant $\\tau$ (in seconds) and ascent speed $v$ (in meters per second). The product $L = v\\tau$ (in meters) is the characteristic vertical response length. For an ascending float, the measured value at $d$ is influenced by water at deeper depths $z \\ge d$ with weights\n  $$\n  E_L(z - d) = \n  \\begin{cases}\n  \\exp\\!\\left(-\\frac{z - d}{L}\\right), & z \\ge d, \\\\\n  0, & z < d.\n  \\end{cases}\n  $$\n- The combined measurement kernel at depth $d$ is the product\n$$\nK(d, z) = G_\\sigma(z - d)\\,E_L(z - d),\n$$\nwhich must be normalized over the finite domain of the calculation.\n- The synthetic observation at depth $d$ must be computed as the normalized weighted integral of $T(z)$ against $K(d, z)$ over $z$:\n$$\ny(d) = \\frac{\\int_{z_{\\min}}^{z_{\\max}} T(z)\\,K(d, z)\\,dz}{\\int_{z_{\\min}}^{z_{\\max}} K(d, z)\\,dz}.\n$$\n- Vertical interpolation: Because $T(z)$ is defined at discrete model levels, your forward operator must first vertically interpolate $T(z)$ to a finer evaluation grid before applying the kernel integration. Use piecewise-linear interpolation to produce $T(z)$ on a fine grid that adequately resolves the kernel. You may choose a fine-grid spacing $\\delta z$ in meters to ensure numerical accuracy.\n- Limiting cases that must be handled:\n  - If $\\tau = 0$ then $L = 0$, and the exponential component reduces to no filtering; the kernel must reduce to the Gaussian component only. If additionally $\\sigma_g = 0$, the kernel degenerates to a Dirac delta and the forward operator reduces to simple linear interpolation of $T(z)$ at $d$.\n  - If $\\sigma_g = 0$ and $\\tau > 0$, the kernel is purely the one-sided exponential due to instrument response.\n\nNumerical units and output requirements:\n- Depths are in meters. Speed $v$ is in meters per second. Time constant $\\tau$ is in seconds. Temperature must be computed and reported in degrees Celsius as decimal floats.\n- Angles do not appear in this problem.\n- No percentages appear in this problem.\n\nTest suite:\nImplement your program to compute synthetic observations for the following parameter sets and observation depths. For each parameter set, compute synthetic observations $y(d_j)$ at all specified depths $d_j$, and aggregate all results into a single flat list (in the order listed below).\n\n1. Happy-path case: Moderate instrument smoothing.\n   - Ascent speed $v = 0.08$ (meters per second), response time $\\tau = 10$ (seconds), Gaussian width $\\sigma_g = 2$ (meters), fine-grid spacing $\\delta z = 1$ (meter), depths $[50, 300, 1000]$ (meters).\n2. Boundary near-surface case: Purely exponential kernel (no Gaussian).\n   - Ascent speed $v = 0.06$ (meters per second), response time $\\tau = 30$ (seconds), Gaussian width $\\sigma_g = 0$ (meters), fine-grid spacing $\\delta z = 1$ (meter), depths $[5]$ (meters).\n3. Degenerate kernel case: Pure interpolation (no smoothing).\n   - Ascent speed $v = 0.10$ (meters per second), response time $\\tau = 0$ (seconds), Gaussian width $\\sigma_g = 0$ (meters), fine-grid spacing $\\delta z = 1$ (meter), depths $[123.4]$ (meters).\n4. Strong smoothing and near-bottom case: Combined Gaussian and exponential, including near-domain boundary.\n   - Ascent speed $v = 0.08$ (meters per second), response time $\\tau = 60$ (seconds), Gaussian width $\\sigma_g = 8$ (meters), fine-grid spacing $\\delta z = 1$ (meter), depths $[800, 1500, 1950]$ (meters).\n\nAlgorithmic design constraints:\n- You must implement the forward operator exactly as described: interpolate the discrete model temperature profile $T(z)$ to a fine grid and evaluate the normalized kernel integral numerically over the truncated domain. Renormalize the kernel over the domain actually used to avoid bias near boundaries.\n- Handle all limiting cases explicitly and consistently with physical reasoning.\n- Do not use any external data; the synthetic temperature profile and parameters provided must be used as-is.\n\nFinal output format:\n- Your program should produce a single line of output containing all computed synthetic observation values, expressed in degrees Celsius, aggregated in the order of the depths across all parameter sets described, as a comma-separated list enclosed in square brackets (for example, $[y_1,y_2,\\dots,y_N]$). Each value must be a decimal float. No additional text may be printed.",
            "solution": "The problem statement presented is valid. It is scientifically grounded in the principles of physical oceanography and instrument measurement, well-posed with all necessary information and constraints provided, and objective in its formulation. The task is to construct a numerical forward operator for an Observing System Simulation Experiment (OSSE), a standard technique in geosciences for evaluating the potential impact of observing systems.\n\nThe forward operator, denoted by $y(d)$, maps the model state—a vertical temperature profile $T(z)$—to a synthetic observation at a specified depth $d$. This process simulates the measurement taken by an ascending Argo profiling float, incorporating the physical effects of spatial averaging and the sensor's temporal response.\n\nThe problem will be solved by implementing the forward operator according to the provided mathematical and algorithmic specifications. The steps are as follows:\n1.  Define the synthetic \"true\" ocean state on a discrete model grid.\n2.  Implement a piecewise-linear interpolation scheme to represent the temperature profile on a finer computational grid.\n3.  Construct the measurement kernel $K(d, z)$ by combining its Gaussian and exponential components, carefully handling the specified limiting cases.\n4.  Compute the synthetic observation $y(d)$ by numerically evaluating the normalized weighted integral of the interpolated temperature profile against the kernel.\n\n**1. Ocean Model State**\n\nThe synthetic ocean is described by a one-dimensional vertical temperature profile, $T(z)$, where $z$ is the depth in meters. The sea surface is at $z=0$. The \"true\" temperature is given by the function:\n$$\nT(z) = T_0 - \\Delta T \\cdot \\frac{1}{2}\\left(1 + \\tanh\\left(\\frac{z - z_0}{w}\\right)\\right)\n$$\nThe parameters are provided as $T_0 = 20 \\,^{\\circ}\\text{C}$, $\\Delta T = 16 \\,^{\\circ}\\text{C}$, $z_0 = 300 \\, \\text{m}$, and $w = 80 \\, \\text{m}$. This function models a thermocline, a region of rapid temperature change, centered at depth $z_0$.\n\nThis continuous profile is initially defined on a discrete model grid with depths $z_m$ ranging from $z_{\\min} = 0 \\, \\text{m}$ to $z_{\\max} = 2000 \\, \\text{m}$ with a uniform spacing of $\\Delta z = 20 \\, \\text{m}$.\n\n**2. Forward Operator and Measurement Kernel**\n\nThe synthetic observation $y(d)$ at an observation depth $d$ is the temperature profile $T(z)$ filtered by a measurement kernel $K(d, z)$, and is mathematically expressed as a normalized integral:\n$$\ny(d) = \\frac{\\int_{z_{\\min}}^{z_{\\max}} T(z)\\,K(d, z)\\,dz}{\\int_{z_{\\min}}^{z_{\\max}} K(d, z)\\,dz}\n$$\nThe normalization by the integral of the kernel over the computational domain $[z_{\\min}, z_{\\max}]$ is crucial to prevent biases, particularly for observations near the domain boundaries where the kernel may be truncated.\n\nThe kernel $K(d, z)$ is the product of two components:\n$K(d, z) = G_\\sigma(z - d) \\cdot E_L(z - d)$.\n\n-   The Gaussian component, $G_\\sigma$, models symmetric spatial averaging:\n    $$\n    G_\\sigma(z - d) = \\exp\\!\\left(-\\frac{(z - d)^2}{2\\sigma_g^2}\\right)\n    $$\n    where $\\sigma_g$ is the standard deviation in meters.\n\n-   The one-sided exponential component, $E_L$, models the first-order response of the ascending sensor:\n    $$\n    E_L(z - d) = \n    \\begin{cases}\n    \\exp\\!\\left(-\\frac{z - d}{L}\\right), & \\text{for } z \\ge d \\\\\n    0, & \\text{for } z < d\n    \\end{cases}\n    $$\n    Here, $L = v\\tau$ is the characteristic response length, with $v$ being the float's ascent speed and $\\tau$ the sensor's time constant. This term reflects that the measurement at depth $d$ is influenced by the water the float has just passed through at deeper depths ($z \\ge d$).\n\n**3. Numerical Implementation**\n\nThe continuous integral for $y(d)$ is approximated numerically.\n\n**Step A: Interpolation to a Fine Grid**\nThe model provides temperature values only at discrete depths $z_m$. To accurately resolve the kernel, we first create a fine computational grid, $z_{fine}$, with a small spacing $\\delta z$ (e.g., $\\delta z = 1 \\, \\text{m}$). The temperature profile is then interpolated from the coarse model grid to this fine grid using piecewise-linear interpolation. This yields a high-resolution profile $T_{fine}(z_i)$ for each point $z_i$ on the fine grid.\n\n**Step B: Kernel Evaluation and Limiting Cases**\nThe kernel $K(d, z_i)$ is evaluated for the given observation depth $d$ at each point $z_i$ of the fine grid. The implementation must correctly handle the prescribed limiting cases:\n-   **General Case ($\\sigma_g > 0, \\tau > 0$):** Both the Gaussian and exponential components are computed and multiplied to form the kernel.\n-   **Purely Exponential Case ($\\sigma_g = 0, \\tau > 0$):** The problem states the kernel reduces to the exponential component $E_L(z-d)$. This is implemented by treating the Gaussian factor as unity.\n-   **Purely Gaussian Case ($\\sigma_g > 0, \\tau = 0$):** The problem states the exponential component reduces to \"no filtering\". This is implemented by treating the exponential factor as unity.\n-   **Degenerate Case ($\\sigma_g = 0, \\tau = 0$):** The problem explicitly states that the kernel degenerates to a Dirac delta function, and the forward operator reduces to simple linear interpolation of $T(z)$ at depth $d$. This case must be handled separately, bypassing the kernel integration and directly interpolating the temperature from the original model grid.\n\n**Step C: Numerical Integration (Weighted Average)**\nThe normalized integral is approximated as a discrete weighted sum over the fine grid points $z_i$:\n$$\ny(d) \\approx \\frac{\\sum_{i} T_{fine}(z_i) \\cdot K(d, z_i) \\cdot \\delta z}{\\sum_{i} K(d, z_i) \\cdot \\delta z} = \\frac{\\sum_{i} T_{fine}(z_i) \\cdot K(d, z_i)}{\\sum_{i} K(d, z_i)}\n$$\nThis is equivalent to a weighted average of the fine-grid temperatures, where the weights are given by the kernel values. This calculation is performed for each required observation depth $d$ and each set of parameters $(v, \\tau, \\sigma_g)$. The results are then aggregated into a single list as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to compute synthetic observations for all test cases.\n    \"\"\"\n    \n    # Define model parameters as specified in the problem statement.\n    T0 = 20.0     # degrees Celsius\n    DT = 16.0     # degrees Celsius\n    z0 = 300.0    # meters\n    w = 80.0      # meters\n    z_min = 0.0   # meters\n    z_max = 2000.0 # meters\n    dz_model = 20.0 # meters\n\n    # Create the discrete model grid and compute the \"true\" temperature profile on it.\n    z_model = np.arange(z_min, z_max + dz_model, dz_model)\n    T_model = T0 - DT * 0.5 * (1 + np.tanh((z_model - z0) / w))\n    \n    # Define a reusable function for the forward operator.\n    def forward_operator(obs_depths, v, tau, sigma_g, dz_fine, z_model_grid, T_model_profile):\n        \"\"\"\n        Computes synthetic observations for a set of depths and parameters.\n\n        Args:\n            obs_depths (list): List of observation depths in meters.\n            v (float): Ascent speed in m/s.\n            tau (float): Sensor time constant in seconds.\n            sigma_g (float): Gaussian standard deviation in meters.\n            dz_fine (float): Fine-grid spacing in meters.\n            z_model_grid (np.ndarray): The model depth grid.\n            T_model_profile (np.ndarray): The temperature profile on the model grid.\n\n        Returns:\n            list: A list of computed synthetic observation values.\n        \"\"\"\n        \n        # Handle the degenerate case: pure interpolation (no smoothing)\n        if tau == 0.0 and sigma_g == 0.0:\n            # As per problem, this reduces to simple linear interpolation of T(z) at d.\n            return [np.interp(d, z_model_grid, T_model_profile) for d in obs_depths]\n\n        # Create the fine evaluation grid\n        z_fine = np.arange(z_model_grid[0], z_model_grid[-1] + dz_fine, dz_fine)\n        \n        # Interpolate the model temperature to the fine grid\n        T_fine = np.interp(z_fine, z_model_grid, T_model_profile)\n        \n        results = []\n        for d in obs_depths:\n            # Initialize kernel as an array of ones\n            kernel = np.ones_like(z_fine)\n            \n            # 1. Gaussian component\n            if sigma_g > 0:\n                gaussian_term = np.exp(-((z_fine - d)**2) / (2 * sigma_g**2))\n                kernel *= gaussian_term\n            \n            # 2. Exponential component\n            if tau > 0:\n                L = v * tau\n                if L > 0: # Avoid division by zero if v=0\n                    exp_term = np.zeros_like(z_fine)\n                    # Apply for z >= d, as per definition of E_L(z-d)\n                    mask = z_fine >= d\n                    exp_term[mask] = np.exp(-(z_fine[mask] - d) / L)\n                    kernel *= exp_term\n                # if L=0 (from v=0, tau>0), exp_term remains zero, effectively nullifying the signal, which is physically consistent.\n            \n            # Compute the normalized weighted average\n            numerator = np.sum(T_fine * kernel)\n            denominator = np.sum(kernel)\n            \n            # Avoid division by zero, though unlikely with the given parameters.\n            if denominator > 0:\n                y_d = numerator / denominator\n            else:\n                # If kernel is zero everywhere, interpolate as a fallback.\n                y_d = np.interp(d, z_fine, T_fine)\n            \n            results.append(y_d)\n            \n        return results\n\n    # Test suite parameters\n    test_cases = [\n        # 1. Happy-path case: Moderate instrument smoothing.\n        {'v': 0.08, 'tau': 10, 'sigma_g': 2, 'dz_fine': 1, 'depths': [50, 300, 1000]},\n        # 2. Boundary near-surface case: Purely exponential kernel (no Gaussian).\n        {'v': 0.06, 'tau': 30, 'sigma_g': 0, 'dz_fine': 1, 'depths': [5]},\n        # 3. Degenerate kernel case: Pure interpolation (no smoothing).\n        {'v': 0.10, 'tau': 0, 'sigma_g': 0, 'dz_fine': 1, 'depths': [123.4]},\n        # 4. Strong smoothing and near-bottom case: Combined Gaussian and exponential.\n        {'v': 0.08, 'tau': 60, 'sigma_g': 8, 'dz_fine': 1, 'depths': [800, 1500, 1950]},\n    ]\n    \n    all_results = []\n    for case in test_cases:\n        results_for_case = forward_operator(\n            obs_depths=case['depths'], \n            v=case['v'], \n            tau=case['tau'], \n            sigma_g=case['sigma_g'],\n            dz_fine=case['dz_fine'],\n            z_model_grid=z_model, \n            T_model_profile=T_model\n        )\n        all_results.extend(results_for_case)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Simply simulating an observation is not enough; we must also characterize its expected error for use in data assimilation. This exercise focuses on constructing the observation error covariance matrix, $R$, by separating uncorrelated instrument noise from spatially correlated representativeness error. You will connect a fundamental concept in physical oceanography—the baroclinic deformation radius—to the statistical modeling of unresolved scales, a critical skill for designing realistic OSSEs .",
            "id": "3805690",
            "problem": "In the context of Observing System Simulation Experiments (OSSEs), consider a one-dimensional along-track set of three sea-surface height observation locations at positions $x_1=0\\,\\mathrm{km}$, $x_2=20\\,\\mathrm{km}$, and $x_3=50\\,\\mathrm{km}$. The observing system is an along-track satellite altimeter sampling a high-resolution ocean model whose data are subsequently thinned to a coarser analysis grid. The total observation error is modeled as the sum of two components: an instrument noise that is spatially uncorrelated with known variance $\\sigma^2$, and a representativeness error arising from unresolved mesoscale variability that is spatially correlated. Assume the instrument noise variance is $\\sigma^2=4.0\\times 10^{-4}\\,\\mathrm{m}^2$ and the representativeness error covariance function is isotropic and given by\n$$\nC(r)=\\sigma_r^2 \\exp\\!\\left(-\\frac{r}{L}\\right),\n$$\nwith representativeness error variance $\\sigma_r^2=2.5\\times 10^{-3}\\,\\mathrm{m}^2$ and unknown correlation length $L$.\n\nUsing a reduced-gravity, first baroclinic mode framework, estimate the baroclinic deformation radius $R_1$ from the phase speed $c$ and the Coriolis parameter $f$, where $c=\\sqrt{g' H}$ and $R_1=c/f$. Take the reduced gravity $g'=2.0\\times 10^{-2}\\,\\mathrm{m}\\,\\mathrm{s}^{-2}$, the upper-layer thickness $H=100\\,\\mathrm{m}$, and the mid-latitude Coriolis parameter $f=1.0\\times 10^{-4}\\,\\mathrm{s}^{-1}$. Argue, from first principles, why it is physically reasonable to set the representativeness correlation length $L$ equal to the baroclinic deformation radius $R_1$ for mesoscale-dominated representativeness error in this OSSE configuration.\n\nThen, for the given observation locations, construct the full $3\\times 3$ observation error covariance matrix $R$ that combines the uncorrelated instrument noise and the correlated representativeness error. Express all entries of $R$ in $\\mathrm{m}^2$ and round each element to four significant figures. Your final answer must be the matrix $R$ only.",
            "solution": "The problem is evaluated as valid. It is scientifically grounded in the principles of physical oceanography and data assimilation, is well-posed with sufficient information for a unique solution, and is stated in objective, formal language. The solution proceeds in three stages: first, the calculation of the baroclinic deformation radius $R_1$; second, the physical justification for equating the representativeness error correlation length $L$ with $R_1$; and third, the construction of the total observation error covariance matrix $R$.\n\nStage 1: Calculation of the Baroclinic Deformation Radius $R_1$\n\nThe first baroclinic Rossby radius of deformation, $R_1$, is defined as the ratio of the first baroclinic mode gravity wave phase speed, $c$, to the Coriolis parameter, $f$. The phase speed $c$ is given by $c=\\sqrt{g' H}$. The givens are:\n- Reduced gravity $g' = 2.0 \\times 10^{-2}\\,\\mathrm{m}\\,\\mathrm{s}^{-2}$\n- Upper-layer thickness $H = 100\\,\\mathrm{m}$\n- Coriolis parameter $f = 1.0 \\times 10^{-4}\\,\\mathrm{s}^{-1}$\n\nFirst, we calculate the phase speed $c$:\n$$\nc = \\sqrt{g' H} = \\sqrt{(2.0 \\times 10^{-2}\\,\\mathrm{m}\\,\\mathrm{s}^{-2}) \\times (100\\,\\mathrm{m})} = \\sqrt{2.0}\\,\\mathrm{m}\\,\\mathrm{s}^{-1}\n$$\nNext, we calculate the deformation radius $R_1$:\n$$\nR_1 = \\frac{c}{f} = \\frac{\\sqrt{2.0}\\,\\mathrm{m}\\,\\mathrm{s}^{-1}}{1.0 \\times 10^{-4}\\,\\mathrm{s}^{-1}} = \\sqrt{2.0} \\times 10^4\\,\\mathrm{m}\n$$\nFor practical use in the covariance calculation, we convert this to kilometers:\n$$\nR_1 = \\sqrt{2.0} \\times 10^4\\,\\mathrm{m} = 10\\sqrt{2}\\,\\mathrm{km} \\approx 14.14\\,\\mathrm{km}\n$$\n\nStage 2: Physical Justification for Setting $L = R_1$\n\nThe problem states that the representativeness error arises from unresolved mesoscale variability. This error component quantifies the discrepancy between a point observation and the value of a coarse-resolution model state variable representing a larger area or volume. In the context of an OSSE, the \"truth\" is a high-resolution nature run that resolves mesoscale features, while the analysis is performed on a coarser grid that does not.\n\nIn mid-latitude oceans, the dominant form of kinetic energy variability at scales of tens to hundreds of kilometers is associated with mesoscale eddies and meanders. The fundamental horizontal length scale that governs the size of these features is the first baroclinic Rossby radius of deformation, $R_1$. Baroclinic instability, the primary mechanism for the generation of mesoscale eddies, is most effective at wavelengths proportional to $R_1$. The resulting eddies have a characteristic radius, and thus a spatial coherence scale, on the order of $R_1$.\n\nSince the representativeness error in this problem is explicitly attributed to unresolved mesoscale variability, its statistical properties, particularly its spatial correlation structure, must reflect the physics of that variability. The correlation length scale, $L$, of the error field should therefore correspond to the characteristic size of the unresolved features. As $R_1$ is the natural length scale for these mesoscale eddies, it is a well-established and physically sound practice in ocean data assimilation to set the representativeness error correlation length $L$ equal to the first baroclinic deformation radius $R_1$. Thus, we set $L=R_1=10\\sqrt{2}\\,\\mathrm{km}$.\n\nStage 3: Construction of the Observation Error Covariance Matrix $R$\n\nThe total observation error covariance matrix $R$ is the sum of the instrument noise covariance matrix, $R_{instr}$, and the representativeness error covariance matrix, $R_{rep}$:\n$$\nR = R_{instr} + R_{rep}\n$$\nThe observation locations are $x_1=0\\,\\mathrm{km}$, $x_2=20\\,\\mathrm{km}$, and $x_3=50\\,\\mathrm{km}$.\n\nThe instrument noise is spatially uncorrelated with variance $\\sigma^2 = 4.0 \\times 10^{-4}\\,\\mathrm{m}^2$. Its covariance matrix is diagonal:\n$$\nR_{instr} = \\sigma^2 I_3 = \\begin{pmatrix} \\sigma^2 & 0 & 0 \\\\ 0 & \\sigma^2 & 0 \\\\ 0 & 0 & \\sigma^2 \\end{pmatrix} = \\begin{pmatrix} 4.0 \\times 10^{-4} & 0 & 0 \\\\ 0 & 4.0 \\times 10^{-4} & 0 \\\\ 0 & 0 & 4.0 \\times 10^{-4} \\end{pmatrix}\\,\\mathrm{m}^2\n$$\n\nThe representativeness error is spatially correlated. The elements of its covariance matrix, $(R_{rep})_{ij}$, are given by the covariance function $C(r_{ij}) = \\sigma_r^2 \\exp(-r_{ij}/L)$, where $r_{ij} = |x_i - x_j|$ is the distance between observations $i$ and $j$. We have $\\sigma_r^2 = 2.5 \\times 10^{-3}\\,\\mathrm{m}^2$ and $L=10\\sqrt{2}\\,\\mathrm{km}$.\nFirst, we compute the matrix of distances $r_{ij}$ in kilometers:\n$$\nr_{12} = |x_1 - x_2| = |0 - 20| = 20\\,\\mathrm{km}\n$$\n$$\nr_{13} = |x_1 - x_3| = |0 - 50| = 50\\,\\mathrm{km}\n$$\n$$\nr_{23} = |x_2 - x_3| = |20 - 50| = 30\\,\\mathrm{km}\n$$\nBy symmetry, $r_{ji}=r_{ij}$, and $r_{ii}=0$.\n\nThe diagonal elements of $R_{rep}$ are the variance $\\sigma_r^2$:\n$$\n(R_{rep})_{11} = (R_{rep})_{22} = (R_{rep})_{33} = C(0) = \\sigma_r^2 \\exp(0) = 2.5 \\times 10^{-3}\\,\\mathrm{m}^2\n$$\nThe off-diagonal elements are:\n$$\n(R_{rep})_{12} = (R_{rep})_{21} = C(20) = (2.5 \\times 10^{-3}) \\exp\\left(-\\frac{20}{10\\sqrt{2}}\\right) = (2.5 \\times 10^{-3}) \\exp(-\\sqrt{2}) \\approx 6.07796 \\times 10^{-4}\\,\\mathrm{m}^2\n$$\n$$\n(R_{rep})_{13} = (R_{rep})_{31} = C(50) = (2.5 \\times 10^{-3}) \\exp\\left(-\\frac{50}{10\\sqrt{2}}\\right) = (2.5 \\times 10^{-3}) \\exp\\left(-\\frac{5}{\\sqrt{2}}\\right) \\approx 7.28601 \\times 10^{-5}\\,\\mathrm{m}^2\n$$\n$$\n(R_{rep})_{23} = (R_{rep})_{32} = C(30) = (2.5 \\times 10^{-3}) \\exp\\left(-\\frac{30}{10\\sqrt{2}}\\right) = (2.5 \\times 10^{-3}) \\exp\\left(-\\frac{3}{\\sqrt{2}}\\right) \\approx 2.99651 \\times 10^{-4}\\,\\mathrm{m}^2\n$$\n\nNow we combine $R_{instr}$ and $R_{rep}$ to form $R$. The elements $R_{ij}$ are given by $R_{ij} = (R_{instr})_{ij} + (R_{rep})_{ij}$.\nThe diagonal elements are:\n$$\nR_{11} = R_{22} = R_{33} = \\sigma^2 + \\sigma_r^2 = (4.0 \\times 10^{-4}) + (2.5 \\times 10^{-3}) = (0.4 \\times 10^{-3}) + (2.5 \\times 10^{-3}) = 2.9 \\times 10^{-3}\\,\\mathrm{m}^2\n$$\nThe off-diagonal elements are simply the elements of $R_{rep}$ since $R_{instr}$ is diagonal. Rounding all elements to four significant figures:\n$R_{11} = R_{22} = R_{33} = 2.900 \\times 10^{-3}\\,\\mathrm{m}^2$\n$R_{12} = R_{21} \\approx 6.078 \\times 10^{-4}\\,\\mathrm{m}^2$\n$R_{13} = R_{31} \\approx 7.286 \\times 10^{-5}\\,\\mathrm{m}^2$\n$R_{23} = R_{32} \\approx 2.997 \\times 10^{-4}\\,\\mathrm{m}^2$\n\nThe final observation error covariance matrix $R$ is:\n$$\nR = \\begin{pmatrix}\n2.900 \\times 10^{-3} & 6.078 \\times 10^{-4} & 7.286 \\times 10^{-5} \\\\\n6.078 \\times 10^{-4} & 2.900 \\times 10^{-3} & 2.997 \\times 10^{-4} \\\\\n7.286 \\times 10^{-5} & 2.997 \\times 10^{-4} & 2.900 \\times 10^{-3}\n\\end{pmatrix}\n$$\nAll elements are in units of $\\mathrm{m}^2$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.900 \\times 10^{-3} & 6.078 \\times 10^{-4} & 7.286 \\times 10^{-5} \\\\\n6.078 \\times 10^{-4} & 2.900 \\times 10^{-3} & 2.997 \\times 10^{-4} \\\\\n7.286 \\times 10^{-5} & 2.997 \\times 10^{-4} & 2.900 \\times 10^{-3}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The ultimate goal of an OSSE is to quantify the value of an observing system. This culminating practice guides you through the final step of the process: data assimilation and impact assessment for a simplified system. Using the core components of a linear estimation framework—the prior uncertainty $B$, the forward operator $H$, and the observation error $R$—you will calculate the posterior analysis error covariance $P_a$ to directly measure the reduction in uncertainty and thus the impact of the simulated observations .",
            "id": "3900301",
            "problem": "An Observing System Simulation Experiment (OSSE) pipeline is being constructed and documented for a two-variable geophysical state representing large-scale anomalies. The pipeline modules and their documented linear operators are as follows:\n\n- Nature run and prior: The unknown state is $x \\in \\mathbb{R}^{2}$. The prior (background) is Gaussian with mean $0$ and covariance\n$$\nB = \\begin{pmatrix}\n4 & 1.2 \\\\\n1.2 & 9\n\\end{pmatrix}.\n$$\n\n- Observation simulator: A satellite forward operator maps $x$ to observation space via\n$$\nH = \\begin{pmatrix}\n1 & 0.5 \\\\\n0.2 & 1\n\\end{pmatrix}.\n$$\nThe raw measurements are subject to an additive, known constant bias vector, which is removed exactly by a documented bias-correction module, and to zero-mean Gaussian measurement noise $v \\sim \\mathcal{N}(0,R)$ with covariance\n$$\nR = \\begin{pmatrix}\n1.0 & 0.3 \\\\\n0.3 & 2.25\n\\end{pmatrix}.\n$$\n\n- Quality control and thinning: Documentation indicates both channels pass quality control and are retained without thinning for assimilation.\n\n- Data assimilation: The analysis is produced by the linear minimum-variance estimator under the Gaussian assumptions consistent with the modules above.\n\nUsing only fundamental principles of Bayesian linear estimation and the documented operators $B$, $H$, and $R$, determine the analysis root-mean-square error (RMSE) in state space, defined as $\\sqrt{\\operatorname{tr}(P_{\\text{a}})/2}$ where $P_{\\text{a}}$ is the posterior error covariance of the analysis. Round your answer to four significant figures. Report the final answer as a nondimensional number.",
            "solution": "The problem requires the calculation of the analysis root-mean-square error (RMSE) for a two-variable linear estimation problem. The framework is that of Bayesian linear estimation, where a prior estimate of the state (the background) is updated with information from observations to produce a posterior estimate (the analysis).\n\nThe background state vector $x_b$ is assumed to be a random variable with mean $0$ and prior error covariance matrix $B$. The true state is denoted by $x$. The observation vector $y$ is related to the true state via the linear operator $H$, and is corrupted by additive zero-mean Gaussian noise $v$ with covariance matrix $R$. The observation model is $y = Hx + v$.\n\nThe analysis state $x_a$ is the minimum-variance estimate of $x$ given the background $x_b$ and the observation $y$. Under the stated Gaussian assumptions, the posterior probability distribution for the state $x$ given the observation $y$ is also Gaussian. The mean of this posterior distribution is the analysis state $x_a$, and its covariance is the analysis error covariance matrix, $P_a$.\n\nThe analysis error covariance $P_a$ is given by the inverse of the sum of the prior and observation precision matrices (inverse covariances). This is a standard result from linear minimum-variance estimation theory and is equivalent to the covariance update equation in the Kalman filter. The formula is:\n$$\nP_a^{-1} = B^{-1} + H^T R^{-1} H\n$$\nWe will compute $P_a$ by first calculating the terms on the right-hand side, summing them to find the posterior precision matrix $P_a^{-1}$, and then inverting the result.\n\nThe given matrices are:\n$$\nB = \\begin{pmatrix} 4 & 1.2 \\\\ 1.2 & 9 \\end{pmatrix}, \\quad H = \\begin{pmatrix} 1 & 0.5 \\\\ 0.2 & 1 \\end{pmatrix}, \\quad R = \\begin{pmatrix} 1.0 & 0.3 \\\\ 0.3 & 2.25 \\end{pmatrix}\n$$\nTo maintain precision, we will convert decimal values to fractions where appropriate: $1.2 = \\frac{6}{5}$, $0.5 = \\frac{1}{2}$, $0.2 = \\frac{1}{5}$, $0.3 = \\frac{3}{10}$, and $2.25 = \\frac{9}{4}$.\n\nFirst, we compute the inverse of the prior covariance matrix $B$:\n$$\n\\det(B) = (4)(9) - (1.2)(1.2) = 36 - 1.44 = 34.56 = \\frac{864}{25}\n$$\n$$\nB^{-1} = \\frac{1}{34.56} \\begin{pmatrix} 9 & -1.2 \\\\ -1.2 & 4 \\end{pmatrix} = \\frac{25}{864} \\begin{pmatrix} 9 & -\\frac{6}{5} \\\\ -\\frac{6}{5} & 4 \\end{pmatrix} = \\frac{1}{864} \\begin{pmatrix} 225 & -30 \\\\ -30 & 100 \\end{pmatrix}\n$$\n\nNext, we compute the inverse of the observation error covariance matrix $R$:\n$$\n\\det(R) = (1.0)(2.25) - (0.3)(0.3) = 2.25 - 0.09 = 2.16 = \\frac{54}{25}\n$$\n$$\nR^{-1} = \\frac{1}{2.16} \\begin{pmatrix} 2.25 & -0.3 \\\\ -0.3 & 1.0 \\end{pmatrix} = \\frac{25}{54} \\begin{pmatrix} \\frac{9}{4} & -\\frac{3}{10} \\\\ -\\frac{3}{10} & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{25}{54} \\frac{9}{4} & -\\frac{25}{54} \\frac{3}{10} \\\\ -\\frac{25}{54} \\frac{3}{10} & \\frac{25}{54} \\end{pmatrix} = \\begin{pmatrix} \\frac{25}{24} & -\\frac{5}{36} \\\\ -\\frac{5}{36} & \\frac{25}{54} \\end{pmatrix}\n$$\n\nNow we compute the term $H^T R^{-1} H$. The transpose of $H$ is $H^T = \\begin{pmatrix} 1 & 0.2 \\\\ 0.5 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{5} \\\\ \\frac{1}{2} & 1 \\end{pmatrix}$.\n$$\nH^T R^{-1} = \\begin{pmatrix} 1 & \\frac{1}{5} \\\\ \\frac{1}{2} & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{25}{24} & -\\frac{5}{36} \\\\ -\\frac{5}{36} & \\frac{25}{54} \\end{pmatrix} = \\begin{pmatrix} \\frac{25}{24} - \\frac{1}{36} & -\\frac{5}{36} + \\frac{5}{54} \\\\ \\frac{25}{48} - \\frac{5}{36} & -\\frac{5}{72} + \\frac{25}{54} \\end{pmatrix} = \\begin{pmatrix} \\frac{73}{72} & -\\frac{5}{108} \\\\ \\frac{55}{144} & \\frac{85}{216} \\end{pmatrix}\n$$\n$$\nH^T R^{-1} H = \\begin{pmatrix} \\frac{73}{72} & -\\frac{5}{108} \\\\ \\frac{55}{144} & \\frac{85}{216} \\end{pmatrix} \\begin{pmatrix} 1 & \\frac{1}{2} \\\\ \\frac{1}{5} & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{73}{72}-\\frac{1}{108} & \\frac{73}{144}-\\frac{5}{108} \\\\ \\frac{55}{144}+\\frac{17}{216} & \\frac{55}{288}+\\frac{85}{216} \\end{pmatrix} = \\begin{pmatrix} \\frac{217}{216} & \\frac{199}{432} \\\\ \\frac{199}{432} & \\frac{505}{864} \\end{pmatrix}\n$$\nTo facilitate addition, we write this matrix with a common denominator of $864$:\n$$\nH^T R^{-1} H = \\frac{1}{864} \\begin{pmatrix} 868 & 398 \\\\ 398 & 505 \\end{pmatrix}\n$$\n\nNow we sum the precision matrices to find $P_a^{-1}$:\n$$\nP_a^{-1} = B^{-1} + H^T R^{-1} H = \\frac{1}{864} \\begin{pmatrix} 225 & -30 \\\\ -30 & 100 \\end{pmatrix} + \\frac{1}{864} \\begin{pmatrix} 868 & 398 \\\\ 398 & 505 \\end{pmatrix} = \\frac{1}{864} \\begin{pmatrix} 1093 & 368 \\\\ 368 & 605 \\end{pmatrix}\n$$\n\nTo find $P_a$, we invert $P_a^{-1}$:\n$$\n\\det(P_a^{-1}) = \\left(\\frac{1}{864}\\right)^2 \\left( (1093)(605) - (368)^2 \\right) = \\frac{661265 - 135424}{864^2} = \\frac{525841}{864^2}\n$$\n$$\nP_a = (P_a^{-1})^{-1} = \\frac{864^2}{525841} \\left( \\frac{1}{864} \\begin{pmatrix} 605 & -368 \\\\ -368 & 1093 \\end{pmatrix} \\right) = \\frac{864}{525841} \\begin{pmatrix} 605 & -368 \\\\ -368 & 1093 \\end{pmatrix}\n$$\n\nThe problem asks for the analysis RMSE, defined as $\\sqrt{\\operatorname{tr}(P_{\\text{a}})/2}$. First, we compute the trace of $P_a$:\n$$\n\\operatorname{tr}(P_a) = \\frac{864}{525841} (605 + 1093) = \\frac{864 \\times 1698}{525841} = \\frac{1467072}{525841}\n$$\n\nFinally, we calculate the RMSE:\n$$\n\\text{RMSE} = \\sqrt{\\frac{\\operatorname{tr}(P_a)}{2}} = \\sqrt{\\frac{1}{2} \\cdot \\frac{1467072}{525841}} = \\sqrt{\\frac{733536}{525841}}\n$$\nNow we compute the numerical value and round to four significant figures:\n$$\n\\text{RMSE} \\approx \\sqrt{1.3949790...} \\approx 1.1811346...\n$$\nRounding to four significant figures gives $1.181$.",
            "answer": "$$\\boxed{1.181}$$"
        }
    ]
}