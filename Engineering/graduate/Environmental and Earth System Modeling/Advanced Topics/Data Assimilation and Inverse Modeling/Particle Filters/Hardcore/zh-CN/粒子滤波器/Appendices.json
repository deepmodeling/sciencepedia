{
    "hands_on_practices": [
        {
            "introduction": "粒子滤波器的核心在于用一组带权重的粒子来近似概率分布。在实际应用中，一个常见的挑战是权重退化（degeneracy），即少数粒子的权重远大于其他粒子，导致样本多样性丧失。本练习旨在解决两个关键的实践问题：首先，如何从数值范围可能极大的对数权重（log-weights）中稳定地计算归一化权重；其次，如何量化退化程度。通过本练习 ，你将掌握避免数值溢出和下溢的“log-sum-exp”技巧，并学会计算有效样本量（Effective Sample Size, ESS），这是诊断粒子集健康状况和决定是否需要重采样的标准指标。",
            "id": "3906073",
            "problem": "考虑一个在环境和地球系统建模中使用的序贯重要性采样场景，其中，一个关于潜在环境状态的概率分布由一个加权粒子集合来近似。设有 $N$ 个粒子，索引为 $i \\in \\{1, \\dots, N\\}$，其未归一化重要性权重为 $\\tilde{w}_i \\geq 0$。归一化权重 $w_i$ 满足 $\\sum_{i=1}^{N} w_i = 1$ 且对于所有 $i$ 都有 $w_i \\geq 0$。在实际实现中，所提供的值通常是未归一化权重的对数，记为 $\\ell_i = \\log \\tilde{w}_i$，因为 $\\tilde{w}_i$ 的值可能跨越多个数量级。粒子滤波器中的一个核心问题是退化现象，即只有少数粒子具有显著的权重。一个公认的退化度量是有效样本量，它取决于归一化权重的二阶矩。\n\n从重要性采样和归一化的核心定义出发，推导并实现数值稳定的程序，以完成以下任务：\n- 将一个包含 $N$ 个对数权重的向量 $\\{\\ell_i\\}_{i=1}^N$ 转换为总和为 $1$ 的归一化权重 $\\{w_i\\}_{i=1}^N$，并在计算过程中避免数值下溢或上溢。\n- 使用基于归一化权重的原则性定义来计算有效样本量。\n\n您的实现必须能处理 $\\ell_i$ 的极端值，包括非常大的负值和负无穷大，并确保处理方式与归一化和有效样本量的数学性质一致。\n\n您将使用 $N=1000$ 个粒子，在五个模拟不同退化程度和数值压力的场景下测试您的程序。为保证可复现性，每个场景都指定了一个伪随机数生成器种子和构建对数权重 $\\{\\ell_i\\}_{i=1}^N$ 的规则：\n\n- 测试用例 1 (均衡变异性)：$N = 1000$。使用种子为 $s_1 = 42$ 的伪随机数生成器，并让 $\\ell_i$ 独立地从均值为 $0$、标准差为 $1$ 的正态分布中抽取。\n- 测试用例 2 (均匀权重)：$N = 1000$。对所有 $i$，设置 $\\ell_i = 0$。\n- 测试用例 3 (近乎完全退化)：$N = 1000$。设置 $\\ell_1 = 0$ 且对所有 $i \\in \\{2, \\dots, 1000\\}$，设置 $\\ell_i = -100$。\n- 测试用例 4 (极小权重)：$N = 1000$。使用种子为 $s_4 = 123$ 的伪随机数生成器，并让 $\\ell_i$ 独立地从均值为 $-1000$、标准差为 $10$ 的正态分布中抽取。\n- 测试用例 5 (结构性零值)：$N = 1000$。对 $i \\in \\{1, \\dots, 500\\}$ 设置 $\\ell_i = 0$，对 $i \\in \\{501, \\dots, 1000\\}$ 设置 $\\ell_i = -\\infty$，其中 $-\\infty$ 表示精确的负无穷大值。\n\n您的程序必须：\n1. 对每个测试用例，使用数值稳定的方法，根据提供的对数权重 $\\{\\ell_i\\}_{i=1}^N$ 计算归一化权重 $\\{w_i\\}_{i=1}^N$，并保证 $\\sum_{i=1}^{N} w_i = 1$。\n2. 对每个测试用例，使用归一化权重计算有效样本量。\n\n每个测试用例的输出必须是实数。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按上述测试用例的顺序排列五个有效样本量值（即 $[\\text{ESS}_1,\\text{ESS}_2,\\text{ESS}_3,\\text{ESS}_4,\\text{ESS}_5]$）。不涉及物理单位，也不需要角度或百分比。每个条目的结果类型必须是浮点数。",
            "solution": "该问题要求推导并实现数值稳定的方法，以便从一组给定的对数权重中计算出归一化重要性权重和有效样本量（ESS）。这是序贯重要性采样方法（如粒子滤波器）中的一项基础任务，该方法被广泛应用于环境和地球系统建模中以近似后验分布。\n\n解决方案分为两部分。首先，我们推导一个用于权重归一化的数值稳定程序。其次，我们定义有效样本量并概述其计算方法。\n\n**1. 对数权重的数值稳定归一化**\n\n设 $\\{\\ell_i\\}_{i=1}^N$ 是 $N$ 个粒子未归一化重要性权重的对数向量，其中 $\\ell_i = \\log \\tilde{w}_i$。因此，未归一化的权重为 $\\tilde{w}_i = \\exp(\\ell_i)$。\n\n第 $i$ 个粒子的归一化权重 $w_i$ 定义为其未归一化权重除以所有未归一化权重的总和：\n$$\nw_i = \\frac{\\tilde{w}_i}{\\sum_{j=1}^{N} \\tilde{w}_j} = \\frac{\\exp(\\ell_i)}{\\sum_{j=1}^{N} \\exp(\\ell_j)}\n$$\n对该表达式进行直接计算容易产生严重的数值错误。如果任何 $\\ell_j$ 是一个大的正数（例如，$\\ell_j  709$），$\\exp(\\ell_j)$ 将会超过标准 $64$ 位浮点数所能表示的最大值，导致上溢。反之，如果 $\\ell_j$ 是一个大的负数（例如，$\\ell_j  -709$），$\\exp(\\ell_j)$ 将会下溢至 $0$，如果所有权重都下溢，可能会导致精度损失或除以零。\n\n为规避此问题，我们采用一种标准的数值稳定技术，通常称为“log-sum-exp”技巧。设 $\\ell_{\\max} = \\max_{j=1}^N \\{\\ell_j\\}$。我们可以从 $w_i$ 的表达式中提出因子 $\\exp(\\ell_{\\max})$：\n$$\nw_i = \\frac{\\exp(\\ell_i)}{\\exp(\\ell_{\\max}) \\sum_{j=1}^{N} \\frac{\\exp(\\ell_j)}{\\exp(\\ell_{\\max})}} = \\frac{\\exp(\\ell_i - \\ell_{\\max})}{\\sum_{j=1}^{N} \\exp(\\ell_j - \\ell_{\\max})}\n$$\n这个修正后的公式是数值稳定的。分子指数项 $\\ell_i - \\ell_{\\max}$ 总是小于或等于 $0$，因此 $\\exp(\\ell_i - \\ell_{\\max})$ 的计算结果将在 $0$ 和 $1$ 之间，从而防止上溢。同样，分母求和中的所有项也都在 $0$ 和 $1$ 之间。对应于最大对数权重的项，即 $\\ell_j = \\ell_{\\max}$ 时，将为 $\\exp(0) = 1$，这确保了分母中的和至少为 $1$（除非所有 $\\ell_i$ 均为 $-\\infty$），从而防止了和的下溢。\n\n此公式也能正确处理对数权重为 $-\\infty$ 的情况。如果 $\\ell_i = -\\infty$，这在物理上对应于未归一化权重 $\\tilde{w}_i = 0$。在我们的稳定公式中，如果 $\\ell_i = -\\infty$ 而 $\\ell_{\\max}$ 是有限的，那么 $\\ell_i - \\ell_{\\max} = -\\infty$，而 $\\exp(-\\infty)$ 的计算结果为 $0$。最终的归一化权重 $w_i$ 将被正确地计算为 $0$。在所有 $\\ell_i = -\\infty$ 的特殊情况下，$\\ell_{\\max} = -\\infty$。这意味着所有粒子权重为零，分布未定义，有效样本量为零。\n\n**2. 有效样本量 (ESS)**\n\n有效样本量（$ESS$）是用于量化粒子集退化程度的度量。如果少数粒子的权重接近 $1$ 而其余粒子的权重接近 $0$，则认为粒子集是退化的。一个大小为 $N$ 的理想非退化样本将具有均匀权重，即对所有 $i$ 都有 $w_i = 1/N$。$ESS$ 提供了一个估计，即具有与当前加权粒子集相同统计方差的等效均匀加权粒子数。\n\n问题陈述指出 $ESS$ 取决于归一化权重的二阶矩。我们在此采用的标准且有原则的定义是：\n$$\nESS = \\frac{1}{\\sum_{i=1}^{N} w_i^2}\n$$\n这个定义与对退化的定性理解相符。\n- 对于具有均匀权重 $w_i = 1/N$ 的非退化样本，平方和为 $\\sum_{i=1}^{N} (1/N)^2 = N \\cdot (1/N^2) = 1/N$。因此 $ESS = 1 / (1/N) = N$，这是可能的最大值。\n- 对于一个最大程度退化的样本，其中一个粒子 $k$ 的权重 $w_k = 1$，而所有其他粒子的权重 $w_j = 0$（$j \\neq k$），平方和为 $\\sum_{i=1}^{N} w_i^2 = 1^2 = 1$。因此 $ESS = 1/1 = 1$，这是一个有效权重分布可能的最小值。\n\n$ESS$ 的值范围从 $1$ 到 $N$，提供了样本质量的连续度量。在粒子滤波器算法中，相对于 $N$ 而言较低的 $ESS$ 值表明需要进行重采样。\n\n**完整算法总结**\n\n从对数权重向量 $\\{\\ell_i\\}_{i=1}^N$ 计算 $ESS$ 的完整流程如下：\n1. 给定对数权重的输入向量 $\\boldsymbol{\\ell} = [\\ell_1, \\dots, \\ell_N]$。\n2. 找出最大对数权重：$\\ell_{\\max} = \\max_{i} \\{\\ell_i\\}$。\n3. 如果 $\\ell_{\\max} = -\\infty$（即所有对数权重均为 $-\\infty$），则有效样本量为 $0$。\n4. 否则，计算平移后的对数权重：$\\boldsymbol{\\ell'} = \\boldsymbol{\\ell} - \\ell_{\\max}$。\n5. 对平移后的对数权重取指数，得到中间值：$u_i = \\exp(\\ell'_i)$。\n6. 将这些值相加，得到归一化常数：$S = \\sum_{i=1}^{N} u_i$。\n7. 计算归一化权重：$w_i = u_i / S$。\n8. 计算归一化权重的平方和：$V = \\sum_{i=1}^{N} w_i^2$。\n9. 有效样本量是该和的倒数：$ESS = 1/V$。\n该算法具有数值鲁棒性，能够正确处理问题陈述中指定的极端值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by generating test cases, computing the effective\n    sample size for each, and printing the results in the specified format.\n    \"\"\"\n\n    def compute_ess_from_log_weights(log_weights: np.ndarray) - float:\n        \"\"\"\n        Computes the effective sample size (ESS) from a vector of log-weights\n        using a numerically stable method.\n\n        Args:\n            log_weights: A 1D NumPy array of log-weights.\n\n        Returns:\n            The effective sample size as a float.\n        \"\"\"\n        # Find the maximum log-weight. np.max correctly handles -np.inf.\n        l_max = np.max(log_weights)\n\n        # If all log-weights are -inf, the maximum will be -inf.\n        # This implies all weights are zero, so the effective sample size is 0.\n        if l_max == -np.inf:\n            return 0.0\n\n        # Shift the log-weights by subtracting the maximum value.\n        # This prevents overflow/underflow in the exp calculation (log-sum-exp trick).\n        # log_weights - l_max results in values = 0.\n        shifted_logs = log_weights - l_max\n\n        # Exponentiate the shifted log-weights.\n        # np.exp(-np.inf) correctly evaluates to 0.0.\n        unnormalized_weights = np.exp(shifted_logs)\n\n        # Calculate the sum for normalization.\n        sum_weights = np.sum(unnormalized_weights)\n\n        # Normalize the weights.\n        # This check is for the unlikely case that sum_weights is zero\n        # despite l_max not being -inf (e.g., due to catastrophic cancellation,\n        # though unlikely here).\n        if sum_weights == 0:\n            return 0.0\n            \n        normalized_weights = unnormalized_weights / sum_weights\n\n        # Compute the sum of the squares of the normalized weights.\n        # This is the second-order moment.\n        sum_sq_weights = np.sum(normalized_weights**2)\n        \n        # The sum of squared weights for a valid probability distribution cannot be zero.\n        # A check for zero is good practice to prevent division by zero errors.\n        if sum_sq_weights == 0:\n            return 0.0 # Should not be reached with valid normalized_weights\n\n        # The effective sample size is the reciprocal of the sum of squared weights.\n        ess = 1.0 / sum_sq_weights\n        \n        return ess\n\n    # --- Test Case Generation and Execution ---\n\n    N = 1000\n    test_cases = [\n        # Test Case 1: Balanced variability\n        {\"name\": \"balanced\", \"seed\": 42, \"type\": \"normal\", \"params\": {\"loc\": 0, \"scale\": 1}},\n        # Test Case 2: Uniform weights\n        {\"name\": \"uniform\", \"type\": \"constant\", \"value\": 0.0},\n        # Test Case 3: Near-total degeneracy\n        {\"name\": \"degenerate\", \"type\": \"specific\"},\n        # Test Case 4: Extremely small weights\n        {\"name\": \"small\", \"seed\": 123, \"type\": \"normal\", \"params\": {\"loc\": -1000, \"scale\": 10}},\n        # Test Case 5: Structural zeros\n        {\"name\": \"zeros\", \"type\": \"structural\"}\n    ]\n\n    results = []\n    for case in test_cases:\n        log_weights = np.zeros(N, dtype=float)\n        \n        if case[\"type\"] == \"normal\":\n            rng = np.random.default_rng(seed=case[\"seed\"])\n            log_weights = rng.normal(loc=case[\"params\"][\"loc\"], scale=case[\"params\"][\"scale\"], size=N)\n        elif case[\"type\"] == \"constant\":\n            log_weights = np.full(N, case[\"value\"])\n        elif case[\"type\"] == \"specific\": # Case 3\n            log_weights = np.full(N, -100.0)\n            log_weights[0] = 0.0\n        elif case[\"type\"] == \"structural\": # Case 5\n            # These indices correspond to mathematical i in {1, ..., 500}\n            log_weights[0:500] = 0.0\n            # These indices correspond to mathematical i in {501, ..., 1000}\n            log_weights[500:1000] = -np.inf\n            \n        ess = compute_ess_from_log_weights(log_weights)\n        results.append(ess)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当通过有效样本量（ESS）检测到严重的权重退化时，标准对策是执行重采样（resampling）步骤。重采样的目的是淘汰低权重的粒子，复制高权重的粒子，从而重新生成一个权重近似均匀的粒子集。本练习  聚焦于一种高效的低方差方法——分层重采样（stratified resampling）。你将通过一个具体的计算实例来实践该算法的执行过程，并从第一性原理出发推导其无偏性，从而深刻理解重采样是如何对抗退化、保持粒子集活力的。",
            "id": "3906053",
            "problem": "在用于一维温室气体示踪剂的序贯蒙特卡罗 (SMC) 粒子滤波器中，一个数据同化步骤使用分层重采样来解决权重退化问题。您有 $N=8$ 个粒子，其归一化重要性权重 $w_{1:8}$ 如下：\n$$\nw_{1:8} = \\big(0.05,\\; 0.10,\\; 0.20,\\; 0.15,\\; 0.25,\\; 0.05,\\; 0.10,\\; 0.10\\big)\n$$\n该权重基于当前时间步的单次卫星反演。令累积和为 $c_{j} = \\sum_{k=1}^{j} w_{k}$ (对于 $j=1,\\dots,8$)，并定义 $c_{0}=0$。在分层重采样中，重采样后的祖先索引定义为 $a_{i} = \\min\\{j : c_{j} \\geq U_{i}\\}$ (对于 $i=1,\\dots,N$)，其中 $U_{i}$ 是在 $[0,1]$ 上的 $N$ 个等长分层中均匀分布的独立抽样：\n$$\nU_{i} = \\frac{i-1 + \\epsilon_{i}}{N}, \\quad \\epsilon_{i} \\sim \\text{Uniform}(0,1], \\quad \\text{对于 } i=1,\\dots,N \\text{ 是独立的。}\n$$\n对于此实现，假设随机偏移量为\n$$\n\\epsilon_{1:8} = \\big(0.12,\\; 0.87,\\; 0.44,\\; 0.03,\\; 0.59,\\; 0.77,\\; 0.21,\\; 0.66\\big).\n$$\n任务1. 对于给定的 $w_{1:8}$ 和 $\\epsilon_{1:8}$，在分层重采样下计算重采样后的祖先索引向量 $a_{1:8}$。按照索引从1开始的约定，以有序索引行的形式报告您的答案。\n\n任务2. 从分层重采样的定义和区间上均匀分布的性质出发，从第一性原理推导期望重采样计数满足的无偏性 $\\mathbb{E}[N_{j}] = N w_{j}, \\quad j=1,\\dots,8$，其中 $N_{j} = \\sum_{i=1}^{N} \\mathbf{1}\\{a_{i}=j\\}$ 是粒子 $j$ 被选择的次数。您的推导必须仅依赖于给定的定义和关于均匀分布下区间长度的标准事实。\n\n答案规格：将任务1的祖先索引行作为最终答案。无需四舍五入。不包含任何单位。任务2的推导应出现在您的解题过程中，但无需体现在最终答案中。",
            "solution": "该问题是适定的，有科学依据，并为获得唯一解提供了所有必要信息。这些任务涉及分层重采样算法的直接应用及其无偏性的标准推导。我们将按顺序处理每个任务。\n\n### 任务1：计算祖先索引向量\n\n第一个任务是为具有 $N=8$ 个粒子的粒子滤波器计算重采样后的祖先索引向量 $a_{1:8}$。\n\n给定的归一化重要性权重为：\n$$\nw_{1:8} = \\big(0.05,\\; 0.10,\\; 0.20,\\; 0.15,\\; 0.25,\\; 0.05,\\; 0.10,\\; 0.10\\big)\n$$\n首先，我们计算累积和 $c_j = \\sum_{k=1}^{j} w_k$，其中 $c_0 = 0$。\n\\begin{align*}\nc_0 = 0 \\\\\nc_1 = 0.05 \\\\\nc_2 = 0.05 + 0.10 = 0.15 \\\\\nc_3 = 0.15 + 0.20 = 0.35 \\\\\nc_4 = 0.35 + 0.15 = 0.50 \\\\\nc_5 = 0.50 + 0.25 = 0.75 \\\\\nc_6 = 0.75 + 0.05 = 0.80 \\\\\nc_7 = 0.80 + 0.10 = 0.90 \\\\\nc_8 = 0.90 + 0.10 = 1.00\n\\end{align*}\n这些累积和定义了 $[0,1]$ 上对应于每个粒子索引的区间的边界。\n\n接下来，我们计算分层随机数 $U_i$（对于 $i=1, \\dots, 8$）。公式为 $U_i = \\frac{i-1 + \\epsilon_i}{N}$，其中 $N=8$，给定的随机偏移量为 $\\epsilon_{1:8} = \\big(0.12,\\; 0.87,\\; 0.44,\\; 0.03,\\; 0.59,\\; 0.77,\\; 0.21,\\; 0.66\\big)$。\n\\begin{align*}\nU_1 = \\frac{1-1 + 0.12}{8} = \\frac{0.12}{8} = 0.015 \\\\\nU_2 = \\frac{2-1 + 0.87}{8} = \\frac{1.87}{8} = 0.23375 \\\\\nU_3 = \\frac{3-1 + 0.44}{8} = \\frac{2.44}{8} = 0.305 \\\\\nU_4 = \\frac{4-1 + 0.03}{8} = \\frac{3.03}{8} = 0.37875 \\\\\nU_5 = \\frac{5-1 + 0.59}{8} = \\frac{4.59}{8} = 0.57375 \\\\\nU_6 = \\frac{6-1 + 0.77}{8} = \\frac{5.77}{8} = 0.72125 \\\\\nU_7 = \\frac{7-1 + 0.21}{8} = \\frac{6.21}{8} = 0.77625 \\\\\nU_8 = \\frac{8-1 + 0.66}{8} = \\frac{7.66}{8} = 0.9575\n\\end{align*}\n\n祖先索引 $a_i$ 是通过找到满足 $c_j \\geq U_i$ 的最小索引 $j$ 来确定的。这等价于找到包含 $U_i$ 的区间 $(c_{j-1}, c_j]$。\n\\begin{itemize}\n    \\item 对于 $U_1 = 0.015$：$c_0=0  0.015 \\leq c_1=0.05$，所以 $a_1=1$。\n    \\item 对于 $U_2 = 0.23375$：$c_2=0.15  0.23375 \\leq c_3=0.35$，所以 $a_2=3$。\n    \\item 对于 $U_3 = 0.305$：$c_2=0.15  0.305 \\leq c_3=0.35$，所以 $a_3=3$。\n    \\item 对于 $U_4 = 0.37875$：$c_3=0.35  0.37875 \\leq c_4=0.50$，所以 $a_4=4$。\n    \\item 对于 $U_5 = 0.57375$：$c_4=0.50  0.57375 \\leq c_5=0.75$，所以 $a_5=5$。\n    \\item 对于 $U_6 = 0.72125$：$c_4=0.50  0.72125 \\leq c_5=0.75$，所以 $a_6=5$。\n    \\item 对于 $U_7 = 0.77625$：$c_5=0.75  0.77625 \\leq c_6=0.80$，所以 $a_7=6$。\n    \\item 对于 $U_8 = 0.9575$：$c_7=0.90  0.9575 \\leq c_8=1.00$，所以 $a_8=8$。\n\\end{itemize}\n得到的祖先索引向量为 $a_{1:8} = (1, 3, 3, 4, 5, 5, 6, 8)$。\n\n### 任务2：无偏性的推导\n\n第二个任务是推导分层重采样的无偏性，即粒子 $j$ 被选择的期望次数 $\\mathbb{E}[N_j]$ 等于 $N w_j$。\n\n粒子 $j$ 被选择的次数 $N_j$ 由指示函数的和给出：\n$$\nN_j = \\sum_{i=1}^{N} \\mathbf{1}\\{a_i = j\\}\n$$\n其中，如果事件 $E$ 为真，则 $\\mathbf{1}\\{E\\}$ 为 $1$，否则为 $0$。\n\n根据期望的线性性，$N_j$ 的期望值为：\n$$\n\\mathbb{E}[N_j] = \\mathbb{E}\\left[\\sum_{i=1}^{N} \\mathbf{1}\\{a_i = j\\}\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\mathbf{1}\\{a_i = j\\}]\n$$\n指示函数的期望是其所指示事件的概率。\n$$\n\\mathbb{E}[\\mathbf{1}\\{a_i = j\\}] = P(a_i = j)\n$$\n因此，我们有：\n$$\n\\mathbb{E}[N_j] = \\sum_{i=1}^{N} P(a_i = j)\n$$\n祖先索引 $a_i$ 定义为 $a_i = \\min\\{k : c_k \\geq U_i\\}$。因此，条件 $a_i = j$ 等价于 $U_i$ 落入对应于粒子 $j$ 的区间，即 $(c_{j-1}, c_j]$。所以，\n$$\nP(a_i = j) = P(c_{j-1}  U_i \\leq c_j)\n$$\n随机变量 $U_i$ 定义为 $U_i = \\frac{i-1+\\epsilon_i}{N}$，其中 $\\epsilon_i$ 从 $(0, 1]$ 上的均匀分布中抽取。这意味着 $i-1  i-1+\\epsilon_i \\leq i$，因此 $\\frac{i-1}{N}  U_i \\leq \\frac{i}{N}$。这表示 $U_i$ 是一个在第 $i$ 个分层 $S_i = (\\frac{i-1}{N}, \\frac{i}{N}]$ 上均匀分布的随机变量，该分层长度为 $\\frac{1}{N}$。\n\n概率 $P(c_{j-1}  U_i \\leq c_j)$ 是事件区间 $E_j = (c_{j-1}, c_j]$ 与 $U_i$ 的支撑集 $S_i$ 的交集长度除以 $U_i$ 支撑集的长度。\n$$\nP(a_i = j) = \\frac{\\text{length}(E_j \\cap S_i)}{\\text{length}(S_i)} = \\frac{\\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)}{1/N} = N \\cdot \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n现在，我们将此代入 $\\mathbb{E}[N_j]$ 的表达式中：\n$$\n\\mathbb{E}[N_j] = \\sum_{i=1}^{N} N \\cdot \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n我们可以提取公因数 $N$：\n$$\n\\mathbb{E}[N_j] = N \\sum_{i=1}^{N} \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n分层 $S_i = (\\frac{i-1}{N}, \\frac{i}{N}]$（对于 $i=1, \\dots, N$）是不相交的，它们的并集覆盖了整个区间 $(0, 1]$。即 $\\bigcup_{i=1}^{N} S_i = (0, 1]$ 且当 $i \\neq k$ 时 $S_i \\cap S_k = \\emptyset$。\n由于这个划分性质，交集长度之和等于 $E_j$ 与全部分层并集的交集长度：\n$$\n\\sum_{i=1}^{N} \\text{length}(E_j \\cap S_i) = \\text{length}\\left(E_j \\cap \\left(\\bigcup_{i=1}^{N} S_i\\right)\\right) = \\text{length}((c_{j-1}, c_j] \\cap (0, 1])\n$$\n由于权重是归一化的，对于所有 $j=1,\\dots,N$，我们有 $0 \\le c_{j-1} \\le c_j \\le 1$。因此，交集 $(c_{j-1}, c_j] \\cap (0, 1]$ 就是区间 $(c_{j-1}, c_j]$ 本身。该区间的长度是 $c_j - c_{j-1}$。\n根据累积和的定义，$c_j - c_{j-1} = w_j$。\n因此，\n$$\n\\sum_{i=1}^{N} \\text{length}(E_j \\cap S_i) = c_j - c_{j-1} = w_j\n$$\n将此结果代回 $\\mathbb{E}[N_j]$ 的表达式，得到最终结果：\n$$\n\\mathbb{E}[N_j] = N w_j\n$$\n这就完成了分层重采样无偏性的推导。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  3  3  4  5  5  6  8\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "虽然重采样是处理退化问题的有效手段，但更根本的策略是通过设计高效的提议分布（proposal distribution）来从源头上减少退化的发生。对于许多物理系统，如环境模型，状态变量常常受到物理约束（例如，污染物浓度必须为非负）。本练习  教授一种关键技术，即通过在变换后的空间（如对数空间）中采样来强制满足这些约束，并推导在这种变量变换下为保证重要性权重计算正确所必需的雅可比（Jacobian）调整项。掌握这项技能对于构建适用于真实物理系统的稳健粒子滤波器至关重要。",
            "id": "3906030",
            "problem": "考虑一个应用于大气化学输运模型的序贯重要性重采样粒子滤波器 (PF)，其中状态是在 $d$ 个网格单元上的非负污染物浓度向量 $c \\in \\mathbb{R}_{+}^{d}$。观测值 $y \\in \\mathbb{R}^{m}$ 通过一个线性测量算子 $H \\in \\mathbb{R}^{m \\times d}$ 和加性高斯测量噪声与浓度相关，因此观测模型为 $y \\mid c \\sim \\mathcal{N}(H c, R)$，其中 $R \\in \\mathbb{R}^{m \\times m}$ 是一个已知的正定协方差矩阵。模型的预报步骤产生关于 $c$ 的先验密度 $p(c)$。\n\n为在建议分布设计中强制浓度的非负性，考虑在对数空间中进行采样，如下所示：按分量定义 $u = \\ln c$（即对于 $i = 1, \\dots, d$，有 $u_{i} = \\ln c_{i}$）。假设在对数空间中的建议分布被选为一个多元高斯分布 $q_{u}(u \\mid y) = \\mathcal{N}(u; \\mu, \\Sigma)$，其均值向量为 $\\mu \\in \\mathbb{R}^{d}$，协方差矩阵为正定的 $\\Sigma \\in \\mathbb{R}^{d \\times d}$，然后通过 $c = \\exp(u)$ 按分量映射回浓度空间。\n\n从粒子滤波器权重的重点采样恒等式和概率密度的变量变换定理出发，推导非归一化重点权重作为 $c$ 的函数的显式闭式表达式，该权重对应于目标后验密度 $p(y \\mid c) \\, p(c)$ 以及在变换 $c = \\exp(u)$ 下由 $q_{u}(u \\mid y)$ 导出的建议分布。您的推导必须包含强制非负性的变换所需的正确雅可比调整项。\n\n在似然和建议分布中都使用多元正态分布的标准、显式概率密度函数：\n$$\np(y \\mid c) = (2\\pi)^{-m/2} \\, |R|^{-1/2} \\, \\exp\\!\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) \\right),\n$$\n$$\nq_{u}(u \\mid y) = (2\\pi)^{-d/2} \\, |\\Sigma|^{-1/2} \\, \\exp\\!\\left( -\\frac{1}{2} (u - \\mu)^{\\top} \\Sigma^{-1} (u - \\mu) \\right).\n$$\n\n将您的最终答案表示为非归一化重点权重 $w(c)$ 的单一闭式解析表达式，该表达式是 $c$, $y$, $H$, $R$, $\\mu$, $\\Sigma$ 和先验 $p(c)$ 的函数。不要使用比例符号；包括变量变换定理所需的所有乘法因子。不需要进行数值计算或四舍五入，最终表达式中不应出现任何物理单位。",
            "solution": "该问题提法清晰，具有科学依据，并包含了推导所要求表达式所需的所有信息。\n\n在序贯重要性重采样粒子滤波器中，一个粒子（一个样本状态向量）$c$ 的非归一化重点权重 $w(c)$ 由目标密度与建议密度在该粒子处的值之比给出。目标密度是给定观测值下状态的非归一化后验概率密度，它与似然乘以先验成正比，即 $p(c \\mid y) \\propto p(y \\mid c) p(c)$。\n\n因此，重点权重 $w(c)$ 定义为：\n$$\nw(c) = \\frac{p(y \\mid c) p(c)}{q_c(c \\mid y)}\n$$\n其中 $p(y \\mid c)$ 是给定状态 $c$ 时观测到 $y$ 的似然，$p(c)$ 是状态的先验密度，而 $q_c(c \\mid y)$ 是从中抽取粒子 $c$ 的建议密度。\n\n问题给出了似然 $p(y \\mid c)$ 的显式形式，而先验 $p(c)$ 是一个给定的函数。主要任务是找到浓度空间 $c$ 中建议密度 $q_c(c \\mid y)$ 的表达式。我们已知在对数空间中的建议密度 $q_u(u \\mid y)$，其中 $u = \\ln c$ 是按分量计算的。我们必须使用概率密度的变量变换定理将 $q_u(u \\mid y)$ 变换为 $q_c(c \\mid y)$。\n\n两个随机变量向量 $U$ 和 $C$ 通过可逆、可微的变换 $C = g(U)$（或等价地 $U = g^{-1}(C)$）相关联，其密度之间的关系由下式给出：\n$$\np_C(c) = p_U(g^{-1}(c)) \\left| \\det\\left( J_{g^{-1}}(c) \\right) \\right|\n$$\n其中 $J_{g^{-1}}(c)$ 是逆变换 $g^{-1}$ 的雅可比矩阵。\n\n在我们的例子中，状态变量是 $c \\in \\mathbb{R}_{+}^{d}$，变换后的变量是 $u \\in \\mathbb{R}^{d}$。\n从 $u$ 到 $c$ 的变换是：$c = \\exp(u)$，其中指数函数按分量作用，因此对于 $i=1, \\dots, d$，有 $c_i = \\exp(u_i)$。\n从 $c$ 到 $u$ 的逆变换是：$u = \\ln c$，其中对数函数按分量作用，因此对于 $i=1, \\dots, d$，有 $u_i = \\ln(c_i)$。这里，$g^{-1}(c) = \\ln(c)$。\n\n我们需要计算这个逆变换的雅可比矩阵，$J_{\\ln(c)} = \\frac{\\partial u}{\\partial c}$。该矩阵的元素为 $J_{ij} = \\frac{\\partial u_i}{\\partial c_j}$。\n$$\nJ_{ij} = \\frac{\\partial (\\ln c_i)}{\\partial c_j} =\n\\begin{cases}\n    \\frac{1}{c_i}  \\text{若 } i=j \\\\\n    0  \\text{若 } i \\neq j\n\\end{cases}\n$$\n这表明雅可比矩阵是一个对角矩阵：\n$$\nJ_{\\ln(c)} = \\text{diag}\\left(\\frac{1}{c_1}, \\frac{1}{c_2}, \\dots, \\frac{1}{c_d}\\right)\n$$\n对角矩阵的行列式是其对角元素的乘积：\n$$\n\\det\\left( J_{\\ln(c)} \\right) = \\prod_{i=1}^{d} \\frac{1}{c_i}\n$$\n由于浓度 $c_i$ 是严格为正的（$c \\in \\mathbb{R}_{+}^{d}$），行列式的绝对值就是行列式本身：\n$$\n\\left| \\det\\left( J_{\\ln(c)} \\right) \\right| = \\prod_{i=1}^{d} \\frac{1}{c_i} = \\left(\\prod_{i=1}^{d} c_i\\right)^{-1}\n$$\n这就是雅可比调整因子。\n\n现在我们可以使用给定的在 $u$ 空间中的建议分布 $q_u(u \\mid y) = \\mathcal{N}(u; \\mu, \\Sigma)$，来写出在 $c$ 空间中的建议密度 $q_c(c \\mid y)$：\n$$\nq_c(c \\mid y) = q_u(\\ln c \\mid y) \\left| \\det\\left( J_{\\ln(c)} \\right) \\right|\n$$\n代入 $q_u$ 的显式形式和雅可比行列式：\n$$\nq_c(c \\mid y) = \\left( (2\\pi)^{-d/2} |\\Sigma|^{-1/2} \\exp\\left( -\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right) \\left( \\prod_{i=1}^{d} \\frac{1}{c_i} \\right)\n$$\n这里，$\\ln c$ 是向量 $(\\ln c_1, \\dots, \\ln c_d)^{\\top}$。\n\n最后，我们将所有分量代回到重点权重 $w(c)$ 的公式中：\n$$\nw(c) = \\frac{p(y \\mid c) p(c)}{q_c(c \\mid y)} = \\frac{ \\left( (2\\pi)^{-m/2} |R|^{-1/2} \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) \\right) \\right) p(c) }{ \\left( (2\\pi)^{-d/2} |\\Sigma|^{-1/2} \\exp\\left( -\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right) \\left( \\prod_{i=1}^{d} c_i^{-1} \\right) }\n$$\n为简化起见，我们可以重新排列各项。分母中的项 $\\left( \\prod_{i=1}^{d} c_i^{-1} \\right)$ 移到分子。分母中的指数项也移到分子，其指数的符号翻转。\n$$\nw(c) = \\frac{(2\\pi)^{-m/2} |R|^{-1/2}}{(2\\pi)^{-d/2} |\\Sigma|^{-1/2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) - \\left(-\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right)\n$$\n组合常数前置因子并合并指数：\n$$\nw(c) = (2\\pi)^{(d-m)/2} \\frac{|\\Sigma|^{1/2}}{|R|^{1/2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) + \\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right)\n$$\n这就是非归一化重点权重 $w(c)$ 的最终、显式、闭式表达式。",
            "answer": "$$\n\\boxed{(2\\pi)^{\\frac{d-m}{2}} \\left( \\frac{|\\Sigma|}{|R|} \\right)^{\\frac{1}{2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left(-\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) + \\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu)\\right)}\n$$"
        }
    ]
}