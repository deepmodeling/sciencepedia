{
    "hands_on_practices": [
        {
            "introduction": "The power of kinetic Monte Carlo simulations lies in their ability to connect microscopic events to macroscopic phenomena. This exercise provides a foundational link between the atomistic energy landscape and the resulting diffusion coefficient. By starting from first principles, you will derive and apply the classic model for vacancy-mediated self-diffusion, providing a critical theoretical baseline that underpins more complex kMC models .",
            "id": "3747898",
            "problem": "Consider a face-centered cubic high-entropy alloy modeled in a kinetic Monte Carlo (kMC) framework for vacancy-mediated diffusion and precipitation kinetics. Assume an effective single-species vacancy mechanism governed by thermally activated processes. The equilibrium vacancy concentration follows the Boltzmann distribution for defect formation, and the elementary exchange event rate follows transition state theory. Neglect the vibrational formation entropy (or assume it is absorbed into the effective formation energy), and assume the vacancy concentration is dilute. Use the following physically consistent parameters:\n- Temperature: $T = 1300\\,\\mathrm{K}$,\n- Vacancy formation energy: $E_f = 1.60\\,\\mathrm{eV}$,\n- Vacancy migration energy: $E_m = 0.90\\,\\mathrm{eV}$,\n- Attempt frequency (prefactor) for vacancy-atom exchange: $\\nu_0 = 1.00 \\times 10^{13}\\,\\mathrm{s}^{-1}$,\n- Lattice parameter: $a = 0.360\\,\\mathrm{nm}$,\n- Nearest-neighbor coordination number (face-centered cubic): $z = 12$,\n- Nearest-neighbor jump distance (face-centered cubic): $\\lambda = a/\\sqrt{2}$,\n- Vacancy correlation factor for face-centered cubic self-diffusion: $f = 0.781$,\n- Boltzmann constant: $k_B = 8.617333262 \\times 10^{-5}\\,\\mathrm{eV\\,K^{-1}}$.\n\nStarting from the following fundamental bases:\n1. The equilibrium probability for a defect of energy $E$ at temperature $T$ is proportional to $\\exp(-E/(k_B T))$.\n2. The transition state theory event rate for a thermally activated process is $r = \\nu_0 \\exp\\!\\left(-E_m/(k_B T)\\right)$.\n3. For an uncorrelated random walk in $d=3$ dimensions, the diffusion coefficient is $D = \\frac{1}{2d}\\lambda^2 \\Gamma$, where $\\Gamma$ is the total mean jump frequency. For vacancy-mediated self-diffusion, incorporate the correlation factor $f$ to account for back-correlation effects.\n\nDerive an expression for the temperature-dependent diffusion coefficient $D(T)$ of the representative species in terms of $E_f$, $E_m$, $k_B$, $T$, $\\nu_0$, $a$, and $f$, by combining the fundamental bases above and the geometry of the face-centered cubic lattice. Then, compute numerically:\n- the equilibrium vacancy concentration $c_v$,\n- and the resulting diffusion coefficient $D(T)$.\n\nExpress the final diffusion coefficient in $\\mathrm{m^2\\,s^{-1}}$, and treat the equilibrium vacancy concentration as dimensionless. Round both $c_v$ and $D(T)$ to four significant figures. Provide your final numerical answer as a pair $\\big(c_v, D(T)\\big)$.",
            "solution": "The problem requires the derivation of an expression for the vacancy-mediated self-diffusion coefficient, $D(T)$, in a face-centered cubic (FCC) lattice, followed by the numerical calculation of the equilibrium vacancy concentration, $c_v$, and the diffusion coefficient, $D(T)$, at a specified temperature.\n\nFirst, we derive the necessary expressions based on the provided fundamental principles.\n\n**1. Equilibrium Vacancy Concentration ($c_v$)**\nAccording to the first fundamental basis provided, the equilibrium probability for a state of energy $E$ is proportional to $\\exp(-E/(k_B T))$. The formation of a single vacancy in a crystal lattice requires an energy $E_f$. In a crystal with $N$ atomic sites, the number of ways to create $n_v$ vacancies is $\\binom{N}{n_v}$. The change in Gibbs free energy upon forming $n_v$ vacancies is $\\Delta G = n_v E_f - T \\Delta S_{conf}$, where $\\Delta S_{conf}$ is the configurational entropy. Using the Stirling approximation for the entropy term, minimization of $\\Delta G$ with respect to $n_v$ yields the equilibrium vacancy site fraction (concentration). For a dilute system ($n_v \\ll N$) and neglecting the vibrational entropy of formation as instructed, this simplifies to the Boltzmann factor for the formation energy:\n$$c_v = \\frac{n_v}{N} = \\exp\\left(-\\frac{E_f}{k_B T}\\right)$$\nThis gives the fraction of lattice sites that are vacant at a given temperature $T$.\n\n**2. Derivation of the Self-Diffusion Coefficient $D(T)$**\nThe diffusion of an atom is mediated by its exchange with a neighboring vacancy. We can derive the atomic diffusion coefficient $D(T)$ by relating it to the properties of the vacancies.\n\nThe rate of exchange, $\\omega$, between a specific atom and an adjacent vacancy is given by transition state theory, as per the second fundamental basis:\n$$\\omega = \\nu_0 \\exp\\left(-\\frac{E_m}{k_B T}\\right)$$\nHere, $\\nu_0$ is the attempt frequency and $E_m$ is the energy barrier for the exchange, i.e., the vacancy migration energy.\n\nThe diffusion coefficient of the vacancies themselves, $D_v$, can be determined using the random walk theory from the third fundamental basis. A vacancy can jump to any of its $z$ neighboring atomic sites. The total jump frequency of a single vacancy, $\\Gamma_v$, is the product of the number of available jump directions, $z$, and the rate of exchange for each, $\\omega$:\n$$\\Gamma_v = z \\omega = z \\nu_0 \\exp\\left(-\\frac{E_m}{k_B T}\\right)$$\nAssuming the vacancy's walk is uncorrelated, its diffusion coefficient in a $3$-dimensional lattice is:\n$$D_v = \\frac{1}{6} \\lambda^2 \\Gamma_v = \\frac{1}{6} z \\lambda^2 \\omega$$\nwhere $\\lambda$ is the jump distance.\n\nThe self-diffusion coefficient of a tracer atom, $D(T)$, is related to the vacancy diffusion coefficient $D_v$ through the expression:\n$$D(T) = c_v f D_v$$\nThis relationship arises because an atom can only jump if a vacancy is present on a neighboring site (with probability $c_v$), and the subsequent jumps of the atom are correlated, which is accounted for by the correlation factor $f$. Substituting the expressions for $c_v$ and $D_v$:\n$$D(T) = \\exp\\left(-\\frac{E_f}{k_B T}\\right) \\cdot f \\cdot \\left( \\frac{1}{6} z \\lambda^2 \\omega \\right)$$\nSubstituting the expression for $\\omega$:\n$$D(T) = f \\frac{z \\lambda^2}{6} \\exp\\left(-\\frac{E_f}{k_B T}\\right) \\nu_0 \\exp\\left(-\\frac{E_m}{k_B T}\\right)$$\nCombining the exponential terms yields an Arrhenius-type equation for diffusion:\n$$D(T) = f \\frac{z \\lambda^2 \\nu_0}{6} \\exp\\left(-\\frac{E_f + E_m}{k_B T}\\right)$$\nThis can be written as $D(T) = D_0 \\exp(-Q/(k_B T))$, where $Q = E_f + E_m$ is the total activation energy for diffusion and $D_0$ is the pre-exponential factor.\n\nFor the specified face-centered cubic (FCC) lattice, the geometric parameters are the coordination number $z=12$ and the nearest-neighbor jump distance $\\lambda = a/\\sqrt{2}$, where $a$ is the lattice parameter. Substituting these into the expression for $D(T)$:\n$$D(T) = f \\frac{12 \\cdot (a/\\sqrt{2})^2 \\nu_0}{6} \\exp\\left(-\\frac{E_f + E_m}{k_B T}\\right)$$\n$$D(T) = f \\frac{12 \\cdot (a^2/2) \\nu_0}{6} \\exp\\left(-\\frac{E_f + E_m}{k_B T}\\right)$$\n$$D(T) = f \\frac{6 a^2 \\nu_0}{6} \\exp\\left(-\\frac{E_f + E_m}{k_B T}\\right)$$\nThe final derived expression for the diffusion coefficient is:\n$$D(T) = f a^2 \\nu_0 \\exp\\left(-\\frac{E_f + E_m}{k_B T}\\right)$$\n\n**3. Numerical Computations**\nWe are given the following parameters:\n- $T = 1300\\,\\mathrm{K}$\n- $E_f = 1.60\\,\\mathrm{eV}$\n- $E_m = 0.90\\,\\mathrm{eV}$\n- $\\nu_0 = 1.00 \\times 10^{13}\\,\\mathrm{s}^{-1}$\n- $a = 0.360\\,\\mathrm{nm} = 0.360 \\times 10^{-9}\\,\\mathrm{m}$\n- $f = 0.781$\n- $k_B = 8.617333262 \\times 10^{-5}\\,\\mathrm{eV\\,K^{-1}}$\n\nFirst, we compute the thermal energy product $k_B T$:\n$$k_B T = (8.617333262 \\times 10^{-5}\\,\\mathrm{eV\\,K^{-1}}) \\times (1300\\,\\mathrm{K}) \\approx 0.112025\\,\\mathrm{eV}$$\n\n**Calculation of Equilibrium Vacancy Concentration ($c_v$)**:\nUsing the formula derived above:\n$$c_v = \\exp\\left(-\\frac{E_f}{k_B T}\\right) = \\exp\\left(-\\frac{1.60\\,\\mathrm{eV}}{0.112025\\,\\mathrm{eV}}\\right) = \\exp(-14.2825)$$\n$$c_v \\approx 6.27038 \\times 10^{-7}$$\nRounding to four significant figures, the vacancy concentration is:\n$$c_v \\approx 6.270 \\times 10^{-7}$$\n\n**Calculation of the Diffusion Coefficient ($D(T)$)**:\nThe total activation energy for diffusion is $Q = E_f + E_m$:\n$$Q = 1.60\\,\\mathrm{eV} + 0.90\\,\\mathrm{eV} = 2.50\\,\\mathrm{eV}$$\nThe argument of the exponential in the diffusion equation is:\n$$-\\frac{Q}{k_B T} = -\\frac{2.50\\,\\mathrm{eV}}{0.112025\\,\\mathrm{eV}} \\approx -22.3163$$\nThe exponential term is $\\exp(-22.3163) \\approx 1.9392 \\times 10^{-10}$.\n\nThe pre-exponential factor, $D_0 = f a^2 \\nu_0$, is:\n$$a^2 = (0.360 \\times 10^{-9}\\,\\mathrm{m})^2 = 1.296 \\times 10^{-19}\\,\\mathrm{m}^2$$\n$$D_0 = (0.781) \\times (1.296 \\times 10^{-19}\\,\\mathrm{m}^2) \\times (1.00 \\times 10^{13}\\,\\mathrm{s}^{-1})$$\n$$D_0 = 1.012176 \\times 10^{-6}\\,\\mathrm{m^2\\,s^{-1}}$$\n\nFinally, we compute $D(T) = D_0 \\exp(-Q/(k_B T))$:\n$$D(T) = (1.012176 \\times 10^{-6}\\,\\mathrm{m^2\\,s^{-1}}) \\times (1.9392 \\times 10^{-10})$$\n$$D(T) \\approx 1.96294 \\times 10^{-16}\\,\\mathrm{m^2\\,s^{-1}}$$\nRounding to four significant figures, the diffusion coefficient is:\n$$D(T) \\approx 1.963 \\times 10^{-16}\\,\\mathrm{m^2\\,s^{-1}}$$\n\nThe computed numerical values are $c_v \\approx 6.270 \\times 10^{-7}$ (dimensionless) and $D(T) \\approx 1.963 \\times 10^{-16}\\,\\mathrm{m^2\\,s^{-1}}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n6.270 \\times 10^{-7} & 1.963 \\times 10^{-16}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A primary output of a kMC diffusion simulation is the time-evolution of particle positions. To extract physical insights, we must process these trajectories into meaningful quantities. This practice guides you through the fundamental procedure of calculating the mean-squared displacement (MSD) from particle trajectory data and using it to estimate the diffusion coefficient, a cornerstone of analyzing any diffusion process .",
            "id": "3747912",
            "problem": "Consider an isotropic, vacancy-mediated diffusion process for each chemical species in a multicomponent high-entropy alloy (HEA), modeled by Kinetic Monte Carlo (kMC). The kMC output is a time series of particle positions for each species. Your task has two parts: first, derive the linear relation between the ensemble mean-squared displacement and time for an isotropic diffusive process starting from fundamental principles, identifying its slope in terms of spatial dimension and the diffusion coefficient; second, design and implement an algorithm that, given synthetic kMC position trajectories for multiple species, estimates the diffusion coefficients with two-sided confidence intervals based on a statistically justified procedure.\n\nYou must begin from the following bases and do not assume any shortcut formula:\n- The probability density function $p(\\mathbf{r},t)$ of the displacement $\\mathbf{r}$ for an isotropic diffusion process in $d$ spatial dimensions satisfies Fick's second law $\\partial_t p(\\mathbf{r},t) = D \\nabla^2 p(\\mathbf{r},t)$ with the initial condition $p(\\mathbf{r},0)=\\delta(\\mathbf{r})$, where $D$ is the diffusion coefficient and $\\delta$ is the Dirac delta.\n- The ensemble mean-squared displacement is defined as $\\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 p(\\mathbf{r},t) \\,\\mathrm{d}^d \\mathbf{r}$.\n- For each species, the kMC trajectory can be treated as a sequence of independent, isotropic increments with zero mean and finite variance over sufficiently coarse time intervals under the Markov assumption.\n\nProgram requirements:\n- Construct synthetic kMC outputs for the following test suite. In each case, simulate particle positions by summing independent, normally distributed increments per time interval $\\Delta t_k$ in each coordinate, with variance $2 D \\Delta t_k$ for a species with diffusion coefficient $D$. Positions must be in $\\mathrm{m}$ and time in $\\mathrm{s}$, and diffusion coefficients in $\\mathrm{m^2/s}$. Use the specified random seeds exactly to ensure reproducibility.\n- For each species, compute the ensemble mean-squared displacement time series $M(t_k)$ defined by $M(t_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\mathbf{r}_i(t_k) - \\mathbf{r}_i(0)\\|^2$, where $N$ is the number of particles of the species and $\\mathbf{r}_i(t_k)$ is the position of particle $i$ at time $t_k$.\n- Estimate the diffusion coefficient $D$ for each species by performing an ordinary least squares linear regression of $M(t_k)$ against $t_k$ with an intercept, and then mapping the slope to $D$. Construct a two-sided $95\\%$ confidence interval for $D$ using the standard error of the slope and the Student distribution. Express all estimated diffusion coefficients and confidence interval bounds in $\\mathrm{m^2/s}$.\n- If $M(t_k)$ is identically zero for all $k$ for a species, return a point estimate and confidence interval both equal to $0$ for that species.\n\nTest suite specification:\n- Case $1$ (general multicomponent, $d=3$): three species with diffusion coefficients $D = [1.0 \\times 10^{-20},\\, 4.0 \\times 10^{-20},\\, 0.0]\\,\\mathrm{m^2/s}$, particle counts $N = [200,\\, 200,\\, 200]$, dimension $d=3$, times $t_k = k \\Delta t$ for $k=0,1,\\dots,100$ with $\\Delta t = 5.0 \\times 10^{-6}\\,\\mathrm{s}$, random seed $123$.\n- Case $2$ (planar diffusion, $d=2$): two species with diffusion coefficients $D = [1.0 \\times 10^{-18},\\, 3.0 \\times 10^{-19}]\\,\\mathrm{m^2/s}$, particle counts $N = [50,\\, 50]$, dimension $d=2$, times $t_k = k \\Delta t$ for $k=0,1,\\dots,150$ with $\\Delta t = 1.0 \\times 10^{-6}\\,\\mathrm{s}$, random seed $456$.\n- Case $3$ (boundary, few particles, $d=3$): two species with diffusion coefficients $D = [5.0 \\times 10^{-23},\\, 1.0 \\times 10^{-20}]\\,\\mathrm{m^2/s}$, particle counts $N = [5,\\, 5]$, dimension $d=3$, times $t_k = k \\Delta t$ for $k=0,1,\\dots,40$ with $\\Delta t = 2.0 \\times 10^{-5}\\,\\mathrm{s}$, random seed $789$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case contributes a list of species results, and each species result must be a list of three floats in the order $[\\hat{D},\\, \\mathrm{CI}_{\\mathrm{low}},\\, \\mathrm{CI}_{\\mathrm{high}}]$, all in $\\mathrm{m^2/s}$. For example, the overall output must have the form $[[[d_{11},l_{11},u_{11}],\\dots],[[d_{21},l_{21},u_{21}],\\dots],[[d_{31},l_{31},u_{31}],\\dots]]$ where $d_{js}$, $l_{js}$, and $u_{js}$ denote the estimate and lower and upper bounds for species $s$ in case $j$.",
            "solution": "The problem presents a dual task: first, a theoretical derivation of the relationship between mean-squared displacement and the diffusion coefficient, and second, the implementation of a computational procedure to estimate this coefficient from simulated particle trajectories. The problem is well-posed, scientifically grounded, and provides sufficient detail for a complete and verifiable solution.\n\n### Part 1: Theoretical Derivation of the Mean-Squared Displacement Relation\n\nThe objective is to establish the linear relationship between the ensemble mean-squared displacement (MSD) $\\langle \\|\\mathbf{r}(t)\\|^2 \\rangle$ and time $t$ for a species undergoing isotropic diffusion. The derivation commences from Fick's second law, which governs the evolution of the probability density function $p(\\mathbf{r}, t)$ of a particle's displacement $\\mathbf{r}$ at time $t$.\n\n**1. Foundational Equations**\n\nWe are given:\n-   Fick's second law in $d$ spatial dimensions:\n    $$ \\frac{\\partial p(\\mathbf{r},t)}{\\partial t} = D \\nabla^2 p(\\mathbf{r},t) $$\n    where $D$ is the diffusion coefficient and $\\nabla^2$ is the Laplacian operator.\n-   The initial condition, representing a particle starting at the origin:\n    $$ p(\\mathbf{r}, 0) = \\delta(\\mathbf{r}) $$\n    where $\\delta(\\mathbf{r})$ is the $d$-dimensional Dirac delta function.\n-   The definition of the ensemble mean-squared displacement:\n    $$ \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 p(\\mathbf{r}, t) \\,\\mathrm{d}^d \\mathbf{r} $$\n    where $\\|\\mathbf{r}\\|^2 = \\sum_{i=1}^{d} r_i^2$ is the squared Euclidean norm of the displacement vector $\\mathbf{r} = (r_1, r_2, \\dots, r_d)$.\n\n**2. Time Derivative of the MSD**\n\nWe analyze the rate of change of the MSD by differentiating its definition with respect to time $t$:\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = \\frac{\\mathrm{d}}{\\mathrm{d}t} \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 p(\\mathbf{r}, t) \\,\\mathrm{d}^d \\mathbf{r} $$\nAssuming sufficient smoothness, we can interchange the derivative and integral operators (Leibniz integral rule):\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 \\frac{\\partial p(\\mathbf{r}, t)}{\\partial t} \\,\\mathrm{d}^d \\mathbf{r} $$\nNow, we substitute Fick's second law into this expression:\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 \\left( D \\nabla^2 p(\\mathbf{r}, t) \\right) \\,\\mathrm{d}^d \\mathbf{r} = D \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 \\nabla^2 p \\,\\mathrm{d}^d \\mathbf{r} $$\n\n**3. Application of Green's Second Identity**\n\nTo evaluate the integral, we use Green's second identity, which is a form of integration by parts in multiple dimensions. The identity states:\n$$ \\int_V (f \\nabla^2 g - g \\nabla^2 f) \\,\\mathrm{d}V = \\int_S (f \\nabla g - g \\nabla f) \\cdot \\mathrm{d}\\mathbf{S} $$\nLet $f = \\|\\mathbf{r}\\|^2$ and $g = p(\\mathbf{r}, t)$, and the volume $V$ be the entire space $\\mathbb{R}^d$. The surface integral is over the boundary at infinity. For a diffusive process, the probability density $p(\\mathbf{r}, t)$ and its gradient $\\nabla p$ must vanish sufficiently rapidly as $\\|\\mathbf{r}\\| \\to \\infty$. Consequently, the surface integral term is zero. This leaves us with:\n$$ \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 \\nabla^2 p \\,\\mathrm{d}^d \\mathbf{r} = \\int_{\\mathbb{R}^d} p \\left(\\nabla^2 \\|\\mathbf{r}\\|^2\\right) \\,\\mathrm{d}^d \\mathbf{r} $$\nWe now compute the Laplacian of $f(\\mathbf{r}) = \\|\\mathbf{r}\\|^2$:\n$$ \\nabla^2 \\|\\mathbf{r}\\|^2 = \\nabla^2 \\left(\\sum_{i=1}^{d} r_i^2\\right) = \\sum_{i=1}^{d} \\frac{\\partial^2}{\\partial r_i^2} \\left(\\sum_{j=1}^{d} r_j^2\\right) $$\nSince $\\frac{\\partial^2 r_j^2}{\\partial r_i^2} = 2 \\delta_{ij}$ (where $\\delta_{ij}$ is the Kronecker delta), the sum becomes:\n$$ \\nabla^2 \\|\\mathbf{r}\\|^2 = \\sum_{i=1}^{d} 2 = 2d $$\nThe Laplacian of the squared displacement is simply twice the spatial dimension.\n\n**4. Final Integration**\n\nSubstituting this result back into the expression for the time derivative of the MSD:\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = D \\int_{\\mathbb{R}^d} p(\\mathbf{r}, t) (2d) \\,\\mathrm{d}^d \\mathbf{r} = 2dD \\int_{\\mathbb{R}^d} p(\\mathbf{r}, t) \\,\\mathrm{d}^d \\mathbf{r} $$\nSince $p(\\mathbf{r}, t)$ is a probability density function, its integral over all space is unity by definition:\n$$ \\int_{\\mathbb{R}^d} p(\\mathbf{r}, t) \\,\\mathrm{d}^d \\mathbf{r} = 1 $$\nThis simplifies the rate of change of the MSD to a constant:\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = 2dD $$\nIntegrating this ordinary differential equation with respect to time from $0$ to $t$:\n$$ \\int_0^t \\frac{\\mathrm{d}}{\\mathrm{d}\\tau} \\langle \\|\\mathbf{r}(\\tau)\\|^2 \\rangle \\,\\mathrm{d}\\tau = \\int_0^t 2dD \\,\\mathrm{d}\\tau $$\n$$ \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle - \\langle \\|\\mathbf{r}(0)\\|^2 \\rangle = 2dDt $$\nFrom the initial condition $p(\\mathbf{r}, 0) = \\delta(\\mathbf{r})$, all particles are at the origin at $t=0$, so the initial displacement and its squared-mean are zero:\n$$ \\langle \\|\\mathbf{r}(0)\\|^2 \\rangle = \\int_{\\mathbb{R}^d} \\|\\mathbf{r}\\|^2 \\delta(\\mathbf{r}) \\,\\mathrm{d}^d \\mathbf{r} = 0 $$\nThus, we arrive at the celebrated Einstein relation for diffusion:\n$$ \\langle \\|\\mathbf{r}(t)\\|^2 \\rangle = 2dDt $$\nThis result demonstrates that the mean-squared displacement is a linear function of time $t$. The slope of this linear relationship, $m$, is given by $m = 2dD$. Consequently, the diffusion coefficient $D$ can be determined from the slope of an MSD versus time plot as:\n$$ D = \\frac{\\text{slope}}{2d} $$\n\n### Part 2: Algorithmic Procedure for Diffusion Coefficient Estimation\n\nThe algorithm proceeds in three stages: synthetic data generation, MSD computation, and statistical estimation of the diffusion coefficient with confidence intervals.\n\n**1. Synthetic Trajectory Generation**\nThe trajectory of each particle is simulated as a discrete-time random walk. The position of particle $i$ at time step $k+1$ is given by $\\mathbf{r}_i(t_{k+1}) = \\mathbf{r}_i(t_k) + \\Delta\\mathbf{r}_{i,k}$, where $\\Delta\\mathbf{r}_{i,k}$ is a random displacement vector. For an isotropic diffusion process over a time interval $\\Delta t = t_{k+1}-t_k$, the displacement components in each of the $d$ dimensions are independent and identically distributed. A cornerstone of Brownian motion theory is that these increments are well-approximated by a normal distribution with mean $0$ and variance $2D\\Delta t$.\nTherefore, for each particle $i$ and time step $k$, we generate a displacement vector $\\Delta\\mathbf{r}_{i,k}$ whose components $(\\Delta r_1, \\dots, \\Delta r_d)$ are drawn from $\\mathcal{N}(0, 2D\\Delta t)$. The simulation starts with all particles at the origin, $\\mathbf{r}_i(0) = \\mathbf{0}$.\n\n**2. Mean-Squared Displacement Calculation**\nFor a given species with $N$ particles, we first generate $N$ independent trajectories $\\{\\mathbf{r}_i(t_k)\\}_{k=0}^{K}$ where $K$ is the total number of time steps. The ensemble mean-squared displacement at each time $t_k$ is calculated by averaging the squared displacement magnitudes over all particles:\n$$ M(t_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\mathbf{r}_i(t_k) - \\mathbf{r}_i(0)\\|^2 $$\nSince $\\mathbf{r}_i(0) = \\mathbf{0}$, this simplifies to:\n$$ M(t_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\|\\mathbf{r}_i(t_k)\\|^2 $$\nThis produces a time series of MSD values, $\\{M(t_k)\\}_{k=0}^{K}$.\n\n**3. Parameter Estimation and Confidence Interval**\nBased on the theoretical derivation, we expect a linear relationship $M(t_k) \\approx b \\cdot t_k + a$, where the theoretical slope is $b = 2dD$ and the theoretical intercept is $a=0$. We use Ordinary Least Squares (OLS) regression to estimate the slope from the computed data $(t_k, M(t_k))$.\n\n*   **OLS Regression**: Given $n=K+1$ data points $(x_k, y_k) = (t_k, M(t_k))$, the slope estimate $\\hat{b}$ is given by:\n    $$ \\hat{b} = \\frac{\\sum_{k=0}^{K} (x_k - \\bar{x})(y_k - \\bar{y})}{\\sum_{k=0}^{K} (x_k - \\bar{x})^2} $$\n    where $\\bar{x}$ and $\\bar{y}$ are the sample means. The diffusion coefficient estimate $\\hat{D}$ is then:\n    $$ \\hat{D} = \\frac{\\hat{b}}{2d} $$\n\n*   **Confidence Interval**: To quantify the uncertainty in our estimate, we construct a two-sided $95\\%$ confidence interval for $D$. This is derived from the confidence interval for the slope $\\hat{b}$.\n    1.  Calculate the residuals of the fit: $e_k = y_k - (\\hat{a} + \\hat{b}x_k)$, where $\\hat{a} = \\bar{y} - \\hat{b}\\bar{x}$.\n    2.  Estimate the variance of the residuals: $s_e^2 = \\frac{1}{n-2} \\sum_{k=0}^{K} e_k^2$. The denominator $n-2$ represents the degrees of freedom for a simple linear regression with an intercept.\n    3.  Calculate the standard error of the slope estimate:\n        $$ SE(\\hat{b}) = \\sqrt{\\frac{s_e^2}{\\sum_{k=0}^{K} (x_k - \\bar{x})^2}} $$\n    4.  The confidence interval for the true slope $b$ is given by $\\hat{b} \\pm t_{\\alpha/2, n-2} \\cdot SE(\\hat{b})$. For a $95\\%$ confidence level, $\\alpha=0.05$. The value $t_{0.025, n-2}$ is the critical value from the Student's t-distribution with $n-2$ degrees of freedom.\n    5.  The lower and upper bounds for the slope are:\n        $$ \\hat{b}_{\\text{low}} = \\hat{b} - t_{0.025, n-2} \\cdot SE(\\hat{b}) $$\n        $$ \\hat{b}_{\\text{high}} = \\hat{b} + t_{0.025, n-2} \\cdot SE(\\hat{b}) $$\n    6.  Finally, these bounds are mapped to the confidence interval for the diffusion coefficient $D$:\n        $$ \\mathrm{CI}_{\\mathrm{low}} = \\frac{\\hat{b}_{\\text{low}}}{2d} \\quad \\text{and} \\quad \\mathrm{CI}_{\\mathrm{high}} = \\frac{\\hat{b}_{\\text{high}}}{2d} $$\n    If a species has $D=0$, its trajectory will consist of all zeros, leading to $M(t_k)=0$ for all $k$. In this special case, the estimation results in $\\hat{D}=0$, and the confidence interval is $[0, 0]$. This is handled as a specific condition in the implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef estimate_diffusion(trajectories: np.ndarray, d: int, times: np.ndarray):\n    \"\"\"\n    Estimates the diffusion coefficient and its 95% CI from particle trajectories.\n\n    Args:\n        trajectories (np.ndarray): Array of particle positions with shape\n                                   (num_timesteps, num_particles, num_dims).\n        d (int): Number of spatial dimensions.\n        times (np.ndarray): Array of time points.\n\n    Returns:\n        list: A list containing [D_est, D_low, D_high].\n    \"\"\"\n    # MSD Calculation: M(t_k) = 1/N * sum_i ||r_i(t_k) - r_i(0)||^2\n    # Since r_i(0) = 0 for all i, this is ||r_i(t_k)||^2\n    squared_displacements = np.sum(trajectories**2, axis=2)\n    msd = np.mean(squared_displacements, axis=1)\n\n    # Handle the case of a non-diffusing species (D=0)\n    if np.all(msd == 0):\n        return [0.0, 0.0, 0.0]\n\n    # Ordinary Least Squares (OLS) regression of msd vs times\n    # Model: msd = intercept + slope * times\n    n = len(times)\n    x = times\n    y = msd\n    \n    # Using OLS formulas for y = a + bx\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    \n    # Calculate slope (b) and intercept (a)\n    ss_xy = np.sum((x - x_mean) * (y - y_mean))\n    ss_xx = np.sum((x - x_mean)**2)\n    \n    if ss_xx == 0: # Should not happen with the given problem constraints\n        return [0.0, 0.0, 0.0]\n\n    slope = ss_xy / ss_xx\n    \n    # Estimate D from the slope: slope = 2*d*D\n    d_est = slope / (2 * d)\n    \n    # Confidence Interval calculation\n    # Degrees of freedom for simple linear regression is n - 2\n    df = n - 2\n    if df <= 0: # Not enough data points to compute CI\n        return [d_est, d_est, d_est]\n\n    intercept = y_mean - slope * x_mean\n    y_pred = intercept + slope * x\n    residuals = y - y_pred\n    ssr = np.sum(residuals**2)\n    \n    # Standard error of the slope\n    se_slope = np.sqrt((ssr / df) / ss_xx)\n\n    # Critical t-value for 95% CI\n    alpha = 0.05\n    t_crit = t.ppf(1 - alpha / 2, df)\n\n    # Margin of error for the slope\n    margin_of_error_slope = t_crit * se_slope\n\n    # Confidence interval for the slope\n    slope_low = slope - margin_of_error_slope\n    slope_high = slope + margin_of_error_slope\n    \n    # Map slope CI to D CI\n    d_low = slope_low / (2 * d)\n    d_high = slope_high / (2 * d)\n\n    return [d_est, d_low, d_high]\n\ndef generate_trajectories(D, N, d, times, dt, seed):\n    \"\"\"\n    Generates synthetic particle trajectories for a given species.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    num_timesteps = len(times)\n    \n    if D == 0.0:\n        return np.zeros((num_timesteps, N, d))\n\n    positions = np.zeros((num_timesteps, N, d))\n    std_dev = np.sqrt(2 * D * dt)\n\n    current_pos = np.zeros((N, d))\n    for k in range(1, num_timesteps):\n        increments = rng.normal(loc=0.0, scale=std_dev, size=(N, d))\n        current_pos += increments\n        positions[k, :, :] = current_pos\n        \n    return positions\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"d_coeffs\": [1.0e-20, 4.0e-20, 0.0],\n            \"n_particles\": [200, 200, 200],\n            \"dim\": 3,\n            \"t_steps\": 101,\n            \"dt\": 5.0e-6,\n            \"seed\": 123\n        },\n        {\n            \"d_coeffs\": [1.0e-18, 3.0e-19],\n            \"n_particles\": [50, 50],\n            \"dim\": 2,\n            \"t_steps\": 151,\n            \"dt\": 1.0e-6,\n            \"seed\": 456\n        },\n        {\n            \"d_coeffs\": [5.0e-23, 1.0e-20],\n            \"n_particles\": [5, 5],\n            \"dim\": 3,\n            \"t_steps\": 41,\n            \"dt\": 2.0e-5,\n            \"seed\": 789\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        d_coeffs = case[\"d_coeffs\"]\n        n_particles = case[\"n_particles\"]\n        d = case[\"dim\"]\n        t_steps = case[\"t_steps\"]\n        dt = case[\"dt\"]\n        seed = case[\"seed\"]\n        \n        times = np.arange(t_steps) * dt\n        \n        case_results = []\n        \n        # We need a reproducible source of seeds for each species.\n        # Use the master seed to generate sub-seeds.\n        master_rng = np.random.default_rng(seed)\n        species_seeds = master_rng.integers(low=0, high=2**32, size=len(d_coeffs))\n\n        for i, D in enumerate(d_coeffs):\n            N = n_particles[i]\n            species_seed = species_seeds[i]\n            \n            trajectories = generate_trajectories(D, N, d, times, dt, species_seed)\n            species_result = estimate_diffusion(trajectories, d, times)\n            case_results.append(species_result)\n        \n        all_results.append(case_results)\n\n    # Format the final output string exactly as required.\n    # The str() function in Python adds spaces, which are not desired.\n    # We will build the string manually or use replacement.\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "For a kMC simulation to be physically meaningful, it must correctly reproduce the statistical mechanics of the system it models. A critical test for simulations of systems in thermal equilibrium is the principle of detailed balance, which ensures the correct thermodynamic state is sampled. This exercise introduces a numerical protocol to verify that your kMC implementation satisfies this fundamental principle, building confidence in the physical accuracy of your simulation results .",
            "id": "3747955",
            "problem": "You are to implement a numerical protocol to verify detailed balance for a small set of kinetic processes representative of vacancy-mediated diffusion and precipitation kinetics in high-entropy alloys (HEAs). Your verification must be based on measuring forward and backward transition probabilities for selected pairs of states using a continuous-time Kinetic Monte Carlo (kMC) simulation. The implementation must be self-contained, without external input, and produce the requested results for the provided test suite.\n\nFundamental base to use:\n- Kinetic Monte Carlo (kMC) defines a continuous-time Markov process over microstates $i \\in \\{0,1,\\dots\\}$ with state energies $E_i$ and transition rates $r_{i \\to j}$ to neighboring states $j$.\n- Under canonical equilibrium at temperature $T$ (in Kelvin), the stationary probability of a microstate $i$ is proportional to the Boltzmann factor, $\\pi_i \\propto \\exp(-\\beta E_i)$, with $\\beta = 1/(k_{\\mathrm{B}} T)$ and Boltzmann constant $k_{\\mathrm{B}}$ in electronvolt per Kelvin.\n- Transition State Theory (TST) gives Arrhenius-form rates for activated transitions: $r_{i \\to j} = \\nu_{i \\to j} \\exp(-\\beta (E_{ij}^{\\ddagger} - E_i))$, where $\\nu_{i \\to j}$ is an attempt frequency (in $\\mathrm{s}^{-1}$) and $E_{ij}^{\\ddagger}$ is the transition-state energy (in $\\mathrm{eV}$) for the reaction coordinate connecting $i$ to $j$.\n\nDefinition of detailed balance to verify numerically:\n- A Markov process satisfies detailed balance with respect to the canonical distribution if and only if $\\pi_i r_{i \\to j} = \\pi_j r_{j \\to i}$ for every pair of connected microstates $(i,j)$.\n\nProtocol to implement:\n- Construct each test case as a small network of microstates with specified energies $E_i$ (in $\\mathrm{eV}$) and undirected edges $(i,j)$ endowed with transition-state energies $E_{ij}^{\\ddagger}$ (in $\\mathrm{eV}$). For each edge, define attempt frequencies $\\nu_{i \\to j}$ (in $\\mathrm{s}^{-1}$). A symmetric physical model uses $\\nu_{i \\to j} = \\nu_{j \\to i}$; an intentionally broken model uses $\\nu_{i \\to j} \\neq \\nu_{j \\to i}$.\n- Simulate the kMC using the Gillespie algorithm:\n  - At current state $i$, compute all outgoing rates $r_{i \\to j}$ to neighbors $j$ using the Arrhenius form above.\n  - The total rate is $R_i = \\sum_j r_{i \\to j}$. Draw a waiting time $\\Delta t$ from an exponential distribution with mean $1/R_i$ and add it to the residence time of state $i$.\n  - Select the next state $j$ with probability $r_{i \\to j}/R_i$, advance to $j$, and record a transition $i \\to j$.\n- Use a burn-in of a specified number of events to let the process approach stationarity; then collect statistics:\n  - For each selected pair $(i,j)$, count forward transitions $N_{i \\to j}$ and backward transitions $N_{j \\to i}$ after burn-in.\n  - Accumulate residence times $\\tau_i$ and $\\tau_j$ after burn-in.\n- Define two numerical checks for detailed balance on each pair $(i,j)$:\n  1. Flux symmetry check: forward/backward flux equality implies $N_{i \\to j} \\approx N_{j \\to i}$ at stationarity. Quantify the relative difference $\\delta_{\\mathrm{flux}} = |N_{i \\to j} - N_{j \\to i}|/(N_{i \\to j}+N_{j \\to i})$.\n  2. Rate-ratio consistency check: the Arrhenius and Boltzmann forms imply $r_{i \\to j}/r_{j \\to i} = \\exp(-\\beta (E_j - E_i))$ when microreversibility holds. Estimate rates empirically as $\\hat{r}_{i \\to j} = N_{i \\to j}/\\tau_i$ and $\\hat{r}_{j \\to i} = N_{j \\to i}/\\tau_j$, and compare $\\hat{r}_{i \\to j}/\\hat{r}_{j \\to i}$ to $\\exp(-\\beta (E_j - E_i))$ by computing the relative deviation $\\delta_{\\mathrm{rate}} = \\left|\\frac{(\\hat{r}_{i \\to j}/\\hat{r}_{j \\to i})}{\\exp(-\\beta (E_j - E_i))} - 1\\right|$.\n- A pair $(i,j)$ passes if both $\\delta_{\\mathrm{flux}}$ and $\\delta_{\\mathrm{rate}}$ are below chosen tolerances.\n\nUnits:\n- Energies $E_i$ and $E_{ij}^{\\ddagger}$ must be in electronvolts ($\\mathrm{eV}$).\n- Temperature $T$ must be in Kelvin ($\\mathrm{K}$).\n- Attempt frequencies $\\nu_{i \\to j}$ must be in inverse seconds ($\\mathrm{s}^{-1}$).\n- Report the final program output as booleans, which are unitless.\n\nTest suite to implement and simulate:\n- Case $1$ (happy path, symmetric two-state): $E_0 = 0.0$ $\\mathrm{eV}$, $E_1 = 0.0$ $\\mathrm{eV}$, edge $(0,1)$ with $E_{01}^{\\ddagger} = 0.4$ $\\mathrm{eV}$, $\\nu_{0 \\to 1} = \\nu_{1 \\to 0} = 1.0 \\times 10^{12}$ $\\mathrm{s}^{-1}$, $T = 1000$ $\\mathrm{K}$, selected pair $(0,1)$, simulate $200000$ post-burn-in events.\n- Case $2$ (happy path, asymmetric energies two-state): $E_0 = 0.0$ $\\mathrm{eV}$, $E_1 = 0.2$ $\\mathrm{eV}$, edge $(0,1)$ with $E_{01}^{\\ddagger} = 0.5$ $\\mathrm{eV}$, $\\nu_{0 \\to 1} = \\nu_{1 \\to 0} = 1.0 \\times 10^{12}$ $\\mathrm{s}^{-1}$, $T = 1000$ $\\mathrm{K}$, selected pair $(0,1)$, simulate $250000$ post-burn-in events.\n- Case $3$ (edge case, broken microreversibility): $E_0 = 0.0$ $\\mathrm{eV}$, $E_1 = 0.2$ $\\mathrm{eV}$, edge $(0,1)$ with $E_{01}^{\\ddagger} = 0.5$ $\\mathrm{eV}$, $\\nu_{0 \\to 1} = 1.0 \\times 10^{12}$ $\\mathrm{s}^{-1}$, $\\nu_{1 \\to 0} = 2.0 \\times 10^{12}$ $\\mathrm{s}^{-1}$, $T = 1000$ $\\mathrm{K}$, selected pair $(0,1)$, simulate $250000$ post-burn-in events.\n- Case $4$ (multi-state coverage): $E_0 = 0.0$ $\\mathrm{eV}$, $E_1 = 0.1$ $\\mathrm{eV}$, $E_2 = 0.3$ $\\mathrm{eV}$, edges $(0,1)$ with $E_{01}^{\\ddagger} = 0.4$ $\\mathrm{eV}$ and $(1,2)$ with $E_{12}^{\\ddagger} = 0.6$ $\\mathrm{eV}$, both with $\\nu_{i \\to j} = \\nu_{j \\to i} = 1.0 \\times 10^{12}$ $\\mathrm{s}^{-1}$, $T = 1200$ $\\mathrm{K}$, selected pairs $(0,1)$ and $(1,2)$, simulate $400000$ post-burn-in events.\n\nTolerances for pass/fail:\n- Flux tolerance $\\delta_{\\mathrm{flux}}^{\\max} = 0.03$.\n- Rate-ratio tolerance $\\delta_{\\mathrm{rate}}^{\\max} = 0.05$.\n\nFinal output specification:\n- For each case, compute a boolean indicating whether all selected pairs passed both checks. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[{\\text{result}_1},{\\text{result}_2},{\\text{result}_3}]$ where each ${\\text{result}_k}$ is either $True$ or $False$. The final output must exactly match this format and contain four entries in the order of Cases $1$ through $4$.",
            "solution": "The user has provided a problem that requires the implementation of a Kinetic Monte Carlo (kMC) simulation to numerically verify the principle of detailed balance for several small-state systems. The problem is scientifically well-grounded, rigorously defined, and computationally feasible.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n\n*   **Physical Model**: Continuous-time Markov process over microstates $i$ with energies $E_i$. Stationary probability $\\pi_i \\propto \\exp(-\\beta E_i)$ where $\\beta = 1/(k_{\\mathrm{B}} T)$.\n*   **Transition Kinetics**: Transition State Theory (TST) with Arrhenius rates $r_{i \\to j} = \\nu_{i \\to j} \\exp(-\\beta (E_{ij}^{\\ddagger} - E_i))$, where $E_{ij}^{\\ddagger}$ is the transition-state energy and $\\nu_{i \\to j}$ is the attempt frequency.\n*   **Fundamental Principle**: Detailed balance is defined by $\\pi_i r_{i \\to j} = \\pi_j r_{j \\to i}$ for all connected state pairs $(i,j)$.\n*   **Simulation Algorithm**: Gillespie kMC algorithm (residence time drawn from exponential distribution, next state chosen via rate-weighted probability).\n*   **Numerical Verification Protocol**:\n    1.  **Flux Symmetry Check**: Calculate $\\delta_{\\mathrm{flux}} = |N_{i \\to j} - N_{j \\to i}|/(N_{i \\to j}+N_{j \\to i})$ using transition counts $N_{i \\to j}$ from the simulation.\n    2.  **Rate-Ratio Consistency Check**: Calculate $\\delta_{\\mathrm{rate}} = \\left|\\frac{(\\hat{r}_{i \\to j}/\\hat{r}_{j \\to i})}{\\exp(-\\beta (E_j - E_i))} - 1\\right|$ using empirical rates $\\hat{r}_{i \\to j} = N_{i \\to j}/\\tau_i$ derived from counts and residence times $\\tau_i$.\n*   **Tolerances**: $\\delta_{\\mathrm{flux}}^{\\max} = 0.03$, $\\delta_{\\mathrm{rate}}^{\\max} = 0.05$.\n*   **Test Suite**: Four specific cases are defined with all necessary parameters: state energies $E_i$, transition-state energies $E_{ij}^{\\ddagger}$, attempt frequencies $\\nu_{i \\to j}$, temperature $T$, pairs to check, and number of post-burn-in simulation events.\n*   **Constants & Units**: Energies are in $\\mathrm{eV}$, temperature in $\\mathrm{K}$, frequencies in $\\mathrm{s}^{-1}$, and the Boltzmann constant $k_{\\mathrm{B}}$ to be used in units of $\\mathrm{eV/K}$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is reviewed against the validation criteria:\n\n*   **Scientifically Grounded**: The problem is based on fundamental principles of statistical mechanics and chemical kinetics. The kMC method is a standard, rigorous computational technique for simulating stochastic processes. The premises and checks are scientifically sound.\n*   **Well-Posed**: All parameters ($E_i, E_{ij}^{\\ddagger}, \\nu_{i \\to j}, T$), simulation lengths, and verification criteria (tolerances) are explicitly defined for each test case. This ensures that a unique and meaningful boolean result can be determined for each case.\n*   **Objective**: The problem is stated in precise, quantitative terms, free from any subjective or ambiguous language.\n*   **Completeness and Consistency**: The problem is self-contained. The provided data is sufficient to perform the simulation and verification. A minor detail, the number of burn-in events, is not specified. However, since the systems are small and mix rapidly, any reasonable choice (e.g., $10^4$ events) is sufficient to reach stationarity and does not represent a flaw. The problem is internally consistent.\n*   **Feasibility**: All specified parameters are within physically realistic ranges. The required number of simulation events is computationally tractable on a standard computer.\n*   **Conceptual Depth**: The problem is not trivial. It requires the correct implementation of the Gillespie algorithm and a sound understanding of detailed balance, particularly the distinction between stationarity (checked by flux balance) and thermodynamic consistency (checked by the rate-ratio test), which is highlighted by Case $3$.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is a well-defined and scientifically sound numerical problem. I will now proceed to construct the complete solution.\n\n### **Solution Implementation**\n\nThe core of the solution is a function that executes a kMC simulation for a given system, followed by the application of the two verification checks.\n\n**1. System Representation**\nEach test case is defined by its system topology and energetics. A suitable representation is a set of dictionaries and arrays: state energies $E_i$, an adjacency list representing connections, and dictionaries for transition-state energies $E_{ij}^{\\ddagger}$ and attempt frequencies $\\nu_{i \\to j}$.\n\n**2. kMC Simulation (Gillespie Algorithm)**\nThe simulation proceeds in discrete events. At each step, from the current state $i$:\n*   All possible outgoing transition rates $r_{i \\to j}$ to neighboring states $j$ are calculated using the Arrhenius formula: $r_{i \\to j} = \\nu_{i \\to j} \\exp\\left(-\\frac{E_{ij}^{\\ddagger} - E_i}{k_{\\mathrm{B}}T}\\right)$.\n*   The total exit rate from state $i$ is the sum of all individual rates, $R_i = \\sum_j r_{i \\to j}$. If $R_i = 0$, the system is in a sink state and the simulation terminates.\n*   A time step $\\Delta t$ is drawn from an exponential distribution with mean $1/R_i$. This is achieved by calculating $\\Delta t = -\\ln(u_1) / R_i$, where $u_1$ is a random number uniformly distributed in $(0, 1]$.\n*   The next state $j$ is chosen with probability proportional to its rate, $p(j) = r_{i \\to j}/R_i$. This is implemented using a \"roulette wheel\" selection based on a second uniform random number $u_2 \\in (0, 1]$.\n*   The system time is advanced by $\\Delta t$, and the current state becomes $j$.\n*   For statistical analysis, we record the residence time $\\Delta t$ in the previous state $i$ and count the transition $i \\to j$.\n\nA burn-in period of $10,000$ events is used to ensure the system reaches its stationary distribution before statistics are collected.\n\n**3. Verification Checks**\nAfter the simulation completes, the collected statistics—transition counts $N_{i \\to j}$ and total residence times $\\tau_i$—are used to perform the checks for each specified pair of states $(i, j)$.\n\n*   **Flux Symmetry Check**: The relative difference in forward and backward transition counts, $\\delta_{\\mathrm{flux}} = |N_{i \\to j} - N_{j \\to i}|/(N_{i \\to j}+N_{j \\to i})$, is calculated. Robustness is added to handle the (unlikely) case where the denominator is zero. The result is compared against the tolerance $\\delta_{\\mathrm{flux}}^{\\max} = 0.03$.\n\n*   **Rate-Ratio Consistency Check**:\n    *   The theoretical rate ratio is calculated based on the Boltzmann distribution: $K_{\\text{theory}} = \\exp(-\\beta(E_j - E_i))$.\n    *   The empirical rates are estimated from the simulation: $\\hat{r}_{i \\to j} = N_{i \\to j}/\\tau_i$ and $\\hat{r}_{j \\to i} = N_{j \\to i}/\\tau_j$.\n    *   The empirical rate ratio is $K_{\\text{empirical}} = \\hat{r}_{i \\to j}/\\hat{r}_{j \\to i}$.\n    *   The relative deviation is computed: $\\delta_{\\mathrm{rate}} = |K_{\\text{empirical}}/K_{\\text{theory}} - 1|$.\n    *   This check requires careful handling of potential divisions by zero (e.g., if $\\tau_j=0$ or $\\hat{r}_{j \\to i}=0$), which would indicate a failure to meet the detailed balance condition or insufficient sampling. The result is compared against the tolerance $\\delta_{\\mathrm{rate}}^{\\max} = 0.05$.\n\nA test case is considered passed only if **all** its specified pairs pass **both** checks.\n\n**Case Analysis Predictions:**\n*   **Case 1 (Symmetric)**: Expected to pass. $E_0=E_1$ and $\\nu_{0 \\to 1}=\\nu_{1 \\to 0}$. The system is perfectly symmetric.\n*   **Case 2 (Asymmetric Energies)**: Expected to pass. The energy difference creates an asymmetry in state populations, but since microreversibility holds ($\\nu_{0 \\to 1}=\\nu_{1 \\to 0}$), detailed balance is satisfied.\n*   **Case 3 (Broken Microreversibility)**: Expected to fail. The condition $\\nu_{0 \\to 1} \\neq \\nu_{1 \\to 0}$ explicitly breaks the underlying assumption for detailed balance relative to the canonical Boltzmann distribution. The rate-ratio check should detect this discrepancy. The flux check may still pass because the system reaches a non-equilibrium steady state with balanced fluxes.\n*   **Case 4 (Multi-State)**: Expected to pass. Detailed balance is a local property that holds for each pair of connected states, regardless of other states in the network, provided microreversibility is maintained for each link.\n\nThe final implementation will encapsulate this logic into a single script that processes all four cases and produces the required output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the KMC simulation and verification for all test cases.\n    \"\"\"\n    \n    # Define physical constants and simulation parameters\n    KB_EV_K = 8.617333262145e-5  # Boltzmann constant in eV/K\n    BURN_IN_EVENTS = 10000\n    FLUX_TOLERANCE = 0.03\n    RATE_RATIO_TOLERANCE = 0.05\n\n    test_cases = [\n        {\n            \"name\": \"Case 1: Symmetric two-state\",\n            \"state_energies\": np.array([0.0, 0.0]),\n            \"edges\": {\n                (0, 1): {\"saddle_energy\": 0.4, \"nu_fwd\": 1.0e12, \"nu_bwd\": 1.0e12}\n            },\n            \"temperature\": 1000.0,\n            \"num_events\": 200000,\n            \"selected_pairs\": [(0, 1)],\n        },\n        {\n            \"name\": \"Case 2: Asymmetric energies two-state\",\n            \"state_energies\": np.array([0.0, 0.2]),\n            \"edges\": {\n                (0, 1): {\"saddle_energy\": 0.5, \"nu_fwd\": 1.0e12, \"nu_bwd\": 1.0e12}\n            },\n            \"temperature\": 1000.0,\n            \"num_events\": 250000,\n            \"selected_pairs\": [(0, 1)],\n        },\n        {\n            \"name\": \"Case 3: Broken microreversibility\",\n            \"state_energies\": np.array([0.0, 0.2]),\n            \"edges\": {\n                (0, 1): {\"saddle_energy\": 0.5, \"nu_fwd\": 1.0e12, \"nu_bwd\": 2.0e12}\n            },\n            \"temperature\": 1000.0,\n            \"num_events\": 250000,\n            \"selected_pairs\": [(0, 1)],\n        },\n        {\n            \"name\": \"Case 4: Multi-state coverage\",\n            \"state_energies\": np.array([0.0, 0.1, 0.3]),\n            \"edges\": {\n                (0, 1): {\"saddle_energy\": 0.4, \"nu_fwd\": 1.0e12, \"nu_bwd\": 1.0e12},\n                (1, 2): {\"saddle_energy\": 0.6, \"nu_fwd\": 1.0e12, \"nu_bwd\": 1.0e12},\n            },\n            \"temperature\": 1200.0,\n            \"num_events\": 400000,\n            \"selected_pairs\": [(0, 1), (1, 2)],\n        },\n    ]\n\n    def run_kmc_case(params):\n        \"\"\"\n        Runs a single KMC simulation and detailed balance check for a given case.\n        \"\"\"\n        state_energies = params[\"state_energies\"]\n        n_states = len(state_energies)\n        T = params[\"temperature\"]\n        beta = 1.0 / (KB_EV_K * T)\n\n        # Build adjacency list and rate info\n        adjacency = [[] for _ in range(n_states)]\n        saddle_energies = {}\n        attempt_freqs = {}\n        for (i, j), edge_data in params[\"edges\"].items():\n            adjacency[i].append(j)\n            adjacency[j].append(i)\n            saddle_energies[(i, j)] = saddle_energies[(j, i)] = edge_data[\"saddle_energy\"]\n            attempt_freqs[(i, j)] = edge_data[\"nu_fwd\"]\n            attempt_freqs[(j, i)] = edge_data[\"nu_bwd\"]\n\n        # KMC simulation state\n        current_state = 0\n        rng = np.random.default_rng(seed=42) # Seed for reproducibility\n\n        # Gillespie step function\n        def gillespie_step(state_idx):\n            neighbors = adjacency[state_idx]\n            if not neighbors:\n                return state_idx, np.inf # Sink state\n\n            rates = []\n            for neighbor_idx in neighbors:\n                E_i = state_energies[state_idx]\n                E_ij_saddle = saddle_energies[(state_idx, neighbor_idx)]\n                barrier = E_ij_saddle - E_i\n                nu = attempt_freqs[(state_idx, neighbor_idx)]\n                rate = nu * np.exp(-beta * barrier)\n                rates.append(rate)\n            \n            total_rate = sum(rates)\n            if total_rate == 0:\n                return state_idx, np.inf\n\n            dt = -np.log(rng.random()) / total_rate\n            \n            # Select next state\n            rand_choice = rng.random() * total_rate\n            cum_rate = 0.0\n            next_state = -1\n            for i, rate in enumerate(rates):\n                cum_rate += rate\n                if rand_choice < cum_rate:\n                    next_state = neighbors[i]\n                    break\n            \n            return next_state, dt\n\n        # --- Simulation Loop ---\n        num_total_events = BURN_IN_EVENTS + params[\"num_events\"]\n        residence_times = np.zeros(n_states)\n        transition_counts = np.zeros((n_states, n_states), dtype=int)\n\n        for event_num in range(num_total_events):\n            next_state, dt = gillespie_step(current_state)\n            \n            # Collect statistics only after burn-in\n            if event_num >= BURN_IN_EVENTS:\n                residence_times[current_state] += dt\n                if next_state != current_state:\n                    transition_counts[current_state, next_state] += 1\n            \n            current_state = next_state\n\n        # --- Verification ---\n        all_pairs_passed = True\n        for i, j in params[\"selected_pairs\"]:\n            # 1. Flux symmetry check\n            N_ij = transition_counts[i, j]\n            N_ji = transition_counts[j, i]\n            \n            flux_check_passed = False\n            total_flux_events = N_ij + N_ji\n            if total_flux_events == 0:\n                # If no transitions occurred, this check is inconclusive but not a failure.\n                flux_check_passed = True\n            else:\n                delta_flux = np.abs(N_ij - N_ji) / total_flux_events\n                if delta_flux <= FLUX_TOLERANCE:\n                    flux_check_passed = True\n\n            # 2. Rate-ratio consistency check\n            tau_i = residence_times[i]\n            tau_j = residence_times[j]\n            \n            rate_check_passed = False\n            if tau_i > 0 and tau_j > 0 and N_ji > 0:\n                r_hat_ij = N_ij / tau_i\n                r_hat_ji = N_ji / tau_j\n                \n                if r_hat_ji > 0:\n                    empirical_ratio = r_hat_ij / r_hat_ji\n                    \n                    E_i, E_j = state_energies[i], state_energies[j]\n                    theoretical_ratio = np.exp(-beta * (E_j - E_i))\n                    \n                    if theoretical_ratio > 0:\n                        delta_rate = np.abs(empirical_ratio / theoretical_ratio - 1)\n                        if delta_rate <= RATE_RATIO_TOLERANCE:\n                            rate_check_passed = True\n\n            if not (flux_check_passed and rate_check_passed):\n                all_pairs_passed = False\n                break # A single failure is enough for the case\n\n        return all_pairs_passed\n\n    # Run all test cases and collect results\n    results = [run_kmc_case(case) for case in test_cases]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}