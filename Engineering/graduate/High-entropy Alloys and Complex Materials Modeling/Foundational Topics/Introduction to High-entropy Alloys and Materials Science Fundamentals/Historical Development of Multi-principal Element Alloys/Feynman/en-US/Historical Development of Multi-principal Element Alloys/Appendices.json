{
    "hands_on_practices": [
        {
            "introduction": "The paradigm of multi-principal element alloys was born from the hypothesis that maximizing the configurational entropy of mixing, $S_{\\text{config}}$, could stabilize simple solid-solution phases over complex intermetallics. This practice  provides a first-principles derivation of this entropy for an ideal, equiatomic alloy, allowing you to quantify the thermodynamic driving force, $-T \\Delta S_{\\text{mix}}$, that defined the early \"high-entropy\" concept. By working through the statistical mechanics, you will connect the microscopic arrangement of atoms to the macroscopic thermodynamic stability of the alloy.",
            "id": "3745159",
            "problem": "In the early development of multi-principal element alloys (also known as high-entropy alloys), a central hypothesis was that a sufficiently large configurational entropy of random mixing can stabilize single-phase random solid solutions on common crystal lattices. Consider the equiatomic refractory alloy NbMoTaW, which is widely observed to form a single-phase body-centered cubic (BCC) solid solution at high temperature. Starting from the Boltzmann entropy definition for an ideal random solution on a rigid lattice, $S = k_B \\ln W$, where $k_B$ is the Boltzmann constant and $W$ is the number of distinct occupation microstates, do the following under the assumptions of ideal random mixing on $N$ indistinguishable lattice sites, equiatomic composition with $n=4$ species, and the thermodynamic limit $N \\to \\infty$:\n- Using combinatorial counting of lattice occupations and Stirling’s approximation, derive the molar configurational entropy of mixing $S_{\\text{config}}$ for equiatomic NbMoTaW in terms of the molar gas constant $R$ and the number of components $n$.\n- Evaluate the result numerically for $n=4$ using $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$ and round your final numerical value to $4$ significant figures. Express the final entropy in $\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- Briefly (in at most two sentences), interpret how the magnitude of your computed $S_{\\text{config}}$ correlates with the observed single-phase BCC solid solution formation in NbMoTaW within the framework of the Gibbs free energy $G = H - TS$ at high temperature.\n\nYour final answer must be a single real number equal to your computed $S_{\\text{config}}$ rounded to $4$ significant figures. Do not include units in the final boxed answer.",
            "solution": "The problem is subjected to validation before proceeding.\n\n### Step 1: Extract Givens\n- System: Equiatomic refractory alloy NbMoTaW.\n- Observation: Forms a single-phase body-centered cubic (BCC) solid solution at high temperature.\n- Entropy definition: $S = k_B \\ln W$.\n- $k_B$: Boltzmann constant.\n- $W$: Number of distinct occupation microstates.\n- Assumption 1: Ideal random mixing on $N$ indistinguishable lattice sites.\n- Assumption 2: Equiatomic composition.\n- Number of components: $n=4$.\n- Assumption 3: Thermodynamic limit $N \\to \\infty$.\n- Task 1: Derive the molar configurational entropy of mixing, $S_{\\text{config}}$, for an equiatomic alloy in terms of the molar gas constant $R$ and the number of components $n$, using combinatorial counting and Stirling's approximation.\n- Task 2: Evaluate the result numerically for $n=4$ using $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- Task 3: Round the numerical result to $4$ significant figures.\n- Task 4: Briefly interpret the result in the context of the Gibbs free energy, $G = H - T S$.\n- Final answer requirement: The rounded numerical value of $S_{\\text{config}}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, drawing upon fundamental principles of statistical mechanics (Boltzmann entropy) and thermodynamics as applied to materials science (high-entropy alloys). The system (NbMoTaW), the concept of configurational entropy stabilizing a solid solution, and the assumptions (ideal random mixing, thermodynamic limit) are standard and well-established in the field. The problem is well-posed, providing all necessary definitions, constants, and constraints to arrive at a unique, meaningful solution. The language is objective and precise. The problem does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution Derivation\n\nThe derivation begins with the Boltzmann entropy definition, $S = k_B \\ln W$, where $W$ is the number of microstates. For an alloy with $N$ total lattice sites and $n$ different atomic species, the number of ways to arrange the atoms is given by the multinomial coefficient:\n$$W = \\frac{N!}{N_1! N_2! \\cdots N_n!} = \\frac{N!}{\\prod_{i=1}^{n} N_i!}$$\nwhere $N_i$ is the number of atoms of species $i$. The total number of atoms is $N = \\sum_{i=1}^{n} N_i$.\n\nThe problem states the alloy is equiatomic, meaning the number of atoms of each species is the same. Therefore, for $n$ components, $N_1 = N_2 = \\cdots = N_n = N/n$. Substituting this into the expression for $W$:\n$$W = \\frac{N!}{\\left(\\left(\\frac{N}{n}\\right)!\\right)^n}$$\n\nThe configurational entropy $S$ is then:\n$$S = k_B \\ln W = k_B \\ln\\left(\\frac{N!}{\\left(\\left(\\frac{N}{n}\\right)!\\right)^n}\\right) = k_B \\left[ \\ln(N!) - n \\ln\\left(\\left(\\frac{N}{n}\\right)!\\right) \\right]$$\n\nTo simplify this expression, we invoke the thermodynamic limit ($N \\to \\infty$) and apply Stirling's approximation for the natural logarithm of a factorial, $\\ln(x!) \\approx x \\ln x - x$.\n\nApplying this to $\\ln(N!)$:\n$$\\ln(N!) \\approx N \\ln N - N$$\nAnd to $\\ln((\\frac{N}{n})!)$:\n$$\\ln\\left(\\left(\\frac{N}{n}\\right)!\\right) \\approx \\frac{N}{n} \\ln\\left(\\frac{N}{n}\\right) - \\frac{N}{n}$$\n\nSubstituting these approximations into the entropy equation:\n$$S \\approx k_B \\left[ (N \\ln N - N) - n \\left( \\frac{N}{n} \\ln\\left(\\frac{N}{n}\\right) - \\frac{N}{n} \\right) \\right]$$\n$$S \\approx k_B \\left[ N \\ln N - N - N \\ln\\left(\\frac{N}{n}\\right) + N \\right]$$\nThe terms $-N$ and $+N$ cancel:\n$$S \\approx k_B \\left[ N \\ln N - N \\ln\\left(\\frac{N}{n}\\right) \\right]$$\nUsing the logarithm property $\\ln a - \\ln b = \\ln(a/b)$:\n$$S \\approx k_B N \\left[ \\ln N - \\ln\\left(\\frac{N}{n}\\right) \\right] = k_B N \\ln\\left(\\frac{N}{N/n}\\right)$$\n$$S \\approx k_B N \\ln n$$\n\nThis is the total configurational entropy for $N$ atoms. The problem asks for the molar configurational entropy of mixing, $S_{\\text{config}}$. To obtain this, we consider one mole of atoms, so $N = N_A$, where $N_A$ is Avogadro's constant.\n$$S_{\\text{config}} = k_B N_A \\ln n$$\nRecognizing that the molar gas constant $R$ is defined as $R = k_B N_A$, we arrive at the final symbolic expression:\n$$S_{\\text{config}} = R \\ln n$$\n\n### Numerical Evaluation\n\nNow we evaluate this expression for the equiatomic NbMoTaW alloy, which has $n=4$ components. The given value for the molar gas constant is $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n$$S_{\\text{config}} = R \\ln(4) = (8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}) \\times \\ln(4)$$\n$$\\ln(4) \\approx 1.38629436$$\n$$S_{\\text{config}} \\approx 8.314462618 \\times 1.38629436 \\approx 11.52554\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$$\nRounding the result to $4$ significant figures gives:\n$$S_{\\text{config}} \\approx 11.53\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$$\n\n### Interpretation\n\nWithin the framework of the Gibbs free energy of mixing, $\\Delta G_{\\mathrm{mix}} = \\Delta H_{\\mathrm{mix}} - T \\Delta S_{\\mathrm{mix}}$, the large calculated configurational entropy of mixing ($S_{\\text{config}} \\approx 11.53\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$) makes the entropic contribution, $-T S_{\\text{config}}$, highly negative, particularly at the high temperatures where NbMoTaW is formed. This substantial negative term can overwhelm a potentially positive (unfavorable) enthalpy of mixing ($\\Delta H_{\\mathrm{mix}}$), thereby minimizing the total Gibbs free energy and thermodynamically stabilizing the single-phase random solid solution over competing intermetallic compounds or phase-separated mixtures.",
            "answer": "$$\\boxed{11.53}$$"
        },
        {
            "introduction": "Beyond the initial thermodynamic arguments, the historical development of high-entropy alloys was also shaped by proposed kinetic \"core effects,\" most notably the concept of \"sluggish diffusion.\" This exercise  challenges you to critically evaluate this claim by analyzing hypothetical diffusion data, emphasizing the importance of statistical rigor and logarithmic scaling when interpreting kinetic phenomena. This practice hones your ability to scrutinize scientific claims and understand the subtle yet crucial distinction between an observed trend and a statistically significant physical effect.",
            "id": "3745198",
            "problem": "A central historical claim in the development of Multi-Principal Element Alloys (MPEAs), including so-called High-Entropy Alloys (HEAs), was that atomic transport is intrinsically retarded compared to conventional alloys, summarized as the notion of “sluggish diffusion.” Consider the equiatomic Co–Cr–Fe–Mn–Ni alloy (commonly called the Cantor alloy), and compare it to pure nickel. Use the following definitions as a fundamental base: Fick’s first law of diffusion, $J=-D\\nabla c$, where $J$ is the flux, $D$ is the tracer diffusion coefficient, and $c$ is concentration; and the Arrhenius form for point-defect-mediated diffusion in metals, $D(T)=D_{0}\\exp\\left(-\\frac{Q}{k_{B}T}\\right)$, where $D_{0}$ is a prefactor, $Q$ is an activation energy, $k_{B}$ is the Boltzmann constant, and $T$ is temperature.\n\nAt $T=1000\\,\\mathrm{K}$, suppose experimentally measured tracer diffusion coefficients for a given atomic species are $D_{\\mathrm{Ni}}(1000\\,\\mathrm{K})=2\\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$ in pure nickel and $D_{\\mathrm{Cantor}}(1000\\,\\mathrm{K})=1\\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$ in the Cantor alloy. Compute the dimensionless ratio $R=D_{\\mathrm{Cantor}}(1000\\,\\mathrm{K})/D_{\\mathrm{Ni}}(1000\\,\\mathrm{K})$ and report it as a decimal number. No rounding is required.\n\nThen, using only the above fundamental base and generic statistical reasoning commonly used for diffusion data (which are often modeled as lognormal because $D$ spans many orders of magnitude), discuss whether a factor-of-two reduction at fixed temperature, reflected by your computed $R$, substantively supports the historical “sluggish diffusion” claim. Your discussion must articulate an analytic criterion in terms of the logarithmic ratio $\\ln R$ and generic standard uncertainties on $\\ln D$ (do not invent numerical uncertainty values; state the criterion symbolically and, if useful, evaluate threshold quantities that depend only on $R$). The final numerical answer to be submitted is the single value of $R$; the discussion does not require any additional numerical output. Express the ratio $R$ without units.",
            "solution": "The problem is first subjected to validation.\n\n### Step 1: Extract Givens\n-   **Alloys:** Equiatomic Co–Cr–Fe–Mn–Ni (Cantor alloy) and pure nickel (Ni).\n-   **Physical Law:** Fick’s first law, $J=-D\\nabla c$, where $J$ is flux, $D$ is the tracer diffusion coefficient, and $c$ is concentration.\n-   **Physical Model:** Arrhenius equation for diffusion, $D(T)=D_{0}\\exp\\left(-\\frac{Q}{k_{B}T}\\right)$, where $D_{0}$ is a prefactor, $Q$ is activation energy, $k_{B}$ is the Boltzmann constant, and $T$ is temperature.\n-   **Condition:** Temperature $T=1000\\,\\mathrm{K}$.\n-   **Data for Pure Ni:** Tracer diffusion coefficient $D_{\\mathrm{Ni}}(1000\\,\\mathrm{K})=2\\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$.\n-   **Data for Cantor Alloy:** Tracer diffusion coefficient $D_{\\mathrm{Cantor}}(1000\\,\\mathrm{K})=1\\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$.\n-   **Task 1:** Compute the dimensionless ratio $R=D_{\\mathrm{Cantor}}(1000\\,\\mathrm{K})/D_{\\mathrm{Ni}}(1000\\,\\mathrm{K})$.\n-   **Task 2:** Discuss whether the computed ratio $R$ substantively supports the claim of “sluggish diffusion,” using an analytic criterion based on the logarithmic ratio $\\ln R$ and generic statistical uncertainties on $\\ln D$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is centered on solid-state diffusion, a core topic in materials science and condensed matter physics. It references established physical laws ($J=-D\\nabla c$) and models ($D=D_0 \\exp(-Q/k_B T)$). The subject, diffusion in high-entropy alloys, is a legitimate and active area of scientific research. The provided diffusion coefficient values are physically realistic for fcc metals at the specified temperature ($T \\approx 0.58 \\, T_m$ for Ni, where $T_m$ is the melting temperature). The problem is scientifically sound.\n-   **Well-Posed:** The problem is clearly defined. It requests a specific calculation followed by a conceptual discussion guided by specific constraints (use of logarithmic ratios and statistical reasoning). The calculation has a unique, stable solution. The discussion is structured to lead to a reasoned, objective argument rather than a subjective opinion.\n-   **Objective:** The problem statement is objective. It refers to \"sluggish diffusion\" as a \"historical claim\" and asks for a critical evaluation of evidence, which is the standard scientific process. The language is precise and free of bias.\n-   **Completeness and Consistency:** All data required for the calculation are provided. There are no internal contradictions.\n-   **Realism and Feasibility:** The physical situation and data are realistic.\n-   **Other Flaws:** The problem is not trivial, as the discussion requires nuanced understanding of experimental uncertainty in the context of diffusion data. It is not ill-posed, metaphorical, or unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\nThe problem asks for two parts: first, the calculation of a ratio of diffusion coefficients, and second, a critical discussion of the significance of this ratio in the context of the \"sluggish diffusion\" hypothesis for high-entropy alloys.\n\n**Part 1: Calculation of the Ratio R**\n\nWe are given the tracer diffusion coefficient for a species in pure nickel at $T=1000\\,\\mathrm{K}$:\n$$\nD_{\\mathrm{Ni}}(1000\\,\\mathrm{K}) = 2 \\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}\n$$\nand in the equiatomic Co–Cr–Fe–Mn–Ni Cantor alloy at the same temperature:\n$$\nD_{\\mathrm{Cantor}}(1000\\,\\mathrm{K}) = 1 \\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}\n$$\nThe dimensionless ratio $R$ is defined as:\n$$\nR = \\frac{D_{\\mathrm{Cantor}}(1000\\,\\mathrm{K})}{D_{\\mathrm{Ni}}(1000\\,\\mathrm{K})}\n$$\nSubstituting the given values:\n$$\nR = \\frac{1 \\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}}{2 \\times 10^{-15}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}} = \\frac{1}{2} = 0.5\n$$\nThe calculation shows that at $T=1000\\,\\mathrm{K}$, the tracer diffusion in the Cantor alloy is slower than in pure nickel by a factor of $2$.\n\n**Part 2: Discussion of the \"Sluggish Diffusion\" Claim**\n\nThe core of the question is whether a measured reduction in the diffusion coefficient by a factor of $2$ constitutes substantive evidence for the \"sluggish diffusion\" hypothesis. The claim itself implies a behavior that is fundamentally and significantly slower than in conventional alloys. To assess this, we must use the requested statistical reasoning.\n\nDiffusion coefficients in solids span many orders of magnitude, and their temperature dependence is exponential, as given by the Arrhenius relation $D(T)=D_{0}\\exp(-\\frac{Q}{k_{B}T})$. For this reason, experimental diffusion data are most appropriately analyzed and compared on a logarithmic scale. Taking the natural logarithm of the Arrhenius equation yields:\n$$\n\\ln D(T) = \\ln D_{0} - \\frac{Q}{k_{B}T}\n$$\nThis shows a linear relationship between $\\ln D$ and $1/T$. Experimental uncertainties in determining $D$ are therefore best expressed as an uncertainty in $\\ln D$, denoted as $\\sigma_{\\ln D}$.\n\nThe comparison between diffusion in the Cantor alloy and pure nickel is captured by the ratio $R$. On a logarithmic scale, this comparison becomes the difference:\n$$\n\\ln R = \\ln \\left( \\frac{D_{\\mathrm{Cantor}}}{D_{\\mathrm{Ni}}} \\right) = \\ln D_{\\mathrm{Cantor}} - \\ln D_{\\mathrm{Ni}}\n$$\nFor the given data, this logarithmic ratio is:\n$$\n\\ln R = \\ln(0.5) = -\\ln(2) \\approx -0.693\n$$\nThe question of whether the observed reduction is significant is equivalent to asking if this difference, $\\ln R$, is statistically distinguishable from zero, given the inherent uncertainties in the experimental measurements.\n\nLet $\\sigma_{\\ln D_{\\mathrm{Cantor}}}$ and $\\sigma_{\\ln D_{\\mathrm{Ni}}}$ be the standard uncertainties associated with the measurements of $\\ln D_{\\mathrm{Cantor}}$ and $\\ln D_{\\mathrm{Ni}}$, respectively. Assuming the two measurements are independent, the uncertainty in their difference, $\\sigma_{\\ln R}$, is found by propagating the uncertainties:\n$$\n\\sigma_{\\ln R} = \\sqrt{\\sigma_{\\ln D_{\\mathrm{Cantor}}}^2 + \\sigma_{\\ln D_{\\mathrm{Ni}}}^2}\n$$\nAn analytic criterion for the \"sluggish diffusion\" claim to be substantively supported is that the magnitude of the measured logarithmic ratio must be significantly larger than its uncertainty. A common threshold for statistical significance is two or three standard deviations (i.e., $2\\sigma$ or $3\\sigma$). Thus, the criterion is:\n$$\n|\\ln R| > z \\cdot \\sigma_{\\ln R}\n$$\nwhere $z$ is a factor, typically $z=2$ or $z=3$, representing the desired confidence level.\n\nThe problem requires a discussion based on *generic* statistical reasoning, without providing specific uncertainty values. In the field of solid-state diffusion, high-precision experiments might achieve an uncertainty in $D$ on the order of $\\pm 20\\%$ to $\\pm 30\\%$. An uncertainty of, say, $25\\%$ in $D$ corresponds to an uncertainty in $\\ln D$ of approximately $\\sigma_{\\ln D} \\approx \\ln(1.25) \\approx 0.22$. Let us adopt a generic standard uncertainty of $\\sigma_{\\ln D} \\approx 0.2-0.3$ as a typical value for a single measurement. Assuming the experimental efforts are comparable, so $\\sigma_{\\ln D_{\\mathrm{Cantor}}} \\approx \\sigma_{\\ln D_{\\mathrm{Ni}}} \\equiv \\sigma_{\\ln D}$, the uncertainty in the logarithmic ratio becomes:\n$$\n\\sigma_{\\ln R} \\approx \\sqrt{\\sigma_{\\ln D}^2 + \\sigma_{\\ln D}^2} = \\sqrt{2} \\sigma_{\\ln D}\n$$\nFor a generic $\\sigma_{\\ln D} = 0.25$, we would have $\\sigma_{\\ln R} \\approx \\sqrt{2} \\times 0.25 \\approx 0.35$.\n\nThe significance criterion then requires $|\\ln R| > z \\cdot 0.35$. With our calculated $|\\ln R| \\approx 0.693$:\n-   For a $z=2$ criterion (approx. $95\\%$ confidence), the threshold would be $2 \\times 0.35 = 0.70$. Our value of $0.693$ is just at this threshold.\n-   For a $z=3$ criterion (approx. $99.7\\%$ confidence), the threshold would be $3 \\times 0.35 = 1.05$. Our value of $0.693$ is well below this.\n\nThis analysis shows that a factor-of-two difference is on the borderline of being statistically significant at the $\\approx 2\\sigma$ level and is not significant at a higher confidence level.\n\nFurthermore, the term \"sluggish\" in a scientific context implies a substantial, often order-of-magnitude, effect. A factor-of-two difference is a very modest change when diffusion coefficients can vary over $10$ or more orders of magnitude across different materials and temperature ranges. The chemical complexity of the Cantor alloy (five principal elements) compared to a pure element (nickel) could easily introduce variations in bonding and defect energetics that result in factor-of-two changes in kinetics, without necessitating a paradigm-shifting concept like \"sluggish diffusion.\"\n\nIn conclusion, while the data indicate that diffusion is slower in the Cantor alloy, a reduction by a factor of only two ($|\\ln R| \\approx 0.693$) is not, by itself, strong or substantive support for the historical claim of \"sluggish diffusion.\" The magnitude of the effect is comparable to what might be expected from typical experimental uncertainty and modest changes in system properties. Conclusive evidence would require demonstrating a reduction by a much larger factor (e.g., an order of magnitude or more, which would mean $|\\ln R| > \\ln(10) \\approx 2.3$) or showing a systematically higher activation energy $Q$ over a wide temperature range.",
            "answer": "$$\\boxed{0.5}$$"
        },
        {
            "introduction": "As the field matured, it became clear that simple heuristics like maximizing entropy were insufficient to reliably predict phase formation, necessitating a shift towards more sophisticated, predictive modeling. This computational practice  immerses you in this modern approach, asking you to model phase selection during solidification by integrating thermodynamic competition between phases with the kinetic realities of microsegregation. By implementing a solidification path model, you will gain hands-on experience with the type of integrated computational tools that drive contemporary alloy design.",
            "id": "3745155",
            "problem": "Consider the historical evolution of reasoning in multi-principal element alloys, where early emphasis on high configurational entropy gave way to phase selection logic grounded in thermodynamics and transport. In the modern view, the phase that nucleates first during solidification at a given composition is the one with the highest equilibrium liquidus temperature. Microsegregation during dendritic growth modifies the local liquid composition, which can alter which phase remains favored as solidification proceeds. You are asked to formalize this reasoning in a quinary High-Entropy Alloy setting using hypothetical, but scientifically plausible, liquidus surfaces and a simplified microsegregation trajectory model.\n\nFundamental base to use:\n- The phase that nucleates first at a given composition is the one whose liquidus surface yields the highest temperature. That is, for composition vector $\\mathbf{x} = (x_A, x_B, x_C, x_D, x_E)$ satisfying $\\sum_i x_i = 1$ and $x_i \\ge 0$, the primary phase at onset is $\\arg\\max_{\\phi \\in \\{\\mathrm{FCC}, \\mathrm{BCC}, \\Sigma\\}} T^{\\phi}_\\mathrm{L}(\\mathbf{x})$, where $T^{\\phi}_\\mathrm{L}$ denotes the liquidus temperature surface of phase $\\phi$ in Kelvin.\n- Under Scheil-type microsegregation logic (no diffusion in solid, complete mixing in liquid), elements with partition coefficient $k_i  1$ enrich in the liquid during solidification. We model the local liquid composition trajectory as a normalized line in composition space that increases components proportional to $(1 - k_i)$, modulated by a trajectory-specific weighting vector $\\mathbf{w}$.\n\nHypothetical liquidus surfaces in Kelvin are defined for three candidate primary phases: Face-Centered Cubic (FCC), Body-Centered Cubic (BCC), and the $\\Sigma$ phase. For any $\\mathbf{x}$,\n$$\nT^{\\mathrm{FCC}}_\\mathrm{L}(\\mathbf{x}) = 1800 + 300 x_A + 100 x_B + 50 x_C - 80 x_D - 120 x_E + 200 x_A x_B + 150 x_C x_D - 100 x_B x_E,\n$$\n$$\nT^{\\mathrm{BCC}}_\\mathrm{L}(\\mathbf{x}) = 1750 + 500 x_B + 250 x_D - 50 x_A - 80 x_C + 180 x_B x_D + 120 x_A x_E - 90 x_C x_E,\n$$\n$$\nT^{\\Sigma}_\\mathrm{L}(\\mathbf{x}) = 1700 + 600 x_C + 300 x_E - 100 x_B - 50 x_D + 200 x_C x_E - 150 x_A x_C + 100 x_B x_C.\n$$\n\nMicrosegregation trajectory model:\n- Let partition coefficients be $\\mathbf{k} = (k_A, k_B, k_C, k_D, k_E) = (0.90, 0.70, 0.60, 0.95, 0.50)$.\n- For a given nominal composition $\\mathbf{x}_0$ and a trajectory weighting vector $\\mathbf{w}$, define the unnormalized path\n$$\n\\tilde{\\mathbf{x}}(t) = \\mathbf{x}_0 + \\alpha \\, t \\, \\left[(\\mathbf{1} - \\mathbf{k}) \\odot \\mathbf{w}\\right],\n$$\nwhere $t \\in [0,1]$, $\\alpha$ is a scalar step size, $\\mathbf{1}$ is the vector of ones, and $\\odot$ denotes element-wise multiplication. Then normalize at each $t$:\n$$\n\\mathbf{x}(t) = \\frac{\\tilde{\\mathbf{x}}(t)}{\\sum_{i \\in \\{A,B,C,D,E\\}} \\tilde{x}_i(t)}.\n$$\nUse $\\alpha = 0.30$.\n\nPrimary phase selection along the path:\n- The primary phase at onset is the index of the phase with the highest liquidus temperature at $t = 0$, i.e., at $\\mathbf{x}(0) = \\mathbf{x}_0$.\n- Define the favored phase at each $t$ as the phase with the maximum $T_\\mathrm{L}^{\\phi}(\\mathbf{x}(t))$. For numerical implementation, break ties by choosing the lowest phase index.\n- Define the persistence fraction $f$ of the primary phase as the fraction of the uniformly sampled $t \\in [0,1]$ grid points for which the favored phase equals the primary phase. Approximate this by discretizing $t$ into $N$ points including endpoints and using the ratio of counts, with $N = 501$.\n\nAngle units are not applicable. Temperatures are in Kelvin. Fractions must be reported as decimals rounded to three decimal places.\n\nTest suite:\nYou must evaluate three trajectories with the following $(\\mathbf{x}_0, \\mathbf{w})$ pairs:\n- Trajectory $1$: $\\mathbf{x}_0 = (0.20, 0.20, 0.20, 0.20, 0.20)$, $\\mathbf{w} = (0.20, 0.20, 0.20, 0.20, 0.20)$.\n- Trajectory $2$: $\\mathbf{x}_0 = (0.15, 0.28, 0.22, 0.20, 0.15)$, $\\mathbf{w} = (0.10, 0.40, 0.20, 0.10, 0.20)$.\n- Trajectory $3$: $\\mathbf{x}_0 = (0.22, 0.18, 0.26, 0.18, 0.16)$, $\\mathbf{w} = (0.05, 0.35, 0.25, 0.05, 0.30)$.\n\nPhase-to-index mapping:\n- $\\mathrm{FCC} \\mapsto 1$,\n- $\\mathrm{BCC} \\mapsto 2$,\n- $\\Sigma \\mapsto 3$.\n\nYour task:\n- Implement the above definitions to compute, for each trajectory, the integer primary phase index at $t = 0$ and the persistence fraction $f$ rounded to three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[p_1, f_1, p_2, f_2, p_3, f_3]$, where $p_i$ is the primary phase index for trajectory $i$ and $f_i$ is the corresponding persistence fraction rounded to three decimal places.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of solidification thermodynamics, mathematically well-posed with all necessary definitions and data, and objectively formulated.\n\nThe task is to model phase selection during the solidification of a quinary High-Entropy Alloy (HEA). The model combines a thermodynamic criterion for primary phase selection with a simplified model for the evolution of liquid composition due to microsegregation. We are asked to compute the primary phase that nucleates at the onset of solidification and its persistence fraction along a simulated solidification path for three different alloy compositions and segregation conditions.\n\nThe core principle for phase selection at a given composition $\\mathbf{x} = (x_A, x_B, x_C, x_D, x_E)$ is that the phase with the highest equilibrium liquidus temperature, $T_\\mathrm{L}$, is the one that will form from the liquid. We are given hypothetical liquidus temperature surfaces for three competing phases: Face-Centered Cubic (FCC), Body-Centered Cubic (BCC), and the $\\Sigma$ phase. These are given by the following functions, where temperatures are in Kelvin:\n$$\nT^{\\mathrm{FCC}}_\\mathrm{L}(\\mathbf{x}) = 1800 + 300 x_A + 100 x_B + 50 x_C - 80 x_D - 120 x_E + 200 x_A x_B + 150 x_C x_D - 100 x_B x_E\n$$\n$$\nT^{\\mathrm{BCC}}_\\mathrm{L}(\\mathbf{x}) = 1750 + 500 x_B + 250 x_D - 50 x_A - 80 x_C + 180 x_B x_D + 120 x_A x_E - 90 x_C x_E\n$$\n$$\nT^{\\Sigma}_\\mathrm{L}(\\mathbf{x}) = 1700 + 600 x_C + 300 x_E - 100 x_B - 50 x_D + 200 x_C x_E - 150 x_A x_C + 100 x_B x_C\n$$\nThe primary phase at the beginning of solidification (at nominal composition $\\mathbf{x}_0$) is thus the phase $\\phi$ that maximizes $T^{\\phi}_\\mathrm{L}(\\mathbf{x}_0)$. The problem maps these phases to integer indices: $\\mathrm{FCC} \\mapsto 1$, $\\mathrm{BCC} \\mapsto 2$, $\\Sigma \\mapsto 3$. Ties are broken by selecting the phase with the lowest index.\n\nAs solidification progresses, the composition of the remaining liquid changes due to microsegregation. The model for this compositional trajectory is based on Scheil-like logic, where elements with a partition coefficient $k_i  1$ are rejected from the solid and enrich the liquid. The partition coefficients for the five elements are given as the vector $\\mathbf{k} = (0.90, 0.70, 0.60, 0.95, 0.50)$. The evolution of the liquid composition is modeled as a normalized path dependent on a parameter $t \\in [0,1]$. Given a nominal starting composition $\\mathbf{x}_0$ and a trajectory weighting vector $\\mathbf{w}$, the unnormalized composition path $\\tilde{\\mathbf{x}}(t)$ is defined as:\n$$\n\\tilde{\\mathbf{x}}(t) = \\mathbf{x}_0 + \\alpha \\, t \\, \\left[(\\mathbf{1} - \\mathbf{k}) \\odot \\mathbf{w}\\right]\n$$\nwhere $\\alpha=0.30$ is a scalar step size, $\\mathbf{1}$ is a vector of ones, and $\\odot$ represents element-wise multiplication. The term $(\\mathbf{1} - \\mathbf{k})$ quantifies the extent to which each element is rejected into the liquid. To ensure the compositions sum to unity, the path is normalized at each step $t$:\n$$\n\\mathbf{x}(t) = \\frac{\\tilde{\\mathbf{x}}(t)}{\\sum_{i} \\tilde{x}_i(t)}\n$$\n\nTo analyze the phase selection along this path, we discretize the parameter $t$ into $N=501$ uniformly spaced points from $t=0$ to $t=1$. For each point on this discretized path, we calculate the liquidus temperatures for all three phases using the composition $\\mathbf{x}(t)$ and determine the \"favored\" phase as the one with the highest $T_\\mathrm{L}$.\n\nThe primary phase is determined at $t=0$ (i.e., at $\\mathbf{x}_0$). The persistence fraction, $f$, is a measure of how stable this primary phase is against constitutional changes in the liquid. It is defined as the fraction of points along the discretized path where the favored phase is the same as the initial primary phase.\n\nThe algorithm to be implemented for each test case is as follows:\n1.  Define the constants $\\mathbf{k}$, $\\alpha$, and $N$.\n2.  For a given test case $(\\mathbf{x}_0, \\mathbf{w})$:\n3.  Compute the liquidus temperatures $T^{\\mathrm{FCC}}_\\mathrm{L}(\\mathbf{x}_0)$, $T^{\\mathrm{BCC}}_\\mathrm{L}(\\mathbf{x}_0)$, and $T^{\\Sigma}_\\mathrm{L}(\\mathbf{x}_0)$.\n4.  Determine the primary phase index, $p$, by finding the phase with the maximum temperature at $\\mathbf{x}_0$.\n5.  Generate the compositional trajectory $\\mathbf{x}(t)$ for $N=501$ discrete values of $t \\in [0,1]$. This is done efficiently using vectorization.\n6.  For each of the $N$ composition vectors in the trajectory, calculate the three liquidus temperatures.\n7.  For each of the $N$ points, determine the favored phase index by finding the phase with the maximum temperature. This results in a vector of favored phase indices.\n8.  Count the number of instances where the favored phase index matches the primary phase index $p$.\n9.  Calculate the persistence fraction $f$ by dividing this count by $N$.\n10. Round the resulting fraction $f$ to three decimal places.\n11. Collate the results $(p, f)$ for all three trajectories into a single list as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the HEA phase selection problem by implementing the specified\n    thermodynamic and microsegregation models.\n    \"\"\"\n\n    # --- Define constants and model parameters ---\n    # Partition coefficients vector\n    K = np.array([0.90, 0.70, 0.60, 0.95, 0.50])\n    # Scalar step size for trajectory\n    ALPHA = 0.30\n    # Number of discretization points for the trajectory parameter t\n    N = 501\n\n    # --- Define liquidus temperature functions ---\n    # These functions are vectorized to accept an (M, 5) array of compositions\n    # and return an (M,) array of temperatures.\n    def T_L_FCC(x):\n        T = (1800.0 +\n             300.0 * x[:, 0] + 100.0 * x[:, 1] + 50.0 * x[:, 2] - 80.0 * x[:, 3] - 120.0 * x[:, 4] +\n             200.0 * x[:, 0] * x[:, 1] + 150.0 * x[:, 2] * x[:, 3] - 100.0 * x[:, 1] * x[:, 4])\n        return T\n\n    def T_L_BCC(x):\n        T = (1750.0 +\n             500.0 * x[:, 1] + 250.0 * x[:, 3] - 50.0 * x[:, 0] - 80.0 * x[:, 2] +\n             180.0 * x[:, 1] * x[:, 3] + 120.0 * x[:, 0] * x[:, 4] - 90.0 * x[:, 2] * x[:, 4])\n        return T\n\n    def T_L_Sigma(x):\n        T = (1700.0 +\n             600.0 * x[:, 2] + 300.0 * x[:, 4] - 100.0 * x[:, 1] - 50.0 * x[:, 3] +\n             200.0 * x[:, 2] * x[:, 4] - 150.0 * x[:, 0] * x[:, 2] + 100.0 * x[:, 1] * x[:, 2])\n        return T\n\n    # --- Define the test cases from the problem statement ---\n    test_cases = [\n        {\n            'x0': np.array([0.20, 0.20, 0.20, 0.20, 0.20]),\n            'w': np.array([0.20, 0.20, 0.20, 0.20, 0.20])\n        },\n        {\n            'x0': np.array([0.15, 0.28, 0.22, 0.20, 0.15]),\n            'w': np.array([0.10, 0.40, 0.20, 0.10, 0.20])\n        },\n        {\n            'x0': np.array([0.22, 0.18, 0.26, 0.18, 0.16]),\n            'w': np.array([0.05, 0.35, 0.25, 0.05, 0.30])\n        }\n    ]\n\n    results = []\n    \n    # --- Main loop to process each trajectory ---\n    for case in test_cases:\n        x0 = case['x0']\n        w = case['w']\n\n        # 1. Generate the compositional trajectory\n        # Create a vector for the parameter t from 0 to 1\n        t_vec = np.linspace(0, 1, N)\n        \n        # Calculate the direction of the segregation path\n        path_direction = (np.ones(5) - K) * w\n        \n        # Compute the unnormalized trajectory using broadcasting\n        # t_vec[:, np.newaxis] has shape (N, 1), path_direction has shape (5,)\n        # x0 has shape (5,). The result xtilde_traj has shape (N, 5).\n        xtilde_traj = x0 + ALPHA * t_vec[:, np.newaxis] * path_direction\n        \n        # Normalize the compositions at each point in the trajectory\n        xtilde_sums = xtilde_traj.sum(axis=1)\n        x_traj = xtilde_traj / xtilde_sums[:, np.newaxis]\n\n        # 2. Calculate liquidus temperatures along the trajectory\n        T_fcc_traj = T_L_FCC(x_traj)\n        T_bcc_traj = T_L_BCC(x_traj)\n        T_sigma_traj = T_L_Sigma(x_traj)\n        \n        # 3. Determine the favored phase at each point along the trajectory\n        # Stack temperatures into an (N, 3) array for comparison\n        all_temps = np.stack([T_fcc_traj, T_bcc_traj, T_sigma_traj], axis=1)\n        # np.argmax finds the index of the maximum value along axis 1.\n        # This handles the tie-breaking rule (lowest index chosen first).\n        # We add 1 to map indices [0, 1, 2] to phase IDs [1, 2, 3].\n        favored_phases = np.argmax(all_temps, axis=1) + 1\n        \n        # 4. Determine the primary phase at t=0\n        primary_phase_index = favored_phases[0]\n        \n        # 5. Calculate the persistence fraction\n        # Count how many points in the trajectory favor the primary phase\n        persistence_count = np.sum(favored_phases == primary_phase_index)\n        # Calculate the fraction\n        persistence_fraction = persistence_count / N\n        \n        # 6. Append the results for this trajectory to the main list\n        results.append(primary_phase_index)\n        results.append(round(persistence_fraction, 3))\n        \n    # --- Final print statement in the exact required format ---\n    # The map(str, ...) converts each number in the list to its string representation.\n    # ','.join(...) concatenates these strings with a comma separator.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}