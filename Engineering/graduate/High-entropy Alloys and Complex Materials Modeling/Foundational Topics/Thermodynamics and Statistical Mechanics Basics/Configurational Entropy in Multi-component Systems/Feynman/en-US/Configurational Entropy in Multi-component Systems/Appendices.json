{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we will derive the cornerstone formula for ideal configurational entropy from first principles. This exercise  grounds our understanding in statistical mechanics, starting with the Boltzmann relation and applying Stirling's approximation to model a multi-component alloy. By comparing an equimolar system with a skewed composition, you will gain direct insight into how composition dictates the entropic stabilization that is central to the formation of high-entropy alloys.",
            "id": "3734841",
            "problem": "A High-Entropy Alloy (HEA) is modeled as a substitutional random solid solution with $k$ distinct chemical species occupying $N$ equivalent lattice sites. The composition is specified by mole fractions $\\{x_1, x_2, \\dots, x_k\\}$, with $\\sum_{i=1}^{k} x_i = 1$. Starting only from the Boltzmann relation for entropy, $S = k_B \\ln \\Omega$, where $\\Omega$ is the number of microscopic configurations consistent with the macroscopic composition, and the Stirling approximation for large integers, $\\ln(n!) \\approx n \\ln n - n$, derive the ideal configurational entropy per mole, $S_{\\text{ideal}}$, for a multicomponent substitutional solution at fixed $\\{x_i\\}$.\n\nThen, for $k = 8$, evaluate $S_{\\text{ideal}}$ for the following two compositions:\n- Equimolar: $x_i = \\frac{1}{8}$ for all $i = 1, \\dots, 8$.\n- Skewed: $x_1 = 0.4$ and $x_i = \\frac{1 - 0.4}{7}$ for $i = 2, \\dots, 8$.\n\nUse the molar gas constant $R = N_A k_B$, with $R = 8.314462618\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$. Express the final entropies in $\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$ using the natural logarithm, and round your numerical answers to four significant figures. Provide your final answer as the ordered pair $\\left(S_{\\text{ideal}}^{\\text{(equimolar)}},\\; S_{\\text{ideal}}^{\\text{(skewed)}}\\right)$.",
            "solution": "The problem statement is evaluated to be valid as it is scientifically grounded, well-posed, objective, and self-contained. It presents a standard problem in statistical thermodynamics applied to materials science, providing all necessary information for a unique and meaningful solution.\n\nThe objective is to derive the ideal configurational entropy per mole for a multicomponent system and then apply the resulting formula to two specific compositions.\n\nThe system consists of $N$ equivalent lattice sites occupied by atoms of $k$ distinct chemical species. The composition is defined by the mole fractions $\\{x_1, x_2, \\dots, x_k\\}$, where $\\sum_{i=1}^{k} x_i = 1$. The number of atoms of species $i$ is $N_i = x_i N$, such that the total number of atoms is $\\sum_{i=1}^{k} N_i = \\sum_{i=1}^{k} x_i N = N \\sum_{i=1}^{k} x_i = N$.\n\nThe derivation begins with the Boltzmann relation for entropy, $S = k_B \\ln \\Omega$, where $k_B$ is the Boltzmann constant and $\\Omega$ is the number of distinct microscopic configurations (microstates) corresponding to the macroscopic state. For a random substitutional solid solution, $\\Omega$ is the number of ways to arrange the $N_1$ atoms of species $1$, $N_2$ atoms of species $2$, ..., and $N_k$ atoms of species $k$ on the $N$ available lattice sites. This is given by the multinomial coefficient:\n$$\n\\Omega = \\frac{N!}{N_1! N_2! \\cdots N_k!} = \\frac{N!}{\\prod_{i=1}^{k} N_i!}\n$$\nSubstituting this into the Boltzmann relation gives:\n$$\nS = k_B \\ln \\left( \\frac{N!}{\\prod_{i=1}^{k} N_i!} \\right)\n$$\nUsing the properties of the logarithm, we can write:\n$$\nS = k_B \\left( \\ln(N!) - \\ln\\left(\\prod_{i=1}^{k} N_i!\\right) \\right) = k_B \\left( \\ln(N!) - \\sum_{i=1}^{k} \\ln(N_i!) \\right)\n$$\nFor a macroscopic system, $N$ and all $N_i$ are very large numbers. Therefore, we can apply the Stirling approximation, $\\ln(n!) \\approx n \\ln n - n$, to each factorial term:\n$$\n\\ln(N!) \\approx N \\ln N - N\n$$\n$$\n\\ln(N_i!) \\approx N_i \\ln N_i - N_i\n$$\nSubstituting these approximations into the expression for $S$:\n$$\nS \\approx k_B \\left[ (N \\ln N - N) - \\sum_{i=1}^{k} (N_i \\ln N_i - N_i) \\right]\n$$\n$$\nS \\approx k_B \\left[ N \\ln N - N - \\sum_{i=1}^{k} N_i \\ln N_i + \\sum_{i=1}^{k} N_i \\right]\n$$\nSince $\\sum_{i=1}^{k} N_i = N$, the terms $-N$ and $+\\sum_{i=1}^{k} N_i$ cancel each other out:\n$$\nS \\approx k_B \\left[ N \\ln N - \\sum_{i=1}^{k} N_i \\ln N_i \\right]\n$$\nNow, we substitute $N_i = x_i N$:\n$$\nS \\approx k_B \\left[ N \\ln N - \\sum_{i=1}^{k} (x_i N) \\ln(x_i N) \\right]\n$$\nUsing the logarithm property $\\ln(a b) = \\ln a + \\ln b$:\n$$\nS \\approx k_B \\left[ N \\ln N - \\sum_{i=1}^{k} (x_i N) (\\ln x_i + \\ln N) \\right]\n$$\n$$\nS \\approx k_B \\left[ N \\ln N - \\sum_{i=1}^{k} x_i N \\ln x_i - \\sum_{i=1}^{k} x_i N \\ln N \\right]\n$$\nWe can factor out $N$ and $N \\ln N$ from the sums:\n$$\nS \\approx k_B \\left[ N \\ln N - N \\sum_{i=1}^{k} x_i \\ln x_i - N \\ln N \\sum_{i=1}^{k} x_i \\right]\n$$\nUsing the constraint $\\sum_{i=1}^{k} x_i = 1$:\n$$\nS \\approx k_B \\left[ N \\ln N - N \\sum_{i=1}^{k} x_i \\ln x_i - N \\ln N \\cdot (1) \\right]\n$$\nThe terms $N \\ln N$ and $-N \\ln N$ cancel, yielding the total configurational entropy for $N$ atoms:\n$$\nS = -N k_B \\sum_{i=1}^{k} x_i \\ln x_i\n$$\nTo find the ideal configurational entropy per mole, $S_{\\text{ideal}}$, we consider a system containing one mole of atoms, so $N = N_A$, where $N_A$ is Avogadro's number. Using the definition of the molar gas constant, $R = N_A k_B$, we obtain the final expression:\n$$\nS_{\\text{ideal}} = -R \\sum_{i=1}^{k} x_i \\ln x_i\n$$\nThis is the required formula for the ideal configurational entropy per mole.\n\nNow, we evaluate $S_{\\text{ideal}}$ for the two given cases with $k=8$ and $R = 8.314462618\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$.\n\nCase 1: Equimolar composition\nThe composition is $x_i = \\frac{1}{8}$ for all $i = 1, \\dots, 8$.\n$$\nS_{\\text{ideal}}^{\\text{(equimolar)}} = -R \\sum_{i=1}^{8} x_i \\ln x_i = -R \\sum_{i=1}^{8} \\frac{1}{8} \\ln\\left(\\frac{1}{8}\\right)\n$$\nSince all terms in the summation are identical, we have:\n$$\nS_{\\text{ideal}}^{\\text{(equimolar)}} = -R \\cdot 8 \\cdot \\left(\\frac{1}{8} \\ln\\left(\\frac{1}{8}\\right)\\right) = -R \\ln\\left(\\frac{1}{8}\\right) = R \\ln(8)\n$$\nSubstituting the value of $R$:\n$$\nS_{\\text{ideal}}^{\\text{(equimolar)}} = (8.314462618\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}) \\cdot \\ln(8) \\approx 17.29177\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}\n$$\nRounding to four significant figures, we get $S_{\\text{ideal}}^{\\text{(equimolar)}} = 17.29\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$.\n\nCase 2: Skewed composition\nThe composition is $x_1 = 0.4$ and $x_i = \\frac{1 - 0.4}{7} = \\frac{0.6}{7}$ for $i = 2, \\dots, 8$.\nThe sum is split into two parts: one term for $x_1$ and seven identical terms for $x_2, \\dots, x_8$.\n$$\nS_{\\text{ideal}}^{\\text{(skewed)}} = -R \\left[ x_1 \\ln x_1 + \\sum_{i=2}^{8} x_i \\ln x_i \\right]\n$$\n$$\nS_{\\text{ideal}}^{\\text{(skewed)}} = -R \\left[ 0.4 \\ln(0.4) + 7 \\cdot \\left(\\frac{0.6}{7}\\right) \\ln\\left(\\frac{0.6}{7}\\right) \\right]\n$$\n$$\nS_{\\text{ideal}}^{\\text{(skewed)}} = -R \\left[ 0.4 \\ln(0.4) + 0.6 \\ln\\left(\\frac{0.6}{7}\\right) \\right]\n$$\nSubstituting the value of $R$:\n$$\nS_{\\text{ideal}}^{\\text{(skewed)}} = -(8.314462618\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}) \\left[ 0.4 \\ln(0.4) + 0.6 \\ln\\left(\\frac{0.6}{7}\\right) \\right]\n$$\nCalculating the terms inside the brackets:\n$0.4 \\ln(0.4) \\approx 0.4 \\times (-0.91629) \\approx -0.366516$\n$0.6 \\ln(\\frac{0.6}{7}) \\approx 0.6 \\times \\ln(0.085714) \\approx 0.6 \\times (-2.45666) \\approx -1.473996$\nSumming them: $-0.366516 - 1.473996 \\approx -1.840512$.\n$$\nS_{\\text{ideal}}^{\\text{(skewed)}} \\approx -(8.314462618\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}) \\times (-1.840512) \\approx 15.30132\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}\n$$\nRounding to four significant figures, we get $S_{\\text{ideal}}^{\\text{(skewed)}} = 15.30\\,\\text{J}\\,\\text{mol}^{-1}\\,\\text{K}^{-1}$.\n\nThe final answer is the ordered pair $\\left(S_{\\text{ideal}}^{\\text{(equimolar)}},\\; S_{\\text{ideal}}^{\\text{(skewed)}}\\right)$ with values rounded to four significant figures.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n17.29  15.30\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While the ideal entropy formula is powerful, it assumes an infinitely large system. This practice  delves deeper by exploring the consequences of finite system size, a critical consideration in computational materials science. By deriving and applying the leading finite-size correction to the entropy density, you will learn how to refine thermodynamic calculations and better understand the behavior of nanoscale systems or computational models where boundary effects and statistical fluctuations become significant.",
            "id": "3734844",
            "problem": "A substitutional binary alloy of species $A$ and $B$ occupies a rigid lattice with $N=10^{5}$ distinguishable sites. The composition is fixed at $x_{A}=0.01$ and $x_{B}=1-x_{A}$. Assume ideal random mixing without energetic interactions, and that the only constraint is the fixed composition (no vacancies or interstitials). Starting from the microcanonical definition of entropy $S=k_{B}\\ln\\Omega$, where $k_{B}$ is the Boltzmann constant and $\\Omega$ is the number of distinct configurations consistent with the composition constraint, and using the exact combinatorial count of configurations for $N_{A}=x_{A}N$ atoms of $A$ and $N_{B}=x_{B}N$ atoms of $B$, derive the configurational entropy density $s=S/N$ in the thermodynamic limit and quantify the leading finite-size correction due to finite $N$ and small $x_{A}$. Evaluate the corrected entropy density $s_{\\text{corr}}/k_{B}$ for $N=10^{5}$ and $x_{A}=0.01$.\n\nYour derivation must begin from the definitions above, use asymptotic expansions appropriate for large factorials, and show how composition enters the entropy density. In your analysis, briefly explain how finite composition at small $x_{A}$ affects the entropy density and the sign of the finite-size correction. Report the final numerical value of the corrected entropy density $s_{\\text{corr}}/k_{B}$ as a dimensionless number, and round your answer to six significant figures.",
            "solution": "The problem is valid as it is a standard, well-posed problem in statistical mechanics that is scientifically grounded, objective, and internally consistent.\n\nThe system is a substitutional binary alloy on a lattice of $N$ sites with $N_A$ atoms of species $A$ and $N_B$ atoms of species $B$. The total number of sites is $N = N_A + N_B$. The composition is given by the mole fractions $x_A = N_A/N$ and $x_B = N_B/N = 1-x_A$.\n\nThe number of distinct configurations $\\Omega$ for arranging $N_A$ atoms of type $A$ on $N$ sites is given by the binomial coefficient:\n$$\n\\Omega = \\binom{N}{N_A} = \\frac{N!}{N_A! N_B!}\n$$\nThe microcanonical entropy $S$ is defined as $S = k_B \\ln \\Omega$, where $k_B$ is the Boltzmann constant.\n$$\nS = k_B \\ln\\left(\\frac{N!}{N_A! N_B!}\\right) = k_B (\\ln N! - \\ln N_A! - \\ln N_B!)\n$$\nTo evaluate this for large numbers of atoms, we use an asymptotic expansion for the factorial, commonly known as Stirling's approximation. To find the finite-size correction, we must use a form more accurate than the leading-order approximation. We use:\n$$\n\\ln n! \\approx n \\ln n - n + \\frac{1}{2}\\ln(2\\pi n) + O(1/n)\n$$\nSubstituting this into the expression for entropy:\n$$\n\\frac{S}{k_B} \\approx \\left(N \\ln N - N + \\frac{1}{2}\\ln(2\\pi N)\\right) - \\left(N_A \\ln N_A - N_A + \\frac{1}{2}\\ln(2\\pi N_A)\\right) - \\left(N_B \\ln N_B - N_B + \\frac{1}{2}\\ln(2\\pi N_B)\\right)\n$$\nWe group the terms. The terms linear in particle number are:\n$$\n(N \\ln N - N) - (N_A \\ln N_A - N_A) - (N_B \\ln N_B - N_B)\n$$\nSince $N = N_A + N_B$, the linear terms $-N$, $-(-N_A)$, and $-(-N_B)$ cancel out. We are left with:\n$$\nN \\ln N - N_A \\ln N_A - N_B \\ln N_B\n$$\nSubstituting $N_A = x_A N$ and $N_B = x_B N = (1-x_A)N$:\n$$\nN \\ln N - (x_A N) \\ln(x_A N) - (x_B N) \\ln(x_B N)\n$$\n$$\n= N \\ln N - x_A N (\\ln x_A + \\ln N) - x_B N (\\ln x_B + \\ln N)\n$$\n$$\n= N (\\ln N - x_A \\ln N - x_B \\ln N) - N(x_A \\ln x_A + x_B \\ln x_B)\n$$\nSince $x_A + x_B = 1$, the first parenthesis becomes $\\ln N - (x_A+x_B)\\ln N = \\ln N - \\ln N = 0$. This leaves the leading contribution to the entropy:\n$$\nS_{\\text{thermo}} = -k_B N (x_A \\ln x_A + x_B \\ln x_B)\n$$\nIn the thermodynamic limit ($N \\to \\infty$), the entropy density $s = S/N$ is:\n$$\ns = \\frac{S_{\\text{thermo}}}{N} = -k_B (x_A \\ln x_A + x_B \\ln x_B)\n$$\nNow, we analyze the correction terms from the Stirling expansion, which we denote as $\\Delta S$:\n$$\n\\frac{\\Delta S}{k_B} = \\frac{1}{2}\\ln(2\\pi N) - \\frac{1}{2}\\ln(2\\pi N_A) - \\frac{1}{2}\\ln(2\\pi N_B)\n$$\n$$\n= \\frac{1}{2} [\\ln(2\\pi N) - \\ln(2\\pi N_A) - \\ln(2\\pi N_B)]\n$$\n$$\n= \\frac{1}{2} \\ln\\left(\\frac{2\\pi N}{(2\\pi N_A)(2\\pi N_B)}\\right) = \\frac{1}{2} \\ln\\left(\\frac{N}{2\\pi N_A N_B}\\right)\n$$\nSubstituting $N_A = x_A N$ and $N_B = x_B N$:\n$$\n\\frac{\\Delta S}{k_B} = \\frac{1}{2} \\ln\\left(\\frac{N}{2\\pi (x_A N)(x_B N)}\\right) = \\frac{1}{2} \\ln\\left(\\frac{1}{2\\pi N x_A x_B}\\right) = -\\frac{1}{2} \\ln(2\\pi N x_A x_B)\n$$\nThe total corrected entropy is $S_{\\text{corr}} = S_{\\text{thermo}} + \\Delta S$. The corrected entropy density $s_{\\text{corr}} = S_{\\text{corr}}/N$ is:\n$$\ns_{\\text{corr}} = s + \\frac{\\Delta S}{N} = -k_B (x_A \\ln x_A + x_B \\ln x_B) - \\frac{k_B}{2N} \\ln(2\\pi N x_A x_B)\n$$\nThe dimensionless corrected entropy density is:\n$$\n\\frac{s_{\\text{corr}}}{k_B} = -(x_A \\ln x_A + x_B \\ln x_B) - \\frac{1}{2N} \\ln(2\\pi N x_A (1-x_A))\n$$\nThe finite-size correction term is $\\Delta s/k_B = -\\frac{1}{2N}\\ln(2\\pi N x_A(1-x_A))$. Its sign is determined by the argument of the logarithm. The use of this correction is valid when the argument of the square root in the Gaussian approximation of the binomial coefficient is large, i.e., $2\\pi N x_A(1-x_A) \\gg 1$. Given $N=10^5$ and $x_A=0.01$, the argument is $2\\pi(10^5)(0.01)(0.99) = 1980\\pi \\approx 6220$, which is much greater than $1$. Therefore, its logarithm is positive. The entire correction term $\\Delta s$ is thus negative. This negative sign indicates that the entropy of a finite system is lower than the value predicted by the simple thermodynamic limit formula, which effectively overestimates the number of available configurations. The small value of $x_A=0.01$ places the alloy in a composition regime of low entropy, far from the maximum at $x_A=0.5$. The magnitude of the finite-size correction, which depends on $x_A(1-x_A)$, is also smaller than it would be for an equimolar composition.\n\nWe now evaluate the corrected entropy density for the given parameters: $N=10^5$ and $x_A=0.01$. Thus, $x_B = 1 - 0.01 = 0.99$.\nThe expression to evaluate is:\n$$\n\\frac{s_{\\text{corr}}}{k_B} = -[0.01 \\ln(0.01) + 0.99 \\ln(0.99)] - \\frac{1}{2 \\times 10^5} \\ln(2\\pi \\times 10^5 \\times 0.01 \\times 0.99)\n$$\nFirst, calculate the thermodynamic term:\n$$\nT_1 = -[0.01 \\ln(0.01) + 0.99 \\ln(0.99)] \\approx -[0.01 \\times (-4.605170) + 0.99 \\times (-0.010050)]\n$$\n$$\nT_1 \\approx -[-0.0460517 - 0.0099495] = 0.0560012\n$$\nNext, calculate the correction term:\n$$\nT_2 = -\\frac{1}{2 \\times 10^5} \\ln(1980\\pi) \\approx -\\frac{1}{2 \\times 10^5} \\ln(6220.353) \\approx -\\frac{8.735593}{2 \\times 10^5}\n$$\n$$\nT_2 \\approx -0.000043678\n$$\nAdding the two terms with higher precision:\n$$\nT_1 \\approx 0.0560015344\n$$\n$$\nT_2 \\approx -0.0000436780\n$$\n$$\n\\frac{s_{\\text{corr}}}{k_B} = T_1 + T_2 \\approx 0.0560015344 - 0.0000436780 = 0.0559578564\n$$\nRounding to six significant figures, we get $0.0559579$.",
            "answer": "$$\\boxed{0.0559579}$$"
        },
        {
            "introduction": "Our final practice transitions from analytical derivations for fixed compositions to a more general and powerful computational framework. Here, we model a system in equilibrium with a chemical reservoir and calculate the full probability distribution of its possible compositions . By computing the entropy directly from this distribution using the Gibbs formulation, $S = -k_B \\sum P \\ln P$, you will develop a more fundamental understanding of entropy as a measure of state-space uncertainty and gain hands-on experience with methods that are at the heart of modern statistical mechanics simulations.",
            "id": "3734828",
            "problem": "Consider a lattice model for a multi-component substitutional solid solution relevant to High-Entropy Alloys (HEA) and complex materials. The lattice has $M$ sites, and there are $K$ chemically distinct species labeled $i \\in \\{1,2,\\dots,K\\}$. Each lattice site is occupied by exactly one species, and $n_i$ denotes the number of sites occupied by species $i$, subject to the constraint $\\sum_{i=1}^K n_i = M$. The system is in contact with a reservoir characterized by chemical potentials $\\{\\mu_i\\}$ and a temperature $T$. Assume that site energies are equivalent and interactions beyond species identity are negligible, so that the only energetic driving terms are the chemical potentials.\n\nStarting from the Grand Canonical Ensemble (GCE) and elementary combinatorics of lattice occupations, derive the composition distribution $P(\\{n_i\\})$ over the allowed vectors $\\{n_i\\}$ and use it to compute the configurational entropy, defined as $S = - k_{\\mathrm{B}} \\sum_{\\{n_i\\}} P(\\{n_i\\}) \\ln P(\\{n_i\\})$, where $k_{\\mathrm{B}}$ is the Boltzmann constant. You must express the final results in units of $k_{\\mathrm{B}}$, i.e., report $S/k_{\\mathrm{B}}$ as dimensionless real numbers. Angles do not appear in this problem. No percentages are involved.\n\nYour program must:\n- Enumerate all integer compositions $\\{n_i\\}$ such that each $n_i \\ge 0$ and $\\sum_{i=1}^K n_i = M$.\n- Use the GCE weighting consistent with the fundamental principle that probabilities are proportional to the exponential of the energy divided by $k_{\\mathrm{B}} T$, together with the combinatorial multiplicity of configurations for a given composition.\n- Normalize the distribution $P(\\{n_i\\})$ exactly (to within numerical precision) over all compositions.\n- Compute $S/k_{\\mathrm{B}}$ exactly by summing $- \\sum_{\\{n_i\\}} P(\\{n_i\\}) \\ln P(\\{n_i\\})$.\n\nUse the Boltzmann constant in electronvolt per Kelvin, $k_{\\mathrm{B}} = 8.617333262145 \\times 10^{-5} \\,\\mathrm{eV/K}$, and chemical potentials $\\mu_i$ specified in electronvolt (eV). Temperature $T$ is in Kelvin (K). The parameter $M$ is dimensionless.\n\nTest Suite:\nEvaluate $S/k_{\\mathrm{B}}$ for the following cases. In all cases, $M$, $K$, $\\{\\mu_i\\}$, and $T$ are provided, with $\\mu_i$ in electronvolt and $T$ in Kelvin.\n\n- Case $1$: $M = 5$, $K = 3$, $\\{\\mu_i\\} = \\{0.2, 0.0, -0.1\\}$, $T = 1000$.\n- Case $2$: $M = 4$, $K = 3$, $\\{\\mu_i\\} = \\{0.0, 0.0, 0.0\\}$, $T = 1000$.\n- Case $3$: $M = 6$, $K = 3$, $\\{\\mu_i\\} = \\{1.0, -1.0, -1.0\\}$, $T = 300$.\n- Case $4$: $M = 1$, $K = 4$, $\\{\\mu_i\\} = \\{0.0, 0.0, 0.0, 0.0\\}$, $T = 500$.\n- Case $5$: $M = 7$, $K = 5$, $\\{\\mu_i\\} = \\{-0.05, 0.1, 0.0, 0.2, -0.15\\}$, $T = 1200$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases listed above. For example, the output should look like $[s_1,s_2,s_3,s_4,s_5]$, where each $s_j$ is the computed $S/k_{\\mathrm{B}}$ for Case $j$ as a floating-point number.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of statistical mechanics as applied to materials science, specifically using a lattice model for a multi-component alloy. The problem is well-posed, with all necessary parameters and definitions provided for a unique and meaningful solution. The methodology is clearly specified, and the test cases are computationally feasible.\n\nThe task is to compute the configurational entropy of the distribution of compositions in a multi-component system. This quantity is explicitly defined as $S = - k_{\\mathrm{B}} \\sum_{\\{n_i\\}} P(\\{n_i\\}) \\ln P(\\{n_i\\})$, where $P(\\{n_i\\})$ is the probability of finding the system in a state with a specific composition vector $\\{n_i\\} = (n_1, n_2, \\dots, n_K)$. The system consists of $M$ lattice sites occupied by $K$ species, with the total number of sites being fixed, $\\sum_{i=1}^K n_i = M$. The system's energetics are governed by the chemical potentials $\\{\\mu_i\\}$ and temperature $T$.\n\nFirst, we derive the probability distribution $P(\\{n_i\\})$. The problem directs us to use the Grand Canonical Ensemble (GCE) framework. However, the total number of particles (or sites) $M$ is fixed. This configuration corresponds to a semi-grand canonical ensemble, where particle types can be exchanged with a reservoir, but the total number of particles is conserved.\n\nThe Hamiltonian of the system is taken to be zero, as site energies are equivalent and there are no interactions. In the presence of a chemical potential reservoir, the effective Hamiltonian is $H' = H - \\sum_{i=1}^K \\mu_i N_i = - \\sum_{i=1}^K \\mu_i N_i$, where $N_i$ is the number operator for species $i$.\n\nThe partition function $Z$ is the sum over all possible microscopic configurations of the lattice. A microstate is a specific assignment of a species $s_j \\in \\{1, \\dots, K\\}$ to each site $j \\in \\{1, \\dots, M\\}$.\n$$ Z = \\sum_{\\text{microstates}} \\exp\\left( - \\frac{H'}{k_{\\mathrm{B}} T} \\right) = \\sum_{s_1=1}^K \\dots \\sum_{s_M=1}^K \\exp\\left( \\frac{\\sum_{j=1}^M \\mu_{s_j}}{k_{\\mathrm{B}} T} \\right) $$\nSince the sites are independent, we can separate the sums:\n$$ Z = \\prod_{j=1}^M \\left( \\sum_{s_j=1}^K \\exp\\left( \\frac{\\mu_{s_j}}{k_{\\mathrm{B}} T} \\right) \\right) = \\left( \\sum_{i=1}^K \\exp\\left( \\frac{\\mu_i}{k_{\\mathrm{B}} T} \\right) \\right)^M $$\nLet's define a single-site partition function $z = \\sum_{i=1}^K \\exp\\left(\\frac{\\mu_i}{k_{\\mathrm{B}} T}\\right)$. Then $Z = z^M$.\nLet $p_i$ be the probability that a given site is occupied by species $i$. This is given by the Boltzmann weight for that species divided by the single-site partition function:\n$$ p_i = \\frac{\\exp\\left(\\frac{\\mu_i}{k_{\\mathrm{B}} T}\\right)}{z} = \\frac{\\exp\\left(\\frac{\\mu_i}{k_{\\mathrm{B}} T}\\right)}{\\sum_{k=1}^K \\exp\\left(\\frac{\\mu_k}{k_{\\mathrm{B}} T}\\right)} $$\nNote that $\\sum_{i=1}^K p_i = 1$. The probability of a specific microstate with composition $\\{n_i\\}$ (i.e., $n_1$ particles of species $1$, $n_2$ of species $2$, etc.) is the product of the probabilities for each site, since the sites are independent: $\\prod_{i=1}^K p_i^{n_i}$.\n\nThe problem asks for the probability of the composition $\\{n_i\\}$ itself, which is a macrostate. To find this, we must multiply the probability of one microstate with that composition by the number of ways to arrange the particles on the lattice to achieve that composition. This combinatorial factor is the multinomial coefficient, $\\Omega(\\{n_i\\}) = \\frac{M!}{n_1! n_2! \\dots n_K!}$.\nThus, the probability distribution of the compositions is the multinomial distribution:\n$$ P(\\{n_i\\}) = \\frac{M!}{\\prod_{i=1}^K n_i!} \\prod_{i=1}^K p_i^{n_i} $$\nwhere $\\{n_i\\}$ is any vector of non-negative integers such that $\\sum_{i=1}^K n_i = M$.\n\nThe final step is to compute the configurational entropy as defined in the problem, $S/k_{\\mathrm{B}} = - \\sum_{\\{n_i\\}} P(\\{n_i\\}) \\ln P(\\{n_i\\})$. The summation is over all possible composition vectors $\\{n_i\\}$.\n\nThe algorithm for the computation is as follows:\n1.  For each test case, define the parameters $M$, $K$, $\\{\\mu_i\\}$, and $T$, and the value of $k_{\\mathrm{B}}$.\n2.  Generate all unique integer compositions $\\{n_i\\}$ such that $n_i \\ge 0$ and $\\sum_{i=1}^K n_i = M$. A recursive function is well-suited for this combinatorial enumeration.\n3.  Calculate the single-site probabilities $\\{p_i\\}$. To ensure numerical stability, we can define a shifted set of chemical potentials $\\mu'_i = \\mu_i - \\max(\\{\\mu_k\\})$. The probabilities $p_i$ are invariant under this shift:\n    $$ p_i = \\frac{\\exp\\left(\\frac{\\mu'_i}{k_{\\mathrm{B}} T}\\right)}{\\sum_{k=1}^K \\exp\\left(\\frac{\\mu'_k}{k_{\\mathrm{B}} T}\\right)} $$\n    This prevents floating-point overflow when calculating the exponentials.\n4.  For each composition $\\{n_i\\}$, calculate its probability $P(\\{n_i\\})$. To avoid both overflow with the factorials and underflow with the probability products, it is best to compute the logarithm of the probability first:\n    $$ \\ln P(\\{n_i\\}) = \\ln(M!) - \\sum_{i=1}^K \\ln(n_i!) + \\sum_{i=1}^K n_i \\ln(p_i) $$\n    The log-factorial term, $\\ln(n!)$, is accurately computed using the log-gamma function, $\\ln(n!) = \\text{gammaln}(n+1)$. From $\\ln P(\\{n_i\\})$, we can find $P(\\{n_i\\}) = \\exp(\\ln P(\\{n_i\\}))$.\n5.  Iterate through all compositions, and for each, calculate the term $-P(\\{n_i\\}) \\ln(P(\\{n_i\\}))$ and add it to a running sum. A check for $P(\\{n_i\\})  0$ is necessary, as computationally $P \\ln P \\to 0$ as $P \\to 0$.\n6.  The final sum is the desired value of $S/k_{\\mathrm{B}}$.\nThis procedure is exact and robust for the given range of parameters.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    k_B = 8.617333262145e-5  # Boltzmann constant in eV/K\n\n    test_cases = [\n        # Case 1: M = 5, K = 3, {mu_i} = {0.2, 0.0, -0.1}, T = 1000\n        {'M': 5, 'K': 3, 'mu': [0.2, 0.0, -0.1], 'T': 1000},\n        # Case 2: M = 4, K = 3, {mu_i} = {0.0, 0.0, 0.0}, T = 1000\n        {'M': 4, 'K': 3, 'mu': [0.0, 0.0, 0.0], 'T': 1000},\n        # Case 3: M = 6, K = 3, {mu_i} = {1.0, -1.0, -1.0}, T = 300\n        {'M': 6, 'K': 3, 'mu': [1.0, -1.0, -1.0], 'T': 300},\n        # Case 4: M = 1, K = 4, {mu_i} = {0.0, 0.0, 0.0, 0.0}, T = 500\n        {'M': 1, 'K': 4, 'mu': [0.0, 0.0, 0.0, 0.0], 'T': 500},\n        # Case 5: M = 7, K = 5, {mu_i} = {-0.05, 0.1, 0.0, 0.2, -0.15}, T = 1200\n        {'M': 7, 'K': 5, 'mu': [-0.05, 0.1, 0.0, 0.2, -0.15], 'T': 1200},\n    ]\n\n    def generate_compositions(m, k):\n        \"\"\"\n        Recursively generates all integer compositions of m into k parts.\n        A composition is a tuple (n_1, n_2, ..., n_k) such that sum(n_i) = m.\n        \"\"\"\n        if k == 1:\n            yield (m,)\n            return\n        for i in range(m + 1):\n            for comp in generate_compositions(m - i, k - 1):\n                yield (i,) + comp\n\n    def calculate_entropy(M, K, mu, T):\n        \"\"\"\n        Calculates the configurational entropy S/k_B for a given set of parameters.\n        \"\"\"\n        beta = 1.0 / (k_B * T)\n        mu_np = np.array(mu, dtype=np.float64)\n\n        # Numerically stable calculation of single-site probabilities p_i\n        mu_max = np.max(mu_np)\n        exp_terms = np.exp(beta * (mu_np - mu_max))\n        Z_site = np.sum(exp_terms)\n        p = exp_terms / Z_site\n        \n        # Handle cases where p_i can be zero to avoid log(0)\n        log_p = np.full_like(p, -np.inf)\n        non_zero_mask = p > 0\n        log_p[non_zero_mask] = np.log(p[non_zero_mask])\n\n        compositions = list(generate_compositions(M, K))\n        \n        total_entropy = 0.0\n        log_M_factorial = gammaln(M + 1)\n\n        for comp in compositions:\n            n = np.array(comp, dtype=np.int64)\n            \n            # Calculate log-probability of the composition\n            log_sum_n_factorial = np.sum(gammaln(n + 1))\n            log_p_terms = np.sum(n * log_p)\n            \n            log_P = log_M_factorial - log_sum_n_factorial + log_p_terms\n            \n            # Check for -inf which results from a_i * log(0) where a_i > 0\n            if log_P == -np.inf:\n                continue\n\n            P = np.exp(log_P)\n\n            # The term P * log(P) = 0 if P = 0.\n            if P > 0:\n                total_entropy -= P * log_P\n        \n        return total_entropy\n\n    results = []\n    for case in test_cases:\n        result = calculate_entropy(case['M'], case['K'], case['mu'], case['T'])\n        results.append(f\"{result:.10f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}