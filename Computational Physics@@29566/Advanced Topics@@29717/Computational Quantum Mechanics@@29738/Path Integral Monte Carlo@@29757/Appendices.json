{"hands_on_practices": [{"introduction": "Before we can confidently apply Path Integral Monte Carlo (PIMC) to complex, unsolved problems, we must first build trust in its foundations. This practice provides a crucial \"sanity check\" by applying the method to a system we can solve exactly: the quantum harmonic oscillator. By deriving both the exact quantum partition function, $Z_{\\mathrm{exact}}$, and its discretized path integral approximation, $Z_P$, we can directly observe how the approximation converges to the true result as we increase the number of \"beads,\" $P$, in our ring polymer [@problem_id:2659206]. This exercise offers a tangible feel for the nature of the Trotter approximation error, a fundamental concept you will need to manage in every PIMC simulation.", "problem": "Consider a one-dimensional quantum harmonic oscillator of mass $m$ and angular frequency $\\omega$ at inverse temperature $\\beta$. Work in reduced units where Planck’s constant divided by $2\\pi$ is set to $\\hbar = 1$ and Boltzmann’s constant is $k_{\\mathrm{B}} = 1$, so that all quantities are dimensionless. Your task is to derive, implement, and test a comparison between the exact quantum canonical partition function and its imaginary-time path integral discretization as a function of the Trotter number $P$.\n\nStart from the following fundamental bases:\n- The canonical partition function is $Z = \\mathrm{Tr}\\left[e^{-\\beta \\hat{H}}\\right]$ with Hamiltonian $\\hat{H} = \\frac{\\hat{p}^2}{2m} + \\frac{1}{2} m \\omega^2 \\hat{q}^2$.\n- The Trotter factorization and Feynman imaginary-time path integral representation express $Z$ as a limit of $P$-fold factorizations of imaginary-time evolution operators, which for finite $P$ yields a classical configuration integral over a $P$-bead ring polymer with nearest-neighbor harmonic springs and on-bead potential $V(q) = \\frac{1}{2} m \\omega^2 q^2$.\n- For a quadratic action, Gaussian integrals reduce to determinants of the quadratic form.\n\nRequirements:\n1) Derive the exact quantum partition function $Z_{\\mathrm{exact}}(\\beta,\\omega)$ for the one-dimensional harmonic oscillator in these units.\n2) From the discretized imaginary-time path integral with $P$ beads and primitive Trotter splitting, derive an explicit, computable expression $Z_P(\\beta,\\omega)$ in terms of a product over the ring-polymer normal modes for finite $P$ (this is the $P$-level Path Integral Monte Carlo (PIMC) target that true Monte Carlo sampling would estimate; here you will compute it deterministically via the equivalent Gaussian integral).\n3) For each specified test case below, compute $Z_{\\mathrm{exact}}(\\beta,\\omega)$ and $Z_P(\\beta,\\omega)$ for $P \\in \\{1,2,4,8,16,32,64\\}$. Use these to compute the absolute error $|Z_P - Z_{\\mathrm{exact}}|$ for each $P$.\n4) Quantify the convergence rate by fitting a power-law $|Z_P - Z_{\\mathrm{exact}}| \\approx C P^{-r}$ to the last four $P$ values $P \\in \\{8,16,32,64\\}$ using linear least squares on $\\log$-$\\log$ data to extract the exponent $r$.\n5) Implement the above as a complete program that produces the required outputs for the test suite.\n\nUse the following test suite of parameter sets (all dimensionless in the stated units $\\hbar = 1$, $k_{\\mathrm{B}}=1$):\n- Case $1$: $(\\beta,\\omega) = (0.5, 1.0)$.\n- Case $2$: $(\\beta,\\omega) = (1.0, 1.0)$.\n- Case $3$: $(\\beta,\\omega) = (3.0, 1.0)$.\n- Case $4$: $(\\beta,\\omega) = (1.0, 0.5)$.\n\nProgram input: None. All parameters are provided above.\n\nProgram outputs:\n- For each case, output a single float: the fitted convergence exponent $r$ from step $4$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases listed above, for example, $[r_1,r_2,r_3,r_4]$.\n- Each $r$ must be reported as a floating-point number. All outputs are unitless due to the choice $\\hbar = 1$, $k_{\\mathrm{B}}=1$.\n\nNumerical guidance and constraints:\n- For numerical stability, evaluate products for $Z_P(\\beta,\\omega)$ using logarithms of eigenmode contributions.\n- Angles used in trigonometric functions must be in radians.\n- No external input or randomness is allowed; your implementation must be deterministic and self-contained.", "solution": "The analysis will be performed in reduced units where Planck's constant divided by $2\\pi$ is $\\hbar=1$ and Boltzmann's constant is $k_{\\mathrm{B}}=1$.\n\nFirst, we derive the exact quantum canonical partition function, $Z_{\\mathrm{exact}}$. The Hamiltonian for the one-dimensional quantum harmonic oscillator is given by $\\hat{H} = \\frac{\\hat{p}^2}{2m} + \\frac{1}{2} m \\omega^2 \\hat{q}^2$. The energy eigenvalues of this system are quantized and given by $E_n = \\hbar \\omega (n + \\frac{1}{2})$, where $n$ is a non-negative integer, $n=0, 1, 2, \\ldots$. In the specified reduced units where $\\hbar=1$, the energy levels are $E_n = \\omega(n + \\frac{1}{2})$. The canonical partition function $Z$ at an inverse temperature $\\beta = 1/(k_{\\mathrm{B}}T)$ is defined as the trace of the Boltzmann operator, $Z = \\mathrm{Tr}[e^{-\\beta \\hat{H}}]$. In the energy eigenbasis, this becomes a sum over all states:\n$$Z_{\\mathrm{exact}} = \\sum_{n=0}^{\\infty} e^{-\\beta E_n} = \\sum_{n=0}^{\\infty} e^{-\\beta \\omega (n + 1/2)}$$\nWe can factor out the ground state contribution and recognize the remaining sum as a geometric series:\n$$Z_{\\mathrm{exact}} = e^{-\\beta \\omega/2} \\sum_{n=0}^{\\infty} (e^{-\\beta \\omega})^n$$\nThe geometric series $\\sum_{n=0}^{\\infty} x^n$ converges to $1/(1-x)$ for $|x|<1$. Here, $x=e^{-\\beta\\omega}$, which is always less than $1$ for positive $\\beta$ and $\\omega$. Thus, the sum evaluates to $1/(1-e^{-\\beta\\omega})$. Substituting this back, we obtain:\n$$Z_{\\mathrm{exact}} = \\frac{e^{-\\beta \\omega/2}}{1 - e^{-\\beta \\omega}} = \\frac{1}{e^{\\beta \\omega/2} - e^{-\\beta \\omega/2}}$$\nThis expression is equivalent to the hyperbolic cosecant function:\n$$Z_{\\mathrm{exact}}(\\beta, \\omega) = \\frac{1}{2\\sinh(\\beta\\omega/2)}$$\nNote that this expression is independent of the mass $m$.\n\nNext, we derive the approximate partition function, $Z_P$, from the discretized imaginary-time path integral formulation. The partition function can be expressed as an integral over closed paths in imaginary time $\\tau \\in [0, \\beta\\hbar]$. Discretizing this time interval into $P$ steps of size $\\epsilon = \\beta/P$ and using the primitive Trotter factorization $e^{-\\beta \\hat{H}} \\approx (e^{-\\epsilon \\hat{V}} e^{-\\epsilon \\hat{T}})^P$ leads to the expression for $Z_P$:\n$$Z_P = \\mathrm{Tr}\\left[ \\left(e^{-\\frac{\\beta}{P}\\hat{T}} e^{-\\frac{\\beta}{P}\\hat{V}}\\right)^P \\right]$$\nInserting complete sets of position eigenstates between the operators results in a classical-like configuration integral over the positions $q_1, q_2, \\ldots, q_P$ of a cyclic polymer chain (a \"ring polymer\"). For a particle of mass $m$, the expression is:\n$$Z_P = \\left(\\frac{mP}{2\\pi\\beta\\hbar^2}\\right)^{P/2} \\int_{-\\infty}^{\\infty} \\! \\dots \\! \\int_{-\\infty}^{\\infty} d\\mathbf{q} \\exp\\left(-\\sum_{i=1}^{P} \\left[ \\frac{mP}{2\\beta\\hbar^2}(q_{i+1}-q_i)^2 + \\frac{\\beta}{P}V(q_i) \\right] \\right)$$\nwhere $q_{P+1} \\equiv q_1$ enforces the ring closure. In our reduced units ($\\hbar=1$) and for the harmonic potential $V(q) = \\frac{1}{2}m\\omega^2 q^2$, the argument of the exponential becomes:\n$$S(\\mathbf{q}) = \\sum_{i=1}^{P} \\left[ \\frac{mP}{2\\beta}(q_{i+1}-q_i)^2 + \\frac{\\beta m\\omega^2}{2P} q_i^2 \\right]$$\nThe integral is a multidimensional Gaussian integral. The term $S(\\mathbf{q})$ can be written as a quadratic form, $S(\\mathbf{q}) = \\frac{1}{2}\\mathbf{q}^T \\mathbf{A} \\mathbf{q}$, where $\\mathbf{q} = (q_1, \\ldots, q_P)^T$ and $\\mathbf{A}$ is a $P \\times P$ symmetric matrix. The elements of $\\mathbf{A}$ are found by expanding the sum:\n$$A_{ij} = m \\left[ \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right)\\delta_{ij} - \\frac{P}{\\beta}(\\delta_{i,j+1} + \\delta_{i,j-1}) \\right]$$\nwhere indices are taken modulo $P$. This is a circulant matrix.\nThe general formula for a $d$-dimensional Gaussian integral is $\\int d^d\\mathbf{x} \\exp(-\\frac{1}{2}\\mathbf{x}^T \\mathbf{M} \\mathbf{x}) = (2\\pi)^{d/2} (\\det \\mathbf{M})^{-1/2}$. Applying this to our integral for $Z_P$ gives:\n$$Z_P = \\left(\\frac{mP}{2\\pi\\beta}\\right)^{P/2} (2\\pi)^{P/2} (\\det \\mathbf{A})^{-1/2} = \\left(\\frac{mP}{\\beta}\\right)^{P/2} m^{-P/2} (\\det \\mathbf{A}')^{-1/2} = \\left(\\frac{P}{\\beta}\\right)^{P/2} (\\det \\mathbf{A}')^{-1/2}$$\nwhere $\\mathbf{A}' = \\mathbf{A}/m$. The mass $m$ cancels out, consistent with the exact result. The eigenvalues $\\lambda_k$ of the circulant matrix $\\mathbf{A}'$ are given by the discrete Fourier transform of its first row. For $k=0, 1, \\dots, P-1$:\n$$\\lambda_k = \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right) - \\frac{P}{\\beta}e^{2\\pi i k/P} - \\frac{P}{\\beta}e^{-2\\pi i k/P} = \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right) - \\frac{2P}{\\beta}\\cos\\left(\\frac{2\\pi k}{P}\\right)$$\nUsing the identity $1-\\cos(2\\theta) = 2\\sin^2(\\theta)$, this simplifies to:\n$$\\lambda_k = \\frac{2P}{\\beta} \\left(1 - \\cos\\left(\\frac{2\\pi k}{P}\\right)\\right) + \\frac{\\beta\\omega^2}{P} = \\frac{4P}{\\beta}\\sin^2\\left(\\frac{\\pi k}{P}\\right) + \\frac{\\beta\\omega^2}{P}$$\nThe determinant is the product of the eigenvalues, $\\det \\mathbf{A}' = \\prod_{k=0}^{P-1} \\lambda_k$. Substituting this into the expression for $Z_P$ yields the final computable formula:\n$$Z_P(\\beta, \\omega) = \\left(\\frac{P}{\\beta}\\right)^{P/2} \\left[ \\prod_{k=0}^{P-1} \\left( \\frac{4P}{\\beta}\\sin^2\\left(\\frac{\\pi k}{P}\\right) + \\frac{\\beta\\omega^2}{P} \\right) \\right]^{-1/2}$$\nFor numerical evaluation, especially for large $P$, it is more stable to compute the logarithm of $Z_P$:\n$$\\log Z_P = \\frac{P}{2} \\log\\left(\\frac{P}{\\beta}\\right) - \\frac{1}{2} \\sum_{k=0}^{P-1} \\log(\\lambda_k)$$\nThis expression is a direct consequence of the path integral formulation and represents the target value for a PIMC simulation.\n\nThe final requirement is to analyze the convergence of $Z_P$ to $Z_{\\mathrm{exact}}$ as $P$ increases. The primitive Trotter approximation introduces an error that scales with the number of beads $P$. We expect a power-law relationship for the absolute error:\n$$|Z_P - Z_{\\mathrm{exact}}| \\approx C P^{-r}$$\nwhere $C$ is a constant and $r$ is the convergence exponent. To determine $r$, we can perform a linear regression on the logarithm of this equation:\n$$\\log|Z_P - Z_{\\mathrm{exact}}| \\approx \\log C - r \\log P$$\nThis is a linear equation of the form $y = b + mx$, with $y = \\log|Z_P - Z_{\\mathrm{exact}}|$, $x = \\log P$, slope $m = -r$, and intercept $b = \\log C$. We will compute the errors for $P \\in \\{1, 2, 4, 8, 16, 32, 64\\}$, and use the last four data points ($P \\in \\{8, 16, 32, 64\\}$) to perform a linear least-squares fit and extract the slope $m$. The convergence exponent is then $r = -m$. For the primitive algorithm used here, theoretical considerations predict that $r=2$. The implementation will calculate this exponent for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing the exact and path-integral discretized\n    partition functions for a quantum harmonic oscillator.\n    \"\"\"\n\n    # Test cases from the problem statement: (beta, omega)\n    test_cases = [\n        (0.5, 1.0),\n        (1.0, 1.0),\n        (3.0, 1.0),\n        (1.0, 0.5),\n    ]\n\n    # Trotter numbers for the analysis\n    P_values = np.array([1, 2, 4, 8, 16, 32, 64])\n\n    # List to store the final convergence exponents r for each test case\n    convergence_exponents = []\n\n    for beta, omega in test_cases:\n        # 1. Calculate the exact partition function Z_exact\n        # Z_exact = 1 / (2 * sinh(beta * omega / 2))\n        z_exact = 1.0 / (2.0 * np.sinh(beta * omega / 2.0))\n\n        errors = []\n        for P in P_values:\n            # 2. Calculate the discretized path integral partition function Z_P\n            # The formula is derived in the solution text. We compute its logarithm\n            # for numerical stability.\n            # log(Z_P) = (P/2)*log(P/beta) - (1/2)*sum_{k=0}^{P-1}log(lambda_k)\n            # lambda_k = (4P/beta)*sin^2(pi*k/P) + (beta*omega^2)/P\n\n            k_vals = np.arange(P)\n            sin_term = np.sin(np.pi * k_vals / P)**2\n            lambda_k = (4.0 * P / beta) * sin_term + (beta * omega**2 / P)\n            \n            # The logarithm of lambda_k can have -inf if lambda_k is 0,\n            # which does not happen for omega > 0.\n            log_lambda_k_sum = np.sum(np.log(lambda_k))\n\n            log_z_p = (P / 2.0) * np.log(P / beta) - 0.5 * log_lambda_k_sum\n            z_p = np.exp(log_z_p)\n\n            # 3. Compute the absolute error\n            error = np.abs(z_p - z_exact)\n            errors.append(error)\n\n        # 4. Fit the convergence rate r from the last four P values\n        # Model: error = C * P^(-r) => log(error) = log(C) - r * log(P)\n        # We perform a linear fit on log-log data.\n        \n        # Use last four points for the fit: P = {8, 16, 32, 64}\n        fit_P_values = P_values[-4:]\n        fit_errors = np.array(errors[-4:])\n        \n        log_P = np.log(fit_P_values)\n        log_error = np.log(fit_errors)\n\n        # Using numpy's polyfit to find the slope of the linear regression\n        # polyfit returns [slope, intercept] for degree 1\n        slope, _ = np.polyfit(log_P, log_error, 1)\n\n        # The convergence exponent r is the negative of the slope\n        r = -slope\n        convergence_exponents.append(r)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in convergence_exponents)}]\")\n\nsolve()\n```", "id": "2659206"}, {"introduction": "While the partition function is a cornerstone of statistical mechanics, the real power of PIMC lies in its ability to compute thermal expectation values of physical observables like energy, pressure, or position. This practice takes the next logical step, moving from validating the partition function to using the path integral framework to estimate the average energy of a quantum system [@problem_id:2446266]. You will simulate the \"ring polymer\" that is isomorphic to a quantum harmonic oscillator and learn to use the powerful thermodynamic energy estimator to calculate its average energy, a technique that cleverly extracts quantum information from the geometry of the paths themselves.", "problem": "Consider a one-dimensional quantum harmonic oscillator of mass $m$ and angular frequency $\\omega$ at absolute temperature $T$, in thermal equilibrium with a heat bath. Use the imaginary-time path integral representation with $P$ Trotter slices (often termed \"beads\") to construct the classical isomorphic \"ring polymer\" system that samples the quantum canonical ensemble at inverse temperature $\\beta = 1/T$. The reduced Planck constant $\\hbar$ and the Boltzmann constant $k_B$ are to be set to unity, $\\hbar = 1$ and $k_B = 1$, so that all energies and temperatures are expressed in the same natural unit.\n\nIn the ring polymer formulation, the $P$-bead classical Hamiltonian for coordinates $\\{q_k\\}_{k=1}^P$ and conjugate momenta $\\{p_k\\}_{k=1}^P$ is\n$$\nH_P(\\mathbf{q},\\mathbf{p}) \\;=\\; \\sum_{k=1}^{P} \\left[ \\frac{p_k^2}{2m} \\;+\\; \\frac{1}{2} m \\omega_P^2 \\left(q_k - q_{k+1}\\right)^2 \\;+\\; \\frac{1}{2} m \\omega^2 q_k^2 \\right],\n$$\nwith cyclic boundary condition $q_{P+1} \\equiv q_1$, and where the ring polymer frequency is $\\omega_P = \\dfrac{P}{\\beta \\hbar} = P T$ under the specified unit convention.\n\nA constant-temperature simulation of this ring polymer system must be performed by coupling it to a thermostat that ensures sampling of the canonical ensemble at the target temperature $T$. From the sampled configurations, estimate the average total energy of the underlying quantum oscillator using the thermodynamic energy estimator that follows from the discretized path integral:\n$$\nE_{\\mathrm{est}} \\;=\\; \\left\\langle \\frac{P}{2\\beta} \\;+\\; \\frac{1}{P} \\sum_{k=1}^{P} \\frac{1}{2} m \\omega^2 q_k^2 \\;-\\; \\frac{m \\omega_P^2}{2P} \\sum_{k=1}^{P} \\left(q_k - q_{k+1}\\right)^2 \\right\\rangle.\n$$\nThe exact quantum-mechanical canonical average total energy of the harmonic oscillator is\n$$\nE_{\\mathrm{exact}}(T) \\;=\\; \\frac{1}{2} \\,\\hbar \\omega \\,\\coth\\!\\left(\\frac{1}{2}\\beta \\hbar \\omega\\right) \\;=\\; \\frac{1}{2} \\,\\omega \\,\\coth\\!\\left(\\frac{\\omega}{2T}\\right),\n$$\nagain under $\\hbar=1$ and $k_B=1$.\n\nYour program must:\n- Simulate the ring polymer dynamics under a constant-temperature thermostat to draw samples from the canonical ensemble for each test case.\n- Compute $E_{\\mathrm{est}}$ by time-averaging the thermodynamic estimator over the sampled configurations.\n- Compare $E_{\\mathrm{est}}$ to $E_{\\mathrm{exact}}$ for each test case, and report whether the relative error,\n$$\n\\varepsilon \\;=\\; \\frac{\\left|E_{\\mathrm{est}} - E_{\\mathrm{exact}}\\right|}{E_{\\mathrm{exact}}},\n$$\nis less than a specified tolerance $\\delta$.\n\nUse the following test suite, where each tuple is $(m,\\omega,T,P)$:\n- Case 1 (general case): $(1.0,\\,1.0,\\,1.0,\\,16)$.\n- Case 2 (low temperature, strong quantum regime): $(1.0,\\,1.0,\\,0.25,\\,64)$.\n- Case 3 (high temperature, classical limit, single-bead edge): $(1.0,\\,2.0,\\,3.0,\\,1)$.\n\nTake the tolerance to be $\\delta = 0.05$ (dimensionless). All answers must be expressed in the natural energy unit where $k_B=\\hbar=1$.\n\nFinal output format specification:\n- Your program should produce a single line of output containing the results as a comma-separated list of boolean values enclosed in square brackets, indicating for each case whether the relative error criterion is satisfied, in the order of the cases above. For example: \"[True,False,True]\".", "solution": "The objective is to sample configurations of a classical ring polymer from the canonical ensemble at a given temperature $T$ and, from these samples, estimate the average energy of the corresponding quantum harmonic oscillator.\n\nThe problem requires a \"constant-temperature thermostat.\" While this often implies molecular dynamics simulations (such as with a Langevin or Nosé-Hoover thermostat), a more direct and robust method for sampling a static probability distribution is the Metropolis Monte Carlo algorithm. This approach, known as Path Integral Monte Carlo (PIMC) in this context, generates a sequence of configurations that are distributed according to the Boltzmann probability $p(\\mathbf{q}) \\propto e^{-\\beta U(\\mathbf{q})}$, thereby perfectly fulfilling the requirement to sample the canonical ensemble. This method avoids introducing additional, unspecified parameters like a friction coefficient or integration timestep, which would be necessary for a dynamics-based approach.\n\nThe potential energy of the ring polymer system is derived from the Hamiltonian $H_P$:\n$$\nU(\\mathbf{q}) = \\sum_{k=1}^{P} \\left[ \\frac{1}{2} m \\omega_P^2 \\left(q_k - q_{k+1}\\right)^2 + \\frac{1}{2} m \\omega^2 q_k^2 \\right]\n$$\nwith $q_{P+1} = q_1$. The PIMC simulation proceeds as follows:\n\n1.  **Initialization**: The positions of the $P$ beads, $\\{q_k\\}$, are initialized. A simple choice is $q_k=0$ for all $k=1, \\dots, P$.\n2.  **Equilibration**: A number of Monte Carlo steps are performed to allow the system to reach thermal equilibrium and \"forget\" its artificial initial state.\n3.  **Production**: After equilibration, further Monte Carlo steps are performed. Periodically, the configuration of the polymer is saved (sampled) for statistical analysis.\n\nA single Monte Carlo step consists of:\na.  **Move Proposal**: A trial configuration $\\mathbf{q}'$ is generated from the current configuration $\\mathbf{q}$. A simple and effective move consists of selecting one bead $k$ at random and proposing a new position $q_k' = q_k + \\delta$, where $\\delta$ is a random displacement drawn from a uniform distribution $[-\\frac{\\Delta q}{2}, +\\frac{\\Delta q}{2}]$. The parameter $\\Delta q$ is the maximum move size, which must be tuned to achieve an efficient acceptance rate (typically $30-50\\%$).\nb.  **Acceptance Criterion**: The change in potential energy, $\\Delta U = U(\\mathbf{q}') - U(\\mathbf{q})$, is calculated. The move is accepted with probability $p_{\\text{acc}} = \\min(1, e^{-\\beta \\Delta U})$. If the move is accepted, the system state becomes $\\mathbf{q}'$. If rejected, the system remains in state $\\mathbf{q}$, which is counted again in the statistical average.\n\nFor a single bead move affecting $q_k$, only the terms in $U(\\mathbf{q})$ involving $q_k$ change. The energy change is:\n$$\n\\Delta U = \\left( \\frac{1}{2} m \\omega_P^2 \\left( (q_k' - q_{k-1})^2 + (q_k' - q_{k+1})^2 \\right) + \\frac{1}{2} m \\omega^2 q_k'^2 \\right) - \\left( \\frac{1}{2} m \\omega_P^2 \\left( (q_k - q_{k-1})^2 + (q_k - q_{k+1})^2 \\right) + \\frac{1}{2} m \\omega^2 q_k^2 \\right)\n$$\nwhere indices are handled cyclically.\n\nAfter collecting a sufficient number of statistically independent samples of the configuration $\\mathbf{q}$, the average energy is computed using the provided thermodynamic estimator:\n$$\nE_{\\mathrm{est}} = \\frac{1}{N_{\\text{samples}}} \\sum_{i=1}^{N_{\\text{samples}}} \\left[ \\frac{P}{2\\beta} + \\frac{1}{P} \\sum_{k=1}^{P} \\frac{1}{2} m \\omega^2 (q_{k}^{(i)})^2 - \\frac{m \\omega_P^2}{2P} \\sum_{k=1}^{P} \\left(q_k^{(i)} - q_{k+1}^{(i)}\\right)^2 \\right]\n$$\nwhere $q_k^{(i)}$ is the position of bead $k$ in the $i$-th sample.\n\nThis calculated $E_{\\mathrm{est}}$ is then compared to the exact analytical result for the quantum harmonic oscillator, $E_{\\mathrm{exact}}(T) = \\frac{1}{2} \\omega \\coth(\\frac{\\omega}{2T})$, to determine if the relative error $\\varepsilon$ is within the tolerance $\\delta=0.05$.\n\nThe move size $\\Delta q$ is chosen for each test case based on the physical parameters to ensure efficient sampling. The characteristic stiffness of the polymer is dominated by the spring frequency $\\omega_P = PT$, suggesting that an appropriate move size scales inversely with this frequency. We will use specific tuned values for each case.\n\nFor Case 3 with $P=1$, the ring polymer collapses to a single classical particle in a harmonic potential. The spring term $(q_k - q_{k+1})^2$ is identically zero. The simulation correctly reduces to sampling a classical harmonic oscillator, and the energy estimator simplifies to $E_{\\mathrm{est}} = \\langle \\frac{1}{2\\beta} + \\frac{1}{2} m \\omega^2 q_1^2 \\rangle$. By the equipartition theorem, $\\langle \\frac{1}{2} m \\omega^2 q_1^2 \\rangle = \\frac{1}{2}k_B T = \\frac{1}{2}T$, so the expected average is $E_{\\mathrm{est}} \\approx \\frac{T}{2} + \\frac{T}{2} = T$. This is the classical limit of the quantum energy.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the path integral quantum harmonic oscillator problem for the given test cases.\n    \"\"\"\n\n    # Global simulation parameters\n    _NUM_STEPS = 500_000\n    _NUM_EQUIL = 100_000\n    _SAMPLE_FREQ = 100\n\n    def coth(x):\n        \"\"\"Computes the hyperbolic cotangent.\"\"\"\n        # Use np.tanh for numerical stability\n        return 1.0 / np.tanh(x)\n\n    def get_exact_energy(w, T):\n        \"\"\"\n        Calculates the exact quantum average energy of a 1D harmonic oscillator.\n        Units: h_bar = 1, k_B = 1.\n        \"\"\"\n        if T == 0:\n            # Zero-point energy\n            return 0.5 * w\n        \n        arg = 0.5 * w / T\n        return 0.5 * w * coth(arg)\n\n    def run_pimc(m, w, T, P, move_size):\n        \"\"\"\n        Performs a Path Integral Monte Carlo (PIMC) simulation for the harmonic oscillator.\n\n        Args:\n            m (float): Mass of the oscillator.\n            w (float): Angular frequency of the oscillator.\n            T (float): Temperature of the heat bath.\n            P (int): Number of Trotter slices (beads).\n            move_size (float): The maximum displacement for a Monte Carlo move.\n\n        Returns:\n            float: The estimated average total energy from the simulation.\n        \"\"\"\n        # Constants for the simulation run\n        beta = 1.0 / T\n        omega_P = P * T\n\n        # Pre-calculated coefficients for energy calculation\n        m_w_sq_half = 0.5 * m * w**2\n        m_wp_sq_half = 0.5 * m * omega_P**2\n\n        # Initialize the ring polymer chain at the origin\n        q = np.zeros(P)\n        \n        energy_samples = []\n\n        # PIMC simulation loop\n        for step in range(_NUM_STEPS):\n            # Propose a move by picking a random bead and displacing it\n            bead_idx = np.random.randint(P)\n            q_old_k = q[bead_idx]\n            q_new_k = q_old_k + move_size * (np.random.rand() - 0.5)\n\n            # Get neighbor positions using cyclic boundary conditions\n            # numpy's negative indexing handles the k=0 case correctly for q[k-1]\n            q_prev_k = q[bead_idx - 1]\n            q_next_k = q[(bead_idx + 1) % P]\n\n            # Calculate the change in potential energy due to the move\n            U_old = m_wp_sq_half * ((q_old_k - q_prev_k)**2 + (q_old_k - q_next_k)**2) \\\n                    + m_w_sq_half * q_old_k**2\n            U_new = m_wp_sq_half * ((q_new_k - q_prev_k)**2 + (q_new_k - q_next_k)**2) \\\n                    + m_w_sq_half * q_new_k**2\n            delta_U = U_new - U_old\n            \n            # Metropolis-Hastings acceptance criterion\n            if delta_U < 0.0 or np.random.rand() < np.exp(-beta * delta_U):\n                q[bead_idx] = q_new_k\n            \n            # After equilibration, sample the energy estimator\n            if step >= _NUM_EQUIL and step % _SAMPLE_FREQ == 0:\n                # Calculate terms for the thermodynamic energy estimator\n                q_next = np.roll(q, -1)\n                sum_sq_dist = np.sum((q - q_next)**2)\n                sum_sq_pos = np.sum(q**2)\n                \n                kinetic_term = P / (2.0 * beta)\n                potential_term = (m * w**2 / (2.0 * P)) * sum_sq_pos\n                spring_term = (m * omega_P**2 / (2.0 * P)) * sum_sq_dist\n\n                estimator_val = kinetic_term + potential_term - spring_term\n                energy_samples.append(estimator_val)\n\n        return np.mean(energy_samples)\n\n    # Test cases: (m, omega, T, P, tuned_move_size)\n    # The move_size is tuned for each case to ensure efficient sampling.\n    test_cases = [\n        (1.0, 1.0, 1.0, 16, 0.25),\n        (1.0, 1.0, 0.25, 64, 0.25),\n        (1.0, 2.0, 3.0, 1, 0.8)\n    ]\n    \n    tolerance = 0.05\n    results = []\n\n    for case in test_cases:\n        m, w, T, P, move_size = case\n        \n        # Calculate theoretical exact energy\n        E_exact = get_exact_energy(w, T)\n        \n        # Run PIMC simulation to get the estimated energy\n        E_est = run_pimc(m, w, T, P, move_size)\n        \n        # Calculate relative error and check against tolerance\n        relative_error = np.abs(E_est - E_exact) / E_exact\n        results.append(relative_error < tolerance)\n\n    # Print results in the specified format\n    print(f\"[{','.join(map(str, [r.item() for r in results]))}]\")\n\nsolve()\n```", "id": "2446266"}, {"introduction": "The quantum world is built on the principle of indistinguishability: all electrons are identical, as are all photons. This final practice explores the profound consequences of this fact, which path integrals must incorporate through permutation sampling. We will investigate how the requirement of symmetrizing (for bosons) or antisymmetrizing (for fermions) the wavefunction gives rise to effective \"statistical forces\" that fundamentally alter the spatial structure of a quantum gas [@problem_id:2798482]. By deriving and calculating the pair-distribution function, $g(r)$, you will see firsthand how bosonic particles tend to \"bunch\" together while fermionic particles exhibit \"Pauli exclusion,\" keeping them apart—behaviors that are central to phenomena ranging from the stability of stars to the superfluidity of liquid helium.", "problem": "You are to work within the ideal, homogeneous quantum gas framework in $3$ spatial dimensions and the path-integral representation of indistinguishable particles. Use only foundational definitions and the free-particle density matrix as starting points. Your goals are to show how exchange symmetry modifies the radial distribution function and to implement a path-integral Monte Carlo (PIMC) style estimator which, in the nondegenerate limit, reduces to a closed-form function of the separation and the thermal de Broglie wavelength.\n\nFundamental starting points you may use:\n- The definition of the radial distribution function $g(r)$ in terms of the two-particle density operator for a uniform system.\n- Symmetrization or antisymmetrization of the $N$-particle density operator for bosons and fermions.\n- The free-particle single-particle density matrix in $3$ dimensions at inverse temperature $\\beta$, \n  $$\\rho^{(1)}(\\mathbf{r},\\mathbf{r}';\\beta) = \\left(\\frac{1}{\\lambda_T^3}\\right)\\exp\\!\\left(-\\pi\\frac{\\lvert \\mathbf{r}-\\mathbf{r}'\\rvert^2}{\\lambda_T^2}\\right),$$\n  with thermal de Broglie wavelength \n  $$\\lambda_T = \\frac{h}{\\sqrt{2\\pi m k_\\mathrm{B} T}},$$\n  where $h$ is Planck’s constant, $m$ is the particle mass, $k_\\mathrm{B}$ is the Boltzmann constant, and $T$ is the absolute temperature.\n\nTasks:\n1. From the definition of $g(r)$ for a homogeneous ideal gas and the symmetrization postulate, derive the exchange-only modification to $g(r)$ at low fugacity (nondegenerate limit) for bosons and fermions. Your derivation must start from the two-particle reduced density and the free-particle density matrix given above, without invoking any pre-remembered target expression for $g(r)$.\n2. Using the path-integral representation with $M$ imaginary-time slices and the primitive free-particle action, express the exchange contribution to the pair estimator as a ratio of off-diagonal to diagonal free-particle density matrices along an exchanged pair of worldlines. Show that for a homogeneous ideal gas this estimator depends only on the scalar separation $r$ and $\\lambda_T$, and obtain the explicit dependence on $M$ that simplifies in the continuum limit to a closed form in $r$ and $\\lambda_T$.\n3. Implement a program that evaluates $g(r)$ predicted by the exchange-only estimator for three statistics choices $s\\in\\{\\mathrm{MB},\\mathrm{FD},\\mathrm{BE}\\}$, corresponding to Maxwell–Boltzmann, Fermi–Dirac, and Bose–Einstein statistics, respectively. For $\\mathrm{MB}$, there is no exchange modification.\n\nPhysical units and constants:\n- Input separations must be in meters.\n- Temperatures must be in Kelvin.\n- Masses must be in kilograms.\n- The output $g(r)$ is dimensionless.\n- Use $h = 6.62607015\\times 10^{-34}\\ \\mathrm{J\\,s}$ and $k_\\mathrm{B} = 1.380649\\times 10^{-23}\\ \\mathrm{J\\,K^{-1}}$.\n- One atomic mass unit is $u = 1.66053906660\\times 10^{-27}\\ \\mathrm{kg}$.\n\nTest suite:\nUse the following parameter sets, each consisting of $(s, m, T, \\{r_i\\})$, where $\\{r_i\\}$ is a finite list of separations in meters. For each test case, your program must output the corresponding list $\\{g(r_i)\\}$ as floats.\n\n- Test A (baseline, no exchange): $s=\\mathrm{MB}$, $m = 4.002602\\,u$, $T=300$, $\\{r_i\\}=\\{0,\\ 1.0\\times 10^{-10},\\ 5.0\\times 10^{-10}\\}$.\n- Test B (fermions, low temperature): $s=\\mathrm{FD}$, $m = 3.016\\,u$, $T=2$, $\\{r_i\\}=\\{0,\\ 5.0\\times 10^{-10},\\ 2.0\\times 10^{-9}\\}$.\n- Test C (bosons, low temperature): $s=\\mathrm{BE}$, $m = 4.002602\\,u$, $T=2$, $\\{r_i\\}=\\{0,\\ 5.0\\times 10^{-10},\\ 2.0\\times 10^{-9}\\}$.\n- Test D (bosons, very low temperature, edge behavior near $r=0$ and saturation at large $r$): $s=\\mathrm{BE}$, $m = 4.002602\\,u$, $T=0.5$, $\\{r_i\\}=\\{0,\\ 1.0\\times 10^{-9},\\ 1.0\\times 10^{-8}\\}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of the $g(r)$ values in the order of the separations provided. For example, in the required format: $[[g_{A,1},g_{A,2},g_{A,3}],[g_{B,1},g_{B,2},g_{B,3}],\\dots]$. Do not print any additional text.", "solution": "The solution is presented in two parts as requested: first, a derivation of the radial distribution function from the two-particle density, and second, an interpretation from the perspective of path-integral Monte Carlo estimators.\n\n### Part 1: Derivation of the Radial Distribution Function, $g(r)$\n\nThe radial distribution function, $g(r)$, for a homogeneous system with number density $n=N/V$ is defined through the two-particle density, $\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2)$, as:\n$$\nn^2 g(|\\mathbf{r}_1 - \\mathbf{r}_2|) = \\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2)\n$$\nThe two-particle density is the diagonal element of the two-particle reduced density matrix, which is obtained by tracing the full $N$-particle density matrix $\\hat{\\rho}_N$ over the coordinates of $N-2$ particles:\n$$\n\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2) = \\frac{N(N-1)}{Z_N} \\int d\\mathbf{r}_3 \\dots d\\mathbf{r}_N \\, \\langle \\mathbf{r}_1, \\dots, \\mathbf{r}_N | e^{-\\beta \\hat{H}} | \\mathbf{r}_1, \\dots, \\mathbf{r}_N \\rangle_{\\text{symm}}\n$$\nwhere $Z_N = \\mathrm{Tr}(e^{-\\beta \\hat{H}})$ is the canonical partition function and $\\beta = (k_\\mathrm{B} T)^{-1}$. The subscript 'symm' indicates that the states are properly symmetrized (for bosons) or antisymmetrized (for fermions).\n\nFor a system of $N$ non-interacting (ideal) particles, the Hamiltonian is $\\hat{H} = \\sum_{i=1}^N \\hat{K}_i$, where $\\hat{K}_i$ is the kinetic energy operator for particle $i$. The coordinate-basis matrix element of the corresponding symmetrized density operator is:\n$$\n\\langle \\mathbf{R} | e^{-\\beta \\hat{H}} | \\mathbf{R} \\rangle_{\\text{symm}} = \\frac{1}{N!} \\sum_{P \\in S_N} \\zeta^{\\epsilon(P)} \\prod_{i=1}^N \\langle \\mathbf{r}_i | e^{-\\beta \\hat{K}} | \\mathbf{r}_{P(i)} \\rangle = \\frac{1}{N!} \\sum_{P \\in S_N} \\zeta^{\\epsilon(P)} \\prod_{i=1}^N \\rho^{(1)}(\\mathbf{r}_i, \\mathbf{r}_{P(i)}; \\beta)\n$$\nHere, $\\mathbf{R} = \\{\\mathbf{r}_1, \\dots, \\mathbf{r}_N\\}$, $P$ is a permutation of the particle labels, $\\epsilon(P)$ is its parity, and $\\zeta=+1$ for bosons (BE) or $\\zeta=-1$ for fermions (FD). $\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}'; \\beta)$ is the single-particle free-particle density matrix.\n\nWe operate in the non-degenerate (low fugacity) limit, where the density is low such that $n\\lambda_T^3 \\ll 1$. In this regime, the probability of multi-particle exchange cycles is negligible. We thus retain only the two most significant permutations for any pair of particles $(1, 2)$: the identity permutation $P=I$ and the simple transposition $P=(12)$. All other permutations give rise to higher-order terms in density and are neglected.\n\nThe matrix element becomes:\n$$\n\\langle \\mathbf{R} | e^{-\\beta \\hat{H}} | \\mathbf{R} \\rangle_{\\text{symm}} \\approx \\frac{1}{N!} \\left( \\prod_{i=1}^N \\rho^{(1)}(\\mathbf{r}_i, \\mathbf{r}_i) + \\zeta \\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2) \\rho^{(1)}(\\mathbf{r}_2, \\mathbf{r}_1) \\prod_{i=3}^N \\rho^{(1)}(\\mathbf{r}_i, \\mathbf{r}_i) \\right)\n$$\nLet us denote the diagonal element $\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}; \\beta)$ as $\\rho_d$. For a free particle, $\\rho_d = 1/\\lambda_T^3$ and is constant.\n\nNow, we compute $\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2)$:\n$$\n\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2) \\approx \\frac{N(N-1)}{Z_N} \\frac{1}{N!} \\int d\\mathbf{r}_3 \\dots d\\mathbf{r}_N \\left[ (\\rho_d)^N + \\zeta \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho_d)^2} (\\rho_d)^N \\right]\n$$\nThe integral over $d\\mathbf{r}_3 \\dots d\\mathbf{r}_N$ yields a factor of $V^{N-2}$.\n$$\n\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2) \\approx \\frac{1}{(N-2)!} \\frac{V^{N-2} (\\rho_d)^N}{Z_N} \\left( 1 + \\zeta \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho_d)^2} \\right)\n$$\nIn the same non-degenerate limit, the partition function $Z_N$ is well-approximated by that of an ideal Bose or Fermi gas, which for low fugacity approaches the classical ideal gas result: $Z_N \\approx \\frac{Z_1^N}{N!} = \\frac{(V\\rho_d)^N}{N!}$.\n\nSubstituting this into the expression for $\\rho^{(2)}$:\n$$\n\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2) \\approx \\frac{1}{(N-2)!} \\frac{V^{N-2} (\\rho_d)^N}{ (V\\rho_d)^N / N! } \\left( \\dots \\right) = \\frac{N(N-1)}{V^2} \\left( 1 + \\zeta \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho_d)^2} \\right)\n$$\nFor large $N$, $n \\approx N/V \\approx (N-1)/V$, so $\\frac{N(N-1)}{V^2} \\approx n^2$.\n$$\n\\rho^{(2)}(\\mathbf{r}_1, \\mathbf{r}_2) \\approx n^2 \\left( 1 + \\zeta \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho_d)^2} \\right)\n$$\nUsing the definition $g(r) = \\rho^{(2)}/n^2$, we arrive at the exchange contribution to the radial distribution function:\n$$\ng(r) = 1 + \\zeta \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}))^2}\n$$\nwhere $r = |\\mathbf{r}_1 - \\mathbf{r}_2|$. Substituting the given form of the free-particle density matrix:\n$$\n\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2; \\beta) = \\frac{1}{\\lambda_T^3} \\exp\\left(-\\pi \\frac{r^2}{\\lambda_T^2}\\right)\n\\quad \\text{and} \\quad\n\\rho_d = \\rho^{(1)}(\\mathbf{r}, \\mathbf{r}; \\beta) = \\frac{1}{\\lambda_T^3}\n$$\nThe ratio becomes:\n$$\n\\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|^2}{(\\rho_d)^2} = \\frac{\\left( \\frac{1}{\\lambda_T^3} \\exp\\left(-\\pi \\frac{r^2}{\\lambda_T^2}\\right) \\right)^2}{\\left( \\frac{1}{\\lambda_T^3} \\right)^2} = \\exp\\left(-2\\pi \\frac{r^2}{\\lambda_T^2}\\right)\n$$\nThus, the final expression for the radial distribution function at this level of approximation is:\n$$\ng(r) = 1 + \\zeta \\exp\\left(-2\\pi \\frac{r^2}{\\lambda_T^2}\\right)\n$$\nFor Maxwell-Boltzmann (MB) statistics, particles are distinguishable, so only the identity permutation is considered, equivalent to setting $\\zeta=0$. For Fermi-Dirac (FD) statistics, $\\zeta=-1$, leading to $g(0)=0$ (Pauli exclusion). For Bose-Einstein (BE) statistics, $\\zeta=+1$, leading to $g(0)=2$ (boson bunching).\n\n### Part 2: Path-Integral Monte Carlo (PIMC) Estimator Perspective\n\nIn the path-integral formalism, the density matrix $\\langle \\mathbf{R} | e^{-\\beta \\hat{H}} | \\mathbf{R}' \\rangle$ is expressed as an integral over all paths connecting $\\mathbf{R}'$ to $\\mathbf{R}$ in imaginary time $\\beta$. The path is discretized into $M$ slices of duration $\\tau = \\beta/M$.\nThe partition function $Z$ involves a sum over all permutations $P$ and an integral over all paths consistent with each permutation. For two particles, the configurations are either direct (identity, $P=I$) or exchanged ($P=(12)$).\nA 'PIMC style estimator' for a quantity is its average value over the sampled path configurations weighted by the path probability. The exchange contribution to $g(r)$ can be understood as the relative probability of finding two particles in an exchanged configuration versus a direct one.\n\nThe statistical weight of a two-particle configuration separated by $r=|\\mathbf{r}_1-\\mathbf{r}_2|$ is proportional to the diagonal two-particle density matrix element:\n$$\nW(\\mathbf{r}_1, \\mathbf{r}_2) \\propto \\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_1; \\beta)\\rho^{(1)}(\\mathbf{r}_2, \\mathbf{r}_2; \\beta) + \\zeta \\, \\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2; \\beta)\\rho^{(1)}(\\mathbf{r}_2, \\mathbf{r}_1; \\beta)\n$$\nThe first term corresponds to direct paths (worldline $1$ starts at $\\mathbf{r}_1$ and ends at $\\mathbf{r}_1$; worldline $2$ starts at $\\mathbf{r}_2$ and ends at $\\mathbf{r}_2$). The second term corresponds to exchanged paths (worldline $1$ starts at $\\mathbf{r}_1$ and ends at $\\mathbf{r}_2$; worldline $2$ starts at $\\mathbf{r}_2$ and ends at $\\mathbf{r}_1$).\n\nThe estimator for the exchange contribution is therefore the ratio of the off-diagonal (exchange) path weight to the diagonal (direct) path weight:\n$$\nE_{\\text{exch}}(r) = \\frac{\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2; \\beta)\\rho^{(1)}(\\mathbf{r}_2, \\mathbf{r}_1; \\beta)}{\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_1; \\beta)\\rho^{(1)}(\\mathbf{r}_2, \\mathbf{r}_2; \\beta)} = \\frac{|\\rho^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2; \\beta)|^2}{(\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}; \\beta))^2}\n$$\nThis is precisely the exchange term derived in Part 1.\n\nThe problem asks to show the dependence on the number of imaginary-time slices $M$. For an ideal gas ($V=0$), the primitive approximation for the short-time propagator is exact:\n$$\n\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}'; \\tau) = \\langle \\mathbf{r} | e^{-\\tau \\hat{K}} | \\mathbf{r}' \\rangle\n$$\nThe full density matrix $\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}'; \\beta)$ is a convolution over intermediate time slices:\n$$\n\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}'; \\beta=M\\tau) = \\int d\\mathbf{r}_1 \\dots d\\mathbf{r}_{M-1} \\, \\rho^{(1)}(\\mathbf{r}, \\mathbf{r}_1; \\tau) \\dots \\rho^{(1)}(\\mathbf{r}_{M-1}, \\mathbf{r}'; \\tau)\n$$\nBecause the free-particle propagator is Gaussian, this convolution is exact and yields the same functional form, simply replacing $\\tau$ with $M\\tau = \\beta$. Specifically:\n$$\n\\int d\\mathbf{y} \\, \\exp(-a|\\mathbf{x}-\\mathbf{y}|^2) \\exp(-b|\\mathbf{y}-\\mathbf{z}|^2) \\propto \\exp\\left(-\\frac{ab}{a+b}|\\mathbf{x}-\\mathbf{z}|^2\\right)\n$$\nApplying this repeatedly confirms that the analytical form of $\\rho^{(1)}(\\mathbf{r}, \\mathbf{r}';\\beta)$ is recovered exactly, for any $M \\ge 1$.\nTherefore, for an ideal gas, the estimator $E_{\\text{exch}}(r)$ has no dependence on $M$. The continuum limit $M \\to \\infty$ is trivial; the expression is already in its final closed form, which depends only on the scalar separation $r$ and the thermal de Broglie wavelength $\\lambda_T$, as shown in Part 1. For interacting systems, this would not be the case, and $M \\to \\infty$ would be a necessary and non-trivial limit.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the radial distribution function g(r) for an ideal quantum gas\n    considering Maxwell-Boltzmann, Fermi-Dirac, and Bose-Einstein statistics.\n    \"\"\"\n    \n    # Physical constants in SI units\n    H_PLANCK = 6.62607015e-34      # J s\n    K_BOLTZMANN = 1.380649e-23     # J K^-1\n    U_AMU = 1.66053906660e-27      # kg (atomic mass unit)\n\n    # Define the test cases from the problem statement.\n    # Each case: (statistics, mass in u, temperature in K, list of separations in m)\n    test_cases = [\n        ('MB', 4.002602, 300.0, [0.0, 1.0e-10, 5.0e-10]),\n        ('FD', 3.016, 2.0, [0.0, 5.0e-10, 2.0e-9]),\n        ('BE', 4.002602, 2.0, [0.0, 5.0e-10, 2.0e-9]),\n        ('BE', 4.002602, 0.5, [0.0, 1.0e-9, 1.0e-8])\n    ]\n\n    all_results = []\n\n    for s, m_u, temp, r_values in test_cases:\n        case_results = []\n        \n        # Set zeta based on statistics\n        # zeta = 0 for Maxwell-Boltzmann (distinguishable particles, no exchange)\n        # zeta = -1 for Fermi-Dirac (antisymmetric wavefunction)\n        # zeta = +1 for Bose-Einstein (symmetric wavefunction)\n        if s == 'MB':\n            zeta = 0.0\n        elif s == 'FD':\n            zeta = -1.0\n        elif s == 'BE':\n            zeta = 1.0\n        else:\n            # This case should not be reached with the given test suite\n            raise ValueError(f\"Unknown statistics type: {s}\")\n\n        # For Maxwell-Boltzmann statistics, g(r) is always 1 in the ideal gas limit.\n        if s == 'MB':\n            case_results = [1.0] * len(r_values)\n        else:\n            # For FD and BE, calculate the exchange contribution\n            m_kg = m_u * U_AMU\n            \n            # Calculate the square of the thermal de Broglie wavelength\n            # lambda_T^2 = h^2 / (2 * pi * m * k_B * T)\n            lambda_T_sq = (H_PLANCK**2) / (2 * np.pi * m_kg * K_BOLTZMANN * temp)\n\n            for r in r_values:\n                # The radial distribution function is g(r) = 1 + zeta * exp(-2*pi*r^2 / lambda_T^2)\n                # If lambda_T_sq is zero (T is infinite), the exponential term is zero.\n                if lambda_T_sq = 0:\n                    exchange_term = 0.0\n                else:\n                    exponent = -2 * np.pi * (r**2) / lambda_T_sq\n                    exchange_term = np.exp(exponent)\n                \n                g_r = 1.0 + zeta * exchange_term\n                case_results.append(g_r)\n        \n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified: [[...],[...],...]\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, res))}]\" for res in all_results]) + \"]\"\n    print(output_str)\n\n# Run the solver.\nsolve()\n```", "id": "2798482"}]}