{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we will bridge the gap between abstract quantum states and their concrete tensor network representation. This first exercise guides you through the process of taking the ground state of a simple, analytically solvable two-site fermionic model and explicitly constructing its Matrix Product State (MPS) form. By building an MPS from scratch and using it to verify physical properties like correlators and entanglement entropy, you will gain a foundational, intuitive understanding of how these powerful data structures encode the intricate details of quantum many-body states [@problem_id:2445466].", "problem": "Consider a one-dimensional chain of $L=2$ spinless fermionic sites with open boundary conditions. The creation and annihilation operators $c_{j}^{\\dagger}$ and $c_{j}$ for site $j \\in \\{1,2\\}$ satisfy the canonical anticommutation relations $\\{c_{i},c_{j}^{\\dagger}\\}=\\delta_{ij}$ and $\\{c_{i},c_{j}\\}=0=\\{c_{i}^{\\dagger},c_{j}^{\\dagger}\\}$. The Hamiltonian is\n$$\nH \\;=\\; -\\,t\\,\\big(c_{1}^{\\dagger}c_{2}+c_{2}^{\\dagger}c_{1}\\big)\\,,\n$$\nwith $t>0$. Work in the sector with total particle number $N=1$. Starting from the definitions above and no further assumptions, do the following:\n\n- Determine the unique normalized ground state $|\\psi_{0}\\rangle$ of $H$ in the $N=1$ sector and express it in the occupation basis $\\{|n_{1}n_{2}\\rangle\\}$ with $n_{j}\\in\\{0,1\\}$.\n- Represent $|\\psi_{0}\\rangle$ exactly as a Matrix Product State (MPS), that is, as\n$$\n|\\psi_{0}\\rangle \\;=\\; \\sum_{n_{1},n_{2}\\in\\{0,1\\}} A^{[1]}_{n_{1}}\\,A^{[2]}_{n_{2}}\\,|n_{1}n_{2}\\rangle\\,,\n$$\nwhere $A^{[1]}_{n_{1}}$ is a $1\\times \\chi$ row vector and $A^{[2]}_{n_{2}}$ is a $\\chi\\times 1$ column vector for some minimal bond dimension $\\chi$. Your MPS must reproduce exactly the amplitudes of $|\\psi_{0}\\rangle$ in the occupation basis.\n- Using your MPS, verify directly that the two-point correlator $\\langle \\psi_{0}|\\,c_{1}^{\\dagger}c_{2}\\,|\\psi_{0}\\rangle$ has the correct value implied by $|\\psi_{0}\\rangle$, and verify that the reduced density matrix of site $1$, $\\rho_{1}=\\mathrm{Tr}_{2}\\,|\\psi_{0}\\rangle\\langle\\psi_{0}|$, is properly normalized and positive semidefinite.\n\nAnswer specification:\n- Compute the von Neumann entanglement entropy across the bipartition $\\{1\\}|\\{2\\}$, defined by $S \\equiv -\\mathrm{Tr}\\big(\\rho_{1}\\,\\ln \\rho_{1}\\big)$, and provide this as your final answer.\n- No rounding is required; provide an exact closed-form analytic expression.\n- Do not include any units with your final answer; the entropy is to be reported in nats (natural logarithm).", "solution": "The problem posed is a standard exercise in quantum many-body physics and is well-defined, scientifically grounded, and objective. It contains all necessary information to determine a unique solution. Therefore, we proceed with the a full analysis.\n\nThe system is a one-dimensional chain of $L=2$ spinless fermionic sites. We are restricted to the sector with total particle number $N=1$. The basis states for this sector are $|10\\rangle$, representing a fermion on site $1$ and none on site $2$, and $|01\\rangle$, representing a fermion on site $2$ and none on site $1$. The Hilbert space for this sector is thus two-dimensional.\n\nThe Hamiltonian is given by $H = -t(c_{1}^{\\dagger}c_{2}+c_{2}^{\\dagger}c_{1})$, where $t>0$. We find the matrix representation of $H$ in the basis $\\{|10\\rangle, |01\\rangle\\}$. We apply $H$ to each basis state:\n$$\nH|10\\rangle = -t(c_{1}^{\\dagger}c_{2}+c_{2}^{\\dagger}c_{1})|10\\rangle = -t(c_{1}^{\\dagger}c_{2}|10\\rangle + c_{2}^{\\dagger}c_{1}|10\\rangle)\n$$\nSince site $2$ is empty in $|10\\rangle$, $c_{2}|10\\rangle = 0$. The operator $c_{1}$ annihilates a fermion on site $1$, resulting in the vacuum state $|00\\rangle$, so $c_{1}|10\\rangle = |00\\rangle$. Then, $c_{2}^{\\dagger}c_{1}|10\\rangle = c_{2}^{\\dagger}|00\\rangle = |01\\rangle$. Thus, $H|10\\rangle = -t|01\\rangle$.\n\nSimilarly, we apply $H$ to $|01\\rangle$:\n$$\nH|01\\rangle = -t(c_{1}^{\\dagger}c_{2}+c_{2}^{\\dagger}c_{1})|01\\rangle = -t(c_{1}^{\\dagger}c_{2}|01\\rangle + c_{2}^{\\dagger}c_{1}|01\\rangle)\n$$\nHere, $c_{1}|01\\rangle = 0$. We have $c_{2}|01\\rangle=|00\\rangle$, so $c_{1}^{\\dagger}c_{2}|01\\rangle = c_{1}^{\\dagger}|00\\rangle = |10\\rangle$. Thus, $H|01\\rangle = -t|10\\rangle$.\n\nIn the ordered basis $(|10\\rangle, |01\\rangle)$, the Hamiltonian matrix is:\n$$\n\\mathbf{H} = \\begin{pmatrix} \\langle 10|H|10\\rangle & \\langle 10|H|01\\rangle \\\\ \\langle 01|H|10\\rangle & \\langle 01|H|01\\rangle \\end{pmatrix} = \\begin{pmatrix} 0 & -t \\\\ -t & 0 \\end{pmatrix}\n$$\nThe eigenvalues $\\lambda$ are found from $\\det(\\mathbf{H} - \\lambda I) = \\lambda^2 - t^2 = 0$, which gives $\\lambda = \\pm t$. Since $t>0$, the ground state energy is $E_0 = -t$. The corresponding eigenvector $(a, b)^T$ satisfies:\n$$\n\\begin{pmatrix} t & -t \\\\ -t & t \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\implies ta - tb = 0 \\implies a = b\n$$\nThe unnormalized ground state is $|10\\rangle + |01\\rangle$. Normalizing this state, we find the unique normalized ground state $|\\psi_0\\rangle$:\n$$\n|\\psi_0\\rangle = \\frac{1}{\\sqrt{2}} \\left( |10\\rangle + |01\\rangle \\right)\n$$\n\nNext, we represent $|\\psi_0\\rangle$ as a Matrix Product State (MPS). In the occupation basis $\\{|n_1 n_2\\rangle\\}$, the state is $|\\psi_0\\rangle = \\sum_{n_1,n_2} C_{n_1 n_2} |n_1 n_2\\rangle$. The coefficient matrix is:\n$$\nC = \\begin{pmatrix} C_{00} & C_{01} \\\\ C_{10} & C_{11} \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} & 0 \\end{pmatrix}\n$$\nThe minimal bond dimension $\\chi$ is the rank of this matrix, which is $\\chi=2$. The MPS representation is given by $C_{n_1 n_2} = A^{[1]}_{n_1} A^{[2]}_{n_2}$, where for each $n_1 \\in \\{0, 1\\}$, $A^{[1]}_{n_1}$ is a $1 \\times 2$ row vector, and for each $n_2 \\in \\{0, 1\\}$, $A^{[2]}_{n_2}$ is a $2 \\times 1$ column vector. We form a $2 \\times 2$ matrix $M_1$ from the rows $A^{[1]}_{n_1}$ and a $2 \\times 2$ matrix $M_2$ from the columns $A^{[2]}_{n_2}$, such that $C = M_1 M_2$. A valid and simple choice is $M_1 = C$ and $M_2 = I$:\n$$\nA^{[1]}_0 = \\begin{pmatrix} 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}, \\quad A^{[1]}_1 = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 \\end{pmatrix}\n$$\n$$\nA^{[2]}_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad A^{[2]}_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThis choice satisfies the conditions and reproduces the coefficients exactly.\n\nWe now verify the two-point correlator $\\langle \\psi_0 | c_1^\\dagger c_2 | \\psi_0 \\rangle$ using this MPS. First, from the exact state, we have $\\langle \\psi_0 | c_1^\\dagger c_2 | \\psi_0 \\rangle = \\frac{1}{2}(\\langle 10| + \\langle 01|)c_1^\\dagger c_2(|10\\rangle + |01\\rangle) = \\frac{1}{2}(\\langle 10| + \\langle 01|)c_1^\\dagger|00\\rangle = \\frac{1}{2}(\\langle 10| + \\langle 01|)|10\\rangle = \\frac{1}{2}$.\nTo calculate this with the MPS, we use the formula for a two-site operator $\\hat{O}_1 \\otimes \\hat{O}_2$:\n$$\n\\langle \\psi_0 | \\hat{O}_1 \\otimes \\hat{O}_2 | \\psi_0 \\rangle = \\sum_{n_1,m_1,n_2,m_2} (A^{[1]}_{m_1}A^{[2]}_{m_2})^* (\\hat{O}_1)_{m_1 n_1} (\\hat{O}_2)_{m_2 n_2} (A^{[1]}_{n_1}A^{[2]}_{n_2})\n$$\nThe expression can be rearranged as:\n$$\n\\langle \\psi_0 | \\hat{O}_1 \\otimes \\hat{O}_2 | \\psi_0 \\rangle = \\sum_{n_2, m_2} (\\hat{O}_2)_{m_2 n_2} (A^{[2]}_{m_2})^\\dagger \\left( \\sum_{n_1, m_1} (\\hat{O}_1)_{m_1 n_1} (A^{[1]}_{m_1})^\\dagger A^{[1]}_{n_1} \\right) A^{[2]}_{n_2}\n$$\nLet $\\tilde{E}_1 = \\sum_{n_1, m_1} \\langle m_1|\\hat{O}_1|n_1\\rangle (A^{[1]}_{m_1})^\\dagger A^{[1]}_{n_1}$. For $\\hat{O}_1 = c_1^\\dagger$, the only non-zero matrix element is $\\langle 1|c_1^\\dagger|0\\rangle=1$.\n$$\n\\tilde{E}_1 = (A^{[1]}_1)^\\dagger A^{[1]}_0 = \\begin{pmatrix} \\sqrt{2}^{-1} \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 0 & \\sqrt{2}^{-1} \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac{1}{2} \\\\ 0 & 0 \\end{pmatrix}\n$$\nThe expectation value is thus $\\sum_{n_2, m_2} \\langle m_2|\\hat{O}_2|n_2\\rangle (A^{[2]}_{m_2})^\\dagger \\tilde{E}_1 A^{[2]}_{n_2}$. For $\\hat{O}_2=c_2$, the non-zero matrix element is $\\langle 0|c_2|1\\rangle=1$.\n$$\n\\langle \\psi_0 | c_1^\\dagger c_2 | \\psi_0 \\rangle = (A^{[2]}_0)^\\dagger \\tilde{E}_1 A^{[2]}_1 = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & \\frac{1}{2} \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\frac{1}{2}\n$$\nThis confirms the correct value.\n\nFinally, we find the reduced density matrix $\\rho_1 = \\mathrm{Tr}_2(|\\psi_0\\rangle\\langle\\psi_0|)$. In the MPS formalism, this is related to the Schmidt decomposition derived from the SVD of the coefficient matrix $C = U S V^\\dagger$. The eigenvalues of $\\rho_1$ are the squares of the singular values of $C$. The singular values are the square roots of the eigenvalues of $C C^\\dagger = \\frac{1}{2}I$, which are $\\sigma_1^2 = \\sigma_2^2 = \\frac{1}{2}$. So the singular values are $s_1 = s_2 = \\frac{1}{\\sqrt{2}}$.\nThe eigenvalues of $\\rho_1$ are $\\lambda_{1,2} = s_{1,2}^2 = \\frac{1}{2}$. The eigenvectors of $\\rho_1$ are the corresponding Schmidt vectors, which are the rows of $U$. Since $C C^\\dagger$ is proportional to identity, we can choose $U=I$, giving eigenvectors $|0\\rangle$ and $|1\\rangle$.\n$$\n\\rho_1 = \\lambda_1 |0\\rangle\\langle 0| + \\lambda_2 |1\\rangle\\langle 1| = \\frac{1}{2}|0\\rangle\\langle 0| + \\frac{1}{2}|1\\rangle\\langle 1| = \\frac{1}{2} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nNormalization: $\\mathrm{Tr}(\\rho_1) = \\frac{1}{2}+\\frac{1}{2}=1$. The matrix is properly normalized.\nPositive semidefiniteness: The eigenvalues $\\frac{1}{2}, \\frac{1}{2}$ are all non-negative. The matrix is positive semidefinite.\n\nThe von Neumann entanglement entropy is $S = -\\mathrm{Tr}(\\rho_1 \\ln \\rho_1)$. Using the eigenvalues $\\lambda_i$ of $\\rho_1$:\n$$\nS = -\\sum_i \\lambda_i \\ln \\lambda_i = -\\left( \\frac{1}{2}\\ln\\left(\\frac{1}{2}\\right) + \\frac{1}{2}\\ln\\left(\\frac{1}{2}\\right) \\right) = - (2) \\left( \\frac{1}{2}\\ln\\left(\\frac{1}{2}\\right) \\right) = -\\ln\\left(\\frac{1}{2}\\right) = \\ln(2)\n$$\nThe entanglement entropy is $\\ln(2)$ nats, which is the maximum possible for a bipartition into two-level systems, indicating maximal entanglement.", "answer": "$$\n\\boxed{\\ln(2)}\n$$", "id": "2445466"}, {"introduction": "Having learned how to represent quantum states, we now turn our attention to operators. This practice introduces the Matrix Product Operator (MPO), the natural tensor network representation for Hamiltonians and other physical observables. You will construct an MPO that acts as a projector onto a subspace with a fixed total particle number, a common task in simulations with conserved quantities. This exercise illuminates how global constraints can be enforced through purely local tensor rules and a virtual \"counting\" index, a core principle that makes tensor network algorithms so powerful and versatile [@problem_id:2445471].", "problem": "Consider an open chain of length $L$ with local Hilbert space $\\{|0\\rangle, |1\\rangle\\}$ at each site, representing the occupation basis of spinless fermions with number operator $n_i$ satisfying $n_i |0\\rangle = 0 |0\\rangle$ and $n_i |1\\rangle = 1 |1\\rangle$. The global Hilbert space is the tensor product of the $L$ local spaces. The projector onto the fixed-total-particle-number sector with total number $N$ is the operator that acts as the identity on states with $\\sum_{i=1}^{L} n_i = N$ and annihilates all other states.\n\nUsing only fundamental definitions of a Matrix Product Operator (MPO) and the occupation basis, construct an explicit MPO representation of this projector by introducing a virtual bond index that encodes the running particle count. Your MPO must be specified by:\n- A bond space spanned by states labeled by integers from $0$ to $N$.\n- Left and right boundary vectors that enforce the total count to be exactly $N$.\n- A local site tensor that enforces counting consistency and diagonality in the occupation basis.\n\nThen, using your construction and first principles (no pre-existing counting formulas), compute the trace of this projector as a closed-form analytic expression in terms of $L$ and $N$. Provide only the final expression for the trace as your answer. No numerical evaluation is required, and no units are involved.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and contains sufficient information for a rigorous solution. We shall therefore proceed with the derivation.\n\nThe projector $P_N$ onto the subspace of states with a fixed total particle number $N$ is diagonal in the occupation number basis $\\{|s_1 s_2 \\dots s_L\\rangle\\}$, where $s_i \\in \\{0, 1\\}$ is the occupation number at site $i$. The operator can be written as:\n$$\nP_N = \\sum_{\\{s_i\\}} \\lambda(\\{s_i\\}) |s_1 \\dots s_L\\rangle \\langle s_1 \\dots s_L |\n$$\nwhere the eigenvalue $\\lambda(\\{s_i\\})$ is $1$ if the total particle number $\\sum_{i=1}^{L} s_i = N$, and $0$ otherwise.\n\nWe are tasked to construct a Matrix Product Operator (MPO) representation for $P_N$. In this representation, the eigenvalue $\\lambda(\\{s_i\\})$ is expressed as a product of matrices:\n$$\n\\lambda(\\{s_i\\}) = B_L M^{s_1} M^{s_2} \\cdots M^{s_L} B_R\n$$\nHere, $M^{s_i}$ is a matrix corresponding to the local physical state $|s_i\\rangle$, $B_L$ is a left boundary row vector, and $B_R$ is a right boundary column vector. The matrix products are taken over a virtual \"bond\" space.\n\nThe construction is based on a virtual index that tracks the running particle count.\n\n$1$. **Virtual Bond Space**:\nThe virtual bond space will be spanned by a basis of states $\\{|\\alpha\\rangle\\}$ where the index $\\alpha$ represents the number of particles counted so far. Since the total number of particles is fixed at $N$, the running count can range from $0$ to $N$. Any path where the running count exceeds $N$ is invalid. Thus, the virtual bond space has dimension $N+1$, with the index $\\alpha$ taking integer values from $0, 1, \\dots, N$.\n\n$2$. **Local Site Tensor**:\nThe local tensor at site $i$ is a collection of $(N+1) \\times (N+1)$ matrices, $\\{M^0, M^1\\}$, corresponding to the physical occupation states $|0\\rangle$ and $|1\\rangle$. The matrix elements $[M^s]_{\\alpha, \\beta}$ connect an incoming virtual state $|\\alpha\\rangle$ (representing the count up to site $i-1$) to an outgoing virtual state $|\\beta\\rangle$ (representing the count up to site $i$).\n- If site $i$ is unoccupied ($s_i=0$), the particle count does not change. Thus, the outgoing count $\\beta$ must equal the incoming count $\\alpha$. This defines the matrix $M^0$:\n$$\n[M^0]_{\\alpha, \\beta} = \\delta_{\\alpha, \\beta} \\quad \\text{for } \\alpha, \\beta \\in \\{0, 1, \\dots, N\\}\n$$\nThis matrix is the $(N+1) \\times (N+1)$ identity matrix, $I$.\n- If site $i$ is occupied ($s_i=1$), the particle count increases by one. The outgoing count $\\beta$ must be $\\alpha+1$. This defines the matrix $M^1$:\n$$\n[M^1]_{\\alpha, \\beta} = \\delta_{\\beta, \\alpha+1} \\quad \\text{for } \\alpha, \\beta \\in \\{0, 1, \\dots, N\\}\n$$\nThis matrix has elements equal to $1$ on the first upper sub-diagonal (i.e., $[M^1]_{k, k+1} = 1$) and zeros elsewhere. This is a nilpotent matrix, which we denote as $S_u$, the \"shift-up\" operator.\n\n$3$. **Boundary Vectors**:\n- The left boundary vector $B_L$ must enforce the initial condition that the particle count is $0$ before the first site. It is a $1 \\times (N+1)$ row vector that selects the virtual state $|\\alpha=0\\rangle$:\n$$\nB_L = \\begin{pmatrix} 1 & 0 & \\dots & 0 \\end{pmatrix} = e_0^T\n$$\n- The right boundary vector $B_R$ must enforce the final condition that the total particle count after the last site $L$ is exactly $N$. It is an $(N+1) \\times 1$ column vector that selects the virtual state $|\\alpha=N\\rangle$:\n$$\nB_R = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\end{pmatrix} = e_N\n$$\nWith this construction, the coefficient for any state $|\\{s_i\\}\\rangle$ is non-zero (and equal to $1$) if and only if the sequence of operators allows a path from virtual state $0$ to virtual state $N$. This occurs precisely when the number of $M^1$ matrices in the product equals $N$, corresponding to $\\sum s_i = N$.\n\nNow, we compute the trace of the projector, $\\text{Tr}(P_N)$. The trace is the sum of the diagonal elements over the entire physical Hilbert space:\n$$\n\\text{Tr}(P_N) = \\sum_{s_1=0}^1 \\sum_{s_2=0}^1 \\cdots \\sum_{s_L=0}^1 \\langle s_1 \\dots s_L | P_N | s_1 \\dots s_L \\rangle\n$$\nUsing the MPO form for the diagonal elements:\n$$\n\\text{Tr}(P_N) = \\sum_{\\{s_i\\}} (B_L M^{s_1} M^{s_2} \\cdots M^{s_L} B_R)\n$$\nDue to the structure of the sum, we can rearrange the terms:\n$$\n\\text{Tr}(P_N) = B_L \\left(\\sum_{s_1=0}^1 M^{s_1}\\right) \\left(\\sum_{s_2=0}^1 M^{s_2}\\right) \\cdots \\left(\\sum_{s_L=0}^1 M^{s_L}\\right) B_R\n$$\nLet us define the transfer matrix $T$ as the sum over local operators:\n$$\nT = \\sum_{s=0}^1 M^s = M^0 + M^1 = I + S_u\n$$\nThe trace is then given by the product:\n$$\n\\text{Tr}(P_N) = B_L T^L B_R = e_0^T (I+S_u)^L e_N\n$$\nThis expression corresponds to the matrix element at row $0$ and column $N$ of the matrix $(I+S_u)^L$.\nWe expand $(I+S_u)^L$ using the binomial theorem:\n$$\n(I+S_u)^L = \\sum_{k=0}^L \\binom{L}{k} I^{L-k} S_u^k = \\sum_{k=0}^L \\binom{L}{k} S_u^k\n$$\nThe matrix element is therefore:\n$$\n[ (I+S_u)^L ]_{0,N} = \\sum_{k=0}^L \\binom{L}{k} [S_u^k]_{0,N}\n$$\nLet us analyze the powers of the shift-up matrix $S_u$. The elements of $S_u$ are $[S_u]_{\\alpha, \\beta} = \\delta_{\\alpha, \\beta-1}$. The elements of its $k$-th power, $[S_u^k]_{\\alpha, \\beta}$, are given by:\n$$\n[S_u^k]_{\\alpha, \\beta} = \\delta_{\\alpha, \\beta-k}\n$$\nWe need the element $[S_u^k]_{0,N} = \\delta_{0, N-k}$. This element is $1$ if $k=N$ and $0$ otherwise.\nSubstituting this into the sum, only the term where $k=N$ survives:\n$$\n\\text{Tr}(P_N) = \\sum_{k=0}^L \\binom{L}{k} \\delta_{k,N} = \\binom{L}{N}\n$$\nThis result is valid for $0 \\le N \\le L$. If $N > L$, the condition $k=N$ is never met for $k \\in \\{0, \\dots, L\\}$, so the sum is zero, correctly reflecting that $\\binom{L}{N}=0$ in this case. The trace is the number of ways to choose $N$ sites out of $L$ to place the particles, which is the dimension of the projected-onto subspace.", "answer": "$$\\boxed{\\binom{L}{N}}$$", "id": "2445471"}, {"introduction": "A tensor network is not just a representation; it's a program for a calculation. The efficiency of this calculation depends critically on the sequence of operations, much like optimizing a series of matrix multiplications. This final practice confronts the fundamental computational challenge at the heart of all tensor network methods: finding the optimal contraction order. By exploring all possible contraction paths for small networks and finding the one with the lowest computational cost, you will develop an appreciation for a problem that is essential for unlocking the true potential of tensor networks in practical, large-scale simulations [@problem_id:2445469].", "problem": "You are given a family of pairwise tensor networks that are connected and closed, meaning every index label appears in exactly two tensors and the network contracts to a scalar. Each tensor is conceptually a complex-valued multidimensional array. Let there be a finite set of index labels $\\mathcal{L}$, with a dimension map $d : \\mathcal{L} \\to \\mathbb{N}$ assigning a strictly positive integer dimension $d_{\\ell}$ to each label $\\ell \\in \\mathcal{L}$. A tensor $t$ is specified by the set of labels $\\mathcal{I}_t \\subset \\mathcal{L}$ that index its modes. A pair of tensors $t_a$ and $t_b$ is contractible if and only if $\\mathcal{I}_{t_a} \\cap \\mathcal{I}_{t_b} \\neq \\varnothing$. The contraction of $t_a$ and $t_b$ along their common labels $S = \\mathcal{I}_{t_a} \\cap \\mathcal{I}_{t_b}$ produces a new tensor $t_{ab}$ whose label set is $\\mathcal{I}_{t_{ab}} = (\\mathcal{I}_{t_a} \\cup \\mathcal{I}_{t_b}) \\setminus S$. The process repeats until a single tensor with the empty label set remains, corresponding to a scalar.\n\nFor computational physics with tensor network state methods, a standard cost model counts Complex Multiply-Add (CMA) operations. For contracting two tensors $t_a$ and $t_b$, the CMA count is the product of the dimensions of all labels in the union of their index sets, namely\n$$\n\\mathrm{cost}(t_a, t_b) \\;=\\; \\prod_{\\ell \\in \\mathcal{I}_{t_a} \\cup \\mathcal{I}_{t_b}} d_{\\ell}.\n$$\nThe total CMA cost of a complete contraction sequence is the sum of these step costs over all binary contractions in the sequence. Your task is to write a complete program that, for each of several specified tensor networks, finds the minimal possible total CMA cost over all valid contraction orders.\n\nYour program must:\n- Parse a fixed, hard-coded test suite of tensor networks provided below.\n- For each test case, compute the minimal total CMA cost over all valid binary contraction orders that respect the rule that only tensors sharing at least one label may be contracted.\n- Output a single line containing a list of the minimal costs for all test cases, formatted exactly as a comma-separated list enclosed in square brackets.\n\nFundamental definitions you may assume:\n- A tensor network is a collection of tensors with labeled indices where each label represents a summation index if it appears in exactly two tensors.\n- The Contraction cost model counts Complex Multiply-Add (CMA) operations. A single contraction step cost equals the product of dimensions of the labels in the union of the two tensors being contracted. The total cost is additive over steps.\n\nTest suite to be used by your program:\n- Test case $1$:\n  - Dimensions: $d_i = 7$.\n  - Tensors: $t_1 = \\{i\\}$, $t_2 = \\{i\\}$.\n- Test case $2$:\n  - Dimensions: $d_x = 2$, $d_y = 3$, $d_z = 4$.\n  - Tensors: $t_1 = \\{x, z\\}$, $t_2 = \\{x, y\\}$, $t_3 = \\{y, z\\}$.\n- Test case $3$:\n  - Dimensions: $d_a = 2$, $d_b = 3$, $d_c = 5$, $d_d = 4$.\n  - Tensors: $t_1 = \\{a, b\\}$, $t_2 = \\{b, c\\}$, $t_3 = \\{c, d\\}$, $t_4 = \\{d, a\\}$.\n- Test case $4$:\n  - Dimensions: $d_a = 2$, $d_b = 3$, $d_c = 5$, $d_d = 4$, $d_e = 6$.\n  - Tensors: $t_1 = \\{a, b, e\\}$, $t_2 = \\{b, c\\}$, $t_3 = \\{c, d, e\\}$, $t_4 = \\{d, a\\}$.\n- Test case $5$:\n  - Dimensions: $d_x = 6$, $d_y = 1$, $d_z = 5$.\n  - Tensors: $t_1 = \\{x, z\\}$, $t_2 = \\{x, y\\}$, $t_3 = \\{y, z\\}$.\n\nAdditional requirements:\n- Your program must compute exact minimal costs by exploring valid contraction orders; heuristic approximations are not permitted for the final values.\n- Angles are not involved and no physical units are required in this problem.\n- The final output format must be a single line containing the results as a comma-separated list enclosed in square brackets (for example, $[c_1,c_2,\\dots]$), where each $c_k$ is an integer minimal CMA count for test case $k$.", "solution": "The problem as stated is subjected to validation.\n\n### Step 1: Extract Givens\n\n- **Tensor Network Structure**: A finite set of tensors forming a connected and closed network.\n- **Index Labels and Dimensions**: A finite set of labels $\\mathcal{L}$, with a dimension map $d: \\mathcal{L} \\to \\mathbb{N}$ where $d_{\\ell} \\ge 1$.\n- **Tensor Definition**: A tensor $t$ is defined by its set of index labels, $\\mathcal{I}_t \\subset \\mathcal{L}$.\n- **Contraction Rule**: A pair of tensors, $t_a$ and $t_b$, can be contracted if and only if their index sets have a non-empty intersection, i.e., $\\mathcal{I}_{t_a} \\cap \\mathcal{I}_{t_b} \\neq \\varnothing$.\n- **Result of Contraction**: The contraction of $t_a$ and $t_b$ yields a new tensor $t_{ab}$ with index set $\\mathcal{I}_{t_{ab}} = (\\mathcal{I}_{t_a} \\cup \\mathcal{I}_{t_b}) \\setminus (\\mathcal{I}_{t_a} \\cap \\mathcal{I}_{t_b})$, which is the symmetric difference $\\mathcal{I}_{t_a} \\Delta \\mathcal{I}_{t_b}$.\n- **Cost Model**: The cost of contracting $t_a$ and $t_b$, measured in Complex Multiply-Add (CMA) operations, is given by $\\mathrm{cost}(t_a, t_b) = \\prod_{\\ell \\in \\mathcal{I}_{t_a} \\cup \\mathcal{I}_{t_b}} d_{\\ell}$.\n- **Total Cost**: The total cost for a sequence of contractions is the sum of the costs of each individual binary contraction step.\n- **Objective**: To find the minimal total CMA cost over all possible valid binary contraction sequences for each given test case.\n- **Test Cases**:\n    - **Case 1**: Dimensions: $d_i = 7$. Tensors: $\\mathcal{I}_{t_1} = \\{i\\}$, $\\mathcal{I}_{t_2} = \\{i\\}$.\n    - **Case 2**: Dimensions: $d_x = 2, d_y = 3, d_z = 4$. Tensors: $\\mathcal{I}_{t_1} = \\{x, z\\}$, $\\mathcal{I}_{t_2} = \\{x, y\\}$, $\\mathcal{I}_{t_3} = \\{y, z\\}$.\n    - **Case 3**: Dimensions: $d_a = 2, d_b = 3, d_c = 5, d_d = 4$. Tensors: $\\mathcal{I}_{t_1} = \\{a, b\\}$, $\\mathcal{I}_{t_2} = \\{b, c\\}$, $\\mathcal{I}_{t_3} = \\{c, d\\}$, $\\mathcal{I}_{t_4} = \\{d, a\\}$.\n    - **Case 4**: Dimensions: $d_a = 2, d_b = 3, d_c = 5, d_d = 4, d_e = 6$. Tensors: $\\mathcal{I}_{t_1} = \\{a, b, e\\}$, $\\mathcal{I}_{t_2} = \\{b, c\\}$, $\\mathcal{I}_{t_3} = \\{c, d, e\\}$, $\\mathcal{I}_{t_4} = \\{d, a\\}$.\n    - **Case 5**: Dimensions: $d_x = 6, d_y = 1, d_z = 5$. Tensors: $\\mathcal{I}_{t_1} = \\{x, z\\}$, $\\mathcal{I}_{t_2} = \\{x, y\\}$, $\\mathcal{I}_{t_3} = \\{y, z\\}$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is analyzed against the validation criteria.\n\n- **Scientific Grounding**: The problem is well-grounded in computational physics and computer science. The optimization of tensor network contraction order is a canonical problem in these fields, essential for the efficiency of methods like the Density Matrix Renormalization Group (DMRG) and Matrix Product States (MPS). The specified CMA cost model is standard.\n- **Well-Posedness**: The problem is well-posed. For a finite number of tensors, there exists a finite, albeit large, number of valid contraction sequences. Each sequence has a deterministically calculable cost. Thus, a minimum cost is guaranteed to exist.\n- **Objectivity**: The problem is stated using precise, objective, mathematical language. All terms are either standard or explicitly defined.\n\nThe problem does not exhibit any of the invalidity flaws. It is scientifically sound, formalizable, complete, and feasible for the given test case sizes.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A solution will be provided.\n\n---\n\n### Solution\n\nThe problem requires finding the optimal sequence of pairwise contractions to minimize the total computational cost. This is a classic optimization problem, an NP-hard problem in the general case, but for the small number of tensors in the provided test cases, it can be solved exactly by systematically exploring all possible valid contraction paths. A brute-force exploration can be made efficient using dynamic programming with memoization.\n\nThe state of the system at any point during contraction is defined by the set of remaining tensors. Let $C(T)$ be the minimum cost to contract a set of tensors $T = \\{t_1, t_2, \\dots, t_k\\}$ into a single scalar. The base case is when there is only one tensor left, which means all contractions are complete, so the cost is $0$.\n\nIf $|T| > 1$, the total minimum cost $C(T)$ can be found by considering every possible first contraction step. A step consists of choosing two contractible tensors $t_i, t_j \\in T$ (i.e., where $\\mathcal{I}_{t_i} \\cap \\mathcal{I}_{t_j} \\neq \\varnothing$), calculating the cost of this contraction, and adding it to the minimum cost of contracting the subsequent set of tensors.\n\nThe recursive formula is:\n$$\nC(T) = \\min_{t_i, t_j \\in T, \\mathcal{I}_{t_i} \\cap \\mathcal{I}_{t_j} \\neq \\varnothing} \\left( \\mathrm{cost}(t_i, t_j) + C\\left((T \\setminus \\{t_i, t_j\\}) \\cup \\{t_{ij}\\}\\right) \\right)\n$$\nwhere $t_{ij}$ is the tensor resulting from the contraction of $t_i$ and $t_j$.\n\nTo implement this, a recursive function with memoization is employed. The function `find_min_cost(tensors, dims)` takes the current set of tensors and the dimension map.\n\n1.  **State Representation and Memoization**: The state is defined by the current set of tensors. To use a dictionary for memoization, the state must be a hashable type. A tuple of frozensets, where each frozenset represents the indices of a tensor, is a suitable representation. To ensure that the order of tensors does not produce different keys for the same set, the tuple is canonicalized, for instance, by sorting its elements based on a canonical representation of each frozenset.\n\n2.  **Recursive Step**: The function iterates through all unique pairs of tensors $(t_i, t_j)$ in the current set.\n    - It first checks if the pair is contractible by verifying that their index sets have a non-empty intersection.\n    - If they are contractible, it calculates the cost of this single step: $\\mathrm{cost}(t_i, t_j) = \\prod_{\\ell \\in \\mathcal{I}_{t_i} \\cup \\mathcal{I}_{t_j}} d_{\\ell}$.\n    - It then determines the resulting tensor $t_{ij}$, whose index set is the symmetric difference of the original two: $\\mathcal{I}_{t_{ij}} = \\mathcal{I}_{t_i} \\Delta \\mathcal{I}_{t_j}$.\n    - It forms the new set of tensors for the next recursive step by removing $t_i$ and $t_j$ and adding $t_{ij}$.\n    - It makes a recursive call with this new set of tensors to find the minimum cost for the remainder of the contraction.\n    - The total cost for this particular path is the sum of the current step's cost and the recursively computed cost.\n    - The function keeps track of the minimum total cost found across all possible valid pairs.\n\n3.  **Base Case**: The recursion terminates when the set of tensors contains only one element. At this point, the contraction is complete, and the cost of any further steps is $0$.\n\nThis algorithm guarantees finding the exact minimum cost by exhaustively exploring the search space of all valid binary contraction trees, while the memoization prunes redundant computations for identical subproblems. For each test case, the memoization cache is cleared, and the process begins with the initial set of tensors.", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\n# Memoization cache for the recursive function. It will be cleared for each test case.\n_memo = {}\n\ndef get_contraction_cost(t1_indices, t2_indices, dims):\n    \"\"\"\n    Calculates the CMA cost of contracting two tensors.\n    Cost is the product of dimensions of all indices in the union of the two tensors' index sets.\n    \"\"\"\n    union_indices = t1_indices.union(t2_indices)\n    # np.prod returns a numpy integer type. We convert to a standard Python int.\n    cost = np.prod([dims[idx] for idx in union_indices])\n    return int(cost)\n\ndef find_min_cost(tensors, dims):\n    \"\"\"\n    Recursively finds the minimum contraction cost for a given set of tensors.\n    Uses memoization to store results for previously seen sets of tensors.\n\n    Args:\n        tensors (tuple of frozenset): The current set of tensors, each represented by a frozenset of its indices.\n        dims (dict): A dictionary mapping index labels to their dimensions.\n\n    Returns:\n        int: The minimum cost to contract the given tensors to a scalar.\n    \"\"\"\n    global _memo\n\n    # Base case: if only one tensor remains, the contraction is finished.\n    if len(tensors) <= 1:\n        return 0\n\n    # Create a canonical, hashable representation of the current state for memoization.\n    # The key is a tuple of frozensets, sorted to ensure order doesn't matter.\n    # To sort frozensets, we sort them by a canonical form of their contents (a sorted tuple of elements).\n    state_key = tuple(sorted(tensors, key=lambda fs: tuple(sorted(list(fs)))))\n    if state_key in _memo:\n        return _memo[state_key]\n\n    min_total_cost = float('inf')\n\n    # Iterate over all unique pairs of tensors to find the next contraction.\n    for i, j in combinations(range(len(tensors)), 2):\n        t1 = tensors[i]\n        t2 = tensors[j]\n\n        # A contraction is only valid if the tensors share at least one index.\n        if not t1.isdisjoint(t2):\n            # Calculate the cost of this specific contraction step.\n            step_cost = get_contraction_cost(t1, t2, dims)\n\n            # The new tensor's indices are the symmetric difference of the two contracted tensors.\n            new_tensor = t1.symmetric_difference(t2)\n\n            # Form the new set of tensors for the recursive call.\n            next_tensors_list = [t for k, t in enumerate(tensors) if k != i and k != j]\n            next_tensors_list.append(new_tensor)\n            next_tensors = tuple(next_tensors_list)\n\n            # Recursively find the minimum cost for the remaining network and add the current step's cost.\n            total_cost_for_path = step_cost + find_min_cost(next_tensors, dims)\n\n            # Update the minimum cost found so far.\n            min_total_cost = min(min_total_cost, total_cost_for_path)\n\n    # Memoize the result for the current state.\n    _memo[state_key] = min_total_cost\n    return min_total_cost\n\ndef solve():\n    \"\"\"\n    Solves the tensor network contraction problem for the provided test suite.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        (\n            {'i': 7},\n            [{'i'}, {'i'}]\n        ),\n        # Test case 2\n        (\n            {'x': 2, 'y': 3, 'z': 4},\n            [{'x', 'z'}, {'x', 'y'}, {'y', 'z'}]\n        ),\n        # Test case 3\n        (\n            {'a': 2, 'b': 3, 'c': 5, 'd': 4},\n            [{'a', 'b'}, {'b', 'c'}, {'c', 'd'}, {'d', 'a'}]\n        ),\n        # Test case 4\n        (\n            {'a': 2, 'b': 3, 'c': 5, 'd': 4, 'e': 6},\n            [{'a', 'b', 'e'}, {'b', 'c'}, {'c', 'd', 'e'}, {'d', 'a'}]\n        ),\n        # Test case 5\n        (\n            {'x': 6, 'y': 1, 'z': 5},\n            [{'x', 'z'}, {'x', 'y'}, {'y', 'z'}]\n        ),\n    ]\n\n    results = []\n    for dims, initial_tensors_list in test_cases:\n        global _memo\n        _memo.clear()  # Ensure memoization cache is empty for each independent test case.\n\n        # Convert list of sets to tuple of frozensets for hashability.\n        initial_tensors = tuple(frozenset(t) for t in initial_tensors_list)\n\n        min_cost = find_min_cost(initial_tensors, dims)\n        results.append(min_cost)\n\n    # Print the results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2445469"}]}