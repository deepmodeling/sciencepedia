{"hands_on_practices": [{"introduction": "The Green-Kubo relations provide a powerful bridge between microscopic fluctuations and macroscopic transport properties. This first exercise allows you to put this theory into practice by calculating the self-diffusion coefficient $D$ directly from several model velocity autocorrelation functions (VACFs). By implementing this calculation, you will gain hands-on experience with the fundamental connection between particle dynamics and diffusion, and develop skills in numerical integration of time-series data.", "problem": "You will determine the self-diffusion coefficient of a light interstitial atom (e.g., hydrogen) in a heavy metal lattice (e.g., palladium) by deriving and evaluating an expression based on a time-correlation function. Start from first principles that connect particle displacement, velocity, and statistical stationarity, and derive a relation that expresses the self-diffusion coefficient in terms of a single-component velocity autocorrelation function. You must not assume any pre-stated transport formula; build the relation from the definitions of mean squared displacement and stationary time correlations. Then implement a numerical procedure to evaluate this relation for three synthetic, but physically plausible, single-component velocity autocorrelation functions at temperature $T$ for a particle of mass $m$. Each case defines $C(t)$, the single-component velocity autocorrelation function, such that $C(0) = \\langle v_x^2 \\rangle$ is fixed by equipartition of energy. Your implementation must use a uniform time grid and a convergent numerical quadrature on a finite domain chosen to control truncation error.\n\nFundamental base you may use:\n- The definition of the self-diffusion coefficient from the long-time limit of the mean squared displacement.\n- The relation between position and velocity as a time derivative.\n- Properties of stationary random processes and time-correlation functions.\n- Equipartition of energy for a single velocity component in thermal equilibrium.\n\nPhysical model and parameters:\n- Treat the heavy lattice as a thermal bath that renders the light interstitial atom’s single-component velocity a stationary stochastic process with a specified autocorrelation function $C(t)$.\n- Use temperature $T = 300$ K and the mass of hydrogen $m = 1.6735575 \\times 10^{-27}$ kg.\n- Boltzmann’s constant is $k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}$ J/K.\n- By equipartition, $C(0) = \\langle v_x^2 \\rangle = k_{\\mathrm{B}} T / m$.\n\nTest suite (three cases for $C(t)$):\n- Case A (single-exponential relaxation): $C(t) = C_0 \\exp(-t/\\tau)$ with $C_0 = k_{\\mathrm{B}} T / m$ and $\\tau = 0.04$ ps. Interpret picoseconds in seconds; that is, $1$ ps $= 10^{-12}$ s.\n- Case B (bi-exponential relaxation to model multi-timescale dynamics): $C(t) = C_0 \\left[a \\exp(-t/\\tau_1) + (1-a)\\exp(-t/\\tau_2)\\right]$ with $C_0 = k_{\\mathrm{B}} T / m$, $a = 0.7$, $\\tau_1 = 0.02$ ps, and $\\tau_2 = 0.2$ ps.\n- Case C (damped oscillatory correlation to mimic coupling to lattice vibrations): $C(t) = C_0 \\exp(-\\gamma t)\\cos(\\omega t)$ with $C_0 = k_{\\mathrm{B}} T / m$, $\\gamma = 1/(0.05$ ps$)$ in s$^{-1}$, and $\\omega = 2\\pi \\times 5 \\times 10^{12}$ rad/s.\n\nNumerical requirements:\n- Construct a uniform time grid from $t=0$ to $t=t_{\\max}$ chosen such that the neglected tail beyond $t_{\\max}$ is negligible for each case. A scientifically reasonable choice is $t_{\\max} \\geq 10$ times the largest decay time present (e.g., $\\max\\{\\tau,\\tau_1,\\tau_2,1/\\gamma\\}$), and, for oscillatory correlations, also several oscillation periods. The time step $\\Delta t$ must resolve the fastest scale present (e.g., the smallest of the decay times and the oscillation period).\n- Numerically evaluate the time integral of the derived expression using a convergent quadrature on the uniform grid (for example, composite Simpson’s rule or the trapezoidal rule with sufficient resolution).\n- All computations must be carried out in the International System of Units (SI). Express the final diffusion coefficients in m$^2$/s.\n\nWhat you must produce:\n1. A brief derivation (internally, in your own development; do not print it) leading to a computable integral expression connecting the self-diffusion coefficient to the single-component velocity autocorrelation function.\n2. A program that:\n   - Implements the three $C(t)$ definitions above, with the given numerical parameter values.\n   - Chooses a suitable time grid as specified and numerically evaluates the integral that yields the self-diffusion coefficient for each case.\n   - Outputs the three diffusion coefficients for cases A, B, and C, respectively, in m$^2$/s.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC]\"), in that order.\n- Each floating-point result must be printed in scientific notation with exactly six digits after the decimal point (for example, $9.900000\\mathrm{e}{-08}$), with no units included in the line; it is understood that the numbers are in m$^2$/s.\n\nThe test suite is the three cases listed above. The answer for each test case is a single real number (a float). The final printed line aggregates these three floats in the specified format and order.", "solution": "The problem statement presented is valid. It is scientifically grounded in the principles of statistical mechanics, specifically the Green-Kubo relations which connect macroscopic transport coefficients to the time integrals of microscopic correlation functions. The problem is well-posed, providing all necessary physical constants, parameters, and functional forms for the velocity autocorrelation function (VACF). The setup is internally consistent, objective, and computationally tractable. We shall now proceed with the solution.\n\nOur objective is to find the self-diffusion coefficient, denoted by $D$, from the single-component velocity autocorrelation function, $C(t) = \\langle v_x(t) v_x(0) \\rangle$. We begin from first principles.\n\nThe self-diffusion coefficient $D$ is defined in three dimensions by the long-time behavior of the mean squared displacement (MSD) of a particle:\n$$\nD = \\lim_{t \\to \\infty} \\frac{1}{6t} \\langle |\\mathbf{r}(t) - \\mathbf{r}(0)|^2 \\rangle\n$$\nwhere $\\mathbf{r}(t)$ is the particle's position vector at time $t$, and the angle brackets $\\langle \\dots \\rangle$ denote an ensemble average over equivalent systems in thermal equilibrium.\n\nThe particle's displacement vector $\\mathbf{r}(t) - \\mathbf{r}(0)$ is the time integral of its velocity vector $\\mathbf{v}(t)$:\n$$\n\\mathbf{r}(t) - \\mathbf{r}(0) = \\int_0^t \\mathbf{v}(t') dt'\n$$\nSubstituting this into the MSD expression gives:\n$$\n\\langle |\\mathbf{r}(t) - \\mathbf{r}(0)|^2 \\rangle = \\left\\langle \\left( \\int_0^t \\mathbf{v}(t') dt' \\right) \\cdot \\left( \\int_0^t \\mathbf{v}(t'') dt'' \\right) \\right\\rangle\n$$\nBy linearity of the integral and the expectation operator, we can write this as a double integral:\n$$\n\\text{MSD}(t) = \\int_0^t dt' \\int_0^t dt'' \\langle \\mathbf{v}(t') \\cdot \\mathbf{v}(t'') \\rangle\n$$\nThe term $\\langle \\mathbf{v}(t') \\cdot \\mathbf{v}(t'') \\rangle$ is the velocity autocorrelation function for the full velocity vector. For a stationary process, this correlation depends only on the time difference $\\tau = |t' - t''|$. In an isotropic system, the cross-correlations between different velocity components vanish on average, i.e., $\\langle v_i(t') v_j(t'') \\rangle = 0$ for $i \\neq j$. Furthermore, the autocorrelations for each component are identical: $\\langle v_x(t') v_x(t'') \\rangle = \\langle v_y(t') v_y(t'') \\rangle = \\langle v_z(t') v_z(t'') \\rangle$. Let the single-component VACF be $C(t' - t'') = \\langle v_x(t') v_x(t'') \\rangle$.\nThe full VACF is then:\n$$\n\\langle \\mathbf{v}(t') \\cdot \\mathbf{v}(t'') \\rangle = 3 \\langle v_x(t') v_x(t'') \\rangle = 3 C(t' - t'')\n$$\nThe problem, however, implicitly adopts a more common convention found in literature which stems from a slightly different starting point, arriving at a simpler final relation. Let us re-derive this carefully. The MSD can be written as $\\langle \\Delta x^2 + \\Delta y^2 + \\Delta z^2 \\rangle$. For an isotropic system, this is $3\\langle \\Delta x^2 \\rangle$. The one-dimensional MSD is:\n$$\n\\langle (x(t) - x(0))^2 \\rangle = \\int_0^t dt' \\int_0^t dt'' \\langle v_x(t') v_x(t'') \\rangle = \\int_0^t dt' \\int_0^t dt'' C(t' - t'')\n$$\nThis double integral over a square domain can be transformed to a single integral:\n$$\n\\langle (x(t) - x(0))^2 \\rangle = 2 \\int_0^t (t-\\tau) C(\\tau) d\\tau\n$$\nNow, we substitute this into the definition of $D$:\n$$\nD = \\lim_{t \\to \\infty} \\frac{1}{6t} \\langle |\\mathbf{r}(t) - \\mathbf{r}(0)|^2 \\rangle = \\lim_{t \\to \\infty} \\frac{3}{6t} \\langle (x(t) - x(0))^2 \\rangle = \\lim_{t \\to \\infty} \\frac{1}{2t} \\left( 2 \\int_0^t (t-\\tau) C(\\tau) d\\tau \\right)\n$$\n$$\nD = \\lim_{t \\to \\infty} \\left( \\int_0^t C(\\tau) d\\tau - \\frac{1}{t} \\int_0^t \\tau C(\\tau) d\\tau \\right)\n$$\nFor the diffusion coefficient to be a finite, non-zero constant, the VACF $C(\\tau)$ must decay to zero sufficiently fast such that its integral converges. Assuming $\\int_0^\\infty C(\\tau)d\\tau$ is a finite value, and that the integral $\\int_0^\\infty \\tau C(\\tau) d\\tau$ also converges, the second term vanishes as $t \\to \\infty$. This leaves the final expression, a cornerstone Green-Kubo relation:\n$$\nD = \\int_0^\\infty C(t) dt\n$$\nThis is the formula we must evaluate. The problem specifies that the initial value of the single-component VACF is determined by the equipartition theorem in one dimension: $C(0) = \\langle v_x^2 \\rangle = k_{\\mathrm{B}} T / m$.\n\nThe numerical evaluation of the integral $D = \\int_0^\\infty C(t) dt$ requires approximating the infinite upper limit with a finite cutoff, $t_{\\max}$. The integral is thus approximated as $D \\approx \\int_0^{t_{\\max}} C(t) dt$. The choice of $t_{\\max}$ must be large enough to ensure the contribution from the neglected tail $\\int_{t_{\\max}}^\\infty C(t) dt$ is negligible. The problem requires $t_{\\max}$ to be at least $10$ times the longest characteristic decay time. The characteristic timescales are: Case A: $\\tau = 0.04$ ps; Case B: $\\tau_2 = 0.2$ ps; Case C: $1/\\gamma = 0.05$ ps. The largest is $\\tau_2 = 0.2$ ps. Therefore, we must choose $t_{\\max} \\geq 10 \\times 0.2$ ps $= 2.0$ ps. A choice of $t_{\\max} = 2.5$ ps is sufficiently conservative.\n\nFor the numerical quadrature, we will construct a uniform time grid $t_i = i \\Delta t$ for $i=0, 1, \\dots, N$, where $t_N = t_{\\max}$. The time step $\\Delta t$ must be small enough to resolve the fastest dynamics. The fastest scales are $\\tau_1 = 0.02$ ps from Case B, and the oscillation period from Case C, $P = 1/(5 \\times 10^{12} \\text{ Hz}) = 0.2$ ps. The shortest characteristic time is $\\tau_1 = 0.02$ ps. A time step of $\\Delta t = 0.001$ ps provides $20$ points to resolve this fastest decay, which is adequate. This results in $N+1 = t_{\\max}/\\Delta t + 1 = 2.5/0.001 + 1 = 2501$ grid points. On this grid, we will evaluate the function $C(t_i)$ for each case and then use a convergent numerical integration method. We will employ the composite Simpson's rule, as implemented in `scipy.integrate.simpson`, which is well-suited for integrating sampled data on a uniform grid and is generally more accurate than the trapezoidal rule for smooth integrands.\n\nAll calculations must be performed in base SI units (meters, kilograms, seconds, Kelvin). The provided time constants in picoseconds ($1$ ps $= 10^{-12}$ s), decay rates, and frequencies must be converted accordingly. The final results for $D$ will be in m$^2$/s. The implementation will calculate $C_0 = k_{\\mathrm{B}} T / m$ and then evaluate the definite integral for each of the three specified forms of $C(t)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import simpson\n\ndef solve():\n    \"\"\"\n    Calculates the self-diffusion coefficient for three cases of a single-component\n    velocity autocorrelation function (VACF).\n    \"\"\"\n    # Physical constants in SI units\n    T = 300.0  # Temperature in Kelvin\n    M_H = 1.6735575e-27  # Mass of hydrogen in kg\n    K_B = 1.380649e-23  # Boltzmann's constant in J/K\n\n    # Conversion factor\n    PS_TO_S = 1e-12\n\n    # Calculate the initial value of the VACF, C(0), from equipartition theorem\n    c0 = (K_B * T) / M_H\n\n    # Define test case parameters\n    # Case A: Single-exponential relaxation\n    tau_A = 0.04 * PS_TO_S\n    # Case B: Bi-exponential relaxation\n    a_B = 0.7\n    tau1_B = 0.02 * PS_TO_S\n    tau2_B = 0.2 * PS_TO_S\n    # Case C: Damped oscillatory correlation\n    gamma_C = 1.0 / (0.05 * PS_TO_S)\n    omega_C = 2.0 * np.pi * 5.0e12\n\n    # Numerical integration parameters\n    # The longest decay timescale is tau2_B = 0.2 ps.\n    # Set t_max to be > 10 * 0.2 ps. We choose 2.5 ps.\n    t_max = 2.5 * PS_TO_S\n    # The fastest timescale is tau1_B = 0.02 ps.\n    # We choose dt to resolve this well. dt = 0.001 ps gives 20 points for 0.02 ps.\n    num_points = 2501  # Gives dt = t_max / (num_points - 1) = 1e-15 s = 0.001 ps\n    t = np.linspace(0, t_max, num_points)\n\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"func\": lambda t_vals: c0 * np.exp(-t_vals / tau_A)\n        },\n        {\n            \"name\": \"B\",\n            \"func\": lambda t_vals: c0 * (a_B * np.exp(-t_vals / tau1_B) + (1 - a_B) * np.exp(-t_vals / tau2_B))\n        },\n        {\n            \"name\": \"C\",\n            \"func\": lambda t_vals: c0 * np.exp(-gamma_C * t_vals) * np.cos(omega_C * t_vals)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Evaluate the VACF C(t) on the time grid\n        c_t = case[\"func\"](t)\n\n        # Numerically integrate C(t) from 0 to t_max using Simpson's rule\n        # D = integral from 0 to infinity of C(t) dt\n        diffusion_coeff = simpson(y=c_t, x=t)\n        results.append(diffusion_coeff)\n\n    # Format and print the final results as specified\n    formatted_results = [f\"{r:.6e}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2447051"}, {"introduction": "While the velocity autocorrelation function (VACF) gives us the diffusion coefficient, its shape contains even deeper information about the system's underlying dynamics. This practice challenges you to numerically solve the Volterra equation from the Mori-Zwanzig formalism to extract the memory kernel, $K(t)$, from a given VACF. Successfully completing this task will provide you with a powerful tool for analyzing the 'memory' effects that govern particle motion in a dense fluid.", "problem": "You are given the task of reconstructing the memory function $K(t)$ of a simple fluid from a known, numerically sampled velocity autocorrelation function (VACF), starting from first principles and proceeding through a principled discretization. The reconstruction must be achieved by numerically solving the Volterra convolution equation that links the normalized VACF to the memory kernel in the generalized Langevin equation. Your final program must be complete and runnable, and it must compute a quantitative error metric over a prescribed test suite.\n\nAssume the normalized velocity autocorrelation function (VACF), denoted $\\varphi(t)$, is defined by $\\varphi(t) \\equiv C_{vv}(t)/C_{vv}(0)$, where $C_{vv}(t) = \\langle \\mathbf{v}(t) \\cdot \\mathbf{v}(0) \\rangle$ and $C_{vv}(0) = \\langle \\mathbf{v}^{2} \\rangle$, and satisfies $\\varphi(0) = 1$. In thermal equilibrium for an isotropic fluid, $\\varphi(t)$ is an even function of time, so $\\varphi'(0) = 0$. The generalized Langevin equation (GLE) for the normalized VACF (a consequence of the Mori–Zwanzig projection formalism) leads to the following causal Volterra equation:\n$$\n\\frac{d\\varphi(t)}{dt} = - \\int_{0}^{t} K(t-\\tau)\\,\\varphi(\\tau)\\,d\\tau,\n$$\nwith $K(t)$ a real, causal memory kernel. Your task is to numerically reconstruct $K(t)$ from a discretely sampled $\\varphi(t)$.\n\nYou must:\n- Start from the above Volterra convolution equation and derive a numerically stable time-discrete algorithm to compute $K(t)$ on a uniform grid by combining a finite-difference approximation for $\\varphi'(t)$ and a Riemann-sum approximation for the time integral. You must employ a uniform time step $\\Delta t$ and a left Riemann sum for the integral. The resulting discrete scheme must yield a recursive computation for $K$ at grid times $t_n = n\\,\\Delta t$, for $n \\ge 1$, in terms of previously computed values.\n- Implement the algorithm to reconstruct $K(t)$ from numerically sampled $\\varphi(t)$.\n\nTo make the problem fully testable, generate synthetic $\\varphi(t)$ data internally using a physically consistent model memory kernel of the form\n$$\nK_{\\text{true}}(t) = a\\,e^{-b t},\n$$\nwith $a>0$ and $b>0$. For this choice, the normalized VACF is the solution of a linear, constant-coefficient, homogeneous second-order ordinary differential equation implied by the above Volterra equation. You may generate $\\varphi(t)$ on a grid either by using an exact closed-form solution of that ordinary differential equation or by integrating it numerically with sufficiently small time step so that discretization errors in $\\varphi(t)$ are negligible compared to the inversion error; in all cases, enforce $\\varphi(0)=1$ and $\\varphi'(0)=0$.\n\nNumerical specifications:\n- Use a uniform time step $\\Delta t = 10^{-3}$ and a total duration $T = 1.5$, so that the grid consists of $N+1$ points with $N = T/\\Delta t$ and $t_n = n\\,\\Delta t$ for $n=0,1,\\dots,N$.\n- Approximate $\\varphi'(t_n)$ using a second-order accurate finite difference wherever possible (central differences for interior points, and one-sided differences at the ends if needed).\n- Approximate the time integral in the Volterra equation using the left Riemann sum on the $\\tau$-grid so that only previously computed values of $K$ appear in the discrete equation at each time step.\n\nTest suite:\n- Use the following three parameter pairs $(a,b)$ for $K_{\\text{true}}(t) = a\\,e^{-b t}$:\n  - Case $1$: $(a,b) = (1.0,\\,1.5)$.\n  - Case $2$: $(a,b) = (0.25,\\,1.0)$.\n  - Case $3$: $(a,b) = (0.10,\\,1.0)$.\n- For each case, generate $\\varphi(t)$ on the prescribed time grid, reconstruct $K(t)$ numerically, and evaluate the reconstruction quality at the evaluation times $t \\in \\{0.01,\\,0.20,\\,0.50,\\,1.00\\}$ by comparing the reconstructed $K(t)$ to the true $K_{\\text{true}}(t)$.\n- For each case, compute a single scalar error as the root-mean-square of the absolute errors over the four specified evaluation times:\n$$\n\\varepsilon = \\sqrt{\\frac{1}{4}\\sum_{j=1}^{4}\\left| K_{\\text{num}}(t_j)-K_{\\text{true}}(t_j)\\right|^2 }.\n$$\n\nOutput requirements:\n- There are no physical units in this problem; all quantities are dimensionless by construction.\n- Your program must output a single line containing a list with three floating-point numbers, each the root-mean-square absolute error $\\varepsilon$ for one case, in the order of the cases above. The format must be exactly a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3]$, where each $r_k$ is a floating-point number.\n\nYour program must be fully self-contained and require no input. It must deterministically generate the synthetic $\\varphi(t)$ for the three cases, reconstruct $K(t)$ by numerically inverting the Volterra equation as specified, evaluate the errors at the given times, and print the final list. The algorithmic steps and approximations you implement must follow from the given fundamental equation and standard numerical analysis constructions, not from any undeclared shortcut formulas.", "solution": "The problem presented is a valid and well-posed exercise in computational physics. It is scientifically grounded in the Mori-Zwanzig formalism of statistical mechanics, specifically the Generalized Langevin Equation (GLE), which connects a time-correlation function to a memory kernel via a Volterra integral equation. The problem requires the numerical inversion of this equation, a standard task in the analysis of molecular dynamics simulation data. All parameters, methods, and constraints are clearly and objectively defined, forming a self-contained and verifiable problem. We shall therefore proceed with its solution.\n\nThe primary task is to reconstruct the memory function $K(t)$ from the normalized velocity autocorrelation function (VACF), $\\varphi(t)$, by numerically solving the causal Volterra equation of the first kind:\n$$\n\\frac{d\\varphi(t)}{dt} = - \\int_{0}^{t} K(t-\\tau)\\,\\varphi(\\tau)\\,d\\tau\n$$\nThe provided initial conditions are $\\varphi(0) = 1$ and $\\varphi'(0) = 0$.\n\nFirst, we derive the discrete algorithm for the reconstruction. We introduce a uniform time grid $t_n = n\\,\\Delta t$ for $n = 0, 1, 2, \\dots, N$, where $\\Delta t$ is the time step. Let $\\varphi_n = \\varphi(t_n)$ and $K_n = K(t_n)$. Evaluating the Volterra equation at $t=t_n$ gives:\n$$\n\\varphi'(t_n) = - \\int_{0}^{t_n} K(t_n-\\tau)\\,\\varphi(\\tau)\\,d\\tau\n$$\nWe discretize both the derivative and the integral. The derivative $\\varphi'(t_n)$ is approximated using a second-order accurate central finite difference for interior points ($n \\ge 1$ and $n < N$):\n$$\n\\varphi'(t_n) \\approx \\frac{\\varphi_{n+1} - \\varphi_{n-1}}{2\\,\\Delta t}\n$$\nThe integral is approximated using the specified left Riemann sum. The integration interval $[0, t_n]$ is divided into $n$ subintervals of width $\\Delta t$. The summation is over the points $\\tau_j = j\\,\\Delta t$ for $j=0, 1, \\dots, n-1$:\n$$\n\\int_{0}^{t_n} K(t_n-\\tau)\\,\\varphi(\\tau)\\,d\\tau \\approx \\sum_{j=0}^{n-1} K(t_n - \\tau_j)\\,\\varphi(\\tau_j)\\,\\Delta t = \\Delta t \\sum_{j=0}^{n-1} K(t_{n-j})\\,\\varphi(t_j) = \\Delta t \\sum_{j=0}^{n-1} K_{n-j}\\,\\varphi_j\n$$\nThis specific choice of a left sum is crucial, as it leads to a solvable recursive structure. Substituting the discrete approximations into the governing equation yields:\n$$\n\\frac{\\varphi_{n+1} - \\varphi_{n-1}}{2\\,\\Delta t} \\approx - \\Delta t \\sum_{j=0}^{n-1} K_{n-j}\\,\\varphi_j\n$$\nWe can separate the term containing the unknown $K_n$ from the sum. The sum is $K_n\\varphi_0 + K_{n-1}\\varphi_1 + \\dots + K_1\\varphi_{n-1}$.\n$$\n\\frac{\\varphi_{n+1} - \\varphi_{n-1}}{2\\,\\Delta t} \\approx - \\Delta t \\left( K_n\\varphi_0 + \\sum_{j=1}^{n-1} K_{n-j}\\,\\varphi_j \\right)\n$$\nWe can now solve for $K_n$. With the given condition $\\varphi_0 = \\varphi(0) = 1$, we arrive at the recursive formula for $n \\ge 1$:\n$$\nK_n \\approx -\\frac{\\varphi_{n+1} - \\varphi_{n-1}}{2\\,(\\Delta t)^2} - \\sum_{j=1}^{n-1} K_{n-j}\\,\\varphi_j\n$$\nThis formula allows for the sequential calculation of $K_1, K_2, K_3, \\dots$. For $n=1$, the sum is empty, giving $K_1 \\approx -(\\varphi_2 - \\varphi_0)/(2(\\Delta t)^2)$. For $n=2$, $K_2 \\approx -(\\varphi_3 - \\varphi_1)/(2(\\Delta t)^2) - K_1\\varphi_1$, and so on.\n\nNext, we address the generation of synthetic test data for $\\varphi(t)$. The problem specifies a true memory kernel $K_{\\text{true}}(t) = a\\,e^{-b t}$. To find the corresponding $\\varphi(t)$, we can transform the integro-differential equation into a pure ordinary differential equation (ODE). Differentiating the Volterra equation with respect to $t$ using the Leibniz integral rule gives:\n$$\n\\varphi''(t) = - \\frac{d}{dt} \\int_{0}^{t} K(t-\\tau)\\,\\varphi(\\tau)\\,d\\tau = - \\left( K(0)\\varphi(t) + \\int_{0}^{t} K'(t-\\tau)\\varphi(\\tau)\\,d\\tau \\right)\n$$\nFor $K(t) = a\\,e^{-b t}$, we have $K(0)=a$ and $K'(t) = -ab\\,e^{-b t} = -b K(t)$. Substituting these into the equation for $\\varphi''(t)$:\n$$\n\\varphi''(t) = -a\\varphi(t) - \\int_{0}^{t} [-b\\,K(t-\\tau)]\\varphi(\\tau)\\,d\\tau = -a\\varphi(t) + b\\int_{0}^{t} K(t-\\tau)\\varphi(\\tau)\\,d\\tau\n$$\nRecognizing that the remaining integral is equal to $-\\varphi'(t)$, we obtain a second-order linear homogeneous ODE with constant coefficients:\n$$\n\\varphi''(t) + b\\,\\varphi'(t) + a\\,\\varphi(t) = 0\n$$\nThis ODE must be solved with the initial conditions $\\varphi(0) = 1$ and $\\varphi'(0) = 0$. The solution depends on the roots of the characteristic equation $r^2 + b\\,r + a = 0$, which are $r_{1,2} = (-b \\pm \\sqrt{b^2 - 4a})/2$. We consider the three cases for the discriminant $\\Delta = b^2 - 4a$:\n\n1.  **Overdamped ($\\Delta > 0$):** $\\varphi(t) = \\frac{1}{r_1-r_2}(-r_2 e^{r_1 t} + r_1 e^{r_2 t})$. The test case $(a,b) = (0.10, 1.0)$ falls into this category since $1.0^2 - 4(0.10) = 0.6 > 0$.\n\n2.  **Critically Damped ($\\Delta = 0$):** $\\varphi(t) = (1 + \\frac{b}{2}t)e^{-bt/2}$. The test case $(a,b) = (0.25, 1.0)$ falls into this category since $1.0^2 - 4(0.25) = 0$.\n\n3.  **Underdamped ($\\Delta < 0$):** $\\varphi(t) = e^{-bt/2}\\left(\\cos(\\omega t) + \\frac{b}{2\\omega}\\sin(\\omega t)\\right)$, where $\\omega = \\frac{\\sqrt{4a - b^2}}{2}$. The test case $(a,b) = (1.0, 1.5)$ falls into this category since $1.5^2 - 4(1.0) = -1.75 < 0$.\n\nThe implementation will proceed as follows. For each test case $(a,b)$:\n1.  Set up the time grid with $\\Delta t = 10^{-3}$ and $T = 1.5$.\n2.  Generate the array of $\\varphi_n$ values by evaluating the appropriate analytical solution from the three cases above at each grid point $t_n$.\n3.  Compute the numerical memory kernel array $K_{\\text{num}}$ by applying the derived recursive formula iteratively for $n=1, \\dots, N-1$.\n4.  At the specified evaluation times $t_j \\in \\{0.01, 0.20, 0.50, 1.00\\}$, find the corresponding integer indices $n_j = t_j/\\Delta t$.\n5.  Calculate the root-mean-square error $\\varepsilon = \\sqrt{\\frac{1}{4}\\sum_{j=1}^{4}\\left| K_{\\text{num}}(t_{n_j}) - K_{\\text{true}}(t_j)\\right|^2}$.\nThis procedure is deterministic and directly implements the derived principles.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of reconstructing a memory kernel from a synthetic\n    velocity autocorrelation function (VACF) for three test cases and\n    computes the reconstruction error.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 1.5),  # Case 1\n        (0.25, 1.0), # Case 2\n        (0.10, 1.0), # Case 3\n    ]\n\n    # Numerical specifications\n    dt = 1e-3\n    T = 1.5\n    N = int(T / dt)\n    t_grid = np.linspace(0, T, N + 1)\n    \n    evaluation_times = np.array([0.01, 0.20, 0.50, 1.00])\n    evaluation_indices = (evaluation_times / dt).astype(int)\n\n    results = []\n    for a, b in test_cases:\n        # Step 1: Generate synthetic VACF data phi(t)\n        phi = generate_phi(a, b, t_grid)\n\n        # Step 2: Reconstruct the memory kernel K(t) numerically\n        K_num = reconstruct_K(phi, dt, N)\n\n        # Step 3: Evaluate the error\n        error = calculate_error(K_num, a, b, evaluation_times, evaluation_indices)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\ndef generate_phi(a, b, t_grid):\n    \"\"\"\n    Generates the normalized VACF phi(t) for a given memory kernel K(t) = a*exp(-b*t).\n    The function phi(t) is the solution to phi'' + b*phi' + a*phi = 0\n    with phi(0)=1, phi'(0)=0.\n    \"\"\"\n    discriminant = b**2 - 4 * a\n    \n    if discriminant > 0: # Overdamped case\n        sqrt_delta = np.sqrt(discriminant)\n        r1 = (-b + sqrt_delta) / 2\n        r2 = (-b - sqrt_delta) / 2\n        C1 = -r2 / (r1 - r2)\n        C2 = r1 / (r1 - r2)\n        phi = C1 * np.exp(r1 * t_grid) + C2 * np.exp(r2 * t_grid)\n    elif discriminant == 0: # Critically damped case\n        r = -b / 2\n        C1 = 1\n        C2 = -r\n        phi = (C1 + C2 * t_grid) * np.exp(r * t_grid)\n    else: # Underdamped case\n        omega = np.sqrt(4 * a - b**2) / 2\n        alpha = b / 2\n        C1 = 1\n        C2 = alpha / omega\n        phi = np.exp(-alpha * t_grid) * (C1 * np.cos(omega * t_grid) + C2 * np.sin(omega * t_grid))\n        \n    return phi\n\ndef reconstruct_K(phi, dt, N):\n    \"\"\"\n    Numerically reconstructs the memory kernel K(t) from phi(t)\n    using the derived recursive formula.\n    \"\"\"\n    K_num = np.zeros(N + 1)\n    dt_sq = dt**2\n\n    # The recursion is for n >= 1. We compute up to K_{N-1}\n    # as the derivative approximation needs phi_{n+1}.\n    for n in range(1, N):\n        # Derivative part: -(phi_{n+1} - phi_{n-1}) / (2 * dt^2)\n        derivative_part = -(phi[n + 1] - phi[n - 1]) / (2 * dt_sq)\n        \n        # Summation part: sum_{j=1}^{n-1} K_{n-j} * phi_j\n        # This is a discrete convolution.\n        sum_part = 0.0\n        if n > 1:\n            # Vectorized summation for efficiency\n            # K_indices from 1 to n-1. phi_indices from n-1 down to 1.\n            sum_part = np.dot(K_num[1:n], phi[n-1:0:-1])\n        \n        K_num[n] = derivative_part - sum_part\n        \n    return K_num\n\ndef calculate_error(K_num, a, b, eval_times, eval_indices):\n    \"\"\"\n    Calculates the root-mean-square error between the numerical\n    and true memory kernel at specified evaluation times.\n    \"\"\"\n    K_true_eval = a * np.exp(-b * eval_times)\n    K_num_eval = K_num[eval_indices]\n    \n    squared_errors = (K_num_eval - K_true_eval)**2\n    mean_squared_error = np.mean(squared_errors)\n    rms_error = np.sqrt(mean_squared_error)\n    \n    return rms_error\n\nsolve()\n```", "id": "2447068"}, {"introduction": "The accuracy of any transport coefficient calculated via the Green-Kubo relations depends critically on the quality of the input time-correlation function, which is typically generated from a molecular dynamics simulation. This practice moves from idealized calculation to practical methodology, challenging you to consider how the choice of a thermostat affects the very dynamics you aim to measure. By carefully evaluating different thermostatting strategies, you will develop the critical judgment necessary to ensure your simulations produce physically valid dynamic properties.", "problem": "A molecular dynamics researcher wishes to compute transport coefficients of a simple fluid at fixed temperature using equilibrium time-correlation functions and the Green–Kubo framework. Two thermostats are considered during equilibration and data collection: a deterministic Nosé–Hoover chain and a stochastic Langevin thermostat that applies independent white-noise and friction terms to each particle. Both thermostats are implemented so that the marginal equilibrium distribution of the physical coordinates and momenta is canonical at temperature $T$. The researcher is aware that the fluctuation–dissipation theorem connects linear response coefficients to spontaneous equilibrium fluctuations and is concerned about whether the choice and strength of the thermostat may bias the time-correlation functions needed for transport coefficients.\n\nWhich of the following statements and procedures are valid to ensure correct equilibrium fluctuations and unbiased Green–Kubo transport coefficients?\n\nA. If the thermostat samples the canonical distribution at temperature $T$, then any choice of Langevin friction coefficient $\\gamma$ or Nosé–Hoover coupling strength is acceptable for Green–Kubo calculations because the equal-time fluctuations determine the time-integrated correlations; distortion of the dynamics does not affect the final transport coefficient.\n\nB. For a deterministic Nosé–Hoover chain, one should verify ergodicity for the chosen system size, coupling, and time step. If ergodicity is uncertain, one may increase chain length or, more conservatively, equilibrate under the thermostat and then switch to microcanonical dynamics for correlation-function measurement to avoid thermostat-induced dynamical artifacts.\n\nC. For Langevin dynamics with particlewise coupling that breaks exact momentum conservation, to obtain unbiased transport coefficients that depend on hydrodynamic modes, one should either choose a friction coefficient $\\gamma$ much smaller than the inverse of the slowest relevant relaxation time or, preferably, perform equilibration with the thermostat and then collect correlation functions with the thermostat turned off. In all cases one must ensure that the noise and friction satisfy the fluctuation–dissipation relation at temperature $T$.\n\nD. Applying a thermostat solely to the center-of-mass degree of freedom preserves hydrodynamic modes but invalidates equilibrium fluctuations because the ensemble is no longer strictly canonical; therefore this practice must be avoided for Green–Kubo calculations even in large systems.\n\nE. When computing a transport coefficient from a microscopic flux that involves forces, if a thermostat exerts nonconservative forces on the particles, the thermostat contribution must be excluded from the definition of the microscopic flux used in the correlation function; otherwise the fluctuation–dissipation relation is violated by double-counting dissipation.\n\nSelect all that apply.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   **System**: A simple fluid.\n-   **Objective**: Compute transport coefficients using equilibrium time-correlation functions via the Green–Kubo framework.\n-   **Ensemble**: Fixed temperature $T$ (canonical ensemble).\n-   **Simulation Method**: Molecular dynamics.\n-   **Thermostats Considered**:\n    1.  A deterministic Nosé–Hoover chain.\n    2.  A stochastic Langevin thermostat with independent white-noise and friction on each particle.\n-   **Thermostat Condition**: Both thermostats are implemented to generate the canonical equilibrium distribution of physical coordinates and momenta.\n-   **Problem Context**: The researcher is concerned about the bias introduced by the choice and strength of the thermostat on the time-correlation functions used for calculating transport coefficients.\n-   **Theoretical Basis**: The fluctuation–dissipation theorem.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically grounded, well-posed, and objective. It addresses a standard, non-trivial issue in computational statistical mechanics: the influence of thermostats on the calculation of dynamic properties like transport coefficients. The concepts mentioned—Green–Kubo relations, Nosé–Hoover and Langevin thermostats, canonical distribution, and the fluctuation-dissipation theorem—are all standard and correctly contextualized. The problem is self-contained and free of scientific flaws, ambiguities, or contradictions.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A full solution will be derived.\n\nThe Green-Kubo relations connect a macroscopic transport coefficient, $\\Lambda$, to the time-integral of an equilibrium time-correlation function of a corresponding microscopic flux, $J$:\n$$ \\Lambda \\propto \\int_0^\\infty \\langle J(0) J(t) \\rangle_{eq} dt $$\nThe average $\\langle \\dots \\rangle_{eq}$ is over an equilibrium ensemble. A thermostat's primary role is to ensure that the static phase-space distribution sampled by the simulation is the canonical distribution, $P(\\mathbf{q}, \\mathbf{p}) \\propto \\exp(-\\beta H(\\mathbf{q}, \\mathbf{p}))$, where $\\beta = 1/(k_B T)$. This guarantees that equal-time correlations, such as $\\langle J(0)^2 \\rangle$, are correct.\n\nHowever, the dynamics, which govern the evolution of the flux from $J(0)$ to $J(t)$, are modified by the thermostat. The equations of motion are no longer purely Hamiltonian. For a particle $i$ with momentum $\\mathbf{p}_i$ and interparticle force $\\mathbf{F}_i^{\\text{int}}$, the equations of motion are altered:\n-   **Nosé-Hoover**: $\\dot{\\mathbf{p}}_i = \\mathbf{F}_i^{\\text{int}} - \\zeta \\mathbf{p}_i$, where $\\zeta$ is a dynamical friction variable.\n-   **Langevin**: $\\dot{\\mathbf{p}}_i = \\mathbf{F}_i^{\\text{int}} - \\gamma \\mathbf{p}_i + \\mathbf{R}_i(t)$, where $\\gamma$ is a friction coefficient and $\\mathbf{R}_i(t)$ is a stochastic force.\n\nThese non-Hamiltonian terms, $-\\zeta \\mathbf{p}_i$ and $-\\gamma \\mathbf{p}_i + \\mathbf{R}_i(t)$, directly interfere with the natural time evolution of the system. This interference can alter the decay of the time-correlation function $\\langle J(0) J(t) \\rangle$, thereby biasing the computed value of the transport coefficient $\\Lambda$. The validity of the statements must be judged based on this fundamental conflict.\n\n**Evaluation of Options**\n\n**A. If the thermostat samples the canonical distribution at temperature $T$, then any choice of Langevin friction coefficient $\\gamma$ or Nosé–Hoover coupling strength is acceptable for Green–Kubo calculations because the equal-time fluctuations determine the time-integrated correlations; distortion of the dynamics does not affect the final transport coefficient.**\n\nThis statement is fundamentally flawed. It correctly states that the thermostat samples the canonical distribution, which fixes the equal-time fluctuations ($\\langle J(0)^2 \\rangle$). However, it incorrectly concludes that this is sufficient. The transport coefficient is the *time-integral* of the correlation function, which is profoundly dependent on the system's dynamics for time $t>0$. A strong thermostat coupling (large $\\gamma$ or strong Nosé-Hoover coupling) will introduce artificial damping, causing correlations to decay much faster than in the unperturbed physical system. This leads to a systematic underestimation of the transport coefficient. The assertion that the distortion of dynamics is irrelevant is false.\n**Verdict: Incorrect.**\n\n**B. For a deterministic Nosé–Hoover chain, one should verify ergodicity for the chosen system size, coupling, and time step. If ergodicity is uncertain, one may increase chain length or, more conservatively, equilibrate under the thermostat and then switch to microcanonical dynamics for correlation-function measurement to avoid thermostat-induced dynamical artifacts.**\n\nThis statement describes established best practices. The single-variable Nosé-Hoover thermostat can suffer from non-ergodicity, particularly in stiff or small systems, by failing to sample the entire constant-energy surface. A Nosé-Hoover *chain* is a standard method to mitigate this problem, and increasing chain length generally improves ergodicity. Furthermore, the most rigorous method to compute dynamic properties is to avoid thermostat-induced artifacts altogether during the measurement phase. The procedure of equilibrating the system to the target temperature using a thermostat and then collecting data for the correlation function during a subsequent microcanonical (NVE) run is the gold standard. In a sufficiently large system, energy is conserved in the NVE run, and temperature fluctuations are minimal, so the dynamics accurately represent the unperturbed physical system.\n**Verdict: Correct.**\n\n**C. For Langevin dynamics with particlewise coupling that breaks exact momentum conservation, to obtain unbiased transport coefficients that depend on hydrodynamic modes, one should either choose a friction coefficient $\\gamma$ much smaller than the inverse of the slowest relevant relaxation time or, preferably, perform equilibration with the thermostat and then collect correlation functions with the thermostat turned off. In all cases one must ensure that the noise and friction satisfy the fluctuation–dissipation relation at temperature $T$.**\n\nThis statement is entirely correct and addresses several critical points regarding Langevin thermostats.\n1.  Applying independent friction and noise to each particle breaks total momentum conservation. This unnaturally damps long-wavelength collective motions (hydrodynamic modes), which are directly related to transport coefficients like shear viscosity.\n2.  Using a very small friction coefficient $\\gamma$ makes the thermostat's perturbation to the dynamics weak. If the thermostat's characteristic time scale, $\\tau_{\\gamma} \\sim 1/\\gamma$, is much longer than the relaxation time of the flux correlation function, its influence on the Green-Kubo integral will be small. This is a valid, though delicate, approach.\n3.  As in option B, the preferred method is to decouple the system from the thermostat during data collection by switching to an NVE simulation after equilibration.\n4.  Crucially, for the Langevin thermostat to generate a canonical distribution at temperature $T$, the magnitude of the stochastic force must be related to the friction coefficient $\\gamma$ and the temperature $T$ through the fluctuation-dissipation relation. This is a prerequisite for the thermostat's basic function.\n**Verdict: Correct.**\n\n**D. Applying a thermostat solely to the center-of-mass degree of freedom preserves hydrodynamic modes but invalidates equilibrium fluctuations because the ensemble is no longer strictly canonical; therefore this practice must be avoided for Green–Kubo calculations even in large systems.**\n\nThis statement contains a flawed conclusion. While it is true that thermostatting only the center-of-mass (CoM) does not generate a strictly canonical ensemble for the entire $3N$-dimensional phase space, its effect on the internal $3N-3$ degrees of freedom becomes negligible in the thermodynamic limit ($N \\to \\infty$). For a large system, energy exchange between the thermostatted CoM and the internal degrees of freedom is sufficient to maintain a state that is practically indistinguishable from canonical for the internal part. The great advantage of this method is that the equations of motion for the *relative* particle positions and momenta are purely Newtonian, thus preserving total momentum and leaving hydrodynamic modes unperturbed. Therefore, the statement that this practice \"must be avoided\" is incorrect; it can be a valid and useful technique, especially for large systems.\n**Verdict: Incorrect.**\n\n**E. When computing a transport coefficient from a microscopic flux that involves forces, if a thermostat exerts nonconservative forces on the particles, the thermostat contribution must be excluded from the definition of the microscopic flux used in the correlation function; otherwise the fluctuation–dissipation relation is violated by double-counting dissipation.**\n\nThis statement is correct and points to a subtle necessity. The microscopic fluxes $J$ in the Green-Kubo relations are physical quantities of the system, defined in terms of particle coordinates, momenta, and the *physical interparticle forces* ($\\mathbf{F}^{\\text{int}}$). The forces originating from the thermostat ($\\mathbf{F}^{\\text{thermo}}$) are part of the simulation algorithm used to maintain temperature; they are not part of the physical system whose transport properties one aims to measure. Including $\\mathbf{F}^{\\text{thermo}}$ in the definition of a flux, such as the stress tensor, would amount to calculating the properties of a different, artificial system. The conceptual argument about \"double-counting dissipation\" is apt: the Green-Kubo integral itself measures the system's intrinsic dissipative response through the decay of correlations. The thermostat forces are an *external* dissipative/fluctuating mechanism. Mixing the two is a fundamental error. The definition of $J$ must be based solely on the Hamiltonian of the physical system.\n**Verdict: Correct.**", "answer": "$$\n\\boxed{BCE}\n$$", "id": "2674588"}]}