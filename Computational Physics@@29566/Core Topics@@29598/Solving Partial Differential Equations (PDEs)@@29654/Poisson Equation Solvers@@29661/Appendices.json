{"hands_on_practices": [{"introduction": "Before we can confidently solve the full Poisson equation, it's crucial to correctly implement its fundamental building block: the discrete Laplacian operator. This practice takes an \"inverse\" approach by providing a known potential $\\phi$ and asking you to compute the source density $\\rho$ using the relation $\\rho = -\\nabla^2 \\phi$. This exercise allows you to directly verify your implementation of the finite-difference stencil and gain practical insight into the concept of truncation error [@problem_id:2427919].", "problem": "You are given a scalar potential map $\\phi(x,y)$ on a square domain $[0,1] \\times [0,1]$ sampled on a uniform Cartesian grid of size $n \\times n$ that includes the boundary points. Assume a dimensionless formulation in which the Poisson equation is\n$$\n\\nabla^{2}\\phi(x,y) = - \\rho(x,y).\n$$\nLet the grid spacing be $h = \\frac{1}{n-1}$ and the grid nodes be $x_i = i h$ and $y_j = j h$ for $i,j \\in \\{0,1,\\dots,n-1\\}$. Define the standard five-point discrete Laplacian operator on interior nodes $(i,j)$ with $i \\in \\{1,\\dots,n-2\\}$ and $j \\in \\{1,\\dots,n-2\\}$ by\n$$\n(\\Delta_h \\phi)_{i,j} = \\frac{\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4 \\phi_{i,j}}{h^{2}}.\n$$\nDefine the discrete source density on interior nodes by\n$$\n\\rho_{i,j}^{\\mathrm{comp}} = - (\\Delta_h \\phi)_{i,j}.\n$$\nFor each test case below, compute the maximum absolute error between the computed source density $\\rho_{i,j}^{\\mathrm{comp}}$ and the exact analytical source density $\\rho^{\\mathrm{exact}}(x_i,y_j)$ over all interior nodes,\n$$\nE = \\max_{1 \\le i \\le n-2,\\; 1 \\le j \\le n-2} \\left| \\rho_{i,j}^{\\mathrm{comp}} - \\rho^{\\mathrm{exact}}(x_i,y_j) \\right|.\n$$\nAll quantities are dimensionless. No physical units are required.\n\nTest suite:\n- Case $1$ (smooth trigonometric interior, nonzero source): $n = 33$, $\\phi(x,y) = \\sin(\\pi x)\\sin(\\pi y)$, $\\rho^{\\mathrm{exact}}(x,y) = 2\\pi^{2}\\sin(\\pi x)\\sin(\\pi y)$.\n- Case $2$ (quadratic polynomial, constant source): $n = 5$, $\\phi(x,y) = x^{2} + y^{2}$, $\\rho^{\\mathrm{exact}}(x,y) = -4$.\n- Case $3$ (bilinear polynomial, zero source): $n = 3$, $\\phi(x,y) = x y$, $\\rho^{\\mathrm{exact}}(x,y) = 0$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the three error values $E$ for the cases above, in the order listed, as a comma-separated list enclosed in square brackets, with each value rounded to $10$ decimal places (for example, $[0.1234567890,0.0000000000,0.0000012346]$).", "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extracted Givens**\n- Domain: A square domain $[0,1] \\times [0,1]$.\n- Grid: A uniform Cartesian grid of size $n \\times n$ containing all boundary points.\n- Grid Spacing: $h = \\frac{1}{n-1}$.\n- Grid Nodes: $(x_i, y_j)$ where $x_i = i h$ and $y_j = j h$ for $i,j \\in \\{0,1,\\dots,n-1\\}$.\n- Governing Equation: The Poisson equation, $\\nabla^{2}\\phi(x,y) = - \\rho(x,y)$.\n- Discrete Laplacian Operator: For interior nodes $(i,j)$ where $i,j \\in \\{1,\\dots,n-2\\}$, the five-point stencil is given by $(\\Delta_h \\phi)_{i,j} = \\frac{\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4 \\phi_{i,j}}{h^{2}}$.\n- Computed Source Density: $\\rho_{i,j}^{\\mathrm{comp}} = - (\\Delta_h \\phi)_{i,j}$.\n- Error Metric: The maximum absolute error over all interior nodes, $E = \\max_{1 \\le i \\le n-2,\\; 1 \\le j \\le n-2} \\left| \\rho_{i,j}^{\\mathrm{comp}} - \\rho^{\\mathrm{exact}}(x_i,y_j) \\right|$.\n- Test Cases:\n    1. $n = 33$, $\\phi(x,y) = \\sin(\\pi x)\\sin(\\pi y)$, $\\rho^{\\mathrm{exact}}(x,y) = 2\\pi^{2}\\sin(\\pi x)\\sin(\\pi y)$.\n    2. $n = 5$, $\\phi(x,y) = x^{2} + y^{2}$, $\\rho^{\\mathrm{exact}}(x,y) = -4$.\n    3. $n = 3$, $\\phi(x,y) = x y$, $\\rho^{\\mathrm{exact}}(x,y) = 0$.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is scientifically grounded. The Poisson equation is fundamental in physics, and the five-point stencil is a standard second-order accurate finite difference approximation of the Laplacian. The analytical relationship between the provided potential functions $\\phi(x,y)$ and exact source densities $\\rho^{\\mathrm{exact}}(x,y)$ is correct for all three test cases, as verified by direct computation of the continuous Laplacian:\n- For Case $1$: $\\nabla^2(\\sin(\\pi x)\\sin(\\pi y)) = -\\pi^2\\sin(\\pi x)\\sin(\\pi y) - \\pi^2\\sin(\\pi x)\\sin(\\pi y) = -2\\pi^2\\sin(\\pi x)\\sin(\\pi y)$, thus $\\rho^{\\mathrm{exact}} = - \\nabla^2\\phi = 2\\pi^2\\sin(\\pi x)\\sin(\\pi y)$.\n- For Case $2$: $\\nabla^2(x^2+y^2) = 2+2=4$, thus $\\rho^{\\mathrm{exact}} = - \\nabla^2\\phi = -4$.\n- For Case $3$: $\\nabla^2(xy) = 0+0=0$, thus $\\rho^{\\mathrm{exact}} = - \\nabla^2\\phi = 0$.\nThe problem is well-posed, objective, and contains all necessary information for a unique solution. It is a standard numerical methods exercise for verifying a discretization scheme.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A reasoned solution will be provided.\n\n**Principle-Based Solution**\n\nThe objective is to quantify the error of a finite difference approximation. The core of the problem lies in the difference between the continuous Laplacian operator, $\\nabla^2$, and its discrete approximation, $\\Delta_h$.\n\nThe discrete five-point Laplacian $(\\Delta_h \\phi)_{i,j}$ at a grid point $(x_i, y_j)$ is derived from Taylor series expansions. For a sufficiently smooth function $\\phi(x,y)$, the central difference approximation for the second partial derivative with respect to $x$ is:\n$$ \\frac{\\phi(x_i+h, y_j) - 2\\phi(x_i, y_j) + \\phi(x_i-h, y_j)}{h^2} = \\frac{\\partial^2\\phi}{\\partial x^2}\\bigg|_{(x_i,y_j)} + \\frac{h^2}{12}\\frac{\\partial^4\\phi}{\\partial x^4}\\bigg|_{(x_i,y_j)} + \\mathcal{O}(h^4) $$\nAn analogous expression holds for the partial derivative with respect to $y$. Summing these gives the approximation for the Laplacian:\n$$ (\\Delta_h \\phi)_{i,j} = \\nabla^2\\phi\\bigg|_{(x_i,y_j)} + \\frac{h^2}{12}\\left(\\frac{\\partial^4\\phi}{\\partial x^4} + \\frac{\\partial^4\\phi}{\\partial y^4}\\right)\\bigg|_{(x_i,y_j)} + \\mathcal{O}(h^4) $$\nThe leading term of the error in the approximation is called the truncation error, which is of order $h^2$.\n\nThe computed source density is $\\rho_{i,j}^{\\mathrm{comp}} = -(\\Delta_h \\phi)_{i,j}$, and the exact source density is $\\rho^{\\mathrm{exact}}(x_i,y_j) = -\\nabla^2\\phi|_{(x_i,y_j)}$. The point-wise error is therefore:\n$$ \\rho_{i,j}^{\\mathrm{comp}} - \\rho^{\\mathrm{exact}}(x_i,y_j) = -\\frac{h^2}{12}\\left(\\frac{\\partial^4\\phi}{\\partial x^4} + \\frac{\\partial^4\\phi}{\\partial y^4}\\right)\\bigg|_{(x_i,y_j)} - \\mathcal{O}(h^4) $$\nThe task is to compute the maximum of the absolute value of this error over the interior grid nodes.\n\n**Algorithmic Procedure:**\nFor each test case with given parameters $n$ and functions $\\phi(x,y)$ and $\\rho^{\\mathrm{exact}}(x,y)$:\n1.  Define the grid. The grid spacing is $h=1/(n-1)$, and the grid nodes are $x_i = i h$, $y_j = j h$ for $i,j \\in \\{0, \\dots, n-1\\}$.\n2.  Sample the potential. Construct an $n \\times n$ matrix $\\Phi$ where each element $\\Phi_{i,j} = \\phi(x_i, y_j)$.\n3.  Compute the source density. For each interior node $(i,j)$ where $i,j \\in \\{1, \\dots, n-2\\}$, calculate $\\rho_{i,j}^{\\mathrm{comp}}$ using the five-point stencil formula:\n    $$ \\rho_{i,j}^{\\mathrm{comp}} = -\\frac{\\Phi_{i+1,j} + \\Phi_{i-1,j} + \\Phi_{i,j+1} + \\Phi_{i,j-1} - 4\\Phi_{i,j}}{h^2} $$\n    This can be efficiently vectorized using array slicing.\n4.  Compute the error. Sample the exact source density $\\rho^{\\mathrm{exact}}(x_i, y_j)$ on the interior grid nodes. Calculate the absolute difference $|\\rho_{i,j}^{\\mathrm{comp}} - \\rho^{\\mathrm{exact}}(x_i, y_j)|$ for all interior nodes.\n5.  Find the maximum error $E$, which is the maximum value among all computed absolute differences.\n\n**Analysis of Test Cases:**\n- **Case 1**: $\\phi(x,y) = \\sin(\\pi x)\\sin(\\pi y)$. The fourth partial derivatives are non-zero: $\\frac{\\partial^4\\phi}{\\partial x^4} = \\pi^4\\phi(x,y)$ and $\\frac{\\partial^4\\phi}{\\partial y^4} = \\pi^4\\phi(x,y)$. The error is expected to be non-zero and proportional to $h^2$. With $n=33$, $h = 1/32$, the error should be small but non-negligible.\n- **Case 2**: $\\phi(x,y) = x^2 + y^2$. This is a quadratic polynomial. All partial derivatives of order three and higher are identically zero. The truncation error term $\\frac{h^2}{12}(\\dots)$ is zero. Therefore, the finite difference approximation is exact for this function. The error $E$ must be $0$, limited only by floating-point precision.\n- **Case 3**: $\\phi(x,y) = xy$. This is a bilinear polynomial. All partial derivatives of order two and higher are identically zero. Again, the truncation error is zero, and the finite difference formula is exact. The error $E$ must be $0$.\n\nThe implementation will follow this procedure for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_error(n, phi_func, rho_exact_func):\n    \"\"\"\n    Computes the maximum absolute error for a given test case.\n\n    Args:\n        n (int): The grid size (n x n).\n        phi_func (callable): A function for the scalar potential phi(x, y).\n        rho_exact_func (callable): A function for the exact source rho(x, y).\n\n    Returns:\n        float: The maximum absolute error E over the interior nodes.\n    \"\"\"\n    # 1. Define the grid.\n    if n < 3:\n        # No interior points for n < 3. Error is trivially 0.\n        return 0.0\n        \n    h = 1.0 / (n - 1)\n    # Create grid coordinates. 'ij' indexing ensures that the first index\n    # corresponds to x and the second to y, matching the problem's notation.\n    x = np.linspace(0.0, 1.0, n)\n    y = np.linspace(0.0, 1.0, n)\n    xx, yy = np.meshgrid(x, y, indexing='ij')\n\n    # 2. Sample the potential on the full grid.\n    phi_grid = phi_func(xx, yy)\n\n    # 3. Compute the source density on the interior grid.\n    # The five-point stencil is applied using vectorized numpy slicing.\n    # phi_grid[1:-1, 1:-1] corresponds to phi_ij for interior i,j\n    # phi_grid[2:, 1:-1]   corresponds to phi_{i+1,j}\n    # phi_grid[:-2, 1:-1]  corresponds to phi_{i-1,j}\n    # etc.\n    laplacian_phi_interior = (phi_grid[2:, 1:-1] + phi_grid[:-2, 1:-1] +\n                              phi_grid[1:-1, 2:] + phi_grid[1:-1, :-2] -\n                              4 * phi_grid[1:-1, 1:-1]) / (h**2)\n    \n    rho_comp_interior = -laplacian_phi_interior\n\n    # 4. Compute the error.\n    # Sample the exact source density on the interior grid.\n    rho_exact_interior = rho_exact_func(xx[1:-1, 1:-1], yy[1:-1, 1:-1])\n    \n    error_matrix = np.abs(rho_comp_interior - rho_exact_interior)\n\n    # 5. Find the maximum error.\n    max_error = np.max(error_matrix)\n    \n    return max_error\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Smooth trigonometric function\n        {\n            \"n\": 33,\n            \"phi_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"rho_exact_func\": lambda x, y: 2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n        },\n        # Case 2: Quadratic polynomial\n        {\n            \"n\": 5,\n            \"phi_func\": lambda x, y: x**2 + y**2,\n            \"rho_exact_func\": lambda x, y: -4.0 + 0 * x  # 0*x ensures array output\n        },\n        # Case 3: Bilinear polynomial\n        {\n            \"n\": 3,\n            \"phi_func\": lambda x, y: x * y,\n            \"rho_exact_func\": lambda x, y: 0.0 + 0 * x\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        error = calculate_error(\n            n=case[\"n\"],\n            phi_func=case[\"phi_func\"],\n            rho_exact_func=case[\"rho_exact_func\"]\n        )\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.10f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2427919"}, {"introduction": "A numerical solution is an approximation, and a key skill for any computational scientist is understanding and systematically reducing its error. This exercise introduces Richardson extrapolation, a powerful and general technique for improving solution accuracy by canceling the leading-order error term. By solving a problem on two grids of different resolutions and linearly combining the results, you will produce a significantly more accurate estimate, demonstrating the practical power of theoretical convergence analysis [@problem_id:2427894].", "problem": "You are given the mathematical task of computing numerical approximations to the solution of the two-dimensional Poisson problem in a square domain. Consider the Partial Differential Equation (PDE) $- \\nabla^2 u(x,y) = f(x,y)$ on the open unit square $\\Omega = (0,1) \\times (0,1)$ with homogeneous Dirichlet boundary conditions $u(x,y) = 0$ on $\\partial \\Omega$. For each prescribed pair of positive integers $(k,\\ell)$, define the exact solution $u^{\\star}(x,y) = \\sin(k \\pi x) \\sin(\\ell \\pi y)$, so that the source term is $f(x,y) = \\pi^2 (k^2 + \\ell^2) \\sin(k \\pi x) \\sin(\\ell \\pi y)$. Angles are in radians.\n\nFor each test case below, consider a uniform Cartesian grid of interior points with $N_{\\mathrm{c}}$ points per spatial direction and mesh spacing $h_{\\mathrm{c}} = 1/(N_{\\mathrm{c}}+1)$ on $\\Omega$. Also consider the finer grid with $N_{\\mathrm{f}} = 2 N_{\\mathrm{c}} + 1$ interior points per direction and mesh spacing $h_{\\mathrm{f}} = 1/(N_{\\mathrm{f}}+1) = h_{\\mathrm{c}}/2$. On each grid, compute a numerical approximation to $u(x,y)$ at the interior grid points using any consistent, second-order accurate spatial discretization on the stated uniform grids that enforces the homogeneous Dirichlet boundary condition.\n\nLet $U_{\\mathrm{c}}$ denote the numerical solution on the coarse grid, and let $U_{\\mathrm{f}}$ denote the numerical solution on the fine grid. Let $\\mathcal{I}$ be the set of coarse-grid interior nodes, and let $U_{\\mathrm{f}\\to\\mathrm{c}}$ denote the restriction of the fine-grid numerical solution to the subset of the fine grid that coincides with the coarse grid (that is, the subset of fine-grid interior nodes whose coordinates match those of nodes in $\\mathcal{I}$). Assume that the pointwise discretization error for the chosen second-order scheme admits an even-power asymptotic expansion in the mesh spacing $h$, with a leading nonzero term proportional to $h^2$ at each fixed grid point where the exact solution is smooth.\n\nFor each test case, compute the following three scalar quantities:\n- $E_{\\mathrm{c}}$, the discrete maximum-norm absolute error of the coarse-grid solution on $\\mathcal{I}$, defined by $E_{\\mathrm{c}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{c}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$.\n- $E_{\\mathrm{f}\\to\\mathrm{c}}$, the discrete maximum-norm absolute error of the fine-grid solution restricted to $\\mathcal{I}$, defined by $E_{\\mathrm{f}\\to\\mathrm{c}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{f}\\to\\mathrm{c}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$.\n- $E_{\\mathrm{comb}}$, the discrete maximum-norm absolute error on $\\mathcal{I}$ of a combined estimate formed at each $(x_i,y_j)\\in \\mathcal{I}$ from $U_{\\mathrm{c}}(x_i,y_j)$ and $U_{\\mathrm{f}\\to\\mathrm{c}}(x_i,y_j)$ in such a way that the leading-order term in the even-power truncation error expansion is eliminated under the above assumption. Report $E_{\\mathrm{comb}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{comb}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$.\n\nTest suite:\n- Case $1$: $(k,\\ell,N_{\\mathrm{c}}) = (1,1,15)$.\n- Case $2$: $(k,\\ell,N_{\\mathrm{c}}) = (2,1,7)$.\n- Case $3$: $(k,\\ell,N_{\\mathrm{c}}) = (3,2,21)$.\n\nYour program must produce a single line of output containing the results as a list of lists in the following order of cases and quantities: for each case in the order listed above, output the triple $[E_{\\mathrm{c}}, E_{\\mathrm{f}\\to\\mathrm{c}}, E_{\\mathrm{comb}}]$. The final printed line must be a single string representing the list of the three triples, for example, $[[a_{11},a_{12},a_{13}],[a_{21},a_{22},a_{23}],[a_{31},a_{32},a_{33}]]$, where each $a_{ij}$ is a floating-point number.\n\nAll floating-point numbers in the output must be printed in scientific notation with exactly eight digits after the decimal point.\n\nNo physical units are involved in this problem. Angles in all trigonometric functions must be in radians.", "solution": "The problem is scientifically and mathematically sound. It presents a well-posed boundary value problem for the Poisson equation and asks for its numerical solution and error analysis using standard, well-defined techniques. All necessary data and definitions are provided. We shall therefore proceed to the solution.\n\nThe core of the problem is to solve the two-dimensional Poisson equation\n$$\n- \\nabla^2 u(x,y) = f(x,y)\n$$\non the unit square domain $\\Omega = (0,1) \\times (0,1)$, subject to homogeneous Dirichlet boundary conditions, $u(x,y) = 0$ for $(x,y) \\in \\partial\\Omega$. The source term $f(x,y)$ is determined by the method of manufactured solutions, where the exact solution is prescribed as $u^{\\star}(x,y) = \\sin(k \\pi x) \\sin(\\ell \\pi y)$. Applying the negative Laplacian operator, we confirm the given source term:\n$$\n- \\nabla^2 u^{\\star}(x,y) = -\\left(\\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}\\right) \\left[ \\sin(k \\pi x) \\sin(\\ell \\pi y) \\right] = \\pi^2 (k^2+\\ell^2) \\sin(k \\pi x) \\sin(\\ell \\pi y) = f(x,y).\n$$\nThe problem requires a numerical solution using a second-order accurate spatial discretization on a uniform Cartesian grid. The standard choice for this is the five-point finite difference stencil. For a grid with uniform spacing $h$ in both $x$ and $y$ directions, the Laplacian at an interior grid node $(x_i, y_j)$ is approximated as:\n$$\n\\nabla^2 u(x_i, y_j) \\approx \\frac{U_{i+1,j} - 2U_{i,j} + U_{i-1,j}}{h^2} + \\frac{U_{i,j+1} - 2U_{i,j} + U_{i,j-1}}{h^2}.\n$$\nHere, $U_{i,j}$ denotes the numerical approximation to $u(x_i, y_j)$. Substituting this into the Poisson equation $- \\nabla^2 u = f$ and rearranging terms yields the discrete equation at each interior node $(i,j)$:\n$$\n4U_{i,j} - U_{i-1,j} - U_{i+1,j} - U_{i,j-1} - U_{i,j+1} = h^2 f(x_i, y_j).\n$$\nThis scheme is consistent and has a second-order truncation error, i.e., $O(h^2)$. The homogeneous Dirichlet boundary conditions $u=0$ are enforced by setting $U_{i,j} = 0$ whenever the node $(i,j)$ lies on the boundary $\\partial\\Omega$. For a grid with $N$ interior points in each direction, this set of $N^2$ linear algebraic equations can be assembled into a matrix system $A\\mathbf{U} = \\mathbf{b}$, where $\\mathbf{U}$ is a vector of the $N^2$ unknown values $U_{i,j}$, $A$ is a sparse, symmetric positive-definite block-tridiagonal matrix of size $N^2 \\times N^2$, and $\\mathbf{b}$ is a vector containing the values of $h^2 f(x_i, y_j)$ at the grid points. This system can be efficiently solved for $\\mathbf{U}$.\n\nThe problem requires the calculation of errors on a coarse grid with mesh spacing $h_{\\mathrm{c}}$ and a fine grid with spacing $h_{\\mathrm{f}} = h_{\\mathrm{c}}/2$. Furthermore, it requires a combined solution derived using Richardson extrapolation. The problem states that the pointwise error has an asymptotic expansion in even powers of $h$:\n$$\nU_h(x,y) = u^{\\star}(x,y) + C(x,y)h^2 + D(x,y)h^4 + \\dots\n$$\nLet $U_{\\mathrm{c}}$ be the solution on the coarse grid (spacing $h_{\\mathrm{c}}$) and $U_{\\mathrm{f}}$ be the solution on the fine grid (spacing $h_{\\mathrm{f}}$). At a point $(x,y)$ that is a node on both grids, we have:\n$$\nU_{\\mathrm{c}}(x,y) = u^{\\star}(x,y) + C(x,y)h_{\\mathrm{c}}^2 + O(h_{\\mathrm{c}}^4)\n$$\n$$\nU_{\\mathrm{f}}(x,y) = u^{\\star}(x,y) + C(x,y)h_{\\mathrm{f}}^2 + O(h_{\\mathrm{f}}^4) = u^{\\star}(x,y) + C(x,y)\\frac{h_{\\mathrm{c}}^2}{4} + O(h_{\\mathrm{c}}^4).\n$$\nWe can eliminate the leading error term $C(x,y)h_{\\mathrm{c}}^2$ by linearly combining these two equations. Multiplying the second equation by $4$ and subtracting the first equation gives:\n$$\n4U_{\\mathrm{f}}(x,y) - U_{\\mathrm{c}}(x,y) = 3u^{\\star}(x,y) + O(h_{\\mathrm{c}}^4).\n$$\nThis yields a more accurate estimate for $u^{\\star}(x,y)$, which we define as the combined solution $U_{\\mathrm{comb}}$:\n$$\nU_{\\mathrm{comb}}(x,y) = \\frac{4U_{\\mathrm{f}}(x,y) - U_{\\mathrm{c}}(x,y)}{3}.\n$$\nThe error of this combined solution is of order $O(h_{\\mathrm{c}}^4)$, an improvement over the $O(h_{\\mathrm{c}}^2)$ error of the original solutions. In our case, the comparison is made on the set of coarse grid nodes $\\mathcal{I}$. Thus, we use $U_{\\mathrm{f}\\to\\mathrm{c}}$, the restriction of the fine grid solution to these nodes, in the formula:\n$$\nU_{\\mathrm{comb}} = \\frac{4U_{\\mathrm{f}\\to\\mathrm{c}} - U_{\\mathrm{c}}}{3}.\n$$\nThe required quantities $E_{\\mathrm{c}}$, $E_{\\mathrm{f}\\to\\mathrm{c}}$, and $E_{\\mathrm{comb}}$ are the discrete maximum-norm absolute errors defined as $E = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$ for the respective numerical solutions $U_{\\mathrm{c}}$, $U_{\\mathrm{f}\\to\\mathrm{c}}$, and $U_{\\mathrm{comb}}$.\n\nThe algorithm proceeds as follows for each test case $(k,\\ell,N_{\\mathrm{c}})$:\n$1$. Define the coarse grid with $N_{\\mathrm{c}}$ interior points and spacing $h_{\\mathrm{c}} = 1/(N_{\\mathrm{c}}+1)$.\n$2$. Define the fine grid with $N_{\\mathrm{f}} = 2N_{\\mathrm{c}}+1$ interior points and spacing $h_{\\mathrm{f}} = h_{\\mathrm{c}}/2$.\n$3$. Solve the linear system $A_{\\mathrm{c}}\\mathbf{U}_{\\mathrm{c}} = \\mathbf{b}_{\\mathrm{c}}$ to obtain the coarse solution $U_{\\mathrm{c}}$.\n$4$. Solve the linear system $A_{\\mathrm{f}}\\mathbf{U}_{\\mathrm{f}} = \\mathbf{b}_{\\mathrm{f}}$ to obtain the fine solution $U_{\\mathrm{f}}$.\n$5$. Evaluate the exact solution $u^{\\star}$ on the coarse grid nodes.\n$6$. Restrict the fine solution $U_{\\mathrm{f}}$ to the coarse grid nodes to obtain $U_{\\mathrm{f}\\to\\mathrm{c}}$. This involves selecting every second point from the fine grid solution array.\n$7$. Compute the combined solution $U_{\\mathrm{comb}}$ on the coarse grid using the Richardson extrapolation formula.\n$8$. Calculate the maximum-norm errors $E_{\\mathrm{c}}$, $E_{\\mathrm{f}\\to\\mathrm{c}}$, and $E_{\\mathrm{comb}}$ by comparing $U_{\\mathrm{c}}$, $U_{\\mathrm{f}\\to\\mathrm{c}}$, and $U_{\\mathrm{comb}}$ with the exact solution $u^{\\star}$ on the coarse grid.\nThis procedure is repeated for all specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef setup_and_solve_poisson(N, k, l):\n    \"\"\"\n    Sets up and solves the 2D Poisson problem on an N x N interior grid using\n    a five-point finite difference scheme.\n\n    Args:\n        N (int): The number of interior grid points in each spatial direction.\n        k (int): Wavenumber in the x-direction for the manufactured solution.\n        l (int): Wavenumber in the y-direction for the manufactured solution.\n\n    Returns:\n        tuple: A tuple containing:\n            - U (np.ndarray): The 2D numerical solution array of shape (N, N).\n            - xx (np.ndarray): The 2D array of x-coordinates.\n            - yy (np.ndarray): The 2D array of y-coordinates.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    \n    # Create grid coordinates for interior points\n    x = np.linspace(h, 1.0 - h, N)\n    y = np.linspace(h, 1.0 - h, N)\n    xx, yy = np.meshgrid(x, y)\n    \n    # Evaluate the source term f(x,y) on the grid\n    f_grid = (np.pi**2 * (k**2 + l**2) * \n              np.sin(k * np.pi * xx) * np.sin(l * np.pi * yy))\n    \n    # Flatten the source term into the RHS vector b, using column-major (Fortran) order\n    b = h**2 * f_grid.flatten(order='F')\n    \n    # Construct the sparse matrix A for the 5-point stencil\n    N2 = N * N\n    \n    main_diag = np.full(N2, 4.0)\n    \n    # Off-diagonals for x-connections (indices i-1, i+1)\n    off_diag_x = np.full(N2 - 1, -1.0)\n    # Remove connections across column boundaries in the flattened vector\n    off_diag_x[N-1::N] = 0.0\n    \n    # Off-diagonals for y-connections (indices j-1, j+1)\n    off_diag_y = np.full(N2 - N, -1.0)\n    \n    diagonals = [main_diag, off_diag_x, off_diag_x, off_diag_y, off_diag_y]\n    offsets = [0, 1, -1, N, -N]\n    \n    # Create the sparse matrix in Compressed Sparse Row format for efficiency\n    A = sparse.diags(diagonals, offsets, shape=(N2, N2), format='csr')\n    \n    # Solve the linear system A*U = b\n    # Using spsolve from SciPy's sparse linear algebra library\n    u_vec = spsolve(A, b)\n    \n    # Reshape the solution vector back to a 2D grid, using the same column-major order\n    U = u_vec.reshape((N, N), order='F')\n    \n    return U, xx, yy\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 1, 15),\n        (2, 1, 7),\n        (3, 2, 21),\n    ]\n\n    all_results_str = []\n    \n    for case in test_cases:\n        k, l, Nc = case\n        \n        # Define fine grid parameters based on coarse grid\n        Nf = 2 * Nc + 1\n        \n        # Solve the PDE on the coarse grid\n        Uc, xc, yc = setup_and_solve_poisson(Nc, k, l)\n        \n        # Solve the PDE on the fine grid\n        Uf, _, _ = setup_and_solve_poisson(Nf, k, l)\n        \n        # Evaluate the exact solution on the coarse grid for error calculation\n        u_star_c = np.sin(k * np.pi * xc) * np.sin(l * np.pi * yc)\n        \n        # Restrict the fine grid solution to the coarse grid nodes.\n        # Coarse grid nodes correspond to odd-indexed nodes (1, 3, 5, ...) in the fine grid.\n        Uf_to_c = Uf[1::2, 1::2]\n        \n        # Apply Richardson extrapolation to get a higher-order accurate solution\n        # U_comb = U_f_to_c + (U_f_to_c - U_c) / (r^p - 1), where r=2, p=2.\n        U_comb = (4.0 * Uf_to_c - Uc) / 3.0\n        \n        # Calculate discrete maximum-norm absolute errors\n        Ec = np.max(np.abs(Uc - u_star_c))\n        Ef_to_c = np.max(np.abs(Uf_to_c - u_star_c))\n        E_comb = np.max(np.abs(U_comb - u_star_c))\n        \n        # Format the results for this case as specified (scientific notation, 8 decimal places)\n        case_result_str = f\"[{Ec:.8e},{Ef_to_c:.8e},{E_comb:.8e}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "2427894"}, {"introduction": "For large-scale problems, the computational cost of solving the linear system $A \\mathbf{u} = \\mathbf{b}$ can be prohibitive for direct methods, making iterative solvers essential. This practice explores the efficiency of these methods by comparing the slow, steady convergence of the simple Jacobi iteration to the dramatically faster convergence of a Chebyshev-accelerated scheme. You will see firsthand how leveraging the spectral properties of the matrix operator leads to superior algorithm performance, a core concept in high-performance scientific computing [@problem_id:2427931].", "problem": "Consider the two-dimensional Poisson problem on the unit square with homogeneous Dirichlet boundary conditions, posed as the discrete linear system $A \\mathbf{u} = \\mathbf{b}$ arising from a standard five-point finite difference discretization of $- \\Delta u = f$ on a uniform grid. Let there be $n$ interior points per coordinate direction, so that the grid spacing is $h = \\frac{1}{n+1}$ and the interior grid points are $(x_i, y_j)$ with $x_i = i h$, $y_j = j h$ for $i,j \\in \\{1, \\dots, n\\}$. Define the discrete operator by\n$$\n(A u)_{i,j} = \\frac{4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}}{h^2},\n$$\nwith the convention that $u_{i,j} = 0$ whenever $(i,j)$ lies outside $\\{1,\\dots,n\\} \\times \\{1,\\dots,n\\}$, corresponding to homogeneous Dirichlet boundary conditions.\n\nLet the exact analytic solution be $u(x,y) = \\sin(\\pi x) \\sin(\\pi y)$. Define the forcing as $f(x,y) = 2 \\pi^2 \\sin(\\pi x) \\sin(\\pi y)$ so that $- \\Delta u = f$ in the continuous sense. Construct $\\mathbf{b}$ by evaluating $f$ at the interior grid points: $b_{i,j} = f(x_i, y_j)$.\n\nLet $D$ denote the diagonal of $A$, which satisfies $D = \\frac{4}{h^2} I$. Consider two discrete-time iterative processes to approximate the solution $\\mathbf{u}$, both starting from the zero initial guess $\\mathbf{u}^{(0)} = \\mathbf{0}$ and using the residual $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{u}^{(k)}$ together with the preconditioned residual $M^{-1} \\mathbf{r}^{(k)} = D^{-1} \\mathbf{r}^{(k)} = \\frac{h^2}{4} \\mathbf{r}^{(k)}$:\n- Process J: $ \\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + D^{-1} \\mathbf{r}^{(k)}$.\n- Process C: $ \\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\alpha_k D^{-1} \\mathbf{r}^{(k)}$, where the step sizes $\\alpha_k$ are non-constant and depend on spectral bounds of the symmetric positive definite (SPD) matrix $D^{-1} A$. For the five-point Laplacian on the $n \\times n$ interior grid, the extremal eigenvalues of $D^{-1} A$ are\n$$\n\\lambda_{\\min} = 2 \\sin^2\\!\\left(\\frac{\\pi}{2 (n+1)}\\right), \\quad\n\\lambda_{\\max} = 2 \\cos^2\\!\\left(\\frac{\\pi}{2 (n+1)}\\right).\n$$\nDefine $c = \\frac{\\lambda_{\\max} + \\lambda_{\\min}}{2}$ and $\\delta = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{2}$. For a prescribed positive integer number of iterations $m$, choose, for $k \\in \\{1,\\dots,m\\}$,\n$$\n\\alpha_k = \\frac{1}{c - \\delta \\cos\\!\\left(\\frac{\\pi (2k - 1)}{2 m}\\right)},\n$$\nwith all angles understood to be in radians.\n\nFor each process, after exactly $m$ iterations, define the discrete Euclidean norm of the error as\n$$\n\\| e \\|_2 = \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( u^{(m)}_{i,j} - \\sin(\\pi x_i)\\sin(\\pi y_j) \\right)^2 \\right)^{1/2}.\n$$\n\nYour task is to compute, for each test case, the ratio $r = \\frac{\\| e \\|_{2,\\mathrm{C}}}{\\| e \\|_{2,\\mathrm{J}}}$, where $\\| e \\|_{2,\\mathrm{C}}$ and $\\| e \\|_{2,\\mathrm{J}}$ are the error norms after $m$ iterations of Process C and Process J, respectively. All trigonometric arguments must be in radians.\n\nTest Suite:\n- Test $1$: $n = 32$, $m = 40$.\n- Test $2$: $n = 8$, $m = 10$.\n- Test $3$: $n = 64$, $m = 1$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the three ratios for the test cases, in the order given above, each rounded to six decimal places, as a comma-separated list enclosed in square brackets (for example, $[0.123456,0.234567,0.345678]$). No other text should be printed.", "solution": "We discretize the two-dimensional Poisson equation $- \\Delta u = f$ on the unit square with homogeneous Dirichlet boundary conditions using a uniform grid with $n$ interior points in each spatial direction and mesh spacing $h = \\frac{1}{n+1}$. The standard five-point finite difference stencil yields the linear system $A \\mathbf{u} = \\mathbf{b}$ with\n$$\n(A u)_{i,j} = \\frac{4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}}{h^2},\n$$\nwhere indices outside the domain correspond to boundary values and are set to zero, consistently enforcing homogeneous Dirichlet boundary conditions. The continuous exact solution is $u(x,y) = \\sin(\\pi x) \\sin(\\pi y)$ and the forcing is $f(x,y) = 2 \\pi^2 \\sin(\\pi x) \\sin(\\pi y)$. The right-hand side vector is constructed by $b_{i,j} = f(x_i, y_j)$ with $x_i = i h$ and $y_j = j h$.\n\nWe consider iterative approximations to the solution, starting from $\\mathbf{u}^{(0)} = \\mathbf{0}$. Let $D$ be the diagonal of $A$, which for this operator is $D = \\frac{4}{h^2} I$. Define the residual at iteration $k$ by $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{u}^{(k)}$ and the preconditioned residual by $D^{-1}\\mathbf{r}^{(k)} = \\frac{h^2}{4} \\mathbf{r}^{(k)}$.\n\nProcess J is the classical Jacobi method expressed in preconditioned Richardson form,\n$$\n\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + D^{-1} \\mathbf{r}^{(k)}.\n$$\nThis arises from splitting $A = D - (L + U)$ and writing\n$$\n\\mathbf{u}^{(k+1)} = D^{-1} \\left( (L + U) \\mathbf{u}^{(k)} + \\mathbf{b} \\right) = \\mathbf{u}^{(k)} + D^{-1} (\\mathbf{b} - A \\mathbf{u}^{(k)}).\n$$\n\nProcess C is a non-stationary preconditioned Richardson iteration with iteration-dependent step sizes $\\alpha_k$ chosen to minimize the maximum error amplification over the spectrum of $D^{-1}A$, based on the minimax property of Chebyshev polynomials of the first kind. For the five-point Laplacian with homogeneous Dirichlet boundary conditions and $n$ interior points in each direction, the eigenvalues of $D^{-1} A$ are\n$$\n\\lambda_{i,j} = \\sin^2\\!\\left( \\frac{\\pi i}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi j}{2 (n+1)} \\right), \\quad i,j \\in \\{1,\\dots,n\\}.\n$$\nThus, the smallest and largest eigenvalues are\n$$\n\\lambda_{\\min} = \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right) = 2 \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right),\n$$\n$$\n\\lambda_{\\max} = \\sin^2\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) = 2 \\cos^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right),\n$$\nusing the identity $\\sin\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) = \\cos\\!\\left( \\frac{\\pi}{2 (n+1)} \\right)$. Let $c = \\frac{\\lambda_{\\max} + \\lambda_{\\min}}{2}$ and $\\delta = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{2}$. The Chebyshev semi-iteration of degree $m$ is realized by setting\n$$\n\\alpha_k = \\frac{1}{c - \\delta \\cos\\!\\left( \\frac{\\pi (2k - 1)}{2 m} \\right)}, \\quad k = 1, \\dots, m,\n$$\nand updating\n$$\n\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\alpha_k D^{-1} \\mathbf{r}^{(k)}.\n$$\nThis choice of $\\alpha_k$ is derived by mapping the spectrum interval $[\\lambda_{\\min}, \\lambda_{\\max}]$ to $[-1, 1]$, selecting nodes corresponding to the extrema of the Chebyshev polynomial $T_m$, and choosing the step sizes to minimize the maximal magnitude of the resulting degree-$m$ error polynomial on the spectral interval. Specifically, the error after $m$ steps can be expressed as\n$$\n\\mathbf{e}^{(m)} = p_m(D^{-1} A) \\mathbf{e}^{(0)},\n$$\nwith $p_m$ the degree-$m$ polynomial satisfying $p_m(0) = 1$ and minimizing $\\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |p_m(\\lambda)|$. The given $\\alpha_k$ produce this optimal $p_m$ via the product representation tied to the Chebyshev nodes.\n\nFor each process, after $m$ iterations, we compute the discrete Euclidean norm of the error\n$$\n\\| e \\|_2 = \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( u^{(m)}_{i,j} - \\sin(\\pi x_i)\\sin(\\pi y_j) \\right)^2 \\right)^{1/2},\n$$\nwhich directly compares the iterate to the analytic solution sampled at grid points. Although this norm mixes discretization error with iteration error, the comparison between Process C and Process J under identical discretization and iteration budget isolates the effect of the iteration process. The ratio\n$$\nr = \\frac{\\| e \\|_{2,\\mathrm{C}}}{\\| e \\|_{2,\\mathrm{J}}}\n$$\nquantifies the relative effectiveness of Process C versus Process J for the same $n$ and $m$.\n\nAlgorithmic realization proceeds by:\n- Constructing $u_{\\text{true}, i,j} = \\sin(\\pi x_i) \\sin(\\pi y_j)$ and $b_{i,j} = 2 \\pi^2 u_{\\text{true}, i,j}$ for interior points.\n- Implementing $A u$ via the five-point stencil with homogeneous Dirichlet boundary conditions, which can be handled by zero padding.\n- Iterating Process J: $u \\leftarrow u + \\frac{h^2}{4} (b - A u)$ for exactly $m$ steps.\n- Iterating Process C: with $\\lambda_{\\min}$ and $\\lambda_{\\max}$ as above, compute $c$ and $\\delta$, then for $k = 1, \\dots, m$, set $\\alpha_k = \\frac{1}{c - \\delta \\cos(\\frac{\\pi (2k - 1)}{2 m})}$ and update $u \\leftarrow u + \\alpha_k \\frac{h^2}{4} (b - A u)$.\n- Computing the error norms and their ratio.\n\nThe test suite covers a general case with moderate grid and iteration budget ($n = 32$, $m = 40$), a small grid case ($n = 8$, $m = 10$), and an edge case with a single iteration on a larger grid ($n = 64$, $m = 1$). The final program reports the three ratios rounded to six decimal places in the required format.", "answer": "```python\nimport numpy as np\n\ndef setup_problem(n):\n    # Grid spacing and coordinates\n    h = 1.0 / (n + 1)\n    i = np.arange(1, n + 1)\n    x = i * h\n    y = x.copy()\n    X, Y = np.meshgrid(x, y, indexing='ij')\n    # True solution and forcing\n    u_true = np.sin(np.pi * X) * np.sin(np.pi * Y)\n    f = 2.0 * (np.pi ** 2) * u_true\n    b = f  # Right-hand side at interior points\n    return h, u_true, b\n\ndef apply_A(u, h):\n    # Apply 5-point Laplacian stencil with homogeneous Dirichlet boundaries (zero outside)\n    up = np.pad(u, 1, mode='constant', constant_values=0.0)\n    Au = (4.0 * up[1:-1, 1:-1]\n          - up[0:-2, 1:-1] - up[2:, 1:-1]\n          - up[1:-1, 0:-2] - up[1:-1, 2:]) / (h * h)\n    return Au\n\ndef jacobi(u0, b, h, m):\n    # Jacobi expressed as preconditioned Richardson with D^{-1} = (h^2/4) I\n    u = u0.copy()\n    invD = (h * h) / 4.0\n    for _ in range(m):\n        r = b - apply_A(u, h)\n        u = u + invD * r\n    return u\n\ndef chebyshev(u0, b, h, n, m):\n    # Chebyshev semi-iteration with M=D (Jacobi preconditioning)\n    u = u0.copy()\n    invD = (h * h) / 4.0\n    theta = np.pi / (2.0 * (n + 1))\n    lam_min = 2.0 * (np.sin(theta) ** 2)\n    lam_max = 2.0 * (np.cos(theta) ** 2)\n    c = 0.5 * (lam_max + lam_min)\n    delta = 0.5 * (lam_max - lam_min)\n    # Perform exactly m steps with Chebyshev step sizes\n    for k in range(1, m + 1):\n        alpha = 1.0 / (c - delta * np.cos(np.pi * (2 * k - 1) / (2.0 * m)))\n        r = b - apply_A(u, h)\n        u = u + alpha * invD * r\n    return u\n\ndef error_ratio(n, m):\n    h, u_true, b = setup_problem(n)\n    u0 = np.zeros_like(u_true)\n    u_j = jacobi(u0, b, h, m)\n    u_c = chebyshev(u0, b, h, n, m)\n    err_j = np.linalg.norm(u_j - u_true)\n    err_c = np.linalg.norm(u_c - u_true)\n    # Avoid division by zero, though it should not occur for finite m > 0\n    ratio = err_c / err_j if err_j != 0.0 else float('inf')\n    return ratio\n\ndef solve():\n    # Define the test cases: (n, m)\n    test_cases = [\n        (32, 40),\n        (8, 10),\n        (64, 1),\n    ]\n    results = []\n    for n, m in test_cases:\n        r = error_ratio(n, m)\n        results.append(f\"{r:.6f}\")\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2427931"}]}