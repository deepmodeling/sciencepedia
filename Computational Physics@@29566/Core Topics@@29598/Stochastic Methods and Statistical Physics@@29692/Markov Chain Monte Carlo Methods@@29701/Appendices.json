{"hands_on_practices": [{"introduction": "The decision to accept or reject a proposed move is the fundamental step in any Metropolis-based MCMC algorithm. This exercise provides direct practice in calculating the acceptance probability, $\\alpha$, a core skill for understanding how these samplers explore a probability distribution. [@problem_id:1371728]", "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.", "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "A powerful MCMC sampler is one that explores the state space efficiently, but this is not always guaranteed. This exercise demonstrates a classic failure mode where strong correlations between variables cause a Gibbs-like sampler to take infinitesimally small steps, drastically slowing down convergence. Understanding this behavior is key to diagnosing and solving performance issues in practical MCMC applications. [@problem_id:1371718]", "problem": "Consider an iterative algorithm designed to locate the mode of a specific two-dimensional probability density function $p(x, y)$. The state of the algorithm at iteration $t$ is a point $(x_t, y_t)$ in the plane. A single full iteration, which transforms the state from $(x_t, y_t)$ to $(x_{t+1}, y_{t+1})$, consists of two sequential updates:\n\n1.  First, the $x$-coordinate is updated to a value $x'$ that maximizes the conditional density $p(x | y=y_t)$, while the $y$-coordinate is held constant. The state becomes $(x', y_t)$.\n2.  Second, the $y$-coordinate is updated to a value $y_{t+1}$ that maximizes the conditional density $p(y | x=x')$, while the new $x$-coordinate is held constant.\n\nThe state after one full iteration is thus $(x_{t+1}, y_{t+1}) = (x', y_{t+1})$.\n\nThe target probability distribution, $p(x, y)$, is a zero-mean bivariate normal distribution for two dimensionless variables $X$ and $Y$. Its covariance matrix is given by:\n$$ \\Sigma = \\begin{pmatrix} \\sigma^2  \\rho \\sigma^2 \\\\ \\rho \\sigma^2  \\sigma^2 \\end{pmatrix} $$\nwhere $\\sigma  0$ is the standard deviation for both variables and $\\rho$ is the correlation coefficient, with $0  \\rho  1$.\n\nFor a Gaussian distribution, the mode of a conditional distribution coincides with its mean. You are given that for this specific bivariate normal distribution, the conditional expectations are $E[X|Y=y] = \\rho y$ and $E[Y|X=x] = \\rho x$.\n\nThe algorithm is initialized at the point $(x_0, y_0) = (A, A)$, where $A$ is a non-zero real constant.\n\nCalculate the ratio $\\frac{D_1^2}{D_0^2}$, where $D_0^2$ is the initial squared Euclidean distance of the point from the mode at $(0,0)$, and $D_1^2$ is the squared Euclidean distance from the mode after one full iteration of the algorithm. Express your answer as a symbolic expression in terms of $\\rho$.", "solution": "The target density is a zero-mean bivariate normal with covariance matrix $\\Sigma=\\sigma^{2}\\begin{pmatrix}1  \\rho \\\\ \\rho  1\\end{pmatrix}$, with $0\\rho1$. For a Gaussian distribution, the conditional mode equals the conditional mean. Given $E[X\\mid Y=y]=\\rho y$ and $E[Y\\mid X=x]=\\rho x$, the algorithm updates are:\n1) From $(x_{0},y_{0})=(A,A)$, update the $x$-coordinate holding $y=y_{0}$: \n$$x'=\\arg\\max_{x}p(x\\mid y=y_{0})=E[X\\mid Y=y_{0}]=\\rho y_{0}=\\rho A.$$\n2) Holding $x=x'$, update the $y$-coordinate:\n$$y_{1}=\\arg\\max_{y}p(y\\mid x=x')=E[Y\\mid X=x']=\\rho x'=\\rho(\\rho A)=\\rho^{2}A.$$\nAfter one full iteration, the state is $(x_{1},y_{1})=(x',y_{1})=(\\rho A,\\rho^{2}A)$.\n\nThe initial squared Euclidean distance from the mode $(0,0)$ is\n$$D_{0}^{2}=x_{0}^{2}+y_{0}^{2}=A^{2}+A^{2}=2A^{2}.$$\nAfter one iteration, the squared distance is\n$$D_{1}^{2}=x_{1}^{2}+y_{1}^{2}=(\\rho A)^{2}+(\\rho^{2}A)^{2}=A^{2}\\left(\\rho^{2}+\\rho^{4}\\right).$$\nTherefore, the ratio is\n$$\\frac{D_{1}^{2}}{D_{0}^{2}}=\\frac{A^{2}\\left(\\rho^{2}+\\rho^{4}\\right)}{2A^{2}}=\\frac{\\rho^{2}+\\rho^{4}}{2}=\\frac{\\rho^{2}\\left(1+\\rho^{2}\\right)}{2}.$$", "answer": "$$\\boxed{\\frac{\\rho^{2}+\\rho^{4}}{2}}$$", "id": "1371718"}, {"introduction": "Moving from theory to practice, this capstone exercise challenges you to build a complete, adaptive MCMC sampler from the ground up. Manually tuning sampler parameters like the proposal step size is often inefficient; here, you will implement a modern algorithm that automatically adjusts its own parameters during a 'burn-in' phase to optimize performance. This hands-on coding task synthesizes the principles of detailed balance and stochastic approximation into a powerful computational tool. [@problem_id:2411370]", "problem": "Implement an adaptive Metropolis random-walk Markov Chain Monte Carlo (MCMC) algorithm that tunes a scalar proposal step size during a burn-in phase to achieve and maintain a target acceptance rate near a specified value. The target density is known only up to a normalization constant. Your implementation must be a complete, runnable program that takes no input and prints the required output. The algorithm must be justified from fundamental principles: (i) the Metropolis-Hastings construction from the detailed balance condition, and (ii) stochastic approximation to solve a root-finding problem for the acceptance rate. The objective is to design the adaptation so that it is confined to burn-in and leaves the stationary distribution unchanged during sampling.\n\nStart from the following fundamental base:\n- The transition kernel of a Markov chain with stationary density $\\pi(\\boldsymbol{x})$ must satisfy detailed balance, that is, for all states $\\boldsymbol{x}$ and $\\boldsymbol{y}$, $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$.\n- In the Metropolis-Hastings construction with proposal density $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$, the acceptance probability must be chosen so that detailed balance holds.\n- In adaptive schemes, parameter updates during burn-in can be posed as a stochastic approximation to solve an equation of the form $\\mathbb{E}[h(\\theta)] = 0$ with a diminishing step size.\n\nYour tasks are:\n1) Derive the Metropolis-Hastings acceptance probability for a symmetric Gaussian random-walk proposal $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ from the detailed balance condition and implement it in your code. You must justify the acceptance formula in your solution, starting from detailed balance, without relying on any unproven shortcut formulas.\n2) Derive and implement a Robbins-Monro-type stochastic approximation that updates the log step size $\\theta = \\log \\sigma$ at iteration $n$ during burn-in according to a diminishing step size sequence. The goal is to drive the expected acceptance probability toward a target value $a^\\star$. Your update must be on the log scale to preserve positivity of $\\sigma$, must use a diminishing gain of the form $\\gamma_n = c/(n+t_0)$ with constants $c  0$ and $t_0 \\ge 0$, and must be confined strictly to the burn-in phase. Clearly state the reasoning for this choice in your solution.\n3) After burn-in, freeze the tuned $\\sigma$ and generate samples. Compute the empirical acceptance rate over the sampling phase only. All acceptance rates must be reported as decimals in the unit interval.\n\nYou must implement and test your program on the following test suite. Each test specifies a target distribution, dimensionality, initial conditions, and a random seed. For reproducibility, use the specified seeds. The target acceptance rate is $a^\\star = 0.23$ in all cases.\n\n- Test A (one-dimensional standard Gaussian):\n  - Dimension $d = 1$.\n  - Target log-density: $\\log \\pi(x) = -\\tfrac{1}{2} x^2$.\n  - Initial position: $x_0 = 0$.\n  - Initial step size: $\\sigma_0 = 0.001$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 6000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $42$.\n\n- Test B (five-dimensional correlated Gaussian):\n  - Dimension $d = 5$.\n  - Target density: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$ with $\\Sigma_{ij} = \\rho^{|i-j|}$ and $\\rho = 0.8$.\n  - Initial position: $\\boldsymbol{x}_0 = \\boldsymbol{0}$.\n  - Initial step size: $\\sigma_0 = 10$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 8000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $123$.\n\n- Test C (two-dimensional Rosenbrock target with softened curvature):\n  - Dimension $d = 2$.\n  - Define the potential $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$.\n  - Target density: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$.\n  - Initial position: $\\boldsymbol{x}_0 = (0,\\,0)$.\n  - Initial step size: $\\sigma_0 = 1$.\n  - Burn-in iterations: $N_{\\mathrm{burn}} = 12000$.\n  - Sampling iterations: $N_{\\mathrm{sample}} = 12000$.\n  - Random seed: $2024$.\n\nAlgorithmic requirements:\n- Use a Gaussian random-walk proposal $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$ with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n- During burn-in only, update $\\theta_n = \\log \\sigma_n$ at each proposal via a Robbins-Monro step with $\\gamma_n = c/(n + t_0)$ for fixed constants $c$ and $t_0$, using the observed acceptance probability at that step.\n- After burn-in, fix $\\sigma$ and continue sampling without any further adaptation.\n- For stability, you may constrain $\\theta_n$ to a broad interval so that $\\sigma_n$ remains finite.\n\nOutput specification:\n- For each test, compute the empirical acceptance rate over the $N_{\\mathrm{sample}}$ sampling iterations only.\n- Your program must print a single line containing a list with the $3$ acceptance rates in the order A, B, C, each rounded to three decimal places, as decimals (no percentage signs), formatted exactly as: $[\\text{r}_A,\\text{r}_B,\\text{r}_C]$.\n\nNo physical units or angle units are involved in this problem. All numerical answers must be decimals. The output must be deterministic under the given seeds. The final program must be complete and runnable as is, with no input required, and must not access any external resources.", "solution": "The task is to implement an adaptive Metropolis random-walk Markov Chain Monte Carlo (MCMC) algorithm. The algorithm must tune its scalar proposal step size, $\\sigma$, during a burn-in phase to achieve a specified target acceptance rate, $a^\\star$. The theoretical foundations for the algorithm—the Metropolis-Hastings acceptance rule and the Robbins-Monro stochastic approximation for adaptation—must be derived from first principles.\n\n### Problem Validation\n\nFirst, we validate the problem statement.\n\n#### Step 1: Extract Givens\n\n- **Fundamental Principles**:\n    - Detailed balance: $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$.\n    - Metropolis-Hastings (M-H) construction: The transition kernel $P(\\boldsymbol{x},\\boldsymbol{y})$ is constructed from a proposal density $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ and an acceptance probability $\\alpha(\\boldsymbol{x},\\boldsymbol{y})$.\n    - Stochastic approximation: Parameter updates follow a scheme to solve $\\mathbb{E}[h(\\theta)] = 0$ with a diminishing step size.\n\n- **Tasks**:\n    1.  Derive the M-H acceptance probability for a symmetric Gaussian random-walk proposal, $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$, from detailed balance.\n    2.  Derive and implement a Robbins-Monro update for the log step size, $\\theta = \\log \\sigma$, to drive the acceptance rate to a target $a^\\star$. The update must use a gain $\\gamma_n = c/(n+t_0)$ and be confined to burn-in.\n    3.  Implement the full algorithm, fix $\\sigma$ after burn-in, and compute the empirical acceptance rate during the sampling phase.\n\n- **Algorithmic Requirements**:\n    - Proposal: Gaussian random-walk $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$ with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n    - Adaptation: Update $\\theta_n = \\log \\sigma_n$ via Robbins-Monro with gain $\\gamma_n = c/(n+t_0)$ during burn-in only.\n    - Sampling: Fix $\\sigma$ after burn-in.\n    - Target acceptance rate: $a^\\star = 0.23$ for all tests.\n\n- **Test Cases**:\n    - **Test A**: $d=1$, log-density $\\log \\pi(x) = -\\tfrac{1}{2} x^2$, $x_0 = 0$, $\\sigma_0 = 0.001$, $N_{\\mathrm{burn}} = 6000$, $N_{\\mathrm{sample}} = 12000$, seed $42$.\n    - **Test B**: $d=5$, $\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$ with $\\Sigma_{ij} = \\rho^{|i-j|}$ and $\\rho = 0.8$, $\\boldsymbol{x}_0 = \\boldsymbol{0}$, $\\sigma_0 = 10$, $N_{\\mathrm{burn}} = 8000$, $N_{\\mathrm{sample}} = 12000$, seed $123$.\n    - **Test C**: $d=2$, $\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$ where $U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$, $\\boldsymbol{x}_0 = (0,0)$, $\\sigma_0 = 1$, $N_{\\mathrm{burn}} = 12000$, $N_{\\mathrm{sample}} = 12000$, seed $2024$.\n\n- **Output Specification**: A single line with a list of three acceptance rates for tests A, B, C, rounded to three decimal places: $[\\text{r}_A,\\text{r}_B,\\text{r}_C]$.\n\n#### Step 2: Validate Using Extracted Givens\n\nThe problem is reviewed against the validation criteria.\n- **Scientifically Grounded**: The problem is based on established, fundamental principles of computational statistics and physics, namely MCMC theory, detailed balance, and stochastic approximation. The target distributions are standard benchmarks in the field. The problem is free from pseudoscience.\n- **Well-Posed**: The objectives are clear, all necessary parameters for each test case (dimensions, target densities, initial conditions, iteration counts, random seeds) are specified. The output format is precisely defined. The problem is deterministic given the seeds. A unique, meaningful solution is expected. The choice of the Robbins-Monro constants $c$ and $t_0$ is left to the implementer, which is a standard design decision, not a flaw.\n- **Objective**: The language is technical, precise, and unambiguous. There are no subjective or opinion-based statements.\n\nThe problem is self-contained, consistent, and scientifically sound. No flaws are identified.\n\n#### Step 3: Verdict and Action\n\nThe problem is valid. We proceed with the solution.\n\n### Derivation and Algorithm Design\n\n#### 1. Metropolis-Hastings Acceptance Probability\n\nThe goal is to construct a Markov chain with a stationary distribution $\\pi(\\boldsymbol{x})$. The transition kernel, $P(\\boldsymbol{x}, \\boldsymbol{y})$, which gives the probability density of moving from state $\\boldsymbol{x}$ to $\\boldsymbol{y}$, must satisfy the detailed balance condition:\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\nIn the Metropolis-Hastings framework, the transition is a two-step process: propose a new state $\\boldsymbol{y}$ from a proposal density $q(\\boldsymbol{y} \\mid \\boldsymbol{x})$, then accept it with probability $\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$. For $\\boldsymbol{x} \\neq \\boldsymbol{y}$, the transition kernel is $P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$. Substituting this into the detailed balance equation gives:\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\nThis implies the following constraint on the ratio of acceptance probabilities:\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\nThe standard Metropolis choice for the acceptance probability, which satisfies this condition, is:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\nThe problem specifies a symmetric Gaussian random-walk proposal: $\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$. The proposal density is:\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\nDue to the term $(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$, the proposal is symmetric, i.e., $q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$. The proposal terms in the acceptance ratio cancel out, yielding the simplified Metropolis acceptance probability:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\nSince the target density $\\pi(\\boldsymbol{x})$ is often known only up to a normalization constant, we compute this ratio using the unnormalized density or, more stably, its logarithm:\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\nThis is the formula to be implemented.\n\n#### 2. Adaptive Step Size using Stochastic Approximation\n\nThe goal is to adjust the proposal step size $\\sigma$ such that the expected acceptance rate matches a target value $a^\\star$. Let $\\theta = \\log \\sigma$ be the parameter to be tuned. The update is performed during the burn-in phase. We want to find the root of the function $g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$, where $\\alpha(\\theta)$ is the acceptance probability for a given $\\theta$.\n\nThe Robbins-Monro algorithm is a stochastic root-finding method. For a function $g(\\theta)$, we can find its root using the iterative scheme $\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$, where $g_n$ is a noisy observation of $g$ at step $n$ and $\\{\\gamma_n\\}$ is a sequence of step sizes satisfying $\\sum \\gamma_n = \\infty$ and $\\sum \\gamma_n^2  \\infty$.\n\nIn our case, we observe the acceptance probability $\\alpha_n$ at iteration $n$ and use this as our noisy measurement. The update rule for $\\theta_n = \\log\\sigma_n$ is formulated to guide the observed acceptance rate towards $a^\\star$:\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\nThe sign is positive because if the current acceptance rate $\\alpha_n$ is higher than the target $a^\\star$, we need to increase $\\theta$ (and thus $\\sigma$) to make proposals bolder and decrease the acceptance rate. Conversely, if $\\alpha_n  a^\\star$, we decrease $\\theta$ to make proposals more conservative and increase the acceptance rate.\n\nThe step size sequence (gain) is given as $\\gamma_n = c/(n + t_0)$ for $n \\geq 1$. We will select $c=1.0$ and $t_0=10.0$ as reasonable constants to ensure stability and effective adaptation. Updating on the log scale, $\\theta = \\log\\sigma$, naturally ensures that $\\sigma = \\exp(\\theta)$ remains positive.\n\nThis adaptation scheme makes the Markov chain non-homogeneous. To guarantee that the samples are drawn from the correct stationary distribution $\\pi(\\boldsymbol{x})$, the adaptation must be terminated after the burn-in phase. After $N_{\\mathrm{burn}}$ iterations, the step size $\\sigma$ is frozen at its final adapted value, and the subsequent $N_{\\mathrm{sample}}$ iterations proceed as a standard, homogeneous Metropolis MCMC algorithm. The ergodic theorem for Markov chains then ensures that averages computed from these samples converge to expectations with respect to $\\pi(\\boldsymbol{x})$.\n\n### Implementation Plan\n\nThe algorithm will be implemented in a function that takes the test case parameters. For each iteration from $n=1$ to $N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$:\n1.  Generate a proposal $\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$, with $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$.\n2.  Compute $\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$.\n3.  Draw $u \\sim U(0,1)$. If $u  \\alpha$, set $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$ and note an acceptance. Otherwise, set $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$.\n4.  If $n \\le N_{\\mathrm{burn}}$:\n    - Update $\\log \\sigma_n$ using the Robbins-Monro step: $\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$.\n    - For robustness, we will clip $\\log\\sigma$ to a reasonable range, e.g., $[-10, 10]$.\n5.  If $n  N_{\\mathrm{burn}}$:\n    - Keep $\\sigma$ fixed.\n    - Tally acceptances to compute the final empirical acceptance rate over the sampling phase.\n\nThis procedure will be applied to each of the three test cases using the specified parameters and random seeds.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```", "id": "2411370"}]}