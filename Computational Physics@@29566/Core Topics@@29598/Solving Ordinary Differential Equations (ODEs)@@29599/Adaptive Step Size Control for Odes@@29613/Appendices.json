{"hands_on_practices": [{"introduction": "To truly master adaptive step-size control, there is no substitute for building a solver from the ground up. This practice guides you through implementing and comparing two canonical strategies for local error estimation: the efficient embedded Runge-Kutta-Fehlberg (RKF45) method and the conceptually simpler step-doubling technique built upon a classical Runge-Kutta method. By comparing their performance in terms of total function evaluations, you will gain direct insight into the computational trade-offs that drive the design of modern ODE solvers [@problem_id:2372273].", "problem": "You are to write a complete program that compares two adaptive step-size strategies for integrating a scalar initial value problem of an ordinary differential equation. Consider an initial value problem of the form $y'(t)=f(t,y)$ with $y(t_0)=y_0$ on a finite interval $[t_0,t_f]$. For each test case below, integrate from $t_0$ to $t_f$ and produce two summaries, one for an embedded Runge–Kutta–Fehlberg $4(5)$ method and one for a step-doubling strategy built on the classical fourth-order Runge–Kutta method. For each strategy, report the total number of function evaluations and the arithmetic mean of the accepted step sizes.\n\nMathematical specifications that must be followed exactly for both strategies:\n- Error scaling: For a trial step from $(t,y)$ with stepsize $h$, define the scalar scale $s=\\max\\{|y|,|y_{\\mathrm{trial}}|\\}$, the tolerance $T=\\text{atol}+\\text{rtol}\\cdot s$, and an error estimate $E\\ge 0$ computed by the strategy. A trial step is accepted if and only if $E\\le T$. If accepted, update $(t,y)\\leftarrow (t+h,y_{\\mathrm{accept}})$. If the trial step would overshoot $t_f$, replace $h$ by $t_f-t$ before the trial.\n- Step-size update: Let the method’s effective local error order be $q=5$ so that the local error behaves as $\\mathcal{O}(h^q)$. After any trial (accepted or rejected), define the growth factor\n$$\ng=\n\\begin{cases}\n\\max(g_{\\min},\\min(g_{\\max},\\,\\sigma\\,(T/\\max(E,\\varepsilon))^{1/q} )), & E>0,\\\\\ng_{\\max}, & E=0,\n\\end{cases}\n$$\nwith fixed constants $\\sigma=0.9$, $g_{\\min}=0.2$, $g_{\\max}=5$, and $\\varepsilon=10^{-30}$. Then set the next trial step size to $h\\leftarrow \\max(h_{\\min},\\min(h_{\\max},g\\,h))$ with $h_{\\min}=10^{-12}$ and $h_{\\max}=t_f-t_0$. The initial step size must be $h_0=(t_f-t_0)/50$ for all test cases.\n- Angle unit: All occurrences of trigonometric functions use radians.\n\nEmbedded Runge–Kutta–Fehlberg $4(5)$ method details:\n- Use the classical Fehlberg coefficients with $6$ stages. Given $h$, the internal stages are\n$$\n\\begin{aligned}\nk_1&=f(t, y),\\\\\nk_2&=f\\!\\left(t+\\tfrac{1}{4}h,\\,y+h\\left(\\tfrac{1}{4}k_1\\right)\\right),\\\\\nk_3&=f\\!\\left(t+\\tfrac{3}{8}h,\\,y+h\\left(\\tfrac{3}{32}k_1+\\tfrac{9}{32}k_2\\right)\\right),\\\\\nk_4&=f\\!\\left(t+\\tfrac{12}{13}h,\\,y+h\\left(\\tfrac{1932}{2197}k_1-\\tfrac{7200}{2197}k_2+\\tfrac{7296}{2197}k_3\\right)\\right),\\\\\nk_5&=f\\!\\left(t+h,\\,y+h\\left(\\tfrac{439}{216}k_1-8k_2+\\tfrac{3680}{513}k_3-\\tfrac{845}{4104}k_4\\right)\\right),\\\\\nk_6&=f\\!\\left(t+\\tfrac{1}{2}h,\\,y+h\\left(-\\tfrac{8}{27}k_1+2k_2-\\tfrac{3544}{2565}k_3+\\tfrac{1859}{4104}k_4-\\tfrac{11}{40}k_5\\right)\\right).\n\\end{aligned}\n$$\nThe fourth- and fifth-order trial solutions are\n$$\n\\begin{aligned}\ny_4&=y+h\\left(\\tfrac{25}{216}k_1+\\tfrac{1408}{2565}k_3+\\tfrac{2197}{4104}k_4-\\tfrac{1}{5}k_5\\right),\\\\\ny_5&=y+h\\left(\\tfrac{16}{135}k_1+\\tfrac{6656}{12825}k_3+\\tfrac{28561}{56430}k_4-\\tfrac{9}{50}k_5+\\tfrac{2}{55}k_6\\right).\n\\end{aligned}\n$$\nUse $y_{\\mathrm{trial}}=y_5$, $y_{\\mathrm{accept}}=y_5$, and error estimate $E=|y_5-y_4|$. Count exactly $6$ function evaluations per trial step (regardless of acceptance).\n\nStep-doubling strategy (based on the classical fourth-order Runge–Kutta method):\n- The classical fourth-order Runge–Kutta step for step size $h$ is\n$$\n\\begin{aligned}\nK_1&=f(t,y),\\quad K_2=f\\!\\left(t+\\tfrac{h}{2},y+\\tfrac{h}{2}K_1\\right),\\quad K_3=f\\!\\left(t+\\tfrac{h}{2},y+\\tfrac{h}{2}K_2\\right),\\\\\nK_4&=f\\!\\left(t+h,y+hK_3\\right),\\quad \\Phi_h(y)=y+\\tfrac{h}{6}\\left(K_1+2K_2+2K_3+K_4\\right).\n\\end{aligned}\n$$\nFor each trial step, compute $y^{(1)}=\\Phi_h(y)$ and $y^{(2)}=\\Phi_{h/2}(\\Phi_{h/2}(y))$. Use $y_{\\mathrm{trial}}=y^{(2)}$, $y_{\\mathrm{accept}}=y^{(2)}$, and the Richardson error estimate\n$$\nE=\\frac{|\\,y^{(2)}-y^{(1)}\\,|}{2^4-1}=\\frac{|\\,y^{(2)}-y^{(1)}\\,|}{15}.\n$$\nCount exactly $12$ function evaluations per trial step (one full step costing $4$ evaluations plus two half steps costing $8$ evaluations), regardless of acceptance.\n\nTest suite:\nFor each case $i\\in\\{1,2,3\\}$ below, the program must run both strategies with the same $(t_0,t_f,y_0,\\text{rtol},\\text{atol})$ and produce the outputs specified under “Required final output format.”\n- Case $1$ (smooth linear): $f(t,y)=-2y+t$, $t_0=0$, $t_f=10$, $y_0=1$, $\\text{rtol}=10^{-6}$, $\\text{atol}=10^{-9}$.\n- Case $2$ (oscillatory forcing, radians): $f(t,y)=50\\cos(50t)-y$, $t_0=0$, $t_f=2$, $y_0=0$, $\\text{rtol}=10^{-5}$, $\\text{atol}=10^{-7}$.\n- Case $3$ (logistic growth): $f(t,y)=y(1-y)$, $t_0=0$, $t_f=10$, $y_0=10^{-6}$, $\\text{rtol}=10^{-7}$, $\\text{atol}=10^{-12}$.\n\nRequired final output format:\nYour program should produce a single line of output containing a list with three entries (one per test case), where each entry is the list\n$$\n[\\;N_{\\mathrm{RKF45}},\\;N_{\\mathrm{SD}},\\;\\overline{h}_{\\mathrm{RKF45}},\\;\\overline{h}_{\\mathrm{SD}}\\;],\n$$\nwith $N_{\\mathrm{RKF45}}$ the total number of function evaluations used by the embedded Runge–Kutta–Fehlberg method, $N_{\\mathrm{SD}}$ the total number of function evaluations used by the step-doubling strategy, $\\overline{h}_{\\mathrm{RKF45}}$ the arithmetic mean of all accepted step sizes for the embedded Runge–Kutta–Fehlberg method over $[t_0,t_f]$, and $\\overline{h}_{\\mathrm{SD}}$ the arithmetic mean of all accepted step sizes for the step-doubling strategy over $[t_0,t_f]$. The output must be printed as a single line in the exact format of a Python list, for example:\n[[N1_RKF45,N1_SD,mean_h1_RKF45,mean_h1_SD],[N2_RKF45,N2_SD,mean_h2_RKF45,mean_h2_SD],[N3_RKF45,N3_SD,mean_h3_RKF45,mean_h3_SD]]\n\nNo additional text should be printed.", "solution": "The task is to implement and compare two adaptive step-size control strategies for solving scalar ordinary differential equations (ODEs). The fundamental principle of adaptive integration is to dynamically adjust the step size $h$ to ensure that the local truncation error per step remains within a user-defined tolerance. This approach is significantly more efficient than using a fixed step size, as it allows the integrator to take large steps when the solution is smooth and small steps when it changes rapidly.\n\nThe control mechanism for both strategies is governed by a common framework. At each time $t$ with solution $y$, a trial step of size $h$ is attempted. This yields a trial solution $y_{\\mathrm{trial}}$ and an estimate of the local error, $E \\ge 0$. The step is deemed acceptable if $E \\le T$, where $T$ is the tolerance, defined as a combination of relative and absolute tolerances: $T = \\text{atol} + \\text{rtol} \\cdot s$, with the scale factor $s = \\max\\{|y|, |y_{\\mathrm{trial}}|\\}$. If the step is accepted, the solution is advanced to $(t+h, y_{\\mathrm{accept}})$.\n\nRegardless of whether the step is accepted or rejected, the step size for the next trial, $h_{\\text{new}}$, is computed based on the observed error. The problem specifies a standard update rule:\n$$\nh_{\\text{new}} = g \\cdot h_{\\text{old}}\n$$\nwhere $g$ is a growth factor. For a method whose local error estimate behaves as $\\mathcal{O}(h^q)$, the ideal factor would be $(T/E)^{1/q}$. To ensure stability, this factor is moderated:\n$$\ng =\n\\begin{cases}\n\\max\\left(g_{\\min}, \\min\\left(g_{\\max}, \\sigma \\left(\\frac{T}{\\max(E, \\varepsilon)}\\right)^{1/q}\\right)\\right), & E > 0 \\\\\ng_{\\max}, & E = 0\n\\end{cases}\n$$\nHere, $\\sigma < 1$ is a safety factor, $\\varepsilon$ is a very small number to prevent division by zero, and $g_{\\min}, g_{\\max}$ are bounds to prevent drastic changes in step size. The problem specifies $q=5$, $\\sigma=0.9$, $g_{\\min}=0.2$, $g_{\\max}=5$, and $\\varepsilon=10^{-30}$. The new step size is also clamped within $[h_{\\min}, h_{\\max}]$.\n\nThe two strategies differ solely in how they compute the trial solution and the error estimate $E$.\n\n**1. Embedded Runge–Kutta–Fehlberg $4(5)$ Method (RKF45)**\n\nThis is an \"embedded\" method, which uses a pair of Runge-Kutta formulas of different orders ($p=4$ and $p+1=5$) that share intermediate function evaluations (stages) to minimize computational cost. For a step size $h$, the method computes six stages, $k_1, \\dots, k_6$, which are then linearly combined to produce two approximations: a fourth-order solution $y_4$ and a fifth-order solution $y_5$.\n$$\ny_4 = y + h \\sum_{i=1}^6 b_i k_i, \\quad y_5 = y + h \\sum_{i=1}^6 b_i^* k_i\n$$\nThe problem specifies using the higher-order solution to advance the integration, so $y_{\\mathrm{trial}} = y_5$ and $y_{\\mathrm{accept}} = y_5$. The difference between the two solutions provides an asymptotically correct estimate of the local truncation error of the lower-order method:\n$$\nE = |y_5 - y_4| = \\mathcal{O}(h^5)\n$$\nThis error estimate is used in the step-size control logic. Since the error estimate is of order $5$, the specified controller parameter $q=5$ is appropriate. The entire procedure requires $6$ function evaluations per trial step.\n\n**2. Step-Doubling with Classical Fourth-Order Runge-Kutta (RK4)**\n\nThis strategy, based on Richardson extrapolation, uses a single underlying method (RK4, order $p=4$) to generate an error estimate. For a desired step size $h$, the solution is advanced from $t$ to $t+h$ in two different ways:\n- One single step of size $h$, yielding $y^{(1)} = \\Phi_h(y)$.\n- Two consecutive steps of size $h/2$, yielding $y^{(2)} = \\Phi_{h/2}(\\Phi_{h/2}(y))$.\n\nThe local truncation error of the more accurate solution, $y^{(2)}$, can be estimated from the difference between the two results:\n$$\nE = \\frac{|y^{(2)} - y^{(1)}|}{2^p - 1} = \\frac{|y^{(2)} - y^{(1)}|}{15}\n$$\nThis error estimate is also of order $\\mathcal{O}(h^{p+1}) = \\mathcal{O}(h^5)$, making $q=5$ the correct choice for the step-size controller. The problem specifies advancing the solution with the more accurate result, $y_{\\text{accept}} = y^{(2)}$. This technique is computationally intensive; a single trial requires one full step ($4$ function evaluations) and two half-steps ($2 \\times 4 = 8$ evaluations), for a total of $12$ function evaluations, as no stage computations are shared.\n\nThe program is structured around a general-purpose adaptive integration function that implements the main control loop. This function accepts a \"stepper\" function as an argument, which encapsulates the logic specific to either RKF45 or step-doubling. This design cleanly separates the control logic from the error estimation method. The main script defines the three specified ODE problems and, for each one, calls the integrator twice—once with the RKF45 stepper and once with the step-doubling stepper—to compute and report the required performance metrics.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# --- Global constants for step-size control ---\nSIGMA = 0.9\nG_MIN = 0.2\nG_MAX = 5.0\nEPSILON = 1e-30\nH_MIN = 1e-12\nQ_ORDER = 5.0\n\n# --- Stepper implementation for RKF45 ---\ndef rkf45_step(f, t, y, h):\n    \"\"\"\n    Performs one trial step using the Runge-Kutta-Fehlberg 4(5) method.\n    \"\"\"\n    # Fehlberg coefficients\n    k1 = f(t, y)\n    k2 = f(t + 1/4 * h, y + h * (1/4 * k1))\n    k3 = f(t + 3/8 * h, y + h * (3/32 * k1 + 9/32 * k2))\n    k4 = f(t + 12/13 * h, y + h * (1932/2197 * k1 - 7200/2197 * k2 + 7296/2197 * k3))\n    k5 = f(t + h, y + h * (439/216 * k1 - 8 * k2 + 3680/513 * k3 - 845/4104 * k4))\n    k6 = f(t + 1/2 * h, y + h * (-8/27 * k1 + 2 * k2 - 3544/2565 * k3 + 1859/4104 * k4 - 11/40 * k5))\n\n    # 4th and 5th order solutions\n    y4 = y + h * (25/216 * k1 + 1408/2565 * k3 + 2197/4104 * k4 - 1/5 * k5)\n    y5 = y + h * (16/135 * k1 + 6656/12825 * k3 + 28561/56430 * k4 - 9/50 * k5 + 2/55 * k6)\n\n    # Use 5th order for trial and acceptance\n    y_trial = y5\n    y_accept = y5\n\n    # Error estimate is the difference between the two\n    error_est = abs(y5 - y4)\n    \n    # 6 function evaluations per trial step\n    f_evals = 6\n    \n    return y_trial, y_accept, error_est, f_evals\n\n# --- Stepper implementation for Step-Doubling RK4 ---\ndef rk4_single_step(f, t, y, h):\n    \"\"\"\n    Performs a single step of the classical 4th order Runge-Kutta method.\n    \"\"\"\n    k1 = f(t, y)\n    k2 = f(t + h/2.0, y + h/2.0 * k1)\n    k3 = f(t + h/2.0, y + h/2.0 * k2)\n    k4 = f(t + h, y + h * k3)\n    return y + h/6.0 * (k1 + 2*k2 + 2*k3 + k4)\n\ndef sd_rk4_step(f, t, y, h):\n    \"\"\"\n    Performs one trial step using step-doubling with the RK4 method.\n    \"\"\"\n    # One step of size h\n    y1 = rk4_single_step(f, t, y, h)\n    \n    # Two steps of size h/2\n    y_mid = rk4_single_step(f, t, y, h/2.0)\n    y2 = rk4_single_step(f, t + h/2.0, y_mid, h/2.0)\n\n    # Use the more accurate solution for trial and acceptance\n    y_trial = y2\n    y_accept = y2\n    \n    # Richardson error estimate\n    error_est = abs(y2 - y1) / 15.0\n    \n    # 12 function evaluations per trial step (4 for full step, 8 for two half-steps)\n    f_evals = 12\n    \n    return y_trial, y_accept, error_est, f_evals\n\n# --- Generic adaptive ODE integrator ---\ndef integrate(f, t0, tf, y0, rtol, atol, stepper_func):\n    \"\"\"\n    Integrates an ODE using an adaptive step-size strategy.\n    \"\"\"\n    t = float(t0)\n    y = float(y0)\n    \n    h_max = float(tf - t0)\n    h = h_max / 50.0\n\n    total_f_evals = 0\n    accepted_h_sum = 0.0\n    accepted_steps_count = 0\n\n    while t < tf:\n        if t + h > tf:\n            h = tf - t\n\n        y_trial, y_accept, E, f_evals = stepper_func(f, t, y, h)\n        total_f_evals += f_evals\n        \n        s = max(abs(y), abs(y_trial))\n        T = atol + rtol * s\n\n        accepted = (E <= T)\n\n        if accepted:\n            accepted_h_sum += h\n            accepted_steps_count += 1\n            t += h\n            y = y_accept\n\n        # Step-size update logic\n        if E > 0:\n            g = max(G_MIN, min(G_MAX, SIGMA * (T / max(E, EPSILON))**(1.0/Q_ORDER)))\n        else: # E == 0 implies error is smaller than machine precision\n            g = G_MAX\n        \n        h = max(H_MIN, min(h_max, g * h))\n\n    mean_h = accepted_h_sum / accepted_steps_count if accepted_steps_count > 0 else 0.0\n    \n    return total_f_evals, mean_h\n\n# --- Main solution function ---\ndef solve():\n    \"\"\"\n    Defines test cases and runs the comparison, printing the final result.\n    \"\"\"\n    # Define the ODE functions for the test cases\n    def f1(t, y): return -2.0 * y + t\n    def f2(t, y): return 50.0 * math.cos(50.0 * t) - y\n    def f3(t, y): return y * (1.0 - y)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: smooth linear\n        (f1, 0.0, 10.0, 1.0, 1e-6, 1e-9),\n        # Case 2: oscillatory forcing\n        (f2, 0.0, 2.0, 0.0, 1e-5, 1e-7),\n        # Case 3: logistic growth\n        (f3, 0.0, 10.0, 1e-6, 1e-7, 1e-12)\n    ]\n\n    results = []\n    for case in test_cases:\n        f, t0, tf, y0, rtol, atol = case\n        \n        # Run RKF45 strategy\n        n_rkf45, h_avg_rkf45 = integrate(f, t0, tf, y0, rtol, atol, rkf45_step)\n        \n        # Run Step-Doubling RK4 strategy\n        n_sd, h_avg_sd = integrate(f, t0, tf, y0, rtol, atol, sd_rk4_step)\n        \n        results.append([n_rkf45, n_sd, h_avg_rkf45, h_avg_sd])\n\n    # Final print statement in the exact required format.\n    print(str(results))\n\nsolve()\n```", "id": "2372273"}, {"introduction": "While controlling local error is crucial, for many problems in physics—especially in mechanics—preserving global invariants like energy over long simulations is equally important. This exercise delves into the world of geometric integration by having you implement a symplectic integrator, a method designed for Hamiltonian systems like the pendulum [@problem_id:2372254]. You will investigate a fundamental question in numerical physics: what happens to the excellent long-term energy stability of a symplectic method when we apply a standard adaptive step-size controller, which breaks its core structure?", "problem": "Consider the one-degree-of-freedom simple pendulum modeled as a separable Hamiltonian system with generalized coordinate $q$ (angle, in radians) and canonical momentum $p$ (angular momentum, in dimensionless units). Use the nondimensionalized Hamiltonian\n$$\nH(q,p) = \\frac{p^{2}}{2} + 1 - \\cos(q),\n$$\nwhich yields Hamilton's equations\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p} = p,\\qquad \\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\sin(q).\n$$\nAngles must be treated in radians. Time is dimensionless. Energy is dimensionless.\n\nYour tasks are as follows, starting from the fundamental base of Hamilton's equations and the definition of a separable Hamiltonian $H(q,p) = T(p) + V(q)$:\n\n- Implement a fixed-step, second-order, symplectic integrator appropriate for separable Hamiltonians (for example, a method that composes the exact flows of $T(p)$ and $V(q)$ and is commonly known to be symplectic when the time step is constant). Use this method to advance $(q,p)$ with a constant step for long times.\n\n- Implement an adaptive step size controller for the same symplectic method using step-doubling: given a step of size $h$, compare the state produced by one full step of size $h$ with the state produced by two half-steps of size $h/2$. Use the Euclidean norm in state space,\n$$\n\\lVert \\Delta \\mathbf{y} \\rVert_2 = \\sqrt{(q_{2} - q_{1})^{2} + (p_{2} - p_{1})^{2}},\n$$\nas the local error indicator to accept or reject a step against a specified scalar tolerance. If the step is accepted, advance using the more accurate two-half-step result. Design your controller to adjust $h$ based on the method's local truncation error order, derived from first principles, and include safeguards with a minimum and maximum step size. Note that changing $h$ in this way generally breaks exact symplecticity; you must still implement and test it.\n\n- Implement a non-symplectic explicit Runge–Kutta method of classical order $4$ with an adaptive step size controller using the same step-doubling strategy and Euclidean norm error indicator described above. Base the step size adaptation on the method's local truncation error order, derived from first principles.\n\nFor each simulation, compute the relative energy drift at the final time $T$,\n$$\n\\delta_H = \\frac{\\lvert H(q(T),p(T)) - H(q(0),p(0)) \\rvert}{H(q(0),p(0))}.\n$$\n\nTest Suite (angles in radians; time is dimensionless):\n- Case $1$ (happy path, moderate amplitude):\n  - Initial state: $q(0) = 1.0$, $p(0) = 0.0$.\n  - Final time: $T = 100.0$.\n  - Tolerance for adaptive controllers: $\\text{tol} = 10^{-5}$.\n  - Fixed symplectic step: $h_{\\text{fixed}} = 0.05$.\n  - Adaptive controller settings: initial step $h_{\\text{init}} = 0.05$, minimum step $h_{\\min} = 10^{-6}$, maximum step $h_{\\max} = 0.2$.\n- Case $2$ (near-separatrix, strong nonlinearity):\n  - Initial state: $q(0) = 2.9$, $p(0) = 0.0$.\n  - Final time: $T = 50.0$.\n  - Tolerance for adaptive controllers: $\\text{tol} = 10^{-5}$.\n  - Fixed symplectic step: $h_{\\text{fixed}} = 0.02$.\n  - Adaptive controller settings: initial step $h_{\\text{init}} = 0.02$, minimum step $h_{\\min} = 10^{-6}$, maximum step $h_{\\max} = 0.2$.\n- Case $3$ (higher momentum, mixed scales):\n  - Initial state: $q(0) = 0.3$, $p(0) = 1.2$.\n  - Final time: $T = 100.0$.\n  - Tolerance for adaptive controllers: $\\text{tol} = 2\\times 10^{-5}$.\n  - Fixed symplectic step: $h_{\\text{fixed}} = 0.04$.\n  - Adaptive controller settings: initial step $h_{\\text{init}} = 0.04$, minimum step $h_{\\min} = 10^{-6}$, maximum step $h_{\\max} = 0.2$.\n\nFor each case, compute three floating-point results:\n- The relative energy drift $\\delta_H$ at $t = T$ for the fixed-step symplectic integrator.\n- The relative energy drift $\\delta_H$ at $t = T$ for the adaptive-step version of the symplectic method (step-doubling controlled).\n- The relative energy drift $\\delta_H$ at $t = T$ for the adaptive-step classical fourth-order Runge–Kutta method (step-doubling controlled).\n\nFinal Output Format:\n- Your program must produce a single line of output that is a comma-separated list enclosed in square brackets. The list must contain $9$ floats in the following order:\n  - $\\big[\\delta_{H,\\text{fixed}}^{(1)}, \\delta_{H,\\text{adapt-sympl}}^{(1)}, \\delta_{H,\\text{adapt-RK4}}^{(1)}, \\delta_{H,\\text{fixed}}^{(2)}, \\delta_{H,\\text{adapt-sympl}}^{(2)}, \\delta_{H,\\text{adapt-RK4}}^{(2)}, \\delta_{H,\\text{fixed}}^{(3)}, \\delta_{H,\\text{adapt-sympl}}^{(3)}, \\delta_{H,\\text{adapt-RK4}}^{(3)}\\big]$.\n- Express each float in scientific notation with exactly $6$ significant digits (for example, $1.234560\\times 10^{-4}$ should be printed as $1.234560\\mathrm{e}{-04}$). The program must not print anything else.\n\nYour implementation must be a complete, runnable program in a modern programming language, and it must not require any user input or external files. The numerical algorithms must be derived from the provided fundamental base and implemented explicitly; do not call black-box ODE solvers from external libraries. The angles must be in radians. Time, momentum, and energy are all dimensionless as specified above.", "solution": "The problem statement presented is valid. It is a well-posed initial value problem grounded in the principles of classical Hamiltonian mechanics and numerical analysis. All parameters and conditions required for a unique solution are provided, and the tasks are clearly defined and scientifically sound. I will therefore proceed with a complete solution.\n\nThe system under consideration is a simple pendulum described by the nondimensionalized, separable Hamiltonian:\n$$\nH(q,p) = T(p) + V(q) = \\frac{p^2}{2} + (1 - \\cos(q))\n$$\nwhere $q$ is the generalized coordinate (angle) and $p$ is the canonical momentum. The dynamics are governed by Hamilton's equations:\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p} = p, \\qquad \\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\sin(q)\n$$\n\nWe are tasked with implementing and comparing three numerical integration schemes. The performance of each method will be evaluated by computing the relative energy drift, $\\delta_H$, at a final time $T$:\n$$\n\\delta_H = \\frac{\\lvert H(q(T),p(T)) - H(q(0),p(0)) \\rvert}{H(q(0),p(0))}\n$$\n\n### 1. Second-Order Symplectic Integrator\n\nFor a separable Hamiltonian, one can construct symplectic integrators by composing the exact flows corresponding to the kinetic energy $T(p)$ and potential energy $V(q)$. The time evolution operator for a step of size $h$, $e^{h L_H}$, can be approximated using a symmetric splitting, such as the Strang splitting, which is second-order accurate.\n$$\n\\Phi_h \\approx \\Phi_V(h/2) \\circ \\Phi_T(h) \\circ \\Phi_V(h/2)\n$$\nHere, $\\Phi_T(\\tau)$ is the exact flow for time $\\tau$ under Hamiltonian $T(p)$, and $\\Phi_V(\\tau)$ is the exact flow for time $\\tau$ under Hamiltonian $V(q)$.\n\nThe flow under $T(p) = p^2/2$ yields:\n$$\n\\frac{dq}{dt} = p, \\qquad \\frac{dp}{dt} = 0 \\quad \\implies \\quad q(\\tau) = q(0) + \\tau p(0), \\quad p(\\tau) = p(0)\n$$\nThe flow under $V(q) = 1 - \\cos(q)$ yields:\n$$\n\\frac{dq}{dt} = 0, \\qquad \\frac{dp}{dt} = -\\sin(q) \\quad \\implies \\quad q(\\tau) = q(0), \\quad p(\\tau) = p(0) - \\tau \\sin(q(0))\n$$\n\nApplying the composition $\\Phi_V(h/2) \\circ \\Phi_T(h) \\circ \\Phi_V(h/2)$ to the state $(q_n, p_n)$ to obtain $(q_{n+1}, p_{n+1})$ results in the Størmer-Verlet or leapfrog integration scheme:\n\\begin{enumerate}\n    \\item Update momentum by a half-step: $p_{n+1/2} = p_n - \\frac{h}{2} \\sin(q_n)$\n    \\item Update position by a full step using the new momentum: $q_{n+1} = q_n + h \\cdot p_{n+1/2}$\n    \\item Update momentum by a second half-step using the new position: $p_{n+1} = p_{n+1/2} - \\frac{h}{2} \\sin(q_{n+1})$\n\\end{enumerate}\nThis method is symplectic for a fixed step size $h$, meaning it exactly preserves a nearby shadow Hamiltonian, which leads to excellent long-term energy stability (bounded energy error). For the fixed-step simulation, this scheme is applied repeatedly with a constant $h$.\n\n### 2. Adaptive Step Size Control\n\nAn adaptive step size controller adjusts the step size $h$ to maintain a local error estimate below a given tolerance $\\text{tol}$. The problem specifies a step-doubling approach. Given a state $\\mathbf{y}_n = (q_n, p_n)^T$, we compute the state at $t_n+h$ in two ways:\n\\begin{enumerate}\n    \\item One step of size $h$: $\\mathbf{y}_1 = \\Psi_h(\\mathbf{y}_n)$\n    \\item Two steps of size $h/2$: $\\mathbf{y}_2 = \\Psi_{h/2}(\\Psi_{h/2}(\\mathbf{y}_n))$\n\\end{enumerate}\nwhere $\\Psi_h$ is the numerical integration map for one step.\n\nFor a method of order $p$, the local truncation error is $O(h^{p+1})$. The error in the less accurate solution, $\\mathbf{y}_1$, is approximately $C h^{p+1}$, while the error in the more accurate solution, $\\mathbf{y}_2$, is approximately $2C(h/2)^{p+1} = C h^{p+1}/2^p$. The difference $\\Delta \\mathbf{y} = \\mathbf{y}_1 - \\mathbf{y}_2$ serves as an estimate of the local error. We use its Euclidean norm, $\\text{err} = \\lVert \\Delta \\mathbf{y} \\rVert_2$, as the error indicator.\n\nThe step control logic is as follows:\n- If $\\text{err} \\le \\text{tol}$, the step is accepted. The state is advanced to $\\mathbf{y}_{n+1} = \\mathbf{y}_2$ (the more accurate result).\n- If $\\text{err} > \\text{tol}$, the step is rejected, and a smaller step size is chosen to retry from $\\mathbf{y}_n$.\n\nThe new step size $h_{\\text{new}}$ is determined by relating the current error to the desired tolerance. Since $\\text{err} \\propto h^{p+1}$, we desire $\\text{tol} \\propto h_{\\text{new}}^{p+1}$. This leads to the update rule:\n$$\nh_{\\text{new}} = S \\cdot h \\left( \\frac{\\text{tol}}{\\text{err}} \\right)^{\\frac{1}{p+1}}\n$$\nwhere $S$ is a safety factor (typically $S \\approx 0.9$) to prevent frequent rejections. The step size is also constrained by a minimum $h_{\\min}$ and maximum $h_{\\max}$. For the second-order symplectic integrator, the order is $p=2$. Varying the step size breaks the exact symplecticity of the method, but it can still provide better energy conservation than a non-symplectic method.\n\n### 3. Fourth-Order Runge-Kutta Method (RK4)\n\nFor comparison, a non-symplectic method is used: the classical fourth-order Runge-Kutta method. For an ODE system $\\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y})$, the update rule for a step of size $h$ is:\n$$\n\\mathbf{k}_1 = \\mathbf{f}(t_n, \\mathbf{y}_n) \\\\\n\\mathbf{k}_2 = \\mathbf{f}(t_n + h/2, \\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_1) \\\\\n\\mathbf{k}_3 = \\mathbf{f}(t_n + h/2, \\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_2) \\\\\n\\mathbf{k}_4 = \\mathbf{f}(t_n + h, \\mathbf{y}_n + h\\mathbf{k}_3) \\\\\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n$$\nIn our case, $\\mathbf{y} = (q, p)^T$ and the function $\\mathbf{f}(\\mathbf{y}) = (p, -\\sin(q))^T$ is autonomous. This method is not symplectic and is expected to exhibit secular energy drift over long integrations.\n\nThe adaptive step size control for RK4 employs the same step-doubling strategy. The only difference is the order of the method, which is $p=4$. The step size adaptation formula therefore uses the exponent $1/(p+1) = 1/5$. The implementation will follow the same logic as for the adaptive symplectic integrator but using the RK4 step function and the appropriate order.", "answer": "```python\nimport numpy as np\n\n# language: Python\n# version: 3.12\n# libraries:\n#     - name: numpy\n#       version: 1.23.5\n#     - name: scipy\n#       version: 1.11.4\n\ndef hamiltonian(y):\n    \"\"\"Computes the Hamiltonian for a given state vector y = [q, p].\"\"\"\n    q, p = y\n    return p**2 / 2.0 + 1.0 - np.cos(q)\n\ndef f_ode(y):\n    \"\"\"RHS of the ODE system dy/dt = f(y) for RK4.\"\"\"\n    q, p = y\n    return np.array([p, -np.sin(q)])\n\ndef step_symplectic(y, h):\n    \"\"\"Performs a single step of the 2nd-order symplectic leapfrog integrator.\"\"\"\n    q, p = y\n    p_half = p - (h / 2.0) * np.sin(q)\n    q_new = q + h * p_half\n    p_new = p_half - (h / 2.0) * np.sin(q_new)\n    return np.array([q_new, p_new])\n\ndef step_rk4(y, h):\n    \"\"\"Performs a single step of the classical 4th-order Runge-Kutta method.\"\"\"\n    k1 = f_ode(y)\n    k2 = f_ode(y + h / 2.0 * k1)\n    k3 = f_ode(y + h / 2.0 * k2)\n    k4 = f_ode(y + h * k3)\n    return y + h / 6.0 * (k1 + 2 * k2 + 2 * k3 + k4)\n\ndef solve_fixed_symplectic(y0, T, h):\n    \"\"\"Solves the ODE with the fixed-step symplectic integrator.\"\"\"\n    t = 0.0\n    y = np.copy(y0)\n    num_steps = int(np.ceil(T / h))\n    for _ in range(num_steps):\n        # Adjust last step to land exactly on T\n        current_h = min(h, T - t)\n        if current_h <= 0: break\n        y = step_symplectic(y, current_h)\n        t += current_h\n    return y\n\ndef solve_adaptive(y0, T, h_init, tol, h_min, h_max, step_func, p_order):\n    \"\"\"Generic adaptive step size solver using step-doubling.\"\"\"\n    t = 0.0\n    y = np.copy(y0)\n    h = h_init\n    S = 0.9  # Safety factor\n\n    while t < T:\n        h = min(h, T - t)\n        \n        step_accepted = False\n        while not step_accepted:\n            if h < h_min:\n                h = h_min\n\n            # Perform one big step and two small steps\n            y1 = step_func(y, h)\n            y_mid = step_func(y, h / 2.0)\n            y2 = step_func(y_mid, h / 2.0)\n\n            # Calculate error\n            err = np.linalg.norm(y1 - y2)\n            if err == 0.0:\n                err = 1e-16  # Avoid division by zero, allow h to grow\n\n            # Step control logic\n            if err <= tol:\n                # Accept step\n                step_accepted = True\n                t += h\n                y = y2  # Use the more accurate result\n                \n                # Propose step size for the next iteration\n                h_new = S * h * (tol / err)**(1.0 / (p_order + 1.0))\n                h = min(h_max, h_new)\n            else:\n                # Reject step, reduce step size for retry\n                h_new = S * h * (tol / err)**(1.0 / (p_order + 1.0))\n                h = max(h_min, h_new)\n                \n                # Prevent infinite loop if h_min is too large for the tolerance\n                if h <= h_min and err > tol:\n                    step_accepted = True\n                    t += h\n                    y = y2\n    return y\n    \ndef solve():\n    \"\"\"Main function to run test cases and produce the final output.\"\"\"\n    test_cases = [\n        {\n            \"q0\": 1.0, \"p0\": 0.0, \"T\": 100.0, \"tol\": 1e-5,\n            \"h_fixed\": 0.05, \"h_init\": 0.05, \"h_min\": 1e-6, \"h_max\": 0.2\n        },\n        {\n            \"q0\": 2.9, \"p0\": 0.0, \"T\": 50.0, \"tol\": 1e-5,\n            \"h_fixed\": 0.02, \"h_init\": 0.02, \"h_min\": 1e-6, \"h_max\": 0.2\n        },\n        {\n            \"q0\": 0.3, \"p0\": 1.2, \"T\": 100.0, \"tol\": 2e-5,\n            \"h_fixed\": 0.04, \"h_init\": 0.04, \"h_min\": 1e-6, \"h_max\": 0.2\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        y0 = np.array([case[\"q0\"], case[\"p0\"]])\n        h0 = hamiltonian(y0)\n\n        # 1. Fixed-step symplectic integrator\n        y_final_fixed = solve_fixed_symplectic(y0, case[\"T\"], case[\"h_fixed\"])\n        h_final_fixed = hamiltonian(y_final_fixed)\n        drift_fixed = abs(h_final_fixed - h0) / h0\n        results.append(drift_fixed)\n\n        # 2. Adaptive-step symplectic integrator\n        y_final_adapt_sympl = solve_adaptive(y0, case[\"T\"], case[\"h_init\"], case[\"tol\"], case[\"h_min\"], case[\"h_max\"], step_symplectic, p_order=2)\n        h_final_adapt_sympl = hamiltonian(y_final_adapt_sympl)\n        drift_adapt_sympl = abs(h_final_adapt_sympl - h0) / h0\n        results.append(drift_adapt_sympl)\n\n        # 3. Adaptive-step RK4 integrator\n        y_final_adapt_rk4 = solve_adaptive(y0, case[\"T\"], case[\"h_init\"], case[\"tol\"], case[\"h_min\"], case[\"h_max\"], step_rk4, p_order=4)\n        h_final_adapt_rk4 = hamiltonian(y_final_adapt_rk4)\n        drift_adapt_rk4 = abs(h_final_adapt_rk4 - h0) / h0\n        results.append(drift_adapt_rk4)\n\n    # Format the final output string\n    output_str = \",\".join([\"{:.6e}\".format(r) for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "2372254"}, {"introduction": "An adaptive solver is a complex dynamical system in its own right, and its behavior can sometimes exhibit unexpected interactions with the problem it is solving. This advanced practice challenges you to become a numerical detective and investigate the phenomenon of \"phase locking,\" where the solver’s internal time steps can synchronize with a periodic driving force in the ODE [@problem_id:2372241]. By applying a statistical measure, the Rayleigh resultant, you will learn how to quantify such numerical artifacts, a critical skill for ensuring the reliability of scientific simulations.", "problem": "Design and implement a program that, for a periodically driven second-order ordinary differential equation, quantitatively assesses whether the internal time mesh generated by a variable step-size integrator exhibits phase locking with the driving force. Consider the linear oscillator governed by\n$$\n\\ddot{x}(t) + 2\\zeta \\,\\omega_0 \\,\\dot{x}(t) + \\omega_0^2 \\, x(t) = F \\cos(\\omega t),\n$$\nwith initial conditions\n$$\nx(0) = 0 \\ \\text{and}\\ \\dot{x}(0) = 0.\n$$\nWork with mass $m=1$ so that all parameters enter as given. Treat time in seconds, and all angles in radians. Convert the second-order equation into a first-order system in the standard way. For a given set of parameters $(\\omega_0,\\zeta,F,\\omega)$, integrate from $t=0$ to $t=t_{\\text{end}}$, where\n$$\nt_{\\text{end}} = N_{\\text{periods}} \\cdot \\frac{2\\pi}{\\omega},\n$$\nusing a variable step-size integrator that controls local truncation error to meet specified absolute and relative tolerances. You must use only the integrator’s own internal time mesh; do not impose externally specified output times.\n\nFor each integration, discard the first $N_{\\text{burn}}$ periods to remove transients. From the remaining internal time stamps $\\{t_k\\}$ used by the integrator, form the phase angles modulo the driving period,\n$$\n\\phi_k = \\left(\\omega t_k \\right) \\bmod 2\\pi,\n$$\nwith all angles in radians. Quantify phase locking between the integrator’s internal mesh and the driving by computing the Rayleigh resultant\n$$\nR = \\frac{1}{N}\\left|\\sum_{k=1}^{N} e^{i \\phi_k}\\right|,\n$$\nwhere $N$ is the number of post-transient time stamps. Larger values of $R$ indicate stronger clustering of phases (perfect locking yields $R=1$), while values near $0$ indicate a nearly uniform phase distribution.\n\nImplement your program to process the following test suite. For each case, the integrator must enforce the given relative tolerance $r_{\\text{tol}}$ and absolute tolerance $a_{\\text{tol}}$, integrate for $N_{\\text{periods}}$ periods, discard $N_{\\text{burn}}$ periods, and then compute and report the corresponding $R$ value as a floating-point number.\n\n- Test case $1$ (general resonant driving):\n  - $\\omega_0 = 1.0$\n  - $\\zeta = 0.02$\n  - $F = 1.0$\n  - $\\omega = 1.0$\n  - $r_{\\text{tol}} = 1\\times 10^{-6}$\n  - $a_{\\text{tol}} = 1\\times 10^{-9}$\n  - $N_{\\text{periods}} = 200$\n  - $N_{\\text{burn}} = 5$\n- Test case $2$ (off-resonance driving):\n  - $\\omega_0 = 1.0$\n  - $\\zeta = 0.02$\n  - $F = 1.0$\n  - $\\omega = \\sqrt{2}$\n  - $r_{\\text{tol}} = 1\\times 10^{-6}$\n  - $a_{\\text{tol}} = 1\\times 10^{-9}$\n  - $N_{\\text{periods}} = 200$\n  - $N_{\\text{burn}} = 5$\n- Test case $3$ (no external driving):\n  - $\\omega_0 = 1.0$\n  - $\\zeta = 0.05$\n  - $F = 0.0$\n  - $\\omega = 1.0$\n  - $r_{\\text{tol}} = 1\\times 10^{-6}$\n  - $a_{\\text{tol}} = 1\\times 10^{-9}$\n  - $N_{\\text{periods}} = 200$\n  - $N_{\\text{burn}} = 5$\n- Test case $4$ (tight tolerance near resonance):\n  - $\\omega_0 = 1.0$\n  - $\\zeta = 0.05$\n  - $F = 10.0$\n  - $\\omega = 1.0$\n  - $r_{\\text{tol}} = 1\\times 10^{-9}$\n  - $a_{\\text{tol}} = 1\\times 10^{-12}$\n  - $N_{\\text{periods}} = 200$\n  - $N_{\\text{burn}} = 5$\n\nYour program should produce a single line of output containing the results as a comma-separated list of the four Rayleigh $R$ values (unitless), each rounded to $6$ decimal places, enclosed in square brackets, in the order of the test cases above (for example, $\"[0.123456,0.234567,0.345678,0.456789]\"$). No other output is permitted.", "solution": "The problem as stated is scientifically sound, self-contained, and well-posed. It presents a standard problem from computational physics: the analysis of numerical artifacts in the integration of ordinary differential equations. Specifically, it asks to quantify the phenomenon of phase locking, where the internal time steps of an adaptive integrator synchronize with a periodic feature of the system, such as an external driving force. The methodology is clearly defined, using the Rayleigh resultant as a standard statistical measure for circular data. All parameters and test cases are specified unambiguously. Therefore, we may proceed with the solution.\n\nThe core of the problem is the second-order linear ordinary differential equation (ODE) for a damped, driven harmonic oscillator:\n$$\n\\ddot{x}(t) + 2\\zeta \\,\\omega_0 \\,\\dot{x}(t) + \\omega_0^2 \\, x(t) = F \\cos(\\omega t)\n$$\nwith initial conditions $x(0) = 0$ and $\\dot{x}(0) = 0$.\n\nTo solve this numerically, we must first convert it into a system of two first-order ODEs. Let the state vector be $\\mathbf{y}(t) = [y_1(t), y_2(t)]^T$, where $y_1(t) = x(t)$ is the position and $y_2(t) = \\dot{x}(t)$ is the velocity. The time derivatives are then:\n$$\n\\dot{y}_1(t) = \\frac{d}{dt}x(t) = \\dot{x}(t) = y_2(t)\n$$\n$$\n\\dot{y}_2(t) = \\frac{d}{dt}\\dot{x}(t) = \\ddot{x}(t) = F \\cos(\\omega t) - 2\\zeta \\omega_0 \\dot{x}(t) - \\omega_0^2 x(t) = F \\cos(\\omega t) - 2\\zeta \\omega_0 y_2(t) - \\omega_0^2 y_1(t)\n$$\nThis can be written in vector form as $\\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y})$:\n$$\n\\frac{d}{dt}\n\\begin{pmatrix}\ny_1 \\\\\ny_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\ny_2 \\\\\nF \\cos(\\omega t) - \\omega_0^2 y_1 - 2\\zeta \\omega_0 y_2\n\\end{pmatrix}\n$$\nThe initial condition is $\\mathbf{y}(0) = [0, 0]^T$.\n\nThis system is to be integrated from $t=0$ to a final time $t_{\\text{end}} = N_{\\text{periods}} \\cdot (2\\pi/\\omega)$ using a variable step-size integrator. Such integrators, like the Runge-Kutta-Fehlberg or Dormand-Prince methods, adapt the step size $h_k = t_{k+1} - t_k$ at each step $k$ to ensure the estimated local truncation error remains within a bound defined by the user-specified relative tolerance, $r_{\\text{tol}}$, and absolute tolerance, $a_{\\text{tol}}$. The sequence of time points $\\{t_k\\}$ is therefore not uniform but is determined dynamically by the solver based on the solution's local behavior.\n\nThe central hypothesis is that the solver's step-selection algorithm may \"lock on\" to the period of the driving force, $T_{drive} = 2\\pi/\\omega$. To investigate this, we analyze the distribution of the internal time steps $\\{t_k\\}$ chosen by the solver. First, we discard the initial portion of the integration corresponding to the first $N_{\\text{burn}}$ periods to eliminate the influence of transient behavior, which decays with a time constant related to $( \\zeta \\omega_0 )^{-1}$. The cutoff time is $t_{\\text{burn}} = N_{\\text{burn}} \\cdot (2\\pi/\\omega)$.\n\nFor the remaining $N$ time stamps $\\{t_k\\}$ where $t_k > t_{\\text{burn}}$, we compute the corresponding phase angle $\\phi_k$ with respect to the driving period:\n$$\n\\phi_k = (\\omega t_k) \\pmod{2\\pi}\n$$\nThis calculation maps each time point onto the interval $[0, 2\\pi)$, representing its position within a driving cycle.\n\nTo quantify the degree of clustering of these phases, we employ the Rayleigh resultant, $R$. Each phase $\\phi_k$ is represented as a unit vector $e^{i\\phi_k}$ in the complex plane. The Rayleigh resultant is the magnitude of the average of these vectors:\n$$\nR = \\frac{1}{N}\\left|\\sum_{k=1}^{N} e^{i \\phi_k}\\right|\n$$\nIf the phases $\\{\\phi_k\\}$ are uniformly distributed, the vectors will tend to cancel each other out, resulting in an $R$ value close to $0$. Conversely, if the phases are tightly clustered around a specific value, the vectors will add constructively, yielding an $R$ value close to $1$. This provides a robust metric for phase locking.\n\nFor implementation, we will use the `scipy.integrate.solve_ivp` function, a high-quality numerical ODE solver from the SciPy library. By calling it with `t_eval=None` (the default), the solver returns its solution at the internally chosen time steps, which are stored in the `t` attribute of the output object. This is precisely the internal time mesh required by the problem. We use the `'RK45'` method, which is a standard choice for an adaptive-step-size algorithm.\n\nThe procedure for each test case will be as follows:\n1. Define the parameters $(\\omega_0, \\zeta, F, \\omega, r_{\\text{tol}}, a_{\\text{tol}}, N_{\\text{periods}}, N_{\\text{burn}})$.\n2. Set up the ODE function $\\mathbf{f}(t, \\mathbf{y})$ and the integration time span $[0, t_{\\text{end}}]$.\n3. Call `solve_ivp` to perform the numerical integration and obtain the internal time mesh $\\{t_k\\}$.\n4. Filter this mesh to retain only points where $t_k > t_{\\text{burn}}$.\n5. Compute the phases $\\phi_k = (\\omega t_k) \\pmod{2\\pi}$ for the filtered time points.\n6. Calculate the Rayleigh resultant $R$ from the phases.\nThe results from all four test cases will then be formatted and printed as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for phase locking analysis.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: general resonant driving\n        {\n            \"omega0\": 1.0, \"zeta\": 0.02, \"F\": 1.0, \"omega\": 1.0,\n            \"rtol\": 1e-6, \"atol\": 1e-9, \"N_periods\": 200, \"N_burn\": 5\n        },\n        # Case 2: off-resonance driving\n        {\n            \"omega0\": 1.0, \"zeta\": 0.02, \"F\": 1.0, \"omega\": np.sqrt(2.0),\n            \"rtol\": 1e-6, \"atol\": 1e-9, \"N_periods\": 200, \"N_burn\": 5\n        },\n        # Case 3: no external driving\n        {\n            \"omega0\": 1.0, \"zeta\": 0.05, \"F\": 0.0, \"omega\": 1.0,\n            \"rtol\": 1e-6, \"atol\": 1e-9, \"N_periods\": 200, \"N_burn\": 5\n        },\n        # Case 4: tight tolerance near resonance\n        {\n            \"omega0\": 1.0, \"zeta\": 0.05, \"F\": 10.0, \"omega\": 1.0,\n            \"rtol\": 1e-9, \"atol\": 1e-12, \"N_periods\": 200, \"N_burn\": 5\n        },\n    ]\n\n    results = []\n    \n    for params in test_cases:\n        omega0 = params[\"omega0\"]\n        zeta = params[\"zeta\"]\n        F = params[\"F\"]\n        omega = params[\"omega\"]\n        rtol = params[\"rtol\"]\n        atol = params[\"atol\"]\n        N_periods = params[\"N_periods\"]\n        N_burn = params[\"N_burn\"]\n\n        # Define the system of first-order ODEs\n        # y[0] = x, y[1] = x_dot\n        def ode_system(t, y):\n            y1, y2 = y\n            dy1_dt = y2\n            dy2_dt = F * np.cos(omega * t) - omega0**2 * y1 - 2 * zeta * omega0 * y2\n            return [dy1_dt, dy2_dt]\n\n        # Set initial conditions and integration time span\n        y0 = [0.0, 0.0]\n        t_end = N_periods * 2 * np.pi / omega\n        t_span = [0, t_end]\n        \n        # Integrate using a variable step-size method.\n        # By not specifying t_eval, solve_ivp returns results at its internal steps.\n        sol = solve_ivp(\n            ode_system,\n            t_span,\n            y0,\n            method='RK45',\n            rtol=rtol,\n            atol=atol,\n            dense_output=False  # Not needed, we only want the time steps\n        )\n\n        internal_times = sol.t\n\n        # Discard the burn-in period to remove transients\n        t_burn = N_burn * 2 * np.pi / omega\n        post_transient_times = internal_times[internal_times > t_burn]\n\n        if len(post_transient_times) == 0:\n            # Handle case where no points remain after burn-in\n            R = 0.0 \n        else:\n            # Form the phase angles modulo the driving period\n            phases = (omega * post_transient_times) % (2 * np.pi)\n\n            # Quantify phase locking by computing the Rayleigh resultant\n            # R = (1/N) * |sum(exp(i * phi_k))|\n            # This is equivalent to the absolute value of the mean of the complex phasors.\n            R = np.abs(np.mean(np.exp(1j * phases)))\n        \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    # The output string should be like \"[0.123456,0.234567,...]\"\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2372241"}]}