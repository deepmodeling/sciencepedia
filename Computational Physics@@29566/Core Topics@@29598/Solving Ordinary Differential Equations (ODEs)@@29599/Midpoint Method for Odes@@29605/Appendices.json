{"hands_on_practices": [{"introduction": "Before trusting a numerical simulation, we must first verify that our code is performing correctly. A powerful technique for this is the \"method of manufactured solutions,\" where we invent a solution, substitute it into the governing equation to determine the necessary forcing function, and then run our solver on this constructed problem. This exercise is fundamental because, with a known exact answer, we can precisely quantify our code's error and confirm that its convergence rate matches theoretical expectations, building essential confidence in our numerical tools.", "problem": "Consider the following verification task based on the method of manufactured solutions for ordinary differential equations. Let the exact solution be the scalar function $y(t)$ defined for $t \\in [0, T]$ by\n$$\ny(t) = e^{-2 t}\\,\\big(\\sin(3 t) + t^2\\big),\n$$\nwhere all angles in trigonometric functions are in radians. Define the initial value problem by taking the right-hand side to be the time derivative of the exact solution and the initial condition to be the exact value at the initial time:\n$$\n\\frac{dy}{dt} = \\frac{d}{dt}\\Big[e^{-2 t}\\,\\big(\\sin(3 t) + t^2\\big)\\Big], \\quad y(0) = y(0).\n$$\nFor this initial value problem, approximate $y(T)$ using the midpoint method with uniform time step size $h$ over the interval $[0, T]$, where $T = 2$ and $h$ divides $T$ exactly so that the number of steps $N = T/h$ is an integer. The global error for a given $h$ is the absolute difference $|y_{\\text{num}}(T) - y(T)|$, where $y_{\\text{num}}(T)$ is the numerical approximation produced by the midpoint method and $y(T)$ is the exact value.\n\nYour program must evaluate the global error for the following test suite of step sizes, all in the same units as $t$:\n- $h = 1.0$ (a single coarse step over $[0, 2]$),\n- $h = 0.5$ (a moderate refinement),\n- $h = 0.2$ (a finer refinement),\n- $h = 0.05$ (a much finer refinement).\n\nRequirements:\n- Use the exact $y(t)$ specified above to define the right-hand side via its time derivative, and use $y(0)$ as the initial condition.\n- Compute the global error $|y_{\\text{num}}(T) - y(T)|$ for each $h$ in the test suite.\n- Report each error rounded to $12$ decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, for example, $[e_1,e_2,e_3,e_4]$, where each $e_i$ is a float rounded to $12$ decimal places.", "solution": "The problem statement has been validated and is deemed sound. It presents a well-posed verification task based on the method of manufactured solutions, a standard technique in computational science for assessing the accuracy of numerical schemes. All provided information is complete, consistent, and scientifically grounded.\n\nThe task is to compute the global error of the midpoint method for a specific ordinary differential equation (ODE) over a fixed interval for a given set of step sizes.\n\nFirst, we define the components of the initial value problem (IVP). The exact solution is given as:\n$$\ny(t) = e^{-2 t}\\,\\big(\\sin(3 t) + t^2\\big)\n$$\nfor the time interval $t \\in [0, T]$, where the final time is $T=2$.\n\nThe IVP is constructed from this solution. The initial condition is the value of the exact solution at $t=0$:\n$$\ny(0) = e^{-2(0)}\\big(\\sin(3(0)) + 0^2\\big) = 1 \\cdot (0 + 0) = 0\n$$\nThe right-hand side of the ODE, which we denote as $f(t, y)$, is the time derivative of the exact solution. Since the derivative of $y(t)$ depends only on $t$, we can write the ODE as $\\frac{dy}{dt} = f(t)$. We compute this derivative using the product rule:\n$$\n\\frac{d}{dt} \\left( u(t) v(t) \\right) = u'(t)v(t) + u(t)v'(t)\n$$\nLet $u(t) = e^{-2t}$ and $v(t) = \\sin(3t) + t^2$. Their derivatives are:\n$$\nu'(t) = -2e^{-2t}\n$$\n$$\nv'(t) = 3\\cos(3t) + 2t\n$$\nApplying the product rule, we obtain the function $f(t)$:\n$$\nf(t) = \\frac{dy}{dt} = (-2e^{-2t})\\big(\\sin(3t) + t^2\\big) + (e^{-2t})\\big(3\\cos(3t) + 2t\\big)\n$$\n$$\nf(t) = e^{-2t}\\big(-2\\sin(3t) - 2t^2 + 3\\cos(3t) + 2t\\big)\n$$\nThis function $f(t)$ defines the right-hand side of our ODE, $\\frac{dy}{dt} = f(t)$.\n\nNext, we define the numerical method. The midpoint method is a second-order Runge-Kutta method. For a general ODE $\\frac{dy}{dt} = F(t, y)$, a single step from $t_n$ to $t_{n+1} = t_n + h$ is given by:\n$$\nk_1 = F(t_n, y_n)\n$$\n$$\nk_2 = F(t_n + h/2, y_n + (h/2)k_1)\n$$\n$$\ny_{n+1} = y_n + h k_2\n$$\nIn our specific case, the right-hand side $F(t, y)$ is independent of $y$, i.e., $F(t, y) = f(t)$. The formula simplifies significantly:\n$$\nk_1 = f(t_n)\n$$\n$$\nk_2 = f(t_n + h/2)\n$$\n$$\ny_{n+1} = y_n + h f(t_n + h/2)\n$$\nThis is the iterative scheme we will use to approximate the solution.\n\nThe algorithm to find the numerical solution $y_{\\text{num}}(T)$ is as follows. We are given the interval $[0, T] = [0, 2]$ and a set of step sizes $h \\in \\{1.0, 0.5, 0.2, 0.05\\}$. For each $h$:\n1.  Calculate the number of steps, $N = T/h$. This will be an integer for the given values.\n2.  Initialize the solution at the starting time: $t_0 = 0$, $y_0 = y(0) = 0$.\n3.  Iterate for $n = 0, 1, 2, \\ldots, N-1$:\n    -   The current time is $t_n = n \\cdot h$.\n    -   The midpoint in time for the current step is $t_{n+1/2} = t_n + h/2$.\n    -   The next value of the solution is computed as $y_{n+1} = y_n + h \\cdot f(t_{n+1/2})$.\n4.  After $N$ steps, the numerical approximation at the final time $T=2$ is $y_{\\text{num}}(T) = y_N$.\n\nFinally, we compute the global error. The exact value at the final time $T=2$ is:\n$$\ny(2) = e^{-2(2)}\\big(\\sin(3 \\cdot 2) + 2^2\\big) = e^{-4}\\big(\\sin(6) + 4\\big)\n$$\nThe global error $E_h$ for a given step size $h$ is the absolute difference between the numerical approximation and the exact value:\n$$\nE_h = |y_{\\text{num}}(T) - y(T)| = |y_N - y(2)|\n$$\nThis procedure is repeated for each specified value of $h$. The resulting errors are then rounded to $12$ decimal places as required. The implementation will use numerical libraries to evaluate the exponential and trigonometric functions, with angles in radians as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the verification task for the midpoint method.\n\n    This function implements the method of manufactured solutions to test the\n    midpoint method for a given ordinary differential equation. It computes\n    the global error at T=2 for a suite of step sizes.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # The step sizes h are given in the problem.\n    test_cases = [1.0, 0.5, 0.2, 0.05]\n\n    # Final time T.\n    T = 2.0\n\n    # 1. Define the exact solution y(t)\n    def y_exact(t):\n        \"\"\"\n        The exact manufactured solution.\n        y(t) = exp(-2t) * (sin(3t) + t^2)\n        \"\"\"\n        return np.exp(-2.0 * t) * (np.sin(3.0 * t) + t**2)\n\n    # 2. Define the right-hand side f(t) = dy/dt\n    def f(t):\n        \"\"\"\n        The time derivative of the exact solution, dy/dt.\n        f(t) = exp(-2t) * (3*cos(3t) - 2*sin(3t) + 2t - 2t^2)\n        \"\"\"\n        return np.exp(-2.0 * t) * (\n            3.0 * np.cos(3.0 * t) - 2.0 * np.sin(3.0 * t) + 2.0 * t - 2.0 * t**2\n        )\n\n    # Calculate the exact value at the final time T.\n    y_T_exact = y_exact(T)\n\n    results = []\n    # Loop over each step size h in the test suite.\n    for h in test_cases:\n        # 3. Apply the midpoint method.\n        \n        # Number of steps. Using int(round(...)) to avoid float precision issues.\n        N = int(round(T / h))\n        \n        # Initialize the numerical solution with the exact initial condition.\n        y_num = y_exact(0.0)\n        t = 0.0\n\n        # Iterate N times to reach T.\n        for n in range(N):\n            # Midpoint in time for the current interval [t, t+h]\n            t_mid = t + h / 2.0\n            \n            # Update the solution using the midpoint method for dy/dt = f(t)\n            # y_{n+1} = y_n + h * f(t_n + h/2)\n            y_num = y_num + h * f(t_mid)\n            \n            # Update the current time for the next step.\n            t = (n + 1) * h\n\n        # 4. Compute the global error.\n        # The global error is the absolute difference at the final time T.\n        error = abs(y_num - y_T_exact)\n        \n        # Append the rounded error to the results list.\n        results.append(round(error, 12))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413529"}, {"introduction": "Many physical systems, from planetary motion to population dynamics, are described by systems of coupled ordinary differential equations. This practice moves beyond single equations to tackle the classic Lotka-Volterra predator-prey model, investigating how the midpoint method handles a conserved quantity, or \"invariant,\" of the system. While the true solution preserves this quantity perfectly, numerical methods often introduce a small drift; analyzing this drift provides deep insight into the long-term fidelity of numerical integrators, a crucial concern in physics simulations.", "problem": "Consider the two-dimensional Lotkaâ€“Volterra model of interacting populations governed by the autonomous system of ordinary differential equations (ODEs):\n$$\n\\frac{dx}{dt} = x\\,(a - b\\,y), \\quad \\frac{dy}{dt} = y\\,(-c + d\\,x),\n$$\nwith parameters $a>0$, $b>0$, $c>0$, $d>0$ and initial condition $(x(0),y(0)) = (x_0,y_0)$ where $x_0>0$ and $y_0>0$. This system has a smooth, non-Hamiltonian conserved quantity\n$$\nI(x,y) = d\\,x - c\\,\\ln(x) + b\\,y - a\\,\\ln(y),\n$$\nwhere $\\ln$ denotes the natural logarithm. Along the exact solution $(x(t),y(t))$, the quantity $I(x(t),y(t))$ remains constant for all $t$ for which $x(t)>0$ and $y(t)>0$.\n\nTask: Write a complete, runnable program that numerically advances the solution using the explicit midpoint method (the two-stage Rungeâ€“Kutta midpoint scheme) with a fixed time step $h$ from time $t=0$ to time $t=T$. For each specified test case, compute the absolute drift in the conserved quantity at the final time,\n$$\n\\Delta I = \\bigl|\\,I\\bigl(x(T),y(T)\\bigr) - I(x_0,y_0)\\,\\bigr|.\n$$\nIn addition, for one designated pair of step sizes, compute the observed order $p$ of the invariant-drift error defined by\n$$\np = \\frac{\\ln\\!\\bigl(\\Delta I(h_2)/\\Delta I(h_1)\\bigr)}{\\ln\\!\\bigl(h_2/h_1\\bigr)}.\n$$\n\nUse the following test suite. In every case, the parameters are $a=1.0$, $b=0.5$, $c=0.75$, $d=0.25$, and the natural logarithm is to be used in $I(x,y)$. All times are in arbitrary but consistent units, and no angles are involved.\n\n- Test case A (general case, moderate step): $(x_0,y_0)=(1.5,1.0)$, $T=20.0$, $h=0.1$. Output the scalar $\\Delta I$ as a float.\n- Test case B (general case, smaller step): $(x_0,y_0)=(1.5,1.0)$, $T=20.0$, $h=0.05$. Output the scalar $\\Delta I$ as a float.\n- Test case C (observed error order using A and B): Let $h_1=0.1$ and $h_2=0.05$ with $(x_0,y_0)=(1.5,1.0)$ and $T=20.0$. Compute $p$ using the $\\Delta I$ obtained at $h_1$ and $h_2$ for these same parameters. Output the scalar $p$ as a float.\n- Test case D (equilibrium initial condition): $(x_0,y_0)=(c/d,\\,a/b)$, $T=9.0$, $h=0.3$. Output the scalar $\\Delta I$ as a float.\n- Test case E (boundary condition in time): $(x_0,y_0)=(1.2,0.8)$, $T=0.0$, $h=0.1$. Output the scalar $\\Delta I$ as a float.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [A,B,C,D,E]. Each float in the list must be rounded to $10$ decimal places before printing, for example $[0.1234567890,0.0000000000,2.0000000000,0.0000000000,0.0000000000]$.", "solution": "The problem presented is a well-posed initial value problem in computational physics, requiring the numerical integration of the Lotka-Volterra equations. The problem is scientifically sound, internally consistent, and contains all necessary information to proceed with a unique solution. The validation criteria are met.\n\nThe system is defined by a pair of autonomous ordinary differential equations (ODEs) for two interacting populations, $x(t)$ and $y(t)$:\n$$\n\\frac{dx}{dt} = x(a - by)\n$$\n$$\n\\frac{dy}{dt} = y(-c + dx)\n$$\nwhere $a, b, c, d$ are positive real parameters. This system can be written in vector form as $\\frac{d\\mathbf{u}}{dt} = \\mathbf{f}(\\mathbf{u})$, where $\\mathbf{u}(t) = [x(t), y(t)]^T$ and the vector field $\\mathbf{f}$ is given by:\n$$\n\\mathbf{f}(\\mathbf{u}) = \\begin{pmatrix} x(a - by) \\\\ y(-c + dx) \\end{pmatrix}\n$$\nThe problem requires advancing the solution from an initial state $\\mathbf{u}_0 = (x_0, y_0)$ at time $t=0$ to a final time $t=T$ using the explicit midpoint method with a fixed time step $h$. The explicit midpoint method is a second-order Runge-Kutta scheme defined by the following steps to advance the solution from $\\mathbf{u}_n$ at time $t_n$ to $\\mathbf{u}_{n+1}$ at time $t_{n+1} = t_n + h$:\n\n$1$. Compute the first stage, which is the slope at the current point $\\mathbf{u}_n$:\n$$\n\\mathbf{k}_1 = \\mathbf{f}(\\mathbf{u}_n)\n$$\n$2$. Use $\\mathbf{k}_1$ to estimate the state at the midpoint in time, $t_n + h/2$:\n$$\n\\mathbf{u}_{\\text{mid}} = \\mathbf{u}_n + \\frac{h}{2} \\mathbf{k}_1\n$$\n$3$. Compute the second stage, which is the slope at the estimated midpoint state $\\mathbf{u}_{\\text{mid}}$:\n$$\n\\mathbf{k}_2 = \\mathbf{f}(\\mathbf{u}_{\\text{mid}})\n$$\n$4$. Use the midpoint slope $\\mathbf{k}_2$ to compute the final state $\\mathbf{u}_{n+1}$:\n$$\n\\mathbf{u}_{n+1} = \\mathbf{u}_n + h \\mathbf{k}_2\n$$\nThis process is repeated for a total of $N = T/h$ steps to obtain the numerical approximation of $\\mathbf{u}(T) = [x(T),y(T)]^T$.\n\nThe problem states that the Lotka-Volterra system possesses a conserved quantity:\n$$\nI(x,y) = dx - c\\ln(x) + by - a\\ln(y)\n$$\nFor an exact solution $(x(t), y(t))$, $I(x(t), y(t))$ remains constant. However, numerical methods such as the explicit midpoint method do not typically preserve such invariants exactly. The deviation of the numerical invariant over time is a measure of the method's error. We are asked to compute the absolute drift $\\Delta I$ at the final time $T$:\n$$\n\\Delta I = |I(x(T), y(T)) - I(x_0, y_0)|\n$$\nFor a method of order $p$, the global error is expected to scale as $O(h^p)$. The drift in the conserved quantity, $\\Delta I(h)$, is also expected to exhibit this scaling for a non-symplectic integrator. The observed order of convergence, $p$, can be computed from the results of two different step sizes, $h_1$ and $h_2$, using the formula:\n$$\np = \\frac{\\ln(\\Delta I(h_2) / \\Delta I(h_1))}{\\ln(h_2 / h_1)}\n$$\n\nThe provided test cases are analyzed as follows:\n- **Cases A and B**: These are standard numerical integrations with different step sizes ($h=0.1$ and $h=0.05$). The results will be non-zero values for $\\Delta I$.\n- **Case C**: This requires computing the observed order $p$ from the results of cases A and B. Since the explicit midpoint method is a second-order method ($p_{theory}=2$), the result should be close to $2$.\n- **Case D**: The initial condition $(x_0, y_0) = (c/d, a/b)$ corresponds to the non-trivial fixed point (or equilibrium) of the system, where $dx/dt = 0$ and $dy/dt = 0$. For a consistent numerical method, if the simulation starts at a fixed point, it should remain there for all time, up to machine precision. Therefore, $(x(T), y(T)) = (x_0, y_0)$, and we expect $\\Delta I = 0$.\n- **Case E**: The integration is over a time interval of zero length ($T=0$). No time steps are taken, so the final state is identical to the initial state. Thus, $(x(T), y(T)) = (x_0, y_0)$, and we expect $\\Delta I = 0$.\n\nThe following algorithm will be implemented:\n$1$. For each test case, retrieve the parameters $a, b, c, d$ and the initial/final conditions $x_0, y_0, T, h$.\n$2$. Implement a function `run_simulation` that performs the time-stepping loop using the explicit midpoint method.\n$3$. Implement a function `I(x, y, ...)` to compute the conserved quantity.\n$4$. For cases A, B, D, and E, calculate $\\Delta I$ by first computing the initial value $I(x_0, y_0)$, then running the simulation to find $(x_T, y_T)$, computing the final value $I(x_T, y_T)$, and taking the absolute difference.\n$5$. For case C, use the computed $\\Delta I$ values from cases A and B to calculate $p$.\n$6$. Collect all results, format them to $10$ decimal places, and print them in the specified list format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Lotka-Volterra problem for the given test cases.\n    \"\"\"\n    \n    # Define problem parameters\n    a, b, c, d = 1.0, 0.5, 0.75, 0.25\n\n    # Define the test cases from the problem statement.\n    # Format: (x0, y0, T, h)\n    test_cases = [\n        (1.5, 1.0, 20.0, 0.1),        # Case A\n        (1.5, 1.0, 20.0, 0.05),       # Case B\n        # Case C is derived from A and B\n        (c / d, a / b, 9.0, 0.3),     # Case D\n        (1.2, 0.8, 0.0, 0.1),         # Case E\n    ]\n\n    def conserved_quantity(x, y, a, b, c, d):\n        \"\"\"Computes the conserved quantity I(x, y).\"\"\"\n        return d * x - c * np.log(x) + b * y - a * np.log(y)\n\n    def run_simulation(x0, y0, T, h, a, b, c, d):\n        \"\"\"\n        Advances the Lotka-Volterra system using the explicit midpoint method.\n        \"\"\"\n        if T == 0.0:\n            return float(x0), float(y0)\n\n        num_steps = int(np.round(T / h))\n        x, y = float(x0), float(y0)\n\n        for _ in range(num_steps):\n            # Stage 1: Slope at current point\n            k1x = x * (a - b * y)\n            k1y = y * (-c + d * x)\n            \n            # State at midpoint\n            x_mid = x + 0.5 * h * k1x\n            y_mid = y + 0.5 * h * k1y\n\n            # Stage 2: Slope at midpoint\n            k2x = x_mid * (a - b * y_mid)\n            k2y = y_mid * (-c + d * x_mid)\n\n            # Update step using midpoint slope\n            x += h * k2x\n            y += h * k2y\n            \n        return x, y\n\n    # List to store final computed values for [A, B, C, D, E]\n    results = []\n    \n    # Store delta_I for cases A and B to use for C\n    delta_I_ab = []\n\n    # Process cases A and B\n    for params in test_cases[:2]:\n        x0, y0, T, h = params\n        I0 = conserved_quantity(x0, y0, a, b, c, d)\n        xT, yT = run_simulation(x0, y0, T, h, a, b, c, d)\n        IT = conserved_quantity(xT, yT, a, b, c, d)\n        delta_I = np.abs(IT - I0)\n        results.append(delta_I)\n        delta_I_ab.append(delta_I)\n\n    # Process case C (Observed order p)\n    h1 = test_cases[0][3]  # h from Case A\n    h2 = test_cases[1][3]  # h from Case B\n    delta_I_h1 = delta_I_ab[0]\n    delta_I_h2 = delta_I_ab[1]\n    \n    # The order p is calculated using the drift values from A and B\n    p = np.log(delta_I_h2 / delta_I_h1) / np.log(h2 / h1)\n    results.append(p)\n    \n    # Process cases D and E\n    for params in test_cases[2:]:\n        x0, y0, T, h = params\n        I0 = conserved_quantity(x0, y0, a, b, c, d)\n        xT, yT = run_simulation(x0, y0, T, h, a, b, c, d)\n        IT = conserved_quantity(xT, yT, a, b, c, d)\n        delta_I = np.abs(IT - I0)\n        results.append(delta_I)\n    \n    # Final print statement in the exact required format.\n    # Each float is rounded to 10 decimal places.\n    formatted_results = [f\"{val:.10f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2413563"}, {"introduction": "Using a fixed step size is inefficient: it may be too large where the solution changes rapidly, compromising accuracy, or too small where the solution is smooth, wasting computation. This practice guides you in building an adaptive step-size controller, the engine behind modern scientific computing software. By comparing the result of a single step of size $h$ with two steps of size $h/2$, we can estimate the local error and use this to automatically adjust the step size, maintaining accuracy while optimizing performance.", "problem": "You are tasked with writing a complete, runnable program that integrates a scalar ordinary differential equation (ODE) using the explicit midpoint method with an adaptive step-size controller based on comparing one step of size $h$ against two steps of size $h/2$. Consider a scalar ODE of the form $y'(t) = f(t,y)$ with an initial condition $y(t_0) = y_0$, where $t$ is time and $y$ is the state variable.\n\nYour program must implement the following mathematical specifications:\n\n- The explicit midpoint one-step update for step size $h$ is\n$$\n\\Phi_h(t,y) \\equiv y + h \\, f\\!\\left(t + \\frac{h}{2},\\, y + \\frac{h}{2} f(t,y)\\right).\n$$\n\n- Define the single full-step approximation by $y_h = \\Phi_h(t,y)$. Define the two half-step composition by first computing $y_{h/2}^{(1)} = \\Phi_{h/2}(t,y)$ and then $y_{h/2}^{(2)} = \\Phi_{h/2}(t + h/2,\\, y_{h/2}^{(1)})$. Use $y_{h/2}^{(2)}$ as the higher-quality approximation at the end of the step.\n\n- The local error estimate for a step of size $h$ is given by\n$$\n\\mathrm{err} = \\frac{\\lvert y_{h/2}^{(2)} - y_h \\rvert}{2^2 - 1}.\n$$\n\n- For a given absolute tolerance $\\mathrm{atol}$ and relative tolerance $\\mathrm{rtol}$, define the scalar acceptance threshold\n$$\n\\tau = \\mathrm{atol} + \\mathrm{rtol} \\cdot \\max\\!\\big(\\lvert y_h \\rvert,\\, \\lvert y_{h/2}^{(2)} \\rvert\\big).\n$$\nAccept the step if $\\mathrm{err} \\le \\tau$. When a step is accepted, advance $(t,y) \\leftarrow (t+h,\\, y_{h/2}^{(2)})$.\n\n- Upon each attempted step (whether accepted or rejected), update the step size according to the controller\n$$\nh_{\\mathrm{new}} = h \\cdot \\mathrm{clip}\\!\\left(s \\left(\\frac{\\tau}{\\mathrm{err}}\\right)^{1/3},\\, \\alpha_{\\min},\\, \\alpha_{\\max}\\right),\n$$\nwhere $s$ is a safety factor, the exponent $1/3$ follows from the leading local error of order $h^3$ for a second-order method, and $\\mathrm{clip}(x, a, b)$ constrains $x$ to the interval $[a,b]$. If $\\mathrm{err} = 0$, use the maximal growth factor, i.e., set the multiplicative term to $\\alpha_{\\max}$. Ensure that $h$ never steps past the target final time by truncating the last step if necessary so that the final time $t_{\\mathrm{end}}$ is reached exactly. Angles appearing in any trigonometric function must be interpreted in radians.\n\n- Use fixed controller parameters $s = 0.9$, $\\alpha_{\\min} = 0.2$, $\\alpha_{\\max} = 5.0$, and a minimum step size $h_{\\min} = 10^{-16}$. If $h$ falls below $h_{\\min}$ before reaching $t_{\\mathrm{end}}$, terminate the integration and return the current approximation.\n\nImplement the integrator and apply it to the following test suite. Each test case specifies $f(t,y)$, $t_0$, $y_0$, $t_{\\mathrm{end}}$, initial step size $h_0$, $\\mathrm{rtol}$, and $\\mathrm{atol}$. All numbers are unitless. All angles are in radians.\n\n- Test case $1$ (exponential decay):\n  - $f(t,y) = -2\\, y$,\n  - $t_0 = 0$,\n  - $y_0 = 1$,\n  - $t_{\\mathrm{end}} = 1$,\n  - $h_0 = 0.1$,\n  - $\\mathrm{rtol} = 10^{-8}$,\n  - $\\mathrm{atol} = 10^{-12}$.\n\n- Test case $2$ (logistic growth with unit carrying capacity):\n  - $f(t,y) = y \\, (1 - y)$,\n  - $t_0 = 0$,\n  - $y_0 = 0.2$,\n  - $t_{\\mathrm{end}} = 5$,\n  - $h_0 = 0.2$,\n  - $\\mathrm{rtol} = 10^{-7}$,\n  - $\\mathrm{atol} = 10^{-12}$.\n\n- Test case $3$ (linear equation with trigonometric forcing):\n  - $f(t,y) = \\cos(t) - y$,\n  - $t_0 = 0$,\n  - $y_0 = 0$,\n  - $t_{\\mathrm{end}} = 4$,\n  - $h_0 = 0.1$,\n  - $\\mathrm{rtol} = 10^{-9}$,\n  - $\\mathrm{atol} = 10^{-12}$.\n\n- Test case $4$ (fast exponential decay):\n  - $f(t,y) = -50\\, y$,\n  - $t_0 = 0$,\n  - $y_0 = 1$,\n  - $t_{\\mathrm{end}} = 0.1$,\n  - $h_0 = 0.05$,\n  - $\\mathrm{rtol} = 10^{-6}$,\n  - $\\mathrm{atol} = 10^{-12}$.\n\nYour program must run all four test cases in the order listed and, for each, return the numerical approximation of $y(t_{\\mathrm{end}})$. The final output must be a single line containing a Python-style list of the four results as decimal numbers, each rounded to exactly $10$ decimal places, in the order of the test suite, for example, $[x_1,x_2,x_3,x_4]$ where each $x_i$ is a float with $10$ digits after the decimal point. Your program must produce exactly one line of output in this format and must not read any input.", "solution": "The problem as stated is valid. It presents a well-defined task in computational physics: the numerical integration of a scalar ordinary differential equation (ODE) using the explicit midpoint method with an adaptive step-size controller. The problem is scientifically sound, self-contained, and all parameters and mathematical relations are specified unambiguously. I will now provide the solution.\n\nThe fundamental challenge in solving an ODE of the form $y'(t) = f(t,y)$ with an initial condition $y(t_0) = y_0$ is to approximate the continuous trajectory of $y(t)$ using a discrete sequence of points. An adaptive-step integrator is superior to a fixed-step integrator as it adjusts the step size $h$ to maintain a desired level of accuracy while minimizing computational effort, taking small steps in regions where the solution changes rapidly and large steps where it is smooth.\n\nThe core of the integrator is the explicit midpoint method, a second-order Runge-Kutta method. For a step from time $t$ to $t+h$, the state $y$ is advanced using the one-step update function $\\Phi_h(t,y)$:\n$$\n\\Phi_h(t,y) = y + h \\, f\\!\\left(t + \\frac{h}{2},\\, y + \\frac{h}{2} f(t,y)\\right)\n$$\nThis formula can be interpreted as a two-stage process. First, an intermediate state is estimated at the midpoint of the interval, $t+h/2$. Second, the slope at this midpoint is used to extrapolate across the full interval $h$.\n\nTo control the step size adaptively, we require an estimate of the local truncation errorâ€”the error incurred in a single step. The problem specifies a step-doubling approach. In this method, we compute the solution at $t+h$ in two ways:\n1. A single step of size $h$, yielding $y_h = \\Phi_h(t,y)$.\n2. Two consecutive steps of size $h/2$, yielding $y_{h/2}^{(2)} = \\Phi_{h/2}(t + h/2, \\Phi_{h/2}(t,y))$.\n\nSince the explicit midpoint method has a local truncation error of order $O(h^3)$, the exact solution $y(t+h)$ can be related to our numerical approximations:\n$$\ny_h = y(t+h) + C h^3 + O(h^4)\n$$\n$$\ny_{h/2}^{(2)} = y(t+h) + 2 C (h/2)^3 + O(h^4) = y(t+h) + \\frac{1}{4} C h^3 + O(h^4)\n$$\nwhere $C$ is a constant related to the derivatives of the solution. By subtracting these two equations, we can eliminate the unknown true value $y(t+h)$ and solve for the error term, $\\frac{1}{4} C h^3$, which is the error in the more accurate two-step approximation $y_{h/2}^{(2)}$. The magnitude of this error is estimated as:\n$$\n\\mathrm{err} = \\lvert y(t+h) - y_{h/2}^{(2)} \\rvert \\approx \\frac{\\lvert y_{h/2}^{(2)} - y_h \\rvert}{2^p - 1} = \\frac{\\lvert y_{h/2}^{(2)} - y_h \\rvert}{3}\n$$\nwhere $p=2$ is the order of the method.\n\nThis error estimate is then compared against a desired tolerance threshold, $\\tau$, which is a combination of an absolute tolerance $\\mathrm{atol}$ and a relative tolerance $\\mathrm{rtol}$:\n$$\n\\tau = \\mathrm{atol} + \\mathrm{rtol} \\cdot \\max\\!\\big(\\lvert y_h \\rvert,\\, \\lvert y_{h/2}^{(2)} \\rvert\\big)\n$$\nIf $\\mathrm{err} \\le \\tau$, the step is accepted, and the state is advanced to $(t+h, y_{h/2}^{(2)})$, using the more accurate approximation. If $\\mathrm{err} > \\tau$, the step is rejected, and the step is re-attempted from the same point $(t,y)$ but with a smaller step size.\n\nThe step size for the next attempt (whether the current one was accepted or rejected) is determined by a proportional-integral (PI) controller formula:\n$$\nh_{\\mathrm{new}} = h \\cdot \\mathrm{clip}\\!\\left(s \\left(\\frac{\\tau}{\\mathrm{err}}\\right)^{1/(p+1)},\\, \\alpha_{\\min},\\, \\alpha_{\\max}\\right)\n$$\nHere, $s=0.9$ is a safety factor to promote stability. The exponent is $1/(p+1)=1/3$ for our second-order method. The ratio $\\tau/\\mathrm{err}$ scales the step size: if the error is smaller than the tolerance, the step size is increased, and if it is larger, the step size is decreased. The $\\mathrm{clip}$ function, with minimum and maximum factors $\\alpha_{\\min}=0.2$ and $\\alpha_{\\max}=5.0$, prevents excessively aggressive changes to the step size. If $\\mathrm{err}=0$, the step size is multiplied by the maximum factor $\\alpha_{\\max}$.\n\nThe complete integration algorithm proceeds as follows:\nInitialize $t=t_0$, $y=y_0$, and an initial step size $h=h_0$. Loop until $t$ reaches $t_{\\mathrm{end}}$:\n1.  Check if the current step would overshoot $t_{\\mathrm{end}}$. If so, set $h = t_{\\mathrm{end}} - t$.\n2.  Enter an inner loop for the current step attempt.\n3.  Check if the current $h$ is below the minimum threshold $h_{\\min}$. If so, terminate the integration.\n4.  Compute $y_h$ and $y_{h/2}^{(2)}$.\n5.  Calculate the error $\\mathrm{err}$ and tolerance $\\tau$.\n6.  If the step is accepted ($\\mathrm{err} \\le \\tau$):\n    a. Advance the state: $t \\leftarrow t+h$, $y \\leftarrow y_{h/2}^{(2)}$.\n    b. Compute the next step size $h_{\\mathrm{new}}$ using the controller formula. Update $h \\leftarrow h_{\\mathrm{new}}$.\n    c. Exit the inner loop to proceed to the next integration step.\n7.  If the step is rejected ($\\mathrm{err} > \\tau$):\n    a. Compute a new, smaller step size $h_{\\mathrm{new}}$. Update $h \\leftarrow h_{\\mathrm{new}}$.\n    b. Repeat the inner loop to re-attempt the step from the same point $(t,y)$ with the smaller $h$.\n\nThis process is repeated until $t=t_{\\mathrm{end}}$, at which point the final value of $y$ is the desired numerical solution. This algorithm will be implemented for each of the four specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adaptive_midpoint_integrator(f, t0, y0, t_end, h0, rtol, atol):\n    \"\"\"\n    Integrates a scalar ODE y'(t) = f(t,y) using an adaptive explicit midpoint method.\n\n    Args:\n        f (callable): The function f(t, y).\n        t0 (float): Initial time.\n        y0 (float): Initial state.\n        t_end (float): Final time.\n        h0 (float): Initial step size.\n        rtol (float): Relative tolerance.\n        atol (float): Absolute tolerance.\n\n    Returns:\n        float: The numerical approximation of y(t_end).\n    \"\"\"\n    \n    # --- Controller parameters ---\n    S = 0.9          # Safety factor\n    ALPHA_MIN = 0.2  # Minimum step size scaling factor\n    ALPHA_MAX = 5.0  # Maximum step size scaling factor\n    H_MIN = 1e-16    # Minimum allowed step size\n\n    # --- One-step explicit midpoint update function ---\n    def phi(t_n, y_n, h_n, func):\n        \"\"\"Computes one step of the explicit midpoint method.\"\"\"\n        k1 = func(t_n, y_n)\n        y_mid = y_n + 0.5 * h_n * k1\n        t_mid = t_n + 0.5 * h_n\n        k2 = func(t_mid, y_mid)\n        return y_n + h_n * k2\n\n    # --- Initial conditions ---\n    t = float(t0)\n    y = float(y0)\n    h = float(h0)\n    \n    # --- Main integration loop ---\n    while t  t_end:\n        # Ensure the final step lands exactly on t_end\n        if t + h > t_end:\n            h = t_end - t\n\n        # --- Adaptive step control loop (accept/reject) ---\n        while True:\n            # Check for termination due to excessively small step size\n            if h  H_MIN:\n                return y \n\n            # Calculate one full step\n            y_h = phi(t, y, h, f)\n\n            # Calculate two half steps\n            h_half = h / 2.0\n            y_half_1 = phi(t, y, h_half, f)\n            y_half_2 = phi(t + h_half, y_half_1, h_half, f)\n\n            # Estimate local error\n            # Denominator is (2^p - 1) where p=2 for midpoint method\n            error_diff = abs(y_half_2 - y_h)\n            err = error_diff / 3.0\n\n            # Calculate tolerance threshold\n            y_scale = max(abs(y_h), abs(y_half_2))\n            tau = atol + rtol * y_scale\n\n            # Check for step acceptance\n            if err = tau:\n                # --- Step accepted ---\n                t += h\n                y = y_half_2  # Use the more accurate result\n                \n                # Calculate step size for the next step\n                if err == 0.0:\n                    factor = ALPHA_MAX\n                else:\n                    factor = S * (tau / err)**(1.0/3.0)\n                \n                # Clip factor and update h\n                h = h * min(ALPHA_MAX, max(ALPHA_MIN, factor))\n                \n                # Exit the inner loop to proceed to the next t\n                break\n            else:\n                # --- Step rejected ---\n                # Calculate a new, smaller step size and retry this step\n                if err == 0.0:\n                    # Should not be reached if err > tau, but for robustness\n                    factor = ALPHA_MIN\n                else:\n                    factor = S * (tau / err)**(1.0/3.0)\n                \n                # Clip the reducing factor and update h for the retry\n                h_new = h * min(ALPHA_MAX, max(ALPHA_MIN, factor))\n                h = h_new\n\n    return y\n\ndef solve():\n    \"\"\"\n    Runs the adaptive midpoint integrator on a suite of test cases and\n    prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (exponential decay)\n        {\n            \"f\": lambda t, y: -2.0 * y,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"t_end\": 1.0,\n            \"h0\": 0.1,\n            \"rtol\": 1e-8,\n            \"atol\": 1e-12,\n        },\n        # Test case 2 (logistic growth)\n        {\n            \"f\": lambda t, y: y * (1.0 - y),\n            \"t0\": 0.0,\n            \"y0\": 0.2,\n            \"t_end\": 5.0,\n            \"h0\": 0.2,\n            \"rtol\": 1e-7,\n            \"atol\": 1e-12,\n        },\n        # Test case 3 (linear equation with trigonometric forcing)\n        {\n            \"f\": lambda t, y: np.cos(t) - y,\n            \"t0\": 0.0,\n            \"y0\": 0.0,\n            \"t_end\": 4.0,\n            \"h0\": 0.1,\n            \"rtol\": 1e-9,\n            \"atol\": 1e-12,\n        },\n        # Test case 4 (fast exponential decay)\n        {\n            \"f\": lambda t, y: -50.0 * y,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"t_end\": 0.1,\n            \"h0\": 0.05,\n            \"rtol\": 1e-6,\n            \"atol\": 1e-12,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        final_y = adaptive_midpoint_integrator(\n            f=case[\"f\"],\n            t0=case[\"t0\"],\n            y0=case[\"y0\"],\n            t_end=case[\"t_end\"],\n            h0=case[\"h0\"],\n            rtol=case[\"rtol\"],\n            atol=case[\"atol\"],\n        )\n        results.append(final_y)\n\n    # Format the final output string as required\n    formatted_results = [f\"{r:.10f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "2413547"}]}