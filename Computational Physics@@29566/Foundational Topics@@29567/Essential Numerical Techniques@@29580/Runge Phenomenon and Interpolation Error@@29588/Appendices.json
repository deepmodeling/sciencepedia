{"hands_on_practices": [{"introduction": "This first exercise provides a direct and visual demonstration of the Runge phenomenon using a familiar function from quantum mechanics. You will interpolate the stationary state wave function of a particle in an infinite square well, $\\psi_n(x) = \\sin(n\\pi x/L)$. By comparing the interpolation error resulting from equispaced nodes versus Chebyshev-Lobatto nodes, this practice illustrates the fundamental mechanism behind the failure of high-degree polynomial interpolation and the effectiveness of non-uniform node placement [@problem_id:2436069].", "problem": "Consider the one-dimensional (1D) time-independent Schrödinger equation in an infinite square well of width $L$, whose normalized stationary states are given by $\\psi_{n}(x)=\\sin\\!\\left(\\dfrac{n\\pi x}{L}\\right)$ on the closed interval $[0,L]$, where $n$ is a positive integer and the sine function takes its argument in radians. For a given integer $M\\geq 2$, define an interpolation node set $\\{x_{j}\\}_{j=0}^{M-1}\\subset[0,L]$ and the unique polynomial $p(x)$ of degree at most $M-1$ that satisfies $p(x_{j})=\\psi_{n}(x_{j})$ for all $j$. For each case in the test suite below, your task is to compute the maximum absolute interpolation error on a uniform evaluation grid of $Q$ points, defined by\n$$E=\\max_{0\\leq k \\leq Q-1}\\left|\\psi_{n}(x_{k})-p(x_{k})\\right|,\\quad x_{k}=\\frac{k\\,L}{Q-1},$$\nwith $Q=10001$. All quantities are dimensionless, and all angles are in radians.\n\nTwo node-set types are to be used:\n- Equispaced nodes: $x_{j}=\\dfrac{j\\,L}{M-1}$ for $j=0,1,\\dots,M-1$.\n- Chebyshev–Lobatto (CL) nodes mapped to $[0,L]$: $x_{j}=\\dfrac{L}{2}\\left(1-\\cos\\!\\left(\\dfrac{j\\pi}{M-1}\\right)\\right)$ for $j=0,1,\\dots,M-1$.\n\nFor each parameter tuple $(L,n,M,\\text{node\\_type})$ in the test suite, construct the corresponding polynomial interpolant $p(x)$ and compute $E$ as defined above.\n\nTest suite (in the exact order to be used for output):\n1. $(L=\\;1,\\;n=\\;3,\\;M=\\;9,\\;\\text{node\\_type}=\\text{equispaced})$,\n2. $(L=\\;1,\\;n=\\;15,\\;M=\\;9,\\;\\text{node\\_type}=\\text{equispaced})$,\n3. $(L=\\;1,\\;n=\\;15,\\;M=\\;9,\\;\\text{node\\_type}=\\text{CL})$,\n4. $(L=\\;1,\\;n=\\;20,\\;M=\\;21,\\;\\text{node\\_type}=\\text{equispaced})$,\n5. $(L=\\;1,\\;n=\\;20,\\;M=\\;21,\\;\\text{node\\_type}=\\text{CL})$,\n6. $(L=\\;2,\\;n=\\;15,\\;M=\\;21,\\;\\text{node\\_type}=\\text{equispaced})$,\n7. $(L=\\;1,\\;n=\\;50,\\;M=\\;51,\\;\\text{node\\_type}=\\text{equispaced})$,\n8. $(L=\\;1,\\;n=\\;50,\\;M=\\;51,\\;\\text{node\\_type}=\\text{CL})$.\n\nYour program should produce a single line of output containing the $8$ results as a comma-separated list enclosed in square brackets, in the same order as the test suite. Each result must be a floating-point number equal to $E$ for the corresponding case, rounded to exactly $8$ digits after the decimal point (for example, $[0.12345679,0.00000001,\\dots]$).", "solution": "The problem presented is a well-defined exercise in computational physics and numerical analysis, specifically concerning the error analysis of polynomial interpolation. It requires the computation of the maximum absolute error when approximating a given function, derived from the stationary states of the one-dimensional quantum infinite square well, with a polynomial interpolant. The core of the problem is to compare the efficacy of two different sets of interpolation nodes: equispaced nodes and Chebyshev-Lobatto nodes.\n\nThe problem is scientifically and mathematically sound. The function to be interpolated is $\\psi_{n}(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right)$, which is an analytic function on the entire real line, making it infinitely differentiable and well-suited for such analysis. The task is to construct a unique polynomial $p(x)$ of degree at most $M-1$ that passes through $M$ given points $(x_j, \\psi_{n}(x_j))$. The existence and uniqueness of such a polynomial is a cornerstone of numerical analysis.\n\nThe methodology for solving this problem involves the following steps:\n1. For each test case specified by the parameters $(L, n, M, \\text{node\\_type})$, the set of $M$ interpolation nodes $\\{x_j\\}_{j=0}^{M-1}$ is generated within the interval $[0, L]$.\n    - For equispaced nodes, the formula is $x_j = j \\frac{L}{M-1}$.\n    - For Chebyshev-Lobatto (CL) nodes, the formula is $x_j = \\frac{L}{2}\\left(1 - \\cos\\left(\\frac{j\\pi}{M-1}\\right)\\right)$. This distribution maps the extrema of the Chebyshev polynomial of the first kind, $T_{M-1}(t)$, from the canonical interval $[-1, 1]$ to $[0, L]$.\n\n2. The corresponding function values $\\{y_j = \\psi_n(x_j)\\}_{j=0}^{M-1}$ are computed.\n\n3. The interpolating polynomial $p(x)$ is constructed. While the Lagrange formula provides the theoretical definition of $p(x)$, its direct implementation is numerically unstable for high degrees. A superior method for evaluation is the barycentric interpolation formula. Given the nodes $x_j$ and values $y_j$, the polynomial can be evaluated at any point $x$ as:\n$$ p(x) = \\frac{\\sum_{j=0}^{M-1} \\frac{w_j}{x - x_j} y_j}{\\sum_{j=0}^{M-1} \\frac{w_j}{x - x_j}} $$\nwhere $w_j$ are the barycentric weights. This form is numerically stable and efficient. The `scipy.interpolate.BarycentricInterpolator` class provides a robust implementation of this method.\n\n4. To find the maximum interpolation error, $E$, a fine, uniform grid of $Q=10001$ evaluation points, $\\{x_k\\}_{k=0}^{Q-1}$, is created over $[0, L]$.\n\n5. The absolute error $|\\psi_n(x_k) - p(x_k)|$ is computed at each evaluation point $x_k$. The maximum of these values is taken as the result $E$:\n$$ E = \\max_{k} |\\psi_n(x_k) - p(x_k)| $$\n\nThis problem serves to demonstrate a critical concept in approximation theory: the choice of interpolation nodes profoundly impacts the accuracy of the approximation. The error of polynomial interpolation is bounded by a term that depends on the $(M)$-th derivative of the function and the node polynomial $\\omega(x) = \\prod_{j=0}^{M-1}(x - x_j)$. Chebyshev-Lobatto nodes minimize the maximum value of $|\\omega(x)|$ over the interval, leading to a much smaller theoretical error bound compared to equispaced nodes. For equispaced nodes, the interpolation error can grow uncontrollably near the interval boundaries as $M$ increases, a behavior known as Runge's phenomenon. This is especially pronounced when the function being interpolated has large derivatives, as is the case for $\\sin(k x)$ with large $k$. The problem's test cases are designed to highlight this precise behavior. Cases with large ratios of $n$ to $M$ and equispaced nodes are expected to yield substantial errors, which will be significantly mitigated by using Chebyshev-Lobatto nodes.\n\nThe algorithm is implemented in Python, leveraging a vectorized approach with the `numpy` library for efficient array computations and `scipy.interpolate.BarycentricInterpolator` for stable polynomial construction and evaluation. The procedure is executed for each of the eight test cases, and the resulting maximum errors are collected and formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\ndef solve():\n    \"\"\"\n    Solves the interpolation error problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (L, n, M, node_type)\n        (1.0, 3, 9, 'equispaced'),\n        (1.0, 15, 9, 'equispaced'),\n        (1.0, 15, 9, 'CL'),\n        (1.0, 20, 21, 'equispaced'),\n        (1.0, 20, 21, 'CL'),\n        (2.0, 15, 21, 'equispaced'),\n        (1.0, 50, 51, 'equispaced'),\n        (1.0, 50, 51, 'CL'),\n    ]\n\n    results = []\n    Q = 10001 # Number of evaluation points\n\n    for L, n, M, node_type in test_cases:\n        # 1. Define the function to be interpolated\n        # psi_n(x) = sin(n*pi*x/L)\n        psi_n = lambda x: np.sin(n * np.pi * x / L)\n\n        # 2. Generate M interpolation nodes\n        if node_type == 'equispaced':\n            x_interp = np.linspace(0.0, L, M)\n        elif node_type == 'CL':\n            j = np.arange(M)\n            # Chebyshev-Lobatto nodes mapped from [-1, 1] to [0, L]\n            x_interp = L / 2.0 * (1.0 - np.cos(j * np.pi / (M - 1)))\n        \n        # 3. Compute function values at interpolation nodes\n        y_interp = psi_n(x_interp)\n\n        # 4. Construct the barycentric interpolant\n        poly = BarycentricInterpolator(x_interp, y_interp)\n\n        # 5. Define the fine evaluation grid\n        x_eval = np.linspace(0.0, L, Q)\n\n        # 6. Evaluate the true function and the polynomial on the grid\n        y_true = psi_n(x_eval)\n        y_poly = poly(x_eval)\n\n        # 7. Compute the maximum absolute error\n        max_error = np.max(np.abs(y_true - y_poly))\n        results.append(max_error)\n\n    # Final print statement in the exact required format.\n    # Each result is rounded to exactly 8 digits after the decimal point.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "2436069"}, {"introduction": "Having seen how interpolation error manifests with a smooth function, we now explore its consequences in a practical data analysis scenario. This exercise challenges you to reconstruct a probability density function (PDF) from simulated histogram data using polynomial interpolation [@problem_id:2436095]. You will test whether the resulting polynomial respects the two fundamental constraints of a PDF, non-negativity and unit normalization, thereby revealing how the oscillations from Runge's phenomenon can lead to physically meaningless models.", "problem": "You are given the task of reconstructing a probability density function (PDF) from binned histogram data using global polynomial interpolation and assessing the reconstruction for two essential properties: non-negativity over its support and normalization to unity. This exercise connects interpolation error and Runge’s phenomenon to physical constraints of a PDF. The fundamental bases to use are the definitions that a probability density function (PDF) $f(x)$ is non-negative for all $x$ in its support and integrates to $1$, i.e., $\\int_{a}^{b} f(x)\\,dx = 1$, and the description of a histogram as a piecewise-constant approximation of $f(x)$ whose bin-average values approximate the local average of $f(x)$ over each bin. The objective is to understand how interpolation error, particularly the oscillatory behavior emphasized by Runge’s phenomenon at equispaced nodes, can violate these constraints when a high-degree polynomial is used.\n\nConstruct the following algorithm from first principles:\n1. Let the support of the distribution be a closed interval $[a,b]$ and let it be partitioned into $m$ equispaced bins with edges $x_0=a, x_1, \\ldots, x_m=b$ and bin width $\\Delta x = (b-a)/m$. Let the bin centers be $c_i = (x_i + x_{i+1})/2$ for $i=0,\\ldots,m-1$.\n2. Given a known target density $f(x)$ defined on $[a,b]$ (each case below defines $f(x)$ and ensures $\\int_a^b f(x)\\,dx = 1$), compute for each bin the exact bin probability $p_i = \\int_{x_i}^{x_{i+1}} f(x)\\,dx$ using accurate numerical quadrature, and then compute the bin-averaged density $\\bar{f}_i = p_i / \\Delta x$.\n3. Form a global polynomial $P_n(x)$ of degree $n$ that interpolates the bin-averaged data at the bin centers, i.e., $P_n(c_i) = \\bar{f}_i$ for all $i$. Use equispaced centers $\\{c_i\\}$, not any special nodes.\n4. Assess the two PDF constraints for the interpolant:\n   - Non-negativity: check whether $P_n(x) \\ge 0$ for all $x \\in [a,b]$ to within a specified tolerance $T_{\\mathrm{pos}}$. Implement this as $ \\min_{x \\in \\mathcal{G}} P_n(x) \\ge -T_{\\mathrm{pos}}$, where $\\mathcal{G}$ is a sufficiently fine uniform grid on $[a,b]$.\n   - Normalization: compute the integral of $P_n(x)$ over $[a,b]$ exactly by integrating the polynomial analytically, and check whether $|\\int_a^b P_n(x)\\,dx - 1| \\le T_{\\mathrm{int}}$.\n5. Use the tolerance values $T_{\\mathrm{pos}} = 10^{-6}$ and $T_{\\mathrm{int}} = 10^{-3}$, both unitless.\n\nUse the following test suite of three cases that collectively probe a happy path, a high-degree equispaced-node scenario that is prone to oscillations, and a boundary-concentrated smooth density:\n- Case $1$ (Runge-like density on $[-1,1]$, many bins): Let $f(x) = C_{\\mathrm{R}} \\, \\frac{1}{1 + 25 x^2}$ on $[a,b]=[-1,1]$, where $C_{\\mathrm{R}}$ is chosen so that $\\int_{-1}^{1} f(x)\\,dx = 1$. The exact integral is $\\int_{-1}^{1} \\frac{dx}{1+25x^2} = \\frac{2}{5}\\arctan(5)$; hence $C_{\\mathrm{R}} = \\frac{5}{2\\arctan(5)}$. Use $m=21$ bins and polynomial degree $n=20$.\n- Case $2$ (Truncated Gaussian on $[-3,3]$, moderate bins): Let $f(x) = C_{\\mathrm{G}} \\exp\\!\\left(-\\frac{x^2}{2}\\right)$ on $[a,b]=[-3,3]$, where $C_{\\mathrm{G}}$ normalizes the integral over $[-3,3]$. The exact integral is $\\int_{-3}^{3} \\exp\\!\\left(-\\frac{x^2}{2}\\right)\\,dx = \\sqrt{2\\pi}\\,\\mathrm{erf}\\!\\left(\\frac{3}{\\sqrt{2}}\\right)$, so $C_{\\mathrm{G}} = \\left[\\sqrt{2\\pi}\\,\\mathrm{erf}\\!\\left(\\frac{3}{\\sqrt{2}}\\right)\\right]^{-1}$. Use $m=11$ bins and polynomial degree $n=10$.\n- Case $3$ (Beta density on $[0,1]$ with moderate skew, few bins): Let $f(x)= \\text{BetaPDF}_{\\alpha,\\beta}(x)$ on $[a,b]=[0,1]$ with $\\alpha=2$ and $\\beta=5$, i.e., $f(x) = C_{\\mathrm{B}}\\, x^{\\alpha-1}(1-x)^{\\beta-1}$ with $C_{\\mathrm{B}} = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} = \\frac{\\Gamma(7)}{\\Gamma(2)\\Gamma(5)} = 30$. Use $m=6$ bins and polynomial degree $n=5$.\n\nAngle units are not applicable. Physical units are not applicable. Express all tolerances and errors as unitless quantities.\n\nProgram requirements:\n- Implement numerical quadrature for $p_i$ using a sufficiently accurate deterministic method; for example, use Gauss–Legendre quadrature with at least $64$ nodes per bin.\n- Build the interpolating polynomial $P_n(x)$ that exactly matches the bin-averaged values at the equispaced bin centers.\n- Evaluate non-negativity on a uniform grid of at least $20001$ points in $[a,b]$.\n- Integrate the polynomial exactly by analytic antiderivation.\n- For each test case, produce two booleans:\n  - The first boolean is true if $P_n(x)$ is non-negative within tolerance $T_{\\mathrm{pos}}$ on $[a,b]$, false otherwise.\n  - The second boolean is true if the integral error is within $T_{\\mathrm{int}}$, false otherwise.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The aggregated output must list, in order, for Case $1$, the non-negativity boolean then the normalization boolean, followed by the same pair for Case $2$, and then for Case $3$. For example, an output with three cases could look like \"[True,False,True,True,False,True]\" where each pair corresponds to one case in sequence.", "solution": "The objective is to reconstruct a probability density function from its binned representation using a global interpolating polynomial and to assess whether this reconstruction maintains the fundamental physical properties of a PDF: non-negativity and unit normalization. This analysis highlights how high-degree polynomial interpolation over equispaced nodes can fail, a phenomenon epitomized by Runge's discovery. The procedure is methodical.\n\n**Step 1: Generation of Interpolation Data**\nThe raw data for interpolation are not function values at specific points, but rather mean values over finite intervals (bins). For a domain $[a,b]$ partitioned into $m$ bins of width $\\Delta x = (b-a)/m$, the $i$-th bin occupies the interval $[x_i, x_{i+1}]$, where $x_i = a + i\\Delta x$. The value to be interpolated at the bin center, $c_i = (x_i + x_{i+1})/2$, is the bin-averaged density, $\\bar{f}_i$. This is computed as:\n$$\n\\bar{f}_i = \\frac{1}{\\Delta x} p_i = \\frac{1}{\\Delta x} \\int_{x_i}^{x_{i+1}} f(x) \\, dx\n$$\nThe integral for the bin probability, $p_i$, must be computed with high accuracy to ensure the data for interpolation are reliable. The problem specifies Gauss-Legendre quadrature with at least $64$ nodes. This is a high-order method appropriate for the smooth functions under consideration, ensuring that the numerical integration error is negligible compared to the interpolation and model errors being studied.\n\n**Step 2: Construction of the Interpolating Polynomial**\nGiven the set of $m$ data points $\\{(c_i, \\bar{f}_i)\\}_{i=0}^{m-1}$, we seek the unique polynomial $P_n(x)$ of degree $n=m-1$ that satisfies the interpolation conditions $P_n(c_i) = \\bar{f}_i$. We can represent this polynomial in the monomial basis:\n$$\nP_n(x) = \\sum_{k=0}^{n} a_k x^k\n$$\nThe coefficients $\\{a_k\\}$ are determined by solving the system of $m$ linear equations:\n$$\n\\sum_{k=0}^{n} a_k c_i^k = \\bar{f}_i, \\quad \\text{for } i = 0, 1, \\ldots, n\n$$\nThis is a Vandermonde linear system, $\\mathbf{V}\\mathbf{a} = \\mathbf{\\bar{f}}$. While numerically sensitive for high degrees, for the degrees specified ($n=5, 10, 20$), standard numerical linear algebra routines, such as those encapsulated in `numpy.polyfit`, can robustly determine the coefficients $a_k$.\n\n**Step 3: Verification of PDF Properties**\nThe resulting polynomial $P_n(x)$ is a candidate for a PDF. It must be tested against two fundamental properties.\n\nFirst, **non-negativity**: $P_n(x) \\ge 0$ must hold for all $x \\in [a,b]$. High-degree polynomial interpolants over equispaced nodes are known to exhibit oscillatory behavior near the interval boundaries (Runge's phenomenon). These oscillations can cause the polynomial to dip below zero, violating a core principle of probability theory. This is checked numerically by evaluating $P_n(x)$ on a dense grid $\\mathcal{G}$ of points in $[a,b]$ and verifying that the minimum value is not less than a small negative tolerance, i.e., $\\min_{x \\in \\mathcal{G}} P_n(x) \\ge -T_{\\mathrm{pos}}$.\n\nSecond, **normalization**: The total probability must be one, $\\int_a^b P_n(x) \\, dx = 1$. The integral of the polynomial $P_n(x)$ can be calculated analytically, yielding an exact value for the model. The antiderivative of $P_n(x)$ is:\n$$\n\\int P_n(x) \\, dx = \\sum_{k=0}^{n} a_k \\frac{x^{k+1}}{k+1} + C\n$$\nThe definite integral is therefore:\n$$\n\\int_a^b P_n(x) \\, dx = \\sum_{k=0}^{n} a_k \\left( \\frac{b^{k+1} - a^{k+1}}{k+1} \\right)\n$$\nThis computed integral is then compared to $1$, and its absolute deviation must be within the specified tolerance $T_{\\mathrm{int}}$.\n\n**Analysis of Test Cases**\n- **Case 1 (Runge-like):** The function $f(x) \\propto 1/(1+25x^2)$ is the canonical example for demonstrating Runge's phenomenon. With $n=20$ equispaced nodes, large oscillations are expected near $x=-1$ and $x=1$. These oscillations will almost certainly cause $P_{20}(x)$ to become negative, failing the non-negativity test. The normalization may also fail due to the poor approximation at the boundaries.\n- **Case 2 (Truncated Gaussian):** The Gaussian function is exceptionally smooth and decays rapidly. Even with degree $n=10$, the interpolant is expected to behave well, as the function values are very small near the boundaries of $[-3,3]$, which mitigates the boundary oscillations characteristic of Runge's phenomenon. Both non-negativity and normalization properties are likely to be preserved.\n- **Case 3 (Beta Density):** The target function, $f(x)=30x(1-x)^4$, is itself a polynomial of degree $5$. We are interpolating data derived from it with a polynomial $P_5(x)$ of the same degree. Although the interpolation data are bin-averages, not point values, the resulting interpolant is expected to be an excellent approximation of the true function. One anticipates that both PDF properties will be satisfied with ease.\n\nThe provided code will execute this protocol for each case.", "answer": "```python\nimport numpy as np\nfrom scipy import special\nfrom scipy.integrate import fixed_quad\n\ndef solve():\n    \"\"\"\n    Solves the problem of validating a polynomial PDF reconstruction for three test cases.\n    \"\"\"\n\n    def solve_case(f_target, a, b, m, T_pos, T_int):\n        \"\"\"\n        Processes a single test case according to the problem description.\n\n        Args:\n            f_target (callable): The target probability density function.\n            a (float): The lower bound of the support.\n            b (float): The upper bound of the support.\n            m (int): The number of bins.\n            T_pos (float): The tolerance for non-negativity.\n            T_int (float): The tolerance for normalization.\n\n        Returns:\n            tuple[bool, bool]: A pair of booleans indicating if the non-negativity\n                               and normalization constraints are met, respectively.\n        \"\"\"\n        n = m - 1  # Polynomial degree\n        delta_x = (b - a) / m\n        \n        # 1. Define bin edges and centers\n        bin_edges = np.linspace(a, b, m + 1)\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n\n        # 2. Compute bin-averaged densities\n        f_bar = np.zeros(m)\n        quad_nodes = 64  # As per problem requirement\n        for i in range(m):\n            x_i, x_i_plus_1 = bin_edges[i], bin_edges[i+1]\n            \n            # Use high-order Gauss-Legendre quadrature for bin probability\n            p_i, _ = fixed_quad(f_target, x_i, x_i_plus_1, n=quad_nodes)\n            f_bar[i] = p_i / delta_x\n\n        # 3. Form the global interpolating polynomial\n        # np.polyfit with degree m-1 on m points gives the interpolating polynomial\n        poly_coeffs = np.polyfit(bin_centers, f_bar, n)\n\n        # 4. Assess PDF constraints\n        # 4.a Non-negativity check\n        grid_points = 20001 # As per problem requirement\n        x_grid = np.linspace(a, b, grid_points)\n        poly_values = np.polyval(poly_coeffs, x_grid)\n        \n        is_non_negative = np.min(poly_values) >= -T_pos\n\n        # 4.b Normalization check\n        # Integrate the polynomial analytically\n        integral_poly = np.polyint(poly_coeffs)\n        integral_value = np.polyval(integral_poly, b) - np.polyval(integral_poly, a)\n        \n        is_normalized = abs(integral_value - 1.0) <= T_int\n\n        return is_non_negative, is_normalized\n\n    # Tolerances\n    T_pos = 1e-6\n    T_int = 1e-3\n\n    # --- Test Case 1: Runge-like density ---\n    C_R = 5.0 / (2.0 * np.arctan(5.0))\n    def f_runge(x):\n        return C_R / (1.0 + 25.0 * x**2)\n    case1_params = {'f_target': f_runge, 'a': -1.0, 'b': 1.0, 'm': 21}\n\n    # --- Test Case 2: Truncated Gaussian ---\n    norm_const = np.sqrt(2.0 * np.pi) * special.erf(3.0 / np.sqrt(2.0))\n    C_G = 1.0 / norm_const\n    def f_gauss(x):\n        return C_G * np.exp(-x**2 / 2.0)\n    case2_params = {'f_target': f_gauss, 'a': -3.0, 'b': 3.0, 'm': 11}\n    \n    # --- Test Case 3: Beta density ---\n    # Beta(alpha=2, beta=5) PDF is C_B * x^(alpha-1) * (1-x)^(beta-1)\n    # C_B = Gamma(alpha+beta) / (Gamma(alpha)*Gamma(beta))\n    # For alpha=2, beta=5, C_B = Gamma(7)/(Gamma(2)*Gamma(5)) = 6!/(1!*4!) = 720/24 = 30\n    def f_beta(x):\n        return 30.0 * x**1 * (1.0 - x)**4\n    case3_params = {'f_target': f_beta, 'a': 0.0, 'b': 1.0, 'm': 6}\n\n    test_cases = [case1_params, case2_params, case3_params]\n    \n    results = []\n    for case_params in test_cases:\n        res_pair = solve_case(**case_params, T_pos=T_pos, T_int=T_int)\n        results.extend(res_pair)\n\n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2436095"}, {"introduction": "Our final practice pushes the boundaries by tackling a function that is continuous but not analytic: the quantum tunneling probability $T(E)$. This function features a \"kink\" at the barrier-top energy $E=V_0$, where its mathematical form changes abruptly. By attempting to approximate $T(E)$ with a single global polynomial, you will investigate how a function's lack of smoothness impacts interpolation accuracy and can severely amplify the Runge phenomenon [@problem_id:2436011].", "problem": "Write a complete, runnable program that quantifies interpolation error and illustrates the emergence or mitigation of Runge’s phenomenon when approximating a quantum mechanical tunneling probability function with a global polynomial interpolant. Consider a non-relativistic particle of mass $m$ incident on a one-dimensional rectangular barrier of height $V_0$ and width $a$. The transmission probability as a function of kinetic energy $E \\ge 0$ is defined by the following piecewise function, expressed in the International System of Units (SI):\n\nFor $0 \\le E < V_0$,\n$$\nT(E) = \\frac{1}{1 + \\dfrac{V_0^2 \\sinh^2\\!\\big(\\kappa a\\big)}{4 E (V_0 - E)}}, \\quad \\kappa = \\frac{\\sqrt{2 m (V_0 - E)}}{\\hbar}.\n$$\n\nFor $E = V_0$,\n$$\nT(E) = \\frac{1}{1 + \\dfrac{m V_0 a^2}{2 \\hbar^2}}.\n$$\n\nFor $E > V_0$,\n$$\nT(E) = \\frac{1}{1 + \\dfrac{V_0^2 \\sin^2\\!\\big(k_2 a\\big)}{4 E (E - V_0)}}, \\quad k_2 = \\frac{\\sqrt{2 m (E - V_0)}}{\\hbar}.\n$$\n\nIf $E = 0$, take $T(0) = 0$. Here $\\hbar$ is the reduced Planck constant. The function $T(E)$ is dimensionless. All computations inside these formulas must be performed in SI units. Energies given in electronvolts must be converted to joules using $1\\ \\text{electronvolt} = 1.602176634 \\times 10^{-19}\\ \\text{joule}$, lengths given in nanometers must be converted to meters using $1\\ \\text{nanometer} = 1.0 \\times 10^{-9}\\ \\text{meter}$, and the reduced Planck constant and the electron mass must be taken as\n$$\n\\hbar = 1.054571817 \\times 10^{-34}\\ \\text{joule}\\cdot\\text{second}, \\quad m_e = 9.1093837015 \\times 10^{-31}\\ \\text{kilogram}.\n$$\n\nFor each test case in the suite below, do the following:\n\n1. Use $m = m_e$.\n2. Define the energy interval as $[0, E_{\\max}]$ with $E_{\\max} = \\alpha V_0$, where $\\alpha$ is a unitless factor provided in the test case, and both $E_{\\max}$ and $V_0$ must be used in joules inside $T(E)$.\n3. Construct the unique polynomial interpolant of degree at most $N-1$ that interpolates $T(E)$ at $N$ nodes in $[0, E_{\\max}]$, where the node set is specified by a node-type flag:\n   - If the node type is “equispaced”, the nodes are $x_i = \\dfrac{i}{N-1} E_{\\max}$ for $i = 0, 1, \\ldots, N-1$.\n   - If the node type is “Chebyshev”, the nodes are the $N$ Chebyshev points of the first kind mapped from $[-1,1]$ to $[0, E_{\\max}]$, namely $x_i = \\dfrac{E_{\\max}}{2}\\left(1 + \\cos\\!\\left(\\dfrac{2 i + 1}{2 N} \\pi\\right)\\right)$ for $i = 0, 1, \\ldots, N-1$.\n4. Evaluate the maximum absolute interpolation error over a uniform evaluation grid of $1001$ points in $[0, E_{\\max}]$, that is, over the set $\\left\\{ 0, \\dfrac{E_{\\max}}{1000}, \\dfrac{2 E_{\\max}}{1000}, \\ldots, E_{\\max} \\right\\}$, by comparing the interpolant against the exact $T(E)$ at these grid points. Report the maximum absolute error as a dimensionless decimal number.\n\nYour program must compute and output, in a single line, the list of maximum absolute errors for the following test suite, in the order listed:\n\n- Test case $1$: $V_0 = 0.6\\ \\text{electronvolt}$, $a = 1.0\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 11$, node type = equispaced.\n- Test case $2$: $V_0 = 0.6\\ \\text{electronvolt}$, $a = 1.0\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 11$, node type = Chebyshev.\n- Test case $3$: $V_0 = 0.6\\ \\text{electronvolt}$, $a = 1.0\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 41$, node type = equispaced.\n- Test case $4$: $V_0 = 0.6\\ \\text{electronvolt}$, $a = 1.0\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 41$, node type = Chebyshev.\n- Test case $5$: $V_0 = 0.8\\ \\text{electronvolt}$, $a = 2.0\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 21$, node type = equispaced.\n- Test case $6$: $V_0 = 0.3\\ \\text{electronvolt}$, $a = 0.3\\ \\text{nanometer}$, $\\alpha = 1.2$, $N = 21$, node type = equispaced.\n\nThe required final output format is a single line containing a comma-separated list of the six maximum absolute errors enclosed in square brackets, for example, “[e1,e2,e3,e4,e5,e6]”, where each $e_k$ is a decimal rounded to six significant digits. The errors are dimensionless, so no physical unit specification is required in the output. No additional text must be printed.", "solution": "The core of the problem is to approximate a given function, the quantum tunneling probability $T(E)$, using a single polynomial interpolant $P_{N-1}(E)$ of degree at most $N-1$. The error of this approximation is then quantified. The function $T(E)$ is defined for a particle of mass $m$ and kinetic energy $E \\ge 0$ incident on a potential barrier of height $V_0$ and width $a$. The function is piecewise, with its analytical form depending on whether the energy $E$ is less than, equal to, or greater than the barrier height $V_0$. The definitions are:\nFor $0 \\le E < V_0$:\n$$\nT(E) = \\frac{1}{1 + \\dfrac{V_0^2 \\sinh^2\\!\\big(\\kappa a\\big)}{4 E (V_0 - E)}}, \\quad \\text{where} \\quad \\kappa = \\frac{\\sqrt{2 m (V_0 - E)}}{\\hbar}\n$$\nFor $E = V_0$:\n$$\nT(E) = \\frac{1}{1 + \\dfrac{m V_0 a^2}{2 \\hbar^2}}\n$$\nFor $E > V_0$:\n$$\nT(E) = \\frac{1}{1 + \\dfrac{V_0^2 \\sin^2\\!\\big(k_2 a\\big)}{4 E (E - V_0)}}, \\quad \\text{where} \\quad k_2 = \\frac{\\sqrt{2 m (E - V_0)}}{\\hbar}\n$$\nA special case is given for $E=0$, where $T(0)=0$. Here, $\\hbar$ is the reduced Planck constant. Analysis shows that the function $T(E)$ is continuous for all $E \\ge 0$. However, the transition from hyperbolic sine (for $E < V_0$) to trigonometric sine (for $E > V_0$) indicates that the function is not analytic at $E=V_0$. This lack of analyticity is a key condition for the emergence of Runge's phenomenon when using high-degree polynomial interpolants with equispaced nodes.\n\nThe interpolation is performed over the energy interval $[0, E_{\\max}]$, where $E_{\\max} = \\alpha V_0$. The polynomial $P_{N-1}(E)$ is constructed to match the exact function $T(E)$ at $N$ specified points, or nodes, $\\{x_i\\}_{i=0}^{N-1}$. Two types of node distributions are considered:\n1. Equispaced nodes: $x_i = \\dfrac{i}{N-1} E_{\\max}$ for $i=0, 1, \\ldots, N-1$. These nodes are known to lead to large oscillations near the interval endpoints for non-analytic functions, a behavior known as Runge's phenomenon.\n2. Chebyshev nodes: $x_i = \\dfrac{E_{\\max}}{2}\\left(1 + \\cos\\!\\left(\\dfrac{(2i+1)\\pi}{2N}\\right)\\right)$ for $i=0, 1, \\ldots, N-1$. These nodes are the roots of the Chebyshev polynomial of the first kind $T_N(x)$, scaled and shifted to the interval $[0, E_{\\max}]$. Their density is higher near the endpoints, which is proven to suppress or mitigate Runge's phenomenon, leading to superior convergence properties for continuous functions.\n\nThe solution is implemented algorithmically as follows. For each test case, the parameters $V_0$, $a$, $\\alpha$, $N$, and the node type are used. All physical quantities given in non-SI units (electronvolts, nanometers) are first converted to their SI counterparts (joules, meters) using the provided conversion factors. The particle mass $m$ is set to the electron mass $m_e$.\n\nFirst, the set of $N$ interpolation nodes $\\{x_i\\}$ is generated according to the specified type. Then, the exact function value $y_i = T(x_i)$ is computed at each node, creating the data set $\\{(x_i, y_i)\\}_{i=0}^{N-1}$. A single polynomial interpolant $P_{N-1}(E)$ that passes through these $N$ points is then constructed. For numerical stability and efficiency, especially for large $N$, the barycentric interpolation formula is the method of choice. The `scipy.interpolate.BarycentricInterpolator` class provides a robust implementation of this technique.\n\nTo quantify the quality of the approximation, the maximum absolute error, $\\|T - P_{N-1}\\|_{\\infty}$, is estimated over the interval $[0, E_{\\max}]$. This is done by computing the error on a fine, uniform grid of $1001$ evaluation points, $\\{E_j\\}_{j=0}^{1000}$, where $E_j = j \\cdot E_{\\max} / 1000$. The maximum absolute error is then calculated as:\n$$\n\\text{Error} = \\max_{j} | T(E_j) - P_{N-1}(E_j) |\n$$\nThis procedure is repeated for each of the six test cases specified in the problem statement. The resulting maximum error values are collected and formatted to six significant digits. The final output is a list of these error values as a single line of text. The comparison between equispaced and Chebyshev nodes, and the effect of increasing the polynomial degree $N-1$, will directly illustrate the theoretical predictions of numerical analysis regarding interpolation error and Runge's phenomenon.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\ndef t_prob(E_J, V0_J, a_m):\n    \"\"\"\n    Calculates the quantum tunneling transmission probability T(E).\n    All inputs must be in SI units.\n    \"\"\"\n    # Physical constants in SI units\n    hbar = 1.054571817e-34  # J*s\n    m_e = 9.1093837015e-31  # kg\n\n    # Ensure E_J is a numpy array for vectorized operations\n    E = np.atleast_1d(E_J).astype(float)\n    T = np.zeros_like(E)\n\n    # Define condition masks for the piecewise function\n    mask_zero = (E == 0)\n    mask_tunnel = (E > 0) & (E < V0_J)\n    mask_barrier_top = (E == V0_J)\n    mask_above_barrier = (E > V0_J)\n\n    # Case 1: T(0) = 0\n    T[mask_zero] = 0.0\n\n    # Case 2: 0 < E < V0 (tunneling)\n    if np.any(mask_tunnel):\n        E_sub = E[mask_tunnel]\n        kappa = np.sqrt(2 * m_e * (V0_J - E_sub)) / hbar\n        sinh_term = np.sinh(kappa * a_m)\n        denom_term = (V0_J**2 * sinh_term**2) / (4 * E_sub * (V0_J - E_sub))\n        T[mask_tunnel] = 1.0 / (1.0 + denom_term)\n\n    # Case 3: E = V0\n    if np.any(mask_barrier_top):\n        denom_term = (m_e * V0_J * a_m**2) / (2 * hbar**2)\n        T[mask_barrier_top] = 1.0 / (1.0 + denom_term)\n\n    # Case 4: E > V0 (above-barrier transmission)\n    if np.any(mask_above_barrier):\n        E_sup = E[mask_above_barrier]\n        k2 = np.sqrt(2 * m_e * (E_sup - V0_J)) / hbar\n        sin_term = np.sin(k2 * a_m)\n        denom_term = (V0_J**2 * sin_term**2) / (4 * E_sup * (E_sup - V0_J))\n        T[mask_above_barrier] = 1.0 / (1.0 + denom_term)\n\n    # Return scalar if input was scalar\n    return T[0] if np.isscalar(E_J) else T\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Unit conversion factors\n    eV_to_J = 1.602176634e-19\n    nm_to_m = 1.0e-9\n\n    # Test cases from the problem statement\n    test_cases = [\n        # (V0_eV, a_nm, alpha, N, node_type)\n        (0.6, 1.0, 1.2, 11, \"equispaced\"),\n        (0.6, 1.0, 1.2, 11, \"Chebyshev\"),\n        (0.6, 1.0, 1.2, 41, \"equispaced\"),\n        (0.6, 1.0, 1.2, 41, \"Chebyshev\"),\n        (0.8, 2.0, 1.2, 21, \"equispaced\"),\n        (0.3, 0.3, 1.2, 21, \"equispaced\"),\n    ]\n\n    results = []\n    for V0_eV, a_nm, alpha, N, node_type in test_cases:\n        # Convert parameters to SI units\n        V0_J = V0_eV * eV_to_J\n        a_m = a_nm * nm_to_m\n\n        # Define the interpolation interval\n        E_max = alpha * V0_J\n\n        # Generate interpolation nodes based on type\n        if node_type == \"equispaced\":\n            x_nodes = np.linspace(0, E_max, N)\n        elif node_type == \"Chebyshev\":\n            # Chebyshev nodes of the first kind mapped to [0, E_max]\n            i = np.arange(N)\n            # The formula produces nodes in descending order, which is acceptable\n            cos_term = np.cos((2 * i + 1) * np.pi / (2 * N))\n            x_nodes = 0.5 * E_max * (1 + cos_term)\n        \n        # Compute exact function values at interpolation nodes\n        y_nodes = t_prob(x_nodes, V0_J, a_m)\n\n        # Construct the barycentric polynomial interpolant\n        poly_interpolant = BarycentricInterpolator(x_nodes, y_nodes)\n\n        # Create a fine grid for error evaluation\n        eval_grid = np.linspace(0, E_max, 1001)\n\n        # Evaluate the exact function and the interpolant on the grid\n        T_exact = t_prob(eval_grid, V0_J, a_m)\n        T_interp = poly_interpolant(eval_grid)\n        \n        # Find the maximum absolute error\n        max_error = np.max(np.abs(T_exact - T_interp))\n        \n        # Format result to six significant digits and store\n        results.append(\"{:.6g}\".format(max_error))\n\n    # Print the final list of errors in the required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2436011"}]}