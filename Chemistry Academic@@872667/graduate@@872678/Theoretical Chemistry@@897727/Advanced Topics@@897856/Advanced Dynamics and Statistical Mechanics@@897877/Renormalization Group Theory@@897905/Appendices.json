{"hands_on_practices": [{"introduction": "This exercise provides a concrete introduction to the Renormalization Group through the method of real-space decimation. By explicitly integrating out degrees of freedom in a simple 1D harmonic chain—a model relevant for polymer vibrations—you will see firsthand how a system can look like itself at a larger scale, but with renormalized parameters [@problem_id:2801692]. This practice is foundational for building intuition about how microscopic details are systematically removed to reveal large-scale effective laws.", "problem": "A classical one-dimensional chain of identical atoms models longitudinal vibrations in a polymer backbone. The chain is described by the Hamiltonian\n$$\nH=\\frac{1}{2}\\sum_{i=1}^{N}\\left[\\frac{p_i^2}{m}+\\kappa\\left(x_{i+1}-x_i\\right)^2\\right],\n$$\nwith periodic boundary conditions, where $N$ is even, $m$ is the mass, $\\kappa$ is the nearest-neighbor spring constant, $x_i$ is the displacement of site $i$, and $p_i$ is its conjugate momentum. Consider the canonical partition function at inverse temperature $\\beta=1/(k_{\\mathrm{B}}T)$:\n$$\nZ=\\int \\prod_{i=1}^{N} dx_i\\,dp_i\\,\\exp\\left(-\\beta H\\right).\n$$\nImplement a real-space decimation step of the Renormalization Group (RG), in which you integrate out all degrees of freedom on the odd sites. Use only the fundamental facts that (i) the canonical partition function is a phase-space Gaussian integral for a quadratic Hamiltonian, and (ii) Gaussian integration over a subset of variables yields another Gaussian in the remaining variables up to multiplicative constants. Assume translational invariance and periodic boundary conditions so that boundary terms can be neglected, and assume that only nearest-neighbor harmonic interactions are present microscopically.\n\nDerive the effective coarse-grained Hamiltonian for the even sites before any rescaling, and then perform a lattice rescaling step that restores the original lattice spacing by relabeling the even sites as nearest neighbors on a chain of length $N/2$ with lattice spacing identical to the original. Under what assumptions does the effective Hamiltonian retain the same harmonic functional form in terms of nearest-neighbor displacements, with a renormalized spring constant? State these assumptions explicitly. Finally, determine the explicit closed-form expression for the renormalized spring constant $\\kappa_{\\mathrm{R}}$ after this single decimation and rescaling step, expressed purely in terms of $\\kappa$. Provide your final answer as a single analytic expression for $\\kappa_{\\mathrm{R}}$ with no units.", "solution": "The problem as stated is scientifically grounded, self-contained, and well-posed. It is a standard pedagogical problem in statistical mechanics for illustrating the real-space renormalization group. We proceed with the solution.\n\nThe system is described by the Hamiltonian:\n$$\nH=\\frac{1}{2}\\sum_{i=1}^{N}\\left[\\frac{p_i^2}{m}+\\kappa\\left(x_{i+1}-x_i\\right)^2\\right]\n$$\nThe canonical partition function at inverse temperature $\\beta$ is given by:\n$$\nZ=\\int \\prod_{i=1}^{N} dx_i\\,dp_i\\,\\exp\\left(-\\beta H\\right)\n$$\nThe Hamiltonian is separable into kinetic and potential energy terms. The integration over the momenta $\\{p_i\\}$ can be performed independently of the positions $\\{x_i\\}$.\n$$\n\\int \\prod_{i=1}^{N} dp_i \\exp\\left(-\\frac{\\beta}{2m}\\sum_{i=1}^{N}p_i^2\\right) = \\left(\\int dp \\exp\\left(-\\frac{\\beta p^2}{2m}\\right)\\right)^N = \\left(\\sqrt{\\frac{2\\pi m}{\\beta}}\\right)^N\n$$\nThis part contributes a constant factor to the partition function and does not affect the renormalization of the potential energy parameters. We can therefore focus on the configurational part of the partition function, which involves integrating over the position coordinates $\\{x_i\\}$ with the potential energy $V = \\frac{1}{2}\\sum_{i=1}^{N}\\kappa(x_{i+1}-x_i)^2$.\nThe configurational partition function is:\n$$\nZ_x = \\int \\prod_{i=1}^{N} dx_i \\exp\\left(-\\beta V\\right)\n$$\nThe renormalization group decimation step requires integrating out the degrees of freedom corresponding to the odd-numbered sites, i.e., $\\{x_i, p_i\\}$ for $i=1, 3, \\dots, N-1$. As the momentum integrals for the odd sites simply contribute to an overall constant, we need only consider the integration of the odd-site position variables $\\{x_i\\}_{i \\text{ odd}}$.\n\nThe potential energy $V$ involves only nearest-neighbor interactions. An odd site $x_k$ (where $k$ is an odd integer) interacts only with its even-numbered neighbors, $x_{k-1}$ and $x_{k+1}$. The terms in the potential energy involving $x_k$ are $\\frac{\\kappa}{2}(x_k - x_{k-1})^2$ and $\\frac{\\kappa}{2}(x_{k+1} - x_k)^2$. Because each odd site is coupled only to its immediate even neighbors, the integrals over the different odd-site positions are independent of one another. We can write the integral over the odd sites as a product of integrals, one for each odd site:\n$$\n\\int \\prod_{i \\text{ odd}} dx_i \\exp(-\\beta V) = \\int \\prod_{i \\text{ odd}} dx_i \\exp\\left(-\\frac{\\beta \\kappa}{2} \\sum_{j \\text{ all}} (x_{j+1}-x_j)^2\\right) = \\prod_{k \\text{ odd}} \\int dx_k \\exp\\left(-\\frac{\\beta \\kappa}{2} \\left[ (x_k - x_{k-1})^2 + (x_{k+1} - x_k)^2 \\right] \\right)\n$$\nLet us evaluate a single one of these Gaussian integrals. The argument of the exponential for a given odd site $x_k$ is a quadratic function of $x_k$:\n$$\n-\\frac{\\beta \\kappa}{2} \\left[ (x_k - x_{k-1})^2 + (x_{k+1} - x_k)^2 \\right] = -\\frac{\\beta \\kappa}{2} \\left[ x_k^2 - 2x_k x_{k-1} + x_{k-1}^2 + x_{k+1}^2 - 2x_{k+1}x_k + x_k^2 \\right]\n$$\n$$\n= -\\frac{\\beta \\kappa}{2} \\left[ 2x_k^2 - 2x_k(x_{k-1} + x_{k+1}) + (x_{k-1}^2 + x_{k+1}^2) \\right]\n$$\nTo perform the integral over $x_k$, we complete the square for the terms involving $x_k$:\n$$\n2x_k^2 - 2x_k(x_{k-1} + x_{k+1}) = 2\\left[x_k^2 - x_k(x_{k-1} + x_{k+1})\\right] = 2\\left[\\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 - \\left(\\frac{x_{k-1} + x_{k+1}}{2}\\right)^2\\right]\n$$\nSubstituting this back into the exponent's argument gives:\n$$\n-\\frac{\\beta \\kappa}{2} \\left[ 2\\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 - \\frac{1}{2}(x_{k-1} + x_{k+1})^2 + x_{k-1}^2 + x_{k+1}^2 \\right]\n$$\n$$\n= -\\frac{\\beta \\kappa}{2} \\left[ 2\\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 + \\frac{1}{2}(x_{k-1}^2 - 2x_{k-1}x_{k+1} + x_{k+1}^2) \\right]\n$$\n$$\n= -\\beta \\kappa \\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 - \\frac{\\beta \\kappa}{4} (x_{k+1} - x_{k-1})^2\n$$\nThe integral over $x_k$ is now straightforward:\n$$\n\\int_{-\\infty}^{\\infty} dx_k \\exp\\left[ -\\beta \\kappa \\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 - \\frac{\\beta \\kappa}{4} (x_{k+1} - x_{k-1})^2 \\right] \n$$\n$$\n= \\exp\\left( - \\frac{\\beta \\kappa}{4} (x_{k+1} - x_{k-1})^2 \\right) \\int_{-\\infty}^{\\infty} dx_k \\exp\\left[ -\\beta \\kappa \\left(x_k - \\frac{x_{k-1} + x_{k+1}}{2}\\right)^2 \\right]\n$$\nThe integral evaluates to a constant, $\\sqrt{\\pi/(\\beta\\kappa)}$, which is independent of the remaining even-site coordinates. Combining all such constants from integrating over all $N/2$ odd sites gives an overall constant prefactor. The remaining part of the Boltzmann factor, which depends on the even-site coordinates, defines the effective potential, $V_{\\text{eff}}$.\nAfter integrating out all odd sites, the new Boltzmann factor for the even sites is:\n$$\n\\exp(-\\beta V_{\\text{eff}}) \\propto \\prod_{k \\text{ odd}} \\exp\\left( - \\frac{\\beta \\kappa}{4} (x_{k+1} - x_{k-1})^2 \\right) = \\exp\\left( - \\beta \\sum_{k \\text{ odd}} \\frac{\\kappa}{4} (x_{k+1} - x_{k-1})^2 \\right)\n$$\nThus, the effective potential for the even sites $\\{x_2, x_4, \\dots, x_N\\}$ is:\n$$\nV_{\\text{eff}} = \\sum_{k \\text{ odd}} \\frac{\\kappa}{4} (x_{k+1} - x_{k-1})^2 = \\frac{\\kappa}{4} \\sum_{j=1}^{N/2} (x_{2j+2}-x_{2j})^2\n$$\nwhere periodic boundary conditions are used ($x_{N+2} = x_2$). The effective Hamiltonian for the coarse-grained system of $N/2$ even-numbered sites, before rescaling, is:\n$$\nH_{\\text{eff}} = \\sum_{j=1}^{N/2} \\frac{p_{2j}^2}{2m} + \\frac{\\kappa}{4} \\sum_{j=1}^{N/2} (x_{2j+2}-x_{2j})^2\n$$\nThis effective Hamiltonian describes a new chain with $N/2$ sites. The interaction is again harmonic and between nearest neighbors on the new, coarser lattice. The preservation of this functional form is not a general feature of RG transformations. It holds here due to two critical assumptions:\n$1$. The original Hamiltonian is quadratic (harmonic) in the degrees of freedom. This makes the partition function a product of Gaussian integrals, and integrating over a subset of variables yields a new Gaussian function of the remaining variables.\n$2$. The interactions in the original Hamiltonian are strictly nearest-neighbor. This ensures that integrating out an odd site $x_k$ only creates a new effective interaction between its immediate neighbors $x_{k-1}$ and $x_{k+1}$, which become nearest neighbors on the coarse-grained lattice. If next-nearest-neighbor or longer-range interactions were present initially, decimation would generate a much more complex, non-local effective Hamiltonian.\n\nNow, we perform the lattice rescaling. We define a new set of coordinates for the coarse-grained lattice of size $N/2$:\n$$\nx'_j = x_{2j}, \\quad p'_j = p_{2j} \\quad \\text{for } j=1, 2, \\dots, N/2\n$$\nThe rescaled Hamiltonian $H_{\\text{R}}$ in terms of these new variables is:\n$$\nH_{\\text{R}} = \\sum_{j=1}^{N/2} \\frac{(p'_j)^2}{2m} + \\frac{\\kappa}{4} \\sum_{j=1}^{N/2} (x'_{j+1}-x'_{j})^2\n$$\nThe problem requires that this renormalized Hamiltonian has the same functional form as the original, i.e.,\n$$\nH_{\\text{R}} = \\frac{1}{2} \\sum_{j=1}^{N/2} \\left[ \\frac{(p'_j)^2}{m'} + \\kappa_{\\text{R}} (x'_{j+1}-x'_{j})^2 \\right]\n$$\nIn this case, no rescaling of mass is performed, so $m' = m$. We compare the potential energy terms:\n$$\n\\frac{1}{2} \\sum_{j=1}^{N/2} \\kappa_{\\text{R}} (x'_{j+1}-x'_{j})^2 = \\frac{\\kappa}{4} \\sum_{j=1}^{N/2} (x'_{j+1}-x'_{j})^2\n$$\nBy equating the coefficients, we find the relation for the renormalized spring constant $\\kappa_{\\text{R}}$:\n$$\n\\frac{\\kappa_{\\text{R}}}{2} = \\frac{\\kappa}{4}\n$$\nThis yields the final expression for the renormalized spring constant:\n$$\n\\kappa_{\\text{R}} = \\frac{\\kappa}{2}\n$$", "answer": "$$\n\\boxed{\\frac{\\kappa}{2}}\n$$", "id": "2801692"}, {"introduction": "We now move from real space to the more powerful momentum-space formulation of the RG, central to modern field theory. This problem tasks you with performing a Wilsonian momentum-shell integration for the classic $\\phi^4$ theory, the workhorse model for critical phenomena [@problem_id:2801635]. By deriving the one-loop flow equations, you will uncover the core mechanism of the RG: how coupling constants \"flow\" with the length scale and how these flows lead to the fixed points that dictate universal physical properties.", "problem": "Consider a single-component real scalar order-parameter field with Euclidean action $S[\\phi]=\\int d^d x \\left[\\frac{1}{2}(\\nabla \\phi)^2+\\frac{r}{2}\\phi^2+\\frac{u}{4!}\\phi^4\\right]$ and a sharp ultraviolet momentum cutoff $|\\mathbf{k}|\\le \\Lambda$. Perform a Wilsonian momentum-shell Renormalization Group (RG) step by integrating out the fast modes with $\\Lambda/b|\\mathbf{q}|\\le \\Lambda$, where $b=\\exp(\\ell)$ and $\\ell$ is infinitesimal, followed by the scale transformation $x'=x/b$ and field rescaling chosen to keep the coefficient of the kinetic term $\\frac{1}{2}(\\nabla \\phi)^2$ invariant. Work to one-loop order using a cumulant expansion and retain terms through order $u^2$ in the recursion relations. \n\nYour derivation must start from the path integral representation of the partition function $Z=\\int \\mathcal{D}\\phi\\,\\exp\\!\\left(-S[\\phi]\\right)$, the mode decomposition $\\phi=\\phi_+\\phi_$ into slow and fast modes, and the cumulant expansion for the effective action of the slow modes to the relevant order. Assume that wavefunction renormalization is absent at this order for the scalar $\\phi^4$ theory. Use the following definitions for geometric factors: $S_d=2\\pi^{d/2}/\\Gamma(d/2)$ and $K_d \\equiv \\frac{S_d}{2(2\\pi)^d}$. Define dimensionless couplings $\\tau \\equiv r/\\Lambda^2$ and $g \\equiv K_d\\,u\\,\\Lambda^{d-4}$. Keep the leading dependence on $\\tau$ in the one-loop shell integrals originating from the propagator denominators.\n\nDerive the differential recursion relations (beta functions) $d\\tau/d\\ell$ and $dg/d\\ell$ to order $u^2$, expressed entirely in terms of $d$, $\\tau$, and $g$. Provide the final answer as a single closed-form analytic row vector containing the two beta functions. No numerical evaluation is required, and no units are involved. The final answer must be a single analytic expression.", "solution": "The problem requires the derivation of the one-loop Renormalization Group (RG) beta functions for a scalar $\\phi^4$ theory in $d$ dimensions using a Wilsonian momentum-shell integration scheme.\n\nThe partition function is given by the path integral over the scalar field $\\phi$:\n$$Z = \\int \\mathcal{D}\\phi \\, \\exp(-S[\\phi])$$\nwhere the Euclidean action is\n$$S[\\phi] = \\int d^d x \\left[\\frac{1}{2}(\\nabla \\phi)^2 + \\frac{r}{2}\\phi^2 + \\frac{u}{4!}\\phi^4\\right]$$\nThe fields have a sharp ultraviolet momentum cutoff at $|\\mathbf{k}| \\le \\Lambda$.\n\nThe first step of the Wilsonian RG procedure is to decompose the field $\\phi$ into slow modes $\\phi_$ and fast modes $\\phi_$. In momentum space:\n$$\n\\phi(\\mathbf{k}) =\n\\begin{cases}\n\\phi_(\\mathbf{k})  \\text{for } 0 \\le |\\mathbf{k}| \\le \\Lambda/b \\\\\n\\phi_(\\mathbf{k})  \\text{for } \\Lambda/b  |\\mathbf{k}| \\le \\Lambda\n\\end{cases}\n$$\nwhere $b = \\exp(\\ell)$ with $\\ell$ being an infinitesimal parameter. The action can be split into parts depending on $\\phi_$ and $\\phi_$.\n$$S[\\phi_ + \\phi_] = S_0[\\phi_] + S_0[\\phi_] + S_{int}[\\phi_ + \\phi_]$$\nHere, $S_0[\\phi] = \\int \\frac{d^d k}{(2\\pi)^d} \\frac{1}{2}(k^2+r) |\\phi(\\mathbf{k})|^2$ is the quadratic (free) part of the action, and $S_{int}[\\phi] = \\int d^d x \\frac{u}{4!}\\phi^4$ is the interaction part.\n\nIntegrating out the fast modes $\\phi_$ yields an effective action for the slow modes, $S_{eff}[\\phi_]$:\n$$\\exp(-S_{eff}[\\phi_]) = \\int \\mathcal{D}\\phi_ \\, \\exp(-S[\\phi_ + \\phi_])$$\nThe effective action can be systematically computed. To one-loop order, the change in the action, $\\Delta S = S_{eff}[\\phi_] - S[\\phi_]$, is given by the one-loop 1PI diagrams with internal fast-mode propagators and external slow-mode fields. This is equivalent to computing the functional trace:\n$$\\Delta S[\\phi_] = \\frac{1}{2}\\text{Tr}\\ln\\left(\\frac{\\delta^2 S}{\\delta\\phi_ \\delta\\phi_}\\right)\\Big|_{\\phi_ = 0} - \\text{const.}$$\nThe operator in the logarithm is $\\frac{\\delta^2 S}{\\delta\\phi_(x) \\delta\\phi_(y)} = (-\\nabla^2+r)\\delta^{(d)}(x-y) + \\frac{u}{2}\\phi^2(x)\\delta^{(d)}(x-y) + O(\\phi^4)$. Treating $\\phi_$ as a background field, this is\n$$-\\nabla^2 + r + \\frac{u}{2}\\phi_^2(x)$$\nThe propagator of the fast modes is $G_(q) = \\frac{1}{q^2+r}$ for $\\Lambda/b  |q| \\le \\Lambda$.\nThe change in the action is then\n$$\\Delta S[\\phi_] = \\frac{1}{2}\\text{Tr}\\ln\\left[ G_^{-1}\\left(1 + G_ \\frac{u}{2}\\phi_^2\\right) \\right] = \\text{const.} + \\frac{1}{2}\\text{Tr}\\ln\\left(1 + G_ \\frac{u}{2}\\phi_^2\\right)$$\nUsing the expansion $\\ln(1+X) \\approx X - \\frac{1}{2}X^2$, we retain terms up to $\\phi_^4$.\n$$\\Delta S[\\phi_] \\approx \\frac{1}{2}\\text{Tr}\\left(G_ \\frac{u}{2}\\phi_^2\\right) - \\frac{1}{4}\\text{Tr}\\left( (G_ \\frac{u}{2}\\phi_^2)^2 \\right)$$\n\nThe first term corrects the mass term, $\\frac{r}{2}\\phi^2$:\n$$\\Delta S_r = \\frac{u}{4}\\text{Tr}(G_ \\phi_^2) = \\frac{u}{4} \\int d^d x \\, \\phi_^2(x) G_(x,x)$$\nwhere $G_(x,x) = \\int_{\\Lambda/b|q|\\le\\Lambda} \\frac{d^d q}{(2\\pi)^d} \\frac{1}{q^2+r} \\equiv I_1$. This integral over the thin momentum shell is\n$$I_1 = \\int_{\\Lambda/b}^{\\Lambda} \\frac{S_d q^{d-1} dq}{(2\\pi)^d} \\frac{1}{q^2+r}$$\nwhere $S_d = 2\\pi^{d/2}/\\Gamma(d/2)$ is the surface area of a unit hypersphere in $d$ dimensions. For infinitesimal $\\ell$, $b = e^\\ell \\approx 1+\\ell$, so the shell width is $\\Lambda - \\Lambda/b \\approx \\Lambda\\ell$.\n$$I_1 \\approx \\frac{S_d \\Lambda^{d-1}}{(2\\pi)^d} \\frac{1}{\\Lambda^2+r} (\\Lambda\\ell) = \\frac{S_d}{(2\\pi)^d} \\frac{\\Lambda^d}{\\Lambda^2(1+r/\\Lambda^2)}\\ell = 2 K_d \\frac{\\Lambda^{d-2}}{1+\\tau}\\ell$$\nusing the definitions $K_d = \\frac{S_d}{2(2\\pi)^d}$ and $\\tau=r/\\Lambda^2$. The coefficient of $\\frac{1}{2}\\phi_^2$ in the action changes by $\\Delta r$:\n$$\\frac{\\Delta r}{2} = \\frac{u}{4}I_1 \\implies \\Delta r = \\frac{u}{2}I_1 = u K_d \\frac{\\Lambda^{d-2}}{1+\\tau}\\ell$$\n\nThe second term in the expansion of $\\Delta S$ corrects the interaction term, $\\frac{u}{4!}\\phi^4$:\n$$\\Delta S_u = -\\frac{1}{8}\\text{Tr}\\left( (G_ \\frac{u}{2}\\phi_^2)^2 \\right) = -\\frac{u^2}{32}\\text{Tr}(G_ \\phi_^2 G_ \\phi_^2)$$\nApproximating $\\phi_$ as spatially constant for the local vertex correction, this becomes\n$$\\Delta S_u \\approx -\\frac{u^2}{32}\\phi_^4 \\int d^dx \\, \\text{Tr}(G_ G_) = -\\frac{u^2}{32}\\phi_^4 \\int d^dx \\int_{\\Lambda/b|q|\\le\\Lambda} \\frac{d^d q}{(2\\pi)^d} \\left(\\frac{1}{q^2+r}\\right)^2$$\nThe integral is $I_2 \\equiv \\int_{\\Lambda/b|q|\\le\\Lambda} \\frac{d^d q}{(2\\pi)^d} \\frac{1}{(q^2+r)^2}$. Evaluating over the thin shell:\n$$I_2 \\approx \\frac{S_d \\Lambda^{d-1}}{(2\\pi)^d} \\frac{1}{(\\Lambda^2+r)^2} (\\Lambda\\ell) = 2 K_d \\frac{\\Lambda^{d-4}}{(1+\\tau)^2}\\ell$$\nThe coefficient of $\\frac{1}{4!}\\phi_^4$ changes by $\\Delta u$. Note that the calculation above gives the correction for a term written as $-\\frac{u^2}{32}\\phi_^4 \\int d^d x I_2$. There are $3$ channels for the one-loop correction contributing to the four-point function, which corresponds to diagrammatic combinatorics. The standard result from Feynman diagrams gives $\\Delta u = -\\frac{3}{2}u^2 I_2$.\n$$\\Delta u = -\\frac{3}{2}u^2 I_2 = -\\frac{3}{2}u^2 \\left( 2 K_d \\frac{\\Lambda^{d-4}}{(1+\\tau)^2}\\ell \\right) = -3 u^2 K_d \\frac{\\Lambda^{d-4}}{(1+\\tau)^2}\\ell$$\n\nThe second step of the RG procedure is to rescale space and fields to restore the original cutoff scale $\\Lambda$ and canonical kinetic term. Let $x' = x/b$ and $\\phi_(x) = \\zeta^{-1}\\phi'(x')$.\nThe kinetic term transforms as:\n$$\\int d^dx \\frac{1}{2}(\\nabla\\phi_)^2 = \\int b^d d^dx' \\frac{1}{2} (b^{-1}\\nabla' (\\zeta^{-1}\\phi'))^2 = b^{d-2}\\zeta^{-2} \\int d^dx' \\frac{1}{2}(\\nabla'\\phi')^2$$\nTo keep this term invariant, we must have $b^{d-2}\\zeta^{-2} = 1$, which gives $\\zeta = b^{(d-2)/2}$. The mass and interaction terms transform as:\n$$\\int d^dx \\, \\frac{r'}{2}\\phi_^2 = \\int b^d d^dx' \\, \\frac{r'}{2}(\\zeta^{-1}\\phi')^2 = b^d \\zeta^{-2} \\int d^dx' \\frac{r'}{2}(\\phi')^2 = b^2 \\int d^dx' \\frac{r'}{2}(\\phi')^2$$\n$$\\int d^dx \\, \\frac{u'}{4!}\\phi_^4 = \\int b^d d^dx' \\, \\frac{u'}{4!}(\\zeta^{-1}\\phi')^4 = b^d \\zeta^{-4} \\int d^dx' \\frac{u'}{4!}(\\phi')^4 = b^{4-d} \\int d^dx' \\frac{u'}{4!}(\\phi')^4$$\nwhere $r'=r+\\Delta r$ and $u'=u+\\Delta u$.\nThe recursion relations for the parameters are:\n$$r(\\ell) = (r+\\Delta r)b^2 = (r+\\Delta r)e^{2\\ell} \\approx (r+\\Delta r)(1+2\\ell) \\approx r + 2r\\ell + \\Delta r$$\n$$u(\\ell) = (u+\\Delta u)b^{4-d} = (u+\\Delta u)e^{(4-d)\\ell} \\approx (u+\\Delta u)(1+(4-d)\\ell) \\approx u + (4-d)u\\ell + \\Delta u$$\nThe differential flow equations are obtained by taking the limit $\\ell \\to 0$:\n$$\\frac{dr}{d\\ell} = \\lim_{\\ell\\to 0}\\frac{r(\\ell)-r}{\\ell} = 2r + \\frac{\\Delta r}{\\ell} = 2r + u K_d \\Lambda^{d-2}(1+\\tau)^{-1}$$\n$$\\frac{du}{d\\ell} = \\lim_{\\ell\\to 0}\\frac{u(\\ell)-u}{\\ell} = (4-d)u + \\frac{\\Delta u}{\\ell} = (4-d)u - 3u^2 K_d \\Lambda^{d-4}(1+\\tau)^{-2}$$\n\nFinally, we derive the beta functions for the dimensionless couplings $\\tau = r/\\Lambda^2$ and $g=K_d u \\Lambda^{d-4}$. The cutoff $\\Lambda$ is treated as a fixed scale parameter in these definitions.\n$$\\frac{d\\tau}{d\\ell} = \\frac{1}{\\Lambda^2} \\frac{dr}{d\\ell} = \\frac{1}{\\Lambda^2}\\left(2r + u K_d \\Lambda^{d-2}\\frac{1}{1+\\tau}\\right) = 2\\frac{r}{\\Lambda^2} + (u K_d \\Lambda^{d-4})\\frac{1}{1+\\tau}$$\n$$\\frac{d\\tau}{d\\ell} = 2\\tau + \\frac{g}{1+\\tau}$$\nFor the coupling $g$:\n$$\\frac{dg}{d\\ell} = K_d \\Lambda^{d-4} \\frac{du}{d\\ell} = K_d \\Lambda^{d-4} \\left( (4-d)u - 3u^2 K_d \\Lambda^{d-4}\\frac{1}{(1+\\tau)^2} \\right)$$\n$$\\frac{dg}{d\\ell} = (4-d)(K_d u \\Lambda^{d-4}) - 3(K_d u \\Lambda^{d-4})^2\\frac{1}{(1+\\tau)^2}$$\n$$\\frac{dg}{d\\ell} = (4-d)g - \\frac{3g^2}{(1+\\tau)^2}$$\nThese are the required recursion relations to order $u^2$.", "answer": "$$\\boxed{\\begin{pmatrix} 2\\tau + \\frac{g}{1+\\tau}  (4-d)g - \\frac{3g^2}{(1+\\tau)^2} \\end{pmatrix}}$$", "id": "2801635"}, {"introduction": "This final practice bridges the gap between abstract RG theory and its application in analyzing simulation or experimental data. You will implement a computational procedure to analyze the scaling of a polymer's radius of gyration, $R_g$, which is a direct consequence of an underlying RG fixed point [@problem_id:2801617]. By employing finite-size scaling and formal model selection, this exercise demonstrates how to extract universal exponents from finite-size data and rigorously account for the corrections to scaling predicted by the RG framework.", "problem": "You are tasked with writing a program that, given a small suite of synthetic polymer datasets, uses finite-size scaling ideas from renormalization group theory to estimate the critical size exponent $\\nu$ of a long chain from its radius of gyration $R_g$ as a function of chain length $N$, while accounting for subleading finite-size corrections. The core physical context is that excluded-volume interactions in dilute polymer solutions drive a renormalization group fixed point that sets the asymptotic scaling $R_g \\sim N^{\\nu}$, with corrections controlled by irrelevant operators that decay with increasing $N$. Your algorithm should be principled and should not rely on ad hoc curve matching; it should use a model selection criterion to decide whether a correction term is required and, if so, which candidate correction exponent best explains the data.\n\nFundamental base to use:\n- Definition of the radius of gyration $R_g$ of a polymer chain as a characteristic size and that for long chains $R_g$ has an asymptotic power-law dependence on the chain length $N$ due to scale invariance at a renormalization group fixed point.\n- The widely used finite-size scaling ansatz that the leading correction to scaling is a decaying power in $N$ controlled by a positive correction-to-scaling exponent $\\Delta$.\n\nYour computational task:\n1. For each dataset, construct the synthetic measurements of $R_g$ from specified parameters by the finite-size scaling form with a single leading correction, without any added noise. This establishes reproducible inputs for the estimator:\n   - $R_g(N) = A\\, N^{\\nu_{\\text{true}}}\\left(1 + B\\, N^{-\\Delta}\\right)$ where $A gt; 0$, $B$ may be positive or negative, and $\\Delta gt; 0$.\n2. Given only the resulting $\\{(N_i, R_{g,i})\\}$ pairs, estimate the exponent $\\nu$ by comparing the following candidate models:\n   - Pure asymptotic scaling: $R_g(N) = A\\, N^{\\nu}$.\n   - Scaling with one subleading correction, with candidate exponents $\\Delta \\in \\{0.5, 1.0\\}$: $R_g(N) = A\\, N^{\\nu}\\left(1 + B\\, N^{-\\Delta}\\right)$.\n3. Perform nonlinear least squares estimation in the original (not logarithmic) space for each candidate model, using physically sensible bounds ($A gt; 0$, $0 lt; \\nu lt; 1$, and a broad bound for $B$). Choose the preferred model by minimizing the small-sample corrected Akaike Information Criterion (AICc), defined for $n$ data points and $k$ parameters as\n   $$ \\mathrm{AIC} = n \\ln\\!\\left(\\frac{\\mathrm{RSS}}{n}\\right) + 2k,\\quad \\mathrm{AICc} = \\mathrm{AIC} + \\frac{2k(k+1)}{n - k - 1}, $$\n   where $\\mathrm{RSS} = \\sum_{i=1}^{n}\\left(R_{g,i}^{\\text{fit}} - R_{g,i}\\right)^2$. If $n - k - 1 \\le 0$, use $\\mathrm{AIC}$ in place of $\\mathrm{AICc}$.\n4. Report the selected-model estimate of $\\nu$ for each dataset, rounded to three decimals.\n\nTest suite (construct the synthetic datasets exactly as specified; $N$ is dimensionless and $R_g$ is in arbitrary consistent units but you do not need to report units for the final answers):\n- Dataset $1$ (general case with strong corrections, three-dimensional excluded volume-like): \n  - $N \\in \\{20, 40, 80, 160, 320, 640\\}$, $A = 0.35$, $\\nu_{\\text{true}} = 0.588$, $B = 0.8$, $\\Delta = 0.5$.\n- Dataset $2$ (boundary case with no correction term, ideal or theta-like chain):\n  - $N \\in \\{10, 20, 40, 80, 160, 320\\}$, $A = 0.6$, $\\nu_{\\text{true}} = 0.5$, $B = 0.0$, $\\Delta = 1.0$.\n- Dataset $3$ (two-dimensional-like with analytic correction):\n  - $N \\in \\{30, 60, 120, 240, 480\\}$, $A = 0.25$, $\\nu_{\\text{true}} = 0.75$, $B = 0.5$, $\\Delta = 1.0$.\n- Dataset $4$ (short chains with very strong corrections):\n  - $N \\in \\{12, 18, 26, 38, 58, 86\\}$, $A = 0.4$, $\\nu_{\\text{true}} = 0.588$, $B = 1.2$, $\\Delta = 0.5$.\n- Dataset $5$ (edge case with few points and no correction):\n  - $N \\in \\{50, 100, 200, 400\\}$, $A = 0.5$, $\\nu_{\\text{true}} = 0.588$, $B = 0.0$, $\\Delta = 0.5$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the five estimated $\\nu$ values (one per dataset) as a comma-separated list enclosed in square brackets, with each value rounded to three decimals, for example, $[0.588,0.500,0.750,0.590,0.585]$ (this example is illustrative only).\n\nAngle units are not involved. No physical units are required in the final numerical outputs. The only accepted outputs are floating-point numbers as specified above.", "solution": "The problem presented is subjected to rigorous validation and is deemed valid. It constitutes a well-posed computational exercise grounded in the fundamental principles of polymer statistical mechanics and renormalization group theory. The task is to implement a principled model selection protocol to estimate a universal critical exponent from synthetic data, a standard procedure in the analysis of both simulation and experimental results. All required parameters and methods are specified, and the problem is free of scientific inaccuracies or logical contradictions.\n\nThe central physical principle is that the characteristic size of a long flexible polymer chain, quantified by its radius of gyration $R_g$, scales with its length (number of monomer units) $N$ according to a power law. At large $N$, the system is described by a renormalization group fixed point, leading to universal scaling behavior:\n$$ R_g(N) \\sim N^{\\nu} $$\nwhere $\\nu$ is a universal critical exponent that depends only on the spatial dimension and the nature of the interactions (e.g., the presence or absence of excluded volume). For finite $N$, deviations from this asymptotic law are expected. These are described by corrections to scaling, which are governed by irrelevant operators in the renormalization group framework. The leading correction typically takes the form of a power law in $N$, leading to the following ansatz for the scaling of $R_g(N)$:\n$$ R_g(N) = A N^{\\nu} \\left(1 + B N^{-\\Delta} + \\dots\\right) $$\nHere, $A$ is a non-universal amplitude, $B$ is a second non-universal amplitude, and $\\Delta  0$ is the leading correction-to-scaling exponent, which is also a universal quantity.\n\nThe task is to take synthetic, noiseless data sets $\\{(N_i, R_{g,i})\\}$ generated from this form and determine the best estimate for $\\nu$. This is accomplished not by a naive logarithmic plot, which can be misleading, but by a formal model comparison procedure.\n\nThe specific steps are as follows:\n$1$. For each dataset, synthetic data for $R_g$ is generated as a function of $N$ using the provided true parameters $(\\nu_{\\text{true}}, A, B, \\Delta)$.\n\n$2$. Three distinct candidate models are fitted to this synthetic data:\n    - Model $0$: A pure power law, $R_g(N) = A N^{\\nu}$. This model has $k=2$ free parameters: $A$ and $\\nu$.\n    - Model $1$: A power law with the leading correction fixed to an exponent of $\\Delta=0.5$, $R_g(N) = A N^{\\nu} (1 + B N^{-0.5})$. This model, relevant for three-dimensional self-avoiding walks, has $k=3$ parameters: $A$, $\\nu$, and $B$.\n    - Model $2$: A power law with the leading correction fixed to an exponent of $\\Delta=1.0$, $R_g(N) = A N^{\\nu} (1 + B N^{-1.0})$. This model, relevant for instance in two dimensions, also has $k=3$ parameters: $A$, $\\nu$, and $B$.\n\n$3$. The parameters for each model are determined by performing a nonlinear least-squares regression, which minimizes the Residual Sum of Squares ($\\mathrm{RSS}$):\n$$ \\mathrm{RSS} = \\sum_{i=1}^{n} \\left( R_{g,i}^{\\text{fit}} - R_{g,i} \\right)^2 $$\nwhere $n$ is the number of data points. The optimization is constrained by physically sensible bounds, namely $A  0$ and $0  \\nu  1$.\n\n$4$. The most appropriate model is selected by employing the small-sample corrected Akaike Information Criterion ($\\mathrm{AICc}$). This criterion provides a formal way to trade off goodness of fit (a lower $\\mathrm{RSS}$) with model complexity (a smaller number of parameters, $k$). The aic is defined as:\n$$ \\mathrm{AIC} = n \\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) + 2k $$\nThe corrected version, $\\mathrm{AICc}$, which is more reliable for small sample sizes $n$, is given by:\n$$ \\mathrm{AICc} = \\mathrm{AIC} + \\frac{2k(k+1)}{n - k - 1} $$\nThe model exhibiting the minimum $\\mathrm{AICc}$ value is chosen as the preferred description of the data. A critical detail arises when the condition $n - k - 1 \\le 0$ holds for a candidate model, as the correction term in $\\mathrm{AICc}$ becomes divergent or undefined. In such a scenario, for the sake of a consistent comparison, we shall revert to using the standard $\\mathrm{AIC}$ for all models being compared for that specific dataset. This situation occurs for Dataset $5$, where $n=4$, and the models with $k=3$ satisfy $4-3-1=0$.\n\n$5$. Since the input data are generated without noise from functions that are special cases of the candidate models, the $\\mathrm{RSS}$ for the correct model (or a more complex, nested model) will be numerically zero. In this case, the logarithmic term in the $\\mathrm{AIC}$ becomes $-\\infty$. If multiple models achieve this perfect fit, the one with the smallest complexity penalty (i.e., the smallest $k$ value) will be selected, upholding the principle of parsimony.\n\n$6$. The final estimate for $\\nu$ reported for each dataset is the value obtained from the parameter fit of the selected model.\n\nThis entire procedure is implemented in the provided program. It systematically processes each dataset, performs the model fitting and selection, and reports the resulting best estimate for the exponent $\\nu$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the polymer scaling exponent nu using\n    finite-size scaling and model selection via AICc.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": np.array([20, 40, 80, 160, 320, 640]), \"A\": 0.35,\n            \"nu_true\": 0.588, \"B\": 0.8, \"Delta\": 0.5\n        },\n        {\n            \"N\": np.array([10, 20, 40, 80, 160, 320]), \"A\": 0.6,\n            \"nu_true\": 0.5, \"B\": 0.0, \"Delta\": 1.0\n        },\n        {\n            \"N\": np.array([30, 60, 120, 240, 480]), \"A\": 0.25,\n            \"nu_true\": 0.75, \"B\": 0.5, \"Delta\": 1.0\n        },\n        {\n            \"N\": np.array([12, 18, 26, 38, 58, 86]), \"A\": 0.4,\n            \"nu_true\": 0.588, \"B\": 1.2, \"Delta\": 0.5\n        },\n        {\n            \"N\": np.array([50, 100, 200, 400]), \"A\": 0.5,\n            \"nu_true\": 0.588, \"B\": 0.0, \"Delta\": 0.5\n        },\n    ]\n\n    # Model definitions\n    # Model 0: Pure scaling (k=2)\n    model_0 = lambda N, A, nu: A * N**nu\n    # Model 1: Correction with Delta=0.5 (k=3)\n    model_1 = lambda N, A, nu, B: A * N**nu * (1 + B * N**-0.5)\n    # Model 2: Correction with Delta=1.0 (k=3)\n    model_2 = lambda N, A, nu, B: A * N**nu * (1 + B * N**-1.0)\n    \n    models = [\n        {'func': model_0, 'k': 2, 'name': 'Model 0 (k=2)'},\n        {'func': model_1, 'k': 3, 'name': 'Model 1 (k=3, D=0.5)'},\n        {'func': model_2, 'k': 3, 'name': 'Model 2 (k=3, D=1.0)'}\n    ]\n\n    results_nu = []\n\n    for case in test_cases:\n        N_data = case[\"N\"]\n        A_true, nu_true, B_true, Delta_true = case[\"A\"], case[\"nu_true\"], case[\"B\"], case[\"Delta\"]\n\n        # 1. Generate synthetic data\n        rg_func_true = lambda n: A_true * n**nu_true * (1 + B_true * n**(-Delta_true))\n        Rg_data = rg_func_true(N_data)\n\n        fit_results = []\n        n = len(N_data)\n\n        # Determine if AIC fallback is needed for this dataset\n        use_aic_fallback = any(n - model['k'] - 1 = 0 for model in models)\n\n        for model_spec in models:\n            k = model_spec['k']\n            model_func = model_spec['func']\n            \n            # Set parameter bounds for the nonlinear fitter\n            if k == 2:\n                bounds = ([0, 0], [np.inf, 1.0])\n                # Good initial guess can help convergence, though not strictly necessary here\n                p0 = [1.0, 0.5]\n            else: # k == 3\n                bounds = ([0, 0, -np.inf], [np.inf, 1.0, np.inf])\n                p0 = [1.0, 0.5, 0.0]\n\n            try:\n                popt, _ = curve_fit(model_func, N_data, Rg_data, p0=p0, bounds=bounds, maxfev=10000)\n                \n                Rg_fit = model_func(N_data, *popt)\n                rss = np.sum((Rg_fit - Rg_data)**2)\n\n                # Use a small threshold to handle numerically zero RSS\n                if rss  1e-25:\n                    log_likelihood_term = -np.inf\n                else:\n                    log_likelihood_term = n * np.log(rss / n)\n                \n                aic = log_likelihood_term + 2 * k\n                \n                if use_aic_fallback:\n                    criterion = aic\n                else:\n                    # AICc calculation\n                    correction_term = (2 * k * (k + 1)) / (n - k - 1)\n                    criterion = aic + correction_term\n\n                fit_results.append({'popt': popt, 'criterion': criterion, 'model': model_spec})\n                \n            except RuntimeError:\n                # If fit fails, assign an infinitely bad criterion value\n                fit_results.append({'popt': [np.nan]*k, 'criterion': np.inf, 'model': model_spec})\n\n        # 3. Select the best model (minimum AICc or AIC)\n        best_fit = min(fit_results, key=lambda x: x['criterion'])\n        \n        # 4. Extract estimated nu from the best model\n        # The exponent nu is always the second parameter (index 1)\n        nu_estimated = best_fit['popt'][1]\n        results_nu.append(nu_estimated)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{nu:.3f}\" for nu in results_nu]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2801617"}]}