{"hands_on_practices": [{"introduction": "At the heart of many sophisticated geometry optimization algorithms lies the Newton-Raphson method. This practice takes you back to this fundamental principle, where the complex potential energy surface is approximated by a simple quadratic model near the current molecular geometry. By working through this exercise [@problem_id:2894209], you will derive and compute the exact Newton step, which represents the ideal displacement towards the minimum of this local model, reinforcing your understanding of how gradient $\\mathbf{g}$ and Hessian $\\mathbf{H}$ information guides the optimization process.", "problem": "In a quantum chemistry geometry optimization performed in scaled, dimensionless internal coordinates, the electronic energy $E(\\mathbf{q})$ in the neighborhood of a current structure $\\mathbf{q}_{0}$ is approximated by the second-order Taylor model\n$$\nm(\\mathbf{s}) \\equiv E(\\mathbf{q}_{0}) + \\mathbf{g}^{\\top}\\mathbf{s} + \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{H}\\mathbf{s},\n$$\nwhere $\\mathbf{s} = \\mathbf{q} - \\mathbf{q}_{0}$ is the displacement, $\\mathbf{g} = \\nabla E(\\mathbf{q}_{0})$ is the gradient, and $\\mathbf{H} = \\nabla^{2} E(\\mathbf{q}_{0})$ is the Hessian. Both $\\mathbf{g}$ and $\\mathbf{H}$ have units of energy because the coordinates are dimensionless by construction. The Newton step is defined as the displacement that minimizes the quadratic model.\n\nAt $\\mathbf{q}_{0}$, suppose the gradient and Hessian are\n$$\n\\mathbf{g} =\n\\begin{pmatrix}\n0.06 \\\\\n-0.08\n\\end{pmatrix}\n\\ \\text{Hartree}, \n\\qquad\n\\mathbf{H} =\n\\begin{pmatrix}\n1.2  0.3 \\\\\n0.3  0.9\n\\end{pmatrix}\n\\ \\text{Hartree}.\n$$\nStarting from the second-order Taylor model and the definition of a minimizer, derive the expression for the Newton step $\\mathbf{s}_{N}$ in terms of $\\mathbf{g}$ and $\\mathbf{H}$, compute $\\mathbf{s}_{N}$ explicitly for the data above, and then evaluate the predicted quadratic energy change\n$$\n\\Delta E_{\\text{pred}} \\equiv m(\\mathbf{s}_{N}) - m(\\mathbf{0}).\n$$\nExpress the final energy change in Hartree and round your answer to five significant figures. The final response must be a single real number.", "solution": "The problem as stated is scientifically sound, well-posed, and contains all necessary information for a unique solution. The Hessian matrix is positive definite, which guarantees that the quadratic model has a unique minimum. Therefore, I will proceed with the solution.\n\nThe objective is to find the displacement $\\mathbf{s}$ that minimizes the quadratic model of the electronic energy:\n$$\nm(\\mathbf{s}) = E(\\mathbf{q}_{0}) + \\mathbf{g}^{\\top}\\mathbf{s} + \\frac{1}{2}\\mathbf{s}^{\\top}\\mathbf{H}\\mathbf{s}\n$$\nA necessary condition for a minimum of a differentiable function is that its gradient vanishes. We must compute the gradient of $m(\\mathbf{s})$ with respect to the displacement vector $\\mathbf{s}$ and set it to the zero vector.\nThe gradient is given by:\n$$\n\\nabla_{\\mathbf{s}} m(\\mathbf{s}) = \\nabla_{\\mathbf{s}} \\left( E(\\mathbf{q}_{0}) + \\mathbf{g}^{\\top}\\mathbf{s} + \\frac{1}{2}\\mathbf{s}^{\\top}\\mathbf{H}\\mathbf{s} \\right)\n$$\nThe term $E(\\mathbf{q}_{0})$ is a constant with respect to $\\mathbf{s}$, so its derivative is zero. The derivatives of the linear and quadratic terms are standard results from vector calculus:\n$$\n\\nabla_{\\mathbf{s}} (\\mathbf{g}^{\\top}\\mathbf{s}) = \\mathbf{g}\n$$\n$$\n\\nabla_{\\mathbf{s}} \\left(\\frac{1}{2}\\mathbf{s}^{\\top}\\mathbf{H}\\mathbf{s}\\right) = \\mathbf{H}\\mathbf{s}\n$$\nwhere the second result assumes a symmetric Hessian matrix $\\mathbf{H}$, which is true for a second derivative matrix. Combining these, the gradient of the model is:\n$$\n\\nabla_{\\mathbf{s}} m(\\mathbf{s}) = \\mathbf{g} + \\mathbf{H}\\mathbf{s}\n$$\nThe Newton step, denoted $\\mathbf{s}_{N}$, is the specific displacement that minimizes $m(\\mathbf{s})$. To find it, we set the gradient to the zero vector:\n$$\n\\mathbf{g} + \\mathbf{H}\\mathbf{s}_{N} = \\mathbf{0}\n$$\nSolving for $\\mathbf{s}_{N}$ yields the expression for the Newton step:\n$$\n\\mathbf{H}\\mathbf{s}_{N} = -\\mathbf{g}\n$$\n$$\n\\mathbf{s}_{N} = -\\mathbf{H}^{-1}\\mathbf{g}\n$$\nThis requires the Hessian matrix $\\mathbf{H}$ to be invertible. The determinant of the given Hessian is $\\det(\\mathbf{H}) = (1.2)(0.9) - (0.3)(0.3) = 1.08 - 0.09 = 0.99$. Since $\\det(\\mathbf{H}) \\neq 0$, the inverse exists and the Newton step is well-defined.\n\nNow, we compute $\\mathbf{s}_{N}$ using the provided data:\n$$\n\\mathbf{g} =\n\\begin{pmatrix}\n0.06 \\\\\n-0.08\n\\end{pmatrix}\n, \\qquad\n\\mathbf{H} =\n\\begin{pmatrix}\n1.2  0.3 \\\\\n0.3  0.9\n\\end{pmatrix}\n$$\nWe solve the linear system $\\mathbf{H}\\mathbf{s}_{N} = -\\mathbf{g}$:\n$$\n\\begin{pmatrix}\n1.2  0.3 \\\\\n0.3  0.9\n\\end{pmatrix}\n\\begin{pmatrix}\ns_1 \\\\\ns_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-0.06 \\\\\n0.08\n\\end{pmatrix}\n$$\nThis corresponds to the system of equations:\n1. $1.2s_1 + 0.3s_2 = -0.06$\n2. $0.3s_1 + 0.9s_2 = 0.08$\n\nMultiplying the first equation by $3$ gives $3.6s_1 + 0.9s_2 = -0.18$. Subtracting the second equation from this result eliminates $s_2$:\n$$\n(3.6s_1 - 0.3s_1) = -0.18 - 0.08\n$$\n$$\n3.3s_1 = -0.26 \\implies s_1 = -\\frac{0.26}{3.3} = -\\frac{26}{330} = -\\frac{13}{165}\n$$\nSubstituting $s_1$ back into the second equation:\n$$\n0.3\\left(-\\frac{13}{165}\\right) + 0.9s_2 = 0.08\n$$\n$$\n-\\frac{3.9}{165} + 0.9s_2 = 0.08 \\implies -\\frac{13}{550} + 0.9s_2 = \\frac{8}{100} = \\frac{2}{25}\n$$\n$$\n0.9s_2 = \\frac{2}{25} + \\frac{13}{550} = \\frac{44}{550} + \\frac{13}{550} = \\frac{57}{550}\n$$\n$$\ns_2 = \\frac{57}{550 \\times 0.9} = \\frac{57}{495} = \\frac{19}{165}\n$$\nSo, the Newton step is $\\mathbf{s}_{N} = \\begin{pmatrix} -13/165 \\\\ 19/165 \\end{pmatrix}$.\n\nNext, we evaluate the predicted quadratic energy change, $\\Delta E_{\\text{pred}}$:\n$$\n\\Delta E_{\\text{pred}} = m(\\mathbf{s}_{N}) - m(\\mathbf{0})\n$$\nSubstituting the definition of $m(\\mathbf{s})$:\n$$\nm(\\mathbf{s}_{N}) = E(\\mathbf{q}_{0}) + \\mathbf{g}^{\\top}\\mathbf{s}_{N} + \\frac{1}{2}\\mathbf{s}_{N}^{\\top}\\mathbf{H}\\mathbf{s}_{N}\n$$\n$$\nm(\\mathbf{0}) = E(\\mathbf{q}_{0})\n$$\nSo,\n$$\n\\Delta E_{\\text{pred}} = \\mathbf{g}^{\\top}\\mathbf{s}_{N} + \\frac{1}{2}\\mathbf{s}_{N}^{\\top}\\mathbf{H}\\mathbf{s}_{N}\n$$\nWe can simplify this expression. From the derivation of the Newton step, we have $\\mathbf{H}\\mathbf{s}_{N} = -\\mathbf{g}$. Substituting this into the quadratic term:\n$$\n\\mathbf{s}_{N}^{\\top}\\mathbf{H}\\mathbf{s}_{N} = \\mathbf{s}_{N}^{\\top}(-\\mathbf{g}) = - \\mathbf{s}_{N}^{\\top}\\mathbf{g}\n$$\nSince $\\mathbf{s}_{N}^{\\top}\\mathbf{g}$ is a scalar, it is equal to its own transpose, $(\\mathbf{s}_{N}^{\\top}\\mathbf{g})^{\\top} = \\mathbf{g}^{\\top}\\mathbf{s}_{N}$. Thus, $\\mathbf{s}_{N}^{\\top}\\mathbf{H}\\mathbf{s}_{N} = -\\mathbf{g}^{\\top}\\mathbf{s}_{N}$.\nThe energy change becomes:\n$$\n\\Delta E_{\\text{pred}} = \\mathbf{g}^{\\top}\\mathbf{s}_{N} + \\frac{1}{2}(-\\mathbf{g}^{\\top}\\mathbf{s}_{N}) = \\frac{1}{2}\\mathbf{g}^{\\top}\\mathbf{s}_{N}\n$$\nNow, we compute this value:\n$$\n\\Delta E_{\\text{pred}} = \\frac{1}{2}\n\\begin{pmatrix}\n0.06  -0.08\n\\end{pmatrix}\n\\begin{pmatrix}\n-13/165 \\\\\n19/165\n\\end{pmatrix}\n$$\n$$\n\\Delta E_{\\text{pred}} = \\frac{1}{2} \\left[ (0.06)\\left(-\\frac{13}{165}\\right) + (-0.08)\\left(\\frac{19}{165}\\right) \\right]\n$$\n$$\n\\Delta E_{\\text{pred}} = \\frac{1}{2 \\times 165} \\left[ (0.06)(-13) + (-0.08)(19) \\right]\n$$\n$$\n\\Delta E_{\\text{pred}} = \\frac{1}{330} \\left[ -0.78 - 1.52 \\right] = \\frac{-2.3}{330} = -\\frac{23}{3300}\n$$\nPerforming the division:\n$$\n\\Delta E_{\\text{pred}} = -\\frac{23}{3300} \\approx -0.00696969... \\ \\text{Hartree}\n$$\nThe problem requires this value rounded to five significant figures. The first non-zero digit is the $6$ in the thousandths place. The first five significant figures are $6$, $9$, $6$, $9$, $6$. The sixth significant digit is $9$, which is $5$ or greater, so we round up the fifth digit.\n$$\n-0.0069696 \\underline{9}... \\implies -0.0069697\n$$", "answer": "$$\\boxed{-0.0069697}$$", "id": "2894209"}, {"introduction": "While the pure Newton method provides the theoretical blueprint, its requirement to compute and invert the full Hessian matrix becomes prohibitive for large systems. This is where quasi-Newton methods, particularly the Limited-memory BFGS (L-BFGS) algorithm, become indispensable practical tools. This exercise [@problem_id:164314] guides you through the famous L-BFGS 'two-loop recursion,' offering a rare opportunity to manually compute a search direction and see how an effective approximation of the Hessian's action is built from just a few previous steps.", "problem": "In computational quantum chemistry, geometry optimization algorithms are essential for finding stable molecular structures, which correspond to minima on the potential energy surface (PES). Quasi-Newton methods are a popular class of algorithms for this task. They iteratively approach a minimum by using the gradient of the energy, $g$, to approximate the inverse Hessian matrix, $H$, which contains information about the curvature of the PES.\n\nThe search direction, $p_k$, at step $k$ is determined by $p_k = -H_k g_k$, where $g_k$ is the gradient at the current geometry $x_k$. The Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is a widely used quasi-Newton method that avoids the explicit formation and storage of the dense inverse Hessian matrix. Instead, it stores a small number, $m$, of the most recent displacement vectors, $s_i = x_{i+1} - x_i$, and gradient difference vectors, $y_i = g_{i+1} - g_i$.\n\nThe product $H_k g_k$ is computed efficiently using the L-BFGS two-loop recursion. Given the current gradient $g_k$ and the $m$ previous pairs of $(s_i, y_i)$, the procedure is as follows:\n\n1.  Initialize $q \\leftarrow g_k$.\n2.  **First loop:** For $i$ from $k-1$ down to $k-m$:\n    -   Compute $\\rho_i = \\frac{1}{y_i^T s_i}$.\n    -   Compute $\\alpha_i = \\rho_i s_i^T q$.\n    -   Update $q \\leftarrow q - \\alpha_i y_i$.\n3.  Choose an initial inverse Hessian approximation $H_k^{(0)}$. A standard choice is $H_k^{(0)} = \\gamma_k I$, where $I$ is the identity matrix and $\\gamma_k = \\frac{s_{k-1}^T y_{k-1}}{y_{k-1}^T y_{k-1}}$.\n4.  Compute the initial version of the result vector: $z \\leftarrow H_k^{(0)} q$.\n5.  **Second loop:** For $i$ from $k-m$ up to $k-1$:\n    -   Compute $\\beta_i = \\rho_i y_i^T z$.\n    -   Update $z \\leftarrow z + s_i (\\alpha_i - \\beta_i)$.\n6.  The final result is $H_k g_k = z$. The search direction is $p_k = -z$.\n\n**Problem:**\nConsider a geometry optimization of a 2D system at step $k$. The L-BFGS algorithm is used with a memory of $m=2$. The current gradient and the two most recent displacement and gradient-difference vectors are given by:\n-   Current gradient: $g_k = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}$\n-   Most recent update vectors (index $k-1$): $s_{k-1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $y_{k-1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$\n-   Second most recent update vectors (index $k-2$): $s_{k-2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $y_{k-2} = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}$\n\nCalculate the search direction vector $p_k$ for the current step $k$.", "solution": "We apply the L-BFGS two-loop recursion with $m=2$.  Let indices $i=k-1,k-2$.\n\n1.  First loop.  Initialize \n$$q^{(0)}=g_k=\\begin{pmatrix}-1\\\\2\\end{pmatrix}.$$\nFor each $i=k-1,k-2$ compute \n$$\\rho_i=\\frac1{y_i^T s_i},\\quad \n\\alpha_i=\\rho_i\\,s_i^T q^{(\\cdot)},\\quad\nq^{(\\text{new})}=q^{(\\text{old})}-\\alpha_i\\,y_i.$$\n\ni)  $i=k-1$: \n$$y_{k-1}^T s_{k-1}=(2,1)\\cdot(1,0)=2\\;\\Rightarrow\\;\n\\rho_{k-1}=\\tfrac12,$$\n$$\\alpha_{k-1}=\\tfrac12\\,(1,0)\\!\\cdot\\!(-1,2)=-\\tfrac12,$$\n$$q^{(1)}=(-1,2)-\\bigl(-\\tfrac12\\bigr)(2,1)\n=( -1,2 )+(1,\\tfrac12)\n=(0,\\tfrac52).$$\n\nii) $i=k-2$: \n$$y_{k-2}^T s_{k-2}=(-1,2)\\cdot(0,1)=2\\;\\Rightarrow\\;\n\\rho_{k-2}=\\tfrac12,$$\n$$\\alpha_{k-2}=\\tfrac12\\,(0,1)\\!\\cdot\\!(0,\\tfrac52)\n=\\tfrac54,$$\n$$q^{(2)}=(0,\\tfrac52)-\\tfrac54\\,(-1,2)\n=(0,\\tfrac52)-(-\\tfrac54,\\tfrac52)\n=(\\tfrac54,0).$$\n\nThus after first loop $q=(5/4,0)^T$.\n\n2.  Form initial Hessian‐times‐vector.  Choose \n$$\\gamma_k=\\frac{s_{k-1}^Ty_{k-1}}{y_{k-1}^Ty_{k-1}}\n=\\frac{2}{2^2+1^2}=\\tfrac25,\\quad\nH^{(0)}_k=\\gamma_kI,$$\n$$z^{(0)}=H^{(0)}_k\\,q=\\tfrac25\\,(5/4,0)=(\\tfrac12,0).$$\n\n3.  Second loop.  For $i=k-2,k-1$ compute \n$$\\beta_i=\\rho_i\\,y_i^T z^{(\\cdot)},\\quad\nz^{(\\rm new)}=z^{(\\rm old)}+s_i(\\alpha_i-\\beta_i).$$\n\ni)  $i=k-2$:\n$$\\beta_{k-2}=\\tfrac12\\;(-1,2)\\!\\cdot\\!(\\tfrac12,0)=-\\tfrac14,$$\n$$z^{(1)}=(\\tfrac12,0)+(0,1)\\bigl(\\tfrac54-(-\\tfrac14)\\bigr)\n=(\\tfrac12,0)+(0,\\tfrac32)\n=(\\tfrac12,\\tfrac32).$$\n\nii) $i=k-1$:\n$$\\beta_{k-1}=\\tfrac12\\;(2,1)\\!\\cdot\\!(\\tfrac12,\\tfrac32)\n=\\tfrac12\\,(1+\\tfrac32)=\\tfrac54,$$\n$$z^{(2)}=(\\tfrac12,\\tfrac32)+(1,0)\\bigl(-\\tfrac12-\\tfrac54\\bigr)\n=(\\tfrac12,\\tfrac32)+(-\\tfrac74,0)\n=(-\\tfrac54,\\tfrac32).$$\n\nThus $H_k g_k=z=(-5/4,3/2)^T$ and the search direction is \n$$p_k=-z=\\begin{pmatrix}5/4\\\\-3/2\\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}\\tfrac{5}{4}\\\\-\\tfrac{3}{2}\\end{pmatrix}}$$", "id": "164314"}, {"introduction": "Calculating a search direction is only half the battle; we must also have confidence in its numerical reliability. The stability of the Newton step is intimately linked to the properties of the Hessian matrix $\\mathbf{H}$, especially when it is nearly singular, such as near a very flat potential energy surface. In this practice [@problem_id:2894238], you will compute the spectral condition number $\\kappa_{2}(\\mathbf{H})$ and analyze how it acts as an amplification factor for numerical errors, providing a quantitative measure for the robustness of your optimization step.", "problem": "Consider a local quadratic model for the electronic energy surface in mass-weighted Cartesian coordinates near a current geometry in a geometry optimization. Let the Hessian matrix be the symmetric matrix\n$$\n\\mathbf{H} \\;=\\;\n\\begin{pmatrix}\n4  1  0 \\\\\n1  3  0 \\\\\n0  0  \\tfrac{1}{2}\n\\end{pmatrix},\n$$\nand let the gradient be\n$$\n\\mathbf{g} \\;=\\;\n\\begin{pmatrix}\n0.10 \\\\\n-0.20 \\\\\n0.05\n\\end{pmatrix}.\n$$\nThe Newton step $\\mathbf{p}$ is defined implicitly by the linear system $\\mathbf{H}\\,\\mathbf{p} \\;=\\; -\\,\\mathbf{g}$. In practice, the Hessian used in a quantum chemistry code is often perturbed by small errors from numerical differentiation or incomplete convergence, so that the step actually computed, $\\tilde{\\mathbf{p}}$, satisfies $(\\mathbf{H} + \\Delta \\mathbf{H})\\,\\tilde{\\mathbf{p}} \\;=\\; -\\,\\mathbf{g}$ with a small perturbation $\\Delta \\mathbf{H}$. Using the spectral norm, analyze the first-order sensitivity of $\\mathbf{p}$ with respect to $\\Delta \\mathbf{H}$ by relating the relative change in $\\mathbf{p}$ to the relative size of $\\Delta \\mathbf{H}$ through the spectral condition number. Your analysis should begin from the linear algebraic definitions of the Newton step and of the matrix inverse, and proceed by first-order perturbation reasoning, without assuming any pre-stated perturbation bounds.\n\nCompute the spectral condition number $\\kappa_{2}(\\mathbf{H})$ associated with $\\mathbf{H}$, and use it to discuss the numerical stability of the Newton step for this problem in the sense of how the relative error in $\\tilde{\\mathbf{p}}$ scales with the relative perturbation in $\\mathbf{H}$. Provide your final answer as the exact value of $\\kappa_{2}(\\mathbf{H})$ in simplest closed form, with no rounding and no units.", "solution": "The problem requires an analysis of the numerical stability of the Newton step in a geometry optimization procedure by relating the sensitivity of the solution to perturbations in the Hessian matrix. This relationship is quantified by the spectral condition number of the Hessian. We will first derive the general first-order perturbation result and then apply it to the specific matrix provided.\n\nLet the exact Newton step $\\mathbf{p}$ be the solution to the linear system:\n$$\n\\mathbf{H}\\mathbf{p} = -\\mathbf{g}\n$$\nwhere $\\mathbf{H}$ is the exact Hessian matrix and $\\mathbf{g}$ is the gradient. In a practical computation, due to numerical errors, we work with a perturbed Hessian, $\\mathbf{H} + \\Delta\\mathbf{H}$, and solve for a perturbed step, $\\tilde{\\mathbf{p}}$:\n$$\n(\\mathbf{H} + \\Delta\\mathbf{H})\\tilde{\\mathbf{p}} = -\\mathbf{g}\n$$\nLet the error in the Newton step be $\\Delta\\mathbf{p} = \\tilde{\\mathbf{p}} - \\mathbf{p}$, which implies $\\tilde{\\mathbf{p}} = \\mathbf{p} + \\Delta\\mathbf{p}$. Substituting this into the perturbed equation gives:\n$$\n(\\mathbf{H} + \\Delta\\mathbf{H})(\\mathbf{p} + \\Delta\\mathbf{p}) = -\\mathbf{g}\n$$\nExpanding the left side yields:\n$$\n\\mathbf{H}\\mathbf{p} + \\mathbf{H}\\Delta\\mathbf{p} + \\Delta\\mathbf{H}\\mathbf{p} + \\Delta\\mathbf{H}\\Delta\\mathbf{p} = -\\mathbf{g}\n$$\nSince $\\mathbf{H}\\mathbf{p} = -\\mathbf{g}$, this simplifies to:\n$$\n\\mathbf{H}\\Delta\\mathbf{p} + \\Delta\\mathbf{H}\\mathbf{p} + \\Delta\\mathbf{H}\\Delta\\mathbf{p} = \\mathbf{0}\n$$\nFor a first-order analysis, we assume that the perturbations are small, meaning $\\|\\Delta\\mathbf{H}\\|$ and consequently $\\|\\Delta\\mathbf{p}\\|$ are small. Therefore, the term $\\Delta\\mathbf{H}\\Delta\\mathbf{p}$, which is second-order in small quantities, can be neglected. This leads to the first-order approximation:\n$$\n\\mathbf{H}\\Delta\\mathbf{p} \\approx -\\Delta\\mathbf{H}\\mathbf{p}\n$$\nAssuming the Hessian $\\mathbf{H}$ is invertible, we can solve for the error $\\Delta\\mathbf{p}$:\n$$\n\\Delta\\mathbf{p} \\approx -\\mathbf{H}^{-1}\\Delta\\mathbf{H}\\mathbf{p}\n$$\nTo analyze the magnitude of this error, we take the spectral norm (denoted by the subscript $2$) of both sides. Using the submultiplicative property of matrix norms ($\\|\\mathbf{A}\\mathbf{B}\\| \\le \\|\\mathbf{A}\\|\\|\\mathbf{B}\\|$ and $\\|\\mathbf{A}\\mathbf{x}\\| \\le \\|\\mathbf{A}\\|\\|\\mathbf{x}\\|$), we obtain an upper bound for the norm of the error:\n$$\n\\|\\Delta\\mathbf{p}\\|_2 \\le \\|\\mathbf{H}^{-1}\\|_2 \\|\\Delta\\mathbf{H}\\|_2 \\|\\mathbf{p}\\|_2\n$$\nTo express this in terms of relative errors, we divide by $\\|\\mathbf{p}\\|_2$ (assuming $\\mathbf{p} \\neq \\mathbf{0}$, which is true if $\\mathbf{g} \\neq \\mathbf{0}$):\n$$\n\\frac{\\|\\Delta\\mathbf{p}\\|_2}{\\|\\mathbf{p}\\|_2} \\le \\|\\mathbf{H}^{-1}\\|_2 \\|\\Delta\\mathbf{H}\\|_2\n$$\nTo relate this to the relative perturbation in the Hessian, $\\frac{\\|\\Delta\\mathbf{H}\\|_2}{\\|\\mathbf{H}\\|_2}$, we multiply and divide the right side by $\\|\\mathbf{H}\\|_2$:\n$$\n\\frac{\\|\\Delta\\mathbf{p}\\|_2}{\\|\\mathbf{p}\\|_2} \\le \\left(\\|\\mathbf{H}\\|_2 \\|\\mathbf{H}^{-1}\\|_2\\right) \\frac{\\|\\Delta\\mathbf{H}\\|_2}{\\|\\mathbf{H}\\|_2}\n$$\nThe quantity in parentheses is the definition of the spectral condition number of the matrix $\\mathbf{H}$, denoted $\\kappa_2(\\mathbf{H})$. Thus, we have the fundamental result:\n$$\n\\frac{\\|\\Delta\\mathbf{p}\\|_2}{\\|\\mathbf{p}\\|_2} \\le \\kappa_2(\\mathbf{H}) \\frac{\\|\\Delta\\mathbf{H}\\|_2}{\\|\\mathbf{H}\\|_2}\n$$\nThis inequality demonstrates that the condition number $\\kappa_2(\\mathbf{H})$ serves as an amplification factor relating the relative error in the Hessian to the maximum possible relative error in the computed Newton step.\n\nOur task now reduces to calculating $\\kappa_2(\\mathbf{H})$ for the given matrix:\n$$\n\\mathbf{H} = \\begin{pmatrix} 4  1  0 \\\\ 1  3  0 \\\\ 0  0  \\tfrac{1}{2} \\end{pmatrix}\n$$\nThe spectral norm of a symmetric matrix is equal to its spectral radius, which is the maximum of the absolute values of its eigenvalues, $\\|\\mathbf{H}\\|_2 = \\max_i |\\lambda_i|$. Consequently, for an invertible symmetric matrix, the condition number is the ratio of the largest to the smallest absolute eigenvalue:\n$$\n\\kappa_2(\\mathbf{H}) = \\frac{\\max_i |\\lambda_i|}{\\min_i |\\lambda_i|}\n$$\nThe matrix $\\mathbf{H}$ is block-diagonal. The eigenvalues of $\\mathbf{H}$ are the union of the eigenvalues of its diagonal blocks. One block is the scalar matrix $[\\frac{1}{2}]$, so one eigenvalue is immediately $\\lambda_1 = \\frac{1}{2}$. The other block is the $2 \\times 2$ submatrix:\n$$\n\\mathbf{A} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}\n$$\nThe eigenvalues of $\\mathbf{A}$ are found from its characteristic equation, $\\det(\\mathbf{A} - \\lambda\\mathbf{I}) = 0$:\n$$\n\\det \\begin{pmatrix} 4-\\lambda  1 \\\\ 1  3-\\lambda \\end{pmatrix} = (4-\\lambda)(3-\\lambda) - 1 = 0\n$$\n$$\n\\lambda^2 - 7\\lambda + 12 - 1 = 0\n$$\n$$\n\\lambda^2 - 7\\lambda + 11 = 0\n$$\nUsing the quadratic formula, the eigenvalues of this submatrix are:\n$$\n\\lambda = \\frac{-(-7) \\pm \\sqrt{(-7)^2 - 4(1)(11)}}{2} = \\frac{7 \\pm \\sqrt{49-44}}{2} = \\frac{7 \\pm \\sqrt{5}}{2}\n$$\nSo, the three eigenvalues of $\\mathbf{H}$ are $\\lambda_1 = \\frac{1}{2}$, $\\lambda_2 = \\frac{7 - \\sqrt{5}}{2}$, and $\\lambda_3 = \\frac{7 + \\sqrt{5}}{2}$. All eigenvalues are positive, indicating that $\\mathbf{H}$ is positive definite, as is expected for a Hessian matrix near a local minimum.\n\nWe must identify the maximum and minimum eigenvalues.\n$$\n\\lambda_1 = \\frac{1}{2} = 0.5\n$$\nSince $2  \\sqrt{5}  3$, we can estimate $\\lambda_2$:\n$$\n\\frac{7 - 3}{2}  \\frac{7 - \\sqrt{5}}{2}  \\frac{7 - 2}{2} \\implies 2  \\lambda_2  2.5\n$$\nThus, $\\lambda_2  \\lambda_1$. The maximum eigenvalue is clearly $\\lambda_{\\max} = \\lambda_3 = \\frac{7 + \\sqrt{5}}{2}$. The minimum eigenvalue is $\\lambda_{\\min} = \\lambda_1 = \\frac{1}{2}$.\n\nThe spectral condition number is therefore:\n$$\n\\kappa_2(\\mathbf{H}) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{\\frac{7 + \\sqrt{5}}{2}}{\\frac{1}{2}} = 7 + \\sqrt{5}\n$$\nThis value, approximately $7 + 2.236 = 9.236$, is a measure of the numerical sensitivity. Since this number is not excessively large, the problem of computing the Newton step from this Hessian is considered well-conditioned. Small relative errors in $\\mathbf{H}$ will not be catastrophically amplified in the resulting step $\\mathbf{p}$.", "answer": "$$\n\\boxed{7 + \\sqrt{5}}\n$$", "id": "2894238"}]}