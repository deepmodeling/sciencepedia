{"hands_on_practices": [{"introduction": "The photoluminescence quantum yield ($\\Phi_f$) and excited-state lifetime ($\\tau$) are two of the most critical figures of merit for any luminescent material. While immensely useful, these are composite observables that arise from the competition between different de-excitation pathways. This practice focuses on the foundational task of dissecting these macroscopic quantities to reveal the microscopic rate constants for radiative ($k_r$) and non-radiative ($k_{nr}$) decay, which provides deeper insight into the material's intrinsic photophysics [@problem_id:2509388].", "problem": "A molecular dye dissolved in ethanol at room temperature exhibits a photoluminescence quantum yield $\\Phi_{f} = 0.35$ and a single-exponential fluorescence decay with lifetime $\\tau = 3.5\\ \\text{ns}$. Assume a simple two-channel first-order kinetic model for the lowest excited singlet state, in which deactivation occurs only via radiative decay with rate constant $k_{r}$ and lumped nonradiative decay with rate constant $k_{nr}$.\n\nStarting from the definition of fluorescence lifetime as the mean survival time of the excited-state population under first-order decay, and the definition of photoluminescence quantum yield as the fraction of excitations that emit a photon, derive expressions for $k_{r}$ and $k_{nr}$ in terms of $\\Phi_{f}$ and $\\tau$. Then use the provided values of $\\Phi_{f}$ and $\\tau$ to compute $k_{r}$ and $k_{nr}$.\n\nFinally, discuss qualitatively, using physical reasoning rooted in nonradiative deactivation mechanisms and local-field effects, how embedding the dye in a rigid, low-mobility host matrix of comparable refractive index to ethanol would be expected to change $k_{r}$ and $k_{nr}$.\n\nReport $k_{r}$ and $k_{nr}$ in $\\text{s}^{-1}$, and round each to three significant figures. Provide the final numerical pair as a two-entry row matrix in the order $\\left(k_{r}, k_{nr}\\right)$.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extracted Givens.\n- A molecular dye is dissolved in ethanol at room temperature.\n- The photoluminescence quantum yield is $\\Phi_{f} = 0.35$.\n- The fluorescence decay is a single exponential with lifetime $\\tau = 3.5\\ \\text{ns}$.\n- The kinetic model for the lowest excited singlet state is a simple two-channel, first-order process.\n- Deactivation pathways are radiative decay (rate constant $k_{r}$) and lumped nonradiative decay (rate constant $k_{nr}$).\n- The task requires derivation of expressions for $k_{r}$ and $k_{nr}$ in terms of $\\Phi_{f}$ and $\\tau$.\n- The task requires calculation of numerical values for $k_{r}$ and $k_{nr}$ in units of $\\text{s}^{-1}$, rounded to three significant figures.\n- The task requires a qualitative discussion on how $k_{r}$ and $k_{nr}$ would change upon embedding the dye in a rigid host matrix of comparable refractive index.\n- The final numerical answer must be a two-entry row matrix $\\left(k_{r}, k_{nr}\\right)$.\n\nStep 2: Validation.\n- The problem is **scientifically grounded**. It is based on the fundamental kinetic model of photoluminescence (a simplified Jablonski diagram), which is a cornerstone of photophysics and materials chemistry. The provided values for quantum yield and lifetime are physically realistic for a typical organic fluorophore.\n- The problem is **well-posed**. It provides precisely the necessary information ($\\Phi_{f}$ and $\\tau$) to determine the two unknown parameters ($k_{r}$ and $k_{nr}$) through a system of two independent equations.\n- The problem is **objective**. It is stated using precise, standard scientific terminology and devoid of subjective or ambiguous language.\n- The qualitative part concerning matrix effects is a standard conceptual question in spectroscopy, which addresses well-understood physical phenomena such as rigidochromism and local-field effects.\n\nStep 3: Verdict.\n- The problem is **valid**. It is self-contained, scientifically sound, and well-posed. A solution will be provided.\n\nThe analysis begins with the first-order kinetic model for the population of the excited singlet state, $N(t)$. The rate of change of this population is governed by the sum of all deactivation rates.\n$$\n\\frac{dN(t)}{dt} = -(k_{r} + k_{nr})N(t)\n$$\nThe total decay rate constant is defined as $k_{tot} = k_{r} + k_{nr}$. The differential equation simplifies to:\n$$\n\\frac{dN(t)}{dt} = -k_{tot} N(t)\n$$\nSolving this first-order linear ordinary differential equation for an initial population $N(0)=N_{0}$ yields the exponential decay law:\n$$\nN(t) = N_{0} \\exp(-k_{tot} t)\n$$\nThe fluorescence lifetime, $\\tau$, is defined as the mean survival time of the excited state population. For a single-exponential decay, this is equivalent to the time required for the population to decay to $1/e$ of its initial value. From the solution above, this occurs when the argument of the exponential is $-1$.\n$$\nk_{tot} \\tau = 1 \\implies \\tau = \\frac{1}{k_{tot}} = \\frac{1}{k_{r} + k_{nr}}\n$$\nThis provides the first fundamental relationship between the lifetime and the rate constants.\n\nThe photoluminescence quantum yield, $\\Phi_{f}$, is defined as the fraction of excited molecules that return to the ground state via radiative emission. This is equivalent to the ratio of the rate of the radiative process to the total rate of all deactivation processes.\n$$\n\\Phi_{f} = \\frac{\\text{rate of radiative decay}}{\\text{total rate of decay}} = \\frac{k_{r} N(t)}{(k_{r} + k_{nr}) N(t)} = \\frac{k_{r}}{k_{r} + k_{nr}}\n$$\nThis provides the second fundamental relationship.\n\nWe now have a system of two equations with two unknowns, $k_{r}$ and $k_{nr}$:\n1. $\\tau = \\frac{1}{k_{r} + k_{nr}}$\n2. $\\Phi_{f} = \\frac{k_{r}}{k_{r} + k_{nr}}$\n\nFrom equation (1), we can express the total decay rate as $k_{r} + k_{nr} = \\frac{1}{\\tau}$.\nSubstituting this into equation (2) gives:\n$$\n\\Phi_{f} = \\frac{k_{r}}{1/\\tau} = k_{r} \\tau\n$$\nSolving for $k_{r}$ yields the desired expression:\n$$\nk_{r} = \\frac{\\Phi_{f}}{\\tau}\n$$\nTo find $k_{nr}$, we rearrange the expression for the total decay rate: $k_{nr} = \\frac{1}{\\tau} - k_{r}$. Substituting the derived expression for $k_{r}$:\n$$\nk_{nr} = \\frac{1}{\\tau} - \\frac{\\Phi_{f}}{\\tau} = \\frac{1 - \\Phi_{f}}{\\tau}\n$$\nThe derivations are now complete.\n\nNext, we calculate the numerical values using the provided data: $\\Phi_{f} = 0.35$ and $\\tau = 3.5\\ \\text{ns} = 3.5 \\times 10^{-9}\\ \\text{s}$.\n\nFor the radiative rate constant, $k_{r}$:\n$$\nk_{r} = \\frac{0.35}{3.5 \\times 10^{-9}\\ \\text{s}} = 0.1 \\times 10^{9}\\ \\text{s}^{-1} = 1.0 \\times 10^{8}\\ \\text{s}^{-1}\n$$\nRounding to three significant figures gives $k_{r} = 1.00 \\times 10^{8}\\ \\text{s}^{-1}$.\n\nFor the nonradiative rate constant, $k_{nr}$:\n$$\nk_{nr} = \\frac{1 - 0.35}{3.5 \\times 10^{-9}\\ \\text{s}} = \\frac{0.65}{3.5 \\times 10^{-9}\\ \\text{s}} \\approx 1.85714... \\times 10^{8}\\ \\text{s}^{-1}\n$$\nRounding to three significant figures gives $k_{nr} = 1.86 \\times 10^{8}\\ \\text{s}^{-1}$.\n\nFinally, we discuss the expected changes upon embedding the dye in a rigid, low-mobility host matrix of comparable refractive index.\n\n1.  **Effect on the Nonradiative Rate Constant ($k_{nr}$):** Nonradiative decay pathways in organic dyes are often mediated by intramolecular motions, such as torsional rotations around single bonds or other large-amplitude vibrations. These motions facilitate internal conversion (IC) by allowing the excited-state potential energy surface to intersect with a high-lying vibrational level of the ground state, thus dissipating energy as heat. In a liquid solvent like ethanol, the dye molecule has considerable motional freedom. When the dye is transferred to a rigid, low-mobility host matrix, these intramolecular rotations and large-amplitude vibrations are sterically hindered and suppressed. The restriction of these motions effectively closes or slows down major nonradiative decay channels. Consequently, the nonradiative decay rate constant $k_{nr}$ is expected to **decrease** substantially.\n\n2.  **Effect on the Radiative Rate Constant ($k_{r}$):** The radiative rate constant $k_{r}$ is an intrinsic property related to the transition dipole moment of the S$_{1} \\rightarrow$ S$_{0}$ transition. However, it is also modulated by the dielectric environment, specifically the refractive index, $n$, of the surrounding medium. Theories of spontaneous emission in a dielectric medium (e.g., using local-field corrections) show that $k_{r}$ is a function of $n$. For instance, a common simple relation is $k_{r} \\propto n^{2}$. The problem explicitly states that the host matrix has a refractive index **comparable** to that of ethanol ($n_{\\text{ethanol}} \\approx 1.36$). By controlling for this variable, the major extrinsic factor affecting $k_{r}$ is eliminated. While minor changes to $k_{r}$ could occur due to slight conformational changes or specific molecule-matrix electronic interactions, these effects are typically secondary. Therefore, to a first approximation, the radiative rate constant $k_{r}$ is expected to remain **largely unchanged**.\n\nIn summary, the transition from a liquid solvent to a rigid matrix of similar refractive index primarily impacts the nonradiative decay channels. The expected outcome is a significant decrease in $k_{nr}$ with a minimal change in $k_{r}$. This would lead to a higher photoluminescence quantum yield ($\\Phi_{f} = k_{r} / (k_{r} + k_{nr})$) and a longer fluorescence lifetime ($\\tau = 1 / (k_{r} + k_{nr})$).", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.00 \\times 10^{8} & 1.86 \\times 10^{8} \\end{pmatrix}}\n$$", "id": "2509388"}, {"introduction": "In an ideal, homogeneous system, photoluminescence intensity decays as a single exponential. However, experimental data from real-world materials—such as polymers with varied chain conformations or quantum dot ensembles with size distributions—often exhibit more complex, multi-exponential decay kinetics. This practice addresses the critical challenge of fitting such data: determining the correct number of exponential components without overfitting to noise, using the statistically robust Akaike Information Criterion (AIC) to select the most parsimonious model [@problem_id:2509319].", "problem": "You are given a materials chemistry scenario in which time-resolved photoluminescence intensity decays are generated from a sum of first-order emissive processes. In such systems, a homogeneous population produces a single-exponential decay, while heterogeneous environments or multiple emissive channels can produce multi-exponential decays. Assume the following fundamental and widely accepted bases:\n- The excited-state population decay for a first-order process is given by $N(t) = N(0)\\,\\exp(-t/\\tau)$, where $t$ is time and $\\tau$ is the characteristic lifetime.\n- The detected photoluminescence intensity (proportional to the rate of decay of the excited population) can be modeled, for a system with $m$ independent emissive channels, as $I(t) = \\sum_{i=1}^{m} A_i \\exp(-t/\\tau_i)$ with amplitudes $A_i \\ge 0$ and lifetimes $\\tau_i > 0$.\n- The measurement is sampled at discrete times $t_j$ with independent, identically distributed additive Gaussian noise of zero mean and unknown variance $\\sigma^2$, so the observed data are $y_j = I(t_j) + \\epsilon_j$ with $\\epsilon_j \\sim \\mathcal{N}(0,\\sigma^2)$ independently across $j$.\n- For each candidate model order $m \\in \\{1,2,3\\}$, parameters are estimated by maximum likelihood, which under the Gaussian noise assumption is equivalent to minimizing the unweighted residual sum of squares $S = \\sum_{j=1}^{n} (y_j - I(t_j;\\theta_m))^2$ with respect to the model parameters $\\theta_m$.\n- Model selection across different $m$ is performed by comparing the Akaike Information Criterion (AIC), which is defined from the maximized likelihood and a penalty depending on the number of free parameters. The most parsimonious model is the one that yields the smallest AIC.\n\nYour task is to implement a program that, for each provided dataset, fits mono-exponential ($m = 1$), bi-exponential ($m = 2$), and tri-exponential ($m = 3$) models to the noisy data by maximum likelihood under the Gaussian noise assumption, computes the corresponding Akaike Information Criterion for each model, and returns the model order that minimizes the Akaike Information Criterion.\n\nScientific realism requirements:\n- Treat the time $t$ in nanoseconds (ns) and intensity in arbitrary linear units. Although the core algorithm is dimensionless, the data-generating process and time grids are grounded in realistic photoluminescence kinetics for materials chemistry.\n- Assume no instrument response convolution and zero baseline offset for the synthetic data. Ensure strictly positive lifetimes and nonnegative amplitudes in fits.\n\nNumerical specification and test suite:\nFor each dataset, the synthetic data are defined as follows. For each case, generate the time axis $t_j$ on a uniform grid over the specified range with the given step size (all $t$ in ns), compute the noise-free intensity $I(t_j) = \\sum_{i=1}^{m} A_i \\exp(-t_j/\\tau_i)$ using the listed amplitudes and lifetimes, then add Gaussian noise with the specified standard deviation $\\sigma$ using a fixed seed. All amplitudes $A_i$ and lifetimes $\\tau_i$ below are expressed as pure numbers; time is in ns.\n- Case $1$ (mono-exponential, high signal-to-noise ratio):\n  - True parameters: $A = [1000]$, $\\tau = [3.5]$.\n  - Time grid: start $0.0$, stop $50.0$, step $0.2$.\n  - Noise: Gaussian with standard deviation $\\sigma = 10.0$.\n  - Random seed: $42$.\n- Case $2$ (bi-exponential, separable lifetimes):\n  - True parameters: $A = [700, 300]$, $\\tau = [1.2, 6.0]$.\n  - Time grid: start $0.0$, stop $40.0$, step $0.1$.\n  - Noise: Gaussian with standard deviation $\\sigma = 8.0$.\n  - Random seed: $123$.\n- Case $3$ (tri-exponential, well-separated lifetimes):\n  - True parameters: $A = [500, 250, 100]$, $\\tau = [0.8, 3.0, 10.0]$.\n  - Time grid: start $0.0$, stop $60.0$, step $0.2$.\n  - Noise: Gaussian with standard deviation $\\sigma = 5.0$.\n  - Random seed: $2023$.\n- Case $4$ (bi-exponential with moderately overlapping lifetimes):\n  - True parameters: $A = [700, 300]$, $\\tau = [1.8, 3.2]$.\n  - Time grid: start $0.0$, stop $30.0$, step $0.15$.\n  - Noise: Gaussian with standard deviation $\\sigma = 6.0$.\n  - Random seed: $11$.\n- Case $5$ (tri-exponential with truncated window where the slow tail is weakly observable):\n  - True parameters: $A = [400, 250, 80]$, $\\tau = [0.7, 2.2, 20.0]$.\n  - Time grid: start $0.0$, stop $8.0$, step $0.05$.\n  - Noise: Gaussian with standard deviation $\\sigma = 10.0$.\n  - Random seed: $99$.\n\nImplementation constraints:\n- For each dataset, fit $m \\in \\{1,2,3\\}$ models of the form $I_m(t) = \\sum_{i=1}^{m} A_i \\exp(-t/\\tau_i)$ by minimizing the residual sum of squares with respect to $\\{A_i\\}_{i=1}^m$ and $\\{\\tau_i\\}_{i=1}^m$ under the constraints $A_i \\ge 0$ and $\\tau_i > 0$.\n- Use deterministic multi-start initializations for robustness. Parameter bounds must enforce $A_i \\ge 0$ and $\\tau_i > 0$.\n- Compute the Akaike Information Criterion from the maximized likelihood under the independent Gaussian noise model and choose the model order $m$ with the smallest Akaike Information Criterion.\n- The final result for each dataset is the selected model order, expressed as the integer $m \\in \\{1,2,3\\}$.\n\nAnswer specification:\n- Your program must produce a single line of output containing the results for the five datasets as a comma-separated Python list of integers enclosed in square brackets, for example, `[1,2,3,2,2]`.\n- No angles are involved. There are no units in the final output since the output is a list of integers.\n\nYour program must implement the entire workflow, including synthetic data generation, model fitting, Akaike Information Criterion computation, and model selection, using only the specified runtime environment.", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically sound, well-posed, and objective. It presents a standard, albeit non-trivial, task in data analysis within materials chemistry: the selection of an appropriate kinetic model for photoluminescence decay data. The provided physical model, statistical assumptions, and numerical test cases are consistent and grounded in established principles of physical chemistry and statistical inference. We shall therefore proceed with a complete solution.\n\nThe core of the problem is to distinguish between mono-, bi-, and tri-exponential decay models for a given time-resolved photoluminescence signal. The intensity decay for a system with $m$ independent first-order emissive channels is given by the model function:\n$$\nI(t; \\theta_m) = \\sum_{i=1}^{m} A_i \\exp\\left(-\\frac{t}{\\tau_i}\\right)\n$$\nwhere the parameter set $\\theta_m = \\{A_1, \\dots, A_m, \\tau_1, \\dots, \\tau_m\\}$ consists of $m$ non-negative amplitudes $A_i \\ge 0$ and $m$ positive characteristic lifetimes $\\tau_i > 0$.\n\nThe observed data $y_j$ at discrete time points $t_j$ are corrupted by noise, which is assumed to be independent and identically distributed additive Gaussian noise with zero mean and unknown variance $\\sigma^2$. That is, $y_j = I(t_j; \\theta_m) + \\epsilon_j$, with $\\epsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$.\n\nUnder this assumption, the principle of maximum likelihood estimation dictates that we find the parameters $\\theta_m$ that maximize the likelihood of observing the data. This is mathematically equivalent to minimizing the Residual Sum of Squares (RSS), defined as:\n$$\nS(\\theta_m) = \\sum_{j=1}^{n} \\left(y_j - I(t_j; \\theta_m)\\right)^2\n$$\nwhere $n$ is the number of data points. This is a non-linear least-squares optimization problem. The physical constraints $A_i \\ge 0$ and $\\tau_i > 0$ must be enforced during optimization.\n\nThe challenge in this problem lies in two areas: the numerical difficulty of the optimization and the statistical validity of model selection.\n\nFirst, the RSS landscape for multi-exponential models is notoriously non-convex, meaning it contains numerous local minima. A naive optimization starting from a single, arbitrary initial guess is highly likely to converge to a suboptimal solution. To robustly find a value close to the global minimum of the RSS, a deterministic multi-start strategy is implemented. For each model order $m \\in \\{1, 2, 3\\}$, a predefined grid of plausible initial guesses for the parameters $\\{A_i, \\tau_i\\}$ is constructed. The optimization is performed from each starting point, and the parameter set yielding the lowest RSS is retained as the best fit for that model order. The optimization itself is performed using the L-BFGS-B algorithm, which is a quasi-Newton method capable of handling box constraints required for $A_i$ and $\\tau_i$.\n\nSecond, simply choosing the model with the lowest RSS is incorrect, as a model with more parameters (a higher order $m$) will almost always achieve a lower RSS by fitting to the noise, a phenomenon known as overfitting. To select a model that is parsimonious—providing a good fit without unnecessary complexity—we employ the Akaike Information Criterion (AIC). The AIC balances goodness of fit against model complexity. For a least-squares problem with Gaussian noise, the AIC is computed as:\n$$\n\\text{AIC} = n \\ln\\left(\\frac{S_{\\min}}{n}\\right) + 2k\n$$\nHere, $S_{\\min}$ is the minimized RSS for a given model, $n$ is the number of data points, and $k$ is the total number of estimated parameters. For a model of order $m$, we estimate $m$ amplitudes and $m$ lifetimes. Additionally, the noise variance $\\sigma^2$ is an implicit parameter, estimated from the residuals as $\\hat{\\sigma}^2 = S_{\\min}/n$. Thus, the total number of parameters is $k = 2m + 1$. The model order $m \\in \\{1, 2, 3\\}$ that yields the minimum AIC value is selected as the most appropriate and parsimonious description of the underlying physical process.\n\nThe overall algorithm is as follows:\n1. For each of the $5$ test cases, generate the time axis $t_j$ and the corresponding noisy intensity data $y_j$ according to the specified true parameters, noise level $\\sigma$, and random seed.\n2. For each dataset, iterate through the candidate model orders $m=1, 2, 3$.\n3. For each $m$, perform the multi-start non-linear least-squares optimization to find the parameters $\\hat{\\theta}_m$ that minimize the RSS, obtaining $S_{\\min, m}$.\n4. Using $S_{\\min, m}$, calculate the AIC value, $\\text{AIC}_m$.\n5. After computing $\\text{AIC}_1, \\text{AIC}_2,$ and $\\text{AIC}_3$, identify the model order $m^*$ that corresponds to the minimum AIC value.\n6. The integer $m^*$ is the result for the current test case. The final output is the list of these integers for all test cases.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport itertools\n\ndef solve():\n    \"\"\"\n    Implements the full workflow for photoluminescence decay model selection.\n\n    For each test case, the function:\n    1. Generates synthetic time-resolved photoluminescence data with specified parameters and noise.\n    2. Fits mono-, bi-, and tri-exponential decay models to the data by minimizing the residual sum of squares (RSS).\n    3. A robust multi-start strategy with deterministic initial guesses is used to avoid local minima in the non-linear optimization.\n    4. Calculates the Akaike Information Criterion (AIC) for each of the three model fits.\n    5. Selects the model order (1, 2, or 3) that has the minimum AIC value.\n    6. Returns a list of the selected model orders for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case 1\", \"A_true\": [1000.0], \"tau_true\": [3.5],\n            \"t_start\": 0.0, \"t_stop\": 50.0, \"t_step\": 0.2,\n            \"sigma\": 10.0, \"seed\": 42\n        },\n        {\n            \"name\": \"Case 2\", \"A_true\": [700.0, 300.0], \"tau_true\": [1.2, 6.0],\n            \"t_start\": 0.0, \"t_stop\": 40.0, \"t_step\": 0.1,\n            \"sigma\": 8.0, \"seed\": 123\n        },\n        {\n            \"name\": \"Case 3\", \"A_true\": [500.0, 250.0, 100.0], \"tau_true\": [0.8, 3.0, 10.0],\n            \"t_start\": 0.0, \"t_stop\": 60.0, \"t_step\": 0.2,\n            \"sigma\": 5.0, \"seed\": 2023\n        },\n        {\n            \"name\": \"Case 4\", \"A_true\": [700.0, 300.0], \"tau_true\": [1.8, 3.2],\n            \"t_start\": 0.0, \"t_stop\": 30.0, \"t_step\": 0.15,\n            \"sigma\": 6.0, \"seed\": 11\n        },\n        {\n            \"name\": \"Case 5\", \"A_true\": [400.0, 250.0, 80.0], \"tau_true\": [0.7, 2.2, 20.0],\n            \"t_start\": 0.0, \"t_stop\": 8.0, \"t_step\": 0.05,\n            \"sigma\": 10.0, \"seed\": 99\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # 1. Generate synthetic data\n        rng = np.random.default_rng(case['seed'])\n        t = np.arange(case['t_start'], case['t_stop'], case['t_step'])\n        if len(t) == 0: continue\n\n        I_true = np.zeros_like(t, dtype=float)\n        for A, tau in zip(case['A_true'], case['tau_true']):\n            I_true += A * np.exp(-t / tau)\n        \n        noise = rng.normal(0, case['sigma'], size=t.shape)\n        y = I_true + noise\n        n = len(t)\n        \n        aic_values = []\n\n        # 2. Iterate through model orders m = 1, 2, 3\n        for m in range(1, 4):\n            def model_func(params, t_axis):\n                Amplitudes = params[:m]\n                lifetimes = params[m:]\n                I_fit = np.zeros_like(t_axis, dtype=float)\n                for i in range(m):\n                    I_fit += Amplitudes[i] * np.exp(-t_axis / lifetimes[i])\n                return I_fit\n\n            def objective_func(params):\n                I_fit = model_func(params, t)\n                return np.sum((y - I_fit)**2)\n\n            # 3. Robust multi-start optimization\n            tau_pool = [0.5, 2.0, 8.0, 25.0]\n            initial_guesses = []\n            y_max = y[0] if y[0] > 0 else np.max(y)\n            \n            if m == 1:\n                for tau_guess in tau_pool:\n                    initial_guesses.append([y_max, tau_guess])\n            elif m == 2:\n                for tau_pair in itertools.combinations(tau_pool, 2):\n                    initial_guesses.append([y_max * 0.5, y_max * 0.5] + list(tau_pair))\n                    initial_guesses.append([y_max * 0.7, y_max * 0.3] + list(tau_pair))\n                    initial_guesses.append([y_max * 0.3, y_max * 0.7] + list(tau_pair))\n            elif m == 3:\n                for tau_triplet in itertools.combinations(tau_pool, 3):\n                    initial_guesses.append([y_max / 3]*3 + list(tau_triplet))\n                    initial_guesses.append([y_max*0.5, y_max*0.3, y_max*0.2] + list(tau_triplet))\n\n            best_rss = np.inf\n            \n            # Constraints: A_i >= 0, tau_i > 0\n            bounds = [(0, y_max * 2.0)] * m + [(1e-6, t[-1] * 10.0)] * m\n            \n            for p0 in initial_guesses:\n                res = minimize(\n                    objective_func,\n                    p0,\n                    method='L-BFGS-B',\n                    bounds=bounds,\n                    options={'maxiter': 2000}\n                )\n                if res.success and res.fun < best_rss:\n                    best_rss = res.fun\n\n            # 4. Calculate AIC\n            if np.isinf(best_rss) or best_rss <= 0:\n                aic = np.inf\n            else:\n                k = 2 * m + 1  # 2m model parameters + 1 variance parameter\n                aic = n * np.log(best_rss / n) + 2 * k\n            aic_values.append(aic)\n\n        # 5. Select best model\n        best_m = np.argmin(aic_values) + 1\n        results.append(best_m)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2509319"}, {"introduction": "While phenomenological multi-exponential fits are useful, a more profound understanding of semiconductor photophysics requires models based on underlying physical processes. This advanced computational practice moves into this domain by tackling the analysis of charge carrier recombination in a material like a metal halide perovskite, governed by the so-called 'ABC' rate equation. By performing a global fit to data across multiple excitation intensities, you will learn to disentangle the contributions of monomolecular (defect-mediated), bimolecular (radiative), and trimolecular (Auger) recombination, a task central to the development of high-performance optoelectronic materials [@problem_id:2509350].", "problem": "You are given a modeling and inference task in time-resolved photoluminescence (TRPL) of a metal halide perovskite film. The fundamental base for this task is the carrier continuity equation, where the recombination rate is the sum of independent processes. In a spatially uniform, optically thin film under pulsed photoexcitation, the photogenerated excess carrier density $n(t)$ obeys an ordinary differential equation where the total recombination rate is composed of three independent channels: a monomolecular (defect-mediated) term proportional to $n$, a bimolecular (radiative) term proportional to $n^2$, and a three-body (Auger) term proportional to $n^3$, each with a positive rate coefficient. The time-resolved photoluminescence (PL) intensity is proportional to the radiative recombination rate. Assume that the detection constant is unity and that the radiative channel is exclusively the bimolecular term. Under these assumptions, your goal is to infer the three recombination coefficients from synthetic TRPL data generated across multiple initial carrier densities.\n\nModeling assumptions to be used:\n- The decay dynamics of the spatially uniform carrier density $n(t)$ are governed by a sum of recombination terms proportional to $n$, $n^2$, and $n^3$ with unknown positive coefficients $A$, $B$, and $C$, respectively. The initial condition is $n(0)=n_0$.\n- The measured PL intensity is proportional to the radiative bimolecular recombination rate, taken here as $I(t)=B\\,n(t)^2$ in arbitrary units.\n- Ignore instrument response and any re-absorption effects. Time is measured in nanoseconds, carrier densities in $\\mathrm{cm^{-3}}$, $A$ in $\\mathrm{s^{-1}}$, $B$ in $\\mathrm{cm^3\\,s^{-1}}$, and $C$ in $\\mathrm{cm^6\\,s^{-1}}$.\n\nConstruct a program that, for each test case defined below, performs a global nonlinear least-squares fit of the three unknown parameters $(A,B,C)$ to synthetic TRPL data generated at several initial carrier densities. The synthetic data for each test case must be generated by numerically solving the initial-value problem described above for each specified $n_0$, computing $I(t)=B\\,n(t)^2$ on the given time grid, and adding zero-mean Gaussian noise with a fixed random seed for reproducibility. Then, fit $(A,B,C)$ by minimizing the sum of squared residuals across all initial densities and times. Use nonnegative bounds for $A$, $B$, and $C$. To avoid domination by high-intensity traces, normalize residuals for each initial density by the maximum intensity of that trace. After fitting, quantify the fractional contribution of the monomolecular (defect-mediated) channel to the instantaneous total recombination rate at $t=0$ for the lowest $n_0$ as\n$$\nf_{\\mathrm{defect}}=\\frac{A\\,n_0}{A\\,n_0+B\\,n_0^2+C\\,n_0^3},\n$$\na unitless number in $[0,1]$, expressed as a decimal.\n\nNumerical details to enforce:\n- Time grid: use a uniform grid from $t=0$ to $t_{\\max} = 300$ nanoseconds with $N_t=201$ points.\n- Initial carrier densities for all test cases (in $\\mathrm{cm^{-3}}$): $n_0 \\in \\{\\,10^{15},\\; 5\\times 10^{16},\\; 5\\times 10^{17}\\,\\}$.\n- Noise model: for each synthetic trace, add independent Gaussian noise with zero mean and standard deviation equal to $\\sigma=\\alpha \\,\\max_t I(t)$ with $\\alpha=0.01$, where $I(t)$ is the noiseless model intensity for that trace. Use a fixed random seed $s=12345$ for the noise generator so that results are reproducible.\n- Units: all internal calculations should be consistent with the units specified; ensure that the time unit conversion between nanoseconds and seconds is handled correctly.\n\nTest Suite:\nFor each of the following test cases, generate synthetic data with the listed $(A,B,C)$ and then fit to recover $(A,B,C)$ and compute $f_{\\mathrm{defect}}$ at the lowest $n_0=10^{15}\\;\\mathrm{cm^{-3}}$.\n1. Test case 1 (trap-dominated at low injection): $A=5\\times 10^{6}\\;\\mathrm{s^{-1}}$, $B=1\\times 10^{-10}\\;\\mathrm{cm^3\\,s^{-1}}$, $C=1\\times 10^{-29}\\;\\mathrm{cm^6\\,s^{-1}}$.\n2. Test case 2 (balanced): $A=1\\times 10^{7}\\;\\mathrm{s^{-1}}$, $B=2\\times 10^{-10}\\;\\mathrm{cm^3\\,s^{-1}}$, $C=5\\times 10^{-29}\\;\\mathrm{cm^6\\,s^{-1}}$.\n3. Test case 3 (Auger-visible at high injection): $A=1\\times 10^{6}\\;\\mathrm{s^{-1}}$, $B=1\\times 10^{-10}\\;\\mathrm{cm^3\\,s^{-1}}$, $C=5\\times 10^{-28}\\;\\mathrm{cm^6\\,s^{-1}}$.\n\nWhat the program must compute and output:\n- For each test case, perform a single global fit across all three initial densities to infer $(A,B,C)$.\n- For each test case, compute $f_{\\mathrm{defect}}$ using the fitted $(A,B,C)$ at $n_0=10^{15}\\;\\mathrm{cm^{-3}}$.\n- The final output must be a single line containing a comma-separated list enclosed in square brackets. Concatenate the four outputs per test case in order $(A,B,C,f_{\\mathrm{defect}})$ for test cases $1$, $2$, and $3$, yielding a flat list of $12$ values. Each number in the list must be printed as a float in scientific notation, rounded to four significant figures. For example, a number equal to $1.234\\times 10^{-5}$ should appear as 1.234e-05.\n\nPhysical units and reporting:\n- Report $A$ in $\\mathrm{s^{-1}}$, $B$ in $\\mathrm{cm^3\\,s^{-1}}$, $C$ in $\\mathrm{cm^6\\,s^{-1}}$, and $f_{\\mathrm{defect}}$ as a unitless decimal. All four values must be printed in the specified scientific-notation format.", "solution": "The problem presented is a standard inverse problem in semiconductor physics, specifically the inference of charge carrier recombination coefficients from time-resolved photoluminescence (TRPL) data. The system is modeled under the common assumption of a spatially uniform carrier distribution in an optically thin film, where the temporal evolution of the excess carrier density, denoted by $n(t)$, is governed by an ordinary differential equation. The total recombination rate, $R(n)$, is the sum of three independent processes: monomolecular (defect-assisted or Shockley-Read-Hall), bimolecular (radiative), and trimolecular (Auger) recombination. This leads to the governing equation:\n$$\n\\frac{dn(t)}{dt} = -R(n) = -\\left(A n(t) + B n(t)^2 + C n(t)^3\\right)\n$$\nHere, $A$ (in units of $\\mathrm{s^{-1}}$), $B$ (in units of $\\mathrm{cm^3\\,s^{-1}}$), and $C$ (in units of $\\mathrm{cm^6\\,s^{-1}}$) are the positive-definite rate coefficients for the respective recombination channels. The initial condition is given by the photo-generated carrier density at time $t=0$, which is $n(0) = n_0$.\n\nThe experimental observable is the photoluminescence intensity, $I(t)$. It is assumed to be directly proportional to the rate of the radiative bimolecular recombination process. With a detection constant of unity, the intensity is given by:\n$$\nI(t) = B n(t)^2\n$$\nThe core task is to determine the unknown parameters $(A, B, C)$ from a set of synthetic TRPL decay traces generated at several distinct initial carrier densities $n_0$. The use of multiple initial densities is critical, as the relative contributions of the three recombination terms ($An$, $Bn^2$, $Cn^3$) scale differently with carrier density. Monomolecular recombination dominates at low $n$, bimolecular at intermediate $n$, and Auger at high $n$. A global fit across datasets spanning a wide range of $n_0$ values is therefore necessary to robustly disentangle and quantify the three coefficients.\n\nThe solution is implemented as a numerical procedure. First, a forward model is constructed to predict the TRPL signal for a given set of parameters $(A, B, C)$ and initial conditions. This requires numerically solving the initial value problem for the carrier density ODE. We employ the `scipy.integrate.solve_ivp` function, which implements an adaptive-step Runge-Kutta method, to obtain the solution $n(t)$ on the specified time grid, which must be converted from nanoseconds to seconds for consistency with the units of the rate coefficients. From $n(t)$, the model intensity $I_{\\text{model}}(t) = B n(t)^2$ is calculated.\n\nThe parameter inference is formulated as a nonlinear least-squares optimization problem. The goal is to find the parameter set $(A, B, C)$ that minimizes the sum of squared residuals between the model predictions and the synthetic data. The objective function, $\\chi^2$, is defined as:\n$$\n\\chi^2(A, B, C) = \\sum_{k} \\sum_{i} \\left[ \\frac{ I_{\\text{model},k}(t_i; A, B, C) - I_{\\text{data},k}(t_i) }{ \\max_{j} I_{\\text{data},k}(t_j) } \\right]^2\n$$\nThe outer sum is over the different datasets $k$, corresponding to each initial density $n_0$, and the inner sum is over all time points $t_i$ in a given trace. A crucial step is the normalization of the residuals for each trace by its maximum intensity, $\\max_{j} I_{\\text{data},k}(t_j)$. This ensures that data from all injection levels, including low-intensity traces from low $n_0$, contribute meaningfully to the fit, preventing the result from being dominated by the high-intensity signals at high $n_0$. The minimization is performed using `scipy.optimize.least_squares` with the Trust Region Reflective algorithm, which efficiently handles the physical constraint that the rate coefficients must be non-negative ($A \\geq 0$, $B \\geq 0$, $C \\geq 0$).\n\nSynthetic data for each test case is generated by first solving the ODE with the known true parameters $(A_{\\text{true}}, B_{\\text{true}}, C_{\\text{true}})$ to obtain the noiseless intensity traces. Then, zero-mean Gaussian noise is added. The standard deviation of the noise is set to $1\\%$ of the maximum intensity for that trace, and a fixed random seed is used to ensure reproducibility.\n\nFinally, after the best-fit parameters $(A_{\\text{fit}}, B_{\\text{fit}}, C_{\\text{fit}})$ are determined, the fractional contribution of the monomolecular (defect) recombination channel to the total initial recombination rate is calculated for the lowest initial carrier density, $n_{0,\\text{low}} = 10^{15}\\;\\mathrm{cm^{-3}}$. This quantity, $f_{\\text{defect}}$, is a key metric for material quality and is calculated as:\n$$\nf_{\\text{defect}} = \\frac{A_{\\text{fit}} n_{0,\\text{low}}}{A_{\\text{fit}} n_{0,\\text{low}} + B_{\\text{fit}} n_{0,\\text{low}}^2 + C_{\\text{fit}} n_{0,\\text{low}}^3}\n$$\nThe entire procedure is executed for each defined test case, and the resulting fitted coefficients and calculated $f_{\\text{defect}}$ values are formatted and reported as specified.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.optimize import least_squares\n\ndef solve():\n    \"\"\"\n    Solves the TRPL parameter inference problem.\n    This involves generating synthetic data, performing a global nonlinear\n    least-squares fit, and calculating a derived quantity for three test cases.\n    \"\"\"\n    # --- Define constants and experimental conditions ---\n    t_max_ns = 300.0\n    N_t = 201\n    t_eval_s = np.linspace(0, t_max_ns * 1e-9, N_t)  # Time grid in seconds\n\n    n0_values = np.array([1e15, 5e16, 5e17])  # Initial carrier densities in cm^-3\n    noise_alpha = 0.01\n    random_seed = 12345\n\n    # Test cases with true parameters (A, B, C)\n    test_cases = [\n        (5e6, 1e-10, 1e-29),   # Case 1: Trap-dominated\n        (1e7, 2e-10, 5e-29),   # Case 2: Balanced\n        (1e6, 1e-10, 5e-28)    # Case 3: Auger-visible\n    ]\n\n    # --- Model and Fitting Functions ---\n\n    def model_ode(t, n, A, B, C):\n        \"\"\" The ODE for carrier density n(t). \"\"\"\n        n_val = n[0]\n        dndt = -(A * n_val + B * n_val**2 + C * n_val**3)\n        return [dndt]\n\n    def generate_synthetic_data(A_true, B_true, C_true):\n        \"\"\" Generates noisy TRPL data for a set of true parameters. \"\"\"\n        rng = np.random.default_rng(random_seed)\n        noisy_data = []\n        for n0 in n0_values:\n            sol = solve_ivp(\n                fun=model_ode,\n                t_span=(t_eval_s[0], t_eval_s[-1]),\n                y0=[n0],\n                t_eval=t_eval_s,\n                args=(A_true, B_true, C_true),\n                method='RK45'\n            )\n            n_t = sol.y[0]\n            n_t[n_t < 0] = 0.0  # Ensure non-physical negative densities are floored\n\n            I_t = B_true * n_t**2\n            noise_std = noise_alpha * np.max(I_t)\n            noise = rng.normal(0, noise_std, size=I_t.shape) if noise_std > 0 else 0\n            I_noisy = I_t + noise\n            noisy_data.append(I_noisy)\n        return noisy_data\n\n    def objective_function(params, t_eval, n0_vals, all_noisy_data):\n        \"\"\" Objective function for least-squares minimization. \"\"\"\n        A, B, C = params\n        all_residuals = []\n\n        for i, n0 in enumerate(n0_vals):\n            I_noisy = all_noisy_data[i]\n            \n            sol = solve_ivp(\n                fun=model_ode,\n                t_span=(t_eval[0], t_eval[-1]),\n                y0=[n0],\n                t_eval=t_eval,\n                args=(A, B, C),\n                method='RK45'\n            )\n\n            if sol.status != 0: # Penalize failed integrations\n                return np.full(len(n0_vals) * len(t_eval), 1e10)\n\n            n_t_model = sol.y[0]\n            n_t_model[n_t_model < 0] = 0.0\n            I_t_model = B * n_t_model**2\n\n            norm_factor = np.max(I_noisy)\n            if norm_factor == 0:\n                norm_factor = 1.0 # Avoid division by zero for null signal\n\n            residuals = (I_t_model - I_noisy) / norm_factor\n            all_residuals.append(residuals)\n        \n        return np.concatenate(all_residuals)\n\n    all_results = []\n\n    # --- Main Loop over Test Cases ---\n    for A_true, B_true, C_true in test_cases:\n        # 1. Generate synthetic data\n        synthetic_data = generate_synthetic_data(A_true, B_true, C_true)\n\n        # 2. Perform nonlinear least-squares fit\n        p0 = [1e7, 1e-10, 1e-28]  # A reasonable generic initial guess\n        bounds = ([0, 0, 0], [np.inf, np.inf, np.inf]) # Coefficients must be non-negative\n\n        fit_result = least_squares(\n            fun=objective_function,\n            x0=p0,\n            args=(t_eval_s, n0_values, synthetic_data),\n            bounds=bounds,\n            method='trf',\n            jac='2-point'\n        )\n        A_fit, B_fit, C_fit = fit_result.x\n\n        # 3. Calculate f_defect using fitted parameters\n        n0_low = n0_values[0]\n        \n        numerator = A_fit * n0_low\n        denominator = (A_fit * n0_low + B_fit * n0_low**2 + C_fit * n0_low**3)\n        \n        f_defect = numerator / denominator if denominator > 0 else 0.0\n            \n        all_results.extend([A_fit, B_fit, C_fit, f_defect])\n\n    # 4. Format and print final results\n    formatted_results = [\"{:.3e}\".format(val) for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2509350"}]}