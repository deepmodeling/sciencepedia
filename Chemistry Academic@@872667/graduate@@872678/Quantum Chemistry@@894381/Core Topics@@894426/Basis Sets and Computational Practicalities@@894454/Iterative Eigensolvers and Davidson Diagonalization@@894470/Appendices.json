{"hands_on_practices": [{"introduction": "To truly understand the Davidson algorithm, there is no substitute for performing a step by hand. This practice guides you through one complete iteration, from calculating the residual for a trial vector to using the diagonal preconditioner to generate and incorporate a correction. This exercise solidifies the fundamental procedure at the heart of this powerful eigensolver. [@problem_id:2900262]", "problem": "A Hermitian matrix $A$ arises as a small sub-block of an electronic Hamiltonian in an orthonormal atomic-orbital basis. Consider the following real-symmetric $4 \\times 4$ matrix\n$$\nA=\\begin{pmatrix}\n1  \\tfrac{1}{5}  0  0 \\\\\n\\tfrac{1}{5}  2  \\tfrac{3}{10}  0 \\\\\n0  \\tfrac{3}{10}  3  \\tfrac{2}{5} \\\\\n0  0  \\tfrac{2}{5}  4\n\\end{pmatrix}.\n$$\nSuppose the current subspace of a Davidson diagonalization contains a single normalized trial vector $u=\\begin{pmatrix}1000\\end{pmatrix}^{\\top}$, intended to approximate the ground-state eigenvector. Let the associated Ritz value $\\theta$ be defined by the Rayleigh quotient $\\theta=\\dfrac{u^{\\top}Au}{u^{\\top}u}$. Using first principles of the Rayleigh–Ritz procedure and the definition of the residual $r$, perform one Davidson expansion step that uses the diagonal preconditioner $D=\\mathrm{diag}(A)$ to form a correction vector $t$, orthogonalizes $t$ to the current subspace, and then carries out the Rayleigh–Ritz extraction in the augmented subspace.\n\nYour tasks are:\n- Compute the residual $r$ from the trial pair $(\\theta,u)$.\n- Construct the standard Davidson correction $t$ using the diagonal preconditioner $D=\\mathrm{diag}(A)$ with shift $\\theta$.\n- Orthogonalize $t$ against the current subspace $\\mathrm{span}\\{u\\}$, normalize it to obtain a unit vector $w$, and form the two-column basis $W=[u\\;w]$.\n- Build the projected $2\\times 2$ Rayleigh–Ritz matrix $B=W^{\\top}AW$ and extract its smallest eigenvalue as the updated ground-state Ritz value.\n\nWhat is the updated smallest Ritz value after this single Davidson expansion step? Express your final answer as an exact analytic expression. Do not round.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and self-contained. It describes a standard application of one step of the Davidson diagonalization algorithm, a well-established iterative method for finding eigenvalues of large matrices, commonly used in quantum chemistry. All necessary data and definitions are provided, and no inconsistencies or ambiguities are present. We shall proceed with the solution.\n\nThe problem requires performing one step of the Davidson iterative procedure to refine the estimate of the lowest eigenvalue of the given matrix $A$. The steps are followed as prescribed.\n\nThe given real-symmetric matrix is\n$$\nA = \\begin{pmatrix}\n1  \\frac{1}{5}  0  0 \\\\\n\\frac{1}{5}  2  \\frac{3}{10}  0 \\\\\n0  \\frac{3}{10}  3  \\frac{2}{5} \\\\\n0  0  \\frac{2}{5}  4\n\\end{pmatrix}\n$$\nThe initial subspace is spanned by the single normalized trial vector\n$$\nu = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nSince $u$ is normalized, $u^{\\top}u = 1$.\n\nFirst, we compute the initial Ritz value $\\theta$, which is the Rayleigh quotient for the current trial vector $u$.\n$$\n\\theta = \\frac{u^{\\top}Au}{u^{\\top}u} = u^{\\top}Au\n$$\nWe compute the product $Au$:\n$$\nAu = \\begin{pmatrix}\n1  \\frac{1}{5}  0  0 \\\\\n\\frac{1}{5}  2  \\frac{3}{10}  0 \\\\\n0  \\frac{3}{10}  3  \\frac{2}{5} \\\\\n0  0  \\frac{2}{5}  4\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} =\n\\begin{pmatrix} 1 \\\\ \\frac{1}{5} \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThen, the Ritz value $\\theta$ is:\n$$\n\\theta = u^{\\top}(Au) = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\frac{1}{5} \\\\ 0 \\\\ 0 \\end{pmatrix} = 1\n$$\nThe initial approximation to the eigenvalue is $\\theta = 1$.\n\nNext, we compute the residual vector $r$ associated with the current Ritz pair $(\\theta, u)$.\n$$\nr = Au - \\theta u = \\begin{pmatrix} 1 \\\\ \\frac{1}{5} \\\\ 0 \\\\ 0 \\end{pmatrix} - 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{1}{5} \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n\nThe next step is to compute the correction vector $t$ by approximately solving the correction equation $(A - \\theta I)t = -r$. In the Davidson method, the matrix $(A - \\theta I)$ is approximated by its diagonal, yielding the preconditioner $(D - \\theta I)$, where $D = \\mathrm{diag}(A)$.\n$$\nD = \\mathrm{diag}(1, 2, 3, 4)\n$$\nThe correction equation becomes $(D - \\theta I)t = -r$.\n$$\n\\left( \\begin{pmatrix} 1  0  0  0 \\\\ 0  2  0  0 \\\\ 0  0  3  0 \\\\ 0  0  0  4 \\end{pmatrix} - 1 \\cdot \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} \\right) t = -r\n$$\n$$\n\\begin{pmatrix} 0  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  2  0 \\\\ 0  0  0  3 \\end{pmatrix} t = -\\begin{pmatrix} 0 \\\\ \\frac{1}{5} \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe components of $t = (t_1, t_2, t_3, t_4)^{\\top}$ are found by $t_i = -r_i / (D_{ii} - \\theta)$. For the index $i=1$, the denominator $D_{11}-\\theta = 1-1=0$. Since the corresponding residual component $r_1$ is also $0$, this component is formally undefined. The standard Davidson procedure requires the correction to be orthogonal to the current solution vector $u$. Since $u$ is the first canonical basis vector, this condition implies $t_1 = 0$. For other components:\n$$\nt_2 = \\frac{-r_2}{D_{22}-\\theta} = \\frac{-1/5}{2-1} = -\\frac{1}{5}\n$$\n$$\nt_3 = \\frac{-r_3}{D_{33}-\\theta} = \\frac{-0}{3-1} = 0\n$$\n$$\nt_4 = \\frac{-r_4}{D_{44}-\\theta} = \\frac{-0}{4-1} = 0\n$$\nSo the correction vector is\n$$\nt = \\begin{pmatrix} 0 \\\\ -1/5 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nNow, we must orthogonalize the correction vector $t$ against the current basis, which consists only of $u$. We use the Gram-Schmidt procedure. Let the orthogonalized vector be $t'$.\n$$\nt' = t - (u^{\\top}t)u\n$$\nThe inner product is\n$$\nu^{\\top}t = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -1/5 \\\\ 0 \\\\ 0 \\end{pmatrix} = 0\n$$\nSince $t$ is already orthogonal to $u$, we have $t' = t$. We then normalize this vector to obtain the new basis vector $w$.\n$$\n\\|t'\\| = \\sqrt{0^2 + \\left(-\\frac{1}{5}\\right)^2 + 0^2 + 0^2} = \\frac{1}{5}\n$$\n$$\nw = \\frac{t'}{\\|t'\\|} = \\frac{1}{1/5} \\begin{pmatrix} 0 \\\\ -1/5 \\\\ 0 \\\\ 0 \\end{pmatrix} = 5 \\begin{pmatrix} 0 \\\\ -1/5 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe new, expanded orthonormal basis is $\\{u, w\\}$. We form the matrix $W$ with these vectors as columns.\n$$\nW = \\begin{bmatrix} u  w \\end{bmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\\\ 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nWe now construct the projected $2 \\times 2$ Rayleigh-Ritz matrix $B = W^{\\top}AW$.\nFirst, we compute $AW$:\n$$\nAW = A \\begin{pmatrix} 1  0 \\\\ 0  -1 \\\\ 0  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  -\\frac{1}{5} \\\\ \\frac{1}{5}  -2 \\\\ 0  -\\frac{3}{10} \\\\ 0  0 \\end{pmatrix}\n$$\nThen we compute $B$:\n$$\nB = W^{\\top} (AW) = \\begin{pmatrix} 1  0  0  0 \\\\ 0  -1  0  0 \\end{pmatrix} \\begin{pmatrix} 1  -\\frac{1}{5} \\\\ \\frac{1}{5}  -2 \\\\ 0  -\\frac{3}{10} \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  -\\frac{1}{5} \\\\ -\\frac{1}{5}  2 \\end{pmatrix}\n$$\nThe final step is to find the eigenvalues of $B$ by solving the characteristic equation $\\det(B - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix} 1-\\lambda  -\\frac{1}{5} \\\\ -\\frac{1}{5}  2-\\lambda \\end{pmatrix} = (1-\\lambda)(2-\\lambda) - \\left(-\\frac{1}{5}\\right)^2 = 0\n$$\n$$\n\\lambda^2 - 3\\lambda + 2 - \\frac{1}{25} = 0\n$$\n$$\n\\lambda^2 - 3\\lambda + \\frac{50 - 1}{25} = 0\n$$\n$$\n\\lambda^2 - 3\\lambda + \\frac{49}{25} = 0\n$$\nWe solve this quadratic equation for $\\lambda$:\n$$\n\\lambda = \\frac{-(-3) \\pm \\sqrt{(-3)^2 - 4(1)\\left(\\frac{49}{25}\\right)}}{2(1)} = \\frac{3 \\pm \\sqrt{9 - \\frac{196}{25}}}{2}\n$$\n$$\n\\lambda = \\frac{3 \\pm \\sqrt{\\frac{225 - 196}{25}}}{2} = \\frac{3 \\pm \\sqrt{\\frac{29}{25}}}{2} = \\frac{3 \\pm \\frac{\\sqrt{29}}{5}}{2}\n$$\nThe two eigenvalues are $\\lambda_1 = \\frac{3}{2} + \\frac{\\sqrt{29}}{10}$ and $\\lambda_2 = \\frac{3}{2} - \\frac{\\sqrt{29}}{10}$.\nThe problem asks for the updated smallest Ritz value, which corresponds to the smallest eigenvalue of $B$. This is $\\lambda_2$.\n$$\n\\lambda_{\\min} = \\frac{3}{2} - \\frac{\\sqrt{29}}{10}\n$$\nThis is the updated estimate for the ground-state eigenvalue after one Davidson expansion step.", "answer": "$$\\boxed{\\frac{3}{2} - \\frac{\\sqrt{29}}{10}}$$", "id": "2900262"}, {"introduction": "Iterative methods are not infallible, and understanding their failure modes is key to using them effectively. This exercise explores the challenging case of nearly degenerate states, where a naive single-vector Davidson approach can fail to converge, oscillating between solutions. By deriving the iterative map, you will gain a deep, analytical insight into this 'root-flipping' phenomenon and appreciate the motivation for block Davidson algorithms. [@problem_id:2900285]", "problem": "In the context of iterative eigensolvers for quantum chemistry, consider a model Hamiltonian representing a nearly degenerate doublet,\n$$\nH \\;=\\; \\begin{pmatrix}\n-\\delta  \\epsilon \\\\\n\\epsilon  \\delta\n\\end{pmatrix},\n$$\nwith real parameters $\\delta$ and $\\epsilon$, where $|\\epsilon| \\ll |\\delta|$ models weak coupling between two nearly degenerate basis states. The matrix $H$ is real symmetric and thus has real eigenvalues and orthogonal eigenvectors.\n\nWe consider the single-vector Davidson diagonalization with one-dimensional restarts, using the diagonal (Davidson) preconditioner. In this naive variant, starting from a normalized vector $v = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$ with $x^{2}+y^{2}=1$, one Davidson iteration proceeds as follows:\n- Compute the Rayleigh quotient $\\theta = v^{\\top} H v$.\n- Compute the residual $r = H v - \\theta v$.\n- With $D = \\mathrm{diag}(H)$, compute the correction $t$ by solving $(D - \\theta I)\\, t = r$.\n- Form the new trial vector as $v^{+} \\propto v + t$ (normalized after addition).\n\nDefine the component ratio $s = y/x$ for the current vector and $s^{+} = y^{+}/x^{+}$ for the updated vector. Starting only from the definitions above of the Rayleigh quotient, the residual, and the Davidson correction, derive the closed-form expression for the rational map $f$ such that $s^{+} = f(s)$ in terms of $s$, $\\delta$, and $\\epsilon$. Your derivation should be explicit and self-contained.\n\nThen, briefly explain (qualitatively, without computing a number) how, for $|\\epsilon| \\ll |\\delta|$ and with $s$ initially near $\\pm 1$, the map $s \\mapsto f(s)$ can produce an oscillatory two-cycle that alternates the iterate between approximations to the two lowest roots when only a single vector is retained each step, and why a block Davidson step with block size $2$ stabilizes convergence for this two-level problem.\n\nProvide as your final answer the closed-form expression for $f(s)$ (i.e., $s^{+}$ as an explicit function of $s$, $\\delta$, and $\\epsilon$). No numerical evaluation is required, and no units are necessary. Do not include any additional commentary in your final answer beyond this single expression.", "solution": "The problem requires the derivation of the iterative map for the component ratio of a trial vector in a single-vector Davidson diagonalization procedure for a specified $2 \\times 2$ Hamiltonian, followed by a qualitative explanation of its convergence behavior.\n\nFirst, the problem is validated.\n\n**Step 1: Extract Givens**\n-   Hamiltonian: $H = \\begin{pmatrix} -\\delta  \\epsilon \\\\ \\epsilon  \\delta \\end{pmatrix}$ with real parameters $\\delta, \\epsilon$ and $|\\epsilon| \\ll |\\delta|$.\n-   Trial vector: $v = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$, with $x^2+y^2=1$.\n-   Component ratio: $s = y/x$.\n-   Davidson iteration:\n    1.  Rayleigh quotient: $\\theta = v^{\\top} H v$.\n    2.  Residual: $r = H v - \\theta v$.\n    3.  Preconditioner: $D = \\mathrm{diag}(H) = \\begin{pmatrix} -\\delta  0 \\\\ 0  \\delta \\end{pmatrix}$.\n    4.  Correction: Solve $(D - \\theta I)\\, t = r$ for $t$.\n    5.  Update: $v^{+} \\propto v + t$, with new ratio $s^{+} = y^{+}/x^{+}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, using a standard model from quantum mechanics and a well-known numerical algorithm (Davidson diagonalization). It is well-posed, providing all necessary definitions to derive the requested mathematical expression. The language is objective and precise. The procedure specified in \"solve $(D-\\theta I)t=r$\" becomes ambiguous if $D-\\theta I$ is singular, which occurs if the Rayleigh quotient $\\theta$ equals a diagonal entry of $H$. This happens if the trial vector is one of the basis vectors (e.g., $s=0$ or $s \\to \\infty$). However, assuming the desired map $s \\mapsto f(s)$ is a rational function, its value at these points can be determined by taking the limit from non-singular cases, thus resolving the ambiguity. Under this reasonable interpretation, the problem is valid.\n\n**Derivation of the map $s^{+} = f(s)$**\n\nLet the current normalized trial vector be $v = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$. The Rayleigh quotient is $\\theta = v^{\\top}Hv$.\nThe components of the residual vector $r = Hv - \\theta v$ are:\n$$r_x = (-\\delta x + \\epsilon y) - \\theta x = (-\\delta - \\theta)x + \\epsilon y$$\n$$r_y = (\\epsilon x + \\delta y) - \\theta y = \\epsilon x + (\\delta - \\theta)y$$\nThe diagonal preconditioner matrix is $D = \\begin{pmatrix} -\\delta  0 \\\\ 0  \\delta \\end{pmatrix}$. The correction vector $t = \\begin{pmatrix} t_x \\\\ t_y \\end{pmatrix}$ is found by solving $(D - \\theta I)t=r$:\n$$t_x = \\frac{r_x}{-\\delta - \\theta} = \\frac{(-\\delta - \\theta)x + \\epsilon y}{-\\delta - \\theta} = x + \\frac{\\epsilon y}{-\\delta - \\theta} = x - \\frac{\\epsilon y}{\\delta + \\theta}$$\n$$t_y = \\frac{r_y}{\\delta - \\theta} = \\frac{\\epsilon x + (\\delta - \\theta)y}{\\delta - \\theta} = y + \\frac{\\epsilon x}{\\delta - \\theta}$$\nThe new trial vector $v^{+}$ is proportional to $v+t$:\n$$v^{+} \\propto \\begin{pmatrix} x+t_x \\\\ y+t_y \\end{pmatrix} = \\begin{pmatrix} x + (x - \\frac{\\epsilon y}{\\delta + \\theta}) \\\\ y + (y + \\frac{\\epsilon x}{\\delta - \\theta}) \\end{pmatrix} = \\begin{pmatrix} 2x - \\frac{\\epsilon y}{\\delta + \\theta} \\\\ 2y + \\frac{\\epsilon x}{\\delta - \\theta} \\end{pmatrix}$$\nThe new component ratio $s^{+} = y^{+}/x^{+}$ is given by:\n$$s^{+} = \\frac{2y + \\frac{\\epsilon x}{\\delta - \\theta}}{2x - \\frac{\\epsilon y}{\\delta + \\theta}}$$\nTo express this in terms of $s=y/x$, we divide the numerator and denominator by $x$:\n$$s^{+} = \\frac{2s + \\frac{\\epsilon}{\\delta - \\theta}}{2 - \\frac{\\epsilon s}{\\delta + \\theta}}$$\nNow, we express $\\theta$ in terms of $s$. Using an unnormalized vector $\\begin{pmatrix} 1 \\\\ s \\end{pmatrix}$ for the Rayleigh quotient calculation gives:\n$$\\theta = \\frac{1}{1+s^2}\\begin{pmatrix} 1  s \\end{pmatrix} \\begin{pmatrix} -\\delta  \\epsilon \\\\ \\epsilon  \\delta \\end{pmatrix} \\begin{pmatrix} 1 \\\\ s \\end{pmatrix} = \\frac{-\\delta + \\delta s^2 + 2\\epsilon s}{1+s^2}$$\nWe compute the denominators needed for the $s^{+}$ expression:\n$$\\delta - \\theta = \\delta - \\frac{\\delta s^2 - \\delta + 2\\epsilon s}{1+s^2} = \\frac{\\delta(1+s^2) - (\\delta s^2 - \\delta + 2\\epsilon s)}{1+s^2} = \\frac{2\\delta - 2\\epsilon s}{1+s^2}$$\n$$\\delta + \\theta = \\delta + \\frac{\\delta s^2 - \\delta + 2\\epsilon s}{1+s^2} = \\frac{\\delta(1+s^2) + (\\delta s^2 - \\delta + 2\\epsilon s)}{1+s^2} = \\frac{2\\delta s^2 + 2\\epsilon s}{1+s^2}$$\nSubstituting these into the expression for $s^{+}$:\n$$s^{+} = \\frac{2s + \\frac{\\epsilon(1+s^2)}{2(\\delta - \\epsilon s)}}{2 - \\frac{\\epsilon s(1+s^2)}{2(\\delta s^2 + \\epsilon s)}} = \\frac{2s + \\frac{\\epsilon(1+s^2)}{2(\\delta - \\epsilon s)}}{2 - \\frac{\\epsilon(1+s^2)}{2(\\delta s + \\epsilon)}}$$\nThe cancellation of $s$ in the denominator is valid for $s \\neq 0$. The resulting rational function will be continuous, and its value at $s=0$ can be obtained by taking the limit.\nWe simplify the numerator and denominator:\nNumerator: $N = \\frac{4s(\\delta - \\epsilon s) + \\epsilon(1+s^2)}{2(\\delta - \\epsilon s)} = \\frac{4\\delta s - 4\\epsilon s^2 + \\epsilon + \\epsilon s^2}{2(\\delta - \\epsilon s)} = \\frac{4\\delta s + \\epsilon - 3\\epsilon s^2}{2(\\delta - \\epsilon s)}$\nDenominator: $D = \\frac{4(\\delta s + \\epsilon) - \\epsilon(1+s^2)}{2(\\delta s + \\epsilon)} = \\frac{4\\delta s + 4\\epsilon - \\epsilon - \\epsilon s^2}{2(\\delta s + \\epsilon)} = \\frac{4\\delta s + 3\\epsilon - \\epsilon s^2}{2(\\delta s + \\epsilon)}$\nCombining these gives the final map $s^{+} = f(s) = N/D$:\n$$s^{+} = \\frac{\\frac{4\\delta s + \\epsilon - 3\\epsilon s^2}{2(\\delta - \\epsilon s)}}{\\frac{4\\delta s + 3\\epsilon - \\epsilon s^2}{2(\\delta s + \\epsilon)}} = \\frac{(4\\delta s + \\epsilon(1 - 3s^2))}{(4\\delta s + \\epsilon(3 - s^2))} \\cdot \\frac{(\\delta s + \\epsilon)}{(\\delta - \\epsilon s)}$$\nThis is the required closed-form expression for the map $f$.\n\n**Qualitative Explanation of Convergence Behavior**\n\nThe described model has two nearly degenerate eigenstates. Let's call them $v_1$ and $v_2$, with corresponding eigenvalues $\\lambda_1 \\approx -\\delta$ and $\\lambda_2 \\approx \\delta$. In the single-vector Davidson method, starting with a trial vector $v^{(k)}$ that is a good approximation to one of the eigenstates, say $v_1$, the Rayleigh quotient $\\theta$ will be close to the corresponding eigenvalue, $\\theta \\approx \\lambda_1$. The residual $r = (H-\\theta I)v^{(k)}$ is supposed to contain information about the error in $v^{(k)}$. The key step is the preconditioning, which computes the correction $t = (D-\\theta I)^{-1}r$.\n\nFor the nearly degenerate case where $|\\epsilon| \\ll |\\delta|$, the true eigenvectors are small perturbations of the basis vectors $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. If the current iterate $v^{(k)}$ is close to the eigenvector $v_1$ (which is close to $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$), then $\\theta \\approx \\lambda_1 \\approx -\\delta$. The preconditioner matrix becomes $D-\\theta I \\approx \\begin{pmatrix} -\\delta - (-\\delta)  0 \\\\ 0  \\delta - (-\\delta) \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  2\\delta \\end{pmatrix}$. This preconditioner is nearly singular. Its inverse, $(D-\\theta I)^{-1}$, will have a very large entry corresponding to the direction of the *other* basis state, $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. The residual $r$ will have a small component pointing towards the other eigenvector $v_2$. The preconditioner will dramatically amplify this component. Consequently, the correction vector $t$ will be dominated by the direction towards $v_2$, which is nearly orthogonal to the current iterate $v^{(k)}$.\n\nThe update step $v^{(k+1)} \\propto v^{(k)} + t$ then produces a vector that is pulled strongly towards $v_2$. The next iteration, starting from an approximation to $v_2$, will similarly generate a correction pointing back towards $v_1$. This results in the iterate oscillating between the two nearly degenerate states, failing to converge to either one. This behavior is called \"root-flipping\" and is a known pathology of single-vector iterative methods when applied to nearly degenerate systems.\n\nA block Davidson method with a block size of $2$ or more resolves this issue. By maintaining a subspace of at least two vectors, the algorithm can build a representation for the entire nearly degenerate manifold. It starts with two initial vectors (e.g., approximations to both eigenstates). At each step, it solves a $2 \\times 2$ eigenvalue problem within the subspace to find the best current approximations (the Ritz vectors) to both eigenstates. It then computes correction vectors for *both* Ritz vectors and uses them to expand the subspace. By working in a vector space that is large enough to describe both nearly degenerate states simultaneously, the algorithm can stably converge to both eigenvectors without the oscillatory behavior caused by the preconditioner pushing the single trial vector from one state to the other.", "answer": "$$\n\\boxed{\\frac{(4\\delta s + \\epsilon(1 - 3s^2))(\\delta s + \\epsilon)}{(4\\delta s + \\epsilon(3 - s^2))(\\delta - \\epsilon s)}}\n$$", "id": "2900285"}, {"introduction": "Most applications in quantum chemistry require computing more than just the ground state. This practice demonstrates the 'deflation' or 'locking' technique, a procedure for removing a converged eigenpair from the search space to allow the algorithm to find the next one. You will see how to confirm convergence and then project the problem into a smaller, deflated subspace to continue the search for other eigenvalues. [@problem_id:2900259]", "problem": "In an iterative subspace diagonalization of a real symmetric effective electronic Hamiltonian in a truncated Configuration Interaction Singles (CIS) space, consider a single Davidson diagonalization iteration in which the current orthonormal trial subspace has basis matrix $V \\in \\mathbb{R}^{3 \\times 2}$ with columns\n$$\nv_{1} \\;=\\; \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix},\n\\qquad\nv_{2} \\;=\\; \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\nThe target operator is the symmetric matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n2  0  0 \\\\\n0  3  0 \\\\\n0  0  5\n\\end{pmatrix}.\n$$\nThe projected (Rayleigh-Ritz) matrix is $T \\equiv V^{\\top} A V$. The Ritz values are the eigenvalues of $T$, and the corresponding Ritz vectors in the full space are given by $y = V c$, where $c$ is a normalized eigenvector of $T$. Suppose the largest Ritz value and its corresponding Ritz vector have met a stringent residual tolerance for convergence in the Davidson method, and they are therefore to be locked and deflated from the active search.\n\nUsing only the definitions of the Rayleigh-Ritz projection $T = V^{\\top} A V$, the construction of Ritz vectors $y = V c$, and the notion of locking in Davidson diagonalization as removal of the converged component from the active search subspace via orthogonal deflation, do the following:\n\n1. Compute $T$ and identify the converged (largest) Ritz pair. Confirm its residual norm from first principles using $r \\equiv A y - \\theta y$, where $\\theta$ is the chosen Ritz value and $y$ is its Ritz vector in the full space.\n2. Apply deflation by locking the converged Ritz vector, remove it from the active subspace, and form the deflated active basis $V_{\\text{act}}$ using the remaining column(s) of $V$. Compute the deflated projected matrix $T_{\\text{act}} \\equiv V_{\\text{act}}^{\\top} A V_{\\text{act}}$.\n3. In a short discussion, explain how spurious convergence may arise in such iterative eigensolvers and how it can be detected and corrected using only residuals and orthogonality relations with the locked subspace. Your explanation should be grounded in first-principles definitions of residuals and orthogonality.\n\nReport as your final answer the determinant of the deflated projected matrix $T_{\\text{act}}$. Express the final answer as an exact rational number with no units. Do not round your answer.", "solution": "The problem requires an analysis of a single iteration of the Davidson diagonalization method, including the computation of a projected matrix, identification of a converged eigenpair, application of deflation, and a discussion of spurious convergence.\n\nThe given full-space operator is the real symmetric matrix:\n$$\nA = \\begin{pmatrix}\n2  0  0 \\\\\n0  3  0 \\\\\n0  0  5\n\\end{pmatrix}\n$$\nThe trial subspace is spanned by the columns of the matrix $V \\in \\mathbb{R}^{3 \\times 2}$, which form an orthonormal set:\n$$\nV = \\begin{pmatrix} v_1  v_2 \\end{pmatrix} = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}}  0 \\\\\n\\frac{1}{\\sqrt{2}}  0 \\\\\n0  1\n\\end{pmatrix}\n$$\n\nThe analysis proceeds in three parts as requested.\n\n1. Computation of the projected matrix $T$, identification of the converged Ritz pair, and verification of its residual.\n\nThe projected matrix, or Rayleigh-Ritz matrix, $T$, is defined as $T = V^{\\top} A V$. First, we compute the product $AV$:\n$$\nAV = \\begin{pmatrix}\n2  0  0 \\\\\n0  3  0 \\\\\n0  0  5\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}}  0 \\\\\n\\frac{1}{\\sqrt{2}}  0 \\\\\n0  1\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{2}{\\sqrt{2}}  0 \\\\\n\\frac{3}{\\sqrt{2}}  0 \\\\\n0  5\n\\end{pmatrix}\n$$\nNext, we pre-multiply by $V^{\\top}$:\n$$\nT = V^{\\top} (AV) = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}}  0 \\\\\n0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{2}{\\sqrt{2}}  0 \\\\\n\\frac{3}{\\sqrt{2}}  0 \\\\\n0  5\n\\end{pmatrix}\n$$\nThe elements of the $2 \\times 2$ matrix $T$ are:\n$$\nT_{11} = \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(\\frac{2}{\\sqrt{2}}\\right) + \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(\\frac{3}{\\sqrt{2}}\\right) + (0)(0) = \\frac{2}{2} + \\frac{3}{2} = \\frac{5}{2}\n$$\n$$\nT_{12} = \\left(\\frac{1}{\\sqrt{2}}\\right)(0) + \\left(\\frac{1}{\\sqrt{2}}\\right)(0) + (0)(5) = 0\n$$\n$$\nT_{21} = (0)\\left(\\frac{2}{\\sqrt{2}}\\right) + (0)\\left(\\frac{3}{\\sqrt{2}}\\right) + (1)(0) = 0\n$$\n$$\nT_{22} = (0)(0) + (0)(0) + (1)(5) = 5\n$$\nSo, the projected matrix is:\n$$\nT = \\begin{pmatrix}\n\\frac{5}{2}  0 \\\\\n0  5\n\\end{pmatrix}\n$$\nThe eigenvalues of this diagonal matrix $T$ are the Ritz values, which are $\\theta_1 = \\frac{5}{2}$ and $\\theta_2 = 5$. The corresponding normalized eigenvectors of $T$ are $c_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $c_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n\nThe problem states that the largest Ritz value has converged. This is $\\theta = \\theta_2 = 5$. The associated eigenvector of $T$ is $c = c_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. The corresponding Ritz vector in the full space is $y = Vc$:\n$$\ny = V c = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}}  0 \\\\\n\\frac{1}{\\sqrt{2}}  0 \\\\\n0  1\n\\end{pmatrix}\n\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\nThe converged Ritz pair is $(\\theta, y) = \\left(5, \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\\right)$.\n\nTo confirm convergence, we compute the residual vector $r = Ay - \\theta y$:\n$$\nA y = \\begin{pmatrix}\n2  0  0 \\\\\n0  3  0 \\\\\n0  0  5\n\\end{pmatrix}\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 0 \\\\ 5 \\end{pmatrix}\n$$\n$$\n\\theta y = 5 \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 5 \\end{pmatrix}\n$$\n$$\nr = A y - \\theta y = \\begin{pmatrix} 0 \\\\ 0 \\\\ 5 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe residual norm is $||r|| = 0$. This confirms that the Ritz pair is in fact an exact eigenpair of the full matrix $A$, which is the ultimate condition for convergence.\n\n2. Application of deflation and computation of the deflated projected matrix $T_{\\text{act}}$.\n\nDeflation is applied by locking the converged Ritz vector $y$ and removing its contribution from the active search space. The problem specifies that the new active basis, $V_{\\text{act}}$, is formed from the \"remaining column(s) of $V$\". The converged Ritz vector $y = v_2$. Thus, the remaining column is $v_1$. The deflated active basis is a $3 \\times 1$ matrix:\n$$\nV_{\\text{act}} = v_1 = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}\n$$\nThe deflated projected matrix is $T_{\\text{act}} = V_{\\text{act}}^{\\top} A V_{\\text{act}}$.\n$$\nA V_{\\text{act}} = \\begin{pmatrix}\n2  0  0 \\\\\n0  3  0 \\\\\n0  0  5\n\\end{pmatrix}\n\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}\n= \\begin{pmatrix} \\frac{2}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}\n$$\n$$\nT_{\\text{act}} = V_{\\text{act}}^{\\top} (A V_{\\text{act}}) = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}}  0 \\end{pmatrix} \\begin{pmatrix} \\frac{2}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}\n$$\nThis results in a $1 \\times 1$ matrix (a scalar):\n$$\nT_{\\text{act}} = \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(\\frac{2}{\\sqrt{2}}\\right) + \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(\\frac{3}{\\sqrt{2}}\\right) = \\frac{2}{2} + \\frac{3}{2} = \\frac{5}{2}\n$$\nThe determinant of a $1 \\times 1$ matrix $[a]$ is simply $a$. Therefore, $\\det(T_{\\text{act}}) = \\frac{5}{2}$.\n\n3. Discussion on spurious convergence.\n\nIn iterative eigensolvers that find multiple eigenpairs, such as Davidson with locking, spurious convergence is the phenomenon where the algorithm converges to a Ritz pair $(\\theta, y)$ that is not a new, distinct eigenpair of the operator $A$. Instead, it represents a \"rediscovery\" of an eigenpair that has already been found and locked. The spurious Ritz vector $y$ is not orthogonal to the subspace spanned by the previously converged (locked) eigenvectors. For a symmetric operator $A$, eigenvectors corresponding to distinct eigenvalues must be orthogonal. A failure to maintain this orthogonality leads to spurious solutions.\n\nDetection of spurious convergence relies on first-principles definitions. A necessary condition for a Ritz pair $(\\theta, y)$ to be a genuine new eigenpair is that its residual norm, $||r|| = ||Ay - \\theta y||$, must be below a specified tolerance. However, this is not a sufficient condition. A spurious Ritz vector can also exhibit a small residual norm, as it is a good approximation to an eigenpair, albeit one already found. The crucial and sufficient test is an orthogonality check. Let $Y_{\\text{lock}} = \\{y_1, y_2, \\dots, y_k\\}$ be the set of $k$ previously locked eigenvectors. For any new candidate for convergence, $y_{\\text{cand}}$, one must compute its projection onto the locked subspace:\n$$\n\\text{Projection magnitude} = |y_{\\text{cand}}^{\\top} y_j| \\quad \\text{for } j = 1, \\dots, k\n$$\nIf this projection is significantly non-zero for any locked vector $y_j$, it indicates that $y_{\\text{cand}}$ has a component in the already-solved subspace. The candidate is thus identified as spurious and must be rejected.\n\nCorrection of this issue is achieved by enforcing orthogonality throughout the iterative process. This is a form of explicit deflation. When a new direction vector $d$ is generated to expand the subspace (typically from the preconditioned residual vector), it must be made orthogonal to all locked eigenvectors before it is used. This is achieved via a Gram-Schmidt-like projection:\n$$\nd_{\\text{ortho}} = d - \\sum_{j=1}^{k} (y_j^{\\top} d) y_j\n$$\nThe corrected vector $d_{\\text{ortho}}$ is then orthogonalized against the current active basis vectors and added to the subspace. This procedure ensures that the search for new eigenpairs is confined to the subspace $Y_{\\text{lock}}^{\\perp}$, which is the orthogonal complement to the space spanned by the locked vectors, thereby systematically preventing the rediscovery of old solutions.", "answer": "$$\n\\boxed{\\frac{5}{2}}\n$$", "id": "2900259"}]}