{"hands_on_practices": [{"introduction": "In any analytical laboratory, quality control (QC) protocols are essential for ensuring reliable results. Often, these protocols use simple rules, such as flagging a measurement if it falls outside a certain range like $\\mu \\pm 3\\sigma$. This exercise demonstrates that these are not arbitrary limits but are directly tied to the statistical concept of the significance level, $\\alpha$. By working through this problem [@problem_id:1446340], you will calculate the probability of a Type I error (a 'false alarm') that is inherent in this common QC rule, bridging the gap between practical procedure and statistical theory.", "problem": "In an analytical chemistry laboratory, a new spectrophotometer is used to verify the concentration of a potassium permanganate Certified Reference Material (CRM). Based on extensive prior calibration, the measurements of the CRM's absorbance are known to follow a normal distribution with a mean $\\mu$ corresponding to the certified concentration and a known population standard deviation $\\sigma$.\n\nThe laboratory's quality control protocol for daily instrument checks involves a single measurement of the CRM. The protocol states that the instrument is considered \"out of statistical control\" if this single measurement falls outside the range of $\\mu \\pm 3\\sigma$. This event triggers a rejection of the null hypothesis, $H_0$, which states that the instrument is functioning correctly and the measurement is a sample from the established normal distribution.\n\nCalculate the significance level, $\\alpha$, associated with this quality control rule. The significance level represents the probability of a Type I error, i.e., incorrectly concluding the instrument is out of control when it is actually functioning correctly.\n\nFor your calculation, you are given that for a standard normal variable $Z$, the cumulative probability $P(Z \\le 3)$ is exactly $0.99865$. Express your answer as a decimal rounded to three significant figures.", "solution": "Under the null hypothesis $H_{0}$, the single measurement $X$ is distributed as $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$. The quality control rule rejects $H_{0}$ if $X$ falls outside the interval $\\mu \\pm 3\\sigma$, i.e., if $X < \\mu - 3\\sigma$ or $X > \\mu + 3\\sigma$. The significance level $\\alpha$ is the probability of this rejection when $H_{0}$ is true:\n$$\n\\alpha = P\\left(X < \\mu - 3\\sigma \\text{ or } X > \\mu + 3\\sigma \\mid H_{0}\\right).\n$$\nStandardize using $Z = \\frac{X - \\mu}{\\sigma}$, for which $Z \\sim \\mathcal{N}(0,1)$. The rejection region becomes $Z < -3$ or $Z > 3$, hence\n$$\n\\alpha = P(Z < -3) + P(Z > 3).\n$$\nBy symmetry of the standard normal distribution,\n$$\nP(Z < -3) = P(Z > 3),\n$$\nso\n$$\n\\alpha = 2P(Z > 3) = 2\\left(1 - \\Phi(3)\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function. Given $P(Z \\le 3) = \\Phi(3) = 0.99865$, we have\n$$\n1 - \\Phi(3) = 1 - 0.99865 = 0.00135,\n$$\nand therefore\n$$\n\\alpha = 2 \\times 0.00135 = 0.00270.\n$$\nRounded to three significant figures, the significance level is $0.00270$.", "answer": "$$\\boxed{0.00270}$$", "id": "1446340"}, {"introduction": "A core task for an analytical chemist is method validation, which often involves comparing a new instrument against an established reference. When measurements can be collected in pairs under identical conditions, the paired t-test is a powerful tool to detect systematic differences. This hands-on practice [@problem_id:1446343] will guide you through the complete process: calculating differences from raw data, computing the test statistic, and making a statistically-sound conclusion about whether two instruments provide equivalent results.", "problem": "An environmental chemist is tasked with evaluating a new portable sensor (Instrument B) against a trusted, stationary reference instrument (Instrument A) for measuring atmospheric Carbon Monoxide (CO) concentration. To test for a systematic difference between the devices, the chemist takes a series of simultaneous measurements with both instruments at the same location over a period of several hours. The resulting data, measured in parts per million (ppm), are recorded as follows:\n\n| Measurement | Instrument A (ppm) | Instrument B (ppm) |\n|-------------|--------------------|--------------------|\n| 1           | 8.1                | 8.5                |\n| 2           | 7.5                | 7.8                |\n| 3           | 9.0                | 9.6                |\n| 4           | 8.4                | 8.9                |\n| 5           | 7.8                | 8.1                |\n| 6           | 8.8                | 9.2                |\n\nUsing the provided data, determine if there is a statistically significant systematic difference between the measurements from Instrument A and Instrument B at a significance level of $\\alpha = 0.05$. You are given that the critical t-value for a two-tailed test with 5 degrees of freedom at $\\alpha = 0.05$ is $t_{crit} = 2.571$. Which of the following statements is the correct conclusion?\n\nA. There is a statistically significant systematic difference between the two instruments.\n\nB. There is no statistically significant systematic difference between the two instruments.\n\nC. The data set is too small to perform a valid statistical test.\n\nD. Instrument B is less precise than Instrument A.\n\nE. Both instruments are malfunctioning as their readings differ.", "solution": "The problem asks us to determine if there is a statistically significant systematic difference between two sets of paired measurements. This requires a paired t-test.\n\nFirst, we define our null and alternative hypotheses.\nThe null hypothesis ($H_0$) states that there is no systematic difference between the instruments, meaning the true mean of the differences between paired measurements is zero.\n$H_0: \\mu_d = 0$\n\nThe alternative hypothesis ($H_a$) states that there is a systematic difference, meaning the true mean of the differences is not zero. This is a two-tailed test.\n$H_a: \\mu_d \\neq 0$\n\nThe significance level is given as $\\alpha = 0.05$.\n\nNext, we calculate the difference, $d_i$, for each pair of measurements, where $d_i = (\\text{Instrument B})_i - (\\text{Instrument A})_i$.\n$d_1 = 8.5 - 8.1 = 0.4$\n$d_2 = 7.8 - 7.5 = 0.3$\n$d_3 = 9.6 - 9.0 = 0.6$\n$d_4 = 8.9 - 8.4 = 0.5$\n$d_5 = 8.1 - 7.8 = 0.3$\n$d_6 = 9.2 - 8.8 = 0.4$\n\nThe set of differences is $d = \\{0.4, 0.3, 0.6, 0.5, 0.3, 0.4\\}$. The number of pairs is $n=6$.\n\nNow, we calculate the mean of these differences, $\\bar{d}$.\n$$ \\bar{d} = \\frac{\\sum_{i=1}^{n} d_i}{n} = \\frac{0.4 + 0.3 + 0.6 + 0.5 + 0.3 + 0.4}{6} = \\frac{2.5}{6} \\approx 0.4167 $$\n\nNext, we calculate the standard deviation of the differences, $s_d$.\n$$ s_d = \\sqrt{\\frac{\\sum_{i=1}^{n} (d_i - \\bar{d})^2}{n-1}} $$\nFirst, we find the squared deviations from the mean:\n$(0.4 - 2.5/6)^2 = (2.4/6 - 2.5/6)^2 = (-0.1/6)^2 \\approx 0.000277...$\n$(0.3 - 2.5/6)^2 = (1.8/6 - 2.5/6)^2 = (-0.7/6)^2 \\approx 0.013611...$\n$(0.6 - 2.5/6)^2 = (3.6/6 - 2.5/6)^2 = (1.1/6)^2 \\approx 0.033611...$\n$(0.5 - 2.5/6)^2 = (3.0/6 - 2.5/6)^2 = (0.5/6)^2 \\approx 0.006944...$\n$(0.3 - 2.5/6)^2 = (1.8/6 - 2.5/6)^2 = (-0.7/6)^2 \\approx 0.013611...$\n$(0.4 - 2.5/6)^2 = (2.4/6 - 2.5/6)^2 = (-0.1/6)^2 \\approx 0.000277...$\n\nThe sum of squared deviations is:\n$$ \\sum (d_i - \\bar{d})^2 \\approx 0.000277 + 0.013611 + 0.033611 + 0.006944 + 0.013611 + 0.000277 = 0.068331 $$\nLet's use fractions for precision: $\\bar{d} = 2.5/6 = 5/12$.\n$\\sum (d_i - \\bar{d})^2 = (0.4 - 5/12)^2 + 2(0.3 - 5/12)^2 + (0.6 - 5/12)^2 + ... = (4/10 - 5/12)^2 + ... $\nThis is getting complicated. Let's use the calculator formula for standard deviation:\n$s_d = \\sqrt{\\frac{n \\sum d_i^2 - (\\sum d_i)^2}{n(n-1)}}$\n$\\sum d_i = 2.5$\n$\\sum d_i^2 = 0.4^2 + 0.3^2 + 0.6^2 + 0.5^2 + 0.3^2 + 0.4^2 = 0.16 + 0.09 + 0.36 + 0.25 + 0.09 + 0.16 = 1.11$\nThe variance of the differences, $s_d^2$, is:\n$$ s_d^2 = \\frac{\\sum (d_i - \\bar{d})^2}{n-1} = \\frac{\\sum d_i^2 - (\\sum d_i)^2/n}{n-1} = \\frac{1.11 - (2.5)^2/6}{6-1} = \\frac{1.11 - 6.25/6}{5} = \\frac{1.11 - 1.041666...}{5} = \\frac{0.068333...}{5} = 0.013666... $$\nThe standard deviation of the differences is:\n$$ s_d = \\sqrt{0.013666...} \\approx 0.1169 $$\n\nNow we calculate the t-statistic, $t_{calc}$.\n$$ t_{calc} = \\frac{\\bar{d}}{s_d / \\sqrt{n}} = \\frac{0.4167}{0.1169 / \\sqrt{6}} = \\frac{0.4167}{0.1169 / 2.449} = \\frac{0.4167}{0.04773} \\approx 8.730 $$\n\nFinally, we compare the absolute value of our calculated t-statistic with the critical t-value provided. The degrees of freedom are $df = n-1 = 6-1=5$. The critical value for a two-tailed test at $\\alpha = 0.05$ with $df=5$ is given as $t_{crit} = 2.571$.\n$$ |t_{calc}| = 8.730 $$\nSince $|t_{calc}| > t_{crit}$ ($8.730 > 2.571$), we reject the null hypothesis $H_0$.\n\nRejecting the null hypothesis means we have sufficient statistical evidence to conclude that the true mean of the differences is not zero. Therefore, there is a statistically significant systematic difference between the measurements from Instrument A and Instrument B.\n\nLet's review the options:\nA. There is a statistically significant systematic difference between the two instruments. - This matches our conclusion.\nB. There is no statistically significant systematic difference between the two instruments. - This is incorrect; we rejected the null hypothesis.\nC. The data set is too small to perform a valid statistical test. - This is incorrect. A t-test is designed for small sample sizes, and a conclusion was reached.\nD. Instrument B is less precise than Instrument A. - The test is for systematic difference (accuracy/bias), not precision (random error/spread). The data provided is not structured to compare precision.\nE. Both instruments are malfunctioning as their readings differ. - A statistical difference does not automatically mean malfunction. It simply indicates a systematic bias. One instrument might be perfectly calibrated and the other slightly off, or both could be off.\n\nThus, the correct conclusion is A.", "answer": "$$\\boxed{A}$$", "id": "1446343"}, {"introduction": "Before investing time and resources into an experiment, it is critical to ensure the study is designed to succeed. A key part of this design is determining the necessary number of samples to achieve sufficient statistical powerâ€”the probability of correctly detecting an effect that truly exists. This problem [@problem_id:1446316] moves beyond analyzing existing data to the crucial step of experimental planning, showing you how to calculate the minimum sample size required to validate a new analytical method with confidence.", "problem": "An analytical chemistry lab is validating a new, high-throughput spectroscopic method for determining the concentration of a specific protein in a biopharmaceutical product. According to the certified reference material, the true concentration of the protein is $\\mu_0$. The new method is suspected of having a small, constant positive systematic bias. The lab wants to design an experiment to detect this bias.\n\nFrom previous validation studies, the analytical method is known to have a measurement variability that can be modeled by a normal distribution with a population standard deviation, $\\sigma$, that is $4.0\\%$ of the true concentration $\\mu_0$ (i.e., $\\sigma = 0.04 \\mu_0$).\n\nThe lab decides to perform a one-tailed hypothesis test at a significance level of $\\alpha = 0.05$. Their goal is to have a statistical power of at least $80\\%$ to correctly detect a situation where the new method's mean measurement, $\\mu_A$, is exactly $5.0\\%$ greater than the true value $\\mu_0$.\n\nAssume the following critical values for the standard normal distribution are sufficient for your calculation: $Z_{0.05} = 1.645$ and $Z_{0.20} = 0.842$.\n\nCalculate the minimum integer number of replicate measurements, $n$, that must be performed with the new method to meet these criteria.", "solution": "We test $H_{0}:\\mu=\\mu_{0}$ versus $H_{1}:\\mu>\\mu_{0}$ using a one-sample $z$-test with known population standard deviation $\\sigma$. For $n$ replicates, the sample mean $\\bar{X}$ satisfies $\\bar{X}\\sim N(\\mu,\\sigma^{2}/n)$. Using the conventional right-tail notation $Z_{\\gamma}$ defined by $P(Z>Z_{\\gamma})=\\gamma$ for $Z\\sim N(0,1)$, the rejection region at significance level $\\alpha$ is\n$$\n\\bar{X}>\\mu_{0}+Z_{\\alpha}\\frac{\\sigma}{\\sqrt{n}}.\n$$\nLet the effect size to be detected be $\\delta=\\mu_{A}-\\mu_{0}=0.05\\,\\mu_{0}$. The statistical power under $\\mu=\\mu_{A}$ is\n$$\n\\text{Power}=P\\!\\left(\\bar{X}>\\mu_{0}+Z_{\\alpha}\\frac{\\sigma}{\\sqrt{n}}\\,\\Big|\\,\\mu=\\mu_{A}\\right)\n= P\\!\\left(Z> Z_{\\alpha}-\\frac{\\delta\\sqrt{n}}{\\sigma}\\right),\n$$\nwhere $Z\\sim N(0,1)$. To achieve power $1-\\beta$, we require\n$$\nP\\!\\left(Z\\leq Z_{\\alpha}-\\frac{\\delta\\sqrt{n}}{\\sigma}\\right)=\\beta.\n$$\nWith $Z_{\\beta}$ defined by $P(Z>Z_{\\beta})=\\beta$, we have $\\Phi^{-1}(\\beta)=-Z_{\\beta}$, hence\n$$\nZ_{\\alpha}-\\frac{\\delta\\sqrt{n}}{\\sigma}=-Z_{\\beta}\n\\quad\\Longrightarrow\\quad\n\\frac{\\delta\\sqrt{n}}{\\sigma}=Z_{\\alpha}+Z_{\\beta}\n\\quad\\Longrightarrow\\quad\nn=\\left(\\frac{\\sigma}{\\delta}\\left(Z_{\\alpha}+Z_{\\beta}\\right)\\right)^{2}.\n$$\nSubstitute $\\sigma=0.04\\,\\mu_{0}$, $\\delta=0.05\\,\\mu_{0}$, $Z_{0.05}=1.645$, and $Z_{0.20}=0.842$ (with $\\alpha=0.05$ and $\\beta=0.20$ for power $0.80$):\n$$\n\\frac{\\sigma}{\\delta}=\\frac{0.04\\,\\mu_{0}}{0.05\\,\\mu_{0}}=0.8,\\qquad\nZ_{\\alpha}+Z_{\\beta}=1.645+0.842=2.487,\n$$\n$$\nn^{\\ast}=\\left(0.8\\times 2.487\\right)^{2}=\\left(1.9896\\right)^{2}\\approx 3.9585.\n$$\nTo ensure power at least $0.80$, take the smallest integer $n\\geq n^{\\ast}$, namely $n=4$.", "answer": "$$\\boxed{4}$$", "id": "1446316"}]}