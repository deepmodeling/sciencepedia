{"hands_on_practices": [{"introduction": "To truly understand the graph Laplacian, we must start with its construction from first principles. This foundational exercise guides you through the essential steps of building the adjacency, degree, and Laplacian matrices for a simple, undirected network. By then computing the full spectrum of eigenvalues for the Laplacian matrix [@problem_id:2710595], you'll gain direct insight into how the algebraic properties of this matrix reflect the topological structure of the graph, including the fundamental link between the number of zero eigenvalues and the number of connected components.", "problem": "In a continuous-time multi-agent consensus network with $N=4$ identical agents, the interaction topology is an undirected weighted graph with bidirectional couplings. The agents are labeled $1,2,3,4$, and the edges are $\\{(1,2),(2,3),(3,4),(4,1)\\}$, each with weight $1$. Using only the fundamental definitions of the adjacency matrix $A$, the degree matrix $D$, and the graph Laplacian $L$, proceed as follows:\n\n- Construct the adjacency matrix $A \\in \\mathbb{R}^{4 \\times 4}$, where $A_{ij}=A_{ji}$ equals the edge weight between nodes $i$ and $j$ for $i \\neq j$, and $A_{ii}=0$ for all $i$.\n- Construct the degree matrix $D \\in \\mathbb{R}^{4 \\times 4}$, where $D$ is diagonal with entries $D_{ii} = \\sum_{j=1}^{4} A_{ij}$.\n- Construct the Laplacian matrix $L \\in \\mathbb{R}^{4 \\times 4}$, defined by $L = D - A$.\n- Compute all eigenvalues of $L$ exactly and present them in nondecreasing order.\n\nExpress the final eigenvalues as exact numbers (no rounding). Your final answer must be a single row matrix containing the eigenvalues in nondecreasing order, with no units.", "solution": "The problem statement is subjected to validation before a solution is attempted.\n\n**Step 1: Extract Givens**\n- Number of agents: $N=4$.\n- Agent labels: $1,2,3,4$.\n- Topology: Undirected weighted graph.\n- Edges: $\\{(1,2),(2,3),(3,4),(4,1)\\}$.\n- Edge weights: All equal to $1$.\n- Adjacency matrix definition: $A \\in \\mathbb{R}^{4 \\times 4}$, with $A_{ij}=A_{ji}$ being the weight of the edge between nodes $i$ and $j$ for $i \\neq j$, and $A_{ii}=0$.\n- Degree matrix definition: $D \\in \\mathbb{R}^{4 \\times 4}$, a diagonal matrix with $D_{ii} = \\sum_{j=1}^{4} A_{ij}$.\n- Graph Laplacian definition: $L \\in \\mathbb{R}^{4 \\times 4}$, given by $L = D - A$.\n- Objective: Compute all eigenvalues of $L$ exactly and present them in nondecreasing order.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is well-grounded in graph theory and linear algebra, which are foundational disciplines for the study of multi-agent systems and control theory. The definitions of the adjacency, degree, and Laplacian matrices are standard.\n- **Well-Posedness**: The problem is well-posed. The graph is completely specified by its nodes, edges, and weights. The task of computing eigenvalues for a given matrix is a standard, solvable problem in linear algebra. Since the graph is undirected, the resulting Laplacian matrix $L$ is real and symmetric, which guarantees the existence of real eigenvalues.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective content.\n\n**Step 3: Verdict and Action**\n- **Verdict**: The problem is valid. It is scientifically sound, well-posed, objective, and complete.\n- **Action**: Proceed with the solution.\n\nThe following steps construct the required matrices and compute the eigenvalues of the graph Laplacian.\n\n**Construction of the Adjacency Matrix $A$**\nThe graph consists of $N=4$ nodes labeled $1, 2, 3, 4$. The edges are given as $\\{(1,2),(2,3),(3,4),(4,1)\\}$. Since the graph is undirected and all edge weights are $1$, the non-zero off-diagonal entries of the adjacency matrix $A$ are determined as follows:\n- Edge $(1,2) \\implies A_{12} = A_{21} = 1$.\n- Edge $(2,3) \\implies A_{23} = A_{32} = 1$.\n- Edge $(3,4) \\implies A_{34} = A_{43} = 1$.\n- Edge $(4,1) \\implies A_{41} = A_{14} = 1$.\nAll other off-diagonal entries are $0$. The diagonal entries $A_{ii}$ are all $0$.\nThe resulting adjacency matrix $A$ is:\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0\n\\end{pmatrix}\n$$\n\n**Construction of the Degree Matrix $D$**\nThe degree matrix $D$ is a diagonal matrix where each diagonal entry $D_{ii}$ is the degree of node $i$, calculated as the sum of the entries in the $i$-th row of $A$.\n- $D_{11} = \\sum_{j=1}^{4} A_{1j} = 0+1+0+1 = 2$.\n- $D_{22} = \\sum_{j=1}^{4} A_{2j} = 1+0+1+0 = 2$.\n- $D_{33} = \\sum_{j=1}^{4} A_{3j} = 0+1+0+1 = 2$.\n- $D_{44} = \\sum_{j=1}^{4} A_{4j} = 1+0+1+0 = 2$.\nThe graph is 2-regular. The degree matrix $D$ is:\n$$\nD = \\begin{pmatrix}\n2 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n0 & 0 & 2 & 0 \\\\\n0 & 0 & 0 & 2\n\\end{pmatrix}\n$$\n\n**Construction of the Laplacian Matrix $L$**\nThe graph Laplacian $L$ is defined as $L = D - A$.\n$$\nL = \\begin{pmatrix}\n2 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n0 & 0 & 2 & 0 \\\\\n0 & 0 & 0 & 2\n\\end{pmatrix} - \\begin{pmatrix}\n0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0\n\\end{pmatrix} = \\begin{pmatrix}\n2 & -1 & 0 & -1 \\\\\n-1 & 2 & -1 & 0 \\\\\n0 & -1 & 2 & -1 \\\\\n-1 & 0 & -1 & 2\n\\end{pmatrix}\n$$\n\n**Computation of the Eigenvalues of $L$**\nThe eigenvalues $\\lambda$ of $L$ are the roots of the characteristic equation $\\det(L - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix}\n2-\\lambda & -1 & 0 & -1 \\\\\n-1 & 2-\\lambda & -1 & 0 \\\\\n0 & -1 & 2-\\lambda & -1 \\\\\n-1 & 0 & -1 & 2-\\lambda\n\\end{pmatrix} = 0\n$$\nLet $x = 2-\\lambda$. The characteristic determinant is:\n$$\n\\det \\begin{pmatrix}\nx & -1 & 0 & -1 \\\\\n-1 & x & -1 & 0 \\\\\n0 & -1 & x & -1 \\\\\n-1 & 0 & -1 & x\n\\end{pmatrix}\n$$\nWe compute the determinant using cofactor expansion along the first row:\n$$\n\\text{det} = x \\begin{vmatrix}\nx & -1 & 0 \\\\\n-1 & x & -1 \\\\\n0 & -1 & x\n\\end{vmatrix} - (-1) \\begin{vmatrix}\n-1 & -1 & 0 \\\\\n0 & x & -1 \\\\\n-1 & -1 & x\n\\end{vmatrix} + 0 - (-1) \\begin{vmatrix}\n-1 & x & -1 \\\\\n0 & -1 & x \\\\\n-1 & 0 & -1\n\\end{vmatrix}\n$$\nThe minors are evaluated as:\n- $\\begin{vmatrix}\nx & -1 & 0 \\\\\n-1 & x & -1 \\\\\n0 & -1 & x\n\\end{vmatrix} = x(x^2 - 1) - (-1)(-x) = x^3 - x - x = x^3 - 2x$.\n- $\\begin{vmatrix}\n-1 & -1 & 0 \\\\\n0 & x & -1 \\\\\n-1 & -1 & x\n\\end{vmatrix} = -1(x^2 - 1) - (-1)(0 - 1) = -x^2 + 1 - 1 = -x^2$.\n- $\\begin{vmatrix}\n-1 & x & -1 \\\\\n0 & -1 & x \\\\\n-1 & 0 & -1\n\\end{vmatrix} = -1(1 - 0) - x(0 - (-x)) + (-1)(0 - 1) = -1 - x^2 + 1 = -x^2$.\n\nSubstituting these back into the determinant expression:\n$$\n\\text{det} = x(x^3 - 2x) + (-x^2) + (-x^2) = x^4 - 2x^2 - 2x^2 = x^4 - 4x^2\n$$\nThe characteristic equation is $x^4 - 4x^2 = 0$, which can be factored as $x^2(x^2 - 4) = 0$, or $x^2(x-2)(x+2) = 0$.\nThe roots for $x$ are $x = 0$ (with multiplicity $2$), $x=2$, and $x=-2$.\n\nWe now find the eigenvalues $\\lambda$ by substituting back $x = 2-\\lambda$:\n- For $x=0$: $2-\\lambda = 0 \\implies \\lambda = 2$. This eigenvalue has a multiplicity of $2$.\n- For $x=2$: $2-\\lambda = 2 \\implies \\lambda = 0$.\n- For $x=-2$: $2-\\lambda = -2 \\implies \\lambda = 4$.\n\nThe eigenvalues of the Laplacian matrix $L$ are $\\{0, 2, 2, 4\\}$. Arranging them in nondecreasing order gives $0, 2, 2, 4$.\nThe smallest eigenvalue is $\\lambda_1 = 0$, which is expected for any connected undirected graph, and its multiplicity is equal to the number of connected components (here, one). The second smallest eigenvalue, $\\lambda_2=2$, is the algebraic connectivity of the graph.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 2 & 2 & 4\n\\end{pmatrix}\n}\n$$", "id": "2710595"}, {"introduction": "Beyond simply calculating eigenvalues, their true power lies in their application. This practice focuses on the algebraic connectivity, $\\lambda_2$, and its associated eigenvector, the Fiedler vector, which acts as a powerful tool for network analysis. You will implement a spectral partitioning algorithm [@problem_id:2710619] to discover that the signs of the Fiedler vector's components can effectively bisect a graph along its weakest connections, a technique that forms the basis of many modern community detection and data clustering algorithms.", "problem": "You are given a set of small undirected weighted graphs. For each graph, do the following in order: construct its combinatorial graph Laplacian, compute a Fiedler vector numerically, use the entries of the Fiedler vector to propose a binary partition by a zero-threshold rule, and compute the resulting cut weight across that partition. The task must be solved from first principles of spectral graph theory.\n\nUse the following fundamental definitions as your base:\n- For an undirected weighted graph with $n$ vertices and symmetric, nonnegative adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$, the degree matrix $D \\in \\mathbb{R}^{n \\times n}$ is the diagonal matrix with $D_{ii} = \\sum_{j=1}^{n} A_{ij}$. The combinatorial graph Laplacian is $L = D - A$.\n- The algebraic connectivity is the second-smallest eigenvalue of $L$. A corresponding eigenvector is called a Fiedler vector. Equivalently, a Fiedler vector is any minimizer of the Rayleigh quotient $x^\\top L x$ over all $x \\in \\mathbb{R}^n$ such that $x^\\top \\mathbf{1} = 0$ and $\\|x\\|_2 = 1$, where $\\mathbf{1}$ is the all-ones vector.\n- Given a Fiedler vector $v \\in \\mathbb{R}^n$, propose a partition $\\{S, \\bar S\\}$ of the node set by the zero-threshold rule: $S = \\{ i \\in \\{1,\\dots,n\\} \\mid v_i \\ge 0 \\}$ and $\\bar S = \\{ i \\in \\{1,\\dots,n\\} \\mid v_i < 0 \\}$.\n- The cut weight between $S$ and $\\bar S$ is $\\mathrm{cut}(S,\\bar S) = \\sum_{i \\in S} \\sum_{j \\in \\bar S} A_{ij}$.\n\nYour program must:\n- For each specified test graph, construct $L$, compute a Fiedler vector numerically, form $\\{S,\\bar S\\}$ using the zero-threshold rule, and output the resulting cut weight as a floating-point number rounded to $6$ decimal places.\n\nImportant implementation details:\n- All eigen-computations must be performed on the symmetric real Laplacian $L$.\n- Select the Fiedler vector as an eigenvector associated with the second-smallest eigenvalue of $L$.\n- The partition must strictly follow the rule $v_i \\ge 0$ goes to $S$ and $v_i < 0$ goes to $\\bar S$.\n- The cut weight for an undirected graph must count each undirected edge exactly once.\n\nTest suite:\n- Case $1$ ($n = 6$): Two unit-weight triangles weakly connected. Nonzero symmetric adjacency entries $A_{12} = A_{21} = 1$, $A_{23} = A_{32} = 1$, $A_{13} = A_{31} = 1$, $A_{45} = A_{54} = 1$, $A_{56} = A_{65} = 1$, $A_{46} = A_{64} = 1$, and a single weak inter-cluster edge $A_{34} = A_{43} = 0.2$. All other entries are $0$.\n- Case $2$ ($n = 4$): A weighted chain with a weak middle link. Nonzero symmetric adjacency entries $A_{12} = A_{21} = 2$, $A_{23} = A_{32} = 0.1$, $A_{34} = A_{43} = 2$. All other entries are $0$.\n- Case $3$ ($n = 5$): A lollipop-like graph. Nonzero symmetric adjacency entries $A_{12} = A_{21} = 1$, $A_{23} = A_{32} = 1$, $A_{13} = A_{31} = 1$, $A_{34} = A_{43} = 0.4$, $A_{45} = A_{54} = 0.4$. All other entries are $0$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the above test cases, with each cut weight rounded to $6$ decimal places. For example: \"[x1,x2,x3]\". No spaces are permitted in the output string.\n\nNo physical quantities or angles are involved, so no unit specification is required. Ensure numerical stability and determinism by following the partition rule as stated and using a standard symmetric eigensolver.", "solution": "The problem statement has been subjected to rigorous validation and is deemed valid. It is scientifically grounded, well-posed, and objective. The problem is based entirely on established, formal definitions from spectral graph theory within the field of control theory and applied mathematics. It provides all necessary data for the construction of the adjacency matrices, and the subsequent computational tasks are unambiguous. The procedure specified is deterministic and leads to a unique, verifiable result for each test case, contingent on the output of a standard numerical eigensolver.\n\nWe shall now proceed with the solution, following the prescribed methodology from first principles.\n\nThe core task is to analyze a given undirected weighted graph $G = (V, E, w)$, where $V$ is the set of $n$ vertices, $E$ is the set of edges, and $w$ is the weight function. The graph is represented by its symmetric adjacency matrix $A$, where $A_{ij} = w(i, j) > 0$ if an edge exists between vertices $i$ and $j$, and $A_{ij} = 0$ otherwise.\n\nThe procedure for each graph is as follows:\n\n1.  **Construct the Graph Laplacian**:\n    The degree of a vertex $i$ is $d_i = \\sum_{j=1}^{n} A_{ij}$. The degree matrix $D$ is a diagonal matrix with $D_{ii} = d_i$. The combinatorial graph Laplacian, $L$, is defined as:\n    $$L = D - A$$\n    This matrix is real, symmetric, and positive semi-definite. For a connected graph with $n$ vertices, its eigenvalues $0 = \\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_n$ have the property that $\\lambda_2 > 0$.\n\n2.  **Compute the Fiedler Vector**:\n    The second-smallest eigenvalue of $L$, denoted $\\lambda_2$, is the algebraic connectivity of the graph. Any eigenvector $v_2$ corresponding to $\\lambda_2$ is a Fiedler vector. We compute the complete eigenspectrum of the symmetric matrix $L$ numerically. Since $L$ is real and symmetric, its eigenvalues are real and its eigenvectors form an orthonormal basis. We use a numerical routine equivalent to `numpy.linalg.eigh`, which returns eigenvalues in ascending order. The Fiedler vector is the eigenvector corresponding to the second eigenvalue in this sorted list.\n\n3.  **Propose a Binary Partition**:\n    Given the Fiedler vector $v_2 \\in \\mathbb{R}^n$, we partition the vertex set $V$ into two disjoint subsets, $S$ and $\\bar{S}$, based on a zero-threshold rule applied to the components of $v_2$.\n    $$S = \\{ i \\in V \\mid (v_2)_i \\ge 0 \\}$$\n    $$\\bar{S} = \\{ i \\in V \\mid (v_2)_i < 0 \\}$$\n    The set of vertices is partitioned as $V = S \\cup \\bar{S}$.\n\n4.  **Compute the Cut Weight**:\n    The quality of this partition is assessed by the weight of the cut, which is the sum of weights of all edges connecting a vertex in $S$ to a vertex in $\\bar{S}$.\n    $$\\mathrm{cut}(S, \\bar{S}) = \\sum_{i \\in S} \\sum_{j \\in \\bar{S}} A_{ij}$$\n    For an undirected graph, this sum counts each inter-partition edge exactly once due to the structure of the summation over disjoint sets of vertices.\n\nWe now apply this four-step procedure to each test case provided. The vertices are indexed starting from $1$ in the problem description, which we map to $0$-based indices for matrix representation (i.e., vertex $k$ corresponds to index $k-1$).\n\n**Case 1: Two weakly connected triangles ($n=6$)**\nThe non-zero adjacency matrix entries are $A_{12}=1$, $A_{23}=1$, $A_{13}=1$, $A_{45}=1$, $A_{56}=1$, $A_{46}=1$, and $A_{34}=0.2$.\nUsing $0$-based indices, the adjacency matrix $A^{(1)}$ is:\n$$A^{(1)} = \\begin{pmatrix}\n0 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0.2 & 0 & 0 \\\\\n0 & 0 & 0.2 & 0 & 1 & 1 \\\\\n0 & 0 & 0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 1 & 1 & 0\n\\end{pmatrix}$$\nThe degree matrix $D^{(1)}$ is the diagonal matrix of row sums of $A^{(1)}$:\n$$D^{(1)} = \\mathrm{diag}(2, 2, 2.2, 2.2, 2, 2)$$\nThe Laplacian is $L^{(1)} = D^{(1)} - A^{(1)}$. We compute a Fiedler vector $v_2^{(1)}$ of $L^{(1)}$. The signs of the components of $v_2^{(1)}$ are expected to separate the two triangular clusters. A numerical computation yields a Fiedler vector that partitions the vertices into sets $S=\\{1, 2, 3\\}$ and $\\bar{S}=\\{4, 5, 6\\}$ (or vice versa, which is equivalent for the cut weight). The cut weight is the sum of weights of edges between these two sets. The only such edge is $(3, 4)$ with weight $A_{34}=0.2$.\n$$\\mathrm{cut}(S, \\bar{S}) = A_{34}^{(1)} = 0.2$$\n\n**Case 2: Weighted chain with a weak link ($n=4$)**\nThe non-zero adjacency matrix entries are $A_{12}=2$, $A_{23}=0.1$, and $A_{34}=2$.\nThe adjacency matrix $A^{(2)}$ is:\n$$A^{(2)} = \\begin{pmatrix}\n0 & 2 & 0 & 0 \\\\\n2 & 0 & 0.1 & 0 \\\\\n0 & 0.1 & 0 & 2 \\\\\n0 & 0 & 2 & 0\n\\end{pmatrix}$$\nThe degree matrix $D^{(2)}$ is:\n$$D^{(2)} = \\mathrm{diag}(2, 2.1, 2.1, 2)$$\nThe Laplacian is $L^{(2)} = D^{(2)} - A^{(2)}$. The Fiedler vector for this chain-like graph with a weak central link is expected to partition the graph across this link. The partition will be $S=\\{1, 2\\}$ and $\\bar{S}=\\{3, 4\\}$. The cut weight is determined by the single edge $(2, 3)$ connecting these sets.\n$$\\mathrm{cut}(S, \\bar{S}) = A_{23}^{(2)} = 0.1$$\n\n**Case 3: Lollipop-like graph ($n=5$)**\nThe non-zero adjacency matrix entries are $A_{12}=1$, $A_{23}=1$, $A_{13}=1$, $A_{34}=0.4$, and $A_{45}=0.4$. This structure consists of a triangle $\\{1, 2, 3\\}$ and a path $\\{3, 4, 5\\}$ attached at vertex $3$.\nThe adjacency matrix $A^{(3)}$ is:\n$$A^{(3)} = \\begin{pmatrix}\n0 & 1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0.4 & 0 \\\\\n0 & 0 & 0.4 & 0 & 0.4 \\\\\n0 & 0 & 0 & 0.4 & 0\n\\end{pmatrix}$$\nThe degree matrix $D^{(3)}$ is:\n$$D^{(3)} = \\mathrm{diag}(2, 2, 2.4, 0.8, 0.4)$$\nThe Laplacian is $L^{(3)} = D^{(3)} - A^{(3)}$. The weakest connection in this graph is the edge $(3, 4)$ which links the dense triangle subgraph to the sparser path subgraph. The Fiedler vector is expected to induce a partition separating these substructures. The most probable partition is $S=\\{1, 2, 3\\}$ and $\\bar{S}=\\{4, 5\\}$. The cut weight is determined by the single edge $(3, 4)$ connecting the two sets.\n$$\\mathrm{cut}(S, \\bar{S}) = A_{34}^{(3)} = 0.4$$\n\nThe numerical implementation will execute these steps precisely as described to obtain the final values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the spectral graph partitioning problem for a given test suite.\n    For each graph, it computes the combinatorial Laplacian, finds a Fiedler\n    vector, partitions the graph using a zero-threshold rule, and calculates\n    the resulting cut weight.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Adjacency matrices are constructed using 0-based indexing from the\n    # 1-based problem description.\n\n    # Case 1 (n=6): Two unit-weight triangles weakly connected.\n    A1 = np.zeros((6, 6))\n    A1[0, 1] = A1[1, 0] = 1.0\n    A1[1, 2] = A1[2, 1] = 1.0\n    A1[0, 2] = A1[2, 0] = 1.0\n    A1[3, 4] = A1[4, 3] = 1.0\n    A1[4, 5] = A1[5, 4] = 1.0\n    A1[3, 5] = A1[5, 3] = 1.0\n    A1[2, 3] = A1[3, 2] = 0.2\n\n    # Case 2 (n=4): A weighted chain with a weak middle link.\n    A2 = np.zeros((4, 4))\n    A2[0, 1] = A2[1, 0] = 2.0\n    A2[1, 2] = A2[2, 1] = 0.1\n    A2[2, 3] = A2[3, 2] = 2.0\n\n    # Case 3 (n=5): A lollipop-like graph.\n    A3 = np.zeros((5, 5))\n    A3[0, 1] = A3[1, 0] = 1.0\n    A3[1, 2] = A3[2, 1] = 1.0\n    A3[0, 2] = A3[2, 0] = 1.0\n    A3[2, 3] = A3[3, 2] = 0.4\n    A3[3, 4] = A3[4, 3] = 0.4\n\n    test_cases = [A1, A2, A3]\n    results = []\n\n    for A in test_cases:\n        # Step 1: Construct the combinatorial graph Laplacian L = D - A.\n        # Degree matrix D\n        D = np.diag(np.sum(A, axis=1))\n        # Laplacian L\n        L = D - A\n\n        # Step 2: Compute a Fiedler vector numerically.\n        # np.linalg.eigh computes eigenvalues and eigenvectors for a symmetric matrix.\n        # It conveniently returns eigenvalues in ascending order.\n        eigenvalues, eigenvectors = np.linalg.eigh(L)\n        \n        # The Fiedler vector corresponds to the second-smallest eigenvalue.\n        # Eigenvalues are sorted, so the second one is at index 1.\n        fiedler_vector = eigenvectors[:, 1]\n\n        # Step 3: Propose a binary partition using the zero-threshold rule.\n        # S = {i | v_i >= 0}, S_bar = {i | v_i < 0}\n        n = A.shape[0]\n        S = {i for i in range(n) if fiedler_vector[i] >= 0}\n        S_bar = {i for i in range(n) if fiedler_vector[i] < 0}\n\n        # Step 4: Compute the resulting cut weight.\n        # cut(S, S_bar) = sum_{i in S, j in S_bar} A_ij\n        cut_weight = 0.0\n        for i in S:\n            for j in S_bar:\n                cut_weight += A[i, j]\n                \n        # Round the result to 6 decimal places.\n        results.append(f\"{cut_weight:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2710619"}, {"introduction": "While many foundational results apply to undirected graphs where interactions are symmetric, numerous real-world multi-agent systems feature directed information flow. This exercise extends our analysis to such directed graphs, or digraphs, where the Laplacian matrix loses its symmetry. You will explore the properties of the left eigenvector associated with the zero eigenvalue [@problem_id:2710584], uncovering its profound connection to the stationary distribution of a random walk on the graph, which is a critical concept for understanding consensus and influence in complex, asymmetric networks.", "problem": "Consider a directed, weighted network of agents modeled by a digraph with weighted adjacency matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0 & 1 & 0 & 2\\\\\n1 & 0 & 2 & 0\\\\\n3 & 0 & 0 & 1\\\\\n0 & 1 & 1 & 0\n\\end{pmatrix}.\n$$\nLet the out-degree matrix be defined by $D_{\\mathrm{out}} \\coloneqq \\mathrm{diag}(d_{1}^{\\mathrm{out}},\\dots,d_{4}^{\\mathrm{out}})$ with $d_{i}^{\\mathrm{out}} \\coloneqq \\sum_{j=1}^{4} A_{ij}$, and let the (out-degree) graph Laplacian be $L \\coloneqq D_{\\mathrm{out}} - A$. This digraph is strongly connected and not weight-balanced. Starting only from core definitions (weighted adjacency, out-degree, Laplacian, and the notion of strong connectivity) and well-tested facts (existence and uniqueness properties that follow from the Perronâ€“Frobenius theorem for nonnegative, irreducible matrices), do the following:\n- Derive why there exists a strictly positive vector $\\pi \\in \\mathbb{R}^{4}$, unique up to scaling, satisfying the left-kernel condition $\\pi^{\\top} L = 0$.\n- Determine the unique normalization $\\pi^{\\top} \\mathbf{1} = 1$, where $\\mathbf{1} \\in \\mathbb{R}^{4}$ is the all-ones vector, and compute the resulting $\\pi$ explicitly for the given $A$.\n- Explain how $\\pi$ can be interpreted as a stationary distribution of an associated discrete-time random walk on the digraph built from $A$.\n\nProvide only the final value of the normalized $\\pi$ as your answer, expressed as a $1 \\times 4$ row vector. No rounding is required and no units are involved.", "solution": "The problem statement is subjected to a rigorous validation process before a solution is attempted.\n\nFirst, the givens are extracted verbatim:\n- A directed, weighted network is described by the weighted adjacency matrix $A = \\begin{pmatrix} 0 & 1 & 0 & 2\\\\ 1 & 0 & 2 & 0\\\\ 3 & 0 & 0 & 1\\\\ 0 & 1 & 1 & 0 \\end{pmatrix}$.\n- The out-degree matrix is $D_{\\mathrm{out}} \\coloneqq \\mathrm{diag}(d_{1}^{\\mathrm{out}},\\dots,d_{4}^{\\mathrm{out}})$ with $d_{i}^{\\mathrm{out}} \\coloneqq \\sum_{j=1}^{4} A_{ij}$.\n- The graph Laplacian is $L \\coloneqq D_{\\mathrm{out}} - A$.\n- The digraph is stated to be strongly connected and not weight-balanced.\n- A strictly positive vector $\\pi \\in \\mathbb{R}^{4}$ is defined by $\\pi^{\\top} L = 0$, unique up to scaling.\n- A unique normalization is specified: $\\pi^{\\top} \\mathbf{1} = 1$, where $\\mathbf{1}$ is the all-ones vector.\n- The required derivation must use core definitions and facts related to the Perron-Frobenius theorem for nonnegative, irreducible matrices.\n- An interpretation of $\\pi$ as a stationary distribution of an associated random walk is required.\n\nSecond, these givens are validated for soundness, completeness, and objectivity. The definitions for $A$, $D_{\\mathrm{out}}$, and $L$ are standard in algebraic graph theory. The claim of strong connectivity is verifiable by inspecting the graph structure defined by $A$; paths exist from any node to any other node. For example, $1 \\to 2 \\to 3 \\to 4 \\to 2 \\to 1$. The claim of not being weight-balanced is also verifiable by comparing the out-degrees $d^{\\mathrm{out}} = (3, 3, 4, 2)^{\\top}$ with the in-degrees $d^{\\mathrm{in}} = (4, 2, 3, 3)^{\\top}$. The problem is mathematically well-posed, grounded in established theory, and free of ambiguity or contradiction.\n\nThe verdict is that the problem is valid. We now proceed to the solution.\n\nThe task is addressed in three parts: derivation, computation, and interpretation.\n\nFirst, we derive the existence, uniqueness, and positivity of the vector $\\pi$. The condition is $\\pi^{\\top} L = 0$. Substituting the definition $L \\coloneqq D_{\\mathrm{out}} - A$, we obtain $\\pi^{\\top} (D_{\\mathrm{out}} - A) = 0$, which is equivalent to the equation $\\pi^{\\top} A = \\pi^{\\top} D_{\\mathrm{out}}$.\nTo relate this to a standard Perron-Frobenius problem, consider the matrix $P \\coloneqq (D_{\\mathrm{out}})^{-1} A$. Since the digraph is strongly connected, every out-degree $d_i^{\\mathrm{out}} = \\sum_j A_{ij}$ is positive, so $D_{\\mathrm{out}}$ is invertible. The entries of $P$ are $P_{ij} = A_{ij}/d_i^{\\mathrm{out}}$.\nThe matrix $P$ is a row-stochastic matrix, because the sum of entries in any row $i$ is $\\sum_j P_{ij} = \\frac{1}{d_i^{\\mathrm{out}}} \\sum_j A_{ij} = \\frac{d_i^{\\mathrm{out}}}{d_i^{\\mathrm{out}}} = 1$.\nFurthermore, because the graph is strongly connected, the matrix $P$ is irreducible.\nThe Perron-Frobenius theorem for irreducible row-stochastic matrices states that $\\lambda=1$ is a simple eigenvalue of $P$, and there exists a unique left eigenvector $p^{\\top}$ corresponding to this eigenvalue that is strictly positive and can be normalized such that its components sum to one ($p^{\\top}\\mathbf{1}=1$). This vector $p^{\\top}$ is the stationary distribution of the random walk defined by transition matrix $P$.\nThis eigenvector equation is $p^{\\top} P = p^{\\top}$, or $p^{\\top} (D_{\\mathrm{out}})^{-1} A = p^{\\top}$.\nNow, let us define a vector $\\pi^{\\top}$ as $\\pi^{\\top} \\coloneqq c \\cdot p^{\\top} (D_{\\mathrm{out}})^{-1}$ for some scaling constant $c$. Since $p$ is positive and the entries of $(D_{\\mathrm{out}})^{-1}$ are positive, $\\pi$ is also a positive vector.\nFrom this definition, we have $p^{\\top} = \\frac{1}{c} \\pi^{\\top} D_{\\mathrm{out}}$. Substituting this back into the eigenvector equation gives:\n$$(\\frac{1}{c} \\pi^{\\top} D_{\\mathrm{out}}) (D_{\\mathrm{out}})^{-1} A = \\frac{1}{c} \\pi^{\\top} D_{\\mathrm{out}}$$\n$$\\pi^{\\top} A = \\pi^{\\top} D_{\\mathrm{out}}$$\nThis is equivalent to $\\pi^{\\top} (D_{\\mathrm{out}} - A) = 0$, which is $\\pi^{\\top} L = 0$.\nThe uniqueness of $p^{\\top}$ up to scaling implies the uniqueness of $\\pi^{\\top}$ up to scaling. This completes the derivation of the existence and uniqueness of a strictly positive vector $\\pi$ satisfying the condition.\n\nSecond, we compute the specific vector $\\pi$ for the given matrix $A$.\nThe adjacency matrix is $A = \\begin{pmatrix} 0 & 1 & 0 & 2\\\\ 1 & 0 & 2 & 0\\\\ 3 & 0 & 0 & 1\\\\ 0 & 1 & 1 & 0 \\end{pmatrix}$.\nThe out-degrees are $d_{1}^{\\mathrm{out}}=1+2=3$, $d_{2}^{\\mathrm{out}}=1+2=3$, $d_{3}^{\\mathrm{out}}=3+1=4$, and $d_{4}^{\\mathrm{out}}=1+1=2$.\nThe out-degree matrix is $D_{\\mathrm{out}} = \\mathrm{diag}(3, 3, 4, 2)$.\nThe Laplacian is $L = D_{\\mathrm{out}} - A = \\begin{pmatrix} 3 & -1 & 0 & -2 \\\\ -1 & 3 & -2 & 0 \\\\ -3 & 0 & 4 & -1 \\\\ 0 & -1 & -1 & 2 \\end{pmatrix}$.\nWe need to solve $\\pi^{\\top} L = 0$ for $\\pi^{\\top} = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$. This is equivalent to solving $L^\\top \\pi = 0$. The system of linear equations is:\n1. $3\\pi_1 - \\pi_2 - 3\\pi_3 = 0$\n2. $-\\pi_1 + 3\\pi_2 - \\pi_4 = 0$\n3. $-2\\pi_2 + 4\\pi_3 - \\pi_4 = 0$\n4. $-2\\pi_1 - \\pi_3 + 2\\pi_4 = 0$\nFrom (2), $\\pi_4 = -\\pi_1 + 3\\pi_2$.\nSubstitute into (3): $-2\\pi_2 + 4\\pi_3 - (-\\pi_1 + 3\\pi_2) = 0 \\implies \\pi_1 - 5\\pi_2 + 4\\pi_3 = 0$.\nSubstitute into (4): $-2\\pi_1 - \\pi_3 + 2(-\\pi_1 + 3\\pi_2) = 0 \\implies -4\\pi_1 + 6\\pi_2 - \\pi_3 = 0 \\implies \\pi_3 = -4\\pi_1 + 6\\pi_2$.\nSubstitute $\\pi_3$ into the equation $\\pi_1 - 5\\pi_2 + 4\\pi_3 = 0$:\n$\\pi_1 - 5\\pi_2 + 4(-4\\pi_1 + 6\\pi_2) = 0 \\implies \\pi_1 - 5\\pi_2 - 16\\pi_1 + 24\\pi_2 = 0 \\implies -15\\pi_1 + 19\\pi_2 = 0 \\implies 19\\pi_2 = 15\\pi_1$.\nWe can choose a solution proportional to this, e.g., $\\pi_1=19, \\pi_2=15$.\nThen, $\\pi_3 = -4(19) + 6(15) = -76 + 90 = 14$.\nAnd $\\pi_4 = -19 + 3(15) = -19 + 45 = 26$.\nAn unnormalized solution is thus proportional to the vector $(19, 15, 14, 26)$.\nWe apply the normalization $\\pi^{\\top}\\mathbf{1} = 1$, which means the sum of the components must be $1$.\nThe sum is $S = 19+15+14+26 = 74$.\nThe normalized vector $\\pi$ is therefore $\\pi = \\frac{1}{74} (19, 15, 14, 26)^{\\top}$.\nThe corresponding row vector is $\\pi^{\\top} = (\\frac{19}{74}, \\frac{15}{74}, \\frac{14}{74}, \\frac{26}{74})$.\n\nThird, we explain the interpretation of $\\pi$ as a stationary distribution.\nThe problem asks for an associated discrete-time random walk for which the normalized $\\pi$ is the stationary distribution.\nConsider a process defined by the transition matrix $P_{\\epsilon} \\coloneqq I - \\epsilon L$, where $I$ is the $4 \\times 4$ identity matrix and $\\epsilon$ is a small positive constant.\nFor $P_{\\epsilon}$ to be a valid stochastic matrix, its rows must sum to $1$ and all its entries must be non-negative.\nThe sum of row $i$ is $\\sum_{j} (P_{\\epsilon})_{ij} = \\sum_{j} (\\delta_{ij} - \\epsilon L_{ij}) = 1 - \\epsilon \\sum_{j} L_{ij}$. Since the rows of the out-degree Laplacian $L$ sum to zero by construction ($\\sum_j L_{ij} = d_i^{\\mathrm{out}} - \\sum_j A_{ij} = 0$), the rows of $P_{\\epsilon}$ sum to $1$.\nFor non-negativity, off-diagonal entries $(P_{\\epsilon})_{ij} = -\\epsilon L_{ij} = \\epsilon A_{ij}$ must be non-negative. Since $\\epsilon > 0$ and $A_{ij} \\ge 0$, this is satisfied. The diagonal entries $(P_{\\epsilon})_{ii} = 1 - \\epsilon L_{ii} = 1 - \\epsilon d_i^{\\mathrm{out}}$ must be non-negative. This requires $\\epsilon \\le 1/d_i^{\\mathrm{out}}$ for all $i$. So, we must choose $\\epsilon \\in (0, 1/\\max_i(d_i^{\\mathrm{out}})]$. With this choice, $P_{\\epsilon}$ is a valid row-stochastic matrix.\nA stationary distribution $p^{\\top}$ for this random walk satisfies the equation $p^{\\top} P_{\\epsilon} = p^{\\top}$.\nLet's check if our normalized vector $\\pi^{\\top}$ satisfies this.\n$\\pi^{\\top} P_{\\epsilon} = \\pi^{\\top}(I-\\epsilon L) = \\pi^{\\top} I - \\epsilon (\\pi^{\\top} L)$.\nFrom the initial definition, we have $\\pi^{\\top}L = 0$.\nTherefore, $\\pi^{\\top} P_{\\epsilon} = \\pi^{\\top} - \\epsilon \\cdot 0 = \\pi^{\\top}$.\nThis confirms that the vector $\\pi$ (when normalized to sum to $1$) is indeed the unique stationary distribution of the random walk governed by the transition matrix $P_{\\epsilon} = I - \\epsilon L$. This process is known as a \"lazy random walk\", where at each step an agent at node $i$ either stays put with probability $1 - \\epsilon d_i^{\\mathrm{out}}$ or moves to a neighbor $j$ with probability $\\epsilon A_{ij}$.\n\nThe final answer required is the explicitly computed normalized vector $\\pi$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{19}{74} & \\frac{15}{74} & \\frac{14}{74} & \\frac{26}{74} \\end{pmatrix}\n}\n$$", "id": "2710584"}]}