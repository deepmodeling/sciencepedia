{"hands_on_practices": [{"introduction": "The \"predictive\" in Model Predictive Control is where we begin. Before we can optimize, we must be able to forecast how a system will evolve based on our actions. This fundamental exercise tasks you with deriving the prediction equations for a linear system from the ground up, using only the basic state-update law. This hands-on derivation solidifies your understanding of how future states depend on the present state and future control inputs, which is the cornerstone upon which the entire MPC framework is built [@problem_id:2884328].", "problem": "In the context of designing a finite-horizon Model Predictive Control (MPC) law for a discrete-time, linear time-invariant state-space model arising from signal processing and systems modeling, consider the state-update equation given by the fundamental state-evolution law\n$$x_{k+1}=A x_{k} + B u_{k},$$\nwhere the state is $x_{k} \\in \\mathbb{R}^{2}$ and the control input is $u_{k} \\in \\mathbb{R}$. The prediction model used in MPC is obtained by repeatedly applying this fundamental law forward in time from the current measured state $x_{0}$. You are given\n$$A=\\begin{bmatrix}0.9 & 0 \\\\ 0.1 & 0.95\\end{bmatrix}, \\quad B=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}.$$\nUsing only the fundamental recursion $x_{k+1}=A x_{k} + B u_{k}$ and first principles (no pre-condensed prediction formulas), derive the three-step-ahead predicted state $x_{3}$ as a closed-form analytic expression that depends only on $x_{0}$ and the input moves $u_{0}, u_{1}, u_{2}$. Express your final answer as a single closed-form analytic expression. No rounding is required and no units are associated with the variables.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It presents a standard task in linear systems theory, fundamental to the field of Model Predictive Control. The problem is valid.\n\nThe objective is to derive the expression for the state vector $x_{3}$ three time steps into the future, based on the initial state $x_{0}$ and a sequence of control inputs $u_{0}$, $u_{1}$, and $u_{2}$. The derivation must proceed from first principles, using the fundamental state-evolution law for a discrete-time linear time-invariant system.\n\nThe state-update equation is given as:\n$$x_{k+1} = A x_{k} + B u_{k}$$\nwhere $k$ is the discrete time index. The initial state at $k=0$ is $x_{0}$. We will derive the state at successive time steps by recurrent substitution.\n\nFor $k=0$, the state at the next time step, $x_{1}$, is:\n$$x_{1} = A x_{0} + B u_{0}$$\n\nFor $k=1$, the state $x_{2}$ is found by applying the evolution law to $x_{1}$:\n$$x_{2} = A x_{1} + B u_{1}$$\nSubstituting the expression for $x_{1}$ into this equation gives:\n$$x_{2} = A (A x_{0} + B u_{0}) + B u_{1}$$\nBy the distributive property of matrix multiplication, this becomes:\n$$x_{2} = A^{2} x_{0} + A B u_{0} + B u_{1}$$\n\nFor $k=2$, the state $x_{3}$ is found by applying the law to $x_{2}$:\n$$x_{3} = A x_{2} + B u_{2}$$\nSubstituting the expression for $x_{2}$ yields:\n$$x_{3} = A (A^{2} x_{0} + A B u_{0} + B u_{1}) + B u_{2}$$\nDistributing the matrix $A$ results in the general closed-form expression for the three-step-ahead prediction:\n$$x_{3} = A^{3} x_{0} + A^{2} B u_{0} + A B u_{1} + B u_{2}$$\n\nThe problem requires a specific analytical expression for the given system matrices:\n$$A = \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\nTo obtain the final expression, we must compute the matrix powers $A^2$, $A^3$ and the products $AB$, $A^2 B$.\n\nFirst, we compute the powers of matrix $A$:\n$$A^{2} = A A = \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix} \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.9) + (0)(0.1) & (0.9)(0) + (0)(0.95) \\\\ (0.1)(0.9) + (0.95)(0.1) & (0.1)(0) + (0.95)(0.95) \\end{bmatrix} = \\begin{bmatrix} 0.81 & 0 \\\\ 0.185 & 0.9025 \\end{bmatrix}$$\n$$A^{3} = A A^{2} = \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix} \\begin{bmatrix} 0.81 & 0 \\\\ 0.185 & 0.9025 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.81) + (0)(0.185) & (0.9)(0) + (0)(0.9025) \\\\ (0.1)(0.81) + (0.95)(0.185) & (0.1)(0) + (0.95)(0.9025) \\end{bmatrix} = \\begin{bmatrix} 0.729 & 0 \\\\ 0.25675 & 0.857375 \\end{bmatrix}$$\n\nNext, we compute the matrix-vector products involving $B$:\n$$A B = \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix}$$\n$$A^{2} B = A (A B) = \\begin{bmatrix} 0.9 & 0 \\\\ 0.1 & 0.95 \\end{bmatrix} \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.9) + (0)(0.1) \\\\ (0.1)(0.9) + (0.95)(0.1) \\end{bmatrix} = \\begin{bmatrix} 0.81 \\\\ 0.185 \\end{bmatrix}$$\n\nSubstituting these computed matrices into the general expression for $x_{3}$:\n$$x_{3} = \\begin{bmatrix} 0.729 & 0 \\\\ 0.25675 & 0.857375 \\end{bmatrix} x_{0} + \\begin{bmatrix} 0.81 \\\\ 0.185 \\end{bmatrix} u_{0} + \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix} u_{1} + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} u_{2}$$\n\nThis expression can be written more compactly by grouping the terms dependent on the control input sequence $U = \\begin{bmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{bmatrix}$:\n$$x_{3} = \\begin{bmatrix} 0.729 & 0 \\\\ 0.25675 & 0.857375 \\end{bmatrix} x_{0} + \\begin{bmatrix} 0.81 & 0.9 & 1 \\\\ 0.185 & 0.1 & 0 \\end{bmatrix} \\begin{bmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{bmatrix}$$\nThis is the required single closed-form analytic expression for the three-step-ahead predicted state $x_{3}$.", "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n0.729 & 0 \\\\\n0.25675 & 0.857375\n\\end{bmatrix}\nx_{0} + \n\\begin{bmatrix}\n0.81 & 0.9 & 1 \\\\\n0.185 & 0.1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{0} \\\\\nu_{1} \\\\\nu_{2}\n\\end{bmatrix}\n}\n$$", "id": "2884328"}, {"introduction": "With a prediction model in hand, the next step is to formulate the \"control\" part of MPC as a well-defined optimization problem. For linear systems with quadratic costs, this problem takes the elegant and highly solvable form of a Quadratic Program (QP). This practice challenges you to perform this transformation by deriving the condensed Hessian matrix $H$, which captures the curvature of the cost function. Mastering this procedure reveals the underlying mathematical structure of the MPC problem and is a prerequisite for understanding and implementing efficient solvers [@problem_id:2884304].", "problem": "Consider a discrete-time, linear time-invariant scalar system in the standard Model Predictive Control (MPC) setup:\n$$x_{k+1} = A x_{k} + B u_{k},$$\nwith given parameters $A = 0.8$ and $B = 1$. Let the finite-horizon cost of length $N = 3$ be\n$$J = \\sum_{k=0}^{N-1} \\left( Q x_{k}^{2} + R u_{k}^{2} \\right),$$\nwith $Q = 1$ and $R = 0.1$. There is no terminal-state penalty, that is, the terminal weight is zero. Introduce the stacked input vector\n$$U = \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix},$$\nand write the cost in the canonical Quadratic Program (QP) form\n$$J(U) = \\frac{1}{2} U^{\\top} H U + f^{\\top} U + c,$$\nwhere $H$ is the condensed Hessian that depends only on the system matrices and cost weights, $f$ depends on the initial condition $x_{0}$, and $c$ is a constant independent of $U$. Starting only from the state update equation and the finite-horizon cost definition, form the prediction model for the stacked states over the horizon and derive the condensed Hessian $H$ explicitly for the given numerical values. You may assume the stacked predicted state is\n$$X = \\begin{pmatrix} x_{1} \\\\ x_{2} \\\\ x_{3} \\end{pmatrix},$$\nand that the terminal weight is zero. Compute $H$ as a numeric $3 \\times 3$ matrix. No rounding is required; report exact decimal values. The final answer must be the explicit matrix $H$.", "solution": "The problem presented is a standard formulation in Model Predictive Control (MPC) and is scientifically grounded, well-posed, and objective. It contains all necessary information for a unique solution. Therefore, a full solution is provided below.\n\nThe objective is to derive the condensed Hessian matrix $H$ for the given discrete-time system and quadratic cost function. The cost function $J$ must be expressed in the quadratic program (QP) form $J(U) = \\frac{1}{2} U^{\\top} H U + f^{\\top} U + c$, where $U$ is the stacked vector of control inputs over the prediction horizon.\n\nThe system dynamics are given by:\n$$x_{k+1} = A x_{k} + B u_{k}$$\nwith scalar parameters $A = 0.8$ and $B = 1$. The state $x_k$ and control input $u_k$ are also scalars.\n\nThe finite-horizon cost is defined over a horizon $N=3$:\n$$J = \\sum_{k=0}^{N-1} \\left( Q x_{k}^{2} + R u_{k}^{2} \\right) = \\sum_{k=0}^{2} \\left( x_{k}^{2} Q + u_{k}^{2} R \\right)$$\nwith weights $Q = 1$ and $R = 0.1$. The terminal weight is zero.\n\nThe control input vector to be optimized is:\n$$U = \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix}$$\nThe states that contribute to the cost are $x_0$, $x_1$, and $x_2$. We must express these states in terms of the initial state $x_0$ and the control inputs $u_0, u_1, u_2$.\nThe state evolution is as follows:\n$x_0$ is the initial condition.\n$$x_{1} = A x_{0} + B u_{0}$$\n$$x_{2} = A x_{1} + B u_{1} = A (A x_{0} + B u_{0}) + B u_{1} = A^2 x_{0} + A B u_{0} + B u_{1}$$\n\nWe can express the sequence of states relevant to the cost, $\\mathbf{X}_{\\text{cost}} = \\begin{pmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{pmatrix}$, in a stacked matrix form:\n$$\\begin{pmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ A \\\\ A^2 \\end{pmatrix} x_{0} + \\begin{pmatrix} 0 & 0 & 0 \\\\ B & 0 & 0 \\\\ AB & B & 0 \\end{pmatrix} \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix}$$\nLet's denote these matrices as $\\mathbf{S}_{x}$ and $\\mathbf{S}_{u}$, so that $\\mathbf{X}_{\\text{cost}} = \\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U$.\n\nThe cost function can be written in matrix form as:\n$$J = \\mathbf{X}_{\\text{cost}}^{\\top} \\bar{Q} \\mathbf{X}_{\\text{cost}} + U^{\\top} \\bar{R} U$$\nwhere $\\bar{Q}$ and $\\bar{R}$ are block-diagonal matrices of weights:\n$$\\bar{Q} = \\begin{pmatrix} Q & 0 & 0 \\\\ 0 & Q & 0 \\\\ 0 & 0 & Q \\end{pmatrix}, \\quad \\bar{R} = \\begin{pmatrix} R & 0 & 0 \\\\ 0 & R & 0 \\\\ 0 & 0 & R \\end{pmatrix}$$\nSubstituting the expression for $\\mathbf{X}_{\\text{cost}}$ into the cost function $J$:\n$$J = (\\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U)^{\\top} \\bar{Q} (\\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U) + U^{\\top} \\bar{R} U$$\nExpanding this expression:\n$$J = x_{0}^{\\top} \\mathbf{S}_{x}^{\\top} \\bar{Q} \\mathbf{S}_{x} x_{0} + 2 x_{0}^{\\top} \\mathbf{S}_{x}^{\\top} \\bar{Q} \\mathbf{S}_{u} U + U^{\\top} \\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} U + U^{\\top} \\bar{R} U$$\nThis expression matches the QP form $J(U) = c + f^{\\top} U + \\frac{1}{2} U^{\\top} H U$.\nThe term quadratic in $U$ is $U^{\\top} (\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R}) U$.\nBy comparison with $\\frac{1}{2} U^{\\top} H U$, we identify the condensed Hessian matrix $H$ as:\n$$H = 2 \\left( \\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R} \\right)$$\nNow, we substitute the given numerical values: $A = 0.8$, $B = 1$, $Q = 1$, $R = 0.1$.\nThe matrices $\\mathbf{S}_u$, $\\bar{Q}$, and $\\bar{R}$ become:\n$$\\mathbf{S}_{u} = \\begin{pmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ (0.8)(1) & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0.8 & 1 & 0 \\end{pmatrix}$$\n$$\\bar{Q} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = I_{3}$$\n$$\\bar{R} = \\begin{pmatrix} 0.1 & 0 & 0 \\\\ 0 & 0.1 & 0 \\\\ 0 & 0 & 0.1 \\end{pmatrix}$$\nSince $\\bar{Q}$ is the identity matrix, $\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} = \\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u}$.\nFirst, we compute $\\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u}$:\n$$\\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u} = \\begin{pmatrix} 0 & 1 & 0.8 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0.8 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0.8)(0.8) & (0.8)(1) & 0 \\\\ (1)(0.8) & (1)(1) & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1.64 & 0.8 & 0 \\\\ 0.8 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nNext, we add $\\bar{R}$:\n$$\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R} = \\begin{pmatrix} 1.64 & 0.8 & 0 \\\\ 0.8 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 0.1 & 0 & 0 \\\\ 0 & 0.1 & 0 \\\\ 0 & 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 1.74 & 0.8 & 0 \\\\ 0.8 & 1.1 & 0 \\\\ 0 & 0 & 0.1 \\end{pmatrix}$$\nFinally, we compute $H$ by multiplying by $2$:\n$$H = 2 \\begin{pmatrix} 1.74 & 0.8 & 0 \\\\ 0.8 & 1.1 & 0 \\\\ 0 & 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 3.48 & 1.6 & 0 \\\\ 1.6 & 2.2 & 0 \\\\ 0 & 0 & 0.2 \\end{pmatrix}$$\nThis is the condensed Hessian matrix for the given MPC problem.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3.48 & 1.6 & 0 \\\\\n1.6 & 2.2 & 0 \\\\\n0 & 0 & 0.2\n\\end{pmatrix}\n}\n$$", "id": "2884304"}, {"introduction": "The true power of MPC is most evident in its ability to gracefully handle system constraintsâ€”a common requirement in nearly all real-world applications. This exercise explores the anatomy of a constrained optimal solution by leveraging the Karush-Kuhn-Tucker (KKT) conditions. By calculating the Lagrange multipliers for an active state constraint, you will learn how to quantify the \"cost\" of that limitation, providing invaluable insight into the controller's decision-making process when operating at its boundaries [@problem_id:2884356].", "problem": "Consider a single-input single-output linear time-invariant discrete-time system used in Model Predictive Control (MPC) with one-step prediction,\n$$\nx_{k+1} = a\\,x_{k} + b\\,u_{k},\n$$\nand a quadratic stage cost\n$$\nJ = \\frac{1}{2}\\,q\\,(x_{k+1} - r)^{2} + \\frac{1}{2}\\,r_{u}\\,u_{k}^{2},\n$$\nsubject to the hard-state bound\n$$\nx_{k+1} \\in [\\underline{x}, \\overline{x}].\n$$\nLet the parameters be\n$$\na = 0.7,\\quad b = 2.0,\\quad x_{k} = 3.0,\\quad q = 5.0,\\quad r_{u} = 0.5,\\quad r = 6.0,\\quad \\underline{x} = -1.0,\\quad \\overline{x} = 4.0.\n$$\nEliminate the control input by expressing $u_{k}$ in terms of $x_{k+1}$ via the system dynamics to obtain a scalar bound-constrained optimization in the decision variable $x_{k+1}$. Then, starting from the Karush-Kuhn-Tucker (KKT) conditions and complementary slackness, determine the Lagrange multipliers associated with the lower and upper state bounds at the optimal solution, under the regime in which the predicted state saturates at the upper bound (that is, $x_{k+1}^{\\star} = \\overline{x}$). Your final answer must be the pair $(\\mu_{\\ell}, \\mu_{u})$ where $\\mu_{\\ell}$ is the multiplier for the lower bound and $\\mu_{u}$ is the multiplier for the upper bound, expressed as a row matrix. No rounding is required.", "solution": "The problem as stated is a valid formulation of a constrained optimization task within the framework of Model Predictive Control. It is scientifically grounded, well-posed, objective, and self-contained, with all necessary parameters provided. It is a standard convex quadratic program with linear inequality constraints, for which a unique solution is guaranteed to exist. We may therefore proceed with the derivation.\n\nThe objective is to find the Lagrange multipliers $(\\mu_{\\ell}, \\mu_{u})$ associated with the state constraints for a single-step prediction horizon, under the specified condition that the optimal predicted state $x_{k+1}^{\\star}$ saturates at its upper bound $\\overline{x}$.\n\nFirst, we formulate the optimization problem solely in terms of the decision variable $x_{k+1}$. The system dynamics are given by\n$$\nx_{k+1} = a\\,x_{k} + b\\,u_{k}.\n$$\nAssuming $b \\neq 0$, which is true for $b=2.0$, we can express the control input $u_k$ as a function of the state at time $k+1$:\n$$\nu_{k} = \\frac{1}{b}(x_{k+1} - a\\,x_{k}).\n$$\nSubstituting this into the quadratic stage cost function\n$$\nJ = \\frac{1}{2}\\,q\\,(x_{k+1} - r)^{2} + \\frac{1}{2}\\,r_{u}\\,u_{k}^{2}\n$$\nyields the cost as a function of $x_{k+1}$ only:\n$$\nJ(x_{k+1}) = \\frac{1}{2}\\,q\\,(x_{k+1} - r)^{2} + \\frac{1}{2}\\,r_{u}\\,\\left(\\frac{1}{b}(x_{k+1} - a\\,x_{k})\\right)^{2}.\n$$\nThe optimization problem is to minimize $J(x_{k+1})$ subject to the hard-state bounds $x_{k+1} \\in [\\underline{x}, \\overline{x}]$. These bounds can be written as two inequality constraints:\n$$\ng_1(x_{k+1}) = x_{k+1} - \\overline{x} \\leq 0,\n$$\n$$\ng_2(x_{k+1}) = \\underline{x} - x_{k+1} \\leq 0.\n$$\nTo solve this constrained optimization problem, we use the Karush-Kuhn-Tucker (KKT) conditions. We define the Lagrangian function $\\mathcal{L}$ with non-negative Lagrange multipliers $\\mu_{u}$ and $\\mu_{\\ell}$ corresponding to the upper and lower bound constraints, respectively:\n$$\n\\mathcal{L}(x_{k+1}, \\mu_{u}, \\mu_{\\ell}) = J(x_{k+1}) + \\mu_{u}(x_{k+1} - \\overline{x}) + \\mu_{\\ell}(\\underline{x} - x_{k+1}).\n$$\nThe KKT conditions for an optimal solution $(x_{k+1}^{\\star}, \\mu_{u}^{\\star}, \\mu_{\\ell}^{\\star})$ are:\n1.  **Stationarity:** $\\nabla_{x_{k+1}} \\mathcal{L} = \\frac{\\partial J}{\\partial x_{k+1}} + \\mu_{u}^{\\star} - \\mu_{\\ell}^{\\star} = 0$.\n2.  **Primal Feasibility:** $\\underline{x} \\leq x_{k+1}^{\\star} \\leq \\overline{x}$.\n3.  **Dual Feasibility:** $\\mu_{u}^{\\star} \\geq 0$ and $\\mu_{\\ell}^{\\star} \\geq 0$.\n4.  **Complementary Slackness:** $\\mu_{u}^{\\star}(x_{k+1}^{\\star} - \\overline{x}) = 0$ and $\\mu_{\\ell}^{\\star}(\\underline{x} - x_{k+1}^{\\star}) = 0$.\n\nThe problem specifies that the solution lies on the upper bound, i.e., $x_{k+1}^{\\star} = \\overline{x}$. We use this fact to determine the multipliers.\n\nFrom the second complementary slackness condition, $\\mu_{\\ell}^{\\star}(\\underline{x} - x_{k+1}^{\\star}) = 0$, we substitute $x_{k+1}^{\\star} = \\overline{x}$:\n$$\n\\mu_{\\ell}^{\\star}(\\underline{x} - \\overline{x}) = 0.\n$$\nUsing the given numerical values, $\\underline{x} = -1.0$ and $\\overline{x} = 4.0$, the term in the parenthesis is $\\underline{x} - \\overline{x} = -1.0 - 4.0 = -5.0$. Since this term is non-zero, it must be that the multiplier $\\mu_{\\ell}^{\\star} = 0$. This is expected, as the lower bound constraint is not active at the solution.\n\nThe first complementary slackness condition, $\\mu_{u}^{\\star}(x_{k+1}^{\\star} - \\overline{x}) = 0$, becomes $\\mu_{u}^{\\star}(\\overline{x} - \\overline{x}) = 0$, which is trivially satisfied and does not determine $\\mu_{u}^{\\star}$.\n\nWe must therefore use the stationarity condition, evaluated at the optimum $x_{k+1}^{\\star} = \\overline{x}$ and with $\\mu_{\\ell}^{\\star}=0$:\n$$\n\\frac{\\partial J}{\\partial x_{k+1}}\\bigg|_{x_{k+1}=\\overline{x}} + \\mu_{u}^{\\star} - 0 = 0.\n$$\nThis allows us to solve for $\\mu_{u}^{\\star}$:\n$$\n\\mu_{u}^{\\star} = -\\frac{\\partial J}{\\partial x_{k+1}}\\bigg|_{x_{k+1}=\\overline{x}}.\n$$\nFirst, we compute the derivative of $J(x_{k+1})$:\n$$\n\\frac{\\partial J}{\\partial x_{k+1}} = q(x_{k+1} - r) + \\frac{r_{u}}{b^2}(x_{k+1} - a\\,x_{k}).\n$$\nNow, we evaluate this derivative at $x_{k+1} = \\overline{x}$:\n$$\n\\frac{\\partial J}{\\partial x_{k+1}}\\bigg|_{x_{k+1}=\\overline{x}} = q(\\overline{x} - r) + \\frac{r_{u}}{b^2}(\\overline{x} - a\\,x_{k}).\n$$\nTherefore, the upper bound multiplier is:\n$$\n\\mu_{u}^{\\star} = - \\left( q(\\overline{x} - r) + \\frac{r_{u}}{b^2}(\\overline{x} - a\\,x_{k}) \\right).\n$$\nWe substitute the given numerical parameters:\n$a = 0.7$, $b = 2.0$, $x_{k} = 3.0$, $q = 5.0$, $r_{u} = 0.5$, $r = 6.0$, $\\overline{x} = 4.0$.\n$$\n\\mu_{u}^{\\star} = - \\left( 5.0(4.0 - 6.0) + \\frac{0.5}{(2.0)^{2}}(4.0 - (0.7)(3.0)) \\right)\n$$\n$$\n\\mu_{u}^{\\star} = - \\left( 5.0(-2.0) + \\frac{0.5}{4.0}(4.0 - 2.1) \\right)\n$$\n$$\n\\mu_{u}^{\\star} = - \\left( -10.0 + (0.125)(1.9) \\right)\n$$\n$$\n\\mu_{u}^{\\star} = - \\left( -10.0 + 0.2375 \\right)\n$$\n$$\n\\mu_{u}^{\\star} = -(-9.7625) = 9.7625.\n$$\nThis value satisfies the dual feasibility condition $\\mu_{u}^{\\star} \\geq 0$. To provide the exact answer, we convert this to a fraction:\n$$\n\\mu_{u}^{\\star} = 9.7625 = \\frac{97625}{10000} = \\frac{19525}{2000} = \\frac{3905}{400} = \\frac{781}{80}.\n$$\nThe pair of Lagrange multipliers is $(\\mu_{\\ell}, \\mu_{u}) = (0, \\frac{781}{80})$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & \\frac{781}{80} \\end{pmatrix}}\n$$", "id": "2884356"}]}