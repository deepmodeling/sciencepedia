{"hands_on_practices": [{"introduction": "This first practice challenges you to derive the fundamental relationship of the impulse invariance method from first principles. By analyzing a specific system configuration, you will determine the correct scaling factor between the continuous-time and discrete-time impulse responses, a detail that often leads to confusion but is critical for a correct implementation [@problem_id:2877401]. This exercise deepens your understanding of how sampling theory and linear time-invariant (LTI) system convolution interact to define this powerful transformation.", "problem": "Consider a continuous-time linear time-invariant system with impulse response $h_a(t)$ that is absolutely integrable, and the continuous-time Fourier transform (CTFT) convention\n$$\nH_a(j\\Omega)=\\int_{-\\infty}^{\\infty} h_a(t)\\, \\exp(-j\\Omega t)\\, dt.\n$$\nLet the sampling period be $T0$. We seek a discrete-time linear time-invariant system with impulse response $h_d[n]$ that is obtained from $h_a(t)$ by the impulse invariance principle. Assume the following interconnection: For an arbitrary discrete-time input sequence $x[n]$, form a continuous-time input\n$$\nx_a(t) = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT),\n$$\ndrive the continuous-time system with $x_a(t)$ to obtain $y_a(t)$, and require that the discrete-time system output $y[n]$ satisfy\n$$\ny[n]=y_a(nT)\\quad\\text{for all integers }n.\n$$\nLet the discrete-time Fourier transform (DTFT) be defined by\n$$\nX_d(\\exp(j\\omega))=\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\omega n),\n$$\nwith inverse\n$$\nx[n]=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} X_d(\\exp(j\\omega))\\, \\exp(j\\omega n)\\, d\\omega.\n$$\nPostulate a time-domain relation of the form\n$$\nh_d[n]=\\gamma\\, h_a(nT),\n$$\nwhere $\\gamma$ is a scalar independent of $n$ and $T$. Starting from the convolution definitions of $y_a(t)$ and $y[n]$ and the above CTFT and DTFT conventions, derive whether the impulse invariance relation includes a factor $T$ in $h_d[n]$; that is, determine the value of $\\gamma$. Then confirm your result in the frequency domain by relating $H_d(\\exp(j\\omega))$ to $H_a(j\\Omega)$ using only well-tested results about sampling and the Poisson summation formula. Your final answer must be the value of $\\gamma$ as a single real number. No rounding is required.", "solution": "The problem requires the determination of a scaling constant $\\gamma$ in the impulse invariance relationship $h_d[n] = \\gamma h_a(nT)$ for a specific discrete-time system derived from a continuous-time system. The derivation must be performed first in the time domain, based on the provided system interconnection, and then confirmed in the frequency domain.\n\nFirst, we validate the problem statement.\nThe givens are:\n1.  A continuous-time linear time-invariant (LTI) system with an absolutely integrable impulse response $h_a(t)$.\n2.  The continuous-time Fourier transform (CTFT) definition: $H_a(j\\Omega)=\\int_{-\\infty}^{\\infty} h_a(t)\\, \\exp(-j\\Omega t)\\, dt$.\n3.  A sampling period $T0$.\n4.  A discrete-time LTI system with impulse response $h_d[n]$.\n5.  The system interconnection is defined as: an arbitrary discrete-time input $x[n]$ is converted to a continuous-time signal $x_a(t) = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT)$. This signal drives the continuous-time system to produce $y_a(t)$. The output of the discrete-time system, $y[n]$, is obtained by sampling the continuous-time output: $y[n]=y_a(nT)$.\n6.  The discrete-time Fourier transform (DTFT) definition: $X_d(\\exp(j\\omega))=\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\omega n)$.\n7.  The postulated relationship: $h_d[n]=\\gamma\\, h_a(nT)$.\n\nThe problem is scientifically grounded, well-posed, objective, and contains no internal contradictions or missing information. All terms are standard in signal processing theory. The question is a formal derivation based on the provided definitions. Thus, the problem is valid.\n\nWe proceed to the solution.\n\n**Time-Domain Derivation**\n\nThe most direct method to find the impulse response $h_d[n]$ of the equivalent discrete-time system is to use a discrete-time impulse as the input and find the corresponding output sequence. Let the input be the unit impulse sequence, $x[n]=\\delta[n]$, where $\\delta[n]=1$ for $n=0$ and $\\delta[n]=0$ for $n \\neq 0$.\n\nAccording to the problem definition, this discrete-time input is used to form the continuous-time signal $x_a(t)$:\n$$\nx_a(t) = \\sum_{k=-\\infty}^{\\infty} x[k]\\, \\delta(t-kT) = \\sum_{k=-\\infty}^{\\infty} \\delta[k]\\, \\delta(t-kT)\n$$\nDue to the properties of the discrete-time impulse $\\delta[k]$, the only non-zero term in the summation is for $k=0$. Thus, the continuous-time input signal becomes:\n$$\nx_a(t) = \\delta[0]\\, \\delta(t-0 \\cdot T) = 1 \\cdot \\delta(t) = \\delta(t)\n$$\nThis signal, a continuous-time Dirac impulse, is the input to the continuous-time LTI system with impulse response $h_a(t)$. The output of this system, $y_a(t)$, is given by the convolution of the input with the impulse response:\n$$\ny_a(t) = x_a(t) * h_a(t) = \\int_{-\\infty}^{\\infty} x_a(\\tau) h_a(t-\\tau) \\, d\\tau = \\int_{-\\infty}^{\\infty} \\delta(\\tau) h_a(t-\\tau) \\, d\\tau\n$$\nBy the sifting property of the Dirac delta function, this integral evaluates to:\n$$\ny_a(t) = h_a(t-0) = h_a(t)\n$$\nThe problem states that the discrete-time output $y[n]$ is obtained by sampling $y_a(t)$ at integer multiples of the sampling period $T$:\n$$\ny[n] = y_a(nT) = h_a(nT)\n$$\nBy definition, the output of a discrete-time LTI system when the input is the unit impulse sequence $\\delta[n]$ is the system's impulse response, $h_d[n]$. Therefore, we have found that:\n$$\nh_d[n] = h_a(nT)\n$$\nThe problem postulates a relationship of the form $h_d[n]=\\gamma\\, h_a(nT)$. Comparing our derived result with this postulate, we can directly conclude that the scaling constant $\\gamma$ is:\n$$\n\\gamma = 1\n$$\n\n**Frequency-Domain Confirmation**\n\nWe now confirm this result by analyzing the system in the frequency domain. Let's find the frequency response $H_d(\\exp(j\\omega))$ of the discrete-time system.\nThe relationship between the discrete-time input $x[n]$ and the continuous-time input $x_a(t)$ is given. Their Fourier transforms are related. The CTFT of $x_a(t)$ is:\n$$\nX_a(j\\Omega) = \\mathcal{F}\\left\\{\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT)\\right\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\mathcal{F}\\{\\delta(t-nT)\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\Omega nT)\n$$\nThis expression is the DTFT of $x[n]$, $X_d(\\exp(j\\omega))$, with the substitution $\\omega=\\Omega T$. So, $X_a(j\\Omega) = X_d(\\exp(j\\Omega T))$.\n\nThe output of the continuous-time filter in the frequency domain is $Y_a(j\\Omega) = H_a(j\\Omega) X_a(j\\Omega)$:\n$$\nY_a(j\\Omega) = H_a(j\\Omega) X_d(\\exp(j\\Omega T))\n$$\nThe discrete-time output $y[n]$ is obtained by sampling $y_a(t)$ at $t=nT$. The DTFT of the sampled signal, $Y_d(\\exp(j\\omega))$, is related to the CTFT of the original signal, $Y_a(j\\Omega)$, by the aliasing formula, which is a consequence of the Poisson summation formula:\n$$\nY_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} Y_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right)\n$$\nSubstituting the expression for $Y_a(j\\Omega)$:\n$$\nY_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) X_d\\left(\\exp\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)T\\right)\\right)\n$$\nThe argument of the exponential in $X_d$ simplifies:\n$$\n\\exp\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)T\\right) = \\exp(j(\\omega - 2\\pi k)) = \\exp(j\\omega)\\exp(-j2\\pi k) = \\exp(j\\omega)\n$$\nsince $k$ is an integer. Thus, the term $X_d(\\exp(j\\omega))$ is independent of the summation index $k$ and can be factored out:\n$$\nY_d(\\exp(j\\omega)) = X_d(\\exp(j\\omega)) \\left[ \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\right]\n$$\nFor a discrete-time LTI system, we have $Y_d(\\exp(j\\omega)) = H_d(\\exp(j\\omega)) X_d(\\exp(j\\omega))$. By comparing this with the derived expression, we identify the frequency response of the discrete-time system:\n$$\nH_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right)\n$$\nTo find the impulse response $h_d[n]$ from this frequency response, we take the inverse DTFT:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} H_d(\\exp(j\\omega)) \\exp(j\\omega n) \\, d\\omega\n$$\nSubstituting the expression for $H_d(\\exp(j\\omega))$:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\left[ \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\right] \\exp(j\\omega n) \\, d\\omega\n$$\nExchanging the order of integration and summation:\n$$\nh_d[n] = \\frac{1}{2\\pi T} \\sum_{k=-\\infty}^{\\infty} \\int_{-\\pi}^{\\pi} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\exp(j\\omega n) \\, d\\omega\n$$\nFor each integral, let's perform a change of variables. Let $\\Omega = \\frac{\\omega}{T} - \\frac{2\\pi k}{T}$. This implies $\\omega = T\\Omega + 2\\pi k$ and $d\\omega = T d\\Omega$. The integration limits for each term change: for $\\omega \\in [-\\pi, \\pi]$, the new limits for $\\Omega$ are $[\\frac{-\\pi}{T} - \\frac{2\\pi k}{T}, \\frac{\\pi}{T} - \\frac{2\\pi k}{T}]$.\nThe integral for a given $k$ becomes:\n$$\n\\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j(T\\Omega + 2\\pi k) n) (T d\\Omega) = T \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) \\exp(j2\\pi kn) d\\Omega\n$$\nSince $k$ and $n$ are integers, $\\exp(j2\\pi kn) = 1$. Substituting this back into the sum for $h_d[n]$:\n$$\nh_d[n] = \\frac{1}{2\\pi T} \\sum_{k=-\\infty}^{\\infty} T \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega\n$$\nThe factors of $T$ cancel. The summation of the integrals over these adjacent intervals covers the entire real line:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\sum_{k=-\\infty}^{\\infty} \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega\n$$\nThis final integral is the definition of the inverse CTFT of $H_a(j\\Omega)$, evaluated at time $t=nT$. The inverse CTFT corresponding to the given forward transform is $h_a(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} H_a(j\\Omega)\\, \\exp(j\\Omega t)\\, d\\Omega$.\nThus, we find:\n$$\nh_d[n] = h_a(nT)\n$$\nThis frequency-domain analysis confirms the result obtained from the time-domain analysis. Comparing again to the postulate $h_d[n]=\\gamma\\, h_a(nT)$, we confirm that $\\gamma = 1$. It is important to note that this result is a direct consequence of the specific system block diagram defined in the problem. Other definitions of impulse invariance may lead to a different scaling factor.", "answer": "$$\n\\boxed{1}\n$$", "id": "2877401"}, {"introduction": "While the impulse invariance transformation preserves the stability of a system, does it preserve all other desirable filter properties? This practice explores the transformation's effect on the minimum-phase property, a key attribute for many control and filtering applications [@problem_id:2877349]. You will investigate the conditions under which this property holds and analyze a counterexample, revealing the non-trivial relationship between the zeros of an analog filter and its digital counterpart.", "problem": "A linear time-invariant analog filter with transfer function $H_{a}(s)$ is called minimum-phase if all its zeros lie strictly in the open left half-plane. Consider a causal impulse-invariance discretization with sampling period $T0$, defined in the time domain by $h_{d}[n] = T\\,h_{a}(nT)$ for $n \\in \\mathbb{Z}$ with $h_{a}(t)$ the analog impulse response. The corresponding discrete-time transfer function is $H_{d}(z) = \\sum_{n=0}^{\\infty} h_{d}[n]\\,z^{-n}$, which is minimum-phase if and only if all its zeros lie strictly inside the open unit disk.\n\nSelect the option that correctly states sufficient conditions under which the impulse-invariant discrete-time system $H_{d}(z)$ remains minimum-phase when $H_{a}(s)$ is minimum-phase, and also provides a correct explicit counterexample (a minimum-phase $H_{a}(s)$ and a sampling period $T$) for which the impulse-invariant $H_{d}(z)$ fails to be minimum-phase.\n\nA. For every strictly proper, causal, stable, minimum-phase $H_{a}(s)$ and every $T0$, the impulse-invariant $H_{d}(z)$ is minimum-phase; no counterexample exists.\n\nB. If $H_{a}(s)$ has exactly one real pole at $s=-p$ with $p0$, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. More generally, if $H_{a}(s)$ has exactly two distinct real poles at $s=-p_{1}$ and $s=-p_{2}$ with $p_{1},p_{2}0$ and the residues in the partial fraction expansion of $H_{a}(s)$ are both nonnegative, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. A counterexample when these hypotheses are not satisfied is\n$$\nH_{a}(s)=\\frac{(s+5)(s+6)}{(s+0.1)(s+0.2)(s+0.3)},\\quad T=1,\n$$\nfor which $H_{a}(s)$ is minimum-phase but the impulse-invariant $H_{d}(z)$ has at least one zero outside the unit circle.\n\nC. If $T$ is sufficiently small so that $T  1/\\max_{k} p_{k}$, then for every strictly proper, causal, stable, minimum-phase $H_{a}(s)$, the impulse-invariant $H_{d}(z)$ is minimum-phase. No counterexample exists for sufficiently small $T$.\n\nD. If $H_{a}(s)$ has no repeated poles and all zeros are strictly in the open left half-plane, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. A counterexample exists only when $H_{a}(s)$ has repeated poles; for example, $H_{a}(s)=\\frac{1}{(s+1)^{2}}$ with $T=1$ yields a non-minimum-phase $H_{d}(z)$.", "solution": "The user requires an analysis of the conditions under which the impulse-invariance transformation preserves the minimum-phase property of a linear time-invariant analog filter, and to identify a correct counterexample.\n\n### Step 1: Problem Validation\n\nThe problem statement defines a linear time-invariant (LTI) analog filter $H_a(s)$, a causal impulse-invariance discretization method with sampling period $T0$ to obtain a discrete-time filter $H_d(z)$, and the definitions of minimum-phase for both continuous-time and discrete-time systems. The task is to select an option that provides both correct sufficient conditions for the preservation of the minimum-phase property and a valid counterexample where it fails.\n\n- **Givens**:\n    - Analog LTI filter with transfer function $H_a(s)$.\n    - Analog minimum-phase: all zeros of $H_a(s)$ are in the open left half-plane ($\\text{Re}(s)  0$).\n    - Discretization rule: $h_d[n] = T\\,h_a(nT)$, for $n \\in \\mathbb{Z}$, with $h_a(t)$ being the causal analog impulse response.\n    - Discrete-time LTI filter with transfer function $H_d(z) = \\sum_{n=0}^{\\infty} h_d[n]\\,z^{-n}$.\n    - Discrete minimum-phase: all zeros of $H_d(z)$ are in the open unit disk ($|z|  1$).\n    - The problem assumes $H_a(s)$ is causal and stable. The options further assume it is strictly proper.\n\n- **Validation**:\n    1.  **Scientific Grounding**: The problem is based on fundamental and standard concepts of Digital Signal Processing (DSP), specifically the impulse invariance method for converting analog filters to digital filters. All definitions and relationships are standard in the field. The analysis is mathematically rigorous. The problem is scientifically sound.\n    2.  **Well-Posedness**: The question is specific and unambiguous. It requires identifying correct mathematical conditions and verifying a counterexample. This is a well-defined task with a unique correct answer among the options, assuming one exists.\n    3.  **Objectivity**: The problem is stated in precise, objective, and technical language, free from any subjectivity or ambiguity.\n\n- **Verdict**: The problem is valid. It is a standard, non-trivial problem in systems theory that tests a deep understanding of the properties of a common discretization technique. I will proceed with the solution.\n\n### Step 2: Derivation and Option Analysis\n\nThe relationship between the transfer functions for a strictly proper $H_a(s)$ with distinct poles is derived as follows.\nLet the partial fraction expansion of $H_a(s)$ be:\n$$H_a(s) = \\sum_{k=1}^{N} \\frac{R_k}{s - p_k}$$\nFor a causal and stable filter, $\\text{Re}(p_k)  0$ for all $k$. The impulse response is:\n$$h_a(t) = \\sum_{k=1}^{N} R_k e^{p_k t} u(t)$$\nSampling this response gives the discrete-time impulse response:\n$$h_d[n] = T h_a(nT) = T \\sum_{k=1}^{N} R_k e^{p_k nT} u[n] = T \\sum_{k=1}^{N} R_k (e^{p_k T})^n u[n]$$\nThe Z-transform of $h_d[n]$ is:\n$$H_d(z) = \\sum_{n=0}^{\\infty} h_d[n] z^{-n} = T \\sum_{k=1}^{N} R_k \\sum_{n=0}^{\\infty} (e^{p_k T} z^{-1})^n$$\nUsing the geometric series formula, we get:\n$$H_d(z) = T \\sum_{k=1}^{N} \\frac{R_k}{1 - e^{p_k T} z^{-1}} = T \\sum_{k=1}^{N} \\frac{R_k z}{z - e^{p_k T}}$$\nThe poles of $H_a(s)$ at $s=p_k$ are mapped to poles of $H_d(z)$ at $z = e^{p_k T}$. Since $\\text{Re}(p_k)  0$, we have $|e^{p_k T}| = e^{\\text{Re}(p_k)T}  1$, so the stability is preserved.\nThe zeros of $H_d(z)$ are more complex. By combining the terms over a common denominator, we get:\n$$H_d(z) = T \\frac{z \\sum_{k=1}^{N} R_k \\prod_{j \\neq k} (z - e^{p_j T})}{\\prod_{k=1}^{N} (z - e^{p_k T})}$$\nThe zeros of $H_d(z)$ are at $z=0$ and the roots of the polynomial in the numerator. The locations of these zeros depend on the analog poles $p_k$, residues $R_k$, and the sampling period $T$. There is no simple mapping for zeros, and it is a known fact that the minimum-phase property is not always preserved.\n\nNow, we evaluate each option.\n\n**A. For every strictly proper, causal, stable, minimum-phase $H_{a}(s)$ and every $T0$, the impulse-invariant $H_{d}(z)$ is minimum-phase; no counterexample exists.**\nThis statement is incorrect. As will be shown in the analysis of option B, counterexamples do exist where a minimum-phase analog filter results in a non-minimum-phase digital filter via impulse invariance.\n\n**Verdict on A: Incorrect.**\n\n**B. If $H_{a}(s)$ has exactly one real pole at $s=-p$ with $p0$, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. More generally, if $H_{a}(s)$ has exactly two distinct real poles at $s=-p_{1}$ and $s=-p_{2}$ with $p_{1},p_{2}0$ and the residues in the partial fraction expansion of $H_{a}(s)$ are both nonnegative, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. A counterexample when these hypotheses are not satisfied is $H_{a}(s)=\\frac{(s+5)(s+6)}{(s+0.1)(s+0.2)(s+0.3)},\\quad T=1$, for which $H_{a}(s)$ is minimum-phase but the impulse-invariant $H_{d}(z)$ has at least one zero outside the unit circle.**\n\nLet's validate the three parts of this option.\n1.  **One-pole case**: If $H_a(s)$ is strictly proper, stable, and has one pole at $s=-p$ ($p0$), it must be of the form $H_a(s) = \\frac{K}{s+p}$ for some constant $K$. This is an all-pole filter (no finite zeros), so it is minimum-phase. Its impulse response is $h_a(t)=K e^{-pt} u(t)$. The digital transfer function is $H_d(z) = \\frac{TKz}{z - e^{-pT}}$. The only zero is at $z=0$, which is inside the unit disk. Thus, $H_d(z)$ is minimum-phase. This statement is correct.\n\n2.  **Two-pole case with non-negative residues**: Let $H_a(s) = \\frac{R_1}{s+p_1} + \\frac{R_2}{s+p_2}$ with $p_1, p_2  0$, $p_1 \\neq p_2$, and residues $R_1 \\ge 0, R_2 \\ge 0$. The impulse response is $h_a(t) = (R_1 e^{-p_1 t} + R_2 e^{-p_2 t})u(t)$. Since $R_1, R_2 \\ge 0$ and the exponential terms are positive for $t0$, $h_a(t) \\ge 0$ for all $t$. This means $h_d[n] = T h_a(nT) \\ge 0$ for all $n \\ge 0$.\n    The discrete transfer function is $H_d(z) = T(\\frac{R_1 z}{z-e^{-p_1 T}} + \\frac{R_2 z}{z-e^{-p_2 T}})$. Its zeros are $z=0$ and the root of $z(R_1+R_2) - (R_1 e^{-p_2 T} + R_2 e^{-p_1 T}) = 0$. The non-trivial zero is $z_0 = \\frac{R_1 e^{-p_2 T} + R_2 e^{-p_1 T}}{R_1+R_2}$. This is a convex combination of $e^{-p_1 T}$ and $e^{-p_2 T}$. Since $p_1, p_2, T  0$, we have $0  e^{-p_1 T}  1$ and $0  e^{-p_2 T}  1$. A convex combination of two points in the interval $(0, 1)$ must also lie in $(0, 1)$. Thus $0  z_0  1$. All zeros are inside the unit disk, so $H_d(z)$ is minimum-phase. This statement is correct.\n\n3.  **Counterexample**: Consider $H_{a}(s)=\\frac{(s+5)(s+6)}{(s+0.1)(s+0.2)(s+0.3)}$ with $T=1$.\n    - $H_a(s)$ has zeros at $s=-5$ and $s=-6$, which are in the open left half-plane. It is minimum-phase.\n    - Poles are at $s=-0.1, -0.2, -0.3$, so it is stable and strictly proper.\n    - Let's check the residues. Let $H_a(s) = \\frac{R_1}{s+0.1} + \\frac{R_2}{s+0.2} + \\frac{R_3}{s+0.3}$.\n    $R_1 = \\left.\\frac{(s+5)(s+6)}{(s+0.2)(s+0.3)}\\right|_{s=-0.1} = \\frac{(4.9)(5.9)}{(0.1)(0.2)} = 1445.5  0$.\n    $R_2 = \\left.\\frac{(s+5)(s+6)}{(s+0.1)(s+0.3)}\\right|_{s=-0.2} = \\frac{(4.8)(5.8)}{(-0.1)(0.1)} = -2784  0$.\n    $R_3 = \\left.\\frac{(s+5)(s+6)}{(s+0.1)(s+0.2)}\\right|_{s=-0.3} = \\frac{(4.7)(5.7)}{(-0.2)(-0.1)} = 1339.5  0$.\n    The residues are not all non-negative, so the sufficient conditions from part 2 are not met.\n    - Now we check if $H_d(z)$ is non-minimum-phase. The zeros of $H_d(z)$ are $z=0$ and the roots of the polynomial $P(z) = R_1(z-e^{-0.2})(z-e^{-0.3}) + R_2(z-e^{-0.1})(z-e^{-0.3}) + R_3(z-e^{-0.1})(z-e^{-0.2})$. Let's evaluate $P(z)$ at $z=-2$.\n    $P(-2) = 1445.5(-2-e^{-0.2})(-2-e^{-0.3}) - 2784(-2-e^{-0.1})(-2-e^{-0.3}) + 1339.5(-2-e^{-0.1})(-2-e^{-0.2})$.\n    Using $e^{-0.1}\\approx0.905$, $e^{-0.2}\\approx0.819$, $e^{-0.3}\\approx0.741$:\n    $P(-2) \\approx 1445.5(-2.819)(-2.741) - 2784(-2.905)(-2.741) + 1339.5(-2.905)(-2.819)$\n    $P(-2) \\approx 1445.5(7.727) - 2784(7.963) + 1339.5(8.189) \\approx 11169 - 22179 + 10996 = -14$.\n    The leading coefficient of $P(z)$ is $A = R_1+R_2+R_3 = \\lim_{s\\to\\infty} sH_a(s) = 1  0$. Therefore, $P(z) \\to +\\infty$ as $z \\to -\\infty$.\n    Since $P(z)  0$ for large negative $z$ and $P(-2)  0$, by the Intermediate Value Theorem, there must be a real root $z_0  -2$. The magnitude of this zero is $|z_0|  2$, which is outside the unit circle. Thus, $H_d(z)$ is non-minimum-phase. The counterexample is valid.\n\nAll parts of this option are correct.\n\n**Verdict on B: Correct.**\n\n**C. If $T$ is sufficiently small so that $T  1/\\max_{k} p_{k}$, then for every strictly proper, causal, stable, minimum-phase $H_{a}(s)$, the impulse-invariant $H_{d}(z)$ is minimum-phase. No counterexample exists for sufficiently small $T$.**\nThe statement that for a sufficiently small sampling period $T$, the minimum-phase property is preserved is indeed correct. As $T \\to 0$, the impulse-invariance mapping of zeros approaches that of the bilinear transform ($z \\approx 1+sT$), which is known to map the left half-plane to the interior of the unit disk. However, this option fails to provide a counterexample as required by the problem statement. It only makes a claim about a situation where counterexamples do *not* exist. Therefore, it does not fully answer the question.\n\n**Verdict on C: Incorrect.** (Fails to provide a counterexample.)\n\n**D. If $H_{a}(s)$ has no repeated poles and all zeros are strictly in the open left half-plane, then for every $T0$ the impulse-invariant $H_{d}(z)$ is minimum-phase. A counterexample exists only when $H_{a}(s)$ has repeated poles; for example, $H_{a}(s)=\\frac{1}{(s+1)^{2}}$ with $T=1$ yields a non-minimum-phase $H_{d}(z)$.**\nThis option makes two claims.\n1.  **Condition**: The counterexample in option B, $H_a(s)=\\frac{(s+5)(s+6)}{(s+0.1)(s+0.2)(s+0.3)}$, has no repeated poles and is minimum-phase, yet for $T=1$ it produces a non-minimum-phase $H_d(z)$. This directly falsifies the first claim.\n2.  **Counterexample**: Let $H_a(s) = \\frac{1}{(s+1)^2}$. This is a minimum-phase filter (all-pole). The impulse response is $h_a(t) = t e^{-t} u(t)$. The discrete impulse response is $h_d[n] = T(nT)e^{-nT}u[n] = nT^2 (e^{-T})^n u[n]$. The Z-transform is $H_d(z) = T^2 \\sum_{n=0}^\\infty n (e^{-T}z^{-1})^n$. Using the identity $\\sum_{n=0}^{\\infty} n a^n = \\frac{a}{(1-a)^2}$, with $a=e^{-T}z^{-1}$:\n    $$H_d(z) = T^2 \\frac{e^{-T} z^{-1}}{(1 - e^{-T} z^{-1})^2} = \\frac{T^2 e^{-T} z}{(z - e^{-T})^2}$$\n    The only zero of this function is at $z=0$, which is inside the unit disk. Therefore, $H_d(z)$ is minimum-phase for all $T0$. The provided counterexample is incorrect.\n\nBoth claims in this option are false.\n\n**Verdict on D: Incorrect.**\n\n### Conclusion\n\nOption B is the only one that provides correct sufficient conditions for preserving the minimum-phase property and a valid, verifiable counterexample where the property is not preserved.", "answer": "$$\\boxed{B}$$", "id": "2877349"}, {"introduction": "This final practice takes you from theory to computational application by tackling a system identification problem. Given a sampled impulse response, your task is to reverse-engineer the original continuous-time system by estimating its poles [@problem_id:2877423]. This requires implementing a numerical algorithm based on the principles of impulse invariance and confronting the multi-valued nature of the complex logarithm, a crucial step in mapping discrete-time modes back to continuous-time poles.", "problem": "You are given the impulse invariance setting for a continuous-time, linear time-invariant (LTI) rational system with transfer function $H_a(s)$ and impulse response $h_a(t)$. Under uniform sampling with period $T$, the discrete-time impulse response is $h_d[n] = h_a(nT)$ for integer $n \\ge 0$. Assume the continuous-time transfer function $H_a(s)$ is strictly proper with simple poles $\\{p_k\\}_{k=1}^K$ with $\\Re\\{p_k\\}  0$ and residues $\\{R_k\\}_{k=1}^K$, so that the impulse response is a finite sum of exponentials $h_a(t) = \\sum_{k=1}^K R_k e^{p_k t}$. Then $h_d[n] = \\sum_{k=1}^K R_k \\left(e^{p_k T}\\right)^n$. Let $z_k = e^{p_k T}$ denote the discrete-time modes.\n\nFrom the definitions above and the properties of exponentials, the sequence $h_d[n]$ is a finite sum of $K$ complex exponentials, which implies it satisfies a homogeneous linear recurrence with constant coefficients of order $K$ whose characteristic roots are $\\{z_k\\}_{k=1}^K$. This can be exploited to estimate the discrete-time modes $\\{z_k\\}$ from a finite set of samples $\\{h_d[n]\\}_{n=0}^{N-1}$ using a consistent data-driven method such as linear prediction or Pronyâ€™s method. Once $\\{z_k\\}$ are estimated, recovering the continuous-time poles requires selecting a logarithm branch because the complex logarithm is multivalued. A physically meaningful and widely used choice consistent with impulse invariance is to select the branch so that the imaginary parts $\\Im\\{p_k\\}$ lie within the open Nyquist band $(-\\pi/T,\\pi/T]$ and the stability constraint $\\Re\\{p_k\\}  0$ holds. The residues $\\{R_k\\}$ can then be obtained by solving a linear system defined by the exponential model for $h_d[n]$.\n\nTask: Develop a complete program that, given measured discrete-time impulse responses $\\{h_d[n]\\}$, the sampling period $T$ in seconds, and the model order $K$, estimates the continuous-time poles $\\{p_k\\}$ and validates them against ground truth using a quantitative criterion. Your program must:\n\n- Implement a robust procedure to estimate the $K$ discrete-time modes $\\{z_k\\}$ from $\\{h_d[n]\\}$ using only the properties above (sum of exponentials implies a linear annihilating filter).\n- Map $\\{z_k\\}$ to continuous-time poles $\\{p_k\\}$ using a branch selection that enforces the imaginary parts in $(-\\pi/T, \\pi/T]$ (angles in radians) and yields $\\Re\\{p_k\\}  0$ when supported by the data.\n- Estimate the residues $\\{R_k\\}$ by least squares from the exponential model implied by the estimated $\\{z_k\\}$.\n- For evaluation, perform an optimal matching between estimated poles and true poles that minimizes the total absolute error in $\\mathbb{C}$, and declare success if the maximum absolute pole error across the matched set is less than or equal to a specified tolerance $\\varepsilon_p$ (in radians per second).\n\nUse the following test suite. For each case, synthesize $h_d[n]$ from the stated ground-truth poles and residues via $h_d[n] = \\sum_{k=1}^K R_k e^{p_k n T}$ for $n \\in \\{0,1,\\dots,N-1\\}$, then apply your estimation procedure. All angular frequencies must be treated in radians per second, and time in seconds. The tolerance for pole estimation must be $\\varepsilon_p = 1.0 \\times 10^{-1}$ (radians per second).\n\n- Case A (two real poles, noiseless):\n  - $K = 2$, $T = 0.1$ (seconds), $N = 50$ (samples).\n  - Poles: $p = \\{-3.0,\\,-7.0\\}$.\n  - Residues: $R = \\{2.0,\\,-1.0\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case B (one complex-conjugate pair, noiseless):\n  - $K = 2$, $T = 0.05$ (seconds), $N = 120$ (samples).\n  - Poles: $p = \\{-1.0 + 5.0\\,\\mathrm{j},\\,-1.0 - 5.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{1.0 - 0.5\\,\\mathrm{j},\\,1.0 + 0.5\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case C (complex-conjugate pair near the Nyquist boundary, noiseless):\n  - $K = 2$, $T = 0.05$ (seconds), $N = 200$ (samples). Note that $\\pi/T \\approx 62.831853\\ldots$ (radians per second).\n  - Poles: $p = \\{-0.5 + 60.0\\,\\mathrm{j},\\,-0.5 - 60.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{0.3 + 0.2\\,\\mathrm{j},\\,0.3 - 0.2\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case D (three poles with small noise):\n  - $K = 3$, $T = 0.02$ (seconds), $N = 200$ (samples).\n  - Poles: $p = \\{-2.0,\\,-0.5 + 20.0\\,\\mathrm{j},\\,-0.5 - 20.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{1.0,\\,0.6 - 0.2\\,\\mathrm{j},\\,0.6 + 0.2\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 1.0 \\times 10^{-6}$.\n\nEvaluation and output specification:\n\n- For each case, compute the estimated continuous-time poles $\\{\\hat{p}_k\\}$ and match them to ground truth $\\{p_k\\}$ by minimizing the sum of absolute errors $\\sum_k |\\hat{p}_{\\pi(k)} - p_k|$ over all permutations $\\pi$. Let the maximum matched pole error be $e_{\\max} = \\max_k |\\hat{p}_{\\pi(k)} - p_k|$. Declare the case successful if $e_{\\max} \\le \\varepsilon_p$.\n- Your program should produce a single line of output containing the success values for the four cases as a comma-separated list enclosed in square brackets, for example, $[\\text{true},\\text{false},\\text{true},\\text{true}]$, but using Python boolean literals in lowercase.\n\nAll numeric outputs in the internal computations must be consistent with radians for angular quantities and seconds for time. The final printed output must be exactly one line in the specified list format with booleans.", "solution": "We begin from the fundamental model of a continuous-time, linear time-invariant (LTI) rational system with strictly proper transfer function $H_a(s)$. If $H_a(s)$ has simple poles $\\{p_k\\}_{k=1}^K$ with $\\Re\\{p_k\\}  0$ and residues $\\{R_k\\}_{k=1}^K$, then the impulse response is\n$$\nh_a(t) \\;=\\; \\sum_{k=1}^K R_k e^{p_k t},\n$$\na direct consequence of the partial fraction expansion of rational functions and the linearity and time-invariance of the system. Under impulse invariance sampling with sampling period $T$ (seconds), the discrete-time impulse response is\n$$\nh_d[n] \\;=\\; h_a(nT) \\;=\\; \\sum_{k=1}^K R_k \\left(e^{p_k T}\\right)^n \\;=\\; \\sum_{k=1}^K R_k z_k^n,\n$$\nwhere $z_k = e^{p_k T}$ are the discrete-time modes. This expresses $h_d[n]$ as a finite sum of $K$ complex exponentials. A well-tested fact is that any such sequence obeys a homogeneous linear recurrence of order $K$ with constant coefficients: there exist coefficients $\\{a_\\ell\\}_{\\ell=1}^K$ such that for all $n$ in a valid range,\n$$\nh_d[n + K] + \\sum_{\\ell=1}^K a_\\ell\\, h_d[n + K - \\ell] = 0.\n$$\nThe characteristic polynomial of this recurrence,\n$$\nA(z) = z^K + a_1 z^{K-1} + \\cdots + a_K,\n$$\nhas roots at the discrete-time modes $\\{z_k\\}_{k=1}^K$. This follows from substituting a trial solution $h_d[n] = c z^n$ and obtaining $A(z) = 0$.\n\nPrinciple-based estimation of $\\{z_k\\}$: Given a finite set of measured samples $\\{h_d[n]\\}_{n=0}^{N-1}$ and assuming $N$ is sufficiently larger than $K$, we can form a set of $M = N - K$ linear equations of the recurrence. Denote $y[n] = -h_d[n + K]$ and $X[n, \\ell] = h_d[n + K - (\\ell+1)]$ for $\\ell \\in \\{0,1,\\dots,K-1\\}$ and $n \\in \\{0,1,\\dots,M-1\\}$. The linear system $X a \\approx y$ with $a = [a_1,\\dots,a_K]^\\top$ can be solved in the least-squares sense. Once $a$ is estimated, compute the roots of $A(z)$ to obtain $\\{\\hat{z}_k\\}$.\n\nBranch-consistent recovery of $\\{p_k\\}$: The mapping from $z_k$ to $p_k$ is multi-valued because the complex logarithm is multivalued: for any integer $m$, $\\log(z_k) = \\ln|z_k| + \\mathrm{j}(\\arg(z_k) + 2\\pi m)$ is a valid branch. The physically meaningful branch under impulse invariance assumes that analog frequencies are in the Nyquist band and thus chooses the branch whose imaginary parts lie in $(-\\pi/T,\\pi/T]$. A consistent way to achieve this is:\n- Compute the magnitude $|z_k|$ and principal argument $\\arg(z_k) \\in (-\\pi,\\pi]$.\n- Form $\\hat{p}_k = \\dfrac{\\ln|z_k| + \\mathrm{j}\\,\\arg(z_k)}{T}$, which places $\\Im\\{\\hat{p}_k\\}$ in $(-\\pi/T,\\pi/T]$ due to the principal value of the argument. This delivers the branch selection aligned with the Nyquist band. Because $|z_k| = e^{\\Re\\{p_k\\} T}$, stable continuous-time poles yield $|z_k|  1$ and thus $\\Re\\{\\hat{p}_k\\}  0$ in the absence of noise.\n\nResidue estimation: With $\\{\\hat{z}_k\\}$ in hand, fit residues $\\{\\hat{R}_k\\}$ to the model $h_d[n] \\approx \\sum_{k=1}^K \\hat{R}_k \\hat{z}_k^n$ by solving a linear least-squares problem. Using the Vandermonde-like matrix $V \\in \\mathbb{C}^{N \\times K}$ with entries $V[n,k] = \\hat{z}_k^n$ for $n \\in \\{0,\\dots,N-1\\}$ and $k \\in \\{1,\\dots,K\\}$, solve $V \\hat{R} \\approx h_d$ in the least-squares sense.\n\nMatching and validation: To compare the estimated poles $\\{\\hat{p}_k\\}$ with ground-truth $\\{p_k\\}$, a permutation-invariant comparison is required. Construct the cost matrix $C \\in \\mathbb{R}^{K \\times K}$ with $C_{ij} = |\\hat{p}_j - p_i|$, then solve the linear sum assignment (Hungarian) problem to find the permutation that minimizes the total absolute error. Let $e_{\\max}$ be the maximum absolute error under this optimal pairing. A test case is declared successful if $e_{\\max} \\le \\varepsilon_p$. Here the tolerance is set to $\\varepsilon_p = 1.0 \\times 10^{-1}$ (radians per second), balancing numerical sensitivity and model identifiability.\n\nAlgorithmic and numerical considerations:\n- Data length $N$ must satisfy $N \\ge 2K$ to ensure at least $K$ equations for a $K$-parameter recurrence, and in practice one uses $N \\gg K$ for robustness.\n- The least-squares solution of the annihilating filter coefficients and of the residues should be computed using numerically stable methods (for example, the singular value decomposition) provided by standard linear algebra routines.\n- The principal argument function $\\arg(\\cdot)$ returns values in $(-\\pi,\\pi]$, ensuring the imaginary parts of $\\hat{p}_k$ lie in $(-\\pi/T,\\pi/T]$, consistent with the Nyquist band assumption of impulse invariance. If noise causes small violations of stability (for example, $\\Re\\{\\hat{p}_k\\} > 0$ slightly), the mismatch will typically be minor and can be tolerated within the tolerance.\n- Complex-conjugate pole pairs with conjugate residues generate real $h_d[n]$. The estimator does not need to explicitly enforce conjugacy; it will typically recover approximate conjugate pairs due to the structure of the data.\n\nTest suite construction:\n- Case A uses two real poles with $K = 2$, $T = 0.1$ (seconds), $N = 50$, zero noise, poles $\\{-3.0,\\,-7.0\\}$, residues $\\{2.0,\\,-1.0\\}$. This verifies basic recovery for real exponentials.\n- Case B uses one complex-conjugate pair with $K = 2$, $T = 0.05$ (seconds), $N = 120$, zero noise, poles $\\{-1.0 \\pm 5.0\\,\\mathrm{j}\\}$, residues $\\{1.0 \\mp 0.5\\,\\mathrm{j}\\}$. This verifies branch handling and complex modes.\n- Case C uses a pair near the Nyquist boundary with $K = 2$, $T = 0.05$ (seconds), $N = 200$, zero noise, poles $\\{-0.5 \\pm 60.0\\,\\mathrm{j}\\}$, residues $\\{0.3 \\pm 0.2\\,\\mathrm{j}\\}$. Since $\\pi/T \\approx 62.831853\\ldots$ (radians per second), the imaginary parts lie inside the band, testing sensitivity to near-boundary angles.\n- Case D uses three poles with small additive noise with $K = 3$, $T = 0.02$ (seconds), $N = 200$, $\\sigma = 1.0 \\times 10^{-6}$, poles $\\{-2.0,\\,-0.5 \\pm 20.0\\,\\mathrm{j}\\}$, and residues $\\{1.0,\\,0.6 \\mp 0.2\\,\\mathrm{j}\\}$. This tests multi-mode recovery under slight perturbations.\n\nFinal program behavior: For each case, synthesize $h_d[n]$, estimate $\\{\\hat{z}_k\\}$, map to $\\{\\hat{p}_k\\}$ with branch selection in the Nyquist band, estimate residues $\\{\\hat{R}_k\\}$, perform optimal pole matching with the ground truth, and emit a boolean indicating whether $e_{\\max} \\le \\varepsilon_p$. The program prints a single line with the booleans for the four cases as a Python list, for example `[true,true,true,true]`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef generate_hd(poles, residues, T, N, noise_sigma=0.0, rng=None):\n    \"\"\"\n    Generate discrete-time impulse response h_d[n] = sum R_k * exp(p_k * T * n)\n    \"\"\"\n    n = np.arange(N, dtype=float)\n    h = np.zeros(N, dtype=complex)\n    for p, R in zip(poles, residues):\n        h += R * np.exp(p * T * n)\n    if noise_sigma > 0.0:\n        if rng is None:\n            rng = np.random.default_rng(0)\n        # Add real-valued Gaussian noise to keep output real if underlying signal is real\n        noise = noise_sigma * rng.standard_normal(N)\n        h = h + noise\n    return h\n\ndef prony_estimate_z(h, K):\n    \"\"\"\n    Estimate discrete-time modes z_k from sequence h using linear prediction (Prony).\n    h: 1-D numpy array (complex or real)\n    K: model order\n    Returns: array of K roots (z_k)\n    \"\"\"\n    h = np.asarray(h, dtype=complex).ravel()\n    N = h.shape[0]\n    M = N - K\n    if M = K:\n        raise ValueError(\"Insufficient data length N relative to model order K.\")\n    # Build least-squares system X a = y, where\n    # y[n] = -h[n+K], X[n, i] = h[n+K-(i+1)] for i=0..K-1\n    X = np.zeros((M, K), dtype=complex)\n    y = -h[K:K+M]\n    for n in range(M):\n        for i in range(K):\n            X[n, i] = h[n + K - (i + 1)]\n    # Solve for a (prediction coefficients)\n    a, *_ = np.linalg.lstsq(X, y, rcond=None)\n    # Characteristic polynomial A(z) = z^K + a1 z^{K-1} + ... + aK\n    poly_coeffs = np.concatenate(([1.0], a))\n    # Roots\n    z_roots = np.roots(poly_coeffs)\n    return z_roots\n\ndef estimate_residues(h, z):\n    \"\"\"\n    Given sequence h[n] and modes z_k, estimate residues R_k in h[n] ~ sum R_k z_k^n\n    via least squares.\n    \"\"\"\n    h = np.asarray(h, dtype=complex).ravel()\n    N = h.shape[0]\n    K = len(z)\n    n = np.arange(N, dtype=float)[:, None]  # shape (N,1)\n    V = (z[None, :] ** n)  # Vandermonde-like matrix\n    R, *_ = np.linalg.lstsq(V, h, rcond=None)\n    return R\n\ndef map_z_to_p(z, T):\n    \"\"\"\n    Map discrete-time modes z to continuous-time poles p using branch selection\n    in the Nyquist band: p = (ln|z| + j*angle(z)) / T, where angle in (-pi, pi].\n    \"\"\"\n    z = np.asarray(z, dtype=complex)\n    mags = np.abs(z)\n    angs = np.angle(z)  # principal value (-pi, pi]\n    p = (np.log(mags) + 1j * angs) / T\n    return p\n\ndef match_poles(p_true, p_est):\n    \"\"\"\n    Match estimated poles to true poles by minimizing total absolute difference.\n    Returns the permutation indices for p_est to match p_true, and the errors.\n    \"\"\"\n    p_true = np.asarray(p_true, dtype=complex)\n    p_est = np.asarray(p_est, dtype=complex)\n    K = len(p_true)\n    cost = np.abs(p_true[:, None] - p_est[None, :])\n    row_ind, col_ind = linear_sum_assignment(cost)\n    errs = np.abs(p_true[row_ind] - p_est[col_ind])\n    return col_ind, errs\n\ndef run_case(poles, residues, T, N, K, noise_sigma=0.0, eps_p=1e-1, rng=None):\n    h = generate_hd(poles, residues, T, N, noise_sigma=noise_sigma, rng=rng)\n    # Estimate z modes\n    z_est = prony_estimate_z(h, K)\n    # Map to continuous-time poles with branch selection in Nyquist band\n    p_est = map_z_to_p(z_est, T)\n    # Estimate residues (not used for validation here, but computed as part of the requested procedure)\n    _ = estimate_residues(h, z_est)\n    # Match estimated poles to true poles\n    _, errs = match_poles(np.array(poles, dtype=complex), p_est)\n    emax = float(np.max(errs)) if errs.size > 0 else float('inf')\n    return emax = eps_p\n\ndef solve():\n    # Fixed RNG for reproducibility of noise in Case D\n    rng = np.random.default_rng(12345)\n    eps_p = 1.0e-1  # radians per second\n\n    # Define the test cases\n    test_cases = [\n        # Case A\n        {\n            \"poles\": np.array([-3.0 + 0.0j, -7.0 + 0.0j], dtype=complex),\n            \"residues\": np.array([2.0 + 0.0j, -1.0 + 0.0j], dtype=complex),\n            \"T\": 0.1,\n            \"N\": 50,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case B\n        {\n            \"poles\": np.array([-1.0 + 5.0j, -1.0 - 5.0j], dtype=complex),\n            \"residues\": np.array([1.0 - 0.5j, 1.0 + 0.5j], dtype=complex),\n            \"T\": 0.05,\n            \"N\": 120,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case C\n        {\n            \"poles\": np.array([-0.5 + 60.0j, -0.5 - 60.0j], dtype=complex),\n            \"residues\": np.array([0.3 + 0.2j, 0.3 - 0.2j], dtype=complex),\n            \"T\": 0.05,\n            \"N\": 200,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case D\n        {\n            \"poles\": np.array([-2.0 + 0.0j, -0.5 + 20.0j, -0.5 - 20.0j], dtype=complex),\n            \"residues\": np.array([1.0 + 0.0j, 0.6 - 0.2j, 0.6 + 0.2j], dtype=complex),\n            \"T\": 0.02,\n            \"N\": 200,\n            \"K\": 3,\n            \"noise_sigma\": 1.0e-6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        ok = run_case(\n            poles=case[\"poles\"],\n            residues=case[\"residues\"],\n            T=case[\"T\"],\n            N=case[\"N\"],\n            K=case[\"K\"],\n            noise_sigma=case[\"noise_sigma\"],\n            eps_p=eps_p,\n            rng=rng\n        )\n        results.append(ok)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda x: str(x).lower(), results))}]\")\n\nsolve()\n```", "id": "2877423"}]}