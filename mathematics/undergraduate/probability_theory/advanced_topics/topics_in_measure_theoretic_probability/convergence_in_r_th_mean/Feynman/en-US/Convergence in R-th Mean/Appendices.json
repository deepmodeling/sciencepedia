{
    "hands_on_practices": [
        {
            "introduction": "Understanding convergence often begins with applying the core definitions to familiar probability distributions. This first exercise provides a practical scenario involving Poisson random variables, which are often used to model the number of events in a fixed interval. By verifying convergence in mean square for a sequence of Poisson variables whose rate parameter approaches zero, you will practice connecting the abstract concept of convergence to the concrete properties of mean and variance. ",
            "id": "1353612",
            "problem": "A team of data scientists is monitoring the daily number of failed login attempts on a secure server. They model the number of failures on day $n$ (for $n=1, 2, 3, \\ldots$) as a random variable $X_n$. Based on security improvements over time, they hypothesize that the expected number of failures decreases. They choose a Poisson distribution for $X_n$ with a rate parameter $\\lambda_n = \\frac{1}{n}$.\n\nTo assess if the number of failures is effectively tending to zero over the long run, they decide to check for convergence in mean square. This involves evaluating if the expected squared difference between $X_n$ and the target value of 0 diminishes to nothing.\n\nCalculate the limit of the mean square difference between $X_n$ and 0. That is, compute the value of $L = \\lim_{n \\to \\infty} E[(X_n - 0)^2]$.",
            "solution": "We are given that $X_{n}\\sim \\text{Poisson}(\\lambda_{n})$ with $\\lambda_{n}=\\frac{1}{n}$ for $n\\in\\{1,2,3,\\ldots\\}$. The quantity of interest is the mean square difference from $0$, which equals the second moment:\n$$\nE\\big[(X_{n}-0)^{2}\\big]=E\\big[X_{n}^{2}\\big].\n$$\nFor any random variable, the identity $E[X^{2}]=\\operatorname{Var}(X)+\\big(E[X]\\big)^{2}$ holds. For a Poisson random variable with parameter $\\lambda$, it is a standard result that\n$$\nE[X]=\\lambda,\\qquad \\operatorname{Var}(X)=\\lambda.\n$$\nApplying this to $X_{n}$ with $\\lambda_{n}=\\frac{1}{n}$, we obtain\n$$\nE[X_{n}^{2}]=\\operatorname{Var}(X_{n})+\\big(E[X_{n}]\\big)^{2}=\\lambda_{n}+\\lambda_{n}^{2}=\\frac{1}{n}+\\frac{1}{n^{2}}.\n$$\nTherefore,\n$$\nL=\\lim_{n\\to\\infty}E\\big[(X_{n}-0)^{2}\\big]=\\lim_{n\\to\\infty}\\left(\\frac{1}{n}+\\frac{1}{n^{2}}\\right)=0.\n$$",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Indicator random variables are a cornerstone of modern probability, simplifying complex problems by breaking them down into binary outcomes. This practice problem utilizes indicator variables to model a sequence of events whose probabilities vanish over time. This will help you solidify your understanding of how to calculate expected values for these simple yet powerful variables and see how their properties directly inform the convergence of the sequence. ",
            "id": "1353629",
            "problem": "Consider a sequence of experiments indexed by the positive integer $n=1, 2, 3, \\dots$. In the $n$-th experiment, a particle is generated, and we are interested in whether it possesses a specific quantum property. Let $A_n$ be the event that the particle generated in the $n$-th experiment possesses this property. The probability of this event is given by $P(A_n) = \\frac{1}{\\sqrt{n}}$.\n\nFor each experiment, we define a random variable $X_n$ such that $X_n = 1$ if event $A_n$ occurs, and $X_n = 0$ if event $A_n$ does not occur. We want to determine if this sequence of random variables, $\\{X_n\\}$, converges in the long run to the random variable $X$ that is identically zero.\n\nWhich of the following statements is correct regarding the convergence of the sequence $\\{X_n\\}$ to $X=0$ in mean square?\n\nA. The sequence converges to 0 in mean square.\n\nB. The sequence does not converge to 0 in mean square.\n\nC. The sequence converges to 1 in mean square.\n\nD. Convergence cannot be determined from the given information because the joint probabilities $P(A_n \\cap A_m)$ are not specified.",
            "solution": "Convergence in mean square to a random variable $X$ means that $\\lim_{n\\to\\infty}\\mathbb{E}\\big[(X_{n}-X)^{2}\\big]=0$. Here $X\\equiv 0$, so we need $\\mathbb{E}\\big[X_{n}^{2}\\big]\\to 0$.\n\nEach $X_{n}$ is an indicator variable for $A_{n}$, hence $X_{n}^{2}=X_{n}$. Therefore,\n$$\n\\mathbb{E}\\big[X_{n}^{2}\\big]=\\mathbb{E}[X_{n}]=\\mathbb{P}(A_{n})=\\frac{1}{\\sqrt{n}}.\n$$\nSince $\\frac{1}{\\sqrt{n}}\\to 0$ as $n\\to\\infty$, it follows that $\\mathbb{E}\\big[(X_{n}-0)^{2}\\big]\\to 0$, so $X_{n}\\to 0$ in mean square. This conclusion uses only the marginal probabilities and does not require any information about joint probabilities $\\mathbb{P}(A_{n}\\cap A_{m})$.\n\nTherefore, the correct choice is A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The theory of convergence has its nuances, and not all modes of convergence are equivalent. This exercise presents a crucial and illustrative example where a sequence of random variables converges in the mean ($L^1$) but fails to converge in the quadratic mean ($L^2$). By working through this problem, you will gain a deeper appreciation for the hierarchy of convergence modes and understand that convergence in $r$-th mean is a stronger statement for larger values of $r$. ",
            "id": "1353588",
            "problem": "Let $U$ be a random variable that is uniformly distributed on the interval $(0, 1)$. Consider a sequence of random variables $\\{X_n\\}_{n=1}^{\\infty}$ defined by\n$$X_n = \\sqrt{n} \\cdot I_{\\{U  1 - 1/n\\}}$$\nwhere $I_A$ is the indicator function for an event $A$, meaning $I_A$ takes the value 1 if the event $A$ occurs, and 0 otherwise.\n\nWe are interested in whether this sequence converges to the constant random variable $X=0$. We will consider two specific modes of convergence:\n\n1.  **Convergence in the mean** (or $L^1$ convergence): The sequence $\\{X_n\\}$ converges to $X$ in the mean if $\\lim_{n \\to \\infty} E[|X_n - X|] = 0$.\n2.  **Convergence in the quadratic mean** (or $L^2$ convergence): The sequence $\\{X_n\\}$ converges to $X$ in the quadratic mean if $\\lim_{n \\to \\infty} E[|X_n - X|^2] = 0$.\n\nWhich of the following statements is true regarding the convergence of the sequence $\\{X_n\\}$ to the zero random variable, $X=0$?\n\nA. $X_n$ converges to 0 in the mean and also in the quadratic mean.\n\nB. $X_n$ converges to 0 in the mean, but not in the quadratic mean.\n\nC. $X_n$ does not converge to 0 in the mean, but it does converge in the quadratic mean.\n\nD. $X_n$ converges to 0 neither in the mean nor in the quadratic mean.",
            "solution": "Let $A_{n}=\\{U1-\\frac{1}{n}\\}$. Since $U$ is uniformly distributed on $(0,1)$, the probability of an interval equals its length, hence\n$$\n\\mathbb{P}(A_{n})=\\mathbb{P}\\!\\left(U\\in\\left(1-\\frac{1}{n},1\\right)\\right)=1-\\left(1-\\frac{1}{n}\\right)=\\frac{1}{n}.\n$$\nBy definition, $X_{n}=\\sqrt{n}\\,I_{A_{n}}$. Using the fact that for any event $A$, $E[I_{A}]=\\mathbb{P}(A)$, we obtain the $L^{1}$ moment\n$$\nE|X_{n}|=E\\left[\\sqrt{n}\\,I_{A_{n}}\\right]=\\sqrt{n}\\,E[I_{A_{n}}]=\\sqrt{n}\\,\\mathbb{P}(A_{n})=\\sqrt{n}\\cdot\\frac{1}{n}=\\frac{1}{\\sqrt{n}}\\to 0,\n$$\nso $X_{n}\\to 0$ in the mean.\n\nFor quadratic mean, compute $E|X_{n}|^{2}=E[X_{n}^{2}]$. Since $X_{n}^{2}=n\\,I_{A_{n}}$, we have\n$$\nE[X_{n}^{2}]=E\\left[n\\,I_{A_{n}}\\right]=n\\,E[I_{A_{n}}]=n\\,\\mathbb{P}(A_{n})=n\\cdot\\frac{1}{n}=1,\n$$\nwhich does not converge to $0$. Hence $X_{n}$ does not converge to $0$ in the quadratic mean.\n\nTherefore, the correct statement is that $X_{n}$ converges to $0$ in the mean but not in the quadratic mean.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}