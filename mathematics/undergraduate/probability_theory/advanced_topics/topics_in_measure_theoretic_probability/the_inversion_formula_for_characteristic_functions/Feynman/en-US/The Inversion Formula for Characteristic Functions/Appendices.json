{
    "hands_on_practices": [
        {
            "introduction": "The inversion formula is a powerful bridge connecting the frequency-domain representation of a random variable (its characteristic function) to its spatial representation (its probability density function). This first practice provides a direct application of the continuous inversion formula. By starting with a simple, yet non-trivial, triangular characteristic function, you will perform the necessary integration to uncover the corresponding PDF, offering a hands-on look at this fundamental transformation. ",
            "id": "1399489",
            "problem": "Let $X$ be a continuous random variable. The characteristic function of $X$, denoted by $\\phi_X(t)$, is defined as the expected value of $\\exp(itX)$, where $t$ is a real number and $i$ is the imaginary unit.\n\nSuppose the characteristic function for $X$ is given by the triangular function:\n$$ \\phi_X(t) = \\max(0, 1-|t|) $$\nDetermine the probability density function (PDF), $f_X(x)$, corresponding to this characteristic function. Present your answer as a function of $x$.",
            "solution": "We use the Fourier inversion formula for characteristic functions. By definition, $\\phi_{X}(t) = \\int_{-\\infty}^{\\infty} \\exp(i t x) f_{X}(x)\\,dx$, and when $\\phi_{X}$ is integrable, the density is recovered by\n$$\nf_{X}(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\exp(-i t x)\\,\\phi_{X}(t)\\,dt.\n$$\nHere $\\phi_{X}(t) = \\max(0, 1 - |t|) = (1 - |t|)\\mathbf{1}_{\\{|t|\\leq 1\\}}$, so\n$$\nf_{X}(x) = \\frac{1}{2\\pi} \\int_{-1}^{1} (1 - |t|)\\,\\exp(-i t x)\\,dt.\n$$\nThe integrand is even in $t$ after taking the real part, hence\n$$\nf_{X}(x) = \\frac{1}{\\pi} \\int_{0}^{1} (1 - t)\\,\\cos(t x)\\,dt.\n$$\nCompute the integral by splitting and integrating by parts:\n$$\n\\int_{0}^{1} (1 - t)\\cos(tx)\\,dt = \\int_{0}^{1} \\cos(tx)\\,dt - \\int_{0}^{1} t\\cos(tx)\\,dt.\n$$\nThe first term is\n$$\n\\int_{0}^{1} \\cos(tx)\\,dt = \\frac{\\sin(x)}{x}.\n$$\nFor the second term, integrate by parts with $u = t$ and $dv = \\cos(tx)\\,dt$, so $du = dt$ and $v = \\frac{\\sin(tx)}{x}$. Then\n$$\n\\int_{0}^{1} t\\cos(tx)\\,dt = \\left.\\frac{t\\sin(tx)}{x}\\right|_{0}^{1} - \\int_{0}^{1} \\frac{\\sin(tx)}{x}\\,dt = \\frac{\\sin(x)}{x} - \\frac{1}{x}\\int_{0}^{1} \\sin(tx)\\,dt.\n$$\nEvaluate the remaining integral:\n$$\n\\int_{0}^{1} \\sin(tx)\\,dt = \\left.-\\frac{\\cos(tx)}{x}\\right|_{0}^{1} = \\frac{1 - \\cos(x)}{x}.\n$$\nTherefore,\n$$\n\\int_{0}^{1} t\\cos(tx)\\,dt = \\frac{\\sin(x)}{x} - \\frac{1 - \\cos(x)}{x^{2}}.\n$$\nSubtracting gives\n$$\n\\int_{0}^{1} (1 - t)\\cos(tx)\\,dt = \\frac{\\sin(x)}{x} - \\left(\\frac{\\sin(x)}{x} - \\frac{1 - \\cos(x)}{x^{2}}\\right) = \\frac{1 - \\cos(x)}{x^{2}}.\n$$\nHence\n$$\nf_{X}(x) = \\frac{1}{\\pi}\\cdot \\frac{1 - \\cos(x)}{x^{2}}.\n$$\nUsing the identity $1 - \\cos(x) = 2\\sin^{2}(x/2)$, an equivalent nonnegative form is\n$$\nf_{X}(x) = \\frac{2}{\\pi}\\,\\frac{\\sin^{2}(x/2)}{x^{2}},\n$$\nwith the continuous extension at $x = 0$ equal to $\\lim_{x\\to 0} f_{X}(x) = \\frac{1}{2\\pi}$.",
            "answer": "$$\\boxed{f_{X}(x)=\\frac{2}{\\pi}\\,\\frac{\\sin^{2}\\!\\left(\\frac{x}{2}\\right)}{x^{2}}}$$"
        },
        {
            "introduction": "While the principle remains the same, applying the inversion formula to discrete random variables often involves a different set of mathematical tools. This exercise demonstrates how to recover a probability mass function (PMF) from its characteristic function, specifically for one of the most important distributions in probability theory. You will use a combination of series expansion and the orthogonality of complex exponentials to derive the PMF of the Poisson distribution, a technique central to Fourier analysis. ",
            "id": "1399475",
            "problem": "Let $X$ be a discrete random variable that can take any non-negative integer value $k$, where $k \\in \\{0, 1, 2, \\dots\\}$. The characteristic function of $X$ is given by\n$$\n\\phi_X(t) = \\exp(\\lambda(e^{it}-1))\n$$\nwhere $t$ is a real number and $\\lambda$ is a positive real constant.\n\nUsing the properties of characteristic functions, determine the probability mass function (PMF), $P(X=k)$, for this random variable. Express your answer as a function of the integer $k$ and the constant $\\lambda$.",
            "solution": "The problem asks for the probability mass function (PMF), $P(X=k)$, of a discrete random variable $X$ given its characteristic function $\\phi_X(t)$. For a discrete random variable taking integer values, the PMF can be recovered from the characteristic function using the Fourier inversion formula:\n$$\nP(X=k) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\phi_X(t) dt\n$$\nWe are given $\\phi_X(t) = \\exp(\\lambda(e^{it}-1))$. Substituting this into the inversion formula gives:\n$$\nP(X=k) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\exp(\\lambda(e^{it}-1)) dt\n$$\nWe can separate the exponential term into two parts:\n$$\n\\exp(\\lambda(e^{it}-1)) = \\exp(\\lambda e^{it} - \\lambda) = \\exp(-\\lambda) \\exp(\\lambda e^{it})\n$$\nThe term $\\exp(-\\lambda)$ is a constant with respect to $t$, so it can be moved outside the integral.\n$$\nP(X=k) = \\frac{\\exp(-\\lambda)}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\exp(\\lambda e^{it}) dt\n$$\nNow, we can expand the term $\\exp(\\lambda e^{it})$ using its Maclaurin series expansion, $e^z = \\sum_{n=0}^{\\infty} \\frac{z^n}{n!}$, with $z = \\lambda e^{it}$:\n$$\n\\exp(\\lambda e^{it}) = \\sum_{n=0}^{\\infty} \\frac{(\\lambda e^{it})^n}{n!} = \\sum_{n=0}^{\\infty} \\frac{\\lambda^n e^{int}}{n!}\n$$\nSubstitute this series back into the integral expression for $P(X=k)$:\n$$\nP(X=k) = \\frac{\\exp(-\\lambda)}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\left( \\sum_{n=0}^{\\infty} \\frac{\\lambda^n e^{int}}{n!} \\right) dt\n$$\nAssuming uniform convergence of the series, we can interchange the order of integration and summation:\n$$\nP(X=k) = \\frac{\\exp(-\\lambda)}{2\\pi} \\sum_{n=0}^{\\infty} \\frac{\\lambda^n}{n!} \\int_{-\\pi}^{\\pi} e^{-ikt} e^{int} dt\n$$\nCombine the exponential terms inside the integral:\n$$\nP(X=k) = \\frac{\\exp(-\\lambda)}{2\\pi} \\sum_{n=0}^{\\infty} \\frac{\\lambda^n}{n!} \\int_{-\\pi}^{\\pi} e^{i(n-k)t} dt\n$$\nNow we evaluate the integral $\\int_{-\\pi}^{\\pi} e^{i(n-k)t} dt$. We must consider two cases based on the value of the integer $n-k$.\n\nCase 1: $n \\neq k$. In this case, $n-k$ is a non-zero integer.\n$$\n\\int_{-\\pi}^{\\pi} e^{i(n-k)t} dt = \\left[ \\frac{e^{i(n-k)t}}{i(n-k)} \\right]_{-\\pi}^{\\pi} = \\frac{e^{i(n-k)\\pi} - e^{-i(n-k)\\pi}}{i(n-k)}\n$$\nUsing Euler's formula, $e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta)$, the numerator becomes $2i\\sin((n-k)\\pi)$. Since $n-k$ is a non-zero integer, $\\sin((n-k)\\pi) = 0$. Therefore, the integral evaluates to 0 for $n \\neq k$.\n\nCase 2: $n = k$. In this case, $n-k = 0$.\n$$\n\\int_{-\\pi}^{\\pi} e^{i(0)t} dt = \\int_{-\\pi}^{\\pi} e^0 dt = \\int_{-\\pi}^{\\pi} 1 dt = [t]_{-\\pi}^{\\pi} = \\pi - (-\\pi) = 2\\pi\n$$\nThis means that the integral acts as an orthogonal filter. It is zero for all terms in the summation except for the single term where $n=k$. The infinite sum collapses to just this one term.\n\nSubstituting this result back into the expression for $P(X=k)$:\n$$\nP(X=k) = \\frac{\\exp(-\\lambda)}{2\\pi} \\left( \\frac{\\lambda^k}{k!} \\times 2\\pi \\right)\n$$\nAll other terms in the summation are multiplied by zero. The $2\\pi$ terms cancel out, leaving the final expression for the PMF:\n$$\nP(X=k) = \\frac{\\exp(-\\lambda) \\lambda^k}{k!}\n$$\nThis is the probability mass function for a Poisson distribution with parameter $\\lambda$.",
            "answer": "$$\\boxed{\\frac{\\exp(-\\lambda) \\lambda^k}{k!}}$$"
        },
        {
            "introduction": "The inversion formula is not just a computational tool; it is also a powerful diagnostic for verifying the theoretical properties of a function. This practice turns the tables: instead of deriving a known distribution, you will use the formula to test whether a given function can legally serve as a characteristic function. By calculating the 'probability' for a specific outcome and finding a non-physical result, you will demonstrate a crucial consequence of the inversion theorem and deepen your understanding of the conditions a characteristic function must satisfy. ",
            "id": "1399516",
            "problem": "In probability theory, the characteristic function of a random variable completely defines its probability distribution. For a discrete random variable $X$ that takes on integer values, its characteristic function is defined as $\\phi_X(t) = E[\\exp(itX)]$, where $t$ is a real number and $i$ is the imaginary unit.\n\nGiven the characteristic function $\\phi_X(t)$, the probability mass function (PMF), $P(X=k)$, for any integer $k$ can be recovered using the discrete inversion formula:\n$$P(X=k) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\phi_X(t) dt$$\nA fundamental axiom of probability is that the probability of any event must be non-negative. Therefore, for a function to be a valid characteristic function of a discrete random variable, the inversion formula must yield $P(X=k) \\ge 0$ for all integers $k$.\n\nConsider the real-valued function $\\phi(t) = \\frac{3}{2}\\cos(t) - \\frac{1}{2}$. We wish to investigate whether this can be a valid characteristic function for some integer-valued random variable $X$.\n\nUsing the discrete inversion formula, calculate the value of the probability mass that would correspond to the outcome $X=0$, assuming $\\phi(t)$ is the characteristic function of $X$. Express your answer as a fraction.",
            "solution": "The problem asks us to calculate the value of the probability mass function (PMF) at $k=0$, denoted as $P(X=0)$, for a hypothetical integer-valued random variable $X$ whose characteristic function is given by $\\phi(t) = \\frac{3}{2}\\cos(t) - \\frac{1}{2}$.\n\nThe discrete inversion formula is provided as:\n$$P(X=k) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-ikt} \\phi_X(t) dt$$\nTo find $P(X=0)$, we set $k=0$ in the formula:\n$$P(X=0) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-i(0)t} \\phi(t) dt$$\nSince $e^0 = 1$, the expression simplifies to:\n$$P(X=0) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\phi(t) dt$$\nNow, we substitute the given function $\\phi(t) = \\frac{3}{2}\\cos(t) - \\frac{1}{2}$ into the integral:\n$$P(X=0) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\left( \\frac{3}{2}\\cos(t) - \\frac{1}{2} \\right) dt$$\nWe can solve this by evaluating the integral directly, or by using Euler's formula for the cosine function, which is often more systematic when dealing with characteristic functions. Let's use Euler's formula: $\\cos(t) = \\frac{e^{it} + e^{-it}}{2}$.\n\nSubstituting Euler's formula into our expression for $\\phi(t)$:\n$$\\phi(t) = \\frac{3}{2} \\left( \\frac{e^{it} + e^{-it}}{2} \\right) - \\frac{1}{2} = \\frac{3}{4}e^{it} + \\frac{3}{4}e^{-it} - \\frac{1}{2}$$\nNow, we substitute this form of $\\phi(t)$ back into our integral for $P(X=0)$:\n$$P(X=0) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\left( \\frac{3}{4}e^{it} + \\frac{3}{4}e^{-it} - \\frac{1}{2} \\right) dt$$\nBy the linearity of integration, we can split this into three separate integrals:\n$$P(X=0) = \\frac{3}{4} \\left( \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{it} dt \\right) + \\frac{3}{4} \\left( \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-it} dt \\right) - \\frac{1}{2} \\left( \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} 1 dt \\right)$$\nWe use the fundamental orthogonality property of complex exponentials over the interval $[-\\pi, \\pi]$:\n$$\\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{int} dt = \\begin{cases} 1 & \\text{if } n=0 \\\\ 0 & \\text{if } n \\text{ is a non-zero integer} \\end{cases}$$\nLet's apply this to each term.\n\nFor the first term, we have $n=1$:\n$$\\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{it} dt = 0$$\nFor the second term, we have $n=-1$:\n$$\\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} e^{-it} dt = 0$$\nFor the third term, the integrand is $1 = e^{i(0)t}$, so we have $n=0$:\n$$\\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} 1 dt = 1$$\nSubstituting these results back into the expression for $P(X=0)$:\n$$P(X=0) = \\frac{3}{4}(0) + \\frac{3}{4}(0) - \\frac{1}{2}(1)$$\n$$P(X=0) = -\\frac{1}{2}$$\nThe calculation shows that if $\\phi(t)$ were a characteristic function, the probability of the outcome $X=0$ would be $-1/2$. Since probabilities must be non-negative, this demonstrates that $\\phi(t) = \\frac{3}{2}\\cos(t) - \\frac{1}{2}$ cannot be a valid characteristic function for any random variable.",
            "answer": "$$\\boxed{-\\frac{1}{2}}$$"
        }
    ]
}