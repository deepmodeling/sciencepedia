{"hands_on_practices": [{"introduction": "Understanding the power of Successive Cancellation List (SCL) decoding begins with appreciating its trade-offs. While adding a list of candidate paths significantly improves error correction, it doesn't come for free. This first practice invites you to analyze the computational price of this enhancement by dissecting the algorithm's steps, giving you a firm grasp on how the block length $N$ and list size $L$ dictate the overall decoding complexity [@problem_id:1637429].", "problem": "An engineer is designing a communication system using polar codes, a class of error-correcting codes with a block length $N$ that is a power of two, i.e., $N=2^n$ for some integer $n$. The standard decoding algorithm, known as Successive Cancellation (SC) decoding, estimates the $N$ transmitted bits one by one. The total computational complexity required for the SC decoder to process the entire block is on the order of $O(N \\log N)$.\n\nTo enhance the system's reliability, the engineer considers using Successive Cancellation List (SCL) decoding. This algorithm improves upon SC by maintaining a list of $L$ different candidate decoding paths simultaneously. For each of the $N$ bits to be decoded in sequence, the SCL decoder performs the following operation: for each of the (at most) $L$ paths currently on the list, it extends the path by considering both possibilities for the current bit (a '0' and a '1'). This temporarily creates up to $2L$ paths. It then calculates a quality metric for each of these new paths and prunes the list back down to size $L$ by keeping only the $L$ paths with the best metrics. This process is repeated for all $N$ bits.\n\nThe core computational work in SC decoding for a single bit decision is proportional to $\\log N$. In SCL, this core work must be performed for each of the $L$ candidate paths. The additional step of managing, sorting, and pruning the list from $2L$ candidates down to $L$ at each of the $N$ stages is found to have a complexity that is also proportional to $L$.\n\nGiven this description, which of the following expressions best characterizes the total computational complexity of SCL decoding with a list size $L$ and block length $N$?\n\nA. $O(LN)$\n\nB. $O(N \\log N)$\n\nC. $O(N + L \\log N)$\n\nD. $O(L N \\log N)$\n\nE. $O(L^2 N \\log N)$", "solution": "The problem asks for the total computational complexity of Successive Cancellation List (SCL) decoding for a polar code of block length $N$ and list size $L$. We can determine this by analyzing the work done at each stage of the decoding process and summing it over all stages.\n\nThe decoding process consists of $N$ sequential stages, one for each bit to be estimated. Let's analyze the complexity of a single stage, say stage $i$ where $1 \\le i \\le N$.\n\nAccording to the problem description, at each stage, the SCL decoder operates on a list of up to $L$ candidate paths. The work performed at a single stage can be broken down into two main parts:\n1.  **Path Extension and Likelihood Calculation:** The standard Successive Cancellation (SC) decoder requires work proportional to $\\log N$ for a single bit decision. In SCL decoding, this core computation must be performed for each of the $L$ paths currently in the list. Therefore, the complexity of extending all $L$ paths and calculating their new likelihoods is $L \\times O(\\log N) = O(L \\log N)$.\n\n2.  **Path Management (Pruning):** After extending the $L$ paths into $2L$ potential new paths, the decoder must sort and prune this list back down to size $L$. The problem statement specifies that the complexity of this management step is proportional to $L$, which can be written as $O(L)$.\n\nThe total complexity for a single stage is the sum of the complexities of these two parts.\nComplexity per stage = (Complexity of likelihood calculation) + (Complexity of path management)\nComplexity per stage = $O(L \\log N) + O(L)$.\n\nFor any polar code with block length $N > 2$, we have $\\log N > 1$. Therefore, the term $O(L \\log N)$ is asymptotically dominant over the $O(L)$ term. So, we can simplify the complexity for a single stage to:\nComplexity per stage = $O(L \\log N)$.\n\nThis work is performed for each of the $N$ bits that need to be decoded. Since the stages are sequential, we find the total complexity by multiplying the complexity per stage by the number of stages, $N$.\n\nTotal Complexity = Number of stages $\\times$ Complexity per stage\nTotal Complexity = $N \\times O(L \\log N)$\nTotal Complexity = $O(L N \\log N)$.\n\nNow we compare this result with the given options:\nA. $O(LN)$: This ignores the $\\log N$ factor inherent in the structure of polar code decoding.\nB. $O(N \\log N)$: This is the complexity of standard SC decoding ($L=1$) and ignores the factor of $L$ for list decoding.\nC. $O(N + L \\log N)$: This incorrectly adds the complexities instead of multiplying them.\nD. $O(L N \\log N)$: This matches our derived complexity.\nE. $O(L^2 N \\log N)$: This would imply that the path management is quadratic in $L$, which contradicts the problem statement.\n\nThus, the correct option is D.", "answer": "$$\\boxed{D}$$", "id": "1637429"}, {"introduction": "To elevate SCL decoding from a theoretical tool to a practical powerhouse, it is often combined with a Cyclic Redundancy Check (CRC). This creates a 'CRC-Aided' SCL decoder, where the CRC acts as a powerful final check to select the correct path. This exercise explores the fundamental decision logic of this system, asking you to consider what happens when none of the decoder's best guesses satisfy this crucial verification step [@problem_id:1637445].", "problem": "In modern communication systems, polar codes are often paired with a powerful decoding algorithm known as CRC-Aided Successive Cancellation List (SCL) decoding. An engineer is monitoring a system where information bits are first appended with a Cyclic Redundancy Check (CRC) checksum and then encoded using a polar code. The receiver employs an SCL decoder with a list size of $L$.\n\nFor a specific received block of data, the SCL decoder correctly executes its algorithm, maintaining a list of the $L$ most probable candidate information sequences at the end of the process. The decoder then proceeds to verify the integrity of each of these $L$ candidates using the CRC. Upon checking all $L$ paths, the engineer observes that none of them produce a valid CRC checksum.\n\nGiven this specific outcome, what is the formal result declared by the decoder for this block?\n\nA. The decoder outputs the candidate sequence that has the most favorable path metric, regardless of the CRC result.\n\nB. The decoder declares a decoding failure for the block.\n\nC. The decoder automatically requests an immediate re-transmission of the block from the transmitter.\n\nD. The decoder outputs an all-zero information sequence as a default error signal.\n\nE. The decoder performs another round of decoding with an increased list size of $2L$.", "solution": "Define the SCL decoderâ€™s candidate list at the end of tree search as $\\mathcal{L}=\\{u^{(1)},u^{(2)},\\ldots,u^{(L)}\\}$, where each $u^{(\\ell)}$ is a length-$k$ information sequence candidate and has an associated path metric $M(u^{(\\ell)})$. Let the CRC be represented by a mapping $\\operatorname{CRC}:\\{0,1\\}^{k}\\to\\{0,1\\}^{r}$, where a candidate is CRC-valid if and only if $\\operatorname{CRC}(u^{(\\ell)})=\\mathbf{0}_{r}$.\n\nThe CRC-aided selection rule is:\n1) Form the subset of CRC-valid candidates $\\mathcal{V}=\\{u^{(\\ell)}\\in\\mathcal{L}:\\operatorname{CRC}(u^{(\\ell)})=\\mathbf{0}_{r}\\}$.\n2) If $\\mathcal{V}\\neq\\varnothing$, output $\\arg\\min_{u\\in\\mathcal{V}} M(u)$ (assuming smaller metric is better).\n3) If $\\mathcal{V}=\\varnothing$, no candidate satisfies the CRC constraint, so the CRC-aided decision cannot endorse any candidate.\n\nBy definition of CRC-aided decoding, the absence of any CRC-valid path implies the decoder cannot validate any hypothesis and thus declares a decoding failure (also termed a block error or CRC failure). This outcome is distinct from higher-layer actions (e.g., retransmission requests), which are handled by protocols outside the decoder, and it is also distinct from ad hoc fallbacks (e.g., outputting the best-metric candidate without CRC), which are not the formal CRC-aided rule.\n\nTherefore, when all $L$ paths fail the CRC, the formal result is a decoding failure for the block, corresponding to option B, while options A, C, D, and E contradict the standard CRC-aided decision rule or belong to other system layers/strategies.", "answer": "$$\\boxed{B}$$", "id": "1637445"}, {"introduction": "Now it's time to roll up your sleeves and step into the role of the decoder itself. This advanced practice guides you through a step-by-step simulation of a sophisticated adaptive SCL algorithm, where the list size is managed dynamically based on path confidence. By tracking path metrics and applying pruning rules based on channel reliability, you will gain an intimate understanding of the intricate mechanics that lie at the heart of list decoding [@problem_id:1637423].", "problem": "An advanced Successive Cancellation List (SCL) decoder for polar codes employs an adaptive list management strategy to optimize its computational complexity. Consider a polar code of length $N=4$ and dimension $K=2$. The set of information bit indices is $\\mathcal{I} = \\{2, 3\\}$, and the set of frozen bit indices is $\\mathcal{F} = \\{0, 1\\}$. The frozen bits are fixed to $u_0 = 0$ and $u_1 = 0$.\n\nThe decoder operates on a Binary Symmetric Channel (BSC) and uses a path metric (PM) that quantifies the penalty for a given path, where a lower PM is better. The initial path metric is $PM_0 = 0$. At each stage $i$ of decoding bit $u_i$, for a given path $\\hat{u}_0^{i-1}$ with metric $PM_i$, the decoder is provided with a conditional Log-Likelihood Ratio (LLR), denoted as $L_i = L(u_i | \\hat{u}_0^{i-1})$. The hard decision for $u_i$ is $0$ if $L_i > 0$ and $1$ if $L_i < 0$. The metric for an extended path $\\hat{u}_0^{i}$ is updated as:\n$$PM_{i+1}(\\hat{u}_0^{i}) = PM_i(\\hat{u}_0^{i-1}) + \\phi(\\hat{u}_i, L_i)$$\nwhere the penalty function $\\phi(\\hat{u}_i, L_i)$ is zero if $\\hat{u}_i$ matches the hard decision for $L_i$, and $|L_i|$ otherwise.\n\nThe adaptive list management policy is as follows, with a maximum list size $L_{max}=2$:\nFor frozen bit stages, the list size does not change; the single most likely path is followed.\nFor information bit stages, the list size $L_i$ is determined dynamically:\n1.  **Candidate Generation**: For each of the $L_{i-1}$ paths in the list from the previous stage, generate two child paths (for $\\hat{u}_i=0$ and $\\hat{u}_i=1$), creating a total of $2L_{i-1}$ candidate paths. Compute their new path metrics.\n2.  **Adaptive Pruning**: Let the set of candidate paths be $\\mathcal{C}$ and let $PM_{new\\_best}$ be the minimum path metric among all paths in $\\mathcal{C}$. A candidate path $k \\in \\mathcal{C}$ with metric $PM^{(k)}$ is deemed \"competitive\" if its metric satisfies the condition:\n    $$PM^{(k)} - PM_{new\\_best} < \\alpha \\cdot Z_i$$\n    Here, $Z_i$ is the pre-computed Bhattacharyya parameter for the $i$-th bit-channel, representing its unreliability. The sensitivity parameter is given as $\\alpha = 10.0$.\n3.  **List Update**: Let $N_{comp}$ be the number of competitive paths. The new list size is $L_i = \\max(1, \\min(N_{comp}, L_{max}))$. The new list will contain the $L_i$ competitive paths with the smallest path metrics.\n\nYou are given the following pre-computed unreliability parameters for the bit-channels:\n$Z_0 = 0.80$, $Z_1 = 0.60$, $Z_2 = 0.20$, $Z_3 = 0.04$.\n\nThe sequence of LLRs encountered during the decoding of a specific received sequence is as follows:\n-   Stage 0 ($u_0$): Path history is empty. $L(u_0) = 2.5$.\n-   Stage 1 ($u_1$): Path history is $(\\hat{u}_0=0)$. $L(u_1 | \\hat{u}_0=0) = 1.8$.\n-   Stage 2 ($u_2$): Path history is $(\\hat{u}_0=0, \\hat{u}_1=0)$. $L(u_2 | \\hat{u}_0=0, \\hat{u}_1=0) = -0.5$.\n-   Stage 3 ($u_3$):\n    -   For path history $(\\hat{u}_0=0, \\hat{u}_1=0, \\hat{u}_2=0)$: $L(u_3 | \\hat{u}_0=0, \\hat{u}_1=0, \\hat{u}_2=0) = 4.0$.\n    -   For path history $(\\hat{u}_0=0, \\hat{u}_1=0, \\hat{u}_2=1)$: $L(u_3 | \\hat{u}_0=0, \\hat{u}_1=0, \\hat{u}_2=1) = -1.0$.\n\nAfter the decoder finishes at stage $i=3$, it produces a final list of paths. The most likely decoded sequence is the one with the lowest path metric in the final list. Let the decoded information bits be $(\\hat{u}_2, \\hat{u}_3)$ and the final list size be $L_3$.\nYour task is to calculate the integer value $S = 100 \\cdot \\hat{u}_2 + 10 \\cdot \\hat{u}_3 + L_3$.", "solution": "We proceed stage by stage, tracking path histories, hard decisions, path metric (PM) updates, and adaptive list management according to the given rules. The path metric update rule for extending a path to include $\\hat{u}_{i}$ with LLR $L_{i}$ is\n$$\nPM_{i+1}(\\hat{u}_{0}^{i}) = PM_{i}(\\hat{u}_{0}^{i-1}) + \\phi(\\hat{u}_{i}, L_{i}),\n$$\nwhere $\\phi(\\hat{u}_{i}, L_{i})=0$ if $\\hat{u}_{i}$ equals the hard decision (which is $0$ if $L_{i}>0$ and $1$ if $L_{i}<0$), and $\\phi(\\hat{u}_{i}, L_{i})=|L_{i}|$ otherwise. The adaptive pruning threshold at stage $i$ is $\\alpha Z_{i}$ with $\\alpha=10.0$ and the given $Z_{i}$.\n\nInitialization: at the start, the list has a single path with $PM_{0}=0$.\n\nStage $0$ (frozen bit $u_{0}=0$): $L(u_{0})=2.5>0$ so the hard decision is $0$. Since the frozen bit equals the hard decision, the penalty is $\\phi(0,2.5)=0$. Hence\n$$\nPM_{1} = PM_{0} + 0 = 0.\n$$\nPer the rule for frozen bits, the list size remains $1$ and no branching occurs. Current path: $(\\hat{u}_{0})=(0)$, $PM=0$.\n\nStage $1$ (frozen bit $u_{1}=0$): $L(u_{1}\\mid \\hat{u}_{0}=0)=1.8>0$ so the hard decision is $0$. The frozen bit equals the hard decision, so $\\phi(0,1.8)=0$. Hence\n$$\nPM_{2} = PM_{1} + 0 = 0.\n$$\nList size remains $1$. Current path: $(\\hat{u}_{0},\\hat{u}_{1})=(0,0)$, $PM=0$.\n\nStage $2$ (information bit $u_{2}$): $L(u_{2}\\mid \\hat{u}_{0}=0,\\hat{u}_{1}=0)=-0.5<0$ so the hard decision is $1$. Candidate generation from the single incoming path $(0,0)$ with $PM=0$:\n- Choose $\\hat{u}_{2}=1$ (matches hard decision): $\\phi(1,-0.5)=0$, so candidate metric $PM=0+0=0$ with path $(0,0,1)$.\n- Choose $\\hat{u}_{2}=0$ (mismatch): $\\phi(0,-0.5)=|{-0.5}|=0.5$, so candidate metric $PM=0+0.5=0.5$ with path $(0,0,0)$.\n\nAdaptive pruning at stage $2$: $\\alpha Z_{2} = 10.0 \\times 0.20 = 2.0$. The best candidate metric is\n$$\nPM_{\\text{new\\_best}} = \\min\\{0, 0.5\\} = 0.\n$$\nCompetitiveness condition: $PM^{(k)} - PM_{\\text{new\\_best}} < 2.0$.\n- For $PM=0$: $0-0=0<2.0$ competitive.\n- For $PM=0.5$: $0.5-0=0.5<2.0$ competitive.\n\nThus $N_{\\text{comp}}=2$, and the updated list size is\n$$\nL_{2}=\\max(1,\\min(N_{\\text{comp}},L_{\\max}))=\\max(1,\\min(2,2))=2.\n$$\nWe retain both competitive paths:\n- Path A: $(0,0,1)$ with $PM=0$.\n- Path B: $(0,0,0)$ with $PM=0.5$.\n\nStage $3$ (information bit $u_{3}$): For each current path, generate two children using the provided LLRs.\n\nFrom Path B $(0,0,0)$ with $PM=0.5$: $L(u_{3}\\mid 0,0,0)=4.0>0$, hard decision $0$.\n- Choose $\\hat{u}_{3}=0$ (match): $\\phi(0,4.0)=0$, new $PM=0.5$ with $(0,0,0,0)$.\n- Choose $\\hat{u}_{3}=1$ (mismatch): $\\phi(1,4.0)=|4.0|=4.0$, new $PM=0.5+4.0=4.5$ with $(0,0,0,1)$.\n\nFrom Path A $(0,0,1)$ with $PM=0$: $L(u_{3}\\mid 0,0,1)=-1.0<0$, hard decision $1$.\n- Choose $\\hat{u}_{3}=1$ (match): $\\phi(1,-1.0)=0$, new $PM=0$ with $(0,0,1,1)$.\n- Choose $\\hatu}_{3}=0$ (mismatch): $\\phi(0,-1.0)=|{-1.0}|=1.0$, new $PM=0+1.0=1.0$ with $(0,0,1,0)$.\n\nCandidate set metrics at stage $3$: $\\{0.5,\\,4.5,\\,0,\\,1.0\\}$. The best metric is\n$$\nPM_{\\text{new\\_best}}=\\min\\{0.5,4.5,0,1.0\\}=0.\n$$\nAdaptive pruning threshold: $\\alpha Z_{3}=10.0 \\times 0.04=0.4$. Competitiveness test $PM^{(k)}-PM_{\\text{new\\_best}}<0.4$:\n- $0-0=0<0.4$ competitive (path $(0,0,1,1)$).\n- $0.5-0=0.5\\not<0.4$ not competitive.\n- $1.0-0=1.0\\not<0.4$ not competitive.\n- $4.5-0=4.5\\not<0.4$ not competitive.\n\nThus $N_{\\text{comp}}=1$, and the updated list size is\n$$\nL_{3}=\\max(1,\\min(1,2))=1.\n$$\nThe final list contains only the path $(\\hat{u}_{0},\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})=(0,0,1,1)$, so the decoded information bits are $(\\hat{u}_{2},\\hat{u}_{3})=(1,1)$ and the final list size is $L_{3}=1$.\n\nTherefore,\n$$\nS=100\\cdot \\hat{u}_{2} + 10\\cdot \\hat{u}_{3} + L_{3}=100\\cdot 1 + 10\\cdot 1 + 1=111.\n$$", "answer": "$$\\boxed{111}$$", "id": "1637423"}]}