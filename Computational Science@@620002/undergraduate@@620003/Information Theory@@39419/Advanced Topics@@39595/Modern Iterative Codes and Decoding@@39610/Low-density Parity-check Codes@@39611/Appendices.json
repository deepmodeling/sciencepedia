{"hands_on_practices": [{"introduction": "The effectiveness of any error-correcting code is a trade-off between its reliability and its efficiency. The code rate, denoted by $R$, is a fundamental metric that quantifies this efficiency, telling us what fraction of the transmitted data is actual information. This exercise provides practice in calculating this crucial parameter directly from the definition of an LDPC code's parity-check matrix, $H$. [@problem_id:1638281]", "problem": "In digital communications, linear block codes are employed to protect information from errors that may occur during transmission. A popular and powerful class of such codes is the Low-Density Parity-Check (LDPC) code, which is defined by a sparse parity-check matrix, denoted by $H$. The properties of the code, such as its error-correcting capability and its efficiency, are determined by the structure of this matrix.\n\nConsider a binary LDPC code whose parity-check matrix $H$ has 4 rows and 8 columns. The number of columns, $n$, corresponds to the total number of bits in a codeword (the block length), while the number of rows, $m$, corresponds to the number of linear parity-check constraints imposed on the codewords. You are given that this matrix $H$ has full row rank.\n\nCalculate the code rate, $R$, of this LDPC code. Present your answer as a single closed-form analytic expression.", "solution": "For a binary linear block code defined by a parity-check matrix $H$ with $n$ columns and $m$ rows, the code dimension $k$ is given by\n$$\nk = n - \\operatorname{rank}(H).\n$$\nThe code rate is defined as\n$$\nR = \\frac{k}{n}.\n$$\nGiven that $H$ has full row rank, we have $\\operatorname{rank}(H) = m$. Therefore,\n$$\nR = \\frac{n - m}{n}.\n$$\nWith $n = 8$ and $m = 4$, we substitute to obtain\n$$\nR = \\frac{8 - 4}{8} = \\frac{4}{8} = \\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1638281"}, {"introduction": "While a parity-check matrix defines an LDPC code algebraically, its true power is often better understood by viewing it as a graph. This exercise guides you through translating a matrix into a Tanner graph, the visual representation that underpins iterative decoding algorithms. By analyzing the graph's structure, you will develop intuition for how information propagates between bits and checks during error correction. [@problem_id:1638246]", "problem": "In the study of error-correcting codes, a Low-Density Parity-Check (LDPC) code is a linear block code defined by a sparse parity-check matrix $H$. The structure of this code can be visualized using a bipartite graph known as a Tanner graph. This graph consists of two sets of nodes: variable nodes, corresponding to the columns of $H$, and check nodes, corresponding to the rows of $H$. An edge exists between a variable node $v_j$ (representing the $j$-th column) and a check node $c_i$ (representing the $i$-th row) if and only if the entry at row $i$ and column $j$ of the matrix $H$ is 1.\n\nConsider an LDPC code defined over the binary field by the following $3 \\times 6$ parity-check matrix $H$:\n$$ H = \\begin{pmatrix} 1  1  0  1  0  0 \\\\ 0  1  1  0  1  0 \\\\ 0  0  1  1  0  1 \\end{pmatrix} $$\nThe code has $n=6$ variable nodes, denoted $\\{v_1, \\dots, v_6\\}$, and $m=3$ check nodes, denoted $\\{c_1, c_2, c_3\\}$.\n\nFor any given variable node $v_j$ in the Tanner graph, we define its *2-hop variable neighborhood* as the set of all other variable nodes $v_k$ (where $k \\neq j$) that are connected to $v_j$ by a path of exactly two edges.\n\nDetermine the size of the largest possible 2-hop variable neighborhood among all variable nodes in the Tanner graph for this code.", "solution": "A Tanner graph for the given parity-check matrix $H$ has variable nodes $v_{1},\\dots,v_{6}$ and check nodes $c_{1},c_{2},c_{3}$. An edge connects $v_{j}$ to $c_{i}$ if and only if $H_{ij}=1$. From\n$$\nH=\\begin{pmatrix}\n1  1  0  1  0  0\\\\\n0  1  1  0  1  0\\\\\n0  0  1  1  0  1\n\\end{pmatrix},\n$$\nthe check-node neighborhoods of variables (equivalently, the variable-node neighborhoods of checks) are:\n$$\nc_{1}:\\{v_{1},v_{2},v_{4}\\},\\quad\nc_{2}:\\{v_{2},v_{3},v_{5}\\},\\quad\nc_{3}:\\{v_{3},v_{4},v_{6}\\}.\n$$\nFor a variable node $v_{j}$, its 2-hop variable neighborhood is\n$$\n\\mathcal{N}^{(2)}(v_{j})=\\bigcup_{c\\in N_{c}(v_{j})}\\left(N_{v}(c)\\setminus\\{v_{j}\\}\\right),\n$$\nwhere $N_{c}(v_{j})$ is the set of check neighbors of $v_{j}$ and $N_{v}(c)$ is the set of variable neighbors of $c$. Thus,\n$$\n\\left|\\mathcal{N}^{(2)}(v_{j})\\right|=\\sum_{c\\in N_{c}(v_{j})}\\left(\\deg(c)-1\\right)-\\text{overlap},\n$$\nwhere the overlap term counts variables that would be included from two different checks. In this graph, no two distinct variables share two checks, so the overlap is zero for all $v_{j}$.\n\nCompute $\\left|\\mathcal{N}^{(2)}(v_{j})\\right|$ for each $j$:\n- For $v_{1}$, $N_{c}(v_{1})=\\{c_{1}\\}$, so $\\left|\\mathcal{N}^{(2)}(v_{1})\\right|=\\deg(c_{1})-1=3-1=2$ with neighbors $\\{v_{2},v_{4}\\}$.\n- For $v_{2}$, $N_{c}(v_{2})=\\{c_{1},c_{2}\\}$, giving size $(3-1)+(3-1)=2+2=4$ with neighbors $\\{v_{1},v_{4},v_{3},v_{5}\\}$ and no overlap.\n- For $v_{3}$, $N_{c}(v_{3})=\\{c_{2},c_{3}\\}$, giving size $(3-1)+(3-1)=4$ with neighbors $\\{v_{2},v_{5},v_{4},v_{6}\\}$ and no overlap.\n- For $v_{4}$, $N_{c}(v_{4})=\\{c_{1},c_{3}\\}$, giving size $(3-1)+(3-1)=4$ with neighbors $\\{v_{1},v_{2},v_{3},v_{6}\\}$ and no overlap.\n- For $v_{5}$, $N_{c}(v_{5})=\\{c_{2}\\}$, so size $3-1=2$ with neighbors $\\{v_{2},v_{3}\\}$.\n- For $v_{6}$, $N_{c}(v_{6})=\\{c_{3}\\}$, so size $3-1=2$ with neighbors $\\{v_{3},v_{4}\\}$.\n\nTherefore, the largest possible 2-hop variable neighborhood size among all variable nodes is $4$.", "answer": "$$\\boxed{4}$$", "id": "1638246"}, {"introduction": "Having defined and visualized LDPC codes, we now turn to their primary function: correcting errors. This problem simulates the first step of a simple yet effective iterative decoding method known as the bit-flipping algorithm. You will act as the decoder, using unsatisfied parity checks as evidence to locate and correct the most likely bit error in a received message. [@problem_id:1638271]", "problem": "In digital communication, error-correcting codes are used to detect and correct errors that occur during transmission over a noisy channel. Consider a simple binary linear block code, a type of Low-Density Parity-Check (LDPC) code, defined by the following parity-check matrix $H$ over the finite field $\\mathrm{GF}(2)$:\n$$\nH = \\begin{pmatrix}\n1  0  1  0  1  0 \\\\\n0  1  1  0  0  1 \\\\\n1  1  0  1  0  0\n\\end{pmatrix}\n$$\nThe rows of this matrix represent parity-check equations. For a vector to be a valid codeword, the result of multiplying it by $H$ must be the zero vector (all calculations are performed modulo 2).\n\nA 6-bit message is encoded and transmitted, but it gets corrupted by noise. The received vector is:\n$$\ny = \\begin{pmatrix} 0  1  1  0  0  0 \\end{pmatrix}\n$$\nWe will attempt to correct this vector using the first iteration of a hard-decision bit-flipping algorithm. The rule for this algorithm is as follows: For each of the 6 bit positions in the received vector, we count how many of the parity-check equations that involve that bit are currently unsatisfied (i.e., evaluate to 1 instead of 0). The bit position that is involved in the greatest number of unsatisfied parity-check equations is the one that should be flipped. For this problem, you will find there is a unique bit with the maximum count.\n\nDetermine the 1-based index (an integer from 1 to 6) of the bit in the received vector $y$ that should be flipped according to this rule.", "solution": "For a received vector $\\mathbf{y}$, the syndrome is $s = H \\mathbf{y}^{\\top}$ with arithmetic in $\\mathrm{GF}(2)$. A parity-check equation (row) is unsatisfied exactly when its syndrome component equals $1$.\n\nCompute the syndrome components row-wise:\n$$\ns_{1} = y_{1} + y_{3} + y_{5} \\ (\\mathrm{mod}\\ 2) = 0 + 1 + 0 = 1,\n$$\n$$\ns_{2} = y_{2} + y_{3} + y_{6} \\ (\\mathrm{mod}\\ 2) = 1 + 1 + 0 = 0,\n$$\n$$\ns_{3} = y_{1} + y_{2} + y_{4} \\ (\\mathrm{mod}\\ 2) = 0 + 1 + 0 = 1.\n$$\nThus\n$$\ns = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix},\n$$\nso the unsatisfied parity checks are rows $1$ and $3$.\n\nFor each bit position $j \\in \\{1,\\dots,6\\}$, the number of unsatisfied checks that involve bit $j$ is\n$$\nc_{j} = \\sum_{i=1}^{3} H_{i,j}\\, s_{i},\n$$\nwhere the sum is over the integers (since $s_{i} \\in \\{0,1\\}$). Using the columns of $H$ and $s=(1,0,1)^{\\top}$:\n$$\nc_{1} = 1\\cdot 1 + 0\\cdot 0 + 1\\cdot 1 = 2, \\quad\nc_{2} = 0\\cdot 1 + 1\\cdot 0 + 1\\cdot 1 = 1,\n$$\n$$\nc_{3} = 1\\cdot 1 + 1\\cdot 0 + 0\\cdot 1 = 1, \\quad\nc_{4} = 0\\cdot 1 + 0\\cdot 0 + 1\\cdot 1 = 1,\n$$\n$$\nc_{5} = 1\\cdot 1 + 0\\cdot 0 + 0\\cdot 1 = 1, \\quad\nc_{6} = 0\\cdot 1 + 1\\cdot 0 + 0\\cdot 1 = 0.\n$$\nThe unique maximum count is $c_{1}=2$, so the bit to flip is at index $1$.", "answer": "$$\\boxed{1}$$", "id": "1638271"}]}