{"hands_on_practices": [{"introduction": "The performance of a relay channel using a Decode-and-Forward (DF) protocol is fundamentally limited by a bottleneck. This bottleneck arises because the overall communication rate can be no higher than what the weakest part of the chain can support. This exercise provides a foundational workout in calculating the achievable rate, which is governed by the minimum of two key quantities: the information rate from the source to the relay, and the rate from both the source and relay to the destination. Mastering this calculation is a crucial first step in understanding and analyzing any DF relaying system [@problem_id:1664036].", "problem": "Consider a discrete memoryless relay channel where a source, a relay, and a destination communicate. The source transmits a symbol $X$, the relay transmits a symbol $X_1$, the relay receives a symbol $Y_1$, and the destination receives a symbol $Y$. The alphabets for all four variables $X, X_1, Y_1, Y$ are binary, i.e., $\\{0, 1\\}$.\n\nThe channel's behavior is defined by the following probabilistic rules, where $\\oplus$ denotes addition modulo 2:\n1.  The symbol received by the relay is $Y_1 = X \\oplus Z_1$, where $Z_1$ is a random noise variable. $Z_1$ follows a Bernoulli distribution with parameter $p_1$, so $P(Z_1=1) = p_1$.\n2.  The symbol received by the destination is $Y = X \\oplus X_1 \\oplus Z_2$, where $Z_2$ is a random noise variable. $Z_2$ follows a Bernoulli distribution with parameter $p_2$, so $P(Z_2=1) = p_2$.\n\nThe noise variables $Z_1$ and $Z_2$ are statistically independent of each other and of the channel inputs $X$ and $X_1$. This channel structure implies that the joint conditional probability mass function of the channel outputs is $p(y, y_1 | x, x_1) = p(y_1 | x) p(y | x, x_1)$.\n\nWe consider a Decode-and-Forward (DF) communication protocol. For a specific choice of input distributions, the achievable rate of this scheme is given by the formula $R = \\min \\{ I(X; Y_1 | X_1), I(X, X_1; Y) \\}$, where $I(\\cdot;\\cdot|\\cdot)$ and $I(\\cdot;\\cdot)$ denote conditional and unconditional mutual information, respectively. All logarithms used in the information-theoretic calculations are base 2.\n\nAssume that the source input $X$ and the relay input $X_1$ are chosen to be statistically independent, and both are uniformly distributed over the alphabet $\\{0, 1\\}$. Given the noise parameters $p_1 = 1/4$ and $p_2 = 1/3$, determine the value of the achievable rate $R$.\n\nExpress your final answer as a single closed-form analytic expression in units of bits per channel use. Your expression may include logarithms and fractions but must be fully simplified.", "solution": "We are given a binary-input, binary-output discrete memoryless relay channel with\n$Y_{1} = X \\oplus Z_{1}$, where $Z_{1} \\sim \\mathrm{Bern}(p_{1})$, and\n$Y = X \\oplus X_{1} \\oplus Z_{2}$, where $Z_{2} \\sim \\mathrm{Bern}(p_{2})$.\nThe inputs $X$ and $X_{1}$ are independent and both uniform over $\\{0,1\\}$, and $Z_{1}, Z_{2}$ are independent of everything.\n\nFor Decode-and-Forward with independent uniform inputs, the achievable rate is\n$$\nR = \\min\\{ I(X; Y_{1} \\mid X_{1}),\\ I(X, X_{1}; Y) \\}.\n$$\n\nFirst, compute $I(X; Y_{1} \\mid X_{1})$.\nBy definition,\n$$\nI(X; Y_{1} \\mid X_{1}) = H(Y_{1} \\mid X_{1}) - H(Y_{1} \\mid X, X_{1}).\n$$\nSince $Y_{1}$ depends only on $(X, Z_{1})$ and $(X, Y_{1})$ are independent of $X_{1}$, we have $H(Y_{1} \\mid X_{1}) = H(Y_{1})$ and $H(Y_{1} \\mid X, X_{1}) = H(Y_{1} \\mid X)$.\nMoreover, $Y_{1} = X \\oplus Z_{1}$ is a binary symmetric channel (BSC) with crossover probability $p_{1}$ and uniform input $X$, so $Y_{1}$ is uniform and\n$$\nH(Y_{1}) = 1, \\quad H(Y_{1} \\mid X) = H(Z_{1}) = h_{2}(p_{1}),\n$$\nwhere $h_{2}(p) = -p \\log_{2} p - (1-p)\\log_{2}(1-p)$ is the binary entropy function. Hence,\n$$\nI(X; Y_{1} \\mid X_{1}) = 1 - h_{2}(p_{1}).\n$$\n\nNext, compute $I(X, X_{1}; Y)$. Let $S = X \\oplus X_{1}$. Since $X$ and $X_{1}$ are independent and uniform, $S$ is uniform on $\\{0,1\\}$. The channel to the destination is\n$$\nY = S \\oplus Z_{2},\n$$\nwhich is a BSC with crossover probability $p_{2}$ and uniform input $S$. The mutual information is $I(X, X_1; Y) = I(S; Y) = 1-h_2(p_2)$.\n\nTherefore,\n$$\nR = \\min\\{ 1 - h_{2}(p_{1}),\\ 1 - h_{2}(p_{2}) \\}.\n$$\nWith $p_{1} = \\frac{1}{4}$ and $p_{2} = \\frac{1}{3}$, and noting that $h_{2}(p)$ is increasing on $[0, \\frac{1}{2}]$ so that $h_{2}\\!\\left(\\frac{1}{3}\\right) > h_{2}\\!\\left(\\frac{1}{4}\\right)$, we have\n$$\nR = 1 - h_{2}\\!\\left(\\frac{1}{3}\\right).\n$$\nExpanding $h_{2}\\!\\left(\\frac{1}{3}\\right)$,\n$$\nh_{2}\\!\\left(\\frac{1}{3}\\right) = -\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right) - \\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)\n= -\\frac{1}{3}(-\\log_{2} 3) - \\frac{2}{3}(1 - \\log_{2} 3)\n= -\\frac{2}{3} + \\log_{2} 3.\n$$\nThus,\n$$\nR = 1 - \\left(-\\frac{2}{3} + \\log_{2} 3\\right) = \\frac{5}{3} - \\log_{2} 3.\n$$\nThis is the achievable rate in bits per channel use.", "answer": "$$\\boxed{\\frac{5}{3}-\\log_{2}3}$$", "id": "1664036"}, {"introduction": "To better understand the potential benefits of relaying, it is often useful to consider idealized scenarios. This problem presents a hypothetical case where the link from the source to the relay is perfect and error-free, effectively removing the first potential bottleneck of the DF protocol. Your task is to determine the maximum rate when the destination receives information via two orthogonal channels: one directly from the source and another from the perfect relay. This thought experiment isolates and highlights how a relay can augment the primary communication by providing an additional, independent path for the data to travel [@problem_id:1664030].", "problem": "Consider a relay channel model inspired by a simple cooperative communication system. The system consists of three nodes: a source node (S), a relay node (R), and a destination node (D). Communication from the source to the destination is assisted by the relay.\n\nThe channel links are characterized as follows:\n1.  The link from the source (S) to the relay (R) is a perfect, noiseless channel, allowing for error-free transmission at any required rate.\n2.  The link from the source (S) to the destination (D) is a Binary Symmetric Channel (BSC), which is a channel model for binary communication systems with noise. It has a crossover probability $p_1$.\n3.  The link from the relay (R) to the destination (D) is an independent BSC with a crossover probability $p_2$.\n\nThe relay operates using the Decode-and-Forward (DF) protocol. In this protocol, the relay first fully decodes the message transmitted by the source and then re-encodes and forwards it to the destination. The transmissions from the source and the relay to the destination occur over orthogonal channels, meaning they do not interfere with each other at the receiver.\n\nFind the maximum achievable communication rate for this system. Express your answer in bits per channel use as a fully expanded symbolic expression in terms of $p_1$ and $p_2$. Your answer should not use the binary entropy function notation, $H_b(p)$, but should instead be written explicitly using logarithms with base 2.", "solution": "Let the source message be $M$. Under Decode-and-Forward with a perfect $S \\to R$ link, the relay decodes $M$ without error and re-encodes it. The source and relay transmit over orthogonal channels to the destination, so in each channel use the destination observes two outputs: $Y_{1}$ from the source through a BSC with crossover probability $p_{1}$, and $Y_{2}$ from the relay through an independent BSC with crossover probability $p_{2}$. Denote the source input by $X_{S}$ and the relay input by $X_{R}$. The channel law factors as\n$$\nP_{Y_{1},Y_{2}|X_{S},X_{R}}(y_{1},y_{2}|x_{S},x_{R})=P_{\\text{BSC}(p_{1})}(y_{1}|x_{S})\\,P_{\\text{BSC}(p_{2})}(y_{2}|x_{R}).\n$$\nSince both encoders know $M$, they can choose codebooks so that $X_{S}$ and $X_{R}$ are independent given $M$ and also independent unconditionally for the purpose of maximizing mutual information. For a memoryless orthogonal product channel, the per-use mutual information for a common message is\n$$\nI(X_{S},X_{R};Y_{1},Y_{2})=H(Y_{1},Y_{2})-H(Y_{1},Y_{2}|X_{S},X_{R}).\n$$\nIf we choose $X_{S}$ and $X_{R}$ independent, then $(Y_{1},Y_{2})$ are independent, and $Y_{1} \\perp Y_{2}$ given $(X_{S},X_{R})$, so\n$$\nH(Y_{1},Y_{2})=H(Y_{1})+H(Y_{2}), \\quad H(Y_{1},Y_{2}|X_{S},X_{R})=H(Y_{1}|X_{S})+H(Y_{2}|X_{R}),\n$$\nand therefore\n$$\nI(X_{S},X_{R};Y_{1},Y_{2})=I(X_{S};Y_{1})+I(X_{R};Y_{2}).\n$$\nMaximizing over input distributions factorizes into two separate maximizations, one for each BSC. For a BSC with crossover probability $p$, the mutual information for input $X \\sim \\text{Bernoulli}(q)$ is\n$$\nI(X;Y)=H(Y)-H(Y|X),\n$$\nwhere $H(Y|X)= -p \\log_{2}(p) - (1-p)\\log_{2}(1-p)$ and $H(Y)$ is maximized (to $1$ bit) by the symmetric input $q=\\frac{1}{2}$. Thus the capacity of a BSC$(p)$ is\n$$\nC_{\\text{BSC}(p)}=1 - \\big(-p \\log_{2}(p) - (1-p)\\log_{2}(1-p)\\big)=1 + p \\log_{2}(p) + (1-p)\\log_{2}(1-p).\n$$\nApplying this to the two independent orthogonal links gives the maximum achievable rate as the sum\n$$\nR_{\\max}=C_{\\text{BSC}(p_{1})}+C_{\\text{BSC}(p_{2})}=2 + p_{1}\\log_{2}(p_{1}) + (1-p_{1})\\log_{2}(1-p_{1}) + p_{2}\\log_{2}(p_{2}) + (1-p_{2})\\log_{2}(1-p_{2}).\n$$\nThere is no additional decoding constraint from the relay because the $S \\to R$ link is perfect and supports any rate.", "answer": "$$\\boxed{2 + p_{1}\\log_{2}(p_{1}) + \\left(1-p_{1}\\right)\\log_{2}\\!\\left(1-p_{1}\\right) + p_{2}\\log_{2}(p_{2}) + \\left(1-p_{2}\\right)\\log_{2}\\!\\left(1-p_{2}\\right)}$$", "id": "1664030"}, {"introduction": "Moving from idealized models to more practical designs, this problem explores a hybrid communication protocol for an Additive White Gaussian Noise (AWGN) channel. Here, the system dynamically switches between direct source-to-destination transmission and a two-phase DF relaying mode, modeling a scenario with resource constraints. The challenge lies in determining the maximum average achievable rate by optimizing the time allocation within the relaying phase and averaging over the different modes. This exercise bridges theoretical concepts with engineering reality, demonstrating how to analyze and optimize systems that combine multiple communication strategies [@problem_id:1664008].", "problem": "A source node (S) wishes to transmit data to a destination node (D). An intermediate relay node (R) is available to assist. The communication channels between the nodes are modeled as independent real-valued Additive White Gaussian Noise (AWGN) channels. The source and the relay have transmission powers of $P_S$ and $P_R$, respectively. All receivers (at R and D) experience AWGN with the same power $N$. The channel power gains from S to D, S to R, and R to D are denoted by $G_{SD}$, $G_{SR}$, and $G_{RD}$, respectively.\n\nDue to processing limitations that model a relay that can only assist with every other transmission block, the system employs a protocol that alternates equally in time between two modes:\n1.  **Direct Mode**: The source transmits directly to the destination. The relay is idle.\n2.  **Relay Mode**: A two-phase Decode-and-Forward protocol is used. In the first phase, the source transmits to the relay, which must successfully decode the message. In the second phase, the relay re-encodes and forwards the message to the destination. The source is silent during the second phase. The time allocation between the two phases of this mode is optimized to maximize the rate.\n\nDetermine the maximum average achievable data rate, $R_{avg}$, of this communication system as a function of the given parameters. The capacity of a real-valued AWGN channel is given by $C = \\frac{1}{2} \\log_2(1 + \\text{SNR})$, where SNR is the Signal-to-Noise Ratio. Express your answer in bits per channel use.", "solution": "Let the real-valued AWGN capacity of a point-to-point link with signal-to-noise ratio $\\gamma$ be $C(\\gamma)=\\frac{1}{2}\\log_{2}(1+\\gamma)$ bits per channel use. For the three links we define the SNRs\n$$\n\\gamma_{SD}=\\frac{P_{S}G_{SD}}{N},\\quad \\gamma_{SR}=\\frac{P_{S}G_{SR}}{N},\\quad \\gamma_{RD}=\\frac{P_{R}G_{RD}}{N},\n$$\nand the corresponding capacities\n$$\nC_{SD}=\\frac{1}{2}\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SD}}{N}\\right),\\quad\nC_{SR}=\\frac{1}{2}\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right),\\quad\nC_{RD}=\\frac{1}{2}\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right).\n$$\n\nThe protocol alternates equally in time between direct mode and relay mode.\n\nDirect mode (fraction $\\frac{1}{2}$ of the time): the source transmits directly to the destination at rate $C_{SD}$. Its contribution to the average rate is\n$$\nR_{\\text{direct,avg}}=\\frac{1}{2}\\,C_{SD}.\n$$\n\nRelay mode (fraction $\\frac{1}{2}$ of the time): use a two-phase decode-and-forward with time split $\\alpha$ for the S-to-R phase and $(1-\\alpha)$ for the R-to-D phase. In this orthogonal DF setting, the end-to-end rate supported within relay mode is\n$$\nR_{\\text{DF}}(\\alpha)=\\min\\{\\alpha\\,C_{SR},\\,(1-\\alpha)\\,C_{RD}\\}.\n$$\nTo maximize $R_{\\text{DF}}(\\alpha)$ over $\\alpha\\in(0,1)$, equalize the two terms:\n$$\n\\alpha\\,C_{SR}=(1-\\alpha)\\,C_{RD}\\;\\;\\Longrightarrow\\;\\;\\alpha^{\\star}=\\frac{C_{RD}}{C_{SR}+C_{RD}},\n$$\nwhich yields the maximized relay-mode rate\n$$\nR_{\\text{DF}}^{\\star}=\\alpha^{\\star}C_{SR}=\\frac{C_{SR}C_{RD}}{C_{SR}+C_{RD}}.\n$$\nIts contribution to the average rate is\n$$\nR_{\\text{relay,avg}}=\\frac{1}{2}\\,R_{\\text{DF}}^{\\star}=\\frac{1}{2}\\,\\frac{C_{SR}C_{RD}}{C_{SR}+C_{RD}}.\n$$\n\nTherefore, the maximum average achievable data rate is\n$$\nR_{\\text{avg}}=\\frac{1}{2}C_{SD}+\\frac{1}{2}\\,\\frac{C_{SR}C_{RD}}{C_{SR}+C_{RD}}.\n$$\nSubstituting the link capacities and simplifying, let\n$$\nA=\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right),\\quad B=\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right),\n$$\nso that $C_{SR}=\\frac{1}{2}A$ and $C_{RD}=\\frac{1}{2}B$. Then\n$$\n\\frac{1}{2}\\,\\frac{C_{SR}C_{RD}}{C_{SR}+C_{RD}}=\\frac{AB}{4\\,(A+B)}.\n$$\nHence\n$$\nR_{\\text{avg}}=\\frac{1}{4}\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SD}}{N}\\right)+\\frac{\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right)\\,\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right)}{4\\left[\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right)+\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right)\\right]}.\n$$\nThis is in bits per channel use.", "answer": "$$\\boxed{\\frac{1}{4}\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SD}}{N}\\right)+\\frac{\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right)\\,\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right)}{4\\left[\\log_{2}\\!\\left(1+\\frac{P_{S}G_{SR}}{N}\\right)+\\log_{2}\\!\\left(1+\\frac{P_{R}G_{RD}}{N}\\right)\\right]}}$$", "id": "1664008"}]}