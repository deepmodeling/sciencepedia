{"hands_on_practices": [{"introduction": "The first step in implementing almost any differentially private mechanism is to understand the query's sensitivity. The $L_1$-sensitivity, denoted $\\Delta_1 f$, measures the maximum possible change in a query's output when a single individual's data is added to or removed from the database. This exercise [@problem_id:1618246] provides hands-on practice in calculating this crucial value for a complex, non-linear query—counting pairs of individuals—which moves beyond simple sums or counts and helps build a robust understanding of how to analyze a query's privacy implications.", "problem": "A new social networking platform for university students aims to release an aggregate statistic about its user base. The platform maintains a database where each user's record includes their Grade Point Average (GPA). The total population of students that can be included in the database is $N$.\n\nThe proposed query, denoted as $f(D)$, is designed to count the number of distinct, unordered pairs of students in the current database $D$ who are both considered \"high-achievers.\" A student is classified as a high-achiever if their GPA is greater than or equal to a fixed threshold $G$.\n\nTo comply with data privacy regulations, it is necessary to determine the $L_1$-sensitivity of this query. The $L_1$-sensitivity, $\\Delta f$, of a function $f$ is defined as the maximum possible absolute difference in the function's output when applied to any two adjacent databases. Two databases, $D_1$ and $D_2$, are considered adjacent if one can be obtained from the other by adding or removing the record of a single student. The size of the database is variable but cannot exceed the total population size $N$.\n\nFormally, the sensitivity is $\\Delta f = \\max_{D_1, D_2} |f(D_1) - f(D_2)|$, where the maximum is taken over all possible databases $D_1$ and all databases $D_2$ adjacent to $D_1$.\n\nDetermine the $L_1$-sensitivity, $\\Delta f$, of this pair-counting query. Express your answer in terms of the total student population size $N$.", "solution": "Let $D$ be any database and let $h(D)$ denote the number of high-achievers in $D$, i.e., the number of students with GPA at least $G$. The query counts unordered pairs of high-achievers, so\n$$\nf(D) = \\binom{h(D)}{2} = \\frac{h(D)\\big(h(D)-1\\big)}{2}.\n$$\n\nTwo databases are adjacent if they differ by the addition or removal of one record. Consider the effect of such a change on $f$.\n\n1) If the differing record corresponds to a non-high-achiever, then $h(D)$ is unchanged, and therefore $f$ is unchanged:\n$$\n|f(D_{1}) - f(D_{2})| = 0.\n$$\n\n2) If the differing record corresponds to a high-achiever, there are two symmetric cases.\n\na) Addition of a high-achiever: suppose $D_{2}$ is obtained from $D_{1}$ by adding one high-achiever. Let $k = h(D_{1})$, so $h(D_{2}) = k+1$. Then\n$$\nf(D_{2}) - f(D_{1}) = \\binom{k+1}{2} - \\binom{k}{2}\n= \\frac{(k+1)k}{2} - \\frac{k(k-1)}{2}\n= \\frac{k\\big((k+1)-(k-1)\\big)}{2}\n= \\frac{2k}{2}\n= k.\n$$\nThus the absolute change is $k = h(D_{1})$. Since the database size cannot exceed $N$, the smaller database in an addition step can have at most $N-1$ high-achievers, so the change is at most $N-1$.\n\nb) Removal of a high-achiever: suppose $D_{2}$ is obtained from $D_{1}$ by removing one high-achiever. Let $k = h(D_{1})$, so $h(D_{2}) = k-1$. Then\n$$\nf(D_{1}) - f(D_{2}) = \\binom{k}{2} - \\binom{k-1}{2}\n= \\frac{k(k-1)}{2} - \\frac{(k-1)(k-2)}{2}\n= \\frac{(k-1)\\big(k-(k-2)\\big)}{2}\n= \\frac{2(k-1)}{2}\n= k-1.\n$$\nThus the absolute change is $k-1$. The larger database in a removal step can have at most $N$ high-achievers, so the change is at most $N-1$.\n\nTaking the maximum over all adjacent databases and both cases, the $L_1$-sensitivity is\n$$\n\\Delta f = N - 1.\n$$", "answer": "$$\\boxed{N-1}$$", "id": "1618246"}, {"introduction": "Once a query's sensitivity is known, we can add calibrated noise to achieve differential privacy. The Laplace mechanism is a fundamental technique for satisfying pure $\\epsilon$-differential privacy by adding noise from a Laplace distribution. This practice [@problem_id:1618236] bridges theory and application, demonstrating how to use the sensitivity of a query, $\\Delta_1 f$, and the desired privacy budget, $\\epsilon$, to calculate the necessary noise scale $b$ through the core relationship $b = \\frac{\\Delta_1 f}{\\epsilon}$.", "problem": "A digital wellness research institute is conducting a study on social media usage. They collect data from $N=500$ volunteers. For each volunteer $i$, the database $D$ stores a single number $d_i$, representing their self-reported hours of social media use per day. To handle outliers and ensure consistency, all reported values are clipped to be within the range $[0, H]$, where the maximum allowed daily usage is $H = 8.0$ hours.\n\nThe institute wishes to release the average daily social media usage across all volunteers. This query is formally defined as $f(D) = \\frac{1}{N} \\sum_{i=1}^{N} d_i$. To protect the privacy of the volunteers, the institute will not publish the true average $f(D)$. Instead, they will release a privatized result $\\tilde{f}(D) = f(D) + Y$, where $Y$ is a random noise value. The noise $Y$ is drawn from a distribution with the probability density function $p(y|b) = \\frac{1}{2b} \\exp\\left(-\\frac{|y|}{b}\\right)$, where $b > 0$ is a scale parameter that controls the amount of noise.\n\nThe privacy mechanism must satisfy $\\epsilon$-Differential Privacy (DP). The $\\epsilon$-DP guarantee ensures that for any two databases $D$ and $D'$ that differ in the data of only one volunteer (i.e., they are adjacent), and for any possible set of outcomes $\\mathcal{S}$, the following inequality holds:\n$$\n\\text{Pr}[\\tilde{f}(D) \\in \\mathcal{S}] \\le \\exp(\\epsilon) \\cdot \\text{Pr}[\\tilde{f}(D') \\in \\mathcal{S}]\n$$\nGiven a privacy budget of $\\epsilon = 0.12$, determine the minimum required value of the scale parameter $b$ to ensure the average usage query satisfies $\\epsilon$-Differential Privacy.\n\nExpress your answer for the scale parameter $b$ in hours, rounded to four significant figures.", "solution": "We are releasing the average $f(D) = \\frac{1}{N} \\sum_{i=1}^{N} d_{i}$ under the Laplace mechanism $\\tilde{f}(D) = f(D) + Y$, where $Y$ has density $p(y \\mid b) = \\frac{1}{2b} \\exp\\!\\left(-\\frac{|y|}{b}\\right)$. To ensure $\\epsilon$-Differential Privacy using the Laplace mechanism, the scale must satisfy\n$$\nb = \\frac{\\Delta_1 f}{\\epsilon},\n$$\nwhere $\\Delta_1 f$ is the global $L_1$-sensitivity of $f$.\n\nCompute the sensitivity of the average. For adjacent databases $D$ and $D'$ differing in one entry, say index $j$,\n$$\n\\left| f(D) - f(D') \\right| = \\left| \\frac{1}{N} \\sum_{i=1}^{N} d_{i} - \\frac{1}{N} \\sum_{i=1}^{N} d_{i}' \\right| = \\frac{1}{N} \\left| \\sum_{i=1}^{N} (d_{i} - d_{i}') \\right| = \\frac{1}{N} \\left| d_{j} - d_{j}' \\right|.\n$$\nSince all values are clipped to $[0, H]$, we have $\\left| d_{j} - d_{j}' \\right| \\leq H$, hence\n$$\n\\Delta_1 f = \\max_{D \\sim D'} \\left| f(D) - f(D') \\right| \\leq \\frac{H}{N}.\n$$\nThis upper bound is tight by taking one value to be $0$ and the other to be $H$, so $\\Delta_1 f = \\frac{H}{N}$.\n\nTherefore, the Laplace scale required for $\\epsilon$-DP is\n$$\nb_{\\min} = \\frac{\\Delta_1 f}{\\epsilon} = \\frac{H}{N \\epsilon}.\n$$\nSubstituting $H = 8.0$, $N = 500$, and $\\epsilon = 0.12$,\n$$\nb_{\\min} = \\frac{8}{500 \\cdot 0.12} = \\frac{8}{60} = \\frac{2}{15} = 0.133333\\ldots\n$$\nRounded to four significant figures, this is $0.1333$ hours.", "answer": "$$\\boxed{0.1333}$$", "id": "1618236"}, {"introduction": "While pure $\\epsilon$-differential privacy provides a very strong guarantee, a slightly relaxed alternative known as $(\\epsilon, \\delta)$-differential privacy is often used in practice, especially in machine learning. This definition allows for a small probability $\\delta$ that the privacy guarantee might not hold. The Gaussian mechanism is the canonical method for achieving this guarantee, adding noise from a Gaussian distribution. This exercise [@problem_id:1618211] explores how to calibrate this mechanism, linking the noise's standard deviation $\\sigma$ to the query's $L_2$-sensitivity and the privacy parameters $\\epsilon$ and $\\delta$.", "problem": "A data privacy officer at a research consortium is tasked with releasing statistics from a sensitive medical database. They plan to answer a specific numerical query, $f$, which counts the number of patients matching a certain criterion. It has been established that this query has an $L_2$-sensitivity of $\\Delta_2 = 1$.\n\nTo ensure patient privacy, the officer employs the Gaussian mechanism. This technique involves computing the true answer, $f(D)$, on the database $D$, and then releasing a perturbed value, $M(D) = f(D) + Z$, where $Z$ is a random noise variable drawn from a Gaussian (normal) distribution with a mean of 0 and a standard deviation of $\\sigma$.\n\nThe privacy release must satisfy the guarantee of $(\\epsilon, \\delta)$-differential privacy. Using the standard calibration for the Gaussian mechanism, determine the minimum required standard deviation $\\sigma$ of the noise.\n\nExpress your answer as a symbolic expression in terms of the privacy parameters $\\epsilon$ and $\\delta$.", "solution": "We are given a counting query with $L_2$-sensitivity $\\Delta_2 = 1$, and the Gaussian mechanism releases $M(D) = f(D) + Z$ with $Z \\sim \\mathcal{N}(0, \\sigma^{2})$. The goal is to ensure $(\\epsilon, \\delta)$-differential privacy.\n\nThe standard calibration for the Gaussian mechanism states that, for $\\epsilon \\in (0,1)$, adding Gaussian noise with standard deviation\n$$\n\\sigma \\geq \\frac{\\Delta_2}{\\epsilon} \\sqrt{2 \\ln\\!\\left(\\frac{1.25}{\\delta}\\right)}\n$$\nensures $(\\epsilon, \\delta)$-differential privacy.\n\nSubstituting the given sensitivity $\\Delta_2 = 1$ into the calibration bound yields\n$$\n\\sigma \\geq \\frac{1}{\\epsilon} \\sqrt{2 \\ln\\!\\left(\\frac{1.25}{\\delta}\\right)}.\n$$\n\nTherefore, the minimum required standard deviation is obtained by equality:\n$$\n\\sigma_{\\min} = \\frac{\\sqrt{2 \\ln\\!\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}.\n$$", "answer": "$$\\boxed{\\frac{\\sqrt{2 \\ln\\!\\left(\\frac{1.25}{\\delta}\\right)}}{\\epsilon}}$$", "id": "1618211"}]}