{"hands_on_practices": [{"introduction": "This problem introduces the fundamental concept of information leakage, a cornerstone of information-theoretic security. By calculating the mutual information $I(M;C)$ between a message and its corresponding ciphertext, we can precisely quantify how much information an eavesdropper gains by observing the encrypted data. This exercise [@problem_id:1632441] provides a concrete example of how imperfections in a cryptographic scheme, such as a non-uniform key distribution, move us away from the ideal of perfect secrecy where $I(M;C) = 0$.", "problem": "In a simplified cryptographic scenario, a binary message $M$ is encrypted using a ternary key $K$. The message space is $\\mathcal{M} = \\{0, 1\\}$, and messages are chosen with uniform probability, i.e., $P(M=0) = P(M=1) = 1/2$. The key space is $\\mathcal{K} = \\{0, 1, 2\\}$. The key $K$ is drawn from this space according to the non-uniform probability distribution: $P(K=0) = 1/2$, and $P(K=1) = P(K=2) = 1/4$.\n\nThe message $M$ and key $K$ are statistically independent. The ciphertext $C$ is generated by the rule $C = (M + K) \\pmod 3$.\n\nCalculate the mutual information $I(M; C)$ between the message and the ciphertext. The calculation should be performed using logarithms in base 2, such that the result is in bits. Your final answer should be a single closed-form analytic expression.", "solution": "We are given $M \\in \\{0,1\\}$ with $P(M=0)=P(M=1)=\\frac{1}{2}$ and $K \\in \\{0,1,2\\}$ with $P(K=0)=\\frac{1}{2}$, $P(K=1)=P(K=2)=\\frac{1}{4}$, and $M \\perp K$. The ciphertext is $C=(M+K) \\bmod 3$. The mutual information is\n$$\nI(M;C)=H(C)-H(C|M),\n$$\nwith logarithms in base $2$.\n\nFirst compute the distribution of $C$. Using\n$$\nP(C=c)=\\sum_{m \\in \\{0,1\\}}\\sum_{k \\in \\{0,1,2\\}} P(M=m)P(K=k)\\,\\mathbf{1}\\{(m+k)\\bmod 3=c\\},\n$$\nwe obtain\n$$\nP(C=0)=\\frac{1}{2}\\cdot\\frac{1}{2}+\\frac{1}{2}\\cdot\\frac{1}{4}=\\frac{3}{8},\\quad\nP(C=1)=\\frac{1}{2}\\cdot\\frac{1}{4}+\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{3}{8},\\quad\nP(C=2)=\\frac{1}{2}\\cdot\\frac{1}{4}+\\frac{1}{2}\\cdot\\frac{1}{4}=\\frac{1}{4}.\n$$\nHence\n$$\nH(C)=-\\left(\\frac{3}{8}\\log_{2}\\frac{3}{8}+\\frac{3}{8}\\log_{2}\\frac{3}{8}+\\frac{1}{4}\\log_{2}\\frac{1}{4}\\right)\n=-\\left(\\frac{3}{4}\\log_{2}\\frac{3}{8}+\\frac{1}{4}\\log_{2}\\frac{1}{4}\\right).\n$$\nUsing $\\log_{2}\\frac{3}{8}=\\log_{2}3-3$ and $\\log_{2}\\frac{1}{4}=-2$,\n$$\nH(C)=-\\left(\\frac{3}{4}(\\log_{2}3-3)-\\frac{1}{2}\\right)\n=\\frac{11}{4}-\\frac{3}{4}\\log_{2}3.\n$$\n\nNext, for fixed $m$, the mapping $k \\mapsto (m+k)\\bmod 3$ is a permutation of $\\{0,1,2\\}$, so $C|M=m$ has the same distribution as $K$. Therefore,\n$$\nH(C|M)=H(K),\n$$\nand\n$$\nH(K)=-\\left(\\frac{1}{2}\\log_{2}\\frac{1}{2}+\\frac{1}{4}\\log_{2}\\frac{1}{4}+\\frac{1}{4}\\log_{2}\\frac{1}{4}\\right)\n=-\\left(-\\frac{1}{2}-\\frac{1}{2}-\\frac{1}{2}\\right)=\\frac{3}{2}.\n$$\n\nThus,\n$$\nI(M;C)=H(C)-H(C|M)=\\left(\\frac{11}{4}-\\frac{3}{4}\\log_{2}3\\right)-\\frac{3}{2}\n=\\frac{5}{4}-\\frac{3}{4}\\log_{2}3\n=\\frac{5-3\\log_{2}3}{4}.\n$$", "answer": "$$\\boxed{\\frac{5-3\\log_{2}(3)}{4}}$$", "id": "1632441"}, {"introduction": "Building on the idea of quantifying leakage, we now explore how to proactively design systems for secure communication. The wiretap channel model provides a powerful framework for this, enabling secure transmission by exploiting a physical advantage over an eavesdropper. This practice problem [@problem_id:1632419] challenges you to calculate the \"secrecy capacity,\" which represents the maximum rate of perfectly secure communication possible in a realistic scenario involving cascaded communication channels.", "problem": "A space agency is managing a communication link with a robotic explorer on a distant planetary moon. The explorer (Alice) sends binary data to the mission control center on Earth (Bob). Due to various forms of interference, the link behaves as a Binary Erasure Channel (BEC), where each transmitted bit is either received correctly or is erased (i.e., replaced by an erasure symbol 'e', indicating the bit's value is unknown). The probability of a bit being erased on this primary channel is $\\epsilon_B = 0.12$.\n\nAn adversarial agency (Eve) is attempting to eavesdrop on the transmission. Eve does not have a direct line-of-sight to the explorer. Instead, her listening post intercepts the signal after it has been unintentionally relayed through two separate, non-ideal relay points in sequence. The link from Alice to the first relay point is a BEC with erasure probability $\\epsilon_{E1} = 0.25$. The subsequent link from the first relay to Eve's final receiver (passing through the second relay) can be modeled as a single equivalent BEC with erasure probability $\\epsilon_{E2} = 0.35$. The erasure events in all channels are independent.\n\nCalculate the secrecy capacity of this communication system. The secrecy capacity is defined as the maximum achievable data rate (in bits per channel use) at which Alice can send information to Bob such that the communication is reliable for Bob, while Eve obtains absolutely no information about the message content. Express your answer as a decimal number, rounded to three significant figures.", "solution": "We model Alice-to-Bob as a Binary Erasure Channel (BEC) with erasure probability $\\epsilon_B$. We model Alice-to-Eve as a cascade of two independent BECs with erasure probabilities $\\epsilon_{E1}$ and $\\epsilon_{E2}$. For a cascade of two independent BECs, the end-to-end erasure probability is the probability that at least one hop erases the bit, given by\n$$\n\\epsilon_E \\;=\\; 1 - (1 - \\epsilon_{E1})(1 - \\epsilon_{E2}) \\;=\\; \\epsilon_{E1} + \\epsilon_{E2} - \\epsilon_{E1}\\epsilon_{E2}.\n$$\nSubstituting the given values $\\epsilon_{E1} = 0.25$ and $\\epsilon_{E2} = 0.35$,\n$$\n\\epsilon_E \\;=\\; 0.25 + 0.35 - (0.25)(0.35) \\;=\\; 0.60 - 0.0875 \\;=\\; 0.5125.\n$$\n\nFor a BEC with erasure probability $\\epsilon$ and binary input $X \\sim \\mathrm{Bernoulli}(p)$, the mutual information is\n$$\nI(X;Y) \\;=\\; (1 - \\epsilon) H_{2}(p),\n$$\nwhere $H_{2}(p)$ is the binary entropy function in bits,\n$$\nH_{2}(p) \\;=\\; -p \\log_{2}(p) - (1 - p)\\log_{2}(1 - p),\n$$\nwith maximum value $H_{2}(p) = 1$ attained at $p = \\tfrac{1}{2}$.\n\nFor the wiretap setting with Bob observing a BEC($\\epsilon_B$) and Eve observing a BEC($\\epsilon_E$) (with independent erasures), the secrecy rate achievable with input $X \\sim \\mathrm{Bernoulli}(p)$ is\n$$\nI(X;Y) - I(X;Z) \\;=\\; \\big[(1 - \\epsilon_B) - (1 - \\epsilon_E)\\big] H_{2}(p) \\;=\\; (\\epsilon_E - \\epsilon_B) H_{2}(p).\n$$\nMaximizing over $p$ gives $H_{2}(p) = 1$, so the secrecy capacity is\n$$\nC_{s} \\;=\\; \\max\\{0, \\epsilon_E - \\epsilon_B\\}.\n$$\nWith $\\epsilon_E = 0.5125$ and $\\epsilon_B = 0.12$,\n$$\nC_{s} \\;=\\; \\max\\{0, 0.5125 - 0.12\\} \\;=\\; 0.3925 \\text{ bits per channel use}.\n$$\nRounding to three significant figures yields $0.393$.", "answer": "$$\\boxed{0.393}$$", "id": "1632419"}, {"introduction": "Our final practice problem tackles one of the most practical topics in information-theoretic security: generating a shared secret key from correlated observations in the presence of a powerful, active adversary. This scenario goes beyond passive eavesdropping to consider an enemy who can alter communications, forcing us to account for the cryptographic \"cost\" of authentication. Solving this problem [@problem_id:1632411] reveals the fundamental trade-off between data reconciliation and security, leading to the net achievable secret key rate, a key performance metric in modern cryptography.", "problem": "Alice and Bob are two parties who wish to establish a shared secret key. They have access to a correlated random source, modeled as a Binary Symmetric Source (BSS). Specifically, for each time step $i=1, 2, \\dots, n$, Alice observes a bit $X_i$ and Bob observes a bit $Y_i$. The sequence $X^n = (X_1, \\dots, X_n)$ consists of independent and identically distributed random variables, each uniformly drawn from $\\{0, 1\\}$ (i.e., $P(X_i=0) = P(X_i=1) = 1/2$). Bob's sequence $Y^n$ is a noisy version of Alice's, where each bit $Y_i$ is generated according to the rule $Y_i = X_i \\oplus Z_i$, with $\\oplus$ denoting addition modulo 2. The noise sequence $Z^n = (Z_1, \\dots, Z_n)$ consists of independent and identically distributed random variables with $P(Z_i=1) = p$ and $P(Z_i=0) = 1-p$, where $p$ is the crossover probability. The noise is independent of Alice's sequence $X^n$.\n\nTo agree upon a key, Alice and Bob can communicate over a public, noiseless communication channel. However, this channel is under the complete control of an active adversary, Eve. Eve can not only listen to all messages but can also instantaneously and arbitrarily substitute any message sent by one party with a fraudulent message of her own construction before it reaches the other party.\n\nTo counteract Eve's active attacks, Alice and Bob must authenticate their public communications. A fundamental result from information-theoretic cryptography states that to guarantee the authenticity of a public message stream against such an adversary, a shared secret key must be consumed at a rate equal to the rate of the message stream being authenticated. This consumed key must be continually replenished from the new key material generated by the protocol.\n\nAssume Alice and Bob use an optimal one-way reconciliation protocol where Alice sends a public message to Bob of the minimum necessary length to allow him to perfectly recover her sequence $X^n$. The total key material generated must first be used to replenish the key consumed for authenticating this public message. The remainder is the net secret key available for external use.\n\nGiven a crossover probability of $p = 0.1$, what is the maximum net achievable secret key rate, in bits per source symbol? The binary entropy function is given by $h_2(q) = -q \\log_2(q) - (1-q) \\log_2(1-q)$. Your final answer should be a single real number, rounded to three significant figures.", "solution": "Alice observes $X \\sim \\text{Bernoulli}\\!\\left(\\frac{1}{2}\\right)$ i.i.d., Bob observes $Y = X \\oplus Z$ with $Z \\sim \\text{Bernoulli}(p)$ independent of $X$. Thus the pair $(X,Y)$ is a binary symmetric channel with crossover probability $p$, yielding\n$$\nH(X) = 1, \\quad H(X|Y) = h_{2}(p), \\quad I(X;Y) = H(X) - H(X|Y) = 1 - h_{2}(p).\n$$\nUsing optimal one-way reconciliation from Alice to Bob, the minimum public communication rate that allows Bob to recover $X^{n}$ with vanishing error is the Slepian-Wolf limit $H(X|Y) = h_{2}(p)$ bits per source symbol. Authenticating this public message stream against an active adversary requires consuming a pre-shared key at a rate equal to the public message rate, namely $h_{2}(p)$ bits per source symbol.\n\nWith authenticated public communication and no additional eavesdropper side information beyond the public transcript, the maximum secret key rate that Alice and Bob can generate from the correlated source is the secret key capacity\n$$\nR_{\\text{gen}} = I(X;Y) = 1 - h_{2}(p).\n$$\nSince the consumed authentication key must be replenished from the generated key material, the net externally available key rate is\n$$\nR_{\\text{net}} = R_{\\text{gen}} - R_{\\text{auth}} = \\bigl(1 - h_{2}(p)\\bigr) - h_{2}(p) = 1 - 2 h_{2}(p).\n$$\n\nFor $p = 0.1$, the binary entropy is\n$$\nh_{2}(0.1) = -0.1 \\log_{2}(0.1) - 0.9 \\log_{2}(0.9).\n$$\nCompute each term:\n$$\n-0.1 \\log_{2}(0.1) = -0.1 \\cdot \\bigl(-3.321928094...\\bigr) = 0.332192809...,\n$$\n$$\n-0.9 \\log_{2}(0.9) = -0.9 \\cdot \\bigl(-0.152003093...\\bigr) = 0.136802784...,\n$$\nhence\n$$\nh_{2}(0.1) \\approx 0.332192809 + 0.136802784 = 0.468995594.\n$$\nTherefore,\n$$\nR_{\\text{net}} = 1 - 2 h_{2}(0.1) \\approx 1 - 2 \\times 0.468995594 = 0.062008812.\n$$\nRounding to three significant figures gives $0.0620$ bits per source symbol.", "answer": "$$\\boxed{0.0620}$$", "id": "1632411"}]}