{"hands_on_practices": [{"introduction": "Before a Maxwell's demon can sort molecules and extract work, it must first gather information about the system. This first practice problem, [@problem_id:1640708], grounds the abstract concept of \"information\" in a concrete, quantifiable unit: the bit. By determining the minimum number of yes/no questions needed to locate a particle, we establish the fundamental currency that underpins the entire thought experiment and its resolution.", "problem": "An experimental physicist is designing a nanoscale device intended to function as a simplified Maxwell's demon. The core of the experiment involves a single inert gas molecule confined within a sealed, rigid chamber. For the device's control system to operate, it must first determine the molecule's location. The chamber is conceptually partitioned into a grid of 64 distinct, non-overlapping, and identical cells. At any given moment, the molecule is assumed to have an equal probability of being found in any one of these cells.\n\nThe locating process is carried out by a measurement apparatus that can ask a series of \"yes/no\" questions to ascertain the molecule's position. An optimal question is one that halves the number of remaining possibilities. For example, a valid first question could be, \"Is the molecule located in the set of cells numbered 1 through 32?\".\n\nWhat is the absolute minimum number of such optimal yes/no questions that the apparatus must ask to guarantee the unique identification of the cell containing the molecule?", "solution": "We need the minimum number of binary (yes/no) questions that can uniquely identify one outcome among $N=64$ equally likely possibilities using optimal halving. Each yes/no question provides at most $1$ bit of information, and with $k$ such questions, the maximum number of distinct outcomes (leaves in a binary decision tree) is $2^{k}$.\n\nTo guarantee unique identification among $N$ possibilities, we require\n$$\n2^{k} \\geq N.\n$$\nWith $N=64$, this becomes\n$$\n2^{k} \\geq 64.\n$$\nTaking base-$2$ logarithms yields\n$$\nk \\geq \\log_{2}(64) = \\log_{2}(2^{6}) = 6.\n$$\nTherefore, the minimal integer number of questions needed is\n$$\nk_{\\min} = \\lceil \\log_{2}(64) \\rceil = 6.\n$$\nSince each optimal question halves the remaining possibilities, six such halvings reduce $64$ to $1$, confirming that $6$ questions suffice and are necessary.", "answer": "$$\\boxed{6}$$", "id": "1640708"}, {"introduction": "Once a demon possesses information, how can it be converted into useful energy? This exercise, [@problem_id:1640693], presents a classic single-molecule heat engine to demonstrate this conversion directly. You will calculate the average work, $\\langle W \\rangle$, that can be extracted by leveraging knowledge of a particle's location, illustrating the core principle that information is a thermodynamic resource.", "problem": "A simple model of a one-molecule engine is constructed as follows: A single molecule, which behaves as an ideal gas particle, is confined within a closed container of total volume $V$. The container is maintained in thermal equilibrium with a large heat bath at a constant absolute temperature $T$.\n\nA hypothetical entity, often called a Maxwell's demon, can perform a measurement to determine the location of the molecule. The measurement has two possible outcomes: either the molecule is in the left one-third of the container (a sub-volume of $V/3$), or it is in the right two-thirds of the container (a sub-volume of $2V/3$).\n\nImmediately following the measurement, a partition is inserted cost-free to trap the molecule in the sub-volume where it was found. Then, this confined molecule is allowed to expand isothermally and reversibly against an external piston until it once again occupies the full volume $V$. This sequence of measurement, partitioning, and expansion constitutes one complete operational cycle.\n\nCalculate the maximum average work that can be extracted from the heat bath per cycle. Express your answer as an analytic expression in terms of the Boltzmann constant $k_B$ and the temperature $T$.", "solution": "The molecule is an ideal gas particle in thermal contact with a heat bath at temperature $T$. After the demon measures the location, a partition is inserted to confine the particle to the sub-volume where it was found, and then the particle expands isothermally and reversibly to the full volume $V$, doing work extracted from the heat bath.\n\nFor a single ideal gas particle undergoing a reversible isothermal expansion from an initial volume $V_{i}$ to a final volume $V_{f}$, the work extracted is obtained from the ideal gas law $pV = k_{B}T$ (with one particle), giving $p = k_{B}T/V$. Then\n$$\nW = \\int_{V_{i}}^{V_{f}} p\\,dV = \\int_{V_{i}}^{V_{f}} \\frac{k_{B}T}{V}\\,dV = k_{B}T \\ln\\!\\left(\\frac{V_{f}}{V_{i}}\\right).\n$$\n\nThe measurement has two outcomes:\n- Left one-third sub-volume $V/3$ with probability $p_{L} = \\frac{1}{3}$, leading to work\n$$\nW_{L} = k_{B}T \\ln\\!\\left(\\frac{V}{V/3}\\right) = k_{B}T \\ln 3.\n$$\n- Right two-thirds sub-volume $2V/3$ with probability $p_{R} = \\frac{2}{3}$, leading to work\n$$\nW_{R} = k_{B}T \\ln\\!\\left(\\frac{V}{2V/3}\\right) = k_{B}T \\ln\\!\\left(\\frac{3}{2}\\right).\n$$\n\nThe maximum average work per cycle is the probability-weighted sum:\n$$\n\\langle W \\rangle_{\\max} = p_{L} W_{L} + p_{R} W_{R} = \\frac{1}{3} k_{B}T \\ln 3 + \\frac{2}{3} k_{B}T \\ln\\!\\left(\\frac{3}{2}\\right).\n$$\nThis simplifies to\n$$\n\\langle W \\rangle_{\\max} = k_{B}T\\left[\\ln 3 - \\frac{2}{3} \\ln 2\\right] = k_{B}T \\ln\\!\\left(\\frac{3}{2^{2/3}}\\right).\n$$\nThis is the maximum average work extracted from the heat bath per cycle under the stated idealizations.", "answer": "$$\\boxed{k_{B}T\\left(\\ln 3 - \\frac{2}{3}\\ln 2\\right)}$$", "id": "1640693"}, {"introduction": "Ideal demons have flawless sensors, but real-world measurements are inevitably noisy. This final practice, [@problem_id:1640651], introduces a more realistic demon with a faulty measurement device. You will use the powerful concept of mutual information, $I(X;Y)$, to quantify exactly how much \"useful\" information is gained in an uncertain scenario, highlighting how imperfection limits the potential to extract work.", "problem": "Consider a simplified model inspired by Maxwell's demon. A single gas particle is confined to a box divided into two equal, identical chambers, labeled \"Left\" and \"Right\". The particle has an equal probability of being in either chamber at any given moment. Let the random variable $X$ represent the true position of the particle, with outcomes {Left, Right}. A hypothetical \"demon\" attempts to determine the particle's location by making a measurement. Let the random variable $Y$ represent the outcome of the demon's measurement, which can also be {Left, Right}.\n\nThe demon's sensor is faulty. The probability that the demon correctly identifies the particle's chamber is $p = 0.75$. This means that if the particle is in the Left chamber, the demon measures it as \"Left\" with probability $p$, and if the particle is in the Right chamber, the demon measures it as \"Right\" with probability $p$.\n\nCalculate the mutual information, $I(X;Y)$, between the true position of the particle and the demon's measurement. Express your answer in units of bits, and round your final answer to three significant figures. For all calculations, use the base-2 logarithm.", "solution": "The problem asks for the mutual information $I(X;Y)$ between the particle's true position $X$ and the demon's measurement $Y$. The mutual information quantifies the reduction in uncertainty about one variable from observing the other. It can be calculated using the formula:\n$$I(X;Y) = H(Y) - H(Y|X)$$\nwhere $H(Y)$ is the entropy of the measurement outcome and $H(Y|X)$ is the conditional entropy of the measurement given the true particle position.\n\n**Step 1: Define the probabilities**\n\nLet the outcomes of $X$ be {$L, R$} for Left and Right. Since the particle has an equal probability of being in either chamber:\n$$P(X=L) = 0.5$$\n$$P(X=R) = 0.5$$\n\nLet the outcomes of $Y$ also be {$L, R$}. The problem states that the sensor is correct with probability $p=0.75$. This gives us the conditional probabilities:\n$$P(Y=L | X=L) = p = 0.75$$\n$$P(Y=R | X=L) = 1-p = 0.25$$\n$$P(Y=R | X=R) = p = 0.75$$\n$$P(Y=L | X=R) = 1-p = 0.25$$\n\n**Step 2: Calculate the conditional entropy $H(Y|X)$**\n\nThe conditional entropy $H(Y|X)$ is the average entropy of $Y$ for each possible value of $X$, weighted by the probability of $X$.\n$$H(Y|X) = \\sum_{x \\in \\{L, R\\}} P(X=x) H(Y|X=x)$$\nFirst, we find the entropy of the measurement conditional on the particle being in a specific chamber. The entropy for a binary variable with probabilities $q$ and $1-q$ is $H_b(q) = -q \\log_2(q) - (1-q) \\log_2(1-q)$.\n\nFor $X=L$:\n$H(Y|X=L) = -P(Y=L|X=L)\\log_2(P(Y=L|X=L)) - P(Y=R|X=L)\\log_2(P(Y=R|X=L))$\n$H(Y|X=L) = -p\\log_2(p) - (1-p)\\log_2(1-p)$\n\nFor $X=R$:\n$H(Y|X=R) = -P(Y=L|X=R)\\log_2(P(Y=L|X=R)) - P(Y=R|X=R)\\log_2(P(Y=R|X=R))$\n$H(Y|X=R) = -(1-p)\\log_2(1-p) - p\\log_2(p)$\n\nBoth conditional entropies are equal to the binary entropy function $H_b(p)$. Therefore:\n$H(Y|X) = P(X=L) H_b(p) + P(X=R) H_b(p)$\n$H(Y|X) = (0.5 + 0.5) H_b(p) = H_b(p)$\n$H(Y|X) = -p\\log_2(p) - (1-p)\\log_2(1-p)$\n\nSubstitute $p=0.75$ and $1-p=0.25$:\n$H(Y|X) = -0.75 \\log_2(0.75) - 0.25 \\log_2(0.25)$\n$H(Y|X) \\approx -0.75(-0.415037) - 0.25(-2)$\n$H(Y|X) \\approx 0.311278 + 0.5$\n$H(Y|X) \\approx 0.811278 \\text{ bits}$\n\n**Step 3: Calculate the entropy of the measurement $H(Y)$**\n\nFirst, we need the marginal probabilities for the measurement outcome $Y$. We use the law of total probability:\n$P(Y=L) = P(Y=L|X=L)P(X=L) + P(Y=L|X=R)P(X=R)$\n$P(Y=L) = (p)(0.5) + (1-p)(0.5) = (0.75)(0.5) + (0.25)(0.5) = 0.375 + 0.125 = 0.5$\n\nSince the probabilities must sum to 1:\n$P(Y=R) = 1 - P(Y=L) = 1 - 0.5 = 0.5$\n\nNow we can calculate the entropy of $Y$:\n$H(Y) = -P(Y=L)\\log_2(P(Y=L)) - P(Y=R)\\log_2(P(Y=R))$\n$H(Y) = -0.5\\log_2(0.5) - 0.5\\log_2(0.5)$\n$H(Y) = -1 \\times 0.5 \\log_2(0.5) \\times 2 = -\\log_2(0.5) = -\\log_2(2^{-1}) = -(-1) = 1 \\text{ bit}$\n\n**Step 4: Calculate the mutual information $I(X;Y)$**\n\nNow we substitute the values of $H(Y)$ and $H(Y|X)$ into the mutual information formula:\n$I(X;Y) = H(Y) - H(Y|X)$\n$I(X;Y) \\approx 1 - 0.811278$\n$I(X;Y) \\approx 0.188722 \\text{ bits}$\n\nAlternatively, we can express this symbolically:\n$I(X;Y) = 1 - [-p\\log_2(p) - (1-p)\\log_2(1-p)]$\n$I(X;Y) = 1 + p\\log_2(p) + (1-p)\\log_2(1-p)$\nWith $p=0.75$:\n$I(X;Y) = 1 + 0.75 \\log_2(0.75) + 0.25 \\log_2(0.25)$\n$I(X;Y) \\approx 1 + 0.75(-0.415037) + 0.25(-2)$\n$I(X;Y) \\approx 1 - 0.311278 - 0.5 = 0.188722 \\text{ bits}$\n\n**Step 5: Round the final answer**\n\nThe problem asks to round the answer to three significant figures.\n$0.188722 \\approx 0.189$\n\nThe mutual information gained from one measurement is approximately 0.189 bits.", "answer": "$$\\boxed{0.189}$$", "id": "1640651"}]}