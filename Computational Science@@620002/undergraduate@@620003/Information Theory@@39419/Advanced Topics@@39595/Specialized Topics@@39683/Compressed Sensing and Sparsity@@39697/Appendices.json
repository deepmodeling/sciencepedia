{"hands_on_practices": [{"introduction": "The journey into compressed sensing begins with understanding the measurement process itself. This initial practice focuses on the forward problem, governed by the linear model $y = Ax$, where we simulate how a sparse, high-dimensional signal $x$ is compressed into a much smaller set of measurements $y$. By performing this calculation [@problem_id:1612169], you will gain a concrete understanding of how the signal's sparsity directly simplifies the computation of the measurement vector, laying the groundwork for the more complex task of signal recovery.", "problem": "In the field of compressed sensing, a high-dimensional sparse signal can be reconstructed from a small number of linear measurements. The fundamental process of acquiring these measurements is described by the linear model $y = Ax$, where $x \\in \\mathbb{R}^N$ is the original signal, $A$ is an $M \\times N$ matrix known as the sensing matrix (with $M \\ll N$), and $y \\in \\mathbb{R}^M$ is the resulting measurement vector.\n\nConsider a sparse signal $x \\in \\mathbb{R}^{16}$ that is known to be \"3-sparse,\" meaning it has at most three non-zero elements. At a specific time, the non-zero elements of this signal are located at the 2nd, 7th, and 12th positions (using 1-based indexing), with corresponding values of $3$, $-2$, and $5$, respectively. All other components of $x$ are zero.\n\nThe signal $x$ is measured using a $4 \\times 16$ sensing matrix $A$ given by:\n$$\nA = \\begin{pmatrix}\n1  2  0  1  -1  0  3  1  0  1  2  -2  1  0  -1  1 \\\\\n-1  1  1  0  2  1  -1  0  1  2  0  1  0  3  1  0 \\\\\n0  1  -2  1  0  1  1  -1  2  0  1  1  -1  2  0  1 \\\\\n2  -1  1  0  1  -2  0  2  -1  1  0  -1  2  1  1  -1\n\\end{pmatrix}\n$$\nCalculate the measurement vector $y \\in \\mathbb{R}^4$. Express your answer as a $1 \\times 4$ row matrix.", "solution": "We are given a linear measurement model $y = Ax$ with $x \\in \\mathbb{R}^{16}$ being $3$-sparse. The nonzero entries are at indices $2$, $7$, and $12$ (1-based), with values $x_{2} = 3$, $x_{7} = -2$, and $x_{12} = 5$, and all other entries are zero. Therefore,\n$$\nx = \\begin{pmatrix}\n0 \\\\ 3 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ -2 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 5 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\n\\end{pmatrix}.\n$$\nBy linearity of matrix-vector multiplication, $y = Ax$ can be expressed as a linear combination of the columns of $A$. Denote the $j$-th column of $A$ by $a_{j}$. Then\n$$\ny = \\sum_{j=1}^{16} x_{j} a_{j} = 3 a_{2} - 2 a_{7} + 5 a_{12}.\n$$\nFrom the given matrix $A$, we read the relevant columns:\n$$\na_{2} = \\begin{pmatrix} 2 \\\\ 1 \\\\ 1 \\\\ -1 \\end{pmatrix}, \\quad\na_{7} = \\begin{pmatrix} 3 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\na_{12} = \\begin{pmatrix} -2 \\\\ 1 \\\\ 1 \\\\ -1 \\end{pmatrix}.\n$$\nCompute each scaled column:\n$$\n3 a_{2} = \\begin{pmatrix} 6 \\\\ 3 \\\\ 3 \\\\ -3 \\end{pmatrix}, \\quad\n-2 a_{7} = \\begin{pmatrix} -6 \\\\ 2 \\\\ -2 \\\\ 0 \\end{pmatrix}, \\quad\n5 a_{12} = \\begin{pmatrix} -10 \\\\ 5 \\\\ 5 \\\\ -5 \\end{pmatrix}.\n$$\nAdd these vectors componentwise to obtain $y$:\n$$\ny = \\begin{pmatrix} 6 \\\\ 3 \\\\ 3 \\\\ -3 \\end{pmatrix}\n+ \\begin{pmatrix} -6 \\\\ 2 \\\\ -2 \\\\ 0 \\end{pmatrix}\n+ \\begin{pmatrix} -10 \\\\ 5 \\\\ 5 \\\\ -5 \\end{pmatrix}\n= \\begin{pmatrix} -10 \\\\ 10 \\\\ 6 \\\\ -8 \\end{pmatrix}.\n$$\nExpressed as a $1 \\times 4$ row matrix, the measurement vector is\n$$\n\\begin{pmatrix} -10  10  6  -8 \\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-10  10  6  -8\\end{pmatrix}}$$", "id": "1612169"}, {"introduction": "Having seen how measurements are formed, we now confront the central challenge of compressed sensing: recovering the original signal. Since we typically take fewer measurements than the signal's dimension ($M \\lt N$), the system $y = Ax$ is underdetermined, meaning it can have multiple solutions. This exercise [@problem_id:1612133] compellingly demonstrates this ambiguity by showing how a single measurement vector can be generated by both a sparse signal and a completely different, non-sparse signal, highlighting the need for a guiding principle to select the \"correct\" one.", "problem": "In a simplified signal acquisition model, a measurement vector $y \\in \\mathbb{R}^{2}$ is obtained from an original signal vector $x \\in \\mathbb{R}^{3}$ via the linear transformation $y=Ax$, where $A$ is the sensing matrix. A vector is defined as $k$-sparse if it contains exactly $k$ non-zero elements.\n\nGiven the sensing matrix $A = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\end{pmatrix}$ and the measurement vector $y = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}$, it is known that two different signals, $x_A$ and $x_B$, can produce this same measurement $y$. Signal $x_A$ is 2-sparse. Signal $x_B$ is 3-sparse (i.e., non-sparse, with no zero elements) and has the additional property that all of its components are equal.\n\nDetermine the components of both signals, $x_A=[x_{A1}, x_{A2}, x_{A3}]^T$ and $x_B=[x_{B1}, x_{B2}, x_{B3}]^T$. Present your final answer as a single row of numbers representing the components in the order ($x_{A1}, x_{A2}, x_{A3}, x_{B1}, x_{B2}, x_{B3}$).", "solution": "We are given $y=Ax$ with $A=\\begin{pmatrix}1  0  1 \\\\ 0  1  1\\end{pmatrix}$ and $y=\\begin{pmatrix}2 \\\\ 2\\end{pmatrix}$. Writing $x=\\begin{pmatrix}x_{1} \\\\ x_{2} \\\\ x_{3}\\end{pmatrix}$, the measurement equations are\n$$\nx_{1}+x_{3}=2,\\quad x_{2}+x_{3}=2.\n$$\nSolving these in terms of the free parameter $s:=x_{3}$ gives\n$$\nx_{1}=2-s,\\quad x_{2}=2-s,\\quad x_{3}=s,\n$$\nso the full solution set is\n$$\nx=\\begin{pmatrix}2-s \\\\ 2-s \\\\ s\\end{pmatrix},\\quad s\\in\\mathbb{R}.\n$$\nFor the 3-sparse signal $x_{B}$ with all components equal, let $x_{B1}=x_{B2}=x_{B3}=t$ with $t\\neq 0$. Substituting into the equations yields $t+t=2$, hence $2t=2$ and $t=1$. Therefore,\n$$\nx_{B}=\\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix}.\n$$\nFor the 2-sparse signal $x_{A}$, exactly one component must be zero. From $x=\\begin{pmatrix}2-s \\\\ 2-s \\\\ s\\end{pmatrix}$, the possibilities for a zero component are:\n- $s=0$ gives $x=\\begin{pmatrix}2 \\\\ 2 \\\\ 0\\end{pmatrix}$, which has exactly two non-zero entries.\n- $s=2$ gives $x=\\begin{pmatrix}0 \\\\ 0 \\\\ 2\\end{pmatrix}$, which is 1-sparse and thus invalid.\n- For $s\\neq 0,2$, all three components are non-zero, giving a 3-sparse vector.\nThus the unique 2-sparse solution is\n$$\nx_{A}=\\begin{pmatrix}2 \\\\ 2 \\\\ 0\\end{pmatrix}.\n$$\nThe components in the required order are $(x_{A1},x_{A2},x_{A3},x_{B1},x_{B2},x_{B3})=(2,2,0,1,1,1)$.", "answer": "$$\\boxed{\\begin{pmatrix} 2  2  0  1  1  1 \\end{pmatrix}}$$", "id": "1612133"}, {"introduction": "To resolve the ambiguity unveiled in the previous practice, compressed sensing introduces a powerful principle: finding the solution with the minimum $\\ell_1$-norm. The $\\ell_1$-norm, defined as the sum of the absolute values of a signal's components, serves as a mathematical proxy for sparsity, and minimizing it often leads directly to the sought-after sparse signal. In this final practice [@problem_id:1612160], you will apply this very principle to an underdetermined system, discovering for yourself how minimizing the $\\ell_1$-norm effectively selects for a sparse solution from an infinite set of possibilities.", "problem": "In the field of signal processing, the principle of compressed sensing allows for the reconstruction of a signal from a limited number of measurements, under the assumption that the signal is sparse. A signal is considered sparse if a large number of its components are zero. This reconstruction often involves solving an underdetermined system of linear equations by finding the solution with the minimum $\\ell_1$-norm, a process that promotes sparsity.\n\nConsider a signal represented by a vector $x = (x_1, x_2, x_3)$ in a three-dimensional space $\\mathbb{R}^3$. A measurement process has subjected the signal to the following two linear constraints:\n$$x_1 + x_2 + 2x_3 = 1$$\n$$x_1 - x_2 = \\frac{1}{2}$$\nThe $\\ell_1$-norm of the vector $x$, denoted as $\\|x\\|_1$, is defined by the sum of the absolute values of its components:\n$$\\|x\\|_1 = |x_1| + |x_2| + |x_3|$$\nDetermine the signal vector $(x_1, x_2, x_3)$ that satisfies both measurement constraints and has the minimum possible $\\ell_1$-norm. Express your answer as a row vector of three components.", "solution": "We are given the linear constraints\n$$x_{1}+x_{2}+2x_{3}=1,\\qquad x_{1}-x_{2}=\\frac{1}{2}.$$\nSolve these equations to parameterize the solution set. From $x_{1}-x_{2}=\\frac{1}{2}$, we have $x_{1}=x_{2}+\\frac{1}{2}$. Substitute into $x_{1}+x_{2}+2x_{3}=1$ to get\n$$(x_{2}+\\frac{1}{2})+x_{2}+2x_{3}=1 \\;\\;\\Rightarrow\\;\\; 2x_{2}+2x_{3}=\\frac{1}{2} \\;\\;\\Rightarrow\\;\\; x_{2}+\\!x_{3}=\\frac{1}{4}.$$\nHence $x_{2}=\\frac{1}{4}-x_{3}$ and\n$$x_{1}=x_{2}+\\frac{1}{2}=\\frac{1}{4}-x_{3}+\\frac{1}{2}=\\frac{3}{4}-x_{3}.$$\nLet $t=x_{3}$. Then all feasible solutions are\n$$(x_{1},x_{2},x_{3})=\\left(\\frac{3}{4}-t,\\;\\frac{1}{4}-t,\\;t\\right).$$\nThe objective to minimize is the L1-norm\n$$\\|x\\|_{1}=|x_{1}|+|x_{2}|+|x_{3}|=\\left|\\frac{3}{4}-t\\right|+\\left|\\frac{1}{4}-t\\right|+|t|.$$\nObserve that\n$$\\left|\\frac{3}{4}-t\\right|+\\left|\\frac{1}{4}-t\\right|+|t|=\\big|t-\\frac{3}{4}\\big|+\\big|t-\\frac{1}{4}\\big|+|t-0|,$$\nwhich is a sum of absolute deviations from the points $\\{0,\\frac{1}{4},\\frac{3}{4}\\}$. A standard property of the function $g(t)=\\sum_{i}|t-a_{i}|$ is that it is convex and minimized at any median of the set $\\{a_{i}\\}$. With three points, the median is unique and equals $\\frac{1}{4}$. Therefore the minimizing parameter is\n$$t^{\\ast}=\\frac{1}{4}.$$\nSubstituting $t^{\\ast}$ back gives\n$$x_{1}=\\frac{3}{4}-\\frac{1}{4}=\\frac{1}{2},\\qquad x_{2}=\\frac{1}{4}-\\frac{1}{4}=0,\\qquad x_{3}=\\frac{1}{4}.$$\nThis vector satisfies both constraints and has minimum L1-norm. For completeness, the minimum norm value is $|\\,\\frac{1}{2}\\,|+|0|+|\\,\\frac{1}{4}\\,|=\\frac{3}{4}$, confirming optimality.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{2}  0  \\frac{1}{4}\\end{pmatrix}}$$", "id": "1612160"}]}