{"hands_on_practices": [{"introduction": "The first step in exploring the landscape of probability distributions is to have a way to measure distances. The Fisher information provides a metric for this space, quantifying how distinguishable two nearby distributions are. This first exercise [@problem_id:1631455] provides fundamental practice by having you calculate the Fisher information for the geometric distribution, a common model for 'time-to-first-event' scenarios. Mastering this calculation is key to understanding the local structure of statistical manifolds.", "problem": "A quality control engineer is testing a batch of newly manufactured microchips. The probability that any given chip is defective (a 'success' in this statistical context) is $p$, where $0 < p < 1$. The chips are tested one by one. Let the random variable $K$ be the number of chips tested until the first defective one is found. The process is modeled by a geometric distribution, where the probability mass function for $K$ is given by:\n$$P(K=k; p) = (1-p)^{k-1}p$$\nfor $k = 1, 2, 3, \\ldots$.\n\nThe Fisher information, $I(p)$, quantifies the amount of information that the observable random variable $K$ carries about the unknown parameter $p$. It is a fundamental concept in statistical inference and information geometry, and is crucial for determining the best possible precision for estimating the parameter $p$.\n\nDetermine the Fisher information $I(p)$ for the parameter $p$ of this geometric distribution. Express your answer as a function of $p$.", "solution": "We have a single observation $K$ from the geometric distribution with pmf $P(K=k;p)=(1-p)^{k-1}p$ for $k\\in\\{1,2,\\ldots\\}$. The log-likelihood for parameter $p$ is\n$$\n\\ell(p;K)=\\ln P(K; p)=\\ln p+(K-1)\\ln(1-p).\n$$\nDifferentiate with respect to $p$ to obtain the score:\n$$\n\\frac{\\partial \\ell}{\\partial p}=\\frac{1}{p}+(K-1)\\frac{\\partial}{\\partial p}\\ln(1-p)=\\frac{1}{p}-\\frac{K-1}{1-p}.\n$$\nDifferentiate again to get the observed information (negative of the second derivative of the log-likelihood):\n$$\n\\frac{\\partial^{2} \\ell}{\\partial p^{2}}=-\\frac{1}{p^{2}}-(K-1)\\frac{\\partial}{\\partial p}\\left(\\frac{1}{1-p}\\right)=-\\frac{1}{p^{2}}-\\frac{K-1}{(1-p)^{2}}.\n$$\nThe Fisher information is the negative expectation of this second derivative:\n$$\nI(p)=-\\operatorname{E}\\!\\left[\\frac{\\partial^{2} \\ell}{\\partial p^{2}}\\right]=\\frac{1}{p^{2}}+\\frac{\\operatorname{E}[K-1]}{(1-p)^{2}}.\n$$\nUsing the known mean of the geometric distribution with support starting at $1$, $\\operatorname{E}[K]=\\frac{1}{p}$, we have\n$$\n\\operatorname{E}[K-1]=\\frac{1}{p}-1=\\frac{1-p}{p}.\n$$\nSubstitute this into the expression for $I(p)$:\n$$\nI(p)=\\frac{1}{p^{2}}+\\frac{(1-p)/p}{(1-p)^{2}}=\\frac{1}{p^{2}}+\\frac{1}{p(1-p)}.\n$$\nCombine over the common denominator $p^{2}(1-p)$:\n$$\nI(p)=\\frac{1-p+p}{p^{2}(1-p)}=\\frac{1}{p^{2}(1-p)}.\n$$\nTherefore, the Fisher information for $p$ is $I(p)=\\frac{1}{p^{2}(1-p)}$.", "answer": "$$\\boxed{\\frac{1}{p^{2}(1-p)}}$$", "id": "1631455"}, {"introduction": "With a metric in hand, we can now explore the geometry it induces. Statistical manifolds possess a rich structure, including a version of the Pythagorean theorem that applies to information divergence instead of Euclidean distance. This practice [@problem_id:1631519] offers a concrete opportunity to verify this remarkable theorem by finding the 'projection' of one probability distribution onto a constrained family of distributions and confirming the relationship between the relevant Kullback-Leibler ($D_{KL}$) divergences.", "problem": "In the field of information geometry, the set of all probability distributions of a given form can be viewed as a smooth manifold. For a discrete random variable with three possible outcomes, the set of all possible probability distributions forms a 2-dimensional statistical manifold, which can be thought of as a simplex in $\\mathbb{R}^3$.\n\nConsider three specific probability distributions, $P$ and $R$, for a random variable that can take one of three states $\\{1, 2, 3\\}$. The distributions are given by the probability vectors:\n- $P = (p_1, p_2, p_3) = (1/2, 1/4, 1/4)$\n- $R = (r_1, r_2, r_3) = (1/3, 1/3, 1/3)$\n\nLet $S$ be a 1-dimensional submanifold within this space, defined by the linear constraint that the probabilities of the first two outcomes are equal. That is, $S = \\{Q = (q_1, q_2, q_3) | q_1 = q_2 \\text{ and } \\sum q_i = 1, q_i > 0\\}$.\n\nThe information-geometric Pythagorean theorem relates a point $P$ to its projection on a submanifold $S$. The \"e-projection\" of $P$ onto $S$, which we will denote as $P^*$, is the unique point in $S$ that minimizes the Kullback-Leibler (KL) divergence from $P$ to points in $S$. The KL divergence is defined as $D_{KL}(A||B) = \\sum_{i} a_i \\ln(a_i/b_i)$ for two distributions $A=(a_i)$ and $B=(b_i)$. The theorem states that for the setup described, $D_{KL}(P||R) = D_{KL}(P||P^*) + D_{KL}(P^*||R)$.\n\nYour task is to verify this theorem for the given distributions. First, find the e-projection $P^*$ of $P$ onto the submanifold $S$. Then, compute the values of the three divergences: $A = D_{KL}(P||R)$, $B = D_{KL}(P||P^*)$, and $C = D_{KL}(P^*||R)$.\n\nCalculate the numerical value of the ratio $\\frac{A}{B+C}$. The final result should be an exact value, not a decimal approximation.", "solution": "We are given $P=(p_{1},p_{2},p_{3})=(\\frac{1}{2},\\frac{1}{4},\\frac{1}{4})$, $R=(r_{1},r_{2},r_{3})=(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3})$, and the submanifold $S=\\{Q=(q_{1},q_{2},q_{3}):q_{1}=q_{2},\\,q_{1}+q_{2}+q_{3}=1,\\,q_{i}>0\\}$.\n\nTo find the e-projection $P^{*}$ of $P$ onto $S$, we minimize $D_{KL}(P\\|Q)=\\sum_{i=1}^{3}p_{i}\\ln\\!\\left(\\frac{p_{i}}{q_{i}}\\right)$ over $Q\\in S$. Since $\\sum_{i}p_{i}\\ln p_{i}$ is constant with respect to $Q$, this is equivalent to minimizing\n$$\nf(Q)=-\\sum_{i=1}^{3}p_{i}\\ln q_{i}\n$$\nsubject to $q_{1}=q_{2}$ and $q_{1}+q_{2}+q_{3}=1$. Let $q_{1}=q_{2}=t$ and $q_{3}=1-2t$ with $0<t<\\frac{1}{2}$. Then\n$$\nf(t)=-(p_{1}+p_{2})\\ln t-p_{3}\\ln(1-2t).\n$$\nDifferentiate and set to zero:\n$$\n\\frac{df}{dt}=-\\frac{p_{1}+p_{2}}{t}+\\frac{2p_{3}}{1-2t}=0\n\\quad\\Longrightarrow\\quad\n\\frac{2p_{3}}{1-2t}=\\frac{p_{1}+p_{2}}{t}.\n$$\nCross-multiplying gives\n$$\n2p_{3}t=(p_{1}+p_{2})(1-2t)\n\\;\\Longrightarrow\\;\n2\\big(p_{3}+p_{1}+p_{2}\\big)t=p_{1}+p_{2}\n\\;\\Longrightarrow\\;\n2t=p_{1}+p_{2}\n\\;\\Longrightarrow\\;\nt=\\frac{p_{1}+p_{2}}{2}.\n$$\nSince $p_{1}+p_{2}+p_{3}=1$, it follows that $q_{3}=1-2t=p_{3}$. Therefore\n$$\nP^{*}=\\left(\\frac{p_{1}+p_{2}}{2},\\,\\frac{p_{1}+p_{2}}{2},\\,p_{3}\\right)=\\left(\\frac{3}{8},\\,\\frac{3}{8},\\,\\frac{1}{4}\\right).\n$$\nThe second derivative is\n$$\n\\frac{d^{2}f}{dt^{2}}=\\frac{p_{1}+p_{2}}{t^{2}}+\\frac{4p_{3}}{(1-2t)^{2}}>0,\n$$\nso this critical point is the unique minimizer, as required for the e-projection.\n\nNext, compute the divergences $A=D_{KL}(P\\|R)$, $B=D_{KL}(P\\|P^{*})$, and $C=D_{KL}(P^{*}\\|R)$.\n\nFor $A$:\n$$\nA=\\sum_{i=1}^{3}p_{i}\\ln\\!\\left(\\frac{p_{i}}{r_{i}}\\right)\n=\\sum_{i=1}^{3}p_{i}\\ln(3p_{i})\n=\\frac{1}{2}\\ln\\!\\left(\\frac{3}{2}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{3}{4}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{3}{4}\\right)\n=\\frac{1}{2}\\ln\\!\\left(\\frac{9}{8}\\right).\n$$\n\nFor $B$:\n$$\nB=\\sum_{i=1}^{3}p_{i}\\ln\\!\\left(\\frac{p_{i}}{q_{i}^{*}}\\right)\n=\\frac{1}{2}\\ln\\!\\left(\\frac{\\frac{1}{2}}{\\frac{3}{8}}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{\\frac{1}{4}}{\\frac{3}{8}}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{\\frac{1}{4}}{\\frac{1}{4}}\\right)\n=\\frac{1}{2}\\ln\\!\\left(\\frac{4}{3}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{2}{3}\\right)+0.\n$$\nUsing $\\ln\\!\\left(\\frac{4}{3}\\right)=-\\ln\\!\\left(\\frac{3}{4}\\right)$ and $\\ln\\!\\left(\\frac{2}{3}\\right)=-\\ln\\!\\left(\\frac{3}{2}\\right)$, we get\n$$\nB=-\\frac{1}{2}\\ln\\!\\left(\\frac{3}{4}\\right)-\\frac{1}{4}\\ln\\!\\left(\\frac{3}{2}\\right).\n$$\n\nFor $C$:\n$$\nC=\\sum_{i=1}^{3}q_{i}^{*}\\ln\\!\\left(\\frac{q_{i}^{*}}{r_{i}}\\right)\n=\\sum_{i=1}^{3}q_{i}^{*}\\ln(3q_{i}^{*})\n=\\frac{3}{8}\\ln\\!\\left(\\frac{9}{8}\\right)+\\frac{3}{8}\\ln\\!\\left(\\frac{9}{8}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{3}{4}\\right)\n=\\frac{3}{4}\\ln\\!\\left(\\frac{9}{8}\\right)+\\frac{1}{4}\\ln\\!\\left(\\frac{3}{4}\\right).\n$$\nSince $\\ln\\!\\left(\\frac{9}{8}\\right)=\\ln\\!\\left(\\frac{3}{2}\\right)+\\ln\\!\\left(\\frac{3}{4}\\right)$, we can write\n$$\nC=\\frac{3}{4}\\ln\\!\\left(\\frac{3}{2}\\right)+\\ln\\!\\left(\\frac{3}{4}\\right).\n$$\n\nNow sum $B$ and $C$:\n$$\nB+C=\\left[-\\frac{1}{2}\\ln\\!\\left(\\frac{3}{4}\\right)-\\frac{1}{4}\\ln\\!\\left(\\frac{3}{2}\\right)\\right]+\\left[\\frac{3}{4}\\ln\\!\\left(\\frac{3}{2}\\right)+\\ln\\!\\left(\\frac{3}{4}\\right)\\right]\n=\\frac{1}{2}\\ln\\!\\left(\\frac{3}{2}\\right)+\\frac{1}{2}\\ln\\!\\left(\\frac{3}{4}\\right)\n=\\frac{1}{2}\\ln\\!\\left(\\frac{9}{8}\\right).\n$$\nTherefore $A=B+C$, and the requested ratio is\n$$\n\\frac{A}{B+C}=1.\n$$\nThis verifies the information-geometric Pythagorean theorem for the given distributions and submanifold.", "answer": "$$\\boxed{1}$$", "id": "1631519"}, {"introduction": "Having explored the metric and a static geometric theorem, we now turn to dynamics: how do we define a 'straight line' path on a statistical manifold? These paths, known as geodesics, represent the most efficient way to transform one distribution into another. In this final practice [@problem_id:1631496], you will trace a geodesic path starting from a fair die, using an elegant mapping to a hypersphere to make the calculation tractable. This exercise beautifully illustrates how abstract geometric concepts can model tangible changes in a statistical system.", "problem": "Consider a standard six-sided die. The statistical state of the die is described by a probability distribution vector $P = (p_1, p_2, p_3, p_4, p_5, p_6)$, where $p_i$ is the probability of rolling the face with $i$ spots. The probabilities must satisfy $p_i \\ge 0$ for all $i$ and $\\sum_{i=1}^{6} p_i = 1$. The set of all such distributions forms a 5-dimensional statistical manifold.\n\nThis manifold is endowed with the Fisher information metric, which provides a natural way to measure the \"distance\" between different probability distributions. A fundamental property of this particular statistical manifold is its connection to spherical geometry. Through the coordinate transformation $\\xi_i = 2\\sqrt{p_i}$, the manifold of probability distributions is mapped isometrically onto the positive orthant of a 5-sphere of radius $R=2$ embedded in a 6-dimensional Euclidean space ($\\mathbb{R}^6$). All points on this sphere satisfy the equation $\\sum_{i=1}^{6} \\xi_i^2 = 4$. Under this mapping, the geodesics of the statistical manifold (which represent the \"straightest possible paths\") correspond to great circles on this hypersphere.\n\nSuppose the die is initially fair, meaning $p_i(0) = 1/6$ for all $i \\in \\{1, 2, 3, 4, 5, 6\\}$. The die is then \"loaded\" in a very specific manner. Its probability distribution begins to change, following a geodesic path on the statistical manifold. The initial direction of this change is such that the probability of rolling a '6' increases, while the probabilities of rolling any of the other five faces ('1' through '5') decrease symmetrically (i.e., at the same rate).\n\nDetermine the probability of rolling a '6', denoted as $p_6(s)$, as a function of the Fisher-information arc length $s$ traveled along this geodesic path from the fair initial state.", "solution": "We use the isometric embedding $\\xi_{i}=2\\sqrt{p_{i}}$ of the Fisher metric manifold into the 5-sphere of radius $R=2$ in $\\mathbb{R}^{6}$, where all points satisfy $\\sum_{i=1}^{6}\\xi_{i}^{2}=4$. Under this mapping, Fisher-information arc length equals Euclidean arc length along great circles on the sphere.\n\nAt the fair distribution, $p_{i}(0)=\\frac{1}{6}$ for all $i$, so\n$$\n\\xi_{i}(0)=\\frac{2}{\\sqrt{6}} \\quad \\text{for all } i,\n$$\nand the position vector is\n$$\n\\Xi_{0}=\\left(\\frac{2}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},\\frac{2}{\\sqrt{6}}\\right).\n$$\nThe geodesic departs in a direction that increases $p_{6}$ and decreases $p_{1},\\dots,p_{5}$ symmetrically. In $\\xi$-coordinates, take the initial tangent vector $v$ at $s=0$ with components\n$$\nv_{1}=v_{2}=v_{3}=v_{4}=v_{5}=a,\\quad v_{6}=b,\n$$\nsubject to the tangent-space condition $v\\cdot \\Xi_{0}=0$ (orthogonality to the radius) and unit speed $\\|v\\|=1$ (since $s$ is arc length). Orthogonality gives\n$$\n\\Xi_{0}\\cdot v=\\sum_{i=1}^{6}\\xi_{i}(0)\\,v_{i}=\\frac{2}{\\sqrt{6}}\\,(5a+b)=0\n\\;\\;\\Longrightarrow\\;\\; b=-5a.\n$$\nUnit speed requires\n$$\n\\|v\\|^{2}=5a^{2}+b^{2}=5a^{2}+25a^{2}=30a^{2}=1\n\\;\\;\\Longrightarrow\\;\\; a=-\\frac{1}{\\sqrt{30}},\\quad b=\\frac{5}{\\sqrt{30}},\n$$\nchoosing $a<0$ so that $v_{6}=b>0$ and hence $p_{6}$ initially increases.\n\nA unit-speed great circle on a sphere of radius $R=2$ parameterized by arc length $s$ is\n$$\n\\xi(s)=\\Xi_{0}\\cos\\!\\left(\\frac{s}{2}\\right)+2\\,v\\,\\sin\\!\\left(\\frac{s}{2}\\right).\n$$\nThus the sixth coordinate evolves as\n$$\n\\xi_{6}(s)=\\frac{2}{\\sqrt{6}}\\cos\\!\\left(\\frac{s}{2}\\right)+2\\cdot\\frac{5}{\\sqrt{30}}\\sin\\!\\left(\\frac{s}{2}\\right)\n=\\frac{\\sqrt{6}}{3}\\cos\\!\\left(\\frac{s}{2}\\right)+\\frac{\\sqrt{30}}{3}\\sin\\!\\left(\\frac{s}{2}\\right).\n$$\nMapping back to probabilities using $p_{6}(s)=\\xi_{6}(s)^{2}/4$ yields\n$$\np_{6}(s)=\\frac{1}{36}\\left(\\sqrt{6}\\cos\\!\\left(\\frac{s}{2}\\right)+\\sqrt{30}\\sin\\!\\left(\\frac{s}{2}\\right)\\right)^{2}.\n$$\nAs a check, at $s=0$ we recover $p_{6}(0)=\\frac{1}{36}\\left(\\sqrt{6}\\right)^{2}=\\frac{1}{6}$, and the initial derivative is positive, consistent with the specified loading direction.", "answer": "$$\\boxed{\\frac{1}{36}\\left(\\sqrt{6}\\cos\\left(\\frac{s}{2}\\right)+\\sqrt{30}\\sin\\left(\\frac{s}{2}\\right)\\right)^{2}}$$", "id": "1631496"}]}