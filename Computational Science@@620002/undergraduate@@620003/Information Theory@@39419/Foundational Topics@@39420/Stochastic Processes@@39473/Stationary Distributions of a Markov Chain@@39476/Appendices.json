{"hands_on_practices": [{"introduction": "Our first practice problem grounds us in the fundamental definition of a stationary distribution. We'll explore a simple two-state Markov chain, a common model for systems that switch between two conditions. By directly applying the core equation $\\pi = \\pi P$, you will practice the essential algebraic skills needed to find the long-term equilibrium of any Markov chain, providing a solid foundation for all subsequent problems [@problem_id:1660504].", "problem": "An algorithmic trading model classifies a stock's daily behavior into one of two states: State 1 (Uptrend) or State 2 (Downtrend). The model's prediction for the next day's state depends only on the current day's state. If the stock is in an Uptrend today, the probability it transitions to a Downtrend tomorrow is $\\alpha$. If the stock is in a Downtrend today, the probability it transitions to an Uptrend tomorrow is $3\\alpha$. The parameter $\\alpha$ is determined by market conditions and is constrained such that $0 < \\alpha < 1/3$.\n\nAfter the system has been running for a very long time, it is expected to settle into a steady state. Determine the vector $\\pi = [\\pi_1, \\pi_2]$ representing the long-term proportion of days the stock spends in the Uptrend state ($\\pi_1$) and the Downtrend state ($\\pi_2$), respectively. Express your answer as a function of $\\alpha$.", "solution": "Let the two states be indexed by $1$ (Uptrend) and $2$ (Downtrend). The one-step transition matrix $P$ with rows as current state and columns as next state is\n$$\nP=\\begin{pmatrix}\n1-\\alpha & \\alpha \\\\\n3\\alpha & 1-3\\alpha\n\\end{pmatrix},\n$$\nsince from state $1$ the chain stays in $1$ with probability $1-\\alpha$ and goes to $2$ with probability $\\alpha$, while from state $2$ it goes to $1$ with probability $3\\alpha$ and stays in $2$ with probability $1-3\\alpha$. The constraint $0<\\alpha<\\frac{1}{3}$ ensures $P$ is stochastic with strictly positive diagonal entries, so the chain is irreducible and aperiodic and has a unique stationary distribution.\n\nLet $\\pi=[\\pi_{1},\\pi_{2}]$ denote the stationary distribution. By definition, it satisfies $\\pi=\\pi P$ and the normalization $\\pi_{1}+\\pi_{2}=1$. Writing the balance equations from $\\pi=\\pi P$ gives\n$$\n\\pi_{1}=\\pi_{1}(1-\\alpha)+\\pi_{2}(3\\alpha), \\quad \\pi_{2}=\\pi_{1}\\alpha+\\pi_{2}(1-3\\alpha).\n$$\nFrom the first equation,\n$$\n\\pi_{1}-\\pi_{1}(1-\\alpha)=3\\alpha\\,\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\alpha\\,\\pi_{1}=3\\alpha\\,\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\pi_{1}=3\\pi_{2},\n$$\nwhere we used $\\alpha>0$ to divide both sides by $\\alpha$. Using the normalization $\\pi_{1}+\\pi_{2}=1$,\n$$\n3\\pi_{2}+\\pi_{2}=1 \\;\\;\\Longrightarrow\\;\\; 4\\pi_{2}=1 \\;\\;\\Longrightarrow\\;\\; \\pi_{2}=\\frac{1}{4}, \\quad \\pi_{1}=\\frac{3}{4}.\n$$\nThus the long-run proportion of days in each state is independent of $\\alpha$ (within the given range) and equals $[\\frac{3}{4},\\frac{1}{4}]$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{4} & \\frac{1}{4} \\end{pmatrix}}$$", "id": "1660504"}, {"introduction": "Building upon the basics, this exercise introduces the concept of symmetry in Markov chains, modeled as a random walk on a simple graph. Instead of immediately resorting to solving a full system of linear equations, this problem encourages you to leverage the system's structural regularities. This approach not only simplifies the calculation but also builds intuition for why symmetric systems often converge to a uniform stationary distribution [@problem_id:1660523].", "problem": "A small, isolated computer network consists of four server nodes, labeled A, B, C, and D, arranged in a square formation. Node A is connected to its adjacent neighbors, nodes B and D. Node C, diagonally opposite to A, is also connected to nodes B and D. The connections thus form a closed loop A-B-C-D-A.\n\nA single diagnostic data packet is continuously routed through this network. At each time step, the packet moves from its current node to one of its two connected neighbors with equal probability. For example, if the packet is at node A, it will move to either node B or node D in the next time step, each with a probability of $1/2$.\n\nAfter the packet has been moving for a very long time, the long-term average proportion of time it spends at any given node converges to a fixed value. This value can be interpreted as the probability of finding the packet at that node if one were to check at a random time in the distant future.\n\nCalculate this limiting probability of finding the packet at node A. Express your answer as an exact fraction.", "solution": "Model the packet motion as a Markov chain on the four nodes with transition probability from each node to each of its two neighbors equal to $\\frac{1}{2}$. Let the stationary distribution be $\\pi=(\\pi_{A},\\pi_{B},\\pi_{C},\\pi_{D})$, which satisfies $\\pi=\\pi P$ and $\\pi_{A}+\\pi_{B}+\\pi_{C}+\\pi_{D}=1$. Using $\\pi=\\pi P$ in component form gives\n$$\n\\pi_{A}=\\frac{1}{2}\\pi_{B}+\\frac{1}{2}\\pi_{D},\\quad\n\\pi_{B}=\\frac{1}{2}\\pi_{A}+\\frac{1}{2}\\pi_{C},\\quad\n\\pi_{C}=\\frac{1}{2}\\pi_{B}+\\frac{1}{2}\\pi_{D},\\quad\n\\pi_{D}=\\frac{1}{2}\\pi_{A}+\\frac{1}{2}\\pi_{C}.\n$$\nSubtracting the first and third equations yields\n$$\n\\pi_{A}-\\pi_{C}=\\frac{1}{2}(\\pi_{B}-\\pi_{B})+\\frac{1}{2}(\\pi_{D}-\\pi_{D})=0 \\quad \\Rightarrow \\quad \\pi_{A}=\\pi_{C}.\n$$\nSubtracting the second and fourth equations yields\n$$\n\\pi_{B}-\\pi_{D}=\\frac{1}{2}(\\pi_{A}-\\pi_{A})+\\frac{1}{2}(\\pi_{C}-\\pi_{C})=0 \\quad \\Rightarrow \\quad \\pi_{B}=\\pi_{D}.\n$$\nSubstituting $\\pi_{C}=\\pi_{A}$ and $\\pi_{D}=\\pi_{B}$ into $\\pi_{A}=\\frac{1}{2}\\pi_{B}+\\frac{1}{2}\\pi_{D}$ gives\n$$\n\\pi_{A}=\\frac{1}{2}\\pi_{B}+\\frac{1}{2}\\pi_{B}=\\pi_{B},\n$$\nso $\\pi_{A}=\\pi_{B}=\\pi_{C}=\\pi_{D}$. Using the normalization condition,\n$$\n\\pi_{A}+\\pi_{B}+\\pi_{C}+\\pi_{D}=4\\pi_{A}=1 \\quad \\Rightarrow \\quad \\pi_{A}=\\frac{1}{4}.\n$$\nTherefore, the long-term probability of finding the packet at node A is $\\frac{1}{4}$.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "1660523"}, {"introduction": "This final practice challenges you to analyze a more complex, multi-state system that appears computationally intensive at first glance. The key to solving this biased random walk on a cube lies in a powerful technique known as state aggregation, where we group states with similar properties. This problem demonstrates how to simplify a large state space by identifying underlying symmetries, a crucial skill for tackling real-world problems where state spaces can be enormous [@problem_id:1660536].", "problem": "A particle performs a discrete-time random walk on the eight vertices of a unit cube. The vertices are identified by their coordinates $(x,y,z)$ where each of $x, y, z$ can be either 0 or 1. At each step, the particle, currently at a vertex $v$, moves to one of its three adjacent neighbors.\n\nThe choice of which neighbor to move to is probabilistic and is biased based on the z-coordinate of the potential destination. Specifically, the probability of moving from the current vertex $v$ to a specific neighbor $u$ is proportional to a weight $w(u)$ assigned to the destination vertex $u$. This weight is defined as follows:\n- $w(u) = 1$ if the z-coordinate of vertex $u$ is 0.\n- $w(u) = 2$ if the z-coordinate of vertex $u$ is 1.\n\nFor example, if a particle at vertex $v$ has three neighbors $u_1, u_2, u_3$, the probability of transitioning to neighbor $u_1$ in the next step is given by the expression $\\frac{w(u_1)}{w(u_1) + w(u_2) + w(u_3)}$.\n\nAfter a very long time, the particle's location will be described by a stationary probability distribution over the eight vertices. Calculate the stationary probability of the particle being at the vertex $(1,1,1)$. Express your answer as a rational number in simplest form.", "solution": "Label the eight vertices by their coordinates $(x,y,z)$ with $x,y,z \\in \\{0,1\\}$. From any vertex, the three neighbors are obtained by flipping exactly one coordinate. The transition probability from the current vertex $v$ to a neighbor $u$ is proportional to the weight $w(u)$, where $w(u)=1$ if the $z$-coordinate of $u$ is $0$ and $w(u)=2$ if it is $1$.\n\nFrom a vertex with $z=0$:\n- Two neighbors keep $z=0$ (flip $x$ or $y$), each with weight $1$.\n- One neighbor has $z=1$ (flip $z$), with weight $2$.\nHence the transition probabilities are $1/4$, $1/4$, and $1/2$, so the probability to move to layer $z=1$ is $\\frac{1}{2}$ and to stay in $z=0$ is $\\frac{1}{2}$.\n\nFrom a vertex with $z=1$:\n- Two neighbors keep $z=1$ (flip $x$ or $y$), each with weight $2$.\n- One neighbor has $z=0$ (flip $z$), with weight $1$.\nHence the transition probabilities are $2/5$, $2/5$, and $1/5$, so the probability to move to layer $z=0$ is $\\frac{1}{5}$ and to stay in $z=1$ is $\\frac{4}{5}$.\n\nBy symmetry in $x$ and $y$, all vertices within the same $z$-layer have equal stationary probability. Let $q_{0}$ and $q_{1}$ be the stationary probabilities of being in layers $z=0$ and $z=1$, respectively. The induced two-state Markov chain has transition matrix\n$$\n\\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{2} \\\\\n\\frac{1}{5} & \\frac{4}{5}\n\\end{pmatrix},\n$$\nso stationarity gives\n$$\nq_{0} = \\frac{1}{2}q_{0} + \\frac{1}{5}q_{1}, \\quad q_{1} = \\frac{1}{2}q_{0} + \\frac{4}{5}q_{1}, \\quad q_{0}+q_{1}=1.\n$$\nFrom the first equation,\n$$\nq_{0} - \\frac{1}{2}q_{0} = \\frac{1}{5}q_{1} \\quad \\Rightarrow \\quad \\frac{1}{2}q_{0} = \\frac{1}{5}q_{1} \\quad \\Rightarrow \\quad q_{0} = \\frac{2}{5}q_{1}.\n$$\nUsing $q_{0}+q_{1}=1$,\n$$\n\\frac{2}{5}q_{1} + q_{1} = 1 \\quad \\Rightarrow \\quad \\frac{7}{5}q_{1} = 1 \\quad \\Rightarrow \\quad q_{1} = \\frac{5}{7}, \\quad q_{0} = \\frac{2}{7}.\n$$\nThere are $4$ vertices in each layer, and by symmetry the stationary probability per vertex in layer $z=1$ is $q_{1}/4$, so the stationary probability of $(1,1,1)$ is\n$$\n\\frac{q_{1}}{4} = \\frac{1}{4}\\cdot \\frac{5}{7} = \\frac{5}{28}.\n$$\nEquivalently, detailed balance across a $z$-edge requires $\\pi_{0}\\cdot \\frac{1}{2} = \\pi_{1}\\cdot \\frac{1}{5}$, so $\\pi_{1}/\\pi_{0} = \\frac{5}{2}$; normalizing $4\\pi_{0}+4\\pi_{1}=1$ gives $\\pi_{1}=\\frac{5}{28}$ for any $z=1$ vertex, consistent with the above.", "answer": "$$\\boxed{\\frac{5}{28}}$$", "id": "1660536"}]}