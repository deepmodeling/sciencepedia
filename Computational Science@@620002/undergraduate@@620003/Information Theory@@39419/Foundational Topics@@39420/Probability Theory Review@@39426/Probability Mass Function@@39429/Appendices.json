{"hands_on_practices": [{"introduction": "A cornerstone skill in probability theory is understanding the relationship between the Cumulative Distribution Function (CDF) and the Probability Mass Function (PMF). While the CDF, $F(x)$, provides the probability that a random variable $X$ takes a value less than or equal to $x$, the PMF, $p(x)$, gives the probability for a single specific outcome. This exercise provides direct practice in deriving the PMF from a given CDF, a fundamental procedure for analyzing discrete random variables. [@problem_id:1947403]", "problem": "A discrete random variable $X$ has a set of possible integer outcomes, also known as its support, given by $S_X = \\{0, 1, 2, 3, 4\\}$. The cumulative distribution function (CDF) of $X$, denoted by $F(x) = P(X \\le x)$, is defined by the formula:\n$$F(x) = \\frac{(x+1)^2}{25}$$\nfor all $x \\in S_X$. Furthermore, for any real number $y < 0$, $F(y) = 0$.\n\nDetermine the probability mass function (PMF) of $X$, denoted by $p(x) = P(X = x)$. Express your answer as a single algebraic formula in terms of $x$, valid for all $x \\in S_X$.", "solution": "For a discrete random variable supported on integers, the probability mass function is obtained from the cumulative distribution function via\n$$p(x)=P(X=x)=P(X\\leq x)-P(X\\leq x-1)=F(x)-F(x-1).$$\nGiven $F(x)=\\frac{(x+1)^{2}}{25}$ for $x\\in S_{X}=\\{0,1,2,3,4\\}$ and $F(y)=0$ for $y<0$, we compute for $x\\in\\{1,2,3,4\\}$:\n$$p(x)=\\frac{(x+1)^{2}}{25}-\\frac{x^{2}}{25}=\\frac{(x^{2}+2x+1)-x^{2}}{25}=\\frac{2x+1}{25}.$$\nFor $x=0$, using $F(-1)=0$,\n$$p(0)=F(0)-F(-1)=\\frac{(0+1)^{2}}{25}-0=\\frac{1}{25}=\\frac{2\\cdot 0+1}{25}.$$\nTherefore a single formula valid for all $x\\in S_{X}$ is\n$$p(x)=\\frac{2x+1}{25}.$$\nAs a check,\n$$\\sum_{x=0}^{4}p(x)=\\frac{1}{25}\\sum_{x=0}^{4}(2x+1)=\\frac{1}{25}\\left(2\\sum_{x=0}^{4}x+5\\right)=\\frac{1}{25}(2\\cdot 10+5)=1,$$\nso the result is a valid PMF.", "answer": "$$\\boxed{\\frac{2x+1}{25}}$$", "id": "1947403"}, {"introduction": "Real-world phenomena are often governed by processes that are a mix of simpler ones. This practice explores such a scenario, where the outcome depends on a randomly determined initial 'mode'. Here, you will construct the PMF for a particle's final position by first determining the conditional PMFs for each mode and then combining them using the law of total probability. This approach is essential for modeling complex systems with underlying uncertainties and introduces the concept of a mixture distribution. [@problem_id:1947340]", "problem": "A factory produces miniaturized particle accelerators for physics experiments. Due to a manufacturing inconsistency, each accelerator operates in one of two modes, determined randomly when it is first switched on. It operates in 'Standard Mode' with a probability of $1/3$, or in 'Biased Mode' with a probability of $2/3$. The mode is fixed for the lifetime of the device.\n\nIn any given experiment, a particle starts at the origin (position 0) on a one-dimensional track and undergoes a sequence of three independent steps.\n- If the accelerator is in 'Standard Mode', each step is either a displacement of $+1$ unit or $-1$ unit, with equal probability.\n- If the accelerator is in 'Biased Mode', each step is a displacement of $+1$ unit with probability $3/4$, or $-1$ unit with probability $1/4$.\n\nAn experimenter uses one of these accelerators without knowing its mode. Let $X$ be the random variable representing the final position of the particle after the three steps. Which of the following options correctly describes the Probability Mass Function (PMF) of $X$, denoted by $p(k) = P(X=k)$?\n\nA. $p(-3)=5/96, p(-1)=21/96, p(1)=39/96, p(3)=31/96$\n\nB. $p(-3)=17/192, p(-1)=57/192, p(1)=75/192, p(3)=43/192$\n\nC. $p(-3)=9/128, p(-1)=33/128, p(1)=51/128, p(3)=35/128$\n\nD. $p(-3)=1/64, p(-1)=9/64, p(1)=27/64, p(3)=27/64$\n\nE. $p(-3)=1/8, p(-1)=3/8, p(1)=3/8, p(3)=1/8$", "solution": "Let $M \\in \\{\\text{S},\\text{B}\\}$ denote the mode, with $P(M=\\text{S})=\\frac{1}{3}$ and $P(M=\\text{B})=\\frac{2}{3}$. Conditional on $M$, the three steps are independent and identically distributed. If $p_{M}=P(\\text{step}=+1 \\mid M)$, then $p_{\\text{S}}=\\frac{1}{2}$ and $p_{\\text{B}}=\\frac{3}{4}$.\n\nLet $Y$ be the number of $+1$ steps in the three steps. Given $M$, $Y \\sim \\text{Bin}(3,p_{M})$, so\n$$\nP(Y=y \\mid M)=\\binom{3}{y} p_{M}^{y} (1-p_{M})^{3-y}, \\quad y=0,1,2,3.\n$$\nThe final position is $X=(\\#\\,+1)-(\\#\\,-1)=Y-(3-Y)=2Y-3$, so the possible values are $X \\in \\{-3,-1,1,3\\}$ corresponding to $Y=0,1,2,3$ respectively. Thus, conditional on $M$,\n$$\n\\begin{aligned}\nP(X=-3 \\mid M)&=(1-p_{M})^{3},\\\\\nP(X=-1 \\mid M)&=\\binom{3}{1} p_{M} (1-p_{M})^{2},\\\\\nP(X=1 \\mid M)&=\\binom{3}{2} p_{M}^{2} (1-p_{M}),\\\\\nP(X=3 \\mid M)&=p_{M}^{3}.\n\\end{aligned}\n$$\n\nCompute these for each mode:\n- For $M=\\text{S}$ with $p_{\\text{S}}=\\frac{1}{2}$,\n$$\nP(X=-3 \\mid \\text{S})=\\frac{1}{8},\\quad P(X=-1 \\mid \\text{S})=\\frac{3}{8},\\quad P(X=1 \\mid \\text{S})=\\frac{3}{8},\\quad P(X=3 \\mid \\text{S})=\\frac{1}{8}.\n$$\n- For $M=\\text{B}$ with $p_{\\text{B}}=\\frac{3}{4}$,\n$$\nP(X=-3 \\mid \\text{B})=\\frac{1}{64},\\quad P(X=-1 \\mid \\text{B})=\\frac{9}{64},\\quad P(X=1 \\mid \\text{B})=\\frac{27}{64},\\quad P(X=3 \\mid \\text{B})=\\frac{27}{64}.\n$$\n\nBy the law of total probability,\n$$\nP(X=k)=P(M=\\text{S})P(X=k \\mid \\text{S})+P(M=\\text{B})P(X=k \\mid \\text{B}).\n$$\nThus,\n$$\n\\begin{aligned}\nP(X=-3)&=\\frac{1}{3}\\cdot \\frac{1}{8}+\\frac{2}{3}\\cdot \\frac{1}{64}=\\frac{5}{96},\\\\\nP(X=-1)&=\\frac{1}{3}\\cdot \\frac{3}{8}+\\frac{2}{3}\\cdot \\frac{9}{64}=\\frac{21}{96},\\\\\nP(X=1)&=\\frac{1}{3}\\cdot \\frac{3}{8}+\\frac{2}{3}\\cdot \\frac{27}{64}=\\frac{39}{96},\\\\\nP(X=3)&=\\frac{1}{3}\\cdot \\frac{1}{8}+\\frac{2}{3}\\cdot \\frac{27}{64}=\\frac{31}{96}.\n\\end{aligned}\n$$\nThese match option A.", "answer": "$$\\boxed{A}$$", "id": "1947340"}, {"introduction": "This final practice delves into the fascinating intersection of probability and combinatorics by examining the structure of random permutations. By conceptualizing a permutation as a set of disjoint cycles, we can ask probabilistic questions about its properties, a line of inquiry relevant to fields like network theory and cryptography. This exercise challenges you to derive the PMF for the length of a cycle containing a specific element, a result which is both elegant and surprisingly simple, showcasing the power of combinatorial probability. [@problem_id:1648269]", "problem": "A set of $n$ servers, labeled $\\{1, 2, \\dots, n\\}$, are part of a distributed network. Due to a network reconfiguration event, a new communication topology is established, represented by a permutation $\\pi$ of the servers. This permutation is chosen uniformly at random from the set of all $n!$ possible permutations. The new topology dictates that server $i$ can only send messages directly to server $\\pi(i)$ for any $i \\in \\{1, 2, \\dots, n\\}$. This process creates a set of disjoint communication cycles among the servers.\n\nLet the random variable $L$ be the length of the specific communication cycle that includes server '1'. For a fixed integer $k$, where $1 \\le k \\le n$, determine the probability $P(L=k)$. Express your final answer as a symbolic expression in terms of $n$.", "solution": "The problem asks for the probability that server '1' is part of a communication cycle of length $k$. A permutation is chosen uniformly at random from the set $S_n$ of all permutations of $\\{1, 2, \\dots, n\\}$. The total number of possible permutations is $n!$. The probability of any specific permutation being chosen is $1/n!$.\n\nTo find the desired probability, $P(L=k)$, we need to count the number of permutations in which the cycle containing '1' has length exactly $k$, and then divide this count by the total number of permutations, $n!$.\n\nLet's construct such a permutation by counting the number of ways to form a cycle of length $k$ containing server '1' and then arranging the remaining servers.\n\nFirst, we must choose the other $k-1$ servers that will be in the cycle with server '1'. These $k-1$ servers must be chosen from the remaining $n-1$ servers (i.e., servers $\\{2, 3, \\dots, n\\}$). The number of ways to choose these $k-1$ servers is given by the binomial coefficient $\\binom{n-1}{k-1}$.\n\nNext, we need to arrange the $k$ chosen servers (server '1' plus the $k-1$ others) into a single cycle of length $k$. The number of ways to arrange $k$ distinct elements in a cycle is $(k-1)!$. This is because if we were to arrange them in a line, there would be $k!$ arrangements. However, in a cycle, arrangements are considered identical if they can be obtained by rotation. Since there are $k$ possible starting points for a cycle of length $k$, we divide $k!$ by $k$ to get $(k-1)!$ distinct cycles.\n\nSo, the number of ways to choose the members of the cycle containing '1' and to form the cycle is the product of these two counts:\n$$ \\text{Number of ways to form the k-cycle containing '1'} = \\binom{n-1}{k-1} \\times (k-1)! $$\nLet's simplify this expression:\n$$ \\binom{n-1}{k-1} (k-1)! = \\frac{(n-1)!}{(k-1)!(n-1-(k-1))!} \\times (k-1)! = \\frac{(n-1)!}{(n-k)!} $$\n\nAfter forming this cycle of length $k$, we have $n-k$ servers remaining. These remaining servers must be permuted among themselves. The sub-permutation involving these $n-k$ servers can be any permutation of those servers. The number of ways to arrange the remaining $n-k$ servers is $(n-k)!$.\n\nUsing the multiplication principle, the total number of permutations where server '1' is in a cycle of length $k$ is the product of the number of ways to form the cycle containing '1' and the number of ways to permute the remaining servers:\n$$ \\text{Number of favorable permutations} = \\left( \\frac{(n-1)!}{(n-k)!} \\right) \\times (n-k)! = (n-1)! $$\nThis result is surprisingly simple: the number of permutations where server '1' is in a cycle of length $k$ is $(n-1)!$, regardless of the specific value of $k$ (for $1 \\le k \\le n$).\n\nFinally, to find the probability $P(L=k)$, we divide the number of favorable permutations by the total number of permutations:\n$$ P(L=k) = \\frac{\\text{Number of favorable permutations}}{\\text{Total number of permutations}} = \\frac{(n-1)!}{n!} $$\nSimplifying the expression for the probability, we get:\n$$ P(L=k) = \\frac{(n-1)!}{n \\times (n-1)!} = \\frac{1}{n} $$\nThus, the probability that server '1' belongs to a cycle of length $k$ is $1/n$ for any $k$ from $1$ to $n$. The result is independent of $k$.", "answer": "$$\\boxed{\\frac{1}{n}}$$", "id": "1648269"}]}