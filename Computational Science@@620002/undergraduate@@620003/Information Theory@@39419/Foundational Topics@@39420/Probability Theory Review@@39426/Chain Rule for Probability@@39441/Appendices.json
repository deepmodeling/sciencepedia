{"hands_on_practices": [{"introduction": "The chain rule of probability is the essential tool for analyzing sequences of events. This first practice problem provides a clear and intuitive scenario of a first-order Markov process, where the outcome of an event depends only on the outcome of the one immediately preceding it. By calculating the probability of a specific sequence of successes and failures in an adaptive learning system, you will gain hands-on experience applying the chain rule to systems with memory [@problem_id:1609151].", "problem": "An adaptive learning system presents a student with a sequence of three mathematical problems. The system's algorithm adjusts the difficulty of each problem based on the student's performance on the preceding one. Let $S_k$ denote the event that the student successfully solves problem $k$ and $F_k$ denote the event that the student fails to solve problem $k$.\n\nThe system operates based on the following probabilistic rules:\n1.  For the first problem, the probability of a successful solution is $P(S_1) = 0.65$.\n2.  For any subsequent problem $k > 1$, the probability of success is conditional upon the outcome of problem $k-1$.\n    -   If the student solved problem $k-1$, the system presents a more difficult problem, and the probability of solving problem $k$ is $P(S_k | S_{k-1}) = 0.40$.\n    -   If the student failed problem $k-1$, the system presents an easier problem, and the probability of solving problem $k$ is $P(S_k | F_{k-1}) = 0.85$.\n3.  The outcome of any problem $k$ is conditionally independent of all outcomes prior to problem $k-1$, given the outcome of problem $k-1$.\n\nCalculate the probability that the student's sequence of outcomes for the three problems is solve, fail, and then solve. Give your final answer as a decimal rounded to three significant figures.", "solution": "We seek the probability of the sequence $S_{1}, F_{2}, S_{3}$. By the chain rule of probability,\n$$\nP(S_{1} \\cap F_{2} \\cap S_{3}) = P(S_{1}) \\, P(F_{2} \\mid S_{1}) \\, P(S_{3} \\mid F_{2}, S_{1}).\n$$\nBy the conditional independence rule (Markov property) specified, the outcome of problem $3$ depends only on problem $2$, so\n$$\nP(S_{3} \\mid F_{2}, S_{1}) = P(S_{3} \\mid F_{2}).\n$$\nUsing the given transition probabilities,\n$$\nP(S_{1}) = 0.65, \\quad P(F_{2} \\mid S_{1}) = 1 - P(S_{2} \\mid S_{1}) = 1 - 0.40 = 0.60, \\quad P(S_{3} \\mid F_{2}) = 0.85.\n$$\nTherefore,\n$$\nP(S_{1} \\cap F_{2} \\cap S_{3}) = 0.65 \\times 0.60 \\times 0.85 = 0.3315.\n$$\nRounded to three significant figures, the probability is $0.332$.", "answer": "$$\\boxed{0.332}$$", "id": "1609151"}, {"introduction": "Building on the concept of sequential events, this problem elevates the challenge by applying the chain rule to a practical engineering scenario: error correction in digital communications. Here, you will not calculate the probability of a single outcome, but rather the total probability of a set of outcomes that meet a specific conditionâ€”in this case, being correctable by a single-error-correcting code. This exercise [@problem_id:1609163] demonstrates how the chain rule is a fundamental building block for evaluating the reliability and performance of real-world systems.", "problem": "A 4-bit data block is transmitted over a noisy digital channel. The channel exhibits a memory effect, where the likelihood of a bit error at a given position depends on whether an error occurred in the preceding position. Let $E_i$ be the event that an error occurs at bit position $i$, for $i \\in \\{1, 2, 3, 4\\}$.\n\nThe error characteristics are as follows:\n- The probability of an error in the first bit is $P(E_1) = p_1$.\n- For any subsequent bit $i > 1$, the conditional probability of an error, given an error occurred in the previous bit position $i-1$, is $P(E_i | E_{i-1}) = p_c$.\n- For any subsequent bit $i > 1$, the conditional probability of an error, given no error occurred in the previous bit position $i-1$, is $P(E_i | E_{i-1}^c) = p_u$, where $E_{i-1}^c$ is the complement of $E_{i-1}$.\n\nThe received block is then processed by a decoder for a single-error-correcting code. This decoder can successfully recover the original 4-bit block if and only if the received block contains at most one bit error.\n\nGiven the parameters $p_1 = 0.05$, $p_c = 0.4$, and $p_u = 0.02$, calculate the total probability that a transmitted 4-bit block is correctable by this decoder. Round your final answer to four significant figures.", "solution": "Let $E_{i}$ denote the event of an error at bit $i$ and $E_{i}^{c}$ its complement. The channel has a first-order memory, so the probability of a length-4 error/no-error sequence equals the product of the initial probability and the three transition probabilities conditioned on the immediately preceding outcome.\n\nDefine the complementary probabilities\n$$q_{1} = 1 - p_{1}, \\quad q_{c} = 1 - p_{c}, \\quad q_{u} = 1 - p_{u}.$$\n\nThe decoder succeeds if and only if there is at most one error in the block. We sum the probabilities of all sequences with zero errors and with exactly one error.\n\nZero errors (pattern $E_{1}^{c}E_{2}^{c}E_{3}^{c}E_{4}^{c}$):\n$$P_{0} = P(E_{1}^{c}) P(E_{2}^{c} \\mid E_{1}^{c}) P(E_{3}^{c} \\mid E_{2}^{c}) P(E_{4}^{c} \\mid E_{3}^{c}) = q_{1} \\, q_{u}^{3}.$$\n\nExactly one error at position 1 (pattern $E_{1}E_{2}^{c}E_{3}^{c}E_{4}^{c}$):\n$$P_{1} = P(E_{1}) P(E_{2}^{c} \\mid E_{1}) P(E_{3}^{c} \\mid E_{2}^{c}) P(E_{4}^{c} \\mid E_{3}^{c}) = p_{1} \\, q_{c} \\, q_{u}^{2}.$$\n\nExactly one error at position 2 (pattern $E_{1}^{c}E_{2}E_{3}^{c}E_{4}^{c}$):\n$$P_{2} = P(E_{1}^{c}) P(E_{2} \\mid E_{1}^{c}) P(E_{3}^{c} \\mid E_{2}) P(E_{4}^{c} \\mid E_{3}^{c}) = q_{1} \\, p_{u} \\, q_{c} \\, q_{u}.$$\n\nExactly one error at position 3 (pattern $E_{1}^{c}E_{2}^{c}E_{3}E_{4}^{c}$):\n$$P_{3} = P(E_{1}^{c}) P(E_{2}^{c} \\mid E_{1}^{c}) P(E_{3} \\mid E_{2}^{c}) P(E_{4}^{c} \\mid E_{3}) = q_{1} \\, q_{u} \\, p_{u} \\, q_{c}.$$\n\nExactly one error at position 4 (pattern $E_{1}^{c}E_{2}^{c}E_{3}^{c}E_{4}$):\n$$P_{4} = P(E_{1}^{c}) P(E_{2}^{c} \\mid E_{1}^{c}) P(E_{3}^{c} \\mid E_{2}^{c}) P(E_{4} \\mid E_{3}^{c}) = q_{1} \\, q_{u}^{2} \\, p_{u}.$$\n\nHence, the total correctable probability is\n$$P_{\\text{corr}} = P_{0} + P_{1} + P_{2} + P_{3} + P_{4} = q_{1} q_{u}^{3} + p_{1} q_{c} q_{u}^{2} + 2 q_{1} p_{u} q_{c} q_{u} + q_{1} q_{u}^{2} p_{u}.$$\nUsing $q_{u}^{3} + q_{u}^{2} p_{u} = q_{u}^{2} (q_{u} + p_{u}) = q_{u}^{2}$, this simplifies to\n$$P_{\\text{corr}} = q_{1} q_{u} \\left(q_{u} + 2 p_{u} q_{c}\\right) + p_{1} q_{c} q_{u}^{2}.$$\n\nSubstitute $p_{1} = 0.05$, $p_{c} = 0.4$, $p_{u} = 0.02$, so $q_{1} = 0.95$, $q_{c} = 0.6$, $q_{u} = 0.98$:\n$$q_{u}^{2} = 0.9604, \\quad 2 p_{u} q_{c} = 2 \\cdot 0.02 \\cdot 0.6 = 0.024,$$\n$$q_{u} + 2 p_{u} q_{c} = 0.98 + 0.024 = 1.004,$$\n$$q_{1} q_{u} \\left(q_{u} + 2 p_{u} q_{c}\\right) = 0.95 \\cdot 0.98 \\cdot 1.004 = 0.934724,$$\n$$p_{1} q_{c} q_{u}^{2} = 0.05 \\cdot 0.6 \\cdot 0.9604 = 0.028812.$$\nTherefore,\n$$P_{\\text{corr}} = 0.934724 + 0.028812 = 0.963536.$$\nRounding to four significant figures yields $0.9635$.", "answer": "$$\\boxed{0.9635}$$", "id": "1609163"}, {"introduction": "This advanced problem challenges you to generalize the chain rule from a simple one-dimensional sequence to a two-dimensional grid, a concept at the heart of models in statistical physics and image processing. You will determine the probability of a specific spatial configuration where each element's state is conditionally dependent on its previously determined neighbors. This exercise [@problem_id:1609176] will sharpen your ability to deconstruct a complex joint probability into a product of manageable conditional probabilities, a powerful skill for tackling problems with intricate dependency structures.", "problem": "Consider a simplified model for a novel type of memory array, consisting of a $3 \\times 3$ grid of interacting binary cells. The state of the cell at row $i$ and column $j$ is denoted by a random variable $X_{i,j} \\in \\{0, 1\\}$, where $i, j \\in \\{1, 2, 3\\}$.\n\nThe states of the cells are determined sequentially in a raster-scan order: $X_{1,1}, X_{1,2}, X_{1,3}, X_{2,1}, X_{2,2}, X_{2,3}, X_{3,1}, X_{3,2}, X_{3,3}$. The state of each cell is conditionally dependent on the states of its previously determined neighbors. Two cells $(i,j)$ and $(k,l)$ are considered neighbors if $|i-k| + |j-l| = 1$.\n\nThe probabilistic rule governing the state of cell $(i,j)$ is as follows. First, a local influence field, $h_{i,j}$, is calculated based on the states of its neighbors that have already been determined in the raster-scan sequence. This field is given by:\n$$h_{i,j} = \\sum_{(k,l) \\in N_{i,j}^{\\text{prev}}} (2X_{k,l} - 1)$$\nwhere $N_{i,j}^{\\text{prev}}$ is the set of previously determined neighbors of $(i,j)$. If a cell has no previously determined neighbors, its influence field is $h_{i,j}=0$.\n\nThe conditional probability of a cell having state 1 is then given by a logistic function of this field:\n$$P(X_{i,j}=1 | \\text{past states}) = \\frac{1}{1 + \\exp(-\\gamma h_{i,j})}$$\nwhere $\\gamma = \\ln(3)$ is a coupling constant.\n\nYour task is to calculate the probability of observing the following specific checkerboard configuration for the entire grid:\n$$\n\\begin{pmatrix}\nX_{1,1} & X_{1,2} & X_{1,3} \\\\\nX_{2,1} & X_{2,2} & X_{2,3} \\\\\nX_{3,1} & X_{3,2} & X_{3,3}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 1\n\\end{pmatrix}\n$$\nCalculate this total probability and provide your answer as a decimal rounded to four significant figures.", "solution": "We use the sequential specification of the joint probability via the chain rule consistent with the raster-scan order. For each cell, the local field is\n$$\nh_{i,j}=\\sum_{(k,l)\\in N_{i,j}^{\\text{prev}}} (2X_{k,l}-1),\n$$\nand the conditional probability is logistic:\n$$\nP(X_{i,j}=1 \\mid \\text{past})=\\frac{1}{1+\\exp(-\\gamma h_{i,j})},\\quad \\gamma=\\ln(3).\n$$\nThus\n$$\n\\exp(-\\gamma h)=\\exp(-\\ln(3)\\,h)=3^{-h},\n$$\nso\n$$\nP(X=1\\mid h)=\\frac{1}{1+3^{-h}},\\qquad P(X=0\\mid h)=1-P(X=1\\mid h)=\\frac{1}{1+3^{h}}.\n$$\nThe joint probability of the specified configuration equals the product of these conditional probabilities in raster order.\n\nWe compute each factor for the target configuration\n$$\n\\begin{pmatrix}\n1 & 0 & 1\\\\\n0 & 1 & 0\\\\\n1 & 0 & 1\n\\end{pmatrix}\n$$\nas follows, using only previously determined neighbors (left and/or above):\n\n1) $(1,1)$: $N_{1,1}^{\\text{prev}}=\\varnothing$, so $h_{1,1}=0$. With $X_{1,1}=1$,\n$$\nP=\\frac{1}{2}.\n$$\n\n2) $(1,2)$: $N_{1,2}^{\\text{prev}}=\\{(1,1)\\}$ with $X_{1,1}=1$, so $h_{1,2}=+1$. With $X_{1,2}=0$,\n$$\nP=\\frac{1}{1+3^{1}}=\\frac{1}{4}.\n$$\n\n3) $(1,3)$: $N_{1,3}^{\\text{prev}}=\\{(1,2)\\}$ with $X_{1,2}=0$, so $h_{1,3}=-1$. With $X_{1,3}=1$,\n$$\nP=\\frac{1}{1+3^{1}}=\\frac{1}{4}.\n$$\n\n4) $(2,1)$: $N_{2,1}^{\\text{prev}}=\\{(1,1)\\}$ with $X_{1,1}=1$, so $h_{2,1}=+1$. With $X_{2,1}=0$,\n$$\nP=\\frac{1}{4}.\n$$\n\n5) $(2,2)$: $N_{2,2}^{\\text{prev}}=\\{(2,1),(1,2)\\}$ with $X_{2,1}=0$ and $X_{1,2}=0$, so $h_{2,2}=-1-1=-2$. With $X_{2,2}=1$,\n$$\nP=\\frac{1}{1+3^{2}}=\\frac{1}{10}.\n$$\n\n6) $(2,3)$: $N_{2,3}^{\\text{prev}}=\\{(2,2),(1,3)\\}$ with $X_{2,2}=1$ and $X_{1,3}=1$, so $h_{2,3}=+1+1=+2$. With $X_{2,3}=0$,\n$$\nP=\\frac{1}{1+3^{2}}=\\frac{1}{10}.\n$$\n\n7) $(3,1)$: $N_{3,1}^{\\text{prev}}=\\{(2,1)\\}$ with $X_{2,1}=0$, so $h_{3,1}=-1$. With $X_{3,1}=1$,\n$$\nP=\\frac{1}{1+3^{1}}=\\frac{1}{4}.\n$$\n\n8) $(3,2)$: $N_{3,2}^{\\text{prev}}=\\{(3,1),(2,2)\\}$ with $X_{3,1}=1$ and $X_{2,2}=1$, so $h_{3,2}=+2$. With $X_{3,2}=0$,\n$$\nP=\\frac{1}{1+3^{2}}=\\frac{1}{10}.\n$$\n\n9) $(3,3)$: $N_{3,3}^{\\text{prev}}=\\{(3,2),(2,3)\\}$ with $X_{3,2}=0$ and $X_{2,3}=0$, so $h_{3,3}=-2$. With $X_{3,3}=1$,\n$$\nP=\\frac{1}{1+3^{2}}=\\frac{1}{10}.\n$$\n\nTherefore, the total probability is\n$$\nP_{\\text{total}}=\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{4}\\right)^{4}\\left(\\frac{1}{10}\\right)^{4}\n=\\frac{1}{2\\cdot 4^{4}\\cdot 10^{4}}=\\frac{1}{512\\cdot 10^{4}}=\\frac{1}{5120000}.\n$$\nConverting to scientific notation and rounding to four significant figures,\n$$\n\\frac{1}{5120000}=1.953125\\times 10^{-7}\\approx 1.953\\times 10^{-7}.\n$$", "answer": "$$\\boxed{1.953 \\times 10^{-7}}$$", "id": "1609176"}]}