{"hands_on_practices": [{"introduction": "Before we can use a joint probability function for any analysis, we must ensure it is a valid one. This first exercise focuses on the most fundamental property of any probability distribution: the probabilities of all possible outcomes must sum to 1. By working through this problem, you will practice applying this axiom to determine the normalization constant for a given joint probability mass function (PMF), a crucial first step in statistical modeling. [@problem_id:1926691]", "problem": "A data scientist at a financial technology company is analyzing the performance of two different fraud detection algorithms, Algorithm A and Algorithm B. Let $X$ be a random variable representing the number of suspicious flags raised by Algorithm A on a given transaction, and let $Y$ be the number of suspicious flags raised by Algorithm B on the same transaction.\n\nBased on extensive testing on a standardized dataset, the joint behavior of these two variables is modeled by the following joint probability mass function (PMF):\n$$p(x, y) = k(x + 2y)$$\nwhere $x$ can take values from the set $\\{1, 2\\}$ and $y$ can take values from the set $\\{1, 2, 3\\}$. The function $p(x, y)$ is zero for all other pairs of $(x, y)$. The constant $k$ is a normalization constant that ensures $p(x, y)$ is a valid PMF.\n\nDetermine the numerical value of the constant $k$. Express your answer as a fraction.", "solution": "To be a valid joint PMF, the total probability over the support must be one. Therefore,\n$$\\sum_{x \\in \\{1,2\\}} \\sum_{y \\in \\{1,2,3\\}} p(x,y) = 1.$$\nGiven $p(x,y) = k(x+2y)$ on the support, we have\n$$k \\sum_{x=1}^{2} \\sum_{y=1}^{3} (x + 2y) = 1.$$\nCompute the inner sum for fixed $x$:\n$$\\sum_{y=1}^{3} (x + 2y) = \\sum_{y=1}^{3} x + 2 \\sum_{y=1}^{3} y = 3x + 2 \\cdot \\frac{3 \\cdot 4}{2} = 3x + 12.$$\nNow sum over $x$:\n$$\\sum_{x=1}^{2} (3x + 12) = 3 \\sum_{x=1}^{2} x + 12 \\cdot 2 = 3 \\cdot \\frac{2 \\cdot 3}{2} + 24 = 9 + 24 = 33.$$\nThus,\n$$k \\cdot 33 = 1 \\quad \\Rightarrow \\quad k = \\frac{1}{33}.$$", "answer": "$$\\boxed{\\frac{1}{33}}$$", "id": "1926691"}, {"introduction": "Once a valid joint probability distribution is established, we can use it to answer meaningful questions about the system it models. This practice problem bridges theory and application by showing how to calculate a key performance metric—the bit-error rate in a data storage system—from the underlying probabilities. You will apply the law of total probability to a scenario involving asymmetric noise, a common feature in real-world engineering systems. [@problem_id:1635042]", "problem": "A computer engineer is analyzing the long-term reliability of a novel type of magnetic storage. In this system, data is stored as individual bits, which can be either a 0 or a 1. Let the random variable $X$ represent a bit that is initially written to the storage medium. Due to the properties of the data being stored, a bit is written as a '0' with probability $P(X=0) = 0.65$ and as a '1' with probability $P(X=1) = 0.35$.\n\nOver time, thermal noise can cause a stored bit to flip. Let the random variable $Y$ represent the value of the bit when it is read back at a later time. The noise process is asymmetric. The probability that a stored '0' is incorrectly read as a '1' is $0.08$. The probability that a stored '1' is incorrectly read as a '0' is $0.05$.\n\nAssuming that errors for different bits are independent events, determine the overall bit-error rate for this storage system. The bit-error rate is defined as the total probability that a randomly selected bit is read incorrectly, i.e., $P(Y \\neq X)$. Calculate this value based on the joint probability distribution of $X$ and $Y$.\n\nExpress your final answer as a numerical value rounded to three significant figures.", "solution": "We represent the initially written bit by the random variable $X$ with $P(X=0)=0.65$ and $P(X=1)=0.35$. The read-back bit is $Y$. The asymmetric noise process gives the conditional probabilities $P(Y=1 \\mid X=0)=0.08$ and $P(Y=0 \\mid X=1)=0.05$. By complementarity, $P(Y=0 \\mid X=0)=1-0.08=0.92$ and $P(Y=1 \\mid X=1)=1-0.05=0.95$.\n\nThe bit-error event is $E=\\{Y \\neq X\\}$, so by the law of total probability using the joint distribution via conditional probabilities,\n$$\nP(E)=P(Y=1,X=0)+P(Y=0,X=1)=P(X=0)P(Y=1 \\mid X=0)+P(X=1)P(Y=0 \\mid X=1).\n$$\nSubstituting the given values,\n$$\nP(E)=0.65 \\cdot 0.08 + 0.35 \\cdot 0.05=0.052+0.0175=0.0695.\n$$\nRounding to three significant figures yields $0.0695$.", "answer": "$$\\boxed{0.0695}$$", "id": "1635042"}, {"introduction": "A common pitfall in statistics is assuming that zero covariance implies independence. This problem is designed to dismantle that misconception through a clear and powerful counterexample using a hypothetical model of a particle's position and energy. By analyzing a simple functional relationship between two variables, $Y = \\alpha X^2$, you will demonstrate that variables can be strongly dependent yet have a covariance of zero. [@problem_id:1926651] Mastering this distinction is essential for correctly interpreting statistical relationships and avoiding erroneous conclusions in data analysis.", "problem": "In a simplified model of a quantum particle trapped in a one-dimensional infinite potential well extending from $-L$ to $L$, the particle's position is described by a random variable. In the high temperature classical limit, we can model the particle's position, $X$, as a continuous random variable uniformly distributed over the interval $[-L, L]$.\n\nThe particle is also subject to a confining potential within the well, modeled by the function $V(x) = \\alpha x^2$, where $\\alpha$ is a known positive constant. The potential energy of the particle is thus also a random variable, denoted by $Y = \\alpha X^2$.\n\nBased on this model, which of the following statements correctly describes the relationship between the particle's position $X$ and its potential energy $Y$?\n\nA. The covariance $\\text{Cov}(X, Y)$ is zero, and the variables $X$ and $Y$ are independent.\n\nB. The covariance $\\text{Cov}(X, Y)$ is zero, and the variables $X$ and $Y$ are not independent.\n\nC. The covariance $\\text{Cov}(X, Y)$ is non-zero, and the variables $X$ and $Y$ are independent.\n\nD. The covariance $\\text{Cov}(X, Y)$ is non-zero, and the variables $X$ and $Y$ are not independent.\n\nE. Whether the covariance is zero or non-zero depends on the specific values of the constants $L$ and $\\alpha$.", "solution": "Let $X$ be uniformly distributed on $[-L, L]$, so its probability density function is $f_{X}(x) = \\frac{1}{2L}$ for $x \\in [-L,L]$ and $0$ otherwise. Define $Y = \\alpha X^{2}$ with $\\alpha>0$.\n\nCompute the expectations needed for the covariance. First,\n$$\n\\mathbb{E}[X] = \\int_{-L}^{L} x \\frac{1}{2L} \\,\\mathrm{d}x = 0\n$$\nby symmetry of an odd integrand over a symmetric interval.\n\nNext,\n$$\n\\mathbb{E}[Y] = \\alpha \\mathbb{E}[X^{2}] = \\alpha \\int_{-L}^{L} x^{2} \\frac{1}{2L} \\,\\mathrm{d}x = \\alpha \\frac{1}{2L} \\cdot \\int_{-L}^{L} x^{2}\\,\\mathrm{d}x = \\alpha \\frac{1}{2L} \\cdot \\frac{2 L^{3}}{3} = \\alpha \\frac{L^{2}}{3}.\n$$\n\nAlso,\n$$\n\\mathbb{E}[XY] = \\alpha \\mathbb{E}[X^{3}] = \\alpha \\int_{-L}^{L} x^{3} \\frac{1}{2L} \\,\\mathrm{d}x = 0\n$$\nagain by symmetry, since $x^{3}$ is an odd function over $[-L,L]$.\n\nTherefore the covariance is\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - 0 \\cdot \\alpha \\frac{L^{2}}{3} = 0.\n$$\nThis holds for all $L>0$ and $\\alpha>0$, so the covariance does not depend on the specific values beyond positivity.\n\nTo assess independence, note that $Y$ is a deterministic (non-constant) function of $X$. For any $y$ with $0<y<\\alpha L^{2}$,\n$$\n\\mathbb{P}(Y \\le y \\mid X = x) = \\mathbf{1}\\{\\alpha x^{2} \\le y\\},\n$$\nwhich depends on $x$. Since $\\mathbb{P}(Y \\le y)$ is strictly between $0$ and $1$ for such $y$, it cannot equal $\\mathbb{P}(Y \\le y \\mid X = x)$ for all $x$ with positive density. Hence $X$ and $Y$ are not independent. Intuitively, knowing $Y$ determines $|X| = \\sqrt{Y/\\alpha}$, so $X$ and $Y$ are dependent.\n\nThus, the correct statement is that the covariance is zero and the variables are not independent.", "answer": "$$\\boxed{B}$$", "id": "1926651"}]}