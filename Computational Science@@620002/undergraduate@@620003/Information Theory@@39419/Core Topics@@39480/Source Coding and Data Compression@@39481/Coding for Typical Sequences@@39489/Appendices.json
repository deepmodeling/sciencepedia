{"hands_on_practices": [{"introduction": "The concept of a \"typical set\" is central to information theory and data compression. While a source can generate a vast number of different sequences, most of the probability is concentrated in a much smaller subset of \"typical\" sequences that reflect the source's statistical properties. This first exercise provides a foundational practice in quantifying the size of this crucial set for a source with non-uniform probabilities, as is common in real-world scenarios like genetics. By completing this calculation, you will be applying the Asymptotic Equipartition Property (AEP), one of the cornerstones of source coding theory [@problem_id:1611193].", "problem": "A team of bioinformaticians is studying a highly conserved region of a viral genome. They model this region as a sequence of nucleic acid bases, where the alphabet of possible bases is $\\mathcal{X} = \\{\\text{A, C, G, T}\\}$. Based on extensive data from thousands of viral samples, they have established a stationary probability model for the occurrence of each base at any given position. The model assumes that each base in the sequence is an independent and identically distributed random variable. The established probabilities for each base are:\n-   Probability of Adenine (A): $p_A = \\frac{1}{2}$\n-   Probability of Guanine (G): $p_G = \\frac{1}{4}$\n-   Probability of Cytosine (C): $p_C = \\frac{1}{8}$\n-   Probability of Thymine (T): $p_T = \\frac{1}{8}$\n\nThe team is developing a computational tool to identify \"statistically typical\" genomic sequences for their analysis. A key component of this tool is a function that estimates the total number of such typical sequences of a given length. For a sufficiently long sequence of length $L$, the number of typical sequences, $N_{typical}$, can be accurately approximated by the quantity $2^{L \\cdot H(X)}$, where $H(X)$ is the Shannon entropy of the single-base source, measured in bits.\n\nFor a genomic sequence of length $L = 64$ bases, calculate the approximate number of statistically typical sequences, $N_{typical}$. Express your answer in scientific notation, rounded to three significant figures.", "solution": "We are given an i.i.d. source over $\\mathcal{X}=\\{\\text{A,C,G,T}\\}$ with probabilities $p_{A}=\\frac{1}{2}$, $p_{G}=\\frac{1}{4}$, $p_{C}=\\frac{1}{8}$, $p_{T}=\\frac{1}{8}$. The Shannon entropy in bits is\n$$\nH(X)=-\\sum_{x\\in\\mathcal{X}} p_{x}\\log_{2} p_{x}.\n$$\nCompute each term:\n- For $p_{A}=\\frac{1}{2}$: $-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)=\\frac{1}{2}$.\n- For $p_{G}=\\frac{1}{4}$: $-\\frac{1}{4}\\log_{2}\\!\\left(\\frac{1}{4}\\right)=\\frac{1}{2}$.\n- For $p_{C}=p_{T}=\\frac{1}{8}$: each contributes $-\\frac{1}{8}\\log_{2}\\!\\left(\\frac{1}{8}\\right)=\\frac{3}{8}$, so together $\\frac{3}{8}+\\frac{3}{8}=\\frac{3}{4}$.\nThus\n$$\nH(X)=\\frac{1}{2}+\\frac{1}{2}+\\frac{3}{4}=\\frac{7}{4}\\ \\text{bits}.\n$$\nFor sequence length $L=64$, the typical set size is approximated by\n$$\nN_{\\text{typical}}\\approx 2^{L H(X)}=2^{64\\cdot \\frac{7}{4}}=2^{112}.\n$$\nTo express $2^{112}$ in scientific notation, write $2^{112}=10^{112\\log_{10} 2}$. Using $\\log_{10} 2\\approx 0.30102999566$,\n$$\n\\log_{10} N_{\\text{typical}}=112\\log_{10} 2\\approx 33.7153595,\n$$\nso\n$$\nN_{\\text{typical}}\\approx 10^{0.7153595}\\times 10^{33}\\approx 5.19\\times 10^{33},\n$$\nrounded to three significant figures.", "answer": "$$\\boxed{5.19 \\times 10^{33}}$$", "id": "1611193"}, {"introduction": "After estimating how many typical sequences exist, a natural next question is: what do these sequences actually look like? This practice moves from counting the size of the typical set to characterizing its members. A sequence being \"typical\" implies that its internal composition—the frequency of its symbols—closely mirrors the probabilities of the source itself. In this problem, you will translate the formal definition of typicality into concrete, quantitative bounds on the composition of a sequence, providing a more tangible understanding of what makes a sequence statistically representative [@problem_id:1611198].", "problem": "An information source generates a stream of symbols from the alphabet $\\mathcal{X}=\\{\\text{'a'},\\text{'b'}\\}$. The symbols are generated independently with probabilities $P(\\text{'a'}) = 0.8$ and $P(\\text{'b'}) = 0.2$.\nA sequence is considered \"statistically representative\" if its properties are close to the long-term average behavior of the source. For a sequence $x^n$ of length $n=100$, this condition is mathematically expressed through its probability of occurrence, $p(x^n)$, as follows:\n$$ \\left| \\frac{-\\log_2(p(x^n))}{n} - H \\right| \\le \\epsilon $$\nIn this expression, $H$ is the Shannon entropy of the source, given by $H = -\\sum_{i \\in \\mathcal{X}} P(i) \\log_2(P(i))$, and $\\epsilon$ is a small tolerance factor.\n\nGiven $n=100$ and $\\epsilon=0.05$, find the minimum and maximum number of times the symbol $\\text{'a'}$ can appear in a 100-symbol sequence for it to be classified as statistically representative. Your answer must consist of two integers.", "solution": "Let $p \\triangleq P(\\text{'a'}) = \\frac{4}{5}$ and $q \\triangleq P(\\text{'b'}) = \\frac{1}{5}$. For a length-$n$ sequence with $k$ occurrences of $\\text{'a'}$ and $n-k$ of $\\text{'b'}$, the probability is\n$$\np(x^{n}) = p^{k} q^{n-k}.\n$$\nDefine the empirical fraction $f \\triangleq \\frac{k}{n}$. Then\n$$\n- \\frac{1}{n} \\log_{2} p(x^{n}) = -\\left( f \\log_{2} p + (1-f) \\log_{2} q \\right).\n$$\nWith $p=\\frac{4}{5}$ and $q=\\frac{1}{5}$, note that\n$$\n\\log_{2}\\!\\left(\\frac{4}{5}\\right) = 2 - \\log_{2} 5, \\quad \\log_{2}\\!\\left(\\frac{1}{5}\\right) = - \\log_{2} 5,\n$$\nso\n$$\n- \\frac{1}{n} \\log_{2} p(x^{n}) = -\\left[ f(2 - \\log_{2} 5) + (1-f)(- \\log_{2} 5) \\right] = \\log_{2} 5 - 2f.\n$$\nThe Shannon entropy is\n$$\nH = -\\left( p \\log_{2} p + q \\log_{2} q \\right) = -\\left( \\frac{4}{5} \\log_{2}\\!\\frac{4}{5} + \\frac{1}{5} \\log_{2}\\!\\frac{1}{5} \\right)\n= \\log_{2} 5 - \\frac{8}{5}.\n$$\nThe typicality condition\n$$\n\\left| - \\frac{1}{n} \\log_{2} p(x^{n}) - H \\right| \\le \\epsilon\n$$\nbecomes\n$$\n\\left| (\\log_{2} 5 - 2f) - \\left(\\log_{2} 5 - \\frac{8}{5}\\right) \\right| \\le \\epsilon\n\\;\\;\\Longleftrightarrow\\;\\;\n|\\,2f - \\tfrac{8}{5}\\,| \\le \\epsilon.\n$$\nThus\n$$\n\\frac{8}{5} - \\epsilon \\le 2f \\le \\frac{8}{5} + \\epsilon\n\\;\\;\\Longleftrightarrow\\;\\;\n\\frac{4}{5} - \\frac{\\epsilon}{2} \\le f \\le \\frac{4}{5} + \\frac{\\epsilon}{2}.\n$$\nWith $n=100$ and $\\epsilon = \\frac{1}{20}$, we get\n$$\n\\frac{4}{5} - \\frac{1}{40} \\le f \\le \\frac{4}{5} + \\frac{1}{40}\n\\;\\;\\Longleftrightarrow\\;\\;\n\\frac{31}{40} \\le f \\le \\frac{33}{40}.\n$$\nMultiplying by $n=100$ gives the allowable range for $k$:\n$$\n77.5 \\le k \\le 82.5.\n$$\nSince $k$ must be an integer,\n$$\nk_{\\min} = \\lceil 77.5 \\rceil = 78, \\quad k_{\\max} = \\lfloor 82.5 \\rfloor = 82.\n$$\nTherefore, the minimum and maximum number of times the symbol $\\text{'a'}$ can appear are $78$ and $82$, respectively.", "answer": "$$\\boxed{\\begin{pmatrix}78 & 82\\end{pmatrix}}$$", "id": "1611198"}, {"introduction": "Our understanding of typicality can be extended from analyzing static, completed sequences to monitoring dynamic processes in real time. This final exercise simulates a practical application in anomaly detection, a key task in manufacturing and systems monitoring. Here, you will not evaluate a finished sequence but will instead perform a sequential test, checking at each step whether an incoming data stream still conforms to its expected statistical behavior. This practice demonstrates how the convergence of empirical entropy to the true source entropy, a direct consequence of the AEP, can be used to build powerful, adaptive monitoring tools [@problem_id:1611204].", "problem": "An anomaly detection system is designed to monitor a manufacturing process that produces a stream of microchips. The process is intended to function as a discrete memoryless source, producing three types of chips, denoted by the alphabet $\\mathcal{X} = \\{A, B, C\\}$, with probabilities $p(A) = \\frac{1}{2}$, $p(B) = \\frac{1}{4}$, and $p(C) = \\frac{1}{4}$.\n\nThe system's anomaly test operates sequentially. After each chip $x_k$ is produced at time step $k$, the system calculates the running empirical entropy, $H_k$, of the observed sequence $x_1, \\dots, x_k$. The empirical entropy is defined as $H_k = - \\sum_{i \\in \\mathcal{X}} \\hat{p}_k(i) \\log_2(\\hat{p}_k(i))$, where $\\hat{p}_k(i)$ is the observed frequency of chip type $i$ in the first $k$ outputs. The convention $0 \\log_2(0) = 0$ is used.\n\nThe system flags an anomaly and halts the manufacturing line at the first time step $k \\ge 1$ where the absolute difference between the empirical entropy $H_k$ and the source's design entropy $H(X)$ exceeds a time-dependent tolerance $\\delta(k)$. The design entropy is $H(X) = - \\sum_{i \\in \\mathcal{X}} p(i) \\log_2(p(i))$, and the tolerance is given by the function $\\delta(k) = \\frac{1.6}{\\sqrt{k}}$.\n\nSuppose the system observes the start of a production run with the following sequence of chips:\nA, B, C, C, C, C, C, C, C, C\n\nAt which time step $k$ does the system halt production? Provide the integer value of $k$.", "solution": "The source distribution is $p(A)=\\frac{1}{2}$, $p(B)=\\frac{1}{4}$, $p(C)=\\frac{1}{4}$. The design entropy is\n$$\nH(X)=-\\sum_{i\\in\\{A,B,C\\}}p(i)\\log_{2}p(i)=-\\left(\\tfrac{1}{2}\\log_{2}\\tfrac{1}{2}+\\tfrac{1}{4}\\log_{2}\\tfrac{1}{4}+\\tfrac{1}{4}\\log_{2}\\tfrac{1}{4}\\right)=\\tfrac{3}{2}.\n$$\nThe sequential tolerance is $\\delta(k)=\\frac{1.6}{\\sqrt{k}}$. After each chip $x_{k}$, with empirical distribution $\\hat{p}_{k}$, the empirical entropy is $H_{k}=-\\sum_{i}\\hat{p}_{k}(i)\\log_{2}\\hat{p}_{k}(i)$, and the system halts at the first $k$ with $|H_{k}-H(X)|>\\delta(k)$.\n\nProcess the observed sequence A, B, C, C, C, C, C, C, C, C step by step:\n\n- $k=1$: counts $(1,0,0)$ so $\\hat{p}_{1}=(1,0,0)$ and $H_{1}=0$. Then $|H_{1}-H(X)|=\\left|0-\\tfrac{3}{2}\\right|=\\tfrac{3}{2}$ and $\\delta(1)=1.6$. Since $\\tfrac{3}{2}<1.6$, no halt.\n\n- $k=2$: counts $(1,1,0)$ so $\\hat{p}_{2}=\\left(\\tfrac{1}{2},\\tfrac{1}{2},0\\right)$ and $H_{2}=-2\\cdot\\tfrac{1}{2}\\log_{2}\\tfrac{1}{2}=1$. Then $|H_{2}-H(X)|=\\tfrac{1}{2}$ and $\\delta(2)=\\tfrac{1.6}{\\sqrt{2}}\\approx 1.131$, no halt.\n\n- $k=3$: counts $(1,1,1)$ so $\\hat{p}_{3}=\\left(\\tfrac{1}{3},\\tfrac{1}{3},\\tfrac{1}{3}\\right)$ and $H_{3}=\\log_{2}3\\approx 1.5849625$. Then $|H_{3}-H(X)|\\approx 0.0849625$ and $\\delta(3)=\\tfrac{1.6}{\\sqrt{3}}\\approx 0.923$, no halt.\n\n- $k=4$: counts $(1,1,2)$ so $\\hat{p}_{4}=\\left(\\tfrac{1}{4},\\tfrac{1}{4},\\tfrac{1}{2}\\right)$ and $H_{4}=H(X)=\\tfrac{3}{2}$. Then $|H_{4}-H(X)|=0$ and $\\delta(4)=\\tfrac{1.6}{2}=0.8$, no halt.\n\n- $k=5$: counts $(1,1,3)$ so $\\hat{p}_{5}=\\left(\\tfrac{1}{5},\\tfrac{1}{5},\\tfrac{3}{5}\\right)$ and\n$$\nH_{5}=-\\left(\\tfrac{2}{5}\\log_{2}\\tfrac{1}{5}+\\tfrac{3}{5}\\log_{2}\\tfrac{3}{5}\\right)\\approx 1.370950594.\n$$\nThen $|H_{5}-H(X)|\\approx 0.129049406$ and $\\delta(5)=\\tfrac{1.6}{\\sqrt{5}}\\approx 0.715541752$, no halt.\n\n- $k=6$: counts $(1,1,4)$ so $\\hat{p}_{6}=\\left(\\tfrac{1}{6},\\tfrac{1}{6},\\tfrac{2}{3}\\right)$ and\n$$\nH_{6}=-\\left(\\tfrac{2}{6}\\log_{2}\\tfrac{1}{6}+\\tfrac{2}{3}\\log_{2}\\tfrac{2}{3}\\right)\\approx 1.251629168.\n$$\nThen $|H_{6}-H(X)|\\approx 0.248370832$ and $\\delta(6)=\\tfrac{1.6}{\\sqrt{6}}\\approx 0.653197265$, no halt.\n\n- $k=7$: counts $(1,1,5)$ so $\\hat{p}_{7}=\\left(\\tfrac{1}{7},\\tfrac{1}{7},\\tfrac{5}{7}\\right)$ and\n$$\nH_{7}=-\\left(\\tfrac{2}{7}\\log_{2}\\tfrac{1}{7}+\\tfrac{5}{7}\\log_{2}\\tfrac{5}{7}\\right)\\approx 1.148834854.\n$$\nThen $|H_{7}-H(X)|\\approx 0.351165146$ and $\\delta(7)=\\tfrac{1.6}{\\sqrt{7}}\\approx 0.604143$, no halt.\n\n- $k=8$: counts $(1,1,6)$ so $\\hat{p}_{8}=\\left(\\tfrac{1}{8},\\tfrac{1}{8},\\tfrac{3}{4}\\right)$ and\n$$\nH_{8}=-\\left(\\tfrac{1}{4}\\log_{2}\\tfrac{1}{8}+\\tfrac{3}{4}\\log_{2}\\tfrac{3}{4}\\right)= -\\left(\\tfrac{1}{4}(-3)+\\tfrac{3}{4}(\\log_{2}3-2)\\right)\\approx 1.061278124.\n$$\nThen $|H_{8}-H(X)|\\approx 0.438721876$ and $\\delta(8)=\\tfrac{1.6}{\\sqrt{8}}\\approx 0.565685425$, no halt.\n\n- $k=9$: counts $(1,1,7)$ so $\\hat{p}_{9}=\\left(\\tfrac{1}{9},\\tfrac{1}{9},\\tfrac{7}{9}\\right)$ and\n$$\nH_{9}=-\\left(\\tfrac{2}{9}\\log_{2}\\tfrac{1}{9}+\\tfrac{7}{9}\\log_{2}\\tfrac{7}{9}\\right)\\approx 1.013573271.\n$$\nThen $|H_{9}-H(X)|\\approx 0.486426729$ and $\\delta(9)=\\tfrac{1.6}{3}\\approx 0.533333333$, no halt.\n\n- $k=10$: counts $(1,1,8)$ so $\\hat{p}_{10}=\\left(\\tfrac{1}{10},\\tfrac{1}{10},\\tfrac{4}{5}\\right)$ and\n$$\nH_{10}=-\\left(\\tfrac{1}{5}\\log_{2}\\tfrac{1}{10}+\\tfrac{4}{5}\\log_{2}\\tfrac{4}{5}\\right)\\approx 0.921928095.\n$$\nThen $|H_{10}-H(X)|\\approx 1.5-0.921928095=0.578071905$ and $\\delta(10)=\\tfrac{1.6}{\\sqrt{10}}\\approx 0.506$, so $|H_{10}-H(X)|>\\delta(10)$.\n\nTherefore, the first time step at which the threshold is exceeded is $k=10$.", "answer": "$$\\boxed{10}$$", "id": "1611204"}]}