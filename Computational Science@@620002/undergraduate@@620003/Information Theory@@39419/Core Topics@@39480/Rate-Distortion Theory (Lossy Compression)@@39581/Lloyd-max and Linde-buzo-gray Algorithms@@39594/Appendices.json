{"hands_on_practices": [{"introduction": "A key aspect of designing an optimal quantizer is determining the best representative value, or reconstruction level, for each partition of the data. This practice explores the fundamental centroid condition, which states that to minimize mean squared error, the reconstruction level must be the centroid (or center of mass) of the data points within its region. By working through this problem, you will see how to calculate these optimal levels for a given partition, a crucial first step in the Lloyd-Max optimization process [@problem_id:1637680].", "problem": "Consider a continuous random variable $X$ representing a signal source. The probability density function of the signal's amplitude is uniform over the interval $[0, 1]$. A 1-bit scalar quantizer is employed to digitize this signal. The quantizer uses a single decision boundary at a value of $0.5$ to partition the input range into two distinct regions, $R_1 = [0, 0.5]$ and $R_2 = (0.5, 1]$. For any input signal $x \\in R_1$, the quantizer outputs a constant reconstruction level $y_1$. For any input signal $x \\in R_2$, it outputs a constant reconstruction level $y_2$. To minimize the mean squared error between the original signal and the quantized signal, the reconstruction levels $y_1$ and $y_2$ must be chosen optimally.\n\nDetermine the optimal values for the reconstruction levels $y_1$ and $y_2$.", "solution": "The problem asks for the optimal reconstruction levels $y_1$ and $y_2$ that minimize the mean squared error (MSE) for a given 1-bit quantizer. Let $X$ be the random variable representing the source signal, and let $Q(X)$ be the quantized output. The source $X$ has a uniform probability density function (PDF), $f_X(x)$, over the interval $[0, 1]$.\n$$\nf_X(x) =\n\\begin{cases}\n1 & \\text{for } 0 \\le x \\le 1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe quantizer function $Q(x)$ is defined based on the two regions $R_1 = [0, 0.5]$ and $R_2 = (0.5, 1]$:\n$$\nQ(x) =\n\\begin{cases}\ny_1 & \\text{for } x \\in R_1 \\\\\ny_2 & \\text{for } x \\in R_2\n\\end{cases}\n$$\nThe mean squared error is defined as the expected value of the squared difference between the original signal and its quantized representation:\n$$\nMSE = E[(X - Q(X))^2] = \\int_{-\\infty}^{\\infty} (x - Q(x))^2 f_X(x) dx\n$$\nGiven the specified regions and the PDF, we can write the MSE integral as a sum of integrals over the two regions:\n$$\nMSE = \\int_{0}^{0.5} (x - y_1)^2 f_X(x) dx + \\int_{0.5}^{1} (x - y_2)^2 f_X(x) dx\n$$\nSince $f_X(x) = 1$ in the interval $[0, 1]$, this simplifies to:\n$$\nMSE = \\int_{0}^{0.5} (x - y_1)^2 dx + \\int_{0.5}^{1} (x - y_2)^2 dx\n$$\nTo find the values of $y_1$ and $y_2$ that minimize the MSE, we must take the partial derivatives of the MSE with respect to $y_1$ and $y_2$ and set them to zero.\n\nFirst, let's find the optimal value for $y_1$. We differentiate the MSE with respect to $y_1$. Note that the second integral does not depend on $y_1$.\n$$\n\\frac{\\partial (MSE)}{\\partial y_1} = \\frac{\\partial}{\\partial y_1} \\int_{0}^{0.5} (x - y_1)^2 dx = \\int_{0}^{0.5} \\frac{\\partial}{\\partial y_1} (x - y_1)^2 dx\n$$\n$$\n\\frac{\\partial (MSE)}{\\partial y_1} = \\int_{0}^{0.5} 2(x - y_1)(-1) dx = -2 \\int_{0}^{0.5} (x - y_1) dx\n$$\nSetting the derivative to zero to find the minimum:\n$$\n-2 \\int_{0}^{0.5} (x - y_1) dx = 0 \\implies \\int_{0}^{0.5} x dx - \\int_{0}^{0.5} y_1 dx = 0\n$$\nSince $y_1$ is a constant, we can pull it out of the integral:\n$$\n\\int_{0}^{0.5} x dx = y_1 \\int_{0}^{0.5} 1 dx\n$$\nSolving for $y_1$:\n$$\ny_1 = \\frac{\\int_{0}^{0.5} x dx}{\\int_{0}^{0.5} 1 dx}\n$$\nThis expression is the centroid (or conditional expectation) of the source distribution over the region $R_1$. We now evaluate the integrals:\nThe numerator is $\\int_{0}^{0.5} x dx = \\left[ \\frac{x^2}{2} \\right]_{0}^{0.5} = \\frac{(0.5)^2}{2} - 0 = \\frac{0.25}{2} = \\frac{1/4}{2} = \\frac{1}{8}$.\nThe denominator is $\\int_{0}^{0.5} 1 dx = [x]_{0}^{0.5} = 0.5 - 0 = 0.5 = \\frac{1}{2}$.\nSo, the optimal value for $y_1$ is:\n$$\ny_1 = \\frac{1/8}{1/2} = \\frac{1}{4}\n$$\nNext, we find the optimal value for $y_2$ using the same procedure. We differentiate the MSE with respect to $y_2$. The first integral does not depend on $y_2$.\n$$\n\\frac{\\partial (MSE)}{\\partial y_2} = \\frac{\\partial}{\\partial y_2} \\int_{0.5}^{1} (x - y_2)^2 dx = \\int_{0.5}^{1} \\frac{\\partial}{\\partial y_2} (x - y_2)^2 dx\n$$\n$$\n\\frac{\\partial (MSE)}{\\partial y_2} = \\int_{0.5}^{1} 2(x - y_2)(-1) dx = -2 \\int_{0.5}^{1} (x - y_2) dx\n$$\nSet the derivative to zero:\n$$\n-2 \\int_{0.5}^{1} (x - y_2) dx = 0 \\implies \\int_{0.5}^{1} x dx - \\int_{0.5}^{1} y_2 dx = 0\n$$\nSolving for $y_2$:\n$$\ny_2 = \\frac{\\int_{0.5}^{1} x dx}{\\int_{0.5}^{1} 1 dx}\n$$\nThis is the centroid of the source distribution over the region $R_2$. We evaluate the integrals:\nThe numerator is $\\int_{0.5}^{1} x dx = \\left[ \\frac{x^2}{2} \\right]_{0.5}^{1} = \\frac{1^2}{2} - \\frac{(0.5)^2}{2} = \\frac{1}{2} - \\frac{0.25}{2} = \\frac{0.75}{2} = \\frac{3/4}{2} = \\frac{3}{8}$.\nThe denominator is $\\int_{0.5}^{1} 1 dx = [x]_{0.5}^{1} = 1 - 0.5 = 0.5 = \\frac{1}{2}$.\nSo, the optimal value for $y_2$ is:\n$$\ny_2 = \\frac{3/8}{1/2} = \\frac{3}{4}\n$$\nThe optimal reconstruction levels are $y_1 = 1/4$ and $y_2 = 3/4$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{4} & \\frac{3}{4}\n\\end{pmatrix}\n}\n$$", "id": "1637680"}, {"introduction": "Complementing the centroid condition, the other pillar of quantizer optimization is defining the decision boundaries. Given a set of fixed reconstruction levels, how do we partition the source's range to minimize distortion? This exercise demonstrates the nearest neighbor condition, an intuitive rule stating that the optimal boundary $b_1$ between two levels $y_1$ and $y_2$ is simply their midpoint, $b_1 = \\frac{y_1 + y_2}{2}$. This ensures every input value is assigned to the closest possible reconstruction level, which is essential for building an efficient quantizer [@problem_id:1637665].", "problem": "An analog sensor produces a voltage signal, which can be modeled as a continuous random variable $X$ with a uniform probability distribution over the interval $[-3, 3]$. To digitize this signal for processing, a simple 1-bit scalar quantizer is employed. This quantizer maps the input voltage to one of two predefined reconstruction levels. Due to hardware constraints, the reconstruction levels are asymmetrically set to $y_1 = -2.5$ and $y_2 = 1.8$.\n\nAssuming the design goal is to minimize the mean squared error (MSE) distortion, determine the optimal decision boundary $b_1$ that separates the two quantization regions. The decision rule is as follows: if the input signal $x$ is less than or equal to $b_1$, it is mapped to $y_1$; otherwise, it is mapped to $y_2$. The domain of the random variable $X$ is the interval $[-3, 3]$, so the two quantization regions are $[-3, b_1]$ and $(b_1, 3]$.\n\nExpress your answer as a single real number.", "solution": "The problem asks for the optimal decision boundary $b_1$ for a 1-bit quantizer that minimizes the mean squared error (MSE). The quantizer maps an input signal $x$ to one of two reconstruction levels, $y_1 = -2.5$ or $y_2 = 1.8$. The input signal $X$ is a random variable uniformly distributed on $[-3, 3]$.\n\nThe probability density function (PDF) of the uniform distribution on the interval $[a, b]$ is given by $p(x) = \\frac{1}{b-a}$ for $x \\in [a, b]$ and $p(x)=0$ otherwise. For our case, with the interval $[-3, 3]$, the PDF is $p(x) = \\frac{1}{3 - (-3)} = \\frac{1}{6}$ for $x \\in [-3, 3]$.\n\nThe quantizer function $Q(x)$ is defined by the decision boundary $b_1$:\n$$\nQ(x) = \\begin{cases} y_1 & \\text{if } x \\le b_1 \\\\ y_2 & \\text{if } x > b_1 \\end{cases}\n$$\nThe MSE distortion, $D$, is the expected value of the squared error between the input signal $X$ and its quantized representation $Q(X)$. It is calculated by integrating the squared error over the entire distribution:\n$$\nD = E[(X - Q(X))^2] = \\int_{-3}^{3} (x - Q(x))^2 p(x) dx\n$$\nWe can split this integral into the two quantization regions defined by the boundary $b_1$: the region $[-3, b_1]$ where $Q(x) = y_1$, and the region $(b_1, 3]$ where $Q(x) = y_2$.\n$$\nD(b_1) = \\int_{-3}^{b_1} (x - y_1)^2 p(x) dx + \\int_{b_1}^{3} (x - y_2)^2 p(x) dx\n$$\nTo find the optimal decision boundary $b_1$ that minimizes the distortion $D$, we need to find the value of $b_1$ for which the derivative of $D$ with respect to $b_1$ is zero. We use the Leibniz integral rule for differentiation under the integral sign:\n$$\n\\frac{d}{dc} \\int_{a(c)}^{b(c)} f(x, c) dx = f(b(c), c) \\frac{db}{dc} - f(a(c), c) \\frac{da}{dc} + \\int_{a(c)}^{b(c)} \\frac{\\partial f}{\\partial c} dx\n$$\nIn our case, the integrand does not depend on $b_1$, so the partial derivative term is zero. Applying the rule, we get:\n$$\n\\frac{dD}{db_1} = \\left[ (b_1 - y_1)^2 p(b_1) \\right] - \\left[ (b_1 - y_2)^2 p(b_1) \\right]\n$$\nSetting the derivative to zero to find the minimum:\n$$\n\\frac{dD}{db_1} = p(b_1) \\left[ (b_1 - y_1)^2 - (b_1 - y_2)^2 \\right] = 0\n$$\nThe optimal boundary $b_1$ must lie within the interval $(-3, 3)$, where $p(b_1) = 1/6 \\neq 0$. Therefore, we can divide by $p(b_1)$:\n$$\n(b_1 - y_1)^2 - (b_1 - y_2)^2 = 0\n$$\n$$\n(b_1 - y_1)^2 = (b_1 - y_2)^2\n$$\nTaking the square root of both sides gives two possibilities:\n1. $b_1 - y_1 = b_1 - y_2$, which simplifies to $y_1 = y_2$. This is not possible since the reconstruction levels $y_1 = -2.5$ and $y_2 = 1.8$ are distinct.\n2. $b_1 - y_1 = -(b_1 - y_2)$, which simplifies to $b_1 - y_1 = y_2 - b_1$.\n\nWe solve the second equation for $b_1$:\n$$\n2b_1 = y_1 + y_2\n$$\n$$\nb_1 = \\frac{y_1 + y_2}{2}\n$$\nThis result is the well-known nearest neighbor condition for optimal quantization: the decision boundary between two reconstruction levels should be their midpoint.\n\nNow, we substitute the given values for $y_1$ and $y_2$ into this formula:\n$$\ny_1 = -2.5\n$$\n$$\ny_2 = 1.8\n$$\n$$\nb_1 = \\frac{-2.5 + 1.8}{2} = \\frac{-0.7}{2} = -0.35\n$$\nThe optimal decision boundary is $b_1 = -0.35$. This value is within the source's range of $[-3, 3]$, confirming it is a valid boundary.", "answer": "$$\\boxed{-0.35}$$", "id": "1637665"}, {"introduction": "Now that we have individually practiced the two necessary conditions for an optimal scalar quantizer—the nearest neighbor and centroid rules—we can combine them to perform a full iteration of the Lloyd-Max algorithm. Starting with an initial guess for the reconstruction levels, we will first re-partition the source alphabet according to the nearest neighbor rule, and then update the levels to be the centroids of these new partitions. This problem provides a concrete example of how the algorithm iteratively refines the quantizer, stepping closer to a minimum distortion configuration with each cycle [@problem_id:1637671].", "problem": "A data acquisition system is designed to measure a physical quantity that, after sampling and some initial processing, produces values from a discrete set of levels. The set of possible output levels is given by the alphabet $\\mathcal{X} = \\{1, 3, 4, 8\\}$. Due to the nature of the underlying physical process, each of these four levels is observed with equal probability.\n\nTo compress this data for transmission, a simple 1-bit scalar quantizer is to be implemented. This means all source values will be mapped to one of two reconstruction levels. The Lloyd-Max algorithm is chosen to optimize the placement of these two reconstruction levels to minimize the mean squared quantization error.\n\nThe optimization process begins with an initial guess for the two reconstruction levels: $y_1^{(0)} = 2.5$ and $y_2^{(0)} = 7.0$.\n\nYour task is to perform one full iteration of the Lloyd-Max algorithm. A full iteration consists of two steps: first, partitioning the source alphabet based on the nearest reconstruction level, and second, updating the reconstruction levels to be the centroids of the new partitions.\n\nCalculate the new pair of reconstruction levels, $(y_1^{(1)}, y_2^{(1)})$. Express your answer as a row matrix containing the two values in increasing order, using exact fractions if necessary.", "solution": "The source alphabet is $\\mathcal{X}=\\{1,3,4,8\\}$ with equal probabilities $p(x)=\\frac{1}{4}$ for each $x \\in \\mathcal{X}$. For mean squared error, the Lloyd-Max partition between two reconstruction levels is the midpoint of the current levels. With $y_{1}^{(0)}=\\frac{5}{2}$ and $y_{2}^{(0)}=7$, the decision boundary is\n$$\nb=\\frac{y_{1}^{(0)}+y_{2}^{(0)}}{2}=\\frac{\\frac{5}{2}+7}{2}=\\frac{\\frac{5}{2}+\\frac{14}{2}}{2}=\\frac{\\frac{19}{2}}{2}=\\frac{19}{4}.\n$$\nThus the partition induced by nearest-neighbor assignment is $S_{1}=\\{1,3,4\\}$ and $S_{2}=\\{8\\}$.\n\nThe centroid update for discrete equiprobable points is\n$$\ny_{k}^{(1)}=\\frac{\\sum_{x \\in S_{k}} x\\,p(x)}{\\sum_{x \\in S_{k}} p(x)}.\n$$\nFor $S_{1}$,\n$$\ny_{1}^{(1)}=\\frac{(1+3+4)\\cdot \\frac{1}{4}}{3 \\cdot \\frac{1}{4}}=\\frac{8}{3},\n$$\nand for $S_{2}$,\n$$\ny_{2}^{(1)}=\\frac{8 \\cdot \\frac{1}{4}}{1 \\cdot \\frac{1}{4}}=8.\n$$\nArranged in increasing order, the updated reconstruction levels are $\\frac{8}{3}$ and $8$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{8}{3} & 8 \\end{pmatrix}}$$", "id": "1637671"}]}