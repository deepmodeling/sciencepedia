{"hands_on_practices": [{"introduction": "This first exercise grounds our understanding in the fundamental definition of squared-error distortion. You will calculate this distortion for a source with a mixed distribution, a common scenario in real-world signals, using a simple quantizer set at the source's true mean. This practice [@problem_id:1659831] directly connects the concept of distortion to statistical variance, providing a solid computational foundation for the more complex optimization problems that follow.", "problem": "A random signal source $X$ has a mixed distribution: with a probability of $1/2$, its value is exactly $0$; with a probability of $1/2$, its value is drawn from a continuous uniform distribution on the interval $[2, 4]$. This source is quantized using a single reconstruction level, $\\hat{x}$, which is set to the true mean of the source $X$. Calculate the average squared-error distortion, defined as $D = E[(X - \\hat{x})^2]$. Express your answer as an exact fraction.", "solution": "Let $X$ be a mixture with $\\Pr(X=0)=\\frac{1}{2}$ and, with probability $\\frac{1}{2}$, $X=U$ where $U \\sim \\text{Uniform}[2,4]$. The reconstruction level is set to the true mean, so $\\hat{x}=E[X]$.\n\nBy the law of total expectation,\n$$\nE[X]=\\frac{1}{2}\\cdot 0+\\frac{1}{2}\\cdot E[U].\n$$\nFor $U \\sim \\text{Uniform}[a,b]$, $E[U]=\\frac{a+b}{2}$. With $a=2$, $b=4$, we have $E[U]=3$, hence\n$$\nE[X]=\\frac{1}{2}\\cdot 3=\\frac{3}{2}.\n$$\n\nThe average squared-error distortion with reconstruction at the mean is the variance:\n$$\nD=E[(X-\\hat{x})^{2}]=E[(X-E[X])^{2}]=\\operatorname{Var}(X)=E[X^{2}]-(E[X])^{2}.\n$$\nCompute $E[X^{2}]$ via the mixture:\n$$\nE[X^{2}]=\\frac{1}{2}\\cdot 0^{2}+\\frac{1}{2}\\cdot E[U^{2}].\n$$\nFor $U \\sim \\text{Uniform}[a,b]$, $E[U^{2}]=\\frac{a^{2}+ab+b^{2}}{3}$. With $a=2$, $b=4$,\n$$\nE[U^{2}]=\\frac{2^{2}+2\\cdot 4+4^{2}}{3}=\\frac{4+8+16}{3}=\\frac{28}{3},\n$$\nso\n$$\nE[X^{2}]=\\frac{1}{2}\\cdot \\frac{28}{3}=\\frac{14}{3}.\n$$\nTherefore,\n$$\nD=\\operatorname{Var}(X)=\\frac{14}{3}-\\left(\\frac{3}{2}\\right)^{2}=\\frac{14}{3}-\\frac{9}{4}=\\frac{56-27}{12}=\\frac{29}{12}.\n$$\nThus the average squared-error distortion is the exact fraction $\\frac{29}{12}$.", "answer": "$$\\boxed{\\frac{29}{12}}$$", "id": "1659831"}, {"introduction": "Having learned to calculate distortion, we now turn to minimizing it. This problem introduces a core principle of quantizer design: finding the optimal reconstruction levels for a given partition of the source alphabet. By working through this example [@problem_id:1659863], you will discover that the ideal representative for any group of source symbols is its conditional mean, or \"centroid\"â€”a powerful insight that is central to designing efficient data compression schemes.", "problem": "A discrete memoryless source $X$ produces symbols from the alphabet $\\mathcal{X} = \\{1, 2, 4, 8\\}$. Each symbol is generated with equal probability. We wish to design a simple data compression scheme using a two-level quantizer. The source alphabet is partitioned into two disjoint sets: $R_1 = \\{1, 2\\}$ and $R_2 = \\{4, 8\\}$. All symbols in $R_1$ are mapped to a single representation level $\\hat{x}_1$, and all symbols in $R_2$ are mapped to a second representation level $\\hat{x}_2$.\n\nThe quality of the quantization is measured by the average squared-error distortion, defined as the expected value of the square of the difference between the source symbol and its representation.\n\nDetermine the optimal representation levels, $\\hat{x}_1^*$ and $\\hat{x}_2^*$, that minimize this average squared-error distortion for the given partitions. Present your answer as the exact values of $\\hat{x}_1^*$ and $\\hat{x}_2^*$ in that order.", "solution": "The problem asks for the optimal representation levels $\\hat{x}_1^*$ and $\\hat{x}_2^*$ that minimize the average squared-error distortion for a given source and partition.\n\nThe source alphabet is $\\mathcal{X} = \\{1, 2, 4, 8\\}$. Since each of the four symbols is generated with equal probability, the probability mass function (PMF) is $p(x) = \\frac{1}{4}$ for each $x \\in \\mathcal{X}$.\n\nThe distortion measure is the squared error, $d(x, \\hat{x}) = (x - \\hat{x})^2$.\n\nThe average distortion, $D$, is the expected value of the distortion, which can be written as a sum over all source symbols:\n$$D = E[d(X, \\hat{X})] = \\sum_{x \\in \\mathcal{X}} p(x) d(x, \\hat{x}(x))$$\nwhere $\\hat{x}(x)$ is the representation level for the source symbol $x$.\n\nThe source alphabet is partitioned into $R_1 = \\{1, 2\\}$ and $R_2 = \\{4, 8\\}$. All symbols in $R_1$ are represented by $\\hat{x}_1$, and all symbols in $R_2$ are represented by $\\hat{x}_2$. We can thus write the average distortion as a function of $\\hat{x}_1$ and $\\hat{x}_2$:\n$$D(\\hat{x}_1, \\hat{x}_2) = \\sum_{x \\in R_1} p(x) (x - \\hat{x}_1)^2 + \\sum_{x \\in R_2} p(x) (x - \\hat{x}_2)^2$$\nThe two terms in the sum are independent. The first term depends only on $\\hat{x}_1$, and the second term depends only on $\\hat{x}_2$. Therefore, we can minimize $D$ by minimizing each term separately.\n\nTo find the optimal representation level $\\hat{x}_1^*$ for the region $R_1$, we minimize the corresponding term by taking its derivative with respect to $\\hat{x}_1$ and setting it to zero:\n$$\\frac{\\partial}{\\partial \\hat{x}_1} \\left[ \\sum_{x \\in R_1} p(x) (x - \\hat{x}_1)^2 \\right] = 0$$\n$$\\sum_{x \\in R_1} p(x) \\cdot 2(x - \\hat{x}_1) \\cdot (-1) = 0$$\n$$-2 \\left( \\sum_{x \\in R_1} x p(x) - \\hat{x}_1 \\sum_{x \\in R_1} p(x) \\right) = 0$$\nSolving for $\\hat{x}_1$, we find the optimal value $\\hat{x}_1^*$:\n$$\\hat{x}_1^* = \\frac{\\sum_{x \\in R_1} x p(x)}{\\sum_{x \\in R_1} p(x)}$$\nThis is the conditional expectation of $X$ given that $X \\in R_1$, also known as the centroid of the region.\n\nNow we can substitute the values for the region $R_1 = \\{1, 2\\}$:\n$$p(1) = \\frac{1}{4}, \\quad p(2) = \\frac{1}{4}$$\n$$\\hat{x}_1^* = \\frac{1 \\cdot p(1) + 2 \\cdot p(2)}{p(1) + p(2)} = \\frac{1 \\cdot \\frac{1}{4} + 2 \\cdot \\frac{1}{4}}{\\frac{1}{4} + \\frac{1}{4}} = \\frac{\\frac{3}{4}}{\\frac{2}{4}} = \\frac{3}{2}$$\n\nSimilarly, for the region $R_2 = \\{4, 8\\}$, the optimal representation level $\\hat{x}_2^*$ is the centroid of $R_2$:\n$$\\hat{x}_2^* = \\frac{\\sum_{x \\in R_2} x p(x)}{\\sum_{x \\in R_2} p(x)}$$\nSubstituting the values for the region $R_2 = \\{4, 8\\}$:\n$$p(4) = \\frac{1}{4}, \\quad p(8) = \\frac{1}{4}$$\n$$\\hat{x}_2^* = \\frac{4 \\cdot p(4) + 8 \\cdot p(8)}{p(4) + p(8)} = \\frac{4 \\cdot \\frac{1}{4} + 8 \\cdot \\frac{1}{4}}{\\frac{1}{4} + \\frac{1}{4}} = \\frac{\\frac{12}{4}}{\\frac{2}{4}} = \\frac{12}{2} = 6$$\n\nThus, the optimal representation levels that minimize the average squared-error distortion are $\\hat{x}_1^* = 3/2$ and $\\hat{x}_2^* = 6$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{2} & 6 \\end{pmatrix}}$$", "id": "1659863"}, {"introduction": "This final practice moves from designing a single quantizer to making strategic decisions in a larger system. You are faced with a classic resource allocation problem: with only one bit available, which of two independent signals should you quantize to achieve the lowest overall system error? This exercise [@problem_id:1659835] demonstrates the practical value of distortion analysis, revealing the important engineering principle that limited resources are most effective when used to reduce the largest uncertainty.", "problem": "A data acquisition system measures two independent physical quantities, which can be modeled as two independent random variables, $X$ and $Y$. Both are normally distributed with a mean of zero. The variance of $X$ is $\\sigma_X^2 = 9$, and the variance of $Y$ is $\\sigma_Y^2 = 1$.\n\nDue to bandwidth limitations, you can only use a single bit to improve the representation of one of these quantities. You have two options:\n1.  Use the bit to create a one-bit quantizer for $X$. In this case, the representation of $Y$, denoted $\\hat{Y}$, will be its expected value.\n2.  Use the bit to create a one-bit quantizer for $Y$. In this case, the representation of $X$, denoted $\\hat{X}$, will be its expected value.\n\nAssume that for whichever variable is quantized, an optimal one-bit quantizer is used. An optimal quantizer is one that minimizes the mean squared-error distortion. The total distortion of the system is the sum of the individual distortions: $D_{total} = E[(X-\\hat{X})^2] + E[(Y-\\hat{Y})^2]$.\n\nWhich of the following strategies results in a lower total mean squared-error distortion?\n\nA. Quantizing $X$ with one bit results in a lower total distortion.\n\nB. Quantizing $Y$ with one bit results in a lower total distortion.\n\nC. Both strategies result in the exact same total distortion.\n\nD. It is not possible to determine which strategy is better without more information about the quantizer design.", "solution": "Let $X \\sim \\mathcal{N}(0,\\sigma_{X}^{2})$ with $\\sigma_{X}^{2}=9$ and $Y \\sim \\mathcal{N}(0,\\sigma_{Y}^{2})$ with $\\sigma_{Y}^{2}=1$, independent. If a variable is not quantized and is represented by its mean, which is zero, its mean squared error equals its variance:\n$$\nE[(V-0)^{2}] = \\operatorname{Var}(V).\n$$\n\nFor the variable that is quantized with one bit using an optimal MSE quantizer, consider first the standard normal case $Z \\sim \\mathcal{N}(0,1)$. By symmetry and the Lloyd-Max optimality conditions, the optimal 1-bit quantizer has a zero threshold and symmetric reconstruction levels $\\pm a$. Define $Q(Z)=a$ if $Z \\geq 0$ and $Q(Z)=-a$ if $Z<0$. The distortion as a function of $a$ is\n$$\nD(a)=E[(Z-Q(Z))^{2}]=E[Z^{2}] - 2a\\,E[Z\\,\\operatorname{sign}(Z)] + a^{2}.\n$$\nSince $Z\\,\\operatorname{sign}(Z)=|Z|$ and $E[Z^{2}]=1$, we have\n$$\nD(a)=1 - 2a\\,E[|Z|] + a^{2}.\n$$\nMinimizing over $a$ gives\n$$\n\\frac{dD}{da}=-2E[|Z|]+2a=0 \\quad \\Rightarrow \\quad a^{\\star}=E[|Z|].\n$$\nTherefore the minimum distortion is\n$$\nD^{\\star}=1-(E[|Z|])^{2}.\n$$\nFor $Z \\sim \\mathcal{N}(0,1)$, using $\\phi(z)=\\frac{1}{\\sqrt{2\\pi}}\\exp(-z^{2}/2)$,\n$$\nE[|Z|]=2\\int_{0}^{\\infty} z \\phi(z)\\,dz=2\\left[-\\phi(z)\\right]_{0}^{\\infty}=2\\phi(0)=\\sqrt{\\frac{2}{\\pi}},\n$$\nso\n$$\nD^{\\star}=1-\\frac{2}{\\pi}.\n$$\n\nBy scale invariance, if $V=\\sigma Z$, applying the scaled optimal 1-bit quantizer yields\n$$\nE[(V-\\hat{V})^{2}]=\\sigma^{2} D^{\\star}=\\sigma^{2}\\left(1-\\frac{2}{\\pi}\\right).\n$$\n\nNow evaluate the two strategies:\n\n1) Quantize $X$, represent $Y$ by its mean:\n$$\nD_{\\text{total},X}=E[(X-\\hat{X})^{2}] + E[(Y-\\hat{Y})^{2}]\n= \\sigma_{X}^{2}\\left(1-\\frac{2}{\\pi}\\right) + \\sigma_{Y}^{2}\n= 9\\left(1-\\frac{2}{\\pi}\\right) + 1.\n$$\n\n2) Quantize $Y$, represent $X$ by its mean:\n$$\nD_{\\text{total},Y}=E[(X-\\hat{X})^{2}] + E[(Y-\\hat{Y})^{2}]\n= \\sigma_{X}^{2} + \\sigma_{Y}^{2}\\left(1-\\frac{2}{\\pi}\\right)\n= 9 + \\left(1-\\frac{2}{\\pi}\\right).\n$$\n\nCompare:\n$$\nD_{\\text{total},X} - D_{\\text{total},Y}\n= \\left[9\\left(1-\\frac{2}{\\pi}\\right)+1\\right] - \\left[9 + \\left(1-\\frac{2}{\\pi}\\right)\\right]\n= -\\frac{16}{\\pi} < 0.\n$$\nHence $D_{\\text{total},X} < D_{\\text{total},Y}$, so quantizing $X$ yields lower total distortion.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1659835"}]}