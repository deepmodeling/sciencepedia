{"hands_on_practices": [{"introduction": "The foundation of constructing any non-binary Huffman code lies in a simple structural rule: the coding tree must be a full $D$-ary tree, where every internal node groups exactly $D$ branches. This exercise [@problem_id:1643132] focuses on the essential first step of the procedure, which is ensuring this condition is met. You will practice applying the formula that determines if, and how many, zero-probability \"dummy\" symbols are required to create a valid tree structure before the encoding process even begins.", "problem": "A data compression algorithm uses a non-binary Huffman coding scheme to represent messages from a source alphabet. In this particular application, the code alphabet is quaternary, meaning it consists of four distinct symbols ($D=4$). The source generates messages from a set of 8 distinct symbols. The construction of a valid $D$-ary Huffman tree requires that the number of source symbols, including any necessary zero-probability \"dummy\" symbols, allows for the creation of a full $D$-ary tree, where every internal node has exactly $D$ children.\n\nGiven this setup, determine the total number of internal nodes in the resulting quaternary Huffman code tree.", "solution": "Let $D=4$ and let $s=8$ be the number of source symbols. In a full $D$-ary Huffman tree, the number of leaves $L$ (which equals the number of source symbols plus any zero-probability dummy symbols) must satisfy the structural constraint that every internal node has exactly $D$ children.\n\nLet $I$ be the number of internal nodes. In any rooted tree, the number of edges is the total number of nodes minus $1$, so\n$$\nE = (I + L) - 1.\n$$\nIn a full $D$-ary tree, each internal node contributes exactly $D$ edges to its children, so\n$$\nE = D I.\n$$\nEquating these gives\n$$\nD I = I + L - 1 \\quad \\Longrightarrow \\quad L = (D - 1) I + 1.\n$$\nThus $L \\equiv 1 \\pmod{D-1}$. For $D=4$, we need $L \\equiv 1 \\pmod{3}$. The smallest $L \\geq s=8$ with this property is found by writing $L = 1 + 3k$ and choosing the smallest integer $k$ such that $1 + 3k \\geq 8$, namely $k=3$, which gives\n$$\nL = 1 + 3 \\cdot 3 = 10.\n$$\nWith $L=10$ and $D=4$, solve for $I$ using $L = (D - 1) I + 1$:\n$$\n10 = 3 I + 1 \\quad \\Longrightarrow \\quad I = \\frac{10 - 1}{3} = 3.\n$$\nTherefore, the total number of internal nodes in the quaternary Huffman code tree is $3$.", "answer": "$$\\boxed{3}$$", "id": "1643132"}, {"introduction": "Once the correct number of symbols (including any necessary dummy symbols) is established, we can proceed with the Huffman algorithm itself. This practice [@problem_id:1643155] provides a direct, hands-on opportunity to execute the ternary ($D=3$) Huffman procedure on a given probability distribution. By iteratively merging the least probable symbols, you will build an optimal code tree and determine the resulting set of codeword lengths, solidifying your understanding of the core mechanics of the algorithm.", "problem": "A discrete memoryless source emits symbols from an alphabet $X = \\{x_1, x_2, x_3, x_4\\}$ with the following probabilities:\n$P(x_1) = 0.50$\n$P(x_2) = 0.20$\n$P(x_3) = 0.15$\n$P(x_4) = 0.15$\n\nA uniquely decodable, variable-length source code is to be constructed for this source using the ternary Huffman algorithm, which groups symbols in sets of three ($D=3$). Determine the set of codeword lengths $\\{l_1, l_2, l_3, l_4\\}$ corresponding to the symbols $\\{x_1, x_2, x_3, x_4\\}$.\n\nWhich of the following represents the set of resulting codeword lengths?\n\nA. $\\{1, 1, 2, 2\\}$\n\nB. $\\{1, 2, 2, 2\\}$\n\nC. $\\{1, 2, 3, 3\\}$\n\nD. $\\{2, 2, 2, 2\\}$", "solution": "We are to construct a ternary Huffman code for a source with probabilities $P(x_1)=0.50$, $P(x_2)=0.20$, $P(x_3)=0.15$, $P(x_4)=0.15$. For a $D$-ary Huffman code with $D=3$, the number of leaves $n$ in the full tree must satisfy $n \\equiv 1 \\pmod{D-1}$, i.e., $n \\equiv 1 \\pmod{2}$. The given $n=4$ is even, so we add one dummy symbol with probability $0$ to obtain $n'=5$, which satisfies $5 \\equiv 1 \\pmod{2}$.\n\nInitialize the multiset of weights as $\\{0.50, 0.20, 0.15, 0.15, 0\\}$. The ternary Huffman step repeatedly combines the three smallest weights into a single node whose weight is their sum, incrementing by $1$ the codeword length of each leaf contained in that combined node at each merge.\n\nStep 1: Combine the three smallest weights $0$, $0.15$, $0.15$ into a node of weight $0.30$. The current set of nodes becomes $\\{0.50, 0.20, 0.30\\}$. The two real symbols with weights $0.15$ (namely $x_3$ and $x_4$) each gain $1$ in length from this merge.\n\nStep 2: With exactly three nodes left, they become the three children of the root. Hence the nodes of weights $0.50$ (symbol $x_1$) and $0.20$ (symbol $x_2$) are assigned depth $1$ (length $1$), while the combined node of weight $0.30$ goes to depth $1$ and its constituent leaves $x_3$ and $x_4$ go to depth $2$ (length $2$).\n\nTherefore the codeword lengths are $l_1=1$, $l_2=1$, $l_3=2$, $l_4=2$, which matches option A. As a quick check, the ternary Kraft inequality holds:\n$$\\sum_{i=1}^{4}3^{-l_{i}}=3^{-1}+3^{-1}+3^{-2}+3^{-2}=\\frac{1}{3}+\\frac{1}{3}+\\frac{1}{9}+\\frac{1}{9}=\\frac{8}{9}\\leq 1.$$\nThus the resulting set of codeword lengths is $\\{1,1,2,2\\}$.", "answer": "$$\\boxed{A}$$", "id": "1643155"}, {"introduction": "While the Huffman algorithm guarantees an optimal code in terms of average length, it does not always produce a unique result. This advanced practice [@problem_id:1643174] explores the important consequences of tie-breaking, where different valid choices during the merging process can lead to distinct, yet equally optimal, code sets. By calculating and comparing the variance of the codeword lengths for two such codes, you will gain a deeper appreciation for the nuances of \"optimality\" and how secondary metrics can differ between equivalent solutions.", "problem": "A data compression scheme is being designed for a simplified robotic arm's set of six primary commands, $\\mathcal{C} = \\{C_1, C_2, C_3, C_4, C_5, C_6\\}$. Based on extensive operational data, the probabilities of these commands are found to be $P(C_1)=0.30$, $P(C_2)=0.20$, $P(C_3)=0.15$, $P(C_4)=0.15$, $P(C_5)=0.10$, and $P(C_6)=0.10$. A ternary ($D=3$) Huffman code is to be used for encoding these commands.\n\nThe D-ary Huffman algorithm proceeds by iteratively merging the $D$ symbols or previously merged nodes with the lowest probabilities. During this process, a tie is encountered when selecting the three lowest-probability items to merge. Two engineers, following the algorithm correctly, make different valid choices at this tie-point. This leads to the generation of two distinct, yet equally optimal, ternary Huffman codes, which we will call Code A and Code B.\n\nThe set of codeword lengths for the six commands in Code A will be different from the set of lengths for Code B. Let $L_A$ and $L_B$ be the random variables representing the codeword lengths for the original six commands under Code A and Code B, respectively. Calculate the absolute difference between the variances of these two length distributions, $\\lvert\\operatorname{Var}(L_A) - \\operatorname{Var}(L_B)\\rvert$.\n\nRound your final answer to three significant figures.", "solution": "We construct a ternary Huffman code for the six commands with probabilities $0.30, 0.20, 0.15, 0.15, 0.10, 0.10$. For a $D$-ary Huffman code with $D=3$, a full tree requires the number of leaves $n$ to satisfy $n \\equiv 1 \\pmod{D-1}$. Here $n=6$ and $D-1=2$, so $6 \\not\\equiv 1 \\pmod{2}$. We therefore add one dummy symbol of probability $0$ so that the augmented set has $7$ items, satisfying $7 \\equiv 1 \\pmod{2}$.\n\nStart with the multiset of probabilities $\\{0, 0.10, 0.10, 0.15, 0.15, 0.20, 0.30\\}$. Merge the three smallest items at each step.\n\nStep 1: Merge $0$, $0.10$, $0.10$ to form a node $N_1$ with probability $0.20$.\n\nThe remaining items are $\\{0.15, 0.15, 0.20, 0.30, 0.20\\}$, where the two $0.20$ entries are $C_2$ and $N_1$. Now we must choose the third item to merge with the two $0.15$ values. A tie occurs between $0.20$ from $C_2$ and $0.20$ from $N_1$, yielding two valid options.\n\nCode A: Merge $0.15, 0.15, 0.20(C_2)$ to form $N_2$ with probability $0.50$. The final three items are $N_1(0.20)$, $C_1(0.30)$, and $N_2(0.50)$, which are merged at the root. Codeword lengths follow from depths:\n- $C_1$ is a child of the root, so $l(C_1)=1$.\n- $N_1$ and $N_2$ are children of the root; their leaves have length $2$. Thus $l(C_2)=l(C_3)=l(C_4)=l(C_5)=l(C_6)=2$.\nTherefore, for $L_A$, the length distribution is\n$$\nP(L_A=1)=0.30,\\quad P(L_A=2)=0.70.\n$$\nCompute mean, second moment, and variance:\n$$\n\\mathbb{E}[L_{A}]=1\\cdot 0.30+2\\cdot 0.70=1.70,\n$$\n$$\n\\mathbb{E}[L_{A}^{2}]=1^{2}\\cdot 0.30+2^{2}\\cdot 0.70=3.10,\n$$\n$$\n\\operatorname{Var}(L_{A})=\\mathbb{E}[L_{A}^{2}]-(\\mathbb{E}[L_{A}])^{2}=3.10-(1.70)^{2}=0.21.\n$$\n\nCode B: Merge $0.15, 0.15, 0.20(N_1)$ to form $N_2'$ with probability $0.50$. The final three items are $C_2(0.20)$, $C_1(0.30)$, and $N_2'(0.50)$, which are merged at the root. Codeword lengths:\n- $C_1$ and $C_2$ are children of the root, so $l(C_1)=l(C_2)=1$.\n- $C_3$ and $C_4$ are children of $N_2'$, so $l(C_3)=l(C_4)=2$.\n- $C_5$ and $C_6$ are children of $N_1$, which is a child of $N_2'$, so $l(C_5)=l(C_6)=3$.\nTherefore, for $L_B$, the length distribution is\n$$\nP(L_{B}=1)=0.30+0.20=0.50,\\quad P(L_{B}=2)=0.15+0.15=0.30,\\quad P(L_{B}=3)=0.10+0.10=0.20.\n$$\nCompute mean, second moment, and variance:\n$$\n\\mathbb{E}[L_{B}]=1\\cdot 0.50+2\\cdot 0.30+3\\cdot 0.20=1.70,\n$$\n$$\n\\mathbb{E}[L_{B}^{2}]=1^{2}\\cdot 0.50+2^{2}\\cdot 0.30+3^{2}\\cdot 0.20=3.50,\n$$\n$$\n\\operatorname{Var}(L_{B})=\\mathbb{E}[L_{B}^{2}]-(\\mathbb{E}[L_{B}])^{2}=3.50-(1.70)^{2}=0.61.\n$$\n\nThe absolute difference between the variances is\n$$\n\\lvert\\operatorname{Var}(L_{A})-\\operatorname{Var}(L_{B})\\rvert = \\lvert 0.21 - 0.61 \\rvert = 0.40,\n$$\nwhich to three significant figures is $0.400$.", "answer": "$$\\boxed{0.400}$$", "id": "1643174"}]}