{"hands_on_practices": [{"introduction": "Perplexity provides an intuitive measure of uncertainty, often interpreted as the \"effective number of choices\" in a random process. We begin our practice with the most straightforward case: a uniform probability distribution, where every possible outcome is equally likely. In this special scenario, the perplexity is exactly equal to the total number of outcomes, providing a solid foundation for our understanding. This exercise [@problem_id:1646104] grounds this principle in a practical security model, where you'll first count the number of valid PINs and see how that count directly translates to the system's perplexity.", "problem": "A security analyst is studying the patterns in 4-digit Personal Identification Numbers (PINs). A PIN is an ordered sequence of four digits, where each digit is an integer from 0 to 9, inclusive. The analyst models a common user behavior wherein individuals avoid repeating a digit immediately after it appears. For example, a PIN like '3435' is considered valid under this model, but '3345' and '3445' are not.\n\nAssuming that every 4-digit PIN that satisfies this non-consecutive-repetition rule is equally likely to be chosen, what is the perplexity of the resulting probability distribution over the set of possible PINs?\n\nProvide the answer as a single integer.", "solution": "A 4-digit PIN is an ordered 4-tuple of digits from the set $\\{0,1,2,\\dots,9\\}$. The non-consecutive-repetition rule requires that for each position $i \\in \\{2,3,4\\}$, the digit at position $i$ must not equal the digit at position $i-1$.\n\nCount the number of valid PINs:\n- For the first digit, there are $10$ choices.\n- For each subsequent digit, there are $9$ choices (any digit except the immediately preceding one).\nThus, the total number of valid PINs is\n$$\nN = 10 \\times 9^{3}.\n$$\nCompute this explicitly:\n$$\nN = 10 \\times 729 = 7290.\n$$\n\nPerplexity of a distribution with entropy $H$ (in bits) is defined as $2^{H}$. For the uniform distribution over $N$ outcomes,\n$$\nH = \\log_{2}(N) \\quad \\Rightarrow \\quad \\text{perplexity} = 2^{H} = 2^{\\log_{2}(N)} = N.\n$$\nTherefore, the perplexity equals the number of valid PINs, which is $7290$.", "answer": "$$\\boxed{7290}$$", "id": "1646104"}, {"introduction": "Real-world events are rarely uniformly distributed; some outcomes are more probable than others. This practice [@problem_id:1646124] extends our understanding to these non-uniform cases, where perplexity quantifies the \"effective\" number of choices, a value that is no longer a simple count of outcomes but a weighted average of uncertainty. By analyzing a hypothetical character-level predictive model, you will learn how to calculate perplexity from a set of observed frequencies, which is a fundamental skill in evaluating the performance and uncertainty of statistical models.", "problem": "A computer scientist is analyzing a simplified character-level predictive model. This model's purpose is to predict the next character in a sequence based on statistical data from a training corpus. After observing a specific sequence of characters, the model consults its training data and finds the following frequencies for the characters that have previously appeared in this context:\n- The character 'a' appeared 125 times.\n- The character 'e' appeared 125 times.\n- The character 'i' appeared 60 times.\n- The character 'o' appeared 60 times.\n- The character 'u' appeared 30 times.\n\nThe model defines the probability of the next character being a specific character as being directly proportional to its observed frequency. Any character not in the list above has a zero probability of appearing. Based on this probability distribution, calculate the perplexity of the model's prediction.\n\nUse the natural logarithm for any logarithmic calculations. Express your final answer as a numerical value rounded to three significant figures.", "solution": "The model assigns probabilities proportional to observed frequencies. Let the counts be $f_{a}=125$, $f_{e}=125$, $f_{i}=60$, $f_{o}=60$, $f_{u}=30$. The total count is\n$$\nF=\\sum f=125+125+60+60+30=400.\n$$\nThus the probabilities are\n$$\np(a)=\\frac{125}{400}=\\frac{5}{16},\\quad p(e)=\\frac{5}{16},\\quad p(i)=\\frac{60}{400}=\\frac{3}{20},\\quad p(o)=\\frac{3}{20},\\quad p(u)=\\frac{30}{400}=\\frac{3}{40}.\n$$\nPerplexity for a single-step prediction distribution using the natural logarithm is defined as\n$$\n\\mathrm{PPL}=\\exp\\!\\left(H\\right),\\quad H=-\\sum_{x}p(x)\\ln p(x).\n$$\nCompute the entropy:\n$$\nH=-\\Bigg[2\\cdot\\frac{5}{16}\\ln\\!\\left(\\frac{5}{16}\\right)+2\\cdot\\frac{3}{20}\\ln\\!\\left(\\frac{3}{20}\\right)+\\frac{3}{40}\\ln\\!\\left(\\frac{3}{40}\\right)\\Bigg].\n$$\nEvaluating the logarithms and products numerically (using $\\ln$):\n$$\nH\\approx -\\Big[2\\cdot 0.3125\\cdot(-1.1631508098)+2\\cdot 0.15\\cdot(-1.8971199849)+0.075\\cdot(-2.5902671654)\\Big]\\approx 1.4903752890.\n$$\nHence the perplexity is\n$$\n\\mathrm{PPL}=\\exp(H)\\approx \\exp(1.4903752890)\\approx 4.4387610695.\n$$\nRounded to three significant figures, the perplexity is $4.44$.", "answer": "$$\\boxed{4.44}$$", "id": "1646124"}, {"introduction": "Beyond simply calculating perplexity for a given distribution, we can use it as a guiding principle for building models from limited information. This advanced practice [@problem_id:1646139] explores the concept of finding a probability distribution that is minimally complex—or has the lowest perplexity—while still satisfying known constraints. You will be challenged to determine the \"least-biased\" distribution for a data stream with a fixed average value, a task that introduces the powerful principle of maximum entropy (or minimum perplexity) used in fields from statistical physics to machine learning.", "problem": "A data stream produces integer values from the set $S = \\{1, 2, 3\\}$. The long-term average value of the stream is known to be a constant, $\\mu$. We can model this stream as a discrete random variable $X$ with outcomes in $S$ and an unknown probability distribution $P = (p_1, p_2, p_3)$, where $p_i = \\text{Prob}(X=i)$. The uncertainty of this model is quantified by its perplexity, defined as $PP(X) = 2^{H(X)}$, where $H(X)$ is the Shannon entropy of the distribution $P$ calculated in bits (i.e., using the base-2 logarithm).\n\nGiven that the mean value of the outcomes is fixed at $\\mu = 2.5$, determine the probability distribution $(p_1, p_2, p_3)$ that minimizes the perplexity of the stream. Express the probabilities $p_1, p_2$, and $p_3$ as exact fractions or terminating decimals.", "solution": "We seek to minimize the perplexity $PP(X) = 2^{H(X)}$ subject to the constraints of a probability distribution on $S=\\{1,2,3\\}$ with fixed mean $\\mu=2.5$. Since $2^{x}$ is strictly increasing, minimizing $PP(X)$ is equivalent to minimizing the Shannon entropy\n$$\nH(X) = -\\sum_{i=1}^{3} p_{i} \\log_{2}(p_{i})\n$$\nsubject to $p_{i} \\geq 0$, $\\sum_{i=1}^{3} p_{i} = 1$, and the mean constraint\n$$\n1 \\cdot p_{1} + 2 \\cdot p_{2} + 3 \\cdot p_{3} = 2.5.\n$$\n\nUsing $p_{1} = 1 - p_{2} - p_{3}$ in the mean constraint gives\n$$\n1 + p_{2} + 2 p_{3} = 2.5 \\quad \\Longrightarrow \\quad p_{2} + 2 p_{3} = 1.5.\n$$\nThus\n$$\np_{2} = 1.5 - 2 p_{3}, \\quad p_{1} = 1 - p_{2} - p_{3} = -0.5 + p_{3}.\n$$\nNonnegativity requires $p_{2} \\geq 0 \\Rightarrow p_{3} \\leq \\frac{3}{4}$ and $p_{1} \\geq 0 \\Rightarrow p_{3} \\geq \\frac{1}{2}$. Therefore the feasible set is the line segment\n$$\np_{3} \\in \\left[\\frac{1}{2}, \\frac{3}{4}\\right], \\quad p_{2} = 1.5 - 2 p_{3}, \\quad p_{1} = -0.5 + p_{3}.\n$$\n\nThe Shannon entropy is a concave function of $(p_{1},p_{2},p_{3})$, so its minimum over this convex feasible set occurs at an extreme point. The endpoints are:\n- At $p_{3} = \\frac{1}{2}$: $(p_{1},p_{2},p_{3}) = \\left(0, \\frac{1}{2}, \\frac{1}{2}\\right)$.\n- At $p_{3} = \\frac{3}{4}$: $(p_{1},p_{2},p_{3}) = \\left(\\frac{1}{4}, 0, \\frac{3}{4}\\right)$.\n\nCompute the entropies at these endpoints (with the convention $0 \\log_{2} 0 = 0$ by continuity):\n$$\nH\\left(0, \\frac{1}{2}, \\frac{1}{2}\\right) = -\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right) - \\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right) = 1,\n$$\n$$\nH\\left(\\frac{1}{4}, 0, \\frac{3}{4}\\right) = -\\frac{1}{4}\\log_{2}\\!\\left(\\frac{1}{4}\\right) - \\frac{3}{4}\\log_{2}\\!\\left(\\frac{3}{4}\\right)\n= \\frac{1}{2} - \\frac{3}{4}\\left(\\log_{2} 3 - 2\\right) = 2 - \\frac{3}{4}\\log_{2} 3.\n$$\nTo compare, note that $3^{3} = 27 \\gt 16 = 2^{4}$ implies $\\log_{2} 3 \\gt \\frac{4}{3}$, hence\n$$\n2 - \\frac{3}{4}\\log_{2} 3 \\lt 2 - \\frac{3}{4}\\cdot \\frac{4}{3} = 1.\n$$\nTherefore $H\\left(\\frac{1}{4}, 0, \\frac{3}{4}\\right) \\lt H\\left(0, \\frac{1}{2}, \\frac{1}{2}\\right)$, so the entropy (and thus the perplexity) is minimized at $(p_{1},p_{2},p_{3}) = \\left(\\frac{1}{4}, 0, \\frac{3}{4}\\right)$.\n\nThus, the distribution minimizing perplexity under the mean constraint $\\mu=2.5$ is $p_{1} = \\frac{1}{4}$, $p_{2} = 0$, $p_{3} = \\frac{3}{4}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{4} & 0 & \\frac{3}{4}\\end{pmatrix}}$$", "id": "1646139"}]}