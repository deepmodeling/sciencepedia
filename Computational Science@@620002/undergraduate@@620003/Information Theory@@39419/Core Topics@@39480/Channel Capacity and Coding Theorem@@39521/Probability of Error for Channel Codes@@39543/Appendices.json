{"hands_on_practices": [{"introduction": "Understanding the performance of a channel code begins with mastering the probability of error events. This first practice exercise [@problem_id:1648496] provides a foundational challenge using a simple repetition code over a Binary Symmetric Channel ($BSC$). By calculating the probability of exactly two errors in a four-bit codeword, you will directly apply the binomial distribution, a cornerstone of analyzing random, independent events. This practice is crucial for building intuition about how errors accumulate and highlights a critical design consideration: the ambiguity that arises when a decoder cannot make a clear majority-rule decision.", "problem": "A simple communication system employs a 4-repetition code to enhance reliability. To send a '0', the codeword '0000' is transmitted, and to send a '1', the codeword '1111' is transmitted. The transmission occurs over a Binary Symmetric Channel (BSC), a memoryless channel where each bit is independently flipped with a constant probability $p$. Assuming a single codeword corresponding to one bit of information is transmitted, determine the probability that exactly two of the four bits in the codeword are received incorrectly. Express your answer as a symbolic expression in terms of $p$.", "solution": "Let the length of the repetition code be $n=4$. The channel is a Binary Symmetric Channel (BSC), which means that each of the $n$ bits in the transmitted codeword is handled independently. For each bit, there are two possible outcomes: it is received correctly, or it is received incorrectly (flipped).\n\nThe problem states that the probability of a single bit being flipped (an error) is $p$. Therefore, the probability of a single bit being transmitted correctly is $1-p$.\n\nWe are interested in the event where exactly two out of the four transmitted bits are incorrect. This is a classic example of a sequence of independent Bernoulli trials. Let a \"success\" be the event that a bit is received in error. We are looking for the probability of obtaining exactly $k=2$ successes in $n=4$ trials.\n\nThe probability of such an event is given by the binomial probability mass function:\n$$P(X=k) = \\binom{n}{k} p^{k} (1-p)^{n-k}$$\nwhere $X$ is the random variable representing the number of errors.\n\nIn our specific case, we have:\n- The number of trials (bits in the codeword), $n=4$.\n- The number of desired successes (errors), $k=2$.\n- The probability of success (a single bit error), $p$.\n- The probability of failure (a single bit transmitted correctly), $1-p$.\n\nSubstituting these values into the binomial formula, we get:\n$$P(X=2) = \\binom{4}{2} p^{2} (1-p)^{4-2}$$\n$$P(X=2) = \\binom{4}{2} p^{2} (1-p)^{2}$$\n\nNow, we need to calculate the binomial coefficient $\\binom{4}{2}$:\n$$\\binom{4}{2} = \\frac{4!}{2!(4-2)!} = \\frac{4!}{2!2!} = \\frac{4 \\times 3 \\times 2 \\times 1}{(2 \\times 1)(2 \\times 1)} = \\frac{24}{4} = 6$$\n\nThis coefficient represents the number of ways to choose which 2 of the 4 bits are in error. For example, the errors could be in positions (1,2), (1,3), (1,4), (2,3), (2,4), or (3,4).\n\nSubstituting the value of the binomial coefficient back into our probability expression, we obtain the final answer:\n$$P(X=2) = 6 p^{2} (1-p)^{2}$$", "answer": "$$\\boxed{6p^{2}(1-p)^{2}}$$", "id": "1648496"}, {"introduction": "A channel code is only as good as its decoding algorithm. This exercise [@problem_id:1648505] moves from calculating component probabilities to analyzing the overall error probability, $P_e$, of a complete, albeit simple, communication system. You will investigate a scenario where the decoder resorts to a random guess when faced with ambiguity, a hypothetical but pedagogically insightful situation. This practice will sharpen your skills in applying the law of total probability and will reveal the critical interplay between encoding and decoding in determining a system's reliability.", "problem": "A digital communication system is designed to transmit a single bit from a source. The source generates bits '0' and '1' with equal probability. To improve reliability, a simple (2,1) repetition code is employed. In this scheme, a source bit '0' is encoded into the codeword '00', and a source bit '1' is encoded into the codeword '11'.\n\nThe two-bit codeword is transmitted over a Binary Symmetric Channel (BSC). A BSC is a channel model where each transmitted bit is independently flipped (i.e., a '0' becomes a '1' or a '1' becomes a '0') with a fixed crossover probability $p$, where $0 < p < 1$.\n\nAt the receiver, a decoder interprets the received two-bit word. The decoding logic is defined as follows:\n- If '00' is received, it is decoded as the source bit '0'.\n- If '11' is received, it is decoded as the source bit '1'.\n- If either '01' or '10' is received, the situation is ambiguous. The decoder resolves this ambiguity by making a random decision: it electronically simulates the flip of a fair coin. If the outcome is 'heads', the word is decoded as '0'; if the outcome is 'tails', it is decoded as '1'.\n\nYour task is to calculate the overall probability of a word error, $P_e$. A word error is defined as the event where the decoded bit is not the same as the original source bit. Express your answer as a function of the crossover probability $p$.", "solution": "Let $X$ be the random variable representing the source bit, and let $\\hat{X}$ be the random variable representing the decoded bit. The problem asks for the overall probability of error, $P_e = P(\\hat{X} \\neq X)$.\n\nWe can compute this using the law of total probability, by conditioning on the value of the source bit $X$.\n$$P_e = P(\\hat{X} \\neq X | X=0)P(X=0) + P(\\hat{X} \\neq X | X=1)P(X=1)$$\nThe problem states that the source bits are equally likely, so $P(X=0) = P(X=1) = \\frac{1}{2}$. The expression for the error probability becomes:\n$$P_e = \\frac{1}{2} P(\\hat{X} = 1 | X=0) + \\frac{1}{2} P(\\hat{X} = 0 | X=1)$$\nWe will now calculate the two conditional probabilities separately.\n\n**Part 1: Calculate $P(\\hat{X} = 1 | X=0)$**\n\nIf the source bit is $X=0$, the transmitted codeword is '00'. Let the received two-bit word be $Y_1Y_2$. Each bit is flipped independently by the BSC with probability $p$. An error occurs in this case if the decoded bit is $\\hat{X}=1$. Let's analyze the outcomes at the receiver.\n\nThe probabilities of receiving each possible two-bit word are:\n- $P(Y_1Y_2 = 00 | \\text{sent 00}) = (1-p)(1-p) = (1-p)^2$. If '00' is received, it is decoded as '0'. This is not an error.\n- $P(Y_1Y_2 = 11 | \\text{sent 00}) = p \\cdot p = p^2$. If '11' is received, it is decoded as '1'. This is an error.\n- $P(Y_1Y_2 = 01 | \\text{sent 00}) = (1-p)p$.\n- $P(Y_1Y_2 = 10 | \\text{sent 00}) = p(1-p)$.\n\nIf either '01' or '10' is received, the decoder flips a fair coin. An error ($\\hat{X}=1$) occurs if the coin flip results in 'tails'. The probability of 'tails' is $\\frac{1}{2}$.\nThe probability of receiving an ambiguous word ('01' or '10') is $p(1-p) + (1-p)p = 2p(1-p)$.\nThe probability of an error occurring through this path is the probability of receiving an ambiguous word multiplied by the probability that the coin flip leads to an error:\n$P(\\text{error and ambiguous word}) = P(\\text{receive '01' or '10'}) \\times P(\\text{decode '1'}) = [2p(1-p)] \\times \\frac{1}{2} = p(1-p)$.\n\nThe total probability of error, given $X=0$, is the sum of probabilities of all disjoint error events:\n$$P(\\hat{X} = 1 | X=0) = P(\\text{receive '11'}) + P(\\text{error and ambiguous word})$$\n$$P(\\hat{X} = 1 | X=0) = p^2 + p(1-p) = p^2 + p - p^2 = p$$\n\n**Part 2: Calculate $P(\\hat{X} = 0 | X=1)$**\n\nIf the source bit is $X=1$, the transmitted codeword is '11'. An error occurs if the decoded bit is $\\hat{X}=0$. The logic is symmetric to Part 1.\n\nThe probabilities of receiving each possible two-bit word are:\n- $P(Y_1Y_2 = 11 | \\text{sent 11}) = (1-p)^2$. If '11' is received, it is decoded as '1'. This is not an error.\n- $P(Y_1Y_2 = 00 | \\text{sent 11}) = p^2$. If '00' is received, it is decoded as '0'. This is an error.\n- $P(Y_1Y_2 = 01 \\text{ or } 10 | \\text{sent 11}) = p(1-p) + (1-p)p = 2p(1-p)$.\n\nIf '01' or '10' is received, the decoder flips a fair coin. An error ($\\hat{X}=0$) occurs if the coin flip results in 'heads'. The probability of 'heads' is $\\frac{1}{2}$.\nThe probability of an error occurring through this path is:\n$P(\\text{error and ambiguous word}) = P(\\text{receive '01' or '10'}) \\times P(\\text{decode '0'}) = [2p(1-p)] \\times \\frac{1}{2} = p(1-p)$.\n\nThe total probability of error, given $X=1$, is the sum of probabilities of all disjoint error events:\n$$P(\\hat{X} = 0 | X=1) = P(\\text{receive '00'}) + P(\\text{error and ambiguous word})$$\n$$P(\\hat{X} = 0 | X=1) = p^2 + p(1-p) = p^2 + p - p^2 = p$$\n\n**Part 3: Combine to find the overall error probability $P_e$**\n\nNow we substitute the conditional probabilities back into our main formula:\n$$P_e = \\frac{1}{2} P(\\hat{X} = 1 | X=0) + \\frac{1}{2} P(\\hat{X} = 0 | X=1)$$\n$$P_e = \\frac{1}{2}(p) + \\frac{1}{2}(p) = p$$\n\nThe overall probability of a word error is simply $p$. This result indicates that this specific coding and decoding scheme provides no improvement over uncoded transmission through the same channel.", "answer": "$$\\boxed{p}$$", "id": "1648505"}, {"introduction": "Not all noisy channels are created equal; the type of error a channel introduces is a critical factor in code design. This practice [@problem_id:1648516] shifts our focus from the Binary Symmetric Channel ($BSC$), where bits are flipped, to the Binary Erasure Channel ($BEC$), where bits are lost. You will determine the error probability for a repetition code in this new environment, where the decoder knows the location of the errors (erasures). This problem highlights how a change in the channel model can dramatically alter the performance of a code and the nature of the decoding task itself.", "problem": "A simple communication system is designed to transmit a single bit, either a 0 or a 1, across a noisy channel. To improve reliability, a (5,1) repetition code is used. This means that if the original bit is a 0, the codeword '00000' is transmitted, and if the original bit is a 1, the codeword '11111' is transmitted.\n\nThe transmission occurs over a Binary Erasure Channel (BEC). For each bit sent through the BEC, there are two possible outcomes:\n1.  The bit is correctly received with probability $1-\\epsilon$.\n2.  The bit is erased with probability $\\epsilon$, where $0 < \\epsilon < 1$. An erased bit is received as an unknown symbol, and the decoder knows that an erasure has occurred. The channel never flips a bit (e.g., a '0' is never received as a '1').\n\nThe decoder at the receiving end uses a majority-logic rule on the non-erased bits. If at least one bit of the 5-bit codeword is received correctly (i.e., not erased), the decoder can determine the original bit. A word error occurs if the decoder cannot uniquely determine the original bit from the received 5-symbol word.\n\nAssuming the outcomes for the five bits in a codeword are independent events, determine the probability of a word error. Express your answer as a closed-form analytic expression in terms of the erasure probability $\\epsilon$.", "solution": "Let each transmitted bit pass through a Binary Erasure Channel with erasure probability $\\epsilon$, independently across the $5$ positions of the $(5,1)$ repetition code.\n\nBecause the BEC never flips bits, any received (non-erased) bit must equal the transmitted bit. Therefore, under a majority-logic rule on the non-erased bits, the decoder can correctly determine the original bit as soon as at least one of the five bits is received (i.e., not erased). Hence, a word error occurs if and only if all five transmitted bits are erased.\n\nDefine $E_{i}$ as the event that the $i$-th bit is erased, with $\\Pr(E_{i})=\\epsilon$, and assume independence across $i=1,\\dots,5$. The word error event is\n$$\nW=\\bigcap_{i=1}^{5} E_{i}.\n$$\nBy independence,\n$$\n\\Pr(W)=\\prod_{i=1}^{5} \\Pr(E_{i})=\\epsilon^{5}.\n$$\nEquivalently, if $K$ is the number of erasures, then $K\\sim\\text{Binomial}(5,\\epsilon)$ and\n$$\n\\Pr(\\text{word error})=\\Pr(K=5)=\\binom{5}{5}\\epsilon^{5}(1-\\epsilon)^{0}=\\epsilon^{5}.\n$$\nThus, the probability of a word error is $\\epsilon^{5}$.", "answer": "$$\\boxed{\\epsilon^{5}}$$", "id": "1648516"}]}