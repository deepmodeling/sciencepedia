{"hands_on_practices": [{"introduction": "Before we can interpret a received signal, we must first understand its statistical properties. This initial practice explores the \"forward problem\" in communications: predicting the probability of receiving a certain symbol. By working through this hypothetical scenario [@problem_id:1604828], you will apply the law of total probability to combine the source's prior probabilities with the channel's noise characteristics, a fundamental first step in analyzing any communication system.", "problem": "A remote weather monitoring station on planet Kepler-186f sends back telemetry about cloud cover. The station's logic is simple: it sends a binary `0` if the sky is predominantly clear, and a binary `1` if the sky is predominantly overcast. Based on long-term atmospheric models, the probability of a clear sky is five times greater than the probability of an overcast sky on any given day.\n\nThe signal from the station is transmitted through the planet's ionosphere, which acts as a noisy communication channel. This channel can be modeled as a Binary Symmetric Channel (BSC), where a transmitted bit is flipped (a `0` becomes a `1` or a `1` becomes a `0`) with a certain crossover probability. For this specific transmission, the crossover probability is $p = 0.2$.\n\nAn engineer at the receiving ground station observes a single bit. What is the total probability that the bit they observe is a `0`?\n\nProvide your answer as a decimal rounded to two significant figures.", "solution": "Let $X \\in \\{0,1\\}$ be the transmitted bit, where $X=0$ denotes clear sky and $X=1$ denotes overcast. Let $Y \\in \\{0,1\\}$ be the received bit through a Binary Symmetric Channel (BSC) with crossover probability $p$.\n\nFrom the statement, the prior probabilities satisfy $P(X=0)=5\\,P(X=1)$. Using normalization,\n$$\nP(X=0)+P(X=1)=1 \\quad \\Rightarrow \\quad 5P(X=1)+P(X=1)=1 \\quad \\Rightarrow \\quad 6P(X=1)=1,\n$$\nso\n$$\nP(X=1)=\\frac{1}{6}, \\qquad P(X=0)=\\frac{5}{6}.\n$$\n\nFor a BSC with crossover probability $p$,\n$$\nP(Y=0 \\mid X=0)=1-p, \\qquad P(Y=0 \\mid X=1)=p.\n$$\nBy the law of total probability,\n$$\nP(Y=0)=P(Y=0 \\mid X=0)P(X=0)+P(Y=0 \\mid X=1)P(X=1)\n=(1-p)\\frac{5}{6}+p\\frac{1}{6}\n=\\frac{5}{6}-\\frac{4}{6}p\n=\\frac{5}{6}-\\frac{2}{3}p.\n$$\n\nSubstitute $p=0.2$:\n$$\nP(Y=0)=\\frac{5}{6}-\\frac{2}{3}\\cdot 0.2=\\frac{5}{6}-\\frac{2}{15}=\\frac{7}{10}=0.70.\n$$\nRounded to two significant figures, this is $0.70$.", "answer": "$$\\boxed{0.70}$$", "id": "1604828"}, {"introduction": "A crucial task in communications is to infer the original input from a noisy output. This is often called the \"inverse problem,\" and it lies at the heart of signal decoding. This exercise [@problem_id:1604870] introduces you to Bayesian inference, a powerful tool for this task, allowing you to calculate the posterior probability $P(X|Y)$. Mastering this technique enables you to quantify your certainty about the transmitted signal after observing the received data.", "problem": "A simple remote environmental sensor is deployed to monitor rainfall. The sensor transmits a binary signal to a base station: a '0' if there is no rain, and a '1' if there is rain. Historical data indicates that the probability of no rain, and thus the transmission of a '0', is $0.8$. The communication channel between the sensor and the base station is modeled as a Binary Symmetric Channel (BSC), which is a classic model for a noisy channel. This channel has a crossover probability of $p=0.1$. The crossover probability is the probability that a transmitted bit is received incorrectly (i.e., a '0' is received as a '1', or a '1' is received as a '0').\n\nOne day, the base station receives a '1'. Given this observation, what is the probability that the sensor actually transmitted a '0' (meaning it was not raining, but the signal was corrupted)? Calculate your answer as a decimal rounded to three significant figures.", "solution": "Let $X$ be the random variable representing the transmitted bit, and $Y$ be the random variable representing the received bit.\nThe problem defines the following events:\n- $X=0$: The sensor transmits a '0' (no rain).\n- $X=1$: The sensor transmits a '1' (rain).\n- $Y=0$: The base station receives a '0'.\n- $Y=1$: The base station receives a '1'.\n\nFrom the problem statement, we are given the a priori probabilities of the source:\nThe probability of transmitting a '0' is $P(X=0) = 0.8$.\nSince there are only two possible events for the source, the probability of transmitting a '1' is $P(X=1) = 1 - P(X=0) = 1 - 0.8 = 0.2$.\n\nThe channel is a Binary Symmetric Channel (BSC) with a crossover probability $p = 0.1$. This gives us the following conditional probabilities, which define the channel's behavior:\n- The probability of a bit flip from '0' to '1': $P(Y=1 | X=0) = p = 0.1$.\n- The probability of a bit flip from '1' to '0': $P(Y=0 | X=1) = p = 0.1$.\n- The probability of correct transmission of a '0': $P(Y=0 | X=0) = 1 - p = 1 - 0.1 = 0.9$.\n- The probability of correct transmission of a '1': $P(Y=1 | X=1) = 1 - p = 1 - 0.1 = 0.9$.\n\nWe are asked to find the probability that a '0' was transmitted, given that a '1' was received. This is the posterior probability $P(X=0 | Y=1)$. We can calculate this using Bayes' theorem:\n$$ P(X=0 | Y=1) = \\frac{P(Y=1 | X=0) P(X=0)}{P(Y=1)} $$\n\nTo apply this theorem, we first need to calculate the total probability of receiving a '1', which is $P(Y=1)$. We can find this using the law of total probability, summing over all possible transmitted bits:\n$$ P(Y=1) = P(Y=1 | X=0)P(X=0) + P(Y=1 | X=1)P(X=1) $$\n\nNow, we substitute the known values into this equation:\n$$ P(Y=1) = (0.1)(0.8) + (0.9)(0.2) $$\n$$ P(Y=1) = 0.08 + 0.18 $$\n$$ P(Y=1) = 0.26 $$\n\nNow that we have $P(Y=1)$, we can substitute it back into the Bayes' theorem expression for $P(X=0 | Y=1)$:\n$$ P(X=0 | Y=1) = \\frac{P(Y=1 | X=0) P(X=0)}{P(Y=1)} $$\n$$ P(X=0 | Y=1) = \\frac{(0.1)(0.8)}{0.26} $$\n$$ P(X=0 | Y=1) = \\frac{0.08}{0.26} $$\n\nTo get the numerical value, we perform the division:\n$$ P(X=0 | Y=1) = \\frac{8}{26} = \\frac{4}{13} \\approx 0.3076923... $$\n\nThe problem requires the answer to be rounded to three significant figures. The first three significant figures are 3, 0, and 7. The fourth significant figure is 6, which is 5 or greater, so we round up the third significant figure.\n$$ P(X=0 | Y=1) \\approx 0.308 $$", "answer": "$$\\boxed{0.308}$$", "id": "1604870"}, {"introduction": "How do we compare the \"usefulness\" of different communication channels, especially when their error characteristics seem counterintuitive? This final practice moves beyond single-bit analysis to the concept of channel capacity, $C$, which defines the ultimate speed limit for reliable communication. By comparing two channels [@problem_id:1604876], you will uncover a profound insight from information theory: a channel that flips bits very predictably (e.g., with probability $p=0.9$) can be nearly as useful as one that rarely makes errors, as both provide a high degree of certainty about the input.", "problem": "An engineer is tasked with selecting one of two available noisy digital communication channels, Channel A and Channel B, for a critical data transmission system. Both channels can be modeled as a Binary Symmetric Channel (BSC), a memoryless channel that transmits one binary digit (0 or 1) at a time and has a certain probability of incorrectly flipping the bit. For a BSC, the crossover probability, denoted by $p$, is the probability that a sent '0' is received as a '1' or a sent '1' is received as a '0'.\n\nThe characterizations for the two channels are as follows:\n- Channel A has a crossover probability of $p_A = 0.2$.\n- Channel B has a crossover probability of $p_B = 0.9$.\n\nThe primary measure of a channel's \"usefulness\" for communication is its capacity, $C$, which represents the maximum rate of information (in bits per channel use) that can be transmitted with an arbitrarily low probability of error. For a BSC with crossover probability $p$, the capacity is given by the formula:\n$C(p) = 1 - H_2(p)$\nwhere $H_2(p)$ is the binary entropy function, defined as:\n$H_2(p) = -p \\log_2(p) - (1-p) \\log_2(1-p)$\n\nTo make a quantitative comparison, calculate the ratio of the capacity of Channel B to the capacity of Channel A. That is, compute the value of $\\frac{C(p_B)}{C(p_A)}$. Round your final answer to three significant figures.", "solution": "We use the BSC capacity formula $C(p)=1-H_{2}(p)$ with $H_{2}(p)=-p\\log_{2}(p)-(1-p)\\log_{2}(1-p)$. For $p_{A}=0.2$,\n$$\nH_{2}(0.2)=-0.2\\log_{2}(0.2)-0.8\\log_{2}(0.8).\n$$\nUsing $\\log_{2}(0.2)=-2.321928094887362$ and $\\log_{2}(0.8)=-0.3219280948873623$,\n$$\nH_{2}(0.2)\\approx -0.2(-2.321928094887362)-0.8(-0.3219280948873623)=0.4643856189774724+0.25754247590988984=0.7219280948873623,\n$$\nso\n$$\nC(p_{A})=1-H_{2}(0.2)\\approx 1-0.7219280948873623=0.2780719051126377.\n$$\nFor $p_{B}=0.9$,\n$$\nH_{2}(0.9)=-0.9\\log_{2}(0.9)-0.1\\log_{2}(0.1).\n$$\nUsing $\\log_{2}(0.9)=-0.15200309344504997$ and $\\log_{2}(0.1)=-3.321928094887362$,\n$$\nH_{2}(0.9)\\approx -0.9(-0.15200309344504997)-0.1(-3.321928094887362)=0.136802784100545+0.3321928094887362=0.4689955935892812,\n$$\nso\n$$\nC(p_{B})=1-H_{2}(0.9)\\approx 1-0.4689955935892812=0.5310044064107188.\n$$\nTherefore, the ratio is\n$$\n\\frac{C(p_{B})}{C(p_{A})}\\approx \\frac{0.5310044064107188}{0.2780719051126377}\\approx 1.909593874\\approx 1.91 \\text{ (to three significant figures)}.\n$$", "answer": "$$\\boxed{1.91}$$", "id": "1604876"}]}