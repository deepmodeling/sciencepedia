{"hands_on_practices": [{"introduction": "The most fundamental skill in analyzing a communication channel is to predict the output distribution for a given input distribution. This exercise provides a concrete scenario involving a volatile memory bit to practice this core calculation. By applying the law of total probability, you will see how a channel's inherent error characteristics transform different input signals, a crucial first step in understanding any communication system [@problem_id:1632599].", "problem": "A simplified model for a volatile digital memory bit considers its state to be either 0 or 1. Let the true state of the bit be a random variable $X \\in \\{0, 1\\}$, and the measured state of the bit be a random variable $Y \\in \\{0, 1\\}$. Due to thermal noise, the measurement process is imperfect. The probability of measuring a 1 when the true state is 0 is 0.1. The probability of measuring a 0 when the true state is 1 is 0.3.\n\nTwo different algorithms are run on the hardware that uses this memory bit.\n- Algorithm A stores data such that the prior probability distribution for the bit's true state is $P_A(X=0) = 0.2$ and $P_A(X=1) = 0.8$.\n- Algorithm B stores data such that the prior probability distribution for the bit's true state is $P_B(X=0) = 0.8$ and $P_B(X=1) = 0.2$.\n\nLet the resulting output probability distributions for the measured state be $P_A(Y)$ and $P_B(Y)$, respectively. These distributions are represented as pairs $(P(Y=0), P(Y=1))$. Which of the following options correctly gives the pair of output distributions $(P_A(Y), P_B(Y))$?\n\nA. $(P_A(Y), P_B(Y)) = ((0.42, 0.58), (0.78, 0.22))$\n\nB. $(P_A(Y), P_B(Y)) = ((0.78, 0.22), (0.42, 0.58))$\n\nC. $(P_A(Y), P_B(Y)) = ((0.74, 0.26), (0.86, 0.14))$\n\nD. $(P_A(Y), P_B(Y)) = ((0.58, 0.42), (0.22, 0.78))$", "solution": "We model the measurement noise with the conditional probabilities: $P(Y=1 \\mid X=0)=0.1$ and $P(Y=0 \\mid X=1)=0.3$. By complementarity, $P(Y=0 \\mid X=0)=1-0.1=0.9$ and $P(Y=1 \\mid X=1)=1-0.3=0.7$.\n\nUsing the law of total probability, for any prior on $X$,\n$$\nP(Y=0)=P(Y=0 \\mid X=0)P(X=0)+P(Y=0 \\mid X=1)P(X=1),\n$$\n$$\nP(Y=1)=P(Y=1 \\mid X=0)P(X=0)+P(Y=1 \\mid X=1)P(X=1)=1-P(Y=0).\n$$\n\nAlgorithm A has $P_{A}(X=0)=0.2$ and $P_{A}(X=1)=0.8$. Therefore,\n$$\nP_{A}(Y=0)=0.9 \\cdot 0.2+0.3 \\cdot 0.8=0.18+0.24=0.42,\n$$\n$$\nP_{A}(Y=1)=1-0.42=0.58.\n$$\nHence $P_{A}(Y)=(0.42, 0.58)$.\n\nAlgorithm B has $P_{B}(X=0)=0.8$ and $P_{B}(X=1)=0.2$. Therefore,\n$$\nP_{B}(Y=0)=0.9 \\cdot 0.8+0.3 \\cdot 0.2=0.72+0.06=0.78,\n$$\n$$\nP_{B}(Y=1)=1-0.78=0.22.\n$$\nHence $P_{B}(Y)=(0.78, 0.22)$.\n\nComparing with the options, this matches option A.", "answer": "$$\\boxed{A}$$", "id": "1632599"}, {"introduction": "Moving beyond simple analysis, a common real-world task is to characterize an unknown system. This practice problem flips the script: instead of calculating the output from a known channel, you will act as an engineer to determine the channel's properties from experimental data. This exercise in system identification requires you to set up and solve a system of linear equations to find the channel's transition probability matrix, a key skill for designing and troubleshooting communication systems [@problem_id:1632593].", "problem": "An engineer is characterizing a newly developed digital communication channel. The channel is known to be a memoryless binary channel, meaning its input alphabet is $\\mathcal{X} = \\{0, 1\\}$ and its output alphabet is $\\mathcal{Y} = \\{0, 1\\}$. The behavior of the channel is described by a transition probability matrix $C$, where the element in row $i$ and column $j$ (0-indexed) is $C_{ij} = P(Y=i|X=j)$. Thus, the first column corresponds to input $X=0$ and the second to input $X=1$, while the first row corresponds to output $Y=0$ and the second to output $Y=1$.\n\nThe engineer performs two experiments to determine this matrix.\n\nIn the first experiment, a uniformly random input signal is used. The input probability distribution is given by the vector $[P(X=0), P(X=1)] = [0.5, 0.5]$. The resulting output probability distribution is measured to be $[P(Y=0), P(Y=1)] = [0.5, 0.5]$.\n\nIn the second experiment, a deterministic input signal is used, where the input is always '0'. This corresponds to an input probability distribution of $[P(X=0), P(X=1)] = [1, 0]$. The measured output distribution for this case is $[P(Y=0), P(Y=1)] = [0.8, 0.2]$.\n\nBased on the results of these two experiments, determine the $2 \\times 2$ channel transition probability matrix $C$.", "solution": "Let the channel transition matrix be $C=\\begin{pmatrix}C_{00} & C_{01} \\\\ C_{10} & C_{11}\\end{pmatrix}$, where $C_{ij}=P(Y=i\\mid X=j)$. For each input $j\\in\\{0,1\\}$, probabilities must sum to one:\n$$\nC_{00}+C_{10}=1,\\quad C_{01}+C_{11}=1.\n$$\nFrom the second experiment with deterministic input $X=0$, the output distribution equals the first column of $C$:\n$$\n\\begin{pmatrix}P(Y=0) \\\\ P(Y=1)\\end{pmatrix}=\\begin{pmatrix}0.8 \\\\ 0.2\\end{pmatrix}=\\begin{pmatrix}C_{00} \\\\ C_{10}\\end{pmatrix}.\n$$\nHence $C_{00}=0.8$ and $C_{10}=0.2$.\n\nFrom the first experiment with $P(X=0)=P(X=1)=\\frac{1}{2}$ and measured $P(Y=0)=\\frac{1}{2}$, use the law of total probability:\n$$\nP(Y=0)=\\sum_{j=0}^{1}P(Y=0\\mid X=j)P(X=j)=\\tfrac{1}{2}C_{00}+\\tfrac{1}{2}C_{01}=\\tfrac{1}{2}.\n$$\nThus\n$$\nC_{00}+C_{01}=1 \\implies C_{01}=1-C_{00}=1-0.8=0.2.\n$$\nBy column normalization for $j=1$,\n$$\nC_{01}+C_{11}=1 \\implies C_{11}=1-C_{01}=1-0.2=0.8.\n$$\nTherefore,\n$$\nC=\\begin{pmatrix}0.8 & 0.2 \\\\ 0.2 & 0.8\\end{pmatrix}.\n$$\nA quick check with the uniform input gives $P(Y=0)=\\tfrac{1}{2}(0.8+0.2)=\\tfrac{1}{2}$ and $P(Y=1)=\\tfrac{1}{2}(0.2+0.8)=\\tfrac{1}{2}$, consistent with the measurements.", "answer": "$$\\boxed{\\begin{pmatrix}0.8 & 0.2 \\\\ 0.2 & 0.8\\end{pmatrix}}$$", "id": "1632593"}, {"introduction": "This advanced problem bridges the gap between analysis and design, reflecting a sophisticated engineering challenge. Here, the goal is not just to analyze or identify a channel, but to find an input distribution that produces a specific, desired output, while also satisfying an optimization goal. This exercise introduces the concept of a solution space and requires you to use linear algebra and optimization techniques to navigate design trade-offs, a scenario common in fields like signal processing and network control [@problem_id:1632614].", "problem": "An engineer is testing a noisy communication channel with a three-symbol input alphabet, $X = \\{x_1, x_2, x_3\\}$, and a three-symbol output alphabet, $Y = \\{y_1, y_2, y_3\\}$. The channel's characteristics are described by the set of conditional probabilities $P(y_j|x_i)$, which is the probability of receiving symbol $y_j$ given that symbol $x_i$ was sent. These probabilities are empirically determined to be:\n\n*   For input $x_1$: $P(y_1|x_1)=0.7$, $P(y_2|x_1)=0.2$, $P(y_3|x_1)=0.1$.\n*   For input $x_2$: $P(y_1|x_2)=0.1$, $P(y_2|x_2)=0.6$, $P(y_3|x_2)=0.3$.\n*   For input $x_3$: $P(y_1|x_3)=0.22$, $P(y_2|x_3)=0.52$, $P(y_3|x_3)=0.26$.\n\nThe engineer wants to find an input probability distribution, $P(X) = (P(X=x_1), P(X=x_2), P(X=x_3))$, that results in a specific target output distribution, $P(Y) = (P(Y=y_1), P(Y=y_2), P(Y=y_3))$, where $P(Y=y_1)=0.4$, $P(Y=y_2)=0.4$, and $P(Y=y_3)=0.2$.\n\nAmong all valid input distributions that produce this target output distribution, what is the maximum possible value for the probability of the first input symbol, $P(X=x_1)$? Your answer should be a single real number, expressed as a fraction or a decimal.", "solution": "Let the input probability distribution be denoted by the row vector $\\mathbf{p} = [p_1, p_2, p_3]$, where $p_i = P(X=x_i)$. Let the output probability distribution be the row vector $\\mathbf{r} = [r_1, r_2, r_3]$, where $r_j = P(Y=y_j)$. The channel is described by the transition matrix $Q$, where $Q_{ij} = P(y_j|x_i)$.\n\nThe given values for the channel matrix $Q$ are:\n$$\nQ = \\begin{pmatrix}\n0.7 & 0.2 & 0.1 \\\\\n0.1 & 0.6 & 0.3 \\\\\n0.22 & 0.52 & 0.26\n\\end{pmatrix}\n$$\nThe target output distribution is $\\mathbf{r} = [0.4, 0.4, 0.2]$.\n\nThe relationship between the input distribution, output distribution, and the channel matrix is given by the law of total probability: $P(y_j) = \\sum_{i=1}^{3} P(y_j|x_i) P(x_i)$. In matrix form, this is $\\mathbf{p} Q = \\mathbf{r}$.\n\nWriting this out component-wise gives a system of linear equations:\n1.  $p_1 P(y_1|x_1) + p_2 P(y_1|x_2) + p_3 P(y_1|x_3) = r_1 \\implies 0.7 p_1 + 0.1 p_2 + 0.22 p_3 = 0.4$\n2.  $p_1 P(y_2|x_1) + p_2 P(y_2|x_2) + p_3 P(y_2|x_3) = r_2 \\implies 0.2 p_1 + 0.6 p_2 + 0.52 p_3 = 0.4$\n3.  $p_1 P(y_3|x_1) + p_2 P(y_3|x_2) + p_3 P(y_3|x_3) = r_3 \\implies 0.1 p_1 + 0.3 p_2 + 0.26 p_3 = 0.2$\n\nAdditionally, since $\\mathbf{p}$ is a probability distribution, its components must sum to 1:\n4.  $p_1 + p_2 + p_3 = 1$\n\nAnd each component must be non-negative:\n5.  $p_1 \\ge 0$, $p_2 \\ge 0$, $p_3 \\ge 0$\n\nWe have a system of equations for $p_1, p_2, p_3$. Notice that the rows of the channel matrix $Q$ are linearly dependent. Specifically, row 3 is a linear combination of rows 1 and 2: $0.2 \\times \\text{row}_1 + 0.8 \\times \\text{row}_2 = [0.14, 0.04, 0.02] + [0.08, 0.48, 0.24] = [0.22, 0.52, 0.26] = \\text{row}_3$. This implies that the system of equations (1), (2), (3) is redundant. We only need to use two of the first three equations along with equation (4).\n\nLet's use equations (1), (2), and (4). From (4), we can express $p_3$ as $p_3 = 1 - p_1 - p_2$. Substitute this into equation (1):\n$0.7 p_1 + 0.1 p_2 + 0.22 (1 - p_1 - p_2) = 0.4$\n$0.7 p_1 + 0.1 p_2 + 0.22 - 0.22 p_1 - 0.22 p_2 = 0.4$\n$0.48 p_1 - 0.12 p_2 = 0.18$\nDividing by $0.12$, we get:\n$4 p_1 - p_2 = 1.5 \\implies p_2 = 4 p_1 - 1.5$\n\nNow, substitute $p_3 = 1 - p_1 - p_2$ into equation (2):\n$0.2 p_1 + 0.6 p_2 + 0.52 (1 - p_1 - p_2) = 0.4$\n$0.2 p_1 + 0.6 p_2 + 0.52 - 0.52 p_1 - 0.52 p_2 = 0.4$\n$-0.32 p_1 + 0.08 p_2 = -0.12$\nDividing by $0.08$, we get:\n$-4 p_1 + p_2 = -1.5 \\implies p_2 = 4 p_1 - 1.5$\n\nBoth equations yield the same relationship between $p_1$ and $p_2$, confirming the redundancy. We now have a family of solutions where the probabilities are parameterized by $p_1$:\n$p_2 = 4 p_1 - 1.5$\nTo find $p_3$, we substitute this back into the expression for $p_3$:\n$p_3 = 1 - p_1 - p_2 = 1 - p_1 - (4 p_1 - 1.5) = 1 - 5p_1 + 1.5 = 2.5 - 5p_1$\n\nNow we must apply the non-negativity constraints from (5):\na) $p_1 \\ge 0$\nb) $p_2 = 4 p_1 - 1.5 \\ge 0 \\implies 4 p_1 \\ge 1.5 \\implies p_1 \\ge \\frac{1.5}{4} = 0.375$\nc) $p_3 = 2.5 - 5 p_1 \\ge 0 \\implies 2.5 \\ge 5 p_1 \\implies p_1 \\le \\frac{2.5}{5} = 0.5$\n\nCombining these constraints, the set of all possible values for $p_1$ is the interval $[0.375, 0.5]$.\nThe problem asks for the maximum possible value of $p_1 = P(X=x_1)$. Looking at the valid range for $p_1$, the maximum value is $0.5$.\n\nAs a check, if $p_1 = 0.5$:\n$p_2 = 4(0.5) - 1.5 = 2 - 1.5 = 0.5$\n$p_3 = 2.5 - 5(0.5) = 2.5 - 2.5 = 0$\nThe input distribution would be $\\mathbf{p} = [0.5, 0.5, 0]$. This is a valid probability distribution as all components are non-negative and they sum to 1.\nThe resulting output is $$\\mathbf{p}Q = [0.5, 0.5, 0] \\begin{pmatrix} 0.7 & 0.2 & 0.1 \\\\ 0.1 & 0.6 & 0.3 \\\\ 0.22 & 0.52 & 0.26 \\end{pmatrix} = [0.5(0.7)+0.5(0.1), 0.5(0.2)+0.5(0.6), 0.5(0.1)+0.5(0.3)] = [0.35+0.05, 0.1+0.3, 0.05+0.15] = [0.4, 0.4, 0.2]$$, which matches the target output distribution $\\mathbf{r}$.\n\nThe maximum value for $P(X=x_1)$ is $0.5$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1632614"}]}