{"hands_on_practices": [{"introduction": "Analyzing an iterative algorithm often requires looking beyond a single loop counter. This first practice challenges you to analyze a search on a 2D matrix where the algorithm's state is defined by both row and column indices. By observing that each comparison definitively eliminates either a row or a column, you can trace the algorithm's path and determine the maximum number of steps it can take, a fundamental skill in analyzing multi-dimensional or state-based iterations [@problem_id:3207190].", "problem": "Consider a rectangular two-dimensional matrix $A$ of real numbers of size $n \\times m$ with $n \\geq 1$ and $m \\geq 1$. Each row of $A$ is sorted in nondecreasing order from left to right, and each column of $A$ is sorted in nondecreasing order from top to bottom. A deterministic iterative search algorithm is defined to locate a given real key $x$ as follows: it starts at the top-right position $(i,j) = (1,m)$ and repeats the following step while the indices remain in bounds $1 \\leq i \\leq n$ and $1 \\leq j \\leq m$:\n- Compare $A[i,j]$ with $x$.\n- If $A[i,j] = x$, terminate and report success.\n- If $A[i,j] > x$, update $j \\leftarrow j - 1$.\n- If $A[i,j] < x$, update $i \\leftarrow i + 1$.\nIf the indices go out of bounds (specifically, if $i = n+1$ or $j = 0$), terminate and report that $x$ is not present.\n\nUsing only foundational definitions of iterative algorithms and comparison-based models from data structures and algorithms, derive from first principles the exact worst-case number of comparisons this algorithm performs as a function of $n$ and $m$ on any valid input matrix $A$ and any real key $x$. Your final answer must be a single closed-form analytical expression in terms of $n$ and $m$. No rounding or unit specification is required for this answer.", "solution": "The number of comparisons is equal to the number of iterations of the main loop. To find the worst case, we must find the maximum possible number of iterations.\n\nLet the state of the algorithm at the beginning of each iteration be represented by the coordinates $(i,j)$. The algorithm starts at $(1,m)$. In each step, the coordinates change from $(i,j)$ to either $(i+1, j)$ (a \"down\" move) or $(i, j-1)$ (a \"left\" move). The worst case occurs when the key is not found, forcing the algorithm to run for the maximum number of steps. The path of the indices starts at the top-right corner and moves towards the bottom-left.\n\nTo analyze the path length, consider the quantity $S = (i - 1) + (m - j)$. At the start of the algorithm, we are at $(1,m)$, so $S = (1 - 1) + (m - m) = 0$. In each iteration, $S$ increases by exactly 1:\n-   **Down move**: From $(i,j)$ to $(i+1, j)$, the new value is $S' = ((i+1) - 1) + (m - j) = (i - 1) + 1 + (m-j) = S+1$.\n-   **Left move**: From $(i,j)$ to $(i, j-1)$, the new value is $S' = (i - 1) + (m - (j-1)) = (i - 1) + (m-j) + 1 = S+1$.\n\nSince $S$ starts at 0 and increments by 1 at each step, after $k$ comparisons (at the start of iteration $k+1$), the value of $S$ is $k$. Let $(i_k, j_k)$ be the coordinates where the $k$-th comparison takes place. The value of $S$ at the beginning of the $k$-th iteration is $k-1$, so $k-1 = (i_k - 1) + (m-j_k)$, which gives $k = i_k + m - j_k$.\n\nThe algorithm terminates when the indices go out of bounds. The longest path occurs when this happens at the \"last possible\" cell. To maximize $k$, we must maximize $i_k$ and minimize $j_k$. The maximum possible value for $i_k$ is $n$ and the minimum for $j_k$ is $1$. This corresponds to a path that ends at or near the bottom-left cell $(n,1)$.\nThe maximum number of comparisons is thus:\n$$ k_{max} = n + m - 1 $$\nThis path requires $(n-1)$ \"down\" moves and $(m-1)$ \"left\" moves. The total number of cells visited, and thus comparisons, is $1 + (n-1) + (m-1) = n+m-1$. This worst case is achievable with a suitable matrix and key.\n\nTherefore, the exact worst-case number of comparisons is $n+m-1$.", "answer": "$$\\boxed{n+m-1}$$", "id": "3207190"}, {"introduction": "Effective algorithm analysis is not just about counting operations; it's about smart problem-solving. This exercise demonstrates how leveraging the intrinsic properties of a data structure—in this case, a binary min-heap—can drastically simplify an algorithm. Instead of a naive scan, you will analyze a procedure that intelligently restricts its search to only the leaf nodes, where the maximum element must reside, providing a lesson in the interplay between data structures and algorithm efficiency [@problem_id:3207269].", "problem": "Consider a binary min-heap stored in an array $A[1], A[2], \\dots, A[n]$ for some integer $n \\geq 1$. A binary min-heap is a complete binary tree where every node value is less than or equal to the values of its children, and the standard array representation maps a node at index $i$ to its children at indices $2i$ and $2i+1$ whenever those indices are at most $n$. An iterative procedure is proposed to find the maximum element in the heap:\n- Initialize $m \\leftarrow A[k]$ where $k = \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$ (the first leaf position in the array).\n- For each index $i$ from $k+1$ to $n$ in increasing order, perform the comparison “if $A[i] > m$ then update $m \\leftarrow A[i]$; otherwise leave $m$ unchanged.”\nAssume that the cost of the algorithm is measured solely by the number of key comparisons of the form “$A[i] > m$,” and that all other operations have zero cost. Using only the defining properties of binary heaps and their array representation, derive an exact closed-form expression, in terms of $n$, for the worst-case number of key comparisons performed by this algorithm over all valid heaps of size $n$. Your final answer must be a single analytic expression in $n$; do not give an inequality, asymptotic order, or a piecewise definition. No rounding is required.", "solution": "We begin from the core definitions of a binary min-heap and its array representation. A binary min-heap is a complete binary tree in which each node’s key is less than or equal to the keys of its children. The array representation places the root at index $1$ and, for any index $i$, places its children at indices $2i$ and $2i+1$ provided these indices are at most $n$. A node at index $i$ is internal if it has at least one child, which occurs exactly when $2i \\leq n$. Therefore, the set of internal nodes is precisely those indices $i$ with $1 \\leq i \\leq \\left\\lfloor \\frac{n}{2} \\right\\rfloor$. Conversely, the leaves are those indices $i$ with $i \\geq \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$ up to $n$. Hence, the number of leaves $L$ in a heap of size $n$ is\n$$\nL = n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor.\n$$\nNext, we argue that the maximum element of a min-heap must reside among the leaves. Consider any non-leaf node at index $i$. By the heap property, its child at index $2i$ (if it exists) satisfies $A[2i] \\geq A[i]$, and similarly $A[2i+1] \\geq A[i]$ if it exists. Following any path from an internal node to a leaf, the sequence of keys is non-decreasing. Therefore, for any internal node, there exists a leaf whose key is greater than or equal to that internal node’s key. Consequently, a maximum key cannot be strictly inside the set of internal nodes; it must be attained at a leaf.\n\nThe given iterative algorithm initializes $m$ to the key at the first leaf index $k = \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$, and then scans the remaining leaves from $k+1$ through $n$, performing exactly one comparison per leaf scanned. There is no early termination condition; thus, regardless of the input arrangement of keys, the algorithm will perform exactly one comparison for each of the leaves after the first. Therefore, the exact number of key comparisons performed is\n$$\n\\text{comparisons} = L - 1 = \\left(n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor\\right) - 1.\n$$\nWe can simplify this using the identity $\\left\\lceil \\frac{n}{2} \\right\\rceil = n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor$, valid for all integers $n$. Substituting yields\n$$\n\\text{comparisons} = \\left\\lceil \\frac{n}{2} \\right\\rceil - 1.\n$$\nBecause the algorithm deterministically compares against each remaining leaf exactly once, this count is both the worst-case and the exact count for any valid heap of size $n$. Hence, the required exact closed-form expression in terms of $n$ is\n$$\n\\left\\lceil \\frac{n}{2} \\right\\rceil - 1.\n$$", "answer": "$$\\boxed{\\left\\lceil \\frac{n}{2} \\right\\rceil - 1}$$", "id": "3207269"}, {"introduction": "This final practice addresses a common and complex scenario: analyzing an algorithm that modifies the very data structure it iterates over. The task is to analyze a procedure that removes duplicates from a sorted linked list, which involves changing `next` pointers during traversal. The key to this analysis is to identify a robust loop invariant related to the original list, a powerful technique for proving correctness and efficiency when dealing with dynamic pointer-based structures [@problem_id:3207266].", "problem": "Consider a singly linked list $L$ of $n$ nodes, where each node stores an integer key and a pointer to the next node. Assume the keys in $L$ are sorted in nondecreasing order, so all duplicate keys appear in consecutive nodes. The following iterative algorithm removes all duplicates, leaving exactly one node for each distinct key:\n\n- Let $x$ denote the head node of $L$.\n- While $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$:\n    - If $x.\\text{key} = x.\\text{next}.\\text{key}$, then set $x.\\text{next} := x.\\text{next}.\\text{next}$.\n    - Otherwise, set $x := x.\\text{next}$.\n\nAssume the standard unit-cost Random Access Machine (RAM) model in which each key comparison (such as $x.\\text{key} = x.\\text{next}.\\text{key}$) and each pointer assignment (such as $x := x.\\text{next}$ or $x.\\text{next} := x.\\text{next}.\\text{next}$) takes constant time, denoted $O(1)$. Under this model, derive from first principles a closed-form expression for the exact number of key comparisons the algorithm performs as a function of $n$, for any input instance consistent with the given assumptions. Then deduce from that count the tight asymptotic time complexity (in Big-Theta notation) of the algorithm as a function of $n$. Express your final answer as a single analytic expression in Big-Theta notation.", "solution": "The problem requires an analysis of a given iterative algorithm for removing duplicates from a sorted singly linked list. The analysis must first yield an exact closed-form expression for the number of key comparisons and then deduce the tight asymptotic time complexity in Big-Theta notation.\n\nLet the singly linked list be $L$, consisting of $n$ nodes. We denote the original nodes in sequence as $N_1, N_2, \\ldots, N_n$. Let $k_i$ be the key stored in node $N_i$. Since the list is sorted in nondecreasing order, we have $k_1 \\le k_2 \\le \\ldots \\le k_n$. The algorithm is as follows:\n1. Initialize a pointer $x$ to the head of the list, $N_1$.\n2. Loop while $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$.\n3. Inside the loop, compare $x.\\text{key}$ with $x.\\text{next}.\\text{key}$.\n   a. If they are equal, a duplicate is found. The node $x.\\text{next}$ is removed by setting $x.\\text{next} := x.\\text{next}.\\text{next}$. The pointer $x$ remains at its current position to check for further duplicates.\n   b. If they are not equal, there is no duplicate for the current key of $x$. The pointer $x$ is advanced to the next node by setting $x := x.\\text{next}$.\n\nThe primary task is to find the exact number of key comparisons. A key comparison $x.\\text{key} = x.\\text{next}.\\text{key}$ is performed exactly once in each iteration of the `while` loop. Therefore, the total number of key comparisons is equal to the total number of iterations of the loop.\n\nLet us analyze the number of loop iterations. The loop continues as long as $x.\\text{next} \\neq \\text{null}$. We will demonstrate that for any input list of size $n \\ge 1$, the loop executes exactly $n-1$ times.\nIf $n=0$, the list is empty, $x$ is initialized to $\\text{null}$, the loop condition $x \\neq \\text{null}$ is false, and $0$ comparisons are made.\nIf $n=1$, $x$ points to $N_1$, but $x.\\text{next}$ is $\\text{null}$. The loop condition $x.\\text{next} \\neq \\text{null}$ is false, and $0$ comparisons are made. Note that $n-1 = 0$ in this case.\n\nNow, consider $n \\ge 2$. Let's trace the node that $x.\\text{next}$ points to at the beginning of each iteration. Let the iteration number be $i$, starting from $i=1$.\n- **Iteration $i=1$**: Initially, $x$ points to $N_1$. Thus, $x.\\text{next}$ points to $N_2$. The loop condition is true, and the first comparison is made.\n- **Start of Iteration $i=2$**: After the first iteration, we analyze the location of $x.\\text{next}$.\n  - Case 1 ($k_1 = k_2$): The assignment $x.\\text{next} := x.\\text{next}.\\text{next}$ is executed. Since $x$ was $N_1$ and $x.\\text{next}$ was $N_2$, the new $x.\\text{next}$ for $N_1$ becomes $N_3$. The pointer $x$ itself does not change. So, at the start of the second iteration, $x$ is still $N_1$ and $x.\\text{next}$ points to $N_3$.\n  - Case 2 ($k_1 \\neq k_2$): The assignment $x := x.\\text{next}$ is executed. Since $x$ was $N_1$ and $x.\\text{next}$ was $N_2$, $x$ now points to $N_2$. The new $x.\\text{next}$ is the successor of $N_2$ in the original list, which is $N_3$.\nIn both cases, at the start of the second iteration, the node being considered at $x.\\text{next}$ is $N_3$.\n\nWe can generalize this observation. Let's propose an invariant: At the beginning of iteration $i$ (where $1 \\le i \\le n-1$), the pointer $x.\\text{next}$ refers to the original node $N_{i+1}$.\n- **Base Case ($i=1$)**: This is true, as shown above.\n- **Inductive Step**: Assume the invariant holds for iteration $i$, where $1 \\le i < n-1$. So at the start of iteration $i$, $x.\\text{next}$ points to $N_{i+1}$. A comparison is made.\n  - If $x.\\text{key} = x.\\text{next}.\\text{key}$, $x$ remains unchanged, and $x.\\text{next}$ is updated to point to $N_{i+2}$.\n  - If $x.\\text{key} \\neq x.\\text{next}.\\text{key}$, $x$ is updated to point to $N_{i+1}$, so its `next` pointer refers to $N_{i+2}$.\nIn both outcomes, at the start of iteration $i+1$, the node referenced by $x.\\text{next}$ is $N_{(i+1)+1} = N_{i+2}$. The invariant holds.\n\nThis inductive argument shows that the loop iterates for $i=1, 2, \\ldots, n-1$. In the $(n-1)$-th iteration, $x.\\text{next}$ points to $N_n$. After this iteration:\n- If $x.\\text{key} = N_n.\\text{key}$: $x.\\text{next}$ is set to $N_n.\\text{next}$, which is $\\text{null}$.\n- If $x.\\text{key} \\neq N_n.\\text{key}$: $x$ is set to $N_n$, and its `next` pointer is $\\text{null}$.\nIn either scenario, the loop condition $x.\\text{next} \\neq \\text{null}$ will be false before the next potential iteration. Therefore, the loop terminates after exactly $n-1$ iterations.\n\nThe number of key comparisons, $C(n)$, for $n \\ge 1$ is exactly $n-1$. For $n=0$, $C(0)=0$. The closed-form expression covering all non-negative $n$ is $C(n) = \\max(0, n-1)$. Assuming non-trivial list sizes ($n \\ge 1$), the count is $n-1$.\n\nNext, we deduce the tight asymptotic time complexity, $T(n)$. We use the standard unit-cost RAM model, where each elementary operation costs $O(1)$.\nThe algorithm consists of:\n1. An initial pointer assignment ($x := \\text{head}$): This takes constant time, $O(1)$.\n2. The `while` loop:\n   - Loop condition checks: The conditions $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$ are checked at the start of each iteration and one final time when the loop terminates. For $n \\ge 1$, this amounts to $n$ checks in total. Each check costs $O(1)$, so the total cost for checks is $n \\times O(1) = O(n)$.\n   - Loop body: The loop executes $n-1$ times for $n \\ge 1$. In each iteration, the algorithm performs:\n     - One key comparison: $O(1)$.\n     - One pointer assignment (either in the `if` or `else` branch): $O(1)$.\n   Thus, the work inside each iteration is constant, $O(1)$. The total time spent in the loop body over all iterations is $(n-1) \\times O(1) = O(n)$.\n\nThe total time complexity is the sum of the costs:\n$T(n) = (\\text{initialization}) + (\\text{loop checks}) + (\\text{loop body execution})$\nFor $n \\ge 1$, $T(n) = O(1) + O(n) + O(n) = O(n)$.\nThis establishes an upper bound on the time complexity.\n\nFor a lower bound, we observe that for any input with $n \\ge 1$, the algorithm must perform $n-1$ iterations. Each iteration involves at least one key comparison and associated pointer operations, which take some minimum constant amount of time, $c > 0$. Therefore, the total time must be at least proportional to $n-1$.\n$T(n) \\ge c \\cdot (n-1)$ for some constant $c>0$ and for $n \\ge 1$.\nThis implies $T(n) \\in \\Omega(n-1)$, which simplifies to $T(n) \\in \\Omega(n)$.\n\nSince $T(n) \\in O(n)$ and $T(n) \\in \\Omega(n)$, the tight asymptotic time complexity of the algorithm is $\\Theta(n)$.", "answer": "$$\\boxed{\\Theta(n)}$$", "id": "3207266"}]}