{"hands_on_practices": [{"introduction": "Effective algorithm design often begins by viewing a problem from multiple angles. This exercise explores that idea using the classic Towers of Hanoi puzzle, a perfect showcase for the contrast between recursive and iterative thinking. You will first specify a solution using the elegant, top-down logic of recursion, and then re-specify it with a deterministic, bottom-up iterative method, gaining insight into two powerful and distinct ways to structure a solution. [@problem_id:3205878]", "problem": "You are to formalize and implement two algorithm specifications in pseudo-code for the Towers of Hanoi problem and then provide a single runnable program that validates these specifications on a predefined test suite. The Towers of Hanoi consists of three pegs and $n$ disks labeled from $1$ (smallest) to $n$ (largest). All disks start on a designated source peg, and the objective is to move the entire stack to a designated target peg using an auxiliary peg, subject to the following constraints: only one disk may be moved at a time, and no disk may be placed on top of a smaller disk.\n\nStarting from a recognized foundational base in data structures and algorithms:\n- The recursive decomposition principle for divide-and-conquer algorithms,\n- Mathematical induction and recurrence relations for counting operations,\n- Deterministic state generation without search using discrete representations,\n\nyou must produce two algorithm designs:\n\n1. A recursive specification that, given $n \\ge 0$ and peg labels (`s`,`a`,`t`), returns the minimal-length sequence of moves to transfer all disks from peg `s` to peg `t` using peg `a` as auxiliary. A move is an ordered pair $(u,v)$ with $u \\ne v$, indicating a legal transfer of the top disk from peg $u$ to peg $v$.\n\n2. A non-recursive iterative specification that deterministically generates the same minimal sequence of moves using only loops, fixed-time arithmetic or bit operations per step, and data structures with constant-time access. It must not use recursion, search, or backtracking. The design must ensure that exactly one disk moves at each step and that all intermediate states are legal under the constraints.\n\nYour implementation must:\n- Provide two functions, one for the recursive method and one for the iterative method, each returning the full sequence of moves as a list of ordered pairs of peg labels.\n- Verify, for each test case, that both sequences are identical, that the sequence is legal when simulated from the initial configuration, and report the total number of moves produced.\n\nThe test suite to be used by the program is the following list of parameter triples $(n,s,a,t)$:\n- Case $1$: $(0, \\text{\"S\"}, \\text{\"A\"}, \\text{\"T\"})$,\n- Case $2$: $(1, \\text{\"S\"}, \\text{\"A\"}, \\text{\"T\"})$,\n- Case $3$: $(2, \\text{\"S\"}, \\text{\"A\"}, \\text{\"T\"})$,\n- Case $4$: $(3, \\text{\"X\"}, \\text{\"Y\"}, \\text{\"Z\"})$,\n- Case $5$: $(4, \\text{\"S\"}, \\text{\"A\"}, \\text{\"T\"})$.\n\nNo physical units or angles are involved. All outputs are pure discrete values.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- For each test case, the program must output a list $[E,L,G]$ where $E$ is a boolean indicating whether the recursive and iterative sequences are identical, $L$ is the integer number of moves produced by the algorithms, and $G$ is a boolean indicating whether the move sequence is legal and results in the entire stack being on the target peg at the end.\n- The test cases must be processed in the exact order listed above, and the final output should aggregate their $[E,L,G]$ results into one top-level list. For example, the final output should look like $[[E_1,L_1,G_1],[E_2,L_2,G_2],\\dots]$ where each $E_i$ is either $\\text{True}$ or $\\text{False}$ and each $L_i$ is an integer.\n\nThe program must be fully self-contained, read no input, and strictly print only the single required output line.", "solution": "The problem of the Towers of Hanoi requires devising algorithms to transfer $n$ disks from a source peg $s$ to a target peg $t$ using an auxiliary peg $a$, following specific rules. This problem is a canonical example in computer science for illustrating recursion and can also be solved using a non-obvious iterative approach. The solution must provide designs for both a recursive and a deterministic iterative algorithm, implement them, and verify their correctness and equivalence on a given test suite.\n\n### Principle-Based Algorithm Design\n\nThe solution is founded on established principles of algorithm design: recursive decomposition, mathematical induction, and deterministic state generation.\n\n#### 1. Recursive Specification\n\nThe recursive approach is a direct application of the **divide-and-conquer** paradigm. The problem of moving $n$ disks can be broken down into smaller, self-similar subproblems.\n\nLet the function be `HanoiRecursive(n, source, target, auxiliary)`, which generates the sequence of moves to transfer $n$ disks from the `source` peg to the `target` peg.\n\n-   **Base Case:** If $n=0$, no disks need to be moved. The required sequence of moves is empty.\n\n-   **Recursive Step:** For $n > 0$, the process is as follows:\n    1.  Transfer the top $n-1$ disks from the `source` peg to the `auxiliary` peg, using the `target` peg as temporary storage. This is a recursive call: `HanoiRecursive(n-1, source, auxiliary, target)`.\n    2.  Move the largest disk, disk $n$, from the `source` peg to the `target` peg. This constitutes a single move, denoted by the pair `(source, target)`.\n    3.  Transfer the $n-1$ disks from the `auxiliary` peg to the `target` peg, using the `source` peg as temporary storage. This is the second recursive call: `HanoiRecursive(n-1, auxiliary, target, source)`.\n\nThe final sequence of moves is the concatenation of the sequences from these three steps. This decomposition guarantees that the constraints are never violated, as the largest disk $n$ is only moved when all smaller disks are on the auxiliary peg, leaving the source and target pegs free for it.\n\nThe number of moves, $T(n)$, follows the recurrence relation $T(n) = 2T(n-1) + 1$ with the base case $T(0) = 0$. The closed-form solution, provable by mathematical induction, is $T(n) = 2^n - 1$. This is the minimal possible number of moves.\n\n#### 2. Iterative Specification\n\nThe problem requires a non-recursive, deterministic algorithm that generates the same minimal sequence of moves. This can be achieved without search or backtracking by observing a remarkable pattern in the sequence of moves. The state of the system can be advanced through all $2^n-1$ necessary moves using a simple loop and arithmetic operations.\n\nThe algorithm relies on tracking the state of the three pegs (i.e., which disks are on which peg) and making the only legal move possible between a specific pair of pegs at each step. The pair of pegs involved in a given step alternates in a fixed cycle.\n\nLet the pegs be specified as `(source, target, auxiliary)`.\n\n-   The total number of moves is $M = 2^n - 1$.\n-   A key observation is that the behavior of the algorithm depends on the parity of $n$.\n    -   If $n$ is odd, the smallest disk (disk $1$) begins by moving from `source` to `target`, and its subsequent moves cycle through the pegs $source \\rightarrow target \\rightarrow auxiliary \\rightarrow source...$\n    -   If $n$ is even, the smallest disk begins by moving from `source` to `auxiliary`, and its subsequent moves cycle through $source \\rightarrow auxiliary \\rightarrow target \\rightarrow source...$\n\nThis observation leads to the following algorithm for `HanoiIterative(n, source, target, auxiliary)`:\n\n1.  Initialize peg data structures. A dictionary mapping peg labels to lists (acting as stacks) is suitable, with the `source` peg containing disks $[n, n-1, \\dots, 1]$.\n2.  Define an effective set of ordered pegs $(p_1, p_2, p_3)$. If $n$ is even, the `target` and `auxiliary` pegs are conceptually swapped, so the order is $(source, auxiliary, target)$. If $n$ is odd, the order is $(source, target, auxiliary)$. This swap simplifies the logic within the loop.\n3.  Loop for $i$ from $1$ to $2^n - 1$:\n    -   If $i \\pmod 3 = 1$: perform the only legal move between pegs $p_1$ and $p_2$.\n    -   If $i \\pmod 3 = 2$: perform the only legal move between pegs $p_1$ and $p_3$.\n    -   If $i \\pmod 3 = 0$: perform the only legal move between pegs $p_2$ and $p_3$.\n\nA \"legal move\" between two pegs, say peg $U$ and peg $V$, is determined by comparing their top disks. Let $d_U$ and $d_V$ be the top disks.\n-   If one peg is empty (e.g., $U$), the disk from $V$ must move to $U$.\n-   Otherwise, the smaller of the two disks ($d_U$ or $d_V$) is moved onto the larger one.\nThis rule deterministically defines a single valid move for any pair of non-empty pegs, satisfying the problem constraints. The algorithm requires $\\mathcal{O}(1)$ time per step to determine and record the move, leading to an overall time complexity proportional to the number of moves, $\\mathcal{O}(2^n)$.\n\n#### 3. Verification of Legality\n\nA verifier function is necessary to confirm that a generated sequence of moves is legal and achieves the goal state. This function simulates the entire process:\n\n1.  Initialize the configuration with $n$ disks on the source peg.\n2.  Iterate through each move $(u,v)$ in the sequence. For each move:\n    a.  Verify that the source peg $u$ is not empty.\n    b.  Pop the disk $d$ from peg $u$.\n    c.  Verify that peg $v$ is either empty or its top disk is larger than $d$.\n    d.  If either check fails, the sequence is illegal.\n    e.  Push disk $d$ onto peg $v$.\n3.  After all moves, check if the `source` and `auxiliary` pegs are empty and the `target` peg contains all $n$ disks in the correct sorted order, $[n, n-1, \\dots, 1]$.\n\nThis simulation provides a definitive check on the correctness of the generated sequences.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef hanoi_recursive(n, source, target, auxiliary):\n    \"\"\"\n    Generates the sequence of moves for Towers of Hanoi using recursion.\n    Args:\n        n (int): The number of disks.\n        source (str): The label of the source peg.\n        target (str): The label of the target peg.\n        auxiliary (str): The label of the auxiliary peg.\n    Returns:\n        list: A list of (from_peg, to_peg) tuples representing the moves.\n    \"\"\"\n    if n > 0:\n        # Move n-1 disks from source to auxiliary.\n        moves1 = hanoi_recursive(n - 1, source, auxiliary, target)\n        # Move disk n from source to target.\n        move_n = [(source, target)]\n        # Move n-1 disks from auxiliary to target.\n        moves2 = hanoi_recursive(n - 1, auxiliary, target, source)\n        return moves1 + move_n + moves2\n    else:\n        return []\n\ndef perform_move(pegs, p1_label, p2_label):\n    \"\"\"\n    Helper function for the iterative solver. Performs the only legal\n    move between two pegs and returns the move as a tuple.\n    It modifies the pegs dictionary in place.\n    \"\"\"\n    s1 = pegs[p1_label]\n    s2 = pegs[p2_label]\n    \n    if not s1: # s1 is empty, so move from s2 to s1\n        disk = s2.pop()\n        s1.append(disk)\n        return p2_label, p1_label\n    elif not s2: # s2 is empty, so move from s1 to s2\n        disk = s1.pop()\n        s2.append(disk)\n        return p1_label, p2_label\n    elif s1[-1] > s2[-1]: # Top of s1 is a larger disk\n        disk = s2.pop()\n        s1.append(disk)\n        return p2_label, p1_label\n    else: # Top of s2 is a larger disk\n        disk = s1.pop()\n        s2.append(disk)\n        return p1_label, p2_label\n\ndef hanoi_iterative(n, source, target, auxiliary):\n    \"\"\"\n    Generates the sequence of moves for Towers of Hanoi using an iterative algorithm.\n    Args:\n        n (int): The number of disks.\n        source (str): The label of the source peg.\n        target (str): The label of the target peg.\n        auxiliary (str): The label of the auxiliary peg.\n    Returns:\n        list: A list of (from_peg, to_peg) tuples representing the moves.\n    \"\"\"\n    if n == 0:\n        return []\n\n    pegs = {\n        source: list(range(n, 0, -1)),\n        auxiliary: [],\n        target: []\n    }\n    \n    # The order of peg pairs depends on the parity of n.\n    # This logic sets up effective pegs p1, p2, p3 to handle the cycle.\n    if n % 2 == 0: # n is even, swap target and auxiliary\n        p1, p2, p3 = source, auxiliary, target\n    else: # n is odd, no swap\n        p1, p2, p3 = source, target, auxiliary\n        \n    total_moves = 2**n - 1\n    moves = []\n    \n    for i in range(1, total_moves + 1):\n        if i % 3 == 1:\n            from_p, to_p = perform_move(pegs, p1, p2)\n        elif i % 3 == 2:\n            from_p, to_p = perform_move(pegs, p1, p3)\n        else: # i % 3 == 0\n            from_p, to_p = perform_move(pegs, p2, p3)\n        moves.append((from_p, to_p))\n        \n    return moves\n\ndef verify_sequence(n, source, target, auxiliary, moves):\n    \"\"\"\n    Verifies if a sequence of moves is legal and solves the puzzle.\n    Args:\n        n (int): Number of disks.\n        source (str): Source peg label.\n        target (str): Target peg label.\n        auxiliary (str): Auxiliary peg label.\n        moves (list): The sequence of moves to verify.\n    Returns:\n        bool: True if the sequence is valid, False otherwise.\n    \"\"\"\n    if n == 0:\n        return len(moves) == 0\n\n    pegs = {\n        source: list(range(n, 0, -1)),\n        auxiliary: [],\n        target: []\n    }\n    \n    for from_p, to_p in moves:\n        # Check for invalid move from an empty peg\n        if not pegs.get(from_p) or not pegs[from_p]:\n            return False\n        \n        disk = pegs[from_p].pop()\n        \n        # Check rule: no larger disk on a smaller disk\n        if pegs.get(to_p) and pegs[to_p] and pegs[to_p][-1]  disk:\n            return False\n            \n        pegs[to_p].append(disk)\n        \n    # Check final state\n    goal_state = list(range(n, 0, -1))\n    if pegs[source] == [] and pegs[auxiliary] == [] and pegs[target] == goal_state:\n        return True\n    else:\n        return False\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite format: (n, source_label, auxiliary_label, target_label)\n    test_cases = [\n        (0, \"S\", \"A\", \"T\"),\n        (1, \"S\", \"A\", \"T\"),\n        (2, \"S\", \"A\", \"T\"),\n        (3, \"X\", \"Y\", \"Z\"),\n        (4, \"S\", \"A\", \"T\"),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, s, a, t = case\n        \n        # Consistent parameter order (n, source, target, auxiliary) for both functions\n        rec_moves = hanoi_recursive(n, s, t, a)\n        iter_moves = hanoi_iterative(n, s, t, a)\n        \n        # E: Check if recursive and iterative sequences are identical\n        are_equal = (rec_moves == iter_moves)\n        \n        # L: Length of the move sequence\n        num_moves = len(rec_moves)\n        \n        # G: Check if the sequence is legal and reaches the goal state\n        is_good = verify_sequence(n, s, t, a, rec_moves)\n        \n        results.append([are_equal, num_moves, is_good])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205878"}, {"introduction": "An initial, correct specification is a great start, but a truly skilled programmer knows how to refine it for performance. This practice focuses on transforming a naive recursive specification for computing Fibonacci numbers into a vastly more efficient one. By analyzing the problem of overlapping subproblems, you will apply the principles of dynamic programming to develop a linear-time, constant-space iterative algorithm, a fundamental optimization technique. [@problem_id:3205750]", "problem": "You are given a recursive specification for the Fibonacci sequence that maps an input integer $n$ to the $n$-th Fibonacci number $F(n)$. The sequence is defined by the core recurrence on nonnegative integers: $F(0) = 0$, $F(1) = 1$, and for all $n \\ge 2$, $F(n) = F(n-1) + F(n-2)$. The naive recursive pseudo-code below follows this definition literally:\n- Input: integer $n \\ge 0$.\n- Procedure $\\mathrm{Fib}(n)$:\n  - If $n \\le 1$ then return $n$.\n  - Else return $\\mathrm{Fib}(n-1) + \\mathrm{Fib}(n-2)$.\n\nTask: Refactor this pseudo-code into a more efficient dynamic programming version and justify the design from first principles of data structures and algorithms. Base your derivation on the fundamental definitions of recurrence relations, the notion of overlapping subproblems, and the cost model where the running time counts elementary operations. Do not use any shortcut identities that jump directly to the answer without constructing the algorithm.\n\nYour deliverables must include:\n- A clear algorithm specification describing how to compute $F(n)$ using dynamic programming with bottom-up iteration and constant auxiliary space, starting from the definition of $F(n)$ and the observation that the naive recursion recomputes overlapping subproblems.\n- Pseudo-code for the refactored algorithm that respects precisely stated loop invariants, ensuring that the computation advances in a valid state from one iteration to the next.\n- A correctness argument that establishes the loop invariant and uses mathematical induction on the iteration counter to conclude that the output equals $F(n)$ for all $n \\ge 0$.\n- A complexity analysis comparing the naive recursive version and your dynamic programming version, expressed using Big-Oh notation (e.g., $\\mathcal{O}(n)$), and justified from the cost model and the structure of the computation.\n- A Python program that implements the refactored dynamic programming algorithm and applies it to the test suite below.\n\nTest suite:\n- $n \\in \\{0, 1, 2, 5, 10, 50, 90\\}$.\n\nOutput format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example $[r_0,r_1,r_2,r_3,r_4,r_5,r_6]$, where each $r_i$ is the integer $F(n)$ for the corresponding test input.", "solution": "The problem requires refactoring a naive recursive algorithm for the Fibonacci sequence into an efficient dynamic programming version, providing a complete justification for the design.\n\n**1. Problem Statement Analysis**\n\nThe problem provides the mathematical definition of the Fibonacci sequence, $F(n)$, for non-negative integers $n$:\n- Base cases: $F(0) = 0$, $F(1) = 1$.\n- Recurrence relation: $F(n) = F(n-1) + F(n-2)$ for $n \\ge 2$.\n\nIt also provides the corresponding naive recursive pseudo-code:\n- Procedure $\\mathrm{Fib}(n)$:\n  - If $n \\le 1$ then return $n$.\n  - Else return $\\mathrm{Fib}(n-1) + \\mathrm{Fib}(n-2)$.\n\nThe task is to transform this into a more efficient algorithm using dynamic programming, specifically a bottom-up iterative approach with constant auxiliary space. This involves identifying the inefficiency in the naive approach and systematically deriving the improved algorithm.\n\n**2. Inefficiency of the Naive Recursive Approach: Overlapping Subproblems**\n\nThe core issue with the naive recursive algorithm is redundant computation. The computation of $F(n)$ involves two recursive calls, $\\mathrm{Fib}(n-1)$ and $\\mathrm{Fib}(n-2)$. The call tree for $F(n)$ expands, and many subproblems are computed multiple times. For example, to compute $F(5)$, the algorithm calls $F(4)$ and $F(3)$. The computation of $F(4)$ in turn requires $F(3)$ and $F(2)$. The subproblem $F(3)$ is thus computed twice. This phenomenon, where the same subproblem is encountered repeatedly in different branches of the recursion tree, is known as **overlapping subproblems**. This is a key characteristic that signals the applicability of dynamic programming.\n\nThe number of recursive calls, $T(n)$, to compute $F(n)$ follows the recurrence $T(n) = T(n-1) + T(n-2) + 1$, with $T(0)=1$ and $T(1)=1$. The solution to this recurrence is exponential in $n$. Specifically, $T(n)$ is in $\\mathcal{O}(\\phi^n)$, where $\\phi = \\frac{1+\\sqrt{5}}{2}$ is the golden ratio. This exponential time complexity makes the naive algorithm impractical for even moderately large values of $n$.\n\n**3. Dynamic Programming Derivation and Algorithm Specification**\n\nDynamic programming remedies the inefficiency of recomputation by storing the results of subproblems. A bottom-up (or iterative) approach computes the solutions to subproblems in increasing order of size. To compute $F(n)$, we can compute $F(2), F(3), \\dots, F(n)$ in sequence, using previously computed values.\n\nThe recurrence $F(i) = F(i-1) + F(i-2)$ shows that to compute the $i$-th Fibonacci number, we only need the two immediately preceding numbers, $F(i-1)$ and $F(i-2)$. This observation is crucial for space optimization. Instead of storing all previously computed Fibonacci numbers in an array (an $\\mathcal{O}(n)$ space solution), we only need to maintain the last two values to compute the next one. This leads to an algorithm with constant auxiliary space, $\\mathcal{O}(1)$.\n\nThe algorithm proceeds as follows:\n- Handle the base cases $n=0$ and $n=1$ directly.\n- For $n \\ge 2$, we initialize two variables to hold $F(0)$ and $F(1)$.\n- We then iterate from $i=2$ to $n$. In each iteration $i$, we compute $F(i)$ using the two stored values representing $F(i-2)$ and $F(i-1)$.\n- After computing $F(i)$, we update the two variables to hold $F(i-1)$ and $F(i)$ in preparation for the next iteration, $i+1$.\n- The loop continues until $F(n)$ is computed.\n\n**4. Pseudo-code with Loop Invariants**\n\nThe following pseudo-code formalizes the constant-space, bottom-up iterative algorithm.\n\n- **Procedure** $\\mathrm{Fib\\_DP}(n)$:\n- **Input**: A non-negative integer $n$.\n- **Output**: The $n$-th Fibonacci number, $F(n)$.\n\n1.  **If** $n = 0$, **return** $0$.\n2.  **If** $n = 1$, **return** $1$.\n3.  \n4.  // Initialize variables for the iterative computation\n5.  $a \\leftarrow 0$  // Represents the $(i-2)$-th Fibonacci number\n6.  $b \\leftarrow 1$  // Represents the $(i-1)$-th Fibonacci number\n7.  \n8.  // Iterate from 2 to n to compute F(2), F(3), ..., F(n)\n9.  **For** $i$ from $2$ to $n$:\n10.     // **Loop Invariant**: At the beginning of the iteration for index $i$,\n11.     // the variable $a$ stores $F(i-2)$ and the variable $b$ stores $F(i-1)$.\n12. \n13.     $temp \\leftarrow a + b$  // Compute $F(i) = F(i-2) + F(i-1)$\n14.     $a \\leftarrow b$         // Update $a$ to be $F(i-1)$ for the next iteration\n15.     $b \\leftarrow temp$      // Update $b$ to be $F(i)$ for the next iteration\n16. \n17. // After the loop terminates, $b$ holds the value of $F(n)$.\n18. **Return** $b$.\n\n**5. Correctness Argument**\n\nWe prove the correctness of the $\\mathrm{Fib\\_DP}$ algorithm for all non-negative integers $n$.\n\n- **Base Cases**: For $n=0$ and $n=1$, the algorithm correctly returns $0$ and $1$ respectively, which match the definition of $F(0)$ and $F(1)$.\n\n- **Inductive Step ($n \\ge 2$)**: We use the loop invariant to prove correctness for $n \\ge 2$.\n  - **Loop Invariant $P(i)$**: At the start of the loop for index $i$ (where $i$ ranges from $2$ to $n$), $a = F(i-2)$ and $b = F(i-1)$.\n\n  - **Initialization**: Before the first iteration where $i=2$, the algorithm sets $a \\leftarrow 0$ and $b \\leftarrow 1$. According to the definition of the Fibonacci sequence, $F(2-2) = F(0) = 0$ and $F(2-1) = F(1) = 1$. Thus, the invariant $P(2)$ holds at the start of the first iteration.\n\n  - **Maintenance**: Assume the invariant $P(k)$ holds for some integer $k$ such that $2 \\le k \\le n$. This means at the start of iteration $k$, we have $a = F(k-2)$ and $b = F(k-1)$.\n    During the body of iteration $k$:\n    1.  $temp \\leftarrow a + b$. By the inductive hypothesis, $temp = F(k-2) + F(k-1)$. By the Fibonacci recurrence relation, $temp = F(k)$.\n    2.  $a \\leftarrow b$. The variable $a$ is updated to hold the value $F(k-1)$.\n    3.  $b \\leftarrow temp$. The variable $b$ is updated to hold the value $F(k)$.\n\n    At the beginning of the next iteration, the index will be $k+1$. The variables will be $a = F(k-1) = F((k+1)-2)$ and $b = F(k) = F((k+1)-1)$. This demonstrates that the invariant $P(k+1)$ holds. Thus, the loop invariant is maintained.\n\n  - **Termination**: The loop terminates after the iteration for $i=n$ is completed. At the start of the final iteration ($i=n$), the invariant $P(n)$ holds, meaning $a=F(n-2)$ and $b=F(n-1)$. Inside this final iteration, $b$ is updated to $F(n)$. The loop then finishes. The algorithm proceeds to return the value of $b$, which is now $F(n)$.\n\nThe argument shows that the algorithm correctly computes $F(n)$ for all $n \\ge 2$. Combined with the base cases, the algorithm is correct for all non-negative integers $n$.\n\n**6. Complexity Analysis**\n\n- **Naive Recursive Algorithm ($\\mathrm{Fib}$)**:\n  - **Time Complexity**: As established, the number of operations is proportional to the number of recursive calls, which grows exponentially. The time complexity is $\\mathcal{O}(\\phi^n)$, where $\\phi \\approx 1.618$.\n  - **Space Complexity**: The space complexity is determined by the maximum depth of the recursion stack. To compute $F(n)$, the recursion goes down to $F(1)$ or $F(0)$, leading to a maximum depth of $n$. Therefore, the space complexity is $\\mathcal{O}(n)$.\n\n- **Dynamic Programming Algorithm ($\\mathrm{Fib\\_DP}$)**:\n  - **Time Complexity**: For $n \\ge 2$, the algorithm executes a single loop that runs from $i=2$ to $n$. The loop iterates $n-1$ times. Inside the loop, a constant number of elementary operations (one addition, two assignments) are performed. Therefore, the total time complexity is $\\mathcal{O}(n)$.\n  - **Space Complexity**: The algorithm uses a fixed number of variables ($n, a, b, temp, i$) regardless of the input size $n$. The space required for these variables is constant. Thus, the auxiliary space complexity is $\\mathcal{O}(1)$.\n\n**Comparison Summary**\n\n| Algorithm | Time Complexity | Auxiliary Space Complexity |\n| :--- | :--- | :--- |\n| Naive Recursive | $\\mathcal{O}(\\phi^n)$ (Exponential) | $\\mathcal{O}(n)$ (Linear) |\n| Dynamic Programming | $\\mathcal{O}(n)$ (Linear) | $\\mathcal{O}(1)$ (Constant) |\n\nThe dynamic programming approach offers an exponential improvement in time complexity and a reduction from linear to constant auxiliary space, making it vastly superior.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef fib_dp(n: int) -> int:\n    \"\"\"\n    Computes the n-th Fibonacci number using dynamic programming with constant space.\n    \n    The algorithm is based on the recurrence F(n) = F(n-1) + F(n-2).\n    It iteratively computes Fibonacci numbers from F(2) up to F(n),\n    keeping track of only the last two computed values.\n\n    Args:\n        n: A non-negative integer.\n\n    Returns:\n        The n-th Fibonacci number, F(n).\n    \"\"\"\n    if not isinstance(n, int) or n  0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n\n    # Base cases as per the definition F(0) = 0, F(1) = 1.\n    if n = 1:\n        return n\n\n    # Initialization for the iterative process.\n    # We start with 'a' as F(0) and 'b' as F(1) to compute F(2).\n    # In general, at the start of the loop to compute F(i), 'a' is F(i-2) and 'b' is F(i-1).\n    a, b = 0, 1\n\n    # The loop runs n-1 times. For n=2, it runs once. For n=3, twice, and so on.\n    # At each step, we update (a, b) from (F(i-2), F(i-1)) to (F(i-1), F(i)).\n    # The Python tuple assignment `a, b = b, a + b` elegantly performs this state update\n    # by first evaluating the right-hand side (b, a + b) using the old values of a and b,\n    # and then assigning them to the left-hand side variables.\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    \n    # After the loop finishes, 'b' holds the value of F(n).\n    return b\n\ndef solve():\n    \"\"\"\n    Runs the dynamic programming Fibonacci algorithm on the specified test suite\n    and prints the results in the required format.\n    \"\"\"\n    # Test suite as specified in the problem statement.\n    test_cases = [0, 1, 2, 5, 10, 50, 90]\n\n    results = []\n    for n in test_cases:\n        # Calculate the Fibonacci number for each case using the optimized algorithm.\n        result = fib_dp(n)\n        results.append(result)\n\n    # Format the final output as a single-line, comma-separated list in brackets.\n    # Note: Python's integers handle arbitrary size, so F(90) does not overflow.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205750"}, {"introduction": "The final test of an algorithm's specification is its robustness: does it handle every possible case correctly? This exercise challenges you to debug a common but subtly flawed implementation of Kadane's algorithm for the maximum subarray problem, which fails on certain edge cases. By analyzing its logical invariants, you will learn to pinpoint and correct subtle errors related to initialization and boundary conditions, a critical skill for writing production-quality code. [@problem_id:3205797]", "problem": "Consider the maximum subarray problem under the constraint that the chosen subarray must contain at least one element. Formally, given an array $A$ of length $n$ with elements $A[1], A[2], \\dots, A[n]$, the goal is to find indices $1 \\le \\ell \\le r \\le n$ that maximize the sum $\\sum_{i=\\ell}^{r} A[i]$, where the subarray is required to be nonempty. A commonly taught linear-time algorithm (Kadane's algorithm) maintains a running sum and a global maximum. You are given the following pseudo-code, which is known to be incorrect for arrays in which all numbers are negative, while it often works otherwise:\n\n- Initialize `maxSoFar` $\\leftarrow 0$ and `current` $\\leftarrow 0$.\n- For each $x$ in $A$ (from left to right):\n    - Set `current` $\\leftarrow \\max(0, \\text{current} + x)$.\n    - Set `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.\n- Return `maxSoFar`.\n\nWhen run on $A = \\langle -3, -5, -2 \\rangle$, this pseudo-code returns $0$, even though the correct answer under the nonempty-subarray constraint is $-2$.\n\nStarting from core definitions and reasoning about invariants that a correct linear-time solution must maintain, identify which of the following modifications yield a correct algorithm for all arrays (including the case where all numbers are negative) while preserving $\\mathcal{O}(n)$ time and $\\mathcal{O}(1)$ extra space. Each option should be considered as a standalone change; select all that apply.\n\nA. Change only the initialization to `maxSoFar` $\\leftarrow -\\infty$ while leaving the rest of the pseudo-code unchanged.\n\nB. Initialize `current` $\\leftarrow A[1]$ and `maxSoFar` $\\leftarrow A[1]$, then iterate $i$ from $2$ to $n$ with the updates `current` $\\leftarrow \\max(A[i], \\text{current} + A[i])$ and `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.\n\nC. Before the main loop, check if all elements of $A$ are negative; if so, return $\\max_{1 \\le i \\le n} A[i]$. Otherwise, run the original pseudo-code as given.\n\nD. Replace the update `current` $\\leftarrow \\max(0, \\text{current} + x)$ with `current` $\\leftarrow \\max(0, x)$, leaving the rest unchanged.\n\nE. Replace every occurrence of $\\max$ in the pseudo-code with $\\min$, leaving everything else unchanged.\n\nSelect the correct option(s).", "solution": "The user has provided a problem concerning the maximum subarray sum, with a known-incorrect pseudo-code implementation of Kadane's algorithm. The task is to validate the problem statement and, if valid, identify which of the provided modifications correct the algorithm for all possible inputs while maintaining $\\mathcal{O}(n)$ time and $\\mathcal{O}(1)$ space complexity.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- **Problem Domain**: The maximum subarray problem with a nonempty subarray constraint.\n- **Input**: An array $A$ of length $n$ with elements $A[1], A[2], \\dots, A[n]$.\n- **Objective**: Find indices $1 \\le \\ell \\le r \\le n$ that maximize the sum $S = \\sum_{i=\\ell}^{r} A[i]$.\n- **Provided Incorrect Pseudo-code**:\n  - Initialize `maxSoFar` $\\leftarrow 0$ and `current` $\\leftarrow 0$.\n  - For each $x$ in $A$:\n    - Set `current` $\\leftarrow \\max(0, \\text{current} + x)$.\n    - Set `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.\n  - Return `maxSoFar`.\n- **Failure Case**: For input $A = \\langle -3, -5, -2 \\rangle$, the pseudo-code returns $0$, while the correct answer is $-2$.\n- **Task**: Identify all correct modifications from the given options that result in a universally correct algorithm preserving $\\mathcal{O}(n)$ time and $\\mathcal{O}(1)$ space.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is a classic and fundamental topic in computer science, specifically in the area of algorithms and dynamic programming. It is scientifically sound and well-established.\n- **Well-Posedness**: The objective is clearly defined (maximize a sum over a constrained set of subarrays). The input is a standard data structure. The question asks for an evaluation of specific modifications to an algorithm, which is a well-posed task.\n- **Objectivity**: The problem is stated using precise mathematical and algorithmic language. There are no subjective or ambiguous terms.\n- **Flaw Analysis**:\n  1.  **Scientific/Factual Unsoundness**: None. The problem correctly identifies a flaw in a common but simplified version of Kadane's algorithm.\n  2.  **Non-Formalizable/Irrelevant**: None. The problem is perfectly formalizable.\n  3.  **Incomplete/Contradictory Setup**: None. The problem provides all necessary information: the goal, the constraints, the faulty algorithm, and a counterexample.\n  4.  **Unrealistic/Infeasible**: Not applicable. This is a problem in theoretical computer science.\n  5.  **Ill-Posed/Poorly Structured**: None. A unique maximum sum exists for any given array. The question is structured clearly.\n  6.  **Pseudo-Profound/Trivial/Tautological**: None. The problem requires a careful understanding of the algorithm's invariants and edge cases.\n  7.  **Outside Scientific Verifiability**: None. The correctness of an algorithm is mathematically verifiable.\n\n**Step 3: Verdict and Action**\n- **Verdict**: The problem is valid.\n- **Action**: Proceed with the solution derivation and option analysis.\n\n**Core Principles and Derivation**\n\nThe maximum subarray problem can be solved using dynamic programming. Let $C(j)$ be the maximum sum of a non-empty subarray ending at index $j$. To compute $C(j)$, we have two choices for the subarray ending at $j$:\n1.  The subarray consists of only the element $A[j]$. The sum is $A[j]$.\n2.  The subarray is formed by extending the maximum subarray ending at index $j-1$ with the element $A[j]$. The sum is $C(j-1) + A[j]$.\n\nSince we want to maximize the sum, we must choose the larger of these two options. This gives the recurrence relation:\n$$C(j) = \\max(A[j], C(j-1) + A[j])$$\nThe base case is $C(1) = A[1]$, as the only non-empty subarray ending at index $1$ is $\\langle A[1] \\rangle$.\n\nThe overall maximum subarray sum, $M$, is the maximum value of $C(j)$ over all possible ending positions $j$:\n$$M = \\max_{1 \\le j \\le n} C(j)$$\n\nThis recurrence can be implemented in a single loop, using one variable (let's call it `current`) to track $C(j)$ as $j$ increases, and another variable (let's call it `maxSoFar`) to track $M$.\n\nThe original pseudo-code fails because its update rule `current` $\\leftarrow \\max(0, \\text{current} + x)$ is not equivalent to the correct recurrence. Instead of comparing with $A[j]$ (or $x$), it compares with $0$. This implicitly considers an empty subarray (with sum $0$) as an alternative for starting a new subarray, which is why it fails when the true maximum sum is negative. The initialization `maxSoFar` $\\leftarrow 0$ further solidifies this flaw.\n\n**Option-by-Option Analysis**\n\n**A. Change only the initialization to `maxSoFar` $\\leftarrow -\\infty$ while leaving the rest of the pseudo-code unchanged.**\n\nThe modified pseudo-code is:\n- Initialize `maxSoFar` $\\leftarrow -\\infty$ and `current` $\\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set `current` $\\leftarrow \\max(0, \\text{current} + x)$.\n  - Set `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.\n- Return `maxSoFar`.\n\nLet's test this with the given failing case $A = \\langle -3, -5, -2 \\rangle$:\n- Initial state: `maxSoFar` $\\leftarrow -\\infty$, `current` $\\leftarrow 0$.\n- For $x = -3$: `current` $\\leftarrow \\max(0, 0 + (-3)) = 0$. `maxSoFar` $\\leftarrow \\max(-\\infty, 0) = 0$.\n- For $x = -5$: `current` $\\leftarrow \\max(0, 0 + (-5)) = 0$. `maxSoFar` $\\leftarrow \\max(0, 0) = 0$.\n- For $x = -2$: `current` $\\leftarrow \\max(0, 0 + (-2)) = 0$. `maxSoFar` $\\leftarrow \\max(0, 0) = 0$.\nThe algorithm returns $0$, which is incorrect. The core flaw in the update rule `current` $\\leftarrow \\max(0, \\text{current} + x)$ is not addressed. This update prevents the algorithm from ever tracking a negative running sum, which is necessary when all elements are negative.\n\n**Verdict: Incorrect.**\n\n**B. Initialize `current` $\\leftarrow A[1]$ and `maxSoFar` $\\leftarrow A[1]$, then iterate $i$ from $2$ to $n$ with the updates `current` $\\leftarrow \\max(A[i], \\text{current} + A[i])$ and `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.**\n\nThis pseudo-code directly implements the dynamic programming recurrence derived above.\n- The initialization `current` $\\leftarrow A[1]$ and `maxSoFar` $\\leftarrow A[1]$ correctly sets up the base case for $i=1$. `current` holds $C(1)$, and `maxSoFar` holds the maximum sum seen so far, which is also $C(1)$.\n- The loop iterates from $i=2$ to $n$.\n- The update `current` $\\leftarrow \\max(A[i], \\text{current} + A[i])$ is precisely the recurrence $C(i) = \\max(A[i], C(i-1) + A[i])$.\n- The update `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$ correctly maintains the overall maximum found across all subarray ending positions considered so far ($M = \\max_{1 \\le j \\le i} C(j)$).\nLet's test with $A = \\langle -3, -5, -2 \\rangle$:\n- Initial state: `current` $\\leftarrow -3$, `maxSoFar` $\\leftarrow -3$. The loop runs for $i=2, 3$.\n- For $i=2$, $A[2]=-5$: `current` $\\leftarrow \\max(-5, -3 + (-5)) = \\max(-5, -8) = -5$. `maxSoFar` $\\leftarrow \\max(-3, -5) = -3$.\n- For $i=3$, $A[3]=-2$: `current` $\\leftarrow \\max(-2, -5 + (-2)) = \\max(-2, -7) = -2$. `maxSoFar` $\\leftarrow \\max(-3, -2) = -2$.\nThe algorithm returns $-2$, which is correct. This version is the standard, robust formulation of Kadane's algorithm and works for all inputs. The time complexity is $\\mathcal{O}(n)$ due to the single pass, and the space complexity is $\\mathcal{O}(1)$.\n\n**Verdict: Correct.**\n\n**C. Before the main loop, check if all elements of $A$ are negative; if so, return $\\max_{1 \\le i \\le n} A[i]$. Otherwise, run the original pseudo-code as given.**\n\nThis modification attempts to \"patch\" the original algorithm by handling its specific failure case.\n- **Analysis of the patch**: The original algorithm fails if and only if the maximum subarray sum is a negative number. This occurs if and only if all elements in the array $A$ are negative. In this situation, any subarray sum will be negative. To maximize the sum, one must choose the single element that is the \"least negative,\" i.e., the maximum element of the array. The proposed check `if all elements of A are negative, return max_{1 \\le i \\le n} A[i]` correctly handles this case. This check and the subsequent search for the maximum take $\\mathcal{O}(n)$ time.\n- **Analysis of the \"otherwise\" case**: If the condition is false, it means there is at least one non-negative element in $A$. In this case, the maximum subarray sum must be greater than or equal to $0$ (since we can at least form a subarray with a single non-negative element). The original algorithm, which finds the maximum subarray sum allowing for an empty subarray (sum $0$), will produce the correct non-negative answer in this scenario. It correctly finds positive maximums, and if the maximum is $0$, it will also find $0$. Its only failure is returning $0$ for a negative true maximum. Since this case is now excluded, the original algorithm works correctly.\nThe total time complexity is $\\mathcal{O}(n)$ for the check plus $\\mathcal{O}(n)$ for one of the branches, resulting in $\\mathcal{O}(n)$. The space complexity is $\\mathcal{O}(1)$. This combined procedure is correct for all inputs.\n\n**Verdict: Correct.**\n\n**D. Replace the update `current` $\\leftarrow \\max(0, \\text{current} + x)$ with `current` $\\leftarrow \\max(0, x)$, leaving the rest unchanged.**\n\nThe modified pseudo-code is:\n- Initialize `maxSoFar` $\\leftarrow 0$ and `current` $\\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set `current` $\\leftarrow \\max(0, x)$.\n  - Set `maxSoFar` $\\leftarrow \\max(\\text{maxSoFar}, \\text{current})$.\n- Return `maxSoFar`.\n\nThis algorithm no longer computes subarray sums. In each step, `current` becomes $x$ if $x > 0$ and $0$ otherwise. `maxSoFar` then tracks the maximum value that `current` has taken. This procedure is equivalent to finding the maximum of $0$ and all elements in the array: $\\max(0, \\max_{x \\in A} x)$.\nLet's test this with a mixed array $A = \\langle -2, 1, -3, 4, -1, 2, 1, -5, 4 \\rangle$. The correct answer is $6$ (from the subarray $\\langle 4, -1, 2, 1 \\rangle$).\nThis algorithm would compute $\\max(0, -2, 1, -3, 4, -1, 2, 1, -5, 4) = 4$. It fails to sum consecutive elements.\n\n**Verdict: Incorrect.**\n\n**E. Replace every occurrence of $\\max$ in the pseudo-code with $\\min$, leaving everything else unchanged.**\n\nThe modified pseudo-code becomes:\n- Initialize `maxSoFar` $\\leftarrow 0$ and `current` $\\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set `current` $\\leftarrow \\min(0, \\text{current} + x)$.\n  - Set `maxSoFar` $\\leftarrow \\min(\\text{maxSoFar}, \\text{current})$.\n- Return `maxSoFar`.\n\nThe problem asks to *maximize* the subarray sum. This modification changes the objective to a minimization problem (specifically, finding the minimum subarray sum, allowing for an empty subarray of sum $0$). It does not solve the stated problem. For $A = \\langle -3, -5, -2 \\rangle$, the maximum subarray sum is $-2$. This algorithm would produce:\n- Initial state: `maxSoFar` $\\leftarrow 0$, `current` $\\leftarrow 0$.\n- For $x = -3$: `current` $\\leftarrow \\min(0, 0 + (-3)) = -3$. `maxSoFar` $\\leftarrow \\min(0, -3) = -3$.\n- For $x = -5$: `current` $\\leftarrow \\min(0, -3 + (-5)) = -8$. `maxSoFar` $\\leftarrow \\min(-3, -8) = -8$.\n- For $x = -2$: `current` $\\leftarrow \\min(0, -8 + (-2)) = -10$. `maxSoFar` $\\leftarrow \\min(-8, -10) = -10$.\nThe algorithm returns $-10$, which is the minimum subarray sum, not the maximum.\n\n**Verdict: Incorrect.**", "answer": "$$\\boxed{BC}$$", "id": "3205797"}]}