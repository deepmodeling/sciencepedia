{"hands_on_practices": [{"introduction": "The first step in mastering the Aho-Corasick automaton is to implement its core logic for finding multiple patterns simultaneously. A key feature is how its failure links enable the detection of patterns that are suffixes of other, longer patterns. This exercise [@problem_id:3204919] solidifies this foundational concept by challenging you to maintain a running count of all pattern occurrences, which requires a precise implementation of the output propagation rule along the failure link chains.", "problem": "You are given a set of finite strings and a longer text over a finite alphabet. The goal is to design and implement a program that constructs the Aho–Corasick automaton (AC automaton) and modifies its output behavior so that, while scanning the text from left to right one symbol at a time, it maintains a running count for each pattern’s total number of occurrences found so far. At specified checkpoints after processing prefixes of the text, the program must output the current vector of counts aligned with the input pattern order.\n\nStart from the following formal and widely used foundations:\n- The definition of a trie of a finite set of strings, where each node corresponds to a unique prefix of at least one string, and edges are labeled by single symbols from the alphabet.\n- The construction of the failure function for the trie as in a finite-state automaton for multi-pattern matching: for each node, the failure link points to the longest proper suffix of the node’s string-label that is also a prefix of at least one pattern.\n- The output function mapping a node to the set of pattern indices that end at that node.\n- The standard breadth-first search (BFS) procedure for computing failure links in linear time in the total length of the patterns.\n\nYour program must:\n- Build the trie on the given set of patterns in their input order. Let the number of patterns be $m \\ge 1$, and let the total length of all patterns be $L = \\sum_{i=1}^{m} |P_i|$, where $P_i$ denotes the $i$-th pattern and $|\\cdot|$ denotes string length. Assume every pattern is non-empty.\n- Compute failure links by processing the trie in breadth-first order. For each node, augment its output set by including the output sets of its failure-linked nodes to ensure that suffix matches are reported at the same step the automaton enters a node.\n- Process the text $T$ of length $n \\ge 0$ left to right. After reading the $k$-th character (so the prefix length is $k$), update the running count vector $C \\in \\mathbb{N}^m$ by incrementing $C_i$ by $1$ for each pattern $P_i$ that ends at the current automaton state’s output set. Overlapping occurrences must be counted, and multiple patterns can match at the same position.\n- At specified checkpoints, each equal to some $k$ with $1 \\le k \\le n$, record a snapshot of the current $C$ as a list of $m$ non-negative integers in the original pattern order.\n\nInput is not read from standard input. Instead, your program must internally run the following test suite and aggregate the results.\n\nTest Suite:\n- Test Case $1$:\n  - Patterns $P = [\\text{\"a\"}, \\text{\"ab\"}, \\text{\"bab\"}, \\text{\"bc\"}, \\text{\"bca\"}, \\text{\"c\"}, \\text{\"caa\"}]$.\n  - Text $T = \\text{\"abccab\"}$ of length $n = 6$.\n  - Checkpoints at prefix lengths $[1, 3, 6]$.\n  - The result for this case is the list of snapshots at these checkpoints, each snapshot being the $m$-length list of counts $C$.\n- Test Case $2$:\n  - Patterns $P = [\\text{\"aa\"}, \\text{\"aaa\"}]$.\n  - Text $T = \\text{\"aaaaa\"}$ with $n = 5$.\n  - Checkpoints $[1, 2, 3, 4, 5]$.\n- Test Case $3$:\n  - Patterns $P = [\\text{\"he\"}, \\text{\"she\"}, \\text{\"his\"}, \\text{\"hers\"}]$.\n  - Text $T = \\text{\"ushers\"}$ with $n = 6$.\n  - Single checkpoint $[6]$.\n- Test Case $4$:\n  - Patterns $P = [\\text{\"xyz\"}, \\text{\"q\"}]$.\n  - Text $T = \\text{\"aaaa\"}$ with $n = 4$.\n  - Single checkpoint $[4]$.\n- Test Case $5$:\n  - Patterns $P = [\\text{\"aba\"}, \\text{\"ba\"}]$.\n  - Text $T = \\text{\"ababa\"}$ with $n = 5$.\n  - Checkpoints $[2, 5]$.\n\nYour program must output a single line containing the aggregated results for the test suite as a single list whose elements are the per-test-case results, in test-case order. Each per-test-case result is a list of snapshots, and each snapshot is a list of integers in the order of the input patterns for that test case. The required final output format is a single line with no whitespace characters, representing the nested lists using only square brackets and commas. Concretely, your program should print a single line of the form $[\\text{R}_1,\\text{R}_2,\\dots,\\text{R}_t]$, where $\\text{R}_j$ is the nested list result for test case $j$ and $t$ is the number of test cases.\n\nAnswers are purely integer lists; no physical units or angles are involved. Ensure that your implementation correctly handles overlapping matches and suffix-linked outputs within the automaton and that it runs in time linear in $|T| + L$ for each test case.", "solution": "The user has provided a well-defined computational problem from the field of data structures and algorithms, requiring the implementation of the Aho-Corasick automaton for multi-pattern string matching. The problem statement is validated as follows:\n\n-   **Scientific or Factual Soundness**: The problem is grounded in the established theory of finite automata and string algorithms. The Aho-Corasick automaton is a standard, sound computer science model. The problem statement accurately describes its components and construction (trie, failure links, output function). No scientific or factual errors are present.\n-   **Well-Posedness**: The problem is well-posed. It provides specific inputs (patterns, text, checkpoints) and requests a clear, deterministic output (a vector of running counts at specified times). The rules for counting, including the handling of overlapping matches and matches of suffixes (via failure links), are explicitly defined, ensuring that a unique and meaningful solution exists.\n-   **Objectivity**: The problem is stated in formal, objective language. All inputs and expected outputs are quantitative and free of ambiguity or subjective interpretation.\n-   **Completeness and Consistency**: The problem provides all necessary information for each test case—patterns, text, and checkpoint locations. The requirements for the algorithm's construction and behavior are internally consistent and complete.\n-   **Feasibility**: The scale of the provided test cases is small, making the problem computationally feasible within typical time limits. The required linear time complexity is the known optimal performance for the Aho-Corasick algorithm, confirming the problem's theoretical grounding.\n\nThe problem is deemed valid as it satisfies all criteria for a formal, solvable scientific problem. The following solution implements the Aho-Corasick algorithm as specified.\n\n### Algorithmic Design\n\nThe solution is divided into two main phases: automaton construction and text processing.\n\n1.  **Automaton Construction**:\n    -   **Trie Construction**: First, a trie (prefix tree) is built from the set of input patterns. Each node in the trie represents a unique prefix of one or more patterns. The root node represents the empty string. Each edge is labeled with a character. A node corresponding to the end of a pattern $P_i$ stores the index $i$ in its `output` set.\n        -   We represent the automaton as a list of nodes, where each node is a dictionary containing its `transitions` (a map from a character to a child node's index), an `output` list (pattern indices), and a `failure_link` (index of another node).\n        -   The trie is built by iterating through each pattern and, for each character, traversing from the root and adding new nodes as necessary.\n\n    -   **Failure Link and Output Propagation**: After the trie is built, failure links are computed. For any state $s$ corresponding to a string $w$, its failure link points to the state corresponding to the longest proper suffix of $w$ that is also a prefix of some pattern in the set.\n        -   These links are computed efficiently using a Breadth-First Search (BFS) starting from the nodes at depth $1$. For a node $v$ reached from its parent $u$ via character $c$, we find its failure link by following the failure link of $u$ to a state $f$ and checking if $f$ has a transition for $c$. If not, we repeat with the failure link of $f$, until we find such a transition or reach the root.\n        -   A critical step, as required by the problem, is augmenting the output sets. The output set of a node $v$ is extended to include all outputs from the node its failure link points to. This ensures that if we match a string like `\"she\"`, we also report the match for its suffix `\"he\"`, if `\"he\"` is in the pattern set. This propagation is also done during the BFS.\n\n2.  **Text Processing and Counting**:\n    -   The input text $T$ is processed one character at a time. The automaton maintains a `current_state`, initially the root.\n    -   For each character $c$ from the text, the automaton attempts to transition from the `current_state`. If a transition for $c$ exists, it is taken. If not, the automaton follows the `current_state`'s failure link and retries the transition. This process is repeated until a transition is found or the root state is reached. If the root is reached and has no transition for $c$, the `current_state` remains the root.\n    -   After each transition, the `current_state` represents the longest string ending at the current position in the text that is also a prefix of some pattern.\n    -   The `output` set of this `current_state` contains the indices of all patterns that end at this position. For each pattern index in the `output` set, the corresponding entry in a `counts` vector $C$ is incremented.\n    -   At each specified checkpoint, which corresponds to the number of characters processed so far, a snapshot of the current `counts` vector is recorded.\n\nThis design guarantees that all occurrences, including overlapping ones and those found via suffixes, are counted correctly, and the overall time complexity is linear in the sum of the pattern lengths and the text length, i.e., $O(L+n)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to run the Aho-Corasick algorithm on a suite of test cases.\n    It builds the automaton, processes the text, and collects results\n    as per the problem specification.\n    \"\"\"\n    \n    # Helper function to format the final output list without spaces.\n    def format_list_no_spaces(data):\n        if isinstance(data, list):\n            return f\"[{','.join(format_list_no_spaces(item) for item in data)}]\"\n        else:\n            return str(data)\n\n    def build_automaton(patterns):\n        \"\"\"\n        Builds the Aho-Corasick automaton (trie, failure links, and output propagation).\n        \"\"\"\n        # The automaton is a list of nodes.\n        # Each node is a dict: {'transitions': {}, 'output': [], 'failure_link': 0}\n        nodes = [{'transitions': {}, 'output': [], 'failure_link': 0}]\n        \n        # 1. Build the basic trie structure.\n        for i, pattern in enumerate(patterns):\n            node_idx = 0\n            for char in pattern:\n                if char not in nodes[node_idx]['transitions']:\n                    new_node_idx = len(nodes)\n                    nodes[node_idx]['transitions'][char] = new_node_idx\n                    nodes.append({'transitions': {}, 'output': [], 'failure_link': 0})\n                node_idx = nodes[node_idx]['transitions'][char]\n            nodes[node_idx]['output'].append(i)\n\n        # 2. Compute failure links and propagate outputs using BFS.\n        queue = collections.deque()\n        # Start BFS with all nodes at depth 1. Their failure links point to the root (0).\n        for node_idx in nodes[0]['transitions'].values():\n            queue.append(node_idx)\n            # The failure link is already 0 by default, so no explicit set needed here.\n\n        while queue:\n            current_idx = queue.popleft()\n            \n            for char, next_idx in nodes[current_idx]['transitions'].items():\n                queue.append(next_idx)\n                \n                # Find failure link for next_idx.\n                fail_idx = nodes[current_idx]['failure_link']\n                while char not in nodes[fail_idx]['transitions'] and fail_idx != 0:\n                    fail_idx = nodes[fail_idx]['failure_link']\n                \n                if char in nodes[fail_idx]['transitions']:\n                    nodes[next_idx]['failure_link'] = nodes[fail_idx]['transitions'][char]\n                else:\n                    # If we reach the root and still no transition, failure link is root.\n                    nodes[next_idx]['failure_link'] = 0\n                \n                # Propagate output from the failure node.\n                fail_output_idx = nodes[next_idx]['failure_link']\n                nodes[next_idx]['output'].extend(nodes[fail_output_idx]['output'])\n        \n        return nodes\n\n    def run_search(automaton, text, num_patterns, checkpoints):\n        \"\"\"\n        Processes the text using the automaton and records counts at checkpoints.\n        \"\"\"\n        checkpoints_set = set(checkpoints)\n        snapshots = []\n        counts = np.zeros(num_patterns, dtype=int)\n        current_state_idx = 0\n\n        for k, char in enumerate(text, 1):\n            # Follow failure links until a transition is found or we are at the root.\n            while char not in automaton[current_state_idx]['transitions'] and current_state_idx != 0:\n                current_state_idx = automaton[current_state_idx]['failure_link']\n            \n            # If a transition for the character exists, take it. Otherwise, stay at root.\n            current_state_idx = automaton[current_state_idx]['transitions'].get(char, 0)\n            \n            # Collect all outputs from the current state.\n            if automaton[current_state_idx]['output']:\n                for pattern_idx in automaton[current_state_idx]['output']:\n                    counts[pattern_idx] += 1\n            \n            # Record a snapshot if the current position is a checkpoint.\n            if k in checkpoints_set:\n                snapshots.append(counts.tolist())\n        \n        return snapshots\n\n    # The test suite provided in the problem statement.\n    test_cases = [\n        (\n            [\"a\", \"ab\", \"bab\", \"bc\", \"bca\", \"c\", \"caa\"],\n            \"abccab\",\n            [1, 3, 6]\n        ),\n        (\n            [\"aa\", \"aaa\"],\n            \"aaaaa\",\n            [1, 2, 3, 4, 5]\n        ),\n        (\n            [\"he\", \"she\", \"his\", \"hers\"],\n            \"ushers\",\n            [6]\n        ),\n        (\n            [\"xyz\", \"q\"],\n            \"aaaa\",\n            [4]\n        ),\n        (\n            [\"aba\", \"ba\"],\n            \"ababa\",\n            [2, 5]\n        )\n    ]\n\n    all_results = []\n    for patterns, text, checkpoints in test_cases:\n        num_patterns = len(patterns)\n        automaton = build_automaton(patterns)\n        snapshots = run_search(automaton, text, num_patterns, checkpoints)\n        all_results.append(snapshots)\n    \n    # Final print statement in the exact required format.\n    print(format_list_no_spaces(all_results))\n\nsolve()\n\n```", "id": "3204919"}, {"introduction": "Once the basic matching mechanism is clear, we can enhance the automaton for more specialized tasks. In many applications, we are interested in finding the most significant match at a given position, rather than all possible matches. This practice [@problem_id:3204893] asks you to modify the automaton to report only the single longest pattern, a task that reveals the power of augmenting the automaton's states with pre-computed information during its construction.", "problem": "Consider a finite alphabet $\\Sigma$, a finite set of patterns $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$ over $\\Sigma$, with $|p_j|$ denoting the length of pattern $p_j$, and a text $T$ of length $n$ over $\\Sigma$. The Aho–Corasick automaton is constructed upon three core components derived from foundational definitions in data structures and algorithms: a trie (prefix tree) capturing all patterns, a failure function that maps each trie node to the longest proper suffix state that is also a prefix in the trie, and an output function that associates each state with the set of patterns that terminate at that state. The standard Aho–Corasick automaton enables simultaneous multi-pattern matching by scanning $T$ left-to-right, following trie transitions and failure transitions, and reporting occurrences whenever the output set of the current state is nonempty.\n\nYour task is to design and implement a complete program that constructs the Aho–Corasick automaton for a given set of patterns and then modifies the output reporting mechanism so that, when scanning the text $T$, at any position $i$ (where $0 \\le i \\le n-1$) the automaton reports only the single longest pattern among all patterns that end at position $i$. If more than one pattern shares this maximal length at position $i$, break ties by choosing the pattern with the smallest original index in $P$ (using $0$-based indexing). The reporting order must be the chronological order of positions in $T$ (from $i = 0$ to $i = n-1$): at each position where at least one pattern ends, append exactly one index (the selected pattern index) to the output sequence; at positions with no pattern ending, append nothing.\n\nBegin from the following context-appropriate fundamental base:\n- The trie is a rooted tree over $\\Sigma$ such that every edge is labeled by a character in $\\Sigma$, and each pattern $p_j$ is inserted by following or creating edges corresponding to its characters. The terminal node of $p_j$ stores $j$ in its output set.\n- The failure function is constructed via Breadth-First Search (BFS) over the trie: the failure of a node corresponds to the longest proper suffix of the string represented by the node that appears as a prefix in the trie. This ensures that, upon a mismatch during scanning, the automaton can transition to a shorter, valid state without re-reading input.\n- The output function at a node is the union of its terminal pattern indices and the outputs of its failure state, ensuring that all patterns that end at the current position are reported.\n\nYou must derive the modified reporting mechanism strictly from these base definitions, without invoking any external shortcut formulas. The modification must preserve the asymptotic time complexity of scanning, which should remain linear in the text length $n$ plus the total size of the automaton. Implement this preservation by an appropriate precomputation so that selecting the single longest pattern per position does not introduce superlinear overhead in the number of matches.\n\nProgram requirements:\n1. Construct the Aho–Corasick automaton for the provided test suite patterns using the above principles. Let $\\ell_j = |p_j|$ be the length of pattern $p_j$.\n2. Define the modified output semantics as follows. If $out(q)$ is the set of pattern indices associated with the current automaton state $q$ after processing text position $i$, report only\n   $$\\boxed{ j^\\star = \\min\\left\\{ j \\in out(q) \\,:\\, \\ell_j = \\max_{k \\in out(q)} \\ell_k \\right\\} }$$\n   and append $j^\\star$ to the result sequence. If $out(q)$ is empty, append nothing for that $i$.\n3. Ensure that the selection of $j^\\star$ at runtime is $\\mathcal{O}(1)$ amortized per position by suitable precomputation rooted in the trie and failure function.\n4. For each test case, output the sequence of reported pattern indices (in chronological order across the text).\n\nTest suite:\n- Test case $1$: $P = [$\"he\", \"she\", \"his\", \"hers\"$]$, $T =$ \"ushers\".\n- Test case $2$: $P = [$\"a\", \"aa\", \"aaa\"$]$, $T =$ \"aaaaa\".\n- Test case $3$: $P = [$\"aba\", \"aba\", \"ba\"$]$, $T =$ \"caba\". This includes duplicated patterns to validate the tie-breaking rule by smallest index.\n- Test case $4$: $P = [$\"xyz\"$]$, $T =$ \"abc\".\n- Test case $5$: $P = [$\"cat\", \"at\", \"t\"$]$, $T =$ \"catcat\".\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and must itself be a bracketed, comma-separated list of integers with no spaces. For example, the outermost structure must look like\n$$ [ [\\dots], [\\dots], [\\dots], [\\dots], [\\dots] ] $$\nwith no spaces anywhere, such as $[[0,2],[1],[\\,],\\dots]$ where $[\\,]$ denotes an empty list. The program must be self-contained and require no input. The output must be computed for exactly the test suite given above.", "solution": "The user's request is to design an algorithm based on the Aho-Corasick automaton to find, at each position in a text $T$, the single longest matching pattern, with ties broken by the smallest pattern index. This process must be efficient, with the selection of the best pattern at each position taking $\\mathcal{O}(1)$ amortized time.\n\nThe problem is computationally well-defined, scientifically grounded in the theory of string algorithms, and provides sufficient information for a unique solution. It is therefore deemed valid. The solution proceeds as follows.\n\n### Principle-Based Design\n\nThe problem requires a modification to the standard Aho-Corasick output mechanism. A standard automaton, upon reaching a state $q$, identifies all patterns ending at the current text position by traversing the failure link chain: $q, \\text{failure}(q), \\text{failure}(\\text{failure}(q)), \\dots$, until the root is reached, and collecting all terminal patterns found. This traversal can take super-constant time per text character, violating the performance constraint.\n\nTo achieve $\\mathcal{O}(1)$ amortized lookup, we must precompute the optimal output for each state of the automaton. Let us define a `best_match` pair $(\\ell, j)$ for each state, where $\\ell$ is the length of the best pattern and $j$ is its original index. The problem defines \"best\" as the pattern with maximum length, breaking ties with the minimum index. A pair $(\\ell_1, j_1)$ is better than $(\\ell_2, j_2)$ if $\\ell_1 > \\ell_2$ or if $(\\ell_1 = \\ell_2 \\text{ and } j_1 < j_2)$.\n\nThe solution is structured into three main phases:\n1. Construction of the trie and failure function, which are standard components of the Aho-Corasick automaton.\n2. Precomputation of the `best_match` for every state.\n3. Scanning the text to find matches using the precomputed data.\n\n#### 1. Automaton Construction (Trie and Failure Links)\n\nFirst, we construct a trie from the set of patterns $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$. The trie is a rooted tree where each edge is labeled with a character from the alphabet $\\Sigma$. Each pattern $p_j$ corresponds to a unique path from the root. The node reached at the end of the path for $p_j$ is a terminal node, where we store its identity—specifically, its length $|p_j|$ and its index $j$.\n\nNext, we compute the failure function, $\\text{failure}(q)$, for each state $q$. The failure function maps a state $q$ (representing a prefix $s$) to the state representing the longest proper suffix of $s$ that is also a prefix in the trie. This is constructed using a Breadth-First Search (BFS) starting from the root. The failure link of the root is itself. For any other state $q$ reached from its parent $p$ via character $c$, its failure link is found by traversing the failure links of $p$ until a state with a transition on $c$ is found.\n\n#### 2. Precomputation of the Best Match\n\nThe key insight is that the set of all patterns matching at a state $q$, denoted $\\text{out}(q)$, is the union of patterns ending exactly at $q$ (let's call this set $\\text{terminal}(q)$) and the set of patterns matching at its failure state, $\\text{out}(\\text{failure}(q))$.\n$$ \\text{out}(q) = \\text{terminal}(q) \\cup \\text{out}(\\text{failure}(q)) $$\n\nThis recursive definition allows us to compute the `best_match` for each state using dynamic programming. Let $\\text{best_match}(q)$ be the best matching pair $(\\ell, j)$ from the set $\\text{out}(q)$. Let $\\text{term_best}(q)$ be the best matching pair from just the patterns in $\\text{terminal}(q)$. Then:\n$$ \\text{best_match}(q) = \\text{better_of}(\\text{term_best}(q), \\text{best_match}(\\text{failure}(q))) $$\n\nWe can compute $\\text{best_match}(q)$ for all states $q$ in the automaton. Since $\\text{failure}(q)$ always points to a state at a strictly smaller depth in the trie, we can compute the $\\text{best_match}$ values for all states in a single BFS traversal. During the BFS, when we process a state $q$, the value for $\\text{best_match}(\\text{failure}(q))$ will have already been computed.\nThe algorithm is as follows:\n1. Initialize $\\text{best_match}(q) = (-1, -1)$ for all states $q$.\n2. For each state $q$, compute $\\text{term_best}(q)$ from the patterns in $\\text{terminal}(q)$. This involves finding the maximum length among terminal patterns and then the minimum index for that length.\n3. Perform a BFS over the trie states. For each state $q$ visited:\n    a. Let $f = \\text{failure}(q)$.\n    b. The best match from the failure chain is $\\text{best_match}(f)$.\n    c. Update $\\text{best_match}(q)$ to be the better of its own $\\text{term_best}(q)$ and $\\text{best_match}(f)$.\n\n#### 3. Text Scanning\n\nWith the `best_match` array precomputed, scanning the text $T$ becomes highly efficient. We traverse the automaton based on the characters of $T$.\n1. Start at the root state, $q_{current} = 0$.\n2. For each character $c$ in $T$:\n    a. Find the next state by following the transition for $c$. If no direct transition exists from $q_{current}$, follow failure links until a transition is found or the root is reached. This is the standard Aho-Corasick state transition logic, which has an amortized constant time complexity. Let the new state be $q_{next}$.\n    b. Update $q_{current} \\leftarrow q_{next}$.\n    c. Look up the precomputed `best_match` for $q_{current}$: $(\\ell, j) = \\text{best_match}(q_{current})$.\n    d. If a valid match exists (i.e., $\\ell \\neq -1$), append the index $j$ to the result sequence.\n\nThis procedure ensures that at each position $i$ in the text, we find the single best matching pattern in $\\mathcal{O}(1)$ amortized time, as it only requires a single array lookup after the state transition. The total time complexity for scanning is $\\mathcal{O}(n)$, where $n=|T|$. The overall complexity of the algorithm is dominated by the construction and precomputation phases, which is $\\mathcal{O}(\\sum_{j=0}^{m-1} |p_j|)$, plus the scanning time.\n\nThis approach correctly implements the required modification while preserving the linear time complexity characteristic of the Aho-Corasick algorithm.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Aho-Corasick longest pattern problem for a suite of test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An implementation of the Aho-Corasick automaton with a modified output\n        mechanism to report only the longest pattern at each position.\n        \"\"\"\n        def __init__(self, patterns):\n            \"\"\"\n            Initializes the automaton from a list of patterns.\n            Args:\n                patterns (list of str): The patterns to search for.\n            \"\"\"\n            self._patterns = patterns\n            \n            # Trie nodes are represented as dicts\n            # 'children': mapping from char to child node index\n            # 'fail': index of the failure link node\n            # 'terminal': list of (length, index) tuples for patterns ending here\n            self._nodes = [{'children': {}, 'fail': 0, 'terminal': []}]\n            \n            # Stores the best match (length, index) for each state, considering failure links\n            self._best_match = [(-1, -1)]\n\n            self._build_trie()\n            self._build_failure_links_and_best_matches()\n\n        def _build_trie(self):\n            \"\"\"Builds the initial trie from the patterns.\"\"\"\n            for i, pattern in enumerate(self._patterns):\n                node_idx = 0\n                for char in pattern:\n                    node = self._nodes[node_idx]\n                    if char not in node['children']:\n                        node['children'][char] = len(self._nodes)\n                        self._nodes.append({'children': {}, 'fail': 0, 'terminal': []})\n                        self._best_match.append((-1, -1))\n                    node_idx = node['children'][char]\n                self._nodes[node_idx]['terminal'].append((len(pattern), i))\n\n        def _build_failure_links_and_best_matches(self):\n            \"\"\"\n            Computes failure links and precomputes the best match for each state\n            using a single Breadth-First Search (BFS) traversal.\n            \"\"\"\n            queue = []\n            # Initialize queue with children of the root (depth 1)\n            for child_idx in self._nodes[0]['children'].values():\n                queue.append(child_idx)\n\n            head = 0\n            while head < len(queue):\n                node_idx = queue[head]\n                head += 1\n\n                # Compute failure link for node_idx's children\n                for char, child_idx in self._nodes[node_idx]['children'].items():\n                    fail_idx = self._nodes[node_idx]['fail']\n                    while char not in self._nodes[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self._nodes[fail_idx]['fail']\n                    \n                    if char in self._nodes[fail_idx]['children']:\n                        self._nodes[child_idx]['fail'] = self._nodes[fail_idx]['children'][char]\n                    else: # fail_idx is root and has no transition for char\n                        self._nodes[child_idx]['fail'] = 0\n                    \n                    queue.append(child_idx)\n\n                # --- Precompute best match for the current node_idx ---\n                \n                # Best match from patterns ending exactly at this node\n                term_best = (-1, -1)\n                if self._nodes[node_idx]['terminal']:\n                    # Find max length first\n                    max_len = 0\n                    for l, _ in self._nodes[node_idx]['terminal']:\n                        if l > max_len:\n                            max_len = l\n                    \n                    # Find min index for that max length\n                    min_idx = float('inf')\n                    for l, i in self._nodes[node_idx]['terminal']:\n                        if l == max_len and i < min_idx:\n                            min_idx = i\n                    term_best = (max_len, min_idx)\n                \n                # Best match from the failure link chain\n                fail_idx = self._nodes[node_idx]['fail']\n                fail_best = self._best_match[fail_idx]\n\n                # The best match for this state is the better of its own terminal\n                # and the one inherited from its failure state.\n                l1, i1 = term_best\n                l2, i2 = fail_best\n                if l1 > l2:\n                    self._best_match[node_idx] = term_best\n                elif l2 > l1:\n                    self._best_match[node_idx] = fail_best\n                elif l1 != -1: # l1 == l2\n                    self._best_match[node_idx] = (l1, min(i1, i2))\n                else: # Both are (-1,-1)\n                    self._best_match[node_idx] = (-1, -1)\n\n        def search(self, text):\n            \"\"\"\n            Scans the text and reports the best match at each position.\n            Args:\n                text (str): The text to scan.\n            Returns:\n                list of int: A list of the indices of the best matching patterns found.\n            \"\"\"\n            current_node_idx = 0\n            results = []\n            \n            for char in text:\n                while char not in self._nodes[current_node_idx]['children'] and current_node_idx != 0:\n                    current_node_idx = self._nodes[current_node_idx]['fail']\n                \n                if char in self._nodes[current_node_idx]['children']:\n                    current_node_idx = self._nodes[current_node_idx]['children'][char]\n                # If still no transition (i.e., we are at the root), current_node_idx remains 0.\n\n                match = self._best_match[current_node_idx]\n                if match[0] != -1:\n                    results.append(match[1])\n\n            return results\n    \n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"ushers\"}),\n        ({\"patterns\": [\"a\", \"aa\", \"aaa\"], \"text\": \"aaaaa\"}),\n        ({\"patterns\": [\"aba\", \"aba\", \"ba\"], \"text\": \"caba\"}),\n        ({\"patterns\": [\"xyz\"], \"text\": \"abc\"}),\n        ({\"patterns\": [\"cat\", \"at\", \"t\"], \"text\": \"catcat\"}),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        patterns = case[\"patterns\"]\n        text = case[\"text\"]\n        \n        automaton = AhoCorasick(patterns)\n        result = automaton.search(text)\n        all_results.append(result)\n\n    # Format output as a single string: [[1,3],[0,1,2,2,2],[0],[],[0,0]]\n    # No spaces are allowed in the output.\n    results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "3204893"}, {"introduction": "Real-world text processing often demands flexibility, such as handling case-insensitive searches. A naive approach would involve adding every case variation of a pattern to the trie, which is highly inefficient. This practice [@problem_id:3205013] introduces a more elegant and fundamental algorithmic technique: normalization. By transforming both patterns and text into a canonical form (e.g., all lowercase), you can apply the standard Aho-Corasick algorithm to solve a seemingly more complex problem efficiently.", "problem": "You are given a finite set of patterns over a finite alphabet and a text. The task is to perform multiple-pattern exact matching under case-insensitive semantics, without explicitly storing every case variation of letters in the underlying trie. Formally, let the alphabet be denoted by $\\Sigma$, and let $P = \\{p_1, p_2, \\dots, p_k\\}$ be a set of patterns where each $p_i \\in \\Sigma^{*}$, and let the text be $T \\in \\Sigma^{*}$. Consider the mapping $\\phi : \\Sigma \\rightarrow \\Sigma$ defined on the standard $7$-bit American Standard Code for Information Interchange (ASCII) as follows: for any character $c \\in \\Sigma$, if $c$ is an uppercase English letter then $\\phi(c)$ is its lowercase counterpart, and otherwise $\\phi(c) = c$. Extend $\\phi$ to strings by homomorphism, i.e., for any string $s = c_1 c_2 \\cdots c_n$, define $\\phi(s) = \\phi(c_1)\\phi(c_2)\\cdots\\phi(c_n)$. Under case-insensitive semantics, a pattern $p$ is said to occur in $T$ at position $i$ if and only if $\\phi(p)$ occurs in $\\phi(T)$ at position $i$. An occurrence contributes $1$ to the total count for that pattern.\n\nFundamental base and constraints to use in your reasoning and design:\n- Strings are sequences over $\\Sigma$ and are compared by equality of symbols.\n- A trie is a rooted tree keyed by symbols of $\\Sigma$ such that each edge from a node is labeled by a symbol and root-to-node label sequences are unique.\n- The Aho–Corasick automaton is obtained by augmenting the trie with failure links defined via the longest proper suffix that is also a prefix in the trie, and an output function per node that lists patterns ending at that node. It supports simultaneous pattern matching in time linear in the length of the text plus the number of matches when the alphabet is fixed.\n- You must not store all case variations of the same letter explicitly in the trie. Instead, reason from the above fundamentals and the mapping $\\phi$ to construct an automaton over a reduced effective alphabet while still reporting occurrences for all original patterns in $P$.\n\nYour task:\n- Design and implement a program that constructs an automaton capable of reporting the total number of pattern occurrences in $T$ under the case-insensitive semantics induced by $\\phi$, without duplicating case-variant edges in the trie. The automaton must be constructed over the canonical alphabet induced by $\\phi$, and the output function must account for the fact that multiple distinct original patterns in $P$ may normalize to the same string under $\\phi$.\n- Correctness requirement: every occurrence of any $p_i \\in P$ in $T$ under case-insensitive matching must be counted, including overlaps. If two distinct patterns $p_i$ and $p_j$ satisfy $\\phi(p_i) = \\phi(p_j)$, then a single occurrence of $\\phi(p_i)$ in $\\phi(T)$ contributes $1$ for $p_i$ and $1$ for $p_j$, i.e., counted twice.\n\nComplexity objective:\n- Ensure that building the automaton is asymptotically linear in $\\sum_{i=1}^{k} |p_i|$ with respect to the size of the constructed trie, and that scanning the text is linear in $|T|$ plus the number of matches. Avoid any approach that inserts both uppercase and lowercase variants of the same letter into the trie.\n\nTest suite:\nImplement your program to compute the total number of matches for each of the following test cases. Each test case is a pair $(P, T)$ where $P$ is the pattern list and $T$ is the text string.\n- Test case $1$: $P = [$\"he\", \"she\", \"his\", \"hers\"$]$, $T =$ \"aHiShErS\".\n- Test case $2$: $P = [$\"Ab\", \"aB\", \"AB\", \"ab\"$]$, $T =$ \"xxAbYYaBzz\".\n- Test case $3$: $P = [$\"a\", \"aa\"$]$, $T =$ \"AaA\".\n- Test case $4$: $P = [$\"C++\", \"c+\"$]$, $T =$ \"C++C+\".\n- Test case $5$: $P = [$\"Test\"$]$, $T =$ \"\" (the empty string).\n\nOutput specification:\n- For each test case, compute a single integer equal to the total number of matches across all patterns in $P$, counting overlaps and counting each pattern separately even if multiple patterns normalize to the same $\\phi$-image.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\"[r_1,r_2,\\dots]\"$), in the order of the test cases $1$ through $5$.\n\nNo physical units, angles, or percentages are involved in this problem. Ensure that the solution is derived from the provided fundamental definitions and facts, not from pre-stated shortcut formulas.", "solution": "The problem requires performing case-insensitive multiple-pattern matching using an Aho-Corasick automaton, with the specific constraint that the underlying trie must not store case variations explicitly. This is a classic algorithmic task that involves adapting a standard algorithm to a specific equivalence relation on the alphabet.\n\n### Principle-Based Design\n\nThe solution is founded on the principle of normalization. The problem defines a mapping $\\phi$ that converts uppercase English letters to their lowercase counterparts and leaves other characters unchanged. This mapping induces an equivalence relation on the alphabet $\\Sigma$, where two characters $c_1$ and $c_2$ are equivalent if $\\phi(c_1) = \\phi(c_2)$. This relation extends to strings: two strings $s_1$ and $s_2$ are equivalent if $\\phi(s_1) = \\phi(s_2)$. The matching rule—a pattern $p$ occurs in text $T$ if $\\phi(p)$ occurs in $\\phi(T)$—leverages this equivalence.\n\nInstead of performing searches over the original alphabet $\\Sigma$, we can simplify the problem by working entirely within the canonical alphabet, which is the image of $\\Sigma$ under $\\phi$ (i.e., lowercase letters and non-alphabetic characters). The Aho-Corasick automaton will be constructed and operated upon using these canonical characters.\n\nThe design proceeds in three main stages:\n1.  **Automaton Construction (Build Phase)**: This phase builds the case-insensitive Aho-Corasick automaton from the set of patterns $P$.\n2.  **Text Processing (Search Phase)**: This phase uses the constructed automaton to find all occurrences of the patterns in the text $T$.\n3.  **Correct Counting**: A crucial detail is ensuring that each match is counted correctly according to the problem's specification, especially when multiple original patterns normalize to the same string.\n\n#### 1. Automaton Construction\n\nThe automaton is built upon a trie constructed from the *normalized* patterns, $\\{\\phi(p) \\mid p \\in P\\}$.\n\n**Trie Construction**: We iterate through each pattern $p \\in P$, compute its normalized form $s = \\phi(p)$, and insert $s$ into the trie. The trie nodes represent prefixes of the normalized patterns. Each edge is labeled with a character from the canonical alphabet.\n\n**Output Function**: The problem specifies that if two distinct patterns $p_i$ and $p_j$ normalize to the same string (i.e., $\\phi(p_i) = \\phi(p_j)$), a single match of this normalized string should count for both. To handle this, we associate a `direct_output_count` with each node in the trie. For each pattern $p_i$ from the input set $P$, after traversing the trie along the path for $\\phi(p_i)$ to a node $u$, we increment `direct_output_count[u]` by $1$. This way, `direct_output_count[u]` stores the number of original patterns that normalize to the exact string represented by node $u$.\n\n**Failure Links**: After the trie is built, we add failure links to create the full automaton. A failure link from a node $u$ (representing string $s$) points to the node $v$ representing the longest proper suffix of $s$ that is also a prefix in the trie. These links are essential for linear-time matching, as they allow the automaton to transition gracefully upon a character mismatch without restarting the search from the beginning of the text. The failure links are computed using a Breadth-First Search (BFS) starting from the root's children. For a node $v$ with parent $u$ reached by character $c$, its failure link is found by following the failure link of its parent `fail[u]` and trying to transition on $c$. This process is repeated until a valid transition is found or the root is reached.\n\n**Output Propagation**: A match for a pattern also implies matches for any of its suffixes that are also patterns. For example, matching \"she\" also means we have matched \"he\". To account for this efficiently, we compute an `aggregated_output_count` for each node. This value is the sum of the node's `direct_output_count` and the `aggregated_output_count` of its failure node. This can be calculated during the BFS for failure links, as a node's failure link always points to a node at a shallower depth, which has already been processed. The recurrence is:\n$$\n\\text{aggregated\\_output\\_count}[u] = \\text{direct\\_output\\_count}[u] + \\text{aggregated\\_output\\_count}[\\text{fail}[u]]\n$$\nThis ensures that when the automaton reaches state $u$, we can find the total number of patterns ending at the current text position in $O(1)$ time by simply looking up `aggregated_output_count[u]`.\n\n#### 2. Text Processing\n\nThe search phase involves feeding the *normalized* text, $\\phi(T)$, to the automaton one character at a time.\n\n**State Transitions**: Starting from the root (state $0$), for each character $c$ in $\\phi(T)$, the automaton transitions to a new state. If the current state has a child for character $c$, it moves to that child. If not, it follows failure links until a state with a transition for $c$ is found, or it reaches the root.\n\n**Counting Matches**: After each transition to a state $u$, we add `aggregated_output_count[u]` to a running total. This correctly counts all patterns (including overlapping ones and suffixes) that end at the current position in the text.\n\n#### 3. Complexity Analysis\n\nLet $L = \\sum_{p \\in P} |p|$ be the total length of all patterns, and $N = |T|$ be the length of the text. The size of the canonical alphabet is a fixed constant (ASCII).\n\n-   **Pattern Normalization**: $O(L)$.\n-   **Trie Construction**: Each character of each normalized pattern is processed once. This takes $O(L)$ time. The number of nodes in the trie is at most $L+1$.\n-   **Failure Link and Output Computation**: The BFS-based computation takes amortized linear time in the size of the trie, which is $O(L)$.\n-   **Total Build Time**: $O(L)$.\n-   **Text Normalization**: $O(N)$.\n-   **Search Time**: For each of the $N$ characters in the normalized text, the automaton performs a state transition. The total number of failure link traversals is amortized over the entire search, leading to an overall search time of $O(N)$.\n-   **Overall Complexity**: The total time complexity is $O(L+N)$, which satisfies the problem's objectives.\n\nThis design correctly implements case-insensitive matching without explicitly representing case variants in the trie, adhering to all constraints and providing an efficient solution.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multiple-pattern matching problem for the given test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An Aho-Corasick automaton for case-insensitive multi-pattern matching.\n        \"\"\"\n        def __init__(self):\n            # The trie is a list of nodes. Each node is a dictionary.\n            # 'children': maps characters to the index of the child node.\n            # 'fail': index of the failure link node.\n            # 'direct_output_count': number of original patterns ending at this node.\n            # 'output_count': total matches found when landing on this state (includes suffixes).\n            self.trie = [{'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0}]\n            self.patterns_added = False\n\n        def _phi(self, text: str) -> str:\n            \"\"\"Normalizes a string to its canonical form (lowercase).\"\"\"\n            return text.lower()\n\n        def add_pattern(self, pattern: str):\n            \"\"\"\n            Adds a normalized pattern to the trie.\n            The `build_automaton` method should be called after all patterns are added.\n            \"\"\"\n            if self.patterns_added:\n                raise Exception(\"Cannot add patterns after building the automaton.\")\n            \n            normalized_pattern = self._phi(pattern)\n            node_idx = 0\n            for char in normalized_pattern:\n                node = self.trie[node_idx]\n                if char not in node['children']:\n                    node['children'][char] = len(self.trie)\n                    self.trie.append({'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0})\n                node_idx = node['children'][char]\n            self.trie[node_idx]['direct_output_count'] += 1\n\n        def build_automaton(self):\n            \"\"\"\n            Builds the failure links and computes aggregated output counts.\n            This must be called after all patterns have been added and before searching.\n            \"\"\"\n            if self.patterns_added:\n                return # Avoid rebuilding\n            \n            self.patterns_added = True\n            queue = []\n\n            # Initialize failure links and output counts for depth 1 nodes.\n            for char, child_idx in self.trie[0]['children'].items():\n                self.trie[child_idx]['fail'] = 0\n                queue.append(child_idx)\n                # This direct propagation is the base for the recursive definition\n                self.trie[child_idx]['output_count'] = self.trie[child_idx]['direct_output_count']\n\n            # BFS to build failure links for nodes at depth > 1.\n            head = 0\n            while head < len(queue):\n                current_idx = queue[head]\n                head += 1\n                current_node = self.trie[current_idx]\n\n                for char, next_idx in current_node['children'].items():\n                    queue.append(next_idx)\n                    fail_idx = current_node['fail']\n                    \n                    # Follow failure links until a transition for `char` is found or root is reached.\n                    while char not in self.trie[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self.trie[fail_idx]['fail']\n                    \n                    if char in self.trie[fail_idx]['children']:\n                        self.trie[next_idx]['fail'] = self.trie[fail_idx]['children'][char]\n                    else:\n                        self.trie[next_idx]['fail'] = 0\n\n                    # Propagate output counts along the failure links.\n                    fail_node_output = self.trie[self.trie[next_idx]['fail']]['output_count']\n                    self.trie[next_idx]['output_count'] = self.trie[next_idx]['direct_output_count'] + fail_node_output\n\n        def search(self, text: str) -> int:\n            \"\"\"\n            Searches for all occurrences of the patterns in the given text.\n            Returns the total count of matches.\n            \"\"\"\n            if not self.patterns_added:\n                self.build_automaton()\n\n            normalized_text = self._phi(text)\n            current_state_idx = 0\n            total_matches = 0\n\n            for char in normalized_text:\n                # Follow failure links if no direct child for the character exists.\n                while char not in self.trie[current_state_idx]['children'] and current_state_idx != 0:\n                    current_state_idx = self.trie[current_state_idx]['fail']\n                \n                # If a transition exists, take it.\n                if char in self.trie[current_state_idx]['children']:\n                    current_state_idx = self.trie[current_state_idx]['children'][char]\n                \n                # Add the aggregated output count of the current state to the total.\n                total_matches += self.trie[current_state_idx]['output_count']\n            \n            return total_matches\n\n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"aHiShErS\"}),\n        ({\"patterns\": [\"Ab\", \"aB\", \"AB\", \"ab\"], \"text\": \"xxAbYYaBzz\"}),\n        ({\"patterns\": [\"a\", \"aa\"], \"text\": \"AaA\"}),\n        ({\"patterns\": [\"C++\", \"c+\"], \"text\": \"C++C+\"}),\n        ({\"patterns\": [\"Test\"], \"text\": \"\"})\n    ]\n\n    results = []\n    for case in test_cases:\n        ac = AhoCorasick()\n        for p in case[\"patterns\"]:\n            ac.add_pattern(p)\n        ac.build_automaton()\n        result = ac.search(case[\"text\"])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205013"}]}