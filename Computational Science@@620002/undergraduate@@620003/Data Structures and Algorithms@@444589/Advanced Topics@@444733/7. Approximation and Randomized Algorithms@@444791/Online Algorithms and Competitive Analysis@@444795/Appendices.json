{"hands_on_practices": [{"introduction": "The classic ski rental problem provides a foundational understanding of competitive analysis. This practice [@problem_id:3257188] extends that model to a more realistic \"rent-to-own\" scenario, where each rental payment contributes towards the final purchase. By analyzing a deterministic threshold algorithm, you will explore how the competitive ratio is affected by this credit mechanism and determine the optimal online strategy.", "problem": "An adversary-controlled user intends to ski for an unknown number of days $T \\in \\mathbb{R}_{\\ge 0}$. You face the following online decision problem. Each day, skiing can be rented at per-day cost $c > 0$. The skis can also be purchased outright for a one-time cost $B > 0$. The setting is rent-to-own: each day of rental contributes a credit of $\\alpha c$ toward ownership, where $\\alpha \\in [0,1]$ is a fixed parameter known to the algorithm. At any time $t \\ge 0$, you may decide to pay the remaining balance $B - \\alpha c t$ (if positive) to obtain ownership immediately; once ownership occurs (either by paying the remaining balance or when credits reach $B$), future use is free. If credits reach $B$ at time $t_{0} = \\frac{B}{\\alpha c}$, ownership occurs automatically with no additional payment.\n\nDesign and analyze the deterministic threshold family of online algorithms parameterized by a time $\\tau \\ge 0$ that rent until time $\\tau$ and, if ownership has not already occurred by credit accumulation, pay the remaining balance at time $\\tau$ to buy. The adversary chooses $T$ after seeing your choice of $\\tau$. Using the formal definition of competitive ratio for online algorithms, derive the worst-case competitive ratio of this threshold algorithm as a function of $\\tau$, $B$, $c$, and $\\alpha$, and then choose $\\tau$ to minimize this worst-case ratio. Your final answer must be the optimal competitive ratio expressed as a closed-form function of $\\alpha$ alone. No rounding is required, and no physical units should be included in the final expression. Also, briefly justify how your expression compares to the classical ski rental setting when $\\alpha = 0$.", "solution": "The user wants to solve a modified version of the ski rental problem with a rent-to-own mechanism.\n\n### Step 1: Extract Givens\n-   Total skiing duration: $T \\in \\mathbb{R}_{\\ge 0}$, chosen by an adversary.\n-   Per-day rental cost: $c > 0$.\n-   Outright purchase cost: $B > 0$.\n-   Rent-to-own credit parameter: $\\alpha \\in [0,1]$. Each day of rental contributes $\\alpha c$ toward the purchase price $B$.\n-   Purchase option: At any time $t \\ge 0$, the user can pay the remaining balance, $B - \\alpha c t$ (if positive), to buy the skis.\n-   Automatic ownership: Ownership is granted at time $t_0 = \\frac{B}{\\alpha c}$ if the accumulated credits $\\alpha c t$ reach $B$.\n-   Algorithm family: Deterministic threshold algorithms parameterized by $\\tau \\ge 0$. The algorithm rents until time $\\tau$ and then, if not already owned, pays the remaining balance to buy.\n-   Objective: Derive the worst-case competitive ratio of this algorithm as a function of $\\tau, B, c, \\alpha$. Then, find the optimal $\\tau$ that minimizes this ratio and state the resulting optimal competitive ratio as a function of $\\alpha$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It is a well-defined problem in the field of online algorithms and competitive analysis. All terms are defined, and the premises are self-contained and consistent. The problem is objective and free of any non-formalizable or subjective elements.\n\n-   **Scientifically Grounded:** Yes. It is a theoretical problem in computer science.\n-   **Well-Posed:** Yes. The objective is clear and the setup allows for a unique solution.\n-   **Objective:** Yes. The language is precise and mathematical.\n-   **Completeness:** Yes. All necessary parameters ($B, c, \\alpha, \\tau, T$) are defined.\n-   **Consistency:** Yes. There are no internal contradictions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. Proceeding to the solution.\n\n### Formal Analysis\n\nLet $C_{\\text{ALG}}(T, \\tau)$ be the cost of the online algorithm with parameter $\\tau$ for a total skiing duration $T$. Let $C_{\\text{OPT}}(T)$ be the cost of the optimal offline algorithm for duration $T$.\n\n**Optimal Offline Algorithm Cost ($C_{\\text{OPT}}$)**\nThe optimal offline algorithm knows $T$ in advance. It has two primary strategies:\n1.  Buy the skis at time $t=0$ for a cost of $B$.\n2.  Rent the skis for the entire duration $T$. The cost would be $cT$.\n\nThe optimal strategy is to choose the minimum of these two costs. The rent-to-own feature does not change the optimal decision framework. If the optimal choice is to buy, it is always best to do so at $t=0$, as delaying the purchase to time $t > 0$ results in a cost of $ct + (B - \\alpha c t) = B + ct(1-\\alpha)$, which is greater than $B$ for $t>0$ and $\\alpha  1$. If $\\alpha=1$, the cost is $B$, so buying at $t=0$ is still optimal. The automatic ownership at $t_0 = \\frac{B}{\\alpha c}$ only occurs if one rents continuously. For the optimal algorithm, renting is only preferred if $cT  B$. Since $B \\le B/(\\alpha c)$, the condition $cT  B$ implies $T  B/c \\le t_0$, so automatic ownership is not a factor in the optimal algorithm's decision.\nThus, the optimal cost is:\n$$ C_{\\text{OPT}}(T) = \\min(cT, B) $$\n\n**Online Algorithm Cost ($C_{\\text{ALG}}$)**\nThe online algorithm rents until time $\\tau$ and then buys if ownership has not been automatically acquired. Let $t_0 = \\frac{B}{\\alpha c}$ be the time of automatic ownership.\n\nThe cost depends on the relationship between the total skiing time $T$ and the algorithm's threshold $\\tau$.\n1.  If $T  \\tau$: The algorithm's decision point $\\tau$ is not reached. The algorithm only rents for the duration $T$. However, if $T$ is large enough to trigger automatic ownership ($T \\ge t_0$), the cost is capped at the total rent paid up to $t_0$, which is $c t_0 = c \\frac{B}{\\alpha c} = \\frac{B}{\\alpha}$.\n    So, for $T  \\tau$, the cost is $C_{\\text{ALG}}(T, \\tau) = \\min(cT, \\frac{B}{\\alpha})$.\n\n2.  If $T \\ge \\tau$: The algorithm reaches its decision point $\\tau$.\n    -   If $\\tau  t_0$: Automatic ownership has not occurred. The algorithm has paid $c\\tau$ in rent and now pays the balance $B - \\alpha c \\tau$. The total cost is $c\\tau + (B - \\alpha c \\tau) = B + c\\tau(1-\\alpha)$.\n    -   If $\\tau \\ge t_0$: Automatic ownership has already occurred at time $t_0$. The algorithm paid rent only up to $t_0$. The total cost is $c t_0 = \\frac{B}{\\alpha}$.\n    Combining these, for $T \\ge \\tau$, the cost is constant: $C_{\\text{ALG}}(T, \\tau) = \\min(B + c\\tau(1-\\alpha), \\frac{B}{\\alpha})$.\n\n**Competitive Ratio $\\mathcal{R}(\\tau)$**\nThe competitive ratio is the supremum of the ratio of costs over all possible choices of $T$ by the adversary:\n$$ \\mathcal{R}(\\tau) = \\sup_{T \\ge 0} \\frac{C_{\\text{ALG}}(T, \\tau)}{C_{\\text{OPT}}(T)} $$\nWe can split the analysis based on $T$:\n$$ \\mathcal{R}(\\tau) = \\max \\left( \\sup_{0 \\le T  \\tau} \\frac{C_{\\text{ALG}}(T, \\tau)}{C_{\\text{OPT}}(T)}, \\sup_{T \\ge \\tau} \\frac{C_{\\text{ALG}}(T, \\tau)}{C_{\\text{OPT}}(T)} \\right) $$\n\nLet's analyze the two parts. Let $t_B = B/c$.\n**Part 1: $\\sup_{0 \\le T  \\tau} \\frac{\\min(cT, B/\\alpha)}{\\min(cT, B)}$**\n-   If $\\tau \\le t_B$, then for any $T  \\tau$, we have $T  t_B$, so $cT  B$. The ratio is $\\frac{cT}{cT} = 1$. The supremum is $1$.\n-   If $t_B  \\tau \\le t_0$, the adversary can choose $T$ in the range $[t_B, \\tau)$. For such $T$, $cT \\ge B$. The ratio is $\\frac{\\min(cT, B/\\alpha)}{B}$. Since $T \\le t_0 = B/(\\alpha c)$, $cT \\le B/\\alpha$, so the ratio is $\\frac{cT}{B}$. This is maximized as $T \\to \\tau^{-}$, giving a supremum of $\\frac{c\\tau}{B}$.\n-   If $\\tau  t_0$, the adversary can choose $T$ in $[t_0, \\tau)$. For such $T$, $C_{\\text{ALG}} = B/\\alpha$ and $C_{\\text{OPT}}=B$. The ratio is $\\frac{B/\\alpha}{B} = \\frac{1}{\\alpha}$. For $T \\in [t_B, t_0)$, the ratio is $cT/B$, which is maximized at $T \\to t_0^-$ giving $ct_0/B = (B/\\alpha)/B = 1/\\alpha$. So the supremum is $1/\\alpha$.\n\n**Part 2: $\\sup_{T \\ge \\tau} \\frac{\\min(B + c\\tau(1-\\alpha), B/\\alpha)}{\\min(cT, B)}$**\nThe numerator is a constant with respect to $T$. To maximize the ratio, the adversary must minimize the denominator, $C_{\\text{OPT}}(T) = \\min(cT, B)$, for $T \\ge \\tau$. The minimum value is achieved at $T=\\tau$, where $C_{\\text{OPT}}(\\tau) = \\min(c\\tau, B)$.\nSo, the supremum is $\\frac{\\min(B + c\\tau(1-\\alpha), B/\\alpha)}{\\min(c\\tau, B)}$.\n\n**Combining and Finding the Optimal $\\tau$**\nLet's express the competitive ratio $\\mathcal{R}$ in terms of a normalized threshold $x = \\frac{c\\tau}{B}$, so $\\tau = \\frac{xB}{c}$. The critical points are $x=1$ (corresponding to $\\tau=t_B$) and $x=1/\\alpha$ (corresponding to $\\tau=t_0$). We analyze $\\mathcal{R}(x)$.\n\n-   **Case 1: $0  x \\le 1$ (i.e., $0  \\tau \\le t_B$)**\n    $\\sup_{T\\tau}$ is $1$.\n    $\\sup_{T\\ge\\tau}$ is $\\frac{B+c\\tau(1-\\alpha)}{c\\tau} = \\frac{B}{c\\tau} + 1-\\alpha = \\frac{1}{x} + 1-\\alpha$.\n    Since $x \\le 1$, $1/x \\ge 1$. Since $\\alpha \\le 1$, $1-\\alpha \\ge 0$. So $\\frac{1}{x} + 1-\\alpha \\ge 1$.\n    $\\mathcal{R}(x) = \\frac{1}{x} + 1-\\alpha$. This function is decreasing in $x$. Its minimum value in this interval occurs at $x=1$, yielding $\\mathcal{R}(1) = 1 + 1 - \\alpha = 2-\\alpha$.\n\n-   **Case 2: $1  x \\le 1/\\alpha$ (i.e., $t_B  \\tau \\le t_0$)**\n    $\\sup_{T\\tau}$ is $\\frac{c\\tau}{B} = x$.\n    $\\sup_{T\\ge\\tau}$ is $\\frac{B+c\\tau(1-\\alpha)}{B} = 1 + \\frac{c\\tau}{B}(1-\\alpha) = 1 + x(1-\\alpha)$.\n    $\\mathcal{R}(x) = \\max(x, 1+x(1-\\alpha))$.\n    We compare $x$ and $1+x(1-\\alpha) = 1+x-\\alpha x$. The inequality $x \\le 1+x-\\alpha x$ simplifies to $0 \\le 1-\\alpha x$, or $\\alpha x \\le 1$, which is true since $x \\le 1/\\alpha$.\n    Thus, $\\mathcal{R}(x) = 1+x(1-\\alpha)$. This is an increasing function of $x$ (for $\\alpha1$). Its minimum on this interval is approached as $x \\to 1^{+}$, which is $1+(1-\\alpha) = 2-\\alpha$.\n\n-   **Case 3: $x  1/\\alpha$ (i.e., $\\tau  t_0$)**\n    $\\sup_{T\\tau}$ is $1/\\alpha$.\n    $\\sup_{T\\ge\\tau}$ is $\\frac{B/\\alpha}{B} = \\frac{1}{\\alpha}$.\n    $\\mathcal{R}(x) = \\max(1/\\alpha, 1/\\alpha) = \\frac{1}{\\alpha}$.\n\n**Conclusion on Optimal Ratio**\nThe function $\\mathcal{R}(x)$ decreases for $x \\in (0,1]$, increases for $x \\in (1, 1/\\alpha]$, and is constant at $1/\\alpha$ for $x  1/\\alpha$.\nThe minimum value of $\\mathcal{R}(x)$ is achieved at $x=1$, which corresponds to setting the threshold $\\tau = \\tau_{\\text{opt}} = B/c$.\nThe minimal worst-case competitive ratio is the value at this minimum:\n$$ \\mathcal{R}_{\\text{opt}} = \\mathcal{R}(\\tau_{\\text{opt}}) = \\mathcal{R}(x=1) = 2-\\alpha $$\n\n**Comparison to Classical Ski Rental ($\\alpha=0$)**\nIn the classical ski rental problem, there is no rent-to-own credit, which corresponds to $\\alpha=0$. Substituting $\\alpha=0$ into our derived optimal competitive ratio yields $2-0=2$. This matches the well-known $2$-competitiveness of the optimal deterministic algorithm for the classical problem. The strategy $\\tau=B/c$ (rent until the total rental cost equals the purchase price, then buy) is also the optimal deterministic strategy in the classical setting. Our result correctly generalizes the classical problem. Furthermore, if $\\alpha=1$, every dollar of rent is credited. The ratio becomes $2-1=1$, indicating a perfect algorithm. This is logical, as there is no penalty for renting first and buying later; the total expenditure to acquire the skis is always capped at $B$.", "answer": "$$\\boxed{2-\\alpha}$$", "id": "3257188"}, {"introduction": "While deterministic strategies provide a guaranteed performance bound, randomization can often achieve better results against an oblivious adversary. This exercise [@problem_id:3257106] investigates a ski rental variant with a resale option, challenging you to derive the best possible competitive ratio for a randomized algorithm. The solution involves a powerful technique based on differential equations, leading to a famous constant in online algorithms.", "problem": "Consider the following online decision problem, an extension of the classic ski-rental model. Time is continuous and measured in nonnegative reals. There is a resource that can be used by renting at rate $r > 0$ per unit time or by buying at a one-time cost $B > 0$. If the resource is bought at any time and later the usage stops, the buyer may resell it and recover a fixed fraction $\\alpha \\in [0,1)$ of the purchase price, independent of how long it was owned. Thus, if one buys and eventually stops, the net buy cost is $(1-\\alpha)B$. The usage horizon $T \\in [0,\\infty)$ is chosen by an oblivious adversary and is not known to the online algorithm in advance.\n\nAn online algorithm specifies, possibly at random, a buy time $\\tau \\in [0,\\infty]$ as a function of no future information. If $T \\le \\tau$, the algorithm rents for the whole duration and incurs cost $rT$. If $T > \\tau$, the algorithm rents until time $\\tau$, then buys and later resells, incurring total cost $r \\tau + (1-\\alpha)B$. Let $\\text{ALG}(T)$ denote the (possibly random) cost of the algorithm on horizon $T$ and let $\\text{OPT}(T)$ denote the offline optimal cost with full knowledge of $T$. The competitive ratio of a randomized online algorithm is defined as $\\sup_{T \\ge 0} \\mathbb{E}[\\text{ALG}(T)]/\\text{OPT}(T)$, where the supremum is over all $T \\in [0,\\infty)$ and the expectation is with respect to the algorithm's internal randomness.\n\nStarting from the core definitions of online algorithms and competitive analysis, and without assuming any target formula, determine the best possible competitive ratio achievable by any randomized online algorithm for this problem. Express your final answer as a closed-form analytic expression in terms of universal constants only. No numerical rounding is required or permitted. Your final answer must be a single expression.", "solution": "The user wants me to solve a problem in the domain of online algorithms and competitive analysis.\n\n### Step 1: Extract Givens\n- Time is continuous and non-negative: $t \\in [0, \\infty)$.\n- Renting rate: $r > 0$.\n- Buying cost: $B > 0$.\n- Resale recovery fraction: $\\alpha \\in [0, 1)$.\n- Net buy cost: $(1-\\alpha)B$.\n- Usage horizon (unknown to the online algorithm): $T \\in [0, \\infty)$.\n- An online algorithm specifies a buy time $\\tau \\in [0, \\infty]$.\n- Algorithm's cost, $\\text{ALG}(T)$:\n  - If $T \\le \\tau$, $\\text{ALG}(T) = rT$.\n  - If $T > \\tau$, $\\text{ALG}(T) = r\\tau + (1-\\alpha)B$.\n- Offline optimal cost with knowledge of $T$: $\\text{OPT}(T)$.\n- The competitive ratio of a randomized online algorithm is $c = \\sup_{T \\ge 0} \\frac{\\mathbb{E}[\\text{ALG}(T)]}{\\text{OPT}(T)}$.\n- The objective is to find the minimum possible competitive ratio over all randomized online algorithms.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a well-defined mathematical problem in the field of theoretical computer science, specifically online algorithms. It is a generalization of the classic ski-rental problem. All terms are formally defined, the parameters are specified with their valid ranges, and the objective is clear. The problem is self-contained, scientifically grounded in its domain, and free of contradictions or ambiguities. It does not violate any of the specified invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\n\nFirst, we determine the cost of the optimal offline algorithm, $\\text{OPT}(T)$, which knows the total usage duration $T$ in advance. The offline algorithm has two choices: rent for the entire duration at a total cost of $rT$, or buy the resource immediately at time $0$ and resell it at time $T$ for a net cost of $(1-\\alpha)B$. The optimal strategy is to choose the cheaper option.\n$$ \\text{OPT}(T) = \\min(rT, (1-\\alpha)B) $$\nThe two costs are equal at a break-even time $T_0$, defined by $rT_0 = (1-\\alpha)B$. Thus, $T_0 = \\frac{(1-\\alpha)B}{r}$. The optimal offline cost can be expressed as:\n$$ \\text{OPT}(T) = \\begin{cases} rT  \\text{if } 0 \\le T \\le T_0 \\\\ (1-\\alpha)B = rT_0  \\text{if } T > T_0 \\end{cases} $$\n\nNext, we consider a randomized online algorithm. Such an algorithm is characterized by a probability distribution for the buy time $\\tau$. Let $F(t) = P(\\tau \\le t)$ be the cumulative distribution function (CDF) of the buy time $\\tau$. We assume $F(0) = 0$ (no buying at time $0$ with finite probability) and that $F$ is continuous. The expected cost of the algorithm for a given usage horizon $T$, denoted $\\mathbb{E}[\\text{ALG}(T)]$, is:\n$$ \\mathbb{E}[\\text{ALG}(T)] = \\int_0^\\infty \\text{cost}(\\tau, T) dF(\\tau) $$\nwhere $\\text{cost}(\\tau, T)$ is the cost for a deterministic buy time $\\tau$. We can split the integral based on whether $\\tau  T$ or $\\tau \\ge T$:\n$$ \\mathbb{E}[\\text{ALG}(T)] = \\int_0^T (r\\tau + (1-\\alpha)B) dF(\\tau) + \\int_T^\\infty rT dF(\\tau) $$\nUsing $1 - F(T) = \\int_T^\\infty dF(\\tau)$, this becomes:\n$$ \\mathbb{E}[\\text{ALG}(T)] = rT(1 - F(T)) + \\int_0^T (r\\tau + rT_0) dF(\\tau) $$\n$$ \\mathbb{E}[\\text{ALG}(T)] = rT(1 - F(T)) + r\\int_0^T \\tau dF(\\tau) + rT_0 F(T) $$\n\nThe competitive ratio is $c = \\sup_{T \\ge 0} \\frac{\\mathbb{E}[\\text{ALG}(T)]}{\\text{OPT}(T)}$. We seek the algorithm (i.e., the CDF $F$) that minimizes this supremum. For the optimal randomized algorithm, the competitive ratio is expected to be a constant $c$ for all \"hard\" inputs $T$. We assume the set of hard inputs is $T \\in [0, \\infty)$ and set the equality:\n$$ \\mathbb{E}[\\text{ALG}(T)] = c \\cdot \\text{OPT}(T) \\quad \\forall T \\ge 0 $$\nThis gives two different equations based on the definition of $\\text{OPT}(T)$.\n\nCase 1: $0 \\le T \\le T_0$.\nHere, $\\text{OPT}(T) = rT$. The condition becomes:\n$$ rT(1 - F(T)) + r\\int_0^T \\tau dF(\\tau) + rT_0 F(T) = c \\cdot rT $$\nDividing by $r$ and differentiating with respect to $T$ (assuming $F$ has a density $f=F'$) gives:\n$$ (1-F(T)) - TF'(T) + TF'(T) + T_0F'(T) = c $$\n$$ T_0 F'(T) - F(T) = c - 1 $$\nThis is a first-order linear ordinary differential equation for $F(T)$. The solution is of the form $F(T) = K\\exp(T/T_0) - (c-1)$ for some constant $K$. Using the boundary condition $F(0)=0$, we get $0 = K - (c-1)$, so $K=c-1$. Thus, for $T \\in [0, T_0]$:\n$$ F(T) = (c-1)(\\exp(T/T_0) - 1) $$\nFor $F(T)$ to be a valid CDF, we must have $F'(T) \\ge 0$. Since $F'(T) = \\frac{c-1}{T_0}\\exp(T/T_0)$, this requires $c \\ge 1$.\n\nCase 2: $T > T_0$.\nHere, $\\text{OPT}(T) = rT_0$. The condition becomes:\n$$ rT(1 - F(T)) + r\\int_0^T \\tau dF(\\tau) + rT_0 F(T) = c \\cdot rT_0 $$\nDifferentiating with respect to $T$:\n$$ (1-F(T)) - TF'(T) + TF'(T) + T_0F'(T) = 0 $$\n$$ T_0 F'(T) + 1 - F(T) = 0 $$\nThe solution to this ODE is of the form $F(T) = 1 - C\\exp(-T/T_0)$ for some constant $C$. For $F(T)$ to be a valid CDF, we must have $\\lim_{T \\to \\infty} F(T) = 1$, which is satisfied by this functional form.\n\nAn online algorithm should not postpone buying indefinitely if renting becomes arbitrarily expensive. Specifically, buying at a time $\\tau > T_0$ is suboptimal. An adversary could choose $T=\\tau$, for which $\\text{ALG}(T)=r\\tau$ while $\\text{OPT}(T)=rT_0$. The ratio would be $\\tau/T_0 > 1$. If the adversary chooses $T=\\tau+\\epsilon$ for some small $\\epsilon0$, the cost is $r\\tau + rT_0$ and the ratio is $(r\\tau+rT_0)/(rT_0) = 1+\\tau/T_0$. An algorithm that might buy at $\\tau > T_0$ faces a worse competitive ratio than one that guarantees buying by $T_0$. This suggests the optimal randomized strategy's support for $\\tau$ is contained within $[0, T_0]$.\nTherefore, we assume $F(T)=1$ for all $T \\ge T_0$.\nThis provides a crucial condition by setting $T=T_0$ in the expression for $F(T)$ from Case 1:\n$$ F(T_0) = 1 $$\n$$ (c-1)(\\exp(T_0/T_0) - 1) = 1 $$\n$$ (c-1)(e - 1) = 1 $$\nSolving for $c$, we find the optimal competitive ratio:\n$$ c-1 = \\frac{1}{e-1} \\implies c = 1 + \\frac{1}{e-1} = \\frac{e-1+1}{e-1} = \\frac{e}{e-1} $$\n\nThe corresponding optimal randomized strategy is to choose the buy time $\\tau$ from the interval $[0, T_0]$ with the CDF:\n$$ F(\\tau) = \\frac{\\exp(\\tau/T_0) - 1}{e - 1} \\quad \\text{for } \\tau \\in [0, T_0] $$\nWe must verify that this strategy achieves the competitive ratio $c = e/(e-1)$ for all $T \\ge 0$. We already established this by construction for $T \\in [0, T_0]$. For $T > T_0$, the algorithm always buys at some $\\tau \\in [0, T_0]$, so the cost is always $r\\tau + (1-\\alpha)B = r\\tau + rT_0$. The expected cost is:\n$$ \\mathbb{E}[\\text{ALG}(T)] = \\mathbb{E}[r\\tau + rT_0] = r\\mathbb{E}[\\tau] + rT_0 $$\nThe expected value of $\\tau$ is:\n$$ \\mathbb{E}[\\tau] = \\int_0^{T_0} \\tau F'(\\tau) d\\tau = \\int_0^{T_0} \\tau \\frac{\\exp(\\tau/T_0)}{T_0(e-1)} d\\tau $$\nUsing integration by parts, with substitutions $u=\\tau/T_0$ and $d\\tau = T_0 du$:\n$$ \\mathbb{E}[\\tau] = \\frac{T_0}{e-1} \\int_0^1 u \\exp(u) du = \\frac{T_0}{e-1} [u\\exp(u) - \\exp(u)]_0^1 $$\n$$ \\mathbb{E}[\\tau] = \\frac{T_0}{e-1} [(1\\cdot e^1 - e^1) - (0 \\cdot e^0 - e^0)] = \\frac{T_0}{e-1} [0 - (-1)] = \\frac{T_0}{e-1} $$\nSubstituting this back into the expected cost for $T > T_0$:\n$$ \\mathbb{E}[\\text{ALG}(T)] = r \\frac{T_0}{e-1} + rT_0 = rT_0 \\left(\\frac{1}{e-1} + 1\\right) = rT_0 \\frac{e}{e-1} $$\nThe competitive ratio for $T > T_0$ is:\n$$ \\frac{\\mathbb{E}[\\text{ALG}(T)]}{\\text{OPT}(T)} = \\frac{rT_0 \\frac{e}{e-1}}{rT_0} = \\frac{e}{e-1} $$\nThe competitive ratio is constant and equal to $e/(e-1)$ for all $T \\ge 0$. By construction, this is the lowest possible competitive ratio for any randomized algorithm against an oblivious adversary. The parameters $r$, $B$, and $\\alpha$ are encapsulated within the break-even time $T_0$, but they do not appear in the final expression for the competitive ratio, which depends only on the universal constant $e$. This result is a well-known finding for the ski-rental family of problems.", "answer": "$$\\boxed{\\frac{e}{e-1}}$$", "id": "3257106"}, {"introduction": "Online decision-making extends beyond simple rent-or-buy choices to complex resource allocation problems like bin packing. This problem [@problem_id:3257046] introduces the concept of recourse, where an algorithm can pay a penalty to move items between bins to accommodate new arrivals. You will analyze a specific online strategy on a carefully constructed adversarial sequence to understand the trade-off between using new resources and paying to reconfigure existing ones.", "problem": "Consider an online bin packing problem with recourse in the following precise model. There are bins of capacity $1$. Items arrive one by one; each item has a size in $(0,1]$. Upon each arrival, an online algorithm must place the item into some bin so that the total size of items in any bin never exceeds $1$. Recourse is allowed: the algorithm may move previously placed items between bins at any arrival, but each moved item incurs a fixed penalty cost. Define the total cost of any algorithm on a given input sequence to be the sum of two components: the number of bins used in the final packing plus a penalty equal to $\\beta > 0$ times the total number of moved items over the entire sequence. For competitive analysis, compare the online algorithm’s cost to the cost of the optimal offline algorithm (OPT), which knows the entire sequence in advance and is measured by the same cost function.\n\nFix parameters $\\alpha \\in (0, \\tfrac{1}{2})$, $\\beta > 0$, and a positive integer $m$ that is a multiple of $4$. Consider the adversarial sequence consisting of $m$ items of size $\\alpha$ arriving first, followed by $m$ items of size $1-\\alpha$.\n\nAnalyze the following deterministic online algorithm, called Local Fix (LF). On arrival of an item of size $s$:\n- If there exists a bin with sufficient remaining capacity to place the item without violating capacity, place it there.\n- Otherwise, if the arriving item is of size $1-\\alpha$ and there exists a bin currently holding two items of size $\\alpha$, select such a bin, move exactly one $\\alpha$-item out of it (paying the penalty for that one moved item), and place the arriving $1-\\alpha$ item into the freed bin alongside the remaining $\\alpha$ item.\n- If neither of the above applies, open a new bin and place the item there.\nEvicted $\\alpha$-items are collected and repacked by LF into bins, placing up to two $\\alpha$-items per bin, subject to bin capacity.\n\nStarting from the foundational definitions of online algorithms, bin packing feasibility, and the competitive ratio $R$, derive the exact competitive ratio of the Local Fix algorithm on the described sequence as a closed-form expression in terms of $\\beta$. Your final answer must be the analytic expression for $R$, with no rounding or approximation.", "solution": "The problem requires the derivation of the exact competitive ratio of the Local Fix (LF) algorithm for a specific adversarial sequence. The competitive ratio, $R$, is defined as the ratio of the cost incurred by the online algorithm (ALG) to the cost incurred by the optimal offline algorithm (OPT) on the same input sequence. The cost function for any algorithm is defined as the sum of the number of bins used and a penalty term proportional to the number of items moved, given by:\n$$ \\text{Cost} = (\\text{Number of bins used}) + \\beta \\times (\\text{Total number of moved items}) $$\nwhere $\\beta > 0$ is a fixed penalty parameter.\n\nThe adversarial sequence consists of two phases: first, $m$ items of size $\\alpha$ arrive, followed by $m$ items of size $1-\\alpha$. The parameters are constrained such that $\\alpha \\in (0, \\frac{1}{2})$ and $m$ is a positive integer that is a multiple of $4$. The capacity of each bin is $1$. The constraint $\\alpha  \\frac{1}{2}$ ensures that $2\\alpha  1$, so two items of size $\\alpha$ can fit into a single bin.\n\nWe will analyze the cost of the Local Fix algorithm ($\\text{Cost}_{\\text{LF}}$) and the optimal offline algorithm ($\\text{Cost}_{\\text{OPT}}$) separately.\n\n**Analysis of the Local Fix (LF) Algorithm's Cost**\n\nWe trace the execution of the LF algorithm on the specified sequence.\n\n**Phase 1: Arrival of $m$ items of size $\\alpha$.**\nThe first $m$ items to arrive each have size $\\alpha$.\n- The first item is placed into a new bin, $B_1$.\n- The second item arrives. The remaining capacity in $B_1$ is $1 - \\alpha$. Since $\\alpha \\in (0, \\frac{1}{2})$, we have $1 - \\alpha > \\frac{1}{2} > \\alpha$. Thus, there is sufficient capacity in $B_1$ for the second item. LF places it there according to its first rule. Bin $B_1$ now contains two items of size $\\alpha$, with contents $\\{\\alpha, \\alpha\\}$.\n- LF continues this process, filling each new bin with two items of size $\\alpha$ before opening another.\n- Since $m$ is an even integer (as it is a multiple of $4$), all $m$ items are paired up perfectly.\n- At the end of this phase, LF has used $\\frac{m}{2}$ bins. Each bin contains two items of size $\\alpha$.\n- The number of bins used in this phase is $\\frac{m}{2}$.\n- The number of items moved is $0$.\n\n**Phase 2: Arrival of $m$ items of size $1-\\alpha$.**\nNext, $m$ items of size $1-\\alpha$ arrive one by one. Let's analyze the algorithm's decisions.\n- Consider the arrival of the first item of size $1-\\alpha$.\n- LF's first rule is to check for a bin with sufficient capacity. All $\\frac{m}{2}$ existing bins contain two $\\alpha$-items, so their remaining capacity is $1 - 2\\alpha$. To fit an item of size $1-\\alpha$, we would need $1 - 2\\alpha \\ge 1 - \\alpha$, which simplifies to $0 \\ge \\alpha$. This is false, as $\\alpha > 0$. Therefore, rule 1 does not apply.\n- LF's second rule is checked: the arriving item has size $1-\\alpha$, and there exist bins holding two items of size $\\alpha$. This rule applies. LF selects one such bin, moves one $\\alpha$-item out, and places the $1-\\alpha$ item in. This action constitutes $1$ move. The bin now contains $\\{\\alpha, 1-\\alpha\\}$ and is full.\n- This process repeats for each arriving $1-\\alpha$ item, as long as there are bins of type $\\{\\alpha, \\alpha\\}$ available. There are $\\frac{m}{2}$ such bins initially.\n- So, for the first $\\frac{m}{2}$ items of size $1-\\alpha$ that arrive:\n    - LF applies its local fix rule $\\frac{m}{2}$ times.\n    - Each application converts one bin of type $\\{\\alpha, \\alpha\\}$ to a bin of type $\\{\\alpha, 1-\\alpha\\}$.\n    - Each application results in one $\\alpha$-item being evicted and one move being counted.\n- After these first $\\frac{m}{2}$ items of size $1-\\alpha$ have been processed:\n    - All of the original $\\frac{m}{2}$ bins are now of type $\\{\\alpha, 1-\\alpha\\}$ and are full.\n    - A total of $\\frac{m}{2}$ moves have occurred.\n    - A total of $\\frac{m}{2}$ items of size $\\alpha$ have been evicted and are \"collected\".\n- Now, the remaining $m - \\frac{m}{2} = \\frac{m}{2}$ items of size $1-\\alpha$ arrive.\n    - LF checks rule 1: All existing bins are full, so there is no sufficient capacity.\n    - LF checks rule 2: There are no more bins holding two $\\alpha$-items.\n    - Therefore, LF must apply its third rule: open a new bin for each of these arriving items.\n- This results in $\\frac{m}{2}$ new bins, each containing a single item of size $1-\\alpha$.\n\n**Phase 3: Repacking of evicted $\\alpha$-items.**\nThe problem states that the evicted items are repacked according to a specific rule: \"placing up to two $\\alpha$-items per bin\".\n- From Phase 2, there are $\\frac{m}{2}$ evicted items of size $\\alpha$.\n- Packing these items two per bin requires $\\frac{m/2}{2} = \\frac{m}{4}$ new bins. The constraint that $m$ is a multiple of $4$ ensures $\\frac{m}{4}$ is an integer.\n\n**Summary of LF's Total Cost ($\\text{Cost}_{\\text{LF}}$):**\n- **Total bins used:**\n    - $\\frac{m}{2}$ bins of type $\\{\\alpha, 1-\\alpha\\}$.\n    - $\\frac{m}{2}$ bins of type $\\{1-\\alpha\\}$.\n    - $\\frac{m}{4}$ bins of type $\\{\\alpha, \\alpha\\}$ for the repacked items.\n    - Total Bins$_{\\text{LF}} = \\frac{m}{2} + \\frac{m}{2} + \\frac{m}{4} = m + \\frac{m}{4} = \\frac{5m}{4}$.\n- **Total items moved:**\n    - The local fix rule was applied $\\frac{m}{2}$ times, each causing one move.\n    - Total Moves$_{\\text{LF}} = \\frac{m}{2}$.\n- **Total Cost:**\n    - $\\text{Cost}_{\\text{LF}} = \\text{Bins}_{\\text{LF}} + \\beta \\times \\text{Moves}_{\\text{LF}} = \\frac{5m}{4} + \\beta \\frac{m}{2} = m(\\frac{5}{4} + \\frac{\\beta}{2})$.\n\n**Analysis of the Optimal Offline Algorithm's Cost ($\\text{Cost}_{\\text{OPT}}$)**\n\nThe optimal offline algorithm (OPT) knows the entire sequence of $m$ items of size $\\alpha$ and $m$ items of size $1-\\alpha$ in advance. Its goal is to minimize the same cost function.\n- **Optimal Packing:** The most efficient way to pack these items is to create pairs of $\\{\\alpha, 1-\\alpha\\}$. The size of such a pair is $\\alpha + (1-\\alpha) = 1$, which perfectly fills a bin. Since there are $m$ items of each size, OPT can form exactly $m$ such pairs. This packing uses $m$ bins and leaves no items unpacked. The total volume of items is $m\\alpha + m(1-\\alpha) = m$, so using $m$ bins of capacity $1$ is the absolute minimum possible.\n- **Optimal Recourse Strategy:** OPT must choose how to achieve this packing with minimal cost.\n    - **Strategy 1 (No Moves):** OPT can pack the items without any moves. For instance, it can place the first $m$ arriving $\\alpha$-items into $m$ separate bins. Then, as the $m$ items of size $1-\\alpha$ arrive, it places one into each of the $m$ bins. The final configuration is $m$ bins of type $\\{\\alpha, 1-\\alpha\\}$.\n        - Bins used = $m$.\n        - Moves = $0$.\n        - Cost = $m + \\beta \\times 0 = m$.\n    - **Strategy 2 (With Moves):** OPT could initially pack the $m$ $\\alpha$-items into $\\frac{m}{2}$ bins (two per bin). Then, to create the optimal final packing, it would need to break up these bins, which would require moves. To form $m$ bins of type $\\{\\alpha, 1-\\alpha\\}$, it would need to move one $\\alpha$ item out of each of the $\\frac{m}{2}$ initial bins. This amounts to $\\frac{m}{2}$ moves. The final bin count would still be $m$.\n        - Bins used = $m$.\n        - Moves = $\\frac{m}{2}$.\n        - Cost = $m + \\beta \\times \\frac{m}{2} = m(1 + \\frac{\\beta}{2})$.\n- **Conclusion for OPT:** OPT will choose the strategy with the minimum cost. We compare the costs: $m$ versus $m(1 + \\frac{\\beta}{2})$. Since $\\beta > 0$, we have $1 + \\frac{\\beta}{2} > 1$, which implies $m(1 + \\frac{\\beta}{2})  m$. Therefore, the optimal strategy is the one with no moves.\n- The minimum possible cost for the offline algorithm is $\\text{Cost}_{\\text{OPT}} = m$.\n\n**Derivation of the Competitive Ratio (R)**\n\nThe competitive ratio $R$ is the ratio of the online algorithm's cost to the optimal offline cost.\n$$ R = \\frac{\\text{Cost}_{\\text{LF}}}{\\text{Cost}_{\\text{OPT}}} $$\nSubstituting the derived costs:\n$$ R = \\frac{m(\\frac{5}{4} + \\frac{\\beta}{2})}{m} $$\nThe factor $m$ cancels out, as long as $m \\ne 0$, which is true.\n$$ R = \\frac{5}{4} + \\frac{\\beta}{2} $$\nThis is the exact competitive ratio of the Local Fix algorithm for the given sequence, expressed as a closed-form expression in terms of $\\beta$.", "answer": "$$\n\\boxed{\\frac{5}{4} + \\frac{\\beta}{2}}\n$$", "id": "3257046"}]}