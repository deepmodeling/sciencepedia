{"hands_on_practices": [{"introduction": "Building a persistent queue is a classic exercise that introduces the core ideas of functional data structures. This practice challenges you to implement a FIFO queue where operations create new versions instead of modifying the old ones, using structural sharing for efficiency [@problem_id:3246712]. By cleverly employing two linked lists, you can achieve amortized $O(1)$ time complexity for both enqueue and dequeue operations, showcasing an elegant solution to a seemingly difficult constraint.", "problem": "You are to implement, from first principles, a persistent First-In First-Out (FIFO) queue using singly linked lists, where any operation that conceptually changes the queue returns a new queue and leaves the original queue unmodified. Start from the core definitions: a queue is an abstract data type in which the element added earliest is removed first; a singly linked list consists of nodes, each with a value and a reference to the next node; a persistent data structure returns a new version on update without altering prior versions, enabling structural sharing between versions. You must ensure that no existing node in any prior version of the queue is mutated after its creation. The intended time complexity target is amortized $O(1)$ per enqueue and dequeue.\n\nImplement a complete, runnable program that defines:\n- An immutable singly linked node type for integers.\n- A queue type with operations that do not mutate existing nodes.\n- An operation $\\mathrm{enqueue}(q, x)$ that returns a new queue with the integer $x$ added at the back.\n- An operation $\\mathrm{dequeue}(q)$ that returns a triple $(s, v, q')$ where $s$ is a boolean indicating success, $v$ is the removed integer when $s$ is true, and $q'$ is the new queue. If $q$ is empty, then $s$ is false, $v$ must be $0$, and $q' = q$.\n- A function to compute the size of a queue, returning a nonnegative integer.\n\nYour program must not rely on any user input and must execute the following test suite internally. Each test case is a sequence of operations on persistent queues and must produce quantifiable results as integers or booleans, aggregated in the specified output format.\n\nTest Suite:\n- Test Case $A$ (happy path and persistence check):\n  1. Let $q_0$ be the empty queue.\n  2. Let $q_1 = \\mathrm{enqueue}(q_0, 1)$.\n  3. Let $q_2 = \\mathrm{enqueue}(q_1, 2)$.\n  4. Let $q_3 = \\mathrm{enqueue}(q_2, 3)$.\n  5. Perform $\\mathrm{dequeue}(q_3)$ yielding $(s_1, v_1, q_4)$.\n  6. Perform $\\mathrm{dequeue}(q_4)$ yielding $(s_2, v_2, q_5)$.\n  7. Perform $\\mathrm{dequeue}(q_3)$ yielding $(s_3, v_3, q_6)$.\n  Output for this test case must be the list $[v_1, v_2, v_3]$.\n\n- Test Case $B$ (rear-to-front reorganization edge):\n  1. Let $q_0$ be the empty queue.\n  2. Let $q_1 = \\mathrm{enqueue}(q_0, 10)$.\n  3. Let $q_2 = \\mathrm{enqueue}(q_1, 20)$.\n  4. Let $q_3 = \\mathrm{enqueue}(q_2, 30)$.\n  5. Let $q_4 = \\mathrm{enqueue}(q_3, 40)$.\n  6. Perform $\\mathrm{dequeue}(q_4)$ yielding $(s_4, v_4, q_5)$.\n  7. Perform $\\mathrm{dequeue}(q_5)$ yielding $(s_5, v_5, q_6)$.\n  Output for this test case must be the list $[v_4, v_5]$.\n\n- Test Case $C$ (empty boundary case):\n  1. Let $q_0$ be the empty queue.\n  2. Perform $\\mathrm{dequeue}(q_0)$ yielding $(s_0, v_0, q_1)$ with $s_0$ expected to be false and $v_0$ required to be $0$.\n  3. Let $q_2 = \\mathrm{enqueue}(q_0, 99)$.\n  4. Perform $\\mathrm{dequeue}(q_2)$ yielding $(s_6, v_6, q_3)$.\n  Output for this test case must be the list $[s_0, s_6, v_6]$.\n\nDesign for correctness and persistence: all operations must preserve immutability of existing nodes and return new queue instances as required. Your program should produce a single line of output containing the concatenated results of Test Case $A$, Test Case $B$, and Test Case $C$ as a comma-separated list enclosed in square brackets, in the exact order: $[v_1, v_2, v_3, v_4, v_5, s_0, s_6, v_6]$. No physical units, angles, or percentages are involved; all outputs are pure integers or booleans.", "solution": "The problem requires the implementation of a persistent First-In First-Out (FIFO) queue using singly linked lists. The implementation must be from first principles, ensuring that all operations are non-mutating (persistent) and that `enqueue` and `dequeue` operations achieve an amortized time complexity of $O(1)$.\n\nA persistent data structure, by definition, preserves previous versions of itself when modified. Any operation that conceptually alters the structure returns a new, modified instance while leaving the original instance untouched. This allows different versions of the data structure to coexist and share common substructures, which is both memory-efficient and crucial for certain functional programming paradigms and algorithms.\n\nA naive implementation of a queue using a single singly linked list fails to meet the performance requirement. A singly linked list naturally supports efficient, constant-time ($O(1)$) additions and removals at its head. If we use the head for `dequeue`, then `enqueue` must add elements to the tail. Finding the tail of a singly linked list requires traversing it from the head, an operation with linear time complexity, $O(n)$, where $n$ is the number of elements. This would make the `enqueue` operation unacceptably slow.\n\nTo achieve the desired amortized $O(1)$ complexity, the standard and correct approach is to represent the queue using two singly linked lists: a `front` list and a `rear` list.\n\nLet the state of a queue $q$ be represented by the pair of lists $(f, r)$, where $f$ is the `front` list and $r$ is the `rear` list.\n- The `front` list stores elements in the correct order for dequeuing. That is, the head of the `front` list is the oldest element in the queue.\n- The `rear` list stores newly enqueued elements in reverse order (like a stack). The head of the `rear` list is the most recently enqueued element.\n\nThe operations are designed as follows:\n- **`enqueue(q, x)`**: To add an element $x$ to the queue $q = (f, r)$, we create a new node for $x$ and prepend it to the `rear` list. A new queue instance $q' = (f, \\mathrm{cons}(x, r))$ is returned. The `front` list $f$ is shared, and because we only prepend to $r$, the original `rear` list is also shared. This is a purely local modification, creating only one new node, and is therefore an $O(1)$ operation.\n\n- **`dequeue(q)`**: This operation removes the element from the head of the queue. Let the queue be $q = (f, r)$.\n    1.  If the `front` list $f$ is non-empty, its head contains the oldest element. We return this element's value. The new queue state is $(f_{\\mathrm{tail}}, r)$, where $f_{\\mathrm{tail}}$ is the `front` list without its head. This is also an $O(1)$ operation as it only involves pointer manipulation and creating a new queue object that shares the existing list structures.\n    2.  If the `front` list $f$ is empty, it signifies that all elements previously positioned for dequeuing have been consumed. To proceed, we must move the elements from the `rear` list $r$ to the `front` list. Since the `rear` list stores elements in reverse order, we must perform a list reversal. We create a new list, $f'$, which is the reversal of $r$. This new list $f'$ becomes the `front` list of the queue, and the `rear` list becomes empty. This reversal operation has a time complexity of $O(k)$, where $k$ is the number of elements in the `rear` list. After this rebalancing, the queue state is effectively $(f', \\mathrm{empty\\_list})$, and we can proceed as in case $1$ by dequeuing from the head of $f'$.\n\nThe $O(k)$ cost of the reversal operation does not violate the amortized $O(1)$ complexity requirement. The cost of this single expensive `dequeue` operation can be distributed, or \"amortized,\" over the $k$ inexpensive `enqueue` operations that built the `rear` list. Each element in the queue is enqueued exactly once ($O(1)$), moved from the `rear` to the `front` list (i.e., part of a reversal) at most once (average cost $O(1)$), and dequeued exactly once ($O(1)$). Therefore, the average cost per operation remains constant.\n\nA critical aspect of persistence is that the reversal operation must not mutate the existing `rear` list. Instead, it must construct a completely new list of nodes that represent the reversed sequence. This ensures that any prior version of the queue that shares this `rear` list remains valid and unchanged. This property is explicitly tested by Test Case $A$, where `dequeue` is called on the same queue version, $q_3$, twice, requiring the operation to be repeatable and free of side effects.\n\nThe implementation will consist of an immutable `Node` class and a `PersistentQueue` class encapsulating the `front` and `rear` lists and the associated logic for the `enqueue`, `dequeue`, and `size` operations. An empty queue is a special case where both lists are empty. The `dequeue` operation on an empty queue returns a failure status, a placeholder value of $0$, and the original empty queue instance, as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef solve():\n    \"\"\"\n    Implements a persistent FIFO queue and runs the specified test suite.\n    \"\"\"\n\n    class Node:\n        \"\"\"\n        An immutable singly linked list node for integers.\n        Immutability is by convention; attributes are not privately enforced.\n        \"\"\"\n        __slots__ = ('value', 'next')\n\n        def __init__(self, value: int, next_node=None):\n            self.value = value\n            self.next = next_node\n\n    def _reverse_list(node: Node | None) -> Node | None:\n        \"\"\"\n        Persistently reverses a singly linked list.\n        It creates a new list structure without mutating the original.\n        \"\"\"\n        new_head = None\n        current = node\n        while current:\n            new_head = Node(current.value, new_head)\n            current = current.next\n        return new_head\n\n    class PersistentQueue:\n        \"\"\"\n        A persistent FIFO queue implemented with two singly linked lists.\n        \"\"\"\n        # A cached singleton instance for the empty queue for efficiency.\n        _EMPTY_INSTANCE = None\n\n        def __init__(self, front: Node | None = None, rear: Node | None = None, size: int = 0):\n            \"\"\"\n            Private constructor. Use get_empty_queue() for the initial queue.\n            \"\"\"\n            self.front = front\n            self.rear = rear\n            self._size = size\n\n        @staticmethod\n        def get_empty_queue():\n            \"\"\"Factory method for creating or retrieving the empty queue instance.\"\"\"\n            if PersistentQueue._EMPTY_INSTANCE is None:\n                PersistentQueue._EMPTY_INSTANCE = PersistentQueue()\n            return PersistentQueue._EMPTY_INSTANCE\n        \n        def enqueue(self, value: int):\n            \"\"\"\n            Returns a new queue with the integer value added at the back.\n            Amortized time complexity: O(1).\n            \"\"\"\n            # Creates a new node and prepends it to the rear list.\n            return PersistentQueue(self.front, Node(value, self.rear), self._size + 1)\n\n        def dequeue(self):\n            \"\"\"\n            Returns a triple (success, value, new_queue).\n            If the queue is empty, success is False, value is 0, and a reference\n            to the same empty queue is returned.\n            Amortized time complexity: O(1).\n            \"\"\"\n            if self._size == 0:\n                return (False, 0, self)\n\n            # If the front list is not empty, we can dequeue from it directly.\n            if self.front is not None:\n                value = self.front.value\n                # The new queue shares the rear list.\n                new_queue = PersistentQueue(self.front.next, self.rear, self._size - 1)\n                return (True, value, new_queue)\n            \n            # If the front list is empty, the rear list must be reversed to become\n            # the new front list. This is the expensive step.\n            new_front = _reverse_list(self.rear)\n            value = new_front.value\n            # The new queue's rear list is now empty.\n            new_queue = PersistentQueue(new_front.next, None, self._size - 1)\n            return (True, value, new_queue)\n\n        def get_size(self) -> int:\n            \"\"\"\n            Returns the total number of elements in the queue.\n            Time complexity: O(1).\n            \"\"\"\n            return self._size\n\n    # --- Test Suite Execution ---\n    all_results = []\n\n    # Test Case A (happy path and persistence check)\n    q0_a = PersistentQueue.get_empty_queue()\n    q1_a = q0_a.enqueue(1)\n    q2_a = q1_a.enqueue(2)\n    q3_a = q2_a.enqueue(3)\n    s1, v1, q4_a = q3_a.dequeue()\n    s2, v2, q5_a = q4_a.dequeue()\n    s3, v3, q6_a = q3_a.dequeue() # Re-use q3 to check persistence\n    all_results.extend([v1, v2, v3])\n\n    # Test Case B (rear-to-front reorganization edge)\n    q0_b = PersistentQueue.get_empty_queue()\n    q1_b = q0_b.enqueue(10)\n    q2_b = q1_b.enqueue(20)\n    q3_b = q2_b.enqueue(30)\n    q4_b = q3_b.enqueue(40)\n    s4, v4, q5_b = q4_b.dequeue()\n    s5, v5, q6_b = q5_b.dequeue()\n    all_results.extend([v4, v5])\n\n    # Test Case C (empty boundary case)\n    q0_c = PersistentQueue.get_empty_queue()\n    s0, v0, q1_c = q0_c.dequeue()\n    q2_c = q0_c.enqueue(99)\n    s6, v6, q3_c = q2_c.dequeue()\n    all_results.extend([s0, s6, v6])\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3246712"}, {"introduction": "Many efficient algorithms, like the Disjoint Set Union (DSU) with path compression, rely on in-place mutations. This practice explores how to create a partially persistent version of such a structure, where you can query any historical state [@problem_id:3258660]. You will learn how to reconcile the destructive nature of path compression with the need for immutability by using versioned nodes and applying optimizations only to newly created versions, a powerful technique for adapting imperative data structures to a persistent context.", "problem": "You are asked to design and implement a partially persistent Disjoint Set Union (DSU), also known as Union-Find, that supports path compression and union by rank or size, while preserving previous versions. The persistence must be partial in the sense that any update creates a new version and does not mutate earlier versions. The implementation must be fully functional and must run as a complete program.\n\nFundamental base to use:\n- The DSU maintains a partition of a finite set of elements into disjoint equivalence classes. An equivalence relation satisfies reflexivity, symmetry, and transitivity. Two elements are in the same set if and only if their representatives (roots) are identical.\n- Union by size (or rank) attaches the smaller tree under the larger tree to maintain balanced forests and improve time complexity.\n- Path compression modifies parent pointers along the search path to point directly to the root, reducing future find costs.\n- Partial persistence can be achieved via fat nodes: each array cell stores a history of updates as pairs of version identifiers and values, and queries retrieve the value as of a specified version by searching this history.\n\nDesign constraints:\n- Let the universe be the set of elements indexed by integers from $0$ to $n-1$.\n- Version identifiers are integers, starting at $0$ for the initial version in which every element is a singleton set.\n- A union operation takes a base version $v_{\\text{base}}$ and two elements $a$ and $b$, computes their roots in $v_{\\text{base}}$ with path compression applied in the newly created version $v_{\\text{new}}$, and then unites the two sets by size. In case of equal sizes, attach the larger-indexed root under the smaller-indexed root to ensure determinism. The operation outputs the identifier $v_{\\text{new}}$.\n- A find operation takes a version $v$ and an element $x$ and returns the representative element (root) of $x$ in version $v$.\n- A connectivity query takes a version $v$ and two elements $a$ and $b$ and returns whether $a$ and $b$ have the same representative in version $v$.\n- Path compression must only affect the newly created version; earlier versions must remain unchanged.\n\nInput and output requirements:\n- There is no external input. Your program must construct the data structure and execute the specified sequence of operations.\n- All numeric outputs must be integers or booleans; there are no physical units involved.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n\nTest suite specification:\n- Initialize the DSU with $n = 8$ elements in version $0$.\n- Perform the following operations, where unions create new versions by incrementing the global version counter:\n    1. $v_1 = \\text{union}(0, 0, 1)$.\n    2. $v_2 = \\text{union}(v_1, 2, 3)$.\n    3. $v_3 = \\text{union}(v_2, 1, 3)$.\n    4. Query $\\text{connected}(v_3, 0, 3)$, record the boolean.\n    5. Query $\\text{connected}(v_2, 0, 3)$, record the boolean.\n    6. $v_4 = \\text{union}(v_3, 4, 5)$.\n    7. $v_5 = \\text{union}(v_4, 5, 6)$.\n    8. $v_6 = \\text{union}(v_5, 6, 7)$.\n    9. Query $\\text{connected}(v_6, 4, 7)$, record the boolean.\n    10. Query $\\text{connected}(v_3, 7, 4)$, record the boolean.\n    11. $v_7 = \\text{union}(v_6, 0, 4)$.\n    12. Query $\\text{connected}(v_7, 2, 7)$, record the boolean.\n    13. Query $\\text{find}(v_7, 7)$, record the integer representative.\n    14. $v_8 = \\text{union}(v_7, 3, 7)$.\n    15. Query $\\text{connected}(v_8, 1, 6)$, record the boolean.\n    16. $v_9 = \\text{union}(v_2, 2, 2)$.\n    17. Query $\\text{connected}(v_2, 2, 2)$, record the boolean.\n    18. Query $\\text{find}(v_2, 3)$, record the integer representative.\n- Your program must output all recorded results aggregated in order as a single list on one line, formatted as, for example, $[\\text{result}_1,\\text{result}_2,\\dots]$.\n\nCorrectness expectations:\n- The design must strictly preserve older versions, meaning any union or path compression performed while creating version $v_{\\text{new}}$ must not alter lookups in any version $v < v_{\\text{new}}$.\n- Union by size with the specified tie-breaking rule must be applied when merging two distinct sets.\n- Finds performed against existing versions must not compress paths in those versions; only union creates compressed paths in the new version via path copying into $v_{\\text{new}}$.\n\nYour implementation must be a complete, runnable program that builds the persistent DSU, executes the operations, and prints the results in the specified format. The output values must be booleans and integers only, and must follow exactly the single-line aggregation format requirement.", "solution": "The problem requires implementing a partially persistent Disjoint Set Union (DSU) data structure. The solution uses the \"fat node\" technique, where each element's properties (its parent and the size of the set it roots) are stored as a history of values over time, indexed by version numbers.\n\nThe state of the DSU is maintained in two primary structures:\n- `parent`: A list of lists, where `parent[i]` stores the history of the parent of element `i`.\n- `size`: A list of lists, where `size[i]` stores the history of the size of the set for which `i` is the root.\n\nEach history is a list of `(version, value)` tuples, kept sorted by version. To find the value of a property at a specific version `v`, we perform a binary search on the history list to find the latest entry whose version is less than or equal to `v`.\n\nThe core operations are implemented as follows:\n\n1.  **`find(v, x)`**: This is a read-only operation that finds the root of element `x` at version `v`. It traverses the parent pointers upward from `x`. At each step, it looks up the parent for the current version `v` using the binary search method. This continues until it reaches a node that is its own parent, which is the root. This operation does not perform path compression or any other modification.\n\n2.  **`union(v_base, a, b)`**: This is the update operation that creates a new version, `v_new`.\n    a. It first finds the roots of `a` and `b` in the `v_base` state, recording the nodes on the paths to these roots.\n    b. If the roots are different, it performs a union by size. The sizes of the two sets are retrieved from `v_base`, and the root of the smaller set is attached to the root of the larger set (with a tie-breaking rule).\n    c. Path compression is then applied for the new version `v_new`. For every node on the recorded paths from `a` and `b` to their original roots, a new parent entry `(v_new, winner_root)` is appended to its parent history.\n    d. Finally, the parent of the losing root and the size of the winning root are also updated in `v_new` by appending new entries to their respective histories.\n    \nThis approach ensures partial persistence: updates for a new version are recorded as new entries in the history lists, leaving all lookups for previous versions completely unaffected.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport bisect\n\nclass PersistentDSU:\n    \"\"\"\n    Implements a partially persistent Disjoint Set Union (DSU) data structure\n    using the \"fat node\" approach, where each node maintains a history of its\n    parent and size across different versions.\n    \"\"\"\n    def __init__(self, n: int):\n        \"\"\"\n        Initializes the DSU with n elements. In version 0, each element\n        is in its own set.\n        \"\"\"\n        self.n = n\n        # Parent history for each element. parent[i] is a list of (version, value).\n        self.parent = [[(0, i)] for i in range(n)]\n        # Size history for each element. Only meaningful for roots.\n        self.size = [[(0, 1)] for i in range(n)]\n        # The latest version number created. Starts at 0.\n        self.latest_version = 0\n\n    def _get_value_at_version(self, history: list, version: int) -> int:\n        \"\"\"\n        Retrieves the value from a history list for a specific version\n        using binary search.\n        \"\"\"\n        # bisect_right finds an insertion point which comes after (to the right of)\n        # any existing entries of (version, ...). idx-1 gives the last entry\n        # with version = the query version.\n        idx = bisect.bisect_right(history, (version, float('inf')))\n        return history[idx - 1][1]\n\n    def _find_path_and_root(self, version: int, i: int) -> tuple[int, list[int]]:\n        \"\"\"\n        Finds the root of element i at a given version and records the path.\n        This is a helper for both find() and union(). It does not perform mutations.\n        \"\"\"\n        path = []\n        current_node = i\n        while True:\n            parent_node = self._get_value_at_version(self.parent[current_node], version)\n            if current_node == parent_node:\n                break\n            path.append(current_node)\n            current_node = parent_node\n        root = current_node\n        return root, path\n\n    def find(self, version: int, i: int) -> int:\n        \"\"\"\n        Finds the representative (root) of element i at a given version.\n        This is a read-only operation.\n        \"\"\"\n        root, _ = self._find_path_and_root(version, i)\n        return root\n\n    def connected(self, version: int, a: int, b: int) -> bool:\n        \"\"\"\n        Checks if elements a and b are in the same set at a given version.\n        \"\"\"\n        return self.find(version, a) == self.find(version, b)\n\n    def union(self, base_version: int, a: int, b: int) -> int:\n        \"\"\"\n        Performs a union of the sets containing a and b, based on the state at\n        base_version. This creates a new version.\n        \"\"\"\n        new_version = self.latest_version + 1\n        self.latest_version = new_version\n\n        root_a, path_a = self._find_path_and_root(base_version, a)\n        root_b, path_b = self._find_path_and_root(base_version, b)\n\n        if root_a != root_b:\n            size_a = self._get_value_at_version(self.size[root_a], base_version)\n            size_b = self._get_value_at_version(self.size[root_b], base_version)\n\n            if size_a  size_b:\n                winner_root, loser_root = root_b, root_a\n            elif size_b  size_a:\n                winner_root, loser_root = root_a, root_b\n            else:  # Equal sizes, use tie-breaker\n                if root_a  root_b:\n                    winner_root, loser_root = root_a, root_b\n                else:\n                    winner_root, loser_root = root_b, root_a\n\n            # Path compression for the new version: all nodes on the paths point to the final winner root.\n            for node in path_a:\n                self.parent[node].append((new_version, winner_root))\n            for node in path_b:\n                self.parent[node].append((new_version, winner_root))\n\n            # Union: point loser root to winner root in the new version.\n            self.parent[loser_root].append((new_version, winner_root))\n\n            # Update size of the winner root in the new version.\n            self.size[winner_root].append((new_version, size_a + size_b))\n        \n        # A new version is created even if the elements are already in the same set.\n        return new_version\n\ndef solve():\n    \"\"\"\n    Executes the specified test suite for the PersistentDSU.\n    \"\"\"\n    dsu = PersistentDSU(n=8)\n    results = []\n    \n    # The version numbers are returned by union operations and stored in variables\n    # v1, v2, ... corresponding to the problem description.\n    # Version 0 is the initial state.\n    \n    # 1. v1 = union(0, 0, 1)\n    v1 = dsu.union(0, 0, 1)\n    \n    # 2. v2 = union(v1, 2, 3)\n    v2 = dsu.union(v1, 2, 3)\n    \n    # 3. v3 = union(v2, 1, 3)\n    v3 = dsu.union(v2, 1, 3)\n    \n    # 4. Query connected(v3, 0, 3)\n    results.append(dsu.connected(v3, 0, 3))\n    \n    # 5. Query connected(v2, 0, 3)\n    results.append(dsu.connected(v2, 0, 3))\n    \n    # 6. v4 = union(v3, 4, 5)\n    v4 = dsu.union(v3, 4, 5)\n    \n    # 7. v5 = union(v4, 5, 6)\n    v5 = dsu.union(v4, 5, 6)\n    \n    # 8. v6 = union(v5, 6, 7)\n    v6 = dsu.union(v5, 6, 7)\n    \n    # 9. Query connected(v6, 4, 7)\n    results.append(dsu.connected(v6, 4, 7))\n    \n    # 10. Query connected(v3, 7, 4)\n    results.append(dsu.connected(v3, 7, 4))\n    \n    # 11. v7 = union(v6, 0, 4)\n    v7 = dsu.union(v6, 0, 4)\n    \n    # 12. Query connected(v7, 2, 7)\n    results.append(dsu.connected(v7, 2, 7))\n    \n    # 13. Query find(v7, 7)\n    results.append(dsu.find(v7, 7))\n    \n    # 14. v8 = union(v7, 3, 7)\n    v8 = dsu.union(v7, 3, 7)\n    \n    # 15. Query connected(v8, 1, 6)\n    results.append(dsu.connected(v8, 1, 6))\n    \n    # 16. v9 = union(v2, 2, 2)\n    v9 = dsu.union(v2, 2, 2)\n    \n    # 17. Query connected(v2, 2, 2)\n    results.append(dsu.connected(v2, 2, 2))\n    \n    # 18. Query find(v2, 3)\n    results.append(dsu.find(v2, 3))\n\n    # Convert boolean True/False to lowercase \"true\"/\"false\" for consistency if needed,\n    # but standard str() gives \"True\"/\"False\" which is also common. Sticking to standard.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3258660"}, {"introduction": "While path-copying offers elegant persistence, it comes with the practical cost of creating new nodes with every update, which can lead to significant memory consumption. This exercise addresses the crucial issue of memory management by tasking you with implementing a mark-and-sweep garbage collector [@problem_id:3258649]. By identifying which nodes are no longer reachable from any \"live\" version of the data structure, you will learn how to reclaim memory and manage the lifecycle of nodes in a persistent environment.", "problem": "You are given a directed acyclic graph representation of a path-copying persistent binary search tree. The arena of nodes is a finite set $V$, with a directed edge set $E$ such that for each node $v \\in V$ there are up to two outgoing edges $(v, \\ell(v))$ and $(v, r(v))$ pointing to the left and right children, respectively, where $\\ell(v)$ and $r(v)$ are either elements of $V$ or a null pointer sentinel $\\bot$. A path-copying update on the tree with root $u \\in V \\cup \\{\\bot\\}$ is defined as an insertion of a key $k$ into the binary search tree that creates new nodes along the unique search path, leaving all unaffected subtrees structurally shared. Persistency means each update produces a new root $u' \\in V$, while previous roots remain valid references to earlier versions.\n\nLet the set of currently live roots be $R \\subseteq V$. Define the reachability set from $R$ by\n$$\n\\mathrm{Reach}(R) = \\{ v \\in V \\mid \\text{there exists } r \\in R \\text{ and a directed path in } E \\text{ from } r \\text{ to } v \\}.\n$$\nA Garbage Collector (GC) is a procedure that, given $V$, $E$, and $R$, reclaims all nodes in $V \\setminus \\mathrm{Reach}(R)$ and adds their identifiers to a free list, which is subsequently used by the allocator to recycle identifiers before creating fresh ones. Consider the standard mark-and-sweep approach: perform a mark phase computing $\\mathrm{Reach}(R)$ and then a sweep phase to reclaim all $v \\in V \\setminus \\mathrm{Reach}(R)$.\n\nImplement a complete, runnable program that:\n- Represents a path-copying persistent binary search tree in an arena with integer identifiers for nodes, where each node stores a key and child pointers.\n- Implements path-copying insertions that result in a new root for each inserted key, following binary search tree semantics for a set of integer keys (duplicates leave the structure unchanged).\n- Implements a mark-and-sweep Garbage Collector that, for a given set of live roots $R$, computes $\\mathrm{Reach}(R)$ and reclaims all nodes not in $\\mathrm{Reach}(R)$, returning the reclaimed identifiers sorted in ascending order. The null pointer sentinel $\\bot$ is not an element of $V$ and must never be reclaimed.\n- Implements an allocator that always reuses the smallest available identifier from the free list before allocating a fresh identifier.\n\nYour program must run an internal test suite with the following four cases and produce the final aggregated results for all cases as a single line. For each case, the program should output a list containing two lists: the first is the list of reclaimed node identifiers from the GC (sorted ascending), and the second is the list of identifiers that were reused by subsequent insertions performed after the GC. All identifiers must be integers.\n\nTest suite:\n- Case $1$: Insert keys $[2,1,3]$ starting from $\\bot$ to produce successive versions with roots $v_0$, $v_1$, and $v_2$ (after inserting $2$, $1$, and $3$, respectively). Let the live roots be $\\{v_2\\}$. Run GC. Then perform insertions of keys $[0,4]$ into the live root and record all reused identifiers during these allocations.\n- Case $2$: Insert keys $[4,2,6,1,3,5,7]$ starting from $\\bot$ to produce successive versions with roots $v_0, v_1, \\dots, v_6$. Let the live roots be $\\{v_2, v_6\\}$. Run GC. Then perform an insertion of key $[8]$ into root $v_6$ and record any reused identifiers.\n- Case $3$: Insert keys $[10,5,15]$ starting from $\\bot$, then let the live roots be the empty set $\\emptyset$. Run GC. Then perform insertions $[12,11]$ starting from $\\bot$ and record any reused identifiers.\n- Case $4$: Insert keys $[2,1,3]$ starting from $\\bot$, keep all roots live $\\{v_0, v_1, v_2\\}$, and run GC. Then perform an insertion of key $[4]$ into the latest root and record any reused identifiers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with no spaces. Each case result is a list of two lists, the first being the reclaimed identifiers and the second the reused identifiers after GC. For example, an output with two cases would look like \"[[[1,2],[1]],[[3],[3]]]\". Your program must follow this format exactly.\n\nThere are no physical units, angles, or percentages in this problem.", "solution": "The problem requires implementing a path-copying persistent binary search tree (BST) along with a mark-and-sweep garbage collector (GC) to manage memory. The solution involves three key components: an allocator that manages node identifiers, a persistent insertion function that implements path-copying, and the GC itself.\n\n**1. Node Representation and Allocation**\nThe BST is stored in a central dictionary or \"arena,\" which maps integer node identifiers to `Node` objects. A custom `Allocator` class is responsible for managing these identifiers. It maintains:\n- A `free_list`: A sorted list of identifiers reclaimed by the GC.\n- A `next_fresh_id` counter for allocating new identifiers when the `free_list` is empty.\nWhen a new node is needed, the allocator first attempts to provide the smallest identifier from the `free_list`. This recycling mechanism is crucial for memory management.\n\n**2. Path-Copying Persistent Insertion**\nInsertion is handled by a recursive function, `p_insert(root_id, key)`. This function embodies the principles of persistence and structural sharing:\n- **Traversal**: It traverses the tree from the `root_id` to find the correct position for the new `key`, just like a standard BST insertion.\n- **Path Copying**: As the recursion unwinds, it creates new parent nodes for the path leading back to the root. Each new node is allocated using our custom allocator. The child pointers of these new nodes are updated: one points to the newly created subtree, while the other points to the existing, untouched sibling subtree. This is structural sharing in action.\n- **Immutability**: No existing nodes are ever modified. A new root identifier is returned, representing the new version of the tree. If the key already exists, no nodes are copied, and the original `root_id` is returned, preserving the structure.\n\n**3. Mark-and-Sweep Garbage Collection**\nThe `garbage_collect` function implements the classic two-phase algorithm:\n- **Mark Phase**: This phase identifies all \"live\" nodes. It starts a graph traversal (e.g., Depth-First Search) from every root in the given `live_roots` set. Every node visited during this traversal is marked as reachable. A `set` is an efficient way to keep track of marked nodes.\n- **Sweep Phase**: This phase reclaims memory. It iterates through all nodes currently in the arena. Any node that was not marked during the mark phase is considered garbage. The identifier of each garbage node is removed from the arena and returned to the allocator's `free_list`. The sorted list of these reclaimed identifiers is then returned as the result of the GC process.\n\nBy combining these components, we create a system that not only leverages the power of persistence for versioning but also includes a mechanism to manage the lifecycle of nodes, preventing memory from growing indefinitely as old versions become obsolete.", "answer": "```python\nimport bisect\n\ndef solve():\n    \"\"\"\n    Solves the persistent binary search tree with garbage collection problem.\n    \"\"\"\n\n    class Node:\n        \"\"\"Represents a node in the binary search tree.\"\"\"\n        def __init__(self, key, left=None, right=None):\n            self.key = key\n            self.left = left  # Node ID or None\n            self.right = right # Node ID or None\n\n        def __repr__(self):\n            return f\"N(k={self.key}, l={self.left}, r={self.right})\"\n\n    class Allocator:\n        \"\"\"Manages allocation and deallocation of node identifiers.\"\"\"\n        def __init__(self):\n            self.free_list = []\n            self.next_fresh_id = 0\n\n        def allocate(self):\n            \"\"\"\n            Allocates a node identifier. Reuses from free list if available,\n            otherwise allocates a fresh one.\n            Returns a tuple (id, was_reused).\n            \"\"\"\n            if self.free_list:\n                reused_id = self.free_list.pop(0)\n                return reused_id, True\n            else:\n                new_id = self.next_fresh_id\n                self.next_fresh_id += 1\n                return new_id, False\n\n        def deallocate(self, node_id):\n            \"\"\"Adds a reclaimed node ID to the free list, maintaining sort order.\"\"\"\n            bisect.insort_left(self.free_list, node_id)\n\n    def p_insert(root_id, key, arena, allocator, reused_ids_tracker):\n        \"\"\"\n        Performs a path-copying persistent insertion of a key into the BST.\n        - root_id: The ID of the root of the tree to insert into.\n        - key: The integer key to insert.\n        - arena: The dictionary mapping node IDs to Node objects.\n        - allocator: The allocator for node identifiers.\n        - reused_ids_tracker: A list to record reused node IDs.\n        Returns the ID of the new root of the modified tree.\n        \"\"\"\n        if root_id is None:\n            new_id, was_reused = allocator.allocate()\n            if was_reused:\n                reused_ids_tracker.append(new_id)\n            arena[new_id] = Node(key)\n            return new_id\n\n        node = arena[root_id]\n\n        if key == node.key:\n            return root_id # Duplicate key, structure is unchanged\n\n        if key  node.key:\n            new_left_id = p_insert(node.left, key, arena, allocator, reused_ids_tracker)\n            if new_left_id == node.left:\n                return root_id # Left subtree was unchanged\n            else:\n                # Path copy the current node\n                new_root_id, was_reused = allocator.allocate()\n                if was_reused:\n                    reused_ids_tracker.append(new_root_id)\n                arena[new_root_id] = Node(node.key, new_left_id, node.right)\n                return new_root_id\n        else:  # key > node.key\n            new_right_id = p_insert(node.right, key, arena, allocator, reused_ids_tracker)\n            if new_right_id == node.right:\n                return root_id # Right subtree was unchanged\n            else:\n                # Path copy the current node\n                new_root_id, was_reused = allocator.allocate()\n                if was_reused:\n                    reused_ids_tracker.append(new_root_id)\n                arena[new_root_id] = Node(node.key, node.left, new_right_id)\n                return new_root_id\n\n    def garbage_collect(live_roots, arena, allocator):\n        \"\"\"\n        Performs mark-and-sweep garbage collection.\n        - live_roots: A set of node IDs that are considered live.\n        - arena: The node store.\n        - allocator: The memory allocator.\n        Returns a sorted list of reclaimed node IDs.\n        \"\"\"\n        # Mark phase: Find all reachable nodes from live roots\n        reachable_nodes = set()\n        stack = list(live_roots)\n        while stack:\n            node_id = stack.pop()\n            if node_id is not None and node_id not in reachable_nodes:\n                reachable_nodes.add(node_id)\n                # It's possible for a live_root not to be in the arena if it was\n                # part of a tree that was completely reclaimed.\n                if node_id in arena:\n                    node = arena[node_id]\n                    stack.append(node.left)\n                    stack.append(node.right)\n\n        # Sweep phase: Reclaim all unreachable nodes\n        all_nodes = set(arena.keys())\n        unreachable_nodes = all_nodes - reachable_nodes\n        reclaimed_ids = sorted(list(unreachable_nodes))\n\n        for reclaimed_id in reclaimed_ids:\n            del arena[reclaimed_id]\n            allocator.deallocate(reclaimed_id)\n            \n        return reclaimed_ids\n\n    results = []\n\n    # --- Case 1 ---\n    arena1, allocator1 = {}, Allocator()\n    roots1 = []\n    current_root1 = None\n    for k in [2, 1, 3]:\n        current_root1 = p_insert(current_root1, k, arena1, allocator1, [])\n        roots1.append(current_root1)\n    \n    live_roots1 = {roots1[2]}\n    reclaimed_ids1 = garbage_collect(live_roots1, arena1, allocator1)\n\n    reused_ids_tracker1 = []\n    post_gc_root1 = roots1[2]\n    for k in [0, 4]:\n        post_gc_root1 = p_insert(post_gc_root1, k, arena1, allocator1, reused_ids_tracker1)\n    \n    results.append(f\"[[{','.join(map(str, reclaimed_ids1))}],[{','.join(map(str, reused_ids_tracker1))}]]\")\n\n    # --- Case 2 ---\n    arena2, allocator2 = {}, Allocator()\n    roots2 = []\n    current_root2 = None\n    for k in [4, 2, 6, 1, 3, 5, 7]:\n        current_root2 = p_insert(current_root2, k, arena2, allocator2, [])\n        roots2.append(current_root2)\n    \n    live_roots2 = {roots2[2], roots2[6]}\n    reclaimed_ids2 = garbage_collect(live_roots2, arena2, allocator2)\n\n    reused_ids_tracker2 = []\n    post_gc_root2 = roots2[6]\n    for k in [8]:\n        post_gc_root2 = p_insert(post_gc_root2, k, arena2, allocator2, reused_ids_tracker2)\n    \n    results.append(f\"[[{','.join(map(str, reclaimed_ids2))}],[{','.join(map(str, reused_ids_tracker2))}]]\")\n\n    # --- Case 3 ---\n    arena3, allocator3 = {}, Allocator()\n    roots3 = []\n    current_root3 = None\n    for k in [10, 5, 15]:\n        current_root3 = p_insert(current_root3, k, arena3, allocator3, [])\n        roots3.append(current_root3)\n        \n    live_roots3 = set()\n    reclaimed_ids3 = garbage_collect(live_roots3, arena3, allocator3)\n\n    reused_ids_tracker3 = []\n    post_gc_root3 = None\n    for k in [12, 11]:\n        post_gc_root3 = p_insert(post_gc_root3, k, arena3, allocator3, reused_ids_tracker3)\n    \n    results.append(f\"[[{','.join(map(str, reclaimed_ids3))}],[{','.join(map(str, reused_ids_tracker3))}]]\")\n\n    # --- Case 4 ---\n    arena4, allocator4 = {}, Allocator()\n    roots4 = []\n    current_root4 = None\n    for k in [2, 1, 3]:\n        current_root4 = p_insert(current_root4, k, arena4, allocator4, [])\n        roots4.append(current_root4)\n\n    live_roots4 = {roots4[0], roots4[1], roots4[2]}\n    reclaimed_ids4 = garbage_collect(live_roots4, arena4, allocator4)\n\n    reused_ids_tracker4 = []\n    post_gc_root4 = roots4[2] # latest root\n    for k in [4]:\n        post_gc_root4 = p_insert(post_gc_root4, k, arena4, allocator4, reused_ids_tracker4)\n\n    results.append(f\"[[{','.join(map(str, reclaimed_ids4))}],[{','.join(map(str, reused_ids_tracker4))}]]\")\n\n    # Final aggregated output\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3258649"}]}