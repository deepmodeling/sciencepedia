{"hands_on_practices": [{"introduction": "While the VERTEX-COVER problem is famously difficult for general graphs, its complexity can change dramatically when we impose structural constraints on the input. This practice demonstrates how the specific structure of a tree allows for a powerful divide-and-conquer approach. By designing a dynamic programming algorithm, you will find an efficient, polynomial-time solution for a problem that is otherwise intractable, offering a key lesson in exploiting problem constraints for algorithmic design [@problem_id:3256361].", "problem": "Consider the canonical decision problem $\\text{VERTEX-COVER}$: given a graph $G = (V,E)$ and an integer $k$, decide whether there exists a subset $S \\subseteq V$ of size at most $k$ such that every edge in $E$ has at least one endpoint in $S$. In general graphs this problem is known to be Nondeterministic Polynomial time (NP)-complete. However, when the input graph is a tree, the problem exhibits structure that enables a polynomial-time solution. Starting from first principles, namely the definitions of vertex cover, tree, and optimal substructure, derive a dynamic programming (DP) algorithm that, given a tree $T = (V,E)$ with $|V| = n$, computes the size of a minimum vertex cover in time polynomial in $n$. Specifically:\n\n1. Formalize the optimal substructure required to support dynamic programming on trees without relying on any pre-stated formulas.\n2. Prove correctness of your approach by arguing that all edges are covered and the solution is minimal via a local-to-global optimality argument over the tree structure.\n3. Analyze the time and space complexity of your algorithm as functions of $n$.\n\nThen apply your algorithm to the following tree instance $T$ with vertex set $V = \\{1,2,3,4,5,6,7,8,9,10,11,12,13,14\\}$ and edge set\n$$\nE = \\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(7,10),(7,11),(9,12),(10,13),(10,14)\\}.\n$$\nRoot the tree at vertex $1$ and compute the size of a minimum vertex cover for $T$. Express your final answer as a single integer (no units). No rounding is required.", "solution": "The problem asks for the derivation and application of a dynamic programming algorithm to find the size of a minimum vertex cover for a given tree. A vertex cover of a graph $G=(V,E)$ is a subset of vertices $S \\subseteq V$ such that for every edge $(u,v) \\in E$, at least one of $u$ or $v$ is in $S$. The minimum vertex cover is a vertex cover of the smallest possible size. The problem is known to be NP-complete for general graphs but is solvable in polynomial time for trees.\n\nWe will first formalize the dynamic programming approach, prove its correctness, analyze its complexity, and then apply it to the specific tree instance provided.\n\n### 1. Optimal Substructure and Dynamic Programming Formulation\n\nTo apply dynamic programming on a tree $T = (V,E)$, we first root it at an arbitrary vertex, which we denote as $r$. For the given instance, we are instructed to use vertex $1$ as the root. This imposes a parent-child structure on the tree. For any node $u \\in V$, let $T_u$ denote the subtree rooted at $u$, which includes $u$ and all its descendants.\n\nThe core idea of the dynamic programming approach is to compute the size of the minimum vertex cover for each subtree $T_u$ in a bottom-up fashion (i.e., via a post-order traversal). A simple state $DP(u)$ representing the size of the minimum vertex cover of $T_u$ is insufficient. The decision of whether to include $u$ in the cover for $T_u$ has implications for its parent, parent$(u)$. Specifically, if $u$ is not included in the cover, parent$(u)$ *must* be included to cover the edge (parent$(u)$, $u$). Therefore, our DP state must distinguish between these two cases.\n\nLet's define two values for each node $u \\in V$:\n- $DP_{in}(u)$: The size of a minimum vertex cover for the subtree $T_u$, with the constraint that the node $u$ *is included* in the vertex cover.\n- $DP_{out}(u)$: The size of a minimum vertex cover for the subtree $T_u$, with the constraint that the node $u$ *is not included* in the vertex cover.\n\nThe optimal substructure property holds: the optimal solution for the subtree $T_u$ can be constructed from the optimal solutions of the subtrees rooted at the children of $u$. Let $Children(u)$ be the set of children of node $u$.\n\nThe recurrence relations are derived as follows:\n\n**Case 1: $u$ is in the vertex cover ($DP_{in}(u)$).**\nIf we include $u$ in the cover, its own cost is $1$. By including $u$, all edges $(u,v)$ for $v \\in Children(u)$ are covered. For each child $v$, we are now free to either include $v$ in the cover for $T_v$ or not. To achieve a minimum size for the cover of $T_u$, we should choose the smaller of the two options for each child's subtree. Thus, for each $v \\in Children(u)$, we add $\\min(DP_{in}(v), DP_{out}(v))$ to the total.\n$$DP_{in}(u) = 1 + \\sum_{v \\in Children(u)} \\min(DP_{in}(v), DP_{out}(v))$$\n\n**Case 2: $u$ is not in the vertex cover ($DP_{out}(u)$).**\nIf we do not include $u$ in the cover, its own cost is $0$. However, to cover the edge $(u,v)$ for each child $v \\in Children(u)$, we are *forced* to include $v$ in the vertex cover for its subtree $T_v$. There is no other choice for covering these edges within the structure of $T_u$ (since $u$ is not in the cover and $v$ is the only other endpoint of the edge $(u,v)$). Therefore, for each child $v$, we must choose the solution where $v$ is included.\n$$DP_{out}(u) = \\sum_{v \\in Children(u)} DP_{in}(v)$$\n\n**Base Cases:**\nThe recursion terminates at the leaves of the tree. For any leaf node $l$, $Children(l) = \\emptyset$.\n- $DP_{in}(l) = 1$: The cover for the subtree $T_l$ (which is just the node $l$) is $\\{l\\}$, of size $1$.\n- $DP_{out}(l) = 0$: The cover for the subtree $T_l$ is $\\emptyset$, of size $0$. Since there are no edges within $T_l$, an empty set is a valid cover.\n\nFinally, after computing these values for all nodes up to the root $r$, the size of the minimum vertex cover for the entire tree $T$ is the minimum of the two possibilities for the root node: $\\min(DP_{in}(r), DP_{out}(r))$.\n\n### 2. Proof of Correctness\n\nWe prove correctness by induction on the structure of the tree, arguing that our algorithm finds a valid and minimal vertex cover for every subtree $T_u$.\n\n**Validity (All Edges Covered):**\n- **Base Case:** For a leaf $l$, the subtree $T_l$ has no edges, so the property holds trivially.\n- **Inductive Hypothesis (I.H.):** Assume for all children $v$ of a node $u$, the values $DP_{in}(v)$ and $DP_{out}(v)$ correspond to valid vertex covers for their respective subtrees $T_v$.\n- **Inductive Step:** Consider the subtree $T_u$. Its edges consist of the set $\\{(u,v) \\mid v \\in Children(u)\\}$ plus all edges within each subtree $T_v$.\n  - If we compute $DP_{in}(u)$, we include $u$ in the cover. This covers all edges $(u,v)$. By the I.H., the sub-solutions chosen for each $T_v$ cover all edges within those subtrees. Thus, all edges in $T_u$ are covered.\n  - If we compute $DP_{out}(u)$, we do not include $u$. The recurrence forces us to choose the $DP_{in}(v)$ solution for each child $v$. This means every $v \\in Children(u)$ is included in the cover, thereby covering all edges $(u,v)$. By the I.H., the $DP_{in}(v)$ solution also covers all edges within $T_v$. Thus, all edges in $T_u$ are covered.\nIn both cases, we produce a valid vertex cover for $T_u$.\n\n**Minimality (Optimality):**\n- **Base Case:** For a leaf $l$, $DP_{in}(l)=1$ and $DP_{out}(l)=0$ are clearly optimal for the respective constraints.\n- **I.H.:** Assume for all children $v$ of a node $u$, $DP_{in}(v)$ and $DP_{out}(v)$ are the sizes of the *minimum* vertex covers for $T_v$ subject to their constraints.\n- **Inductive Step:** Consider an optimal vertex cover $S^*$ for $T_u$.\n  - If $u \\in S^*$, then $S^* \\setminus \\{u\\}$ must cover all edges within the subtrees $T_v$. To do this optimally, for each $T_v$, the part of $S^*$ in $T_v$ must be a minimum vertex cover of $T_v$. The size would be $\\min(|S^*_{v,in}|, |S^*_{v,out}|)$, which by the I.H. is $\\min(DP_{in}(v), DP_{out}(v))$. Summing over all children and adding $1$ for $u$ shows that $|S^*| = DP_{in}(u)$.\n  - If $u \\notin S^*$, then to cover edges $(u,v)$, every child $v$ must be in $S^*$. The remainder of $S^*$ must then be an optimal cover for each $T_v$ given that $v$ is included. By the I.H., the size for each $T_v$ is $DP_{in}(v)$. Summing over all children shows that $|S^*| = DP_{out}(u)$.\nSince any optimal solution for $T_u$ must fall into one of these two categories, the minimum of $DP_{in}(u)$ and $DP_{out}(u)$ gives the size of the minimum vertex cover for $T_u$. This local optimality propagates to the root, ensuring a globally optimal solution.\n\n### 3. Complexity Analysis\n\n- **Time Complexity:** The algorithm computes two values, $DP_{in}(u)$ and $DP_{out}(u)$, for each node $u \\in V$. The computation for node $u$ requires summing over its children. A post-order traversal (e.g., using Depth First Search) ensures that when we compute the values for $u$, the values for all its children are already available. The total computation time is the sum of the work done at each node. The work at node $u$ is proportional to its number of children, $|Children(u)|$.\nThe total time is therefore proportional to $\\sum_{u \\in V} |Children(u)|$. In a tree with $n$ vertices, the sum of the number of children over all nodes is the total number of edges, which is $|E| = n-1$. Thus, the time complexity is $O(n-1) = O(n)$.\n- **Space Complexity:** We need to store the two DP values for each of the $n$ vertices. This requires $O(n)$ space. Additionally, if the algorithm is implemented recursively, the call stack can have a depth of at most $n$ (in the case of a path graph), also contributing $O(n)$ space. Therefore, the total space complexity is $O(n)$.\n\n### 4. Application to the Given Instance\n\nThe tree is $T=(V,E)$ with $V=\\{1, \\dots, 14\\}$ and $E = \\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(7,10),(7,11),(9,12),(10,13),(10,14)\\}$. We root the tree at vertex $1$. The parent-child relationships are:\n- $Children(1) = \\{2,3,4\\}$\n- $Children(2) = \\{5,6\\}$\n- $Children(3) = \\{7\\}$\n- $Children(4) = \\{8,9\\}$\n- $Children(7) = \\{10,11\\}$\n- $Children(9) = \\{12\\}$\n- $Children(10) = \\{13,14\\}$\n- Vertices $\\{5,6,8,11,12,13,14\\}$ are leaves.\n\nWe compute the DP values in a post-order traversal (bottom-up). For any node $u$, we denote its DP values as a pair $(DP_{in}(u), DP_{out}(u))$.\n\n**Leaves:** For any leaf $l \\in \\{5,6,8,11,12,13,14\\}$:\n- $(DP_{in}(l), DP_{out}(l)) = (1, 0)$\n\n**Node 2:** $Children(2)=\\{5,6\\}$\n- $DP_{in}(2) = 1 + \\min(DP_{in}(5), DP_{out}(5)) + \\min(DP_{in}(6), DP_{out}(6)) = 1 + \\min(1,0) + \\min(1,0) = 1+0+0 = 1$\n- $DP_{out}(2) = DP_{in}(5) + DP_{in}(6) = 1+1 = 2$\n- For node $2$: $(1, 2)$\n\n**Node 10:** $Children(10)=\\{13,14\\}$\n- $DP_{in}(10) = 1 + \\min(1,0) + \\min(1,0) = 1$\n- $DP_{out}(10) = 1+1 = 2$\n- For node $10$: $(1, 2)$\n\n**Node 7:** $Children(7)=\\{10,11\\}$\n- $DP_{in}(7) = 1 + \\min(DP_{in}(10), DP_{out}(10)) + \\min(DP_{in}(11), DP_{out}(11)) = 1 + \\min(1,2) + \\min(1,0) = 1+1+0 = 2$\n- $DP_{out}(7) = DP_{in}(10) + DP_{in}(11) = 1+1 = 2$\n- For node $7$: $(2, 2)$\n\n**Node 3:** $Children(3)=\\{7\\}$\n- $DP_{in}(3) = 1 + \\min(DP_{in}(7), DP_{out}(7)) = 1 + \\min(2,2) = 1+2 = 3$\n- $DP_{out}(3) = DP_{in}(7) = 2$\n- For node $3$: $(3, 2)$\n\n**Node 9:** $Children(9)=\\{12\\}$\n- $DP_{in}(9) = 1 + \\min(DP_{in}(12), DP_{out}(12)) = 1 + \\min(1,0) = 1$\n- $DP_{out}(9) = DP_{in}(12) = 1$\n- For node $9$: $(1, 1)$\n\n**Node 4:** $Children(4)=\\{8,9\\}$\n- $DP_{in}(4) = 1 + \\min(DP_{in}(8), DP_{out}(8)) + \\min(DP_{in}(9), DP_{out}(9)) = 1 + \\min(1,0) + \\min(1,1) = 1+0+1 = 2$\n- $DP_{out}(4) = DP_{in}(8) + DP_{in}(9) = 1+1 = 2$\n- For node $4$: $(2, 2)$\n\n**Root Node 1:** $Children(1)=\\{2,3,4\\}$\n- $DP_{in}(1) = 1 + \\min(DP_{in}(2), DP_{out}(2)) + \\min(DP_{in}(3), DP_{out}(3)) + \\min(DP_{in}(4), DP_{out}(4))$\n  $DP_{in}(1) = 1 + \\min(1,2) + \\min(3,2) + \\min(2,2) = 1 + 1 + 2 + 2 = 6$\n- $DP_{out}(1) = DP_{in}(2) + DP_{in}(3) + DP_{in}(4) = 1 + 3 + 2 = 6$\n- For node $1$: $(6, 6)$\n\nThe size of the minimum vertex cover for the entire tree $T$ is $\\min(DP_{in}(1), DP_{out}(1))$.\nSize = $\\min(6, 6) = 6$.", "answer": "$$\\boxed{6}$$", "id": "3256361"}, {"introduction": "The theory of NP-completeness is built around decision problems which have a simple \"yes\" or \"no\" answer. This exercise explores the profound connection between decision and search, showing that if we could solve the decision version of a problem efficiently, we could also find the actual solution. Using a hypothetical \"oracle\" for the CLIQUE decision problem, you will design an algorithm to construct a maximum clique, demonstrating the fundamental technique of a search-to-decision reduction [@problem_id:3256391].", "problem": "You are given access to a hypothetical decision oracle for the canonical Non-deterministic Polynomial-time (NP) problem CLIQUE. The input to the oracle is an undirected graph $G=(V,E)$ and an integer $k \\in \\mathbb{Z}_{\\ge 0}$, and the oracle returns whether there exists a subset $C \\subseteq V$ of size at least $k$ such that every distinct pair of vertices in $C$ is connected by an edge in $E$ (that is, $C$ is a clique of size at least $k$). Assume the oracle answers each query in $O(1)$ time.\n\nStarting only from the core definitions of graphs, cliques, decision versus search versions of problems, and the notion of a polynomial-time Turing reduction, derive from first principles a polynomial-time algorithm that, using the oracle as a subroutine, finds an actual maximum clique in a given graph. Justify correctness by explaining why your procedure always returns a clique of the largest possible size and why the number of oracle queries and all other computations are bounded by a polynomial in $|V|$. You must also fix a deterministic tie-breaking rule: among all maximum cliques, your algorithm must return the lexicographically smallest one when vertices are labeled by integers in ascending order. Here, lexicographic order on a clique $C=\\{v_1,\\dots,v_t\\}$ with $v_1<\\dots<v_t$ means that for two cliques $C$ and $C'$ with sorted sequences $(v_1,\\dots,v_t)$ and $(v'_1,\\dots,v'_t)$, we have $C \\prec C'$ if and only if there exists an index $i$ such that $v_j=v'_j$ for all $j<i$ and $v_i < v'_i$.\n\nImplement your derived algorithm as a complete program that hardcodes the following test suite of graphs. For each graph $G$, compute and output the lexicographically smallest maximum clique as a list of vertex indices in nondecreasing order. Vertices are labeled by consecutive integers starting at $0$. All graphs are simple, undirected, and without self-loops.\n\nTest suite (five graphs):\n- Graph $G_1$: $V=\\{0,1,2,3,4,5\\}$ and\n  $E=\\{(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(0,1),(0,2),(4,5)\\}$.\n- Graph $G_2$: $V=\\{0,1,2,3,4\\}$ and $E=\\{(u,v) \\mid u,v \\in V, u<v\\}$ (that is, the complete graph on $5$ vertices).\n- Graph $G_3$: $V=\\{0,1,2,3\\}$ and $E=\\emptyset$.\n- Graph $G_4$: $V=\\{0,1,2,3,4,5\\}$ and $E=\\{(0,1),(1,2),(0,2),(2,3),(3,4),(2,4)\\}$.\n- Graph $G_5$: $V=\\{0,1,2,3,4,5,6\\}$ and \n  $E=\\{(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(1,4),(2,4),(3,4),(4,5),(5,6),(4,6)\\}$.\n\nYour algorithm must be based solely on calls to the decision oracle and polynomial-time computations around it, using only the foundational facts that define cliques and decision problems. Do not assume any additional structure beyond what is stated. Your program must emulate the oracle internally in any correct manner, but the overall control flow must reflect a polynomial number of oracle calls relative to $|V|$, as justified by your derivation.\n\nAnswer format:\n- For each graph $G_i$, output the lexicographically smallest maximum clique as a list of integers. Aggregate the five answers in order $G_1$ through $G_5$ into a single list.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is itself a list, for example: $[[a_1,\\dots],[a_2,\\dots],\\dots]$.\n\nThere are no physical units, angles, or percentages in this problem; all outputs are lists of integers. The outputs must be fully determined by the specified test suite and the lexicographic tie-breaking rule.", "solution": "The problem requires the derivation and implementation of a polynomial-time algorithm to find the lexicographically smallest maximum clique in a graph $G=(V, E)$, given access to a decision oracle for the CLIQUE problem. The oracle, hereafter denoted `CLIQUE_ORACLE(G', k)`, returns `True` if graph $G'$ contains a clique of size at least $k$, and `False` otherwise, in $O(1)$ time. The derivation must be from first principles.\n\nLet $|V|=n$. The problem can be divided into two main parts:\n1.  Finding the size of the maximum clique.\n2.  Constructing the specific vertices of the lexicographically smallest maximum clique.\n\nThis is a classic example of a search-to-decision reduction, a fundamental concept in computational complexity theory demonstrating that if a decision problem can be solved efficiently, so can its corresponding search problem.\n\n### Part 1: Determining the Maximum Clique Size\n\nThe size of a maximum clique in $G$, let's call it $k_{max}$, must be an integer in the range $[0, n]$. We can determine $k_{max}$ by making a series of calls to the `CLIQUE_ORACLE`.\n\nA property of cliques is that if a graph has a clique of size $k$, it also has a clique of every size smaller than $k$. This means the function $f(k) = \\text{CLIQUE\\_ORACLE}(G, k)$ is monotonic: for $k \\in \\{0, 1, \\dots, n\\}$, the sequence of outputs $f(0), f(1), \\dots, f(n)$ will be of the form $(\\text{True}, \\dots, \\text{True}, \\text{False}, \\dots, \\text{False})$. We are interested in the largest $k$ for which $f(k)$ is `True`.\n\nThis value can be found efficiently using binary search over the range of possible sizes, $[0, n]$.\nLet the search range be `[low, high]`, initialized to $[0, n]$. In each step, we query the oracle with the midpoint `mid = (low + high) // 2`.\n- If `CLIQUE_ORACLE(G, mid)` returns `True`, we know a clique of size `mid` exists, so the maximum size is at least `mid`. We record `mid` as a potential answer and search for a larger size by setting `low = mid + 1`.\n- If `CLIQUE_ORACLE(G, mid)` returns `False`, no clique of size `mid` exists, so the maximum size must be smaller. We set `high = mid - 1`.\n\nThe binary search terminates when `low > high`, and the last `mid` for which the oracle returned `True` is the maximum clique size, $k_{max}$. This procedure involves $O(\\log n)$ calls to the oracle. Since each oracle call is $O(1)$, this part of the algorithm runs in $O(\\log n)$ time.\n\n### Part 2: Constructing the Lexicographically Smallest Maximum Clique\n\nOnce $k_{max}$ is known, we can construct the clique itself. The problem requires the lexicographically smallest maximum clique, where vertices are labeled by integers $0, 1, \\dots, n-1$. This tie-breaking rule implies a greedy approach. We should try to include vertices with the smallest indices first.\n\nWe will build the clique, let's call it $C$, one vertex at a time. We iterate through all vertices $v \\in V$ in increasing order of their indices, from $0$ to $n-1$. At each step, we decide whether to add vertex $v$ to our clique $C$.\n\nThe greedy choice is as follows: A vertex $v$ is added to $C$ if and only if there exists a maximum clique of size $k_{max}$ that is a superset of $C \\cup \\{v\\}$. This check can be performed using the oracle.\n\nLet's formalize the algorithm for construction:\n1.  Initialize an empty set for the clique, $C = \\emptyset$.\n2.  Let the vertices of $G$ be $v_0, v_1, \\dots, v_{n-1}$ in increasing order of their integer labels.\n3.  For each vertex $v_i$ from $i=0$ to $n-1$:\n    a. Form a potential clique prefix $C_{potential} = C \\cup \\{v_i\\}$.\n    b. A necessary condition for $C_{potential}$ to be part of a larger clique is that $C_{potential}$ must itself be a clique. This means $v_i$ must be adjacent to every vertex already in $C$. If not, we cannot add $v_i$ and continue to the next vertex.\n    c. If $C_{potential}$ is a clique, we must check if it can be extended to a clique of size $k_{max}$. The remaining $k_{needed} = k_{max} - |C_{potential}|$ vertices must be chosen from the set of vertices that are adjacent to *all* vertices in $C_{potential}$. Let this set of candidate vertices be $U = \\{u \\in V \\mid \\forall w \\in C_{potential}, (u, w) \\in E \\}$.\n    d. Let $G_U$ be the subgraph of $G$ induced by the vertex set $U$. The problem reduces to asking if there exists a clique of size $k_{needed}$ within the graph $G_U$. This is precisely what the oracle can answer.\n    e. We call `CLIQUE_ORACLE(G_U, k_needed)`.\n    f. If the oracle returns `True`, it confirms that a maximum clique containing $C_{potential}$ exists. Since we are iterating through vertices in increasing order, adding $v_i$ is the correct greedy choice to maintain the lexicographically smallest property. We permanently add $v_i$ to our solution: $C \\leftarrow C \\cup \\{v_i\\}$.\n    g. If the oracle returns `False`, no maximum clique contains the prefix $C_{potential}$. We do not add $v_i$ to $C$ and proceed to the next vertex.\n4.  Once $|C| = k_{max}$, the clique is complete, and we can terminate. The final set $C$ is the lexicographically smallest maximum clique.\n\n### Correctness and Complexity Analysis\n\n**Correctness:** Let $C^* = \\{c_1, c_2, \\dots, c_{k_{max}}\\}$ be the true lexicographically smallest maximum clique, with $c_1 < c_2 < \\dots < c_{k_{max}}$. The algorithm iterates through vertices $v_0, v_1, \\dots, v_{n-1}$. For any vertex $v_i < c_1$, the algorithm will test if adding it can lead to a $k_{max}$-clique. If it could, we would find a maximum clique lexicographically smaller than $C^*$, a contradiction. Thus, the test must fail for all $v_i < c_1$. When the algorithm reaches $v_{c_1}$, the test will pass because $C^*$ is a valid extension. The algorithm adds $c_1$ to its clique. This reasoning extends inductively: at each step, the algorithm makes the same choice as prescripted by $C^*$, ensuring the final constructed clique is indeed $C^*$.\n\n**Complexity:**\n- **Part 1 (Finding $k_{max}$):** $O(\\log n)$ oracle calls and negligible computation.\n- **Part 2 (Constructing $C$):**\n    - The main loop runs at most $n$ times.\n    - Inside the loop, for each vertex $v_i$:\n        - Compatibility check (step 3b): $O(|C|) = O(n)$.\n        - Identifying the candidate set $U$ (step 3c): For each of the $O(n)$ vertices in $V$, we check adjacency against $O(|C_{potential}|) = O(n)$ vertices. This takes $O(n^2)$ time.\n        - Constructing the subgraph $G_U$ (step 3d): This can take up to $O(n^2)$ time to build an adjacency matrix for a graph with $O(n)$ vertices.\n        - Oracle call (step 3e): $O(1)$.\n    - The total computational work is dominated by the construction of subgraphs inside the loop, leading to a complexity of $O(n \\cdot n^2) = O(n^3)$.\n    - The number of oracle calls in this part is at most $n$.\n\nThe total number of oracle calls is $O(n + \\log n) = O(n)$, and the total computational time is $O(n^3)$. Since both are bounded by a polynomial in $n=|V|$, the algorithm is a polynomial-time Turing reduction.\n\nThis completes the derivation from first principles. The algorithm correctly finds the required clique and respects the polynomial-time constraint relative to the oracle.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Derives and implements an algorithm to find the lexicographically smallest maximum clique\n    using a hypothetical decision oracle for the CLIQUE problem.\n    \"\"\"\n\n    # This nested function serves as the emulated oracle for the CLIQUE decision problem.\n    # Its internal implementation uses brute force, which is acceptable because the\n    # problem's focus is on the polynomial-time reduction algorithm that uses the oracle,\n    # not the oracle's own efficiency. A cache is used to memoize results for a given graph,\n    # significantly speeding up the emulation for repeated queries.\n    _oracle_cache = {}\n\n    def get_adj_hash(adj):\n        \"\"\"Returns a hashable representation of a numpy array.\"\"\"\n        return adj.tobytes()\n\n    def clique_oracle(adj, k):\n        \"\"\"\n        Decision oracle for CLIQUE. Returns True if graph `adj` has a clique of size >= `k`.\n        \"\"\"\n        n = adj.shape[0]\n        adj_hash = get_adj_hash(adj)\n\n        if (adj_hash, k) in _oracle_cache:\n            return _oracle_cache[(adj_hash, k)]\n        \n        if k is None or k < 0: return True\n        if k == 0: return True\n        if n == 0 and k > 0: return False\n        if k == 1 and n > 0: return True\n        if k > n : return False\n        \n        # Check if the maximum clique size for this graph is already computed.\n        max_k_cache_key = (adj_hash, None)\n        if max_k_cache_key in _oracle_cache:\n            max_k_found = _oracle_cache[max_k_cache_key]\n            result = max_k_found >= k\n            _oracle_cache[(adj_hash, k)] = result\n            return result\n\n        # Brute-force check using itertools.combinations to find max clique size\n        nodes = list(range(n))\n        max_k = 0\n        if n > 0:\n            max_k = 1 # At least a 1-clique (single vertex) exists\n        for size in range(n, 1, -1):\n            found_clique_of_this_size = False\n            for combo in itertools.combinations(nodes, size):\n                is_a_clique = True\n                for i1_idx in range(len(combo)):\n                    for i2_idx in range(i1_idx + 1, len(combo)):\n                        u, v = combo[i1_idx], combo[i2_idx]\n                        if not adj[u, v]:\n                            is_a_clique = False\n                            break\n                    if not is_a_clique:\n                        break\n                if is_a_clique:\n                    max_k = size\n                    found_clique_of_this_size = True\n                    break\n            if found_clique_of_this_size:\n                break\n        \n        _oracle_cache[max_k_cache_key] = max_k\n        result = max_k >= k\n        _oracle_cache[(adj_hash, k)] = result\n        return result\n\n    # --- Test Suite Definition ---\n    \n    # G1: V={0..5}, E={(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(0,1),(0,2),(4,5)}\n    adj1 = np.zeros((6, 6), dtype=bool)\n    for u, v in [(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(0,1),(0,2),(4,5)]:\n        adj1[u,v] = adj1[v,u] = True\n\n    # G2: K5 on V={0..4}\n    adj2 = np.ones((5, 5), dtype=bool)\n    np.fill_diagonal(adj2, False)\n\n    # G3: V={0..3}, E=empty\n    adj3 = np.zeros((4, 4), dtype=bool)\n\n    # G4: V={0..5}, E={(0,1),(1,2),(0,2),(2,3),(3,4),(2,4)}\n    adj4 = np.zeros((6, 6), dtype=bool)\n    for u, v in [(0,1),(1,2),(0,2),(2,3),(3,4),(2,4)]:\n        adj4[u,v] = adj4[v,u] = True\n\n    # G5: V={0..6}, E={(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(1,4),(2,4),(3,4),(4,5),(5,6),(4,6)}\n    adj5 = np.zeros((7, 7), dtype=bool)\n    for u, v in [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(1,4),(2,4),(3,4),(4,5),(5,6),(4,6)]:\n        adj5[u,v] = adj5[v,u] = True\n\n    test_cases = [adj1, adj2, adj3, adj4, adj5]\n    all_results = []\n    \n    for adj in test_cases:\n        _oracle_cache.clear()\n        n = adj.shape[0]\n\n        # Part 1: Find k_max using binary search on the oracle\n        k_max = 0\n        if n > 0:\n            low, high = 1, n\n            while low <= high:\n                mid = (low + high) // 2\n                if mid == 0:\n                    low = mid + 1\n                    continue\n                if clique_oracle(adj, mid):\n                    k_max = mid\n                    low = mid + 1\n                else:\n                    high = mid - 1\n\n        # Part 2: Construct the lexicographically smallest max clique\n        clique = []\n        for v_idx in range(n):\n            if len(clique) == k_max:\n                break\n                \n            is_compatible = all(adj[v_idx, c_node] for c_node in clique)\n            if not is_compatible:\n                continue\n\n            potential_clique = clique + [v_idx]\n            k_needed = k_max - len(potential_clique)\n\n            test_result = False\n            if k_needed < 0: continue\n            if k_needed == 0:\n                test_result = True\n            else:\n                common_neighbors = [u for u in range(v_idx + 1, n) if all(adj[u, pc_node] for pc_node in potential_clique)]\n                \n                if len(common_neighbors) >= k_needed:\n                    sub_n = len(common_neighbors)\n                    sub_adj = np.zeros((sub_n, sub_n), dtype=bool)\n                    for i in range(sub_n):\n                        for j in range(i + 1, sub_n):\n                            u1, u2 = common_neighbors[i], common_neighbors[j]\n                            if adj[u1, u2]:\n                                sub_adj[i, j] = sub_adj[j, i] = True\n                    test_result = clique_oracle(sub_adj, k_needed)\n            \n            if test_result:\n                clique.append(v_idx)\n        \n        all_results.append(clique)\n\n    string_results = [str(r).replace(\" \", \"\") for r in all_results]\n    print(f\"[{','.join(string_results)}]\")\n\nsolve()\n```", "id": "3256391"}, {"introduction": "When faced with an NP-hard problem, finding a guaranteed optimal solution in polynomial time is considered impossible. A practical alternative is to use approximation algorithms, which trade optimality for speed. This practice delves into the critical analysis of such algorithms by examining how a standard greedy strategy for the SET-COVER problem can be forced to produce a solution far from optimal on a cleverly constructed instance, teaching you to formally quantify performance via the approximation ratio [@problem_id:3256360].", "problem": "Consider the canonical Set-Cover problem, which is known to be NP-complete. In the weighted version, one is given a finite universe $U$ and a family of subsets $\\mathcal{S} \\subseteq 2^{U}$, where each set $S \\in \\mathcal{S}$ has an associated nonnegative cost $c(S)$. A set cover is a subfamily $\\mathcal{C} \\subseteq \\mathcal{S}$ whose union is $U$. The standard greedy approximation algorithm for weighted Set-Cover iteratively chooses a set $S \\in \\mathcal{S}$ that minimizes the ratio $c(S)/|S \\setminus C|$, where $C$ is the set of elements already covered, until $U$ is fully covered.\n\nDesign a specific family of weighted Set-Cover instances parameterized by an integer $r \\geq 2$ and a real parameter $\\epsilon$ with $0 < \\epsilon < 1$, as follows. Let the universe be any set $U$ with $|U| = 2^{r}$. Partition $U$ into $r+1$ disjoint blocks $B_{1}, B_{2}, \\dots, B_{r}, B_{r+1}$ with sizes $|B_{j}| = 2^{r-j}$ for each $1 \\leq j \\leq r$ and $|B_{r+1}| = 1$. Define the family of sets $\\mathcal{S}$ to consist of:\n- the single global set $G = U$ with cost $c(G) = 2 + \\epsilon$, and\n- the $r+1$ block sets $A_{j} = B_{j}$ with costs $c(A_{j}) = 1$ for all $1 \\leq j \\leq r+1$.\n\nUsing only the core definitions of Set-Cover and the stated greedy rule, derive the exact approximation ratio of the greedy algorithm on this instance family, defined as the total cost returned by the greedy algorithm divided by the optimal cost. Express your final answer as a single simplified symbolic expression in terms of $r$ and $\\epsilon$. No rounding is needed, and no units are involved.", "solution": "The problem asks for the derivation of the exact approximation ratio of the standard greedy algorithm for weighted Set-Cover on a specific family of instances. The approximation ratio is defined as the total cost of the cover produced by the greedy algorithm divided by the cost of an optimal cover.\n\nLet us first formalize the problem givens.\nThe universe is a set $U$ with size $|U| = 2^r$, where $r \\geq 2$ is an integer.\nThe universe $U$ is partitioned into $r+1$ disjoint blocks: $U = B_1 \\cup B_2 \\cup \\dots \\cup B_r \\cup B_{r+1}$.\nThe sizes of these blocks are given by $|B_j| = 2^{r-j}$ for $1 \\leq j \\leq r$, and $|B_{r+1}| = 1$.\nThe sum of the sizes of the blocks is $\\sum_{j=1}^{r} |B_j| + |B_{r+1}| = \\left(\\sum_{j=1}^{r} 2^{r-j}\\right) + 1$. The sum is a geometric series: $\\sum_{k=0}^{r-1} 2^k = \\frac{2^r - 1}{2-1} = 2^r - 1$. Thus, the total size is $(2^r - 1) + 1 = 2^r$, which correctly matches $|U|$.\n\nThe family of subsets $\\mathcal{S}$ is composed of:\n1.  A single global set $G = U$ with cost $c(G) = 2 + \\epsilon$, where $0 < \\epsilon < 1$.\n2.  A set of $r+1$ block sets $A_j = B_j$ for $1 \\leq j \\leq r+1$, each with cost $c(A_j) = 1$.\n\nThe solution requires two components: the cost of an optimal solution, $C_{OPT}$, and the cost of the solution produced by the greedy algorithm, $C_{Greedy}$.\n\n**1. Determining the Optimal Cost ($C_{OPT}$)**\n\nA set cover for $U$ must be a subfamily of $\\mathcal{S}$ whose union is $U$. We identify two primary candidates for the optimal cover:\n-   **Candidate 1:** Choose the single set $G$. Since $G=U$, this forms a valid cover. The cost of this cover is $C_1 = c(G) = 2 + \\epsilon$.\n-   **Candidate 2:** Choose the collection of all block sets $\\{A_1, A_2, \\dots, A_{r+1}\\}$. Since the blocks $\\{B_1, \\dots, B_{r+1}\\}$ form a partition of $U$, their union is $U$. Thus, $\\bigcup_{j=1}^{r+1} A_j = \\bigcup_{j=1}^{r+1} B_j = U$. This is a valid cover. The cost of this cover is $C_2 = \\sum_{j=1}^{r+1} c(A_j) = \\sum_{j=1}^{r+1} 1 = r+1$.\n\nAny other valid cover would be a superset of one of these and thus more expensive. For instance, $\\{G, A_1\\}$ is a valid cover but costs more than $\\{G\\}$.\nThe optimal cost $C_{OPT}$ is the minimum of the costs of all possible valid covers. Therefore, $C_{OPT} = \\min(C_1, C_2) = \\min(2+\\epsilon, r+1)$.\n\nGiven the constraints $r \\geq 2$ and $0 < \\epsilon < 1$:\n-   The value of $r+1$ is an integer greater than or equal to $3$.\n-   The value of $2+\\epsilon$ is a real number such that $2 < 2+\\epsilon < 3$.\nSince $r+1 \\geq 3$ and $2+\\epsilon < 3$, it is always true that $2+\\epsilon < r+1$.\nTherefore, the minimum cost is achieved by choosing the single set $G$.\n$$C_{OPT} = 2 + \\epsilon$$\n\n**2. Determining the Greedy Algorithm's Cost ($C_{Greedy}$)**\n\nThe greedy algorithm iteratively selects the set $S$ that minimizes the cost-effectiveness ratio, defined as $\\frac{c(S)}{|S \\setminus C|}$, where $C$ is the set of elements already covered. Let $C_k$ be the set of covered elements after iteration $k$.\n\n**Iteration 1:**\nInitially, the set of covered elements is empty, $C_0 = \\emptyset$. We calculate the ratio for each set $S \\in \\mathcal{S}$.\n-   For the global set $G$: $\\frac{c(G)}{|G \\setminus C_0|} = \\frac{2+\\epsilon}{|G|} = \\frac{2+\\epsilon}{2^r}$.\n-   For the block sets $A_j=B_j$ ($1 \\leq j \\leq r$): $\\frac{c(A_j)}{|A_j \\setminus C_0|} = \\frac{1}{|B_j|} = \\frac{1}{2^{r-j}}$.\n-   For the block set $A_{r+1}=B_{r+1}$: $\\frac{c(A_{r+1})}{|A_{r+1} \\setminus C_0|} = \\frac{1}{|B_{r+1}|} = \\frac{1}{1} = 1$.\n\nThe set of ratios for the block sets is $\\{\\frac{1}{2^{r-1}}, \\frac{1}{2^{r-2}}, \\dots, \\frac{1}{2^1}, \\frac{1}{2^0}=1, 1\\}$. The minimum of these is $\\frac{1}{2^{r-1}}$, corresponding to the set $A_1$.\nNow, we compare this minimum ratio with the ratio for set $G$.\nWe compare $\\frac{1}{2^{r-1}}$ and $\\frac{2+\\epsilon}{2^r}$.\nMultiplying both by $2^r$ gives $2$ and $2+\\epsilon$.\nSince $0 < \\epsilon < 1$, we have $2 < 2+\\epsilon$. Thus, $\\frac{2}{2^r} < \\frac{2+\\epsilon}{2^r}$, which means $\\frac{1}{2^{r-1}} < \\frac{2+\\epsilon}{2^r}$.\nThe greedy algorithm selects the set with the minimum ratio, which is $A_1$.\nThe cost incurred is $1$. The set of covered elements becomes $C_1 = B_1$.\n\n**Iteration $k$ (for $2 \\leq k \\leq r$):**\nLet us assume that for iterations $1, 2, \\dots, k-1$, the algorithm has selected the sets $A_1, A_2, \\dots, A_{k-1}$.\nThe set of covered elements is $C_{k-1} = \\bigcup_{i=1}^{k-1} B_i$. The remaining sets to consider are $\\{G, A_k, A_{k+1}, \\dots, A_{r+1}\\}$.\nThe number of uncovered elements is $|U \\setminus C_{k-1}| = |U| - \\sum_{i=1}^{k-1} |B_i| = 2^r - \\sum_{i=1}^{k-1} 2^{r-i}$.\nThe sum is a geometric series: $\\sum_{i=1}^{k-1} 2^{r-i} = 2^{r-1} + 2^{r-2} + \\dots + 2^{r-k+1} = 2^{r-k+1}(2^{k-2} + \\dots + 1) = 2^{r-k+1}(2^{k-1}-1) = 2^r-2^{r-k+1}$.\nSo, $|U \\setminus C_{k-1}| = 2^r - (2^r-2^{r-k+1}) = 2^{r-k+1}$.\n\nNow we evaluate the ratios:\n-   For the global set $G$: $\\frac{c(G)}{|G \\setminus C_{k-1}|} = \\frac{2+\\epsilon}{|U \\setminus C_{k-1}|} = \\frac{2+\\epsilon}{2^{r-k+1}}$.\n-   For the block sets $A_j$ where $j \\geq k$, since $B_j$ is disjoint from $C_{k-1}$, we have $|A_j \\setminus C_{k-1}|=|A_j|=|B_j|$.\n    The ratio is $\\frac{c(A_j)}{|A_j \\setminus C_{k-1}|} = \\frac{1}{|B_j|}$.\n    The minimum of these ratios for $j \\in \\{k, \\dots, r+1\\}$ corresponds to the set $A_j$ with the largest size $|B_j|$, which is $A_k$ with size $|B_k|=2^{r-k}$. The minimum ratio is $\\frac{1}{2^{r-k}}$.\n\nComparing the minimum ratio for a block set with the ratio for $G$:\nWe compare $\\frac{1}{2^{r-k}}$ and $\\frac{2+\\epsilon}{2^{r-k+1}}$.\nMultiplying both by $2^{r-k+1}$ gives $2$ and $2+\\epsilon$.\nSince $2 < 2+\\epsilon$, we have $\\frac{1}{2^{r-k}} < \\frac{2+\\epsilon}{2^{r-k+1}}$.\nThe greedy algorithm selects $A_k$. This holds for all $k$ from $2$ to $r$.\n\n**Last Iteration ($k=r+1$):**\nAfter $r$ iterations, the algorithm has selected sets $A_1, A_2, \\dots, A_r$.\nThe covered set is $C_r = \\bigcup_{j=1}^{r} B_j$. The only uncovered elements are in the block $B_{r+1}$.\nThe sets available to cover these elements are $G$ and $A_{r+1}$.\n-   For the global set $G$: $\\frac{c(G)}{|G \\setminus C_r|} = \\frac{2+\\epsilon}{|B_{r+1}|} = \\frac{2+\\epsilon}{1} = 2+\\epsilon$.\n-   For the block set $A_{r+1}$: $\\frac{c(A_{r+1})}{|A_{r+1} \\setminus C_r|} = \\frac{1}{|B_{r+1}|} = \\frac{1}{1} = 1$.\n\nComparing the ratios, $1 < 2+\\epsilon$. The algorithm selects $A_{r+1}$.\nNow all elements in $U$ are covered, and the algorithm terminates.\n\nThe collection of sets selected by the greedy algorithm is $\\mathcal{C}_{Greedy} = \\{A_1, A_2, \\dots, A_r, A_{r+1}\\}$.\nThe total cost of this cover is $C_{Greedy} = \\sum_{j=1}^{r+1} c(A_j) = \\sum_{j=1}^{r+1} 1 = r+1$.\n\n**3. Calculating the Approximation Ratio**\n\nThe approximation ratio is given by the formula $\\frac{C_{Greedy}}{C_{OPT}}$.\nSubstituting the derived values:\n$$ \\text{Approximation ratio} = \\frac{r+1}{2+\\epsilon} $$\n\nThis expression is the exact approximation ratio of the greedy algorithm for the given family of instances.", "answer": "$$\\boxed{\\frac{r+1}{2+\\epsilon}}$$", "id": "3256360"}]}