{"hands_on_practices": [{"introduction": "This practice serves as a fundamental introduction to amortized analysis using the aggregate method. By analyzing a dynamic array, you will derive the total cost of a sequence of operations to determine the average cost, revealing how occasional expensive resizes can be \"paid for\" by many cheap appends. This exercise [@problem_id:3206964] demonstrates how the choice of growth factor, $\\alpha$, directly influences the constant amortized cost, a key insight in data structure design.", "problem": "A dynamic array supports an operation that appends a single element at the end. The array is created empty with initial capacity $1$. Whenever an append occurs into a full array of capacity $C$, the array is resized by allocating a new array of capacity exactly $\\alpha C$, where $\\alpha1$ is a fixed real growth factor, and then copying all $C$ current elements into the new array. The cost model counts only element movements caused by resizing (that is, copying existing elements into the new array); writing the newly appended element is not counted. Let $M_{\\alpha}(N)$ denote the total number of existing elements moved due to all resizing operations during the first $N$ appends, starting from an empty array.\n\nDefine $c_{\\alpha}$ to be the smallest real constant such that the inequality $M_{\\alpha}(N)\\leq c_{\\alpha} N$ holds for all integers $N\\geq 1$.\n\nUsing only first principles of amortized analysis and basic properties of geometric series, derive $c_{\\alpha}$ and then compute the exact value of the ratio $c_{3/2}/c_{2}$. Express your final answer as a single exact number with no units. Do not use pre-established results specific to dynamic arrays beyond the definitions above.", "solution": "The problem asks for the derivation of a constant $c_{\\alpha}$ related to the amortized cost of appends in a dynamic array and for the computation of the ratio $c_{3/2}/c_{2}$.\n\nFirst, we establish the model for the resizing process based on the problem statement. The array starts with a capacity of $1$. When an append operation is performed on a full array of capacity $C$, a new array of capacity $\\alpha C$ is allocated, and the $C$ existing elements are copied. The growth factor $\\alpha$ is a real number greater than $1$.\n\nLet us analyze the sequence of events.\nInitial state: The array is empty, and its capacity is $C_0 = 1$.\nThe first append operation places an element into the array, which now contains $n=1$ element and has capacity $C_0=1$. The array is full. No copies were made, so $M_{\\alpha}(1) = 0$.\n\nFor the second append ($N=2$), the array is full. A resize is triggered.\nThe number of elements to copy is the current capacity, $C_0=1$.\nThe new capacity becomes $C_1 = \\alpha C_0 = \\alpha$.\nAfter this first resize, the array contains $2$ elements.\n\nThe standard simplifying assumption in this analysis, which aligns with the \"first principles\" and \"geometric series\" directive, is to model the capacities as a direct geometric progression. We take the sequence of capacities at which resizes are completed to be $C_k = \\alpha^k$ for $k=0, 1, 2, \\ldots$. A resize from capacity $C_{k-1} = \\alpha^{k-1}$ to $C_k = \\alpha^k$ occurs when the array is full with $\\alpha^{k-1}$ elements and we need to append one more. The cost of this resize is the number of elements copied, which is $\\alpha^{k-1}$.\n\nLet's consider a sequence of $N$ append operations, where $N \\ge 1$. Let $m$ be the total number of resizing operations that have taken place. This means the current capacity of the array is $C_m = \\alpha^m$. The number of elements $N$ must be greater than the previous capacity $C_{m-1} = \\alpha^{m-1}$ but no more than the current capacity $C_m = \\alpha^m$. Thus, we have the condition $\\alpha^{m-1}  N \\le \\alpha^m$. Note that for $N=1$, we have $m=0$ (no resizes), $\\alpha^{-1}  1 \\le \\alpha^0=1$.\n\nThe total number of element movements, $M_{\\alpha}(N)$, is the sum of the costs of all $m$ resizes. The costs are the capacities before each resize: $C_0, C_1, \\ldots, C_{m-1}$.\n$$M_{\\alpha}(N) = \\sum_{k=0}^{m-1} C_k = \\sum_{k=0}^{m-1} \\alpha^k$$\nThis is a finite geometric series with first term $1$, ratio $\\alpha$, and $m$ terms. Its sum is:\n$$M_{\\alpha}(N) = \\frac{\\alpha^m - 1}{\\alpha-1}$$\nThe constant $c_{\\alpha}$ is defined as the smallest real constant such that $M_{\\alpha}(N) \\le c_{\\alpha} N$ for all $N \\ge 1$. This is equivalent to finding the supremum of the ratio $\\frac{M_{\\alpha}(N)}{N}$ over all integers $N \\ge 1$.\n$$c_{\\alpha} = \\sup_{N \\ge 1} \\frac{M_{\\alpha}(N)}{N}$$\nLet's analyze this ratio. For a given $N$, we find $m$ such that $\\alpha^{m-1}  N \\le \\alpha^m$. The ratio is:\n$$\\frac{M_{\\alpha}(N)}{N} = \\frac{1}{N} \\left(\\frac{\\alpha^m - 1}{\\alpha-1}\\right)$$\nWithin the range $\\alpha^{m-1}  N \\le \\alpha^m$, the numerator is constant, while the denominator $N$ varies. The ratio is therefore maximized when $N$ is as small as possible. The peaks of this function occur immediately after a resize, i.e., at the smallest integer values of $N$ for each $m$. These values are of the form $N = \\lfloor \\alpha^{m-1} \\rfloor + 1$.\n\nTo find the supremum, we can establish an upper bound on the ratio. We know $N  \\alpha^{m-1}$, which implies $\\frac{1}{N}  \\frac{1}{\\alpha^{m-1}}$.\n$$\\frac{M_{\\alpha}(N)}{N}  \\frac{1}{\\alpha^{m-1}} \\left(\\frac{\\alpha^m - 1}{\\alpha-1}\\right) = \\frac{\\alpha^m - 1}{\\alpha^{m-1}(\\alpha-1)} = \\frac{\\alpha - \\frac{1}{\\alpha^{m-1}}}{\\alpha-1}$$\nSince $\\alpha  1$, we have $\\frac{1}{\\alpha^{m-1}}  0$. Thus:\n$$\\frac{M_{\\alpha}(N)}{N}  \\frac{\\alpha}{\\alpha-1}$$\nThis shows that $\\frac{\\alpha}{\\alpha-1}$ is a strict upper bound for the ratio $\\frac{M_{\\alpha}(N)}{N}$. To show it is the least upper bound (the supremum), we must show that we can get arbitrarily close to this value. Let's consider the sequence of points $N_m = \\lfloor \\alpha^{m-1} \\rfloor + 1$ for $m \\ge 1$, which represent the state just after the $m$-th resize is complete.\nFor these points, the ratio is:\n$$\\frac{M_{\\alpha}(N_m)}{N_m} = \\frac{(\\alpha^m - 1)/(\\alpha-1)}{\\lfloor \\alpha^{m-1} \\rfloor + 1}$$\nWe take the limit as $m \\to \\infty$ (which corresponds to $N \\to \\infty$):\n$$\\lim_{m\\to\\infty} \\frac{M_{\\alpha}(N_m)}{N_m} = \\lim_{m\\to\\infty} \\frac{\\alpha^m - 1}{(\\alpha-1)(\\lfloor \\alpha^{m-1} \\rfloor + 1)}$$\nTo evaluate this limit, we divide the numerator and denominator by $\\alpha^{m-1}$:\n$$\\lim_{m\\to\\infty} \\frac{\\alpha - \\frac{1}{\\alpha^{m-1}}}{(\\alpha-1)\\left(\\frac{\\lfloor \\alpha^{m-1} \\rfloor}{\\alpha^{m-1}} + \\frac{1}{\\alpha^{m-1}}\\right)}$$\nAs $m \\to \\infty$, $\\frac{1}{\\alpha^{m-1}} \\to 0$. For the term $\\frac{\\lfloor \\alpha^{m-1} \\rfloor}{\\alpha^{m-1}}$, we use the property $x-1  \\lfloor x \\rfloor \\le x$. This gives $1 - \\frac{1}{\\alpha^{m-1}}  \\frac{\\lfloor \\alpha^{m-1} \\rfloor}{\\alpha^{m-1}} \\le 1$. By the Squeeze Theorem, $\\lim_{m\\to\\infty} \\frac{\\lfloor \\alpha^{m-1} \\rfloor}{\\alpha^{m-1}} = 1$.\nSubstituting these limits into the expression gives:\n$$\\frac{\\alpha - 0}{(\\alpha-1)(1+0)} = \\frac{\\alpha}{\\alpha-1}$$\nSince the ratio $\\frac{M_\\alpha(N)}{N}$ can be made arbitrarily close to $\\frac{\\alpha}{\\alpha-1}$, this value is the supremum.\nThus, the smallest constant $c_{\\alpha}$ is:\n$$c_{\\alpha} = \\frac{\\alpha}{\\alpha-1}$$\nNow, we must compute the ratio $c_{3/2}/c_{2}$.\nFirst, we calculate $c_{3/2}$ by setting $\\alpha = 3/2$:\n$$c_{3/2} = \\frac{\\frac{3}{2}}{\\frac{3}{2} - 1} = \\frac{\\frac{3}{2}}{\\frac{1}{2}} = 3$$\nNext, we calculate $c_2$ by setting $\\alpha = 2$:\n$$c_{2} = \\frac{2}{2 - 1} = \\frac{2}{1} = 2$$\nFinally, we compute the ratio:\n$$\\frac{c_{3/2}}{c_{2}} = \\frac{3}{2}$$", "answer": "$$\\boxed{\\frac{3}{2}}$$", "id": "3206964"}, {"introduction": "Now let's explore the same concept through a different lens: the accounting method. Instead of averaging the total cost, this approach assigns a fixed \"charge\" to each operation, saving any surplus as \"credit\" to pay for future expensive events. This practice [@problem_id:3206856] challenges you to determine the minimum growth factor $\\alpha$ required to ensure your credit balance never goes negative, offering a powerful mental model for designing efficient data structures.", "problem": "You are designing a dynamic array that grows geometrically by a factor $\\alpha  1$ whenever it is full. The cost model is as follows: writing one appended element into any available slot costs $1$, and when the array resizes, copying each existing element into the new array costs $1$ per element. Allocation and pointer updates are assumed to have constant cost independent of $n$ and are ignored.\n\nYou will use the accounting method from amortized analysis: assign to each append operation an amortized charge that may exceed its actual cost, storing any surplus as credits that can be used later to pay for movement costs incurred at resizes. Credits cannot be negative at any point.\n\nDevise an accounting scheme in which each append is charged exactly $3$ units: $1$ unit to pay for its own immediate write, and $2$ units deposited as credits usable only to pay for future moves during resizes (credits may be used to pay for moving any elements, not necessarily the element that generated them). Assume the array starts empty with initial capacity $1$, and consider an arbitrary finite sequence of appends with no deletions. Determine the smallest growth factor $\\alpha$ for which this accounting scheme can be sustained without ever running a credit deficit, for all such sequences.\n\nYour final answer must be a single exact value for $\\alpha$ with no rounding.", "solution": "The user wants me to find the smallest growth factor $\\alpha$ for a dynamic array such that a specific accounting scheme for amortized analysis can be sustained indefinitely.\n\n### Step 1: Formalize the Problem\nLet $n$ be the number of elements in the dynamic array. The array has a capacity $C$. When an element is appended, if $n  C$, the element is added to an empty slot. If $n = C$, the array is full, and a resize operation must occur before appending the new element.\n\nThe initial state is an empty array ($n=0$) with capacity $C_0=1$.\nWhen a resize is triggered, a new array with capacity $C_{new} = \\alpha C_{old}$ is allocated, and the $n=C_{old}$ existing elements are copied to the new array. We can model the sequence of capacities after each resize as $C_k = \\alpha^k$ for $k=0, 1, 2, \\ldots$. A resize from capacity $C_{k-1} = \\alpha^{k-1}$ to $C_k = \\alpha^k$ is triggered when we attempt to add the $(\\alpha^{k-1}+1)$-th element.\n\nThe cost model is:\n-   Actual cost of writing one element: $1$ unit.\n-   Actual cost of copying one element during a resize: $1$ unit.\n\nThe accounting scheme is:\n-   Amortized charge for each append operation: $3$ units.\n-   For each append, $1$ unit pays for the immediate write.\n-   For each append, $2$ units are deposited as credits into a bank.\n-   The cost of copying elements during a resize must be paid by withdrawing from this credit bank.\n-   The critical constraint is that the credit balance must never be negative.\n\nWe must find the minimum $\\alpha  1$ for which this holds for any number of appends.\n\n### Step 2: Analyze the Credit Balance\nLet $B_i$ be the credit balance after the $i$-th append operation. Let $c_{actual, i}$ be the actual cost of the $i$-th append. According to the stated accounting scheme, for each operation $i$, we deposit $2$ credits and then pay any resize costs. This can be viewed through the lens of potential functions where the amortized cost $c'_{i}$ relates to the actual cost $c_i$ and the change in potential (credits) $\\Delta B_i = B_i - B_{i-1}$. The scheme can be stated as: $c'_{i} = 3$ for all $i$. The balance update is $B_i = B_{i-1} + 3 - c_{actual, i}$. The constraint is $B_i \\ge 0$ for all $i$.\n\nThe actual cost $c_{actual, i}$ is:\n-   $c_{actual, i} = 1$ if the append does not trigger a resize.\n-   $c_{actual, i} = 1 + M$ if the append triggers a resize, where $M$ is the number of elements to copy.\n\nThe credit balance is most stressed just after paying for a large resize. These are the critical points to analyze. Let's analyze the state of the system just before the $k$-th resize is paid for. This happens when we append the $i$-th element, where $i = \\alpha^{k-1} + 1$.\n\nAt this point, there are $n = i-1 = \\alpha^{k-1}$ elements in the array, and the capacity is $C = \\alpha^{k-1}$. The array is full.\nThe number of append operations performed so far is $n = \\alpha^{k-1}$.\nFor each of these $n$ appends, $2$ units of credit were deposited.\nSo, the total credits deposited amount to $2n = 2\\alpha^{k-1}$.\n\nHowever, some of these credits have already been spent on previous resizes. The resizes occurred for appends $j = \\alpha^0+1, \\alpha^1+1, \\dots, \\alpha^{k-2}+1$.\nThe cost of the resize triggered by append $j=\\alpha^m+1$ is the number of elements at that time, which is $\\alpha^m$.\nSo, the total cost of all resizes that have occurred *before* the current one is the sum of costs for $m=0, 1, \\dots, k-2$.\n$$ \\text{Cost}_{\\text{resizes}, \\text{past}} = \\sum_{m=0}^{k-2} \\alpha^m $$\nThis is a geometric series with sum:\n$$ \\sum_{m=0}^{k-2} \\alpha^m = \\frac{\\alpha^{k-1}-1}{\\alpha-1} $$\n\nThe credit balance $B$ available just before the $k$-th resize is the total deposits minus total past expenditures:\n$$ B = 2\\alpha^{k-1} - \\frac{\\alpha^{k-1}-1}{\\alpha-1} $$\n\nNow, the $k$-th resize must be paid for. The cost is the number of elements to copy, which is $n=\\alpha^{k-1}$. This cost must be paid from the available balance $B$. The constraint that the balance never becomes negative means that the balance must be at least the cost of the upcoming resize.\n$$ B \\ge \\alpha^{k-1} $$\nSubstituting the expression for $B$:\n$$ 2\\alpha^{k-1} - \\frac{\\alpha^{k-1}-1}{\\alpha-1} \\ge \\alpha^{k-1} $$\n\n### Step 3: Solve the Inequality for $\\alpha$\nWe simplify the inequality:\n$$ \\alpha^{k-1} \\ge \\frac{\\alpha^{k-1}-1}{\\alpha-1} $$\nSince $\\alpha  1$, the denominator $(\\alpha-1)$ is positive, so we can multiply both sides by it without changing the inequality direction:\n$$ \\alpha^{k-1}(\\alpha-1) \\ge \\alpha^{k-1}-1 $$\n$$ \\alpha^k - \\alpha^{k-1} \\ge \\alpha^{k-1}-1 $$\n$$ \\alpha^k - 2\\alpha^{k-1} + 1 \\ge 0 $$\nThis inequality must hold for all resize events, i.e., for all integers $k \\ge 1$ (the first resize corresponds to $k=1$, for capacity $C_0=\\alpha^0=1$).\n\nLet's analyze the inequality $\\alpha^k - 2\\alpha^{k-1} + 1 \\ge 0$. We can factor out $\\alpha^{k-1}$:\n$$ \\alpha^{k-1}(\\alpha - 2) + 1 \\ge 0 $$\nLet $g(k) = \\alpha^{k-1}(\\alpha - 2) + 1$. We need $g(k) \\ge 0$ for all $k \\ge 1$.\n\nCase 1: $\\alpha = 2$.\nThe inequality becomes $2^{k-1}(2 - 2) + 1 \\ge 0$, which simplifies to $1 \\ge 0$. This is true for all $k$. Thus, $\\alpha=2$ is a possible solution.\n\nCase 2: $\\alpha  2$.\nIn this case, $(\\alpha-2)  0$. Since $\\alpha  1$, $\\alpha^{k-1}$ is always positive. Therefore, $\\alpha^{k-1}(\\alpha - 2)  0$, and $g(k) = \\alpha^{k-1}(\\alpha - 2) + 1  1$. The condition is always satisfied.\n\nCase 3: $1  \\alpha  2$.\nIn this case, $(\\alpha-2)$ is negative. The term $\\alpha^{k-1}$ is positive and grows with $k$. Thus, the term $\\alpha^{k-1}(\\alpha - 2)$ is negative and its magnitude increases as $k$ increases.\nAs $k \\to \\infty$, $\\alpha^{k-1} \\to \\infty$, so $\\alpha^{k-1}(\\alpha - 2) \\to -\\infty$.\nThis means that for any $\\alpha$ in the range $(1, 2)$, we can find a sufficiently large $k$ such that $g(k) = \\alpha^{k-1}(\\alpha - 2) + 1  0$. This would correspond to a credit deficit after a large number of appends. Therefore, any $\\alpha  2$ cannot sustain the accounting scheme for all possible sequences of appends.\n\nCombining these cases, the condition $\\alpha^{k-1}(\\alpha - 2) + 1 \\ge 0$ holds for all $k \\ge 1$ if and only if $\\alpha \\ge 2$.\nThe problem asks for the smallest such growth factor $\\alpha$. This is the minimum value of the valid range, which is $\\alpha=2$.\n\n### Conclusion\nThe smallest growth factor $\\alpha$ for which the given accounting scheme is sustainable without ever running a credit deficit is $2$.", "answer": "$$\\boxed{2}$$", "id": "3206856"}, {"introduction": "Amortized efficiency is a result of careful design, not a universal guarantee. This final practice explores a common pitfall known as \"thrashing,\" where a poorly designed dynamic array that can both grow and shrink experiences catastrophic performance degradation. By analyzing a specific sequence of insertions and deletions [@problem_id:3206966], you will see how an amortized cost can escalate from a constant to linear time, highlighting the critical importance of choosing growth and shrink policies that prevent oscillatory resizing.", "problem": "A dynamic array stores elements in a contiguous block of memory with a current size $s$ and a capacity $C$. When $s = C$, the array grows by allocating a new block of capacity $\\alpha C$ and copying all $s$ elements; when $s \\leq \\beta C$, the array shrinks by allocating a new block of capacity $\\beta C$ and copying all $s$ elements. Assume the following cost model: copying one element has cost $1$, each insertion or deletion that does not trigger a resize has cost $1$, and the cost of allocation is negligible. The amortized cost of a sequence is defined using the aggregate-cost method: the amortized cost per operation is the total cost divided by the number of operations.\n\nConsider the case where the growth factor and shrink factor are nearly inverses so that the array is prone to oscillatory resizing. Let $k$ be a fixed positive integer, and set the growth factor to $\\alpha = \\frac{k+1}{k}$ and the shrink factor to $\\beta = \\frac{k}{k+1}$ so that $\\alpha \\beta = 1$. Assume the initial capacity is $C_{0} = n$ with $n$ divisible by $k$, and the array is full initially, i.e., $s = n$. Now perform the following two-operation cycle repeatedly:\n1. Insert one element.\n2. Delete one element.\n\nUnder the resize policy $s = C \\Rightarrow$ grow to capacity $\\alpha C$ and $s \\leq \\beta C \\Rightarrow$ shrink to capacity $\\beta C$, and using the stated cost model, this alternating sequence induces resizing on each operation when $\\alpha \\beta = 1$, producing a \"thrashing\" behavior.\n\nDerive from first principles the exact amortized cost per operation (total cost divided by the total number of operations) for the above alternating sequence, expressed as a closed-form analytic expression in terms of $n$. No rounding is required. Provide your final answer as a single expression.", "solution": "The problem asks for the amortized cost per operation for a specific sequence of operations on a dynamic array, using the aggregate-cost method. The analysis requires a step-by-step derivation from first principles, tracking the array's state (size $s$ and capacity $C$) and the costs incurred.\n\nThe given parameters are:\n- Growth factor: $\\alpha = \\frac{k+1}{k}$ for a positive integer $k$.\n- Shrink factor: $\\beta = \\frac{k}{k+1}$, which implies $\\alpha \\beta = 1$.\n- Growth condition: Resize is triggered before an insertion if the array is full, i.e., $s=C$.\n- Shrink condition: Resize is triggered after a deletion if the array is underutilized, i.e., $s \\leq \\beta C$.\n- Cost model: The cost of an insertion or deletion operation is $1$ plus the cost of any resizing it triggers. The cost of resizing is equal to the number of elements copied.\n\nThe initial state of the array is given as:\n- Initial capacity: $C_0 = n$.\n- Initial size: $s_0 = n$ (the array is full).\n- It is also given that $n$ is divisible by $k$.\n\nThe sequence of operations is a repeated cycle of one insertion followed by one deletion. We will analyze the cost and state changes for one full cycle.\n\n**Step 1: Analyze the first operation (Insertion)**\n\nThe system starts in the state $(s_0, C_0) = (n, n)$.\nAn insertion operation is performed.\nFirst, we check the condition for resizing. Since $s_0 = n$ and $C_0 = n$, the condition $s=C$ is met. This triggers a growth operation before the new element is inserted.\nA new, larger array is allocated. The new capacity, $C_1$, is calculated as:\n$$C_1 = \\alpha C_0 = \\left(\\frac{k+1}{k}\\right) n$$\nThe cost of this growth operation is the number of elements that must be copied from the old array to the new one. At this point, the size is $s_0 = n$.\n$$ \\text{Cost}_{\\text{copy, grow}} = s_0 = n $$\nAfter the resize, the insertion itself is performed. This has a base cost of $1$.\nThe total cost of the first operation (the resizing insertion) is the sum of the copying cost and the base insertion cost:\n$$ \\text{Cost}_1 = \\text{Cost}_{\\text{copy, grow}} + \\text{Cost}_{\\text{base insert}} = n + 1 $$\nAfter this operation, the size of the array increases by one. The new state of the array is:\n- New size: $s_1 = s_0 + 1 = n + 1$.\n- New capacity: $C_1 = \\left(\\frac{k+1}{k}\\right) n$.\n\n**Step 2: Analyze the second operation (Deletion)**\n\nThe system is now in the state $(s_1, C_1) = \\left(n+1, \\left(\\frac{k+1}{k}\\right)n\\right)$.\nA deletion operation is performed. This reduces the number of elements by one.\nThe size of the array becomes $s' = s_1 - 1 = (n+1) - 1 = n$.\nAfter the element is removed, we check the condition for shrinking. The condition is $s' \\leq \\beta C_1$.\nLet's evaluate the shrink threshold $\\beta C_1$:\n$$ \\beta C_1 = \\left(\\frac{k}{k+1}\\right) \\times C_1 = \\left(\\frac{k}{k+1}\\right) \\left(\\frac{k+1}{k}\\right) n = 1 \\cdot n = n $$\nThe condition to check is therefore $s' \\leq n$. Since $s' = n$, the condition $n \\leq n$ is met. This triggers a shrink operation.\nA new, smaller array is allocated. The new capacity, $C_2$, is:\n$$ C_2 = \\beta C_1 = n $$\nThe cost of this shrink operation is the number of elements to be copied, which is the current size $s' = n$.\n$$ \\text{Cost}_{\\text{copy, shrink}} = s' = n $$\nThe base cost of the deletion operation is $1$.\nThe total cost of the second operation (the resizing deletion) is the sum of the copying cost and the base deletion cost:\n$$ \\text{Cost}_2 = \\text{Cost}_{\\text{copy, shrink}} + \\text{Cost}_{\\text{base delete}} = n + 1 $$\nAfter this operation, the state of the array is:\n- New size: $s_2 = s' = n$.\n- New capacity: $C_2 = n$.\n\n**Step 3: Calculate the Amortized Cost**\n\nAfter two operations (one insertion, one deletion), the state of the array is $(s_2, C_2) = (n, n)$. This is identical to the initial state $(s_0, C_0)$.\nThe sequence of operations and costs will repeat indefinitely. We can therefore calculate the amortized cost by analyzing a single two-operation cycle.\nThe total number of operations in one cycle is $2$.\nThe total cost for one cycle is the sum of the costs of the two operations:\n$$ \\text{Total Cost}_{\\text{cycle}} = \\text{Cost}_1 + \\text{Cost}_2 = (n+1) + (n+1) = 2n + 2 $$\nThe amortized cost per operation is defined by the aggregate-cost method as the total cost divided by the total number of operations.\n$$ \\text{Amortized Cost} = \\frac{\\text{Total Cost}_{\\text{cycle}}}{\\text{Number of Operations}_{\\text{cycle}}} = \\frac{2n + 2}{2} = n + 1 $$\nThis is the exact amortized cost per operation for the given sequence, which demonstrates thrashing behavior where every operation triggers an expensive resize, leading to a linear amortized cost with respect to the array size $n$. The condition that $n$ is divisible by $k$ ensures that the intermediate capacity $C_1$ is an integer, making the problem well-defined.", "answer": "$$\\boxed{n+1}$$", "id": "3206966"}]}