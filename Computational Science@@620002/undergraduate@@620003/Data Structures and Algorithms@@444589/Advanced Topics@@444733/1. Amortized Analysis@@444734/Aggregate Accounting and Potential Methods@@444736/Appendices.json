{"hands_on_practices": [{"introduction": "The cost of incrementing a binary number can vary wildly, as sometimes only one bit flips, while other times a long cascade of bits changes. This makes the binary counter a perfect case study for amortized analysis. This exercise [@problem_id:3204641] demonstrates the power of the potential method to cut through this complexity, revealing a small constant amortized cost and leading to an elegant, exact formula for the total cost of a sequence of operations.", "problem": "A binary counter stores nonnegative integers in base $2$, with the least significant bit at position $0$. For each increment from state $i$ to state $i+1$, define the actual cost of the operation to be the number of bit positions that change value between the binary representations of $i$ and $i+1$. This cost is the Hamming distance between $i$ and $i+1$, where the Hamming distance is the number of coordinates at which two equal-length strings differ.\n\nStarting from the counter state $0$, perform exactly $m$ consecutive increments, for a fixed positive integer $m$. Let $\\mathcal{C}(m)$ be the total actual cost accumulated over these $m$ increments. Derive, from first principles and using any of the aggregate, accounting, or potential methods, an exact closed-form expression for $\\mathcal{C}(m)$ in terms of $m$ only, with no summations. You may use a function symbol $s_{2}(m)$ to denote the number of ones in the base-$2$ representation of $m$.\n\nYour final answer must be a single closed-form analytical expression for $\\mathcal{C}(m)$, with no inequalities or equations included in the answer. No rounding is required.", "solution": "The problem is valid as it is a standard, well-posed problem in the analysis of algorithms. It is scientifically grounded in mathematics and computer science, formally stated, and objective. We will proceed to derive the closed-form expression for the total cost $\\mathcal{C}(m)$ using the potential method of amortized analysis.\n\nLet the state of the binary counter after $i$ increments be represented by the integer $i$. The initial state is $0$. We perform a sequence of $m$ increments, leading the counter through states $0, 1, 2, \\dots, m$.\n\nLet $c_k$ be the actual cost of the $k$-th increment operation, which transitions the counter from state $k-1$ to state $k$. The problem defines this cost as the number of bits that flip during this transition. The total actual cost over $m$ increments is $\\mathcal{C}(m) = \\sum_{k=1}^{m} c_k$.\n\nTo apply the potential method, we define a potential function $\\Phi$ that maps the state of the data structure to a real number. A suitable choice for the potential of the counter in state $i$, let's call it $\\Phi(i)$, is the number of ones in the binary representation of $i$. We use the notation from the problem, $s_2(i)$, for this quantity.\n$$\n\\Phi(i) = s_2(i)\n$$\nFor the potential method to be valid, we must have $\\Phi(i) \\ge \\Phi(0)$ for all states $i$. The initial state is $0$, and $\\Phi(0) = s_2(0) = 0$. Since the number of ones in any non-negative integer's binary representation is non-negative, $s_2(i) \\ge 0$ for all $i \\ge 0$. Thus, the condition $\\Phi(i) \\ge \\Phi(0)$ is satisfied.\n\nThe amortized cost, $a_k$, of the $k$-th operation is defined as the actual cost plus the change in potential:\n$$\na_k = c_k + \\Phi(k) - \\Phi(k-1)\n$$\nLet's analyze the change in the counter for the $k$-th increment (from state $k-1$ to $k$). Suppose the binary representation of $k-1$ has $j$ trailing ones. That is, its binary form is $\\dots p_j 0 1 \\dots 1$, where there is a contiguous block of $j$ ones at the end, preceded by a zero.\nThe increment operation flips these $j$ ones to zeros and flips the rightmost zero (at position $j$) to a one. All bits to the left of position $j$ remain unchanged.\nThe number of bit flips in this operation is $j$ (for the $1 \\to 0$ flips) plus $1$ (for the $0 \\to 1$ flip). Therefore, the actual cost is:\n$$\nc_k = j+1\n$$\nThis also covers the case where $k-1$ is even, meaning its binary representation ends in $0$. In this case, $j=0$, and only the last bit flips from $0$ to $1$, so $c_k=1$, which matches the formula.\n\nNow, we evaluate the change in potential, $\\Phi(k) - \\Phi(k-1) = s_2(k) - s_2(k-1)$.\nThe number of ones in state $k-1$ can be expressed in terms of the number of ones in the bits higher than position $j$, let's call this $N$, and the $j$ trailing ones. So, $s_2(k-1) = N+j$.\nIn state $k$, the $j$ trailing ones have become zeros, and the zero at position $j$ has become a one. The higher-order bits are unchanged. Thus, the number of ones in state $k$ is $s_2(k) = N+1$.\nThe change in the number of ones is:\n$$\ns_2(k) - s_2(k-1) = (N+1) - (N+j) = 1-j\n$$\nThis gives us the change in potential: $\\Delta\\Phi_k = \\Phi(k) - \\Phi(k-1) = 1-j$.\n\nNow we can calculate the amortized cost $a_k$:\n$$\na_k = c_k + \\Delta\\Phi_k = (j+1) + (1-j) = 2\n$$\nThe amortized cost for each increment operation is a constant, $2$.\n\nThe total actual cost $\\mathcal{C}(m)$ is related to the total amortized cost by the fundamental theorem of amortized analysis:\n$$\n\\sum_{k=1}^{m} c_k = \\sum_{k=1}^{m} a_k - (\\Phi(m) - \\Phi(0))\n$$\nSubstituting the known quantities:\n$$\n\\mathcal{C}(m) = \\sum_{k=1}^{m} 2 - (s_2(m) - s_2(0))\n$$\nThe sum of the constant amortized costs is $\\sum_{k=1}^{m} 2 = 2m$. The potential of the initial state is $\\Phi(0) = s_2(0) = 0$. The potential of the final state is $\\Phi(m) = s_2(m)$.\nSubstituting these values, we obtain the expression for the total actual cost:\n$$\n\\mathcal{C}(m) = 2m - (s_2(m) - 0)\n$$\n$$\n\\mathcal{C}(m) = 2m - s_2(m)\n$$\nThis is the exact, closed-form expression for the total number of bit flips that occur during $m$ consecutive increments of a binary counter starting from $0$. The expression consists of the term $2m$ and a correction term which is the number of ones in the final state $m$.", "answer": "$$\\boxed{2m - s_{2}(m)}$$", "id": "3204641"}, {"introduction": "The aggregate, accounting, and potential methods offer different conceptual frameworks for amortized analysis. This practice [@problem_id:3204638] analyzes a simple abstract data structure to demonstrate how all three methods can be used to arrive at the same tight bound on amortized cost. By working through each perspective, you will gain a deeper, more unified understanding of how to distribute and account for operational costs over time.", "problem": "A data structure supports two operations on an initially empty instance: an insertion operation $\\text{INSERT}(x)$ and an audit operation $\\text{AUDIT}()$. The actual (unamortized) cost of $\\text{INSERT}(x)$ is $1$. The actual (unamortized) cost of $\\text{AUDIT}()$ is $k$, where $k$ equals the number of items that have been inserted since the most recent $\\text{AUDIT}()$ (or since the beginning if no $\\text{AUDIT}()$ has yet occurred). Consider any finite sequence of operations of total length $n$.\n\nUsing only the foundational definitions of amortized analysis—specifically, the aggregate method (total cost over a sequence divided by the number of operations), the accounting method (assigning fixed amortized charges and maintaining nonnegative credits), and the potential method (with a carefully justified potential function)—derive from first principles a tight uniform constant upper bound on the amortized cost per operation that holds for every finite operation sequence. Your derivation must justify why the bound is valid for all sequences and why it is tight in the sense of being the smallest constant $c$ such that the total cost of any length-$n$ sequence is at most $c n$ for all $n$.\n\nReport your final answer as the single exact constant $c$ (a real number). No rounding is required.", "solution": "We begin from the definitions of amortized analysis. Let $n$ denote the total number of operations in an arbitrary finite sequence. Let $I$ be the number of $\\text{INSERT}(x)$ operations and $A$ be the number of $\\text{AUDIT}()$ operations, so $n = I + A$. The actual cost model is: each $\\text{INSERT}(x)$ has cost $1$, and each $\\text{AUDIT}()$ has cost equal to the number of insertions performed since the most recent $\\text{AUDIT}()$ (or since the beginning if none has occurred).\n\nAggregate method. Let $T$ denote the total actual cost of the sequence. The total cost contributed by all $\\text{INSERT}(x)$ operations is $I$, since each costs $1$. For the $\\text{AUDIT}()$ costs, observe that the $j$-th $\\text{AUDIT}()$ pays $k_j$, where $k_j$ counts exactly the number of insertions since the previous $\\text{AUDIT}()$. Across all $\\text{AUDIT}()$ operations, every insertion is counted in at most one $k_j$—specifically, in the first $\\text{AUDIT}()$ that follows it—because the counter resets after each $\\text{AUDIT}()$. Therefore,\n$$\n\\sum_{j=1}^{A} k_j \\le I.\n$$\nHence the total cost satisfies\n$$\nT \\;=\\; \\underbrace{I}_{\\text{inserts}} \\;+\\; \\underbrace{\\sum_{j=1}^{A} k_j}_{\\text{audits}} \\;\\le\\; I + I \\;=\\; 2I \\;\\le\\; 2n.\n$$\nDividing by $n$ yields an amortized cost per operation at most $2$ for every finite sequence. This proves that a uniform constant $c = 2$ is a valid bound.\n\nTightness via aggregate method. Consider the sequence consisting of $I$ insertions followed by a single audit, so $n = I + 1$. The total cost is $T = I$ (for insertions) $+\\, I$ (for the single audit) $= 2I$. The average cost is\n$$\n\\frac{T}{n} \\;=\\; \\frac{2I}{I+1},\n$$\nwhich approaches $2$ from below as $I \\to \\infty$. Thus no constant $c < 2$ can upper bound $T/n$ uniformly over all finite sequences. Therefore the aggregate method yields the tight constant $c = 2$.\n\nAccounting method. Assign an amortized charge of $2$ to each $\\text{INSERT}(x)$ and $0$ to each $\\text{AUDIT}()$. For each $\\text{INSERT}(x)$, pay its actual cost $1$ and store a credit of $1$ on the inserted item. At an $\\text{AUDIT}()$, suppose $k$ items have been inserted since the last audit. The actual cost is $k$, and there are exactly $k$ items carrying $1$ unit of credit each, for a total of $k$ credits. Use these credits to pay the entire audit cost. Credits never go negative, and every operation’s amortized charge is at most $2$. Therefore the accounting method also shows an amortized cost per operation of $2$, matching the aggregate bound and hence tight by the same example as above.\n\nPotential method. Define the potential function $\\Phi$ to be the number of items inserted since the last $\\text{AUDIT}()$. Initially, $\\Phi_0 = 0$. This potential is always nonnegative.\n\n- For $\\text{INSERT}(x)$: the actual cost is $1$, and $\\Phi$ increases by $1$, so $\\Delta \\Phi = +1$. The amortized cost is\n$$\n\\hat{c} \\;=\\; \\text{actual} + \\Delta \\Phi \\;=\\; 1 + 1 \\;=\\; 2.\n$$\n\n- For $\\text{AUDIT}()$: the actual cost is $k$, where $k$ equals the current $\\Phi$, and the potential drops to $0$, so $\\Delta \\Phi = -k$. The amortized cost is\n$$\n\\hat{c} \\;=\\; \\text{actual} + \\Delta \\Phi \\;=\\; k + (-k) \\;=\\; 0.\n$$\n\nThus every operation has amortized cost at most $2$, and the total amortized cost over any sequence is at most $2n$. Since $\\Phi$ is nonnegative and starts at $0$, the total amortized cost upper bounds the total actual cost. Therefore the potential method establishes the same uniform constant $2$. By the earlier tightness example, $2$ is the smallest such constant.\n\nConclusion. All three methods agree on the tight uniform constant amortized cost per operation, which is $2$.", "answer": "$$\\boxed{2}$$", "id": "3204638"}, {"introduction": "A true mastery of amortized analysis involves adapting techniques to new problems, not just memorizing standard examples. This advanced exercise [@problem_id:3204622] challenges you by modifying the familiar binary counter with a non-standard cost model where flipping higher-order bits is more expensive. To solve this, you must move beyond known formulas and derive a new potential function from first principles, thereby honing your problem-solving skills.", "problem": "You are given an unbounded binary counter whose bits are indexed by nonnegative integers, with bit $i$ having weight $2^{i}$ and bit $0$ being the Least Significant Bit (LSB). The counter starts at the all-zero state. An increment operation adds $1$ to the counter in binary, flipping the trailing block of consecutive $1$-bits (if any) to $0$ and then flipping the next higher $0$-bit to $1$. The actual cost model is as follows: flipping bit $i$ incurs cost $i+1$. Thus, the actual cost of an increment is the sum of $i+1$ over all bits $i$ flipped by that increment. Consider an arbitrary sequence of $m$ increments from the all-zero state, assuming no overflow (the counter has sufficiently many bits so that all $m$ increments are feasible).\n\nStarting only from the formal semantics of binary increment and the above cost model, do the following.\n- Using the aggregate method, derive a closed-form upper bound on the total cost $C(m)$ of $m$ increments by counting, for each bit $i$, how many times it flips in the first $m$ increments, and summing these contributions. Your derivation must begin from first principles and may use only basic series facts.\n- Using the accounting method, propose a fixed per-increment amortized charge $c$ and a credit invariant that assigns a nonnegative number of stored credits to each bit $i$ as a function of $i$ and whether the bit is currently $1$ or $0$, such that for every increment the credits released from bits that flip to $0$ together with the charged $c$ cover the actual cost of that increment and reestablish the invariant. Prove that this scheme works for all $m$ starting from the zero state, and determine the smallest constant $c$ that makes this possible.\n- Using the potential method, define a potential function $\\Phi$ depending only on the current bit pattern, and prove that the amortized cost of each increment, defined as the actual cost plus the change in potential, is exactly the same constant $c$ that you found via accounting, for every increment regardless of $m$.\n- Finally, use your aggregate analysis to evaluate $\\lim_{m \\to \\infty} \\frac{C(m)}{m}$ and argue that your constant $c$ is tight.\n\nReport the minimal constant $c$ as your final answer. No rounding is required, and no units are involved. The final answer must be a single real number.", "solution": "The problem requires an amortized analysis of a binary counter increment operation under a non-standard cost model. We are asked to use the aggregate, accounting, and potential methods to find and justify the tightest constant amortized cost for a sequence of $m$ increments.\n\nFirst, let's establish the cost model and operation dynamics. A binary counter starts at $0$. An increment operation adds $1$. This causes a block of trailing $1$s to flip to $0$s and the next $0$ to flip to a $1$. The cost of flipping bit $i$ is defined as $i+1$. The actual cost of an increment is the sum of costs of all bits flipped.\n\n**1. Aggregate Method**\n\nThe aggregate method calculates the total actual cost, $C(m)$, of a sequence of $m$ operations and then determines the average cost per operation, which is $C(m)/m$.\n\nTo find $C(m)$, we sum the costs of all bit flips over the course of $m$ increments. Instead of summing costs per increment, we can sum costs per bit. The total cost is $C(m) = \\sum_{i=0}^{\\infty} (\\text{cost to flip bit } i) \\times (\\text{number of times bit } i \\text{ flips in } m \\text{ increments})$.\n\nThe cost to flip bit $i$ is given as $i+1$.\nBit $i$ flips when the counter transitions from a value $v$ to $v+1$ where the binary representations of $v$ and $v+1$ differ at bit $i$. This occurs precisely when adding $1$ causes a carry that propagates up to bit $i$. Bit $i$ flips from $0$ to $1$ or $1$ to $0$ if and only if bits $0, 1, \\dots, i-1$ are all $1$s before the increment. This happens at counter values of the form $k \\cdot 2^i + (2^i - 1)$ for any integer $k \\ge 0$. The increment moves the value to $(k+1) \\cdot 2^i$. Therefore, bit $i$ flips on the $j$-th increment if $j$ is a multiple of $2^i$.\n\nIn a sequence of $m$ increments (from value $0$ to $m-1$, resulting in counter value $m$), bit $i$ flips on increments $1 \\cdot 2^i, 2 \\cdot 2^i, 3 \\cdot 2^i, \\dots, \\lfloor m/2^i \\rfloor \\cdot 2^i$. The number of times bit $i$ flips is exactly $\\lfloor m/2^i \\rfloor$.\n\nThe total cost $C(m)$ is the sum over all bits $i$:\n$$C(m) = \\sum_{i=0}^{\\infty} (i+1) \\left\\lfloor \\frac{m}{2^i} \\right\\rfloor$$\nThis sum is finite because for $2^i > m$, the term $\\lfloor m/2^i \\rfloor$ becomes $0$.\n\nTo find a closed-form upper bound, we use the inequality $\\lfloor x \\rfloor \\le x$:\n$$C(m) \\le \\sum_{i=0}^{\\infty} (i+1) \\frac{m}{2^i} = m \\sum_{i=0}^{\\infty} \\frac{i+1}{2^i}$$\nThe sum is an arithmetic-geometric series. Let $S = \\sum_{k=0}^{\\infty} (k+1)x^k$. This series is the derivative of a related geometric series. We know that for $|x|<1$, $\\sum_{k=0}^{\\infty} x^k = \\frac{1}{1-x}$. Differentiating with respect to $x$ gives $\\sum_{k=1}^{\\infty} kx^{k-1} = \\frac{1}{(1-x)^2}$. Letting $i=k-1$, this is $\\sum_{i=0}^{\\infty} (i+1)x^i = \\frac{1}{(1-x)^2}$.\nFor our sum, $x=1/2$, so:\n$$S = \\sum_{i=0}^{\\infty} \\frac{i+1}{2^i} = \\frac{1}{(1-1/2)^2} = \\frac{1}{(1/4)} = 4$$\nThus, the total cost is bounded above:\n$$C(m) \\le 4m$$\nThis suggests an amortized cost of $4$ per operation.\n\n**2. Accounting Method**\n\nIn the accounting method, we charge a fixed amortized cost $c$ for each operation. Part of this charge pays for the immediate actual cost, and the rest is stored as \"credit\" on the data structure. This credit can be used later to pay for expensive operations. The total credit must never be negative.\n\nLet's propose an amortized charge of $c=4$, based on our aggregate analysis. We need to define a credit invariant. A common strategy is to store credit on bits that are set to $1$. Let's define the credit invariant:\n*If bit $i$ is $1$, it stores $\\phi_i$ credits.*\n*If bit $i$ is $0$, it stores $0$ credits.*\n\nWe need to determine the function $\\phi_i$. The initial state is all zeros, so the total credit is $0$.\nConsider an increment operation that flips bits $0, 1, \\dots, k-1$ from $1$ to $0$, and bit $k$ from $0$ to $1$.\nThe actual cost of this operation is $A_k = (\\sum_{i=0}^{k-1} (i+1)) + (k+1) = \\frac{k(k+1)}{2} + (k+1) = \\frac{(k+1)(k+2)}{2}$.\nTo pay for this operation, we use the charged amount $c$ and any credits released by bits flipping from $1$ to $0$.\nCredits released: $\\sum_{i=0}^{k-1} \\phi_i$.\nAfter the operation, we must re-establish the invariant by storing credit on bit $k$, which is now $1$.\nCredits to be stored: $\\phi_k$.\n\nThe fundamental inequality of the accounting method is:\nAmortized Charge + Credits Released $\\ge$ Actual Cost + Credits Stored\n$$c + \\sum_{i=0}^{k-1} \\phi_i \\ge \\frac{(k+1)(k+2)}{2} + \\phi_k$$\nWe need to find a non-negative function $\\phi_i$ that satisfies this for $c=4$ and for all $k \\ge 0$. Let's try to find $\\phi_i$ by setting this to an equality. Let's try the credit invariant: a bit $i$ set to $1$ stores $\\phi_i = i+3$ credits.\nLet's verify this for $c=4$.\n$$4 + \\sum_{i=0}^{k-1} (i+3) \\ge \\frac{(k+1)(k+2)}{2} + (k+3)$$\n$$4 + \\left(\\frac{(k-1)k}{2} + 3k\\right) \\ge \\frac{k^2+3k+2}{2} + k+3$$\n$$4 + \\frac{k^2-k+6k}{2} \\ge \\frac{k^2+3k+2+2k+6}{2}$$\n$$\\frac{8+k^2+5k}{2} \\ge \\frac{k^2+5k+8}{2}$$\nThis is an equality, so it holds. For any increment, a charge of $c=4$ is exactly sufficient to pay the actual cost and maintain the credit invariant where each 1-bit at position $i$ stores $i+3$ credits. The minimal constant charge is therefore $c=4$.\n\n**3. Potential Method**\n\nThe potential method defines a potential function $\\Phi$ that maps the state of the data structure to a non-negative real number, with $\\Phi=0$ for the initial state. The amortized cost $c_a$ of an operation is its actual cost $c_{act}$ plus the change in potential, $c_a = c_{act} + \\Delta\\Phi$.\n\nWe use the credit function from the accounting method to define our potential function. Let the state of the counter be defined by the set $S$ of indices of bits that are $1$.\n$$\\Phi(S) = \\sum_{i \\in S} (i+3)$$\nThe initial state is all zeros, so $S=\\emptyset$ and $\\Phi(\\emptyset)=0$. Since $i \\ge 0$, $\\Phi(S) \\ge 0$ for all states.\n\nConsider an increment that flips bits $0, 1, \\dots, k-1$ from $1$ to $0$ and bit $k$ from $0$ to $1$.\nThe state before is $S_{old} = \\{0, 1, \\dots, k-1\\} \\cup S'$, where $S'$ represents the bits greater than $k$ that are $1$.\nThe state after is $S_{new} = \\{k\\} \\cup S'$.\nThe actual cost is $c_{act} = \\sum_{i=0}^{k-1} (i+1) + (k+1) = \\frac{(k+1)(k+2)}{2}$.\nThe change in potential is $\\Delta\\Phi = \\Phi(S_{new}) - \\Phi(S_{old})$.\n$\\Phi(S_{new}) = (k+3) + \\sum_{i \\in S'} (i+3)$.\n$\\Phi(S_{old}) = \\sum_{i=0}^{k-1} (i+3) + \\sum_{i \\in S'} (i+3)$.\n$\\Delta\\Phi = (k+3) - \\sum_{i=0}^{k-1} (i+3) = (k+3) - \\left(\\frac{(k-1)k}{2} + 3k\\right) = k+3 - \\frac{k^2-k+6k}{2} = \\frac{2k+6 - k^2-5k}{2} = \\frac{-k^2-3k+6}{2}$.\nThe amortized cost is:\n$$c_a = c_{act} + \\Delta\\Phi = \\frac{k^2+3k+2}{2} + \\frac{-k^2-3k+6}{2} = \\frac{8}{2} = 4$$\nThe amortized cost of every increment operation is exactly $4$, regardless of the state of the counter. This confirms that $c=4$ is a valid constant amortized cost.\n\n**4. Asymptotic Analysis and Tightness**\n\nThe constant $c=4$ is an upper bound on the average cost. To show it is tight, we must show that the average cost per operation can be arbitrarily close to $4$. We can do this by analyzing the average cost as the number of operations $m$ goes to infinity.\n\nThe average cost after $m$ increments is $\\frac{C(m)}{m}$. Using the formula from the aggregate analysis:\n$$\\frac{C(m)}{m} = \\frac{1}{m} \\sum_{i=0}^{\\infty} (i+1) \\left\\lfloor \\frac{m}{2^i} \\right\\rfloor = \\sum_{i=0}^{\\infty} (i+1) \\frac{\\lfloor m/2^i \\rfloor}{m}$$\nAs $m \\to \\infty$, the term $\\frac{\\lfloor m/2^i \\rfloor}{m}$ approaches $\\frac{m/2^i}{m} = \\frac{1}{2^i}$. So we can find the limit:\n$$\\lim_{m\\to\\infty} \\frac{C(m)}{m} = \\lim_{m\\to\\infty} \\sum_{i=0}^{\\infty} (i+1) \\frac{\\lfloor m/2^i \\rfloor}{m} = \\sum_{i=0}^{\\infty} (i+1) \\lim_{m\\to\\infty} \\frac{\\lfloor m/2^i \\rfloor}{m}$$\n(Interchanging the limit and sum is justified by the Dominated Convergence Theorem, as the terms are bounded by an absolutely convergent series $(i+1)/2^i$.)\n$$\\lim_{m\\to\\infty} \\frac{C(m)}{m} = \\sum_{i=0}^{\\infty} \\frac{i+1}{2^i} = 4$$\nSince the average cost per operation approaches $4$, no constant amortized cost less than $4$ could possibly be valid for all $m$. If we chose $c' < 4$, for a sufficiently large $m$, the total payments $m c'$ would be less than the total actual cost $C(m) \\approx 4m$, violating the definition of amortized cost.\nTherefore, the constant $c=4$ is the smallest possible, i.e., it is tight.\n\nIn summary, all three methods of amortized analysis consistently point to a minimal constant amortized cost of $4$.", "answer": "$$\\boxed{4}$$", "id": "3204622"}]}