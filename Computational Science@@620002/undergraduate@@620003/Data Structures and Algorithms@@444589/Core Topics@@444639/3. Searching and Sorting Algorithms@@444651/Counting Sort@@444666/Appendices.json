{"hands_on_practices": [{"introduction": "This practice moves beyond sorting simple integers to sorting complex data structures. You will generalize Counting Sort by using a `key function` to extract a sortable integer from each object, a powerful technique that makes the algorithm highly versatile. This modular approach is fundamental to applying Counting Sort in real-world scenarios and is a critical component of more advanced algorithms like Radix Sort. [@problem_id:3224624]", "problem": "Design and implement a stable sorting procedure that adapts counting sort to operate on an array of arbitrary elements by using a key extraction function. Let $A$ be a finite sequence of elements, and let $\\mathrm{key\\_func}$ be a function such that for every element $x \\in A$, $\\mathrm{key\\_func}(x)$ is an integer in the inclusive range $[0,k]$ for some given nonnegative integer $k$. Your task is to derive, from first principles, a stable algorithm that uses the bounded integer range of keys to sort $A$ in nondecreasing order with respect to the keys computed by $\\mathrm{key\\_func}$.\n\nBase your derivation on the following foundational facts and definitions:\n- Arrays support random access and indexing in deterministic time per access under the Random Access Machine model.\n- The frequency of occurrences of a finite set of discrete values can be tabulated by counting, and cumulative totals enable computation of positions for grouped placement.\n- A sorting algorithm is stable if and only if any two elements with equal keys appear in the output in the same relative order as they appear in the input.\n- For any finite sequence of nonnegative integers bounded by $k$, the multiset of keys can be represented by a frequency array of length $k+1$.\n\nYou must construct the algorithm so that it:\n- Uses the ability to count occurrences of each possible key in $[0,k]$ and uses cumulative information to place elements deterministically.\n- Preserves the stability property as defined above.\n- Runs in time proportional to $|A| + k$ using additional space proportional to $|A| + k$.\n\nProgram specification:\n- Implement a function $\\text{sort}(A,\\mathrm{key\\_func},k)$ that returns a new sequence consisting of the elements of $A$ sorted in nondecreasing order of $\\mathrm{key\\_func}(x)$ and preserving the input order among equal keys.\n- For verification, apply your function to the following test suite. In each case, $A$ is a list of pairs $(v,i)$ where $v$ is the value relevant to the key function and $i$ is a unique identifier. For each test case, the required output is the list of identifiers $i$ in the order induced by the stable key-based sort. The test cases are:\n  1. General case with repeated keys: $A_1 = [(3,101),(1,102),(3,103),(0,104),(5,105),(1,106),(2,107),(5,108),(4,109),(2,110)]$, $\\mathrm{key\\_func}_1(v,i) = v$, $k_1 = 5$.\n  2. Boundary case with $k=0$ (all keys identical): $A_2 = [(7,201),(3,202),(9,203),(1,204),(7,205),(3,206)]$, $\\mathrm{key\\_func}_2(v,i) = 0$, $k_2 = 0$.\n  3. Edge case with empty input: $A_3 = [\\ ]$, $\\mathrm{key\\_func}_3(v,i) = 0$, $k_3 = 3$.\n  4. Nontrivial key function on strings: $A_4 = [(\\text{\"delta\"},301),(\\text{\"mu\"},302),(\\text{\"epsilon\"},303),(\\text{\"pi\"},304),(\\text{\"alpha\"},305),(\\text{\"beta\"},306),(\\text{\"omicron\"},307)]$, $\\mathrm{key\\_func}_4(v,i) = |v| \\bmod 4$ where $|v|$ denotes the length of the string $v$, and $k_4 = 3$.\n\nFinal output format:\n- Your program must produce a single line containing the results for the $4$ test cases as a comma-separated list enclosed in square brackets. Each result must itself be the list of identifiers in the induced sorted order, enclosed in square brackets. For example, the output format is $[\\ [i\\_1,i\\_2,\\dots],[\\dots],[\\dots],[\\dots]\\ ]$ with no additional text. The required outputs are lists of integers.", "solution": "We begin from the foundational facts that for any finite multiset of integers bounded in a known range $[0,k]$, one can count occurrences via a frequency array, and cumulative totals of these frequencies yield deterministic placement indices for a stable arrangement. Arrays support constant-time indexed access under the Random Access Machine model, ensuring that accumulation and placement steps run in time proportional to the number of indices visited.\n\nLet $A$ be a sequence of length $n = |A|$ and let $K(x) = \\mathrm{key\\_func}(x) \\in [0,k]$ be the integer key for element $x$. The goal is to construct a stable sort of $A$ by nondecreasing keys $K(x)$ using operations linear in $n+k$ and additional memory linear in $n+k$.\n\nThe algorithm is constructed as follows:\n1. Counting phase. Allocate an array $C$ of length $k+1$ initialized to $0$. For each $x \\in A$, read its key $t = K(x)$ and increment $C[t] \\leftarrow C[t] + 1$. After this pass, $C[t]$ stores the count of elements with key $t$ for all $t \\in \\{0,1,\\dots,k\\}$.\n\n2. Prefix-sum (cumulative) phase. Transform $C$ in place so that $C[t]$ becomes the starting index (offset) in the output array for key $t$. Initialize an accumulator $s \\leftarrow 0$, and for $t$ from $0$ to $k$, perform:\n   - Let $c \\leftarrow C[t]$.\n   - Set $C[t] \\leftarrow s$.\n   - Update $s \\leftarrow s + c$.\n   After this phase, for each key $t$, $C[t]$ equals the first position in the output array where an element of key $t$ should be placed. Since $s$ increments by the total number of elements seen up to key $t$, the segments for distinct keys are contiguous and nonoverlapping, spanning indices $[C[t], C[t] + \\text{count}(t) - 1]$.\n\n3. Stable placement phase. Allocate an output array $B$ of length $n$. Traverse $A$ from left to right. For each element $x$, compute $t = K(x)$, place $x$ at index $C[t]$ in $B$, and then increment $C[t] \\leftarrow C[t] + 1$. Because $C[t]$ initially stores the left boundary for key $t$ and is incremented after each placement, elements of the same key are assigned to strictly increasing indices in the exact order they are read from $A$. This preserves stability: if $x$ appears before $y$ in $A$ and $K(x)=K(y)$, then $x$ is placed at a smaller index in $B$ than $y$.\n\nCorrectness argument:\n- Sorting by keys: By construction, all elements with key $t$ are assigned indices in $[L_t, R_t]$, where $L_t$ is the value stored in $C[t]$ after the prefix-sum phase and $R_t = L_t + \\text{count}(t) - 1$. For $t_1 < t_2$, the ranges are ordered by $t_1$ then $t_2$ because the accumulation $s$ ensures $L_{t_2} = L_{t_1} + \\sum_{u = t_1}^{t_2-1} \\text{count}(u) \\ge L_{t_1} + \\text{count}(t_1)$, so all indices for $t_1$ precede those for $t_2$. Therefore, the output $B$ is nondecreasing in key.\n- Stability: Within key $t$, the index used for placement is incremented each time an element with key $t$ is placed, in the same left-to-right traversal order of $A$. Thus, equal-key elements preserve input order.\n\nComplexity analysis:\n- The counting phase visits each of the $n$ elements once and performs $O(1)$ work per element, totaling $O(n)$ time.\n- The prefix-sum phase visits each key index from $0$ to $k$ once, totaling $O(k)$ time.\n- The placement phase visits each of the $n$ elements once, totaling $O(n)$ time.\n- Overall time is $O(n + k)$. The auxiliary storage used is the output array of $n$ elements plus the count array of $k+1$ entries, hence $O(n + k)$ additional space.\n\nTest suite application:\n- Test $1$: $A_1 = [(3,101),(1,102),(3,103),(0,104),(5,105),(1,106),(2,107),(5,108),(4,109),(2,110)]$, $\\mathrm{key\\_func}_1(v,i) = v$, $k_1 = 5$. The stable sort groups by keys $0,1,2,3,4,5$ in order, yielding identifiers in the order $[104,102,106,107,110,101,103,109,105,108]$.\n- Test $2$: $A_2$ with $\\mathrm{key\\_func}_2(v,i) = 0$ and $k_2 = 0$ places all elements into a single key bucket and, by stability, returns the identifiers in the original order $[201,202,203,204,205,206]$.\n- Test $3$: $A_3 = [\\ ]$ produces the empty list $[\\ ]$ regardless of $k_3$.\n- Test $4$: $A_4$ with $\\mathrm{key\\_func}_4(v,i) = |v| \\bmod 4$ and $k_4 = 3$ computes keys $[1,2,3,2,1,0,3]$ for the given strings, and the stable grouping by keys $0,1,2,3$ yields identifiers $[306,301,305,302,304,303,307]$.\n\nThe specified output is a single line aggregating these per-test lists in order as a comma-separated list enclosed in square brackets, with each sublist also enclosed in square brackets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np  # Not strictly required; included per allowed environment.\n\ndef counting_sort_by_key(A, key_func, k):\n    \"\"\"\n    Stable counting-based sort of arbitrary elements by integer key in [0, k].\n    Returns a new list with elements of A sorted by key_func(x) in nondecreasing order.\n    \"\"\"\n    n = len(A)\n    # Frequency array for keys 0..k\n    counts = [0] * (k + 1)\n    for x in A:\n        t = key_func(x)\n        if not isinstance(t, int):\n            raise ValueError(\"key_func must return an integer.\")\n        if t < 0 or t > k:\n            raise ValueError(\"key_func returned a key outside [0, k].\")\n        counts[t] += 1\n\n    # Convert counts to starting indices (prefix sums)\n    total = 0\n    for t in range(k + 1):\n        c = counts[t]\n        counts[t] = total\n        total += c\n\n    # Stable placement\n    output = [None] * n\n    for x in A:\n        t = key_func(x)\n        idx = counts[t]\n        output[idx] = x\n        counts[t] = idx + 1\n\n    return output\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Test 1: General case with repeated keys\n    A1 = [(3, 101), (1, 102), (3, 103), (0, 104), (5, 105),\n          (1, 106), (2, 107), (5, 108), (4, 109), (2, 110)]\n    def key_func1(x):\n        return x[0]\n    k1 = 5\n\n    # Test 2: Boundary case k = 0 (all keys identical)\n    A2 = [(7, 201), (3, 202), (9, 203), (1, 204), (7, 205), (3, 206)]\n    def key_func2(x):\n        return 0\n    k2 = 0\n\n    # Test 3: Edge case empty input\n    A3 = []\n    def key_func3(x):\n        return 0\n    k3 = 3\n\n    # Test 4: Nontrivial key function on strings: length mod 4\n    A4 = [(\"delta\", 301), (\"mu\", 302), (\"epsilon\", 303),\n          (\"pi\", 304), (\"alpha\", 305), (\"beta\", 306), (\"omicron\", 307)]\n    def key_func4(x):\n        return len(x[0]) % 4\n    k4 = 3\n\n    test_cases = [\n        (A1, key_func1, k1),\n        (A2, key_func2, k2),\n        (A3, key_func3, k3),\n        (A4, key_func4, k4),\n    ]\n\n    results = []\n    for A, key_func, k in test_cases:\n        sorted_A = counting_sort_by_key(A, key_func, k)\n        # Extract the identifiers (second component)\n        ids_in_order = [x[1] for x in sorted_A]\n        results.append(ids_in_order)\n\n    # Helper to format a list of ints without spaces\n    def format_list(lst):\n        return \"[\" + \",\".join(map(str, lst)) + \"]\"\n\n    # Final print statement in the exact required format.\n    print(\"[\" + \",\".join(format_list(lst) for lst in results) + \"]\")\n\nsolve()\n```", "id": "3224624"}, {"introduction": "The standard Counting Sort algorithm has a significant drawback: its space and time complexity depend on the key range, $k$, making it impractical for sparse data with a large key range. This exercise challenges you to overcome this limitation by replacing the counting array with a hash table. By doing so, you will adapt the algorithm to handle sparse data efficiently, exploring the trade-offs in time complexity that arise from this new design. [@problem_id:3224735]", "problem": "You are given the task of designing and analyzing a stable sorting procedure for integer-keyed records over a potentially very large key range. The setting is sparse: only a small subset of keys is present, yet the keys themselves may be arbitrarily large in magnitude. You must develop a variant of counting sort that uses a hash table to store counts instead of a direct-mapped array indexed by keys. The algorithm must be stable: when two records have equal keys, their relative order in the output must match their relative order in the input.\n\nFundamental base for derivation: Use only the following foundational facts to justify the algorithm’s correctness and complexity.\n- Counting sort relies on counting the number of occurrences of each key to determine output positions, and its stability is achieved by placing items in the output in an order that preserves input order for equal keys.\n- A hash table provides expected constant-time operations for insert, find, and update under standard randomization and uniform hashing assumptions.\n- A prefix sum of nonnegative counts provides starting indices for contiguous segments in an output array.\n\nYour program must implement a function that takes a list of records, where each record is a pair $\\left(x_i, id_i\\right)$ with integer key $x_i$ and integer identifier $id_i$, and returns the stable order of $id_i$ after sorting by nondecreasing $x_i$. You must not allocate an array of size proportional to the largest key value; instead, you must use a hash table for counting. The implementation must be stable for all inputs.\n\nDefine the input size as $n$, the number of records, and let $u$ be the number of distinct keys present in the input. Your analysis must reason from the listed base to establish the asymptotic time and space complexity as functions of $n$ and $u$.\n\nTest suite. Your program must run the algorithm on the following six test cases and aggregate the results:\n- Test case $1$: records $\\left[\\left(7,0\\right),\\left(3,1\\right),\\left(7,2\\right),\\left(2,3\\right),\\left(3,4\\right),\\left(9,5\\right)\\right]$. Expected stable sort by key produces the $id$ sequence corresponding to keys in nondecreasing order.\n- Test case $2$: records $\\left[\\;\\right]$ (the empty list).\n- Test case $3$: records $\\left[\\left(42,0\\right)\\right]$.\n- Test case $4$: records $\\left[\\left(5,0\\right),\\left(5,1\\right),\\left(5,2\\right),\\left(5,3\\right)\\right]$.\n- Test case $5$: records $\\left[\\left(-1000000000,0\\right),\\left(1000000000,1\\right),\\left(0,2\\right),\\left(-1000000000,3\\right),\\left(1000000000,4\\right)\\right]$.\n- Test case $6$: records $\\left[\\left(100,0\\right),\\left(-50,1\\right),\\left(100,2\\right),\\left(50,3\\right),\\left(-50,4\\right),\\left(200,5\\right),\\left(0,6\\right)\\right]$.\n\nFor each test case, the result is the list of identifiers $id_i$ in the stable, nondecreasing-by-key order. All outputs are lists of integers.\n\nFinal output format. Your program must produce a single line of output containing the results for the six test cases as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated list of integers and there are no spaces anywhere. For example, if the six results were lists $R_1,\\dots,R_6$, the output must be of the exact form $\\left[\\;R_1,R_2,R_3,R_4,R_5,R_6\\;\\right]$. There are no physical units or angle measurements in this problem, and no percentages are required. The program must be self-contained and must not read any input.", "solution": "The task is to develop a stable sorting algorithm for records with integer keys, where the range of keys can be very large but the number of records is manageable. This scenario renders traditional counting sort impractical due to its requirement for an auxiliary array of size proportional to the maximum key value. The proposed solution is a variant of counting sort that leverages a hash table to manage counts, thereby bypassing the large key range limitation. The algorithm must be stable, meaning records with equal keys retain their original relative order.\n\nLet $n$ be the number of records in the input list and $u$ be the number of unique keys. Each record is a pair $(x_i, id_i)$, where $x_i$ is an integer key and $id_i$ is an integer identifier.\n\nThe algorithm is constructed in three main phases, adhering to the foundational principles provided.\n\n**Phase 1: Frequency Counting**\n\nThe first step is to count the occurrences of each unique key in the input. A hash table, which we will call `counts`, is used for this purpose. We iterate through the $n$ input records. For each record $(x_i, id_i)$, we update the count for the key $x_i$ in the `counts` hash table. If $x_i$ is not yet in the table, it is inserted with a count of $1$; otherwise, its existing count is incremented.\n\n- **Principle**: This step uses the property that a hash table provides expected constant-time operations for insertion and updates. Therefore, processing all $n$ records takes an expected time of $O(n)$.\n- **Space**: The `counts` hash table will store one entry for each of the $u$ unique keys. The space complexity for this phase is thus $O(u)$.\n\n**Phase 2: Position Calculation**\n\nThe second phase determines the starting position in the final output array for each group of records sharing the same key. This is analogous to the prefix sum calculation in standard counting sort.\n\n1.  **Extract and Sort Keys**: First, we extract the $u$ unique keys from the `counts` hash table. To establish a nondecreasing order for the output, these keys must be sorted. Let the sorted unique keys be $k_1, k_2, \\dots, k_u$. The time complexity of this step is dominated by sorting, which is $O(u \\log u)$ using a standard comparison-based sort.\n\n2.  **Compute Starting Indices**: We create a second hash table, `positions`, to map each unique key to its starting index in the final sorted array. This is done by computing a prefix sum over the counts of the sorted keys. A running `offset` is initialized to $0$. We iterate through the sorted keys $k_j$ for $j=1, \\dots, u$:\n    - The starting position for key $k_j$ is the current `offset`. We set `positions[k_j] = offset`.\n    - The `offset` is then incremented by the number of elements with key $k_j$, which is stored in `counts[k_j]`.\n    \n    This process calculates that the first block of items (with key $k_1$) will start at index $0$. The second block (with key $k_2$) will start at index `counts[k_1]`. The third block (with key $k_3$) will start at index `counts[k_1] + counts[k_2]`, and so on.\n\n- **Principle**: This step directly applies the principle that a prefix sum of counts provides starting indices for contiguous segments. By performing this on the sorted unique keys, we map the abstract order of keys to concrete indices in memory.\n- **Complexity**: This step involves an $O(u)$ iteration over the sorted keys. The dominant cost for this phase remains the $O(u \\log u)$ sorting step. The `positions` hash table requires $O(u)$ space.\n\n**Phase 3: Stable Placement**\n\nThe final phase places the record identifiers into an output array of size $n$ in their stable, sorted order.\n\nTo ensure stability, we must iterate through the input records $(x_i, id_i)$ in their original order, from $i=1$ to $n$. For each record:\n1.  Look up the current placement index for its key $x_i$ in the `positions` hash table. Let this be `p = positions[x_i]`.\n2.  Place the identifier $id_i$ into the output array at index `p`.\n3.  Increment the position for key $x_i$ in the `positions` hash table: `positions[x_i] = p + 1`.\n\n- **Principle**: Stability is achieved because we process the input records sequentially. If two records have the same key, the one that appeared earlier in the input will be placed first. Its placement action increments the starting position for that key, ensuring the subsequent record with the same key is placed immediately after it, thus preserving their initial relative order.\n- **Complexity**: This phase involves a single pass through the $n$ input records. Each step inside the loop consists of a hash table lookup and an update, which are expected $O(1)$ operations. The total time for this phase is $O(n)$. An output array of size $n$ is required, contributing $O(n)$ to the space complexity.\n\n**Overall Complexity Analysis**\n\n- **Time Complexity**: The total expected time is the sum of the complexities of the three phases: $O(n)$ (counting) + $O(u \\log u)$ (sorting keys) + $O(n)$ (placement). This simplifies to $O(n + u \\log u)$.\n- **Space Complexity**: The space is determined by the storage for the `counts` hash table ($O(u)$), the `positions` hash table ($O(u)$), the temporary storage for sorted keys ($O(u)$), and the output array ($O(n)$). The total space complexity is therefore $O(n + u)$.\n\nThis algorithmic design successfully adapts counting sort for sparse, large-range keys while maintaining stability and adhering to the specified constraints and foundational principles.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the hash-based counting sort problem for the given test cases.\n    \"\"\"\n\n    def hash_counting_sort(records):\n        \"\"\"\n        Implements a stable, hash-based counting sort for integer-keyed records.\n\n        The algorithm handles sparse keys over a potentially large range by using\n        hash tables for counting and position mapping, avoiding the creation of\n        an array proportional to the key range.\n\n        Args:\n            records: A list of tuples, where each tuple is a pair (key, id).\n\n        Returns:\n            A list of ids, stably sorted by their corresponding keys in non-decreasing order.\n        \"\"\"\n        n = len(records)\n        if n == 0:\n            return []\n\n        # Phase 1: Frequency Counting\n        # Use a dictionary (hash table) to count occurrences of each key.\n        # Time: O(n) expected, Space: O(u) where u is the number of unique keys.\n        counts = {}\n        for key, _ in records:\n            counts[key] = counts.get(key, 0) + 1\n\n        # Phase 2: Position Calculation\n        # 1. Get unique keys and sort them to establish the output order.\n        # Time: O(u log u)\n        unique_keys = sorted(counts.keys())\n        \n        # 2. Compute prefix sums to find the starting index for each key's block.\n        #    Store these starting positions in a hash table.\n        # Time: O(u), Space: O(u)\n        positions = {}\n        start_pos = 0\n        for key in unique_keys:\n            positions[key] = start_pos\n            start_pos += counts[key]\n\n        # Phase 3: Stable Placement\n        # Create an output array. Iterate through the *original* input records to\n        # ensure stability. Place each item's id in its correct sorted position\n        # and increment the position for that key.\n        # Time: O(n) expected, Space: O(n) for the output array.\n        output = [0] * n\n        for key, item_id in records:\n            # Get the current position for this key\n            pos = positions[key]\n            # Place the id in the output array\n            output[pos] = item_id\n            # Increment the position for the next item with the same key\n            positions[key] += 1\n            \n        return output\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        [(7, 0), (3, 1), (7, 2), (2, 3), (3, 4), (9, 5)],\n        [],\n        [(42, 0)],\n        [(5, 0), (5, 1), (5, 2), (5, 3)],\n        [(-1000000000, 0), (1000000000, 1), (0, 2), (-1000000000, 3), (1000000000, 4)],\n        [(100, 0), (-50, 1), (100, 2), (50, 3), (-50, 4), (200, 5), (0, 6)],\n    ]\n\n    results = []\n    for case in test_cases:\n        result = hash_counting_sort(case)\n        results.append(result)\n\n    # Format the final output string exactly as required: no spaces, comma-separated lists within a list.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3224735"}, {"introduction": "In many applications, memory is a critical resource, making in-place algorithms highly desirable. This practice challenges you to re-engineer Counting Sort to operate without an auxiliary output array of size $n$. You will explore how this constraint forces a fundamental trade-off, compelling you to sacrifice the algorithm's renowned stability to achieve lower space complexity. [@problem_id:3224601]", "problem": "You are given the task of deriving and implementing an in-place version of counting sort for integer keys from first principles in data structures and algorithms. Begin from the core definitions: a frequency histogram over a known bounded integer domain, bucket boundaries derived from prefix sums, and the meaning of stability in sorting. You must rigorously show how these primitives imply correctness for distribution into bucket ranges, and then design an algorithm that eliminates the external output array while still sorting in place. You must analyze what properties are necessarily lost under the in-place constraint and determine the asymptotic time complexity.\n\nYour program must implement two variants derived from the same base mechanism:\n- An in-place counting sort for a list of integers, where only a frequency array of size $k$ (the number of distinct integer values in the domain) is used as auxiliary space. The algorithm must sort the given list in non-decreasing order by overwriting the original list according to the frequency counts. This variant treats elements as pure keys and must not allocate an auxiliary output array of size $n$.\n- An in-place counting sort for a list of records $(\\text{key}, \\text{tag})$, where the $\\text{key}$ is an integer in a known bounded range and $\\text{tag}$ is an identifier that represents original order. Use bucket boundaries derived from prefix sums and perform in-place distribution with cycle-leader style placement. This variant must not allocate an auxiliary output array of size $n$ and must operate by swapping records into their correct bucket ranges in-place.\n\nDefinitions to use as the fundamental base:\n- Let $A$ be an input array of length $n$ and let its integer keys lie in a contiguous range $[\\min, \\max]$. Let $k = \\max - \\min + 1$ denote the number of distinct key values in the domain.\n- The frequency histogram is an array $C$ of length $k$ where $C[i]$ equals the number of occurrences of the key value $(\\min + i)$ in $A$.\n- The prefix sums of $C$ determine bucket start indices. Let $S[0] = 0$ and $S[i] = \\sum_{j=0}^{i-1} C[j]$ for $i \\geq 1$. Then all items with key $(\\min + i)$ must occupy indices from $S[i]$ (inclusive) to $S[i] + C[i]$ (exclusive) in the sorted array.\n- A sorting algorithm is stable if for any two records with equal keys, their relative order in the output is identical to their relative order in the input.\n\nTasks:\n1. Implement the integer in-place counting sort by computing the histogram $C$ and then overwriting the original array $A$ in non-decreasing order using $C$. This must use at most $O(k)$ extra space and must not use an auxiliary array of size $n$. Report how many write operations to $A$ are performed by this overwrite step for each test case.\n2. Implement the record in-place counting sort (for tuples $(\\text{key}, \\text{tag})$) using the histogram $C$ and bucket boundaries from prefix sums, distributing records into bucket ranges via in-place swaps without allocating an auxiliary output array of size $n$. For each test case, compute:\n   - A boolean indicating whether the sort is stable relative to the original order of $\\text{tag}$ values within equal-key groups.\n   - The total number of swap operations performed to place records into correct buckets.\n3. State in your solution which property is lost by the in-place versions and what the new asymptotic time complexity is, expressed using \\LaTeX{} with Big O notation.\n\nInput domain and units:\n- All keys are integers; there are no physical units. The angle unit is not applicable. There are no percentages.\n\nTest suite:\nUse the following explicit test cases. For integer arrays, each case is a triple $(A, \\min, \\max)$ with $A$ a list of integers. For record arrays, each case is a triple $(R, \\min, \\max)$ with $R$ a list of pairs $(\\text{key}, \\text{tag})$.\n\nInteger-array cases:\n- Case $1$: $A = [\\,3,\\,1,\\,2,\\,1,\\,0,\\,2,\\,3,\\,3\\,]$, $\\min = 0$, $\\max = 3$.\n- Case $2$: $A = [\\,5\\,]$, $\\min = 5$, $\\max = 5$.\n- Case $3$: $A = [\\,0,\\,0,\\,1,\\,1,\\,2,\\,2,\\,3\\,]$, $\\min = 0$, $\\max = 3$.\n- Case $4$: $A = [\\,4,\\,3,\\,2,\\,1,\\,0\\,]$, $\\min = 0$, $\\max = 4$.\n- Case $5$: $A = [\\, -2,\\,-1,\\,-1,\\,0,\\,1\\,]$, $\\min = -2$, $\\max = 1$.\n\nRecord-array cases (each record is $(\\text{key}, \\text{tag})$):\n- Case $1$: $R = [\\,(2,\\,\\text{'a'}),\\,(1,\\,\\text{'b'}),\\,(2,\\,\\text{'c'}),\\,(1,\\,\\text{'d'}),\\,(0,\\,\\text{'e'})\\,]$, $\\min = 0$, $\\max = 2$.\n- Case $2$: $R = [\\,(0,\\,\\text{'a'}),\\,(0,\\,\\text{'b'}),\\,(1,\\,\\text{'c'}),\\,(1,\\,\\text{'d'}),\\,(2,\\,\\text{'e'})\\,]$, $\\min = 0$, $\\max = 2$.\n- Case $3$: $R = [\\,(1,\\,\\text{'a'}),\\,(1,\\,\\text{'b'}),\\,(1,\\,\\text{'c'})\\,]$, $\\min = 1$, $\\max = 1$.\n- Case $4$: $R = [\\,(-1,\\,\\text{'a'}),\\,(0,\\,\\text{'b'}),\\,(-1,\\,\\text{'c'}),\\,(1,\\,\\text{'d'})\\,]$, $\\min = -1$, $\\max = 1$.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The single line must have the following structure:\n$[\\,\\text{V},\\,\\text{S},\\,\\text{W},\\,\\text{WV}\\,]$\nwhere:\n- $\\text{V}$ is the list of sorted integer arrays for the five integer cases, in order.\n- $\\text{S}$ is the list of booleans for the four record cases indicating whether the in-place record sort is stable.\n- $\\text{W}$ is the list of integers for the four record cases giving the total number of swaps performed.\n- $\\text{WV}$ is the list of integers for the five integer cases giving the total number of write operations to the array during the overwrite step.\n\nFor example, the output will look like $[\\,[\\ldots],\\,[\\ldots],\\,[\\ldots],\\,[\\ldots]\\,]$ with all inner lists filled according to the above specification and no extra text.", "solution": "The fundamental principle of counting sort is to leverage a known, bounded integer domain for the keys. Instead of comparing elements against each other, we count their occurrences and use these counts to determine their final positions. The standard implementation is stable but requires an auxiliary output array of size $n$, where $n$ is the number of elements. The task is to derive versions that eliminate this $O(n)$ space requirement, operating in-place.\n\nLet $A$ be the input array of length $n$ with keys in the range $[\\min, \\max]$. The size of the key domain is $k = \\max - \\min + 1$.\n\n**Part 1: In-Place Integer Sort**\n\nThe first variant deals with an array of integers where the elements themselves are the keys. The goal is to sort the array in-place using only $O(k)$ auxiliary space for a frequency histogram.\n\n**Principle and Derivation:**\n$1$. **Frequency Histogram:** First, we construct a frequency histogram, an array $C$ of size $k$. For each integer value $v$ in the input array $A$, we increment the count at index $v - \\min$ in $C$. After scanning all $n$ elements of $A$, $C[i]$ will hold the total number of occurrences of the key $(\\min + i)$. This step takes $O(n)$ time to iterate through $A$ and $O(k)$ space for $C$.\n$2$. **In-Place Overwriting:** Once the histogram $C$ is computed, the contents of the sorted array are fully determined. We know that the sorted array must consist of $C[0]$ copies of the value $(\\min + 0)$, followed by $C[1]$ copies of $(\\min + 1)$, and so on, up to $C[k-1]$ copies of $(\\min + k - 1)$. Since the original positions of the integers do not matter for this variant (as they are just keys), we can directly overwrite the original array $A$. We use a pointer, say `write_idx`, initialized to $0$. We iterate from $i=0$ to $k-1$. For each $i$, we write the value $(\\min + i)$ into $A$ at the current `write_idx` a total of $C[i]$ times, incrementing `write_idx` after each write. This overwrite process performs exactly $n$ write operations and takes $O(n+k)$ time.\n\n**Analysis:**\n- **Time Complexity:** The total time complexity is the sum of building the histogram ($O(n)$) and overwriting the array ($O(k+n)$), which results in $O(n+k)$.\n- **Space Complexity:** The algorithm uses an auxiliary array $C$ of size $k$, so the auxiliary space complexity is $O(k)$. This satisfies the constraint of not using an $O(n)$ auxiliary array.\n- **Lost Property:** This method completely erases any information about the original relative ordering of identical keys. It reconstructs the array based solely on frequency counts. Therefore, this in-place variant is **not stable**.\n\n**Part 2: In-Place Record Sort**\n\nThe second variant handles records of the form $(\\text{key}, \\text{tag})$, where preserving the original order of records with equal keys (stability) is a concern. The goal is to sort in-place by swapping elements into their correct bucket ranges.\n\n**Principle and Derivation:**\n$1$. **Bucket Boundaries:** As before, we compute the frequency histogram $C$ in $O(n)$ time. To determine where groups of elements should reside in the final sorted array, we compute prefix sums of $C$. Let $S$ be an array of size $k$ where $S[0] = 0$ and $S[i] = \\sum_{j=0}^{i-1} C[j]$ for $i > 0$. The array $S$ defines the starting index for each key's \"bucket\". The elements with key $(\\min + i)$ belong in the contiguous index range $[S[i], S[i] + C[i] - 1)$.\n$2$. **In-Place Permutation (Cycle-Following):** The standard stable counting sort uses $S$ to place elements into a separate output array. To perform this in-place, we must permute the elements of $A$ into their correct buckets. A robust method is to follow the permutation cycles.\n- We iterate through each index $i$ of the array $A$ from $0$ to $n-1$.\n- At each index $i$, we examine the element $A[i]$. Let its key be $v$. This element belongs in the bucket for key $v$. We check if the current index $i$ falls within the bucket range for $v$.\n- If $A[i]$ is already in its correct bucket (i.e., its \"home\"), we move to the next index, $i+1$.\n- If $A[i]$ is not in its correct bucket, we must swap it to a position inside its target bucket. We use a separate array of pointers, `next_pos`, initialized identically to $S$, to track the next available slot in each bucket. We find the destination index `dest = next_pos[v - min]`, swap $A[i]$ with $A[\\text{dest}]$, and increment `next_pos[v - min]`. This places one element correctly.\n- Crucially, the new element now at $A[i]$ may also be in the wrong place. We do not advance $i$. Instead, we repeat the process for the new $A[i]$: check if it is home, and if not, swap it to its destination. This inner process continues until an element that is \"home\" at index $i$ is moved into $A[i]$. At this point, the cycle starting at $i$ is complete, and we can advance the outer loop to $i+1$.\n- This process ensures every element is moved at most once into its final bucket, and the total work for the permutation is $O(n)$.\n\n**Analysis:**\n- **Time Complexity:** The steps are: building the histogram ($O(n)$), computing prefix sums ($O(k)$), and performing the in-place permutation ($O(n)$). The total time complexity is $O(n+k)$.\n- **Space Complexity:** This variant requires the histogram $C$ ($O(k)$) and the prefix sum/pointer array $S$ ($O(k)$). The total auxiliary space is $O(k)$.\n- **Lost Property:** Because an element is swapped into the *next available* slot in its bucket, without regard to its original relative position among other elements of the same key, **stability is generally lost**. While some inputs may be sorted stably by chance, the algorithm does not guarantee it. This is the primary property sacrificed to achieve an in-place sort.\n\n**Summary of Analysis (Task 3):**\n\nThe property that is necessarily lost or, at best, no longer guaranteed by these in-place counting sort variants is **stability**. The asymptotic time complexity for both described in-place algorithms remains $O(n+k)$, which is the same as the standard, non-in-place, stable counting sort. The constraint of operating in-place primarily impacts stability rather than asymptotic performance.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Derives and implements two variants of in-place counting sort.\n    \"\"\"\n\n    def inplace_counting_sort_int(A, min_val, max_val):\n        \"\"\"\n        Sorts a list of integers in-place using a frequency histogram.\n        Returns the sorted list and the number of write operations during the overwrite step.\n        \"\"\"\n        if not A:\n            return [], 0\n            \n        n = len(A)\n        k = max_val - min_val + 1\n        \n        # 1. Compute frequency histogram\n        counts = np.zeros(k, dtype=int)\n        for x in A:\n            counts[x - min_val] += 1\n            \n        # 2. Overwrite the original array\n        write_ops = 0\n        write_idx = 0\n        for i in range(k):\n            val = min_val + i\n            count = counts[i]\n            for _ in range(count):\n                A[write_idx] = val\n                write_idx += 1\n                write_ops += 1\n                \n        return A, write_ops\n\n    def inplace_counting_sort_record(R, min_val, max_val):\n        \"\"\"\n        Sorts a list of (key, tag) records in-place using cycle-following.\n        Returns the sorted list, a boolean for stability, and the number of swaps.\n        \"\"\"\n        n = len(R)\n        if n == 0:\n            return [], True, 0\n\n        original_R = list(R)\n        k = max_val - min_val + 1\n\n        # 1. Compute frequency histogram\n        counts = np.zeros(k, dtype=int)\n        for key, _ in R:\n            counts[key - min_val] += 1\n\n        # 2. Compute bucket boundaries (static) and next available positions (dynamic)\n        bucket_starts = np.zeros(k, dtype=int)\n        bucket_starts[1:] = np.cumsum(counts[:-1])\n        bucket_ends = bucket_starts + counts\n        next_pos = bucket_starts.copy()\n\n        swaps = 0\n        # 3. In-place permutation via cycle-following\n        for i in range(n):\n            key, _ = R[i]\n            key_idx = key - min_val\n            \n            # An element is \"home\" if its index is within its key's designated bucket\n            is_home = bucket_starts[key_idx] <= i < bucket_ends[key_idx]\n\n            while not is_home:\n                dest_idx = next_pos[key_idx]\n                R[i], R[dest_idx] = R[dest_idx], R[i]\n                swaps += 1\n                next_pos[key_idx] += 1\n\n                # Re-evaluate the new element at R[i]\n                key, _ = R[i]\n                key_idx = key - min_val\n                is_home = bucket_starts[key_idx] <= i < bucket_ends[key_idx]\n\n        # 4. Check stability\n        original_order = defaultdict(list)\n        for key, tag in original_R:\n            original_order[key].append(tag)\n        \n        final_order = defaultdict(list)\n        for key, tag in R:\n            final_order[key].append(tag)\n            \n        is_stable = True\n        for key in original_order:\n            if original_order[key] != final_order[key]:\n                is_stable = False\n                break\n                \n        return R, is_stable, swaps\n\n    # Define test cases from the problem statement.\n    integer_cases = [\n        ([3, 1, 2, 1, 0, 2, 3, 3], 0, 3),\n        ([5], 5, 5),\n        ([0, 0, 1, 1, 2, 2, 3], 0, 3),\n        ([4, 3, 2, 1, 0], 0, 4),\n        ([-2, -1, -1, 0, 1], -2, 1),\n    ]\n\n    record_cases = [\n        ([(2, 'a'), (1, 'b'), (2, 'c'), (1, 'd'), (0, 'e')], 0, 2),\n        ([(0, 'a'), (0, 'b'), (1, 'c'), (1, 'd'), (2, 'e')], 0, 2),\n        ([(1, 'a'), (1, 'b'), (1, 'c')], 1, 1),\n        ([(-1, 'a'), (0, 'b'), (-1, 'c'), (1, 'd')], -1, 1),\n    ]\n\n    # Process integer cases\n    V_results = []\n    WV_results = []\n    for A, min_val, max_val in integer_cases:\n        # A.copy() is important to not modify the original test case list\n        sorted_A, writes = inplace_counting_sort_int(A.copy(), min_val, max_val)\n        V_results.append(sorted_A)\n        # Number of writes to overwrite an array of length n is n\n        WV_results.append(len(A))\n\n    # Process record cases\n    S_results = []\n    W_results = []\n    for R, min_val, max_val in record_cases:\n        # R.copy() is important\n        _, is_stable, swaps = inplace_counting_sort_record(R.copy(), min_val, max_val)\n        S_results.append(is_stable)\n        W_results.append(swaps)\n\n    # Final print statement in the exact required format.\n    print(f\"[{V_results},{S_results},{W_results},{WV_results}]\")\n\nsolve()\n```", "id": "3224601"}]}