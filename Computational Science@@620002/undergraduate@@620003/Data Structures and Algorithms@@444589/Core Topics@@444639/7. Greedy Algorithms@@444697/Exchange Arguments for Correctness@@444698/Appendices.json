{"hands_on_practices": [{"introduction": "A powerful way to master a proof technique is to understand not only when it works, but also when it fails. This exercise challenges you to analyze a common but incorrect greedy approach to the interval scheduling problem. By constructing a counterexample and pinpointing exactly where an exchange argument breaks down, you will develop a deeper intuition for the conditions required for a greedy algorithm to be optimal [@problem_id:3232103].", "problem": "Consider the interval scheduling problem on a single machine: a finite set of requests $I = \\{I_1, I_2, I_3, I_4, I_5\\}$, where each request $I_k$ occupies a time interval $[s_k, f_k)$ with $s_k \\in \\mathbb{R}$, $f_k \\in \\mathbb{R}$, and $s_k < f_k$. Two requests $I_a$ and $I_b$ are compatible if and only if either $f_a \\le s_b$ or $f_b \\le s_a$. A schedule is any subset $S \\subseteq I$ whose requests are pairwise compatible. The goal is to maximize the cardinality $|S|$. Use only the following fundamental base: the formal definitions of compatibility, feasibility, and optimality as given, together with the standard notion of an exchange argument that attempts to transform any optimal schedule into one that agrees with a designated greedy choice without reducing the objective value.\n\nLet the instance be\n- $I_1 : [1, 10)$,\n- $I_2 : [2, 3)$,\n- $I_3 : [3, 4)$,\n- $I_4 : [4, 5)$,\n- $I_5 : [5, 6)$.\n\nConsider the greedy rule that selects requests by minimum start time: at each step, among requests not yet considered, choose the request with the smallest start time $s_k$ that is compatible with those already chosen (breaking ties arbitrarily), and irrevocably add it to the schedule. Suppose we start from the empty schedule and apply this rule to the given instance.\n\nTasks:\n- Determine the schedule produced by the minimum-start-time greedy rule and its cardinality.\n- Determine a maximum-cardinality schedule and its cardinality.\n- Identify a single local swap that takes the greedy schedule to a strictly larger feasible schedule by exchanging one chosen request for another available request, and formally pinpoint the exchange predicate that is violated in an attempted correctness proof for the minimum-start-time rule.\n\nWhich option correctly identifies both the swap and the violated predicate?\n\nA. Swap $I_1 : [1, 10)$ out for $I_2 : [2, 3)$; afterward, requests $I_3 : [3, 4)$, $I_4 : [4, 5)$, and $I_5 : [5, 6)$ can be appended, strictly increasing the feasible set size. The violated exchange predicate is: “For any optimal schedule $S^\\star$, there exists an optimal schedule $S'$ with $|S'| \\ge |S^\\star|$ that contains the minimum-start-time request.”\n\nB. Swap $I_3 : [3, 4)$ out for $I_1 : [1, 10)$ while preserving cardinality. The violated exchange predicate is: “Compatibility is transitive under start-time order; hence sorting by start time maximizes the number of requests.”\n\nC. Swap $I_1 : [1, 10)$ out for $I_2 : [2, 3)$; the violated exchange predicate is: “For any optimal schedule $S^\\star$, there exists an optimal schedule $S'$ with $|S'| \\ge |S^\\star|$ that contains the minimum-finish-time request,” which fails for the given instance.\n\nD. Swap $I_1 : [1, 10)$ out for $I_2 : [2, 3)$; the violated exchange predicate is: “Minimizing the first start time minimizes cumulative idle time and therefore maximizes cardinality.”\n\nChoose the single best answer.", "solution": "By definition, two intervals $I_a = [s_a, f_a)$ and $I_b = [s_b, f_b)$ are compatible if and only if either $f_a \\le s_b$ or $f_b \\le s_a$. A feasible schedule is any subset of $I$ whose pairs are all compatible, and an optimal schedule is a feasible schedule that maximizes cardinality.\n\nStep 1: Apply the minimum-start-time greedy rule from first principles. Starting with the empty schedule, the available requests and their start times are: $s_1 = 1$, $s_2 = 2$, $s_3 = 3$, $s_4 = 4$, $s_5 = 5$. The smallest start time is $s_1 = 1$, so the greedy rule selects $I_1 : [1, 10)$. By compatibility, any other request $I_k$ must satisfy $f_k \\le s_1$ or $f_1 \\le s_k$. Since $f_1 = 10$, $f_1 \\le s_k$ would require $10 \\le s_k$, but $s_2 = 2$, $s_3 = 3$, $s_4 = 4$, $s_5 = 5$, so none satisfy $10 \\le s_k$. Also, $f_k \\le s_1$ would require $f_k \\le 1$, which does not hold for any $k \\in \\{2, 3, 4, 5\\}$ because $f_2 = 3$, $f_3 = 4$, $f_4 = 5$, and $f_5 = 6$. Therefore, after choosing $I_1$, no further request can be added while preserving compatibility. The greedy schedule is $S_{\\text{greedy}} = \\{I_1\\}$ with $|S_{\\text{greedy}}| = 1$.\n\nStep 2: Determine a maximum-cardinality schedule. Consider the schedule $S^\\star = \\{I_2, I_3, I_4, I_5\\}$. Check pairwise compatibility in chronological order:\n- $I_2 = [2, 3)$ and $I_3 = [3, 4)$ are compatible because $f_2 = 3 \\le s_3 = 3$.\n- $I_3 = [3, 4)$ and $I_4 = [4, 5)$ are compatible because $f_3 = 4 \\le s_4 = 4$.\n- $I_4 = [4, 5)$ and $I_5 = [5, 6)$ are compatible because $f_4 = 5 \\le s_5 = 5$.\nBy transitivity of the constructed chain, all adjacent pairs are compatible, and non-adjacent pairs are separated by equalities that maintain the non-overlap condition. Hence $S^\\star$ is feasible with $|S^\\star| = 4$. No schedule can exceed cardinality $4$ because there are only $4$ requests that can feasibly fit after time $s_2 = 2$ without overlap once $I_1$ is excluded, and this sequence achieves that bound. Thus $S^\\star$ is a maximum-cardinality schedule.\n\nStep 3: Identify a local swap that strictly increases feasible set size from the greedy schedule and pinpoint the violated exchange predicate. Starting from $S_{\\text{greedy}} = \\{I_1\\}$:\n- Remove $I_1$ and add $I_2$ to obtain $S_1 = \\{I_2\\}$.\n- Since $f_2 = 3 \\le s_3 = 3$, we can append $I_3$ to get $S_2 = \\{I_2, I_3\\}$.\n- Similarly, $f_3 = 4 \\le s_4 = 4$ permits appending $I_4$ to get $S_3 = \\{I_2, I_3, I_4\\}$.\n- Finally, $f_4 = 5 \\le s_5 = 5$ permits appending $I_5$ to get $S_4 = \\{I_2, I_3, I_4, I_5\\}$.\nThis single local swap—exchanging $I_1$ for $I_2$—creates the opportunity to strictly increase the feasible set size from $1$ to $4$.\n\nIn an exchange argument for a greedy rule, the central exchange predicate typically asserts that for any optimal schedule $S^\\star$ there exists another optimal schedule $S'$ with $|S'| \\ge |S^\\star|$ that agrees with the greedy choice in the first position (that is, contains the greedy-selected request). For the minimum-start-time rule, this predicate becomes: “For any optimal schedule $S^\\star$, there exists an optimal schedule $S'$ with $|S'| \\ge |S^\\star|$ that contains the minimum-start-time request.” In this instance, any optimal schedule of cardinality $4$ (such as $S^\\star = \\{I_2, I_3, I_4, I_5\\}$) cannot contain $I_1$, because $I_1$ overlaps all of $I_2, I_3, I_4, I_5$. Including $I_1$ forces the schedule size down to $1$. Therefore, the exchange predicate required to prove correctness of the minimum-start-time heuristic is violated: it is impossible to transform an optimal schedule to include $I_1$ without strictly decreasing the objective value.\n\nOption-by-option analysis:\n- Option A: The proposed swap is $I_1 \\mapsto I_2$, and the follow-on construction of $\\{I_3, I_4, I_5\\}$ is feasible, yielding cardinality $4 > 1$. The stated violated predicate is exactly the exchange predicate one would need to prove the minimum-start-time rule correct (“any optimal schedule can be transformed to include the minimum-start-time request without reducing cardinality”), and this predicate fails for the given instance. Verdict — Correct.\n- Option B: The proposed swap replaces $I_3$ with $I_1$. This cannot preserve cardinality because adding $I_1$ eliminates compatibility with $I_4$ and $I_5$, collapsing the schedule size toward $1$. The stated predicate invokes a non-existent transitivity property tied to start-time order; compatibility is not transitive under start-time order in a way that would guarantee optimality of start-time sorting. Verdict — Incorrect.\n- Option C: The swap $I_1 \\mapsto I_2$ is feasible, but the predicate named is the classic exchange predicate for the minimum-finish-time rule (“there exists an optimal schedule that contains a minimum-finish-time request”), which is true and underpins the correct greedy algorithm by earliest finish time. It is not the violated predicate for the minimum-start-time rule. Verdict — Incorrect.\n- Option D: The swap $I_1 \\mapsto I_2$ is feasible, but the stated predicate claims that minimizing the first start time minimizes cumulative idle time and maximizes cardinality. This is neither a standard nor a valid exchange predicate for interval scheduling, and it is false for the instance because choosing $I_1$ with minimum start time produces maximal idle time afterward (due to blockage until time $10$) and minimal cardinality. Verdict — Incorrect.\n\nTherefore, the single best answer is Option A.", "answer": "$$\\boxed{A}$$", "id": "3232103"}, {"introduction": "Having seen how a plausible greedy strategy can fail, we now turn to designing one that succeeds and proving its correctness. This practice moves into the online setting, where decisions must be made without knowledge of future inputs, adding a layer of complexity. You will derive an optimal greedy algorithm for an online job scheduling problem and formalize its correctness using a rigorous exchange argument [@problem_id:3205848].", "problem": "You are given a single-machine scheduling problem in which jobs arrive one by one (online). Each job is characterized by a nonnegative processing time $p_j$ and a nonnegative deadline $d_j$. A schedule is a total ordering of the accepted jobs on the single machine. A job $j$ is considered on time if it completes no later than its deadline $d_j$. The goal is to design an online algorithm that, upon each arrival, decides whether to accept or reject jobs so that the total number of accepted jobs that can be scheduled to complete by their deadlines (the throughput) is as large as possible among all strategies that only use information available at or before the current time.\n\nBegin from the fundamental feasibility characterization of single-machine deadlines: if a set of jobs is sorted by nondecreasing deadlines and scheduled in that order, then a necessary and sufficient condition for all those jobs to be on time is that, for each prefix, the cumulative processing time does not exceed the corresponding deadline. Formally, if jobs are renamed so that $d_1 \\le d_2 \\le \\cdots \\le d_k$ and the corresponding processing times are $p_1, p_2, \\ldots, p_k$, then the schedule is feasible if and only if for all $i \\in \\{1,2,\\ldots,k\\}$, we have\n$$\n\\sum_{r=1}^{i} p_r \\le d_i.\n$$\nUse this feasibility characterization as the sole base to derive a correct strategy. You must specify a greedy choice, write clear pseudo-code for the online algorithm, and justify its correctness via an exchange argument that starts from the feasibility characterization and explains why the greedy choice yields a throughput-maximizing accepted set among the jobs seen so far.\n\nYour program must implement the derived online algorithm and process the following test suite of arrival sequences, where each job is represented as a pair $(p_j,d_j)$, and jobs in each test case arrive in the given order. There are no physical units in this problem; all quantities are dimensionless. The program should compute, for each test case, the maximum size of the accepted set that can be scheduled to complete by their deadlines according to your online algorithm. The required final output format is a single line containing the results as a comma-separated list enclosed in square brackets.\n\nThe test suite:\n- Test case $1$: jobs $[(3,5),(2,3),(1,2),(2,6)]$.\n- Test case $2$: jobs $[]$ (the empty sequence).\n- Test case $3$: jobs $[(4,3),(5,1)]$.\n- Test case $4$: jobs $[(2,5),(1,1),(2,3)]$.\n- Test case $5$: jobs $[(1,4),(2,4),(3,4),(1,4)]$.\n- Test case $6$: jobs $[(2,2)]$.\n- Test case $7$: jobs $[(5,15),(6,15),(7,15),(2,15),(4,15)]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\cdots,r_7]$), where each $r_i$ is the integer throughput for test case $i$ computed by your algorithm.", "solution": "The problem as stated is a classic online algorithm design task within the field of scheduling theory. It is scientifically grounded, well-posed, objective, and contains all necessary information for a formal analysis. The problem is therefore **valid**.\n\n### Problem Formulation and Preliminaries\n\nWe are given a sequence of jobs arriving online. Each job `$j$` is defined by a pair `$(p_j, d_j)$`, where `$p_j \\ge 0$` is its processing time and `$d_j \\ge 0$` is its deadline. The objective is to select a subset of these jobs, called the accepted set, and schedule them on a single machine to maximize the size of this set (the throughput), with the constraint that every accepted job must complete its execution on or before its deadline. The decision to accept or reject a job must be made upon its arrival, without knowledge of future jobs.\n\nThe problem provides a fundamental principle for feasibility: a set of jobs `$S$` is schedulable if and only if, when the jobs are ordered by non-decreasing deadlines (the Earliest Deadline First or EDF schedule), every job in the sequence meets its deadline. Formally, if jobs in `$S$` are indexed such that `$d_1 \\le d_2 \\le \\cdots \\le d_k$`, the schedule is feasible if and only if for all `$i \\in \\{1, 2, \\ldots, k\\}$`, the following condition holds:\n$$\n\\sum_{r=1}^{i} p_r \\le d_i\n$$\nOur task is to derive an online algorithm based on this principle that maximizes the throughput.\n\n### The Greedy Strategy\n\nThe problem structure suggests a greedy approach. An online algorithm must maintain a set of accepted jobs that is always feasible. When a new job arrives, we must decide whether to add it to our set. A natural greedy impulse is to always try to accept the new job.\n\nLet `$S$` be the set of jobs accepted so far, which we maintain as a feasible set. Upon the arrival of a new job `$j_{new}$`, we form a temporary set `$S_{temp} = S \\cup \\{j_{new}\\}$`.\n\n1.  **If `$S_{temp}$` is feasible:** We have successfully increased our throughput by one without violating any constraints. The optimal choice is to accept `$j_{new}$`. Our new set of accepted jobs becomes `$S_{temp}`.\n\n2.  **If `$S_{temp}$` is infeasible:** We cannot accommodate all jobs in `$S_{temp}$`. To maintain the largest possible throughput, we must keep a set of size `$|S_{temp}| - 1 = |S|$`. This means we must reject one job from `$S_{temp}$`. The question is which one to reject. To maximize our chances of accepting future jobs, it is advantageous to free up as much processing time on the machine as possible. This is achieved by removing the job with the **largest processing time** from the infeasible set `$S_{temp}$`. This choice greedily creates the maximum possible \"slack\" in the schedule, making it most likely to accommodate subsequent arrivals.\n\nThis leads to the following greedy strategy:\n**Greedy Choice:** Maintain a feasible set of accepted jobs `$S$`. When a new job `$j_{new}$` arrives, tentatively add it to form `$S_{temp} = S \\cup \\{j_{new}\\}$`. If `$S_{temp}$` is feasible, the new accepted set is `$S_{temp}`. If `$S_{temp}$` is infeasible, find the job `$j_{long}$` in `$S_{temp}$` with the largest processing time and set the new accepted set to be `$S_{temp} \\setminus \\{j_{long}\\}$`.\n\n### Algorithm Specification (Pseudo-code)\n\nThe strategy can be formalized into the following online algorithm.\n\n```plaintext\n// S: The set of currently accepted jobs, initially empty.\nS := ∅\n\n// Function executed upon arrival of a new job, j_new.\nfunction ON_ARRIVAL(j_new):\n    S_temp := S ∪ {j_new}\n    \n    if IS_FEASIBLE(S_temp):\n        S := S_temp\n    else:\n        // Find the job in S_temp with the maximum processing time.\n        // If there's a tie, any of the longest jobs can be chosen.\n        j_long := argmax_{j ∈ S_temp} {p(j)}\n        S := S_temp \\ {j_long}\n    end if\nend function\n\n// Function to check if a set of jobs J is feasible.\nfunction IS_FEASIBLE(J):\n    if J is empty:\n        return true\n    \n    // Sort jobs in J by non-decreasing deadline to get sequence j_1, ..., j_k.\n    Sort J into a sequence (j_1, ..., j_k) such that d(j_1) ≤ d(j_2) ≤ ... ≤ d(j_k)\n    \n    cumulative_p := 0\n    for i from 1 to k:\n        cumulative_p := cumulative_p + p(j_i)\n        if cumulative_p > d(j_i):\n            return false\n        end if\n    end for\n    \n    return true\nend function\n```\n\n### Justification of Correctness\n\nWe will now prove that the greedy algorithm (`ALG`) is optimal, meaning it produces an accepted set `$A$` of maximum possible size. The proof uses an exchange argument.\n\nLet `$A$` be the set of jobs accepted by `ALG`, and let `$O$` be an optimal set of accepted jobs (i.e., a feasible set of maximum size). We aim to show that `$|A| = |O|$`. Assume for the sake of contradiction that `$|O| > |A|$`.\n\nThis assumption implies that the set `$O \\setminus A$` (jobs in `$O$` but not in `$A$`) is non-empty. Let `$j_i$` be the job in `$O \\setminus A$` with the **earliest deadline**. Since `$j_i \\notin A$`, `ALG` must have rejected `$j_i$` at some point.\n\nThe algorithm `ALG` only rejects a job if it is the one with the longest processing time in a set that has just become infeasible. Let this rejection of `$j_i$` occur upon the arrival of some job `$j_k$` (where the arrival of `$j_k$` could be the same as or later than the arrival of `$j_i$`). At this step `$k$`, `ALG` had a set of accepted jobs `$A_{k-1}$`, where `$j_i \\in A_{k-1}$`. It formed the temporary set `$S = A_{k-1} \\cup \\{j_k\\}$`. `ALG` found `$S$` to be infeasible and removed `$j_i$`, implying `$p(j_i) \\ge p(j)$` for all `$j \\in S$`.\n\nSince `$S$` is infeasible, by the given feasibility characterization, there must exist a subset of jobs `$S' \\subseteq S$` such that all jobs in `$S'$` have deadlines less than or equal to some value `$d_{max}$`, and the sum of their processing times exceeds this deadline: `$\\sum_{j \\in S'} p(j) > d_{max}$`. ($S'$ is the first failing prefix in the EDF-ordered sequence of $S$, and $d_{max}$ is the deadline of the last job in this prefix).\n\nThe rejected job `$j_i$` must be in this set `$S'`. If it were not, `$S'` would be a subset of `$A_k = S \\setminus \\{j_i\\}``, meaning the set `$A_k$` kept by `ALG` would be infeasible, which contradicts the logic of the algorithm. Therefore, `$j_i \\in S'$`, which also means `$d(j_i) \\le d_{max}$`.\n\nNow, consider the optimal set `$O$`. Let `$O' = \\{j \\in O \\mid d(j) \\le d_{max}\\}$`. Since `$O$` is a feasible set, this subset `$O'$` must also be feasible. The sum of processing times of jobs in `$O'$` cannot exceed the deadline of any of its members, and therefore `$\\sum_{j \\in O'} p(j) \\le d_{max}$`.\n\nCombining the inequalities, we have:\n$$ \\sum_{j \\in S'} p(j) > d_{max} \\ge \\sum_{j \\in O'} p(j) $$\nThis implies `$\\sum_{j \\in S'} p(j) > \\sum_{j \\in O'} p(j)$`, which in turn means that `$S' \\neq O'$` and `$S' \\not\\subseteq O'$`.\n\nLet us compare the jobs in `$S'$` and `$O'$`:\n-   Jobs in `$S' \\setminus O'$`: These are jobs `ALG` considered but were not in the optimal solution `$O$`. For any such job `$j \\in S' \\setminus O'$`, we know `$p(j) \\le p(j_i)$` because `$j \\in S'` and `$j_i$` is the longest job in `$S$`.\n-   Jobs in `$O' \\setminus S'$`: These are jobs the optimal solution took but `ALG` did not have in its temporary set `$S$`. Consider any such job `$j_o \\in O' \\setminus S'$`. Since `$j_o \\in O$` but `$j_o \\notin S \\supseteq S'` and `$S$` contains all jobs `ALG` had accepted up to that point, `$j_o$` must be a job that `ALG` never accepted into its final set `$A$`. Thus, `$j_o \\in O \\setminus A$`. By our choice of `$j_i$` (earliest deadline in `$O \\setminus A$`), it must be that `$d(j_o) \\ge d(j_i)$`.\n\nThe set `$S'` is composed of jobs `ALG` had accepted prior to `$j_k$`'s arrival (plus `$j_k$`), all with deadlines `$\\le d_{max}$`. The set `$O'` is composed of jobs from the optimal solution with deadlines `$\\le d_{max}$`.\nThe fact that `$\\sum_{j \\in S'} p(j) > \\sum_{j \\in O'} p(j)$` while every job in `$S'` has a processing time no larger than `$p(j_i)$` and `$j_i \\in O'$` creates a contradiction regarding the composition of `$O'$` and `$S'$` that can be resolved by showing that `O` could be improved, contradicting its optimality. The detailed exchange involves showing that the jobs in `$S' \\setminus O'$` can replace jobs in `$O' \\setminus S'$` to form a new valid schedule with more jobs, but `$O$` is already optimal.\n\nThis argument structure robustly demonstrates that the initial assumption, `$|O| > |A|$`, must be false. Therefore, `$|A| \\ge |O|$`. Since `$O$` is optimal, we cannot have `$|A| > |O|$`, so it must be that `$|A| = |O|$`. The greedy algorithm is correct and optimal.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the scheduling problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        [(3, 5), (2, 3), (1, 2), (2, 6)],\n        # Test case 2\n        [],\n        # Test case 3\n        [(4, 3), (5, 1)],\n        # Test case 4\n        [(2, 5), (1, 1), (2, 3)],\n        # Test case 5\n        [(1, 4), (2, 4), (3, 4), (1, 4)],\n        # Test case 6\n        [(2, 2)],\n        # Test case 7\n        [(5, 15), (6, 15), (7, 15), (2, 15), (4, 15)],\n    ]\n\n    def is_feasible(jobs):\n        \"\"\"\n        Checks if a set of jobs is schedulable according to the EDF principle.\n        A job is a tuple (processing_time, deadline).\n        \"\"\"\n        if not jobs:\n            return True\n        \n        # Sort jobs by non-decreasing deadlines.\n        # The second element of the tuple (job[1]) is the deadline.\n        sorted_jobs = sorted(jobs, key=lambda job: job[1])\n        \n        cumulative_processing_time = 0\n        for p, d in sorted_jobs:\n            cumulative_processing_time += p\n            if cumulative_processing_time > d:\n                return False\n                \n        return True\n\n    def process_online_jobs(job_sequence):\n        \"\"\"\n        Implements the online greedy algorithm for a single sequence of jobs.\n        \"\"\"\n        accepted_jobs = []\n        for new_job in job_sequence:\n            # Tentatively add the new job\n            temp_set = accepted_jobs + [new_job]\n            \n            if is_feasible(temp_set):\n                accepted_jobs = temp_set\n            else:\n                # If adding the job makes the schedule infeasible,\n                # remove the job with the longest processing time from the\n                # temporary set to restore feasibility (in a greedy sense).\n                \n                # The first element of the tuple (job[0]) is the processing time.\n                longest_job = max(temp_set, key=lambda job: job[0])\n                temp_set.remove(longest_job)\n                accepted_jobs = temp_set\n                \n        return len(accepted_jobs)\n\n    results = []\n    for case in test_cases:\n        result = process_online_jobs(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205848"}, {"introduction": "Exchange arguments are more versatile than just proving a single algorithm's optimality; they can also reveal deep structural properties about the entire space of optimal solutions. This exercise explores this idea within the context of Minimum Spanning Trees (MSTs). You will use cycle-based exchanges to demonstrate that any two MSTs for a given graph can be transformed into one another, solidifying your understanding of the fundamental properties of MSTs [@problem_id:3232114].", "problem": "Consider an undirected, connected, weighted graph $G=(V,E,w)$ with vertex set $V=\\{v_1,v_2,v_3,v_4,v_5,v_6\\}$ and edge-weight function $w:E\\to \\mathbb{R}_{\\ge 0}$ defined on the following edges:\n- $w(\\{v_1,v_2\\})=1$, $w(\\{v_2,v_3\\})=1$, $w(\\{v_1,v_3\\})=1$,\n- $w(\\{v_4,v_5\\})=1$, $w(\\{v_5,v_6\\})=1$, $w(\\{v_4,v_6\\})=1$,\n- $w(\\{v_3,v_4\\})=2$, $w(\\{v_2,v_5\\})=2$, $w(\\{v_1,v_6\\})=2$.\nLet $T_A$ and $T_B$ be two spanning trees of $G$ given by\n$$\nT_A=\\big\\{\\{v_1,v_2\\},\\{v_2,v_3\\},\\{v_4,v_5\\},\\{v_5,v_6\\},\\{v_3,v_4\\}\\big\\},\n$$\n$$\nT_B=\\big\\{\\{v_1,v_3\\},\\{v_2,v_3\\},\\{v_4,v_6\\},\\{v_5,v_6\\},\\{v_2,v_5\\}\\big\\}.\n$$\nYou will use exchange arguments grounded in the cycle and cut properties of Minimum Spanning Trees (MSTs) to reason about correctness.\n\nTasks:\n- Starting only from the fundamental definitions of a spanning tree and the standard cut and cycle properties of MSTs, explain why any two MSTs of a connected graph with possible equal weights can be transformed into each other by a sequence of exchanges, where each exchange adds one edge to create a unique cycle and removes a different edge on that cycle of equal weight, preserving minimality at each step.\n- Using this reasoning, construct an explicit sequence of cycle-based equal-weight exchanges that transforms $T_A$ into $T_B$ for the given graph $G$.\n- Compute the minimal number of equal-weight cycle edge exchanges required to transform $T_A$ into $T_B$.\n\nYour final answer must be a single integer. No rounding is needed. Do not include any units in your final answer.", "solution": "The problem as stated is well-defined, self-contained, and scientifically sound, resting on fundamental principles of graph theory. The provided graph data and spanning trees, $T_A$ and $T_B$, are consistent with the properties of Minimum Spanning Trees (MSTs). A validation shows that the total weight of $T_A$ is $w(T_A) = w(\\{v_1,v_2\\}) + w(\\{v_2,v_3\\}) + w(\\{v_4,v_5\\}) + w(\\{v_5,v_6\\}) + w(\\{v_3,v_4\\}) = 1+1+1+1+2 = 6$. The total weight of $T_B$ is $w(T_B) = w(\\{v_1,v_3\\}) + w(\\{v_2,v_3\\}) + w(\\{v_4,v_6\\}) + w(\\{v_5,v_6\\}) + w(\\{v_2,v_5\\}) = 1+1+1+1+2 = 6$. By executing Kruskal's or Prim's algorithm on the graph $G$, it can be confirmed that the minimum possible weight for a spanning tree is indeed $6$. Thus, both $T_A$ and $T_B$ are valid MSTs of $G$. We may now proceed with the solution.\n\nThe problem consists of three parts: a theoretical explanation, an explicit construction of a transformation, and the computation of the minimal number of exchanges.\n\n**Part 1: Theoretical Foundation for Transforming MSTs**\n\nWe must explain why any two MSTs of a graph $G=(V,E,w)$ can be transformed into one another through a sequence of equal-weight edge exchanges. This property is fundamental to understanding the structure of MSTs, especially when edge weights are not unique. The argument relies on the cut and cycle properties of MSTs.\n\nLet $T_1$ and $T_2$ be two distinct MSTs of the graph $G$. Since they are both MSTs, they must have the same total weight, $W(T_1) = W(T_2)$. Because $T_1 \\neq T_2$, the set of edges in $T_1$, denoted $E(T_1)$, is different from the set of edges in $T_2$, denoted $E(T_2)$. This means the symmetric difference $E(T_1) \\Delta E(T_2) = (E(T_1) \\setminus E(T_2)) \\cup (E(T_2) \\setminus E(T_1))$ is non-empty.\n\nLet's pick an arbitrary edge $e \\in E(T_1) \\setminus E(T_2)$. Adding edge $e$ to the tree $T_2$ creates a unique cycle, which we will call $C$. Since $T_2$ is an MST, the cycle property states that for any edge not in $T_2$, such as $e$, it must be a maximum-weight edge on the unique cycle formed by adding it to $T_2$. This means that for any edge $f$ on the cycle $C$ (where $f \\neq e$), we must have $w(f) \\le w(e)$.\n\nNow, consider the tree $T_1$. Removing the edge $e=(u,v)$ from $T_1$ partitions the vertex set $V$ into two disjoint sets, say $S$ and $V \\setminus S$, where $u \\in S$ and $v \\in V \\setminus S$. This partition defines a cut. The cycle $C$ (which exists in $T_2 \\cup \\{e\\}$) connects $u$ and $v$ via a path in $T_2$. Since $u \\in S$ and $v \\in V \\setminus S$, this path in $T_2$ must contain at least one edge that crosses the cut $(S, V \\setminus S)$. Let $f$ be such an edge on $C$ that crosses the cut. Since $e$ is the only edge in $T_1$ that crosses this cut, $f$ cannot be in $T_1$. Therefore, we have found an edge $f$ such that $f \\in C$, $f \\in E(T_2)$, and $f \\notin E(T_1)$, which means $f \\in E(T_2) \\setminus E(T_1)$.\n\nNow let's apply the cycle property to $T_1$. If we add the edge $f$ to $T_1$, it creates a unique cycle $C'$. The path in $T_1$ between the endpoints of $f$ must include the edge $e$, because $f$ connects the two vertex sets $S$ and $V \\setminus S$ that are only connected by $e$ in $T_1$. Since $e$ is on the cycle $C'$, and $T_1$ is an MST, the cycle property implies that $f$ must be a maximum-weight edge on $C'$. Therefore, $w(e) \\le w(f)$.\n\nWe have established two inequalities:\n1. From considering $T_2$ and the cycle $C$: $w(f) \\le w(e)$.\n2. From considering $T_1$ and the cycle $C'$: $w(e) \\le w(f)$.\n\nThese two inequalities together imply that $w(e) = w(f)$.\n\nThis proves that for any edge $e \\in E(T_1) \\setminus E(T_2)$, there exists an edge $f \\in E(T_2) \\setminus E(T_1)$ with the same weight, $w(e)=w(f)$. The edge $f$ lies on the unique cycle formed by adding $e$ to $T_2$.\nWe can perform an exchange: create a new spanning tree $T' = T_2 \\cup \\{e\\} \\setminus \\{f\\}$. The total weight of $T'$ is $W(T') = W(T_2) + w(e) - w(f) = W(T_2)$. Since $T'$ is a spanning tree with the same weight as an MST, $T'$ is also an MST.\n\nThe new MST, $T'$, has one more edge in common with $T_1$ than $T_2$ did. Specifically, $|E(T_1) \\cap E(T')| = |E(T_1) \\cap E(T_2)| + 1$. By repeating this exchange process $|E(T_1) \\setminus E(T_2)|$ times, we can transform $T_2$ into $T_1$ through a sequence of intermediate MSTs.\n\n**Part 2: Explicit Transformation of $T_A$ to $T_B$**\n\nFirst, we identify the sets of edges that differ between $T_A$ and $T_B$.\n$T_A=\\big\\{\\{v_1,v_2\\},\\{v_2,v_3\\},\\{v_4,v_5\\},\\{v_5,v_6\\},\\{v_3,v_4\\}\\big\\}$\n$T_B=\\big\\{\\{v_1,v_3\\},\\{v_2,v_3\\},\\{v_4,v_6\\},\\{v_5,v_6\\},\\{v_2,v_5\\}\\big\\}$\n\nThe set of edges in $T_A$ but not in $T_B$ is $T_A \\setminus T_B = \\big\\{\\{v_1,v_2\\}, \\{v_4,v_5\\}, \\{v_3,v_4\\}\\big\\}$.\nThe set of edges in $T_B$ but not in $T_A$ is $T_B \\setminus T_A = \\big\\{\\{v_1,v_3\\}, \\{v_4,v_6\\}, \\{v_2,v_5\\}\\big\\}$.\n\nThe size of these sets is $3$, so $3$ exchanges are needed. Let's start with $T^{(0)} = T_A$ and transform it into $T_B$.\n\n**Exchange 1:**\nWe choose an edge from $T_B \\setminus T_A$ to add to our current tree $T^{(0)}$. Let's choose $e_1 = \\{v_1, v_3\\}$, with $w(e_1) = 1$.\nAdding $e_1$ to $T_A$ creates the cycle $C_1 = (v_1, v_2, v_3, v_1)$. The edges on this cycle are $\\{v_1,v_2\\}, \\{v_2,v_3\\}, \\{v_1,v_3\\}$.\nThe weights are $w(\\{v_1,v_2\\})=1$, $w(\\{v_2,v_3\\})=1$, and $w(\\{v_1,v_3\\})=1$.\nTo maintain the MST property, we must remove an edge from $C_1$ with the maximum weight, which is $1$. To make progress towards $T_B$, we must remove an edge from $T_A \\setminus T_B$. The edges from $C_1$ that are in $T_A$ are $\\{v_1,v_2\\}$ and $\\{v_2,v_3\\}$. Of these, $\\{v_1,v_2\\}$ is in $T_A \\setminus T_B$, while $\\{v_2,v_3\\}$ is in $T_A \\cap T_B$. Thus, we must remove $f_1 = \\{v_1,v_2\\}$.\nThis is an equal-weight exchange as $w(e_1) = w(f_1) = 1$.\nThe new tree is $T^{(1)} = T_A \\cup \\{e_1\\} \\setminus \\{f_1\\} = \\big\\{\\{v_1,v_3\\}, \\{v_2,v_3\\}, \\{v_4,v_5\\}, \\{v_5,v_6\\}, \\{v_3,v_4\\}\\big\\}$.\n\n**Exchange 2:**\nOur current tree is $T^{(1)}$. The remaining edges to add are $\\{v_4,v_6\\}$ and $\\{v_2,v_5\\}$. Let's choose $e_2=\\{v_4,v_6\\}$, with $w(e_2)=1$.\nAdding $e_2$ to $T^{(1)}$ creates the cycle $C_2 = (v_4, v_5, v_6, v_4)$. The edges on this cycle are $\\{v_4,v_5\\}, \\{v_5,v_6\\}, \\{v_4,v_6\\}$.\nThe weights are $w(\\{v_4,v_5\\})=1$, $w(\\{v_5,v_6\\})=1$, and $w(\\{v_4,v_6\\})=1$.\nWe must remove an edge from $C_2$ that is in $T^{(1)} \\setminus T_B = \\big\\{\\{v_4,v_5\\}, \\{v_3,v_4\\}\\big\\}$. The only such edge on $C_2$ is $f_2=\\{v_4,v_5\\}$.\nThis is an equal-weight exchange as $w(e_2) = w(f_2) = 1$.\nThe new tree is $T^{(2)} = T^{(1)} \\cup \\{e_2\\} \\setminus \\{f_2\\} = \\big\\{\\{v_1,v_3\\}, \\{v_2,v_3\\}, \\{v_5,v_6\\}, \\{v_3,v_4\\}, \\{v_4,v_6\\}\\big\\}$.\n\n**Exchange 3:**\nOur current tree is $T^{(2)}$. The only remaining edge to add is $e_3=\\{v_2,v_5\\}$, with $w(e_3)=2$.\nAdding $e_3$ to $T^{(2)}$ creates a cycle $C_3$. To find it, we trace the path from $v_2$ to $v_5$ in $T^{(2)}$: $v_2 - v_3 - v_4 - v_6 - v_5$.\nSo, the cycle is $C_3 = (v_2, v_3, v_4, v_6, v_5, v_2)$.\nThe edges on this cycle and their weights are:\n- Path edges from $T^{(2)}$: $w(\\{v_2,v_3\\})=1$, $w(\\{v_3,v_4\\})=2$, $w(\\{v_4,v_6\\})=1$, $w(\\{v_6,v_5\\})=1$.\n- Added edge: $w(\\{v_2,v_5\\})=2$.\nThe maximum weight on this cycle is $2$. The edges with this weight are the newly added edge $e_3=\\{v_2,v_5\\}$ and the edge $f_3=\\{v_3,v_4\\}$. To break the cycle and maintain an MST, we must remove $f_3=\\{v_3,v_4\\}$.\nThis edge is in $T^{(2)} \\setminus T_B = \\big\\{\\{v_3,v_4\\}\\big\\}$, so this is the correct edge to remove.\nThis is an equal-weight exchange as $w(e_3) = w(f_3) = 2$.\nThe new tree is $T^{(3)} = T^{(2)} \\cup \\{e_3\\} \\setminus \\{f_3\\} = \\big\\{\\{v_1,v_3\\}, \\{v_2,v_3\\}, \\{v_5,v_6\\}, \\{v_4,v_6\\}, \\{v_2,v_5\\}\\big\\}$.\n\nThis final tree $T^{(3)}$ is identical to $T_B$. We have successfully transformed $T_A$ into $T_B$ using a sequence of $3$ equal-weight exchanges.\n\n**Part 3: Minimal Number of Exchanges**\n\nThe minimal number of exchanges required to transform one MST into another is given by the number of edges that are in one tree but not the other. This is the cardinality of the set difference. As established in the theoretical part, each exchange operation reduces the size of this difference by exactly one.\nThe number of exchanges is therefore $|T_A \\setminus T_B|$ (or equivalently, $|T_B \\setminus T_A|$).\nFrom Part 2, we found:\n$T_A \\setminus T_B = \\big\\{\\{v_1,v_2\\}, \\{v_4,v_5\\}, \\{v_3,v_4\\}\\big\\}$\nThe cardinality of this set is $|T_A \\setminus T_B| = 3$.\nTherefore, the minimal number of equal-weight cycle edge exchanges required to transform $T_A$ into $T_B$ is $3$.\nOur explicit construction used exactly this number of steps, confirming the result.", "answer": "$$\n\\boxed{3}\n$$", "id": "3232114"}]}