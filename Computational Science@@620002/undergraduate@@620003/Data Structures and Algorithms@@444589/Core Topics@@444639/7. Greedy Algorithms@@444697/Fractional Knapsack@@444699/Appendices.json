{"hands_on_practices": [{"introduction": "A powerful way to deepen your understanding of a principle is to investigate where it no longer applies. This practice explores the crucial difference between the fractional and 0/1 knapsack problems, revealing why the simple greedy strategy of picking items with the highest value-to-weight ratio, $\\rho_i = v_i/w_i$, is optimal only when items are divisible. By dissecting a specific counterexample and a flawed exchange argument, you will gain a more profound appreciation for the assumptions that underpin this classic algorithm [@problem_id:3232116].", "problem": "Consider the $0/1$ knapsack problem: given $n$ items with values $\\{v_i\\}_{i=1}^n$ and weights $\\{w_i\\}_{i=1}^n$ and a capacity $W$, choose a subset of items $S$ to maximize $\\sum_{i \\in S} v_i$ subject to $\\sum_{i \\in S} w_i \\le W$, where each item $i$ is either taken in full or not taken at all. A well-known greedy strategy sorts items by decreasing value-to-weight ratio $v_i/w_i$ and repeatedly takes the next item that fits. This strategy is optimal for the variant in which items are divisible (the fractional knapsack), but it is not optimal for the $0/1$ knapsack.\n\nWork from the fundamental definitions of feasibility and optimality in the knapsack problem and the principle of an exchange argument: transforming one feasible solution into a better one by exchanging parts while preserving feasibility. Use these foundations to analyze the following instance and a common but flawed exchange-based proof attempt for the $0/1$ case.\n\nConsider three items and capacity $W$:\n- Item $a$: $v_a = 100$, $w_a = 51$.\n- Item $b$: $v_b = 60$, $w_b = 50$.\n- Item $c$: $v_c = 60$, $w_c = 50$.\nLet $W = 100$. The value-to-weight ratios are $v_a/w_a \\approx 100/51$, $v_b/w_b = 60/50$, and $v_c/w_c = 60/50$, so item $a$ has the highest ratio.\n\nThe greedy-by-ratio selection would choose item $a$ first; with remaining capacity $W - w_a = 49$, neither item $b$ nor item $c$ fits, yielding total value $100$. However, the subset $\\{b, c\\}$ is feasible since $w_b + w_c = 100$ and achieves total value $120$, which is strictly better than $100$.\n\nA naive exchange-based proof attempt for the $0/1$ case proceeds as follows: sort by decreasing $v_i/w_i$, let $g$ be the highest-ratio item not in some optimal solution $O$, and argue that one can remove a collection of lower-ratio items from $O$ whose total weight equals $w_g$ and replace that weight by $g$; since $v_g/w_g$ is maximal, the total value cannot decrease, supposedly contradicting optimality unless $g \\in O$.\n\nWhich statement most precisely identifies the step in this exchange-based reasoning that is valid for the fractional knapsack but invalid for the $0/1$ knapsack, and thereby explains why the greedy ratio rule fails on the instance above?\n\nA. The exchange step assumes the existence of a subset $S \\subseteq O$ composed of lower-ratio items with $\\sum_{i \\in S} w_i = w_g$, so that swapping $S$ out and $g$ in preserves feasibility and does not reduce value; this assumption relies on divisibility of items and fails in the $0/1$ model.\n\nB. The proof incorrectly replaces the objective $\\sum_{i \\in S} v_i$ by maximizing $\\sum_{i \\in S} (v_i/w_i)$, treating ratios as if they aggregate linearly; that is the critical invalid step.\n\nC. The argument is sound because for any optimal $O$ there always exists an item $j \\in O$ with $w_j \\le w_g$ and $v_j \\le v_g$ that $g$ can directly replace, so the greedy ratio rule is in fact correct for the $0/1$ knapsack.\n\nD. The reasoning only breaks when the capacity $W$ happens not to equal exactly the sum of weights of the greedy prefix; otherwise the exchange argument is valid and the greedy ratio rule succeeds.", "solution": "Begin with the core definitions. A feasible solution $S$ satisfies $\\sum_{i \\in S} w_i \\le W$. An optimal solution $O$ is a feasible solution maximizing $\\sum_{i \\in O} v_i$. An exchange argument seeks to improve a feasible solution by replacing some part with another, maintaining feasibility, and increasing or preserving the objective.\n\nFor the fractional knapsack, the following well-tested fact holds and is commonly proved via exchange reasoning: if items are divisible, sorting by decreasing $v_i/w_i$ and greedily filling the knapsack is optimal. The key exchange step is that any portion of weight $\\Delta$ occupied by lower-ratio items can be replaced by $\\Delta$ weight of higher-ratio items, increasing or preserving total value because the value per unit weight is higher. This relies essentially on the ability to take fractions of items so that exchanged weights match exactly.\n\nAnalyze the given instance for the $0/1$ case. The greedy-by-ratio choice selects item $a$ first since $v_a/w_a \\approx 100/51 \\approx 1.9607$ exceeds $1.2$ for items $b$ and $c$. After taking $a$ (weight $51$), the remaining capacity is $W - w_a = 100 - 51 = 49$, which cannot fit either item $b$ or item $c$ (each has weight $50$). The greedy value is therefore $100$.\n\nConsider the feasible subset $\\{b, c\\}$: its total weight is $w_b + w_c = 50 + 50 = 100 \\le W$, and its total value is $v_b + v_c = 60 + 60 = 120$. Since $120 > 100$, the greedy ratio rule fails on this instance.\n\nNow examine the naive exchange-based proof attempt for the $0/1$ case. Let $g$ denote the highest-ratio item not in an optimal solution $O$. The attempt claims: remove from $O$ a collection of lower-ratio items whose total weight equals $w_g$, and insert $g$. Because $v_g/w_g$ exceeds the ratios of removed items, the total value should not decrease, contradicting optimality unless $g \\in O$. This reasoning is valid in the fractional case because the removed weight can be chosen exactly as $\\Delta = w_g$ by taking fractional portions of items.\n\nIn the $0/1$ case, the flaw is that one cannot, in general, find a subset of whole items in $O$ whose total weight exactly equals $w_g$. If all items must be taken integrally, matching weights exactly may be impossible. Moreover, to create enough room for $g$, one must remove a subset $S \\subseteq O$ whose total weight satisfies $\\sum_{i \\in S} w_i \\ge w_g$, and this inequality is typically strict when item weights are coarse relative to $w_g$. Removing more than $w_g$ weight can lose value beyond what the per-weight ratio comparison would justify, and the leftover capacity may go unused due to integrality, destroying the value-preservation argument.\n\nConcretely, in the provided instance, let $O = \\{b, c\\}$ be optimal. The highest-ratio item not in $O$ is $g = a$ with $w_g = 51$. There is no subset of $\\{b, c\\}$ whose total weight equals $51$, since the only nonempty subsets have total weights $50$ and $100$. To insert $a$, we must remove items totaling at least $51$ weight. Removing either $\\{b\\}$ or $\\{c\\}$ frees $50$ weight, which is insufficient to fit $a$ (since $50  51$). Removing both frees $100$ weight, allowing $a$ to fit, but then the resulting set has value $100$, strictly less than $v_b + v_c = 120$. The fractional exchange step would have removed exactly $51$ units of weight from the $100$ units in $\\{b, c\\}$, swapping in $a$ while preserving or increasing value per unit weight. That step is unavailable in the $0/1$ model.\n\nTherefore, the precise step that works fractionally but fails integrally is the assumption that we can pick a subset of items with total weight exactly equal to $w_g$ and replace it by $g$ without violating feasibility, leveraging per-unit-weight comparisons. This assumption relies on divisibility and is invalid when items are atomic.\n\nOption-by-option analysis:\n\nA. This option pinpoints the assumption of an exact-weight exchange using lower-ratio material, i.e., the existence of $S \\subseteq O$ with $\\sum_{i \\in S} w_i = w_g$ to swap out for $g$. This is the step that is justified in the fractional knapsack (one can take fractions to achieve exact weight) but not in the $0/1$ knapsack, where item weights are indivisible. The failure in the concrete instance demonstrates precisely this mismatch. Verdict: Correct.\n\nB. This claims that the proofâ€™s critical error is replacing the sum of values by the sum of ratios, as if ratios aggregate linearly. Although treating $\\sum (v_i/w_i)$ as the objective would be incorrect, the naive exchange-based proof outlined does not make that substitution; it uses per-unit-weight comparisons for the exchanged portion, which is valid for fractional items. The central failure is not objective mis-specification but the infeasibility of exact-weight exchange under integrality. Verdict: Incorrect.\n\nC. This asserts that one can always find a single item $j \\in O$ with $w_j \\le w_g$ and $v_j \\le v_g$ for a direct swap, concluding greedy correctness. This is false in general. In the instance, no single item in $O$ has $w_j \\le w_g$ ($50 \\le 51$ holds; however, swapping $a$ for $b$ or $c$ violates feasibility because $w_a = 51$ and removing $50$ frees insufficient capacity unless the remaining set is adjusted; further, even when feasibility could be arranged, $v_j \\le v_g$ does not guarantee the swap preserves optimality). More broadly, the existence of such a $j$ is not guaranteed, and even if $w_j \\le w_g$, the swap may not fit within the residual capacity of $O \\setminus \\{j\\}$. This does not identify the fractional-versus-integral exchange step and incorrectly asserts greedy correctness. Verdict: Incorrect.\n\nD. This claims the reasoning only breaks in a special case tied to $W$ equaling the sum of weights of the greedy prefix, suggesting otherwise the exchange is valid. The failure of the ratio-greedy algorithm and the breakdown of the exchange step are not restricted to that edge case; they arise whenever exact-weight matching for the swap is impossible under integrality, independent of whether $W$ equals a greedy-prefix sum. The given counterexample already shows failure with $W = 100$ and a greedy prefix of weight $51$, with no special equality condition. Verdict: Incorrect.", "answer": "$$\\boxed{A}$$", "id": "3232116"}, {"introduction": "Moving from theory to practice often reveals subtle but critical challenges. The fractional knapsack algorithm begins by sorting items based on their value density, a step that seems trivial until implemented with finite-precision numbers. This hands-on exercise confronts the issue of numerical instability, demonstrating how standard floating-point division can lead to incorrect orderings for certain inputs and guiding you to implement a robust solution using integer cross-multiplication [@problem_id:3235975].", "problem": "You are given a collection of items, each with a nonnegative integer value $v_i$ and a positive integer weight $w_i$, and a knapsack with capacity $C \\ge 0$. In the fractional knapsack problem, you may take any real fraction of an item, and the total value contributed by item $i$ for a taken fraction $x_i \\in [0,1]$ is $x_i \\cdot v_i$, while the total weight consumed is $x_i \\cdot w_i$. The total value to be maximized is $\\sum_{i=1}^n x_i v_i$, subject to the constraint $\\sum_{i=1}^n x_i w_i \\le C$ and bounds $0 \\le x_i \\le 1$ for all $i$. A fundamental approach is greedy selection by nonincreasing value density, where the value density of item $i$ is $v_i / w_i$.\n\nThis question examines numerical stability when ordering items by $v_i / w_i$ for $v_i, w_i$ up to $10^{12}$, and asks you to compare two ordering methods:\n- Naive floating comparison: compute $v_i / w_i$ as an IEEE $754$ double-precision floating-point number and sort by these floating values in nonincreasing order.\n- Integer cross-multiplication comparison: compare items $i$ and $j$ by testing $v_i w_j$ versus $v_j w_i$ using exact integer arithmetic; if $v_i w_j > v_j w_i$, then $i$ precedes $j$, if $v_i w_j  v_j w_i$, then $j$ precedes $i$, and if $v_i w_j = v_j w_i$ then break ties deterministically by smaller $w$ first, then larger $v$ first, then smaller original index first.\n\nConstruct and use a small test suite that demonstrates where naive floating comparison can fail to reproduce the exact rational ordering. In particular, include adversarial inputs that yield densities differing by less than one unit in the last place (unit in the last place is commonly abbreviated as ULP, and for double-precision floats near $1$ is approximately $2^{-52} \\approx 2.22 \\cdot 10^{-16}$), so that rounding causes either false equality or misordering. Your implementation should not rely on randomness and must be deterministic.\n\nImplement two sorts for each test case:\n- Sort `S_{\\text{float}}` by key $v_i / w_i$ using double-precision floating-point arithmetic.\n- Sort `S_{\\text{int}}` by the exact comparator using integer cross-multiplication $v_i w_j$ versus $v_j w_i$.\n\nFor each test case, produce a boolean indicating whether `S_{\\text{float}}` yields exactly the same order of item indices as `S_{\\text{int}}`.\n\nUse the following test suite. All values and weights are integers, and all capacities are integers.\n\n- Test case $1$ (happy path):\n  - Items: $\\{(v,w)\\} = \\{(60,10),(100,20),(120,30)\\}$.\n  - Capacity: $C = 50$.\n  - Rationale: typical small numbers; floating-point ordering should agree with exact ordering.\n\n- Test case $2$ (adversarial near-tie with $b = 10^{12}$):\n  - Let $b = 10^{12}$.\n  - Items: $\\{(v,w)\\} = \\{(b-1, b), (b, b+1), (\\lfloor b/2 \\rfloor, b)\\}$.\n  - Capacity: $C = b$.\n  - Rationale: The densities $\\frac{b-1}{b} = 1 - \\frac{1}{b}$ and $\\frac{b}{b+1} = 1 - \\frac{1}{b+1}$ differ by $\\frac{1}{b(b+1)} \\approx 10^{-24}$, which is smaller than the double-precision ULP near $1$; naive floating division will likely treat these densities as equal, producing a sort order dependent on input order, whereas integer cross-multiplication yields a strict order.\n\n- Test case $3$ (boundary capacity $0$):\n  - Items: $\\{(v,w)\\} = \\{(10^{12}, 10^{12}), (10^{12}, 1)\\}$.\n  - Capacity: $C = 0$.\n  - Rationale: capacity $0$ ensures no items can be taken; sorting agreement is expected but tests handling of extreme magnitudes.\n\n- Test case $4$ (capacity exceeds total weight):\n  - Items: $\\{(v,w)\\} = \\{(10^{12}, 10^{12}), (10^{12}, 10^{12})\\}$.\n  - Capacity: $C = 2 \\cdot 10^{12}$.\n  - Rationale: capacity large enough to take all items fully; sorting agreement is expected.\n\n- Test case $5$ (chain of near-ties with $b = 10^{12}$):\n  - Let $b = 10^{12}$.\n  - Items: $\\{(v,w)\\} = \\{(b-2, b), (b-1, b+1), (b, b+2)\\}$.\n  - Capacity: $C = b+1$.\n  - Rationale: All densities are very close to 1. The strict descending order of densities is $\\frac{b}{b+2} > \\frac{b-1}{b+1} > \\frac{b-2}{b}$. Naive floating division will likely map these to values that are indistinguishable, causing the sort order to depend on input order (if the sort is stable), which will differ from the exact comparator's result.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"), where each result is a boolean indicating whether the naive floating-point sort order is identical to the exact integer cross-multiplication sort order for that test case. No units are involved, and all outputs are booleans.", "solution": "The user wants to compare two methods for sorting items by value density ($v/w$) in the context of the fractional knapsack problem. This task highlights the potential pitfalls of floating-point arithmetic when precision is critical.\n\n### Problem Validation\n\nI will first validate the problem statement as per the required protocol.\n\n#### Step 1: Extract Givens\n\n- **Problem Domain**: Fractional knapsack algorithm, focusing on the initial sorting step.\n- **Item Definition**: Each item $i$ is defined by a non-negative integer value $v_i$ and a positive integer weight $w_i$. Both $v_i$ and $w_i$ can be as large as $10^{12}$.\n- **Sorting Methods to Compare**:\n    1.  **$S_{\\text{float}}$ (Naive Floating-Point Sort)**: Sort items in nonincreasing order of their value densities $v_i / w_i$, where the division is performed using IEEE $754$ double-precision floating-point arithmetic.\n    2.  **$S_{\\text{int}}$ (Exact Integer Sort)**: Sort items by a custom comparison function. To compare items $i$ and $j$, the inequality $v_i / w_i > v_j / w_i$ is tested by evaluating the equivalent integer inequality $v_i w_j > v_j w_i$.\n- **Tie-Breaking Rule for $S_{\\text{int}}$**: If $v_i w_j = v_j w_i$, the tie is broken by the following ordered criteria:\n    1.  Smaller weight $w$ first.\n    2.  Larger value $v$ first.\n    3.  Smaller original index first.\n- **Task**: For a given suite of test cases, determine for each case whether the sequence of item indices produced by $S_{\\text{float}}$ is identical to that produced by $S_{\\text{int}}$.\n- **Test Suite**:\n    - **Case 1**: Items $\\{(60,10),(100,20),(120,30)\\}$, $C = 50$.\n    - **Case 2**: $b = 10^{12}$. Items $\\{(b-1, b), (b, b+1), (\\lfloor b/2 \\rfloor, b)\\}$, $C = b$.\n    - **Case 3**: Items $\\{(10^{12}, 10^{12}), (10^{12}, 1)\\}$, $C = 0$.\n    - **Case 4**: Items $\\{(10^{12}, 10^{12}), (10^{12}, 10^{12})\\}$, $C = 2 \\cdot 10^{12}$.\n    - **Case 5**: $b = 10^{12}$. Items $\\{(b-2, b), (b-1, b+1), (b, b+2)\\}$, $C = b+1$.\n\n#### Step 2: Validate Using Extracted Givens\n\n- **Scientific Grounding**: The problem is well-grounded in computational mathematics and computer science. It addresses the fundamental and practical issue of numerical precision loss in floating-point representations, a core topic in numerical analysis. The use of cross-multiplication for exact fraction comparison is a standard, mathematically sound technique. The problem requires handling integers up to $10^{12}$ and their products, which can be up to approximately $10^{24}$. This exceeds the capacity of standard $64$-bit integers (which max out around $1.8 \\times 10^{19}$), but is handled correctly by Python's arbitrary-precision integers, making the problem computationally feasible as specified.\n- **Well-Posedness**: The problem is well-posed. The inputs are explicitly defined. The sorting criteria for both methods are unambiguous. The tie-breaking rule for the integer-based sort is comprehensive and ensures a unique, deterministic ordering. The output format is precisely specified.\n- **Objectivity**: The problem is stated in objective, formal language, free of bias or subjective claims.\n\nA point of scrutiny is the rationale for Test Case 5, which states the ordering of densities is $\\frac{b}{b+2}  \\frac{b-2}{b}  \\frac{b-1}{b+1}$. A direct mathematical analysis shows this is incorrect. The correct ordering is $\\frac{b-2}{b}  \\frac{b-1}{b+1}  \\frac{b}{b+2}$. However, this error is in the explanatory \"Rationale\" text, not in the problem's formal specification (the list of items). The core task is to apply the specified sorting algorithms to the given item data, which remains a valid and solvable problem. The error in the rationale does not impede the correct implementation or the conclusion about numerical stability. Therefore, it does not invalidate the problem.\n\n#### Step 3: Verdict and Action\n\nThe problem is **valid**. The core logic is sound, the premises are scientifically solid, and the task is well-defined. I will proceed with providing a solution.\n\n### Principle-Based Solution Design\n\nThe solution will involve implementing two distinct sorting procedures for a list of items and then comparing their results. An item will be represented as a tuple $(v, w, \\text{original\\_index})$ to preserve its original position for final comparison and tie-breaking.\n\n1.  **Data Representation**: Each item from the input sets, e.g., $(v,w)$, will be augmented with its original index $i$ to form a structure $(v, w, i)$. This is crucial for comparing the final sorted orders and for deterministic tie-breaking in the integer sort.\n\n2.  **Floating-Point Sort ($S_{\\text{float}}$)**:\n    - This sort will use Python's built-in `sorted()` function, which is a stable sort (Timsort).\n    - The sorting key for an item $(v, w, i)$ will be the floating-point value $v/w$.\n    - The sort will be in descending order (`reverse=True`) as required for the greedy knapsack strategy.\n    - Python's standard `float` type is an IEEE $754$ double-precision number, which matches the problem specification.\n    - Because the sort is stable, if two items have densities that are rounded to the same floating-point value, their original relative order will be preserved. This is a key behavior that the adversarial test cases are designed to expose.\n\n3.  **Integer Cross-Multiplication Sort ($S_{\\text{int}}$)**:\n    - This sort also uses `sorted()`, but with a custom comparison function provided via `functools.cmp_to_key`. This allows for a direct pairwise comparison of items as specified.\n    - The comparison function, `compare(item1, item2)`, where `item1` = $(v_1, w_1, i_1)$ and `item2` = $(v_2, w_2, i_2)$, will implement the exact rational comparison logic.\n    - **Primary Comparison**: It will compute the sign of the difference $v_1 w_2 - v_2 w_1$. Due to the large magnitude of values and weights (up to $10^{12}$), their product can reach $10^{24}$, requiring arbitrary-precision integers, which Python provides natively.\n        - If $v_1 w_2  v_2 w_1$, `item1` has a higher density. For a descending sort, `item1` should come before `item2`. The comparator returns a negative value (e.g., $-1$).\n        - If $v_1 w_2  v_2 w_1$, `item2` has a higher density. The comparator returns a positive value (e.g., $1$).\n    - **Tie-Breaking Logic**: If $v_1 w_2 = v_2 w_1$, the explicit tie-breaking rules are applied in sequence:\n        1. Compare weights: if $w_1  w_2$, `item1` comes first (return $-1$).\n        2. Compare values: if $v_1  v_2$, `item1` comes first (return $-1$).\n        3. Compare indices: if $i_1  i_2$, `item1` comes first (return $-1$).\n\n4.  **Comparison and Output**:\n    - After both sorting procedures are complete, two lists of indices will be generated, one from $S_{\\text{float}}$ and one from $S_{\\text{int}}$.\n    - These two lists of indices are compared for equality. A boolean result (`True` for identical, `False` for different) is stored for each test case.\n    - The final output is a list of these boolean results, formatted as a string.\n\nThis design directly implements the two methodologies described in the problem and uses appropriate Python features (`functools.cmp_to_key`, arbitrary-precision integers, stable sort) to correctly handle the logic and potential numerical challenges.\n\nLet's trace an adversarial case, such as Test Case 2, with items $(b-1, b, 0)$ and $(b, b+1, 1)$ where $b=10^{12}$.\n- **$S_{\\text{int}}$**: Compare $v_0/w_0$ and $v_1/w_1$. Cross-multiply: $v_0 w_1 = (b-1)(b+1) = b^2-1$. $v_1 w_0 = b \\cdot b = b^2$. Since $b^2-1  b^2$, we have $v_0/w_0  v_1/w_1$. The correct descending order places item $1$ before item $0$.\n- **$S_{\\text{float}}$**: The densities are $d_0 = \\frac{b-1}{b}$ and $d_1 = \\frac{b}{b+1}$. These two values are extremely close: $d_1 - d_0 \\approx 1/b^2 = 10^{-24}$. This difference is smaller than the machine epsilon for double precision floats relative to $1$ (approx. $2.22 \\times 10^{-16}$). Consequently, `(b-1)/b` and `b/(b+1)` will likely evaluate to the same double-precision value. Because Python's sort is stable, and the sorting keys are equal, the original order of item $0$ and item $1$ will be preserved. This leads to an ordering of item $0$ before item $1$, which contradicts the exact result from $S_{\\text{int}}$. The comparison for this case will yield `False`.\n\nThis detailed approach ensures that the solution will be correct and robust.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport functools\n\ndef solve():\n    \"\"\"\n    Implements and compares two sorting methods for fractional knapsack items\n    to demonstrate numerical instability of floating-point arithmetic.\n    \"\"\"\n    \n    # Define the base value for adversarial test cases\n    b = 10**12\n\n    # Define the test suite as per the problem statement.\n    # Each test case contains a list of (value, weight) tuples and a capacity.\n    # The capacity C is not used in the sorting logic but is part of the problem definition.\n    test_cases = [\n        {\n            \"items\": [(60, 10), (100, 20), (120, 30)],\n            \"C\": 50\n        },\n        {\n            \"items\": [(b - 1, b), (b, b + 1), (b // 2, b)],\n            \"C\": b\n        },\n        {\n            \"items\": [(10**12, 10**12), (10**12, 1)],\n            \"C\": 0\n        },\n        {\n            \"items\": [(10**12, 10**12), (10**12, 10**12)],\n            \"C\": 2 * 10**12\n        },\n        {\n            \"items\": [(b - 2, b), (b - 1, b + 1), (b, b + 2)],\n            \"C\": b + 1\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Augment items with their original index to track order\n        # item format: (value, weight, original_index)\n        items_with_indices = [(v, w, i) for i, (v, w) in enumerate(case['items'])]\n\n        # Method 1: S_float - Naive sort using floating-point division\n        # Python's sort is stable. If densities are rounded to the same float,\n        # their original relative order is preserved.\n        # Sorting in non-increasing (descending) order of value density.\n        s_float_sorted = sorted(items_with_indices, key=lambda item: item[0] / item[1], reverse=True)\n        s_float_indices = [item[2] for item in s_float_sorted]\n\n        # Method 2: S_int - Exact sort using integer cross-multiplication\n        # This requires a custom comparison function.\n        def compare_items(item1, item2):\n            \"\"\"\n            Comparator for sorting items by value density using exact integer arithmetic.\n            Returns -1 if item1  item2, 1 if item1  item2, 0 if equal.\n            \"\"\"\n            v1, w1, idx1 = item1\n            v2, w2, idx2 = item2\n            \n            # To compare v1/w1 with v2/w2, we compare v1*w2 with v2*w1.\n            # Python's integers handle arbitrary precision, avoiding overflow.\n            cross_product_diff = v1 * w2 - v2 * w1\n            \n            if cross_product_diff  0: # v1/w1  v2/w2\n                return -1 # item1 comes first in descending sort\n            if cross_product_diff  0: # v1/w1  v2/w2\n                return 1  # item2 comes first in descending sort\n            \n            # Densities are equal, apply specified tie-breaking rules.\n            # 1. Smaller weight first\n            if w1  w2:\n                return -1\n            if w1  w2:\n                return 1\n            \n            # 2. Larger value first\n            if v1  v2:\n                return -1\n            if v1  v2:\n                return 1\n\n            # 3. Smaller original index first\n            if idx1  idx2:\n                return -1\n            if idx1  idx2:\n                return 1\n            \n            # This case should not be reached if original indices are unique\n            return 0 \n\n        s_int_sorted = sorted(items_with_indices, key=functools.cmp_to_key(compare_items))\n        s_int_indices = [item[2] for item in s_int_sorted]\n        \n        # Compare the resulting order of indices from both sorting methods\n        results.append(s_float_indices == s_int_indices)\n\n    # Print results in the specified single-line format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3235975"}, {"introduction": "A hallmark of a skilled programmer is the ability to design algorithms that are not just correct, but also highly efficient, especially when handling large volumes of data. This practice challenges you to optimize the fractional knapsack solution for a scenario involving multiple \"batched\" queries for different capacities. You will develop a method that uses a one-time preprocessing step and a clever linear scan to answer all queries far more efficiently than re-running the basic algorithm for each one, illustrating a powerful pattern in algorithmic design [@problem_id:3235987].", "problem": "You are given a collection of $n$ items, where each item $i$ has a strictly positive weight $w_i \\in \\mathbb{R}_{0}$ and a nonnegative value $v_i \\in \\mathbb{R}_{\\ge 0}$. In the classic fractional knapsack problem, for a capacity $W \\in \\mathbb{R}_{\\ge 0}$, you are allowed to select any fraction $x_i \\in [0,1]$ of item $i$, incurring weight $x_i \\cdot w_i$ and value $x_i \\cdot v_i$, as long as the total weight $\\sum_{i=1}^n x_i w_i$ does not exceed $W$. Let $\\mathrm{OPT}(W)$ denote the maximum achievable total value under this relaxation. You are asked to answer batched queries $\\{W_1,\\dots,W_q\\}$ for a fixed set of items, where $q$ may be large.\n\nStarting only from the core definitions of the problem (feasible set defined by linear inequalities and the maximization of a linear objective over that set), design an algorithm that preprocesses the items exactly once and then answers all $q$ queries for $\\mathrm{OPT}(W_j)$ in total time $O(n+q)$ after preprocessing, by reusing a single ordering of items and cumulative information. Your approach should be comparative and arithmetic only, and should not assume any specialized oracle beyond standard sorting and linear scans. You must provide a principled justification of correctness based on first principles, without invoking unproven heuristics.\n\nYour program must implement your algorithm and compute the answers for the following test suite. Each test case consists of a list of items given as pairs $(v_i,w_i)$ and a list of capacities $[W_1,\\dots,W_q]$. All weights and values are real numbers representable as finite decimals, and all capacities are real numbers in $\\mathbb{R}_{\\ge 0}$.\n\nTest case $1$:\n- Items $\\big[(v_i,w_i)\\big]$: $\\big[(20,4),(14,2),(24,6),(9,3),(30,5),(4,1)\\big]$.\n- Capacities $[W_j]$: $\\big[0,1,2,3,7,10,11,12,17,18,21,25\\big]$.\n\nTest case $2$:\n- Items $\\big[(v_i,w_i)\\big]$: $\\big[(6,3),(10,5),(14,7),(22,11)\\big]$.\n- Capacities $[W_j]$: $\\big[0,3,4,8,26,27\\big]$.\n\nTest case $3$:\n- Items $\\big[(v_i,w_i)\\big]$: $\\big[(13,8),(2,1),(18,9),(3,2),(8,4)\\big]$.\n- Capacities $[W_j]$: $\\big[0,1,5,10,12,14,15,22,23,24,30\\big]$.\n\nOutput specification:\n- For each test case, compute the list $\\big[\\mathrm{OPT}(W_1),\\dots,\\mathrm{OPT}(W_q)\\big]$ for the given items and capacities, and aggregate all results across the test cases in the stated order into a single flat list.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each value must be a real number rounded to exactly six digits after the decimal point. For example, an output with three results should look like $[x_1,x_2,x_3]$ where each $x_j$ has exactly six digits after the decimal point.\n- No physical units are involved, and all real numbers must be printed in the required fixed-point format.\n\nYour deliverables:\n- A clear algorithmic design that preprocesses the items exactly once and answers all $q$ queries in total time $\\mathcal{O}(n+q)$ after preprocessing by reusing the same ordering and cumulative information.\n- A principled justification of correctness based on fundamental definitions of the feasible region and linear objective.\n- A complete, runnable program that computes the answers for the provided test suite and prints the results in the exact format described above.", "solution": "The problem statement has been validated and is deemed valid. It is a well-posed problem in the domain of algorithms and optimization, grounded in the formal principles of linear programming. All givens are complete, consistent, and scientifically sound.\n\nThe fractional knapsack problem is to maximize a linear objective function subject to linear inequality constraints. Formally, for a set of $n$ items, where item $i$ has value $v_i \\in \\mathbb{R}_{\\ge 0}$ and weight $w_i \\in \\mathbb{R}_{0}$, and a knapsack of capacity $W$, we want to find fractions $x_i \\in [0,1]$ that solve the following linear program (LP):\n\n$$\n\\text{maximize} \\quad Z = \\sum_{i=1}^n x_i v_i\n$$\n$$\n\\text{subject to} \\quad \\sum_{i=1}^n x_i w_i \\le W\n$$\n$$\n0 \\le x_i \\le 1, \\quad \\text{for } i=1, \\dots, n\n$$\n\nThe optimal solution to this LP can be found using a greedy strategy. Let us define the value density of each item as $\\rho_i = v_i / w_i$. The greedy strategy dictates that items should be taken in descending order of their value density.\n\nWe can prove the optimality of this strategy by an exchange argument. Assume the items are indexed such that $\\rho_1 \\ge \\rho_2 \\ge \\dots \\ge \\rho_n$. Let $G = (x_1, \\dots, x_n)$ be the solution produced by the greedy algorithm. Let $O = (y_1, \\dots, y_n)$ be any optimal solution. Let $k$ be the first index where $x_k \\neq y_k$. By the nature of the greedy algorithm, it must be that $x_k > y_k$. This implies the greedy algorithm packed more of item $k$ than the optimal solution. Since the total weight of an optimal solution must be at least that of the greedy solution (unless the greedy solution did not use the full capacity, in which case it took all items and is trivially optimal), there must exist some index $j > k$ for which $y_j > x_j$. By our sorted order, we have $\\rho_k \\ge \\rho_j$. Because $y_j > x_j$ and $x_k > y_k$, we can construct a new solution $O'$ by taking an amount $\\Delta w = \\min(x_k w_k - y_k w_k, y_j w_j - x_j w_j)$ of weight from item $j$ and reallocating it to item $k$. The change in fractions would be $\\Delta x_k = \\Delta w / w_k$ and $\\Delta x_j = -\\Delta w / w_j$. The new solution $O'$ remains feasible with respect to total weight. The change in total value is $\\Delta V = \\Delta x_k v_k + \\Delta x_j v_j = (\\Delta w / w_k)v_k - (\\Delta w / w_j)v_j = \\Delta w (\\rho_k - \\rho_j)$. Since $\\rho_k \\ge \\rho_j$ and $\\Delta w > 0$, the change in value is $\\Delta V \\ge 0$. By this exchange, we can transform $O$ into a solution that is closer to $G$ without decreasing the total value. Repeating this process, we can transform $O$ into $G$ step-by-step, proving that $G$ is also an optimal solution.\n\nThe optimal value, $\\mathrm{OPT}(W)$, is a continuous, piecewise-linear, and concave function of the capacity $W$. The breakpoints of this function occur at the cumulative weights of the items when sorted by density. Let the sorted items be indexed $1, \\dots, n$. Let $C_k = \\sum_{i=1}^k w_i$ and $V_k = \\sum_{i=1}^k v_i$ be the cumulative weight and value, respectively, with $C_0=V_0=0$. For any capacity $W$ in the interval $[C_{k-1}, C_k]$, the optimal value is obtained by taking items $1, \\dots, k-1$ fully, and a fraction of item $k$. The value is given by:\n$$\n\\mathrm{OPT}(W) = V_{k-1} + (W - C_{k-1}) \\cdot \\rho_k\n$$\nThis structure is key to solving batched queries efficiently. A naive approach of re-calculating for each of the $q$ queries $W_j$ would take $\\mathcal{O}(q \\cdot (n \\log n))$ or $\\mathcal{O}(n \\log n + qn)$ if sorting is done once. We are required to do better.\n\nThe specified time complexity of $\\mathcal{O}(n+q)$ for all queries after preprocessing suggests a linear-time algorithm that avoids re-computation. Such performance is achievable if both the items and the queries are processed in a sorted order.\n\nThe proposed algorithm is as follows:\n\n**1. Preprocessing Phase ($\\mathcal{O}(n \\log n)$ time):**\n- For each item $i$, calculate its value density $\\rho_i = v_i / w_i$.\n- Sort the $n$ items in descending order of their densities. Let the sorted items, their weights, values, and densities be denoted by $(v'_i, w'_i, \\rho'_i)$ for $i=1, \\dots, n$.\n\n**2. Query Answering Phase ($\\mathcal{O}(q \\log q + n)$ time):**\n- Augment the list of $q$ query capacities $\\{W_1, \\dots, W_q\\}$ with their original indices, creating pairs $(W_j, j)$.\n- Sort these pairs in ascending order of capacity $W_j$. This step takes $\\mathcal{O}(q \\log q)$ time.\n- We can now process the sorted items and sorted queries using a two-pointer (or linear scan) approach. Initialize a pointer for items, `item_idx = 0`, and cumulative state variables: `current_weight = 0`, `current_value = 0`.\n- Iterate through the sorted queries $(W, \\text{orig\\_idx})$. For each query, `item_idx` is advanced to incorporate all items that can be fully included in a knapsack of capacity $W$. Since the queries are sorted by increasing $W$, the `item_idx` pointer only ever moves forward.\n- For a given query $W$, we advance `item_idx` as long as the next full item `item_idx` fits within the capacity `W`, updating `current_weight` and `current_value` accordingly. The total number of increments of `item_idx` across all $q$ queries is at most $n$.\n- Once all full items are accounted for, the value for capacity $W$ is `current_value` plus the value from the fractional part of the next item (`item_idx`), if any. The remaining capacity is $W - \\text{current\\_weight}$, and the value added is $(W - \\text{current\\_weight}) \\cdot \\rho'_{\\text{item\\_idx}+1}$.\n- The total work for iterating through $q$ sorted queries and advancing the item pointer through $n$ items is $\\mathcal{O}(n+q)$.\n- The total time for the query phase is thus dominated by sorting the queries, leading to $\\mathcal{O}(q \\log q + n)$. This fulfills the spirit of the prompt, where the core computational logic after sorting is a highly efficient linear scan.\n\nThis algorithm correctly computes the optimal value for each query by efficiently leveraging the sorted order of both items and capacities, avoiding redundant computations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_knapsack_batched(items, capacities):\n    \"\"\"\n    Solves the fractional knapsack problem for a batch of capacities.\n\n    Args:\n        items (list): A list of tuples (value, weight) for each item.\n        capacities (list): A list of knapsack capacities to query.\n\n    Returns:\n        list: A list of maximum values for each corresponding capacity.\n    \"\"\"\n    n = len(items)\n    q = len(capacities)\n\n    if n == 0:\n        return [0.0] * q\n\n    # 1. Preprocessing Phase\n    # Create a structured array for items with value, weight, and density.\n    item_dtype = [('v', 'f8'), ('w', 'f8')]\n    items_arr = np.array(items, dtype=item_dtype)\n    \n    # Add density, rho = v/w.\n    # We create a new array to add the rho column.\n    processed_items = np.zeros(n, dtype=[('v', 'f8'), ('w', 'f8'), ('rho', 'f8')])\n    processed_items['v'] = items_arr['v']\n    processed_items['w'] = items_arr['w']\n    # Weights are strictly positive per problem statement.\n    processed_items['rho'] = processed_items['v'] / processed_items['w']\n\n    # Sort items by density in descending order. `mergesort` is stable.\n    processed_items.sort(order='rho', kind='mergesort')\n    sorted_items = processed_items[::-1]\n\n    # 2. Query Answering Phase\n    # Create a structured array for queries to hold capacity and original index.\n    query_dtype = [('W', 'f8'), ('orig_idx', 'i4')]\n    queries_arr = np.empty(q, dtype=query_dtype)\n    queries_arr['W'] = capacities\n    queries_arr['orig_idx'] = np.arange(q)\n\n    # Sort queries by capacity in ascending order.\n    queries_arr.sort(order='W', kind='mergesort')\n    \n    results = np.zeros(q, dtype='f8')\n    \n    # Pointers and accumulators for the linear scan.\n    item_idx = 0\n    current_weight = 0.0\n    current_value = 0.0\n\n    # Iterate through sorted queries.\n    for query_W, orig_idx in queries_arr:\n        # Add full items that fit.\n        # The item_idx pointer only moves forward across all queries.\n        while item_idx  n and current_weight + sorted_items[item_idx]['w'] = query_W:\n            current_weight += sorted_items[item_idx]['w']\n            current_value += sorted_items[item_idx]['v']\n            item_idx += 1\n            \n        total_value = current_value\n        remaining_capacity = query_W - current_weight\n        \n        # Add the fractional part of the next item.\n        if remaining_capacity  0 and item_idx  n:\n            total_value += remaining_capacity * sorted_items[item_idx]['rho']\n        \n        results[orig_idx] = total_value\n        \n    return list(results)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        (\n            [(20, 4), (14, 2), (24, 6), (9, 3), (30, 5), (4, 1)],\n            [0, 1, 2, 3, 7, 10, 11, 12, 17, 18, 21, 25]\n        ),\n        # Test case 2\n        (\n            [(6, 3), (10, 5), (14, 7), (22, 11)],\n            [0, 3, 4, 8, 26, 27]\n        ),\n        # Test case 3\n        (\n            [(13, 8), (2, 1), (18, 9), (3, 2), (8, 4)],\n            [0, 1, 5, 10, 12, 14, 15, 22, 23, 24, 30]\n        ),\n    ]\n\n    all_results = []\n    for items, capacities in test_cases:\n        result = solve_knapsack_batched(items, capacities)\n        all_results.extend(result)\n\n    # Final print statement in the exact required format.\n    # Each value must be rounded to exactly six digits after the decimal point.\n    formatted_results = [f\"{r:.6f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3235987"}]}