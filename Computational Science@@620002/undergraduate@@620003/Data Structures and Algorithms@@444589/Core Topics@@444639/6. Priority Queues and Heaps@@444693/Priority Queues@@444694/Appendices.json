{"hands_on_practices": [{"introduction": "Priority queues are the engine behind many efficient graph algorithms. This first practice challenges you to implement Dijkstra's algorithm for finding the shortest paths in a graph, using a clever \"lazy\" approach that works with even the simplest priority queue implementations. By allowing duplicate, outdated entries in the queue, you will see how to avoid the need for a complex `decrease-key` operation while still achieving the correct result. [@problem_id:3227995]", "problem": "You are given a directed graph with nonnegative edge weights. Let the graph be denoted by $G = (V, E)$ with a weight function $w : E \\to \\mathbb{R}_{\\ge 0}$. For a vertex $s \\in V$, the single-source shortest-path distance to a vertex $v \\in V$ is defined as the minimum, over all directed paths from $s$ to $v$, of the sum of the weights of the edges on the path. If there is no path from $s$ to $v$, the distance is considered undefined.\n\nYour task is to write a complete program that computes the single-source shortest-path distances from a given source $s$ using a design that relies only on the core definitions of path length and nonnegativity of weights. Your program must implement the following algorithmic constraint: use a min-priority queue (Priority Queue (PQ)) that permits duplicate entries and does not provide or simulate a decrease-key operation. That is, when a shorter tentative distance to a vertex is discovered, instead of modifying an existing PQ entry, push a new entry into the PQ and allow stale entries to be removed lazily when they are popped.\n\nFormally, the program must:\n- Accept a graph described by its vertex count $n$ and a set of directed edges $\\{(u, v, w)\\}$ where $u, v \\in \\{0, 1, \\dots, n-1\\}$ and $w \\in \\mathbb{Z}_{\\ge 0}$.\n- Compute the shortest-path distance from the source $s$ to every vertex $v \\in \\{0, 1, \\dots, n-1\\}$ using only PQ push and pop operations, allowing duplicate keys and without any operation that decreases a key inside the PQ.\n- Output, for each test case, a list of $n$ integers where the $i$-th entry is the shortest-path distance from $s$ to $i$, with unreachable vertices encoded as $-1$.\n\nThe foundational base you must rely on is restricted to the following facts:\n- A path from a vertex $x$ to a vertex $y$ is a sequence of edges whose concatenation is valid in $G$, and the length of a path is the sum of its edge weights.\n- All edge weights satisfy $w(e) \\ge 0$ for every $e \\in E$.\n- For any vertices $x, y, z \\in V$, if a path from $x$ to $y$ has length $\\ell(x, y)$ and a path from $y$ to $z$ has length $\\ell(y, z)$, then the concatenated path from $x$ to $z$ has length $\\ell(x, y) + \\ell(y, z)$.\n- If a vertex is extracted from the PQ with a value strictly larger than its current best-known distance, that PQ entry must be stale and must be ignored.\n\nTest suite. Your program must solve the following seven test cases. For each, the graph is specified by an integer $n$, a source $s$, and a set of directed edges written as triples $(u, v, w)$:\n\n- Test case $1$: $n = 5$, $s = 0$, edges $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$.\n- Test case $2$: $n = 3$, $s = 0$, edges $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$.\n- Test case $3$: $n = 4$, $s = 0$, edges $\\{(0, 1, 7)\\}$.\n- Test case $4$: $n = 1$, $s = 0$, edges $\\{\\}$.\n- Test case $5$: $n = 3$, $s = 0$, edges $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$.\n- Test case $6$: $n = 6$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$.\n- Test case $7$: $n = 4$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$.\n\nAll edge weights in the test suite are integers and satisfy nonnegativity.\n\nFinal output format. Your program should produce a single line of output containing all results aggregated as a single list, where each element is the distance list for one test case, in the order listed above. The aggregation must be printed as a single comma-separated list enclosed in square brackets and without spaces. For example, if there were two test cases with per-case results $[0, 1]$ and $[0, 2]$, the final output would be $[[0,1],[0,2]]$. In your program’s final output, use $-1$ to denote unreachable vertices. No physical units are involved in this problem; all quantities are pure numbers.", "solution": "The user has provided a problem statement that requires the computation of single-source shortest paths in a directed graph with non-negative edge weights. The core constraint is the implementation of an algorithm, equivalent to Dijkstra's, using a min-priority queue that does not support a `decrease-key` operation, thereby necessitating the handling of stale entries.\n\n### Step 1: Extract Givens\n\n-   **Graph**: A directed graph $G = (V, E)$, where $V = \\{0, 1, \\dots, n-1\\}$.\n-   **Edge Weights**: A function $w : E \\to \\mathbb{R}_{\\ge 0}$ assigns a non-negative weight to each edge. For the test cases, $w(e) \\in \\mathbb{Z}_{\\ge 0}$.\n-   **Source Vertex**: A specified vertex $s \\in V$.\n-   **Shortest-Path Distance**: The minimum sum of weights over all directed paths from $s$ to any vertex $v \\in V$. Unreachable vertices have an undefined distance.\n-   **Algorithmic Constraint 1**: The implementation must use a min-priority queue (PQ) that only supports `push` and `pop` operations.\n-   **Algorithmic Constraint 2**: A `decrease-key` operation is forbidden. If a shorter path to a vertex is found, a new entry `(distance, vertex)` must be pushed into the PQ, allowing for duplicate vertex entries.\n-   **Algorithmic Constraint 3**: Stale entries must be handled lazily. An entry `(d, u)` popped from the PQ is stale if $d$ is strictly greater than the currently known shortest distance to $u$. Such entries must be ignored.\n-   **Output Specification**: For each test case, the output must be a list of $n$ integers representing the shortest distances from $s$. Unreachable vertices must be encoded as $-1$. The final output is an aggregation of these lists.\n-   **Provided Foundational Facts**:\n    1.  The definitions of a path and its length (sum of edge weights).\n    2.  The non-negativity of edge weights: $w(e) \\ge 0$ for all $e \\in E$.\n    3.  The optimal substructure property related to path concatenation: the length of a concatenated path is the sum of the lengths of its subpaths.\n    4.  The specific rule for identifying and ignoring stale entries in the PQ.\n-   **Test Suite**:\n    -   Test case $1$: $n = 5$, $s = 0$, edges $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$.\n    -   Test case $2$: $n = 3$, $s = 0$, edges $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$.\n    -   Test case $3$: $n = 4$, $s = 0$, edges $\\{(0, 1, 7)\\}$.\n    -   Test case $4$: $n = 1$, $s = 0$, edges $\\{\\}$.\n    -   Test case $5$: $n = 3$, $s = 0$, edges $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$.\n    -   Test case $6$: $n = 6$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$.\n    -   Test case $7$: $n = 4$, $s = 0$, edges $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to rigorous validation.\n\n-   **Scientifically Grounded**: The problem describes a standard variation of Dijkstra's algorithm. The algorithm's correctness for graphs with non-negative edge weights is a cornerstone of graph theory and computer science. The specified implementation detail—handling the absence of a `decrease-key` operation by inserting duplicates and lazily discarding stale entries—is a well-established and correct technique. This is scientifically and algorithmically sound.\n-   **Well-Posed**: The problem is well-posed. For a given graph with non-negative weights and a source vertex, the set of single-source shortest-path distances is uniquely defined. The constraints on the algorithm are precise, leading to a deterministic outcome.\n-   **Objective**: The problem is stated using formal mathematical notation and unambiguous terminology. It is free from subjective or opinion-based content.\n-   **Self-Contained and Consistent**: The problem provides all necessary data for each test case ($n$, $s$, and the edge set). The constraints are explicit and not contradictory. The foundational facts provided are correct and consistent with the principles underlying the algorithm.\n-   **Formalizable and Relevant**: The problem is directly an implementation task for a core algorithm, Dijkstra's algorithm, within the specified topic. It is perfectly suited for formalization into a program.\n-   **Complete and Unambiguous**: The vertex and edge specifications are complete. The output format is precisely defined. Terms like \"shortest-path distance\" and \"nonnegative\" are standard and unambiguous.\n-   **Non-Trivial**: The problem is not trivial. It requires a correct implementation of a non-trivial algorithm, including careful management of the priority queue state according to the specified constraints.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-defined, scientifically sound problem in the field of algorithms. I will now proceed to construct the solution.\n\nThe algorithm to be implemented is a variant of Dijkstra's algorithm. Let $d[v]$ be the tentative shortest distance from the source $s$ to a vertex $v$.\n\n1.  **Initialization**: An array $d$ of size $n$ is initialized to store the shortest-path estimates. We set $d[s] = 0$ and $d[v] = \\infty$ for all other vertices $v \\in V \\setminus \\{s\\}$. The value $\\infty$ signifies that no path from $s$ to $v$ has been discovered yet. A min-priority queue, PQ, is initialized. The PQ will store tuples of the form `(distance, vertex)`. We begin by inserting the source vertex into the PQ: `PQ.push((0, s))`.\n\n2.  **Iterative Processing**: The algorithm proceeds by repeatedly extracting the vertex with the minimum distance from the PQ. As long as the PQ is not empty, we perform the following steps:\n    a. Extract the entry $(dist_u, u)$ with the smallest $dist_u$ from the PQ.\n    b. **Stale Entry Check**: This is the critical step dictated by the problem constraints. We compare the extracted distance $dist_u$ with the current best-known distance to $u$, which is $d[u]$. If $dist_u > d[u]$, it implies that we have already found a shorter path to $u$ and have processed it in a previous iteration. The entry $(dist_u, u)$ is therefore \"stale\" and must be discarded. We then continue to the next iteration of the loop.\n    c. **Vertex Finalization and Relaxation**: If $dist_u \\le d[u]$ (which must be $dist_u = d[u]$ due to the properties of the algorithm and the stale check), it means we have found the shortest path to $u$. The non-negativity of edge weights ensures that any other path to $u$ not yet discovered must pass through some other vertex currently in the PQ, which by definition has a tentative distance greater than or equal to $d[u]$. Thus, no shorter path is possible. We then \"relax\" the edges originating from $u$. For each neighbor $v$ of $u$ connected by an edge $(u, v)$ with weight $w(u, v)$, we calculate a new potential distance to $v$ through $u$: $d[u] + w(u, v)$.\n    d. **Path Improvement**: If this new path is shorter than the current best-known path to $v$ (i.e., if $d[u] + w(u, v)  d[v]$), we have found an improvement. We update the distance array: $d[v] = d[u] + w(u, v)$. Crucially, instead of performing a `decrease-key` operation on $v$ in the PQ, we simply insert the new, improved entry $(d[v], v)$ into the PQ. This is the source of the duplicate entries.\n\n3.  **Termination**: The loop terminates when the PQ becomes empty. At this point, for every vertex $v$, the value $d[v]$ is the length of the shortest path from $s$ to $v$. If $d[v]$ remains $\\infty$, it means $v$ is unreachable from $s$.\n\n4.  **Final Output Formatting**: The final distance array $d$ is processed to replace any remaining $\\infty$ values with $-1$ to conform to the output specification. The results for all test cases are then aggregated into the required string format. For the implementation, the Python `heapq` module serves as an ideal min-priority queue, as it naturally accommodates duplicate entries and lacks a `decrease-key` method.\n\nThis procedure correctly computes the single-source shortest paths under the specified constraints, relying on the fundamental properties of non-negative edge weights and the greedy choice made by extracting the minimum-distance vertex from the priority queue.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Solves the single-source shortest path problem for a series of test cases\n    using a Dijkstra-like algorithm with a priority queue that allows duplicates\n    and has no decrease-key operation.\n    \"\"\"\n    \n    test_cases = [\n        {'n': 5, 's': 0, 'edges': [(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)]},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 0), (1, 2, 0), (0, 2, 5)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 7)]},\n        {'n': 1, 's': 0, 'edges': []},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)]},\n        {'n': 6, 's': 0, 'edges': [(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n = case['n']\n        s = case['s']\n        edges = case['edges']\n        \n        # Adjacency list representation of the graph\n        adj = [[] for _ in range(n)]\n        for u, v, w in edges:\n            adj[u].append((v, w))\n            \n        # Initialize distances: 0 for the source, infinity for all others.\n        # np.inf is used to represent infinite distance.\n        distances = np.full(n, np.inf)\n        distances[s] = 0\n        \n        # Min-priority queue storing tuples of (distance, vertex).\n        # We start with the source vertex.\n        pq = [(0, s)]\n        \n        while pq:\n            # Pop the vertex with the smallest tentative distance\n            dist_u, u = heapq.heappop(pq)\n            \n            # If the popped distance is greater than the known shortest distance,\n            # this is a stale entry. We ignore it and proceed.\n            if dist_u  distances[u]:\n                continue\n            \n            # Relax edges for the current vertex u\n            for v, weight in adj[u]:\n                # If we found a shorter path to v through u\n                if distances[u] + weight  distances[v]:\n                    # Update the distance to v\n                    distances[v] = distances[u] + weight\n                    # Push the new, better path information to the priority queue.\n                    # This may create duplicate entries for vertex v, as required.\n                    heapq.heappush(pq, (distances[v], v))\n                    \n        # Prepare the final result list for this test case.\n        # Replace np.inf with -1 for unreachable vertices.\n        # Convert all distances to integers.\n        result = [int(d) if d != np.inf else -1 for d in distances]\n        all_results.append(result)\n\n    # Format the final output string as specified in the problem.\n    # e.g., [[0,1,2],[0,-1]]\n    str_results = []\n    for res in all_results:\n        str_results.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output_string = f\"[{','.join(str_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "3227995"}, {"introduction": "Beyond graphs, priority queues are fundamental to greedy algorithms that make locally optimal choices. This exercise applies the priority queue to Huffman coding, a classic data compression technique that builds an optimal prefix code. You will implement a dynamic version where the Huffman tree is rebuilt at each step, showcasing how a priority queue can efficiently and repeatedly find the two least-frequent symbols to merge. [@problem_id:3261138]", "problem": "You must design and implement a complete, runnable program that computes the total number of bits required to encode several given symbol sequences using an online (dynamic) Huffman coding scheme built from a priority queue (priority queue (PQ)). The symbol probabilities are not known in advance; they are learned incrementally from the sequence seen so far. The program should output a single line containing the total bit length for each test sequence in the format specified below.\n\nFundamental base and definitions to use:\n- A priority queue is an abstract data type that supports removal of the element with smallest (or largest) key in time sublinear in the number of elements. You may assume a binary heap implementation with the standard operations that remove the minimum key in time proportional to $O(\\log n)$.\n- A prefix code is a code in which no codeword is a prefix of another codeword.\n- The classical Huffman algorithm constructs an optimal prefix code for a fixed set of symbols with fixed nonnegative weights by repeatedly merging the two least-weight nodes; this can be implemented with a priority queue.\n\nDynamic coding model to implement:\n- Alphabet and raw cost: Symbols are bytes (values $0$ to $255$). When a previously unseen symbol is encoded, it must be emitted in raw form using $8$ bits immediately after an escape symbol described below.\n- Escape mechanism: Maintain a dedicated escape symbol $\\mathsf{ESC}$. At any step where there exists at least one byte value not yet observed in the sequence so far, include $\\mathsf{ESC}$ in the Huffman model with a fixed weight of $1$. If all $256$ byte values have been observed, omit $\\mathsf{ESC}$.\n- Modeling and update rule:\n  1. Before encoding the next symbol $x$, build a Huffman code using the multiset consisting of all previously seen symbols with their current frequencies (weights), and include $\\mathsf{ESC}$ with weight $1$ if applicable as per the previous item.\n  2. Encoding:\n     - If $x$ has been observed before, emit its current Huffman codeword. The cost in bits is the codeword length of $x$ in the current Huffman tree.\n     - If $x$ has not been observed before, emit the current Huffman codeword for $\\mathsf{ESC}$, then emit $x$ in raw form using $8$ bits. The total cost for this event is the codeword length of $\\mathsf{ESC}$ plus $8$.\n  3. After emitting $x$, update the model by incrementing the frequency of $x$ by $1$ (if $x$ was unseen, it now has frequency $1$). The weight of $\\mathsf{ESC}$ remains fixed at $1$ whenever it is present.\n- Huffman construction details:\n  - Use a priority queue keyed by $(w, o)$ where $w$ is the node weight and $o$ is a deterministic tie-breaker order.\n  - For all leaves corresponding to byte values, set the tie-breaker to the byte value (an integer in $[0,255]$). For $\\mathsf{ESC}$, set the tie-breaker to $256$.\n  - For internal nodes created during Huffman merging, assign strictly increasing tie-breakers starting at $257$ in the order the nodes are created.\n  - When there is only a single node in the Huffman forest (for example, at the very beginning when only $\\mathsf{ESC}$ is present), define the codeword length of that sole node to be $1$ bit. Otherwise, codeword lengths are the depths of the leaves in the final tree, with the root at depth $0$.\n\nComputation objective:\n- For each provided test sequence, compute the total number of bits produced by the above process when encoding the sequence from left to right, rebuilding the Huffman tree from scratch using a priority queue before each symbol is encoded.\n\nTest suite:\n- Use exactly the following sequences of bytes, each given as an ASCII string:\n  1. \"ABC\"\n  2. \"AAAAA\"\n  3. \"ABABA\"\n\nRequired outputs:\n- For each sequence, output the total number of bits as an integer.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\").\n\nAll computations are unitless bit counts. No physical units are involved. The output must be deterministic given the rules above and the specified tie-breaking policy. Your implementation must use a priority queue to construct the Huffman tree at each step, as described. No randomness is permitted in any part of the algorithm. The final output format must strictly match the specification and must contain the results for the test suite in the given order.", "solution": "The problem requires the implementation of a dynamic Huffman coding algorithm to calculate the total bit cost for encoding several byte sequences. The key characteristic of this specific algorithm is that the Huffman tree is not updated incrementally but is rebuilt from scratch before encoding each symbol. The solution can be broken down into a sequence of operations performed for each symbol in the input stream.\n\nThe state of the encoder evolves over time and must be maintained. This state consists of:\n1.  A frequency map, which stores the counts of each symbol encountered so far. Let's denote the frequency of a symbol $x$ as $f(x)$.\n2.  A set of unique symbols seen so far. This is used to determine if the escape symbol, $\\mathsf{ESC}$, should be included in the model.\n\nThe overall process is a loop over the symbols of an input sequence. For each symbol $s_i$ at step $i$:\n\nStep 1: Model Construction\nBefore encoding $s_i$, we construct a model of the source. This model is a collection of nodes, each representing a symbol to be included in the Huffman tree.\n- For each symbol $x$ that has been seen previously (i.e., its frequency $f(x) > 0$), a leaf node is created with a weight $w$ equal to its frequency $f(x)$. The problem specifies a deterministic tie-breaking rule, so each node is associated with a key pair $(w, o)$, where $o$ is the tie-breaker. For a symbol node, $o$ is its byte value (an integer in $[0, 255]$).\n- A special escape symbol, $\\mathsf{ESC}$, is included in the model if the set of all $256$ possible byte values has not yet been exhausted. The $\\mathsf{ESC}$ node is always assigned a fixed weight of $w=1$ and a tie-breaker of $o=256$.\n\nStep 2: Huffman Tree Generation\nWith the collection of nodes from the model, a Huffman tree is constructed using a priority queue (min-heap).\n- All nodes from the model are inserted into the priority queue. The priority of a node is determined by its $(w, o)$ key pair, where lexical comparison is used.\n- The tree is built by repeatedly performing the following merge operation until only one node (the root) remains in the queue:\n    1. Extract the two nodes with the lowest priority, say $N_1$ and $N_2$.\n    2. Create a new internal parent node, $N_p$. Its weight is the sum of its children's weights, $w_p = w_1 + w_2$. Its tie-breaker $o_p$ is assigned from a counter that starts at $257$ and increments for each internal node created during the construction of a single tree.\n    3. Insert the new parent node $N_p$ back into the priority queue.\n- A special case, as defined, occurs if the model contains only a single node (e.g., at the very start, only the $\\mathsf{ESC}$ node exists). In this situation, its codeword length is defined to be $1$ bit.\n\nStep 3: Codeword Length Calculation\nThe length of the Huffman codeword for any symbol is equal to the depth of its corresponding leaf node in the tree (with the root at depth $0$). After the tree is constructed, it is traversed to compute the depth of each leaf, and these lengths are stored for the encoding step.\n\nStep 4: Encoding and Cost Accumulation\nThe cost in bits to encode the current symbol $s_i$ is determined as follows:\n- If $s_i$ is a symbol that has been seen before (i.e., it was part of the model with $f(s_i)>0$), the cost is simply the length of its codeword, $L(s_i)$, obtained in the previous step.\n- If $s_i$ is a new symbol, it is encoded using the escape mechanism. The cost is the length of the $\\mathsf{ESC}$ symbol's codeword plus an additional $8$ bits to transmit the raw byte value of $s_i$. The total cost for this event is $L(\\mathsf{ESC}) + 8$.\nThis cost is added to a running total for the entire sequence.\n\nStep 5: State Update\nAfter encoding $s_i$, the frequency map is updated. The frequency $f(s_i)$ is incremented by $1$. If $s_i$ was a new symbol, its frequency is initialized to $1$, and it is added to the set of seen symbols.\n\nThis five-step process is repeated for every symbol in the input sequence. The final accumulated total represents the\ntotal number of bits required to encode the sequence according to the specified dynamic Huffman coding scheme. The entire procedure is then repeated for each test case provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\nclass HuffmanNode:\n    \"\"\"Represents a node in the Huffman tree.\"\"\"\n    def __init__(self, weight, tie_breaker, symbol=None, left=None, right=None):\n        \"\"\"\n        Initializes a Huffman node.\n        \n        Args:\n            weight (int): The weight of the node (frequency).\n            tie_breaker (int): A value for deterministic sorting.\n            symbol (int, optional): The symbol represented by this node (byte value or ESC).\n                                   None for internal nodes.\n            left (HuffmanNode, optional): The left child.\n            right (HuffmanNode, optional): The right child.\n        \"\"\"\n        self.weight = weight\n        self.tie_breaker = tie_breaker\n        self.symbol = symbol\n        self.left = left\n        self.right = right\n\n    def __lt__(self, other):\n        \"\"\"\n        Comparison for priority queue ordering.\n        Nodes are compared first by weight, then by the tie-breaker.\n        \"\"\"\n        if self.weight != other.weight:\n            return self.weight  other.weight\n        return self.tie_breaker  other.tie_breaker\n\n    def is_leaf(self):\n        \"\"\"Checks if the node is a leaf.\"\"\"\n        return self.left is None and self.right is None\n\ndef calculate_sequence_cost(sequence: str) - int:\n    \"\"\"\n    Calculates the total bit cost to encode a sequence using the specified dynamic Huffman algorithm.\n    \"\"\"\n    total_bits = 0\n    frequencies = {}\n    seen_symbols = set()\n\n    # Constants for the escape mechanism\n    ESC_SYMBOL = -1  # A unique identifier for the ESC symbol\n    ESC_TIE_BREAKER = 256\n    INTERNAL_NODE_TIE_BREAKER_START = 257\n\n    for char_symbol in sequence:\n        symbol_ord = ord(char_symbol)\n\n        # 1. Build Model: Create nodes for the current state.\n        model_nodes = []\n        for sym, freq in frequencies.items():\n            model_nodes.append(HuffmanNode(weight=freq, tie_breaker=sym, symbol=sym))\n        \n        # Add ESC node if not all 256 byte values have been observed.\n        if len(seen_symbols)  256:\n            model_nodes.append(HuffmanNode(weight=1, tie_breaker=ESC_TIE_BREAKER, symbol=ESC_SYMBOL))\n\n        # 2. Construct Huffman Tree and find codeword lengths.\n        codeword_lengths = {}\n        \n        # Special case for a single node in the forest.\n        if len(model_nodes) == 1:\n            leaf = model_nodes[0]\n            if leaf.symbol is not None:\n                codeword_lengths[leaf.symbol] = 1\n        else:\n            # Use a min-priority queue (heapq in Python).\n            pq = model_nodes\n            heapq.heapify(pq)\n            \n            next_internal_tie_breaker = INTERNAL_NODE_TIE_BREAKER_START\n            \n            # Merge nodes until only the root remains.\n            while len(pq)  1:\n                left_node = heapq.heappop(pq)\n                right_node = heapq.heappop(pq)\n                \n                new_weight = left_node.weight + right_node.weight\n                \n                parent_node = HuffmanNode(weight=new_weight, \n                                          tie_breaker=next_internal_tie_breaker,\n                                          left=left_node,\n                                          right=right_node)\n                next_internal_tie_breaker += 1\n                \n                heapq.heappush(pq, parent_node)\n            \n            root = pq[0] if pq else None\n            \n            # 3. Calculate codeword lengths by traversing the tree.\n            if root:\n                # Stack for iterative traversal to find depths.\n                traversal_stack = [(root, 0)]\n                while traversal_stack:\n                    node, depth = traversal_stack.pop()\n                    if node.is_leaf():\n                        if node.symbol is not None:\n                            # A tree with one symbol still has a codeword of length 1, not 0.\n                            codeword_lengths[node.symbol] = depth if depth  0 else 1\n                    else:\n                        if node.right:\n                            traversal_stack.append((node.right, depth + 1))\n                        if node.left:\n                            traversal_stack.append((node.left, depth + 1))\n\n        # 4. Encode Symbol and Update Cost.\n        is_new_symbol = symbol_ord not in seen_symbols\n        \n        if is_new_symbol:\n            # Cost is ESC codeword length + 8 bits for the raw symbol.\n            esc_len = codeword_lengths.get(ESC_SYMBOL, 0)\n            total_bits += esc_len + 8\n        else:\n            # Cost is the symbol's codeword length.\n            sym_len = codeword_lengths.get(symbol_ord, 0)\n            total_bits += sym_len\n            \n        # 5. Update Model State for the next iteration.\n        if is_new_symbol:\n            seen_symbols.add(symbol_ord)\n        frequencies[symbol_ord] = frequencies.get(symbol_ord, 0) + 1\n            \n    return total_bits\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\"ABC\", \"AAAAA\", \"ABABA\"]\n\n    results = []\n    for sequence in test_cases:\n        result = calculate_sequence_cost(sequence)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3261138"}, {"introduction": "Our first practice with Dijkstra's algorithm used a \"lazy\" method to work around the absence of a `decrease-key` operation, which can sometimes lead to a larger queue size. This final, advanced practice confronts that challenge head-on by asking you to build an Indexed Priority Queue (IPQ) that efficiently supports `decrease-key` and `delete` operations. By augmenting a binary heap with an index map and a robust handle system, you will engineer a more powerful data structure essential for high-performance implementations of algorithms like Dijkstra's and Prim's. [@problem_id:3261051]", "problem": "Design and implement an Indexed Priority Queue (IPQ) with a binary heap that supports the operations $insert$, $decrease\\text{-}key$ by handle, $delete$ by handle, and $extract\\text{-}min$. Propose a robust handle scheme and rigorously justify that all operations execute in $O(\\log n)$ worst-case time, where $n$ is the current number of elements in the IPQ. The IPQ must maintain the heap-order invariant on keys and use an array-based complete binary tree representation to ensure the shape invariant. For deterministic behavior in the presence of equal keys, ties must be broken using immutable identifiers.\n\nFundamental basis to be used for the derivation and design:\n- A binary heap is a complete binary tree that satisfies the heap-order property on keys.\n- An array-backed complete binary tree of size $n$ has height $h = \\lfloor \\log_2 n \\rfloor$, and any path from a node to the root or to a leaf has length at most $h$.\n- Bubble-up (also called sift-up) adjusts a node upward by repeatedly comparing with its parent and swapping while the heap-order property is violated; bubble-down (also called sift-down) adjusts a node downward by repeatedly comparing with its minimal child and swapping while the heap-order property is violated.\n\nHandle scheme requirement:\n- The handle returned by $insert$ must be a robust token that remains valid for the life of the specific element and becomes invalid immediately upon $delete$ of that element.\n- The handle must prevent the \"ABA problem\" where a stale handle could accidentally refer to a newly inserted element that reuses an internal identifier.\n- Any operation presented with a stale or invalid handle must be rejected without mutating the IPQ.\n\nOperation semantics:\n- $insert(k)$ inserts a key $k$ and returns a handle $h$ for the inserted element.\n- $decrease\\text{-}key(h, k')$ decreases the key associated with handle $h$ to a new key $k'$ under the precondition $k'  k$; if the handle is invalid or the precondition fails, the operation must be rejected.\n- $delete(h)$ deletes the element associated with handle $h$; if the handle is invalid, the operation must be rejected.\n- $extract\\text{-}min()$ removes and returns the minimum key currently in the IPQ.\n\nValidation and complexity justification:\n- You must implement instrumentation that records the number of heap index movements performed by bubble-up or bubble-down during each operation. An index movement is defined as any swap that relocates an element from index $i$ to a different index $j$ in the heap array. Use this instrumentation to report per-test-case summary values as specified below. This instrumentation is required only for reporting; it must not change the asymptotic complexity of the implemented operations.\n\nRobust handle scheme to be implemented:\n- Each element has an immutable identifier $i \\in \\mathbb{N}$ assigned at insertion and never reused for another element.\n- Maintain a generation counter $g_i \\in \\mathbb{N}$ per identifier. The current valid handle for an element is the pair $(i, g_i)$ at the time of insertion. When the element is deleted, increment $g_i$ by $1$, which invalidates any previously issued handle for that identifier. Validity checks must ensure that a presented handle $(i, g)$ is accepted only if $g = g_i$ and the identifier $i$ is currently present in the heap (i.e., has a mapped position).\n- This $(i, g_i)$ scheme must be used in $decrease\\text{-}key$ and $delete$ to ensure robustness against stale handles.\n\nTest suite and required outputs:\n- Test Case $1$ (general case): Insert the keys $A_1 = [\\,7,\\,3,\\,5,\\,2,\\,9,\\,1,\\,4\\,]$ in that order, collect the returned handles in the same order. Then perform $decrease\\text{-}key$ on the handle corresponding to the third insertion (original key $5$) to the new key $0$. Then perform $delete$ on the handle corresponding to the first insertion (original key $7$). Finally, repeatedly call $extract\\text{-}min$ until the IPQ is empty, and record the list of extracted keys. The expected output for this test is the list of integers representing the extracted keys in ascending order after these operations.\n- Test Case $2$ (height-bound stress): Insert the keys $A_2 = [\\,10,\\,8,\\,6,\\,4,\\,2\\,]$ in that order. Perform $decrease\\text{-}key$ on the handle corresponding to the last insertion (original key $2$) to the new key $-100$. Then perform $delete$ on the handle corresponding to the second insertion (original key $8$). During this test, record the maximum number of heap index movements made by any single bubble-up or bubble-down across all operations in this test case. The expected output for this test is a single integer equal to this maximum.\n- Test Case $3$ (stale handle and repeated decreases): Insert the single key $A_3 = [\\,50\\,]$ and capture the handle $h_0$. Perform $decrease\\text{-}key(h_0, 20)$, then $decrease\\text{-}key(h_0, 10)$, then $decrease\\text{-}key(h_0, 5)$. Then perform $delete(h_0)$. Finally, attempt $decrease\\text{-}key(h_0, 1)$ and record whether the operation is rejected due to the handle being stale. The expected output for this test is a boolean indicating whether the stale handle was correctly rejected.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, specifically $[R_1, R_2, R_3]$, where $R_1$ is the list from Test Case $1$, $R_2$ is the integer from Test Case $2$, and $R_3$ is the boolean from Test Case $3$.\n- The program must be self-contained, require no input, and use Python version $3.12$ with only the Python standard library and the library Numerical Python (NumPy) version $1.23.5$.\n\nScientific realism and constraints:\n- All keys are integers and all operations must adhere to the described semantics.\n- Complexity claims must be justified from the properties of complete binary trees and the heap-order invariant, starting from the fundamental basis given above, without relying on unproven shortcuts or external references.", "solution": "The design and implementation of a robust Indexed Priority Queue (IPQ) must be grounded in the established principles of binary heaps and augmented with data structures to support efficient indexed operations. We will construct the IPQ by combining a binary heap with auxiliary mappings for position tracking and a generation-based scheme for robust handle management.\n\n### Data Structures\n\nThe IPQ is realized through four primary components:\n\n$1$. **The Heap Array, $\\mathcal{H}$**: A dynamic array representing a complete binary tree. For algebraic convenience, we use $1$-based indexing, where the element at index $j  0$ has its parent at index $\\lfloor j/2 \\rfloor$ and its children at indices $2j$ and $2j+1$. Each entry in $\\mathcal{H}$ is a tuple $(k, i)$, where $k$ is the priority key (an integer) and $i$ is a unique, immutable identifier from $\\mathbb{N}$. The heap-order property is maintained on these tuples, where $(k_1, i_1)  (k_2, i_2)$ if $k_1  k_2$, or if $k_1 = k_2$ and $i_1  i_2$. This establishes a deterministic total ordering.\n\n$2$. **The Position Map, $\\mathcal{P}$**: A hash map that provides a bidirectional link between an element's identifier and its location in the heap. It maps an identifier $i$ to its current index $j$ in $\\mathcal{H}$, i.e., $\\mathcal{P}[i] = j$. This structure is critical for achieving $O(1)$ time access to an element for the $decrease\\text{-}key$ and $delete$ operations.\n\n$3$. **The Generation Map, $\\mathcal{G}$**: A hash map that stores the current generation counter for each identifier that has ever been inserted into the IPQ. It maps an identifier $i$ to its generation $g_i \\in \\mathbb{N}$, i.e., $\\mathcal{G}[i] = g_i$.\n\n$4$. **The Identifier Counter, $N_{id}$**: A monotonically increasing integer counter used to dispense fresh, unique identifiers for new elements, ensuring no identifier is ever reused.\n\n### The Robust Handle Scheme\n\nA handle $h$ provides an external reference to an element within the IPQ. To ensure robustness against accidental misuse of stale handles (e.g., the \"ABA problem\"), a handle is defined as a pair $h = (i, g)$, where $i$ is the element's unique identifier and $g$ is the generation count of that identifier at the moment the handle was issued (i.e., upon insertion).\n\nAn operation invoked with a handle $h=(i, g)$ is considered valid if and only if two conditions are met simultaneously:\n- The identifier $i$ is present in the position map $\\mathcal{P}$, meaning the element is currently in the heap.\n- The generation $g$ provided in the handle matches the current generation $g_i$ stored in the generation map $\\mathcal{G}$.\n\nWhen an element with identifier $i$ is removed from the heap (via $delete$ or $extract\\text{-}min$), its entry is removed from $\\mathcal{P}$, and its generation counter $\\mathcal{G}[i]$ is incremented. This dual action immediately invalidates all previously issued handles for this element, as they will now fail one or both of the validity conditions. Any subsequent operation attempting to use a stale handle $(i, g)$ will be rejected.\n\n### Algorithmic Design and Complexity Analysis\n\nAll operations must maintain the heap invariants: the shape property (the heap is a complete binary tree) and the heap-order property. The shape property is maintained by adding/removing elements only at the end of the array. The heap-order property is restored using two fundamental procedures, $bubble\\text{-}up$ and $bubble\\text{-}down$, each operating along a path in the heap. Since the heap is a complete binary tree of size $n$, its height is $h_{heap} = \\lfloor \\log_2 n \\rfloor$. The complexity of both restoration procedures is therefore bounded by the height of the tree, resulting in $O(\\log n)$ performance.\n\n**$insert(k)$**\n$1$. A new unique identifier $i$ is drawn from $N_{id}$, which is then incremented.\n$2$. The element's initial generation is recorded: $\\mathcal{G}[i] \\leftarrow 0$. A handle $h = (i, 0)$ is created.\n$3$. The new element $(k, i)$ is appended to the end of the heap array $\\mathcal{H}$, at index $j=n+1$.\n$4$. The position map is updated: $\\mathcal{P}[i] \\leftarrow j$.\n$5$. The $bubble\\text{-}up(j)$ procedure is called to move the element up the tree until the heap-order property is restored. This involves at most $\\lfloor \\log_2 n \\rfloor$ comparisons and swaps.\n$6$. The handle $h$ is returned.\n**Complexity**: Steps $1-4$ are $O(1)$. Step $5$, $bubble\\text{-}up$, has a worst-case complexity of $O(\\log n)$. Thus, $insert$ is $O(\\log n)$.\n\n**$extract\\text{-}min()$**\n$1$. The minimum element $(k_{min}, i_{min})$ at the root of the heap, $\\mathcal{H}[1]$, is identified.\n$2$. The last element in the heap, $(k_{last}, i_{last})$ at index $n$, is moved to the root: $\\mathcal{H}[1] \\leftarrow (k_{last}, i_{last})$.\n$3$. The position map for the moved element is updated: $\\mathcal{P}[i_{last}] \\leftarrow 1$.\n$4$. The heap size is decremented, effectively removing the old last element's position.\n$5$. The identifier $i_{min}$ of the extracted element is removed from the position map $\\mathcal{P}$, and its generation is incremented in $\\mathcal{G}$: $\\mathcal{G}[i_{min}] \\leftarrow \\mathcal{G}[i_{min}] + 1$.\n$6$. The $bubble\\text{-}down(1)$ procedure is called to move the element now at the root down the tree to its correct position, restoring the heap-order property. This involves at most $O(\\log n)$ comparisons and swaps.\n$7$. The key $k_{min}$ is returned.\n**Complexity**: All steps are $O(1)$ except for $bubble\\text{-}down$, which is $O(\\log n)$. Thus, $extract\\text{-}min$ is $O(\\log n)$.\n\n**$decrease\\text{-}key(h, k')$**\n$1$. The handle $h=(i, g)$ is validated as described previously. If invalid, the operation is rejected.\n$2$. The element's current position $j$ is retrieved from $\\mathcal{P}[i]$ in $O(1)$ time.\n$3$. The precondition $k'  \\mathcal{H}[j].key$ is verified. If it fails, the operation is rejected.\n$4$. The key of the element at $\\mathcal{H}[j]$ is updated to $k'$.\n$5$. As the key has decreased, the heap-order property may be violated with the element's parent. The $bubble\\text{-}up(j)$ procedure is called to restore the invariant.\n**Complexity**: Handle validation, position lookup, and key update are $O(1)$. The dominant cost is $bubble\\text{-}up$, which is $O(\\log n)$.\n\n**$delete(h)$**\n$1$. The handle $h=(i, g)$ is validated. If invalid, the operation is rejected.\n$2$. The element's current position $j$ is retrieved from $\\mathcal{P}[i]$ in $O(1)$ time.\n$3$. The element to be deleted at index $j$ is swapped with the last element in the heap at index $n$. The position map $\\mathcal{P}$ is updated for the swapped-in element.\n$4$. The heap size is decremented. The entry for identifier $i$ is removed from $\\mathcal{P}$, and its generation $\\mathcal{G}[i]$ is incremented.\n$5$. The element that was moved from index $n$ to index $j$ may violate the heap-order property. We compare it with its parent. If it is smaller than its parent, $bubble\\text{-}up(j)$ is performed. Otherwise, $bubble\\text{-}down(j)$ is performed. Only one of these procedures will perform any work.\n**Complexity**: All steps are $O(1)$ except for the final heap restoration. Both $bubble\\text{-}up$ and $bubble\\text{-}down$ are $O(\\log n)$, so the complexity of $delete$ is $O(\\log n)$.\n\n**Instrumentation**\nTo satisfy the validation requirement, a counter is maintained for each high-level operation. This counter is incremented by $1$ for each swap of two elements in the heap array $\\mathcal{H}$. The maximum count observed across all operations in a given test case is recorded. This instrumentation adds a constant overhead to the swap operation and does not alter the asymptotic complexity.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Indexed Priority Queue problem by implementing the required class\n    and running the specified test cases.\n    \"\"\"\n\n    class IndexedPriorityQueue:\n        \"\"\"\n        An Indexed Priority Queue (IPQ) implemented with a binary heap.\n\n        This IPQ supports insert, extract-min, decrease-key by handle, and\n        delete by handle, all in O(log n) time. It uses a robust handle\n        scheme based on unique identifiers and generation counters to prevent\n        issues with stale handles.\n\n        The heap is 1-indexed for simpler parent/child arithmetic.\n        - parent(i) = i // 2\n        - left_child(i) = 2 * i\n        - right_child(i) = 2 * i + 1\n        \"\"\"\n\n        def __init__(self):\n            # self.heap stores tuples of (key, identifier).\n            # Index 0 is a placeholder to enable 1-based indexing.\n            self.heap = [None]\n            # self.pos maps an identifier to its index in the heap array.\n            self.pos = {}\n            # self.gen maps an identifier to its generation counter.\n            self.gen = {}\n            # self.next_id is a counter for assigning new unique identifiers.\n            self.next_id = 0\n            # Instrumentation: tracks max movements for any single operation.\n            self.max_movements_per_op = 0\n            self._current_op_movements = 0\n\n        def is_empty(self):\n            return len(self.heap) == 1\n\n        def _swap(self, i, j):\n            \"\"\"Swaps elements at heap indices i and j, updating position map.\"\"\"\n            h = self.heap\n            p = self.pos\n            h[i], h[j] = h[j], h[i]\n            p[h[i][1]] = i\n            p[h[j][1]] = j\n            self._current_op_movements += 1\n\n        def _compare(self, i, j):\n            \"\"\"\n            Compares elements at heap indices i and j.\n            Uses (key, identifier) for deterministic tie-breaking.\n            Returns True if element at i is smaller than element at j.\n            \"\"\"\n            return self.heap[i]  self.heap[j]\n\n        def _bubble_up(self, i):\n            \"\"\"Restores heap property by moving element at index i up.\"\"\"\n            parent = i // 2\n            while i  1 and self._compare(i, parent):\n                self._swap(i, parent)\n                i = parent\n                parent = i // 2\n\n        def _bubble_down(self, i):\n            \"\"\"Restores heap property by moving element at index i down.\"\"\"\n            size = len(self.heap)\n            while 2 * i  size:\n                left = 2 * i\n                right = 2 * i + 1\n                smallest = left\n                if right  size and self._compare(right, left):\n                    smallest = right\n                \n                if self._compare(smallest, i):\n                    self._swap(i, smallest)\n                    i = smallest\n                else:\n                    break\n\n        def _start_op(self):\n            \"\"\"Resets the movement counter for a new operation.\"\"\"\n            self._current_op_movements = 0\n\n        def _end_op(self):\n            \"\"\"Updates the max movement counter at the end of an operation.\"\"\"\n            self.max_movements_per_op = max(self.max_movements_per_op, self._current_op_movements)\n\n        def _validate_handle(self, handle):\n            \"\"\"Validates a handle (identifier, generation).\"\"\"\n            identifier, generation = handle\n            return identifier in self.pos and self.gen.get(identifier) == generation\n\n        def insert(self, key):\n            \"\"\"\n            Inserts a key, returns a robust handle. Complexity: O(log n).\n            \"\"\"\n            self._start_op()\n            identifier = self.next_id\n            self.next_id += 1\n            \n            # This is the first time we see this identifier\n            self.gen[identifier] = 0\n            handle = (identifier, self.gen[identifier])\n\n            self.heap.append((key, identifier))\n            new_pos = len(self.heap) - 1\n            self.pos[identifier] = new_pos\n            \n            self._bubble_up(new_pos)\n            self._end_op()\n            return handle\n\n        def extract_min(self):\n            \"\"\"\n            Removes and returns the minimum key. Complexity: O(log n).\n            \"\"\"\n            if self.is_empty():\n                raise IndexError(\"extract_min from an empty priority queue\")\n            \n            self._start_op()\n            min_key, min_id = self.heap[1]\n            last_item = self.heap.pop()\n            \n            if not self.is_empty():\n                self.heap[1] = last_item\n                self.pos[last_item[1]] = 1\n                self._bubble_down(1)\n            \n            del self.pos[min_id]\n            self.gen[min_id] += 1\n            \n            self._end_op()\n            return min_key\n\n        def decrease_key(self, handle, new_key):\n            \"\"\"\n            Decreases the key of an element specified by a handle.\n            Complexity: O(log n). Returns True on success, False on failure.\n            \"\"\"\n            if not self._validate_handle(handle):\n                return False\n\n            self._start_op()\n            identifier, _ = handle\n            current_pos = self.pos[identifier]\n            current_key, _ = self.heap[current_pos]\n\n            if new_key = current_key:\n                # Precondition k'  k failed, do not count movements\n                self._current_op_movements = 0\n                self._end_op() \n                return False\n\n            self.heap[current_pos] = (new_key, identifier)\n            self._bubble_up(current_pos)\n            self._end_op()\n            return True\n\n        def delete(self, handle):\n            \"\"\"\n            Deletes an element specified by a handle. Complexity: O(log n).\n            Returns True on success, False on failure.\n            \"\"\"\n            if not self._validate_handle(handle):\n                return False\n\n            self._start_op()\n            identifier, _ = handle\n            pos_to_delete = self.pos[identifier]\n            \n            # Swap with the last element\n            last_pos = len(self.heap) - 1\n            self._swap(pos_to_delete, last_pos) # This counts as 1 movement\n            \n            # Pop the target element (which is now at the end)\n            deleted_key, deleted_id = self.heap.pop()\n            del self.pos[deleted_id]\n            self.gen[deleted_id] += 1\n\n            # If the heap is now empty or we deleted the last element, we are done.\n            if not self.is_empty() and pos_to_delete = len(self.heap) - 1:\n                # The swapped-in element might need to be moved up or down.\n                # A bubble_up will only occur if the element is smaller than its parent.\n                # Otherwise, a bubble_down might be needed.\n                item_key, _ = self.heap[pos_to_delete]\n                parent_pos = pos_to_delete // 2\n\n                # If it's not the root and smaller than its parent, bubble up.\n                if parent_pos  0 and self._compare(pos_to_delete, parent_pos):\n                    self._bubble_up(pos_to_delete)\n                else: # Otherwise, it might need to bubble down.\n                    self._bubble_down(pos_to_delete)\n\n            self._end_op()\n            return True\n\n    results = []\n\n    # --- Test Case 1 ---\n    ipq1 = IndexedPriorityQueue()\n    handles1 = []\n    keys1 = [7, 3, 5, 2, 9, 1, 4]\n    for k in keys1:\n        handles1.append(ipq1.insert(k))\n\n    ipq1.decrease_key(handles1[2], 0)  # Decrease key of 5 to 0\n    ipq1.delete(handles1[0])          # Delete key 7\n    \n    extracted_keys = []\n    while not ipq1.is_empty():\n        extracted_keys.append(ipq1.extract_min())\n    results.append(extracted_keys)\n\n    # --- Test Case 2 ---\n    ipq2 = IndexedPriorityQueue()\n    handles2 = []\n    keys2 = [10, 8, 6, 4, 2]\n    for k in keys2:\n        handles2.append(ipq2.insert(k))\n    \n    ipq2.decrease_key(handles2[4], -100) # Decrease key of 2 to -100\n    ipq2.delete(handles2[1])           # Delete key 8\n\n    results.append(ipq2.max_movements_per_op)\n\n    # --- Test Case 3 ---\n    ipq3 = IndexedPriorityQueue()\n    h0 = ipq3.insert(50)\n    ipq3.decrease_key(h0, 20)\n    ipq3.decrease_key(h0, 10)\n    ipq3.decrease_key(h0, 5)\n    ipq3.delete(h0)\n    \n    # Attempt to use the stale handle, expecting rejection.\n    # decrease_key returns False on rejection.\n    is_rejected = not ipq3.decrease_key(h0, 1)\n    results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    # We need to manually format the list R1 to avoid spaces.\n    r1_str = f\"[{','.join(map(str, results[0]))}]\"\n    print(f\"[{r1_str},{results[1]},{str(results[2]).lower()}]\")\n\nsolve()\n```", "id": "3261051"}]}