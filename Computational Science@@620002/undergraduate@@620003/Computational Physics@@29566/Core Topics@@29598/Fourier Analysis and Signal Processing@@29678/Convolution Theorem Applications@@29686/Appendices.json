{"hands_on_practices": [{"introduction": "The best way to understand and trust a computational theorem is to verify it from first principles. This practice guides you through a numerical verification of the convolution theorem, a cornerstone of signal processing and computational science. You will implement both a direct, brute-force convolution and the far more efficient method based on the Fast Fourier Transform (FFT), allowing you to directly compare their results and appreciate the dramatic computational speed-up the theorem offers. [@problem_id:2383312]", "problem": "You are asked to verify the convolution theorem numerically by comparing a direct time-domain linear convolution with a frequency-domain method that uses a radix-$2$ Cooley–Tukey Fast Fourier Transform (FFT). Work entirely in discrete time with sequences indexed by nonnegative integers. All quantities are dimensionless. Angles inside complex exponentials must be measured in radians.\n\nBegin from the following fundamental base:\n- The discrete-time linear convolution of two finite-length sequences $\\{x[n]\\}_{n=0}^{n_x-1}$ and $\\{h[n]\\}_{n=0}^{n_h-1}$ is defined by $y[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n-m]$, where $x[m] = 0$ for $m \\notin \\{0,\\dots,n_x-1\\}$ and $h[m] = 0$ for $m \\notin \\{0,\\dots,n_h-1\\}$. The linear convolution length is $n_y = n_x + n_h - 1$.\n- The length-$L$ Discrete Fourier Transform (DFT) of $\\{x[n]\\}_{n=0}^{L-1}$ is $X[k] = \\sum_{n=0}^{L-1} x[n] \\exp\\!\\left(-2\\pi i \\frac{kn}{L}\\right)$ for $k \\in \\{0,\\dots,L-1\\}$, and its inverse is $x[n] = \\frac{1}{L}\\sum_{k=0}^{L-1} X[k] \\exp\\!\\left(2\\pi i \\frac{kn}{L}\\right)$ for $n \\in \\{0,\\dots,L-1\\}$. Angles are in radians.\n\nTask:\n- Implement a radix-$2$ Cooley–Tukey Fast Fourier Transform (FFT) and its inverse to compute the DFT and inverse DFT. Your implementation must require input lengths to be powers of $2$ and must use the divide-and-conquer decomposition into even and odd indices with the twiddle factors $\\exp\\!\\left(-2\\pi i \\frac{k}{N}\\right)$.\n- Implement the direct linear convolution using its definition, with explicit summation that runs in $\\mathcal{O}(n_x n_h)$ time.\n- Implement the FFT-based linear convolution as follows: given $\\{x[n]\\}$ and $\\{h[n]\\}$, choose $L$ to be the smallest power of $2$ that is at least $n_x + n_h - 1$, zero-pad both sequences to length $L$, compute their DFTs via your radix-$2$ Cooley–Tukey FFT, multiply pointwise in the frequency domain, and apply your inverse FFT. Return the first $n_x + n_h - 1$ samples to obtain the linear convolution result.\n- For the numerical comparison, generate signals using a fixed random seed so that results are reproducible. For each test below, compute the maximum absolute difference between the direct linear convolution and the FFT-based linear convolution:\n  $$\\varepsilon = \\max_{0 \\le n \\le n_x+n_h-2} \\left|y_{\\text{direct}}[n] - y_{\\text{FFT}}[n]\\right|.$$\n  Report $\\varepsilon$ rounded to $10$ decimal places.\n\nAngle unit requirement:\n- All complex exponentials must use radians.\n\nTest suite:\n- Use a single random number generator with seed $2025$. For each case, draw each independent real component from the standard normal distribution with mean $0$ and variance $1$.\n  1. General real case: $n_x = 64$, $n_h = 47$, $x[n]$ and $h[n]$ real-valued.\n  2. General complex case: $n_x = 32$, $n_h = 16$, $x[n]$ and $h[n]$ complex-valued with independent real and imaginary parts drawn as above.\n  3. Tiny case: $n_x = 1$, $n_h = 1$, $x[n]$ and $h[n]$ real-valued.\n  4. Prime-length edge case: $n_x = 7$, $n_h = 11$, $x[n]$ and $h[n]$ real-valued.\n\nAnswer specification:\n- For each test case, compute $\\varepsilon$ as defined above. The expected outcome is that each $\\varepsilon$ is a small nonnegative real number due to numerical round-off, typically on the order of $10^{-12}$ or smaller. There is no physical unit.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases $1$ through $4$, where each entry is the float $\\varepsilon$ rounded to $10$ decimal places. For example, a valid output format is like $[\\text{e1},\\text{e2},\\text{e3},\\text{e4}]$ with each $\\text{e}$ printed as a decimal number with exactly $10$ digits after the decimal point (no percentage signs).\n\nYour final deliverable must be a complete, runnable program that performs all computations and prints only the required single-line output in the specified format.", "solution": "The problem statement is scrutinized and found to be valid. It is scientifically grounded in the principles of Fourier analysis, specifically the convolution theorem. The problem is well-posed, with all necessary definitions, parameters, and constraints for performing a numerical verification. The instructions are objective and explicit, allowing for a unique and reproducible solution. We may therefore proceed with the derivation and implementation.\n\nThe objective is to verify the discrete convolution theorem by implementing and comparing two methods for computing the linear convolution of two finite discrete-time sequences, $\\{x[n]\\}_{n=0}^{n_x-1}$ and $\\{h[n]\\}_{n=0}^{n_h-1}$.\n\nThe first method is direct computation. The linear convolution, denoted by $\\{y[n]\\} = \\{x[n]\\} * \\{h[n]\\}$, is defined as:\n$$\ny[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n-m]\n$$\nGiven that $x[m]$ is non-zero only for $m \\in \\{0, \\dots, n_x-1\\}$ and $h[k]$ is non-zero only for $k \\in \\{0, \\dots, n_h-1\\}$, the sum is non-zero only over a finite range of $m$. The resulting sequence $y[n]$ has a length of $n_y = n_x + n_h - 1$. A direct implementation involves nested loops iterating through indices $n$ and $m$, leading to a computational complexity of $\\mathcal{O}(n_x n_h)$.\n\nThe second method leverages the convolution theorem, which states that convolution in the time domain is equivalent to pointwise multiplication in the frequency domain. For discrete sequences, this theorem applies to circular convolution:\n$$\n\\text{DFT}\\{x \\circledast_L y\\} = \\text{DFT}\\{x\\} \\cdot \\text{DFT}\\{y\\}\n$$\nwhere $\\circledast_L$ denotes circular convolution of length $L$, and the DFTs are also of length $L$. To compute linear convolution using this property, we must prevent the wrap-around effect (time-domain aliasing) inherent in circular convolution. This is achieved by zero-padding both sequences, $x[n]$ and $h[n]$, to a length $L$ such that $L \\ge n_x + n_h - 1$. The product of their $L$-point DFTs is then computed, and an $L$-point inverse DFT is applied to return to the time domain. The resulting $L$-point sequence's first $n_x + n_h - 1$ samples are identical to the linear convolution result.\n\nThe Discrete Fourier Transform (DFT) of a length-$N$ sequence $\\{x[n]\\}$ is:\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n] \\exp\\left(-2\\pi i \\frac{kn}{N}\\right), \\quad k \\in \\{0, \\dots, N-1\\}\n$$\nA direct computation of the DFT has a complexity of $\\mathcal{O}(N^2)$. The problem mandates the use of the more efficient radix-2 Cooley–Tukey Fast Fourier Transform (FFT) algorithm, which has a complexity of $\\mathcal{O}(N \\log N)$, but requires the sequence length $N$ to be a power of $2$.\n\nThe Cooley-Tukey algorithm is a divide-and-conquer algorithm. For a sequence $x[n]$ of length $N = 2^p$, we split the DFT sum into even and odd-indexed terms:\n$$\nX[k] = \\sum_{m=0}^{N/2-1} x[2m] e^{-2\\pi i \\frac{k(2m)}{N}} + \\sum_{m=0}^{N/2-1} x[2m+1] e^{-2\\pi i \\frac{k(2m+1)}{N}}\n$$\nLet $x_e[m] = x[2m]$ and $x_o[m] = x[2m+1]$ be the even and odd sub-sequences, each of length $N/2$. The expression becomes:\n$$\nX[k] = \\sum_{m=0}^{N/2-1} x_e[m] e^{-2\\pi i \\frac{km}{N/2}} + e^{-2\\pi i \\frac{k}{N}} \\sum_{m=0}^{N/2-1} x_o[m] e^{-2\\pi i \\frac{km}{N/2}}\n$$\nThis reveals that the $N$-point DFT can be constructed from two $(N/2)$-point DFTs. Let $X_e[k]$ and $X_o[k]$ be the $(N/2)$-point DFTs of $x_e$ and $x_o$, respectively. Let $W_N^k = \\exp(-2\\pi i \\frac{k}{N})$ be the \"twiddle factor\". Then for $k \\in \\{0, \\dots, N/2 - 1\\}$:\n$$\nX[k] = X_e[k] + W_N^k X_o[k]\n$$\nUsing the periodicity of the DFT ($X_e[k] = X_e[k+N/2]$) and properties of the twiddle factor ($W_N^{k+N/2} = -W_N^k$), we find for the upper half of the transform:\n$$\nX[k + N/2] = X_e[k] - W_N^k X_o[k]\n$$\nThis decomposition is applied recursively until we reach a base case of length $N=1$, where the DFT is the identity operation: $\\text{DFT}\\{x[0]\\} = x[0]$.\n\nFor the FFT-based convolution, we must choose the transform length $L$ to be the smallest power of $2$ such that $L \\ge n_x + n_h - 1$. After padding $x[n]$ and $h[n]$ to this length $L$, we compute their FFTs, multiply the results, and then perform an inverse FFT (IFFT). The IFFT can be computed using the FFT algorithm via the identity:\n$$\n\\text{IFFT}\\{X[k]\\} = \\frac{1}{N} \\overline{\\text{FFT}\\{\\overline{X[k]}\\}}\n$$\nwhere $\\overline{z}$ denotes the complex conjugate of $z$.\n\nThe final step is to compare the result of the direct convolution, $y_{\\text{direct}}[n]$, with the result from the FFT-based method, $y_{\\text{FFT}}[n]$, by calculating the maximum absolute difference:\n$$\n\\varepsilon = \\max_{0 \\le n < n_x+n_h-1} \\left|y_{\\text{direct}}[n] - y_{\\text{FFT}}[n]\\right|\n$$\nThis error $\\varepsilon$ should be a small number, close to machine precision, confirming the numerical equivalence of the two methods, thereby verifying the convolution theorem in a practical computational setting.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef cooley_tukey_fft(x: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements the radix-2 Cooley-Tukey FFT algorithm recursively.\n    Input length must be a power of 2.\n    \"\"\"\n    N = len(x)\n    if N == 0:\n        return np.array([], dtype=np.complex128)\n    \n    # Validate that N is a power of 2\n    if (N & (N - 1)) != 0:\n        raise ValueError(\"FFT input length must be a power of 2.\")\n\n    # Base case for recursion\n    if N == 1:\n        return x.astype(np.complex128)\n\n    # Recursive step: divide\n    x_even = cooley_tukey_fft(x[0::2])\n    x_odd = cooley_tukey_fft(x[1::2])\n\n    # Combine step: conquer\n    k = np.arange(N // 2)\n    \n    # Twiddle factors. Angles must be in radians.\n    twiddle_factors = np.exp(-2j * np.pi * k / N)\n    \n    # Butterfly operations\n    X_k = x_even + twiddle_factors * x_odd\n    X_k_plus_N2 = x_even - twiddle_factors * x_odd\n    \n    return np.concatenate([X_k, X_k_plus_N2])\n\ndef inverse_fft(X: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the inverse FFT using the Cooley-Tukey FFT implementation.\n    \"\"\"\n    N = len(X)\n    if N == 0:\n        return np.array([], dtype=np.complex128)\n        \n    # The IFFT can be computed by conjugating the input and output\n    # of a forward FFT and scaling by 1/N.\n    result = np.conj(cooley_tukey_fft(np.conj(X))) / N\n    return result\n\ndef direct_convolution(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes linear convolution using the direct summation definition.\n    Complexity is O(nx * nh).\n    \"\"\"\n    nx = len(x)\n    nh = len(h)\n    ny = nx + nh - 1\n\n    if ny <= 0:\n        return np.array([])\n    \n    # The output type should accommodate complex results if inputs are complex\n    y_dtype = np.result_type(x.dtype, h.dtype, np.float64)\n    y = np.zeros(ny, dtype=y_dtype)\n\n    for n in range(ny):\n        for m in range(nx):\n            if 0 <= n - m < nh:\n                y[n] += x[m] * h[n - m]\n    return y\n\ndef fft_convolution(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes linear convolution using the FFT-based method.\n    \"\"\"\n    nx = len(x)\n    nh = len(h)\n    ny = nx + nh - 1\n    \n    if ny <= 0:\n        return np.array([])\n\n    # Find the smallest power of 2 that is >= ny\n    # (ny-1).bit_length() gives ceil(log2(ny)). 1 << ... gives 2^ceil(log2(ny)).\n    if ny == 1:\n        L = 1\n    else:\n        L = 1 << (ny - 1).bit_length()\n\n    # Zero-pad signals to length L\n    x_padded = np.zeros(L, dtype=x.dtype)\n    x_padded[:nx] = x\n    \n    h_padded = np.zeros(L, dtype=h.dtype)\n    h_padded[:nh] = h\n\n    # Compute FFTs, pointwise product, and inverse FFT\n    X = cooley_tukey_fft(x_padded)\n    H = cooley_tukey_fft(h_padded)\n    Y = X * H\n    y_padded = inverse_fft(Y)\n\n    # Truncate to the linear convolution length\n    return y_padded[:ny]\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    # Use a single random number generator with a fixed seed for reproducibility.\n    # The seed is 2025 as per the problem.\n    rng = np.random.default_rng(2025)\n\n    test_cases = [\n        # (nx, nh, value_type)\n        (64, 47, 'real'),\n        (32, 16, 'complex'),\n        (1, 1, 'real'),\n        (7, 11, 'real'),\n    ]\n\n    results = []\n    for nx, nh, value_type in test_cases:\n        # Generate signals based on test case parameters\n        if value_type == 'real':\n            x = rng.standard_normal(size=nx)\n            h = rng.standard_normal(size=nh)\n        elif value_type == 'complex':\n            x_real = rng.standard_normal(size=nx)\n            x_imag = rng.standard_normal(size=nx)\n            x = x_real + 1j * x_imag\n            h_real = rng.standard_normal(size=nh)\n            h_imag = rng.standard_normal(size=nh)\n            h = h_real + 1j * h_imag\n        \n        # Compute convolution using both methods\n        y_direct = direct_convolution(x, h)\n        y_fft = fft_convolution(x, h)\n\n        # Calculate the maximum absolute difference\n        # The absolute value handles complex numbers correctly.\n        max_abs_diff = np.max(np.abs(y_direct - y_fft))\n        \n        # Append the formatted result\n        results.append(f\"{max_abs_diff:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2383312"}, {"introduction": "With the computational machinery of the FFT validated, we now apply it to a classic problem in probability and statistics. This exercise involves calculating the probability distribution for the sum of multiple independent dice rolls, a task that quickly becomes unwieldy with direct calculation. By leveraging the convolution theorem, you will see how this complex repeated convolution in the time domain transforms into a simple exponentiation in the frequency domain, providing an elegant and highly efficient solution. [@problem_id:2383106]", "problem": "You are to write a complete, runnable program that uses the Convolution Theorem to compute discrete probability distributions for sums of independent dice rolls. The central computational task is to obtain the probability mass function of the sum of $n$ independent and identically distributed discrete random variables with a given base distribution, by convolving the base distribution with itself $n-1$ times. You must use the Convolution Theorem and the Fast Fourier Transform (FFT), not direct time-domain convolution.\n\nFundamental base to assume:\n- The probability mass function (PMF) of a discrete random variable $X$ taking integer values is the function $p(k) = \\mathbb{P}[X = k]$, where $k$ is an integer.\n- The discrete convolution $(p * q)(k)$ of two PMFs $p$ and $q$ is defined by $(p * q)(k) = \\sum_{j} p(j)\\, q(k - j)$.\n- The Discrete Fourier Transform (DFT) of a sequence $x[n]$ is $\\hat{x}[m] = \\sum_{n=0}^{N-1} x[n]\\, e^{-2 \\pi i m n / N}$, with the inverse $\\displaystyle x[n] = \\frac{1}{N}\\sum_{m=0}^{N-1} \\hat{x}[m]\\, e^{+2 \\pi i m n / N}$, where $N$ is the transform length. Fast Fourier Transform (FFT) is an efficient algorithm to compute the DFT.\n- The Convolution Theorem states that the DFT of a convolution equals the pointwise product of DFTs: $\\widehat{p * q} = \\hat{p}\\,\\hat{q}$. For $n$-fold convolution of the same sequence $p$, the DFT is $\\widehat{p^{*n}} = (\\hat{p})^n$.\n\nYour program must:\n- Construct the $n$-fold convolution of a base die PMF using the Convolution Theorem with FFT. You must reason about and implement zero-padding to ensure that the result corresponds to a linear convolution without circular aliasing. Derive, justify, and use the smallest padding length that guarantees no wrap-around for the $n$-fold convolution. Explicitly, the base die takes values in $\\{1,2,\\dots,m\\}$ with PMF entries $p_1, p_2, \\dots, p_m$, and the $n$-fold sum takes values on a finite integer interval. Your choice of transform length must ensure correct linear convolution over this support.\n- Handle the boundary condition $n = 0$ consistently with probability theory, that is, the sum of zero independent variables should be almost surely zero (a unit point mass at $0$).\n- Extract point probabilities $\\mathbb{P}[S_n = s]$ for specified $s$, and interval probabilities $\\mathbb{P}[a \\le S_n \\le b]$ for specified integers $a$ and $b$ with $a \\le b$, where $S_n$ is the sum of $n$ independent copies of the base die.\n- Numerically stabilize the inverse FFT result by discarding negligible imaginary parts, clipping tiny negative values to zero when caused by numerical round-off, and renormalizing to sum to $1$.\n\nTest suite to implement in the program (no user input; hard-code these cases):\n- Case A (happy path): Base die is fair with $m = 6$ and $p_k = 1/6$ for $k \\in \\{1,\\dots,6\\}$, with $n = 10$. Compute the point probability $\\mathbb{P}[S_{10} = 35]$.\n- Case B (boundary: minimum sum): Same fair die, $n = 10$. Compute $\\mathbb{P}[S_{10} = 10]$.\n- Case C (boundary: maximum sum): Same fair die, $n = 10$. Compute $\\mathbb{P}[S_{10} = 60]$.\n- Case D (edge case: zero dice): Same fair die, $n = 0$. Compute $\\mathbb{P}[S_{0} = 0]$.\n- Case E (biased die): Base die is biased with $m = 6$ and $p = [0.05, 0.15, 0.20, 0.20, 0.20, 0.20]$ corresponding to faces $\\{1,2,3,4,5,6\\}$ respectively, with $n = 3$. Compute $\\mathbb{P}[S_{3} = 10]$.\n- Case F (different die size): Base die is fair with $m = 4$ and $p_k = 1/4$ for $k \\in \\{1,2,3,4\\}$, with $n = 5$. Compute $\\mathbb{P}[S_{5} = 10]$.\n- Case G (interval probability): Same fair $6$-sided die, $n = 20$. Compute the interval probability $\\mathbb{P}[60 \\le S_{20} \\le 70]$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results for Cases A through G, in order, as a comma-separated list of floating-point numbers enclosed in square brackets.\n- Express each probability as a decimal rounded to exactly $12$ digits after the decimal point.\n- The output must be precisely of the form $[r_A,r_B,r_C,r_D,r_E,r_F,r_G]$ with no spaces, where each $r_\\cdot$ is a float formatted with exactly $12$ digits after the decimal point.\n\nNo physical units or angle units apply in this problem. All answers are pure probabilities in $\\mathbb{R}$.\n\nConstraints and additional requirements:\n- You must employ the Convolution Theorem with the Fast Fourier Transform (FFT) to obtain the $n$-fold convolution; direct repeated time-domain convolution or enumeration is not permitted.\n- Ensure that the transform length you choose is the smallest that avoids circular aliasing for the $n$-fold linear convolution, and justify this choice in your solution reasoning.\n- The code must be self-contained, use only the standard library and allowed libraries, and produce the exact output format described above.", "solution": "The problem is valid as it is scientifically grounded in probability theory and numerical methods, is well-posed, and provides a complete and consistent set of requirements and data.\n\nThe core of the problem is to compute the probability mass function (PMF) of a sum of $n$ independent and identically distributed (i.i.d.) discrete random variables, $S_n = \\sum_{i=1}^{n} X_i$. Each random variable $X_i$ represents the outcome of a single die roll with $m$ faces, taking integer values in the set $\\{1, 2, \\dots, m\\}$. The PMF of $X_i$ is a given sequence $p_X(k) = \\mathbb{P}[X_i = k]$.\n\nAccording to probability theory, the PMF of the sum of two independent random variables is the convolution of their individual PMFs. By extension, the PMF of $S_n$, denoted as $p_{S_n}$, is the $n$-fold convolution of the base PMF $p_X$ with itself:\n$$\np_{S_n} = \\underbrace{p_X * p_X * \\dots * p_X}_{n \\text{ times}} \\equiv p_X^{*n}\n$$\nwhere the discrete convolution $(f * g)(k)$ is defined as $(f * g)(k) = \\sum_{j} f(j) g(k-j)$. A direct computation of this $n$-fold convolution is computationally expensive, with a complexity that grows rapidly with $n$.\n\nThe Convolution Theorem provides a more efficient method using the Discrete Fourier Transform (DFT). The theorem states that the DFT of a convolution of two sequences is the element-wise product of their individual DFTs. Let $\\mathcal{F}$ denote the DFT operator. Then,\n$$\n\\mathcal{F}\\{f * g\\} = \\mathcal{F}\\{f\\} \\cdot \\mathcal{F}\\{g\\}\n$$\nApplying this theorem recursively to the $n$-fold convolution gives:\n$$\n\\mathcal{F}\\{p_{S_n}\\} = \\mathcal{F}\\{p_X^{*n}\\} = (\\mathcal{F}\\{p_X\\})^n\n$$\nTherefore, the desired PMF $p_{S_n}$ can be obtained by computing the inverse DFT (IDFT), denoted $\\mathcal{F}^{-1}$, of the $n$-th power of the DFT of the base PMF:\n$$\np_{S_n} = \\mathcal{F}^{-1}\\left\\{ (\\mathcal{F}\\{p_X\\})^n \\right\\}\n$$\nThe Fast Fourier Transform (FFT) is an efficient algorithm for computing the DFT and its inverse, which we will employ.\n\nA critical aspect of using the DFT for convolution is the distinction between linear and circular convolution. The DFT inherently computes a circular convolution. To obtain the correct linear convolution result, the input sequences must be zero-padded to a sufficient length before the transform. Let the base PMF $p_X$ be non-zero for $m$ outcomes. We can represent this as a sequence of length $m$. The linear convolution of two sequences of lengths $L_1$ and $L_2$ results in a sequence of length $L_1 + L_2 - 1$. For an $n$-fold convolution of a sequence of length $m$, the resulting sequence has a length of $L_n = n(m-1) + 1$. To prevent circular aliasing (wrap-around error), the transform length $N$ for the DFT must be at least this long: $N \\ge n(m-1) + 1$. The problem requires the smallest valid padding length, so we will choose the transform length $N$ to be exactly $N = n(m-1) + 1$.\n\nThe algorithmic procedure is as follows:\n$1.$ **Represent the Base PMF**: The PMF for a single die with outcomes $\\{1, \\dots, m\\}$ is represented as a sequence $p$ of length $m$, where $p[k-1] = \\mathbb{P}[X=k]$.\n$2.$ **Handle Edge Cases**:\n   - If $n=1$, the PMF is simply the base PMF $p_X$.\n   - If $n=0$, the \"sum of zero variables\" is by convention a random variable that is a point mass at $0$. So, $\\mathbb{P}[S_0=0] = 1$. The algorithm will handle this as a special case.\n$3.$ **Determine Transform Length**: For $n>1$, calculate the required length of the resulting PMF, which is also the minimum transform length: $N = n(m-1) + 1$.\n$4.$ **Forward FFT**: Zero-pad the base PMF sequence $p$ to length $N$ and compute its DFT using the FFT algorithm: $\\hat{p} = \\text{FFT}(p_{\\text{padded}}, N)$.\n$5.$ **Exponentiation in Frequency Domain**: Raise each element of the resulting frequency-domain spectrum to the power of $n$: $\\hat{p}_{S_n} = (\\hat{p})^n$.\n$6.$ **Inverse FFT**: Compute the inverse DFT of $\\hat{p}_{S_n}$ to obtain the final PMF in the time domain: $p_{S_n, \\text{raw}} = \\text{IFFT}(\\hat{p}_{S_n})$.\n$7.$ **Numerical Stabilization**: The result of the IFFT may contain small non-zero imaginary parts and negative real values due to floating-point precision errors.\n   - Discard the imaginary component: $p_{S_n} = \\text{Re}(p_{S_n, \\text{raw}})$.\n   - Clip any small negative values to zero: $p_{S_n}[p_{S_n} < 0] = 0$.\n   - Renormalize the PMF to ensure its elements sum to exactly $1$: $p_{S_n} = p_{S_n} / \\sum p_{S_n}$.\n$8.$ **Interpret the Result**: The resulting array $p_{S_n}$ is the PMF of the sum $S_n$. The sum $S_n$ can take values from $s_{\\min} = n \\times 1 = n$ to $s_{\\max} = n \\times m$. The calculated PMF array $p_{S_n}$ has length $N=n(m-1)+1$. The element $p_{S_n}[k]$ corresponds to the probability $\\mathbb{P}[S_n = s]$ where the sum $s$ is related to the index $k$ by $s = k + n$. Inversely, to find the probability for a sum $s$, we access the element at index $k=s-n$.\n   - A point probability $\\mathbb{P}[S_n=s]$ is found by accessing $p_{S_n}[s-n]$, provided $n \\le s \\le nm$.\n   - An interval probability $\\mathbb{P}[a \\le S_n \\le b]$ is found by summing the elements from index $a-n$ to $b-n$: $\\sum_{s=a}^{b} p_{S_n}[s-n]$.\nThis procedure provides a computationally efficient and robust method to solve the problem for all specified test cases.", "answer": "```python\nimport numpy as np\nfrom scipy import fft\n\ndef compute_dice_sum_pmf(pmf_base, n):\n    \"\"\"\n    Computes the PMF of the sum of n i.i.d. dice rolls using FFT-based convolution.\n\n    Args:\n        pmf_base (list or np.ndarray): The PMF of a single die roll for outcomes 1, 2, ..., m.\n        n (int): The number of dice to sum.\n\n    Returns:\n        tuple: A tuple containing:\n            - pmf_sum (np.ndarray): The resulting PMF of the sum.\n            - min_sum (int): The minimum possible sum.\n    \"\"\"\n    m = len(pmf_base)\n    \n    # Handle the edge case of n=0 dice. The sum is deterministically 0.\n    if n == 0:\n        return np.array([1.0]), 0\n\n    # The minimum possible sum is n*1 = n.\n    min_sum = n\n    \n    # For n=1, the PMF is just the base PMF.\n    if n == 1:\n        return np.array(pmf_base), min_sum\n\n    # Calculate the minimal transform length to avoid circular convolution.\n    # The length of the n-fold linear convolution of a sequence of length m is n*(m-1) + 1.\n    transform_length = n * (m - 1) + 1\n\n    # Perform FFT on the zero-padded base PMF.\n    # The 'n' argument in scipy.fft.fft handles the zero-padding.\n    fft_base = fft.fft(pmf_base, n=transform_length)\n\n    # Apply the convolution theorem: DFT of convolution is product of DFTs.\n    # For n-fold self-convolution, this becomes the n-th power of the DFT.\n    fft_sum = fft_base ** n\n\n    # Perform inverse FFT to get the convolved PMF back in the time domain.\n    pmf_sum_raw = fft.ifft(fft_sum)\n\n    # --- Numerical Stabilization ---\n    # 1. The result should be real; discard negligible imaginary parts.\n    pmf_sum = pmf_sum_raw.real\n\n    # 2. Clip tiny negative values resulting from floating-point errors.\n    pmf_sum = np.clip(pmf_sum, 0, None)\n\n    # 3. Renormalize to ensure the PMF sums to 1.\n    total_prob = np.sum(pmf_sum)\n    if total_prob > 0:\n        pmf_sum /= total_prob\n    \n    return pmf_sum, min_sum\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define base PMFs for the dice used in test cases.\n    fair_6_sided_pmf = np.full(6, 1/6)\n    biased_6_sided_pmf = np.array([0.05, 0.15, 0.20, 0.20, 0.20, 0.20])\n    fair_4_sided_pmf = np.full(4, 1/4)\n\n    # Test suite definition: (pmf_base, n, query_type, query_value)\n    # query_type can be 'point' or 'interval'.\n    # query_value is an integer for 'point' or a tuple (a, b) for 'interval'.\n    test_cases = [\n        # Case A: Fair 6-sided, n=10, P(S_10 = 35)\n        (fair_6_sided_pmf, 10, 'point', 35),\n        # Case B: Fair 6-sided, n=10, P(S_10 = 10)\n        (fair_6_sided_pmf, 10, 'point', 10),\n        # Case C: Fair 6-sided, n=10, P(S_10 = 60)\n        (fair_6_sided_pmf, 10, 'point', 60),\n        # Case D: Fair 6-sided, n=0, P(S_0 = 0)\n        (fair_6_sided_pmf, 0, 'point', 0),\n        # Case E: Biased 6-sided, n=3, P(S_3 = 10)\n        (biased_6_sided_pmf, 3, 'point', 10),\n        # Case F: Fair 4-sided, n=5, P(S_5 = 10)\n        (fair_4_sided_pmf, 5, 'point', 10),\n        # Case G: Fair 6-sided, n=20, P(60 <= S_20 <= 70)\n        (fair_6_sided_pmf, 20, 'interval', (60, 70)),\n    ]\n\n    results = []\n    for pmf_base, n, query_type, query_value in test_cases:\n        pmf_sum, min_sum = compute_dice_sum_pmf(pmf_base, n)\n        \n        m = len(pmf_base)\n        max_sum = n * m\n        \n        result = 0.0\n        if query_type == 'point':\n            s = query_value\n            # Check if sum s is within the possible range [min_sum, max_sum].\n            if min_sum <= s <= max_sum:\n                # The index corresponding to sum s is s - min_sum.\n                index = s - min_sum\n                result = pmf_sum[index]\n        elif query_type == 'interval':\n            a, b = query_value\n            # Clamp the interval to the valid range of sums.\n            start_s = max(a, min_sum)\n            end_s = min(b, max_sum)\n\n            if start_s <= end_s:\n                start_index = start_s - min_sum\n                end_index = end_s - min_sum\n                # Sum the probabilities in the specified range (inclusive).\n                result = np.sum(pmf_sum[start_index : end_index + 1])\n        \n        results.append(result)\n\n    # Format the final output as specified.\n    output_str = \",\".join(f\"{r:.12f}\" for r in results)\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "2383106"}, {"introduction": "We conclude by exploring a powerful, real-world application of the convolution theorem in scientific data analysis: matched filtering. This technique is essential for detecting a known signal or \"template\" buried in noisy data, a common challenge in fields from astrophysics to engineering. In this practice, you will discover how to transform a brute-force search for the best-fitting signal—minimizing the chi-squared statistic $\\chi^2$ across all possible time shifts—into a highly efficient cross-correlation computation solvable with the FFT. [@problem_id:2383038]", "problem": "You are given two real-valued, finite, discrete time series of equal length $N$, a data sequence $d = \\{d_n\\}_{n=0}^{N-1}$ and a template sequence $h = \\{h_n\\}_{n=0}^{N-1}$. Consider the circularly shifted model $m_n(\\tau, A) = A \\, h_{(n-\\tau) \\bmod N}$ with shift $\\tau \\in \\{0,1,\\dots,N-1\\}$ and real amplitude $A \\in \\mathbb{R}$. For each shift $\\tau$, define the chi-squared\n$$\n\\chi^2(\\tau) = \\sum_{n=0}^{N-1} \\frac{\\left(d_n - A_{\\star}(\\tau) \\, h_{(n-\\tau) \\bmod N}\\right)^2}{\\sigma^2},\n$$\nwhere $\\sigma^2$ is a known, uniform variance and $A_{\\star}(\\tau)$ is the amplitude that minimizes $\\chi^2(\\tau)$ for that fixed $\\tau$. If $\\sum_{n=0}^{N-1} h_n^2 = 0$, interpret $A_{\\star}(\\tau)$ as $0$ for all $\\tau$ and $\\chi^2(\\tau) = \\sum_{n=0}^{N-1} d_n^2 / \\sigma^2$. If multiple shifts $\\tau$ attain the same minimal value of $\\chi^2(\\tau)$, select the smallest such $\\tau$.\n\nYour task is to compute, for each of the following test cases, the shift $\\tau_{\\min}$ that minimizes $\\chi^2(\\tau)$, the corresponding minimal value $\\chi^2_{\\min}$, and the corresponding best-fit amplitude $A_{\\star}(\\tau_{\\min})]$. Use $N=8$ and $\\sigma^2 = 1$ for all cases. All sequences are to be interpreted with circular indexing modulo $N$.\n\nTest Suite:\n1) Happy-path (nontrivial template and shift):\n$$\nN = 8, \\quad \\sigma^2 = 1, \\quad h = [0,1,2,3,2,1,0,0], \\quad d = [2,0,0,0,2,4,6,4].\n$$\n\n2) Boundary (alternating sequence, exact negative match):\n$$\nN = 8, \\quad \\sigma^2 = 1, \\quad h = [1,-1,1,-1,1,-1,1,-1], \\quad d = [-1,1,-1,1,-1,1,-1,1].\n$$\n\n3) Edge case (zero template):\n$$\nN = 8, \\quad \\sigma^2 = 1, \\quad h = [0,0,0,0,0,0,0,0], \\quad d = [3,-1,4,1,5,-9,2,6].\n$$\n\n4) General case (periodic template, fractional amplitude):\n$$\nN = 8, \\quad \\sigma^2 = 1, \\quad h = [0,1,0,-1,0,1,0,-1], \\quad d = [0,-0.5,0,0.5,0,-0.5,0,0.5].\n$$\n\nFor each test case, your program must output a list of three values $[\\tau_{\\min}, \\chi^2_{\\min}, A_{\\star}(\\tau_{\\min})]$, where $\\tau_{\\min}$ is an integer, and the two floating-point values are rounded to six decimal places. Your program should produce a single line of output containing the results for all four test cases as a comma-separated list of these per-case lists, enclosed in square brackets, with no spaces. For example, an output with two hypothetical cases would look like\n$$\n[[\\tau_1,\\chi^2_1,A_1],[\\tau_2,\\chi^2_2,A_2]].\n$$", "solution": "We start from the least-squares definition. For a fixed shift $\\tau$, define\n$$\n\\chi^2(\\tau;A) = \\sum_{n=0}^{N-1} \\frac{\\left(d_n - A \\, h_{(n-\\tau) \\bmod N}\\right)^2}{\\sigma^2}.\n$$\nWith uniform variance $\\sigma^2 = 1$, the minimizing amplitude $A_{\\star}(\\tau)$ is obtained by setting the derivative with respect to $A$ to zero:\n$$\n\\frac{\\partial}{\\partial A} \\chi^2(\\tau;A) = -2 \\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N} + 2 A \\sum_{n=0}^{N-1} h_{(n-\\tau) \\bmod N}^2 = 0.\n$$\nBecause circular shifts preserve the squared norm, $\\sum_{n=0}^{N-1} h_{(n-\\tau) \\bmod N}^2 = \\sum_{n=0}^{N-1} h_n^2 \\equiv \\|h\\|^2$. Thus, if $\\|h\\|^2 > 0$,\n$$\nA_{\\star}(\\tau) = \\frac{\\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N}}{\\|h\\|^2}.\n$$\nSubstituting $A_{\\star}(\\tau)$ back into $\\chi^2$ and expanding yields\n$$\n\\chi^2(\\tau) = \\sum_{n=0}^{N-1} d_n^2 - \\frac{\\left(\\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N}\\right)^2}{\\|h\\|^2}.\n$$\nIf $\\|h\\|^2 = 0$, we follow the stated convention $A_{\\star}(\\tau)=0$ for all $\\tau$ and $\\chi^2(\\tau)=\\sum_{n=0}^{N-1} d_n^2$.\n\nThe quantity $\\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N}$ is the circular cross-correlation of $d$ with $h$ at lag $\\tau$. Denote\n$$\nc(\\tau) \\equiv \\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N}.\n$$\nBy the convolution theorem, $c(\\tau)$ can be computed for all $\\tau$ using the Discrete Fourier Transform (DFT) efficiently via the Fast Fourier Transform (FFT). With the DFT convention\n$$\nD_k = \\sum_{n=0}^{N-1} d_n \\, e^{-2\\pi i k n / N}, \\quad H_k = \\sum_{n=0}^{N-1} h_n \\, e^{-2\\pi i k n / N},\n$$\nthe inverse DFT gives\n$$\nc(\\tau) = \\operatorname{IDFT}\\left(D_k \\, \\overline{H_k}\\right)_\\tau = \\frac{1}{N} \\sum_{k=0}^{N-1} D_k \\, \\overline{H_k} \\, e^{2\\pi i k \\tau / N}.\n$$\nA direct derivation shows\n$$\n\\operatorname{IDFT}\\left(D_k \\, \\overline{H_k}\\right)_\\tau = \\sum_{n=0}^{N-1} d_n \\, h_{(n-\\tau) \\bmod N},\n$$\nwhich is exactly the desired circular cross-correlation. Therefore, we can compute the entire correlation sequence $c(\\tau)$ in $\\mathcal{O}(N \\log N)$ time via one forward FFT of $d$, one forward FFT of $h$, pointwise multiplication by the complex conjugate, and one inverse FFT.\n\nAlgorithmic steps:\n1) Compute $\\|h\\|^2 = \\sum_{n=0}^{N-1} h_n^2$ and $\\|d\\|^2 = \\sum_{n=0}^{N-1} d_n^2$.\n2) If $\\|h\\|^2 = 0$, set $A_{\\star}(\\tau)=0$ and $\\chi^2(\\tau)=\\|d\\|^2$ for all $\\tau$.\n3) Otherwise, compute $c(\\tau)$ via the convolution theorem using the FFT. Then for each $\\tau$,\n$$\nA_{\\star}(\\tau) = \\frac{c(\\tau)}{\\|h\\|^2}, \\quad \\chi^2(\\tau) = \\|d\\|^2 - \\frac{c(\\tau)^2}{\\|h\\|^2}.\n$$\n4) Find $\\tau_{\\min}$ that minimizes $\\chi^2(\\tau)$; break ties by choosing the smallest $\\tau$.\n5) Report $[\\tau_{\\min}, \\chi^2_{\\min}, A_{\\star}(\\tau_{\\min})]$ with the floating-point entries rounded to six decimal places.\n\nApplying to the provided test suite:\n\nCase $1$: $h = [0,1,2,3,2,1,0,0]$, $d = [2,0,0,0,2,4,6,4]$.\nWe have $\\|h\\|^2 = 19$ and $\\|d\\|^2 = 76$. The cross-correlation attains its maximum at $\\tau=3$ with $c(3) = 38$, giving $A_{\\star}(3) = 38/19 = 2$ and $\\chi^2_{\\min} = 76 - 38^2/19 = 0$.\n\nCase $2$: $h = [1,-1,1,-1,1,-1,1,-1]$, $d = [-1,1,-1,1,-1,1,-1,1]$.\nHere $\\|h\\|^2 = 8$, $\\|d\\|^2 = 8$. For all $\\tau$, $c(\\tau) \\in \\{\\pm 8\\}$ so $\\chi^2(\\tau) = 8 - 64/8 = 0$ for every $\\tau$. We select the smallest index $\\tau_{\\min} = 0$, with $A_{\\star}(0) = -1$.\n\nCase $3$: $h = [0,0,0,0,0,0,0,0]$, $d = [3,-1,4,1,5,-9,2,6]$.\nThen $\\|h\\|^2 = 0$, so by convention $A_{\\star}(\\tau) = 0$ and $\\chi^2(\\tau) = \\|d\\|^2 = 173$ for all $\\tau$. We choose $\\tau_{\\min} = 0$ and $A_{\\star}(0) = 0$.\n\nCase $4$: $h = [0,1,0,-1,0,1,0,-1]$, $d = [0,-0.5,0,0.5,0,-0.5,0,0.5]$.\nWe have $\\|h\\|^2 = 4$, $\\|d\\|^2 = 1$. The cross-correlation peaks at $\\tau=2$ with $c(2)=2$, yielding $A_{\\star}(2) = 2/4 = 0.5$ and $\\chi^2_{\\min} = 1 - 4/4 = 0$.\n\nRounded to six decimals, the expected per-case outputs are\n$$\n[3, 0.000000, 2.000000], \\quad [0, 0.000000, -1.000000], \\quad [0, 173.000000, 0.000000], \\quad [2, 0.000000, 0.500000].\n$$\nAggregated into a single line as required:\n$$\n[[3,0.000000,2.000000],[0,0.000000,-1.000000],[0,173.000000,0.000000],[2,0.000000,0.500000]].\n$$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_min_chi2_shift(d, h):\n    \"\"\"\n    Given data d and template h (both length N), compute for circular shifts tau:\n    - A_hat(tau) = argmin_A sum (d_n - A h_{n - tau})^2\n    - chi2(tau) = min value at A_hat(tau) with sigma^2 = 1\n    Return (tau_min, chi2_min, A_hat_at_tau_min), breaking ties by smallest tau.\n    \"\"\"\n    d = np.asarray(d, dtype=np.float64)\n    h = np.asarray(h, dtype=np.float64)\n    N = d.size\n    assert h.size == N, \"d and h must have the same length\"\n\n    norm_h2 = float(np.dot(h, h))\n    norm_d2 = float(np.dot(d, d))\n\n    if norm_h2 == 0.0:\n        # Degenerate case: A_hat(tau)=0 and chi2(tau)=norm_d2 for all tau\n        tau_min = 0\n        chi2_min = norm_d2\n        A_hat_min = 0.0\n        return tau_min, chi2_min, A_hat_min\n\n    # Compute circular cross-correlation c[tau] = sum_n d_n h_{n - tau}\n    D = np.fft.fft(d)\n    H = np.fft.fft(h)\n    c = np.fft.ifft(D * np.conj(H))\n    # Numerical errors may leave tiny imaginary parts\n    c = np.real(c)\n\n    # Compute chi2(tau) = ||d||^2 - c[tau]^2 / ||h||^2\n    chi2 = norm_d2 - (c * c) / norm_h2\n    # Guard against tiny negative due to numerical precision\n    chi2 = np.maximum(chi2, 0.0)\n\n    tau_min = int(np.argmin(chi2))\n    chi2_min = float(chi2[tau_min])\n    A_hat_min = float(c[tau_min] / norm_h2)\n\n    return tau_min, chi2_min, A_hat_min\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            [2, 0, 0, 0, 2, 4, 6, 4],\n            [0, 1, 2, 3, 2, 1, 0, 0]\n        ),\n        # Case 2\n        (\n            [-1, 1, -1, 1, -1, 1, -1, 1],\n            [1, -1, 1, -1, 1, -1, 1, -1]\n        ),\n        # Case 3\n        (\n            [3, -1, 4, 1, 5, -9, 2, 6],\n            [0, 0, 0, 0, 0, 0, 0, 0]\n        ),\n        # Case 4\n        (\n            [0.0, -0.5, 0.0, 0.5, 0.0, -0.5, 0.0, 0.5],\n            [0, 1, 0, -1, 0, 1, 0, -1]\n        ),\n    ]\n\n    results = []\n    for d, h in test_cases:\n        tau_min, chi2_min, A_hat_min = compute_min_chi2_shift(d, h)\n        # Format with required rounding for floats\n        results.append([tau_min, f\"{chi2_min:.6f}\", f\"{A_hat_min:.6f}\"])\n\n    # Build the exact required single-line output without spaces\n    inner = \",\".join(\"[\" + \",\".join([str(r[0]), r[1], r[2]]) + \"]\" for r in results)\n    print(f\"[{inner}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2383038"}]}