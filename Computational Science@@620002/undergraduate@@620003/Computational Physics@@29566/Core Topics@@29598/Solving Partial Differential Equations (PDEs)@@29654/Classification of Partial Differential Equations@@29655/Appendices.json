{"hands_on_practices": [{"introduction": "Many fundamental laws of physics are expressed as systems of first-order partial differential equations. A crucial skill is to combine these systems into a single higher-order equation, whose type reveals the physical character of the system. This exercise [@problem_id:2380226] provides hands-on practice in this process, guiding you to derive a second-order PDE and classify it using the discriminant, connecting the abstract mathematical form to concrete physical behavior like wave propagation.", "problem": "Consider smooth scalar fields $u(x,t)$ and $v(x,t)$ on $\\mathbb{R} \\times \\mathbb{R}$ that satisfy the first-order system\n$$\nu_{t} = v_{x}, \\qquad v_{t} = u_{x}.\n$$\nDerive a single second-order Partial Differential Equation (PDE) for $u(x,t)$ alone. Then express that PDE in the standard second-order form\n$$\nA\\,u_{xx} + 2 B\\,u_{xt} + C\\,u_{tt} + \\text{(lower-order terms)} = 0\n$$\nand report the value of the discriminant $B^{2} - A C$. Provide your final answer as this discriminant value. Do not include any units, and do not include the classification name in your final answer.", "solution": "The problem as stated is valid. It is a well-posed mathematical exercise in the field of partial differential equations, free of any scientific or logical inconsistencies. We shall proceed with the derivation.\n\nWe are given a system of two first-order partial differential equations for two smooth scalar fields, $u(x,t)$ and $v(x,t)$:\n$$\nu_{t} = v_{x} \\quad (1)\n$$\n$$\nv_{t} = u_{x} \\quad (2)\n$$\nOur objective is to derive a single second-order PDE for the field $u(x,t)$ and then determine the value of its discriminant. To eliminate the field $v(x,t)$ from the system, we differentiate the given equations.\n\nFirst, we differentiate equation $(1)$ with respect to the variable $t$:\n$$\n\\frac{\\partial}{\\partial t}(u_{t}) = \\frac{\\partial}{\\partial t}(v_{x})\n$$\nThis gives us the second partial derivative of $u$ with respect to $t$ on the left-hand side, and a mixed partial derivative of $v$ on the right-hand side:\n$$\nu_{tt} = v_{xt} \\quad (3)\n$$\nNext, we differentiate equation $(2)$ with respect to the variable $x$:\n$$\n\\frac{\\partial}{\\partial x}(v_{t}) = \\frac{\\partial}{\\partial x}(u_{x})\n$$\nThis yields a mixed partial derivative of $v$ on the left-hand side and the second partial derivative of $u$ with respect to $x$ on the right-hand side:\n$$\nv_{tx} = u_{xx} \\quad (4)\n$$\nThe problem statement specifies that $u(x,t)$ and $v(x,t)$ are \"smooth\" fields. This is a standard term implying that the functions are sufficiently differentiable, at least of class $C^{2}$. According to Clairaut's theorem on the equality of mixed partials, for a $C^{2}$ function $v(x,t)$, the order of differentiation does not matter. Therefore, we have:\n$$\nv_{xt} = v_{tx}\n$$\nUsing this equality, we can equate the left-hand side of equation $(3)$ with the right-hand side of equation $(4)$:\n$$\nu_{tt} = u_{xx}\n$$\nThis is the second-order partial differential equation for $u(x,t)$ alone. To classify this equation, we must write it in the standard form provided in the problem statement:\n$$\nA\\,u_{xx} + 2 B\\,u_{xt} + C\\,u_{tt} + \\text{(lower-order terms)} = 0\n$$\nRearranging our derived equation $u_{tt} = u_{xx}$ gives:\n$$\nu_{xx} - u_{tt} = 0\n$$\nOr, to be more explicit in matching the standard form:\n$$\n(1)u_{xx} + (0)u_{xt} + (-1)u_{tt} = 0\n$$\nBy comparing this to the standard form, we can identify the coefficients $A$, $B$, and $C$:\n- The coefficient of $u_{xx}$ is $A = 1$.\n- The coefficient of $u_{xt}$ is $2B = 0$, which implies $B = 0$.\n- The coefficient of $u_{tt}$ is $C = -1$.\n\nThe final step is to calculate the discriminant, which is defined as $B^{2} - A C$. Substituting the values we have found for $A$, $B$, and $C$:\n$$\nB^{2} - A C = (0)^{2} - (1)(-1)\n$$\n$$\nB^{2} - A C = 0 - (-1)\n$$\n$$\nB^{2} - A C = 1\n$$\nThe value of the discriminant is $1$. This confirms the equation is of hyperbolic type, although the problem explicitly asks not to state the classification.", "answer": "$$\\boxed{1}$$", "id": "2380226"}, {"introduction": "The type of a partial differential equation is not always constant; in many physical systems, the coefficients depend on position, causing the equation's character to change across the domain. This practice [@problem_id:2380287] explores such a 'mixed-type' scenario, where you will analyze the discriminant as a function of the coordinates $(x,y)$ to map out the elliptic, parabolic, and hyperbolic regions. This skill is vital for understanding and numerically solving problems where the underlying physics varies, such as in transonic fluid dynamics or general relativity.", "problem": "Consider the second-order linear partial differential equation (PDE)\n$$(x^{2}-1)\\,u_{xx} + 2\\,x y\\,u_{xy} + (y^{2}-1)\\,u_{yy} = 0,$$\nposed on the entire $\\mathbb{R}^{2}$, where $u=u(x,y)$ is twice continuously differentiable. Classify this PDE as elliptic, parabolic, or hyperbolic in different regions of the $x y$-plane by analyzing its principal part from first principles. Identify the precise boundary curve that separates regions of different type and specify which side of this boundary corresponds to each type.\n\nYour final reported answer must be a single simplified analytic expression in the variables $x$ and $y$ whose zero level set is exactly the classification boundary you identify. No units are involved. Do not provide inequalities or piecewise descriptions in the final reported answer.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   The partial differential equation is given as $(x^{2}-1)\\,u_{xx} + 2\\,x y\\,u_{xy} + (y^{2}-1)\\,u_{yy} = 0$.\n-   The domain is specified as the entire plane $\\mathbb{R}^{2}$.\n-   The function $u(x,y)$ is stated to be twice continuously differentiable.\n-   The task is to classify the equation as elliptic, parabolic, or hyperbolic in different regions of the $xy$-plane.\n-   The task requires identification of the boundary curve separating these regions and specification of which side of the boundary corresponds to each type.\n-   The final answer must be a single analytic expression whose zero level set is the classification boundary.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is a standard exercise in the mathematical theory of partial differential equations. The classification of second-order linear PDEs based on the discriminant of the principal part is a fundamental and well-established concept. The problem is scientifically sound.\n-   **Well-Posedness**: The problem is completely specified. The equation is provided, and the classification procedure is unique and deterministic. A unique solution to the classification problem exists.\n-   **Objectivity**: The problem is stated using precise mathematical language, free from ambiguity or subjective interpretation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically grounded question within the domain of partial differential equations. I will proceed with the solution.\n\nThe classification of a general second-order linear partial differential equation in two variables, written in the form\n$$A(x,y) u_{xx} + 2B(x,y) u_{xy} + C(x,y) u_{yy} + \\dots = 0,$$\ndepends on the sign of the discriminant of its principal part, which is defined as $\\Delta(x,y) = B(x,y)^{2} - A(x,y)C(x,y)$. The type of the equation at a point $(x,y)$ is determined as follows:\n-   If $\\Delta > 0$, the equation is hyperbolic.\n-   If $\\Delta = 0$, the equation is parabolic.\n-   If $\\Delta  0$, the equation is elliptic.\n\nThe given equation is\n$$(x^{2}-1)\\,u_{xx} + 2(xy)\\,u_{xy} + (y^{2}-1)\\,u_{yy} = 0.$$\nBy comparing this with the general form, we identify the coefficients:\n-   $A(x,y) = x^{2}-1$\n-   $B(x,y) = xy$\n-   $C(x,y) = y^{2}-1$\n\nNow, we compute the discriminant $\\Delta(x,y)$:\n$$\n\\Delta = B^{2} - AC = (xy)^{2} - (x^{2}-1)(y^{2}-1)\n$$\nExpanding the terms, we get:\n$$\n\\Delta = x^{2}y^{2} - (x^{2}y^{2} - x^{2} - y^{2} + 1)\n$$\n$$\n\\Delta = x^{2}y^{2} - x^{2}y^{2} + x^{2} + y^{2} - 1\n$$\n$$\n\\Delta = x^{2} + y^{2} - 1\n$$\nThe sign of $\\Delta$ is determined by the sign of the expression $x^{2} + y^{2} - 1$. We analyze the three cases.\n\nCase 1: Hyperbolic region ($\\Delta > 0$)\nThe equation is hyperbolic where $x^{2} + y^{2} - 1 > 0$. This simplifies to:\n$$x^{2} + y^{2} > 1$$\nThis inequality describes the set of all points $(x,y)$ in the plane that are outside the unit circle centered at the origin.\n\nCase 2: Parabolic boundary ($\\Delta = 0$)\nThe equation is parabolic where $x^{2} + y^{2} - 1 = 0$. This simplifies to:\n$$x^{2} + y^{2} = 1$$\nThis is the equation of the unit circle centered at the origin. This curve is the boundary that separates the regions of different types.\n\nCase 3: Elliptic region ($\\Delta  0$)\nThe equation is elliptic where $x^{2} + y^{2} - 1  0$. This simplifies to:\n$$x^{2} + y^{2}  1$$\nThis inequality describes the set of all points $(x,y)$ in the open disk of radius $1$ centered at the origin, which is the region inside the unit circle.\n\nIn summary:\n-   The PDE is **hyperbolic** for all points $(x,y)$ in the region exterior to the unit circle, where $x^{2} + y^{2} > 1$.\n-   The PDE is **parabolic** on the unit circle itself, where $x^{2} + y^{2} = 1$.\n-   The PDE is **elliptic** for all points $(x,y)$ in the region interior to the unit circle, where $x^{2} + y^{2}  1$.\n\nThe problem asks for a single analytic expression whose zero level set is the classification boundary. The boundary is defined by the condition $\\Delta = 0$, which is equivalent to $x^{2} + y^{2} - 1 = 0$. The required expression is therefore $x^{2} + y^{2} - 1$.", "answer": "$$\n\\boxed{x^{2} + y^{2} - 1}\n$$", "id": "2380287"}, {"introduction": "In many scientific endeavors, we are confronted with data from a simulation or experiment without full knowledge of the governing equations. This advanced computational exercise [@problem_id:2380244] tackles this inverse problem, challenging you to determine the type of an unknown PDE based solely on its numerical solution. By analyzing local correlations in the data to estimate the coefficients of the principal part, you will develop a practical algorithm that connects the abstract concept of the discriminant to tangible data analysis, a core skill in modern computational physics.", "problem": "You are given only values of a scalar field $u(x,y)$ sampled on a uniform Cartesian grid, with no direct access to the underlying partial differential equation (PDE). The goal is to use only local correlations of the sampled data to computationally estimate whether the unknown linear, second-order PDE that $u$ plausibly satisfies in the region is elliptic or hyperbolic. The classification refers to the sign of the discriminant $D = B^2 - AC$ of the principal part $A u_{xx} + 2 B u_{xy} + C u_{yy}$: if $D  0$ the PDE is elliptic, and if $D  0$ the PDE is hyperbolic. All computations are dimensionless, and any trigonometric functions must use angles in radians.\n\nConstruct a program that, for each test case below, takes the provided $u(x,y)$ on a uniform grid and outputs an integer label: $+1$ if you estimate the underlying PDE to be elliptic, and $-1$ if you estimate it to be hyperbolic. Your method must rely solely on local data correlations of the sampled field values. No external input is allowed; all data are fully specified below.\n\nGrid specification common to all test cases:\n- Domain: $x \\in [-1,1]$, $y \\in [-1,1]$.\n- Grid size: $N \\times N$ with $N = 61$ uniformly spaced nodes in each direction.\n- Grid spacing: $h = \\dfrac{2}{N-1}$.\n- Coordinates: $(x_i,y_j)$ with $x_i = -1 + (i-1)h$, $y_j = -1 + (j-1)h$, for integer indices $i,j \\in \\{1,2,\\dots,N\\}$.\n\nTest suite of four scalar fields $u(x,y)$:\n- Case $\\#1$ (elliptic prototype): $u_1(x,y) = x^2 - y^2$.\n- Case $\\#2$ (hyperbolic prototype): $u_2(x,y) = \\cos\\!\\big(3 \\pi (x - y)\\big)$.\n- Case $\\#3$ (elliptic, higher-order harmonic): $u_3(x,y) = x^3 - 3 x y^2$.\n- Case $\\#4$ (hyperbolic with smooth contamination): $u_4(x,y) = \\cos\\!\\big(2 \\pi (x - y)\\big) + 0.05 \\cos(4 \\pi x)\\cos(4 \\pi y)$.\n\nRequired output:\n- Produce a single line of output containing the four integer labels in order of the test cases $(\\#1,\\#2,\\#3,\\#4)$, as a comma-separated list enclosed in square brackets, for example $[1,-1,1,-1]$.\n\nYour program must be self-contained and run without user input or external files. The final answers have no physical units, and angles must be in radians. The final output must be a single line exactly in the specified list format. The answer for each test case must be an integer from the set $\\{+1,-1\\}$.", "solution": "The problem as stated is valid. It is a well-posed problem in computational physics, specifically in the domain of system identification for partial differential equations (PDEs). The problem is scientifically grounded, objective, and provides all necessary information to construct a computational solution. There are no contradictions, and the specified test cases are standard examples for the targeted PDE classes.\n\nThe core of the problem is to estimate the type (elliptic or hyperbolic) of an unknown linear, second-order PDE of the form\n$$\nA u_{xx} + 2B u_{xy} + C u_{yy} + \\dots = 0\n$$\ngiven only a discrete sampling of its solution, $u(x,y)$, on a uniform Cartesian grid. The classification depends on the sign of the discriminant $D = B^2 - AC$. The method must be based on \"local data correlations.\"\n\nWe will formalize this requirement by approximating the partial derivatives using finite difference stencils and then identifying the linear algebraic relationship that holds among these approximations. This is a regression problem for the unknown constant coefficients $A$, $B$, and $C$.\n\nLet the grid data be $u_{i,j} = u(x_j, y_i)$, where $i,j \\in \\{0, 1, \\dots, N-1\\}$ are zero-based indices, $N=61$, and the grid spacing is $h = 2/(N-1)$. We approximate the second-order derivatives at interior grid points using second-order accurate central differences. The underlying PDE suggests that a linear combination of these derivatives equals zero (ignoring lower-order terms and source terms, which is a common assumption in discovering the principal part of an equation).\n\nThe discrete operators corresponding to the derivatives are given by applying stencils to the grid data. For an interior point $(i,j)$, where $i,j \\in \\{1, \\dots, N-2\\}$, we define:\n\\begin{align*}\ns_{xx}[u]_{i,j} = u_{i,j+1} - 2u_{i,j} + u_{i,j-1} \\\\\ns_{yy}[u]_{i,j} = u_{i+1,j} - 2u_{i,j} + u_{i,j-1} \\\\\ns_{xy}[u]_{i,j} = u_{i+1,j+1} - u_{i+1,j-1} - u_{i-1,j+1} + u_{i-1,j-1}\n\\end{align*}\nNote that these stencils are proportional to the finite difference approximations of the derivatives:\n$$\nu_{xx} \\approx \\frac{s_{xx}[u]}{h^2}, \\quad u_{yy} \\approx \\frac{s_{yy}[u]}{h^2}, \\quad u_{xy} \\approx \\frac{s_{xy}[u]}{4h^2}\n$$\nSubstituting these into the principal part of the PDE gives:\n$$\nA \\frac{s_{xx}[u]}{h^2} + 2B \\frac{s_{xy}[u]}{4h^2} + C \\frac{s_{yy}[u]}{h^2} \\approx 0\n$$\nMultiplying by $h^2$ yields a relationship between the stencil responses themselves:\n$$\nA s_{xx}[u] + \\frac{B}{2} s_{xy}[u] + C s_{yy}[u] \\approx 0\n$$\nWe seek coefficients $(k_1, k_2, k_3)$ such that $k_1 s_{xx}[u] + k_2 s_{xy}[u] + k_3 s_{yy}[u] \\approx 0$ across the grid. By comparing with the equation above, we can identify $A \\propto k_1$, $B/2 \\propto k_2$, and $C \\propto k_3$. This implies $B \\propto 2k_2$. The discriminant can then be estimated from the sign of:\n$$\nD_{est} \\propto B^2 - AC \\propto (2k_2)^2 - k_1 k_3 = 4k_2^2 - k_1 k_3\n$$\nTo find the coefficients $(k_1, k_2, k_3)$, we treat the stencil responses at all $(N-2)^2$ interior points as vectors. Let $\\mathbf{v}_{xx}$, $\\mathbf{v}_{xy}$, and $\\mathbf{v}_{yy}$ be the flattened vectors of the stencil grids $s_{xx}[u]$, $s_{xy}[u]$, and $s_{yy}[u]$, respectively. The problem is to find a coefficient vector $\\mathbf{k} = [k_1, k_2, k_3]^T$ that minimizes $\\|\\mathbf{v}_{xx} k_1 + \\mathbf{v}_{xy} k_2 + \\mathbf{v}_{yy} k_3 \\|_2^2$, subject to $\\|\\mathbf{k}\\|_2=1$ to avoid the trivial solution $\\mathbf{k}=0$.\n\nThis is a standard total least squares problem. If we form a data matrix $M = [\\mathbf{v}_{xx} | \\mathbf{v}_{xy} | \\mathbf{v}_{yy}]$, the problem is equivalent to minimizing $\\|M \\mathbf{k}\\|_2^2 = \\mathbf{k}^T (M^T M) \\mathbf{k}$. The solution $\\mathbf{k}$ is the eigenvector corresponding to the smallest eigenvalue of the $3 \\times 3$ symmetric matrix $M^T M$. The matrix $M^T M$ is precisely the covariance matrix of the derivative fields, thus this method directly implements the idea of finding \"local data correlations.\"\n\nA special case arises if one of the derivative fields is identically zero (or numerically insignificant), for instance, if $u_{xy}=0$ for the given function $u(x,y)$. In this situation, the corresponding column vector in $M$ would be null. Following the principle of parsimony (Occam's razor), we should seek the simplest PDE. This implies setting the coefficient for the null derivative to zero and solving the reduced regression problem. For example, if $\\mathbf{v}_{xy} \\approx \\mathbf{0}$, we set $k_2=0$ and find the best-fit $[k_1, k_3]$ for the remaining two vectors.\n\nThe complete algorithm is as follows:\n1. For each test case, generate the $N \\times N$ data grid $U$ by sampling the given function $u(x,y)$.\n2. Compute the $(N-2) \\times (N-2)$ stencil response grids $S_{xx}$, $S_{xy}$, and $S_{yy}$.\n3. Flatten these grids into vectors $\\mathbf{v}_{xx}$, $\\mathbf{v}_{xy}$, and $\\mathbf{v}_{yy}$.\n4. A-priori handle trivial derivatives. Calculate the norms of these vectors. If a norm is negligible compared to the maximum norm (e.g., smaller than $10^{-9}$ times the max), its corresponding coefficient is set to zero, and the vector is excluded from the regression analysis.\n5. Form the data matrix $M$ from the non-trivial vectors.\n6. Compute the covariance matrix $C_M = M^T M$.\n7. Find the eigenvalues and eigenvectors of $C_M$. The eigenvector corresponding to the smallest eigenvalue provides the coefficients for the non-trivial derivatives.\n8. Reconstruct the full coefficient vector $\\mathbf{k}=[k_1, k_2, k_3]^T$.\n9. Calculate the discriminant estimate $D_{est} = 4k_2^2 - k_1 k_3$.\n10. Classify the PDE: if $D_{est}  0$, the label is $+1$ (elliptic); otherwise, the label is $-1$ (hyperbolic).\n\nThis procedure provides a robust and objective method for estimating the PDE type from sampled data.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PDE classification problem for the given test cases.\n    \"\"\"\n    N = 61\n    h = 2.0 / (N - 1)\n    \n    # Create the grid coordinates\n    x_coords = np.linspace(-1, 1, N)\n    y_coords = np.linspace(-1, 1, N)\n    x, y = np.meshgrid(x_coords, y_coords, indexing='xy')\n\n    # Define the four test case functions\n    test_functions = [\n        lambda x, y: x**2 - y**2,\n        lambda x, y: np.cos(3 * np.pi * (x - y)),\n        lambda x, y: x**3 - 3 * x * y**2,\n        lambda x, y: np.cos(2 * np.pi * (x - y)) + 0.05 * np.cos(4 * np.pi * x) * np.cos(4 * np.pi * y),\n    ]\n\n    results = []\n    \n    for u_func in test_functions:\n        # 1. Sample the scalar field on the grid\n        U = u_func(x, y)\n\n        # 2. Compute stencil responses on the interior grid\n        # Stencil for u_xx, proportional to s_xx\n        s_xx_grid = U[1:-1, 2:] - 2 * U[1:-1, 1:-1] + U[1:-1, :-2]\n        # Stencil for u_yy, proportional to s_yy\n        s_yy_grid = U[2:, 1:-1] - 2 * U[1:-1, 1:-1] + U[:-2, 1:-1]\n        # Stencil for u_xy, proportional to s_xy\n        s_xy_grid = U[2:, 2:] - U[2:, :-2] - U[:-2, 2:] + U[:-2, :-2]\n\n        # 3. Flatten the stencil grids into vectors\n        v_xx = s_xx_grid.flatten()\n        v_yy = s_yy_grid.flatten()\n        v_xy = s_xy_grid.flatten()\n\n        # 4. Handle trivial derivatives (Principle of Parsimony)\n        norms = np.array([np.linalg.norm(v) for v in [v_xx, v_xy, v_yy]])\n        max_norm = np.max(norms)\n        \n        # Use a relative tolerance to detect null vectors\n        trivial_tol = 1e-9\n        is_trivial = norms  trivial_tol * max_norm if max_norm > 0 else np.ones(3, dtype=bool)\n\n        active_indices = np.where(~is_trivial)[0]\n        active_vectors = [v for i, v in enumerate([v_xx, v_xy, v_yy]) if i in active_indices]\n\n        # 5. Form the data matrix M\n        if not active_vectors:\n            # All derivatives are zero, cannot classify. This should not happen for the given cases.\n            k_full = np.zeros(3)\n        elif len(active_vectors) == 1:\n            # Equation is of the form k*u_deriv = 0, implies k=0. Again, non-physical.\n            k_full = np.zeros(3)\n        else:\n            M = np.stack(active_vectors, axis=1)\n\n            # 6. Compute the covariance-like matrix C_M = M^T * M\n            C_M = M.T @ M\n\n            # 7. Find the eigenvector corresponding to the smallest eigenvalue\n            eigenvalues, eigenvectors = np.linalg.eigh(C_M)\n            k_active = eigenvectors[:, 0]\n\n            # 8. Reconstruct the full coefficient vector\n            k_full = np.zeros(3)\n            k_full[active_indices] = k_active\n        \n        k1, k2, k3 = k_full\n        \n        # 9. Calculate the discriminant\n        # We found coefficients k1, k2, k3 for the linear combination of stencil responses:\n        # k1*s_xx + k2*s_xy + k3*s_yy = 0.\n        # This corresponds to A~k1, B/2~k2, C~k3 in the stencil equation\n        # A*s_xx + (B/2)*s_xy + C*s_yy = 0.\n        # So we identify A=k1, B=2*k2, C=k3 for the PDE form A*u_xx + 2*B*u_xy + C*u_yy = 0.\n        # The discriminant is D = B^2 - A*C.\n        discriminant = (2 * k2)**2 - k1 * k3\n        \n        # 10. Classify and store the result\n        if discriminant  0:\n            results.append(1)  # Elliptic\n        else:\n            results.append(-1) # Hyperbolic (includes Parabolic case D=0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2380244"}]}