{"hands_on_practices": [{"introduction": "This first practice immerses you in the world of active matter by simulating the Vicsek model, a cornerstone for understanding collective motion in systems from bird flocks to bacterial swarms [@problem_id:2422305]. You will implement particle dynamics where individuals align with their neighbors, subject to an angular noise of amplitude $\\eta$. By measuring the global polarization, you will directly observe the non-equilibrium phase transition from disorder to order as $\\eta$ is reduced, gaining key skills in simulating systems far from thermal equilibrium.", "problem": "You must write a complete, runnable program that simulates the Vicsek model of self-propelled particles on a finite, two-dimensional periodic square domain and computes the flocking order parameter for a specified set of cases. All angles must be expressed and implemented in radians. The model must be defined from first principles as follows.\n\nConsider a square domain of side length $L$ with periodic boundary conditions. There are $N$ particles with positions $\\mathbf{r}_i(t) \\in [0,L) \\times [0,L)$ and orientations $\\theta_i(t) \\in \\mathbb{R}$ for $i \\in \\{1,\\dots,N\\}$. Each particle moves with constant speed $v_0$ and its position and orientation are updated synchronously at discrete times $t = 0, \\Delta t, 2 \\Delta t, \\dots$ according to the following rules.\n\n- Initialization at $t=0$: The positions $\\mathbf{r}_i(0)$ are independent and identically distributed uniformly on $[0,L) \\times [0,L)$, and the orientations $\\theta_i(0)$ are independent and identically distributed uniformly on $[-\\pi,\\pi)$.\n\n- Neighborhood under periodic boundary conditions: Let $\\mathbf{r}_i = (x_i,y_i)$ and $\\mathbf{r}_j = (x_j,y_j)$. Define the periodic displacement\n$$\n\\Delta \\mathbf{r}_{ij} = \\left(\\Delta x_{ij}, \\Delta y_{ij}\\right) = \\left(x_i - x_j - L \\,\\mathrm{round}\\!\\left(\\frac{x_i - x_j}{L}\\right),\\; y_i - y_j - L \\,\\mathrm{round}\\!\\left(\\frac{y_i - y_j}{L}\\right)\\right),\n$$\nand the periodic distance\n$$\nd_{ij} = \\sqrt{(\\Delta x_{ij})^2 + (\\Delta y_{ij})^2}.\n$$\nParticle $j$ is a neighbor of particle $i$ if and only if $d_{ij} \\le R$, where $R$ is the interaction radius. By construction, $d_{ii} = 0 \\le R$, so the particle counts itself as its own neighbor.\n\n- Orientation update: Let $\\mathcal{N}_i(t) = \\{ j \\in \\{1,\\dots,N\\} \\mid d_{ij}(t) \\le R \\}$ be the neighbor set of particle $i$ at time $t$. Define the complex unit vectors $u_j(t) = e^{\\mathrm{i}\\theta_j(t)}$. The noiseless mean heading of neighbors is $\\mathrm{Arg}\\!\\left(\\sum_{j \\in \\mathcal{N}_i(t)} u_j(t)\\right)$, where $\\mathrm{Arg}$ denotes the complex argument. The orientation is updated synchronously by\n$$\n\\theta_i(t+\\Delta t) = \\mathrm{Arg}\\!\\left(\\sum_{j \\in \\mathcal{N}_i(t)} e^{\\mathrm{i}\\theta_j(t)}\\right) + \\xi_i(t),\n$$\nwhere $\\xi_i(t)$ are independent random angles sampled uniformly from the interval $[-\\eta/2,\\;\\eta/2]$, and $\\eta \\ge 0$ is the noise amplitude.\n\n- Position update with periodic wrapping:\n$$\n\\mathbf{r}_i(t+\\Delta t) = \\mathbf{r}_i(t) + v_0 \\Delta t \\, \\big(\\cos \\theta_i(t+\\Delta t), \\; \\sin \\theta_i(t+\\Delta t)\\big),\n$$\nwith periodic boundary conditions applied componentwise so that positions remain in $[0,L)$ by wrapping modulo $L$.\n\n- Instantaneous polarization (order parameter) at time $t$:\n$$\n\\Phi(t) = \\frac{1}{N}\\left\\| \\sum_{i=1}^{N} \\big(\\cos \\theta_i(t), \\; \\sin \\theta_i(t)\\big) \\right\\|,\n$$\nwhich takes values in $[0,1]$.\n\n- Time-averaged order parameter after relaxation:\nGiven a total number of steps $T$ and a nonnegative number of discarded transient steps $T_{\\mathrm{disc}}  T$, define the sample set $\\mathcal{S} = \\{ t_k \\mid t_k = k\\Delta t,\\; k \\in \\{T_{\\mathrm{disc}}, T_{\\mathrm{disc}}+1,\\dots, T-1\\} \\}$ consisting of $T - T_{\\mathrm{disc}}$ equally spaced samples. The reported order parameter is the time average\n$$\n\\overline{\\Phi} = \\frac{1}{T - T_{\\mathrm{disc}}} \\sum_{k=T_{\\mathrm{disc}}}^{T-1} \\Phi(k\\Delta t).\n$$\n\nRandomness and reproducibility requirements:\n- For each case in the test suite below, use the provided integer random seed to initialize the pseudorandom number generator that is used for all random draws in that case. The initial positions, initial orientations, and all noise angles must be generated using this seeded generator to ensure deterministic outputs.\n\nAngle unit requirement:\n- All angles must be in radians. The uniform distributions over angles are in radians, and the noise interval is $[-\\eta/2,\\;\\eta/2]$ in radians.\n\nOutput requirement:\n- For each test case, compute a single floating-point number $\\overline{\\Phi}$ as defined above. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, with each value rounded to exactly $6$ decimal places (for example, $\\texttt{[0.912345,0.053210,...]}$). No other text must be printed.\n\nTest suite:\nFor each case, the tuple lists $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed})$.\n\n- Case $1$ (ordered, low noise, moderate density):\n  - $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed}) = (150, 10.0, 1.0, 0.03, 1.0, 0.10, 600, 200, 1)$.\n- Case $2$ (disordered, high noise, same density):\n  - $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed}) = (150, 10.0, 1.0, 0.03, 1.0, 3.00, 600, 200, 2)$.\n- Case $3$ (intermediate noise, near transition regime):\n  - $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed}) = (150, 10.0, 1.0, 0.03, 1.0, 2.00, 600, 200, 3)$.\n- Case $4$ (edge case, self-only interaction radius):\n  - $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed}) = (150, 10.0, 0.0, 0.03, 1.0, 0.50, 600, 200, 4)$.\n- Case $5$ (finite-size effect, small system):\n  - $(N, L, R, v_0, \\Delta t, \\eta, T, T_{\\mathrm{disc}}, \\text{seed}) = (16, 5.0, 1.5, 0.05, 1.0, 0.30, 800, 300, 5)$.\n\nYour program must implement exactly the rules specified above, adhere to the angle unit requirement, use the provided seeds, and produce the final output in the exact required format. The output list must be ordered as $[\\overline{\\Phi}_1,\\overline{\\Phi}_2,\\overline{\\Phi}_3,\\overline{\\Phi}_4,\\overline{\\Phi}_5]$ corresponding to Cases $1$ through $5$, rounded to $6$ decimal places.", "solution": "The problem presented is a well-posed and standard exercise in computational statistical physics. It requires the implementation of the Vicsek model of self-propelled particles, a canonical model for studying collective motion and flocking phenomena. All definitions, parameters, and computational requirements are specified with sufficient precision to permit a unique and reproducible solution. The problem is scientifically sound and algorithmically implementable. We shall proceed with the derivation of the computational algorithm.\n\nThe objective is to compute the time-averaged order parameter, $\\overline{\\Phi}$, for several parameter sets. This requires a direct simulation of the system's dynamics over a specified number of time steps.\n\nThe algorithm is structured as a time-stepping simulation.\n\n1.  **Initialization ($t=0$):**\n    For each test case, a specific integer seed is provided. This seed must be used to initialize a pseudorandom number generator (RNG). This ensures that the simulation is deterministic and the results are reproducible.\n    -   The positions of the $N$ particles, $\\mathbf{r}_i = (x_i, y_i)$, are stored in a numerical array of size $N \\times 2$. Each component $x_i(0)$ and $y_i(0)$ is drawn independently from a uniform distribution over the interval $[0, L)$.\n    -   The orientations of the $N$ particles, $\\theta_i$, are stored in a numerical array of size $N$. Each $\\theta_i(0)$ is drawn independently from a uniform distribution over the interval $[-\\pi, \\pi)$. All angles are treated in radians.\n\n2.  **Simulation Loop:**\n    The system evolves in discrete time steps of size $\\Delta t$. A loop iterates from step $k=0$ to $k=T-1$. At each step, the state of all $N$ particles is updated synchronously. This means we must first compute all new orientations $\\{\\theta_i(t+\\Delta t)\\}$ and only then use these new orientations to update all particle positions $\\{\\mathbf{r}_i(t+\\Delta t)\\}$.\n\n3.  **State Update (from time $t$ to $t+\\Delta t$):**\n    This is the core of the simulation, comprising three sequential operations within each time step.\n\n    a. **Neighborhood Identification:**\n    For each particle $i$, its neighbors $\\mathcal{N}_i(t)$ are all particles $j$ (including itself) such that the periodic distance $d_{ij}(t)$ is less than or equal to the interaction radius $R$. The periodic distance calculation must implement the minimum image convention on the square domain of side length $L$. The displacement vector $\\Delta \\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j$ is calculated, and each component is wrapped into the interval $[-L/2, L/2]$. The specified formula, $\\Delta x' = \\Delta x - L \\cdot \\mathrm{round}(\\Delta x / L)$, achieves this. The distance is then $d_{ij} = \\sqrt{(\\Delta x'_{ij})^2 + (\\Delta y'_{ij})^2}$.\n    Computationally, this is accomplished efficiently by first computing the matrix of all pairwise position differences, $\\mathbf{r}_i - \\mathbf{r}_j$. This yields an $N \\times N \\times 2$ tensor. The periodic boundary condition is applied element-wise. Then, the squared Euclidean norm of each displacement vector is computed, resulting in an $N \\times N$ matrix of squared distances, $D^2_{ij}$. A boolean mask where $D^2_{ij} \\le R^2$ then identifies all neighbor pairs.\n\n    b. **Orientation Update:**\n    The new orientation $\\theta_i(t+\\Delta t)$ is the sum of the local average heading and a random noise term. The average heading is the argument of the sum of complex unit vectors corresponding to the orientations of the neighbors:\n    $$ \\langle \\theta(t) \\rangle_{\\mathcal{N}_i(t)} = \\mathrm{Arg}\\left(\\sum_{j \\in \\mathcal{N}_i(t)} e^{\\mathrm{i}\\theta_j(t)}\\right) = \\mathrm{atan2}\\left(\\sum_{j \\in \\mathcal{N}_i(t)} \\sin\\theta_j(t), \\sum_{j \\in \\mathcal{N}_i(t)} \\cos\\theta_j(t)\\right) $$\n    The noise term $\\xi_i(t)$ is a random variable drawn from the uniform distribution on $[-\\eta/2, \\eta/2]$.\n    The update rule is:\n    $$ \\theta_i(t+\\Delta t) = \\langle \\theta(t) \\rangle_{\\mathcal{N}_i(t)} + \\xi_i(t) $$\n    This operation is performed for all $N$ particles. To maintain synchronicity, the new angles $\\{\\theta_i(t+\\Delta t)\\}$ must be stored in a temporary array and should not overwrite the current angles $\\{\\theta_i(t)\\}$ until all new angles have been computed.\n\n    c. **Position Update:**\n    Each particle moves with constant speed $v_0$ in its new direction $\\theta_i(t+\\Delta t)$. The velocity vector for particle $i$ is $\\mathbf{v}_i(t+\\Delta t) = v_0 (\\cos\\theta_i(t+\\Delta t), \\sin\\theta_i(t+\\Delta t))$. The position is updated as:\n    $$ \\mathbf{r}_i(t+\\Delta t) = \\mathbf{r}_i(t) + \\mathbf{v}_i(t+\\Delta t) \\Delta t $$\n    Periodic boundary conditions are then applied to the components of $\\mathbf{r}_i(t+\\Delta t)$ to ensure they remain within the domain $[0, L)$. This is achieved by taking the result modulo $L$.\n\n4.  **Order Parameter Calculation:**\n    After the state update, if the current step $k$ is $T_{\\mathrm{disc}}$ or greater, the instantaneous polarization (order parameter) $\\Phi(t)$ is calculated. It is the magnitude of the average velocity vector of the whole swarm:\n    $$ \\Phi(t) = \\left\\| \\frac{1}{N} \\sum_{i=1}^N \\mathbf{\\hat{v}}_i(t) \\right\\| = \\frac{1}{N} \\sqrt{\\left(\\sum_{i=1}^N \\cos\\theta_i(t)\\right)^2 + \\left(\\sum_{i=1}^N \\sin\\theta_i(t)\\right)^2} $$\n    where $\\mathbf{\\hat{v}}_i(t) = (\\cos\\theta_i(t), \\sin\\theta_i(t))$. These values of $\\Phi(k\\Delta t)$ for $k \\in \\{T_{\\mathrm{disc}}, \\dots, T-1\\}$ are stored.\n\n5.  **Final Averaging:**\n    After the simulation loop completes, the final result $\\overline{\\Phi}$ is the arithmetic mean of the stored instantaneous order parameter values:\n    $$ \\overline{\\Phi} = \\frac{1}{T - T_{\\mathrm{disc}}} \\sum_{k=T_{\\mathrm{disc}}}^{T-1} \\Phi(k\\Delta t) $$\n    This procedure is repeated for each test case, and the resulting values are formatted as specified. The case with interaction radius $R=0$ is a valid physical limit where each particle only interacts with itself, and its orientation dynamics simplify to a random walk, $\\theta_i(t+\\Delta t) = \\theta_i(t) + \\xi_i(t)$. A correct implementation must handle this case without error.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(N, L, R, v0, dt, eta, T, T_disc, seed):\n    \"\"\"\n    Simulates the Vicsek model for a given set of parameters.\n\n    Args:\n        N (int): Number of particles.\n        L (float): Side length of the square domain.\n        R (float): Interaction radius.\n        v0 (float): Constant speed of particles.\n        dt (float): Time step size.\n        eta (float): Noise amplitude.\n        T (int): Total number of simulation steps.\n        T_disc (int): Number of transient steps to discard.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        float: The time-averaged order parameter over the steady state.\n    \"\"\"\n    # Initialize the pseudo-random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization at t=0\n    # Positions: r is an (N, 2) array, distributed uniformly in [0, L) x [0, L).\n    r = rng.uniform(0, L, size=(N, 2))\n    # Orientations: theta is an (N,) array, distributed uniformly in [-pi, pi).\n    theta = rng.uniform(-np.pi, np.pi, size=N)\n\n    order_params = []\n    R_sq = R**2  # Use squared radius for distance comparison to avoid sqrt.\n\n    # 2. Simulation Loop\n    for t_step in range(T):\n        # 3a. Neighborhood Identification (Vectorized)\n        # Calculate pairwise displacement tensor (N, N, 2).\n        # r[:, np.newaxis, :] - (N, 1, 2)\n        # r[np.newaxis, :, :] - (1, N, 2)\n        # Broadcasting gives all (r_i - r_j) pairs.\n        delta_r = r[:, np.newaxis, :] - r[np.newaxis, :, :]\n\n        # Apply periodic boundary conditions using the minimum image convention.\n        # This wraps displacements into the [-L/2, L/2] interval.\n        delta_r -= L * np.round(delta_r / L)\n\n        # Calculate squared distances (N, N) matrix.\n        dist_sq = np.sum(delta_r**2, axis=-1)\n\n        # Get neighbor mask: True if distance = R.\n        neighbor_mask = (dist_sq = R_sq).astype(float)\n        \n        # 3b. Orientation Update\n        # Convert angles to complex vectors (cos, sin components).\n        vel_vectors = np.stack([np.cos(theta), np.sin(theta)], axis=1)\n\n        # Sum neighbor velocity components using matrix multiplication.\n        # neighbor_mask (N, N) @ vel_vectors (N, 2) - (N, 2)\n        sum_vel = neighbor_mask @ vel_vectors\n        \n        # Calculate mean angles from the sum of vectors.\n        mean_angles = np.arctan2(sum_vel[:, 1], sum_vel[:, 0])\n\n        # Generate noise for each particle.\n        noise = rng.uniform(-eta / 2, eta / 2, size=N)\n        \n        # New orientations are mean angle + noise.\n        # The update is synchronous as we use old 'theta' for all calculations.\n        new_theta = mean_angles + noise\n\n        # 3c. Position Update\n        # Update positions using the *new* orientations.\n        r[:, 0] += v0 * dt * np.cos(new_theta)\n        r[:, 1] += v0 * dt * np.sin(new_theta)\n        \n        # Apply periodic boundary conditions to positions (wrap around).\n        r %= L\n\n        # Update the orientations for the next step.\n        theta = new_theta\n\n        # 4. Order Parameter Calculation\n        if t_step = T_disc:\n            # Calculate the average velocity vector of the swarm.\n            # Using current orientations `theta` (which are `theta(t+dt)`).\n            mean_vel_x = np.mean(np.cos(theta))\n            mean_vel_y = np.mean(np.sin(theta))\n            \n            # Magnitude of the average velocity vector is the order parameter.\n            phi = np.sqrt(mean_vel_x**2 + mean_vel_y**2)\n            order_params.append(phi)\n    \n    # 5. Final Averaging\n    # Compute the arithmetic mean of the collected order parameters.\n    if order_params:\n        avg_phi = np.mean(order_params)\n    else:\n        avg_phi = 0.0\n\n    return avg_phi\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite from the problem statement:\n    # (N, L, R, v0, dt, eta, T, T_disc, seed)\n    test_cases = [\n        (150, 10.0, 1.0, 0.03, 1.0, 0.10, 600, 200, 1),\n        (150, 10.0, 1.0, 0.03, 1.0, 3.00, 600, 200, 2),\n        (150, 10.0, 1.0, 0.03, 1.0, 2.00, 600, 200, 3),\n        (150, 10.0, 0.0, 0.03, 1.0, 0.50, 600, 200, 4),\n        (16, 5.0, 1.5, 0.05, 1.0, 0.30, 800, 300, 5),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, L, R, v0, dt, eta, T, T_disc, seed = case\n        result = run_simulation(N, L, R, v0, dt, eta, T, T_disc, seed)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of floats\n    # rounded to 6 decimal places, enclosed in square brackets.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2422305"}, {"introduction": "Moving from physics to social science, this exercise explores Schelling's model of segregation, a classic agent-based model demonstrating how macroscopic patterns emerge from a local tolerance parameter $\\tau$ [@problem_id:2422368]. Your task is not only to simulate the model but also to analyze the resulting data to classify the nature of the segregation transition. This practice will equip you with the essential skill of distinguishing between first-order (abrupt) and second-order (continuous) phase transitions by examining the statistical distribution of an order parameter, a critical tool in finite-size scaling analysis.", "problem": "You will implement and analyze a two-species Schelling segregation model on a finite, periodic, two-dimensional square lattice to determine the qualitative order of the transition to a segregated state by inspecting the distribution of a suitable order parameter. The context is observing finite-size signatures of phase transitions in lattice systems.\n\nStart from the following fundamental base:\n- An order parameter is a macroscopic observable that distinguishes phases by taking characteristically different values in each phase. For segregation on a lattice with two species, a natural choice is the average fraction of like-type neighbors per occupied site.\n- In finite systems, a first-order (discontinuous) transition is characterized at the pseudo-critical control parameter by a bimodal distribution of the order parameter with two well-separated peaks corresponding to coexisting phases, while a second-order (continuous) transition exhibits a single, broadened peak with enhanced fluctuations but no phase coexistence.\n- The Schelling model dynamics on a lattice is defined by local rules and is Markovian: an agent’s move depends only on the current configuration.\n\nModel specification:\n- Lattice: a periodic square lattice of linear size $L$ with $L \\times L$ sites, each site containing either a species $+1$ agent, a species $-1$ agent, or a vacancy.\n- Occupancy: a fraction $\\rho$ of sites are occupied, split as evenly as possible between the two species; the remaining fraction $1-\\rho$ are vacancies.\n- Neighborhood: Moore neighborhood (the set of $8$ nearest sites at Chebyshev distance $1$), with periodic boundary conditions.\n- Local tolerance: an occupied site is called “happy” if the fraction of like-type neighbors among its occupied neighbors is at least a tolerance parameter $\\tau \\in [0,1]$.\n- Dynamics per sweep:\n  1. Compute the set of unhappy agents at the current $\\tau$.\n  2. If no unhappy agents exist, the configuration is absorbing and the dynamics stops.\n  3. Otherwise, in a sweep, iterate through the unhappy agents in a random order. For each such agent, move it to a uniformly random vacant site (regardless of whether the move will make it happy). After moving all currently identified unhappy agents once, recompute the set of unhappy agents for the next sweep.\n  4. Stop when either there are no unhappy agents or a maximum number of sweeps is reached.\n- Order parameter: define, at the end of the dynamics, the segregation order parameter $m$ as\n  $$ m \\equiv \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i \\in \\text{occupied}} f_i, $$\n  where $N_{\\mathrm{occ}}$ is the number of occupied sites, and $f_i$ is the fraction of like-type neighbors among the occupied neighbors of site $i$ in the Moore neighborhood. If a site $i$ has zero occupied neighbors, set $f_i \\equiv 1/2$ so that such isolated sites are neutral with respect to segregation. By construction $m \\in [0,1]$ and for a well-mixed random configuration $m \\approx 1/2$, while for a highly segregated configuration $m$ is close to $1$.\n\nTransition-order classification via order-parameter distribution:\n- For each parameter set, draw $\\tau$ independently and uniformly from a prescribed interval $[\\tau_{\\min}, \\tau_{\\max}]$ that is intended to straddle any putative transition. For each sampled $\\tau$, run an independent simulation to obtain a final $m$. Collect the sample $\\{m_r\\}_{r=1}^R$ of size $R$.\n- Use the finite-size phenomenology: declare a transition to be “first order” if the empirical distribution of $\\{m_r\\}$ is clearly bimodal with two well-separated peaks and a pronounced dip between them; declare it “second order” otherwise.\n- Concretely, implement a quantitative decision rule based on two tests:\n  1. Peak-separation test on a histogram of $\\{m_r\\}$ with an automatically chosen number of bins: identify local maxima; if at least two peaks exist, compute their separation in $m$ and the depth of the minimum between them relative to peak heights; require a separation exceeding a chosen threshold and a sufficiently deep valley.\n  2. Pearson’s bimodality coefficient $b \\equiv \\dfrac{\\gamma^2 + 1}{\\kappa}$, where $\\gamma$ is the sample skewness and $\\kappa$ is the sample kurtosis (not excess). Classify as bimodal only if $b$ exceeds the reference value $5/9$.\n- Classify as “first order” only if both tests indicate bimodality; otherwise classify as “second order.”\n\nNumerical details and constraints:\n- Use periodic boundary conditions.\n- Use Moore neighborhoods with $8$ neighbors.\n- Use dimensionless lattice units (no physical units required).\n- Angles are not involved.\n- All random choices must be reproducible from a provided seed.\n\nYour program must be a single, complete, runnable script that:\n- Implements the model and the analysis above.\n- Runs the following test suite of parameter sets and outputs the classification for each as an integer on a single line:\n  - Test $1$: $L=20$, $\\rho=0.90$, $[\\tau_{\\min},\\tau_{\\max}] = [0.45,0.55]$, $R=60$, maximum sweeps $=60$, seed $=12345$.\n  - Test $2$: $L=20$, $\\rho=0.60$, $[\\tau_{\\min},\\tau_{\\max}] = [0.45,0.55]$, $R=60$, maximum sweeps $=60$, seed $=23456$.\n  - Test $3$: $L=12$, $\\rho=0.85$, $[\\tau_{\\min},\\tau_{\\max}] = [0.35,0.65]$, $R=80$, maximum sweeps $=80$, seed $=34567$.\n- For each test, output $1$ if the transition is classified as first-order and $2$ if classified as second-order.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\\texttt{[1,2,2]}$ for three tests in order. The outputs must be integers $1$ or $2$, with no spaces.\n\nImplementation and performance notes:\n- Your implementation must use efficient array operations for neighbor counting (for example, via array shifts) to keep runtimes reasonable at the specified sizes and repetitions.\n- Your random number stream must be reproducible by using the specified seed per test; within a test, derive independent sub-seeds for each replicate deterministically from the test seed.\n- The program must not require any user input or external files and must strictly follow the execution environment and library constraints.", "solution": "The posed problem is subjected to validation.\n\n**Step 1: Extracted Givens**\n-   **Model:** Two-species Schelling segregation on a finite, periodic, $L \\times L$ square lattice.\n-   **State Space:** Sites can be occupied by species $+1$, species $-1$, or be a vacancy (denoted $0$).\n-   **Parameters:**\n    -   $L$: linear lattice size.\n    -   $\\rho$: fraction of occupied sites.\n    -   $\\tau$: tolerance parameter, a threshold for the fraction of like-type neighbors.\n    -   $R$: number of independent simulation runs per test case.\n    -   `max_sweeps`: maximum number of simulation sweeps.\n    -   `seed`: an integer for initializing the random number generator.\n-   **Neighborhood:** Moore neighborhood (8 adjacent sites), with periodic boundary conditions.\n-   **Dynamics:** Unhappy agents, defined as those where the fraction of like-type neighbors among occupied neighbors is less than $\\tau$, are moved. In each sweep, all currently unhappy agents are moved sequentially, in a random order, each to a random vacant site. The process stops if an absorbing state (no unhappy agents) is reached or after `max_sweeps`.\n-   **Order Parameter:** The segregation order parameter $m$ is the average fraction of like-type neighbors per agent, $m = \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i \\in \\text{occupied}} f_i$, where $f_i$ is the fraction of like-type neighbors for agent $i$. If an agent has no neighbors, $f_i$ is defined as $1/2$.\n-   **Analysis Method:** For each test case, $R$ simulations are run. In each simulation $r$, $\\tau_r$ is drawn uniformly from $[\\tau_{\\min}, \\tau_{\\max}]$, and the final order parameter $m_r$ is computed. The collected sample $\\{m_r\\}$ is analyzed.\n-   **Classification Rule:** A transition is classified as \"first order\" (output $1$) if and only if two tests both indicate bimodality. Otherwise, it is \"second order\" (output $2$).\n    1.  **Peak-Separation Test:** A histogram of $\\{m_r\\}$ must show at least two peaks that are sufficiently separated and have a deep valley between them. Specific thresholds are not provided.\n    2.  **Pearson's Bimodality Coefficient:** The coefficient $b = (\\gamma^2 + 1) / \\kappa$ must exceed $5/9$, where $\\gamma$ is sample skewness and $\\kappa$ is sample kurtosis.\n-   **Test Cases:**\n    1.  $L=20$, $\\rho=0.90$, $[\\tau_{\\min},\\tau_{\\max}]=[0.45,0.55]$, $R=60$, `max_sweeps`$=60$, `seed`$=12345$.\n    2.  $L=20$, $\\rho=0.60$, $[\\tau_{\\min},\\tau_{\\max}]=[0.45,0.55]$, $R=60$, `max_sweeps`$=60$, `seed`$=23456$.\n    3.  $L=12$, $\\rho=0.85$, $[\\tau_{\\min},\\tau_{\\max}]=[0.35,0.65]$, $R=80$, `max_sweeps`$=80$, `seed`$=34567$.\n\n**Step 2: Validation**\n-   **Scientific Grounding:** The problem is scientifically sound. The Schelling model, phase transitions, order parameters, and their finite-size signatures are standard concepts in statistical and computational physics.\n-   **Well-Posedness:** The problem is largely well-posed. All necessary parameters and dynamics are specified. A minor ambiguity exists in the \"Peak-Separation Test,\" where quantitative thresholds for \"sufficiently separated\" and \"deep valley\" are not given. This is an acceptable level of ambiguity for a problem of this nature, as a competent practitioner is expected to define reasonable, explicit criteria. I will resolve this by instituting explicit, principled thresholds.\n-   **Objectivity:** The problem is stated objectively and requires a quantitative, reproducible analysis.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. The minor ambiguity regarding specific thresholds for the peak-separation test will be resolved by establishing and stating them explicitly. I will now provide the full solution.\n\n**Solution Methodology**\n\nThe solution proceeds by first implementing the Schelling model simulation on a periodic lattice, followed by the statistical analysis of the order parameter distribution to classify the phase transition.\n\n**1. Model Implementation**\n-   **Lattice:** An $L \\times L$ lattice is represented by a `numpy` array. Site values are $1$ (species +1), $-1$ (species -1), and $0$ (vacancy). The initial configuration is created by randomly placing the required number of agents, determined by $\\rho$, on the lattice. The number of agents of each species is made as equal as possible.\n-   **Neighbor Counting:** To achieve computational efficiency, neighbor counts for each site are computed using vectorized operations. For a given property (e.g., being occupied by species $+1$), a binary mask is created. The number of neighbors with this property for every site on the grid is then calculated by summing eight shifted versions of this mask, where each shift corresponds to one of the Moore neighbors. This is implemented using `numpy.roll`.\n-   **Dynamics:** The simulation evolves in discrete time steps called sweeps. In each sweep:\n    1.  The sets of like-type neighbors and total occupied neighbors are computed for every lattice site.\n    2.  The fraction of like-type neighbors, $f_i$, is calculated for each agent. Agents with no occupied neighbors have $f_i=1/2$.\n    3.  Agents for which $f_i  \\tau$ are identified as \"unhappy.\"\n    4.  If there are no unhappy agents, the system has reached an absorbing state, and the simulation for this replicate terminates.\n    5.  Otherwise, a list of unhappy agent positions is randomly shuffled. The agents are moved one by one, in this random order. For each agent, a vacant site is chosen uniformly at random from the currently available vacancies, and the agent moves there. The grid is updated after each individual move.\n    6.  This process is repeated up to a maximum number of sweeps.\n\n**2. Order Parameter Calculation**\nUpon termination of a simulation run, the final configuration is used to calculate the segregation order parameter $m$. This is done by computing the fraction of like-type neighbors $f_i$ for all $N_{\\mathrm{occ}}$ agents (again, with $f_i=1/2$ for isolated agents) and then averaging these fractions: $m = \\frac{1}{N_{\\mathrm{occ}}} \\sum_{i} f_i$.\n\n**3. Transition-Order Classification**\nFor each test case, $R$ independent simulations are performed. For each run, a tolerance $\\tau$ is sampled uniformly from the specified range $[\\tau_{\\min}, \\tau_{\\max}]$. The resulting set of $R$ final order parameters $\\{m_r\\}$ is then analyzed for bimodality using two tests.\n\n-   **Test 1: Pearson's Bimodality Coefficient**\n    The coefficient is calculated as $b = (\\gamma^2 + 1) / \\kappa$. Here, $\\gamma$ is the sample skewness and $\\kappa$ is the sample kurtosis (non-excess), computed from the moments of the empirical distribution of $\\{m_r\\}$:\n    $$ \\gamma = \\frac{\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^3}{\\left(\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^2\\right)^{3/2}}, \\quad \\kappa = \\frac{\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^4}{\\left(\\frac{1}{R}\\sum_{r=1}^R (m_r - \\bar{m})^2\\right)^2} $$\n    where $\\bar{m}$ is the mean of the sample. A distribution is considered bimodal by this test if $b  5/9$.\n\n-   **Test 2: Peak-Separation Test**\n    To formalize the qualitative description, the following quantitative criteria are established:\n    1.  A histogram of the data $\\{m_r\\}$ is generated over the interval $[0, 1]$ using `numpy.histogram` with the `'auto'` binning strategy.\n    2.  Local maxima (peaks) in the histogram counts are identified. If fewer than two peaks are found, the test fails.\n    3.  The two highest peaks are selected for analysis. Let their positions be $m_1$ and $m_2$ and their heights be $h_1$ and $h_2$.\n    4.  The minimum histogram count between these two peaks is identified as the valley height, $h_{\\text{valley}}$. A valley is considered to exist only if there is at least one histogram bin between the peaks.\n    5.  Bimodality is declared if both of the following conditions are met:\n        -   **Separation:** The distance between peak centers must be significant: $|m_1 - m_2|  0.2$.\n        -   **Depth:** The valley must be pronounced: $h_{\\text{valley}}  \\frac{2}{3} \\min(h_1, h_2)$.\n\nA test case is classified as first-order (output $1$) only if both the Pearson coefficient test and the peak-separation test indicate bimodality. Otherwise, it is classified as second-order (output $2$). This conjunctive rule ensures a conservative classification of first-order transitions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Schelling model analysis.\n    \"\"\"\n    test_cases = [\n        {'L': 20, 'rho': 0.90, 'tau_range': [0.45, 0.55], 'R': 60, 'max_sweeps': 60, 'seed': 12345},\n        {'L': 20, 'rho': 0.60, 'tau_range': [0.45, 0.55], 'R': 60, 'max_sweeps': 60, 'seed': 23456},\n        {'L': 12, 'rho': 0.85, 'tau_range': [0.35, 0.65], 'R': 80, 'max_sweeps': 80, 'seed': 34567},\n    ]\n\n    results = []\n    for params in test_cases:\n        classification = run_analysis_for_case(params)\n        results.append(classification)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_analysis_for_case(params):\n    \"\"\"\n    Runs R simulations for a given parameter set and classifies the transition.\n    \"\"\"\n    m_values = []\n    for r in range(params['R']):\n        rep_seed = params['seed'] + r\n        rep_rng = np.random.default_rng(rep_seed)\n        \n        tau = rep_rng.uniform(params['tau_range'][0], params['tau_range'][1])\n        \n        final_m = run_single_simulation(\n            L=params['L'], \n            rho=params['rho'], \n            tau=tau, \n            max_sweeps=params['max_sweeps'], \n            rng=rep_rng\n        )\n        m_values.append(final_m)\n        \n    m_values = np.array(m_values)\n    \n    pearson_bimodal = is_bimodal_pearson(m_values)\n    peak_bimodal = is_bimodal_peaks(m_values)\n    \n    if pearson_bimodal and peak_bimodal:\n        return 1  # First-order\n    else:\n        return 2  # Second-order\n\ndef run_single_simulation(L, rho, tau, max_sweeps, rng):\n    \"\"\"\n    Executes a single run of the Schelling model simulation.\n    \"\"\"\n    grid = initialize_grid(L, rho, rng)\n    \n    for _ in range(max_sweeps):\n        num_like, num_occupied_neighbors = count_neighbors(grid)\n        \n        occupied_mask = (grid != 0)\n        \n        with np.errstate(divide='ignore', invalid='ignore'):\n            f = np.divide(num_like, num_occupied_neighbors, \n                          out=np.full(grid.shape, 0.5, dtype=float), \n                          where=num_occupied_neighbors != 0)\n\n        unhappy_mask = (f  tau)  occupied_mask\n        unhappy_indices = np.argwhere(unhappy_mask)\n\n        if len(unhappy_indices) == 0:\n            break\n\n        rng.shuffle(unhappy_indices)\n        \n        vacant_indices = np.argwhere(grid == 0)\n        num_vacancies = len(vacant_indices)\n\n        if num_vacancies == 0:\n            break\n\n        for agent_pos_tuple in unhappy_indices:\n            agent_pos = tuple(agent_pos_tuple)\n            \n            # Find current vacancies; this is inefficient but correct for sequential moves\n            current_vacancies = np.argwhere(grid == 0)\n            if len(current_vacancies) == 0:\n                continue\n\n            target_idx = rng.choice(len(current_vacancies))\n            target_pos = tuple(current_vacancies[target_idx])\n            \n            # Move agent\n            grid[target_pos], grid[agent_pos] = grid[agent_pos], grid[target_pos]\n\n    # Calculate final order parameter\n    num_like_final, num_occupied_neighbors_final = count_neighbors(grid)\n    occupied_mask_final = (grid != 0)\n    num_occ = np.sum(occupied_mask_final)\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n        f_final = np.divide(num_like_final, num_occupied_neighbors_final,\n                            out=np.full(grid.shape, 0.5, dtype=float),\n                            where=num_occupied_neighbors_final != 0)\n    \n    m = np.sum(f_final[occupied_mask_final]) / num_occ if num_occ  0 else 0.5\n    return m\n\ndef initialize_grid(L, rho, rng):\n    \"\"\"\n    Initializes the lattice with agents and vacancies.\n    \"\"\"\n    N = L * L\n    N_occ = int(rho * N)\n    N_p1 = N_occ // 2\n    N_m1 = N_occ - N_p1\n    \n    grid_flat = np.zeros(N, dtype=int)\n    grid_flat[:N_p1] = 1\n    grid_flat[N_p1:N_occ] = -1\n    \n    rng.shuffle(grid_flat)\n    return grid_flat.reshape((L, L))\n\ndef count_neighbors(grid):\n    \"\"\"\n    Efficiently counts neighbors using numpy.roll.\n    \"\"\"\n    L = grid.shape[0]\n    \n    shifts = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n\n    p1_mask = (grid == 1)\n    m1_mask = (grid == -1)\n\n    num_neighbors_p1 = np.zeros_like(grid, dtype=int)\n    num_neighbors_m1 = np.zeros_like(grid, dtype=int)\n\n    for dy, dx in shifts:\n        num_neighbors_p1 += np.roll(p1_mask, (dy, dx), axis=(0, 1))\n        num_neighbors_m1 += np.roll(m1_mask, (dy, dx), axis=(0, 1))\n\n    num_like_neighbors = num_neighbors_p1 * p1_mask + num_neighbors_m1 * m1_mask\n    num_occupied_neighbors = num_neighbors_p1 + num_neighbors_m1\n    \n    return num_like_neighbors, num_occupied_neighbors\n\ndef is_bimodal_pearson(data):\n    \"\"\"\n    Calculates Pearson's bimodality coefficient and checks against the threshold.\n    \"\"\"\n    n = len(data)\n    if n  3: return False\n    \n    mean = np.mean(data)\n    var = np.var(data)\n    if var == 0: return False\n\n    std_dev = np.sqrt(var)\n    skewness = np.mean(((data - mean) / std_dev)**3)\n    kurtosis = np.mean(((data - mean) / std_dev)**4)\n\n    if kurtosis == 0: return False\n\n    b = (skewness**2 + 1) / kurtosis\n    return b  (5/9)\n\ndef is_bimodal_peaks(data, sep_thresh=0.2, depth_thresh=2/3.):\n    \"\"\"\n    Performs a peak-separation test on the data's histogram.\n    \"\"\"\n    counts, bin_edges = np.histogram(data, bins='auto', range=(0.0, 1.0))\n    if np.sum(counts)  3: return False\n    \n    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n    \n    peak_indices = []\n    for i in range(1, len(counts) - 1):\n        if counts[i]  counts[i-1] and counts[i]  counts[i+1]:\n            peak_indices.append(i)\n    \n    if len(peak_indices)  2:\n        return False\n        \n    peak_heights = counts[peak_indices]\n    highest_peak_indices_in_list = np.argsort(peak_heights)[::-1][:2]\n    \n    idx1 = peak_indices[highest_peak_indices_in_list[0]]\n    idx2 = peak_indices[highest_peak_indices_in_list[1]]\n    \n    if idx1  idx2:\n        idx1, idx2 = idx2, idx1\n        \n    h1, h2 = counts[idx1], counts[idx2]\n    m1, m2 = bin_centers[idx1], bin_centers[idx2]\n    \n    # Valley must have at least one bin between peaks\n    if idx2 = idx1 + 1:\n        return False\n        \n    valley_height = np.min(counts[idx1+1 : idx2])\n    \n    separation_ok = (m2 - m1)  sep_thresh\n    depth_ok = valley_height  depth_thresh * min(h1, h2)\n    \n    return separation_ok and depth_ok\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2422368"}, {"introduction": "Our final practice turns to the Ising model, the canonical model of magnetism and a pillar of statistical mechanics. You will explore how a system's topology can influence its collective behavior by comparing the magnetic susceptibility $\\chi$ on a cylinder versus a Möbius strip [@problem_id:2422307]. This exercise employs the technique of exact enumeration, providing a deep, albeit computationally intensive, look into the complete statistical ensemble of a small system and revealing the subtle yet crucial role of boundary conditions in physics.", "problem": "Consider the two-dimensional Ising model with spins $s_{x,y} \\in \\{+1,-1\\}$ on a rectangular $L_x \\times L_y$ lattice with Hamiltonian\n$$\nH(\\{s\\}) \\;=\\; -J \\sum_{\\langle i,j\\rangle} s_i s_j,\n$$\nwhere $J0$ and the sum is over nearest-neighbor pairs defined by the lattice topology. Work at zero external field and in units where the Boltzmann constant $k_{\\mathrm{B}}=1$. The equilibrium (canonical) probability of a configuration $\\{s\\}$ at temperature $T$ is proportional to $\\exp(-\\beta H)$ with $\\beta = 1/T$. The total magnetization is $M(\\{s\\})=\\sum_{x=0}^{L_x-1}\\sum_{y=0}^{L_y-1} s_{x,y}$ and the magnetic susceptibility per spin is defined by\n$$\n\\chi(T) \\;=\\; \\frac{\\beta}{N} \\left( \\langle M^2 \\rangle - \\langle M \\rangle^2 \\right),\n$$\nwhere $N=L_x L_y$ and $\\langle \\cdot \\rangle$ denotes the canonical ensemble average.\n\nDefine two topologies on the same $L_x \\times L_y$ grid:\n\n- Cylinder: open boundaries in the $x$-direction and periodic boundaries in the $y$-direction. The set of nearest-neighbor bonds consists of pairs $\\big((x,y),(x+1,y)\\big)$ for all $x$ with $0 \\le x  L_x-1$, $0 \\le y  L_y$, and pairs $\\big((x,y),(x, y')\\big)$ with $y'=(y+1)\\bmod L_y$ for all $x$ and $y$.\n\n- Möbius strip: open boundaries in the $x$-direction and twisted periodic boundaries in the $y$-direction. The set of nearest-neighbor bonds consists of pairs $\\big((x,y),(x+1,y)\\big)$ for all $x$ with $0 \\le x  L_x-1$, $0 \\le y  L_y$, and vertical bonds connecting $(x,y)$ to $(x,y+1)$ for $y  L_y-1$ (for all $x$), and pairs connecting $(x,L_y-1)$ to $(L_x-1-x,0)$ (for all $x$).\n\nUsing only the definitions above (no approximations), compute the susceptibility $\\chi$ for both topologies by evaluating the canonical ensemble exactly through sums over all spin configurations. Set $J=1$ and express temperatures $T$ in dimensionless units (since $k_{\\mathrm{B}}=1$ and $J=1$), with $\\beta=1/T$.\n\nTest Suite:\nFor each of the following parameter sets $(L_x,L_y,T)$, compute two numbers: $\\chi_{\\mathrm{Mobius}}(T)$ and $\\chi_{\\mathrm{Cylinder}}(T)$.\n\n- Case A: $L_x=4$, $L_y=3$, $T=2.30$.\n- Case B: $L_x=5$, $L_y=3$, $T=1.80$.\n- Case C: $L_x=4$, $L_y=4$, $T=4.00$.\n\nFinal Output Format:\nYour program should produce a single line of output containing a comma-separated flat list with the six susceptibility values in the order\n$$\n\\big[\\chi_{\\mathrm{Mobius}}^{\\mathrm{A}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{A}},\\;\\chi_{\\mathrm{Mobius}}^{\\mathrm{B}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{B}},\\;\\chi_{\\mathrm{Mobius}}^{\\mathrm{C}},\\;\\chi_{\\mathrm{Cylinder}}^{\\mathrm{C}}\\big],\n$$\nrounded to exactly $6$ decimal places, and enclosed in square brackets. For example: $[\\chi_1,\\chi_2,\\chi_3,\\chi_4,\\chi_5,\\chi_6]$.", "solution": "The problem statement is assessed to be valid. It is a well-posed problem in computational statistical mechanics, free of scientific or logical flaws, and provides all necessary information for a unique solution. The specified method of exact enumeration is computationally feasible for the given lattice sizes.\n\nThe magnetic susceptibility per spin, $\\chi(T)$, is defined as\n$$\n\\chi(T) = \\frac{\\beta}{N} \\left( \\langle M^2 \\rangle - \\langle M \\rangle^2 \\right),\n$$\nwhere $N=L_x L_y$ is the total number of spins, $\\beta = 1/T$ (with $k_{\\mathrm{B}}=1$), $M$ is the total magnetization, and $\\langle \\cdot \\rangle$ denotes the canonical ensemble average. An observable $O$ has a canonical average given by\n$$\n\\langle O \\rangle = \\frac{\\sum_{\\{s\\}} O(\\{s\\}) e^{-\\beta H(\\{s\\})}}{Z},\n$$\nwhere the sum runs over all $2^N$ spin configurations $\\{s\\}$, and $Z = \\sum_{\\{s\\}} e^{-\\beta H(\\{s\\})}$ is the partition function.\n\nThe Hamiltonian $H(\\{s\\}) = -J \\sum_{\\langle i,j\\rangle} s_i s_j$ is invariant under a global spin-flip transformation, where all spins $\\{s_k\\}$ become $\\{-s_k\\}$. This holds for both the cylinder and Möbius strip topologies as the set of neighbor pairs is fixed. Under this transformation, the energy $H$ is unchanged, while the magnetization reverses sign, $M \\to -M$. Consequently, for every configuration with magnetization $M$, there exists a degenerate configuration with magnetization $-M$. The sum for $\\langle M \\rangle$ can be written as a sum over pairs of such configurations:\n$$\n\\sum_{\\{s\\} \\text{ pairs}} \\left( M e^{-\\beta H} + (-M) e^{-\\beta H} \\right) = 0.\n$$\nTherefore, the average magnetization $\\langle M \\rangle$ is strictly zero for any temperature. The expression for susceptibility simplifies to\n$$\n\\chi(T) = \\frac{\\beta}{N} \\langle M^2 \\rangle.\n$$\nTo compute $\\chi(T)$, we must evaluate $\\langle M^2 \\rangle$ by summing over all $2^N$ spin configurations. This is an exact enumeration approach. The algorithm is as follows:\n\n1.  For a given lattice of size $N=L_x \\times L_y$, there are $2^N$ unique spin configurations. We can systematically generate each configuration by mapping it to an integer $i$ in the range $[0, 2^N-1]$. The state of the $k$-th spin, $s_k \\in \\{+1, -1\\}$, is determined by the $k$-th bit of the binary representation of $i$. For example, a map can be $s_k = 2 \\cdot (\\text{bit}_k \\text{ of } i) - 1$. A 1D spin index $k \\in [0, N-1]$ is mapped to a 2D lattice coordinate $(x,y)$ via $k = y \\cdot L_x + x$.\n\n2.  The crucial element defining the model is the lattice topology, which determines the set of nearest-neighbor pairs $\\langle i,j \\rangle$ used in the Hamiltonian sum. We generate a definitive list of unique bonds for each specified topology.\n    *   For the **Cylinder** topology ($L_x \\times L_y$), the bonds are defined by:\n        *   Horizontal connections: Pairs of sites $((x,y), (x+1,y))$ for $0 \\le x  L_x-1$ and $0 \\le y  L_y$.\n        *   Vertical connections with periodic boundaries: Pairs $((x,y), (x, (y+1) \\pmod{L_y}))$ for $0 \\le x  L_x$ and $0 \\le y  L_y$.\n    *   For the **Möbius strip** topology, the bonds are:\n        *   Horizontal connections: Same as the cylinder.\n        *   Vertical connections with a twist: Pairs $((x,y), (x,y+1))$ for $0 \\le y  L_y-1$, and a specific twisted connection for the boundary columns of spins, linking site $(x, L_y-1)$ to site $(L_x-1-x, 0)$ for all $x \\in [0, L_x-1]$.\n\n3.  With the bond list established, we iterate through all $2^N$ configurations. For each configuration $\\{s\\}$, we compute:\n    *   The total magnetization: $M(\\{s\\}) = \\sum_{k=0}^{N-1} s_k$.\n    *   The total energy: $H(\\{s\\}) = -J \\sum_{\\langle i,j \\rangle} s_i s_j$. We are given $J=1$.\n\n4.  We then compute the required sums over all configurations:\n    *   The partition function sum $Z_{\\text{sum}} = \\sum_{\\{s\\}} \\exp(-\\beta H(\\{s\\}))$.\n    *   The sum for the second moment of magnetization $S_{M^2} = \\sum_{\\{s\\}} M(\\{s\\})^2 \\exp(-\\beta H(\\{s\\}))$.\n\n5.  The calculation of Boltzmann factors $\\exp(-\\beta H)$ can lead to numerical overflow if $-\\beta H$ is large and positive. To ensure stability, we first find the minimum energy over all configurations, $H_{\\min} = \\min_{\\{s\\}} H(\\{s\\})$. We then compute numerically stable weights $w_s = \\exp(-\\beta(H(\\{s\\}) - H_{\\min}))$. The factor $\\exp(\\beta H_{\\min})$ is common to all terms in both the numerator and denominator of $\\langle M^2 \\rangle$ and thus cancels:\n    $$\n    \\langle M^2 \\rangle = \\frac{\\sum_{\\{s\\}} M^2(\\{s\\}) w_s}{\\sum_{\\{s\\}} w_s} = \\frac{S_{M^2}}{Z_{\\text{sum}}}.\n    $$\n\n6.  Finally, the susceptibility is calculated using the simplified formula: $\\chi(T) = \\frac{\\beta}{N} \\langle M^2 \\rangle$.\n\nThe provided code implements this exact algorithm. It generates all spin configurations and their corresponding magnetizations and energies for a given topology. It then uses these to compute the partition function sum and the thermal average of the squared magnetization, leading to the final susceptibility value. This process is repeated for each set of parameters and each topology in the test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_bonds(Lx, Ly, topology):\n    \"\"\"\n    Generates the list of unique nearest-neighbor bonds for a given topology.\n\n    Args:\n        Lx (int): Lattice size in the x-direction.\n        Ly (int): Lattice size in the y-direction.\n        topology (str): 'cylinder' or 'mobius'.\n\n    Returns:\n        list: A list of tuples, where each tuple represents a bond (pair of site indices).\n    \"\"\"\n    bonds = set()\n\n    def add_bond(i, j):\n        bonds.add(tuple(sorted((i, j))))\n\n    def get_idx(x, y):\n        return y * Lx + x\n\n    # Horizontal bonds (common to both topologies)\n    for y in range(Ly):\n        for x in range(Lx - 1):\n            add_bond(get_idx(x, y), get_idx(x + 1, y))\n\n    # Vertical bonds (topology-dependent)\n    if topology == 'cylinder':\n        for x in range(Lx):\n            for y in range(Ly):\n                add_bond(get_idx(x, y), get_idx(x, (y + 1) % Ly))\n    elif topology == 'mobius':\n        for x in range(Lx):\n            # Normal vertical bonds for y  Ly-1\n            for y in range(Ly - 1):\n                add_bond(get_idx(x, y), get_idx(x, y + 1))\n            # Twisted bonds connecting y=Ly-1 to y=0\n            add_bond(get_idx(x, Ly - 1), get_idx(Lx - 1 - x, 0))\n    \n    return list(bonds)\n\ndef calculate_chi(Lx, Ly, T, topology):\n    \"\"\"\n    Computes the magnetic susceptibility per spin for the 2D Ising model\n    by exact enumeration of all spin configurations.\n\n    Args:\n        Lx (int): Lattice size in the x-direction.\n        Ly (int): Lattice size in the y-direction.\n        T (float): Temperature.\n        topology (str): The lattice topology, 'cylinder' or 'mobius'.\n\n    Returns:\n        float: The calculated magnetic susceptibility per spin.\n    \"\"\"\n    N = Lx * Ly\n    beta = 1.0 / T\n    J = 1.0\n    \n    bonds = get_bonds(Lx, Ly, topology)\n    \n    num_configs = 1  N\n    \n    # 1. Generate all 2^N spin configurations using numpy broadcasting.\n    # Each row is a configuration, each column is a spin site.\n    # The value is +1 or -1.\n    i_vals = np.arange(num_configs, dtype=np.uint32)\n    k_vals = np.arange(N, dtype=np.uint8)\n    spins = (((i_vals[:, None]  k_vals[None, :])  1) * 2 - 1).astype(np.int8)\n\n    # 2. Calculate magnetization M for each configuration.\n    magnetizations = np.sum(spins, axis=1, dtype=np.int32)\n\n    # 3. Calculate energy H for each configuration.\n    energies = np.zeros(num_configs, dtype=np.float64)\n    for idx1, idx2 in bonds:\n        energies -= spins[:, idx1] * spins[:, idx2]\n    energies *= J\n\n    # 4. Compute sums for M^2 using numerically stable weights.\n    # Find minimum energy to prevent overflow in exp.\n    H_min = np.min(energies)\n    shifted_energies = energies - H_min\n    weights = np.exp(-beta * shifted_energies)\n    \n    # Partition function sum\n    Z_sum = np.sum(weights)\n    \n    # Thermal sum for M^2\n    M2_sum = np.sum(magnetizations**2 * weights)\n    \n    # 5. Calculate susceptibility.\n    # M = 0 due to spin-flip symmetry.\n    mean_M2 = M2_sum / Z_sum\n    chi = (beta / N) * mean_M2\n    \n    return chi\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (4, 3, 2.30),  # Case A\n        (5, 3, 1.80),  # Case B\n        (4, 4, 4.00),  # Case C\n    ]\n\n    results = []\n    for Lx, Ly, T in test_cases:\n        chi_mobius = calculate_chi(Lx, Ly, T, 'mobius')\n        chi_cylinder = calculate_chi(Lx, Ly, T, 'cylinder')\n        results.append(chi_mobius)\n        results.append(chi_cylinder)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2422307"}]}