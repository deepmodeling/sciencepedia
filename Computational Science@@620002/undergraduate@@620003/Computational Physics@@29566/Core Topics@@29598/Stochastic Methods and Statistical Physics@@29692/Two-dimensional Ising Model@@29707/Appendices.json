{"hands_on_practices": [{"introduction": "For small systems, we can compute thermodynamic quantities exactly by enumerating every possible microstate. This exercise provides fundamental practice in this technique, guiding you to calculate the complete energy probability distribution $P(E)$ for a small 2D Ising lattice. By analyzing this distribution, you will numerically verify a cornerstone of statistical mechanics: the connection between microscopic energy fluctuations and the macroscopic heat capacity [@problem_id:2448166].", "problem": "Consider the two-dimensional Ising model on a square lattice of linear size $L$ with periodic boundary conditions, zero external field, and uniform nearest-neighbor coupling $J$. Each spin $s_i$ takes values in $\\{-1,+1\\}$. The Hamiltonian is\n$$\n\\mathcal{H}(\\{s\\}) \\;=\\; -J \\sum_{\\langle i,j\\rangle} s_i s_j,\n$$\nwhere the sum is over all distinct nearest-neighbor pairs with periodic boundary conditions. Work in canonical equilibrium at absolute temperature $T$ and Boltzmann constant $k_{\\mathrm B}$, and define the total number of spins $N=L^2$, the inverse temperature $\\beta = 1/(k_{\\mathrm B} T)$, the partition function\n$$\nZ(\\beta) \\;=\\; \\sum_{\\{s\\}} e^{-\\beta \\mathcal{H}(\\{s\\})},\n$$\nand the probability distribution of total energies $P(E)$ induced by the canonical ensemble. Let $g(E)$ denote the density of states (the number of microstates with total energy exactly equal to $E$). Then\n$$\nP(E) \\;=\\; \\frac{g(E)\\, e^{-\\beta E}}{Z(\\beta)}.\n$$\n\nTasks:\n1. For the specified system, compute the discrete energy distribution $P(E)$ implied by the canonical ensemble and verify its normalization.\n2. Compute the mean energy $\\langle E\\rangle$ and the variance $\\mathrm{Var}(E)=\\langle E^2\\rangle - \\langle E\\rangle^2$ with respect to $P(E)$.\n3. Compute the heat capacity per spin $c(T)$ defined by\n$$\nc(T) \\;=\\; \\frac{1}{N}\\,\\frac{d\\langle E\\rangle}{dT}.\n$$\nUsing only the fundamental definitions above, demonstrate the relationship between the variance of $E$ and the heat capacity.\n\nUse the following fixed parameters for all computations:\n- $L=4$,\n- $J=1$,\n- $k_{\\mathrm B}=1$.\nAll energies, temperatures, and heat capacities are therefore dimensionless in these units. Angles do not appear in this problem. No other physical units are required.\n\nTest suite (three temperatures that probe qualitatively different regimes): \n- Low temperature $T=0.5$,\n- Near-critical temperature $T=2.2691853$,\n- High temperature $T=5.0$.\n\nFor each temperature in the order given above, produce three outputs:\n- A boolean indicating whether $\\sum_E P(E)$ equals $1$ within an absolute tolerance of $10^{-12}$,\n- The variance per spin $\\mathrm{Var}(E)/N$ as a real number,\n- The heat capacity per spin $c(T)$ as a real number.\n\nFinal output format:\nYour program should produce a single line of output containing the results, aggregated over the three temperatures, as a comma-separated list enclosed in square brackets. The list must contain exactly nine entries arranged as\n$$\n[\\text{norm\\_ok}_{T=0.5},\\, \\mathrm{Var}(E)/N\\big|_{T=0.5},\\, c(T)\\big|_{T=0.5},\\, \\text{norm\\_ok}_{T=2.2691853},\\, \\mathrm{Var}(E)/N\\big|_{T=2.2691853},\\, c(T)\\big|_{T=2.2691853},\\, \\text{norm\\_ok}_{T=5.0},\\, \\mathrm{Var}(E)/N\\big|_{T=5.0},\\, c(T)\\big|_{T=5.0}],\n$$\nwhere each $\\text{norm\\_ok}_{T}$ is either the boolean literal True or False, and each real number is printed in decimal form. No additional text should be printed.", "solution": "The two-dimensional Ising model with Hamiltonian $\\mathcal{H}(\\{s\\}) = -J \\sum_{\\langle i,j\\rangle} s_i s_j$ on an $L\\times L$ lattice with periodic boundary conditions has a finite set of microstates for any finite $L$. At equilibrium in the canonical ensemble at temperature $T$, the probability of a microstate $\\{s\\}$ is given by the Boltzmann factor divided by the partition function, namely $p(\\{s\\}) = e^{-\\beta \\mathcal{H}(\\{s\\})}/Z(\\beta)$ with $\\beta = 1/(k_{\\mathrm B} T)$ and $Z(\\beta) = \\sum_{\\{s\\}} e^{-\\beta \\mathcal{H}(\\{s\\})}$. Grouping microstates by their total energy $E$ defines the density of states $g(E)$ and yields the canonical energy distribution\n$$\nP(E) \\;=\\; \\frac{g(E)\\, e^{-\\beta E}}{Z(\\beta)}.\n$$\nNormalization follows from the definition:\n$$\n\\sum_E P(E) \\;=\\; \\sum_E \\frac{g(E)\\, e^{-\\beta E}}{Z(\\beta)} \\;=\\; \\frac{1}{Z(\\beta)} \\sum_{\\{s\\}} e^{-\\beta \\mathcal{H}(\\{s\\})} \\;=\\; 1.\n$$\n\nFrom first principles, the mean energy and mean squared energy are\n$$\n\\langle E\\rangle \\;=\\; \\sum_E E\\, P(E), \n\\qquad\n\\langle E^2\\rangle \\;=\\; \\sum_E E^2\\, P(E),\n$$\nand the variance is $\\mathrm{Var}(E) = \\langle E^2\\rangle - \\langle E\\rangle^2$.\n\nTo connect the variance to the heat capacity, begin with the partition function $Z(\\beta)$ and its logarithm. Differentiating with respect to $\\beta$ gives\n$$\n\\frac{\\partial \\ln Z}{\\partial \\beta} \n\\;=\\; \\frac{1}{Z}\\frac{\\partial Z}{\\partial \\beta}\n\\;=\\; \\frac{1}{Z} \\sum_{\\{s\\}} \\left(-\\mathcal{H}(\\{s\\})\\right) e^{-\\beta \\mathcal{H}(\\{s\\})}\n\\;=\\; - \\langle E\\rangle.\n$$\nDifferentiating once more,\n$$\n\\frac{\\partial^2 \\ln Z}{\\partial \\beta^2}\n\\;=\\; -\\frac{\\partial \\langle E\\rangle}{\\partial \\beta}\n\\;=\\; \\langle E^2\\rangle - \\langle E\\rangle^2\n\\;=\\; \\mathrm{Var}(E).\n$$\nThe total heat capacity $C$ is defined by\n$$\nC \\;=\\; \\frac{d\\langle E\\rangle}{dT}.\n$$\nUsing $\\beta = 1/(k_{\\mathrm B} T)$, we have $d\\beta/dT = -1/(k_{\\mathrm B} T^2)$. Therefore,\n$$\nC \\;=\\; \\frac{d\\langle E\\rangle}{d\\beta} \\frac{d\\beta}{dT}\n\\;=\\; \\left(-\\frac{\\partial^2 \\ln Z}{\\partial \\beta^2}\\right)\\left(-\\frac{1}{k_{\\mathrm B} T^2}\\right)\n\\;=\\; \\frac{\\mathrm{Var}(E)}{k_{\\mathrm B} T^2}.\n$$\nDividing by the number of spins $N=L^2$ yields the heat capacity per spin\n$$\nc(T) \\;=\\; \\frac{C}{N} \\;=\\; \\frac{\\mathrm{Var}(E)}{N\\, k_{\\mathrm B}\\, T^2}.\n$$\n\nWith $J=1$ and $k_{\\mathrm B}=1$, all quantities are dimensionless and the above reduces to $c(T) = \\mathrm{Var}(E)/(N T^2)$. This identity emerges directly from the canonical definitions and shows precisely how the variance of the energy determines the heat capacity.\n\nAlgorithmically, for finite $L$ one can obtain $g(E)$ by constructing all spin configurations $\\{s\\}$, computing their energies using the Hamiltonian with periodic boundary conditions, tallying the number of occurrences of each distinct energy to form $g(E)$, and then evaluating $P(E) = g(E) e^{-\\beta E}/Z$ with $Z = \\sum_E g(E) e^{-\\beta E}$. From $P(E)$, compute $\\langle E\\rangle$, $\\langle E^2\\rangle$, $\\mathrm{Var}(E)$, and finally $c(T)=\\mathrm{Var}(E)/(N T^2)$. The normalization check verifies that $\\sum_E P(E)$ equals $1$ within the prescribed numerical tolerance. The chosen test temperatures $T=0.5$, $T=2.2691853$, and $T=5.0$ span low, near-critical, and high temperature regimes; correspondingly, the variance per spin is small at very low and very high temperatures and larger near the critical region for this finite system, while the heat capacity per spin follows the same qualitative trend as mandated by $c(T) = \\mathrm{Var}(E)/(N T^2)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef ising_energy_spectrum_L(L: int, J: float = 1.0):\n    \"\"\"\n    Compute the energy spectrum (unique energies and their degeneracies g(E))\n    for the 2D Ising model on an LxL lattice with periodic boundary conditions\n    and zero external field, with coupling J.\n\n    Returns:\n        E_values: np.ndarray of shape (M,), sorted unique energies (dtype=int64)\n        g_values: np.ndarray of shape (M,), degeneracy counts for each energy (dtype=int64)\n        N: total number of spins (int)\n    \"\"\"\n    N = L * L\n    # Neighbor indices for counting each bond once: right and down neighbors\n    right = np.empty(N, dtype=np.int64)\n    down = np.empty(N, dtype=np.int64)\n    for r in range(L):\n        for c in range(L):\n            idx = r * L + c\n            right[idx] = r * L + ((c + 1) % L)\n            down[idx] = ((r + 1) % L) * L + c\n\n    # Enumerate all spin configurations via bit representation\n    num_states = 1  N  # 2^N\n    states = np.arange(num_states, dtype=np.uint32)  # shape (num_states,)\n    masks = (1  np.arange(N, dtype=np.uint32))     # shape (N,)\n\n    # Convert bits to spins in {-1, +1}\n    bits = ((states[:, None]  masks) != 0).astype(np.int8)  # shape (num_states, N)\n    spins = (bits  1) - 1  # 0--1, 1-+1\n\n    # Compute total energy for each configuration; count each bond once (right and down)\n    # E = -J * sum_{i} (s_i s_{right(i)} + s_i s_{down(i)})\n    # We can vectorize using advanced indexing over columns\n    prod_right = spins * spins[:, right]\n    prod_down = spins * spins[:, down]\n    bond_sum = prod_right + prod_down\n    # Sum over all sites to get total bond contribution, then multiply by -J\n    E = (-J * bond_sum.sum(axis=1)).astype(np.int64)  # shape (num_states,)\n\n    # Get unique energies and degeneracies g(E)\n    E_values, g_values = np.unique(E, return_counts=True)\n    g_values = g_values.astype(np.int64)\n    return E_values.astype(np.int64), g_values, N\n\ndef canonical_stats_from_spectrum(E_values, g_values, T: float, kB: float = 1.0):\n    \"\"\"\n    Given energy levels E_values (int) and degeneracies g_values (int),\n    compute canonical probabilities P(E), mean energy, mean squared energy,\n    and variance at temperature T with Boltzmann constant kB.\n    \"\"\"\n    beta = 1.0 / (kB * T)\n    E_float = E_values.astype(np.float64)\n    g_float = g_values.astype(np.float64)\n\n    # Unnormalized weights: w(E) = g(E) * exp(-beta * E)\n    # For numerical stability here, direct exponentiation is sufficient for given L and T.\n    weights = g_float * np.exp(-beta * E_float)\n    Z = weights.sum()\n    P_E = weights / Z\n\n    # Normalization check\n    norm_ok = bool(np.isclose(P_E.sum(), 1.0, atol=1e-12, rtol=0.0))\n\n    # Moments\n    mean_E = np.sum(P_E * E_float)\n    mean_E2 = np.sum(P_E * (E_float ** 2))\n    var_E = mean_E2 - mean_E ** 2\n    # Guard against tiny negative due to floating errors\n    if var_E  0 and var_E  -1e-18:\n        var_E = 0.0\n\n    return norm_ok, mean_E, mean_E2, var_E\n\ndef solve():\n    # Define the test cases from the problem statement.\n    L = 4\n    J = 1.0\n    kB = 1.0\n    test_temperatures = [0.5, 2.2691853, 5.0]\n\n    # Precompute spectrum for given L and J\n    E_values, g_values, N = ising_energy_spectrum_L(L=L, J=J)\n\n    results = []\n    for T in test_temperatures:\n        norm_ok, mean_E, mean_E2, var_E = canonical_stats_from_spectrum(E_values, g_values, T=T, kB=kB)\n        var_per_spin = var_E / N\n        c_per_spin = var_E / (N * (T ** 2) * kB)  # with kB=1.0\n        results.append(norm_ok)\n        results.append(var_per_spin)\n        results.append(c_per_spin)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2448166"}, {"introduction": "Beyond direct enumeration, the transfer matrix method offers a powerful semi-analytical approach for studying lattice models. This practice involves recasting the 2D Ising model on an infinitely long strip into a linear algebra problem, where properties are determined by the eigenvalues of the transfer matrix. You will implement this method to compute the correlation length $\\xi$, a key quantity describing the scale over which spin correlations decay, from the leading eigenvalues of the matrix [@problem_id:2384603].", "problem": "Consider the ferromagnetic two-dimensional (2D) Ising model on a strip of width $W$ with periodic boundary conditions across the strip and a transfer direction along rows. Let each spin $s_i \\in \\{-1,+1\\}$, with nearest-neighbor coupling along the transfer direction (between successive rows) given by a dimensionless coupling $K_v$, and nearest-neighbor coupling within a row (horizontal) given by a dimensionless coupling $K_h$. The row-to-row transfer matrix $T$ is defined on the $2^W$-dimensional space of row configurations. For two successive row configurations $\\boldsymbol{s}$ and $\\boldsymbol{s}'$, define\n$$\n\\mathcal{H}_{\\text{row}}(\\boldsymbol{s})=\\sum_{i=1}^{W} s_i s_{i+1},\\quad s_{W+1}\\equiv s_1,\\qquad\n\\mathcal{V}(\\boldsymbol{s},\\boldsymbol{s}')=\\sum_{i=1}^{W} s_i s_i',\n$$\nand the symmetric transfer matrix entries\n$$\nT_{\\boldsymbol{s},\\boldsymbol{s}'}=\\exp\\!\\left(K_v\\,\\mathcal{V}(\\boldsymbol{s},\\boldsymbol{s}')+\\frac{K_h}{2}\\,\\mathcal{H}_{\\text{row}}(\\boldsymbol{s})+\\frac{K_h}{2}\\,\\mathcal{H}_{\\text{row}}(\\boldsymbol{s}')\\right).\n$$\nLet $\\lambda_0$ be the largest eigenvalue of $T$ and $\\lambda_1$ be the second-largest eigenvalue in magnitude. The correlation length $\\xi$ along the transfer direction (in units of the lattice spacing between rows) is defined by\n$$\n\\xi=\\frac{1}{\\ln\\!\\left(\\frac{\\lambda_0}{|\\lambda_1|}\\right)}.\n$$\nConstruct a program that, for each test case provided below, builds $T$ exactly as defined, determines $\\lambda_0$ and $\\lambda_1$ as defined above, and returns the corresponding $\\xi$. If $|\\lambda_1|$ is effectively zero to within numerical precision, define $\\xi=0$.\n\nAll outputs must be reported as dimensionless quantities in lattice-spacing units along the transfer direction. Angles do not appear in this problem. The final output must be a single line containing a comma-separated list of the correlation lengths for all test cases enclosed in square brackets, with each value rounded to $8$ decimal places, for example, $[\\xi_1,\\xi_2,\\xi_3]$.\n\nUse the following test suite of parameter values:\n- Test case A (boundary-size strip): $W=1$, $K_v=0.4$, $K_h=0.4$.\n- Test case B (high-temperature anisotropic): $W=3$, $K_v=0.1$, $K_h=0.2$.\n- Test case C (near-critical isotropic on a moderate strip): $W=4$, $K_v=0.4$, $K_h=0.4$.\n- Test case D (low-temperature isotropic on a wider strip): $W=5$, $K_v=0.7$, $K_h=0.7$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_A,\\text{result}_B,\\text{result}_C,\\text{result}_D]$), with each entry rounded to $8$ decimal places. Each result must be a float.", "solution": "The problem requires the calculation of the correlation length $\\xi$ for a ferromagnetic 2D Ising model on a finite-width strip. The fundamental theoretical tool for this task is the transfer matrix method. For a system on a lattice of width $W$ and length $N$, the partition function $Z$ can be expressed as a trace of the $N$-th power of a row-to-row transfer matrix $T$: $Z = \\text{Tr}(T^N)$. In the thermodynamic limit where the length of the strip $N \\to \\infty$, the physical properties of the system are dominated by the largest eigenvalue, $\\lambda_0$, of the transfer matrix $T$.\n\nThe correlation length $\\xi$ characterizes the exponential decay of the spin-spin correlation function with distance. Along the transfer direction, this decay is governed by the ratio of the largest eigenvalue $\\lambda_0$ to the eigenvalue with the second-largest magnitude, which we denote $\\lambda_1$. The correlation length, measured in units of the lattice spacing between rows, is given by the formula:\n$$\n\\xi = \\frac{1}{\\ln\\left(\\frac{\\lambda_0}{|\\lambda_1|}\\right)}\n$$\nOur task is to construct the matrix $T$ for the given parameters, compute its eigenvalues, and use this formula to find $\\xi$.\n\nThe transfer matrix $T$ acts on the vector space spanned by the possible spin configurations of a single row. For a strip of width $W$, a row configuration is a vector $\\boldsymbol{s} = (s_1, s_2, \\dots, s_W)$, where each spin $s_i \\in \\{-1, +1\\}$. The total number of such configurations is $2^W$, so $T$ is a $2^W \\times 2^W$ matrix. The indices of this matrix correspond to the row configurations.\n\nThe matrix element $T_{\\boldsymbol{s},\\boldsymbol{s}'}$ connects a configuration $\\boldsymbol{s}$ in one row to a configuration $\\boldsymbol{s}'$ in the next row. The problem provides a symmetric definition for this element:\n$$\nT_{\\boldsymbol{s},\\boldsymbol{s}'} = \\exp\\left(K_v\\,\\mathcal{V}(\\boldsymbol{s},\\boldsymbol{s}') + \\frac{K_h}{2}\\,\\mathcal{H}_{\\text{row}}(\\boldsymbol{s}) + \\frac{K_h}{2}\\,\\mathcal{H}_{\\text{row}}(\\boldsymbol{s}')\\right)\n$$\nwhere $K_v$ and $K_h$ are the vertical and horizontal coupling constants, respectively. The terms in the exponent represent interaction energies:\n1.  $\\mathcal{V}(\\boldsymbol{s},\\boldsymbol{s}') = \\sum_{i=1}^{W} s_i s_i'$ is the interaction energy between the adjacent rows with configurations $\\boldsymbol{s}$ and $\\boldsymbol{s}'$.\n2.  $\\mathcal{H}_{\\text{row}}(\\boldsymbol{s}) = \\sum_{i=1}^{W} s_i s_{i+1}$ (with periodic boundary condition $s_{W+1} \\equiv s_1$) is the interaction energy within the row of configuration $\\boldsymbol{s}$. The symmetric splitting of this term between the two configurations $\\boldsymbol{s}$ and $\\boldsymbol{s}'$ ensures that the resulting matrix $T$ is symmetric ($T_{\\boldsymbol{s},\\boldsymbol{s}'} = T_{\\boldsymbol{s}',\\boldsymbol{s}}$).\n\nThe algorithm proceeds as follows:\n1.  **Generate State Space**: For a given width $W$, we first enumerate all $2^W$ possible spin configurations. This can be done by mapping the integers $k$ from $0$ to $2^W-1$ to unique spin vectors using their binary representations. For instance, the bits $b_i \\in \\{0, 1\\}$ of an integer can be mapped to spins $s_i \\in \\{+1, -1\\}$ via a transformation such as $s_i = 1 - 2b_i$. These configurations are stored in a matrix of size $2^W \\times W$.\n\n2.  **Construct Transfer Matrix $T$**: We construct the $2^W \\times 2^W$ matrix $T$. This process is amenable to vectorization for computational efficiency.\n    - The intra-row interaction energies $\\mathcal{H}_{\\text{row}}(\\boldsymbol{s})$ are pre-computed for all $2^W$ configurations.\n    - The matrix of all inter-row energies, with elements $\\mathcal{V}_{ij} = \\mathcal{V}(\\boldsymbol{s}^{(i)}, \\boldsymbol{s}^{(j)})$, can be calculated as the matrix product of the configuration matrix with its transpose.\n    - The matrix of summed intra-row energies, with elements $(\\mathcal{H}_{\\text{row}}(\\boldsymbol{s}^{(i)}) + \\mathcal{H}_{\\text{row}}(\\boldsymbol{s}^{(j)}))$, is formed using broadcasting operations on the pre-computed energy vector.\n    - Finally, the elements of $T$ are computed element-wise using the exponential function as defined.\n\n3.  **Solve Eigenvalue Problem**: Since $T$ is a real, symmetric matrix, all its eigenvalues are real. We use a standard numerical eigensolver optimized for symmetric matrices to find the complete spectrum. These solvers typically return the eigenvalues sorted in ascending order. The elements of $T$ are strictly positive for any real couplings $K_v, K_h$, so by the Perron-Frobenius theorem, there is a unique largest eigenvalue $\\lambda_0$ which is positive and of multiplicity one.\n\n4.  **Calculate Correlation Length**:\n    - The largest eigenvalue, $\\lambda_0$, is the last element of the sorted array of eigenvalues.\n    - To find $|\\lambda_1|$, the second-largest eigenvalue in magnitude, we identify the maximum of the absolute values of all other eigenvalues.\n    - The correlation length $\\xi$ is then computed using the formula $\\xi = 1/\\ln(\\lambda_0/|\\lambda_1|)$. As per the problem specification, if $|\\lambda_1|$ is numerically zero (within machine precision), we define $\\xi=0$.\n\nThis procedure is deterministic and provides the exact correlation length for the finite-width system as defined. The implementation will apply this method to each of the specified test cases.", "answer": "```python\nimport numpy as np\n\ndef calculate_xi(W, K_v, K_h):\n    \"\"\"\n    Calculates the correlation length for the 2D Ising model on a strip.\n\n    Args:\n        W (int): The width of the strip.\n        K_v (float): The dimensionless vertical coupling.\n        K_h (float): The dimensionless horizontal coupling.\n\n    Returns:\n        float: The calculated correlation length xi.\n    \"\"\"\n    num_configs = 1  W\n\n    # Step 1: Generate all 2^W spin configurations.\n    # We map integers 0 to 2^W-1 to spin configurations {-1, +1}^W.\n    # The j-th bit of integer i corresponds to the j-th spin.\n    # We use bit order from MSB to LSB for s_1 to s_W.\n    indices = np.arange(num_configs, dtype=int)\n    bit_positions = np.arange(W - 1, -1, -1)\n    bits = ((indices[:, None]  (1  bit_positions))  0).astype(np.int8)\n    configs = 1 - 2 * bits  # Map {0, 1} - {+1, -1}\n\n    # Step 2: Pre-calculate the horizontal interaction energy H_row for each configuration.\n    # H_row(s) = sum(s_i * s_{i+1}) with periodic s_{W+1}=s_1.\n    # np.roll shifts columns cyclically, implementing the periodic boundary condition.\n    H_values = np.sum(configs * np.roll(configs, -1, axis=1), axis=1)\n\n    # Step 3: Build the transfer matrix T in a vectorized manner.\n    # V_ij = sum(s_i_k * s_j_k), the vertical interaction between rows.\n    # This is equivalent to a matrix multiplication of the configs with its transpose.\n    V = configs @ configs.T\n\n    # H_sum_ij = H_i + H_j\n    # This is constructed using numpy's broadcasting rules.\n    H_sum = H_values[:, None] + H_values[None, :]\n\n    # T_ij = exp(K_v * V_ij + 0.5 * K_h * (H_i + H_j))\n    T = np.exp(K_v * V + 0.5 * K_h * H_sum)\n\n    # Step 4: Find eigenvalues.\n    # T is real and symmetric, so we use np.linalg.eigvalsh for efficiency.\n    # It returns real eigenvalues sorted in ascending order.\n    eigenvalues = np.linalg.eigvalsh(T)\n\n    # Step 5: Identify lambda_0 and the magnitude of lambda_1.\n    # lambda_0 is the largest eigenvalue.\n    lambda_0 = eigenvalues[-1]\n\n    # This case is not strictly necessary for W = 1, but is good practice.\n    if num_configs  2:\n        return 0.0\n\n    # |lambda_1| is the second-largest eigenvalue in magnitude. We find it by\n    # taking the maximum of the absolute values of all other eigenvalues.\n    other_evals = eigenvalues[:-1]\n    abs_lambda_1 = np.max(np.abs(other_evals))\n\n    # Step 6: Calculate the correlation length xi.\n    # Handle the case where the second largest eigenvalue is numerically zero.\n    if abs_lambda_1  1e-15:\n        return 0.0\n\n    # The ratio must be  1 for the logarithm to be positive. For a positive\n    # matrix, Perron-Frobenius guarantees lambda_0  |lambda_k| for all k!=0.\n    ratio = lambda_0 / abs_lambda_1\n    if ratio = 1.0:\n        # This case suggests numerical instability or degeneracy,\n        # which is not expected here. Returning infinity for a critical system.\n        return np.inf\n\n    xi = 1.0 / np.log(ratio)\n\n    return xi\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite of parameters.\n    \"\"\"\n    test_cases = [\n        # (W, K_v, K_h)\n        (1, 0.4, 0.4),  # Test case A\n        (3, 0.1, 0.2),  # Test case B\n        (4, 0.4, 0.4),  # Test case C\n        (5, 0.7, 0.7),  # Test case D\n    ]\n\n    results = []\n    for W, K_v, K_h in test_cases:\n        xi = calculate_xi(W, K_v, K_h)\n        results.append(xi)\n\n    # Format the results to 8 decimal places and print in the required format.\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the solver.\nsolve()\n```", "id": "2384603"}, {"introduction": "Near a phase transition, physical systems exhibit universal behavior described by critical exponents. Since numerical simulations are always performed on finite systems, finite-size scaling (FSS) is the essential tool for extracting these universal properties. In this exercise, you will act as a computational physicist analyzing synthetic simulation data to estimate the critical exponents $\\beta$, $\\gamma$, and $\\nu$ by applying the FSS hypothesis and linear regression, a standard and vital skill in the study of critical phenomena [@problem_id:2448171].", "problem": "You are given synthetic, noise-perturbed observables for the two-dimensional Ising model on square lattices of size $L \\times L$ at zero external field. The goal is to estimate the critical exponents $\\,\\beta\\,$, $\\,\\gamma\\,$, and $\\,\\nu\\,$ using finite-size scaling analysis. Your program must implement a principled analysis starting from the fundamental definitions and the finite-size scaling hypothesis, and then infer exponents by regression on the provided data. All quantities in this problem are dimensionless, so no unit conversion is needed.\n\nThe fundamental base is as follows.\n\n- The Ising Hamiltonian is $\\,\\mathcal{H} = -J \\sum_{\\langle i j \\rangle} s_i s_j - h \\sum_i s_i\\,$, with $\\,s_i \\in \\{-1,+1\\}\\,$, coupling $\\,J>0\\,$, and field $\\,h=0\\,$ for this problem.\n- The magnetization per spin is $\\,m = L^{-2} \\sum_i s_i\\,$. The static magnetic susceptibility is $\\,\\chi = L^{2} \\left(\\langle m^2 \\rangle - \\langle m \\rangle^2 \\right)/T\\,$.\n- The two-dimensional model with nearest-neighbor interactions has a known critical temperature $\\,T_c = \\dfrac{2J}{\\ln(1+\\sqrt{2})}\\,$. In reduced units $\\,J=1\\,$ and Boltzmann constant $\\,k_B=1\\,$, we use $\\,T_c = 2/\\ln(1+\\sqrt{2}) \\approx 2.269185314\\,$.\n\nThe well-tested finite-size scaling (FSS) hypothesis for the singular part of the free energy density states $\\,f_s(t,h,L) = L^{-d} \\mathcal{F}(t L^{1/\\nu}, h L^{y_h})\\,$, where $\\,d=2\\,$ is the spatial dimension, $\\,t=(T-T_c)/T_c\\,$ is the reduced temperature, $\\,\\nu\\,$ is the correlation length exponent, and $\\,y_h\\,$ is the scaling dimension of the magnetic field. From this hypothesis it follows that, at criticality $\\,t=0\\,$,\n- the magnetization scales as $\\,\\langle |m| \\rangle \\sim L^{-\\beta/\\nu}\\,$,\n- the susceptibility scales as $\\,\\chi \\sim L^{\\gamma/\\nu}\\,$,\n- the pseudo-critical temperature defined by the location $\\,T_{\\max}(L)\\,$ of the susceptibility peak approaches $\\,T_c\\,$ as $\\,T_{\\max}(L) - T_c \\sim L^{-1/\\nu}\\,$.\n\nYour task is to use these scaling statements to estimate $\\,\\beta\\,$, $\\,\\gamma\\,$, and $\\,\\nu\\,$ by fitting straight lines in appropriate log-log representations. Specifically, for each dataset,\n- fit $\\,\\log \\langle |m| \\rangle\\,$ versus $\\,\\log L\\,$ to estimate the slope $\\,s_m \\approx -\\beta/\\nu\\,$,\n- fit $\\,\\log \\chi\\,$ versus $\\,\\log L\\,$ to estimate the slope $\\,s_\\chi \\approx \\gamma/\\nu\\,$,\n- fit $\\,\\log\\!\\left(T_{\\max}(L)-T_c\\right)\\,$ versus $\\,\\log L\\,$ to estimate the slope $\\,s_t \\approx -1/\\nu\\,$,\nthen combine to obtain $\\,\\nu \\approx -1/s_t\\,$, $\\,\\beta \\approx (-s_m)\\,\\nu\\,$, and $\\,\\gamma \\approx (s_\\chi)\\,\\nu\\,$.\n\nUse ordinary least squares on the logarithms for the three fits. Do not assume any prior knowledge of the exact exponent values; infer them from the data.\n\nTest suite. The following three datasets emulate measurements produced by Markov Chain Monte Carlo (MCMC) near criticality with mild corrections to scaling. Use $\\,T_c = 2.269185314\\,$ exactly as given below in all computations of $\\,T_{\\max}(L)-T_c\\,$.\n\nDataset A:\n- $\\,L = [8,12,16,24,32,48,64]\\,$\n- $\\,\\langle |m| \\rangle = [0.806300,\\,0.742300,\\,0.706000,\\,0.660900,\\,0.631600,\\,0.595200,\\,0.572000]\\,$\n- $\\,\\chi = [32.300,\\,64.360,\\,105.430,\\,212.330,\\,350.690,\\,707.700,\\,1167.590]\\,$\n- $\\,T_{\\max}(L) = [2.387310314,\\,2.346685314,\\,2.326841314,\\,2.307310314,\\,2.297661914,\\,2.288091314,\\,2.283335714]\\,$\n\nDataset B:\n- $\\,L = [10,14,20,28,40,56,80]\\,$\n- $\\,\\langle |m| \\rangle = [0.937100,\\,0.864300,\\,0.801600,\\,0.750100,\\,0.703600,\\,0.665300,\\,0.627800]\\,$\n- $\\,\\chi = [45.840,\\,84.620,\\,160.970,\\,293.370,\\,555.000,\\,1003.200,\\,1891.000]\\,$\n- $\\,T_{\\max}(L) = [2.384415314,\\,2.350605314,\\,2.325688314,\\,2.309288314,\\,2.297116314,\\,2.289062314,\\,2.283059314]\\,$\n\nDataset C:\n- $\\,L = [6,8,10,12,14]\\,$\n- $\\,\\langle |m| \\rangle = [0.904500,\\,0.828700,\\,0.778300,\\,0.743600,\\,0.716900]\\,$\n- $\\,\\chi = [18.790,\\,29.925,\\,43.343,\\,58.709,\\,76.010]\\,$\n- $\\,T_{\\max}(L) = [2.420296314,\\,2.379185314,\\,2.355585314,\\,2.340296314,\\,2.329838314]\\,$\n\nRequirements:\n- Implement the three separate least-squares fits for each dataset using natural logarithms.\n- Compute $\\,\\nu\\,$ from the $\\,T_{\\max}(L)\\,$ shift fit, then compute $\\,\\beta\\,$ and $\\,\\gamma\\,$ from the magnetization and susceptibility fits using the estimates of $\\,\\beta/\\nu\\,$ and $\\,\\gamma/\\nu\\,$.\n- For each dataset, return a list $\\,[\\beta, \\gamma, \\nu]\\,$ with each value rounded to three decimal places using standard rounding to nearest.\n- Final Output Format: Your program should produce a single line of output containing the results as a comma-separated list of the three lists for the three datasets, enclosed in square brackets, for example $\\,[[\\beta_A,\\gamma_A,\\nu_A],[\\beta_B,\\gamma_B,\\nu_B],[\\beta_C,\\gamma_C,\\nu_C]]\\,$. No additional text should be printed.\n\nYour solution must be a complete, runnable program that reads no input and uses exactly the data above. The only allowed libraries are the Python standard library, NumPy, and SciPy.", "solution": "The analysis is founded upon the finite-size scaling (FSS) hypothesis. For a system of linear dimension $L$ in $d$ spatial dimensions, the singular part of the free energy density, denoted $f_s$, near a critical point is postulated to have the scaling form:\n$$f_s(t, h, L) = L^{-d} \\mathcal{F}(t L^{1/\\nu}, h L^{y_h})$$\nHere, $t = (T-T_c)/T_c$ is the reduced temperature, $h$ is the external magnetic field, $\\nu$ is the correlation length critical exponent, and $y_h$ is the scaling dimension of the magnetic field. For this problem, the spatial dimension is $d=2$. The analysis is performed at the critical temperature, where $t=0$, and zero external field, $h=0$.\n\nFrom the FSS hypothesis, scaling relations for various thermodynamic quantities can be derived. The problem correctly provides the necessary relations for the observables at criticality:\n1.  The average absolute magnetization per spin, $\\langle |m| \\rangle$, scales with system size $L$ as:\n    $$\\langle |m| \\rangle \\propto L^{-\\beta/\\nu}$$\n    where $\\beta$ is the magnetization critical exponent.\n2.  The magnetic susceptibility, $\\chi$, scales as:\n    $$\\chi \\propto L^{\\gamma/\\nu}$$\n    where $\\gamma$ is the susceptibility critical exponent.\n3.  The location of the susceptibility peak for a finite system, $T_{\\max}(L)$, approaches the true critical temperature $T_c$ in the thermodynamic limit ($L \\to \\infty$) according to the relation:\n    $$T_{\\max}(L) - T_c \\propto L^{-1/\\nu}$$\nThese power-law dependencies form the basis for our estimation procedure.\n\nTo determine the exponents from the provided data, we transform these power-law relations into linear equations by applying the natural logarithm to both sides:\n1.  $\\ln(\\langle |m| \\rangle) = C_m - (\\beta/\\nu) \\ln L$\n2.  $\\ln(\\chi) = C_\\chi + (\\gamma/\\nu) \\ln L$\n3.  $\\ln(T_{\\max}(L) - T_c) = C_t - (1/\\nu) \\ln L$\nHere, $C_m$, $C_\\chi$, and $C_t$ are constants. Each of these equations is of the linear form $y = c + s \\cdot x$, where the independent variable is $x = \\ln L$ and the dependent variable $y$ is the logarithm of the corresponding observable quantity. The slopes of these lines are directly related to the critical exponents: $s_m = -\\beta/\\nu$, $s_\\chi = \\gamma/\\nu$, and $s_t = -1/\\nu$. These slopes can be determined numerically via ordinary least squares (OLS) linear regression.\n\nThe computational procedure is executed for each of the three datasets as follows:\na.  For each lattice size $L_i$ in a given dataset, the independent variable for all regressions is prepared as $x_i = \\ln(L_i)$.\nb.  The dependent variables for the regressions are computed: $y_{m,i} = \\ln(\\langle |m| \\rangle_i)$, $y_{\\chi,i} = \\ln(\\chi_i)$, and $y_{t,i} = \\ln(T_{\\max}(L)_i - T_c)$. For the calculation of $y_{t,i}$, the provided value of the critical temperature, $T_c = 2.269185314$, is used.\nc.  Three independent OLS regressions are performed to find the best-fit slopes:\n    -   $s_m$ is obtained from the regression of $y_m$ versus $x$.\n    -   $s_\\chi$ is obtained from the regression of $y_\\chi$ versus $x$.\n    -   $s_t$ is obtained from the regression of $y_t$ versus $x$.\nd.  The critical exponents are then calculated from these estimated slopes using the specified relations:\n    -   $\\nu = -1 / s_t$\n    -   $\\beta = -s_m \\cdot \\nu$\n    -   $\\gamma = s_\\chi \\cdot \\nu$\ne.  Finally, the computed values of $\\beta$, $\\gamma$, and $\\nu$ are rounded to three decimal places as required. This entire procedure is implemented systematically in the accompanying program. The known exact values for the two-dimensional Ising model are $\\beta = 1/8=0.125$, $\\gamma = 7/4=1.75$, and $\\nu=1$. The results from the provided data, which include noise and corrections to scaling, are expected to be approximations of these theoretical values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Estimates the critical exponents beta, gamma, and nu for the 2D Ising model\n    using finite-size scaling analysis on three provided datasets.\n    \"\"\"\n    \n    # Define the critical temperature T_c as given in the problem statement.\n    T_c = 2.269185314\n\n    # The three datasets provided in the problem statement.\n    datasets = [\n        # Dataset A\n        {\n            \"L\": np.array([8, 12, 16, 24, 32, 48, 64]),\n            \"m_abs\": np.array([0.806300, 0.742300, 0.706000, 0.660900, 0.631600, 0.595200, 0.572000]),\n            \"chi\": np.array([32.300, 64.360, 105.430, 212.330, 350.690, 707.700, 1167.590]),\n            \"T_max\": np.array([2.387310314, 2.346685314, 2.326841314, 2.307310314, 2.297661914, 2.288091314, 2.283335714])\n        },\n        # Dataset B\n        {\n            \"L\": np.array([10, 14, 20, 28, 40, 56, 80]),\n            \"m_abs\": np.array([0.937100, 0.864300, 0.801600, 0.750100, 0.703600, 0.665300, 0.627800]),\n            \"chi\": np.array([45.840, 84.620, 160.970, 293.370, 555.000, 1003.200, 1891.000]),\n            \"T_max\": np.array([2.384415314, 2.350605314, 2.325688314, 2.309288314, 2.297116314, 2.289062314, 2.283059314])\n        },\n        # Dataset C\n        {\n            \"L\": np.array([6, 8, 10, 12, 14]),\n            \"m_abs\": np.array([0.904500, 0.828700, 0.778300, 0.743600, 0.716900]),\n            \"chi\": np.array([18.790, 29.925, 43.343, 58.709, 76.010]),\n            \"T_max\": np.array([2.420296314, 2.379185314, 2.355585314, 2.340296314, 2.329838314])\n        }\n    ]\n\n    all_results = []\n\n    for data in datasets:\n        # Prepare the variables for linear regression by taking natural logarithms.\n        log_L = np.log(data[\"L\"])\n        \n        # 1. Magnetization fit: log(|m|) = C_m - (beta/nu) * log(L)\n        log_m = np.log(data[\"m_abs\"])\n        # Perform OLS regression to find the slope s_m = -beta/nu\n        s_m = stats.linregress(log_L, log_m).slope\n        \n        # 2. Susceptibility fit: log(chi) = C_chi + (gamma/nu) * log(L)\n        log_chi = np.log(data[\"chi\"])\n        # Perform OLS regression to find the slope s_chi = gamma/nu\n        s_chi = stats.linregress(log_L, log_chi).slope\n        \n        # 3. T_max shift fit: log(T_max(L) - T_c) = C_t - (1/nu) * log(L)\n        log_T_shift = np.log(data[\"T_max\"] - T_c)\n        # Perform OLS regression to find the slope s_t = -1/nu\n        s_t = stats.linregress(log_L, log_T_shift).slope\n        \n        # Calculate the critical exponents from the slopes.\n        nu = -1.0 / s_t\n        beta = -s_m * nu\n        gamma = s_chi * nu\n        \n        # Round the results to three decimal places.\n        beta_rounded = round(beta, 3)\n        gamma_rounded = round(gamma, 3)\n        nu_rounded = round(nu, 3)\n        \n        # Store the list of exponents for the current dataset.\n        all_results.append([beta_rounded, gamma_rounded, nu_rounded])\n        \n    # Format the final output according to the problem specification.\n    # The string representation of a list of lists is converted to a compact\n    # format by removing all space characters.\n    final_output_string = str(all_results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```", "id": "2448171"}]}