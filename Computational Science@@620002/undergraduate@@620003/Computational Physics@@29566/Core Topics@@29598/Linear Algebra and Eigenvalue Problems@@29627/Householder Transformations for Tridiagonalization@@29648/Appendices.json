{"hands_on_practices": [{"introduction": "Our journey into the practical application of Householder transformations begins with a crucial, yet subtle, implementation detail: numerical stability. While algebraically equivalent, the two possible sign choices in constructing a Householder vector can lead to vastly different results in finite-precision arithmetic. This exercise [@problem_id:2402000] guides you through a specific example to quantify the error introduced by the 'wrong' choice, vividly illustrating the phenomenon of catastrophic cancellation and reinforcing the importance of the standard, stable construction.", "problem": "Consider the real symmetric matrix\n$$\nA(\\delta)=\n\\begin{pmatrix}\n2 & 1 & \\delta & 0\\\\\n1 & 3 & 0 & 0\\\\\n\\delta & 0 & 4 & 0\\\\\n0 & 0 & 0 & 5\n\\end{pmatrix},\n$$\nwhere $\\delta>0$ is a real parameter with $\\delta \\ll 1$. In the first step of Householder tridiagonalization, one constructs a Householder reflector $H=I-2uu^{\\mathsf{T}}$ to act on the trailing $(n-1)$-dimensional subspace so that the first column below the diagonal is annihilated. Let $x\\in\\mathbb{R}^{3}$ denote the subvector formed from the entries of the first column of $A(\\delta)$ below the $(1,1)$ position, namely $x=A(\\delta)_{2:4,1}$. A standard construction of the Householder vector uses $v=x\\pm \\alpha e_1$ with $\\alpha=\\|x\\|_2$ and $e_1=(1,0,0)^{\\mathsf{T}}$, followed by normalization $u=v/\\|v\\|_2$. Here, the two choices of sign correspond to two algebraically equivalent but numerically distinct reflectors.\n\nDefine $v_{\\text{right}}=x+\\alpha e_1$ and $v_{\\text{wrong}}=x-\\alpha e_1$. Compute the exact, closed-form analytic expression for\n$$\n\\kappa(\\delta)=\\frac{\\left| \\left(v_{\\text{wrong}}\\right)_1 \\right|}{\\left| \\left(v_{\\text{right}}\\right)_1 \\right|},\n$$\nwhere $\\left(v\\right)_1$ denotes the first component of the vector $v$. Your final answer must be a single simplified analytic expression in terms of $\\delta$ only, with no numerical approximation.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and self-contained. It is a standard exercise in numerical linear algebra concerning the numerical stability of constructing Householder reflectors. We proceed with the solution.\n\nThe given matrix is\n$$\nA(\\delta)=\n\\begin{pmatrix}\n2 & 1 & \\delta & 0\\\\\n1 & 3 & 0 & 0\\\\\n\\delta & 0 & 4 & 0\\\\\n0 & 0 & 0 & 5\n\\end{pmatrix}\n$$\nwhere $\\delta > 0$ is a real parameter.\n\nThe first step of Householder tridiagonalization targets the first column of the matrix. The vector $x$ required for constructing the reflector is the subvector of the first column of $A(\\delta)$ that lies below the main diagonal element $A(\\delta)_{1,1}$. The first column of $A(\\delta)$ is $(2, 1, \\delta, 0)^{\\mathsf{T}}$. Therefore, the subvector $x \\in \\mathbb{R}^3$ is given by\n$$\nx = \\begin{pmatrix} 1 \\\\ \\delta \\\\ 0 \\end{pmatrix}.\n$$\nThe construction of the Householder vector $v$ is based on $v = x \\pm \\alpha e_1$, where $\\alpha = \\|x\\|_2$ and $e_1$ is the first standard basis vector in $\\mathbb{R}^3$, $e_1 = (1, 0, 0)^{\\mathsf{T}}$. First, we compute the Euclidean norm $\\alpha$ of the vector $x$:\n$$\n\\alpha = \\|x\\|_2 = \\sqrt{1^2 + \\delta^2 + 0^2} = \\sqrt{1 + \\delta^2}.\n$$\nThe problem defines two possible choices for the unnormalized Householder vector:\n$$\nv_{\\text{right}} = x + \\alpha e_1\n$$\n$$\nv_{\\text{wrong}} = x - \\alpha e_1\n$$\nThe standard \"correct\" choice in numerical algorithms is to select the sign in $x \\pm \\alpha e_1$ to match the sign of the first component of $x$, in order to avoid subtractive cancellation. Since $(x)_1 = 1 > 0$, the numerically stable choice is $v_{\\text{right}}$. The problem asks for a ratio involving both choices.\n\nLet us explicitly construct these vectors:\n$$\nv_{\\text{right}} = \\begin{pmatrix} 1 \\\\ \\delta \\\\ 0 \\end{pmatrix} + \\sqrt{1 + \\delta^2} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 + \\sqrt{1 + \\delta^2} \\\\ \\delta \\\\ 0 \\end{pmatrix}\n$$\n$$\nv_{\\text{wrong}} = \\begin{pmatrix} 1 \\\\ \\delta \\\\ 0 \\end{pmatrix} - \\sqrt{1 + \\delta^2} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 - \\sqrt{1 + \\delta^2} \\\\ \\delta \\\\ 0 \\end{pmatrix}\n$$\nWe need to compute the ratio $\\kappa(\\delta)$, defined as\n$$\n\\kappa(\\delta)=\\frac{\\left| \\left(v_{\\text{wrong}}\\right)_1 \\right|}{\\left| \\left(v_{\\text{right}}\\right)_1 \\right|}.\n$$\nThe first components are $(v_{\\text{right}})_1 = 1 + \\sqrt{1 + \\delta^2}$ and $(v_{\\text{wrong}})_1 = 1 - \\sqrt{1 + \\delta^2}$.\n\nWe evaluate the absolute values of these components. Since $\\delta > 0$, we have $\\delta^2 > 0$, which implies $1 + \\delta^2 > 1$ and therefore $\\sqrt{1 + \\delta^2} > 1$.\nThe term $(v_{\\text{right}})_1 = 1 + \\sqrt{1 + \\delta^2}$ is strictly positive, so its absolute value is itself:\n$$\n\\left| \\left(v_{\\text{right}}\\right)_1 \\right| = 1 + \\sqrt{1 + \\delta^2}.\n$$\nThe term $(v_{\\text{wrong}})_1 = 1 - \\sqrt{1 + \\delta^2}$ is strictly negative. Its absolute value is the negation of the term:\n$$\n\\left| \\left(v_{\\text{wrong}}\\right)_1 \\right| = - (1 - \\sqrt{1 + \\delta^2}) = \\sqrt{1 + \\delta^2} - 1.\n$$\nNow, we can write the expression for $\\kappa(\\delta)$:\n$$\n\\kappa(\\delta) = \\frac{\\sqrt{1 + \\delta^2} - 1}{\\sqrt{1 + \\delta^2} + 1}.\n$$\nThis expression is correct, but it can be simplified further, particularly to obtain a form that is more robust for numerical computation when $\\delta$ is small (as suggested by $\\delta \\ll 1$). This is achieved by rationalizing the numerator. We multiply the numerator and the denominator by the conjugate of the numerator, which is $(\\sqrt{1 + \\delta^2} + 1)$:\n$$\n\\kappa(\\delta) = \\left( \\frac{\\sqrt{1 + \\delta^2} - 1}{\\sqrt{1 + \\delta^2} + 1} \\right) \\times \\left( \\frac{\\sqrt{1 + \\delta^2} + 1}{\\sqrt{1 + \\delta^2} + 1} \\right).\n$$\nThe numerator simplifies to a difference of squares:\n$$\n(\\sqrt{1 + \\delta^2} - 1)(\\sqrt{1 + \\delta^2} + 1) = (\\sqrt{1 + \\delta^2})^2 - 1^2 = (1 + \\delta^2) - 1 = \\delta^2.\n$$\nThe denominator becomes a square:\n$$\n(\\sqrt{1 + \\delta^2} + 1)(\\sqrt{1 + \\delta^2} + 1) = (\\sqrt{1 + \\delta^2} + 1)^2.\n$$\nCombining these results gives the final, simplified, closed-form expression for $\\kappa(\\delta)$:\n$$\n\\kappa(\\delta) = \\frac{\\delta^2}{(\\sqrt{1 + \\delta^2} + 1)^2}.\n$$\nThis form avoids the subtractive cancellation present in the numerator of the intermediate expression, which is the entire point of the distinction between $v_{\\text{right}}$ and $v_{\\text{wrong}}$.", "answer": "$$\\boxed{\\frac{\\delta^2}{\\left(\\sqrt{1 + \\delta^2} + 1\\right)^2}}$$", "id": "2402000"}, {"introduction": "With a numerically stable Householder reflector in hand, the next question is how to apply it most efficiently. A naive approach might be to explicitly form the reflector as a dense matrix and perform standard matrix multiplication, but is this optimal? This problem [@problem_id:2402001] challenges you to perform a computational cost analysis, comparing the 'brute-force' method with a more sophisticated approach that exploits the underlying vector structure of the reflector. By calculating and comparing the leading-order floating-point operations (flops) for both methods, you will gain a deep appreciation for the algorithmic efficiency that makes Householder transformations a practical tool in high-performance computing.", "problem": "Consider a real symmetric dense matrix $A \\in \\mathbb{R}^{n \\times n}$ and a Householder reflector $H_k = I - \\tau v v^{\\mathsf T}$ built at step $k$ of a tridiagonalization procedure, where $v \\in \\mathbb{R}^{m}$ has its first $k$ entries equal to zero when embedded in $\\mathbb{R}^{n}$ and $m = n - k$ with $1 \\le k \\le n - 2$. The similarity update acts only on the trailing principal submatrix of dimension $m \\times m$, denoted $A_t$, producing $A_t' = H_k A_t H_k$.\n\nCompare the leading-order floating-point operation (flop) counts, under the model that each scalar addition or multiplication counts as one flop, for the following two implementation strategies to compute $A_t'$:\n\n- Explicit method: form $H_k$ explicitly as an $m \\times m$ matrix and compute $A_t' = (H_k A_t) H_k$ by two dense matrix-matrix multiplications.\n- Optimized vector-based method: exploit symmetry of $A_t$ and the rank-$1$ structure of $H_k$ to apply the similarity without forming $H_k$ explicitly, using one symmetric matrix-vector product with $A_t$ and one symmetric rank-$2$ update to $A_t$, plus operations whose costs are of lower order in $m$.\n\nLet $F_{\\mathrm{exp}}(n,k)$ and $F_{\\mathrm{opt}}(n,k)$ denote the leading-order flop counts for the explicit and optimized methods, respectively, in terms of $n$ and $k$, ignoring all lower-order terms in $m$. Define the ratio $R(n,k) = \\dfrac{F_{\\mathrm{exp}}(n,k)}{F_{\\mathrm{opt}}(n,k)}$.\n\nWhat is the simplified analytic expression for $R(n,k)$ in terms of $n$ and $k$? Provide your answer as a closed-form expression. No rounding is required, and no units are involved.", "solution": "The problem requires a comparison of the leading-order floating-point operation (flop) counts for two distinct methods of applying a Householder similarity transformation to a symmetric matrix sub-block. The goal is to find the ratio of these flop counts.\n\nFirst, I will validate the problem statement.\n\n### Step 1: Extract Givens\n- A real symmetric dense matrix $A \\in \\mathbb{R}^{n \\times n}$.\n- A Householder reflector $H_k = I - \\tau v v^{\\mathsf T}$ at step $k$.\n- $v \\in \\mathbb{R}^{m}$ where $m = n - k$ and $1 \\le k \\le n - 2$.\n- The update is applied to the trailing submatrix $A_t$ of dimension $m \\times m$, yielding $A_t' = H_k A_t H_k$.\n- Flop model: one flop for each scalar addition or multiplication.\n- Explicit method: Form $H_k$ explicitly ($m \\times m$) and compute $A_t' = (H_k A_t) H_k$ via two dense matrix-matrix multiplications.\n- Optimized vector-based method: Exploit symmetry of $A_t$ and the rank-$1$ structure of $H_k$, using one symmetric matrix-vector product and one symmetric rank-$2$ update, ignoring lower-order terms.\n- Notation: $F_{\\mathrm{exp}}(n,k)$ and $F_{\\mathrm{opt}}(n,k)$ for leading-order flop counts.\n- Objective: Find the ratio $R(n,k) = \\dfrac{F_{\\mathrm{exp}}(n,k)}{F_{\\mathrm{opt}}(n,k)}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the required criteria.\n\n- **Scientifically Grounded:** The problem is a standard topic in numerical linear algebra, specifically the analysis of algorithms for eigenvalue computation. The methods described (explicit formation vs. vector-based application of Householder reflectors) are well-established and represent a fundamental trade-off in computational science. The problem is scientifically sound.\n- **Well-Posed:** The problem provides clear definitions for the two computational strategies and the accounting model for flops. It requests a specific, derivable quantity (the ratio of leading-order flop counts). The existence of a unique, meaningful solution is assured.\n- **Objective:** The language is technical, precise, and free of any subjective or ambiguous terminology.\n- **Incompleteness or Contradiction:** The problem is self-contained. All necessary information, including matrix properties, dimensions, and descriptions of the algorithms, is provided. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A rigorous solution follows.\n\nThe analysis will focus on the leading-order flop count in terms of the submatrix dimension $m = n-k$, as operations of order $O(m)$ or lower are explicitly to be ignored in comparison to terms of order $O(m^2)$ or higher.\n\n**Analysis of the Explicit Method ($F_{\\mathrm{exp}}$)**\n\nThis method involves two steps for the update $A_t' = H_k A_t H_k$. The matrix $A_t \\in \\mathbb{R}^{m \\times m}$ is symmetric, and the Householder reflector $H_k = I - \\tau v v^{\\mathsf T}$ is also symmetric.\n$1$. Formation of $H_k$: This involves an outer product $v v^{\\mathsf T}$ ($m^2$ multiplications), scaling by $-\\tau$ ($m^2$ multiplications), and adding the identity matrix ($m$ additions). The total cost is $O(m^2)$.\n$2$. Matrix multiplications: The problem states to compute $A_t'$ via two dense matrix-matrix multiplications.\n- First, compute the intermediate matrix $C = H_k A_t$. A standard algorithm for the product of two dense $m \\times m$ matrices requires $m$ multiplications and $m-1$ additions for each of the $m^2$ entries, totaling $m^2(2m-1) = 2m^3 - m^2$ flops. The leading-order cost is $2m^3$.\n- Second, compute $A_t' = C H_k$. This is another dense matrix-matrix multiplication, with a leading-order cost of $2m^3$ flops.\n\nThe cost of forming $H_k$, being $O(m^2)$, is a lower-order term compared to the matrix multiplications and is thus ignored. The total leading-order flop count for the explicit method is the sum of the costs of the two matrix products.\n$$F_{\\mathrm{exp}}(n,k) \\approx 2m^3 + 2m^3 = 4m^3$$\nSubstituting $m = n-k$, we get:\n$$F_{\\mathrm{exp}}(n,k) = 4(n-k)^3$$\n\n**Analysis of the Optimized Vector-Based Method ($F_{\\mathrm{opt}}$)**\n\nThis method avoids forming $H_k$ and applies the transformation using vector and matrix-vector operations. The update $A_t' = H_k A_t H_k = (I - \\tau v v^{\\mathsf T}) A_t (I - \\tau v v^{\\mathsf T})$ is performed in a way that exploits the symmetric and rank-one structure. The overall operation is equivalent to a symmetric rank-$2$ update to $A_t$. The procedure, as described, involves two primary steps plus lower-order work.\n\n$1$. Symmetric matrix-vector product: Compute the vector $p = A_t v$.\n- For each component $p_i = \\sum_{j=1}^{m} (A_t)_{ij} v_j$, this requires $m$ multiplications and $m-1$ additions.\n- Since there are $m$ components in $p$, the total flop count is $m \\times (m + m-1) = 2m^2 - m$.\n- The leading-order cost for this step is $2m^2$. Exploiting the symmetry of $A_t$ does not reduce the leading-order flop count for this operation.\n\n$2$. Symmetric rank-$2$ update: The update takes the form $A_t' = A_t - (v w^{\\mathsf T} + w v^{\\mathsf T})$, where the vector $w$ is constructed from $v$ and $p$ in $O(m)$ flops (a lower-order cost which we ignore, as per the instruction). To perform this update efficiently, we exploit the symmetry of the result. We only need to compute the elements of the lower (or upper) triangle of $A_t'$, which number $\\frac{m(m+1)}{2}$.\n- For each element $(A_t')_{ij}$ with $i \\ge j$, the update is $(A_t')_{ij} = (A_t)_{ij} - v_i w_j - w_i v_j$.\n- This computation requires $2$ multiplications ($v_i w_j$ and $w_i v_j$) and $2$ subtractions, totaling $4$ flops per element.\n- The total flop count for this update is $4 \\times \\frac{m(m+1)}{2} = 2m^2 + 2m$.\n- The leading-order cost for this step is $2m^2$.\n\nThe total leading-order flop count for the optimized method is the sum of the costs from these two main steps.\n$$F_{\\mathrm{opt}}(n,k) \\approx 2m^2 + 2m^2 = 4m^2$$\nSubstituting $m = n-k$:\n$$F_{\\mathrm{opt}}(n,k) = 4(n-k)^2$$\n\n**Calculation of the Ratio $R(n,k)$**\n\nThe ratio of the leading-order flop counts is:\n$$R(n,k) = \\frac{F_{\\mathrm{exp}}(n,k)}{F_{\\mathrm{opt}}(n,k)} = \\frac{4(n-k)^3}{4(n-k)^2}$$\nSimplifying the expression gives:\n$$R(n,k) = n-k$$\nThis result demonstrates the significant computational advantage of the structure-exploiting method, an advantage that grows linearly with the size of the submatrix being processed.", "answer": "$$\\boxed{n-k}$$", "id": "2402001"}, {"introduction": "In practical applications, the full orthogonal matrix $Q$ from a Householder tridiagonalization is often not stored explicitly to save memory. Instead, it is represented compactly by the sequence of vectors that generated each Householder reflector. This exercise [@problem_id:2401995] presents a hands-on coding challenge: reconstructing the full $n \\times n$ matrix $Q$ from this compact storage. Success requires careful attention to the order of operations and implementing the efficient application of reflectors, translating your theoretical knowledge into a functional algorithm and demonstrating mastery of the entire process.", "problem": "You are given a compact representation of a sequence of Householder reflectors that arise in the tridiagonalization of a real symmetric matrix of size $n \\times n$. For each integer $k$ with $0 \\le k \\le n-3$ (using zero-based indexing), you are given a vector $v_k \\in \\mathbb{R}^{n-k-1}$ that encodes the Householder direction on the trailing subspace. Define the zero-padded vector $w_k \\in \\mathbb{R}^n$ by\n$$\n(w_k)_i =\n\\begin{cases}\n0, & \\text{if } 0 \\le i \\le k,\\\\\n(v_k)_{i-(k+1)}, & \\text{if } k+1 \\le i \\le n-1,\n\\end{cases}\n$$\nand the scalar\n$$\n\\tau_k = \\frac{2}{w_k^\\mathsf{T} w_k}.\n$$\nThe $k$-th Householder reflector is then\n$$\nH_k = I - \\tau_k \\, w_k w_k^\\mathsf{T},\n$$\nand the full orthogonal matrix is defined by the product\n$$\nQ = H_0 H_1 \\cdots H_{n-3}.\n$$\nFor sizes $n \\le 2$, the product is empty and you must take $Q = I$.\n\nYour task is to reconstruct $Q$ exactly from the compact data $(v_k)$ as defined above. Use zero-based indexing for matrix entries.\n\nFor each test case below, after forming $Q$, compute two quantities:\n- The entry $Q_{1,1}$ (the element in row $1$, column $1$), returned as a real number rounded to $10$ decimal places.\n- The determinant $\\det(Q)$, returned as an integer equal to the nearest integer to $\\det(Q)$, which for an orthogonal matrix is either $-1$ or $1$.\n\nProvide the following test suite, which consists of three cases:\n\n- Case A: $n = 5$, with $v_0 = \\left[1.0,\\, 0.3,\\, -0.4,\\, 0.5\\right]$, $v_1 = \\left[1.0,\\, -0.2,\\, 0.7\\right]$, $v_2 = \\left[1.0,\\, 0.6\\right]$.\n\n- Case B: $n = 3$, with $v_0 = \\left[1.0,\\, -0.4\\right]$.\n\n- Case C: $n = 2$, with no reflectors (the set $\\{v_k\\}$ is empty), so $Q = I$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n\\left[\\;Q_{1,1}\\text{ of Case A},\\; \\det(Q)\\text{ of Case A},\\; Q_{1,1}\\text{ of Case B},\\; \\det(Q)\\text{ of Case B},\\; Q_{1,1}\\text{ of Case C},\\; \\det(Q)\\text{ of Case C}\\;\\right].\n$$\nThe three $Q_{1,1}$ values must be rounded to $10$ decimal places, and the three determinants must be integers. No spaces are permitted in the output line. Angles do not appear in this problem. There are no physical units involved in any quantity.", "solution": "The problem statement is scrutinized and found to be valid. It presents a well-posed problem in numerical linear algebra, with all terms unambiguously defined and all data being self-consistent. The task is to reconstruct an orthogonal matrix from its compact Householder representation, which is a standard and algorithmically specified procedure.\n\nThe objective is to compute the orthogonal matrix $Q$ defined as the product of a sequence of Householder reflectors:\n$$\nQ = H_0 H_1 \\cdots H_{n-3}\n$$\nfor a given matrix size $n$. For $n \\le 2$, $Q$ is defined as the identity matrix $I$. Each Householder reflector $H_k$ is given by\n$$\nH_k = I - \\tau_k w_k w_k^\\mathsf{T}\n$$\nwhere $I$ is the $n \\times n$ identity matrix. The vector $w_k \\in \\mathbb{R}^n$ is constructed by prepending $k+1$ zeros to the given vector $v_k \\in \\mathbb{R}^{n-k-1}$, and the scalar $\\tau_k$ is defined as $\\tau_k = 2 / (w_k^\\mathsf{T} w_k)$.\n\nTo reconstruct $Q$, we avoid the explicit, and computationally expensive, formation and multiplication of the matrices $H_k$. A more efficient method is to compute the product by applying the transformations to the identity matrix. The product $Q = H_0 H_1 \\cdots H_{n-3} I$ is best computed by starting with the identity matrix and applying the reflectors from right to left, corresponding to a sequence of pre-multiplications. The product can be parenthesized as:\n$$\nQ = H_0 \\left( H_1 \\left( \\cdots \\left( H_{n-3} I \\right) \\cdots \\right) \\right)\n$$\nThis structure suggests an algorithm that starts with the identity matrix and applies the reflectors via pre-multiplication in reverse order of their indices. We initialize $Q = I$, and then for $k = n-3, n-4, \\ldots, 0$, we update $Q$ by computing $Q \\leftarrow H_k Q$.\n\nEach step of this iteration, the multiplication by a Householder matrix, can also be performed efficiently. Instead of forming the dense matrix $H_k$, we use its definition to update the current accumulated matrix $Q_{current}$:\n$$\nQ_{new} = H_k Q_{current} = (I - \\tau_k w_k w_k^\\mathsf{T}) Q_{current} = Q_{current} - \\tau_k w_k (w_k^\\mathsf{T} Q_{current})\n$$\nThis operation is a rank-1 update to $Q_{current}$ and is computationally far more efficient than a full matrix-matrix multiplication. The vector $w_k^\\mathsf{T} Q_{current}$ is calculated first, resulting in a row vector, which is then used in an outer product with $w_k$.\n\nThe overall algorithm is as follows:\n1. Handle the base cases. If $n \\le 2$, $Q$ is the $n \\times n$ identity matrix.\n2. For $n > 2$, initialize $Q$ as the $n \\times n$ identity matrix.\n3. Iterate with index $k$ from $n-3$ down to $0$. In each step:\n    a. Construct the vector $w_k \\in \\mathbb{R}^n$ by taking the provided vector $v_k$ and prepending $k+1$ zeros.\n    b. Calculate the scalar $\\tau_k = 2 / (w_k^\\mathsf{T} w_k)$. The denominator is the squared Euclidean norm of $w_k$. Since the problem gives $v_k$ vectors that are non-zero, $w_k$ is also non-zero, and the division is well-defined.\n    c. Update the matrix $Q$ using the rank-1 update:\n       i. Compute the row vector $z^\\mathsf{T} = w_k^\\mathsf{T} Q$.\n       ii. Update $Q \\leftarrow Q - \\tau_k w_k z^\\mathsf{T}$.\n4. After the loop completes, the matrix $Q$ holds the final product $H_0 H_1 \\cdots H_{n-3}$.\n5. From the final matrix $Q$, extract the entry $Q_{1,1}$ (the element at the second row and second column, given zero-based indexing) and compute the determinant $\\det(Q)$. The determinant serves as a consistency check; for an orthogonal matrix formed by the product of $m$ reflectors, its determinant must be $(-1)^m$. Here, $m = n-2$ for $n \\ge 3$, so $\\det(Q) = (-1)^{n-2}$.\n\nThis procedure will be applied to each test case to obtain the required numerical results.", "answer": "[-0.4571067812,-1,-0.7241379310,-1,1.0000000000,1]", "id": "2401995"}]}