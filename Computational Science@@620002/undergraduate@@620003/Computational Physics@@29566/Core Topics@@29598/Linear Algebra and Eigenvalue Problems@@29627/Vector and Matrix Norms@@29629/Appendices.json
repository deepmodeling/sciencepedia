{"hands_on_practices": [{"introduction": "To effectively apply matrix norms in physics and engineering, we must first be fluent in their calculation. This foundational exercise provides direct practice in applying the definitions of the most common matrix norms—the $1$-norm, $\\infty$-norm, spectral ($2$-norm), and Frobenius norm. By working through these calculations for a simple but illustrative matrix, you will solidify your understanding of these essential tools and build the computational dexterity required for more advanced analysis [@problem_id:2449594].", "problem": "Let $m,n \\in \\mathbb{N}$ with $m \\geq 1$ and $n \\geq 1$. For a matrix $A \\in \\mathbb{R}^{m \\times n}$ and $p \\in \\{1,2,\\infty\\}$, the operator norm induced by the vector $p$-norm is defined by\n$$\n\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}},\n$$\nwhere, for $x \\in \\mathbb{R}^{k}$, the vector norms are $\\|x\\|_{1} = \\sum_{i=1}^{k} |x_{i}|$, $\\|x\\|_{2} = \\sqrt{\\sum_{i=1}^{k} |x_{i}|^{2}}$, and $\\|x\\|_{\\infty} = \\max_{1 \\leq i \\leq k} |x_{i}|$. The Frobenius norm of $A$ is defined by\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}.\n$$\nConsider the all-ones matrix $J \\in \\mathbb{R}^{m \\times n}$ with entries $J_{ij} = 1$ for all $i,j$. Determine $\\|J\\|_{1}$, $\\|J\\|_{2}$, $\\|J\\|_{\\infty}$, and $\\|J\\|_{F}$ as explicit functions of $m$ and $n$. Provide your final answer as a single row vector in the order $\\big(\\|J\\|_{1}, \\|J\\|_{2}, \\|J\\|_{\\infty}, \\|J\\|_{F}\\big)$. The answer must be exact; do not approximate.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- $m, n \\in \\mathbb{N}$ with $m \\geq 1$ and $n \\geq 1$.\n- Matrix $A \\in \\mathbb{R}^{m \\times n}$.\n- Operator norm: $\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}}$ for $p \\in \\{1, 2, \\infty\\}$.\n- Vector norms for $x \\in \\mathbb{R}^{k}$:\n  - $\\|x\\|_{1} = \\sum_{i=1}^{k} |x_{i}|$\n  - $\\|x\\|_{2} = \\sqrt{\\sum_{i=1}^{k} |x_{i}|^{2}}$\n  - $\\|x\\|_{\\infty} = \\max_{1 \\leq i \\leq k} |x_{i}|$\n- Frobenius norm: $\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}$.\n- The matrix under consideration is the all-ones matrix $J \\in \\mathbb{R}^{m \\times n}$ with entries $J_{ij} = 1$ for all $i,j$.\n- The objective is to determine $\\|J\\|_{1}$, $\\|J\\|_{2}$, $\\|J\\|_{\\infty}$, and $\\|J\\|_{F}$ as explicit functions of $m$ and $n$.\n- The final answer is required in the format of a row vector: $\\big(\\|J\\|_{1}, \\|J\\|_{2}, \\|J\\|_{\\infty}, \\|J\\|_{F}\\big)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed against the required criteria.\n- **Scientifically Grounded:** The problem uses standard, universally accepted definitions for vector and matrix norms from the field of linear algebra and numerical analysis. It is scientifically and mathematically sound.\n- **Well-Posed:** The problem is clearly stated. The matrix $J$ is unambiguously defined, as are the norms to be computed. A unique, meaningful solution exists for each of the four requested quantities.\n- **Objective:** The problem is formulated with precise mathematical language, devoid of any subjectivity or ambiguity.\n\nThe problem is found to be free of any flaws such as scientific unsoundness, incompleteness, or contradiction.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A complete, reasoned solution will be provided.\n\nWe proceed to calculate the four specified norms for the all-ones matrix $J \\in \\mathbb{R}^{m \\times n}$.\n\n**1. Calculation of the $1$-norm, $\\|J\\|_{1}$**\nThe operator $1$-norm of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is defined as the maximum absolute column sum:\n$$\n\\|A\\|_{1} = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{m} |a_{ij}|\n$$\nFor the matrix $J$, all entries are $J_{ij} = 1$. We compute the sum of the absolute values for an arbitrary column $j$:\n$$\n\\sum_{i=1}^{m} |J_{ij}| = \\sum_{i=1}^{m} |1| = \\sum_{i=1}^{m} 1 = m\n$$\nThis sum is constant for every column $j$, where $1 \\leq j \\leq n$. Therefore, the maximum of these identical sums is $m$.\n$$\n\\|J\\|_{1} = m\n$$\n\n**2. Calculation of the $\\infty$-norm, $\\|J\\|_{\\infty}$**\nThe operator $\\infty$-norm of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is defined as the maximum absolute row sum:\n$$\n\\|A\\|_{\\infty} = \\max_{1 \\leq i \\leq m} \\sum_{j=1}^{n} |a_{ij}|\n$$\nFor the matrix $J$, we compute the sum of the absolute values for an arbitrary row $i$:\n$$\n\\sum_{j=1}^{n} |J_{ij}| = \\sum_{j=1}^{n} |1| = \\sum_{j=1}^{n} 1 = n\n$$\nThis sum is constant for every row $i$, where $1 \\leq i \\leq m$. The maximum of these identical sums is $n$.\n$$\n\\|J\\|_{\\infty} = n\n$$\n\n**3. Calculation of the Frobenius norm, $\\|J\\|_{F}$**\nThe Frobenius norm of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is defined by:\n$$\n\\|A\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^{2}}\n$$\nFor the matrix $J$, this becomes:\n$$\n\\|J\\|_{F} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |1|^{2}} = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} 1}\n$$\nThe double summation represents the total number of entries in the matrix, which is $mn$.\n$$\n\\|J\\|_{F} = \\sqrt{mn}\n$$\n\n**4. Calculation of the $2$-norm (Spectral Norm), $\\|J\\|_{2}$**\nThe operator $2$-norm of a matrix $A$ is its largest singular value, $\\sigma_{\\max}(A)$. This is equivalent to the square root of the largest eigenvalue of the matrix $A^T A$.\n$$\n\\|A\\|_{2} = \\sqrt{\\lambda_{\\max}(A^T A)}\n$$\nFor our matrix $J$, we first construct the matrix $J^T J$. The matrix $J$ is an $m \\times n$ matrix of all ones, so its transpose $J^T$ is an $n \\times m$ matrix of all ones. The product $J^T J$ is an $n \\times n$ matrix. An entry $(k,l)$ of this product is:\n$$\n(J^T J)_{kl} = \\sum_{i=1}^{m} (J^T)_{ki} J_{il} = \\sum_{i=1}^{m} J_{ik} J_{il} = \\sum_{i=1}^{m} 1 \\cdot 1 = m\n$$\nThus, $J^T J$ is an $n \\times n$ matrix where every entry is equal to $m$. We can write this as $J^T J = m U_n$, where $U_n$ is the $n \\times n$ matrix of all ones. The eigenvalues of $J^T J$ are $m$ times the eigenvalues of $U_n$.\n\nThe matrix $U_n$ has rank $1$, since all its columns are identical. A matrix of rank $k$ has at least $n-k$ zero eigenvalues. Thus, $U_n$ has an eigenvalue of $0$ with multiplicity of at least $n-1$. The sum of the eigenvalues of a matrix equals its trace. The trace of $U_n$ is $\\text{Tr}(U_n) = \\sum_{i=1}^{n} 1 = n$. Since $n-1$ eigenvalues are $0$, the remaining eigenvalue must be $n$. So, the eigenvalues of $U_n$ are $n$ (with multiplicity $1$) and $0$ (with multiplicity $n-1$).\n\nThe eigenvalues of $J^T J = m U_n$ are therefore $mn$ (multiplicity $1$) and $0$ (multiplicity $n-1$). The largest eigenvalue is $\\lambda_{\\max}(J^T J) = mn$.\nThe $2$-norm is the square root of this value:\n$$\n\\|J\\|_{2} = \\sqrt{\\lambda_{\\max}(J^T J)} = \\sqrt{mn}\n$$\n\nIn summary, the four computed norms are:\n- $\\|J\\|_{1} = m$\n- $\\|J\\|_{2} = \\sqrt{mn}$\n- $\\|J\\|_{\\infty} = n$\n- $\\|J\\|_{F} = \\sqrt{mn}$\n\nThe final answer is presented as a row vector in the specified order.", "answer": "$$\n\\boxed{\\begin{pmatrix} m & \\sqrt{mn} & n & \\sqrt{mn} \\end{pmatrix}}\n$$", "id": "2449594"}, {"introduction": "Matrix norms are far more than just abstract measures of size; they are powerful analytical tools for estimating the properties of physical systems. This problem bridges the abstract concept of norms to the concrete world of computational quantum mechanics, demonstrating how a simple norm calculation can establish a rigorous bound on the energy spectrum of a particle [@problem_id:2449165]. You will discretize the Schrödinger equation to form a Hamiltonian matrix and then use its infinity norm, a readily computable quantity, to find an upper limit for the system's energy eigenvalues.", "problem": "A single nonrelativistic particle of mass $m$ in one spatial dimension is governed by the time-independent Schrödinger equation $-\\dfrac{\\hbar^{2}}{2m}\\dfrac{d^{2}\\psi}{dx^{2}} + V(x)\\,\\psi = E\\,\\psi$. On the finite domain $x \\in [-L,L]$ with homogeneous Dirichlet boundary conditions $\\psi(-L)=\\psi(L)=0$, introduce a uniform grid with $N$ interior points and approximate the second derivative by the central finite difference formula. Work in atomic units where $\\hbar=1$ and $m=1$ so that the kinetic prefactor is $1/2$. Consider the harmonic oscillator potential $V(x) = \\dfrac{1}{2}\\,\\omega^{2} x^{2}$ with $\\omega = 3$, domain half-width $L=1$, and number of interior grid points $N=4$.\n\nStarting from these definitions, discretize the Schrödinger equation into a matrix eigenvalue problem $H\\,\\psi = E\\,\\psi$ for the $N \\times N$ Hamiltonian matrix $H$. Then, using the induced infinity matrix norm (the operator norm induced by the vector infinity norm), provide a rigorous upper bound on the absolute value of the ground-state energy $|E_{0}|$ of the discrete problem, and evaluate this bound numerically for the given parameters. Express the final bound in Hartree and round your answer to four significant figures.", "solution": "The problem statement is subjected to validation and is found to be valid. It is a well-posed, scientifically grounded problem in computational physics that is free of contradictions or ambiguities. All necessary parameters and methods are specified. We shall proceed with the solution.\n\nThe time-independent Schrödinger equation in one dimension for a particle of mass $m$ is given by:\n$$\n-\\dfrac{\\hbar^{2}}{2m}\\dfrac{d^{2}\\psi}{dx^{2}} + V(x)\\,\\psi(x) = E\\,\\psi(x)\n$$\nWe are instructed to work in atomic units, where $\\hbar=1$ and $m=1$. The equation simplifies to:\n$$\n-\\dfrac{1}{2}\\dfrac{d^{2}\\psi}{dx^{2}} + V(x)\\,\\psi(x) = E\\,\\psi(x)\n$$\nThe domain is specified as $x \\in [-L, L]$, with homogeneous Dirichlet boundary conditions $\\psi(-L)=\\psi(L)=0$. The domain is discretized using a uniform grid with $N$ interior points. The total domain length is $2L$. The number of intervals on this grid is $N+1$. Therefore, the grid spacing, or step size, $h$, is given by:\n$$\nh = \\dfrac{2L}{N+1}\n$$\nThe interior grid points are denoted by $x_j$, where $j=1, 2, \\dots, N$. Their positions are given by $x_j = -L + j \\cdot h$. The boundary points are $x_0 = -L$ and $x_{N+1} = L$. The wavefunction at these discrete points is denoted by $\\psi_j = \\psi(x_j)$. The boundary conditions imply $\\psi_0 = 0$ and $\\psi_{N+1} = 0$.\n\nThe second derivative term, $\\dfrac{d^{2}\\psi}{dx^{2}}$, is approximated using the second-order central finite difference formula at each interior point $x_j$:\n$$\n\\dfrac{d^{2}\\psi}{dx^{2}}\\bigg|_{x_j} \\approx \\dfrac{\\psi(x_j - h) - 2\\psi(x_j) + \\psi(x_j + h)}{h^2} = \\dfrac{\\psi_{j-1} - 2\\psi_j + \\psi_{j+1}}{h^2}\n$$\nSubstituting this approximation into the Schrödinger equation yields a system of linear equations for the unknown values $\\psi_j$:\n$$\n-\\dfrac{1}{2}\\left(\\dfrac{\\psi_{j-1} - 2\\psi_j + \\psi_{j+1}}{h^2}\\right) + V(x_j)\\,\\psi_j = E\\,\\psi_j \\quad \\text{for } j=1, 2, \\dots, N\n$$\nRearranging the terms to fit the structure of a matrix equation, we have:\n$$\n-\\dfrac{1}{2h^2}\\psi_{j-1} + \\left(\\dfrac{1}{h^2} + V(x_j)\\right)\\psi_j - \\dfrac{1}{2h^2}\\psi_{j+1} = E\\,\\psi_j\n$$\nThis system of $N$ equations can be written in the matrix form $H\\mathbf{\\psi} = E\\mathbf{\\psi}$, where $\\mathbf{\\psi} = (\\psi_1, \\psi_2, \\dots, \\psi_N)^T$ is the vector of wavefunction values, and $H$ is the $N \\times N$ discrete Hamiltonian matrix. The elements of this matrix, $H_{ij}$, are:\n$$\nH_{ij} =\n\\begin{cases}\n\\dfrac{1}{h^2} + V(x_i) & \\text{if } i=j \\\\\n-\\dfrac{1}{2h^2} & \\text{if } |i-j|=1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nNow, we substitute the given numerical values: $L=1$, $N=4$, and for the potential $V(x) = \\dfrac{1}{2}\\omega^2 x^2$, we have $\\omega=3$.\nFirst, we calculate the grid spacing $h$:\n$$\nh = \\dfrac{2 \\cdot 1}{4+1} = \\dfrac{2}{5} = 0.4\n$$\nThe kinetic energy terms in the matrix are determined by $h$:\n$$\n\\dfrac{1}{h^2} = \\dfrac{1}{(0.4)^2} = \\dfrac{1}{0.16} = 6.25\n$$\n$$\n-\\dfrac{1}{2h^2} = -\\dfrac{6.25}{2} = -3.125\n$$\nNext, we determine the positions of the interior grid points $x_j = -1 + j \\cdot (0.4)$:\n$$\nx_1 = -1 + 1(0.4) = -0.6 \\\\\nx_2 = -1 + 2(0.4) = -0.2 \\\\\nx_3 = -1 + 3(0.4) = 0.2 \\\\\nx_4 = -1 + 4(0.4) = 0.6\n$$\nThe potential is $V(x) = \\dfrac{1}{2}(3)^2 x^2 = 4.5 x^2$. We evaluate the potential at each grid point:\n$$\nV(x_1) = 4.5(-0.6)^2 = 4.5(0.36) = 1.62 \\\\\nV(x_2) = 4.5(-0.2)^2 = 4.5(0.04) = 0.18 \\\\\nV(x_3) = 4.5(0.2)^2 = 4.5(0.04) = 0.18 \\\\\nV(x_4) = 4.5(0.6)^2 = 4.5(0.36) = 1.62\n$$\nNow we assemble the $4 \\times 4$ Hamiltonian matrix $H$:\nThe diagonal elements are $H_{jj} = \\dfrac{1}{h^2} + V(x_j) = 6.25 + V(x_j)$:\n$$\nH_{11} = 6.25 + 1.62 = 7.87 \\\\\nH_{22} = 6.25 + 0.18 = 6.43 \\\\\nH_{33} = 6.25 + 0.18 = 6.43 \\\\\nH_{44} = 6.25 + 1.62 = 7.87\n$$\nThe off-diagonal elements are $H_{j, j\\pm1} = -3.125$. The matrix $H$ is:\n$$\nH = \\begin{pmatrix}\n7.87 & -3.125 & 0 & 0 \\\\\n-3.125 & 6.43 & -3.125 & 0 \\\\\n0 & -3.125 & 6.43 & -3.125 \\\\\n0 & 0 & -3.125 & 7.87\n\\end{pmatrix}\n$$\nThe problem requires finding a rigorous upper bound on the absolute value of the ground-state energy, $|E_0|$, using the induced infinity matrix norm. For any matrix $A$ and any of its eigenvalues $\\lambda$, it is a fundamental theorem that $|\\lambda| \\le \\|A\\|$ for any induced matrix norm.\nThe induced infinity norm of a matrix $A$, denoted $\\|A\\|_{\\infty}$, is defined as the maximum absolute row sum:\n$$\n\\|A\\|_{\\infty} = \\max_{1 \\le i \\le N} \\sum_{j=1}^{N} |A_{ij}|\n$$\nApplying this to our Hamiltonian matrix $H$, we have the bound $|E_k| \\le \\|H\\|_{\\infty}$ for all eigenvalues $E_k$, including the ground-state energy $E_0$. Thus, a rigorous upper bound for $|E_0|$ is $\\|H\\|_{\\infty}$.\n\nWe compute the absolute row sums for our matrix $H$:\nRow $1$: $|7.87| + |-3.125| + |0| + |0| = 7.87 + 3.125 = 10.995$\nRow $2$: $|-3.125| + |6.43| + |-3.125| + |0| = 3.125 + 6.43 + 3.125 = 12.68$\nRow $3$: $|0| + |-3.125| + |6.43| + |-3.125| = 3.125 + 6.43 + 3.125 = 12.68$\nRow $4$: $|0| + |0| + |-3.125| + |7.87| = 3.125 + 7.87 = 10.995$\n\nThe maximum of these sums is:\n$$\n\\|H\\|_{\\infty} = \\max\\{10.995, 12.68, 12.68, 10.995\\} = 12.68\n$$\nTherefore, the upper bound for the magnitude of the ground-state energy is $|E_0| \\le 12.68$.\nThe calculations were performed in atomic units, so the energy is in Hartrees. The problem asks for the answer to be rounded to four significant figures. The value $12.68$ already has four significant figures.\nThe final upper bound is $12.68$ Hartree.", "answer": "$$\n\\boxed{12.68}\n$$", "id": "2449165"}, {"introduction": "The theoretical power of norms culminates in the concept of the condition number, a value that quantifies the stability of linear systems. This hands-on coding practice moves theory into the computational arena, allowing you to witness the dramatic effects of ill-conditioning firsthand. By solving a linear system with a notoriously ill-conditioned Hilbert matrix and introducing a miniscule perturbation to the right-hand side vector, you will observe and quantify a disproportionately large error in the solution [@problem_id:2449583]. This experiment provides a crucial, tangible lesson on the practical limits of numerical computation.", "problem": "Design and implement a complete, runnable program that performs a numerical experiment demonstrating that for an ill-conditioned matrix $A$, a small relative error in $b$ can lead to a large relative error in the solution $x$ of the linear system $A x = b$. The experiment must be based strictly on first principles: norms, relative errors, and the definition of the linear solve. All quantities must use the vector and matrix $2$-norm. The program must compute, for each specified test case, the amplification factor defined as\n$$\nr \\;=\\; \\frac{\\|x_{\\epsilon} - x^\\star\\|_{2} / \\|x^\\star\\|_{2}}{\\|\\delta b\\|_{2} / \\|b\\|_{2}},\n$$\nwhere $x^\\star$ is the exact solution corresponding to the unperturbed right-hand side $b$, $\\delta b$ is a perturbation of $b$, and $x_{\\epsilon}$ is the solution of $A x = b + \\delta b$. The program must use the following experiment setup for every test case:\n- Let $x^\\star$ be the vector in $\\mathbb{R}^n$ with all components equal to $1$.\n- Let $b = A x^\\star$.\n- Let the perturbation direction $v \\in \\mathbb{R}^n$ be defined componentwise by $v_i = \\frac{(-1)^{i-1}}{\\sqrt{n}}$ for $i = 1, \\dots, n$ so that $\\|v\\|_2 = 1$.\n- Let $\\delta b = \\epsilon \\, \\|b\\|_2 \\, v$, where $\\epsilon$ is the prescribed relative perturbation magnitude for the test.\n- Let $x_{\\epsilon}$ be the solution of $A x = b + \\delta b$.\n\nYour program must compute, for each test case, the amplification factor $r$ as a floating-point number. The set of test cases is as follows, each identified by its case number and executed in the listed order:\n- Case $1$: $A$ is the Hilbert matrix $H \\in \\mathbb{R}^{5 \\times 5}$ with entries $H_{ij} = \\frac{1}{i + j - 1}$ for $i, j \\in \\{1,\\dots,5\\}$, and $\\epsilon = 10^{-8}$.\n- Case $2$: $A$ is the Hilbert matrix $H \\in \\mathbb{R}^{10 \\times 10}$ with entries $H_{ij} = \\frac{1}{i + j - 1}$ for $i, j \\in \\{1,\\dots,10\\}$, and $\\epsilon = 10^{-8}$.\n- Case $3$: $A$ is the identity matrix $I \\in \\mathbb{R}^{8 \\times 8}$, and $\\epsilon = 10^{-8}$.\n- Case $4$: $A \\in \\mathbb{R}^{2 \\times 2}$ is given by\n$$\nA = \\begin{bmatrix}\n1 & 1 \\\\\n1 & 1 + 10^{-10}\n\\end{bmatrix},\n$$\nand $\\epsilon = 10^{-12}$.\n\nAll norms must be the $2$-norm. There are no physical units involved. Angles are not used. Percentages must not be used; all ratios and magnitudes must be expressed as decimal floating-point numbers.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[r1,r2,r3,r4]\"). Each entry must be the amplification factor $r$ for the corresponding case, rounded to $6$ significant digits, in the order of cases $1$ through $4$.", "solution": "The experiment is designed from first principles of linear algebra and norm-based error analysis. We consider a linear system $A x = b$ with exact data and its perturbed counterpart $A x = b + \\delta b$. For a given matrix $A \\in \\mathbb{R}^{n \\times n}$ and an exact solution vector $x^\\star \\in \\mathbb{R}^n$, we define $b = A x^\\star$. We then construct a perturbation $\\delta b$ with prescribed relative magnitude $\\epsilon$ as follows. Let $v \\in \\mathbb{R}^n$ with entries $v_i = \\frac{(-1)^{i-1}}{\\sqrt{n}}$, for $i = 1, \\dots, n$. This $v$ satisfies $\\|v\\|_2 = 1$ by construction:\n$$\n\\|v\\|_2^2 = \\sum_{i=1}^n \\left(\\frac{1}{\\sqrt{n}}\\right)^2 = \\frac{n}{n} = 1.\n$$\nWe set $\\delta b = \\epsilon \\, \\|b\\|_2 \\, v$. Then the relative perturbation in $b$ is exactly $\\frac{\\|\\delta b\\|_2}{\\|b\\|_2} = \\epsilon$ because\n$$\n\\|\\delta b\\|_2 = \\epsilon \\, \\|b\\|_2 \\, \\|v\\|_2 = \\epsilon \\, \\|b\\|_2.\n$$\nLet $x_\\epsilon$ denote the solution to the perturbed system $A x = b + \\delta b$. The error in the solution equals\n$$\nx_\\epsilon - x^\\star = A^{-1}\\,(b+\\delta b) - A^{-1} b = A^{-1}\\,\\delta b.\n$$\nTherefore the relative error in $x$ is\n$$\n\\frac{\\|x_\\epsilon - x^\\star\\|_2}{\\|x^\\star\\|_2} = \\frac{\\|A^{-1}\\,\\delta b\\|_2}{\\|x^\\star\\|_2}.\n$$\nThe amplification factor $r$ that the program reports for each case is\n$$\nr = \\frac{\\|x_{\\epsilon} - x^\\star\\|_{2} / \\|x^\\star\\|_{2}}{\\|\\delta b\\|_{2} / \\|b\\|_{2}}.\n$$\nFrom norm properties and the definition of the matrix $2$-norm, we can relate this amplification to the condition number in the matrix $2$-norm, $\\kappa_2(A) = \\|A\\|_2 \\, \\|A^{-1}\\|_2$. Specifically, using $\\|A^{-1} \\delta b\\|_2 \\le \\|A^{-1}\\|_2 \\, \\|\\delta b\\|_2$ and $\\|b\\|_2 = \\|A x^\\star\\|_2 \\le \\|A\\|_2 \\, \\|x^\\star\\|_2$, we obtain\n$$\n\\frac{\\|x_\\epsilon - x^\\star\\|_2}{\\|x^\\star\\|_2} \\le \\|A^{-1}\\|_2 \\, \\|\\delta b\\|_2 \\,\\frac{1}{\\|x^\\star\\|_2}\n\\le \\|A^{-1}\\|_2 \\, \\|A\\|_2 \\, \\frac{\\|\\delta b\\|_2}{\\|b\\|_2} = \\kappa_2(A) \\, \\frac{\\|\\delta b\\|_2}{\\|b\\|_2}.\n$$\nHence\n$$\nr \\le \\kappa_2(A).\n$$\nThis inequality shows that the relative error in the solution can be amplified by up to approximately the condition number. For well-conditioned matrices such as the identity matrix $I$, we have $\\kappa_2(I) = 1$, and thus $r$ should be close to $1$. For ill-conditioned matrices such as Hilbert matrices, $\\kappa_2(A)$ is very large, and even a very small $\\epsilon$ can result in a large relative error in $x$, producing a large $r$.\n\nThe test suite covers several regimes:\n- Case $1$ uses a Hilbert matrix of size $5$, which is ill-conditioned but moderate in size.\n- Case $2$ uses a Hilbert matrix of size $10$, which is more ill-conditioned, typically yielding a much larger amplification $r$.\n- Case $3$ uses the identity matrix of size $8$, which is perfectly conditioned, so $r$ should be approximately $1$.\n- Case $4$ uses a nearly singular $2 \\times 2$ matrix with entries differing by $10^{-10}$ on one element, producing a very large amplification.\n\nFor each case, the program constructs $x^\\star$, $b$, the unit-norm perturbation direction $v$, the perturbation $\\delta b$ with the specified $\\epsilon$, solves for $x_\\epsilon$, computes the relative errors, and reports $r$ rounded to $6$ significant digits. The final output is a single line containing the list $[r_1, r_2, r_3, r_4]$ in that order. This procedure directly and transparently exhibits how ill-conditioning in $A$ magnifies small relative perturbations in $b$ into large relative errors in the solution $x$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hilbert(n: int) -> np.ndarray:\n    # H[i,j] = 1 / (i + j + 1) with zero-based i,j; but use one-based formula directly\n    i = np.arange(1, n + 1).reshape(-1, 1)\n    j = np.arange(1, n + 1).reshape(1, -1)\n    return 1.0 / (i + j - 1.0)\n\ndef alternating_unit_vector(n: int) -> np.ndarray:\n    # v_i = (-1)^(i-1) / sqrt(n), i = 1..n\n    signs = (-1.0) ** np.arange(n)\n    v = signs / np.sqrt(n)\n    # Ensure unit norm numerically\n    return v / np.linalg.norm(v, 2)\n\ndef amplification_factor(A: np.ndarray, eps: float) -> float:\n    n = A.shape[0]\n    x_star = np.ones(n, dtype=float)\n    b = A @ x_star\n    nb = np.linalg.norm(b, 2)\n    if nb == 0.0:\n        # Degenerate, but not expected with provided tests; return NaN-like large value\n        return float('nan')\n    v = alternating_unit_vector(n)\n    delta_b = eps * nb * v\n    b_tilde = b + delta_b\n    # Solve for perturbed solution\n    x_tilde = np.linalg.solve(A, b_tilde)\n    # Relative errors\n    rel_b = np.linalg.norm(delta_b, 2) / nb\n    rel_x = np.linalg.norm(x_tilde - x_star, 2) / np.linalg.norm(x_star, 2)\n    # Amplification factor\n    return rel_x / rel_b\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (A_matrix, epsilon)\n    A1 = hilbert(5)\n    eps1 = 1e-8\n\n    A2 = hilbert(10)\n    eps2 = 1e-8\n\n    A3 = np.eye(8, dtype=float)\n    eps3 = 1e-8\n\n    A4 = np.array([[1.0, 1.0],\n                   [1.0, 1.0 + 1e-10]], dtype=float)\n    eps4 = 1e-12\n\n    test_cases = [\n        (A1, eps1),\n        (A2, eps2),\n        (A3, eps3),\n        (A4, eps4),\n    ]\n\n    results = []\n    for A, eps in test_cases:\n        r = amplification_factor(A, eps)\n        # Round to 6 significant digits\n        if np.isnan(r) or np.isinf(r):\n            results.append(\"nan\")\n        else:\n            results.append(f\"{r:.6g}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2449583"}]}