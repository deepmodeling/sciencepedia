{"hands_on_practices": [{"introduction": "This practice serves as a fundamental check on the setup of the BiCGSTAB algorithm. By considering the ideal scenario where our initial guess is already the exact solution, we can verify our understanding of the initial residual $r_0$ and the parameter $\\rho_1$. These quantities are the essential building blocks for the first step and the entire iterative process that follows [@problem_id:2208859].", "problem": "Consider the problem of solving a linear system of equations $Ax = b$, where $A$ is an $n \\times n$ invertible matrix, and $x$ and $b$ are column vectors in $\\mathbb{R}^n$. The Bi-Conjugate Gradient Stabilized (BiCGSTAB) method is a popular iterative algorithm for finding an approximate solution to this system.\n\nThe algorithm begins with an initial guess, $x_0$. Based on this guess, the initial residual vector is calculated as $r_0 = b - Ax_0$. An auxiliary \"shadow\" residual vector, $\\hat{r}_0$, is also chosen, typically such that its dot product with the initial residual is non-zero. In the first step of the iterative process (for index $i=1$), the algorithm computes a scalar parameter $\\rho_1$, which is defined as the dot product (or inner product) $\\rho_1 = \\hat{r}_0^T r_0$.\n\nSuppose that, by an exceptional stroke of luck, the chosen initial guess $x_0$ happens to be the exact solution to the system $Ax = b$. Based solely on this information, determine the value of the initial residual vector $r_0$ and the scalar parameter $\\rho_1$.\n\nSelect the correct statement from the options below.\n\nA. $r_0$ is the zero vector and $\\rho_1 = 0$.\n\nB. $r_0$ is the zero vector and $\\rho_1 = 1$.\n\nC. $r_0$ is the vector $b$ and $\\rho_1 = \\hat{r}_0^T b$.\n\nD. The values of $r_0$ and $\\rho_1$ depend on the specific choice of the shadow residual $\\hat{r}_0$.\n\nE. It is not possible to determine $r_0$ and $\\rho_1$ without knowing the specific matrix $A$ and vector $b$.", "solution": "We are given the linear system $Ax=b$ with $A \\in \\mathbb{R}^{n \\times n}$ invertible, and the BiCGSTAB setup with initial guess $x_{0}$, initial residual $r_{0}=b-Ax_{0}$, and shadow residual $\\hat{r}_{0}$ such that $\\rho_{1}=\\hat{r}_{0}^{T}r_{0}$.\n\nAssume $x_{0}$ is the exact solution to $Ax=b$. Denote the exact solution by $x^{\\ast}$, which satisfies $Ax^{\\ast}=b$. Since $x_{0}=x^{\\ast}$, we have\n$$\nAx_{0}=b.\n$$\nBy the definition of the residual,\n$$\nr_{0}=b-Ax_{0}=b-b=0,\n$$\nwhere $0$ denotes the zero vector in $\\mathbb{R}^{n}$.\n\nThe scalar $\\rho_{1}$ is defined by the inner product\n$$\n\\rho_{1}=\\hat{r}_{0}^{T}r_{0}.\n$$\nSince $r_{0}=0$, it follows that\n$$\n\\rho_{1}=\\hat{r}_{0}^{T}0=0,\n$$\nindependently of the choice of $\\hat{r}_{0}$.\n\nTherefore, the correct statement is that $r_{0}$ is the zero vector and $\\rho_{1}=0$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "2208859"}, {"introduction": "The \"STAB\" in BiCGSTAB signifies a crucial improvement in robustness over its predecessor, the Bi-Conjugate Gradient (BiCG) method. This exercise provides a concrete numerical example where the BiCG algorithm fails due to a breakdown in its mathematical structure [@problem_id:2376326]. By performing the step-by-step calculations, you will see firsthand how BiCGSTAB's additional smoothing step allows it to navigate this common pitfall and proceed successfully towards a solution.", "problem": "You are asked to demonstrate, from first principles of Krylov subspace iterative methods, how breakdowns in the Bi-Conjugate Gradient (BiCG) method can occur while the Bi-Conjugate Gradient Stabilized (BiCGSTAB) method still converges on the same linear system. Consider the linear system $A x = b$ with\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 0 & 1\\\\\n1 & 3 & 0\\\\\n0 & 0 & 4\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix},\n\\qquad\nx_0 \\;=\\; \\begin{pmatrix} 0\\\\ 0\\\\ 0 \\end{pmatrix}.\n$$\nFor Bi-Conjugate Gradient (BiCG), set the initial residual $r_0 = b - A x_0$ and the initial shadow residual $\\tilde{r}_0 = r_0$. Using only the definitions of the first update step in BiCG (residuals and shadow residuals defined by single-step Krylov projections with a biorthogonality pairing), explicitly compute $r_1$ and $\\tilde{r}_1$ and verify that $r_1 \\neq 0$, $\\tilde{r}_1 \\neq 0$, and $r_1^{T}\\tilde{r}_1 = 0$, which implies BiCG breakdown at the next step.\n\nNext, apply the Bi-Conjugate Gradient Stabilized (BiCGSTAB) method to the same system with the same initial guess $x_0$, the same initial residual $r_0$, and a fixed shadow residual $\\hat{r}$ chosen as\n$$\n\\hat{r} \\;=\\; r_0 + \\begin{pmatrix} 0\\\\ 1\\\\ 0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1\\\\ 1\\\\ 0 \\end{pmatrix}.\n$$\nUsing the standard definitions of the BiCGSTAB recurrence (scalar coefficients defined by inner products of $r_{k-1}$, $\\hat{r}$, and Krylov images under $A$), carry out the first BiCGSTAB iteration to compute the smoothing parameter $\\omega_1$.\n\nYour task is to provide the value of the scalar $\\omega_1$. Express your final answer exactly as a reduced fraction. No rounding is required. The final answer must be a single number with no units.", "solution": "The linear system under consideration is $A x = b$, with the givens:\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 0 & 1\\\\\n1 & 3 & 0\\\\\n0 & 0 & 4\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix},\n\\qquad\nx_0 \\;=\\; \\begin{pmatrix} 0\\\\ 0\\\\ 0 \\end{pmatrix}.\n$$\n\nFirst, we analyze the BiCG method. The initial residual is $r_0 = b - A x_0 = b - 0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\nThe problem specifies setting the initial shadow residual $\\tilde{r}_0 = r_0$. Thus, $\\tilde{r}_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\nThe BiCG algorithm sets the initial search directions as $p_0 = r_0$ and $\\tilde{p}_0 = \\tilde{r}_0$.\nThe scalar $\\alpha_k$ is computed at each step $k$ as $\\alpha_k = \\frac{\\tilde{r}_k^T r_k}{\\tilde{p}_k^T A p_k}$.\nFor the first step ($k=0$):\nThe numerator is $\\tilde{r}_0^T r_0 = r_0^T r_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = 1$.\nTo compute the denominator, we first find $A p_0$:\n$A p_0 = A r_0 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix}$.\nThe denominator is then $\\tilde{p}_0^T A p_0 = \\tilde{r}_0^T (A r_0) = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = 2$.\nThus, $\\alpha_0 = \\frac{1}{2}$.\n\nThe updated residuals $r_1$ and $\\tilde{r}_1$ are computed as follows:\n$r_1 = r_0 - \\alpha_0 A p_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1\\\\ 1/2\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\\\ -1/2\\\\ 0 \\end{pmatrix}$.\n$\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 A^T \\tilde{p}_0$. The transpose of $A$ is $A^T = \\begin{pmatrix} 2 & 1 & 0\\\\ 0 & 3 & 0\\\\ 1 & 0 & 4 \\end{pmatrix}$.\n$A^T \\tilde{p}_0 = A^T \\tilde{r}_0 = \\begin{pmatrix} 2 & 1 & 0\\\\ 0 & 3 & 0\\\\ 1 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 0\\\\ 1 \\end{pmatrix}$.\n$\\tilde{r}_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 2\\\\ 0\\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1\\\\ 0\\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 0\\\\ 0\\\\ -1/2 \\end{pmatrix}$.\n\nWe verify the conditions stated in the problem:\n1. $r_1 = \\begin{pmatrix} 0\\\\ -1/2\\\\ 0 \\end{pmatrix} \\neq 0$.\n2. $\\tilde{r}_1 = \\begin{pmatrix} 0\\\\ 0\\\\ -1/2 \\end{pmatrix} \\neq 0$.\n3. $r_1^T \\tilde{r}_1 = \\begin{pmatrix} 0 & -1/2 & 0 \\end{pmatrix} \\begin{pmatrix} 0\\\\ 0\\\\ -1/2 \\end{pmatrix} = (0)(0) + (-1/2)(0) + (0)(-1/2) = 0$.\n\nThe next step in the BiCG algorithm would be to compute $\\beta_0 = \\frac{\\tilde{r}_1^T r_1}{\\tilde{r}_0^T r_0} = \\frac{0}{1} = 0$.\nThis leads to new search directions $p_1 = r_1 + \\beta_0 p_0 = r_1$ and $\\tilde{p}_1 = \\tilde{r}_1 + \\beta_0 \\tilde{p}_0 = \\tilde{r}_1$.\nThen, the next scalar $\\alpha_1$ is computed as $\\alpha_1 = \\frac{\\tilde{r}_1^T r_1}{\\tilde{p}_1^T A p_1} = \\frac{0}{\\tilde{r}_1^T A r_1}$.\nThe denominator term is $\\tilde{r}_1^T A r_1 = \\begin{pmatrix} 0 & 0 & -1/2 \\end{pmatrix} \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 0\\\\ -1/2\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & -2 \\end{pmatrix} \\begin{pmatrix} 0\\\\ -1/2\\\\ 0 \\end{pmatrix} = 0$.\nSince both the numerator and denominator for $\\alpha_1$ are zero, this constitutes a serious breakdown of the BiCG algorithm.\n\nNext, we apply the BiCGSTAB method. The initial residual is $r_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$. The fixed shadow residual is given as $\\hat{r} = \\begin{pmatrix} 1\\\\ 1\\\\ 0 \\end{pmatrix}$.\nThe standard algorithm starts with initial values $\\rho_0=1$, $\\alpha_0=1$, $\\omega_0=1$, $p_0=0$, and $v_0=0$. We perform the first iteration ($k=1$).\n\n1. Compute $\\rho_1 = \\hat{r}^T r_0$:\n$\\rho_1 = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = 1$.\n\n2. Compute $\\beta_1 = \\frac{\\rho_1}{\\rho_0} \\frac{\\alpha_0}{\\omega_0}$:\n$\\beta_1 = \\frac{1}{1} \\cdot \\frac{1}{1} = 1$.\n\n3. Compute $p_1 = r_0 + \\beta_1 (p_0 - \\omega_0 v_0)$:\n$p_1 = r_0 + 1 (0 - 1 \\cdot 0) = r_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\n\n4. Compute $v_1 = A p_1$:\n$v_1 = A r_0 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix}$.\n\n5. Compute $\\alpha_1 = \\frac{\\rho_1}{\\hat{r}^T v_1}$:\n$\\hat{r}^T v_1 = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = (1)(2) + (1)(1) + (0)(0) = 3$.\n$\\alpha_1 = \\frac{1}{3}$.\n\n6. Compute the temporary residual $s_1 = r_0 - \\alpha_1 v_1$:\n$s_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 - 2/3\\\\ 0 - 1/3\\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix}$.\n\n7. Compute $t_1 = A s_1$:\n$t_1 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2(1/3) + 0(-1/3) + 1(0) \\\\ 1(1/3) + 3(-1/3) + 0(0) \\\\ 0(1/3) + 0(-1/3) + 4(0) \\end{pmatrix} = \\begin{pmatrix} 2/3\\\\ 1/3 - 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2/3\\\\ -2/3\\\\ 0 \\end{pmatrix}$.\n\n8. Compute the smoothing parameter $\\omega_1 = \\frac{t_1^T s_1}{t_1^T t_1}$:\nThe numerator is $t_1^T s_1 = \\begin{pmatrix} 2/3 & -2/3 & 0 \\end{pmatrix} \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix} = (\\frac{2}{3})(\\frac{1}{3}) + (\\frac{-2}{3})(\\frac{-1}{3}) = \\frac{2}{9} + \\frac{2}{9} = \\frac{4}{9}$.\nThe denominator is $t_1^T t_1 = \\begin{pmatrix} 2/3 & -2/3 & 0 \\end{pmatrix} \\begin{pmatrix} 2/3\\\\ -2/3\\\\ 0 \\end{pmatrix} = (\\frac{2}{3})^2 + (\\frac{-2}{3})^2 = \\frac{4}{9} + \\frac{4}{9} = \\frac{8}{9}$.\n$\\omega_1 = \\frac{4/9}{8/9} = \\frac{4}{8} = \\frac{1}{2}$.\n\nThe value of the smoothing parameter $\\omega_1$ is $\\frac{1}{2}$. This demonstrates that the BiCGSTAB algorithm, with a suitable choice of $\\hat{r}$, does not break down and proceeds with the computation.", "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$", "id": "2376326"}, {"introduction": "While iterative solvers like BiCGSTAB are designed to reduce the residual error, their convergence path is not always a steady decline; often, the residual norm exhibits temporary \"spikes.\" This advanced practice delves into this phenomenon by linking the algorithm's behavior directly to the spectral properties of the system matrix, specifically the presence of outlier eigenvalues [@problem_id:2376279]. By analyzing an idealized system and deriving a \"spike amplification factor,\" you will develop a deeper, analytical intuition for the dynamics of Krylov subspace methods.", "problem": "A linear system arises from a discretized partial differential equation and is to be solved with the BiConjugate Gradient Stabilized (BiCGSTAB) method without preconditioning in exact arithmetic. Consider the real diagonal matrix\n$$\nA = \\operatorname{diag}(L, 1, 1, \\dots, 1) \\in \\mathbb{R}^{m \\times m},\n$$\nwith $m \\geq 2$ and $L > 0$. Let the initial guess be $x_{0} = 0$ and choose the right-hand side so that the initial residual is\n$$\nr_{0} = b - A x_{0} = b = \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^{m}.\n$$\nUse the standard Euclidean inner product $(u, v) = u^{\\mathsf{T}} v$ and the Euclidean norm $\\|v\\|_{2} = \\sqrt{(v, v)}$. Let the shadow residual be $\\,\\hat{r} = r_{0}$.\n\nDefine the first BiCGSTAB iteration by\n$$\np_{1} = r_{0}, \\quad v_{1} = A p_{1}, \\quad \\alpha_{1} = \\frac{(\\hat{r}, r_{0})}{(\\hat{r}, v_{1})}, \\quad s_{1} = r_{0} - \\alpha_{1} v_{1},\n$$\n$$\nt_{1} = A s_{1}, \\quad \\omega_{1} = \\frac{(t_{1}, s_{1})}{(t_{1}, t_{1})}, \\quad r_{1} = s_{1} - \\omega_{1} t_{1}.\n$$\n\nIn the regime where the eigenvalue distribution consists of a single extreme outlier $L$ and a tight cluster at $1$ (that is, take the limit $L \\to \\infty$ with $m$ fixed), define the spike amplification factor\n$$\nQ(m) \\equiv \\lim_{L \\to \\infty} \\frac{\\|s_{1}\\|_{2}}{\\|r_{1}\\|_{2}}.\n$$\n\nDerive the exact closed-form expression for $Q(m)$ as a function of $m$. Your final answer must be a single analytic expression. Do not include any units. No rounding is required.", "solution": "The problem requires the derivation of a closed-form expression for the spike amplification factor $Q(m)$, defined as the limit of the ratio of the norms of two intermediate residuals, $s_1$ and $r_1$, in the first iteration of the BiCGSTAB method. The limit is taken as a single outlier eigenvalue $L$ of the system matrix $A$ approaches infinity. We shall proceed by a direct and systematic computation of all quantities involved.\n\nThe given parameters are:\nThe matrix $A = \\operatorname{diag}(L, 1, 1, \\dots, 1) \\in \\mathbb{R}^{m \\times m}$, with $m \\geq 2$ and $L > 0$.\nThe initial guess is $x_{0} = 0$.\nThe initial residual is $r_{0} = b = \\begin{pmatrix} 1 & 1 & \\dots & 1 \\end{pmatrix}^{\\mathsf{T}}$. Let us denote this vector of ones as $\\mathbf{1}_{m}$.\nThe shadow residual is $\\hat{r} = r_{0} = \\mathbf{1}_{m}$.\n\nThe first step is to compute the quantities defined in the first BiCGSTAB iteration.\n\n1.  Compute the search direction $p_1$ and the vector $v_1 = A p_1$.\n    According to the standard algorithm, we set $p_1 = r_0$.\n    $$p_{1} = r_{0} = \\mathbf{1}_{m}$$\n    Then, $v_{1}$ is computed as:\n    $$v_{1} = A p_{1} = A r_{0} = \\operatorname{diag}(L, 1, \\dots, 1) \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} L \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}$$\n    The first component of $v_1$ is $L$, and the subsequent $m-1$ components are all $1$.\n\n2.  Compute the coefficient $\\alpha_1$.\n    $\\alpha_{1} = \\frac{(\\hat{r}, r_{0})}{(\\hat{r}, v_{1})}$. Since $\\hat{r}=r_0$, this simplifies to $\\alpha_1 = \\frac{(r_0, r_0)}{(r_0, v_1)}$.\n    The required inner products are:\n    $$(\\hat{r}, r_{0}) = (r_{0}, r_{0}) = r_{0}^{\\mathsf{T}} r_{0} = \\sum_{i=1}^{m} 1^2 = m$$\n    $$(\\hat{r}, v_{1}) = (r_{0}, v_{1}) = r_{0}^{\\mathsf{T}} v_{1} = \\begin{pmatrix} 1 & 1 & \\dots & 1 \\end{pmatrix} \\begin{pmatrix} L \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = 1 \\cdot L + (m-1) \\cdot 1 = L + m - 1$$\n    Thus, $\\alpha_1$ is:\n    $$\\alpha_{1} = \\frac{m}{L + m - 1}$$\n\n3.  Compute the intermediate residual $s_1 = r_0 - \\alpha_1 v_1$.\n    $$s_{1} = \\mathbf{1}_{m} - \\frac{m}{L + m - 1} \\begin{pmatrix} L \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}$$\n    We compute the components of $s_1$:\n    The first component is:\n    $$s_{1,1} = 1 - \\alpha_1 L = 1 - \\frac{m L}{L + m - 1} = \\frac{L + m - 1 - m L}{L + m - 1} = \\frac{(1-m)L + m - 1}{L + m - 1} = \\frac{-(m-1)L + (m-1)}{L + m - 1} = \\frac{(m-1)(1-L)}{L + m - 1}$$\n    For $i \\in \\{2, \\dots, m\\}$, the components are:\n    $$s_{1,i} = 1 - \\alpha_1 \\cdot 1 = 1 - \\frac{m}{L + m - 1} = \\frac{L + m - 1 - m}{L + m - 1} = \\frac{L-1}{L+m-1}$$\n    We can factor out a common term to write $s_1$ more compactly:\n    $$s_{1} = \\frac{L-1}{L+m-1} \\begin{pmatrix} -(m-1) \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}$$\n\n4.  Compute $t_1 = A s_1$ and the coefficient $\\omega_1$.\n    $$t_{1} = A s_{1} = \\frac{L-1}{L+m-1} \\operatorname{diag}(L, 1, \\dots, 1) \\begin{pmatrix} -(m-1) \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\frac{L-1}{L+m-1} \\begin{pmatrix} -L(m-1) \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}$$\n    The coefficient $\\omega_1$ is given by $\\omega_{1} = \\frac{(t_{1}, s_{1})}{(t_{1}, t_{1})}$.\n    Let us compute the inner products:\n    $$(t_{1}, s_{1}) = \\left(\\frac{L-1}{L+m-1}\\right)^2 \\left( (-L(m-1))(-(m-1)) + \\sum_{i=2}^{m} 1 \\cdot 1 \\right) = \\left(\\frac{L-1}{L+m-1}\\right)^2 (L(m-1)^2 + m-1)$$\n    $$(t_{1}, s_{1}) = \\left(\\frac{L-1}{L+m-1}\\right)^2 (m-1)(L(m-1)+1)$$\n    $$(t_{1}, t_{1}) = \\|t_1\\|_2^2 = \\left(\\frac{L-1}{L+m-1}\\right)^2 \\left( (-L(m-1))^2 + \\sum_{i=2}^{m} 1^2 \\right) = \\left(\\frac{L-1}{L+m-1}\\right)^2 (L^2(m-1)^2 + m-1)$$\n    $$(t_{1}, t_{1}) = \\left(\\frac{L-1}{L+m-1}\\right)^2 (m-1)(L^2(m-1)+1)$$\n    The coefficient $\\omega_1$ is therefore:\n    $$\\omega_{1} = \\frac{\\left(\\frac{L-1}{L+m-1}\\right)^2 (m-1)(L(m-1)+1)}{\\left(\\frac{L-1}{L+m-1}\\right)^2 (m-1)(L^2(m-1)+1)} = \\frac{L(m-1)+1}{L^2(m-1)+1}$$\n\n5.  Compute the final residual of the first iteration, $r_1 = s_1 - \\omega_1 t_1$.\n    First, we determine the vector $s_1 - \\omega_1 t_1$ component-wise.\n    The first component:\n    $$s_{1,1} - \\omega_{1} t_{1,1} = \\frac{(L-1)(-(m-1))}{L+m-1} - \\frac{L(m-1)+1}{L^2(m-1)+1} \\frac{(L-1)(-L(m-1))}{L+m-1}$$\n    $$= \\frac{(L-1)(-(m-1))}{L+m-1} \\left(1 - \\frac{L(L(m-1)+1)}{L^2(m-1)+1}\\right) = \\frac{-(L-1)(m-1)}{L+m-1} \\left(\\frac{L^2(m-1)+1 - L^2(m-1)-L}{L^2(m-1)+1}\\right)$$\n    $$= \\frac{-(L-1)(m-1)}{L+m-1} \\frac{1-L}{L^2(m-1)+1} = \\frac{(L-1)^2(m-1)}{(L+m-1)(L^2(m-1)+1)}$$\n    For $i \\in \\{2, \\dots, m\\}$, the components are:\n    $$s_{1,i} - \\omega_{1} t_{1,i} = \\frac{L-1}{L+m-1} - \\frac{L(m-1)+1}{L^2(m-1)+1} \\frac{L-1}{L+m-1} = \\frac{L-1}{L+m-1} \\left(1 - \\frac{L(m-1)+1}{L^2(m-1)+1}\\right)$$\n    $$= \\frac{L-1}{L+m-1} \\left(\\frac{L^2(m-1)+1 - L(m-1)-1}{L^2(m-1)+1}\\right) = \\frac{L-1}{L+m-1} \\frac{L^2(m-1)-L(m-1)}{L^2(m-1)+1}$$\n    $$= \\frac{(L-1)L(m-1)(L-1)}{(L+m-1)(L^2(m-1)+1)} = \\frac{L(L-1)^2(m-1)}{(L+m-1)(L^2(m-1)+1)}$$\n    Combining these components, we get the vector $r_1$:\n    $$r_{1} = \\frac{(L-1)^2(m-1)}{(L+m-1)(L^2(m-1)+1)} \\begin{pmatrix} 1 \\\\ L \\\\ \\vdots \\\\ L \\end{pmatrix}$$\n\n6.  Compute the norms $\\|s_1\\|_2$ and $\\|r_1\\|_2$.\n    For $\\|s_1\\|_2$:\n    $$\\|s_1\\|_2^2 = \\left(\\frac{L-1}{L+m-1}\\right)^2 \\left( (-(m-1))^2 + (m-1) \\cdot 1^2 \\right) = \\left(\\frac{L-1}{L+m-1}\\right)^2 ((m-1)^2 + m-1)$$\n    $$\\|s_1\\|_2^2 = \\left(\\frac{L-1}{L+m-1}\\right)^2 m(m-1)$$\n    For large $L$, $L-1 > 0$, so we take the positive square root:\n    $$\\|s_1\\|_2 = \\frac{L-1}{L+m-1} \\sqrt{m(m-1)}$$\n    For $\\|r_1\\|_2$:\n    $$\\|r_1\\|_2^2 = \\left(\\frac{(L-1)^2(m-1)}{(L+m-1)(L^2(m-1)+1)}\\right)^2 \\left( 1^2 + (m-1) L^2 \\right)$$\n    Notice that the term $1+(m-1)L^2 = L^2(m-1)+1$. This leads to a cancellation:\n    $$\\|r_1\\|_2^2 = \\frac{(L-1)^4(m-1)^2}{(L+m-1)^2(L^2(m-1)+1)^2} (L^2(m-1)+1) = \\frac{(L-1)^4(m-1)^2}{(L+m-1)^2(L^2(m-1)+1)}$$\n    Taking the square root:\n    $$\\|r_1\\|_2 = \\frac{(L-1)^2(m-1)}{(L+m-1)\\sqrt{L^2(m-1)+1}}$$\n\n7.  Compute the ratio and take the limit to find $Q(m)$.\n    The ratio is:\n    $$\\frac{\\|s_1\\|_2}{\\|r_1\\|_2} = \\frac{\\frac{L-1}{L+m-1}\\sqrt{m(m-1)}}{\\frac{(L-1)^2(m-1)}{(L+m-1)\\sqrt{L^2(m-1)+1}}} = \\frac{(L-1)\\sqrt{m(m-1)}}{1} \\cdot \\frac{\\sqrt{L^2(m-1)+1}}{(L-1)^2(m-1)}$$\n    $$= \\frac{\\sqrt{m}\\sqrt{m-1}}{(L-1)(m-1)} \\sqrt{L^2(m-1)+1} = \\frac{\\sqrt{m}}{(L-1)\\sqrt{m-1}} \\sqrt{L^2(m-1)+1}$$\n    $$= \\frac{\\sqrt{m}}{\\sqrt{m-1}} \\cdot \\frac{\\sqrt{L^2(m-1)+1}}{L-1}$$\n    Now we take the limit as $L \\to \\infty$:\n    $$Q(m) = \\lim_{L \\to \\infty} \\frac{\\|s_1\\|_2}{\\|r_1\\|_2} = \\frac{\\sqrt{m}}{\\sqrt{m-1}} \\lim_{L \\to \\infty} \\frac{\\sqrt{L^2(m-1)+1}}{L-1}$$\n    The limit is evaluated as follows:\n    $$\\lim_{L \\to \\infty} \\frac{\\sqrt{L^2(m-1)+1}}{L-1} = \\lim_{L \\to \\infty} \\frac{\\sqrt{L^2(m-1+1/L^2)}}{L(1-1/L)} = \\lim_{L \\to \\infty} \\frac{L\\sqrt{m-1+1/L^2}}{L(1-1/L)}$$\n    $$= \\lim_{L \\to \\infty} \\frac{\\sqrt{m-1+1/L^2}}{1-1/L} = \\frac{\\sqrt{m-1+0}}{1-0} = \\sqrt{m-1}$$\n    Substituting this result back into the expression for $Q(m)$:\n    $$Q(m) = \\frac{\\sqrt{m}}{\\sqrt{m-1}} \\cdot \\sqrt{m-1} = \\sqrt{m}$$\nThe derivation is complete. The exact closed-form expression for the spike amplification factor is $\\sqrt{m}$.", "answer": "$$\\boxed{\\sqrt{m}}$$", "id": "2376279"}]}