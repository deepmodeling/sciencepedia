{"hands_on_practices": [{"introduction": "While the theory of Gaussian elimination is elegant, its real-world implementation on computers is fraught with the peril of finite-precision arithmetic. This exercise provides a concrete, hands-on demonstration of why pivoting is not just an optimization but a crucial component for numerical stability. By using a simplified \"three-digit chopping arithmetic,\" you will directly observe how a seemingly insignificant pivot choice can lead to catastrophic errors, and how partial pivoting elegantly resolves the issue.", "problem": "Consider the following system of linear equations:\n$$\n\\begin{align*}\n(2.00 \\times 10^{-4}) x_1 + 2.00 x_2 &= 4.00 \\\\\n1.00 x_1 + 3.00 x_2 &= 5.00\n\\end{align*}\n$$\nYou are to solve this system using Gaussian elimination, but all calculations must be performed using a simplified floating-point representation known as **three-digit chopping arithmetic**. In this arithmetic system, numbers are first written in normalized decimal form, $\\pm 0.d_1d_2d_3d_4... \\times 10^n$, where $d_1 \\in \\{1, 2, \\dots, 9\\}$. The number is then stored by \"chopping off\" all digits after the third, resulting in the form $\\pm 0.d_1d_2d_3 \\times 10^n$. This chopping occurs after every individual arithmetic operation (addition, subtraction, multiplication, division).\n\nCalculate the solution vector $\\mathbf{x} = [x_1, x_2]^T$ using Gaussian elimination **with partial pivoting**. Express your final answer as the two components of the solution vector.", "solution": "We apply Gaussian elimination with partial pivoting under three-digit chopping arithmetic (store numbers in normalized form with three significant digits after each operation).\n\nStart with the augmented matrix\n$$\n\\left[\\begin{array}{cc|c}\n2.00\\times 10^{-4} & 2.00 & 4.00\\\\\n1.00 & 3.00 & 5.00\n\\end{array}\\right].\n$$\nPartial pivoting on column 1 compares $|2.00\\times 10^{-4}|$ and $|1.00|$, so we swap the two rows:\n$$\n\\left[\\begin{array}{cc|c}\n1.00 & 3.00 & 5.00\\\\\n2.00\\times 10^{-4} & 2.00 & 4.00\n\\end{array}\\right].\n$$\nElimination multiplier\n$$\n\\ell_{21}=\\text{chop}_{3}\\left(\\frac{2.00\\times 10^{-4}}{1.00}\\right)=2.00\\times 10^{-4}.\n$$\nUpdate row 2 entries with chopping after each operation:\n- New $a_{21}$:\n$$\n\\text{chop}_{3}\\left(2.00\\times 10^{-4}-\\ell_{21}\\cdot 1.00\\right)=\\text{chop}_{3}\\left(2.00\\times 10^{-4}-2.00\\times 10^{-4}\\right)=0.\n$$\n- New $a_{22}$:\n$$\n\\ell_{21}\\cdot a_{12}=\\text{chop}_{3}\\left((2.00\\times 10^{-4})\\cdot 3.00\\right)=6.00\\times 10^{-4},\n$$\n$$\na_{22}^{(new)}=\\text{chop}_{3}\\left(2.00-6.00\\times 10^{-4}\\right)=\\text{chop}_{3}(1.9994)=1.99.\n$$\n- New $b_{2}$:\n$$\n\\ell_{21}\\cdot b_{1}=\\text{chop}_{3}\\left((2.00\\times 10^{-4})\\cdot 5.00\\right)=1.00\\times 10^{-3},\n$$\n$$\nb_{2}^{(new)}=\\text{chop}_{3}\\left(4.00-1.00\\times 10^{-3}\\right)=\\text{chop}_{3}(3.999)=3.99.\n$$\nThe upper triangular system is thus\n$$\n\\begin{cases}\n1.00\\,x_{1}+3.00\\,x_{2}=5.00,\\\\\n1.99\\,x_{2}=3.99.\n\\end{cases}\n$$\nBack substitution with chopping after each operation:\n$$\nx_{2}=\\text{chop}_{3}\\left(\\frac{3.99}{1.99}\\right)=\\text{chop}_{3}(2.005025\\ldots)=2.00.\n$$\nThen\n$$\na_{12}\\,x_{2}=\\text{chop}_{3}(3.00\\cdot 2.00)=6.00,\\quad\nb_{1}-a_{12}x_{2}=\\text{chop}_{3}(5.00-6.00)=-1.00,\n$$\n$$\nx_{1}=\\text{chop}_{3}\\left(\\frac{-1.00}{1.00}\\right)=-1.00.\n$$\nTherefore, under three-digit chopping arithmetic with partial pivoting, the solution vector is $x_{1}=-1.00$ and $x_{2}=2.00$.", "answer": "$$\\boxed{\\begin{pmatrix}-1.00 & 2.00\\end{pmatrix}}$$", "id": "2193047"}, {"introduction": "Physical systems often involve quantities with vastly different scales, from microscopic distances to astronomical forces, which can lead to ill-conditioned linear systems when modeled. This practice challenges you to solve several such systems where coefficients span many orders of magnitude or where matrices are nearly singular. This exercise highlights the power and necessity of using robust, professionally implemented numerical libraries, which have sophisticated pivoting strategies built-in to handle these exact challenges reliably.", "problem": "Consider three independent linear systems that arise after converting heterogeneous physical models into the International System of Units (SI). The coefficients already include all necessary unit conversions, and each system has unknowns with specified SI units. Due to the dramatically different magnitudes across equations and coefficients, the numerical solution must be obtained accurately. For each system, solve for the unknown vector $\\mathbf{x} = [x_1, x_2, x_3]^{\\mathsf{T}}$ given the matrix $\\mathbf{A}$ and the right-hand side vector $\\mathbf{b}$, and report the solution components as real numbers in the specified SI units (do not include unit symbols in the output; the values should be interpreted in the units stated for each system). Your program must process the following test suite and produce the aggregated output as specified.\n\nSystem A (heterogeneous units, happy path):\n- Unknowns: $x_1$ in $\\mathrm{W}\\,\\mathrm{m}^{-1}\\,\\mathrm{K}^{-1}$, $x_2$ in $\\mathrm{C}$, $x_3$ in $\\mathrm{m}$.\n- Coefficient matrix\n$$\n\\mathbf{A}_A =\n\\begin{bmatrix}\n10^{9} & 3 & -2\\times 10^{-6} \\\\\n2\\times 10^{-3} & -5\\times 10^{6} & 7 \\\\\n4 & 10^{-9} & 3\\times 10^{3}\n\\end{bmatrix}\n$$\n- Right-hand side\n$$\n\\mathbf{b}_A =\n\\begin{bmatrix}\n1999999990.999998 \\\\\n15000007.004 \\\\\n3007.999999997\n\\end{bmatrix}\n$$\n\nSystem B (nearly singular structure with disparate scales):\n- Unknowns: $x_1$, $x_2$, $x_3$ are dimensionless.\n- Coefficient matrix\n$$\n\\mathbf{A}_B =\n\\begin{bmatrix}\n10^{-12} & 1 & 1 \\\\\n1 & 1 & 1 \\\\\n1 & 1 & 1+10^{-12}\n\\end{bmatrix}\n$$\n- Right-hand side\n$$\n\\mathbf{b}_B =\n\\begin{bmatrix}\n10^{-12} \\\\\n1 \\\\\n1+10^{-12}\n\\end{bmatrix}\n$$\n\nSystem C (zero leading diagonal entry and extreme coefficient variation):\n- Unknowns: $x_1$ in $\\mathrm{m}$, $x_2$ in $\\mathrm{Pa}$, $x_3$ in $\\mathrm{s}$.\n- Coefficient matrix\n$$\n\\mathbf{A}_C =\n\\begin{bmatrix}\n0 & 10^{5} & 1 \\\\\n10^{-10} & 1 & 1 \\\\\n1 & 0 & 10^{-5}\n\\end{bmatrix}\n$$\n- Right-hand side\n$$\n\\mathbf{b}_C =\n\\begin{bmatrix}\n200003 \\\\\n5.0000000001 \\\\\n1.00003\n\\end{bmatrix}\n$$\n\nRequired output format:\n- For each system, compute the solution vector $\\mathbf{x}$ and round each component to $8$ significant digits.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the list of the three rounded solution components for the corresponding system in the order A, B, C. For example, the output must look like\n$$\n[\\,[x_{1,A},x_{2,A},x_{3,A}],\\,[x_{1,B},x_{2,B},x_{3,B}],\\,[x_{1,C},x_{2,C},x_{3,C}]\\,]\n$$\nwith each $x$ being a real number rounded to $8$ significant digits.", "solution": "The problem presented is valid. It is a well-posed set of linear algebra problems that are grounded in numerical analysis and relevant to computational physics. All necessary data are provided, and there are no scientific or logical contradictions. The core of the problem is to solve the matrix equation $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ for three distinct systems, each designed to test the robustness of the numerical method used. The matrices exhibit characteristics that are challenging for naive algorithms, such as large variations in the magnitude of coefficients, near-singularity, and the presence of a zero on the main diagonal. These are precisely the conditions where a numerically stable algorithm is not just preferable, but required.\n\nThe fundamental principle for solving such systems is Gaussian elimination. However, a naive implementation of Gaussian elimination is numerically unstable if a pivot element (the diagonal element used for normalization) is zero or very small relative to other elements in the matrix. This can lead to division by zero or catastrophic amplification of round-off errors. The standard and correct method to ensure numerical stability is Gaussian elimination with a pivoting strategy.\n\nThe most common strategy is partial pivoting. At step $k$ of the elimination process, the algorithm searches for the element with the largest absolute value in the $k$-th column, from row $k$ to the last row. The row containing this element is then swapped with the $k$-th row. This ensures that the pivot element is as large as possible in magnitude, which minimizes the multipliers used in the elimination steps and thereby controls the growth of numerical errors. System $\\mathbf{A}_C$, with a $0$ at position $(1,1)$, makes pivoting non-negotiable; without a row swap, the algorithm would immediately fail due to division by zero. Systems $\\mathbf{A}_A$ and $\\mathbf{A}_B$ possess large disparities in coefficient magnitudes, making them ill-conditioned. For such matrices, pivoting is crucial to obtain an accurate solution.\n\nIn modern computational practice, one does not implement this algorithm from scratch. Instead, one relies on highly optimized, rigorously tested, and numerically stable implementations available in standard scientific computing libraries. These libraries, such as LAPACK (Linear Algebra PACKage), form the foundation for the linear algebra routines in environments like NumPy. The function `numpy.linalg.solve` internally uses an LAPACK solver (typically a variant of `_gesv`) that implements LU decomposition with partial pivoting. This is the appropriate, professional tool for this task.\n\nThe procedure to solve each system is as follows:\n$1$. For each system (A, B, C), the coefficient matrix $\\mathbf{A}$ and the right-hand side vector $\\mathbf{b}$ are defined as numerical arrays of type `float64` for maximum precision.\n$2$. The `numpy.linalg.solve(A, b)` function is called to compute the solution vector $\\mathbf{x}$. This function automatically handles the numerical challenges presented by the matrices through its underlying pivoting strategy.\n$3$. The problem requires that each component of the resulting solution vector $\\mathbf{x}$ be rounded to $8$ significant digits. This requires a specific rounding function that accounts for the magnitude of the number. For a non-zero number $x$, the number of decimal places $d$ to which it must be rounded to achieve $n$ significant digits is given by $d = n - 1 - \\lfloor\\log_{10}|x|\\rfloor$.\n$4$. The rounded solution vectors for all three systems are collected and formatted into a single string as specified by the problem statement. Analytical inspection reveals that the exact solutions are integer vectors: $\\mathbf{x}_A = [2, -3, 1]^{\\mathsf{T}}$, $\\mathbf{x}_B = [1, -1, 1]^{\\mathsf{T}}$, and $\\mathbf{x}_C = [1, 2, 3]^{\\mathsf{T}}$. A robust numerical solver should recover these solutions with high accuracy, and after rounding, the results should match these exact values. The output will thus be a list of lists containing these floating-point numbers.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef round_to_significant_digits(x, n):\n    \"\"\"\n    Rounds a number x to n significant digits.\n    \"\"\"\n    if x == 0 or not np.isfinite(x):\n        return float(x) if isinstance(x, (int, float)) else x\n    \n    power = n - 1 - math.floor(math.log10(abs(x)))\n    factor = 10**power\n    \n    return round(x * factor) / factor\n\ndef solve():\n    \"\"\"\n    Solves the three linear systems defined in the problem statement\n    using a robust numerical solver and formats the output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([\n                [1e9, 3, -2e-6],\n                [2e-3, -5e6, 7],\n                [4, 1e-9, 3e3]\n            ], dtype=np.float64),\n            \"b\": np.array([\n                1999999990.999998,\n                15000007.004,\n                3007.999999997\n            ], dtype=np.float64)\n        },\n        {\n            \"A\": np.array([\n                [1e-12, 1, 1],\n                [1, 1, 1],\n                [1, 1, 1 + 1e-12]\n            ], dtype=np.float64),\n            \"b\": np.array([\n                1e-12,\n                1,\n                1 + 1e-12\n            ], dtype=np.float64)\n        },\n        {\n            \"A\": np.array([\n                [0, 1e5, 1],\n                [1e-10, 1, 1],\n                [1, 0, 1e-5]\n            ], dtype=np.float64),\n            \"b\": np.array([\n                200003,\n                5.0000000001,\n                1.00003\n            ], dtype=np.float64)\n        }\n    ]\n\n    results = []\n    num_significant_digits = 8\n\n    for case in test_cases:\n        A = case[\"A\"]\n        b = case[\"b\"]\n        \n        # Solve the linear system using numpy's robust solver, which\n        # employs LU decomposition with partial pivoting.\n        x = np.linalg.solve(A, b)\n        \n        # Round each component of the solution vector to 8 significant digits.\n        x_rounded = [round_to_significant_digits(val, num_significant_digits) for val in x]\n        \n        results.append(x_rounded)\n\n    # Final print statement in the exact required format.\n    # The str() representation of a Python list is used for the inner lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2397351"}, {"introduction": "To truly master an algorithm, it is invaluable to build it from the ground up. This advanced practice invites you to step away from the world of floating-point approximations and implement Gaussian elimination using exact rational arithmetic. By doing so, you will disentangle the logic of the algorithm—including pivoting and rank detection—from the separate issue of numerical error. You will be able to solve notoriously ill-conditioned systems, like the Hilbert matrix, with perfect accuracy, providing a profound insight into the pure mechanics of the method.", "problem": "You are to design and implement a robust solver for square linear systems using Gaussian elimination (GE) with partial pivoting (PP) carried out in exact rational arithmetic. The goal is to eliminate roundoff error altogether by representing every entry as a rational number and to use pivoting to ensure correct row selection and reliable singularity detection for ill-conditioned systems. You must start from the fundamental definition of a linear system and the invariance of the solution set under elementary row operations. Do not introduce any floating-point approximations in the elimination or back-substitution phases; all computations must be performed exactly using rational numbers.\n\nFundamental base and setting: A square linear system is given by $A \\, x = b$, where $A \\in \\mathbb{Q}^{n \\times n}$ and $b \\in \\mathbb{Q}^{n}$. Two systems related by elementary row operations have the same solution set. Gaussian elimination applies a finite sequence of row permutations, row scalings, and row additions to reduce the system to an upper triangular form, after which back substitution recovers a solution if the system is nonsingular. Partial pivoting selects, at each column $k$, a row from indices $i \\in \\{k, k+1, \\dots, n-1\\}$ with a pivot entry of maximal absolute value in that column and swaps it into position $k$ before elimination, which avoids division by zero and mitigates the effect of small pivots. In exact rational arithmetic, pivoting also provides a principled way to detect singularity by counting the number of nonzero pivots.\n\nYour implementation requirements:\n- Implement Gaussian elimination with partial pivoting using exact rational arithmetic for all matrix and vector entries. Represent all numbers as rationals, and ensure that every division is exact in the field $\\mathbb{Q}$.\n- At each step $k$, choose a pivot row with maximal $|A_{ik}|$ for $i \\ge k$. If the maximal value is $0$, declare the column $k$ as having no pivot and continue with the next column to enable rank computation. Track the number of nonzero pivots to obtain the rank.\n- If the system is of full rank $n$, perform exact back substitution to compute the unique solution $x \\in \\mathbb{Q}^{n}$. If the system is rank-deficient, report the computed rank $r < n$ and do not attempt to produce one particular solution.\n\nTest suite:\nImplement your solver and run it on the following four test cases. All matrices $A$ and vectors $b$ must be constructed exactly over $\\mathbb{Q}$, and all right-hand sides $b$ are to be formed exactly as specified.\n\n- Test case $1$ (happy path, ill-conditioned but nonsingular): Let $n = 5$, let $A$ be the Hilbert matrix with entries $A_{ij} = 1/(i+j-1)$ for $i,j \\in \\{1,2,3,4,5\\}$, and let the exact solution be $x^{\\star} = [1,1,1,1,1]^{\\top}$. Construct $b = A \\, x^{\\star}$ exactly in $\\mathbb{Q}^{n}$.\n- Test case $2$ (harder ill-conditioned, nonsingular): Let $n = 7$, let $A$ be the Hilbert matrix with entries $A_{ij} = 1/(i+j-1)$ for $i,j \\in \\{1,2,3,4,5,6,7\\}$, and let the exact solution be $x^{\\star} = [1,-1,1,-1,1,-1,1]^{\\top}$. Construct $b = A \\, x^{\\star}$ exactly.\n- Test case $3$ (singular but consistent): Let $A$ be the $3 \\times 3$ matrix with rows $[1,2,3]$, $[2,4,6]$, $[1,2,3]$, and let $b = [6,12,6]^{\\top}$. This system has infinitely many solutions; your solver must detect singularity and report the rank.\n- Test case $4$ (boundary singular case): Let $A$ be the $1 \\times 1$ matrix $[0]$ and let $b = [0]$. This system is consistent with infinitely many solutions; your solver must report the rank.\n\nRequired outputs for each test case:\n- For test cases $1$ and $2$: Produce a list of three items $[\\text{ok}, r_{\\infty}, e_{\\infty}]$, where $\\text{ok}$ is a boolean that is true if and only if the computed exact solution $x$ matches $x^{\\star}$ entrywise in $\\mathbb{Q}$ without any discrepancy, $r_{\\infty} = \\max_{i} |(A x - b)_{i}|$ is the maximum absolute residual reported as a floating-point number, and $e_{\\infty} = \\max_{i} |(x - x^{\\star})_{i}|$ is the maximum absolute error reported as a floating-point number.\n- For test cases $3$ and $4$: Produce the integer rank $r$ of the matrix $A$ computed by counting nonzero pivots during elimination with partial pivoting.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The line must contain four entries in order, corresponding to test cases $1$ through $4$. The first two entries must each be a list as specified above, and the last two entries must be integers. For example, an admissible format is $[[\\text{True}, 0.0, 0.0],[\\text{True}, 0.0, 0.0],1,0]$. No physical units are involved in this problem, and no angles are used.\n\nConstraints:\n- You must not use floating-point arithmetic anywhere in the elimination or back-substitution logic. All arithmetic in the solver must be done over $\\mathbb{Q}$.\n- You must implement partial pivoting and rank detection as described. You must not rely on external linear algebra solvers or symbolic algebra systems.", "solution": "The problem requires the design and implementation of a solver for square linear systems $A x = b$, where the matrix $A \\in \\mathbb{Q}^{n \\times n}$ and the vector $b \\in \\mathbb{Q}^{n}$ are defined over the field of rational numbers. The solution must employ Gaussian elimination with partial pivoting (GE-PP), with all arithmetic performed exactly in $\\mathbb{Q}$ to preclude any roundoff error.\n\nThe fundamental principle is that the solution set of a linear system is invariant under elementary row operations. Gaussian elimination systematically applies these operations—row swapping, row scaling, and adding a multiple of one row to another—to transform the original system into an equivalent, but more easily solved, upper triangular form.\n\nOur methodology is as follows:\n\nFirst, we represent all numerical values as rational numbers. Python's `fractions.Fraction` class is suitable for this, as it performs exact arithmetic on objects representing fractions $\\frac{p}{q}$ where $p$ and $q$ are integers. This approach completely circumvents the precision and stability issues inherent in floating-point arithmetic, which is particularly critical for the ill-conditioned Hilbert matrices in the test suite.\n\nThe algorithm operates on the augmented matrix $[A|b]$. It proceeds via two main phases: forward elimination and back substitution.\n\nThe forward elimination phase aims to reduce the matrix $A$ to row echelon form. The process iterates through the columns $k$ from $0$ to $n-1$. At each step, we determine the rank of the matrix processed so far, denoted by a variable `rank`.\n$1$. **Pivoting**: For the current column $k$, we search for the entry with the maximum absolute value in rows $i \\ge \\text{rank}$. Let this pivot entry be $A_{p,k}$. We then swap the entire row $p$ with row `rank`. This is partial pivoting. Its purpose in exact arithmetic is to handle zero pivots systematically and provide a consistent method for rank determination.\n$2$. **Rank Determination**: If the selected pivot element is zero, it implies that column $k$ is linearly dependent on the preceding pivot columns. In this case, no elimination is performed for this column, the rank is not incremented, and the algorithm proceeds to the next column $k+1$.\n$3$. **Elimination**: If the pivot $A_{\\text{rank},k}$ is non-zero, we use it to eliminate all entries below it in the same column. For each row $i > \\text{rank}$, we compute a multiplier $m_{i,k} = A_{i,k} / A_{\\text{rank},k}$. This division is exact. We then update the row via the operation $R_i \\leftarrow R_i - m_{i,k} R_{\\text{rank}}$. This operation is applied to the entire augmented row, from column $k$ to the end. After elimination for column $k$ is complete, we increment the rank, `rank` $\\leftarrow$ `rank` $+ 1$.\n\nAfter the forward elimination process finishes, the variable `rank` holds the rank of the matrix $A$.\n\nThe solution phase depends on the computed rank.\n- **Singular Case**: If $\\text{rank} < n$, the matrix $A$ is singular. The system may have no solution or infinitely many solutions. As per the problem specification, we do not attempt to find a solution but instead report the computed rank $r = \\text{rank}$. This is the outcome for Test Cases $3$ and $4$.\n- **Nonsingular Case**: If $\\text{rank} = n$, the matrix is of full rank. The forward elimination has produced an equivalent system where the matrix is upper triangular with a non-zero diagonal. A unique solution $x \\in \\mathbb{Q}^{n}$ exists and is found using back substitution. Starting from the last variable, $x_{n-1}$, we solve for each $x_i$ iteratively:\n$$x_{n-1} = \\frac{b_{n-1}}{A_{n-1,n-1}}$$\n$$x_i = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j=i+1}^{n-1} A_{ij} x_j \\right) \\quad \\text{for } i = n-2, n-3, \\dots, 0$$\nAll calculations in this phase are also exact. This path is followed for Test Cases $1$ and $2$.\n\nFor the nonsingular test cases, we must verify the computed solution. The problem provides the exact solution $x^{\\star}$. We verify our computed solution $x$ by checking if $x = x^{\\star}$ entrywise. Since all arithmetic is exact, the two must be identical. We then compute two metrics: the maximum absolute residual $r_{\\infty} = \\max_{i} |(A x - b)_{i}|$ and the maximum absolute error $e_{\\infty} = \\max_{i} |(x - x^{\\star})_{i}|$. These quantities are calculated exactly as rational numbers and then converted to floating-point numbers for the final report. Given the exactness of the solver, we expect both $r_{\\infty}$ and $e_{\\infty}$ to be $0.0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\nimport copy\n\ndef GEPP_rational(A_in, b_in):\n    \"\"\"\n    Solves a linear system Ax=b using Gaussian elimination with partial pivoting\n    in exact rational arithmetic.\n\n    Args:\n        A_in (list of lists): The matrix A.\n        b_in (list): The vector b.\n\n    Returns:\n        tuple: A tuple containing a status string ('nonsingular' or 'singular')\n               and a payload (the solution vector x or the rank).\n    \"\"\"\n    n = len(A_in)\n    # Create an augmented matrix with Fraction objects.\n    # A deep copy is used to avoid modifying inputs.\n    Ab = []\n    for i in range(n):\n        row = [Fraction(x) for x in A_in[i]] + [Fraction(b_in[i])]\n        Ab.append(row)\n\n    rank = 0\n    # Forward elimination phase\n    for k in range(n):  # Iterate through columns\n        if rank == n:\n            break\n\n        # Find pivot in column k, from row 'rank' downwards\n        i_max = rank\n        v_max = abs(Ab[rank][k])\n        for i in range(rank + 1, n):\n            if abs(Ab[i][k]) > v_max:\n                v_max = abs(Ab[i][k])\n                i_max = i\n\n        # If maximal pivot in this column (in the active submatrix) is zero,\n        # the column is linearly dependent. We move to the next column.\n        if Ab[i_max][k] == 0:\n            continue\n\n        # Swap the found pivot row with the current rank row\n        Ab[rank], Ab[i_max] = Ab[i_max], Ab[rank]\n        \n        pivot_val = Ab[rank][k]\n\n        # Eliminate entries below the pivot\n        for i in range(rank + 1, n):\n            factor = Ab[i][k] / pivot_val\n            # Apply row operation to the rest of the row\n            for j in range(k, n + 1):\n                Ab[i][j] -= factor * Ab[rank][j]\n        \n        rank += 1\n    \n    # Solution phase\n    if rank < n:\n        return (\"singular\", rank)\n\n    # Nonsingular case: perform back substitution\n    x = [Fraction(0)] * n\n    for i in range(n - 1, -1, -1):\n        # We know pivots are on the diagonal because rank == n for a square matrix\n        sum_ax = sum(Ab[i][j] * x[j] for j in range(i + 1, n))\n        x[i] = (Ab[i][n] - sum_ax) / Ab[i][i]\n    \n    return (\"nonsingular\", x)\n\ndef mat_vec_mul(A, x):\n    \"\"\"Matrix-vector multiplication with Fraction objects.\"\"\"\n    n = len(A)\n    b = [Fraction(0)] * n\n    for i in range(n):\n        for j in range(n):\n            b[i] += A[i][j] * x[j]\n    return b\n\ndef solve():\n    \"\"\"\n    Defines, runs, and formats the results for the four test cases.\n    \"\"\"\n    # Test Case 1: Hilbert matrix n=5\n    n1 = 5\n    A1 = [[Fraction(1, i + j + 1) for j in range(n1)] for i in range(n1)]\n    x1_star = [Fraction(1)] * n1\n    b1 = mat_vec_mul(A1, x1_star)\n\n    # Test Case 2: Hilbert matrix n=7\n    n2 = 7\n    A2 = [[Fraction(1, i + j + 1) for j in range(n2)] for i in range(n2)]\n    x2_star = [Fraction(-1) if i % 2 else Fraction(1) for i in range(n2)]\n    b2 = mat_vec_mul(A2, x2_star)\n\n    # Test Case 3: Singular consistent system\n    A3 = [[1, 2, 3], [2, 4, 6], [1, 2, 3]]\n    b3 = [6, 12, 6]\n\n    # Test Case 4: Boundary singular case\n    A4 = [[0]]\n    b4 = [0]\n\n    test_cases = [\n        {'A': A1, 'b': b1, 'x_star': x1_star},\n        {'A': A2, 'b': b2, 'x_star': x2_star},\n        {'A': A3, 'b': b3, 'x_star': None},\n        {'A': A4, 'b': b4, 'x_star': None},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        A, b, x_star = case['A'], case['b'], case['x_star']\n        status, payload = GEPP_rational(A, b)\n        \n        if status == \"singular\":\n            all_results.append(payload) # Payload is the rank\n        else: # \"nonsingular\"\n            x_computed = payload\n            n = len(A)\n            \n            # Verify solution correctness\n            ok = all(x_computed[i] == x_star[i] for i in range(n))\n\n            # Compute residual r = Ax - b\n            Ax = mat_vec_mul(A, x_computed)\n            # The input b may not be Fraction objects, so convert\n            b_frac = [Fraction(val) for val in b]\n            residual = [Ax[i] - b_frac[i] for i in range(n)]\n            r_inf = float(max(abs(v) for v in residual))\n\n            # Compute error e = x - x_star\n            error = [x_computed[i] - x_star[i] for i in range(n)]\n            e_inf = float(max(abs(v) for v in error))\n\n            all_results.append([ok, r_inf, e_inf])\n    \n    # Custom string formatting to avoid spaces after comma in lists\n    formatted_results = []\n    for res in all_results:\n        if isinstance(res, list):\n            # Format list as [True,0.0,0.0] without spaces\n            list_str = f\"[{str(res[0])},{str(res[1])},{str(res[2])}]\"\n            formatted_results.append(list_str)\n        else:\n            formatted_results.append(str(res))\n    \n    # Final print statement must match the exact specified format.\n    # The default str() for a list has spaces, which might be undesirable.\n    # The example format `[[True, 0.0, 0.0],[True, 0.0, 0.0],1,0]` has spaces\n    # inside the sublists but not between elements of the main list.\n    # `str(list)` gives spaces. `','.join(map(str, list))` also gives spaces\n    # when an element is a list itself. Let's build the string manually for precision.\n    result_str = f\"[{','.join(str(r) for r in all_results)}]\"\n    # Python's str([True, 0.0, 0.0]) is '[True, 0.0, 0.0]', which has spaces.\n    # The prompt's example format is `[[True, 0.0, 0.0],[True, 0.0, 0.0],1,0]`\n    # This implies str(list) is acceptable for sublists. Let's use the simplest\n    # correct method.\n    \n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2397350"}]}