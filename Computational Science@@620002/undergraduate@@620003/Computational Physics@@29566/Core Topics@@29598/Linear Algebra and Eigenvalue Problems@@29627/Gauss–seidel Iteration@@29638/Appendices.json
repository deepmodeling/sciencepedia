{"hands_on_practices": [{"introduction": "To truly grasp the Gauss–Seidel method, we begin with the fundamental mechanics. This first practice invites you to perform a single, manual iteration on a simple $2 \\times 2$ system, providing a clear illustration of the core update procedure [@problem_id:1394889]. The goal is to build muscle memory for the algorithm's key feature: as you solve for each variable, you immediately use its new value in the subsequent equations within the same iteration.", "problem": "In a simplified economic model, the output of two interdependent sectors, Technology ($x_1$) and Services ($x_2$), must satisfy a market equilibrium condition. The relationship between the production levels of these sectors, measured in trillions of currency units, is described by the following system of linear equations:\n\n$$\n\\begin{align*}\n5x_1 - x_2 &= 12 \\\\\n-2x_1 + 6x_2 &= 20\n\\end{align*}\n$$\n\nAn economist is trying to find the equilibrium production levels iteratively. Starting with an initial estimate of $x_1^{(0)} = 3.0$ and $x_2^{(0)} = 4.0$, perform a single iteration of the Gauss–Seidel method to find the next approximation for the production levels, $(x_1^{(1)}, x_2^{(1)})$.\n\nExpress your answer for $x_1^{(1)}$ and $x_2^{(1)}$ in trillions of currency units, with each value rounded to three significant figures.", "solution": "We apply one Gauss–Seidel iteration to the linear system using the latest available values as soon as they are computed. First, rewrite each equation solving for the variable associated with its diagonal term:\n$$\n5x_{1}-x_{2}=12 \\implies x_{1}=\\frac{12+x_{2}}{5}, \\quad -2x_{1}+6x_{2}=20 \\implies x_{2}=\\frac{20+2x_{1}}{6}=\\frac{10+x_{1}}{3}.\n$$\nGiven the initial estimate $x_{1}^{(0)}=3.0$ and $x_{2}^{(0)}=4.0$, compute $x_{1}^{(1)}$ using $x_{2}^{(0)}$:\n$$\nx_{1}^{(1)}=\\frac{12+x_{2}^{(0)}}{5}=\\frac{12+4.0}{5}=\\frac{16}{5}=3.2.\n$$\nNext, compute $x_{2}^{(1)}$ using the newly updated $x_{1}^{(1)}$:\n$$\nx_{2}^{(1)}=\\frac{10+x_{1}^{(1)}}{3}=\\frac{10+3.2}{3}=\\frac{13.2}{3}=4.4.\n$$\nRounding each to three significant figures gives $x_{1}^{(1)}=3.20$ and $x_{2}^{(1)}=4.40$ (in trillions of currency units).", "answer": "$$\\boxed{\\begin{pmatrix} 3.20 & 4.40 \\end{pmatrix}}$$", "id": "1394889"}, {"introduction": "Now that you have mastered the mechanics, let's explore the crucial question of convergence: when is the Gauss–Seidel method guaranteed to work? While strict diagonal dominance is a well-known sufficient condition, it is not a necessary one. This advanced practice challenges you to investigate the boundary between convergence and non-convergence by analyzing a matrix that is not strictly diagonally dominant, revealing the deeper connection between convergence and the matrix being positive definite [@problem_id:2406953].", "problem": "Consider the one-parameter family of real symmetric matrices\n$$\nA(b) \\;=\\; \\begin{pmatrix}\n1 & b & 0 \\\\\nb & 1 & b \\\\\n0 & b & 1\n\\end{pmatrix},\n$$\nwhere $b$ is a positive real parameter. A matrix is said to be strictly diagonally dominant by rows if, for each row $i$, the inequality $|a_{ii}| \\;>\\; \\sum_{j \\neq i} |a_{ij}|$ holds. The Gauss–Seidel iteration (GS) is the classical fixed-point method for solving the linear system $A \\boldsymbol{x} = \\boldsymbol{b}$ obtained by splitting $A$ into strictly lower, diagonal, and strictly upper parts.\n\nDetermine the complete set of $b>0$ for which $A(b)$ is not strictly diagonally dominant by rows but the Gauss–Seidel iteration converges for every initial guess and every right-hand side vector. Then, compute the arithmetic mean of the smallest and largest endpoints of this admissible $b$-interval. Round your final answer to four significant figures. Your final answer must be this single real number (with no units).", "solution": "The problem requires finding the set of positive real numbers $b$ for which the matrix $A(b)$ is not strictly diagonally dominant, but for which the Gauss–Seidel iteration converges. Subsequently, we must compute the arithmetic mean of the endpoints of this set and round the result.\n\nFirst, let us analyze the condition of strict diagonal dominance (SDD) for the given matrix:\n$$\nA(b) = \\begin{pmatrix} 1 & b & 0 \\\\ b & 1 & b \\\\ 0 & b & 1 \\end{pmatrix}\n$$\nwhere $b > 0$. A matrix is strictly diagonally dominant if for each row $i$, the magnitude of the diagonal element is greater than the sum of the magnitudes of the off-diagonal elements in that row, i.e., $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$.\n\nFor row $1$: $|1| > |b| + |0|$. Since $b > 0$, this simplifies to $1 > b$.\nFor row $2$: $|1| > |b| + |b|$. This simplifies to $1 > 2b$, or $b < \\frac{1}{2}$.\nFor row $3$: $|1| > |0| + |b|$. This simplifies to $1 > b$.\n\nFor $A(b)$ to be strictly diagonally dominant, all three conditions must be satisfied. The most restrictive condition is $b < \\frac{1}{2}$. Therefore, $A(b)$ is strictly diagonally dominant for $b \\in (0, \\frac{1}{2})$. The problem asks for the condition where $A(b)$ is **not** strictly diagonally dominant. This occurs when at least one of the inequalities is not met. This is true if $b \\geq \\frac{1}{2}$.\n\nNext, we analyze the convergence of the Gauss–Seidel method. The iteration converges for every initial guess and every right-hand side vector if and only if the spectral radius of the iteration matrix $G = -(D+L)^{-1}U$ is less than one, i.e., $\\rho(G) < 1$. Here, $A = D+L+U$ is the decomposition of $A$ into its diagonal, strictly lower triangular, and strictly upper triangular parts.\n\nA more direct approach for the given matrix is to use a powerful theorem concerning convergence. The matrix $A(b)$ is real and symmetric. The diagonal entries are all $1$, which are positive. For such a matrix (symmetric with positive diagonal entries), the Ostrowski-Reich theorem states that the Gauss–Seidel method converges if and only if the matrix is positive definite.\n\nA symmetric matrix is positive definite if and only if all its eigenvalues are positive. We find the eigenvalues of $A(b)$ by solving the characteristic equation $\\det(A(b) - \\lambda I) = 0$.\n$$\n\\det\\begin{pmatrix} 1-\\lambda & b & 0 \\\\ b & 1-\\lambda & b \\\\ 0 & b & 1-\\lambda \\end{pmatrix} = 0\n$$\nExpanding the determinant along the first row:\n$$\n(1-\\lambda) \\begin{vmatrix} 1-\\lambda & b \\\\ b & 1-\\lambda \\end{vmatrix} - b \\begin{vmatrix} b & b \\\\ 0 & 1-\\lambda \\end{vmatrix} = 0\n$$\n$$\n(1-\\lambda) \\left( (1-\\lambda)^{2} - b^{2} \\right) - b \\left( b(1-\\lambda) \\right) = 0\n$$\n$$\n(1-\\lambda) \\left( (1-\\lambda)^{2} - 2b^{2} \\right) = 0\n$$\nThis equation gives the eigenvalues. One eigenvalue is $\\lambda_1 = 1$. The other two are found from $(1-\\lambda)^2 = 2b^2$, which gives $1-\\lambda = \\pm \\sqrt{2b^2} = \\pm b\\sqrt{2}$. Thus, the other eigenvalues are $\\lambda_2 = 1 - b\\sqrt{2}$ and $\\lambda_3 = 1 + b\\sqrt{2}$.\n\nFor $A(b)$ to be positive definite, all eigenvalues must be positive.\n$1$. $\\lambda_1 = 1$ is positive.\n$2$. Since $b > 0$, $\\lambda_3 = 1 + b\\sqrt{2}$ is always positive.\n$3$. We require $\\lambda_2 = 1 - b\\sqrt{2} > 0$. This implies $1 > b\\sqrt{2}$, or $b < \\frac{1}{\\sqrt{2}}$.\n\nSo, the Gauss–Seidel iteration converges if and only if $0 < b < \\frac{1}{\\sqrt{2}}$.\n\nWe must find the set of $b > 0$ that satisfies both conditions:\n$1$. $A(b)$ is not strictly diagonally dominant: $b \\geq \\frac{1}{2}$.\n$2$. The Gauss–Seidel iteration converges: $0 < b < \\frac{1}{\\sqrt{2}}$.\n\nThe intersection of these two sets is the interval $b \\in \\left[ \\frac{1}{2}, \\frac{1}{\\sqrt{2}} \\right)$. The smallest endpoint of this interval is $b_{\\text{min}} = \\frac{1}{2}$ and the largest endpoint is $b_{\\text{max}} = \\frac{1}{\\sqrt{2}}$.\n\nThe problem asks for the arithmetic mean of these endpoints:\n$$\n\\text{Mean} = \\frac{b_{\\text{min}} + b_{\\text{max}}}{2} = \\frac{\\frac{1}{2} + \\frac{1}{\\sqrt{2}}}{2} = \\frac{1}{2} \\left( \\frac{1}{2} + \\frac{\\sqrt{2}}{2} \\right) = \\frac{1+\\sqrt{2}}{4}\n$$\nFinally, we compute the numerical value and round it to four significant figures.\nUsing the approximation $\\sqrt{2} \\approx 1.41421356$, we have:\n$$\n\\text{Mean} = \\frac{1 + 1.41421356}{4} = \\frac{2.41421356}{4} = 0.60355339\\dots\n$$\nRounding to four significant figures, we get $0.6036$.", "answer": "$$\n\\boxed{0.6036}\n$$", "id": "2406953"}, {"introduction": "The final step in our practical exploration is to bridge theory and application by translating the algorithm into code. In this exercise, you will implement the Gauss–Seidel iteration and apply it to matrices with different mathematical properties, including one that is symmetric positive-definite and one that is not [@problem_id:2396644]. By observing the behavior of the residuals, you will gain tangible, computational proof of the convergence theories discussed earlier, watching the method succeed for well-behaved systems and demonstrably fail for others.", "problem": "You are given square linear systems of the form $A x = b$ with real symmetric matrices $A \\in \\mathbb{R}^{n \\times n}$ and vectors $b \\in \\mathbb{R}^{n}$. Consider the Gauss–Seidel fixed-point iteration defined by the splitting $A = D + L + U$, where $D$ is the diagonal of $A$, $L$ is the strict lower-triangular part of $A$, and $U$ is the strict upper-triangular part of $A$. The iteration is\n$$\nx^{(k+1)} = -(D+L)^{-1} U \\, x^{(k)} + (D+L)^{-1} b,\n$$\nstarting from the initial iterate $x^{(0)} = 0$ (the zero vector). For each case below, generate the iterates and the residuals $r^{(k)} = b - A x^{(k)}$.\n\nDefine a quantitative divergence criterion as follows. Fix an iteration cap $K$ and a growth factor $\\alpha > 1$. Compute the Euclidean norm $\\|r^{(k)}\\|_2$ at each iteration $k = 0, 1, \\dots, K$. Declare that the iteration diverges if there exists any $k \\in \\{0,1,\\dots,K\\}$ such that $\\|r^{(k)}\\|_2 > \\alpha \\, \\|r^{(0)}\\|_2$; otherwise, declare that it does not diverge. In all cases below, use $K = 25$ and $\\alpha = 10^{6}$.\n\nTest suite:\n- Case $1$ (symmetric positive-definite reference case): $A_1 = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $b_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$, $n = 2$.\n- Case $2$ (symmetric but not positive-definite, designed to diverge): $A_2 = \\begin{bmatrix} 2 & 3 \\\\ 3 & 2 \\end{bmatrix}$, $b_2 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, $n = 2$.\n- Case $3$ (symmetric positive semidefinite, singular): $A_3 = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$, $b_3 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$, $n = 2$.\n\nRequired output for each case: a boolean indicating whether the iteration diverges according to the criterion above.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). For the test suite above, the output line must be of the form \"[r1,r2,r3]\" where each $r_i$ is the boolean result for Case $i$ in order.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of numerical linear algebra, well-posed with all necessary parameters defined, and formulated with objective, unambiguous language. We shall proceed with the solution.\n\nThe problem requires the implementation and analysis of the Gauss–Seidel iteration for three distinct linear systems of the form $A x = b$. For each system, we must determine if the iteration diverges according to a specified quantitative criterion. The core of this analysis rests on the iterative formula and the properties of the matrix $A$.\n\nThe Gauss–Seidel method is a fixed-point iteration for solving a linear system. Given a splitting of the matrix $A$ into its diagonal ($D$), strict lower-triangular ($L$), and strict upper-triangular ($U$) parts, such that $A = D + L + U$, the iteration is defined as:\n$$\nx^{(k+1)} = T_{GS} x^{(k)} + c_{GS}\n$$\nwhere the iteration matrix is $T_{GS} = -(D+L)^{-1}U$ and the constant vector is $c_{GS} = (D+L)^{-1}b$. The process starts with an initial guess, specified here as $x^{(0)} = 0$.\n\nFor computational purposes, it is more efficient to write the iteration in its component-wise form. For the $i$-th component of the vector $x^{(k+1)}$, the update rule is:\n$$\nx_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)\n$$\nThis formula highlights that the computation of $x_i^{(k+1)}$ utilizes the most recently updated components $x_j^{(k+1)}$ for $j < i$. This procedure is well-defined provided that all diagonal elements $a_{ii}$ are non-zero, which is true for all cases presented.\n\nThe problem defines divergence based on the behavior of the Euclidean norm of the residual vector, $r^{(k)} = b - A x^{(k)}$. The initial residual is $r^{(0)} = b - A x^{(0)} = b$. The iteration is declared to diverge if, for any iteration count $k$ within the cap $K=25$, the residual norm grows excessively:\n$$\n\\|r^{(k)}\\|_2 > \\alpha \\|r^{(0)}\\|_2\n$$\nwhere the growth factor is $\\alpha = 10^6$. If this condition is not met for any $k \\in \\{0, 1, \\dots, K\\}$, the process is considered not to have diverged. Note that for $k=0$, the condition $\\|r^{(0)}\\|_2 > \\alpha \\|r^{(0)}\\|_2$ is equivalent to $1 > \\alpha$, which is false for $\\alpha = 10^6$. Thus, we need only check for $k \\in \\{1, 2, \\dots, K\\}$.\n\nWe now analyze each case:\n\nCase $1$: $A_1 = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $b_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$.\nThe matrix $A_1$ is symmetric. Its eigenvalues are the roots of $(\\lambda-4)(\\lambda-3) - 1 = 0$, which are $\\lambda = \\frac{7 \\pm \\sqrt{5}}{2}$. Both eigenvalues are positive, so $A_1$ is symmetric positive-definite (SPD). A fundamental theorem of numerical linear algebra states that the Gauss–Seidel method is guaranteed to converge for any SPD matrix. Therefore, the residual norm $\\|r^{(k)}\\|_2$ is expected to decrease towards zero. The divergence criterion will not be met.\n\nCase $2$: $A_2 = \\begin{bmatrix} 2 & 3 \\\\ 3 & 2 \\end{bmatrix}$, $b_2 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\nThe matrix $A_2$ is symmetric. Its eigenvalues are the roots of $(\\lambda-2)^2 - 9 = 0$, which are $\\lambda = 5$ and $\\lambda = -1$. Since one eigenvalue is negative, the matrix is indefinite, not positive-definite. Convergence is not guaranteed. We must examine the spectral radius of the iteration matrix $T_{GS} = -(D_2+L_2)^{-1}U_2$.\nHere, $D_2+L_2 = \\begin{bmatrix} 2 & 0 \\\\ 3 & 2 \\end{bmatrix}$ and $U_2 = \\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix}$.\nThe inverse is $(D_2+L_2)^{-1} = \\begin{bmatrix} 1/2 & 0 \\\\ -3/4 & 1/2 \\end{bmatrix}$.\nSo, $T_{GS} = -\\begin{bmatrix} 1/2 & 0 \\\\ -3/4 & 1/2 \\end{bmatrix}\\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & -3/2 \\\\ 0 & 9/4 \\end{bmatrix}$.\nThe eigenvalues of this upper-triangular matrix are its diagonal entries, $0$ and $9/4$. The spectral radius is $\\rho(T_{GS}) = \\max(|0|, |9/4|) = 9/4 = 2.25$. Since $\\rho(T_{GS}) > 1$, the iteration is guaranteed to diverge for almost all initial vectors. The residual norm is expected to grow, and the divergence criterion will be met.\n\nCase $3$: $A_3 = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$, $b_3 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$.\nThe matrix $A_3$ is symmetric. Its eigenvalues are the roots of $(\\lambda-1)^2 - 1 = 0$, which are $\\lambda=0$ and $\\lambda=2$. Since one eigenvalue is zero, the matrix is symmetric positive semi-definite and singular. The vector $b_3$ is in the column space of $A_3$, as $A_3 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = b_3$, so the system $A_3x = b_3$ is consistent and has infinitely many solutions.\nWe analyze the iteration matrix $T_{GS} = -(D_3+L_3)^{-1}U_3$.\nHere, $D_3+L_3 = \\begin{bmatrix} 1 & 0 \\\\ -1 & 1 \\end{bmatrix}$ and $U_3 = \\begin{bmatrix} 0 & -1 \\\\ 0 & 0 \\end{bmatrix}$.\nThe inverse is $(D_3+L_3)^{-1} = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}$.\nSo, $T_{GS} = -\\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}\\begin{bmatrix} 0 & -1 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 0 & 1 \\end{bmatrix}$.\nThe eigenvalues are $0$ and $1$. The spectral radius is $\\rho(T_{GS}) = 1$. When the spectral radius is exactly $1$, convergence behavior is subtle. We must perform the iteration:\n$x^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\nThe update equations are $x_1^{(k+1)} = 1 - (-1)x_2^{(k)} = 1 + x_2^{(k)}$ and $x_2^{(k+1)} = -1 - (-1)x_1^{(k+1)} = -1 + x_1^{(k+1)}$.\nFor $k=0$:\n$x_1^{(1)} = 1 + x_2^{(0)} = 1 + 0 = 1$.\n$x_2^{(1)} = -1 + x_1^{(1)} = -1 + 1 = 0$.\nSo, $x^{(1)} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\nThe residual is $r^{(1)} = b_3 - A_3 x^{(1)} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} - \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\nThe method converges to an exact solution in a single step. The residual norm falls to $0$. All subsequent residuals will also be zero. The divergence criterion will not be met.\n\nThe implementation will follow this analysis, executing the iteration for $K=25$ steps and checking the residual norm at each step against the divergence threshold.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef check_gauss_seidel_divergence(A: np.ndarray, b: np.ndarray, K: int, alpha: float) -> bool:\n    \"\"\"\n    Performs Gauss-Seidel iteration and checks for divergence based on the problem's criterion.\n\n    Args:\n        A: The square matrix of the linear system.\n        b: The right-hand side vector.\n        K: The iteration cap.\n        alpha: The divergence growth factor.\n\n    Returns:\n        A boolean indicating whether the iteration diverges (True) or not (False).\n    \"\"\"\n    n = A.shape[0]\n    x = np.zeros(n)  # Initial iterate x^(0)\n\n    # Calculate initial residual r^(0) and its norm.\n    # r^(0) = b - A*x^(0) = b since x^(0) is the zero vector.\n    r0 = b\n    norm_r0 = np.linalg.norm(r0)\n\n    # Edge case: if b is the zero vector, then x=0 is the exact solution.\n    # The initial residual norm is 0. The criterion ||r^(k)||_2 > alpha*0 becomes ||r^(k)||_2 > 0.\n    # Since all residuals will be zero, this condition is never met.\n    if norm_r0 == 0:\n        return False\n\n    divergence_threshold = alpha * norm_r0\n\n    # The problem specifies checking k in {0, 1, ..., K}.\n    # The check for k=0: ||r^(0)||_2 > alpha * ||r^(0)||_2, is never true for alpha > 1.\n    # Thus, we only need to check for k = 1, ..., K by iterating K times.\n    \n    # Iterate K times to generate x^(1) through x^(K).\n    for _ in range(K):\n        x_new = np.copy(x)\n        for i in range(n):\n            # Sum for terms with already updated x_new components for j < i\n            sum1 = np.dot(A[i, :i], x_new[:i])\n            # Sum for terms with old x components for j > i\n            sum2 = np.dot(A[i, i + 1:], x[i + 1:])\n            \n            # The component-wise update. The problem cases ensure A[i, i] != 0.\n            x_new[i] = (b[i] - sum1 - sum2) / A[i, i]\n        \n        x = x_new  # Update x for the next iteration\n\n        # Calculate the residual r^(k) and its norm for the current iterate x.\n        r_k = b - A @ x\n        norm_r_k = np.linalg.norm(r_k)\n        \n        # Check against the divergence criterion.\n        if norm_r_k > divergence_threshold:\n            return True\n\n    # If the loop completes without meeting the criterion, it has not diverged.\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the divergence check.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (symmetric positive-definite)\n        (np.array([[4., 1.], [1., 3.]]), np.array([1., 2.])),\n        \n        # Case 2 (symmetric, not positive-definite)\n        (np.array([[2., 3.], [3., 2.]]), np.array([1., 1.])),\n        \n        # Case 3 (symmetric positive semidefinite, singular)\n        (np.array([[1., -1.], [-1., 1.]]), np.array([1., -1.]))\n    ]\n    \n    K = 25\n    alpha = 1e6\n\n    results = []\n    for A, b in test_cases:\n        diverged = check_gauss_seidel_divergence(A, b, K, alpha)\n        results.append(diverged)\n\n    # Final print statement in the exact required format.\n    # str(True) -> 'True', str(False) -> 'False'\n    print(f\"[{','.join(map(str, results)).lower()}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2396644"}]}