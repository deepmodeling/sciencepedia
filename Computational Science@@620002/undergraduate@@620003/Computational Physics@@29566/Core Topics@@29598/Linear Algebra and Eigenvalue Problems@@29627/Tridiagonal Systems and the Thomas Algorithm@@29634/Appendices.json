{"hands_on_practices": [{"introduction": "The Thomas algorithm is a two-stage process: forward elimination and backward substitution. To master the algorithm, it's helpful to practice each stage in isolation. This first exercise [@problem_id:2222856] zeros in on the second stage, backward substitution, by providing you with a system that has already undergone the forward elimination pass. Your task is to take the resulting upper bidiagonal system and efficiently reconstruct the final solution vector, giving you hands-on experience with the mechanics of the backward pass.", "problem": "In computational physics, discretizing differential equations often leads to large systems of linear equations. For example, modeling one-dimensional steady-state heat conduction in a rod can result in a tridiagonal system of the form $A\\mathbf{x} = \\mathbf{d}$, where $\\mathbf{x}$ represents the temperatures at discrete points along the rod.\n\nSuppose such a $5 \\times 5$ system has been pre-processed using the forward elimination stage of the Thomas algorithm. This operation transforms the original system into an equivalent upper bidiagonal system $U\\mathbf{x} = \\mathbf{y}$ of the form:\n$$\n\\begin{pmatrix}\n1 & c'_{1} & 0 & 0 & 0 \\\\\n0 & 1 & c'_{2} & 0 & 0 \\\\\n0 & 0 & 1 & c'_{3} & 0 \\\\\n0 & 0 & 0 & 1 & c'_{4} \\\\\n0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5\n\\end{pmatrix}\n=\n\\begin{pmatrix}\ny_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5\n\\end{pmatrix}\n$$\nThe non-zero off-diagonal coefficients of the matrix $U$ are given as:\n$c'_{1} = -0.5$\n$c'_{2} = 0.25$\n$c'_{3} = -0.2$\n$c'_{4} = 0.5$\n\nThe elements of the transformed right-hand side vector $\\mathbf{y}$ are:\n$y_1 = 3.0$\n$y_2 = -1.0$\n$y_3 = 5.0$\n$y_4 = 2.0$\n$y_5 = 8.0$\n\nYour task is to complete the solution process by performing the backward substitution pass to find the unknown vector $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)^T$. Calculate the value of the first component, $x_1$. Round your final answer to four significant figures.", "solution": "The backward substitution for an upper bidiagonal system with unit diagonal proceeds from the last equation upward. For the given system, the equations are:\n$$x_{5} = y_{5},$$\n$$x_{4} + c'_{4} x_{5} = y_{4} \\implies x_{4} = y_{4} - c'_{4} x_{5},$$\n$$x_{3} + c'_{3} x_{4} = y_{3} \\implies x_{3} = y_{3} - c'_{3} x_{4},$$\n$$x_{2} + c'_{2} x_{3} = y_{2} \\implies x_{2} = y_{2} - c'_{2} x_{3},$$\n$$x_{1} + c'_{1} x_{2} = y_{1} \\implies x_{1} = y_{1} - c'_{1} x_{2}.$$\n\nSubstituting the given values:\n$$x_{5} = 8.0,$$\n$$x_{4} = 2.0 - (0.5)(8.0) = 2.0 - 4.0 = -2.0,$$\n$$x_{3} = 5.0 - (-0.2)(-2.0) = 5.0 - 0.4 = 4.6,$$\n$$x_{2} = -1.0 - (0.25)(4.6) = -1.0 - 1.15 = -2.15,$$\n$$x_{1} = 3.0 - (-0.5)(-2.15) = 3.0 - 1.075 = 1.925.$$\n\nRounding $x_{1}$ to four significant figures gives $1.925$.", "answer": "$$\\boxed{1.925}$$", "id": "2222856"}, {"introduction": "Why is the Thomas algorithm so important in computational physics? This practice problem [@problem_id:2222858] answers that question by connecting the algorithm to a tangible physical model: steady-state heat flow in a metal rod. You will start with a differential equation describing the temperature distribution, apply the finite difference method to discretize it, and arrive at the characteristic tridiagonal system of linear equations. Solving this system reveals the temperature profile, demonstrating the end-to-end workflow from a physical problem to a numerical solution.", "problem": "Consider a thin, uniform metal rod of length $L = 0.500 \\text{ m}$. The rod's thermal conductivity is constant at $k = 200. \\text{ W/(m}\\cdot\\text{K)}$. The two ends of the rod are maintained at fixed temperatures: the temperature at $x=0$ is $T_A = 100. \\text{ °C}$, and the temperature at $x=L$ is $T_B = 50.0 \\text{ °C}$. The rod is subjected to an internal heat source that varies linearly along its length, described by the function $Q(x) = \\beta x$, where $\\beta = 8.00 \\times 10^4 \\text{ W/m}^4$. The steady-state temperature distribution $T(x)$ along the rod is governed by the one-dimensional heat equation:\n$$ k \\frac{d^2T}{dx^2} + Q(x) = 0 $$\nTo find an approximate numerical solution, the domain from $x=0$ to $x=L$ is discretized by defining 4 equally spaced internal points, $x_1, x_2, x_3, x_4$. These points, along with the endpoints $x_0=0$ and $x_5=L$, divide the rod into 5 equal segments. The second derivative in the heat equation is to be approximated using the centered finite difference formula:\n$$ \\frac{d^2T}{dx^2}\\bigg|_{x_i} \\approx \\frac{T_{i-1} - 2T_i + T_{i+1}}{\\Delta x^2} $$\nwhere $T_i$ represents the temperature $T(x_i)$ and $\\Delta x$ is the spacing between adjacent points.\n\nBy discretizing the governing differential equation, a system of linear algebraic equations for the unknown internal temperatures ($T_1, T_2, T_3, T_4$) is obtained. Calculate the temperature at the point $x_3$, which is located at three-fifths of the rod's length from the end at $x=0$.\n\nExpress your answer in degrees Celsius, rounded to three significant figures.", "solution": "The steady-state one-dimensional heat equation with a spatially varying internal heat source is\n$$\nk\\,\\frac{d^{2}T}{dx^{2}}+Q(x)=0,\n$$\nwith $Q(x)=\\beta x$. Discretizing the interval $[0,L]$ into 5 equal segments defines nodes $x_{i}=i\\,\\Delta x$ for $i=0,1,2,3,4,5$, where $\\Delta x=L/5$. Approximating the second derivative at internal nodes by the centered finite difference gives, for $i=1,2,3,4$,\n$$\nk\\,\\frac{T_{i-1}-2T_{i}+T_{i+1}}{\\Delta x^2}+Q(x_{i})=0.\n$$\nDefine $a=\\frac{k}{\\Delta x^2}$ and use $Q(x_{i})=\\beta x_{i}=\\beta i\\,\\Delta x$. With boundary conditions $T_{0}=T_{A}$ and $T_{5}=T_{B}$, the linear equations for the internal temperatures are\n$$\na\\,T_{i-1}-2a\\,T_{i}+a\\,T_{i+1}=-Q(x_{i}),\\quad i=1,2,3,4,\n$$\nwith $T_{0}$ and $T_{5}$ known.\n\nInsert the given data: $L=0.500$, $k=200$, $\\beta=8.00\\times 10^{4}$, $T_{A}=100$, $T_{B}=50.0$. Then\n$$\n\\Delta x=\\frac{L}{5}=0.100,\\qquad a=\\frac{k}{\\Delta x^2}=\\frac{200}{(0.100)^{2}}=20000,\n$$\nand\n$$\nQ(x_{i})=\\beta i\\,\\Delta x=(8.00\\times 10^{4})\\,i\\,(0.100)=8000\\,i.\n$$\nDivide each equation by $a$ to simplify:\n- For $i=1$: $T_{0}-2T_{1}+T_{2}=-\\frac{Q(x_{1})}{a}=-\\frac{8000}{20000}=-0.4$, hence $-2T_{1}+T_{2}=-100.4$.\n- For $i=2$: $T_{1}-2T_{2}+T_{3}=-\\frac{16000}{20000}=-0.8$.\n- For $i=3$: $T_{2}-2T_{3}+T_{4}=-\\frac{24000}{20000}=-1.2$.\n- For $i=4$: $T_{3}-2T_{4}+T_{5}=-\\frac{32000}{20000}=-1.6$, hence $T_{3}-2T_{4}=-1.6-T_{5}=-51.6$.\n\nThus the system is\n$$\n\\begin{aligned}\n-2T_{1}+T_{2}&=-100.4,\\\\\nT_{1}-2T_{2}+T_{3}&=-0.8,\\\\\nT_{2}-2T_{3}+T_{4}&=-1.2,\\\\\nT_{3}-2T_{4}&=-51.6.\n\\end{aligned}\n$$\nSolve sequentially from the last equation:\n$T_{3}=-51.6+2T_{4}$.\nSubstitute into the third equation to express $T_{2}$ in terms of $T_{4}$:\n$T_{2}-2(-51.6+2T_{4})+T_{4}=-1.2\\;\\Rightarrow\\;T_{2}=-104.4+3T_{4}$.\nSubstitute $T_{2}$ and $T_{3}$ into the second equation to express $T_{1}$:\n$T_{1}-2(-104.4+3T_{4})+(-51.6+2T_{4})=-0.8\\;\\Rightarrow\\;T_{1}=-158.0+4T_{4}$.\nInsert $T_{1}$ and $T_{2}$ into the first equation to solve for $T_{4}$:\n$-2(-158.0+4T_{4})+(-104.4+3T_{4})=-100.4$\nwhich simplifies to\n$211.6-5T_{4}=-100.4$\nso\n$-5T_{4}=-312.0\\;\\Rightarrow\\;T_{4}=62.4.$\nThen\n$$T_{3}=-51.6+2(62.4)=73.2.$$\nTherefore, the temperature at $x_{3}$ (three-fifths of the rod length from $x=0$) is $73.2$ degrees Celsius, already at three significant figures as required.", "answer": "$$\\boxed{73.2}$$", "id": "2222858"}, {"introduction": "Once you've mastered a numerical tool like the Thomas algorithm, you can use it as a building block to solve more complex problems. This advanced practice [@problem_id:2447589] challenges you to solve the system $A^2 x = b$ where $A$ is a tridiagonal matrix. A brute-force approach would involve computing the pentadiagonal matrix $A^2$, but a far more elegant and efficient strategy exists. By cleverly decomposing the problem, you can solve it by applying your tridiagonal solver twice in succession, illustrating a powerful problem-solving pattern in computational science.", "problem": "Consider the linear system $A^2 x = b$ where $A \\in \\mathbb{R}^{n \\times n}$ is tridiagonal with strictly subdiagonal entries $a_i$ for $i = 2,\\dots,n$, diagonal entries $d_i$ for $i = 1,\\dots,n$, and strictly superdiagonal entries $c_i$ for $i = 1,\\dots,n-1$. Assume that $A$ is nonsingular and that all computations are performed in double precision floating point arithmetic. Your task is to derive, from the associativity of matrix multiplication and the uniqueness of solutions for nonsingular linear systems, a method to solve $A^2 x = b$ using only operations involving $A$ without ever forming the pentadiagonal matrix $A^2$. Then, implement this method in a program that uses a tridiagonal solver based on Gaussian elimination specialized to tridiagonal matrices. You must not form $A^2$ explicitly at any point.\n\nAs a measure of correctness, for each test case specified below, compute the infinity norm of the residual constructed without $A^2$ as $r = b - A(Ax)$ using only applications of the tridiagonal matrix $A$. Specifically, compute $y = A x$, then $z = A y$, and the residual $r = b - z$, and finally report $\\lVert r \\rVert_{\\infty} = \\max_i |r_i|$.\n\nImplement a function that solves tridiagonal systems robustly for nonsingular inputs, and apply it as needed by your method. Your implementation must be general and work for any valid tridiagonal input data of the sizes given.\n\nTest suite:\n- Test case $1$ (symmetric positive definite, uniform coefficients): $n = 6$, $a = (-1,-1,-1,-1,-1)$, $d = (2,2,2,2,2,2)$, $c = (-1,-1,-1,-1,-1)$, $b = (1,2,3,4,5,6)$.\n- Test case $2$ (nonsymmetric, strictly diagonally dominant): $n = 7$, $a = (-1,-1,-1,-1,-1,-1)$, $d = (3,3,3,3,3,3,3)$, $c = (2,2,2,2,2,2)$, $b = (1,-1,1,-1,1,-1,1)$.\n- Test case $3$ (scalar edge case): $n = 1$, $a = ()$, $d = (5)$, $c = ()$, $b = (3)$.\n- Test case $4$ (weak diagonal dominance, symmetric positive definite): $n = 10$, $a = (-1,-1,-1,-1,-1,-1,-1,-1,-1)$, $d = (2.001,2.001,2.001,2.001,2.001,2.001,2.001,2.001,2.001,2.001)$, $c = (-1,-1,-1,-1,-1,-1,-1,-1,-1)$, $b = (1,1,1,1,1,1,1,1,1,1)$.\n\nAll numbers in the vectors above are unitless scalars. Angles are not used. Percentages are not used.\n\nFinal output format: Your program should produce a single line of output containing the results for the four test cases, in order, as a comma-separated list of floating-point numbers enclosed in square brackets, for example $[r_1,r_2,r_3,r_4]$, where each $r_i$ is the infinity norm of the residual defined above for test case $i$.", "solution": "The problem requires solving the linear system $A^2 x = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is a given nonsingular tridiagonal matrix, without explicitly computing the matrix $A^2$. The solution must be derived from fundamental principles of linear algebra and implemented using a specialized solver for tridiagonal systems.\n\nThe validation of the problem statement confirms its scientific and mathematical soundness. It is a well-posed problem in numerical linear algebra with complete and consistent data, requiring a standard, verifiable computational method. All provided test cases involve matrices for which the proposed algorithm is numerically stable.\n\n**Derivation of the Method**\n\nThe core of the method lies in the associativity of matrix multiplication. The equation to be solved is:\n$$A^2 x = b$$\nBy the associative property, we can group the multiplication as:\n$$A(Ax) = b$$\nThis structure suggests a decomposition of the problem into a sequence of two simpler problems. We introduce an intermediate vector $y \\in \\mathbb{R}^n$ defined as:\n$$y = Ax$$\nSubstituting this definition into the previous equation yields the first linear system:\n$$Ay = b$$\nSince the matrix $A$ is given to be nonsingular, a unique solution $y$ for this system exists. Once $y$ is determined, we can find the final solution $x$ by solving the second linear system, which is our initial definition of $y$:\n$$Ax = y$$\nAgain, the nonsingularity of $A$ guarantees a unique solution for $x$.\n\nThis two-step procedure correctly solves the original problem while adhering to the critical constraint of not forming the matrix $A^2$. The method consists of two sequential solves of linear systems involving the same tridiagonal matrix $A$:\n$1$. Solve $Ay = b$ to find the intermediate vector $y$.\n$2$. Solve $Ax = y$ to find the final solution vector $x$.\n\n**Algorithmic Implementation: The Thomas Algorithm**\n\nTo solve the tridiagonal systems $Ay=b$ and $Ax=y$, we employ the Thomas algorithm, also known as the Tridiagonal Matrix Algorithm (TDMA). This algorithm is a highly efficient form of Gaussian elimination specialized for tridiagonal matrices, with a computational complexity of $O(n)$, which is vastly superior to the $O(n^3)$ complexity of general Gaussian elimination.\n\nA tridiagonal system is defined by the matrix $A$ with a lower diagonal (subdiagonal) vector $a = (a_2, \\dots, a_n)$, a main diagonal vector $d = (d_1, \\dots, d_n)$, and an upper diagonal (superdiagonal) vector $c = (c_1, \\dots, c_{n-1})$. The $i$-th equation of the system $Af = g$ is:\n$$a_i f_{i-1} + d_i f_i + c_i f_{i+1} = g_i$$\nwhere, by convention, $a_1 = 0$ and $c_n = 0$.\n\nThe Thomas algorithm consists of two stages:\n\n$1$. **Forward Elimination**: The algorithm transforms the system into an equivalent upper bidiagonal system by eliminating the subdiagonal elements. This is achieved by modifying the coefficients of the main diagonal $d_i$ and the right-hand side vector $g_i$. The procedure involves computing a new set of coefficients, let us say $c'_i$ and $g'_i$:\nFor $i=1$:\n$$c'_1 = \\frac{c_1}{d_1}$$\n$$g'_1 = \\frac{g_1}{d_1}$$\nFor $i = 2, 3, \\dots, n-1$:\n$$m_i = d_i - a_i c'_{i-1}$$\n$$c'_i = \\frac{c_i}{m_i}$$\n$$g'_i = \\frac{g_i - a_i g'_{i-1}}{m_i}$$\nAnd for the last row, $i=n$:\n$$m_n = d_n - a_n c'_{n-1}$$\n$$g'_n = \\frac{g_n - a_n g'_{n-1}}{m_n}$$\nThis process is numerically stable without pivoting for matrices that are strictly or irreducibly diagonally dominant, or symmetric and positive definite, which is true for all test cases provided.\n\n$2$. **Backward Substitution**: After the forward elimination, the system has an upper bidiagonal form, which can be solved easily for the unknown vector $f$ by starting from the last equation and moving backward:\n$$f_n = g'_n$$\nFor $i = n-1, n-2, \\dots, 1$:\n$$f_i = g'_i - c'_i f_{i+1}$$\n\n**Verification of the Solution**\n\nTo assess the correctness of the computed solution $x$, we calculate the infinity norm of the residual vector, $r = b - A^2x$. As stipulated, $A^2$ is not formed. The term $A^2x$ is computed as $A(Ax)$.\nThe procedure is as follows:\n$1$. Compute the vector $y_{check} = Ax$. This is a matrix-vector multiplication involving the tridiagonal matrix $A$ and the computed solution $x$.\n$2$. Compute the vector $z_{check} = Ay_{check}$. This is a second application of the matrix $A$ to the result of the first multiplication.\n$3$. Compute the residual vector $r = b - z_{check}$.\n$4$. Compute the infinity norm of the residual, $\\lVert r \\rVert_{\\infty} = \\max_{i} |r_i|$. A small residual norm indicates that the computed solution $x$ is accurate.\n\nThis comprehensive approach solves the problem efficiently and robustly, satisfying all specified constraints. The total computational cost is dominated by the two applications of the Thomas algorithm, leading to an overall complexity of $O(n)$.", "answer": "```python\nimport numpy as np\n\ndef thomas_solver(a_sub, d_diag, c_super, b_rhs):\n    \"\"\"\n    Solves a tridiagonal system of linear equations Ax=b using the Thomas algorithm.\n\n    Args:\n        a_sub (np.ndarray): The sub-diagonal (length n-1).\n        d_diag (np.ndarray): The main diagonal (length n).\n        c_super (np.ndarray): The super-diagonal (length n-1).\n        b_rhs (np.ndarray): The right-hand side vector (length n).\n\n    Returns:\n        np.ndarray: The solution vector x (length n).\n    \"\"\"\n    n = len(d_diag)\n    if n == 0:\n        return np.array([])\n    if n == 1:\n        return np.array([b_rhs[0] / d_diag[0]])\n\n    # Create copies to avoid modifying input arrays\n    c_prime = np.zeros(n - 1)\n    b_prime = np.zeros(n)\n\n    # Forward elimination phase\n    c_prime[0] = c_super[0] / d_diag[0]\n    b_prime[0] = b_rhs[0] / d_diag[0]\n\n    for i in range(1, n - 1):\n        m = d_diag[i] - a_sub[i-1] * c_prime[i-1]\n        c_prime[i] = c_super[i] / m\n        b_prime[i] = (b_rhs[i] - a_sub[i-1] * b_prime[i-1]) / m\n        \n    m_last = d_diag[n-1] - a_sub[n-2] * c_prime[n-2]\n    b_prime[n-1] = (b_rhs[n-1] - a_sub[n-2] * b_prime[n-2]) / m_last\n\n    # Backward substitution phase\n    x = np.zeros(n)\n    x[n-1] = b_prime[n-1]\n    for i in range(n - 2, -1, -1):\n        x[i] = b_prime[i] - c_prime[i] * x[i+1]\n\n    return x\n\ndef matvec_tridiagonal(a_sub, d_diag, c_super, v):\n    \"\"\"\n    Computes the matrix-vector product Ax for a tridiagonal matrix A.\n\n    Args:\n        a_sub (np.ndarray): The sub-diagonal (length n-1).\n        d_diag (np.ndarray): The main diagonal (length n).\n        c_super (np.ndarray): The super-diagonal (length n-1).\n        v (np.ndarray): The vector to multiply with (length n).\n\n    Returns:\n        np.ndarray: The resulting vector Ax (length n).\n    \"\"\"\n    n = len(d_diag)\n    if n == 0:\n        return np.array([])\n    if n == 1:\n        return np.array([d_diag[0] * v[0]])\n\n    res = np.zeros(n)\n    \n    # First row\n    res[0] = d_diag[0] * v[0] + c_super[0] * v[1]\n    \n    # Middle rows\n    for i in range(1, n - 1):\n        res[i] = a_sub[i-1] * v[i-1] + d_diag[i] * v[i] + c_super[i] * v[i+1]\n        \n    # Last row\n    res[n-1] = a_sub[n-2] * v[n-2] + d_diag[n-1] * v[n-1]\n    \n    return res\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, solve them, and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"n\": 6,\n            \"a\": np.array([-1, -1, -1, -1, -1], dtype=np.float64),\n            \"d\": np.array([2, 2, 2, 2, 2, 2], dtype=np.float64),\n            \"c\": np.array([-1, -1, -1, -1, -1], dtype=np.float64),\n            \"b\": np.array([1, 2, 3, 4, 5, 6], dtype=np.float64)\n        },\n        {\n            \"n\": 7,\n            \"a\": np.array([-1, -1, -1, -1, -1, -1], dtype=np.float64),\n            \"d\": np.array([3, 3, 3, 3, 3, 3, 3], dtype=np.float64),\n            \"c\": np.array([2, 2, 2, 2, 2, 2], dtype=np.float64),\n            \"b\": np.array([1, -1, 1, -1, 1, -1, 1], dtype=np.float64)\n        },\n        {\n            \"n\": 1,\n            \"a\": np.array([], dtype=np.float64),\n            \"d\": np.array([5], dtype=np.float64),\n            \"c\": np.array([], dtype=np.float64),\n            \"b\": np.array([3], dtype=np.float64)\n        },\n        {\n            \"n\": 10,\n            \"a\": np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=np.float64),\n            \"d\": np.array([2.001] * 10, dtype=np.float64),\n            \"c\": np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=np.float64),\n            \"b\": np.array([1] * 10, dtype=np.float64)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        a, d, c, b = case[\"a\"], case[\"d\"], case[\"c\"], case[\"b\"]\n        \n        # Step 1: Solve Ay = b for y\n        y = thomas_solver(a, d, c, b)\n        \n        # Step 2: Solve Ax = y for x\n        x = thomas_solver(a, d, c, y)\n        \n        # Verification: compute norm of residual r = b - A(Ax)\n        y_check = matvec_tridiagonal(a, d, c, x)\n        z_check = matvec_tridiagonal(a, d, c, y_check)\n        residual = b - z_check\n        residual_norm = np.linalg.norm(residual, ord=np.inf)\n        \n        results.append(residual_norm)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2447589"}]}