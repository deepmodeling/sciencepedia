{"hands_on_practices": [{"introduction": "Solving the Schrödinger equation for bound states is a cornerstone of quantum mechanics. This exercise demonstrates how to transform a linear, second-order boundary value problem into a matrix eigenvalue problem using the finite difference method [@problem_id:2377652]. This powerful technique allows you to numerically approximate the quantized energy levels and corresponding wavefunctions for one of the most fundamental systems in physics, the quantum harmonic oscillator.", "problem": "Consider the one-dimensional stationary Schrödinger boundary value problem for the quantum harmonic oscillator with potential $V(x) = \\tfrac{1}{2} m \\omega^{2} x^{2}$:\n$$\n-\\frac{\\hbar^{2}}{2 m}\\,\\frac{d^{2}\\psi}{dx^{2}} + \\frac{1}{2} m \\omega^{2} x^{2}\\,\\psi(x) = E\\,\\psi(x),\n$$\nwith the bound-state condition that $\\psi(x) \\to 0$ as $x \\to \\pm \\infty$. To render this into a computational boundary value problem on a finite interval, truncate the domain to $x \\in [-L,L]$ and impose homogeneous Dirichlet boundary conditions $\\psi(-L)=\\psi(L)=0$. Using a uniform grid of $N$ interior points on $[-L,L]$, discretize the second derivative by a symmetric second-order finite difference and construct the corresponding symmetric matrix representation of the Hamiltonian operator. Then, compute the lowest $K$ energy eigenvalues and compare them to the known exact harmonic-oscillator spectrum $E_n^{(\\mathrm{exact})} = \\hbar \\omega \\left(n + \\tfrac{1}{2}\\right)$ for $n \\in \\{0,1,\\dots\\}$.\n\nYour program must:\n- Start from the time-independent Schrödinger equation and enforce the boundary conditions at $x=\\pm L$.\n- Use a uniform grid with $N$ interior points and a symmetric second-order finite difference to approximate the second derivative operator on the interior.\n- Assemble the discrete Hamiltonian matrix as the sum of the discrete kinetic-energy operator and the diagonal potential-energy operator evaluated at the grid points.\n- Compute the lowest $K$ eigenvalues of this matrix.\n- For each test case, form the maximum absolute relative error across the first $K$ levels:\n$$\n\\varepsilon_{\\max} = \\max_{0 \\le n < K} \\left| \\frac{E_n^{(\\mathrm{num})} - E_n^{(\\mathrm{exact})}}{E_n^{(\\mathrm{exact})}} \\right|.\n$$\nAll errors are to be reported as dimensionless decimal numbers (no physical units are required for the final reported values).\n\nTest suite:\n- Case $1$: $(\\hbar, m, \\omega, L, N, K) = (1, 1, 1, 8, 300, 6)$\n- Case $2$: $(\\hbar, m, \\omega, L, N, K) = (1, 1, 1, 6, 60, 4)$\n- Case $3$: $(\\hbar, m, \\omega, L, N, K) = (1, 1, 2.3, 8, 300, 5)$\n- Case $4$: $(\\hbar, m, \\omega, L, N, K) = (1, 1, 1, 3, 300, 4)$\n\nNotes and constraints:\n- You must treat $N$ as the number of interior grid points (so the total number of points including boundaries is $N+2$), and use homogeneous Dirichlet values at $x=\\pm L$.\n- Use real arithmetic in double precision for numerical stability.\n- Angles are not involved; no angle units are required.\n- The final answers must be reported as dimensionless numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases. Each number must be printed in scientific notation with six significant digits. For example: $[1.23457\\mathrm{e}{-04},3.21000\\mathrm{e}{-03},\\dots]$.\n\nYour task: Implement the above and produce the single-line output for the four test cases as specified.", "solution": "The problem presented is valid. It is a well-posed, scientifically grounded problem from computational quantum mechanics, free of any inconsistencies, ambiguities, or factual errors. I will now provide the solution.\n\nThe core of the problem is to find the discrete spectrum of the quantum harmonic oscillator by solving the time-independent Schrödinger equation on a finite domain. The governing equation is:\n$$\n-\\frac{\\hbar^{2}}{2 m}\\,\\frac{d^{2}\\psi}{dx^{2}} + V(x)\\,\\psi(x) = E\\,\\psi(x)\n$$\nwhere the potential is $V(x) = \\frac{1}{2} m \\omega^{2} x^{2}$. The analytical solution on an infinite domain $x \\in (-\\infty, \\infty)$ yields the energy eigenvalues $E_n = \\hbar \\omega (n + \\frac{1}{2})$ for non-negative integers $n$. For numerical computation, the problem must be restricted to a finite interval $x \\in [-L, L]$ with boundary conditions $\\psi(-L) = \\psi(L) = 0$.\n\nThe first step is to discretize the domain. We define a uniform grid with $N$ interior points. The total number of grid points, including the boundaries, is $N+2$. The interval length is $2L$, and it is divided into $N+1$ subintervals. The grid spacing, or step size, is therefore:\n$$\n\\Delta x = \\frac{L - (-L)}{N+1} = \\frac{2L}{N+1}\n$$\nThe grid points are $x_i = -L + i \\cdot \\Delta x$ for $i \\in \\{0, 1, \\dots, N+1\\}$. The wavefunction $\\psi(x)$ is represented by its values at these points, $\\psi_i = \\psi(x_i)$. The problem focuses on the $N$ interior points, $x_1, \\dots, x_N$, where the wavefunction is unknown. The boundary conditions stipulate that $\\psi_0 = \\psi(-L) = 0$ and $\\psi_{N+1} = \\psi(L) = 0$.\n\nThe continuous Schrödinger equation is transformed into a matrix eigenvalue problem by discretizing the operators. The second derivative operator is approximated using a symmetric second-order finite difference formula at each interior grid point $x_i$:\n$$\n\\left. \\frac{d^2\\psi}{dx^2} \\right|_{x_i} \\approx \\frac{\\psi(x_{i-1}) - 2\\psi(x_i) + \\psi(x_{i+1})}{(\\Delta x)^2} = \\frac{\\psi_{i-1} - 2\\psi_i + \\psi_{i+1}}{(\\Delta x)^2}\n$$\nSubstituting this into the Schrödinger equation for an interior point $x_i$ gives:\n$$\n-\\frac{\\hbar^2}{2m} \\left( \\frac{\\psi_{i-1} - 2\\psi_i + \\psi_{i+1}}{(\\Delta x)^2} \\right) + V(x_i)\\psi_i = E \\psi_i\n$$\nThis set of $N$ linear equations for the unknown values $\\psi_1, \\dots, \\psi_N$ can be written in the matrix form $\\mathbf{H}\\vec{\\psi} = E\\vec{\\psi}$, where $\\vec{\\psi} = [\\psi_1, \\dots, \\psi_N]^T$ is the vector of wavefunction values at the interior points, and $\\mathbf{H}$ is the $N \\times N$ discrete Hamiltonian matrix.\n\nThe Hamiltonian matrix $\\mathbf{H}$ is the sum of the kinetic energy matrix $\\mathbf{T}$ and the potential energy matrix $\\mathbf{V}$.\n\nThe potential energy operator becomes a diagonal matrix $\\mathbf{V}$ with elements corresponding to the potential evaluated at each interior grid point:\n$$\nV_{ij} = \\delta_{ij} V(x_i) = \\delta_{ij} \\left( \\frac{1}{2} m \\omega^2 x_i^2 \\right)\n$$\n\nThe kinetic energy operator gives rise to a tridiagonal matrix $\\mathbf{T}$. Its elements are derived from the finite difference formula:\n$$\n\\mathbf{T}_{ij} =\n\\begin{cases}\n\\frac{\\hbar^2}{m(\\Delta x)^2} & \\text{if } i=j \\\\\n-\\frac{\\hbar^2}{2m(\\Delta x)^2} & \\text{if } |i-j|=1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe boundary conditions $\\psi_0=0$ and $\\psi_{N+1}=0$ are incorporated directly into the equations for the first ($i=1$) and last ($i=N$) interior points, ensuring the tridiagonal structure is maintained.\n\nThe full Hamiltonian matrix $\\mathbf{H} = \\mathbf{T} + \\mathbf{V}$ is therefore a real, symmetric, tridiagonal matrix with elements:\n$$\nH_{ij} =\n\\begin{cases}\n\\frac{\\hbar^2}{m(\\Delta x)^2} + \\frac{1}{2} m \\omega^2 x_i^2 & \\text{if } i=j \\\\\n-\\frac{\\hbar^2}{2m(\\Delta x)^2} & \\text{if } |i-j|=1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe problem reduces to finding the eigenvalues of this matrix $\\mathbf{H}$. Since $\\mathbf{H}$ is symmetric and tridiagonal, its eigenvalues can be computed very efficiently. The lowest $K$ eigenvalues of $\\mathbf{H}$ correspond to the numerical estimates of the first $K$ energy levels of the quantum system, $E_n^{(\\mathrm{num})}$ for $n \\in \\{0, 1, \\dots, K-1\\}$.\n\nFinally, these numerical eigenvalues are compared to the exact analytical eigenvalues, $E_n^{(\\mathrm{exact})} = \\hbar \\omega (n + \\frac{1}{2})$. The quality of the numerical approximation is quantified by the maximum absolute relative error across the lowest $K$ states:\n$$\n\\varepsilon_{\\max} = \\max_{0 \\le n < K} \\left| \\frac{E_n^{(\\mathrm{num})} - E_n^{(\\mathrm{exact})}}{E_n^{(\\mathrm{exact})}} \\right|\n$$\nThe implementation will use the `scipy.linalg.eigh_tridiagonal` function, which is specifically optimized for finding eigenvalues of symmetric tridiagonal matrices. We will request the lowest $K$ eigenvalues for each test case, calculate the exact values, and then compute $\\varepsilon_{\\max}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh_tridiagonal\n\ndef solve():\n    \"\"\"\n    Solves the stationary Schrödinger boundary value problem for the quantum\n    harmonic oscillator using a finite difference method.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (hbar, m, omega, L, N, K)\n    test_cases = [\n        (1.0, 1.0, 1.0, 8.0, 300, 6),\n        (1.0, 1.0, 1.0, 6.0, 60, 4),\n        (1.0, 1.0, 2.3, 8.0, 300, 5),\n        (1.0, 1.0, 1.0, 3.0, 300, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        hbar, m, omega, L, N, K = case\n\n        # 1. Discretize the spatial domain [-L, L] with N interior points.\n        # The total number of intervals is N+1.\n        delta_x = 2.0 * L / (N + 1)\n        \n        # Grid of N interior points x_i for i=1, ..., N.\n        # The numpy array will be 0-indexed, corresponding to i=1...N.\n        x_interior = np.linspace(-L + delta_x, L - delta_x, N)\n\n        # 2. Construct the discrete Hamiltonian matrix H as a tridiagonal matrix.\n        # H is the sum of the kinetic matrix T and potential matrix V.\n\n        # The potential energy V(x) = 0.5 * m * omega^2 * x^2 evaluated\n        # at the interior grid points gives the diagonal of V.\n        potential_diagonal = 0.5 * m * (omega**2) * (x_interior**2)\n\n        # The finite difference approximation of the kinetic energy operator\n        # gives the diagonal and off-diagonal elements of T.\n        # T_ii = hbar^2 / (m * delta_x^2)\n        # T_{i, i-1} = T_{i, i+1} = -hbar^2 / (2 * m * delta_x^2)\n        kinetic_diag_term = hbar**2 / (m * delta_x**2)\n        kinetic_off_diag_term = -hbar**2 / (2.0 * m * delta_x**2)\n\n        # The main diagonal of H is the sum of the diagonals of T and V.\n        main_diagonal = kinetic_diag_term + potential_diagonal\n        \n        # The off-diagonal of H is the same as the off-diagonal of T.\n        off_diagonal = np.full(N - 1, kinetic_off_diag_term)\n\n        # 3. Solve the eigenvalue problem for the lowest K eigenvalues.\n        # eigh_tridiagonal is highly efficient for symmetric tridiagonal matrices.\n        # 'select=\"i\"' and 'select_range=(0, K-1)' computes the K smallest\n        # eigenvalues (indices 0 to K-1). Eigenvalues are returned in ascending order.\n        eigenvalues_numerical = eigh_tridiagonal(\n            main_diagonal, \n            off_diagonal, \n            select='i', \n            select_range=(0, K - 1), \n            eigvals_only=True\n        )\n\n        # 4. Calculate the corresponding exact eigenvalues for comparison.\n        # E_n = hbar * omega * (n + 0.5) for n = 0, 1, ..., K-1.\n        n_levels = np.arange(K)\n        eigenvalues_exact = hbar * omega * (n_levels + 0.5)\n\n        # 5. Compute the maximum absolute relative error over the K levels.\n        relative_errors = np.abs((eigenvalues_numerical - eigenvalues_exact) / eigenvalues_exact)\n        max_relative_error = np.max(relative_errors)\n        \n        results.append(max_relative_error)\n\n    # Final print statement in the exact required format.\n    # Format each number in scientific notation with 6 significant digits (1 before, 5 after decimal).\n    formatted_results = [f\"{res:.5e}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2377652"}, {"introduction": "While linear models are foundational, many real-world physical systems are governed by nonlinear equations that can exhibit surprisingly rich behavior. This practice introduces the shooting method, an intuitive and powerful approach that reframes a boundary value problem into a root-finding exercise for an initial value problem [@problem_id:2377656]. By applying this method to a nonlinear oscillator, you will not only learn a versatile computational technique but also directly observe the concept of non-unique solutions, where multiple distinct physical motions can satisfy the same boundary conditions.", "problem": "Consider the nonlinear boundary value problem for an ordinary differential equation on a finite interval: find a function $y(x)$ satisfying\n$$\ny''(x) + y(x)^3 = 0 \\quad \\text{for } x \\in [0,L], \\quad \\text{with} \\quad y(0)=0, \\; y(L)=0,\n$$\nwhere $L>0$ is a given length. This problem is a model for the motion of a unit-mass particle in a quartic potential $V(y)=\\tfrac{1}{4}y^4$, with $x$ playing the role of time. From first principles in classical mechanics and ordinary differential equations, do the following.\n\n1) Starting from Newton's second law and the definition of mechanical energy for a unit mass, use the potential $V(y)=\\tfrac{1}{4}y^4$ to justify that the initial value problem with initial conditions $y(0)=0$ and $y'(0)=s$ conserves the energy\n$$\nE = \\tfrac{1}{2}\\,[y'(x)]^2 + \\tfrac{1}{4}\\, [y(x)]^4,\n$$\nand that, for $s>0$, the solution $y(x)$ is periodic in $x$ and oscillates between symmetric turning points $\\pm A$ determined by the energy. Then, using only these fundamental facts (without invoking any pre-derived period formulas), argue qualitatively why the boundary value problem can admit multiple distinct solutions for a fixed $L$: different choices of the initial slope $s$ can produce trajectories in which one or more half-oscillations fit exactly into the interval $[0,L]$, all satisfying the same final boundary condition $y(L)=0$.\n\n2) Implement a shooting method to reveal this non-uniqueness numerically. Treat the initial slope $s=y'(0)$ as an adjustable shooting parameter, and define the residual\n$$\nR(s;L) := y(L;s),\n$$\nwhere $y(x;s)$ solves the initial value problem with $y(0)=0$, $y'(0)=s$. Use a numerically stable ordinary differential equation integrator for the first-order system equivalent to the second-order equation, and a robust bracketing-based one-dimensional root finder to locate distinct positive roots of $R(s;L)=0$. Specifically:\n- Convert the second-order equation to the first-order system $y_1' = y_2$, $y_2' = -y_1^3$, with $y_1(0)=0$ and $y_2(0)=s$.\n- For each given $L$, compute the two smallest distinct positive shooting values $s_1(L)$ and $s_2(L)$, with $s_2(L) > s_1(L) > 0$, such that $|R(s_k;L)| \\le \\varepsilon$ for tolerance $\\varepsilon = 10^{-8}$.\n- Exclude the trivial solution $s=0$ from consideration.\n\n3) Test suite. Run your program on the following set of three domain lengths:\n- $L_1 = 1.00$,\n- $L_2 = 1.20$,\n- $L_3 = 0.75$.\nFor each $L_i$, return the list $[s_1(L_i), s_2(L_i)]$ rounded to $6$ decimal places. Your final program output must be a single line containing the results as a comma-separated list enclosed in square brackets, in the order $L_1, L_2, L_3$, for example:\n$[[s_1(L_1),s_2(L_1)],[s_1(L_2),s_2(L_2)],[s_1(L_3),s_2(L_3)]]$.\nAll numbers must be written in decimal notation. No additional text should be printed.\n\nAdditional implementation requirements:\n- Use a standard adaptive-step ordinary differential equation solver with absolute and relative tolerances at or below $10^{-9}$.\n- Use a bracketing root-finding method with an absolute solution tolerance at or below $10^{-10}$ on $s$.\n- Ensure robustness by using a sign-change scan in $s$ over a sufficiently large interval to isolate at least two distinct positive roots for each $L_i$.", "solution": "The problem as stated is subjected to validation and is found to be scientifically grounded, well-posed, objective, and internally consistent. It is a standard problem in computational physics and nonlinear dynamics concerning the solution of a boundary value problem (BVP) for a conservative system. All necessary data, equations, and constraints are provided. The problem is therefore deemed valid. We proceed with a complete solution.\n\nThe solution is presented in two parts as requested: first, a theoretical justification from first principles, and second, a description of the numerical shooting method designed to solve the problem.\n\n**1. Theoretical Justification and Qualitative Analysis**\n\nThe problem concerns the motion of a particle of unit mass, $m=1$, under the influence of a force $F(y)$ derived from a potential energy function $V(y)$. Newton's second law states that $ma = F$, where the acceleration is $a = y''(x)$, with $x$ representing time. The force is conservative, given by $F(y) = -V'(y)$. For the given potential $V(y) = \\frac{1}{4}y^4$, the corresponding force is $F(y) = -\\frac{d}{dy}(\\frac{1}{4}y^4) = -y^3$. Substituting these into Newton's law for $m=1$ gives:\n$$\n(1) y''(x) = -y(x)^3\n$$\nwhich rearranges to the specified ordinary differential equation (ODE):\n$$\ny''(x) + y(x)^3 = 0.\n$$\nThis confirms the physical origin of the governing equation.\n\nTo demonstrate the conservation of mechanical energy, we multiply the ODE by the velocity, $y'(x)$:\n$$\ny''(x) y'(x) + y(x)^3 y'(x) = 0.\n$$\nThis expression is equivalent to the total time derivative of the energy. Recognizing that $y'' y' = \\frac{d}{dx}(\\frac{1}{2}[y'(x)]^2)$ and $y^3 y' = \\frac{d}{dx}(\\frac{1}{4}[y(x)]^4)$, we have:\n$$\n\\frac{d}{dx} \\left( \\frac{1}{2}[y'(x)]^2 + \\frac{1}{4}[y(x)]^4 \\right) = 0.\n$$\nThis implies that the quantity within the parentheses, which is the total mechanical energy $E$, is a constant of motion:\n$$\nE = \\frac{1}{2}[y'(x)]^2 + \\frac{1}{4}[y(x)]^4 = \\text{constant}.\n$$\nThe energy $E$ is determined by the initial conditions. For the initial value problem (IVP) with $y(0)=0$ and $y'(0)=s$, the energy is:\n$$\nE = \\frac{1}{2}[y'(0)]^2 + \\frac{1}{4}[y(0)]^4 = \\frac{1}{2}s^2 + \\frac{1}{4}(0)^4 = \\frac{1}{2}s^2.\n$$\nFor any $s > 0$, the energy $E > 0$. The particle's motion is confined by the potential. The turning points of the oscillation, denoted $\\pm A$, occur where the velocity $y'(x)$ is zero. At these points, the kinetic energy is zero, and all energy is potential: $E = V(A) = \\frac{1}{4}A^4$. Equating the two expressions for energy gives:\n$$\n\\frac{1}{2}s^2 = \\frac{1}{4}A^4 \\implies A = (2s^2)^{1/4}.\n$$\nThe particle starts at $y(0)=0$ with positive velocity $s$, moves towards the positive turning point $+A$, reverses direction, passes through $y=0$ with velocity $-s$, reaches the negative turning point $-A$, and returns to $y=0$. This cycle constitutes a periodic motion.\n\nThe non-uniqueness of solutions for the BVP arises from the periodic nature of the IVP solutions. The boundary condition $y(L)=0$ requires the particle to be at the origin at time $x=L$. Starting from $y(0)=0$, the particle reaches $y=0$ again after one half-period, two half-periods (a full period), three half-periods, and so on. Let $T_{1/2}(s)$ denote the half-period of the oscillation corresponding to the initial slope $s$. The boundary condition $y(L)=0$ is satisfied if the interval length $L$ is an integer multiple of the half-period:\n$$\nL = k \\cdot T_{1/2}(s) \\quad \\text{for } k = 1, 2, 3, \\dots\n$$\nThe period of this anharmonic oscillator depends on its energy, and therefore on $s$. By changing $s$, we change the period. For a fixed length $L$, the above equation becomes an implicit equation for $s$. It is plausible that this equation can be solved for different values of $s$, each corresponding to a different integer $k$. For $k=1$, we seek an initial slope $s_1$ such that the particle just completes its first half-oscillation in the interval $[0, L]$. This yields the fundamental solution, a single arch. For $k=2$, we seek a different slope $s_2$ such that the particle completes two half-oscillations (one full wave) in $[0, L]$. These distinct values $s_1, s_2, \\dots$ all produce solutions $y(x; s_k)$ that satisfy both boundary conditions, $y(0)=0$ and $y(L)=0$, thus explaining the existence of multiple, non-trivial solutions to the BVP.\n\n**2. Numerical Design: The Shooting Method**\n\nTo find these distinct initial slopes numerically, we employ the shooting method. This method reframes the BVP as a root-finding problem.\n\nThe shooting parameter is the unknown initial slope, $s = y'(0)$.\nThe IVP is defined as:\n$$\ny''(x) + y(x)^3 = 0, \\quad y(0)=0, \\quad y'(0)=s.\n$$\nTo solve this numerically, we convert the second-order ODE into an equivalent first-order system. Let $y_1(x) = y(x)$ and $y_2(x) = y'(x)$. The system is:\n$$\n\\begin{cases}\ny_1'(x) = y_2(x) \\\\\ny_2'(x) = -y_1(x)^3\n\\end{cases}\n$$\nwith initial conditions at $x=0$:\n$$\n\\begin{pmatrix} y_1(0) \\\\ y_2(0) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ s \\end{pmatrix}.\n$$\nWe integrate this system from $x=0$ to $x=L$. The solution at $x=L$, which we denote $y(L;s)$, depends on the choice of $s$. The second boundary condition $y(L)=0$ (or $y_1(L)=0$) is satisfied only for specific values of $s$. We define a residual function $R(s;L)$ which measures the mismatch at the final boundary:\n$$\nR(s;L) = y_1(L;s).\n$$\nThe problem is now to find the roots of the equation $R(s;L) = 0$.\n\nThe numerical procedure is as follows:\n1.  **Define the Residual Function**: Create a function that, for a given $s$ and $L$, numerically solves the IVP from $x=0$ to $x=L$ using a high-precision, adaptive-step ODE integrator (such as `scipy.integrate.solve_ivp` with absolute and relative tolerances set to $10^{-10}$). This function returns the value of $y_1(L)$.\n2.  **Bracket the Roots**: As argued qualitatively, the residual $R(s;L)$ will be an oscillatory function of $s$. To find its roots, we first need to isolate them in intervals. We achieve this by evaluating $R(s;L)$ over a grid of $s$ values and identifying pairs of adjacent points, $(s_a, s_b)$, where $R(s_a;L)$ and $R(s_b;L)$ have opposite signs. Each such interval $[s_a, s_b]$ is guaranteed to contain at least one root.\n3.  **Solve for the Roots**: For each bracket $[s_a, s_b]$ found, a robust one-dimensional bracketing root-finder (such as Brent's method, `scipy.optimize.brentq`) is used to locate the root $s_k$ to a high degree of accuracy (tolerance on $s$ set to $10^{-11}$).\n4.  **Collect and Report**: We apply this procedure for each given length $L_i$ to find the two smallest distinct positive roots, $s_{1}(L_i)$ and $s_{2}(L_i)$, round them to the specified precision, and format the output as required. The trivial solution $s=0$ is explicitly excluded.\n\nThis combination of a high-fidelity ODE solver and a reliable root-finding algorithm provides a robust and accurate method for determining the non-unique solutions of the nonlinear BVP.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear BVP y'' + y^3 = 0 with y(0)=0, y(L)=0\n    using a shooting method to find the first two non-trivial positive\n    initial slopes s = y'(0) for given lengths L.\n    \"\"\"\n\n    # --- 1. Define the core components of the shooting method ---\n\n    # ODE system: y' = f(x, y), where y = [y_1, y_2] = [y, y']\n    def ode_system(t, y):\n        \"\"\"First-order system for y'' = -y^3\"\"\"\n        return [y[1], -y[0]**3]\n\n    # Residual function R(s; L) = y(L; s)\n    def residual(s, L):\n        \"\"\"\n        Computes the residual R(s;L) = y(L;s) by solving the IVP.\n\n        Args:\n            s (float): The initial slope y'(0), our shooting parameter.\n            L (float): The length of the interval [0, L].\n\n        Returns:\n            float: The value of y(L), which we want to be zero.\n        \"\"\"\n        if s == 0:\n            return 0.0 # Trivial solution y(x)=0 for all x\n\n        # Initial conditions for the IVP: y(0)=0, y'(0)=s\n        y0 = [0.0, s]\n        \n        # Integration interval\n        t_span = [0, L]\n        \n        # High-precision ODE solver settings\n        atol = 1e-10\n        rtol = 1e-10\n\n        # Solve the initial value problem\n        sol = solve_ivp(\n            fun=ode_system,\n            t_span=t_span,\n            y0=y0,\n            method='DOP853',\n            atol=atol,\n            rtol=rtol,\n        )\n        \n        # Return the final value of y(x), which is y_1(L)\n        # sol.y is a 2xN array. We need the first component at the last time step.\n        return sol.y[0, -1]\n\n    # --- 2. Implement the root-finding logic ---\n\n    def find_shooting_values(L, num_roots=2):\n        \"\"\"\n        Finds the first `num_roots` positive values of s for a given L.\n        \"\"\"\n        roots = []\n        \n        # Scan for sign changes to find brackets for the roots.\n        # The required s values increase as L decreases. The scan range\n        # must be large enough to find the required number of roots.\n        s_scan_points = np.linspace(0.1, 100.0, 500)\n        r_values = np.array([residual(s, L) for s in s_scan_points])\n        \n        # Find intervals where the sign of the residual changes\n        for i in range(len(s_scan_points) - 1):\n            if np.sign(r_values[i]) != np.sign(r_values[i+1]):\n                s_a, s_b = s_scan_points[i], s_scan_points[i+1]\n                \n                try:\n                    # Use a robust bracketing root-finder\n                    root = brentq(\n                        residual, \n                        a=s_a, \n                        b=s_b, \n                        args=(L,), \n                        xtol=1e-11 # Tolerance on the root s\n                    )\n                    roots.append(root)\n                    \n                    if len(roots) == num_roots:\n                        break\n                except ValueError:\n                    # brentq can fail if signs are not opposite, though our check prevents this.\n                    continue\n        \n        if len(roots) < num_roots:\n            raise RuntimeError(f\"Could not find {num_roots} roots for L={L}. Try increasing the scan range for s.\")\n        \n        return sorted(roots)\n\n    # --- 3. Execute for the test suite ---\n\n    # Define the test cases from the problem statement.\n    test_cases = [1.00, 1.20, 0.75]\n    \n    all_results = []\n    \n    for L_val in test_cases:\n        # Find the two smallest positive shooting values\n        s1, s2 = find_shooting_values(L_val, num_roots=2)\n        \n        # Round to 6 decimal places as required\n        result_pair = [round(s1, 6), round(s2, 6)]\n        all_results.append(result_pair)\n    \n    # Format the final output string exactly as specified\n    # e.g., [[val1,val2],[val3,val4]]\n    output_str = \"[\" + \",\".join([str(pair) for pair in all_results]) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str.replace(\" \", \"\"))\n\nsolve()\n```", "id": "2377656"}, {"introduction": "Not all boundaries are fixed in place; many physical processes, from melting ice to advancing chemical reactions, involve moving interfaces. This practice introduces you to a \"free boundary problem,\" where the position of the boundary itself is an unknown part of the solution [@problem_id:2377639]. By analyzing the Stefan problem for a melting solid, you will learn how a similarity transformation can reduce a complex partial differential equation to a single transcendental equation, which can then be solved numerically to determine the dynamics of the moving front.", "problem": "Consider the classical one-dimensional one-phase Stefan melting problem on the semi-infinite half-line. A semi-infinite solid initially at the melting temperature $T_m$ occupies $x>0$. For $t>0$, the boundary at $x=0$ is held at a constant temperature $T_s$ with $T_s>T_m$, producing a liquid phase on $0<x<s(t)$ separated from the solid at $x=s(t)$, where $s(t)$ is the unknown moving interface. Assume the liquid has constant properties: density $\\rho$, specific heat $c$, thermal conductivity $k$, and thermal diffusivity $\\alpha=k/(\\rho c)$. The liquid temperature $T(x,t)$ satisfies the heat equation $T_t=\\alpha T_{xx}$ on $0<x<s(t)$ with boundary conditions $T(0,t)=T_s$ and $T(s(t),t)=T_m$, while the solid for $x>s(t)$ remains at $T_m$. The energy balance at the moving interface is given by the Stefan condition $\\rho L \\, s'(t)=-k\\,T_x(x=s(t)^-,t)$, where $L$ is the latent heat of fusion and the superscript $^-$ denotes the limit from the liquid side.\n\nUse the above mathematical model, with all quantities expressed in International System of Units, to determine the interface position $s(t)$ for the following material parameters and test cases:\n- Material parameters (constant in time): $\\rho = 1000\\,\\mathrm{kg/m^3}$, $c = 4180\\,\\mathrm{J/(kg\\cdot K)}$, $k = 0.6\\,\\mathrm{W/(m\\cdot K)}$, $L = 334000\\,\\mathrm{J/kg}$, $T_m = 273.15\\,\\mathrm{K}$, and $\\alpha = k/(\\rho c)$.\n- Test suite of boundary temperatures and evaluation times (each pair $(T_s,t)$ to be treated independently):\n  1. $(T_s,t)=\\left(283.15\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$,\n  2. $(T_s,t)=\\left(273.65\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$,\n  3. $(T_s,t)=\\left(303.15\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$,\n  4. $(T_s,t)=\\left(283.15\\,\\mathrm{K},\\,10\\,\\mathrm{s}\\right)$.\n\nFor each test case, compute the value of $s(t)$ in meters. Express each numerical answer in meters, rounded to six decimal places.\n\nYour program must produce a single line of output containing the results for the test suite, in the same order as listed above, as a comma-separated list enclosed in square brackets. For example, the output format must be exactly like $[a,b,c,d]$ with each entry rounded to six decimal places and no additional text. Angles do not appear in this problem, and no angle units are needed.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n\nThe governing partial differential equation for the liquid temperature $T(x,t)$ in the domain $0 < x < s(t)$ is the heat equation:\n$$\n\\frac{\\partial T}{\\partial t} = \\alpha \\frac{\\partial^2 T}{\\partial x^2}\n$$\nThe boundary conditions are:\n$$\nT(0, t) = T_s, \\quad t>0\n$$\n$$\nT(s(t), t) = T_m, \\quad t>0\n$$\nThe initial condition is that the solid for $x>0$ is at temperature $T_m$. The liquid phase forms for $t>0$, so the initial position of the interface is $s(0)=0$.\n\nThe Stefan condition at the moving interface $x=s(t)$ is:\n$$\n\\rho L \\frac{ds}{dt} = -k \\left. \\frac{\\partial T}{\\partial x} \\right|_{x=s(t)^-}\n$$\nMaterial parameters are given as:\n- Density: $\\rho = 1000\\,\\mathrm{kg/m^3}$\n- Specific heat: $c = 4180\\,\\mathrm{J/(kg\\cdot K)}$\n- Thermal conductivity: $k = 0.6\\,\\mathrm{W/(m\\cdot K)}$\n- Latent heat of fusion: $L = 334000\\,\\mathrm{J/kg}$\n- Melting temperature: $T_m = 273.15\\,\\mathrm{K}$\n- Thermal diffusivity is defined as $\\alpha = k/(\\rho c)$.\n\nThe test cases are four pairs of $(T_s, t)$:\n1. $(T_s,t)=\\left(283.15\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$\n2. $(T_s,t)=\\left(273.65\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$\n3. $(T_s,t)=\\left(303.15\\,\\mathrm{K},\\,3600\\,\\mathrm{s}\\right)$\n4. $(T_s,t)=\\left(283.15\\,\\mathrm{K},\\,10\\,\\mathrm{s}\\right)$\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is a classic one-dimensional, one-phase Stefan problem.\n- **Scientifically Grounded:** The model is based on the fundamental principle of energy conservation applied to heat conduction and phase change. The heat equation and the Stefan condition are canonical in this field. All parameters provided are physically realistic and correspond to water/ice.\n- **Well-Posed:** This is a standard problem in mathematical physics with a known method of solution leading to a unique result.\n- **Objective:** The problem is stated in precise, quantitative terms.\n- **Completeness:** All necessary physical constants and boundary/initial conditions required for a unique solution are provided.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. A rigorous analytical solution will be derived.\n\n**Solution Derivation**\n\nThis problem admits a similarity solution. We introduce a similarity variable $\\eta$:\n$$\n\\eta = \\frac{x}{2\\sqrt{\\alpha t}}\n$$\nWe seek a solution for the temperature of the form $T(x,t) = f(\\eta)$. The derivatives of $T$ are:\n$$\n\\frac{\\partial T}{\\partial t} = f'(\\eta) \\frac{\\partial \\eta}{\\partial t} = f'(\\eta) \\left( -\\frac{x}{4\\sqrt{\\alpha} t^{3/2}} \\right) = -\\frac{\\eta}{2t} f'(\\eta)\n$$\n$$\n\\frac{\\partial T}{\\partial x} = f'(\\eta) \\frac{\\partial \\eta}{\\partial x} = \\frac{1}{2\\sqrt{\\alpha t}} f'(\\eta)\n$$\n$$\n\\frac{\\partial^2 T}{\\partial x^2} = \\frac{1}{4\\alpha t} f''(\\eta)\n$$\nSubstituting these into the heat equation, $T_t = \\alpha T_{xx}$, yields:\n$$\n-\\frac{\\eta}{2t} f'(\\eta) = \\alpha \\left( \\frac{1}{4\\alpha t} f''(\\eta) \\right) \\implies f''(\\eta) + 2\\eta f'(\\eta) = 0\n$$\nThis is a second-order ordinary differential equation for $f(\\eta)$.\n\nThe moving interface position $s(t)$ must be consistent with the similarity transformation. This requires $s(t)$ to be proportional to $\\sqrt{t}$. We define a dimensionless constant $\\lambda$ such that:\n$$\ns(t) = 2\\lambda\\sqrt{\\alpha t}\n$$\nAt this position, the similarity variable has the constant value $\\eta = \\lambda$.\n\nThe boundary conditions for $T(x,t)$ are transformed into boundary conditions for $f(\\eta)$:\n- At $x=0$, we have $\\eta=0$. Thus, $T(0,t) = T_s \\implies f(0) = T_s$.\n- At $x=s(t)$, we have $\\eta=\\lambda$. Thus, $T(s(t),t) = T_m \\implies f(\\lambda) = T_m$.\n\nThe general solution to the ODE $f'' + 2\\eta f' = 0$ is found by two successive integrations. The solution is of the form:\n$$\nf(\\eta) = A \\cdot \\mathrm{erf}(\\eta) + B\n$$\nwhere $\\mathrm{erf}(\\eta) = \\frac{2}{\\sqrt{\\pi}} \\int_0^\\eta e^{-u^2} du$ is the error function, and $A$ and $B$ are constants.\n\nApplying the boundary conditions for $f(\\eta)$:\n- $f(0) = T_s \\implies A \\cdot \\mathrm{erf}(0) + B = T_s \\implies B = T_s$.\n- $f(\\lambda) = T_m \\implies A \\cdot \\mathrm{erf}(\\lambda) + T_s = T_m \\implies A = \\frac{T_m - T_s}{\\mathrm{erf}(\\lambda)}$.\n\nThe temperature profile in the liquid phase is therefore:\n$$\nT(x,t) = T_s + (T_m-T_s) \\frac{\\mathrm{erf}\\left(\\frac{x}{2\\sqrt{\\alpha t}}\\right)}{\\mathrm{erf}(\\lambda)}\n$$\nNow we apply the Stefan condition, which requires the derivatives $s'(t)$ and $T_x(x,t)$:\n$$\ns'(t) = \\frac{d}{dt} (2\\lambda\\sqrt{\\alpha t}) = \\lambda\\sqrt{\\frac{\\alpha}{t}}\n$$\n$$\n\\frac{\\partial T}{\\partial x} = \\frac{T_m-T_s}{\\mathrm{erf}(\\lambda)} \\cdot \\frac{d}{dx} \\left( \\mathrm{erf}\\left(\\frac{x}{2\\sqrt{\\alpha t}}\\right) \\right) = \\frac{T_m-T_s}{\\mathrm{erf}(\\lambda)} \\cdot \\frac{2}{\\sqrt{\\pi}} e^{-\\left(\\frac{x}{2\\sqrt{\\alpha t}}\\right)^2} \\cdot \\frac{1}{2\\sqrt{\\alpha t}}\n$$\nEvaluating the temperature gradient at the interface $x=s(t)$, where $\\eta=\\lambda$:\n$$\n\\left. \\frac{\\partial T}{\\partial x} \\right|_{x=s(t)^-} = \\frac{T_m-T_s}{\\mathrm{erf}(\\lambda)} \\frac{e^{-\\lambda^2}}{\\sqrt{\\pi\\alpha t}}\n$$\nSubstituting these into the Stefan condition $\\rho L s'(t) = -k T_x(s(t),t)$:\n$$\n\\rho L \\left(\\lambda\\sqrt{\\frac{\\alpha}{t}}\\right) = -k \\left( \\frac{T_m-T_s}{\\mathrm{erf}(\\lambda)} \\frac{e^{-\\lambda^2}}{\\sqrt{\\pi\\alpha t}} \\right)\n$$\nSimplifying and rearranging terms:\n$$\n\\rho L \\lambda \\sqrt{\\frac{\\alpha}{t}} = k \\frac{T_s-T_m}{\\mathrm{erf}(\\lambda)} \\frac{e^{-\\lambda^2}}{\\sqrt{\\pi\\alpha t}}\n$$\n$$\n\\rho L \\lambda \\alpha \\sqrt{\\pi} \\mathrm{erf}(\\lambda) = k(T_s-T_m) e^{-\\lambda^2}\n$$\nUsing the definition of thermal diffusivity, $\\alpha = k/(\\rho c)$:\n$$\n\\rho L \\lambda \\frac{k}{\\rho c} \\sqrt{\\pi} \\mathrm{erf}(\\lambda) = k(T_s-T_m) e^{-\\lambda^2}\n$$\n$$\n\\frac{L\\lambda\\sqrt{\\pi}}{c} \\mathrm{erf}(\\lambda) = (T_s-T_m) e^{-\\lambda^2}\n$$\nThis gives the final transcendental equation for the unknown constant $\\lambda$:\n$$\n\\frac{e^{-\\lambda^2}}{\\lambda \\mathrm{erf}(\\lambda)} = \\frac{L \\sqrt{\\pi}}{c(T_s - T_m)}\n$$\nFor each test case, we must numerically solve this equation for $\\lambda$. The term on the right is a constant for a given set of parameters. Let this constant be $C_{st}$. The function on the left is monotonic for $\\lambda > 0$, guaranteeing a unique positive solution. Once $\\lambda$ is determined, the interface position is calculated using $s(t) = 2\\lambda\\sqrt{\\alpha t}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Solves the one-phase Stefan problem for the given material parameters\n    and test cases.\n    \"\"\"\n\n    # Material parameters in SI units\n    rho = 1000.  # kg/m^3\n    c = 4180.    # J/(kg*K)\n    k = 0.6      # W/(m*K)\n    L = 334000.  # J/kg\n    T_m = 273.15 # K\n\n    # Calculate thermal diffusivity\n    alpha = k / (rho * c)\n\n    # Test suite of boundary temperatures and evaluation times\n    test_cases = [\n        # (T_s in K, t in s)\n        (283.15, 3600.0),\n        (273.65, 3600.0),\n        (303.15, 3600.0),\n        (283.15, 10.0),\n    ]\n\n    results = []\n    \n    for T_s, t in test_cases:\n        # Check for the trivial case to avoid division by zero.\n        # This problem assumes T_s > T_m.\n        if T_s <= T_m:\n            results.append(0.0)\n            continue\n\n        # The transcendental equation for lambda is F(lambda) = C\n        # where F(lambda) = exp(-lambda^2) / (lambda * erf(lambda))\n        # and C = L * sqrt(pi) / (c * (T_s - T_m))\n        \n        # Calculate the constant part of the equation\n        const_C = (L * np.sqrt(np.pi)) / (c * (T_s - T_m))\n\n        # Define the function whose root we need to find, g(lambda) = F(lambda) - C = 0\n        def g(lam):\n            if lam <= 0:\n                # The function diverges at lambda=0, return a large positive number\n                return np.inf\n            return np.exp(-lam**2) / (lam * erf(lam)) - const_C\n        \n        # The function g(lambda) is strictly decreasing for lambda > 0.\n        # g(lambda -> 0+) -> +inf\n        # g(lambda -> inf) -> -const_C\n        # A root is guaranteed in (0, inf). We use a reasonably large bracket.\n        bracket = [1e-9, 10.0]\n        \n        # Solve for lambda using a robust root-finding algorithm\n        sol = root_scalar(g, bracket=bracket, method='brentq')\n        lambda_val = sol.root\n\n        # Calculate the interface position s(t)\n        s_t = 2 * lambda_val * np.sqrt(alpha * t)\n        \n        # Round to 6 decimal places as required\n        results.append(round(s_t, 6))\n\n    # Format the final output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2377639"}]}