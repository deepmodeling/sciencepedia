{"hands_on_practices": [{"introduction": "Adams-Bashforth methods are built on the principle of polynomial interpolation. While standard formulas assume a constant step size $h$, real-world adaptive solvers often vary this step to maintain efficiency and accuracy. This first practice challenges you to derive the coefficients for a two-step method on a non-uniform grid defined by step sizes $h$ and $\\alpha h$ [@problem_id:2410017]. By working through this derivation from first principles, you will gain a deeper understanding of how these methods are constructed and generalized for adaptive integration.", "problem": "Consider the initial value problem for an ordinary differential equation (ODE), $y^{\\prime}(t)=f(t,y(t))$, with a time grid $\\{t_{n-2},t_{n-1},t_{n}\\}$ satisfying $t_{n}-t_{n-1}=h$ and $t_{n-1}-t_{n-2}=\\alpha h$, where $\\alpha>0$ and $h>0$. Let $f_{k}:=f(t_{k},y_{k})$ for $k\\in\\{n-2,n-1\\}$. Assume $f$ is sufficiently smooth so that a second-order accurate linear multistep method exists.\n\nDerive the coefficients $\\beta_{0}(\\alpha)$ and $\\beta_{1}(\\alpha)$ for the explicit $2$-step Adams–Bashforth method that advances from $t_{n-1}$ to $t_{n}$ in the form\n$$\ny_{n}=y_{n-1}+h\\left[\\beta_{0}(\\alpha)\\,f_{n-1}+\\beta_{1}(\\alpha)\\,f_{n-2}\\right].\n$$\nExpress your final answer as a closed-form analytic expression in terms of $\\alpha$. No rounding is required.", "solution": "The problem as stated is well-posed, scientifically grounded, and contains all necessary information to derive a unique solution. It is a standard problem in the field of numerical analysis concerning the construction of linear multistep methods for non-uniform step sizes. We shall proceed with the derivation.\n\nThe objective is to find the coefficients $\\beta_{0}(\\alpha)$ and $\\beta_{1}(\\alpha)$ for the explicit $2$-step method given by\n$$\ny_{n}=y_{n-1}+h\\left[\\beta_{0}(\\alpha)\\,f_{n-1}+\\beta_{1}(\\alpha)\\,f_{n-2}\\right]\n$$\nwhere $f_{k}$ is an abbreviation for $y'(t_k)$. The method must be second-order accurate. This requirement dictates that the local truncation error must be of order $O(h^3)$.\n\nThe local truncation error, $T_n$, is the residual obtained when the exact solution $y(t)$ is substituted into the numerical scheme. For this method, $T_n$ is defined as:\n$$\nT_{n} = y(t_n) - \\left( y(t_{n-1}) + h\\left[\\beta_{0}(\\alpha)y'(t_{n-1}) + \\beta_{1}(\\alpha)y'(t_{n-2})\\right] \\right)\n$$\nTo determine the coefficients, we employ the method of undetermined coefficients, which requires expanding all terms in Taylor series around a common point, which we choose to be $t_{n-1}$. The grid points are related by $t_n = t_{n-1} + h$ and $t_{n-2} = t_{n-1} - \\alpha h$, with $h > 0$ and $\\alpha > 0$.\n\nFirst, we expand $y(t_n)$ around $t_{n-1}$:\n$$\ny(t_n) = y(t_{n-1}+h) = y(t_{n-1}) + h y'(t_{n-1}) + \\frac{h^2}{2} y''(t_{n-1}) + \\frac{h^3}{6} y'''(t_{n-1}) + O(h^4)\n$$\nNext, we expand $y'(t_{n-2})$ around $t_{n-1}$:\n$$\ny'(t_{n-2}) = y'(t_{n-1}-\\alpha h) = y'(t_{n-1}) - \\alpha h \\, y''(t_{n-1}) + \\frac{(\\alpha h)^2}{2} y'''(t_{n-1}) + O(h^3)\n$$\nSubstituting these expansions into the expression for $T_n$:\n$$\nT_n = \\left(y(t_{n-1}) + h y'(t_{n-1}) + \\frac{h^2}{2} y''(t_{n-1}) + \\dots\\right) - y(t_{n-1}) - h\\beta_0 y'(t_{n-1}) - h\\beta_1 \\left(y'(t_{n-1}) - \\alpha h y''(t_{n-1}) + \\dots\\right)\n$$\nTo achieve second-order accuracy, the error $T_n$ must be $O(h^3)$. This is accomplished by setting the coefficients of the terms of order $h$ and $h^2$ to zero. We collect terms based on the derivatives of $y$ evaluated at $t_{n-1}$.\n\nThe term proportional to $y(t_{n-1})$ is $y(t_{n-1}) - y(t_{n-1}) = 0$, which is satisfied.\n\nThe terms proportional to $h y'(t_{n-1})$ must sum to zero:\n$$\nh y'(t_{n-1}) - h\\beta_0 y'(t_{n-1}) - h\\beta_1 y'(t_{n-1}) = 0\n$$\nDividing by $h y'(t_{n-1})$ (assuming $y'(t_{n-1}) \\neq 0$), we obtain our first condition:\n$$\n1 - \\beta_0 - \\beta_1 = 0 \\quad \\implies \\quad \\beta_0 + \\beta_1 = 1\n$$\nThe terms proportional to $h^2 y''(t_{n-1})$ must also sum to zero:\n$$\n\\frac{h^2}{2} y''(t_{n-1}) - h\\beta_1(-\\alpha h y''(t_{n-1})) = 0\n$$\n$$\n\\frac{h^2}{2} y''(t_{n-1}) + \\alpha h^2 \\beta_1 y''(t_{n-1}) = 0\n$$\nDividing by $h^2 y''(t_{n-1})$ (assuming $y''(t_{n-1}) \\neq 0$), we get the second condition:\n$$\n\\frac{1}{2} + \\alpha \\beta_1 = 0\n$$\nWe now have a system of two linear equations for the two unknowns, $\\beta_0$ and $\\beta_1$:\n$$\n\\begin{cases}\n\\beta_0 + \\beta_1 = 1 \\\\\n\\alpha \\beta_1 = -\\frac{1}{2}\n\\end{cases}\n$$\nFrom the second equation, we solve for $\\beta_1(\\alpha)$. Since $\\alpha>0$ is given, this is always well-defined:\n$$\n\\beta_1(\\alpha) = -\\frac{1}{2\\alpha}\n$$\nSubstituting this result into the first equation, we find $\\beta_0(\\alpha)$:\n$$\n\\beta_0 + \\left(-\\frac{1}{2\\alpha}\\right) = 1 \\quad \\implies \\quad \\beta_0(\\alpha) = 1 + \\frac{1}{2\\alpha}\n$$\nThus, the coefficients for the second-order accurate Adams-Bashforth method on the specified non-uniform grid are:\n$$\n\\beta_0(\\alpha) = 1 + \\frac{1}{2\\alpha} \\quad \\text{and} \\quad \\beta_1(\\alpha) = -\\frac{1}{2\\alpha}\n$$\nFor the standard case of a uniform grid, $\\alpha=1$, which correctly recovers the coefficients $\\beta_0(1) = \\frac{3}{2}$ and $\\beta_1(1) = -\\frac{1}{2}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 + \\frac{1}{2\\alpha} & -\\frac{1}{2\\alpha} \\end{pmatrix}}\n$$", "id": "2410017"}, {"introduction": "A theoretical understanding of a numerical method truly solidifies when you implement it in code. This exercise guides you through building a versatile, class-based Adams-Bashforth solver for methods of order $k \\in \\{1, 2, 3, 4\\}$ [@problem_id:2371225]. You will tackle crucial practical details, such as the startup procedure, which requires a separate, self-starting method to generate the initial history for the multistep integration.", "problem": "Construct a complete, runnable program that defines a class-based solver for explicit Adams–Bashforth multistep methods and uses it to integrate several initial value problems. The solver must maintain the internal state consisting of the most recent right-hand-side evaluations in the order $\\left[f_n,f_{n-1},\\dots\\right]$, where $f_n=f\\left(t_n,y_n\\right)$. The solver must support constant step size and orders $k \\in \\{1,2,3,4\\}$. All variables are to be treated as dimensionless. Angles, where they appear, must be interpreted in radians.\n\nThe program must, for each test case described below, numerically integrate the given initial value problem from $t=t_0$ to $t=t_{\\mathrm{final}}$ using a fixed step size $h$ and the specified Adams–Bashforth order $k$. For each test case, compute a scalar error as follows: for scalar problems, the absolute value $|y\\left(t_{\\mathrm{final}}\\right)-y_{\\mathrm{exact}}\\left(t_{\\mathrm{final}}\\right)|$; for vector problems, the Euclidean norm $\\left\\|y\\left(t_{\\mathrm{final}}\\right)-y_{\\mathrm{exact}}\\left(t_{\\mathrm{final}}\\right)\\right\\|_2$. Your program must then output a single line that is a comma-separated Python-style list of the four error values in the order of the test cases below.\n\nTest suite specification:\n\n- Test case $1$ (scalar, linear, order $k=1$):\n  - Differential equation: $\\dfrac{dy}{dt}=-y$.\n  - Initial condition: $y(0)=1$ at $t_0=0$.\n  - Final time: $t_{\\mathrm{final}}=1$.\n  - Step size: $h=0.1$.\n  - Exact solution: $y_{\\mathrm{exact}}(t)=e^{-t}$.\n  - Required error to compute: $|y(1)-e^{-1}|$.\n\n- Test case $2$ (scalar, linear, order $k=2$):\n  - Differential equation: $\\dfrac{dy}{dt}=-y$.\n  - Initial condition: $y(0)=1$ at $t_0=0$.\n  - Final time: $t_{\\mathrm{final}}=1$.\n  - Step size: $h=0.1$.\n  - Exact solution: $y_{\\mathrm{exact}}(t)=e^{-t}$.\n  - Required error to compute: $|y(1)-e^{-1}|$.\n\n- Test case $3$ (scalar, nonlinear, order $k=3$):\n  - Differential equation: $\\dfrac{dy}{dt}=-y^3$.\n  - Initial condition: $y(0)=1$ at $t_0=0$.\n  - Final time: $t_{\\mathrm{final}}=1$.\n  - Step size: $h=0.05$.\n  - Exact solution: $y_{\\mathrm{exact}}(t)=\\dfrac{1}{\\sqrt{1+2t}}$.\n  - Required error to compute: $|y(1)-1/\\sqrt{3}|$.\n\n- Test case $4$ (vector, linear rotation, order $k=4$):\n  - Differential equation: $\\dfrac{d}{dt}\\begin{bmatrix}u\\\\v\\end{bmatrix}=\\begin{bmatrix}0 & -\\omega\\\\ \\omega & 0\\end{bmatrix}\\begin{bmatrix}u\\\\v\\end{bmatrix}$ with $\\omega=1$.\n  - Initial condition: $\\begin{bmatrix}u(0)\\\\v(0)\\end{bmatrix}=\\begin{bmatrix}1\\\\0\\end{bmatrix}$ at $t_0=0$.\n  - Final time: $t_{\\mathrm{final}}=\\dfrac{\\pi}{2}$.\n  - Step size: $h=\\dfrac{\\pi}{400}$.\n  - Exact solution: $\\begin{bmatrix}u_{\\mathrm{exact}}(t)\\\\v_{\\mathrm{exact}}(t)\\end{bmatrix}=\\begin{bmatrix}\\cos(t)\\\\\\sin(t)\\end{bmatrix}$.\n  - Required error to compute: $\\left\\|\\begin{bmatrix}u\\left(\\frac{\\pi}{2}\\right)\\\\v\\left(\\frac{\\pi}{2}\\right)\\end{bmatrix}-\\begin{bmatrix}0\\\\1\\end{bmatrix}\\right\\|_2$.\n\nFinal output format specification:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the fixed order of test cases $\\left[1,2,3,4\\right]$. For example, a syntactically valid line would be of the form $[r_1,r_2,r_3,r_4]$ where each $r_i$ is a floating-point number. Do not print any additional text before or after this line.", "solution": "The problem statement has been subjected to rigorous validation. All givens, including the differential equations, initial conditions, integration parameters, and exact solutions for four distinct test cases, have been extracted and verified. The mathematical and physical premises are sound. The specified ordinary differential equations are standard, and their provided exact solutions are correct. The task is to implement an explicit Adams–Bashforth multistep solver for orders $k \\in \\{1,2,3,4\\}$, which is a well-defined problem in numerical analysis.\n\nA minor ambiguity exists in the problem statement regarding the startup procedure for the multistep methods (where $k > 1$). A $k$-step method requires $k$ historical values of the derivative, $f_{n}, f_{n-1}, \\dots, f_{n-k+1}$, to compute the next step, $y_{n+1}$. To begin the integration, the first $k-1$ points, $(t_1, y_1), \\dots, (t_{k-1}, y_{k-1})$, must be generated by a different, self-starting method. The problem does not specify this method. This omission is a common characteristic of such problems, where the implementer is expected to select a standard, scientifically justifiable approach. For this solution, the classical fourth-order Runge-Kutta (RK4) method is chosen for the startup phase. Its single-step nature and $O(h^4)$ accuracy make it a robust and appropriate choice for generating the initial history for Adams–Bashforth methods up to order $4$. With this clarification, the problem is deemed complete, consistent, and well-posed. We proceed with the solution.\n\nThe explicit $k$-step Adams–Bashforth method for solving the initial value problem $\\frac{dy}{dt} = f(t,y)$ with $y(t_0) = y_0$ is defined by the iterative formula:\n$$\ny_{n+1} = y_n + h \\sum_{i=0}^{k-1} b_{k,i} f(t_{n-i}, y_{n-i})\n$$\nwhere $h$ is the constant step size, $y_n$ is the numerical approximation of $y(t_n)$ at time $t_n = t_0 + nh$, and $f_{n-i} = f(t_{n-i}, y_{n-i})$. The coefficients $b_{k,i}$ for the required orders $k=1, 2, 3, 4$ are as follows:\n\nFor $k=1$ (Forward Euler method):\n$$\ny_{n+1} = y_n + h f_n\n$$\nThe single coefficient is $b_{1,0} = 1$.\n\nFor $k=2$:\n$$\ny_{n+1} = y_n + h \\left( \\frac{3}{2} f_n - \\frac{1}{2} f_{n-1} \\right)\n$$\nThe coefficients are $b_{2,0} = \\frac{3}{2}$ and $b_{2,1} = -\\frac{1}{2}$.\n\nFor $k=3$:\n$$\ny_{n+1} = y_n + \\frac{h}{12} \\left( 23 f_n - 16 f_{n-1} + 5 f_{n-2} \\right)\n$$\nThe coefficients are $b_{3,0} = \\frac{23}{12}$, $b_{3,1} = -\\frac{16}{12}$, and $b_{3,2} = \\frac{5}{12}$.\n\nFor $k=4$:\n$$\ny_{n+1} = y_n + \\frac{h}{24} \\left( 55 f_n - 59 f_{n-1} + 37 f_{n-2} - 9 f_{n-3} \\right)\n$$\nThe coefficients are $b_{4,0} = \\frac{55}{24}$, $b_{4,1} = -\\frac{59}{24}$, $b_{4,2} = \\frac{37}{24}$, and $b_{4,3} = -\\frac{9}{24}$.\n\nThe implementation will be encapsulated within a class, `AdamsBashforthSolver`. The solver's constructor, `__init__`, will initialize the state ($t$, $y$) and handle the startup procedure. For a given order $k>1$, it will execute $k-1$ steps of the RK4 method to compute the points $(y_1, y_2, \\ldots, y_{k-1})$ and populate the required history of function evaluations, $[f_{k-1}, f_{k-2}, \\ldots, f_0]$. The RK4 formula for a single step from $(t_n, y_n)$ is:\n$$\n\\begin{align*}\nk_1 &= f(t_n, y_n) \\\\\nk_2 &= f(t_n + \\frac{h}{2}, y_n + \\frac{h}{2} k_1) \\\\\nk_3 &= f(t_n + \\frac{h}{2}, y_n + \\frac{h}{2} k_2) \\\\\nk_4 &= f(t_n + h, y_n + h k_3) \\\\\ny_{n+1} &= y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n\\end{align*}\n$$\nAfter the startup phase, the solver's state will consist of the current time $t_{k-1}$, the current solution $y_{k-1}$, and the history of derivative evaluations $[f_{k-1}, f_{k-2}, \\ldots, f_0]$. A `step` method will advance the solution by one time step using the appropriate Adams–Bashforth formula. This involves calculating a weighted sum of the historical $f$ values. An `integrate` method will orchestrate the process, repeatedly calling the `step` method until the final integration time $t_{\\mathrm{final}}$ is reached.\n\nThe program will define the four right-hand side functions, set up the parameters for each test case, and instantiate the solver for each case. The `integrate` method will be called to obtain the final numerical solution $y(t_{\\mathrm{final}})$. The error will then be computed as specified: for scalar problems, the absolute difference $|y(t_{\\mathrm{final}}) - y_{\\mathrm{exact}}(t_{\\mathrm{final}})|$, and for the vector problem, the Euclidean norm $\\|y(t_{\\mathrm{final}}) - y_{\\mathrm{exact}}(t_{\\mathrm{final}})\\|_2$. The computed errors for the four cases will be collected and printed in the required format.", "answer": "```python\nimport numpy as np\n\nclass AdamsBashforthSolver:\n    \"\"\"\n    A class-based solver for explicit Adams–Bashforth multistep methods.\n    \"\"\"\n    AB_COEFFS = {\n        1: np.array([1.0]),\n        2: np.array([3.0/2.0, -1.0/2.0]),\n        3: np.array([23.0/12.0, -16.0/12.0, 5.0/12.0]),\n        4: np.array([55.0/24.0, -59.0/24.0, 37.0/24.0, -9.0/24.0])\n    }\n\n    def __init__(self, f, y0, t0, h, k):\n        \"\"\"\n        Initializes the Adams-Bashforth solver.\n\n        Args:\n            f (callable): The right-hand side function f(t, y) of the ODE.\n            y0 (float or np.ndarray): The initial condition y(t0).\n            t0 (float): The initial time.\n            h (float): The step size.\n            k (int): The order of the Adams-Bashforth method (1, 2, 3, or 4).\n        \"\"\"\n        if k not in self.AB_COEFFS:\n            raise ValueError(\"Order k must be in {1, 2, 3, 4}\")\n\n        self.f = f\n        self.y0 = np.array(y0, dtype=float)\n        self.t0 = float(t0)\n        self.h = float(h)\n        self.k = int(k)\n        \n        self.coeffs = self.AB_COEFFS[self.k]\n        \n        # Initialize state\n        self.t = self.t0\n        self.y = self.y0\n        \n        # f_history stores [f_n, f_{n-1}, ..., f_{n-k+1}]\n        self.f_history = []\n        \n        # Startup procedure to generate initial history for k>1\n        self._startup()\n\n    def _rk4_step(self, t, y):\n        \"\"\"Performs a single RK4 step.\"\"\"\n        k1 = self.f(t, y)\n        k2 = self.f(t + 0.5 * self.h, y + 0.5 * self.h * k1)\n        k3 = self.f(t + 0.5 * self.h, y + 0.5 * self.h * k2)\n        k4 = self.f(t + self.h, y + self.h * k3)\n        y_next = y + (self.h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n        t_next = t + self.h\n        return t_next, y_next\n\n    def _startup(self):\n        \"\"\"\n        Generates the first k-1 points using RK4 to populate f_history.\n        \"\"\"\n        # First evaluation at (t0, y0)\n        f0 = self.f(self.t0, self.y0)\n        self.f_history.insert(0, f0)\n        \n        # If k > 1, perform k-1 RK4 steps\n        if self.k > 1:\n            for _ in range(self.k - 1):\n                t_next, y_next = self._rk4_step(self.t, self.y)\n                self.t = t_next\n                self.y = y_next\n                f_next = self.f(self.t, self.y)\n                self.f_history.insert(0, f_next)\n\n    def step(self):\n        \"\"\"\n        Advances the solution by one step using the Adams-Bashforth formula.\n        \"\"\"\n        # Ensure f_history has the correct size\n        f_hist_array = np.array(self.f_history)\n        \n        # Calculate the weighted sum for the AB step\n        # For scalar y, f_hist_array is (k,), for vector y it is (k, dim)\n        # We need to dot coeffs with f_hist_array.\n        # np.dot handles this if f_hist_array is (dim, k)\n        if self.y.ndim > 0: # Vector case\n            ab_sum = np.dot(f_hist_array.T, self.coeffs)\n        else: # Scalar case\n            ab_sum = np.dot(self.coeffs, f_hist_array)\n\n        y_next = self.y + self.h * ab_sum\n        t_next = self.t + self.h\n        \n        # Update state\n        self.y = y_next\n        self.t = t_next\n        \n        # Update history\n        f_next = self.f(self.t, self.y)\n        self.f_history.insert(0, f_next)\n        if len(self.f_history) > self.k:\n            self.f_history.pop()\n\n    def integrate(self, t_final):\n        \"\"\"\n        Integrates the ODE from the current time to t_final.\n        \"\"\"\n        num_total_steps = int(round((t_final - self.t0) / self.h))\n        # Startup phase performed k-1 steps.\n        num_ab_steps = num_total_steps - (self.k - 1)\n        \n        for _ in range(num_ab_steps):\n            self.step()\n            \n        return self.y\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    \n    # --- Define RHS functions for the test cases ---\n    def f_case12(t, y):\n        # dy/dt = -y\n        return -y\n\n    def f_case3(t, y):\n        # dy/dt = -y^3\n        return -y**3\n\n    def f_case4(t, y):\n        # d/dt [u,v] = [0,-1; 1,0] * [u,v]\n        omega = 1.0\n        A = np.array([[0, -omega], [omega, 0]])\n        return A @ y\n\n    # --- Test suite specification ---\n    test_cases = [\n        # Case 1\n        {\n            'f': f_case12, 'y0': 1.0, 't0': 0.0, 't_final': 1.0, 'h': 0.1, 'k': 1,\n            'y_exact_final': np.exp(-1.0)\n        },\n        # Case 2\n        {\n            'f': f_case12, 'y0': 1.0, 't0': 0.0, 't_final': 1.0, 'h': 0.1, 'k': 2,\n            'y_exact_final': np.exp(-1.0)\n        },\n        # Case 3\n        {\n            'f': f_case3, 'y0': 1.0, 't0': 0.0, 't_final': 1.0, 'h': 0.05, 'k': 3,\n            'y_exact_final': 1.0 / np.sqrt(3.0)\n        },\n        # Case 4\n        {\n            'f': f_case4, 'y0': np.array([1.0, 0.0]), 't0': 0.0, 't_final': np.pi / 2.0, \n            'h': np.pi / 400.0, 'k': 4,\n            'y_exact_final': np.array([0.0, 1.0])\n        }\n    ]\n\n    results = []\n    for i, case in enumerate(test_cases):\n        solver = AdamsBashforthSolver(\n            f=case['f'],\n            y0=case['y0'],\n            t0=case['t0'],\n            h=case['h'],\n            k=case['k']\n        )\n        \n        y_final = solver.integrate(case['t_final'])\n        \n        y_exact = case['y_exact_final']\n        \n        if i == 3: # Vector case\n            error = np.linalg.norm(y_final - y_exact)\n        else: # Scalar cases\n            error = np.abs(y_final - y_exact)\n            \n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2371225"}, {"introduction": "We conclude our practices with a classic challenge from computational physics: integrating the Lorenz system, a model of atmospheric convection famous for its chaotic behavior. This exercise explores the profound implications of finite-precision arithmetic on the long-term prediction of chaotic systems [@problem_id:2371228]. By comparing simulations run in single and double precision, you will witness the 'butterfly effect' firsthand and gain a critical perspective on the limits of numerical modeling.", "problem": "Consider the three-dimensional Lorenz system defined by the autonomous ordinary differential equation $\\frac{d\\mathbf{y}}{dt}=\\mathbf{f}(\\mathbf{y})$ with state $\\mathbf{y}(t)=[x(t),y(t),z(t)]^\\top$ and vector field\n$$\n\\mathbf{f}(\\mathbf{y})=\n\\begin{bmatrix}\n\\sigma\\,(y-x)\\\\\nx\\,(\\rho-z)-y\\\\\nx\\,y-\\beta\\,z\n\\end{bmatrix},\n$$\nwhere the parameters are $\\sigma=10$, $\\rho=28$, and $\\beta=8/3$, and the initial condition is $\\mathbf{y}(0)=[1,1,1]^\\top$. Time is dimensionless.\n\nYou must integrate this system using the explicit four-step Adams–Bashforth method of order $4$ (AB$4$) with a fixed step size $h>0$. The AB$4$ recurrence is\n$$\n\\mathbf{y}_{n+1}=\\mathbf{y}_n+h\\left(\\frac{55}{24}\\mathbf{f}_n-\\frac{59}{24}\\mathbf{f}_{n-1}+\\frac{37}{24}\\mathbf{f}_{n-2}-\\frac{9}{24}\\mathbf{f}_{n-3}\\right),\n$$\nwhere $\\mathbf{f}_k=\\mathbf{f}(\\mathbf{y}_k)$ and $\\mathbf{y}_k\\approx \\mathbf{y}(t_k)$ with $t_k=t_0+k\\,h$ and $t_0=0$. To obtain the first three steps $\\mathbf{y}_1$, $\\mathbf{y}_2$, and $\\mathbf{y}_3$, use the classical fourth-order Runge–Kutta (RK$4$) one-step method with the same fixed step size $h$, defined for the autonomous case by\n$$\n\\begin{aligned}\n\\mathbf{k}_1&=\\mathbf{f}(\\mathbf{y}_n),\\\\\n\\mathbf{k}_2&=\\mathbf{f}\\left(\\mathbf{y}_n+\\frac{h}{2}\\mathbf{k}_1\\right),\\\\\n\\mathbf{k}_3&=\\mathbf{f}\\left(\\mathbf{y}_n+\\frac{h}{2}\\mathbf{k}_2\\right),\\\\\n\\mathbf{k}_4&=\\mathbf{f}\\left(\\mathbf{y}_n+h\\,\\mathbf{k}_3\\right),\\\\\n\\mathbf{y}_{n+1}&=\\mathbf{y}_n+\\frac{h}{6}\\left(\\mathbf{k}_1+2\\,\\mathbf{k}_2+2\\,\\mathbf{k}_3+\\mathbf{k}_4\\right).\n\\end{aligned}\n$$\n\nDefine two numerical solutions computed with the same AB$4$ scheme, same initial condition, and same fixed step size $h$, but with different floating-point arithmetic:\n- A double-precision solution $\\mathbf{y}^{(64)}(t)$ computed entirely in IEEE $64$-bit binary floating-point arithmetic (commonly called double precision).\n- A single-precision solution $\\mathbf{y}^{(32)}(t)$ computed entirely in IEEE $32$-bit binary floating-point arithmetic (commonly called single precision).\n\nFor the single-precision computation, every arithmetic operation and stored quantity in both the RK$4$ startup and the AB$4$ recurrence must be carried out and stored in $32$-bit precision; in particular, after each completed step, the state vector must be rounded to the nearest representable $32$-bit floating-point number.\n\nFor a given total integration time $T>0$, define the separation time $\\tau_\\epsilon$ as the earliest discrete time $t_k=k\\,h$ at which the Euclidean norm of the difference between the two numerical solutions first exceeds a specified threshold $\\epsilon>0$:\n$$\n\\tau_\\epsilon=\\min\\{t_k:\\ \\|\\mathbf{y}^{(64)}_k-\\mathbf{y}^{(32)}_k\\|_2>\\epsilon\\},\n$$\nwith the convention that if no such $t_k$ occurs for $0\\le k\\le N$ where $N=T/h$ is an integer, then $\\tau_\\epsilon=T$.\n\nImplement the above and compute $\\tau_\\epsilon$ for each of the following test cases. In every case, use the same Lorenz parameters and initial condition given above, and assume $T/h$ is an integer.\n\n- Test case $1$: $h=10^{-3}$, $T=20$, $\\epsilon=10^{-2}$.\n- Test case $2$: $h=5\\times 10^{-4}$, $T=30$, $\\epsilon=10^{-2}$.\n- Test case $3$: $h=2\\times 10^{-3}$, $T=20$, $\\epsilon=10^{-3}$.\n- Test case $4$: $h=10^{-3}$, $T=2$, $\\epsilon=1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of decimal numbers rounded to six digits after the decimal point, enclosed in square brackets in the same order as the test cases (for example, a line of the form $\\texttt{[0.123456,0.234567,0.345678,0.456789]}$). Time is dimensionless, so no physical units are required in the output.", "solution": "The problem presented is a valid computational physics exercise. It is scientifically grounded, well-posed, and objective. It requires the numerical integration of the Lorenz system, a canonical model of deterministic chaos, to study its sensitivity to floating-point precision. This is a fundamental topic in numerical analysis and the study of dynamical systems. All parameters, methods, and evaluation criteria are defined with sufficient clarity and rigor to permit a unique and verifiable solution.\n\nThe objective is to determine the \"separation time\" $\\tau_\\epsilon$, which is the time required for two numerical solutions of the Lorenz system, computed with different floating-point precisions, to diverge by a specified amount $\\epsilon$. One solution, $\\mathbf{y}^{(64)}$, is computed using standard $64$-bit double-precision arithmetic, serving as a high-accuracy reference. The other, $\\mathbf{y}^{(32)}$, is computed using $32$-bit single-precision arithmetic, where all constants, variables, and intermediate results are constrained to this lower precision. This setup is designed to demonstrate the exponential amplification of small round-off errors, a hallmark of chaotic systems known as the butterfly effect.\n\nThe system to be integrated is the Lorenz system, given by the first-order autonomous ordinary differential equation $\\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(\\mathbf{y})$, where $\\mathbf{y}(t) = [x(t), y(t), z(t)]^\\top$ and the vector field $\\mathbf{f}$ is defined as:\n$$\n\\mathbf{f}(\\mathbf{y}) =\n\\begin{bmatrix}\n\\sigma(y-x) \\\\\nx(\\rho-z) - y \\\\\nxy - \\beta z\n\\end{bmatrix}\n$$\nThe parameters are fixed at the classical chaotic values: $\\sigma=10$, $\\rho=28$, and $\\beta=8/3$. The integration starts from the initial condition $\\mathbf{y}(0) = [1, 1, 1]^\\top$.\n\nThe numerical integration scheme is the explicit fourth-order Adams-Bashforth (AB$4$) method. Being a multistep method, it is not self-starting. It requires a history of four previous function evaluations, $\\mathbf{f}_n, \\mathbf{f}_{n-1}, \\mathbf{f}_{n-2}, \\mathbf{f}_{n-3}$, to compute the next state $\\mathbf{y}_{n+1}$ from the current state $\\mathbf{y}_n$:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{24}(55\\mathbf{f}_n - 59\\mathbf{f}_{n-1} + 37\\mathbf{f}_{n-2} - 9\\mathbf{f}_{n-3})\n$$\nHere, $h$ is the fixed time step, $\\mathbf{y}_k \\approx \\mathbf{y}(kh)$, and $\\mathbf{f}_k = \\mathbf{f}(\\mathbf{y}_k)$. To generate the required history, the first three steps of the integration (to find $\\mathbf{y}_1, \\mathbf{y}_2, \\mathbf{y}_3$ from $\\mathbf{y}_0$) are performed using the classical fourth-order Runge-Kutta (RK$4$) method. RK$4$ is a one-step method, and its formula for an autonomous system is:\n$$\n\\begin{aligned}\n\\mathbf{k}_1 &= \\mathbf{f}(\\mathbf{y}_n) \\\\\n\\mathbf{k}_2 &= \\mathbf{f}\\left(\\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_1\\right) \\\\\n\\mathbf{k}_3 &= \\mathbf{f}\\left(\\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_2\\right) \\\\\n\\mathbf{k}_4 &= \\mathbf{f}\\left(\\mathbf{y}_n + h\\mathbf{k}_3\\right) \\\\\n\\mathbf{y}_{n+1} &= \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n\\end{aligned}\n$$\nThe procedural implementation is as follows for each test case:\n$1$. Two parallel simulations are initialized, one with $64$-bit precision (`numpy.float64`) and one with $32$-bit precision (`numpy.float32`). All system parameters, initial conditions, integration constants, and state vectors are typed accordingly.\n$2$. For $k=0, 1, 2$, the states $\\mathbf{y}_{k+1}^{(64)}$ and $\\mathbf{y}_{k+1}^{(32)}$ are computed from $\\mathbf{y}_k^{(64)}$ and $\\mathbf{y}_k^{(32)}$ respectively, using the RK$4$ method. The function evaluations $\\mathbf{f}_k^{(64)}$ and $\\mathbf{f}_k^{(32)}$ are stored.\n$3$. For all subsequent steps $k \\ge 3$ up to the total number of steps $N = T/h$, the states $\\mathbf{y}_{k+1}^{(64)}$ and $\\mathbf{y}_{k+1}^{(32)}$ are computed using the AB$4$ method, which utilizes the four most recent function evaluations stored in their respective histories.\n$4$. After each step $k$, the Euclidean norm of the difference between the states, $\\|\\mathbf{y}_{k+1}^{(64)} - \\mathbf{y}_{k+1}^{(32)}\\|_2$, is calculated. For this comparison, the $32$-bit vector is cast to $64$-bit precision to ensure the comparison itself is not a source of error.\n$5$. The separation time $\\tau_\\epsilon$ is the first time $t_{k+1} = (k+1)h$ at which this norm exceeds the threshold $\\epsilon$. If the threshold is not exceeded by the final time $T$, then $\\tau_\\epsilon = T$.\n\nThis rigorous procedure allows for the direct measurement of trajectory divergence due to finite precision arithmetic in a chaotic system.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1e-3, 20.0, 1e-2),    # Test case 1\n        (5e-4, 30.0, 1e-2),    # Test case 2\n        (2e-3, 20.0, 1e-3),    # Test case 3\n        (1e-3, 2.0, 1.0),      # Test case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        h, T, epsilon = case\n        tau_epsilon = compute_separation_time(h, T, epsilon)\n        results.append(tau_epsilon)\n\n    # Format results to six decimal places for the final output.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef compute_separation_time(h, T, epsilon):\n    \"\"\"\n    Computes the separation time for a given set of parameters.\n\n    Args:\n        h (float): The step size.\n        T (float): The total integration time.\n        epsilon (float): The separation threshold.\n\n    Returns:\n        float: The separation time tau_epsilon.\n    \"\"\"\n    # --- Setup for 64-bit (double precision) simulation ---\n    dtype64 = np.float64\n    y64 = np.array([1.0, 1.0, 1.0], dtype=dtype64)\n    sigma64, rho64, beta64 = dtype64(10.0), dtype64(28.0), dtype64(8.0/3.0)\n    h64 = dtype64(h)\n    ab_coeffs64 = np.array([55.0/24.0, -59.0/24.0, 37.0/24.0, -9.0/24.0], dtype=dtype64)\n    f_hist64 = deque(maxlen=4)\n\n    # --- Setup for 32-bit (single precision) simulation ---\n    dtype32 = np.float32\n    y32 = np.array([1.0, 1.0, 1.0], dtype=dtype32)\n    sigma32, rho32, beta32 = dtype32(10.0), dtype32(28.0), dtype32(8.0/3.0)\n    h32 = dtype32(h)\n    ab_coeffs32 = np.array([55.0/24.0, -59.0/24.0, 37.0/24.0, -9.0/24.0], dtype=dtype32)\n    f_hist32 = deque(maxlen=4)\n    \n    # --- Lorenz vector field function, typed for precision ---\n    def lorenz_f(y_vec, sigma, rho, beta, dtype):\n        x, y_comp, z = y_vec\n        dxdt = sigma * (y_comp - x)\n        dydt = x * (rho - z) - y_comp\n        dzdt = x * y_comp - beta * z\n        return np.array([dxdt, dydt, dzdt], dtype=dtype)\n\n    num_steps = int(round(T / h))\n\n    for k in range(num_steps):\n        # I. Evaluate f at the current step for both precisions\n        fk_64 = lorenz_f(y64, sigma64, rho64, beta64, dtype64)\n        f_hist64.append(fk_64)\n\n        fk_32 = lorenz_f(y32, sigma32, rho32, beta32, dtype32)\n        f_hist32.append(fk_32)\n\n        # II. Step forward using RK4 (startup) or AB4 (main)\n        if k < 3:\n            # RK4 step for 64-bit\n            k1_64 = fk_64\n            k2_64 = lorenz_f(y64 + h64/dtype64(2.0) * k1_64, sigma64, rho64, beta64, dtype64)\n            k3_64 = lorenz_f(y64 + h64/dtype64(2.0) * k2_64, sigma64, rho64, beta64, dtype64)\n            k4_64 = lorenz_f(y64 + h64 * k3_64, sigma64, rho64, beta64, dtype64)\n            y64_next = y64 + h64/dtype64(6.0) * (k1_64 + dtype64(2.0)*k2_64 + dtype64(2.0)*k3_64 + k4_64)\n\n            # RK4 step for 32-bit\n            k1_32 = fk_32\n            k2_32 = lorenz_f(y32 + h32/dtype32(2.0) * k1_32, sigma32, rho32, beta32, dtype32)\n            k3_32 = lorenz_f(y32 + h32/dtype32(2.0) * k2_32, sigma32, rho32, beta32, dtype32)\n            k4_32 = lorenz_f(y32 + h32 * k3_32, sigma32, rho32, beta32, dtype32)\n            y32_next = y32 + h32/dtype32(6.0) * (k1_32 + dtype32(2.0)*k2_32 + dtype32(2.0)*k3_32 + k4_32)\n        else:\n            # AB4 step for 64-bit (f_hist has f_n, f_{n-1}, f_{n-2}, f_{n-3})\n            term64 = (ab_coeffs64[0] * f_hist64[3] +\n                      ab_coeffs64[1] * f_hist64[2] +\n                      ab_coeffs64[2] * f_hist64[1] +\n                      ab_coeffs64[3] * f_hist64[0])\n            y64_next = y64 + h64 * term64\n            \n            # AB4 step for 32-bit\n            term32 = (ab_coeffs32[0] * f_hist32[3] +\n                      ab_coeffs32[1] * f_hist32[2] +\n                      ab_coeffs32[2] * f_hist32[1] +\n                      ab_coeffs32[3] * f_hist32[0])\n            y32_next = y32 + h32 * term32\n\n        # III. Update state vectors\n        y64 = y64_next\n        y32 = y32_next\n\n        # IV. Check for separation\n        diff_norm = np.linalg.norm(y64 - y32.astype(dtype64))\n        if diff_norm > epsilon:\n            return (k + 1) * h\n\n    return T\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2371228"}]}