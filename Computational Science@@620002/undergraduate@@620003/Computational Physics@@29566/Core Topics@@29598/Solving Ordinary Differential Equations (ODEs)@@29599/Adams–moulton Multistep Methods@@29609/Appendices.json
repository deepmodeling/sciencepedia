{"hands_on_practices": [{"introduction": "The power of implicit methods like Adams-Moulton comes with a unique challenge: we must solve an algebraic equation to find the solution at each time step. This practice provides a concrete first step by applying the method to the famous logistic equation, a model for population growth [@problem_id:2187830]. You will see exactly how the method's formula transforms a differential equation into a quadratic equation that needs to be solved.", "problem": "The logistic differential equation is a fundamental model for population growth under limiting constraints. It is given by\n$$\ny'(t) = r y(t) \\left(1 - \\frac{y(t)}{K}\\right)\n$$\nwhere $y(t)$ is the population at time $t$, $r$ is the intrinsic growth rate, and $K$ is the carrying capacity. Both $r$ and $K$ are positive constants.\n\nTo solve this equation numerically, one can use a variety of methods. The two-step Adams-Moulton method is an implicit multistep method defined by the formula:\n$$\ny_{n+1} = y_n + \\frac{h}{12}(5f_{n+1} + 8f_n - f_{n-1})\n$$\nHere, $h$ is the constant step size, $y_k$ is the numerical approximation of $y(t_k)$ at time $t_k = t_0 + kh$, and $f_k$ is the shorthand for $f(t_k, y_k)$, where $f(t, y) = y'(t)$.\n\nBecause the term $f_{n+1}$ depends on the unknown value $y_{n+1}$, applying this method to a nonlinear differential equation results in a nonlinear algebraic equation that must be solved for $y_{n+1}$ at each step. For the logistic equation, this algebraic equation is quadratic in $y_{n+1}$ and can be written in the standard form:\n$$\nA y_{n+1}^2 + B y_{n+1} + C = 0\n$$\nYour task is to determine the expressions for the coefficients $A$, $B$, and $C$. Your final answer should be the expressions for $A$, $B$, and $C$ in terms of the step size $h$, the logistic model parameters $r$ and $K$, and the known values from previous steps, $y_n$, $f_n$, and $f_{n-1}$.", "solution": "We start from the logistic differential equation with $f(t,y)=r y\\left(1-\\frac{y}{K}\\right)=r y-\\frac{r}{K}y^{2}$ and the two-step Adams-Moulton method\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5 f_{n+1}+8 f_{n}-f_{n-1}\\right).\n$$\nSubstituting $f_{n+1}=f(t_{n+1},y_{n+1})=r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}$ gives\n$$\ny_{n+1}=y_{n}+\\frac{h}{12}\\left(5\\left(r y_{n+1}-\\frac{r}{K}y_{n+1}^{2}\\right)+8 f_{n}-f_{n-1}\\right).\n$$\nBring all terms to the left-hand side to write a quadratic equation in $y_{n+1}$:\n$$\ny_{n+1}-y_{n}-\\frac{h}{12}\\left(5 r y_{n+1}-5\\frac{r}{K}y_{n+1}^{2}+8 f_{n}-f_{n-1}\\right)=0.\n$$\nCollecting like terms yields\n$$\n\\frac{5 h r}{12 K}y_{n+1}^{2}+\\left(1-\\frac{5 h r}{12}\\right)y_{n+1}-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)=0.\n$$\nMatching this with $A y_{n+1}^{2}+B y_{n+1}+C=0$, we identify\n$$\nA=\\frac{5 h r}{12 K},\\quad B=1-\\frac{5 h r}{12},\\quad C=-y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right).\n$$\nThese are expressed in terms of $h$, $r$, $K$, and the known quantities $y_{n}$, $f_{n}$, and $f_{n-1}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{5 h r}{12 K} & 1-\\frac{5 h r}{12} & -y_{n}-\\frac{h}{12}\\left(8 f_{n}-f_{n-1}\\right)\\end{pmatrix}}$$", "id": "2187830"}, {"introduction": "It is a common misconception that higher-order numerical methods are universally \"better.\" This hands-on exercise reveals the counterintuitive nature of numerical stability by constructing a scenario where the second-order AM-2 method is stable, but the more accurate fourth-order AM-4 method is not [@problem_id:2371562]. By numerically computing the roots of the method's characteristic polynomial, you will directly verify how stability regions can differ in unexpected ways.", "problem": "You are to construct and analyze a linear ordinary differential equation (ODE) to expose a counterintuitive stability behavior between two implicit Adams–Moulton multistep methods of different orders. The goal is to identify an example where the second-order Adams–Moulton method (AM-2) is stable for a given step size, while the higher-order fourth-order Adams–Moulton method (AM-4) is unstable. You must implement a program that certifies stability or instability by applying the fundamental root condition for linear multistep methods to the linear test equation.\n\nFundamental base and definitions:\n- Consider the linear test equation $y' = \\lambda y$ with complex scalar $\\lambda \\in \\mathbb{C}$. For a fixed step size $h > 0$, define the complex number $z = h \\lambda$.\n- A linear multistep method has the form $\\sum_{j=0}^{s} \\alpha_j y_{n+j} = h \\sum_{j=0}^{s} \\beta_j f_{n+j}$, where $f_{n+j} = f(t_{n+j}, y_{n+j})$. On the test equation $f(t,y) = \\lambda y$, the method reduces to the characteristic equation in the amplification factor $\\xi$: $\\rho(\\xi) - z \\sigma(\\xi) = 0$, where $\\rho(\\xi) = \\sum_{j=0}^{s} \\alpha_j \\xi^j$ and $\\sigma(\\xi) = \\sum_{j=0}^{s} \\beta_j \\xi^j$.\n- Absolute stability for a given $z$ means that all roots $\\xi$ of $\\rho(\\xi) - z \\sigma(\\xi) = 0$ satisfy $|\\xi| < 1$; if a root lies on the unit circle it must be simple to be marginally stable. You should implement a numerical check of the root condition and treat $|\\xi| \\le 1$ within a small numerical tolerance as stable.\n\nTask requirements:\n1. Use the above principles to implement stability tests for the Adams–Moulton method of order $2$ (AM-2) and the Adams–Moulton method of order $4$ (AM-4). You should use the standard Adams–Moulton coefficients for these methods. For each method, construct the corresponding polynomials $\\rho(\\xi)$ and $\\sigma(\\xi)$ and test the root condition for a given $z$.\n2. Construct a scalar linear ODE of the form $y' = \\lambda y$ that is “pathological” in the following sense: for a specified step size $h$ the AM-2 method is stable (all roots satisfy $|\\xi| < 1$) while the AM-4 method is unstable (at least one root satisfies $|\\xi| > 1$). Your program should verify this numerically via the root condition, not by appealing to any external stability region plot.\n3. Implement the stability check robustly by computing the roots of the characteristic polynomial using a standard polynomial root finder and verifying the modulus condition with a small numerical tolerance.\n\nTest suite:\nEvaluate your implementation on the following three test cases, each specified by the pair $(\\lambda,h)$:\n- Case $1$: $\\lambda = -1.0$, $h = 0.1$.\n- Case $2$: $\\lambda = -50.0$, $h = 0.2$.\n- Case $3$: $\\lambda = 1.0$, $h = 0.1$.\n\nFor each case, compute $z = h \\lambda$ and determine two booleans: the first indicates whether AM-2 is stable, and the second indicates whether AM-4 is stable, both according to the root condition. The “pathological” behavior is embedded in one of these cases.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists, each inner list being of the form $[b_{\\mathrm{AM2}}, b_{\\mathrm{AM4}}]$ with unquoted booleans. For example, the output must look like $[[\\text{True},\\text{False}],[\\text{True},\\text{True}],[\\text{False},\\text{False}]]$ but with the actual values determined by your computation for the above test suite.", "solution": "The problem as stated is a standard exercise in the numerical analysis of ordinary differential equations. It is scientifically grounded, well-posed, and contains sufficient information to proceed. The objective is to demonstrate a known phenomenon where a higher-order numerical method can exhibit a smaller stability region than a lower-order one, leading to counterintuitive behavior for certain stiff problems. I will proceed with the solution.\n\nThe analysis is centered on the linear test equation, a fundamental tool for studying the stability of numerical methods for ODEs. The equation is given by:\n$$\ny'(t) = \\lambda y(t)\n$$\nwhere $y(t) \\in \\mathbb{C}$ and $\\lambda \\in \\mathbb{C}$. When a linear multistep method (LMM) of the form $\\sum_{j=0}^{s} \\alpha_j y_{n+j} = h \\sum_{j=0}^{s} \\beta_j f_{n+j}$ is applied to this equation with $f(t,y) = \\lambda y$, it yields a linear constant-coefficient recurrence relation for the sequence $\\{y_n\\}$. The solutions to this recurrence are of the form $y_n = \\xi^n$, where $\\xi$ is a root of the characteristic equation:\n$$\n\\rho(\\xi) - z \\sigma(\\xi) = 0\n$$\nHere, $z = h\\lambda$, and $\\rho(\\xi) = \\sum_{j=0}^{s} \\alpha_j \\xi^j$ and $\\sigma(\\xi) = \\sum_{j=0}^{s} \\beta_j \\xi^j$ are the first and second characteristic polynomials of the method, respectively.\n\nA method is defined as absolutely stable for a given $z$ if all roots $\\xi_k$ of its characteristic equation satisfy $|\\xi_k| \\le 1$. Any root with modulus equal to $1$ must be simple. The problem statement permits a slight relaxation for numerical implementation, where $|\\xi_k| \\le 1 + \\epsilon$ for a small tolerance $\\epsilon$ is considered stable. This check simplifies the analysis by avoiding the explicit check for simple roots on the unit circle.\n\nFirst, we analyze the second-order Adams-Moulton method (AM-2), also known as the trapezoidal rule. This is a one-step method ($s=1$) defined by:\n$$\ny_{n+1} - y_{n} = \\frac{h}{2} (f_{n+1} + f_n)\n$$\nFrom this form, we identify the coefficients $\\alpha_1=1$, $\\alpha_0=-1$ and $\\beta_1=1/2$, $\\beta_0=1/2$. The characteristic polynomials are:\n$$\n\\rho(\\xi) = \\xi - 1\n$$\n$$\n\\sigma(\\xi) = \\frac{1}{2}\\xi + \\frac{1}{2}\n$$\nThe resulting characteristic equation is a linear equation for $\\xi$:\n$$\n(\\xi - 1) - z \\left( \\frac{1}{2}\\xi + \\frac{1}{2} \\right) = 0 \\implies \\xi\\left(1 - \\frac{z}{2}\\right) = 1 + \\frac{z}{2}\n$$\nThe single root, known as the amplification factor, is:\n$$\n\\xi = \\frac{1 + z/2}{1 - z/2}\n$$\nFor stability, we require $|\\xi| \\le 1$. Let $z = x+iy$. The condition $|\\frac{2+z}{2-z}| \\le 1$ is equivalent to $|2+z|^2 \\le |2-z|^2$.\n$$\n(2+x)^2 + y^2 \\le (2-x)^2 + y^2 \\implies 4+4x+x^2 \\le 4-4x+x^2 \\implies 8x \\le 0 \\implies x \\le 0\n$$\nThus, the AM-2 method is stable for all $z$ in the left half of the complex plane, $\\text{Re}(z) \\le 0$. This property is known as A-stability.\n\nNext, we analyze the fourth-order Adams-Moulton method (AM-4). This is a three-step method ($s=3$) given by the formula:\n$$\ny_{n+3} - y_{n+2} = \\frac{h}{24}(9f_{n+3} + 19f_{n+2} - 5f_{n+1} + f_n)\n$$\nFrom this, we extract the coefficients. The first characteristic polynomial has $\\alpha_3=1$, $\\alpha_2=-1$, and all other $\\alpha_j=0$:\n$$\n\\rho(\\xi) = \\xi^3 - \\xi^2\n$$\nThe coefficients for the second characteristic polynomial are $\\beta_3 = 9/24$, $\\beta_2 = 19/24$, $\\beta_1 = -5/24$, and $\\beta_0 = 1/24$:\n$$\n\\sigma(\\xi) = \\frac{1}{24}(9\\xi^3 + 19\\xi^2 - 5\\xi + 1)\n$$\nThe characteristic equation $\\rho(\\xi) - z \\sigma(\\xi) = 0$ is:\n$$\n(\\xi^3 - \\xi^2) - \\frac{z}{24}(9\\xi^3 + 19\\xi^2 - 5\\xi + 1) = 0\n$$\nMultiplying by $24$ and collecting terms by powers of $\\xi$ yields a cubic polynomial equation:\n$$\n(24 - 9z)\\xi^3 + (-24 - 19z)\\xi^2 + (5z)\\xi - z = 0\n$$\nUnlike AM-2, this equation cannot be easily solved analytically for regions of stability. The stability of AM-4 for a given $z$ must be determined by numerically finding the three roots of this polynomial and checking if their moduli are all less than or equal to $1$. It is a known result that AM-4 is not A-stable; its region of absolute stability does not contain the entire left half-plane.\n\nThe implementation will proceed as follows. For each given pair $(\\lambda, h)$:\n1. Calculate $z = h\\lambda$.\n2. For AM-2, compute $\\xi = (1 + z/2)/(1 - z/2)$ and check if $|\\xi| \\le 1 + \\epsilon$.\n3. For AM-4, construct the complex coefficients of the cubic polynomial $P(\\xi) = a_3 \\xi^3 + a_2 \\xi^2 + a_1 \\xi + a_0$, where $a_3=24-9z$, $a_2=-24-19z$, $a_1=5z$, and $a_0=-z$. Use a standard numerical root-finder to obtain the roots $\\xi_1, \\xi_2, \\xi_3$. Check if $\\max(|\\xi_1|, |\\xi_2|, |\\xi_3|) \\le 1 + \\epsilon$.\n4. A small tolerance $\\epsilon = 10^{-9}$ is appropriate for this numerical check.\n\nWe now evaluate the provided test cases based on this procedure.\n\n- **Case 1**: $(\\lambda, h) = (-1.0, 0.1) \\implies z = -0.1$.\n  - AM-2: $\\text{Re}(z) = -0.1 \\le 0$. The method is stable.\n  - AM-4: $z = -0.1$ is a point very close to the origin. The method is zero-stable, and for small negative real $z$, it is known to be stable. We expect stability.\n  - Predicted outcome: $[\\text{True}, \\text{True}]$.\n\n- **Case 2**: $(\\lambda, h) = (-50.0, 0.2) \\implies z = -10.0$.\n  - AM-2: $\\text{Re}(z) = -10.0 \\le 0$. The method is A-stable, so it remains stable.\n  - AM-4: The stability region of AM-4 along the negative real axis is approximately $(-3.0, 0)$. Since $z = -10.0$ is far outside this interval, we expect at least one root to have a modulus greater than $1$. The method is unstable. This is the pathological case.\n  - Predicted outcome: $[\\text{True}, \\text{False}]$.\n\n- **Case 3**: $(\\lambda, h) = (1.0, 0.1) \\implies z = 0.1$.\n  - AM-2: $\\text{Re}(z) = 0.1 > 0$. The method is unstable.\n  - AM-4: For $\\text{Re}(z) > 0$, instability is expected. The root of $\\rho(\\xi)$ at $\\xi=1$ is perturbed to a value greater than $1$. The method is unstable.\n  - Predicted outcome: $[\\text{False}, \\text{False}]$.\n\nThe final program will implement this logic and confirm these predictions numerically.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef check_stability_am2(z: complex, tol: float = 1e-9) -> bool:\n    \"\"\"\n    Checks the stability of the AM-2 method for a given z = h*lambda.\n    AM-2 is stable if the single root xi of its characteristic equation has |xi| <= 1.\n    \"\"\"\n    # The characteristic polynomial for AM-2 is (1 - z/2)*xi - (1 + z/2) = 0.\n    # Avoid division by zero if z = 2.\n    if abs(z - 2.0) < tol:\n        # If z=2, the equation is degenerate. Physically, this corresponds to an\n        # infinite amplification factor, hence unstable.\n        return False\n        \n    xi = (1 + z / 2) / (1 - z / 2)\n    return np.abs(xi) <= 1.0 + tol\n\ndef check_stability_am4(z: complex, tol: float = 1e-9) -> bool:\n    \"\"\"\n    Checks the stability of the AM-4 method for a given z = h*lambda.\n    AM-4 is stable if all roots xi of its characteristic equation have |xi| <= 1.\n    \"\"\"\n    # Characteristic equation for AM-4:\n    # (24 - 9*z)*xi^3 + (-24 - 19*z)*xi^2 + (5*z)*xi - z = 0\n    # Coefficients of the cubic polynomial a*xi^3 + b*xi^2 + c*xi + d = 0\n    # The coefficients are complex numbers.\n    coeffs = [\n        24 - 9 * z,\n        -24 - 19 * z,\n        5 * z,\n        -z\n    ]\n    \n    # Use numpy.roots to find the roots of the polynomial.\n    # The roots will be complex.\n    try:\n        roots = np.roots(coeffs)\n    except np.linalg.LinAlgError:\n        # This can happen in degenerate cases, considered unstable.\n        return False\n\n    # Check the modulus of each root. The method is unstable if any root has\n    # a modulus greater than 1 (plus tolerance).\n    max_modulus = np.max(np.abs(roots))\n    \n    return max_modulus <= 1.0 + tol\n\ndef solve():\n    \"\"\"\n    Solves the problem by evaluating the stability of AM-2 and AM-4 for given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement as tuples of (lambda, h).\n    test_cases = [\n        (-1.0, 0.1),\n        (-50.0, 0.2),\n        (1.0, 0.1),\n    ]\n\n    results = []\n    for lambda_val, h_val in test_cases:\n        # Calculate z = h * lambda\n        z = h_val * lambda_val\n        \n        # Check stability for AM-2 and AM-4\n        is_stable_am2 = check_stability_am2(z)\n        is_stable_am4 = check_stability_am4(z)\n        \n        results.append([is_stable_am2, is_stable_am4])\n\n    # Format the final output string exactly as specified.\n    # e.g., [[True,False],[True,True],[False,False]]\n    # No spaces within the inner lists.\n    formatted_inner_lists = [f\"[{r[0]},{r[1]}]\" for r in results]\n    output_string = f\"[{','.join(formatted_inner_lists)}]\"\n    \n    print(output_string)\n\nsolve()\n```", "id": "2371562"}, {"introduction": "To move from textbook formulas to practical tools, we must address efficiency and reliability, which is where adaptive step-size control comes in. This practice challenges you to build a complete solver that automatically adjusts its step size to meet a specified error tolerance, a core feature of modern numerical software [@problem_id:2371573]. By implementing a controller based on the difference between a predictor and corrector, you will gain insight into how solvers can intelligently navigate complex solution landscapes.", "problem": "You are to design and implement an adaptive step-size controller for a predictor–corrector Adams–Moulton method that aims to keep the local error per unit step below a user-specified tolerance. Consider an initial-value problem defined by the ordinary differential equation (ODE) $y'(t)=f(t,y)$ with initial condition $y(t_0)=y_0$. You will use the second-order implicit trapezoidal rule (an Adams–Moulton method) as the corrector, coupled with a forward Euler predictor. The local error per unit step is to be estimated by the norm of the predictor–corrector difference divided by the current step size.\n\nStarting point (fundamental base): the ODE satisfies the integral relation\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s))\\, ds,\n$$\nwith time nodes $t_{n+1}=t_n+h_n$, where $h_n$ is the step size for the $n$-th step. The implicit trapezoidal rule approximates the integral by a linear interpolant of $f$, leading to a corrector that utilizes $f(t_n,y_n)$ and $f(t_{n+1},y_{n+1})$. To avoid solving a fully implicit nonlinear equation, use a predictor–corrector approach: predict $y_{n+1}^p$ explicitly, then correct to $y_{n+1}^c$ by applying the trapezoidal rule with $f(t_{n+1},y_{n+1}^p)$ in place of the unknown $f(t_{n+1},y_{n+1}^c)$.\n\nDefine the per-step error indicator by\n$$\ne_n \\equiv \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm. The adaptive controller must:\n- accept a step if $e_n \\le \\text{tol}$, where $\\text{tol} > 0$ is a user-specified tolerance,\n- otherwise reject the step and retry with a smaller $h_n$,\n- adjust $h_n$ for the next attempted step using a scale factor informed by how $e_n$ compares to $\\text{tol}$, together with a safety factor strictly between $0$ and $1$, and lower and upper bounds $h_{\\min}$ and $h_{\\max}$,\n- handle the final step so that $t$ lands exactly on the final time $T$ by shortening the step as needed,\n- use the Euclidean norm for vectors and the absolute value for scalars,\n- if $e_n=0$, increase the step cautiously within bounds,\n- if $h_n$ reaches $h_{\\min}$ and $e_n$ still exceeds tolerance, proceed by accepting the step to avoid deadlock, while still attempting to reduce $e_n$ on subsequent steps.\n\nImplement this algorithm in a single, complete, runnable program. The program must include a function that integrates any provided right-hand side $f(t,y)$ on an interval $[t_0,T]$ with initial condition $y_0$, using the described adaptive Adams–Moulton predictor–corrector scheme. Use the Euclidean norm for $\\|\\cdot\\|$. All variables are dimensionless; no physical units are required.\n\nTest suite. Run your solver on the following four test cases:\n\n- Case A (scalar exponential decay):\n  - $f(t,y) = -2\\,y$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 1$.\n  - Output for this case: the final value $y(T)$ as a float.\n\n- Case B (two-dimensional harmonic oscillator with angular frequency $\\omega$):\n  - State $y = [q,p]^\\top$ obeys $q' = p$, $p' = -\\omega^2 q$ with $\\omega = 5$,\n  - $t_0 = 0$, $T = 2\\pi/\\omega$,\n  - $y_0 = [1,0]^\\top$,\n  - $\\text{tol} = 10^{-6}$,\n  - $h_0 = 0.05$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.2$.\n  - Output for this case: the final values $q(T)$ and $p(T)$ as two floats, in that order.\n\n- Case C (scalar logistic growth):\n  - $f(t,y) = r\\,y\\,(1 - y/K)$ with parameters $r = 3$, $K=1$,\n  - $t_0 = 0$, $T = 5$,\n  - $y_0 = 0.2$,\n  - $\\text{tol} = 10^{-5}$,\n  - $h_0 = 0.1$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 0.5$.\n  - Output for this case: the final value $y(T)$ as a float.\n\n- Case D (edge case: very tight tolerance and small final time):\n  - $f(t,y) = y$,\n  - $t_0 = 0$, $T = 10^{-3}$,\n  - $y_0 = 1$,\n  - $\\text{tol} = 10^{-10}$,\n  - $h_0 = 10^{-4}$, $h_{\\min} = 10^{-8}$, $h_{\\max} = 10^{-2}$.\n  - Output for this case: the total number of accepted steps as an integer.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\;y_A(T),\\; q_B(T),\\; p_B(T),\\; y_C(T),\\; N_D\\;],\n$$\nwhere $y_A(T)$ is the Case A final value, $q_B(T)$ and $p_B(T)$ are the Case B final position and momentum, $y_C(T)$ is the Case C final value, and $N_D$ is the Case D number of accepted steps. For example, a valid printed line looks like\n$$\n[\\;0.123456,\\;0.99999,\\;-0.00001,\\;0.98765,\\;42\\;].\n$$", "solution": "The problem is to construct and implement a numerical solver for an initial value problem (IVP) of a first-order ordinary differential equation (ODE). The IVP is defined as\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0.\n$$\nThe solver must employ an adaptive step-size strategy based on a predictor-corrector scheme. The scheme specified is a forward Euler predictor coupled with a second-order Adams-Moulton corrector, which is the implicit trapezoidal rule.\n\nThe fundamental principle is the integral form of the ODE, which relates the solution at time $t_n$ to the solution at $t_{n+1} = t_n + h_n$:\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, ds.\n$$\n\nThe specified predictor-corrector algorithm proceeds in two stages for each step from $t_n$ to $t_{n+1}$:\n\n1.  **Predictor Step**: An explicit forward Euler method is used to generate a first estimate of the solution at $t_{n+1}$, denoted $y_{n+1}^p$. This method approximates the integral by assuming the integrand $f(s, y(s))$ is constant over the interval $[t_n, t_{n+1}]$ and equal to its value at the start of the interval, $f(t_n, y_n)$.\n    $$\n    y_{n+1}^p = y_n + h_n f(t_n, y_n).\n    $$\n    This is a first-order accurate prediction.\n\n2.  **Corrector Step**: The trapezoidal rule is used to obtain a more accurate, corrected value, $y_{n+1}^c$. This rule approximates the integral by the area of a trapezoid formed by a linear interpolant between $f(t_n, y_n)$ and $f(t_{n+1}, y_{n+1})$. To avoid solving a nonlinear implicit equation for $y_{n+1}$, the predicted value $y_{n+1}^p$ is used to evaluate the function at the end of the interval, $f(t_{n+1}, y_{n+1}^p)$.\n    $$\n    y_{n+1}^c = y_n + \\frac{h_n}{2} \\left[ f(t_n, y_n) + f(t_{n+1}, y_{n+1}^p) \\right].\n    $$\n    This is a second-order accurate correction. The value $y_{n+1}^c$ is accepted as the final approximation for the step, $y_{n+1} = y_{n+1}^c$, provided the error criterion is met.\n\nThe core of the adaptive algorithm is the step-size controller, which relies on an estimate of the local error. The problem defines a specific error indicator, $e_n$, for the step from $t_n$ to $t_{n+1}$:\n$$\ne_n = \\frac{\\|y_{n+1}^p - y_{n+1}^c\\|}{h_n},\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm for vectors or the absolute value for scalars. This indicator must be controlled to remain below a specified tolerance, $\\text{tol}$.\n\nThe local truncation error of the first-order predictor is $O(h_n^2)$, while the local truncation error of the second-order corrector is $O(h_n^3)$. The difference between the predictor and corrector values, $y_{n+1}^c - y_{n+1}^p$, is an estimate of the error in the predictor step and is of order $O(h_n^2)$.\n$$\n\\|y_{n+1}^p - y_{n+1}^c\\| = \\left\\| h_n f_n - \\frac{h_n}{2}(f_n + f(t_n+h_n, y_n+h_n f_n)) \\right\\| \\approx \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\|.\n$$\nTherefore, the error indicator $e_n$ is of order $O(h_n)$:\n$$\ne_n \\approx \\frac{1}{h_n} \\left\\| \\frac{h_n^2}{2} y''(t_n) \\right\\| = \\frac{h_n}{2} \\|y''(t_n)\\|.\n$$\nSince $e_n \\propto h_n$, to adjust the step size from $h_{\\text{old}}$ to $h_{\\text{new}}$ such that the new error $e_{\\text{new}}$ approximates the tolerance $\\text{tol}$, we use the relation $e_{\\text{new}}/e_{\\text{old}} \\approx h_{\\text{new}}/h_{\\text{old}}$. This gives $h_{\\text{new}} \\approx h_{\\text{old}} (\\text{tol}/e_{\\text{old}})$.\n\nThe complete adaptive step-size control logic is as follows:\n\n1.  For a step from $t_n$ to $t_{n+1}$ with a proposed step size $h$, first ensure that the integration does not proceed past the final time $T$. The actual step size used is $h_{\\text{step}} = \\min(h, T - t_n)$.\n\n2.  Calculate $y_{n+1}^p$ and $y_{n+1}^c$ using $h_{\\text{step}}$.\n\n3.  Compute the error indicator $e_n = \\|y_{n+1}^p - y_{n+1}^c\\|/h_{\\text{step}}$.\n\n4.  **Step Acceptance/Rejection**:\n    -   If $e_n \\le \\text{tol}$, the step is accepted. The new state is $(t_{n+1}, y_{n+1}) = (t_n + h_{\\text{step}}, y_{n+1}^c)$.\n    -   If $e_n > \\text{tol}$, the step is rejected. The state remains $(t_n, y_n)$, and a new, smaller step size $h$ must be computed to retry the step.\n\n5.  **Step Size Update**: The calculation of the next step size, $h_{\\text{next}}$, is based on the current step's outcome.\n    -   A safety factor $S$ (e.g., $S=0.9$) is used to provide a conservative estimate.\n    -   The update formula is $h_{\\text{new}} = h_{\\text{step}} \\times S \\times (\\frac{\\text{tol}}{e_n})$.\n    -   If $e_n=0$, the step size should be increased cautiously. A reasonable choice is to set the scaling factor $\\text{tol}/e_n$ to a maximum growth factor, for instance $5$.\n    -   To ensure stability, the change in step size is typically bounded. We enforce $h_{\\text{new}}/h_{\\text{step}} \\in [0.2, 5.0]$.\n    -   The new step size is clamped to the interval $[h_{\\min}, h_{\\max}]$.\n\n6.  **Algorithm Flow**:\n    -   If a step is accepted, $h_{\\text{next}}$ is calculated using the update rule and used as the initial guess for the subsequent step.\n    -   If a step is rejected, $h_{\\text{next}}$ is calculated and used to *retry* the current step. This loop continues until a step is accepted.\n\n7.  **Deadlock Prevention**: If a step is rejected and the required new step size $h_{\\text{next}}$ is smaller than $h_{\\min}$, or if the current step size $h_{\\text{step}}$ is already at $h_{\\min}$, the algorithm is stuck. To prevent deadlock, the step is accepted with the current result $y_{n+1}^c$ computed using $h_{\\text{step}}=h_{\\min}$. The next step will also start with $h_{\\min}$. This is a pragmatic choice to ensure forward progress, even if the error tolerance is momentarily violated.\n\nThe integration proceeds from $t_0$ to $T$ by iteratively applying this adaptive step-taking logic until $t_n=T$. The final implementation aggregates results from the four specified test cases into a single output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adaptive_am2_solver(f, t0, T, y0, tol, h0, h_min, h_max):\n    \"\"\"\n    Integrates an ODE y'(t) = f(t,y) from t0 to T with initial condition y0\n    using an adaptive 2nd-order Adams-Moulton (Trapezoidal) method.\n\n    The predictor is the Forward Euler method. The step size is adapted to keep\n    the local error per unit step below a tolerance.\n    \"\"\"\n    t = t0\n    y = np.asarray(y0, dtype=float)\n    h = h0\n\n    accepted_steps = 0\n    rejected_steps = 0\n\n    # Safety factor for step size update\n    safety_factor = 0.9\n    # Step size change limiters\n    max_growth = 5.0\n    min_shrink = 0.2\n\n    while t < T:\n        # Ensure the last step lands exactly on T\n        if t + h > T:\n            h = T - t\n\n        # Rejection loop for the current step\n        while True:\n            # Check for infinitesimal step size\n            if t + h <= t:\n                # Cannot make progress, break from all loops\n                # This can happen if h becomes smaller than machine epsilon relative to t.\n                t = T \n                break\n\n            # Predictor step (Forward Euler)\n            f_current = f(t, y)\n            y_p = y + h * f_current\n\n            # Corrector step (Trapezoidal Rule)\n            y_c = y + (h / 2.0) * (f_current + f(t + h, y_p))\n            \n            # Estimate error\n            if y.ndim == 0: # Scalar case\n                error_norm = np.abs(y_p - y_c)\n            else: # Vector case\n                error_norm = np.linalg.norm(y_p - y_c)\n            \n            # Error per unit step as defined in the problem\n            e_n = error_norm / h if h > 0 else np.inf\n            \n            # Determine if the step is accepted or rejected\n            if e_n <= tol:\n                # Step accepted\n                t += h\n                y = y_c\n                accepted_steps += 1\n                \n                # Calculate step size for the next step\n                if e_n == 0:\n                    growth_ratio = max_growth\n                else:\n                    growth_ratio = safety_factor * (tol / e_n)**1.0\n                \n                h = h * min(max_growth, max(min_shrink, growth_ratio))\n                h = min(h_max, max(h_min, h))\n                \n                break # Exit rejection loop\n            else:\n                # Step rejected\n                rejected_steps += 1\n                \n                # Propose a smaller step size for retry\n                shrink_ratio = safety_factor * (tol / e_n)**1.0\n                h_new = h * min(max_growth, max(min_shrink, shrink_ratio))\n                \n                # Deadlock prevention\n                if h <= h_min:\n                    # Current step size is at minimum, but error is too high.\n                    # Accept the step to move on.\n                    t += h\n                    y = y_c\n                    accepted_steps += 1\n                    h = h_min # Continue with h_min\n                    break # Exit rejection loop\n\n                h = max(h_min, h_new)\n\n\n    result = {\n        'y_final': y.item() if y.ndim == 0 else y,\n        'accepted_steps': accepted_steps,\n        'rejected_steps': rejected_steps,\n        'final_time': t\n    }\n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: scalar exponential decay\n        {\n            'name': 'A',\n            'f': lambda t, y: -2.0 * y,\n            't0': 0.0, 'T': 5.0,\n            'y0': 1.0,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 1.0,\n            'output': 'y_final'\n        },\n        # Case B: two-dimensional harmonic oscillator\n        {\n            'name': 'B',\n            'f': lambda t, y: np.array([y[1], -25.0 * y[0]]),\n            't0': 0.0, 'T': 2.0 * np.pi / 5.0,\n            'y0': np.array([1.0, 0.0]),\n            'tol': 1e-6,\n            'h0': 0.05, 'h_min': 1e-6, 'h_max': 0.2,\n            'output': 'y_final'\n        },\n        # Case C: scalar logistic growth\n        {\n            'name': 'C',\n            'f': lambda t, y: 3.0 * y * (1.0 - y / 1.0),\n            't0': 0.0, 'T': 5.0,\n            'y0': 0.2,\n            'tol': 1e-5,\n            'h0': 0.1, 'h_min': 1e-6, 'h_max': 0.5,\n            'output': 'y_final'\n        },\n        # Case D: edge case\n        {\n            'name': 'D',\n            'f': lambda t, y: y,\n            't0': 0.0, 'T': 1e-3,\n            'y0': 1.0,\n            'tol': 1e-10,\n            'h0': 1e-4, 'h_min': 1e-8, 'h_max': 1e-2,\n            'output': 'accepted_steps'\n        }\n    ]\n\n    results_list = []\n    for case in test_cases:\n        res = adaptive_am2_solver(\n            case['f'], case['t0'], case['T'], case['y0'],\n            case['tol'], case['h0'], case['h_min'], case['h_max']\n        )\n        output_val = res[case['output']]\n        \n        if isinstance(output_val, np.ndarray):\n            results_list.extend(output_val.tolist())\n        else:\n            results_list.append(output_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results_list))}]\")\n\nsolve()\n```", "id": "2371573"}]}