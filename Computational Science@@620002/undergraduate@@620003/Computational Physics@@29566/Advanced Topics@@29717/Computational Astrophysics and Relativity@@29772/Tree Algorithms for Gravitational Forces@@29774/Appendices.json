{"hands_on_practices": [{"introduction": "This first practice puts theory into action by tasking you with building a complete two-dimensional gravitational $N$-body simulation from the ground up. You will implement the Barnes-Hut quadtree algorithm to approximate forces and a symplectic leapfrog scheme to integrate particle orbits in a protoplanetary disk. By tracking the total angular momentum $L_z$, a fundamental conserved quantity, you will gain an intuitive understanding of how algorithmic parameters like the opening angle $\\theta$ and the time step $\\Delta t$ affect the trade-off between simulation accuracy and computational efficiency [@problem_id:2447325].", "problem": "Implement a two-dimensional gravitational $N$-body simulator using a Barnes–Hut (BH) quadtree to approximate forces in a rotating protoplanetary disk and track the total angular momentum over time to analyze its conservation. Work entirely in dimensionless \"code units\" with gravitational constant $G=1$, so no physical units are required. All angular measures must be in radians. Your task is to design and implement the complete algorithm from first principles, beginning from fundamental laws and core definitions, without relying on any prepackaged $N$-body routines.\n\nThe simulation domain consists of a central star and a surrounding disk of particles:\n- The central star has mass $M_{\\star}$ placed initially at the origin.\n- The disk has total mass $M_{\\mathrm{disk}}$ distributed among $N_{\\mathrm{disk}}$ equal-mass particles sampled in an annulus with inner radius $r_{\\min}$ and outer radius $r_{\\max}$, with radial probability density proportional to $r$ on $[r_{\\min}, r_{\\max}]$ and uniform angle in $[0,2\\pi)$.\n- The initial velocity of each disk particle is tangential and set to the circular speed generated by the central star alone, so that $v(r) = \\sqrt{G M_{\\star} / r}$ with direction perpendicular to the radius vector, consistent with prograde rotation. The star’s initial velocity is zero.\n\nFundamental base:\n- Newton’s second law: $m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$.\n- Newton’s law of universal gravitation for point masses with Plummer softening: for particles $i \\neq j$, the acceleration on $i$ due to $j$ is\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, .\n$$\n- Total angular momentum about the origin in two dimensions (the $z$-component) is\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) \\, .\n$$\n\nAlgorithmic requirements:\n- Use a Barnes–Hut quadtree (define acronym on first use) in two dimensions. Each tree node stores total mass and center of mass. Use the geometric acceptance criterion that treats a node of side length $s$ at center-of-mass distance $d$ from the target particle as a single source when $s/d < \\theta$, where $\\theta$ is the opening angle parameter. If not accepted, recurse into children. For leaf nodes, sum direct pairwise softened contributions, excluding self-interaction.\n- Use a symplectic leapfrog (kick–drift–kick) time integrator with fixed time step $\\Delta t$:\n  $$\n  \\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n  \\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n  \\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n  $$\n- Track the initial angular momentum $L_z(0)$ and the final angular momentum $L_z(T)$ at the end of the integration interval $T = n_{\\mathrm{steps}} \\, \\Delta t$. Report the relative drift (dimensionless) defined by\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\nImplementation details and constraints:\n- Use a deterministic random number generator seed for initial condition generation so that results are reproducible.\n- Construct the root quadtree cell to enclose all particles, and subdivide as needed. Prevent pathological infinite subdivision by allowing a small maximum depth and switching to direct summation within an over-refined leaf.\n- Ensure that the tree is rebuilt at each time step when computing forces.\n- The program must not read input. It must generate the specified test cases internally and print the results.\n\nTest suite:\nCommon parameters for all tests:\n- $G = 1$, $M_{\\star} = 10$, $M_{\\mathrm{disk}} = 1$, $N_{\\mathrm{disk}} = 128$, $r_{\\min} = 0.5$, $r_{\\max} = 2.5$, deterministic seed $= 42$, total number of particles $N = N_{\\mathrm{disk}} + 1$.\n- The initial conditions must be regenerated identically for each test so that only algorithmic parameters differ.\n\nEach test case specifies $(\\theta, \\Delta t, n_{\\mathrm{steps}}, \\epsilon)$:\n- Test $1$ (happy path): $(\\theta = 0.5, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$.\n- Test $2$ (stricter opening; boundary toward direct summation): $(\\theta = 0.2, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$.\n- Test $3$ (looser opening; larger approximation error): $(\\theta = 1.0, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$.\n- Test $4$ (coarser time step; integrator stress test): $(\\theta = 0.5, \\ \\Delta t = 0.02, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$.\n\nFor each test, compute the scalar $\\delta_L$ defined above. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[0.00123,0.00045,0.00321,0.00456]$), in the order of Tests $1$ through $4$. The outputs are dimensionless real numbers. Angles must be in radians throughout. No additional text may be printed.", "solution": "We design the solution from first principles. Begin with Newton’s second law $m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$. For a system of $N$ point masses interacting gravitationally, Newton’s law of universal gravitation gives the pairwise force $\\mathbf{F}_{ij}$ on $i$ by $j$. Dividing by $m_i$ yields the acceleration\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, ,\n$$\nwhere $\\epsilon$ is a small Plummer softening length introduced to regularize the singularity at zero separation and to model finite-sized mass elements. Summing over all $j \\neq i$ yields the net acceleration $\\mathbf{a}_i$.\n\nDefine the total angular momentum about the origin for a two-dimensional system by its $z$-component:\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{v}_i)_z \\, .\n$$\nTaking a time derivative gives\n$$\n\\frac{dL_z}{dt} = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{a}_i)_z \\, .\n$$\nFor exact Newtonian gravity with pairwise central forces, internal torques cancel in pairs by Newton’s third law (equal and opposite forces along the line of centers), implying $\\frac{dL_z}{dt} = 0$ and conservation of total angular momentum in the absence of external torques. Numerical approximations can introduce violations of action–reaction symmetry and time integration error, leading to small drifts $\\delta_L$.\n\nDirect summation of all pairwise interactions costs $\\mathcal{O}(N^2)$ per force evaluation. The Barnes–Hut (BH) algorithm organizes particles into a hierarchical quadtree in two dimensions. Each node represents a square region and stores the total mass and center of mass of the particles inside. For a target particle at position $\\mathbf{r}$ and a tree node of side length $s$ whose center of mass is at distance $d$ from $\\mathbf{r}$, the monopole approximation treats the entire node as a single pseudo-particle located at its center of mass when\n$$\n\\frac{s}{d} < \\theta \\, ,\n$$\nwhere $\\theta$ is the opening angle parameter controlling accuracy–efficiency trade-off. If the criterion is not satisfied, the node is “opened” and we recurse into its children. For a leaf, we compute direct softened contributions from its contained particles, excluding self-interaction. The monopole truncation error scales as $\\mathcal{O}\\!\\left((s/d)^2\\right)$ for well-separated groups, so decreasing $\\theta$ improves accuracy and reduces systematic force asymmetries that can cause angular momentum drift.\n\nTime integration uses the symplectic leapfrog (kick–drift–kick) method, which is time-reversible and exhibits superior long-term conservation properties for Hamiltonian systems. Given time step $\\Delta t$, the update is:\n$$\n\\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n\\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n\\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n$$\nThis scheme requires one force evaluation at the beginning and one per step thereafter. We evaluate forces with the BH tree using the chosen $\\theta$ and softening $\\epsilon$.\n\nInitial conditions model a protoplanetary disk in code units. The central star of mass $M_{\\star}$ is at the origin with zero velocity. The disk of total mass $M_{\\mathrm{disk}}$ is represented by $N_{\\mathrm{disk}}$ equal-mass particles sampled in an annulus $[r_{\\min}, r_{\\max}]$, with radial probability density proportional to $r$ to achieve an area-uniform distribution in the annulus. A sample can be drawn by transforming a uniform variate $u \\in [0,1]$ into radius\n$$\nr = \\sqrt{u \\, (r_{\\max}^2 - r_{\\min}^2) + r_{\\min}^2} \\, ,\n$$\nand angle $\\phi$ uniform on $[0, 2\\pi)$. Each disk particle begins on a circular orbit around the star with speed $v(r) = \\sqrt{G M_{\\star}/r}$ in the tangential direction $\\hat{\\boldsymbol{\\phi}} = (-\\sin \\phi, \\cos \\phi)$, so that the initial state approximates a cold, near-Keplerian disk. The star’s initial velocity is zero; by symmetry, total linear momentum is near zero for a sufficiently isotropic sample.\n\nNumerical design details:\n- Tree construction: compute a bounding square containing all positions, with center and half-size slightly padded. Recursively subdivide nodes into four children (quadtree) as needed. To avoid pathological infinite subdivision for nearly coincident points, enforce a maximum depth (for example, $d_{\\max}$) and permit a leaf to store multiple bodies once the limit is reached; such leaves are summed by direct interaction.\n- Mass and center-of-mass computation: after all insertions, perform a post-order traversal to compute each node’s total mass and center of mass from its children or contained bodies.\n- Force evaluation: for a target particle, traverse the tree, applying the acceptance criterion $s/d < \\theta$. For accepted nodes, add the softened monopole acceleration. For leaves or rejected nodes, recurse or sum directly, skipping self-interaction. Use $\\epsilon$ to compute softened distances via $(r^2 + \\epsilon^2)^{3/2}$.\n- Angular momentum tracking: compute $L_z(0)$ from initial positions and velocities. Run the leapfrog integrator for $n_{\\mathrm{steps}}$ steps. After performing the final half-kick, compute $L_z(T)$ and the relative drift\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\nTest suite rationale:\n- Test $1$ ($\\theta = 0.5$, $\\Delta t = 0.01$, $n_{\\mathrm{steps}} = 40$, $\\epsilon = 0.02$) is a balanced configuration expected to yield small $\\delta_L$.\n- Test $2$ ($\\theta = 0.2$) tightens the opening angle, bringing the BH forces closer to direct summation; $\\delta_L$ should not exceed Test $1$ and typically decreases.\n- Test $3$ ($\\theta = 1.0$) loosens the criterion, increasing approximation error; $\\delta_L$ is expected to be larger than in Tests $1$–$2$.\n- Test $4$ (coarser $\\Delta t = 0.02$) stresses the time integrator, likely increasing $\\delta_L$ even with the same $\\theta$ as Test $1$.\n\nThe program regenerates identical initial conditions for each test (same seed) and runs the simulation with the specified parameters, computing the four $\\delta_L$ values. It prints a single line formatted as a Python-style list $[x_1,x_2,x_3,x_4]$, where each $x_k$ is the corresponding $\\delta_L$ for Test $k$. All outputs are dimensionless real numbers and angles are in radians throughout.", "answer": "```python\n# Barnes–Hut angular momentum conservation analysis in a rotating disk\n# Execution environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used)\nimport numpy as np\n\n# ----------------------------\n# Utility: angular momentum\n# ----------------------------\ndef angular_momentum_z(m, r, v):\n    # Lz = sum m_i (x_i v_yi - y_i v_xi)\n    return float(np.sum(m * (r[:, 0] * v[:, 1] - r[:, 1] * v[:, 0])))\n\n# ----------------------------\n# Quadtree implementation\n# ----------------------------\nclass QuadNode:\n    __slots__ = (\n        \"cx\", \"cy\", \"h\", \"children\", \"bodies\", \"mass\", \"comx\", \"comy\", \"depth\"\n    )\n\n    def __init__(self, cx, cy, h, depth=0):\n        self.cx = float(cx)\n        self.cy = float(cy)\n        self.h = float(h)  # half-size\n        self.children = None  # list of 4 QuadNode or None\n        self.bodies = []      # list of indices if leaf\n        self.mass = 0.0\n        self.comx = 0.0\n        self.comy = 0.0\n        self.depth = depth\n\n    def subdivide(self):\n        hh = 0.5 * self.h\n        d = self.depth + 1\n        self.children = [\n            QuadNode(self.cx - hh, self.cy - hh, hh, d),  # SW\n            QuadNode(self.cx + hh, self.cy - hh, hh, d),  # SE\n            QuadNode(self.cx - hh, self.cy + hh, hh, d),  # NW\n            QuadNode(self.cx + hh, self.cy + hh, hh, d),  # NE\n        ]\n\n    def which_child(self, x, y):\n        east = x > self.cx\n        north = y > self.cy\n        if not east and not north:\n            return 0  # SW\n        if east and not north:\n            return 1  # SE\n        if not east and north:\n            return 2  # NW\n        return 3  # NE\n\n    def insert(self, idx, pos, max_bucket, max_depth):\n        # Insert body index idx at position pos[idx]\n        if self.children is None:\n            # Leaf: store body\n            self.bodies.append(idx)\n            # If exceeds bucket and can subdivide, split and reinsert\n            if len(self.bodies) > max_bucket and self.depth  max_depth:\n                self.subdivide()\n                old = self.bodies\n                self.bodies = []\n                for j in old:\n                    child = self.which_child(pos[j, 0], pos[j, 1])\n                    self.children[child].insert(j, pos, max_bucket, max_depth)\n        else:\n            # Internal: insert into appropriate child\n            child = self.which_child(pos[idx, 0], pos[idx, 1])\n            self.children[child].insert(idx, pos, max_bucket, max_depth)\n\n    def finalize_mass_com(self, m, pos):\n        if self.children is None:\n            if len(self.bodies) == 0:\n                self.mass = 0.0\n                self.comx = self.cx\n                self.comy = self.cy\n            elif len(self.bodies) == 1:\n                j = self.bodies[0]\n                self.mass = float(m[j])\n                self.comx = float(pos[j, 0])\n                self.comy = float(pos[j, 1])\n            else:\n                # Aggregate\n                mm = 0.0\n                cx = 0.0\n                cy = 0.0\n                for j in self.bodies:\n                    mj = float(m[j])\n                    mm += mj\n                    cx += mj * float(pos[j, 0])\n                    cy += mj * float(pos[j, 1])\n                self.mass = mm\n                if mm > 0.0:\n                    self.comx = cx / mm\n                    self.comy = cy / mm\n                else:\n                    self.comx = self.cx\n                    self.comy = self.cy\n        else:\n            mm = 0.0\n            cx = 0.0\n            cy = 0.0\n            for ch in self.children:\n                ch.finalize_mass_com(m, pos)\n                mm += ch.mass\n                cx += ch.mass * ch.comx\n                cy += ch.mass * ch.comy\n            self.mass = mm\n            if mm > 0.0:\n                self.comx = cx / mm\n                self.comy = cy / mm\n            else:\n                self.comx = self.cx\n                self.comy = self.cy\n\n    def acc_on(self, i, pos, m, G, theta, eps2):\n        ax = 0.0\n        ay = 0.0\n        if self.mass == 0.0:\n            return 0.0, 0.0\n\n        # Distance from particle i to node COM\n        dx = self.comx - pos[i, 0]\n        dy = self.comy - pos[i, 1]\n        d2 = dx * dx + dy * dy\n\n        if self.children is None:\n            # Leaf: direct sum over contained bodies excluding self\n            for j in self.bodies:\n                if j == i:\n                    continue\n                rx = pos[j, 0] - pos[i, 0]\n                ry = pos[j, 1] - pos[i, 1]\n                r2 = rx * rx + ry * ry + eps2\n                invr3 = 1.0 / (r2 * np.sqrt(r2))\n                s = G * float(m[j]) * invr3\n                ax += s * rx\n                ay += s * ry\n            return ax, ay\n\n        # Internal node: apply BH acceptance criterion\n        # side length s = 2h\n        if d2 > 0.0:\n            s_over_d = (2.0 * self.h) / np.sqrt(d2)\n        else:\n            s_over_d = np.inf\n\n        if s_over_d  theta:\n            # Accept node as single source\n            r2 = d2 + eps2\n            invr3 = 1.0 / (r2 * np.sqrt(r2))\n            s = G * self.mass * invr3\n            ax += s * dx\n            ay += s * dy\n        else:\n            # Recurse into children\n            for ch in self.children:\n                cx, cy = ch.acc_on(i, pos, m, G, theta, eps2)\n                ax += cx\n                ay += cy\n        return ax, ay\n\n# ----------------------------\n# Force computation via BH\n# ----------------------------\ndef compute_accelerations(pos, m, theta, eps, max_bucket=1, max_depth=20):\n    N = pos.shape[0]\n    # Build bounding square\n    xmin = float(np.min(pos[:, 0]))\n    xmax = float(np.max(pos[:, 0]))\n    ymin = float(np.min(pos[:, 1]))\n    ymax = float(np.max(pos[:, 1]))\n    cx = 0.5 * (xmin + xmax)\n    cy = 0.5 * (ymin + ymax)\n    half = max(xmax - xmin, ymax - ymin) * 0.5\n    if half = 0.0:\n        half = 1.0\n    half *= 1.05  # small padding\n\n    root = QuadNode(cx, cy, half, depth=0)\n    for i in range(N):\n        root.insert(i, pos, max_bucket, max_depth)\n    root.finalize_mass_com(m, pos)\n\n    G = 1.0\n    eps2 = float(eps) * float(eps)\n    acc = np.zeros_like(pos)\n    for i in range(N):\n        ax, ay = root.acc_on(i, pos, m, G, theta, eps2)\n        acc[i, 0] = ax\n        acc[i, 1] = ay\n    return acc\n\n# ----------------------------\n# Leapfrog integrator (KDK)\n# ----------------------------\ndef leapfrog_bh(pos0, vel0, m, dt, nsteps, theta, eps):\n    pos = pos0.copy()\n    vel = vel0.copy()\n\n    # Initial angular momentum (using velocities at integer time)\n    L0 = angular_momentum_z(m, pos, vel)\n\n    # Initial acceleration and half kick\n    acc = compute_accelerations(pos, m, theta, eps)\n    vel += 0.5 * dt * acc\n\n    # Time stepping\n    for step in range(nsteps):\n        pos += dt * vel\n        acc = compute_accelerations(pos, m, theta, eps)\n        if step != nsteps - 1:\n            vel += dt * acc\n\n    # Final half kick\n    vel += 0.5 * dt * acc\n\n    Lf = angular_momentum_z(m, pos, vel)\n    rel_drift = abs(Lf - L0) / max(1e-16, abs(L0))\n    return rel_drift\n\n# ----------------------------\n# Initial conditions: rotating disk + central star\n# ----------------------------\ndef generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax):\n    rng = np.random.default_rng(seed)\n    # Star at origin\n    pos_star = np.array([[0.0, 0.0]])\n    vel_star = np.array([[0.0, 0.0]])\n    m_star = np.array([M_star], dtype=float)\n\n    # Disk sampling: radial PDF ∝ r on [rmin, rmax]\n    u = rng.random(N_disk)\n    radii = np.sqrt(u * (rmax * rmax - rmin * rmin) + rmin * rmin)\n    phi = rng.random(N_disk) * (2.0 * np.pi)\n    x = radii * np.cos(phi)\n    y = radii * np.sin(phi)\n    pos_disk = np.column_stack((x, y))\n\n    # Tangential velocity for circular orbit due to star alone\n    G = 1.0\n    v_mag = np.sqrt(G * M_star / np.maximum(radii, 1e-12))\n    vx = -v_mag * np.sin(phi)\n    vy =  v_mag * np.cos(phi)\n    vel_disk = np.column_stack((vx, vy))\n\n    # Masses\n    m_disk = np.full(N_disk, M_disk / N_disk, dtype=float)\n\n    # Combine star + disk\n    pos = np.vstack((pos_star, pos_disk))\n    vel = np.vstack((vel_star, vel_disk))\n    m = np.concatenate((m_star, m_disk))\n    return pos, vel, m\n\n# ----------------------------\n# Main solve function\n# ----------------------------\ndef solve():\n    # Common parameters\n    G = 1.0  # code units\n    M_star = 10.0\n    M_disk = 1.0\n    N_disk = 128\n    rmin = 0.5\n    rmax = 2.5\n    seed = 42\n\n    # Test suite: (theta, dt, nsteps, eps)\n    test_cases = [\n        (0.5, 0.01, 40, 0.02),  # Test 1: happy path\n        (0.2, 0.01, 40, 0.02),  # Test 2: stricter opening\n        (1.0, 0.01, 40, 0.02),  # Test 3: looser opening\n        (0.5, 0.02, 40, 0.02),  # Test 4: coarser time step\n    ]\n\n    # Generate identical initial conditions for each test\n    pos0, vel0, m = generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax)\n\n    results = []\n    for theta, dt, nsteps, eps in test_cases:\n        # Copy initial conditions so each test starts identically\n        pos = pos0.copy()\n        vel = vel0.copy()\n        rel_drift = leapfrog_bh(pos, vel, m, dt, nsteps, theta, eps)\n        # format with reasonable precision\n        results.append(rel_drift)\n\n    # Print in the exact required format\n    # Use repr-like formatting for clarity without extra text\n    print(f\"[{','.join(f'{x:.8g}' for x in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2447325"}, {"introduction": "Moving beyond simple force calculations, this exercise challenges you to extend the tree-code framework to compute the gravitational tidal tensor, $T_{ij} = \\partial a_i / \\partial x_j$. This involves adapting the monopole approximation to calculate not just the force vector $\\mathbf{a}$ but also its spatial derivatives. This practice cultivates a deeper understanding of gravitational fields and the error characteristics of tree algorithms, as you will directly compare the approximation accuracy for both a vector field and its corresponding tensor field [@problem_id:2447281].", "problem": "You are given a three-dimensional system of $N$ point masses at positions $\\{\\mathbf{r}_k\\}_{k=1}^N \\subset \\mathbb{R}^3$ with positive masses $\\{m_k\\}_{k=1}^N$. Work in code units with gravitational constant $G = 1$ and use Plummer softening with softening length $\\varepsilon  0$. The gravitational potential at position $\\mathbf{x} \\in \\mathbb{R}^3$ is\n$$\n\\Phi(\\mathbf{x}) \\;=\\; -\\sum_{k=1}^N \\frac{m_k}{\\sqrt{\\|\\mathbf{x}-\\mathbf{r}_k\\|^2 + \\varepsilon^2}} \\, .\n$$\nDefine the gravitational force per unit test mass (acceleration) by $\\mathbf{a}(\\mathbf{x}) = -\\nabla \\Phi(\\mathbf{x})$, and define the tidal tensor by $T(\\mathbf{x}) = \\nabla \\mathbf{a}(\\mathbf{x})$, i.e., the Jacobian matrix with components $T_{ij}(\\mathbf{x}) = \\partial a_i(\\mathbf{x})/\\partial x_j$.\n\nConsider the following approximation rule for grouping sources. For any subset $S \\subset \\{1,\\dots,N\\}$, let $M_S = \\sum_{k \\in S} m_k$ be its total mass, let $\\mathbf{c}_S = \\left(\\sum_{k \\in S} m_k \\mathbf{r}_k\\right) / M_S$ be its center of mass, and let $L_S  0$ be the side length of an axis-aligned cubic bounding box that contains $\\{\\mathbf{r}_k\\}_{k \\in S}$. For a target $\\mathbf{x}$ and an opening parameter $\\theta \\in (0,1)$, the contribution of $S$ may be approximated by treating the subset as a single point mass $M_S$ at $\\mathbf{c}_S$ if and only if\n$$\n\\frac{L_S}{\\|\\mathbf{x} - \\mathbf{c}_S\\|} \\;\\le\\; \\theta \\, .\n$$\nOtherwise, $S$ must be partitioned into disjoint proper subsets, and the same rule applied recursively until every contributing subset satisfies the acceptance inequality or consists of a single source.\n\nYour task is to write a complete, runnable program that, for each test case specified below:\n- computes the exact (direct-sum) $\\mathbf{a}(\\mathbf{x})$ and $T(\\mathbf{x})$ at each listed target $\\mathbf{x}$,\n- computes the approximate grouped-sum $\\mathbf{a}(\\mathbf{x})$ and $T(\\mathbf{x})$ at each listed target $\\mathbf{x}$ according to the acceptance rule above, and\n- reports, for each test case, two real numbers:\n  1. the maximum relative error over the provided targets in the acceleration, measured as $\\max_{\\mathbf{x}} \\|\\mathbf{a}_{\\mathrm{approx}}(\\mathbf{x}) - \\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2 \\,/\\, \\|\\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2$,\n  2. the maximum relative error over the provided targets in the tidal tensor, measured as $\\max_{\\mathbf{x}} \\|T_{\\mathrm{approx}}(\\mathbf{x}) - T_{\\mathrm{exact}}(\\mathbf{x})\\|_F \\,/\\, \\|T_{\\mathrm{exact}}(\\mathbf{x})\\|_F$, where $\\|\\cdot\\|_F$ is the Frobenius norm.\n\nAll computations are dimensionless in these code units; report the final errors as pure real numbers (no units). Angles do not appear. There are no percentages; all results are real numbers.\n\nUse the following test suite. For each test case, the program must use the given opening parameter $\\theta$ and softening length $\\varepsilon$, evaluate at the listed targets, and use the exact same source data.\n\nTest case $1$ (cluster at cube corners; general case):\n- Sources: masses and positions\n  - $m = [\\,1.0,\\, 2.0,\\, 3.0,\\, 4.0,\\, 1.5,\\, 0.5,\\, 0.8,\\, 2.5\\,]$,\n  - $\\mathbf{r} = [\\,(-1.0,-1.0,-1.0),\\; (1.0,-1.0,-1.0),\\; (-1.0,1.0,-1.0),\\; (1.0,1.0,-1.0),\\; (-1.0,-1.0,1.0),\\; (1.0,-1.0,1.0),\\; (-1.0,1.0,1.0),\\; (1.0,1.0,1.0)\\,]$.\n- Targets:\n  - $\\mathbf{x}_1 = (\\,0.3,\\, 0.2,\\, 0.1\\,)$,\n  - $\\mathbf{x}_2 = (\\,-0.4,\\, 0.5,\\, -0.2\\,)$,\n  - $\\mathbf{x}_3 = (\\,0.7,\\, -0.6,\\, 0.4\\,)$.\n- Parameters: $\\theta = 0.5$, $\\varepsilon = 0.01$.\n\nTest case $2$ (compact cluster; far-field targets):\n- Sources: masses and positions\n  - $m = [\\,5.0,\\, 3.0,\\, 4.0,\\, 2.0\\,]$,\n  - $\\mathbf{r} = [\\,(0.02,\\,-0.01,\\,0.03),\\; (-0.03,\\,0.01,\\,-0.02),\\; (0.01,\\,0.02,\\,-0.01),\\; (-0.02,\\,-0.02,\\,0.02)\\,]$.\n- Targets:\n  - $\\mathbf{x}_1 = (\\,10.0,\\, -9.0,\\, 8.0\\,)$,\n  - $\\mathbf{x}_2 = (\\,15.0,\\, 15.0,\\, -20.0\\,)$.\n- Parameters: $\\theta = 0.7$, $\\varepsilon = 0.001$.\n\nTest case $3$ (near-field and cancellation-sensitive geometry):\n- Sources: masses and positions\n  - $m = [\\,1.0,\\, 1.0,\\, 0.3\\,]$,\n  - $\\mathbf{r} = [\\,(-0.2,\\, 0.0,\\, 0.0),\\; (0.2,\\, 0.0,\\, 0.0),\\; (0.05,\\, 0.04,\\, 0.0)\\,]$.\n- Targets:\n  - $\\mathbf{x}_1 = (\\,0.05,\\, 0.0,\\, 0.0\\,)$,\n  - $\\mathbf{x}_2 = (\\,0.0,\\, 0.05,\\, 0.0\\,)$.\n- Parameters: $\\theta = 0.3$, $\\varepsilon = 0.05$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $6$ floating-point numbers ordered as\n$$\n[\\;E^{(1)}_{\\mathrm{acc}},\\; E^{(1)}_{\\mathrm{tid}},\\; E^{(2)}_{\\mathrm{acc}},\\; E^{(2)}_{\\mathrm{tid}},\\; E^{(3)}_{\\mathrm{acc}},\\; E^{(3)}_{\\mathrm{tid}}\\;] \\, ,\n$$\nwhere $E^{(t)}_{\\mathrm{acc}}$ is the maximum relative error in acceleration for test case $t$ and $E^{(t)}_{\\mathrm{tid}}$ is the maximum relative error in the tidal tensor for test case $t$. Each number in the output must be rounded to exactly $6$ digits after the decimal point. For example, a valid output would look like\n$$\n[\\,0.001234,0.045678,0.000012,0.000345,0.056789,0.012345\\,] \\, .\n$$", "solution": "The problem is scientifically grounded, objective, and well-posed, contingent on a standard interpretation of the recursive partitioning scheme. I will proceed with the solution under the assumption that the partitioning of a set of sources within an axis-aligned cubic bounding box is achieved via a standard octree decomposition, where the box is subdivided into eight equal cubic octants. This is the canonical approach for tree algorithms in three dimensions and is strongly suggested by the problem's reference to a cubic bounding box and recursive partitioning.\n\nThe problem requires the computation of gravitational acceleration and the tidal tensor for a system of $N$ point masses, both exactly via direct summation and approximately using a tree-based algorithm.\n\nFirst, we establish the analytical expressions for the required physical quantities. The gravitational potential with Plummer softening is given as:\n$$\n\\Phi(\\mathbf{x}) = -\\sum_{k=1}^N \\frac{m_k}{\\sqrt{\\|\\mathbf{x}-\\mathbf{r}_k\\|^2 + \\varepsilon^2}}\n$$\nwhere $m_k$ is the mass of the $k$-th particle, $\\mathbf{r}_k$ is its position, $\\mathbf{x}$ is the evaluation point, and $\\varepsilon$ is the softening length. For brevity, let $\\Delta\\mathbf{r}_k = \\mathbf{x} - \\mathbf{r}_k$ and let $d_k = \\sqrt{\\|\\Delta\\mathbf{r}_k\\|^2 + \\varepsilon^2}$.\n\nThe gravitational acceleration $\\mathbf{a}(\\mathbf{x})$ is the negative gradient of the potential:\n$$\n\\mathbf{a}(\\mathbf{x}) = -\\nabla\\Phi(\\mathbf{x}) = -\\sum_{k=1}^N \\nabla\\left(-\\frac{m_k}{d_k}\\right) = \\sum_{k=1}^N m_k \\nabla(d_k^{-1})\n$$\nThe gradient of $d_k^{-1}$ is $\\nabla(d_k^{-1}) = -d_k^{-2} \\nabla d_k$. Since $\\nabla d_k = d_k^{-1} \\Delta\\mathbf{r}_k$, this simplifies to $\\nabla(d_k^{-1}) = -d_k^{-3} \\Delta\\mathbf{r}_k$.\nThus, the acceleration is:\n$$\n\\mathbf{a}(\\mathbf{x}) = -\\sum_{k=1}^N m_k \\frac{\\mathbf{x} - \\mathbf{r}_k}{\\left(\\|\\mathbf{x} - \\mathbf{r}_k\\|^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n\nThe tidal tensor $T(\\mathbf{x})$ is the Jacobian of the acceleration, $T_{ij}(\\mathbf{x}) = \\partial a_i(\\mathbf{x}) / \\partial x_j$. This is equivalent to the negative Hessian of the potential, $T_{ij}(\\mathbf{x}) = -\\partial^2\\Phi(\\mathbf{x}) / \\partial x_i \\partial x_j$.\nWe compute the components $T_{ij}^{(k)}$ for a single particle $k$:\n$$\nT_{ij}^{(k)}(\\mathbf{x}) = -\\frac{\\partial}{\\partial x_j} \\left( -m_k \\frac{(\\Delta r_k)_i}{d_k^3} \\right) = m_k \\frac{\\partial}{\\partial x_j} \\left( (\\Delta r_k)_i d_k^{-3} \\right)\n$$\nUsing the product rule:\n$$\nT_{ij}^{(k)} = m_k \\left( \\frac{\\partial (\\Delta r_k)_i}{\\partial x_j} d_k^{-3} + (\\Delta r_k)_i \\frac{\\partial d_k^{-3}}{\\partial x_j} \\right) = m_k \\left( \\delta_{ij} d_k^{-3} - 3 (\\Delta r_k)_i d_k^{-5} (\\Delta r_k)_j \\right)\n$$\nwhere $\\delta_{ij}$ is the Kronecker delta. The total tidal tensor is $T(\\mathbf{x}) = \\sum_k T^{(k)}(\\mathbf{x})$. In matrix form, the contribution from particle $k$ is:\n$$\nT^{(k)}(\\mathbf{x}) = \\frac{m_k}{d_k^5} \\left( d_k^2 I - 3 (\\Delta\\mathbf{r}_k \\otimes \\Delta\\mathbf{r}_k) \\right)\n$$\nThis expression is incorrect; the sign is reversed from the derivation of the acceleration. Let's re-verify. $\\mathbf{a}=-\\nabla\\Phi$. $T=\\nabla\\mathbf{a} = -\\nabla\\nabla\\Phi$.\n$a_i = -\\partial_i\\Phi$. $T_{ij} = \\partial_j a_i = -\\partial_j\\partial_i\\Phi$.\n$-\\partial_j\\partial_i\\Phi = -\\partial_j (m_k d_k^{-3}(\\Delta r_k)_i) = -m_k [ \\delta_{ij}d_k^{-3} + (\\Delta r_k)_i (-3 d_k^{-5})(\\Delta r_k)_j ] = m_k[ 3 d_k^{-5} (\\Delta r_k)_i (\\Delta r_k)_j - d_k^{-3}\\delta_{ij}]$.\nIn matrix notation:\n$$\nT^{(k)}(\\mathbf{x}) = \\frac{m_k}{d_k^5} \\left( 3 (\\Delta\\mathbf{r}_k \\otimes \\Delta\\mathbf{r}_k) - d_k^2 I \\right)\n$$\nwhere $I$ is the $3 \\times 3$ identity matrix and $\\otimes$ denotes the outer product. This is the correct form.\n\nThe exact calculation involves summing these contributions for all $N$ particles for each target point $\\mathbf{x}$.\n\nThe approximate calculation is based on a tree-code method. An octree data structure is built to spatially organize the particles.\n1.  **Tree Construction**: An initial cubic bounding box enclosing all particles is defined. This forms the root node of the octree. Each particle is then inserted recursively. When a particle is inserted into a node that already contains a particle, the node becomes an internal node, its cell is subdivided into eight octants (children), and both the old and new particles are passed down to the appropriate children. This process continues until each leaf node contains exactly one particle. During this process, each internal node stores the total mass $M_S$ and center of mass $\\mathbf{c}_S$ of all particles contained within its subtree.\n\n2.  **Force  Tide Approximation**: For a given target point $\\mathbf{x}$, the tree is traversed starting from the root. At each node $S$, the monopole acceptance criterion (MAC) is evaluated:\n    $$\n    \\frac{L_S}{\\|\\mathbf{x} - \\mathbf{c}_S\\|} \\le \\theta\n    $$\n    Here, $L_S$ is the side length of the node's cubic cell and $\\theta$ is the opening parameter.\n    -   If the criterion is met, the gravitational contribution of the entire group of particles $S$ is approximated by a single-particle interaction using the node's total mass $M_S$ and center of mass $\\mathbf{c}_S$. The traversal does not proceed to its children.\n    -   If the criterion is not met, the node is \"opened,\" and the traversal continues recursively to each of its children.\n    -   If a leaf node is reached (which cannot be opened further), its contribution is calculated exactly using the single particle it contains.\n\nThis adaptive method ensures that distant groups of particles are approximated, while nearby particles are resolved individually, balancing accuracy and computational cost.\n\nThe error is quantified by the maximum relative error over all targets for a given test case. For acceleration, the metric is the relative L2-norm error. For the tidal tensor, it is the relative Frobenius norm error:\n$$\nE_{\\mathrm{acc}} = \\max_{\\mathbf{x}} \\frac{\\|\\mathbf{a}_{\\mathrm{approx}}(\\mathbf{x}) - \\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2}{\\|\\mathbf{a}_{\\mathrm{exact}}(\\mathbf{x})\\|_2}\n$$\n$$\nE_{\\mathrm{tid}} = \\max_{\\mathbf{x}} \\frac{\\|T_{\\mathrm{approx}}(\\mathbf{x}) - T_{\\mathrm{exact}}(\\mathbf{x})\\|_F}{\\|T_{\\mathrm{exact}}(\\mathbf{x})\\|_F}\n$$\n\nThe provided code implements this entire procedure. It defines a `Node` class for the octree, functions for tree construction, and functions for calculating exact and approximate interactions. It iterates through each test case, builds the tree, evaluates forces and tides at each target point, computes the errors, and reports the final results in the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No other library imports are permitted.\n\nclass Node:\n    \"\"\"A node in the octree.\"\"\"\n    def __init__(self, center, size):\n        self.center = center  # Geometric center of the node's cube\n        self.size = size      # Side length of the node's cube\n        \n        # Aggregate properties for monopole approximation\n        self.mass = 0.0\n        self.com = np.zeros(3)  # Center of mass\n        \n        # Children nodes (for internal nodes)\n        self.children = None\n        \n        # Particle index (for leaf nodes)\n        self.particle_index = -1\n\n    def is_leaf(self):\n        return self.children is None\n\ndef _get_octant(position, center):\n    \"\"\"Determine which of the 8 octants a position belongs to.\"\"\"\n    octant = 0\n    if position[0] >= center[0]: octant |= 1  # x-axis\n    if position[1] >= center[1]: octant |= 2  # y-axis\n    if position[2] >= center[2]: octant |= 4  # z-axis\n    return octant\n\ndef _insert_particle(node, particle_pos, particle_mass, particle_idx, positions, masses):\n    \"\"\"Recursively insert a particle into the octree.\"\"\"\n    # Update aggregate properties of the node\n    new_total_mass = node.mass + particle_mass\n    node.com = (node.com * node.mass + particle_pos * particle_mass) / new_total_mass\n    node.mass = new_total_mass\n\n    # If node is an internal node, pass particle down to the correct child\n    if not node.is_leaf():\n        octant = _get_octant(particle_pos, node.center)\n        _insert_particle(node.children[octant], particle_pos, particle_mass, particle_idx, positions, masses)\n        return\n\n    # If node is empty, it becomes a leaf with the new particle\n    if node.particle_index == -1:\n        node.particle_index = particle_idx\n        return\n\n    # If node is a leaf with an existing particle, it must become an internal node\n    # Create children\n    node.children = [Node(node.center + 0.5 * node.size * octant_vec, node.size * 0.5) for octant_vec in [\n        np.array([-1,-1,-1]), np.array([1,-1,-1]), np.array([-1,1,-1]), np.array([1,1,-1]),\n        np.array([-1,-1,1]), np.array([1,-1,1]), np.array([-1,1,1]), np.array([1,1,1])\n    ]]\n    \n    # Move the original particle to its new child node\n    old_particle_idx = node.particle_index\n    old_particle_pos = positions[old_particle_idx]\n    old_particle_mass = masses[old_particle_idx]\n    octant_old = _get_octant(old_particle_pos, node.center)\n    _insert_particle(node.children[octant_old], old_particle_pos, old_particle_mass, old_particle_idx, positions, masses)\n    \n    # Insert the new particle into its child node\n    octant_new = _get_octant(particle_pos, node.center)\n    _insert_particle(node.children[octant_new], particle_pos, particle_mass, particle_idx, positions, masses)\n\n    # The node is now an internal node, so clear its particle_index\n    node.particle_index = -1\n\ndef _calc_interaction(mass, pos, target_pos, epsilon):\n    \"\"\"Calculate acceleration and tidal tensor contribution from a single source.\"\"\"\n    delta_r = target_pos - pos\n    dist_sq = np.dot(delta_r, delta_r)\n    d_sq = dist_sq + epsilon**2\n    d = np.sqrt(d_sq)\n    \n    if d == 0:\n        return np.zeros(3), np.zeros((3,3))\n\n    d_inv3 = d**-3\n    accel = -mass * delta_r * d_inv3\n\n    d_inv5 = d_inv3 / d_sq\n    tidal = mass * d_inv5 * (3 * np.outer(delta_r, delta_r) - d_sq * np.eye(3))\n    \n    return accel, tidal\n\ndef compute_exact(positions, masses, target_pos, epsilon):\n    \"\"\"Compute exact acceleration and tidal tensor via direct summation.\"\"\"\n    total_accel = np.zeros(3)\n    total_tidal = np.zeros((3, 3))\n    for i in range(len(masses)):\n        accel, tidal = _calc_interaction(masses[i], positions[i], target_pos, epsilon)\n        total_accel += accel\n        total_tidal += tidal\n    return total_accel, total_tidal\n\ndef compute_approx(root, positions, masses, target_pos, epsilon, theta):\n    \"\"\"Compute approximate acceleration and tidal tensor using the octree.\"\"\"\n    total_accel = np.zeros(3)\n    total_tidal = np.zeros((3, 3))\n    \n    stack = [root]\n    \n    while stack:\n        node = stack.pop()\n        if node.mass == 0:\n            continue\n            \n        is_leaf = node.is_leaf()\n        if is_leaf:\n            # If leaf, always compute interaction directly with the particle\n            accel, tidal = _calc_interaction(node.mass, node.com, target_pos, epsilon)\n            total_accel += accel\n            total_tidal += tidal\n            continue\n        \n        # For internal nodes, apply the monopole acceptance criterion (MAC)\n        dist_to_com = np.linalg.norm(target_pos - node.com)\n        \n        if dist_to_com == 0: # Target is at center of mass, must open node\n            mac_ratio = np.inf\n        else:\n            mac_ratio = node.size / dist_to_com\n\n        if mac_ratio = theta:\n            # Node is far enough, approximate as a single point mass\n            accel, tidal = _calc_interaction(node.mass, node.com, target_pos, epsilon)\n            total_accel += accel\n            total_tidal += tidal\n        else:\n            # Node is too close, push children onto stack to resolve further\n            for child in node.children:\n                stack.append(child)\n                \n    return total_accel, total_tidal\n\ndef solve():\n    test_cases = [\n        # Test case 1\n        {\n            \"masses\": np.array([1.0, 2.0, 3.0, 4.0, 1.5, 0.5, 0.8, 2.5]),\n            \"positions\": np.array([\n                [-1.0, -1.0, -1.0], [1.0, -1.0, -1.0], [-1.0, 1.0, -1.0], [1.0, 1.0, -1.0],\n                [-1.0, -1.0, 1.0], [1.0, -1.0, 1.0], [-1.0, 1.0, 1.0], [1.0, 1.0, 1.0]\n            ]),\n            \"targets\": np.array([\n                [0.3, 0.2, 0.1], [-0.4, 0.5, -0.2], [0.7, -0.6, 0.4]\n            ]),\n            \"theta\": 0.5, \"epsilon\": 0.01\n        },\n        # Test case 2\n        {\n            \"masses\": np.array([5.0, 3.0, 4.0, 2.0]),\n            \"positions\": np.array([\n                [0.02, -0.01, 0.03], [-0.03, 0.01, -0.02],\n                [0.01, 0.02, -0.01], [-0.02, -0.02, 0.02]\n            ]),\n            \"targets\": np.array([\n                [10.0, -9.0, 8.0], [15.0, 15.0, -20.0]\n            ]),\n            \"theta\": 0.7, \"epsilon\": 0.001\n        },\n        # Test case 3\n        {\n            \"masses\": np.array([1.0, 1.0, 0.3]),\n            \"positions\": np.array([\n                [-0.2, 0.0, 0.0], [0.2, 0.0, 0.0], [0.05, 0.04, 0.0]\n            ]),\n            \"targets\": np.array([\n                [0.05, 0.0, 0.0], [0.0, 0.05, 0.0]\n            ]),\n            \"theta\": 0.3, \"epsilon\": 0.05\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        masses = case[\"masses\"]\n        positions = case[\"positions\"]\n        targets = case[\"targets\"]\n        theta = case[\"theta\"]\n        epsilon = case[\"epsilon\"]\n\n        # 1. Build the Octree\n        # Find root bounding box\n        min_coords = np.min(positions, axis=0)\n        max_coords = np.max(positions, axis=0)\n        box_center = (min_coords + max_coords) / 2.0\n        box_size = np.max(max_coords - min_coords)\n        \n        # Add a small buffer to handle particles on the boundary\n        box_size *= 1.0001 \n        \n        root = Node(box_center, box_size)\n        \n        for i in range(len(masses)):\n            _insert_particle(root, positions[i], masses[i], i, positions, masses)\n\n        # 2. Compute errors for each target\n        accel_errors = []\n        tidal_errors = []\n\n        for target_pos in targets:\n            # Exact calculation\n            a_exact, T_exact = compute_exact(positions, masses, target_pos, epsilon)\n            \n            # Approximate calculation\n            a_approx, T_approx = compute_approx(root, positions, masses, target_pos, epsilon, theta)\n\n            # Calculate norms\n            norm_a_exact = np.linalg.norm(a_exact)\n            norm_T_exact = np.linalg.norm(T_exact, 'fro')\n\n            # Avoid division by zero if exact field is zero (e.g., at a symmetry point)\n            if norm_a_exact > 0:\n                err_a = np.linalg.norm(a_approx - a_exact) / norm_a_exact\n                accel_errors.append(err_a)\n            else: # If exact is 0, error is 0 only if approx is also 0\n                accel_errors.append(np.linalg.norm(a_approx))\n                \n            if norm_T_exact > 0:\n                err_T = np.linalg.norm(T_approx - T_exact, 'fro') / norm_T_exact\n                tidal_errors.append(err_T)\n            else:\n                tidal_errors.append(np.linalg.norm(T_approx, 'fro'))\n\n        # 3. Find max error for this test case\n        max_err_a = max(accel_errors) if accel_errors else 0.0\n        max_err_T = max(tidal_errors) if tidal_errors else 0.0\n        \n        final_results.extend([max_err_a, max_err_T])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join([f'{r:.6f}' for r in final_results])}]\")\n\nsolve()\n```", "id": "2447281"}, {"introduction": "This final practice addresses a key limitation of pure tree codes and introduces a powerful optimization strategy common in high-performance simulations. You will design a hybrid algorithm that combines computationally expensive, high-accuracy direct summation for a dense central region with a fast tree-based approximation for the sparser outer region. By searching for an optimal boundary radius $R_c$ that minimizes a computational cost model subject to an accuracy constraint $E(R_c) \\le \\tau$, you will engage in the practical algorithm tuning that is essential for tackling large-scale scientific problems [@problem_id:2447320].", "problem": "You are given a set of point masses confined to a plane, with positions and equal masses deterministically specified below. The gravitational acceleration on particle $i$ due to all other particles is defined by Newton’s law with Plummer softening,\n$$\n\\mathbf{a}_i \\;=\\; G \\sum_{\\substack{j=1 \\\\ j\\neq i}}^{N} m_j \\,\\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\varepsilon^2\\right)^{3/2}},\n$$\nwhere $G$ is the gravitational constant, $m_j$ is the mass of particle $j$, $\\mathbf{r}_j \\in \\mathbb{R}^2$ is its position, $\\varepsilon$ is a softening length, and $\\lVert \\cdot \\rVert$ is the Euclidean norm. Use $G = 1$, $m_j = 1/N$ for all $j$, and $\\varepsilon = 10^{-3}$. All quantities are expressed in consistent dimensionless units; boundary radii are to be reported in the same length units as positions.\n\nDefine a hybrid evaluation operator for the full set of $N$ targets that depends on a boundary radius $R_c \\ge 0$ centered at the origin:\n- For each target with $\\lVert \\mathbf{r}_i \\rVert \\le R_c$ (the “central” region), the acceleration is evaluated by the exact direct summation of the softened Newtonian expression above over all other sources.\n- For each target with $\\lVert \\mathbfr_i \\rVert  R_c$ (the “outer” region), the acceleration is evaluated by a hierarchical tree approximation defined as follows. The domain is enclosed in a square of half-size $H$ centered at the origin, recursively subdivided into four equal squares (a quadtree) until each leaf contains at most $n_{\\text{leaf}}$ particles. Each tree node $u$ has side length $s_u$, total node mass $M_u$, and center-of-mass position $\\mathbf{R}_u$. For a target at $\\mathbf{r}$, a node $u$ is accepted as a single multipole if\n$$\n\\frac{s_u}{d_u} \\le \\theta, \\quad d_u = \\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert,\n$$\nin which case its contribution is the monopole term\n$$\n\\mathbf{a}_u(\\mathbf{r}) \\;=\\; G \\, M_u \\,\\frac{\\mathbf{R}_u - \\mathbf{r}}{\\left(\\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert^2 + \\varepsilon^2\\right)^{3/2}}.\n$$\nIf the node is not accepted, it is opened and the same rule is applied to its children; if a leaf is reached, its particles are summed by the exact softened Newtonian expression. The opening parameter $\\theta0$ and the leaf capacity $n_{\\text{leaf}} \\in \\mathbb{N}$ are given constants.\n\nFor a fixed $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}})$, the particle positions are deterministic and given by a low-discrepancy construction. For $i \\in \\{1,2,\\dots,N\\}$, define the van der Corput radical inverse in base $b \\in \\mathbb{N}$ by writing $i$ in base $b$ as $i = \\sum_{k=0}^{K} d_k b^k$ with digits $d_k \\in \\{0,1,\\dots,b-1\\}$ and setting\n$$\n\\operatorname{vdc}(i;b) \\;=\\; \\sum_{k=0}^{K} \\frac{d_k}{b^{k+1}}.\n$$\nLet\n$$\nu_i \\;=\\; \\operatorname{vdc}(i;2), \\qquad v_i \\;=\\; \\operatorname{vdc}(i;3),\n$$\nand preliminary coordinates\n$$\nx_i \\;=\\; u_i - \\tfrac{1}{2}, \\qquad y_i \\;=\\; v_i - \\tfrac{1}{2}.\n$$\nDensify the central region by mapping radius $r_i = \\sqrt{x_i^2 + y_i^2}$ to $r_i' = r_i^{\\beta}$ for a given exponent $\\beta \\ge 1$, keeping the direction:\n$$\n\\mathbf{r}_i =\n\\begin{cases}\nr_i' \\frac{(x_i, y_i)}{r_i},  \\text{if } r_i > 0, \\\\[6pt]\n(0,0),  \\text{if } r_i = 0.\n\\end{cases}\n$$\n\nFor a given $R_c$, define the hybrid acceleration $\\mathbf{a}^{\\text{hyb}}_i(R_c)$ computed by the rule above. Let the fully direct acceleration be $\\mathbf{a}^{\\text{dir}}_i$ (the exact softened Newtonian sum). Define the error metric\n$$\nE(R_c) \\;=\\; \\max_{1 \\le i \\le N} \\frac{\\lVert \\mathbf{a}^{\\text{hyb}}_i(R_c) - \\mathbf{a}^{\\text{dir}}_i \\rVert}{\\max\\!\\big(\\lVert \\mathbf{a}^{\\text{dir}}_i \\rVert,\\, a_{\\min}\\big)},\n$$\nwith $a_{\\min} = 10^{-12}$. Define the total cost model for the hybrid evaluation at $R_c$ by\n$$\nC(R_c) \\;=\\; \\mathbb{I}\\{N_{\\text{outer}}(R_c)  0\\}\\, w_{\\text{build}}\\, N \\;+\\; w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{central}}(R_c) \\;+\\; w_{\\text{cell}}\\, N_{\\text{cell}}^{\\text{outer}}(R_c) \\;+\\; w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{outer}}(R_c),\n$$\nwhere $N_{\\text{outer}}(R_c)$ is the number of targets with $\\lVert \\mathbf{r}_i \\rVert  R_c$, $N_{\\text{pair}}^{\\text{central}}(R_c)$ is the number of exact particle–particle interactions evaluated for central targets (equal to $N_{\\text{central}}(R_c)\\,(N-1)$ if each central target sums over all other sources), $N_{\\text{cell}}^{\\text{outer}}(R_c)$ is the total number of accepted particle–cell interactions used for outer targets, and $N_{\\text{pair}}^{\\text{outer}}(R_c)$ is the number of particle–particle interactions evaluated at leaves for outer targets. The indicator $\\mathbb{I}\\{\\cdot\\}$ equals $1$ if its condition is true and $0$ otherwise.\n\nYour task is to choose the boundary radius $R_c$ that minimizes $C(R_c)$ subject to the accuracy constraint $E(R_c) \\le \\tau$, where $\\tau$ is a given tolerance. Restrict the search for $R_c$ to the finite candidate set\n$$\n\\mathcal{R} \\;=\\; \\{0\\} \\,\\cup\\, \\{\\lVert \\mathbf{r}_i \\rVert: i=1,\\dots,N\\} \\,\\cup\\, \\{r_{\\max} + 10^{-12}\\},\n$$\nwhere $r_{\\max} = \\max_i \\lVert \\mathbf{r}_i \\rVert$. If multiple candidates achieve the same minimal cost within the feasible set, choose the smallest $R_c$. Use $n_{\\text{leaf}} = 8$ for the tree leaves and define the quadtree root as the smallest axis-aligned square centered at the origin with half-size\n$$\nH \\;=\\; \\max\\left(\\max_i |x_i'|, \\max_i |y_i'|\\right) + 10^{-12},\n$$\nwhere $(x_i',y_i') = \\mathbf{r}_i$.\n\nTest suite. For each of the following parameter sets $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}})$, construct the particle set as above and determine the optimal $R_c$:\n- Case $1$: $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.6,\\,0.6,\\,10^{-3},\\,20,\\,2,\\,1)$.\n- Case $2$: $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (128,\\,1.2,\\,0.5,\\,5\\times 10^{-4},\\,30,\\,1.5,\\,1)$.\n- Case $3$: $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.4,\\,0.9,\\,10^{-2},\\,10,\\,1,\\,1)$.\n- Case $4$: $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.8,\\,0.7,\\,10^{-8},\\,20,\\,2,\\,1)$.\n\nYour program must compute, for each case, the $R_c \\in \\mathcal{R}$ that minimizes $C(R_c)$ under the constraint $E(R_c) \\le \\tau$. Express each $R_c$ in the same length units as $\\mathbf{r}_i$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above, with each $R_c$ rounded to $6$ decimal places (for example, $[r_1,r_2,r_3,r_4]$). Do not print any other characters or text.", "solution": "The problem statement has been rigorously validated and is determined to be scientifically sound, objective, and well-posed. It presents a clearly defined optimization task within the domain of computational physics. We shall therefore proceed with a complete solution.\n\nThe core of the problem is to find an optimal boundary radius $R_c$ that minimizes a computational cost function $C(R_c)$ while maintaining a specified level of accuracy $E(R_c) \\le \\tau$ for an N-body gravitational simulation. The simulation employs a hybrid force evaluation scheme, combining a direct summation method for a central region with a hierarchical tree-based approximation for an outer region.\n\nFirst, we must deterministically generate the set of $N$ particle positions. For each particle $i \\in \\{1, 2, \\dots, N\\}$, we compute its preliminary coordinates $(x_i, y_i)$ using the van der Corput low-discrepancy sequence. The van der Corput sequence, or radical inverse function, for an integer $i = \\sum_{k=0}^{K} d_k b^k$ in base $b$ is given by:\n$$\n\\operatorname{vdc}(i;b) = \\sum_{k=0}^{K} \\frac{d_k}{b^{k+1}}\n$$\nWe generate $u_i = \\operatorname{vdc}(i;2)$ and $v_i = \\operatorname{vdc}(i;3)$, and set the initial coordinates to $x_i = u_i - \\frac{1}{2}$ and $y_i = v_i - \\frac{1}{2}$. These points are distributed within the square $[-\\frac{1}{2}, \\frac{1}{2}] \\times [-\\frac{1}{2}, \\frac{1}{2}]$. A radial non-linear transformation is then applied to increase the density of particles near the origin. The initial radius $r_i = \\sqrt{x_i^2 + y_i^2}$ is mapped to a new radius $r_i' = r_i^{\\beta}$ for a given exponent $\\beta \\ge 1$. The final particle position $\\mathbf{r}_i$ is obtained by scaling the original direction vector $(x_i, y_i)$ to this new radius. Specifically, if $r_i  0$, $\\mathbf{r}_i = (r_i') \\frac{(x_i, y_i)}{r_i}$; otherwise, $\\mathbf{r}_i = (0,0)$. All particles are assigned an equal mass $m_j = 1/N$ for $j=1, \\dots, N$. The gravitational constant is set to $G=1$.\n\nThe problem requires a reference calculation of gravitational acceleration, which is performed by direct summation. The acceleration on particle $i$ is calculated using a Plummer-softened Newtonian law:\n$$\n\\mathbf{a}^{\\text{dir}}_i = G \\sum_{\\substack{j=1 \\\\ j \\neq i}}^{N} m_j \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\nwhere a softening length of $\\varepsilon = 10^{-3}$ is used to prevent singularities at small particle separations. This calculation serves as the \"ground truth\" against which the hybrid method's accuracy is measured.\n\nThe hybrid evaluation method depends on a boundary radius $R_c$. For any target particle $i$ located in the central region, defined by $\\lVert \\mathbf{r}_i \\rVert \\le R_c$, its acceleration is computed using the exact direct sum $\\mathbf{a}^{\\text{dir}}_i$. For any target particle $i$ in the outer region, where $\\lVert \\mathbf{r}_i \\rVert  R_c$, its acceleration is approximated using a hierarchical quadtree method.\n\nThe quadtree algorithm begins by enclosing all particles in a root square centered at the origin. This square is recursively subdivided into four equal quadrants until each terminal node, or leaf, contains no more than a specified maximum number of particles, $n_{\\text{leaf}} = 8$. Each node $u$ in the tree stores its total mass $M_u$ and center-of-mass position $\\mathbf{R}_u$. To calculate the force on a target particle at position $\\mathbf{r}$, the tree is traversed from the root. For each node $u$, the Barnes-Hut opening criterion is applied:\n$$\n\\frac{s_u}{d_u} \\le \\theta\n$$\nwhere $s_u$ is the side length of the node's square, $d_u = \\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert$ is the distance from the target to the node's center of mass, and $\\theta$ is a given opening parameter. If the criterion is met, the collective gravitational contribution of all particles within node $u$ is approximated by a single monopole term:\n$$\n\\mathbf{a}_u(\\mathbf{r}) = G M_u \\frac{\\mathbf{R}_u - \\mathbf{r}}{\\left(\\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\nIf the criterion is not met, the node is \"opened,\" and the same procedure is applied to its children. If a leaf node is reached and must be opened, the acceleration is computed by direct summation over the individual particles it contains, excluding any self-interaction.\n\nThe goal is to find the optimal $R_c$ from a finite candidate set $\\mathcal{R} = \\{0\\} \\cup \\{\\lVert \\mathbf{r}_i \\rVert: i=1,\\dots,N\\} \\cup \\{r_{\\max} + 10^{-12}\\}$, where $r_{\\max} = \\max_i \\lVert \\mathbf{r}_i \\rVert$. The optimization is defined by minimizing the cost function $C(R_c)$ subject to an error constraint $E(R_c) \\le \\tau$.\n\nThe error is defined as the maximum relative error over all particles:\n$$\nE(R_c) = \\max_{1 \\le i \\le N} \\frac{\\lVert \\mathbf{a}^{\\text{hyb}}_i(R_c) - \\mathbf{a}^{\\text{dir}}_i \\rVert}{\\max(\\lVert \\mathbf{a}^{\\text{dir}}_i \\rVert, a_{\\min})}\n$$\nwith $a_{\\min} = 10^{-12}$. The cost function $C(R_c)$ models the computational work:\n$$\nC(R_c) = \\mathbb{I}\\{N_{\\text{outer}}(R_c)  0\\}\\, w_{\\text{build}}\\, N + w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{central}}(R_c) + w_{\\text{cell}}\\, N_{\\text{cell}}^{\\text{outer}}(R_c) + w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{outer}}(R_c)\n$$\nwhere the terms represent the costs of tree construction, central direct interactions, outer cell-particle interactions, and outer leaf-particle interactions, respectively, weighted by the given parameters $w_{\\text{build}}$, $w_{\\text{cell}}$, and $w_{\\text{pair}}$.\n\nThe solution is found by implementing the following algorithm for each test case:\n$1$. Construct the particle positions and masses.\n$2$. Compute the reference accelerations $\\mathbf{a}^{\\text{dir}}_i$ for all particles via direct summation.\n$3$. Generate the sorted candidate set $\\mathcal{R}$ for $R_c$.\n$4$. For each candidate $R_c \\in \\mathcal{R}$:\n    a. Partition particles into central and outer sets.\n    b. Compute the hybrid acceleration $\\mathbf{a}^{\\text{hyb}}_i(R_c)$ for each particle according to its region.\n    c. Track the number of interactions to compute the total cost $C(R_c)$.\n    d. Calculate the error $E(R_c)$ against the reference accelerations.\n$5$. Identify all feasible candidates $R_c$ for which $E(R_c) \\le \\tau$.\n$6$. Among these feasible candidates, find the minimum achievable cost.\n$7$. The final answer is the smallest $R_c$ that achieves this minimum cost.\nThe implementation uses vectorized operations from the NumPy library for efficiency, particularly in force calculations. The quadtree is implemented as a class-based data structure, and the tree traversal for force evaluation on outer particles is managed using a stack to avoid deep recursion.", "answer": "```python\nimport numpy as np\n\n# Global constants from the problem description\nG_CONST = 1.0\nEPSILON = 1e-3\nA_MIN = 1e-12\nN_LEAF_CAPACITY = 8\n\nclass Node:\n    \"\"\"A node in the QuadTree.\"\"\"\n    def __init__(self, center, half_size):\n        self.center = center\n        self.half_size = half_size\n        self.children = [None, None, None, None]  # SW, SE, NW, NE\n        self.particle_indices = []\n        self.mass = 0.0\n        self.com = np.zeros(2)\n        self.is_leaf = True\n\nclass QuadTree:\n    \"\"\"QuadTree for N-body simulation.\"\"\"\n    def __init__(self, positions, n_leaf):\n        self.positions = positions\n        self.n = len(positions)\n        self.particle_mass = 1.0 / self.n if self.n > 0 else 0.0\n        self.n_leaf = n_leaf\n\n        max_abs_coord = np.max(np.abs(positions)) if self.n > 0 else 1.0\n        root_half_size = max_abs_coord + 1e-12\n        \n        self.root = Node(np.zeros(2), root_half_size)\n        self.root.particle_indices = list(range(self.n))\n        \n        self._build(self.root)\n\n    def _get_quadrant(self, node, p_idx):\n        pos = self.positions[p_idx]\n        if pos[0]  node.center[0]: # West\n            return 2 if pos[1] > node.center[1] else 0 # NW or SW\n        else: # East\n            return 3 if pos[1] > node.center[1] else 1 # NE or SE\n\n    def _build(self, node):\n        if not node.particle_indices:\n            return\n\n        node.mass = len(node.particle_indices) * self.particle_mass\n        if node.mass > 0:\n            node.com = np.mean(self.positions[node.particle_indices], axis=0)\n        \n        if len(node.particle_indices) = self.n_leaf:\n            node.is_leaf = True\n            return\n\n        node.is_leaf = False\n        child_half_size = node.half_size / 2.0\n        centers = [\n            node.center + np.array([-child_half_size, -child_half_size]), # SW\n            node.center + np.array([child_half_size, -child_half_size]),  # SE\n            node.center + np.array([-child_half_size, child_half_size]),  # NW\n            node.center + np.array([child_half_size, child_half_size]),   # NE\n        ]\n\n        child_particles = [[] for _ in range(4)]\n        for p_idx in node.particle_indices:\n            quadrant = self._get_quadrant(node, p_idx)\n            child_particles[quadrant].append(p_idx)\n\n        for i in range(4):\n            if child_particles[i]:\n                child_node = Node(centers[i], child_half_size)\n                child_node.particle_indices = child_particles[i]\n                node.children[i] = child_node\n                self._build(child_node)\n\ndef vdc(n, base):\n    \"\"\"Van der Corput sequence generator.\"\"\"\n    val, inv_base = 0.0, 1.0 / base\n    while n > 0:\n        digit = n % base\n        val += digit * inv_base\n        inv_base /= base\n        n //= base\n    return val\n\ndef generate_particles(N, beta):\n    \"\"\"Generates particle positions based on the problem specification.\"\"\"\n    if N == 0:\n        return np.array([])\n    \n    indices = np.arange(1, N + 1)\n    u = np.array([vdc(i, 2) for i in indices])\n    v = np.array([vdc(i, 3) for i in indices])\n\n    x = u - 0.5\n    y = v - 0.5\n\n    r = np.sqrt(x**2 + y**2)\n    r_prime = np.where(r > 0, r**beta, 0)\n    \n    positions = np.zeros((N, 2))\n    non_zero_r_mask = r > 0\n    if np.any(non_zero_r_mask):\n        ratio = r_prime[non_zero_r_mask] / r[non_zero_r_mask]\n        positions[non_zero_r_mask, 0] = x[non_zero_r_mask] * ratio\n        positions[non_zero_r_mask, 1] = y[non_zero_r_mask] * ratio\n\n    return positions\n\ndef calculate_tree_force_for_target(target_idx, all_pos, tree, theta, part_mass):\n    \"\"\"Calculates acceleration on a single target using the tree.\"\"\"\n    target_pos = all_pos[target_idx]\n    accel = np.zeros(2)\n    cell_count = 0\n    pair_count = 0\n    \n    stack = [tree.root]\n\n    while stack:\n        node = stack.pop()\n        if not node or not node.particle_indices:\n            continue\n\n        dist_vec = node.com - target_pos\n        dist_sq = dist_vec[0]**2 + dist_vec[1]**2\n\n        if dist_sq == 0: \n            if not node.is_leaf:\n                for child in node.children:\n                    if child: stack.append(child)\n            else: # Direct sum for leaf particles\n                for p_idx in node.particle_indices:\n                    if p_idx == target_idx: continue\n                    dr = all_pos[p_idx] - target_pos\n                    dsq = dr[0]**2 + dr[1]**2\n                    inv_r3 = (dsq + EPSILON**2)**(-1.5)\n                    accel += G_CONST * part_mass * dr * inv_r3\n                    pair_count += 1\n            continue\n        \n        node_size = 2 * node.half_size \n        if node_size / np.sqrt(dist_sq) = theta:\n            inv_r3 = (dist_sq + EPSILON**2)**(-1.5)\n            accel += G_CONST * node.mass * dist_vec * inv_r3\n            cell_count += 1\n        else:\n            if node.is_leaf:\n                for p_idx in node.particle_indices:\n                    if p_idx == target_idx: continue\n                    dr = all_pos[p_idx] - target_pos\n                    dsq = dr[0]**2 + dr[1]**2\n                    inv_r3 = (dsq + EPSILON**2)**(-1.5)\n                    accel += G_CONST * part_mass * dr * inv_r3\n                    pair_count += 1\n            else:\n                for child in node.children:\n                    if child: stack.append(child)\n                        \n    return accel, cell_count, pair_count\n\ndef solve():\n    \"\"\"Main function to solve the problem for the given test cases.\"\"\"\n    test_cases = [\n        (64, 1.6, 0.6, 1e-3, 20, 2, 1),\n        (128, 1.2, 0.5, 5e-4, 30, 1.5, 1),\n        (64, 1.4, 0.9, 1e-2, 10, 1, 1),\n        (64, 1.8, 0.7, 1e-8, 20, 2, 1),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N, beta, theta, tau, w_build, w_cell, w_pair = case\n        particle_mass = 1.0 / N\n\n        positions = generate_particles(N, beta)\n        \n        all_indices = np.arange(N)\n        a_dir = np.zeros_like(positions)\n        for i in all_indices:\n            sources_mask = all_indices != i\n            dr = positions[sources_mask] - positions[i]\n            dist_sq = np.sum(dr**2, axis=1)\n            inv_r3 = (dist_sq + EPSILON**2)**(-1.5)\n            a_dir[i] = G_CONST * particle_mass * np.sum(dr * inv_r3[:, np.newaxis], axis=0)\n\n        a_dir_norm = np.linalg.norm(a_dir, axis=1)\n\n        radii = np.linalg.norm(positions, axis=1)\n        r_max = np.max(radii) if N > 0 else 0.0\n        candidate_rc = sorted(list(np.unique(np.concatenate(([0.0], radii, [r_max + 1e-12])))))\n\n        feasible_solutions = []\n\n        for rc in candidate_rc:\n            central_indices = np.where(radii = rc)[0]\n            outer_indices = np.where(radii > rc)[0]\n\n            a_hyb = np.zeros_like(positions)\n            n_pair_central, n_cell_outer, n_pair_outer = 0, 0, 0\n\n            # Central region: direct sum\n            if len(central_indices) > 0:\n                a_hyb[central_indices] = a_dir[central_indices]\n                n_pair_central = len(central_indices) * (N - 1)\n            \n            # Outer region: tree code\n            tree = None\n            if len(outer_indices) > 0:\n                tree = QuadTree(positions, N_LEAF_CAPACITY)\n                for i in outer_indices:\n                    accel, cells, pairs = calculate_tree_force_for_target(\n                        i, positions, tree, theta, particle_mass)\n                    a_hyb[i] = accel\n                    n_cell_outer += cells\n                    n_pair_outer += pairs\n\n            err_num = np.linalg.norm(a_hyb - a_dir, axis=1)\n            err_den = np.maximum(a_dir_norm, A_MIN)\n            error = np.max(err_num / err_den) if N > 0 else 0.0\n\n            cost = w_pair * n_pair_central + w_cell * n_cell_outer + w_pair * n_pair_outer\n            if len(outer_indices) > 0:\n                cost += w_build * N\n\n            if error = tau:\n                feasible_solutions.append((rc, cost))\n\n        if not feasible_solutions:\n            # Fallback, though problem structure ensures this is not reached\n            optimal_rc = -1.0 \n        else:\n            min_cost = min(c for r, c in feasible_solutions)\n            optimal_rc = min(r for r, c in feasible_solutions if c == min_cost)\n        \n        results.append(f\"{optimal_rc:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2447320"}]}