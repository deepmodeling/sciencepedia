{"hands_on_practices": [{"introduction": "Many physical systems, from nanoparticles in a fluid to fluctuating electrical circuits, are described by stochastic differential equations (SDEs). One of the most famous examples is the Langevin equation for a particle's velocity. This exercise [@problem_id:1311625] provides a crucial first step in analyzing such systems by asking how a related quantity—the kinetic energy, $K_t = \\frac{1}{2}V_t^2$—evolves. To answer this, you will need to apply Itô's lemma, the fundamental theorem of stochastic calculus, which reveals how the rules of differentiation change in the presence of random noise.", "problem": "The one-dimensional motion of a nanoparticle suspended in a fluid at thermal equilibrium can be modeled using the Langevin equation. The velocity of the particle, $V_t$, is described by a stochastic process that accounts for both viscous drag from the fluid and random thermal kicks from surrounding molecules. This process is governed by the following Stochastic Differential Equation (SDE):\n$$dV_t = -\\gamma V_t dt + \\sigma dW_t$$\nHere, $V_t$ is the particle's velocity at time $t$, $\\gamma$ is a positive constant representing the drag coefficient, $\\sigma$ is a positive constant representing the magnitude of the random thermal forces, and $W_t$ is a standard Wiener process (Brownian motion).\n\nThe specific kinetic energy of the particle (kinetic energy per unit mass) is given by $K_t = \\frac{1}{2}V_t^2$. The evolution of this specific kinetic energy over time can also be described by an SDE of the form:\n$$dK_t = \\mu(V_t) dt + \\eta(V_t) dW_t$$\nwhere $\\mu(V_t)$ is the drift coefficient and $\\eta(V_t)$ is the diffusion coefficient, both of which may depend on the velocity $V_t$.\n\nYour task is to find the expressions for the drift coefficient $\\mu(V_t)$ and the diffusion coefficient $\\eta(V_t)$ for the specific kinetic energy process $K_t$. Present your answer as a pair of expressions $(\\mu(V_t), \\eta(V_t))$.", "solution": "We start from the given SDE for the velocity:\n$$dV_{t} = -\\gamma V_{t}\\,dt + \\sigma\\,dW_{t}.$$\nDefine the specific kinetic energy as\n$$K_{t} = \\frac{1}{2}V_{t}^{2}.$$\nApply Itô's lemma to the function $f(v) = \\frac{1}{2}v^{2}$. Its first and second derivatives are\n$$f'(v) = v, \\qquad f''(v) = 1.$$\nFor a one-dimensional Itô process $dV_{t} = a(V_{t},t)\\,dt + b(V_{t},t)\\,dW_{t}$, Itô's lemma gives\n$$df(V_{t}) = f'(V_{t})\\,dV_{t} + \\frac{1}{2}f''(V_{t})\\,(dV_{t})^{2},$$\nusing the Itô rules $(dW_{t})^{2} = dt$, $dt\\,dW_{t} = 0$, and $(dt)^{2} = 0$. Here, $a(V_{t},t) = -\\gamma V_{t}$ and $b(V_{t},t) = \\sigma$, so\n$$(dV_{t})^{2} = \\sigma^{2}\\,dt.$$\nTherefore,\n$$dK_{t} = f'(V_{t})\\,dV_{t} + \\frac{1}{2}f''(V_{t})\\,(dV_{t})^{2} = V_{t}\\left(-\\gamma V_{t}\\,dt + \\sigma\\,dW_{t}\\right) + \\frac{1}{2}\\cdot 1 \\cdot \\sigma^{2}\\,dt.$$\nCollecting terms yields\n$$dK_{t} = \\left(-\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2}\\right)dt + \\sigma V_{t}\\,dW_{t}.$$\nBy identification with $dK_{t} = \\mu(V_{t})\\,dt + \\eta(V_{t})\\,dW_{t}$, we obtain\n$$\\mu(V_{t}) = -\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2}, \\qquad \\eta(V_{t}) = \\sigma V_{t}.$$", "answer": "$$\\boxed{\\begin{pmatrix}-\\gamma V_{t}^{2} + \\frac{1}{2}\\sigma^{2} & \\sigma V_{t}\\end{pmatrix}}$$", "id": "1311625"}, {"introduction": "While understanding the analytical properties of SDEs is essential, we often rely on computers to simulate their trajectories. However, simply transcribing an SDE into a numerical scheme can lead to unstable and meaningless results. This practice [@problem_id:1710321] investigates the stability of the Euler-Maruyama method, a common algorithm for simulating SDEs. By analyzing the conditions for mean-square stability, you will develop a critical understanding of the interplay between the time step $\\Delta t$ and the SDE parameters, ensuring your computational models are both accurate and reliable.", "problem": "A stochastic model for a certain quantity $X_t$ is described by the scalar linear Stochastic Differential Equation (SDE):\n$$\ndX_t = \\lambda X_t dt + \\mu X_t dW_t\n$$\nwhere $t$ is time, $X_0$ is the non-zero initial value, $W_t$ is a standard Wiener process, and $\\lambda$ and $\\mu$ are real constants with $\\lambda \\neq 0$. The parameters $\\lambda$ and $\\mu$ are such that the exact solution $X_t$ is mean-square stable, meaning $\\lim_{t \\to \\infty} \\mathbb{E}[X_t^2] = 0$.\n\nTo approximate the solution numerically, the explicit Euler-Maruyama (EM) method is applied with a constant time step $\\Delta t > 0$, generating a sequence of approximations $\\{X_n\\}_{n \\geq 0}$ where $X_n \\approx X(n\\Delta t)$. The EM method is said to be mean-square stable if the sequence of second moments of the numerical solution, $\\mathbb{E}[X_n^2]$, converges to zero as $n \\to \\infty$.\n\nDetermine the maximum allowable time step, $\\Delta t_{max}$, for which the EM scheme is guaranteed to be mean-square stable. Express your answer as a single analytic expression in terms of $\\lambda$ and $\\mu$.", "solution": "The given Stochastic Differential Equation (SDE) is $dX_t = \\lambda X_t dt + \\mu X_t dW_t$.\nThe explicit Euler-Maruyama (EM) scheme for a general SDE $dY_t = a(t, Y_t) dt + b(t, Y_t) dW_t$ is given by $Y_{n+1} = Y_n + a(t_n, Y_n) \\Delta t + b(t_n, Y_n) \\Delta W_n$, where $\\Delta t = t_{n+1} - t_n$ and $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$. The increments of the Wiener process $\\Delta W_n$ are independent and identically distributed normal random variables with mean $\\mathbb{E}[\\Delta W_n] = 0$ and variance $\\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$.\n\nApplying the EM scheme to the specific SDE in the problem, we get the discrete-time update rule:\n$$\nX_{n+1} = X_n + \\lambda X_n \\Delta t + \\mu X_n \\Delta W_n\n$$\nWe can factor out $X_n$ to write this as:\n$$\nX_{n+1} = X_n (1 + \\lambda \\Delta t + \\mu \\Delta W_n)\n$$\nTo analyze the mean-square stability, we need to examine the evolution of the second moment, $\\mathbb{E}[X_n^2]$. We start by squaring the expression for $X_{n+1}$:\n$$\nX_{n+1}^2 = X_n^2 (1 + \\lambda \\Delta t + \\mu \\Delta W_n)^2\n$$\nExpanding the squared term gives:\n$$\nX_{n+1}^2 = X_n^2 (1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 (\\Delta W_n)^2 + 2\\lambda \\Delta t + 2\\mu \\Delta W_n + 2\\lambda\\mu \\Delta t \\Delta W_n)\n$$\nNow, we take the expectation of both sides. It is most rigorous to first take the conditional expectation with respect to the filtration $\\mathcal{F}_{t_n}$ (the information available up to time $t_n$). Since $X_n$ and $\\Delta t$ are known at time $t_n$, they can be treated as constants inside the conditional expectation. The increment $\\Delta W_n$ is independent of $\\mathcal{F}_{t_n}$.\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 \\mathbb{E}[(1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 (\\Delta W_n)^2 + 2\\lambda \\Delta t + 2\\mu \\Delta W_n + 2\\lambda\\mu \\Delta t \\Delta W_n) | \\mathcal{F}_{t_n}]\n$$\nUsing the linearity of expectation and the properties $\\mathbb{E}[\\Delta W_n | \\mathcal{F}_{t_n}] = \\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2 | \\mathcal{F}_{t_n}] = \\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$, we get:\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 (1 + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t + 2\\lambda \\Delta t + 0 + 0)\n$$\n$$\n\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] = X_n^2 (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t)\n$$\nUsing the law of total expectation, $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y | \\mathcal{G}]]$, we have:\n$$\n\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}[\\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}]] = \\mathbb{E}[X_n^2 (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t)]\n$$\nSince the term in the parentheses is constant, we can pull it out of the outer expectation:\n$$\n\\mathbb{E}[X_{n+1}^2] = (1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t) \\mathbb{E}[X_n^2]\n$$\nThis is a geometric recurrence relation for the sequence of second moments. Let the amplification factor be $R(\\Delta t) = 1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t$.\nFor the numerical scheme to be mean-square stable, we require $\\lim_{n \\to \\infty} \\mathbb{E}[X_n^2] = 0$. This holds if and only if the magnitude of the amplification factor is less than one, i.e., $|R(\\Delta t)| < 1$.\n\nWe can rewrite $R(\\Delta t)$ as:\n$$\nR(\\Delta t) = (1 + \\lambda \\Delta t)^2 + \\mu^2 \\Delta t\n$$\nSince $(\\Delta t) > 0$ and $\\mu^2 \\geq 0$, the term $\\mu^2 \\Delta t$ is non-negative. Also, $(1 + \\lambda \\Delta t)^2$ is non-negative. Therefore, $R(\\Delta t) \\geq 0$. The stability condition $|R(\\Delta t)| < 1$ simplifies to $R(\\Delta t) < 1$.\n$$\n1 + 2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t < 1\n$$\nSubtracting 1 from both sides gives:\n$$\n2\\lambda \\Delta t + \\lambda^2 (\\Delta t)^2 + \\mu^2 \\Delta t < 0\n$$\nSince $\\Delta t > 0$, we can divide by $\\Delta t$ without changing the inequality's direction:\n$$\n2\\lambda + \\lambda^2 \\Delta t + \\mu^2 < 0\n$$\nNow, we solve for $\\Delta t$. Rearranging the terms, we get:\n$$\n\\lambda^2 \\Delta t < -2\\lambda - \\mu^2\n$$\nFor this inequality to have any solution for $\\Delta t > 0$, the right-hand side must be positive, which means $-2\\lambda - \\mu^2 > 0$, or $2\\lambda + \\mu^2 < 0$. This is precisely the condition for the exact SDE to be mean-square stable, which was given in the problem statement.\nSince the problem states that $\\lambda \\neq 0$, we have $\\lambda^2 > 0$. We can divide by $\\lambda^2$ to isolate $\\Delta t$:\n$$\n\\Delta t < \\frac{-2\\lambda - \\mu^2}{\\lambda^2}\n$$\nThe right-hand side of this inequality represents the upper bound on the time step for mean-square stability. Therefore, the maximum allowable time step is:\n$$\n\\Delta t_{max} = \\frac{-2\\lambda - \\mu^2}{\\lambda^2}\n$$", "answer": "$$\\boxed{\\frac{-2\\lambda - \\mu^{2}}{\\lambda^{2}}}$$", "id": "1710321"}, {"introduction": "This final practice combines theory and computation to tackle a classic problem in statistical physics: the \"first-passage time\" problem for a random walker. Here, you will calculate the survival probability of a particle diffusing inside a circle with an absorbing boundary [@problem_id:2443225]. The exercise guides you from the microscopic SDE description of the particle's motion to the macroscopic diffusion equation for its probability density. Your task is to implement the analytical solution, which involves a series of Bessel functions, to create a robust program that computes a physically meaningful outcome, bridging the gap between abstract equations and tangible results.", "problem": "You are to compute the survival probability $P(t)$ for a two-dimensional isotropic random walker undergoing Brownian motion inside a circular domain with an absorbing boundary. The random motion is governed by the stochastic differential equation (SDE)\n$$\nd\\mathbf{X}_t = \\sqrt{2D}\\, d\\mathbf{W}_t,\n$$\nwhere $\\mathbf{X}_t \\in \\mathbb{R}^2$ is the position at time $t$, $D$ is the diffusion coefficient, and $\\mathbf{W}_t$ is a two-dimensional Wiener process. The particle starts at a distance $r_0$ from the center at time $t=0$ inside a disk of radius $R$. The boundary at $r=R$ is perfectly absorbing, meaning that once the trajectory hits the boundary, the process terminates and the particle is considered absorbed.\n\nLet $p(\\mathbf{x},t \\mid \\mathbf{x}_0)$ be the transition probability density that satisfies the diffusion equation with absorbing boundary conditions and point-source initial data. Define the survival probability as\n$$\nP(t) = \\int_{r<R} p(\\mathbf{x},t \\mid \\mathbf{x}_0)\\, d^2\\mathbf{x},\n$$\nwhich is the probability that the particle has not been absorbed up to time $t$. You must start from fundamental principles, namely the link between the SDE and the diffusion (heat) equation with absorbing boundary conditions, and derive an expression suitable for accurate numerical evaluation of $P(t)$ for given $(D,R,r_0,t)$.\n\nYour program must implement a numerically stable and convergent algorithm to evaluate $P(t)$ to high accuracy, starting from the diffusion equation and boundary conditions implied by the SDE. You must ensure the method is scientifically sound and justifiable from first principles without relying on any ad hoc approximations. The evaluation should be self-consistent under non-dimensionalization and must handle all the test cases below robustly. If $t=0$, the answer must be exactly $P(0)=1$ by the definition of survival probability.\n\nPhysical units:\n- Diffusion coefficient $D$ must be provided in $\\mathrm{m}^2/\\mathrm{s}$.\n- Radii $R$ and $r_0$ must be provided in $\\mathrm{m}$.\n- Time $t$ must be provided in $\\mathrm{s}$.\n- The survival probability $P(t)$ is dimensionless and must be output as a decimal number.\n\nTest suite:\nProvide results for the following parameter sets $(D,R,r_0,t)$:\n- Case $1$: $(0.2,\\,1.0,\\,0.3,\\,0.5)$\n- Case $2$: $(1.0,\\,1.0,\\,0.7,\\,0.0)$\n- Case $3$: $(0.1,\\,2.0,\\,0.0,\\,5.0)$\n- Case $4$: $(0.5,\\,1.0,\\,0.99,\\,0.1)$\n- Case $5$: $(0.1,\\,1.0,\\,0.5,\\,50.0)$\n\nOutput format:\nYour program should produce a single line of output containing the results as a comma-separated list of decimal numbers, each rounded to exactly $8$ digits after the decimal point, enclosed in square brackets. For example, the output format must be\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5].\n$$", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of stochastic processes and diffusion, well-posed with sufficient initial and boundary conditions, and formulated objectively. We may therefore proceed with a solution.\n\nThe motion of the particle is described by the two-dimensional stochastic differential equation (SDE):\n$$\nd\\mathbf{X}_t = \\sqrt{2D}\\, d\\mathbf{W}_t\n$$\nwhere $\\mathbf{X}_t$ is the position vector, $D$ is the diffusion coefficient, and $\\mathbf{W}_t$ is a standard two-dimensional Wiener process. The Fokker-Planck equation corresponding to this SDE governs the evolution of the probability density function $p(\\mathbf{x}, t | \\mathbf{x}_0, 0)$, and it is the diffusion equation:\n$$\n\\frac{\\partial p}{\\partial t} = D \\nabla^2 p\n$$\nThe problem is set in a circular domain of radius $R$ with an absorbing boundary. The initial condition is a particle located at a position $\\mathbf{x}_0$ such that $|\\mathbf{x}_0| = r_0 < R$ at time $t=0$. The absorbing boundary condition implies that the probability density must be zero at the boundary for all time $t>0$.\n\nDue to the circular symmetry of the domain and the isotropic nature of the diffusion process, it is advantageous to work in polar coordinates $(r, \\theta)$. The problem possesses azimuthal symmetry, meaning the solution will depend only on the radial distance $r$ and the initial radial distance $r_0$, not on the angular coordinates. The diffusion equation in polar coordinates, for an azimuthally symmetric function $p(r, t)$, simplifies to:\n$$\n\\frac{\\partial p}{\\partial t} = D \\left( \\frac{\\partial^2 p}{\\partial r^2} + \\frac{1}{r} \\frac{\\partial p}{\\partial r} \\right)\n$$\nThe boundary and initial conditions are:\n$1$. Absorbing boundary at $r=R$: $p(R, t) = 0$ for $t > 0$.\n$2$. Particle must be finite at the origin: $|p(0, t)| < \\infty$.\n$3$. Initial position at $r_0$: This is formally represented by a Dirac delta function source, $p(\\mathbf{x}, 0) = \\delta(\\mathbf{x} - \\mathbf{x}_0)$.\n\nThe survival probability $P(t)$ is the total probability of finding the particle within the disk at time $t$, given it started at $\\mathbf{x}_0$ at $t=0$. It is defined by the integral of the probability density over the domain:\n$$\nP(t) = \\int_{|\\mathbf{x}|<R} p(\\mathbf{x}, t | \\mathbf{x}_0) \\, d^2\\mathbf{x}\n$$\nThe solution for the probability density $p(\\mathbf{x}, t | \\mathbf{x}_0)$, also known as the Green's function for the diffusion equation in a disk with absorbing boundaries, can be constructed using an eigenfunction expansion. The full solution involves an infinite series over both radial and angular modes. However, to calculate the survival probability $P(t)$, we integrate over all final positions $(r, \\theta)$ within the disk. This integration over the angle $\\theta$ causes all angular modes with non-zero mode number $m$ to vanish, leaving only the $m=0$ (azimuthally symmetric) contribution.\n\nThe well-established result for the survival probability, derived from this procedure, is given by the following infinite series:\n$$\nP(t) = 2 \\sum_{n=1}^{\\infty} \\frac{J_0(\\alpha_n r_0/R)}{\\alpha_n J_1(\\alpha_n)} e^{-D \\alpha_n^2 t / R^2}\n$$\nHere, $J_k(x)$ is the Bessel function of the first kind of order $k$, and $\\alpha_n$ represents the $n$-th positive root of the equation $J_0(x) = 0$.\n\nThis formula is derived from first principles and is suitable for numerical evaluation. We verify its consistency. For $t=0$, the exponential term becomes $1$, and we are left with the series $P(0) = 2 \\sum_{n=1}^{\\infty} \\frac{J_0(\\alpha_n r_0/R)}{\\alpha_n J_1(\\alpha_n)}$. This is a known Fourier-Bessel series expansion which evaluates to $1$ for any $r_0 \\in [0, R)$. This correctly reflects the initial condition that the particle is guaranteed to be inside the domain at $t=0$, so $P(0)=1$.\n\nFor numerical computation, it is best practice to non-dimensionalize the expression. We introduce the dimensionless radius $\\rho_0 = r_0/R$ and the dimensionless time (or Fourier number) $\\tau = Dt/R^2$. The expression for the survival probability becomes:\n$$\nP(\\tau) = 2 \\sum_{n=1}^{\\infty} \\frac{J_0(\\alpha_n \\rho_0)}{\\alpha_n J_1(\\alpha_n)} e^{-\\alpha_n^2 \\tau}\n$$\nThis form is robust and mitigates potential numerical issues with very large or small physical parameters.\n\nThe algorithm for computation is as follows:\n$1$. For a given set of parameters $(D, R, r_0, t)$, first check if $t=0$. If so, the result is exactly $1.0$.\n$2$. Otherwise, compute the dimensionless parameters $\\rho_0 = r_0/R$ and $\\tau = Dt/R^2$.\n$3$. The infinite series must be truncated for computation. The convergence of the series is dominated by the exponential term $e^{-\\alpha_n^2 \\tau}$. Since $\\alpha_n$ grows approximately linearly with $n$ (specifically, $\\alpha_n \\approx \\pi(n - 1/4)$ for large $n$), the terms decay extremely rapidly for any $\\tau > 0$. We can therefore truncate the sum after a finite number of terms, $N$, without significant loss of accuracy. A fixed, sufficiently large number of terms (e.g., $N=500$) will provide high accuracy for the range of $\\tau$ values in the test cases.\n$4$. The roots $\\alpha_n$ of $J_0(x)$ are standard and can be pre-computed using numerical libraries.\n$5$. The Bessel functions $J_0(x)$ and $J_1(x)$ are also standard library functions.\n$6$. The final algorithm involves computing the roots $\\alpha_n$, then for each $n$ up to the truncation limit $N$, calculating the corresponding term in the series and adding it to a running sum. Vectorized computation can perform this efficiently. The special case of $r_0=0$ is handled naturally by the formula, since $J_0(0)=1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import j0, j1, jn_zeros\n\ndef solve():\n    \"\"\"\n    Solves for the survival probability of a random walker in a 2D disk.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (D, R, r0, t)\n        (0.2, 1.0, 0.3, 0.5),\n        (1.0, 1.0, 0.7, 0.0),\n        (0.1, 2.0, 0.0, 5.0),\n        (0.5, 1.0, 0.99, 0.1),\n        (0.1, 1.0, 0.5, 50.0),\n    ]\n\n    results = []\n    \n    # Pre-calculate a sufficient number of roots for J0(x) for all test cases.\n    # The number of terms needed for convergence depends on the dimensionless time tau.\n    # Smaller tau requires more terms. The smallest non-zero tau in the test cases\n    # is tau = 0.5 * 0.1 / 1.0^2 = 0.05. A few hundred terms are more than\n    # sufficient for high precision. We choose 500 as a safe upper bound.\n    num_roots = 500\n    alphas = jn_zeros(0, num_roots)\n\n    for D, R, r0, t in test_cases:\n        # According to the problem definition, P(0) = 1.\n        if t == 0.0:\n            results.append(1.0)\n            continue\n        \n        # All parameters must be physically valid.\n        if D  0 or R = 0 or r0  0 or r0 > R or t  0:\n            # This case will not occur with the given test suite, but it is\n            # a necessary check for a robust implementation.\n            results.append(np.nan)\n            continue\n\n        # Non-dimensionalize parameters for numerical stability and correctness.\n        # rho0: dimensionless initial radius\n        # tau: dimensionless time (Fourier number)\n        rho0 = r0 / R\n        tau = (D * t) / (R**2)\n        \n        # The survival probability P(t) is given by the series:\n        # P(t) = 2 * sum_{n=1 to inf} [ J0(alpha_n * rho0) / (alpha_n * J1(alpha_n)) ] * exp(-alpha_n^2 * tau)\n        # where alpha_n are the roots of J0(x).\n        \n        # We use vectorized NumPy operations for efficient computation of the series.\n        \n        # Calculate arguments for Bessel functions\n        j0_args = alphas * rho0\n        \n        # Evaluate Bessel functions\n        j0_vals = j0(j0_args)\n        j1_vals = j1(alphas)\n        \n        # Calculate the exponential decay term\n        exp_terms = np.exp(-(alphas**2) * tau)\n        \n        # Calculate each term in the series\n        # Note: J1(alpha_n) is never zero since alpha_n are roots of J0.\n        terms = 2 * j0_vals / (alphas * j1_vals) * exp_terms\n        \n        # Sum the series to get the survival probability\n        survival_probability = np.sum(terms)\n        \n        results.append(survival_probability)\n\n    # Final print statement in the exact required format.\n    # Each result is rounded to exactly 8 decimal places.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "2443225"}]}