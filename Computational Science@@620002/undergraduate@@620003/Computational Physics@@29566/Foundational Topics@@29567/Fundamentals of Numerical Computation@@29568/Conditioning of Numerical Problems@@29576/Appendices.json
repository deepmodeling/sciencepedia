{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of conditioning, we will start with a foundational problem from modern physics: blackbody radiation. This exercise involves deriving Wien's displacement law from the more fundamental Planck's radiation law. By treating this derivation as a parameterized optimization problem, you will analytically compute the condition number to quantify the sensitivity of the peak emission wavelength to variations in Planck's constant, $h$ [@problem_id:2382057]. This practice will provide a concrete understanding of how the condition number is defined and calculated in a clean, theoretical setting, revealing how even fundamental physical relationships can be examined through the lens of numerical stability.", "problem": "Consider Planck’s spectral radiance per unit wavelength for a blackbody at absolute temperature $T$ given by\n$$\nB_{\\lambda}(\\lambda, T; h) = \\frac{2 h c^{2}}{\\lambda^{5}} \\frac{1}{\\exp\\!\\left(\\frac{h c}{\\lambda k_{B} T}\\right) - 1},\n$$\nwhere $h$ is Planck’s constant, $c$ is the speed of light in vacuum, and $k_{B}$ is the Boltzmann constant. Using only fundamental calculus and this physical law, do the following for fixed $T$ and physical constants $c$ and $k_{B}$:\n\n1. Determine the wavelength $\\lambda^{\\star}(h)$ that maximizes $B_{\\lambda}(\\lambda, T; h)$ with respect to $\\lambda$, and from this derive Wien’s displacement law in the form $\\lambda^{\\star} T = b$, identifying $b$ in terms of $h$, $c$, $k_{B}$, and a dimensionless number arising from the maximization.\n\n2. Treating the maximization as a parameterized optimization problem with parameter $h$, analyze the conditioning of the argmax mapping $h \\mapsto \\lambda^{\\star}(h)$ by computing the relative condition number with respect to $h$ defined by\n$$\n\\kappa_{h} = \\left| \\frac{d \\ln \\lambda^{\\star}(h)}{d \\ln h} \\right|.\n$$\n\nProvide your final answer as the value of $\\kappa_{h}$ at the maximizer, expressed as a pure number without units. If any intermediate numerical evaluation is needed, do not round; the final reported quantity $\\kappa_{h}$ must be exact and unitless.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extracted Givens\n-   Planck's spectral radiance: $B_{\\lambda}(\\lambda, T; h) = \\frac{2 h c^{2}}{\\lambda^{5}} \\frac{1}{\\exp\\!\\left(\\frac{h c}{\\lambda k_{B} T}\\right) - 1}$.\n-   Variables: $\\lambda$ (wavelength), $T$ (absolute temperature), $h$ (Planck's constant).\n-   Constants: $c$ (speed of light), $k_{B}$ (Boltzmann constant).\n-   Task 1: For fixed $T$, $c$, and $k_B$, find the wavelength $\\lambda^{\\star}(h)$ that maximizes $B_{\\lambda}(\\lambda, T; h)$ with respect to $\\lambda$. Derive Wien's displacement law, $\\lambda^{\\star} T = b$, and identify the constant $b$.\n-   Task 2: Compute the relative condition number $\\kappa_{h} = \\left| \\frac{d \\ln \\lambda^{\\star}(h)}{d \\ln h} \\right|$ for the mapping $h \\mapsto \\lambda^{\\star}(h)$.\n\nStep 2: Validation\nThe problem is scientifically grounded, being based on Planck's law of blackbody radiation, a fundamental theory in modern physics. It is well-posed, as the function $B_{\\lambda}$ has a unique maximum for positive wavelength, leading to a unique solution. The language is objective and precise. The problem is self-contained and free of contradictions or ambiguities.\n\nStep 3: Verdict\nThe problem is valid. A complete solution will be provided.\n\nPart 1: Derivation of Wien's Displacement Law\n\nTo find the wavelength $\\lambda^{\\star}$ that maximizes the spectral radiance $B_{\\lambda}(\\lambda, T; h)$, we must solve for $\\frac{\\partial B_{\\lambda}}{\\partial \\lambda} = 0$. The function is given by:\n$$\nB_{\\lambda}(\\lambda, T; h) = \\frac{2 h c^{2}}{\\lambda^{5}} \\frac{1}{\\exp\\!\\left(\\frac{h c}{\\lambda k_{B} T}\\right) - 1}\n$$\nTo simplify the maximization, we introduce a dimensionless variable $x$ defined as:\n$$\nx = \\frac{h c}{\\lambda k_{B} T}\n$$\nFrom this, we can express $\\lambda$ as $\\lambda = \\frac{h c}{x k_{B} T}$. Substituting this into the expression for $B_{\\lambda}$ gives:\n$$\nB_{\\lambda} = 2 h c^{2} \\left(\\frac{x k_{B} T}{h c}\\right)^{5} \\frac{1}{\\exp(x) - 1} = 2 h c^{2} \\left(\\frac{k_{B} T}{h c}\\right)^{5} \\frac{x^5}{\\exp(x) - 1}\n$$\nFor a fixed temperature $T$ and constants $h$, $c$, $k_B$, maximizing $B_{\\lambda}$ with respect to $\\lambda$ is equivalent to maximizing the function $f(x) = \\frac{x^5}{\\exp(x) - 1}$ with respect to $x$. Note that when $\\lambda$ varies from $0$ to $\\infty$, $x$ varies from $\\infty$ to $0$. We compute the derivative of $f(x)$ and set it to zero.\n$$\n\\frac{df}{dx} = \\frac{d}{dx} \\left( \\frac{x^5}{\\exp(x) - 1} \\right) = \\frac{5x^4(\\exp(x) - 1) - x^5 \\exp(x)}{(\\exp(x) - 1)^2} = 0\n$$\nFor a non-trivial maximum ($x > 0$), the numerator must be zero:\n$$\n5x^4(\\exp(x) - 1) - x^5 \\exp(x) = 0\n$$\nDividing by $x^4$ (since $x \\neq 0$):\n$$\n5(\\exp(x) - 1) - x \\exp(x) = 0\n$$\nThis is a transcendental equation for the value of $x$ that maximizes the function. Let the non-zero root of this equation be denoted by the dimensionless constant $\\alpha$. The equation for $\\alpha$ is:\n$$\n5(\\exp(\\alpha) - 1) - \\alpha \\exp(\\alpha) = 0\n$$\nThe maximizing wavelength $\\lambda^{\\star}$ corresponds to this value $\\alpha$. From the definition of $x$:\n$$\n\\alpha = \\frac{h c}{\\lambda^{\\star} k_{B} T}\n$$\nRearranging this equation gives Wien's displacement law:\n$$\n\\lambda^{\\star} T = \\frac{h c}{\\alpha k_{B}}\n$$\nThis is of the form $\\lambda^{\\star} T = b$, where the constant $b$ is identified as:\n$$\nb = \\frac{h c}{\\alpha k_{B}}\n$$\n\nPart 2: Conditioning Analysis\n\nWe are asked to compute the relative condition number $\\kappa_{h}$ of the mapping $h \\mapsto \\lambda^{\\star}(h)$, defined as:\n$$\n\\kappa_{h} = \\left| \\frac{d \\ln \\lambda^{\\star}(h)}{d \\ln h} \\right|\n$$\nFrom the result of Part 1, we have an explicit expression for $\\lambda^{\\star}$ as a function of $h$:\n$$\n\\lambda^{\\star}(h) = \\frac{h c}{\\alpha k_{B} T}\n$$\nHere, $c$, $k_B$, and $T$ are treated as fixed constants. Critically, $\\alpha$ is a universal mathematical constant, being the solution to an equation that does not depend on any physical parameters. Therefore, we can write $\\lambda^{\\star}(h)$ as:\n$$\n\\lambda^{\\star}(h) = C h\n$$\nwhere $C = \\frac{c}{\\alpha k_{B} T}$ is a constant with respect to $h$.\n\nTo compute $\\kappa_h$, we take the natural logarithm of $\\lambda^{\\star}(h)$:\n$$\n\\ln(\\lambda^{\\star}(h)) = \\ln(C h) = \\ln(C) + \\ln(h)\n$$\nNow, we differentiate with respect to $\\ln(h)$:\n$$\n\\frac{d \\ln(\\lambda^{\\star}(h))}{d \\ln(h)} = \\frac{d}{d \\ln(h)} (\\ln(C) + \\ln(h)) = 0 + 1 = 1\n$$\nThe condition number is the absolute value of this derivative:\n$$\n\\kappa_{h} = |1| = 1\n$$\nThis result indicates that the problem of finding the maximizing wavelength is perfectly well-conditioned with respect to Planck's constant. A relative error in $h$ produces the same relative error in $\\lambda^\\star$.\n\nFor completeness, we confirm this result using a more general method based on the implicit function theorem, which is the standard tool for sensitivity analysis of parameterized optimization problems. The first-order condition for the maximum can be written as an implicit function $F(\\lambda, h) = 0$:\n$$\nF(\\lambda, h) = 5\\left(\\exp\\left(\\frac{hc}{\\lambda k_B T}\\right) - 1\\right) - \\frac{hc}{\\lambda k_B T} \\exp\\left(\\frac{hc}{\\lambda k_B T}\\right) = 0\n$$\nLet $x(\\lambda, h) = \\frac{hc}{\\lambda k_B T}$. Then $F(\\lambda, h) = 5(\\exp(x) - 1) - x\\exp(x) = 0$. By the implicit function theorem, the derivative of the solution $\\lambda^\\star(h)$ is given by $\\frac{d\\lambda^\\star}{dh} = - \\frac{\\partial F / \\partial h}{\\partial F / \\partial \\lambda}$.\nThe partial derivatives are computed via the chain rule. At the optimum $\\lambda = \\lambda^\\star$, $x = \\alpha$.\n$$\n\\frac{\\partial F}{\\partial \\lambda} = \\frac{dF}{dx} \\frac{\\partial x}{\\partial \\lambda} = \\left[5e^x - (e^x + xe^x)\\right] \\left(-\\frac{hc}{\\lambda^2 k_B T}\\right) = (4-x)e^x \\left(-\\frac{x}{\\lambda}\\right)\n$$\n$$\n\\frac{\\partial F}{\\partial h} = \\frac{dF}{dx} \\frac{\\partial x}{\\partial h} = \\left[(4-x)e^x\\right] \\left(\\frac{c}{\\lambda k_B T}\\right) = (4-x)e^x \\left(\\frac{x}{h}\\right)\n$$\nAt the optimum $\\lambda^\\star$, provided the denominator is non-zero (which it is, since $\\alpha \\approx 4.965 \\neq 4$), we have:\n$$\n\\frac{d\\lambda^\\star}{dh} = - \\frac{(4-\\alpha)e^\\alpha ( \\alpha / h )}{(4-\\alpha)e^\\alpha ( -\\alpha / \\lambda^\\star )} = \\frac{\\alpha / h}{\\alpha / \\lambda^\\star} = \\frac{\\lambda^\\star}{h}\n$$\nNow we compute the condition number using this derivative:\n$$\n\\kappa_{h} = \\left| \\frac{h}{\\lambda^\\star(h)} \\frac{d\\lambda^\\star}{dh} \\right| = \\left| \\frac{h}{\\lambda^\\star} \\left(\\frac{\\lambda^\\star}{h}\\right) \\right| = |1| = 1\n$$\nBoth methods yield the same result, confirming the analysis. The final answer is an exact pure number.", "answer": "$$\\boxed{1}$$", "id": "2382057"}, {"introduction": "Having established the analytical basis of conditioning, we now turn to a practical, computational example from aerodynamics. Physical systems often exhibit sharp transitions where their behavior changes dramatically, and the problem of predicting this behavior can become ill-conditioned near these critical points. In this exercise [@problem_id:2382100], you will implement a numerical model for the aerodynamic lift of an airfoil, focusing on the phenomenon of stall. Your task is to write a program that calculates both the absolute and relative condition numbers, allowing you to observe firsthand how the sensitivity of the lift coefficient to the angle of attack skyrockets as the airfoil approaches its stall angle.", "problem": "Consider the mapping from angle of attack to two-dimensional steady lift coefficient for a single airfoil, modeled by the following smooth stall-onset function:\n$$\nC_L(\\alpha; a,\\alpha_s,\\Delta C,\\delta) \\;=\\; a\\,\\alpha \\;-\\; \\Delta C\\; S(\\alpha), \\quad\\text{with}\\quad S(\\alpha) \\;=\\; \\tfrac{1}{2}\\Big(1+\\tanh\\Big(\\frac{\\alpha-\\alpha_s}{\\delta}\\Big)\\Big),\n$$\nwhere $a&gt;0$ is the small-angle lift slope in radians$^{-1}$, $\\alpha_s$ is the characteristic stall-onset angle, $\\Delta C&gt;0$ is the net loss in lift coefficient across the stall transition, and $\\delta&gt;0$ controls the sharpness of the transition. Angles must be expressed in radians.\n\nLet the absolute condition number of the problem “evaluate $C_L$ given $\\alpha$” be defined by\n$$\n\\kappa_{\\mathrm{abs}}(\\alpha) \\;=\\; \\left|\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}(\\alpha)\\right|,\n$$\nand the relative condition number (when $C_L(\\alpha)\\neq 0$) be defined by\n$$\n\\kappa_{\\mathrm{rel}}(\\alpha) \\;=\\; \\left|\\frac{\\alpha}{C_L(\\alpha)}\\,\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}(\\alpha)\\right|.\n$$\nYou must compute these two condition numbers for the parameter sets listed below. If $C_L(\\alpha)=0$ for a given case, report the relative condition number as the special floating-point value Not-a-Number.\n\nAngles of attack must be in radians, and the final numerical values you compute are dimensionless.\n\nTest suite (each case is an ordered $5$-tuple $(a,\\alpha_s,\\Delta C,\\delta,\\alpha)$, in the stated order):\n- Case 1 (representative pre-stall): $(6.2,\\;0.35,\\;0.8,\\;0.015,\\;0.10)$.\n- Case 2 (near stall with sharp transition): $(6.2,\\;0.35,\\;0.8,\\;0.015,\\;0.35)$.\n- Case 3 (post-stall, still influenced by stall onset): $(6.2,\\;0.35,\\;0.8,\\;0.015,\\;0.42)$.\n- Case 4 (near stall with gentle transition): $(6.2,\\;0.35,\\;0.8,\\;0.10,\\;0.35)$.\n- Case 5 (no stall drop, purely linear model): $(6.2,\\;0.35,\\;0.0,\\;0.020,\\;0.30)$.\n\nYour program must:\n- For each test case, evaluate $C_L(\\alpha)$ and its derivative with respect to $\\alpha$ implied by the model above, then compute $\\kappa_{\\mathrm{abs}}(\\alpha)$ and $\\kappa_{\\mathrm{rel}}(\\alpha)$ as defined.\n- Use radians for all angles.\n- Produce a single line of output containing a comma-separated list of pairs in the order of the test suite. Each pair must be a two-element list $[\\kappa_{\\mathrm{abs}},\\kappa_{\\mathrm{rel}}]$ for that case. The complete output line must therefore look like\n$[[\\kappa_{\\mathrm{abs}}^{(1)},\\kappa_{\\mathrm{rel}}^{(1)}],[\\kappa_{\\mathrm{abs}}^{(2)},\\kappa_{\\mathrm{rel}}^{(2)}],\\dots]$\nwith numerical values in place of symbols, and with Not-a-Number represented by the standard floating-point literal.\n\nThe program must not read any input.", "solution": "The problem statement is examined and found to be valid. It is scientifically grounded, well-posed, objective, and self-contained. The model provided for the lift coefficient $C_L$ as a function of the angle of attack $\\alpha$ is a standard phenomenological representation of aerodynamic lift including a smooth stall transition. The definitions for absolute and relative condition numbers are correct standard forms from numerical analysis. The parameters and test cases are physically plausible and mathematically tractable. We shall proceed with the solution.\n\nThe objective is to compute the absolute condition number, $\\kappa_{\\mathrm{abs}}(\\alpha)$, and the relative condition number, $\\kappa_{\\mathrm{rel}}(\\alpha)$, for the problem of evaluating the lift coefficient $C_L(\\alpha)$. The model for $C_L$ is given by:\n$$\nC_L(\\alpha; a, \\alpha_s, \\Delta C, \\delta) = a\\alpha - \\Delta C S(\\alpha)\n$$\nwhere $S(\\alpha)$ is the stall-onset function:\n$$\nS(\\alpha) = \\frac{1}{2}\\left(1 + \\tanh\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\\right)\n$$\nThe parameters are the lift-curve slope $a$, the stall angle $\\alpha_s$, the lift drop $\\Delta C$, and the transition sharpness $\\delta$. All angles are in radians.\n\nThe condition numbers are defined as:\n$$\n\\kappa_{\\mathrm{abs}}(\\alpha) = \\left|\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}(\\alpha)\\right|\n$$\n$$\n\\kappa_{\\mathrm{rel}}(\\alpha) = \\left|\\frac{\\alpha}{C_L(\\alpha)}\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}(\\alpha)\\right|\n$$\n\nThe first step is to derive the analytical expression for the derivative $\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}$. We apply the chain rule to the term containing $S(\\alpha)$. Let the argument of the hyperbolic tangent be $u(\\alpha) = \\frac{\\alpha - \\alpha_s}{\\delta}$. The derivative of $u$ with respect to $\\alpha$ is $\\frac{\\mathrm{d}u}{\\mathrm{d}\\alpha} = \\frac{1}{\\delta}$. The derivative of the hyperbolic tangent function is $\\frac{\\mathrm{d}}{\\mathrm{d}u}\\tanh(u) = \\mathrm{sech}^2(u)$.\nApplying the chain rule to find the derivative of $S(\\alpha)$:\n$$\n\\frac{\\mathrm{d}S}{\\mathrm{d}\\alpha} = \\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left[\\frac{1}{2}\\left(1 + \\tanh(u(\\alpha))\\right)\\right] = \\frac{1}{2} \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}u}\\tanh(u) \\cdot \\frac{\\mathrm{d}u}{\\mathrm{d}\\alpha} = \\frac{1}{2} \\cdot \\mathrm{sech}^2(u) \\cdot \\frac{1}{\\delta} = \\frac{1}{2\\delta}\\mathrm{sech}^2\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\n$$\nNow, we can differentiate the full expression for $C_L(\\alpha)$:\n$$\n\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha} = \\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}(a\\alpha) - \\Delta C \\frac{\\mathrm{d}S}{\\mathrm{d}\\alpha} = a - \\frac{\\Delta C}{2\\delta}\\mathrm{sech}^2\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\n$$\nwhere $\\mathrm{sech}(x) = 1/\\cosh(x)$.\n\nWith the expressions for $C_L(\\alpha)$ and its derivative $\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}$, we can write the explicit formulas for the condition numbers.\nThe absolute condition number is:\n$$\n\\kappa_{\\mathrm{abs}}(\\alpha) = \\left|a - \\frac{\\Delta C}{2\\delta}\\mathrm{sech}^2\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\\right|\n$$\nThe relative condition number, for $C_L(\\alpha) \\neq 0$, is:\n$$\n\\kappa_{\\mathrm{rel}}(\\alpha) = \\left|\\frac{\\alpha}{a\\alpha - \\frac{\\Delta C}{2}\\left(1 + \\tanh\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\\right)} \\left(a - \\frac{\\Delta C}{2\\delta}\\mathrm{sech}^2\\left(\\frac{\\alpha - \\alpha_s}{\\delta}\\right)\\right)\\right|\n$$\nIf $C_L(\\alpha) = 0$, the relative condition number is undefined, and we are instructed to report it as Not-a-Number (NaN).\n\nThe computational procedure is to implement these formulas in a program. For each of the $5$ test cases provided, each specified by a tuple $(a, \\alpha_s, \\Delta C, \\delta, \\alpha)$, the following steps are performed:\n$1$. Evaluate the argument $u = (\\alpha - \\alpha_s) / \\delta$.\n$2$. Compute $C_L(\\alpha)$ using the given model.\n$3$. Compute the derivative $\\frac{\\mathrm{d}C_L}{\\mathrm{d}\\alpha}$ using the derived formula.\n$4$. Compute $\\kappa_{\\mathrm{abs}}(\\alpha)$ by taking the absolute value of the derivative.\n$5$. Compute $\\kappa_{\\mathrm{rel}}(\\alpha)$. If $C_L(\\alpha)$ evaluates to $0.0$, the result is NaN. Otherwise, it is computed using its definition.\nThe resulting pair of values $[\\kappa_{\\mathrm{abs}}, \\kappa_{\\mathrm{rel}}]$ is recorded for each case. The final output is an aggregation of these pairs into a single list structure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the absolute and relative condition numbers for a given aerodynamic\n    lift coefficient model for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is an ordered 5-tuple (a, alpha_s, delta_C, delta, alpha).\n    test_cases = [\n        (6.2, 0.35, 0.8, 0.015, 0.10),  # Case 1 (pre-stall)\n        (6.2, 0.35, 0.8, 0.015, 0.35),  # Case 2 (near stall, sharp transition)\n        (6.2, 0.35, 0.8, 0.015, 0.42),  # Case 3 (post-stall)\n        (6.2, 0.35, 0.8, 0.10, 0.35),   # Case 4 (near stall, gentle transition)\n        (6.2, 0.35, 0.0, 0.020, 0.30),  # Case 5 (linear model)\n    ]\n\n    results = []\n    for case in test_cases:\n        a, alpha_s, delta_c, delta, alpha = case\n        \n        # Argument for the hyperbolic functions\n        u = (alpha - alpha_s) / delta\n        \n        # Lift coefficient C_L(alpha)\n        # C_L = a*alpha - delta_C * S(alpha)\n        # S(alpha) = 0.5 * (1 + tanh(u))\n        c_l = a * alpha - (delta_c / 2.0) * (1.0 + np.tanh(u))\n        \n        # Derivative d(C_L)/d(alpha)\n        # d(C_L)/d(alpha) = a - (delta_C / (2*delta)) * sech^2(u)\n        # sech(u) = 1/cosh(u)\n        cosh_u = np.cosh(u)\n        # Avoid division by zero if cosh_u is somehow zero, though it's always >= 1.\n        sech_u_sq = (1.0 / cosh_u)**2 if cosh_u != 0 else 0.0\n        dcl_dalpha = a - (delta_c / (2.0 * delta)) * sech_u_sq\n        \n        # Absolute condition number\n        k_abs = np.abs(dcl_dalpha)\n        \n        # Relative condition number\n        # Handle the case where C_L(alpha) is zero\n        if c_l == 0.0:\n            k_rel = np.nan\n        else:\n            k_rel = np.abs((alpha / c_l) * dcl_dalpha)\n            \n        results.append([k_abs, k_rel])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists, with no spaces after commas.\n    result_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2382100"}, {"introduction": "The final and most advanced practice moves our focus from diagnosing ill-conditioning to actively mitigating it—a crucial skill in computational science. Many problems in physics and engineering lead to large systems of linear equations, $A\\mathbf{x} = \\mathbf{b}$, where the properties of the matrix $A$ determine the difficulty of finding a solution. This exercise [@problem_id:2382055] explores how discretizing a diffusion equation with highly variable material properties creates an ill-conditioned matrix. You will implement a program not only to construct this matrix and measure its poor conditioning but also to apply a fundamental technique called Jacobi preconditioning and quantify its remarkable effectiveness in making the problem more numerically tractable.", "problem": "You are given a family of linear systems arising from the one-dimensional steady-state diffusion (Poisson-type) equation on the unit interval with homogeneous Dirichlet boundary conditions. Let $k(x) &gt; 0$ be a scalar conductivity function, and consider the boundary value problem on $x \\in [0,1]$ with $u(0) = 0$ and $u(1) = 0$:\n$$\n-\\frac{d}{dx}\\left(k(x)\\frac{du}{dx}\\right) = f(x).\n$$\nDiscretize this operator using $n$ interior points and a uniform grid spacing $h = \\frac{1}{n+1}$. Denote interior node locations by $x_i = i h$ for $i = 1,2,\\dots,n$, and interface locations by $x_{i+\\frac{1}{2}} = \\left(i+\\frac{1}{2}\\right) h$ for $i = 0,1,\\dots,n$. Form the symmetric positive definite matrix $A \\in \\mathbb{R}^{n \\times n}$ with entries\n$$\nA_{i,i} = \\frac{k\\!\\left(x_{i-\\frac{1}{2}}\\right) + k\\!\\left(x_{i+\\frac{1}{2}}\\right)}{h^2}, \\quad\nA_{i,i-1} = -\\frac{k\\!\\left(x_{i-\\frac{1}{2}}\\right)}{h^2}, \\quad\nA_{i,i+1} = -\\frac{k\\!\\left(x_{i+\\frac{1}{2}}\\right)}{h^2},\n$$\nwith the understanding that $A_{i,i-1}$ is present only for $i \\ge 2$ and $A_{i,i+1}$ only for $i \\le n-1$. This stencil corresponds to a consistent centered discretization of the fluxes using the conductivity sampled at interfaces.\n\nLet the Jacobi preconditioner be defined as the diagonal matrix $D = \\mathrm{diag}(A)$, and let the symmetrically preconditioned operator be\n$$\nS = D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}}.\n$$\nFor any symmetric positive definite matrix $X$, define the spectral condition number by\n$$\n\\kappa_2(X) = \\frac{\\lambda_{\\max}(X)}{\\lambda_{\\min}(X)},\n$$\nwhere $\\lambda_{\\max}(X)$ and $\\lambda_{\\min}(X)$ are the largest and smallest eigenvalues of $X$, respectively.\n\nTask: For each test case below, construct $A$ as defined, construct $D$ and $S$, and compute the triplet of real numbers\n$$\n\\Big(\\kappa_2(A), \\ \\kappa_2(S), \\ \\frac{\\kappa_2(A)}{\\kappa_2(S)}\\Big).\n$$\nRound each of the three numbers to six decimal places.\n\nTest suite (use $x$ in radians as usual; no physical units are required since all quantities are nondimensional in this setup):\n- Test 1 (uniform medium, moderate size): $n = 50$, $k(x) = 1$ for all $x \\in [0,1]$.\n- Test 2 (piecewise high-contrast medium): $n = 50$, $k(x) = 1$ for $x < 0.5$ and $k(x) = 100$ for $x \\ge 0.5$.\n- Test 3 (edge size): $n = 1$, $k(x) = 1 + x$ for $x \\in [0,1]$.\n- Test 4 (oscillatory high-contrast medium): $n = 51$, $k(x) = 100$ if $\\lfloor 20 x \\rfloor$ is even, and $k(x) = 1$ if $\\lfloor 20 x \\rfloor$ is odd.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list of lists, ordered as above, with each inner list being the three rounded floats for that test, for example:\n\"[[a1,b1,c1],[a2,b2,c2],[a3,b3,c3],[a4,b4,c4]]\"\nwhere each $a_j$, $b_j$, and $c_j$ is a decimal numeral with six digits after the decimal point.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extracted Givens.\n- Equation: $-\\frac{d}{dx}\\left(k(x)\\frac{du}{dx}\\right) = f(x)$ for $x \\in [0,1]$.\n- Boundary Conditions: $u(0) = 0$, $u(1) = 0$.\n- Discretization: $n$ interior points, uniform grid spacing $h = \\frac{1}{n+1}$.\n- Nodes: $x_i = i h$ for $i = 1,2,\\dots,n$.\n- Interfaces: $x_{i+\\frac{1}{2}} = \\left(i+\\frac{1}{2}\\right) h$ for $i = 0,1,\\dots,n$.\n- Matrix $A \\in \\mathbb{R}^{n \\times n}$: Symmetric positive definite, with entries $A_{i,i} = \\frac{k(x_{i-\\frac{1}{2}}) + k(x_{i+\\frac{1}{2}})}{h^2}$, $A_{i,i-1} = -\\frac{k(x_{i-\\frac{1}{2}})}{h^2}$, $A_{i,i+1} = -\\frac{k(x_{i+\\frac{1}{2}})}{h^2}$.\n- Preconditioner: $D = \\mathrm{diag}(A)$.\n- Preconditioned Matrix: $S = D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}}$.\n- Condition Number: $\\kappa_2(X) = \\frac{\\lambda_{\\max}(X)}{\\lambda_{\\min}(X)}$.\n- Task: Compute $(\\kappa_2(A), \\kappa_2(S), \\frac{\\kappa_2(A)}{\\kappa_2(S)})$ for four test cases, rounded to six decimal places.\n- Test Cases:\n    1.  $n = 50$, $k(x) = 1$.\n    2.  $n = 50$, $k(x) = 1$ for $x < 0.5$, $k(x) = 100$ for $x \\ge 0.5$.\n    3.  $n = 1$, $k(x) = 1 + x$.\n    4.  $n = 51$, $k(x) = 100$ if $\\lfloor 20 x \\rfloor$ is even, $k(x) = 1$ if $\\lfloor 20 x \\rfloor$ is odd.\n\nStep 2: Validation.\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard finite difference discretization of the one-dimensional Poisson-type equation, a fundamental problem in computational physics. The matrix $A$ generated by this method with $k(x) > 0$ is known to be symmetric and positive definite, ensuring that its eigenvalues are real and positive, and thus its condition number $\\kappa_2(A)$ is well-defined and greater than or equal to $1$. The Jacobi preconditioner $D$ is the diagonal of $A$, which will have strictly positive entries, making its inverse square root $D^{-1/2}$ real and well-defined. The resulting symmetrically preconditioned matrix $S$ is also symmetric and positive definite. All definitions and test cases are specified with sufficient precision to admit a unique, verifiable solution. The problem is therefore valid.\n\nStep 3: Action.\nThe problem is valid. We proceed with the solution.\n\nThe solution requires implementing a procedure to compute the spectral condition numbers for the matrix $A$ and its Jacobi-preconditioned counterpart $S$ for each specified test case. The methodology is as follows.\n\nFor each test case, defined by the number of interior points $n$ and the conductivity function $k(x)$:\n1.  First, the grid spacing $h$ is calculated as $h = \\frac{1}{n+1}$.\n\n2.  Next, the $n \\times n$ matrix $A$ is constructed. We may use zero-based indexing for implementation, where array indices `i`, `j` run from `0` to `n-1`. The mathematical index `i` from `1` to `n` corresponds to the programmatic index `i-1`.\n    - The diagonal entries are $A_{i,i} = \\frac{k(x_{i-\\frac{1}{2}}) + k(x_{i+\\frac{1}{2}})}{h^2}$. In program terms, for an index `i` from `0` to `n-1`, this is `A[i,i] = (k_func((i + 0.5)*h) + k_func((i + 1.5)*h)) / h**2`.\n    - The off-diagonal entries are defined by $A_{i,i+1} = -\\frac{k(x_{i+\\frac{1}{2}})}{h^2}$ and $A_{i,i-1} = -\\frac{k(x_{i-\\frac{1}{2}})}{h^2}$. Due to the symmetry of the problem formulation, $A_{ij} = A_{ji}$. For an index `i` from `0` to `n-2`, the super-diagonal entry is `A[i,i+1] = -k_func((i + 1.5)*h) / h**2`. The sub-diagonal is populated by symmetry, `A[i+1,i] = A[i,i+1]`.\n\n3.  The Jacobi preconditioner $D$ is a diagonal matrix containing the diagonal entries of $A$. We extract this diagonal, $D_{ii} = A_{ii}$.\n\n4.  The symmetrically preconditioned matrix $S = D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}}$ is constructed. Its entries are given by $S_{ij} = \\frac{A_{ij}}{\\sqrt{D_{ii} D_{jj}}}$. Computationally, this is achieved by first computing the vector of diagonal entries of $D^{-1/2}$, which are $1/\\sqrt{A_{ii}}$, and then scaling the matrix $A$. The diagonal elements of $S$ are all equal to $1$.\n\n5.  The spectral condition number $\\kappa_2(X)$ is computed for both $X=A$ and $X=S$. Since $A$ and $S$ are symmetric positive definite, their eigenvalues are real and positive. We compute the full spectrum of eigenvalues for each matrix using a reliable numerical method, such as the one implemented in `numpy.linalg.eigh`. The condition number is the ratio of the largest eigenvalue $\\lambda_{\\max}$ to the smallest eigenvalue $\\lambda_{\\min}$.\n    $$\n    \\kappa_2(X) = \\frac{\\lambda_{\\max}(X)}{\\lambda_{\\min}(X)}\n    $$\n\n6.  Finally, the analysis triplet $(\\kappa_2(A), \\kappa_2(S), \\frac{\\kappa_2(A)}{\\kappa_2(S)})$ is assembled. The ratio $\\frac{\\kappa_2(A)}{\\kappa_2(S)}$ measures the effectiveness of the Jacobi preconditioner at reducing the condition number. A value greater than $1$ indicates an improvement. Each of the three values in the triplet is rounded to six decimal places as required.\n\nThis procedure is systematically applied to the four test cases.\n- Test $1$ ($n=50$, $k(x)=1$): For a constant $k(x)$, the matrix $A$ is a multiple of the standard discrete Laplacian. Its diagonal $D$ is a multiple of the identity matrix. Consequently, $S$ is a scaling of $A$, and their condition numbers are identical, yielding $\\kappa_2(A) / \\kappa_2(S) = 1$.\n- Test $2$ ($n=50$, high-contrast jump): The large jump in $k(x)$ induces a large variation in the magnitudes of the entries of $A$, leading to a large $\\kappa_2(A)$. The Jacobi preconditioner, by scaling each row, mitigates this variation. We expect $\\kappa_2(S) \\ll \\kappa_2(A)$ and a large improvement ratio.\n- Test $3$ ($n=1$): This is a trivial case with a $1 \\times 1$ matrix. For any scalar matrix $A = [c]$ with $c \\ne 0$, $\\lambda_{\\max} = \\lambda_{\\min} = c$, so $\\kappa_2(A) = 1$. The same holds for $S$, thus the result is expected to be $(1, 1, 1)$.\n- Test $4$ ($n=51$, oscillating contrast): The rapid oscillation of $k(x)$ between $1$ and $100$ presents a difficult case. The entries of $A$ and its diagonal $D$ fluctuate significantly, leading to a large condition number. Jacobi preconditioning is expected to provide some benefit, but its local nature may be insufficient to fully resolve the poor conditioning arising from oscillations over different length scales.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the result.\n    \"\"\"\n\n    def k_func_1(x):\n        return 1.0\n\n    def k_func_2(x):\n        return 1.0 if x < 0.5 else 100.0\n\n    def k_func_3(x):\n        return 1.0 + x\n\n    def k_func_4(x):\n        # The floor of 20*x is an integer. Check if it's even or odd.\n        return 100.0 if np.floor(20.0 * x) % 2 == 0 else 1.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (50, k_func_1),\n        (50, k_func_2),\n        (1, k_func_3),\n        (51, k_func_4),\n    ]\n\n    results = []\n    for n, k_func in test_cases:\n        result_triplet = calculate_condition_numbers(n, k_func)\n        results.append(result_triplet)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"[{r[0]:.6f},{r[1]:.6f},{r[2]:.6f}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef calculate_condition_numbers(n, k_func):\n    \"\"\"\n    Builds matrices A and S, and computes their condition numbers.\n    \n    Args:\n        n (int): The number of interior grid points.\n        k_func (function): The conductivity function k(x).\n\n    Returns:\n        tuple: A triplet of floats (kappa_A, kappa_S, ratio).\n    \"\"\"\n\n    # For n=0, matrices are empty. Problem constraints imply n>=1.\n    # For n=1, matrix is 1x1, condition number is 1, a special case.\n    if n == 1:\n        # For a 1x1 matrix, lambda_max = lambda_min, so kappa = 1.\n        # This holds for A and S.\n        return (1.0, 1.0, 1.0)\n\n    h = 1.0 / (n + 1.0)\n    \n    # Construct the matrix A\n    A = np.zeros((n, n))\n    h2 = h * h\n\n    # Vectorized calculation of k values at interfaces\n    # Interfaces are at (i + 0.5) * h for i = 0, ..., n\n    interface_x = (np.arange(n + 1) + 0.5) * h\n    k_at_interfaces = np.array([k_func(x) for x in interface_x])\n\n    for i in range(n):\n        # In mathematical notation, this is row i+1\n        # Interface indices are i and i+1, corresponding to x_{i+1/2} and x_{i+3/2}\n        k_imhalf = k_at_interfaces[i]\n        k_iphalf = k_at_interfaces[i+1]\n\n        # Diagonal entry\n        A[i, i] = (k_imhalf + k_iphalf) / h2\n        # Off-diagonal entries\n        if i < n - 1:\n            A[i, i + 1] = -k_iphalf / h2\n            A[i + 1, i] = -k_iphalf / h2 # By symmetry argument in problem description\n\n    # Eigenvalues and condition number of A\n    eigvals_A = np.linalg.eigh(A)[0]\n    kappa_A = eigvals_A[-1] / eigvals_A[0]\n\n    # Construct the symmetrically preconditioned matrix S\n    D_diag = np.diag(A)\n    D_inv_sqrt_diag = 1.0 / np.sqrt(D_diag)\n    \n    # Efficiently compute S = D^{-1/2} A D^{-1/2} using element-wise multiplication\n    # with an outer product of the scaling vector.\n    S = A * np.outer(D_inv_sqrt_diag, D_inv_sqrt_diag)\n    \n    # Eigenvalues and condition number of S\n    eigvals_S = np.linalg.eigh(S)[0]\n    kappa_S = eigvals_S[-1] / eigvals_S[0]\n    \n    # Ratio\n    ratio = kappa_A / kappa_S\n\n    return (round(kappa_A, 6), round(kappa_S, 6), round(ratio, 6))\n\nsolve()\n```", "id": "2382055"}]}