{"hands_on_practices": [{"introduction": "A primary goal in metagenomics is to quantify the diversity within a microbial community, a concept known as alpha diversity. Indices like the Shannon and Simpson indices are used to distill complex community structures into a single number, but they do so in different ways. This practice provides a hands-on opportunity to explore their distinct properties by computationally simulating the introduction of rare species into a community, a task directly relevant to understanding how these indices respond to changes in richness versus evenness [@problem_id:2405536].", "problem": "In metagenomic analysis of either 16S ribosomal RNA (16S rRNA) amplicon data or whole-genome shotgun data, within-sample diversity is often summarized by indices based on the empirical relative abundances of observed taxa. Consider a community represented by a finite list of nonnegative integer read counts $\\mathbf{c} = [c_1,c_2,\\dots,c_S]$ with total $N = \\sum_{i=1}^{S} c_i$ and corresponding relative abundances $p_i = c_i / N$ for $i \\in \\{1,\\dots,S\\}$. Define the Shannon index (natural logarithm) as $H = -\\sum_{i=1}^{S} p_i \\ln p_i$ and the Simpson concentration index as $D = \\sum_{i=1}^{S} p_i^2$. A small influx of additional rare taxa increases richness while minimally altering evenness.\n\nYou must write a program that constructs a deterministic synthetic perturbation of each provided baseline community by reallocating a specified integer number of reads $m$ from a designated existing taxon to $k$ new taxa, each new taxon receiving exactly $m/k$ reads, so that the total read count remains constant. For a given test case with parameters $(\\mathbf{c}, j, m, k)$, where $j$ is a one-based index identifying the existing taxon to be debited, the perturbed community $\\mathbf{c}'$ is obtained by:\n- Replacing $c_j$ by $c_j - m$.\n- Appending $k$ new taxa, each with count $m/k$.\n- Leaving all other counts unchanged.\n\nAssume that $m$ and $k$ are positive integers with $k$ dividing $m$, and that $c_j \\ge m$ so that all counts remain nonnegative. For each test case, compute $H$ and $D$ before and after perturbation and report the boolean value of the statement $\\lvert H' - H \\rvert > \\lvert D' - D \\rvert$, where $H'$ and $D'$ are the indices for $\\mathbf{c}'$ and $H$ and $D$ are the indices for $\\mathbf{c}$.\n\nUse the following test suite, which covers a range of realistic metagenomic compositions and perturbations:\n- Test case A (uneven amplicon-like community): $\\mathbf{c} = [7000,2000,800,150,50]$, $j = 1$, $m = 100$, $k = 10$.\n- Test case B (even community): $\\mathbf{c} = [2000,2000,2000,2000,2000]$, $j = 1$, $m = 100$, $k = 10$.\n- Test case C (highly dominated shotgun-like community): $\\mathbf{c} = [9500,500]$, $j = 1$, $m = 50$, $k = 50$.\n- Test case D (minimal single rare-taxon addition): $\\mathbf{c} = [999,1]$, $j = 1$, $m = 1$, $k = 1$.\n\nAll logarithms must be natural logarithms, and all computations are dimensionless. Your program must produce a single line of output containing the boolean results for the test cases in the order A, B, C, D as a comma-separated list enclosed in square brackets (for example, $[{\\tt True},{\\tt False},{\\tt True},{\\tt True}]$). The required final outputs are booleans, and no additional text should be printed.", "solution": "We model a microbial community by a finite set of taxa with read counts $\\mathbf{c} = [c_1,\\dots,c_S]$ and total $N=\\sum_{i=1}^{S} c_i$. The empirical relative abundance of taxon $i$ is $p_i = c_i/N$. The Shannon index is $H = -\\sum_{i=1}^{S} p_i \\ln p_i$, derived from information theory as the entropy of the categorical distribution induced by $\\{p_i\\}$. The Simpson concentration index is $D = \\sum_{i=1}^{S} p_i^2$, the probability that two independent reads drawn without replacement but approximated as independent from the relative abundance distribution belong to the same taxon; it emphasizes abundant taxa because the squaring operation increases the weight of large $p_i$.\n\nTo formalize the perturbation that increases richness, fix integers $m>0$ and $k>0$ and a one-based index $j \\in \\{1,\\dots,S\\}$ identifying the source taxon. We construct $\\mathbf{c}'$ by subtracting $m$ from $c_j$ and appending $k$ new taxa, each with count $m/k$. This preserves the total count $N' = N - m + k \\cdot (m/k) = N$. The new relative abundances are $p'_i = c'_i/N$. Because each new taxon has probability mass $f/k$ where $f = m/N$, their contributions to $H$ and $D$ are small when $f$ is small, reflecting rarity.\n\nTo compare sensitivities, define the absolute change in Shannon index as $\\Delta_H = \\lvert H' - H \\rvert$ and the absolute change in Simpson concentration as $\\Delta_D = \\lvert D' - D \\rvert$. Analytically, when a fraction $f$ of mass is moved from one taxon with probability $p_j$ to $k$ new taxa equally, a first-order approximation yields\n- $\\Delta_D \\approx 2 f p_j$ (the leading term arises from the derivative of $p_j^2$),\n- $\\Delta_H \\approx f \\left[\\ln\\!\\left(\\frac{p_j k}{f}\\right) + 1 \\right]$ (from the derivative of $-p \\ln p$ for the donor taxon and the entropy added by the $k$ new taxa).\nFor small $f$ and moderate $k$, the logarithmic term $\\ln(p_j k / f)$ is typically large, so $\\Delta_H$ often exceeds $\\Delta_D$, expressing that the Shannon index is more sensitive to rare taxa than the Simpson concentration index.\n\nWe now compute the quantities exactly from first principles for the specified test suite by:\n- Converting integer counts to probabilities via $p_i = c_i/N$.\n- Computing $H$ and $D$ as defined.\n- Applying the deterministic perturbation $(\\mathbf{c}, j, m, k) \\mapsto \\mathbf{c}'$ with $c'_j = c_j - m$ and $k$ appended counts equal to $m/k$.\n- Recomputing $H'$ and $D'$ and evaluating the boolean $\\Delta_H > \\Delta_D$.\n\nFor each test case:\n- Test case A uses $\\mathbf{c} = [7000,2000,800,150,50]$, $N = 7000 + 2000 + 800 + 150 + 50 = 10000$, with $j = 1$, $m = 100$, $k = 10$. Here $f = m/N = 100/10000 = 0.01$. The perturbation debits the most abundant taxon and creates $10$ rare taxa.\n- Test case B uses $\\mathbf{c} = [2000,2000,2000,2000,2000]$, $N = 10000$, $j = 1$, $m = 100$, $k = 10$, representing an even community perturbed identically.\n- Test case C uses $\\mathbf{c} = [9500,500]$, $N = 10000$, $j = 1$, $m = 50$, $k = 50$, i.e., $f = 0.005$ and many singletons are added.\n- Test case D uses $\\mathbf{c} = [999,1]$, $N = 1000$, $j = 1$, $m = 1$, $k = 1$, adding a single new rare taxon.\n\nIn all cases, the computations yield $\\Delta_H > \\Delta_D$, consistent with the principle that the Shannon index is more sensitive to changes in richness due to rare taxa than the Simpson concentration index. The program will implement these definitions and transformations exactly, using natural logarithms, and will output $[{\\tt True},{\\tt True},{\\tt True},{\\tt True}]$ in the required single-line format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef shannon_index(probabilities: np.ndarray) -> float:\n    # Compute H = -sum p_i ln p_i with natural logarithm\n    p = probabilities\n    # Mask to avoid log(0); by construction we will not have zeros for present taxa\n    mask = p > 0\n    return float(-np.sum(p[mask] * np.log(p[mask])))\n\ndef simpson_concentration(probabilities: np.ndarray) -> float:\n    # Compute D = sum p_i^2\n    p = probabilities\n    return float(np.sum(p * p))\n\ndef to_probabilities(counts: np.ndarray) -> np.ndarray:\n    total = np.sum(counts)\n    return counts.astype(float) / float(total)\n\ndef perturb_counts(counts: np.ndarray, j_one_based: int, m: int, k: int) -> np.ndarray:\n    # Deterministic perturbation: subtract m from taxon j (1-based), append k taxa with m/k each\n    counts = counts.astype(int).copy()\n    j = j_one_based - 1  # convert to 0-based index\n    if m % k != 0:\n        raise ValueError(\"m must be divisible by k\")\n    if counts[j] < m:\n        raise ValueError(\"Insufficient counts to debit m from selected taxon\")\n    counts[j] -= m\n    # Append k new taxa, each with m/k counts\n    new_counts = np.concatenate([counts, np.full(k, m // k, dtype=int)])\n    return new_counts\n\ndef evaluate_case(counts_list, j_idx, m, k) -> bool:\n    counts = np.array(counts_list, dtype=int)\n    p_before = to_probabilities(counts)\n    H_before = shannon_index(p_before)\n    D_before = simpson_concentration(p_before)\n\n    counts_after = perturb_counts(counts, j_idx, m, k)\n    p_after = to_probabilities(counts_after)\n    H_after = shannon_index(p_after)\n    D_after = simpson_concentration(p_after)\n\n    delta_H = abs(H_after - H_before)\n    delta_D = abs(D_after - D_before)\n\n    return delta_H > delta_D\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (counts_list, j_one_based, m, k)\n    test_cases = [\n        ([7000, 2000, 800, 150, 50], 1, 100, 10),   # Test case A\n        ([2000, 2000, 2000, 2000, 2000], 1, 100, 10),  # Test case B\n        ([9500, 500], 1, 50, 50),                   # Test case C\n        ([999, 1], 1, 1, 1),                        # Test case D\n    ]\n\n    results = []\n    for counts_list, j_idx, m, k in test_cases:\n        result = evaluate_case(counts_list, j_idx, m, k)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2405536"}, {"introduction": "After assessing diversity within samples, a logical next step is to compare compositions between them, a measure known as beta diversity. The Bray-Curtis dissimilarity is a cornerstone metric for this purpose, quantifying how different two communities are based on taxon abundances. This exercise will guide you in implementing the Bray-Curtis formula from first principles, building your intuition for how it behaves across diverse ecological scenarios, including the important case where a single hyper-abundant organism can dominate the signal [@problem_id:2405539].", "problem": "You are given two nonnegative integer-valued community abundance vectors representing the taxon-specific read counts obtained from either 16S ribosomal ribonucleic acid (rRNA) gene amplicon sequencing or shotgun metagenomic sequencing. For two communities with abundance vectors $\\mathbf{x} = (x_1, x_2, \\dots, x_K)$ and $\\mathbf{y} = (y_1, y_2, \\dots, y_K)$ over the same ordered list of $K$ taxa, the Bray–Curtis dissimilarity $D_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y})$ is defined by\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{\\sum_{i=1}^{K} \\lvert x_i - y_i \\rvert}{\\sum_{i=1}^{K} (x_i + y_i)} \\, .\n$$\nThis quantity is dimensionless and lies in the closed interval $[0,1]$ when the denominator is nonzero.\n\nWrite a complete program that, using the above definition, computes the Bray–Curtis dissimilarity for each of the following test pairs of communities. Each community vector is specified over the same fixed order of taxa for that pair. All entries are nonnegative integers and represent read counts.\n\nTest suite (each item is a pair $(\\mathbf{x}, \\mathbf{y})$):\n- Case A (general case): $\\mathbf{x} = (12, 3, 0, 5)$ and $\\mathbf{y} = (10, 5, 0, 3)$.\n- Case B (identical communities): $\\mathbf{x} = (7, 0, 4)$ and $\\mathbf{y} = (7, 0, 4)$.\n- Case C (disjoint composition across taxa): $\\mathbf{x} = (0, 9, 0, 0)$ and $\\mathbf{y} = (0, 0, 0, 9)$.\n- Case D (one community has no observed reads while the other has some): $\\mathbf{x} = (0, 0, 0)$ and $\\mathbf{y} = (5, 0, 0)$.\n- Case E (hyper-abundant shared organism dominates): $\\mathbf{x} = (10000, 1, 1, 1)$ and $\\mathbf{y} = (10000, 0, 2, 1)$.\n\nFor each case, compute $D_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y})$ exactly as given. If the denominator $\\sum_{i=1}^{K} (x_i + y_i)$ equals $0$, the dissimilarity is undefined; none of the provided test cases fall into this undefined scenario.\n\nFinal output format: Your program should produce a single line of output containing the results for Cases A through E, in that order, as decimal numbers rounded to exactly $6$ decimal places, aggregated as a comma-separated list enclosed in square brackets. For example, the output must look like $[a,b,c,d,e]$ where $a$, $b$, $c$, $d$, and $e$ are the rounded values for Cases A, B, C, D, and E, respectively, with no additional text.", "solution": "The problem statement has been validated and is deemed acceptable for solution. It is scientifically grounded, well-posed, and objective. It requires the direct application of a standard, well-defined formula from computational biology, the Bray-Curtis dissimilarity, to several unambiguous test cases. We proceed with the calculations.\n\nThe Bray-Curtis dissimilarity, $D_{\\mathrm{BC}}$, between two community abundance vectors $\\mathbf{x} = (x_1, x_2, \\dots, x_K)$ and $\\mathbf{y} = (y_1, y_2, \\dots, y_K)$ is defined as:\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{\\sum_{i=1}^{K} \\lvert x_i - y_i \\rvert}{\\sum_{i=1}^{K} (x_i + y_i)}\n$$\nThis metric quantifies the compositional dissimilarity between two samples. A value of $0$ indicates identical composition, while a value of $1$ indicates no shared taxa. We will now compute this value for each specified case.\n\nCase A: General case\nGiven $\\mathbf{x} = (12, 3, 0, 5)$ and $\\mathbf{y} = (10, 5, 0, 3)$.\nThe sum of absolute differences in the numerator is:\n$$\n\\sum_{i=1}^{4} \\lvert x_i - y_i \\rvert = \\lvert 12 - 10 \\rvert + \\lvert 3 - 5 \\rvert + \\lvert 0 - 0 \\rvert + \\lvert 5 - 3 \\rvert = 2 + 2 + 0 + 2 = 6\n$$\nThe sum of abundances in the denominator is:\n$$\n\\sum_{i=1}^{4} (x_i + y_i) = (12 + 10) + (3 + 5) + (0 + 0) + (5 + 3) = 22 + 8 + 0 + 8 = 38\n$$\nThe dissimilarity is:\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{6}{38} \\approx 0.1578947...\n$$\n\nCase B: Identical communities\nGiven $\\mathbf{x} = (7, 0, 4)$ and $\\mathbf{y} = (7, 0, 4)$.\nThe numerator is:\n$$\n\\sum_{i=1}^{3} \\lvert x_i - y_i \\rvert = \\lvert 7 - 7 \\rvert + \\lvert 0 - 0 \\rvert + \\lvert 4 - 4 \\rvert = 0 + 0 + 0 = 0\n$$\nSince the numerator is $0$ and the denominator is non-zero, the dissimilarity is $0$.\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = 0\n$$\n\nCase C: Disjoint composition\nGiven $\\mathbf{x} = (0, 9, 0, 0)$ and $\\mathbf{y} = (0, 0, 0, 9)$.\nThe numerator is:\n$$\n\\sum_{i=1}^{4} \\lvert x_i - y_i \\rvert = \\lvert 0 - 0 \\rvert + \\lvert 9 - 0 \\rvert + \\lvert 0 - 0 \\rvert + \\lvert 0 - 9 \\rvert = 0 + 9 + 0 + 9 = 18\n$$\nThe denominator is:\n$$\n\\sum_{i=1}^{4} (x_i + y_i) = (0 + 0) + (9 + 0) + (0 + 0) + (0 + 9) = 0 + 9 + 0 + 9 = 18\n$$\nThe dissimilarity is:\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{18}{18} = 1\n$$\n\nCase D: One empty community\nGiven $\\mathbf{x} = (0, 0, 0)$ and $\\mathbf{y} = (5, 0, 0)$. Note that $\\mathbf{x}$ is not truly an empty community as it is compared to $\\mathbf{y}$ which has taxa; rather $\\mathbf{x}$ has zero observed counts for all taxa under consideration.\nThe numerator is:\n$$\n\\sum_{i=1}^{3} \\lvert x_i - y_i \\rvert = \\lvert 0 - 5 \\rvert + \\lvert 0 - 0 \\rvert + \\lvert 0 - 0 \\rvert = 5 + 0 + 0 = 5\n$$\nThe denominator is:\n$$\n\\sum_{i=1}^{3} (x_i + y_i) = (0 + 5) + (0 + 0) + (0 + 0) = 5 + 0 + 0 = 5\n$$\nThe dissimilarity is:\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{5}{5} = 1\n$$\n\nCase E: Hyper-abundant shared organism\nGiven $\\mathbf{x} = (10000, 1, 1, 1)$ and $\\mathbf{y} = (10000, 0, 2, 1)$.\nThe numerator is:\n$$\n\\sum_{i=1}^{4} \\lvert x_i - y_i \\rvert = \\lvert 10000 - 10000 \\rvert + \\lvert 1 - 0 \\rvert + \\lvert 1 - 2 \\rvert + \\lvert 1 - 1 \\rvert = 0 + 1 + 1 + 0 = 2\n$$\nThe denominator is:\n$$\n\\sum_{i=1}^{4} (x_i + y_i) = (10000 + 10000) + (1 + 0) + (1 + 2) + (1 + 1) = 20000 + 1 + 3 + 2 = 20006\n$$\nThe dissimilarity is:\n$$\nD_{\\mathrm{BC}}(\\mathbf{x}, \\mathbf{y}) = \\frac{2}{20006} = \\frac{1}{10003} \\approx 0.00009997...\n$$\n\nThe final results, rounded to $6$ decimal places as required, are:\n- Case A: $0.157895$\n- Case B: $0.000000$\n- Case C: $1.000000$\n- Case D: $1.000000$\n- Case E: $0.000100", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Bray-Curtis dissimilarity for a test suite of community abundance vectors.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple containing two NumPy arrays (x, y).\n    test_cases = [\n        # Case A: General case\n        (np.array([12, 3, 0, 5]), np.array([10, 5, 0, 3])),\n        # Case B: Identical communities\n        (np.array([7, 0, 4]), np.array([7, 0, 4])),\n        # Case C: Disjoint composition\n        (np.array([0, 9, 0, 0]), np.array([0, 0, 0, 9])),\n        # Case D: One community with no observed reads\n        (np.array([0, 0, 0]), np.array([5, 0, 0])),\n        # Case E: Hyper-abundant shared organism\n        (np.array([10000, 1, 1, 1]), np.array([10000, 0, 2, 1])),\n    ]\n\n    results = []\n    for x, y in test_cases:\n        # The Bray-Curtis dissimilarity is defined as:\n        # D_BC(x, y) = sum(|x_i - y_i|) / sum(x_i + y_i)\n\n        # Calculate the numerator: sum of absolute differences between corresponding elements.\n        numerator = np.sum(np.abs(x - y))\n\n        # Calculate the denominator: sum of all elements in both vectors.\n        denominator = np.sum(x + y)\n\n        # Calculate the dissimilarity. The problem guarantees the denominator is non-zero.\n        if denominator == 0:\n            # This case is stated not to occur in the test suite.\n            # If it did, the dissimilarity would be undefined.\n            # We would handle it here, perhaps by appending a specific value like 'nan'.\n            # For this problem, we assume bray_curtis is always calculable.\n            # A common convention is to define it as 0, but we follow the problem.\n            bray_curtis = 0.0\n        else:\n            bray_curtis = numerator / denominator\n        \n        results.append(bray_curtis)\n\n    # Format the results to exactly 6 decimal places, as specified.\n    # The \"{:.6f}\".format() method ensures rounding and padding with zeros.\n    formatted_results = [\"{:.6f}\".format(r) for r in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2405539"}, {"introduction": "Moving beyond descriptive summaries of diversity, metagenomic analysis enables us to investigate functional roles and interactions, such as those between viruses and their microbial hosts. This advanced practice simulates a real-world bioinformatics challenge: predicting the host of a novel virus by integrating two powerful and distinct lines of evidence. You will build a model that combines direct evidence of past infection from CRISPR spacer matches with the subtler patterns of codon usage similarity, providing a practical lesson in multi-modal data integration for uncovering ecological links [@problem_id:2405543].", "problem": "You are given a simplified, self-contained framework to predict the most likely prokaryotic host of a novel viral contig from a gut shotgun metagenomic dataset by combining Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) spacer matches and codon usage bias analysis. Your task is to implement a program that computes a host score for each candidate host based on these two evidence types and selects the host with the highest combined score for each test contig.\n\nFundamental base and definitions:\n- CRISPR biology: Prokaryotic hosts integrate short spacers derived from mobile genetic elements (for example, viruses) into CRISPR arrays. A strong spacer-protospacer match between a host’s spacer and a viral contig provides evidence for a host-virus interaction.\n- Codon usage bias: Different hosts exhibit characteristic codon usage distributions across the set of all possible deoxyribonucleic acid (DNA) codons. Viruses infecting a host often show codon usage more similar to that host. Codon usage can be represented by a frequency vector over the set of $64$ possible DNA codons.\n- Hamming distance: For two strings $x$ and $y$ of equal length $L$, the Hamming distance is $d_{\\mathrm{H}}(x,y) = \\left|\\left\\{ i \\in \\{1,\\dots,L\\} : x_i \\neq y_i \\right\\}\\right|$.\n- Reverse complement: For a DNA string $s \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}^L$, the reverse complement $\\mathrm{rc}(s)$ is the reverse of $s$ with base-wise complements $\\mathrm{A}\\leftrightarrow\\mathrm{T}$ and $\\mathrm{C}\\leftrightarrow\\mathrm{G}$.\n- Cosine similarity: For nonnegative vectors $u, v \\in \\mathbb{R}^{64}$, the cosine similarity is $\\cos(u,v) = \\dfrac{u \\cdot v}{\\|u\\|_2 \\, \\|v\\|_2}$, where the dot denotes the Euclidean inner product and $\\|\\cdot\\|_2$ denotes the Euclidean norm.\n\nScoring model to implement:\n1) CRISPR evidence for host $h$:\n   - Let the set of spacers for host $h$ be $S_h = \\{ s^{(h)}_1, \\dots, s^{(h)}_{n_h} \\}$, where spacer $s^{(h)}_j$ has length $L_j$.\n   - For a viral contig string $C$, and a given maximum mismatch threshold $m_{\\max}$, define the best mismatch count for spacer $s$ against $C$ as\n     $$m^*(s,C) = \\min\\left\\{ \\min_{w \\in \\mathcal{W}(C, L)} d_{\\mathrm{H}}(s,w), \\; \\min_{w \\in \\mathcal{W}(C, L)} d_{\\mathrm{H}}(\\mathrm{rc}(s),w) \\right\\},$$\n     where $\\mathcal{W}(C, L)$ is the multiset of all length-$L$ windows of $C$.\n   - The contribution of spacer $s$ is\n     $$\\phi(s,C) = \\begin{cases}\n     \\dfrac{L - m^*(s,C)}{L}, & \\text{if } m^*(s,C) \\le m_{\\max} \\\\[6pt]\n     0, & \\text{otherwise.}\n     \\end{cases}$$\n   - The CRISPR evidence score for host $h$ is the mean spacer contribution\n     $$E_h(C) = \\begin{cases}\n     \\dfrac{1}{n_h} \\sum_{j=1}^{n_h} \\phi\\!\\left(s^{(h)}_j, C\\right), & \\text{if } n_h \\ge 1 \\\\[6pt]\n     0, & \\text{if } n_h = 0.\n     \\end{cases}$$\n\n2) Codon usage similarity for host $h$:\n   - For a coding DNA sequence $X$ of length divisible by $3$, define the codon count vector $c(X) \\in \\mathbb{N}^{64}$ over all DNA triplets in lexicographic order. Define the frequency vector $f(X) \\in [0,1]^{64}$ by\n     $$f(X) = \\frac{c(X)}{\\sum_{i=1}^{64} c_i(X)}.$$\n   - For host $h$ with host coding sequence $H_h$, and viral open reading frame (ORF) sequence $V$, compute\n     $$U_h(V) = \\cos\\!\\left(f(H_h), f(V)\\right) = \\frac{f(H_h) \\cdot f(V)}{\\|f(H_h)\\|_2 \\, \\|f(V)\\|_2}.$$\n\n3) Combined score and prediction:\n   - Given nonnegative weights $w_C$ and $w_U$ with $w_C + w_U = 1$, define\n     $$T_h(C,V) = w_C \\, E_h(C) + w_U \\, U_h(V).$$\n   - Predict the host as the index $h$ that maximizes $T_h(C,V)$. In the event of an exact tie in $T_h$, select the smallest such index.\n\nParameter values to use:\n- Number of candidate hosts: $3$, indexed as $0,1,2$.\n- Maximum mismatch threshold: $m_{\\max} = 1$.\n- Weights: $w_C = 0.7$, $w_U = 0.3$.\n- Host CRISPR spacers:\n  - Host $0$: $S_0 = \\{\\texttt{ATGCTTACGA}, \\texttt{TTTATATAAA}\\}$.\n  - Host $1$: $S_1 = \\{\\texttt{GCGCCGCGGC}, \\texttt{CCGGGCGGCC}\\}$.\n  - Host $2$: $S_2 = \\{\\}$ (no spacers).\n- Host coding DNA sequences $H_h$ are constructed by repeating the following codon patterns $30$ times (concatenate the triplets in order and then repeat the concatenated block):\n  - Host $0$ pattern: [TTT, TTA, TAT, ATA, ATT, AAA, AAT].\n  - Host $1$ pattern: [GCG, GGC, CCG, CGC, GCC, CCC, GGG].\n  - Host $2$ pattern: [CTG, GAT, ATG, ACC, TCC, GTA, GTT].\n\nTest suite:\nProvide four viral test cases. Each test case $i$ supplies a contig string $C_i$ and a viral ORF sequence $V_i$ defined by repeating a codon pattern $5$ times, built analogously to hosts.\n- Test $1$ (happy path; strong CRISPR evidence for host $0$):\n  - $C_1 =$ the string \"GGGATGCTTACGATTTACGCCGTA\".\n  - $V_1$ pattern: [TTT, TTA, TAT, ATA, ATT, AAA, AAT].\n- Test $2$ (boundary on mismatches; CRISPR evidence ties, codon usage breaks in favor of host $1$):\n  - $C_2 =$ the string \"AAAGCGCCGCGGATTGTTTTATATCAAACCC\".\n  - $V_2$ pattern: [GCG, GGC, CCG, CGC, GCC, CCC, GGG].\n- Test $3$ (no CRISPR matches; rely solely on codon usage; favors host $2$):\n  - $C_3 =$ the string \"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\".\n  - $V_3$ pattern: [CTG, GAT, ATG, ACC, TCC, GTA, GTT].\n- Test $4$ (edge case interplay; one-mismatch CRISPR for host $0$ vs strong codon usage for host $1$; weights favor CRISPR):\n  - $C_4 =$ the string \"TTTATGCTTACGGAAA\".\n  - $V_4$ pattern: [GCG, GGC, CCG, CGC, GCC, CCC, GGG].\n\nRequired final output format:\n- Your program must produce a single line containing the predictions for the $4$ tests as a comma-separated list of integers in a single pair of square brackets, with no spaces. For example, the output must look like \"[0,1,2,0]\" but with the actual results computed by your program.\n\nNotes:\n- All DNA is uppercase and uses bases from $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$.\n- When computing codon usage, treat the sequence as already in-frame and of length divisible by $3$; do not translate or filter stop codons specially. Use all observed triplets to form $f(X)$.\n- For CRISPR matching, scan both the forward spacer and its reverse complement across all windows of the contig.\n- All reported quantities in your program must be computed from the provided definitions; do not hard-code expected answers.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of metagenomic analysis, specifically using CRISPR-spacer homology and codon usage bias for host-virus association. The problem is well-posed, providing all necessary definitions, parameters, and data to compute a unique solution for each test case. The objective is clearly defined, and the scoring model is mathematically sound and free of ambiguity. We will proceed to construct the solution.\n\nThe core task is to determine the most likely host for a given viral contig by maximizing a composite score, $T_h$. For each candidate host $h \\in \\{0, 1, 2\\}$, this score is a weighted average of two components: a CRISPR evidence score $E_h(C)$ and a codon usage similarity score $U_h(V)$. The total score is defined as:\n$$T_h(C,V) = w_C \\, E_h(C) + w_U \\, U_h(V)$$\nThe problem specifies the weights as $w_C = 0.7$ and $w_U = 0.3$.\n\nFirst, we address the computation of the CRISPR evidence score, $E_h(C)$. This score reflects direct physical evidence of past interactions. Its calculation involves several steps:\n$1$. For each spacer $s$ of length $L$ belonging to a host $h$, we must find its best match within the viral contig $C$. This search must account for both the forward orientation of the spacer, $s$, and its reverse complement, $\\mathrm{rc}(s)$. The reverse complement is formed by reversing the sequence string and replacing each nucleotide with its Watson-Crick pair ($\\mathrm{A} \\leftrightarrow \\mathrm{T}$, $\\mathrm{C} \\leftrightarrow \\mathrm{G}$).\n$2$. The quality of a match is inverse to the Hamming distance, $d_{\\mathrm{H}}(x,y)$, which counts the number of positions at which two strings $x$ and $y$ of equal length differ.\n$3$. For a given spacer $s$, we compute the best mismatch count, $m^*(s,C)$, by scanning all length-$L$ windows of the contig $C$ and finding the minimum Hamming distance against both $s$ and $\\mathrm{rc}(s)$.\n$$m^*(s,C) = \\min\\left\\{ \\min_{w \\in \\mathcal{W}(C, L)} d_{\\mathrm{H}}(s,w), \\; \\min_{w \\in \\mathcal{W}(C, L)} d_{\\mathrm{H}}(\\mathrm{rc}(s),w) \\right\\}$$\nwhere $\\mathcal{W}(C, L)$ denotes the multiset of all length-$L$ substrings of $C$.\n$4$. A significant match is defined as one where $m^*(s,C)$ is less than or equal to a specified threshold, $m_{\\max} = 1$. The contribution of such a spacer, $\\phi(s,C)$, is a normalized score reflecting the match quality:\n$$\\phi(s,C) = \\begin{cases}\n \\dfrac{L - m^*(s,C)}{L}, & \\text{if } m^*(s,C) \\le m_{\\max} \\\\\n 0, & \\text{otherwise.}\n \\end{cases}$$\nA perfect match ($m^* = 0$) contributes $1$, a $1$-mismatch match contributes $(L-1)/L$, and any match with more than $m_{\\max}$ mismatches contributes $0$.\n$5$. The final CRISPR evidence score for host $h$, $E_h(C)$, is the arithmetic mean of the contributions from all its spacers. If a host has no spacers ($n_h = 0$), its score is $0$.\n$$E_h(C) = \\begin{cases}\n \\dfrac{1}{n_h} \\sum_{j=1}^{n_h} \\phi\\!\\left(s^{(h)}_j, C\\right), & \\text{if } n_h \\ge 1 \\\\\n 0, & \\text{if } n_h = 0.\n \\end{cases}$$\n\nSecond, we implement the codon usage similarity score, $U_h(V)$. This score is based on the principle that a virus's codon usage tends to adapt to that of its host.\n$1$. We establish a fixed, ordered basis of all $64$ DNA codons (e.g., in lexicographical order from `AAA` to `TTT`).\n$2$. For any coding sequence $X$ (either a host's concatenated CDS, $H_h$, or a viral ORF, $V$), we compute a $64$-dimensional codon frequency vector, $f(X)$. This is achieved by first counting the occurrences of each of the $64$ codons in $X$ to get a count vector $c(X)$, and then normalizing this vector by the total number of codons:\n$$f(X) = \\frac{c(X)}{\\sum_{i=1}^{64} c_i(X)}$$\nWe pre-calculate these frequency vectors for the coding material of each host, $f(H_h)$, from the provided patterns.\n$3$. The similarity score $U_h(V)$ is then calculated as the cosine similarity between the host's frequency vector $f(H_h)$ and the virus's frequency vector $f(V)$:\n$$U_h(V) = \\cos\\!\\left(f(H_h), f(V)\\right) = \\frac{f(H_h) \\cdot f(V)}{\\|f(H_h)\\|_2 \\, \\|f(V)\\|_2}$$\nThis score ranges from $0$ (no shared codons) to $1$ (identical frequency distributions).\n\nFinally, for each viral test case $(C_i, V_i)$, we compute the total scores $T_0, T_1, T_2$. The predicted host is the index $h$ that yields the maximum score, $\\arg\\max_h T_h(C_i, V_i)$. In case of an exact tie, the problem specifies selecting the smallest host index, a rule naturally handled by standard `argmax` implementations. The program will execute this full procedure for all $4$ test cases and report the resulting predictions.", "answer": "```python\nimport numpy as np\nfrom itertools import product\n\ndef solve():\n    \"\"\"\n    Computes host predictions for novel viral contigs based on CRISPR and codon usage.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    NUM_HOSTS = 3\n    M_MAX = 1\n    W_C = 0.7\n    W_U = 0.3\n\n    HOST_SPACERS = {\n        0: ['ATGCTTACGA', 'TTTATATAAA'],\n        1: ['GCGCCGCGGC', 'CCGGGCGGCC'],\n        2: []\n    }\n\n    HOST_PATTERNS = {\n        0: ['TTT', 'TTA', 'TAT', 'ATA', 'ATT', 'AAA', 'AAT'],\n        1: ['GCG', 'GGC', 'CCG', 'CGC', 'GCC', 'CCC', 'GGG'],\n        2: ['CTG', 'GAT', 'ATG', 'ACC', 'TCC', 'GTA', 'GTT']\n    }\n\n    TEST_CASES = [\n        {\n            \"C\": \"GGGATGCTTACGATTTACGCCGTA\",\n            \"V_pattern\": ['TTT', 'TTA', 'TAT', 'ATA', 'ATT', 'AAA', 'AAT']\n        },\n        {\n            \"C\": \"AAAGCGCCGCGGATTGTTTTATATCAAACCC\",\n            \"V_pattern\": ['GCG', 'GGC', 'CCG', 'CGC', 'GCC', 'CCC', 'GGG']\n        },\n        {\n            \"C\": \"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\",\n            \"V_pattern\": ['CTG', 'GAT', 'ATG', 'ACC', 'TCC', 'GTA', 'GTT']\n        },\n        {\n            \"C\": \"TTTATGCTTACGGAAA\",\n            \"V_pattern\": ['GCG', 'GGC', 'CCG', 'CGC', 'GCC', 'CCC', 'GGG']\n        }\n    ]\n\n    # --- Helper Functions ---\n    def reverse_complement(dna_seq):\n        complement_map = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n        return \"\".join(complement_map[base] for base in reversed(dna_seq))\n\n    def hamming_distance(s1, s2):\n        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n\n    # --- Scoring Functions ---\n    def compute_crispr_score(contig, spacers):\n        if not spacers:\n            return 0.0\n\n        total_phi = 0.0\n        for spacer in spacers:\n            L = len(spacer)\n            if L > len(contig):\n                continue\n\n            rc_spacer = reverse_complement(spacer)\n            \n            min_dist_s = L + 1\n            min_dist_rc = L + 1\n\n            for i in range(len(contig) - L + 1):\n                window = contig[i:i+L]\n                min_dist_s = min(min_dist_s, hamming_distance(spacer, window))\n                min_dist_rc = min(min_dist_rc, hamming_distance(rc_spacer, window))\n\n            m_star = min(min_dist_s, min_dist_rc)\n            \n            phi = 0.0\n            if m_star <= M_MAX:\n                phi = (L - m_star) / L\n            total_phi += phi\n        \n        return total_phi / len(spacers)\n\n    def get_codon_freq_vector(sequence, codon_map):\n        counts = np.zeros(64, dtype=float)\n        num_codons = len(sequence) // 3\n        if num_codons == 0:\n            return counts\n\n        for i in range(num_codons):\n            codon = sequence[i*3:(i+1)*3]\n            if codon in codon_map:\n                counts[codon_map[codon]] += 1\n        \n        return counts / num_codons\n\n    def compute_codon_usage_score(vec1, vec2):\n        norm1 = np.linalg.norm(vec1)\n        norm2 = np.linalg.norm(vec2)\n        if norm1 == 0 or norm2 == 0:\n            return 0.0\n        return np.dot(vec1, vec2) / (norm1 * norm2)\n\n    # --- Main Logic ---\n\n    # Pre-compute host data\n    codons = [''.join(p) for p in product('ACGT', repeat=3)]\n    codon_map = {codon: i for i, codon in enumerate(codons)}\n    \n    host_sequences = {h: ''.join(p) * 30 for h, p in HOST_PATTERNS.items()}\n    host_freq_vectors = {\n        h: get_codon_freq_vector(seq, codon_map) for h, seq in host_sequences.items()\n    }\n\n    results = []\n    for test in TEST_CASES:\n        contig = test[\"C\"]\n        viral_seq = ''.join(test[\"V_pattern\"]) * 5\n        viral_freq_vector = get_codon_freq_vector(viral_seq, codon_map)\n\n        host_total_scores = []\n        for h in range(NUM_HOSTS):\n            e_h = compute_crispr_score(contig, HOST_SPACERS[h])\n            u_h = compute_codon_usage_score(host_freq_vectors[h], viral_freq_vector)\n            t_h = W_C * e_h + W_U * u_h\n            host_total_scores.append(t_h)\n            \n        prediction = np.argmax(host_total_scores)\n        results.append(prediction)\n    \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2405543"}]}