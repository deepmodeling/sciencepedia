{"hands_on_practices": [{"introduction": "Before diving into complex algorithms, it's crucial to understand the fundamental limits of genome assembly. This practice asks you to determine the best-case scenario for assembling a genome, building your intuition for the relationship between read length, genome size, and the very possibility of creating a complete sequence. By considering an idealized case without errors or repeats, you will derive the theoretical minimum number of reads required, providing a baseline against which all real-world assembly efforts are measured [@problem_id:2405190].", "id": "2405190", "problem": "A single linear DNA genome of length $1 \\times 10^{6}$ base pairs (bp) is to be assembled from error-free sequencing reads, each of fixed length $L$ bp. Assume the genome contains no repeat-induced ambiguities at any overlap length that occurs among the reads (so that any observed sequence overlap uniquely determines adjacency), and that the assembly goal is to produce one contiguous sequence spanning the full $1 \\times 10^{6}$ bp. What is the theoretical minimum number of reads of length $L$ required to achieve this? Express your answer as a closed-form symbolic expression in terms of $L$. Provide your final answer as an exact expression; no rounding is required.", "solution": "The problem statement is subjected to validation before a solution is attempted.\n\nFirst, I extract the givens verbatim:\n- Genome type: single linear DNA genome.\n- Genome length: $G = 1 \\times 10^{6}$ base pairs (bp).\n- Read length: $L$ bp (fixed).\n- Read quality: error-free.\n- Assembly condition: no repeat-induced ambiguities; any observed sequence overlap uniquely determines adjacency.\n- Assembly goal: produce one contiguous sequence spanning the full $1 \\times 10^{6}$ bp.\n- Question: theoretical minimum number of reads of length $L$.\n- Answer format: closed-form symbolic expression in terms of $L$.\n\nNext, I validate these givens against the required criteria.\n1.  **Scientifically Grounded:** The problem is a classic theoretical question in genomics, concerning the minimal requirements for genome assembly. The concepts of genome length, read length, overlap, and contiguity are fundamental to computational biology. The problem is scientifically sound.\n2.  **Well-Posed:** The request for a \"theoretical minimum\" number of reads implies an idealized, optimal placement of reads. The conditions given (error-free reads, no repeats) are standard simplifications for such theoretical problems, ensuring a unique and meaningful solution exists. The problem is well-posed.\n3.  **Objective:** The problem is stated using precise, quantitative language, free of subjectivity or ambiguity.\n4.  **Completeness:** The problem provides all necessary information ($G$ and $L$) to derive the theoretical minimum number of reads. It is self-contained.\n5.  **Feasibility:** While real genome assembly is a stochastic process (shotgun sequencing) complicated by errors and repeats, this problem addresses the deterministic lower bound, which is a valid and useful theoretical construct.\n\nThe verdict is that the problem is valid. It is a well-defined exercise in bioinformatics theory. I will proceed to derive the solution.\n\nLet the length of the genome be denoted by $G$, where $G = 1 \\times 10^{6}$ bp. Let the length of each read be $L$. The number of reads is $N$. We seek to find the minimum possible integer value of $N$, which we denote as $N_{min}$.\n\nFor a successful assembly into a single contiguous sequence (contig) that covers the entire genome, two conditions must be met:\n1.  **Coverage:** Every base pair from $1$ to $G$ must be contained within at least one read.\n2.  **Connectivity:** The set of reads must form a single connected component in an overlap graph, meaning they can be ordered sequentially such that each read overlaps with the next.\n\nTo find the minimum number of reads, $N_{min}$, we must arrange the reads in the most efficient manner possible. This means that each read must contribute the maximum possible amount of new, previously uncovered sequence length while maintaining the connectivity of the assembly. This is achieved by minimizing the overlap between adjacent reads in the sequence.\n\nThe problem statement asserts that \"any observed sequence overlap uniquely determines adjacency\". This is a critical piece of information. It implies that even the smallest possible overlap is sufficient to confidently link two reads. In a discrete sequence of base pairs, the minimum possible overlap is one base pair. Let this minimum overlap be $o_{min} = 1$ bp.\n\nLet us construct the optimal tiling of reads. The first read, $R_1$, covers a segment of the genome of length $L$. To maximize the total length covered by the next read, $R_2$, we place it such that it overlaps with $R_1$ by exactly $o_{min} = 1$ bp. By doing so, $R_2$ extends the total covered length by $L - o_{min} = L - 1$ base pairs.\n\nFollowing this logic, the first read covers $L$ base pairs. Each of the subsequent $N-1$ reads extends the contig by an additional $L-1$ base pairs. Therefore, the total length, $C(N)$, covered by $N$ reads arranged in this optimal configuration is:\n$$C(N) = L + (N-1)(L-1)$$\n\nFor the assembly to be complete, this total covered length must be at least the full genome length $G$.\n$$L + (N-1)(L-1) \\ge G$$\n\nWe now solve this inequality for $N$. The problem formulation is meaningful only if $L > 1$, as reads of length $L=1$ cannot form overlaps to create a contig. Therefore, we assume $L > 1$, which means $L-1 > 0$.\n$$(N-1)(L-1) \\ge G-L$$\n$$N-1 \\ge \\frac{G-L}{L-1}$$\n$$N \\ge 1 + \\frac{G-L}{L-1}$$\nSimplifying the right side:\n$$N \\ge \\frac{L-1}{L-1} + \\frac{G-L}{L-1} = \\frac{(L-1) + (G-L)}{L-1} = \\frac{G-1}{L-1}$$\nSo, we have the condition $N \\ge \\frac{G-1}{L-1}$. Since $N$ must be an integer (as it is a count of reads), the minimum number of reads $N_{min}$ is the smallest integer that satisfies this inequality. This is given by the ceiling function:\n$$N_{min} = \\left\\lceil \\frac{G-1}{L-1} \\right\\rceil$$\nThe problem specifies the genome length $G = 1 \\times 10^6$. Substituting this value provides the final expression in terms of $L$:\n$$N_{min} = \\left\\lceil \\frac{1 \\times 10^{6} - 1}{L-1} \\right\\rceil$$\nThis is the theoretical minimum number of reads required.", "answer": "$$\\boxed{\\left\\lceil \\frac{10^{6} - 1}{L - 1} \\right\\rceil}$$"}, {"introduction": "A common and serious error in genome assembly is the creation of a \"chimeric\" contig, where sequences from distant parts of a genome are incorrectly joined. This hands-on exercise guides you through developing a quantitative metric to detect such misassemblies by looking for tell-tale signs of a structural break. You will learn to implement an algorithm that systematically scans a contig for inconsistencies in both its sequence composition (using $k$-mers) and its read coverage, two powerful and orthogonal sources of evidence for assembly quality [@problem_id:2405143].", "id": "2405143", "problem": "You are given the task of defining and computing a quantitative metric that measures whether a contiguous assembled sequence (a contig) is likely to be a chimera by jointly assessing the consistency of its $k$-mer composition and its sequencing coverage along its length. Consider a contig as a string $S$ over the deoxyribonucleic acid (DNA) alphabet $\\{A,C,G,T\\}$, of length $L$, indexed by positions $1,2,\\dots,L$, and a nonnegative per-base coverage vector $D \\in \\mathbb{R}_{\\ge 0}^L$ whose component $D_j$ gives the coverage at position $j$.\n\nDefine the following, for a given positive integer window length $W$ and a positive integer $k$-mer length $k$ with alphabet size $|\\Sigma|=4$:\n1. Partition the contig into $M=\\left\\lfloor \\frac{L}{W} \\right\\rfloor$ non-overlapping windows of equal length $W$: window $i$ spans positions $((i-1)W+1)$ through $(iW)$ for $i \\in \\{1,2,\\dots,M\\}$. If $M<2$, define the final score to be $0$ by convention.\n2. For each window $i$, define the $k$-mer count function $c_i: \\Sigma^k \\to \\mathbb{N}_0$ as the number of occurrences of each exact $k$-mer (with stride $1$) entirely contained within the window. Let $N_i=\\max\\{W-k+1,0\\}$ be the number of $k$-mer positions in each window when $W \\ge k$ (and $0$ otherwise). Define the normalized $k$-mer frequency vector $p_i \\in \\mathbb{R}^{4^k}$ by $p_i(w)=\\frac{c_i(w)}{\\max\\{N_i,1\\}}$ for each $w \\in \\Sigma^k$.\n3. Define the composition inconsistency between adjacent windows $i$ and $(i+1)$ as the Euclidean distance\n$$\nd_i=\\left\\|p_i-p_{i+1}\\right\\|_2=\\sqrt{\\sum_{w \\in \\Sigma^k}\\left(p_i(w)-p_{i+1}(w)\\right)^2}.\n$$\nNormalize this using the bound $\\max d_i=\\sqrt{2}$ for distributions, and define the average normalized composition inconsistency\n$$\nI_{\\mathrm{comp}}=\\frac{1}{M-1}\\sum_{i=1}^{M-1}\\frac{d_i}{\\sqrt{2}}.\n$$\n4. Define the mean coverage in window $i$ as\n$$\n\\bar{c}_i=\\frac{1}{W}\\sum_{j=(i-1)W+1}^{iW} D_j.\n$$\nDefine the relative coverage inconsistency between adjacent windows $i$ and $(i+1)$ as\n$$\nr_i=\n\\begin{cases}\n0, & \\text{if }\\bar{c}_i+\\bar{c}_{i+1}=0,\\\n$$4pt]\n\\frac{\\left|\\bar{c}_{i+1}-\\bar{c}_i\\right|}{\\bar{c}_{i+1}+\\bar{c}_i}, & \\text{otherwise.}\n\\end{cases}\n$$\nDefine the average coverage inconsistency\n$$\nI_{\\mathrm{cov}}=\\frac{1}{M-1}\\sum_{i=1}^{M-1} r_i.\n$$\n5. Define the chimericity score as the convex combination\n$$\n\\mathrm{Score}=\\alpha I_{\\mathrm{comp}}+(1-\\alpha)I_{\\mathrm{cov}},\n$$\nwith $\\alpha=\\frac{1}{2}$.\n\nCompute the chimericity score for each of the following test cases. For each case, unless otherwise stated, use $k=3$, window length $W=30$, non-overlapping windows as above, and $\\alpha=\\frac{1}{2}$. All sequences are over $\\{A,C,G,T\\}$, and all coverages are nonnegative real values. Construct the sequences and coverage vectors exactly as specified:\n\n- Test case $1$ (balanced composition and uniform coverage):\n  - Length $L_1=120$.\n  - Sequence $S_1$: the first $L_1$ symbols of the infinite periodic string $\\text{\"ACGTACGT}\\dots\\text{\"}$.\n  - Coverage $D^{(1)}$: $D^{(1)}_j=30$ for all $j \\in \\{1,\\dots,L_1\\}$.\n\n- Test case $2$ (composition and coverage shift at midpoint):\n  - Length $L_2=120$.\n  - Sequence $S_2$: positions $1$ through $60$ are the first $60$ symbols of the infinite periodic string $\\text{\"GCGCGC}\\dots\\text{\"}$; positions $61$ through $120$ are the first $60$ symbols of the infinite periodic string $\\text{\"ATATAT}\\dots\\text{\"}$.\n  - Coverage $D^{(2)}$: $D^{(2)}_j=40$ for $j \\in \\{1,\\dots,60\\}$ and $D^{(2)}_j=10$ for $j \\in \\{61,\\dots,120\\}$.\n\n- Test case $3$ (short contig, fewer than two windows):\n  - Length $L_3=20$.\n  - Sequence $S_3$: the first $L_3$ symbols of the infinite periodic string $\\text{\"ACGTACGT}\\dots\\text{\"}$.\n  - Coverage $D^{(3)}$: $D^{(3)}_j=20$ for all $j \\in \\{1,\\dots,L_3\\}$.\n\n- Test case $4$ (identical composition across two windows, slightly different coverage):\n  - Length $L_4=60$.\n  - Sequence $S_4$: positions $1$ through $30$ are the first $30$ symbols of the infinite periodic string $\\text{\"ACGTACGT}\\dots\\text{\"}$; positions $31$ through $60$ are the first $30$ symbols of the same infinite periodic string.\n  - Coverage $D^{(4)}$: $D^{(4)}_j=20$ for $j \\in \\{1,\\dots,30\\}$ and $D^{(4)}_j=22$ for $j \\in \\{31,\\dots,60\\}$.\n\n- Test case $5$ (three windows with a composition change in the middle, uniform coverage):\n  - Length $L_5=90$.\n  - Sequence $S_5$: positions $1$ through $30$ are the first $30$ symbols of the infinite periodic string $\\text{\"ATATAT}\\dots\\text{\"}$; positions $31$ through $60$ are the first $30$ symbols of the infinite periodic string $\\text{\"GCGCGC}\\dots\\text{\"}$; positions $61$ through $90$ are the first $30$ symbols of the infinite periodic string $\\text{\"ATATAT}\\dots\\text{\"}$.\n  - Coverage $D^{(5)}$: $D^{(5)}_j=30$ for all $j \\in \\{1,\\dots,90\\}$.\n\nYour program must compute the chimericity score for each test case and produce a single line of output containing the results as a comma-separated list of real numbers in the exact order of the test cases, enclosed in square brackets. Each real number must be rounded to $6$ decimal places using standard rounding to nearest, ties to even are not required. The final output must therefore be of the form\n$[\\text{score}_1,\\text{score}_2,\\text{score}_3,\\text{score}_4,\\text{score}_5]$,\nwith each $\\text{score}_i$ rounded to $6$ decimal places.", "solution": "The problem statement is scientifically grounded, mathematically well-posed, and internally consistent. It provides a complete set of definitions, parameters, and test cases required to compute a deterministic chimericity score for DNA contigs. The defined metric is a plausible approach for identifying chimeric sequences in metagenome assembly by quantifying discontinuities in both sequence composition and sequencing coverage. The problem is therefore deemed valid.\n\nThe solution involves a direct implementation of the provided formulas. For each test case, we compute the chimericity score using the specified parameters: $k$-mer length $k=3$, window size $W=30$, and convex combination weight $\\alpha=\\frac{1}{2}$.\n\nThe core of the algorithm is as follows:\n$1$. The contig of length $L$ is partitioned into $M=\\lfloor L/W \\rfloor$ non-overlapping windows. If $M < 2$, the score is $0$ by definition.\n$2$. For each window $i \\in \\{1, \\dots, M\\}$, we compute a normalized $k$-mer frequency vector $p_i$ and the mean coverage $\\bar{c}_i$. The vector $p_i$ has $4^k = 4^3 = 64$ components. The number of $k$-mers in a window is $N_i = W-k+1 = 30-3+1 = 28$.\n$3$. We then compute two forms of inconsistency between adjacent windows $i$ and $i+1$, for $i \\in \\{1, \\dots, M-1\\}$:\n    a. Composition inconsistency: $d_i = \\|p_i - p_{i+1}\\|_2$.\n    b. Relative coverage inconsistency: $r_i = \\frac{|\\bar{c}_{i+1}-\\bar{c}_i|}{\\bar{c}_{i+1}+\\bar{c}_i}$, with $r_i=0$ if $\\bar{c}_i+\\bar{c}_{i+1}=0$.\n$4$. These are averaged over all $M-1$ window transitions to get $I_{\\mathrm{comp}} = \\frac{1}{M-1}\\sum_{i=1}^{M-1}\\frac{d_i}{\\sqrt{2}}$ and $I_{\\mathrm{cov}} = \\frac{1}{M-1}\\sum_{i=1}^{M-1}r_i$.\n$5$. The final score is a weighted sum: $\\mathrm{Score} = \\alpha I_{\\mathrm{comp}} + (1-\\alpha)I_{\\mathrm{cov}}$.\n\nWe now apply this procedure to each test case.\n\n**Test Case 1:**\n- Contig length $L_1=120$, window size $W=30$, so we have $M = \\lfloor 120/30 \\rfloor = 4$ windows.\n- The sequence $S_1$ is a repetition of \"ACGT\". Each window is a cyclic shift of the others. The number of occurrences for each of the $k$-mers \"ACG\", \"CGT\", \"GTA\", and \"TAC\" is $7$ within each window of $28$ total $k$-mers. All other $k$-mer counts are $0$.\n- Consequently, the normalized $k$-mer frequency vectors are identical for all windows: $p_1 = p_2 = p_3 = p_4$. Each of these vectors has $4$ non-zero components, each with value $7/28 = 1/4$.\n- The composition inconsistencies are $d_i = \\|p_i - p_{i+1}\\|_2 = 0$ for $i=1, 2, 3$. This gives $I_{\\mathrm{comp}} = 0$.\n- The coverage $D^{(1)}_j = 30$ is uniform. The mean coverage for every window is $\\bar{c}_i = 30$.\n- The relative coverage inconsistencies are $r_i = 0$ for all $i$. This gives $I_{\\mathrm{cov}} = 0$.\n- The final score is $\\mathrm{Score}_1 = \\frac{1}{2}(0) + \\frac{1}{2}(0) = 0$.\n\n**Test Case 2:**\n- Contig length $L_2=120$, $W=30$, resulting in $M=4$ windows.\n- Windows $1$ and $2$ consist of the sequence \"GCGCGC...\", while windows $3$ and $4$ consist of \"ATATAT...\".\n- For windows $1$ and $2$, the only non-zero $k$-mer frequencies are for \"GCG\" and \"CGC\", each being $14/28 = 1/2$. Thus, $p_1=p_2$.\n- For windows $3$ and $4$, the only non-zero frequencies are for \"ATA\" and \"TAT\", each being $14/28 = 1/2$. Thus, $p_3=p_4$.\n- The composition inconsistencies are:\n    - $d_1 = \\|p_1-p_2\\|_2 = 0$.\n    - $d_2 = \\|p_2-p_3\\|_2 = \\sqrt{(1/2)^2 + (1/2)^2 + (-1/2)^2 + (-1/2)^2} = \\sqrt{4 \\cdot (1/4)} = 1$. The $k$-mer sets are disjoint.\n    - $d_3 = \\|p_3-p_4\\|_2 = 0$.\n- $I_{\\mathrm{comp}} = \\frac{1}{4-1} (\\frac{d_1}{\\sqrt{2}} + \\frac{d_2}{\\sqrt{2}} + \\frac{d_3}{\\sqrt{2}}) = \\frac{1}{3} (0 + \\frac{1}{\\sqrt{2}} + 0) = \\frac{1}{3\\sqrt{2}}$.\n- Coverage: $\\bar{c}_1 = \\bar{c}_2 = 40$ and $\\bar{c}_3 = \\bar{c}_4 = 10$.\n- The relative coverage inconsistencies are:\n    - $r_1 = \\frac{|40-40|}{40+40} = 0$.\n    - $r_2 = \\frac{|10-40|}{10+40} = \\frac{30}{50} = \\frac{3}{5}$.\n    - $r_3 = \\frac{|10-10|}{10+10} = 0$.\n- $I_{\\mathrm{cov}} = \\frac{1}{3} (0 + \\frac{3}{5} + 0) = \\frac{1}{5}$.\n- The final score is $\\mathrm{Score}_2 = \\frac{1}{2} I_{\\mathrm{comp}} + \\frac{1}{2} I_{\\mathrm{cov}} = \\frac{1}{2}(\\frac{1}{3\\sqrt{2}}) + \\frac{1}{2}(\\frac{1}{5}) = \\frac{1}{6\\sqrt{2}} + \\frac{1}{10} \\approx 0.217851$.\n\n**Test Case 3:**\n- Contig length $L_3=20$, $W=30$. The number of windows is $M = \\lfloor 20/30 \\rfloor = 0$.\n- As per the problem definition, if $M < 2$, the score is $0$.\n- Thus, $\\mathrm{Score}_3 = 0$.\n\n**Test Case 4:**\n- Contig length $L_4=60$, $W=30$, giving $M = \\lfloor 60/30 \\rfloor = 2$ windows.\n- The sequence in both windows is identical (\"ACGT...\" for $30$ characters). This is identical to the windows in Test Case 1. Therefore, $p_1 = p_2$.\n- The composition inconsistency is $d_1 = \\|p_1-p_2\\|_2 = 0$, giving $I_{\\mathrm{comp}} = \\frac{1}{2-1}\\frac{0}{\\sqrt{2}}=0$.\n- The mean coverages are $\\bar{c}_1=20$ and $\\bar{c}_2=22$.\n- The relative coverage inconsistency is $r_1 = \\frac{|22-20|}{22+20} = \\frac{2}{42} = \\frac{1}{21}$.\n- $I_{\\mathrm{cov}} = \\frac{1}{2-1} r_1 = \\frac{1}{21}$.\n- The final score is $\\mathrm{Score}_4 = \\frac{1}{2}(0) + \\frac{1}{2}(\\frac{1}{21}) = \\frac{1}{42} \\approx 0.023810$.\n\n**Test Case 5:**\n- Contig length $L_5=90$, $W=30$, giving $M = 3$ windows.\n- Window $1$: \"ATATAT...\", Window $2$: \"GCGCGC...\", Window $3$: \"ATATAT...\".\n- From Test Case 2, we know that the $k$-mer profile for \"ATATAT...\" ($p_1, p_3$) is disjoint from that of \"GCGCGC...\" ($p_2$).\n- Therefore, $p_1=p_3$.\n- The composition inconsistencies are:\n    - $d_1 = \\|p_1-p_2\\|_2 = 1$.\n    - $d_2 = \\|p_2-p_3\\|_2 = \\|p_2-p_1\\|_2 = 1$.\n- $I_{\\mathrm{comp}} = \\frac{1}{3-1} (\\frac{d_1}{\\sqrt{2}} + \\frac{d_2}{\\sqrt{2}}) = \\frac{1}{2} (\\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{2}}) = \\frac{1}{\\sqrt{2}}$.\n- The coverage is uniform, $\\bar{c}_1 = \\bar{c}_2 = \\bar{c}_3 = 30$.\n- All relative coverage inconsistencies are $r_i=0$, so $I_{\\mathrm{cov}} = 0$.\n- The final score is $\\mathrm{Score}_5 = \\frac{1}{2}(\\frac{1}{\\sqrt{2}}) + \\frac{1}{2}(0) = \\frac{1}{2\\sqrt{2}} \\approx 0.353553$.", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef compute_chimericity_score(S, D, L, k, W, alpha):\n    \"\"\"\n    Computes the chimericity score for a contig based on k-mer composition and coverage.\n    \"\"\"\n    M = L // W\n    if M < 2:\n        return 0.0\n\n    kmer_positions = max(W - k + 1, 0)\n    # The denominator for k-mer frequencies, as per the problem statement\n    # p_i(w) = c_i(w) / max(N_i, 1) where N_i = W-k+1\n    kmer_freq_denominator = float(max(kmer_positions, 1))\n\n    alphabet = 'ACGT'\n    all_kmers = sorted([''.join(p) for p in itertools.product(alphabet, repeat=k)])\n    kmer_to_idx = {kmer: i for i, kmer in enumerate(all_kmers)}\n    num_total_kmers = len(all_kmers)\n\n    window_p_vectors = []\n    window_mean_coverages = []\n\n    for i in range(M):\n        start_idx = i * W\n        end_idx = start_idx + W\n        \n        window_seq = S[start_idx:end_idx]\n        \n        # Calculate k-mer frequency vector p_i\n        counts = np.zeros(num_total_kmers, dtype=float)\n        if kmer_positions > 0:\n            for j in range(kmer_positions):\n                kmer = window_seq[j:j+k]\n                # In case of non-standard characters, though the problem restricts to ACGT\n                if kmer in kmer_to_idx:\n                    counts[kmer_to_idx[kmer]] += 1\n        \n        p_vector = counts / kmer_freq_denominator\n        window_p_vectors.append(p_vector)\n        \n        # Calculate mean coverage c_i\n        window_cov_data = D[start_idx:end_idx]\n        mean_cov = np.mean(window_cov_data)\n        window_mean_coverages.append(mean_cov)\n        \n    total_comp_inconsistency = 0.0\n    total_cov_inconsistency = 0.0\n    \n    for i in range(M - 1):\n        # Composition inconsistency\n        p_i = window_p_vectors[i]\n        p_i_plus_1 = window_p_vectors[i+1]\n        d_i = np.linalg.norm(p_i - p_i_plus_1)\n        total_comp_inconsistency += d_i / np.sqrt(2.0)\n        \n        # Coverage inconsistency\n        c_i = window_mean_coverages[i]\n        c_i_plus_1 = window_mean_coverages[i+1]\n        c_sum = c_i + c_i_plus_1\n        if c_sum == 0.0:\n            r_i = 0.0\n        else:\n            r_i = np.abs(c_i_plus_1 - c_i) / c_sum\n        total_cov_inconsistency += r_i\n    \n    I_comp = total_comp_inconsistency / (M - 1)\n    I_cov = total_cov_inconsistency / (M - 1)\n    \n    score = alpha * I_comp + (1 - alpha) * I_cov\n    return score\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute scores.\n    \"\"\"\n    k = 3\n    W = 30\n    alpha = 0.5\n\n    # Test case 1\n    L1 = 120\n    S1 = ('ACGT' * (L1 // 4 + 1))[:L1]\n    D1 = np.full(L1, 30.0)\n    \n    # Test case 2\n    L2 = 120\n    S2_part1 = ('GC' * (60 // 2 + 1))[:60]\n    S2_part2 = ('AT' * (60 // 2 + 1))[:60]\n    S2 = S2_part1 + S2_part2\n    D2 = np.concatenate([np.full(60, 40.0), np.full(60, 10.0)])\n    \n    # Test case 3\n    L3 = 20\n    S3 = ('ACGT' * (L3 // 4 + 1))[:L3]\n    D3 = np.full(L3, 20.0)\n    \n    # Test case 4\n    L4 = 60\n    S4_part = ('ACGT' * (30 // 4 + 2))[:30] # +2 ensures enough length\n    S4 = S4_part + S4_part\n    D4 = np.concatenate([np.full(30, 20.0), np.full(30, 22.0)])\n    \n    # Test case 5\n    L5 = 90\n    S5_part_AT = ('AT' * (30 // 2 + 1))[:30]\n    S5_part_GC = ('GC' * (30 // 2 + 1))[:30]\n    S5 = S5_part_AT + S5_part_GC + S5_part_AT\n    D5 = np.full(L5, 30.0)\n    \n    test_cases = [\n        (S1, D1, L1, k, W, alpha),\n        (S2, D2, L2, k, W, alpha),\n        (S3, D3, L3, k, W, alpha),\n        (S4, D4, L4, k, W, alpha),\n        (S5, D5, L5, k, W, alpha),\n    ]\n\n    results = []\n    for params in test_cases:\n        score = compute_chimericity_score(*params)\n        results.append(score)\n    \n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}, {"introduction": "Once a set of reliable contigs has been assembled, the next challenge is to determine their relative order and orientation, a process known as scaffolding. This practical exercise will have you build a scaffold graph from scratch, using paired-end read data as evidence to link contigs together. By modeling contigs as nodes and paired-end links as weighted edges, you will implement the core logic that underpins modern scaffolding tools and gain direct experience in translating sequencing data into genomic structure [@problem_id:2405168].", "id": "2405168", "problem": "You are given a finite set of contigs and a finite set of paired-end (PE) read mappings at contig ends. Model the scaffold inference as a simple undirected weighted graph. Let the set of contigs be denoted by $C=\\{1,2,\\dots,n\\}$, where each element is an integer identifier. Let the set of paired-end read mappings be denoted by $P$, where each element is an ordered $6$-tuple $\\langle c_1,e_1,s_1,c_2,e_2,s_2\\rangle$ with the following components: $c_1\\in C$, $c_2\\in C$, $e_1\\in\\{\\mathrm{L},\\mathrm{R}\\}$, $e_2\\in\\{\\mathrm{L},\\mathrm{R}\\}$, $s_1\\in\\{+,-\\}$, and $s_2\\in\\{+,-\\}$. The symbol $\\mathrm{L}$ denotes the left end of a contig and $\\mathrm{R}$ denotes the right end of a contig; the symbols $+$ and $-$ denote the forward and reverse read orientations, respectively, relative to the contig reference strand. Assume a standard inward-facing fragment orientation model for paired-end sequencing (commonly termed FR): a valid linkage between distinct contigs arises from a read pair when one mate maps to a right end with forward orientation and the other maps to a left end with reverse orientation. Formally, a read pair $\\langle c_1,e_1,s_1,c_2,e_2,s_2\\rangle$ supports a linkage if and only if $c_1\\neq c_2$ and either $(e_1=\\mathrm{R}\\wedge s_1=+ \\wedge e_2=\\mathrm{L}\\wedge s_2=-)$ or $(e_1=\\mathrm{L}\\wedge s_1=- \\wedge e_2=\\mathrm{R}\\wedge s_2=+)$ holds.\n\nDefine the scaffold graph $G=(V,E)$ with $V=C$. For each unordered pair $\\{u,v\\}$ with $u,v\\in C$ and $u\\neq v$, define the edge weight $w(u,v)$ to be the count of read pairs in $P$ that support a linkage between $u$ and $v$ according to the rule above. Given a nonnegative integer threshold parameter $\\tau$, include an undirected edge between $u$ and $v$ in $E$ if and only if $w(u,v)\\ge \\tau$. The output representation for $G$ must be a list of triples, where each triple is the list $[u,v,w(u,v)]$ with $u&lt;v$, and the set of triples is sorted in ascending lexicographic order by $(u,v)$.\n\nYour task is to write a program that, for each of the following test cases, constructs the corresponding scaffold graph and outputs, for each case, the sorted list of edge triples as specified. Aggregate the results for all test cases into a single list in test-case order.\n\nTest case $1$:\n- Contigs: $C=\\{1,2,3\\}$.\n- Threshold: $\\tau=2$.\n- Paired mappings $P$ given as the following $6$-tuples:\n  $\\langle 1,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 2,\\mathrm{L},-,1,\\mathrm{R},+\\rangle$,\n  $\\langle 1,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 1,\\mathrm{L},+,2,\\mathrm{R},-\\rangle$,\n  $\\langle 1,\\mathrm{R},+,3,\\mathrm{L},-\\rangle$,\n  $\\langle 1,\\mathrm{R},+,1,\\mathrm{L},-\\rangle$.\n\nTest case $2$:\n- Contigs: $C=\\{1,2\\}$.\n- Threshold: $\\tau=1$.\n- Paired mappings $P$:\n  $\\langle 1,\\mathrm{L},+,2,\\mathrm{R},-\\rangle$,\n  $\\langle 1,\\mathrm{R},+,1,\\mathrm{L},-\\rangle$.\n\nTest case $3$:\n- Contigs: $C=\\{1,2,3,4\\}$.\n- Threshold: $\\tau=1$.\n- Paired mappings $P$:\n  $\\langle 1,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 2,\\mathrm{L},-,1,\\mathrm{R},+\\rangle$,\n  $\\langle 2,\\mathrm{R},+,3,\\mathrm{L},-\\rangle$,\n  $\\langle 4,\\mathrm{L},-,3,\\mathrm{R},+\\rangle$,\n  $\\langle 3,\\mathrm{R},+,4,\\mathrm{L},-\\rangle$,\n  $\\langle 2,\\mathrm{R},+,4,\\mathrm{L},-\\rangle$,\n  $\\langle 1,\\mathrm{L},+,3,\\mathrm{R},-\\rangle$,\n  $\\langle 3,\\mathrm{R},+,3,\\mathrm{L},-\\rangle$.\n\nTest case $4$:\n- Contigs: $C=\\{1,2,3\\}$.\n- Threshold: $\\tau=3$.\n- Paired mappings $P$:\n  $\\langle 1,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 2,\\mathrm{L},-,1,\\mathrm{R},+\\rangle$,\n  $\\langle 1,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 1,\\mathrm{L},+,2,\\mathrm{R},-\\rangle$,\n  $\\langle 3,\\mathrm{R},+,2,\\mathrm{L},-\\rangle$,\n  $\\langle 2,\\mathrm{L},-,3,\\mathrm{R},+\\rangle$.\n\nFinal output format: Your program should produce a single line of output containing a list of length $4$, where the $i$-th element is the list of edge triples $[u,v,w]$ for test case $i$, sorted by $(u,v)$. The overall line must be a single bracketed list with elements separated by commas, for example, $[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$. All identifiers in the output are integers; do not print any strings, units, or additional text.", "solution": "The problem is valid. It is scientifically grounded in the principles of bioinformatics, specifically genome assembly, and is well-posed with a clear, objective definition of the task.\n\nThe objective is to construct a scaffold graph $G=(V, E)$ based on a set of contigs $C$ and paired-end read mappings $P$. The vertices $V$ of the graph are the contigs themselves. The edges $E$ and their corresponding weights are determined by analyzing the paired-end read data according to a specified biological model.\n\nThe algorithmic procedure to construct this graph is outlined as follows:\n\n1.  **Initialization of Edge Weights**: The graph is undirected, so for every unordered pair of distinct contigs $\\{u, v\\}$ from the set $C=\\{1, 2, \\dots, n\\}$, we need to compute an associated weight $w(u,v)$. A suitable data structure for this task is an associative array (or a dictionary), which maps a canonical representation of the edge, such as an ordered tuple $(\\min(u,v), \\max(u,v))$, to its integer weight. All potential weights are implicitly initialized to $0$.\n\n2.  **Processing Paired-End Mappings**: We iterate through each paired-end read mapping $\\langle c_1,e_1,s_1,c_2,e_2,s_2\\rangle$ provided in the set $P$. For each mapping, we must determine if it constitutes a valid linkage between two different contigs.\n\n3.  **Validation of Linkage Support**: A read pair provides evidence for a scaffold linkage if it adheres to the standard inward-facing fragment orientation model, also known as the FR model. The problem formalizes this condition precisely. A read pair $\\langle c_1,e_1,s_1,c_2,e_2,s_2\\rangle$ supports a linkage between contigs $c_1$ and $c_2$ if and only if two criteria are met:\n    a. The contigs must be distinct, i.e., $c_1 \\neq c_2$. Mappings within the same contig are disregarded for scaffolding.\n    b. The mapping configuration must match one of two symmetrical patterns:\n        i.  $(e_1=\\mathrm{R} \\wedge s_1=+ \\wedge e_2=\\mathrm{L} \\wedge s_2=-)$: One mate maps to the right end of contig $c_1$ with a forward orientation, and the other mate maps to the left end of contig $c_2$ with a reverse orientation.\n        ii. $(e_1=\\mathrm{L} \\wedge s_1=- \\wedge e_2=\\mathrm{R} \\wedge s_2=+)$: The symmetric case where one mate maps to the left end of $c_1$ (reverse) and the other to the right end of $c_2$ (forward).\n    Physically, these patterns suggest that contigs $c_1$ and $c_2$ are adjacent in the source genome, with the right end of one proximal to the left end of the other.\n\n4.  **Weight Aggregation**: If a read mapping is validated as a supporting linkage between contigs $c_1$ and $c_2$, we increment the weight associated with this pair. Using the canonical representation, we update the weight $w(\\min(c_1, c_2), \\max(c_1, c_2))$. This process is repeated for all mappings in $P$, aggregating the total evidence for each potential linkage.\n\n5.  **Graph Construction via Thresholding**: After processing all mappings, we have a complete set of raw edge weights. The final set of edges $E$ for the graph $G$ is determined by a given non-negative integer threshold $\\tau$. An edge $\\{u, v\\}$ is included in $E$ if and only if its aggregated weight $w(u, v) \\ge \\tau$. This step filters out linkages with insufficient evidence, retaining only those supported by a substantial number of read pairs.\n\n6.  **Output Generation**: The final representation of the graph is required as a list of triples $[u, v, w(u,v)]$, where $u < v$. This list must be sorted in ascending lexicographical order based on the pair $(u, v)$. This is accomplished by iterating through the keys of our weight dictionary (which are already canonical and can be sorted), filtering them based on the threshold $\\tau$, and formatting the resulting edges as specified. The results from all test cases are then aggregated into a single list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Solves the scaffold graph construction problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": {1, 2, 3}, \"tau\": 2, \"P\": [\n                (1, 'R', '+', 2, 'L', '-'),\n                (2, 'L', '-', 1, 'R', '+'),\n                (1, 'R', '+', 2, 'L', '-'),\n                (1, 'L', '+', 2, 'R', '-'),\n                (1, 'R', '+', 3, 'L', '-'),\n                (1, 'R', '+', 1, 'L', '-')\n            ]\n        },\n        {\n            \"C\": {1, 2}, \"tau\": 1, \"P\": [\n                (1, 'L', '+', 2, 'R', '-'),\n                (1, 'R', '+', 1, 'L', '-')\n            ]\n        },\n        {\n            \"C\": {1, 2, 3, 4}, \"tau\": 1, \"P\": [\n                (1, 'R', '+', 2, 'L', '-'),\n                (2, 'L', '-', 1, 'R', '+'),\n                (2, 'R', '+', 3, 'L', '-'),\n                (4, 'L', '-', 3, 'R', '+'),\n                (3, 'R', '+', 4, 'L', '-'),\n                (2, 'R', '+', 4, 'L', '-'),\n                (1, 'L', '+', 3, 'R', '-'),\n                (3, 'R', '+', 3, 'L', '-')\n            ]\n        },\n        {\n            \"C\": {1, 2, 3}, \"tau\": 3, \"P\": [\n                (1, 'R', '+', 2, 'L', '-'),\n                (2, 'L', '-', 1, 'R', '+'),\n                (1, 'R', '+', 2, 'L', '-'),\n                (1, 'L', '+', 2, 'R', '-'),\n                (3, 'R', '+', 2, 'L', '-'),\n                (2, 'L', '-', 3, 'R', '+')\n            ]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        tau = case[\"tau\"]\n        mappings = case[\"P\"]\n        weights = collections.defaultdict(int)\n\n        for mapping in mappings:\n            c1, e1, s1, c2, e2, s2 = mapping\n            \n            # A read pair supports a linkage if and only if c1 != c2 and \n            # either (e1=R ^ s1=+ ^ e2=L ^ s2=-) or (e1=L ^ s1=- ^ e2=R ^ s2=+).\n            if c1 == c2:\n                continue\n\n            valid_link = False\n            if (e1 == 'R' and s1 == '+' and e2 == 'L' and s2 == '-') or \\\n               (e1 == 'L' and s1 == '-' and e2 == 'R' and s2 == '+'):\n                valid_link = True\n            \n            # The problem logic is symmetrical, check the other direction.\n            elif (e2 == 'R' and s2 == '+' and e1 == 'L' and s1 == '-') or \\\n                 (e2 == 'L' and s2 == '-' and e1 == 'R' and s1 == '+'):\n                 valid_link = True\n\n            if valid_link:\n                u, v = min(c1, c2), max(c1, c2)\n                weights[(u, v)] += 1\n\n        # Filter edges by threshold and sort\n        edge_list = []\n        # Sort keys for lexicographical order\n        sorted_keys = sorted(weights.keys())\n        \n        for u, v in sorted_keys:\n            w = weights[(u, v)]\n            if w >= tau:\n                edge_list.append([u, v, w])\n        \n        all_results.append(edge_list)\n\n    # Format the final output string to be completely space-free within lists.\n    outer_parts = []\n    for case_result in all_results:\n        inner_parts = []\n        for triple in case_result:\n            inner_parts.append(f\"[{triple[0]},{triple[1]},{triple[2]}]\")\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_output_string = f\"[{','.join(outer_parts)}]\"\n    print(final_output_string)\n\nsolve()\n```"}]}