{"hands_on_practices": [{"introduction": "Mastering machine learning begins not with writing code, but with correctly identifying the nature of the problem at hand. This foundational exercise ([@problem_id:2432842]) challenges you to apply the formal definitions of supervised, unsupervised, and semi-supervised learning to classify a variety of common bioinformatics scenarios. By working through these abstracted but realistic cases, you will sharpen your ability to distinguish between tasks that learn from labeled data to make predictions and those that seek to uncover hidden structure in unlabeled data.", "problem": "You are given the fundamental definitions below, framed in mathematical terms. Let a dataset be denoted by either $D=\\{(x_i,y_i)\\}_{i=1}^{n}$ when outputs $y_i$ are available or $D=\\{x_i\\}_{i=1}^{n}$ when outputs are absent. A task is called supervised if the goal is to estimate a function $f:\\mathcal{X}\\to\\mathcal{Y}$ using pairs $(x_i,y_i)$ and the learning procedure uses the outputs $y_i$ during training to enable prediction for new inputs. A task is called unsupervised if only inputs $\\{x_i\\}$ are used to infer latent structure, density, or representations without using external outputs $y_i$. A task is called semi-supervised if both labeled and unlabeled data are used together in training to improve prediction of outputs. For decision-making purposes, each test case is encoded by a tuple $(L,U,P)$ where $L\\in\\{0,1,2\\}$ indicates the labeling condition with $L=0$ meaning no outputs are provided, $L=1$ meaning outputs are provided for all training samples, and $L=2$ meaning outputs are provided for a strict subset only; $U\\in\\{0,1\\}$ indicates whether the learning procedure uses outputs in its training objective; and $P\\in\\{0,1\\}$ indicates whether the primary goal is to predict outputs for new inputs ($P=1$) versus to discover latent structure or density ($P=0$). Your program must, for each test case, output an integer code $c$ defined as $c=1$ if the task is supervised, $c=0$ if the task is unsupervised, and $c=2$ if the task is semi-supervised.\n\nTest suite (each item describes a computational biology or bioinformatics scenario and its tuple $(L,U,P)$):\n\n- Test case A: Reconstruct a phylogenetic tree from a symmetric matrix of protein sequence similarities across $m$ taxa, without any externally supplied class labels; the procedure seeks a tree structure consistent with the similarities. Tuple $(L,U,P)=(0,0,0)$.\n- Test case B: Predict tumor type from gene expression profiles using a training set in which each sample has a known tumor type label, and the training process uses those labels to build a predictor for new samples. Tuple $(L,U,P)=(1,1,1)$.\n- Test case C: Group single-cell ribonucleic acid sequencing (RNA-seq) transcriptomes into cell states without any labels, aiming to discover clusters. Tuple $(L,U,P)=(0,0,0)$.\n- Test case D: Predict real-valued protein–ligand binding affinity from protein sequence descriptors, with measured affinities provided for all training samples and used in training to generalize to unseen sequences. Tuple $(L,U,P)=(1,1,1)$.\n- Test case E: Infer protein functional annotations on a protein–protein interaction network using a small subset of labeled proteins together with many unlabeled proteins, with the labels used during training to improve predictions for unlabeled nodes. Tuple $(L,U,P)=(2,1,1)$.\n- Test case F: Reduce the dimensionality of metabolomic profiles to visualize variation, with class labels available but intentionally not used by the procedure; the aim is representation learning rather than output prediction. Tuple $(L,U,P)=(1,0,0)$.\n\nYour program must apply the definitions above to determine, for each test case, whether it is supervised ($c=1$), unsupervised ($c=0$), or semi-supervised ($c=2$). The final output format must be a single line containing a comma-separated list of the integer codes for test cases A through F, in order, enclosed in square brackets, for example $[c_A,c_B,c_C,c_D,c_E,c_F]$. No physical units, angle units, or percentages are involved in this problem. The only acceptable outputs are integers $0$, $1$, or $2$, as defined.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens.\nThe givens are:\n- A dataset is denoted by $D=\\{(x_i,y_i)\\}_{i=1}^{n}$ with outputs or $D=\\{x_i\\}_{i=1}^{n}$ without outputs.\n- A task is supervised if the goal is to estimate $f:\\mathcal{X}\\to\\mathcal{Y}$ using pairs $(x_i,y_i)$ and the learning procedure uses outputs $y_i$ during training.\n- A task is unsupervised if only inputs $\\{x_i\\}$ are used to infer latent structure, density, or representations without using external outputs $y_i$.\n- A task is semi-supervised if both labeled and unlabeled data are used together in training to improve prediction of outputs.\n- A task is encoded by a tuple $(L,U,P)$, where:\n    - $L \\in \\{0, 1, 2\\}$: Labeling condition. $L=0$ means no outputs provided. $L=1$ means outputs provided for all samples. $L=2$ means outputs provided for a strict subset only.\n    - $U \\in \\{0, 1\\}$: Use of outputs. $U=0$ means outputs are not used in the training objective. $U=1$ means outputs are used.\n    - $P \\in \\{0, 1\\}$: Primary goal. $P=0$ means the goal is to discover latent structure or density. $P=1$ means the goal is to predict outputs for new inputs.\n- The output is an integer code $c$, where $c=1$ for supervised, $c=0$ for unsupervised, and $c=2$ for semi-supervised.\n- Test Cases:\n    - A: $(L,U,P)=(0,0,0)$\n    - B: $(L,U,P)=(1,1,1)$\n    - C: $(L,U,P)=(0,0,0)$\n    - D: $(L,U,P)=(1,1,1)$\n    - E: $(L,U,P)=(2,1,1)$\n    - F: $(L,U,P)=(1,0,0)$\n\nStep 2: Validate Using Extracted Givens.\nThe problem is assessed for validity.\n- **Scientifically Grounded**: The definitions of supervised, unsupervised, and semi-supervised learning are standard and foundational in machine learning. The application scenarios described (phylogenetics, RNA-seq analysis, etc.) are standard problems in computational biology and bioinformatics. The problem is based on established scientific principles.\n- **Well-Posed**: The problem provides a clear, rule-based mapping from a task's abstract properties, encoded as a tuple $(L,U,P)$, to a classification code $c$. The definitions and encodings are precise, ensuring a unique and meaningful solution exists for each test case.\n- **Objective**: The problem is stated in formal, mathematical language, free of subjective or ambiguous terminology.\n- **Complete and Consistent**: All necessary information to perform the classification is provided. The definitions of the learning paradigms and the feature tuple $(L,U,P)$ are self-contained and consistent. No contradictions are present.\n\nStep 3: Verdict and Action.\nThe problem is valid. A reasoned solution will be provided.\n\nThe task is to classify each scenario as supervised ($c=1$), unsupervised ($c=0$), or semi-supervised ($c=2$) based on the provided tuple $(L,U,P)$. The classification logic is derived directly from the fundamental definitions of these learning paradigms.\n\nA logical framework for mapping the tuple $(L,U,P)$ to the classification code $c$ is as follows:\n\n1.  **Unsupervised Learning ($c=0$)**: The core definition is that the learning process uses *only* inputs to infer structure, without using outputs. This is captured by two conditions in the tuple: the procedure does not use outputs in its objective ($U=0$), and the primary goal is structure or representation discovery, not prediction of outputs ($P=0$). The availability of labels is immaterial if they are not used. Therefore, any task where ($U=0$ and $P=0$) is unsupervised.\n    $$ (U=0 \\land P=0) \\implies c=0 $$\n\n2.  **Supervised Learning ($c=1$)**: This paradigm requires learning a predictive function from a fully labeled dataset. This implies three conditions: outputs are provided for all training samples ($L=1$), these outputs are used by the learning algorithm ($U=1$), and the goal is to predict outputs for new data ($P=1$).\n    $$ (L=1 \\land U=1 \\land P=1) \\implies c=1 $$\n\n3.  **Semi-Supervised Learning ($c=2$)**: This is a hybrid approach that uses both labeled and unlabeled data to improve a predictive model. The tuple must reflect this: outputs are provided for only a strict subset of the data ($L=2$), these available labels are used in training ($U=1$), and the overall goal is prediction ($P=1$).\n    $$ (L=2 \\land U=1 \\land P=1) \\implies c=2 $$\n\nThese three rules are mutually exclusive and cover all scenarios presented in the test suite. We now apply this formal logic to each test case.\n\n- **Test Case A**: $(L,U,P)=(0,0,0)$.\n  The conditions are $U=0$ and $P=0$. According to our first rule, this task is unsupervised. This aligns with the description of reconstructing a phylogenetic tree (a structure) from similarities without any class labels.\n  The code is $c_A = 0$.\n\n- **Test Case B**: $(L,U,P)=(1,1,1)$.\n  The conditions are $L=1$, $U=1$, and $P=1$. According to our second rule, this task is supervised. This aligns with the description of using a fully labeled dataset of gene expression profiles to train a predictor for tumor types.\n  The code is $c_B = 1$.\n\n- **Test Case C**: $(L,U,P)=(0,0,0)$.\n  The conditions are $U=0$ and $P=0$. Similar to case A, this task is unsupervised. The goal is to discover clusters (a form of latent structure) in RNA-seq data without any predefined labels.\n  The code is $c_C = 0$.\n\n- **Test Case D**: $(L,U,P)=(1,1,1)$.\n  The conditions are $L=1$, $U=1$, and $P=1$. Similar to case B, this task is supervised. It involves predicting a real-valued output (binding affinity) using a training set where this output is known for every sample.\n  The code is $c_D = 1$.\n\n- **Test Case E**: $(L,U,P)=(2,1,1)$.\n  The conditions are $L=2$, $U=1$, and $P=1$. According to our third rule, this task is semi-supervised. The description confirms this: a small set of labeled proteins is used along with a large set of unlabeled ones to improve the predictive model for functional annotations.\n  The code is $c_E = 2$.\n\n- **Test Case F**: $(L,U,P)=(1,0,0)$.\n  The conditions are $U=0$ and $P=0$. Even though labels are available ($L=1$), they are explicitly not used ($U=0$), and the goal is representation learning ($P=0$), not prediction. Therefore, according to our first rule, the task is unsupervised. This case correctly illustrates that the *use* of labels, not their mere *availability*, is the defining characteristic.\n  The code is $c_F = 0$.\n\nThe final sequence of classification codes for test cases A through F is $[0, 1, 0, 1, 2, 0]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Determines the learning paradigm for computational biology tasks.\n\n    The classification is based on a tuple (L, U, P) where:\n    - L: Labeling condition (0: none, 1: all, 2: partial)\n    - U: Use of labels in training (0: no, 1: yes)\n    - P: Primary goal (0: structure, 1: prediction)\n\n    The output codes are:\n    - 0: Unsupervised\n    - 1: Supervised\n    - 2: Semi-supervised\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is in the format (L, U, P).\n    test_cases = [\n        (0, 0, 0),  # Case A: Phylogenetic tree reconstruction\n        (1, 1, 1),  # Case B: Tumor type prediction from expression\n        (0, 0, 0),  # Case C: scRNA-seq clustering\n        (1, 1, 1),  # Case D: Protein-ligand affinity prediction\n        (2, 1, 1),  # Case E: Protein annotation with partial labels\n        (1, 0, 0),  # Case F: Dimensionality reduction without using labels\n    ]\n\n    results = []\n    for case in test_cases:\n        L, U, P = case\n        \n        # Logic derived from the fundamental definitions of learning paradigms.\n        \n        # Rule for Semi-supervised learning:\n        # Uses a mix of labeled (L=2) and unlabeled data to improve prediction (P=1),\n        # with labels being used in training (U=1).\n        if L == 2 and U == 1 and P == 1:\n            result = 2  # Semi-supervised\n        \n        # Rule for Supervised learning:\n        # Learns from a fully labeled dataset (L=1) to make predictions (P=1),\n        # using the labels in training (U=1).\n        elif L == 1 and U == 1 and P == 1:\n            result = 1  # Supervised\n            \n        # Rule for Unsupervised learning:\n        # Infers latent structure or representation (P=0) using only inputs,\n        # without using outputs in the training objective (U=0).\n        # The availability of labels (L) is irrelevant if they are not used.\n        elif U == 0 and P == 0:\n            result = 0  # Unsupervised\n            \n        else:\n            # This case should not be reached given the problem's well-posed nature.\n            # It indicates a combination of (L, U, P) that does not fit the\n            # canonical definitions provided.\n            raise ValueError(f\"Invalid or unclassifiable case: (L={L}, U={U}, P={P})\")\n            \n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2432842"}, {"introduction": "With the foundational concepts established, we can now explore the practical differences between supervised and unsupervised paradigms on a concrete task. This practice ([@problem_id:2432827]) puts you in the role of a bioinformatician tasked with distinguishing protein-coding from non-coding DNA sequences, a classic problem in genomics. You will build and evaluate both a supervised Support Vector Machine (SVM) that learns from labeled examples and an unsupervised clustering algorithm that groups sequences by intrinsic similarity alone, offering a direct comparison of their approaches and effectiveness.", "problem": "You are given a finite alphabet $\\mathcal{A} = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ and a definition of a feature map from a deoxyribonucleic acid (DNA) sequence $s$ of length $L$ to a vector of normalized $k$-mer frequencies $\\phi_k(s) \\in \\mathbb{R}^{4^k}$. For a given positive integer $k$, let $\\mathcal{M}_k$ be the set of all strings of length $k$ over $\\mathcal{A}$, enumerated in lexicographic order. For each $m \\in \\mathcal{M}_k$, the component $\\left[\\phi_k(s)\\right]_m$ is defined as the count of occurrences of $m$ in $s$ using a sliding window of stride $1$, divided by the total number of $k$-mers in $s$, which is $L - k + 1$ (assume $L \\ge k$ and that no ambiguous characters appear). Formally,\n$$\n\\left[\\phi_k(s)\\right]_m = \\frac{1}{L - k + 1} \\sum_{i=1}^{L-k+1} \\mathbf{1}\\left\\{ s_i s_{i+1} \\cdots s_{i+k-1} = m \\right\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function and indices are $1$-based.\n\nA binary label $y \\in \\{-1, +1\\}$ indicates whether a DNA sequence is protein-coding ($+1$) or non-coding ($-1$). Consider a supervised linear classifier defined by a weight vector $w \\in \\mathbb{R}^{4^k}$ and bias $b \\in \\mathbb{R}$ acting on features $\\phi_k(s)$ via the score $f(s) = w^\\top \\phi_k(s) + b$ and the prediction rule $\\hat{y}(s) = \\mathrm{sign}(f(s))$, where $\\mathrm{sign}(z) = +1$ if $z \\ge 0$ and $-1$ otherwise. The model parameters $(w,b)$ are obtained by minimizing the regularized empirical risk with squared hinge loss:\n$$\nJ(w,b) = \\frac{1}{2} \\lVert w \\rVert_2^2 + C \\sum_{i=1}^{N} \\left( \\max\\left(0, 1 - y_i (w^\\top x_i + b) \\right) \\right)^2,\n$$\nwhere $C > 0$ is a given regularization parameter, $\\{(x_i, y_i)\\}_{i=1}^N$ are training examples with $x_i = \\phi_k(s_i)$ and $y_i \\in \\{-1, +1\\}$, and $\\lVert \\cdot \\rVert_2$ denotes the Euclidean norm.\n\nFor an unsupervised baseline, consider partitioning a given set of feature vectors $\\{x_j\\}_{j=1}^M$ (with $x_j = \\phi_k(s_j)$ for $M$ sequences) into exactly two non-empty clusters $\\mathcal{C}_0$ and $\\mathcal{C}_1$ so as to minimize the within-cluster sum of squares:\n$$\nW(\\mathcal{C}_0, \\mathcal{C}_1) = \\sum_{j \\in \\mathcal{C}_0} \\lVert x_j - \\mu_0 \\rVert_2^2 + \\sum_{j \\in \\mathcal{C}_1} \\lVert x_j - \\mu_1 \\rVert_2^2,\n$$\nwhere $\\mu_0$ and $\\mu_1$ are the means of their respective clusters. After obtaining the minimizing partition, define a cluster-based prediction $\\tilde{y}_j \\in \\{-1, +1\\}$ for each item by mapping the two clusters to $\\{-1, +1\\}$ in the way that maximizes the fraction of matches with ground-truth labels on the same items; report that maximal fraction as the unsupervised accuracy expressed as a decimal.\n\nYou are provided with a labeled training set $\\mathcal{D}_{\\mathrm{train}}$ and a labeled test set $\\mathcal{D}_{\\mathrm{test}}$ of DNA sequences. All sequences consist only of symbols from $\\mathcal{A}$.\n\nTraining sequences (with labels $y$ shown in parentheses, where $+1$ denotes coding and $-1$ denotes non-coding):\n- $s_1 = \\texttt{ATGGCGGCCGCGGGCGCCGCGGGCGACGGCTGA}$ $(+1)$\n- $s_2 = \\texttt{ATGCGCGCGCGGGCCGCGGCTGCGGCGTAG}$ $(+1)$\n- $s_3 = \\texttt{ATGGGCGACGGCGGCGACGGCGGCGACTAA}$ $(+1)$\n- $s_4 = \\texttt{ATGGCCGCTGCGGCTGGCGCTGCGGCTTGA}$ $(+1)$\n- $s_5 = \\texttt{ATGGCGGCGGCGGCGGCGGCGGCGGCGGCGTAA}$ $(+1)$\n- $s_6 = \\texttt{ATGGGCGCCGCGGGCGCCGCGGGCGCCTGA}$ $(+1)$\n- $s_7 = \\texttt{TATATAAATAATATATATTTATATAATAATA}$ $(-1)$\n- $s_8 = \\texttt{AAATATATATTTAAATATATATATATAAAA}$ $(-1)$\n- $s_9 = \\texttt{TTTATATATAAATATAATATATTTATAAAT}$ $(-1)$\n- $s_{10} = \\texttt{AATAATAATATATTTATAAATAATATATAT}$ $(-1)$\n- $s_{11} = \\texttt{ATATATAAATATATAATATATAAATATATA}$ $(-1)$\n- $s_{12} = \\texttt{TATATATAAATAAATATATATATAAATATA}$ $(-1)$\n\nTest sequences (with labels):\n- $t_1 = \\texttt{ATGGCGGGCGGGCGACGGCTAA}$ $(+1)$\n- $t_2 = \\texttt{ATGGCCGCGGCTGGCGCTGCGTAG}$ $(+1)$\n- $t_3 = \\texttt{ATGGCGGCGGCGGCGGCGTGA}$ $(+1)$\n- $t_4 = \\texttt{AATATATATATAAATATATATAAATAATA}$ $(-1)$\n- $t_5 = \\texttt{TATATTTATAAATATATATAAATATTTAT}$ $(-1)$\n- $t_6 = \\texttt{AAATAATATATATATAAATAATATATATA}$ $(-1)$\n\nYour tasks are as follows.\n\n1. Supervised classification. For each specified pair $(k, C)$, compute the feature vectors $\\phi_k(s)$ for all $s \\in \\mathcal{D}_{\\mathrm{train}}$, learn $(w,b)$ by minimizing $J(w,b)$, and then compute the test accuracy (as a decimal) on $\\mathcal{D}_{\\mathrm{test}}$ using $\\hat{y}(s) = \\mathrm{sign}(w^\\top \\phi_k(s) + b)$.\n2. Unsupervised clustering baseline. For each specified $k$, compute $\\phi_k(s)$ for all $s \\in \\mathcal{D}_{\\mathrm{test}}$ and find a partition into exactly two non-empty clusters that minimizes $W(\\mathcal{C}_0,\\mathcal{C}_1)$. Map clusters to labels $\\{-1,+1\\}$ to maximize agreement with the true labels on $\\mathcal{D}_{\\mathrm{test}}$, and report that maximal agreement as the accuracy (as a decimal).\n\nTest suite. Run the following five cases in this exact order:\n- Case $1$: supervised with $k = 3$, $C = 1$.\n- Case $2$: supervised with $k = 2$, $C = 1$.\n- Case $3$: supervised with $k = 3$, $C = 0.01$.\n- Case $4$: unsupervised with $k = 3$ on the test set only.\n- Case $5$: unsupervised with $k = 2$ on the test set only.\n\nAnswer specification and output format.\n- For each case, the answer is a single real number equal to the accuracy on $\\mathcal{D}_{\\mathrm{test}}$ expressed as a decimal, rounded to exactly three digits after the decimal point.\n- Your program should produce a single line of output containing the five results as a comma-separated list enclosed in square brackets, in the order of the cases above. For example, an output with five placeholder values should look like $[\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4,\\alpha_5]$ where each $\\alpha_i$ is a real number rounded to three digits after the decimal point.", "solution": "The problem presented requires the implementation and evaluation of two distinct machine learning paradigms—supervised classification and unsupervised clustering—for the task of discriminating between protein-coding and non-coding deoxyribonucleic acid (DNA) sequences. The problem is scientifically grounded, well-posed, and formally specified. It provides all necessary data and definitions for a complete computational solution. Thus, it is a valid problem. The solution proceeds by first constructing the feature representation, then implementing the specified algorithms for both paradigms.\n\nThe fundamental step for both approaches is the transformation of symbolic DNA sequences into a quantitative, numerical format suitable for algorithmic processing. This is achieved through a feature map $\\phi_k(s)$, which projects a sequence $s$ of length $L$ into a real-valued vector in $\\mathbb{R}^{4^k}$. Each dimension of this vector corresponds to one of the $4^k$ possible strings of length $k$ (termed $k$-mers) over the alphabet $\\mathcal{A} = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$. The value of each component is the normalized frequency of the corresponding $k$-mer in the sequence. Specifically, for a $k$-mer $m$, its frequency is its count within a sliding window of size $k$ and stride $1$, divided by the total number of windows, which is $L-k+1$. This establishes a vector space model where each sequence is a point, and the geometric relationships between these points can be exploited by learning algorithms. The set of all $k$-mers, $\\mathcal{M}_k$, is ordered lexicographically, which defines a consistent mapping from a $k$-mer to an index in the feature vector. This can be achieved by treating the characters A, C, G, T as digits in a base-$4$ number system (e.g., $A=0, C=1, G=2, T=3$).\n\nFirst, we address the supervised classification task. We are given a training dataset $\\mathcal{D}_{\\mathrm{train}}$ of $N$ sequences with known labels $y_i \\in \\{-1, +1\\}$. The goal is to learn a linear decision function $f(s) = w^\\top \\phi_k(s) + b$ that can predict the label of a new sequence. The parameters, a weight vector $w \\in \\mathbb{R}^{4^k}$ and a scalar bias $b \\in \\mathbb{R}$, are determined by minimizing a regularized empirical risk function. The specified objective function is:\n$$\nJ(w,b) = \\frac{1}{2} \\lVert w \\rVert_2^2 + C \\sum_{i=1}^{N} \\left( \\max\\left(0, 1 - y_i (w^\\top x_i + b) \\right) \\right)^2\n$$\nHere, $x_i = \\phi_k(s_i)$ is the feature vector for the $i$-th training sequence. The first term, $\\frac{1}{2} \\lVert w \\rVert_2^2$, is an $\\ell_2$-regularizer that penalizes large weights to prevent overfitting. The second term is the sum of squared hinge losses over the training set, which penalizes misclassifications and correct classifications with insufficient margin. The parameter $C > 0$ controls the trade-off between regularization and fitting the training data. This objective function $J(w,b)$ is convex and differentiable everywhere, ensuring that a unique global minimum exists. We can find this minimum using a gradient-based optimization algorithm, such as L-BFGS-B (Limited-memory Broyden–Fletcher–Goldfarb–Shanno with Bounds). To do this, we compute the partial derivatives of $J(w,b)$ with respect to $w$ and $b$. Let $\\mathcal{S}$ be the set of indices for which $y_i(w^\\top x_i + b) < 1$. The gradients are:\n$$\n\\nabla_w J = w - 2C \\sum_{i \\in \\mathcal{S}} y_i (1 - y_i(w^\\top x_i + b)) x_i\n$$\n$$\n\\nabla_b J = -2C \\sum_{i \\in \\mathcal{S}} y_i (1 - y_i(w^\\top x_i + b))\n$$\nStarting with an initial guess (e.g., $w=0, b=0$), the optimizer iteratively updates the parameters to find the optimal $(w^*, b^*)$. Once trained, the model's performance is evaluated on the test set $\\mathcal{D}_{\\mathrm{test}}$ by calculating its accuracy: the fraction of test sequences for which the predicted label $\\hat{y}(s) = \\mathrm{sign}(w^{*\\top} \\phi_k(s) + b^*)$ matches the true label.\n\nSecond, we address the unsupervised clustering baseline. This approach does not use labels during the learning phase. The task is to partition the feature vectors $\\{x_j\\}_{j=1}^M$ derived from the test set $\\mathcal{D}_{\\mathrm{test}}$ into exactly two non-empty clusters, $\\mathcal{C}_0$ and $\\mathcal{C}_1$. The partitioning must minimize the within-cluster sum of squares (WCSS), a standard objective for k-means clustering:\n$$\nW(\\mathcal{C}_0, \\mathcal{C}_1) = \\sum_{j \\in \\mathcal{C}_0} \\lVert x_j - \\mu_0 \\rVert_2^2 + \\sum_{j \\in \\mathcal{C}_1} \\lVert x_j - \\mu_1 \\rVert_2^2\n$$\nwhere $\\mu_0$ and $\\mu_1$ are the centroids (means) of the clusters. While finding the optimal partition for general $k$-means is NP-hard, the number of data points in the test set is small ($M=6$). This allows for an exact solution by enumerating all possible non-trivial partitions. The number of ways to partition a set of $M$ items into two non-empty subsets is given by the Stirling number of the second kind $S(M, 2) = 2^{M-1} - 1$. For $M=6$, this is $2^5 - 1 = 31$ unique partitions. We can iterate through each of these partitions, calculate the corresponding WCSS, and identify the partition that yields the global minimum. After finding the optimal clusters $\\mathcal{C}_0^*$ and $\\mathcal{C}_1^*$, we evaluate their quality by comparing them against the true labels. Since the cluster identities ($0$ and $1$) are arbitrary, we must test both possible mappings to the true labels $\\{-1, +1\\}$: ($\\mathcal{C}_0^* \\to -1, \\mathcal{C}_1^* \\to +1$) and ($\\mathcal{C}_0^* \\to +1, \\mathcal{C}_1^* \\to -1$). The unsupervised accuracy is defined as the maximum accuracy achieved between these two mappings.\n\nThe final procedure involves executing these two algorithmic frameworks for the specified parameters ($k, C$) and reporting the resulting test accuracies, rounded to three decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the complete problem, including both supervised and unsupervised tasks.\n    \"\"\"\n    # Define the problem data\n    train_seqs = [\n        \"ATGGCGGCCGCGGGCGCCGCGGGCGACGGCTGA\", \"ATGCGCGCGCGGGCCGCGGCTGCGGCGTAG\",\n        \"ATGGGCGACGGCGGCGACGGCGGCGACTAA\", \"ATGGCCGCTGCGGCTGGCGCTGCGGCTTGA\",\n        \"ATGGCGGCGGCGGCGGCGGCGGCGGCGGCGTAA\", \"ATGGGCGCCGCGGGCGCCGCGGGCGCCTGA\",\n        \"TATATAAATAATATATATTTATATAATAATA\", \"AAATATATATTTAAATATATATATATAAAA\",\n        \"TTTATATATAAATATAATATATTTATAAAT\", \"AATAATAATATATTTATAAATAATATATAT\",\n        \"ATATATAAATATATAATATATAAATATATA\", \"TATATATAAATAAATATATATATAAATATA\"\n    ]\n    train_labels = np.array([1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1])\n\n    test_seqs = [\n        \"ATGGCGGGCGGGCGACGGCTAA\", \"ATGGCCGCGGCTGGCGCTGCGTAG\",\n        \"ATGGCGGCGGCGGCGGCGTGA\", \"AATATATATATAAATATATATAAATAATA\",\n        \"TATATTTATAAATATATATAAATATTTAT\", \"AAATAATATATATATAAATAATATATATA\"\n    ]\n    test_labels = np.array([1, 1, 1, -1, -1, -1])\n\n    alphabet_map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n\n    def get_kmer_index(kmer):\n        \"\"\"Calculates the lexicographical index of a k-mer.\"\"\"\n        index = 0\n        for char in kmer:\n            index = index * 4 + alphabet_map[char]\n        return index\n\n    def phi_k(s, k):\n        \"\"\"Computes the k-mer frequency vector phi_k(s).\"\"\"\n        L = len(s)\n        dim = 4**k\n        if L < k:\n            return np.zeros(dim)\n        \n        counts = np.zeros(dim)\n        num_kmers = L - k + 1\n        \n        for i in range(num_kmers):\n            kmer = s[i:i+k]\n            idx = get_kmer_index(kmer)\n            counts[idx] += 1\n            \n        return counts / num_kmers\n\n    def objective_function(theta, X, y, C):\n        \"\"\"Computes J(w, b) and its gradient for L2-SVM.\"\"\"\n        N, D = X.shape\n        w = theta[:-1]\n        b = theta[-1]\n        \n        margins = y * (X.dot(w) + b)\n        loss_terms = 1 - margins\n        violations_mask = loss_terms > 0\n        \n        squared_hinge_loss = np.sum(loss_terms[violations_mask]**2)\n        objective_value = 0.5 * np.dot(w, w) + C * squared_hinge_loss\n        \n        grad = np.zeros_like(theta)\n        grad[:-1] = w\n        \n        if np.any(violations_mask):\n            common_grad_factor = -2 * C * loss_terms[violations_mask] * y[violations_mask]\n            grad[:-1] += np.dot(common_grad_factor, X[violations_mask, :])\n            grad[-1] += np.sum(common_grad_factor)\n        \n        return objective_value, grad\n\n    def solve_supervised(k, C):\n        \"\"\"Trains the SVM and computes test accuracy.\"\"\"\n        D = 4**k\n        X_train = np.array([phi_k(s, k) for s in train_seqs])\n        \n        initial_theta = np.zeros(D + 1)\n        res = minimize(\n            objective_function,\n            initial_theta,\n            args=(X_train, train_labels, C),\n            jac=True,\n            method='L-BFGS-B'\n        )\n        \n        w_opt, b_opt = res.x[:-1], res.x[-1]\n        \n        X_test = np.array([phi_k(s, k) for s in test_seqs])\n        \n        scores = X_test.dot(w_opt) + b_opt\n        predictions = np.sign(scores)\n        predictions[predictions == 0] = 1 # Per problem: sign(z>=0) = +1\n        \n        accuracy = np.mean(predictions == test_labels)\n        return accuracy\n\n    def solve_unsupervised(k):\n        \"\"\"Performs clustering and computes best-match accuracy.\"\"\"\n        M = len(test_seqs)\n        X_test = np.array([phi_k(s, k) for s in test_seqs])\n        \n        min_wcss = np.inf\n        best_partition = None\n        \n        # Enumerate all non-trivial partitions of M items into 2 clusters.\n        # Fix the first item in cluster 0 and iterate through assignments for the rest.\n        # This gives 2^(M-1) possibilities. The case where all items are in cluster 0\n        # (i=0) is excluded to ensure non-empty clusters.\n        num_items_to_partition = M - 1\n        for i in range(1, 2**num_items_to_partition):\n            c0_indices = [0]\n            c1_indices = []\n            \n            for j in range(num_items_to_partition):\n                if (i >> j) & 1:\n                    c1_indices.append(j + 1)\n                else:\n                    c0_indices.append(j + 1)\n\n            C0 = X_test[c0_indices, :]\n            C1 = X_test[c1_indices, :]\n            \n            wcss = np.sum((C0 - np.mean(C0, axis=0))**2) + \\\n                   np.sum((C1 - np.mean(C1, axis=0))**2)\n\n            if wcss < min_wcss:\n                min_wcss = wcss\n                best_partition = (c0_indices, c1_indices)\n\n        c0_indices, c1_indices = best_partition\n        \n        # Mapping 1: C0 -> -1, C1 -> +1\n        pred1 = np.ones(M)\n        pred1[c0_indices] = -1\n        acc1 = np.mean(pred1 == test_labels)\n        \n        # Mapping 2: C0 -> +1, C1 -> -1\n        pred2 = np.ones(M)\n        pred2[c1_indices] = -1\n        acc2 = np.mean(pred2 == test_labels)\n        \n        return max(acc1, acc2)\n\n    # Execute all five test cases\n    results = [\n        solve_supervised(k=3, C=1.0),\n        solve_supervised(k=2, C=1.0),\n        solve_supervised(k=3, C=0.01),\n        solve_unsupervised(k=3),\n        solve_unsupervised(k=2)\n    ]\n    \n    # Format and print the final output\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2432827"}, {"introduction": "The distinction between supervised and unsupervised learning is not always a strict dichotomy; often, they are most powerful when combined. This advanced practice ([@problem_id:2432878]) guides you through building a two-stage pipeline that reflects a modern approach to complex biological data analysis. You will first use an unsupervised method to learn a compressed, meaningful representation of high-dimensional gene expression data, and then feed this learned representation into a supervised model to predict a clinical outcome, demonstrating how unsupervised learning can serve as a critical feature engineering step.", "problem": "You are to write a complete, runnable program that performs a two-stage learning pipeline on simulated gene expression data for multiple test cases, combining an unsupervised representation learning stage with a supervised prediction stage. The objectives and the data-generating process are specified mathematically below, and your program must implement these definitions exactly.\n\nData-generating process. For each test case, generate a training set and an independent test set as follows. Let the number of training patients be $n_{\\mathrm{train}}$, the number of test patients be $n_{\\mathrm{test}}$, the number of genes be $p$, and the true latent dimension be $r^\\star$. Let the unsupervised latent dimension used by the learner be $k$, where $k$ is an integer in the range $0 \\le k \\le \\min\\{p,n_{\\mathrm{train}}-1\\}$. Fix a base random seed $s$ for each test case to ensure reproducibility.\n\n- Draw a gene loading matrix $W \\in \\mathbb{R}^{p \\times r^\\star}$ with independent standard normal entries, using the base seed $s$.\n- Draw a survival coefficient vector $b \\in \\mathbb{R}^{r^\\star}$ with independent standard normal entries, using the same base seed $s$ and continuing the sequence of generated values.\n- Draw training latent factors $Z_{\\mathrm{train}} \\in \\mathbb{R}^{n_{\\mathrm{train}} \\times r^\\star}$ with independent standard normal entries, using the same base seed $s$ and continuing the sequence of generated values.\n- Draw training gene expression noise $E^{(X)}_{\\mathrm{train}} \\in \\mathbb{R}^{n_{\\mathrm{train}} \\times p}$ with independent entries distributed as $\\mathcal{N}(0,\\sigma_X^2)$, using the same base seed $s$ and continuing the sequence of generated values.\n- Draw training survival noise $e^{(y)}_{\\mathrm{train}} \\in \\mathbb{R}^{n_{\\mathrm{train}}}$ with independent entries distributed as $\\mathcal{N}(0,\\sigma_y^2)$, using the same base seed $s$ and continuing the sequence of generated values.\n- Define training gene expression as $X_{\\mathrm{train}} = Z_{\\mathrm{train}} W^\\top + E^{(X)}_{\\mathrm{train}} \\in \\mathbb{R}^{n_{\\mathrm{train}} \\times p}$.\n- Define training survival times as $y_{\\mathrm{train}} = Z_{\\mathrm{train}} b + e^{(y)}_{\\mathrm{train}} \\in \\mathbb{R}^{n_{\\mathrm{train}}}$.\n\nFor the test set, use the same $W$ and $b$ as above but independent latent factors and noise:\n- Use the test seed $s+1$ to draw $Z_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times r^\\star}$ with independent standard normal entries, $E^{(X)}_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times p}$ with independent entries distributed as $\\mathcal{N}(0,\\sigma_X^2)$, and $e^{(y)}_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}}}$ with independent entries distributed as $\\mathcal{N}(0,\\sigma_y^2)$, respectively.\n- Define test gene expression and survival as $X_{\\mathrm{test}} = Z_{\\mathrm{test}} W^\\top + E^{(X)}_{\\mathrm{test}}$ and $y_{\\mathrm{test}} = Z_{\\mathrm{test}} b + e^{(y)}_{\\mathrm{test}}$.\n\nTwo-stage learning pipeline. Your program must perform the following two optimization problems on the training data and then evaluate on the test data.\n\n1. Unsupervised representation learning. Learn a linear encoder $E: \\mathbb{R}^p \\to \\mathbb{R}^k$ and a linear decoder $D: \\mathbb{R}^k \\to \\mathbb{R}^p$, together with a centering vector $\\mu \\in \\mathbb{R}^p$, by solving\n$$\n\\min_{E,D,\\mu} \\ \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\left\\| x_i - D\\!\\left(E\\!\\left(x_i - \\mu\\right)\\right) \\right\\|_2^2,\n$$\nwhere $x_i \\in \\mathbb{R}^p$ denotes the $i$-th row of $X_{\\mathrm{train}}$. The learned encoder $E$ must be linear and the learned decoder $D$ must be linear. Use the learned encoder and centering vector to produce latent representations $z_i^{(\\mathrm{lat})} = E(x_i - \\mu) \\in \\mathbb{R}^k$ for each training sample $i \\in \\{1,\\dots,n_{\\mathrm{train}}\\}$, and for each test sample $j \\in \\{1,\\dots,n_{\\mathrm{test}}\\}$ produce $z_j^{(\\mathrm{lat,test})} = E(x^{(\\mathrm{test})}_j - \\mu)$ using the same $E$ and $\\mu$ estimated from the training data.\n\n2. Supervised prediction. Learn an affine predictor $g: \\mathbb{R}^k \\to \\mathbb{R}$ of the form $g(z) = c^\\top z + d$ by solving\n$$\n\\min_{c \\in \\mathbb{R}^k, \\ d \\in \\mathbb{R}} \\ \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\left( y_i - \\left(c^\\top z_i^{(\\mathrm{lat})} + d\\right) \\right)^2,\n$$\nwhere $y_i$ denotes the $i$-th entry of $y_{\\mathrm{train}}$. Using the learned $(c,d)$, compute predictions $\\hat{y}_j = c^\\top z_j^{(\\mathrm{lat,test})} + d$ for each test sample $j$, and evaluate the test mean squared error\n$$\n\\mathrm{MSE}_{\\mathrm{test}} = \\frac{1}{n_{\\mathrm{test}}} \\sum_{j=1}^{n_{\\mathrm{test}}} \\left( \\hat{y}_j - y^{(\\mathrm{test})}_j \\right)^2.\n$$\n\nTest suite. Your program must implement the above process and output the test mean squared error for each of the following parameter settings, using the exact generation and training procedures described. Each test case is a tuple $(s, n_{\\mathrm{train}}, n_{\\mathrm{test}}, p, r^\\star, k, \\sigma_X, \\sigma_y)$:\n\n- Test case 1: (7, 120, 80, 60, 5, 5, 0.3, 0.5).\n- Test case 2: (13, 150, 150, 80, 6, 6, 2.0, 2.0).\n- Test case 3: (21, 50, 50, 200, 3, 3, 0.5, 0.5).\n- Test case 4: (1, 100, 100, 70, 8, 2, 0.4, 0.4).\n- Test case 5: (99, 100, 100, 50, 4, 0, 0.5, 0.5).\n\nAnswer specification and output format. Your program must produce a single line of output containing the list of test mean squared errors for the test cases in the order listed above. Each value must be rounded to exactly $6$ decimal places. The output must be a comma-separated list enclosed in square brackets, for example, $[\\mathrm{mse}_1,\\mathrm{mse}_2,\\dots]$, with no extra spaces or text.", "solution": "The problem statement is valid. It is scientifically grounded, well-posed, objective, and provides a complete and consistent specification for a computational experiment. The task involves a standard two-stage machine learning pipeline applied to simulated data, a common practice in bioinformatics research for evaluating methods. The data-generating process is a linear factor model, and the learning algorithms are principal component analysis and ordinary least squares regression, both of which are fundamental and well-understood. The parameters for all test cases are within valid ranges. We may therefore proceed with the solution.\n\nThe problem requires the implementation of a two-stage learning pipeline. The first stage is unsupervised, learning a low-dimensional representation of the gene expression data. The second is supervised, using this learned representation to predict a clinical outcome (survival time).\n\n**Stage 1: Unsupervised Representation Learning**\n\nThe first optimization problem is:\n$$\n\\min_{E,D,\\mu} \\ \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\left\\| x_i - D\\!\\left(E\\!\\left(x_i - \\mu\\right)\\right) \\right\\|_2^2\n$$\nwhere $E: \\mathbb{R}^p \\to \\mathbb{R}^k$ and $D: \\mathbb{R}^k \\to \\mathbb{R}^p$ are linear transformations and $\\mu \\in \\mathbb{R}^p$ is a centering vector. This objective function seeks to minimize the reconstruction error of a linear autoencoder. The solution to this problem is given by Principal Component Analysis (PCA).\n\nFirst, the optimal centering vector $\\mu$ is the empirical mean of the training data vectors $x_i$:\n$$\n\\mu = \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} x_i = \\frac{1}{n_{\\mathrm{train}}} X_{\\mathrm{train}}^\\top \\mathbf{1}_{n_{\\mathrm{train}}}\n$$\nLet $\\bar{X}_{\\mathrm{train}} = X_{\\mathrm{train}} - \\mathbf{1}_{n_{\\mathrm{train}}} \\mu^\\top$ be the centered training data matrix. The optimization problem reduces to finding the best rank-$k$ approximation of $\\bar{X}_{\\mathrm{train}}$. By the Eckart-Young-Mirsky theorem, this is achieved using the Singular Value Decomposition (SVD) of $\\bar{X}_{\\mathrm{train}}$.\n\nLet the SVD of the centered data matrix be $\\bar{X}_{\\mathrm{train}} = U S V^\\top$, where the columns of $V \\in \\mathbb{R}^{p \\times p}$ are the principal components (eigenvectors of the sample covariance matrix). Let $V_k \\in \\mathbb{R}^{p \\times k}$ be the matrix whose columns are the first $k$ principal components, corresponding to the $k$ largest singular values.\n\nThe linear encoder $E$ projects the centered data onto the basis defined by these $k$ components. Its matrix representation is $V_k^\\top$. The learned latent representations for the training samples are:\n$$\nZ^{(\\mathrm{lat})} = \\bar{X}_{\\mathrm{train}} V_k \\in \\mathbb{R}^{n_{\\mathrm{train}} \\times k}\n$$\nFor the test data $X_{\\mathrm{test}}$, the latent representations are computed by first centering the data using the mean $\\mu$ from the training set, and then applying the same projection:\n$$\nZ^{(\\mathrm{lat,test})} = (X_{\\mathrm{test}} - \\mathbf{1}_{n_{\\mathrm{test}}} \\mu^\\top) V_k\n$$\n\n**Stage 2: Supervised Prediction**\n\nThe second stage involves learning an affine predictor $g(z) = c^\\top z + d$ by solving the following ordinary least squares (OLS) problem on the training data:\n$$\n\\min_{c \\in \\mathbb{R}^k, \\ d \\in \\mathbb{R}} \\ \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\left( y_i - \\left(c^\\top z_i^{(\\mathrm{lat})} + d\\right) \\right)^2\n$$\nTo solve this, we can augment the latent representation matrix $Z^{(\\mathrm{lat})}$ with a column of ones to account for the intercept term $d$. Let $\\tilde{Z}^{(\\mathrm{lat})} = [Z^{(\\mathrm{lat})} \\ \\mathbf{1}_{n_{\\mathrm{train}}}] \\in \\mathbb{R}^{n_{\\mathrm{train}} \\times (k+1)}$ and $\\tilde{c} = [c^\\top, d]^\\top \\in \\mathbb{R}^{k+1}$. The objective becomes minimizing $\\|\\mathbf{y}_{\\mathrm{train}} - \\tilde{Z}^{(\\mathrm{lat})} \\tilde{c}\\|_2^2$.\n\nThe solution is found by solving the normal equations, yielding:\n$$\n\\tilde{c}_{\\mathrm{opt}} = (\\tilde{Z}^{(\\mathrm{lat})\\top} \\tilde{Z}^{(\\mathrm{lat})})^\\dagger \\tilde{Z}^{(\\mathrm{lat})\\top} \\mathbf{y}_{\\mathrm{train}}\n$$\nwhere $\\dagger$ denotes the Moore-Penrose pseudoinverse, which provides a stable solution even if the matrix is not invertible.\n\nA special case arises when $k=0$. Here, the latent space is trivial (dimension zero), so $Z^{(\\mathrm{lat})}$ is an empty matrix. The model simplifies to $g(z)=d$. The optimization problem becomes $\\min_d \\sum_i (y_i - d)^2$, whose solution is the mean of the training labels: $d = \\bar{y}_{\\mathrm{train}} = \\frac{1}{n_{\\mathrm{train}}} \\sum_i y_i$.\n\n**Evaluation**\n\nFinally, predictions for the test set are generated using the learned coefficients $\\tilde{c}_{\\mathrm{opt}} = [c_{\\mathrm{opt}}^\\top, d_{\\mathrm{opt}}]^\\top$ and the test latent representations $Z^{(\\mathrm{lat,test})}$.\nFor $k > 0$, we form an augmented test matrix $\\tilde{Z}^{(\\mathrm{lat,test})} = [Z^{(\\mathrm{lat,test})} \\ \\mathbf{1}_{n_{\\mathrm{test}}}]$, and the predictions are $\\hat{\\mathbf{y}}_{\\mathrm{test}} = \\tilde{Z}^{(\\mathrm{lat,test})} \\tilde{c}_{\\mathrm{opt}}$.\nFor $k=0$, the prediction for every test sample is simply the constant value $\\hat{y}_j = d_{\\mathrm{opt}} = \\bar{y}_{\\mathrm{train}}$.\n\nThe performance is evaluated using the test Mean Squared Error (MSE):\n$$\n\\mathrm{MSE}_{\\mathrm{test}} = \\frac{1}{n_{\\mathrm{test}}} \\sum_{j=1}^{n_{\\mathrm{test}}} \\left( \\hat{y}_j - y^{(\\mathrm{test})}_j \\right)^2\n$$\nThe following program implements this entire procedure for each of the specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_pipeline(s, n_train, n_test, p, r_star, k, sigma_X, sigma_y):\n    \"\"\"\n    Implements the full data generation and two-stage learning pipeline for a single test case.\n    \n    Args:\n        s (int): Base random seed.\n        n_train (int): Number of training patients.\n        n_test (int): Number of test patients.\n        p (int): Number of genes.\n        r_star (int): True latent dimension.\n        k (int): Unsupervised latent dimension for the learner.\n        sigma_X (float): Standard deviation of gene expression noise.\n        sigma_y (float): Standard deviation of survival noise.\n        \n    Returns:\n        float: The test mean squared error.\n    \"\"\"\n    \n    # --- Data Generation ---\n    # Training data generation\n    rng_train = np.random.default_rng(s)\n    W = rng_train.standard_normal(size=(p, r_star))\n    b = rng_train.standard_normal(size=r_star)\n    Z_train = rng_train.standard_normal(size=(n_train, r_star))\n    E_X_train = rng_train.normal(scale=sigma_X, size=(n_train, p))\n    e_y_train = rng_train.normal(scale=sigma_y, size=n_train)\n    \n    X_train = Z_train @ W.T + E_X_train\n    y_train = Z_train @ b + e_y_train\n    \n    # Test data generation\n    rng_test = np.random.default_rng(s + 1)\n    Z_test = rng_test.standard_normal(size=(n_test, r_star))\n    E_X_test = rng_test.normal(scale=sigma_X, size=(n_test, p))\n    e_y_test = rng_test.normal(scale=sigma_y, size=n_test)\n    \n    X_test = Z_test @ W.T + E_X_test\n    y_test = Z_test @ b + e_y_test\n\n    # --- Two-Stage Learning Pipeline ---\n\n    # Stage 1: Unsupervised Representation Learning (PCA)\n    mu = np.mean(X_train, axis=0)\n    X_train_centered = X_train - mu\n    \n    if k > 0:\n        # SVD on centered training data\n        # full_matrices=False is more efficient\n        _, _, Vt = np.linalg.svd(X_train_centered, full_matrices=False)\n        \n        # Encoder is based on the top k principal components (right singular vectors)\n        # Vt is V.T, so we take the first k rows and transpose\n        Vk = Vt[:k, :].T  # Shape: (p, k)\n        \n        # Get latent representations for training and test sets\n        Z_lat_train = X_train_centered @ Vk\n        X_test_centered = X_test - mu\n        Z_lat_test = X_test_centered @ Vk\n    \n    # Stage 2: Supervised Prediction (OLS)\n    if k == 0:\n        # If k=0, the model is y = d. The best predictor is the mean of y_train.\n        d = np.mean(y_train)\n        y_hat_test = np.full(n_test, d)\n    else:\n        # Augment latent features with a column of ones for the intercept\n        Z_train_aug = np.c_[Z_lat_train, np.ones(n_train)]\n        \n        # Solve for coefficients (c and d) using least squares\n        # coeffs will contain [c_1, ..., c_k, d]\n        coeffs, _, _, _ = np.linalg.lstsq(Z_train_aug, y_train, rcond=None)\n        \n        # Predict on the test set\n        Z_test_aug = np.c_[Z_lat_test, np.ones(n_test)]\n        y_hat_test = Z_test_aug @ coeffs\n\n    # --- Evaluation ---\n    mse_test = np.mean((y_hat_test - y_test)**2)\n    return mse_test\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test cases: (s, n_train, n_test, p, r_star, k, sigma_X, sigma_y)\n    test_cases = [\n        (7, 120, 80, 60, 5, 5, 0.3, 0.5),\n        (13, 150, 150, 80, 6, 6, 2.0, 2.0),\n        (21, 50, 50, 200, 3, 3, 0.5, 0.5),\n        (1, 100, 100, 70, 8, 2, 0.4, 0.4),\n        (99, 100, 100, 50, 4, 0, 0.5, 0.5),\n    ]\n\n    results = []\n    for params in test_cases:\n        mse = solve_pipeline(*params)\n        results.append(mse)\n\n    # Format the output as specified: a comma-separated list in brackets,\n    # with each value rounded to 6 decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2432878"}]}