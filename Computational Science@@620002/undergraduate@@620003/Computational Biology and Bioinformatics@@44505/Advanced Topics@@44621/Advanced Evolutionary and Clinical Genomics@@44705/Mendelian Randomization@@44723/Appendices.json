{"hands_on_practices": [{"introduction": "The foundation of Mendelian Randomization lies in a simple yet powerful calculation known as the Wald ratio. This exercise walks you through this core principle using a single genetic variant as an instrumental variable. By calculating the ratio of the gene-outcome association ($\\beta_{YG}$) to the gene-exposure association ($\\beta_{EG}$), you will derive the causal effect estimate of the exposure on the outcome, providing a hands-on look at how MR leverages genetic data to infer causality [@problem_id:2854802].", "problem": "A single nucleotide polymorphism (SNP) $G$ acts as a cis-expression quantitative trait locus (cis-eQTL) for the expression level $E$ of a transcriptional regulator within a gene regulatory network, and is also associated with a complex trait $Y$. Consider a two-sample setting with non-overlapping samples so that the summary association estimates for $Y$ on $G$ and for $E$ on $G$ are statistically independent. Assume linear relationships, additivity on the appropriate scales, large-sample normality of the association estimates, and the standard instrumental variable assumptions for Mendelian Randomization (MR): instrument relevance, instrument independence from confounders, and exclusion of any pathway from $G$ to $Y$ other than through $E$. You are given the following summary estimates from regression analyses: the association of $Y$ on $G$ is $\\hat{\\beta}_{YG} = 0.10$ with standard error $\\mathrm{SE}(\\hat{\\beta}_{YG}) = 0.03$, and the association of $E$ on $G$ is $\\hat{\\beta}_{EG} = 0.25$ with standard error $\\mathrm{SE}(\\hat{\\beta}_{EG}) = 0.05$.\n\nUsing only the assumptions stated above, compute:\n- the MR causal effect estimate of $E$ on $Y$,\n- its standard error,\n- and the two-sided $p$-value for testing the null hypothesis that the causal effect is zero at significance level $\\alpha = 0.05$.\n\nReport your result as a row vector $\\left[\\hat{\\beta}_{\\mathrm{MR}}, \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}), p\\right]$. Round each component to three significant figures. No units are required.", "solution": "The problem requires the computation of a Mendelian Randomization (MR) causal effect estimate, its standard error, and the corresponding p-value in a two-sample setting. We begin by validating the problem statement.\n\nThe givens are:\n- A single nucleotide polymorphism (SNP) $G$ is an instrumental variable (IV).\n- The exposure is the expression level $E$ of a transcriptional regulator.\n- The outcome is a complex trait $Y$.\n- A two-sample design is used with non-overlapping samples, ensuring statistical independence of the summary estimates.\n- Standard MR assumptions are stated to hold:\n    1. Instrument relevance: $G$ is associated with $E$.\n    2. Instrument independence from confounders: $G$ is independent of any unmeasured confounders of the $E-Y$ relationship.\n    3. Exclusion restriction: $G$ affects $Y$ only through $E$.\n- The association estimate of $Y$ on $G$ is $\\hat{\\beta}_{YG} = 0.10$.\n- The standard error of this estimate is $\\mathrm{SE}(\\hat{\\beta}_{YG}) = 0.03$.\n- The association estimate of $E$ on $G$ is $\\hat{\\beta}_{EG} = 0.25$.\n- The standard error of this estimate is $\\mathrm{SE}(\\hat{\\beta}_{EG}) = 0.05$.\n- Additivity, linearity, and large-sample normality of estimates are assumed.\n- The significance level for testing is $\\alpha = 0.05$.\n\nThe problem is scientifically grounded, well-posed, objective, and internally consistent. It describes a standard application of the Wald ratio estimator for two-sample Mendelian Randomization, a cornerstone method in genetic epidemiology and systems genetics. All necessary data and assumptions are provided to derive a unique, meaningful solution. The problem is therefore valid.\n\nWe proceed with the solution.\n\nFirst, we compute the MR estimate for the causal effect of $E$ on $Y$, denoted $\\beta_{EY}$. Under the given assumptions, this effect can be estimated by the ratio of the SNP-outcome association to the SNP-exposure association. This is the Wald ratio estimator, which for our summary data is:\n$$ \\hat{\\beta}_{\\mathrm{MR}} = \\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{EG}} $$\nSubstituting the provided values:\n$$ \\hat{\\beta}_{\\mathrm{MR}} = \\frac{0.10}{0.25} = 0.4 $$\n\nSecond, we compute the standard error of this estimate, $\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})$. Since $\\hat{\\beta}_{YG}$ and $\\hat{\\beta}_{EG}$ are from non-overlapping samples, they are independent random variables. The variance of their ratio can be approximated using the first-order Taylor series expansion (the Delta method). For a function $f(x, y) = x/y$, the variance is approximated as:\n$$ \\mathrm{Var}\\left(\\frac{X}{Y}\\right) \\approx \\left(\\frac{\\mu_X}{\\mu_Y}\\right)^2 \\left( \\frac{\\mathrm{Var}(X)}{\\mu_X^2} + \\frac{\\mathrm{Var}(Y)}{\\mu_Y^2} \\right) $$\nApplying this to our estimates, where $\\mathrm{Var}(\\hat{\\beta}) = \\mathrm{SE}(\\hat{\\beta})^2$:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\left(\\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{EG}}\\right)^2 \\left( \\frac{\\mathrm{SE}(\\hat{\\beta}_{YG})^2}{\\hat{\\beta}_{YG}^2} + \\frac{\\mathrm{SE}(\\hat{\\beta}_{EG})^2}{\\hat{\\beta}_{EG}^2} \\right) $$\nA more direct and commonly used form derived from the Delta method is:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{\\mathrm{SE}(\\hat{\\beta}_{YG})^2}{\\hat{\\beta}_{EG}^2} + \\frac{\\hat{\\beta}_{YG}^2 \\mathrm{SE}(\\hat{\\beta}_{EG})^2}{\\hat{\\beta}_{EG}^4} $$\nWe will use this formulation. Substituting the given values:\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{(0.03)^2}{(0.25)^2} + \\frac{(0.10)^2 (0.05)^2}{(0.25)^4} $$\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx \\frac{0.0009}{0.0625} + \\frac{(0.01)(0.0025)}{0.00390625} $$\n$$ \\mathrm{Var}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx 0.0144 + \\frac{0.000025}{0.00390625} = 0.0144 + 0.0064 = 0.0208 $$\nThe standard error is the square root of the variance:\n$$ \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}) = \\sqrt{0.0208} \\approx 0.144222051... $$\n\nThird, we compute the two-sided p-value for the null hypothesis $H_0: \\beta_{\\mathrm{MR}} = 0$. Given the assumption of large-sample normality, the test statistic $Z$ follows a standard normal distribution $\\mathcal{N}(0, 1)$ under the null hypothesis.\n$$ Z = \\frac{\\hat{\\beta}_{\\mathrm{MR}} - 0}{\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})} = \\frac{\\hat{\\beta}_{\\mathrm{MR}}}{\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}})} $$\nSubstituting the calculated values:\n$$ Z \\approx \\frac{0.4}{0.144222051...} \\approx 2.77350098... $$\nThe two-sided p-value is the probability of observing a test statistic at least as extreme as $|Z|$:\n$$ p = 2 \\times P(Z_{std} \\ge |Z|) = 2 \\times (1 - \\Phi(|Z|)) $$\nwhere $\\Phi$ is the cumulative distribution function of the standard normal distribution.\n$$ p \\approx 2 \\times (1 - \\Phi(2.7735)) \\approx 2 \\times (1 - 0.99723) \\approx 2 \\times 0.00277 = 0.00554 $$\n\nFinally, we report the results rounded to three significant figures as a row vector $[\\hat{\\beta}_{\\mathrm{MR}}, \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}), p]$.\n- $\\hat{\\beta}_{\\mathrm{MR}} = 0.4$ rounded to three significant figures is $0.400$.\n- $\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{MR}}) \\approx 0.14422...$ rounded to three significant figures is $0.144$.\n- $p \\approx 0.00554$ (already has three significant figures, $5, 5, 4$).\n\nThe final result is the vector $[0.400, 0.144, 0.00554]$.", "answer": "$$\\boxed{\\begin{pmatrix} 0.400 & 0.144 & 0.00554 \\end{pmatrix}}$$", "id": "2854802"}, {"introduction": "While a single instrument can illustrate the principle of MR, real-world analyses gain statistical power by combining information from multiple genetic variants. This practice guides you through the essential techniques for multi-instrument MR, including the standard Inverse-Variance Weighted (IVW) method [@problem_id:2404096]. You will also implement key diagnostic tools like MR-Egger regression and funnel plots, which are crucial for detecting heterogeneity and directional pleiotropy—major challenges to the validity of an MR study.", "problem": "You are given summary association data from Genome-Wide Association Study (GWAS) instruments, each being a Single Nucleotide Polymorphism (SNP), in the setting of Mendelian randomization (MR). For each SNP, you have the association with an exposure, denoted $ \\beta_{GX,i} $, and the association with an outcome, denoted $ \\beta_{GY,i} $, together with the standard error of the outcome association $ \\sigma_{GY,i} $. Assume the following fundamental base: (i) a linear causal model for the exposure–outcome relationship; (ii) instruments affect the outcome only through the exposure apart from any potential horizontal pleiotropy; (iii) sampling variability in $ \\beta_{GY,i} $ is quantified by $ \\sigma_{GY,i} $, and uncertainty in $ \\beta_{GX,i} $ is negligible relative to $ \\sigma_{GY,i} $ for the purpose of weighting; (iv) the causal effect is estimable by aggregating per-variant information using weighted least squares.\n\nYour task is to write a complete program that, for each test case described below, computes the numerical objects required to generate (a) a scatter plot of $ \\beta_{GY} $ versus $ \\beta_{GX} $ with both the intercept-constrained Inverse-Variance Weighted (IVW) regression line and the Mendelian randomization Egger (MR-Egger) regression line, and (b) a funnel plot of ratio estimates versus their standard errors to visually inspect for heterogeneity and pleiotropy. Instead of drawing any plot, your program must return the precise numerical quantities that define those plots.\n\nStarting only from the base principles above, implement the following computations for each test case:\n- Use weights $ w_i $ defined by the inverse of the outcome variance, i.e., $ w_i $ proportional to $ 1 / \\sigma_{GY,i}^2 $.\n- Compute the intercept-constrained IVW estimate of the causal slope, by solving the weighted least squares problem with intercept fixed to zero that minimizes $ \\sum_i w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2 $ over $ b $.\n- Compute the MR-Egger weighted regression line with an unconstrained intercept, by minimizing $ \\sum_i w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2 $ over $ a $ and $ b $.\n- Compute Cochran’s $ Q $ statistic for heterogeneity under the IVW fit and the corresponding $ I^2 $ heterogeneity metric, where $ Q $ compares the dispersion of the weighted residuals to their expected value under homogeneity.\n- For the funnel plot, compute the per-variant ratio estimate $ \\theta_i $ and its approximate standard error $ s_i $ under the assumption that uncertainty in $ \\beta_{GX,i} $ is negligible relative to $ \\sigma_{GY,i} $. Then compute the pseudo $ 95\\% $ funnel bounds for each variant around the pooled IVW effect as $ \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i $.\n\nYour program must apply these computations to the following test suite. Each test case is defined by three lists of equal length: $ \\beta_{GX} $, $ \\beta_{GY} $, and $ \\sigma_{GY} $.\n\nTest case A (happy path; consistent instruments):\n- $ \\beta_{GX} = [\\, 0.08, \\, 0.12, \\, 0.10, \\, 0.15, \\, 0.07, \\, 0.11 \\,] $\n- $ \\beta_{GY} = [\\, 0.040, \\, 0.060, \\, 0.051, \\, 0.072, \\, 0.033, \\, 0.057 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.018, \\, 0.022, \\, 0.019, \\, 0.021, \\, 0.020 \\,] $\n\nTest case B (directional pleiotropy; nonzero intercept expected):\n- $ \\beta_{GX} = [\\, 0.05, \\, -0.04, \\, 0.09, \\, 0.12, \\, 0.03, \\, 0.07 \\,] $\n- $ \\beta_{GY} = [\\, 0.037, \\, 0.007, \\, 0.048, \\, 0.054, \\, 0.029, \\, 0.042 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.021, \\, 0.019, \\, 0.018, \\, 0.022, \\, 0.020 \\,] $\n\nTest case C (heterogeneity and a weak instrument):\n- $ \\beta_{GX} = [\\, 0.20, \\, 0.15, \\, 0.10, \\, 0.05, \\, 0.004 \\,] $\n- $ \\beta_{GY} = [\\, 0.080, \\, 0.070, \\, 0.045, \\, 0.050, \\, 0.010 \\,] $\n- $ \\sigma_{GY} = [\\, 0.015, \\, 0.015, \\, 0.016, \\, 0.020, \\, 0.020 \\,] $\n\nTest case D (balanced pleiotropy; heterogeneity with approximately zero intercept):\n- $ \\beta_{GX} = [\\, 0.10, \\, 0.12, \\, 0.09, \\, 0.11, \\, 0.08 \\,] $\n- $ \\beta_{GY} = [\\, 0.080, \\, 0.052, \\, 0.064, \\, 0.056, \\, 0.048 \\,] $\n- $ \\sigma_{GY} = [\\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020 \\,] $\n\nImplementation and numerical requirements:\n- Treat all weights as $ w_i = 1 / \\sigma_{GY,i}^2 $.\n- For the funnel plot, compute $ \\theta_i = \\beta_{GY,i} / \\beta_{GX,i} $ and $ s_i = \\sigma_{GY,i} / \\lvert \\beta_{GX,i} \\rvert $.\n- Use the IVW slope for the pooled effect in the funnel plot bounds $ \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i $.\n- For Cochran’s heterogeneity statistic under the IVW fit, compute $ Q $ and then $ I^2 = \\max \\left( 0, \\, \\dfrac{Q - (M - 1)}{Q} \\right) $ with $ M $ the number of variants. If $ Q = 0 $, set $ I^2 = 0 $.\n- Your program must output, for each test case, a list of nine elements in the following order:\n  1. the IVW slope (a float),\n  2. the MR-Egger slope (a float),\n  3. the MR-Egger intercept (a float),\n  4. the IVW Cochran’s $ Q $ (a float),\n  5. the IVW $ I^2 $ (a float),\n  6. the list of ratio estimates $ [ \\theta_i ] $,\n  7. the list of ratio standard errors $ [ s_i ] $,\n  8. the list of lower funnel bounds $ [ \\theta_{\\text{IVW}} - 1.96 \\, s_i ] $,\n  9. the list of upper funnel bounds $ [ \\theta_{\\text{IVW}} + 1.96 \\, s_i ] $.\n- Express all floats rounded to six decimal places.\n- Final output format: Your program should produce a single line of output containing the four per-test-case results aggregated as a comma-separated list enclosed in square brackets, with no spaces. That is, a single line of the form $ [r_A, r_B, r_C, r_D] $ where each $ r_\\cdot $ is the nine-element list described above.\n\nEdge conditions and scientific realism:\n- Enforce that $ \\lvert \\beta_{GX,i} \\rvert $ is not zero to avoid division by zero in ratio computations. The provided test suite satisfies this; in general, if any $ \\lvert \\beta_{GX,i} \\rvert $ were below a small threshold $ \\varepsilon $, the variant should be excluded from the ratio and funnel components while remaining consistent in regression fits if handled appropriately. In this test suite, no exclusions are necessary.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established principles of Mendelian randomization (MR), a standard method in genetic epidemiology. The problem is well-posed, providing all necessary data and explicit mathematical definitions for the required computations. The language is objective and formal, free of ambiguity or subjective claims. It presents a solvable computational task based on verifiable statistical and mathematical principles.\n\nWe will now proceed with a systematic derivation of the required quantities. The context is the estimation of a causal effect of an exposure on an outcome using genetic variants as instrumental variables. For each of $M$ genetic variants (SNPs), we are given its estimated association with the exposure, $\\beta_{GX,i}$, its estimated association with the outcome, $\\beta_{GY,i}$, and the standard error of the latter, $\\sigma_{GY,i}$.\n\nThe weights for all weighted calculations are defined by the inverse of the outcome variance, assuming uncertainty in $\\beta_{GX,i}$ is negligible for this purpose:\n$$\nw_i = \\frac{1}{\\sigma_{GY,i}^2}\n$$\n\n**1. Intercept-Constrained Inverse-Variance Weighted (IVW) Slope**\n\nThe IVW method estimates the causal effect, $b$, by solving a weighted least squares problem that forces the regression line through the origin. This corresponds to the assumption of no horizontal pleiotropy. The objective is to minimize the sum of weighted squared residuals:\n$$\nS(b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2\n$$\nTo find the minimum, we set the derivative with respect to $b$ to zero:\n$$\n\\frac{dS}{db} = -2 \\sum_{i=1}^{M} w_i \\beta_{GX,i} \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right) = 0\n$$\nSolving for $b$ yields the IVW estimate, which we denote $\\theta_{\\text{IVW}}$:\n$$\n\\theta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{M} w_i \\beta_{GX,i} \\beta_{GY,i}}{\\sum_{i=1}^{M} w_i \\beta_{GX,i}^2}\n$$\n\n**2. Mendelian Randomization Egger (MR-Egger) Regression**\n\nThe MR-Egger method relaxes the no-pleiotropy assumption of the IVW method by allowing for a non-zero intercept in the regression of $\\beta_{GY,i}$ on $\\beta_{GX,i}$. The intercept, $a$, can be interpreted as an estimate of the average directional pleiotropic effect, while the slope, $b$, remains the estimate of the causal effect. We minimize the following objective function over both $a$ and $b$:\n$$\nS(a, b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2\n$$\nThis is a standard weighted linear regression problem. The solutions for the MR-Egger slope ($b_{\\text{Egger}}$) and intercept ($a_{\\text{Egger}}$) are given by the normal equations:\n$$\nb_{\\text{Egger}} = \\frac{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i} \\beta_{GY,i}\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right) \\left(\\sum w_i \\beta_{GY,i}\\right) }{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i}^2\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right)^2 }\n$$\n$$\na_{\\text{Egger}} = \\frac{\\sum w_i \\beta_{GY,i}}{\\sum w_i} - b_{\\text{Egger}} \\frac{\\sum w_i \\beta_{GX,i}}{\\sum w_i}\n$$\nThese formulas correspond to the standard solution for weighted least squares regression coefficients.\n\n**3. Cochran’s Q Statistic and I² Heterogeneity Metric**\n\nHeterogeneity among the instrument-specific causal estimates can indicate either violation of the MR assumptions (such as pleiotropy) or that the true causal effect differs for subsets of the population targeted by different instruments. Cochran’s $Q$ statistic for the IVW model quantifies this heterogeneity by summing the weighted squared differences between the individual ratio estimates and the pooled IVW estimate. It is calculated as:\n$$\nQ = \\sum_{i=1}^{M} w_i \\left( \\frac{\\beta_{GY,i}}{\\beta_{GX,i}} - \\theta_{\\text{IVW}} \\right)^2 \\beta_{GX,i}^2 = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - \\theta_{\\text{IVW}} \\beta_{GX,i} \\right)^2\n$$\nUnder the null hypothesis of homogeneity (i.e., all instruments estimate the same causal effect), $Q$ follows a chi-squared distribution with $M-1$ degrees of freedom.\n\nThe $I^2$ statistic describes the percentage of variation across instruments that is due to heterogeneity rather than sampling error. It is derived from $Q$:\n$$\nI^2 = \\max\\left(0, \\frac{Q - (M-1)}{Q}\\right)\n$$\nIf $Q=0$, which is highly unlikely in practice, $I^2$ is defined as $0$.\n\n**4. Funnel Plot Components**\n\nA funnel plot is a visual tool to investigate heterogeneity and publication bias. It plots the effect size of each instrument against a measure of its precision.\n\n-   **Per-variant ratio estimate ($\\theta_i$):** This is the causal effect estimated from a single instrument $i$:\n    $$\n    \\theta_i = \\frac{\\beta_{GY,i}}{\\beta_{GX,i}}\n    $$\n-   **Standard error of the ratio estimate ($s_i$):** Using the delta method and the assumption that $\\beta_{GX,i}$ is measured with negligible error, the standard error of $\\theta_i$ is approximated as:\n    $$\n    s_i = \\text{SE}(\\theta_i) \\approx \\frac{\\sigma_{GY,i}}{\\lvert \\beta_{GX,i} \\rvert}\n    $$\n-   **Funnel plot bounds:** The funnel is constructed around the pooled IVW causal estimate, $\\theta_{\\text{IVW}}$. For a pseudo $95\\%$ confidence interval, the bounds for each variant $i$ are:\n    $$\n    \\text{Bounds}_i = \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i\n    $$\n    The lower and upper bounds are $\\theta_{\\text{IVW}} - 1.96 \\, s_i$ and $\\theta_{\\text{IVW}} + 1.96 \\, s_i$, respectively.\n\nThe implementation will compute these nine quantities for each provided test case: the IVW slope, the MR-Egger slope and intercept, the Cochran's $Q$ and $I^2$ statistics for the IVW fit, and the lists of ratio estimates, their standard errors, and the corresponding lower and upper funnel bounds. All floating-point numbers will be rounded to six decimal places as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_mr_metrics(beta_gx: list[float], beta_gy: list[float], sigma_gy: list[float]) -> list:\n    \"\"\"\n    Computes Mendelian randomization metrics for a given set of summary statistics.\n\n    Args:\n        beta_gx: List of SNP-exposure associations.\n        beta_gy: List of SNP-outcome associations.\n        sigma_gy: List of standard errors for SNP-outcome associations.\n\n    Returns:\n        A list containing nine elements as specified in the problem description.\n    \"\"\"\n    # Convert lists to NumPy arrays for vectorized operations\n    bgx = np.array(beta_gx)\n    bgy = np.array(beta_gy)\n    sgy = np.array(sigma_gy)\n    \n    # 1. Weights\n    # w_i = 1 / sigma_GY,i^2\n    w = 1.0 / (sgy**2)\n    \n    # 2. IVW Slope (Intercept-constrained)\n    # theta_ivw = (sum w_i * beta_gx_i * beta_gy_i) / (sum w_i * beta_gx_i^2)\n    ivw_numerator = np.sum(w * bgx * bgy)\n    ivw_denominator = np.sum(w * bgx**2)\n    ivw_slope = ivw_numerator / ivw_denominator\n    \n    # 3. MR-Egger Slope and Intercept\n    # Weighted least squares regression of bgy on bgx with weights w\n    W = np.sum(w)\n    Swx = np.sum(w * bgx)\n    Swy = np.sum(w * bgy)\n    Swxx = np.sum(w * bgx**2)\n    Swxy = np.sum(w * bgx * bgy)\n    \n    egger_denominator = (W * Swxx - Swx**2)\n    if egger_denominator == 0:\n        # This case is unlikely with real data but handle for robustness\n        mr_egger_slope = np.nan\n        mr_egger_intercept = np.nan\n    else:\n        mr_egger_slope = (W * Swxy - Swx * Swy) / egger_denominator\n        mr_egger_intercept = (Swy / W) - mr_egger_slope * (Swx / W)\n\n    # 4. Cochran's Q for IVW\n    # Q = sum w_i * (beta_gy_i - theta_ivw * beta_gx_i)^2\n    cochran_q = np.sum(w * (bgy - ivw_slope * bgx)**2)\n    \n    # 5. I^2 for IVW\n    M = len(bgx)\n    df = M - 1\n    if cochran_q == 0:\n        i_squared = 0.0\n    else:\n        i_squared = max(0.0, (cochran_q - df) / cochran_q)\n\n    # 6. Ratio estimates (theta_i)\n    # theta_i = beta_gy_i / beta_gx_i\n    theta_i = bgy / bgx\n    \n    # 7. Ratio standard errors (s_i)\n    # s_i = sigma_gy_i / |beta_gx_i|\n    s_i = sgy / np.abs(bgx)\n    \n    # 8. & 9. Funnel plot bounds\n    # lower/upper = theta_ivw +/- 1.96 * s_i\n    z_score = 1.96\n    funnel_lower_bounds = ivw_slope - z_score * s_i\n    funnel_upper_bounds = ivw_slope + z_score * s_i\n    \n    # Assemble results and round to 6 decimal places\n    results = [\n        round(ivw_slope, 6),\n        round(mr_egger_slope, 6),\n        round(mr_egger_intercept, 6),\n        round(cochran_q, 6),\n        round(i_squared, 6),\n        [round(val, 6) for val in theta_i],\n        [round(val, 6) for val in s_i],\n        [round(val, 6) for val in funnel_lower_bounds],\n        [round(val, 6) for val in funnel_upper_bounds],\n    ]\n    \n    return results\n\ndef format_result_list(res_list: list) -> str:\n    \"\"\"Formats a single test case result list into the required string format.\"\"\"\n    str_parts = []\n    for item in res_list:\n        if isinstance(item, list):\n            formatted_list = f\"[{','.join([f'{x:.6f}' for x in item])}]\"\n            str_parts.append(formatted_list)\n        else:\n            str_parts.append(f\"{item:.6f}\")\n    return f\"[{','.join(str_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = {\n        'A': {\n            \"beta_gx\": [0.08, 0.12, 0.10, 0.15, 0.07, 0.11],\n            \"beta_gy\": [0.040, 0.060, 0.051, 0.072, 0.033, 0.057],\n            \"sigma_gy\": [0.020, 0.018, 0.022, 0.019, 0.021, 0.020]\n        },\n        'B': {\n            \"beta_gx\": [0.05, -0.04, 0.09, 0.12, 0.03, 0.07],\n            \"beta_gy\": [0.037, 0.007, 0.048, 0.054, 0.029, 0.042],\n            \"sigma_gy\": [0.020, 0.021, 0.019, 0.018, 0.022, 0.020]\n        },\n        'C': {\n            \"beta_gx\": [0.20, 0.15, 0.10, 0.05, 0.004],\n            \"beta_gy\": [0.080, 0.070, 0.045, 0.050, 0.010],\n            \"sigma_gy\": [0.015, 0.015, 0.016, 0.020, 0.020]\n        },\n        'D': {\n            \"beta_gx\": [0.10, 0.12, 0.09, 0.11, 0.08],\n            \"beta_gy\": [0.080, 0.052, 0.064, 0.056, 0.048],\n            \"sigma_gy\": [0.020, 0.020, 0.020, 0.020, 0.020]\n        }\n    }\n\n    all_results_str = []\n    # Process cases in alphabetical order to match output format\n    for key in sorted(test_cases.keys()):\n        case = test_cases[key]\n        result = calculate_mr_metrics(case[\"beta_gx\"], case[\"beta_gy\"], case[\"sigma_gy\"])\n        all_results_str.append(format_result_list(result))\n\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "2404096"}, {"introduction": "A key challenge in Mendelian Randomization is the presence of horizontal pleiotropy, where genetic instruments affect the outcome through pathways other than the exposure. When diagnostics suggest that some instruments may be invalid, standard methods like IVW can be biased. This exercise introduces you to robust estimation methods, specifically the weighted median and weighted mode estimators, which are designed to provide a consistent causal effect estimate even when a substantial proportion of instruments violate the MR assumptions [@problem_id:2404047].", "problem": "Implement a program that, given summarized two-sample Mendelian randomization (MR) data for several independent genetic variants, computes three causal effect estimators: the inverse-variance weighted (IVW) estimator, the weighted median estimator, and the weighted mode estimator. The context is Mendelian randomization (MR), where genetic variants serve as instrumental variables for an exposure-outcome relationship. You are given variant-level association estimates for the exposure and for the outcome, together with their standard errors, and you must compute each estimator from first principles using only these summary inputs.\n\nLet there be $m$ independent genetic variants (Single Nucleotide Polymorphisms (SNPs)), indexed by $i \\in \\{1,\\dots,m\\}$. For each variant $i$, you are given the exposure association $\\hat{\\gamma}_{X,i}$, its standard error $\\operatorname{se}(\\hat{\\gamma}_{X,i})$, the outcome association $\\hat{\\gamma}_{Y,i}$, and its standard error $\\operatorname{se}(\\hat{\\gamma}_{Y,i})$. Assume two-sample MR with no sample overlap, so that the measurement error in $\\hat{\\gamma}_{X,i}$ can be ignored when approximating the variance of the ratio estimator. For each variant, define the ratio estimate\n$$\n\\hat{\\beta}_i \\equiv \\frac{\\hat{\\gamma}_{Y,i}}{\\hat{\\gamma}_{X,i}},\n$$\nthe approximate standard error\n$$\n\\hat{\\sigma}_{\\beta_i} \\equiv \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}{\\lvert \\hat{\\gamma}_{X,i} \\rvert},\n$$\nand the inverse-variance weight\n$$\nw_i \\equiv \\frac{1}{\\hat{\\sigma}_{\\beta_i}^2} = \\left(\\frac{\\lvert \\hat{\\gamma}_{X,i} \\rvert}{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}\\right)^2.\n$$\n\nDefine the three estimators as follows:\n\n1. Inverse-variance weighted (IVW) estimator:\n$$\n\\hat{\\beta}_{\\mathrm{IVW}} \\equiv \\frac{\\sum_{i=1}^m w_i \\hat{\\beta}_i}{\\sum_{i=1}^m w_i}.\n$$\n\n2. Weighted median estimator: Let $(\\hat{\\beta}_{(1)}, \\dots, \\hat{\\beta}_{(m)})$ be the ratio estimates sorted in nondecreasing order with corresponding weights $(w_{(1)}, \\dots, w_{(m)})$ permuted consistently, and let $W \\equiv \\sum_{i=1}^m w_i$. The weighted median is any $\\hat{\\beta}_{(k)}$ satisfying\n$$\n\\sum_{j=1}^{k-1} \\frac{w_{(j)}}{W} < 0.5 \\le \\sum_{j=1}^{k} \\frac{w_{(j)}}{W}.\n$$\nReturn the smallest such $\\hat{\\beta}_{(k)}$.\n\n3. Weighted mode estimator: For a fixed bandwidth $h > 0$, define the weighted Gaussian-kernel score for any $b \\in \\mathbb{R}$ as\n$$\nS_h(b) \\equiv \\sum_{i=1}^m w_i \\exp\\!\\left(-\\frac{(\\,b - \\hat{\\beta}_i\\,)^2}{2 h^2}\\right).\n$$\nThe weighted mode estimator is\n$$\n\\hat{\\beta}_{\\mathrm{mode}}(h) \\equiv \\operatorname*{arg\\,max}_{b \\in \\mathbb{R}} S_h(b).\n$$\nFor numerical computation, evaluate $S_h(b)$ on a uniform grid covering\n$$\n\\left[\\min_i \\hat{\\beta}_i - 0.2,\\; \\max_i \\hat{\\beta}_i + 0.2\\right]\n$$\nwith at least $20001$ evenly spaced points, and take the maximizer on this grid. Use a common bandwidth $h = 0.06$ for all test cases.\n\nYour program must compute $(\\hat{\\beta}_{\\mathrm{IVW}}, \\hat{\\beta}_{\\mathrm{WM}}, \\hat{\\beta}_{\\mathrm{mode}})$ for each test case below, where $\\hat{\\beta}_{\\mathrm{WM}}$ denotes the weighted median, and then print all results on a single line as a list of lists, with each inner list corresponding to one test case in order, and with each numeric value rounded to exactly $4$ decimal places.\n\nTest Suite (three cases):\n- Case A (all instruments valid, cluster around a single causal effect): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.053, 0.056, 0.042, -0.044, 0.080, -0.057, 0.038, 0.094, -0.062, 0.026, -0.084, 0.072),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02).\n$$\n\n- Case B (exactly $50$ percent invalid instruments, two clusters; the invalid set exhibits directional pleiotropy proportional to exposure association): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.052, 0.057, 0.041, -0.043, 0.079, -0.056, 0.057, 0.156, -0.101, 0.042, -0.132, 0.115),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03).\n$$\nIn this case, $6$ variants (the first $6$ entries) are valid and $6$ variants (the last $6$ entries) are invalid.\n\n- Case C (exactly $50$ percent invalid instruments with one very weak instrument for the exposure): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.02, 0.06, -0.07, 0.09, -0.05, 0.11, -0.10, 0.04, 0.13, -0.08, 0.03, 0.12),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.011, 0.047, -0.034, 0.0655, -0.026, 0.0855, -0.048, 0.029, 0.062, -0.058, 0.016, 0.086),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02).\n$$\nIn this case, by construction, $6$ variants are valid and $6$ variants are invalid; the first entry includes a very weak exposure association $\\hat{\\gamma}_{X,1} = 0.02$.\n\nYour program should produce a single line of output containing the results for the three cases as a comma-separated list of lists in the form\n$$\n\\big[\\,[\\hat{\\beta}_{\\mathrm{IVW}}^{(A)}, \\hat{\\beta}_{\\mathrm{WM}}^{(A)}, \\hat{\\beta}_{\\mathrm{mode}}^{(A)}],\\; [\\hat{\\beta}_{\\mathrm{IVW}}^{(B)}, \\hat{\\beta}_{\\mathrm{WM}}^{(B)}, \\hat{\\beta}_{\\mathrm{mode}}^{(B)}],\\; [\\hat{\\beta}_{\\mathrm{IVW}}^{(C)}, \\hat{\\beta}_{\\mathrm{WM}}^{(C)}, \\hat{\\beta}_{\\mathrm{mode}}^{(C)}] \\big],\n$$\nwith each numeric value rounded to exactly $4$ decimal places. No additional text should be printed. Angles and physical units do not apply here. All numerical results must be reported as decimal floats in the specified list-of-lists format.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It presents a standard computational task within the field of Mendelian randomization (MR), a well-established method in statistical genetics and epidemiology. All necessary data, mathematical definitions, and numerical parameters are provided, rendering the problem self-contained and unambiguous. The defined estimators—Inverse-Variance Weighted (IVW), Weighted Median, and Weighted Mode—are standard in MR literature. The supplied numerical data is realistic for summary statistics from genome-wide association studies. Therefore, we proceed with the solution.\n\nThe task is to compute three distinct estimators for the causal effect of an exposure on an outcome using summary data from $m$ independent genetic variants, which serve as instrumental variables. For each variant $i \\in \\{1, \\dots, m\\}$, we are provided with the association estimate with the exposure, $\\hat{\\gamma}_{X,i}$, its standard error, $\\operatorname{se}(\\hat{\\gamma}_{X,i})$, the association estimate with the outcome, $\\hat{\\gamma}_{Y,i}$, and its standard error, $\\operatorname{se}(\\hat{\\gamma}_{Y,i})$.\n\nFirst, we compute two key quantities for each variant $i$: the ratio estimate of the causal effect, $\\hat{\\beta}_i$, and its corresponding inverse-variance weight, $w_i$.\n\nThe ratio estimate is the ratio of the variant-outcome association to the variant-exposure association:\n$$\n\\hat{\\beta}_i = \\frac{\\hat{\\gamma}_{Y,i}}{\\hat{\\gamma}_{X,i}}\n$$\nThis estimate represents the causal effect of the exposure on the outcome as instrumented by variant $i$.\n\nThe variance of this ratio estimate can be approximated using the delta method. Under the assumption of two-sample MR with no sample overlap, the covariance between $\\hat{\\gamma}_{X,i}$ and $\\hat{\\gamma}_{Y,i}$ is zero. Further, we can ignore the uncertainty in the denominator $\\hat{\\gamma}_{X,i}$ (the \"no measurement error\" or NOME assumption for the exposure), which is a common simplification when the variant-exposure associations are strong. This leads to the approximate variance:\n$$\n\\operatorname{Var}(\\hat{\\beta}_i) \\approx \\frac{\\operatorname{Var}(\\hat{\\gamma}_{Y,i})}{\\gamma_{X,i}^2} = \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})^2}{\\gamma_{X,i}^2}\n$$\nReplacing the true effect $\\gamma_{X,i}$ with its estimate $\\hat{\\gamma}_{X,i}$ gives the estimated standard error of the ratio estimate:\n$$\n\\hat{\\sigma}_{\\beta_i} = \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}{|\\hat{\\gamma}_{X,i}|}\n$$\nThe absolute value is used to ensure the standard error is positive. The inverse-variance weight for each ratio estimate is the reciprocal of its estimated variance:\n$$\nw_i = \\frac{1}{\\hat{\\sigma}_{\\beta_i}^2} = \\left( \\frac{|\\hat{\\gamma}_{X,i}|}{\\operatorname{se}(\\hat{\\gamma}_{Y,i})} \\right)^2\n$$\nThese weights reflect the precision of each individual ratio estimate.\n\nWith $\\hat{\\beta}_i$ and $w_i$ computed for all $m$ variants, we can now define and compute the three required estimators.\n\n1.  **Inverse-Variance Weighted (IVW) Estimator**\n    The IVW estimator, $\\hat{\\beta}_{\\mathrm{IVW}}$, is the weighted average of the individual ratio estimates $\\hat{\\beta}_i$, with weights $w_i$:\n    $$\n    \\hat{\\beta}_{\\mathrm{IVW}} = \\frac{\\sum_{i=1}^m w_i \\hat{\\beta}_i}{\\sum_{i=1}^m w_i}\n    $$\n    This estimator is statistically efficient under the assumption that all variants are valid instruments and there is no horizontal pleiotropy (or that any pleiotropy is balanced around zero). It is equivalent to the slope from a weighted linear regression of $\\hat{\\gamma}_{Y,i}$ on $\\hat{\\gamma}_{X,i}$ with the intercept constrained to zero.\n\n2.  **Weighted Median Estimator**\n    The weighted median estimator, $\\hat{\\beta}_{\\mathrm{WM}}$, provides a robust estimate when a significant fraction (up to $50\\%$) of the genetic variants are invalid instruments (i.e., exhibit horizontal pleiotropy). The calculation proceeds as follows:\n    First, the ratio estimates $\\hat{\\beta}_i$ are sorted in non-decreasing order to obtain $(\\hat{\\beta}_{(1)}, \\dots, \\hat{\\beta}_{(m)})$. The corresponding weights $(w_{(1)}, \\dots, w_{(m)})$ are permuted consistently.\n    Second, the total weight $W = \\sum_{i=1}^m w_i$ is computed.\n    Third, we find the smallest index $k$ such that the cumulative sum of normalized weights up to that index is at least $0.5$. Formally, we seek $\\hat{\\beta}_{(k)}$ where:\n    $$\n    \\sum_{j=1}^{k-1} \\frac{w_{(j)}}{W} < 0.5 \\le \\sum_{j=1}^{k} \\frac{w_{(j)}}{W}\n    $$\n    The weighted median estimate is then $\\hat{\\beta}_{\\mathrm{WM}} = \\hat{\\beta}_{(k)}$. The algorithm involves sorting the $(\\hat{\\beta}_i, w_i)$ pairs by $\\hat{\\beta}_i$ and identifying the value at which the cumulative normalized weight first meets or exceeds $0.5$.\n\n3.  **Weighted Mode Estimator**\n    The weighted mode estimator, $\\hat{\\beta}_{\\mathrm{mode}}$, identifies the causal effect as the mode of the distribution of the individual ratio estimates, weighted by their precision. This is particularly useful when the largest group of variants are valid instruments, even if they do not constitute a majority. The mode is estimated by finding the maximum of a weighted kernel density estimate of the $\\hat{\\beta}_i$ values. For a given bandwidth $h > 0$, the weighted Gaussian-kernel score function $S_h(b)$ is defined as:\n    $$\n    S_h(b) = \\sum_{i=1}^m w_i \\phi_h(b - \\hat{\\beta}_i) = \\sum_{i=1}^m w_i \\exp\\left(-\\frac{(b - \\hat{\\beta}_i)^2}{2 h^2}\\right)\n    $$\n    where the problem simplifies the Gaussian kernel normalization factor. The estimator is the value of $b$ that maximizes this score:\n    $$\n    \\hat{\\beta}_{\\mathrm{mode}}(h) = \\operatorname*{arg\\,max}_{b \\in \\mathbb{R}} S_h(b)\n    $$\n    For numerical computation, this maximization is performed via a grid search. We use the specified bandwidth $h = 0.06$. A uniform grid of $20001$ points is constructed over the interval $[\\min_i \\hat{\\beta}_i - 0.2, \\max_i \\hat{\\beta}_i + 0.2]$. The score $S_h(b)$ is evaluated at each point on this grid, and the value of $b$ that yields the maximum score is taken as the estimate $\\hat{\\beta}_{\\mathrm{mode}}$.\n\nThe program implements these three estimators for each of the test cases provided.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes IVW, Weighted Median, and Weighted Mode estimators for Mendelian Randomization.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"gamma_x\": np.array([0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.053, 0.056, 0.042, -0.044, 0.080, -0.057, 0.038, 0.094, -0.062, 0.026, -0.084, 0.072]),\n            \"se_gamma_y\": np.full(12, 0.02),\n        },\n        # Case B\n        {\n            \"gamma_x\": np.array([0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.052, 0.057, 0.041, -0.043, 0.079, -0.056, 0.057, 0.156, -0.101, 0.042, -0.132, 0.115]),\n            \"se_gamma_y\": np.array([0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03]),\n        },\n        # Case C\n        {\n            \"gamma_x\": np.array([0.02, 0.06, -0.07, 0.09, -0.05, 0.11, -0.10, 0.04, 0.13, -0.08, 0.03, 0.12]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.011, 0.047, -0.034, 0.0655, -0.026, 0.0855, -0.048, 0.029, 0.062, -0.058, 0.016, 0.086]),\n            \"se_gamma_y\": np.full(12, 0.02),\n        }\n    ]\n\n    H_BANDWIDTH = 0.06\n    MODE_GRID_POINTS = 20001\n    \n    all_results = []\n\n    for case in test_cases:\n        gamma_x = case[\"gamma_x\"]\n        gamma_y = case[\"gamma_y\"]\n        se_gamma_y = case[\"se_gamma_y\"]\n\n        # Calculate ratio estimates and weights\n        beta_hat = gamma_y / gamma_x\n        w = (np.abs(gamma_x) / se_gamma_y)**2\n\n        # 1. Inverse-variance weighted (IVW) estimator\n        ivw_est = np.sum(w * beta_hat) / np.sum(w)\n\n        # 2. Weighted median estimator\n        sorted_indices = np.argsort(beta_hat)\n        beta_hat_sorted = beta_hat[sorted_indices]\n        w_sorted = w[sorted_indices]\n        \n        total_weight = np.sum(w)\n        w_cumsum_norm = np.cumsum(w_sorted) / total_weight\n        \n        median_index = np.where(w_cumsum_norm >= 0.5)[0][0]\n        wm_est = beta_hat_sorted[median_index]\n        \n        # 3. Weighted mode estimator\n        b_min = np.min(beta_hat) - 0.2\n        b_max = np.max(beta_hat) + 0.2\n        b_grid = np.linspace(b_min, b_max, num=MODE_GRID_POINTS)\n\n        # Vectorized calculation of scores S_h(b)\n        b_grid_reshaped = b_grid[:, np.newaxis]\n        diff_sq = (b_grid_reshaped - beta_hat)**2\n        h_sq = 2 * H_BANDWIDTH**2\n        scores = np.sum(w * np.exp(-diff_sq / h_sq), axis=1)\n        \n        mode_est = b_grid[np.argmax(scores)]\n\n        all_results.append([ivw_est, wm_est, mode_est])\n\n    # Format the final output string as a list of lists with 4 decimal places\n    output_str_parts = []\n    for res in all_results:\n        inner_list_str = f\"[{res[0]:.4f}, {res[1]:.4f}, {res[2]:.4f}]\"\n        output_str_parts.append(inner_list_str)\n    \n    final_output_str = f\"[{', '.join(output_str_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "2404047"}]}