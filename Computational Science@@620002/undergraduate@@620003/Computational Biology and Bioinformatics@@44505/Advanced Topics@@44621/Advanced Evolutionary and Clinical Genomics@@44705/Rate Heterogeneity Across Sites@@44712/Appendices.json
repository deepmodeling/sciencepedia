{"hands_on_practices": [{"introduction": "The theory of phylogenetic likelihood is powerful, but to truly grasp it, we must see it in action. This first exercise takes you into the engine room of likelihood-based phylogenetics, where you will perform a single, crucial step of Felsenstein's pruning algorithm. By calculating the partial likelihood for a parent node based on its children, you will see how a site-specific rate, $r$, directly scales branch lengths and alters substitution probabilities, a fundamental calculation repeated millions of times by phylogenetic software. [@problem_id:2747174]", "problem": "Consider a single site evolving under the Jukes–Cantor 1969 (JC69) model of nucleotide substitution on a binary phylogeny. Let an internal node $v$ have two children $c_{1}$ and $c_{2}$ connected by edges of equal length $t = 0.2$ (in expected substitutions per site). Assume rate heterogeneity across sites is modeled by a finite mixture of categories with relative rates, and that this site belongs to a category with relative rate $r = 1.5$. For JC69, the transition probabilities along an edge of length $t$ are given by\n$$\nP_{xy}(t) \\;=\\; \\frac{1}{4} \\;+\\; \\left(\\delta_{xy} - \\frac{1}{4}\\right)\\exp\\!\\left(-\\frac{4t}{3}\\right),\n$$\nwhere $\\delta_{xy}$ is the Kronecker delta. For a relative rate $r$, the effective branch length is scaled by $r$, i.e., use $rt$ in place of $t$.\n\nSuppose the partial likelihood vectors at the children, evaluated at this site and category, are\n$$\n\\boldsymbol{L}^{(1)} \\;=\\; \\big(L^{(1)}_{A},L^{(1)}_{C},L^{(1)}_{G},L^{(1)}_{T}\\big) \\;=\\; (0.8,\\,0.1,\\,0.05,\\,0.05),\n$$\n$$\n\\boldsymbol{L}^{(2)} \\;=\\; \\big(L^{(2)}_{A},L^{(2)}_{C},L^{(2)}_{G},L^{(2)}_{T}\\big) \\;=\\; (0.2,\\,0.3,\\,0.4,\\,0.1),\n$$\nin the nucleotide order $(A,C,G,T)$.\n\nUsing the pruning recursion for a continuous-time homogeneous Markov chain on nucleotides,\n$$\nL_{v}(x) \\;=\\; \\prod_{i=1}^{2}\\left(\\sum_{y\\in\\{A,C,G,T\\}} P_{xy}(rt)\\,L^{(i)}_{y}\\right),\n$$\nnumerically compute the parent partial likelihood $L_{v}(A)$. Round your final answer to six significant figures. Express your answer as a pure number without units.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded in the principles of molecular phylogenetics, well-posed, objective, and internally consistent. All necessary data and formulae are provided to compute a unique, meaningful solution. We may therefore proceed with the calculation.\n\nThe objective is to compute the partial likelihood $L_{v}(A)$ for an internal node $v$ given the partial likelihoods at its two children, $c_{1}$ and $c_{2}$. The state at node $v$ is specified as nucleotide $A$.\n\nThe pruning recursion formula provided is:\n$$\nL_{v}(x) \\;=\\; \\prod_{i=1}^{2}\\left(\\sum_{y\\in\\{A,C,G,T\\}} P_{xy}(rt)\\,L^{(i)}_{y}\\right)\n$$\nFor the specific state $x=A$, this becomes:\n$$\nL_{v}(A) \\;=\\; \\left(\\sum_{y\\in\\{A,C,G,T\\}} P_{Ay}(rt)\\,L^{(1)}_{y}\\right) \\times \\left(\\sum_{y\\in\\{A,C,G,T\\}} P_{Ay}(rt)\\,L^{(2)}_{y}\\right)\n$$\nLet us denote the two terms in the product as $S_{1}$ and $S_{2}$:\n$$\nS_{1} \\;=\\; \\sum_{y\\in\\{A,C,G,T\\}} P_{Ay}(rt)\\,L^{(1)}_{y}\n$$\n$$\nS_{2} \\;=\\; \\sum_{y\\in\\{A,C,G,T\\}} P_{Ay}(rt)\\,L^{(2)}_{y}\n$$\nSo, $L_{v}(A) = S_{1} \\times S_{2}$.\n\nFirst, we calculate the effective branch length. The branch length is given as $t = 0.2$ and the site-specific relative rate is $r = 1.5$. The effective branch length is therefore:\n$$\nt_{\\text{eff}} \\;=\\; rt \\;=\\; 1.5 \\times 0.2 \\;=\\; 0.3\n$$\nNext, we determine the transition probabilities under the Jukes-Cantor (JC69) model for this effective branch length. The general formula is:\n$$\nP_{xy}(t_{\\text{eff}}) \\;=\\; \\frac{1}{4} \\;+\\; \\left(\\delta_{xy} - \\frac{1}{4}\\right)\\exp\\!\\left(-\\frac{4t_{\\text{eff}}}{3}\\right)\n$$\nwhere $\\delta_{xy}$ is the Kronecker delta. We are interested in transitions from state $A$ to states $y \\in \\{A,C,G,T\\}$.\n\nThe argument of the exponential function is:\n$$\n-\\frac{4t_{\\text{eff}}}{3} \\;=\\; -\\frac{4 \\times 0.3}{3} \\;=\\; -0.4\n$$\nFor a transition from $A$ to $A$ (a match), $\\delta_{AA} = 1$:\n$$\nP_{AA}(0.3) \\;=\\; \\frac{1}{4} \\;+\\; \\left(1 - \\frac{1}{4}\\right)\\exp(-0.4) \\;=\\; 0.25 \\;+\\; 0.75\\exp(-0.4)\n$$\nFor a transition from $A$ to any other nucleotide $y \\in \\{C,G,T\\}$ (a mismatch), $\\delta_{Ay} = 0$:\n$$\nP_{Ay}(0.3) \\;=\\; \\frac{1}{4} \\;+\\; \\left(0 - \\frac{1}{4}\\right)\\exp(-0.4) \\;=\\; 0.25 \\;-\\; 0.25\\exp(-0.4)\n$$\nLet us denote $P_{A \\to A} = P_{AA}(0.3)$ and $P_{A \\to \\text{mismatch}} = P_{Ay}(0.3)$ for $y \\ne A$.\n\nNow we compute $S_{1}$ and $S_{2}$. The partial likelihood vector for child $c_{1}$ is given as $\\boldsymbol{L}^{(1)} = (0.8,\\,0.1,\\,0.05,\\,0.05)$.\n$$\nS_{1} \\;=\\; P_{AA}(0.3)L^{(1)}_{A} \\;+\\; P_{AC}(0.3)L^{(1)}_{C} \\;+\\; P_{AG}(0.3)L^{(1)}_{G} \\;+\\; P_{AT}(0.3)L^{(1)}_{T}\n$$\n$$\nS_{1} \\;=\\; P_{A \\to A} \\cdot L^{(1)}_{A} \\;+\\; P_{A \\to \\text{mismatch}} \\cdot (L^{(1)}_{C} + L^{(1)}_{G} + L^{(1)}_{T})\n$$\nSubstituting the values:\n$L^{(1)}_{A} = 0.8$, and $L^{(1)}_{C} + L^{(1)}_{G} + L^{(1)}_{T} = 0.1 + 0.05 + 0.05 = 0.2$.\n$$\nS_{1} \\;=\\; \\left(0.25 + 0.75\\exp(-0.4)\\right) \\times 0.8 \\;+\\; \\left(0.25 - 0.25\\exp(-0.4)\\right) \\times 0.2\n$$\n$$\nS_{1} \\;=\\; 0.2 + 0.6\\exp(-0.4) \\;+\\; 0.05 - 0.05\\exp(-0.4)\n$$\n$$\nS_{1} \\;=\\; 0.25 \\;+\\; 0.55\\exp(-0.4)\n$$\nThe partial likelihood vector for child $c_{2}$ is $\\boldsymbol{L}^{(2)} = (0.2,\\,0.3,\\,0.4,\\,0.1)$.\n$$\nS_{2} \\;=\\; P_{A \\to A} \\cdot L^{(2)}_{A} \\;+\\; P_{A \\to \\text{mismatch}} \\cdot (L^{(2)}_{C} + L^{(2)}_{G} + L^{(2)}_{T})\n$$\nSubstituting the values:\n$L^{(2)}_{A} = 0.2$, and $L^{(2)}_{C} + L^{(2)}_{G} + L^{(2)}_{T} = 0.3 + 0.4 + 0.1 = 0.8$.\n$$\nS_{2} \\;=\\; \\left(0.25 + 0.75\\exp(-0.4)\\right) \\times 0.2 \\;+\\; \\left(0.25 - 0.25\\exp(-0.4)\\right) \\times 0.8\n$$\n$$\nS_{2} \\;=\\; 0.05 + 0.15\\exp(-0.4) \\;+\\; 0.2 - 0.2\\exp(-0.4)\n$$\n$$\nS_{2} \\;=\\; 0.25 \\;-\\; 0.05\\exp(-0.4)\n$$\nNow, we compute the final partial likelihood $L_{v}(A) = S_{1} \\times S_{2}$:\n$$\nL_{v}(A) \\;=\\; \\left(0.25 + 0.55\\exp(-0.4)\\right) \\times \\left(0.25 - 0.05\\exp(-0.4)\\right)\n$$\nExpanding this product:\n$$\nL_{v}(A) \\;=\\; 0.25^{2} \\;-\\; 0.25 \\times 0.05\\exp(-0.4) \\;+\\; 0.55\\exp(-0.4) \\times 0.25 \\;-\\; 0.55\\exp(-0.4) \\times 0.05\\exp(-0.4)\n$$\n$$\nL_{v}(A) \\;=\\; 0.0625 \\;+\\; \\left(0.1375 - 0.0125\\right)\\exp(-0.4) \\;-\\; 0.0275\\exp(-0.8)\n$$\n$$\nL_{v}(A) \\;=\\; 0.0625 \\;+\\; 0.125\\exp(-0.4) \\;-\\; 0.0275\\exp(-0.8)\n$$\nWe now substitute the numerical values for the exponential terms.\n$$\n\\exp(-0.4) \\approx 0.6703200458\n$$\n$$\n\\exp(-0.8) \\approx 0.4493289641\n$$\nSubstituting these into the expression for $L_{v}(A)$:\n$$\nL_{v}(A) \\approx 0.0625 \\;+\\; 0.125 \\times 0.6703200458 \\;-\\; 0.0275 \\times 0.4493289641\n$$\n$$\nL_{v}(A) \\approx 0.0625 \\;+\\; 0.0837900057 \\;-\\; 0.0123565465\n$$\n$$\nL_{v}(A) \\approx 0.1462900057 \\;-\\; 0.0123565465\n$$\n$$\nL_{v}(A) \\approx 0.1339334592\n$$\nThe problem requires the answer to be rounded to six significant figures. The first six significant digits are $1, 3, 3, 9, 3, 3$. The seventh digit is $4$, which is less than $5$, so we round down.\n$$\nL_{v}(A) \\approx 0.133933\n$$", "answer": "$$\n\\boxed{0.133933}\n$$", "id": "2747174"}, {"introduction": "After mastering the mechanics of likelihood calculation for a single site, the next step is to evaluate models for an entire alignment. In science, more complex models are not always better; they risk overfitting the data. This exercise places you in the role of a data analyst choosing the most appropriate nucleotide substitution model from a set of candidates with varying complexity. Using the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC), you will practice balancing model fit (the log-likelihood) against model complexity (the number of parameters), a central task in statistical bioinformatics. [@problem_id:2424572]", "problem": "You are given a fixed unrooted phylogenetic tree topology and branch lengths for a DNA alignment, and five nested time-reversible nucleotide substitution models: Jukes–Cantor (JC), Hasegawa–Kishino–Yano (HKY), HKY with gamma-distributed site-rate heterogeneity (HKY+$\\Gamma$), General Time Reversible (GTR), and GTR with gamma-distributed site-rate heterogeneity and a proportion of invariant sites (GTR+$\\Gamma$+I). The data alphabet has size $4$ (A, C, G, T). The number of discrete categories used to approximate the gamma distribution is held fixed in advance. Only substitution-process parameters are to be counted toward model complexity; the tree topology, branch lengths, and the fixed number of gamma rate categories are not counted.\n\nModel definitions for parameter counting:\n- JC: all base frequencies equal and all exchangeabilities equal.\n- HKY: distinct transition/transversion rate ratio and free stationary base frequencies.\n- GTR: fully general time-reversible exchangeabilities and free stationary base frequencies.\n- $\\Gamma$: continuous site-rate heterogeneity modeled by a gamma distribution with a free shape parameter $\\alpha$.\n- I: a free proportion of invariant sites $p_I$.\n\nUse the following coding of models:\n- $0$: JC\n- $1$: HKY\n- $2$: HKY+$\\Gamma$\n- $3$: GTR\n- $4$: GTR+$\\Gamma$+I\n\nFor each dataset below, you are given the alignment length $n$ (the number of sites) and the maximized natural logarithm of the likelihood, $\\ln \\mathcal{L}$, obtained under each of the five models on the same fixed tree (in the model code order $0,1,2,3,4$). You must decide, for each dataset, which model minimizes the Akaike Information Criterion (AIC) and which model minimizes the Bayesian Information Criterion (BIC), based on first principles. In the event of an exact tie in a criterion value, choose the model with the smaller number of free substitution-process parameters $k$; if $k$ is also equal, choose the smaller model code.\n\nTest suite (alignment length $n$ and log-likelihood vector $(\\ln \\mathcal{L}_0,\\ln \\mathcal{L}_1,\\ln \\mathcal{L}_2,\\ln \\mathcal{L}_3,\\ln \\mathcal{L}_4)$ for models $0$ through $4$):\n- Dataset $1$: $n = 500$, $( -1650.0,\\ -1585.0,\\ -1568.0,\\ -1565.0,\\ -1560.5 )$.\n- Dataset $2$: $n = 50$, $( -540.0,\\ -505.0,\\ -500.0,\\ -499.2,\\ -493.0 )$.\n- Dataset $3$: $n = 200$, $( -700.0,\\ -650.0,\\ -650.0,\\ -649.5,\\ -649.5 )$.\n- Dataset $4$: $n = 10$, $( -120.0,\\ -120.0,\\ -120.0,\\ -120.0,\\ -120.0 )$.\n\nYour program must:\n- Infer the number of free substitution-process parameters $k$ for each model from first principles given a $4$-state alphabet, accounting for the stationary base-frequency constraint that probabilities sum to $1$ and the overall rate-scale identifiability constraint in time-reversible models. Count $1$ parameter for the gamma shape $\\alpha$ when $\\Gamma$ is present, and $1$ parameter for the invariant-site proportion $p_I$ when I is present.\n- For each dataset, compute the model code that minimizes AIC and the model code that minimizes BIC.\n- Apply the specified tie-breaking rule.\n\nFinal output format:\nYour program should produce a single line of output containing $8$ integers in a single list, corresponding to the results for Datasets $1$ through $4$ in order, and for each dataset reporting first the AIC-minimizing model code and then the BIC-minimizing model code. The line must be a comma-separated list enclosed in square brackets with no spaces, for example, $[a_1,b_1,a_2,b_2,a_3,b_3,a_4,b_4]$, where $a_i$ is the AIC-minimizing model code and $b_i$ is the BIC-minimizing model code for dataset $i$.", "solution": "We work from first principles. For time-reversible nucleotide substitution models on a $4$-state alphabet, free parameters arise from three sources: exchangeability parameters of the reversible rate matrix, stationary base frequencies, and any site-rate heterogeneity parameters such as the gamma shape parameter $\\alpha$ or the invariant-site proportion $p_I$.\n\nStationary base frequencies: there are $4$ frequencies that sum to $1$, yielding $4-1=3$ free parameters when base frequencies are free. In JC, base frequencies are constrained equal, contributing $0$ free parameters.\n\nExchangeabilities: for a fully general time-reversible rate matrix (GTR) on $4$ states, there are $\\binom{4}{2}=6$ exchangeability rates but one overall rate-scale factor is not identifiable (it can be absorbed into branch lengths), leaving $6-1=5$ free exchangeability parameters. In HKY, there are two exchangeability classes (transitions versus transversions), but the same identifiability constraint removes the overall scale, leaving $2-1=1$ free exchangeability parameter (the transition/transversion rate ratio). In JC, all exchangeabilities are constrained equal, contributing $0$ free parameters.\n\nGamma site-rate heterogeneity: the continuous gamma distribution used for across-site rate heterogeneity contributes one free shape parameter $\\alpha$ when present. The number of discrete categories used to approximate the gamma distribution is fixed and does not change model complexity. Invariant sites: the proportion $p_I$ is a single free parameter when present.\n\nThus, the number of free substitution-process parameters $k$ for each model is:\n- JC: $k = 0 \\ (\\text{no free base frequencies, no free exchangeabilities, no heterogeneity parameters})$.\n- HKY: $k = 1 \\ (\\text{exchangeability}) + 3 \\ (\\text{base frequencies}) = 4$.\n- HKY+$\\Gamma$: $k = 4 + 1 \\ (\\alpha) = 5$.\n- GTR: $k = 5 \\ (\\text{exchangeabilities}) + 3 \\ (\\text{base frequencies}) = 8$.\n- GTR+$\\Gamma$+I: $k = 8 + 1 \\ (\\alpha) + 1 \\ (p_I) = 10$.\n\nInformation criteria definitions in terms of the maximized natural log-likelihood $\\ln \\mathcal{L}$ and free-parameter count $k$ are:\n- Akaike Information Criterion: $\\mathrm{AIC} = 2k - 2 \\ln \\mathcal{L}$.\n- Bayesian Information Criterion: $\\mathrm{BIC} = k \\ln n - 2 \\ln \\mathcal{L}$, where $n$ is the number of independent observations (here, sites).\n\nFor each dataset, we compute $\\mathrm{AIC}$ and $\\mathrm{BIC}$ for all five models using the provided $\\ln \\mathcal{L}$ values and $n$ and select the model with the smallest criterion value, breaking ties by smaller $k$, and then by smaller model code.\n\nCompute results:\n\nDataset $1$: $n=500$, $\\ln n \\approx 6.2146081$.\n- JC: $k=0$, $-2\\ln \\mathcal{L} = 3300.0$; $\\mathrm{AIC}=3300.0$, $\\mathrm{BIC}=3300.0$.\n- HKY: $k=4$, $-2\\ln \\mathcal{L} = 3170.0$; $\\mathrm{AIC}=3178.0$, $\\mathrm{BIC}\\approx 3170.0 + 4 \\times 6.2146081 \\approx 3194.858$.\n- HKY+$\\Gamma$: $k=5$, $-2\\ln \\mathcal{L} = 3136.0$; $\\mathrm{AIC}=3146.0$, $\\mathrm{BIC}\\approx 3167.073$.\n- GTR: $k=8$, $-2\\ln \\mathcal{L} = 3130.0$; $\\mathrm{AIC}=3146.0$, $\\mathrm{BIC}\\approx 3179.717$.\n- GTR+$\\Gamma$+I: $k=10$, $-2\\ln \\mathcal{L} = 3121.0$; $\\mathrm{AIC}=3141.0$, $\\mathrm{BIC}\\approx 3183.146$.\nMinimum $\\mathrm{AIC}$ is GTR+$\\Gamma$+I (code $4$). Minimum $\\mathrm{BIC}$ is HKY+$\\Gamma$ (code $2$).\n\nDataset $2$: $n=50$, $\\ln n \\approx 3.9120230$.\n- JC: $k=0$, $-2\\ln \\mathcal{L} = 1080.0$; $\\mathrm{AIC}=1080.0$, $\\mathrm{BIC}=1080.0$.\n- HKY: $k=4$, $-2\\ln \\mathcal{L} = 1010.0$; $\\mathrm{AIC}=1018.0$, $\\mathrm{BIC}\\approx 1025.648$.\n- HKY+$\\Gamma$: $k=5$, $-2\\ln \\mathcal{L} = 1000.0$; $\\mathrm{AIC}=1010.0$, $\\mathrm{BIC}\\approx 1019.560$.\n- GTR: $k=8$, $-2\\ln \\mathcal{L} = 998.4$; $\\mathrm{AIC}=1014.4$, $\\mathrm{BIC}\\approx 1029.696$.\n- GTR+$\\Gamma$+I: $k=10$, $-2\\ln \\mathcal{L} = 986.0$; $\\mathrm{AIC}=1006.0$, $\\mathrm{BIC}\\approx 1025.120$.\nMinimum $\\mathrm{AIC}$ is GTR+$\\Gamma$+I (code $4$). Minimum $\\mathrm{BIC}$ is HKY+$\\Gamma$ (code $2$).\n\nDataset $3$: $n=200$, $\\ln n \\approx 5.2983174$.\n- JC: $k=0$, $-2\\ln \\mathcal{L} = 1400.0$; $\\mathrm{AIC}=1400.0$, $\\mathrm{BIC}=1400.0$.\n- HKY: $k=4$, $-2\\ln \\mathcal{L} = 1300.0$; $\\mathrm{AIC}=1308.0$, $\\mathrm{BIC}\\approx 1321.192$.\n- HKY+$\\Gamma$: $k=5$, $-2\\ln \\mathcal{L} = 1300.0$; $\\mathrm{AIC}=1310.0$, $\\mathrm{BIC}\\approx 1326.492$.\n- GTR: $k=8$, $-2\\ln \\mathcal{L} = 1299.0$; $\\mathrm{AIC}=1315.0$, $\\mathrm{BIC}\\approx 1341.386$.\n- GTR+$\\Gamma$+I: $k=10$, $-2\\ln \\mathcal{L} = 1299.0$; $\\mathrm{AIC}=1319.0$, $\\mathrm{BIC}\\approx 1351.983$.\nMinimum $\\mathrm{AIC}$ and $\\mathrm{BIC}$ are both HKY (code $1$).\n\nDataset $4$: $n=10$, $\\ln n \\approx 2.3025851$; all $\\ln \\mathcal{L} = -120.0$, so $-2 \\ln \\mathcal{L} = 240.0$ for all models.\n- JC: $k=0$; $\\mathrm{AIC}=240.0$, $\\mathrm{BIC}=240.0$.\n- HKY: $k=4$; $\\mathrm{AIC}=248.0$, $\\mathrm{BIC}\\approx 249.210$.\n- HKY+$\\Gamma$: $k=5$; $\\mathrm{AIC}=250.0$, $\\mathrm{BIC}\\approx 251.513$.\n- GTR: $k=8$; $\\mathrm{AIC}=256.0$, $\\mathrm{BIC}\\approx 258.421$.\n- GTR+$\\Gamma$+I: $k=10$; $\\mathrm{AIC}=260.0$, $\\mathrm{BIC}\\approx 263.026$.\nMinimum $\\mathrm{AIC}$ and $\\mathrm{BIC}$ are both JC (code $0$).\n\nTherefore, the required output is the flat list of $8$ integers:\n$[4,2,4,2,1,1,0,0]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef count_free_parameters(model_code: int) -> int:\n    \"\"\"\n    Compute the number of free substitution-process parameters k for a 4-state\n    time-reversible nucleotide model, excluding topology/branch lengths and\n    the fixed number of gamma categories.\n\n    Model codes:\n      0: JC\n      1: HKY\n      2: HKY+Gamma\n      3: GTR\n      4: GTR+Gamma+I\n    \"\"\"\n    # Base frequency degrees of freedom: 3 when free, 0 for JC (equal)\n    if model_code == 0:\n        basefreq_df = 0  # JC has equal base frequencies\n        exch_df = 0      # JC has all exchangeabilities equal\n        gamma_shape = 0\n        pinv = 0\n    elif model_code == 1:\n        basefreq_df = 3  # HKY: free base frequencies\n        exch_df = 1      # HKY: transitions vs transversions, minus overall scale\n        gamma_shape = 0\n        pinv = 0\n    elif model_code == 2:\n        basefreq_df = 3\n        exch_df = 1\n        gamma_shape = 1  # Gamma shape alpha\n        pinv = 0\n    elif model_code == 3:\n        basefreq_df = 3\n        exch_df = 5      # GTR: 6 exchangeabilities minus one overall scale\n        gamma_shape = 0\n        pinv = 0\n    elif model_code == 4:\n        basefreq_df = 3\n        exch_df = 5\n        gamma_shape = 1\n        pinv = 1         # Proportion invariant sites\n    else:\n        raise ValueError(\"Unknown model code\")\n    return basefreq_df + exch_df + gamma_shape + pinv\n\ndef aic(k: int, logL: float) -> float:\n    return 2.0 * k - 2.0 * logL\n\ndef bic(k: int, logL: float, n: int) -> float:\n    return k * float(np.log(n)) - 2.0 * logL\n\ndef select_min(values, ks, tol=0.0):\n    \"\"\"\n    Select the index of the minimal value with tie-breaking:\n    1) smaller k (model complexity), 2) smaller index.\n    tol allows treating near-equalities as ties; default exact.\n    \"\"\"\n    best_idx = None\n    best_val = None\n    best_k = None\n    for idx, (v, k) in enumerate(zip(values, ks)):\n        if best_idx is None:\n            best_idx = idx\n            best_val = v\n            best_k = k\n            continue\n        if v < best_val - tol:\n            best_idx = idx\n            best_val = v\n            best_k = k\n        elif abs(v - best_val) <= tol:\n            if k < best_k:\n                best_idx = idx\n                best_val = v\n                best_k = k\n            elif k == best_k and idx < best_idx:\n                best_idx = idx\n                best_val = v\n                best_k = k\n    return best_idx\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each entry: (n, [logL_model0, logL_model1, logL_model2, logL_model3, logL_model4])\n    test_cases = [\n        (500, [-1650.0, -1585.0, -1568.0, -1565.0, -1560.5]),\n        (50,  [-540.0,  -505.0,  -500.0,  -499.2,  -493.0]),\n        (200, [-700.0,  -650.0,  -650.0,  -649.5,  -649.5]),\n        (10,  [-120.0,  -120.0,  -120.0,  -120.0,  -120.0]),\n    ]\n\n    model_codes = [0, 1, 2, 3, 4]\n    ks = [count_free_parameters(m) for m in model_codes]\n\n    results = []\n    for n, logLs in test_cases:\n        aics = [aic(ks[i], logLs[i]) for i in range(5)]\n        bics = [bic(ks[i], logLs[i], n) for i in range(5)]\n        best_aic_model = select_min(aics, ks, tol=0.0)\n        best_bic_model = select_min(bics, ks, tol=0.0)\n        results.append(best_aic_model)\n        results.append(best_bic_model)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2424572"}, {"introduction": "The previous exercises focused on inferring parameters from data. We conclude our hands-on section by reversing the process: creating data from a model. Simulating evolution is a powerful tool for building intuition and testing the behavior of our methods. In this challenge, you will implement an algorithm to simulate DNA sequences evolving on a tree, incorporating site-specific rates drawn from a Gamma distribution. This not only solidifies your understanding of how rate heterogeneity manifests in sequence data but also gives you a chance to validate that the simulated data reflects the theoretical properties of the model you designed. [@problem_id:2747214]", "problem": "You are to implement a complete and reproducible algorithm that simulates DNA sequence evolution under a fixed rooted tree using the Jukes–Cantor $1969$ (JC$69$) model with across-site gamma-distributed rate heterogeneity having mean-one rates (denoted JC$69$+$\\Gamma$), and then validate the realized distribution of site rates. The implementation must follow a continuous-time Markov chain construction.\n\nBegin from the following foundations:\n- A continuous-time Markov chain on a finite state space with instantaneous rate matrix $Q$ evolves along a branch of length $t$ via the transition probability matrix $P(t) = \\exp(Qt)$, where $\\exp$ denotes the matrix exponential.\n- The JC$69$ model has equal stationary base frequencies $\\pi_i = 1/4$ for $i \\in \\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$ and an instantaneous rate matrix $Q$ satisfying $Q_{ij} = \\mu$ for $i \\neq j$ and $Q_{ii} = -3\\mu$, scaled so that the average substitution rate is $1$, i.e., $\\sum_i \\pi_i (-Q_{ii}) = 1$, which implies $\\mu = 1/3$.\n- Under JC$69$, the transition probabilities along time $t$ admit a closed form: for $i=j$, $P_{ii}(t) = 1/4 + 3/4 \\exp(-4t/3)$, and for $i \\neq j$, $P_{ij}(t) = 1/4 - 1/4 \\exp(-4t/3)$.\n- For across-site gamma-distributed rate heterogeneity, the site-specific rate $r$ is drawn from a Gamma distribution with shape parameter $\\alpha$ and scale parameter $\\theta$ so that the mean is one, i.e., $\\mathbb{E}[r] = \\alpha \\theta = 1$. Set $\\theta = 1/\\alpha$ so that $\\operatorname{Var}(r) = \\alpha \\theta^2 = 1/\\alpha$.\n\nAlgorithmic specification:\n- Let the state space be $\\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$ encoded as $\\{0,1,2,3\\}$.\n- For each site $s \\in \\{1,\\dots,S\\}$, draw a rate $r_s \\sim \\text{Gamma}(\\alpha, \\theta)$ with $\\theta = 1/\\alpha$.\n- For each site independently, assign the root state by sampling from the stationary distribution $(1/4,1/4,1/4,1/4)$.\n- For each directed edge $(u \\to v)$ with branch length $t_{uv}$ and a given site rate $r_s$, propagate the state from the parent $u$ to the child $v$ by sampling from the row of the JC$69$ transition matrix computed at effective time $r_s t_{uv}$, i.e., $P(r_s t_{uv})$.\n- For any branch with length $t=0$, enforce that $P(0)$ equals the identity matrix, so that the child must inherit the parent state with probability $1$.\n\nTree and parameters:\n- Use the rooted tree with node set $\\{0,1,2,3,4\\}$, root at node $0$, and directed edges $(0 \\to 1)$ with length $t_{01} = 0.1$, $(1 \\to 2)$ with length $t_{12} = 0.3$, $(1 \\to 3)$ with length $t_{13} = 0.3$, and $(0 \\to 4)$ with length $t_{04} = 0.2$. Leaves are nodes $\\{2,3,4\\}$. All branch lengths are measured in expected substitutions per site under mean rate $1$.\n- Use a fixed pseudorandom number generator seed $20231105$ for all stochastic draws to ensure reproducibility.\n\nValidation of realized rate distribution:\n- Given $S$ drawn rates $\\{r_s\\}_{s=1}^S$, compute the sample mean $\\bar r = \\frac{1}{S}\\sum_{s=1}^S r_s$ and the unbiased sample variance $s^2 = \\frac{1}{S-1}\\sum_{s=1}^S (r_s - \\bar r)^2$.\n- For a given $\\alpha$, compare $\\bar r$ to the theoretical mean $1$ and $s^2$ to the theoretical variance $1/\\alpha$, using absolute-error tolerances $\\varepsilon_{\\text{mean}}$ and $\\varepsilon_{\\text{var}}$.\n- Additionally, validate the JC$69$ transition matrix construction by checking that for arbitrary positive rates $r$ and times $t$, each row of $P(rt)$ sums to $1$ within a small tolerance, and that $P(0)$ is the identity matrix within a small tolerance.\n\nYour program must implement the above algorithm and produce a single-line output aggregating the results of the following test suite as a comma-separated list enclosed in square brackets:\n\n- Test $1$ (rate validation, high heterogeneity): $\\alpha = 0.5$, $S = 200000$, $\\varepsilon_{\\text{mean}} = 0.01$, $\\varepsilon_{\\text{var}} = 0.05$. Output a boolean indicating whether both $|\\bar r - 1| \\le 0.01$ and $|s^2 - 2.0| \\le 0.05$ hold.\n- Test $2$ (rate validation, low heterogeneity): $\\alpha = 5.0$, $S = 200000$, $\\varepsilon_{\\text{mean}} = 0.005$, $\\varepsilon_{\\text{var}} = 0.01$. Output a boolean indicating whether both $|\\bar r - 1| \\le 0.005$ and $|s^2 - 0.2| \\le 0.01$ hold.\n- Test $3$ (transition matrix stochasticity): For $N = 25$ independently drawn pairs $(r,t)$ with $r$ uniform on $[0,3]$ and $t$ uniform on $[0,2]$, compute $P(rt)$ and check that the maximum absolute deviation of row sums from $1$ is at most $\\varepsilon_{\\text{row}} = 10^{-12}$. Output a boolean indicating whether this holds across all $N$ draws.\n- Test $4$ (zero-branch identity): For $N = 25$ independently drawn rates $r$ uniform on $[0,3]$, check that $P(0)$ equals the identity matrix with maximum absolute entrywise deviation at most $\\varepsilon_{\\text{id}} = 10^{-12}$. Output a boolean indicating whether this holds across all $N$ draws.\n\nFinal output format:\n- Your program should produce a single line of output containing the four boolean results for the test cases in order, as a comma-separated list enclosed in square brackets (e.g., [True,False,True,True], using standard Python boolean string representation). No other output should be produced.", "solution": "We design the algorithm and validation from first principles of continuous-time Markov chains and the properties of the Jukes–Cantor $1969$ (JC$69$) model and the Gamma distribution.\n\n1. JC$69$ rate matrix scaling and transition probabilities:\n   - In JC$69$, the instantaneous rate matrix $Q$ has off-diagonal entries $Q_{ij} = \\mu$ for $i \\neq j$ and diagonal entries $Q_{ii} = -3\\mu$. The stationary distribution is uniform $\\pi = (1/4,1/4,1/4,1/4)$.\n   - The average substitution rate under stationarity is $\\sum_{i=1}^4 \\pi_i (-Q_{ii}) = \\sum_{i=1}^4 (1/4) \\cdot 3\\mu = 3\\mu$. To enforce a mean rate of $1$ substitution per unit time, we set $3\\mu = 1$, hence $\\mu = 1/3$.\n   - The transition probability matrix $P(t) = \\exp(Qt)$ admits a closed form for JC$69$:\n     - For $i=j$, $P_{ii}(t) = 1/4 + 3/4 \\exp(-4t/3)$.\n     - For $i \\neq j$, $P_{ij}(t) = 1/4 - 1/4 \\exp(-4t/3)$.\n     This follows from the spectral decomposition of $Q$, where there is one eigenvalue $0$ with eigenvector $\\mathbf{1}$ and three identical eigenvalues $-4/3$ on the orthogonal subspace, yielding the stated expressions.\n\n2. Across-site rate heterogeneity via a Gamma distribution:\n   - Let $r$ denote the site-specific relative rate. To model heterogeneity, we draw $r \\sim \\text{Gamma}(\\alpha, \\theta)$, with shape $\\alpha$ and scale $\\theta$.\n   - We choose $\\theta = 1/\\alpha$ so that $\\mathbb{E}[r] = \\alpha \\theta = \\alpha \\cdot (1/\\alpha) = 1$, i.e., the mean rate is one.\n   - The variance is $\\operatorname{Var}(r) = \\alpha \\theta^2 = \\alpha \\cdot (1/\\alpha^2) = 1/\\alpha$, which is the key theoretical target for validation.\n\n3. Site-wise continuous-time Markov chain evolution along a tree:\n   - For each site $s \\in \\{1,\\dots,S\\}$:\n     - Draw $r_s \\sim \\text{Gamma}(\\alpha, 1/\\alpha)$.\n     - Draw the root state from $\\pi = (1/4,1/4,1/4,1/4)$.\n     - For each branch $(u \\to v)$ of length $t_{uv}$, compute the effective time $\\tau_{uv,s} = r_s t_{uv}$ and form the JC$69$ transition matrix $P(\\tau_{uv,s})$ using the closed form above. Then sample the child state at $v$ from the categorical distribution given by the row of $P(\\tau_{uv,s})$ indexed by the parent’s state.\n   - This procedure is consistent with the time-change property of continuous-time Markov chains: scaling time by $r_s$ along each branch is equivalent to scaling the generator by $r_s$, which is exactly the effect of using site-specific rates.\n\n4. Validation of the realized rate distribution:\n   - Given the drawn rates $\\{r_s\\}$, compute the sample mean $\\bar r = \\frac{1}{S}\\sum_{s=1}^{S} r_s$ and unbiased sample variance $s^2 = \\frac{1}{S-1}\\sum_{s=1}^{S} (r_s - \\bar r)^2$.\n   - For a specified $\\alpha$, compare $\\bar r$ with the theoretical mean $1$ and $s^2$ with the theoretical variance $1/\\alpha$. We specify absolute-error tolerances $\\varepsilon_{\\text{mean}}$ and $\\varepsilon_{\\text{var}}$ and require $|\\bar r - 1| \\le \\varepsilon_{\\text{mean}}$ and $|s^2 - 1/\\alpha| \\le \\varepsilon_{\\text{var}}$ to pass.\n   - Additional algorithmic validations reinforce correctness:\n     - Stochasticity: For arbitrary $r \\ge 0$ and $t \\ge 0$, the computed $P(rt)$ must have rows that sum to $1$. Because the closed-form construction enforces $P_{ii} = 1/4 + 3/4 e^{-4rt/3}$ and $P_{ij} = 1/4 - 1/4 e^{-4rt/3}$ for $i \\neq j$, each row sum is $(1/4 + 3/4 e) + 3(1/4 - 1/4 e) = 1$ exactly in exact arithmetic. In floating-point arithmetic, we require deviations not exceeding a small tolerance $\\varepsilon_{\\text{row}}$.\n     - Identity at zero branch length: For any rate $r$, $P(r \\cdot 0) = P(0)$ must equal the identity matrix, i.e., $\\exp(Q \\cdot 0) = I$. From the closed form, substituting $t=0$ gives $e^{-4 \\cdot 0/3} = 1$, hence $P_{ii}(0) = 1/4 + 3/4 \\cdot 1 = 1$ and $P_{ij}(0) = 1/4 - 1/4 \\cdot 1 = 0$ for $i \\neq j$. We check this within a tolerance $\\varepsilon_{\\text{id}}$.\n\n5. Test suite design and outputs:\n   - Test $1$: $\\alpha = 0.5$, $S = 200000$, $\\varepsilon_{\\text{mean}} = 0.01$, $\\varepsilon_{\\text{var}} = 0.05$. Theoretical variance is $1/\\alpha = 2.0$. Output a boolean pass/fail.\n   - Test $2$: $\\alpha = 5.0$, $S = 200000$, $\\varepsilon_{\\text{mean}} = 0.005$, $\\varepsilon_{\\text{var}} = 0.01$. Theoretical variance is $1/\\alpha = 0.2$. Output a boolean pass/fail.\n   - Test $3$: Draw $N = 25$ pairs $(r,t)$ with $r \\sim \\text{Uniform}[0,3]$ and $t \\sim \\text{Uniform}[0,2]$. For each, compute $P(rt)$ and check the maximum absolute deviation of row sums from $1$ is at most $\\varepsilon_{\\text{row}} = 10^{-12}$. Output a boolean indicating whether all draws pass.\n   - Test $4$: Draw $N = 25$ rates $r \\sim \\text{Uniform}[0,3]$ and verify that $P(0)$ equals identity within $\\varepsilon_{\\text{id}} = 10^{-12}$. Output a boolean indicating whether all draws pass.\n\nImplementation notes:\n- Use a fixed pseudorandom seed $20231105$ to make the results deterministic.\n- Use the given rooted tree with branch lengths for sequence simulation routines; while the distribution validation does not require simulating sequences, the sequence simulation functions must be implemented as described to reflect the algorithm.\n- The final program must print a single line with the four boolean results enclosed in square brackets and separated by commas, with no additional text.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Fixed RNG for reproducibility as mandated by the problem statement.\nRNG = np.random.default_rng(20231105)\n\n# State mapping: 0,1,2,3 correspond to A,C,G,T (any consistent mapping suffices for JC69).\nNUM_STATES = 4\n\ndef draw_gamma_rates(n_sites: int, alpha: float, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Draw n_sites rates from Gamma(shape=alpha, scale=1/alpha) so that E[r]=1 and Var[r]=1/alpha.\n    \"\"\"\n    scale = 1.0 / alpha\n    return rng.gamma(shape=alpha, scale=scale, size=n_sites)\n\ndef jc69_transition_matrix(effective_time: float) -> np.ndarray:\n    \"\"\"\n    Construct the JC69 transition matrix P(t) at time 'effective_time' = r * t.\n    JC69 scaling uses mu=1/3 so that average rate is 1, giving exponent -4 t / 3.\n    \"\"\"\n    e = np.exp(-4.0 * effective_time / 3.0)\n    P = np.full((NUM_STATES, NUM_STATES), 0.25 - 0.25 * e, dtype=float)\n    # Set diagonal entries\n    diag_val = 0.25 + 0.75 * e\n    for i in range(NUM_STATES):\n        P[i, i] = diag_val\n    return P\n\ndef simulate_sequences_on_tree(n_sites: int,\n                               alpha: float,\n                               edges: list[tuple[int, int, float]],\n                               root: int,\n                               rng: np.random.Generator) -> dict[int, np.ndarray]:\n    \"\"\"\n    Simulate sequences under JC69+Gamma on a rooted directed tree.\n    edges: list of (parent, child, branch_length) with branch lengths in expected substitutions/site.\n    Returns a dictionary mapping node -> sequence array of length n_sites with states in {0,1,2,3}.\n    \"\"\"\n    # Prepare adjacency and topological order from root.\n    children = {}\n    parents = {}\n    nodes = set([root])\n    for u, v, t in edges:\n        children.setdefault(u, []).append((v, t))\n        parents[v] = u\n        nodes.add(u); nodes.add(v)\n    # Derive a topological order (BFS from root suffices as edges are directed away from root).\n    topo_order = []\n    queue = [root]\n    visited = set()\n    while queue:\n        u = queue.pop(0)\n        if u in visited:\n            continue\n        visited.add(u)\n        topo_order.append(u)\n        for (v, _) in children.get(u, []):\n            queue.append(v)\n\n    # Draw site-specific rates.\n    rates = draw_gamma_rates(n_sites, alpha, rng)\n\n    # Initialize sequences per node.\n    seqs = {node: np.empty(n_sites, dtype=np.int8) for node in nodes}\n\n    # Root states sampled from stationary distribution (uniform over 4 states).\n    seqs[root] = rng.integers(low=0, high=NUM_STATES, size=n_sites, endpoint=False, dtype=np.int8)\n\n    # Propagate down the tree per site.\n    for u in topo_order:\n        for (v, t) in children.get(u, []):\n            parent_states = seqs[u]\n            child_states = np.empty(n_sites, dtype=np.int8)\n            if t == 0.0:\n                # Identity transition: child copies parent.\n                child_states[:] = parent_states\n            else:\n                # For each site, compute P(r*t) and sample child state conditional on parent state.\n                # To keep memory low, process in chunks.\n                chunk = 4096\n                for start in range(0, n_sites, chunk):\n                    end = min(start + chunk, n_sites)\n                    parent_chunk = parent_states[start:end]\n                    rates_chunk = rates[start:end]\n                    # For each site in chunk, compute P and sample.\n                    for idx in range(end - start):\n                        tau = rates_chunk[idx] * t\n                        P = jc69_transition_matrix(tau)\n                        p_row = P[parent_chunk[idx], :]\n                        # Sample according to probabilities in p_row.\n                        # Use choice with p; ensure numerical stability by normalizing.\n                        p_row = p_row / p_row.sum()\n                        child_states[start + idx] = rng.choice(NUM_STATES, p=p_row)\n            seqs[v] = child_states\n    return seqs\n\ndef sample_mean_and_unbiased_variance(x: np.ndarray) -> tuple[float, float]:\n    \"\"\"\n    Return sample mean and unbiased sample variance (denominator n-1).\n    \"\"\"\n    mean = float(np.mean(x))\n    # Unbiased sample variance\n    var = float(np.var(x, ddof=1))\n    return mean, var\n\ndef test_rate_validation(alpha: float, n_sites: int, tol_mean: float, tol_var: float, rng: np.random.Generator) -> bool:\n    \"\"\"\n    Draw rates and validate that sample mean and sample variance match 1 and 1/alpha within tolerances.\n    \"\"\"\n    rates = draw_gamma_rates(n_sites, alpha, rng)\n    mean, var = sample_mean_and_unbiased_variance(rates)\n    target_mean = 1.0\n    target_var = 1.0 / alpha\n    return (abs(mean - target_mean) <= tol_mean) and (abs(var - target_var) <= tol_var)\n\ndef test_stochasticity_row_sums(n_trials: int, tol_row: float, rng: np.random.Generator) -> bool:\n    \"\"\"\n    Randomly draw rates and times, compute P(r*t), and check row sums within tolerance.\n    \"\"\"\n    max_dev = 0.0\n    for _ in range(n_trials):\n        r = rng.uniform(0.0, 3.0)\n        t = rng.uniform(0.0, 2.0)\n        P = jc69_transition_matrix(r * t)\n        row_sums = P.sum(axis=1)\n        dev = float(np.max(np.abs(row_sums - 1.0)))\n        if dev > max_dev:\n            max_dev = dev\n        if dev > tol_row:\n            return False\n    return True\n\ndef test_identity_zero_branch(n_trials: int, tol_id: float, rng: np.random.Generator) -> bool:\n    \"\"\"\n    For random rates, check that P(0) equals identity within tolerance.\n    \"\"\"\n    I = np.eye(NUM_STATES)\n    for _ in range(n_trials):\n        _ = rng.uniform(0.0, 3.0)  # rate r (unused because t=0 forces tau=0)\n        P0 = jc69_transition_matrix(0.0)\n        if np.max(np.abs(P0 - I)) > tol_id:\n            return False\n    return True\n\ndef solve():\n    results = []\n\n    # Test 1: alpha=0.5, n_sites=200000, tol_mean=0.01, tol_var=0.05\n    res1 = test_rate_validation(alpha=0.5, n_sites=200000, tol_mean=0.01, tol_var=0.05, rng=RNG)\n    results.append(res1)\n\n    # Test 2: alpha=5.0, n_sites=200000, tol_mean=0.005, tol_var=0.01\n    res2 = test_rate_validation(alpha=5.0, n_sites=200000, tol_mean=0.005, tol_var=0.01, rng=RNG)\n    results.append(res2)\n\n    # Test 3: stochasticity of transition matrices, N=25, tol_row=1e-12\n    res3 = test_stochasticity_row_sums(n_trials=25, tol_row=1e-12, rng=RNG)\n    results.append(res3)\n\n    # Test 4: identity at zero branch length, N=25, tol_id=1e-12\n    res4 = test_identity_zero_branch(n_trials=25, tol_id=1e-12, rng=RNG)\n    results.append(res4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Implement the tree structure and simulation functions as required by the problem statement.\n# Although not directly used in the tests above (which focus on rate validation and matrix checks),\n# the following demonstrates the sequence simulation algorithm on the specified rooted tree.\ndef _demo_sequence_simulation():\n    # Rooted tree as specified: nodes {0,1,2,3,4}, root=0, edges with lengths.\n    root = 0\n    edges = [\n        (0, 1, 0.1),\n        (1, 2, 0.3),\n        (1, 3, 0.3),\n        (0, 4, 0.2),\n    ]\n    # Simulate a small alignment to verify procedure (not printed).\n    _ = simulate_sequences_on_tree(n_sites=10, alpha=0.5, edges=edges, root=root, rng=RNG)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2747214"}]}