{"hands_on_practices": [{"introduction": "Gene regulatory networks are built from fundamental recurring patterns called network motifs. One of the simplest and most widespread motifs is negative autoregulation, where a protein inhibits its own production, creating a feedback loop that stabilizes its concentration. This practice [@problem_id:1435734] provides a quantitative look at this homeostatic mechanism by guiding you through the process of deriving the stable, steady-state concentration of a self-repressing protein using a Hill function model.", "problem": "A synthetic biologist is engineering a simple genetic circuit in a bacterial host. This circuit is designed to implement negative autoregulation, where a protein, which we will call the Repressor (R), inhibits the expression of its own gene. The concentration of the Repressor protein at time $t$ is denoted by $R(t)$. The dynamics of this system are modeled by the following principles:\n\n1.  **Production:** The rate of synthesis of the Repressor protein is described by a repressive Hill function. When the concentration of R is zero, its production rate is at a maximum value of $k_p$. As the concentration $R(t)$ increases, the protein binds to its own promoter region, inhibiting synthesis. This repression is characterized by a constant $K$, defined as the concentration of R that reduces the production rate to one-half of its maximum. The binding process is non-cooperative, corresponding to a Hill coefficient of $n=1$.\n\n2.  **Degradation:** The Repressor protein is continuously removed from the cell. This removal process follows first-order kinetics, characterized by a degradation rate constant $k_d$.\n\nAll parameters $k_p$, $k_d$, and $K$ are positive real constants. After a sufficient amount of time, the system is observed to reach a stable configuration where the concentration of the Repressor protein no longer changes. Determine the concentration of the Repressor protein R in this final, stable configuration. Your answer should be an analytical expression in terms of the parameters $k_p$, $k_d$, and $K$.", "solution": "Let $R(t)$ denote the concentration of the Repressor. By the problem statement:\n- Production follows a repressive Hill function with $n=1$, maximum rate $k_{p}$ at $R=0$, and half-maximum at $R=K$. Thus the production rate is\n$$\n\\text{Production}(R) = \\frac{k_{p}}{1 + \\frac{R}{K}}.\n$$\n- Degradation follows first-order kinetics with rate constant $k_{d}$, so the degradation rate is\n$$\n\\text{Degradation}(R) = k_{d} R.\n$$\n\nThe dynamical equation is therefore\n$$\n\\frac{dR}{dt} = \\frac{k_{p}}{1 + \\frac{R}{K}} - k_{d} R.\n$$\n\nAt the final stable configuration (steady state), $\\frac{dR}{dt}=0$. Hence $R$ satisfies\n$$\n\\frac{k_{p}}{1 + \\frac{R}{K}} - k_{d} R = 0.\n$$\nRearranging gives\n$$\n\\frac{k_{p}}{1 + \\frac{R}{K}} = k_{d} R.\n$$\nMultiply both sides by $1 + \\frac{R}{K}$:\n$$\nk_{p} = k_{d} R \\left(1 + \\frac{R}{K}\\right) = k_{d} R + \\frac{k_{d}}{K} R^{2}.\n$$\nThus $R$ satisfies the quadratic equation\n$$\n\\frac{k_{d}}{K} R^{2} + k_{d} R - k_{p} = 0.\n$$\nLet $a = \\frac{k_{d}}{K}$, $b = k_{d}$, and $c = -k_{p}$. By the quadratic formula,\n$$\nR = \\frac{-b \\pm \\sqrt{b^{2} - 4 a c}}{2 a} = \\frac{-k_{d} \\pm \\sqrt{k_{d}^{2} + \\frac{4 k_{d} k_{p}}{K}}}{2 \\frac{k_{d}}{K}}.\n$$\nSince $k_{p}, k_{d}, K > 0$, the physically relevant (nonnegative) root uses the plus sign. Simplifying by factoring $k_{d}$ under the square root,\n$$\nR^{\\ast} = \\frac{K}{2 k_{d}} \\left(-k_{d} + \\sqrt{k_{d}^{2} + \\frac{4 k_{d} k_{p}}{K}}\\right)\n= \\frac{K}{2} \\left(-1 + \\sqrt{1 + \\frac{4 k_{p}}{k_{d} K}}\\right).\n$$\nThis is the steady-state concentration of the Repressor in terms of $k_{p}$, $k_{d}$, and $K$.", "answer": "$$\\boxed{\\frac{K}{2}\\left(\\sqrt{1+\\frac{4 k_{p}}{k_{d} K}}-1\\right)}$$", "id": "1435734"}, {"introduction": "Building on the principles of single-gene regulation, we now explore how these motifs function in a spatial context to create complex biological patterns. During embryonic development, sharp boundaries between different cell fates are often established by morphogen gradients, where the concentration of a signaling molecule provides positional information. This exercise [@problem_id:2393654] delves into how the switch-like behavior of a gene, governed by the Hill coefficient, can translate a smooth chemical gradient into a sharp gene expression boundary, a fundamental principle of developmental biology.", "problem": "You are given a one-dimensional developmental model in which a repressor morphogen forms a spatial gradient along a coordinate $x$ on the interval $[0,L]$, and a target gene is repressed according to a Hill function. The morphogen concentration is modeled as $M(x) = M_{0}\\,\\exp(-x/\\lambda)$, and the steady-state gene expression level is modeled as $G(x) = \\dfrac{G_{\\max}}{1 + \\left(\\dfrac{M(x)}{K}\\right)^{n}}$, where $n$ is the Hill coefficient. All quantities in this problem are dimensionless. Consider the fixed parameter values $M_{0} = 100$, $K = 1$, $\\lambda = 2$, $L = 20$, and $G_{\\max} = 1$.\n\nDefine the boundary sharpness as the width $\\Delta x_{10-90}$ between the positions $x_{0.1}$ and $x_{0.9}$ at which the expression reaches $0.1\\,G_{\\max}$ and $0.9\\,G_{\\max}$, respectively. That is, $G(x_{0.1}) = 0.1\\,G_{\\max}$ and $G(x_{0.9}) = 0.9\\,G_{\\max}$, and $\\Delta x_{10-90} = x_{0.9} - x_{0.1}$. Assume $x \\in [0,L]$.\n\nYour task is to compute $\\Delta x_{10-90}$ for each Hill coefficient $n$ in the following test suite:\n- $n = 0.5$\n- $n = 1$\n- $n = 2$\n- $n = 4$\n- $n = 10$\n\nAll outputs must be real numbers. Your program must produce a single line of output containing the resulting widths, in the same order as the test suite and rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets. For example, if the five results are $a_1$ through $a_5$, the output must be of the form \"[a1,a2,a3,a4,a5]\".", "solution": "The problem as stated is scientifically sound, self-contained, and well-posed. It describes a standard model of spatial pattern formation in developmental biology, where a morphogen gradient establishes a boundary of gene expression. I will proceed with a rigorous analytical solution.\n\nThe objective is to compute the boundary sharpness, $\\Delta x_{10-90}$, for a gene repressed by a morphogen. The morphogen concentration, $M(x)$, and the resulting gene expression, $G(x)$, are given by:\n$$M(x) = M_{0} \\exp(-x/\\lambda)$$\n$$G(x) = \\frac{G_{\\max}}{1 + \\left(\\frac{M(x)}{K}\\right)^{n}}$$\nThe fixed dimensionless parameters are $M_{0} = 100$, $K = 1$, $\\lambda = 2$, $L = 20$, and $G_{\\max} = 1$. The Hill coefficient, $n$, is the variable parameter.\n\nThe boundary sharpness is defined as $\\Delta x_{10-90} = x_{0.9} - x_{0.1}$, where $x_{0.1}$ and $x_{0.9}$ are the spatial positions at which the gene expression level is $10\\%$ and $90\\%$ of its maximum, respectively. That is, $G(x_{0.1}) = 0.1 G_{\\max}$ and $G(x_{0.9}) = 0.9 G_{\\max}$.\n\nFirst, we must derive a general expression for the position, $x_p$, where the gene expression is a fraction $p$ of its maximum: $G(x_p) = p \\cdot G_{\\max}$.\nSubstituting the expression for $G(x)$, we have:\n$$p \\cdot G_{\\max} = \\frac{G_{\\max}}{1 + \\left(\\frac{M(x_p)}{K}\\right)^{n}}$$\nSince $G_{\\max} \\neq 0$, we can divide both sides by $G_{\\max}$:\n$$p = \\frac{1}{1 + \\left(\\frac{M(x_p)}{K}\\right)^{n}}$$\nWe now solve for the morphogen concentration $M(x_p)$ at this position:\n$$1 + \\left(\\frac{M(x_p)}{K}\\right)^{n} = \\frac{1}{p}$$\n$$\\left(\\frac{M(x_p)}{K}\\right)^{n} = \\frac{1}{p} - 1 = \\frac{1-p}{p}$$\n$$M(x_p) = K \\left(\\frac{1-p}{p}\\right)^{1/n}$$\nNext, we substitute the expression for the morphogen gradient, $M(x) = M_{0} \\exp(-x/\\lambda)$, to solve for the position $x_p$:\n$$M_{0} \\exp(-x_p/\\lambda) = K \\left(\\frac{1-p}{p}\\right)^{1/n}$$\n$$\\exp(-x_p/\\lambda) = \\frac{K}{M_{0}} \\left(\\frac{1-p}{p}\\right)^{1/n}$$\nTaking the natural logarithm of both sides:\n$$-x_p/\\lambda = \\ln\\left[\\frac{K}{M_{0}} \\left(\\frac{1-p}{p}\\right)^{1/n}\\right]$$\nUsing the properties of logarithms, $\\ln(ab) = \\ln(a) + \\ln(b)$ and $\\ln(a^b) = b\\ln(a)$:\n$$-x_p/\\lambda = \\ln\\left(\\frac{K}{M_{0}}\\right) + \\frac{1}{n} \\ln\\left(\\frac{1-p}{p}\\right)$$\nFinally, solving for $x_p$:\n$$x_p = -\\lambda \\left[ \\ln\\left(\\frac{K}{M_{0}}\\right) + \\frac{1}{n} \\ln\\left(\\frac{1-p}{p}\\right) \\right]$$\nThis can be rewritten in a more convenient form using $\\ln(a/b) = -\\ln(b/a)$ and $\\ln((1-p)/p) = -\\ln(p/(1-p))$:\n$$x_p = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln\\left(\\frac{p}{1-p}\\right) \\right]$$\nThis equation provides the position $x_p$ for any given expression level fraction $p$.\n\nNow, we apply this general formula to find $x_{0.9}$ (where $p = 0.9$) and $x_{0.1}$ (where $p = 0.1$).\nFor $x_{0.9}$:\n$$x_{0.9} = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln\\left(\\frac{0.9}{1-0.9}\\right) \\right] = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln(9) \\right]$$\nFor $x_{0.1}$:\n$$x_{0.1} = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln\\left(\\frac{0.1}{1-0.1}\\right) \\right] = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln\\left(\\frac{1}{9}\\right) \\right]$$\nSince $\\ln(1/9) = -\\ln(9)$, this simplifies to:\n$$x_{0.1} = \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) - \\frac{1}{n} \\ln(9) \\right]$$\nThe boundary sharpness $\\Delta x_{10-90}$ is the difference between these two positions:\n$$\\Delta x_{10-90} = x_{0.9} - x_{0.1}$$\n$$\\Delta x_{10-90} = \\left( \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) + \\frac{1}{n} \\ln(9) \\right] \\right) - \\left( \\lambda \\left[ \\ln\\left(\\frac{M_{0}}{K}\\right) - \\frac{1}{n} \\ln(9) \\right] \\right)$$\nThe term $\\lambda \\ln(M_0/K)$ cancels out, yielding a remarkably simple result:\n$$\\Delta x_{10-90} = \\frac{\\lambda}{n} \\ln(9) - \\left(-\\frac{\\lambda}{n} \\ln(9)\\right) = \\frac{2\\lambda}{n} \\ln(9)$$\nThis result shows that the boundary sharpness is inversely proportional to the Hill coefficient $n$ and directly proportional to the morphogen decay length $\\lambda$. A higher Hill coefficient (a more switch-like, or ultrasensitive, response) leads to a sharper boundary (smaller $\\Delta x$).\n\nWe now substitute the given value of $\\lambda=2$ into this formula:\n$$\\Delta x_{10-90} = \\frac{2 \\cdot 2}{n} \\ln(9) = \\frac{4}{n} \\ln(9)$$\nThe value of the natural logarithm of $9$ is approximately $\\ln(9) \\approx 2.197224577$. Using this, we compute the sharpness for each value of $n$ in the test suite.\n\nFor $n=0.5$:\n$\\Delta x = \\frac{4}{0.5} \\ln(9) = 8 \\ln(9) \\approx 17.577797$\nFor $n=1$:\n$\\Delta x = \\frac{4}{1} \\ln(9) = 4 \\ln(9) \\approx 8.788898$\nFor $n=2$:\n$\\Delta x = \\frac{4}{2} \\ln(9) = 2 \\ln(9) \\approx 4.394449$\nFor $n=4$:\n$\\Delta x = \\frac{4}{4} \\ln(9) = \\ln(9) \\approx 2.197225$\nFor $n=10$:\n$\\Delta x = \\frac{4}{10} \\ln(9) = 0.4 \\ln(9) \\approx 0.878890$\n\nThese values will be computed and formatted as required by the implementation.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the boundary sharpness for a gene expression pattern formed by a repressor morphogen gradient.\n    \"\"\"\n    \n    # Define the constants from the problem statement.\n    # While M0, K, L, and Gmax are given, they are not needed for the final analytical formula.\n    # The decay length lambda is required.\n    lambda_val = 2.0\n    \n    # Define the test suite of Hill coefficients.\n    hill_coefficients = [0.5, 1.0, 2.0, 4.0, 10.0]\n    \n    results = []\n    \n    # The derived analytical formula for boundary sharpness is:\n    # delta_x_10_90 = (2 * lambda / n) * ln(9)\n    constant_term = 2.0 * lambda_val * np.log(9.0)\n    \n    for n in hill_coefficients:\n        # Calculate the boundary sharpness for the current Hill coefficient.\n        delta_x = constant_term / n\n        \n        # Format the result to 6 decimal places and add to the list.\n        # Using string formatting a la f-string is precise for this task.\n        results.append(f\"{delta_x:.6f}\")\n        \n    # Print the final output in the specified format: [a1,a2,a3,a4,a5]\n    print(f\"[{','.join(results)}]\")\n\n# Execute the solver function.\nsolve()\n```", "id": "2393654"}, {"introduction": "Having explored steady-state behavior and its role in spatial patterning, we now turn to the dynamic properties of interacting genes. The genetic toggle switch, composed of two mutually repressing genes, is a canonical network motif capable of producing bistability—the ability of a cell to exist in one of two stable states, creating a form of cellular memory. This advanced computational practice [@problem_id:2393647] challenges you to perform a full dynamical systems analysis, from finding the stable states of the switch to simulating how an external pulse can flip the system from one state to the other.", "problem": "Consider a symmetric two-gene toggle switch in which gene product $X$ represses the production of $Y$ and gene product $Y$ represses the production of $X$. Assume transcription-translation follows the Central Dogma of Molecular Biology, with production and decay aggregated into effective rates. The repressive regulation is modeled by Hill-type repression using well-tested phenomenological kinetics, and each species experiences linear decay due to dilution and degradation. The resulting Ordinary Differential Equation (ODE) model of the protein concentrations $X(t)$ and $Y(t)$ is\n$$\n\\frac{dX}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y}{K}\\right)^n} \\;-\\; \\delta X,\\qquad\n\\frac{dY}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{X}{K}\\right)^n} \\;-\\; \\delta Y,\n$$\nwhere $\\alpha$ is the basal promoter leakage (basal production), $\\beta$ is the maximal regulated production, $\\delta$ is the effective first-order loss rate, $K$ is the repression threshold, and $n$ is the Hill coefficient. All variables and parameters are dimensionless.\n\nA transient external stimulus can be applied to $X$ production for a fixed duration to probe switching dynamics. Specifically, during a stimulus of amplitude $s$ and duration $T$, the equation for $X$ is modified to\n$$\n\\frac{dX}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y}{K}\\right)^n} \\;+\\; s \\cdot \\mathbf{1}_{[0,T]}(t) \\;-\\; \\delta X,\n$$\nwhere $\\mathbf{1}_{[0,T]}(t)$ is $1$ if $0 \\le t \\le T$ and $0$ otherwise. The equation for $Y$ is unchanged.\n\nStarting from well-tested modeling facts about gene regulatory networks and dynamical systems:\n- Production is modeled as the sum of a basal term and a regulated term; repression decreases production as a monotone function of the repressor concentration, here captured by a Hill function.\n- Decay is proportional to concentration due to dilution and degradation.\n- Steady states $(X^\\ast, Y^\\ast)$ satisfy the nullcline equations obtained by setting time derivatives to zero.\n- Local asymptotic stability is determined by the Jacobian matrix eigenvalues having strictly negative real parts.\n\nYour task is to write a complete, runnable program that, for each parameter set in the test suite below, performs the following computations from first principles:\n\n1. Compute all equilibrium points $(X^\\ast, Y^\\ast)$ by solving the steady-state equations\n$$\n0 \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y}{K}\\right)^n} \\;-\\; \\delta X,\\qquad\n0 \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{X}{K}\\right)^n} \\;-\\; \\delta Y.\n$$\nSearch within a closed, bounded domain based on parameter magnitudes to ensure scientific realism. Deduplicate numerically close solutions.\n\n2. For each equilibrium point, evaluate the Jacobian matrix\n$$\nJ(X^\\ast, Y^\\ast) \\;=\\;\n\\begin{bmatrix}\n-\\delta & \\displaystyle -\\beta \\cdot \\frac{n}{K}\\cdot \\frac{\\left(\\frac{Y^\\ast}{K}\\right)^{n-1}}{\\left(1+\\left(\\frac{Y^\\ast}{K}\\right)^{n}\\right)^2} \\\\\n\\displaystyle -\\beta \\cdot \\frac{n}{K}\\cdot \\frac{\\left(\\frac{X^\\ast}{K}\\right)^{n-1}}{\\left(1+\\left(\\frac{X^\\ast}{K}\\right)^{n}\\right)^2} & -\\delta\n\\end{bmatrix},\n$$\nand determine whether it is locally asymptotically stable (that is, whether all eigenvalues have strictly negative real part). Report the integer number of stable equilibria $k$ found for the parameter set.\n\n3. If there are at least two stable equilibria and one has $X^\\ast > Y^\\ast$ (the $X$-high state) and another has $Y^\\ast > X^\\ast$ (the $Y$-high state), test switching dynamics as follows. Initialize the system at the $Y$-high equilibrium, apply the stimulus of amplitude $s$ for duration $T$, then integrate forward in time to allow relaxation after the pulse. Determine whether the trajectory converges to the basin of attraction of the $X$-high equilibrium (i.e., whether it ends up closest to the $X$-high stable equilibrium after sufficient time). Return a boolean value that is true if switching occurred and false otherwise. If the parameter set does not admit distinct $X$-high and $Y$-high stable equilibria, return false for switching by definition.\n\n4. Aggregate the results for all test cases into a single line of output containing a comma-separated list enclosed in square brackets, where for each test case you output in sequence the integer number of stable equilibria $k$ followed by the boolean switching outcome. For example, a program processing two test cases would output a list of length $4$: $[k_1,\\text{bool}_1,k_2,\\text{bool}_2]$.\n\nTest suite:\n- Case $1$: $\\alpha = 0.01$, $\\beta = 20.0$, $\\delta = 1.0$, $K = 1.0$, $n = 2$, $s = 6.0$, $T = 5.0$.\n- Case $2$: $\\alpha = 0.50$, $\\beta = 20.0$, $\\delta = 1.0$, $K = 1.0$, $n = 2$, $s = 6.0$, $T = 5.0$.\n- Case $3$: $\\alpha = 2.00$, $\\beta = 20.0$, $\\delta = 1.0$, $K = 1.0$, $n = 2$, $s = 10.0$, $T = 5.0$.\n- Case $4$: $\\alpha = 0.10$, $\\beta = 12.0$, $\\delta = 1.0$, $K = 1.0$, $n = 3$, $s = 5.0$, $T = 5.0$.\n\nAll variables are dimensionless; no physical units are required. Angles do not appear. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[k_1,\\text{bool}_1,k_2,\\text{bool}_2,k_3,\\text{bool}_3,k_4,\\text{bool}_4]$). The program must be complete and runnable without user input.", "solution": "The posed problem requests a comprehensive analysis of a symmetric two-gene toggle switch model, a canonical system in computational and synthetic biology. The analysis involves three main stages: first, identifying all equilibrium points of the system; second, determining the local asymptotic stability of each equilibrium; and third, simulating the system's response to an external stimulus to test for state-switching behavior. This entire process must be performed for several given parameter sets. The problem is scientifically well-grounded, mathematically well-posed, and provides sufficient information for a unique numerical solution. I will proceed with a detailed, principle-based solution.\n\nThe dynamics of the protein concentrations $X(t)$ and $Y(t)$ are described by the following system of Ordinary Differential Equations (ODEs):\n$$\n\\frac{dX}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y}{K}\\right)^n} \\;-\\; \\delta X\n$$\n$$\n\\frac{dY}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{X}{K}\\right)^n} \\;-\\; \\delta Y\n$$\nHere, $\\alpha$ is the basal production rate, $\\beta$ is the maximal regulated production rate, $\\delta$ is the degradation/dilution rate, $K$ is the repression threshold, and $n$ is the Hill coefficient measuring the cooperativity of repression.\n\n**1. Equilibrium Point Computation**\n\nEquilibrium points, or steady states $(X^\\ast, Y^\\ast)$, are solutions to the system where the time derivatives are zero. This transforms the dynamical system into a system of two coupled nonlinear algebraic equations:\n$$\n\\delta X^\\ast \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y^\\ast}{K}\\right)^n}\n$$\n$$\n\\delta Y^\\ast \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{X^\\ast}{K}\\right)^n}\n$$\nThese equations can be written as a root-finding problem $F(X^\\ast, Y^\\ast) = 0$, where $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$ is the vector function defined by the steady-state conditions.\n\nTo solve this system numerically, we employ an iterative root-finding algorithm, specifically the `scipy.optimize.root` function, which is a robust implementation based on modifications of the Powell hybrid method. Since such algorithms require an initial guess and may only find one root at a time, we must use a systematic approach to find all physically relevant solutions. The physically meaningful concentration values are non-negative. A reasonable search domain can be established by considering the system's bounds. The minimum concentration occurs under full repression ($X \\to \\infty$ or $Y \\to \\infty$), giving a steady-state value approaching $\\alpha/\\delta$. The maximum concentration occurs with no repression ($X=0$ or $Y=0$), giving a steady-state value of $(\\alpha+\\beta)/\\delta$. Therefore, all equilibria must lie within the bounded box $[0, (\\alpha+\\beta)/\\delta] \\times [0, (\\alpha+\\beta)/\\delta]$. We will use a grid of initial guesses spanning this domain to ensure comprehensive discovery of all equilibria.\n\nNumerically-found roots that are very close to each other (within a small tolerance, e.g., $10^{-6}$, in Euclidean distance) are considered duplicates and are merged into a single representative equilibrium point.\n\n**2. Local Stability Analysis**\n\nThe local stability of an equilibrium point $(X^\\ast, Y^\\ast)$ is determined by the eigenvalues of the Jacobian matrix $J$ of the system evaluated at that point. The Jacobian matrix is the matrix of all first-order partial derivatives of the system's vector field:\n$$\nJ(X, Y) \\;=\\; \\begin{bmatrix} \\frac{\\partial}{\\partial X}(\\frac{dX}{dt}) & \\frac{\\partial}{\\partial Y}(\\frac{dX}{dt}) \\\\ \\frac{\\partial}{\\partial X}(\\frac{dY}{dt}) & \\frac{\\partial}{\\partial Y}(\\frac{dY}{dt}) \\end{bmatrix}\n$$\nFor the given system, this evaluates to:\n$$\nJ(X^\\ast, Y^\\ast) \\;=\\;\n\\begin{bmatrix}\n-\\delta & \\displaystyle -\\beta \\cdot \\frac{n}{K}\\cdot \\frac{\\left(\\frac{Y^\\ast}{K}\\right)^{n-1}}{\\left(1+\\left(\\frac{Y^\\ast}{K}\\right)^{n}\\right)^2} \\\\\n\\displaystyle -\\beta \\cdot \\frac{n}{K}\\cdot \\frac{\\left(\\frac{X^\\ast}{K}\\right)^{n-1}}{\\left(1+\\left(\\frac{X^\\ast}{K}\\right)^{n}\\right)^2} & -\\delta\n\\end{bmatrix} \\;=\\; \\begin{bmatrix} -\\delta & J_{12} \\\\ J_{21} & -\\delta \\end{bmatrix}\n$$\nAn equilibrium is locally asymptotically stable if and only if all eigenvalues $\\lambda$ of its Jacobian matrix have strictly negative real parts ($\\text{Re}(\\lambda) < 0$). The eigenvalues are the roots of the characteristic equation $\\det(J - \\lambda I) = 0$:\n$$\n(-\\delta - \\lambda)^2 - J_{12} J_{21} = 0\n$$\n$$\n\\lambda + \\delta = \\pm\\sqrt{J_{12} J_{21}} \\quad \\implies \\quad \\lambda = -\\delta \\pm\\sqrt{J_{12} J_{21}}\n$$\nSince all parameters and concentrations are non-negative, the off-diagonal terms $J_{12}$ and $J_{21}$ are non-positive. Their product $J_{12} J_{21}$ is therefore non-negative, and its square root is real. For stability, both eigenvalues must be negative:\n$$\n-\\delta + \\sqrt{J_{12} J_{21}} < 0 \\quad \\implies \\quad J_{12}(Y^\\ast) J_{21}(X^\\ast) < \\delta^2\n$$\nThis inequality provides a simple and direct test for the stability of any found equilibrium. The number of equilibria satisfying this condition, $k$, is then counted.\n\n**3. Switching Dynamics Simulation**\n\nBistability, the existence of at least two stable equilibria, is a key feature of the toggle switch. The problem asks to investigate switching from a \"$Y$-high\" state to an \"$X$-high\" state, induced by an external stimulus. This is possible if the system exhibits at least two stable equilibria: one $(X^\\ast_1, Y^\\ast_1)$ with $X^\\ast_1 > Y^\\ast_1$ and another $(X^\\ast_2, Y^\\ast_2)$ with $Y^\\ast_2 > X^\\ast_2$. If this condition is not met (e.g., the system is monostable), switching is defined as `False`.\n\nThe simulation proceeds as an initial value problem.\n1.  **Initialization**: The system is initialized at the $Y$-high stable equilibrium, $(X(0), Y(0)) = (X^\\ast_{Yh}, Y^\\ast_{Yh})$, where $Y^\\ast_{Yh} > X^\\ast_{Yh}$.\n2.  **Stimulus Phase**: For a duration $T$, a stimulus $s$ is added to the production rate of $X$. The system is integrated from $t=0$ to $t=T$ using the modified ODE:\n    $$\n    \\frac{dX}{dt} \\;=\\; \\alpha \\;+\\; \\frac{\\beta}{1 + \\left(\\frac{Y}{K}\\right)^n} \\;+\\; s \\;-\\; \\delta X\n    $$\n    The equation for $Y$ remains unchanged.\n3.  **Relaxation Phase**: At $t=T$, the stimulus is removed. The system is then integrated further, from $t=T$ to a final time $t_{final}$ (chosen to be sufficiently large for relaxation, e.g., $100$ time units), using the original ODEs.\n\nThis numerical integration is performed using `scipy.integrate.solve_ivp`, a modern, adaptive step-size ODE solver.\n\nFinally, to determine if switching was successful, the state of the system at $t_{final}$, denoted $(X_{final}, Y_{final})$, is compared to the identified stable equilibria. Switching is deemed successful if $(X_{final}, Y_{final})$ is closer in Euclidean distance to the $X$-high stable equilibrium, $(X^\\ast_{Xh}, Y^\\ast_{Xh})$, than to the $Y$-high one. This outcome is reported as a boolean value.\n\nThe procedure is repeated for each parameter set provided in the test suite, and the results are aggregated into the specified output format.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import root\nfrom scipy.integrate import solve_ivp\n\nclass ToggleSwitchAnalyzer:\n    \"\"\"\n    Analyzes a symmetric two-gene toggle switch model.\n    \"\"\"\n    def __init__(self, params):\n        self.alpha, self.beta, self.delta, self.K, self.n, self.s, self.T = params\n        self.equilibria = []\n        self.stable_equilibria = []\n\n    def _steady_state_residuals(self, z):\n        \"\"\"Residuals for the steady-state equations.\"\"\"\n        X, Y = z\n        res_X = self.alpha + self.beta / (1 + (Y / self.K)**self.n) - self.delta * X\n        res_Y = self.alpha + self.beta / (1 + (X / self.K)**self.n) - self.delta * Y\n        return [res_X, res_Y]\n\n    def find_equilibria(self, grid_size=15, tol=1e-6):\n        \"\"\"\n        Finds all equilibria by root-finding from a grid of initial guesses.\n        \"\"\"\n        found_roots = []\n        max_val = (self.alpha + self.beta) / self.delta + 5.0  # Search domain buffer\n        \n        # Grid search for initial guesses\n        for x0 in np.linspace(0, max_val, grid_size):\n            for y0 in np.linspace(0, max_val, grid_size):\n                sol = root(self._steady_state_residuals, [x0, y0], method='hybr')\n                if sol.success:\n                    # Filter out non-physical (negative) roots\n                    if np.all(sol.x >= 0):\n                        found_roots.append(sol.x)\n\n        if not found_roots:\n            return\n\n        # Deduplicate roots\n        unique_roots = []\n        for r in found_roots:\n            is_duplicate = False\n            for ur in unique_roots:\n                if np.linalg.norm(r - ur) < tol:\n                    is_duplicate = True\n                    break\n            if not is_duplicate:\n                unique_roots.append(r)\n        \n        self.equilibria = unique_roots\n\n    def analyze_stability(self):\n        \"\"\"\n        Analyzes the stability of each found equilibrium point.\n        \"\"\"\n        def jacobian_off_diagonal(val):\n            val_k = val / self.K\n            if val_k < 0: return 0 # Handle potential numerical noise\n            term = (1 + val_k**self.n)\n            # handle potential overflow if val_k is very large\n            if term == 0: return 0\n            \n            numerator = self.n / self.K * (val_k)**(self.n - 1)\n            denominator = term**2\n            \n            # Avoid division by zero or large number issues\n            if denominator == 0: return -np.inf if numerator > 0 else 0\n\n            return -self.beta * numerator / denominator\n\n        for eq in self.equilibria:\n            X_star, Y_star = eq\n            \n            # For n<1 and X=0 or Y=0, (val/K)^(n-1) is undefined.\n            # However, in our system X,Y > alpha/delta > 0.\n            # But just in case of numerical issues close to zero:\n            if X_star < 1e-9 and self.n < 1: J21 = -np.inf\n            else: J21 = jacobian_off_diagonal(X_star)\n            \n            if Y_star < 1e-9 and self.n < 1: J12 = -np.inf\n            else: J12 = jacobian_off_diagonal(Y_star)\n\n            # Stability condition: J12 * J21 < delta^2\n            if J12 * J21 < self.delta**2:\n                self.stable_equilibria.append(eq)\n\n    def simulate_switching(self):\n        \"\"\"\n        Simulates switching dynamics from a Y-high to an X-high state.\n        \"\"\"\n        num_stable = len(self.stable_equilibria)\n        \n        # Identify high-X and high-Y states\n        x_high_states = [p for p in self.stable_equilibria if p[0] > p[1]]\n        y_high_states = [p for p in self.stable_equilibria if p[1] > p[0]]\n\n        # Condition for bistable switching experiment\n        if not (x_high_states and y_high_states):\n            return num_stable, False\n\n        # Select representative states (e.g., max separation from diagonal)\n        x_high_state = max(x_high_states, key=lambda p: p[0] - p[1])\n        y_high_state = max(y_high_states, key=lambda p: p[1] - p[0])\n\n        # --- ODE Integration ---\n        # 1. Stimulus phase\n        def ode_stimulus(t, z):\n            X, Y = z\n            dX_dt = self.alpha + self.beta / (1 + (Y / self.K)**self.n) + self.s - self.delta * X\n            dY_dt = self.alpha + self.beta / (1 + (X / self.K)**self.n) - self.delta * Y\n            return [dX_dt, dY_dt]\n\n        t_span_stim = [0, self.T]\n        sol_stim = solve_ivp(ode_stimulus, t_span_stim, y_high_state, dense_output=True)\n        state_after_stim = sol_stim.y[:, -1]\n\n        # 2. Relaxation phase\n        def ode_no_stimulus(t, z):\n            X, Y = z\n            dX_dt = self.alpha + self.beta / (1 + (Y / self.K)**self.n) - self.delta * X\n            dY_dt = self.alpha + self.beta / (1 + (X / self.K)**self.n) - self.delta * Y\n            return [dX_dt, dY_dt]\n\n        t_final = 100.0\n        t_span_relax = [self.T, t_final]\n        sol_relax = solve_ivp(ode_no_stimulus, t_span_relax, state_after_stim, dense_output=True)\n        final_state = sol_relax.y[:, -1]\n\n        # --- Check for switching success ---\n        dist_to_x_high = np.linalg.norm(final_state - x_high_state)\n        dist_to_y_high = np.linalg.norm(final_state - y_high_state)\n        \n        switched = dist_to_x_high < dist_to_y_high\n        \n        return num_stable, switched\n\n    def run_analysis(self):\n        \"\"\"\n        Executes the full analysis pipeline.\n        \"\"\"\n        self.find_equilibria()\n        self.analyze_stability()\n        k, switched = self.simulate_switching()\n        return k, switched\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # alpha, beta,  delta, K,   n, s,    T\n        (0.01,  20.0,  1.0,   1.0, 2, 6.0,  5.0),\n        (0.50,  20.0,  1.0,   1.0, 2, 6.0,  5.0),\n        (2.00,  20.0,  1.0,   1.0, 2, 10.0, 5.0),\n        (0.10,  12.0,  1.0,   1.0, 3, 5.0,  5.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        analyzer = ToggleSwitchAnalyzer(params)\n        k, switched = analyzer.run_analysis()\n        results.extend([k, switched])\n    \n    # Format the final output as a comma-separated list in brackets.\n    # Python's str(True) is 'True', which is standard.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2393647"}]}