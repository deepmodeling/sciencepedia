{"hands_on_practices": [{"introduction": "Real-world virtual screening is rarely a single step; it's a strategic cascade of filters designed to efficiently sift through vast chemical libraries. This exercise [@problem_id:2440164] challenges you to build a complete, three-stage screening funnel from first principles. By implementing 2D similarity searching, 3D pharmacophore matching, and a simplified flexible docking protocol, you will gain hands-on experience with the core logic of balancing computational speed and predictive accuracy in drug discovery.", "problem": "Implement a complete screening cascade that operates in three sequential stages consistent with virtual screening practice: a $2\\text{D}$ similarity search, then a $3\\text{D}$ pharmacophore filter, and finally a flexible docking stage. Your program must be a deterministic implementation based on the following definitions and rules, and it must process a fixed test suite of parameter sets. All distances must be expressed in angstroms, denoted $\\mathrm{\\mathring{A}}$, and all angles must be expressed in radians.\n\nBegin from the following fundamental bases and core definitions.\n\n1. $2\\text{D}$ similarity as set similarity. Represent each molecule and the query as a fixed-length binary fingerprint vector that encodes molecular substructures. Let $A$ and $B$ be two binary fingerprints interpreted as sets of indices where the bits are $1$. The Tanimoto coefficient (also known as the Jaccard index for binary fingerprints) is defined by\n$$\nT(A,B) \\;=\\; \\frac{|A \\cap B|}{|A \\cup B|} \\;=\\; \\frac{c}{a + b - c},\n$$\nwhere $a = |A|$, $b = |B|$, and $c = |A \\cap B|$. A molecule passes the $2\\text{D}$ filter if $T(A,B) \\ge \\tau_{\\mathrm{sim}}$, where $\\tau_{\\mathrm{sim}}$ is a given similarity threshold.\n\n2. $3\\text{D}$ pharmacophore as geometric distance constraints. A pharmacophore template is specified by an ordered triple of feature types and their target pairwise distances. In this problem, each molecule provides three feature points labeled $\\mathrm{DON}$ (hydrogen bond donor), $\\mathrm{ACC}$ (hydrogen bond acceptor), and $\\mathrm{HYD}$ (hydrophobe), each with a $3$-dimensional coordinate in $\\mathrm{\\mathring{A}}$. Let $d_{XY}$ denote the Euclidean distance between features $X$ and $Y$. Given target distances $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)$ and a nonnegative tolerance $\\delta$ in $\\mathrm{\\mathring{A}}$, a molecule passes the $3\\text{D}$ pharmacophore filter if and only if\n$$\n|d_{\\mathrm{DA}} - d^{\\star}_{\\mathrm{DA}}| \\le \\delta,\\quad\n|d_{\\mathrm{DH}} - d^{\\star}_{\\mathrm{DH}}| \\le \\delta,\\quad\n|d_{\\mathrm{AH}} - d^{\\star}_{\\mathrm{AH}}| \\le \\delta.\n$$\n\n3. Flexible docking as discrete internal rotation minimizing an energy-like score. For each molecule that passes the first two stages, consider a simplified docking setup with the following components:\n- Rigid receptor interaction sites at fixed coordinates $S_{\\mathrm{DON}}$, $S_{\\mathrm{ACC}}$, and $S_{\\mathrm{HYD}}$ in $\\mathrm{\\mathring{A}}$. The ligand’s feature $\\mathrm{DON}$ is the anchor that is translated to $S_{\\mathrm{DON}}$ for all candidate conformations.\n- A single internal flexibility modeled by rotation around the $z$-axis through the anchor point $S_{\\mathrm{DON}}$. Let $\\theta \\in \\Theta$ be a discrete set of rotation angles. For each $\\theta$, rotate the ligand’s $\\mathrm{ACC}$ and $\\mathrm{HYD}$ feature coordinates about the anchor by $\\theta$ using a standard rotation in the $xy$-plane.\n- An attraction energy defined by a sum of isotropic Gaussian terms:\n$$\nE_{\\mathrm{attr}}(\\theta) \\;=\\; -\\,w_{\\mathrm{ACC}} \\exp\\!\\Big(\\!-\\frac{\\|R_{\\theta}(P_{\\mathrm{ACC}}-P_{\\mathrm{DON}}) + S_{\\mathrm{DON}} - S_{\\mathrm{ACC}}\\|^2}{2\\sigma^2}\\Big) \\;-\\; w_{\\mathrm{HYD}} \\exp\\!\\Big(\\!-\\frac{\\|R_{\\theta}(P_{\\mathrm{HYD}}-P_{\\mathrm{DON}}) + S_{\\mathrm{DON}} - S_{\\mathrm{HYD}}\\|^2}{2\\sigma^2}\\Big),\n$$\nwhere $P_{\\mathrm{DON}}$, $P_{\\mathrm{ACC}}$, and $P_{\\mathrm{HYD}}$ are the molecule’s original feature coordinates, $R_{\\theta}$ is the rotation by angle $\\theta$ about the $z$-axis, $\\sigma > 0$ is a length scale in $\\mathrm{\\mathring{A}}$, and $w_{\\mathrm{ACC}}, w_{\\mathrm{HYD}} > 0$ are weights.\n- A steric clash penalty. Given an excluded sphere with center $C$ and radius $R_{\\mathrm{clash}}$ in $\\mathrm{\\mathring{A}}$, if any transformed feature point lies strictly within the sphere, add a penalty $+\\lambda_{\\mathrm{clash}}$ to the energy for that $\\theta$:\n$$\nE_{\\mathrm{clash}}(\\theta) \\;=\\; \n\\begin{cases}\n\\lambda_{\\mathrm{clash}}, & \\text{if any } \\|Q(\\theta) - C\\| \\lt R_{\\mathrm{clash}},\\\\\n0, & \\text{otherwise},\n\\end{cases}\n$$\nwhere $Q(\\theta)$ ranges over the transformed positions of $\\mathrm{DON}$, $\\mathrm{ACC}$, and $\\mathrm{HYD}$ at angle $\\theta$. The total energy is\n$$\nE(\\theta) \\;=\\; E_{\\mathrm{attr}}(\\theta) \\;+\\; E_{\\mathrm{clash}}(\\theta).\n$$\nDefine the docking score of a molecule to be the minimum of $E(\\theta)$ over $\\theta \\in \\Theta$. Lower (more negative) values indicate better docking.\n\nThe screening cascade proceeds in order: apply the $2\\text{D}$ filter, then the $3\\text{D}$ pharmacophore filter, then compute the docking score for each remaining molecule and select the molecule with the lowest docking score. If there is a tie, select the molecule with the smallest index.\n\nYou must implement the cascade over a fixed library and a fixed query, and evaluate it under a test suite of three parameter sets described below. For each parameter set, your program must output the index of the selected molecule as a single integer according to the rules above, or output $-1$ if no molecule survives through docking. The final program output must be a single line containing all three results as a comma-separated list enclosed in square brackets.\n\nUse the following fixed library and query data.\n\n- Query fingerprint $F_q$ of length $8$: $[1,1,0,1,0,1,0,0]$.\n\n- Library of $4$ molecules indexed $0$ through $3$:\n    - Molecule $0$:\n        - Fingerprint $F_0 = [1,1,0,1,0,1,0,0]$.\n        - Features in $\\mathrm{\\mathring{A}}$: $P_{\\mathrm{DON}}=(0,0,0)$, $P_{\\mathrm{ACC}}=(3,0,0)$, $P_{\\mathrm{HYD}}=(0,4,0)$.\n    - Molecule $1$:\n        - Fingerprint $F_1 = [1,0,1,1,0,0,1,0]$.\n        - Features in $\\mathrm{\\mathring{A}}$: $P_{\\mathrm{DON}}=(0,0,0)$, $P_{\\mathrm{ACC}}=(2.0,1.0,0)$, $P_{\\mathrm{HYD}}=(-1.0,3.5,0)$.\n    - Molecule $2$:\n        - Fingerprint $F_2 = [0,1,0,1,1,0,0,1]$.\n        - Features in $\\mathrm{\\mathring{A}}$: $P_{\\mathrm{DON}}=(0,0,0)$, $P_{\\mathrm{ACC}}=(2.5,0.2,0)$, $P_{\\mathrm{HYD}}=(-0.5,4.2,0)$.\n    - Molecule $3$:\n        - Fingerprint $F_3 = [0,0,0,1,0,1,0,1]$.\n        - Features in $\\mathrm{\\mathring{A}}$: $P_{\\mathrm{DON}}=(0,0,0)$, $P_{\\mathrm{ACC}}=(2.7,0,0)$, $P_{\\mathrm{HYD}}=(0,4.1,0)$.\n\n- Receptor interaction sites in $\\mathrm{\\mathring{A}}$: $S_{\\mathrm{DON}}=(0,0,0)$, $S_{\\mathrm{ACC}}=(5,0,0)$, $S_{\\mathrm{HYD}}=(0,5,0)$.\n\n- Docking parameters common to all test cases unless otherwise specified: Gaussian length scale $\\sigma=1.5\\,\\mathrm{\\mathring{A}}$, weights $w_{\\mathrm{ACC}}=1.0$, $w_{\\mathrm{HYD}}=0.8$, excluded sphere center $C=(1.0,1.0,0.0)$, excluded radius $R_{\\mathrm{clash}}=1.0\\,\\mathrm{\\mathring{A}}$, penalty $\\lambda_{\\mathrm{clash}}=50.0$, and rotation angle set $\\Theta$ consisting of $24$ uniformly spaced values in $[0,2\\pi)$.\n\nImplement the test suite as three parameter sets, each specifying the $2\\text{D}$ similarity threshold $\\tau_{\\mathrm{sim}}$, the pharmacophore target distances $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)$ in $\\mathrm{\\mathring{A}}$, and the pharmacophore tolerance $\\delta$ in $\\mathrm{\\mathring{A}}$:\n- Test case $1$ (happy path): $\\tau_{\\mathrm{sim}}=0.5$, $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)=(3.0,4.0,5.0)$, $\\delta=0.3$.\n- Test case $2$ (boundary inclusion for $2\\text{D}$ similarity): $\\tau_{\\mathrm{sim}}=0.4$, $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)=(3.0,4.0,5.0)$, $\\delta=0.3$.\n- Test case $3$ (edge case, no survivors due to stringent $3\\text{D}$ template): $\\tau_{\\mathrm{sim}}=0.3$, $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)=(2.4,2.4,2.4)$, $\\delta=0.05$.\n\nProgram requirements and output format:\n- Your program must implement the three-stage cascade exactly as defined.\n- For each test case, compute the index (zero-based) of the single best-scoring molecule after docking among those that pass the filters. If no molecule survives, output $-1$ for that test case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3]$, where each $r_i$ is an integer result for test case $i$.", "solution": "The problem statement is a valid, well-posed computational exercise grounded in the principles of virtual screening in bioinformatics and computational chemistry. It is self-contained, with all necessary data, parameters, and mathematical definitions provided. The staged pipeline mimics a realistic (albeit simplified) screening cascade, progressing from less computationally intensive methods ($2\\text{D}$ similarity) to more intensive ones ($3\\text{D}$ docking). The objective is to implement this deterministic cascade and report the index of the optimal molecule for a given set of test parameters, or $-1$ if no molecule passes the filters. The problem is scientifically consistent and mathematically unambiguous.\n\nThe solution is implemented by following the prescribed three-stage cascade.\n\nStage $1$: $2\\text{D}$ Similarity Search\n\nThis stage filters molecules based on their structural similarity to a query molecule, quantified using a binary fingerprint. A fingerprint is a vector of $0$s and $1$s representing the presence or absence of specific substructures. The similarity between two molecules, represented by their fingerprint sets $A$ and $B$, is calculated using the Tanimoto coefficient, $T(A,B)$. This coefficient is defined as the size of the intersection of the sets divided by the size of their union:\n$$\nT(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}\n$$\nThe problem provides an equivalent formula for computation: $T(A,B) = \\frac{c}{a + b - c}$, where $a = |A|$, $b = |B|$, and $c = |A \\cap B|$. A molecule with fingerprint $F_{mol}$ passes this filter if its Tanimoto coefficient with the query fingerprint $F_q$ meets or exceeds a given threshold $\\tau_{\\mathrm{sim}}$:\n$$\nT(F_{mol}, F_q) \\ge \\tau_{\\mathrm{sim}}\n$$\n\nStage $2$: $3\\text{D}$ Pharmacophore Filtering\n\nMolecules that pass the first stage are then subjected to a geometric filter based on a $3\\text{D}$ pharmacophore model. A pharmacophore represents the spatial arrangement of essential features for molecular recognition. In this problem, the model consists of three features—a hydrogen bond donor ($\\mathrm{DON}$), an acceptor ($\\mathrm{ACC}$), and a hydrophobe ($\\mathrm{HYD}$)—and a set of target distances between them, $\\big(d^{\\star}_{\\mathrm{DA}}, d^{\\star}_{\\mathrm{DH}}, d^{\\star}_{\\mathrm{AH}}\\big)$. A molecule, with its own internal feature distances $\\big(d_{\\mathrm{DA}}, d_{\\mathrm{DH}}, d_{\\mathrm{AH}}\\big)$, is considered a match if each of its internal distances is within a specified tolerance $\\delta$ of the corresponding target distance. That is, all three of the following conditions must be met:\n$$\n|d_{\\mathrm{DA}} - d^{\\star}_{\\mathrm{DA}}| \\le \\delta \\\\\n|d_{\\mathrm{DH}} - d^{\\star}_{\\mathrm{DH}}| \\le \\delta \\\\\n|d_{\\mathrm{AH}} - d^{\\star}_{\\mathrm{AH}}| \\le \\delta\n$$\nThe distance $d_{XY}$ is the standard Euclidean distance between the coordinates of features $X$ and $Y$ within the molecule.\n\nStage $3$: Flexible Docking and Scoring\n\nThe final stage evaluates the binding of the remaining molecules to a rigid receptor model. This simplified docking protocol involves a single degree of internal flexibility and an energy-like scoring function.\n\n- **Conformation Generation**: For each molecule, a set of conformations is generated. The molecule's $\\mathrm{DON}$ feature is designated as the anchor and is translated to the receptor's corresponding site, $S_{\\mathrm{DON}}$. The rest of the molecule is then rotated around the $z$-axis passing through this anchor point. The rotation is sampled at a discrete set of angles $\\Theta$, which consists of $24$ uniformly spaced values in $[0, 2\\pi)$. For each angle $\\theta \\in \\Theta$, the coordinates of the $\\mathrm{ACC}$ and $\\mathrm{HYD}$ features are transformed. If a point $P_X$ is a feature coordinate in the molecule's original frame, its transformed coordinate $Q_X(\\theta)$ after moving the anchor $P_{DON}$ to $S_{DON}$ and rotating is:\n  $$\n  Q_X(\\theta) = R_{\\theta}(P_X - P_{\\mathrm{DON}}) + S_{\\mathrm{DON}}\n  $$\n  where $R_{\\theta}$ is the standard $3\\text{D}$ rotation matrix for an angle $\\theta$ about the $z$-axis.\n\n- **Scoring Function**: The goodness-of-fit for each conformation is evaluated by a total energy score $E(\\theta)$, which is the sum of an attraction term $E_{\\mathrm{attr}}(\\theta)$ and a steric clash penalty $E_{\\mathrm{clash}}(\\theta)$.\n\n  The attraction energy is modeled as a sum of negative Gaussian functions, rewarding proximity between the ligand's features ($\\mathrm{ACC}$, $\\mathrm{HYD}$) and their respective receptor sites ($S_{\\mathrm{ACC}}$, $S_{\\mathrm{HYD}}$):\n  $$\n  E_{\\mathrm{attr}}(\\theta) = -w_{\\mathrm{ACC}} \\exp\\left(-\\frac{\\|Q_{\\mathrm{ACC}}(\\theta) - S_{\\mathrm{ACC}}\\|^2}{2\\sigma^2}\\right) - w_{\\mathrm{HYD}} \\exp\\left(-\\frac{\\|Q_{\\mathrm{HYD}}(\\theta) - S_{\\mathrm{HYD}}\\|^2}{2\\sigma^2}\\right)\n  $$\n  Here, $w_X$ are positive weights and $\\sigma$ is a length scale defining the width of the potential wells.\n\n  The steric clash penalty is applied if any of the transformed feature points $Q_X(\\theta)$ penetrates an excluded volume, modeled as a sphere with center $C$ and radius $R_{\\mathrm{clash}}$. If $\\|Q_X(\\theta) - C\\| < R_{\\mathrm{clash}}$ for any feature $X \\in \\{\\mathrm{DON, ACC, HYD}\\}$, a large positive penalty $\\lambda_{\\mathrm{clash}}$ is added to the energy for that angle $\\theta$. Otherwise, the penalty is $0$.\n  $$\n  E(\\theta) = E_{\\mathrm{attr}}(\\theta) + E_{\\mathrm{clash}}(\\theta)\n  $$\n\n- **Docking Score**: The final docking score for a molecule is the minimum energy conformation found among all sampled rotations:\n  $$\n  \\text{Score} = \\min_{\\theta \\in \\Theta} E(\\theta)\n  $$\n\nFinal Selection\n\nThe cascade is executed sequentially for each test case. From the set of molecules that pass all three stages, the one with the lowest (most negative) docking score is selected as the winner. If two or more molecules have the same minimum score, the one with the lower original index (from $0$ to $3$) is chosen. If no molecules survive the entire cascade, the result is reported as $-1$. The procedure is repeated for all three test cases provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the three-stage virtual screening cascade for the given test cases.\n    \"\"\"\n    \n    # --- Fixed Data and Parameters ---\n    \n    # Query fingerprint\n    F_Q = np.array([1, 1, 0, 1, 0, 1, 0, 0], dtype=int)\n\n    # Library of molecules\n    MOLECULES = [\n        {\n            \"id\": 0,\n            \"fp\": np.array([1, 1, 0, 1, 0, 1, 0, 0], dtype=int),\n            \"coords\": {\n                \"DON\": np.array([0.0, 0.0, 0.0]),\n                \"ACC\": np.array([3.0, 0.0, 0.0]),\n                \"HYD\": np.array([0.0, 4.0, 0.0]),\n            },\n        },\n        {\n            \"id\": 1,\n            \"fp\": np.array([1, 0, 1, 1, 0, 0, 1, 0], dtype=int),\n            \"coords\": {\n                \"DON\": np.array([0.0, 0.0, 0.0]),\n                \"ACC\": np.array([2.0, 1.0, 0.0]),\n                \"HYD\": np.array([-1.0, 3.5, 0.0]),\n            },\n        },\n        {\n            \"id\": 2,\n            \"fp\": np.array([0, 1, 0, 1, 1, 0, 0, 1], dtype=int),\n            \"coords\": {\n                \"DON\": np.array([0.0, 0.0, 0.0]),\n                \"ACC\": np.array([2.5, 0.2, 0.0]),\n                \"HYD\": np.array([-0.5, 4.2, 0.0]),\n            },\n        },\n        {\n            \"id\": 3,\n            \"fp\": np.array([0, 0, 0, 1, 0, 1, 0, 1], dtype=int),\n            \"coords\": {\n                \"DON\": np.array([0.0, 0.0, 0.0]),\n                \"ACC\": np.array([2.7, 0.0, 0.0]),\n                \"HYD\": np.array([0.0, 4.1, 0.0]),\n            },\n        },\n    ]\n\n    # Receptor and common docking parameters\n    RECEPTOR_SITES = {\n        \"DON\": np.array([0.0, 0.0, 0.0]),\n        \"ACC\": np.array([5.0, 0.0, 0.0]),\n        \"HYD\": np.array([0.0, 5.0, 0.0]),\n    }\n    DOCKING_PARAMS = {\n        \"sigma\": 1.5,\n        \"w_acc\": 1.0,\n        \"w_hyd\": 0.8,\n        \"clash_C\": np.array([1.0, 1.0, 0.0]),\n        \"clash_R\": 1.0,\n        \"clash_lambda\": 50.0,\n        \"angles\": np.linspace(0, 2 * np.pi, 24, endpoint=False),\n    }\n\n    # Test suite parameter sets\n    test_cases = [\n        # (tau_sim, (d_DA_star, d_DH_star, d_AH_star), delta)\n        (0.5, (3.0, 4.0, 5.0), 0.3),  # Test case 1\n        (0.4, (3.0, 4.0, 5.0), 0.3),  # Test case 2\n        (0.3, (2.4, 2.4, 2.4), 0.05), # Test case 3\n    ]\n\n    # --- Helper Functions ---\n    def tanimoto_coeff(fp_a, fp_b):\n        a = np.sum(fp_a)\n        b = np.sum(fp_b)\n        c = np.sum(np.logical_and(fp_a, fp_b))\n        if a + b - c == 0:\n            return 1.0\n        return c / (a + b - c)\n\n    def internal_distances(coords):\n        d_da = np.linalg.norm(coords[\"ACC\"] - coords[\"DON\"])\n        d_dh = np.linalg.norm(coords[\"HYD\"] - coords[\"DON\"])\n        d_ah = np.linalg.norm(coords[\"ACC\"] - coords[\"HYD\"])\n        return (d_da, d_dh, d_ah)\n\n    def docking_score(molecule, receptor_sites, params):\n        p_don = molecule[\"coords\"][\"DON\"]\n        p_acc = molecule[\"coords\"][\"ACC\"]\n        p_hyd = molecule[\"coords\"][\"HYD\"]\n\n        s_don = receptor_sites[\"DON\"]\n        s_acc = receptor_sites[\"ACC\"]\n        s_hyd = receptor_sites[\"HYD\"]\n\n        v_acc = p_acc - p_don\n        v_hyd = p_hyd - p_don\n\n        min_energy = float('inf')\n\n        for theta in params[\"angles\"]:\n            # 2D rotation matrix for rotation about z-axis\n            cos_t, sin_t = np.cos(theta), np.sin(theta)\n            \n            # Rotated relative vectors\n            rot_v_acc = np.array([v_acc[0] * cos_t - v_acc[1] * sin_t, v_acc[0] * sin_t + v_acc[1] * cos_t, v_acc[2]])\n            rot_v_hyd = np.array([v_hyd[0] * cos_t - v_hyd[1] * sin_t, v_hyd[0] * sin_t + v_hyd[1] * cos_t, v_hyd[2]])\n\n            # Transformed absolute coordinates\n            q_don = s_don\n            q_acc = rot_v_acc + s_don\n            q_hyd = rot_v_hyd + s_don\n            \n            # Attraction energy\n            dist_sq_acc = np.sum((q_acc - s_acc)**2)\n            dist_sq_hyd = np.sum((q_hyd - s_hyd)**2)\n            energy_attr = -params[\"w_acc\"] * np.exp(-dist_sq_acc / (2 * params[\"sigma\"]**2)) \\\n                          -params[\"w_hyd\"] * np.exp(-dist_sq_hyd / (2 * params[\"sigma\"]**2))\n\n            # Clash penalty\n            energy_clash = 0.0\n            clash_R_sq = params[\"clash_R\"]**2\n            clash_points = [q_don, q_acc, q_hyd]\n            for point in clash_points:\n                if np.sum((point - params[\"clash_C\"])**2)  clash_R_sq:\n                    energy_clash = params[\"clash_lambda\"]\n                    break\n            \n            total_energy = energy_attr + energy_clash\n            if total_energy  min_energy:\n                min_energy = total_energy\n        \n        return min_energy\n\n    # --- Main Cascade Logic ---\n    results = []\n    \n    # Pre-calculate molecule properties that don't depend on test case parameters\n    for mol in MOLECULES:\n        mol['tanimoto'] = tanimoto_coeff(mol['fp'], F_Q)\n        mol['distances'] = internal_distances(mol['coords'])\n\n    for case in test_cases:\n        tau_sim, d_star, delta = case\n        d_star_da, d_star_dh, d_star_ah = d_star\n\n        # Stage 1: 2D Similarity Filter\n        survivors_1 = []\n        for mol in MOLECULES:\n            if mol['tanimoto'] >= tau_sim:\n                survivors_1.append(mol)\n\n        # Stage 2: 3D Pharmacophore Filter\n        survivors_2 = []\n        for mol in survivors_1:\n            d_da, d_dh, d_ah = mol['distances']\n            if (abs(d_da - d_star_da) = delta and\n                abs(d_dh - d_star_dh) = delta and\n                abs(d_ah - d_star_ah) = delta):\n                survivors_2.append(mol)\n        \n        # Stage 3: Docking and Selection\n        if not survivors_2:\n            results.append(-1)\n            continue\n            \n        best_score = float('inf')\n        best_mol_idx = -1\n\n        for mol in survivors_2:\n            score = docking_score(mol, RECEPTOR_SITES, DOCKING_PARAMS)\n            if score  best_score:\n                best_score = score\n                best_mol_idx = mol[\"id\"]\n        \n        results.append(best_mol_idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2440164"}, {"introduction": "Running a virtual screen is only half the battle; the true test is in evaluating its performance. This practice [@problem_id:2440123] focuses on the essential task of quantifying and comparing the success of screening campaigns. You will implement standard validation metrics like the Area Under the ROC Curve ($AUC$) and Enrichment Factor ($EF$) to critically assess results from two common scenarios: screening against an experimental crystal structure versus a computationally-derived homology model.", "problem": "You are given the outcomes of two virtual screens of the same ligand set against the same target protein: one using an X-ray crystal structure and one using a high-quality homology model. For each screen, a real-valued docking score is provided for every ligand, where lower scores indicate stronger predicted binding. A binary activity label is also provided for each ligand, where $1$ denotes an experimentally confirmed active and $0$ denotes an inactive. You must quantify and compare the ranking quality of the two screens using the following definitions.\n\nLet the ligand index set be $\\{0,1,\\dots,N-1\\}$. Let $y(j) \\in \\{0,1\\}$ be the ground-truth activity label for ligand $j$, with the active index set $A = \\{ j \\mid y(j) = 1 \\}$ and inactive index set $I = \\{ j \\mid y(j) = 0 \\}$. Let $s_{C}(j)$ be the docking score from the X-ray crystal structure screen and $s_{H}(j)$ be the docking score from the homology model screen. Lower scores are better.\n\nDefine, for a given model $M \\in \\{C,H\\}$ with scores $s_{M}(j)$:\n1. Receiver Operating Characteristic (ROC) area under the curve (AUC): \n   $$\\mathrm{AUC}(M) = \\frac{1}{|A|\\cdot|I|} \\sum_{a \\in A} \\sum_{i \\in I} \\phi\\big(s_{M}(a), s_{M}(i)\\big),$$\n   where \n   $$\\phi(x,y) = \\begin{cases}\n   1  \\text{if } x  y,\\\\\n   \\tfrac{1}{2}  \\text{if } x = y,\\\\\n   0  \\text{if } x  y,\n   \\end{cases}$$\n   reflecting the probability that a randomly chosen active has a strictly better (lower) score than a randomly chosen inactive, with ties contributing $\\tfrac{1}{2}$.\n\n2. Early enrichment factor at fraction $f \\in (0,1]$:\n   - Let $T = f \\cdot N$ (assumed to be an integer in the test suite below). Rank ligands by ascending $s_{M}(j)$. If a tie occurs at the selection boundary, break ties by choosing smaller indices first so that exactly $T$ ligands are selected.\n   - Let $\\mathrm{TP}_{f}(M)$ be the number of actives among these top $T$ ligands. Let $|A|$ be the total number of actives.\n   - Define \n     $$\\mathrm{EF}_{f}(M) = \\frac{\\mathrm{TP}_{f}(M)}{f \\cdot |A|}.$$\n\n3. Jaccard index of the top-$K$ ligand sets between the two models:\n   - For each model, form the top-$K$ set by taking the $K$ ligands with the smallest scores (ties broken by smaller indices first to obtain exactly $K$ ligands).\n   - Let $S_{C}^{(K)}$ and $S_{H}^{(K)}$ be these two sets. Define\n     $$J^{(K)} = \\frac{\\left| S_{C}^{(K)} \\cap S_{H}^{(K)} \\right|}{\\left| S_{C}^{(K)} \\cup S_{H}^{(K)} \\right|}.$$\n\nFor each test case below, compute the $5$-tuple \n$$\\left[ \\mathrm{AUC}(C),\\ \\mathrm{AUC}(H),\\ \\mathrm{EF}_{f}(C),\\ \\mathrm{EF}_{f}(H),\\ J^{(K)} \\right],$$\nwith all values rounded to $6$ decimal places.\n\nTest suite (each case specifies $N$, the two score lists, the activity labels, the fraction $f$, and the integer $K$):\n\n- Case $1$:\n  - $N = 12$\n  - $s_{C} = [-9.8,\\ -7.3,\\ -10.5,\\ -6.8,\\ -8.1,\\ -9.1,\\ -7.0,\\ -8.7,\\ -6.5,\\ -10.2,\\ -7.9,\\ -8.3]$\n  - $s_{H} = [-9.0,\\ -7.5,\\ -9.8,\\ -7.2,\\ -8.4,\\ -8.9,\\ -7.1,\\ -8.5,\\ -6.8,\\ -9.7,\\ -7.6,\\ -8.0]$\n  - $y = [1,\\ 0,\\ 1,\\ 0,\\ 0,\\ 1,\\ 0,\\ 0,\\ 0,\\ 1,\\ 0,\\ 0]$\n  - $f = 0.25$\n  - $K = 5$\n\n- Case $2$:\n  - $N = 10$\n  - $s_{C} = [-11.0,\\ -10.5,\\ -10.2,\\ -9.8,\\ -8.0,\\ -7.9,\\ -7.5,\\ -7.2,\\ -7.0,\\ -6.8]$\n  - $s_{H} = [-7.5,\\ -7.4,\\ -7.3,\\ -7.2,\\ -10.0,\\ -9.8,\\ -9.5,\\ -9.2,\\ -9.0,\\ -8.8]$\n  - $y = [1,\\ 1,\\ 1,\\ 1,\\ 0,\\ 0,\\ 0,\\ 0,\\ 0,\\ 0]$\n  - $f = 0.2$\n  - $K = 3$\n\n- Case $3$:\n  - $N = 8$\n  - $s_{C} = [-8.0,\\ -9.0,\\ -8.0,\\ -9.0,\\ -8.0,\\ -8.0,\\ -9.0,\\ -8.0]$\n  - $s_{H} = [-8.5,\\ -8.5,\\ -8.5,\\ -8.5,\\ -8.5,\\ -8.5,\\ -8.5,\\ -8.5]$\n  - $y = [0,\\ 1,\\ 0,\\ 1,\\ 0,\\ 0,\\ 1,\\ 0]$\n  - $f = 0.5$\n  - $K = 4$\n\nFinal output format: Your program should produce a single line of output containing a list of per-case results, where each per-case result is the $5$-tuple described above, rounded to $6$ decimal places. The single line must be a valid list-of-lists without any spaces. For example: $[[x_{11},x_{12},x_{13},x_{14},x_{15}],[x_{21},x_{22},x_{23},x_{24},x_{25}],\\dots]$ where each $x_{ij}$ is a decimal number with exactly $6$ digits after the decimal point.", "solution": "The problem statement has been rigorously evaluated and is deemed valid. It is scientifically grounded in the field of computational drug discovery, well-posed with precise mathematical definitions and explicit test cases, and objective in its formulation. All necessary data, conditions, and constraints are provided, and there are no logical contradictions or ambiguities. I will therefore proceed with the derivation of the solution.\n\nThe task is to evaluate and compare the performance of two virtual screening models—one based on an X-ray crystal structure ($C$) and another on a homology model ($H$)—using three distinct metrics: the Area Under the Receiver Operating Characteristic Curve ($\\mathrm{AUC}$), the Early Enrichment Factor ($\\mathrm{EF}_f$), and the Jaccard index ($J^{(K)}$). The solution requires a systematic implementation of the algorithms for these metrics, paying strict attention to the specified tie-breaking rules.\n\nLet the set of all $N$ ligands be indexed by $j \\in \\{0, 1, \\dots, N-1\\}$. For each ligand $j$, we are given a binary activity label $y(j)$ and two docking scores, $s_C(j)$ and $s_H(j)$.\n\nFirst, we define helper sets based on the activity labels: the set of active ligands $A = \\{j \\mid y(j) = 1\\}$ and the set of inactive ligands $I = \\{j \\mid y(j) = 0\\}$, with cardinalities $|A|$ and $|I|$ respectively.\n\nThe algorithmic approach for computing each required quantity is as follows:\n\n1.  **Area Under the ROC Curve ($\\mathrm{AUC}(M)$)**\n\nThe $\\mathrm{AUC}$ for a model $M \\in \\{C, H\\}$ is a measure of its ability to rank active ligands higher than inactive ones. The provided formula is a direct implementation of the Mann-Whitney U test statistic, which is equivalent to the $\\mathrm{AUC}$:\n$$\n\\mathrm{AUC}(M) = \\frac{1}{|A|\\cdot|I|} \\sum_{a \\in A} \\sum_{i \\in I} \\phi\\big(s_{M}(a), s_{M}(i)\\big)\n$$\nwhere the function $\\phi(x, y)$ evaluates to $1$ if $x  y$, $\\frac{1}{2}$ if $x = y$, and $0$ if $x  y$. This corresponds to the probability that a randomly selected active ligand has a better (lower) score than a randomly selected inactive ligand.\n\nThe algorithm is a direct implementation of this formula:\n- Separate the scores $s_M$ into two groups: active scores $\\{s_M(a) \\mid a \\in A\\}$ and inactive scores $\\{s_M(i) \\mid i \\in I\\}$.\n- Initialize a sum, $\\Sigma_\\phi = 0$.\n- For each active score $s_M(a)$, iterate through all inactive scores $s_M(i)$ and add $\\phi(s_M(a), s_M(i))$ to the sum $\\Sigma_\\phi$.\n- The final $\\mathrm{AUC}(M)$ is computed as $\\frac{\\Sigma_\\phi}{|A| \\cdot |I|}$. This computation must be performed for both models, $C$ and $H$.\n\n2.  **Early Enrichment Factor ($\\mathrm{EF}_{f}(M)$)**\n\nThe $\\mathrm{EF}_f$ metric quantifies how many active ligands are found within the top-scoring fraction $f$ of the ranked list, compared to a random selection.\n$$\n\\mathrm{EF}_{f}(M) = \\frac{\\mathrm{TP}_{f}(M)}{f \\cdot |A|}\n$$\nThe key to this calculation is the correct ranking of ligands. The problem specifies that ligands are to be ranked by ascending score $s_M(j)$, with ties broken by choosing the smaller ligand index $j$ first.\n\nThe algorithm proceeds as follows:\n- For a given model $M$, create a list of tuples $(s_M(j), j)$ for all ligands $j \\in \\{0, \\dots, N-1\\}$.\n- Perform a stable sort on this list, first by score (ascending) and then by index (ascending). This correctly implements the specified tie-breaking rule.\n- Determine the number of ligands to select, $T = f \\cdot N$. This is given to be an integer.\n- Select the first $T$ ligands from the sorted list.\n- Count the number of true positives, $\\mathrm{TP}_f(M)$, which is the number of active ligands (where $y(j)=1$) within this top-$T$ set.\n- Calculate the enrichment factor using the formula above. The denominator $f \\cdot |A|$ represents the expected number of actives in a random selection of $T$ ligands.\n\n3.  **Jaccard Index ($J^{(K)}$)**\n\nThe Jaccard index measures the similarity between the top-$K$ ligand sets as predicted by the two models, $C$ and $H$.\n$$\nJ^{(K)} = \\frac{\\left| S_{C}^{(K)} \\cap S_{H}^{(K)} \\right|}{\\left| S_{C}^{(K)} \\cup S_{H}^{(K)} \\right|}\n$$\nThe top-$K$ sets, $S_C^{(K)}$ and $S_H^{(K)}$, are constructed using the same ranking and tie-breaking procedure as for the enrichment factor.\n\nThe algorithm is:\n- For model $C$, generate the ranked list of ligands and select the indices of the top $K$ ligands to form the set $S_C^{(K)}$.\n- Repeat the process for model $H$ to form the set $S_H^{(K)}$.\n- Compute the cardinality of the intersection of these two sets, $|S_C^{(K)} \\cap S_H^{(K)}|$.\n- Compute the cardinality of the union of these two sets, $|S_C^{(K)} \\cup S_H^{(K)}|$. Note that $|S_C^{(K)} \\cup S_H^{(K)}| = |S_C^{(K)}| + |S_H^{(K)}| - |S_C^{(K)} \\cap S_H^{(K)}| = 2K - |S_C^{(K)} \\cap S_H^{(K)}|$.\n- The Jaccard index is the ratio of these two cardinalities.\n\nFor each test case, these three algorithms are applied to the provided data to compute the five required values: $\\mathrm{AUC}(C)$, $\\mathrm{AUC}(H)$, $\\mathrm{EF}_f(C)$, $\\mathrm{EF}_f(H)$, and $J^{(K)}$. The results are then rounded to $6$ decimal places and formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_top_n_indices(scores: np.ndarray, n: int) - list[int]:\n    \"\"\"\n    Ranks ligands by score (ascending) and index (ascending for ties)\n    and returns the indices of the top n ligands.\n    \"\"\"\n    N = len(scores)\n    # Create pairs of (score, index) for sorting.\n    indexed_scores = sorted([(scores[j], j) for j in range(N)])\n    # Extract indices from the top n sorted pairs.\n    top_indices = [index for score, index in indexed_scores[:n]]\n    return top_indices\n\ndef calculate_auc(scores: np.ndarray, y: np.ndarray) - float:\n    \"\"\"\n    Calculates the Area Under the ROC Curve (AUC).\n    \"\"\"\n    active_indices = np.where(y == 1)[0]\n    inactive_indices = np.where(y == 0)[0]\n\n    num_actives = len(active_indices)\n    num_inactives = len(inactive_indices)\n\n    if num_actives == 0 or num_inactives == 0:\n        return 0.5  # Per convention, AUC is 0.5 if one class is missing.\n\n    active_scores = scores[active_indices]\n    inactive_scores = scores[inactive_indices]\n\n    # Vectorized comparison\n    # Reshape for broadcasting: active_scores (num_actives, 1), inactive_scores (1, num_inactives)\n    # Resulting comparison matrices have shape (num_actives, num_inactives)\n    less_than_count = np.sum(active_scores[:, np.newaxis]  inactive_scores)\n    equal_to_count = np.sum(active_scores[:, np.newaxis] == inactive_scores)\n\n    phi_sum = less_than_count + 0.5 * equal_to_count\n    \n    auc = phi_sum / (num_actives * num_inactives)\n    return auc\n\ndef calculate_ef(scores: np.ndarray, y: np.ndarray, f: float) - float:\n    \"\"\"\n    Calculates the Early Enrichment Factor at fraction f.\n    \"\"\"\n    N = len(y)\n    num_actives_total = np.sum(y)\n    \n    if num_actives_total == 0:\n        return 0.0 # No actives to enrich.\n\n    T = int(f * N)\n    if T == 0:\n        return 0.0\n\n    top_indices = get_top_n_indices(scores, T)\n    \n    # Count true positives in the top T ligands\n    tp_f = np.sum(y[top_indices])\n    \n    # Denominator is the expected number of actives in a random selection of size T\n    ef = tp_f / (f * num_actives_total)\n    return ef\n\ndef calculate_jaccard(scores_c: np.ndarray, scores_h: np.ndarray, k: int) - float:\n    \"\"\"\n    Calculates the Jaccard index between the top-K sets of two models.\n    \"\"\"\n    if k == 0:\n        return 1.0 if len(scores_c) == 0 else 0.0\n\n    top_k_indices_c = get_top_n_indices(scores_c, k)\n    top_k_indices_h = get_top_n_indices(scores_h, k)\n\n    set_c = set(top_k_indices_c)\n    set_h = set(top_k_indices_h)\n    \n    intersection_size = len(set_c.intersection(set_h))\n    union_size = len(set_c.union(set_h))\n\n    if union_size == 0:\n        return 1.0 # By convention, Jaccard of two empty sets is 1.\n\n    jaccard = intersection_size / union_size\n    return jaccard\n\ndef process_case(s_c: list, s_h: list, y_labels: list, f: float, k: int) - list[float]:\n    \"\"\"\n    Processes a single test case and computes all required metrics.\n    \"\"\"\n    s_c_np = np.array(s_c)\n    s_h_np = np.array(s_h)\n    y_np = np.array(y_labels)\n\n    auc_c = calculate_auc(s_c_np, y_np)\n    auc_h = calculate_auc(s_h_np, y_np)\n\n    ef_c = calculate_ef(s_c_np, y_np, f)\n    ef_h = calculate_ef(s_h_np, y_np, f)\n    \n    jaccard_k = calculate_jaccard(s_c_np, s_h_np, k)\n\n    return [auc_c, auc_h, ef_c, ef_h, jaccard_k]\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the calculations, and prints the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 12,\n            \"s_C\": [-9.8, -7.3, -10.5, -6.8, -8.1, -9.1, -7.0, -8.7, -6.5, -10.2, -7.9, -8.3],\n            \"s_H\": [-9.0, -7.5, -9.8, -7.2, -8.4, -8.9, -7.1, -8.5, -6.8, -9.7, -7.6, -8.0],\n            \"y\": [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n            \"f\": 0.25,\n            \"K\": 5\n        },\n        {\n            \"N\": 10,\n            \"s_C\": [-11.0, -10.5, -10.2, -9.8, -8.0, -7.9, -7.5, -7.2, -7.0, -6.8],\n            \"s_H\": [-7.5, -7.4, -7.3, -7.2, -10.0, -9.8, -9.5, -9.2, -9.0, -8.8],\n            \"y\": [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n            \"f\": 0.2,\n            \"K\": 3\n        },\n        {\n            \"N\": 8,\n            \"s_C\": [-8.0, -9.0, -8.0, -9.0, -8.0, -8.0, -9.0, -8.0],\n            \"s_H\": [-8.5, -8.5, -8.5, -8.5, -8.5, -8.5, -8.5, -8.5],\n            \"y\": [0, 1, 0, 1, 0, 0, 1, 0],\n            \"f\": 0.5,\n            \"K\": 4\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_tuple = process_case(case[\"s_C\"], case[\"s_H\"], case[\"y\"], case[\"f\"], case[\"K\"])\n        all_results.append(result_tuple)\n    \n    # Manually construct the output string to match the required format without spaces.\n    formatted_results = []\n    for res_tuple in all_results:\n        # Format each float to 6 decimal places and join into a string like \"[x.xxxxxx,y.yyyyyy,...]\"\n        formatted_tuple_str = f\"[{','.join([f'{v:.6f}' for v in res_tuple])}]\"\n        formatted_results.append(formatted_tuple_str)\n    \n    # Join the individual case strings into the final list-of-lists format \"[[...],[...]]\"\n    final_output_str = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```", "id": "2440123"}, {"introduction": "While classical scoring functions are powerful, machine learning offers a path to creating even more accurate, data-driven models for pose selection. In this advanced exercise [@problem_id:2440145], you will step into the role of a model developer, training a logistic regression classifier to distinguish between high-quality 'active' poses and incorrect 'decoy' poses. This practice introduces the foundational principles of building a custom statistical scoring function, from feature standardization to model optimization and evaluation.", "problem": "You are tasked with implementing from first principles a binary classifier for pose quality in virtual screening. Each data point represents a docked protein–ligand pose summarized by five physically meaningful features commonly used in structure-based virtual screening. A \"true active pose\" is a pose that is consistent with experimentally verified binding conformations, while a \"decoy pose\" is a plausible but incorrect alternative produced by a docking program. Your classifier must distinguish actives from decoys using a principled probabilistic model and must be trained only on the provided training sets, then evaluated on the provided test sets.\n\nYou must build a model grounded in the following fundamental bases:\n- The conditional probability of a binary label given features is modeled by a Generalized Linear Model with a logistic link, that is, for feature vector $\\mathbf{x} \\in \\mathbb{R}^d$, the probability of the positive class is $p(y=1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)$, where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$, $\\mathbf{w} \\in \\mathbb{R}^d$ is the weight vector, and $b \\in \\mathbb{R}$ is the intercept.\n- Maximum Likelihood Estimation for independent observations yields minimization of the negative log-likelihood, which, for the logistic model, is equivalent to minimizing the empirical cross-entropy loss.\n- To reduce overfitting, apply $\\ell_2$ (ridge) regularization on $\\mathbf{w}$ (but not on $b$) with regularization strength $\\lambda  0$, yielding a penalized objective that is the sum of the negative log-likelihood and $\\frac{\\lambda}{2}\\lVert \\mathbf{w} \\rVert_2^2$.\n- The optimal Bayes decision rule under $0$–$1$ loss thresholds the posterior $p(y=1 \\mid \\mathbf{x})$; however, to evaluate ranking quality independent of a specific threshold, use the Area Under the Receiver Operating Characteristic Curve (AUC), defined as the probability that a randomly chosen positive example receives a higher score than a randomly chosen negative example. For finite samples with possible ties, this can be computed from average ranks of the predicted scores.\n\nYou must implement the following algorithmic design, derived from these principles:\n1. Standardize each feature dimension to zero mean and unit variance using training-set statistics only. Specifically, for training matrix $X_{\\text{train}} \\in \\mathbb{R}^{n \\times d}$, compute per-feature mean vector $\\boldsymbol{\\mu} \\in \\mathbb{R}^d$ and standard deviation vector $\\boldsymbol{\\sigma} \\in \\mathbb{R}^d$ with $\\sigma_j = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_{ij} - \\mu_j)^2}$. Transform both training and test features by $\\tilde{\\mathbf{x}} = (\\mathbf{x} - \\boldsymbol{\\mu}) \\oslash \\boldsymbol{\\sigma}$, where division is element-wise. If any $\\sigma_j = 0$, set it to $1$ to avoid division by $0$.\n2. Fit $\\mathbf{w}$ and $b$ by minimizing the average regularized negative log-likelihood on the standardized training features using batch gradient descent. Use a learning rate schedule $\\alpha_t = \\frac{\\alpha_0}{1 + t/T_0}$ with iteration index $t \\in \\{0,1,2,\\dots\\}$, and terminate when the Euclidean norm of the gradient drops below a tolerance $\\epsilon$ or after a maximum of $T_{\\max}$ iterations. The intercept $b$ must not be regularized.\n3. Compute predicted probabilities on the test set and evaluate the AUC. For AUC, use the finite-sample definition based on average ranks of the predicted probabilities with ties assigned their average rank. The AUC must be reported as a float.\n4. For reproducibility, do not use any randomness. Your implementation must be deterministic.\n\nFeature definitions (for each pose):\n- $x_1$: docking score in $\\text{kcal/mol}$ (more negative indicates better binding).\n- $x_2$: number of protein–ligand hydrogen bonds (nonnegative integer).\n- $x_3$: fraction of hydrophobic contact surface (unitless between $0$ and $1$).\n- $x_4$: steric clash penalty (nonnegative real; larger is worse).\n- $x_5$: ligand strain energy in $\\text{kcal/mol}$ (nonnegative real; larger is worse).\n\nLabels: use $y=1$ for true active poses and $y=0$ for decoy poses.\n\nYou will be given three test cases. Each test case specifies a training set, a test set, and a regularization strength $\\lambda$. For each test case, you must output the test AUC as a decimal rounded to exactly $6$ decimal places. There are no angles or physical units in the required outputs.\n\nTest Suite:\n- Test Case 1 (balanced, linearly separable tendencies, moderate regularization $\\lambda$):\n  - $\\lambda = 0.1$.\n  - Training set ($12$ rows, each row is $(x_1,x_2,x_3,x_4,x_5)$):\n    - Actives ($y=1$):\n      - $(-10.5, 4, 0.62, 0.0, 2.1)$\n      - $(-9.8, 3, 0.55, 0.1, 1.8)$\n      - $(-11.2, 5, 0.70, 0.0, 1.5)$\n      - $(-8.9, 3, 0.50, 0.2, 2.3)$\n      - $(-10.1, 4, 0.60, 0.1, 1.7)$\n      - $(-9.2, 2, 0.58, 0.1, 2.0)$\n    - Decoys ($y=0$):\n      - $(-6.0, 1, 0.33, 0.8, 5.5)$\n      - $(-5.2, 0, 0.25, 1.2, 6.2)$\n      - $(-7.1, 1, 0.40, 0.6, 4.8)$\n      - $(-6.5, 2, 0.38, 0.7, 5.2)$\n      - $(-5.8, 0, 0.20, 1.0, 6.0)$\n      - $(-7.5, 1, 0.35, 0.5, 4.5)$\n  - Test set ($8$ rows):\n    - Actives ($y=1$):\n      - $(-10.8, 4, 0.65, 0.0, 1.6)$\n      - $(-9.0, 3, 0.52, 0.2, 2.4)$\n      - $(-9.7, 2, 0.60, 0.1, 2.0)$\n      - $(-11.0, 5, 0.72, 0.0, 1.4)$\n    - Decoys ($y=0$):\n      - $(-6.2, 1, 0.30, 0.9, 5.7)$\n      - $(-5.5, 0, 0.22, 1.1, 6.3)$\n      - $(-7.0, 1, 0.42, 0.6, 4.6)$\n      - $(-6.7, 2, 0.36, 0.7, 5.0)$\n\n- Test Case 2 (class imbalance, stronger regularization $\\lambda$):\n  - $\\lambda = 1.0$.\n  - Training set ($16$ rows):\n    - Actives ($y=1$):\n      - $(-10.2, 4, 0.60, 0.1, 1.9)$\n      - $(-9.5, 3, 0.54, 0.1, 2.1)$\n      - $(-11.5, 5, 0.68, 0.0, 1.2)$\n      - $(-8.7, 2, 0.50, 0.3, 2.5)$\n    - Decoys ($y=0$):\n      - $(-6.3, 1, 0.35, 0.7, 5.2)$\n      - $(-5.9, 0, 0.28, 1.0, 6.0)$\n      - $(-7.2, 1, 0.40, 0.6, 4.7)$\n      - $(-6.6, 2, 0.38, 0.7, 5.1)$\n      - $(-5.7, 0, 0.24, 1.1, 6.4)$\n      - $(-7.4, 1, 0.37, 0.5, 4.9)$\n      - $(-6.8, 1, 0.36, 0.8, 5.5)$\n      - $(-5.5, 0, 0.20, 1.2, 6.6)$\n      - $(-6.1, 0, 0.25, 1.0, 6.2)$\n      - $(-7.0, 1, 0.39, 0.6, 4.8)$\n      - $(-6.4, 1, 0.34, 0.7, 5.3)$\n      - $(-5.8, 0, 0.22, 1.1, 6.1)$\n  - Test set ($10$ rows):\n    - Actives ($y=1$):\n      - $(-10.0, 4, 0.61, 0.1, 1.8)$\n      - $(-9.2, 3, 0.53, 0.2, 2.2)$\n      - $(-11.1, 5, 0.70, 0.0, 1.3)$\n      - $(-8.9, 2, 0.49, 0.3, 2.6)$\n    - Decoys ($y=0$):\n      - $(-6.0, 1, 0.33, 0.7, 5.4)$\n      - $(-5.6, 0, 0.26, 1.1, 6.5)$\n      - $(-7.1, 1, 0.41, 0.6, 4.6)$\n      - $(-6.5, 2, 0.37, 0.8, 5.2)$\n      - $(-5.9, 0, 0.23, 1.0, 6.3)$\n      - $(-6.9, 1, 0.35, 0.7, 5.0)$\n\n- Test Case 3 (near-noninformative features, very strong regularization $\\lambda$):\n  - $\\lambda = 10.0$.\n  - Training set ($10$ rows):\n    - Actives ($y=1$):\n      - $(-7.4, 2, 0.44, 0.5, 4.1)$\n      - $(-7.6, 2, 0.46, 0.6, 3.9)$\n      - $(-7.5, 1, 0.45, 0.5, 4.0)$\n      - $(-7.3, 2, 0.47, 0.5, 4.2)$\n      - $(-7.7, 2, 0.43, 0.6, 3.8)$\n    - Decoys ($y=0$):\n      - $(-7.5, 2, 0.45, 0.5, 4.0)$\n      - $(-7.6, 2, 0.44, 0.5, 4.1)$\n      - $(-7.4, 1, 0.46, 0.6, 3.9)$\n      - $(-7.7, 2, 0.45, 0.5, 4.2)$\n      - $(-7.3, 2, 0.44, 0.6, 3.9)$\n  - Test set ($8$ rows):\n    - Actives ($y=1$):\n      - $(-7.5, 2, 0.45, 0.5, 4.0)$\n      - $(-7.6, 2, 0.46, 0.5, 4.1)$\n      - $(-7.4, 1, 0.44, 0.6, 3.9)$\n      - $(-7.7, 2, 0.45, 0.5, 4.0)$\n    - Decoys ($y=0$):\n      - $(-7.4, 2, 0.45, 0.5, 4.0)$\n      - $(-7.6, 2, 0.45, 0.6, 3.9)$\n      - $(-7.5, 1, 0.46, 0.5, 4.1)$\n      - $(-7.7, 2, 0.44, 0.5, 3.9)$\n\nImplementation requirements:\n- Use batch gradient descent on the standardized features with an explicit bias term. Only the weight vector $\\mathbf{w}$ is penalized; the bias $b$ is not.\n- Use $\\alpha_0 = 0.1$, $T_0 = 2000$, $\\epsilon = 10^{-9}$, and $T_{\\max} = 10000$.\n- Compute AUC using average ranks with ties, and return it as a float rounded to $6$ decimal places.\n\nFinal Output Specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the three AUC values for Test Case $1$, Test Case $2$, and Test Case $3$, in that order. For example: \"[0.987654,0.912345,0.503210]\".", "solution": "The user has specified a problem that is valid. The problem requires the implementation of a logistic regression classifier for a task in computational drug discovery, specifically, distinguishing between correct (active) and incorrect (decoy) protein-ligand binding poses from virtual screening. The problem is scientifically grounded, well-posed, and provides all necessary data and algorithmic specifications. The validation checklist reveals no flaws.\n\nThe problem is fundamentally a binary classification task. We are given a dataset of $n$ observations, where each observation consists of a feature vector $\\mathbf{x}_i \\in \\mathbb{R}^d$ and a corresponding binary label $y_i \\in \\{0, 1\\}$. Our objective is to construct a model that, given a new feature vector $\\mathbf{x}$, predicts the probability of the positive class, $p(y=1 \\mid \\mathbf{x})$.\n\n**1. Probabilistic Model and Objective Function**\n\nThe foundation of our classifier is the logistic regression model, a type of Generalized Linear Model. It models the conditional probability of the positive class as:\n$$\np(y=1 \\mid \\mathbf{x}; \\mathbf{w}, b) = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)\n$$\nwhere $\\mathbf{w} \\in \\mathbb{R}^d$ is a vector of weights, $b \\in \\mathbb{R}$ is a scalar intercept (or bias), and $\\sigma(z)$ is the logistic sigmoid function:\n$$\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n$$\nThis model posits that the log-odds of the positive class is a linear function of the features, i.e., $\\log\\left(\\frac{p}{1-p}\\right) = \\mathbf{w}^\\top \\mathbf{x} + b$.\n\nTo find the optimal parameters $(\\mathbf{w}, b)$, we employ the principle of Maximum Likelihood Estimation (MLE). For a set of $n$ independent and identically distributed training samples $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$, maximizing the likelihood of the data is equivalent to minimizing the negative log-likelihood (NLL). For logistic regression, this NLL is the binary cross-entropy loss:\n$$\nL_{\\text{NLL}}(\\mathbf{w}, b) = - \\sum_{i=1}^n \\left[ y_i \\log(\\sigma(\\mathbf{w}^\\top \\mathbf{x}_i + b)) + (1-y_i) \\log(1 - \\sigma(\\mathbf{w}^\\top \\mathbf{x}_i + b)) \\right]\n$$\n\nTo mitigate overfitting, where the model learns the training data too well at the expense of generalization to unseen data, we introduce an $\\ell_2$ regularization (or ridge) penalty on the weight vector $\\mathbf{w}$. The intercept $b$ is not regularized, as penalizing it would introduce a data-dependent bias. The final objective function to be minimized is the average regularized NLL:\n$$\nJ(\\mathbf{w}, b) = \\frac{1}{n} L_{\\text{NLL}}(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2\n$$\nwhere $\\lambda  0$ is the regularization strength hyperparameter, which controls the trade-off between fitting the data and keeping model weights small.\n\n**2. Data Standardization**\n\nThe features provided exist on different physical scales (e.g., energy in $\\text{kcal/mol}$, counts of hydrogen bonds, unitless fractions). Gradient-based optimization algorithms perform more effectively when features are on a comparable scale. Therefore, we standardize each feature dimension to have a mean of $0$ and a standard deviation of $1$. The statistics (mean vector $\\boldsymbol{\\mu}$ and standard deviation vector $\\boldsymbol{\\sigma}$) must be computed *only* from the training data:\n$$\n\\mu_j = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} x_{ij} \\quad \\text{and} \\quad \\sigma_j = \\sqrt{\\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (x_{ij} - \\mu_j)^2}\n$$\nThe transformation $\\tilde{\\mathbf{x}} = (\\mathbf{x} - \\boldsymbol{\\mu}) \\oslash \\boldsymbol{\\sigma}$ (element-wise division) is then applied to both the training and test sets. If a feature has zero variance in the training set ($\\sigma_j = 0$), we set its standard deviation to $1$ to avoid division by zero. Using training set statistics for the test set is critical to prevent information from the test set \"leaking\" into the training process.\n\n**3. Optimization by Batch Gradient Descent**\n\nThe objective function $J(\\mathbf{w}, b)$ is convex, which guarantees that gradient descent can find its unique global minimum. We use batch gradient descent, where the gradient is computed over the entire training set at each iteration. The partial derivatives of $J(\\mathbf{w}, b)$ with respect to the parameters are:\n$$\n\\nabla_{\\mathbf{w}} J = \\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\mathbf{w}^\\top \\mathbf{x}_i + b) - y_i)\\mathbf{x}_i + \\lambda \\mathbf{w} = \\frac{1}{n} X^\\top (\\mathbf{p} - \\mathbf{y}) + \\lambda \\mathbf{w}\n$$\n$$\n\\nabla_b J = \\frac{\\partial J}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\mathbf{w}^\\top \\mathbf{x}_i + b) - y_i)\n$$\nwhere $X \\in \\mathbb{R}^{n \\times d}$ is the matrix of standardized training features, and $\\mathbf{p}$ and $\\mathbf{y}$ are the vectors of predicted probabilities and true labels, respectively.\n\nThe parameters are initialized (e.g., to zero) and iteratively updated:\n$$\n\\mathbf{w}_{t+1} \\leftarrow \\mathbf{w}_t - \\alpha_t \\nabla_{\\mathbf{w}} J\n$$\n$$\nb_{t+1} \\leftarrow b_t - \\alpha_t \\nabla_b J\n$$\nThe learning rate $\\alpha_t$ is adjusted at each iteration $t$ according to the schedule $\\alpha_t = \\frac{\\alpha_0}{1 + t/T_0}$. The process terminates when the Euclidean norm of the full gradient vector, $\\lVert [\\nabla_{\\mathbf{w}} J, \\nabla_b J] \\rVert_2$, falls below a tolerance $\\epsilon$, or a maximum number of iterations $T_{\\max}$ is reached.\n\n**4. Performance Evaluation via AUC**\n\nFor virtual screening, the absolute predicted probabilities are often less important than the model's ability to rank true active poses higher than decoy poses. The Area Under the Receiver Operating Characteristic Curve (AUC) is the standard metric for this purpose. The AUC represents the probability that a randomly chosen positive sample is ranked higher than a randomly chosen negative sample.\n\nFor a finite sample set with possible ties in predicted scores, the AUC can be computed robustly using the Wilcoxon-Mann-Whitney U statistic. This is equivalent to calculating the sum of ranks for the positive samples. First, we compute the ranks of all predicted scores on the test set, assigning the average rank in case of ties. Let $n_1$ and $n_0$ be the number of positive and negative samples, respectively, and let $\\sum_{i \\in \\text{pos}} \\text{rank}(p_i)$ be the sum of ranks of the scores for the positive samples. The AUC is then given by:\n$$\n\\text{AUC} = \\frac{\\sum_{i \\in \\text{pos}} \\text{rank}(p_i) - \\frac{n_1(n_1+1)}{2}}{n_0 n_1}\n$$\nThis formulation is deterministic and provides a single scalar value measuring the ranking quality of the classifier, independent of any specific classification threshold.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import rankdata\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Main function to run the complete pipeline for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"lambda\": 0.1,\n            \"train_actives\": [\n                (-10.5, 4, 0.62, 0.0, 2.1), (-9.8, 3, 0.55, 0.1, 1.8),\n                (-11.2, 5, 0.70, 0.0, 1.5), (-8.9, 3, 0.50, 0.2, 2.3),\n                (-10.1, 4, 0.60, 0.1, 1.7), (-9.2, 2, 0.58, 0.1, 2.0)\n            ],\n            \"train_decoys\": [\n                (-6.0, 1, 0.33, 0.8, 5.5), (-5.2, 0, 0.25, 1.2, 6.2),\n                (-7.1, 1, 0.40, 0.6, 4.8), (-6.5, 2, 0.38, 0.7, 5.2),\n                (-5.8, 0, 0.20, 1.0, 6.0), (-7.5, 1, 0.35, 0.5, 4.5)\n            ],\n            \"test_actives\": [\n                (-10.8, 4, 0.65, 0.0, 1.6), (-9.0, 3, 0.52, 0.2, 2.4),\n                (-9.7, 2, 0.60, 0.1, 2.0), (-11.0, 5, 0.72, 0.0, 1.4)\n            ],\n            \"test_decoys\": [\n                (-6.2, 1, 0.30, 0.9, 5.7), (-5.5, 0, 0.22, 1.1, 6.3),\n                (-7.0, 1, 0.42, 0.6, 4.6), (-6.7, 2, 0.36, 0.7, 5.0)\n            ]\n        },\n        {\n            \"lambda\": 1.0,\n            \"train_actives\": [\n                (-10.2, 4, 0.60, 0.1, 1.9), (-9.5, 3, 0.54, 0.1, 2.1),\n                (-11.5, 5, 0.68, 0.0, 1.2), (-8.7, 2, 0.50, 0.3, 2.5)\n            ],\n            \"train_decoys\": [\n                (-6.3, 1, 0.35, 0.7, 5.2), (-5.9, 0, 0.28, 1.0, 6.0),\n                (-7.2, 1, 0.40, 0.6, 4.7), (-6.6, 2, 0.38, 0.7, 5.1),\n                (-5.7, 0, 0.24, 1.1, 6.4), (-7.4, 1, 0.37, 0.5, 4.9),\n                (-6.8, 1, 0.36, 0.8, 5.5), (-5.5, 0, 0.20, 1.2, 6.6),\n                (-6.1, 0, 0.25, 1.0, 6.2), (-7.0, 1, 0.39, 0.6, 4.8),\n                (-6.4, 1, 0.34, 0.7, 5.3), (-5.8, 0, 0.22, 1.1, 6.1)\n            ],\n            \"test_actives\": [\n                (-10.0, 4, 0.61, 0.1, 1.8), (-9.2, 3, 0.53, 0.2, 2.2),\n                (-11.1, 5, 0.70, 0.0, 1.3), (-8.9, 2, 0.49, 0.3, 2.6)\n            ],\n            \"test_decoys\": [\n                (-6.0, 1, 0.33, 0.7, 5.4), (-5.6, 0, 0.26, 1.1, 6.5),\n                (-7.1, 1, 0.41, 0.6, 4.6), (-6.5, 2, 0.37, 0.8, 5.2),\n                (-5.9, 0, 0.23, 1.0, 6.3), (-6.9, 1, 0.35, 0.7, 5.0)\n            ]\n        },\n        {\n            \"lambda\": 10.0,\n            \"train_actives\": [\n                (-7.4, 2, 0.44, 0.5, 4.1), (-7.6, 2, 0.46, 0.6, 3.9),\n                (-7.5, 1, 0.45, 0.5, 4.0), (-7.3, 2, 0.47, 0.5, 4.2),\n                (-7.7, 2, 0.43, 0.6, 3.8)\n            ],\n            \"train_decoys\": [\n                (-7.5, 2, 0.45, 0.5, 4.0), (-7.6, 2, 0.44, 0.5, 4.1),\n                (-7.4, 1, 0.46, 0.6, 3.9), (-7.7, 2, 0.45, 0.5, 4.2),\n                (-7.3, 2, 0.44, 0.6, 3.9)\n            ],\n            \"test_actives\": [\n                (-7.5, 2, 0.45, 0.5, 4.0), (-7.6, 2, 0.46, 0.5, 4.1),\n                (-7.4, 1, 0.44, 0.6, 3.9), (-7.7, 2, 0.45, 0.5, 4.0)\n            ],\n            \"test_decoys\": [\n                (-7.4, 2, 0.45, 0.5, 4.0), (-7.6, 2, 0.45, 0.6, 3.9),\n                (-7.5, 1, 0.46, 0.5, 4.1), (-7.7, 2, 0.44, 0.5, 3.9)\n            ]\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        auc = solve_case(case)\n        results.append(f\"{auc:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef standardize_features(X_train, X_test):\n    \"\"\"Standardize features based on training set statistics.\"\"\"\n    mu = np.mean(X_train, axis=0)\n    sigma = np.std(X_train, axis=0)\n    # Avoid division by zero for features with no variance\n    sigma[sigma == 0] = 1.0\n    X_train_std = (X_train - mu) / sigma\n    X_test_std = (X_test - mu) / sigma\n    return X_train_std, X_test_std\n\ndef train_logistic_regression(X_train, y_train, lambda_val, alpha_0, T_0, epsilon, T_max):\n    \"\"\"Train a logistic regression model with L2 regularization using batch gradient descent.\"\"\"\n    n_train, d = X_train.shape\n    w = np.zeros(d)\n    b = 0.0\n\n    for t in range(T_max):\n        alpha_t = alpha_0 / (1 + t / T_0)\n        \n        # Linear combination and sigmoid activation\n        z = X_train @ w + b\n        p = expit(z)\n        \n        error = p - y_train\n        \n        # Gradients\n        grad_w = (X_train.T @ error) / n_train + lambda_val * w\n        grad_b = np.mean(error)\n        \n        # Check for convergence\n        grad_norm = np.sqrt(np.sum(grad_w**2) + grad_b**2)\n        if grad_norm  epsilon:\n            break\n            \n        # Update parameters\n        w -= alpha_t * grad_w\n        b -= alpha_t * grad_b\n        \n    return w, b\n\ndef calculate_auc(y_true, y_scores):\n    \"\"\"Calculate AUC using the rank-based Wilcoxon-Mann-Whitney U-statistic formula.\"\"\"\n    n_pos = np.sum(y_true == 1)\n    n_neg = np.sum(y_true == 0)\n\n    if n_pos == 0 or n_neg == 0:\n        return 0.5\n\n    ranks = rankdata(y_scores, method='average')\n    sum_ranks_pos = np.sum(ranks[y_true == 1])\n    \n    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg)\n    return auc\n\ndef solve_case(case):\n    \"\"\"Solve one specific test case.\"\"\"\n    lambda_val = case['lambda']\n    X_train_actives = np.array(case['train_actives'])\n    X_train_decoys = np.array(case['train_decoys'])\n    X_test_actives = np.array(case['test_actives'])\n    X_test_decoys = np.array(case['test_decoys'])\n    \n    # Assemble full datasets\n    X_train = np.vstack((X_train_actives, X_train_decoys))\n    y_train = np.array([1] * len(X_train_actives) + [0] * len(X_train_decoys))\n    X_test = np.vstack((X_test_actives, X_test_decoys))\n    y_test = np.array([1] * len(X_test_actives) + [0] * len(X_test_decoys))\n\n    # Standardize features\n    X_train_std, X_test_std = standardize_features(X_train, X_test)\n    \n    # Training hyperparameters\n    hparams = {'alpha_0': 0.1, 'T_0': 2000, 'epsilon': 1e-9, 'T_max': 10000}\n    w, b = train_logistic_regression(X_train_std, y_train, lambda_val, **hparams)\n    \n    # Predict probabilities on the test set\n    z_test = X_test_std @ w + b\n    p_test = expit(z_test)\n    \n    # Evaluate performance using AUC\n    auc = calculate_auc(y_test, p_test)\n    \n    return auc\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2440145"}]}