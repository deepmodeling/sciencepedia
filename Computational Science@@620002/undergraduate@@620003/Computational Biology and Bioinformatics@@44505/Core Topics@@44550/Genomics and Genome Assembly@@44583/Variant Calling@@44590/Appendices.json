{"hands_on_practices": [{"introduction": "At its core, variant calling is an exercise in statistical inference, where we weigh the evidence for and against the presence of a genetic variation. This practice delves into the interpretation of allele balance, the proportion of sequencing reads supporting a variant allele, which is rarely a perfect $0.5$ for heterozygotes in real data. By building a probabilistic model that accounts for complicating factors like sequencing errors and copy number variations, you will learn to determine which biological scenario is most consistent with the observed data, a fundamental skill for any bioinformatician.", "problem": "A whole-genome short-read sequencing experiment on a germline sample reports a candidate single nucleotide polymorphism (SNP) at a locus with total depth $n = 50$ and $k = 45$ reads supporting the alternate allele, giving an allele balance $AB = k/n = 0.9$. Assume per-base sequencing error rate $\\epsilon = 0.01$, unbiased mapping, and independent reads. Let the expected fraction of reads supporting the alternate allele be determined by the underlying allele copy proportions and sequencing error: if there are $a$ copies of the alternate allele and $r$ copies of the reference allele at this locus due to a copy number variation (CNV), then the true alternate-allele proportion is $p = a/(a+r)$, and a read supports the alternate base with probability $p_{\\mathrm{eff}} = p(1-\\epsilon) + (1-p)\\epsilon$. The sample is germline, and at this locus the total copy number is known to be in $\\{1,2,3,4\\}$.\n\nWhich interpretation is most consistent with the observed allele balance $AB = 0.9$ under these assumptions?\n\nA. A true homozygous alternate variant in a diploid region (no CNV), i.e., $a = 2$, $r = 0$.\n\nB. A heterozygous variant in a region with total copy number $3$, with $a = 2$ and $r = 1$.\n\nC. A heterozygous variant in a region with total copy number $4$, with $a = 3$ and $r = 1$.\n\nD. No true variant is present; the $k = 45$ alternate reads arise entirely from random sequencing errors at rate $\\epsilon = 0.01$.\n\nSelect the single best choice.", "solution": "The problem statement has been validated and found to be scientifically sound, well-posed, objective, and self-contained. The data provided are realistic and sufficient for a rigorous analysis. We shall now proceed to the solution.\n\nThe task is to determine which of the four proposed scenarios is most consistent with the experimental observation of $k=45$ reads supporting an alternate allele out of a total sequencing depth of $n=50$. The observed allele balance is therefore $AB = k/n = 45/50 = 0.9$. Consistency is to be evaluated in a statistical sense, meaning we must find the scenario under which the observed data are most probable, i.e., have the highest likelihood.\n\nThe number of reads supporting the alternate allele, $k$, can be modeled as a random variable following a binomial distribution, $k \\sim \\mathrm{Binomial}(n, p_{\\mathrm{eff}})$, where $p_{\\mathrm{eff}}$ is the effective probability that a single read supports the alternate allele. The likelihood of observing $k$ alternate reads in a sample of $n$ reads is given by the binomial probability mass function:\n$$L(p_{\\mathrm{eff}} | k, n) = P(k | n, p_{\\mathrm{eff}}) = \\binom{n}{k} (p_{\\mathrm{eff}})^k (1-p_{\\mathrm{eff}})^{n-k}$$\nSince the term $\\binom{n}{k} = \\binom{50}{45}$ is a constant for all scenarios, we only need to compare the values of $(p_{\\mathrm{eff}})^k (1-p_{\\mathrm{eff}})^{n-k}$ for each option. For numerical stability and convenience, it is often simpler to compare the log-likelihoods. The term to be maximized is proportional to the log-likelihood:\n$$\\ln(L) \\propto k \\ln(p_{\\mathrm{eff}}) + (n-k) \\ln(1 - p_{\\mathrm{eff}})$$\nSubstituting the observed values $k=45$ and $n=50$, we evaluate the expression:\n$$45 \\ln(p_{\\mathrm{eff}}) + 5 \\ln(1 - p_{\\mathrm{eff}})$$\nThe value of $p_{\\mathrm{eff}}$ depends on the true underlying allele proportion, $p = a/(a+r)$, and the sequencing error rate, $\\epsilon = 0.01$, according to the given formula:\n$$p_{\\mathrm{eff}} = p(1-\\epsilon) + (1-p)\\epsilon$$\nWe will now calculate $p_{\\mathrm{eff}}$ and the corresponding log-likelihood term for each of the four options.\n\n**Option A: A true homozygous alternate variant in a diploid region (no CNV), i.e., $a = 2$, $r = 0$.**\nIn this scenario, the true alternate-allele proportion is $p = a/(a+r) = 2/(2+0) = 1$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,A}} = 1(1-0.01) + (1-1)(0.01) = 1(0.99) + 0(0.01) = 0.99$$\nThe log-likelihood term is:\n$$\\ln(L_A) \\propto 45 \\ln(0.99) + 5 \\ln(1-0.99) = 45 \\ln(0.99) + 5 \\ln(0.01)$$\n$$\\ln(L_A) \\propto 45(-0.01005) + 5(-4.60517) = -0.45225 - 23.02585 = -23.4781$$\nThe observed allele balance of $0.9$ deviates from the expected $0.99$. The five observed reference-supporting reads are highly improbable if the probability of sequencing a reference allele is only $1-p_{\\mathrm{eff,A}} = 0.01$.\n\n**Option B: A heterozygous variant in a region with total copy number $3$, with $a = 2$ and $r = 1$.**\nHere, the true alternate-allele proportion is $p = a/(a+r) = 2/(2+1) = 2/3$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,B}} = \\frac{2}{3}(1-0.01) + \\left(1-\\frac{2}{3}\\right)(0.01) = \\frac{2}{3}(0.99) + \\frac{1}{3}(0.01) = \\frac{1.98 + 0.01}{3} = \\frac{1.99}{3} \\approx 0.6633$$\nThe log-likelihood term is:\n$$\\ln(L_B) \\propto 45 \\ln\\left(\\frac{1.99}{3}\\right) + 5 \\ln\\left(1-\\frac{1.99}{3}\\right) = 45 \\ln\\left(\\frac{1.99}{3}\\right) + 5 \\ln\\left(\\frac{1.01}{3}\\right)$$\n$$\\ln(L_B) \\propto 45(-0.41050) + 5(-1.08864) = -18.4725 - 5.4432 = -23.9157$$\nThis log-likelihood is lower (more negative) than that of Option A, indicating it is even less consistent with the data.\n\n**Option C: A heterozygous variant in a region with total copy number $4$, with $a = 3$ and $r = 1$.**\nThe true alternate-allele proportion is $p = a/(a+r) = 3/(3+1) = 3/4 = 0.75$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,C}} = \\frac{3}{4}(1-0.01) + \\left(1-\\frac{3}{4}\\right)(0.01) = 0.75(0.99) + 0.25(0.01) = 0.7425 + 0.0025 = 0.745$$\nThe log-likelihood term is:\n$$\\ln(L_C) \\propto 45 \\ln(0.745) + 5 \\ln(1-0.745) = 45 \\ln(0.745) + 5 \\ln(0.255)$$\n$$\\ln(L_C) \\propto 45(-0.29440) + 5(-1.36649) = -13.2480 - 6.83245 = -20.08045$$\nThis log-likelihood value is the highest (least negative) among all options considered so far. A superficial analysis might favor Option A because its expected allele balance ($0.99$) is arithmetically closer to the observed $0.9$ than Option C's ($0.745$). However, this is incorrect. The binomial likelihood function, $L(p) \\propto p^{45}(1-p)^5$, is highly asymmetric around its maximum at $p=0.9$. The penalty for deviation is much more severe for $p>0.9$ due to the $(1-p)^5$ term. Observing $5$ reads of a type expected with probability $0.01$ (Option A) is far less likely than observing $45$ reads of a type expected with probability $0.745$ (Option C).\n\n**Option D: No true variant is present.**\nThis implies a homozygous reference genotype. Assuming a diploid region ($a=0, r=2$), the true alternate-allele proportion is $p = 0/(0+2) = 0$.\nThe effective probability of observing an alternate allele is due entirely to sequencing error:\n$$p_{\\mathrm{eff,D}} = 0(1-0.01) + (1-0)(0.01) = 0.01$$\nThe log-likelihood term is:\n$$\\ln(L_D) \\propto 45 \\ln(0.01) + 5 \\ln(0.99)$$\n$$\\ln(L_D) \\propto 45(-4.60517) + 5(-0.01005) = -207.23265 - 0.05025 = -207.2829$$\nThis log-likelihood is extremely low, indicating that observing $45$ alternate reads when they are expected only from error is virtually impossible. This is the least plausible scenario by a very large margin.\n\n**Conclusion:**\nComparing the log-likelihood terms for all options:\n- Option A: $-23.4781$\n- Option B: $-23.9157$\n- Option C: $-20.08045$\n- Option D: $-207.2829$\n\nThe highest log-likelihood corresponds to Option C. Therefore, the interpretation most consistent with the observed data is a heterozygous variant in a region with total copy number $4$, having three copies of the alternate allele and one copy of the reference allele.\n\n**Option-by-Option Verdict:**\n- A: **Incorrect**. While the expected allele balance of $0.99$ seems close to the observation of $0.9$, the likelihood of observing $5$ reference reads is extremely low under this model, making it less plausible than Option C.\n- B: **Incorrect**. The expected allele balance of approximately $0.663$ is far from the observation, and the corresponding likelihood is lower than for options A and C.\n- C: **Correct**. This scenario maximizes the likelihood of the observed data among the given choices. The statistical evidence strongly supports this interpretation over the others.\n- D: **Incorrect**. The observation of $45$ alternate reads cannot be plausibly explained by random sequencing error alone. The likelihood for this scenario is vanishingly small.", "answer": "$$\\boxed{C}$$", "id": "2439432"}, {"introduction": "A raw variant call set is often noisy, containing numerous false positives that must be filtered out. Quality metrics like QualByDepth ($QD$), which normalizes variant confidence by sequencing depth, are essential tools for this task, but they are not infallible. This exercise explores a critical edge case where a common filtering strategy can fail, leading to the incorrect removal of a true positive variant. By analyzing this scenario, you will develop a crucial appreciation for the context-dependent limitations of automated quality control and the importance of critical thinking in data analysis.", "problem": "A laboratory uses a hard-filtering rule that removes any called variant with a QualByDepth (QD) annotation below a fixed threshold. QualByDepth (QD) is defined as the variant confidence on the Phred scale divided by the unfiltered depth of coverage at the locus, i.e., $QD = QUAL / DP$, where $QUAL$ is the Phred-scaled variant confidence and $DP$ is the unfiltered depth of coverage. The Phred scale is defined by $Q = -10 \\log_{10} p$, where $p$ is the error probability of the call. The lab sets a hard filter to remove variants with $QD < 2.0$. Consider the following four scenarios. In each scenario, assume the variant caller and aligner were properly configured and that read base qualities and mapping qualities are typical for modern short-read sequencing. Select the option that best exemplifies an edge case in which filtering on low $QD$ would remove a true positive variant.\n\nA. Targeted amplicon sequencing of a known germline heterozygous Single Nucleotide Polymorphism (SNP). The locus is captured extremely deeply, with unfiltered depth $DP = 4000$. The variant caller down-samples internally to limit evidence for genotype likelihoods, yielding a variant confidence $QUAL = 350$ based on an effective subset of reads. The allele balance among non-duplicated, high-quality reads is consistent with a heterozygote, and orthogonal validation confirms the SNP is real.\n\nB. Whole-genome sequencing at typical coverage of approximately $30\\times$. A germline heterozygous SNP has unfiltered depth $DP = 30$, variant confidence $QUAL = 200$, and an alternate allele fraction near $0.5$. Independent validation confirms the SNP is real.\n\nC. Whole-exome sequencing with modest coverage variability. A germline heterozygous insertion/deletion (indel) call is supported by unfiltered depth $DP = 8$, with variant confidence $QUAL = 30$ and balanced allele counts across both strands. Independent long-read sequencing confirms the indel is real.\n\nD. A short homopolymer run in a low-complexity region shows an apparent indel with unfiltered depth $DP = 120$ but variant confidence $QUAL = 20$. The signal appears in many unrelated samples processed across different batches, suggesting a recurrent sequencing or alignment artifact rather than a true biological variant.\n\nWhich option best matches an edge case where a low $QD$-based filter would remove a true positive variant?\n\nAnswer choices:\n- A\n\n- B\n\n- C\n\n- D", "solution": "The problem requires the identification of a specific scenario from a set of four options that best exemplifies an edge case where a true positive variant is erroneously filtered out by a low QualByDepth (QD) threshold. The filtering criterion is defined as removing any variant where $QD < 2.0$. The QualByDepth metric itself is defined as the ratio of the Phred-scaled variant confidence ($QUAL$) to the unfiltered depth of coverage ($DP$), such that $QD = QUAL / DP$. A true positive is a variant that is biologically real and has been correctly identified by the variant caller. The task is therefore to find the option describing a confirmed true variant for which the calculated $QD$ value falls below the $2.0$ threshold, leading to its incorrect removal.\n\nLet us analyze each scenario methodically.\n\nFirst, we establish the filtering rule: A variant is removed if $QD < 2.0$.\n\nOption A: Targeted amplicon sequencing of a known germline heterozygous Single Nucleotide Polymorphism (SNP).\n- Givens: The unfiltered depth is $DP = 4000$. The variant confidence, limited by internal down-sampling, is $QUAL = 350$. The variant is confirmed as a true positive (\"orthogonal validation confirms the SNP is real\").\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{350}{4000} = \\frac{35}{400} = \\frac{7}{80} = 0.0875$$\n- Evaluation: The calculated $QD$ value is $0.0875$. Since $0.0875 < 2.0$, this variant would be removed by the hard filter. The problem explicitly states this is a true positive variant. This scenario represents a classic failure mode for the $QD$ metric. In regions of extremely high coverage, such as those produced by amplicon sequencing, the denominator $DP$ becomes very large. Even if the absolute variant confidence $QUAL$ is extremely high (a $QUAL$ of $350$ corresponds to a vanishingly small error probability of $10^{-35}$), the $QD$ ratio can be artificially suppressed. Variant callers often down-sample reads in such high-depth regions to maintain computational tractability, which can cap the maximum achievable $QUAL$ score. The combination of a capped $QUAL$ and an extremely large $DP$ leads to a low $QD$ value, causing the erroneous rejection of a high-confidence, true positive call. This situation precisely matches the description of a problematic edge case for $QD$ filtering.\n- Verdict: **Correct**. This option perfectly exemplifies an edge case where a low $QD$-based filter removes a true positive variant.\n\nOption B: Whole-genome sequencing at typical coverage.\n- Givens: The unfiltered depth is $DP = 30$. The variant confidence is $QUAL = 200$. The variant is a confirmed true positive SNP.\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{200}{30} \\approx 6.67$$\n- Evaluation: The calculated $QD$ value is approximately $6.67$. Since $6.67 > 2.0$, this variant would *not* be removed by the filter. This scenario describes a high-quality true positive variant that is correctly passed by the filter. It does not illustrate a failure of the filter.\n- Verdict: **Incorrect**.\n\nOption C: Whole-exome sequencing with modest coverage.\n- Givens: The unfiltered depth is $DP = 8$. The variant confidence is $QUAL = 30$. The variant is a confirmed true positive indel.\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{30}{8} = 3.75$$\n- Evaluation: The calculated $QD$ value is $3.75$. Since $3.75 > 2.0$, this variant would *not* be removed by the filter. While the depth is low, the confidence is sufficiently high relative to the depth to produce a good $QD$ score. This is an example of a true positive call that correctly passes the filter.\n- Verdict: **Incorrect**.\n\nOption D: An apparent indel in a low-complexity region.\n- Givens: The unfiltered depth is $DP = 120$. The variant confidence is $QUAL = 20$. The problem text states that the signal is a \"recurrent sequencing or alignment artifact rather than a true biological variant\". This means it is a false positive.\n- The primary goal is to find an example of a *true positive* being filtered. Since this scenario describes a likely *false positive*, it cannot be the correct answer, irrespective of the $QD$ value.\n- For completeness, we calculate the $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{20}{120} = \\frac{1}{6} \\approx 0.167$$\n- Evaluation: The calculated $QD$ is approximately $0.167$. Since $0.167 < 2.0$, the variant would be filtered. However, since the variant is described as an artifact (a false positive), its removal represents a *success* of the filtering strategy, not a failure. The low $QUAL$ score of $20$ relative to the substantial depth of $120$ is exactly the type of low-quality signal that the $QD$ metric is designed to detect and filter out.\n- Verdict: **Incorrect**.\n\nConclusion: Only scenario A describes a situation where a confirmed true positive variant is filtered out by the $QD < 2.0$ rule. This occurs due to an artifact of the $QD$ calculation in an edge case of extremely high sequencing depth, which is a known limitation of this particular filtering metric.", "answer": "$$\\boxed{A}$$", "id": "2439414"}, {"introduction": "After running a complex bioinformatics pipeline, how can you objectively assess its performance? The answer lies in benchmarking against a \"gold standard\" or truth set of known variants. This practice guides you through the fundamental process of evaluating a variant caller by calculating its precision and recall. Implementing these core metrics will provide you with a concrete understanding of how to quantify a pipeline's accuracy and reliability, an indispensable skill for developing, comparing, and choosing bioinformatics tools.", "problem": "You are given a formal evaluation task to benchmark two variant calling pipelines against a trusted set of variants. Variants include single-nucleotide polymorphisms and insertion-deletion polymorphisms. Each variant is represented as a tuple of four fields: chromosome string, genomic coordinate as a positive integer, reference allele string, and alternate allele string. For this task, the trusted set is treated as ground truth. You must compute the precision and recall for each pipeline under exact-match criteria. An exact match means the chromosome strings are identical, the genomic coordinates are identical, and the reference and alternate allele strings are identical.\n\nLet a truth set be denoted by the finite set $T$ and a pipeline call set be denoted by the finite set $C$. Define the true positive set as $TP = C \\cap T$, the false positive set as $FP = C \\setminus T$, and the false negative set as $FN = T \\setminus C$. Define precision $P$ and recall $R$ by:\n$$\nP =\n\\begin{cases}\n\\dfrac{|TP|}{|TP| + |FP|}, & \\text{if } |TP| + |FP| > 0 \\\\\n1, & \\text{if } |TP| + |FP| = 0\n\\end{cases}\n\\qquad\nR =\n\\begin{cases}\n\\dfrac{|TP|}{|TP| + |FN|}, & \\text{if } |TP| + |FN| > 0 \\\\\n1, & \\text{if } |TP| + |FN| = 0\n\\end{cases}\n$$\nAll counts $| \\cdot |$ are cardinalities of finite sets. These definitions should be applied separately to each test case and each pipeline. All reported values must be decimals rounded to three decimal places. No physical units are involved. All decimals must be reported as base-$10$ decimal numbers.\n\nEvaluation criteria:\n- Treat all comparisons as exact string equality for chromosome, reference, and alternate allele fields, and exact integer equality for the genomic coordinate field.\n- Ignore genotype, phasing, and any other annotations; only the four-field variant identity determines matches.\n- All variants provided lie within benchmark regions and are eligible for evaluation.\n\nYou will evaluate the following test suite. For each test case $i \\in \\{1,2,3\\}$, you are given a truth set $T_i$, a pipeline $A$ call set $C^{(A)}_i$, and a pipeline $B$ call set $C^{(B)}_i$. Each variant is written as a $4$-tuple $(\\text{chrom}, \\text{pos}, \\text{ref}, \\text{alt})$, where $\\text{pos}$ is a positive integer. The sets are:\n\n- Test case $1$:\n$$\n\\begin{aligned}\nT_1 &= \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 200, \\text{T}, \\text{TA}),\\; (\\text{chr1}, 300, \\text{CT}, \\text{C}) \\} \\\\\nC^{(A)}_1 &= \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 200, \\text{T}, \\text{TA}),\\; (\\text{chr1}, 250, \\text{G}, \\text{C}) \\} \\\\\nC^{(B)}_1 &= \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 300, \\text{CT}, \\text{C}),\\; (\\text{chr1}, 400, \\text{A}, \\text{AT}) \\}\n\\end{aligned}\n$$\n\n- Test case $2$:\n$$\n\\begin{aligned}\nT_2 &= \\{ (\\text{chr2}, 1000, \\text{G}, \\text{A}),\\; (\\text{chr2}, 1001, \\text{C}, \\text{CG}) \\} \\\\\nC^{(A)}_2 &= \\varnothing \\\\\nC^{(B)}_2 &= \\{ (\\text{chr2}, 1500, \\text{T}, \\text{G}) \\}\n\\end{aligned}\n$$\n\n- Test case $3$:\n$$\n\\begin{aligned}\nT_3 &= \\varnothing \\\\\nC^{(A)}_3 &= \\varnothing \\\\\nC^{(B)}_3 &= \\{ (\\text{chr3}, 10, \\text{A}, \\text{G}),\\; (\\text{chr3}, 20, \\text{T}, \\text{TA}) \\}\n\\end{aligned}\n$$\n\nYour task is to write a program that, for each test case $i$, computes the precision and recall for pipeline $A$ applied to $(C^{(A)}_i, T_i)$ and for pipeline $B$ applied to $(C^{(B)}_i, T_i)$, using the definitions above.\n\nFinal output format:\n- Your program should produce a single line of output containing a single list of decimals in the exact order\n$$\n[ P^{(A)}_1, R^{(A)}_1, P^{(B)}_1, R^{(B)}_1, P^{(A)}_2, R^{(A)}_2, P^{(B)}_2, R^{(B)}_2, P^{(A)}_3, R^{(A)}_3, P^{(B)}_3, R^{(B)}_3 ].\n$$\n- Each decimal must be rounded to three decimal places.\n- The list must be enclosed in square brackets and the values separated by commas, with no additional text.", "solution": "The problem requires the computation of precision and recall for two variant calling pipelines across three test cases. The problem is well-defined, scientifically grounded, and provides all necessary data and formulae for a unique solution. It is a standard exercise in bioinformatics performance evaluation. We proceed with the solution.\n\nThe fundamental task is to compare a set of variant calls generated by a pipeline, denoted as the call set $C$, against a ground-truth set of variants, the truth set $T$. Both are finite sets of variants, where each variant is a $4$-tuple $(\\text{chrom}, \\text{pos}, \\text{ref}, \\text{alt})$. An exact match is required.\n\nThe core metrics are derived from the cardinalities of three sets:\n1.  True Positives ($TP$): Variants correctly identified by the pipeline. This is the set intersection $TP = C \\cap T$.\n2.  False Positives ($FP$): Variants incorrectly called by the pipeline that are not in the truth set. This is the set difference $FP = C \\setminus T$.\n3.  False Negatives ($FN$): True variants that the pipeline failed to identify. This is the set difference $FN = T \\setminus C$.\n\nThe problem defines precision ($P$) and recall ($R$) as:\n$$\nP =\n\\begin{cases}\n\\dfrac{|TP|}{|TP| + |FP|}, & \\text{if } |TP| + |FP| > 0 \\\\\n1, & \\text{if } |TP| + |FP| = 0\n\\end{cases}\n\\qquad\nR =\n\\begin{cases}\n\\dfrac{|TP|}{|TP| + |FN|}, & \\text{if } |TP| + |FN| > 0 \\\\\n1, & \\text{if } |TP| + |FN| = 0\n\\end{cases}\n$$\nNote that $|TP| + |FP| = |C|$ and $|TP| + |FN| = |T|$. The special cases handle scenarios with empty call sets or empty truth sets. We will apply these definitions rigorously to each case.\n\n**Test Case 1**\n\nTruth Set: $T_1 = \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 200, \\text{T}, \\text{TA}),\\; (\\text{chr1}, 300, \\text{CT}, \\text{C}) \\}$. The cardinality is $|T_1| = 3$.\n\nPipeline A: $C^{(A)}_1 = \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 200, \\text{T}, \\text{TA}),\\; (\\text{chr1}, 250, \\text{G}, \\text{C}) \\}$, so $|C^{(A)}_1| = 3$.\n-   $TP^{(A)}_1 = C^{(A)}_1 \\cap T_1 = \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 200, \\text{T}, \\text{TA}) \\}$. Thus, $|TP^{(A)}_1| = 2$.\n-   $FP^{(A)}_1 = C^{(A)}_1 \\setminus T_1 = \\{ (\\text{chr1}, 250, \\text{G}, \\text{C}) \\}$. Thus, $|FP^{(A)}_1| = 1$.\n-   $FN^{(A)}_1 = T_1 \\setminus C^{(A)}_1 = \\{ (\\text{chr1}, 300, \\text{CT}, \\text{C}) \\}$. Thus, $|FN^{(A)}_1| = 1$.\n-   Precision $P^{(A)}_1 = \\frac{|TP^{(A)}_1|}{|TP^{(A)}_1| + |FP^{(A)}_1|} = \\frac{2}{2+1} = \\frac{2}{3} \\approx 0.667$.\n-   Recall $R^{(A)}_1 = \\frac{|TP^{(A)}_1|}{|TP^{(A)}_1| + |FN^{(A)}_1|} = \\frac{2}{2+1} = \\frac{2}{3} \\approx 0.667$.\n\nPipeline B: $C^{(B)}_1 = \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 300, \\text{CT}, \\text{C}),\\; (\\text{chr1}, 400, \\text{A}, \\text{AT}) \\}$, so $|C^{(B)}_1| = 3$.\n-   $TP^{(B)}_1 = C^{(B)}_1 \\cap T_1 = \\{ (\\text{chr1}, 100, \\text{A}, \\text{G}),\\; (\\text{chr1}, 300, \\text{CT}, \\text{C}) \\}$. Thus, $|TP^{(B)}_1| = 2$.\n-   $FP^{(B)}_1 = C^{(B)}_1 \\setminus T_1 = \\{ (\\text{chr1}, 400, \\text{A}, \\text{AT}) \\}$. Thus, $|FP^{(B)}_1| = 1$.\n-   $FN^{(B)}_1 = T_1 \\setminus C^{(B)}_1 = \\{ (\\text{chr1}, 200, \\text{T}, \\text{TA}) \\}$. Thus, $|FN^{(B)}_1| = 1$.\n-   Precision $P^{(B)}_1 = \\frac{|TP^{(B)}_1|}{|TP^{(B)}_1| + |FP^{(B)}_1|} = \\frac{2}{2+1} = \\frac{2}{3} \\approx 0.667$.\n-   Recall $R^{(B)}_1 = \\frac{|TP^{(B)}_1|}{|TP^{(B)}_1| + |FN^{(B)}_1|} = \\frac{2}{2+1} = \\frac{2}{3} \\approx 0.667$.\n\n**Test Case 2**\n\nTruth Set: $T_2 = \\{ (\\text{chr2}, 1000, \\text{G}, \\text{A}),\\; (\\text{chr2}, 1001, \\text{C}, \\text{CG}) \\}$. The cardinality is $|T_2| = 2$.\n\nPipeline A: $C^{(A)}_2 = \\varnothing$, so $|C^{(A)}_2| = 0$.\n-   $|TP^{(A)}_2| = 0$, $|FP^{(A)}_2| = 0$.\n-   $FN^{(A)}_2 = T_2 \\setminus \\varnothing = T_2$. Thus, $|FN^{(A)}_2| = 2$.\n-   Precision: $|TP^{(A)}_2| + |FP^{(A)}_2| = 0$. By definition, $P^{(A)}_2 = 1.000$.\n-   Recall: $R^{(A)}_2 = \\frac{|TP^{(A)}_2|}{|TP^{(A)}_2| + |FN^{(A)}_2|} = \\frac{0}{0+2} = 0.000$.\n\nPipeline B: $C^{(B)}_2 = \\{ (\\text{chr2}, 1500, \\text{T}, \\text{G}) \\}$, so $|C^{(B)}_2| = 1$.\n-   $TP^{(B)}_2 = C^{(B)}_2 \\cap T_2 = \\varnothing$. Thus, $|TP^{(B)}_2| = 0$.\n-   $FP^{(B)}_2 = C^{(B)}_2 \\setminus T_2 = C^{(B)}_2$. Thus, $|FP^{(B)}_2| = 1$.\n-   $FN^{(B)}_2 = T_2 \\setminus C^{(B)}_2 = T_2$. Thus, $|FN^{(B)}_2| = 2$.\n-   Precision $P^{(B)}_2 = \\frac{|TP^{(B)}_2|}{|TP^{(B)}_2| + |FP^{(B)}_2|} = \\frac{0}{0+1} = 0.000$.\n-   Recall $R^{(B)}_2 = \\frac{|TP^{(B)}_2|}{|TP^{(B)}_2| + |FN^{(B)}_2|} = \\frac{0}{0+2} = 0.000$.\n\n**Test Case 3**\n\nTruth Set: $T_3 = \\varnothing$. The cardinality is $|T_3| = 0$.\n\nPipeline A: $C^{(A)}_3 = \\varnothing$, so $|C^{(A)}_3| = 0$.\n-   $|TP^{(A)}_3| = 0$, $|FP^{(A)}_3| = 0$, $|FN^{(A)}_3| = 0$.\n-   Precision: $|TP^{(A)}_3| + |FP^{(A)}_3| = 0$. By definition, $P^{(A)}_3 = 1.000$.\n-   Recall: $|TP^{(A)}_3| + |FN^{(A)}_3| = 0$. By definition, $R^{(A)}_3 = 1.000$.\nThis reflects perfect performance: no variants were called, and none were expected.\n\nPipeline B: $C^{(B)}_3 = \\{ (\\text{chr3}, 10, \\text{A}, \\text{G}),\\; (\\text{chr3}, 20, \\text{T}, \\text{TA}) \\}$, so $|C^{(B)}_3| = 2$.\n-   $TP^{(B)}_3 = C^{(B)}_3 \\cap T_3 = \\varnothing$. Thus, $|TP^{(B)}_3| = 0$.\n-   $FP^{(B)}_3 = C^{(B)}_3 \\setminus T_3 = C^{(B)}_3$. Thus, $|FP^{(B)}_3| = 2$.\n-   $FN^{(B)}_3 = T_3 \\setminus C^{(B)}_3 = \\varnothing$. Thus, $|FN^{(B)}_3| = 0$.\n-   Precision $P^{(B)}_3 = \\frac{|TP^{(B)}_3|}{|TP^{(B)}_3| + |FP^{(B)}_3|} = \\frac{0}{0+2} = 0.000$.\n-   Recall: $|TP^{(B)}_3| + |FN^{(B)}_3| = 0$. By definition, $R^{(B)}_3 = 1.000$.\nThe recall is perfect because there were no true variants to miss ($FN = 0$).\n\n**Summary of Results**\nThe consolidated results, rounded to three decimal places, are:\n-   $P^{(A)}_1 = 0.667$, $R^{(A)}_1 = 0.667$\n-   $P^{(B)}_1 = 0.667$, $R^{(B)}_1 = 0.667$\n-   $P^{(A)}_2 = 1.000$, $R^{(A)}_2 = 0.000$\n-   $P^{(B)}_2 = 0.000$, $R^{(B)}_2 = 0.000$\n-   $P^{(A)}_3 = 1.000$, $R^{(A)}_3 = 1.000$\n-   $P^{(B)}_3 = 0.000$, $R^{(B)}_3 = 1.000$\n\nThese values will be composed into a single list for the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the variant calling evaluation problem by calculating precision\n    and recall for given test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each variant is a tuple (chrom, pos, ref, alt).\n    # Each test case is a tuple (truth_set, call_set_A, call_set_B).\n    test_cases = [\n        # Test Case 1\n        (\n            {('chr1', 100, 'A', 'G'), ('chr1', 200, 'T', 'TA'), ('chr1', 300, 'CT', 'C')},\n            {('chr1', 100, 'A', 'G'), ('chr1', 200, 'T', 'TA'), ('chr1', 250, 'G', 'C')},\n            {('chr1', 100, 'A', 'G'), ('chr1', 300, 'CT', 'C'), ('chr1', 400, 'A', 'AT')}\n        ),\n        # Test Case 2\n        (\n            {('chr2', 1000, 'G', 'A'), ('chr2', 1001, 'C', 'CG')},\n            set(),\n            {('chr2', 1500, 'T', 'G')}\n        ),\n        # Test Case 3\n        (\n            set(),\n            set(),\n            {('chr3', 10, 'A', 'G'), ('chr3', 20, 'T', 'TA')}\n        )\n    ]\n\n    def calculate_metrics(call_set, truth_set):\n        \"\"\"\n        Calculates precision and recall based on the provided formulae.\n\n        Args:\n            call_set (set): A set of variant tuples from a pipeline.\n            truth_set (set): A set of ground-truth variant tuples.\n\n        Returns:\n            tuple: A tuple containing (precision, recall).\n        \"\"\"\n        # Calculate cardinalities of TP, FP, FN sets using set operations.\n        # True Positives: intersection of call set and truth set.\n        tp_set = call_set.intersection(truth_set)\n        tp = len(tp_set)\n\n        # False Positives: variants in call set but not in truth set.\n        fp_set = call_set.difference(truth_set)\n        fp = len(fp_set)\n\n        # False Negatives: variants in truth set but not in call set.\n        fn_set = truth_set.difference(call_set)\n        fn = len(fn_set)\n\n        # Calculate Precision\n        # Denominator is |TP| + |FP|, which is equal to |C|.\n        p_denominator = tp + fp\n        if p_denominator == 0:\n            precision = 1.0\n        else:\n            precision = tp / p_denominator\n\n        # Calculate Recall\n        # Denominator is |TP| + |FN|, which is equal to |T|.\n        r_denominator = tp + fn\n        if r_denominator == 0:\n            recall = 1.0\n        else:\n            recall = tp / r_denominator\n            \n        return (precision, recall)\n\n    results = []\n    # Iterate through each test case and calculate metrics for both pipelines.\n    for truth_set, call_set_A, call_set_B in test_cases:\n        # Pipeline A\n        p_A, r_A = calculate_metrics(call_set_A, truth_set)\n        results.extend([p_A, r_A])\n        \n        # Pipeline B\n        p_B, r_B = calculate_metrics(call_set_B, truth_set)\n        results.extend([p_B, r_B])\n\n    # Format the results to three decimal places as required.\n    formatted_results = [f\"{r:.3f}\" for r in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2439428"}]}