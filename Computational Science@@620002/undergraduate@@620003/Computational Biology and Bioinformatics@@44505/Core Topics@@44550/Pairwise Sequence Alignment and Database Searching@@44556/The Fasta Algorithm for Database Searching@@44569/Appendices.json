{"hands_on_practices": [{"introduction": "The FASTA algorithm begins by creating a \"lookup table\" to rapidly find the positions of all short \"words\" (or $k$-tuples) from the query sequence. Before diving into the statistical complexities of scoring, it is crucial to understand the fundamental computational constraints of this first step. This practice challenges you to calculate the memory required for this lookup table, illuminating the critical trade-off between the word size $k$, alphabet size $A$, and the algorithm's memory footprint [@problem_id:2435282]. Mastering this calculation provides a concrete understanding of why parameter choices in bioinformatics software have such profound effects on performance.", "problem": "In the Fast-All (FASTA) algorithm for database searching, the query indexing step constructs a direct-address lookup table that maps each possible contiguous word of length $k$ (a $k$-tuple) over a finite alphabet of size $A$ to a fixed-size record. Assume the following model for the lookup table: it is a fully allocated array with one entry for every possible $k$-tuple, and each entry stores exactly $b$ bytes (e.g., a pointer or offset), with no compression, pooling, or lazy allocation. The table is constructed identically regardless of the query content.\n\nUsing only these assumptions and basic counting principles, determine the expected total memory usage of the lookup table, expressed as a closed-form function of $A$, $k$, and $b$. Express your final answer in bytes. No rounding is required, and the final result must be a single analytic expression.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded, well-posed, and objective. It describes a simplified but valid model of a direct-address lookup table, a fundamental data structure in computer science, as applied in the context of the FASTA algorithm. All parameters required for the solution—the alphabet size $A$, the word length $k$, and the memory size per entry $b$—are explicitly provided. The problem is a straightforward application of basic counting principles.\n\nThe objective is to determine the total memory usage of the lookup table. The total memory $M$ required for a fully allocated array-like data structure is given by the product of the total number of entries, $N$, and the memory required for each entry, which is given as $b$ bytes.\n\n$$M = N \\times b$$\n\nThe problem states that the memory per entry is a fixed size of $b$ bytes.\n\nThe core of the problem is to determine $N$, the total number of entries in the lookup table. The problem specifies that the table has \"one entry for every possible $k$-tuple\" that can be formed from an alphabet of size $A$. A $k$-tuple is a contiguous word of length $k$.\n\nWe can determine the number of unique $k$-tuples using a fundamental counting principle, the rule of product. A word of length $k$ consists of $k$ positions. For each position, there are $A$ possible characters that can be chosen from the alphabet. Since the choice for each position is independent of the choices for all other positions, the total number of unique words is the product of the number of choices for each of the $k$ positions.\n\n$$N = \\underbrace{A \\times A \\times \\dots \\times A}_{k \\text{ times}}$$\n\nThis product is equivalent to $A$ raised to the power of $k$.\n\n$$N = A^{k}$$\n\nThe problem statement asks for the *expected* total memory usage. However, the model provided is deterministic. The table is \"fully allocated\" and its construction is \"identically regardless of the query content\". This means the size of the table is fixed and does not depend on any random variable or the specific input query sequence. Therefore, the expected memory usage is simply its actual, calculated memory usage.\n\nSubstituting the expression for the number of entries $N$ into the equation for total memory $M$, we obtain the final expression.\n\n$$M = A^{k} \\times b$$\n\nThe units are in bytes, as specified by the definition of $b$. The final expression for the total memory usage of the lookup table is a closed-form function of the given parameters $A$, $k$, and $b$.", "answer": "$$\\boxed{b A^{k}}$$", "id": "2435282"}, {"introduction": "A powerful algorithm is not just one that is fast, but one whose limitations are well understood. This thought experiment explores a common and challenging scenario in bioinformatics: searching a massive database with a very short query sequence [@problem_id:2435280]. By analyzing this situation, you will develop a deeper intuition for the delicate balance between sensitivity (finding true relatives) and the statistical significance ($E$-value) of your results. This exercise sharpens your critical thinking about how algorithmic parameters, like word size $k$, interact with biological data to determine the success or failure of a search.", "problem": "In computational biology and bioinformatics, consider applying the FAST-All (FASTA) algorithm to search a large protein database with a very short query sequence, specifically a peptide of length $15$. Assume a standard protein alphabet of size $20$, a database with total length $n$ where $n \\gg 10^6$, and the default FAST-All (FASTA) protein word length $k=2$ unless otherwise changed. Which statement best describes the expected impact of such a short query on performance characteristics, including sensitivity, false positives, statistical significance (as quantified by the expected value, or $E$-value), and parameter choice?\n\nA. With such a short query, sensitivity to distant homologs decreases and statistical significance is harder to achieve because maximum alignment scores are limited; many short $k$-mer seeds occur by chance in a large database, inflating spurious initial matches. Reducing $k$ can recover some sensitivity but increases noise and runtime.\n\nB. Short queries improve both sensitivity and statistical significance because fewer words are available, which reduces random matches; increasing $k$ further enhances sensitivity while also lowering the false-positive rate.\n\nC. Runtime increases superlinearly as the query becomes shorter because the dynamic programming phase dominates, but statistical significance is essentially independent of query length.\n\nD. The method automatically switches to global alignment and yields only full-length matches with very small $E$-values, making very short queries ideal for database searching.", "solution": "The problem statement must first be validated for scientific soundness and consistency before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Algorithm**: FAST-All (FASTA)\n- **Application**: Searching a large protein database\n- **Query**: A peptide of length $L = 15$. This is described as \"very short\".\n- **Alphabet**: Standard protein alphabet of size $A = 20$.\n- **Database**: Total length $n$, where $n \\gg 10^6$.\n- **Parameter**: Default protein word length $k=2$.\n- **Question**: Describe the expected impact of the short query on performance characteristics: sensitivity, false positives, statistical significance ($E$-value), and parameter choice.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Grounding**: The FASTA algorithm, the concepts of query length ($L$), database size ($n$), word size ($k$), sensitivity, and statistical significance ($E$-value) are all fundamental and well-established principles in the field of computational biology and bioinformatics. The scenario presented—searching a large database with a short peptide—is a realistic and common task, for instance, in proteomics for identifying proteins from mass spectrometry fragmentation data or searching for short functional motifs.\n- **Well-Posedness**: The problem is clearly stated and asks for a qualitative analysis of performance trade-offs based on the provided parameters. The relationships between these parameters and performance metrics are well-understood, allowing for a unique and meaningful analysis.\n- **Objectivity**: The language is technical and precise. `very short` is quantified with a length of $15$, and `large` is quantified with $n \\gg 10^6$. There are no subjective or ambiguous terms.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A rigorous analysis can proceed.\n\n### Derivation of Solution\n\nThe FASTA algorithm operates in several stages, and the effect of a short query must be analyzed through these stages.\n\n1.  **Stage 1: Word Matching.** FASTA identifies all exact matches of length $k$ (known as $k$-mers or words) between the query and database sequences.\n    - The query has length $L=15$. With a word size of $k=2$, the number of words in the query is $L - k + 1 = 15 - 2 + 1 = 14$.\n    - The protein alphabet has size $A=20$. The total number of possible distinct words of length $k=2$ is $A^k = 20^2 = 400$.\n    - In a large random database of length $n$, the expected number of occurrences of any single $k=2$ word is very high: $n / A^k = n/400$. Since $n \\gg 10^6$, each word is expected to appear thousands of times by chance alone.\n    - Consequently, the initial step of finding common words will generate a vast number of `hits`. This high volume of random, background matches constitutes significant noise that the algorithm must filter.\n\n2.  **Stage 2 & 3: Scoring Hotspots.** FASTA identifies regions with a high density of these word matches (diagonals) and scores them to find the best initial regions (`init1` scores).\n    - With a large number of spurious random `hits` from Stage 1, many non-homologous regions in the database will appear to have a high density of matches by chance. This increases the computational burden of this stage and inflates the number of spurious initial matches that must be considered.\n\n3.  **Stage 4: Optimization and Statistical Evaluation.** The best initial regions are joined, and a banded dynamic programming alignment is performed to produce a final optimized score ($S$). This score's significance is then assessed using an Expectation value ($E$-value).\n    - The $E$-value is approximated by the formula $E = K \\cdot m \\cdot n \\cdot e^{-\\lambda S}$, where $m$ is the query length (here, $m=15$), $n$ is the database length, $S$ is the alignment score, and $K$ and $\\lambda$ are statistical parameters dependent on the scoring system and amino acid frequencies.\n    - A very short query has a low ceiling on its maximum possible alignment score, $S_{max}$. For example, even a perfect identity match will yield a score proportional to its short length.\n    - Because the maximum achievable score $S$ is small, it is difficult to obtain a small (statistically significant) $E$-value. The term $e^{-\\lambda S}$ will be relatively large (closer to $1$) compared to what is possible with a longer query that can achieve a much higher score $S$. Thus, statistical significance is harder to achieve.\n    - **Sensitivity**: This refers to the ability to detect true relationships (homologs). For distant homologs, sequence similarity is low, and the alignment score $S$ will be modest. For a short query, this modest score is likely to be indistinguishable from scores of random, unrelated sequences, which can be relatively high due to the short sequence length. The signal (true homology) is drowned out by the noise (random matches). Therefore, sensitivity to distant homologs is significantly decreased.\n    - **False Positives**: The combination of high background noise (many random $k$-mer matches) and the difficulty in achieving statistically significant scores leads to a higher rate of false positives—unrelated sequences that achieve a score high enough to be reported but not high enough to be statistically convincing.\n\n4.  **Parameter Choice (adjusting $k$):**\n    - **Reducing $k$ (e.g., to $k=1$):** This would make the problem far worse. The number of possible words becomes $A^1 = 20$. The number of chance matches would explode to approximately $n/20$ for each of the $14$ amino acids in the query. While this might increase the chance of finding a seed match in a very distant homolog, the signal-to-noise ratio would become astronomically poor, and the runtime would increase dramatically due to the massive number of initial hits to process. However, the statement that it \"can recover some sensitivity\" is technically correct in the sense that it lowers the bar for an initial match, but at a severe cost.\n    - **Increasing $k$ (e.g., to $k=3$):** The number of possible words becomes $A^3 = 20^3 = 8000$. A match of length $3$ is much more specific. The number of chance matches would decrease drastically, reducing noise and likely improving runtime. However, this increased specificity can lead to a loss of sensitivity for distant homologs, which may not share a perfect $3$-amino-acid block with the query.\n\n### Option-by-Option Analysis\n\n- **A. With such a short query, sensitivity to distant homologs decreases and statistical significance is harder to achieve because maximum alignment scores are limited; many short $k$-mer seeds occur by chance in a large database, inflating spurious initial matches. Reducing $k$ can recover some sensitivity but increases noise and runtime.**\n  - `sensitivity to distant homologs decreases`: **Correct**. The weak signal from true but distant relatives is masked by statistical noise.\n  - `statistical significance is harder to achieve because maximum alignment scores are limited`: **Correct**. A low maximum score $S$ leads to a higher (less significant) $E$-value.\n  - `many short k-mer seeds occur by chance... inflating spurious initial matches`: **Correct**. With $k=2$, words are non-specific and occur frequently by chance in a large database.\n  - `Reducing k can recover some sensitivity but increases noise and runtime`: **Correct**. This accurately describes the standard trade-off. Reducing $k$ makes it easier to find an initial seed, potentially helping with distant homologs, but at the cost of processing a huge number of random matches.\n  - This statement is a comprehensive and accurate description of the situation. **Verdict: Correct.**\n\n- **B. Short queries improve both sensitivity and statistical significance because fewer words are available, which reduces random matches; increasing $k$ further enhances sensitivity while also lowering the false-positive rate.**\n  - `improve both sensitivity and statistical significance`: **Incorrect**. Both are degraded for the reasons explained above.\n  - `fewer words are available, which reduces random matches`: **Incorrect**. The problem is not the number of words in the query ($14$), but the low specificity of each word type ($k=2$), leading to a massive number of random matches from the database.\n  - `increasing k further enhances sensitivity`: **Incorrect**. Increasing $k$ increases specificity, which generally *decreases* sensitivity for divergent sequences. It makes it harder to find an initial seed.\n  - **Verdict: Incorrect.**\n\n- **C. Runtime increases superlinearly as the query becomes shorter because the dynamic programming phase dominates, but statistical significance is essentially independent of query length.**\n  - `Runtime increases superlinearly as the query becomes shorter`: **Incorrect**. For a fixed $k$, a shorter query generally means a faster search, as fewer words and shorter potential alignments are processed. The runtime increase is associated with reducing $k$, not reducing query length $L$.\n  - `dynamic programming phase dominates`: **Incorrect**. The DP phase in FASTA is banded and its cost is related to the alignment being built. For a short query, this phase is computationally inexpensive. The potential bottleneck is the initial filtering of a vast number of word hits.\n  - `statistical significance is essentially independent of query length`: **Incorrect**. The $E$-value formula contains the query length $m$, and the achievable score $S$ is critically dependent on it. This statement is fundamentally false.\n  - **Verdict: Incorrect.**\n\n- **D. The method automatically switches to global alignment and yields only full-length matches with very small $E$-values, making very short queries ideal for database searching.**\n  - `automatically switches to global alignment`: **Incorrect**. FASTA is a heuristic for local alignment. It does not perform global alignment (Needleman-Wunsch).\n  - `yields only full-length matches`: **Incorrect**. It reports local alignments.\n  - `with very small E-values`: **Incorrect**. As established, achieving small $E$-values is a primary difficulty with short queries.\n  - `making very short queries ideal for database searching`: **Incorrect**. They are challenging, not ideal.\n  - **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2435280"}, {"introduction": "To truly master an algorithm, one must build it. This final practice moves beyond theory and challenges you to implement a simplified model of FASTA's core logic: identifying initial \"seeds,\" scoring the diagonals they form, and filtering out noise based on a score threshold [@problem_id:2435286]. By translating concepts like diagonal offsets ($d$), initial scores ($init1$), and filtering thresholds ($\\\\tau$) into a working program, you will gain a procedural understanding of how FASTA efficiently hones in on promising alignments. This exercise bridges the gap between abstract principles and their tangible implementation, a crucial skill for any computational biologist.", "problem": "Construct a complete, runnable program that models the trade-off in the Fast Alignment Search Tool (FASTA) between the initial diagonal score (denoted as $init1$) threshold and the number of diagonals that must be stored and joined, under an idealized but mathematically precise setup described below. All computations are purely symbolic and combinatorial; no physical units are involved.\n\nDefinitions and setup:\n\n- Let the nucleotide alphabet be $\\Sigma=\\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$. A sequence is a finite string over $\\Sigma$.\n- Let the query sequence be $Q$ of length $L_Q$, with zero-based indices $i\\in\\{0,1,\\dots,L_Q-1\\}$. Let the subject (database) sequence be $S$ of length $L_S$, with zero-based indices $j\\in\\{0,1,\\dots,L_S-1\\}$.\n- Fix a word length $k\\in\\mathbb{Z}_{\\ge 1}$. A $k$-mer is any contiguous substring of length $k$. For any $i\\in\\{0,1,\\dots,L_Q-k\\}$ and $j\\in\\{0,1,\\dots,L_S-k\\}$, a seed occurs at the pair $(i,j)$ if and only if the $k$-mers are exactly equal, i.e., $Q[i:i+k]=S[j:j+k]$.\n- Define the diagonal offset $d=i-j$. For a fixed diagonal $d\\in\\mathbb{Z}$, let $M_d=\\{i\\in\\{0,1,\\dots,L_Q-k\\}\\mid \\exists j \\text{ with } j=i-d \\text{ and } 0\\le j\\le L_S-k \\text{ such that } Q[i:i+k]=S[j:j+k]\\}$ be the set of query indices participating in seeds on diagonal $d$. Let $|M_d|$ denote its cardinality.\n- Fix a seed reward $s_m\\in\\mathbb{Z}_{\\ge 1}$. Define the initial diagonal score as $init1(d)=s_m\\cdot |M_d|$.\n- Given a threshold $\\tau\\in\\mathbb{Z}_{\\ge 0}$, the retained (stored) diagonal set is $D_{\\tau}=\\{d\\in\\mathbb{Z}\\mid init1(d)\\ge \\tau\\}$, and the number of stored diagonals is $|D_{\\tau}|$.\n- Fix a proximity parameter $\\delta\\in\\mathbb{Z}_{\\ge 0}$. For each retained diagonal $d\\in D_{\\tau}$, sort the elements of $M_d$ increasingly as $i_1<i_2<\\dots<i_{t_d}$. Define the number of join operations contributed by diagonal $d$ as $J_d=\\left|\\{\\ell\\in\\{1,2,\\dots,t_d-1\\}\\mid i_{\\ell+1}-i_\\ell\\le \\delta\\}\\right|$. The total number of joins is $J=\\sum_{d\\in D_{\\tau}}J_d$.\n- For each test case, you are given a set of true homologous diagonals $D^\\star\\subset\\mathbb{Z}$ that encode where known homologous regions align. Define the boolean $B$ to be $\\text{True}$ if and only if $D^\\star\\subseteq D_{\\tau}$, and $\\text{False}$ otherwise.\n\nYour program must, for each test case, compute and return the triple $[|D_{\\tau}|,J,B]$.\n\nTest suite:\n\nUse the following three test cases. In all cases, indices are zero-based, and the diagonal offset is $d=i-j$.\n\n- Test case $1$ (representative case):\n  - $Q=$ \"ACGTGACCTGATCGTACGTA\" (so $L_Q=20$).\n  - $S=$ \"TTTT\" + $Q$ + \"CCCC\" (so $L_S=28$).\n  - $k=4$, $s_m=1$, $\\tau=8$, $\\delta=5$.\n  - True homologous diagonal set $D^\\star=\\{-4\\}$.\n- Test case $2$ (high threshold boundary where nothing is retained):\n  - Same $Q$ and $S$ as in test case $1$.\n  - $k=4$, $s_m=1$, $\\tau=18$, $\\delta=5$.\n  - $D^\\star=\\{-4\\}$.\n- Test case $3$ (multiple homologous blocks on distinct diagonals):\n  - Let $A=$ \"ACGTCGATGCTAGTCA\" and $B=$ \"TGACCTGATCGTAGCA\".\n  - $Q=$ $A$ + \"GGGG\" + $B$ (so $L_Q=36$).\n  - $S=$ \"TT\" + $A$ + \"TTTTTT\" + $B$ + \"CC\" (so $L_S=42$).\n  - $k=4$, $s_m=1$, $\\tau=10$, $\\delta=5$.\n  - The block $A$ aligns at offset $d=-2$, and block $B$ aligns at offset $d=-4$, so $D^\\star=\\{-2,-4\\}$.\n\nRequired final output format:\n\n- Your program must process the three test cases in the order listed above and produce a single line of output containing the list of results, one per test case, where each result is the list $[|D_{\\tau}|,J,B]$ for that test. The line must be a single string representation of the outer list with comma-separated inner lists, for example, \"[[a,b,True],[c,d,False],[e,f,True]]\" with actual computed integers and booleans in place of $a,b,c,d,e,f$.", "solution": "The problem statement is a valid, well-posed, and scientifically grounded formulation of a simplified model of the FASTA algorithm's initial stages. It provides a clear, objective, and complete set of definitions and parameters to compute the trade-off between sensitivity (retaining true homologous diagonals) and computational cost (number of stored diagonals and join operations). All terms are rigorously defined, and the data for the test cases are self-contained and consistent. I will therefore proceed with a full solution.\n\nThe solution is constructed by implementing a computational procedure that strictly follows the definitions provided in the problem statement. The algorithm is executed for each test case to compute the required triple $[|D_{\\tau}|, J, B]$. The process is divided into four main logical steps.\n\nFirst, we must identify all seed matches between the query sequence $Q$ of length $L_Q$ and the subject sequence $S$ of length $L_S$. A seed is a perfect match between a $k$-mer from $Q$ and a $k$-mer from $S$. To do this efficiently, we first build a lookup table (a hash map or dictionary) that maps each unique $k$-mer present in the subject sequence $S$ to a list of its starting indices $j$. We then iterate through the query sequence $Q$, extracting each $k$-mer starting at index $i \\in \\{0, 1, \\dots, L_Q - k\\}$. For each query $k$-mer, we use the lookup table to find all matching $k$-mers in $S$. For each match found between a query $k$-mer starting at $i$ and a subject $k$-mer starting at $j$, we calculate the diagonal offset $d = i - j$. We populate a primary data structure, a map where keys are diagonal offsets $d$ and values are lists of the query indices $i$ that contribute seeds to that diagonal. This structure represents the collection of sets $\\{M_d\\}_{d\\in\\mathbb{Z}}$.\n\nSecond, with the `diagonal_matches` map constructed, we compute the initial score for each diagonal and filter them based on the threshold $\\tau$. For each diagonal $d$ that has at least one seed, its score is given by $init1(d) = s_m \\cdot |M_d|$, where $|M_d|$ is the number of seeds on that diagonal and $s_m$ is the seed reward. We then form the retained diagonal set, $D_{\\tau} = \\{d \\in \\mathbb{Z} \\mid init1(d) \\ge \\tau\\}$. The first component of our output is the cardinality of this set, $|D_{\\tau}|$.\n\nThird, we calculate the total number of join operations, $J$. This calculation is performed only on the diagonals retained in the set $D_{\\tau}$. For each such diagonal $d \\in D_{\\tau}$, we retrieve the list of its contributing query indices, $M_d$. This list must be sorted in ascending order to analyze proximity: $i_1 < i_2 < \\dots < i_{t_d}$, where $t_d = |M_d|$. The number of joins for this single diagonal, $J_d$, is the count of adjacent index pairs $(i_\\ell, i_{\\ell+1})$ whose difference is within the proximity parameter $\\delta$, i.e., $i_{\\ell+1} - i_\\ell \\le \\delta$. The total number of joins, $J$, is the summation of these counts over all retained diagonals: $J = \\sum_{d \\in D_{\\tau}} J_d$. This is the second component of our output.\n\nFourth, we perform a validation check against the known homologous regions. The problem provides a set of true homologous diagonals, $D^\\star$. We must determine if our filtering procedure a successfully retained all these essential diagonals. This is formalized by checking if $D^\\star$ is a subset of our computed retained set $D_{\\tau}$. A boolean variable, $B$, is set to True if $D^\\star \\subseteq D_{\\tau}$, and False otherwise. This boolean is the third and final component of our output triple.\n\nBy executing these four steps for each of the provided test cases, we can generate the required output list $[|D_{\\tau}|, J, B]$ for each case and format them as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Main function to solve the FASTA trade-off problem for all test cases.\n    \"\"\"\n\n    def compute_fasta_metrics(Q, S, k, s_m, tau, delta, D_star):\n        \"\"\"\n        Computes the required metrics for a single FASTA test case.\n\n        Args:\n            Q (str): The query sequence.\n            S (str): The subject sequence.\n            k (int): The k-mer length.\n            s_m (int): The seed reward.\n            tau (int): The initial diagonal score threshold.\n            delta (int): The proximity parameter for joining.\n            D_star (list): The list of true homologous diagonals.\n\n        Returns:\n            list: A list containing [|D_tau|, J, B].\n        \"\"\"\n        L_Q = len(Q)\n        L_S = len(S)\n\n        # Step 1: Find all seeds and populate diagonal_matches.\n        # Create a lookup table for k-mer positions in the subject sequence S.\n        kmer_positions_s = defaultdict(list)\n        if L_S >= k:\n            for j in range(L_S - k + 1):\n                kmer = S[j : j + k]\n                kmer_positions_s[kmer].append(j)\n\n        # Find matches by iterating through k-mers in the query sequence Q.\n        diagonal_matches = defaultdict(list)\n        if L_Q >= k:\n            for i in range(L_Q - k + 1):\n                kmer = Q[i : i + k]\n                if kmer in kmer_positions_s:\n                    for j in kmer_positions_s[kmer]:\n                        d = i - j\n                        diagonal_matches[d].append(i)\n\n        # Step 2: Compute initial scores and filter diagonals.\n        D_tau = set()\n        retained_matches = {}\n        for d, M_d in diagonal_matches.items():\n            init1_score = s_m * len(M_d)\n            if init1_score >= tau:\n                D_tau.add(d)\n                retained_matches[d] = M_d\n        \n        num_stored_diagonals = len(D_tau)\n\n        # Step 3: Calculate total number of joins (J).\n        total_joins = 0\n        for d in D_tau:\n            M_d = retained_matches[d]\n            M_d.sort()  # Ensure indices are sorted for proximity check.\n            \n            joins_d = 0\n            if len(M_d) > 1:\n                for idx in range(len(M_d) - 1):\n                    if M_d[idx + 1] - M_d[idx] = delta:\n                        joins_d += 1\n            total_joins += joins_d\n\n        # Step 4: Check for homologous diagonals.\n        D_star_set = set(D_star)\n        B = D_star_set.issubset(D_tau)\n\n        return [num_stored_diagonals, total_joins, B]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 8, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 18, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"A\": \"ACGTCGATGCTAGTCA\",\n            \"B_seq\": \"TGACCTGATCGTAGCA\",\n            \"Q\": \"ACGTCGATGCTAGTCA\" + \"GGGG\" + \"TGACCTGATCGTAGCA\",\n            \"S\": \"TT\" + \"ACGTCGATGCTAGTCA\" + \"TTTTTT\" + \"TGACCTGATCGTAGCA\" + \"CC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 10, \"delta\": 5,\n            \"D_star\": [-2, -4]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_fasta_metrics(\n            case[\"Q\"], case[\"S\"], case[\"k\"], case[\"s_m\"], \n            case[\"tau\"], case[\"delta\"], case[\"D_star\"]\n        )\n        results.append(result)\n\n    # Convert results to a string representation for the final output.\n    # The boolean True/False needs to be capitalized as per Python's str() behavior.\n    result_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(result_str)\n\nsolve()\n```", "id": "2435286"}]}