{"hands_on_practices": [{"introduction": "The integrity and consistency of scientific data are paramount for reproducible research. In structural biology, the Protein Data Bank (PDB) format is the standard, but real-world files often contain minor inconsistencies, such as deprecated or non-standard names for amino acid residues. This exercise [@problem_id:2431200] introduces the crucial concept of a \"linter,\" a tool that validates data against a controlled vocabulary. By developing a script to identify and flag these discrepancies, you will practice parsing fixed-column data and learn the importance of data standardization in bioinformatics.", "problem": "You are to write a complete, runnable program that implements a validator for Protein Data Bank (PDB) flatfile records. The validator must detect residue names that are either deprecated synonyms or non-standard with respect to a specified controlled vocabulary. Your program must apply the rules below exactly as stated and must process a fixed suite of test cases defined in this problem.\n\nDefinitions and field layout:\n- Only records whose record name occupies positions $1$ through $6$ (inclusive, $1$-indexed) equal to either the exact string \"ATOM␣␣\" or the exact string \"HETATM\" are considered. All other record types must be ignored.\n- The residue name field occupies positions $18$ through $20$ (inclusive, $1$-indexed). If a line is shorter than position $20$ and therefore does not contain a complete residue name field, that line must be ignored.\n- A residue name $x$ is considered standard if and only if $x \\in S$, where $S$ is the set of canonical three-letter amino acid residue names together with water:\n  $S = \\{$ALA, ARG, ASN, ASP, CYS, GLN, GLU, GLY, HIS, ILE, LEU, LYS, MET, PHE, PRO, SER, THR, TRP, TYR, VAL, HOH$\\}$.\n- A mapping $M$ of deprecated synonyms to canonical residue names is specified. Any residue name $x \\in \\mathrm{dom}(M)$ is considered a deprecated synonym and must be flagged as such. The mapping is:\n  - WAT $\\mapsto$ HOH\n  - HID $\\mapsto$ HIS\n  - HIE $\\mapsto$ HIS\n  - HIP $\\mapsto$ HIS\n  - ASH $\\mapsto$ ASP\n  - GLH $\\mapsto$ GLU\n  - LYN $\\mapsto$ LYS\n  - CYX $\\mapsto$ CYS\n  - CYM $\\mapsto$ CYS\n- A residue name $x$ is considered non-standard if and only if $x \\notin S$ and $x \\notin \\mathrm{dom}(M)$.\n\nCounting rules:\n- For each input case, define $c_{\\mathrm{deprecated}}$ as the count of records with residue name in $\\mathrm{dom}(M)$, and define $c_{\\mathrm{nonstd}}$ as the count of records with residue name neither in $S$ nor in $\\mathrm{dom}(M)$.\n- Only the records of type \"ATOM␣␣\" and \"HETATM\" contribute to these counts, and only if they contain a complete residue name field (positions $18$–$20$ present).\n\nSynthesis of test inputs:\n- Each test case is specified as an ordered list of triples $(r, x, m)$ where $r$ is a record name string, $x$ is a $3$-letter uppercase residue name string, and $m \\in \\{0,1\\}$ is a binary indicator.\n- For each triple $(r, x, m)$, a single line is synthesized as follows:\n  1. Place $r$ left-justified into positions $1$–$6$ (pad with spaces on the right if needed).\n  2. Fill positions $7$–$16$ with spaces.\n  3. Place a single space in position $17$.\n  4. If $m = 0$, place the residue name $x$ into positions $18$–$20$; if $m = 1$, truncate the line before position $20$ so that the residue name field is absent.\n  5. Any characters beyond position $20$ are irrelevant and may be omitted.\n- The entire test case content is the concatenation of these synthesized lines separated by newline characters.\n\nTest suite:\n- Case $1$: [(\"ATOM␣␣\",\"ALA\",$0$), (\"ATOM␣␣\",\"GLY\",$0$), (\"HETATM\",\"HOH\",$0$)]\n- Case $2$: [(\"HETATM\",\"WAT\",$0$), (\"HETATM\",\"WAT\",$0$), (\"ATOM␣␣\",\"HIS\",$0$)]\n- Case $3$: [(\"ATOM␣␣\",\"HIE\",$0$), (\"ATOM␣␣\",\"HID\",$0$), (\"HETATM\",\"ABC\",$0$), (\"ATOM␣␣\",\"LYN\",$0$)]\n- Case $4$: [(\"ATOM␣␣\",\"GLU\",$1$), (\"ATOM␣␣\",\"GLH\",$0$), (\"TER␣␣␣\",\"GLY\",$0$), (\"HETATM\",\"MSE\",$0$)]\n- Case $5$: [] (the empty case)\n\nFor each case $i$, compute the pair $[c_{\\mathrm{deprecated}}^{(i)}, c_{\\mathrm{nonstd}}^{(i)}]$ as defined above.\n\nFinal output format:\n- Your program must produce a single line containing a JSON-like representation of a list of results, one per test case, in order, where each result is a two-element list $[c_{\\mathrm{deprecated}}, c_{\\mathrm{nonstd}}]$ for that case.\n- For example, an output for three cases would look like \"[[a,b],[c,d],[e,f]]\" with integers in place of $a,b,c,d,e,f$ and no extra whitespace.", "solution": "The problem statement has been rigorously validated and is found to be sound. It is scientifically grounded in the principles of bioinformatics, specifically concerning the parsing and validation of Protein Data Bank (PDB) file formats. The problem is well-posed, objective, and self-contained, providing all necessary definitions, rules, and data for a unique and verifiable solution. There are no logical contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with a solution.\n\nThe task is to implement a validator that processes a series of simulated PDB record lines and counts occurrences of deprecated and non-standard residue names based on a provided vocabulary. The solution requires a methodical application of a defined set of rules.\n\nThe core of the solution is an algorithm that iterates through a series of test cases. For each case, it processes a list of triples, $(r, x, m)$, where $r$ is a record name, $x$ is a residue name, and $m$ is a binary flag indicating if the record is truncated.\n\nFirst, we must define the controlled vocabularies. The set of standard residue names, $S$, is given as:\n$$ S = \\{\\text{ALA, ARG, ASN, ASP, CYS, GLN, GLU, GLY, HIS, ILE, LEU, LYS, MET, PHE, PRO, SER, THR, TRP, TYR, VAL, HOH}\\} $$\nThe mapping of deprecated synonyms, $M$, is also specified:\n$$ M = \\{ \\text{WAT} \\mapsto \\text{HOH}, \\text{HID} \\mapsto \\text{HIS}, \\text{HIE} \\mapsto \\text{HIS}, \\text{HIP} \\mapsto \\text{HIS}, \\text{ASH} \\mapsto \\text{ASP}, \\text{GLH} \\mapsto \\text{GLU}, \\text{LYN} \\mapsto \\text{LYS}, \\text{CYX} \\mapsto \\text{CYS}, \\text{CYM} \\mapsto \\text{CYS} \\} $$\nFrom this mapping, we derive the set of deprecated residue names, which is the domain of $M$, denoted $\\mathrm{dom}(M)$. For computational efficiency, $S$ will be implemented as a set data structure, offering average time complexity of $O(1)$ for membership tests. The mapping $M$ will be a dictionary or hash map, and its domain, $\\mathrm{dom}(M)$, will be derived from its keys, also forming a set for efficient lookups.\n\nThe algorithm proceeds as follows for each test case:\n1. Initialize two counters: $c_{\\mathrm{deprecated}} = 0$ and $c_{\\mathrm{nonstd}} = 0$.\n2. For each triple $(r, x, m)$ provided in the test case:\n    a. First, we apply the record-level filters. The record name $r$ must be either the exact string `\"ATOM  \"` or `\"HETATM\"`. If $r$ does not match, the triple is disregarded, and we proceed to the next one.\n    b. Second, we check for completeness. The problem specifies that lines shorter than position $20$ are to be ignored. The binary indicator $m$ synthesizes this rule: if $m = 1$, the line is considered truncated and the residue name field is absent. Therefore, if $m = 1$, the triple is also disregarded.\n    c. If a triple passes both filters (i.e., has a valid record name and is not truncated), its residue name $x$ is classified.\n    d. The classification logic is as follows:\n        i. If the residue name $x$ is present in the set of deprecated names, $x \\in \\mathrm{dom}(M)$, the counter $c_{\\mathrm{deprecated}}$ is incremented by $1$.\n        ii. If $x$ is not a deprecated synonym, we then check if it is non-standard. A residue is non-standard if $x \\notin S$ and $x \\notin \\mathrm{dom}(M)$. Since the first condition ($x \\in \\mathrm{dom}(M)$) has already been evaluated, this check simplifies to: if $x \\notin S$, the counter $c_{\\mathrm{nonstd}}$ is incremented by $1$. A standard residue ($x \\in S$) results in no change to the counters.\n3. After processing all triples for a given case, the resulting pair of counts, $[c_{\\mathrm{deprecated}}, c_{\\mathrm{nonstd}}]$, is recorded.\n\nThis procedure is repeated for all specified test cases. Finally, the collected list of result pairs is formatted into a single string, a JSON-like array of arrays, as specified by the problem's output format requirement. This ensures a deterministic and correct result for the provided test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n# No external libraries are needed for this problem.\n\ndef solve():\n    \"\"\"\n    Solves the PDB residue validator problem by processing a fixed suite of test cases.\n    \"\"\"\n    # Define the controlled vocabulary for standard and deprecated residue names.\n    # S is the set of canonical three-letter amino acid residue names plus water.\n    standard_residues = {\n        \"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLN\", \"GLU\", \"GLY\", \"HIS\", \n        \"ILE\", \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\", \"SER\", \"THR\", \"TRP\", \n        \"TYR\", \"VAL\", \"HOH\"\n    }\n\n    # M is the mapping of deprecated synonyms to canonical residue names.\n    deprecated_map = {\n        \"WAT\": \"HOH\", \"HID\": \"HIS\", \"HIE\": \"HIS\", \"HIP\": \"HIS\",\n        \"ASH\": \"ASP\", \"GLH\": \"GLU\", \"LYN\": \"LYS\", \"CYX\": \"CYS\",\n        \"CYM\": \"CYS\"\n    }\n    # The domain of M is the set of deprecated residue names.\n    deprecated_residues = set(deprecated_map.keys())\n\n    # Define the test suite as specified in the problem statement.\n    # Each case is a list of triples (record_name, residue_name, is_truncated_flag).\n    test_cases = [\n        # Case 1\n        [(\"ATOM  \", \"ALA\", 0), (\"ATOM  \", \"GLY\", 0), (\"HETATM\", \"HOH\", 0)],\n        # Case 2\n        [(\"HETATM\", \"WAT\", 0), (\"HETATM\", \"WAT\", 0), (\"ATOM  \", \"HIS\", 0)],\n        # Case 3\n        [(\"ATOM  \", \"HIE\", 0), (\"ATOM  \", \"HID\", 0), (\"HETATM\", \"ABC\", 0), (\"ATOM  \", \"LYN\", 0)],\n        # Case 4\n        [(\"ATOM  \", \"GLU\", 1), (\"ATOM  \", \"GLH\", 0), (\"TER   \", \"GLY\", 0), (\"HETATM\", \"MSE\", 0)],\n        # Case 5 (empty case)\n        []\n    ]\n\n    # A list to store the results for each test case.\n    all_results = []\n\n    # Process each test case.\n    for case in test_cases:\n        c_deprecated = 0\n        c_nonstd = 0\n\n        # Process each record (triple) in the current case.\n        for record_name, residue_name, is_truncated in case:\n            # Rule: Only \"ATOM  \" and \"HETATM\" records are considered.\n            if record_name not in (\"ATOM  \", \"HETATM\"):\n                continue\n\n            # Rule: If the record is truncated (m=1), the residue name field is absent and the line is ignored.\n            if is_truncated == 1:\n                continue\n\n            # Classify the residue name.\n            if residue_name in deprecated_residues:\n                c_deprecated += 1\n            elif residue_name not in standard_residues:\n                # This covers the non-standard case, as the deprecated case is already handled.\n                # A name is non-standard if it's not in standard_residues AND not in deprecated_residues.\n                c_nonstd += 1\n\n        # Store the result pair for the current case.\n        all_results.append([c_deprecated, c_nonstd])\n\n    # Format the final output string exactly as required, without any extra whitespace.\n    # Example format: [[a,b],[c,d],[e,f]]\n    result_strings = [f\"[{res[0]},{res[1]}]\" for res in all_results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2431200"}, {"introduction": "GenBank files are central to genomics, storing richly annotated sequences in a complex, semi-structured format. A common and essential task for bioinformaticians is to parse the \"FEATURES\" table, particularly the intricate location strings, to make the data usable for large-scale analysis. In this exercise [@problem_id:2431179], you will write a script to \"flatten\" these hierarchical GenBank records into a simple, tabular format by tackling nested operators like `join()` and `complement()`. This practice develops critical skills for transforming raw bioinformatics data into a clean, analysis-ready state.", "problem": "Write a complete program that reads an in-memory multi-entry National Center for Biotechnology Information (NCBI) GenBank flatfile and produces a logical flattening into a Tab-Separated Values (TSV) representation, where each row corresponds to a single biological feature. Instead of writing files, for each input in a provided test suite, compute a set of summary integers derived deterministically from the TSV rows and aggregate them into a single-line output as specified below.\n\nFormal specification of records and features:\n- A record begins at a line whose first token is the literal string \"LOCUS\" and ends at a line that is exactly \"//\".\n- The accession identifier for a record is the first non-space token that appears on the line whose first token is \"ACCESSION\". Use that token unchanged.\n- The features block of a record begins at the line whose first token is \"FEATURES\" and ends strictly before the line whose first token is \"ORIGIN\" or the record terminator line \"//\", whichever appears first.\n- Feature entries appear within the features block. A feature entry consists of:\n  - A feature key (for example, \"source\", \"gene\", \"CDS\", \"mRNA\", \"misc_feature\", \"repeat_region\") followed by a location expression. The first non-space token on a line not starting with \"/\" is interpreted as the feature key, and the remainder of that line, together with any immediately following lines of the features block that are not starting with \"/\" and are visually indented more deeply than the key line, together form the location expression for that feature. Qualifiers (lines beginning with \"/\") and their continuations are present but must be ignored for the purpose of computing the requested summary integers in this task. Lines within the features block visually indented more deeply than the key line that start with \"/\" are qualifiers and do not contribute to the location. Qualifier continuations are lines within the features block that are visually indented more deeply than the key line and do not start with \"/\".\n  - For this problem, treat all feature keys as valid and include all features in the TSV if and only if their location expression yields at least one on-sequence interval under the rules below.\n\nLocation expression interpretation rules:\n- The location expression is to be parsed over the alphabet consisting of letters, digits, parentheses, commas, colons, dots, carets, less-than and greater-than symbols. All whitespace in the location expression is insignificant and is to be ignored during interpretation.\n- The base coordinate system is one-based and inclusive. If a location denotes a single base position, it contributes an interval whose start and end are that base. If a location denotes a closed range with two base positions separated by two dots, it contributes an interval whose inclusive endpoints are those two bases.\n- The only location constructs to support are:\n  - The symbol \"complement(\" applied to a balanced parenthetic subexpression.\n  - The symbols \"join(\" or \"order(\" applied to a comma-separated list of balanced subexpressions.\n  - Single-base coordinates and closed ranges with the potential presence of the characters \"<\" or \">\" immediately preceding a base coordinate; these characters indicate fuzziness and must be ignored when extracting the numeric value.\n  - Remote intervals indicated by a prefix of the form \"X:\" immediately before a single base or closed range, where \"X\" is any non-empty sequence of non-colon characters. Remote intervals must be completely ignored and treated as contributing no on-sequence interval.\n- The overall strand to report is determined exclusively by whether the outermost syntactic form of the entire location expression is a single \"complement(\" wrapper whose matching closing parenthesis is the final character of the expression. If and only if that condition holds, report the strand as the single character \"-\"; otherwise report the strand as the single character \"+\".\n- For purposes of this problem, do not consider or attempt to detect mixed-orientation substructures; the only required strand rule is the one stated above.\n- When a location expression contains \"join(\" or \"order(\", compute the feature’s reported start as the minimum numeric start among all non-remote intervals contained anywhere within the expression (recursively), and compute the feature’s reported end as the maximum numeric end among all such intervals. If after ignoring all remote intervals there are no remaining on-sequence intervals, the feature must be omitted from the TSV.\n- Let the reported inclusive length of a TSV row be defined by the formula $L = E - S + 1$, where $S$ is the reported start and $E$ is the reported end of that row.\n\nTSV logical schema to be used for this problem:\n- Each TSV row comprises the following fields in order: accession, feature key, start, end, strand. The accession is the record accession string as defined above. The start and end are decimal integers according to the interpretation rules above. The strand is the single character \"+\" or \"-\".\n\nRequired computed outputs for each input in the test suite:\n- For each input, after constructing the TSV rows by applying the rules above across all records in that input, compute and return the list $[T, C, \\Sigma, M]$, where:\n  - $T$ is the total number of TSV rows constructed (an integer).\n  - $C$ is the number of TSV rows whose feature key string is exactly \"CDS\" (an integer).\n  - $\\Sigma$ is the sum over all TSV rows of the inclusive lengths $L$ (an integer).\n  - $M$ is the number of TSV rows whose strand is \"-\" (an integer).\n\nTest suite:\n- Your program must compute results for the following three inputs. Each input is a complete multi-entry GenBank flatfile content in plain text. The inputs are specified here by their records and features, and your program must embed corresponding strings that satisfy the described structure.\n\n  Input $1$ (two records):\n  - Record with accession \"REC1\" and the following features and locations:\n    - source: $1..100$\n    - gene: $10..20$\n    - CDS: $complement(10..20)$\n    - mRNA: $join(10..12,15..20)$\n  - Record with accession \"REC2\" and the following features and locations:\n    - source: $1..200$\n    - gene: $join(50..60,80..90)$\n    - CDS: $join(50..60,80..90)$\n\n  Input $2$ (one record):\n  - Record with accession \"REC3\" and the following features and locations:\n    - source: $1..1000$\n    - gene: $<5..>10$ (treat as $5..10$ for numeric purposes)\n    - misc_feature: $100$\n    - CDS: $join(200..210,RECX:300..310)$ (ignore the remote interval $RECX:300..310$)\n    - repeat_region: $complement(500)$\n    - misc_feature: $join(700..705,710..715,720..725)$\n\n  Input $3$ (one record):\n  - Record with accession \"REC4\" and the following features and locations:\n    - source: $1..300$\n    - gene: $complement(join(50..60,70..80))$\n    - CDS: $complement(join(50..60,70..80))$\n    - misc_feature: $join(RECZ:10..20,RECY:30..40)$ (remote-only; omit entirely)\n    - gene: $250..260$\n\nFinal output format:\n- Your program must produce a single line of output containing a list of three lists, one per input, in input order. For each input, output the list $[T,C,\\Sigma,M]$ defined above. The single line must be exactly a comma-separated list enclosed in square brackets, with each inner list also enclosed in square brackets and with no spaces, for example: \"[[1,2,3,4],[5,6,7,8],[9,10,11,12]]\".", "solution": "The problem proposed is a well-defined task in computational biology, specifically in the domain of bioinformatics data parsing. It requires the implementation of a parser for a simplified, yet representative, subset of the GenBank flatfile format. The objective is to extract structured information from semi-structured text data, a common and fundamental challenge in the field.\n\nThe problem statement is validated as follows:\n\n**Step 1: Extract Givens**\n\n*   **Record Structure**: A record begins with a line starting with `LOCUS` and ends with a line containing exactly `//`.\n*   **Accession ID**: The first non-space token on the `ACCESSION` line.\n*   **Features Block**: Begins at the `FEATURES` line and ends just before `ORIGIN` or `//`.\n*   **Feature Entry**: Consists of a feature key and a location expression. The key is the first non-space token on a non-qualifier line. The location is the rest of that line, plus any immediately following, more deeply indented lines that do not begin with `/`.\n*   **Qualifiers**: Lines starting with `/` and their continuations are to be ignored.\n*   **Location Expression Parsing**:\n    *   Whitespace is insignificant.\n    *   Coordinates are $1$-based and inclusive. A single number $N$ represents the interval $[N, N]$.\n    *   Supported constructs: `complement(...)`, `join(...)`, `order(...)`, single numbers, ranges `N..M`, fuzzy markers `<` and `>` (to be ignored), and remote intervals `X:...` (to be ignored).\n*   **Strand Rule**: The strand is `-` if and only if the *entire* location string is wrapped in `complement(...)`. Otherwise, it is `+`.\n*   **Start/End for `join`/`order`**: For features with `join` or `order`, the start is the minimum of all start coordinates from non-remote sub-intervals, and the end is the maximum of all end coordinates from the same.\n*   **Omission Rule**: Features with no on-sequence intervals (after ignoring remote ones) are excluded from the output.\n*   **TSV Schema**: `(accession, feature_key, start, end, strand)`.\n*   **Length Definition**: The length $L$ of a feature is $E - S + 1$, where $S$ is the start and $E$ is the end.\n*   **Summary Outputs**: For each input file, a list $[T, C, \\Sigma, M]$ must be computed, where:\n    *   $T$: Total count of TSV rows.\n    *   $C$: Count of rows where the feature key is `CDS`.\n    *   $\\Sigma$: Sum of all lengths $L$.\n    *   $M$: Count of rows where the strand is `-`.\n*   **Test Suite**: Three specific multi-record/multi-feature inputs are provided.\n*   **Final Output Format**: A single line representing a list of lists, e.g., `[[T1,C1,S1,M1],[T2,C2,S2,M2],...]`.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria:\n\n*   **Scientifically Grounded**: The problem is an accurate, if simplified, representation of parsing GenBank files, a standard task in bioinformatics. The concepts of accessions, features, location strings, and strands are fundamental to molecular biology and genomics. It is scientifically sound.\n*   **Well-Posed**: The problem is well-posed. The rules for parsing, though simplified, are explicit and unambiguous. For instance, the strand determination is reduced to a simple syntactic check, and the handling of `join`/`order` is precisely defined as taking the minimum start and maximum end. This ensures a unique, deterministic solution can be derived.\n*   **Objective**: The problem is formulated with objective, technical language, free from subjectivity or ambiguity.\n\nThe problem does not exhibit any invalidating flaws. It is not based on false premises, is formalizable, is self-contained, requires feasible computations, and is well-structured.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. A solution will be constructed.\n\nThe overall algorithm will process each input string by first segmenting it into individual GenBank records. For each record, it will extract the accession number and then isolate the features block. A dedicated parser for the features block will iterate through its lines, identifying each feature key and its complete, potentially multi-line, location string, correctly handling indentation as per the rules.\n\nThe core of the solution is a recursive parser for the location string. This parser will be designed to handle the specified constructs: `complement()`, `join()`, and `order()`.\n\n1.  A function `_get_intervals` will recursively descend through the location string structure. It will decompose `join` and `order` constructs by splitting their arguments at top-level commas (i.e., commas not enclosed in parentheses). It will strip `complement` wrappers.\n2.  The recursion terminates at base cases: simple coordinates ($N$) or ranges ($N..M$). Remote intervals (containing `:`) are identified and yield no coordinates. Fuzzy markers (`<`, `>`) are removed before numeric conversion.\n3.  This recursive function will return a flat list of all elementary, non-remote `(start, end)` coordinate pairs found within the location string.\n4.  A higher-level function, `parse_location`, will orchestrate this process. First, it determines the strand based on the top-level structure of the raw location string. Then, it calls `_get_intervals`. If the returned list of intervals is empty, the feature is discarded. Otherwise, it calculates the feature's final start as the minimum of all start coordinates and the final end as the maximum of all end coordinates.\n5.  After processing all features from all records in an input, the summary statistics $T$, $C$, $\\Sigma$, and $M$ are calculated from the collected set of valid TSV rows. This process is repeated for each input in the test suite, and the results are aggregated into the specified final format.\n\nLet us trace an example: `complement(join(50..60,70..80))`.\n1.  `parse_location` is called with this string. It sees the `complement(...)` wrapper and sets strand to `-`.\n2.  It then calls `_get_intervals` on the inner part, `join(50..60,70..80)`.\n3.  `_get_intervals` sees `join(...)` and calls itself on the comma-separated parts: `50..60` and `70..80`.\n4.  For `50..60`, the base case is reached, returning `[(50, 60)]`.\n5.  For `70..80`, the base case is reached, returning `[(70, 80)]`.\n6.  The `join` level combines these into `[(50, 60), (70, 80)]`.\n7.  `parse_location` receives this list. It is not empty. It computes start = $\\min(50, 70) = 50$ and end = $\\max(60, 80) = 80$.\n8.  The final parsed feature data is `(start=50, end=80, strand='-')`. The length is $80 - 50 + 1 = 31$.\n\nThis structured, recursive approach correctly implements the specified logic for all cases. The implementation will be encapsulated within a Python program adhering to the specified constraints.", "answer": "```python\nimport re\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print the final result.\n    \"\"\"\n    # Construct GenBank flatfile strings for the test suite.\n    # The indentation is crucial for correct parsing based on problem rules.\n    input1 = \"\"\"LOCUS       REC1   100 bp    DNA     linear   SYN 01-JAN-2023\nACCESSION   REC1\nFEATURES             Location/Qualifiers\n     source          1..100\n     gene            10..20\n     CDS             complement(10..20)\n     mRNA            join(10..12,15..20)\n//\nLOCUS       REC2   200 bp    DNA     linear   SYN 01-JAN-2023\nACCESSION   REC2\nFEATURES             Location/Qualifiers\n     source          1..200\n     gene            join(50..60,80..90)\n     CDS             join(50..60,80..90)\n//\n\"\"\"\n\n    input2 = \"\"\"LOCUS       REC3   1000 bp   DNA     linear   SYN 01-JAN-2023\nACCESSION   REC3\nFEATURES             Location/Qualifiers\n     source          1..1000\n     gene            <5..>10\n     misc_feature    100\n     CDS             join(200..210,RECX:300..310)\n     repeat_region   complement(500)\n     misc_feature    join(700..705,710..715,720..725)\n//\n\"\"\"\n\n    input3 = \"\"\"LOCUS       REC4   300 bp    DNA     linear   SYN 01-JAN-2023\nACCESSION   REC4\nFEATURES             Location/Qualifiers\n     source          1..300\n     gene            complement(join(50..60,70..80))\n     CDS             complement(join(50..60,70..80))\n     misc_feature    join(RECZ:10..20,RECY:30..40)\n     gene            250..260\n//\n\"\"\"\n    test_cases = [input1, input2, input3]\n    all_results = [process_gbk_content(case) for case in test_cases]\n    \n    # Format the final output string as specified.\n    result_str = \",\".join(map(str, all_results))\n    print(f\"[{result_str}]\".replace(\" \", \"\"))\n\ndef _split_on_top_level_comma(text):\n    \"\"\"\n    Splits a string by commas that are not inside parentheses.\n    Example: \"join(a,b),c\" -> [\"join(a,b)\", \"c\"]\n    \"\"\"\n    parts = []\n    balance = 0\n    start_index = 0\n    for i, char in enumerate(text):\n        if char == '(':\n            balance += 1\n        elif char == ')':\n            balance -= 1\n        elif char == ',' and balance == 0:\n            parts.append(text[start_index:i])\n            start_index = i + 1\n    parts.append(text[start_index:])\n    return parts\n\ndef _get_intervals_recursive(loc_str):\n    \"\"\"\n    Recursively parses a location string to find all elementary, non-remote intervals.\n    Returns a list of (start, end) tuples.\n    \"\"\"\n    # Normalize by removing all whitespace\n    loc_str = \"\".join(loc_str.split())\n\n    # Handle complement(), join(), order() recursively\n    if (m := re.fullmatch(r\"complement\\((.*)\\)\", loc_str)):\n        return _get_intervals_recursive(m.group(1))\n    \n    if (m := re.fullmatch(r\"(?:join|order)\\((.*)\\)\", loc_str)):\n        sub_locs_str = m.group(1)\n        sub_locs = _split_on_top_level_comma(sub_locs_str)\n        intervals = []\n        for sub in sub_locs:\n            intervals.extend(_get_intervals_recursive(sub))\n        return intervals\n\n    # Base case: handle simple coordinates, ranges, and remote intervals\n    if ':' in loc_str:  # Ignore remote intervals\n        return []\n\n    # Ignore fuzziness markers\n    loc_str = loc_str.replace('<', '').replace('>', '')\n\n    # Find all numbers in the simple location string\n    nums = [int(n) for n in re.findall(r\"\\d+\", loc_str)]\n\n    if len(nums) == 1:\n        return [(nums[0], nums[0])]\n    elif len(nums) == 2:\n        return [(min(nums), max(nums))]\n    \n    return []\n\ndef parse_location_string(raw_location_string):\n    \"\"\"\n    Parses a complete location string to determine start, end, and strand.\n    Returns a tuple (start, end, strand) or None if the feature has no on-sequence parts.\n    \"\"\"\n    clean_loc = raw_location_string.strip()\n    \n    # Determine strand based on the outermost structure\n    strand = '-' if clean_loc.startswith('complement(') and clean_loc.endswith(')') else '+'\n    \n    intervals = _get_intervals_recursive(raw_location_string)\n\n    if not intervals:\n        return None\n\n    starts = [i[0] for i in intervals]\n    ends = [i[1] for i in intervals]\n    \n    min_start = min(starts)\n    max_end = max(ends)\n    \n    return min_start, max_end, strand\n\ndef parse_features_block(feature_lines):\n    \"\"\"\n    Parses the lines of a FEATURES block into a list of key-location dictionaries.\n    \"\"\"\n    features = []\n    i = 0\n    while i < len(feature_lines):\n        line = feature_lines[i]\n        stripped_line = line.lstrip()\n        \n        # Skip empty lines and qualifier lines\n        if not stripped_line or stripped_line.startswith('/'):\n            i += 1\n            continue\n\n        # Found a new feature line\n        key_line_indent = len(line) - len(stripped_line)\n        tokens = stripped_line.split(None, 1)\n        key = tokens[0]\n        location = tokens[1] if len(tokens) > 1 else \"\"\n\n        # Greedily consume subsequent continuation lines for the location\n        j = i + 1\n        while j < len(feature_lines):\n            next_line = feature_lines[j]\n            next_stripped = next_line.lstrip()\n            next_indent = len(next_line) - len(next_stripped)\n            \n            # A location continuation must be more indented and not a qualifier\n            if next_indent > key_line_indent and next_stripped and not next_stripped.startswith('/'):\n                location += next_stripped # Whitespace is ignored in location string later\n                j += 1\n            else:\n                break\n        \n        features.append({'key': key, 'location': location})\n        i = j  # Continue parsing from the line after the consumed block\n    return features\n\n\ndef process_gbk_content(gbk_content):\n    \"\"\"\n    Processes a complete GenBank file content string and computes summary statistics.\n    Returns the list [T, C, Sigma, M].\n    \"\"\"\n    tsv_rows = []\n    \n    # Split content into records\n    # The trailing `\\n` in `//\\n` is important for splitting multi-record files.\n    records_text = filter(None, gbk_content.split('//\\n'))\n\n    for record_text in records_text:\n        lines = record_text.splitlines()\n        accession = \"\"\n        in_features = False\n        feature_lines = []\n\n        for line in lines:\n            if line.startswith('ACCESSION'):\n                accession = line.split()[1]\n            elif line.startswith('FEATURES'):\n                in_features = True\n            elif line.startswith('ORIGIN') or line.startswith('//'):\n                in_features = False\n            elif in_features:\n                feature_lines.append(line)\n        \n        parsed_features = parse_features_block(feature_lines)\n\n        for feature in parsed_features:\n            key = feature['key']\n            location_str = feature['location']\n            \n            parsed_loc = parse_location_string(location_str)\n            if parsed_loc:\n                start, end, strand = parsed_loc\n                length = end - start + 1\n                tsv_rows.append({\n                    'key': key,\n                    'strand': strand,\n                    'length': length\n                })\n\n    T = len(tsv_rows)\n    C = sum(1 for row in tsv_rows if row['key'] == 'CDS')\n    Sigma = sum(row['length'] for row in tsv_rows)\n    M = sum(1 for row in tsv_rows if row['strand'] == '-')\n    \n    return [T, C, Sigma, M]\n\n# The script is designed to be executed directly.\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2431179"}, {"introduction": "We now return to the PDB format, moving beyond syntax validation to perform a meaningful scientific analysis. The precise 3D coordinates stored in PDB files are not just numbers; they represent the physical reality of a molecule, enabling us to investigate its function and interactions. This culminating exercise [@problem_id:2431199] guides you in using this coordinate data to identify water molecules that form \"bridges\" between different protein chains, a common and important structural motif. By applying geometric calculations to parsed data, you'll see firsthand how structural data formats provide the foundation for answering tangible biological questions.", "problem": "You are given textual fragments that conform to the Protein Data Bank (PDB) flatfile format, each consisting of lines that begin with either \"ATOM\" or \"HETATM\". Each line encodes one atom. Interpret the fields of each atom line as follows, in order when splitting by whitespace: record name, atom serial number, atom name, residue name, chain identifier, residue sequence number, Cartesian coordinates $x$, $y$, $z$ in Angstroms, occupancy, temperature factor, and element symbol. Treat only lines whose record name equals the literal string \"ATOM\" as protein atoms. Treat water molecules as residues with record name equal to the literal string \"HETATM\" and residue name equal to the literal string \"HOH\". For each water residue, consider only the atom whose atom name equals the literal string \"O\" as the position of that water.\n\nDefine the Euclidean distance between two atoms with coordinates $(x_1,y_1,z_1)$ and $(x_2,y_2,z_2)$ in Angstroms as\n$$\nd\\big((x_1,y_1,z_1),(x_2,y_2,z_2)\\big)=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}.\n$$\nLet the nonnegative real number $r$ (in Angstroms) denote a distance cutoff. A water residue acts as a bridge between two different protein chains if and only if there exist two distinct protein chain identifiers $c_1$ and $c_2$ with $c_1\\neq c_2$, and there exists at least one protein atom in chain $c_1$ with distance $\\leq r$ to the water oxygen atom, and at least one protein atom in chain $c_2$ with distance $\\leq r$ to the water oxygen atom. For each test case below, you must identify all such bridging water residues and report their residue sequence numbers as integers, sorted in ascending order. Distances must be computed in Angstroms and the cutoff $r$ must be applied with the inclusive condition $\\leq r$.\n\nYour program must process the following test suite, where each test case is a pair consisting of a PDB text block and a cutoff $r$ in Angstroms:\n\n- Test case 1:\n  - PDB:\n    ATOM      1  CA  ALA A   1       0.000   0.000   0.000  1.00 20.00           C\n    ATOM      2  CA  ALA B   1       6.000   0.000   0.000  1.00 20.00           C\n    HETATM  101  O   HOH W 101       3.000   0.000   0.000  1.00 10.00           O\n    HETATM  102  O   HOH W 102       0.000   3.100   0.000  1.00 10.00           O\n    HETATM  103  O   HOH W 103      20.000  20.000  20.000  1.00 10.00           O\n  - $r = 3.2$\n- Test case 2:\n  - PDB:\n    ATOM      1  CA  GLY A   1       0.000   0.000   0.000  1.00 20.00           C\n    ATOM      2  CA  GLY B   1       7.000   0.000   0.000  1.00 20.00           C\n    HETATM  201  O   HOH W 201       3.500   0.000   0.000  1.00 10.00           O\n    HETATM  202  O   HOH W 202       3.500   3.500   0.000  1.00 10.00           O\n  - $r = 3.5$\n- Test case 3:\n  - PDB:\n    ATOM      1  CA  LYS A   1       0.000   0.000   0.000  1.00 20.00           C\n    ATOM      2  CA  LYS B   1       0.000   6.000   0.000  1.00 20.00           C\n    ATOM      3  CA  LYS C   1      10.000   0.000   0.000  1.00 20.00           C\n    HETATM  301  O   HOH W 301       0.000   3.000   0.000  1.00 10.00           O\n    HETATM  302  O   HOH W 302       5.000   0.000   0.000  1.00 10.00           O\n    HETATM  303  O   HOH W 303      12.500   0.000   0.000  1.00 10.00           O\n  - $r = 5.0$\n- Test case 4:\n  - PDB:\n    ATOM      1  CA  SER A   1       0.000   0.000   0.000  1.00 20.00           C\n    ATOM      2  CA  SER B   1       8.000   0.000   0.000  1.00 20.00           C\n    HETATM  401  O   HOH W 401       2.500   0.000   0.000  1.00 10.00           O\n    HETATM  402  O   HOH W 402       4.000   0.000   0.000  1.00 10.00           O\n    HETATM  900  FE  HEM L   1       2.500   0.000   0.000  1.00 15.00           FE\n  - $r = 4.0$\n\nFor each test case, the required output is a list of integers representing the residue sequence numbers of all water residues that are bridges according to the definition above, sorted in ascending order. Your program should produce a single line of output containing the results for all four test cases as a comma-separated list of these lists, enclosed in square brackets, with no spaces. For example, a valid output format would be \"[[a,b],[c],[d,e,f],[]]\" where $a$, $b$, $c$, $d$, $e$, and $f$ are integers.", "solution": "The problem will first be subjected to a rigorous validation process.\n\nStep 1: Extract Givens\n\n- **Input Data**: A set of textual fragments conforming to the Protein Data Bank (PDB) flatfile format.\n- **Line Types**: Each line begins with \"ATOM\" or \"HETATM\".\n- **PDB Line Fields (whitespace-separated)**:\n    1. Record name\n    2. Atom serial number\n    3. Atom name\n    4. Residue name\n    5. Chain identifier\n    6. Residue sequence number\n    7. Cartesian coordinate $x$ (in Angstroms)\n    8. Cartesian coordinate $y$ (in Angstroms)\n    9. Cartesian coordinate $z$ (in Angstroms)\n    10. Occupancy\n    11. Temperature factor\n    12. Element symbol\n- **Protein Atom Definition**: A line whose record name is the literal string \"ATOM\".\n- **Water Molecule Definition**: A residue with record name \"HETATM\" and residue name \"HOH\".\n- **Water Position Definition**: For a water residue, its position is defined by the coordinates of the atom whose atom name is \"O\".\n- **Distance Metric**: The Euclidean distance between two atoms at $(x_1, y_1, z_1)$ and $(x_2, y_2, z_2)$ is $d = \\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2 + (z_1-z_2)^2}$.\n- **Distance Cutoff**: A non-negative real number $r$ in Angstroms.\n- **Bridging Water Definition**: A water residue acts as a bridge if its oxygen atom is at a distance less than or equal to $r$ ($\\leq r$) from at least one protein atom in a chain $c_1$ and also from at least one protein atom in a different chain $c_2$, where $c_1 \\neq c_2$.\n- **Required Output**: For each test case, a list of integer residue sequence numbers of all bridging water residues, sorted in ascending order. The final output for all test cases is a comma-separated list of these lists, within a single pair of square brackets.\n- **Test Suite**: Four specific test cases are provided, each with a PDB text block and a corresponding cutoff value $r$.\n\nStep 2: Validate Using Extracted Givens\n\n- **Scientifically Grounded**: The problem is based on fundamental concepts in structural biology and bioinformatics. The PDB format is a standard for representing three-dimensional structures of biological macromolecules. The concept of water-mediated bridges between protein chains is a well-established principle in protein-protein interactions and protein stability analysis. The Euclidean distance is the standard metric for spatial calculations in this context. The problem is scientifically valid and realistic.\n- **Well-Posed**: The problem is clearly defined. All terms such as \"protein atom\", \"water molecule\", \"bridging water\", and \"distance\" are given precise, unambiguous definitions. The input data is provided, and the expected output format is specified. For any given input, the set of rules leads to a single, deterministic outcome. A unique solution exists and can be computed.\n- **Objective**: The problem statement is free of subjective language, opinions, or speculation. All criteria are based on objective, quantifiable measures (record names, distances, counts).\n- **Completeness and Consistency**: The problem is self-contained. All necessary information to solve it is provided within the statement, including the data for all test cases and the exact definitions to be used. There are no contradictions in the provided rules. For example, the criteria for \"ATOM\" and \"HETATM\" records are mutually exclusive for the purposes of categorization into protein vs. water.\n- **Feasibility and Realism**: The coordinate values and distances are physically plausible for atomic structures. The computational task is straightforward and does not require unrealistic resources.\n- **Structure**: The problem is well-structured and does not contain circular reasoning or tautologies.\n\nStep 3: Verdict and Action\n\nThe problem is **valid**. It is scientifically grounded, well-posed, objective, and self-contained. Therefore, a solution will be developed.\n\nThe solution requires implementing an algorithm that processes each test case according to the given rules. The algorithm can be structured as follows:\n\n1.  **Data Parsing and Segregation**: For each test case, parse the provided multi-line PDB string. Iterate through each line, split it by whitespace to extract the relevant fields. Based on the record name and residue name, categorize each relevant atom.\n    -   If the record name is \"ATOM\", store its chain identifier (field 5) and its coordinates (fields 7-9) as a protein atom.\n    -   If the record name is \"HETATM\", the residue name is \"HOH\", and the atom name is \"O\", store its residue sequence number (field 6) and its coordinates (fields 7-9) as a water molecule.\n    -   All other lines (e.g., other `HETATM` types like the `FE` in a `HEM` group) are ignored as per the problem definition.\n\n2.  **Bridging Logic**: For each identified water molecule, determine if it functions as a bridge.\n    -   Initialize an empty set, `contacted_chains`, to store the unique identifiers of protein chains that are in close contact with the current water molecule.\n    -   Iterate through all aformentioned protein atoms.\n    -   For each protein atom, calculate the squared Euclidean distance to the current water molecule's oxygen atom. The squared distance is given by $d^2 = (x_w - x_p)^2 + (y_w - y_p)^2 + (z_w - z_p)^2$, where $(x_w, y_w, z_w)$ are the water coordinates and $(x_p, y_p, z_p)$ are the protein atom coordinates.\n    -   Comparing $d^2$ with $r^2$ is computationally more efficient than calculating the square root. If $d^2 \\leq r^2$, the protein atom is within the cutoff distance.\n    -   If a protein atom is within the cutoff, add its chain identifier to the `contacted_chains` set. The use of a set automatically handles uniqueness.\n    -   After checking all protein atoms against the current water molecule, inspect the size of the `contacted_chains` set.\n    -   If the number of elements in `contacted_chains` is greater than or equal to $2$, the water molecule bridges at least two different chains and is therefore a \"bridging water\". Add its residue sequence number to a list of results for the current test case.\n\n3.  **Finalization**: After iterating through all water molecules in a test case, sort the collected list of bridging water residue sequence numbers in ascending order. Repeat this entire process for all test cases in the suite.\n\n4.  **Output Formatting**: Aggregate the sorted lists of residue numbers from all test cases into a final structure as specified: a single string representing a list of lists.\n\nThe use of `numpy` arrays is highly advisable for storing coordinates, as it enables vectorized and efficient computation of distances, which is superior to performing calculations in a simple Python loop, especially for larger datasets. For a given water molecule with coordinate vector $\\vec{v}_w$, and a set of $N$ protein atoms with coordinate matrix $\\mathbf{P}$ (of shape $N \\times 3$), the squared distances can be computed in a single operation by broadcasting $\\vec{v}_w$ across all rows of $\\mathbf{P}$ and summing the squared differences along the coordinate axis.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the bridging water identification problem for a suite of test cases.\n    \"\"\"\n    test_suite = [\n        {\n            \"pdb_text\": \"\"\"\nATOM      1  CA  ALA A   1       0.000   0.000   0.000  1.00 20.00           C\nATOM      2  CA  ALA B   1       6.000   0.000   0.000  1.00 20.00           C\nHETATM  101  O   HOH W 101       3.000   0.000   0.000  1.00 10.00           O\nHETATM  102  O   HOH W 102       0.000   3.100   0.000  1.00 10.00           O\nHETATM  103  O   HOH W 103      20.000  20.000  20.000  1.00 10.00           O\n\"\"\",\n            \"r\": 3.2\n        },\n        {\n            \"pdb_text\": \"\"\"\nATOM      1  CA  GLY A   1       0.000   0.000   0.000  1.00 20.00           C\nATOM      2  CA  GLY B   1       7.000   0.000   0.000  1.00 20.00           C\nHETATM  201  O   HOH W 201       3.500   0.000   0.000  1.00 10.00           O\nHETATM  202  O   HOH W 202       3.500   3.500   0.000  1.00 10.00           O\n\"\"\",\n            \"r\": 3.5\n        },\n        {\n            \"pdb_text\": \"\"\"\nATOM      1  CA  LYS A   1       0.000   0.000   0.000  1.00 20.00           C\nATOM      2  CA  LYS B   1       0.000   6.000   0.000  1.00 20.00           C\nATOM      3  CA  LYS C   1      10.000   0.000   0.000  1.00 20.00           C\nHETATM  301  O   HOH W 301       0.000   3.000   0.000  1.00 10.00           O\nHETATM  302  O   HOH W 302       5.000   0.000   0.000  1.00 10.00           O\nHETATM  303  O   HOH W 303      12.500   0.000   0.000  1.00 10.00           O\n\"\"\",\n            \"r\": 5.0\n        },\n        {\n            \"pdb_text\": \"\"\"\nATOM      1  CA  SER A   1       0.000   0.000   0.000  1.00 20.00           C\nATOM      2  CA  SER B   1       8.000   0.000   0.000  1.00 20.00           C\nHETATM  401  O   HOH W 401       2.500   0.000   0.000  1.00 10.00           O\nHETATM  402  O   HOH W 402       4.000   0.000   0.000  1.00 10.00           O\nHETATM  900  FE  HEM L   1       2.500   0.000   0.000  1.00 15.00           FE\n\"\"\",\n            \"r\": 4.0\n        }\n    ]\n\n    all_results = []\n\n    for case in test_suite:\n        pdb_text = case[\"pdb_text\"]\n        r = case[\"r\"]\n        r_squared = r**2\n\n        protein_atoms = [] # List of tuples: (chain_id, np.array([x, y, z]))\n        water_molecules = [] # List of tuples: (res_seq_num, np.array([x, y, z]))\n\n        lines = pdb_text.strip().split('\\n')\n        for line in lines:\n            fields = line.split()\n            record_name = fields[0]\n            \n            if record_name == \"ATOM\":\n                chain_id = fields[4]\n                coords = np.array([float(fields[6]), float(fields[7]), float(fields[8])])\n                protein_atoms.append((chain_id, coords))\n            elif record_name == \"HETATM\":\n                atom_name = fields[2]\n                res_name = fields[3]\n                if res_name == \"HOH\" and atom_name == \"O\":\n                    res_seq_num = int(fields[5])\n                    coords = np.array([float(fields[6]), float(fields[7]), float(fields[8])])\n                    water_molecules.append((res_seq_num, coords))\n\n        if not protein_atoms:\n            all_results.append([])\n            continue\n\n        protein_chain_ids = np.array([p[0] for p in protein_atoms])\n        protein_coords = np.array([p[1] for p in protein_atoms])\n\n        bridging_waters = []\n        for water_res_seq, water_coord in water_molecules:\n            # Calculate squared Euclidean distances from this water to all protein atoms\n            squared_distances = np.sum((protein_coords - water_coord)**2, axis=1)\n            \n            # Find which protein atoms are within the cutoff\n            contact_mask = squared_distances <= r_squared\n            \n            # Get the unique chain IDs of the contacted protein atoms\n            contacted_chains = set(protein_chain_ids[contact_mask])\n            \n            # A water is a bridge if it contacts 2 or more distinct chains\n            if len(contacted_chains) >= 2:\n                bridging_waters.append(water_res_seq)\n        \n        bridging_waters.sort()\n        all_results.append(bridging_waters)\n\n    # Format the final output string\n    result_str = \",\".join([str(res) for res in all_results])\n    print(f\"[{result_str}]\".replace(\" \", \"\"))\n\nsolve()\n```", "id": "2431199"}]}