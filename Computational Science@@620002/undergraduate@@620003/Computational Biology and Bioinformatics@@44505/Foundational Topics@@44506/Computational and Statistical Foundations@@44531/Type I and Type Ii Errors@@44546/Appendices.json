{"hands_on_practices": [{"introduction": "Imagine developing a near-perfect test for a rare genetic disease. When screening a large population, you might be shocked to find that most of your positive results are actually wrong. This exercise reveals why this happens, demonstrating the critical difference between a test's inherent accuracy and its predictive value in the real world [@problem_id:2438715]. You will use fundamental definitions to calculate the expected number of true and false positives, uncovering the profound impact of disease prevalence on diagnostic outcomes.", "problem": "A genomics lab is evaluating a binary variant-detection assay to screen a large biobank for a rare Mendelian disease. The population prevalence is $p = 10^{-4}$. The assay has sensitivity $0.99$ and specificity $0.999$. The lab plans to screen $10^{6}$ unrelated individuals.\n\nWhich of the following statements about the expected outcomes among those tested is correct?\n\nA. With these parameters, the expected number of false positives exceeds the expected number of true positives, and the positive predictive value is approximately $9\\%$.\n\nB. With these parameters, the expected number of false positives is less than $10$, and the positive predictive value exceeds $90\\%$.\n\nC. If specificity were increased from $0.999$ to $0.9999$ while holding prevalence and sensitivity fixed, the positive predictive value would increase only slightly, from about $9\\%$ to about $10\\%$.\n\nD. If sensitivity were decreased from $0.99$ to $0.90$ while holding prevalence and specificity fixed, the expected number of false positives would decrease by about $10\\%$.\n\nE. For any prevalence, the fraction of positive test results that are false positives equals the Type I error rate.", "solution": "The problem statement has been validated and is deemed scientifically sound, well-posed, and objective. We may proceed with a formal analysis.\n\nLet $D+$ denote the state of having the disease and $D-$ denote the state of not having the disease. Let $T+$ and $T-$ be the outcomes of a positive and negative test, respectively. The problem provides the following parameters: a total of $N = 10^{6}$ individuals are tested. The prevalence of the disease is $p = P(D+) = 10^{-4}$. The probability of an individual not having the disease is $P(D-) = 1 - p = 1 - 10^{-4} = 0.9999$. The assay's sensitivity is the true positive rate, $P(T+|D+) = 0.99$. The assay's specificity is the true negative rate, $P(T-|D-) = 0.999$.\n\nFrom these definitions, we can derive other key probabilities. The false positive rate (Type I error, $\\alpha$) is $\\alpha = P(T+|D-) = 1 - \\text{Specificity} = 1 - 0.999 = 0.001$. The false negative rate (Type II error, $\\beta$) is $\\beta = P(T-|D+) = 1 - \\text{Sensitivity} = 1 - 0.99 = 0.01$.\n\nWe now calculate the expected number of individuals in each category for a population of $N=10^6$.\n\nThe expected number of individuals with the disease is:\n$$E[D+] = N \\times p = 10^{6} \\times 10^{-4} = 100$$\nThe expected number of individuals without the disease is:\n$$E[D-] = N \\times (1-p) = 10^{6} \\times 0.9999 = 999,900$$\n\nUsing these values, we can find the expected counts for the four possible outcomes of testing:\nExpected number of True Positives ($TP$):\n$$E[TP] = E[D+] \\times P(T+|D+) = 100 \\times 0.99 = 99$$\nExpected number of False Negatives ($FN$):\n$$E[FN] = E[D+] \\times P(T-|D+) = 100 \\times 0.01 = 1$$\nExpected number of False Positives ($FP$):\n$$E[FP] = E[D-] \\times P(T+|D-) = 999,900 \\times 0.001 = 999.9$$\nExpected number of True Negatives ($TN$):\n$$E[TN] = E[D-] \\times P(T-|D-) = 999,900 \\times 0.999 = 998,900.1$$\n\nThe total number of expected positive tests is $E[T+] = E[TP] + E[FP] = 99 + 999.9 = 1098.9$.\nThe Positive Predictive Value ($PPV$) is the probability that an individual with a positive test result actually has the disease, $P(D+|T+)$. It can be calculated from the expected numbers:\n$$PPV = \\frac{E[TP]}{E[TP] + E[FP]} = \\frac{99}{99 + 999.9} = \\frac{99}{1098.9} \\approx 0.090089...$$\nThis is approximately $9.01\\%$.\n\nNow we evaluate each statement.\n\n**A. With these parameters, the expected number of false positives exceeds the expected number of true positives, and the positive predictive value is approximately $9\\%$.**\nThe first part of the statement claims $E[FP]  E[TP]$. Our calculation shows $E[FP] = 999.9$ and $E[TP] = 99$. The inequality $999.9  99$ is true. The second part claims the $PPV$ is approximately $9\\%$. Our calculation shows $PPV \\approx 9.01\\%$, which is indeed approximately $9\\%$. Both parts of the statement are correct.\nVerdict: **Correct**.\n\n**B. With these parameters, the expected number of false positives is less than $10$, and the positive predictive value exceeds $90\\%$.**\nThe first part claims $E[FP]  10$. Our calculation gives $E[FP] = 999.9$. The statement $999.9  10$ is false. The second part claims $PPV  90\\%$. Our calculation gives $PPV \\approx 9.01\\%$. The statement $9.01\\%  90\\%$ is false.\nVerdict: **Incorrect**.\n\n**C. If specificity were increased from $0.999$ to $0.9999$ while holding prevalence and sensitivity fixed, the positive predictive value would increase only slightly, from about $9\\%$ to about $10\\%$.**\nLet us recalculate the necessary values with the new specificity of $0.9999$. The new false positive rate is $\\alpha' = 1 - 0.9999 = 0.0001$. The expected number of true positives, $E[TP]$, remains $99$. The new expected number of false positives is:\n$$E[FP]' = E[D-] \\times \\alpha' = 999,900 \\times 0.0001 = 99.99$$\nThe new positive predictive value would be:\n$$PPV' = \\frac{E[TP]}{E[TP] + E[FP]'} = \\frac{99}{99 + 99.99} = \\frac{99}{198.99} \\approx 0.4975$$\nThe new $PPV$ is approximately $49.8\\%$. The statement claims a slight increase from about $9\\%$ to about $10\\%$. An increase from $9\\%$ to nearly $50\\%$ is a substantial, not slight, increase. The claim is quantitatively incorrect.\nVerdict: **Incorrect**.\n\n**D. If sensitivity were decreased from $0.99$ to $0.90$ while holding prevalence and specificity fixed, the expected number of false positives would decrease by about $10\\%$.**\nThe expected number of false positives is calculated as $E[FP] = N \\times (1-p) \\times (1 - \\text{Specificity})$. This quantity is functionally independent of the sensitivity. Therefore, changing the sensitivity has no effect on the expected number of false positives. The premise of the statement is fundamentally flawed.\nVerdict: **Incorrect**.\n\n**E. For any prevalence, the fraction of positive test results that are false positives equals the Type I error rate.**\nThe fraction of positive test results that are false positives is given by $\\frac{E[FP]}{E[TP]+E[FP]} = 1 - PPV$. In terms of probabilities, this is $P(D-|T+)$. The Type I error rate, $\\alpha$, is the false positive rate, $P(T+|D-)$. The statement thus claims that $P(D-|T+) = P(T+|D-)$ for any prevalence. This is a common logical error confusing two different conditional probabilities. Using Bayes' theorem:\n$$P(D-|T+) = \\frac{P(T+|D-)P(D-)}{P(T+)}$$\nThe equality holds only if $\\frac{P(D-)}{P(T+)} = 1$, which is not generally true. For the given parameters in this problem, we calculated $1 - PPV \\approx 1 - 0.0901 = 0.9099$. The Type I error rate is $\\alpha = 0.001$. Clearly, $0.9099 \\neq 0.001$. The statement is false.\nVerdict: **Incorrect**.\n\nBased on this rigorous analysis, only statement A is correct.", "answer": "$$\\boxed{A}$$", "id": "2438715"}, {"introduction": "A well-designed experiment is the foundation of reliable science. This practice shifts our focus from interpreting results to proactively planning experiments with sufficient statistical power to detect a real effect. You will perform a sample size calculation for a common bioinformatics scenario—a differential gene expression study—to ensure the experiment has a high probability of success and avoids a costly Type II error [@problem_id:2438773].", "problem": "A laboratory plans a differential expression analysis between two conditions using Ribonucleic Acid sequencing (RNA-seq). After normalization, the analysis will be performed on the base-$2$ logarithm of counts per gene. For a particular gene of interest, pilot data suggest that within each condition the log$_{2}$ expression values are approximately independent and normally distributed with a common variance of $\\sigma^{2} = 0.09$. The study aims to detect a subtle $1.2$-fold change in mean expression between the two conditions. On the log$_{2}$ scale, let the mean difference be $\\delta = \\log_{2}(1.2)$. The hypothesis test will be two-sided with a Type I error rate $\\alpha = 0.05$, and the design must achieve a power of $1-\\beta = 0.90$ for this effect size. Assume equal sample sizes $n$ per condition and that the variance estimate is accurate for planning purposes.\n\nCompute the minimal integer value of $n$ (samples per condition) required to achieve the specified power under these assumptions. Report the smallest integer $n$ that satisfies the requirement. No rounding by significant figures is needed because $n$ must be an integer.", "solution": "The problem shall first be subjected to rigorous validation.\n\nStep 1: Extract Givens\n- Data transformation: base-$2$ logarithm of counts per gene, $\\log_{2}(\\text{counts})$.\n- Distribution: Log-transformed values are independent and normally distributed within each condition.\n- Common variance: $\\sigma^{2} = 0.09$.\n- Fold change to detect: $1.2$-fold.\n- Mean difference on $\\log_{2}$ scale: $\\delta = \\log_{2}(1.2)$.\n- Test type: Two-sided hypothesis test.\n- Type I error rate: $\\alpha = 0.05$.\n- Desired power: $1-\\beta = 0.90$.\n- Sample size design: Equal sample sizes, $n$, per condition.\n- Objective: Compute the minimal integer value of $n$.\n\nStep 2: Validate Using Extracted Givens\nThe problem describes a standard a priori power analysis for a two-sample test of means.\n- **Scientifically Grounded**: The premise is sound. The use of logarithmic transformation for RNA-seq count data to stabilize variance and approximate normality is a common and accepted practice in bioinformatics. The statistical framework, based on hypothesis testing with specified Type I and Type II error rates, is fundamental to experimental design in biological sciences. The parameter values ($\\sigma^2=0.09$, a $1.2$-fold change, $\\alpha=0.05$, power$=0.90$) are realistic for such studies.\n- **Well-Posed**: The problem is well-posed. It provides all necessary parameters to uniquely determine the sample size. The objective to find the minimal integer $n$ is clear and unambiguous.\n- **Objective**: The problem is stated in objective, quantitative terms, free from subjective or speculative content.\n\nStep 3: Verdict and Action\nThe problem statement is valid. It is a standard problem in biostatistics that is scientifically sound, well-posed, and objective. A solution is therefore required.\n\nThe problem is to determine the sample size $n$ for a two-sample test comparing the means of two normal distributions with a known common variance. Let $\\mu_1$ and $\\mu_2$ be the true mean log-expression values for the two conditions. The hypotheses are:\n- Null hypothesis $H_0: \\mu_1 = \\mu_2$.\n- Alternative hypothesis $H_1: \\mu_1 \\neq \\mu_2$.\n\nThe problem specifies that the difference to be detected is $\\delta = \\mu_1 - \\mu_2 = \\log_2(1.2)$. We perform a two-sided test. Let $\\bar{X}_1$ and $\\bar{X}_2$ be the sample means from the two conditions, each with $n$ samples. Since the population variance $\\sigma^2$ is assumed to be known, the appropriate test statistic under $H_0$ is the Z-statistic:\n$$ Z = \\frac{(\\bar{X}_1 - \\bar{X}_2) - 0}{\\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sigma \\sqrt{\\frac{2}{n}}} $$\nUnder $H_0$, $Z$ follows a standard normal distribution, $N(0,1)$. For a two-sided test with a Type I error rate of $\\alpha$, we reject $H_0$ if $|Z|  z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the standard normal distribution.\n\nPower, $1-\\beta$, is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_1$ is true, i.e., when the true mean difference is $\\delta$. Under $H_1$, the statistic $(\\bar{X}_1 - \\bar{X}_2)$ is normally distributed with mean $\\delta$ and variance $\\frac{2\\sigma^2}{n}$. Therefore, the standardized test statistic $Z$ is not standard normal. Instead, under $H_1$:\n$$ E[Z] = \\frac{E[\\bar{X}_1 - \\bar{X}_2]}{\\sigma \\sqrt{\\frac{2}{n}}} = \\frac{\\delta}{\\sigma \\sqrt{\\frac{2}{n}}} $$\nThe power is the probability that $Z$ falls into the rejection region:\n$$ 1-\\beta = P\\left(Z  z_{1-\\alpha/2} \\mid H_1\\right) + P\\left(Z  -z_{1-\\alpha/2} \\mid H_1\\right) $$\nTo evaluate this, we standardize $Z$ under $H_1$:\n$$ \\frac{Z - \\frac{\\delta}{\\sigma \\sqrt{2/n}}}{1} \\sim N(0,1) $$\nAssuming $\\delta  0$ (which is true since $\\log_2(1.2)  0$), the power is dominated by the first term. The second term, $P(Z  -z_{1-\\alpha/2})$, is negligible. Thus, we approximate the power as:\n$$ 1-\\beta \\approx P\\left(Z  z_{1-\\alpha/2} \\mid H_1\\right) $$\nLet $Z' \\sim N(0,1)$.\n$$ 1-\\beta = P\\left( Z' + \\frac{\\delta}{\\sigma\\sqrt{2/n}}  z_{1-\\alpha/2} \\right) = P\\left( Z'  z_{1-\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}} \\right) $$\nFor a standard normal variable $Z'$, $P(Z'k) = 1-\\Phi(k)$, where $\\Phi$ is the cumulative distribution function. Also, $1-\\Phi(k) = \\Phi(-k)$. So, we require the probability to be $1-\\beta$, which means the argument of $\\Phi$ must be $z_{1-\\beta}$.\n$$ - \\left( z_{1-\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}} \\right) \\ge z_{1-\\beta} $$\nThis simplifies to the standard power equation for a two-sided Z-test:\n$$ \\frac{|\\delta|}{\\sigma\\sqrt{2/n}} \\ge z_{1-\\alpha/2} + z_{1-\\beta} $$\nWe solve for $n$:\n$$ \\sqrt{n} \\ge \\frac{\\sqrt{2}\\sigma(z_{1-\\alpha/2} + z_{1-\\beta})}{|\\delta|} $$\n$$ n \\ge \\frac{2\\sigma^2(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\delta^2} $$\nNow we substitute the values provided in the problem.\n- $\\sigma^2 = 0.09$.\n- $\\delta = \\log_2(1.2) = \\frac{\\ln(1.2)}{\\ln(2)}$.\n- $\\alpha = 0.05 \\implies \\alpha/2 = 0.025$. The critical value is $z_{1-0.025} = z_{0.975} \\approx 1.96$.\n- $1-\\beta = 0.90 \\implies \\beta = 0.10$. The corresponding one-sided quantile is $z_{1-0.10} = z_{0.90} \\approx 1.2816$.\n\nThe sum of the quantiles is $z_{1-\\alpha/2} + z_{1-\\beta} \\approx 1.96 + 1.2816 = 3.2416$.\nThe effect size on the log scale is $\\delta = \\log_2(1.2) \\approx 0.26303$.\n\nSubstituting these into the inequality for $n$:\n$$ n \\ge \\frac{2 \\times 0.09 \\times (1.96 + 1.2816)^2}{(\\log_2(1.2))^2} $$\n$$ n \\ge \\frac{0.18 \\times (3.2416)^2}{(0.26303)^2} $$\n$$ n \\ge \\frac{0.18 \\times 10.5080}{(0.069185)} $$\n$$ n \\ge \\frac{1.89144}{0.069185} $$\n$$ n \\ge 27.339... $$\nSince the number of samples $n$ must be an integer, we must take the smallest integer that satisfies this condition. This is the ceiling of the calculated value.\n$$ n = \\lceil 27.339... \\rceil = 28 $$\nTherefore, a minimum of $28$ samples per condition is required to achieve the desired power of $0.90$.", "answer": "$$\\boxed{28}$$", "id": "2438773"}, {"introduction": "Science often progresses through the replication of key findings, but what happens when a significant result fails to replicate? This complex scenario challenges us to move beyond simple definitions of statistical errors. This exercise places you in the role of a genetic epidemiologist interpreting a failed replication of a genome-wide association study (GWAS) finding [@problem_id:2438780]. You will reason through the interplay of statistical power, population differences, and the possibility of both Type I and Type II errors to understand why an exciting discovery might vanish upon a second look.", "problem": "A Genome-Wide Association Study (GWAS) of a binary disease in European-ancestry participants discovers a single-nucleotide polymorphism (SNP) with per-allele association that is genome-wide significant. The discovery cohort has $n_{\\text{case},1} = 30{,}000$ cases and $n_{\\text{control},1} = 70{,}000$ controls. The index SNP has European risk-allele frequency $p_{\\text{EUR}} = 0.30$, estimated odds ratio $\\widehat{\\mathrm{OR}}_1 = 1.08$, and a two-sided $p$-value $p_1 = 2\\times 10^{-9}$ (which is below the conventional threshold $5\\times 10^{-8}$ for genome-wide significance). An independent replication is attempted in East Asian ancestry with $n_{\\text{case},2} = 5{,}000$ and $n_{\\text{control},2} = 5{,}000$, testing the same index SNP or its best available proxy, which has squared correlation $r^2 = 0.80$ with the index SNP in Europeans. In the East Asian sample, the risk-allele frequency is $p_{\\text{EAS}} = 0.10$. The replication uses a two-sided threshold $p_2  0.05$ for this single pre-specified SNP and reports $\\widehat{\\mathrm{OR}}_2 = 1.05$ with $p_2 = 0.12$ (not significant). Both studies perform standard quality control and adjust for principal components of ancestry.\n\nUsing only fundamental definitions about statistical errors and widely accepted properties of statistical power in association testing, reason about why a genome-wide significant discovery can fail to replicate, and how to interpret such a failure in terms of Type I and Type II errors. Select all statements that are correct in this scenario.\n\nA. The failure to replicate implies the discovery was a Type I error, because a true association would have yielded $p_2  0.05$ in the replication.\n\nB. The replication may have committed a Type II error: smaller $n_{\\text{case},2}$ and $n_{\\text{control},2}$, lower $p_{\\text{EAS}}$, and imperfect linkage disequilibrium between the tested proxy and the causal variant reduce power, so non-significance can occur even if the association is real.\n\nC. If the causal effect is present in Europeans but absent or materially weaker in East Asians, then the null hypothesis may be true in the replication cohort; in that case, non-significance does not constitute a Type II error with respect to the replication’s hypothesis test.\n\nD. Achieving $p_1  5\\times 10^{-8}$ in discovery eliminates the possibility that the discovery was a Type I error.\n\nE. Despite $p_1 = 2\\times 10^{-9}$, the discovery could still be a Type I error; the genome-wide threshold controls but does not abolish the probability of false positives across many tested variants, and residual confounding could inflate test statistics.\n\nF. If, instead of $p_2  0.05$, the replication required $p_2  5\\times 10^{-8}$ for this single pre-specified SNP, the probability of a Type II error would increase substantially relative to using $p_2  0.05$.", "solution": "The problem statement must first be validated for scientific soundness, clarity, and completeness.\n\n**Step 1: Extract Givens**\n\nDiscovery Study (European Ancestry):\n- Case sample size: $n_{\\text{case},1} = 30{,}000$\n- Control sample size: $n_{\\text{control},1} = 70{,}000$\n- Index SNP risk-allele frequency: $p_{\\text{EUR}} = 0.30$\n- Estimated odds ratio: $\\widehat{\\mathrm{OR}}_1 = 1.08$\n- Genome-wide significance threshold: $5 \\times 10^{-8}$\n- Observed $p$-value: $p_1 = 2 \\times 10^{-9}$\n\nReplication Study (East Asian Ancestry):\n- Case sample size: $n_{\\text{case},2} = 5{,}000$\n- Control sample size: $n_{\\text{control},2} = 5{,}000$\n- Risk-allele frequency of proxy SNP: $p_{\\text{EAS}} = 0.10$\n- Squared correlation between index SNP and proxy SNP: $r^2 = 0.80$\n- Replication significance threshold: $p_2  0.05$ (for a single pre-specified SNP)\n- Estimated odds ratio: $\\widehat{\\mathrm{OR}}_2 = 1.05$\n- Observed $p$-value: $p_2 = 0.12$\n\nGeneral Information:\n- Both studies are of a binary disease.\n- Both studies perform standard quality control and adjust for principal components of ancestry.\n- The task is to reason about the failure to replicate and evaluate statements related to Type I and Type II errors.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem describes a standard scenario in genetic epidemiology: a genome-wide association study (GWAS) with a significant finding that fails to replicate in an independent cohort.\n\n- **Scientifically Grounded:** All concepts presented—GWAS, single-nucleotide polymorphism (SNP), odds ratio (OR), p-value, genome-wide significance, replication, linkage disequilibrium ($r^2$), Type I and Type II errors, population-specific allele frequencies, and adjustment for ancestry—are fundamental to the field of statistical genetics. The numerical values for sample sizes, allele frequencies, effect sizes, and p-values are realistic for such studies. The scenario is not only plausible but common, and represents a key topic of methodological discussion in the field.\n- **Well-Posed:** The problem is structured as a conceptual question requiring the evaluation of several statements based on established statistical principles. The information provided is sufficient to assess the validity of each statement without ambiguity. A definite\nset of correct conclusions can be drawn.\n- **Objective:** The problem is stated using precise, objective, and technical language. It is free from subjective assertions or bias.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is scientifically sound, well-posed, unambiguous, and grounded in established principles of statistics and genetics. I will proceed with the solution.\n\n**Derivation of Principles**\n\nIn hypothesis testing, we evaluate a null hypothesis ($H_0$) against an alternative hypothesis ($H_A$). In this context:\n- $H_0$: The true odds ratio for the association between the SNP and the disease is $1$. There is no effect.\n- $H_A$: The true odds ratio is not $1$. There is a real effect.\n\nTwo types of errors can occur:\n- **Type I Error (False Positive):** Rejecting $H_0$ when $H_0$ is true. The probability of this error is denoted by $\\alpha$, the significance level.\n- **Type II Error (False Negative):** Failing to reject $H_0$ when $H_A$ is true. The probability of this error is denoted by $\\beta$.\n\n**Statistical power** is the probability of correctly rejecting $H_0$ when it is false, i.e., Power $= 1 - \\beta$. Power is a critical concept for interpreting non-significant results and is influenced by several factors:\n1.  **Significance level ($\\alpha$):** A more stringent (smaller) $\\alpha$ reduces power.\n2.  **Effect size (true OR):** A larger effect size (OR further from $1$) increases power.\n3.  **Sample size ($n$):** Larger sample sizes increase power.\n4.  **Allele frequency ($p$):** For a binary trait and an additive genetic model, power is maximized when $p=0.5$ and decreases as the allele becomes rarer or more common. The effective sample size is proportional to $n \\cdot p(1-p)$.\n5.  **Linkage Disequilibrium (LD):** If the genotyped SNP is a proxy for the true causal variant, power is reduced by a factor of $r^2$, where $r^2$ is the squared correlation between the proxy and the causal variant.\n\nThe discovery study has a very large sample size ($n_1 = 100{,}000$) and found a highly significant result ($p_1 = 2 \\times 10^{-9}$), despite a small estimated effect size ($\\widehat{\\mathrm{OR}}_1 = 1.08$). The replication study failed to find a significant result ($p_2 = 0.12  0.05$). The task is to interpret this failure.\n\n**Option-by-Option Analysis**\n\n**A. The failure to replicate implies the discovery was a Type I error, because a true association would have yielded $p_2  0.05$ in the replication.**\nThis statement is incorrect. The word \"implies\" suggests a deterministic outcome, which is contrary to the probabilistic nature of statistics. A true association (i.e., the discovery was not a Type I error) does not guarantee a significant result in any given replication attempt. The replication study may lack sufficient statistical power to detect the true effect. If the power is less than $100\\%$, there is a non-zero probability of a Type II error. As will be shown in the analysis of option B, there are multiple reasons why the replication study has substantially lower power than the discovery study. Therefore, a failure to replicate cannot be taken as definitive proof that the original finding was a Type I error. It is a possibility, but not a certainty.\n**Verdict: Incorrect.**\n\n**B. The replication may have committed a Type II error: smaller $n_{\\text{case},2}$ and $n_{\\text{control},2}$, lower $p_{\\text{EAS}}$, and imperfect linkage disequilibrium between the tested proxy and the causal variant reduce power, so non-significance can occur even if the association is real.**\nThis statement correctly identifies several key factors that reduce statistical power.\n- **Sample size:** The replication total sample size ($n_2=10{,}000$) is one-tenth of the discovery sample size ($n_1=100{,}000$). This drastically reduces power.\n- **Allele frequency:** The risk-allele frequency is much lower in the replication cohort ($p_{\\text{EAS}} = 0.10$) than in the discovery cohort ($p_{\\text{EUR}} = 0.30$). Statistical power is proportional to the variance of the allele count, which is a function of $n \\cdot p(1-p)$. For discovery, this is proportional to $100{,}000 \\times 0.3 \\times 0.7 = 21{,}000$. For replication, it is proportional to $10{,}000 \\times 0.1 \\times 0.9 = 900$. This is a reduction in effective sample size by a factor of more than $20$, which severely cripples power.\n- **Imperfect LD:** The use of a proxy SNP with $r^2=0.80$ means that even if the effect size were identical in both populations and the index SNP were causal, the power in the replication is automatically reduced by a factor of approximately $r^2 = 0.80$.\nThese factors combine to make the replication study substantially underpowered to detect a small effect size like $\\mathrm{OR} = 1.08$. Thus, failing to achieve significance ($p_2  0.05$) is a highly plausible outcome even if the association is real, and this would constitute a Type II error.\n**Verdict: Correct.**\n\n**C. If the causal effect is present in Europeans but absent or materially weaker in East Asians, then the null hypothesis may be true in the replication cohort; in that case, non-significance does not constitute a Type II error with respect to the replication’s hypothesis test.**\nThis statement addresses the possibility of population-specific effects (genetic heterogeneity). It is scientifically plausible that a genetic variant has an effect on a disease in one ancestry group but not another, due to differing genetic backgrounds (e.g., interactions with other genes) or environmental exposures. If the true OR in the East Asian population is $1$, then the null hypothesis is true for the replication study. A Type II error is defined as failing to reject $H_0$ *when it is false*. If $H_0$ is true, it is impossible to commit a Type II error. In that scenario, the non-significant result ($p_2=0.12$) is a correct outcome, a failure to reject a true null hypothesis. The statement accurately describes this logical point.\n**Verdict: Correct.**\n\n**D. Achieving $p_1  5\\times 10^{-8}$ in discovery eliminates the possibility that the discovery was a Type I error.**\nThis statement reflects a fundamental misunderstanding of p-values. A p-value is a measure of evidence against the null hypothesis, not a proof of its falsehood. A p-value of $p_1 = 2 \\times 10^{-9}$ means that if the null hypothesis were true, there would be a $2 \\times 10^{-9}$ probability of observing a test statistic at least as extreme as the one found. While this probability is extremely small, it is not zero. Unlikely events can and do occur. The genome-wide significance threshold of $5 \\times 10^{-8}$ is chosen to control the family-wise error rate across the entire genome, making false positives rare, but it does not eliminate them. Therefore, a Type I error remains a possibility, however small.\n**Verdict: Incorrect.**\n\n**E. Despite $p_1 = 2\\times 10^{-9}$, the discovery could still be a Type I error; the genome-wide threshold controls but does not abolish the probability of false positives across many tested variants, and residual confounding could inflate test statistics.**\nThis statement is the correct interpretation. As explained for option D, a Type I error is always possible as long as the p-value is not exactly zero. The purpose of the stringent GWAS threshold is to control this error rate, not eliminate it. Furthermore, the statement correctly introduces another critical issue: confounding. GWAS test statistics can be inflated by unmeasured or imperfectly corrected confounding factors, such as subtle population structure, cryptic relatedness, or technical artifacts in genotyping. The problem states that principal components were used to adjust for ancestry, but this method may not perfectly capture all population-level differences. Such residual confounding can create spurious associations, leading to a Type I error that appears highly significant. This is a well-known vulnerability of observational studies.\n**Verdict: Correct.**\n\n**F. If, instead of $p_2  0.05$, the replication required $p_2  5\\times 10^{-8}$ for this single pre-specified SNP, the probability of a Type II error would increase substantially relative to using $p_2  0.05$.**\nThere is a direct trade-off between the Type I error rate ($\\alpha$) and the Type II error rate ($\\beta$). Statistical power is $1 - \\beta$. By making the significance threshold ($\\alpha$) more stringent (i.e., smaller), one makes it harder to reject the null hypothesis. This means that the region of the test statistic distribution that leads to rejection becomes smaller. Consequently, if the null hypothesis is false, the probability of rejecting it (power) decreases, and the probability of failing to reject it (Type II error, $\\beta$) increases. Changing the required significance level from $\\alpha = 0.05$ to $\\alpha = 5 \\times 10^{-8}$ is a dramatic increase in stringency (a decrease in $\\alpha$ by over six orders of magnitude). This would drastically reduce the power of the replication study and thus substantially increase the probability of a Type II error. This is precisely why replication studies of a *single*, pre-specified hypothesis use a conventional threshold like $\\alpha=0.05$ and not a genome-wide correction.\n**Verdict: Correct.**", "answer": "$$\\boxed{BCEF}$$", "id": "2438780"}]}