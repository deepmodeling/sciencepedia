{"hands_on_practices": [{"introduction": "The net charge of an amino acid is a fundamental chemical property that dictates its behavior in the cellular environment, influencing solubility, reactivity, and electrostatic interactions. The isoelectric point ($pI$) is the specific pH at which an amino acid has a net charge of zero, a critical value for techniques like isoelectric focusing. This first practice provides a foundational exercise in quantitatively determining the $pI$ for histidine, an amino acid with an ionizable side chain, reinforcing your understanding of acid-base chemistry as it applies to protein building blocks [@problem_id:2303334].", "problem": "Isoelectric focusing (IEF) is a powerful biochemical technique used to separate molecules, such as proteins and peptides, based on their isoelectric point. The isoelectric point ($pI$) of a molecule is the specific pH at which its net electrical charge is zero. In a typical IEF setup, a pH gradient is established in a gel matrix. When a sample is applied, each molecule migrates through the gradient until it reaches the pH corresponding to its $pI$, where it ceases to move.\n\nA researcher is planning an experiment to separate a mixture of amino acids and wants to predict the final position of Histidine in the IEF gel. To do this, they need to calculate the isoelectric point of Histidine. You are given the acid dissociation constants ($pKa$) for the three ionizable groups in Histidine:\n\n- The $\\alpha$-carboxyl group has a $pKa_1 = 1.82$.\n- The imidazole side chain has a $pKa_R = 6.00$.\n- The $\\alpha$-amino group has a $pKa_2 = 9.17$.\n\nCalculate the isoelectric point ($pI$) of Histidine. Report your answer to three significant figures.", "solution": "In isoelectric focusing, the isoelectric point $pI$ is the pH at which the net charge of the molecule is zero. For histidine, the relevant sequential deprotonations with increasing pH are:\n1) $\\alpha$-carboxyl group at $pKa_{1}=1.82$ (yielding the $+1$ species),\n2) imidazole side chain at $pKa_{R}=6.00$ (yielding the neutral, zwitterionic species),\n3) $\\alpha$-amino group at $pKa_{2}=9.17$ (yielding the $-1$ species).\n\nNear the $pI$, the dominant interconverting species are the $+1$ cation ($X^{+}$), the neutral zwitterion ($Z^{0}$), and the $-1$ anion ($Y^{-}$). The $pI$ occurs when the average charge is zero, which is achieved when the concentrations of the $+1$ and $-1$ forms are equal, i.e., $[X^{+}] = [Y^{-}]$, because the neutral form carries no charge.\n\nThe relevant equilibria and Henderson–Hasselbalch relations are:\n$$\npH = pKa_{R} + \\log_{10}\\!\\left(\\frac{[Z^{0}]}{[X^{+}]}\\right), \\quad\npH = pKa_{2} + \\log_{10}\\!\\left(\\frac{[Y^{-}]}{[Z^{0}]}\\right).\n$$\nMultiplying the corresponding ratios gives\n$$\n\\frac{[Y^{-}]}{[X^{+}]} = 10^{\\left(pH - pKa_{R}\\right)} \\cdot 10^{\\left(pH - pKa_{2}\\right)} = 10^{\\,2\\,pH - \\left(pKa_{R} + pKa_{2}\\right)}.\n$$\nAt $pI$, impose $[Y^{-}] = [X^{+}]$, hence\n$$\n10^{\\,2\\,pH - \\left(pKa_{R} + pKa_{2}\\right)} = 1 \\;\\;\\Longrightarrow\\;\\; 2\\,pH - \\left(pKa_{R} + pKa_{2}\\right) = 0,\n$$\nso\n$$\npI = \\frac{pKa_{R} + pKa_{2}}{2}.\n$$\nSubstituting the given values,\n$$\npI = \\frac{6.00 + 9.17}{2} = 7.585 \\approx 7.59 \\text{ (to three significant figures).}\n$$\nThe $\\alpha$-carboxyl $pKa_{1}$ does not enter this average because the neutral (zwitterionic) form of histidine lies between $pKa_{R}$ and $pKa_{2}$ on the titration curve.", "answer": "$$\\boxed{7.59}$$", "id": "2303334"}, {"introduction": "Building on the chemical properties of individual residues, we now explore how these properties drive the complex process of protein folding. The hydrophobic effect, the tendency of nonpolar substances to aggregate in aqueous solution, is a primary driving force in this process. This exercise asks you to implement a simulation based on the simplified Hydrophobic-Polar (HP) model, a classic \"toy model\" in computational biology that captures the essence of hydrophobic collapse, giving you hands-on experience with core concepts like conformational sampling and energy landscapes [@problem_id:2371271].", "problem": "You are asked to implement a simplified protein folding simulator using the hydrophobic–polar (HP) model on a two-dimensional square lattice. The model captures the tendency of hydrophobic amino acids to seek contact with one another. The only energy term is a contact potential between hydrophobic residues.\n\nStarting points, definitions, and constraints:\n- The underlying polymer chain has length $N$ and is encoded by a string $S$ of length $N$ over the alphabet $\\{ \\text{H}, \\text{P} \\}$, where $\\text{H}$ denotes a hydrophobic residue and $\\text{P}$ denotes a polar residue.\n- A conformation is a mapping $f : \\{0,1,\\dots,N-1\\} \\to \\mathbb{Z}^2$ satisfying the following:\n  - Self-avoiding walk on the square lattice: for all $i \\in \\{0,\\dots,N-2\\}$, the lattice (Manhattan) distance satisfies $\\| f(i+1) - f(i) \\|_1 = 1$, and $f$ is injective (no two residues occupy the same lattice position).\n  - Without loss of generality for rotational symmetry, fix $f(0) = (0,0)$ and, when $N \\ge 2$, fix $f(1) = (1,0)$.\n- The energy of a conformation $f$ under the HP model with contact potential is\n  $$ E(f) = -\\varepsilon \\cdot \\#\\left\\{ \\{i,j\\} \\mid 0 \\le i  j \\le N-1,\\ \\lvert i - j \\rvert  1,\\ S[i] = \\text{H},\\ S[j] = \\text{H},\\ \\| f(i) - f(j) \\|_1 = 1 \\right\\}, $$\n  where $\\varepsilon$ is a positive constant. In this problem, take $\\varepsilon = 1$ in dimensionless energy units, so that $E(f)$ is an integer.\n\nTask:\n- For each given test sequence $S$, compute the minimal possible energy\n  $$ E_{\\min}(S) = \\min_{f} E(f), $$\n  where the minimum is taken over all self-avoiding conformations $f$ on the two-dimensional square lattice that satisfy the constraints above.\n- Report each $E_{\\min}(S)$ as an integer.\n\nFundamental bases you may assume:\n- The hydrophobic effect in aqueous environments drives hydrophobic residues to cluster, which is approximated in the HP model by a favorable contact energy between nonconsecutive hydrophobic residues that are adjacent on the lattice.\n- Self-avoiding walks on a lattice provide a combinatorial abstraction of polymer conformations.\n- The Manhattan distance $\\| (x_1,y_1) - (x_2,y_2) \\|_1 = |x_1 - x_2| + |y_1 - y_2|$ on $\\mathbb{Z}^2$ encodes adjacency when equal to $1$.\n\nInput and output specifications for your program:\n- There is no external input. Use the following test suite of sequences in the order given.\n  - Test $1$: $S_1 = \\text{\"H\"}$ (so $N = 1$).\n  - Test $2$: $S_2 = \\text{\"HH\"}$ (so $N = 2$).\n  - Test $3$: $S_3 = \\text{\"HHHH\"}$ (so $N = 4$).\n  - Test $4$: $S_4 = \\text{\"PPPPPP\"}$ (so $N = 6$).\n  - Test $5$: $S_5 = \\text{\"HHPHHH\"}$ (so $N = 6$).\n  - Test $6$: $S_6 = \\text{\"HPHPPHHPH\"}$ (so $N = 9$).\n- Your program should compute $E_{\\min}(S_k)$ for each $k \\in \\{1,2,3,4,5,6\\}$ and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the tests. For example, the format must be $\\left[\\text{res}_1,\\text{res}_2,\\dots,\\text{res}_6\\right]$, where each $\\text{res}_k$ is an integer.\n\nNotes and requirements:\n- Use only the definitions and constraints stated; do not assume any unproven shortcuts. The conformation space is defined by self-avoiding walks on $\\mathbb{Z}^2$ with the stated anchoring to break rotational symmetry.\n- There are no physical units beyond the dimensionless $\\varepsilon = 1$. Angles do not appear in this problem.\n- Ensure your algorithm is correct for all cases in the test suite, including the boundary cases with $N = 1$ and $N = 2$.", "solution": "We construct a principled solution by integrating physical motivation with a mathematically exact combinatorial model and an exhaustive algorithmic procedure.\n\nPrinciples and definitions:\n- In water, hydrophobic residues tend to cluster to minimize exposure to solvent; the hydrophobic–polar (HP) model encodes this by assigning a favorable contact energy for nonconsecutive pairs of hydrophobic residues that are adjacent in space. This is a coarse-grained approximation of solvation free energy contributions.\n- We represent a polymer conformation as a self-avoiding walk on the two-dimensional square lattice $\\mathbb{Z}^2$. Formally, a conformation is a function $f : \\{0,1,\\dots,N-1\\} \\to \\mathbb{Z}^2$ such that $\\| f(i+1) - f(i) \\|_1 = 1$ for all $i \\in \\{0,\\dots,N-2\\}$ and $f$ is injective. Without loss of generality, to remove global rotational degeneracy, we fix $f(0) = (0,0)$ and, if $N \\ge 2$, fix $f(1) = (1,0)$.\n- The energy is defined by\n  $$ E(f) = -\\varepsilon \\cdot C(f), $$\n  where $C(f)$ is the count of unordered pairs $\\{i,j\\}$ with $0 \\le i  j \\le N-1$, $\\lvert i - j \\rvert  1$, $S[i] = \\text{H}$, $S[j] = \\text{H}$, and $\\| f(i) - f(j) \\|_1 = 1$. With $\\varepsilon = 1$, $E(f)$ is simply the negative of the hydrophobic contact count.\n\nProblem reduction:\n- Minimizing $E(f)$ is equivalent to maximizing $C(f)$ because $\\varepsilon = 1$ is positive. Therefore,\n  $$ E_{\\min}(S) = - \\max_{f} C(f). $$\n\nAlgorithmic strategy:\n- We enumerate all self-avoiding walks of length $N-1$ steps consistent with the anchoring constraint. This is done via depth-first search (DFS) with backtracking:\n  - Maintain a list of placed coordinates $\\left[ f(0), f(1), \\dots, f(k) \\right]$ and a hash set of occupied lattice sites for $k \\in \\{0,\\dots,N-1\\}$ during search.\n  - At each step, attempt to extend the walk by one of the four unit lattice moves $(\\pm 1, 0)$ and $(0, \\pm 1)$ provided the target site is unoccupied.\n  - Continue until a full conformation $f$ of length $N$ is built ($k = N-1$), at which point compute $C(f)$ and update the best (lowest) energy found, $E_{\\min}$.\n- Energy computation for a full conformation:\n  - Compute\n    $$ C(f) = \\sum_{0 \\le i  j \\le N-1} \\mathbf{1}\\left[ \\lvert i - j \\rvert > 1 \\right] \\cdot \\mathbf{1}\\left[ S[i] = \\text{H} \\right] \\cdot \\mathbf{1}\\left[ S[j] = \\text{H} \\right] \\cdot \\mathbf{1}\\left[ \\| f(i) - f(j) \\|_1 = 1 \\right], $$\n    where $\\mathbf{1}[\\cdot]$ is the indicator function. Then $E(f) = -C(f)$.\n- Correctness:\n  - The DFS enumerates exactly the set of self-avoiding walks under the anchoring constraint and therefore explores all conformations modulo global rotations (which do not change $C(f)$). Because every feasible $f$ is evaluated and $E(f)$ is computed from first principles as the negative of hydrophobic contacts between nonconsecutive adjacent residues, the minimum over all enumerated conformations is $E_{\\min}(S)$ by definition.\n- Complexity considerations:\n  - The number of self-avoiding walks of length $n$ on $\\mathbb{Z}^2$ grows approximately as $A \\cdot \\mu^n$ with connective constant $\\mu \\approx 2.638$. Here $n = N-1$. For $N \\le 9$ in the test suite, exhaustive enumeration is computationally feasible, especially with the rotational symmetry fixed by $f(1) = (1,0)$.\n- Boundary cases:\n  - If $N = 1$, there are no pairs and thus $C(f) = 0$ for the single conformation $f(0) = (0,0)$, so $E_{\\min} = 0$.\n  - If $N = 2$, only the consecutive pair exists, which is excluded by $\\lvert i-j \\rvert  1$, so again $E_{\\min} = 0$.\n  - For $N = 4$ and $S = \\text{\"HHHH\"}$, a $2 \\times 2$ square conformation exists with two nonconsecutive hydrophobic contacts, yielding $E_{\\min} \\le -2$; exhaustive enumeration confirms optimality.\n\nImplementation plan:\n- Hard-code the test suite sequences $S_1$ through $S_6$.\n- For each $S_k$, run the DFS enumerator to determine $E_{\\min}(S_k)$.\n- Print a single line containing the results in order as a list $\\left[ E_{\\min}(S_1), E_{\\min}(S_2), \\dots, E_{\\min}(S_6) \\right]$.\n\nThis approach follows directly from the foundational definitions of the HP model on a lattice, uses no heuristic shortcuts, and fully explores the discrete conformation space required to certify the minimal energy values for the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hp_min_energy(sequence: str) - int:\n    \"\"\"\n    Compute the minimal HP-model energy for a given sequence on a 2D square lattice,\n    using exhaustive enumeration of self-avoiding walks with rotational symmetry fixed.\n\n    Energy E = - (# of nonconsecutive H-H contacts that are adjacent on the lattice).\n    \"\"\"\n    N = len(sequence)\n    # Trivial small cases\n    if N = 1:\n        return 0\n    if N == 2:\n        return 0\n\n    # Directions: right, up, left, down\n    dirs = [(1,0), (0,1), (-1,0), (0,-1)]\n\n    # Anchor positions to break rotational symmetry\n    positions = [(0,0), (1,0)]\n    occupied = {positions[0], positions[1]}\n\n    best_energy = None  # minimal energy found\n\n    # Precompute H flags for speed\n    is_h = [c == 'H' for c in sequence]\n\n    def manhattan(p, q):\n        return abs(p[0]-q[0]) + abs(p[1]-q[1])\n\n    def energy_of_full_conformation(pos_list):\n        # Count nonconsecutive adjacent H-H contacts\n        contacts = 0\n        for i in range(N):\n            if not is_h[i]:\n                continue\n            pi = pos_list[i]\n            for j in range(i+1, N):\n                if not is_h[j]:\n                    continue\n                if abs(i - j) = 1:\n                    continue                 # consecutive pairs excluded\n                if manhattan(pi, pos_list[j]) == 1:\n                    contacts += 1\n        return -contacts\n\n    # DFS to enumerate all SAWs consistent with anchors\n    def dfs(idx):\n        nonlocal best_energy\n        if idx == N-1:\n            # Full conformation built\n            e = energy_of_full_conformation(positions)\n            if (best_energy is None) or (e  best_energy):\n                best_energy = e\n            return\n\n        curr = positions[idx]\n        for dx, dy in dirs:\n            nx, ny = curr[0] + dx, curr[1] + dy\n            nxt = (nx, ny)\n            if nxt in occupied:\n                continue\n            # Append\n            positions.append(nxt)\n            occupied.add(nxt)\n            dfs(idx + 1)\n            # Backtrack\n            occupied.remove(nxt)\n            positions.pop()\n\n    dfs(1)\n    # Safety: if best_energy remained None (should not happen), return 0\n    return 0 if best_energy is None else best_energy\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        \"H\",          # N=1, boundary\n        \"HH\",         # N=2, boundary\n        \"HHHH\",       # N=4\n        \"PPPPPP\",     # N=6, all polar\n        \"HHPHHH\",     # N=6\n        \"HPHPPHHPH\",  # N=9\n    ]\n\n    results = []\n    for seq in test_cases:\n        result = hp_min_energy(seq)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2371271"}, {"introduction": "Beyond simplified physical models, bioinformatics often relies on empirical data to make predictions. Decades of structural biology have revealed that certain amino acids have a statistical preference, or \"propensity,\" to appear in specific secondary structures like alpha-helices or beta-sheets. In this advanced practice, you will implement the famous Chou-Fasman algorithm, a method that uses these empirical propensities to predict a protein's secondary structure from its primary sequence, demonstrating a powerful, data-driven approach to computational protein analysis [@problem_id:2371310].", "problem": "Implement from first principles a propensity-based secondary structure predictor for proteins using the Chou–Fasman (CF) framework. The fundamental base consists of the following widely accepted facts and definitions: amino acids have empirically estimated propensities to appear in alpha helix and beta sheet conformations; independence across positions is assumed in the original CF methodology; and windows of residues whose average propensity exceeds a neutral baseline are more likely to nucleate that secondary structure. Let $P_{\\alpha}(a)$ and $P_{\\beta}(a)$ denote the helix and sheet propensities, respectively, for amino acid $a$.\n\nUse the following propensity values for the $20$ standard amino acids (one-letter code, then $P_{\\alpha}$ and $P_{\\beta}$):\n- Alanine (A): $P_{\\alpha}=1.45$, $P_{\\beta}=0.97$.\n- Arginine (R): $P_{\\alpha}=1.00$, $P_{\\beta}=0.90$.\n- Asparagine (N): $P_{\\alpha}=0.67$, $P_{\\beta}=0.89$.\n- Aspartic acid (D): $P_{\\alpha}=0.98$, $P_{\\beta}=0.80$.\n- Cysteine (C): $P_{\\alpha}=0.77$, $P_{\\beta}=1.30$.\n- Glutamine (Q): $P_{\\alpha}=1.11$, $P_{\\beta}=1.10$.\n- Glutamic acid (E): $P_{\\alpha}=1.53$, $P_{\\beta}=0.26$.\n- Glycine (G): $P_{\\alpha}=0.53$, $P_{\\beta}=0.81$.\n- Histidine (H): $P_{\\alpha}=1.24$, $P_{\\beta}=0.71$.\n- Isoleucine (I): $P_{\\alpha}=1.00$, $P_{\\beta}=1.60$.\n- Leucine (L): $P_{\\alpha}=1.34$, $P_{\\beta}=1.22$.\n- Lysine (K): $P_{\\alpha}=1.07$, $P_{\\beta}=0.74$.\n- Methionine (M): $P_{\\alpha}=1.20$, $P_{\\beta}=1.67$.\n- Phenylalanine (F): $P_{\\alpha}=1.12$, $P_{\\beta}=1.28$.\n- Proline (P): $P_{\\alpha}=0.59$, $P_{\\beta}=0.62$.\n- Serine (S): $P_{\\alpha}=0.79$, $P_{\\beta}=0.72$.\n- Threonine (T): $P_{\\alpha}=0.82$, $P_{\\beta}=1.20$.\n- Tryptophan (W): $P_{\\alpha}=1.14$, $P_{\\beta}=1.19$.\n- Tyrosine (Y): $P_{\\alpha}=0.61$, $P_{\\beta}=1.29$.\n- Valine (V): $P_{\\alpha}=0.97$, $P_{\\beta}=1.65$.\n\nDerive and implement the following decision process rooted in the independence assumption and the neutral baseline $1.0$ for propensity averages:\n\n- Alpha helix nucleation: slide a window of length $6$ along the sequence. In a window starting at index $i$ (zero-based), let $c_{\\alpha}(i)$ be the count of residues with $P_{\\alpha}1.03$ and let $\\overline{P}_{\\alpha}(i)$ be the arithmetic mean of $P_{\\alpha}$ in the window. If $c_{\\alpha}(i)\\ge 4$ and $\\overline{P}_{\\alpha}(i)  1.0$, mark this window as an alpha helix seed.\n- Beta sheet nucleation: slide a window of length $5$. In a window starting at index $j$, let $c_{\\beta}(j)$ be the count of residues with $P_{\\beta}1.00$ and let $\\overline{P}_{\\beta}(j)$ be the arithmetic mean of $P_{\\beta}$ in the window. If $c_{\\beta}(j)\\ge 3$ and $\\overline{P}_{\\beta}(j)  1.0$, mark this window as a beta sheet seed.\n- Extension: for any helix seed spanning indices $[s,e)$ (with $e=s+6$ initially), extend to the right by repeatedly increasing $e$ by $1$ while $en$ and the mean of the last $4$ residues in the current region, $\\frac{1}{4}\\sum_{k=e-4}^{e-1} P_{\\alpha}(a_k)$, remains strictly greater than $1.0$. Similarly, extend to the left by repeatedly decreasing $s$ by $1$ while $s0$ and $\\frac{1}{4}\\sum_{k=s}^{s+3} P_{\\alpha}(a_k)  1.0$. Apply the same extension logic to each beta seed, replacing $P_{\\alpha}$ with $P_{\\beta}$. If a $4$-residue end-window would extend beyond sequence bounds, do not extend in that direction.\n- Conflict resolution: after all helix and sheet regions are extended, positions may be marked as both helix and sheet. Partition any contiguous overlap into a segment of indices $[u,v]$. If $\\frac{1}{v-u+1}\\sum_{k=u}^{v} P_{\\alpha}(a_k)  \\frac{1}{v-u+1}\\sum_{k=u}^{v} P_{\\beta}(a_k)$, assign the entire overlap to helix; if the inequality is reversed, assign the entire overlap to sheet; if the means are exactly equal, assign the overlap to coil.\n- Any position not assigned to helix or sheet is coil.\n\nEncode the final per-residue prediction using integers: helix $=1$, sheet $=2$, coil $=0$.\n\nYour program must implement the above logic exactly and produce predictions for the following test suite of amino acid sequences (each sequence is a string of uppercase one-letter codes):\n- Test $1$ (happy path, helix-favoring with a perturbation): \"AAAAAAAGAAAA\".\n- Test $2$ (sheet-favoring): \"VVVVVVVV\".\n- Test $3$ (coverage across all residues): \"ACDEFGHIKLMNPQRSTVWY\".\n- Test $4$ (edge case, helix breakers): \"PPGPPGPP\".\n- Test $5$ (overlap resolution stress): \"EEEELLLVVVVLLLEEEE\".\n\nAll indices in your derivation must be zero-based, and all comparisons to thresholds must be strict where stated. The final output format must be a single line containing a comma-separated list of the five prediction lists, in order, with no spaces. Each prediction list must be the same length as its input sequence and contain only integers $0$, $1$, or $2$. For example, a valid overall output would look like \"[[1,1],[0,2],[...],[...],[...]]\" but with the values computed by your implementation. No physical units are involved in this problem. Angles are not involved. Percentages are not involved. The required final output must be printed exactly as a single line of text as specified, with no additional characters.", "solution": "The problem requires the implementation of a propensity-based algorithm for protein secondary structure prediction, based on the principles of the Chou-Fasman method. The algorithm is to be applied to a set of test sequences, and the predictions must be formatted in a specific manner. The process is deterministic and follows a sequence of well-defined steps: nucleation, extension, and conflict resolution.\n\nFirst, we establish the fundamental data. For each of the $20$ standard amino acids, denoted by a single-letter code $a$, we are given two empirical propensity values: $P_{\\alpha}(a)$ for its tendency to be in an alpha-helix, and $P_{\\beta}(a)$ for its tendency to be in a beta-sheet. These values are stored in a lookup table. The final prediction for each residue in a sequence of length $n$ is an integer: $1$ for alpha-helix (H), $2$ for beta-sheet (S), and $0$ for coil (C).\n\nThe prediction algorithm proceeds in four distinct stages.\n\n**Stage 1: Nucleation Site Identification**\n\nThe first stage identifies short segments of the protein sequence, known as \"seeds\" or \"nucleation sites,\" which are highly likely to form either an alpha-helix or a beta-sheet. This is accomplished by sliding a window of a fixed length along the sequence and applying a set of rules.\n\n1.  **Alpha-Helix Nucleation**: A sliding window of length $L_{\\alpha} = 6$ is moved along the sequence. For each window starting at a zero-based index $i$ and covering residues $a_i, a_{i+1}, \\ldots, a_{i+5}$:\n    *   We calculate the number of helix-forming residues, $c_{\\alpha}(i)$, defined as the count of residues within the window for which the propensity $P_{\\alpha}(a_k)  1.03$.\n    *   We also compute the arithmetic mean of the helix propensities within the window: $\\overline{P}_{\\alpha}(i) = \\frac{1}{6} \\sum_{k=i}^{i+5} P_{\\alpha}(a_k)$.\n    *   A window is declared an alpha-helix seed if both of the following conditions are met: $c_{\\alpha}(i) \\ge 4$ and $\\overline{P}_{\\alpha}(i)  1.0$.\n\n2.  **Beta-Sheet Nucleation**: A similar procedure is followed for beta-sheets, using a sliding window of length $L_{\\beta} = 5$. For each window starting at index $j$ and covering residues $a_j, a_{j+1}, \\ldots, a_{j+4}$:\n    *   We calculate the number of sheet-forming residues, $c_{\\beta}(j)$, defined as the count of residues in the window where $P_{\\beta}(a_k)  1.00$.\n    *   We compute the mean sheet propensity: $\\overline{P}_{\\beta}(j) = \\frac{1}{5} \\sum_{k=j}^{j+4} P_{\\beta}(a_k)$.\n    *   A window is declared a beta-sheet seed if $c_{\\beta}(j) \\ge 3$ and $\\overline{P}_{\\beta}(j)  1.0$.\n\nAll identified seeds, which are contiguous segments of the primary sequence, are collected for the next stage.\n\n**Stage 2: Region Extension**\n\nOnce nucleation sites are identified, they are extended in both directions (left and right) along the sequence. This process continues as long as the propensity in the terminal regions remains favorable for the given secondary structure type.\n\nLet an initial seed region be represented by a half-open interval of indices $[s, e)$.\n\n1.  **Helix Extension**: For each alpha-helix seed, initially spanning $[s_0, s_0+6)$:\n    *   **Rightward Extension**: The region's end index $e$ is repeatedly incremented by $1$ as long as $e  n$ (where $n$ is the sequence length) and the average alpha-helix propensity of the four residues at the trailing end of the current region, $[e-4, e-1]$, is above a threshold. The condition is: $\\frac{1}{4} \\sum_{k=e-4}^{e-1} P_{\\alpha}(a_k)  1.0$.\n    *   **Leftward Extension**: The region's start index $s$ is repeatedly decremented by $1$ as long as $s  0$ and the average alpha-helix propensity of the four residues at the leading end of the current region, $[s, s+3]$, is above the threshold. The condition is: $\\frac{1}{4} \\sum_{k=s}^{s+3} P_{\\alpha}(a_k)  1.0$.\n\n2.  **Sheet Extension**: The same logic is applied to each beta-sheet seed, using the beta-sheet propensities $P_{\\beta}$ and the same threshold of $1.0$ for the average propensity of the 4-residue terminal windows.\n\nAfter extending every seed, all resulting regions for a given structure type are merged. This is achieved by creating two boolean arrays, `is_helix` and `is_sheet`, of length $n$. For every final extended helix region $[s, e)$, all elements `is_helix[k]` for $k \\in [s, e)$ are set to true. The same is done for sheet regions and the `is_sheet` array. This step effectively takes the union of all extended regions of the same type.\n\n**Stage 3: Conflict Resolution**\n\nThe extension process may result in some residues being classified as part of both an alpha-helix and a beta-sheet. These conflicts must be resolved.\n\nThe set of conflicting indices is identified as all $i$ where `is_helix[i]` and `is_sheet[i]` are both true. These indices are partitioned into contiguous segments. For each such contiguous overlapping segment, say from index $u$ to $v$ inclusive:\n*   The average alpha-helix propensity, $\\overline{P}_{\\alpha}([u, v]) = \\frac{1}{v-u+1} \\sum_{k=u}^{v} P_{\\alpha}(a_k)$, is calculated.\n*   The average beta-sheet propensity, $\\overline{P}_{\\beta}([u, v]) = \\frac{1}{v-u+1} \\sum_{k=u}^{v} P_{\\beta}(a_k)$, is calculated.\n*   The segment is assigned to the structure type with the strictly greater average propensity. For example, if $\\overline{P}_{\\alpha}([u, v])  \\overline{P}_{\\beta}([u, v])$, the segment is assigned to helix, and the `is_sheet` flags for indices $u$ through $v$ are set to false.\n*   If the average propensities are exactly equal, the segment is assigned to coil, meaning both `is_helix` and `is_sheet` flags for these indices are set to false.\n\nAfter this stage, for any given index $i$, at most one of `is_helix[i]` or `is_sheet[i]` can be true.\n\n**Stage 4: Final State Assignment**\n\nThe final prediction is generated by iterating through the resolved boolean arrays:\n*   If `is_helix[i]` is true, residue $i$ is assigned state $1$ (helix).\n*   If `is_sheet[i]` is true, residue $i$ is assigned state $2$ (sheet).\n*   Otherwise, residue $i$ is assigned state $0$ (coil).\n\nThis deterministic procedure provides a unique secondary structure prediction for any given amino acid sequence.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Chou-Fasman based secondary structure prediction algorithm\n    and applies it to the given test cases.\n    \"\"\"\n    \n    propensities = {\n        'A': (1.45, 0.97), 'R': (1.00, 0.90), 'N': (0.67, 0.89),\n        'D': (0.98, 0.80), 'C': (0.77, 1.30), 'Q': (1.11, 1.10),\n        'E': (1.53, 0.26), 'G': (0.53, 0.81), 'H': (1.24, 0.71),\n        'I': (1.00, 1.60), 'L': (1.34, 1.22), 'K': (1.07, 0.74),\n        'M': (1.20, 1.67), 'F': (1.12, 1.28), 'P': (0.59, 0.62),\n        'S': (0.79, 0.72), 'T': (0.82, 1.20), 'W': (1.14, 1.19),\n        'Y': (0.61, 1.29), 'V': (0.97, 1.65),\n    }\n\n    def predict_structure(sequence: str) - list[int]:\n        n = len(sequence)\n        if n == 0:\n            return []\n\n        seq_p_alpha = np.array([propensities[aa][0] for aa in sequence])\n        seq_p_beta = np.array([propensities[aa][1] for aa in sequence])\n\n        # Stage 1: Nucleation\n        helix_seeds = []\n        win_len_h = 6\n        for i in range(n - win_len_h + 1):\n            window = seq_p_alpha[i : i + win_len_h]\n            count_formers = np.sum(window  1.03)\n            mean_propensity = np.mean(window)\n            if count_formers = 4 and mean_propensity  1.0:\n                helix_seeds.append([i, i + win_len_h])\n\n        sheet_seeds = []\n        win_len_s = 5\n        for j in range(n - win_len_s + 1):\n            window = seq_p_beta[j : j + win_len_s]\n            count_formers = np.sum(window  1.00)\n            mean_propensity = np.mean(window)\n            if count_formers = 3 and mean_propensity  1.0:\n                sheet_seeds.append([j, j + win_len_s])\n        \n        # Stage 2: Extension\n        is_helix = np.zeros(n, dtype=bool)\n        for s, e in helix_seeds:\n            # Extend right\n            current_e = e\n            while current_e  n:\n                if current_e - 4  0: break # Not a valid 4-residue window\n                if np.mean(seq_p_alpha[current_e - 4 : current_e])  1.0:\n                    current_e += 1\n                else:\n                    break\n            \n            # Extend left\n            current_s = s\n            while current_s  0:\n                if current_s + 4  n: break # Not a valid 4-residue window\n                if np.mean(seq_p_alpha[current_s : current_s + 4])  1.0:\n                    current_s -= 1\n                else:\n                    break\n            \n            is_helix[current_s:current_e] = True\n\n        is_sheet = np.zeros(n, dtype=bool)\n        for s, e in sheet_seeds:\n            # Extend right\n            current_e = e\n            while current_e  n:\n                if current_e - 4  0: break\n                if np.mean(seq_p_beta[current_e - 4 : current_e])  1.0:\n                    current_e += 1\n                else:\n                    break\n            \n            # Extend left\n            current_s = s\n            while current_s  0:\n                if current_s + 4  n: break\n                if np.mean(seq_p_beta[current_s : current_s + 4])  1.0:\n                    current_s -= 1\n                else:\n                    break\n            \n            is_sheet[current_s:current_e] = True\n\n        # Stage 3: Conflict Resolution\n        overlap = np.logical_and(is_helix, is_sheet)\n        i = 0\n        while i  n:\n            if overlap[i]:\n                j = i\n                while j  n and overlap[j]:\n                    j += 1\n                \n                # We have a contiguous overlap region [i, j-1]\n                overlap_slice = slice(i, j)\n                mean_alpha = np.mean(seq_p_alpha[overlap_slice])\n                mean_beta = np.mean(seq_p_beta[overlap_slice])\n\n                if mean_alpha  mean_beta:\n                    is_sheet[overlap_slice] = False\n                elif mean_beta  mean_alpha:\n                    is_helix[overlap_slice] = False\n                else: # Equal, assign to coil\n                    is_helix[overlap_slice] = False\n                    is_sheet[overlap_slice] = False\n                i = j\n            else:\n                i += 1\n\n        # Stage 4: Final Assignment\n        prediction = np.zeros(n, dtype=int)\n        prediction[is_helix] = 1\n        prediction[is_sheet] = 2\n        \n        return prediction.tolist()\n\n    test_cases = [\n        \"AAAAAAAGAAAA\",\n        \"VVVVVVVV\",\n        \"ACDEFGHIKLMNPQRSTVWY\",\n        \"PPGPPGPP\",\n        \"EEEELLLVVVVLLLEEEE\",\n    ]\n\n    results = []\n    for case in test_cases:\n        result = predict_structure(case)\n        results.append(result)\n\n    # Format output as specified: a list of lists, comma-separated, no spaces.\n    results_str = \",\".join(str(r) for r in results).replace(\" \", \"\")\n    print(f\"[{results_str}]\")\n\nsolve()\n```", "id": "2371310"}]}