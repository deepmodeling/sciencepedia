{"hands_on_practices": [{"introduction": "The DNA molecule is not merely a passive string of information; its sequence dictates its local three-dimensional structure. This practice delves into how specific sequences can fold into secondary structures, such as hairpins, which can act as physical obstacles to the DNA polymerase machinery. By implementing an algorithm to detect these potential replication-stalling structures based on a simplified biophysical model, you will gain hands-on experience in sequence analysis and translating biological rules into computational code [@problem_id:2403464].", "problem": "You are given a formal definition of reverse-complement palindromic substrings in a Deoxyribonucleic Acid (DNA) string and a simplified biophysical criterion for hairpin formation that may stall DNA-dependent DNA polymerases. Let the alphabet be $\\{A,C,G,T\\}$. For a genome string $G$ of length $N$, a hairpin candidate is any substring $H$ of $G$ that can be partitioned as $H = L \\cdot \\ell \\cdot R$, where $L$ is the left arm of length $s$, $\\ell$ is the loop of length $l$, and $R$ is the right arm of length $s$, with $s \\in \\mathbb{Z}_{\\ge 1}$ and $l \\in \\mathbb{Z}_{\\ge 1}$. Define the complement map $c$ by $c(A)=T$, $c(T)=A$, $c(C)=G$, and $c(G)=C$. For each position $j \\in \\{0,1,\\dots,s-1\\}$, define a base-pair between $L[j]$ and $R[s-1-j]$. A base-pair is a match if $R[s-1-j] = c(L[j])$ and a mismatch otherwise. Let $b$ be the total number of matches, $m$ be the total number of mismatches so that $m = s - b$, and let $g$ be the count of matches that are guanine-cytosine (GC) pairs, namely those matches where $\\{L[j],R[s-1-j]\\} = \\{G,C\\}$. Define the GC fraction $f_{\\mathrm{GC}}$ by $f_{\\mathrm{GC}}=g/b$ if $b \\neq 0$, and $f_{\\mathrm{GC}} = 0$ if $b=0$.\n\nA hairpin candidate $H$ is considered predicted to form a stable hairpin that can stall the polymerase if and only if all of the following hold simultaneously:\n- Stem length constraint: $s_{\\min} \\le s \\le s_{\\max}$.\n- Loop length constraint: $l_{\\min} \\le l \\le l_{\\max}$.\n- Mismatch tolerance: $m \\le k_{\\max}$.\n- Minimum pairing: $b \\ge b_{\\min}$.\n- Minimum GC fraction: $f_{\\mathrm{GC}} \\ge f_{\\mathrm{GC}}^{\\min}$.\n\nFor a given genome $G$ and parameters $(s_{\\min}, s_{\\max}, l_{\\min}, l_{\\max}, k_{\\max}, b_{\\min}, f_{\\mathrm{GC}}^{\\min})$, define the task output as the total number of distinct hairpin instances in $G$ that satisfy the above criteria, where distinct instances are defined by triples $(i,s,l)$ with $i \\in \\{0,1,\\dots,N-(2s+l)\\}$ being the start index of $H$ in $G$, and $s$ and $l$ as above.\n\nYour program must implement this definition exactly and produce the required outputs for the following test suite. Each test case is a tuple consisting of a genome string $G$ and a parameter septuple $(s_{\\min}, s_{\\max}, l_{\\min}, l_{\\max}, k_{\\max}, b_{\\min}, f_{\\mathrm{GC}}^{\\min})$:\n\n- Test case $1$ (general GC-rich palindrome):\n  - $G =$ \"AAAGCGCTTGCGCAAATTT\"\n  - Parameters: $(s_{\\min}, s_{\\max}, l_{\\min}, l_{\\max}, k_{\\max}, b_{\\min}, f_{\\mathrm{GC}}^{\\min}) = (\\,4,\\,4,\\,2,\\,2,\\,0,\\,4,\\,0.75\\,)$\n- Test case $2$ (boundary with exactly one mismatch and GC fraction at threshold):\n  - $G =$ \"TTTATCAAAGTTCCC\"\n  - Parameters: $(\\,3,\\,3,\\,3,\\,3,\\,1,\\,2,\\,0.5\\,)$\n- Test case $3$ (no valid hairpin under strict constraints):\n  - $G =$ \"ATCAAAGTT\"\n  - Parameters: $(\\,3,\\,3,\\,3,\\,3,\\,0,\\,3,\\,1.0\\,)$\n- Test case $4$ (two separated strong hairpins, both GC-rich):\n  - $G =$ \"AAAGCGCTTGCGCTTTCCGGAACCGGAAA\"\n  - Parameters: $(\\,4,\\,4,\\,2,\\,2,\\,0,\\,4,\\,1.0\\,)$\n- Test case $5$ (inclusivity at thresholds with $\\frac{2}{3}$ GC fraction and mismatches at limit):\n  - $G =$ \"AAAGTATCAAAGGTCCAAA\"\n  - Parameters: $(\\,5,\\,5,\\,3,\\,3,\\,2,\\,3,\\,\\frac{2}{3}\\,)$\n\nAngle units are not applicable and no physical units are involved.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases listed above (from test case $1$ to test case $5$). For example, the required format is \"[rA,rB,rC,rD,rE]\" where each item is the integer count for the corresponding test case.", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically grounded, well-posed, and objective. It presents a simplified but coherent biophysical model for the formation of DNA hairpin structures, which are known to be implicated in the stalling of DNA polymerases during replication. All terms, parameters, and criteria are defined with mathematical precision, rendering the problem unambiguous and algorithmically solvable. No contradictions, missing information, or pseudoscientific claims have been identified. Therefore, a solution is not only possible but required.\n\nThe task is to enumerate all distinct hairpin instances within a given genome string $G$ that satisfy a set of simultaneous biophysical and structural constraints. A distinct instance is uniquely identified by a triple $(i, s, l)$, where $i$ is the $0$-indexed starting position of the hairpin candidate $H$ in $G$, $s$ is the length of the stem arms, and $l$ is the length of the loop.\n\nThe methodological approach is a direct and exhaustive search over the entire space of possible hairpin candidates. The algorithm proceeds systematically as follows:\n\n1.  **Candidate Generation**: We iterate through all permissible integer values for the stem length $s$ and loop length $l$, as constrained by the input parameters $(s_{\\min}, s_{\\max})$ and $(l_{\\min}, l_{\\max})$, respectively.\n    $$ s \\in [s_{\\min}, s_{\\max}] $$\n    $$ l \\in [l_{\\min}, l_{\\max}] $$\n    For each valid pair $(s, l)$, the total length of a hairpin candidate $H$ is $2s+l$. We then iterate through all possible starting positions $i$ for such a candidate within the genome $G$ of length $N$.\n    $$ i \\in [0, N - (2s+l)] $$\n    This triple loop structure ensures that every potential hairpin candidate, defined by $(i, s, l)$, is considered exactly once.\n\n2.  **Substructure Partitioning**: For each candidate triple $(i,s,l)$, we extract the corresponding substring $H = G[i:i+2s+l]$. This substring is partitioned into its constituent parts: the left arm $L$, the loop $\\ell$, and the right arm $R$.\n    -   $L = G[i:i+s]$\n    -   $\\ell = G[i+s:i+s+l]$\n    -   $R = G[i+s+l:i+2s+l]$\n\n3.  **Biophysical Analysis**: We then analyze the pairing potential between the left arm $L$ and the right arm $R$. According to the problem definition, a base pair is formed between $L[j]$ and $R[s-1-j]$ for each position $j \\in \\{0, 1, \\dots, s-1\\}$. We must quantify the following properties:\n    -   The total number of matches, $b$, where $R[s-1-j] = c(L[j])$, with $c$ being the complement map $\\{A \\leftrightarrow T, C \\leftrightarrow G\\}$.\n    -   The total number of mismatches, $m$, which is simply $m = s-b$.\n    -   The count of Guanine-Cytosine (GC) matches, $g$, where a match involves the pair $\\{G,C\\}$.\n\n4.  **Constraint Validation**: The computed properties $(b, m, g)$ for the candidate defined by $(i,s,l)$ are validated against the given stability criteria:\n    -   Mismatch tolerance: $m \\le k_{\\max}$\n    -   Minimum pairing: $b \\ge b_{\\min}$\n    -   Minimum GC fraction: A crucial check involves the GC fraction, $f_{\\mathrm{GC}}$. It is defined as $f_{\\mathrm{GC}} = g/b$ if $b \\neq 0$, and $f_{\\mathrm{GC}} = 0$ if $b=0$. This calculated value must satisfy $f_{\\mathrm{GC}} \\ge f_{\\mathrm{GC}}^{\\min}$.\n\n5.  **Enumeration**: If a candidate $(i,s,l)$ satisfies all the specified constraints simultaneously, it is counted as a valid hairpin instance. The total count is accumulated across all evaluated candidates.\n\nThis exhaustive enumeration provides the exact, unique, and correct solution as demanded by the problem statement. The final result for each test case is the total count of such valid $(i,s,l)$ triples.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the DNA hairpin counting problem for a suite of test cases.\n    \"\"\"\n    \n    # The complement map for DNA bases.\n    complement_map = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            \"AAAGCGCTTGCGCAAATTT\",\n            (4, 4, 2, 2, 0, 4, 0.75)\n        ),\n        (\n            \"TTTATCAAAGTTCCC\",\n            (3, 3, 3, 3, 1, 2, 0.5)\n        ),\n        (\n            \"ATCAAAGTT\",\n            (3, 3, 3, 3, 0, 3, 1.0)\n        ),\n        (\n            \"AAAGCGCTTGCGCTTTCCGGAACCGGAAA\",\n            (4, 4, 2, 2, 0, 4, 1.0)\n        ),\n        (\n            \"AAAGTATCAAAGGTCCAAA\",\n            (5, 5, 3, 3, 2, 3, 2/3)\n        ),\n    ]\n\n    def count_hairpins(G, params):\n        \"\"\"\n        Calculates the number of valid hairpin instances in a genome string.\n        \"\"\"\n        s_min, s_max, l_min, l_max, k_max, b_min, f_gc_min = params\n        N = len(G)\n        valid_hairpin_count = 0\n\n        # Iterate over all possible stem lengths s\n        for s in range(s_min, s_max + 1):\n            if s < 1: continue\n\n            # Iterate over all possible loop lengths l\n            for l in range(l_min, l_max + 1):\n                if l < 1: continue\n\n                hairpin_len = 2 * s + l\n                if hairpin_len > N:\n                    continue\n\n                # Iterate over all possible start positions i\n                for i in range(N - hairpin_len + 1):\n                    # Extract hairpin candidate substructures\n                    L = G[i : i + s]\n                    # Loop ell is G[i + s : i + s + l]\n                    R = G[i + s + l : i + hairpin_len]\n                    \n                    # Calculate biophysical properties\n                    b = 0  # matches\n                    g = 0  # GC matches\n                    \n                    for j in range(s):\n                        base_L = L[j]\n                        base_R = R[s - 1 - j]\n                        \n                        if complement_map.get(base_L) == base_R:\n                            b += 1\n                            if base_L in ('G', 'C'):\n                                g += 1\n                    \n                    m = s - b # mismatches\n\n                    # Check stability criteria\n                    # 1. Stem length (implicit in loop bounds)\n                    # 2. Loop length (implicit in loop bounds)\n                    # 3. Mismatch tolerance\n                    if m > k_max:\n                        continue\n                    \n                    # 4. Minimum pairing\n                    if b < b_min:\n                        continue\n                        \n                    # 5. Minimum GC fraction\n                    if b == 0:\n                        f_gc = 0.0\n                    else:\n                        f_gc = g / b\n                    \n                    if f_gc < f_gc_min:\n                        continue\n                        \n                    # If all criteria are met, this is a valid hairpin instance\n                    valid_hairpin_count += 1\n                        \n        return valid_hairpin_count\n\n    results = []\n    for genome, parameters in test_cases:\n        result = count_hairpins(genome, parameters)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2403464"}, {"introduction": "At the heart of DNA replication lies a fundamental compromise between speed and accuracy. The DNA polymerase must work quickly to copy the entire genome, yet it must also maintain incredibly high fidelity to prevent mutations. This exercise challenges you to model this speed-fidelity trade-off by building a kinetic simulation of a polymerase with proofreading capabilities, providing quantitative insights into how error rates, replication velocity, and energy consumption are interconnected [@problem_id:2403505].", "problem": "You are to develop a program that models the trade-off between replication speed and fidelity for deoxyribonucleic acid (DNA) synthesis by a single-processive polymerase with a proofreading exonuclease. The model must treat proofreading as a probabilistic excision step that follows each incorporation attempt. The polymerase attempts to add one nucleotide at a time. Each attempt takes a deterministic time of $t_\\mathrm{add} = 1 / v_0$, where $v_0$ is the baseline elongation rate in nucleotides per second. Upon completion of each addition attempt, exactly one of the following mutually exclusive events occurs:\n- A correct nucleotide is added with probability $1 - p_\\mathrm{mis}$. Immediately after this event, an unnecessary excision (a false-positive proofreading event) occurs with probability $p_\\mathrm{fp}$; if it occurs, the just-added correct nucleotide is excised and the net chain length does not advance. If it does not occur, the addition is accepted and contributes a net forward step of exactly one nucleotide.\n- An incorrect nucleotide is added with probability $p_\\mathrm{mis}$. Immediately after this event, proofreading excises the incorrect nucleotide with probability $p_\\mathrm{proof}$; if it occurs, the net chain length does not advance. If it does not occur, the incorrect nucleotide remains incorporated and the addition is accepted, advancing the net chain length by exactly one nucleotide but introducing a replication error at this position.\n\nEach excision event, whether following a correct or an incorrect addition, incurs a deterministic time penalty of $\\tau_\\mathrm{proof}$ seconds. Energy consumption is accounted for as follows. Every accepted net forward step consumes exactly one deoxynucleotide triphosphate (dNTP) hydrolysis. Each excision event wastes exactly one previous dNTP hydrolysis because the incorporated nucleotide that was just added is removed and must later be re-incorporated. The energetic cost per dNTP hydrolysis is $E_\\mathrm{dNTP}$ expressed in units of Boltzmann constant times absolute temperature ($k_\\mathrm{B}T$) at the temperature of interest, where Boltzmann constant times absolute temperature ($k_\\mathrm{B}T$) is denoted by $k_\\mathrm{B}T$.\n\nUnder this probabilistic process, for each parameter set you must compute the following expected quantities, defined per net forward nucleotide incorporated:\n- The effective replication speed $v_\\mathrm{eff}$ in nucleotides per second.\n- The error fraction $e$, defined as the probability that a net accepted incorporation is incorrect, expressed as a unitless decimal (not a percentage).\n- The mean energy cost $E_\\mathrm{tot}$ in units of $k_\\mathrm{B}T$.\n\nAll physical units must be respected: report $v_\\mathrm{eff}$ in nucleotides per second, $e$ as a decimal, and $E_\\mathrm{tot}$ in $k_\\mathrm{B}T$. For output, round each reported float to exactly $6$ decimal places.\n\nUse the following test suite of parameter sets. For each set, parameters are given as $(v_0, p_\\mathrm{mis}, p_\\mathrm{proof}, p_\\mathrm{fp}, \\tau_\\mathrm{proof}, E_\\mathrm{dNTP})$ with $v_0$ in nucleotides per second, probabilities unitless in the closed interval $[0,1]$, $\\tau_\\mathrm{proof}$ in seconds, and $E_\\mathrm{dNTP}$ in $k_\\mathrm{B}T$:\n- Test case $1$: $(1000, 1 \\times 10^{-5}, 0.99, 0.01, 0.005, 20)$.\n- Test case $2$: $(1000, 1 \\times 10^{-5}, 0, 0.01, 0.005, 20)$.\n- Test case $3$: $(1000, 1 \\times 10^{-4}, 1, 0, 0.005, 20)$.\n- Test case $4$: $(800, 0, 1, 0.2, 0.002, 20)$.\n- Test case $5$: $(1200, 5 \\times 10^{-5}, 0.95, 0.05, 0.02, 20)$.\n\nYour program must produce a single line of output containing the results for the test cases, in order, as a comma-separated list of lists, where each inner list contains three floats $[v_\\mathrm{eff}, e, E_\\mathrm{tot}]$ rounded to exactly $6$ decimal places. The final output format must be:\n\"[[v1,e1,E1],[v2,e2,E2],[v3,e3,E3],[v4,e4,E4],[v5,e5,E5]]\"\nwith no additional whitespace beyond what is necessary for valid comma separation and brackets, and no additional text.", "solution": "The problem presented is a valid and well-posed exercise in biophysical modeling, specifically concerning the kinetics of DNA replication. It requires the derivation of key performance metrics for a polymerase with proofreading activity. The problem is scientifically grounded, free of contradictions, and contains all necessary information. I will proceed to derive the solution from first principles.\n\nThe core of the problem is to determine the expected time, expected number of errors, and expected energy cost per net nucleotide incorporated into the growing DNA chain. This is a classic renewal-reward process. We will first analyze the outcomes of a single nucleotide addition attempt by the polymerase, which we define as a single process cycle. The duration of the fundamental addition attempt is $t_\\mathrm{add} = 1/v_0$, where $v_0$ is the baseline elongation rate.\n\nThere are four mutually exclusive outcomes for each attempt cycle:\n\n1.  **Correct nucleotide incorporated, accepted**: A correct nucleotide (chosen with probability $1 - p_\\mathrm{mis}$) is added and not excised (probability $1 - p_\\mathrm{fp}$).\n    -   Probability: $P_1 = (1 - p_\\mathrm{mis})(1 - p_\\mathrm{fp})$\n    -   Time elapsed: $T_1 = 1/v_0$\n    -   Net advancement: $\\Delta L_1 = +1$ nucleotide\n    -   Error introduced: $\\Delta E_1 = 0$\n\n2.  **Correct nucleotide incorporated, excised (futile cycle)**: A correct nucleotide (probability $1 - p_\\mathrm{mis}$) is added but then incorrectly excised (probability $p_\\mathrm{fp}$).\n    -   Probability: $P_2 = (1 - p_\\mathrm{mis})p_\\mathrm{fp}$\n    -   Time elapsed: $T_2 = 1/v_0 + \\tau_\\mathrm{proof}$\n    -   Net advancement: $\\Delta L_2 = 0$ nucleotides\n    -   Error introduced: $\\Delta E_2 = 0$\n\n3.  **Incorrect nucleotide incorporated, excised (proofreading)**: An incorrect nucleotide (probability $p_\\mathrm{mis}$) is added and correctly excised (probability $p_\\mathrm{proof}$).\n    -   Probability: $P_3 = p_\\mathrm{mis}p_\\mathrm{proof}$\n    -   Time elapsed: $T_3 = 1/v_0 + \\tau_\\mathrm{proof}$\n    -   Net advancement: $\\Delta L_3 = 0$ nucleotides\n    -   Error introduced: $\\Delta E_3 = 0$\n\n4.  **Incorrect nucleotide incorporated, accepted (error)**: An incorrect nucleotide (probability $p_\\mathrm{mis}$) is added and not excised (probability $1 - p_\\mathrm{proof}$).\n    -   Probability: $P_4 = p_\\mathrm{mis}(1 - p_\\mathrm{proof})$\n    -   Time elapsed: $T_4 = 1/v_0$\n    -   Net advancement: $\\Delta L_4 = +1$ nucleotide\n    -   Error introduced: $\\Delta E_4 = 1$\n\nFrom these elementary events, we can compute the expectation values for time, chain advancement, and errors over a single attempt cycle. Let $\\langle X \\rangle$ denote the expectation of a quantity $X$.\n\nThe expected time per attempt cycle, $\\langle T \\rangle$:\n$$ \\langle T \\rangle = \\sum_{i=1}^{4} P_i T_i = P_1(1/v_0) + P_2(1/v_0+\\tau_\\mathrm{proof}) + P_3(1/v_0+\\tau_\\mathrm{proof}) + P_4(1/v_0) $$\nSince $\\sum P_i = 1$, this simplifies to:\n$$ \\langle T \\rangle = \\frac{1}{v_0} + (P_2 + P_3)\\tau_\\mathrm{proof} = \\frac{1}{v_0} + ((1 - p_\\mathrm{mis})p_\\mathrm{fp} + p_\\mathrm{mis}p_\\mathrm{proof})\\tau_\\mathrm{proof} $$\n\nThe expected net advancement in chain length per attempt cycle, $\\langle N \\rangle$:\n$$ \\langle N \\rangle = \\sum_{i=1}^{4} P_i \\Delta L_i = P_1(1) + P_2(0) + P_3(0) + P_4(1) = P_1 + P_4 $$\n$$ \\langle N \\rangle = (1 - p_\\mathrm{mis})(1 - p_\\mathrm{fp}) + p_\\mathrm{mis}(1 - p_\\mathrm{proof}) $$\nThis is the probability that an attempt results in a net forward step.\n\nThe expected number of errors introduced per attempt cycle, $\\langle Err \\rangle$:\n$$ \\langle Err \\rangle = \\sum_{i=1}^{4} P_i \\Delta E_i = P_1(0) + P_2(0) + P_3(0) + P_4(1) = P_4 $$\n$$ \\langle Err \\rangle = p_\\mathrm{mis}(1 - p_\\mathrm{proof}) $$\n\nThe required quantities are defined per net incorporated nucleotide. They can be found by taking the ratio of the corresponding expectation values.\n\n1.  **Effective replication speed, $v_\\mathrm{eff}$**: This is the expected advancement per expected time.\n    $$v_\\mathrm{eff} = \\frac{\\langle N \\rangle}{\\langle T \\rangle} = \\frac{(1 - p_\\mathrm{mis})(1 - p_\\mathrm{fp}) + p_\\mathrm{mis}(1 - p_\\mathrm{proof})}{1/v_0 + ((1 - p_\\mathrm{mis})p_\\mathrm{fp} + p_\\mathrm{mis}p_\\mathrm{proof})\\tau_\\mathrm{proof}}$$\n\n2.  **Error fraction, $e$**: This is the expected number of errors per expected advancement.\n    $$e = \\frac{\\langle Err \\rangle}{\\langle N \\rangle} = \\frac{p_\\mathrm{mis}(1 - p_\\mathrm{proof})}{(1 - p_\\mathrm{mis})(1 - p_\\mathrm{fp}) + p_\\mathrm{mis}(1 - p_\\mathrm{proof})}$$\n\n3.  **Mean energy cost, $E_\\mathrm{tot}$**: Each attempt cycle, successful or not, consumes one dNTP, at an energy cost of $E_\\mathrm{dNTP}$. Thus, the expected energy cost per attempt is $\\langle \\text{Energy} \\rangle = 1 \\cdot E_\\mathrm{dNTP}$. The total energy cost per net incorporated nucleotide is this cost divided by the expected advancement per attempt.\n    $$E_\\mathrm{tot} = \\frac{\\langle \\text{Energy} \\rangle}{\\langle N \\rangle} = \\frac{E_\\mathrm{dNTP}}{(1 - p_\\mathrm{mis})(1 - p_\\mathrm{fp}) + p_\\mathrm{mis}(1 - p_\\mathrm{proof})}$$\n\nThese formulas are implemented to compute the results for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the effective replication speed, error fraction, and mean energy cost\n    for a model of DNA polymerase with proofreading.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: (v0, p_mis, p_proof, p_fp, tau_proof, E_dNTP)\n    test_cases = [\n        (1000.0, 1e-5, 0.99, 0.01, 0.005, 20.0),\n        (1000.0, 1e-5, 0.0, 0.01, 0.005, 20.0),\n        (1000.0, 1e-4, 1.0, 0.0, 0.005, 20.0),\n        (800.0, 0.0, 1.0, 0.2, 0.002, 20.0),\n        (1200.0, 5e-5, 0.95, 0.05, 0.02, 20.0),\n    ]\n\n    results_list = []\n    \n    for case in test_cases:\n        v0, p_mis, p_proof, p_fp, tau_proof, E_dNTP = case\n\n        # Probability of a successful net forward step per attempt cycle.\n        # This corresponds to <N> in the derivation.\n        prob_success = (1.0 - p_mis) * (1.0 - p_fp) + p_mis * (1.0 - p_proof)\n\n        # Probability of an excision event per attempt cycle (either futile or productive).\n        prob_excision = (1.0 - p_mis) * p_fp + p_mis * p_proof\n        \n        # Expected time per attempt cycle. This corresponds to <T>.\n        # Handle v0=0 case to avoid division by zero, although not in test cases.\n        if v0 == 0:\n            v_eff = 0.0\n            # Other metrics would be undefined, but we can set them to handle the case.\n            e = float('nan')\n            E_tot = float('inf')\n        else:\n            exp_time_per_attempt = 1.0 / v0 + prob_excision * tau_proof\n\n            # Effective speed (nucleotides per second).\n            v_eff = prob_success / exp_time_per_attempt\n\n        # Error fraction: probability of an error event, conditioned on a successful incorporation.\n        # Corresponds to <Err> / <N>.\n        prob_error_incorporation = p_mis * (1.0 - p_proof)\n        if prob_success == 0:\n            e = float('nan') # Undefined if polymerase can never advance\n            E_tot = float('inf')\n        else:\n            e = prob_error_incorporation / prob_success\n            # Mean energy cost per net incorporated nucleotide.\n            E_tot = (1.0 / prob_success) * E_dNTP\n\n        results_list.append([v_eff, e, E_tot])\n    \n    # Format the final output string exactly as specified.\n    # Each float must be rounded to exactly 6 decimal places.\n    # The output should be a list of lists, with no extra whitespace.\n    formatted_results = []\n    for res in results_list:\n        v_str = f\"{res[0]:.6f}\"\n        e_str = f\"{res[1]:.6f}\"\n        E_str = f\"{res[2]:.6f}\"\n        formatted_results.append(f\"[{v_str},{e_str},{E_str}]\")\n    \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2403505"}, {"introduction": "Replication across a vast eukaryotic genome is a highly coordinated event, starting at multiple \"origins\" and concluding in \"termination zones.\" These events leave characteristic footprints in genome-wide experimental data, which often appear as U-shaped and N-shaped valleys in replication timing profiles. This final practice introduces you to the world of bioinformatics data analysis, where you will build a classifier to distinguish these initiation and termination signatures from noisy data, demonstrating how computational modeling helps us decipher the large-scale organization of DNA replication [@problem_id:2403516].", "problem": "You are given the task of building a deterministic classifier that distinguishes between genomic windows corresponding to initiation zones and termination zones of deoxyribonucleic acid (DNA) replication, using simplified synthetic replication timing profiles. In replication timing data, initiation zones tend to manifest as U-shaped valleys, whereas termination zones tend to manifest as inverted U-shaped profiles (N-shaped). For this task, each replication timing profile is represented as a discrete set of samples from a scalar function of a one-dimensional genomic coordinate.\n\nEach test case defines a synthetic replication timing profile over a window by sampling at $n$ equally spaced coordinates $x_i$ on the closed interval $\\left[-1,1\\right]$, where $i \\in \\{1,2,\\dots,n\\}$. The observed replication timing value at coordinate $x_i$ is given by\n$$\ny_i \\;=\\; a\\,(x_i - c)^2 + b + d\\,x_i + \\varepsilon_i,\n$$\nwhere $a, b, c, d$ are real-valued parameters, and $\\varepsilon_i$ are independent and identically distributed samples from a normal distribution with mean $0$ and standard deviation $\\sigma$. The coordinate grid is defined by $x_i = -1 + \\dfrac{2(i-1)}{n-1}$ for $i = 1,\\dots,n$. The label is defined by the sign of the intrinsic curvature parameter $a$: initiation (U-shaped) if $a > 0$, and termination (N-shaped) if $a < 0$. However, when deciding labels, you must treat only the observable pairs $(x_i, y_i)$ as available; you are not allowed to rely on the hidden generating parameter $a$.\n\nYour program must construct the profiles for the following test suite and output a binary prediction for each test case in order, using the rule: output $1$ for predicted initiation (U-shaped) and $0$ for predicted termination (N-shaped). No user input is provided; all quantities needed are specified here. There are no physical units to report. Angles are not used. All outputs must be integers.\n\nTest suite (each bullet describes one test case in the exact order they must be evaluated):\n\n- Case $1$: $n = 101$, $a = 0.8$, $b = 0.05$, $c = 0.0$, $d = 0.0$, $\\sigma = 0.05$, random seed $= 41$.\n- Case $2$: $n = 101$, $a = -0.7$, $b = -0.02$, $c = 0.2$, $d = 0.0$, $\\sigma = 0.05$, random seed $= 7$.\n- Case $3$: $n = 121$, $a = 0.4$, $b = 0.0$, $c = -0.2$, $d = 0.3$, $\\sigma = 0.07$, random seed $= 99$.\n- Case $4$: $n = 121$, $a = -0.5$, $b = 0.1$, $c = 0.1$, $d = -0.2$, $\\sigma = 0.08$, random seed $= 123$.\n- Case $5$: $n = 81$, $a = 0.25$, $b = 0.0$, $c = 0.0$, $d = -0.1$, $\\sigma = 0.15$, random seed $= 2025$.\n- Case $6$: $n = 81$, $a = -0.2$, $b = 0.05$, $c = -0.1$, $d = 0.0$, $\\sigma = 0.05$, random seed $= 555$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[1,0,1,1,0,0]\"), in the same order as the test cases above, with no additional text. The required outputs are integers and must be reported as a list of length $6$.", "solution": "The problem presented is a standard exercise in statistical estimation and classification, and as such, it is valid. It requires the construction of a deterministic classifier to distinguish between two classes of synthetic genomic profiles based on their shape. The classification is to be performed on data generated from a known model with stochastic components.\n\nThe underlying physical process is modeled by the equation:\n$$ y_i \\;=\\; a(x_i - c)^2 + b + d x_i + \\varepsilon_i $$\nwhere $(x_i, y_i)$ for $i \\in \\{1, \\dots, n\\}$ represent the observable data, $\\varepsilon_i$ are independent and identically distributed random variables from a normal distribution $\\mathcal{N}(0, \\sigma^2)$, and $a, b, c, d$ are the hidden parameters defining the signal.\n\nThe classification rule is based on the sign of the parameter $a$. A positive value of $a$ corresponds to an 'initiation' profile (U-shaped, concave up), while a negative value of $a$ corresponds to a 'termination' profile (N-shaped, concave down). The task is to infer this sign from the observed data $(x_i, y_i)$ alone.\n\nTo accomplish this, we must first recognize the structure of the model equation. By expanding the quadratic term, the equation can be rewritten as:\n$$ y_i = a x_i^2 - 2ac x_i + ac^2 + b + d x_i + \\varepsilon_i $$\nGrouping terms by powers of $x_i$ reveals a simple polynomial structure:\n$$ y_i = (a) x_i^2 + (d - 2ac) x_i + (ac^2 + b) + \\varepsilon_i $$\nThis is a quadratic model of the form $y_i = \\beta_2 x_i^2 + \\beta_1 x_i + \\beta_0 + \\varepsilon_i$, where the coefficients are defined as:\n$$ \\beta_2 = a $$\n$$ \\beta_1 = d - 2ac $$\n$$ \\beta_0 = ac^2 + b $$\nThe critical parameter for classification, $a$, is identical to the coefficient of the quadratic term, $\\beta_2$. Therefore, the problem reduces to estimating $\\beta_2$ from the noisy data and determining its sign.\n\nThe standard and optimal method for estimating the coefficients of such a linear model is the method of least squares. We seek to find a set of estimated coefficients $\\hat{\\boldsymbol{\\beta}} = [\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2]^T$ that minimizes the sum of squared residuals, $SSR$:\n$$ SSR = \\sum_{i=1}^{n} (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i + \\hat{\\beta}_2 x_i^2))^2 $$\nThis problem can be expressed in matrix algebra. Let $\\mathbf{y}$ be the $n \\times 1$ column vector of observations $[y_1, \\dots, y_n]^T$. Let $\\mathbf{X}$ be the $n \\times 3$ design matrix, where each row corresponds to an observation and each column to a predictor term:\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1 & x_1 & x_1^2 \\\\\n1 & x_2 & x_2^2 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_n & x_n^2\n\\end{pmatrix}\n$$\nThe linear model is then $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$. The least-squares solution $\\hat{\\boldsymbol{\\beta}}$ that minimizes $\\|\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\|^2$ is given by the solution to the normal equations:\n$$ \\mathbf{X}^T \\mathbf{X} \\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T \\mathbf{y} $$\nAssuming $\\mathbf{X}^T \\mathbf{X}$ is invertible, the solution is:\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} $$\nNumerically, this solution is computed efficiently using methods such as QR decomposition, as implemented in standard scientific computing libraries.\n\nOur estimate for the parameter $a$ is the estimated coefficient of the quadratic term, $\\hat{a} = \\hat{\\beta}_2$. The classification rule is then definitively established:\n- If $\\hat{\\beta}_2 > 0$, the profile is classified as initiation (label $1$).\n- If $\\hat{\\beta}_2 \\le 0$, the profile is classified as termination (label $0$).\n\nFor each test case, the procedure is as follows:\n1.  Set the random number generator seed to ensure reproducibility.\n2.  Generate the $n$ coordinates $x_i$ over the interval $[-1, 1]$.\n3.  Generate $n$ noise samples $\\varepsilon_i$ from $\\mathcal{N}(0, \\sigma^2)$.\n4.  Compute the observed data $y_i$ using the given parameters $a, b, c, d, \\sigma$.\n5.  Construct the design matrix $\\mathbf{X}$ and the observation vector $\\mathbf{y}$.\n6.  Solve the least-squares problem for $\\hat{\\boldsymbol{\\beta}} = [\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2]^T$.\n7.  Apply the decision rule based on the sign of $\\hat{\\beta}_2$ to obtain the classification label.\n\nThis procedure is applied to all specified test cases to generate the final list of predictions.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the classification problem for a suite of synthetic DNA replication timing profiles.\n    The method involves fitting a quadratic model to the data using least squares\n    and classifying based on the sign of the estimated quadratic coefficient.\n    \"\"\"\n    test_cases = [\n        # n, a, b, c, d, sigma, seed\n        (101, 0.8, 0.05, 0.0, 0.0, 0.05, 41),\n        (101, -0.7, -0.02, 0.2, 0.0, 0.05, 7),\n        (121, 0.4, 0.0, -0.2, 0.3, 0.07, 99),\n        (121, -0.5, 0.1, 0.1, -0.2, 0.08, 123),\n        (81, 0.25, 0.0, 0.0, -0.1, 0.15, 2025),\n        (81, -0.2, 0.05, -0.1, 0.0, 0.05, 555),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n, a, b, c, d, sigma, seed = case\n        \n        # 1. Set the random seed for reproducibility.\n        np.random.seed(seed)\n        \n        # 2. Generate the coordinate grid over [-1, 1].\n        x = np.linspace(-1, 1, int(n))\n        \n        # 3. Generate Gaussian noise.\n        epsilon = np.random.normal(loc=0.0, scale=sigma, size=int(n))\n        \n        # 4. Compute the observed data y using the generative model.\n        y = a * (x - c)**2 + b + d * x + epsilon\n        \n        # 5. Construct the design matrix for quadratic regression.\n        # The model is y = beta_0 + beta_1*x + beta_2*x^2.\n        # The columns represent powers of x: x^0, x^1, x^2.\n        X = np.vstack([np.ones_like(x), x, x**2]).T\n        \n        # 6. Solve the linear least-squares problem to find the coefficients.\n        # The solution vector beta_hat corresponds to [beta_0, beta_1, beta_2].\n        beta_hat, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n        \n        # 7. The estimated quadratic coefficient, a_hat, is the third element.\n        a_hat = beta_hat[2]\n        \n        # 8. Apply the decision rule:\n        # 1 for initiation (U-shaped, a > 0), 0 for termination (N-shaped, a < 0).\n        prediction = 1 if a_hat > 0 else 0\n        results.append(prediction)\n\n    # 9. Format the output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2403516"}]}