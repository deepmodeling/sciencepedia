{"hands_on_practices": [{"introduction": "For many **NP-hard** problems, finding the exact optimal solution is computationally infeasible. We often turn to polynomial-time approximation algorithms that guarantee a solution within a certain factor of the optimum. This first exercise [@problem_id:1426648] invites you to analyze a simple, intuitive greedy algorithm for the classic **Minimum Vertex Cover** problem. Mastering this analysis is a cornerstone of understanding approximation, as it demonstrates how to rigorously prove a constant performance guarantee by relating the algorithm's output to the size of an optimal solution.", "problem": "In computational complexity theory, many optimization problems are **NP-hard**, meaning we do not expect to find an algorithm that can solve them optimally in polynomial time. For such problems, we often seek polynomial-time approximation algorithms that guarantee a solution within a certain factor of the optimal one.\n\nConsider the **MINIMUM VERTEX COVER** problem: Given an undirected graph $G = (V, E)$ with a set of vertices $V$ and a set of edges $E$, find a subset of vertices $V' \\subseteq V$ of minimum possible size such that every edge in $E$ has at least one of its endpoints in $V'$.\n\nLet's analyze a simple greedy algorithm for this problem, which we'll call **EDGE-PICKER**:\n1. Initialize the vertex cover, $C$, as an empty set.\n2. While the graph still contains at least one edge:\n   a. Choose an arbitrary edge $(u, v)$ from the graph's edge set $E$.\n   b. Add both vertices, $u$ and $v$, to the cover $C$.\n   c. Remove the edge $(u,v)$ and all other edges incident to either $u$ or $v$ from the graph.\n3. Return the set $C$ as the approximate vertex cover.\n\nThe **approximation ratio** of an algorithm for a minimization problem is the maximum possible ratio of the size of the solution produced by the algorithm to the size of an optimal solution, taken over all possible inputs. A **tight** approximation ratio is an approximation ratio for which there exists an input instance where the algorithm's performance exactly matches the ratio.\n\nWhat is the tight approximation ratio for the EDGE-PICKER algorithm for the MINIMUM VERTEX COVER problem?\n\nA. $1.5$\n\nB. $2$\n\nC. $\\log_2(|V|)$, where $|V|$ is the number of vertices in the graph.\n\nD. $|V|^{1/2}$\n\nE. The ratio is not bounded by any function of $|V|$.", "solution": "Let $G=(V,E)$ be the input graph. Run EDGE-PICKER and let $C$ be the returned set. Let $M$ be the set of edges selected in step 2a during the execution.\n\nFirst, $M$ is a matching. Indeed, when an edge $(u,v)$ is selected, step 2c removes all edges incident to $u$ or $v$. Hence no later selected edge can share an endpoint with $(u,v)$, so the selected edges are pairwise disjoint.\n\nMoreover, $M$ is maximal as a matching in $G$. At termination, there is no edge remaining in the residual graph; therefore there is no edge in $G$ with both endpoints outside the set of endpoints of $M$, for otherwise such an edge would still be present and selectable. Hence no additional edge can be added to $M$ without violating the matching property.\n\nBecause the algorithm adds both endpoints of each edge in $M$ to $C$, and because edges in $M$ are disjoint, no endpoint is added twice. Therefore\n$$\n|C|=2|M|.\n$$\nLet $C^{*}$ be an optimal vertex cover. Every edge in $M$ must be covered by $C^{*}$, and since the edges in $M$ are disjoint, covering them requires at least one distinct endpoint per edge. Therefore\n$$\n|C^{*}| \\ge |M|.\n$$\nCombining the two inequalities gives\n$$\n|C| = 2|M| \\le 2|C^{*}|,\n$$\nso the approximation ratio is at most $2$.\n\nTo show tightness, consider a star graph with one center and $k$ leaves. An optimal vertex cover has size $1$ (the center). EDGE-PICKER selects some edge $(\\text{center}, \\text{leaf})$, adds both endpoints, and removes all edges, returning $|C|=2$. Thus the ratio $|C|/|C^{*}|=2$. Alternatively, on a graph of $k$ disjoint edges, $|C^{*}|=k$ while EDGE-PICKER returns $2k$, again yielding ratio $2$.\n\nTherefore, the tight approximation ratio of EDGE-PICKER is $2$, which corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1426648"}, {"introduction": "Not all simple heuristics perform well, even for problems that seem similar. While we found a good approximation for Vertex Cover, this practice [@problem_id:1426630] explores a similar greedy strategy for its close cousin, the **Maximum Independent Set** problem. Your task is to analyze its performance on a specially constructed family of graphs, revealing how a seemingly reasonable approach can yield solutions that are arbitrarily far from optimal. This highlights the critical importance of worst-case analysis and shows that some problems are much harder to approximate than others.", "problem": "In computational complexity theory, many optimization problems are **NP-hard**, meaning no known algorithm can find the optimal solution in polynomial time. For such problems, we often rely on polynomial-time heuristics that aim to find a \"good enough\" but not necessarily optimal solution. One of the most fundamental **NP-hard** problems on graphs is the **Maximum Independent Set (MIS)** problem. An independent set is a subset of vertices in a graph where no two vertices are adjacent. The **MIS** problem seeks to find an independent set of the maximum possible size.\n\nConsider a simple heuristic for this problem, which we will call the **Greedy Selection Heuristic**. The heuristic works as follows:\n1. Initialize the independent set, $S$, to be an empty set.\n2. While the graph still contains vertices:\n   a. Choose an arbitrary vertex, $v$, from the graph.\n   b. Add $v$ to the set $S$.\n   c. Remove $v$ and all of its neighbors from the graph.\n3. Return the set $S$.\n\nThe quality of the solution found by this heuristic can depend heavily on the \"arbitrary\" choices made at each step. To analyze its limitations, consider a specific family of graphs, $G_k$, parameterized by an integer $k \\ge 2$. The graph $G_k$ is constructed as follows:\n- The vertex set is composed of two disjoint sets of vertices: a set $C = \\{c_1, c_2, \\dots, c_k\\}$ and a set $U = \\{u_1, u_2, \\dots, u_k\\}$.\n- The edge set is defined by two rules:\n    1. The vertices in $C$ form a clique; that is, every pair of distinct vertices $(c_i, c_j)$ in $C$ is connected by an edge.\n    2. For every pair of indices $(i, j)$ where $i \\neq j$, there is an edge connecting vertex $c_i \\in C$ to vertex $u_j \\in U$.\n\nYour task is to determine the performance guarantee of the Greedy Selection Heuristic on this family of graphs. Specifically, find the ratio $\\frac{\\alpha(G_k)}{|S_{\\text{worst}}|}$, where $\\alpha(G_k)$ is the size of the true maximum independent set in $G_k$, and $|S_{\\text{worst}}|$ is the size of the smallest possible independent set that the Greedy Selection Heuristic can produce by making a particularly \"unlucky\" sequence of choices.\n\nExpress your answer as a function of $k$.", "solution": "We first restate the structure of $G_{k}$. The vertex set is $V=C \\cup U$ with $C=\\{c_{1},\\dots,c_{k}\\}$ and $U=\\{u_{1},\\dots,u_{k}\\}$ disjoint. The edges are:\n1) $C$ induces a clique, so every distinct pair $c_{i},c_{j}$ is adjacent.\n2) For $i \\neq j$, $c_{i}$ is adjacent to $u_{j}$. Consequently, $c_{i}$ is not adjacent to $u_{i}$, and there are no edges within $U$.\n\nDetermine $\\alpha(G_{k})$. Since there are no edges among vertices of $U$, the set $U$ is an independent set of size $k$, hence\n$$\n\\alpha(G_{k}) \\geq k.\n$$\nLet $S$ be any independent set and write $a=|S \\cap C|$ and $b=|S \\cap U|$. Because $C$ is a clique, we have $a \\leq 1$. If $a=0$, then $|S|=b \\leq k$. If $a=1$, say $c_{i} \\in S$, then for every $j \\neq i$, $c_{i}$ is adjacent to $u_{j}$, so $u_{j} \\notin S$ for all $j \\neq i$, and only $u_{i}$ could potentially be included from $U$. Hence $b \\leq 1$ and $|S|=a+b \\leq 2$. In all cases,\n$$\n|S| \\leq k.\n$$\nCombining with the lower bound gives\n$$\n\\alpha(G_{k})=k.\n$$\n\nAnalyze the Greedy Selection Heuristic in the worst case. The heuristic iteratively picks a vertex $v$, inserts $v$ into $S$, and deletes $v$ together with all its neighbors.\n\nConsider an “unlucky” first choice $v=c_{i} \\in C$. The neighbors of $c_{i}$ are precisely $(C \\setminus \\{c_{i}\\}) \\cup (U \\setminus \\{u_{i}\\})$. After removing $c_{i}$ and its neighbors, the only remaining vertex is $u_{i}$. The next (and final) step picks $u_{i}$, and the process terminates. Thus in this run the heuristic outputs an independent set of size\n$$\n|S|=2.\n$$\nAlternatively, if the first choice is $v=u_{j} \\in U$, the neighbors of $u_{j}$ are exactly $\\{c_{i}: i \\neq j\\}$. After removing $u_{j}$ and these neighbors, the remaining vertices are $c_{j}$ and all $u_{\\ell}$ with $\\ell \\neq j$. An adversarial second choice $v=c_{j}$ removes $c_{j}$ and all remaining $u_{\\ell}$ with $\\ell \\neq j$, leaving no vertices. The heuristic then outputs $S=\\{u_{j},c_{j}\\}$ of size\n$$\n|S|=2.\n$$\nIn either case, the heuristic cannot terminate after a single selection because the first choice leaves at least one vertex not adjacent to it (specifically $u_{i}$ if $v=c_{i}$, or at least $c_{j}$ if $v=u_{j}$). Therefore the smallest possible independent set the heuristic can produce on $G_{k}$ is\n$$\n|S_{\\text{worst}}|=2.\n$$\n\nThe requested performance ratio is therefore\n$$\n\\frac{\\alpha(G_{k})}{|S_{\\text{worst}}|}=\\frac{k}{2}.\n$$", "answer": "$$\\boxed{\\frac{k}{2}}$$", "id": "1426630"}, {"introduction": "The previous exercises demonstrated two different outcomes: an algorithm with a constant approximation ratio ($2$) and another with a ratio that can grow without bound. This distinction is formalized by complexity classes like **APX**. This practice [@problem_id:1426604] solidifies the definition of **APX** by asking you to determine which types of performance guarantees are sufficient to place a problem into this class. By analyzing various functions of the input size $n$, you will learn to precisely identify what it means for a problem to be approximable within a constant factor.", "problem": "In computational complexity theory, many optimization problems are **NP-hard**, meaning it is unlikely that a polynomial-time algorithm exists to find the optimal solution. For such problems, we often seek polynomial-time approximation algorithms.\n\nAn approximation algorithm for a minimization problem takes an instance $I$ of the problem and returns a solution with a cost $C(I)$. The optimal solution for that instance has a cost $OPT(I)$. The performance ratio, $\\rho(I)$, of the algorithm for instance $I$ is defined as $\\rho(I) = \\frac{C(I)}{OPT(I)}$. By convention, $\\rho(I) \\ge 1$.\n\nThe complexity class **APX** (Approximable) contains all **NP-hard** optimization problems for which there exists a polynomial-time approximation algorithm with a performance ratio bounded by a constant. That is, there is a constant $c > 1$ such that for all possible problem instances $I$, the algorithm's performance ratio $\\rho(I)$ satisfies $\\rho(I) \\le c$.\n\nA team of researchers is studying a new **NP-hard** minimization problem. They have developed several different polynomial-time algorithms. For each algorithm, they have managed to determine an upper bound on its performance ratio as a function of $n$, where $n$ is a parameter representing the size of the input instance (e.g., the number of vertices in a graph). Assume $n \\ge 1$.\n\nWhich of the following discovered algorithms, described by their performance ratio upper bounds, would be sufficient to prove that the problem is in **APX**? Select all that apply.\n\nA. An algorithm with a performance ratio bounded by $3 - \\exp(-n)$.\n\nB. An algorithm with a performance ratio bounded by $\\frac{n}{1000} + 1$.\n\nC. An algorithm with a performance ratio bounded by $2 + \\sin(n)$.\n\nD. An algorithm with a performance ratio bounded by $1 + \\ln(\\ln(n))$, for $n > e$.\n\nE. An algorithm with a performance ratio bounded by $1.0001$.", "solution": "We recall the definition: a minimization problem is in **APX** if there exists a polynomial-time algorithm and a constant $c>1$ such that for every input instance $I$ (equivalently, for every input size parameter $n \\ge 1$), the performance ratio satisfies $\\rho(I) \\le c$. Given an algorithm whose performance ratio is upper bounded by a function $f(n)$, it suffices to show that there exists a constant $c>1$ such that $f(n) \\le c$ for all $n \\ge 1$.\n\nAnalyze each option:\n\nA. Bound $f(n) = 3 - \\exp(-n)$. For all $n \\ge 1$, we have $0 < \\exp(-n) \\le \\exp(-1)$, hence $3 - \\exp(-n) < 3$. Therefore $f(n) \\le 3$ for all $n \\ge 1$. Choosing $c = 3$ gives $\\rho(I) \\le f(n) \\le 3 = c$ for all $n$, with $c>1$. This proves **APX** membership.\n\nB. Bound $f(n) = \\frac{n}{1000} + 1$. We have $\\lim_{n \\to \\infty} f(n) = \\infty$, so for any finite constant $c$, there exists $n$ with $f(n) > c$. Hence there is no uniform constant bound over all $n$, and this does not prove **APX** membership.\n\nC. Bound $f(n) = 2 + \\sin(n)$. For all $n$, $-1 \\le \\sin(n) \\le 1$, so $1 \\le f(n) \\le 3$. Hence $f(n) \\le 3$ for all $n$. Choosing $c = 3$ yields a constant bound $c>1$, proving **APX** membership.\n\nD. Bound $f(n) = 1 + \\ln(\\ln(n))$ for $n > e$. Since $\\lim_{n \\to \\infty} \\ln(\\ln(n)) = \\infty$, $f(n)$ is unbounded above. Therefore, no finite constant $c$ bounds $f(n)$ for all sufficiently large $n$, and this does not prove **APX** membership.\n\nE. Bound $f(n) = 1.0001$. This is a constant bound independent of $n$, so choosing $c = 1.0001$ gives $\\rho(I) \\le c$ for all $n$, with $c>1$, proving **APX** membership.\n\nTherefore, the sufficient options are A, C, and E.", "answer": "$$\\boxed{ACE}$$", "id": "1426604"}]}