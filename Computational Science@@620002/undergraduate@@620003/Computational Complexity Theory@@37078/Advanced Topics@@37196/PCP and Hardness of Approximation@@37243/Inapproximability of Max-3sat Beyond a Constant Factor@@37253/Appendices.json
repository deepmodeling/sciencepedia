{"hands_on_practices": [{"introduction": "The study of MAX-3SAT reveals a fascinating and sharp threshold in computational complexity. A remarkably simple randomized algorithm can satisfy an expected fraction of $\\frac{7}{8}$ of all clauses, a result that holds for any instance. The celebrated PCP theorem provides a stunning counterpart: it is NP-hard to achieve a better approximation ratio than $7/8 + \\epsilon$ for any $\\epsilon > 0$. This exercise invites you to explore the \"easy\" side of this boundary by analyzing this simple algorithm, providing the crucial context for why the $\\frac{7}{8}$ value is the fundamental limit for this classic problem.", "problem": "The Maximum 3-Satisfiability (MAX-3-SAT) problem asks to find a truth assignment that satisfies the maximum number of clauses in a given 3-Conjunctive Normal Form (3-CNF) formula. A 3-CNF formula is a conjunction of clauses, where each clause is a disjunction (OR) of three distinct literals (a variable like $x_i$ or its negation $\\neg x_i$).\n\nAn algorithm for MAX-3-SAT has an approximation ratio of $\\alpha$ (where $0 \\le \\alpha \\le 1$) if it always finds an assignment satisfying a number of clauses $V_{alg}$ such that $V_{alg} \\geq \\alpha \\cdot V_{opt}$, where $V_{opt}$ is the number of clauses satisfied in an optimal assignment. A fundamental result in computational complexity, derived from the Probabilistically Checkable Proofs (PCP) theorem, states that assuming P $\\neq$ NP, it is NP-hard to approximate MAX-3-SAT with an approximation ratio $\\alpha > 7/8$.\n\nNow, consider a very simple randomized algorithm: for each variable, independently set it to TRUE with probability 1/2 and to FALSE with probability 1/2. By calculating the expected fraction of clauses satisfied by this random assignment, choose the option that best explains the significance of the 7/8 value in the context of the inapproximability result.\n\nA. The random algorithm satisfies an expected fraction of 7/8 of the clauses. This demonstrates that there is a polynomial-time algorithm providing a 7/8-approximation. The inapproximability result complements this by showing that doing any better is NP-hard.\nB. The random algorithm satisfies an expected fraction of 1/2 of the clauses. The 7/8 in the hardness result is therefore unrelated and arises from complex properties of error-correcting codes used in the PCP theorem proof.\nC. The random algorithm satisfies an expected fraction of 1/8 of the clauses, which is very poor. This is consistent with the problem being hard to approximate, but doesn't explain the 7/8 threshold.\nD. The random algorithm can be shown to satisfy all clauses if the formula is satisfiable. This contradicts the NP-hardness of SAT and proves P=NP, rendering the approximation question moot.\nE. The random algorithm's performance is exactly 7/8, while the hardness result is for ratios strictly greater than 7/8. This small gap implies that our understanding of MAX-3-SAT is incomplete and there might be a polynomial-time algorithm that achieves a ratio between 7/8 and 1.", "solution": "Consider any clause $C$ with three distinct literals, $C=(\\ell_{1} \\lor \\ell_{2} \\lor \\ell_{3})$. Under the randomized algorithm, each variable is independently set to TRUE with probability $\\frac{1}{2}$ and to FALSE with probability $\\frac{1}{2}$. For any literal $\\ell$, whether it is a variable $x$ or its negation $\\neg x$, the probability that $\\ell$ evaluates to FALSE is $\\frac{1}{2}$, because $P[x=\\text{FALSE}]=\\frac{1}{2}$ and $P[\\neg x=\\text{FALSE}]=P[x=\\text{TRUE}]=\\frac{1}{2}$. Since the three literals are on distinct variables, these events are independent. Therefore, the probability that all three literals are FALSE is\n$$\nP[\\ell_{1}=\\text{FALSE},\\ \\ell_{2}=\\text{FALSE},\\ \\ell_{3}=\\text{FALSE}]=\\left(\\frac{1}{2}\\right)^{3}=\\frac{1}{8}.\n$$\nHence, the probability that the clause is satisfied is the complement:\n$$\nP[C\\ \\text{is satisfied}]=1-\\frac{1}{8}=\\frac{7}{8}.\n$$\nLet there be $m$ clauses, and let $X_{i}$ be the indicator that clause $i$ is satisfied. By linearity of expectation,\n$$\n\\mathbb{E}\\left[\\sum_{i=1}^{m} X_{i}\\right]=\\sum_{i=1}^{m} \\mathbb{E}[X_{i}]=\\sum_{i=1}^{m} P[X_{i}=1]=m \\cdot \\frac{7}{8}.\n$$\nTherefore, the expected fraction of satisfied clauses is $\\frac{7}{8}$. Since $V_{opt} \\leq m$, the expected guarantee satisfies\n$$\n\\mathbb{E}[V_{alg}] = \\frac{7}{8} m \\geq \\frac{7}{8} V_{opt},\n$$\nso this randomized algorithm achieves an expected $\\frac{7}{8}$-approximation, and by the method of conditional expectations it can be derandomized to a deterministic $\\frac{7}{8}$-approximation. The PCP-based hardness result stating that approximating MAX-3-SAT with any ratio $\\alpha > \\frac{7}{8}$ is NP-hard precisely complements this, showing that improving on $\\frac{7}{8}$ is NP-hard. Thus, the significance of $\\frac{7}{8}$ is that it is both achieved by a simple polynomial-time algorithm and is a threshold beyond which approximation becomes NP-hard. The correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1428198"}, {"introduction": "While a random assignment provides a strong expected performance guarantee for MAX-3SAT, in practice we need deterministic algorithms that deliver a concrete solution.[@problem_id:1428198] This practice problem demonstrates how to transform a probabilistic argument into a step-by-step deterministic procedure using the method of conditional expectations. By calculating the expected outcome of fixing one variable at a time, you will manually execute the first step of an algorithm guaranteed to match the $\\frac{7}{8}$ approximation ratio, turning an abstract concept into a tangible problem-solving skill.", "problem": "The Maximum 3-Satisfiability (MAX-3SAT) problem asks to find a truth assignment for a set of boolean variables to maximize the number of satisfied clauses in a given 3-Conjunctive Normal Form (3-CNF) formula. A 3-CNF formula is a collection of clauses joined by AND operators ($\\land$), where each clause consists of exactly three literals joined by OR operators ($\\lor$), and a literal is either a variable or its negation.\n\nConsider a simple randomized algorithm for this problem: for each variable, assign it the value `true` with probability 0.5 and `false` with probability 0.5, independently of all other variables. This algorithm is known to satisfy, in expectation, $7/8$ of the total clauses.\n\nWe can devise a deterministic procedure that achieves at least this performance. The procedure assigns truth values to the variables $x_1, x_2, \\ldots, x_n$ in order. For the first variable $x_1$, it computes the expected total number of satisfied clauses under two scenarios: once assuming $x_1$ is set to `true` and once assuming $x_1$ is set to `false`. In both scenarios, the remaining variables $x_2, \\ldots, x_n$ are still considered random (i.e., assigned `true` or `false` with probability 0.5 each). The procedure then permanently sets $x_1$ to the value that yields the greater expected number of satisfied clauses. In case of a tie, the variable is set to `true`. This process is then repeated for $x_2$, conditioned on the value chosen for $x_1$, and so on for all variables.\n\nGiven the following 3-CNF formula $\\phi$ with four variables and four clauses:\n$$ \\phi = (x_1 \\lor x_2 \\lor \\neg x_3) \\land (\\neg x_1 \\lor \\neg x_2 \\lor x_4) \\land (x_1 \\lor \\neg x_3 \\lor \\neg x_4) \\land (\\neg x_1 \\lor x_2 \\lor x_3) $$\n\nAccording to the first step of the deterministic procedure described, which of the following statements is correct?\n\nA. $x_1$ is set to `true`, and the new expected number of satisfied clauses is 3.25.\nB. $x_1$ is set to `true`, and the new expected number of satisfied clauses is 3.5.\nC. $x_1$ is set to `false`, and the new expected number of satisfied clauses is 3.25.\nD. $x_1$ is set to `false`, and the new expected number of satisfied clauses is 3.5.\nE. The procedure cannot determine the value for $x_1$ in the first step.", "solution": "The problem asks us to determine the setting for the variable $x_1$ and the resulting expected number of satisfied clauses by applying the first step of a deterministic procedure. This procedure is an application of the method of conditional expectations.\n\nLet the four clauses be denoted as:\n$C_1 = x_1 \\lor x_2 \\lor \\neg x_3$\n$C_2 = \\neg x_1 \\lor \\neg x_2 \\lor x_4$\n$C_3 = x_1 \\lor \\neg x_3 \\lor \\neg x_4$\n$C_4 = \\neg x_1 \\lor x_2 \\lor x_3$\n\nLet $S$ be the random variable representing the total number of satisfied clauses. We want to compute the conditional expectations $E[S | x_1=\\text{true}]$ and $E[S | x_1=\\text{false}]$. The remaining variables $x_2, x_3, x_4$ are assumed to be random, each taking the value `true` or `false` with a probability of $0.5$.\n\nBy the linearity of expectation, the expected number of satisfied clauses is the sum of the probabilities that each clause is satisfied. Let $S_i$ be an indicator variable which is 1 if clause $C_i$ is satisfied and 0 otherwise. Then $S = S_1 + S_2 + S_3 + S_4$, and $E[S | \\cdot] = \\sum_{i=1}^4 E[S_i | \\cdot] = \\sum_{i=1}^4 P(C_i \\text{ is satisfied } | \\cdot)$.\n\nFirst, let's calculate the expected number of satisfied clauses given that $x_1$ is set to `true`.\n$E[S | x_1=\\text{true}] = \\sum_{i=1}^4 P(C_i \\text{ is satisfied } | x_1=\\text{true})$\n\n-   For $C_1 = x_1 \\lor x_2 \\lor \\neg x_3$: Since $x_1$ is true, this clause is satisfied regardless of the values of $x_2$ and $x_3$. So, $P(C_1 \\text{ is satisfied } | x_1=\\text{true}) = 1$.\n-   For $C_2 = \\neg x_1 \\lor \\neg x_2 \\lor x_4$: With $x_1=\\text{true}$, this clause becomes $\\text{false} \\lor \\neg x_2 \\lor x_4$, which simplifies to $\\neg x_2 \\lor x_4$. This clause is unsatisfied only if both $\\neg x_2$ and $x_4$ are false, which means $x_2=\\text{true}$ and $x_4=\\text{false}$. Since $x_2$ and $x_4$ are independent random variables, the probability of this event is $P(x_2=\\text{true}) \\times P(x_4=\\text{false}) = (1/2) \\times (1/2) = 1/4$. The probability that the clause is satisfied is $1 - 1/4 = 3/4$.\n-   For $C_3 = x_1 \\lor \\neg x_3 \\lor \\neg x_4$: Since $x_1$ is true, this clause is satisfied. So, $P(C_3 \\text{ is satisfied } | x_1=\\text{true}) = 1$.\n-   For $C_4 = \\neg x_1 \\lor x_2 \\lor x_3$: With $x_1=\\text{true}$, this clause becomes $\\text{false} \\lor x_2 \\lor x_3$, which simplifies to $x_2 \\lor x_3$. This clause is unsatisfied only if both $x_2$ and $x_3$ are false. The probability of this is $P(x_2=\\text{false}) \\times P(x_3=\\text{false}) = (1/2) \\times (1/2) = 1/4$. The probability that the clause is satisfied is $1 - 1/4 = 3/4$.\n\nSumming these probabilities gives the total expected number of satisfied clauses:\n$$E[S | x_1=\\text{true}] = 1 + \\frac{3}{4} + 1 + \\frac{3}{4} = 2 + \\frac{6}{4} = 2 + 1.5 = 3.5.$$\n\nNext, let's calculate the expected number of satisfied clauses given that $x_1$ is set to `false`.\n$E[S | x_1=\\text{false}] = \\sum_{i=1}^4 P(C_i \\text{ is satisfied } | x_1=\\text{false})$\n\n-   For $C_1 = x_1 \\lor x_2 \\lor \\neg x_3$: With $x_1=\\text{false}$, this clause becomes $x_2 \\lor \\neg x_3$. This is unsatisfied if $x_2=\\text{false}$ and $\\neg x_3=\\text{false}$ (i.e., $x_3=\\text{true}$). The probability is $(1/2) \\times (1/2) = 1/4$. The probability of being satisfied is $1 - 1/4 = 3/4$.\n-   For $C_2 = \\neg x_1 \\lor \\neg x_2 \\lor x_4$: Since $x_1=\\text{false}$, $\\neg x_1$ is true, so this clause is satisfied. $P(C_2 \\text{ is satisfied } | x_1=\\text{false}) = 1$.\n-   For $C_3 = x_1 \\lor \\neg x_3 \\lor \\neg x_4$: With $x_1=\\text{false}$, this clause becomes $\\neg x_3 \\lor \\neg x_4$. This is unsatisfied if $\\neg x_3=\\text{false}$ and $\\neg x_4=\\text{false}$ (i.e., $x_3=\\text{true}$ and $x_4=\\text{true}$). The probability is $(1/2) \\times (1/2) = 1/4$. The probability of being satisfied is $1 - 1/4 = 3/4$.\n-   For $C_4 = \\neg x_1 \\lor x_2 \\lor x_3$: Since $x_1=\\text{false}$, $\\neg x_1$ is true, so this clause is satisfied. $P(C_4 \\text{ is satisfied } | x_1=\\text{false}) = 1$.\n\nSumming these probabilities gives the total expected number of satisfied clauses:\n$$E[S | x_1=\\text{false}] = \\frac{3}{4} + 1 + \\frac{3}{4} + 1 = 2 + \\frac{6}{4} = 2 + 1.5 = 3.5.$$\n\nWe have $E[S | x_1=\\text{true}] = 3.5$ and $E[S | x_1=\\text{false}] = 3.5$. The expected values are equal. The problem states that \"In case of a tie, the variable is set to `true`.\" Therefore, the procedure sets $x_1$ to `true`. The resulting expected number of satisfied clauses, upon which the rest of the assignments will be conditioned, is 3.5.\n\nThis corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1428172"}, {"introduction": "The hardness of approximating MAX-3SAT [@problem_id:1428198] is not an isolated fact but a direct consequence of the deep results of the PCP theorem, which connects NP-completeness to proof verification. This exercise demystifies this profound connection by modeling the reduction from a PCP verifier to a MAX-3SAT instance. By working with a hypothetical verifier with imperfect parameters, you will calculate the precise inapproximability \"gap\" that results, gaining a hands-on understanding of how the properties of a PCP system translate directly into the computational hardness of an optimization problem.", "problem": "In computational complexity theory, the Probabilistically Checkable Proof (PCP) theorem is a cornerstone for proving hardness of approximation results. The standard version of the theorem, equivalent to the statement $NP = \\text{PCP}(\\log n, 1)$, leads to the famous inapproximability result for the Maximum 3-Satisfiability (MAX-3SAT) problem. It establishes that it is NP-hard to distinguish between a 3-conjunctive normal form (3-CNF) formula that is fully satisfiable and one where at most a fraction $7/8 + \\epsilon$ of clauses can be satisfied for any $\\epsilon > 0$.\n\nThis result is derived via a reduction from a language in NP to MAX-3SAT. This reduction converts a PCP verifier into a 3-CNF formula. A common construction based on a 3-bit query verifier works as follows: for each possible random string of the verifier, a small block of 8 distinct 3-CNF clauses is generated. If the verifier's local test on the 3 queried bits passes, all 8 clauses in that block can be satisfied. If the test fails, any assignment can satisfy at most 7 of the 8 clauses.\n\nThe standard PCP verifier has perfect completeness (acceptance probability $c=1$ for YES instances) and soundness $s  1$ (e.g., $s=1/2$ for NO instances).\n\nNow, consider a hypothetical, weaker PCP system characterized by the following parameters:\n-   **Completeness, $c$**: For any YES instance, there exists a proof that the verifier accepts with a probability of exactly $c = 0.9$.\n-   **Soundness, $s$**: For any NO instance, any proof will cause the verifier to accept with a probability of at most $s = 0.5$.\n\nAssume we apply the same reduction described above to this hypothetical PCP system. This process creates a gap for MAX-3SAT, making it NP-hard to distinguish between instances where at least a fraction $G_c$ of clauses are satisfiable, and instances where at most a fraction $G_s$ of clauses are satisfiable.\n\nDetermine the pair of values $(G_c, G_s)$ that represents this new inapproximability gap.\n\nA. (0.9000, 0.5000)\nB. (0.9875, 0.9375)\nC. (1.0000, 0.9375)\nD. (0.9125, 0.5625)\nE. (0.8875, 0.9375)", "solution": "The problem asks us to determine the new inapproximability gap $(G_c, G_s)$ for MAX-3SAT based on a hypothetical PCP system with imperfect completeness. The reduction from the PCP system to a MAX-3SAT instance has specific properties: each random string for the verifier corresponds to a block of 8 clauses. If the local test passes, all 8 clauses are satisfiable. If it fails, at most 7 out of 8 are satisfiable.\n\nFirst, let's calculate the satisfiability threshold for a YES instance, which we denote as $G_c$.\nA YES instance corresponds to the completeness case of the PCP system. By definition, for a YES instance, there exists a proof such that the verifier accepts with probability $c=0.9$. The verifier's acceptance probability is the fraction of random strings that lead to an accepting local test.\n- A fraction $c$ of the clause blocks correspond to accepting tests. For these blocks, all 8 out of 8 clauses can be satisfied. The contribution to the total fraction of satisfied clauses is $c \\times \\frac{8}{8} = c \\times 1$.\n- The remaining fraction, $1-c$, of the clause blocks correspond to rejecting tests. For these blocks, at most 7 out of 8 clauses can be satisfied. The contribution from these blocks is $(1-c) \\times \\frac{7}{8}$.\n\nTherefore, the maximum fraction of satisfiable clauses in a YES instance, $G_c$, is the sum of these contributions:\n$$G_c = c \\cdot 1 + (1-c) \\cdot \\frac{7}{8}$$\nSubstituting the given value $c = 0.9$:\n$$G_c = 0.9 + (1 - 0.9) \\cdot \\frac{7}{8}$$\n$$G_c = 0.9 + 0.1 \\cdot 0.875$$\n$$G_c = 0.9 + 0.0875 = 0.9875$$\n\nNext, let's calculate the satisfiability threshold for a NO instance, which we denote as $G_s$.\nA NO instance corresponds to the soundness case of the PCP system. For any NO instance, and for any purported proof, the verifier accepts with a probability of at most $s=0.5$. To find the upper bound on the fraction of satisfiable clauses, we consider the worst-case scenario for distinguishing, which is the best-case scenario for an adversary trying to satisfy as many clauses as possible. This occurs when the acceptance probability is exactly $s$.\n- At most a fraction $s$ of the clause blocks correspond to accepting tests. These blocks can be fully satisfied, contributing $s \\times \\frac{8}{8} = s \\times 1$ to the total fraction of satisfiable clauses.\n- The remaining fraction, $1-s$, of the clause blocks correspond to rejecting tests, where at most 7 out of 8 clauses can be satisfied. These contribute $(1-s) \\times \\frac{7}{8}$ to the total fraction.\n\nTherefore, the maximum fraction of satisfiable clauses in a NO instance, $G_s$, is:\n$$G_s = s \\cdot 1 + (1-s) \\cdot \\frac{7}{8}$$\nSubstituting the given value $s = 0.5$:\n$$G_s = 0.5 + (1 - 0.5) \\cdot \\frac{7}{8}$$\n$$G_s = 0.5 + 0.5 \\cdot 0.875$$\n$$G_s = 0.5 + 0.4375 = 0.9375$$\n\nSo, the new inapproximability gap is defined by the pair $(G_c, G_s) = (0.9875, 0.9375)$. This means it is NP-hard to distinguish between 3-CNF formulas where at least 98.75% of clauses are satisfiable and those where at most 93.75% of clauses are satisfiable.\n\nComparing our result with the given choices:\nA. (0.9000, 0.5000) - This incorrectly assumes the gap is just $(c, s)$.\nB. (0.9875, 0.9375) - This matches our calculation.\nC. (1.0000, 0.9375) - This correctly calculates $G_s$ but incorrectly assumes perfect completeness ($c=1$).\nD. (0.9125, 0.5625) - This would result from using $1/8$ instead of $7/8$ for the fraction of satisfied clauses in failing blocks.\nE. (0.8875, 0.9375) - This correctly calculates $G_s$ but makes an error in calculating $G_c$.\n\nThe correct option is B.", "answer": "$$\\boxed{B}$$", "id": "1428181"}]}