{"hands_on_practices": [{"introduction": "The heart of a Las Vegas algorithm, which defines the class ZPP, is its variable running time. We can model this by considering a series of independent attempts, each with a certain probability of success. This first exercise invites you to apply a fundamental concept from probability theory—the geometric distribution—to calculate the expected number of attempts needed for success, forming the basis for analyzing the efficiency of any ZPP algorithm [@problem_id:1455277].", "problem": "The complexity class ZPP (Zero-error Probabilistic Polynomial time) is characterized by problems that can be solved by a Las Vegas algorithm. A Las Vegas algorithm is a randomized algorithm that always returns a correct answer if it provides one, but its running time varies and is treated as a random variable. The algorithm is considered efficient if its expected running time is polynomial in the input size.\n\nConsider a novel Las Vegas algorithm designed to locate a unique 'sentinel' element within an unsorted array of $n$ distinct elements. The algorithm works by making a series of discrete, independent attempts. In each attempt, it performs a check. If the check is successful, it immediately finds the sentinel element and halts. If the check is unsuccessful, it discards the attempt and begins a new one. The properties of the data and the checking procedure are such that the probability of success for any single attempt is given by $p = \\frac{1}{\\alpha n + \\beta}$, where $n$ is the number of elements in the array, and $\\alpha$ and $\\beta$ are positive real constants inherent to the algorithm's design.\n\nDetermine the expected number of attempts the algorithm will make before it finds the sentinel element and halts. Express your answer as a function of $n$, $\\alpha$, and $\\beta$.", "solution": "Let $X$ be the random variable representing the number of attempts required for the algorithm to succeed. The problem describes a sequence of independent trials, each with a constant probability of success $p$. The first success occurs on the $k$-th trial if and only if the first $k-1$ trials are failures and the $k$-th trial is a success. This is the definition of a geometric distribution.\n\nThe probability of success for a single attempt is given as $p = \\frac{1}{\\alpha n + \\beta}$.\nThe probability of failure for a single attempt is $1-p$.\n\nThe probability that the algorithm succeeds on the $k$-th attempt, denoted by $P(X=k)$, is the probability of having $k-1$ failures followed by one success. Since the attempts are independent, we can write:\n$$ P(X=k) = (1-p)^{k-1} p $$\nThis is the probability mass function for a geometric distribution, where $k$ can be any integer from $1, 2, 3, \\dots$.\n\nThe expected number of attempts, $E[X]$, is the expected value of this distribution. By definition, the expected value of a discrete random variable is the sum of the product of each possible value and its probability:\n$$ E[X] = \\sum_{k=1}^{\\infty} k \\cdot P(X=k) $$\nSubstituting the expression for $P(X=k)$, we get:\n$$ E[X] = \\sum_{k=1}^{\\infty} k (1-p)^{k-1} p $$\nWe can factor out the constant $p$ from the summation:\n$$ E[X] = p \\sum_{k=1}^{\\infty} k (1-p)^{k-1} $$\nThe summation is a well-known result from the analysis of geometric series. The geometric series is given by $\\sum_{k=0}^{\\infty} x^k = \\frac{1}{1-x}$ for $|x|<1$. Differentiating this with respect to $x$ gives:\n$$ \\frac{d}{dx} \\left( \\sum_{k=0}^{\\infty} x^k \\right) = \\sum_{k=1}^{\\infty} k x^{k-1} = \\frac{d}{dx} \\left( \\frac{1}{1-x} \\right) = \\frac{1}{(1-x)^2} $$\nLet $x = 1-p$. Since $p$ is a probability and $n, \\alpha, \\beta$ are positive, we have $0 < p < 1$, which implies $0 < 1-p < 1$, so the series converges. Substituting $x = 1-p$ into the derivative formula, we find the value of our summation:\n$$ \\sum_{k=1}^{\\infty} k (1-p)^{k-1} = \\frac{1}{(1 - (1-p))^2} = \\frac{1}{p^2} $$\nNow, we substitute this result back into our expression for $E[X]$:\n$$ E[X] = p \\cdot \\left( \\frac{1}{p^2} \\right) = \\frac{1}{p} $$\nThis confirms the standard result that the expected value of a geometric distribution with success probability $p$ is $\\frac{1}{p}$.\n\nFinally, we substitute the given expression for the probability $p$:\n$$ p = \\frac{1}{\\alpha n + \\beta} $$\nTherefore, the expected number of attempts is:\n$$ E[X] = \\frac{1}{\\frac{1}{\\alpha n + \\beta}} = \\alpha n + \\beta $$", "answer": "$$\\boxed{\\alpha n + \\beta}$$", "id": "1455277"}, {"introduction": "While expected polynomial time is a key feature of ZPP, the \"Zero-Error\" aspect is what truly defines it. An algorithm can run quickly on average, but if it can produce a verifiably wrong answer, it does not belong in ZPP. This practice challenges you to analyze an algorithm that exhibits a one-sided error and articulate precisely why it fails to meet the strict definitional requirements of ZPP, thereby clarifying the crucial distinction between zero-error and bounded-error probabilistic classes [@problem_id:1455254].", "problem": "A systems engineer develops a new probabilistic algorithm, `NetCheck`, designed to determine if a computer network is fully connected. A network is represented as a graph where computers are vertices and direct links are edges. `NetCheck` runs in polynomial time with respect to the number of vertices in the network. The algorithm is tested extensively with the following consistent results:\n\n1.  If the input network graph is connected, `NetCheck` always outputs \"CONNECTED\".\n2.  If the input network graph is disconnected, `NetCheck` outputs \"CONNECTED\" with a probability of $1/3$ and \"DISCONNECTED\" with a probability of $2/3$.\n\nThe complexity class Zero-error Probabilistic Polynomial-time (ZPP) is defined for decision problems. A problem is in ZPP if there exists a probabilistic algorithm that is allowed to return a \"FAIL\" answer (i.e., \"I don't know\") with a probability of at most $1/2$, but must always be correct whenever it returns a \"YES\" or \"NO\" answer. Furthermore, a ZPP algorithm must have an expected running time that is polynomial in the size of the input.\n\nBased on the behavior of `NetCheck` and the definition of a ZPP algorithm, which of the following statements provides the most accurate reason why the problem of network connectivity, as decided by the `NetCheck` algorithm, is not in the class ZPP?\n\nA. The algorithm's probability of error for disconnected networks ($1/3$) is not less than or equal to an arbitrarily small constant.\nB. The algorithm only exhibits one-sided error, whereas a ZPP algorithm must be capable of error on both \"YES\" and \"NO\" instances.\nC. The algorithm can produce an incorrect \"YES\" or \"NO\" answer, which is forbidden for a ZPP algorithm.\nD. The algorithm's running time is only polynomial on average, not in the worst case.\nE. The algorithm never returns a \"FAIL\" answer, which is a required possible output for any non-deterministic ZPP algorithm.", "solution": "We formalize the decision problem as language membership: let $L$ be the set of connected graphs, where the correct output is \"YES\" for $x \\in L$ and \"NO\" for $x \\notin L$.\n\nBy specification, the probabilistic algorithm NetCheck satisfies:\n- For all $x \\in L$ (connected graphs), it outputs YES with probability $1$ and NO with probability $0$.\n- For all $x \\notin L$ (disconnected graphs), it outputs YES with probability $\\frac{1}{3}$ and NO with probability $\\frac{2}{3}$.\n\nA ZPP algorithm for a decision problem must satisfy the zero-error property: it may output a special symbol (call it FAIL), but whenever it outputs YES or NO, that answer must be correct. Formally, letting $A$ be a ZPP algorithm, for every input $x$ we have:\n- $\\Pr[A(x) = \\text{FAIL}] \\leq \\frac{1}{2}$,\n- $\\Pr[A(x) = \\text{YES} \\mid A(x) \\neq \\text{FAIL}] = 1$ if and only if $x \\in L$,\n- $\\Pr[A(x) = \\text{NO} \\mid A(x) \\neq \\text{FAIL}] = 1$ if and only if $x \\notin L$,\nand the expected running time is polynomial in the input size.\n\nNetCheck violates the zero-error requirement because there exists $x \\notin L$ such that it outputs YES with positive probability $\\frac{1}{3}$. That is, NetCheck can produce an incorrect YES on NO instances. Therefore, regardless of its runtime, NetCheck is not a ZPP algorithm.\n\nWe now evaluate the options:\n- A is incorrect because ZPP requires zero error on YES/NO outputs, not merely a small error probability; moreover, error reduction by repetition is irrelevant to ZPP’s zero-error criterion.\n- B is incorrect because ZPP does not require two-sided error; it requires zero error on definitive answers.\n- C is correct: NetCheck can output an incorrect YES, which is forbidden for ZPP algorithms.\n- D is incorrect because ZPP requires expected polynomial time, not worst-case polynomial time; NetCheck’s time bound is not the issue here.\n- E is incorrect because a ZPP algorithm is allowed to return FAIL but is not required to; absence of FAIL does not preclude ZPP as long as there is zero error, which NetCheck does not have.\n\nHence the most accurate reason is that NetCheck can produce an incorrect YES or NO answer, violating the zero-error requirement of ZPP.", "answer": "$$\\boxed{C}$$", "id": "1455254"}, {"introduction": "A hallmark of robust complexity classes is that they are often \"closed\" under certain operations, meaning you can combine algorithms from the class to solve new, more complex problems that also fall within the same class. This final practice is a constructive challenge: you will design a ZPP algorithm for the concatenation of two languages, given ZPP algorithms for each individual language. By building this new algorithm and analyzing its expected runtime, you will gain hands-on experience with closure properties, a cornerstone of computational complexity theory [@problem_id:1455255].", "problem": "In computational complexity theory, the class ZPP, which stands for Zero-error Probabilistic Polynomial time, represents problems solvable by a probabilistic algorithm that is always correct and runs in expected polynomial time. A ZPP algorithm for a decision problem can output 'yes', 'no', or 'unknown' (often denoted as '?'). It is characterized by two key properties:\n1.  It never returns an incorrect answer (i.e., if the true answer is 'yes', it never outputs 'no', and vice-versa).\n2.  For any given input, the probability of it returning 'unknown' is at most $1/2$.\n\nConsider two languages, $L_1$ and $L_2$, over a common alphabet. You are provided with two ZPP algorithms, $A_1$ and $A_2$, which decide membership in $L_1$ and $L_2$, respectively. For an input of length $k$, the expected running time of $A_1$ is given by $T_1(k) = C_1 k^{a_1}$, and the expected running time of $A_2$ is given by $T_2(k) = C_2 k^{a_2}$. Here, $C_1, C_2, a_1,$ and $a_2$ are given positive real constants.\n\nYour task is to design a new ZPP algorithm, $A_{cat}$, that decides membership in the concatenation language $L_{cat} = L_1 L_2 = \\{uv \\mid u \\in L_1 \\text{ and } v \\in L_2\\}$. Determine the tightest possible polynomial upper bound for the worst-case expected running time of your algorithm $A_{cat}$ on an input string of length $n$. For simplicity in the final derivation, you may approximate any sum of the form $\\sum_{i=0}^{n} g(i)$ with the integral $\\int_0^n g(x) dx$. Express your answer as a symbolic expression in terms of $n, C_1, C_2, a_1$, and $a_2$.", "solution": "We are given ZPP algorithms $A_1$ and $A_2$ for the languages $L_1$ and $L_2$. A ZPP algorithm is a Las Vegas algorithm, meaning it always produces a correct answer, and its expected running time is polynomial. The problem states that the expected running time for $A_1$ on an input of length $k$ is $T_1(k) = C_1 k^{a_1}$, and for $A_2$ it is $T_2(k) = C_2 k^{a_2}$. This expected time already accounts for any internal repetitions required to obtain a definitive answer.\n\nWe design $A_{cat}$ as follows. On an input string $x$ of length $n$, we iterate through all possible split points $i \\in \\{0, 1, \\dots, n\\}$. For each split, we define two substrings, a prefix $u = x[1..i]$ and a suffix $v = x[i+1..n]$.\n- First, we run algorithm $A_1$ on $u$. If $A_1$ returns NO, this split is invalid, and we continue to the next split point $i+1$.\n- If $A_1$ returns YES, we then run algorithm $A_2$ on $v$. If $A_2$ also returns YES, we have found a valid partition. The algorithm halts and accepts the input string $x$. If $A_2$ returns NO, we continue to the next split point.\nIf the algorithm tries all $n+1$ possible splits and none result in acceptance, it halts and rejects the input string $x$. This algorithm is a ZPP algorithm because it is always correct and, as we will show, has an expected polynomial runtime.\n\nTo determine the worst-case expected running time, we consider an input $x$ that is *not* in $L_{cat}$. This forces the algorithm to check every possible split. For a fixed split $i$, the worst case involves running both $A_1$ on $u$ (length $i$) and $A_2$ on $v$ (length $n-i$). By linearity of expectation, the expected time for checking split $i$ is the sum of the expected times for its sub-problems, which is at most $T_1(i) + T_2(n-i)$.\n\nThe total worst-case expected running time is the sum of the expected times over all possible splits:\n$$ \\mathbb{E}[T_{cat}(n)] \\leq \\sum_{i=0}^{n} (T_1(i) + T_2(n-i)) = \\sum_{i=0}^{n} (C_1 i^{a_1} + C_2 (n-i)^{a_2}) $$\nWe can separate the sums:\n$$ \\mathbb{E}[T_{cat}(n)] \\leq C_1 \\sum_{i=0}^{n} i^{a_1} + C_2 \\sum_{i=0}^{n} (n-i)^{a_2} $$\nThe second summation, $\\sum_{i=0}^{n} (n-i)^{a_2}$, is equivalent to $\\sum_{j=0}^{n} j^{a_2}$ by a change of index $j = n-i$.\n\nUsing the suggested approximation of the sum by an integral for a tight polynomial bound:\n$$ \\sum_{k=0}^{n} k^a \\approx \\int_0^n x^a \\,dx = \\frac{n^{a+1}}{a+1} $$\nApplying this approximation to both sums in our expression for the expected time:\n$$ \\mathbb{E}[T_{cat}(n)] \\lesssim \\frac{C_1}{a_1+1} n^{a_1+1} + \\frac{C_2}{a_2+1} n^{a_2+1} $$\nThis expression represents the tightest possible polynomial upper bound for the worst-case expected running time of our algorithm $A_{cat}$.", "answer": "$$\\boxed{\\frac{C_{1}}{a_{1}+1}\\,n^{a_{1}+1}+\\frac{C_{2}}{a_{2}+1}\\,n^{a_{2}+1}}$$", "id": "1455255"}]}