{"hands_on_practices": [{"introduction": "The definition of BPP hinges on a crucial detail: a guaranteed \"gap\" in probabilities between accepting strings in the language and those not in it. This exercise probes your understanding of this core requirement by presenting a hypothetical machine that seems powerful but may lack this essential property. By analyzing it, you will solidify your grasp of what truly qualifies a problem for inclusion in BPP, moving beyond simple high-probability acceptance [@problem_id:1450963].", "problem": "Consider a language $L$. Suppose there exists a polynomial-time Probabilistic Turing Machine (PTM), $M$, with the following characteristics for any input string $w$:\n1. If $w \\in L$, the probability that $M$ accepts $w$ is at least $0.9$.\n2. If $w \\notin L$, the probability that $M$ rejects $w$ is at least $0.1$.\n\nDoes the existence of such a machine $M$ necessarily imply that the language $L$ is in the complexity class BPP (Bounded-error Probabilistic Polynomial time)? Select the best reasoning.\n\nA. Yes, because amplification can be used to decrease the error probability to any desired amount, which is the defining feature of BPP.\nB. No, because the rejection probability for strings not in $L$ is far too low. BPP requires a much higher rejection probability for 'no' instances.\nC. Yes, because the acceptance probability for strings in $L$ is $0.9$, which is greater than the standard BPP threshold of $2/3$.\nD. No, because there is no guaranteed gap between the acceptance probability for a string in $L$ and the acceptance probability for a string not in $L$.\nE. It is impossible to determine without knowing the specific polynomial that bounds the runtime of $M$.", "solution": "Let $L$ be a language and let $M$ be a polynomial-time probabilistic Turing machine with the stated properties. Write, for any input $w$,\n$$\np_{\\text{yes}}(w) := \\Pr[M \\text{ accepts } w \\mid w \\in L], \\quad p_{\\text{no}}(w) := \\Pr[M \\text{ accepts } w \\mid w \\notin L].\n$$\nThe given conditions are:\n$$\nw \\in L \\implies p_{\\text{yes}}(w) \\geq 0.9, \\quad w \\notin L \\implies \\Pr[M \\text{ rejects } w] \\geq 0.1 \\iff p_{\\text{no}}(w) \\leq 0.9.\n$$\nThus the only guaranteed relation between the two cases is\n$$\np_{\\text{yes}}(w) \\geq 0.9 \\quad \\text{and} \\quad p_{\\text{no}}(w) \\leq 0.9,\n$$\nwhich permits $p_{\\text{yes}}(w) = p_{\\text{no}}(w) = 0.9$ for all $w$. Hence there is no guaranteed advantage (gap) between the acceptance probabilities on yes- versus no-instances.\n\nBy definition, $L \\in \\mathrm{BPP}$ if there exists a polynomial-time PTM $N$ and a constant $\\epsilon \\in (0, \\tfrac{1}{2})$ such that for all $w$,\n$$\nw \\in L \\implies \\Pr[N \\text{ accepts } w] \\geq \\tfrac{1}{2} + \\epsilon, \\quad\nw \\notin L \\implies \\Pr[N \\text{ accepts } w] \\leq \\tfrac{1}{2} - \\epsilon.\n$$\nThe standard amplification by independent repetition and majority vote reduces error exponentially fast only when such a constant gap $\\epsilon>0$ exists. If the acceptance probabilities for yes- and no-instances can be equal (e.g., both $0.9$), then there is no bias to amplify, and repetition cannot yield a bounded-error decider.\n\nA concrete counterexample shows the issue: consider a machine $M_{0}$ that ignores its input and accepts with probability $0.9$ and rejects with probability $0.1$. For any language $L$ and any input $w$, if $w \\in L$ then $\\Pr[M_{0} \\text{ accepts } w] = 0.9 \\geq 0.9$, and if $w \\notin L$ then $\\Pr[M_{0} \\text{ rejects } w] = 0.1 \\geq 0.1$. Thus $M_{0}$ satisfies the stated properties, yet it provides no separation between yes- and no-instances and cannot be amplified into a BPP decider for $L$.\n\nTherefore, the mere existence of such an $M$ does not imply $L \\in \\mathrm{BPP}$. The correct reasoning is that there is no guaranteed gap between acceptance probabilities on yes- and no-instances.\n\nHence, the best choice is D.", "answer": "$$\\boxed{D}$$", "id": "1450963"}, {"introduction": "A defining feature of BPP is that its bounded error isn't fixed; it can be made arbitrarily small through a process called probability amplification. This practice exercise makes that abstract concept concrete by asking you to calculate the number of repetitions needed to make an algorithm more reliable than the physical hardware it runs on. It's a powerful demonstration of how randomness, when used correctly, can lead to near-certain outcomes [@problem_id:1450962].", "problem": "An algorithm in the complexity class BPP (Bounded-error Probabilistic Polynomial time) is designed to solve a decision problem. For any given input, it has a two-sided error probability, meaning it might return the wrong answer (either \"yes\" when it should be \"no\", or vice-versa) with a probability of at most $p=1/3$.\n\nTo improve the reliability of this algorithm, a standard amplification technique is employed: the algorithm is run $k$ times on the same input, and the results are aggregated. For the purpose of this problem, we define the overall procedure as having failed if the number of incorrect individual runs is at least half of the total number of runs, $k$.\n\nYour task is to determine how robust this amplification must be to outperform the physical limitations of the hardware it runs on. Calculate the minimum integer number of repetitions, $k$, required to ensure that the algorithm's overall failure probability is strictly less than the probability of a hardware error from a random high-energy particle. Assume the probability of such a hardware error during a single computation, for instance a bit-flip caused by a cosmic ray, is $P_{\\text{cosmic}} = 2.5 \\times 10^{-15}$.\n\nFor your calculation, you are provided with the following form of a Chernoff bound. Let $X_1, \\dots, X_k$ be independent indicator random variables where $P(X_i=1)=p$. Let $X = \\sum_{i=1}^k X_i$ be the sum of these variables, and let $\\mu = E[X] = kp$ be the expectation of the sum. For any $\\delta > 0$, the probability that $X$ deviates from its mean is bounded by:\n$$P(X \\ge (1+\\delta)\\mu) \\le \\exp\\left(-\\frac{\\delta^2 \\mu}{3}\\right)$$\n\nProvide your answer as the smallest integer $k$ that satisfies the condition. You may use the numerical values $\\ln(10) \\approx 2.3026$ and $\\ln(2.5) \\approx 0.9163$.", "solution": "We consider $k$ independent repetitions of the BPP algorithm. Let $X_{i}$ be the indicator of an incorrect outcome on run $i$, with $P(X_{i}=1)=p=\\frac{1}{3}$, and define $X=\\sum_{i=1}^{k}X_{i}$. Then $X \\sim \\text{Binomial}(k,p)$ and $\\mu=E[X]=kp=\\frac{k}{3}$. The overall procedure is defined to fail if at least half of the runs are incorrect, i.e., the event $\\{X \\ge \\frac{k}{2}\\}$.\n\nWe apply the given Chernoff bound. Choose $\\delta>0$ such that $(1+\\delta)\\mu=\\frac{k}{2}$. Substituting $\\mu=\\frac{k}{3}$ gives\n$$\n(1+\\delta)\\frac{k}{3}=\\frac{k}{2}\\quad\\Rightarrow\\quad 1+\\delta=\\frac{3}{2}\\quad\\Rightarrow\\quad \\delta=\\frac{1}{2}.\n$$\nThe Chernoff bound states\n$$\nP\\!\\left(X \\ge (1+\\delta)\\mu\\right) \\le \\exp\\!\\left(-\\frac{\\delta^{2}\\mu}{3}\\right).\n$$\nWith $\\delta=\\frac{1}{2}$ and $\\mu=\\frac{k}{3}$, we obtain\n$$\nP\\!\\left(X \\ge \\frac{k}{2}\\right) \\le \\exp\\!\\left(-\\frac{\\left(\\frac{1}{2}\\right)^{2}\\cdot \\frac{k}{3}}{3}\\right)=\\exp\\!\\left(-\\frac{k}{36}\\right).\n$$\n\nWe require the overall algorithmic failure probability to be strictly less than the hardware error probability $P_{\\text{cosmic}}=2.5 \\times 10^{-15}$:\n$$\n\\exp\\!\\left(-\\frac{k}{36}\\right) < 2.5 \\times 10^{-15}.\n$$\nTaking natural logarithms and solving for $k$,\n$$\n-\\frac{k}{36} < \\ln(2.5) + \\ln\\!\\left(10^{-15}\\right)=\\ln(2.5) - 15\\ln(10),\n$$\n$$\n\\frac{k}{36} > 15\\ln(10) - \\ln(2.5),\n$$\n$$\nk > 36\\bigl(15\\ln(10) - \\ln(2.5)\\bigr).\n$$\nUsing the provided approximations $\\ln(10)\\approx 2.3026$ and $\\ln(2.5)\\approx 0.9163$,\n$$\n15\\ln(10) - \\ln(2.5) \\approx 15\\cdot 2.3026 - 0.9163 = 34.539 - 0.9163 = 33.6227,\n$$\n$$\n36 \\cdot 33.6227 \\approx 1210.4172.\n$$\nSince the inequality is strict, the smallest integer $k$ satisfying it is\n$$\nk=1211.\n$$", "answer": "$$\\boxed{1211}$$", "id": "1450962"}, {"introduction": "Exploring the boundaries between complexity classes deepens our understanding of computation itself. This problem investigates the relationship between P and BPP by examining the role of randomness as a resource. You will discover that if a probabilistic algorithm uses only a logarithmic number of random bits, its power can be fully captured by a deterministic polynomial-time algorithm, effectively showing that `BPP` in this restricted form collapses to `P` [@problem_id:1450965].", "problem": "A technology startup has developed a novel probabilistic algorithm, called `PathCheck`, for a decision problem they term `DYNAMIC-PATH-VALIDITY`. The problem is to determine if a specified path in a network remains valid under a complex set of dynamically changing constraints. The precise nature of these constraints is proprietary, but the performance characteristics of the `PathCheck` algorithm are known.\n\nFor any given input instance (encoding the network and the path) of size $n$, the `PathCheck` algorithm has the following properties:\n1.  It always halts within a time bounded by the polynomial $p(n) = n^4 + 100n^2$.\n2.  It uses exactly $k(n) = 10 \\log_2(n)$ random bits to make its decision.\n3.  The algorithm has a two-sided error probability of at most $\\epsilon = 1/4$. That is, for any input, the probability that `PathCheck` returns the incorrect answer is at most $1/4$.\n\nRecall the definitions of the following complexity classes:\n- **P (Polynomial Time)**: The class of decision problems solvable by a deterministic algorithm in a number of steps that is a polynomial function of the input size $n$.\n- **BPP (Bounded-error Probabilistic Polynomial time)**: The class of decision problems solvable by a probabilistic algorithm in polynomial time, where for any input, the algorithm gives the correct answer with a probability of at least $2/3$. The constant $2/3$ can be replaced by any constant greater than $1/2$ without changing the class.\n\nBased *only* on the documented properties of the `PathCheck` algorithm, what is the strongest certain conclusion that can be drawn about the complexity class of the `DYNAMIC-PATH-VALIDITY` problem?\n\nA. `DYNAMIC-PATH-VALIDITY` is in P.\nB. `DYNAMIC-PATH-VALIDITY` is in BPP, but there is not enough information to conclude it is in P.\nC. `DYNAMIC-PATH-VALIDITY` is in NP, but there is not enough information to conclude it is in BPP.\nD. `DYNAMIC-PATH-VALIDITY` is not in BPP because its error probability of $1/4$ is not less than or equal to $1/3$.\nE. The properties of `PathCheck` are insufficient to place `DYNAMIC-PATH-VALIDITY` in any complexity class smaller than EXP (Exponential Time).", "solution": "We are given a probabilistic algorithm PathCheck for input size $n$ with the following properties:\n- Running time bounded by the polynomial $p(n) = n^{4} + 100 n^{2}$.\n- Uses exactly $k(n) = 10 \\log_{2}(n)$ random bits.\n- Two-sided error probability at most $\\epsilon = \\frac{1}{4}$ on any input.\n\nFirst, note that the total number of random bit strings (seeds) used by PathCheck on inputs of size $n$ is\n$$\nS(n) = 2^{k(n)} = 2^{10 \\log_{2}(n)} = \\left(2^{\\log_{2}(n)}\\right)^{10} = n^{10}.\n$$\nFor any fixed input $x$, the error probability bound implies that the number of seeds that cause an incorrect answer, denoted $B(x)$, satisfies\n$$\n|B(x)| \\le \\epsilon \\cdot S(n) = \\frac{1}{4} n^{10}.\n$$\nTherefore, the number of seeds that produce the correct answer, denoted $G(x)$, satisfies\n$$\n|G(x)| = S(n) - |B(x)| \\ge n^{10} - \\frac{1}{4} n^{10} = \\frac{3}{4} n^{10} > \\frac{1}{2} n^{10}.\n$$\nHence, for any input $x$, strictly more than half of all seeds yield the correct answer.\n\nConstruct a deterministic algorithm for the decision problem as follows: enumerate all $S(n) = n^{10}$ seeds $r \\in \\{0,1\\}^{k(n)}$, run PathCheck on input $x$ with randomness fixed to $r$, and take the majority output. This works because the majority of seeds yield the correct answer, so the majority vote equals the correct decision on $x$.\n\nThe running time of this deterministic simulation is at most\n$$\nT(n) \\le S(n) \\cdot p(n) = n^{10} \\left(n^{4} + 100 n^{2}\\right) = n^{14} + 100 n^{12},\n$$\nwhich is a polynomial in $n$. Therefore, there exists a deterministic polynomial-time algorithm for the problem, implying that the language is in P.\n\nAlthough the given properties also certify membership in BPP (since correctness probability $\\frac{3}{4} \\ge \\frac{2}{3}$ and runtime is polynomial), the strongest certain conclusion from the additional fact of using only $O(\\log n)$ random bits is that the problem is in P by exhaustive enumeration of all seeds within polynomial time. Thus, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1450965"}]}