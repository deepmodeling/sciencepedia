{"hands_on_practices": [{"introduction": "We begin our hands-on exploration by examining the very foundation of resource constructibility. This first practice focuses on the simplest class of functions—constants—and asks whether they are space-constructible. By analyzing the minimal resources a Turing Machine requires, you will gain a precise understanding of how space usage is formally defined and measured, revealing how even the most basic cases, like using zero or one memory cell, are critical for building a rigorous theory of computational complexity [@problem_id:1466676].", "problem": "In computational complexity theory, we analyze the resources required by algorithms, such as time and space. A function is considered \"well-behaved\" or \"constructible\" if the resources it describes can be tracked by a Turing Machine (TM) itself.\n\nFormally, a function $s: \\mathbb{N} \\to \\mathbb{N}$ is said to be **space-constructible** if there exists a multi-tape Turing Machine that, when given any input string of length $n$, halts and uses exactly $s(n)$ cells on its work tape(s). The space used is defined as the number of unique cells visited by the head(s) on the work tape(s).\n\nConsider the following two statements about constant functions:\n\n**Statement I:** The function $f(n) = k$, where $k$ is a fixed positive integer ($k \\ge 1$), is space-constructible.\n**Statement II:** The function $g(n) = 0$ is space-constructible.\n\nWhich of the following options correctly evaluates the truth of these two statements?\n\nA. Statement I is true, and Statement II is false.\nB. Statement I is false, and Statement II is true.\nC. Both Statement I and Statement II are true.\nD. Both Statement I and Statement II are false.", "solution": "We adopt the standard space-complexity model: a deterministic multi-tape Turing machine has a read-only input tape and at least one read-write work tape; the machine starts with each work-tape head positioned on a designated start cell. The space used on an input of length $n$ is the number of distinct cells on the work tape(s) that are scanned during the computation. Under this definition, scanning the starting cell already counts as visiting it.\n\nAnalysis of Statement I: Let $k \\in \\mathbb{N}$ with $k \\ge 1$ and define $f(n)=k$ for all $n \\in \\mathbb{N}$. We construct a multi-tape Turing machine $M_{k}$ that, on any input of length $n$, uses exactly $k$ work-tape cells and halts. Construction:\n1. If $k=1$, $M_{1}$ immediately halts without moving its work-tape head. Since the head starts on a designated start cell, exactly one unique work-tape cell has been visited. Thus the space used is $1=f(n)$.\n2. If $k>1$, $M_{k}$ performs the following: starting from the initial work-tape head position (which visits the first cell), it moves the head to a fresh, previously unvisited cell $k-1$ times (for example, by moving right $k-1$ steps on a blank tape), and then halts. The set of distinct visited work-tape cells has cardinality exactly $k$, independent of the input length $n$. Therefore on any input of length $n$, $M_{k}$ uses exactly $f(n)=k$ cells.\n\nThus $f(n)=k$ with $k \\ge 1$ is space-constructible, so Statement I is true.\n\nAnalysis of Statement II: Let $g(n)=0$ for all $n \\in \\mathbb{N}$. Suppose, for contradiction, that there exists a multi-tape Turing machine $M$ that, on any input of length $n$, halts and uses exactly $g(n)=0$ work-tape cells. Let $V$ denote the set of distinct work-tape cells visited during a computation. By the model’s initial configuration, at time zero the work-tape head is scanning its start cell, which counts as a visit; hence $|V| \\ge 1$ immediately. Since the head cannot avoid scanning that start cell if the work tape exists, the total number of visited work-tape cells on any halting computation is at least $1$, contradicting the requirement $|V|=0$. Therefore no such $M$ exists, and $g(n)=0$ is not space-constructible. Hence Statement II is false.\n\nCombining the two, Statement I is true and Statement II is false, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1466676"}, {"introduction": "Next, we move from the static nature of constant functions to the dynamic growth of a famous sequence. This problem provides a concrete exercise in analyzing the time-constructibility of the Fibonacci numbers. You will dissect a specific, iterative algorithm and calculate its total runtime by summing the cost of its operations, which depend on the growing bit-length of the numbers involved, a core skill in complexity analysis [@problem_id:1466665].", "problem": "In theoretical computer science, a function $T: \\mathbb{N} \\to \\mathbb{N}$ is called time-constructible if there exists a deterministic Turing machine that, given an input of $n$ ones (denoted $1^n$), halts after exactly $T(n)$ computational steps.\n\nConsider the Fibonacci sequence, defined by $F_0=0, F_1=1$, and $F_k = F_{k-1} + F_{k-2}$ for $k \\ge 2$. We are interested in the time complexity of a specific algorithm designed to compute the value of $F_n$. This algorithm could be the first phase of a machine designed to halt in a number of steps related to the value of $F_n$.\n\nThe algorithm runs on a multi-tape Turing machine that computes $F_n$ for an integer $n \\ge 3$. The machine is given the input $n$ in unary format, i.e., a string of $n$ ones ($1^n$) on a read-only input tape. The machine also has two work tapes, W1 and W2, and sufficient scratch space on other tapes for temporary storage.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: The machine writes the binary representation of $F_1=1$ onto work tape W1 and the binary representation of $F_2=1$ onto work tape W2.\n2.  **Iterative Calculation**: The machine's input head scans the input $1^n$. For each '1' from the third to the $n$-th symbol, it performs one iteration of a loop. This loop is thus indexed by $k$ from $3$ to $n$. In the $k$-th iteration, which computes $F_k$, the machine performs these operations:\n    a. Let $A$ be the number on W1 (which is $F_{k-2}$) and $B$ be the number on W2 (which is $F_{k-1}$).\n    b. A temporary copy of $A$ is made to a scratch tape.\n    c. The value of $B$ is copied to W1, overwriting its previous content.\n    d. The value from the temporary copy of $A$ and the value $B$ (which is now on W1) are added. The sum $S = A + B = F_k$ is computed and the result is stored on W2, overwriting its previous content.\n\nThe time cost of these operations depends on the number of bits in the operands. Let $|X|$ denote the number of bits in the binary representation of a positive integer $X$.\n- The cost of copying a number $X$ from one tape to another is $c_{\\text{copy}}|X|$.\n- The cost of adding two numbers $X$ and $Y$ is $c_{\\text{add}}\\max(|X|,|Y|)$.\n\nFor sufficiently large $k$, the number of bits in $F_k$ is well-approximated by the formula $|F_k| \\approx \\alpha k$, where $\\alpha = \\log_{2}(\\phi)$ with $\\phi = \\frac{1+\\sqrt{5}}{2}$ being the golden ratio.\n\nAssuming $n$ is large, determine the leading term of the total time complexity, $T(n)$, of the iterative calculation phase (step 2). You should neglect the cost of initialization and any terms in your final complexity expression that grow slower than $n^2$. Express your answer as a single expression in terms of $n$, $c_{\\text{copy}}$, $c_{\\text{add}}$, and $\\alpha$.", "solution": "The problem asks for the total time complexity $T(n)$ of the iterative calculation phase for a machine computing the $n$-th Fibonacci number, $F_n$. The calculation phase consists of a loop that runs for $k$ from $3$ to $n$. We need to find the cost of each iteration and then sum these costs.\n\nFirst, let's determine the cost of a single iteration, indexed by $k$. At the beginning of iteration $k$, work tape W1 holds the value $A = F_{k-2}$ and work tape W2 holds the value $B = F_{k-1}$. The operations in iteration $k$ are:\n1.  Make a temporary copy of $A = F_{k-2}$. The cost of this copy operation is $c_{\\text{copy}}|F_{k-2}|$.\n2.  Copy $B = F_{k-1}$ to W1. The cost is $c_{\\text{copy}}|F_{k-1}|$.\n3.  Add the temporary copy of $A$ and the value $B$ to get $S = F_k$. The cost of addition is $c_{\\text{add}}\\max(|A|, |B|) = c_{\\text{add}}\\max(|F_{k-2}|, |F_{k-1}|)$. Since the Fibonacci sequence is increasing for $k \\ge 2$, we have $|F_{k-1}| \\ge |F_{k-2}|$. Thus, the addition cost is $c_{\\text{add}}|F_{k-1}|$.\n\nThe total cost of the $k$-th iteration, $T_k$, is the sum of the costs of these operations:\n$$T_k = c_{\\text{copy}}|F_{k-2}| + c_{\\text{copy}}|F_{k-1}| + c_{\\text{add}}|F_{k-1}|$$\n$$T_k = c_{\\text{copy}}|F_{k-2}| + (c_{\\text{copy}} + c_{\\text{add}})|F_{k-1}|$$\n\nThe total time complexity $T(n)$ is the sum of the costs of all iterations from $k=3$ to $n$:\n$$T(n) = \\sum_{k=3}^{n} T_k = \\sum_{k=3}^{n} \\left( c_{\\text{copy}}|F_{k-2}| + (c_{\\text{copy}} + c_{\\text{add}})|F_{k-1}| \\right)$$\n\nWe are given the approximation $|F_j| \\approx \\alpha j$ for large $j$. We can substitute this into the expression for $T(n)$:\n$$T(n) \\approx \\sum_{k=3}^{n} \\left( c_{\\text{copy}}(\\alpha(k-2)) + (c_{\\text{copy}} + c_{\\text{add}})(\\alpha(k-1)) \\right)$$\n$$T(n) \\approx \\alpha \\sum_{k=3}^{n} \\left( c_{\\text{copy}}(k-2) + (c_{\\text{copy}} + c_{\\text{add}})(k-1) \\right)$$\n\nWe can split the summation into two parts:\n$$T(n) \\approx \\alpha c_{\\text{copy}} \\sum_{k=3}^{n} (k-2) + \\alpha(c_{\\text{copy}} + c_{\\text{add}}) \\sum_{k=3}^{n} (k-1)$$\n\nLet's evaluate each sum.\nFor the first sum, let $j = k-2$. When $k=3$, $j=1$. When $k=n$, $j=n-2$.\n$$\\sum_{k=3}^{n} (k-2) = \\sum_{j=1}^{n-2} j = \\frac{(n-2)(n-1)}{2} = \\frac{1}{2}n^2 - \\frac{3}{2}n + 1$$\nFor the second sum, let $j = k-1$. When $k=3$, $j=2$. When $k=n$, $j=n-1$.\n$$\\sum_{k=3}^{n} (k-1) = \\sum_{j=2}^{n-1} j = \\left(\\sum_{j=1}^{n-1} j\\right) - 1 = \\frac{(n-1)n}{2} - 1 = \\frac{1}{2}n^2 - \\frac{1}{2}n - 1$$\n\nThe problem asks for the leading term of the complexity, neglecting terms that grow slower than $n^2$. For large $n$, the leading term of both sums is $\\frac{1}{2}n^2$.\nSo, we can approximate the sums as:\n$$\\sum_{k=3}^{n} (k-2) \\approx \\frac{1}{2}n^2$$\n$$\\sum_{k=3}^{n} (k-1) \\approx \\frac{1}{2}n^2$$\n\nSubstituting these leading terms back into the expression for $T(n)$:\n$$T(n) \\approx \\alpha c_{\\text{copy}} \\left(\\frac{1}{2}n^2\\right) + \\alpha(c_{\\text{copy}} + c_{\\text{add}}) \\left(\\frac{1}{2}n^2\\right)$$\n$$T(n) \\approx \\frac{\\alpha n^2}{2} \\left( c_{\\text{copy}} + (c_{\\text{copy}} + c_{\\text{add}}) \\right)$$\n$$T(n) \\approx \\frac{\\alpha n^2}{2} (2c_{\\text{copy}} + c_{\\text{add}})$$\n\nThis is the leading term of the total time complexity.", "answer": "$$\\boxed{\\frac{\\alpha n^{2}}{2}(2c_{\\text{copy}} + c_{\\text{add}})}$$", "id": "1466665"}, {"introduction": "After practicing with concrete constructions, we conclude with a more abstract thought experiment that probes the boundaries of what it means to be constructible. This problem poses a subtle question: if a function $f(n)$ is always very close to a known time-constructible function $t(n)$, is $f(n)$ itself guaranteed to be time-constructible? Answering this requires you to connect the idea of constructibility with the more fundamental theory of computability, challenging the intuition that approximation preserves \"nice\" computational properties [@problem_id:1466727].", "problem": "In computational complexity theory, a function $t: \\mathbb{N} \\to \\mathbb{N}$ is defined as **time-constructible** if there exists a deterministic Turing Machine (TM) which, upon receiving an input of length $n$ (conventionally represented as a string of $n$ ones, i.e., $1^n$), halts after exactly $t(n)$ computational steps.\n\nConsider a non-decreasing function $f: \\mathbb{N} \\to \\mathbb{N}$. Suppose we know that this function can be closely approximated by a known time-constructible function $t(n)$. Specifically, there exists a constant integer $c \\ge 1$ such that for all $n \\ge 1$, the absolute difference between the two functions is bounded:\n$$|f(n) - t(n)| \\le c$$\n\nBased on this information, is the function $f(n)$ itself guaranteed to be time-constructible?\n\nChoose the best explanation from the options below.\n\nA. Yes, because a Turing Machine designed to halt in $f(n)$ steps can first simulate a machine that halts in $t(n)$ steps, and then execute a constant number of additional or fewer steps to precisely match the target time $f(n)$.\n\nB. No, because the value of $f(n)$ might depend on an uncomputable property. A Turing Machine would need to determine this property to know its exact halting time, but deciding the property could be impossible within the given time bounds, or at all.\n\nC. Yes, provided that $f(n)$ is a computable function. If $f(n)$ is computable, a Turing machine can calculate the value of $f(n)$ first and then simply loop for that many steps.\n\nD. No, because the difference $f(n) - t(n)$ could be a rapidly oscillating value between $-c$ and $c$. A Turing Machine's control logic is too simple to adjust its runtime to match such oscillations.\n\nE. The statement is undecidable. Determining whether $f(n)$ is time-constructible under these conditions is equivalent to solving the Halting Problem.", "solution": "We recall the definition: a function $t:\\mathbb{N}\\to\\mathbb{N}$ is time-constructible if there exists a deterministic Turing machine $M_{t}$ such that, on input of length $n$ (i.e., $1^{n}$), $M_{t}$ halts after exactly $t(n)$ steps.\n\nKey implication: if a function $g$ is time-constructible, then $g$ is (Turing-)computable. Indeed, given a machine $M_{g}$ that halts in exactly $g(n)$ steps on input $1^{n}$, a simulator can run $M_{g}$ step-by-step while incrementing a counter; when $M_{g}$ halts, the counter equals $g(n)$. Therefore, there is a Turing machine that, on input $1^{n}$, eventually outputs $g(n)$ (in unary, and then in any standard representation). Hence, time-constructible $\\Rightarrow$ computable.\n\nNow assume we are given a non-decreasing $f:\\mathbb{N}\\to\\mathbb{N}$ and a known time-constructible function $t$ together with a constant $c\\ge 1$ such that\n$$\n|f(n)-t(n)|\\le c \\quad \\text{for all } n\\ge 1.\n$$\nThis closeness condition alone does not imply that $f$ is computable. To see this, fix any time-constructible $t$, for concreteness take $t(n)=n$ (which is time-constructible). Define $s:\\mathbb{N}\\to\\{-c,\\ldots,c\\}$ to be any (potentially uncomputable) bounded sequence satisfying the simple local constraint\n$$\ns(n+1)-s(n)\\ge -1 \\quad \\text{for all } n,\n$$\nwhich ensures that $n+s(n)$ is non-decreasing since\n$$\n(n+1)+s(n+1) - \\bigl(n+s(n)\\bigr) = 1 + \\bigl(s(n+1)-s(n)\\bigr) \\ge 0.\n$$\nSuch sequences $s$ abound; in fact there are uncountably many, and many can be defined to depend on an uncomputable set. Define\n$$\nf(n) \\coloneqq t(n) + s(n) = n + s(n).\n$$\nThen $f$ is non-decreasing and satisfies $|f(n)-t(n)|=|s(n)|\\le c$ for all $n$. If $f$ were computable, then so would be $s(n)=f(n)-n$, contradicting the choice of $s$ when it encodes uncomputable information. Therefore, there exist functions $f$ satisfying the stated closeness and monotonicity conditions that are not computable, hence not time-constructible.\n\nConsequently, from the given hypothesis alone, $f$ is not guaranteed to be time-constructible.\n\nEvaluating the options:\n- A is incorrect because achieving exactly $f(n)$ steps from $t(n)$ steps requires knowing $f(n)-t(n)$, which may be uncomputable.\n- B is correct: $f$ can encode uncomputable information within the bounded difference, preventing a TM from determining the exact halting time.\n- C is a true conditional statement but does not answer the guarantee under the given hypothesis (computability of $f$ is not implied).\n- D is incorrect; the obstacle is not the simplicity of control logic but potential noncomputability.\n- E is incorrect; the question is not equivalent to the Halting Problem in the sense stated.\n\nTherefore, the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1466727"}]}