{"hands_on_practices": [{"introduction": "Latent factor models are powerful, but their inner workings can often feel like a black box. This practice explores Nonnegative Matrix Factorization (NMF), a technique that adds a simple but powerful constraint: all factor entries must be nonnegative. By examining a concrete example in this exercise [@problem_id:3167538], you will discover how this constraint leads to an additive, \"parts-based\" representation, making the latent factors more interpretable and often sparser than in unconstrained models.", "problem": "A company builds a recommender system by factorizing a nonnegative user–item interaction matrix $R \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$ into two lower-rank nonnegative factor matrices $U \\in \\mathbb{R}_{\\ge 0}^{m \\times k}$ and $V \\in \\mathbb{R}_{\\ge 0}^{n \\times k}$, with $k \\ll \\min\\{m,n\\}$. Consider the following small illustrative case with $m = 3$, $n = 4$, and $k = 2$. The observed matrix $R$ and a learned exact nonnegative factorization $R = U V^{\\top}$ are:\n$$\nR \\;=\\;\n\\begin{bmatrix}\n6 & 3 & 0 & 0 \\\\\n0 & 0 & 6 & 2 \\\\\n4 & 2 & 3 & 1\n\\end{bmatrix},\n\\quad\nU \\;=\\;\n\\begin{bmatrix}\n3 & 0 \\\\\n0 & 2 \\\\\n2 & 1\n\\end{bmatrix},\n\\quad\nV \\;=\\;\n\\begin{bmatrix}\n2 & 0 \\\\\n1 & 0 \\\\\n0 & 3 \\\\\n0 & 1\n\\end{bmatrix}.\n$$\nAssume $R$ encodes implicit positive feedback counts (so all entries are nonnegative), and that the factorization was obtained by minimizing a standard squared reconstruction objective subject to elementwise nonnegativity on $U$ and $V$.\n\nWhich of the following statements about nonnegativity constraints, interpretability of latent factors, and sparsity patterns is/are correct?\n\nA. Because all entries of $U$ and $V$ are nonnegative, each reconstructed entry $\\hat{R}_{ij}$ is a sum of nonnegative contributions from the $k$ latent components. This additive structure encourages a parts-based representation, making it meaningful to interpret each column of $U$ as a user’s strength on a coherent positive concept and each column of $V$ as an item’s loading on that concept.\n\nB. If the nonnegativity constraints were removed but the same squared loss were minimized, the learned factors would still necessarily produce an elementwise nonnegative product $\\hat{R}$ whenever they are fit to a nonnegative $R$, so the interpretability of latent components would be unaffected.\n\nC. Under nonnegativity constraints, optimality conditions permit exact zeros in $U$ or $V$ when a decrease in a coefficient would improve fit but the constraint prevents it; this tends to yield sparser factors than unconstrained least squares, where the same coefficients would almost surely be small nonzero values.\n\nD. For any nonnegative matrix $R$, any exact nonnegative factorization $R = U V^{\\top}$ with rank $k$ is unique up to permutation and scaling of columns, so nonnegative factorization is identifiable in general.\n\nE. Zero entries in $R$ (for example, $R_{1,3} = 0$ and $R_{1,4} = 0$) force corresponding rows and columns of $U$ and $V$ to contain zeros that exactly preserve the same sparsity pattern in the reconstruction for any nonnegative factorization of rank $k$.\n\nSelect all that apply.", "solution": "We begin from the linear latent factor model definition for recommender systems: the observed interaction matrix $R \\in \\mathbb{R}^{m \\times n}$ is approximated by a low-rank product $\\hat{R} = U V^{\\top}$ with $U \\in \\mathbb{R}^{m \\times k}$ and $V \\in \\mathbb{R}^{n \\times k}$. A common learning principle is empirical risk minimization with squared reconstruction loss and regularization, for example minimizing $\\sum_{i=1}^{m}\\sum_{j=1}^{n} (R_{ij} - (U V^{\\top})_{ij})^{2}$ plus a regularization term, subject to constraints. When $U$ and $V$ are constrained to be elementwise nonnegative, the model is known as Nonnegative Matrix Factorization (NMF). The nonnegativity constraint changes both the geometry of feasible solutions and the stationarity conditions.\n\nTo analyze sparsity under nonnegativity, recall the Karush–Kuhn–Tucker (KKT) conditions for bound-constrained optimization. For a generic nonnegativity-constrained variable $x \\ge 0$ with Lagrange multiplier $\\lambda \\ge 0$, at an optimum the conditions include stationarity (gradient plus multiplier equals zero), complementarity ($\\lambda x = 0$), and primal feasibility ($x \\ge 0$). If the unconstrained gradient at a coordinate would drive $x$ negative, the KKT conditions set $x = 0$ with a positive multiplier. This mechanism can induce exact zeros and hence sparsity in $U$ and $V$.\n\nWe now verify the given factorization and use it to interpret the latent components. With\n$$\nU \\;=\\;\n\\begin{bmatrix}\n3 & 0 \\\\\n0 & 2 \\\\\n2 & 1\n\\end{bmatrix},\n\\quad\nV \\;=\\;\n\\begin{bmatrix}\n2 & 0 \\\\\n1 & 0 \\\\\n0 & 3 \\\\\n0 & 1\n\\end{bmatrix},\n$$\nthe reconstructed entries are $\\hat{R}_{ij} = \\sum_{t=1}^{2} U_{i t} V_{j t}$. Computing by rows of $U$:\n- For user $1$ with $U_{1,:} = (3,0)$, we have $\\hat{R}_{1,:} = (3,0)\\,V^{\\top} = \\big(3 \\cdot 2 + 0 \\cdot 0,\\; 3 \\cdot 1 + 0 \\cdot 0,\\; 3 \\cdot 0 + 0 \\cdot 3,\\; 3 \\cdot 0 + 0 \\cdot 1\\big) = (6, 3, 0, 0)$.\n- For user $2$ with $U_{2,:} = (0,2)$, we have $\\hat{R}_{2,:} = (0,2)\\,V^{\\top} = \\big(0 \\cdot 2 + 2 \\cdot 0,\\; 0 \\cdot 1 + 2 \\cdot 0,\\; 0 \\cdot 0 + 2 \\cdot 3,\\; 0 \\cdot 0 + 2 \\cdot 1\\big) = (0, 0, 6, 2)$.\n- For user $3$ with $U_{3,:} = (2,1)$, we have $\\hat{R}_{3,:} = (2,1)\\,V^{\\top} = \\big(2 \\cdot 2 + 1 \\cdot 0,\\; 2 \\cdot 1 + 1 \\cdot 0,\\; 2 \\cdot 0 + 1 \\cdot 3,\\; 2 \\cdot 0 + 1 \\cdot 1\\big) = (4, 2, 3, 1)$.\nThus $\\hat{R} = R$ exactly. Note that items $1$ and $2$ load only on the first latent component ($V_{1,2}$ have zeros in the second coordinate), and items $3$ and $4$ load only on the second component ($V_{3,4}$ have zeros in the first coordinate). Consequently, the first column of $U$ measures each user’s affinity for the concept expressed by items $1$ and $2$, while the second column measures affinity for the concept expressed by items $3$ and $4$. Because all contributions are nonnegative, each $\\hat{R}_{ij}$ is an additive mixture of concept-wise contributions without cancellation.\n\nWe now analyze each option:\n\nA. Statement: Because $U, V \\ge 0$, each reconstructed entry $\\hat{R}_{ij} = \\sum_{t=1}^{k} U_{i t} V_{j t}$ is a sum of nonnegative terms. This additive structure encourages a parts-based representation, enabling interpretation of columns of $U$ and $V$ as strengths on coherent positive concepts. This follows directly from the definitions: with nonnegativity, there is no subtraction and thus no cancellation; each latent component contributes additively and only in the positive direction. In the given example, the parts-based view is clear: the first latent factor supports items $1$ and $2$ and the second supports items $3$ and $4$. Verdict: Correct.\n\nB. Statement: Removing nonnegativity while keeping squared loss would still necessarily yield an elementwise nonnegative $\\hat{R}$ when fitting a nonnegative $R$, so interpretability is unaffected. This is not generally true. Without nonnegativity constraints, $U$ and $V$ can have mixed signs, and the product $\\hat{R} = U V^{\\top}$ can have negative entries during training or even at convergence if the model trades small negative errors against overall loss. Although the optimizer can approximate a nonnegative $R$ well in squared loss, there is no requirement that $\\hat{R}$ be elementwise nonnegative, and the presence of positive–negative cancellations undermines parts-based interpretability. Verdict: Incorrect.\n\nC. Statement: Under nonnegativity, optimality conditions allow exact zeros that tend to produce sparser factors than unconstrained least squares. By the Karush–Kuhn–Tucker (KKT) conditions for nonnegativity constraints, at an optimum for a coordinate $x \\ge 0$, stationarity gives $\\nabla f(x) + \\lambda = 0$ with $\\lambda \\ge 0$ and complementarity $\\lambda x = 0$. If the unconstrained gradient would push $x$ negative (descent direction toward decreasing $x$), the constrained optimum sets $x = 0$ with $\\lambda > 0$. This mechanism yields exact zeros. In contrast, unconstrained least squares typically yields dense solutions with small but nonzero coefficients. In the provided $V$, many coordinates are exactly zero, illustrating such sparsity. Verdict: Correct.\n\nD. Statement: Any exact nonnegative factorization is unique up to permutation and scaling, so identifiability holds in general. This is false. Nonnegative factorizations are not guaranteed to be unique without additional assumptions (for example, separability, sufficiently scattered conditions, or cone conditions). Multiple distinct nonnegative pairs $(U, V)$ can produce the same $R$, even up to scaling and permutation, especially when $k$ is small relative to the inherent nonnegative rank structure. Verdict: Incorrect.\n\nE. Statement: Zero entries in $R$ force corresponding rows and columns of $U$ and $V$ to contain zeros that exactly preserve the same sparsity pattern in the reconstruction for any nonnegative factorization of rank $k$. In general this is not guaranteed. For a given pair $(i,j)$ with $R_{ij} = 0$, the constraint $\\hat{R}_{ij} = \\sum_{t=1}^{k} U_{i t} V_{j t} = 0$ with $U, V \\ge 0$ requires that $U_{i t} V_{j t} = 0$ for all $t$, but this does not force all entries in the entire $i$th row of $U$ or $j$th row of $V$ to be zero; it only constrains their elementwise products for that pair. Across the whole matrix, low-rank coupling may prevent matching all zeros exactly unless specific structures emerge. Therefore, zeros in $R$ do not universally imply zeros in $U$ or $V$, nor preservation of the overall sparsity pattern. Verdict: Incorrect.\n\nTherefore, the correct statements are A and C.", "answer": "$$\\boxed{AC}$$", "id": "3167538"}, {"introduction": "Moving from theory to practice, this exercise [@problem_id:3167503] challenges you to build a recommender system using a core matrix factorization approach. You will implement a model from the ground up and confront one of the most pervasive issues in real-world systems: popularity bias. By comparing a standard model with one that reweights the loss function, you will gain hands-on experience in measuring and mitigating bias, and appreciate the fundamental trade-off between recommendation accuracy and diversity.", "problem": "Construct a program that implements a simple empirical risk minimization framework for implicit-feedback recommendation with and without item-popularity reweighting, and then measures the change in top-$K$ accuracy and recommendation diversity. The setting is as follows.\n\nStart from the following fundamental base: empirical risk minimization with pointwise logistic loss for binary labels and linear predictors. Given a set of users, items, and a binary training interaction set, learn user and item latent vectors by minimizing a weighted logistic loss plus quadratic regularization. For a user-item pair with label $y_{ui} \\in \\{0,1\\}$ and score $x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$, the logistic loss is $\\ell(y,x) = \\log(1 + \\exp(-(2y-1)x))$. In this problem, use the equivalent separated form:\n$$\n\\ell_+(x) = \\log(1 + \\exp(-x)), \\quad \\ell_-(x) = \\log(1 + \\exp(x)).\n$$\nLet the training set be a set of positive pairs $\\mathcal{P} \\subseteq \\mathcal{U} \\times \\mathcal{I}$ and define the set of negatives for each user $u$ as all items not present in the user’s training positives and not equal to that user’s held-out test item. Define item popularity in the training data as $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$.\n\nTrain two models that share the same structure (user and item embeddings and the same optimizer), but differ in the positive-example weight $w_i$ applied to each item $i$:\n- Unweighted baseline: $w_i = 1$ for all items with $\\text{pop}(i) > 0$.\n- Reweighted: $w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$ for items with $\\text{pop}(i) > 0$, normalized so that the average of $\\{w_i: \\text{pop}(i) > 0\\}$ equals $1$.\n\nUse the following empirical risk with regularization:\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right),\n$$\nwhere $\\mathcal{N}(u)$ is the set of negatives for user $u$, $c_0$ is a constant negative weight, and $\\lambda$ is the regularization strength.\n\nOptimize the loss with full-batch gradient descent for a fixed number of iterations using a fixed learning rate. Initialize all latent vectors with the same pseudorandom seed to ensure determinism across both models.\n\nAfter training each model, compute for each user the top-$K$ recommendations by ranking all candidate items (items not in that user’s training positives) by predicted score $x_{ui}$. Define the top-$K$ accuracy as the mean hit rate at $K$: for each user, the hit indicator is $1$ if the user’s held-out item is within the top-$K$ list and $0$ otherwise; the accuracy is the average of these indicators across users. Define recommendation diversity as one minus the Gini coefficient of item frequencies across all recommended lists:\n- Let $f_i$ be the number of times item $i$ appears across all users’ top-$K$ lists.\n- The Gini coefficient is\n$$\nG = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i},\n$$\nwhere $n$ is the number of items. Define diversity as $D = 1 - G$. Larger $D$ indicates a more even distribution of recommendations across items.\n\nYour program must compute the differences between the reweighted model and the unweighted model for both metrics on a fixed test suite. For each test case, output the pair $[\\Delta \\text{Acc}, \\Delta D]$ where $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ and $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$.\n\nTraining and evaluation protocol and hyperparameters:\n- Use latent dimension $d = 3$.\n- Use learning rate $\\eta = 0.02$.\n- Use number of full-batch iterations $T = 300$.\n- Use negative weight $c_0 = 0.05$.\n- Use regularization $\\lambda = 0.01$.\n- Use top-$K$ with $K = 2$ for all test cases.\n- Use the sigmoid function $\\sigma(x) = \\frac{1}{1 + e^{-x}}$.\n- For negatives, for each user $u$, define $\\mathcal{N}(u)$ as all items not in that user’s training positives and not equal to the held-out item for that user.\n- Initialize all latent vectors from a normal distribution with mean $0$ and standard deviation $0.01$, with pseudorandom seed fixed to $0$.\n\nTest suite:\nProvide exactly three test cases, each specified by a set of training interactions and one held-out positive per user. In each case, the program should construct the user-item cardinalities from the data given.\n\n- Case $1$ (popularity skew; $|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$):\n  - Training positives $\\mathcal{P}$:\n    - User $0$: items $\\{0, 1\\}$\n    - User $1$: items $\\{0\\}$\n    - User $2$: items $\\{0\\}$\n    - User $3$: items $\\{0\\}$\n  - Held-out items:\n    - User $0$: item $2$\n    - User $1$: item $2$\n    - User $2$: item $3$\n    - User $3$: item $4$\n\n- Case $2$ (balanced popularity; $|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$):\n  - Training positives $\\mathcal{P}$:\n    - User $0$: items $\\{0\\}$\n    - User $1$: items $\\{1\\}$\n    - User $2$: items $\\{2\\}$\n    - User $3$: items $\\{3\\}$\n  - Held-out items:\n    - User $0$: item $1$\n    - User $1$: item $2$\n    - User $2$: item $3$\n    - User $3$: item $4$\n\n- Case $3$ (extreme skew with some tail signal; $|\\mathcal{U}| = 5$, $|\\mathcal{I}| = 7$):\n  - Training positives $\\mathcal{P}$:\n    - User $0$: items $\\{0, 1\\}$\n    - User $1$: items $\\{0\\}$\n    - User $2$: items $\\{0, 1\\}$\n    - User $3$: items $\\{0, 2\\}$\n    - User $4$: items $\\{0, 2\\}$\n  - Held-out items:\n    - User $0$: item $3$\n    - User $1$: item $2$\n    - User $2$: item $4$\n    - User $3$: item $5$\n    - User $4$: item $6$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of pairs, one per test case, enclosed in square brackets. Each pair must be a two-element list $[\\Delta \\text{Acc}, \\Delta D]$ with both values rounded to $4$ decimal places. For example: $[[0.1250,0.3500],[0.0000,0.0000],[0.0500,0.1200]]$.\n\nThere are no physical units in this problem. All angles, if any, must be interpreted in radians, but no angles occur here. All fractional values should be expressed as decimals. If there are fewer than $K$ candidate items for a user, use $K' = \\min(K, \\text{number of candidates})$ to form the recommendation list for that user.", "solution": "The user's problem statement has been meticulously reviewed and validated against the established criteria.\n\n### Step 1: Extract Givens\n- **Model:** Empirical Risk Minimization with user-item latent vectors.\n- **Score Function:** The predicted score for a user $u$ and item $i$ is the dot product of their latent vectors: $x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$.\n- **Loss Function:** A weighted pointwise logistic loss with quadratic regularization. The total loss $\\mathcal{L}$ is given by:\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right)\n$$\nwhere $\\ell_+(x) = \\log(1 + \\exp(-x))$ is the loss for positive examples and $\\ell_-(x) = \\log(1 + \\exp(x))$ is for negative examples. $\\mathcal{P}$ is the set of positive training pairs.\n- **Data Sets:** Three test cases are provided, each with a set of users $\\mathcal{U}$, items $\\mathcal{I}$, training positives $\\mathcal{P}$, and a single held-out positive item per user for testing.\n- **Negative Examples:** For each user $u$, the set of negative items $\\mathcal{N}(u)$ consists of all items not in user $u$'s training set and not the user's held-out test item.\n- **Weighting Schemes:**\n  1.  **Unweighted:** $w_i = 1$ for all items $i$ with at least one interaction in $\\mathcal{P}$, i.e., $\\text{pop}(i) > 0$.\n  2.  **Reweighted:** $w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$ for items with $\\text{pop}(i) > 0$, where $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$. The weights $\\{w_i: \\text{pop}(i) > 0\\}$ are normalized to have an average of $1$.\n- **Hyperparameters:**\n  - Latent dimension: $d = 3$.\n  - Learning rate: $\\eta = 0.02$.\n  - Training iterations: $T = 300$.\n  - Negative weight: $c_0 = 0.05$.\n  - Regularization strength: $\\lambda = 0.01$.\n  - Evaluation rank: $K = 2$.\n- **Initialization:** All latent vectors are to be initialized from a normal distribution $\\mathcal{N}(0, 0.01^2)$ with a fixed pseudorandom seed of $0$.\n- **Evaluation Metrics:**\n  - **Top-$K$ Accuracy:** The fraction of users for whom the held-out item is present in the top-$K$ recommended items. Candidate items for ranking for a user $u$ include all items except those in user $u$'s training set.\n  - **Recommendation Diversity:** $D = 1 - G$, where $G$ is the Gini coefficient of item recommendation frequencies. $G = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i}$, with $f_i$ being the count of item $i$ across all users' top-$K$ lists, and $n=|\\mathcal{I}|$.\n- **Task:** For each test case, compute the differences $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ and $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$.\n- **Output Format:** A list of pairs `[[d_acc1, d_div1], [d_acc2, d_div2], ...]` with values rounded to 4 decimal places.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding:** The problem is firmly grounded in the principles of statistical learning and recommender systems. It employs standard a Empirical Risk Minimization (ERM) framework, logistic loss, L2 regularization, and gradient descent. The concept of reweighting to mitigate popularity bias is a well-established technique. The evaluation metrics are standard in the field.\n- **Well-Posedness:** The problem is fully specified. All required data, parameters, and procedures are defined unambiguously. The deterministic initialization ensures a unique training trajectory and a single, verifiable solution.\n- **Objectivity:** The problem statement is objective and devoid of subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is self-contained, scientifically sound, and well-posed. A solution will be constructed.\n\n### Principle-Based Design\nThe solution proceeds by implementing the specified ERM framework. For each test case, we will train two models—one unweighted and one reweighted—and then compute the difference in their performance on the specified metrics.\n\n**Model and Optimization**\nThe objective function $\\mathcal{L}$ is differentiable with respect to the latent vectors $\\mathbf{p}_u$ and $\\mathbf{q}_i$. We use full-batch gradient descent to minimize this loss. The gradients are derived using the chain rule. Let $\\sigma(x) = (1 + e^{-x})^{-1}$ be the sigmoid function. The derivatives of the loss components are $\\frac{d}{dx}\\ell_+(x) = \\sigma(x) - 1$ and $\\frac{d}{dx}\\ell_-(x) = \\sigma(x)$.\n\nThe gradients of the total loss $\\mathcal{L}$ with respect to a user vector $\\mathbf{p}_u$ and an item vector $\\mathbf{q}_i$ are:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{p}_u} = \\sum_{i \\in \\text{Pos}(u)} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{q}_i + c_0 \\sum_{j \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\mathbf{q}_j + \\lambda \\mathbf{p}_u\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{q}_i} = \\sum_{u | (u,i) \\in \\mathcal{P}} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{p}_u + c_0 \\sum_{u | i \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\mathbf{p}_u + \\lambda \\mathbf{q}_i\n$$\nwhere $\\text{Pos}(u)$ is the set of items user $u$ has interacted with in the training set $\\mathcal{P}$.\n\nFor computational efficiency, these gradients are computed in a vectorized manner. We construct an error matrix $E$ of size $|\\mathcal{U}| \\times |\\mathcal{I}|$, where each entry $E_{ui}$ represents the error signal for the pair $(u,i)$. The total error is the sum of errors from positive and negative examples:\n$$\nE = (W_{\\text{pos}} \\odot (\\Sigma - 1)) + c_0 (M_{\\text{neg}} \\odot \\Sigma)\n$$\nHere, $\\odot$ denotes the element-wise product, $\\Sigma$ is the matrix of sigmoid-transformed scores $\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i)$, $W_{\\text{pos}}$ is a matrix where $(W_{\\text{pos}})_{ui} = w_i$ for $(u,i) \\in \\mathcal{P}$ and $0$ otherwise, and $M_{\\text{neg}}$ is a binary matrix indicating the negative pairs.\nThe full-batch gradient updates for the latent factor matrices $P$ and $Q$ are then:\n$$\n\\nabla_P \\mathcal{L} = E Q + \\lambda P \\quad \\implies \\quad P \\leftarrow P - \\eta \\nabla_P \\mathcal{L}\n$$\n$$\n\\nabla_Q \\mathcal{L} = E^\\top P + \\lambda Q \\quad \\implies \\quad Q \\leftarrow Q - \\eta \\nabla_Q \\mathcal{L}\n$$\nThis process is repeated for $T=300$ iterations. To ensure a fair comparison, both unweighted and reweighted models for a given test case start from the exact same initial latent vectors, generated with the specified random seed.\n\n**Weight Calculation**\nFor the reweighted model, item weights are calculated based on their training set popularity, $\\text{pop}(i)$. Let $\\mathcal{I}_{\\text{pop}} = \\{i \\in \\mathcal{I} | \\text{pop}(i) > 0\\}$. The raw weight for an item $i \\in \\mathcal{I}_{\\text{pop}}$ is $w'_i = 1/\\sqrt{\\text{pop}(i)}$. These are then normalized to ensure their mean is $1$:\n$$\nw_i = \\frac{w'_i}{\\frac{1}{|\\mathcal{I}_{\\text{pop}}|} \\sum_{j \\in \\mathcal{I}_{\\text{pop}}} w'_j}\n$$\nThis scheme down-weights popular items and up-weights niche ones, with the goal of improving recommendation diversity without excessively harming accuracy. For the unweighted baseline, $w_i=1$ for all $i \\in \\mathcal{I}_{\\text{pop}}$.\n\n**Evaluation**\nAfter training, each model is evaluated. For each user, we compute scores for all candidate items (those not in their training set). The candidates are ranked, and the top $K=2$ items form the recommendation list.\n- **Accuracy:** We calculate the hit rate by checking if the user's held-out test item appears in their recommendation list, averaged over all users.\n- **Diversity:** We first compute the frequency $f_i$ for each item across all generated recommendation lists. The Gini coefficient $G$ is then calculated from these frequencies, and diversity is reported as $D = 1-G$. A higher value of $D$ signifies that recommendations are more evenly spread across the item catalog.\n\nThe final output is the difference in these metrics between the reweighted and unweighted models.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define hyperparameters from the problem statement.\n    D_LATENT = 3\n    LEARNING_RATE = 0.02\n    ITERATIONS = 300\n    C0_NEGATIVE_WEIGHT = 0.05\n    LAMBDA_REG = 0.01\n    K_TOP = 2\n    RANDOM_SEED = 0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Popularity skew\n        (4, 6, {0: [0, 1], 1: [0], 2: [0], 3: [0]}, {0: 2, 1: 2, 2: 3, 3: 4}),\n        # Case 2: Balanced popularity\n        (4, 6, {0: [0], 1: [1], 2: [2], 3: [3]}, {0: 1, 1: 2, 2: 3, 3: 4}),\n        # Case 3: Extreme skew with some tail signal\n        (5, 7, {0: [0, 1], 1: [0], 2: [0, 1], 3: [0, 2], 4: [0, 2]}, {0: 3, 1: 2, 2: 4, 3: 5, 4: 6}),\n    ]\n\n    # --- Helper Functions ---\n\n    def calculate_weights(num_items, train_pos, reweighted):\n        \"\"\"Calculates item weights for the loss function.\"\"\"\n        item_pops = np.zeros(num_items)\n        for _, items in train_pos.items():\n            for item in items:\n                item_pops[item] += 1\n                \n        active_items_mask = item_pops > 0\n        weights = np.zeros(num_items)\n\n        if not np.any(active_items_mask):\n            return weights\n\n        if not reweighted:\n            weights[active_items_mask] = 1.0\n        else:\n            raw_weights = np.zeros(num_items)\n            raw_weights[active_items_mask] = 1.0 / np.sqrt(item_pops[active_items_mask])\n            \n            avg_raw_weight = np.mean(raw_weights[active_items_mask])\n            if avg_raw_weight > 0:\n                weights[active_items_mask] = raw_weights[active_items_mask] / avg_raw_weight\n\n        return weights\n\n    def train_model(num_users, num_items, train_pos, held_out, p_init, q_init, weights):\n        \"\"\"Trains the model using full-batch gradient descent.\"\"\"\n        P = p_init.copy()\n        Q = q_init.copy()\n\n        pos_indicator = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_indicator[u, items] = 1\n\n        pos_weights_matrix = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_weights_matrix[u, items] = weights[items]\n\n        held_out_indicator = np.zeros((num_users, num_items))\n        if held_out:\n            held_out_users, held_out_items = zip(*held_out.items())\n            held_out_indicator[held_out_users, held_out_items] = 1\n\n        neg_indicator = 1.0 - pos_indicator - held_out_indicator\n\n        for _ in range(ITERATIONS):\n            scores = P @ Q.T\n            sigma_scores = sigmoid(scores)\n\n            error_pos = pos_weights_matrix * (sigma_scores - 1)\n            error_neg = C0_NEGATIVE_WEIGHT * (neg_indicator * sigma_scores)\n            total_error = error_pos + error_neg\n\n            grad_P = total_error @ Q + LAMBDA_REG * P\n            grad_Q = total_error.T @ P + LAMBDA_REG * Q\n\n            P -= LEARNING_RATE * grad_P\n            Q -= LEARNING_RATE * grad_Q\n\n        return P, Q\n\n    def evaluate_model(P, Q, num_users, num_items, train_pos, held_out):\n        \"\"\"Evaluates the model on top-K accuracy and recommendation diversity.\"\"\"\n        scores = P @ Q.T\n        hits = 0\n        all_recommendations = []\n        \n        for u in range(num_users):\n            training_items = set(train_pos.get(u, []))\n            candidate_items = [i for i in range(num_items) if i not in training_items]\n            \n            if not candidate_items:\n                continue\n                \n            candidate_scores = scores[u, candidate_items]\n            sorted_indices = np.argsort(-candidate_scores)\n            \n            k_prime = min(K_TOP, len(candidate_items))\n            top_k_items = [candidate_items[i] for i in sorted_indices[:k_prime]]\n            \n            all_recommendations.extend(top_k_items)\n            \n            if held_out.get(u) in top_k_items:\n                hits += 1\n\n        accuracy = hits / num_users if num_users > 0 else 0.0\n\n        if not all_recommendations:\n            diversity = 0.0\n        else:\n            item_counts = np.zeros(num_items)\n            counts = collections.Counter(all_recommendations)\n            for item, count in counts.items():\n                item_counts[item] = count\n            \n            abs_diff_sum = np.sum(np.abs(item_counts[:, None] - item_counts[None, :]))\n            total_recs = np.sum(item_counts)\n            \n            if total_recs == 0:\n                gini = 0.0\n            else:\n                denominator = 2 * num_items * total_recs\n                gini = abs_diff_sum / denominator if denominator > 0 else 0.0\n            \n            diversity = 1.0 - gini\n\n        return accuracy, diversity\n\n    def solve_case(num_users, num_items, train_pos, held_out):\n        \"\"\"Executes one full test case, returning performance differences.\"\"\"\n        rng = np.random.RandomState(RANDOM_SEED)\n        p_init = rng.normal(0, 0.01, (num_users, D_LATENT))\n        q_init = rng.normal(0, 0.01, (num_items, D_LATENT))\n        \n        unweighted_w = calculate_weights(num_items, train_pos, reweighted=False)\n        p_unweighted, q_unweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, unweighted_w)\n        acc_unweighted, div_unweighted = evaluate_model(p_unweighted, q_unweighted, num_users, num_items, train_pos, held_out)\n\n        reweighted_w = calculate_weights(num_items, train_pos, reweighted=True)\n        p_reweighted, q_reweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, reweighted_w)\n        acc_reweighted, div_reweighted = evaluate_model(p_reweighted, q_reweighted, num_users, num_items, train_pos, held_out)\n        \n        return acc_reweighted - acc_unweighted, div_reweighted - div_unweighted\n    \n    # --- Main Execution Logic ---\n    results = []\n    for case in test_cases:\n        delta_acc, delta_div = solve_case(*case)\n        results.append([delta_acc, delta_div])\n\n    case_strings = [f\"[{da:.4f},{dd:.4f}]\" for da, dd in results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3167503"}, {"introduction": "A recommender system's task is not complete after generating relevance scores; it must construct the final slate of items presented to the user. This final practice [@problem_id:3167527] delves into this crucial re-ranking stage, where raw predictions must be balanced with real-world business or fairness constraints. You will solve a constrained optimization problem to build a slate that maximizes total relevance while adhering to fairness caps, learning to frame recommendation as a practical resource allocation challenge.", "problem": "A content platform performs second-stage re-ranking to form a slate of size $K$ from a candidate set with estimated relevance scores. To satisfy provider-fairness constraints, it imposes group caps that limit how many items from each provider group may appear in the slate. You are given $9$ candidate items partitioned into three provider groups with their estimated relevance scores $r_i$:\n- Group $\\mathcal{A}$: items $1,2,3$ with scores $r_1=9$, $r_2=8.2$, $r_3=6.1$.\n- Group $\\mathcal{B}$: items $4,5,6$ with scores $r_4=7.5$, $r_5=7.4$, $r_6=4$.\n- Group $\\mathcal{C}$: items $7,8,9$ with scores $r_7=5.9$, $r_8=5.2$, $r_9=3.5$.\n\nThe platform selects a slate of at most $K=4$ items by solving the binary optimization\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n\\quad\\text{subject to}\\quad\n\\sum_{i=1}^{9} x_i \\le K,\\quad\n\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\},\\quad\nx_i \\in \\{0,1\\},\n$$\nwhere $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$, $\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$, $\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$, and group caps are $c_{\\mathcal{A}}=2$, $c_{\\mathcal{B}}=1$, $c_{\\mathcal{C}}=2$.\n\nUsing only fundamental definitions of binary decision optimization and the $0$–$1$ knapsack framework, derive an equivalent combinatorial formulation that captures the effect of the group caps as capacity-like constraints, and compute the exact maximum achievable total relevance value of the above optimization. Report only the optimal objective value as your final answer. No rounding is required and no units are involved.", "solution": "The user has provided a binary optimization problem for which an optimal objective value is requested.\n\n### Step 1: Extract Givens\nThe problem provides the following data:\n- A set of $9$ candidate items, indexed $i=1, \\dots, 9$.\n- A slate size limit $K=4$.\n- The items are partitioned into three provider groups:\n  - Group $\\mathcal{A}$: Items $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$ with relevance scores $r_1=9$, $r_2=8.2$, $r_3=6.1$.\n  - Group $\\mathcal{B}$: Items $\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$ with relevance scores $r_4=7.5$, $r_5=7.4$, $r_6=4$.\n  - Group $\\mathcal{C}$: Items $\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$ with relevance scores $r_7=5.9$, $r_8=5.2$, $r_9=3.5$.\n- Group caps (maximum number of items from each group):\n  - $c_{\\mathcal{A}}=2$\n  - $c_{\\mathcal{B}}=1$\n  - $c_{\\mathcal{C}}=2$\n- The optimization problem formulation is:\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n$$\nsubject to the constraints:\n1. $\\sum_{i=1}^{9} x_i \\le K$ (Total items constraint)\n2. $\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\}$ (Group cap constraints)\n3. $x_i \\in \\{0,1\\}$ (Binary decision variables)\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation against the specified criteria.\n- **Scientifically Grounded**: The problem is a well-established formulation in operations research and computer science known as an integer linear program, specifically a variant of the $0$-$1$ knapsack problem (the generalized assignment problem or multiple-choice multidimensional knapsack problem). It is a standard model for resource allocation and is scientifically sound.\n- **Well-Posed**: The problem is well-posed. The set of feasible solutions is finite (a subset of $2^9$ possibilities), ensuring that a maximum value exists. The data and constraints are clearly defined, leading to a unique optimal objective value.\n- **Objective**: The problem statement is entirely objective, using precise mathematical definitions and numerical values without any subjective or ambiguous language.\n- **Completeness and Consistency**: All necessary data ($r_i$, $K$, $c_j$, and group definitions) are provided. There are no contradictions among the constraints. For example, the sum of group caps ($2+1+2=5$) is greater than the total slate size $K=4$, which is a non-trivial condition.\n- **No other flaws are detected.** The problem is formally structured and solvable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe problem is to select a subset of items that maximizes the total relevance, subject to a total cardinality constraint and per-group cardinality constraints. The prompt requires deriving an equivalent combinatorial formulation based on the $0$-$1$ knapsack framework. This can be achieved by reformulating the problem as a Multiple-Choice Knapsack Problem (MCKP).\n\nThe core insight is that for each group $\\mathcal{G}_j$, if we decide to select exactly $k$ items (where $0 \\le k \\le c_j$), the optimal choice is always to select the $k$ items with the highest relevance scores within that group. Any other choice of $k$ items would yield a smaller total relevance and thus be suboptimal.\n\nThis allows us to pre-compute \"bundles\" of items for each group. Each bundle corresponds to a choice of selecting $k$ items from that group. A bundle is characterized by its \"cost\" (the number of items, $k$) and its \"value\" (the sum of relevances of the top $k$ items).\n\nLet $V_{j,k}$ be the value and $W_{j,k}$ be the cost of the optimal bundle of size $k$ from group $j$. The cost is simply $W_{j,k}=k$.\n\n**Group $\\mathcal{A}$**: Items $\\{1,2,3\\}$, scores $\\{9, 8.2, 6.1\\}$, cap $c_{\\mathcal{A}}=2$.\nThe items sorted by relevance are item $1$ ($r_1=9$), item $2$ ($r_2=8.2$), and item $3$ ($r_3=6.1$).\n- Bundle $\\mathcal{A}_0$ (select $k=0$ items): Value $V_{\\mathcal{A},0}=0$, Cost $W_{\\mathcal{A},0}=0$.\n- Bundle $\\mathcal{A}_1$ (select $k=1$ item): Choose item $1$. Value $V_{\\mathcal{A},1}=9$, Cost $W_{\\mathcal{A},1}=1$.\n- Bundle $\\mathcal{A}_2$ (select $k=2$ items): Choose items $1,2$. Value $V_{\\mathcal{A},2}=r_1+r_2=9+8.2=17.2$, Cost $W_{\\mathcal{A},2}=2$.\n\n**Group $\\mathcal{B}$**: Items $\\{4,5,6\\}$, scores $\\{7.5, 7.4, 4\\}$, cap $c_{\\mathcal{B}}=1$.\nThe items sorted by relevance are item $4$ ($r_4=7.5$), item $5$ ($r_5=7.4$), and item $6$ ($r_6=4$).\n- Bundle $\\mathcal{B}_0$ (select $k=0$ items): Value $V_{\\mathcal{B},0}=0$, Cost $W_{\\mathcal{B},0}=0$.\n- Bundle $\\mathcal{B}_1$ (select $k=1$ item): Choose item $4$. Value $V_{\\mathcal{B},1}=7.5$, Cost $W_{\\mathcal{B},1}=1$.\n\n**Group $\\mathcal{C}$**: Items $\\{7,8,9\\}$, scores $\\{5.9, 5.2, 3.5\\}$, cap $c_{\\mathcal{C}}=2$.\nThe items sorted by relevance are item $7$ ($r_7=5.9$), item $8$ ($r_8=5.2$), and item $9$ ($r_9=3.5$).\n- Bundle $\\mathcal{C}_0$ (select $k=0$ items): Value $V_{\\mathcal{C},0}=0$, Cost $W_{\\mathcal{C},0}=0$.\n- Bundle $\\mathcal{C}_1$ (select $k=1$ item): Choose item $7$. Value $V_{\\mathcal{C},1}=5.9$, Cost $W_{\\mathcal{C},1}=1$.\n- Bundle $\\mathcal{C}_2$ (select $k=2$ items): Choose items $7,8$. Value $V_{\\mathcal{C},2}=r_7+r_8=5.9+5.2=11.1$, Cost $W_{\\mathcal{C},2}=2$.\n\nThe original problem is now equivalent to selecting exactly one bundle from each group, such that the sum of the costs (total number of items) does not exceed the knapsack capacity $K=4$, and the sum of the values is maximized. Let $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ be a triplet representing the number of items selected from group $\\mathcal{A}$, $\\mathcal{B}$, and $\\mathcal{C}$ respectively. We must satisfy $k_{\\mathcal{A}} \\le c_{\\mathcal{A}}$, $k_{\\mathcal{B}} \\le c_{\\mathcal{B}}$, $k_{\\mathcal{C}} \\le c_{\\mathcal{C}}$, and the total items constraint $k_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le K=4$.\n\nWe seek to find:\n$$\n\\max_{k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}} \\left( V_{\\mathcal{A},k_{\\mathcal{A}}} + V_{\\mathcal{B},k_{\\mathcal{B}}} + V_{\\mathcal{C},k_{\\mathcal{C}}} \\right)\n$$\nsubject to:\n$$\nk_{\\mathcal{A}} \\in \\{0, 1, 2\\}, \\quad k_{\\mathcal{B}} \\in \\{0, 1\\}, \\quad k_{\\mathcal{C}} \\in \\{0, 1, 2\\}\n$$\n$$\nk_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le 4\n$$\n\nSince all relevance scores are positive, the optimal solution will utilize as many items as possible, up to the total limit $K=4$. We therefore enumerate all combinations $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ that sum to $4$ or less and calculate the total value. We focus on combinations summing to $4$, as they are the most likely candidates for the maximum.\n\nCombinations $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ summing to $4$:\n1.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 1)$: This combination is valid as $k_{\\mathcal{A}}=2 \\le c_{\\mathcal{A}}$, $k_{\\mathcal{B}}=1 \\le c_{\\mathcal{B}}$, and $k_{\\mathcal{C}}=1 \\le c_{\\mathcal{C}}$.\n    Total Value = $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},1} = 17.2 + 7.5 + 5.9 = 30.6$.\n    The items selected are $\\{1, 2\\}$ from $\\mathcal{A}$, $\\{4\\}$ from $\\mathcal{B}$, and $\\{7\\}$ from $\\mathcal{C}$.\n\n2.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 0, 2)$: This combination is valid.\n    Total Value = $V_{\\mathcal{A},2} + V_{\\mathcal{B},0} + V_{\\mathcal{C},2} = 17.2 + 0 + 11.1 = 28.3$.\n\n3.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (1, 1, 2)$: This combination is valid.\n    Total Value = $V_{\\mathcal{A},1} + V_{\\mathcal{B},1} + V_{\\mathcal{C},2} = 9 + 7.5 + 11.1 = 27.6$.\n\nNo other combinations of $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ sum to $4$ while respecting the group caps. For example, $(1,2,1)$ is invalid since $k_{\\mathcal{B}}=2 > c_{\\mathcal{B}}=1$.\n\nCombinations summing to less than $4$ will have lower total values. For example, the best combination summing to $3$ is $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 0)$, which yields a value of $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},0} = 17.2 + 7.5 + 0 = 24.7$. This is less than $30.6$.\n\nComparing the values calculated for combinations summing to $4$:\n- Combination $(2,1,1)$ yields a value of $30.6$.\n- Combination $(2,0,2)$ yields a value of $28.3$.\n- Combination $(1,1,2)$ yields a value of $27.6$.\n\nThe maximum achievable total relevance is the highest among these values.\n\nMaximum Value = $\\max(30.6, 28.3, 27.6) = 30.6$.\n\nThis corresponds to selecting $2$ items from Group $\\mathcal{A}$ (items $1$ and $2$), $1$ item from Group $\\mathcal{B}$ (item $4$), and $1$ item from Group $\\mathcal{C}$ (item $7$). The total number of items is $2+1+1=4$, which satisfies the slate size constraint $\\sum x_i \\le 4$. The group constraints are also satisfied.", "answer": "$$\n\\boxed{30.6}\n$$", "id": "3167527"}]}