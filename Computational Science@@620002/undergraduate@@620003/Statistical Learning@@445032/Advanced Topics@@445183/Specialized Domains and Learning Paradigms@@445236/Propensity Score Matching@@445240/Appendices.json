{"hands_on_practices": [{"introduction": "The foundation of propensity score matching lies in its name: the propensity score. Before we can match individuals, we must first calculate this score, which represents the probability of receiving a treatment given a set of observed characteristics. This first exercise [@problem_id:2488850] provides a direct, hands-on calculation of a propensity score from a given logistic regression model, grounding the abstract statistical concept in a concrete application from environmental science.", "problem": "An environmental scientist, distinguishing their empirical evaluation role from advocacy-oriented environmentalism, seeks to estimate the causal impact of protected area designation on deforestation. Because protected area siting is nonrandom, selection bias can arise if areas designated as protected systematically differ from non-designated areas in biophysical or political characteristics. To address this, the scientist adopts the propensity score framework, where the propensity score is the conditional probability of treatment (protected area designation) given observed covariates.\n\nYou have previously estimated a binary response model for protected area designation using a Generalized Linear Model (GLM) with a logit link based on a training sample from the same region. The predictor variables are slope, distance to roads, and an indicator for proximity to a political boundary. The estimated linear predictor uses the following coefficients (estimated from prior data): intercept $\\beta_{0}=-3.8$, slope coefficient $\\beta_{\\text{slope}}=0.07$ per degree (degrees are the angle unit), distance-to-roads coefficient $\\beta_{\\text{dist}}=0.05$ per kilometer, and political-boundary coefficient $\\beta_{\\text{bound}}=0.60$ for a binary indicator equal to $1$ if the parcel lies within $10$ kilometers of a provincial boundary and $0$ otherwise.\n\nFor a specific forest parcel with slope $18$ degrees, distance to the nearest road $25$ kilometers, and within $10$ kilometers of a provincial boundary (indicator equals $1$), compute the parcel’s propensity score for protected area designation. Begin from the definition that a propensity score is a conditional probability of treatment given covariates, and from the definition of the log-odds transformation (logit) in a GLM with a logit link, and derive any probability mapping you need from those definitions before substituting values.\n\nRound your final numerical propensity score to four significant figures and express it as a unitless decimal (do not use a percentage). In addition, briefly outline in words how matching on this score can reduce selection bias when estimating the impact of protected areas on deforestation, making clear the scientific reasoning that distinguishes inferential evaluation from advocacy.\n\nState only the computed propensity score as your final numerical answer.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Model: Generalized Linear Model (GLM) with a logit link for binary response of protected area designation.\n- The propensity score is defined as the conditional probability of treatment (protected area designation) given observed covariates.\n- Linear predictor coefficients:\n  - Intercept $\\beta_{0} = -3.8$\n  - Slope coefficient $\\beta_{\\text{slope}} = 0.07$ per degree\n  - Distance-to-roads coefficient $\\beta_{\\text{dist}} = 0.05$ per kilometer\n  - Political-boundary coefficient $\\beta_{\\text{bound}} = 0.60$\n- Forest parcel characteristics (covariates):\n  - Slope: $18$ degrees\n  - Distance to nearest road: $25$ kilometers\n  - Proximity to political boundary indicator: $1$\n\n**Step 2: Validate Using Extracted Givens**\n- The problem is **scientifically grounded**. The use of GLMs with a logit link and the propensity score framework are standard, well-established methodologies in statistics and econometrics for causal inference in observational studies.\n- The problem is **well-posed**. It provides all necessary parameters and variable values to compute a unique solution. The question is unambiguous.\n- The problem is **objective**. It uses precise, technical language and correctly frames the methodological challenge of selection bias in program evaluation, distinguishing the empirical-scientific role from advocacy.\n- The problem contains no scientific or factual unsoundness, is not non-formalizable, has no incomplete or contradictory setup, is not unrealistic or infeasible, is not ill-posed, is not trivial, and is scientifically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be derived.\n\nThe task is to compute the propensity score for a specific forest parcel and to explain the logic of propensity score matching. The propensity score, which we denote as $p(X)$, is the conditional probability of receiving treatment ($T=1$) given a vector of observed covariates $X$. In this context, treatment is the designation of a parcel as a protected area.\n\n$$p(X) = P(T=1 | X)$$\n\nThe model used is a Generalized Linear Model (GLM) with a logit link function. The logit function maps a probability $p \\in (0, 1)$ to the real line $(-\\infty, \\infty)$ and is defined as the natural logarithm of the odds:\n\n$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\nIn the GLM framework, the link function of the conditional mean of the response is equated to a linear predictor, $\\eta$. For a binary response, the conditional mean is the probability $p$. Thus, we have:\n\n$$\\eta = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\nTo compute the probability $p$ from the linear predictor $\\eta$, we must derive the inverse of the logit function, which is the logistic sigmoid function. We begin by exponentiating both sides:\n\n$$\\exp(\\eta) = \\frac{p}{1-p}$$\n\nNow, we solve for $p$:\n$$\\exp(\\eta) \\cdot (1-p) = p$$\n$$\\exp(\\eta) - p \\cdot \\exp(\\eta) = p$$\n$$\\exp(\\eta) = p + p \\cdot \\exp(\\eta)$$\n$$\\exp(\\eta) = p \\cdot (1 + \\exp(\\eta))$$\n\nThis gives the expression for the propensity score as a function of the linear predictor:\n$$p = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)}$$\n\nThe linear predictor $\\eta$ is a linear combination of the given covariates and their corresponding coefficients:\n$$\\eta = \\beta_{0} + \\beta_{\\text{slope}} \\cdot X_{\\text{slope}} + \\beta_{\\text{dist}} \\cdot X_{\\text{dist}} + \\beta_{\\text{bound}} \\cdot X_{\\text{bound}}$$\n\nThe problem provides the following values:\n- Intercept: $\\beta_{0} = -3.8$\n- Coefficients: $\\beta_{\\text{slope}} = 0.07$, $\\beta_{\\text{dist}} = 0.05$, $\\beta_{\\text{bound}} = 0.60$\n- Covariates for the parcel: $X_{\\text{slope}} = 18$, $X_{\\text{dist}} = 25$, $X_{\\text{bound}} = 1$\n\nWe substitute these values to compute the linear predictor $\\eta$:\n$$\\eta = -3.8 + (0.07 \\times 18) + (0.05 \\times 25) + (0.60 \\times 1)$$\n$$\\eta = -3.8 + 1.26 + 1.25 + 0.60$$\n$$\\eta = -3.8 + 3.11$$\n$$\\eta = -0.69$$\n\nNow, we use this value of $\\eta$ to compute the propensity score $p$:\n$$p = \\frac{\\exp(-0.69)}{1 + \\exp(-0.69)}$$\n\nComputing the numerical value:\n$$p \\approx \\frac{0.501574}{1 + 0.501574} = \\frac{0.501574}{1.501574} \\approx 0.334033$$\n\nThe problem requires rounding to four significant figures. Therefore, the propensity score for this parcel is $0.3340$.\n\nRegarding the utility of this method, selection bias arises because the siting of protected areas is nonrandom. Parcels designated for protection may systematically differ from those not designated (e.g., they may be more remote, on steeper slopes, or have lower agricultural potential). A naive comparison of outcomes like deforestation would conflate the effect of protection with these pre-existing differences. Propensity score matching is a statistical technique to mitigate this bias. It operates under the assumption of conditional ignorability, which posits that, conditional on the observed covariates $X$, treatment assignment is independent of potential outcomes. By matching a treated unit (a protected parcel) with one or more control units (unprotected parcels) that have very similar propensity scores, we create a comparison group that is balanced on the observed covariates. That is, for a given propensity score, a treated and a control unit had the same *ex ante* probability of being protected. This procedure mimics the properties of a randomized experiment, allowing for a more credible estimate of the causal effect of protection. This purely inferential goal—isolating a causal effect by controlling for confounding factors—is the hallmark of environmental science in this context. It is distinct from environmentalism, which is an advocacy position that may promote protection regardless of its empirically demonstrated, isolated impact. The scientist's role is to provide an objective, evidence-based estimate of the treatment effect, for which this method is a critical tool.", "answer": "$$\n\\boxed{0.3340}\n$$", "id": "2488850"}, {"introduction": "Building a good propensity score model is as much an art as a science, with the primary goal of achieving covariate balance between the treated and control groups. Simply including every available variable can sometimes be counterproductive. This coding practice [@problem_id:3162937] guides you through a complete workflow: building a model, using data-driven methods to prune less important variables, performing matching, and, most critically, evaluating the model's success by assessing covariate balance using the Standardized Mean Difference (SMD).", "problem": "You are given a task to algorithmically decide a variable pruning strategy for a propensity score model and to evaluate how pruning affects covariate balance after one-to-one nearest-neighbor matching on the estimated propensity scores. You must implement the full pipeline, grounded in fundamental definitions of causal inference and statistical modeling, and compute a quantitative comparison across a small test suite.\n\nFundamental base and definitions to use:\n- The propensity score is defined as $e(x) = \\mathbb{P}(T = 1 \\mid X = x)$, where $T \\in \\{0,1\\}$ is a binary treatment and $X \\in \\mathbb{R}^p$ is a vector of covariates.\n- You will model the propensity score via logistic regression, namely $\\text{logit}(e(x)) = \\beta_0 + x^\\top \\beta$, where $\\text{logit}(u) = \\log\\left(\\frac{u}{1-u}\\right)$ and $\\beta \\in \\mathbb{R}^p$.\n- Fit logistic regression by maximizing the binomial log-likelihood using Iteratively Reweighted Least Squares (IRLS), which is the Newton–Raphson method applied to the logistic regression log-likelihood. Use a small ridge stabilization on the information matrix to ensure numerical invertibility.\n- Two variable importance measures in the propensity model are to be computed:\n  1. Absolute standardized coefficient magnitude, defined as $I^{(\\text{coef})}_j = \\lvert \\hat{\\beta}_j \\rvert$ for covariate $j$, after standardizing covariates to zero mean and unit variance. This measures the magnitude of the change in log-odds per one standard deviation of $X_j$.\n  2. Absolute Wald $z$-statistic, defined as $I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\beta}_j}{\\widehat{\\text{se}}(\\hat{\\beta}_j)} \\right|$, where $\\widehat{\\text{se}}(\\hat{\\beta}_j)$ is obtained from the inverse observed Fisher information matrix at the maximum likelihood estimate. This measures a signal-to-noise standardized effect on the log-odds scale.\n- Aggregate the two measures by rank-averaging:\n  - For each measure, assign ranks $r^{(\\text{coef})}_j, r^{(\\text{wald})}_j \\in \\{1,2,\\dots,p\\}$ so that larger values receive larger ranks. Break ties deterministically by covariate index order. Define the combined rank as $r^{(\\text{comb})}_j = \\frac{r^{(\\text{coef})}_j + r^{(\\text{wald})}_j}{2}$.\n- Pruning rule: given a pruning fraction $q \\in [0,1)$, keep the top $\\lceil (1-q) \\cdot p \\rceil$ covariates by descending $r^{(\\text{comb})}_j$ and drop the rest.\n- Matching: perform one-to-one nearest-neighbor matching without replacement on the estimated propensity scores. Define the absolute distance $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$. Use the group (treated or control) with the smaller sample size as the anchor set to guarantee a full matching, sort the anchors by $\\hat{e}$ ascending, and for each anchor pick the unmatched opposite-group unit that minimizes $d(i,k)$, breaking ties by the smallest index to ensure determinism.\n- Balance assessment: for each covariate $j \\in \\{1,\\dots,p\\}$, compute the standardized mean difference (SMD) after matching as\n  $$\\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}},$$\n  where $\\bar{x}^{(T=t)}_j$ and $s^{2,(T=t)}_j$ are the sample mean and unbiased sample variance of the matched subsamples with treatment $t \\in \\{0,1\\}$. If the denominator is zero, define $\\text{SMD}_j = 0$. Summarize balance by the mean absolute standardized mean difference, namely $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$.\n- Compare two models: the full model (all $p$ covariates) versus the pruned model (kept covariates only, re-estimated). For each case, compute $\\text{mSMD}^{\\text{full}}$ and $\\text{mSMD}^{\\text{pruned}}$ using matches built from each model’s propensity scores, and report the change due to pruning as $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$. A negative $\\Delta$ indicates improved balance after pruning.\n\nData generating process for each test case:\n- Generate $n$ observations of $p$-dimensional covariates $X \\sim \\mathcal{N}(0, \\Sigma)$, where $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$ for a given correlation parameter $\\rho \\in [0,1)$.\n- Let the true log-odds be $\\eta = \\alpha_0 + X \\beta^{\\star}$ with a specified vector $\\beta^{\\star} \\in \\mathbb{R}^p$ and intercept $\\alpha_0 \\in \\mathbb{R}$, then $T \\sim \\text{Bernoulli}(\\sigma(\\eta))$ independently across observations, where $\\sigma(u) = \\frac{1}{1 + e^{-u}}$.\n- In modeling, standardize covariates to zero mean and unit variance before fitting logistic regression so that the importance measure $I^{(\\text{coef})}_j$ has a scale-free interpretation.\n\nTest suite:\nYou must run your program on the following three parameter sets, in this exact order. Each parameter set specifies $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0, q)$, where all numbers are real-valued or integers as indicated. For $\\beta^{\\star}$, list the $p$ entries in order.\n\n- Test case A (general case):\n  - $n = 400$, $p = 6$, $\\rho = 0.3$, $\\text{seed} = 2021$, $\\beta^{\\star} = [0.8, -0.7, 0.6, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.5$.\n- Test case B (weak-signal edge case):\n  - $n = 300$, $p = 5$, $\\rho = 0.2$, $\\text{seed} = 7$, $\\beta^{\\star} = [0.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.4$.\n- Test case C (high collinearity):\n  - $n = 500$, $p = 5$, $\\rho = 0.9$, $\\text{seed} = 99$, $\\beta^{\\star} = [1.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = -0.2$, $q = 0.6$.\n\nProgram requirements:\n- Implement logistic regression by IRLS with a small ridge stabilization on the observed information matrix. Use standardized covariates and include an intercept term in the model.\n- Compute both importance measures $I^{(\\text{coef})}_j$ and $I^{(\\text{wald})}_j$, aggregate by rank averaging, and prune by the specified fraction $q$ for each test case.\n- For balance, compute $\\text{mSMD}$ across all original $p$ covariates, both for the full model and for the pruned model, using matches produced from each model’s propensity scores respectively, as described above.\n- For each test case, output the single float $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$.\n- Final output format: Your program should produce a single line of output containing the results of the three test cases as a comma-separated list enclosed in square brackets, with each float rounded to exactly six digits after the decimal point, for example, `[0.012345,-0.067890,0.000000]`.\n\nNo user input is required. There are no physical units or angles involved. All proportions and probabilities must be computed and presented as decimals, not with a percentage sign.", "solution": "The user has provided a well-defined statistical simulation problem centered on propensity score analysis. The task is to implement a complete pipeline from data generation to model fitting, variable selection, matching, and balance evaluation. The objective is to quantify the change in covariate balance resulting from a specific variable pruning strategy in the propensity score model.\n\n### 1. Problem Validation\nThe problem statement has been rigorously validated and is determined to be **valid**. It is scientifically grounded in established principles of statistics and causal inference, is well-posed with deterministic procedural steps, and is expressed in objective, formal language. All necessary parameters and definitions are provided, ensuring a unique and verifiable solution can be computed.\n\n### 2. Methodological Framework and Algorithmic Design\n\nThe solution is implemented by constructing a sequence of functions corresponding to the distinct logical stages of the analysis.\n\n#### 2.1. Data Generation\nFor each test case, we first simulate a dataset according to the specified parameters $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0)$.\nThe $p$-dimensional covariates $X \\in \\mathbb{R}^{n \\times p}$ are drawn from a multivariate normal distribution, $X \\sim \\mathcal{N}(0, \\Sigma)$. The covariance matrix $\\Sigma$ is an autoregressive-1 (AR-1) structure, where $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$ for $i,j \\in \\{1, \\dots, p\\}$. This matrix is generated using a Toeplitz construction.\nThe binary treatment assignment $T \\in \\{0,1\\}^n$ is then generated for each observation $i=1, \\dots, n$. The true log-odds of receiving treatment are modeled as a linear function of the covariates, $\\eta_i = \\alpha_0 + X_i^\\top \\beta^{\\star}$. The treatment $T_i$ is then drawn from a Bernoulli distribution with probability $\\mathbb{P}(T_i = 1 \\mid X_i) = \\sigma(\\eta_i)$, where $\\sigma(u) = (1 + e^{-u})^{-1}$ is the logistic sigmoid function. A specific random seed is used for each test case to ensure reproducibility.\n\n#### 2.2. Covariate Standardization and Propensity Score Estimation\nBefore fitting any models, the generated covariates $X$ are standardized to have a mean of $0$ and a standard deviation of $1$ for each column. Let this standardized data be $X_{\\text{std}}$. This step ensures that the coefficient-based importance measure, $I^{(\\text{coef})}$, is on a comparable scale across covariates.\n\nThe propensity score, $e(x) = \\mathbb{P}(T=1 \\mid X=x)$, is estimated using a logistic regression model, $\\text{logit}(e(x)) = \\gamma_0 + x_{\\text{std}}^\\top \\gamma$. We fit this model using the Iteratively Reweighted Least Squares (IRLS) algorithm, which is an application of the Newton-Raphson method to find the maximum likelihood estimates of the parameters $\\gamma$ (denoted $\\hat{\\beta}$ in the problem description, but we use $\\gamma$ here to distinguish from true $\\beta^{\\star}$). The IRLS update step is:\n$$ \\gamma^{(k+1)} = \\gamma^{(k)} + (X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}} + \\lambda I)^{-1} X_{\\text{aug}}^\\top (T - \\mu^{(k)}) $$\nwhere $X_{\\text{aug}}$ is the standardized covariate matrix augmented with an intercept column, $\\mu^{(k)} = \\sigma(X_{\\text{aug}}\\gamma^{(k)})$ are the predicted probabilities at iteration $k$, and $W^{(k)}$ is a diagonal matrix of weights with entries $W_{ii}^{(k)} = \\mu_i^{(k)}(1-\\mu_i^{(k)})$. The term $\\lambda I$ represents a small ridge penalty ($\\lambda=10^{-8}$) added to the Fisher information matrix $(X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}})$ to ensure numerical stability, particularly in cases of high collinearity. The algorithm is iterated until the L2-norm of the change in coefficients falls below a tolerance of $10^{-7}$ or a maximum of $25$ iterations is reached.\nThe procedure returns the estimated coefficients $\\hat{\\gamma}$ and their estimated covariance matrix, $\\widehat{\\text{Cov}}(\\hat{\\gamma}) = (X_{\\text{aug}}^\\top \\hat{W} X_{\\text{aug}} + \\lambda I)^{-1}$.\n\n#### 2.3. Variable Importance and Pruning\nTo identify covariates for pruning, we compute two importance measures for each covariate $j \\in \\{1, \\dots, p\\}$ based on the full model fit:\n1.  Absolute Standardized Coefficient Magnitude: $I^{(\\text{coef})}_j = \\lvert \\hat{\\gamma}_j \\rvert$.\n2.  Absolute Wald z-statistic: $I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\gamma}_j}{\\widehat{\\text{se}}(\\hat{\\gamma}_j)} \\right|$, where $\\widehat{\\text{se}}(\\hat{\\gamma}_j)$ is the standard error derived from the square root of the diagonal elements of $\\widehat{\\text{Cov}}(\\hat{\\gamma})$.\n\nThese two measures are aggregated via rank-averaging. For each measure, covariates are ranked from $1$ to $p$ such that a larger importance value receives a larger rank. Ties are broken deterministically by assigning a lower rank to the covariate with the smaller index. The combined rank is $r^{(\\text{comb})}_j = (r^{(\\text{coef})}_j + r^{(\\text{wald})}_j) / 2$.\nGiven a pruning fraction $q$, we keep the top $k = \\lceil (1-q)p \\rceil$ covariates with the highest combined ranks. This defines the \"pruned\" set of covariates. A new propensity score model is then re-estimated using only this subset of standardized covariates.\n\n#### 2.4. One-to-One Nearest-Neighbor Matching\nFor both the full and pruned models, we perform one-to-one nearest-neighbor matching on the estimated propensity scores, $\\hat{e}$, without replacement. The group with the smaller sample size (treated or control) is designated as the \"anchor\" group. Anchors are sorted in ascending order of their propensity scores. For each anchor unit, we find the unit in the opposite (\"target\") group that has the minimum absolute difference in propensity scores, $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$. This target unit must not have been previously matched. Ties in distance are broken by selecting the target unit with the smallest original row index. This procedure results in a matched sample of pairs, one treated and one control unit per pair.\n\n#### 2.5. Covariate Balance Assessment\nThe effectiveness of matching is assessed by measuring the covariate balance in the matched sample. For each of the original $p$ covariates (on their original, unstandardized scale), we calculate the Standardized Mean Difference (SMD):\n$$ \\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}} $$\nHere, $\\bar{x}^{(T=t)}_j$ and $s^{2,(T=t)}_j$ are the sample mean and unbiased sample variance, respectively, of covariate $j$ for treatment group $t$ within the matched subsample. If the denominator is zero, $\\text{SMD}_j$ is defined to be $0$.\nThe overall balance is summarized by the mean Absolute Standardized Mean Difference (mSMD), calculated as $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$.\n\n#### 2.6. Evaluation Protocol\nThe entire pipeline is executed twice for each test case:\n1.  **Full Model**: The mSMD, denoted $\\text{mSMD}^{\\text{full}}$, is computed using matches derived from propensity scores estimated with all $p$ covariates.\n2.  **Pruned Model**: The mSMD, denoted $\\text{mSMD}^{\\text{pruned}}$, is computed using matches derived from propensity scores estimated with the pruned subset of covariates.\n\nThe final metric reported for each test case is the change in balance due to pruning: $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$. A negative value of $\\Delta$ indicates that the variable pruning strategy improved covariate balance.", "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef generate_data(n, p, rho, seed, beta_star, alpha_0):\n    \"\"\"Generates synthetic data for a single test case.\"\"\"\n    rng = np.random.default_rng(seed)\n    # Generate covariates X ~ N(0, Sigma)\n    first_row = rho ** np.arange(p)\n    cov_matrix = scipy.linalg.toeplitz(first_row)\n    X = rng.multivariate_normal(np.zeros(p), cov_matrix, size=n)\n\n    # Generate treatment T ~ Bernoulli(sigma(alpha_0 + X @ beta_star))\n    eta = alpha_0 + X @ beta_star\n    prob_T = 1 / (1 + np.exp(-eta))\n    T = rng.binomial(1, prob_T)\n    \n    return X, T\n\ndef fit_logistic_irls(X, y, l2_penalty=1e-8, max_iter=25, tol=1e-7):\n    \"\"\"Fits logistic regression using Iteratively Reweighted Least Squares.\"\"\"\n    X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n    n_samples, n_features = X_aug.shape\n    beta = np.zeros(n_features)\n\n    for _ in range(max_iter):\n        eta = X_aug @ beta\n        mu = 1 / (1 + np.exp(-eta))\n        \n        gradient = X_aug.T @ (y - mu)\n        W_diag = mu * (1 - mu)\n        info_matrix = X_aug.T * W_diag @ X_aug\n        \n        # Add ridge stabilization\n        info_reg = info_matrix + l2_penalty * np.eye(n_features)\n        \n        delta_beta = np.linalg.solve(info_reg, gradient)\n        beta += delta_beta\n        \n        if np.linalg.norm(delta_beta)  tol:\n            break\n            \n    # Final Information Matrix and Covariance\n    eta = X_aug @ beta\n    mu = 1 / (1 + np.exp(-eta))\n    W_diag = mu * (1 - mu)\n    final_info_matrix = X_aug.T * W_diag @ X_aug\n    final_info_reg = final_info_matrix + l2_penalty * np.eye(n_features)\n    cov_beta = np.linalg.inv(final_info_reg)\n    \n    return beta, cov_beta\n\ndef get_pruning_indices(beta, cov_beta, p, q):\n    \"\"\"Determines which covariates to keep based on rank-averaged importance.\"\"\"\n    beta_coeffs = beta[1:]\n    se_beta = np.sqrt(np.diag(cov_beta))[1:]\n    \n    imp_coef = np.abs(beta_coeffs)\n    imp_wald = np.abs(np.divide(beta_coeffs, se_beta, out=np.zeros_like(beta_coeffs), where=se_beta != 0))\n    \n    covariate_indices = np.arange(p)\n    \n    # Ranking with tie-breaking: higher value -> higher rank. Tie -> smaller index -> smaller rank.\n    # Sort by (value, index) to achieve this.\n    sorted_by_coef = sorted(covariate_indices, key=lambda j: (imp_coef[j], j))\n    rank_coef = np.empty(p, dtype=int); rank_coef[sorted_by_coef] = np.arange(1, p + 1)\n    \n    sorted_by_wald = sorted(covariate_indices, key=lambda j: (imp_wald[j], j))\n    rank_wald = np.empty(p, dtype=int); rank_wald[sorted_by_wald] = np.arange(1, p + 1)\n    \n    rank_comb = (rank_coef + rank_wald) / 2\n    \n    num_to_keep = int(np.ceil((1 - q) * p))\n    # Sort indices by descending combined rank\n    indices_to_keep_sorted_by_rank = np.argsort(-rank_comb)\n    \n    kept_indices = indices_to_keep_sorted_by_rank[:num_to_keep]\n    return np.sort(kept_indices)\n\ndef perform_matching(pscores, T):\n    \"\"\"Performs 1-to-1 nearest neighbor matching without replacement.\"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    if len(treated_indices) = len(control_indices):\n        anchor_indices, target_indices = treated_indices, control_indices\n        is_anchor_treated = True\n    else:\n        anchor_indices, target_indices = control_indices, treated_indices\n        is_anchor_treated = False\n        \n    sorted_anchor_indices = anchor_indices[np.argsort(pscores[anchor_indices])]\n    \n    target_pool = list(target_indices)\n    matched_targets = []\n    \n    for anchor_idx in sorted_anchor_indices:\n        anchor_pscore = pscores[anchor_idx]\n        \n        dists = np.abs(anchor_pscore - pscores[target_pool])\n        min_dist = np.min(dists)\n        \n        # Tie-breaking by smallest original index\n        candidate_pool_indices = np.where(dists == min_dist)[0]\n        candidate_original_indices = [target_pool[i] for i in candidate_pool_indices]\n        best_match_idx = min(candidate_original_indices)\n        \n        matched_targets.append(best_match_idx)\n        target_pool.remove(best_match_idx)\n        \n    matched_targets = np.array(matched_targets)\n    \n    if is_anchor_treated:\n        return sorted_anchor_indices, matched_targets\n    else:\n        return matched_targets, sorted_anchor_indices\n\ndef calculate_msmd(X_orig, matched_treated_indices, matched_control_indices):\n    \"\"\"Calculates the mean absolute standardized mean difference.\"\"\"\n    if len(matched_treated_indices) == 0 or len(matched_control_indices) == 0:\n        return 0.0\n\n    X_matched_treated = X_orig[matched_treated_indices, :]\n    X_matched_control = X_orig[matched_control_indices, :]\n    \n    mean_treated = np.mean(X_matched_treated, axis=0)\n    mean_control = np.mean(X_matched_control, axis=0)\n    \n    # Unbiased sample variance with ddof=1\n    var_treated = np.var(X_matched_treated, axis=0, ddof=1)\n    var_control = np.var(X_matched_control, axis=0, ddof=1)\n    \n    pooled_sd = np.sqrt((var_treated + var_control) / 2)\n    \n    smds = np.divide(mean_treated - mean_control, pooled_sd, out=np.zeros_like(pooled_sd), where=pooled_sd != 0)\n    \n    return np.mean(np.abs(smds))\n\ndef run_single_case(n, p, rho, seed, beta_star, alpha_0, q):\n    \"\"\"Executes the full pipeline for one test case.\"\"\"\n    # 1. Data Generation\n    X_orig, T = generate_data(n, p, rho, seed, beta_star, alpha_0)\n    \n    # 2. Standardization\n    X_mean = np.mean(X_orig, axis=0)\n    X_std = np.std(X_orig, axis=0)\n    X_std[X_std == 0] = 1.0  # Avoid division by zero for constant covariates\n    X_norm = (X_orig - X_mean) / X_std\n\n    # --- FULL MODEL ANALYSIS ---\n    beta_full, cov_beta_full = fit_logistic_irls(X_norm, T)\n    X_aug_full = np.hstack([np.ones((n, 1)), X_norm])\n    pscores_full = 1 / (1 + np.exp(-(X_aug_full @ beta_full)))\n    matched_treated_full, matched_control_full = perform_matching(pscores_full, T)\n    msmd_full = calculate_msmd(X_orig, matched_treated_full, matched_control_full)\n\n    # --- PRUNED MODEL ANALYSIS ---\n    indices_to_keep = get_pruning_indices(beta_full, cov_beta_full, p, q)\n    if len(indices_to_keep) > 0:\n        X_norm_pruned = X_norm[:, indices_to_keep]\n        beta_pruned, _ = fit_logistic_irls(X_norm_pruned, T)\n        X_aug_pruned = np.hstack([np.ones((n, 1)), X_norm_pruned])\n        pscores_pruned = 1 / (1 + np.exp(-(X_aug_pruned @ beta_pruned)))\n    else: # If all covariates are pruned, pscore is constant (based on intercept only)\n        beta_pruned_intercept_only, _ = fit_logistic_irls(np.empty((n,0)), T)\n        pscores_pruned = np.full(n, 1 / (1 + np.exp(-beta_pruned_intercept_only[0])))\n\n    matched_treated_pruned, matched_control_pruned = perform_matching(pscores_pruned, T)\n    msmd_pruned = calculate_msmd(X_orig, matched_treated_pruned, matched_control_pruned)\n    \n    # --- Final Result ---\n    delta = msmd_pruned - msmd_full\n    return delta\n\ndef solve():\n    \"\"\"Main function to run test suite and print results.\"\"\"\n    test_cases = [\n        # Test case A\n        dict(n=400, p=6, rho=0.3, seed=2021, beta_star=np.array([0.8, -0.7, 0.6, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.5),\n        # Test case B\n        dict(n=300, p=5, rho=0.2, seed=7, beta_star=np.array([0.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.4),\n        # Test case C\n        dict(n=500, p=5, rho=0.9, seed=99, beta_star=np.array([1.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=-0.2, q=0.6)\n    ]\n    \n    results = []\n    for params in test_cases:\n        delta = run_single_case(**params)\n        results.append(f\"{delta:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3162937"}, {"introduction": "Real-world data often requires more sophisticated matching strategies than simple nearest-neighbor matching on a single propensity score. In many studies, it is crucial to enforce exact matches on key categorical confounders (e.g., matching patients only within the same hospital) while allowing for small, controlled differences in other variables. This advanced practice [@problem_id:3163024] challenges you to implement such a hybrid matching algorithm, combining exact matching with caliper constraints to achieve a more robust and credible comparison between groups.", "problem": "You are tasked with implementing a matching procedure that enforces exact matches on key categorical confounders while allowing calipered differences on a continuous covariate. The goal is to assess the bias of the Average Treatment Effect (ATE). Begin from the potential outcomes framework and the definition of the propensity score. Average Treatment Effect (ATE) and Propensity Score Matching (PSM) must be reasoned from first principles in your algorithmic design.\n\nConsider the following data-generating process defined in purely mathematical terms. For each unit $i$, let $X_i$ be a continuous covariate, $C_{1,i}\\in\\{0,1\\}$ be a binary categorical confounder, $C_{2,i}\\in\\{0,1,2\\}$ be a ternary categorical confounder, $T_i\\in\\{0,1\\}$ be the treatment indicator, and $Y_i(0),Y_i(1)$ be the potential outcomes. Let $\\varepsilon_i$ be an independent noise term.\n\nDefine the confounders and covariate:\n- $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$.\n- $C_{2,i} \\in \\{0,1,2\\}$ with $\\Pr(C_{2,i}=0)=0.4$, $\\Pr(C_{2,i}=1)=0.4$, $\\Pr(C_{2,i}=2)=0.2$.\n- $X_i \\sim \\mathcal{N}(\\mu_i, 1)$, where $\\mu_i = 0.5\\,C_{1,i} + 0.3\\,\\mathbb{1}\\{C_{2,i}=1\\} - 0.3\\,\\mathbb{1}\\{C_{2,i}=2\\}$.\n\nDefine the treatment assignment using the logistic function $\\sigma(u) = 1/(1+\\exp(-u))$:\n$$\n\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}) \n= \\sigma\\!\\Big(\\alpha_0 + \\alpha_X X_i + \\alpha_{C_1} C_{1,i} + \\alpha_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\alpha_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\}\\Big),\n$$\nwith fixed coefficients $\\alpha_0=0.2$, $\\alpha_X=0.8$, $\\alpha_{C_1}=0.6$, $\\alpha_{C_2,1}=0.4$, $\\alpha_{C_2,2}=-0.4$.\n\nDefine the potential outcomes and observed outcome:\n- $\\varepsilon_i \\sim \\mathcal{N}(0,1)$ independently.\n- $Y_i(0) = \\gamma_0 + \\gamma_X X_i + \\gamma_{C_1} C_{1,i} + \\gamma_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\gamma_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\} + \\varepsilon_i$, with $\\gamma_0=1.0$, $\\gamma_X=1.0$, $\\gamma_{C_1}=0.5$, $\\gamma_{C_2,1}=0.2$, $\\gamma_{C_2,2}=-0.2$.\n- $Y_i(1) = Y_i(0) + \\tau$, with $\\tau=2.0$.\n- $Y_i = T_i\\,Y_i(1) + (1-T_i)\\,Y_i(0)$.\n\nThe propensity score is $e(X_i,C_{1,i},C_{2,i})=\\Pr(T_i=1\\mid X_i,C_{1,i},C_{2,i})$. In your program, you must estimate the propensity score via logistic regression using maximum likelihood, employing the design matrix with an intercept and covariates $(X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$.\n\nImplement the following matching rule:\n- For every treated unit $i$ with $T_i=1$, find at most one control unit $j$ with $T_j=0$ such that $C_{1,j}=C_{1,i}$ and $C_{2,j}=C_{2,i}$ (exact matching on both categorical confounders).\n- Impose calipers on the continuous covariate and the propensity score: $|X_i - X_j| \\le \\delta_x$ and $|e_i - e_j| \\le \\delta_p$, where $e_k$ denotes the estimated propensity score for unit $k$.\n- Among all eligible control candidates for $i$, choose the one that minimizes $|e_i - e_j|$. Match without replacement.\n\nCompute the estimated ATE as the mean of the matched treated-minus-control differences in observed outcomes, denoted $\\widehat{\\mathrm{ATE}}$. Compute the bias as $\\widehat{\\mathrm{ATE}} - \\tau$.\n\nYour program must implement the above logic and evaluate the bias for each of the following test cases, which together form the test suite:\n- Case $1$: $(\\text{seed}=101, N=800, \\delta_p=0.05, \\delta_x=0.5)$.\n- Case $2$: $(\\text{seed}=202, N=800, \\delta_p=0.02, \\delta_x=0.1)$.\n- Case $3$: $(\\text{seed}=303, N=800, \\delta_p=0.20, \\delta_x=2.0)$.\n- Case $4$: $(\\text{seed}=404, N=120, \\delta_p=0.05, \\delta_x=0.5)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry must be the bias for the corresponding case expressed as a decimal float rounded to six decimal places (for example, `[0.012345,-0.004321,0.000000,0.123456]`).", "solution": "The problem requires the implementation of a propensity score matching algorithm to estimate the bias of the Average Treatment Effect (ATE) in a simulated observational study. The solution will be derived from first principles of causal inference, specifically the potential outcomes framework.\n\n### Fundamental Principles of Causal Inference\n\nThe foundation of this problem lies in the potential outcomes framework, often called the Neyman-Rubin Causal Model. For each unit $i$, we define two potential outcomes: $Y_i(1)$, the outcome if the unit receives the treatment, and $Y_i(0)$, the outcome if the unit does not receive the treatment. The treatment assignment is indicated by a binary variable $T_i \\in \\{0, 1\\}$. The causal effect of the treatment for unit $i$ is the difference in its potential outcomes, $Y_i(1) - Y_i(0)$.\n\nThe central estimand of interest is the Average Treatment Effect (ATE), defined as the expected value of this unit-level effect over the entire population:\n$$\n\\mathrm{ATE} = \\mathbb{E}[Y_i(1) - Y_i(0)]\n$$\nIn the specific data-generating process provided, we have $Y_i(1) = Y_i(0) + \\tau$, where $\\tau = 2.0$ is a constant. Thus, the ATE is simply $\\tau$.\n\nThe fundamental problem of causal inference arises because for any given unit $i$, we can only observe one of the two potential outcomes. The observed outcome $Y_i$ is given by:\n$$\nY_i = T_i Y_i(1) + (1-T_i) Y_i(0)\n$$\n\n### Confounding and the Role of Propensity Scores\n\nIn a non-randomized study, treatment assignment is often influenced by pre-treatment covariates. If these covariates also influence the potential outcomes, they are known as confounders. A naive comparison of the average outcome between the treated and control groups, $\\mathbb{E}[Y_i | T_i=1] - \\mathbb{E}[Y_i | T_i=0]$, does not estimate the ATE. Instead, it is biased due to systematic differences in the covariates between the two groups. In this problem, the covariates are $\\mathbf{Z}_i = (X_i, C_{1,i}, C_{2,i})$, and they influence both the treatment assignment $\\Pr(T_i=1 \\mid \\mathbf{Z}_i)$ and the potential outcomes $Y_i(0)$ and $Y_i(1)$.\n\nTo overcome this confounding bias, we rely on the assumption of **unconfoundedness** (or conditional ignorability). This assumption states that, conditional on the covariates $\\mathbf{Z}_i$, the treatment assignment is independent of the potential outcomes:\n$$\n(Y_i(0), Y_i(1)) \\perp T_i \\mid \\mathbf{Z}_i\n$$\nThis assumption holds true by design in the given data-generating process. Under unconfoundedness, we can identify the ATE by adjusting for the covariates.\n\nA powerful tool for this adjustment is the **propensity score**, defined by Rosenbaum and Rubin as the conditional probability of receiving treatment given the covariates:\n$$\ne(\\mathbf{Z}_i) = \\Pr(T_i=1 \\mid \\mathbf{Z}_i)\n$$\nThe key property of the propensity score is that if unconfoundedness holds given $\\mathbf{Z}_i$, it also holds given the scalar propensity score $e(\\mathbf{Z}_i)$, assuming $0  e(\\mathbf{Z}_i)  1$ (the positivity or overlap assumption). This dimensional reduction is crucial, as it allows us to control for confounding by matching or stratifying on a single variable, the propensity score, rather than the full, potentially high-dimensional set of covariates $\\mathbf{Z}_i$.\n\n### Algorithmic Design\n\nThe solution involves a sequence of steps: data generation, propensity score estimation, matching, and finally, ATE estimation and bias calculation.\n\n**1. Data Generation**\nA dataset of size $N$ is generated according to the specified stochastic process. For each unit $i=1, \\dots, N$:\n- Draw the categorical confounders $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$ and $C_{2,i}$ from its discrete distribution.\n- Draw the continuous covariate $X_i \\sim \\mathcal{N}(\\mu_i, 1)$, where $\\mu_i$ depends on $C_{1,i}$ and $C_{2,i}$.\n- Calculate the true propensity score using the given logistic function and coefficients $(\\alpha_0, \\alpha_X, \\alpha_{C_1}, \\ldots)$.\n- Assign treatment $T_i \\sim \\mathrm{Bernoulli}(\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}))$.\n- Generate the potential outcome $Y_i(0)$ based on the linear model involving the covariates and a noise term $\\varepsilon_i \\sim \\mathcal{N}(0,1)$. The potential outcome $Y_i(1)$ is $Y_i(0) + \\tau$.\n- Determine the observed outcome $Y_i$ based on $T_i$.\n\n**2. Propensity Score Estimation**\nWhile the true propensity score function is known in this simulation, standard practice is to estimate it from the observed data. The problem specifies using logistic regression.\n- A design matrix $\\mathbf{M}$ is constructed for the $N$ observations. Each row $\\mathbf{M}_i$ corresponds to unit $i$ and contains an intercept and the covariates used in the model: $(1, X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$.\n- The logistic model predicts the probability of treatment as $p_i(\\boldsymbol{\\beta}) = \\sigma(\\mathbf{M}_i \\cdot \\boldsymbol{\\beta})$, where $\\sigma(u)$ is the sigmoid function and $\\boldsymbol{\\beta}$ is the vector of coefficients to be estimated.\n- The coefficients $\\hat{\\boldsymbol{\\beta}}$ are found by maximizing the log-likelihood function via numerical optimization. This is equivalent to minimizing the negative log-likelihood:\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = -\\sum_{i=1}^N \\left[ T_i \\log(p_i(\\boldsymbol{\\beta})) + (1-T_i) \\log(1 - p_i(\\boldsymbol{\\beta})) \\right]\n$$\n- The gradient of the negative log-likelihood, required for efficient optimization, is:\n$$\n-\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^N (T_i - p_i(\\boldsymbol{\\beta})) \\mathbf{M}_i = \\mathbf{M}^T (\\mathbf{T} - \\mathbf{p}(\\boldsymbol{\\beta}))\n$$\n- Once $\\hat{\\boldsymbol{\\beta}}$ is obtained, the estimated propensity score for each unit is calculated as $\\hat{e}_i = \\sigma(\\mathbf{M}_i \\cdot \\hat{\\boldsymbol{\\beta}})$.\n\n**3. Matching Procedure**\nThe core of the task is to implement the specified matching algorithm. The goal is to find a control counterpart for each treated unit. This is a form of greedy nearest-neighbor matching with additional constraints, performed without replacement.\n- The dataset is partitioned into a treated group ($T_i=1$) and a control group ($T_i=0$).\n- For each treated unit $i$:\n    a. A pool of candidate controls is formed from all available (unmatched) control units $j$.\n    b. The pool is filtered based on the matching rules:\n        - **Exact Match:** $C_{1,j} = C_{1,i}$ and $C_{2,j} = C_{2,i}$.\n        - **Caliper on Covariate:** $|X_i - X_j| \\le \\delta_x$.\n        - **Caliper on Propensity Score:** $|\\hat{e}_i - \\hat{e}_j| \\le \\delta_p$.\n    c. If the resulting pool of eligible controls is not empty, the control unit $j^*$ that minimizes the propensity score distance, $|\\hat{e}_i - \\hat{e}_{j^*}|$, is selected as the match.\n    d. The pair $(i, j^*)$ is recorded, and the control unit $j^*$ is marked as unavailable for future matches.\n    e. If no eligible control is found, the treated unit $i$ is discarded.\n\n**4. ATE Estimation and Bias Calculation**\n- After the matching process is complete, a set of $N_{\\text{matched}}$ pairs is obtained.\n- The estimated ATE is calculated as the simple mean of the outcome differences within these pairs:\n$$\n\\widehat{\\mathrm{ATE}} = \\frac{1}{N_{\\text{matched}}} \\sum_{(i,j) \\in \\text{matched pairs}} (Y_i - Y_j)\n$$\n- This estimator is an approximation of the Average Treatment Effect on the Treated (ATT). Under the constant treatment effect assumption of this problem, ATT = ATE.\n- Finally, the bias of the estimator is computed by comparing it to the true ATE, $\\tau=2.0$:\n$$\n\\text{Bias} = \\widehat{\\mathrm{ATE}} - \\tau\n$$\nThis entire process is repeated for each of the four test cases defined by different random seeds, sample sizes, and caliper widths.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (101, 800, 0.05, 0.5),\n        (202, 800, 0.02, 0.1),\n        (303, 800, 0.20, 2.0),\n        (404, 120, 0.05, 0.5),\n    ]\n\n    tau = 2.0\n    results = []\n\n    for seed, n_samples, delta_p, delta_x in test_cases:\n        bias = calculate_bias(seed, n_samples, delta_p, delta_x, tau)\n        results.append(f\"{bias:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_bias(seed, n_samples, delta_p, delta_x, tau):\n    \"\"\"\n    Calculates the bias of the ATE estimator for a single simulation case.\n    \"\"\"\n    # 1. Generate data\n    data = generate_data(seed, n_samples, tau)\n    X, C1, C2, T, Y = data['X'], data['C1'], data['C2'], data['T'], data['Y']\n    \n    # 2. Estimate propensity scores\n    e_hat = estimate_propensity_scores(X, C1, C2, T)\n    \n    # 3. Perform matching\n    matched_diffs = perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x)\n    \n    # 4. Calculate ATE and bias\n    if not matched_diffs:\n        # If no matches are found, the mean is undefined.\n        # A reasonable choice is to set the estimated ATE to 0, which is standard in some packages,\n        # though this implies a large bias. The problem setup makes this outcome unlikely.\n        ate_hat = 0.0\n    else:\n        ate_hat = np.mean(matched_diffs)\n    \n    bias = ate_hat - tau\n    return bias\n\ndef generate_data(seed, n_samples, tau):\n    \"\"\"\n    Generates data according to the problem's data-generating process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Confounders\n    C1 = rng.binomial(1, 0.5, size=n_samples)\n    C2 = rng.choice([0, 1, 2], size=n_samples, p=[0.4, 0.4, 0.2])\n    \n    mu = 0.5 * C1 + 0.3 * (C2 == 1) - 0.3 * (C2 == 2)\n    X = rng.normal(loc=mu, scale=1, size=n_samples)\n    \n    # Treatment assignment\n    alpha_0, alpha_X, alpha_C1 = 0.2, 0.8, 0.6\n    alpha_C2_1, alpha_C2_2 = 0.4, -0.4\n    \n    linear_pred_T = alpha_0 + alpha_X * X + alpha_C1 * C1 + \\\n                    alpha_C2_1 * (C2 == 1) + alpha_C2_2 * (C2 == 2)\n    propensity_true = 1 / (1 + np.exp(-linear_pred_T))\n    T = rng.binomial(1, propensity_true, size=n_samples)\n    \n    # Potential outcomes\n    gamma_0, gamma_X, gamma_C1 = 1.0, 1.0, 0.5\n    gamma_C2_1, gamma_C2_2 = 0.2, -0.2\n    \n    epsilon = rng.normal(0, 1, size=n_samples)\n    Y0 = gamma_0 + gamma_X * X + gamma_C1 * C1 + \\\n         gamma_C2_1 * (C2 == 1) + gamma_C2_2 * (C2 == 2) + epsilon\n    Y1 = Y0 + tau\n    \n    # Observed outcome\n    Y = T * Y1 + (1 - T) * Y0\n    \n    return {'X': X, 'C1': C1, 'C2': C2, 'T': T, 'Y': Y}\n\ndef estimate_propensity_scores(X, C1, C2, T):\n    \"\"\"\n    Estimates propensity scores using logistic regression with MLE.\n    \"\"\"\n    # Design matrix M\n    M = np.c_[np.ones(len(X)), X, C1, (C2 == 1).astype(int), (C2 == 2).astype(int)]\n    \n    def sigmoid(u):\n        return 1 / (1 + np.exp(-u))\n\n    def neg_log_likelihood(beta, M, T):\n        p = sigmoid(M @ beta)\n        # Add small epsilon to prevent log(0)\n        p = np.clip(p, 1e-9, 1 - 1e-9)\n        return -np.sum(T * np.log(p) + (1 - T) * np.log(1 - p))\n\n    def gradient(beta, M, T):\n        p = sigmoid(M @ beta)\n        return M.T @ (p - T)\n\n    initial_beta = np.zeros(M.shape[1])\n    res = minimize(neg_log_likelihood, initial_beta, args=(M, T), jac=gradient, method='BFGS')\n    \n    beta_hat = res.x\n    e_hat = sigmoid(M @ beta_hat)\n    \n    return e_hat\n\ndef perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x):\n    \"\"\"\n    Performs matching based on exact confounder match and calipers.\n    \"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    control_data = {\n        'C1': C1[control_indices],\n        'C2': C2[control_indices],\n        'X': X[control_indices],\n        'e_hat': e_hat[control_indices]\n    }\n    \n    is_control_available = np.ones(len(control_indices), dtype=bool)\n    matched_diffs = []\n\n    for i in treated_indices:\n        # Candidate controls must be available and match exactly on C1, C2\n        eligible_mask = (is_control_available)  \\\n                        (control_data['C1'] == C1[i])  \\\n                        (control_data['C2'] == C2[i])\n        \n        # Apply calipers\n        eligible_mask = (np.abs(control_data['X'] - X[i]) = delta_x)\n        eligible_mask = (np.abs(control_data['e_hat'] - e_hat[i]) = delta_p)\n        \n        candidate_control_local_indices = np.where(eligible_mask)[0]\n        \n        if len(candidate_control_local_indices) > 0:\n            # Find the best match among eligible candidates (nearest neighbor on propensity score)\n            prop_diffs = np.abs(control_data['e_hat'][candidate_control_local_indices] - e_hat[i])\n            best_match_local_idx = candidate_control_local_indices[np.argmin(prop_diffs)]\n            \n            # Get the global index of the matched control\n            best_match_global_idx = control_indices[best_match_local_idx]\n            \n            # Record the matched difference and update control availability\n            matched_diffs.append(Y[i] - Y[best_match_global_idx])\n            is_control_available[best_match_local_idx] = False\n            \n    return matched_diffs\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3163024"}]}