{"hands_on_practices": [{"introduction": "The core promise of self-training is to leverage vast pools of unlabeled data, but this comes with a fundamental risk: the model's own predictions, used as \"pseudo-labels,\" can be incorrect. This exercise provides a foundational analysis of this trade-off by asking you to quantify the expected error rate, or \"noise,\" introduced into the training set. By deriving an expression for this noise rate, you will gain a precise understanding of how the initial classifier's quality and the confidence threshold directly impact the success of a self-training procedure [@problem_id:3172749].", "problem": "Consider binary classification with labels $y \\in \\{0,1\\}$ and class prior $\\pi = \\Pr(y=1) \\in (0,1)$. A fixed classifier produces predictions $\\hat{y} \\in \\{0,1\\}$ with confusion rates $\\alpha = \\Pr(\\hat{y}=1 \\mid y=0)$ and $\\beta = \\Pr(\\hat{y}=0 \\mid y=1)$, and is equipped with calibrated confidence scores so that for any input $x$, the maximum predicted class probability is used as a confidence $c(x) \\in [0,1]$. In a self-training procedure, unlabeled inputs are pseudo-labeled by this classifier and added to the training set only if their confidence exceeds a fixed threshold $\\tau \\in (0.5,1)$.\n\nDefine the selection rates $s_{0}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=0)$ and $s_{1}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=1)$, and assume that, within each true class, crossing the threshold $\\tau$ is independent of whether the classifier predicts correctly, so that the confusion rates $\\alpha$ and $\\beta$ apply uniformly to the selected subset. Let $n_{L}$ denote the size of the labeled dataset and $n_{U}$ the size of the unlabeled pool. Suppose all selected unlabeled inputs are added, yielding an expected number $m = n_{U}\\big((1-\\pi)s_{0}(\\tau) + \\pi s_{1}(\\tau)\\big)$ of pseudo-labeled examples.\n\nUsing the law of total probability and the definition of empirical $0$-$1$ loss, derive an expression for the expected noise rate among the added pseudo labels at threshold $\\tau$, defined as\n$$\n\\eta(\\tau) = \\Pr\\big(\\hat{y} \\neq y \\,\\big|\\, c(X) \\ge \\tau\\big),\n$$\nin terms of $\\alpha$, $\\beta$, $\\pi$, $s_{0}(\\tau)$, and $s_{1}(\\tau)$. Then, analyze how this expected noise rate affects the empirical $0$-$1$ risk when retraining by Empirical Risk Minimization (ERM) on the augmented dataset under the simplifying assumption that the retrained classifier perfectly fits the added pseudo labels, giving the expected empirical $0$-$1$ loss on the augmented dataset as a function of $n_{L}$, the labeled empirical loss $R_{L}$, $m$, and $\\eta(\\tau)$.\n\nProvide your final answer as the closed-form analytic expression for $\\eta(\\tau)$. No rounding is required.", "solution": "The problem is evaluated as valid, as it is self-contained, scientifically grounded in statistical learning theory, and well-posed. We can proceed with the derivation.\n\nThe problem asks for two derivations. First, an expression for the expected noise rate $\\eta(\\tau)$ among the added pseudo-labels. Second, an analysis of the expected empirical $0$-$1$ loss on the augmented dataset.\n\n**Part 1: Derivation of the Expected Noise Rate $\\eta(\\tau)$**\n\nThe expected noise rate among the added pseudo-labels is defined as the probability that a pseudo-label is incorrect, conditioned on the instance being selected for pseudo-labeling. The selection criterion is that the confidence $c(X)$ exceeds a threshold $\\tau$. Formally, this is:\n$$\n\\eta(\\tau) = \\Pr\\big(\\hat{y} \\neq y \\,\\big|\\, c(X) \\ge \\tau\\big)\n$$\nWe use the definition of conditional probability:\n$$\n\\eta(\\tau) = \\frac{\\Pr(\\hat{y} \\neq y, c(X) \\ge \\tau)}{\\Pr(c(X) \\ge \\tau)}\n$$\nLet's denote the selection event as $S = \\{c(X) \\ge \\tau\\}$. The expression becomes:\n$$\n\\eta(\\tau) = \\frac{\\Pr(\\hat{y} \\neq y, S)}{\\Pr(S)}\n$$\nWe will evaluate the numerator and the denominator separately using the law of total probability, conditioning on the true class label $y \\in \\{0, 1\\}$.\n\nFirst, we compute the denominator, $\\Pr(S) = \\Pr(c(X) \\ge \\tau)$:\n$$\n\\Pr(S) = \\Pr(S \\mid y=0)\\Pr(y=0) + \\Pr(S \\mid y=1)\\Pr(y=1)\n$$\nFrom the problem statement, we are given:\n- The class prior $\\pi = \\Pr(y=1)$, which implies $\\Pr(y=0) = 1-\\pi$.\n- The class-conditional selection rates $s_{0}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=0)$ and $s_{1}(\\tau) = \\Pr(c(X) \\ge \\tau \\mid y=1)$.\n\nSubstituting these givens into the expression for $\\Pr(S)$:\n$$\n\\Pr(S) = s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi\n$$\n\nNext, we compute the numerator, $\\Pr(\\hat{y} \\neq y, S)$. Again, we use the law of total probability, conditioning on the true class $y$:\n$$\n\\Pr(\\hat{y} \\neq y, S) = \\Pr(\\hat{y} \\neq y, S \\mid y=0)\\Pr(y=0) + \\Pr(\\hat{y} \\neq y, S \\mid y=1)\\Pr(y=1)\n$$\nLet's analyze each term in the sum:\n1.  For the case $y=0$, an incorrect prediction means $\\hat{y}=1$. So, the first term is $\\Pr(\\hat{y} = 1, S \\mid y=0)\\Pr(y=0)$.\n2.  For the case $y=1$, an incorrect prediction means $\\hat{y}=0$. So, the second term is $\\Pr(\\hat{y} = 0, S \\mid y=1)\\Pr(y=1)$.\n\nThe problem states a crucial independence assumption: \"within each true class, crossing the threshold $\\tau$ is independent of whether the classifier predicts correctly\".\nThis can be formalized as:\n- Given $y=0$, the event of an incorrect prediction, $\\{\\hat{y}=1\\}$, is independent of the selection event $S$.\n  $$ \\Pr(\\hat{y}=1, S \\mid y=0) = \\Pr(\\hat{y}=1 \\mid y=0) \\Pr(S \\mid y=0) $$\n- Given $y=1$, the event of an incorrect prediction, $\\{\\hat{y}=0\\}$, is independent of the selection event $S$.\n  $$ \\Pr(\\hat{y}=0, S \\mid y=1) = \\Pr(\\hat{y}=0 \\mid y=1) \\Pr(S \\mid y=1) $$\n\nWe are given the confusion rates $\\alpha = \\Pr(\\hat{y}=1 \\mid y=0)$ and $\\beta = \\Pr(\\hat{y}=0 \\mid y=1)$. Using these and the selection rates, the conditional probabilities become:\n- $\\Pr(\\hat{y}=1, S \\mid y=0) = \\alpha \\cdot s_{0}(\\tau)$\n- $\\Pr(\\hat{y}=0, S \\mid y=1) = \\beta \\cdot s_{1}(\\tau)$\n\nNow, we can write the full expression for the numerator:\n$$\n\\Pr(\\hat{y} \\neq y, S) = \\big( \\alpha \\cdot s_{0}(\\tau) \\big) (1-\\pi) + \\big( \\beta \\cdot s_{1}(\\tau) \\big) \\pi\n$$\n\nFinally, we combine the numerator and denominator to obtain the expression for $\\eta(\\tau)$:\n$$\n\\eta(\\tau) = \\frac{\\alpha s_{0}(\\tau)(1-\\pi) + \\beta s_{1}(\\tau)\\pi}{s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi}\n$$\n\n**Part 2: Analysis of the Expected Empirical Risk**\n\nThe second part of the problem asks for the expected empirical $0$-$1$ loss on the augmented dataset. The augmented dataset $D_{aug}$ consists of the original labeled set $D_L$ of size $n_L$ and the set of pseudo-labeled examples $D_{pseudo}$ of size $m$. The total size is $n_L + m$.\n\nThe empirical $0$-$1$ loss on this augmented set for a retrained classifier $h_{new}$ must be evaluated with respect to the *true* labels to quantify the effect of noise. Let $y_i$ be the true label for an instance $x_i$. The true empirical loss is:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{1}{n_L + m} \\left( \\sum_{(x_i, y_i) \\in D_L} \\mathbb{I}(h_{new}(x_i) \\neq y_i) + \\sum_{(x_j, y_j) \\in D_{pseudo}} \\mathbb{I}(h_{new}(x_j) \\neq y_j) \\right)\n$$\nThe problem specifies that the retrained classifier \"perfectly fits the added pseudo labels\". This means that for any pseudo-labeled example $(x_j, \\hat{y}_j) \\in D_{pseudo}$, we have $h_{new}(x_j) = \\hat{y}_j$. Substituting this into the second sum:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{1}{n_L + m} \\left( \\sum_{(x_i, y_i) \\in D_L} \\mathbb{I}(h_{new}(x_i) \\neq y_i) + \\sum_{(x_j, y_j) \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j) \\right)\n$$\nThe first sum is the total loss on the original labeled set, which is given as $n_L R_L$, where $R_L$ is the labeled empirical loss for $h_{new}$. The expression becomes:\n$$\nR_{D_{aug}}^{true}(h_{new}) = \\frac{n_L R_L + \\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)}{n_L + m}\n$$\nWe need to find the *expected* empirical loss. The expectation is taken over the random selection of the unlabeled data.\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{1}{n_L+m} E\\left[ n_L R_L + \\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j) \\right]\n$$\nAssuming $R_L$ is a fixed outcome of the process, and using the linearity of expectation:\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{n_L R_L + E\\left[\\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)\\right]}{n_L+m}\n$$\nThe sum is over the $m$ selected pseudo-labeled examples. For each such example, indexed by $j$, the term $\\mathbb{I}(\\hat{y}_j \\neq y_j)$ is a Bernoulli random variable. Its expectation is the probability that its pseudo-label is incorrect. By definition, this is the probability of an incorrect prediction, given that the example was selected, which is precisely $\\eta(\\tau)$.\n$$\nE[\\mathbb{I}(\\hat{y}_j \\neq y_j)] = \\Pr(\\hat{y} \\neq y \\mid c(X) \\ge \\tau) = \\eta(\\tau)\n$$\nSince this holds for each of the $m$ i.i.d. selected examples, the expectation of the sum is:\n$$\nE\\left[\\sum_{j \\in D_{pseudo}} \\mathbb{I}(\\hat{y}_j \\neq y_j)\\right] = \\sum_{j=1}^{m} E[\\mathbb{I}(\\hat{y}_j \\neq y_j)] = \\sum_{j=1}^{m} \\eta(\\tau) = m \\eta(\\tau)\n$$\nSubstituting this back, the expected empirical $0$-$1$ loss on the augmented dataset is:\n$$\nE[R_{D_{aug}}^{true}(h_{new})] = \\frac{n_L R_L + m \\eta(\\tau)}{n_L + m}\n$$\nThis expression shows that the resulting effective loss is a weighted average of the loss on the original labeled data, $R_L$, and the noise rate of the pseudo-labels, $\\eta(\\tau)$.\n\nThe problem, however, only asks for the expression for $\\eta(\\tau)$ in the final answer.\n$$\n\\eta(\\tau) = \\frac{\\alpha s_0(\\tau)(1-\\pi) + \\beta s_1(\\tau)\\pi}{(1-\\pi)s_0(\\tau) + \\pi s_1(\\tau)}\n$$\nThis can also be written in a more compact form, but the current form is clear and directly derived.\nFinal check on the expression for final answer:\n$\\eta(\\tau) = \\frac{\\Pr(\\mathrm{error}, \\mathrm{selected})}{\\Pr(\\mathrm{selected})} = \\frac{\\Pr(\\mathrm{error}|y=0)\\Pr(y=0)\\Pr(\\mathrm{selected}|y=0) + \\Pr(\\mathrm{error}|y=1)\\Pr(y=1)\\Pr(\\mathrm{selected}|y=1)}{\\Pr(\\mathrm{selected}|y=0)\\Pr(y=0) + \\Pr(\\mathrm{selected}|y=1)\\Pr(y=1)}$.\nNo, this is wrong. The independence is conditional on $y$. So $\\Pr(\\mathrm{error}, \\mathrm{selected} | y=0) = \\Pr(\\mathrm{error}|y=0)\\Pr(\\mathrm{selected}|y=0)$.\n$\\Pr(\\mathrm{error}, \\mathrm{selected}) = \\Pr(\\mathrm{error}, \\mathrm{selected} | y=0) \\Pr(y=0) + \\Pr(\\mathrm{error}, \\mathrm{selected} | y=1) \\Pr(y=1) = \\Pr(\\mathrm{error} | y=0) \\Pr(\\mathrm{selected} | y=0) \\Pr(y=0) + \\Pr(\\mathrm{error} | y=1) \\Pr(\\mathrm{selected} | y=1) \\Pr(y=1)$.\n$\\Pr(\\mathrm{error}|y=0) = \\Pr(\\hat{y}=1|y=0) = \\alpha$.\n$\\Pr(\\mathrm{error}|y=1) = \\Pr(\\hat{y}=0|y=1) = \\beta$.\nSo the numerator is $\\alpha s_0(\\tau) (1-\\pi) + \\beta s_1(\\tau) \\pi$.\nThe denominator is $s_0(\\tau)(1-\\pi) + s_1(\\tau)\\pi$.\nThe derivation is correct.\nThe final answer is the expression for $\\eta(\\tau)$.", "answer": "$$\n\\boxed{\\frac{\\alpha s_{0}(\\tau)(1-\\pi) + \\beta s_{1}(\\tau)\\pi}{s_{0}(\\tau)(1-\\pi) + s_{1}(\\tau)\\pi}}\n$$", "id": "3172749"}, {"introduction": "While self-training can introduce noise, it can also, perhaps surprisingly, act as a denoising mechanism. This practice explores a scenario where the initial labeled dataset is already corrupted with significant label noise. You will investigate the conditions under which the pseudo-labels generated by a model trained on this noisy data are statistically cleaner than the original labels, thereby allowing self-training to improve model performance by purifying the dataset [@problem_id:3172790].", "problem": "Consider a binary classification problem with features $X \\in \\mathcal{X}$ and clean labels $Y \\in \\{0,1\\}$. You observe a labeled sample where each clean label is independently flipped with a symmetric label noise rate $\\rho \\in (0, \\tfrac{1}{2})$: for each example, with probability $\\rho$ the observed label equals $1-Y$ and with probability $1-\\rho$ it equals $Y$. You also have an unlabeled sample drawn from the same marginal distribution of $X$.\n\nA probabilistic classifier is trained on the noisy labeled sample to optimality in the sense that it returns, for any $x$, the corrupted posterior $g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid X=x)$, where $\\tilde{Y}$ denotes the observed noisy label. Define the clean posterior $\\eta(x) = \\mathbb{P}(Y=1 \\mid X=x)$.\n\nA single round of Self-Training (ST) is performed as follows. On the unlabeled sample, assign a pseudo-label $\\hat{Y}(x) \\in \\{0,1\\}$ equal to the Bayes decision with respect to $g(x)$, that is, $\\hat{Y}(x) = \\mathbf{1}\\{g(x) \\geq \\tfrac{1}{2}\\}$. Accept only those pseudo-labels whose confidence margin exceeds a fixed threshold $\\gamma \\in [0, \\tfrac{1}{2})$, meaning the accepted set is $\\{x: |g(x) - \\tfrac{1}{2}| \\geq \\gamma\\}$. Combine the original noisy labeled set with the accepted pseudo-labeled examples, and view the combined set as having an effective label noise rate equal to the fraction of incorrect labels relative to the clean labels $Y$.\n\nStarting from the definitions of symmetric label noise and conditional probabilities, derive the exact affine relationship between $g(x)$ and $\\eta(x)$. Then, using only this relationship and the acceptance rule $|g(x) - \\tfrac{1}{2}| \\geq \\gamma$, compute a distribution-free worst-case upper bound on the pseudo-label error rate among the accepted examples. Using this bound, determine the minimal confidence margin $\\gamma_{\\star}(\\rho)$ such that, for any $\\gamma \\geq \\gamma_{\\star}(\\rho)$ with $\\gamma  \\tfrac{1}{2} - \\rho$, the effective label noise rate after one ST round is strictly lower than the original noise rate $\\rho$, regardless of the distribution of $X$.\n\nYour final answer should be a single closed-form expression for $\\gamma_{\\star}(\\rho)$ in terms of $\\rho$. Do not include any inequalities in the final answer.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   **Problem Domain**: Binary classification.\n-   **Features and Labels**: $X \\in \\mathcal{X}$, clean labels $Y \\in \\{0, 1\\}$.\n-   **Noise Model**: Symmetric label noise with rate $\\rho \\in (0, \\frac{1}{2})$. The observed noisy label is $\\tilde{Y}$. For each example, $\\mathbb{P}(\\tilde{Y} = 1-Y) = \\rho$ and $\\mathbb{P}(\\tilde{Y} = Y) = 1-\\rho$, where the noise is independent of $X$.\n-   **Data**: A labeled sample with noisy labels $\\tilde{Y}$ and an unlabeled sample from the same marginal distribution of $X$.\n-   **Classifier**: A probabilistic classifier trained on the noisy data to optimality, yielding the corrupted posterior $g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid X=x)$.\n-   **Clean Posterior**: $\\eta(x) = \\mathbb{P}(Y=1 \\mid X=x)$.\n-   **Self-Training (ST) Rule**:\n    -   Pseudo-label assignment: $\\hat{Y}(x) = \\mathbf{1}\\{g(x) \\geq \\frac{1}{2}\\}$.\n    -   Acceptance criterion: Accept example $x$ if $|g(x) - \\frac{1}{2}| \\geq \\gamma$, for a fixed threshold $\\gamma \\in [0, \\frac{1}{2})$.\n-   **Objective**:\n    1.  Derive the relationship between $g(x)$ and $\\eta(x)$.\n    2.  Compute a distribution-free worst-case upper bound on the pseudo-label error rate for accepted examples.\n    3.  Find the minimal confidence margin $\\gamma_{\\star}(\\rho)$ such that for any $\\gamma \\geq \\gamma_{\\star}(\\rho)$ with $\\gamma  \\frac{1}{2} - \\rho$, the effective label noise rate of the combined dataset (original noisy set + accepted pseudo-labeled set) is strictly lower than $\\rho$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically sound, resting on established principles of statistical learning, in particular, learning with label noise and semi-supervised learning. The concepts of posterior probabilities, symmetric noise, and self-training are standard in the field. The problem is well-posed, with all terms and conditions precisely defined, leading to a request for a specific, derivable quantity. The language is objective and formal. The setup is self-contained and free of contradictions. The constraint $\\rho \\in (0, \\frac{1}{2})$ is standard, ensuring the labels are not completely random, and $\\gamma  \\frac{1}{2} - \\rho$ is a consistent constraint that becomes clear during the derivation. The problem is non-trivial and requires a rigorous mathematical derivation.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation\nThe solution proceeds in three stages as required by the problem statement.\n\n**1. Relationship between $g(x)$ and $\\eta(x)$**\n\nThe corrupted posterior $g(x)$ is defined as $g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid X=x)$. Using the law of total probability, we can expand this by conditioning on the clean label $Y$:\n$$g(x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=1, X=x)\\mathbb{P}(Y=1 \\mid X=x) + \\mathbb{P}(\\tilde{Y}=1 \\mid Y=0, X=x)\\mathbb{P}(Y=0 \\mid X=x)$$\nThe symmetric noise model states that the label flip probability is independent of the feature $X$. Therefore, $\\mathbb{P}(\\tilde{Y}=1 \\mid Y=1, X=x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=1) = 1-\\rho$ and $\\mathbb{P}(\\tilde{Y}=1 \\mid Y=0, X=x) = \\mathbb{P}(\\tilde{Y}=1 \\mid Y=0) = \\rho$. The clean posteriors are given by $\\eta(x) = \\mathbb{P}(Y=1 \\mid X=x)$ and $1-\\eta(x) = \\mathbb{P}(Y=0 \\mid X=x)$.\nSubstituting these into the equation for $g(x)$:\n$$g(x) = (1-\\rho)\\eta(x) + \\rho(1-\\eta(x))$$\n$$g(x) = (1-\\rho)\\eta(x) + \\rho - \\rho\\eta(x)$$\n$$g(x) = (1-2\\rho)\\eta(x) + \\rho$$\nThis is the affine relationship between the corrupted posterior $g(x)$ and the clean posterior $\\eta(x)$. Since $\\rho \\in (0, \\frac{1}{2})$, the term $1-2\\rho$ is non-zero, and we can invert this relationship to express $\\eta(x)$ in terms of $g(x)$:\n$$\\eta(x) = \\frac{g(x) - \\rho}{1-2\\rho}$$\n\n**2. Worst-Case Pseudo-Label Error Rate**\n\nA pseudo-label $\\hat{Y}(x)$ is assigned based on the Bayes decision rule for the corrupted posterior: $\\hat{Y}(x) = \\mathbf{1}\\{g(x) \\geq \\frac{1}{2}\\}$. An example is accepted for self-training if its confidence margin $|g(x) - \\frac{1}{2}|$ is at least $\\gamma$. This acceptance condition partitions the accepted set into two disjoint subsets:\n-   Set 1: $\\{x \\mid g(x) \\geq \\frac{1}{2} + \\gamma\\}$. For these examples, the pseudo-label is $\\hat{Y}(x) = 1$.\n-   Set 2: $\\{x \\mid g(x) \\leq \\frac{1}{2} - \\gamma\\}$. For these examples, the pseudo-label is $\\hat{Y}(x) = 0$.\n\nThe pseudo-label error rate for a given $x$ is the probability that the pseudo-label $\\hat{Y}(x)$ does not match the true clean label $Y$, i.e., $\\mathbb{P}(\\hat{Y}(x) \\neq Y \\mid X=x)$. Let us find an upper bound for this error rate for any accepted example.\n\nFor an example in Set 1 ($g(x) \\geq \\frac{1}{2} + \\gamma$ and $\\hat{Y}(x)=1$), an error occurs if the true label is $Y=0$. The probability of this is:\n$$\\mathbb{P}(Y=0 \\mid X=x) = 1 - \\eta(x) = 1 - \\frac{g(x) - \\rho}{1-2\\rho} = \\frac{(1-2\\rho) - (g(x) - \\rho)}{1-2\\rho} = \\frac{1 - \\rho - g(x)}{1-2\\rho}$$\nSince $1-2\\rho  0$, this error probability is a decreasing function of $g(x)$. To find a worst-case (maximum) bound, we must use the minimum possible value of $g(x)$ in this set, which is $g(x) = \\frac{1}{2} + \\gamma$.\n$$\\text{Error Rate (Set 1)} \\leq \\frac{1 - \\rho - (\\frac{1}{2} + \\gamma)}{1-2\\rho} = \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\n\nFor an example in Set 2 ($g(x) \\leq \\frac{1}{2} - \\gamma$ and $\\hat{Y}(x)=0$), an error occurs if the true label is $Y=1$. The probability of this is:\n$$\\mathbb{P}(Y=1 \\mid X=x) = \\eta(x) = \\frac{g(x) - \\rho}{1-2\\rho}$$\nSince $1-2\\rho  0$, this error probability is an increasing function of $g(x)$. To find a worst-case bound, we must use the maximum possible value of $g(x)$ in this set, which is $g(x) = \\frac{1}{2} - \\gamma$.\n$$\\text{Error Rate (Set 2)} \\leq \\frac{(\\frac{1}{2} - \\gamma) - \\rho}{1-2\\rho} = \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\nBoth cases yield the same worst-case error bound. This bound is independent of $x$ and the underlying data distribution, as long as the example satisfies the acceptance criterion. Let $\\rho_{\\text{ST}}$ denote the pseudo-label error rate on the accepted set. We have established a distribution-free upper bound:\n$$\\rho_{\\text{ST}} \\leq \\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}$$\n\n**3. Minimal Confidence Margin $\\gamma_{\\star}(\\rho)$**\n\nThe problem asks for the condition that ensures the effective label noise rate of the combined dataset is strictly lower than the original noise rate $\\rho$. Let the original noisy labeled set be $S_L$ with size $n_L$, and the set of accepted pseudo-labeled examples be $S_A$ with size $n_A$. The number of errors in $S_L$ is approximately $n_L \\rho$. The number of errors in $S_A$ is $n_A \\rho_{\\text{ST}}$.\nThe effective noise rate, $\\rho_{\\text{eff}}$, is the total number of errors divided by the total size of the combined dataset:\n$$\\rho_{\\text{eff}} = \\frac{n_L \\rho + n_A \\rho_{\\text{ST}}}{n_L + n_A}$$\nWe require $\\rho_{\\text{eff}}  \\rho$:\n$$\\frac{n_L \\rho + n_A \\rho_{\\text{ST}}}{n_L + n_A}  \\rho$$\n$$n_L \\rho + n_A \\rho_{\\text{ST}}  n_L \\rho + n_A \\rho$$\nAssuming $n_A  0$ (i.e., self-training adds some examples), this inequality simplifies to:\n$$\\rho_{\\text{ST}}  \\rho$$\nTo guarantee this condition holds regardless of the data distribution, we must enforce that the worst-case upper bound on $\\rho_{\\text{ST}}$ is strictly less than $\\rho$:\n$$\\frac{\\frac{1}{2} - \\rho - \\gamma}{1-2\\rho}  \\rho$$\nSince $\\rho \\in (0, \\frac{1}{2})$, we have $1-2\\rho  0$. We can multiply both sides by $1-2\\rho$ without changing the direction of the inequality:\n$$\\frac{1}{2} - \\rho - \\gamma  \\rho(1-2\\rho)$$\n$$\\frac{1}{2} - \\rho - \\gamma  \\rho - 2\\rho^2$$\nNow, we solve for $\\gamma$:\n$$\\frac{1}{2} - 2\\rho + 2\\rho^2  \\gamma$$\nThis inequality specifies the condition that $\\gamma$ must satisfy to guarantee a reduction in noise rate. The problem asks for the minimal confidence margin $\\gamma_{\\star}(\\rho)$ such that for any $\\gamma \\geq \\gamma_{\\star}(\\rho)$, this condition holds. This minimal value is the lower bound of the derived interval for $\\gamma$.\nTherefore, the minimal confidence margin is:\n$$\\gamma_{\\star}(\\rho) = \\frac{1}{2} - 2\\rho + 2\\rho^2$$\nThis can also be written as $\\gamma_{\\star}(\\rho) = 2(\\rho - \\frac{1}{2})^2$. The problem constraint $\\gamma  \\frac{1}{2} - \\rho$ ensures that $\\gamma_{\\star}(\\rho)$ is a valid choice, as $2(\\rho - \\frac{1}{2})^2  \\frac{1}{2} - \\rho$ for $\\rho \\in (0, \\frac{1}{2})$.", "answer": "$$\\boxed{\\frac{1}{2} - 2\\rho + 2\\rho^2}$$", "id": "3172790"}, {"introduction": "A critical challenge in real-world applications is that the unlabeled data pool may contain inputs from classes the model has never seen before (out-of-distribution data). Blindly applying self-training in this setting can lead to catastrophic error accumulation as the model confidently mislabels these novel inputs. This exercise guides you through the process of designing a probabilistic safeguard, using Bayes decision theory to determine an optimal threshold for an anomaly detector that can identify and reject such inputs, thereby protecting the integrity of the semi-supervised learning process [@problem_id:3172796].", "problem": "A classifier with parameters $\\theta$ produces a categorical distribution $p_{\\theta}(y \\mid x)$ over $K$ seen classes for each input $x$ via the softmax transformation applied to its logits. In semi-supervised learning with self-training, unlabeled inputs $\\{x_{i}\\}$ are assigned pseudo-labels when the model is sufficiently confident, and are otherwise held out. However, the unlabeled pool also contains inputs from an unseen class (out-of-distribution, OOD), which must be prevented from being pseudo-labeled to avoid error accumulation.\n\nConsider an anomaly detector that thresholds the Shannon entropy $H(p_{\\theta}(x)) = -\\sum_{j=1}^{K} p_{\\theta,j}(x) \\ln p_{\\theta,j}(x)$: declare an input $x$ as in-distribution (eligible for pseudo-labeling) if $H(p_{\\theta}(x)) \\leq \\tau$, and otherwise declare it anomalous (reject). This detector is equivalent in spirit to thresholding an energy score $E(x) = -\\ln\\left(\\sum_{j=1}^{K} \\exp(z_{j}(x))\\right)$ when the softmax logits $z_{j}(x)$ are well-calibrated, since higher uncertainty (flatter softmax) simultaneously increases entropy and energy.\n\nAssume the following scientifically plausible model for entropy under the two regimes:\n- For inputs from seen classes, $H \\mid \\text{seen} \\sim \\mathcal{N}(\\mu_{s}, \\sigma^{2})$ with $\\mu_{s} = 0.4$ and $\\sigma = 0.25$ (nats).\n- For inputs from the unseen class, $H \\mid \\text{unseen} \\sim \\mathcal{N}(\\mu_{u}, \\sigma^{2})$ with $\\mu_{u} = 1.3$ and the same $\\sigma = 0.25$ (nats).\n\nLet the prior probabilities in the unlabeled pool be $\\pi_{s} = 0.85$ for seen-class inputs and $\\pi_{u} = 0.15$ for unseen-class inputs. Suppose the cost of a false acceptance (declaring unseen as seen, which leads to mislabeling) is $C_{\\text{FA}} = 4$, while the cost of a false rejection (declaring seen as unseen, which forgoes a useful pseudo-label) is $C_{\\text{FR}} = 1$.\n\nStarting from the principles of Bayes decision theory and the definitions above, derive the Bayes-optimal threshold $\\tau^{\\star}$ that minimizes the expected cost of detection trade-offs under this entropy-thresholding rule. Then compute the numerical value of $\\tau^{\\star}$ using the given parameters. Round your final numeric answer to four significant figures and express it in nats.", "solution": "The problem asks for the Bayes-optimal decision threshold $\\tau^{\\star}$ for classifying an input as belonging to a 'seen' or 'unseen' class based on the Shannon entropy $H$ of a model's prediction. The optimal threshold is the one that minimizes the total expected cost (Bayes risk) associated with classification errors.\n\nThe decision rule is defined as:\n- Declare 'seen' if the observed entropy $h \\leq \\tau$.\n- Declare 'unseen' if the observed entropy $h  \\tau$.\n\nThe two types of errors and their associated costs are:\n1.  **False Acceptance (FA)**: Declaring an 'unseen' input as 'seen'. This occurs when the true class is 'unseen' but $h \\leq \\tau$. The cost is $C_{\\text{FA}} = 4$.\n2.  **False Rejection (FR)**: Declaring a 'seen' input as 'unseen'. This occurs when the true class is 'seen' but $h  \\tau$. The cost is $C_{\\text{FR}} = 1$.\n\nThe prior probabilities for the classes are given as $\\pi_{s} = P(\\text{seen}) = 0.85$ and $\\pi_{u} = P(\\text{unseen}) = 0.15$.\n\nThe conditional distributions of the entropy $H$ for each class are given as Normal distributions:\n- For 'seen' inputs: $p(h|\\text{seen}) = p_s(h) = \\mathcal{N}(h; \\mu_s, \\sigma^2)$, with $\\mu_s = 0.4$ and $\\sigma = 0.25$.\n- For 'unseen' inputs: $p(h|\\text{unseen}) = p_u(h) = \\mathcal{N}(h; \\mu_u, \\sigma^2)$, with $\\mu_u = 1.3$ and $\\sigma = 0.25$.\n\nAccording to Bayes decision theory, we must minimize the expected cost, or risk, $R(\\tau)$. The risk is the sum of the costs of each type of error, weighted by their respective probabilities of occurrence.\n\nThe probability of a false acceptance is the joint probability of the input being 'unseen' and being declared 'seen':\n$$ P(\\text{FA}) = P(h \\leq \\tau, \\text{unseen}) = P(h \\leq \\tau | \\text{unseen}) P(\\text{unseen}) = \\pi_u \\int_{-\\infty}^{\\tau} p_u(h) \\, dh $$\nThe probability of a false rejection is the joint probability of the input being 'seen' and being declared 'unseen':\n$$ P(\\text{FR}) = P(h  \\tau, \\text{seen}) = P(h  \\tau | \\text{seen}) P(\\text{seen}) = \\pi_s \\int_{\\tau}^{\\infty} p_s(h) \\, dh $$\n\nThe total expected cost $R(\\tau)$ is the sum of the products of the costs and their probabilities:\n$$ R(\\tau) = C_{\\text{FA}} P(\\text{FA}) + C_{\\text{FR}} P(\\text{FR}) $$\n$$ R(\\tau) = C_{\\text{FA}} \\pi_u \\int_{-\\infty}^{\\tau} p_u(h) \\, dh + C_{\\text{FR}} \\pi_s \\int_{\\tau}^{\\infty} p_s(h) \\, dh $$\n\nTo find the optimal threshold $\\tau^{\\star}$ that minimizes $R(\\tau)$, we differentiate $R(\\tau)$ with respect to $\\tau$ and set the derivative to zero. Using the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule):\n$$ \\frac{d}{d\\tau} \\int_{-\\infty}^{\\tau} f(x) \\, dx = f(\\tau) $$\n$$ \\frac{d}{d\\tau} \\int_{\\tau}^{\\infty} f(x) \\, dx = -f(\\tau) $$\n\nApplying this to the risk function $R(\\tau)$:\n$$ \\frac{dR(\\tau)}{d\\tau} = C_{\\text{FA}} \\pi_u p_u(\\tau) + C_{\\text{FR}} \\pi_s (-p_s(\\tau)) $$\nSetting the derivative to zero to find the minimum:\n$$ C_{\\text{FA}} \\pi_u p_u(\\tau^{\\star}) - C_{\\text{FR}} \\pi_s p_s(\\tau^{\\star}) = 0 $$\n$$ C_{\\text{FA}} \\pi_u p_u(\\tau^{\\star}) = C_{\\text{FR}} \\pi_s p_s(\\tau^{\\star}) $$\nThis equation defines the Bayes-optimal threshold $\\tau^{\\star}$. It signifies that at the decision boundary, the weighted likelihoods of the two classes are equal, where the weights are the products of the costs and prior probabilities.\n\nNow, we substitute the probability density functions (PDFs) for the Normal distributions:\n$$ p_s(h) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(h - \\mu_s)^2}{2\\sigma^2}\\right) $$\n$$ p_u(h) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(h - \\mu_u)^2}{2\\sigma^2}\\right) $$\nPlugging these into the optimality condition for $\\tau = \\tau^{\\star}$:\n$$ C_{\\text{FA}} \\pi_u \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(\\tau - \\mu_u)^2}{2\\sigma^2}\\right) = C_{\\text{FR}} \\pi_s \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(\\tau - \\mu_s)^2}{2\\sigma^2}\\right) $$\nThe normalization constant $\\frac{1}{\\sqrt{2\\pi}\\sigma}$ cancels from both sides:\n$$ C_{\\text{FA}} \\pi_u \\exp\\left(-\\frac{(\\tau - \\mu_u)^2}{2\\sigma^2}\\right) = C_{\\text{FR}} \\pi_s \\exp\\left(-\\frac{(\\tau - \\mu_s)^2}{2\\sigma^2}\\right) $$\nTo solve for $\\tau$, we take the natural logarithm of both sides:\n$$ \\ln(C_{\\text{FA}} \\pi_u) - \\frac{(\\tau - \\mu_u)^2}{2\\sigma^2} = \\ln(C_{\\text{FR}} \\pi_s) - \\frac{(\\tau - \\mu_s)^2}{2\\sigma^2} $$\nRearranging the terms to isolate $\\tau$:\n$$ \\frac{(\\tau - \\mu_s)^2}{2\\sigma^2} - \\frac{(\\tau - \\mu_u)^2}{2\\sigma^2} = \\ln(C_{\\text{FR}} \\pi_s) - \\ln(C_{\\text{FA}} \\pi_u) $$\nMultiplying by $2\\sigma^2$ and expanding the squared terms:\n$$ (\\tau^2 - 2\\tau\\mu_s + \\mu_s^2) - (\\tau^2 - 2\\tau\\mu_u + \\mu_u^2) = 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nThe $\\tau^2$ terms cancel out:\n$$ 2\\tau\\mu_u - 2\\tau\\mu_s + \\mu_s^2 - \\mu_u^2 = 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\n$$ 2\\tau(\\mu_u - \\mu_s) = \\mu_u^2 - \\mu_s^2 + 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nFactoring $\\mu_u^2 - \\mu_s^2 = (\\mu_u - \\mu_s)(\\mu_u + \\mu_s)$:\n$$ 2\\tau(\\mu_u - \\mu_s) = (\\mu_u - \\mu_s)(\\mu_u + \\mu_s) + 2\\sigma^2 \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nSince $\\mu_u \\neq \\mu_s$, we can divide by $2(\\mu_u - \\mu_s)$:\n$$ \\tau = \\frac{\\mu_u + \\mu_s}{2} + \\frac{\\sigma^2}{\\mu_u - \\mu_s} \\ln\\left(\\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u}\\right) $$\nThis is the analytical expression for the Bayes-optimal threshold $\\tau^{\\star}$.\n\nNow, we substitute the given numerical values:\n$\\mu_{s} = 0.4$, $\\mu_{u} = 1.3$, $\\sigma = 0.25$, $\\pi_{s} = 0.85$, $\\pi_{u} = 0.15$, $C_{\\text{FR}} = 1$, $C_{\\text{FA}} = 4$.\n\nThe first term is the midpoint of the means:\n$$ \\frac{\\mu_u + \\mu_s}{2} = \\frac{1.3 + 0.4}{2} = \\frac{1.7}{2} = 0.85 $$\nThe argument of the logarithm is:\n$$ \\frac{C_{\\text{FR}} \\pi_s}{C_{\\text{FA}} \\pi_u} = \\frac{1 \\times 0.85}{4 \\times 0.15} = \\frac{0.85}{0.60} = \\frac{17}{12} $$\nThe remaining terms are:\n$$ \\mu_u - \\mu_s = 1.3 - 0.4 = 0.9 $$\n$$ \\sigma^2 = (0.25)^2 = 0.0625 $$\nSubstituting these into the expression for $\\tau^{\\star}$:\n$$ \\tau^{\\star} = 0.85 + \\frac{0.0625}{0.9} \\ln\\left(\\frac{17}{12}\\right) $$\nNow we compute the numerical value:\n$$ \\ln\\left(\\frac{17}{12}\\right) \\approx \\ln(1.41666...) \\approx 0.3483203 $$\n$$ \\frac{0.0625}{0.9} = \\frac{625 \\times 10^{-4}}{9 \\times 10^{-1}} = \\frac{625}{9000} = \\frac{5}{72} \\approx 0.0694444 $$\nCombining these:\n$$ \\tau^{\\star} \\approx 0.85 + (0.0694444) \\times (0.3483203) $$\n$$ \\tau^{\\star} \\approx 0.85 + 0.0241889 $$\n$$ \\tau^{\\star} \\approx 0.8741889 $$\nRounding the result to four significant figures gives $0.8742$.\nThe unit is nats, as the entropy is calculated using the natural logarithm.", "answer": "$$\n\\boxed{0.8742}\n$$", "id": "3172796"}]}