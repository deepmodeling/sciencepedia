{"hands_on_practices": [{"introduction": "Our choice of loss function during training is a critical design decision, often motivated by computational convenience or robustness to outliers. However, the true measure of performance might be dictated by a different cost structure in the real world. This practice explores the consequences of such a mismatch, quantifying the \"excess risk\" that arises when we train a model by minimizing the absolute error ($\\ell_1$ loss) but ultimately evaluate it using squared error ($\\ell_2$ loss). By working through this hypothetical scenario, you will connect the choice of a loss function to fundamental population statistics—the median and the mean—and understand when and why this misalignment can lead to suboptimal performance.", "problem": "Consider independent and identically distributed (i.i.d.) observations $\\{Y_i\\}_{i=1}^{n}$ drawn from the distribution $Y=\\mu+X$, where $X$ has the exponential distribution with rate parameter $\\lambda>0$. You consider the hypothesis class of constant predictors $\\{f_{\\theta}:\\theta\\in\\mathbb{R}\\}$ with $f_{\\theta}(x)=\\theta$ for all inputs. Training is performed by minimizing the empirical risk under the absolute loss $\\ell_{1}(y,\\theta)=|y-\\theta|$, that is, you choose an empirical risk minimizer $\\hat{\\theta}_{n}\\in\\arg\\min_{\\theta}\\hat{R}_{\\ell_{1}}(\\theta)$ with $\\hat{R}_{\\ell_{1}}(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$. Evaluation, however, is performed under the squared loss $\\ell_{2}(y,\\theta)=(y-\\theta)^{2}$ with expected risk $R_{\\ell_{2}}(\\theta)=\\mathbb{E}[(Y-\\theta)^{2}]$.\n\nStarting only from the definitions of empirical risk and expected risk for $\\ell_{1}$ and $\\ell_{2}$, and fundamental properties of expectations and quantiles, do the following in the large-sample limit $n\\to\\infty$:\n1. Argue which population parameter the empirical $\\ell_{1}$ minimizer converges to, and which population parameter minimizes the expected $\\ell_{2}$ risk, within the chosen hypothesis class.\n2. Define the asymptotic excess $\\ell_{2}$ risk of the $\\ell_{1}$-trained predictor by $\\mathcal{E}=R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star})-\\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta)$, where $\\theta_{\\ell_{1}}^{\\star}$ is the almost sure limit of $\\hat{\\theta}_{n}$ as $n\\to\\infty$. Derive a closed-form expression for $\\mathcal{E}$ in terms of $\\lambda$ only.\n3. State the alignment condition, in terms of population statistics, under which $\\mathcal{E}=0$, and discuss whether this condition can hold for the given exponential-shifted model.\n\nProvide the exact closed-form expression for $\\mathcal{E}$ as your final answer. Do not approximate or round your result.", "solution": "The problem asks for an analysis of the performance mismatch that arises when a model is trained using one loss function but evaluated using another. Specifically, we consider a constant predictor $f_{\\theta}(x) = \\theta$ trained by minimizing the empirical $\\ell_{1}$ risk (absolute loss) and evaluated on its asymptotic expected $\\ell_{2}$ risk (squared loss). The data $\\{Y_i\\}_{i=1}^{n}$ are i.i.d. samples from $Y = \\mu + X$, where $X$ follows an exponential distribution with rate $\\lambda > 0$.\n\nFirst, we address the three parts of the problem: identifying the relevant population parameters, deriving the asymptotic excess risk, and discussing the alignment condition.\n\n1. Population Parameters for $\\ell_{1}$ and $\\ell_{2}$ Risk Minimization\n\nThe training process involves finding $\\hat{\\theta}_{n} \\in \\arg\\min_{\\theta} \\hat{R}_{\\ell_{1}}(\\theta)$, where the empirical risk is $\\hat{R}_{\\ell_{1}}(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$. It is a fundamental result in statistics that the value of $\\theta$ which minimizes the sum of absolute differences to a set of points $\\{Y_i\\}_{i=1}^n$ is the sample median of those points. Therefore, $\\hat{\\theta}_{n} = \\text{median}(\\{Y_i\\}_{i=1}^n)$.\nAs the sample size $n$ tends to infinity, the sample median converges almost surely to the population median. The problem defines $\\theta_{\\ell_{1}}^{\\star}$ as this limit. Thus,\n$$ \\theta_{\\ell_{1}}^{\\star} = \\lim_{n\\to\\infty} \\hat{\\theta}_{n} = \\text{median}(Y) $$\nThe evaluation is performed using the expected $\\ell_{2}$ risk, $R_{\\ell_{2}}(\\theta) = \\mathbb{E}[(Y-\\theta)^{2}]$. To find the parameter $\\theta$ that minimizes this risk, we can differentiate $R_{\\ell_{2}}(\\theta)$ with respect to $\\theta$ and set the derivative to zero.\n$$ \\frac{d}{d\\theta}R_{\\ell_{2}}(\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[(Y-\\theta)^{2}] = \\mathbb{E}\\left[\\frac{\\partial}{\\partial\\theta}(Y-\\theta)^{2}\\right] = \\mathbb{E}[-2(Y-\\theta)] = -2(\\mathbb{E}[Y] - \\theta) $$\nSetting this derivative to zero yields $\\theta = \\mathbb{E}[Y]$. The second derivative is $\\frac{d^2}{d\\theta^2}R_{\\ell_{2}}(\\theta) = 2 > 0$, confirming that this value of $\\theta$ is indeed a minimizer. The optimal parameter under the expected squared loss is the population mean. We denote this minimizer as $\\theta_{\\ell_2}^\\star$:\n$$ \\theta_{\\ell_2}^\\star = \\arg\\inf_{\\theta \\in \\mathbb{R}} R_{\\ell_2}(\\theta) = \\mathbb{E}[Y] $$\nIn summary, the empirical $\\ell_{1}$ minimizer converges to the population median, while the expected $\\ell_{2}$ risk is minimized by the population mean.\n\n2. Derivation of the Asymptotic Excess $\\ell_{2}$ Risk\n\nThe asymptotic excess $\\ell_{2}$ risk, $\\mathcal{E}$, measures the penalty for using the $\\ell_{1}$-optimal parameter, $\\theta_{\\ell_1}^\\star$, in the context of $\\ell_2$ evaluation. It is defined as:\n$$ \\mathcal{E} = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - \\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta) = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - R_{\\ell_2}(\\theta_{\\ell_2}^\\star) $$\nUsing the identity $R_{\\ell_2}(\\theta) = \\mathbb{E}[(Y-\\theta)^2] = \\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta)^2$, we can express the excess risk as:\n$$ \\mathcal{E} = \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{1}}^{\\star})^2\\right) - \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{2}}^{\\star})^2\\right) $$\nSince $\\theta_{\\ell_2}^\\star = \\mathbb{E}[Y]$, the second term simplifies, and we obtain:\n$$ \\mathcal{E} = (\\mathbb{E}[Y] - \\theta_{\\ell_{1}}^{\\star})^2 = (\\mathbb{E}[Y] - \\text{median}(Y))^2 $$\nTo find a closed-form expression, we must compute the mean and median of the specified distribution $Y = \\mu + X$, where $X \\sim \\text{Exp}(\\lambda)$. The probability density function of $X$ is $f_X(x) = \\lambda \\exp(-\\lambda x)$ for $x \\ge 0$.\n\nThe mean of $Y$ is:\n$$ \\mathbb{E}[Y] = \\mathbb{E}[\\mu + X] = \\mu + \\mathbb{E}[X] $$\nThe mean of an exponential distribution with rate $\\lambda$ is $\\mathbb{E}[X] = \\frac{1}{\\lambda}$. Therefore,\n$$ \\mathbb{E}[Y] = \\mu + \\frac{1}{\\lambda} $$\nThe median of $Y$, which we denote $m_Y$, is the value such that $P(Y \\le m_Y) = 1/2$.\n$$ P(Y \\le m_Y) = P(\\mu + X \\le m_Y) = P(X \\le m_Y - \\mu) = \\int_{0}^{m_Y - \\mu} \\lambda \\exp(-\\lambda x) dx = 1 - \\exp(-\\lambda(m_Y - \\mu)) $$\nSetting this probability to $1/2$:\n$$ 1 - \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} \\implies \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} $$\nTaking the natural logarithm of both sides:\n$$ -\\lambda(m_Y - \\mu) = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2) \\implies m_Y - \\mu = \\frac{\\ln(2)}{\\lambda} $$\nThus, the median of $Y$ is:\n$$ \\text{median}(Y) = m_Y = \\mu + \\frac{\\ln(2)}{\\lambda} $$\nNow we can compute the excess risk $\\mathcal{E}$ by substituting the mean and median into our expression:\n$$ \\mathcal{E} = \\left( \\left(\\mu + \\frac{1}{\\lambda}\\right) - \\left(\\mu + \\frac{\\ln(2)}{\\lambda}\\right) \\right)^2 = \\left( \\frac{1}{\\lambda} - \\frac{\\ln(2)}{\\lambda} \\right)^2 $$\nThis simplifies to the final closed-form expression in terms of $\\lambda$:\n$$ \\mathcal{E} = \\frac{(1 - \\ln(2))^2}{\\lambda^2} $$\n\n3. Alignment Condition\n\nThe alignment condition is the condition under which the excess risk $\\mathcal{E}$ is zero. From our derivation, $\\mathcal{E} = (\\mathbb{E}[Y] - \\text{median}(Y))^2$. This quantity is zero if and only if:\n$$ \\mathbb{E}[Y] = \\text{median}(Y) $$\nIn terms of population statistics, alignment occurs when the population mean is equal to the population median. In this scenario, the optimal parameter for the training loss function ($\\ell_1$) is the same as the optimal parameter for the evaluation loss function ($\\ell_2$), resulting in no performance degradation due to the mismatch.\n\nFor the given exponential-shifted model, this condition would require:\n$$ \\mu + \\frac{1}{\\lambda} = \\mu + \\frac{\\ln(2)}{\\lambda} $$\nSince $\\lambda > 0$, this simplifies to $1 = \\ln(2)$. However, this is a false statement, as $\\ln(2) \\approx 0.6931$. The exponential distribution is a skewed distribution, for which the mean and median do not coincide. Specifically, since $1 > \\ln(2)$, the mean is always greater than the median for any $\\lambda > 0$. Consequently, the alignment condition can never hold for this model, and the asymptotic excess risk $\\mathcal{E}$ is always strictly positive.", "answer": "$$\n\\boxed{\\frac{\\left(1 - \\ln(2)\\right)^2}{\\lambda^2}}\n$$", "id": "3123205"}, {"introduction": "A core assumption in machine learning is that our training data is a faithful representation of the world in which our model will operate. This is often not the case; for instance, medical datasets may over-sample rare diseases, creating a mismatch between the sample's class balance and the population's. This exercise demonstrates how naively computing empirical risk on such an unrepresentative sample leads to a biased estimate of the true generalization error. You will implement the principle of importance weighting to correct for this dataset shift, deriving an unbiased risk estimator and analyzing its statistical variance.", "problem": "Consider a binary classification task with labels $Y \\in \\{0,1\\}$ and a fixed classifier $h$. The loss is the zero-one loss $\\ell(h(X),Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$. The population of interest is balanced, meaning the target label distribution satisfies $\\mathbb{P}(Y=1)=\\mathbb{P}(Y=0)=\\frac{1}{2}$. However, a training sample is drawn from an unbalanced case-control design in which the sampling distribution over labels is $\\mathbb{P}_{\\text{sample}}(Y=1)=0.8$ and $\\mathbb{P}_{\\text{sample}}(Y=0)=0.2$. Suppose the classifier has class-conditional error rates that are invariant across population and sample: when $Y=1$, the misclassification probability is $\\alpha=0.1$, and when $Y=0$, the misclassification probability is $\\beta=0.3$. Assume observations are independent and identically distributed (i.i.d.) under the sampling distribution, and that conditional on $Y$, losses across examples are independent Bernoulli random variables with parameters $\\alpha$ for $Y=1$ and $\\beta$ for $Y=0$. The sample size is $n=1000$.\n\nUsing only fundamental definitions of expected risk and empirical risk, and the principle of importance weighting, do the following:\n\n(a) Define the expected risk under the balanced target population and compute its value in terms of $\\alpha$ and $\\beta$.\n\n(b) Define the expected value of the naive empirical risk computed by averaging $\\ell(h(X),Y)$ over the unbalanced sample without any reweighting, and compute its value in terms of the given parameters.\n\n(c) Design a class-based reweighting scheme that yields an unbiased estimator of the balanced population risk when applied to the unbalanced sample. Justify why it is unbiased from first principles.\n\n(d) Derive the variance of the reweighted empirical risk estimator under the unbalanced sampling distribution, and then calculate its numerical value for the given parameters and $n=1000$.\n\nRound your final numerical answer to four significant figures. Express the final answer as a decimal in scientific notation. Do not use a percentage sign anywhere in your answer.", "solution": "This problem explores the relationship between population risk (generalization error) and empirical risk, particularly in the context of a dataset shift where the training sample distribution differs from the target population distribution. We will use the principle of importance weighting to correct for this mismatch.\n\nLet $P$ denote the target (balanced) data-generating distribution and $P_{\\text{sample}}$ denote the sampling (unbalanced) distribution. The loss function is the zero-one loss, $\\ell(h(X), Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$. The given class-conditional error rates are $\\alpha = \\mathbb{P}(h(X) \\neq 1 | Y=1) = 0.1$ and $\\beta = \\mathbb{P}(h(X) \\neq 0 | Y=0) = 0.3$. These rates are assumed to be invariant with respect to the distribution, meaning $\\mathbb{P}_{\\text{sample}}(h(X) \\neq y | Y=y) = \\mathbb{P}(h(X) \\neq y | Y=y)$ for $y \\in \\{0,1\\}$.\n\n(a) Expected risk under the balanced target population.\n\nThe expected risk, or generalization error, $R(h)$, is the expected loss with respect to the target population distribution $P(X,Y)$.\n$$R(h) = \\mathbb{E}_{P(X,Y)}[\\ell(h(X), Y)]$$\nUsing the law of total expectation, we can condition on the label $Y$:\n$$R(h) = \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\nThis simplifies to:\n$$R(h) = \\mathbb{P}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\nIn the balanced target population, $\\mathbb{P}(Y=1) = \\mathbb{P}(Y=0) = \\frac{1}{2}$. Substituting the given values:\n$$R(h) = \\left(\\frac{1}{2}\\right) \\alpha + \\left(\\frac{1}{2}\\right) \\beta = \\frac{1}{2}(\\alpha + \\beta)$$\n$$R(h) = \\frac{1}{2}(0.1 + 0.3) = \\frac{1}{2}(0.4) = 0.2$$\n\n(b) Expected value of the naive empirical risk.\n\nThe naive empirical risk is the average loss computed over the unbalanced sample of size $n$, drawn from $P_{\\text{sample}}$.\n$$\\hat{R}_{\\text{naive}}(h) = \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i), \\quad \\text{where } (X_i, Y_i) \\sim P_{\\text{sample}}$$\nThe expected value of this estimator is taken with respect to the sampling distribution $P_{\\text{sample}}$. Due to the linearity of expectation and the i.i.d. nature of the sample:\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i) \\right] = \\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)]$$\nThis is the expected risk under the sampling distribution. Applying the law of total expectation again, but with the sampling probabilities for $Y$:\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)] = \\mathbb{P}_{\\text{sample}}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\nWe are given $\\mathbb{P}_{\\text{sample}}(Y=1) = 0.8$ and $\\mathbb{P}_{\\text{sample}}(Y=0) = 0.2$.\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = (0.8)\\alpha + (0.2)\\beta = (0.8)(0.1) + (0.2)(0.3) = 0.08 + 0.06 = 0.14$$\n\n(c) Reweighting scheme for an unbiased estimator.\n\nTo obtain an unbiased estimator of the target risk $R(h)$ from a sample drawn from $P_{\\text{sample}}$, we use importance weighting. The weight for an observation $(x,y)$ is the ratio of its probability under the target distribution to its probability under the sampling distribution: $w(x,y) = \\frac{P(x,y)}{P_{\\text{sample}}(x,y)}$.\nSince the conditional distribution $P(X|Y)$ is invariant, we have $P(x,y) = P(y) P(x|y)$ and $P_{\\text{sample}}(x,y) = P_{\\text{sample}}(y) P(x|y)$. The weight simplifies to be dependent only on the class label $y$:\n$$w(y) = \\frac{P(y) P(x|y)}{P_{\\text{sample}}(y) P(x|y)} = \\frac{P(y)}{P_{\\text{sample}}(y)}$$\nWe define two weights, one for each class:\nWeight for $Y=1$: $w_1 = w(1) = \\frac{\\mathbb{P}(Y=1)}{\\mathbb{P}_{\\text{sample}}(Y=1)} = \\frac{0.5}{0.8} = \\frac{5}{8} = 0.625$.\nWeight for $Y=0$: $w_0 = w(0) = \\frac{\\mathbb{P}(Y=0)}{\\mathbb{P}_{\\text{sample}}(Y=0)} = \\frac{0.5}{0.2} = \\frac{5}{2} = 2.5$.\nThe reweighted empirical risk estimator, $\\hat{R}_{\\text{rw}}(h)$, is:\n$$\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i)$$\nTo justify that it is unbiased, we compute its expectation with respect to the sampling distribution $P_{\\text{sample}}$:\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i) \\right]$$\n$$= \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)]$$\nUsing the law of total expectation:\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\mathbb{E}_{P_{\\text{sample}}(X|Y=y)}[w(y) \\ell(h(X), y) | Y=y]$$\nSince $w(y)$ is constant given $y$:\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) w(y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\nSubstituting $w(y) = \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)}$:\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)} \\mathbb{P}(h(X) \\neq y | Y=y)$$\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{P}(h(X) \\neq y | Y=y)$$\nThis is precisely the definition of the target population risk $R(h)$ from part (a). Thus, the estimator is unbiased: $\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = R(h)$.\n\n(d) Variance of the reweighted empirical risk estimator.\n\nLet $Z_i = w(Y_i) \\ell(h(X_i), Y_i)$. The estimator is $\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n Z_i$. Since the samples $(X_i, Y_i)$ are i.i.d. draws from $P_{\\text{sample}}$, the random variables $Z_i$ are also i.i.d.\nThe variance of the estimator is:\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n Z_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(Z_i) = \\frac{1}{n} \\text{Var}(Z_1)$$\nThe variance of a single term $Z_1$ is given by $\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2$.\nFrom part (c), we know that $\\mathbb{E}[Z_1] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)] = R(h) = 0.2$.\nNow we compute the second moment, $\\mathbb{E}[Z_1^2]$, under the sampling distribution $P_{\\text{sample}}$:\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[(w(Y) \\ell(h(X), Y))^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)^2]$$\nSince the loss $\\ell$ is an indicator function ($\\mathbf{1}\\{\\cdot\\}$), its value is either $0$ or $1$. Therefore, $\\ell^2 = \\ell$.\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)]$$\nApplying the law of total expectation:\n$$\\mathbb{E}[Z_1^2] = \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\mathbb{P}(h(X) \\neq 1|Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\mathbb{P}(h(X) \\neq 0|Y=0)$$\n$$= \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\alpha + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\beta$$\nSubstituting the known values:\n$$\\mathbb{E}[Z_1^2] = (0.8)(0.625)^2(0.1) + (0.2)(2.5)^2(0.3)$$\n$$= (0.8)(0.390625)(0.1) + (0.2)(6.25)(0.3)$$\n$$= 0.03125 + 0.375 = 0.40625$$\nNow we compute $\\text{Var}(Z_1)$:\n$$\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2 = 0.40625 - (0.2)^2 = 0.40625 - 0.04 = 0.36625$$\nFinally, the variance of the reweighted estimator for $n=1000$ is:\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\frac{\\text{Var}(Z_1)}{n} = \\frac{0.36625}{1000} = 0.00036625$$\nRounding to four significant figures and expressing in scientific notation:\n$$0.00036625 = 3.6625 \\times 10^{-4} \\approx 3.663 \\times 10^{-4}$$", "answer": "$$\\boxed{3.663 \\times 10^{-4}}$$", "id": "3123242"}, {"introduction": "A single performance score on a validation set provides only a point estimate of a model's true risk, which can be sensitive to the randomness of how the data was split. To build robust and reliable models, we must quantify the uncertainty in our evaluation, which stems from multiple sources. This exercise tackles this challenge by analyzing risk estimates from repeated train-validation splits of a dataset. You will use the law of total variance to decompose the uncertainty into components from the data-splitting process and the finite-sample validation, culminating in the construction of a more honest confidence interval for the expected risk.", "problem": "A binary classification model is trained on repeated random train/validation splits of the same independently and identically distributed dataset. For each random seed $s \\in \\{1,\\dots,k\\}$, a training set is formed and the model is evaluated on a validation set of size $n_{\\mathrm{val}}$, producing a validation empirical risk (average $0\\text{-}1$ loss) denoted $\\hat{R}_{s}$. Assume that, across seeds, the $\\hat{R}_{s}$ are independent realizations of the same data-generating mechanism, and that each $\\hat{R}_{s}$ is an unbiased estimator of the expected (population) risk $R$. The goal is to estimate $R$ and quantify uncertainty that accounts for both the variability across different splits (between-split variability) and the finite validation sample size (within-split variability).\n\nYou may assume: (i) validation losses for different examples are independent Bernoulli random variables with success probability equal to the true misclassification probability for that trained model, and (ii) the Central Limit Theorem (CLT) applies to averages across seeds.\n\nIn one experiment with $k=8$ seeds and validation size $n_{\\mathrm{val}}=5000$ per seed, the observed validation empirical risks are:\n$0.158,\\; 0.171,\\; 0.165,\\; 0.162,\\; 0.169,\\; 0.155,\\; 0.166,\\; 0.160$.\n\nStarting from core definitions of expected risk $R$ and empirical risk $\\hat{R}_{s}$, use the law of total variance to derive a variance estimator for the across-seed average $\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ that explicitly accounts for both between-split variability and within-split validation sampling noise. Then, under a Student’s $t$ approximation with $\\nu=k-1$ degrees of freedom for the sampling distribution of $\\bar{R}$, compute the two-sided $95\\%$ confidence interval half-width for $R$.\n\nExpress your final answer as a single decimal value (the half-width only), and round your answer to four significant figures. No units are required.", "solution": "The goal is to estimate the expected risk $R$ using the average empirical risk $\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ and to quantify the uncertainty in this estimate. The total uncertainty arises from two sources:\n1.  **Within-split variability**: The variance due to using a finite validation set of size $n_{\\mathrm{val}}$ for each split. This is a form of sampling error.\n2.  **Between-split variability**: The variance due to the specific choice of the training set for each split, which results in a different trained model for each seed $s$.\n\nWe are tasked with deriving a variance estimator for $\\bar{R}$ that explicitly accounts for both sources. Let $\\theta_s$ denote the random variable representing the model parameters learned on the training data for seed $s$. The empirical risk $\\hat{R}_s$ is also a random variable, dependent on both $\\theta_s$ and the random sampling of the validation set.\n\nThe overall expected risk is $R = E[\\hat{R}_s]$. Since the $\\hat{R}_s$ for $s=1, \\dots, k$ are independent and identically distributed, the variance of their average $\\bar{R}$ is:\n$$ \\mathrm{Var}(\\bar{R}) = \\mathrm{Var}\\left(\\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}\\right) = \\frac{1}{k^2}\\sum_{s=1}^{k}\\mathrm{Var}(\\hat{R}_{s}) = \\frac{1}{k}\\mathrm{Var}(\\hat{R}_{s}) $$\nTo understand the components of $\\mathrm{Var}(\\hat{R}_{s})$, we apply the law of total variance, conditioning on the trained model $\\theta_s$:\n$$ \\mathrm{Var}(\\hat{R}_{s}) = E_{\\theta_s}[\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)] + \\mathrm{Var}_{\\theta_s}(E[\\hat{R}_{s} | \\theta_s]) $$\nLet's analyze each term:\n- The inner expectation, $E[\\hat{R}_{s} | \\theta_s]$, is the expected empirical risk for a *fixed* model $\\theta_s$. This is the true risk of that specific model, let's call it $R(\\theta_s)$. So, $E[\\hat{R}_{s} | \\theta_s] = R(\\theta_s)$.\n- The variance of this expectation, $\\mathrm{Var}_{\\theta_s}(R(\\theta_s))$, is the variance in the true model performance across different training splits. This is the **between-split variance**, which we denote as $\\sigma^2_{\\text{between}}$.\n- The inner variance, $\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)$, is the variance of the empirical risk for a fixed model $\\theta_s$, which arises from the finite validation set. Since $\\hat{R}_s$ is the average of $n_{\\mathrm{val}}$ independent Bernoulli trials (0-1 loss) with success probability $R(\\theta_s)$, its variance is $\\frac{R(\\theta_s)(1-R(\\theta_s))}{n_{\\mathrm{val}}}$.\n- The expectation of this inner variance, $E_{\\theta_s}\\left[\\frac{R(\\theta_s)(1-R(\\theta_s))}{n_{\\mathrm{val}}}\\right]$, is the average variance due to validation set sampling, taken over all possible training splits. This is the **within-split variance**, which we denote as $\\sigma^2_{\\text{within}}$.\n\nCombining these, the total variance of a single empirical risk measurement $\\hat{R}_s$ is:\n$$ \\mathrm{Var}(\\hat{R}_{s}) = \\sigma^2_{\\text{within}} + \\sigma^2_{\\text{between}} $$\nThis derivation explicitly shows how the total variance is a sum of the two distinct sources of variability.\n\nTo estimate $\\mathrm{Var}(\\bar{R})$, we need to first estimate $\\mathrm{Var}(\\hat{R}_{s})$. We have a sample of $k$ observations $\\{\\hat{R}_1, \\dots, \\hat{R}_k\\}$. The sample variance of these observations,\n$$ S^2_{\\hat{R}} = \\frac{1}{k-1} \\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2 $$\nis an unbiased estimator for the total variance, $\\mathrm{Var}(\\hat{R}_{s})$. That is, $E[S^2_{\\hat{R}}] = \\mathrm{Var}(\\hat{R}_{s}) = \\sigma^2_{\\text{within}} + \\sigma^2_{\\text{between}}$. This single statistic empirically captures the combined effect of both sources of variance.\n\nTherefore, an unbiased estimator for the variance of the mean $\\bar{R}$ is:\n$$ \\widehat{\\mathrm{Var}}(\\bar{R}) = \\frac{S^2_{\\hat{R}}}{k} $$\nThe standard error of $\\bar{R}$ is the square root of this estimated variance:\n$$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\frac{S^2_{\\hat{R}}}{k}} = \\frac{S_{\\hat{R}}}{\\sqrt{k}} $$\nNow, we proceed with the numerical calculation. The given data for $\\hat{R}_s$ are:\n$\\{0.158, 0.171, 0.165, 0.162, 0.169, 0.155, 0.166, 0.160\\}$. We have $k=8$.\n\nFirst, compute the sample mean $\\bar{R}$:\n$$ \\bar{R} = \\frac{1}{8} (0.158 + 0.171 + 0.165 + 0.162 + 0.169 + 0.155 + 0.166 + 0.160) = \\frac{1.306}{8} = 0.16325 $$\nNext, compute the sum of squared deviations $\\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2$. This is found to be $\\approx 2.115 \\times 10^{-4}$.\n\nNow, compute the sample variance $S^2_{\\hat{R}}$:\n$$ S^2_{\\hat{R}} = \\frac{1}{k-1} \\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2 = \\frac{2.115 \\times 10^{-4}}{8-1} = \\frac{2.115 \\times 10^{-4}}{7} \\approx 3.0214286 \\times 10^{-5} $$\nThe estimated variance of the mean is:\n$$ \\widehat{\\mathrm{Var}}(\\bar{R}) = \\frac{S^2_{\\hat{R}}}{k} = \\frac{3.0214286 \\times 10^{-5}}{8} \\approx 3.7767857 \\times 10^{-6} $$\nThe standard error of the mean is:\n$$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{R})} = \\sqrt{3.7767857 \\times 10^{-6}} \\approx 0.001943395 $$\nThe problem asks for the half-width of a two-sided $95\\%$ confidence interval for $R$, using a Student's $t$ approximation with $\\nu = k-1 = 7$ degrees of freedom. The half-width $H$ is given by:\n$$ H = t_{\\alpha/2, \\nu} \\times \\mathrm{SE}(\\bar{R}) $$\nFor a $95\\%$ confidence interval, $\\alpha=0.05$, so $\\alpha/2 = 0.025$. The critical value from the $t$-distribution with $\\nu=7$ degrees of freedom is:\n$$ t_{0.025, 7} \\approx 2.3646 $$\nNow, we compute the half-width:\n$$ H = 2.3646 \\times 0.001943395 \\approx 0.00459523 $$\nRounding the result to four significant figures gives:\n$$ H \\approx 0.004595 $$", "answer": "$$\\boxed{0.004595}$$", "id": "3123300"}]}