{"hands_on_practices": [{"introduction": "The core of the Metropolis-Hastings algorithm lies in its decision to accept or reject a proposed new state. This practice provides a fundamental exercise in calculating the acceptance probability, $\\alpha$, for a simple yet common scenario: a symmetric random-walk proposal. By working through this calculation [@problem_id:1932824], you will solidify your understanding of how the relative likelihood of the current and proposed states, dictated by the target distribution $\\pi(\\lambda)$, governs the behavior of the Markov chain.", "problem": "A statistician is using a Markov Chain Monte Carlo (MCMC) method to sample from the posterior distribution of a parameter $\\lambda$. The posterior distribution is known to follow an exponential distribution with a rate parameter $\\beta_0$, given by the probability density function $\\pi(\\lambda) = \\beta_0 \\exp(-\\beta_0 \\lambda)$ for $\\lambda > 0$, and $\\pi(\\lambda)=0$ for $\\lambda \\le 0$.\n\nFor the MCMC simulation, a random-walk Metropolis-Hastings algorithm is employed. The proposal for a new state $\\lambda_p$ given the current state $\\lambda_c$ is drawn from a normal distribution with a mean equal to the current state and a standard deviation $\\sigma$. That is, the proposal distribution is $q(\\lambda_p | \\lambda_c)$ corresponding to a normal distribution $\\mathcal{N}(\\lambda_c, \\sigma^2)$.\n\nSuppose the rate parameter of the posterior is $\\beta_0 = 0.5$ and the standard deviation of the proposal distribution is $\\sigma = 1.0$. At a certain step in the chain, the current state is $\\lambda_c = 2.4$. The algorithm then proposes a new state $\\lambda_p = 3.1$. Both the current and proposed states are in the valid domain ($\\lambda > 0$).\n\nCalculate the acceptance probability for this proposed move. Round your final answer to three significant figures.", "solution": "In the Metropolis-Hastings algorithm, the acceptance probability for a proposed move from $\\lambda_{c}$ to $\\lambda_{p}$ is\n$$\n\\alpha = \\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})\\,q(\\lambda_{c}\\mid \\lambda_{p})}{\\pi(\\lambda_{c})\\,q(\\lambda_{p}\\mid \\lambda_{c})}\\right).\n$$\nWith a random-walk normal proposal $q(\\lambda_{p}\\mid \\lambda_{c})$ given by $\\mathcal{N}(\\lambda_{c},\\sigma^{2})$, the proposal is symmetric, so\n$$\nq(\\lambda_{c}\\mid \\lambda_{p})=q(\\lambda_{p}\\mid \\lambda_{c}),\n$$\nand therefore the proposal ratio equals $1$. Thus,\n$$\n\\alpha=\\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\\right).\n$$\nThe target density is exponential with rate $\\beta_{0}$:\n$$\n\\pi(\\lambda)=\\beta_{0}\\exp(-\\beta_{0}\\lambda)\\quad\\text{for}\\ \\lambda0,\\quad \\pi(\\lambda)=0\\ \\text{otherwise}.\n$$\nSince both $\\lambda_{c}$ and $\\lambda_{p}$ are positive, we have\n$$\n\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\n=\\frac{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{p})}{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{c})}\n=\\exp\\!\\big(-\\beta_{0}(\\lambda_{p}-\\lambda_{c})\\big).\n$$\nSubstituting the given values $\\beta_{0}=0.5$, $\\lambda_{c}=2.4$, and $\\lambda_{p}=3.1$,\n$$\n\\alpha=\\min\\left(1,\\;\\exp\\!\\big(-0.5\\cdot(3.1-2.4)\\big)\\right)\n=\\min\\left(1,\\;\\exp(-0.35)\\right)\n=\\exp(-0.35).\n$$\nNumerically, $\\exp(-0.35)\\approx 0.704688\\ldots$, which rounded to three significant figures is $0.705$.", "answer": "$$\\boxed{0.705}$$", "id": "1932824"}, {"introduction": "In many real-world applications, a parameter's domain is constrained (e.g., a probability $\\theta$ must be in $[0,1]$), but a convenient proposal distribution like a Gaussian might suggest values outside this range. This thought experiment [@problem_id:2442876] challenges you to analyze the consequences of such a mismatch. Understanding how the algorithm inherently handles these 'out-of-bounds' proposals is crucial for both verifying the correctness of your sampler and diagnosing potential sources of inefficiency, such as high rejection rates near boundaries.", "problem": "In a credit risk model, suppose the probability of default parameter is denoted by $\\theta \\in [0,1]$. You place a Beta prior on $\\theta$ and observe binary default data, yielding a posterior density $\\pi(\\theta)$ that has support only on $[0,1]$ (i.e., $\\pi(\\theta)=0$ for $\\theta \\notin [0,1]$). You implement a Metropolis-Hastings Markov chain Monte Carlo (MCMC) sampler with a Gaussian random-walk proposal $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2)$, which can produce proposals $\\theta' \\notin [0,1]$.\n\nWhich statement best describes the consequences for the Markov chain and the posterior inference?\n\nA. The chain will sometimes accept proposals $\\theta' \\notin [0,1]$ but then clamps $\\theta'$ back into $[0,1]$ implicitly, which changes the stationary distribution unless $q(\\theta' \\mid \\theta)$ is truncated to $[0,1]$.\n\nB. Because the posterior density $\\pi(\\theta)$ is zero outside $[0,1]$, any proposal $\\theta' \\notin [0,1]$ has Metropolis–Hastings acceptance probability equal to $0$, is always rejected, and the chain remains at the current state; the invariant distribution remains $\\pi(\\theta)$ on $[0,1]$, though the rejection rate and autocorrelation can increase, especially near the boundaries.\n\nC. The posterior must be renormalized over $\\mathbb{R}$ to match the support of $q(\\theta' \\mid \\theta)$; otherwise the chain is not reversible and has no stationary distribution.\n\nD. The chain will drift outside $[0,1]$ with positive probability because $q(\\theta' \\mid \\theta)$ has unbounded support, so the empirical distribution of draws will assign positive mass to $\\theta \\notin [0,1]$ and bias the inference.", "solution": "The validity of the problem statement must be established first.\n\n**Step 1: Extract Givens**\n- The parameter is $\\theta \\in [0,1]$.\n- The posterior density is denoted by $\\pi(\\theta)$.\n- The support of the posterior is $[0,1]$, meaning $\\pi(\\theta) = 0$ for all $\\theta \\notin [0,1]$.\n- The sampling method is the Metropolis-Hastings algorithm.\n- The proposal distribution is a Gaussian random-walk, $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2)$.\n- The proposal distribution $q(\\theta' \\mid \\theta)$ can generate values $\\theta'$ outside of the interval $[0,1]$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a standard scenario in applied Bayesian statistics. A parameter constrained to an interval, such as a probability $\\theta \\in [0,1]$, is common. The use of a Beta distribution as a prior for a probability parameter, which leads to a Beta posterior after observing binary (Bernoulli) data, is a canonical example. The posterior correctly has support on $[0,1]$. The Metropolis-Hastings algorithm is a fundamental tool for sampling from posterior distributions, and the use of a Gaussian random-walk proposal is a very common implementation choice. The central issue raised—the mismatch between the support of the target distribution $\\pi(\\theta)$ and the proposal distribution $q(\\theta' \\mid \\theta)$—is a well-understood and practical consideration in MCMC methods. The problem is scientifically grounded, well-posed, and objectively stated. It contains no logical contradictions, missing information, or pseudoscientific claims.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A rigorous solution will now be derived.\n\nThe Metropolis-Hastings algorithm generates a sequence of samples $\\{\\theta^{(0)}, \\theta^{(1)}, \\theta^{(2)}, \\dots\\}$ that form a Markov chain whose stationary distribution is the target posterior distribution $\\pi(\\theta)$. At each step $t$, a new candidate state $\\theta'$ is proposed from a proposal distribution $q(\\theta' \\mid \\theta^{(t)})$. This proposal is accepted with probability $\\alpha(\\theta', \\theta^{(t)})$, given by:\n$$\n\\alpha(\\theta', \\theta^{(t)}) = \\min\\left(1, \\frac{\\pi(\\theta') q(\\theta^{(t)} \\mid \\theta')}{\\pi(\\theta^{(t)}) q(\\theta' \\mid \\theta^{(t)})}\\right)\n$$\nIf the proposal is accepted, $\\theta^{(t+1)} = \\theta'$. If rejected, $\\theta^{(t+1)} = \\theta^{(t)}$.\n\nIn this problem, the proposal distribution is a Gaussian random-walk, $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2)$. The probability density function of this normal distribution is:\n$$\nf(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\nThus, $q(\\theta' \\mid \\theta^{(t)})$ is proportional to $\\exp(-(\\theta' - \\theta^{(t)})^2 / (2\\sigma^2))$ and $q(\\theta^{(t)} \\mid \\theta')$ is proportional to $\\exp(-(\\theta^{(t)} - \\theta')^2 / (2\\sigma^2))$. Since $(\\theta' - \\theta^{(t)})^2 = (\\theta^{(t)} - \\theta')^2$, the proposal distribution is symmetric: $q(\\theta' \\mid \\theta^{(t)}) = q(\\theta^{(t)} \\mid \\theta')$. The acceptance probability simplifies to the Metropolis form:\n$$\n\\alpha(\\theta', \\theta^{(t)}) = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta^{(t)})}\\right)\n$$\nLet us analyze the situation when a proposal $\\theta'$ is generated outside the support $[0,1]$. We assume the current state of the chain is $\\theta^{(t)} \\in [0,1]$, which implies $\\pi(\\theta^{(t)}) > 0$.\n\nIf a proposal $\\theta'$ is generated such that $\\theta' \\notin [0,1]$, then according to the problem statement, the posterior density at this point is zero: $\\pi(\\theta') = 0$.\nThe acceptance probability for such a proposal is:\n$$\n\\alpha(\\theta', \\theta^{(t)}) = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta^{(t)})}\\right) = \\min\\left(1, \\frac{0}{\\pi(\\theta^{(t)})}\\right)\n$$\nSince $\\pi(\\theta^{(t)})$ is a positive, non-zero value, the ratio is $0$. Therefore, the acceptance probability is $\\alpha(\\theta', \\theta^{(t)}) = \\min(1, 0) = 0$.\n\nAn acceptance probability of $0$ means that any proposal outside the support of the posterior distribution will be rejected with certainty. When a proposal is rejected, the chain does not move: $\\theta^{(t+1)} = \\theta^{(t)}$. Consequently, the Markov chain will never enter a state outside the interval $[0,1]$. The samples generated will all lie within the correct support.\n\nThe detailed balance condition, $\\pi(\\theta) P(\\theta' \\mid \\theta) = \\pi(\\theta') P(\\theta \\mid \\theta')$, which guarantees that $\\pi(\\theta)$ is the stationary distribution, is not violated. If $\\theta \\in [0,1]$ and $\\theta' \\notin [0,1]$, then $\\pi(\\theta')=0$ and $\\alpha(\\theta', \\theta)=0$. The right side of the equation is $0$, and the left side is $\\pi(\\theta)q(\\theta' \\mid \\theta)\\alpha(\\theta', \\theta) = \\pi(\\theta)q(\\theta' \\mid \\theta)(0) = 0$. The condition holds. Thus, the algorithm is formally correct and an infinitely long chain will converge to the correct invariant distribution $\\pi(\\theta)$ on $[0,1]$.\n\nHowever, this implementation has practical consequences for the efficiency of the sampler. If the current state $\\theta^{(t)}$ is near a boundary (e.g., close to $0$ or $1$), the symmetric Gaussian proposal has a substantial probability of generating a value $\\theta'$ outside $[0,1]$. For example, if $\\theta^{(t)} = 0.01$ and $\\sigma=0.1$, approximately half of the proposals will be negative. All such proposals are automatically rejected. This leads to a high rejection rate, causing the chain to remain at the same state for many consecutive iterations. This increases the autocorrelation of the sample sequence and reduces the effective sample size, meaning the chain explores the posterior distribution very slowly.\n\nNow, we evaluate the given options.\n\n**A. The chain will sometimes accept proposals $\\theta' \\notin [0,1]$ but then clamps $\\theta'$ back into $[0,1]$ implicitly, which changes the stationary distribution unless $q(\\theta' \\mid \\theta)$ is truncated to $[0,1]$.**\nThis statement is incorrect. The standard Metropolis-Hastings algorithm does not \"clamp\" values. It rejects proposals for which $\\pi(\\theta')=0$ with probability $1$. The chain will *never* accept a proposal outside the support of $\\pi(\\theta)$. Modifying the algorithm to clamp proposals would indeed change the algorithm and require a different acceptance probability calculation to preserve the correct stationary distribution.\n\n**B. Because the posterior density $\\pi(\\theta)$ is zero outside $[0,1]$, any proposal $\\theta' \\notin [0,1]$ has Metropolis-Hastings acceptance probability equal to $0$, is always rejected, and the chain remains at the current state; the invariant distribution remains $\\pi(\\theta)$ on $[0,1]$, though the rejection rate and autocorrelation can increase, especially near the boundaries.**\nThis statement is entirely correct. It accurately describes the mechanism: $\\pi(\\theta')=0$ leads to $\\alpha=0$, resulting in rejection. It correctly states that the chain remains at its current state and that the invariant distribution is not compromised. Finally, it correctly identifies the practical consequences of inefficiency: increased rejection rate and autocorrelation, particularly near the boundaries of the support.\n\n**C. The posterior must be renormalized over $\\mathbb{R}$ to match the support of $q(\\theta' \\mid \\theta)$; otherwise the chain is not reversible and has no stationary distribution.**\nThis is incorrect. The posterior distribution $\\pi(\\theta)$ is defined by the model and data; it cannot and should not be altered. The Metropolis-Hastings algorithm is specifically designed to handle cases where the proposal and target distributions have different forms and supports. The chain remains reversible, and the stationary distribution is correct, as shown by the detailed balance condition.\n\n**D. The chain will drift outside $[0,1]$ with positive probability because $q(\\theta' \\mid \\theta)$ has unbounded support, so the empirical distribution of draws will assign positive mass to $\\theta \\notin [0,1]$ and bias the inference.**\nThis is incorrect. The fact that $q(\\theta' \\mid \\theta)$ has unbounded support only means that values outside $[0,1]$ can be *proposed*. It does not mean they can be *accepted*. As derived, the acceptance probability for such proposals is $0$. The chain's state space is confined to the support of $\\pi(\\theta)$, which is $[0,1]$. The empirical distribution of draws will therefore have zero mass outside $[0,1]$, and the algorithm does not introduce a bias in the target distribution.\n\nBased on this rigorous analysis, only option B provides a correct and complete description of the consequences.", "answer": "$$\\boxed{B}$$", "id": "2442876"}, {"introduction": "For a Metropolis-Hastings sampler to be reliable, it must be capable of exploring the entire support of the target distribution, a property known as irreducibility. This hands-on coding exercise [@problem_id:3160213] provides a powerful and concrete demonstration of what happens when this property fails. By simulating a chain on a disconnected state space $S$ with a local proposal, you will directly observe how an inappropriately chosen step size $\\delta$ can trap the sampler in one region, preventing it from ever converging to the true target distribution $\\pi(x)$.", "problem": "Consider the Metropolis-Hastings (MH) algorithm, which constructs a Markov chain with a prescribed stationary distribution. Let the real-valued state space be the union of two disjoint closed intervals, with target probability density function $\\pi(x)$ supported on $$S = [0,1] \\cup [2,3],$$ and zero elsewhere. Define $$\\pi(x) = \\begin{cases} \\tfrac{1}{2},  x \\in [0,1] \\text{ or } x \\in [2,3], \\\\ 0,  \\text{otherwise,} \\end{cases}$$ which is a valid probability density because the total length of $S$ is $2$, and the density is $\\tfrac{1}{2}$ on each unit-length interval. Consider two types of proposals:\n\n- A symmetric local proposal $q(x' \\mid x)$ given by the uniform law on $$[x - \\delta,\\, x + \\delta],$$ where $\\delta > 0$ is a fixed half-width. This proposal is symmetric in the sense that $q(x' \\mid x) = q(x \\mid x')$ whenever both are nonzero.\n- An independent proposal $q(x' \\mid x) = q(x')$ given by the uniform law on $$[0,3],$$ which does not depend on the current state $x.$\n\nYou must analyze, implement, and empirically demonstrate the failure of ergodicity (specifically, the failure of $\\psi$-irreducibility) when the local proposal half-width $\\delta$ is too small to cross the gap between the intervals, and contrast it with parameterizations or proposal mechanisms that restore irreducibility.\n\nStart from fundamental bases: the definitions of a Markov chain, the concept of support of a probability measure, the detailed balance condition, and the definition of irreducibility. In particular, use the principle that the MH acceptance function must be derived from ensuring detailed balance with respect to the target density $\\pi(x)$ and that proposals landing in regions where $\\pi(x') = 0$ must be rejected.\n\nAlgorithmic requirements for your program:\n\n- Implement a function that simulates the MH chain for $N$ steps from an initial state $x_0,$ using the specified proposal type and parameter(s). If $\\pi(x_0) = 0,$ the implementation must detect the invalid initial state and return the integer $1$ as the test result for that case.\n- For valid starts, track whether the chain ever visits the right interval $[2,3]$ within the $N$ steps. The result for that case must be a boolean: $\\text{True}$ if the chain visits $[2,3]$ at least once, and $\\text{False}$ otherwise.\n- Use a fixed random seed for each test case to ensure reproducibility.\n- Use closed intervals for membership tests; specifically, use $\\le$ comparisons so that points exactly at $0, 1, 2,$ and $3$ are considered inside their respective intervals.\n\nTest suite and coverage:\n\nLet the gap length be $g = 1,$ i.e., the distance between the right endpoint of $[0,1]$ and the left endpoint of $[2,3]$ is $g.$ The following five test cases must be implemented exactly as specified, to cover the happy path, boundary condition, and edge cases:\n\n1. Local symmetric proposal with $\\delta = 0.49,$ initial state $x_0 = 0.5,$ steps $N = 20000,$ seed $42.$ Expected behavior: the chain cannot cross the gap because $\\delta  g.$\n2. Local symmetric proposal with $\\delta = 1.5,$ initial state $x_0 = 1.0,$ steps $N = 20000,$ seed $123.$ Expected behavior: the chain can cross the gap because $\\delta > g.$\n3. Local symmetric proposal with $\\delta = 1.0,$ initial state $x_0 = 1.0,$ steps $N = 20000,$ seed $2023.$ Boundary behavior: the chain cannot cross the gap with nonzero probability because proposals from $x \\in [0,1]$ land in $[x - 1, x + 1] \\subset [0,2],$ and the event $x' = 2$ has probability $0.$\n4. Independent proposal $q(x')$ uniform on $[0,3],$ initial state $x_0 = 0.5,$ steps $N = 100,$ seed $7.$ Expected behavior: the chain is irreducible because proposals have positive probability to land in $[2,3]$ from any state in $S.$\n5. Invalid initial state: local symmetric proposal with $\\delta = 0.4,$ initial state $x_0 = 1.5,$ steps $N = 100,$ seed $99.$ Required behavior: detect that $\\pi(x_0) = 0$ and return the integer $1.$\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the five test cases listed above. For the first four test cases, print booleans indicating whether the chain visited $[2,3]$ at least once; for the fifth test case, print the integer $1.$ For example, the printed line must have the form $$[b_1, b_2, b_3, b_4, i_5],$$ where each $b_k$ is a boolean and $i_5 = 1.$ No additional text should be printed.", "solution": "The problem is valid as it is scientifically sound, well-posed, and all necessary information is provided. It presents a canonical example of the failure of irreducibility in the Metropolis-Hastings algorithm, which is a fundamental concept in computational science and Markov chain Monte Carlo methods.\n\nThe Metropolis-Hastings (MH) algorithm is a method for generating a sequence of random samples from a probability distribution for which direct sampling is difficult. The sequence of samples constitutes a Markov chain, which is a stochastic process where the probability of transitioning to any particular state depends solely on the current state and not on the sequence of events that preceded it. The core idea of the MH algorithm is to construct a Markov chain whose stationary distribution is the desired target distribution, $\\pi(x)$. A key property required for a Markov chain to converge to its unique stationary distribution from any starting point within the support is ergodicity. Ergodicity implies that the chain is both irreducible and aperiodic. This analysis focuses on irreducibility.\n\nA Markov chain is said to be $\\pi$-irreducible if, for any state $x$ within the support of $\\pi(x)$, denoted $\\text{supp}(\\pi)$, and any set $A \\subseteq \\text{supp}(\\pi)$ with positive probability, $\\int_A \\pi(x) dx > 0$, there is a non-zero probability of the chain moving from $x$ to the set $A$ in a finite number of steps. In this problem, the support of the target distribution is the set $S = [0,1] \\cup [2,3]$. For the chain to be irreducible, it must be possible to transition between the two disjoint intervals $[0,1]$ and $[2,3]$.\n\nThe MH algorithm constructs the transition kernel of the Markov chain to satisfy the detailed balance condition with respect to $\\pi(x)$. This condition is a sufficient, but not necessary, condition for $\\pi(x)$ to be the stationary distribution. Detailed balance is given by:\n$$\n\\pi(x) P(x' \\mid x) = \\pi(x') P(x \\mid x')\n$$\nwhere $P(x' \\mid x)$ is the probability density of transitioning from state $x$ to state $x'$. The MH algorithm defines this transition by a two-step process: proposal and acceptance. First, a candidate state $x'$ is proposed from a proposal distribution $q(x' \\mid x)$. Second, this proposal is accepted with a probability $\\alpha(x' \\mid x)$. The transition density is thus $P(x' \\mid x) = q(x' \\mid x) \\alpha(x' \\mid x)$ for $x' \\neq x$. Substituting this into the detailed balance equation gives:\n$$\n\\pi(x) q(x' \\mid x) \\alpha(x' \\mid x) = \\pi(x') q(x \\mid x') \\alpha(x \\mid x')\n$$\nThe MH acceptance probability is chosen to satisfy this relation:\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\nIf a proposed state $x'$ lies outside the support of $\\pi(x)$, then $\\pi(x')=0$, which leads to an acceptance probability of $\\alpha(x' \\mid x) = 0$. In such cases, the proposal is always rejected, and the chain remains at its current state, i.e., $x_{t+1} = x_t$.\n\nThe specified target distribution is $\\pi(x) = \\frac{1}{2}$ for $x \\in S = [0,1] \\cup [2,3]$ and $\\pi(x) = 0$ otherwise. A crucial simplification arises from this definition: for any two states $x, x' \\in S$, the ratio of the target densities is $\\frac{\\pi(x')}{\\pi(x)} = \\frac{1/2}{1/2} = 1$. The acceptance probability formula thus simplifies to:\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{q(x \\mid x')}{q(x' \\mid x)} \\right)\n$$\nfor any proposed move from $x \\in S$ to $x' \\in S$.\n\nWe analyze the two proposal mechanisms:\n\n1.  **Local Symmetric Proposal**: The proposal distribution is $q(x' \\mid x)$ corresponding to a uniform distribution on $[x-\\delta, x+\\delta]$. The density is $q(x' \\mid x) = \\frac{1}{2\\delta}$ if $x' \\in [x-\\delta, x+\\delta]$ and $0$ otherwise. This is symmetric, meaning $q(x' \\mid x) = q(x \\mid x')$, because the condition $|x' - x| \\le \\delta$ is symmetric in $x$ and $x'$. Therefore, the ratio $\\frac{q(x \\mid x')}{q(x' \\mid x)} = 1$. The acceptance probability for any proposed move to a state $x' \\in S$ is $\\alpha(x' \\mid x) = \\min(1, 1) = 1$. So, if a proposal lands within the support $S$, it is always accepted. If it lands outside $S$, it is always rejected.\n    The irreducibility of the chain depends on whether the proposal distribution can bridge the gap $g=1$ between the intervals $[0,1]$ and $[2,3]$. A proposal from a state $x \\in [0,1]$ is generated from $[x-\\delta, x+\\delta]$. The highest possible value for a proposal originating in $[0,1]$ is from $x=1$, which gives a proposal interval of $[1-\\delta, 1+\\delta]$. For the chain to be able to jump from $[0,1]$ to $[2,3]$, this interval must have a non-zero overlap with $[2,3]$. This requires $1+\\delta \\ge 2$, or $\\delta \\ge 1$.\n    -   **Case 1 ($\\delta = 0.49  1$)**: The maximum reach from $x=1$ is $1.49$. It is impossible to propose a state in $[2,3]$. The chain is reducible, trapped in the interval it started in.\n    -   **Case 2 ($\\delta = 1.5 > 1$)**: From any $x \\in [0.5, 1]$, the proposal interval $[x-1.5, x+1.5]$ has a non-empty intersection with $[2,3]$. For example, from $x_0=1$, proposals can be up to $2.5$. Transitions are possible, and the chain is irreducible.\n    -   **Case 3 ($\\delta = 1.0$)**: The maximum reach from $x=1$ is exactly $2$. The proposal interval is $[0, 2]$. Since the proposal is drawn from a continuous uniform distribution, the probability of generating the exact value $x'=2$ is $0$. Therefore, the chain cannot cross into the interior of $[2,3]$ with non-zero probability. The chain is reducible.\n\n2.  **Independent Proposal**: The proposal distribution is $q(x' \\mid x) = q(x')$ uniform on $[0,3]$, so the density is $q(x') = \\frac{1}{3}$ for $x' \\in [0,3]$. Here, the proposal does not depend on the current state $x$. The ratio of proposal densities is $\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{q(x)}{q(x')} = \\frac{1/3}{1/3} = 1$ for any $x, x' \\in [0,3]$. Similar to the symmetric case, the acceptance probability for any move to $x' \\in S$ is $\\alpha(x' \\mid x) = 1$.\n    The irreducibility is guaranteed. From any state $x \\in S$, a new state $x'$ is proposed uniformly from $[0,3]$. The probability of this proposal falling into the right interval $[2,3]$ is $\\frac{3-2}{3-0} = \\frac{1}{3} > 0$. Since such a proposal will be accepted, the chain can move between the two components of the support in a single step. The chain is irreducible.\n\nFinally, the problem requires identifying invalid initial states. If $x_0$ is such that $\\pi(x_0)=0$ (e.g., $x_0 = 1.5$ as in Case 5), the chain is not properly initialized on the support of the target distribution. The implementation must detect this.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Metropolis-Hastings problem by running five specified test cases.\n    \"\"\"\n\n    def pi(x: float) - float:\n        \"\"\"\n        Target probability density function pi(x).\n        Supported on S = [0,1] U [2,3].\n        \"\"\"\n        if (0.0 = x = 1.0) or (2.0 = x = 3.0):\n            return 0.5\n        return 0.0\n\n    def run_mh_simulation(\n        proposal_type: str,\n        delta: float | None,\n        x0: float,\n        N: int,\n        seed: int\n    ) - bool | int:\n        \"\"\"\n        Simulates the Metropolis-Hastings Markov chain for a given test case.\n\n        Args:\n            proposal_type: 'local' for symmetric or 'independent' for independent proposal.\n            delta: Half-width for the local proposal.\n            x0: Initial state.\n            N: Number of steps.\n            seed: Random seed for reproducibility.\n\n        Returns:\n            - Integer 1 if the initial state x0 is invalid (pi(x0) == 0).\n            - Boolean True if the chain visits the interval [2,3].\n            - Boolean False otherwise.\n        \"\"\"\n        # Step 1: Validate initial state\n        if pi(x0) == 0.0:\n            return 1\n\n        # Step 2: Initialize chain and tracking variables\n        rng = np.random.default_rng(seed)\n        current_x = x0\n        visited_right_interval = (2.0 = current_x = 3.0)\n\n        # Step 3: Run the MCMC simulation for N steps\n        for _ in range(N):\n            # Propose a new state x_prime\n            if proposal_type == 'local':\n                if delta is None:\n                    # This case should not happen based on problem description but is a safeguard\n                    raise ValueError(\"Delta must be provided for local proposal.\")\n                x_prime = rng.uniform(current_x - delta, current_x + delta)\n            elif proposal_type == 'independent':\n                x_prime = rng.uniform(0.0, 3.0)\n            else:\n                raise ValueError(f\"Unknown proposal type: {proposal_type}\")\n\n            # As derived in the solution, for this specific problem, the acceptance\n            # probability alpha is 1 for any proposal that lands in the support of pi,\n            # and 0 otherwise. This simplifies the accept/reject step.\n            if pi(x_prime)  0.0:\n                current_x = x_prime\n\n            # Track if the chain has ever visited the right interval [2, 3]\n            if not visited_right_interval and (2.0 = current_x = 3.0):\n                visited_right_interval = True\n        \n        return visited_right_interval\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Local proposal, delta  gap, should not cross\n        {'proposal_type': 'local', 'delta': 0.49, 'x0': 0.5, 'N': 20000, 'seed': 42},\n        # 2. Local proposal, delta  gap, should cross\n        {'proposal_type': 'local', 'delta': 1.5, 'x0': 1.0, 'N': 20000, 'seed': 123},\n        # 3. Local proposal, delta = gap, cannot cross (prob=0 event)\n        {'proposal_type': 'local', 'delta': 1.0, 'x0': 1.0, 'N': 20000, 'seed': 2023},\n        # 4. Independent proposal, should be irreducible and cross\n        {'proposal_type': 'independent', 'delta': None, 'x0': 0.5, 'N': 100, 'seed': 7},\n        # 5. Invalid initial state, should return 1\n        {'proposal_type': 'local', 'delta': 0.4, 'x0': 1.5, 'N': 100, 'seed': 99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_mh_simulation(\n            proposal_type=case['proposal_type'],\n            delta=case['delta'],\n            x0=case['x0'],\n            N=case['N'],\n            seed=case['seed']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160213"}]}