{"hands_on_practices": [{"introduction": "The theoretical guarantees of the perceptron algorithm often depend on the geometric properties of the data, such as the margin and the radius of the data points. This exercise provides a hands-on exploration of another critical geometric factor: the correlation between features. By empirically comparing the algorithm's convergence on data with correlated features versus decorrelated (orthonormalized) features, you will develop an intuition for how data preprocessing can dramatically impact learning efficiency [@problem_id:3099389].", "problem": "You are asked to write a complete, runnable program that empirically analyzes how feature correlation affects the convergence rate of the perceptron learning algorithm, and how decorrelating features via the Gram–Schmidt process alters this behavior. Your program must implement the perceptron from first principles and perform a feature-space transformation based on Gram–Schmidt orthonormalization to obtain a decorrelated representation for comparison.\n\nFundamental bases to use:\n- Definition of a linear classifier with the perceptron update: for data points $\\{(x_i,y_i)\\}_{i=1}^n$ with $x_i \\in \\mathbb{R}^d$ and labels $y_i \\in \\{-1,+1\\}$, the perceptron maintains a weight vector $w \\in \\mathbb{R}^d$ and updates it upon a mistake on $(x_i,y_i)$ using the rule $w \\leftarrow w + y_i x_i$.\n- Gram–Schmidt orthonormalization: for a matrix $X \\in \\mathbb{R}^{n \\times d}$, the Gram–Schmidt process yields a factorization $X = QR$ where $Q \\in \\mathbb{R}^{n \\times d}$ has orthonormal columns and $R \\in \\mathbb{R}^{d \\times d}$ is upper triangular and invertible when $X$ has full column rank. The corresponding linear feature transformation $A = R^{-1}$ maps each $x_i$ to $z_i = A x_i$, producing $Z = X A = Q$ whose columns are orthonormal across the dataset.\n\nYour program must:\n- Generate synthetic, linearly separable datasets with controlled feature correlation. For each test case, draw $n$ samples in dimension $d$ from a zero-mean multivariate normal distribution with equicorrelation covariance $\\Sigma = (1-\\rho) I_d + \\rho \\mathbf{1}\\mathbf{1}^\\top$, where $\\rho \\in (-1,1)$ is the correlation parameter and $\\mathbf{1}$ is the vector of ones in $\\mathbb{R}^d$. Draw a ground-truth weight $w_\\star \\in \\mathbb{R}^d$ from a standard normal distribution, and assign labels $y_i = \\operatorname{sign}(w_\\star^\\top x_i) \\in \\{-1,+1\\}$. To ensure a positive margin, modify the features by $x_i \\leftarrow x_i + m\\, y_i\\, u$ where $u = \\frac{w_\\star}{\\|w_\\star\\|_2}$ and $m > 0$ is a fixed margin-injection constant common to all test cases.\n- Implement a deterministic perceptron procedure that:\n  - Initializes $w = 0 \\in \\mathbb{R}^d$.\n  - Scans the $n$ samples in fixed index order $i = 1,2,\\dots,n$.\n  - Applies the update $w \\leftarrow w + y_i x_i$ on each mistake where $y_i (w^\\top x_i) \\le 0$.\n  - Continues making full passes over the dataset until a complete pass incurs zero mistakes, and returns the total number of updates made.\n- Compute the Gram–Schmidt transformation on the original feature matrix $X \\in \\mathbb{R}^{n \\times d}$ via $X = Q R$ and form decorrelated features $Z = X R^{-1} = Q$. Run the exact same perceptron procedure on $Z$ with the same labels $y$, and record the total number of updates to convergence.\n- Use a fixed random seed per test case for reproducibility. All random draws must use the stated seed for that test case.\n- For all linear algebra and norms, use the standard Euclidean inner product.\n\nTest suite to implement:\n- Use margin injection $m = 1.0$.\n- For each test case, generate data as specified above using the corresponding tuple $(d,n,\\rho,\\text{seed})$:\n  - Case $1$: $(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,0.0,\\,42\\,)$.\n  - Case $2$: $(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,0.95,\\,43\\,)$.\n  - Case $3$: $(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,{-0.95},\\,44\\,)$.\n  - Case $4$: $(d,n,\\rho,\\text{seed}) = (\\,3,\\,120,\\,0.8,\\,45\\,)$.\n\nRequired outputs per test case:\n- Produce a pair of integers $[u_{\\text{orig}}, u_{\\text{ortho}}]$, where $u_{\\text{orig}}$ is the total number of perceptron updates to convergence on the original correlated features $X$, and $u_{\\text{ortho}}$ is the total number of perceptron updates to convergence on the Gram–Schmidt–decorrelated features $Z$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the four pairs, enclosed in square brackets, with no spaces. For example: $[[u_1,v_1],[u_2,v_2],[u_3,v_3],[u_4,v_4]]$, where each $u_k$ and $v_k$ are integers corresponding to the $k$-th test case in the order listed above.", "solution": "The user requires an empirical analysis of the perceptron algorithm's convergence rate as a function of feature correlation. This is to be achieved by generating synthetic datasets with controlled inter-feature correlation, running a deterministic perceptron algorithm on this original data, and then comparing its performance against the same algorithm run on a decorrelated version of the data. The decorrelation is performed via a feature-space transformation derived from the Gram-Schmidt orthonormalization process.\n\nThe solution is structured as follows:\n1.  **Data Generation**: A precise method for creating linearly separable datasets with a specified correlation structure.\n2.  **Perceptron Algorithm**: The implementation of the perceptron learning rule.\n3.  **Feature Decorrelation**: The application of Gram-Schmidt orthonormalization to transform the feature space.\n4.  **Experimental Procedure**: The complete pipeline for a single test case, combining the above components to produce the required output.\n\n**1. Data Generation**\n\nA synthetic dataset consists of $n$ instances, each being a pair $(x_i, y_i)$ where $x_i \\in \\mathbb{R}^d$ is a feature vector and $y_i \\in \\{-1, +1\\}$ is a class label.\n\n- **Initial Feature Generation**: The feature vectors are initially drawn from a $d$-dimensional multivariate normal distribution with zero mean and a specified covariance matrix $\\Sigma$:\n$$\nx_i \\sim \\mathcal{N}(0, \\Sigma)\n$$\nThe covariance matrix $\\Sigma$ is constructed to have an equicorrelation structure, controlled by a parameter $\\rho \\in (-1/(d-1), 1)$:\n$$\n\\Sigma = (1-\\rho) I_d + \\rho \\mathbf{1}\\mathbf{1}^\\top\n$$\nHere, $I_d$ is the $d \\times d$ identity matrix and $\\mathbf{1}$ is a $d \\times 1$ vector of ones. This structure ensures that the variance of each feature is $1$ and the covariance between any two distinct features $j$ and $k$ is $\\text{Cov}(X_j, X_k) = \\rho$.\n\n- **Label Assignment**: A ground-truth separating hyperplane is defined by a weight vector $w_\\star \\in \\mathbb{R}^d$, whose components are drawn from a standard normal distribution, $w_{\\star,j} \\sim \\mathcal{N}(0,1)$. The labels are then assigned based on which side of this hyperplane each point $x_i$ falls:\n$$\ny_i = \\operatorname{sgn}(w_\\star^\\top x_i)\n$$\nTo ensure that $y_i \\in \\{-1, +1\\}$, any case where $w_\\star^\\top x_i = 0$ (a rare event with continuous distributions) is resolved by assigning $y_i = +1$.\n\n- **Margin Injection**: To ensure that the data is linearly separable with a non-zero margin (a condition for the perceptron algorithm's guaranteed convergence), the feature vectors are adjusted. This process shifts each point $x_i$ further away from the separating hyperplane, in the correct direction. The modified feature vector $x'_i$ is given by:\n$$\nx'_i = x_i + m y_i u\n$$\nwhere $m > 0$ is a fixed margin constant ($m=1.0$ in this problem) and $u$ is the unit vector normal to the true hyperplane, $u = \\frac{w_\\star}{\\|w_\\star\\|_2}$. This operation guarantees that each point has a geometric margin of at least $m$ with respect to the hyperplane defined by $w_\\star$. The collection of these modified vectors $\\{x'_i\\}$ forms the final feature matrix $X$.\n\n**2. Perceptron Learning Algorithm**\n\nThe perceptron algorithm is an iterative method for finding a separating hyperplane for a linearly separable dataset. The algorithm implemented here is deterministic.\n\n- **Initialization**: The weight vector is initialized to the zero vector, $w = 0 \\in \\mathbb{R}^d$. A counter for the total number of updates is initialized to $0$.\n\n- **Iteration**: The algorithm proceeds in passes. In each pass, it iterates through all data points $(x_i, y_i)$ for $i=1, \\dots, n$ in a fixed order. For each point, it checks the classification condition:\n$$\ny_i (w^\\top x_i) \\le 0\n$$\nIf this condition is met, the point is misclassified (or lies on the boundary), and the weight vector is updated according to the perceptron rule:\n$$\nw \\leftarrow w + y_i x_i\n$$\nThe total update counter is incremented.\n\n- **Termination**: The algorithm terminates when it completes a full pass over the dataset without making any updates. The final value of the update counter is the result of interest, denoted $u$.\n\n**3. Feature Decorrelation via Gram-Schmidt**\n\nThe problem requires a comparison with a decorrelated feature set. This is achieved by applying a linear transformation to the original feature matrix $X \\in \\mathbb{R}^{n \\times d}$.\n\n- **QR Decomposition**: The Gram-Schmidt process is applied to the *columns* of the feature matrix $X$. The columns of $X$, $\\{c_1, \\dots, c_d\\}$, can be viewed as vectors in $\\mathbb{R}^n$, where each vector represents all observations of a single feature. The process is computationally realized via the reduced QR decomposition of $X$:\n$$\nX = QR\n$$\nwhere $Q \\in \\mathbb{R}^{n \\times d}$ is a matrix with orthonormal columns (i.e., $Q^\\top Q = I_d$), and $R \\in \\mathbb{R}^{d \\times d}$ is an invertible upper triangular matrix (assuming $X$ has full column rank, which is highly probable for the given data generation process).\n\n- **Feature Transformation**: The problem defines the transformation via a matrix $A = R^{-1}$. The new feature matrix, $Z \\in \\mathbb{R}^{n \\times d}$, is obtained by applying this transformation to $X$:\n$$\nZ = XA = XR^{-1}\n$$\nBy substituting $X=QR$, we find the new feature matrix is simply $Q$:\n$$\nZ = (QR)R^{-1} = Q(RR^{-1}) = QI_d = Q\n$$\nThe new feature vectors, which are the rows of $Z=Q$, are then used with the original labels $y$ to train a second perceptron. The resulting feature space has the property that its feature-defining column vectors are orthonormal, meaning they are uncorrelated across the samples of the dataset.\n\n**4. Experimental Procedure**\n\nFor each test case specified by a tuple $(d, n, \\rho, \\text{seed})$, the following steps are executed:\n1.  Set the random number generator's seed for reproducibility.\n2.  Generate the original feature matrix $X$ and labels $y$ using the procedure described in section 1.\n3.  Run the perceptron algorithm (section 2) on the dataset $(X,y)$ and record the total number of updates to convergence, $u_{\\text{orig}}$.\n4.  Compute the reduced QR decomposition of $X$ to obtain $Q$ and $R$.\n5.  Set the transformed feature matrix $Z=Q$.\n6.  Run the perceptron algorithm on the transformed dataset $(Z,y)$ and record the total updates, $u_{\\text{ortho}}$.\n7.  The final output for the test case is the pair $[u_{\\text{orig}}, u_{\\text{ortho}}]$.\n\nThis comparative analysis is expected to show that for high values of correlation $|\\rho|$, the number of updates $u_{\\text{orig}}$ is significantly larger than $u_{\\text{ortho}}$. The orthonormalization process regularizes the geometry of the data, typically leading to faster and more stable convergence.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_perceptron(features, labels):\n    \"\"\"\n    Runs the deterministic perceptron algorithm.\n\n    Args:\n        features (np.ndarray): The feature matrix (n_samples, n_features).\n        labels (np.ndarray): The label vector (n_samples,).\n\n    Returns:\n        int: The total number of updates until convergence.\n    \"\"\"\n    n_samples, n_features = features.shape\n    w = np.zeros(n_features)\n    total_updates = 0\n    \n    while True:\n        updates_in_pass = 0\n        for i in range(n_samples):\n            # Perceptron mistake condition\n            if labels[i] * np.dot(w, features[i]) = 0:\n                # Perceptron update rule\n                w += labels[i] * features[i]\n                total_updates += 1\n                updates_in_pass += 1\n        \n        # Termination condition\n        if updates_in_pass == 0:\n            break\n            \n    return total_updates\n\ndef run_single_case(d, n, rho, seed, m):\n    \"\"\"\n    Performs the full analysis for a single test case.\n\n    Args:\n        d (int): Number of features (dimensions).\n        n (int): Number of samples.\n        rho (float): Correlation coefficient.\n        seed (int): Random seed for reproducibility.\n        m (float): Margin injection constant.\n\n    Returns:\n        list[int, int]: A pair of integers [u_orig, u_ortho].\n    \"\"\"\n    # 1. Set seed for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    # 2. Generate synthetic data\n    # Create the equicorrelation covariance matrix\n    cov_matrix = (1 - rho) * np.eye(d) + rho * np.ones((d, d))\n    \n    # Draw samples from a multivariate normal distribution\n    X_initial = rng.multivariate_normal(mean=np.zeros(d), cov=cov_matrix, size=n)\n    \n    # Draw a ground-truth weight vector\n    w_star = rng.standard_normal(size=d)\n    \n    # Assign labels\n    y = np.sign(X_initial @ w_star)\n    # Ensure labels are in {-1, +1}\n    y[y == 0] = 1\n    \n    # 3. Perform margin injection\n    u = w_star / np.linalg.norm(w_star)\n    # Use broadcasting to add the margin term to each row of X\n    X_orig = X_initial + m * y[:, np.newaxis] * u\n    \n    # 4. Run perceptron on original features\n    u_orig = run_perceptron(X_orig, y)\n    \n    # 5. Decorrelate features using Gram-Schmidt (QR decomposition)\n    # 'reduced' mode is essential for non-square matrices\n    Q, R = np.linalg.qr(X_orig, mode='reduced')\n    Z_ortho = Q\n    \n    # 6. Run perceptron on decorrelated features\n    u_ortho = run_perceptron(Z_ortho, y)\n    \n    return [u_orig, u_ortho]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Margin injection constant common to all tests\n    m = 1.0\n\n    # Test suite: (d, n, rho, seed)\n    test_cases = [\n        (2, 100, 0.0, 42),\n        (2, 100, 0.95, 43),\n        (2, 100, -0.95, 44),\n        (3, 120, 0.8, 45),\n    ]\n\n    results = []\n    for d, n, rho, seed in test_cases:\n        result = run_single_case(d, n, rho, seed, m)\n        results.append(result)\n\n    # Format the output string as specified, e.g., [[u1,v1],[u2,v2],...]\n    result_str_parts = [f\"[{u},{v}]\" for u, v in results]\n    final_output = f\"[{','.join(result_str_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3099389"}, {"introduction": "While the basic perceptron algorithm is guaranteed to converge on linearly separable data, its path to a solution can be inefficient, especially for datasets with a small margin between classes. This practice introduces momentum, a powerful optimization technique that helps accelerate convergence by accumulating a \"velocity\" in consistent gradient directions. You will implement this modification and measure its effects on both convergence speed and the potential for \"overshooting,\" a common behavior where an update temporarily worsens classification performance [@problem_id:3099401].", "problem": "Consider binary classification in a Euclidean space where inputs are vectors $x \\in \\mathbb{R}^d$ and labels are $y \\in \\{-1,+1\\}$. A linear classifier with bias uses an augmented weight vector $w \\in \\mathbb{R}^{d+1}$ and augmented inputs $\\tilde{x} \\in \\mathbb{R}^{d+1}$ defined by $\\tilde{x} = [x; 1]$, and predicts $f(\\tilde{x}) = \\mathrm{sign}(w^\\top \\tilde{x})$. The perceptron update is a mistake-driven rule that modifies $w$ whenever a data point is misclassified. In this task, you will implement a perceptron with momentum (a heavy-ball type update) on borderline-separable datasets to explore convergence speed and overshooting.\n\nFundamental base for this task:\n- Linear separability: A dataset $\\{(x_i,y_i)\\}_{i=1}^n$ is linearly separable if there exists $w^\\star$ such that $y_i (w^{\\star\\top} \\tilde{x}_i)  0$ for all $i$. The perceptron learning principle updates $w$ when $y_i (w^\\top \\tilde{x}_i) \\le 0$.\n- Mistake-driven updates: On a misclassified example $(x_t,y_t)$, the classical perceptron performs $w_{t+1} = w_t + \\eta y_t \\tilde{x}_t$ for learning rate $\\eta  0$.\n- Momentum (heavy-ball): A velocity vector $v_t$ is maintained with $v_{t+1} = \\beta v_t + \\eta y_t \\tilde{x}_t$ for momentum coefficient $\\beta \\in [0,1)$ on misclassification, and $v_{t+1} = \\beta v_t$ otherwise; the weight update is $w_{t+1} = w_t + v_{t+1}$.\n\nYour program must:\n1. Implement a single-pass, cyclic, mistake-driven perceptron with momentum. At iteration $t$, let $i = t \\bmod n$ index the next data point $(x_i,y_i)$. Compute the margin $m_t = y_i (w_t^\\top \\tilde{x}_i)$. If $m_t \\le 0$, perform the momentum update $v_{t+1} = \\beta v_t + \\eta y_i \\tilde{x}_i$, increment the mistake counter by $1$, and set $w_{t+1} = w_t + v_{t+1}$. If $m_t  0$, perform $v_{t+1} = \\beta v_t$ and $w_{t+1} = w_t + v_{t+1}$. Initialize $w_0 = 0$ and $v_0 = 0$. Use an iteration cap $T_{\\max}$ to stop if convergence is not achieved.\n2. Convergence criterion: declare convergence as soon as $y_j (w^\\top \\tilde{x}_j)  0$ for all $j \\in \\{1,\\dots,n\\}$.\n3. Overshooting quantification: let $M(w)$ be the total number of misclassified points under $w$, namely $M(w) = \\sum_{i=1}^n \\mathbf{1}\\{y_i (w^\\top \\tilde{x}_i) \\le 0\\}$. For each mistake-driven update (that is, each iteration with $m_t \\le 0$), compute $M(w_t)$ immediately before updating, and $M(w_{t+1})$ immediately after the update. Count an overshoot event if $M(w_{t+1})  M(w_t)$. Define the overshoot ratio as the total overshoot events divided by the total number of mistake-driven updates. If there are zero mistake-driven updates, define the overshoot ratio as $0$.\n4. Convergence speed measure: report the total number of mistake-driven updates performed until convergence (or until the iteration cap, if no convergence).\n\nTest suite. Use the following fixed datasets and hyperparameters:\n- Dataset $\\mathcal{D}_1$ (borderline-separable in $\\mathbb{R}^2$): positives at $(1.0, 1.05)$, $(2.0, 2.05)$, $(3.0, 3.05)$ and negatives at $(1.0, 0.95)$, $(2.0, 1.95)$, $(3.0, 2.95)$. Labels are $+1$ for positives and $-1$ for negatives.\n- Dataset $\\mathcal{D}_2$ (extremely small margin): positives at $(0.0, 0.001)$, $(1.0, 1.001)$, $(2.0, 2.001)$ and negatives at $(0.0, -0.001)$, $(1.0, 0.999)$, $(2.0, 1.999)$, with labels $+1$ and $-1$ respectively.\n- Dataset $\\mathcal{D}_3$ (non-separable edge case): positives at $(0.0, 0.0)$, $(1.0, 1.0)$ and negatives at $(0.0, 0.0)$, $(1.0, 1.0)$, with labels $+1$ and $-1$ respectively.\n\nConstruct the following four test cases:\n- Test case $1$: dataset $\\mathcal{D}_1$, learning rate $\\eta = 0.1$, momentum $\\beta = 0.0$, iteration cap $T_{\\max} = 5000$.\n- Test case $2$: dataset $\\mathcal{D}_1$, learning rate $\\eta = 0.1$, momentum $\\beta = 0.9$, iteration cap $T_{\\max} = 5000$.\n- Test case $3$: dataset $\\mathcal{D}_2$, learning rate $\\eta = 0.05$, momentum $\\beta = 0.95$, iteration cap $T_{\\max} = 8000$.\n- Test case $4$: dataset $\\mathcal{D}_3$, learning rate $\\eta = 0.1$, momentum $\\beta = 0.9$, iteration cap $T_{\\max} = 2000$.\n\nRequired outputs for each test case, in order:\n- The integer number of mistake-driven updates until convergence (or until the iteration cap if not converged).\n- The overshoot ratio as a float rounded to $6$ decimals.\n- A boolean indicating whether convergence was achieved.\n\nFinal output format:\nYour program should produce a single line of output containing the aggregated results for the four test cases as a comma-separated list enclosed in square brackets, where each element is the list $[\\text{steps}, \\text{overshoot\\_ratio}, \\text{converged}]$ for one test case. For example, an output of the form $[[s_1, r_1, c_1],[s_2, r_2, c_2],[s_3, r_3, c_3],[s_4, r_4, c_4]]$, with the overshoot ratios rounded to $6$ decimals.", "solution": "We begin with the perceptron classification model in augmented form. For an input $x \\in \\mathbb{R}^d$, we append a constant bias coordinate to obtain $\\tilde{x} = [x; 1] \\in \\mathbb{R}^{d+1}$. A linear classifier parameterized by $w \\in \\mathbb{R}^{d+1}$ predicts $f(\\tilde{x}) = \\mathrm{sign}(w^\\top \\tilde{x})$. The margin of $(\\tilde{x},y)$ under $w$ is $m = y (w^\\top \\tilde{x})$. Correct classification corresponds to $m  0$.\n\nThe perceptron learning principle is mistake-driven: whenever a point $(\\tilde{x}_i, y_i)$ is misclassified or lies on the decision boundary, $y_i (w^\\top \\tilde{x}_i) \\le 0$, the parameters are updated in the direction of $y_i \\tilde{x}_i$. The classical update is $w_{t+1} = w_t + \\eta y_t \\tilde{x}_t$ for learning rate $\\eta  0$. To incorporate momentum, we maintain a velocity vector $v_t \\in \\mathbb{R}^{d+1}$ that exponentially averages past updates. The heavy-ball style update is defined by\n$$\nv_{t+1} =\n\\begin{cases}\n\\beta v_t + \\eta y_t \\tilde{x}_t  \\text{if } y_t (w_t^\\top \\tilde{x}_t) \\le 0,\\\\\n\\beta v_t  \\text{if } y_t (w_t^\\top \\tilde{x}_t)  0,\n\\end{cases}\n\\qquad\nw_{t+1} = w_t + v_{t+1},\n$$\nwith $\\beta \\in [0,1)$ the momentum coefficient. We initialize $w_0 = 0$ and $v_0 = 0$. Iterations cycle deterministically through the dataset: at iteration $t$, the index is $i = t \\bmod n$ over $n$ points. This is a deterministic cyclic schedule aligned with mistake-driven logic to test convergence behavior.\n\nConvergence is detected when the current parameters $w$ correctly classify all training points, that is, when $y_j (w^\\top \\tilde{x}_j)  0$ for all $j \\in \\{1,\\dots,n\\}$. We quantify two aspects:\n1. Convergence speed: the total number of mistake-driven updates taken until convergence. Formally, count the iterations where $y_t (w_t^\\top \\tilde{x}_t) \\le 0$ and an update uses $\\eta y_t \\tilde{x}_t$; denote this count by an integer $S$.\n2. Overshooting: momentum can cause updates that deteriorate the immediate classification performance, especially on borderline-separable datasets with small margins. We define $M(w) = \\sum_{i=1}^n \\mathbf{1}\\{y_i (w^\\top \\tilde{x}_i) \\le 0\\}$ as the misclassification count. On each mistake-driven update, compute $M(w_t)$ before updating and $M(w_{t+1})$ after. If $M(w_{t+1})  M(w_t)$, count an overshoot event. The overshoot ratio is the number of overshoot events divided by $S$, and is defined to be $0$ if $S = 0$.\n\nThe algorithm proceeds as follows:\n- Initialize $w_0 = 0$, $v_0 = 0$, mistake count $S = 0$, overshoot count $O = 0$.\n- For $t = 0,1,2,\\dots$ until an iteration cap $T_{\\max}$:\n  - Set $i = t \\bmod n$ and compute $m_t = y_i (w_t^\\top \\tilde{x}_i)$.\n  - Compute the current misclassification count $M(w_t)$.\n  - If $m_t \\le 0$, update $v_{t+1} = \\beta v_t + \\eta y_i \\tilde{x}_i$, then $w_{t+1} = w_t + v_{t+1}$, increment $S$. Compute $M(w_{t+1})$; if $M(w_{t+1})  M(w_t)$, increment $O$.\n  - If $m_t  0$, update $v_{t+1} = \\beta v_t$ and $w_{t+1} = w_t + v_{t+1}$.\n  - After the update, check convergence: if $M(w_{t+1}) = 0$, stop.\n- The outputs are $S$, overshoot ratio $O/S$ rounded to $6$ decimals (or $0$ if $S = 0$), and a boolean indicating convergence.\n\nWhy these definitions are grounded:\n- The margin $y (w^\\top \\tilde{x})$ directly encodes correct classification and is the foundational quantity in linear classification under the perceptron principle.\n- The mistake-driven rule follows the well-tested perceptron algorithm, a cornerstone in statistical learning for linearly separable data.\n- Momentum with coefficient $\\beta$ averages past updates to accelerate movement along consistent directions, potentially reducing the number of updates to reach a separating hyperplane on borderline-separable data, but it can overshoot due to inertia, temporarily increasing $M(w)$.\n\nThe test suite explores:\n- A typical borderline-separable dataset $\\mathcal{D}_1$ with small offset between classes, comparing no momentum ($\\beta = 0$) and strong momentum ($\\beta = 0.9$).\n- An extremely small margin dataset $\\mathcal{D}_2$ with strong momentum ($\\beta = 0.95$) to highlight overshooting tendencies.\n- A non-separable dataset $\\mathcal{D}_3$ as a boundary condition to verify termination by iteration cap with no convergence.\n\nThe final program implements exactly this algorithm, computes the required metrics for each test case, rounds overshoot ratios to $6$ decimals, and prints the aggregated results in the specified single-line format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef misclassification_count(w, Xb, y):\n    # y * (Xb @ w) = 0 counts as misclassification\n    margins = y * (Xb @ w)\n    return int(np.sum(margins = 0.0))\n\ndef perceptron_with_momentum(X, y, eta, beta, max_steps):\n    \"\"\"\n    Implements cyclic mistake-driven perceptron with momentum.\n\n    Parameters:\n        X: np.ndarray of shape (n_samples, n_features)\n        y: np.ndarray of shape (n_samples,), labels in {-1, +1}\n        eta: float, learning rate\n        beta: float, momentum coefficient in [0,1)\n        max_steps: int, iteration cap (each iteration visits one example)\n\n    Returns:\n        steps: int, number of mistake-driven updates performed\n        overshoot_ratio: float, overshoot events / steps (rounded to 6 decimals)\n        converged: bool, True if converged before cap\n    \"\"\"\n    n, d = X.shape\n    # Augment with bias term\n    Xb = np.hstack([X, np.ones((n, 1))])\n    w = np.zeros(d + 1, dtype=float)\n    v = np.zeros(d + 1, dtype=float)\n\n    steps = 0  # mistake-driven updates\n    overshoots = 0  # overshoot events only counted on mistake-driven updates\n\n    converged = False\n    for t in range(max_steps):\n        i = t % n\n        margin = y[i] * (np.dot(w, Xb[i]))\n        before_mis = misclassification_count(w, Xb, y)\n\n        if margin = 0.0:\n            # mistake-driven update\n            v = beta * v + eta * y[i] * Xb[i]\n            w_new = w + v\n            after_mis = misclassification_count(w_new, Xb, y)\n            steps += 1\n            if after_mis > before_mis:\n                overshoots += 1\n            w = w_new\n        else:\n            # decay-only update\n            v = beta * v\n            w = w + v\n\n        # check convergence\n        if misclassification_count(w, Xb, y) == 0:\n            converged = True\n            break\n\n    if steps == 0:\n        overshoot_ratio = 0.0\n    else:\n        overshoot_ratio = round(overshoots / steps, 6)\n\n    return steps, overshoot_ratio, converged\n\ndef solve():\n    # Define the datasets as per the problem statement.\n    # Dataset D1: borderline-separable\n    X1 = np.array([\n        [1.0, 1.05], [2.0, 2.05], [3.0, 3.05],  # positives\n        [1.0, 0.95], [2.0, 1.95], [3.0, 2.95]   # negatives\n    ], dtype=float)\n    y1 = np.array([+1, +1, +1, -1, -1, -1], dtype=int)\n\n    # Dataset D2: extremely small margin\n    X2 = np.array([\n        [0.0, 0.001], [1.0, 1.001], [2.0, 2.001],   # positives\n        [0.0, -0.001], [1.0, 0.999], [2.0, 1.999]   # negatives\n    ], dtype=float)\n    y2 = np.array([+1, +1, +1, -1, -1, -1], dtype=int)\n\n    # Dataset D3: non-separable edge case\n    X3 = np.array([\n        [0.0, 0.0], [1.0, 1.0],   # positives\n        [0.0, 0.0], [1.0, 1.0]    # negatives (duplicate locations)\n    ], dtype=float)\n    y3 = np.array([+1, +1, -1, -1], dtype=int)\n\n    # Test cases: (X, y, eta, beta, max_steps)\n    test_cases = [\n        (X1, y1, 0.1, 0.0, 5000),   # Case 1: baseline no momentum\n        (X1, y1, 0.1, 0.9, 5000),   # Case 2: strong momentum on D1\n        (X2, y2, 0.05, 0.95, 8000), # Case 3: tiny margin with strong momentum\n        (X3, y3, 0.1, 0.9, 2000)    # Case 4: non-separable edge case\n    ]\n\n    results = []\n    for X, y, eta, beta, max_steps in test_cases:\n        steps, overshoot_ratio, converged = perceptron_with_momentum(X, y, eta, beta, max_steps)\n        # Ensure overshoot ratio is a float with up to 6 decimals already\n        results.append([steps, overshoot_ratio, converged])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3099401"}, {"introduction": "The standard perceptron update rule, $w \\leftarrow w + yx$, reveals a critical vulnerability: the magnitude of the update is directly proportional to the norm of the input vector $x$. This makes the algorithm highly sensitive to outliers, where a single misclassified point with a large norm can derail the learning process. This exercise asks you to quantify this sensitivity and then implement and test two practical mitigation strategies: update clipping and robust data normalization, providing valuable insight into building more robust classifiers [@problem_id:3099471].", "problem": "You are asked to implement and evaluate a linear classifier trained by the perceptron algorithm under the presence of a small number of large-norm outliers. The aim is to quantify sensitivity to these outliers and to test two mitigation strategies: clipping the update magnitudes and robust normalization based on a distributional scale estimate. Your implementation must be a complete, runnable program that produces exactly the specified output format.\n\nStart from the following fundamental base and core definitions. A linear classifier is defined by a weight vector $w \\in \\mathbb{R}^d$ and a bias $b \\in \\mathbb{R}$, and it predicts a label $\\hat{y} \\in \\{-1,+1\\}$ on an input $x \\in \\mathbb{R}^d$ via the decision rule $\\hat{y} = \\mathrm{sign}(w^\\top x + b)$. The perceptron learning rule updates the parameters when a sample $(x,y)$ is misclassified, performing $w \\leftarrow w + y x$ and $b \\leftarrow b + y$ whenever $y(w^\\top x + b) \\le 0$. The number of mistakes made by the perceptron on linearly separable data is known to be upper bounded by a quantity that depends on the data radius and the margin; however, you should not assume any specific shortcut formula and must instead implement and measure the behavior empirically.\n\nYou will generate synthetic data in $d=2$ dimensions with two linearly separable classes. Use the following construction and parameters for all test cases:\n- Let the base scale be $R = 1.0$.\n- Place the positive-class center at $\\mu_+ = (3R, 0)$ and the negative-class center at $\\mu_- = (-3R, 0)$.\n- For each class, generate $n_+ = n_- = 50$ base points with coordinates $x = (\\mu_{\\mathrm{class},1}, u)$ where $u$ is sampled uniformly from the interval $[-R, R]$ independent for each point, and $\\mu_{\\mathrm{class},1}$ is the first coordinate of the corresponding class center. This ensures linear separability by the hyperplane defined by $x_1 = 0$.\n- Outliers: When specified by a test case, add $k_+ = k_- = 2$ outliers per class, placed deterministically at $x = (N\\cdot R, 0)$ for the positive class and $x = (-N\\cdot R, 0)$ for the negative class, where $N$ is the outlier norm factor specific to the test case. Insert outliers at the beginning of the sequence in alternating order by class: positive, negative, positive, negative, and then append all base points (first all positive-class base points, then all negative-class base points). This ordering increases the potential for harmful updates due to alternating large-norm misclassifications early in training.\n- Labels are $y=+1$ for positive-class points and $y=-1$ for negative-class points.\n\nTraining protocol to be implemented:\n- Augment inputs with a bias term by appending a constant feature $1$, so that updates can be written in vector form on augmented vectors.\n- Initialize the weight vector to the zero vector and the bias to $0$, equivalently initialize the augmented weight vector to the zero vector.\n- Perform $T = 5$ full passes (epochs) over the dataset in the fixed order described above, without shuffling between epochs.\n- For each sample $(x, y)$, if $y \\cdot (w^\\top x + b) \\le 0$ then make an update. The precise form of the update depends on the mitigation method specified by the test case:\n  1. Standard perceptron: perform the unmodified update $w \\leftarrow w + y x$ and $b \\leftarrow b + y$ on the original $x$.\n  2. Clipped updates: compute the Euclidean norm $\\|x\\|_2$. Let $c$ be a positive threshold; define a scaling factor $s = \\min\\{1, c / \\|x\\|\\}$. Apply the update using $s x$ in place of $x$, that is $w \\leftarrow w + y (s x)$ and $b \\leftarrow b + y$. This limits the maximum step magnitude contributed by any single example.\n  3. Robust normalization: pre-process all inputs $x_i$ by computing the robust scale parameter $s_{\\mathrm{rob}} = \\mathrm{median}(\\{\\|x_i\\|_2\\})$ across the full training set. Replace each $x_i$ by $\\tilde{x}_i = x_i \\cdot \\frac{s_{\\mathrm{rob}}}{\\max\\{s_{\\mathrm{rob}}, \\|x_i\\|_2\\}}$, then train with the standard perceptron update on the normalized inputs. This leaves points with $\\|x_i\\|_2 \\le s_{\\mathrm{rob}}$ unchanged and downscales larger-norm points to have norm at most $s_{\\mathrm{rob}}$.\n\nMetric to report for each test case:\n- Count the total number of updates (equivalently, the total number of mistakes) made across all $T$ epochs. This is an integer.\n\nYou must implement the above in a single program and run it on the following test suite, which is designed to cover a general case, moderate outliers, and extreme outliers, as well as the mitigation strategies:\n- Test case $1$: No outliers ($N = 0$), standard perceptron.\n- Test case $2$: Moderate outliers with $N = 50$, standard perceptron.\n- Test case $3$: Moderate outliers with $N = 50$, clipped updates with threshold $c = R$.\n- Test case $4$: Moderate outliers with $N = 50$, robust normalization.\n- Test case $5$: Extreme outliers with $N = 1000$, standard perceptron.\n- Test case $6$: Extreme outliers with $N = 1000$, clipped updates with threshold $c = R/2$.\n\nDeterminism requirement:\n- Use a fixed seed $s_0 = 2025$ for any randomness in data generation to ensure deterministic outputs.\n- Do not shuffle the dataset between epochs.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1, r_2, r_3, r_4, r_5, r_6]$, where $r_i$ is the integer total update count for test case $i$ in the order listed above. The printed line must contain only this list, with no additional text.", "solution": "The problem requires the implementation and evaluation of the perceptron linear classifier, with a specific focus on its sensitivity to large-norm outliers and the efficacy of two mitigation strategies. The solution involves generating synthetic data, implementing the perceptron algorithm with specified modifications, and reporting the total number of classification mistakes (updates) across several test cases.\n\nA linear classifier is defined by a weight vector $w \\in \\mathbb{R}^d$ and a scalar bias $b \\in \\mathbb{R}$. For an input vector $x \\in \\mathbb{R}^d$, it predicts a label $\\hat{y} \\in \\{-1, +1\\}$ according to the rule $\\hat{y} = \\mathrm{sign}(w^\\top x + b)$. The problem is set in $d=2$ dimensions. The perceptron learning algorithm iteratively adjusts the parameters $w$ and $b$ to correctly classify training examples. When an example $(x, y)$ is misclassified, which occurs if the condition $y(w^\\top x + b) \\le 0$ is met, the parameters are updated as follows:\n$$\nw \\leftarrow w + y x\n$$\n$$\nb \\leftarrow b + y\n$$\nFor notational and computational convenience, we can augment the input and weight vectors. Let the augmented weight vector be $\\tilde{w} = [w_1, \\dots, w_d, b]^\\top \\in \\mathbb{R}^{d+1}$ and the augmented input vector be $\\tilde{x} = [x_1, \\dots, x_d, 1]^\\top \\in \\mathbb{R}^{d+1}$. The decision rule becomes $\\hat{y} = \\mathrm{sign}(\\tilde{w}^\\top \\tilde{x})$, and the update rule for a misclassification, $y(\\tilde{w}^\\top \\tilde{x}) \\le 0$, simplifies to a single vector addition:\n$$\n\\tilde{w} \\leftarrow \\tilde{w} + y\\tilde{x}\n$$\nThe parameters are initialized to zero, i.e., $\\tilde{w}_{\\text{init}} = \\mathbf{0}$.\n\nA crucial property of the standard perceptron update is that the magnitude of the change to the weight vector is $\\|\\Delta \\tilde{w}\\|_2 = \\|y\\tilde{x}\\|_2 = \\|\\tilde{x}\\|_2 = \\sqrt{\\|x\\|_2^2 + 1}$. This direct dependence on the norm of the input vector is the source of the algorithm's sensitivity to outliers. A misclassified point with an unusually large norm will cause a disproportionately large update, potentially moving the decision boundary far from an optimal position and causing many subsequent mistakes on other, well-behaved data points.\n\nThe experiment is designed to demonstrate this phenomenon. A base dataset is generated from two classes centered at $\\mu_+ = (3R, 0)$ and $\\mu_- = (-3R, 0)$ respectively, with a base scale of $R=1.0$. Each class contains $n=50$ points of the form $(\\mu_{\\mathrm{class},1}, u)$ where $u$ is drawn from a uniform distribution over $[-R, R]$. This construction creates a dataset that is linearly separable by the vertical axis $x_1=0$. To this clean dataset, we add $k=2$ pairs of outliers, located deterministically at $(\\pm N \\cdot R, 0)$. The outlier norm factor $N$ is large ($N \\in \\{50, 1000\\}$), ensuring these points have a very large norm. These outliers are placed at the beginning of the training sequence to maximize their disruptive effect on the initially zero-valued weight vector.\n\nTwo mitigation strategies are tested against the standard perceptron:\n\n1.  **Clipped Updates**: This strategy directly constrains the magnitude of the parameter update. For a misclassified point $(x, y)$, a scaling factor $s = \\min\\{1, c/\\|x\\|_2\\}$ is computed based on a pre-defined clipping threshold $c0$. The weight vector $w$ is updated via $w \\leftarrow w + y(sx)$, while the bias is updated normally, $b \\leftarrow b+y$. This means the update to the spatial weights is scaled, but the update to the bias term is not. This approach ensures that the change in $w$ due to any single sample is bounded.\n\n2.  **Robust Normalization**: This is a data pre-processing technique applied once before training commences. First, a robust estimate of the data's scale, $s_{\\mathrm{rob}} = \\mathrm{median}(\\{\\|x_i\\|_2\\})$, is calculated over the entire training set. Then, each input vector $x_i$ is replaced by a normalized version $\\tilde{x}_i$:\n    $$\n    \\tilde{x}_i = x_i \\cdot \\frac{s_{\\mathrm{rob}}}{\\max\\{s_{\\mathrm{rob}}, \\|x_i\\|_2\\}}\n    $$\n    This transformation leaves points with norms less than or equal to the median norm unchanged, while shrinking all points with norms greater than the median to have a norm of exactly $s_{\\mathrm{rob}}$. This effectively \"pulls in\" the large-norm outliers, reducing their potential impact before the learning process begins.\n\nThe implementation will proceed by first generating the specified dataset for each test case. Then, for the 'robust normalization' case, the data is pre-processed. The training loop iterates $T=5$ times (epochs) over the fixed-order dataset. Within each epoch, every sample is evaluated. If a mistake is made, the total mistake counter is incremented, and the weights are updated according to the method specified for that test case ('standard', 'clipped', or 'robust'). The final output for each case is the total accumulated count of mistakes. The entire procedure is made deterministic by using a fixed random seed $s_0=2025$ for data generation and by not shuffling the data between epochs.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_test_case(params, seed):\n    \"\"\"\n    Runs a single test case for the perceptron algorithm.\n\n    Args:\n        params (dict): A dictionary containing the parameters for the test case,\n                       including 'N', 'method', and 'c'.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        int: The total number of updates (mistakes) made during training.\n    \"\"\"\n    np.random.seed(seed)\n    \n    # Define problem constants\n    R = 1.0\n    n = 50\n    k = 2\n    d = 2\n    T = 5\n    \n    # Extract test case parameters\n    N = params['N']\n    method = params['method']\n    c = params['c']\n\n    # --- Data Generation ---\n    # Base points\n    x_pos_base = np.zeros((n, d))\n    x_pos_base[:, 0] = 3 * R\n    x_pos_base[:, 1] = np.random.uniform(-R, R, size=n)\n    y_pos_base = np.ones(n)\n\n    x_neg_base = np.zeros((n, d))\n    x_neg_base[:, 0] = -3 * R\n    x_neg_base[:, 1] = np.random.uniform(-R, R, size=n)\n    y_neg_base = -np.ones(n)\n\n    # Assemble dataset with outliers first, in specified alternating order\n    X_list = []\n    y_list = []\n\n    if N > 0:\n        x_pos_outlier = np.array([N * R, 0.0])\n        x_neg_outlier = np.array([-N * R, 0.0])\n        for _ in range(k):\n            X_list.append(x_pos_outlier)\n            y_list.append(1.0)\n            X_list.append(x_neg_outlier)\n            y_list.append(-1.0)\n    \n    X_list.extend(list(x_pos_base))\n    y_list.extend(list(y_pos_base))\n    X_list.extend(list(x_neg_base))\n    y_list.extend(list(y_neg_base))\n\n    X = np.array(X_list)\n    y = np.array(y_list)\n\n    # --- Pre-processing for Robust Normalization ---\n    if method == 'robust':\n        norms = np.linalg.norm(X, axis=1)\n        # Handle the case where all norms are zero to avoid division by zero\n        s_rob = np.median(norms)\n        if s_rob > 0:\n            scaling_factors = s_rob / np.maximum(s_rob, norms)\n            X = X * scaling_factors[:, np.newaxis]\n\n    # --- Training ---\n    # Augment inputs with a bias term\n    X_aug = np.hstack([X, np.ones((X.shape[0], 1))])\n    \n    # Initialize augmented weight vector\n    w_aug = np.zeros(d + 1)\n    \n    update_count = 0\n\n    for _ in range(T):\n        for i in range(X.shape[0]):\n            x_i_aug = X_aug[i]\n            y_i = y[i]\n            \n            # Check for misclassification\n            if y_i * (w_aug @ x_i_aug) = 0:\n                update_count += 1\n                \n                # Apply update based on the specified method\n                if method == 'standard' or method == 'robust':\n                    w_aug += y_i * x_i_aug\n                elif method == 'clipped':\n                    x_i = X[i]  # Original un-augmented vector for norm calculation\n                    norm_x = np.linalg.norm(x_i)\n                    s = 1.0\n                    if norm_x > 0 and c is not None:\n                        s = min(1.0, c / norm_x)\n                    \n                    # Update weights and bias separately as specified\n                    w_update = y_i * s * x_i\n                    b_update = y_i * 1.0  # Bias update is not scaled\n                    \n                    w_aug[:d] += w_update\n                    w_aug[d] += b_update\n\n    return update_count\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    s0 = 2025\n    test_cases = [\n        {'N': 0, 'method': 'standard', 'c': None},\n        {'N': 50, 'method': 'standard', 'c': None},\n        {'N': 50, 'method': 'clipped', 'c': 1.0},\n        {'N': 50, 'method': 'robust', 'c': None},\n        {'N': 1000, 'method': 'standard', 'c': None},\n        {'N': 1000, 'method': 'clipped', 'c': 0.5},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_single_test_case(params, s0)\n        all_results.append(result)\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3099471"}]}