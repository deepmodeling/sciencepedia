{"hands_on_practices": [{"introduction": "This exercise provides a concrete, step-by-step calculation of a single update in Stochastic Gradient Descent. It breaks down the process of using just one data point to approximate the overall gradient, which is the foundational concept behind SGD's efficiency. By working through this simple quadratic example, you will gain a hands-on feel for the core mechanics of the algorithm and see how the parameter is adjusted based on the error from a single sample [@problem_id:2206637].", "problem": "An iterative optimization algorithm is used to find a parameter $x$ that minimizes a cost function. The total cost function is an average of several component functions: $F(x) = \\frac{1}{N}\\sum_{i=1}^{N} f_i(x)$. In this specific case, the component functions are quadratic and given by $f_i(x) = (x - c_i)^2$, where the constants are $c_i = i$ for $i = 1, 2, \\dots, 10$, and thus $N=10$.\n\nThe optimization process starts with an initial guess for the parameter, $x_0$. At each step, a new estimate, $x_{k+1}$, is calculated from the current estimate, $x_k$, by using only a single, randomly chosen component function, $f_j(x)$. The update rule is defined as:\n$$x_{k+1} = x_k - \\eta \\left( \\frac{d f_j(x)}{dx} \\bigg|_{x=x_k} \\right)$$\nwhere $\\eta$ is a constant known as the learning rate.\n\nGiven an initial parameter value of $x_0 = 10.0$ and a learning rate of $\\eta = 0.1$, compute the value of the parameter $x_1$ after one update step. For this first step, the component function used is $f_j(x)$ with the index $j=5$.", "solution": "We are given component functions of the form $f_{i}(x) = (x - c_{i})^{2}$ with $c_{i} = i$. For the first update, the chosen index is $j=5$, so the component function is $f_{5}(x) = (x - 5)^{2}$.\n\nThe update rule is\n$$\nx_{k+1} = x_{k} - \\eta \\left.\\frac{d f_{j}(x)}{dx}\\right|_{x=x_{k}}.\n$$\nUsing the power rule and chain rule, the derivative of the chosen component is\n$$\n\\frac{d f_{5}(x)}{dx} = \\frac{d}{dx}\\left[(x - 5)^{2}\\right] = 2(x - 5).\n$$\nEvaluating at the current iterate $x_{0} = 10$ gives\n$$\n\\left.\\frac{d f_{5}(x)}{dx}\\right|_{x=10} = 2(10 - 5) = 10.\n$$\nWith learning rate $\\eta = 0.1$, the update becomes\n$$\nx_{1} = x_{0} - \\eta \\cdot 10 = 10 - 0.1 \\times 10 = 10 - 1 = 9.\n$$\nThus, after one update step using $f_{5}$, the parameter value is $x_{1} = 9$.", "answer": "$$\\boxed{9}$$", "id": "2206637"}, {"introduction": "The learning rate, denoted by $\\eta$, is arguably the most critical hyperparameter in SGD, as it controls the magnitude of the steps taken toward the minimum. This exercise demonstrates the dramatic effect of an improperly chosen learning rate. You will observe firsthand how a learning rate that is too large can cause the optimization process to \"overshoot\" the minimum and diverge, a common and important challenge to understand when training machine learning models [@problem_id:2206673].", "problem": "In a machine learning context, we often optimize a model's parameters by minimizing a loss function. Consider a simplified model with a single scalar parameter, $w$. The loss function associated with a single data point is given by $L(w) = \\frac{1}{2} c w^2$, where the minimum loss occurs at $w=0$. The parameter is updated using the Stochastic Gradient Descent (SGD) algorithm. The update rule for the parameter at step $k$ is given by $w_{k+1} = w_k - \\eta \\nabla L(w_k)$, where $\\nabla L(w_k)$ is the gradient of the loss function evaluated at $w_k$, and $\\eta$ is the learning rate.\n\nSuppose the initial value of the parameter is $w_0 = 4.0$. The model parameters are set as $c = 0.75$ and the learning rate is $\\eta = 3.2$. Calculate the value of the parameter $w$ after 3 update steps (i.e., find $w_3$).\n\nRound your final answer to three significant figures.", "solution": "The loss is $L(w)=\\frac{1}{2} c w^{2}$. Its gradient is obtained by differentiation:\n$$\n\\nabla L(w)=\\frac{\\mathrm{d}}{\\mathrm{d}w}\\left(\\frac{1}{2} c w^{2}\\right)=c w.\n$$\nThe SGD update rule is\n$$\nw_{k+1}=w_{k}-\\eta \\nabla L(w_{k})=w_{k}-\\eta c w_{k}=(1-\\eta c)\\,w_{k}.\n$$\nThis linear recurrence solves to\n$$\nw_{k}=(1-\\eta c)^{k} w_{0}.\n$$\nSubstituting $c=0.75$, $\\eta=3.2$, and $w_{0}=4.0$,\n$$\n1-\\eta c=1-(3.2)(0.75)=1-2.4=-1.4,\n$$\nso\n$$\nw_{3}=(-1.4)^{3}\\cdot 4.0=-10.976.\n$$\nRounding to three significant figures gives $-11.0$.", "answer": "$$\\boxed{-11.0}$$", "id": "2206673"}, {"introduction": "Gradient-based algorithms like SGD fundamentally rely on the gradient to provide a direction for improvement. This conceptual problem explores a critical scenario where this principle breaks down. By analyzing a model with a step-function loss, you will uncover why SGD fails when the loss function is flat almost everywhere, providing no useful directional information for the updates. This practice highlights the essential requirement of using sufficiently smooth loss functions for gradient-based optimization methods to be effective [@problem_id:2206644].", "problem": "An engineer is developing a real-time monitoring system for a critical process in a factory. The system uses a single sensor reading, denoted by $x$, to predict a key performance indicator, $y$. For this task, the engineer selects a simple linear model without a bias term: $y_{pred} = w \\cdot x$, where $w$ is the single model parameter to be learned.\n\nFor this specific application, an error is only considered significant if its magnitude, $|y_{true} - y_{pred}|$, exceeds a predefined tolerance threshold, $\\epsilon > 0$. Any prediction error within this tolerance is deemed acceptable. To formalize this, the engineer designs a custom loss function, $L(w)$, for a single data point $(x, y_{true})$ as follows:\n$$\nL(w) = \\begin{cases} 0 & \\text{if } |y_{true} - w \\cdot x| \\le \\epsilon \\\\ 1 & \\text{if } |y_{true} - w \\cdot x| > \\epsilon \\end{cases}\n$$\nThe engineer attempts to find the optimal value of $w$ by training the model on a large dataset of $(x, y_{true})$ pairs using the Stochastic Gradient Descent (SGD) algorithm. After running the training process, they observe that the parameter $w$ barely changes from its initial random value, regardless of the learning rate used.\n\nWhich of the following statements provides the most accurate and fundamental explanation for this failure of the training process?\n\nA. The step-function loss is non-convex, meaning that Stochastic Gradient Descent (SGD) is likely to get trapped in a local minimum that is not the global minimum.\n\nB. For almost any given value of the parameter $w$, the gradient of the loss function with respect to $w$ is zero, meaning the SGD update step does not change the parameter's value.\n\nC. The loss function is discontinuous, and the infinite gradients at the points of discontinuity cause numerical overflow and unstable updates in the SGD algorithm.\n\nD. The stochasticity of SGD introduces too much noise when using a binary (0/1) loss, preventing the parameter $w$ from converging to a stable value.", "solution": "We consider the per-sample loss as a function of the single parameter $w$:\n$$\nL(w)=\\begin{cases}\n0 & \\text{if } |y_{\\text{true}}-wx|\\le \\epsilon,\\\\\n1 & \\text{if } |y_{\\text{true}}-wx|>\\epsilon.\n\\end{cases}\n$$\nDefine the error $e(w)=y_{\\text{true}}-wx$. The loss is a step function of $w$ that switches value at the points where $|e(w)|=\\epsilon$. For $x\\neq 0$, the condition $|y_{\\text{true}}-wx|\\le \\epsilon$ defines a closed interval in $w$:\n$$\n|y_{\\text{true}}-wx|\\le \\epsilon \\iff -\\epsilon \\le y_{\\text{true}}-wx \\le \\epsilon.\n$$\nIf $x>0$, this gives\n$$\n\\frac{y_{\\text{true}}-\\epsilon}{x} \\le w \\le \\frac{y_{\\text{true}}+\\epsilon}{x},\n$$\nand if $x<0$, the inequalities reverse but the feasible set is still the closed interval with endpoints $\\frac{y_{\\text{true}}-\\epsilon}{x}$ and $\\frac{y_{\\text{true}}+\\epsilon}{x}$. Outside this interval, $L(w)=1$; inside, $L(w)=0$. Therefore $L(w)$ is piecewise constant with jumps only at the two boundary points\n$$\nw=\\frac{y_{\\text{true}}-\\epsilon}{x} \\quad \\text{and} \\quad w=\\frac{y_{\\text{true}}+\\epsilon}{x}.\n$$\nFor $x=0$, we have $e(w)=y_{\\text{true}}$ independent of $w$, so $L(w)$ is constant for all $w$ and thus flat everywhere.\n\nDifferentiability: On any open interval that does not include a boundary point, $L(w)$ is constant, so its derivative is\n$$\n\\frac{dL}{dw}=0 \\quad \\text{for all } w \\notin S,\n$$\nwhere $S=\\{w:\\,|y_{\\text{true}}-wx|=\\epsilon\\}$. At $w\\in S$, $L(w)$ is discontinuous and not differentiable; there is no finite derivative, nor a well-defined subgradient for this $0/1$ step loss. Since $S$ is a finite set for a single sample (and a measure-zero set in $\\mathbb{R}$), the gradient with respect to $w$ is zero almost everywhere.\n\nIn stochastic gradient descent using any minibatch or single sample, the update is\n$$\nw_{t+1}=w_{t}-\\eta \\,\\frac{\\partial L}{\\partial w}(w_{t}),\n$$\nbut $\\frac{\\partial L}{\\partial w}(w_{t})=0$ for all $w_{t}\\notin S$. Because hitting exactly $w_{t}\\in S$ has probability zero under continuous updates and floating-point arithmetic, the algorithm almost never encounters a non-differentiable point and thus almost always computes a zero gradient. Consequently, $w_{t+1}=w_{t}$ for essentially all steps, so the parameter barely changes regardless of learning rate.\n\nThis establishes that the fundamental reason training fails is that the gradient is zero almost everywhere. Option A mentions non-convexity, which is true, but non-convexity alone does not force zero updates; the decisive issue here is the vanishing gradient. Option C incorrectly attributes the issue to infinite gradients at discontinuities; the derivative is undefined at the jump points and these points are rarely, if ever, encountered in practice. Option D blames stochastic noise, but the lack of parameter change is due to zero gradients rather than noise. Therefore, the most accurate and fundamental explanation is that the gradient is zero for almost all $w$, preventing SGD from updating the parameter, which corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "2206644"}]}