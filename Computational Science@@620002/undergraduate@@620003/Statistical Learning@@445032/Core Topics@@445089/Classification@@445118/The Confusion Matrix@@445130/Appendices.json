{"hands_on_practices": [{"introduction": "A confusion matrix is the direct result of a model's predictions on a set of test data. This first exercise provides fundamental, hands-on practice in the complete workflow: from applying a classifier's logic to new data points, to systematically tallying the outcomes into the structured format of a confusion matrix [@problem_id:1423429]. Completing this process solidifies the essential link between individual predictions and the aggregate performance summary.", "problem": "A systems biologist is developing a model to classify single cells into one of three distinct cell cycle phases: Phase 1 (P1), Phase 2 (P2), and Phase 3 (P3). The classification is based on the normalized expression levels of two key regulatory genes, Gene A and Gene B.\n\nA Gaussian Naive Bayes classifier is chosen for this task. This model assumes that for a given cell cycle phase, the expression levels of Gene A and Gene B are conditionally independent. It also assumes that the expression level of each gene within each phase follows a Normal (Gaussian) distribution.\n\nFrom a large set of pre-classified cells, the following statistical summary of the training data was derived:\n- The total number of training cells is 1000. The counts for each phase are: 400 cells in P1, 350 cells in P2, and 250 cells in P3.\n- The mean ($\\mu$) and standard deviation ($\\sigma$) of the normalized expression levels for each gene in each phase are given in the table below. The expression levels are dimensionless quantities.\n\n| Phase | Gene A ($\\mu_A, \\sigma_A$) | Gene B ($\\mu_B, \\sigma_B$) |\n|---|---|---|\n| P1 | (5.0, 1.0) | (4.0, 1.2) |\n| P2 | (8.0, 1.5) | (6.0, 1.0) |\n| P3 | (6.0, 1.2) | (9.0, 1.5) |\n\nA new set of 6 test cells with known true phases is collected to evaluate the classifier's performance. Their gene expression levels and true phases are:\n\n| Cell ID | Gene A Expr. | Gene B Expr. | True Phase |\n|---|---|---|---|\n| S1 | 5.5 | 4.5 | P1 |\n| S2 | 7.5 | 5.8 | P2 |\n| S3 | 6.2 | 8.5 | P3 |\n| S4 | 4.8 | 6.5 | P1 |\n| S5 | 8.5 | 8.8 | P2 |\n| S6 | 7.0 | 7.0 | P3 |\n\nFor each test cell, determine its predicted phase using the trained Gaussian Naive Bayes classifier. Then, construct the confusion matrix for the classifier's performance on this test set. The confusion matrix should be a 3x3 matrix where the rows represent the true phases (in the order P1, P2, P3) and the columns represent the predicted phases (in the order P1, P2, P3).\n\nProvide the 9 integer elements of the confusion matrix as your final answer, listed row by row. That is, provide the element for (True P1, Predicted P1), then (True P1, Predicted P2), (True P1, Predicted P3), followed by (True P2, Predicted P1), and so on.", "solution": "We model class-conditional densities with a Gaussian Naive Bayes classifier. Let the class labels be $c \\in \\{\\text{P1}, \\text{P2}, \\text{P3}\\}$ and the features be $x = (x_{A}, x_{B})$ for Gene A and Gene B. The model assumes conditional independence given the class and univariate Normal distributions for each gene:\n$$\np(x \\mid c) \\;=\\; \\prod_{j \\in \\{A,B\\}} \\frac{1}{\\sigma_{c,j}\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}}\\right).\n$$\nThe class prior probabilities from counts are\n$$\n\\pi_{\\text{P1}}=\\frac{400}{1000}=0.4,\\quad \\pi_{\\text{P2}}=\\frac{350}{1000}=0.35,\\quad \\pi_{\\text{P3}}=\\frac{250}{1000}=0.25.\n$$\nFor prediction, we compare the (unnormalized) log-posterior scores\n$$\ns_{c}(x) \\;=\\; \\ln \\pi_{c} \\;+\\; \\sum_{j \\in \\{A,B\\}} \\left[-\\ln \\sigma_{c,j} \\;-\\; \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}} \\right] \\;-\\; \\sum_{j \\in \\{A,B\\}} \\ln \\sqrt{2\\pi}.\n$$\nThe last term $-\\sum_{j} \\ln \\sqrt{2\\pi}$ is constant across classes for a fixed $x$ and can be omitted for the argmax. Define\n$$\n\\text{base}_{c} \\;=\\; \\ln \\pi_{c} \\;-\\; \\sum_{j \\in \\{A,B\\}} \\ln \\sigma_{c,j}, \\qquad Q_{c}(x) \\;=\\; \\sum_{j \\in \\{A,B\\}} \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}},\n$$\nso that $s_{c}(x)=\\text{base}_{c} - Q_{c}(x)$ up to an additive constant independent of $c$.\n\nFrom the table, the parameters are:\n- P1: $(\\mu_{A},\\sigma_{A})=(5.0,1.0)$, $(\\mu_{B},\\sigma_{B})=(4.0,1.2)$,\n- P2: $(\\mu_{A},\\sigma_{A})=(8.0,1.5)$, $(\\mu_{B},\\sigma_{B})=(6.0,1.0)$,\n- P3: $(\\mu_{A},\\sigma_{A})=(6.0,1.2)$, $(\\mu_{B},\\sigma_{B})=(9.0,1.5)$.\n\nCompute the base terms:\n$$\n\\ln \\pi_{\\text{P1}} = \\ln(0.4) \\approx -0.916291,\\quad -\\sum \\ln \\sigma_{\\text{P1},j} = -\\ln 1.0 - \\ln 1.2 \\approx -0.182322,\\quad \\text{base}_{\\text{P1}} \\approx -1.098613,\n$$\n$$\n\\ln \\pi_{\\text{P2}} = \\ln(0.35) \\approx -1.049822,\\quad -\\sum \\ln \\sigma_{\\text{P2},j} = -\\ln 1.5 - \\ln 1.0 \\approx -0.405465,\\quad \\text{base}_{\\text{P2}} \\approx -1.455287,\n$$\n$$\n\\ln \\pi_{\\text{P3}} = \\ln(0.25) \\approx -1.386294,\\quad -\\sum \\ln \\sigma_{\\text{P3},j} = -\\ln 1.2 - \\ln 1.5 \\approx -0.587787,\\quad \\text{base}_{\\text{P3}} \\approx -1.974081.\n$$\n\nFor each test cell $x=(x_{A},x_{B})$, compute $Q_{c}(x)=\\sum_{j} \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}}$ and then $s_{c}(x)=\\text{base}_{c}-Q_{c}(x)$; predict the class with the largest $s_{c}(x)$.\n\nS1: $(5.5,4.5)$.\n- P1: deviations $(0.5,0.5)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{0.5^{2}}{2\\cdot 1.0} + \\frac{0.5^{2}}{2\\cdot 1.44} = 0.125 + 0.086806 \\approx 0.211806,\\quad s_{\\text{P1}} \\approx -1.098613 - 0.211806 = -1.310419.\n$$\n- P2: deviations $(-2.5,-1.5)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{2.5^{2}}{2\\cdot 2.25} + \\frac{1.5^{2}}{2\\cdot 1.0} = 1.388889 + 1.125 = 2.513889,\\quad s_{\\text{P2}} \\approx -1.455287 - 2.513889 = -3.969176.\n$$\n- P3: deviations $(-0.5,-4.5)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{0.5^{2}}{2\\cdot 1.44} + \\frac{4.5^{2}}{2\\cdot 2.25} = 0.086806 + 4.5 = 4.586806,\\quad s_{\\text{P3}} \\approx -1.974081 - 4.586806 = -6.560887.\n$$\nPrediction: P1.\n\nS2: $(7.5,5.8)$.\n- P1: deviations $(2.5,1.8)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{2.5^{2}}{2\\cdot 1.0} + \\frac{1.8^{2}}{2\\cdot 1.44} = 3.125 + 1.125 = 4.25,\\quad s_{\\text{P1}} \\approx -1.098613 - 4.25 = -5.348613.\n$$\n- P2: deviations $(-0.5,-0.2)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{0.5^{2}}{2\\cdot 2.25} + \\frac{0.2^{2}}{2\\cdot 1.0} = 0.055556 + 0.02 = 0.075556,\\quad s_{\\text{P2}} \\approx -1.455287 - 0.075556 = -1.530843.\n$$\n- P3: deviations $(1.5,-3.2)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{1.5^{2}}{2\\cdot 1.44} + \\frac{3.2^{2}}{2\\cdot 2.25} = 0.78125 + 2.275556 = 3.056806,\\quad s_{\\text{P3}} \\approx -1.974081 - 3.056806 = -5.030887.\n$$\nPrediction: P2.\n\nS3: $(6.2,8.5)$.\n- P1: deviations $(1.2,4.5)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{1.2^{2}}{2\\cdot 1.0} + \\frac{4.5^{2}}{2\\cdot 1.44} = 0.72 + 7.03125 = 7.75125,\\quad s_{\\text{P1}} \\approx -1.098613 - 7.75125 = -8.849863.\n$$\n- P2: deviations $(-1.8,2.5)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{1.8^{2}}{2\\cdot 2.25} + \\frac{2.5^{2}}{2\\cdot 1.0} = 0.72 + 3.125 = 3.845,\\quad s_{\\text{P2}} \\approx -1.455287 - 3.845 = -5.300287.\n$$\n- P3: deviations $(0.2,-0.5)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{0.2^{2}}{2\\cdot 1.44} + \\frac{0.5^{2}}{2\\cdot 2.25} = 0.013889 + 0.055556 = 0.0694449,\\quad s_{\\text{P3}} \\approx -1.974081 - 0.0694449 = -2.043526.\n$$\nPrediction: P3.\n\nS4: $(4.8,6.5)$.\n- P1: deviations $(-0.2,2.5)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{0.2^{2}}{2\\cdot 1.0} + \\frac{2.5^{2}}{2\\cdot 1.44} = 0.02 + 2.170139 = 2.190139,\\quad s_{\\text{P1}} \\approx -1.098613 - 2.190139 = -3.288752.\n$$\n- P2: deviations $(-3.2,0.5)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{3.2^{2}}{2\\cdot 2.25} + \\frac{0.5^{2}}{2\\cdot 1.0} = 2.275556 + 0.125 = 2.400556,\\quad s_{\\text{P2}} \\approx -1.455287 - 2.400556 = -3.855843.\n$$\n- P3: deviations $(-1.2,-2.5)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{1.2^{2}}{2\\cdot 1.44} + \\frac{2.5^{2}}{2\\cdot 2.25} = 0.5 + 1.388889 = 1.888889,\\quad s_{\\text{P3}} \\approx -1.974081 - 1.888889 = -3.862970.\n$$\nPrediction: P1.\n\nS5: $(8.5,8.8)$.\n- P1: deviations $(3.5,4.8)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{3.5^{2}}{2\\cdot 1.0} + \\frac{4.8^{2}}{2\\cdot 1.44} = 6.125 + 8 = 14.125,\\quad s_{\\text{P1}} \\approx -1.098613 - 14.125 = -15.223613.\n$$\n- P2: deviations $(0.5,2.8)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{0.5^{2}}{2\\cdot 2.25} + \\frac{2.8^{2}}{2\\cdot 1.0} = 0.055556 + 3.92 = 3.975556,\\quad s_{\\text{P2}} \\approx -1.455287 - 3.975556 = -5.430843.\n$$\n- P3: deviations $(2.5,-0.2)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{2.5^{2}}{2\\cdot 1.44} + \\frac{0.2^{2}}{2\\cdot 2.25} = 2.170139 + 0.008889 = 2.179028,\\quad s_{\\text{P3}} \\approx -1.974081 - 2.179028 = -4.153109.\n$$\nPrediction: P3.\n\nS6: $(7.0,7.0)$.\n- P1: deviations $(2.0,3.0)$, variances $(1.0,1.44)$,\n$$\nQ_{\\text{P1}} = \\frac{2.0^{2}}{2\\cdot 1.0} + \\frac{3.0^{2}}{2\\cdot 1.44} = 2 + 3.125 = 5.125,\\quad s_{\\text{P1}} \\approx -1.098613 - 5.125 = -6.223613.\n$$\n- P2: deviations $(-1.0,1.0)$, variances $(2.25,1.0)$,\n$$\nQ_{\\text{P2}} = \\frac{1.0^{2}}{2\\cdot 2.25} + \\frac{1.0^{2}}{2\\cdot 1.0} = 0.222222 + 0.5 = 0.722222,\\quad s_{\\text{P2}} \\approx -1.455287 - 0.722222 = -2.177509.\n$$\n- P3: deviations $(1.0,-2.0)$, variances $(1.44,2.25)$,\n$$\nQ_{\\text{P3}} = \\frac{1.0^{2}}{2\\cdot 1.44} + \\frac{2.0^{2}}{2\\cdot 2.25} = 0.347222 + 0.888889 = 1.236111,\\quad s_{\\text{P3}} \\approx -1.974081 - 1.236111 = -3.210192.\n$$\nPrediction: P2.\n\nPredicted labels:\n- S1: P1; S4: P1 (true P1 both),\n- S2: P2; S5: P3 (true P2, one correct, one misclassified as P3),\n- S3: P3; S6: P2 (true P3, one correct, one misclassified as P2).\n\nConstruct the confusion matrix with rows as true phases (P1, P2, P3) and columns as predicted phases (P1, P2, P3). Counting:\n- True P1: predicted P1 twice, P2 zero, P3 zero → $(2,0,0)$.\n- True P2: predicted P1 zero, P2 once, P3 once → $(0,1,1)$.\n- True P3: predicted P1 zero, P2 once, P3 once → $(0,1,1)$.\n\nListed row by row, the 9 elements are $2, 0, 0, 0, 1, 1, 0, 1, 1$.", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}}$$", "id": "1423429"}, {"introduction": "A confusion matrix is more than just a table of numbers; it's a powerful diagnostic tool for understanding a classifier's behavior. This practice explores the crucial distinction between overall accuracy and the $F_1$-score, demonstrating how two models with identical accuracy can have vastly different practical performance [@problem_id:3094202]. By analyzing how different types of errors—false positives ($FP$) versus false negatives ($FN$)—impact these metrics, you will develop a deeper intuition for choosing the right metric for your problem.", "problem": "A binary classifier is evaluated on a dataset summarized by a confusion matrix with entries $(TP, FP, TN, FN)$, where $TP$ denotes the number of true positives, $FP$ denotes the number of false positives, $TN$ denotes the number of true negatives, and $FN$ denotes the number of false negatives. Accuracy ($\\text{Acc}$) is defined by $\\text{Acc} = \\frac{TP + TN}{TP + FP + TN + FN}$. Precision ($P$) and recall ($R$) are defined by $P = \\frac{TP}{TP + FP}$ and $R = \\frac{TP}{TP + FN}$, respectively. The $F_1$-score ($F_1$) is the standard single-number summary of $P$ and $R$.\n\nSelect the single option that presents two confusion matrices $(TP, FP, TN, FN)$ for two systems, say System $X$ and System $Y$, that have the same $\\text{Acc}$ but drastically different $F_1$ (interpret “drastically different” as a difference of at least $0.30$ in $F_1$), and that also provides the correct structural explanation of why $F_1$ differs, stated in terms of $P$ and $R$ and grounded in how $FP$ and $FN$ differ. Only one option satisfies both the numerical and explanatory requirements.\n\nA. System $X$: $(TP, FP, TN, FN) = (20, 5, 895, 80)$; System $Y$: $(TP, FP, TN, FN) = (80, 65, 835, 20)$. Explanation: Both systems have the same $TP + TN$, so $\\text{Acc}$ matches. $F_1$ differs because $FP$ and $FN$ are traded off: System $X$ has small $FP$ (high $P$) but large $FN$ (low $R$); System $Y$ has larger $FP$ (lower $P$) but smaller $FN$ (higher $R$), yielding a substantially different harmonic balance of $P$ and $R$.\n\nB. System $X$: $(TP, FP, TN, FN) = (50, 50, 850, 50)$; System $Y$: $(TP, FP, TN, FN) = (45, 45, 855, 55)$. Explanation: Because both have the same $\\text{Acc}$, their $F_1$ scores are necessarily equal; $F_1$ is determined solely by $\\text{Acc}$.\n\nC. System $X$: $(TP, FP, TN, FN) = (10, 10, 980, 0)$; System $Y$: $(TP, FP, TN, FN) = (10, 0, 970, 20)$. Explanation: Their $\\text{Acc}$ values are equal and $F_1$ differs because the number of true negatives $TN$ drives $F_1$ directly.\n\nD. System $X$: $(TP, FP, TN, FN) = (90, 10, 890, 10)$; System $Y$: $(TP, FP, TN, FN) = (80, 0, 900, 20)$. Explanation: Any $F_1$ difference here is caused primarily by changing $TN$, since $TN$ appears in the denominators of $P$ and $R$ and directly alters both.", "solution": "The user has requested a critical validation of the problem statement, followed by a full derivation and evaluation of the options provided.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following definitions and conditions for a binary classifier evaluated on a dataset:\n- Confusion matrix entries: $(TP, FP, TN, FN)$, representing true positives, false positives, true negatives, and false negatives.\n- Accuracy definition: $ \\text{Acc} = \\dfrac{TP + TN}{TP + FP + TN + FN} $.\n- Precision definition: $ P = \\dfrac{TP}{TP + FP} $.\n- Recall definition: $ R = \\dfrac{TP}{TP + FN} $.\n- The $\\text{F}_{1}$-score, $( F_1 )$, is defined as \"the standard single-number summary of $P$ and $R$\".\n- The task is to select the single option that presents two confusion matrices for System $X$ and System $Y$ that satisfy two numerical criteria and one explanatory criterion:\n    1.  The accuracies are the same: $\\text{Acc}_X = \\text{Acc}_Y$.\n    2.  The $F_1$ scores are \"drastically different\", interpreted as a difference of at least $0.30$: $|F_{1,X} - F_{1,Y}| \\geq 0.30$.\n    3.  The option provides the correct structural explanation for the difference in $F_1$ in terms of $P$, $R$, $FP$, and $FN$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is based on fundamental and standard metrics used in statistical learning and model evaluation. The definitions for accuracy, precision, and recall are correct. The reference to the $F_1$-score as the \"standard single-number summary\" correctly points to the harmonic mean of precision and recall, a well-established concept.\n- **Well-Posed:** The problem is a multiple-choice question requiring the application of given formulas and evaluation of logical explanations. The term \"drastically different\" is given a precise quantitative meaning ($|F_{1,X} - F_{1,Y}| \\geq 0.30$), removing ambiguity. The problem is structured to have a single correct answer satisfying both numerical and explanatory criteria.\n- **Objective:** The problem statement is written in precise, objective language, using mathematical definitions. There is no subjectivity.\n- **Completeness and Consistency:** All necessary definitions and data (within the options) are provided to solve the problem. The reference to the standard $F_1$ score is unambiguous in this context. The problem is internally consistent.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n### Solution Derivation\n\nThe $F_1$-score is the harmonic mean of precision ($P$) and recall ($R$). Its standard formula is:\n$$ F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} $$\nSubstituting the definitions of $P$ and $R$ gives a formula directly in terms of the confusion matrix components:\n$$ F_1 = 2 \\cdot \\frac{\\frac{TP}{TP + FP} \\cdot \\frac{TP}{TP + FN}}{\\frac{TP}{TP + FP} + \\frac{TP}{TP + FN}} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN} $$\nThis latter form is computationally convenient. The total number of samples is $N = TP + FP + TN + FN$. Accuracy can be written as $\\text{Acc} = \\frac{TP + TN}{N}$.\n\nWe will now evaluate each option by calculating the required metrics and assessing the validity of the provided explanation.\n\n**Analysis of Option A**\n\nSystem $X$: $(TP, FP, TN, FN) = (20, 5, 895, 80)$\n- Total samples: $N_X = 20 + 5 + 895 + 80 = 1000$.\n- Accuracy: $\\text{Acc}_X = \\frac{20 + 895}{1000} = \\frac{915}{1000} = 0.915$.\n- Precision: $P_X = \\frac{20}{20 + 5} = \\frac{20}{25} = 0.8$.\n- Recall: $R_X = \\frac{20}{20 + 80} = \\frac{20}{100} = 0.2$.\n- $F_1$-score: $F_{1,X} = \\frac{2 \\cdot TP_X}{2 \\cdot TP_X + FP_X + FN_X} = \\frac{2 \\cdot 20}{2 \\cdot 20 + 5 + 80} = \\frac{40}{40 + 85} = \\frac{40}{125} = 0.32$.\n\nSystem $Y$: $(TP, FP, TN, FN) = (80, 65, 835, 20)$\n- Total samples: $N_Y = 80 + 65 + 835 + 20 = 1000$.\n- Accuracy: $\\text{Acc}_Y = \\frac{80 + 835}{1000} = \\frac{915}{1000} = 0.915$.\n- Precision: $P_Y = \\frac{80}{80 + 65} = \\frac{80}{145} = \\frac{16}{29} \\approx 0.5517$.\n- Recall: $R_Y = \\frac{80}{80 + 20} = \\frac{80}{100} = 0.8$.\n- $F_1$-score: $F_{1,Y} = \\frac{2 \\cdot TP_Y}{2 \\cdot TP_Y + FP_Y + FN_Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 65 + 20} = \\frac{160}{160 + 85} = \\frac{160}{245} = \\frac{32}{49} \\approx 0.6531$.\n\n**Evaluation of Option A:**\n1.  **Equal Accuracy:** $\\text{Acc}_X = 0.915$ and $\\text{Acc}_Y = 0.915$. This condition is satisfied.\n2.  **F1 Difference:** $|F_{1,X} - F_{1,Y}| = |0.32 - 0.6531| = 0.3331$. Since $0.3331 \\geq 0.30$, this condition is satisfied.\n3.  **Explanation:** The explanation states that $\\text{Acc}$ matches because $TP + TN$ is the same ($915$) for both, while the total $N$ is also the same ($1000$). This is correct. It further explains that $F_1$ differs because of a trade-off between $FP$ and $FN$. System $X$ has low $FP$ ($5$) and high $FN$ ($80$), resulting in high $P$ ($0.8$) and low $R$ ($0.2$). System $Y$ has high $FP$ ($65$) and low $FN$ ($20$), resulting in lower $P$ ($\\approx 0.55$) and high $R$ ($0.8$). This trade-off between $P$ and $R$ causes the difference in the $F_1$-score, which as a harmonic mean is sensitive to such imbalances. The explanation is structurally and factually correct.\n\nVerdict for Option A: **Correct**.\n\n**Analysis of Option B**\n\nSystem $X$: $(TP, FP, TN, FN) = (50, 50, 850, 50)$\nSystem $Y$: $(TP, FP, TN, FN) = (45, 45, 855, 55)$\n- $\\text{Acc}_X = \\frac{50 + 850}{1000} = 0.9$.\n- $\\text{Acc}_Y = \\frac{45 + 855}{1000} = 0.9$.\nThe accuracies are equal.\n- $F_{1,X} = \\frac{2 \\cdot 50}{2 \\cdot 50 + 50 + 50} = \\frac{100}{200} = 0.5$.\n- $F_{1,Y} = \\frac{2 \\cdot 45}{2 \\cdot 45 + 45 + 55} = \\frac{90}{90 + 100} = \\frac{90}{190} = \\frac{9}{19} \\approx 0.4737$.\n- $|F_{1,X} - F_{1,Y}| = |0.5 - 0.4737| \\approx 0.0263$. This is not $\\geq 0.30$.\n- **Explanation:** The explanation claims \"Because both have the same $ \\text{Acc} $, their $F_1$ scores are necessarily equal; $F_1$ is determined solely by $ \\text{Acc} $.\" This statement is fundamentally false. Accuracy and $F_1$-score are different metrics that are not deterministically linked. Our analysis of Option A has already provided a counterexample.\n\nVerdict for Option B: **Incorrect**.\n\n**Analysis of Option C**\n\nSystem $X$: $(TP, FP, TN, FN) = (10, 10, 980, 0)$\nSystem $Y$: $(TP, FP, TN, FN) = (10, 0, 970, 20)$\n- $\\text{Acc}_X = \\frac{10 + 980}{1000} = 0.99$.\n- $\\text{Acc}_Y = \\frac{10 + 970}{1000} = 0.98$.\n- The accuracies are not equal ($\\text{Acc}_X \\neq \\text{Acc}_Y$). The first condition of the problem is not met.\n- **Explanation:** The explanation contains two false statements. First, it incorrectly claims the accuracies are equal. Second, it claims \"$TN$ drives $F_1$ directly.\" The formula for $F_1$ is $F_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$, which does not include the $TN$ term. Therefore, $TN$ has no direct effect on the $F_1$-score.\n\nVerdict for Option C: **Incorrect**.\n\n**Analysis of Option D**\n\nSystem $X$: $(TP, FP, TN, FN) = (90, 10, 890, 10)$\nSystem $Y$: $(TP, FP, TN, FN) = (80, 0, 900, 20)$\n- $\\text{Acc}_X = \\frac{90 + 890}{1000} = 0.98$.\n- $\\text{Acc}_Y = \\frac{80 + 900}{1000} = 0.98$.\nThe accuracies are equal.\n- $F_{1,X} = \\frac{2 \\cdot 90}{2 \\cdot 90 + 10 + 10} = \\frac{180}{200} = 0.9$.\n- $F_{1,Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 0 + 20} = \\frac{160}{180} = \\frac{8}{9} \\approx 0.8889$.\n- $|F_{1,X} - F_{1,Y}| = |0.9 - 0.8889| \\approx 0.0111$. This is not $\\geq 0.30$.\n- **Explanation:** The explanation claims the $F_1$ difference is \"caused primarily by changing $TN$, since $TN$ appears in the denominators of $P$ and $R$\". This is factually incorrect. The formulas for $P$ and $R$ are $P = \\frac{TP}{TP + FP}$ and $R = \\frac{TP}{TP + FN}$. The $TN$ term does not appear in either formula, nor in the formula for $F_1$.\n\nVerdict for Option D: **Incorrect**.\n\nBased on the detailed analysis, only Option A satisfies all the stated numerical and explanatory requirements.", "answer": "$$\\boxed{A}$$", "id": "3094202"}, {"introduction": "Evaluating classifiers on imbalanced datasets, where one class vastly outnumbers another, presents a significant challenge. This exercise reveals the pitfalls of relying on overall accuracy in such scenarios and introduces balanced accuracy as a more robust alternative [@problem_id:3181064]. You will analyze a situation where a model with lower overall accuracy is arguably the better one, learning to align your choice of evaluation metric with the specific goals and error costs of your classification task.", "problem": "Consider a binary classification task with a highly imbalanced dataset of size $N = 1000$, containing $100$ positive instances and $900$ negative instances. Two classifiers, denoted $\\mathcal{A}$ and $\\mathcal{B}$, are evaluated on this dataset and produce the following confusion matrices (entries are counts of instances): for $\\mathcal{A}$, $\\mathrm{TP} = 20$, $\\mathrm{FN} = 80$, $\\mathrm{TN} = 891$, and $\\mathrm{FP} = 9$; for $\\mathcal{B}$, $\\mathrm{TP} = 80$, $\\mathrm{FN} = 20$, $\\mathrm{TN} = 810$, and $\\mathrm{FP} = 90$. Using only the core definitions of confusion matrix quantities and the standard rates derived from them, reason from first principles to determine which metric each classifier optimizes, and whether choosing a classifier that optimizes a per-class-averaged measure can reduce prevalence-weighted overall accuracy. Then, based on that reasoning, select all correct statements from the options below. Do not assume any unstated formulas; base your answer on the definitions of counts and rates implied by the confusion matrix.\n\nA. Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$; this pattern can occur in imbalanced data because per-class averaging treats minority and majority classes equally.\n\nB. Classifier $\\mathcal{B}$ has higher overall accuracy and higher balanced accuracy than classifier $\\mathcal{A}$; the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur.\n\nC. Optimizing for balanced accuracy is desirable when class priors are highly imbalanced and errors in the minority and majority classes are considered comparably important, or when recall for the minority class is a primary objective, because per-class averaging counteracts prevalence dominance.\n\nD. Optimizing for balanced accuracy is undesirable when the objective is to minimize the total number of mistakes under equal per-instance misclassification costs, since overall accuracy already weights classes by prevalence.\n\nE. If two classifiers have the same balanced accuracy, then they must also have the same overall accuracy, regardless of class imbalance.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- Total dataset size: $N = 1000$\n- Number of positive instances: $P = 100$\n- Number of negative instances: $N_{neg} = 900$ (to avoid confusion with total size $N$, let's denote this by $N_{neg}$)\n- Classifier $\\mathcal{A}$ confusion matrix counts: $\\mathrm{TP}_{\\mathcal{A}} = 20$, $\\mathrm{FN}_{\\mathcal{A}} = 80$, $\\mathrm{TN}_{\\mathcal{A}} = 891$, $\\mathrm{FP}_{\\mathcal{A}} = 9$\n- Classifier $\\mathcal{B}$ confusion matrix counts: $\\mathrm{TP}_{\\mathcal{B}} = 80$, $\\mathrm{FN}_{\\mathcal{B}} = 20$, $\\mathrm{TN}_{\\mathcal{B}} = 810$, $\\mathrm{FP}_{\\mathcal{B}} = 90$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is situated within the standard framework of binary classification evaluation in statistical learning. We must verify the internal consistency of the provided data.\n\n1.  **Consistency of Positive Class Counts:** The total number of positive instances, $P$, must equal the sum of true positives and false negatives ($\\mathrm{TP} + \\mathrm{FN}$).\n    - For classifier $\\mathcal{A}$: $\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{FN}_{\\mathcal{A}} = 20 + 80 = 100$. This matches the given $P = 100$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{FN}_{\\mathcal{B}} = 80 + 20 = 100$. This also matches the given $P = 100$.\n\n2.  **Consistency of Negative Class Counts:** The total number of negative instances, $N_{neg}$, must equal the sum of true negatives and false positives ($\\mathrm{TN} + \\mathrm{FP}$).\n    - For classifier $\\mathcal{A}$: $\\mathrm{TN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 891 + 9 = 900$. This matches the given $N_{neg} = 900$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 810 + 90 = 900$. This also matches the given $N_{neg} = 900$.\n\n3.  **Consistency of Total Dataset Size:** The total dataset size, $N$, must equal the sum of all confusion matrix entries.\n    - For classifier $\\mathcal{A}$: $\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{FN}_{\\mathcal{A}} + \\mathrm{TN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 20 + 80 + 891 + 9 = 1000$. This matches the given $N=1000$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{FN}_{\\mathcal{B}} + \\mathrm{TN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 80 + 20 + 810 + 90 = 1000$. This also matches the given $N=1000$.\n\nThe problem is scientifically grounded in established statistical theory, is well-posed with all necessary information provided, and is internally consistent. The scenario of an imbalanced dataset is realistic and common in practice. The language is objective and precise.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. We proceed to the solution.\n\n### Derivation and Option Analysis\n\nWe will derive the relevant metrics from first principles for both classifiers. The core metrics are the True Positive Rate (TPR), True Negative Rate (TNR), Overall Accuracy (ACC), and Balanced Accuracy (BA). Let $P$ be the number of positive instances and $N_{neg}$ be the number of negative instances.\n\n- **True Positive Rate (TPR)** or **Recall**: $\\mathrm{TPR} = \\frac{\\mathrm{TP}}{P} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$\n- **True Negative Rate (TNR)** or **Specificity**: $\\mathrm{TNR} = \\frac{\\mathrm{TN}}{N_{neg}} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}}$\n- **Overall Accuracy (ACC)**: $\\mathrm{ACC} = \\frac{\\mathrm{TP} + \\mathrm{TN}}{P + N_{neg}}$\n- **Balanced Accuracy (BA)**: $\\mathrm{BA} = \\frac{\\mathrm{TPR} + \\mathrm{TNR}}{2}$\n\nThe given dataset has $P=100$ and $N_{neg}=900$.\n\n**Calculations for Classifier $\\mathcal{A}$:**\n- $\\mathrm{TPR}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}}}{P} = \\frac{20}{100} = 0.2$\n- $\\mathrm{TNR}_{\\mathcal{A}} = \\frac{\\mathrm{TN}_{\\mathcal{A}}}{N_{neg}} = \\frac{891}{900} = 0.99$\n- $\\mathrm{ACC}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{TN}_{\\mathcal{A}}}{P + N_{neg}} = \\frac{20 + 891}{1000} = \\frac{911}{1000} = 0.911$\n- $\\mathrm{BA}_{\\mathcal{A}} = \\frac{\\mathrm{TPR}_{\\mathcal{A}} + \\mathrm{TNR}_{\\mathcal{A}}}{2} = \\frac{0.2 + 0.99}{2} = \\frac{1.19}{2} = 0.595$\n\n**Calculations for Classifier $\\mathcal{B}$:**\n- $\\mathrm{TPR}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}}}{P} = \\frac{80}{100} = 0.8$\n- $\\mathrm{TNR}_{\\mathcal{B}} = \\frac{\\mathrm{TN}_{\\mathcal{B}}}{N_{neg}} = \\frac{810}{900} = 0.90$\n- $\\mathrm{ACC}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{TN}_{\\mathcal{B}}}{P + N_{neg}} = \\frac{80 + 810}{1000} = \\frac{890}{1000} = 0.890$\n- $\\mathrm{BA}_{\\mathcal{B}} = \\frac{\\mathrm{TPR}_{\\mathcal{B}} + \\mathrm{TNR}_{\\mathcal{B}}}{2} = \\frac{0.8 + 0.9}{2} = \\frac{1.7}{2} = 0.85$\n\n**Comparison:**\n- Overall Accuracy: $\\mathrm{ACC}_{\\mathcal{A}} (0.911) > \\mathrm{ACC}_{\\mathcal{B}} (0.890)$\n- Balanced Accuracy: $\\mathrm{BA}_{\\mathcal{A}} (0.595) < \\mathrm{BA}_{\\mathcal{B}} (0.85)$\n\nClassifier $\\mathcal{A}$ favors performance on the majority (negative) class, achieving a very high $\\mathrm{TNR}_{\\mathcal{A}}$ of $0.99$ at the cost of a very low $\\mathrm{TPR}_{\\mathcal{A}}$ of $0.2$. This strategy maximizes overall accuracy due to the high prevalence ($90\\%$) of the negative class. Classifier $\\mathcal{B}$ has more balanced performance across classes, achieving high $\\mathrm{TPR}_{\\mathcal{B}}$ ($0.8$) and $\\mathrm{TNR}_{\\mathcal{B}}$ ($0.9$), resulting in a much higher balanced accuracy but a slightly lower overall accuracy.\n\nNow, we evaluate each option.\n\n**A. Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$; this pattern can occur in imbalanced data because per-class averaging treats minority and majority classes equally.**\n- The first clause, \"Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$,\" is confirmed by our calculations ($0.911 > 0.890$ for ACC, and $0.595 < 0.85$ for BA).\n- The reasoning provided is that \"per-class averaging treats minority and majority classes equally.\" Balanced accuracy is the arithmetic mean of per-class accuracies (TPR and TNR), giving each class a weight of $1/2$. Overall accuracy can be expressed as a weighted average: $\\mathrm{ACC} = \\pi_P \\cdot \\mathrm{TPR} + \\pi_{N_{neg}} \\cdot \\mathrm{TNR}$, where $\\pi_P = P/(P+N_{neg}) = 0.1$ and $\\pi_{N_{neg}} = N_{neg}/(P+N_{neg}) = 0.9$ are the class prevalences. The high prevalence of the negative class, $\\pi_{N_{neg}}=0.9$, means overall accuracy is dominated by TNR. Balanced accuracy's equal weighting counteracts this. The statement is entirely correct.\n- Verdict: **Correct**.\n\n**B. Classifier $\\mathcal{B}$ has higher overall accuracy and higher balanced accuracy than classifier $\\mathcal{A}$; the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur.**\n- The first clause, \"Classifier $\\mathcal{B}$ has higher overall accuracy,\" is false, as $\\mathrm{ACC}_{\\mathcal{B}} = 0.890 < \\mathrm{ACC}_{\\mathcal{A}} = 0.911$.\n- The second clause, \"the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur,\" is also false. This exact problem provides a counterexample: classifier $\\mathcal{B}$ has a significantly higher balanced accuracy but a lower overall accuracy than classifier $\\mathcal{A}$. Choosing $\\mathcal{B}$ over $\\mathcal{A}$ (optimizing for BA) reduces ACC.\n- Verdict: **Incorrect**.\n\n**C. Optimizing for balanced accuracy is desirable when class priors are highly imbalanced and errors in the minority and majority classes are considered comparably important, or when recall for the minority class is a primary objective, because per-class averaging counteracts prevalence dominance.**\n- This is a conceptual statement about the utility of balanced accuracy. When class priors are imbalanced, a model can achieve high overall accuracy by simply predicting the majority class. If errors in both classes are \"comparably important,\" a metric that weights class performance by prevalence (like overall accuracy) is inappropriate. Balanced accuracy gives equal weight to each class's performance, fulfilling this need. Furthermore, to achieve a high balanced accuracy, a classifier cannot afford to have a very low TPR (minority class recall), making it a suitable objective when minority recall is important. The reason for this behavior is correctly identified as \"per-class averaging counteracts prevalence dominance.\" The statement is a clear and accurate description of the motivation for using balanced accuracy.\n- Verdict: **Correct**.\n\n**D. Optimizing for balanced accuracy is undesirable when the objective is to minimize the total number of mistakes under equal per-instance misclassification costs, since overall accuracy already weights classes by prevalence.**\n- The objective \"to minimize the total number of mistakes\" is mathematically equivalent to minimizing the sum $\\mathrm{FN} + \\mathrm{FP}$. Overall accuracy is defined as $\\mathrm{ACC} = 1 - \\frac{\\mathrm{FN} + \\mathrm{FP}}{N_{total}}$. Therefore, maximizing overall accuracy is equivalent to minimizing the total number of mistakes.\n- Our example shows that classifier $\\mathcal{A}$ has higher ACC ($0.911$) and fewer total mistakes ($\\mathrm{FN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 80+9=89$). Classifier $\\mathcal{B}$ has higher BA ($0.85$) but more total mistakes ($\\mathrm{FN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 20+90=110$). If the goal is to minimize total mistakes, one should prefer $\\mathcal{A}$, which is the classifier with higher ACC, not higher BA. Thus, optimizing for BA would be the wrong strategy. The reasoning provided is also correct: overall accuracy achieves this objective because it weights instances equally, which means classes are weighted by prevalence.\n- Verdict: **Correct**.\n\n**E. If two classifiers have the same balanced accuracy, then they must also have the same overall accuracy, regardless of class imbalance.**\n- This statement can be proven false with a counterexample. Let $\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$. This implies $\\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{C}} + \\mathrm{TNR}_{\\mathcal{C}}) = \\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{D}} + \\mathrm{TNR}_{\\mathcal{D}})$.\n- Overall accuracy is $\\mathrm{ACC} = \\pi_P \\mathrm{TPR} + \\pi_{N_{neg}} \\mathrm{TNR}$.\n- Assume our imbalanced dataset with $\\pi_P = 0.1$ and $\\pi_{N_{neg}} = 0.9$.\n- Let classifier $\\mathcal{C}$ have $\\mathrm{TPR}_{\\mathcal{C}} = 0.9$ and $\\mathrm{TNR}_{\\mathcal{C}} = 0.7$. Then $\\mathrm{BA}_{\\mathcal{C}} = (0.9+0.7)/2 = 0.8$. Its accuracy is $\\mathrm{ACC}_{\\mathcal{C}} = (0.1)(0.9) + (0.9)(0.7) = 0.09 + 0.63 = 0.72$.\n- Let classifier $\\mathcal{D}$ have $\\mathrm{TPR}_{\\mathcal{D}} = 0.7$ and $\\mathrm{TNR}_{\\mathcal{D}} = 0.9$. Then $\\mathrm{BA}_{\\mathcal{D}} = (0.7+0.9)/2 = 0.8$. Its accuracy is $\\mathrm{ACC}_{\\mathcal{D}} = (0.1)(0.7) + (0.9)(0.9) = 0.07 + 0.81 = 0.88$.\n- Here, $\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$, but $\\mathrm{ACC}_{\\mathcal{C}} \\neq \\mathrm{ACC}_{\\mathcal{D}}$. The statement is false. It would only be true in the special case of a balanced dataset where $\\pi_P = \\pi_{N_{neg}} = 0.5$, in which case $\\mathrm{ACC} = 0.5(\\mathrm{TPR}+\\mathrm{TNR}) = \\mathrm{BA}$. The phrase \"regardless of class imbalance\" makes the statement definitively false.\n- Verdict: **Incorrect**.", "answer": "$$\\boxed{ACD}$$", "id": "3181064"}]}