{"hands_on_practices": [{"introduction": "This first exercise provides a concrete, numerical scenario to build your intuition about the fundamental difference between squared and absolute error losses. By comparing two models based on their specific residual errors, you will directly observe how the Mean Squared Error ($MSE$) heavily penalizes a single large outlier, while the Mean Absolute Error ($MAE$) remains more stable [@problem_id:3168840]. This practice illuminates the core trade-off between sensitivity and robustness that governs the choice between these two critical metrics.", "problem": "Consider a deep learning regression task where two models, labeled $X$ and $Y$, are evaluated on $n=10$ hold-out samples. The residuals (predicted minus true) are observed as follows. For model $X$, the residuals are $-0.5$ for $9$ samples and $10$ for $1$ sample. For model $Y$, the residuals are $-1.8$ for $5$ samples and $+1.8$ for $5$ samples. Without using any pre-given formulas, determine which model is ranked better by Mean Absolute Error (MAE) and which is ranked better by Mean Squared Error (MSE), and select the option that correctly explains why the rankings reverse by referencing appropriate residual distribution moments. Recall that Mean Absolute Error (MAE) and Mean Squared Error (MSE) are standard regression performance metrics.\n\nWhich option is correct?\n\nA. $MAE$ prefers model $X$ while $MSE$ prefers model $Y$. This reversal is explained because $MSE$ is driven by the second moment (variance) and becomes large under heavy-tailed residuals with high kurtosis due to the single extreme outlier in $X$, whereas $MAE$ depends on the first absolute moment and is comparatively robust to isolated outliers. The positive skewness in $X$ indicates asymmetry but does not by itself overturn $MAE$’s robustness.\n\nB. Both $MAE$ and $MSE$ prefer model $Y$ because its mean residual is $0$, and $MSE$ mainly depends on the mean; the outlier in $X$ does not change the ranking once the mean is accounted for.\n\nC. $MAE$ prefers model $Y$ while $MSE$ prefers model $X$ because $MAE$ amplifies large outliers more strongly than $MSE$, so the extreme residual in $X$ hurts $MAE$ but not $MSE$.\n\nD. The rankings cannot reverse when there is a single positive outlier; such reversal requires negative skewness. Therefore, with the given residuals, both $MAE$ and $MSE$ prefer the same model.\n\nE. $MAE$ prefers model $X$ and $MSE$ prefers model $Y$, but the reversal is primarily because $MSE$ responds to skewness rather than variance; skewness alone directly increases $MSE$ even if variance is similar.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- A deep learning regression task involves two models, $X$ and $Y$.\n- The number of hold-out samples is $n=10$.\n- The residuals for model $X$, denoted as the set $R_X$, consist of $9$ values of $-0.5$ and $1$ value of $10$.\n- The residuals for model $Y$, denoted as the set $R_Y$, consist of $5$ values of $-1.8$ and $5$ values of $1.8$.\n- The task is to determine which model is ranked better by Mean Absolute Error (MAE) and Mean Squared Error (MSE) and to explain the potential reversal of rankings by referencing residual distribution moments.\n- The constraint is to solve \"without using any pre-given formulas,\" which is interpreted as deriving the results from the fundamental definitions of the metrics.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is based on fundamental and standard concepts in statistics and machine learning evaluation: Mean Absolute Error (MAE), Mean Squared Error (MSE), and the analysis of residual distributions using statistical moments (mean, variance, skewness, kurtosis). These are well-established and core to the field.\n- **Well-Posed:** The problem provides all necessary numerical data to calculate the required metrics. The sets of residuals are fully specified, and the number of samples is consistent. The question is unambiguous, leading to a unique, calculable solution.\n- **Objective:** The problem is stated using precise, objective language and numerical data. It is free of subjective or opinion-based claims.\n\nThe problem does not violate any of the invalidity criteria. It is a well-posed, scientifically sound, and objective question that tests the understanding of regression metrics.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation of Solution\nThe metrics are defined from first principles as follows. For a set of $n$ residuals $\\{r_i\\}_{i=1}^n$:\n- **Mean Absolute Error (MAE)** is the average of the absolute values of the residuals: $MAE = \\frac{1}{n} \\sum_{i=1}^n |r_i|$.\n- **Mean Squared Error (MSE)** is the average of the squared values of the residuals: $MSE = \\frac{1}{n} \\sum_{i=1}^n r_i^2$.\nA lower value for either metric indicates a better-performing model.\n\n**Calculation for Model X:**\nThe residuals are $R_X = \\{ \\underbrace{-0.5, \\dots, -0.5}_{9 \\text{ times}}, 10 \\}$. The number of samples is $n=10$.\n\n- **MAE for Model X ($MAE_X$):**\n$$MAE_X = \\frac{1}{10} \\left( 9 \\times |-0.5| + 1 \\times |10| \\right)$$\n$$MAE_X = \\frac{1}{10} \\left( 9 \\times 0.5 + 10 \\right)$$\n$$MAE_X = \\frac{1}{10} \\left( 4.5 + 10 \\right) = \\frac{14.5}{10} = 1.45$$\n\n- **MSE for Model X ($MSE_X$):**\n$$MSE_X = \\frac{1}{10} \\left( 9 \\times (-0.5)^2 + 1 \\times (10)^2 \\right)$$\n$$MSE_X = \\frac{1}{10} \\left( 9 \\times 0.25 + 100 \\right)$$\n$$MSE_X = \\frac{1}{10} \\left( 2.25 + 100 \\right) = \\frac{102.25}{10} = 10.225$$\n\n**Calculation for Model Y:**\nThe residuals are $R_Y = \\{ \\underbrace{-1.8, \\dots, -1.8}_{5 \\text{ times}}, \\underbrace{1.8, \\dots, 1.8}_{5 \\text{ times}} \\}$. The number of samples is $n=10$.\n\n- **MAE for Model Y ($MAE_Y$):**\n$$MAE_Y = \\frac{1}{10} \\left( 5 \\times |-1.8| + 5 \\times |1.8| \\right)$$\n$$MAE_Y = \\frac{1}{10} \\left( 5 \\times 1.8 + 5 \\times 1.8 \\right)$$\n$$MAE_Y = \\frac{1}{10} \\left( 10 \\times 1.8 \\right) = 1.8$$\n\n- **MSE for Model Y ($MSE_Y$):**\n$$MSE_Y = \\frac{1}{10} \\left( 5 \\times (-1.8)^2 + 5 \\times (1.8)^2 \\right)$$\n$$MSE_Y = \\frac{1}{10} \\left( 10 \\times (1.8)^2 \\right)$$\n$$MSE_Y = (1.8)^2 = 3.24$$\n\n**Comparison of Rankings:**\n- **MAE:** $MAE_X = 1.45$ and $MAE_Y = 1.8$. Since $1.45 < 1.8$, model $X$ is ranked better by MAE.\n- **MSE:** $MSE_X = 10.225$ and $MSE_Y = 3.24$. Since $10.225 > 3.24$, model $Y$ is ranked better by MSE.\n\nThe rankings are indeed reversed.\n\n**Analysis using Residual Distribution Moments:**\n- **MAE** is the first absolute moment about the origin ($E[|R|]$). It treats all errors linearly (in absolute value). For model $X$, the $9$ small errors result in a small contribution to the sum, and the single large outlier contributes linearly ($10$). The overall average remains relatively low.\n- **MSE** is the second moment about the origin ($E[R^2]$). It is related to the variance (the second central moment, $\\sigma^2 = E[(R-\\mu)^2]$) and the mean (the first moment, $\\mu = E[R]$) by the identity $MSE = \\sigma^2 + \\mu^2$. Due to the squaring operation, MSE penalizes large errors disproportionately. For model $X$, the single residual of $10$ contributes $10^2 = 100$ to the sum of squares, dominating the total and resulting in a very high MSE. This sensitivity to extreme outliers is characteristic of MSE.\n- The presence of an extreme outlier, as in the residuals of model $X$, creates a \"heavy-tailed\" distribution. This is quantified by **kurtosis** (the scaled fourth central moment), which for model $X$ would be very high (a leptokurtic distribution). High kurtosis indicates that outliers are more extreme than in a normal distribution, and MSE is highly sensitive to this.\n- The distribution for model $X$ is also asymmetric, as shown by its **skewness** (the scaled third central moment). The single large positive residual creates a strong positive skew. While skewness describes asymmetry, it is the kurtosis and the underlying variance that are most directly connected to the magnitude of the MSE.\n- Model $Y$'s residuals are symmetric around $0$, so its mean and skewness are both $0$. It has no extreme outliers, resulting in a moderate variance and thus a moderate MSE.\n\n### Option-by-Option Analysis\n\n**A. $MAE$ prefers model $X$ while $MSE$ prefers model $Y$. This reversal is explained because $MSE$ is driven by the second moment (variance) and becomes large under heavy-tailed residuals with high kurtosis due to the single extreme outlier in $X$, whereas $MAE$ depends on the first absolute moment and is comparatively robust to isolated outliers. The positive skewness in $X$ indicates asymmetry but does not by itself overturn $MAE$’s robustness.**\n- The rankings are correct: our calculations show $MAE$ prefers $X$ and $MSE$ prefers $Y$.\n- The explanation is sound. $MSE$ is indeed driven by the second moment ($E[R^2]$) and is thus closely related to variance. It is extremely sensitive to heavy tails and high kurtosis, which are caused by the outlier in $X$'s residuals.\n- Conversely, $MAE$ ($E[|R|]$) is the first absolute moment and is known to be more robust to such outliers.\n- The statement about skewness is also correct; it indicates asymmetry, but the primary cause of the MSE's large value is the magnitude of the squared error, which is better described in terms of variance and kurtosis.\n- **Verdict:** Correct.\n\n**B. Both $MAE$ and $MSE$ prefer model $Y$ because its mean residual is $0$, and $MSE$ mainly depends on the mean; the outlier in $X$ does not change the ranking once the mean is accounted for.**\n- The first clause, \"Both $MAE$ and $MSE$ prefer model $Y$,\" is false. Our calculations show $MAE$ prefers model $X$.\n- The reasoning, \"$MSE$ mainly depends on the mean,\" is false. $MSE = \\sigma^2 + \\mu^2$. For model $X$, the mean is $\\mu_X = \\frac{1}{10}(9 \\times -0.5 + 10) = 0.55$, so $\\mu_X^2 = 0.3025$. The variance is $\\sigma_X^2 = MSE_X - \\mu_X^2 = 10.225 - 0.3025 = 9.9225$. The MSE is clearly dominated by the variance, not the mean.\n- **Verdict:** Incorrect.\n\n**C. $MAE$ prefers model $Y$ while $MSE$ prefers model $X$ because $MAE$ amplifies large outliers more strongly than $MSE$, so the extreme residual in $X$ hurts $MAE$ but not $MSE$.**\n- The ranking, \"$MAE$ prefers model $Y$ while $MSE$ prefers model $X$,\" is the exact opposite of what was calculated.\n- The reasoning, \"$MAE$ amplifies large outliers more strongly than $MSE$,\" is fundamentally false. The squaring operation in MSE ($r^2$) causes much stronger amplification of large errors than the absolute value operation in MAE ($|r|$).\n- **Verdict:** Incorrect.\n\n**D. The rankings cannot reverse when there is a single positive outlier; such reversal requires negative skewness. Therefore, with the given residuals, both $MAE$ and $MSE$ prefer the same model.**\n- The premise, \"The rankings cannot reverse when there is a single positive outlier,\" is demonstrably false, as the calculations have shown a reversal.\n- The claim that reversal \"requires negative skewness\" is a baseless and incorrect assertion. The reversal depends on the interplay between the magnitude of the outlier and the distribution of the other residuals, not on the sign of the skew.\n- **Verdict:** Incorrect.\n\n**E. $MAE$ prefers model $X$ and $MSE$ prefers model $Y$, but the reversal is primarily because $MSE$ responds to skewness rather than variance; skewness alone directly increases $MSE$ even if variance is similar.**\n- The initial ranking is correct.\n- The reasoning, \"$MSE$ responds to skewness rather than variance,\" is false. $MSE$ is the second moment about the origin. Variance is the second central moment. Skewness is related to the third central moment. They are distinct concepts. MSE is directly a function of variance and mean, not skewness. High skewness often co-occurs with high variance in outlier-driven distributions, but MSE's value is determined by the variance and mean, not the skewness directly.\n- **Verdict:** Incorrect.", "answer": "$$\\boxed{A}$$", "id": "3168840"}, {"introduction": "Moving from a single data sample to the realm of statistical theory, this practice challenges you to analyze the behavior of loss functions at the population level [@problem_id:3175076]. You will derive the \"oracle\" predictors—the best possible predictors if we knew the true data-generating distribution—for both squared ($L_2$) and absolute ($L_1$) losses. By calculating the theoretical minimum risk for a noise model contaminated with heavy-tailed outliers, you will formalize the concept of robustness and prove why absolute error is the superior choice in such settings.", "problem": "Consider a regression setting with an unknown deterministic target function $f$ and a regressor $X$. The observed response is modeled as $Y = f(X) + Z$, where the noise $Z$ is independent of $X$ and has a symmetric two-component Gaussian mixture distribution\n$$\nZ \\sim 0.9\\,\\mathcal{N}(0,1) + 0.1\\,\\mathcal{N}(0,25).\n$$\nDefine the squared loss $\\ell_{2}(y,t) = (y-t)^{2}$ and the absolute loss $\\ell_{1}(y,t) = |y-t|$. For a measurable predictor $g$, the expected risk under a loss $\\ell$ is $R_{\\ell}(g) = \\mathbb{E}[\\ell(Y,g(X))]$. The oracle risk $R_{\\ell}^{\\star}$ is the infimum of $R_{\\ell}(g)$ over all measurable functions $g$.\n\nStarting from these definitions, derive from first principles the oracle predictors that minimize the respective risks under $\\ell_{2}$ and $\\ell_{1}$. Then compute the exact oracle risks $R_{2}^{\\star}$ and $R_{1}^{\\star}$ for the given model. Finally, justify, using your derived expressions, why the absolute loss $\\ell_{1}$ is preferable to the squared loss $\\ell_{2}$ under heavy-tailed contamination in the noise distribution.\n\nReport your final answers as a two-entry row matrix $\\begin{pmatrix} R_{2}^{\\star} & R_{1}^{\\star} \\end{pmatrix}$. No rounding is required; provide exact expressions.", "solution": "The solution is derived from first principles as requested.\n\n**Step 1: Derivation of the Oracle Predictors**\nThe expected risk for a predictor $g$ is $R_{\\ell}(g) = \\mathbb{E}[\\ell(Y, g(X))]$. By the law of total expectation, this is $R_{\\ell}(g) = \\mathbb{E}_{X}[\\mathbb{E}_{Y|X}[\\ell(Y, g(X)) | X=x]]$. To minimize this over all functions $g$, we can minimize the inner expectation pointwise for each $x$. Thus, the oracle predictor $g^*(x)$ must minimize $\\mathbb{E}_{Y|X}[\\ell(Y, c) | X=x]$ with respect to the constant $c = g(x)$.\n\nGiven the model $Y = f(X) + Z$ where $Z$ is independent of $X$, the distribution of $Y$ conditioned on $X=x$ is the distribution of $f(x) + Z$. The task reduces to finding a constant $c$ that minimizes $\\mathbb{E}_{Z}[\\ell(f(x) + Z, c)]$.\n\n*   **For squared loss $\\ell_2$**: We minimize $\\mathbb{E}_{Z}[(f(x) + Z - c)^2]$. This is a quadratic in $c$, and its minimum is achieved at the mean of the distribution of $f(x)+Z$.\n    $$c = \\mathbb{E}[f(x) + Z] = f(x) + \\mathbb{E}[Z].$$\n    Thus, the oracle predictor is $g_2^*(x) = \\mathbb{E}[Y|X=x] = f(x) + \\mathbb{E}[Z]$.\n\n*   **For absolute loss $\\ell_1$**: We minimize $\\mathbb{E}_{Z}[|f(x) + Z - c|]$. The value of $c$ that minimizes the expected absolute deviation from the points in a distribution is the median of that distribution.\n    $$c = \\operatorname{median}(f(x) + Z) = f(x) + \\operatorname{median}(Z).$$\n    Thus, the oracle predictor is $g_1^*(x) = \\operatorname{median}(Y|X=x) = f(x) + \\operatorname{median}(Z)$.\n\n**Step 2: Calculation of Noise Properties and Oracle Predictors**\nThe noise $Z$ is drawn from a symmetric mixture of two zero-mean Gaussians: $Z \\sim 0.9\\,\\mathcal{N}(0,1) + 0.1\\,\\mathcal{N}(0,25)$.\n*   The mean of $Z$ is $\\mathbb{E}[Z] = 0.9 \\cdot \\mathbb{E}[\\mathcal{N}(0,1)] + 0.1 \\cdot \\mathbb{E}[\\mathcal{N}(0,25)] = 0.9 \\cdot 0 + 0.1 \\cdot 0 = 0$.\n*   The probability density function of $Z$ is symmetric about 0. Therefore, its median is $\\operatorname{median}(Z) = 0$.\n\nSince both the mean and median of the noise are zero, both oracle predictors are identical:\n$$g_2^*(x) = f(x) + 0 = f(x)$$\n$$g_1^*(x) = f(x) + 0 = f(x)$$\n\n**Step 3: Calculation of Oracle Risks**\nThe oracle risk is the risk achieved by the oracle predictor.\n*   **For squared loss $\\ell_2$**:\n    $$R_2^{\\star} = \\mathbb{E}[\\ell_2(Y, g_2^*(X))] = \\mathbb{E}[( (f(X)+Z) - f(X) )^2] = \\mathbb{E}[Z^2]$$\n    The second moment $\\mathbb{E}[Z^2]$ (which equals the variance since $\\mathbb{E}[Z]=0$) is computed using the law of total expectation over the mixture components:\n    $$ \\mathbb{E}[Z^2] = 0.9 \\cdot \\mathbb{E}[\\mathcal{N}(0,1)^2] + 0.1 \\cdot \\mathbb{E}[\\mathcal{N}(0,25)^2] $$\n    $$ \\mathbb{E}[Z^2] = 0.9 \\cdot (1) + 0.1 \\cdot (25) = 0.9 + 2.5 = 3.4 = \\frac{17}{5} $$\n    So, $R_2^{\\star} = \\frac{17}{5}$.\n\n*   **For absolute loss $\\ell_1$**:\n    $$R_1^{\\star} = \\mathbb{E}[\\ell_1(Y, g_1^*(X))] = \\mathbb{E}[| (f(X)+Z) - f(X) |] = \\mathbb{E}[|Z|]$$\n    The mean absolute deviation $\\mathbb{E}[|Z|]$ is also computed over the mixture:\n    $$ \\mathbb{E}[|Z|] = 0.9 \\cdot \\mathbb{E}[|\\mathcal{N}(0,1)|] + 0.1 \\cdot \\mathbb{E}[|\\mathcal{N}(0,25)|] $$\n    For a random variable $W \\sim \\mathcal{N}(0, \\sigma^2)$, we have $\\mathbb{E}[|W|] = \\sigma \\sqrt{2/\\pi}$.\n    $$ \\mathbb{E}[|Z|] = 0.9 \\cdot \\left(1 \\cdot \\sqrt{\\frac{2}{\\pi}}\\right) + 0.1 \\cdot \\left(5 \\cdot \\sqrt{\\frac{2}{\\pi}}\\right) $$\n    $$ \\mathbb{E}[|Z|] = (0.9 + 0.5) \\sqrt{\\frac{2}{\\pi}} = 1.4 \\sqrt{\\frac{2}{\\pi}} = \\frac{7}{5} \\sqrt{\\frac{2}{\\pi}} $$\n    So, $R_1^{\\star} = \\frac{7}{5} \\sqrt{\\frac{2}{\\pi}}$.\n\n**Step 4: Justification of Preference**\nWe compare the oracle risks:\n$R_2^{\\star} = 3.4$\n$R_1^{\\star} = \\frac{7}{5} \\sqrt{\\frac{2}{\\pi}} \\approx 1.4 \\times 0.7979 \\approx 1.117$\n\nThe absolute loss yields a significantly lower oracle risk. The reason lies in how the losses handle the heavy-tailed contamination. The squared error risk is the variance, $\\mathbb{E}[Z^2]$. The $10\\%$ contaminant component with variance $25$ contributes $0.1 \\times 25 = 2.5$ to the total risk, dominating the value. In contrast, the absolute error risk is the mean absolute deviation, $\\mathbb{E}[|Z|]$. The contaminant component has a standard deviation of $5$, and its contribution to the risk is proportional to this, not its square. Its contribution is $0.1 \\times (5\\sqrt{2/\\pi})$, which is much more tempered. This demonstrates the robustness of the absolute loss: its penalty on outliers grows linearly, while the squared loss's quadratic penalty makes it highly sensitive to the large variance of the heavy-tailed component.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{17}{5} & \\frac{7}{5} \\sqrt{\\frac{2}{\\pi}} \\end{pmatrix} } $$", "id": "3175076"}, {"introduction": "This final practice brings theory into the practical world of computational simulation [@problem_id:3175044]. You will implement the empirical risk minimizers for $L_1$ and $L_2$ loss—the sample median and sample mean, respectively—and test them in a scenario featuring rare but catastrophic errors. By evaluating their performance not only with standard risk metrics but also with a custom \"safety-oriented\" utility, this exercise demonstrates how the theoretical properties of loss functions translate into tangible decisions in designing reliable and safe systems.", "problem": "You are asked to implement a simulation to compare empirical risk under squared error loss and absolute error loss in the presence of rare but catastrophic target values. The setting is a constant predictor in a univariate output model, and your task is to derive and implement empirical risk minimization (ERM) from first principles for two losses, then define and evaluate a safety-oriented utility that prefers median accuracy.\n\nStart from the following foundational bases:\n- The empirical risk for a predictor under a loss is the sample average of that loss over observed data.\n- For the squared error loss, the loss for a prediction $c$ on a target $y$ is $(y - c)^2$.\n- For the absolute error loss, the loss for a prediction $c$ on a target $y$ is $|y - c|$.\n- A safety-oriented utility for a constant predictor is defined to increase as the median of absolute errors decreases.\n\nData generation protocol for each test case:\n1. Fix a random seed $s$ and sample size $n$.\n2. Draw a base sample $(y_1, \\dots, y_n)$ from a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ independently.\n3. Independently for each index $i$, with probability $p$ replace $y_i$ by $y_i + M$, where $M \\gt 0$ represents a catastrophic positive shift. This yields rare catastrophic target values.\n\nFor a given sample $(y_1, \\dots, y_n)$:\n- Define the empirical risk under squared error loss for a constant predictor $c$ by\n$$ R_{2}(c) \\equiv \\frac{1}{n} \\sum_{i=1}^{n} (y_i - c)^2. $$\n- Define the empirical risk under absolute error loss for a constant predictor $c$ by\n$$ R_{1}(c) \\equiv \\frac{1}{n} \\sum_{i=1}^{n} |y_i - c|. $$\n- Define a safety-oriented utility for a constant predictor $c$ by\n$$ U(c) \\equiv \\frac{1}{1 + \\operatorname{median}\\left( |y_i - c| \\right)}, $$\nwhere the median is taken over $i = 1, \\dots, n$.\n\nYour tasks:\n1. Derive, from first principles, the empirical risk minimizer under squared error loss over constant predictors, and implement it to obtain a predictor $c_{2}$ that minimizes $R_{2}(c)$.\n2. Derive, from first principles, the empirical risk minimizer under absolute error loss over constant predictors, and implement it to obtain a predictor $c_{1}$ that minimizes $R_{1}(c)$.\n3. For each test case, generate the data using the specified parameters and compute the following six quantities:\n   - $R_{2}(c_{2})$,\n   - $R_{2}(c_{1})$,\n   - $R_{1}(c_{2})$,\n   - $R_{1}(c_{1})$,\n   - $U(c_{2})$,\n   - $U(c_{1})$.\n4. For each test case, also compute three boolean indicators:\n   - $B_{2}$ is $\\mathrm{True}$ if $R_{2}(c_{1}) \\le R_{2}(c_{2})$, otherwise $\\mathrm{False}$.\n   - $B_{1}$ is $\\mathrm{True}$ if $R_{1}(c_{1}) \\le R_{1}(c_{2})$, otherwise $\\mathrm{False}$.\n   - $B_{U}$ is $\\mathrm{True}$ if $U(c_{1}) \\ge U(c_{2})$, otherwise $\\mathrm{False}$.\n\nTest suite:\nUse the following five test cases. Each test case is a tuple $(s, n, p, M, \\mu, \\sigma)$ with the meanings defined above.\n- Test case $1$: $(42, 101, 0.0, 0, 0, 1)$.\n- Test case $2$: $(7, 200, 0.02, 50, 0, 1)$.\n- Test case $3$: $(11, 200, 0.01, 200, 0, 1)$.\n- Test case $4$: $(123, 9, 0.2, 30, 0, 1)$.\n- Test case $5$: $(2024, 500, 0.05, 20, 0, 1)$.\n\nOutput specification:\n- For each test case, produce a list with nine entries in the following order:\n  $[R_{2}(c_{2}), R_{2}(c_{1}), R_{1}(c_{2}), R_{1}(c_{1}), U(c_{2}), U(c_{1}), B_{2}, B_{1}, B_{U}]$.\n- Aggregate the results for all five test cases into a single outer list preserving the test case order.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[...],[...],...]\"). There must be exactly one printed line, with no extra text.\n\nAll quantities are dimensionless. No angles or physical units are involved. The boolean indicators must be standard logical values. The numeric entries must be real numbers. The random number generation must strictly follow the seeds provided for reproducibility. The solution should be implementable in any modern programming language; however, you must provide the final answer as an executable program as specified.", "solution": "We proceed from first principles within empirical risk minimization (ERM). Under ERM, for a given loss function and hypothesis class, we select the hypothesis that minimizes the empirical risk, namely the average loss on the observed sample. Here, the hypothesis class is the set of constant predictors $c \\in \\mathbb{R}$, and the observed targets are $y_1, \\dots, y_n$.\n\n1. Squared error loss ERM for constant predictors.\n\nDefine the empirical risk under squared error loss as\n$$ R_{2}(c) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - c)^2. $$\nTo minimize $R_{2}(c)$ over $c \\in \\mathbb{R}$, consider the derivative with respect to $c$. Since $R_{2}(c)$ is differentiable and strictly convex in $c$, the unique minimizer $c_{2}$ satisfies the first-order condition $\\frac{d}{dc} R_{2}(c) = 0$. Compute\n$$ \\frac{d}{dc} R_{2}(c) = \\frac{1}{n} \\sum_{i=1}^{n} 2(c - y_i) = \\frac{2}{n} \\left( n c - \\sum_{i=1}^{n} y_i \\right). $$\nSetting this derivative to zero yields\n$$ n c - \\sum_{i=1}^{n} y_i = 0 \\quad \\Rightarrow \\quad c = \\frac{1}{n} \\sum_{i=1}^{n} y_i. $$\nTherefore, the ERM constant predictor under squared error loss is the sample mean,\n$$ c_{2} = \\bar{y} \\equiv \\frac{1}{n} \\sum_{i=1}^{n} y_i. $$\n\n2. Absolute error loss ERM for constant predictors.\n\nDefine the empirical risk under absolute error loss as\n$$ R_{1}(c) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - c|. $$\nThe function $R_{1}(c)$ is convex but not differentiable everywhere. We use subgradient calculus. A subgradient of $|y_i - c|$ with respect to $c$ is $-1$ when $c < y_i$, $+1$ when $c > y_i$, and the interval $[-1,1]$ when $c = y_i$. Summing subgradients, a necessary and sufficient condition for optimality is that $0$ belongs to the subdifferential of $R_{1}(c)$, i.e.,\n$$ 0 \\in \\frac{1}{n} \\sum_{i=1}^{n} \\partial |y_i - c|. $$\nThis holds if and only if the number of sample points $y_i$ less than $c$ is at most the number greater than $c$, and vice versa; equivalently, any sample median satisfies this condition. Hence, any median of the sample minimizes $R_{1}(c)$. Using the standard definition, we take\n$$ c_{1} = \\operatorname{median}(y_1, \\dots, y_n). $$\n\n3. Safety-oriented utility based on median accuracy.\n\nFor a constant predictor $c$, define the safety-oriented utility\n$$ U(c) = \\frac{1}{1 + \\operatorname{median}\\left( |y_i - c| \\right)}. $$\nThe function $\\operatorname{median}\\left( |y_i - c| \\right)$ is the median absolute error of $c$ on the sample. Smaller median absolute error corresponds to better typical performance on a majority of cases, which is aligned with safety-critical preferences that de-emphasize rare extremes. The mapping $x \\mapsto \\frac{1}{1 + x}$ is strictly decreasing for $x \\ge 0$, so maximizing $U(c)$ corresponds to minimizing the median absolute error.\n\n4. Data generation with rare catastrophic values.\n\nGiven parameters $(s, n, p, M, \\mu, \\sigma)$:\n- Initialize a pseudo-random number generator with seed $s$.\n- Draw $y_i^{(0)} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ independently for $i = 1, \\dots, n$.\n- For each $i$, draw an independent Bernoulli indicator $Z_i \\sim \\operatorname{Bernoulli}(p)$. Define\n$$ y_i = y_i^{(0)} + M Z_i. $$\nThus, with probability $p$, a catastrophic positive shift of magnitude $M$ occurs.\n\n5. Quantities to compute per test case.\n\nFrom the sample $(y_1, \\dots, y_n)$:\n- Compute $c_{2} = \\bar{y}$ and $c_{1} = \\operatorname{median}(y_1, \\dots, y_n)$.\n- Compute\n  $$ R_{2}(c_{2}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - c_{2})^2, \\quad R_{2}(c_{1}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - c_{1})^2, $$\n  $$ R_{1}(c_{2}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - c_{2}|, \\quad R_{1}(c_{1}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - c_{1}|, $$\n  $$ U(c_{2}) = \\frac{1}{1 + \\operatorname{median}_i |y_i - c_{2}|}, \\quad U(c_{1}) = \\frac{1}{1 + \\operatorname{median}_i |y_i - c_{1}|}. $$\n- Define booleans\n  $$ B_{2} = \\left[ R_{2}(c_{1}) \\le R_{2}(c_{2}) \\right], \\quad B_{1} = \\left[ R_{1}(c_{1}) \\le R_{1}(c_{2}) \\right], \\quad B_{U} = \\left[ U(c_{1}) \\ge U(c_{2}) \\right]. $$\nBecause $c_{2}$ minimizes $R_{2}$ over constants by construction, we generally have $R_{2}(c_{2}) \\le R_{2}(c_{1})$, with equality if $c_{1} = c_{2}$. Similarly, $c_{1}$ minimizes $R_{1}$, so $R_{1}(c_{1}) \\le R_{1}(c_{2})$. The safety utility comparison depends on the sample and is expected to favor $c_{1}$ in the presence of rare catastrophes.\n\n6. Algorithmic design.\n\nImplement the above steps exactly for each test case in the suite:\n- Use the specified seeds to ensure reproducibility.\n- Compute the predictors $c_{2}$ and $c_{1}$ using the sample mean and sample median, respectively.\n- Compute the six scalar metrics and three booleans per test case.\n- Output a single line: a list of five inner lists (one per test case), each inner list containing the nine values in the prescribed order\n$$ [R_{2}(c_{2}), R_{2}(c_{1}), R_{1}(c_{2}), R_{1}(c_{1}), U(c_{2}), U(c_{1}), B_{2}, B_{1}, B_{U}]. $$\nNo other text should be printed.\n\nThe test suite parameters to use are:\n- Test case $1$: $(s, n, p, M, \\mu, \\sigma) = (42, 101, 0.0, 0, 0, 1)$.\n- Test case $2$: $(s, n, p, M, \\mu, \\sigma) = (7, 200, 0.02, 50, 0, 1)$.\n- Test case $3$: $(s, n, p, M, \\mu, \\sigma) = (11, 200, 0.01, 200, 0, 1)$.\n- Test case $4$: $(s, n, p, M, \\mu, \\sigma) = (123, 9, 0.2, 30, 0, 1)$.\n- Test case $5$: $(s, n, p, M, \\mu, \\sigma) = (2024, 500, 0.05, 20, 0, 1)$.\n\nThese cover a baseline with no contamination, rare mild and rare extreme catastrophic shifts, a small-sample condition, and a moderate contamination rate. The outputs are purely numerical and boolean, enabling automated verification.", "answer": "```python\nimport numpy as np\nimport json\n\ndef generate_sample(seed, n, p, M, mu, sigma):\n    rng = np.random.default_rng(seed)\n    base = rng.normal(loc=mu, scale=sigma, size=n)\n    contam = rng.random(n) < p\n    y = base + M * contam.astype(float)\n    return y\n\ndef empirical_risks_and_utility(y):\n    n = y.size\n    c2 = float(np.mean(y))\n    c1 = float(np.median(y))\n    # Residuals\n    r2 = y - c2\n    r1 = y - c1\n    # Risks\n    R2_c2 = float(np.mean(r2 ** 2))\n    R2_c1 = float(np.mean(r1 ** 2))\n    R1_c2 = float(np.mean(np.abs(r2)))\n    R1_c1 = float(np.mean(np.abs(r1)))\n    # Safety utility: 1 / (1 + median absolute error)\n    U_c2 = float(1.0 / (1.0 + float(np.median(np.abs(r2)))))\n    U_c1 = float(1.0 / (1.0 + float(np.median(np.abs(r1)))))\n    # Booleans\n    B2 = R2_c1 <= R2_c2\n    B1 = R1_c1 <= R1_c2\n    BU = U_c1 >= U_c2\n    return [R2_c2, R2_c1, R1_c2, R1_c1, U_c2, U_c1, B2, B1, BU]\n\ndef solve():\n    # Test cases: (seed, n, p, M, mu, sigma)\n    test_cases = [\n        (42, 101, 0.0, 0, 0, 1),\n        (7, 200, 0.02, 50, 0, 1),\n        (11, 200, 0.01, 200, 0, 1),\n        (123, 9, 0.2, 30, 0, 1),\n        (2024, 500, 0.05, 20, 0, 1),\n    ]\n    results = []\n    for seed, n, p, M, mu, sigma in test_cases:\n        y = generate_sample(seed, n, p, M, mu, sigma)\n        res = empirical_risks_and_utility(y)\n        results.append(res)\n    # Print a single line JSON-like list for deterministic formatting\n    print(json.dumps(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3175044"}]}