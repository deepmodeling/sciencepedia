{"hands_on_practices": [{"introduction": "A single accuracy score, while useful, doesn't tell the whole story about a model's performance. This practice demonstrates how to use the bootstrap to quantify the uncertainty around a classifier's accuracy, derived from its confusion matrix. By resampling the classification outcomes, you will construct confidence intervals, providing a robust range of plausible values for the true accuracy and gaining deeper insight into your model's reliability [@problem_id:3106305].", "problem": "You are given a binary classification setting with observed confusion matrix entries for a dataset. The confusion matrix entries are defined as follows: $TP$ is the number of true positives, $FP$ is the number of false positives, $TN$ is the number of true negatives, and $FN$ is the number of false negatives. The accuracy is defined as $A = (TP + TN)/n$, where $n = TP + FP + TN + FN$ is the total number of observations. You will use the nonparametric bootstrap to quantify uncertainty in the vector of confusion matrix entries $(TP, FP, TN, FN)$ and propagate this uncertainty to a confidence interval for accuracy. You will also assess covariance effects between confusion matrix entries.\n\nFundamental base:\n- The nonparametric bootstrap approximates the sampling distribution by resampling with replacement from the empirical distribution.\n- The empirical distribution of the four categorical outcomes $(TP, FP, TN, FN)$ places mass $\\hat{p}_k = c_k / n$ on each category $k \\in \\{TP, FP, TN, FN\\}$, where $c_k$ is the observed count. A bootstrap sample of size $n$ drawn from the empirical distribution induces a count vector with a multinomial distribution with parameters $n$ and probabilities $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$.\n- A confidence interval (CI) can be formed by the percentile method: for a statistic $T$, the lower and upper endpoints are the $\\alpha/2$ and $1-\\alpha/2$ empirical quantiles of the bootstrap replicates of $T$ at a chosen level $1-\\alpha$.\n- For a smooth function $g$ of a random vector $X$, the delta method gives an approximation $\\mathrm{Var}(g(X)) \\approx \\nabla g(\\mu)^\\top \\Sigma \\nabla g(\\mu)$, where $\\mu = \\mathbb{E}[X]$, $\\Sigma = \\mathrm{Cov}(X)$, and $\\nabla g$ is the gradient. When $\\Sigma$ is estimated by the bootstrap covariance of the vector $(TP, FP, TN, FN)$, this yields a normal-approximation CI for $A$.\n\nYour program must implement the following steps for each test case:\n1. Use the observed confusion matrix counts $(TP, FP, TN, FN)$ and total $n$ to define the empirical probabilities $\\hat{p}_{TP} = TP/n$, $\\hat{p}_{FP} = FP/n$, $\\hat{p}_{TN} = TN/n$, $\\hat{p}_{FN} = FN/n$.\n2. Generate $B$ bootstrap replicates of the count vector by drawing from a multinomial distribution of size $n$ with category probabilities $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$. Use a fixed random seed to ensure reproducibility.\n3. For each bootstrap replicate $b$, compute the accuracy $A^{(b)} = (TP^{(b)} + TN^{(b)})/n$.\n4. Construct a percentile confidence interval for accuracy at level $1-\\alpha$ by taking the empirical quantiles of $\\{A^{(b)}\\}$ at $q_{\\mathrm{low}} = \\alpha/2$ and $q_{\\mathrm{high}} = 1-\\alpha/2$.\n5. Estimate the covariance matrix $\\hat{\\Sigma}$ of the bootstrap replicates of the vector $(TP, FP, TN, FN)$ and use the delta method to form a normal-approximation confidence interval for accuracy at level $1-\\alpha$. Specifically, use the linearization of accuracy as a function of $(TP, FP, TN, FN)$ at the observed counts to obtain the standard error and then construct the symmetric normal CI. Do not clip the interval to $[0,1]$; report the raw endpoints as decimals.\n6. Assess covariance effects by computing the bootstrap correlation between $(TP, TN)$ and between $(TP, FP)$ from the bootstrap replicates. If either component in a pair has zero bootstrap variance, define the correlation as $0$.\n\nTest suite:\n- Case $1$ (balanced, moderate accuracy): $n = 200$, $(TP, FP, TN, FN) = (70, 20, 90, 20)$.\n- Case $2$ (imbalanced, rare positives): $n = 300$, $(TP, FP, TN, FN) = (5, 25, 260, 10)$.\n- Case $3$ (small sample, degenerate predictor): $n = 40$, $(TP, FP, TN, FN) = (0, 0, 28, 12)$.\n\nCommon settings for all cases:\n- Confidence level: $1-\\alpha = 0.95$ (so $\\alpha = 0.05$).\n- Number of bootstrap replicates: $B = 40000$.\n- Random seed: $R = 1729$.\n- All accuracy-related quantities must be reported as decimals, not percentages.\n\nRequired outputs for each test case:\n- A list of $7$ floats in the following order:\n  - Accuracy point estimate $A$.\n  - Percentile CI lower endpoint for $A$.\n  - Percentile CI upper endpoint for $A$.\n  - Delta-method CI lower endpoint for $A$.\n  - Delta-method CI upper endpoint for $A$.\n  - Correlation between $(TP, TN)$ estimated from bootstrap replicates.\n  - Correlation between $(TP, FP)$ estimated from bootstrap replicates.\n- If a correlation is undefined due to zero variance in either component, return $0$ for that correlation.\n\nFinal output format:\n- Your program should produce a single line of output containing a comma-separated list of the per-case results, enclosed in square brackets, where each per-case result is itself a bracketed, comma-separated list in the order specified above. All floats must be rounded to $6$ decimal places. For example, an output with two cases would look like $[[0.800000,0.750000,0.840000,0.760000,0.840000,-0.300000,-0.200000],[\\dots]]$.", "solution": "The user a-priori states that the problem statement is valid. My analysis confirms this: the problem is scientifically grounded, well-posed, objective, and has no other invalidating flaws. It falls squarely within the domain of computational statistics and statistical learning, with all necessary parameters and definitions provided for a unique, verifiable solution.\n\nThe objective is to analyze the uncertainty of a binary classifier's accuracy using the nonparametric bootstrap, based on its confusion matrix counts $(TP, FP, TN, FN)$. We will compute a point estimate for accuracy, construct two types of confidence intervals (percentile and delta-method), and assess the correlations between certain count components. The total number of observations is $n = TP + FP + TN + FN$.\n\nThe accuracy $A$ is defined as the fraction of correct predictions:\n$$A = \\frac{TP + TN}{n}$$\nThis serves as our point estimate for the true accuracy, computed from the observed counts.\n\nThe core of the analysis is the nonparametric bootstrap. This method simulates the sampling process by drawing with replacement from the observed data. For categorical data summarized by counts $(c_{TP}, c_{FP}, c_{TN}, c_{FN})$, this is equivalent to drawing from the empirical probability distribution. The empirical probabilities are $\\hat{p}_k = c_k / n$ for each category $k \\in \\{TP, FP, TN, FN\\}$. A bootstrap sample of the counts is a vector $\\mathbf{c}^{(b)} = (TP^{(b)}, FP^{(b)}, TN^{(b)}, FN^{(b)})$ drawn from a multinomial distribution with $n$ trials and the probability vector $\\hat{\\mathbf{p}} = (\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$.\n$$\\mathbf{c}^{(b)} \\sim \\mathrm{Multinomial}(n, \\hat{\\mathbf{p}})$$\nWe generate $B = 40000$ such bootstrap replicate vectors.\n\nFor each bootstrap replicate of the counts $\\mathbf{c}^{(b)}$, we compute the corresponding accuracy:\n$$A^{(b)} = \\frac{TP^{(b)} + TN^{(b)}}{n}$$\nThis process yields a distribution of $B$ bootstrap accuracies, $\\{A^{(b)}\\}_{b=1}^B$, which approximates the sampling distribution of the accuracy estimate $A$.\n\nFrom this bootstrap distribution, we construct a $(1-\\alpha)$ confidence interval for accuracy using the percentile method. For a confidence level of $1-\\alpha = 0.95$ (i.e., $\\alpha=0.05$), the lower and upper bounds of the interval are the $q_{\\mathrm{low}} = \\alpha/2 = 0.025$ and $q_{\\mathrm{high}} = 1 - \\alpha/2 = 0.975$ empirical quantiles of the bootstrap accuracies $\\{A^{(b)}\\}$.\n$$\\text{CI}_{\\text{percentile}} = [Q_{0.025}, Q_{0.975}]$$\n\nNext, we construct a confidence interval using the delta method. This method uses a first-order Taylor expansion to approximate the variance of a function of random variables. Here, accuracy is a function of the count vector $\\mathbf{c} = (TP, FP, TN, FN)$: $A = g(\\mathbf{c}) = (TP + TN)/n$. The gradient of this function with respect to the counts is a constant vector:\n$$\\nabla g = \\left( \\frac{\\partial g}{\\partial TP}, \\frac{\\partial g}{\\partial FP}, \\frac{\\partial g}{\\partial TN}, \\frac{\\partial g}{\\partial FN} \\right)^\\top = \\left( \\frac{1}{n}, 0, \\frac{1}{n}, 0 \\right)^\\top$$\nThe delta method approximates the variance of $A$ as:\n$$\\widehat{\\mathrm{Var}}(A) \\approx (\\nabla g)^\\top \\hat{\\Sigma} (\\nabla g)$$\nwhere $\\hat{\\Sigma}$ is the sample covariance matrix of the bootstrap count vectors $\\{\\mathbf{c}^{(b)}\\}_{b=1}^B$. The standard error of $A$ is $SE(A) = \\sqrt{\\widehat{\\mathrm{Var}}(A)}$. The $(1-\\alpha)$ normal-approximation confidence interval is then constructed symmetrically around the point estimate $A$:\n$$\\text{CI}_{\\text{delta}} = [A - z_{1-\\alpha/2} \\cdot SE(A), A + z_{1-\\alpha/2} \\cdot SE(A)]$$\nwhere $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the standard normal distribution. For $\\alpha=0.05$, $z_{0.975} \\approx 1.96$.\n\nFinally, we assess the relationships between the count components by computing their correlations from the bootstrap replicates. The correlation between two components, say $X_i$ and $X_j$ (e.g., $TP$ and $TN$), is estimated from the bootstrap covariance matrix $\\hat{\\Sigma}$ as:\n$$\\hat{\\rho}_{ij} = \\frac{\\hat{\\Sigma}_{ij}}{\\sqrt{\\hat{\\Sigma}_{ii} \\hat{\\Sigma}_{jj}}}$$\nwhere $\\hat{\\Sigma}_{ii}$ and $\\hat{\\Sigma}_{jj}$ are the variances. If the bootstrap variance of either component is $0$ (which occurs if the empirical probability is $0$), the correlation is defined to be $0$.\n\nThe implementation will proceed by iterating through each test case, applying these steps with a fixed random seed $R=1729$ for reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes bootstrap confidence intervals and correlations for classifier accuracy.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # ((TP, FP, TN, FN), n)\n        ((70, 20, 90, 20), 200),\n        ((5, 25, 260, 10), 300),\n        ((0, 0, 28, 12), 40),\n    ]\n\n    # Common settings for all cases\n    B = 40000\n    alpha = 0.05\n    R = 1729\n    rng = np.random.default_rng(R)\n\n    all_results_str = []\n    for case in test_cases:\n        counts, n = case\n        \n        # 1. Point estimate and empirical probabilities\n        tp, fp, tn, fn = counts\n        A = (tp + tn) / n\n        p_hat = np.array(counts) / n\n\n        # 2. Generate B bootstrap replicates of the count vector\n        # Each row is a draw from Multinomial(n, p_hat)\n        bootstrap_counts = rng.multinomial(n, p_hat, size=B)\n\n        # 3. Compute accuracy for each bootstrap replicate\n        bootstrap_accuracies = (bootstrap_counts[:, 0] + bootstrap_counts[:, 2]) / n\n\n        # 4. Construct percentile confidence interval\n        q_low = alpha / 2\n        q_high = 1 - alpha / 2\n        ci_percentile_low = np.quantile(bootstrap_accuracies, q_low)\n        ci_percentile_high = np.quantile(bootstrap_accuracies, q_high)\n\n        # 5. Construct delta-method confidence interval\n        # Estimate covariance matrix from bootstrap replicates\n        cov_mat = np.cov(bootstrap_counts, rowvar=False)\n        \n        # Gradient of accuracy function g(TP, FP, TN, FN) = (TP + TN)/n\n        grad_g = np.array([1/n, 0, 1/n, 0])\n        \n        # Delta method variance approximation\n        var_A_delta = grad_g.T @ cov_mat @ grad_g\n        # Use max(0, ...) for numerical stability, though var should be non-negative\n        se_A_delta = np.sqrt(max(0, var_A_delta))\n        \n        z_val = norm.ppf(q_high)\n        ci_delta_low = A - z_val * se_A_delta\n        ci_delta_high = A + z_val * se_A_delta\n\n        # 6. Assess covariance effects by computing correlations\n        var_tp = cov_mat[0, 0]\n        var_fp = cov_mat[1, 1]\n        var_tn = cov_mat[2, 2]\n\n        # Correlation between TP and TN\n        if var_tp == 0 or var_tn == 0:\n            corr_tp_tn = 0.0\n        else:\n            cov_tp_tn = cov_mat[0, 2]\n            corr_tp_tn = cov_tp_tn / np.sqrt(var_tp * var_tn)\n\n        # Correlation between TP and FP\n        if var_tp == 0 or var_fp == 0:\n            corr_tp_fp = 0.0\n        else:\n            cov_tp_fp = cov_mat[0, 1]\n            corr_tp_fp = cov_tp_fp / np.sqrt(var_tp * var_fp)\n\n        # Collate and format results for the current case\n        case_results = [A, ci_percentile_low, ci_percentile_high, ci_delta_low, ci_delta_high, corr_tp_tn, corr_tp_fp]\n        formatted_case_results = [f\"{x:.6f}\" for x in case_results]\n        all_results_str.append(f\"[{','.join(formatted_case_results)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3106305"}, {"introduction": "The gap between a model's performance on training and test data is a crucial indicator of overfitting. This exercise applies the bootstrap to estimate the uncertainty of this generalization gap, defined as the difference between training and test loss. By independently resampling both datasets, you will learn to construct a confidence interval for this difference, helping you assess whether your model is truly generalizing or simply memorizing the training data [@problem_id:3106350].", "problem": "You are given binary per-example losses for independent training and test samples under the zero-one loss and asked to estimate a confidence interval for the generalization gap using the bootstrap. The empirical loss on a sample is defined as the arithmetic mean of its per-example losses. The generalization gap is defined as the difference between the empirical training loss and the empirical test loss. You must design and implement a program that, for each provided case, uses the nonparametric bootstrap to approximate the sampling distribution of the generalization gap and then forms a two-sided confidence interval via the percentile method.\n\nStart from the following fundamental base:\n- The empirical loss on a sample with per-example losses $l_1,\\dots,l_n \\in \\{0,1\\}$ is $\\hat{L} = \\frac{1}{n}\\sum_{i=1}^n l_i$.\n- The generalization gap is $G = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$.\n- The nonparametric bootstrap approximates the sampling distribution of a statistic by resampling with replacement from the observed data and recomputing the statistic on each resample.\n- A two-sided percentile confidence interval at level $1-\\alpha$ for a scalar parameter $\\theta$ uses the $\\alpha/2$ and $1-\\alpha/2$ quantiles of the bootstrap distribution of the statistic that estimates $\\theta$.\n\nAlgorithmic task:\n- For each test case, independently resample with replacement within the training set and within the test set. For each bootstrap replicate, compute the empirical training loss and the empirical test loss on the resampled data, then compute the corresponding bootstrap replicate $G^\\ast$. Repeat this for $B$ bootstrap replicates to obtain a bootstrap sample $\\{G^\\ast_b\\}_{b=1}^B$.\n- Let $\\hat{G}$ be the point estimate computed from the original data, i.e., the difference between the original empirical training and test losses. Form the two-sided percentile confidence interval for $G$ at level $1-\\alpha$ by taking the empirical quantiles at probabilities $\\alpha/2$ and $1-\\alpha/2$ of the bootstrap sample $\\{G^\\ast_b\\}_{b=1}^B$.\n\nYour program must implement this procedure for the following test suite. In each case, per-example losses are given explicitly as sequences of $0$ and $1$, the bootstrap replicate count is $B$, and the nominal level is $1-\\alpha$. Random number generation for the bootstrap must use the specified seed to ensure deterministic output.\n\nTest suite:\n- Case A:\n  - Training losses: $[0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,1,0,0]$.\n  - Test losses: $[0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0]$.\n  - Bootstrap replicates: $B=5000$.\n  - Confidence level: $1-\\alpha=0.95$ (so $\\alpha=0.05$).\n  - Random seed: $12345$.\n- Case B:\n  - Training losses: $[1,0,0,1,0,0]$.\n  - Test losses: $[0,1,0,0,0,0,1]$.\n  - Bootstrap replicates: $B=4000$.\n  - Confidence level: $1-\\alpha=0.90$ (so $\\alpha=0.10$).\n  - Random seed: $2023$.\n- Case C:\n  - Training losses: $[0,0,0,0,0,0,0,0,0,0,0,0]$.\n  - Test losses: $[0,0,1,0,0,0,0,1,0,0,0,1]$.\n  - Bootstrap replicates: $B=8000$.\n  - Confidence level: $1-\\alpha=0.95$ (so $\\alpha=0.05$).\n  - Random seed: $777$.\n\nRequirements:\n- For each case, compute the point estimate $\\hat{G}$ from the original data and the corresponding two-sided percentile confidence interval $\\left[q_{\\alpha/2}, q_{1-\\alpha/2}\\right]$ from the bootstrap distribution of $G^\\ast$.\n- Express all outputs as real numbers with six digits after the decimal point.\n- Final output format: Your program should produce a single line of output containing the results for all cases as a single comma-separated list enclosed in square brackets. Each case must itself be a three-element list in the order $[\\hat{G}, \\text{lower}, \\text{upper}]$. For example, an output for three cases must look like $[[g_1,\\ell_1,u_1],[g_2,\\ell_2,u_2],[g_3,\\ell_3,u_3]]$ with each $g_i,\\ell_i,u_i$ printed to six decimal places.\n\nNo user input is allowed; all data are specified above and must be embedded in the program. There are no physical units in this problem, and all probabilities or levels must be expressed as decimals rather than with a percent sign.", "solution": "The problem is valid as it presents a well-defined, scientifically-grounded task in the domain of computational statistics. All necessary data and parameters are provided, and the methodology is standard and objective.\n\nThe objective is to estimate a confidence interval for the generalization gap, $G$, which is the difference between the empirical training loss and the empirical test loss. The per-example losses are binary, $l_i \\in \\{0, 1\\}$, representing the zero-one loss. Given a set of per-example losses $\\{l_i\\}_{i=1}^n$, the empirical loss is defined as their arithmetic mean, $\\hat{L} = \\frac{1}{n}\\sum_{i=1}^n l_i$.\n\nLet the observed training losses be the set $S_{\\text{train}} = \\{l_{\\text{train},i}\\}_{i=1}^{n_{\\text{train}}}$ and the observed test losses be $S_{\\text{test}} = \\{l_{\\text{test},j}\\}_{j=1}^{n_{\\text{test}}}$, where $n_{\\text{train}}$ and $n_{\\text{test}}$ are the respective sample sizes.\n\nThe empirical training loss is $\\hat{L}_{\\text{train}} = \\frac{1}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} l_{\\text{train},i}$, and the empirical test loss is $\\hat{L}_{\\text{test}} = \\frac{1}{n_{\\text{test}}}\\sum_{j=1}^{n_{\\text{test}}} l_{\\text{test},j}$. The generalization gap statistic, $G$, is their difference:\n$$G = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$$\nThe point estimate for a given dataset, denoted $\\hat{G}$, is calculated directly from the original training and test samples.\n\nTo construct a confidence interval for $G$, we employ the nonparametric bootstrap. This method approximates the sampling distribution of the statistic $G$ by repeatedly resampling from the observed data. The underlying principle is that resampling from the empirical distribution (the observed sample) mimics the process of sampling from the true underlying distribution.\n\nThe algorithm proceeds as follows:\n\n1.  **Point Estimate**: Calculate the point estimate $\\hat{G} = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$ using the original, complete samples $S_{\\text{train}}$ and $S_{\\text{test}}$.\n\n2.  **Bootstrap Resampling**: For each bootstrap replicate $b$ from $1$ to $B$:\n    a.  Generate a bootstrap training sample, $S_{\\text{train}}^{\\ast, b}$, by drawing $n_{\\text{train}}$ observations from $S_{\\text{train}}$ with replacement.\n    b.  Generate a bootstrap test sample, $S_{\\text{test}}^{\\ast, b}$, by drawing $n_{\\text{test}}$ observations from $S_{\\text{test}}$ with replacement. The training and test resampling processes are independent.\n\n3.  **Bootstrap Statistic Calculation**: For each replicate $b$, compute the bootstrap version of the generalization gap, $G_b^\\ast$:\n    a.  Calculate the empirical loss on the bootstrap training sample: $\\hat{L}_{\\text{train}}^{\\ast, b} = \\frac{1}{n_{\\text{train}}}\\sum_{l \\in S_{\\text{train}}^{\\ast, b}} l_i$.\n    b.  Calculate the empirical loss on the bootstrap test sample: $\\hat{L}_{\\text{test}}^{\\ast, b} = \\frac{1}{n_{\\text{test}}}\\sum_{l \\in S_{\\text{test}}^{\\ast, b}} l_j$.\n    c.  Compute the bootstrap replicate of the statistic: $G_b^\\ast = \\hat{L}_{\\text{train}}^{\\ast, b} - \\hat{L}_{\\text{test}}^{\\ast, b}$.\n\n4.  **Confidence Interval Construction**: The collection of $B$ bootstrap statistics, $\\{G_b^\\ast\\}_{b=1}^B$, forms an empirical approximation of the sampling distribution of $G$. The percentile method uses the quantiles of this empirical distribution to form a confidence interval. For a nominal confidence level of $1-\\alpha$, the two-sided percentile confidence interval is given by:\n    $$[q_{\\alpha/2}, q_{1-\\alpha/2}]$$\n    where $q_p$ denotes the $p$-th quantile of the bootstrap distribution $\\{G_b^\\ast\\}_{b=1}^B$. For example, with a confidence level of $0.95$, we have $\\alpha=0.05$. The interval is formed by a lower bound at the $2.5$-th percentile and an upper bound at the $97.5$-th percentile of the bootstrap replicates.\n\nThis procedure is applied to each of the three test cases provided, using a seeded random number generator to ensure deterministic and reproducible results. The point estimate $\\hat{G}$ and the lower and upper bounds of the confidence interval are computed and reported to six decimal places.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes a point estimate and a bootstrap percentile confidence interval\n    for the generalization gap for several test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"train_losses\": [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n            \"test_losses\": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"B\": 5000,\n            \"alpha\": 0.05,\n            \"seed\": 12345\n        },\n        {\n            \"train_losses\": [1, 0, 0, 1, 0, 0],\n            \"test_losses\": [0, 1, 0, 0, 0, 0, 1],\n            \"B\": 4000,\n            \"alpha\": 0.10,\n            \"seed\": 2023\n        },\n        {\n            \"train_losses\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"test_losses\": [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n            \"B\": 8000,\n            \"alpha\": 0.05,\n            \"seed\": 777\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        train_losses = np.array(case[\"train_losses\"])\n        test_losses = np.array(case[\"test_losses\"])\n        B = case[\"B\"]\n        alpha = case[\"alpha\"]\n        seed = case[\"seed\"]\n\n        n_train = len(train_losses)\n        n_test = len(test_losses)\n\n        # Step 1: Calculate the point estimate of the generalization gap\n        L_hat_train = np.mean(train_losses)\n        L_hat_test = np.mean(test_losses)\n        G_hat = L_hat_train - L_hat_test\n\n        # Initialize random number generator for reproducibility\n        np.random.seed(seed)\n\n        # Steps 2  3: Perform bootstrap resampling and compute the statistic\n        bootstrap_gaps = []\n        for _ in range(B):\n            # Resample with replacement from training and test sets\n            train_resample = np.random.choice(train_losses, size=n_train, replace=True)\n            test_resample = np.random.choice(test_losses, size=n_test, replace=True)\n\n            # Compute empirical losses for the bootstrap samples\n            L_star_train = np.mean(train_resample)\n            L_star_test = np.mean(test_resample)\n\n            # Compute and store the bootstrap replicate of the generalization gap\n            G_star = L_star_train - L_star_test\n            bootstrap_gaps.append(G_star)\n        \n        bootstrap_gaps = np.array(bootstrap_gaps)\n\n        # Step 4: Construct the percentile confidence interval\n        lower_percentile = (alpha / 2.0) * 100\n        upper_percentile = (1 - alpha / 2.0) * 100\n        \n        ci_lower, ci_upper = np.percentile(bootstrap_gaps, [lower_percentile, upper_percentile])\n\n        results.append([G_hat, ci_lower, ci_upper])\n\n    # Format and print the final output\n    formatted_results = [f\"[{gh:.6f},{l:.6f},{u:.6f}]\" for gh, l, u in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3106350"}, {"introduction": "The standard bootstrap rests on the assumption of independent data points, a condition often violated in real-world scenarios like image analysis or time series. This practice explores the consequences of ignoring spatial correlation and introduces the block bootstrap as a solution. You will conduct a simulation study to compare the performance of the naive bootstrap against the block bootstrap, gaining a deep, practical understanding of how to handle dependent data correctly [@problem_id:3106269].", "problem": "Consider a binary pixel classification task on a single synthetic image of size $N \\times N$ pixels, where neighboring pixels exhibit spatial correlation in their classification correctness. Let $X_{ij} \\in \\{0,1\\}$ denote the indicator of a correct classification at pixel $(i,j)$, and define the empirical accuracy over the entire image as\n$$\n\\hat{A} \\;=\\; \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} X_{ij}.\n$$\nAssume the following generative mechanism for spatially correlated correctness:\n- Draw a white noise field $W_{ij} \\sim \\mathcal{N}(0,1)$ independently for all pixels.\n- Smooth $W$ by convolution with a normalized, isotropic Gaussian kernel of standard deviation $s$ to obtain a correlated field $Z_{ij}$.\n- Set a base logit-level $\\alpha = \\log\\left(\\frac{p}{1-p}\\right)$, where $p$ is the target baseline correctness probability of an uncorrelated model.\n- Define pixel-wise correctness probabilities via the logistic map $\\pi_{ij} = \\frac{1}{1 + e^{-(\\alpha + Z_{ij})}}$, and then draw $X_{ij} \\sim \\mathrm{Bernoulli}(\\pi_{ij})$ independently across pixels conditional on the field.\n\nFor inference on $\\hat{A}$ using bootstrap, consider two resampling schemes applied to the single observed image:\n- An independent and identically distributed (iid) bootstrap resampling at the pixel level, where resamples are formed by drawing $N^2$ pixels with replacement from the $N^2$ observed pixels and computing the mean of the resampled indicators.\n- A patch-based block bootstrap resampling that preserves spatial dependence by drawing square patches (blocks) of side length $b$ with replacement from all possible overlapping $b \\times b$ patches in the image; concatenate a sufficient number of patches to reach at least $N^2$ pixels and compute the mean over the first $N^2$ pixels of the concatenated patches.\n\nFor each resampling scheme, form a two-sided bootstrap confidence interval (CI) for $\\hat{A}$ by taking the empirical lower and upper quantiles at levels $0.025$ and $0.975$ of the bootstrap distribution of resampled means. Define coverage for a given scheme and a single image realization to be the event that the interval contains the true empirical accuracy $\\hat{A}$ computed on the full image pixels. Over repeated independent realizations of the image (new draws of $W$ and $X$), define the coverage rate as the fraction of realizations whose interval contains the corresponding $\\hat{A}$. This coverage rate must be expressed as a decimal in $[0,1]$.\n\nStarting from the core definitions of bootstrap resampling, confidence intervals, and empirical accuracy, implement a program that:\n1. Generates $R$ independent realizations of the image according to the mechanism above.\n2. For each realization, computes $\\hat{A}$ and two bootstrap CIs (iid pixel-level and patch-based block) using $B$ bootstrap resamples for each scheme.\n3. Records whether each CI covers $\\hat{A}$ and aggregates the coverage rate over the $R$ realizations for both schemes.\n\nUse a fixed pseudorandom seed of $2025$ for reproducibility. Use a Gaussian convolution kernel with standard deviation $s$ and a square support of side length $L = 2\\lceil 3s \\rceil + 1$ pixels, normalized to sum to $1$. The baseline correctness parameter $p$ appears only through $\\alpha$; all other notation is defined above.\n\nTest Suite. Run the program for the following four parameter sets, where $N$ is the image side length, $p$ is the baseline correctness probability, $s$ controls the spatial correlation (as the Gaussian kernel standard deviation), $b$ is the patch side length for the block bootstrap, $R$ is the number of realizations, and $B$ is the number of bootstrap resamples per scheme:\n- Case $1$: $(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,1.0,\\,1,\\,200,\\,400\\,)$.\n- Case $2$: $(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,4,\\,200,\\,400\\,)$.\n- Case $3$: $(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,8,\\,200,\\,400\\,)$.\n- Case $4$: $(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,4.0,\\,4,\\,200,\\,400\\,)$.\n\nYour program must produce a single line of output containing the coverage rates for the iid and block bootstrap schemes for all four cases. The required format is a comma-separated list of lists of two floats, enclosed in square brackets. Concretely, the output must be of the form\n$$\n[\\,[c^{\\mathrm{iid}}_1, c^{\\mathrm{block}}_1], [c^{\\mathrm{iid}}_2, c^{\\mathrm{block}}_2], [c^{\\mathrm{iid}}_3, c^{\\mathrm{block}}_3], [c^{\\mathrm{iid}}_4, c^{\\mathrm{block}}_4]\\,]\n$$\nwhere $c^{\\mathrm{iid}}_k$ and $c^{\\mathrm{block}}_k$ are the coverage rates for case $k$, each reported as a decimal in $[0,1]$.", "solution": "The user wants to evaluate the coverage rates of two bootstrap-based confidence interval schemes for the mean accuracy of a pixel-wise classifier on a spatially correlated synthetic image. The problem is well-posed and grounded in standard statistical simulation methodology. We will proceed by implementing the specified data generation process and the two resampling schemes (IID and block bootstrap), wrapping them in a Monte Carlo simulation to estimate the coverage probabilities.\n\n### Algorithm Breakdown\n\nThe core of the problem is to run a simulation study. For each of the four specified parameter sets, we must perform the following steps:\n\n1.  **Initialization**: Set a master pseudorandom number generator (RNG) with the specified seed, $2025$, for reproducibility. Initialize coverage counters for both the IID and block bootstrap schemes to zero.\n\n2.  **Monte Carlo Loop**: Repeat $R$ times (for $R$ independent realizations):\n    a. **Data Generation**: Generate a single $N \\times N$ binary image $X$ representing classification correctness, according to the specified spatial correlation model.\n        i.  Generate an $N \\times N$ field of standard normal white noise, $W_{ij}$.\n        ii. Create a 2D Gaussian convolution kernel with standard deviation $s$ and support side length $L = 2\\lceil 3s \\rceil + 1$. The kernel must be normalized to sum to $1$.\n        iii. Convolve the noise field $W$ with the Gaussian kernel to produce a spatially correlated Gaussian field $Z$. We will use periodic boundary conditions (`wrap`) to avoid edge effects.\n        iv. Convert the baseline correctness probability $p$ to a logit-scale parameter $\\alpha = \\log(p/(1-p))$.\n        v.  Transform the correlated field $Z$ into pixel-wise correctness probabilities $\\pi_{ij}$ using the logistic function: $\\pi_{ij} = (1 + e^{-(\\alpha + Z_{ij})})^{-1}$.\n        vi. Generate the final binary image $X$ where each pixel $X_{ij}$ is an independent Bernoulli trial with success probability $\\pi_{ij}$.\n\n    b. **True Accuracy**: Compute the empirical accuracy $\\hat{A}$ for the generated image $X$, which is simply the mean of all pixel values: $\\hat{A} = \\frac{1}{N^2} \\sum_{i,j} X_{ij}$. This value serves as the \"true\" parameter that the confidence intervals are intended to capture.\n\n    c. **IID Bootstrap Confidence Interval**:\n        i.  Generate $B$ bootstrap samples by drawing $N^2$ pixels with replacement from the $N^2$ pixels of the image $X$.\n        ii. For each bootstrap sample, compute its mean. This yields a distribution of $B$ bootstrap means.\n        iii. Construct a $95\\%$ confidence interval by finding the $2.5^{th}$ and $97.5^{th}$ percentiles of this distribution.\n\n    d. **Block Bootstrap Confidence Interval**:\n        i.  Generate $B$ block-bootstrap samples. Each sample is constructed by:\n            - Identifying all overlapping $b \\times b$ blocks in the image $X$.\n            - Calculating the number of blocks to draw, $M = \\lceil N^2 / b^2 \\rceil$.\n            - Drawing $M$ blocks with replacement.\n            - Concatenating the drawn blocks and taking the first $N^2$ pixels.\n        ii. For each of the $B$ resulting sequences of $N^2$ pixels, compute its mean. This yields a distribution of $B$ block-bootstrap means.\n        iii. Construct a $95\\%$ confidence interval using the $2.5^{th}$ and $97.5^{th}$ percentiles of this distribution.\n\n    e. **Coverage Check**:\n        i.  Check if the IID bootstrap CI contains $\\hat{A}$. If it does, increment the IID coverage counter.\n        ii. Check if the block bootstrap CI contains $\\hat{A}$. If it does, increment the block coverage counter.\n\n3.  **Compute Coverage Rates**: After the $R$ repetitions, calculate the coverage rate for each scheme by dividing its coverage counter by $R$.\n\n4.  **Repeat for all Cases**: Perform the entire process for each of the four parameter sets provided.\n\n### Implementation Details\n\n-   **RNG**: A single `numpy.random.default_rng` instance will be created with the seed and passed to all functions that require random number generation to ensure full reproducibility.\n-   **Vectorization**: To ensure computational efficiency, the bootstrap procedures will be vectorized. Instead of looping $B$ times, we will generate the random indices for all $B$ bootstrap samples at once and use NumPy's advanced indexing and broadcasting capabilities to compute all $B$ bootstrap means simultaneously.\n-   **Stride Tricks**: The extraction of overlapping blocks for the block bootstrap, which can be a bottleneck, will be implemented efficiently using `numpy.lib.stride_tricks.as_strided`. This creates a memory-efficient view of the original image data, avoiding the need to store all blocks in memory explicitly.\n-   **Special Case**: For the block bootstrap, if the block side length $b=1$, the procedure is mathematically equivalent to the IID bootstrap. Our implementation will handle this by delegating to the IID bootstrap function.\n\nThis structured approach ensures that all requirements of the problem are met in a scientifically rigorous and computationally efficient manner. The final output will be formatted precisely as specified.", "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom scipy.special import logit, expit\n\ndef solve():\n    \"\"\"\n    Solves the bootstrap coverage rate problem for all test cases.\n    \"\"\"\n\n    def generate_gaussian_kernel(s: float) -> np.ndarray:\n        \"\"\"\n        Generates a 2D Gaussian kernel normalized to sum to 1.\n        \n        Args:\n            s (float): Standard deviation of the Gaussian.\n        \n        Returns:\n            np.ndarray: The normalized 2D kernel.\n        \"\"\"\n        L = 2 * int(np.ceil(3 * s)) + 1\n        center = L // 2\n        coords = np.arange(L) - center\n        x, y = np.meshgrid(coords, coords)\n        kernel = np.exp(-(x**2 + y**2) / (2 * s**2))\n        return kernel / np.sum(kernel)\n\n    def generate_spatially_correlated_data(N: int, p: float, s: float, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Generates a single realization of the spatially correlated binary image.\n        \n        Args:\n            N (int): Side length of the square image.\n            p (float): Baseline correctness probability.\n            s (float): Standard deviation for the Gaussian correlation kernel.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: The N x N binary image X.\n        \"\"\"\n        # Generate white noise field\n        W = rng.normal(size=(N, N))\n        \n        # Create and apply Gaussian kernel for spatial correlation\n        kernel = generate_gaussian_kernel(s)\n        Z = convolve2d(W, kernel, mode='same', boundary='wrap')\n        \n        # Define pixel-wise correctness probabilities\n        alpha = logit(p)\n        pi = expit(alpha + Z)\n        \n        # Draw binary outcomes\n        X = rng.binomial(1, pi)\n        return X\n\n    def iid_bootstrap(X: np.ndarray, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the IID bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n        N_sq = N * N\n        X_flat = X.flatten()\n        \n        # Vectorized generation of B bootstrap samples\n        resample_indices = rng.choice(N_sq, size=(B, N_sq), replace=True)\n        bootstrap_samples = X_flat[resample_indices]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(bootstrap_samples, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    def block_bootstrap(X: np.ndarray, b: int, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the block bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            b (int): The side length of the square blocks.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n\n        if b == 1:\n            return iid_bootstrap(X, B, rng)\n            \n        N_sq = N * N\n\n        # Use stride tricks to get an efficient view of all overlapping blocks\n        n_blocks_dim = N - b + 1\n        block_view = np.lib.stride_tricks.as_strided(\n            X,\n            shape=(n_blocks_dim, n_blocks_dim, b, b),\n            strides=(X.strides[0], X.strides[1], X.strides[0], X.strides[1])\n        )\n        all_blocks = block_view.reshape(-1, b * b)\n        num_total_blocks = all_blocks.shape[0]\n\n        # Number of blocks to sample to get at least N^2 pixels\n        num_blocks_to_sample = int(np.ceil(N_sq / (b * b)))\n        \n        # Vectorized sampling of block indices for all B resamples\n        block_indices = rng.choice(num_total_blocks, size=(B, num_blocks_to_sample), replace=True)\n        \n        # Form B bootstrap samples by concatenating blocks\n        resampled_blocks = all_blocks[block_indices]\n        resampled_pixels = resampled_blocks.reshape(B, -1)[:, :N_sq]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(resampled_pixels, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    # --- Main Execution ---\n    \n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(2025)\n    \n    test_cases = [\n        (32, 0.80, 1.0, 1, 200, 400),\n        (32, 0.80, 2.0, 4, 200, 400),\n        (32, 0.80, 2.0, 8, 200, 400),\n        (32, 0.80, 4.0, 4, 200, 400),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, p, s, b, R, B = case\n        \n        iid_cover_count = 0\n        block_cover_count = 0\n        \n        for _ in range(R):\n            # 1. Generate one realization of the data\n            X = generate_spatially_correlated_data(N, p, s, rng)\n            A_hat = np.mean(X)\n            \n            # 2. Compute IID bootstrap CI and check coverage\n            iid_ci = iid_bootstrap(X, B, rng)\n            if iid_ci[0] = A_hat = iid_ci[1]:\n                iid_cover_count += 1\n            \n            # 3. Compute Block bootstrap CI and check coverage\n            block_ci = block_bootstrap(X, b, B, rng)\n            if block_ci[0] = A_hat = block_ci[1]:\n                block_cover_count += 1\n                \n        # 4. Calculate coverage rates for the current case\n        iid_rate = iid_cover_count / R\n        block_rate = block_cover_count / R\n        all_results.append([iid_rate, block_rate])\n\n    # Final print statement in the exact required format\n    # Example format: [[c_iid_1,c_block_1],[c_iid_2,c_block_2],...]\n    formatted_results = \",\".join(f\"[{res[0]},{res[1]}]\" for res in all_results)\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "3106269"}]}