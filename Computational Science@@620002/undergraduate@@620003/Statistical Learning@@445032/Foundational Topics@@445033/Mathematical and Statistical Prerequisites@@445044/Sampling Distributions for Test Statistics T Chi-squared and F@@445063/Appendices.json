{"hands_on_practices": [{"introduction": "Statistical theory provides the tools not just for analyzing data, but for designing effective experiments in the first place. A crucial question in any study is, 'How large a sample do I need?' This practice delves into the fundamentals of power analysis for the two-sample $t$-test. By working through this problem, you will see how the theoretical properties of the central and noncentral $t$-distributions directly translate into a practical formula for determining the required sample size to detect a scientifically meaningful effect with high probability. [@problem_id:3172267]", "problem": "A researcher plans a balanced two-sample study comparing two independent populations assumed to be Gaussian with a common but unknown variance. Let $X_{1},\\dots,X_{n} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(\\mu_{1},\\sigma^{2})$ and $Y_{1},\\dots,Y_{n} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(\\mu_{2},\\sigma^{2})$, with all observations independent. The primary analysis will use the pooled two-sample $t$-statistic for the one-sided test of $H_{0}:\\mu_{1}-\\mu_{2}=0$ versus $H_{1}:\\mu_{1}-\\mu_{2}=\\delta>0$. A pilot study suggests that the common standard deviation can be taken as $\\sigma=1.2$ for planning, and the scientifically relevant difference to detect is $\\delta=0.6$. The significance level is $\\alpha=0.05$ (one-sided), and the desired power is $1-\\beta=0.9$ when the true difference equals $\\delta$.\n\nStarting from first principles appropriate to normal sampling and sampling distributions of test statistics:\n- Define the pooled two-sample $t$-statistic and identify its sampling distribution under $H_{0}$ in terms of a central $t$-distribution with the appropriate degrees of freedom.\n- Identify its sampling distribution under $H_{1}$ in terms of a noncentral $t$-distribution, and express the noncentrality parameter in terms of $n$, $\\delta$, and $\\sigma$.\n- Translate the power requirement into a probability statement involving the noncentral $t$-distribution, and then derive a tractable approximation based on large-sample behavior that yields a closed-form planning formula for $n$ in terms of standard normal quantiles.\n- Using that derivation, compute the minimal integer per-group sample size $n$ that achieves at least the target power.\n\nFinally, briefly outline how you would validate the achieved power by simulating the sampling distribution of the test statistic under $H_{1}$, explicitly stating the steps you would take to generate data, compute the test statistic, determine rejection, and estimate power. No numerical simulation is required; only a clear, principled validation plan is needed.\n\nReport as your final answer the minimal integer $n$ per group that satisfies the power requirement. Do not include units. No rounding to significant figures is necessary because $n$ is an integer.", "solution": "The problem is valid as it represents a standard and well-posed question in statistical power analysis, a core topic in statistical learning and experimental design. All necessary parameters are provided, the question is scientifically grounded in established statistical theory, and it is free of ambiguity or contradiction.\n\nThe objective is to determine the minimum per-group sample size $n$ required for a balanced two-sample $t$-test to achieve a specified power. The solution proceeds by first defining the test statistic and its sampling distributions under the null and alternative hypotheses, then deriving a sample size formula, calculating the required $n$, and finally outlining a simulation-based validation plan.\n\nLet the two independent random samples be $X_{1}, \\dots, X_{n} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(\\mu_{1},\\sigma^{2})$ and $Y_{1}, \\dots, Y_{n} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(\\mu_{2},\\sigma^{2})$. The sample sizes are equal ($n_1=n_2=n$), and the population variances are assumed to be equal but unknown.\n\nThe sample means are $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ and $\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n} Y_i$. The sample variances are $S_{X}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (X_i - \\bar{X})^2$ and $S_{Y}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (Y_i - \\bar{Y})^2$. The pooled variance estimator, $S_p^2$, which combines information from both samples to estimate the common variance $\\sigma^2$, is given by:\n$$S_p^2 = \\frac{(n-1)S_X^2 + (n-1)S_Y^2}{(n-1) + (n-1)} = \\frac{S_X^2 + S_Y^2}{2}$$\nThis estimator is associated with $df = (n-1) + (n-1) = 2n-2$ degrees of freedom.\n\nThe pooled two-sample $t$-statistic is defined as:\n$$T = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)}{S_p \\sqrt{\\frac{1}{n} + \\frac{1}{n}}} = \\frac{\\bar{X} - \\bar{Y} - (\\mu_1 - \\mu_2)}{S_p \\sqrt{\\frac{2}{n}}}$$\n\nUnder the null hypothesis $H_0: \\mu_1 - \\mu_2 = 0$, the statistic simplifies to:\n$$T_0 = \\frac{\\bar{X} - \\bar{Y}}{S_p \\sqrt{\\frac{2}{n}}}$$\nThe sampling distribution of $T_0$ under $H_0$ is a central $t$-distribution with $2n-2$ degrees of freedom. We write this as $T_0 \\sim t_{2n-2}$.\n\nUnder the alternative hypothesis $H_1: \\mu_1 - \\mu_2 = \\delta > 0$, the numerator of the $t$-statistic, $\\bar{X} - \\bar{Y}$, has a mean of $\\delta$, not $0$. To identify the distribution, we can express the statistic $T$ as the ratio of a non-standard normal variable to the square root of an independent scaled chi-squared variable:\n$$T = \\frac{\\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)}{\\sigma \\sqrt{2/n}} + \\frac{\\mu_1 - \\mu_2}{\\sigma \\sqrt{2/n}}}{\\sqrt{S_p^2/\\sigma^2}}$$\nUnder $H_1$, the term $\\frac{(\\bar{X} - \\bar{Y}) - \\delta}{\\sigma \\sqrt{2/n}}$ is a standard normal variable, $Z \\sim \\mathcal{N}(0,1)$. The term $\\frac{(2n-2)S_p^2}{\\sigma^2}$ follows a chi-squared distribution with $df=2n-2$ degrees of freedom, $\\chi^2_{2n-2}$. Therefore, under $H_1$, the statistic $T$ follows a noncentral $t$-distribution with $df=2n-2$ degrees of freedom and a noncentrality parameter (NCP), denoted $\\lambda$, given by:\n$$\\lambda = \\frac{\\mu_1 - \\mu_2}{\\sigma \\sqrt{\\frac{2}{n}}} = \\frac{\\delta}{\\sigma \\sqrt{\\frac{2}{n}}} = \\frac{\\delta}{\\sigma}\\sqrt{\\frac{n}{2}}$$\nThus, under $H_1$, we have $T \\sim t_{2n-2}(\\lambda)$.\n\nThe one-sided test rejects $H_0$ if $T_0$ exceeds a critical value $c$. This critical value is the $(1-\\alpha)$-quantile of the central $t$-distribution, $c = t_{1-\\alpha, 2n-2}$. The power of the test, $1-\\beta$, is the probability of rejecting $H_0$ when $H_1$ is true:\n$$\\text{Power} = 1-\\beta = P(T > c \\mid H_1) = P\\left(t_{2n-2}(\\lambda) > t_{1-\\alpha, 2n-2}\\right)$$\nTo derive a tractable formula for $n$, we use a large-sample approximation. For large degrees of freedom ($df = 2n-2$), the central $t_{df}$ distribution approaches the standard normal distribution $\\mathcal{N}(0,1)$, and the noncentral $t_{df}(\\lambda)$ distribution approaches a normal distribution $\\mathcal{N}(\\lambda, 1)$.\nUsing this approximation, the critical value becomes $c \\approx z_{1-\\alpha}$, and the power equation becomes:\n$$1-\\beta \\approx P(\\mathcal{N}(\\lambda, 1) > z_{1-\\alpha})$$\nLet $Z' \\sim \\mathcal{N}(\\lambda, 1)$. Standardizing gives $Z = Z' - \\lambda \\sim \\mathcal{N}(0,1)$. The probability is:\n$$1-\\beta \\approx P(Z + \\lambda > z_{1-\\alpha}) = P(Z > z_{1-\\alpha} - \\lambda)$$\nSince $P(Z>z) = 1-\\Phi(z)$, where $\\Phi$ is the standard normal cumulative distribution function (CDF), we have $1-\\beta \\approx 1 - \\Phi(z_{1-\\alpha} - \\lambda)$, which implies $\\beta \\approx \\Phi(z_{1-\\alpha} - \\lambda)$. Taking the inverse normal CDF (quantile function) of both sides gives:\n$$z_{\\beta} \\approx z_{1-\\alpha} - \\lambda$$\nUsing the identity $z_{\\beta} = -z_{1-\\beta}$, we get:\n$$-z_{1-\\beta} \\approx z_{1-\\alpha} - \\lambda$$\nSolving for the noncentrality parameter $\\lambda$:\n$$\\lambda \\approx z_{1-\\alpha} + z_{1-\\beta}$$\nNow, we substitute the expression for $\\lambda$:\n$$\\frac{\\delta}{\\sigma}\\sqrt{\\frac{n}{2}} \\approx z_{1-\\alpha} + z_{1-\\beta}$$\nFinally, we solve for the per-group sample size $n$:\n$$\\sqrt{n} \\approx \\frac{\\sigma \\sqrt{2}}{\\delta}(z_{1-\\alpha} + z_{1-\\beta})$$\n$$n \\approx 2 \\left(\\frac{\\sigma}{\\delta}\\right)^2 (z_{1-\\alpha} + z_{1-\\beta})^2$$\nThis is the required closed-form planning formula for $n$.\n\nWe now compute $n$ using the provided values: $\\sigma = 1.2$, $\\delta = 0.6$, $\\alpha = 0.05$ (one-sided), and power $1-\\beta = 0.9$ (so $\\beta = 0.1$). We need the standard normal quantiles:\n$z_{1-\\alpha} = z_{0.95} \\approx 1.645$\n$z_{1-\\beta} = z_{0.90} \\approx 1.282$\nSubstituting these values into the formula:\n$$n \\approx 2 \\left(\\frac{1.2}{0.6}\\right)^2 (1.645 + 1.282)^2$$\n$$n \\approx 2 (2)^2 (2.927)^2$$\n$$n \\approx 8 (8.567329)$$\n$$n \\approx 68.5386$$\nSince the sample size must be an integer and the power must be at least $0.9$, we must round up to the nearest integer.\n$$n = 69$$\n\nTo validate this result, one would perform a Monte Carlo simulation. The plan is as follows:\n1.  **Set Simulation Parameters**: Define the true state of the world under $H_1$ and the test parameters.\n    - True difference in means: $\\mu_1 - \\mu_2 = \\delta = 0.6$. Let $\\mu_1 = 0.6$ and $\\mu_2 = 0$.\n    - True standard deviation: $\\sigma = 1.2$.\n    - Sample size per group: $n = 69$.\n    - Significance level: $\\alpha = 0.05$ (one-sided).\n    - Number of simulation repetitions: $M$, a large integer (e.g., $M=10,000$ or higher).\n2.  **Calculate Critical Value**: Determine the exact critical value for the test. With $n=69$, the degrees of freedom are $df = 2(69)-2 = 136$. The critical value is $c = t_{1-\\alpha, df} = t_{0.95, 136}$.\n3.  **Run Simulation Loop**: For each repetition $i$ from $1$ to $M$:\n    a. **Generate Data**: Draw two independent samples of size $n=69$: $X_{1}^{(i)}, \\dots, X_{n}^{(i)} \\sim \\mathcal{N}(0.6, 1.2^2)$ and $Y_{1}^{(i)}, \\dots, Y_{n}^{(i)} \\sim \\mathcal{N}(0, 1.2^2)$.\n    b. **Compute Test Statistic**: From the generated data, calculate the observed pooled two-sample $t$-statistic, $T_{obs}^{(i)} = \\frac{\\bar{X}^{(i)} - \\bar{Y}^{(i)}}{S_p^{(i)} \\sqrt{2/n}}$.\n    c. **Test Decision**: Compare the observed statistic to the critical value. If $T_{obs}^{(i)} > c$, the null hypothesis is rejected for this repetition.\n4.  **Estimate Power**: The estimated power is the fraction of repetitions where $H_0$ was rejected.\n    $$\\widehat{\\text{Power}} = \\frac{\\text{Number of rejections}}{M}$$\n5.  **Validation**: Compare the estimated power $\\widehat{\\text{Power}}$ to the target power of $0.9$. A value close to $0.9$ would validate the sample size calculation.", "answer": "$$\\boxed{69}$$", "id": "3172267"}, {"introduction": "Moving from comparing two means to the more general framework of linear regression, we encounter the omnibus $F$-test. A frequent source of confusion is the effect of multicollinearity—correlation among predictor variables—on the validity of this test. This computational exercise provides a powerful, hands-on demonstration that the null distribution of the $F$-statistic is robust to such correlations. Through simulation, you will verify that conditional on your predictors, the statistic follows an exact $F$-distribution, deepening your understanding of the geometric foundations of least squares and its inferential framework. [@problem_id:3172367]", "problem": "Consider the normal linear model with fixed design: for integers $n \\geq 2$ and $p \\geq 1$, let $X \\in \\mathbb{R}^{n \\times p}$ be a nonrandom design matrix, and let $y \\in \\mathbb{R}^{n}$ satisfy $y = X \\beta + \\varepsilon$, where $\\beta \\in \\mathbb{R}^{p}$ is an unknown parameter vector and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$ for a known $\\sigma^{2} > 0$. Focus on the omnibus test of the null hypothesis $H_{0}: \\beta = 0$ in this model. Conditional on $X$, the test statistic constructed from the orthogonal decomposition of $y$ into the column space of $X$ and its orthogonal complement is known to have an exact sampling distribution that depends only on the ranks of the associated projections when $H_{0}$ is true.\n\nYour task is to write a program that, for several correlated-design scenarios, verifies numerically that the conditional sampling distribution of the omnibus $F$-statistic under $H_{0}$ is exactly the central $F$ distribution with degrees of freedom determined by the rank of $X$, even when the columns of $X$ are correlated and possibly linearly dependent. You must build $X$ with equicorrelated feature columns using a multivariate normal generator, fix $X$, simulate many independent realizations of $y$ under $H_{0}$, compute the omnibus $F$-statistic for each realization using the least-squares projection onto the column space of $X$ (robust to rank deficiency), and then compare the empirical distribution of the statistic to the theoretical central $F$ distribution. Treat all matrices and vectors as purely mathematical objects without physical units.\n\nFundamental base to use:\n- The normal linear model assumptions: $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$ with fixed $X$.\n- Properties of orthogonal projections in $\\mathbb{R}^{n}$ and distributions of quadratic forms of Gaussian vectors.\n- The definitions of the chi-squared distribution and the central $F$ distribution.\n- The notion of Degrees of Freedom (df): the rank of a projection matrix determines the df of the associated chi-squared distribution.\n\nProgram requirements:\n1. For each test case, construct $X$ as follows.\n   - Draw rows of $X$ independently from a $p$-variate normal distribution with zero mean and equicorrelation covariance $\\Sigma \\in \\mathbb{R}^{p \\times p}$ having entries $\\Sigma_{ii} = 1$ for all $i$ and $\\Sigma_{ij} = \\rho$ for all $i \\neq j$ with a specified $\\rho \\in (-1, 1)$.\n   - Optionally (as specified per test), enforce a perfect linear dependence by replacing the last column of $X$ with the sum of the first two columns $X_{\\cdot, p} \\leftarrow X_{\\cdot, 1} + X_{\\cdot, 2}$.\n   - Compute an orthonormal basis $Q \\in \\mathbb{R}^{n \\times r}$ for the column space of $X$, where $r$ is the numerical rank of $X$ obtained from the singular value decomposition using a standard tolerance rule. This must handle both full-rank and rank-deficient designs.\n2. Conditional on the fixed $X$ in each test case, simulate $m$ independent realizations $y^{(1)}, \\dots, y^{(m)}$ under $H_{0}$ with $\\beta = 0$ and $\\sigma^{2} = 1$; equivalently, draw $\\varepsilon^{(k)} \\sim \\mathcal{N}(0, I_{n})$ and set $y^{(k)} = \\varepsilon^{(k)}$ for $k = 1, \\dots, m$.\n3. For each realization, compute the omnibus $F$-statistic using the decomposition induced by $Q$:\n   - The regression sum of squares is the squared norm of the projection of $y^{(k)}$ onto the column space of $X$, i.e., $\\operatorname{SSR}^{(k)} = \\|Q^{\\top} y^{(k)}\\|^{2}$.\n   - The residual sum of squares is the squared norm of the projection of $y^{(k)}$ onto the orthogonal complement, i.e., $\\operatorname{SSE}^{(k)} = \\|y^{(k)}\\|^{2} - \\operatorname{SSR}^{(k)}$.\n   - The omnibus statistic is $F^{(k)} = \\left(\\operatorname{SSR}^{(k)} / r\\right) \\big/ \\left(\\operatorname{SSE}^{(k)} / (n - r)\\right)$.\n4. Validate the exactness of the conditional sampling distribution in two complementary ways for each test case:\n   - Quantile agreement: compute empirical quantiles of $\\{F^{(k)}\\}_{k=1}^{m}$ at probabilities $q \\in \\{0.25, 0.5, 0.75, 0.9\\}$ and compare to the corresponding theoretical quantiles of the central $F$ distribution with df $(r, n - r)$. Report whether the maximum relative deviation across these probabilities is less than a specified tolerance.\n   - Uniform $p$-values: compute right-tail $p$-values $p^{(k)}$ using the central $F$ distribution with df $(r, n - r)$ and assess whether $\\{p^{(k)}\\}$ is consistent with the Uniform$(0,1)$ distribution using the Kolmogorov–Smirnov (KS) test (Kolmogorov–Smirnov (KS) will be the acronym used for this test). Report whether the KS statistic does not exceed a specified threshold.\n5. Combine the two checks to produce a boolean result per test case: return $true$ if both checks pass and $false$ otherwise.\n\nTest suite:\n- Case $1$ (happy path, correlated full rank): $n = 200$, $p = 5$, $\\rho = 0.8$, no enforced collinearity, $m = 5000$.\n- Case $2$ (boundary, $p = 1$ so $F$ reduces to a squared $t$): $n = 50$, $p = 1$, $\\rho = 0.0$, no enforced collinearity, $m = 5000$.\n- Case $3$ (edge, perfect collinearity): $n = 100$, $p = 4$, $\\rho = 0.5$, enforce $X_{\\cdot, 4} \\leftarrow X_{\\cdot, 1} + X_{\\cdot, 2}$, $m = 5000$.\n- Case $4$ (highly correlated many features): $n = 80$, $p = 10$, $\\rho = 0.99$, no enforced collinearity, $m = 5000$.\n\nAcceptance thresholds:\n- Quantile relative deviation tolerance: a test passes if the maximum over $q \\in \\{0.25, 0.5, 0.75, 0.9\\}$ of $\\left|\\widehat{Q}(q) - Q_{F}(q; r, n - r)\\right| / Q_{F}(q; r, n - r)$ is less than $0.07$, where $\\widehat{Q}(q)$ is the empirical quantile and $Q_{F}(q; r, n - r)$ is the theoretical central $F$ quantile.\n- KS statistic threshold: a test passes if the KS statistic comparing $\\{p^{(k)}\\}$ to Uniform$(0,1)$ does not exceed $0.035$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$result_{1},result_{2},result_{3},result_{4}$]\"), where $result_{i}$ is $true$ or $false$ for Case $i$ in the order presented above. All booleans must be in lowercase.\n\nNo external input is allowed, and the random number generator seed must be fixed inside your program to ensure reproducibility. All answers are dimensionless real numbers or booleans, so no physical unit specification is required. The entire computation must be done conditionally on the fixed $X$ per test case, i.e., do not resample $X$ within a test case once constructed.", "solution": "The problem requires a numerical verification of a fundamental result in linear models theory: under the null hypothesis $H_{0}: \\beta = 0$, the omnibus $F$-statistic follows a central $F$-distribution, with degrees of freedom determined by the rank of the design matrix $X$. This property remains true even when the columns of $X$ are correlated or linearly dependent. The verification will be conducted by simulating data under various scenarios and comparing the empirical distribution of the calculated $F$-statistic to its theoretical counterpart.\n\nThe theoretical foundation for this result rests on the properties of projections and quadratic forms of Gaussian random vectors, often summarized by Cochran's Theorem. In the normal linear model $y = X \\beta + \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$, the null hypothesis $H_0: \\beta=0$ implies $y = \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$. For simplicity and without loss of generality (as the $F$-statistic is invariant to $\\sigma^2$), we set $\\sigma^2=1$, so $y \\sim \\mathcal{N}(0, I_n)$.\n\nThe total sum of squares, $\\|y\\|^2$, can be orthogonally decomposed into the sum of squares due to regression (SSR) and the sum of squares due to error (SSE). This decomposition is achieved using the projection matrix $P_X$ onto the column space of $X$, denoted $\\operatorname{col}(X)$, and its orthogonal complement, $P_{X^\\perp} = I_n - P_X$.\nThe regression sum of squares is the squared norm of the projection of $y$ onto $\\operatorname{col}(X)$:\n$$ \\operatorname{SSR} = \\|P_X y\\|^2 = y^\\top P_X y $$\nThe residual sum of squares is the squared norm of the projection of $y$ onto the orthogonal complement of $\\operatorname{col}(X)$:\n$$ \\operatorname{SSE} = \\|P_{X^\\perp} y\\|^2 = y^\\top P_{X^\\perp} y = \\|y\\|^2 - \\operatorname{SSR} $$\nAccording to Cochran's theorem, since $y \\sim \\mathcal{N}(0, I_n)$, the quadratic forms $\\operatorname{SSR}$ and $\\operatorname{SSE}$ are independent and follow chi-squared distributions. The degrees of freedom for each are determined by the rank of their respective projection matrices:\n$$ \\operatorname{SSR} \\sim \\chi^2_{r} \\quad \\text{where} \\quad r = \\operatorname{rank}(P_X) = \\operatorname{rank}(X) $$\n$$ \\operatorname{SSE} \\sim \\chi^2_{n-r} \\quad \\text{where} \\quad n-r = \\operatorname{rank}(P_{X^\\perp}) $$\nThe omnibus $F$-statistic is defined as the ratio of the mean square for regression to the mean square for error:\n$$ F = \\frac{\\operatorname{SSR} / r}{\\operatorname{SSE} / (n-r)} $$\nBy definition, a random variable formed by the ratio of two independent chi-squared variables, each divided by its degrees of freedom, follows an $F$-distribution. Therefore, the statistic $F$ follows a central $F$-distribution with $(r, n-r)$ degrees of freedom, denoted $F(r, n-r)$. It is critical to note that the numerator degrees of freedom is $r=\\operatorname{rank}(X)$, not necessarily the number of columns $p$. This is key to handling rank-deficient design matrices.\n\nThe numerical implementation proceeds as follows:\n$1$. **Design Matrix Construction**: For each test case, we first construct the fixed $n \\times p$ design matrix $X$. We generate $n$ independent rows, each from a $p$-variate normal distribution $\\mathcal{N}(0, \\Sigma)$, where $\\Sigma$ is an equicorrelation matrix with $\\Sigma_{ii}=1$ and $\\Sigma_{ij}=\\rho$ for $i \\neq j$. This is achieved by generating standard normal variates and transforming them using the Cholesky decomposition of $\\Sigma$. For cases requiring perfect collinearity, a specific column is replaced by a linear combination of others.\n\n$2$. **Rank and Basis Computation**: The crucial step for handling correlated and rank-deficient designs is the accurate determination of the rank $r$ of $X$ and a corresponding orthonormal basis for its column space. The Singular Value Decomposition (SVD) of $X = U S V^\\top$ provides a numerically stable way to do this. The number of singular values significantly greater than zero gives the numerical rank $r$. The first $r$ columns of the matrix $U$ form an orthonormal basis $Q \\in \\mathbb{R}^{n \\times r}$ for $\\operatorname{col}(X)$.\n\n$3$. **F-Statistic Simulation**: Conditional on the fixed matrix $X$, we simulate $m=5000$ independent realizations of the response vector $y^{(k)}$ under $H_0$. With $\\sigma^2=1$, each $y^{(k)}$ is a draw from $\\mathcal{N}(0, I_n)$. For each $y^{(k)}$, we compute the $F$-statistic. The projection matrix $P_X$ can be written as $P_X = QQ^\\top$. The regression sum of squares is then calculated efficiently as $\\operatorname{SSR}^{(k)} = \\|Q^\\top y^{(k)}\\|^2$. The residual sum of squares is $\\operatorname{SSE}^{(k)} = \\|y^{(k)}\\|^2 - \\operatorname{SSR}^{(k)}$. Finally, the statistic is $F^{(k)} = \\left(\\operatorname{SSR}^{(k)}/r\\right) / \\left(\\operatorname{SSE}^{(k)}/(n-r)\\right)$.\n\n$4$. **Distribution Validation**:\n- **Quantile Agreement**: We compute the empirical quantiles of the $m=5000$ simulated $F$-statistics at probabilities $q \\in \\{0.25, 0.5, 0.75, 0.9\\}$. These are compared to the theoretical quantiles of the $F(r, n-r)$ distribution. The test passes if the maximum relative deviation is below the tolerance of $0.07$.\n- **Kolmogorov-Smirnov (KS) Test**: We transform each simulated statistic $F^{(k)}$ into a $p$-value, $p^{(k)} = P(F_{r, n-r} \\ge F^{(k)})$, using the survival function of the theoretical $F$-distribution. If the original statistics truly follow the $F(r, n-r)$ distribution, the resulting $p$-values should be uniformly distributed on $(0, 1)$. We test this hypothesis using the KS test. The test passes if the KS statistic is below the threshold of $0.035$.\n\nA test case is considered successful (returning `true`) only if both validation checks pass, confirming the theoretical result with high numerical confidence. The program iterates through all specified test cases, including those with high correlation and perfect collinearity, to demonstrate the robustness of the theory. A fixed random seed ensures the reproducibility of the entire simulation study.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import f, kstest\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for verifying the F-statistic distribution\n    in a normal linear model and print the results.\n    \"\"\"\n    # Define global parameters for the simulation study\n    M_SIMS = 5000\n    QUANTILE_LEVELS = [0.25, 0.5, 0.75, 0.9]\n    QUANTILE_TOL = 0.07\n    KS_TOL = 0.035\n    SEED = 42\n\n    # Initialize a random number generator for reproducibility\n    rng = np.random.default_rng(SEED)\n\n    # Define the suite of test cases\n    test_cases = [\n        # Case 1: Correlated full rank design\n        {'n': 200, 'p': 5, 'rho': 0.8, 'enforce_collinearity': False, 'label': 'Case 1'},\n        # Case 2: p=1, where F is equivalent to a squared t-statistic\n        {'n': 50, 'p': 1, 'rho': 0.0, 'enforce_collinearity': False, 'label': 'Case 2'},\n        # Case 3: Perfect collinearity (rank-deficient design)\n        {'n': 100, 'p': 4, 'rho': 0.5, 'enforce_collinearity': True, 'label': 'Case 3'},\n        # Case 4: Highly correlated design, potentially numerically rank-deficient\n        {'n': 80, 'p': 10, 'rho': 0.99, 'enforce_collinearity': False, 'label': 'Case 4'},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(\n            n=case['n'],\n            p=case['p'],\n            rho=case['rho'],\n            enforce_collinearity=case['enforce_collinearity'],\n            m_sims=M_SIMS,\n            quantile_levels=QUANTILE_LEVELS,\n            quantile_tol=QUANTILE_TOL,\n            ks_tol=KS_TOL,\n            rng=rng\n        )\n        results.append(str(result).lower())\n    \n    # Print the final results in the required format\n    print(f\"[{','.join(results)}]\")\n\ndef run_test_case(n, p, rho, enforce_collinearity, m_sims, quantile_levels, quantile_tol, ks_tol, rng):\n    \"\"\"\n    Executes a single simulation scenario to validate the F-statistic's distribution.\n\n    Args:\n        n (int): Number of observations.\n        p (int): Number of features.\n        rho (float): Equicorrelation coefficient for features.\n        enforce_collinearity (bool): Flag to enforce linear dependence.\n        m_sims (int): Number of simulation replications.\n        quantile_levels (list): Probabilities for quantile comparison.\n        quantile_tol (float): Tolerance for relative deviation of quantiles.\n        ks_tol (float): Threshold for the Kolmogorov-Smirnov statistic.\n        rng (np.random.Generator): NumPy random number generator instance.\n\n    Returns:\n        bool: True if both validation checks pass, False otherwise.\n    \"\"\"\n    # Step 1: Construct the design matrix X\n    mean = np.zeros(p)\n    if p == 1:\n        cov_matrix = np.array([[1.0]])\n    else:\n        cov_matrix = np.full((p, p), rho)\n        np.fill_diagonal(cov_matrix, 1.0)\n    \n    # Generate X with rows drawn from N(0, cov_matrix)\n    X = rng.multivariate_normal(mean, cov_matrix, size=n)\n\n    if enforce_collinearity:\n        if p >= 3:\n            # Replace the last column with a linear combination of the first two\n            X[:, p-1] = X[:, 0] + X[:, 1]\n        else:\n            # Cannot enforce this type of collinearity if p < 3\n            return False\n\n    # Step 2: Determine rank and orthonormal basis Q for Col(X)\n    r = np.linalg.matrix_rank(X)\n    \n    if r == 0:\n        return False # Zero matrix has no well-defined F-test\n    if n - r <= 0:\n        # F-statistic is not well-defined if residual degrees of freedom is not positive\n        return False \n        \n    # SVD is a robust method to find an orthonormal basis for the column space\n    U, _, _ = np.linalg.svd(X, full_matrices=False)\n    Q = U[:, :r]\n\n    # Step 3: Simulate m realizations of y and compute F-statistics\n    # Under H0: y = epsilon ~ N(0, I_n)\n    y_realizations = rng.standard_normal(size=(n, m_sims))\n    \n    # SSR = ||Q'y||^2\n    projected_y = Q.T @ y_realizations\n    ssr = np.sum(np.square(projected_y), axis=0)\n    \n    # SSE = ||y||^2 - SSR\n    y_sq_norm = np.sum(np.square(y_realizations), axis=0)\n    sse = y_sq_norm - ssr\n    \n    # F = (SSR/r) / (SSE/(n-r))\n    f_stats = (ssr / r) / (sse / (n - r))\n    \n    # Step 4: Validate the empirical distribution against the theoretical F-distribution\n    \n    # 4a: Quantile agreement check\n    empirical_quantiles = np.quantile(f_stats, quantile_levels)\n    theoretical_quantiles = f.ppf(quantile_levels, dfn=r, dfd=n-r)\n    \n    # Avoid division by zero, though F quantiles for q>0 are positive\n    if np.any(theoretical_quantiles <= 1e-9):\n        quantile_check_passed = False\n    else:\n        relative_deviations = np.abs(empirical_quantiles - theoretical_quantiles) / theoretical_quantiles\n        max_rel_dev = np.max(relative_deviations)\n        quantile_check_passed = max_rel_dev < quantile_tol\n\n    # 4b: Uniform p-values check using the KS test\n    # p-values are computed using the survival function (1 - CDF) for better precision\n    p_values = f.sf(f_stats, dfn=r, dfd=n-r)\n    ks_statistic, _ = kstest(p_values, 'uniform')\n    ks_check_passed = ks_statistic <= ks_tol\n\n    return quantile_check_passed and ks_check_passed\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3172367"}, {"introduction": "The era of big data brings new statistical challenges, one of the most prominent being multiple hypothesis testing. When screening thousands of features, as is common in fields like genomics or finance, how do we avoid being drowned in false positives? This exercise uses the familiar one-sample $t$-statistic as a building block to explore the distribution of extreme values in high-dimensional settings. You will derive the widely-used Bonferroni correction and use simulation to investigate the behavior of the maximum absolute $t$-statistic, providing a concrete introduction to the critical task of controlling the family-wise error rate. [@problem_id:3172330]", "problem": "You are asked to design and implement a simulation-based study of multiple testing under a high-dimensional null model, focusing on the sampling distribution of Student’s $t$-statistics, the distribution of their maximum absolute value across many independent features, and a Bonferroni correction for Family-Wise Error Rate (FWER) control.\n\nFundamental base you may assume:\n- Under a mean-zero Normal model with unknown variance, the one-sample Student’s $t$ statistic for a single feature, computed as $T = \\frac{\\bar{X}}{S / \\sqrt{n}}$ where $X_1,\\dots,X_n$ are independent and identically distributed with a Normal distribution and $S$ is the sample standard deviation, follows a Student’s $t$ distribution with degrees of freedom $\\nu = n - 1$ under the null hypothesis that the true mean is $0$.\n- The Bonferroni inequality states that for events $A_1,\\dots,A_p$, $\\Pr\\left(\\bigcup_{j=1}^{p} A_j\\right) \\le \\sum_{j=1}^{p} \\Pr(A_j)$.\n- Independence across features: assume $p$ features are independent under the global null.\n\nScenario and tasks:\n- Consider $p$ independent features, each under the null hypothesis with data sampled from a mean-zero Normal distribution with unknown variance; for each feature, the two-sided test statistic $T_j$ is the Student’s $t$ statistic with degrees of freedom $\\nu = n - 1$.\n- Define the maximum absolute statistic across features as $M = \\max_{1 \\le j \\le p} |T_j|$.\n- Your tasks are:\n  1. Analytically derive a threshold $c_B$ using the Bonferroni inequality that ensures the Family-Wise Error Rate (FWER) for $p$ two-sided tests at level $\\alpha$ is at most $\\alpha$. Express $c_B$ in terms of the inverse cumulative distribution function of the Student’s $t$ distribution with $\\nu = n - 1$ degrees of freedom and do not use any shortcut formulas beyond the stated fundamental base.\n  2. Implement a simulation that, for each test case, repeatedly samples $p$ independent $T_j$ values from the Student’s $t$ distribution with $\\nu = n - 1$ degrees of freedom to approximate the distribution of $M$ under the global null. Use a fixed pseudorandom number generator seed $123456$ for reproducibility.\n  3. For each test case, compute:\n     - The Bonferroni threshold $c_B$ derived in step $1$.\n     - The empirical FWER at $c_B$, defined as the fraction (as a decimal) of simulation replicates in which at least one $|T_j|$ exceeds $c_B$.\n     - The empirical mean of $M$ across simulation replicates.\n\nSimulation details to implement:\n- For each replicate, generate $p$ independent draws from the Student’s $t$ distribution with $\\nu = n - 1$ degrees of freedom to represent the $p$ null $t$ statistics, take absolute values, and record the maximum.\n- Repeat for $R$ replicates.\n- Compute the empirical FWER as the proportion of replicates where the maximum absolute statistic exceeds $c_B$.\n- Compute the empirical mean of the maximum absolute statistic across replicates.\n\nTest suite:\n- Use the following three test cases, each specified as $(n, p, \\alpha, R)$:\n  1. $(20, 50, 0.05, 40000)$ as a general case with moderate $p$ and common significance level.\n  2. $(20, 1, 0.05, 100000)$ as a boundary case with a single test, where the Bonferroni threshold should coincide with the usual two-sided threshold.\n  3. $(5, 200, 0.01, 20000)$ as a heavy-tailed case with small sample size (small degrees of freedom) and many features at a stringent significance level.\n\nOutput requirements:\n- For each test case, output a list $[c_B, \\text{empirical\\_FWER}, \\text{mean\\_max}]$ of three real numbers rounded to $6$ decimal places, where all three values are decimals (no percentage symbols).\n- Aggregate the results of all test cases into a single list of these triplets, printed on one line as a comma-separated list enclosed in square brackets, with no extra text. For example, an output with two test cases would look like $[[x_{11},x_{12},x_{13}],[x_{21},x_{22},x_{23}]]$ with each $x_{ij}$ a real number formatted to $6$ decimal places.\n\nAngle units and physical units:\n- There are no angle or physical units involved in this problem.\n\nYour program must:\n- Be a complete, runnable program that requires no user input and does not access external files or the network.\n- Use the specified pseudorandom seed $123456$.\n- Produce exactly one line of output in the specified format.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- **Model:** For each of $p$ independent features, data are sampled from a mean-zero Normal distribution with unknown variance.\n- **Test Statistic:** The one-sample Student's $t$-statistic for feature $j$ is $T_j$. Under the null hypothesis, $T_j \\sim t_{\\nu}$ where $\\nu = n - 1$.\n- **Global Null:** All $p$ features are under the null hypothesis. Features are assumed to be independent.\n- **Statistic of Interest:** The maximum absolute statistic across features is $M = \\max_{1 \\le j \\le p} |T_j|$.\n- **Bonferroni Inequality:** $\\Pr\\left(\\bigcup_{j=1}^{p} A_j\\right) \\le \\sum_{j=1}^{p} \\Pr(A_j)$.\n- **Task 1 (Analysis):** Derive a threshold $c_B$ using the Bonferroni inequality to ensure Family-Wise Error Rate (FWER) $\\le \\alpha$ for $p$ two-sided tests. The expression must be in terms of the inverse CDF of the Student's $t$-distribution.\n- **Task 2 (Simulation):** Implement a simulation to approximate the distribution of $M$ by sampling $p$ independent values from $t_{n-1}$ for each replicate. A fixed seed of $123456$ must be used.\n- **Task 3 (Computation):** From the simulation, compute the Bonferroni threshold $c_B$, the empirical FWER at $c_B$, and the empirical mean of $M$.\n- **Simulation Parameters:** $R$ replicates.\n- **Test Cases $(n, p, \\alpha, R)$:**\n  1. $(20, 50, 0.05, 40000)$\n  2. $(20, 1, 0.05, 100000)$\n  3. $(5, 200, 0.01, 20000)$\n- **Output Format:** For each test case, a list $[c_B, \\text{empirical\\_FWER}, \\text{mean\\_max}]$ with values rounded to $6$ decimal places. The final output is an aggregated list of these lists.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the established statistical theory of hypothesis testing, specifically multiple comparisons. It leverages standard concepts such as the Student's $t$-distribution, the Bonferroni correction, Family-Wise Error Rate (FWER), and Monte Carlo simulation. The problem is well-posed, providing a clear objective, all necessary parameters ($n, p, \\alpha, R$), and explicit definitions. The tasks are unambiguous and lead to a unique analytical derivation and a reproducible numerical outcome (given the fixed seed). The problem is objective and free of any scientific or factual unsoundness, incompleteness, or contradictions. It is a standard, non-trivial exercise in computational statistics.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\n**Methodology**\n\n**1. Analytical Derivation of the Bonferroni Threshold ($c_B$)**\n\nThe Family-Wise Error Rate (FWER) is the probability of making at least one Type I error among all $p$ tests, assuming the global null hypothesis (i.e., all individual null hypotheses are true) is correct. A Type I error for the $j$-th feature test occurs if we reject the null hypothesis $H_{0j}$ when it is true. For a two-sided test based on the statistic $T_j$, we reject $H_{0j}$ if its absolute value exceeds a critical threshold, $|T_j| > c$.\n\nThe FWER is thus defined as:\n$$\n\\text{FWER} = \\Pr\\left( \\bigcup_{j=1}^{p} \\{|T_j| > c\\} \\right)\n$$\nWe seek a threshold, which we will call $c_B$, such that the FWER is controlled at level $\\alpha$, i.e., FWER $\\le \\alpha$.\n\nApplying the Bonferroni inequality to the union of events:\n$$\n\\text{FWER} = \\Pr\\left( \\bigcup_{j=1}^{p} \\{|T_j| > c_B\\} \\right) \\le \\sum_{j=1}^{p} \\Pr(|T_j| > c_B)\n$$\nUnder the global null hypothesis, each statistic $T_j$ is an independent draw from a Student's $t$-distribution with $\\nu = n-1$ degrees of freedom. As the distributions are identical for all $j=1,\\dots,p$, the probabilities $\\Pr(|T_j| > c_B)$ are all equal. Therefore, the sum simplifies to:\n$$\n\\sum_{j=1}^{p} \\Pr(|T_j| > c_B) = p \\cdot \\Pr(|T| > c_B)\n$$\nwhere $T$ is a random variable following the Student's $t$-distribution with $\\nu$ degrees of freedom, $T \\sim t_{\\nu}$.\n\nTo ensure FWER $\\le \\alpha$, we enforce the stricter condition on the Bonferroni upper bound:\n$$\np \\cdot \\Pr(|T| > c_B) = \\alpha\n$$\nThis sets the significance level for each individual test to $\\alpha/p$.\n$$\n\\Pr(|T| > c_B) = \\frac{\\alpha}{p}\n$$\nThe event $|T| > c_B$ corresponds to $T > c_B$ or $T < -c_B$. Due to the symmetry of the Student's $t$-distribution about $0$, $\\Pr(T > c_B) = \\Pr(T < -c_B)$. Thus:\n$$\n\\Pr(|T| > c_B) = 2 \\cdot \\Pr(T > c_B)\n$$\nSubstituting this into the previous equation gives:\n$$\n2 \\cdot \\Pr(T > c_B) = \\frac{\\alpha}{p} \\implies \\Pr(T > c_B) = \\frac{\\alpha}{2p}\n$$\nTo find $c_B$, we can use the cumulative distribution function (CDF) of the $t$-distribution, denoted $F_{t, \\nu}(x) = \\Pr(T \\le x)$. The tail probability is $\\Pr(T > c_B) = 1 - F_{t, \\nu}(c_B)$.\n$$\n1 - F_{t, \\nu}(c_B) = \\frac{\\alpha}{2p} \\implies F_{t, \\nu}(c_B) = 1 - \\frac{\\alpha}{2p}\n$$\nFinally, by applying the inverse CDF (also known as the quantile function or percent-point function), denoted $F_{t, \\nu}^{-1}$, we obtain the expression for the Bonferroni threshold $c_B$:\n$$\nc_B = F_{t, \\nu}^{-1}\\left(1 - \\frac{\\alpha}{2p}\\right)\n$$\nThis is the analytical formula used for the computation of $c_B$.\n\n**2. Simulation and Computation of Metrics**\n\nA Monte Carlo simulation is implemented to study the distribution of the maximum absolute statistic $M = \\max_{j} |T_j|$ and to evaluate the performance of the Bonferroni correction. The procedure for each test case $(n, p, \\alpha, R)$ is as follows:\n\n1.  **Initialization**: A pseudorandom number generator is seeded with $123456$ to ensure reproducibility. The degrees of freedom are calculated as $\\nu = n-1$.\n\n2.  **Generate Test Statistics**: A matrix of size $R \\times p$ is generated, where each entry is an independent draw from the Student's $t$-distribution with $\\nu$ degrees of freedom. This matrix represents $R$ replicates of $p$ null $t$-statistics.\n    $$\n    \\mathbf{T} = \\begin{pmatrix} T_{11} & \\dots & T_{1p} \\\\ \\vdots & \\ddots & \\vdots \\\\ T_{R1} & \\dots & T_{Rp} \\end{pmatrix}, \\quad T_{ij} \\sim t_{\\nu} \\text{ i.i.d.}\n    $$\n\n3.  **Compute Maximum Absolute Statistics**: For each of the $R$ replicates (rows of the matrix), the maximum of the absolute values of the $p$ statistics is computed. This yields a vector of $R$ values for $M$.\n    $$\n    M_i = \\max_{1 \\le j \\le p} |T_{ij}|, \\quad \\text{for } i=1, \\dots, R\n    $$\n\n4.  **Calculate Empirical FWER**: The analytically derived Bonferroni threshold $c_B$ is computed. The empirical FWER is the fraction of simulation replicates in which the maximum absolute statistic $M_i$ exceeds this threshold. This is a Monte Carlo estimate of $\\Pr(M > c_B)$.\n    $$\n    \\text{empirical\\_FWER} = \\frac{1}{R} \\sum_{i=1}^{R} \\mathbf{1}(M_i > c_B)\n    $$\n    where $\\mathbf{1}(\\cdot)$ is the indicator function.\n\n5.  **Calculate Empirical Mean of M**: The empirical mean of the maximum absolute statistic is the arithmetic average of the $R$ observed values of $M_i$.\n    $$\n    \\text{mean\\_max} = \\frac{1}{R} \\sum_{i=1}^{R} M_i\n    $$\nThese three quantities—$c_B$, empirical FWER, and mean of $M$—are computed for each test case and reported as specified. The case with $p=1$ serves as a verification, where the Bonferroni correction is inactive, and the empirical FWER should closely approximate the nominal level $\\alpha$. The case with small $n$ and large $p$ demonstrates the behavior under heavy-tailed distributions and a high-dimensional multiple testing burden.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Performs a simulation study on multiple testing with Bonferroni correction.\n\n    For each test case, the function:\n    1. Analytically calculates the Bonferroni-corrected critical value (c_B).\n    2. Simulates the distribution of the maximum absolute t-statistic under the global null.\n    3. Computes the empirical Family-Wise Error Rate (FWER) at the c_B threshold.\n    4. Computes the empirical mean of the maximum absolute t-statistic.\n    \"\"\"\n    # Test suite: each entry is a tuple of (n, p, alpha, R)\n    # n: sample size\n    # p: number of features (tests)\n    # alpha: target FWER\n    # R: number of simulation replicates\n    test_cases = [\n        (20, 50, 0.05, 40000),      # General case\n        (20, 1, 0.05, 100000),      # Boundary case (single test)\n        (5, 200, 0.01, 20000),       # Heavy-tailed case\n    ]\n\n    # Seed the random number generator for reproducibility.\n    # Using default_rng is the modern, recommended practice.\n    rng = np.random.default_rng(123456)\n\n    results = []\n    \n    for n, p, alpha, R in test_cases:\n        # Degrees of freedom for the Student's t-distribution\n        df = n - 1\n\n        # 1. Analytically derive the Bonferroni threshold c_B\n        # The Bonferroni-corrected significance level for each of p two-sided tests\n        # is alpha / p. For a two-sided test, this probability mass is split\n        # into two tails, so the upper tail probability is (alpha / p) / 2.\n        # The quantile corresponds to a cumulative probability of 1 - (alpha / (2*p)).\n        bonferroni_p_value_per_tail = alpha / (2 * p)\n        c_b = t.ppf(1 - bonferroni_p_value_per_tail, df=df)\n\n        # 2. Simulate the distribution of M = max |T_j|\n        # Generate R replicates of p independent t-statistics\n        # The size is (R, p) for R rows (replicates) and p columns (features).\n        t_statistics = rng.standard_t(df, size=(R, p))\n\n        # Take the absolute value of all generated statistics\n        abs_t_statistics = np.abs(t_statistics)\n\n        # For each replicate, find the maximum absolute value across the p features\n        # axis=1 computes the max along each row.\n        max_abs_t = np.max(abs_t_statistics, axis=1)\n\n        # 3. Compute empirical FWER and the mean of the maximum statistic\n        # The empirical FWER is the proportion of replicates where the maximum\n        # absolute statistic exceeds the Bonferroni threshold.\n        # np.mean of a boolean array correctly computes the proportion of True values.\n        empirical_fwer = np.mean(max_abs_t > c_b)\n\n        # The empirical mean of M is the average of the observed maximums.\n        mean_max = np.mean(max_abs_t)\n\n        # Store the results for the current test case.\n        results.append([c_b, empirical_fwer, mean_max])\n\n    # Format the final output string as specified in the problem statement.\n    # E.g., [[val1,val2,val3],[val4,val5,val6]]\n    # Each value is formatted to 6 decimal places.\n    inner_results_str = [\n        f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\" for res in results\n    ]\n    final_output_str = f\"[{','.join(inner_results_str)}]\"\n\n    print(final_output_str)\n\nsolve()\n\n```", "id": "3172330"}]}