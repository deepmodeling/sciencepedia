{"hands_on_practices": [{"introduction": "The Bayes classifier represents the gold standard in statistical decision theory, providing the optimal decision rule that minimizes the probability of error. This exercise [@problem_id:3166549] guides you through deriving this ideal classifier for a common scenario with Gaussian data. In doing so, you will see how the concept of a minimal sufficient statistic allows us to distill all the relevant information from an observation into a single value, simplifying a complex decision into a straightforward threshold comparison.", "problem": "Consider binary classification with class label $Y \\in \\{0,1\\}$ and observation $X \\in \\mathbb{R}$. The class priors are $\\pi_{0} = \\mathbb{P}(Y=0)$ and $\\pi_{1} = \\mathbb{P}(Y=1)$ with $\\pi_{0} + \\pi_{1} = 1$. Assume the class-conditional densities belong to a one-parameter natural exponential family indexed by the mean, with a common known variance. Concretely, suppose that\n$$\nX \\mid Y=y \\sim \\mathcal{N}(\\mu_{y}, \\sigma^{2})\n$$\nfor parameters $\\mu_{0}, \\mu_{1} \\in \\mathbb{R}$ and a known $\\sigma^{2} > 0$. You will analyze sufficiency and derive the Bayes-optimal decision in terms of a sufficient statistic.\n\nUsing only fundamental definitions from probability and statistical decision theory (for example, the factorization theorem for sufficiency and the definition of the Bayes classifier as the decision that maximizes the posterior probability), do the following:\n\n1. Show that this family of densities can be written in the natural exponential family form, identify a sufficient statistic $T(X)$ for $\\mu$, and explain why $T(X)$ is minimal sufficient under standard regularity conditions for this one-parameter family.\n\n2. Determine the distribution of $T(X)$ under each class $Y=y$.\n\n3. Derive the Bayes-optimal decision rule under zero-one loss by comparing posterior probabilities, and show that it depends on $X$ only through the sufficient statistic $T(X)$.\n\n4. Specialize to the following numerically specified case: $\\mu_{0} = 0$, $\\mu_{1} = 3$, $\\sigma^{2} = 1$, $\\pi_{0} = \\frac{13}{20}$, $\\pi_{1} = \\frac{7}{20}$. For this case, compute the Bayes-optimal threshold $t^{\\ast}$ such that the decision rule is to predict $Y=1$ if and only if $T(X) > t^{\\ast}$, and otherwise predict $Y=0$. Express the final threshold as a single closed-form analytic expression. Do not round.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is rooted in the fundamental principles of statistical decision theory and consists of a sequence of logically connected tasks for which a unique, meaningful solution can be derived from the provided information. Therefore, the problem is valid and I will proceed with a full solution.\n\nThe solution is presented in four parts, corresponding to the four tasks in the problem description.\n\n**Part 1: Exponential Family Form and Minimal Sufficiency**\n\nWe are given that the class-conditional density of the observation $X \\in \\mathbb{R}$ is Gaussian: $X \\mid Y=y \\sim \\mathcal{N}(\\mu_{y}, \\sigma^{2})$. Let us consider a single such density with parameter $\\mu$ and known variance $\\sigma^2 > 0$. The probability density function (PDF) is\n$$\nf(x; \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)\n$$\nTo demonstrate that this belongs to a one-parameter natural exponential family, we must write it in the canonical form $f(x; \\eta) = h(x) \\exp(\\eta T(x) - A(\\eta))$. We expand the term in the exponent:\n$$\n-\\frac{(x-\\mu)^2}{2\\sigma^2} = -\\frac{x^2 - 2x\\mu + \\mu^2}{2\\sigma^2} = \\frac{\\mu}{\\sigma^2}x - \\frac{\\mu^2}{2\\sigma^2} - \\frac{x^2}{2\\sigma^2}\n$$\nSubstituting this back into the PDF expression, we can rearrange the terms as follows:\n$$\nf(x; \\mu) = \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\right] \\exp\\left( \\left(\\frac{\\mu}{\\sigma^2}\\right)x - \\frac{\\mu^2}{2\\sigma^2} \\right)\n$$\nThis expression matches the natural exponential family form. By comparing terms, we identify:\n- The sufficient statistic: $T(x) = x$.\n- The natural parameter: $\\eta = \\eta(\\mu) = \\frac{\\mu}{\\sigma^2}$.\n- The base measure: $h(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$.\n- The log-partition function (cumulant-generating function): $A(\\eta) = \\frac{\\mu^2}{2\\sigma^2}$. To express this as a function of $\\eta$, we invert the relationship for the natural parameter: $\\mu = \\eta\\sigma^2$. Substituting this gives $A(\\eta) = \\frac{(\\eta\\sigma^2)^2}{2\\sigma^2} = \\frac{\\eta^2 \\sigma^4}{2\\sigma^2} = \\frac{1}{2}\\eta^2\\sigma^2$.\n\nThus, a sufficient statistic for the parameter $\\mu$ is $T(X) = X$.\n\nRegarding minimal sufficiency, a standard result for one-parameter natural exponential families states that if the natural parameter space $\\mathcal{H} = \\{\\eta(\\mu) \\mid \\mu \\in \\mathbb{R}\\}$ contains an open interval, then the corresponding statistic $T(X)$ is minimal sufficient. In this case, the original parameter $\\mu$ belongs to $\\mathbb{R}$. Since $\\sigma^2$ is a fixed positive constant, the natural parameter $\\eta = \\mu/\\sigma^2$ also spans the entire real line, $\\mathcal{H} = \\mathbb{R}$. As $\\mathbb{R}$ is an open set, the regularity conditions are met, and we conclude that $T(X) = X$ is a minimal sufficient statistic for $\\mu$.\n\n**Part 2: Distribution of the Sufficient Statistic**\n\nAs established in Part 1, a sufficient statistic for $\\mu$ is $T(X) = X$. The problem asks for the distribution of $T(X)$ conditional on the class label $Y=y$. This is, by definition, the distribution of $X$ conditional on $Y=y$.\nThe problem statement provides these distributions directly:\n$$\nX \\mid Y=y \\sim \\mathcal{N}(\\mu_{y}, \\sigma^{2})\n$$\nTherefore, the distribution of the sufficient statistic $T(X)$ is:\n- For class $Y=0$: $T(X) \\mid (Y=0) \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$\n- For class $Y=1$: $T(X) \\mid (Y=1) \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$\n\n**Part 3: Derivation of the Bayes-Optimal Decision Rule**\n\nFor a binary classification problem with zero-one loss, the Bayes-optimal decision rule seeks to minimize the probability of misclassification. This is equivalent to assigning an observation $x$ to the class with the maximum posterior probability. The decision rule is to predict $Y=1$ if and only if:\n$$\n\\mathbb{P}(Y=1 \\mid X=x) > \\mathbb{P}(Y=0 \\mid X=x)\n$$\nUsing Bayes' theorem, $\\mathbb{P}(Y=y \\mid X=x) = \\frac{p(x \\mid Y=y)\\mathbb{P}(Y=y)}{p(x)}$, where $p(x \\mid Y=y)$ is the class-conditional density and $\\mathbb{P}(Y=y) = \\pi_y$ is the class prior. The inequality becomes:\n$$\n\\frac{p(x \\mid Y=1)\\pi_{1}}{p(x)} > \\frac{p(x \\mid Y=0)\\pi_{0}}{p(x)}\n$$\nSince $p(x) > 0$, we can simplify this to a comparison involving the likelihoods and priors:\n$$\np(x \\mid Y=1)\\pi_{1} > p(x \\mid Y=0)\\pi_{0}\n$$\nBy the definition of sufficiency via the Factorization Theorem, any likelihood ratio $\\frac{p(x|\\theta_1)}{p(x|\\theta_0)}$ depends on the data $x$ only through a sufficient statistic $T(x)$. Here, the relevant parameters are $\\mu_1$ and $\\mu_0$. Hence, the decision rule must be a function of $T(X)=X$.\n\nTo derive the explicit form of the rule, we take the natural logarithm of both sides (a strictly increasing function):\n$$\n\\ln(p(x \\mid Y=1)) + \\ln(\\pi_{1}) > \\ln(p(x \\mid Y=0)) + \\ln(\\pi_{0})\n$$\nThe log-density for a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is $\\ln(p(x; \\mu)) = -\\frac{(x-\\mu)^2}{2\\sigma^2} - \\frac{1}{2}\\ln(2\\pi\\sigma^2)$. Substituting this into the inequality:\n$$\n-\\frac{(x-\\mu_{1})^2}{2\\sigma^2} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) + \\ln(\\pi_{1}) > -\\frac{(x-\\mu_{0})^2}{2\\sigma^2} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) + \\ln(\\pi_{0})\n$$\nThe term $-\\frac{1}{2}\\ln(2\\pi\\sigma^2)$ cancels. Rearranging terms, we get:\n$$\n\\ln\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right) > \\frac{(x-\\mu_{1})^2 - (x-\\mu_{0})^2}{2\\sigma^2}\n$$\nMultiplying by $2\\sigma^2$ and expanding the squares in the numerator:\n$$\n2\\sigma^2 \\ln\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right) > (x^2 - 2x\\mu_{1} + \\mu_{1}^2) - (x^2 - 2x\\mu_{0} + \\mu_{0}^2)\n$$\n$$\n2\\sigma^2 \\ln\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right) > -2x\\mu_{1} + 2x\\mu_{0} + \\mu_{1}^2 - \\mu_{0}^2\n$$\nWe isolate the terms containing $x$:\n$$\n2x(\\mu_{1} - \\mu_{0}) > \\mu_{1}^2 - \\mu_{0}^2 - 2\\sigma^2 \\ln\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right) = \\mu_{1}^2 - \\mu_{0}^2 + 2\\sigma^2 \\ln\\left(\\frac{\\pi_{0}}{\\pi_{1}}\\right)\n$$\nAssuming $\\mu_{1} \\neq \\mu_{0}$, we can divide by $2(\\mu_{1} - \\mu_{0})$. If $\\mu_{1} > \\mu_{0}$, the inequality direction is preserved:\n$$\nx > \\frac{\\mu_{1}^2 - \\mu_{0}^2}{2(\\mu_{1} - \\mu_{0})} + \\frac{2\\sigma^2}{2(\\mu_{1} - \\mu_{0})} \\ln\\left(\\frac{\\pi_{0}}{\\pi_{1}}\\right)\n$$\nSimplifying the first term gives:\n$$\nx > \\frac{(\\mu_{1} - \\mu_{0})(\\mu_{1} + \\mu_{0})}{2(\\mu_{1} - \\mu_{0})} + \\frac{\\sigma^2}{\\mu_{1} - \\mu_{0}} \\ln\\left(\\frac{\\pi_{0}}{\\pi_{1}}\\right)\n$$\n$$\nx > \\frac{\\mu_{0} + \\mu_{1}}{2} + \\frac{\\sigma^2}{\\mu_{1} - \\mu_{0}} \\ln\\left(\\frac{\\pi_{0}}{\\pi_{1}}\\right)\n$$\nThe Bayes-optimal rule is to predict $Y=1$ if and only if $T(X) = X$ exceeds this threshold. This explicitly shows that the decision depends on $X$ only through $T(X)$.\n\n**Part 4: Numerical Calculation of the Threshold**\n\nWe are given the numerical values: $\\mu_{0} = 0$, $\\mu_{1} = 3$, $\\sigma^{2} = 1$, $\\pi_{0} = \\frac{13}{20}$, and $\\pi_{1} = \\frac{7}{20}$. The decision rule is to predict $Y=1$ if $T(X) > t^{\\ast}$, where $t^{\\ast}$ is the threshold derived in Part 3.\n$$\nt^{\\ast} = \\frac{\\mu_{0} + \\mu_{1}}{2} + \\frac{\\sigma^2}{\\mu_{1} - \\mu_{0}}\\ln\\left(\\frac{\\pi_{0}}{\\pi_{1}}\\right)\n$$\nWe substitute the given values into this expression. First, we compute the components:\n- $\\mu_{0} + \\mu_{1} = 0 + 3 = 3$\n- $\\mu_{1} - \\mu_{0} = 3 - 0 = 3$\n- $\\sigma^2 = 1$\n- $\\frac{\\pi_{0}}{\\pi_{1}} = \\frac{13/20}{7/20} = \\frac{13}{7}$\n\nPlugging these into the formula for $t^{\\ast}$:\n$$\nt^{\\ast} = \\frac{3}{2} + \\frac{1}{3}\\ln\\left(\\frac{13}{7}\\right)\n$$\nThis is the final closed-form analytic expression for the Bayes-optimal decision threshold.", "answer": "$$\n\\boxed{\\frac{3}{2} + \\frac{1}{3} \\ln\\left(\\frac{13}{7}\\right)}\n$$", "id": "3166549"}, {"introduction": "In practice, we rarely know the true parameters of our models; instead, we work with estimates derived from data. A critical question then arises: what is the distribution of a quantity that is a *function* of our estimator? This practice [@problem_id:3166562] introduces the Delta Method, a fundamental tool based on Taylor expansion that allows us to approximate this distribution. By working through this problem, you will develop a hands-on understanding of how uncertainty propagates through nonlinear transformations, a key skill for quantifying the confidence in our model's predictions.", "problem": "A learning system observes $n$ independent and identically distributed (i.i.d.) samples $\\{Y_{i}\\}_{i=1}^{n}$ generated by the model $Y_{i} = \\theta + \\varepsilon_{i}$, where $\\theta \\in \\mathbb{R}$ is a fixed but unknown parameter and $\\varepsilon_{i}$ are i.i.d. noise terms with mean $0$ and finite variance. The estimator for $\\theta$ is the sample mean $\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i}$. Consider the nonlinear functional $\\psi(\\theta) = \\ln\\!\\big(1 + \\theta^{4}\\big)$.\n\nStarting from foundational principles—specifically, the definition of variance and the Central Limit Theorem (CLT), which states that $\\sqrt{n}\\,(\\hat{\\theta} - \\theta)$ converges in distribution to a normal random variable with mean $0$ and variance equal to $\\operatorname{Var}(\\varepsilon_{1})$, together with a first-order Taylor expansion—derive the large-sample (asymptotic) distribution of $\\psi(\\hat{\\theta})$ around $\\psi(\\theta)$.\n\nThen, evaluate how this asymptotic distribution depends on the noise distribution under the following two scenarios, keeping $n$ and $\\theta$ fixed:\n- Scenario (i): $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2})$ with $\\sigma^{2} = 1.44$.\n- Scenario (ii): $\\varepsilon_{i} \\sim \\text{Laplace}(0, b)$ with scale $b = 0.80$ (so that $\\operatorname{Var}(\\varepsilon_{1}) = 2 b^{2}$).\n\nTake $n = 200$ and $\\theta = 1.20$. Using the first-order delta method justified by the CLT and Taylor expansion, compute the ratio of the asymptotic variances of $\\psi(\\hat{\\theta})$ in Scenario (ii) to Scenario (i). Round your final answer to five significant figures. No units are required.", "solution": "The problem statement is well-posed, self-contained, and scientifically grounded in the principles of statistical learning and probability theory. We may proceed with the derivation and solution.\n\nThe learning system observes $n$ independent and identically distributed (i.i.d.) samples $\\{Y_{i}\\}_{i=1}^{n}$ from the model $Y_{i} = \\theta + \\varepsilon_{i}$. The parameter $\\theta$ is estimated by the sample mean $\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i}$. The noise terms $\\varepsilon_{i}$ are i.i.d. with $E[\\varepsilon_{i}] = 0$ and a finite variance, which we denote as $V_{\\varepsilon} = \\operatorname{Var}(\\varepsilon_{1})$.\n\nFirst, we establish the properties of the estimator $\\hat{\\theta}$. The expectation of $\\hat{\\theta}$ is:\n$$ E[\\hat{\\theta}] = E\\left[\\frac{1}{n} \\sum_{i=1}^{n} Y_{i}\\right] = \\frac{1}{n} \\sum_{i=1}^{n} E[Y_{i}] = \\frac{1}{n} \\sum_{i=1}^{n} E[\\theta + \\varepsilon_{i}] = \\frac{1}{n} \\sum_{i=1}^{n} (\\theta + 0) = \\frac{1}{n} (n\\theta) = \\theta $$\nThe variance of $\\hat{\\theta}$ is:\n$$ \\operatorname{Var}(\\hat{\\theta}) = \\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} Y_{i}\\right) = \\frac{1}{n^{2}} \\sum_{i=1}^{n} \\operatorname{Var}(Y_{i}) = \\frac{1}{n^{2}} \\sum_{i=1}^{n} \\operatorname{Var}(\\theta + \\varepsilon_{i}) = \\frac{1}{n^{2}} \\sum_{i=1}^{n} \\operatorname{Var}(\\varepsilon_{i}) = \\frac{n V_{\\varepsilon}}{n^{2}} = \\frac{V_{\\varepsilon}}{n} $$\nThe problem states that according to the Central Limit Theorem (CLT), the standardized estimator converges in distribution to a normal distribution:\n$$ \\sqrt{n}(\\hat{\\theta} - \\theta) \\xrightarrow{d} \\mathcal{N}(0, V_{\\varepsilon}) $$\nwhere $\\xrightarrow{d}$ denotes convergence in distribution.\n\nWe are interested in the asymptotic distribution of the nonlinear functional $\\psi(\\hat{\\theta})$, where $\\psi(\\theta) = \\ln(1 + \\theta^{4})$. To find this, we use the Delta Method, which is based on a first-order Taylor expansion of $\\psi(\\hat{\\theta})$ around the true parameter $\\theta$. For $\\hat{\\theta}$ close to $\\theta$, which is true for large $n$, we have:\n$$ \\psi(\\hat{\\theta}) \\approx \\psi(\\theta) + \\psi'(\\theta) (\\hat{\\theta} - \\theta) $$\nwhere $\\psi'(\\theta)$ is the first derivative of $\\psi(\\theta)$ evaluated at $\\theta$. The derivative is:\n$$ \\psi'(\\theta) = \\frac{d}{d\\theta}\\ln(1 + \\theta^{4}) = \\frac{1}{1 + \\theta^{4}} \\cdot \\frac{d}{d\\theta}(1 + \\theta^{4}) = \\frac{4\\theta^{3}}{1 + \\theta^{4}} $$\nRearranging the Taylor expansion, we get:\n$$ \\psi(\\hat{\\theta}) - \\psi(\\theta) \\approx \\psi'(\\theta) (\\hat{\\theta} - \\theta) $$\nTo analyze the asymptotic distribution, we scale the difference by $\\sqrt{n}$:\n$$ \\sqrt{n}(\\psi(\\hat{\\theta}) - \\psi(\\theta)) \\approx \\psi'(\\theta) \\left( \\sqrt{n}(\\hat{\\theta} - \\theta) \\right) $$\nFrom the CLT, we know the asymptotic distribution of the term in the parentheses on the right-hand side. Since $\\psi'(\\theta)$ is a constant for a fixed $\\theta$, we can apply Slutsky's theorem. The asymptotic distribution of $\\sqrt{n}(\\psi(\\hat{\\theta}) - \\psi(\\theta))$ is the distribution of the product of the constant $\\psi'(\\theta)$ and a normal random variable $Z \\sim \\mathcal{N}(0, V_{\\varepsilon})$. If $Z \\sim \\mathcal{N}(0, \\sigma^{2})$, then $cZ \\sim \\mathcal{N}(0, c^{2}\\sigma^{2})$.\nTherefore, the large-sample distribution is:\n$$ \\sqrt{n}(\\psi(\\hat{\\theta}) - \\psi(\\theta)) \\xrightarrow{d} \\mathcal{N}\\left(0, [\\psi'(\\theta)]^{2} V_{\\varepsilon}\\right) $$\nThis result implies that for large $n$, $\\psi(\\hat{\\theta})$ is approximately normally distributed with mean $\\psi(\\theta)$ and variance $\\frac{[\\psi'([\\theta)]^{2} V_{\\varepsilon}}{n}$. This variance is the asymptotic variance of the estimator $\\psi(\\hat{\\theta})$, which we denote as $\\operatorname{Var}_{asym}(\\psi(\\hat{\\theta}))$.\n$$ \\operatorname{Var}_{asym}(\\psi(\\hat{\\theta})) = \\frac{[\\psi'(\\theta)]^{2} \\operatorname{Var}(\\varepsilon_{1})}{n} = \\frac{1}{n} \\left(\\frac{4\\theta^{3}}{1 + \\theta^{4}}\\right)^{2} V_{\\varepsilon} $$\nThe problem asks for the ratio of the asymptotic variances of $\\psi(\\hat{\\theta})$ in two different scenarios. Let $\\operatorname{Var}_{asym}^{(i)}(\\psi(\\hat{\\theta}))$ and $\\operatorname{Var}_{asym}^{(ii)}(\\psi(\\hat{\\theta}))$ be the asymptotic variances in Scenario (i) and Scenario (ii), respectively. The noise variances are $V_{\\varepsilon}^{(i)}$ and $V_{\\varepsilon}^{(ii)}$.\n$$ \\operatorname{Var}_{asym}^{(i)}(\\psi(\\hat{\\theta})) = \\frac{1}{n} \\left(\\frac{4\\theta^{3}}{1 + \\theta^{4}}\\right)^{2} V_{\\varepsilon}^{(i)} $$\n$$ \\operatorname{Var}_{asym}^{(ii)}(\\psi(\\hat{\\theta})) = \\frac{1}{n} \\left(\\frac{4\\theta^{3}}{1 + \\theta^{4}}\\right)^{2} V_{\\varepsilon}^{(ii)} $$\nThe ratio is:\n$$ \\frac{\\operatorname{Var}_{asym}^{(ii)}(\\psi(\\hat{\\theta}))}{\\operatorname{Var}_{asym}^{(i)}(\\psi(\\hat{\\theta}))} = \\frac{\\frac{1}{n} \\left(\\frac{4\\theta^{3}}{1 + \\theta^{4}}\\right)^{2} V_{\\varepsilon}^{(ii)}}{\\frac{1}{n} \\left(\\frac{4\\theta^{3}}{1 + \\theta^{4}}\\right)^{2} V_{\\varepsilon}^{(i)}} = \\frac{V_{\\varepsilon}^{(ii)}}{V_{\\varepsilon}^{(i)}} $$\nThe ratio of the asymptotic variances of the estimator $\\psi(\\hat{\\theta})$ simplifies to the ratio of the variances of the underlying noise distributions. The specific values of $n=200$ and $\\theta=1.20$ are not needed for this calculation, as the common factor involving them cancels out.\n\nNow we compute the noise variances for each scenario.\n\nScenario (i): The noise terms are Gaussian, $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2})$, with $\\sigma^{2} = 1.44$.\nThe variance is given directly:\n$$ V_{\\varepsilon}^{(i)} = \\sigma^{2} = 1.44 $$\n\nScenario (ii): The noise terms follow a Laplace distribution, $\\varepsilon_{i} \\sim \\text{Laplace}(0, b)$, with scale parameter $b = 0.80$. The variance for this distribution is given as $2b^{2}$.\nThe variance is:\n$$ V_{\\varepsilon}^{(ii)} = 2b^{2} = 2(0.80)^{2} = 2(0.64) = 1.28 $$\n\nFinally, we compute the ratio:\n$$ \\frac{V_{\\varepsilon}^{(ii)}}{V_{\\varepsilon}^{(i)}} = \\frac{1.28}{1.44} $$\nThis fraction can be simplified:\n$$ \\frac{1.28}{1.44} = \\frac{128}{144} = \\frac{16 \\times 8}{16 \\times 9} = \\frac{8}{9} $$\nAs a decimal, this is $0.88888...$. Rounding to five significant figures, we get $0.88889$.", "answer": "$$\\boxed{0.88889}$$", "id": "3166562"}, {"introduction": "Modern machine learning algorithms often incorporate randomness as a core part of their design, for example, to improve generalization. This practice [@problem_id:3166636] provides a deep dive into the probabilistic mechanics of dropout, a popular regularization technique, within a simplified linear regression setting. By deriving the expected loss and the properties of the stochastic gradient updates, you will use first principles of probability to analyze how intentional randomness influences the training process, a vital skill for understanding and developing sophisticated learning algorithms.", "problem": "Consider the following probabilistic model for random feature masking, commonly referred to as dropout, in a linear regression setting. Let the feature dimension be $d$, and let the random feature vector $X \\in \\mathbb{R}^d$ have independent coordinates with $X_j \\sim \\mathcal{N}(0,\\sigma_j^2)$ for $j \\in \\{1,\\dots,d\\}$. Define the diagonal covariance matrix $\\Sigma = \\operatorname{diag}(\\sigma_1^2,\\dots,\\sigma_d^2)$. Let the independent mask variables $D_j \\sim \\operatorname{Bernoulli}(p)$ for a fixed $p \\in [0,1]$, with independence across $j$, and let the masked feature vector be $X' = D \\odot X$ where $\\odot$ denotes the Hadamard (element-wise) product. Let the label be $y = w_*^\\top X + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2)$ is independent of $X$ and $D$. Consider a fixed current parameter vector $w \\in \\mathbb{R}^d$ and fixed learning rate $\\eta > 0$. The training loss on one masked observation is $L = \\tfrac{1}{2}(y - w^\\top X')^2$, and the one-step Stochastic Gradient Descent (SGD) update is $w_{\\text{new}} = w - \\eta \\nabla_w L = w + \\eta (y - w^\\top X') X'$.\n\nStarting from the core definitions of expectation, variance, independence, and the known moments of the normal distribution, derive closed-form expressions for the following quantities:\n- The expectation $\\mathbb{E}[L]$ as a function of $p$, $w_*$, $w$, $(\\sigma_j^2)_{j=1}^d$, and $\\sigma_\\epsilon^2$.\n- The variance $\\operatorname{Var}(L)$ using the law of total variance.\n- The expected update vector $\\mathbb{E}[\\Delta w]$ where $\\Delta w = w_{\\text{new}} - w$.\n- The per-coordinate variance $\\operatorname{Var}(\\Delta w_k)$ for $k \\in \\{1,\\dots,d\\}$.\n\nYour program must implement these derived expressions exactly and compute the requested quantities for the following test suite of parameter values. For each test, $d=3$ and all vectors are in $\\mathbb{R}^3$:\n\n- Test $1$ (general case): $p=0.5$, $w_* = [1.0,-0.5,2.0]$, $w = [0.8,-0.2,1.5]$, $(\\sigma_1,\\sigma_2,\\sigma_3) = [1.0,2.0,0.5]$, $\\sigma_\\epsilon = 0.3$, $\\eta=0.1$.\n- Test $2$ (no dropout, no label noise): $p=1.0$, $w_* = [1.0,1.0,1.0]$, $w = [0.0,0.0,0.0]$, $(\\sigma_1,\\sigma_2,\\sigma_3) = [1.0,1.0,1.0]$, $\\sigma_\\epsilon = 0.0$, $\\eta=0.05$.\n- Test $3$ (full dropout, nonzero label noise): $p=0.0$, $w_* = [0.5,-1.0,1.5]$, $w = [1.0,0.0,-0.5]$, $(\\sigma_1,\\sigma_2,\\sigma_3) = [0.3,1.5,2.0]$, $\\sigma_\\epsilon = 0.7$, $\\eta=0.2$.\n- Test $4$ (one zero-variance feature): $p=0.7$, $w_* = [2.0,-1.0,0.0]$, $w = [1.5,-0.5,0.5]$, $(\\sigma_1,\\sigma_2,\\sigma_3) = [0.0,1.0,2.0]$, $\\sigma_\\epsilon = 0.0$, $\\eta=0.15$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a list with four elements in the following order: $[\\mathbb{E}[L], \\operatorname{Var}(L), \\mathbb{E}[\\Delta w], \\operatorname{Var}(\\Delta w)]$, where $\\mathbb{E}[\\Delta w]$ and $\\operatorname{Var}(\\Delta w)$ are three-element lists containing the per-coordinate values. The final printed output must therefore be a list of four lists (one per test case), in the exact specified structure. All numerical answers must be floats or lists of floats, with no percentage signs and no units. The program must be self-contained and require no input.", "solution": "The problem is well-posed, scientifically grounded, objective, and contains all necessary information for a unique solution. We proceed with the derivation of the four requested quantities.\n\nThe model involves three sources of randomness: the feature vector $X$, the mask vector $D$, and the noise $\\epsilon$. These are mutually independent. We start by listing the key properties of the underlying random variables which will be used throughout the derivations.\n\n-   The features $X_j \\sim \\mathcal{N}(0, \\sigma_j^2)$ are independent, zero-mean normal variables. Their moments are: $\\mathbb{E}[X_j]=0$, $\\mathbb{E}[X_j^2]=\\sigma_j^2$, $\\mathbb{E}[X_j^3]=0$, $\\mathbb{E}[X_j^4]=3\\sigma_j^4$. For $j \\neq k$, $\\mathbb{E}[X_j X_k] = \\mathbb{E}[X_j]\\mathbb{E}[X_k]=0$.\n-   The mask variables $D_j \\sim \\operatorname{Bernoulli}(p)$ are independent. Their moments are: $\\mathbb{E}[D_j]=p$, $\\mathbb{E}[D_j^k]=p$ for any integer $k \\ge 1$ since $D_j \\in \\{0,1\\}$, and $\\operatorname{Var}(D_j) = p(1-p)$.\n-   The observation noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$ has moments $\\mathbb{E}[\\epsilon]=0$ and $\\mathbb{E}[\\epsilon^2]=\\sigma_\\epsilon^2$.\n-   The masked feature is $X'_j = D_j X_j$. Due to independence of $D_j$ and $X_j$:\n    -   $\\mathbb{E}[X'_j] = \\mathbb{E}[D_j]\\mathbb{E}[X_j] = p \\cdot 0 = 0$.\n    -   $\\mathbb{E}[(X'_j)^2] = \\mathbb{E}[D_j^2 X_j^2] = \\mathbb{E}[D_j^2]\\mathbb{E}[X_j^2] = p\\sigma_j^2$.\n    -   For $j \\neq k$, $\\mathbb{E}[X'_j X'_k] = \\mathbb{E}[D_jX_j D_kX_k] = \\mathbb{E}[D_j]\\mathbb{E}[X_j]\\mathbb{E}[D_k]\\mathbb{E}[X_k]=0$.\n\nLet $\\Sigma = \\operatorname{diag}(\\sigma_1^2, \\dots, \\sigma_d^2)$ be the diagonal covariance matrix of $X$.\n\n### Derivation of the Expected Loss $\\mathbb{E}[L]$\nThe loss is $L = \\frac{1}{2}(y - w^\\top X')^2$. Substituting $y = w_*^\\top X + \\epsilon$ and $X' = D \\odot X$:\n$$\nL = \\frac{1}{2} (w_*^\\top X + \\epsilon - w^\\top X')^2\n$$\nBy linearity of expectation, we have:\n$$\n\\mathbb{E}[L] = \\frac{1}{2} \\mathbb{E}[ (w_*^\\top X)^2 + \\epsilon^2 + (w^\\top X')^2 + 2(w_*^\\top X)\\epsilon - 2(w_*^\\top X)(w^\\top X') - 2\\epsilon(w^\\top X') ]\n$$\nWe evaluate the expectation of each term:\n-   $\\mathbb{E}[\\epsilon^2]=\\sigma_\\epsilon^2$.\n-   Terms with a single factor of $\\epsilon$ or a single un-squared factor of $X_j$ or $X'_j$ have an expectation of $0$, because $\\mathbb{E}[\\epsilon]=0$ and $\\mathbb{E}[X]=\\mathbb{E}[X']=0$, and all variables are independent. Thus, $\\mathbb{E}[(w_*^\\top X)\\epsilon]=0$ and $\\mathbb{E}[\\epsilon(w^\\top X')]=0$.\n-   $\\mathbb{E}[(w_*^\\top X)^2] = \\mathbb{E}[(\\sum_j w_{*j} X_j)^2] = \\sum_j w_{*j}^2 \\mathbb{E}[X_j^2] = \\sum_j w_{*j}^2 \\sigma_j^2 = w_*^\\top \\Sigma w_*$.\n-   $\\mathbb{E}[(w^\\top X')^2] = \\mathbb{E}[(\\sum_j w_j X'_j)^2] = \\sum_j w_j^2 \\mathbb{E}[(X'_j)^2] = \\sum_j w_j^2 p \\sigma_j^2 = p(w^\\top \\Sigma w)$.\n-   $\\mathbb{E}[(w_*^\\top X)(w^\\top X')] = \\mathbb{E}[(\\sum_j w_{*j} X_j)(\\sum_k w_k X'_k)] = \\sum_j w_{*j} w_j \\mathbb{E}[X_j X'_j] = \\sum_j w_{*j} w_j \\mathbb{E}[X_j D_j X_j] = \\sum_j w_{*j} w_j \\mathbb{E}[D_j]\\mathbb{E}[X_j^2] = \\sum_j w_{*j} w_j p \\sigma_j^2 = p(w_*^\\top \\Sigma w)$.\n\nCombining these terms gives the expected loss:\n$$\n\\mathbb{E}[L] = \\frac{1}{2} \\left( w_*^\\top \\Sigma w_* + \\sigma_\\epsilon^2 + p(w^\\top \\Sigma w) - 2p(w_*^\\top \\Sigma w) \\right)\n$$\n\n### Derivation of the Variance of the Loss $\\operatorname{Var}(L)$\nWe use the Law of Total Variance: $\\operatorname{Var}(L) = \\mathbb{E}[\\operatorname{Var}(L|D)] + \\operatorname{Var}(\\mathbb{E}[L|D])$.\nGiven the mask $D$, let $w_D = w \\odot D$. The loss is $L = \\frac{1}{2}Z^2$ where $Z = (w_* - w_D)^\\top X + \\epsilon$. $Z$ is a sum of independent normal variables, so it is normal with mean $\\mathbb{E}[Z]=0$ and variance $\\sigma_Z^2 = \\operatorname{Var}(Z) = \\operatorname{Var}((w_* - w_D)^\\top X) + \\operatorname{Var}(\\epsilon) = (w_*-w_D)^\\top \\Sigma (w_*-w_D) + \\sigma_\\epsilon^2$.\nThe conditional expectation of the loss is $\\mathbb{E}[L|D] = \\frac{1}{2}\\mathbb{E}[Z^2|D] = \\frac{1}{2}\\sigma_Z^2$.\nThe conditional variance is $\\operatorname{Var}(L|D) = \\operatorname{Var}(\\frac{1}{2}Z^2|D) = \\frac{1}{4}\\operatorname{Var}(Z^2|D)$. Since $Z/\\sigma_Z \\sim \\mathcal{N}(0,1)$, $(Z/\\sigma_Z)^2 \\sim \\chi^2_1$, which has variance $2$. Thus $\\operatorname{Var}(Z^2) = \\sigma_Z^4 \\operatorname{Var}((Z/\\sigma_Z)^2) = 2\\sigma_Z^4$. So, $\\operatorname{Var}(L|D) = \\frac{1}{2}(\\sigma_Z^2)^2$.\n\nLet $S_D = (w_*-w_D)^\\top \\Sigma (w_*-w_D) = \\sum_j (w_{*j} - w_j D_j)^2 \\sigma_j^2$. Then $\\sigma_Z^2 = S_D + \\sigma_\\epsilon^2$.\nThe two components of the total variance are:\n1.  $\\operatorname{Var}(\\mathbb{E}[L|D]) = \\operatorname{Var}(\\frac{1}{2}(S_D + \\sigma_\\epsilon^2)) = \\frac{1}{4}\\operatorname{Var}(S_D)$. Let $A_j = (w_{*j}-w_j D_j)^2\\sigma_j^2$. Since $D_j$ are independent, $A_j$ are independent. $S_D = \\sum_j A_j$.\n    $\\operatorname{Var}(S_D) = \\sum_j \\operatorname{Var}(A_j)$.\n    $A_j = \\sigma_j^2(w_{*j}^2 - 2w_{*j}w_j D_j + w_j^2 D_j^2) = \\sigma_j^2(w_{*j}^2 + (w_j^2 - 2w_{*j}w_j)D_j)$ since $D_j^2=D_j$.\n    $\\operatorname{Var}(A_j) = \\sigma_j^4(w_j^2 - 2w_{*j}w_j)^2 \\operatorname{Var}(D_j) = \\sigma_j^4(w_j^2-2w_{*j}w_j)^2 p(1-p)$.\n    So, $\\operatorname{Var}(\\mathbb{E}[L|D]) = \\frac{p(1-p)}{4} \\sum_j \\sigma_j^4(w_j^2 - 2w_{*j}w_j)^2$.\n2.  $\\mathbb{E}[\\operatorname{Var}(L|D)] = \\mathbb{E}[\\frac{1}{2}(\\sigma_Z^2)^2] = \\frac{1}{2}\\mathbb{E}[(S_D + \\sigma_\\epsilon^2)^2] = \\frac{1}{2}(\\mathbb{E}[S_D^2] + 2\\sigma_\\epsilon^2 \\mathbb{E}[S_D] + \\sigma_\\epsilon^4)$.\n    $\\mathbb{E}[S_D^2] = \\operatorname{Var}(S_D) + (\\mathbb{E}[S_D])^2$.\n    $\\mathbb{E}[S_D] = \\mathbb{E}[\\sum_j A_j] = \\sum_j \\mathbb{E}[A_j] = \\sum_j \\sigma_j^2(w_{*j}^2 - 2pw_{*j}w_j + pw_j^2) = w_*^\\top\\Sigma w_* - 2p w_*^\\top\\Sigma w + p w^\\top\\Sigma w$.\n    Note that $\\mathbb{E}[S_D] + \\sigma_\\epsilon^2 = 2\\mathbb{E}[L]$.\n    $\\mathbb{E}[\\operatorname{Var}(L|D)] = \\frac{1}{2}(\\operatorname{Var}(S_D) + (\\mathbb{E}[S_D])^2 + 2\\sigma_\\epsilon^2\\mathbb{E}[S_D] + \\sigma_\\epsilon^4) = \\frac{1}{2}(\\operatorname{Var}(S_D) + (\\mathbb{E}[S_D] + \\sigma_\\epsilon^2)^2) = \\frac{1}{2}\\operatorname{Var}(S_D) + 2(\\mathbb{E}[L])^2$.\n\nCombining the terms: $\\operatorname{Var}(L) = (\\frac{1}{2}\\operatorname{Var}(S_D) + 2(\\mathbb{E}[L])^2) + \\frac{1}{4}\\operatorname{Var}(S_D) = 2(\\mathbb{E}[L])^2 + \\frac{3}{4}\\operatorname{Var}(S_D)$.\n$$\n\\operatorname{Var}(L) = 2(\\mathbb{E}[L])^2 + \\frac{3p(1-p)}{4} \\sum_{j=1}^d \\sigma_j^4(w_j^2 - 2w_{*j}w_j)^2\n$$\n\n### Derivation of the Expected Update Vector $\\mathbb{E}[\\Delta w]$\nThe update vector is $\\Delta w = \\eta(y - w^\\top X')X'$. We compute its expectation coordinate-wise.\n$$\n\\mathbb{E}[\\Delta w_k] = \\eta \\mathbb{E}[(w_*^\\top X + \\epsilon - w^\\top X') X'_k] = \\eta (\\mathbb{E}[(w_*^\\top X)X'_k] + \\mathbb{E}[\\epsilon X'_k] - \\mathbb{E}[(w^\\top X')X'_k])\n$$\n-   $\\mathbb{E}[\\epsilon X'_k] = \\mathbb{E}[\\epsilon]\\mathbb{E}[X'_k] = 0$.\n-   $\\mathbb{E}[(w_*^\\top X)X'_k] = \\mathbb{E}[(\\sum_j w_{*j} X_j)(D_k X_k)] = \\sum_j w_{*j} \\mathbb{E}[X_j D_k X_k]$. Only the $j=k$ term is non-zero, yielding $w_{*k}\\mathbb{E}[D_k X_k^2] = w_{*k} \\mathbb{E}[D_k]\\mathbb{E}[X_k^2] = w_{*k} p \\sigma_k^2$.\n-   $\\mathbb{E}[(w^\\top X')X'_k] = \\mathbb{E}[(\\sum_j w_j X'_j)X'_k] = \\sum_j w_j \\mathbb{E}[X'_j X'_k]$. Only the $j=k$ term is non-zero, yielding $w_k \\mathbb{E}[(X'_k)^2] = w_k p \\sigma_k^2$.\nCombining gives:\n$$\n\\mathbb{E}[\\Delta w_k] = \\eta (w_{*k}p\\sigma_k^2 - w_k p\\sigma_k^2) = \\eta p \\sigma_k^2 (w_{*k} - w_k)\n$$\n\n### Derivation of the Per-coordinate Update Variance $\\operatorname{Var}(\\Delta w_k)$\nWe use the Law of Total Variance again: $\\operatorname{Var}(\\Delta w_k) = \\mathbb{E}[\\operatorname{Var}(\\Delta w_k|D)] + \\operatorname{Var}(\\mathbb{E}[\\Delta w_k|D])$.\nFirst, we find the conditional expectation $\\mathbb{E}[\\Delta w_k|D] = \\eta \\mathbb{E}[(y - w^\\top X')X'_k|D]$.\n$$\n\\mathbb{E}[\\Delta w_k|D] = \\eta \\mathbb{E}[ ((w_* - w_D)^\\top X + \\epsilon)D_k X_k | D ] = \\eta D_k (w_{*k} - w_k D_k)\\sigma_k^2\n$$\nSince $D_k^2=D_k$, this is $\\eta D_k (w_{*k}-w_k)\\sigma_k^2$. This is a scaled Bernoulli variable.\nThe variance of this term is $\\operatorname{Var}(\\mathbb{E}[\\Delta w_k|D]) = \\operatorname{Var}_D(\\eta D_k (w_{*k}-w_k)\\sigma_k^2) = \\eta^2 (w_{*k}-w_k)^2 \\sigma_k^4 \\operatorname{Var}(D_k) = \\eta^2 p(1-p)(w_{*k}-w_k)^2 \\sigma_k^4$.\n\nNext we compute $\\operatorname{Var}(\\Delta w_k | D) = \\eta^2 \\operatorname{Var}((y - w^\\top X')X'_k | D) = \\eta^2 D_k^2 \\operatorname{Var}(((w_*-w_D)^\\top X + \\epsilon)X_k|D)$. Since $D_k^2=D_k$ and $D_k$ is a constant given $D$:\nLet $v_D=w_*-w_D$. The variance is over $X$ and $\\epsilon$.\n$\\operatorname{Var}((v_D^\\top X)X_k + \\epsilon X_k | D) = \\operatorname{Var}((v_D^\\top X)X_k|D) + \\operatorname{Var}(\\epsilon X_k|D)$, due to independence.\n$\\operatorname{Var}(\\epsilon X_k|D) = \\mathbb{E}[\\epsilon^2 X_k^2] - (\\mathbb{E}[\\epsilon X_k])^2 = \\sigma_\\epsilon^2 \\sigma_k^2$.\nFor the other term, we use Isserlis' theorem.\n$\\operatorname{Var}((v_D^\\top X)X_k|D) = \\mathbb{E}[(v_D^\\top X)^2 X_k^2 |D] - (\\mathbb{E}[(v_D^\\top X)X_k|D])^2$.\n$\\mathbb{E}[(v_D^\\top X)X_k|D] = (v_D)_k \\sigma_k^2$.\n$\\mathbb{E}[(v_D^\\top X)^2 X_k^2|D] = \\mathbb{E}[(v_D^\\top X)^2]\\mathbb{E}[X_k^2] + 2(\\mathbb{E}[(v_D^\\top X)X_k])^2 = (v_D^\\top \\Sigma v_D)\\sigma_k^2 + 2((v_D)_k \\sigma_k^2)^2$.\nSo, $\\operatorname{Var}((v_D^\\top X)X_k|D) = (v_D^\\top \\Sigma v_D)\\sigma_k^2 + ((v_D)_k \\sigma_k^2)^2$.\nCombining, $\\operatorname{Var}(\\Delta w_k | D) = \\eta^2 D_k \\left[ (v_D^\\top \\Sigma v_D + \\sigma_\\epsilon^2)\\sigma_k^2 + ((v_D)_k \\sigma_k^2)^2 \\right]$.\nNote $(v_D)_k = w_{*k} - w_k D_k$.\n$\\mathbb{E}_D[\\operatorname{Var}(\\Delta w_k | D)]$ is the expectation of the above over $D$.\n$\\mathbb{E}_D[\\operatorname{Var}(\\Delta w_k|D)] = \\eta^2 \\mathbb{E}_D \\left[ D_k ( \\sigma_k^2(S_D + \\sigma_\\epsilon^2) + (w_{*k}-w_k D_k)^2 \\sigma_k^4 ) \\right]$.\nTaking the expectation over $D$ and combining with $\\operatorname{Var}(\\mathbb{E}[\\Delta w_k|D])$ leads to the following expression:\n$$\n\\operatorname{Var}(\\Delta w_k) = \\eta^2 p \\left( (3-p)(w_{*k}-w_k)^2 \\sigma_k^4 + \\sigma_k^2 \\sigma_\\epsilon^2 + \\sigma_k^2 \\left( 2\\mathbb{E}[L] - \\sigma_\\epsilon^2 - (w_{*k}^2-2pw_{*k}w_k+pw_k^2)\\sigma_k^2 \\right) \\right)\n$$\nThis expression conveniently reuses the already-computed $\\mathbb{E}[L]$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite of parameters.\n    Implements the derived closed-form expressions for the requested quantities.\n    \"\"\"\n    \n    test_cases = [\n        {'p': 0.5, 'w_star': [1.0, -0.5, 2.0], 'w': [0.8, -0.2, 1.5], 'sigmas': [1.0, 2.0, 0.5], 'sigma_eps': 0.3, 'eta': 0.1},\n        {'p': 1.0, 'w_star': [1.0, 1.0, 1.0], 'w': [0.0, 0.0, 0.0], 'sigmas': [1.0, 1.0, 1.0], 'sigma_eps': 0.0, 'eta': 0.05},\n        {'p': 0.0, 'w_star': [0.5, -1.0, 1.5], 'w': [1.0, 0.0, -0.5], 'sigmas': [0.3, 1.5, 2.0], 'sigma_eps': 0.7, 'eta': 0.2},\n        {'p': 0.7, 'w_star': [2.0, -1.0, 0.0], 'w': [1.5, -0.5, 0.5], 'sigmas': [0.0, 1.0, 2.0], 'sigma_eps': 0.0, 'eta': 0.15},\n    ]\n\n    results = []\n    \n    for params in test_cases:\n        p = params['p']\n        w_star = np.array(params['w_star'])\n        w = np.array(params['w'])\n        sigmas = np.array(params['sigmas'])\n        sigma_eps = params['sigma_eps']\n        eta = params['eta']\n        \n        d = len(w_star)\n        sigma_sq = sigmas**2\n        sigma_eps_sq = sigma_eps**2\n        \n        # --- 1. Expectation of the Loss: E[L] ---\n        w_star_S_w_star = np.sum(w_star**2 * sigma_sq)\n        w_S_w = np.sum(w**2 * sigma_sq)\n        w_star_S_w = np.sum(w_star * w * sigma_sq)\n        \n        exp_L = 0.5 * (w_star_S_w_star + sigma_eps_sq + p * (w_S_w - 2 * w_star_S_w))\n\n        # --- 2. Variance of the Loss: Var(L) ---\n        C_j = sigma_sq * (w**2 - 2 * w_star * w)\n        var_S = p * (1 - p) * np.sum(C_j**2)\n        var_L = 2 * exp_L**2 + 0.75 * var_S\n\n        # --- 3. Expected Update Vector: E[Δw] ---\n        v = w_star - w\n        exp_delta_w = eta * p * sigma_sq * v\n        \n        # --- 4. Per-coordinate Update Variance: Var(Δw_k) ---\n        var_delta_w = np.zeros(d)\n        if p > 0: # If p=0, variance is 0\n            EL_term = 2 * exp_L - sigma_eps_sq\n            for k in range(d):\n                v_k = w_star[k] - w[k]\n                sigma_k_sq = sigma_sq[k]\n                sigma_k_4 = sigma_k_sq**2\n\n                # Term S_k from derivation\n                S_k = w_star[k]**2 - 2 * p * w_star[k] * w[k] + p * w[k]**2\n                \n                term1 = (3 - p) * v_k**2 * sigma_k_4\n                term2 = sigma_k_sq * sigma_eps_sq\n                term3 = sigma_k_sq * (EL_term - S_k * sigma_k_sq)\n                \n                var_delta_w[k] = (eta**2 * p) * (term1 + term2 + term3)\n\n        result_case = [\n            exp_L,\n            var_L,\n            exp_delta_w.tolist(),\n            var_delta_w.tolist()\n        ]\n        results.append(result_case)\n\n    # Format and print the final output exactly as required.\n    # The default str() for lists includes spaces, which is standard.\n    final_output = []\n    for res in results:\n        # Convert numpy arrays to lists for standard Python list string representation\n        exp_L_val = res[0]\n        var_L_val = res[1]\n        exp_dw_list = res[2]\n        var_dw_list = res[3]\n        final_output.append(str([exp_L_val, var_L_val, exp_dw_list, var_dw_list]))\n\n    print(f\"[{','.join(final_output)}]\")\n\nsolve()\n```", "id": "3166636"}]}