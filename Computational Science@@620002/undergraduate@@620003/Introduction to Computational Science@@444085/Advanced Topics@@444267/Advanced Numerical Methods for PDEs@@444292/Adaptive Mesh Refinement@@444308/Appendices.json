{"hands_on_practices": [{"introduction": "Our first practice grounds us in a classic application: solving an elliptic boundary value problem. We will implement a complete AMR solver for the one-dimensional Poisson equation using the Finite Element Method (FEM). This exercise focuses on the core 'solve-estimate-mark-refine' cycle, where you will use a standard *a posteriori* error indicator to iteratively pinpoint and refine regions of high error, providing a foundational understanding of how AMR dynamically adapts the mesh to the solution [@problem_id:2420755].", "problem": "You are to implement a complete, runnable program that performs one-dimensional finite element analysis with continuous, piecewise-affine hat functions and executes an adaptive mesh refinement strategy driven by a residual-type a posteriori error indicator. Consider the boundary value problem on the unit interval: find $u:[0,1]\\to\\mathbb{R}$ such that\n$$-u''(x)=f(x)\\ \\text{for}\\ x\\in(0,1),\\quad u(0)=0,\\quad u(1)=0.$$\nLet $\\mathcal{T}_h$ be a mesh with nodes $0=x_0<x_1<\\dots<x_N=1$ and let $V_h$ be the space of continuous, piecewise affine functions that vanish at $x=0$ and $x=1$. The finite element method (FEM) seeks $u_h\\in V_h$ such that\n$$\\int_{0}^{1} u_h'(x)\\,v_h'(x)\\,dx=\\int_{0}^{1} f(x)\\,v_h(x)\\,dx\\quad \\text{for all}\\ v_h\\in V_h.$$\nUse standard hat functions associated with the mesh nodes as a basis of $V_h$, assemble the global linear system, impose the Dirichlet boundary conditions strongly, and solve for the nodal values of $u_h$.\n\nDefine the elementwise error indicator on each element $K_i=(x_{i-1},x_i)$ with length $h_i=x_i-x_{i-1}$ by\n$$\\eta_i^2 := h_i^2\\, f(m_i)^2 + \\tfrac{1}{2} h_i\\Big(\\mathbf{1}_{\\{i>1\\}}\\,J_{i-1}^2 + \\mathbf{1}_{\\{i<N\\}}\\,J_i^2\\Big),$$\nwhere $m_i=\\tfrac{1}{2}(x_{i-1}+x_i)$, and for each interior node $x_j$ with $j\\in\\{1,\\dots,N-1\\}$,\n$$J_j := \\big|\\,u_h'(x_j^-)-u_h'(x_j^+)\\,\\big|,$$\nwith $u_h'(x_j^-)$ the derivative on the left element $(x_{j-1},x_j)$ and $u_h'(x_j^+)$ the derivative on the right element $(x_j,x_{j+1})$. On each element $K_i$, the derivative $u_h'$ is constant and equal to the slope of $u_h$ on $K_i$.\n\nPerform adaptive refinement by iterating the following cycle: solve the discrete problem on the current mesh, compute $(\\eta_i)_{i=1}^N$, select an index $i^\\star$ that maximizes $\\eta_i$ (if multiple indices attain the maximum, select the smallest index), and bisect $K_{i^\\star}$ by inserting its midpoint $m_{i^\\star}$ as a new node. Repeat this for a specified number of refinement steps.\n\nAll integrals in the bilinear and linear forms must be evaluated exactly for the given $f(x)$ in each test case. The right-hand sides $f(x)$ in all test cases below are polynomials of degree at most $1$, so the exact integrals of $f(x)$ times a hat function on each element exist in closed form. You must not introduce any units. Angles do not appear.\n\nTest suite. For each case, begin from a uniform partition of $[0,1]$ with $N_0$ elements (that is, nodes at $x_j=j/N_0$ for $j=0,\\dots,N_0$), run exactly $S$ refinement steps as defined above, and report the final node coordinates:\n- Case A: $f(x)=1$ for all $x\\in[0,1]$, with $N_0=2$ and $S=2$.\n- Case B: $f(x)=2x+1$ for all $x\\in[0,1]$, with $N_0=3$ and $S=3$.\n- Case C: $f(x)=-4x+2$ for all $x\\in[0,1]$, with $N_0=1$ and $S=4$.\n\nFinal output format. Your program must produce a single line of output containing a list of three lists, corresponding to Cases A, B, and C in this order. Each inner list must contain the final mesh node coordinates in increasing order, written as decimal fractions rounded to exactly $6$ digits after the decimal point. The outer list and each inner list must use square brackets and commas, with no additional whitespace or text. For example, a valid shape is\n$$\\big[ [x_0^{(A)},x_1^{(A)},\\dots], [x_0^{(B)},x_1^{(B)},\\dots], [x_0^{(C)},x_1^{(C)},\\dots] \\big],$$\nwhere each $x_j^{(\\cdot)}$ is a rounded decimal number. The program must not read any input.", "solution": "The problem presented is a standard one-dimensional boundary value problem (BVP) for the Poisson equation with homogeneous Dirichlet boundary conditions. We are tasked to find a function $u(x)$ on the interval $[0,1]$ that satisfies\n$$-u''(x) = f(x) \\quad \\text{for } x \\in (0,1),$$\n$$u(0) = 0, \\quad u(1) = 0.$$\nThis problem is to be solved using the finite element method (FEM) with an adaptive mesh refinement strategy. The problem statement is well-posed, scientifically sound, and contains all necessary information for its unique, verifiable solution. We proceed with the derivation and implementation of the method.\n\nFirst, we establish the weak formulation of the BVP. Let $V = H_0^1(0,1)$ be the Sobolev space of functions with square-integrable first derivatives that vanish at the boundaries $x=0$ and $x=1$. Multiplying the differential equation by a test function $v(x) \\in V$ and integrating over the domain $(0,1)$ yields\n$$-\\int_0^1 u''(x) v(x) dx = \\int_0^1 f(x) v(x) dx.$$\nApplying integration by parts to the left-hand side and using the boundary conditions $v(0)=v(1)=0$, we obtain the weak formulation: find $u \\in V$ such that\n$$a(u,v) := \\int_0^1 u'(x) v'(x) dx = \\int_0^1 f(x) v(x) dx =: L(v) \\quad \\forall v \\in V.$$\n\nThe finite element method approximates this infinite-dimensional problem with a finite-dimensional one. We introduce a mesh $\\mathcal{T}_h$ consisting of nodes $0=x_0 < x_1 < \\dots < x_N=1$, which partition the interval $[0,1]$ into $N$ elements $K_i=(x_{i-1}, x_i)$ of length $h_i = x_i - x_{i-1}$. We define a finite-dimensional subspace $V_h \\subset V$ of continuous, piecewise-affine functions on this mesh that are zero at the boundaries. The FEM problem is: find $u_h \\in V_h$ such that\n$$a(u_h, v_h) = L(v_h) \\quad \\forall v_h \\in V_h.$$\nAny function $u_h \\in V_h$ can be expressed as a linear combination of basis functions. A standard choice for the basis of $V_h$ is the set of \"hat functions\" $\\{\\phi_j\\}_{j=1}^{N-1}$ associated with the interior nodes $\\{x_j\\}_{j=1}^{N-1}$. The hat function $\\phi_j(x)$ is defined to be $1$ at node $x_j$ and $0$ at all other nodes $x_k$ for $k \\neq j$. It is affine on each element.\nThe solution $u_h(x)$ is thus written as\n$$u_h(x) = \\sum_{j=1}^{N-1} U_j \\phi_j(x),$$\nwhere $U_j = u_h(x_j)$ are the unknown nodal values. Since the boundary conditions $u_h(0)=u_h(1)=0$ are imposed strongly, the sum only runs over interior nodes.\n\nSubstituting this expansion into the weak form and choosing $v_h = \\phi_i$ for each $i \\in \\{1,\\dots,N-1\\}$ gives a system of linear equations $A\\mathbf{U} = \\mathbf{b}$, where $\\mathbf{U} = [U_1, \\dots, U_{N-1}]^T$ is the vector of unknown nodal values, and the entries of the stiffness matrix $A$ and load vector $\\mathbf{b}$ are\n$$A_{ij} = a(\\phi_j, \\phi_i) = \\int_0^1 \\phi_j'(x) \\phi_i'(x) dx,$$\n$$b_i = L(\\phi_i) = \\int_0^1 f(x) \\phi_i(x) dx.$$\nThe derivative of $\\phi_j(x)$ is piecewise constant: $\\phi_j'(x) = 1/h_j$ on $(x_{j-1}, x_j)$, $-1/h_{j+1}$ on $(x_j, x_{j+1})$, and $0$ elsewhere. The support of $\\phi_i'(x)$ and $\\phi_j'(x)$ overlaps only if $|i-j| \\le 1$, making the matrix $A$ tridiagonal. The entries are calculated as:\n$$A_{ii} = \\int_{x_{i-1}}^{x_{i+1}} (\\phi_i'(x))^2 dx = \\frac{1}{h_i} + \\frac{1}{h_{i+1}},$$\n$$A_{i,i+1} = A_{i+1,i} = \\int_{x_i}^{x_{i+1}} \\phi_{i+1}'(x) \\phi_i'(x) dx = -\\frac{1}{h_{i+1}}.$$\nFor the load vector, we are given that $f(x)$ is a polynomial of degree at most $1$, which we write as $f(x) = cx+d$. The integral for $b_i$ must be computed exactly:\n$$b_i = \\int_{x_{i-1}}^{x_i} (cx+d)\\frac{x-x_{i-1}}{h_i}dx + \\int_{x_i}^{x_{i+1}} (cx+d)\\frac{x_{i+1}-x}{h_{i+1}}dx.$$\nExact evaluation of these integrals yields the formula:\n$$b_i = (cx_i+d)\\frac{h_i+h_{i+1}}{2} + c \\frac{h_{i+1}^2 - h_i^2}{6} = f(x_i)\\frac{h_i+h_{i+1}}{2} + f'(x_i) \\frac{h_{i+1}^2 - h_i^2}{6}.$$\nWith $A$ and $\\mathbf{b}$ assembled, the system $A\\mathbf{U}=\\mathbf{b}$ is solved to find the nodal values of $u_h$.\n\nThe core of the task is the adaptive mesh refinement. After solving for $u_h$ on a given mesh, we compute an a posteriori error indicator $\\eta_i$ for each element $K_i=(x_{i-1},x_i)$. The specified indicator is\n$$\\eta_i^2 = h_i^2 f(m_i)^2 + \\frac{1}{2} h_i \\left( \\mathbf{1}_{\\{i>1\\}} J_{i-1}^2 + \\mathbf{1}_{\\{i<N\\}} J_i^2 \\right),$$\nwhere $m_i = (x_{i-1}+x_i)/2$ is the element midpoint. The first term, $h_i^2 f(m_i)^2$, is the element residual term, approximating the contribution of the source term $f$ to the error. The second term involves the jump residual $J_j$ at each interior node $x_j$, which is the jump in the derivative of the numerical solution:\n$$J_j = \\left| u_h'(x_j^-) - u_h'(x_j^+) \\right| = \\left| \\frac{U_j - U_{j-1}}{h_j} - \\frac{U_{j+1} - U_j}{h_{j+1}} \\right|,$$\nwhere $U_0=0$ and $U_N=0$ are the boundary values. Note that the indicator functions $\\mathbf{1}_{\\{\\cdot\\}}$ correctly handle boundary elements where one of the jump terms is absent.\n\nThe adaptive algorithm proceeds in cycles. In each cycle:\n1.  Solve the FEM problem on the current mesh $\\mathcal{T}_h$ to obtain $u_h$.\n2.  Compute the error indicators $\\eta_i$ for all elements $K_i \\in \\mathcal{T}_h$.\n3.  Identify the element $K_{i^\\star}$ with the largest error indicator, $\\eta_{i^\\star} = \\max_i \\eta_i$. Ties are broken by choosing the smallest index $i^\\star$.\n4.  Refine the mesh by bisecting the marked element $K_{i^\\star}$, i.e., adding its midpoint $m_{i^\\star}$ as a new node. This creates a new mesh for the next cycle.\n\nThis process is repeated for a specified number of steps $S$. The implementation will start with an initial uniform mesh for each test case, then execute the solve-estimate-mark-refine loop $S$ times, and finally report the sorted coordinates of the nodes in the final mesh.\nFor the special case where there are no interior nodes ($N=1$), the linear system is of size $0 \\times 0$, and the solution is trivially $u_h=0$. The error indicators are computed based on this zero solution, and the refinement proceeds as specified.\nThe final program implements this complete algorithm, handling the matrix assembly, system solution, error indication, and refinement strategy for each of the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the 1D Poisson BVP with adaptive mesh refinement using FEM.\n    \"\"\"\n\n    test_cases = [\n        # Case A: f(x)=1, N0=2, S=2\n        (lambda x: 1.0, 0.0, 1.0, 2, 2),\n        # Case B: f(x)=2x+1, N0=3, S=3\n        (lambda x: 2.0 * x + 1.0, 2.0, 1.0, 3, 3),\n        # Case C: f(x)=-4x+2, N0=1, S=4\n        (lambda x: -4.0 * x + 2.0, -4.0, 2.0, 1, 4)\n    ]\n\n    all_results = []\n    \n    for f_func, c, d, N0, S in test_cases:\n        # Initialize mesh\n        nodes = np.linspace(0.0, 1.0, N0 + 1).tolist()\n\n        for _ in range(S):\n            nodes.sort()\n            current_nodes = np.array(nodes)\n            N = len(current_nodes) - 1  # Number of elements\n            num_interior_nodes = N - 1\n\n            if num_interior_nodes == 0:\n                # Trivial solution u_h = 0\n                full_U = np.zeros(N + 1)\n            else:\n                # Assemble stiffness matrix A\n                A = np.zeros((num_interior_nodes, num_interior_nodes))\n                h = np.diff(current_nodes)\n                \n                # Diagonal entries\n                for i in range(num_interior_nodes):\n                    idx = i + 1 # node index\n                    A[i, i] = 1.0 / h[idx-1] + 1.0 / h[idx]\n                \n                # Off-diagonal entries\n                for i in range(num_interior_nodes - 1):\n                    idx = i + 1 # node index\n                    A[i, i + 1] = -1.0 / h[idx]\n                    A[i + 1, i] = -1.0 / h[idx]\n\n                # Assemble load vector b\n                b = np.zeros(num_interior_nodes)\n                for i in range(num_interior_nodes):\n                    idx = i + 1  # node index\n                    x_i = current_nodes[idx]\n                    h_left = h[idx - 1]\n                    h_right = h[idx]\n                    \n                    val = (c * x_i + d) * (h_left + h_right) / 2.0\n                    val += c * (h_right**2 - h_left**2) / 6.0\n                    b[i] = val\n\n                # Solve linear system AU=b\n                interior_U = np.linalg.solve(A, b)\n                full_U = np.concatenate(([0], interior_U, [0]))\n\n            # Compute error indicators\n            h = np.diff(current_nodes)\n            \n            # Compute jumps J_j at interior nodes\n            jumps = np.zeros(num_interior_nodes)\n            if num_interior_nodes > 0:\n                derivs = (full_U[1:] - full_U[:-1]) / h\n                for j in range(1, N): # iterate over interior node indices\n                    jump_val = np.abs(derivs[j-1] - derivs[j])\n                    jumps[j-1] = jump_val\n\n            # Compute indicators eta_i for each element\n            etas_sq = np.zeros(N)\n            for i in range(N): # iterate over element indices\n                m_i = (current_nodes[i] + current_nodes[i+1]) / 2.0\n                h_i = h[i]\n                \n                # Element residual term\n                term1 = h_i**2 * f_func(m_i)**2\n                \n                # Jump residual term\n                term2 = 0.0\n                # Jump at left node x_i\n                if i > 0:\n                    term2 += 0.5 * h_i * jumps[i-1]**2\n                # Jump at right node x_{i+1}\n                if i  N - 1:\n                    term2 += 0.5 * h_i * jumps[i]**2\n                \n                etas_sq[i] = term1 + term2\n\n            # Mark element for refinement\n            # np.argmax selects the first occurrence in case of a tie, which matches the spec.\n            i_star = np.argmax(etas_sq)\n\n            # Refine by bisection\n            new_node = (current_nodes[i_star] + current_nodes[i_star+1]) / 2.0\n            nodes.append(new_node)\n        \n        nodes.sort()\n        formatted_nodes = [f\"{node:.6f}\" for node in nodes]\n        all_results.append(f\"[{','.join(formatted_nodes)}]\")\n        \n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2420755"}, {"introduction": "An effective AMR algorithm relies on a trustworthy error indicator, but are these indicators always reliable? This practice shifts our focus from solving a differential equation to critically examining the AMR trigger mechanism itself. By testing a simple gradient-based indicator against a high-frequency manufactured solution, you will investigate the phenomenon of aliasing and discover how undersampling can lead to 'false positives,' causing the mesh to refine unnecessarily [@problem_id:3094969].", "problem": "You will investigate whether a simple gradient-based adaptive mesh refinement (AMR) indicator can produce false positives due to aliasing when applied to a manufactured smooth oscillatory function. Consider the periodic domain $[0,1)$ and define a manufactured solution $u(x) = \\sin(2\\pi \\nu x)$, where $\\nu$ is the number of cycles per unit length, and all trigonometric arguments are in radians. You will discretize the domain with a uniform periodic grid of $N$ points located at $x_j = j/N$ for $j \\in \\{0,1,\\dots,N-1\\}$, with grid spacing $h = 1/N$. Define a discrete gradient indicator on this grid by\n$$\nG_j = \\frac{\\left|u(x_{j+1}) - u(x_j)\\right|}{h},\n$$\nwhere the index is periodic so that $x_{N} \\equiv x_0$. A cell (index $j$) is flagged for refinement if $G_j  \\tau$, where $\\tau$ is a user-chosen threshold.\n\nTo define what constitutes a false positive due to aliasing, assume an ideal anti-aliasing low-pass filter is applied before sampling. For a monochromatic $\\sin$ wave with frequency $\\nu$, sampling at rate $N$ points per unit length has a Nyquist cutoff at $N/2$ cycles per unit length. Under this idealized model, if $\\nu \\ge N/2$ the low-pass filter completely suppresses the content before sampling, implying an ideal coarse-grid representation with $u \\equiv 0$ and hence zero gradient everywhere; if $\\nu  N/2$, the filter passes the signal unchanged. Declare a false positive if the actual sampled indicator flags at least one cell while the ideal anti-aliased indicator would flag no cells. Formally, with\n$$\n\\text{actual\\_flags}(N,\\nu,\\tau) = \\#\\{\\, j \\in \\{0,\\dots,N-1\\} \\mid G_j  \\tau \\,\\},\n$$\nthe idealized decision is\n$$\n\\text{ideal\\_flags}(N,\\nu,\\tau) = \n\\begin{cases}\n\\text{actual\\_flags}(N,\\nu,\\tau),  \\nu  N/2,\\\\\n0,  \\nu \\ge N/2,\n\\end{cases}\n$$\nand a false positive is the boolean event $\\big(\\text{actual\\_flags}(N,\\nu,\\tau)  0\\big)$ and $\\big(\\text{ideal\\_flags}(N,\\nu,\\tau) = 0\\big)$.\n\nTask: Write a complete, runnable program that, for each test case listed below, constructs the discrete samples, computes $G_j$, counts the number of flagged cells, applies the idealized anti-aliasing criterion, and outputs whether a false positive occurs.\n\nTest suite (each tuple is $(N,\\nu,\\tau)$):\n- $(32,17,10)$: frequency just above Nyquist, expect aliasing-induced flags while the ideal low-pass would remove the signal.\n- $(32,16,10)$: exactly at Nyquist, the sampled sine is identically zero at grid points.\n- $(32,8,10)$: well-resolved frequency, flags (if any) are not aliasing-induced.\n- $(33,20,10)$: above Nyquist on an odd-sized grid, expect aliasing-induced flags.\n- $(64,63,10)$: far above Nyquist but aliases to a very low discrete frequency; threshold may be high enough to suppress flags.\n\nAll computations use unitless quantities; all angles in trigonometric functions are in radians. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[True,False,False,True,False]\"). The output must be a list of booleans corresponding, in order, to the test cases above.", "solution": "The problem requires an investigation into whether a simple gradient-based adaptive mesh refinement (AMR) indicator can generate false positives due to aliasing. We are provided with a specific framework to test this phenomenon using a manufactured solution.\n\nThe problem is evaluated as valid according to the specified criteria. It is scientifically grounded in the established principles of numerical analysis and signal processing (specifically, the Nyquist-Shannon sampling theorem and finite difference approximations). It is well-posed, with all quantities, conditions, and objectives formally and unambiguously defined. The setup is self-contained, consistent, and computationally feasible. The problem poses a non-trivial question about a practical issue in computational science, making it a substantive exercise.\n\nThe analytical procedure proceeds as follows. For each test case, specified by a tuple of parameters $(N, \\nu, \\tau)$, we must determine if a false positive occurs.\n\nA false positive is formally defined as the boolean event $(\\text{actual\\_flags}(N,\\nu,\\tau)  0) \\land (\\text{ideal\\_flags}(N,\\nu,\\tau) = 0)$. The term $\\text{actual\\_flags}$ is the number of grid cells where the computed gradient indicator exceeds a threshold, while $\\text{ideal\\_flags}$ represents the number of flags that would be raised if an ideal anti-aliasing filter were applied before sampling.\n\nThe problem statement defines the behavior of this ideal filter:\n$$\n\\text{ideal\\_flags}(N,\\nu,\\tau) = \n\\begin{cases}\n\\text{actual\\_flags}(N,\\nu,\\tau),  \\nu  N/2,\\\\\n0,  \\nu \\ge N/2,\n\\end{cases}\n$$\nHere, $N$ is the number of sample points and $\\nu$ is the frequency of the continuous signal. The quantity $N/2$ is the Nyquist frequency, which is the highest frequency that can be uniquely represented at this sampling rate. The condition $\\nu \\ge N/2$ means the signal is undersampled. In this idealized model, any signal content at or above the Nyquist frequency is completely attenuated, resulting in a null signal ($u \\equiv 0$) and thus zero gradient indicators everywhere. Consequently, $\\text{ideal\\_flags} = 0$.\n\nSubstituting this definition into the false positive condition, we find that a false positive can only occur if $\\nu \\ge N/2$. The condition simplifies to:\n$$\n(\\text{actual\\_flags}(N,\\nu,\\tau)  0) \\land (\\nu \\ge N/2)\n$$\nThis forms the basis of our algorithm. For each test case $(N, \\nu, \\tau)$:\n1.  First, we check if the frequency $\\nu$ is at or above the Nyquist frequency, i.e., if $\\nu \\ge N/2$. If this condition is not met, a false positive is impossible by definition, and the result for the test case is `False`.\n2.  If $\\nu \\ge N/2$, we must then compute the actual number of flagged cells. The discrete signal values, $u_j$, are sampled from the continuous manufactured solution $u(x) = \\sin(2\\pi \\nu x)$ at the grid points $x_j = j/N$ for $j \\in \\{0, 1, \\dots, N-1\\}$. This gives:\n    $$\n    u_j = u(x_j) = \\sin\\left(2\\pi \\nu \\frac{j}{N}\\right)\n    $$\n3.  Next, we compute the discrete gradient indicator, $G_j$, for each cell. The grid spacing is $h=1/N$. The indicator is defined as the magnitude of a forward difference, normalized by the grid spacing:\n    $$\n    G_j = \\frac{\\left|u_{j+1} - u_j\\right|}{h} = N \\left|u_{j+1} - u_j\\right|\n    $$\n    The index is periodic, meaning $u_N$ is taken to be $u_0$.\n4.  We then count the number of cells for which this indicator exceeds the given threshold $\\tau$:\n    $$\n    \\text{actual\\_flags} = \\#\\{\\, j \\in \\{0,\\dots,N-1\\} \\mid G_j  \\tau \\,\\}\n    $$\n5.  Finally, if $\\text{actual\\_flags}  0$ (and we are in the case where $\\nu \\ge N/2$), a false positive has occurred, and the result for the test case is `True`. Otherwise, it is `False`.\n\nThis complete procedure will be implemented and applied to each of the provided test cases. For instance, in the case $(N, \\nu, \\tau) = (32, 17, 10)$, the Nyquist frequency is $N/2 = 16$. Since $\\nu = 17  16$, the signal is undersampled. The sampled signal $u_j = \\sin(2\\pi \\cdot 17 \\cdot j/32)$ aliases to a high-frequency oscillation, $u_j = (-1)^j \\sin(2\\pi j/32)$, which produces large gradient values. If any of these values exceed $\\tau=10$, a false positive is registered. Conversely, for $(N, \\nu, \\tau) = (32, 8, 10)$, the frequency $\\nu=8$ is below the Nyquist frequency of $16$, so the signal is well-resolved. By our definition, this case cannot produce a false positive, regardless of the value of `actual_flags`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes whether a simple gradient-based AMR indicator produces false \n    positives due to aliasing for a set of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple is (N, nu, tau)\n    # N: number of grid points\n    # nu: frequency of the sine wave\n    # tau: threshold for the gradient indicator\n    test_cases = [\n        (32, 17, 10),\n        (32, 16, 10),\n        (32, 8, 10),\n        (33, 20, 10),\n        (64, 63, 10),\n    ]\n\n    results = []\n    \n    for N, nu, tau in test_cases:\n        # A false positive is defined as (actual_flags > 0) AND (ideal_flags == 0).\n        # The condition (ideal_flags == 0) is equivalent to nu >= N/2.\n        # Therefore, a false positive occurs if nu >= N/2 AND actual_flags > 0.\n\n        # Step 1: Check if the frequency is at or above the Nyquist frequency.\n        # The Nyquist frequency is N/2 cycles per unit length.\n        nyquist_freq = N / 2.0\n        \n        if nu  nyquist_freq:\n            # If the signal is well-resolved, a false positive (as defined) cannot occur.\n            results.append(False)\n            continue\n\n        # Step 2: If undersampled (nu >= nyquist_freq), compute the actual flags.\n        # Define the grid and grid spacing.\n        # Domain is [0, 1), so grid spacing h = 1/N.\n        h = 1.0 / N\n        # Grid points x_j = j/N for j = 0, ..., N-1.\n        j = np.arange(N)\n        x = j * h\n\n        # Step 3: Sample the continuous function u(x) = sin(2*pi*nu*x) on the grid.\n        u = np.sin(2 * np.pi * nu * x)\n        \n        # Step 4: Compute the discrete gradient indicator G_j = |u_{j+1} - u_j| / h.\n        # np.roll(u, -1) provides u_{j+1} with periodic boundary conditions (u_N = u_0).\n        u_j_plus_1 = np.roll(u, -1)\n        G = np.abs(u_j_plus_1 - u) / h\n        \n        # Step 5: Count the number of cells where the indicator exceeds the threshold.\n        actual_flags = np.sum(G > tau)\n        \n        # Step 6: Determine if a false positive occurred.\n        # This happens if there are any flags raised despite the signal\n        # frequency being above the Nyquist limit.\n        is_false_positive = actual_flags > 0\n        results.append(is_false_positive)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3094969"}, {"introduction": "We now advance to a more complex and dynamic scenario involving a time-dependent advection-reaction equation, a common model in fluid dynamics. This exercise uses the Finite Volume Method (FVM), where maintaining conservation across grid levels is paramount. You will implement a two-level AMR scheme and tackle the critical challenge of designing a coarse-fine interface treatment that preserves both conservation through flux correction and physical positivity of the solution, showcasing the sophisticated techniques needed for robust AMR in real-world applications [@problem_id:3094985].", "problem": "Consider the one-dimensional advection–reaction equation for a nonnegative scalar $u(x,t)$ on the periodic domain $x \\in [0,1)$,\n$$\n\\partial_t u + \\partial_x\\left(a\\,u\\right) = S - k\\,u,\n$$\nwith constant advection speed $a \\ge 0$, constant source $S \\ge 0$, and reaction rate $k \\ge 0$. Assume that the exact solution stays nonnegative when initialized with a nonnegative state and when $S \\ge 0$.\n\nYou will design and implement a two-level Adaptive Mesh Refinement (AMR) scheme that preserves $u \\ge 0$ across coarse–fine interfaces. The base discretization is the Finite Volume Method (FVM) over cell averages. Let $u_i^n$ denote the cell average in cell $i$ at time step $n$. The FVM semi-discrete update over a uniform mesh with spacing $\\Delta x$ and time step $\\Delta t$ is\n$$\nu_i^{n+1} = u_i^n - \\frac{\\Delta t}{\\Delta x}\\left(F_{i+\\tfrac{1}{2}}^n - F_{i-\\tfrac{1}{2}}^n\\right) + \\Delta t\\,R(u_i^n),\n$$\nwhere $R(u) = S - k\\,u$ and $F_{i+\\tfrac{1}{2}}$ is a consistent numerical flux. For $a \\ge 0$, use the upwind flux\n$$\nF_{i+\\tfrac{1}{2}} = a\\,u_{i+\\tfrac{1}{2}}^{L},\n$$\nwhere $u_{i+\\tfrac{1}{2}}^{L}$ is the left-sided reconstructed value at face $i+\\tfrac{1}{2}$. A piecewise-linear reconstruction with a Total Variation Diminishing (TVD) slope limiter should be used:\n- Compute the raw slope $\\sigma_i$ using the minmod operator,\n$$\n\\sigma_i = \\text{minmod}\\left(u_i - u_{i-1},\\, u_{i+1} - u_i\\right),\n$$\nwith periodic indexing as appropriate. The minmod function is defined by\n$$\n\\text{minmod}(p,q) =\n\\begin{cases}\n\\operatorname{sign}(p)\\,\\min\\left(|p|,|q|\\right),  \\text{if } p\\,q  0,\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n- Define the left-biased face value from cell $i$ as $u_{i+\\tfrac{1}{2}}^{L,\\star} = u_i + \\tfrac{1}{2}\\,\\sigma_i$ and the right-biased face value as $u_{i-\\tfrac{1}{2}}^{R,\\star} = u_i - \\tfrac{1}{2}\\,\\sigma_i$. To guarantee positivity, rescale the slope by a factor $\\theta_i \\in [0,1]$ so that both reconstructed edge values from cell $i$ are nonnegative:\n$$\n\\theta_i = \\min\\left(1,\\ \\min\\left\\{ \\frac{u_i}{u_i - u_{i+\\tfrac{1}{2}}^{L,\\star}} \\ \\text{ if } u_{i+\\tfrac{1}{2}}^{L,\\star}0,\\ \\frac{u_i}{u_i - u_{i-\\tfrac{1}{2}}^{R,\\star}} \\ \\text{ if } u_{i-\\tfrac{1}{2}}^{R,\\star}0 \\right\\}\\right),\n$$\nwith the convention that any fraction with a nonpositive denominator is ignored, and if $u_i = 0$ then set $\\theta_i = 0$. Use the limited slope $\\tilde{\\sigma}_i = \\theta_i\\,\\sigma_i$ to form $u_{i+\\tfrac{1}{2}}^{L} = u_i + \\tfrac{1}{2}\\,\\tilde{\\sigma}_i$.\n\nFor the reaction term, apply an exact positivity-preserving update per cell for constant $S$ and $k$ over $\\Delta t$:\n- If $k  0$,\n$$\nu^{n+\\tfrac{1}{2}} = u^{n}\\,e^{-k\\,\\Delta t} + \\frac{S}{k}\\left(1 - e^{-k\\,\\Delta t}\\right).\n$$\n- If $k = 0$,\n$$\nu^{n+\\tfrac{1}{2}} = u^{n} + S\\,\\Delta t.\n$$\n\nIn the AMR setting, use two levels: a coarse grid with $N_c$ cells of width $\\Delta x_c = 1/N_c$, and a single fine patch with refinement ratio $r=2$ that covers the coarse cell indices $i \\in \\{i_0, i_0+1, \\dots, i_1-1\\}$, where $0 \\le i_0  i_1 \\le N_c$. The fine grid has $N_f = r\\,(i_1 - i_0)$ cells of width $\\Delta x_f = \\Delta x_c / r$. Use a single global time step $\\Delta t$ chosen by the Courant–Friedrichs–Lewy (CFL) condition from the smallest cell size:\n$$\n\\Delta t = \\nu\\,\\frac{\\min(\\Delta x_c,\\Delta x_f)}{a},\n$$\nwith a prescribed CFL number $\\nu \\in (0,1]$.\n\nTo ensure conservation and positivity at the coarse–fine interfaces:\n- Let the left boundary of the fine patch coincide with the coarse face at index $i_0$ and the right boundary coincide with coarse face $i_1$. For $a \\ge 0$:\n  - At face $i_0$ (upwind side outside the patch), compute the left state using the coarse cell $i_0-1$ with the limited slope. Use that same left state for the fine-grid face at the left boundary.\n  - At face $i_1$ (upwind side inside the patch), compute the left state using the last fine cell within the patch with its limited slope. Override the coarse-grid left state at face $i_1$ to equal this fine-grid left state (flux correction).\n- Update both levels with the same $\\Delta t$, then restrict (average) the fine solution back onto the coarse cells covered by the patch, replacing those coarse-cell values to maintain consistency.\n\nBoundary conditions are periodic on the coarse grid. Within the fine patch, use the interface prescriptions described above; do not use time subcycling.\n\nTasks:\n- Implement the above two-level AMR FVM with the described positivity-preserving slope rescaling and interface flux correction for $a \\ge 0$.\n- Use the exact per-cell reaction update to preserve positivity.\n- Use periodic boundary conditions on the coarse grid.\n\nTest suite:\nRun the solver for each of the following parameter sets. In all cases, take $\\nu = 0.45$ and $a = 1.0$. Initialize both levels from the continuous initial condition $u(x,0)$, then restrict the fine patch to the coarse level in covered cells so that the composite solution is consistent. The domain is $[0,1)$ with cell centers at $x_i = (i+0.5)\\Delta x$.\n\nCase $1$ (smooth “happy path”):\n- $N_c = 32$, $(i_0,i_1) = (8,12)$.\n- Reaction: $k = 0.0$, $S = 0.0$.\n- Initial condition: Gaussian $u(x,0) = A \\exp\\left(-\\frac{(x-x_0)^2}{2\\,\\sigma^2}\\right)$ with $A=1.0$, $x_0=0.25$, $\\sigma=0.07$.\n- Steps: $50$.\n\nCase $2$ (steep front near zero to test limiters at the interface):\n- $N_c = 32$, $(i_0,i_1) = (8,12)$.\n- Reaction: $k = 0.0$, $S = 0.0$.\n- Initial condition: step $u(x,0) = A$ if $x  x_c$ and $u(x,0)=0$ otherwise, with $A=1.0$, $x_c=0.40$.\n- Steps: $80$.\n\nCase $3$ (strong reaction sink with weak source):\n- $N_c = 32$, $(i_0,i_1) = (8,12)$.\n- Reaction: $k = 20.0$, $S = 0.1$.\n- Initial condition: constant $u(x,0) = 0.05$.\n- Steps: $40$.\n\nCase $4$ (narrow spike crossing the patch boundary):\n- $N_c = 32$, $(i_0,i_1) = (8,12)$.\n- Reaction: $k = 0.0$, $S = 0.0$.\n- Initial condition: triangular spike of width $w=0.02$ centered at $x_s=0.49$, height $A=1.0$:\n  $$\n  u(x,0) = \\max\\left(0,\\ A\\left(1 - \\frac{|x-x_s|}{w}\\right)\\right).\n  $$\n- Steps: $60$.\n\nAnswer specification:\n- For each case, compute the minimum value of the composite AMR solution (fine values inside the patch and coarse values outside) at the final time. Return a boolean indicating whether the minimum is greater than or equal to $-10^{-10}$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$), where each $result_j$ is either True or False.", "solution": "The solution implements a two-level Adaptive Mesh Refinement (AMR) scheme for the one-dimensional advection-reaction equation, $\\partial_t u + \\partial_x(au) = S - ku$. The implementation adheres strictly to the specifications provided, including the finite volume discretization, piecewise-linear Total Variation Diminishing (TVD) reconstruction, a positivity-preserving slope limiter, an exact reaction-term solver, and a conservative coarse-fine interface treatment.\n\n**1. Grid and State Initialization**\n- Two grids are established: a coarse grid with $N_c$ cells spanning the domain $[0,1)$, and a single fine-to-coarse ratio $r=2$ patch covering a specified range of coarse cells.\n- The initial condition for both grids is determined by computing the cell-average of the given continuous function $u(x,0)$ over each cell's domain. This is crucial for accurately representing sharp features like step functions or triangular spikes. For smooth functions like a Gaussian, this is well-approximated by evaluating the function at the cell center.\n- To ensure the initial state is consistent across levels, the initial fine-grid solution is restricted (averaged) onto the coarse cells it covers, overwriting their values.\n\n**2. Time Evolution**\nA global time step $\\Delta t$ is computed based on the Courant–Friedrichs–Lewy (CFL) condition for the fine grid, as it has the smallest cells and thus the most restrictive stability constraint. The solution is advanced in time using operator splitting, where the reaction and advection operators are applied sequentially.\n\n**2.1. Reaction Step**\nThe reaction part of the equation, $\\partial_t u = S - ku$, is solved first for each cell independently over the time step $\\Delta t$. The problem specifies using the exact solution for this ordinary differential equation, which guarantees that if $u \\ge 0$ and $S \\ge 0$, the solution will remain non-negative. The update formulas are:\n- For $k  0$: $u^* = u^n e^{-k\\Delta t} + \\frac{S}{k}(1 - e^{-k\\Delta t})$\n- For $k = 0$: $u^* = u^n + S\\Delta t$\nThis update is applied to all cells on both the coarse and fine grids.\n\n**2.2. Advection Step**\nThe advection part, $\\partial_t u + \\partial_x(au) = 0$, is solved using a conservative finite volume scheme.\n\n**2.2.1. Reconstruction and Slope Limiting**\nTo achieve second-order accuracy, a piecewise-linear polynomial is reconstructed within each cell $i$, $u_i(x) = u_i + \\tilde{\\sigma}_i \\frac{x-x_i}{\\Delta x}$.\n- The raw slope $\\sigma_i$ is computed using the `minmod` limiter, $\\sigma_i = \\text{minmod}(u_i - u_{i-1}, u_{i+1} - u_i)$, which prevents spurious oscillations near sharp gradients. For the coarse grid, periodic boundary conditions are used. For the fine grid, ghost cells are required.\n- The values for the fine-grid ghost cells are derived from the reconstructed solution in the adjacent coarse cells. For a refinement ratio $r=2$, the value for the left ghost cell (adjacent to coarse cell $i_0-1$) is $u_{c, i_0-1} + \\tilde{\\sigma}_{c, i_0-1} (\\Delta x_c / 4)$, where $\\tilde{\\sigma}_{c, i_0-1}$ is the limited slope in the coarse cell. A similar calculation provides the right ghost cell value from coarse cell $i_1$.\n- The raw slope $\\sigma_i$ is then rescaled by a factor $\\theta_i$ to form the limited slope $\\tilde{\\sigma}_i = \\theta_i \\sigma_i$. This rescaling enforces positivity by ensuring that the reconstructed values at the cell edges, $u_i \\pm \\frac{1}{2}\\tilde{\\sigma}_i$, do not become negative. The scaling factor is $\\theta_i = \\min(1, \\frac{2u_i}{|\\sigma_i|})$ for $u_i  0, \\sigma_i \\ne 0$, and $\\theta_i=0$ if $u_i=0$. This is an efficient implementation of the provided formula for $\\theta_i$.\n\n**2.2.2. Flux Calculation and Interface Correction**\nWith the limited slopes, the state at the left side of each cell face is computed as $u_{i+1/2}^L = u_i + \\frac{1}{2}\\tilde{\\sigma}_i$. The upwind numerical flux is $F_{i+1/2} = a u_{i+1/2}^L$.\n- **Coarse-Fine Interface (Left, $x_{i_0}$):** The flux entering the fine patch is determined by the state in the coarse cell to its left, $i_0-1$. This flux, $F_{i_0-1/2}$, is computed using the coarse grid reconstruction and used as the inflow flux for the first fine cell. This ensures consistency as information flows into the refined region.\n- **Fine-Coarse Interface (Right, $x_{i_1}$):** The flux leaving the fine patch, computed from the last fine cell, is more accurate than the flux that would be computed from the coarse grid. Therefore, the coarse grid flux at this interface, $F_{i_1-1/2}$, is overridden with the value computed from the fine grid. This is a conservative flux correction that injects high-resolution information back into the coarse grid.\n\n**2.2.3. Finite Volume Update**\nThe cell averages are updated using the conservative formula $u_i^{n+1} = u_i^* - \\frac{\\Delta t}{\\Delta x}(F_{i+1/2} - F_{i-1/2})$. This update is performed for all fine cells and for coarse cells *not* covered by the fine patch.\n\n**2.3. Restriction Step**\nTo complete the time step, the solution on both levels must be synchronized. The coarse cell averages under the fine patch are replaced by the average of the corresponding fine cell values. For $r=2$, this means $u_{c,i}^{n+1} = \\frac{1}{2}(u_{f,2(i-i_0)}^{n+1} + u_{f,2(i-i_0)+1}^{n+1})$ for $i \\in [i_0, i_1-1]$.\n\n**3. Final Analysis**\nAfter the specified number of time steps, a composite solution is formed by taking the fine grid values within the patch and the coarse grid values outside. The minimum value of this composite solution is computed to verify the positivity-preserving nature of the scheme. A small tolerance is used to account for floating-point arithmetic.", "answer": "```python\nimport numpy as np\n\ndef minmod(p, q):\n    \"\"\"The minmod limiter function.\"\"\"\n    if p * q > 0:\n        return np.sign(p) * min(abs(p), abs(q))\n    else:\n        return 0.0\n\ndef get_limited_slopes(u, u_len, periodic, dx):\n    \"\"\"Computes positivity-preserving limited slopes for a given solution array.\"\"\"\n    slopes_raw = np.zeros(u_len)\n    u_vals_for_slope = u\n    if not periodic:\n        # u is expected to be padded with one ghost cell on each side\n        u_vals_for_slope = u[1:-1]\n\n    for i in range(u_len):\n        if periodic:\n            u_prev = u[(i - 1 + u_len) % u_len]\n            u_curr = u[i]\n            u_next = u[(i + 1) % u_len]\n        else: # Padded array\n            u_prev = u[i]\n            u_curr = u[i + 1]\n            u_next = u[i + 2]\n        \n        delta_L = u_curr - u_prev\n        delta_R = u_next - u_curr\n        slopes_raw[i] = minmod(delta_L, delta_R) / dx\n\n    slopes_limited = np.zeros(u_len)\n    for i in range(u_len):\n        u_i = u_vals_for_slope[i]\n        sigma_i = slopes_raw[i] * dx # Use dimensionless slope for reconstruction logic\n        \n        if u_i  1e-12:\n            theta_i = 0.0\n        else:\n            if abs(sigma_i)  1e-12:\n                theta_i = 1.0\n            else:\n                # Based on reconstruction u_i +/- 0.5 * theta * sigma_i >= 0\n                theta_i = min(1.0, 2.0 * u_i / abs(sigma_i))\n\n        slopes_limited[i] = theta_i * slopes_raw[i]\n        \n    return slopes_limited\n\ndef apply_reaction(u, k, S, dt):\n    \"\"\"Applies the exact reaction update for a time step dt.\"\"\"\n    if k > 0:\n        return u * np.exp(-k * dt) + (S / k) * (1 - np.exp(-k * dt))\n    else:\n        return u + S * dt\n\ndef get_cell_averaged_ic(x_centers, dx, ic_type, ic_params):\n    \"\"\"Computes cell-averaged initial conditions.\"\"\"\n    if ic_type == 'gauss':\n        return ic_params['A'] * np.exp(-(x_centers - ic_params['x0'])**2 / (2 * ic_params['sigma']**2))\n    \n    x_L = x_centers - 0.5 * dx\n    x_R = x_centers + 0.5 * dx\n    u_avg = np.zeros_like(x_centers)\n    \n    if ic_type == 'step':\n        A, xc = ic_params['A'], ic_params['xc']\n        u_avg[x_R = xc] = A\n        u_avg[x_L >= xc] = 0.0\n        mask = (x_L  xc)  (x_R > xc)\n        u_avg[mask] = A * (xc - x_L[mask]) / dx\n        return u_avg\n        \n    if ic_type == 'triangle':\n        A, xs, w = ic_params['A'], ic_params['xs'], ic_params['w']\n        def F(x): # Primitive of the triangle function\n            return A * (x - (x - xs) * abs(x - xs) / (2.0 * w))\n        \n        for i in range(len(x_centers)):\n            a, b = x_L[i], x_R[i]\n            c, d = xs - w, xs + w\n            # Intersection of cell and triangle's support\n            isect_start = max(a, c)\n            isect_end = min(b, d)\n            if isect_start  isect_end:\n                integral = F(isect_end) - F(isect_start)\n                u_avg[i] = integral / dx\n        return u_avg\n\ndef run_simulation(case_params):\n    \"\"\"Runs a single AMR simulation case.\"\"\"\n    Nc, (i0, i1) = case_params['Nc'], case_params['i0_i1']\n    k, S = case_params['k'], case_params['S']\n    steps = case_params['steps']\n    a, nu, r = 1.0, 0.45, 2\n\n    # Grids\n    dx_c = 1.0 / Nc\n    xc = (np.arange(Nc) + 0.5) * dx_c\n    Nf = r * (i1 - i0)\n    dx_f = dx_c / r\n    patch_start_x = i0 * dx_c\n    xf = patch_start_x + (np.arange(Nf) + 0.5) * dx_f\n    dt = nu * dx_f / a\n\n    # Initial conditions\n    u_c = get_cell_averaged_ic(xc, dx_c, case_params['ic_type'], case_params['ic_params'])\n    u_f = get_cell_averaged_ic(xf, dx_f, case_params['ic_type'], case_params['ic_params'])\n    \n    # Initial restriction\n    for i in range(i0, i1):\n        j = r * (i - i0)\n        u_c[i] = np.mean(u_f[j:j+r])\n\n    # Time-stepping loop\n    for _ in range(steps):\n        u_c_react = apply_reaction(u_c, k, S, dt)\n        u_f_react = apply_reaction(u_f, k, S, dt)\n\n        tilde_sigma_c_dim = get_limited_slopes(u_c_react, Nc, periodic=True, dx=dx_c)\n        \n        idx_c_left = (i0 - 1 + Nc) % Nc\n        idx_c_right = i1 % Nc if i1  Nc else 0\n        \n        # Extrapolate to find ghost cell averages\n        u_g_L = u_c_react[idx_c_left] + 0.25 * tilde_sigma_c_dim[idx_c_left] * dx_c\n        u_g_R = u_c_react[idx_c_right] - 0.25 * tilde_sigma_c_dim[idx_c_right] * dx_c\n\n        u_f_padded = np.concatenate(([u_g_L], u_f_react, [u_g_R]))\n        tilde_sigma_f_dim = get_limited_slopes(u_f_padded, Nf, periodic=False, dx=dx_f)\n        \n        # Fluxes\n        F_c = a * (u_c_react + 0.5 * tilde_sigma_c_dim * dx_c)\n        F_f_internal = a * (u_f_react + 0.5 * tilde_sigma_f_dim * dx_f)\n        F_f = np.zeros(Nf + 1)\n        F_f[0] = F_c[idx_c_left]\n        F_f[1:] = F_f_internal\n        \n        # Flux correction\n        F_c[(i1 - 1 + Nc) % Nc] = F_f[-1]\n\n        # Update\n        u_f_new = u_f_react - (dt/dx_f) * (F_f[1:] - F_f[:-1])\n        u_c_new = u_c_react.copy()\n        \n        coarse_mask = np.ones(Nc, dtype=bool)\n        if i0  i1: coarse_mask[i0:i1] = False\n        F_c_left = np.roll(F_c, 1)\n        dF = F_c - F_c_left\n        u_c_new[coarse_mask] -= (dt/dx_c) * dF[coarse_mask]\n\n        # Restriction\n        for i in range(i0, i1):\n            j = r * (i - i0)\n            u_c_new[i] = np.mean(u_f_new[j:j+r])\n            \n        u_c, u_f = u_c_new, u_f_new\n\n    # Final minimum value check\n    coarse_mask = np.ones(Nc, dtype=bool)\n    if i0  i1: coarse_mask[i0:i1] = False\n    min_coarse = np.min(u_c[coarse_mask]) if np.any(coarse_mask) else np.inf\n    min_fine = np.min(u_f) if Nf > 0 else np.inf\n    \n    return min(min_coarse, min_fine) >= -1.0e-10\n\ndef solve():\n    test_cases = [\n        {\n            \"Nc\": 32, \"i0_i1\": (8, 12), \"k\": 0.0, \"S\": 0.0, \"steps\": 50,\n            \"ic_type\": \"gauss\", \"ic_params\": {\"A\": 1.0, \"x0\": 0.25, \"sigma\": 0.07}\n        },\n        {\n            \"Nc\": 32, \"i0_i1\": (8, 12), \"k\": 0.0, \"S\": 0.0, \"steps\": 80,\n            \"ic_type\": \"step\", \"ic_params\": {\"A\": 1.0, \"xc\": 0.40}\n        },\n        {\n            \"Nc\": 32, \"i0_i1\": (8, 12), \"k\": 20.0, \"S\": 0.1, \"steps\": 40,\n            \"ic_type\": \"step\", \"ic_params\": {\"A\": 0.05, \"xc\": 2.0} # step IC u=0.05 everywhere\n        },\n        {\n            \"Nc\": 32, \"i0_i1\": (8, 12), \"k\": 0.0, \"S\": 0.0, \"steps\": 60,\n            \"ic_type\": \"triangle\", \"ic_params\": {\"A\": 1.0, \"xs\": 0.49, \"w\": 0.02}\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(run_simulation(case))\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3094985"}]}