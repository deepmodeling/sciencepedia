{"hands_on_practices": [{"introduction": "To build our practical skills, we begin with a foundational exercise in analytical sensitivity analysis. We will explore a classic RLC circuit, a cornerstone of electrical engineering, to understand how its resonance frequency $\\omega_0$ responds to manufacturing imperfections in one of its components. By using basic calculus to derive the normalized sensitivity, this practice [@problem_id:3272518] provides a clear, \"pen-and-paper\" illustration of how to quantify the relationship between a parameter and a system's behavior.", "problem": "A Resistor–Inductor–Capacitor (RLC) series circuit is driven in sinusoidal steady state by a source at angular frequency $\\omega$. The impedance of the inductor is $j \\omega L$, the impedance of the capacitor is $\\frac{1}{j \\omega C}$, and the impedance of the resistor is $R$, where $j$ denotes the imaginary unit, $L$ is the inductance, $C$ is the capacitance, and $R$ is the resistance. In the usual engineering sense of resonance for a series RLC network, the resonance angular frequency $\\omega_{0}$ is defined as the frequency at which the net reactance is zero, so that the impedance is purely real. \n\nManufacturing tolerance in the capacitor means that the realized capacitance is $C + \\delta C$ with $|\\delta C| \\ll C$. Using first principles (the impedance definition and the resonance condition), derive the resonance angular frequency $\\omega_{0}$ as a function of $L$ and $C$, and then from the total differential define the normalized sensitivity of $\\omega_{0}$ with respect to $C$ as\n$$\nS_{C} \\equiv \\frac{C}{\\omega_{0}} \\frac{\\partial \\omega_{0}}{\\partial C}.\n$$\nCompute $S_{C}$, expressing your final answer as a single real number. No rounding is required, and no units are to be provided with the final answer.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in circuit analysis and sensitivity theory. We may proceed with the solution.\n\nThe total impedance $Z$ of a series RLC circuit is the sum of the individual impedances of the resistor ($R$), inductor ($L$), and capacitor ($C$). The impedances are given as $Z_R = R$, $Z_L = j \\omega L$, and $Z_C = \\frac{1}{j \\omega C}$, where $j$ is the imaginary unit satisfying $j^2 = -1$.\n\nThe total impedance as a function of angular frequency $\\omega$ is:\n$$\nZ(\\omega) = Z_R + Z_L + Z_C = R + j \\omega L + \\frac{1}{j \\omega C}\n$$\nUsing the property $\\frac{1}{j} = -j$, we can rewrite the impedance as:\n$$\nZ(\\omega) = R + j \\omega L - \\frac{j}{\\omega C} = R + j \\left(\\omega L - \\frac{1}{\\omega C}\\right)\n$$\nThe impedance $Z(\\omega)$ is a complex number with a real part (resistance) and an imaginary part (reactance). The real part is $\\text{Re}(Z) = R$, and the imaginary part, or net reactance, is $\\text{Im}(Z) = X(\\omega) = \\omega L - \\frac{1}{\\omega C}$.\n\nThe problem defines the resonance angular frequency, $\\omega_0$, as the frequency at which the net reactance is zero. This condition implies that the imaginary part of the total impedance vanishes:\n$$\n\\text{Im}(Z(\\omega_0)) = 0\n$$\nSubstituting the expression for the reactance, we get:\n$$\n\\omega_0 L - \\frac{1}{\\omega_0 C} = 0\n$$\nTo solve for $\\omega_0$, we rearrange the equation:\n$$\n\\omega_0 L = \\frac{1}{\\omega_0 C}\n$$\n$$\n\\omega_0^2 = \\frac{1}{LC}\n$$\nSince angular frequency must be a positive quantity, we take the positive square root:\n$$\n\\omega_0 = \\frac{1}{\\sqrt{LC}} = (LC)^{-1/2}\n$$\nThis is the expression for the resonance angular frequency as a function of inductance $L$ and capacitance $C$.\n\nNext, we must compute the normalized sensitivity of $\\omega_0$ with respect to $C$, which is defined as:\n$$\nS_{C} \\equiv \\frac{C}{\\omega_{0}} \\frac{\\partial \\omega_{0}}{\\partial C}\n$$\nTo compute this, we first need to find the partial derivative of $\\omega_0$ with respect to $C$. We treat $L$ as a constant.\n$$\n\\omega_0(C) = L^{-1/2} C^{-1/2}\n$$\nUsing the power rule for differentiation, $\\frac{d}{dx}(x^n) = nx^{n-1}$, we get:\n$$\n\\frac{\\partial \\omega_0}{\\partial C} = L^{-1/2} \\left(-\\frac{1}{2} C^{-1/2 - 1}\\right) = L^{-1/2} \\left(-\\frac{1}{2} C^{-3/2}\\right)\n$$\n$$\n\\frac{\\partial \\omega_0}{\\partial C} = -\\frac{1}{2} L^{-1/2} C^{-3/2}\n$$\nNow, we substitute the expressions for $\\omega_0$ and $\\frac{\\partial \\omega_0}{\\partial C}$ into the sensitivity formula:\n$$\nS_C = \\frac{C}{\\omega_0} \\left( -\\frac{1}{2} L^{-1/2} C^{-3/2} \\right)\n$$\nSubstitute $\\omega_0 = (LC)^{-1/2} = L^{-1/2}C^{-1/2}$:\n$$\nS_C = \\frac{C}{L^{-1/2}C^{-1/2}} \\left( -\\frac{1}{2} L^{-1/2} C^{-3/2} \\right)\n$$\nWe can simplify this expression by combining the terms:\n$$\nS_C = -\\frac{1}{2} \\cdot \\frac{C}{L^{-1/2}C^{-1/2}} \\cdot L^{-1/2} C^{-3/2}\n$$\nThe terms involving $L$ cancel out: $L^{-1/2}$ in the numerator and $L^{-1/2}$ in the denominator.\n$$\nS_C = -\\frac{1}{2} \\cdot \\frac{C}{C^{-1/2}} \\cdot C^{-3/2}\n$$\nNow, combine the powers of $C$:\n$$\nS_C = -\\frac{1}{2} \\cdot C^{1 - (-1/2) - 3/2} = -\\frac{1}{2} \\cdot C^{1 + 1/2 - 3/2} = -\\frac{1}{2} \\cdot C^{3/2 - 3/2} = -\\frac{1}{2} \\cdot C^0\n$$\nSince any non-zero quantity raised to the power of $0$ is $1$, we have:\n$$\nS_C = -\\frac{1}{2}\n$$\nThe normalized sensitivity of the resonance angular frequency with respect to the capacitance is a constant value of $-\\frac{1}{2}$. This signifies that a small fractional increase in capacitance leads to a fractional decrease in the resonance frequency of half that magnitude. For instance, a $1\\%$ increase in $C$ results in approximately a $0.5\\%$ decrease in $\\omega_0$.", "answer": "$$\\boxed{-\\frac{1}{2}}$$", "id": "3272518"}, {"introduction": "While analytical methods provide clear insight, many real-world systems are too complex for them and require computational approaches. This next practice [@problem_id:3191044] moves into the realm of Partial Differential Equations (PDEs), which model phenomena from heat transfer to structural mechanics. We will numerically investigate how the solution to a diffusion-reaction equation is sensitive to small perturbations in its boundary conditions, a common and critical question in engineering and physics that is often tackled with numerical methods like the finite difference scheme.", "problem": "You are asked to quantify and compute the sensitivity of a linear partial differential equation (PDE) solution with respect to perturbations of Dirichlet boundary data. Consider the one-dimensional steady diffusion–reaction equation on a domain $\\Omega = (0,L)$:\n$$\n-\\,k\\,\\frac{d^2 u}{dx^2} + c\\,u = f \\quad \\text{on } (0,L),\n$$\nwith Dirichlet boundary conditions\n$$\nu(0) = g_0 + \\delta g_0, \\quad u(L) = g_L + \\delta g_L,\n$$\nwhere $k > 0$ is the diffusion coefficient, $c \\ge 0$ is the reaction coefficient, $f$ is a given source term, and $(\\delta g_0,\\delta g_L)$ are small boundary perturbations. All quantities are dimensionless. Define $u(\\delta g)$ as the solution corresponding to the perturbed boundary $(g_0+\\delta g_0, g_L+\\delta g_L)$ and $u(0)$ as the baseline solution with $(\\delta g_0,\\delta g_L) = (0,0)$. The sensitivity to boundary perturbations is measured by the ratio\n$$\n\\alpha = \\frac{\\|u(\\delta g) - u(0)\\|}{\\|(\\delta g_0,\\delta g_L)\\|},\n$$\nwhere the numerator is the $L^2$ norm over $(0,L)$ and the denominator is the Euclidean norm on the boundary data vector.\n\nYour task is to:\n- Start from the principle of linear superposition for linear PDEs and construct the difference field $w = u(\\delta g) - u(0)$, which solves the homogeneous equation with inhomogeneous Dirichlet boundary data.\n- Approximate $w$ numerically using a second-order centered finite difference (FD) discretization with $N$ interior nodes. Use a uniform grid with spacing $h = L/(N+1)$. For the operator $-k\\,u'' + c\\,u$, the standard FD scheme for interior node index $i \\in \\{1,\\dots,N\\}$ is\n$$\n-\\,k\\,\\frac{w_{i-1} - 2w_i + w_{i+1}}{h^2} + c\\,w_i = 0,\n$$\nwith Dirichlet values $w_0 = \\delta g_0$ and $w_{N+1} = \\delta g_L$ entering the right-hand side of the first and last interior equations, respectively.\n- Use the discrete $L^2$ norm on the interior to approximate the numerator:\n$$\n\\|w\\|_{L^2(0,L)} \\approx \\left( h \\sum_{i=1}^{N} w_i^2 \\right)^{1/2}.\n$$\n- Use the Euclidean norm for the boundary perturbation magnitude:\n$$\n\\|(\\delta g_0,\\delta g_L)\\| = \\left( (\\delta g_0)^2 + (\\delta g_L)^2 \\right)^{1/2}.\n$$\n- Compute the sensitivity ratio $\\alpha$ for each test case below.\n\nImplementation requirements:\n- Use a linear system solver to compute the interior values $(w_1,\\dots,w_N)$.\n- Use only second-order centered finite differences as described above.\n- All quantities are dimensionless; no physical units are required.\n- Report each sensitivity ratio $\\alpha$ as a floating-point number rounded to $6$ decimal places.\n\nTest suite:\nFor each tuple $(L,k,c,N,\\delta g_0,\\delta g_L)$, compute the corresponding sensitivity ratio $\\alpha$:\n- Test $1$: $(L,k,c,N,\\delta g_0,\\delta g_L) = (\\,1.0,\\,1.0,\\,0.0,\\,200,\\,0.1,\\,-0.05\\,)$.\n- Test $2$: $(L,k,c,N,\\delta g_0,\\delta g_L) = (\\,5.0,\\,1.0,\\,0.0,\\,200,\\,0.1,\\,-0.05\\,)$.\n- Test $3$: $(L,k,c,N,\\delta g_0,\\delta g_L) = (\\,1.0,\\,1.0,\\,1.0,\\,200,\\,0.1,\\,-0.05\\,)$.\n- Test $4$: $(L,k,c,N,\\delta g_0,\\delta g_L) = (\\,0.25,\\,1.0,\\,10.0,\\,100,\\,0.0,\\,0.2\\,)$.\n- Test $5$: $(L,k,c,N,\\delta g_0,\\delta g_L) = (\\,2.0,\\,0.5,\\,0.0,\\,300,\\,0.05,\\,0.05\\,)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the $5$ rounded sensitivity ratios in the order of the tests, enclosed in square brackets, for example, \"[a,b,c,d,e]\". Each entry must be rounded to $6$ decimal places and printed in standard decimal notation without scientific notation.\n\nNote: You must provide a complete, runnable program that implements the finite difference method as specified and outputs the results in the exact format described. Do not read any input; hard-code the test suite in your program.", "solution": "The user-provided problem is assessed to be valid. It is scientifically sound, well-posed, and all necessary parameters for a complete numerical solution are provided. The problem asks for the computation of a sensitivity ratio for a linear partial differential equation (PDE) with respect to boundary condition perturbations, a standard procedure in sensitivity analysis within computational science.\n\nThe solution proceeds in four fundamental steps:\n1.  Derivation of the governing equation for the solution difference.\n2.  Discretization of this equation using the finite difference method.\n3.  Formulation and solution of the resulting system of linear equations.\n4.  Calculation of the sensitivity ratio using discrete norms.\n\n**1. The Principle of Superposition and the Difference Field**\nThe governing PDE is a linear second-order ordinary differential equation:\n$$\n-\\,k\\,\\frac{d^2 u}{dx^2} + c\\,u = f \\quad \\text{for } x \\in (0,L)\n$$\nLet us denote the linear differential operator as $\\mathcal{L}u = -k\\,u'' + c\\,u$. The problem involves a baseline solution, $u(0)$, corresponding to boundary conditions $u(0) = g_0$ and $u(L) = g_L$, and a perturbed solution, $u(\\delta g)$, corresponding to boundary conditions $u(0) = g_0 + \\delta g_0$ and $u(L) = g_L + \\delta g_L$.\n\nThe equations for the two scenarios are:\n$$\n\\mathcal{L}u(0) = f, \\quad \\text{with B.C.s } u(0)(0) = g_0, u(0)(L) = g_L\n$$\n$$\n\\mathcal{L}u(\\delta g) = f, \\quad \\text{with B.C.s } u(\\delta g)(0) = g_0 + \\delta g_0, u(\\delta g)(L) = g_L + \\delta g_L\n$$\nWe are interested in the difference field, defined as $w = u(\\delta g) - u(0)$. Due to the linearity of the operator $\\mathcal{L}$, we can write:\n$$\n\\mathcal{L}w = \\mathcal{L}(u(\\delta g) - u(0)) = \\mathcal{L}u(\\delta g) - \\mathcal{L}u(0) = f - f = 0\n$$\nThus, the difference field $w$ satisfies the homogeneous version of the original PDE:\n$$\n-\\,k\\,\\frac{d^2 w}{dx^2} + c\\,w = 0\n$$\nThe boundary conditions for $w$ are found by subtracting the baseline boundary conditions from the perturbed ones:\n$$\nw(0) = u(\\delta g)(0) - u(0)(0) = (g_0 + \\delta g_0) - g_0 = \\delta g_0\n$$\n$$\nw(L) = u(\\delta g)(L) - u(0)(L) = (g_L + \\delta g_L) - g_L = \\delta g_L\n$$\nThis derivation confirms that the sensitivity of the solution to boundary perturbations can be analyzed by solving a simpler, homogeneous PDE for the difference field $w$ with the perturbations themselves as the new boundary conditions.\n\n**2. Finite Difference Discretization**\nTo solve for $w(x)$ numerically, we discretize the domain $(0,L)$ using a uniform grid with $N$ interior nodes. The grid points are $x_i = i h$ for $i = 0, 1, \\dots, N+1$, where the grid spacing is $h = L/(N+1)$. The discrete solution at these nodes is denoted by $w_i \\approx w(x_i)$.\n\nThe second derivative $w''(x_i)$ at an interior node $x_i$ is approximated using a second-order centered finite difference formula:\n$$\n\\frac{d^2 w}{dx^2}\\bigg|_{x=x_i} \\approx \\frac{w_{i-1} - 2w_i + w_{i+1}}{h^2}\n$$\nSubstituting this into the homogeneous PDE for $w$ gives the discrete equation for each interior node $i \\in \\{1, 2, \\dots, N\\}$:\n$$\n-\\,k\\,\\frac{w_{i-1} - 2w_i + w_{i+1}}{h^2} + c\\,w_i = 0\n$$\nRearranging this equation to group terms involving the unknown values $w_1, \\dots, w_N$ on the left-hand side yields:\n$$\n-\\frac{k}{h^2}w_{i-1} + \\left(\\frac{2k}{h^2} + c\\right)w_i - \\frac{k}{h^2}w_{i+1} = 0\n$$\n\n**3. Linear System Formulation and Solution**\nThe set of $N$ discrete equations forms a system of linear equations, which can be written in matrix form as $A\\mathbf{w} = \\mathbf{b}$, where $\\mathbf{w} = [w_1, w_2, \\dots, w_N]^T$ is the vector of unknown solution values at the interior nodes.\n\nThe boundary values $w_0 = \\delta g_0$ and $w_{N+1} = \\delta g_L$ are known quantities. They are incorporated into the equations for the first ($i=1$) and last ($i=N$) interior nodes:\n\nFor $i=1$:\n$$\n-\\frac{k}{h^2}w_0 + \\left(\\frac{2k}{h^2} + c\\right)w_1 - \\frac{k}{h^2}w_2 = 0 \\implies \\left(\\frac{2k}{h^2} + c\\right)w_1 - \\frac{k}{h^2}w_2 = \\frac{k}{h^2}w_0 = \\frac{k}{h^2}\\delta g_0\n$$\n\nFor $i=N$:\n$$\n-\\frac{k}{h^2}w_{N-1} + \\left(\\frac{2k}{h^2} + c\\right)w_N - \\frac{k}{h^2}w_{N+1} = 0 \\implies -\\frac{k}{h^2}w_{N-1} + \\left(\\frac{2k}{h^2} + c\\right)w_N = \\frac{k}{h^2}w_{N+1} = \\frac{k}{h^2}\\delta g_L\n$$\nThe resulting $N \\times N$ matrix $A$ is a symmetric tridiagonal matrix with the following structure:\n-   Main diagonal entries: $A_{ii} = \\frac{2k}{h^2} + c$\n-   Sub-diagonal and super-diagonal entries: $A_{i,i-1} = A_{i,i+1} = -\\frac{k}{h^2}$\n\nThe right-hand side vector $\\mathbf{b}$ is of size $N \\times 1$:\n$$\n\\mathbf{b} = \\begin{bmatrix} (k/h^2)\\delta g_0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ (k/h^2)\\delta g_L \\end{bmatrix}\n$$\nThis linear system $A\\mathbf{w}=\\mathbf{b}$ is solved for the vector $\\mathbf{w}$ using a standard linear algebra solver. For the given parameters ($k>0, c \\ge 0$), the matrix $A$ is strictly diagonally dominant, guaranteeing a unique solution.\n\n**4. Sensitivity Ratio Calculation**\nThe sensitivity ratio $\\alpha$ is defined as the ratio of the norms of the output difference and the input perturbation:\n$$\n\\alpha = \\frac{\\|w\\|_{L^2(0,L)}}{\\|(\\delta g_0,\\delta g_L)\\|}\n$$\nThe numerator is approximated using the discrete $L^2$ norm, which involves a sum over the computed interior solution values $w_i$:\n$$\n\\|w\\|_{L^2(0,L)} \\approx \\left( h \\sum_{i=1}^{N} w_i^2 \\right)^{1/2}\n$$\nThe denominator is the standard Euclidean norm of the boundary perturbation vector:\n$$\n\\|(\\delta g_0,\\delta g_L)\\| = \\sqrt{(\\delta g_0)^2 + (\\delta g_L)^2}\n$$\nBy computing these two norms from the solved vector $\\mathbf{w}$ and the given perturbations $(\\delta g_0, \\delta g_L)$, the sensitivity ratio $\\alpha$ is calculated for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity ratio for a series of test cases based on a\n    finite difference discretization of a diffusion-reaction PDE.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (L, k, c, N, delta_g0, delta_gL)\n        (1.0, 1.0, 0.0, 200, 0.1, -0.05),\n        (5.0, 1.0, 0.0, 200, 0.1, -0.05),\n        (1.0, 1.0, 1.0, 200, 0.1, -0.05),\n        (0.25, 1.0, 10.0, 100, 0.0, 0.2),\n        (2.0, 0.5, 0.0, 300, 0.05, 0.05),\n    ]\n\n    results = []\n    for L, k, c, N, delta_g0, delta_gL in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        alpha = compute_sensitivity(L, k, c, N, delta_g0, delta_gL)\n        results.append(alpha)\n\n    # Final print statement in the exact required format.\n    # Each value is rounded to 6 decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\ndef compute_sensitivity(L: float, k: float, c: float, N: int, delta_g0: float, delta_gL: float) -> float:\n    \"\"\"\n    Solves for the difference field w and computes the sensitivity ratio alpha.\n\n    Args:\n        L: Domain length.\n        k: Diffusion coefficient.\n        c: Reaction coefficient.\n        N: Number of interior nodes.\n        delta_g0: Perturbation at the x=0 boundary.\n        delta_gL: Perturbation at the x=L boundary.\n\n    Returns:\n        The computed sensitivity ratio alpha.\n    \"\"\"\n    # 1. Setup grid and constants\n    h = L / (N + 1)\n    k_over_h2 = k / (h**2)\n\n    # 2. Assemble the linear system A*w = b\n    # A is an N x N tridiagonal matrix\n    main_diag = (2 * k_over_h2 + c) * np.ones(N)\n    off_diag = -k_over_h2 * np.ones(N - 1)\n    \n    A = np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n    \n    # b is the N x 1 right-hand side vector\n    b = np.zeros(N)\n    b[0] = k_over_h2 * delta_g0\n    b[N - 1] = k_over_h2 * delta_gL\n\n    # 3. Solve the linear system for the interior solution w\n    w = np.linalg.solve(A, b)\n\n    # 4. Compute norms and the sensitivity ratio alpha\n    # Numerator: Discrete L2 norm of the solution difference w\n    # ||w||_L2 ≈ sqrt(h * sum(w_i^2))\n    norm_w_l2 = np.sqrt(h * np.sum(np.square(w)))\n\n    # Denominator: Euclidean norm of the boundary perturbations\n    norm_delta_g = np.sqrt(delta_g0**2 + delta_gL**2)\n\n    # Handle the case of zero perturbation to avoid division by zero\n    if norm_delta_g == 0:\n        return 0.0\n\n    alpha = norm_w_l2 / norm_delta_g\n    \n    return alpha\n\nsolve()\n```", "id": "3191044"}, {"introduction": "Our final practice offers a deeper, more nuanced perspective on sensitivity, moving beyond a simple input-output relationship. Here, we distinguish between the inherent sensitivity of a mathematical *problem* (its conditioning) and the performance of the *algorithm* used to solve it. By analyzing Newton's method for root-finding [@problem_id:3272508], we will uncover how a seemingly small change—finding a double root instead of a simple one—dramatically affects both the problem's stability under perturbation and the algorithm's rate of convergence, a crucial lesson in numerical analysis.", "problem": "A scalar nonlinear equation is to be solved with Newton’s method. Let $f:\\mathbb{R}\\to\\mathbb{R}$ be twice continuously differentiable near a root $x=r$ with $f(r)=0$. The Newton iteration is defined by $x_{k+1}=x_k-\\dfrac{f(x_k)}{f'(x_k)}$. A root $x=r$ is called simple if $f'(r)\\neq 0$, and is called a double root if $f'(r)=0$ and $f''(r)\\neq 0$. Consider two aspects of sensitivity in this context:\n\n- Sensitivity of the solution to a small additive perturbation in the equation: solve $f(x)+\\varepsilon=0$ with small $\\varepsilon\\in\\mathbb{R}$. The sensitivity is quantified by how the perturbed root $x=r(\\varepsilon)$ changes in magnitude as a function of $\\varepsilon$.\n- Sensitivity of Newton’s method to perturbations in the initial guess: start from $x_0=r+e_0$ with small $e_0$, and quantify how the one-step error $e_1=x_{1}-r$ depends on $e_0$.\n\nAssume the setting is locally well-posed so that $f$ is sufficiently smooth and $f''(r)\\neq 0$ when $f'(r)=0$. Which option best describes the change in sensitivity when the method is applied near a double root versus a simple root?\n\nA. Near a simple root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$; near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\sqrt{|\\varepsilon|})$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0)$ (specifically, $e_1\\approx \\dfrac{1}{2}e_0$).\n\nB. Near a simple root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\sqrt{|\\varepsilon|})$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0)$; near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$.\n\nC. In both the simple root and double root cases, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$.\n\nD. Near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s method removes the initial error exactly in one step, i.e., $e_1=0$ for all sufficiently small $e_0$.", "solution": "The validity of the problem statement is first assessed.\n\n### Step 1: Extract Givens\n- A scalar nonlinear equation is to be solved using Newton's method.\n- The function $f:\\mathbb{R}\\to\\mathbb{R}$ is twice continuously differentiable near a root $x=r$.\n- The root condition is $f(r)=0$.\n- The Newton iteration is $x_{k+1}=x_k-\\dfrac{f(x_k)}{f'(x_k)}$.\n- A simple root is defined by $f'(r)\\neq 0$.\n- A double root is defined by $f'(r)=0$ and $f''(r)\\neq 0$.\n- Sensitivity of the root is analyzed by solving the perturbed equation $f(x)+\\varepsilon=0$ for small $\\varepsilon\\in\\mathbb{R}$ and quantifying the change in the root $r(\\varepsilon)$.\n- Sensitivity of Newton's method is analyzed by starting from $x_0=r+e_0$ with small $e_0$ and quantifying the one-step error $e_1=x_1-r$.\n- An assumption is made that the problem is locally well-posed and $f''(r)\\neq 0$ when $f'(r)=0$.\n- The question asks to describe the change in sensitivity when applying the method near a double root versus a simple root.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically sound, well-posed, and objective. It is a standard problem in introductory numerical analysis, used to illustrate the concepts of problem conditioning and algorithm convergence rate. The definitions for simple and double roots are standard. The two types of sensitivity analysis (problem sensitivity vs. method sensitivity) are well-defined. All required assumptions, such as the non-vanishing second derivative for a double root, are provided. The problem is formalizable and asks for a verifiable mathematical derivation based on Taylor series expansions, which is a core technique in this field.\n\n1.  **Scientific/Factual Unsoundness**: None. The problem is based on fundamental principles of calculus and numerical analysis.\n2.  **Non-Formalizable or Irrelevant**: None. The problem is directly relevant to sensitivity analysis in numerical methods.\n3.  **Incomplete or Contradictory Setup**: None. All necessary definitions and conditions are provided and are consistent.\n4.  **Unrealistic or Infeasible**: None. The problem operates within a standard mathematical framework.\n5.  **Ill-Posed or Poorly Structured**: None. The problem is well-structured and leads to a unique, derivable conclusion.\n6.  **Pseudo-Profound, Trivial, or Tautological**: None. The problem requires a non-trivial derivation that highlights key concepts in numerical analysis.\n7.  **Outside Scientific Verifiability**: None. The results can be proven mathematically.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A full solution will be derived.\n\n### Derivation\n\nWe analyze the two types of sensitivity for both simple and double roots. This requires the use of Taylor series expansions for the function $f(x)$ around the root $x=r$.\n\n**Part 1: Analysis for a Simple Root**\nA simple root $x=r$ is characterized by $f(r)=0$ and $f'(r)\\neq 0$.\n\n**1.1. Sensitivity of the Solution**\nWe analyze the perturbed equation $f(x) + \\varepsilon = 0$. Let the new root be $x(\\varepsilon) = r + \\delta r$. We assume $\\delta r$ is small for small $\\varepsilon$.\nWe substitute $x=r+\\delta r$ into the equation:\n$$f(r+\\delta r) + \\varepsilon = 0$$\nWe perform a Taylor expansion of $f(r+\\delta r)$ around $r$:\n$$f(r) + f'(r)\\delta r + \\mathcal{O}((\\delta r)^2) + \\varepsilon = 0$$\nSince $f(r)=0$, this simplifies to:\n$$f'(r)\\delta r + \\mathcal{O}((\\delta r)^2) + \\varepsilon = 0$$\nFor small $\\varepsilon$, $\\delta r$ is also small, so we can neglect the higher-order terms:\n$$f'(r)\\delta r \\approx -\\varepsilon$$\nSolving for the root perturbation $\\delta r$:\n$$\\delta r \\approx -\\frac{\\varepsilon}{f'(r)}$$\nSince $f'(r)$ is a non-zero constant, the perturbation in the root, $\\delta r$, is directly proportional to $\\varepsilon$. Thus, the root shift is of order $\\mathcal{O}(\\varepsilon)$. This indicates the problem is well-conditioned.\n\n**1.2. Sensitivity of Newton's Method (One-Step Error)**\nLet the initial guess be $x_0 = r + e_0$, where $e_0$ is the initial error. The first iteration gives $x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)}$. The new error is $e_1 = x_1 - r$.\n$$e_1 = (x_0 - r) - \\frac{f(x_0)}{f'(x_0)} = e_0 - \\frac{f(r+e_0)}{f'(r+e_0)}$$\nWe use Taylor expansions for the numerator and denominator around $r$:\n$$f(r+e_0) = f(r) + f'(r)e_0 + \\frac{f''(r)}{2!}e_0^2 + \\mathcal{O}(e_0^3) = f'(r)e_0 + \\frac{f''(r)}{2}e_0^2 + \\mathcal{O}(e_0^3)$$\n$$f'(r+e_0) = f'(r) + f''(r)e_0 + \\mathcal{O}(e_0^2)$$\nSubstituting these into the expression for $e_1$:\n$$e_1 = e_0 - \\frac{f'(r)e_0 + \\frac{1}{2}f''(r)e_0^2 + \\mathcal{O}(e_0^3)}{f'(r) + f''(r)e_0 + \\mathcal{O}(e_0^2)}$$\nFactor out $f'(r)$ from the denominator:\n$$e_1 = e_0 - \\frac{f'(r)e_0 + \\frac{1}{2}f''(r)e_0^2 + \\dots}{f'(r) \\left(1 + \\frac{f''(r)}{f'(r)}e_0 + \\dots\\right)}$$\nUsing the geometric series approximation $\\frac{1}{1+z} \\approx 1-z$ for small $z = \\frac{f''(r)}{f'(r)}e_0$:\n$$e_1 \\approx e_0 - \\frac{1}{f'(r)} \\left(f'(r)e_0 + \\frac{1}{2}f''(r)e_0^2\\right) \\left(1 - \\frac{f''(r)}{f'(r)}e_0\\right)$$\nExpanding and keeping terms up to order $e_0^2$:\n$$e_1 \\approx e_0 - \\frac{1}{f'(r)} \\left(f'(r)e_0 + \\frac{1}{2}f''(r)e_0^2 - f'(r)\\frac{f''(r)}{f'(r)}e_0^2\\right)$$\n$$e_1 \\approx e_0 - \\frac{1}{f'(r)} \\left(f'(r)e_0 - \\frac{1}{2}f''(r)e_0^2\\right)$$\n$$e_1 \\approx e_0 - \\left(e_0 - \\frac{f''(r)}{2f'(r)}e_0^2\\right) = \\frac{f''(r)}{2f'(r)}e_0^2$$\nThe error $e_1$ is proportional to the square of the previous error $e_0$. Therefore, $e_1 = \\mathcal{O}(e_0^2)$, which is the signature of quadratic convergence.\n\n**Part 2: Analysis for a Double Root**\nA double root $x=r$ is characterized by $f(r)=0$, $f'(r)=0$, and $f''(r)\\neq 0$.\n\n**2.1. Sensitivity of the Solution**\nWe again analyze the perturbed equation $f(x) + \\varepsilon = 0$ with $x(\\varepsilon) = r + \\delta r$.\n$$f(r+\\delta r) + \\varepsilon = 0$$\nThe Taylor expansion of $f(r+\\delta r)$ around $r$ is:\n$$f(r) + f'(r)\\delta r + \\frac{f''(r)}{2!}(\\delta r)^2 + \\mathcal{O}((\\delta r)^3) + \\varepsilon = 0$$\nUsing the conditions for a double root, this becomes:\n$$0 + 0 \\cdot \\delta r + \\frac{f''(r)}{2}(\\delta r)^2 + \\mathcal{O}((\\delta r)^3) + \\varepsilon = 0$$\nFor small $\\varepsilon$ and $\\delta r$, we neglect the higher-order term:\n$$\\frac{f''(r)}{2}(\\delta r)^2 \\approx -\\varepsilon$$\nSolving for $\\delta r$:\n$$(\\delta r)^2 \\approx -\\frac{2\\varepsilon}{f''(r)} \\implies |\\delta r| \\approx \\sqrt{\\left|-\\frac{2\\varepsilon}{f''(r)}\\right|}$$\nThe magnitude of the root perturbation $|\\delta r|$ is proportional to $\\sqrt{|\\varepsilon|}$. Thus, the root shift is of order $\\mathcal{O}(\\sqrt{|\\varepsilon|})$. The square root dependence indicates that the problem of finding a double root is ill-conditioned.\n\n**2.2. Sensitivity of Newton's Method (One-Step Error)**\nAs before, $e_1 = e_0 - \\frac{f(r+e_0)}{f'(r+e_0)}$. We use Taylor expansions appropriate for a double root:\n$$f(r+e_0) = f(r) + f'(r)e_0 + \\frac{f''(r)}{2}e_0^2 + \\mathcal{O}(e_0^3) = \\frac{f''(r)}{2}e_0^2 + \\mathcal{O}(e_0^3)$$\n$$f'(r+e_0) = f'(r) + f''(r)e_0 + \\frac{f'''(r)}{2}e_0^2 + \\mathcal{O}(e_0^3) = f''(r)e_0 + \\mathcal{O}(e_0^2)$$\nSubstitute these into the expression for $e_1$:\n$$e_1 = e_0 - \\frac{\\frac{1}{2}f''(r)e_0^2 + \\mathcal{O}(e_0^3)}{f''(r)e_0 + \\mathcal{O}(e_0^2)}$$\nTo find the dominant behavior for small $e_0$, we consider the ratio of the leading terms:\n$$e_1 \\approx e_0 - \\frac{\\frac{1}{2}f''(r)e_0^2}{f''(r)e_0}$$\nSince $f''(r)\\neq 0$ and we assume $e_0\\neq 0$, we can simplify:\n$$e_1 \\approx e_0 - \\frac{1}{2}e_0 = \\frac{1}{2}e_0$$\nThe error $e_1$ is linearly proportional to the previous error $e_0$, with a constant factor of approximately $\\frac{1}{2}$. Therefore, $e_1 = \\mathcal{O}(e_0)$, which indicates linear convergence.\n\n### Summary of Results and Option Evaluation\n- **Simple Root**:\n    - Solution sensitivity: $\\delta r = \\mathcal{O}(\\varepsilon)$.\n    - Method sensitivity: $e_1 = \\mathcal{O}(e_0^2)$.\n- **Double Root**:\n    - Solution sensitivity: $|\\delta r| = \\mathcal{O}(\\sqrt{|\\varepsilon|})$.\n    - Method sensitivity: $e_1 \\approx \\frac{1}{2}e_0$, so $e_1 = \\mathcal{O}(e_0)$.\n\nNow we evaluate the given options based on this summary.\n\n**A. Near a simple root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$; near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\sqrt{|\\varepsilon|})$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0)$ (specifically, $e_1\\approx \\dfrac{1}{2}e_0$).**\nThis option perfectly matches all four parts of our derived results.\n**Verdict: Correct.**\n\n**B. Near a simple root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\sqrt{|\\varepsilon|})$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0)$; near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$.**\nThis option swaps the results for simple and double roots.\n**Verdict: Incorrect.**\n\n**C. In both the simple root and double root cases, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s one-step error satisfies $e_1=\\mathcal{O}(e_0^2)$.**\nThis option incorrectly claims that the behavior for a double root is the same as for a simple root. Our derivation shows significant differences in both solution sensitivity and method convergence.\n**Verdict: Incorrect.**\n\n**D. Near a double root, the solution to $f(x)+\\varepsilon=0$ has a root shift of order $\\mathcal{O}(\\varepsilon)$, and Newton’s method removes the initial error exactly in one step, i.e., $e_1=0$ for all sufficiently small $e_0$.**\nThis option makes two incorrect claims about the double root case. The root shift is $\\mathcal{O}(\\sqrt{|\\varepsilon|})$, not $\\mathcal{O}(\\varepsilon)$. Newton's method converges linearly ($e_1 \\approx \\frac{1}{2}e_0$), it does not converge in one step ($e_1=0$).\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3272508"}]}