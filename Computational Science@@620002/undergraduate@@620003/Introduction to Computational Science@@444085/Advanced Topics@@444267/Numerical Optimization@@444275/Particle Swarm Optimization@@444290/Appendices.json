{"hands_on_practices": [{"introduction": "A key question for any optimization algorithm is how its performance scales with the size of the problem. This exercise tackles this question head-on by exploring the impact of dimensionality on PSO's convergence speed. You will implement a controlled benchmark to measure the number of iterations required for the swarm to find a high-quality solution to the simple, convex sphere function, $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$, as the dimension $d$ increases [@problem_id:3161040]. This practice is fundamental to developing an appreciation for the challenges posed by high-dimensional search spaces, often referred to as the 'curse of dimensionality'.", "problem": "You are asked to design and implement a controlled numerical benchmark to study how the search space dimension affects the performance of Particle Swarm Optimization (PSO) on a smooth convex test function. Use only definitions, widely accepted formulas, and reproducible randomization. Your program must be a complete, runnable program that computes and reports a single summarized performance figure for each test dimension.\n\nTask. Minimize the function $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$ over the hypercube $[-b,b]^d$ with $b = 5$, using Particle Swarm Optimization (PSO). Let the algorithm use a fixed inertia weight $w$, and fixed cognitive and social accelerations $c_1$ and $c_2$, respectively. Use the canonical, widely adopted PSO velocity-position update with independent uniform random factors per particle and coordinate:\n- Velocity update: at iteration $t$, for each particle $i$ and dimension $j$, \n$$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right),$$\nwhere $r_{i,j}^{(t,1)}$ and $r_{i,j}^{(t,2)}$ are independent random variables sampled from the uniform distribution on $[0,1]$.\n- Velocity clamp: enforce component-wise $v_{i,j}^{(t+1)} \\in [-v_{\\max}, v_{\\max}]$ with $v_{\\max} = 0.2 \\times 2b$.\n- Position update: \n$$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right).$$\n\nInitialization. For a given dimension $d$, use $m(d)$ particles with positions independently sampled from the uniform distribution on $[-b,b]^d$, and velocities independently sampled from the uniform distribution on $[-v_{\\max}, v_{\\max}]^d$. Set each particle’s personal best $pbest_i$ initially to its starting position, and set the global best $gbest$ to the best among all initial $pbest_i$.\n\nTermination and metric. Fix a target tolerance $\\varepsilon > 0$ and a maximum iteration budget $T_{\\max}$. Define the time-to-$\\varepsilon$ as the smallest iteration count $T$ such that the current best-so-far objective value satisfies $f(gbest^{(T)}) \\le \\varepsilon$ when evaluated after completing iteration $T$’s position updates. If this condition is never met within $T_{\\max}$ iterations, define the time-to-$\\varepsilon$ to be $T_{\\max}$.\n\nBenchmark protocol. For each dimension $d$ in a given test suite, run the PSO algorithm for $R$ independent trials (each with a different random seed) and report the arithmetic mean of the time-to-$\\varepsilon$ across the $R$ trials.\n\nUse the following fixed parameters:\n- Inertia weight $w = 0.7298$.\n- Cognitive acceleration $c_1 = 1.49618$.\n- Social acceleration $c_2 = 1.49618$.\n- Bound parameter $b = 5$, hence $v_{\\max} = 0.2 \\times 2b = 2$.\n- Number of iterations budget $T_{\\max} = 500$.\n- Tolerance $\\varepsilon = 10^{-6}$.\n- Number of trials $R = 3$.\n- Swarm size schedule $m(d) = \\min(10d, 200)$.\n- Randomization: use a fixed base seed $s_0 = 1337$; for dimension $d$ and trial index $r \\in \\{0,1,\\dots,R-1\\}$, use seed $s(d,r) = s_0 + 100d + r$.\n\nTest suite. You must evaluate the benchmark on the following dimensions:\n- $d \\in \\{1, 5, 20, 50\\}$.\n\nOutput specification. Your program should produce a single line of output containing the mean time-to-$\\varepsilon$ for each $d$ in the above order, formatted as a comma-separated list of decimal numbers with exactly three digits after the decimal point, enclosed in square brackets. For example, the output must look like $[a_1,a_2,a_3,a_4]$ where each $a_k$ is a floating-point number with exactly three digits after the decimal point.\n\nUnits. The time-to-$\\varepsilon$ is a count of iterations and is therefore dimensionless; report it as a real number (a decimal) to allow averaging across trials.\n\nYour program must be self-contained, require no input, and comply with the specified output format exactly.", "solution": "The problem statement has been analyzed and is determined to be **valid**. It presents a well-defined and scientifically sound numerical experiment in the field of computational optimization. All necessary parameters, equations, and evaluation protocols are specified with clarity and precision, allowing for a reproducible implementation. The task is objective, self-contained, and grounded in established principles of Particle Swarm Optimization (PSO).\n\nThe objective is to minimize the sphere function, defined as $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$, within the hypercubic domain $\\mathbf{x} \\in [-b, b]^d$, where $d$ is the dimension of the search space and the boundary parameter is $b=5$. This benchmark is designed to analyze how the performance of the PSO algorithm scales with increasing dimensionality.\n\nThe core of the solution lies in the implementation of the canonical PSO algorithm. The state of a swarm of $m(d)$ particles is described by their positions $\\mathbf{x}_i$ and velocities $\\mathbf{v}_i$ for $i=1, \\dots, m(d)$. At each iteration $t$, every particle's velocity and position are updated according to the following rules for each dimension $j$:\n\n1.  **Velocity Update**: The velocity of particle $i$ is updated based on its previous velocity, its personal best known position ($\\mathbf{pbest}_i$), and the global best known position ($\\mathbf{gbest}$) discovered by the entire swarm.\n    $$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right)$$\n    The parameters are fixed: inertia weight $w = 0.7298$, cognitive acceleration $c_1 = 1.49618$, and social acceleration $c_2 = 1.49618$. The terms $r_{i,j}^{(t,1)}$ and $r_{i,j}^{(t,2)}$ are random numbers sampled independently from a uniform distribution on $[0,1]$ for each particle and dimension at each iteration.\n\n2.  **Velocity Clamping**: To prevent particle velocities from becoming excessively large and destabilizing the swarm, each velocity component is clamped to the range $[-v_{\\max}, v_{\\max}]$, where $v_{\\max} = 0.2 \\times (2b) = 2$.\n\n3.  **Position Update**: The new position of particle $i$ is calculated by adding the updated velocity to its current position. The position is then hard-clipped to ensure it remains within the search bounds $[-b, b]$.\n    $$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right)$$\n\nThe benchmark protocol is executed for each dimension $d$ in the test suite $\\{1, 5, 20, 50\\}$. For each $d$, the following steps are performed:\n-   The swarm size is set to $m(d) = \\min(10d, 200)$.\n-   The algorithm is run for $R=3$ independent trials to account for the stochastic nature of PSO.\n-   Reproducibility is ensured by using a deterministic seeding strategy: for trial $r \\in \\{0, 1, 2\\}$ in dimension $d$, the random number generator is seeded with $s(d,r) = 1337 + 100d + r$.\n-   In each trial, particles are initialized with positions uniformly sampled from $[-5, 5]^d$ and velocities from $[-2, 2]^d$.\n-   The performance metric for a single trial is the \"time-to-$\\varepsilon$,\" defined as the first iteration count $T$ at which the global best objective value $f(\\mathbf{gbest}^{(T)})$ drops to or below the tolerance $\\varepsilon = 10^{-6}$. If this tolerance is not met within the maximum iteration budget of $T_{\\max} = 500$, the time-to-$\\varepsilon$ is set to $T_{\\max}$.\n-   The final reported value for each dimension $d$ is the arithmetic mean of the time-to-$\\varepsilon$ values obtained across the $R=3$ trials.\n\nThe implementation is written in Python, leveraging the `numpy` library for efficient, vectorized computations. This approach avoids explicit looping over particles and dimensions, making the code both concise and performant. The program follows the prescribed protocol precisely, calculates the mean performance figures, and formats the final output as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the PSO benchmark study.\n    It iterates through the specified dimensions, runs multiple trials for each,\n    computes the mean performance, and prints the final formatted result.\n    \"\"\"\n    \n    def run_pso_trial(d: int, seed: int) - int:\n        \"\"\"\n        Executes a single trial of the Particle Swarm Optimization algorithm.\n\n        Args:\n            d: The dimension of the search space.\n            seed: The seed for the random number generator.\n\n        Returns:\n            The number of iterations to reach the target tolerance (\"time-to-epsilon\").\n        \"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Fixed parameters from the problem statement\n        w = 0.7298\n        c1 = 1.49618\n        c2 = 1.49618\n        b = 5.0\n        v_max = 2.0\n        T_max = 500\n        eps = 1e-6\n        m = min(10 * d, 200)\n\n        # Initialization\n        # (m, d) array of particle positions\n        positions = rng.uniform(-b, b, size=(m, d))\n        # (m, d) array of particle velocities\n        velocities = rng.uniform(-v_max, v_max, size=(m, d))\n\n        # Personal best positions are initialized to the starting positions\n        pbest_positions = np.copy(positions)\n        # Objective function f(x) = sum(x_j^2)\n        pbest_values = np.sum(pbest_positions**2, axis=1)\n\n        # Global best initialization\n        gbest_idx = np.argmin(pbest_values)\n        gbest_value = pbest_values[gbest_idx]\n        gbest_position = np.copy(pbest_positions[gbest_idx])\n        \n        # If the solution is found at initialization (iteration 0)\n        if gbest_value = eps:\n            return 0\n\n        # Main optimization loop\n        for t in range(1, T_max + 1):\n            # Generate random factors for velocity update\n            r1 = rng.random(size=(m, d))\n            r2 = rng.random(size=(m, d))\n\n            # Update velocities (vectorized for all particles)\n            velocities = w * velocities + \\\n                         c1 * r1 * (pbest_positions - positions) + \\\n                         c2 * r2 * (gbest_position - positions)\n            \n            # Clamp velocities\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            # Update positions\n            positions = positions + velocities\n            # Clip positions to stay within the search space\n            positions = np.clip(positions, -b, b)\n\n            # Evaluate objective function for all particles\n            current_values = np.sum(positions**2, axis=1)\n\n            # Update personal bests\n            improved_mask = current_values  pbest_values\n            pbest_values[improved_mask] = current_values[improved_mask]\n            pbest_positions[improved_mask] = positions[improved_mask]\n\n            # Update global best\n            min_pbest_idx = np.argmin(pbest_values)\n            if pbest_values[min_pbest_idx]  gbest_value:\n                gbest_value = pbest_values[min_pbest_idx]\n                gbest_position = pbest_positions[min_pbest_idx]\n\n            # Check for termination\n            if gbest_value = eps:\n                return t\n\n        # Return T_max if tolerance was not met\n        return T_max\n\n    # Benchmark protocol parameters\n    test_dims = [1, 5, 20, 50]\n    R = 3  # Number of trials\n    s0 = 1337  # Base seed\n\n    mean_results = []\n    for d in test_dims:\n        trial_times = []\n        for r in range(R):\n            # Calculate the deterministic seed for the trial\n            seed = s0 + 100 * d + r\n            time_to_eps = run_pso_trial(d, seed)\n            trial_times.append(time_to_eps)\n        \n        # Calculate the arithmetic mean of the time-to-epsilon\n        mean_time = np.mean(trial_times)\n        mean_results.append(mean_time)\n\n    # Format and print the final output as specified\n    formatted_results = [f'{res:.3f}' for res in mean_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3161040"}, {"introduction": "Real-world optimization problems rarely occur in unbounded spaces; they are almost always subject to constraints. This practice focuses on a common and crucial implementation detail: how to handle particles that attempt to move beyond the boundaries of a defined search domain. You will implement and compare three distinct boundary handling schemes—'reflect', 'absorb', and 'random restart'—to see how each impacts the swarm's ability to explore the feasible region and converge to a solution [@problem_id:3161093]. Understanding these trade-offs is essential for effectively applying PSO to constrained optimization tasks.", "problem": "Consider the bounded minimization of the shifted sphere objective over a hyper-rectangle. Let $d \\in \\mathbb{N}$, lower and upper bounds $l \\in \\mathbb{R}$ and $u \\in \\mathbb{R}$ with $l  u$, and a shift vector $a \\in \\mathbb{R}^d$. Define the objective function $$f(x) = \\sum_{j=1}^{d} (x_j - a_j)^2,$$ and the feasible set $$\\Omega = [l,u]^d = \\{x \\in \\mathbb{R}^d \\mid \\forall j \\in \\{1,\\dots,d\\}, \\, l \\le x_j \\le u\\}.$$ The unconstrained minimizer is $x^\\star = a$ with $f(x^\\star) = 0$, and under the box constraint the minimizer is the componentwise projection of $a$ onto $\\Omega$, which is $\\tilde{a}_j = \\min(\\max(a_j, l), u)$ for each $j$, yielding $x^\\star_\\Omega = \\tilde{a}$.\n\nYour task is to implement a complete, runnable program that uses Particle Swarm Optimization (PSO) to minimize $f(x)$ over $\\Omega$ and to examine the impact of three boundary handling schemes on feasibility and convergence. Particle Swarm Optimization (PSO) maintains a swarm of $N$ particles with positions $x_i(t) \\in \\mathbb{R}^d$ and velocities $v_i(t) \\in \\mathbb{R}^d$ at iteration $t$. Each particle tracks its personal best position $p_i(t)$ and the swarm tracks the global best position $g(t)$. At each iteration $t$, velocities and positions evolve according to the canonical inertial PSO update, where $$v_i(t+1) = w \\, v_i(t) + c_1 \\, r_1(t) \\odot (p_i(t) - x_i(t)) + c_2 \\, r_2(t) \\odot (g(t) - x_i(t)),$$ $$x_i(t+1) = x_i(t) + v_i(t+1),$$ with inertia weight $w \\in \\mathbb{R}$, cognitive and social coefficients $c_1 \\in \\mathbb{R}$ and $c_2 \\in \\mathbb{R}$, and independent random vectors $r_1(t), r_2(t) \\in [0,1]^d$ drawn componentwise from the uniform distribution. The operator $\\odot$ denotes componentwise multiplication. Velocities are clamped componentwise to $[-v_{\\max}, v_{\\max}]$ for a given $v_{\\max} \\in \\mathbb{R}_{0}$. Initial positions are drawn uniformly from $\\Omega$ and initial velocities are drawn uniformly from $[-v_{\\max}, v_{\\max}]^d$. Personal and global bests update only when a strictly lower objective value is observed.\n\nBoundary handling is required when an attempted position $x_i^{\\mathrm{prop}}(t+1) = x_i(t) + v_i(t+1)$ lies outside $\\Omega$. Implement the following three schemes, each acting independently per component $j$:\n\n- Reflect: If $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$, use reflective mapping over the interval $[l,u]$ by computing $$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k.$$ Set $$x_{ij}(t+1) = \\begin{cases} l + z_{\\mathrm{frac}}(u - l)  \\text{if } k \\text{ is even}, \\\\ u - z_{\\mathrm{frac}}(u - l)  \\text{if } k \\text{ is odd}, \\end{cases}$$ and flip the velocity component when $k$ is odd, that is $$v_{ij}(t+1) = \\begin{cases} v_{ij}(t+1)  \\text{if } k \\text{ is even}, \\\\ -v_{ij}(t+1)  \\text{if } k \\text{ is odd}. \\end{cases}$$ If $x_{ij}^{\\mathrm{prop}} \\in [l,u]$, keep $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ and $v_{ij}(t+1)$ unchanged.\n\n- Absorb: If $x_{ij}^{\\mathrm{prop}}  l$, set $x_{ij}(t+1) = l$ and $v_{ij}(t+1) = 0$. If $x_{ij}^{\\mathrm{prop}}  u$, set $x_{ij}(t+1) = u$ and $v_{ij}(t+1) = 0$. If $x_{ij}^{\\mathrm{prop}} \\in [l,u]$, keep $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ and $v_{ij}(t+1)$ unchanged.\n\n- Random restart: If $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$, set $x_{ij}(t+1)$ to a new value drawn uniformly from $[l,u]$ and set $v_{ij}(t+1) = 0$. If $x_{ij}^{\\mathrm{prop}} \\in [l,u]$, keep $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ and $v_{ij}(t+1)$ unchanged.\n\nDefine the feasibility metric as the attempted feasibility rate over the run, that is, $$r_{\\mathrm{feasible}} = \\frac{\\text{number of proposals } x_i^{\\mathrm{prop}}(t+1) \\in \\Omega}{\\text{total number of proposals}} = \\frac{\\#\\{(i,t) \\mid x_i(t) + v_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ where $T \\in \\mathbb{N}$ is the total number of iterations.\n\nDefine the convergence condition via a tolerance $\\varepsilon \\in \\mathbb{R}_{0}$: the run is said to have converged at iteration $t^\\star$ if $$\\min_{i} f(p_i(t^\\star)) \\le \\varepsilon.$$ Record whether this condition is met and the earliest $t^\\star$ when it is met, with $t^\\star = -1$ if it is never met. Also record the final best objective value $$f^\\star = \\min_{i} f(p_i(T)).$$\n\nImplement the PSO algorithm with boundary handling and metrics as described above. Use an independent and fixed seed for the random number generator in each test case to ensure reproducibility. No physical units are involved. All angles, if any, are not applicable.\n\nTest suite and parameters to implement:\n\n- Case $1$ (happy path, reflect): $d=5$, $l=-5$, $u=5$, $a = [1.5, -2.0, 0.5, -1.0, 2.0]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, boundary scheme = reflect, seed $=42$, $\\varepsilon = 10^{-6}$.\n\n- Case $2$ (near upper boundary, absorb): $d=5$, $l=-5$, $u=5$, $a = [4.9, 4.8, 4.7, 4.6, 4.5]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, boundary scheme = absorb, seed $=123$, $\\varepsilon = 10^{-6}$.\n\n- Case $3$ (unattainable zero within domain, random restart): $d=5$, $l=-2$, $u=2$, $a = [10.0, 10.0, 10.0, 10.0, 10.0]$, $N=40$, $T=300$, $w=0.8$, $c_1=1.7$, $c_2=1.7$, $v_{\\max}=4$, boundary scheme = random restart, seed $=7$, $\\varepsilon = 10^{-6}$.\n\n- Case $4$ (low dimension, overshoot, reflect): $d=2$, $l=-1$, $u=1$, $a = [0.99, -0.99]$, $N=10$, $T=150$, $w=0.9$, $c_1=2.05$, $c_2=2.05$, $v_{\\max}=2$, boundary scheme = reflect, seed $=999$, $\\varepsilon = 10^{-6}$.\n\n- Case $5$ (small domain, absorb): $d=3$, $l=0$, $u=1$, $a = [0.9, 0.1, 0.5]$, $N=12$, $T=150$, $w=0.6$, $c_1=1.4$, $c_2=1.4$, $v_{\\max}=1$, boundary scheme = absorb, seed $=2024$, $\\varepsilon = 10^{-6}$.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is itself a list $[f^\\star, r_{\\mathrm{feasible}}, \\text{converged}, t^\\star]$ for the test cases in the order given above. For example, the output should look like $$[[f^\\star_1, r_{\\mathrm{feasible},1}, \\text{converged}_1, t^\\star_1], [f^\\star_2, r_{\\mathrm{feasible},2}, \\text{converged}_2, t^\\star_2], \\dots].$$ The types must be as follows: $f^\\star$ is a real number (float), $r_{\\mathrm{feasible}}$ is a real number (float) in $[0,1]$, $\\text{converged}$ is a boolean, and $t^\\star$ is an integer with $-1$ indicating no convergence within $T$ iterations.", "solution": "We are minimizing the shifted sphere function $$f(x) = \\sum_{j=1}^{d} (x_j - a_j)^2$$ subject to the box constraint $x \\in \\Omega = [l,u]^d$. The shifted sphere function is strictly convex with a unique unconstrained minimizer at $x^\\star = a$. Under box constraints, the minimizer is the projection of $a$ onto $\\Omega$, so the constrained minimizer is $x^\\star_\\Omega = \\tilde{a}$ where $\\tilde{a}_j = \\min(\\max(a_j, l), u)$ for each $j$, and the minimum objective value is $$f(x^\\star_\\Omega) = \\sum_{j=1}^{d} (\\tilde{a}_j - a_j)^2.$$ If $a \\in \\Omega$, then $x^\\star_\\Omega = a$ and $f(x^\\star_\\Omega) = 0$; if any component of $a$ lies outside the bounds, the minimum within $\\Omega$ is strictly positive.\n\nParticle Swarm Optimization (PSO) is a population-based stochastic optimization method. It maintains a set of $N$ particles, each with position $x_i(t) \\in \\mathbb{R}^d$ and velocity $v_i(t) \\in \\mathbb{R}^d$ at iteration $t$. The update rule blends inertia, attraction to the particle's personal best $p_i(t)$, and attraction to the global best $g(t)$. This design embodies two fundamental principles: exploration via inertia and stochasticity, and exploitation via attraction to known good solutions. The canonical inertial PSO update is given by $$v_i(t+1) = w \\, v_i(t) + c_1 \\, r_1(t) \\odot (p_i(t) - x_i(t)) + c_2 \\, r_2(t) \\odot (g(t) - x_i(t)),$$ $$x_i(t+1) = x_i(t) + v_i(t+1),$$ with independent uniform random vectors $r_1(t), r_2(t) \\in [0,1]^d$. Velocity clamping ensures bounded step sizes: $$v_{ij}(t+1) \\leftarrow \\operatorname{clip}(v_{ij}(t+1), -v_{\\max}, v_{\\max}).$$ Initial positions $x_i(0)$ are drawn uniformly from $\\Omega$ and initial velocities $v_i(0)$ are drawn uniformly from $[-v_{\\max}, v_{\\max}]^d$. After each position update, we evaluate $f(x_i(t+1))$ and update the personal best $p_i(t+1)$ and the global best $g(t+1)$ if improvements occur.\n\nThe presence of constraints requires boundary handling when an attempted position $x_i^{\\mathrm{prop}}(t+1) = x_i(t) + v_i(t+1)$ leaves $\\Omega$. We examine three schemes:\n\n1. Reflect: The reflective mapping enforces a mirror boundary, which preserves exploration while preventing particles from leaving the domain. For a single component $j$, let $$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k.$$ If $k$ is even, we set $$x_{ij}(t+1) = l + z_{\\mathrm{frac}}(u - l);$$ if $k$ is odd, we set $$x_{ij}(t+1) = u - z_{\\mathrm{frac}}(u - l).$$ The parity of $k$ counts the number of interval crossings; when $k$ is odd, the component has bounced an odd number of times, so we flip the velocity sign: $$v_{ij}(t+1) \\leftarrow -v_{ij}(t+1).$$ This mapping correctly handles arbitrary overshoots, including those larger than the interval width $u - l$.\n\n2. Absorb: The absorbing boundary clamps the position to the nearest boundary and resets the corresponding velocity component to zero when a violation occurs: $$x_{ij}(t+1) = \\begin{cases} l  \\text{if } x_{ij}^{\\mathrm{prop}}  l, \\\\ u  \\text{if } x_{ij}^{\\mathrm{prop}}  u, \\\\ x_{ij}^{\\mathrm{prop}}  \\text{otherwise}, \\end{cases} \\quad v_{ij}(t+1) = \\begin{cases} 0  \\text{if } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\\\ v_{ij}(t+1)  \\text{otherwise}. \\end{cases}$$ This scheme discourages boundary violations by damping motion upon impact, potentially reducing oscillations but also diminishing exploration near the boundary.\n\n3. Random restart: The random restart boundary replaces an out-of-bounds component with a new random value drawn uniformly from $[l,u]$ and sets its velocity to zero: $$x_{ij}(t+1) \\sim \\mathcal{U}(l,u) \\quad \\text{if } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\quad v_{ij}(t+1) \\leftarrow 0.$$ This scheme promotes exploration by reintroducing diversity when violations occur, which can help escape stagnation but may slow convergence near precise boundary optima.\n\nTo quantify the effect of each scheme, we measure two metrics:\n\n- Attempted feasibility rate $$r_{\\mathrm{feasible}} = \\frac{\\#\\{(i,t) \\mid x_i(t) + v_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ which counts proposals before correction and reflects how often particles attempt positions inside $\\Omega$ under the dynamics induced by each boundary rule.\n\n- Convergence behavior: a boolean indicating whether the global best reaches the threshold $\\varepsilon$ at any iteration, and the earliest iteration $t^\\star$ where $$\\min_i f(p_i(t^\\star)) \\le \\varepsilon.$$ We also report the final best objective value $$f^\\star = \\min_i f(p_i(T)).$$\n\nImplementation details:\n\n- Randomness is controlled by a fixed seed per test case using a pseudorandom number generator to ensure reproducible results.\n\n- Personal bests $p_i(t)$ update only on strict improvements of $f(x)$, ensuring monotonic nonincreasing personal best values.\n\n- The global best $g(t)$ tracks the best among personal bests at each iteration.\n\n- Velocities are clamped componentwise to $[-v_{\\max}, v_{\\max}]$ after computation of $v_i(t+1)$ and before position proposals to prevent excessive overshoot.\n\n- Boundary handling schemes are applied componentwise to $x_i^{\\mathrm{prop}}(t+1)$ to yield the final $x_i(t+1)$ and the corrected $v_i(t+1)$, ensuring $x_i(t+1) \\in \\Omega$.\n\nDesign rationale:\n\n- The shifted sphere function’s quadratic structure provides a smooth landscape with a unique minimum, making it ideal for observing PSO dynamics and the interplay between exploration and exploitation.\n\n- Reflect preserves momentum while maintaining feasibility, often improving $r_{\\mathrm{feasible}}$ by reducing extended excursions and can speed convergence when the optimum lies near a boundary.\n\n- Absorb reduces oscillations by nullifying velocity at the boundary, which may decrease boundary crossings, increasing $r_{\\mathrm{feasible}}$, but can slow convergence near boundary optima due to loss of momentum.\n\n- Random restart increases diversity when violations occur, often increasing attempted violations early in the run but potentially aiding convergence in multimodal problems; for the convex shifted sphere, it can slow precise convergence near boundaries yet is effective when the unconstrained minimizer lies outside $\\Omega$, encouraging exploration near the constrained minimizer $x^\\star_\\Omega$.\n\nComputational considerations:\n\n- Each update costs $O(N d)$ operations, and the total runtime is $O(N d T)$ per test case.\n\n- With the given parameters, the program remains computationally lightweight and fully deterministic.\n\nThe program processes the five specified test cases, computes $f^\\star$, $r_{\\mathrm{feasible}}$, the convergence boolean, and $t^\\star$, and outputs a single line with the list of these four-tuple results for each case in order.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef sphere_shifted(x, a):\n    # f(x) = sum_j (x_j - a_j)^2\n    diff = x - a\n    return np.dot(diff, diff)\n\ndef reflect_component(x_prop, v_comp, l, u):\n    # Reflective mapping with parity-based velocity flip\n    if l = x_prop = u:\n        return x_prop, v_comp\n    width = u - l\n    # Compute z, k = floor(z), z_frac = z - k\n    z = (x_prop - l) / width\n    k = math.floor(z)\n    z_frac = z - k\n    if k % 2 == 0:\n        x_new = l + z_frac * width\n        v_new = v_comp\n    else:\n        x_new = u - z_frac * width\n        v_new = -v_comp\n    # Numerical guard to ensure bounds inclusion\n    if x_new  l:\n        x_new = l\n    elif x_new  u:\n        x_new = u\n    return x_new, v_new\n\ndef absorb_component(x_prop, v_comp, l, u):\n    if x_prop  l:\n        return l, 0.0\n    elif x_prop  u:\n        return u, 0.0\n    else:\n        return x_prop, v_comp\n\ndef restart_component(x_prop, v_comp, l, u, rng):\n    if l = x_prop = u:\n        return x_prop, v_comp\n    else:\n        return rng.uniform(l, u), 0.0\n\ndef pso_run(d, l, u, a, N, T, w, c1, c2, vmax, scheme, seed, eps):\n    rng = np.random.default_rng(seed)\n    # Initialize positions uniformly in [l, u]^d\n    X = rng.uniform(l, u, size=(N, d))\n    # Initialize velocities uniformly in [-vmax, vmax]^d\n    V = rng.uniform(-vmax, vmax, size=(N, d))\n    # Personal bests and fitnesses\n    P = X.copy()\n    P_fit = np.array([sphere_shifted(P[i], a) for i in range(N)])\n    # Global best\n    g_idx = int(np.argmin(P_fit))\n    G = P[g_idx].copy()\n    G_fit = P_fit[g_idx]\n    # Metrics\n    total_props = N * T\n    feasible_props = 0\n    converged = False\n    t_star = -1\n\n    for t in range(1, T + 1):\n        for i in range(N):\n            # Random coefficients per particle and dimension\n            r1 = rng.uniform(0.0, 1.0, size=d)\n            r2 = rng.uniform(0.0, 1.0, size=d)\n            # Velocity update\n            V[i] = w * V[i] + c1 * r1 * (P[i] - X[i]) + c2 * r2 * (G - X[i])\n            # Clamp velocity\n            V[i] = np.clip(V[i], -vmax, vmax)\n            # Proposed position\n            X_prop = X[i] + V[i]\n            # Feasibility check before correction (attempted feasibility)\n            inside = (X_prop = l - 1e-12)  (X_prop = u + 1e-12)\n            if np.all(inside):\n                feasible_props += 1\n            # Apply boundary handling per component\n            for j in range(d):\n                xpj = X_prop[j]\n                vj = V[i, j]\n                if scheme == 'reflect':\n                    x_new, v_new = reflect_component(xpj, vj, l, u)\n                elif scheme == 'absorb':\n                    x_new, v_new = absorb_component(xpj, vj, l, u)\n                elif scheme == 'restart':\n                    x_new, v_new = restart_component(xpj, vj, l, u, rng)\n                else:\n                    # Default: clamp (should not happen in provided tests)\n                    x_new = min(max(xpj, l), u)\n                    v_new = vj\n                X[i, j] = x_new\n                V[i, j] = v_new\n            # Evaluate and update personal best\n            f_val = sphere_shifted(X[i], a)\n            if f_val  P_fit[i]:\n                P[i] = X[i].copy()\n                P_fit[i] = f_val\n        # Update global best\n        g_idx = int(np.argmin(P_fit))\n        if P_fit[g_idx]  G_fit:\n            G_fit = P_fit[g_idx]\n            G = P[g_idx].copy()\n        # Convergence check\n        if (not converged) and (G_fit = eps):\n            converged = True\n            t_star = t\n\n    r_feasible = feasible_props / total_props\n    f_star = G_fit\n    return [f_star, r_feasible, converged, t_star]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, reflect\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([1.5, -2.0, 0.5, -1.0, 2.0], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"reflect\",\n            \"seed\": 42, \"eps\": 1e-6\n        },\n        # Case 2: near upper boundary, absorb\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([4.9, 4.8, 4.7, 4.6, 4.5], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"absorb\",\n            \"seed\": 123, \"eps\": 1e-6\n        },\n        # Case 3: unattainable zero within domain, random restart\n        {\n            \"d\": 5, \"l\": -2.0, \"u\": 2.0,\n            \"a\": np.array([10.0, 10.0, 10.0, 10.0, 10.0], dtype=float),\n            \"N\": 40, \"T\": 300,\n            \"w\": 0.8, \"c1\": 1.7, \"c2\": 1.7,\n            \"vmax\": 4.0, \"scheme\": \"restart\",\n            \"seed\": 7, \"eps\": 1e-6\n        },\n        # Case 4: low dimension, overshoot, reflect\n        {\n            \"d\": 2, \"l\": -1.0, \"u\": 1.0,\n            \"a\": np.array([0.99, -0.99], dtype=float),\n            \"N\": 10, \"T\": 150,\n            \"w\": 0.9, \"c1\": 2.05, \"c2\": 2.05,\n            \"vmax\": 2.0, \"scheme\": \"reflect\",\n            \"seed\": 999, \"eps\": 1e-6\n        },\n        # Case 5: small domain, absorb\n        {\n            \"d\": 3, \"l\": 0.0, \"u\": 1.0,\n            \"a\": np.array([0.9, 0.1, 0.5], dtype=float),\n            \"N\": 12, \"T\": 150,\n            \"w\": 0.6, \"c1\": 1.4, \"c2\": 1.4,\n            \"vmax\": 1.0, \"scheme\": \"absorb\",\n            \"seed\": 2024, \"eps\": 1e-6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        res = pso_run(\n            d=case[\"d\"], l=case[\"l\"], u=case[\"u\"], a=case[\"a\"], N=case[\"N\"], T=case[\"T\"],\n            w=case[\"w\"], c1=case[\"c1\"], c2=case[\"c2\"], vmax=case[\"vmax\"],\n            scheme=case[\"scheme\"], seed=case[\"seed\"], eps=case[\"eps\"]\n        )\n        results.append(res)\n\n    # Final print statement in the exact required format (single line, no spaces).\n    # Convert to string and remove spaces for a compact bracketed list.\n    out = str(results).replace(\" \", \"\")\n    print(out)\n\nsolve()\n```", "id": "3161093"}, {"introduction": "One of the greatest challenges in global optimization is the risk of premature convergence, where an algorithm becomes trapped in a local minimum, failing to find the true global solution. This exercise provides a hands-on demonstration of this phenomenon by designing a specific scenario that deliberately traps a PSO swarm in a suboptimal basin of attraction. You will then implement a diversification strategy—probabilistic random jumps—to show how injecting exploration can enable the swarm to escape the trap and successfully locate the global minimum [@problem_id:3160999]. This practice illuminates the critical balance between exploration and exploitation that underpins the success of all metaheuristic algorithms.", "problem": "You are to design and implement a one-dimensional Particle Swarm Optimization (PSO) experiment that demonstrates a worst-case initialization that traps the swarm in a strict local basin of attraction and then mitigates this failure mode by introducing diversification via random jumps with a time-dependent probability. Your program must simulate the canonical PSO dynamics and report quantitative outcomes for a small test suite.\n\nThe fundamental base is the canonical PSO state update, reproduced here. Let there be $N$ particles in one dimension, with state for particle $i$ at time $t$ given by position $x_{i,t} \\in \\mathbb{R}$ and velocity $v_{i,t} \\in \\mathbb{R}$. Each particle maintains a personal best position $p_{i,t}$, and the swarm maintains a global best position $g_t$. The canonical updates are\n$$\nv_{i,t+1} \\leftarrow \\omega\\, v_{i,t} \\;+\\; c_1\\, r_{1,i,t}\\, \\big(p_{i,t} - x_{i,t}\\big) \\;+\\; c_2\\, r_{2,i,t}\\, \\big(g_t - x_{i,t}\\big),\n$$\n$$\nx_{i,t+1} \\leftarrow x_{i,t} + v_{i,t+1},\n$$\nwhere $r_{1,i,t}, r_{2,i,t} \\sim \\mathrm{Uniform}([0,1])$ are independent random variables. After updating $x_{i,t+1}$, the objective $f(x_{i,t+1})$ is evaluated to update $p_{i,t+1}$ and $g_{t+1}$ in the standard way: $p_{i,t+1}$ replaces $p_{i,t}$ if and only if $f(x_{i,t+1})  f(p_{i,t})$, and $g_{t+1}$ is the best of $\\{p_{i,t+1}\\}_{i=1}^N$.\n\nThe objective is the smooth, multimodal function\n$$\nf(x) \\;=\\; x^2 \\;-\\; b \\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n$$\nwith parameters $b = 12$, $\\mu = 4$, and $\\sigma = 0.5$. The search domain is the closed interval $\\mathcal{D} = [-L,L]$ with $L = 6$. Positions must be clipped to $\\mathcal{D}$ after every update.\n\nWorst-case initialization that induces a trap: initialize all particle positions near the shallow local basin around $x \\approx \\mu$. Specifically, for some $\\delta  0$, sample $x_{i,0} \\sim \\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$ independently and set $v_{i,0} = 0$, $p_{i,0} = x_{i,0}$, and $g_0$ as the best among the $\\{p_{i,0}\\}$. Use $\\delta = 0.2$. This construction ensures that initially $p_{i,0} - x_{i,0} = 0$ for all $i$, and $g_0$ lies in the same shallow basin of attraction.\n\nDiversification via random jumps: after computing $x_{i,t+1}$ from the canonical update but before evaluating $f(x_{i,t+1})$, apply the following rule independently for each particle $i$. With probability $\\pi(t)$, draw a new position $\\tilde{x}_{i,t+1} \\sim \\mathrm{Uniform}(\\mathcal{D})$ and set $x_{i,t+1} \\leftarrow \\tilde{x}_{i,t+1}$ and $v_{i,t+1} \\leftarrow 0$. Otherwise, leave $x_{i,t+1}$ and $v_{i,t+1}$ unchanged. Then evaluate $f(x_{i,t+1})$ and update $p_{i,t+1}$ and $g_{t+1}$ as above. This diversification injects exploration by making $p_{i,t} - x_{i,t}$ and $g_t - x_{i,t}$ nonzero after a jump, even if the swarm was previously stagnant.\n\nAlgorithmic requirements:\n- Use the canonical PSO updates with parameters $\\omega$, $c_1$, and $c_2$ as specified per test case.\n- Use the same initialization mechanism described above for all test cases, but with different random seeds as provided.\n- All random numbers, including initial positions, the $r_{1,i,t}$, $r_{2,i,t}$, and random jumps, must be generated from a reproducible pseudo-random number generator seeded as specified.\n- After each position update and any applied jump, clip positions to $\\mathcal{D}$.\n- The objective $f(x)$ must be evaluated exactly as defined. No physical units or angles are involved in this problem.\n\nTest suite: implement five test cases, each defined by a tuple $(N, T, \\omega, c_1, c_2, \\pi(\\cdot), \\text{seed})$. The probability schedule $\\pi(t)$ is a function of the discrete iteration index $t \\in \\{0,1,\\dots,T-1\\}$.\n\n- Case A (no diversification, many particles): $N = 20$, $T = 80$, $\\omega = 0.6$, $c_1 = 1.7$, $c_2 = 1.7$, $\\pi(t) \\equiv 0$, $\\text{seed} = 123$.\n- Case B (constant diversification, many particles): $N = 20$, $T = 80$, $\\omega = 0.6$, $c_1 = 1.7$, $c_2 = 1.7$, $\\pi(t) \\equiv 0.05$, $\\text{seed} = 123$.\n- Case C (annealed diversification): $N = 10$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) = 0.3 \\cdot \\big(1 - \\frac{t}{T}\\big)$, $\\text{seed} = 456$.\n- Case D (edge case, single particle, no diversification): $N = 1$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) \\equiv 0$, $\\text{seed} = 789$.\n- Case E (edge case, single particle, constant diversification): $N = 1$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) \\equiv 0.2$, $\\text{seed} = 789$.\n\nFor all cases use the same objective parameters $b = 12$, $\\mu = 4$, $\\sigma = 0.5$, domain half-width $L = 6$, and initialization width $\\delta = 0.2$.\n\nRequired outputs:\n- For each test case, run the PSO for $T$ iterations and report the final best objective value $\\min_{i} f(p_{i,T})$ as a floating-point number rounded to four decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\\,[\\text{result}_1,\\text{result}_2,\\dots]$). The ordering must be $[\\text{Case A}, \\text{Case B}, \\text{Case C}, \\text{Case D}, \\text{Case E}]$.", "solution": "The problem presents a well-posed and computationally verifiable task within the domain of optimization methods, specifically focusing on Particle Swarm Optimization (PSO). All parameters, equations, and experimental conditions are explicitly defined, rendering the problem valid and free of scientific or logical inconsistencies. The setup is designed to demonstrate a common failure mode of PSO—premature convergence to a local optimum—and a mitigation strategy using a probabilistic diversification mechanism.\n\nThe core of the problem is to simulate a one-dimensional PSO algorithm under several parameter configurations. The algorithm's objective is to find the global minimum of the function $f(x)$:\n$$\nf(x) = x^2 - b \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\nwith parameters $b = 12$, $\\mu = 4$, and $\\sigma = 0.5$, within the search domain $\\mathcal{D} = [-6, 6]$. This function possesses a global minimum near $x=0$ with a value $f(x) \\approx 0$, and a prominent local minimum near $x \\approx 3.818$ with a value $f(x) \\approx 3.361$.\n\nThe algorithmic procedure will be implemented as follows, adhering to the principles of vectorization for computational efficiency.\n\n**1. System State and Initialization**\n\nThe state of the swarm of $N$ particles is defined by their positions $x \\in \\mathbb{R}^N$ and velocities $v \\in \\mathbb{R}^N$. Each particle also records its personal best position found so far, $p_{best} \\in \\mathbb{R}^N$, and the corresponding objective function values, $f_{p_{best}} \\in \\mathbb{R}^N$. The swarm collectively maintains the global best position, $g_{best} \\in \\mathbb{R}$, which is the personal best position corresponding to the minimum value among all $f_{p_{best}}$.\n\nThe initialization is specifically designed to trap the swarm. All particle positions $x_i$ for $i=1, \\dots, N$ are drawn from a uniform distribution $\\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$, which is $[3.8, 4.2]$. This region constitutes the basin of attraction for the local minimum. Initial velocities are set to zero, $v_{i,0}=0$. The initial personal best positions are set to the initial positions, $p_{best; i,0} = x_{i,0}$, and the initial global best $g_{best,0}$ is determined by finding the minimum of $f(x)$ over these initial positions. A reproducible pseudo-random number generator, seeded as specified for each case, ensures deterministic outcomes.\n\n**2. Iterative Dynamics**\n\nThe simulation proceeds for $T$ discrete time steps (iterations). At each time step $t$, the state is updated to $t+1$.\n\n**2.1. Velocity and Position Update**\n\nThe core of the canonical PSO algorithm is the update of each particle's velocity and position. Using a vectorized representation, the updates from time $t$ to $t+1$ are:\n$$\nv_{t+1} \\leftarrow \\omega v_t + c_1 r_{1,t} \\odot (p_{best,t} - x_t) + c_2 r_{2,t} \\odot (g_{best,t} - x_t)\n$$\n$$\nx_{t+1} \\leftarrow x_t + v_{t+1}\n$$\nwhere $\\omega$, $c_1$, and $c_2$ are the inertia weight, cognitive coefficient, and social coefficient, respectively. The symbols $r_{1,t}, r_{2,t} \\in \\mathbb{R}^N$ represent vectors of random numbers drawn independently from $\\mathrm{Uniform}([0,1])$. The operator $\\odot$ denotes element-wise multiplication.\n\n**2.2. Diversification via Random Jumps**\n\nTo counteract premature convergence, a random jump mechanism is introduced. After the position update, for each particle $i$, a random decision is made. With a time-dependent probability $\\pi(t)$, the particle's state is reset: its position $x_{i,t+1}$ is replaced by a new position drawn uniformly from the entire search domain $\\mathcal{D}$, and its velocity $v_{i,t+1}$ is reset to $0$. This action breaks the particle from the swarm's consensus and forces exploration of a new region.\n\n**2.3. Boundary Enforcement**\n\nAfter the position update and any potential random jump, all particle positions must be constrained to the search domain $\\mathcal{D} = [-L, L]$. This is achieved by clipping the values in the position vector $x_{t+1}$ to the range $[-6, 6]$.\n\n**2.4. Fitness Evaluation and Best Position Updates**\n\nThe objective function $f(x)$ is evaluated for all new particle positions $x_{t+1}$ to get a vector of current fitness values $f_{current}$. For each particle $i$, if its new fitness $f_{current, i}$ is better (i.e., less than) its previous personal best fitness $f_{p_{best}, i}$, its personal best is updated: $p_{best, i, t+1} \\leftarrow x_{i,t+1}$ and $f_{p_{best}, i, t+1} \\leftarrow f_{current, i}$. Otherwise, they remain unchanged.\n\nFollowing the update of all personal bests, the new global best position $g_{best,t+1}$ is determined by finding the particle with the overall minimum personal best value in the updated set $\\{f_{p_{best}, i, t+1}\\}$.\n\n**3. Simulation Execution and Output**\n\nThis entire iterative process is executed for each of the five test cases defined in the problem statement. Each case specifies a unique combination of parameters $(N, T, \\omega, c_1, c_2, \\pi(t), \\text{seed})$. After $T$ iterations, the final best objective value found by the swarm, which is $\\min_{i} f(p_{best, i, T})$, is recorded. The final output is a list of these values, one for each test case, formatted to four decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PSO simulation for all test cases and print results.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    B_PARAM = 12.0\n    MU_PARAM = 4.0\n    SIGMA_PARAM = 0.5\n    L_PARAM = 6.0\n    DELTA_PARAM = 0.2\n\n    def objective_function(x, b=B_PARAM, mu=MU_PARAM, sigma=SIGMA_PARAM):\n        \"\"\"\n        Calculates the value of the objective function f(x).\n        \"\"\"\n        return x**2 - b * np.exp(-((x - mu)**2) / (2 * sigma**2))\n\n    def run_pso_simulation(N, T, omega, c1, c2, pi_func, seed):\n        \"\"\"\n        Runs a single PSO simulation with the given parameters.\n        \n        Args:\n            N (int): Number of particles.\n            T (int): Number of iterations.\n            omega (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            pi_func (callable): Function pi(t, T) for jump probability.\n            seed (int): Seed for the random number generator.\n            \n        Returns:\n            float: The best objective value found after T iterations.\n        \"\"\"\n        # Initialize the pseudo-random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Initialization\n        # Initial positions are sampled near the local minimum trap\n        x = rng.uniform(MU_PARAM - DELTA_PARAM, MU_PARAM + DELTA_PARAM, size=N)\n        \n        # Initial velocities are zero\n        v = np.zeros(N)\n        \n        # Personal best positions initialized to starting positions\n        p_best_pos = np.copy(x)\n        \n        # Personal best values are f(p_best_pos)\n        p_best_val = objective_function(p_best_pos)\n        \n        # Global best position is the one with the minimum initial value\n        g_best_idx = np.argmin(p_best_val)\n        g_best_pos = p_best_pos[g_best_idx]\n        \n        # 2. Main PSO loop\n        for t in range(T):\n            # Generate random numbers for this iteration's updates\n            r1 = rng.random(size=N)\n            r2 = rng.random(size=N)\n            \n            # Canonical PSO updates (vectorized for efficiency)\n            # Velocity update\n            v = omega * v + c1 * r1 * (p_best_pos - x) + c2 * r2 * (g_best_pos - x)\n            \n            # Position update\n            x = x + v\n            \n            # Diversification via random jumps\n            pi_t = pi_func(t, T)\n            if pi_t  0:\n                jump_rand = rng.random(size=N)\n                jump_mask = jump_rand  pi_t\n                \n                if np.any(jump_mask):\n                    num_jumps = np.sum(jump_mask)\n                    # Draw new positions for jumping particles\n                    x[jump_mask] = rng.uniform(-L_PARAM, L_PARAM, size=num_jumps)\n                    # Reset velocity for jumping particles\n                    v[jump_mask] = 0.0\n\n            # Clipping positions to the search domain [-L, L]\n            x = np.clip(x, -L_PARAM, L_PARAM)\n            \n            # Evaluate objective function for new positions\n            f_x = objective_function(x)\n            \n            # Update personal bests\n            improvement_mask = f_x  p_best_val\n            p_best_pos[improvement_mask] = x[improvement_mask]\n            p_best_val[improvement_mask] = f_x[improvement_mask]\n            \n            # Update global best\n            g_best_idx = np.argmin(p_best_val)\n            g_best_pos = p_best_pos[g_best_idx]\n            \n        # After T iterations, return the best objective value found by any particle,\n        # which is the minimum of the final personal best values.\n        return np.min(p_best_val)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: (N, T, omega, c1, c2, pi_func, seed) - No diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.0, 'seed': 123},\n        # Case B: Constant diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.05, 'seed': 123},\n        # Case C: Annealed diversification\n        {'N': 10, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.3 * (1 - t / T_max), 'seed': 456},\n        # Case D: Single particle, no diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.0, 'seed': 789},\n        # Case E: Single particle, constant diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.2, 'seed': 789},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pso_simulation(**case)\n        results.append(f\"{result:.4f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3160999"}]}